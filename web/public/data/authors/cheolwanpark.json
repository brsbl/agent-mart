{
  "author": {
    "id": "cheolwanpark",
    "display_name": "CodingVillain",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/17137908?u=4151668fb08eb16d61ff0df03860473fe38fda04&v=4",
    "url": "https://github.com/cheolwanpark",
    "bio": null,
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 8,
      "total_commands": 4,
      "total_skills": 10,
      "total_stars": 2,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "personal-curation",
      "version": null,
      "description": "A research toolkit for claude code",
      "owner_info": {
        "name": "Cheolwan Park",
        "email": "cheolwan.park552@gmail.com"
      },
      "keywords": [],
      "repo_full_name": "cheolwanpark/claude-plugins",
      "repo_url": "https://github.com/cheolwanpark/claude-plugins",
      "repo_description": "A marketplace of curated Claude Code plugins for personal use",
      "homepage": null,
      "signals": {
        "stars": 2,
        "forks": 0,
        "pushed_at": "2026-01-14T01:26:19Z",
        "created_at": "2025-10-29T01:22:19Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 3786
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 413
        },
        {
          "path": "plugins/auto-review/README.md",
          "type": "blob",
          "size": 6991
        },
        {
          "path": "plugins/auto-review/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/hooks/hooks.json",
          "type": "blob",
          "size": 838
        },
        {
          "path": "plugins/auto-review/hooks/on_stop.sh",
          "type": "blob",
          "size": 1239
        },
        {
          "path": "plugins/auto-review/hooks/pre_exit_plan_mode.sh",
          "type": "blob",
          "size": 1108
        },
        {
          "path": "plugins/auto-review/hooks/user_prompt_submit.sh",
          "type": "blob",
          "size": 504
        },
        {
          "path": "plugins/auto-review/mcp",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/@anthropic-ai",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/@anthropic-ai/claude-agent-sdk",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/@anthropic-ai/claude-agent-sdk/README.md",
          "type": "blob",
          "size": 2041
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/@img",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/@img/sharp-darwin-arm64",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/@img/sharp-darwin-arm64/README.md",
          "type": "blob",
          "size": 699
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/@img/sharp-libvips-darwin-arm64",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/@img/sharp-libvips-darwin-arm64/README.md",
          "type": "blob",
          "size": 4333
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/@modelcontextprotocol",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/@modelcontextprotocol/sdk",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/@modelcontextprotocol/sdk/README.md",
          "type": "blob",
          "size": 47546
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/@openai",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/@openai/codex-sdk",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/@openai/codex-sdk/README.md",
          "type": "blob",
          "size": 3075
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/@types",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/@types/node",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/@types/node/README.md",
          "type": "blob",
          "size": 1541
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/accepts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/accepts/README.md",
          "type": "blob",
          "size": 4122
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/ajv-formats",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/ajv-formats/README.md",
          "type": "blob",
          "size": 6164
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/ajv",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/ajv/README.md",
          "type": "blob",
          "size": 13781
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/body-parser",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/body-parser/README.md",
          "type": "blob",
          "size": 19420
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/call-bind-apply-helpers",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/call-bind-apply-helpers/README.md",
          "type": "blob",
          "size": 2330
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/call-bound",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/call-bound/README.md",
          "type": "blob",
          "size": 1897
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/content-disposition",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/content-disposition/README.md",
          "type": "blob",
          "size": 5205
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/content-type",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/content-type/README.md",
          "type": "blob",
          "size": 2782
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/cookie",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/cookie/README.md",
          "type": "blob",
          "size": 11769
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/cors",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/cors/README.md",
          "type": "blob",
          "size": 9206
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/cross-spawn",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/cross-spawn/README.md",
          "type": "blob",
          "size": 4117
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/debug",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/debug/README.md",
          "type": "blob",
          "size": 22115
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/dunder-proto",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/dunder-proto/README.md",
          "type": "blob",
          "size": 1907
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/ee-first",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/ee-first/README.md",
          "type": "blob",
          "size": 2617
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/encodeurl",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/encodeurl/README.md",
          "type": "blob",
          "size": 3221
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/es-define-property",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/es-define-property/README.md",
          "type": "blob",
          "size": 2056
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/es-errors",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/es-errors/README.md",
          "type": "blob",
          "size": 2114
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/es-object-atoms",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/es-object-atoms/README.md",
          "type": "blob",
          "size": 2603
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/etag",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/etag/README.md",
          "type": "blob",
          "size": 4198
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/eventsource-parser",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/eventsource-parser/README.md",
          "type": "blob",
          "size": 5023
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/eventsource",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/eventsource/README.md",
          "type": "blob",
          "size": 5184
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/fast-deep-equal",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/fast-deep-equal/README.md",
          "type": "blob",
          "size": 3323
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/fast-uri",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/fast-uri/README.md",
          "type": "blob",
          "size": 11278
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/finalhandler",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/finalhandler/README.md",
          "type": "blob",
          "size": 4120
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/forwarded",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/forwarded/README.md",
          "type": "blob",
          "size": 1654
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/fresh",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/fresh/README.md",
          "type": "blob",
          "size": 3348
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/function-bind",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/function-bind/README.md",
          "type": "blob",
          "size": 1755
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/get-intrinsic",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/get-intrinsic/README.md",
          "type": "blob",
          "size": 2791
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/get-proto",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/get-proto/README.md",
          "type": "blob",
          "size": 1794
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/gopd",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/gopd/README.md",
          "type": "blob",
          "size": 1562
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/has-symbols",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/has-symbols/README.md",
          "type": "blob",
          "size": 2044
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/hasown",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/hasown/README.md",
          "type": "blob",
          "size": 1613
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/http-errors",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/http-errors/README.md",
          "type": "blob",
          "size": 5962
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/http-errors/node_modules",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/http-errors/node_modules/statuses",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/http-errors/node_modules/statuses/README.md",
          "type": "blob",
          "size": 3559
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/iconv-lite",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/iconv-lite/README.md",
          "type": "blob",
          "size": 6352
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/inherits",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/inherits/README.md",
          "type": "blob",
          "size": 1625
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/ipaddr.js",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/ipaddr.js/README.md",
          "type": "blob",
          "size": 8309
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/isexe",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/isexe/README.md",
          "type": "blob",
          "size": 1395
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/json-schema-traverse",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/json-schema-traverse/README.md",
          "type": "blob",
          "size": 3350
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/math-intrinsics",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/math-intrinsics/README.md",
          "type": "blob",
          "size": 1884
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/media-typer",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/media-typer/README.md",
          "type": "blob",
          "size": 2992
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/mime-db",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/mime-db/README.md",
          "type": "blob",
          "size": 4949
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/mime-types",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/mime-types/README.md",
          "type": "blob",
          "size": 4472
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/negotiator",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/negotiator/README.md",
          "type": "blob",
          "size": 5330
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/on-finished",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/on-finished/README.md",
          "type": "blob",
          "size": 5160
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/once",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/once/README.md",
          "type": "blob",
          "size": 1772
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/parseurl",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/parseurl/README.md",
          "type": "blob",
          "size": 4094
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/pkce-challenge",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/pkce-challenge/README.md",
          "type": "blob",
          "size": 1063
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/proxy-addr",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/proxy-addr/README.md",
          "type": "blob",
          "size": 4131
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/qs",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/qs/README.md",
          "type": "blob",
          "size": 25887
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/range-parser",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/range-parser/README.md",
          "type": "blob",
          "size": 2278
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/raw-body",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/raw-body/README.md",
          "type": "blob",
          "size": 6553
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/raw-body/node_modules",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/raw-body/node_modules/iconv-lite",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/raw-body/node_modules/iconv-lite/README.md",
          "type": "blob",
          "size": 6587
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/router",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/router/README.md",
          "type": "blob",
          "size": 12656
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/safe-buffer",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/safe-buffer/README.md",
          "type": "blob",
          "size": 19555
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/send",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/send/README.md",
          "type": "blob",
          "size": 9062
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/serve-static",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/serve-static/README.md",
          "type": "blob",
          "size": 7450
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/setprototypeof",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/setprototypeof/README.md",
          "type": "blob",
          "size": 844
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/side-channel-list",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/side-channel-list/README.md",
          "type": "blob",
          "size": 2285
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/side-channel-map",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/side-channel-map/README.md",
          "type": "blob",
          "size": 2278
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/side-channel-weakmap",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/side-channel-weakmap/README.md",
          "type": "blob",
          "size": 2342
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/side-channel",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/side-channel/README.md",
          "type": "blob",
          "size": 2152
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/statuses",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/statuses/README.md",
          "type": "blob",
          "size": 3866
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/toidentifier",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/toidentifier/README.md",
          "type": "blob",
          "size": 1803
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/type-is",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/type-is/README.md",
          "type": "blob",
          "size": 6504
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/typescript",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/typescript/README.md",
          "type": "blob",
          "size": 2842
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/undici-types",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/undici-types/README.md",
          "type": "blob",
          "size": 455
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/unpipe",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/unpipe/README.md",
          "type": "blob",
          "size": 1250
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/vary",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/vary/README.md",
          "type": "blob",
          "size": 2716
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/which",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/which/README.md",
          "type": "blob",
          "size": 1352
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/wrappy",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/wrappy/README.md",
          "type": "blob",
          "size": 685
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/zod-to-json-schema",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/zod-to-json-schema/README.md",
          "type": "blob",
          "size": 33661
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/zod",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/auto-review/mcp/node_modules/zod/README.md",
          "type": "blob",
          "size": 6247
        },
        {
          "path": "plugins/crypto",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/crypto/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/crypto/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 588
        },
        {
          "path": "plugins/crypto/README.md",
          "type": "blob",
          "size": 7189
        },
        {
          "path": "plugins/crypto/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/crypto/skills/evm-address-info",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/crypto/skills/evm-address-info/SKILL.md",
          "type": "blob",
          "size": 1483
        },
        {
          "path": "plugins/crypto/skills/evm-block-info",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/crypto/skills/evm-block-info/SKILL.md",
          "type": "blob",
          "size": 1413
        },
        {
          "path": "plugins/crypto/skills/evm-contract-source",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/crypto/skills/evm-contract-source/SKILL.md",
          "type": "blob",
          "size": 1879
        },
        {
          "path": "plugins/crypto/skills/evm-gas-price",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/crypto/skills/evm-gas-price/SKILL.md",
          "type": "blob",
          "size": 1220
        },
        {
          "path": "plugins/crypto/skills/evm-tx-info",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/crypto/skills/evm-tx-info/SKILL.md",
          "type": "blob",
          "size": 1448
        },
        {
          "path": "plugins/crypto/skills/sol-account-info",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/crypto/skills/sol-account-info/SKILL.md",
          "type": "blob",
          "size": 1230
        },
        {
          "path": "plugins/crypto/skills/sol-fees",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/crypto/skills/sol-fees/SKILL.md",
          "type": "blob",
          "size": 1014
        },
        {
          "path": "plugins/crypto/skills/sol-program-idl",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/crypto/skills/sol-program-idl/SKILL.md",
          "type": "blob",
          "size": 1290
        },
        {
          "path": "plugins/crypto/skills/sol-slot-info",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/crypto/skills/sol-slot-info/SKILL.md",
          "type": "blob",
          "size": 1218
        },
        {
          "path": "plugins/crypto/skills/sol-tx-info",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/crypto/skills/sol-tx-info/SKILL.md",
          "type": "blob",
          "size": 1237
        },
        {
          "path": "plugins/go-lint",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/go-lint/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/go-lint/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 516
        },
        {
          "path": "plugins/go-lint/README.md",
          "type": "blob",
          "size": 6938
        },
        {
          "path": "plugins/go-lint/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/go-lint/commands/lint-project.md",
          "type": "blob",
          "size": 233
        },
        {
          "path": "plugins/go-lint/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/go-lint/hooks/go-lint.sh",
          "type": "blob",
          "size": 4332
        },
        {
          "path": "plugins/go-lint/hooks/hooks.json",
          "type": "blob",
          "size": 358
        },
        {
          "path": "plugins/python-lint",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/python-lint/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/python-lint/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 525
        },
        {
          "path": "plugins/python-lint/README.md",
          "type": "blob",
          "size": 11174
        },
        {
          "path": "plugins/python-lint/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/python-lint/commands/lint-project.md",
          "type": "blob",
          "size": 241
        },
        {
          "path": "plugins/python-lint/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/python-lint/hooks/hooks.json",
          "type": "blob",
          "size": 377
        },
        {
          "path": "plugins/python-lint/hooks/python-lint.sh",
          "type": "blob",
          "size": 8189
        },
        {
          "path": "plugins/research",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/research/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/research/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 379
        },
        {
          "path": "plugins/research/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/research/agents/arxiv-search.md",
          "type": "blob",
          "size": 5370
        },
        {
          "path": "plugins/research/agents/devils-advocate.md",
          "type": "blob",
          "size": 6333
        },
        {
          "path": "plugins/research/agents/github-search.md",
          "type": "blob",
          "size": 4822
        },
        {
          "path": "plugins/research/agents/reddit-search.md",
          "type": "blob",
          "size": 6100
        },
        {
          "path": "plugins/research/agents/research-planner.md",
          "type": "blob",
          "size": 8800
        },
        {
          "path": "plugins/research/agents/web-research-specialist.md",
          "type": "blob",
          "size": 5663
        },
        {
          "path": "plugins/rust-lint",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/rust-lint/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/rust-lint/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 519
        },
        {
          "path": "plugins/rust-lint/README.md",
          "type": "blob",
          "size": 11545
        },
        {
          "path": "plugins/rust-lint/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/rust-lint/commands/lint-project.md",
          "type": "blob",
          "size": 246
        },
        {
          "path": "plugins/rust-lint/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/rust-lint/hooks/hooks.json",
          "type": "blob",
          "size": 351
        },
        {
          "path": "plugins/rust-lint/hooks/rust-lint.sh",
          "type": "blob",
          "size": 3275
        },
        {
          "path": "plugins/search",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/search/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/search/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 419
        },
        {
          "path": "plugins/search/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/search/agents/brave.md",
          "type": "blob",
          "size": 1268
        },
        {
          "path": "plugins/search/agents/context7.md",
          "type": "blob",
          "size": 3081
        },
        {
          "path": "plugins/typescript-lint",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/typescript-lint/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/typescript-lint/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 489
        },
        {
          "path": "plugins/typescript-lint/README.md",
          "type": "blob",
          "size": 10276
        },
        {
          "path": "plugins/typescript-lint/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/typescript-lint/commands/lint-project.md",
          "type": "blob",
          "size": 257
        },
        {
          "path": "plugins/typescript-lint/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/typescript-lint/hooks/hooks.json",
          "type": "blob",
          "size": 220
        },
        {
          "path": "plugins/typescript-lint/hooks/typescript-lint.sh",
          "type": "blob",
          "size": 6382
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n    \"name\": \"personal-curation\",\n    \"owner\": {\n        \"name\": \"Cheolwan Park\",\n        \"email\": \"cheolwan.park552@gmail.com\"\n    },\n    \"plugins\": [\n        {\n            \"name\": \"research\",\n            \"description\": \"A research toolkit for claude code\",\n            \"source\": \"./plugins/research\",\n            \"author\": {\n                \"name\": \"Cheolwan Park\",\n                \"url\": \"https://github.com/cheolwanpark\"\n            },\n            \"repository\": \"https://github.com/cheolwanpark/useful-claude-plugins\",\n            \"license\": \"MIT\"\n        },\n        {\n            \"name\": \"python-lint\",\n            \"description\": \"Automatically lint, format, and type-check Python files with ruff and pyright\",\n            \"source\": \"./plugins/python-lint\",\n            \"author\": {\n                \"name\": \"Cheolwan Park\",\n                \"url\": \"https://github.com/cheolwanpark\"\n            },\n            \"repository\": \"https://github.com/cheolwanpark/useful-claude-plugins\",\n            \"license\": \"MIT\"\n        },\n        {\n            \"name\": \"auto-review\",\n            \"description\": \"Automated code review using gemini-cli and codex\",\n            \"source\": \"./plugins/auto-review\",\n            \"author\": {\n                \"name\": \"Cheolwan Park\",\n                \"url\": \"https://github.com/cheolwanpark\"\n            },\n            \"repository\": \"https://github.com/cheolwanpark/useful-claude-plugins\",\n            \"license\": \"MIT\"\n        },\n        {\n            \"name\": \"typescript-lint\",\n            \"description\": \"Automatically lint, format, and type-check TypeScript files with ESLint and TypeScript compiler\",\n            \"source\": \"./plugins/typescript-lint\",\n            \"author\": {\n                \"name\": \"Cheolwan Park\",\n                \"url\": \"https://github.com/cheolwanpark\"\n            },\n            \"repository\": \"https://github.com/cheolwanpark/useful-claude-plugins\",\n            \"license\": \"MIT\"\n        },\n        {\n            \"name\": \"rust-lint\",\n            \"description\": \"Automatically format Rust files with rustfmt and provide on-demand clippy linting\",\n            \"source\": \"./plugins/rust-lint\",\n            \"author\": {\n                \"name\": \"Cheolwan Park\",\n                \"url\": \"https://github.com/cheolwanpark\"\n            },\n            \"repository\": \"https://github.com/cheolwanpark/useful-claude-plugins\",\n            \"license\": \"MIT\"\n        },\n        {\n            \"name\": \"go-lint\",\n            \"description\": \"Automatically lint and format Go files using goimports, go vet, and golangci-lint\",\n            \"source\": \"./plugins/go-lint\",\n            \"author\": {\n                \"name\": \"Cheolwan Park\",\n                \"url\": \"https://github.com/cheolwanpark\"\n            },\n            \"repository\": \"https://github.com/cheolwanpark/useful-claude-plugins\",\n            \"license\": \"MIT\"\n        },\n        {\n            \"name\": \"search\",\n            \"description\": \"Access up-to-date library documentation and code examples via Context7 API\",\n            \"source\": \"./plugins/search\",\n            \"author\": {\n                \"name\": \"Cheolwan Park\",\n                \"url\": \"https://github.com/cheolwanpark\"\n            },\n            \"repository\": \"https://github.com/cheolwanpark/useful-claude-plugins\",\n            \"license\": \"MIT\"\n        },\n        {\n            \"name\": \"crypto\",\n            \"description\": \"Multi-chain blockchain explorer using Foundry's cast CLI for Etherscan, Polygonscan, Arbiscan, and more\",\n            \"source\": \"./plugins/crypto\",\n            \"author\": {\n                \"name\": \"Cheolwan Park\",\n                \"url\": \"https://github.com/cheolwanpark\"\n            },\n            \"repository\": \"https://github.com/cheolwanpark/useful-claude-plugins\",\n            \"license\": \"MIT\"\n        }\n    ]\n}",
        "plugins/auto-review/.claude-plugin/plugin.json": "{\n  \"name\": \"auto-review\",\n  \"description\": \"Automated code review using gemini-cli and codex\",\n  \"version\": \"1.0.0\",\n  \"author\": {\n    \"name\": \"Cheolwan Park\",\n    \"url\": \"https://github.com/cheolwanpark\"\n  },\n  \"repository\": \"https://github.com/cheolwanpark/useful-claude-plugins\",\n  \"license\": \"MIT\",\n  \"keywords\": [\"review\", \"gemini\", \"codex\", \"automation\", \"code-quality\"],\n  \"hooks\": \"./hooks/hooks.json\"\n}\n",
        "plugins/auto-review/README.md": "# Auto-Review Plugin\n\nAutomated triple-AI code review system for Claude Code that provides critical feedback on plans and implementations using Gemini, Codex, and Claude in parallel.\n\n## Overview\n\nThe auto-review plugin integrates with Claude Code through hooks and an MCP (Model Context Protocol) server to automatically trigger comprehensive code reviews at strategic workflow points:\n- **Before executing plans** - Critical review of feasibility, risks, and gaps\n- **Before completing work** - Critical review of implementation quality and correctness\n\n## Concept & Mechanism\n\nThe plugin intercepts Claude's workflow using hooks, which trigger triple-AI reviews via an MCP server:\n\n```\nUser Action\n    ↓\nHook Intercepts (bash scripts)\n    ↓\nMCP Server Receives Request (TypeScript)\n    ↓\n    ├─→ Gemini CLI Review (parallel)\n    ├─→ Codex SDK Review (parallel)\n    └─→ Claude Agent SDK Review (parallel)\n    ↓\nAggregated Results\n    ↓\nClaude Analyzes & Acts on Feedback\n```\n\n### Workflow Details\n\n1. **Plan Mode Entry**: `UserPromptSubmit` hook detects plan mode and sets review flag\n2. **Plan Review Trigger**: `PreToolUse` hook blocks `ExitPlanMode`, prompts Claude to call `review_plan`\n3. **Implementation Review**: `Stop` hook prompts Claude to self-evaluate and call `review_impl` if significant changes were made\n4. **Triple-AI Processing**: MCP server runs Gemini, Codex, and Claude reviews in parallel\n5. **Feedback Integration**: Claude receives critical feedback and may revise plan/code\n\n## Hooks\n\nThe plugin uses 3 hooks to intercept workflow events:\n\n### 1. UserPromptSubmit Hook\n- **File**: `hooks/user_prompt_submit.sh`\n- **Trigger**: When user submits a prompt\n- **Action**: Detects plan mode entry and creates flag file `/tmp/<session_id>/.auto_review_required`\n- **Purpose**: Mark that plan review is needed\n\n### 2. PreToolUse Hook (ExitPlanMode)\n- **File**: `hooks/pre_exit_plan_mode.sh`\n- **Trigger**: Before Claude calls `ExitPlanMode` tool\n- **Action**:\n  - Checks for review flag file\n  - If exists: Blocks with exit code 2, instructs Claude to call `review_plan`, deletes flag\n  - If not: Allows ExitPlanMode to proceed\n- **Purpose**: Ensure plans are reviewed before execution\n\n### 3. Stop Hook\n- **File**: `hooks/on_stop.sh`\n- **Trigger**: When Claude is about to stop/finish\n- **Action**: Outputs evaluation prompt for Claude to self-evaluate if significant implementation occurred\n- **Output**: Returns JSON decision to block/approve with instructions to call `review_impl`\n- **Purpose**: Ensure implementations are reviewed before completion\n\n## MCP Server\n\nLocated in `mcp/` directory, provides 2 review tools via Model Context Protocol:\n\n### review_plan\n\nReviews project plans for feasibility and potential issues using Gemini, Codex, and Claude.\n\n**Parameters:**\n- `plan` (string): The plan to review\n- `user_purpose` (string): User's intended purpose or goal\n- `context` (string): Additional context for the review\n- `cwd` (string, optional): Working directory\n\n**Returns:**\n```json\n{\n  \"review_by_gemini\": \"Critical analysis...\",\n  \"review_by_codex\": \"Critical analysis...\",\n  \"review_by_claude\": \"Critical analysis...\"\n}\n```\n\n**Focus Areas:**\n- Feasibility issues (what won't work and why)\n- Potential risks/problems (concrete issues)\n- Missing considerations\n- Actionable improvements\n\n### review_impl\n\nReviews implementations against plans using Gemini, Codex, and Claude.\n\n**Parameters:**\n- `plan` (string): The original plan\n- `impl_detail` (string): Implementation details to review\n- `context` (string): Additional context\n- `cwd` (string, optional): Working directory\n\n**Returns:**\n```json\n{\n  \"review_by_gemini\": \"Critical analysis...\",\n  \"review_by_codex\": \"Critical analysis...\",\n  \"review_by_claude\": \"Critical analysis...\"\n}\n```\n\n**Focus Areas:**\n- Plan deviations (how implementation differs)\n- Correctness issues (bugs, errors, logic problems)\n- Code quality problems (antipatterns, inefficiencies)\n- Concrete improvement suggestions\n\n## Prerequisites\n\nInstall these tools before using the plugin:\n\n- **Node.js 18+** - For MCP server\n- **[gemini-cli](https://github.com/google-gemini/gemini-cli)** - Gemini AI integration\n- **[Codex SDK](https://openai.com/index/introducing-codex/)** - OpenAI Codex integration\n- **Claude Code** - With active authentication (used by Claude Agent SDK)\n- **jq** - JSON parsing in bash hooks\n\n## Installation\n\n### 1. Install MCP Server Dependencies\n\n```bash\ncd plugins/auto-review/mcp\nnpm install\nnpm run build\n```\n\n### 2. Configure MCP Server\n\nAdd to your `.mcp.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"auto-review\": {\n      \"type\": \"stdio\",\n      \"command\": \"npx\",\n      \"args\": [\n        \"-y\",\n        \"/absolute/path/to/useful-claude-plugins/plugins/auto-review/mcp\"\n      ],\n      \"env\": {}\n    }\n  }\n}\n```\n\n**Alternative configurations:**\n\nUsing node directly:\n```json\n{\n  \"mcpServers\": {\n    \"auto-review\": {\n      \"type\": \"stdio\",\n      \"command\": \"node\",\n      \"args\": [\n        \"/absolute/path/to/plugins/auto-review/mcp/dist/index.js\"\n      ],\n      \"env\": {}\n    }\n  }\n}\n```\n\n### 3. Enable Plugin\n\nThe hooks are automatically loaded from `hooks/hooks.json` when the plugin is installed.\n\n## Example\n\nWhen Claude creates a plan to add a new authentication feature:\n\n1. **Plan Mode Entry**: User requests \"Add OAuth authentication\"\n2. **Claude Creates Plan**: Outlines steps for OAuth integration\n3. **Review Triggered**: PreToolUse hook blocks ExitPlanMode\n4. **Triple Review Runs**:\n   - **Gemini**: \"Missing rate limiting, session management, CSRF protection...\"\n   - **Codex**: \"No token refresh strategy, security headers not considered...\"\n   - **Claude**: \"Lacks error handling for OAuth failures, missing state validation...\"\n5. **Claude Revises**: Incorporates feedback, adds missing security measures\n6. **Execution Approved**: Plan proceeds with improvements\n\nSimilar workflow occurs for implementation reviews when work is completed.\n\n## Project Structure\n\n```\nplugins/auto-review/\n├── .claude-plugin/\n│   └── plugin.json           # Plugin metadata\n├── .mcp.json                  # MCP server configuration\n├── hooks/\n│   ├── hooks.json             # Hook definitions\n│   ├── user_prompt_submit.sh # Plan mode detector\n│   ├── pre_exit_plan_mode.sh # Plan review trigger\n│   └── on_stop.sh             # Implementation review evaluator\n└── mcp/                       # MCP server implementation\n    ├── src/\n    │   ├── server.ts          # MCP server & tool registration\n    │   ├── tools/             # review_plan, review_impl\n    │   ├── prompts/           # Review prompt builders\n    │   └── utils/             # Gemini/Codex wrappers\n    └── dist/                  # Compiled output\n```\n\n## Development\n\n```bash\ncd mcp\n\n# Install dependencies\nnpm install\n\n# Build\nnpm run build\n\n# Watch mode (auto-rebuild)\nnpm run dev\n```\n\n## License\n\nMIT\n",
        "plugins/auto-review/hooks/hooks.json": "{\n  \"description\": \"Automatically trigger plan and implementation reviews at appropriate times\",\n  \"hooks\": {\n    \"UserPromptSubmit\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"\\\"${CLAUDE_PLUGIN_ROOT}\\\"/hooks/user_prompt_submit.sh\",\n            \"timeout\": 10\n          }\n        ]\n      }\n    ],\n    \"PreToolUse\": [\n      {\n        \"matcher\": \"ExitPlanMode\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"\\\"${CLAUDE_PLUGIN_ROOT}\\\"/hooks/pre_exit_plan_mode.sh\",\n            \"timeout\": 10\n          }\n        ]\n      }\n    ],\n    \"Stop\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"\\\"${CLAUDE_PLUGIN_ROOT}\\\"/hooks/on_stop.sh\",\n            \"timeout\": 30\n          }\n        ]\n      }\n    ]\n  }\n}\n",
        "plugins/auto-review/hooks/on_stop.sh": "#!/bin/bash\n\n# Read JSON input from stdin\nINPUT=$(cat)\n\n# Extract session_id\nSESSION_ID=$(echo \"$INPUT\" | jq -r '.session_id // empty')\n\n# Check if implementation review flag exists\nREVIEW_FLAG=\"/tmp/$SESSION_ID/.impl_review_required\"\n\nif [ -f \"$REVIEW_FLAG\" ]; then\n  # Delete the flag and block with review prompt\n  rm -f \"$REVIEW_FLAG\"\n  cat <<'EOF'\n{\n  \"decision\": \"block\",\n  \"reason\": \"Implementation review required.\\n\\nAnalyze what you accomplished:\\n- Did you make SIGNIFICANT code changes (new features, refactoring, bug fixes)?\\n- Do the changes warrant critical review for correctness and quality?\\n- Skip if: only trivial changes (typos, comments, formatting), no code written, or already reviewed\\n\\nIf significant implementation occurred, please run the 'mcp__plugin_auto-review_auto-review__review_impl' tool with:\\n- plan: '<the original plan you were implementing>'\\n- impl_detail: '<summary of what you implemented: files changed, functions added, key logic>'\\n- context: '<technology stack, coding standards, architecture patterns, dependencies>'\\n\\nAfter reviewing the feedback, address any issues found before stopping.\"\n}\nEOF\n  exit 0\nfi\n\n# No flag, approve stopping\ncat <<'EOF'\n{\n  \"decision\": \"approve\"\n}\nEOF\nexit 0",
        "plugins/auto-review/hooks/pre_exit_plan_mode.sh": "#!/bin/bash\n\n# Read JSON input from stdin\nINPUT=$(cat)\n\n# Extract session_id\nSESSION_ID=$(echo \"$INPUT\" | jq -r '.session_id // empty')\n\n# Exit if we can't extract required fields\nif [ -z \"$SESSION_ID\" ]; then\n  exit 0\nfi\n\n# Check if review is required\nFLAG_FILE=\"/tmp/$SESSION_ID/.auto_review_required\"\n\nif [ -f \"$FLAG_FILE\" ]; then\n  # Remove the flag file\n  rm -f \"$FLAG_FILE\"\n\n  # Print the review request message to stderr (exit code 2 will block and show this to Claude)\n  cat >&2 <<'EOF'\nThe plan requires review. Please run the tool 'mcp__plugin_auto-review_auto-review__review_plan' with these parameters:\n- plan: '<summarize the plan steps clearly>'\n- user_purpose: '<the user's stated goal or purpose>'\n- context: '<technology stack, constraints, project type, any relevant background>'\n\nAfter reviewing the feedback, you may revise the plan if needed, then present it again.\nEOF\n\n  exit 2\nfi\n\n# No review required, allow the tool call\n# Create implementation review flag to signal that implementation will happen\nmkdir -p \"/tmp/$SESSION_ID\"\ntouch \"/tmp/$SESSION_ID/.impl_review_required\"\n\nexit 0\n",
        "plugins/auto-review/hooks/user_prompt_submit.sh": "#!/bin/bash\n\n# Read JSON input from stdin\nINPUT=$(cat)\n\n# Extract session_id and permission_mode\nSESSION_ID=$(echo \"$INPUT\" | jq -r '.session_id // empty')\nPERMISSION_MODE=$(echo \"$INPUT\" | jq -r '.permission_mode // empty')\n\n# Exit if we can't extract required fields\nif [ -z \"$SESSION_ID\" ]; then\n  exit 0\nfi\n\n# If permission_mode is \"plan\", set the review required flag\nif [ \"$PERMISSION_MODE\" = \"plan\" ]; then\n  mkdir -p \"/tmp/$SESSION_ID\"\n  touch \"/tmp/$SESSION_ID/.auto_review_required\"\nfi\n\nexit 0\n",
        "plugins/auto-review/mcp/node_modules/@anthropic-ai/claude-agent-sdk/README.md": "# Claude Agent SDK\n\n![](https://img.shields.io/badge/Node.js-18%2B-brightgreen?style=flat-square) [![npm]](https://www.npmjs.com/package/@anthropic-ai/claude-agent-sdk)\n\n[npm]: https://img.shields.io/npm/v/@anthropic-ai/claude-agent-sdk.svg?style=flat-square\n\nThe Claude Agent SDK enables you to programmatically build AI agents with Claude Code's capabilities. Create autonomous agents that can understand codebases, edit files, run commands, and execute complex workflows.\n\n**Learn more in the [official documentation](https://docs.claude.com/en/api/agent-sdk/overview)**.\n\n## Get started\n\nInstall the Claude Agent SDK:\n\n```sh\nnpm install @anthropic-ai/claude-agent-sdk\n```\n\n## Migrating from the Claude Code SDK\n\nThe Claude Code SDK is now the Claude Agent SDK. Please check out the [migration guide](https://docs.claude.com/en/docs/claude-code/sdk/migration-guide) for details on breaking changes.\n\n## Reporting Bugs\n\nWe welcome your feedback. File a [GitHub issue](https://github.com/anthropics/claude-agent-sdk-typescript/issues) to report bugs or request features.\n\n## Connect on Discord\n\nJoin the [Claude Developers Discord](https://anthropic.com/discord) to connect with other developers building with the Claude Agent SDK. Get help, share feedback, and discuss your projects with the community.\n\n## Data collection, usage, and retention\n\nWhen you use the Claude Agent SDK, we collect feedback, which includes usage data (such as code acceptance or rejections), associated conversation data, and user feedback submitted via the /bug command.\n\n### How we use your data\n\nSee our [data usage policies](https://docs.anthropic.com/en/docs/claude-code/data-usage).\n\n### Privacy safeguards\n\nWe have implemented several safeguards to protect your data, including limited retention periods for sensitive information and restricted access to user session data.\n\nFor full details, please review our [Commercial Terms of Service](https://www.anthropic.com/legal/commercial-terms) and [Privacy Policy](https://www.anthropic.com/legal/privacy).\n\n",
        "plugins/auto-review/mcp/node_modules/@img/sharp-darwin-arm64/README.md": "# `@img/sharp-darwin-arm64`\n\nPrebuilt sharp for use with macOS 64-bit ARM.\n\n## Licensing\n\nCopyright 2013 Lovell Fuller and others.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n[https://www.apache.org/licenses/LICENSE-2.0](https://www.apache.org/licenses/LICENSE-2.0)\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n",
        "plugins/auto-review/mcp/node_modules/@img/sharp-libvips-darwin-arm64/README.md": "# `@img/sharp-libvips-darwin-arm64`\n\nPrebuilt libvips and dependencies for use with sharp on macOS 64-bit ARM.\n\n## Licensing\n\nThis software contains third-party libraries\nused under the terms of the following licences:\n\n| Library       | Used under the terms of                                                                                   |\n|---------------|-----------------------------------------------------------------------------------------------------------|\n| aom           | BSD 2-Clause + [Alliance for Open Media Patent License 1.0](https://aomedia.org/license/patent-license/)  |\n| cairo         | Mozilla Public License 2.0                                                                                |\n| cgif          | MIT Licence                                                                                               |\n| expat         | MIT Licence                                                                                               |\n| fontconfig    | [fontconfig Licence](https://gitlab.freedesktop.org/fontconfig/fontconfig/blob/main/COPYING) (BSD-like)   |\n| freetype      | [freetype Licence](https://git.savannah.gnu.org/cgit/freetype/freetype2.git/tree/docs/FTL.TXT) (BSD-like) |\n| fribidi       | LGPLv3                                                                                                    |\n| glib          | LGPLv3                                                                                                    |\n| harfbuzz      | MIT Licence                                                                                               |\n| highway       | Apache-2.0 License, BSD 3-Clause                                                                          |\n| lcms          | MIT Licence                                                                                               |\n| libarchive    | BSD 2-Clause                                                                                              |\n| libexif       | LGPLv3                                                                                                    |\n| libffi        | MIT Licence                                                                                               |\n| libheif       | LGPLv3                                                                                                    |\n| libimagequant | [BSD 2-Clause](https://github.com/lovell/libimagequant/blob/main/COPYRIGHT)                               |\n| libnsgif      | MIT Licence                                                                                               |\n| libpng        | [libpng License](https://github.com/pnggroup/libpng/blob/master/LICENSE)                                  |\n| librsvg       | LGPLv3                                                                                                    |\n| libspng       | [BSD 2-Clause, libpng License](https://github.com/randy408/libspng/blob/master/LICENSE)                   |\n| libtiff       | [libtiff License](https://gitlab.com/libtiff/libtiff/blob/master/LICENSE.md) (BSD-like)                   |\n| libvips       | LGPLv3                                                                                                    |\n| libwebp       | New BSD License                                                                                           |\n| libxml2       | MIT Licence                                                                                               |\n| mozjpeg       | [zlib License, IJG License, BSD-3-Clause](https://github.com/mozilla/mozjpeg/blob/master/LICENSE.md)      |\n| pango         | LGPLv3                                                                                                    |\n| pixman        | MIT Licence                                                                                               |\n| proxy-libintl | LGPLv3                                                                                                    |\n| zlib-ng       | [zlib Licence](https://github.com/zlib-ng/zlib-ng/blob/develop/LICENSE.md)                                |\n\nUse of libraries under the terms of the LGPLv3 is via the\n\"any later version\" clause of the LGPLv2 or LGPLv2.1.\n\nPlease report any errors or omissions via\nhttps://github.com/lovell/sharp-libvips/issues/new\n",
        "plugins/auto-review/mcp/node_modules/@modelcontextprotocol/sdk/README.md": "# MCP TypeScript SDK ![NPM Version](https://img.shields.io/npm/v/%40modelcontextprotocol%2Fsdk) ![MIT licensed](https://img.shields.io/npm/l/%40modelcontextprotocol%2Fsdk)\n\n<details>\n<summary>Table of Contents</summary>\n\n- [Overview](#overview)\n- [Installation](#installation)\n- [Quick Start](#quick-start)\n- [Core Concepts](#core-concepts)\n    - [Server](#server)\n    - [Tools](#tools)\n    - [Resources](#resources)\n    - [Prompts](#prompts)\n    - [Completions](#completions)\n    - [Display Names and Metadata](#display-names-and-metadata)\n    - [Sampling](#sampling)\n- [Running Your Server](#running-your-server)\n    - [Streamable HTTP](#streamable-http)\n    - [stdio](#stdio)\n    - [Testing and Debugging](#testing-and-debugging)\n- [Examples](#examples)\n    - [Echo Server](#echo-server)\n    - [SQLite Explorer](#sqlite-explorer)\n- [Advanced Usage](#advanced-usage)\n    - [Dynamic Servers](#dynamic-servers)\n    - [Improving Network Efficiency with Notification Debouncing](#improving-network-efficiency-with-notification-debouncing)\n    - [Low-Level Server](#low-level-server)\n    - [Eliciting User Input](#eliciting-user-input)\n    - [Writing MCP Clients](#writing-mcp-clients)\n    - [Proxy Authorization Requests Upstream](#proxy-authorization-requests-upstream)\n    - [Backwards Compatibility](#backwards-compatibility)\n- [Documentation](#documentation)\n- [Contributing](#contributing)\n- [License](#license)\n\n</details>\n\n## Overview\n\nThe Model Context Protocol allows applications to provide context for LLMs in a standardized way, separating the concerns of providing context from the actual LLM interaction. This TypeScript SDK implements\n[the full MCP specification](https://modelcontextprotocol.io/specification/latest), making it easy to:\n\n- Create MCP servers that expose resources, prompts and tools\n- Build MCP clients that can connect to any MCP server\n- Use standard transports like stdio and Streamable HTTP\n\n## Installation\n\n```bash\nnpm install @modelcontextprotocol/sdk\n```\n\n## Quick Start\n\nLet's create a simple MCP server that exposes a calculator tool and some data. Save the following as `server.ts`:\n\n```typescript\nimport { McpServer, ResourceTemplate } from '@modelcontextprotocol/sdk/server/mcp.js';\nimport { StreamableHTTPServerTransport } from '@modelcontextprotocol/sdk/server/streamableHttp.js';\nimport express from 'express';\nimport { z } from 'zod';\n\n// Create an MCP server\nconst server = new McpServer({\n    name: 'demo-server',\n    version: '1.0.0'\n});\n\n// Add an addition tool\nserver.registerTool(\n    'add',\n    {\n        title: 'Addition Tool',\n        description: 'Add two numbers',\n        inputSchema: { a: z.number(), b: z.number() },\n        outputSchema: { result: z.number() }\n    },\n    async ({ a, b }) => {\n        const output = { result: a + b };\n        return {\n            content: [{ type: 'text', text: JSON.stringify(output) }],\n            structuredContent: output\n        };\n    }\n);\n\n// Add a dynamic greeting resource\nserver.registerResource(\n    'greeting',\n    new ResourceTemplate('greeting://{name}', { list: undefined }),\n    {\n        title: 'Greeting Resource', // Display name for UI\n        description: 'Dynamic greeting generator'\n    },\n    async (uri, { name }) => ({\n        contents: [\n            {\n                uri: uri.href,\n                text: `Hello, ${name}!`\n            }\n        ]\n    })\n);\n\n// Set up Express and HTTP transport\nconst app = express();\napp.use(express.json());\n\napp.post('/mcp', async (req, res) => {\n    // Create a new transport for each request to prevent request ID collisions\n    const transport = new StreamableHTTPServerTransport({\n        sessionIdGenerator: undefined,\n        enableJsonResponse: true\n    });\n\n    res.on('close', () => {\n        transport.close();\n    });\n\n    await server.connect(transport);\n    await transport.handleRequest(req, res, req.body);\n});\n\nconst port = parseInt(process.env.PORT || '3000');\napp.listen(port, () => {\n    console.log(`Demo MCP Server running on http://localhost:${port}/mcp`);\n}).on('error', error => {\n    console.error('Server error:', error);\n    process.exit(1);\n});\n```\n\nInstall the deps with `npm install @modelcontextprotocol/sdk express zod@3`, and run with `npx -y tsx server.ts`.\n\nYou can connect to it using any MCP client that supports streamable http, such as:\n\n- [MCP Inspector](https://modelcontextprotocol.io/docs/tools/inspector): `npx @modelcontextprotocol/inspector` and connect to the streamable HTTP URL `http://localhost:3000/mcp`\n- [Claude Code](https://docs.claude.com/en/docs/claude-code/mcp): `claude mcp add --transport http my-server http://localhost:3000/mcp`\n- [VS Code](https://code.visualstudio.com/docs/copilot/customization/mcp-servers): `code --add-mcp \"{\\\"name\\\":\\\"my-server\\\",\\\"type\\\":\\\"http\\\",\\\"url\\\":\\\"http://localhost:3000/mcp\\\"}\"`\n- [Cursor](https://cursor.com/docs/context/mcp): Click [this deeplink](cursor://anysphere.cursor-deeplink/mcp/install?name=my-server&config=eyJ1cmwiOiJodHRwOi8vbG9jYWxob3N0OjMwMDAvbWNwIn0%3D)\n\nThen try asking your agent to add two numbers using its new tool!\n\n## Core Concepts\n\n### Server\n\nThe McpServer is your core interface to the MCP protocol. It handles connection management, protocol compliance, and message routing:\n\n```typescript\nconst server = new McpServer({\n    name: 'my-app',\n    version: '1.0.0'\n});\n```\n\n### Tools\n\n[Tools](https://modelcontextprotocol.io/specification/latest/server/tools) let LLMs take actions through your server. Tools can perform computation, fetch data and have side effects. Tools should be designed to be model-controlled - i.e. AI models will decide which tools to call,\nand the arguments.\n\n```typescript\n// Simple tool with parameters\nserver.registerTool(\n    'calculate-bmi',\n    {\n        title: 'BMI Calculator',\n        description: 'Calculate Body Mass Index',\n        inputSchema: {\n            weightKg: z.number(),\n            heightM: z.number()\n        },\n        outputSchema: { bmi: z.number() }\n    },\n    async ({ weightKg, heightM }) => {\n        const output = { bmi: weightKg / (heightM * heightM) };\n        return {\n            content: [\n                {\n                    type: 'text',\n                    text: JSON.stringify(output)\n                }\n            ],\n            structuredContent: output\n        };\n    }\n);\n\n// Async tool with external API call\nserver.registerTool(\n    'fetch-weather',\n    {\n        title: 'Weather Fetcher',\n        description: 'Get weather data for a city',\n        inputSchema: { city: z.string() },\n        outputSchema: { temperature: z.number(), conditions: z.string() }\n    },\n    async ({ city }) => {\n        const response = await fetch(`https://api.weather.com/${city}`);\n        const data = await response.json();\n        const output = { temperature: data.temp, conditions: data.conditions };\n        return {\n            content: [{ type: 'text', text: JSON.stringify(output) }],\n            structuredContent: output\n        };\n    }\n);\n\n// Tool that returns ResourceLinks\nserver.registerTool(\n    'list-files',\n    {\n        title: 'List Files',\n        description: 'List project files',\n        inputSchema: { pattern: z.string() },\n        outputSchema: {\n            count: z.number(),\n            files: z.array(z.object({ name: z.string(), uri: z.string() }))\n        }\n    },\n    async ({ pattern }) => {\n        const output = {\n            count: 2,\n            files: [\n                { name: 'README.md', uri: 'file:///project/README.md' },\n                { name: 'index.ts', uri: 'file:///project/src/index.ts' }\n            ]\n        };\n        return {\n            content: [\n                { type: 'text', text: JSON.stringify(output) },\n                // ResourceLinks let tools return references without file content\n                {\n                    type: 'resource_link',\n                    uri: 'file:///project/README.md',\n                    name: 'README.md',\n                    mimeType: 'text/markdown',\n                    description: 'A README file'\n                },\n                {\n                    type: 'resource_link',\n                    uri: 'file:///project/src/index.ts',\n                    name: 'index.ts',\n                    mimeType: 'text/typescript',\n                    description: 'An index file'\n                }\n            ],\n            structuredContent: output\n        };\n    }\n);\n```\n\n#### ResourceLinks\n\nTools can return `ResourceLink` objects to reference resources without embedding their full content. This can be helpful for performance when dealing with large files or many resources - clients can then selectively read only the resources they need using the provided URIs.\n\n### Resources\n\n[Resources](https://modelcontextprotocol.io/specification/latest/server/resources) can also expose data to LLMs, but unlike tools shouldn't perform significant computation or have side effects.\n\nResources are designed to be used in an application-driven way, meaning MCP client applications can decide how to expose them. For example, a client could expose a resource picker to the human, or could expose them to the model directly.\n\n```typescript\n// Static resource\nserver.registerResource(\n    'config',\n    'config://app',\n    {\n        title: 'Application Config',\n        description: 'Application configuration data',\n        mimeType: 'text/plain'\n    },\n    async uri => ({\n        contents: [\n            {\n                uri: uri.href,\n                text: 'App configuration here'\n            }\n        ]\n    })\n);\n\n// Dynamic resource with parameters\nserver.registerResource(\n    'user-profile',\n    new ResourceTemplate('users://{userId}/profile', { list: undefined }),\n    {\n        title: 'User Profile',\n        description: 'User profile information'\n    },\n    async (uri, { userId }) => ({\n        contents: [\n            {\n                uri: uri.href,\n                text: `Profile data for user ${userId}`\n            }\n        ]\n    })\n);\n\n// Resource with context-aware completion\nserver.registerResource(\n    'repository',\n    new ResourceTemplate('github://repos/{owner}/{repo}', {\n        list: undefined,\n        complete: {\n            // Provide intelligent completions based on previously resolved parameters\n            repo: (value, context) => {\n                if (context?.arguments?.['owner'] === 'org1') {\n                    return ['project1', 'project2', 'project3'].filter(r => r.startsWith(value));\n                }\n                return ['default-repo'].filter(r => r.startsWith(value));\n            }\n        }\n    }),\n    {\n        title: 'GitHub Repository',\n        description: 'Repository information'\n    },\n    async (uri, { owner, repo }) => ({\n        contents: [\n            {\n                uri: uri.href,\n                text: `Repository: ${owner}/${repo}`\n            }\n        ]\n    })\n);\n```\n\n### Prompts\n\n[Prompts](https://modelcontextprotocol.io/specification/latest/server/prompts) are reusable templates that help humans prompt models to interact with your server. They're designed to be user-driven, and might appear as slash commands in a chat interface.\n\n```typescript\nimport { completable } from '@modelcontextprotocol/sdk/server/completable.js';\n\nserver.registerPrompt(\n    'review-code',\n    {\n        title: 'Code Review',\n        description: 'Review code for best practices and potential issues',\n        argsSchema: { code: z.string() }\n    },\n    ({ code }) => ({\n        messages: [\n            {\n                role: 'user',\n                content: {\n                    type: 'text',\n                    text: `Please review this code:\\n\\n${code}`\n                }\n            }\n        ]\n    })\n);\n\n// Prompt with context-aware completion\nserver.registerPrompt(\n    'team-greeting',\n    {\n        title: 'Team Greeting',\n        description: 'Generate a greeting for team members',\n        argsSchema: {\n            department: completable(z.string(), value => {\n                // Department suggestions\n                return ['engineering', 'sales', 'marketing', 'support'].filter(d => d.startsWith(value));\n            }),\n            name: completable(z.string(), (value, context) => {\n                // Name suggestions based on selected department\n                const department = context?.arguments?.['department'];\n                if (department === 'engineering') {\n                    return ['Alice', 'Bob', 'Charlie'].filter(n => n.startsWith(value));\n                } else if (department === 'sales') {\n                    return ['David', 'Eve', 'Frank'].filter(n => n.startsWith(value));\n                } else if (department === 'marketing') {\n                    return ['Grace', 'Henry', 'Iris'].filter(n => n.startsWith(value));\n                }\n                return ['Guest'].filter(n => n.startsWith(value));\n            })\n        }\n    },\n    ({ department, name }) => ({\n        messages: [\n            {\n                role: 'assistant',\n                content: {\n                    type: 'text',\n                    text: `Hello ${name}, welcome to the ${department} team!`\n                }\n            }\n        ]\n    })\n);\n```\n\n### Completions\n\nMCP supports argument completions to help users fill in prompt arguments and resource template parameters. See the examples above for [resource completions](#resources) and [prompt completions](#prompts).\n\n#### Client Usage\n\n```typescript\n// Request completions for any argument\nconst result = await client.complete({\n    ref: {\n        type: 'ref/prompt', // or \"ref/resource\"\n        name: 'example' // or uri: \"template://...\"\n    },\n    argument: {\n        name: 'argumentName',\n        value: 'partial' // What the user has typed so far\n    },\n    context: {\n        // Optional: Include previously resolved arguments\n        arguments: {\n            previousArg: 'value'\n        }\n    }\n});\n```\n\n### Display Names and Metadata\n\nAll resources, tools, and prompts support an optional `title` field for better UI presentation. The `title` is used as a display name (e.g. 'Create a new issue'), while `name` remains the unique identifier (e.g. `create_issue`).\n\n**Note:** The `register*` methods (`registerTool`, `registerPrompt`, `registerResource`) are the recommended approach for new code. The older methods (`tool`, `prompt`, `resource`) remain available for backwards compatibility.\n\n#### Title Precedence for Tools\n\nFor tools specifically, there are two ways to specify a title:\n\n- `title` field in the tool configuration\n- `annotations.title` field (when using the older `tool()` method with annotations)\n\nThe precedence order is: `title` → `annotations.title` → `name`\n\n```typescript\n// Using registerTool (recommended)\nserver.registerTool(\n    'my_tool',\n    {\n        title: 'My Tool', // This title takes precedence\n        annotations: {\n            title: 'Annotation Title' // This is ignored if title is set\n        }\n    },\n    handler\n);\n\n// Using tool with annotations (older API)\nserver.tool(\n    'my_tool',\n    'description',\n    {\n        title: 'Annotation Title' // This is used as title\n    },\n    handler\n);\n```\n\nWhen building clients, use the provided utility to get the appropriate display name:\n\n```typescript\nimport { getDisplayName } from '@modelcontextprotocol/sdk/shared/metadataUtils.js';\n\n// Automatically handles the precedence: title → annotations.title → name\nconst displayName = getDisplayName(tool);\n```\n\n### Sampling\n\nMCP servers can request LLM completions from connected clients that support sampling.\n\n```typescript\nimport { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';\nimport { StreamableHTTPServerTransport } from '@modelcontextprotocol/sdk/server/streamableHttp.js';\nimport express from 'express';\nimport { z } from 'zod';\n\nconst mcpServer = new McpServer({\n    name: 'tools-with-sample-server',\n    version: '1.0.0'\n});\n\n// Tool that uses LLM sampling to summarize any text\nmcpServer.registerTool(\n    'summarize',\n    {\n        title: 'Text Summarizer',\n        description: 'Summarize any text using an LLM',\n        inputSchema: {\n            text: z.string().describe('Text to summarize')\n        },\n        outputSchema: { summary: z.string() }\n    },\n    async ({ text }) => {\n        // Call the LLM through MCP sampling\n        const response = await mcpServer.server.createMessage({\n            messages: [\n                {\n                    role: 'user',\n                    content: {\n                        type: 'text',\n                        text: `Please summarize the following text concisely:\\n\\n${text}`\n                    }\n                }\n            ],\n            maxTokens: 500\n        });\n\n        const summary = response.content.type === 'text' ? response.content.text : 'Unable to generate summary';\n        const output = { summary };\n        return {\n            content: [{ type: 'text', text: JSON.stringify(output) }],\n            structuredContent: output\n        };\n    }\n);\n\nconst app = express();\napp.use(express.json());\n\napp.post('/mcp', async (req, res) => {\n    const transport = new StreamableHTTPServerTransport({\n        sessionIdGenerator: undefined,\n        enableJsonResponse: true\n    });\n\n    res.on('close', () => {\n        transport.close();\n    });\n\n    await mcpServer.connect(transport);\n    await transport.handleRequest(req, res, req.body);\n});\n\nconst port = parseInt(process.env.PORT || '3000');\napp.listen(port, () => {\n    console.log(`MCP Server running on http://localhost:${port}/mcp`);\n}).on('error', error => {\n    console.error('Server error:', error);\n    process.exit(1);\n});\n```\n\n## Running Your Server\n\nMCP servers in TypeScript need to be connected to a transport to communicate with clients. How you start the server depends on the choice of transport:\n\n### Streamable HTTP\n\nFor remote servers, use the Streamable HTTP transport.\n\n#### Without Session Management (Recommended)\n\nFor most use cases where session management isn't needed:\n\n```typescript\nimport { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';\nimport { StreamableHTTPServerTransport } from '@modelcontextprotocol/sdk/server/streamableHttp.js';\nimport express from 'express';\nimport { z } from 'zod';\n\nconst app = express();\napp.use(express.json());\n\n// Create the MCP server once (can be reused across requests)\nconst server = new McpServer({\n    name: 'example-server',\n    version: '1.0.0'\n});\n\n// Set up your tools, resources, and prompts\nserver.registerTool(\n    'echo',\n    {\n        title: 'Echo Tool',\n        description: 'Echoes back the provided message',\n        inputSchema: { message: z.string() },\n        outputSchema: { echo: z.string() }\n    },\n    async ({ message }) => {\n        const output = { echo: `Tool echo: ${message}` };\n        return {\n            content: [{ type: 'text', text: JSON.stringify(output) }],\n            structuredContent: output\n        };\n    }\n);\n\napp.post('/mcp', async (req, res) => {\n    // In stateless mode, create a new transport for each request to prevent\n    // request ID collisions. Different clients may use the same JSON-RPC request IDs,\n    // which would cause responses to be routed to the wrong HTTP connections if\n    // the transport state is shared.\n\n    try {\n        const transport = new StreamableHTTPServerTransport({\n            sessionIdGenerator: undefined,\n            enableJsonResponse: true\n        });\n\n        res.on('close', () => {\n            transport.close();\n        });\n\n        await server.connect(transport);\n        await transport.handleRequest(req, res, req.body);\n    } catch (error) {\n        console.error('Error handling MCP request:', error);\n        if (!res.headersSent) {\n            res.status(500).json({\n                jsonrpc: '2.0',\n                error: {\n                    code: -32603,\n                    message: 'Internal server error'\n                },\n                id: null\n            });\n        }\n    }\n});\n\nconst port = parseInt(process.env.PORT || '3000');\napp.listen(port, () => {\n    console.log(`MCP Server running on http://localhost:${port}/mcp`);\n}).on('error', error => {\n    console.error('Server error:', error);\n    process.exit(1);\n});\n```\n\n#### With Session Management\n\nIn some cases, servers need stateful sessions. This can be achieved by [session management](https://modelcontextprotocol.io/specification/2025-03-26/basic/transports#session-management) in the MCP protocol.\n\n```typescript\nimport express from 'express';\nimport { randomUUID } from 'node:crypto';\nimport { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';\nimport { StreamableHTTPServerTransport } from '@modelcontextprotocol/sdk/server/streamableHttp.js';\nimport { isInitializeRequest } from '@modelcontextprotocol/sdk/types.js';\n\nconst app = express();\napp.use(express.json());\n\n// Map to store transports by session ID\nconst transports: { [sessionId: string]: StreamableHTTPServerTransport } = {};\n\n// Handle POST requests for client-to-server communication\napp.post('/mcp', async (req, res) => {\n    // Check for existing session ID\n    const sessionId = req.headers['mcp-session-id'] as string | undefined;\n    let transport: StreamableHTTPServerTransport;\n\n    if (sessionId && transports[sessionId]) {\n        // Reuse existing transport\n        transport = transports[sessionId];\n    } else if (!sessionId && isInitializeRequest(req.body)) {\n        // New initialization request\n        transport = new StreamableHTTPServerTransport({\n            sessionIdGenerator: () => randomUUID(),\n            onsessioninitialized: sessionId => {\n                // Store the transport by session ID\n                transports[sessionId] = transport;\n            }\n            // DNS rebinding protection is disabled by default for backwards compatibility. If you are running this server\n            // locally, make sure to set:\n            // enableDnsRebindingProtection: true,\n            // allowedHosts: ['127.0.0.1'],\n        });\n\n        // Clean up transport when closed\n        transport.onclose = () => {\n            if (transport.sessionId) {\n                delete transports[transport.sessionId];\n            }\n        };\n        const server = new McpServer({\n            name: 'example-server',\n            version: '1.0.0'\n        });\n\n        // ... set up server resources, tools, and prompts ...\n\n        // Connect to the MCP server\n        await server.connect(transport);\n    } else {\n        // Invalid request\n        res.status(400).json({\n            jsonrpc: '2.0',\n            error: {\n                code: -32000,\n                message: 'Bad Request: No valid session ID provided'\n            },\n            id: null\n        });\n        return;\n    }\n\n    // Handle the request\n    await transport.handleRequest(req, res, req.body);\n});\n\n// Reusable handler for GET and DELETE requests\nconst handleSessionRequest = async (req: express.Request, res: express.Response) => {\n    const sessionId = req.headers['mcp-session-id'] as string | undefined;\n    if (!sessionId || !transports[sessionId]) {\n        res.status(400).send('Invalid or missing session ID');\n        return;\n    }\n\n    const transport = transports[sessionId];\n    await transport.handleRequest(req, res);\n};\n\n// Handle GET requests for server-to-client notifications via SSE\napp.get('/mcp', handleSessionRequest);\n\n// Handle DELETE requests for session termination\napp.delete('/mcp', handleSessionRequest);\n\napp.listen(3000);\n```\n\n#### CORS Configuration for Browser-Based Clients\n\nIf you'd like your server to be accessible by browser-based MCP clients, you'll need to configure CORS headers. The `Mcp-Session-Id` header must be exposed for browser clients to access it:\n\n```typescript\nimport cors from 'cors';\n\n// Add CORS middleware before your MCP routes\napp.use(\n    cors({\n        origin: '*', // Configure appropriately for production, for example:\n        // origin: ['https://your-remote-domain.com', 'https://your-other-remote-domain.com'],\n        exposedHeaders: ['Mcp-Session-Id'],\n        allowedHeaders: ['Content-Type', 'mcp-session-id']\n    })\n);\n```\n\nThis configuration is necessary because:\n\n- The MCP streamable HTTP transport uses the `Mcp-Session-Id` header for session management\n- Browsers restrict access to response headers unless explicitly exposed via CORS\n- Without this configuration, browser-based clients won't be able to read the session ID from initialization responses\n\n#### DNS Rebinding Protection\n\nThe Streamable HTTP transport includes DNS rebinding protection to prevent security vulnerabilities. By default, this protection is **disabled** for backwards compatibility.\n\n**Important**: If you are running this server locally, enable DNS rebinding protection:\n\n```typescript\nconst transport = new StreamableHTTPServerTransport({\n  sessionIdGenerator: () => randomUUID(),\n  enableDnsRebindingProtection: true,\n\n  allowedHosts: ['127.0.0.1', ...],\n  allowedOrigins: ['https://yourdomain.com', 'https://www.yourdomain.com']\n});\n```\n\n### stdio\n\nFor local integrations spawned by another process, you can use the stdio transport:\n\n```typescript\nimport { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';\nimport { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';\n\nconst server = new McpServer({\n    name: 'example-server',\n    version: '1.0.0'\n});\n\n// ... set up server resources, tools, and prompts ...\n\nconst transport = new StdioServerTransport();\nawait server.connect(transport);\n```\n\n### Testing and Debugging\n\nTo test your server, you can use the [MCP Inspector](https://github.com/modelcontextprotocol/inspector). See its README for more information.\n\n## Examples\n\n### Echo Server\n\nA simple server demonstrating resources, tools, and prompts:\n\n```typescript\nimport { McpServer, ResourceTemplate } from '@modelcontextprotocol/sdk/server/mcp.js';\nimport { z } from 'zod';\n\nconst server = new McpServer({\n    name: 'echo-server',\n    version: '1.0.0'\n});\n\nserver.registerTool(\n    'echo',\n    {\n        title: 'Echo Tool',\n        description: 'Echoes back the provided message',\n        inputSchema: { message: z.string() },\n        outputSchema: { echo: z.string() }\n    },\n    async ({ message }) => {\n        const output = { echo: `Tool echo: ${message}` };\n        return {\n            content: [{ type: 'text', text: JSON.stringify(output) }],\n            structuredContent: output\n        };\n    }\n);\n\nserver.registerResource(\n    'echo',\n    new ResourceTemplate('echo://{message}', { list: undefined }),\n    {\n        title: 'Echo Resource',\n        description: 'Echoes back messages as resources'\n    },\n    async (uri, { message }) => ({\n        contents: [\n            {\n                uri: uri.href,\n                text: `Resource echo: ${message}`\n            }\n        ]\n    })\n);\n\nserver.registerPrompt(\n    'echo',\n    {\n        title: 'Echo Prompt',\n        description: 'Creates a prompt to process a message',\n        argsSchema: { message: z.string() }\n    },\n    ({ message }) => ({\n        messages: [\n            {\n                role: 'user',\n                content: {\n                    type: 'text',\n                    text: `Please process this message: ${message}`\n                }\n            }\n        ]\n    })\n);\n```\n\n### SQLite Explorer\n\nA more complex example showing database integration:\n\n```typescript\nimport { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';\nimport sqlite3 from 'sqlite3';\nimport { promisify } from 'util';\nimport { z } from 'zod';\n\nconst server = new McpServer({\n    name: 'sqlite-explorer',\n    version: '1.0.0'\n});\n\n// Helper to create DB connection\nconst getDb = () => {\n    const db = new sqlite3.Database('database.db');\n    return {\n        all: promisify<string, any[]>(db.all.bind(db)),\n        close: promisify(db.close.bind(db))\n    };\n};\n\nserver.registerResource(\n    'schema',\n    'schema://main',\n    {\n        title: 'Database Schema',\n        description: 'SQLite database schema',\n        mimeType: 'text/plain'\n    },\n    async uri => {\n        const db = getDb();\n        try {\n            const tables = await db.all(\"SELECT sql FROM sqlite_master WHERE type='table'\");\n            return {\n                contents: [\n                    {\n                        uri: uri.href,\n                        text: tables.map((t: { sql: string }) => t.sql).join('\\n')\n                    }\n                ]\n            };\n        } finally {\n            await db.close();\n        }\n    }\n);\n\nserver.registerTool(\n    'query',\n    {\n        title: 'SQL Query',\n        description: 'Execute SQL queries on the database',\n        inputSchema: { sql: z.string() },\n        outputSchema: {\n            rows: z.array(z.record(z.any())),\n            rowCount: z.number()\n        }\n    },\n    async ({ sql }) => {\n        const db = getDb();\n        try {\n            const results = await db.all(sql);\n            const output = { rows: results, rowCount: results.length };\n            return {\n                content: [\n                    {\n                        type: 'text',\n                        text: JSON.stringify(output, null, 2)\n                    }\n                ],\n                structuredContent: output\n            };\n        } catch (err: unknown) {\n            const error = err as Error;\n            return {\n                content: [\n                    {\n                        type: 'text',\n                        text: `Error: ${error.message}`\n                    }\n                ],\n                isError: true\n            };\n        } finally {\n            await db.close();\n        }\n    }\n);\n```\n\n## Advanced Usage\n\n### Dynamic Servers\n\nIf you want to offer an initial set of tools/prompts/resources, but later add additional ones based on user action or external state change, you can add/update/remove them _after_ the Server is connected. This will automatically emit the corresponding `listChanged` notifications:\n\n```typescript\nimport { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';\nimport { StreamableHTTPServerTransport } from '@modelcontextprotocol/sdk/server/streamableHttp.js';\nimport express from 'express';\nimport { z } from 'zod';\n\nconst server = new McpServer({\n    name: 'Dynamic Example',\n    version: '1.0.0'\n});\n\nconst listMessageTool = server.registerTool(\n    'listMessages',\n    {\n        title: 'List Messages',\n        description: 'List messages in a channel',\n        inputSchema: { channel: z.string() },\n        outputSchema: { messages: z.array(z.string()) }\n    },\n    async ({ channel }) => {\n        const messages = await listMessages(channel);\n        const output = { messages };\n        return {\n            content: [{ type: 'text', text: JSON.stringify(output) }],\n            structuredContent: output\n        };\n    }\n);\n\nconst putMessageTool = server.registerTool(\n    'putMessage',\n    {\n        title: 'Put Message',\n        description: 'Send a message to a channel',\n        inputSchema: { channel: z.string(), message: z.string() },\n        outputSchema: { success: z.boolean() }\n    },\n    async ({ channel, message }) => {\n        await putMessage(channel, message);\n        const output = { success: true };\n        return {\n            content: [{ type: 'text', text: JSON.stringify(output) }],\n            structuredContent: output\n        };\n    }\n);\n// Until we upgrade auth, `putMessage` is disabled (won't show up in listTools)\nputMessageTool.disable();\n\nconst upgradeAuthTool = server.registerTool(\n    'upgradeAuth',\n    {\n        title: 'Upgrade Authorization',\n        description: 'Upgrade user authorization level',\n        inputSchema: { permission: z.enum(['write', 'admin']) },\n        outputSchema: {\n            success: z.boolean(),\n            newPermission: z.string()\n        }\n    },\n    // Any mutations here will automatically emit `listChanged` notifications\n    async ({ permission }) => {\n        const { ok, err, previous } = await upgradeAuthAndStoreToken(permission);\n        if (!ok) {\n            return {\n                content: [{ type: 'text', text: `Error: ${err}` }],\n                isError: true\n            };\n        }\n\n        // If we previously had read-only access, 'putMessage' is now available\n        if (previous === 'read') {\n            putMessageTool.enable();\n        }\n\n        if (permission === 'write') {\n            // If we've just upgraded to 'write' permissions, we can still call 'upgradeAuth'\n            // but can only upgrade to 'admin'.\n            upgradeAuthTool.update({\n                paramsSchema: { permission: z.enum(['admin']) } // change validation rules\n            });\n        } else {\n            // If we're now an admin, we no longer have anywhere to upgrade to, so fully remove that tool\n            upgradeAuthTool.remove();\n        }\n\n        const output = { success: true, newPermission: permission };\n        return {\n            content: [{ type: 'text', text: JSON.stringify(output) }],\n            structuredContent: output\n        };\n    }\n);\n\n// Connect with HTTP transport\nconst app = express();\napp.use(express.json());\n\napp.post('/mcp', async (req, res) => {\n    const transport = new StreamableHTTPServerTransport({\n        sessionIdGenerator: undefined,\n        enableJsonResponse: true\n    });\n\n    res.on('close', () => {\n        transport.close();\n    });\n\n    await server.connect(transport);\n    await transport.handleRequest(req, res, req.body);\n});\n\nconst port = parseInt(process.env.PORT || '3000');\napp.listen(port, () => {\n    console.log(`MCP Server running on http://localhost:${port}/mcp`);\n});\n```\n\n### Improving Network Efficiency with Notification Debouncing\n\nWhen performing bulk updates that trigger notifications (e.g., enabling or disabling multiple tools in a loop), the SDK can send a large number of messages in a short period. To improve performance and reduce network traffic, you can enable notification debouncing.\n\nThis feature coalesces multiple, rapid calls for the same notification type into a single message. For example, if you disable five tools in a row, only one `notifications/tools/list_changed` message will be sent instead of five.\n\n> [!IMPORTANT] This feature is designed for \"simple\" notifications that do not carry unique data in their parameters. To prevent silent data loss, debouncing is **automatically bypassed** for any notification that contains a `params` object or a `relatedRequestId`. Such\n> notifications will always be sent immediately.\n\nThis is an opt-in feature configured during server initialization.\n\n```typescript\nimport { McpServer } from \"@modelcontextprotocol/sdk/server/mcp.js\";\n\nconst server = new McpServer(\n  {\n    name: \"efficient-server\",\n    version: \"1.0.0\"\n  },\n  {\n    // Enable notification debouncing for specific methods\n    debouncedNotificationMethods: [\n      'notifications/tools/list_changed',\n      'notifications/resources/list_changed',\n      'notifications/prompts/list_changed'\n    ]\n  }\n);\n\n// Now, any rapid changes to tools, resources, or prompts will result\n// in a single, consolidated notification for each type.\nserver.registerTool(\"tool1\", ...).disable();\nserver.registerTool(\"tool2\", ...).disable();\nserver.registerTool(\"tool3\", ...).disable();\n// Only one 'notifications/tools/list_changed' is sent.\n```\n\n### Low-Level Server\n\nFor more control, you can use the low-level Server class directly:\n\n```typescript\nimport { Server } from '@modelcontextprotocol/sdk/server/index.js';\nimport { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';\nimport { ListPromptsRequestSchema, GetPromptRequestSchema } from '@modelcontextprotocol/sdk/types.js';\n\nconst server = new Server(\n    {\n        name: 'example-server',\n        version: '1.0.0'\n    },\n    {\n        capabilities: {\n            prompts: {}\n        }\n    }\n);\n\nserver.setRequestHandler(ListPromptsRequestSchema, async () => {\n    return {\n        prompts: [\n            {\n                name: 'example-prompt',\n                description: 'An example prompt template',\n                arguments: [\n                    {\n                        name: 'arg1',\n                        description: 'Example argument',\n                        required: true\n                    }\n                ]\n            }\n        ]\n    };\n});\n\nserver.setRequestHandler(GetPromptRequestSchema, async request => {\n    if (request.params.name !== 'example-prompt') {\n        throw new Error('Unknown prompt');\n    }\n    return {\n        description: 'Example prompt',\n        messages: [\n            {\n                role: 'user',\n                content: {\n                    type: 'text',\n                    text: 'Example prompt text'\n                }\n            }\n        ]\n    };\n});\n\nconst transport = new StdioServerTransport();\nawait server.connect(transport);\n```\n\n### Eliciting User Input\n\nMCP servers can request additional information from users through the elicitation feature. This is useful for interactive workflows where the server needs user input or confirmation:\n\n```typescript\n// Server-side: Restaurant booking tool that asks for alternatives\nserver.registerTool(\n    'book-restaurant',\n    {\n        title: 'Book Restaurant',\n        description: 'Book a table at a restaurant',\n        inputSchema: {\n            restaurant: z.string(),\n            date: z.string(),\n            partySize: z.number()\n        },\n        outputSchema: {\n            success: z.boolean(),\n            booking: z\n                .object({\n                    restaurant: z.string(),\n                    date: z.string(),\n                    partySize: z.number()\n                })\n                .optional(),\n            alternatives: z.array(z.string()).optional()\n        }\n    },\n    async ({ restaurant, date, partySize }) => {\n        // Check availability\n        const available = await checkAvailability(restaurant, date, partySize);\n\n        if (!available) {\n            // Ask user if they want to try alternative dates\n            const result = await server.server.elicitInput({\n                message: `No tables available at ${restaurant} on ${date}. Would you like to check alternative dates?`,\n                requestedSchema: {\n                    type: 'object',\n                    properties: {\n                        checkAlternatives: {\n                            type: 'boolean',\n                            title: 'Check alternative dates',\n                            description: 'Would you like me to check other dates?'\n                        },\n                        flexibleDates: {\n                            type: 'string',\n                            title: 'Date flexibility',\n                            description: 'How flexible are your dates?',\n                            enum: ['next_day', 'same_week', 'next_week'],\n                            enumNames: ['Next day', 'Same week', 'Next week']\n                        }\n                    },\n                    required: ['checkAlternatives']\n                }\n            });\n\n            if (result.action === 'accept' && result.content?.checkAlternatives) {\n                const alternatives = await findAlternatives(restaurant, date, partySize, result.content.flexibleDates as string);\n                const output = { success: false, alternatives };\n                return {\n                    content: [\n                        {\n                            type: 'text',\n                            text: JSON.stringify(output)\n                        }\n                    ],\n                    structuredContent: output\n                };\n            }\n\n            const output = { success: false };\n            return {\n                content: [\n                    {\n                        type: 'text',\n                        text: JSON.stringify(output)\n                    }\n                ],\n                structuredContent: output\n            };\n        }\n\n        // Book the table\n        await makeBooking(restaurant, date, partySize);\n        const output = {\n            success: true,\n            booking: { restaurant, date, partySize }\n        };\n        return {\n            content: [\n                {\n                    type: 'text',\n                    text: JSON.stringify(output)\n                }\n            ],\n            structuredContent: output\n        };\n    }\n);\n```\n\nClient-side: Handle elicitation requests\n\n```typescript\n// This is a placeholder - implement based on your UI framework\nasync function getInputFromUser(\n    message: string,\n    schema: any\n): Promise<{\n    action: 'accept' | 'decline' | 'cancel';\n    data?: Record<string, any>;\n}> {\n    // This should be implemented depending on the app\n    throw new Error('getInputFromUser must be implemented for your platform');\n}\n\nclient.setRequestHandler(ElicitRequestSchema, async request => {\n    const userResponse = await getInputFromUser(request.params.message, request.params.requestedSchema);\n\n    return {\n        action: userResponse.action,\n        content: userResponse.action === 'accept' ? userResponse.data : undefined\n    };\n});\n```\n\n**Note**: Elicitation requires client support. Clients must declare the `elicitation` capability during initialization.\n\n### Writing MCP Clients\n\nThe SDK provides a high-level client interface:\n\n```typescript\nimport { Client } from '@modelcontextprotocol/sdk/client/index.js';\nimport { StdioClientTransport } from '@modelcontextprotocol/sdk/client/stdio.js';\n\nconst transport = new StdioClientTransport({\n    command: 'node',\n    args: ['server.js']\n});\n\nconst client = new Client({\n    name: 'example-client',\n    version: '1.0.0'\n});\n\nawait client.connect(transport);\n\n// List prompts\nconst prompts = await client.listPrompts();\n\n// Get a prompt\nconst prompt = await client.getPrompt({\n    name: 'example-prompt',\n    arguments: {\n        arg1: 'value'\n    }\n});\n\n// List resources\nconst resources = await client.listResources();\n\n// Read a resource\nconst resource = await client.readResource({\n    uri: 'file:///example.txt'\n});\n\n// Call a tool\nconst result = await client.callTool({\n    name: 'example-tool',\n    arguments: {\n        arg1: 'value'\n    }\n});\n```\n\n### Proxy Authorization Requests Upstream\n\nYou can proxy OAuth requests to an external authorization provider:\n\n```typescript\nimport express from 'express';\nimport { ProxyOAuthServerProvider } from '@modelcontextprotocol/sdk/server/auth/providers/proxyProvider.js';\nimport { mcpAuthRouter } from '@modelcontextprotocol/sdk/server/auth/router.js';\n\nconst app = express();\n\nconst proxyProvider = new ProxyOAuthServerProvider({\n    endpoints: {\n        authorizationUrl: 'https://auth.external.com/oauth2/v1/authorize',\n        tokenUrl: 'https://auth.external.com/oauth2/v1/token',\n        revocationUrl: 'https://auth.external.com/oauth2/v1/revoke'\n    },\n    verifyAccessToken: async token => {\n        return {\n            token,\n            clientId: '123',\n            scopes: ['openid', 'email', 'profile']\n        };\n    },\n    getClient: async client_id => {\n        return {\n            client_id,\n            redirect_uris: ['http://localhost:3000/callback']\n        };\n    }\n});\n\napp.use(\n    mcpAuthRouter({\n        provider: proxyProvider,\n        issuerUrl: new URL('http://auth.external.com'),\n        baseUrl: new URL('http://mcp.example.com'),\n        serviceDocumentationUrl: new URL('https://docs.example.com/')\n    })\n);\n```\n\nThis setup allows you to:\n\n- Forward OAuth requests to an external provider\n- Add custom token validation logic\n- Manage client registrations\n- Provide custom documentation URLs\n- Maintain control over the OAuth flow while delegating to an external provider\n\n### Backwards Compatibility\n\nClients and servers with StreamableHttp transport can maintain [backwards compatibility](https://modelcontextprotocol.io/specification/2025-03-26/basic/transports#backwards-compatibility) with the deprecated HTTP+SSE transport (from protocol version 2024-11-05) as follows\n\n#### Client-Side Compatibility\n\nFor clients that need to work with both Streamable HTTP and older SSE servers:\n\n```typescript\nimport { Client } from '@modelcontextprotocol/sdk/client/index.js';\nimport { StreamableHTTPClientTransport } from '@modelcontextprotocol/sdk/client/streamableHttp.js';\nimport { SSEClientTransport } from '@modelcontextprotocol/sdk/client/sse.js';\nlet client: Client | undefined = undefined;\nconst baseUrl = new URL(url);\ntry {\n    client = new Client({\n        name: 'streamable-http-client',\n        version: '1.0.0'\n    });\n    const transport = new StreamableHTTPClientTransport(new URL(baseUrl));\n    await client.connect(transport);\n    console.log('Connected using Streamable HTTP transport');\n} catch (error) {\n    // If that fails with a 4xx error, try the older SSE transport\n    console.log('Streamable HTTP connection failed, falling back to SSE transport');\n    client = new Client({\n        name: 'sse-client',\n        version: '1.0.0'\n    });\n    const sseTransport = new SSEClientTransport(baseUrl);\n    await client.connect(sseTransport);\n    console.log('Connected using SSE transport');\n}\n```\n\n#### Server-Side Compatibility\n\nFor servers that need to support both Streamable HTTP and older clients:\n\n```typescript\nimport express from 'express';\nimport { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';\nimport { StreamableHTTPServerTransport } from '@modelcontextprotocol/sdk/server/streamableHttp.js';\nimport { SSEServerTransport } from '@modelcontextprotocol/sdk/server/sse.js';\n\nconst server = new McpServer({\n    name: 'backwards-compatible-server',\n    version: '1.0.0'\n});\n\n// ... set up server resources, tools, and prompts ...\n\nconst app = express();\napp.use(express.json());\n\n// Store transports for each session type\nconst transports = {\n    streamable: {} as Record<string, StreamableHTTPServerTransport>,\n    sse: {} as Record<string, SSEServerTransport>\n};\n\n// Modern Streamable HTTP endpoint\napp.all('/mcp', async (req, res) => {\n    // Handle Streamable HTTP transport for modern clients\n    // Implementation as shown in the \"With Session Management\" example\n    // ...\n});\n\n// Legacy SSE endpoint for older clients\napp.get('/sse', async (req, res) => {\n    // Create SSE transport for legacy clients\n    const transport = new SSEServerTransport('/messages', res);\n    transports.sse[transport.sessionId] = transport;\n\n    res.on('close', () => {\n        delete transports.sse[transport.sessionId];\n    });\n\n    await server.connect(transport);\n});\n\n// Legacy message endpoint for older clients\napp.post('/messages', async (req, res) => {\n    const sessionId = req.query.sessionId as string;\n    const transport = transports.sse[sessionId];\n    if (transport) {\n        await transport.handlePostMessage(req, res, req.body);\n    } else {\n        res.status(400).send('No transport found for sessionId');\n    }\n});\n\napp.listen(3000);\n```\n\n**Note**: The SSE transport is now deprecated in favor of Streamable HTTP. New implementations should use Streamable HTTP, and existing SSE implementations should plan to migrate.\n\n## Documentation\n\n- [Model Context Protocol documentation](https://modelcontextprotocol.io)\n- [MCP Specification](https://spec.modelcontextprotocol.io)\n- [Example Servers](https://github.com/modelcontextprotocol/servers)\n\n## Contributing\n\nIssues and pull requests are welcome on GitHub at <https://github.com/modelcontextprotocol/typescript-sdk>.\n\n## License\n\nThis project is licensed under the MIT License—see the [LICENSE](LICENSE) file for details.\n",
        "plugins/auto-review/mcp/node_modules/@openai/codex-sdk/README.md": "# Codex SDK\n\nEmbed the Codex agent in your workflows and apps.\n\nThe TypeScript SDK wraps the bundled `codex` binary. It spawns the CLI and exchanges JSONL events over stdin/stdout.\n\n## Installation\n\n```bash\nnpm install @openai/codex-sdk\n```\n\nRequires Node.js 18+.\n\n## Quickstart\n\n```typescript\nimport { Codex } from \"@openai/codex-sdk\";\n\nconst codex = new Codex();\nconst thread = codex.startThread();\nconst turn = await thread.run(\"Diagnose the test failure and propose a fix\");\n\nconsole.log(turn.finalResponse);\nconsole.log(turn.items);\n```\n\nCall `run()` repeatedly on the same `Thread` instance to continue that conversation.\n\n```typescript\nconst nextTurn = await thread.run(\"Implement the fix\");\n```\n\n### Streaming responses\n\n`run()` buffers events until the turn finishes. To react to intermediate progress—tool calls, streaming responses, and file diffs—use `runStreamed()` instead, which returns an async generator of structured events.\n\n```typescript\nconst { events } = await thread.runStreamed(\"Diagnose the test failure and propose a fix\");\n\nfor await (const event of events) {\n  switch (event.type) {\n    case \"item.completed\":\n      console.log(\"item\", event.item);\n      break;\n    case \"turn.completed\":\n      console.log(\"usage\", event.usage);\n      break;\n  }\n}\n```\n\n### Structured output\n\nThe Codex agent can produce a JSON response that conforms to a specified schema. The schema can be provided for each turn as a plain JSON object.\n\n```typescript\nconst schema = {\n  type: \"object\",\n  properties: {\n    summary: { type: \"string\" },\n    status: { type: \"string\", enum: [\"ok\", \"action_required\"] },\n  },\n  required: [\"summary\", \"status\"],\n  additionalProperties: false,\n} as const;\n\nconst turn = await thread.run(\"Summarize repository status\", { outputSchema: schema });\nconsole.log(turn.finalResponse);\n```\n\nYou can also create a JSON schema from a [Zod schema](https://github.com/colinhacks/zod) using the [`zod-to-json-schema`](https://www.npmjs.com/package/zod-to-json-schema) package and setting the `target` to `\"openAi\"`.\n\n```typescript\nconst schema = z.object({\n  summary: z.string(),\n  status: z.enum([\"ok\", \"action_required\"]),\n});\n\nconst turn = await thread.run(\"Summarize repository status\", {\n  outputSchema: zodToJsonSchema(schema, { target: \"openAi\" }),\n});\nconsole.log(turn.finalResponse);\n```\n\n### Resuming an existing thread\n\nThreads are persisted in `~/.codex/sessions`. If you lose the in-memory `Thread` object, reconstruct it with `resumeThread()` and keep going.\n\n```typescript\nconst savedThreadId = process.env.CODEX_THREAD_ID!;\nconst thread = codex.resumeThread(savedThreadId);\nawait thread.run(\"Implement the fix\");\n```\n\n### Working directory controls\n\nCodex runs in the current working directory by default. To avoid unrecoverable errors, Codex requires the working directory to be a Git repository. You can skip the Git repository check by passing the `skipGitRepoCheck` option when creating a thread. \n\n```typescript\nconst thread = codex.startThread({\n  workingDirectory: \"/path/to/project\",\n  skipGitRepoCheck: true,\n});\n```\n",
        "plugins/auto-review/mcp/node_modules/@types/node/README.md": "# Installation\r\n> `npm install --save @types/node`\r\n\r\n# Summary\r\nThis package contains type definitions for node (https://nodejs.org/).\r\n\r\n# Details\r\nFiles were exported from https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/types/node/v22.\r\n\r\n### Additional Details\r\n * Last updated: Tue, 11 Nov 2025 23:33:13 GMT\r\n * Dependencies: [undici-types](https://npmjs.com/package/undici-types)\r\n\r\n# Credits\r\nThese definitions were written by [Microsoft TypeScript](https://github.com/Microsoft), [Alberto Schiabel](https://github.com/jkomyno), [Andrew Makarov](https://github.com/r3nya), [Benjamin Toueg](https://github.com/btoueg), [David Junger](https://github.com/touffy), [Mohsen Azimi](https://github.com/mohsen1), [Nikita Galkin](https://github.com/galkin), [Sebastian Silbermann](https://github.com/eps1lon), [Wilco Bakker](https://github.com/WilcoBakker), [Marcin Kopacz](https://github.com/chyzwar), [Trivikram Kamat](https://github.com/trivikr), [Junxiao Shi](https://github.com/yoursunny), [Ilia Baryshnikov](https://github.com/qwelias), [ExE Boss](https://github.com/ExE-Boss), [Piotr Błażejewicz](https://github.com/peterblazejewicz), [Anna Henningsen](https://github.com/addaleax), [Victor Perin](https://github.com/victorperin), [NodeJS Contributors](https://github.com/NodeJS), [Linus Unnebäck](https://github.com/LinusU), [wafuwafu13](https://github.com/wafuwafu13), [Matteo Collina](https://github.com/mcollina), [Dmitry Semigradsky](https://github.com/Semigradsky), and [René](https://github.com/Renegade334).\r\n",
        "plugins/auto-review/mcp/node_modules/accepts/README.md": "# accepts\n\n[![NPM Version][npm-version-image]][npm-url]\n[![NPM Downloads][npm-downloads-image]][npm-url]\n[![Node.js Version][node-version-image]][node-version-url]\n[![Build Status][github-actions-ci-image]][github-actions-ci-url]\n[![Test Coverage][coveralls-image]][coveralls-url]\n\nHigher level content negotiation based on [negotiator](https://www.npmjs.com/package/negotiator).\nExtracted from [koa](https://www.npmjs.com/package/koa) for general use.\n\nIn addition to negotiator, it allows:\n\n- Allows types as an array or arguments list, ie `(['text/html', 'application/json'])`\n  as well as `('text/html', 'application/json')`.\n- Allows type shorthands such as `json`.\n- Returns `false` when no types match\n- Treats non-existent headers as `*`\n\n## Installation\n\nThis is a [Node.js](https://nodejs.org/en/) module available through the\n[npm registry](https://www.npmjs.com/). Installation is done using the\n[`npm install` command](https://docs.npmjs.com/getting-started/installing-npm-packages-locally):\n\n```sh\n$ npm install accepts\n```\n\n## API\n\n```js\nvar accepts = require('accepts')\n```\n\n### accepts(req)\n\nCreate a new `Accepts` object for the given `req`.\n\n#### .charset(charsets)\n\nReturn the first accepted charset. If nothing in `charsets` is accepted,\nthen `false` is returned.\n\n#### .charsets()\n\nReturn the charsets that the request accepts, in the order of the client's\npreference (most preferred first).\n\n#### .encoding(encodings)\n\nReturn the first accepted encoding. If nothing in `encodings` is accepted,\nthen `false` is returned.\n\n#### .encodings()\n\nReturn the encodings that the request accepts, in the order of the client's\npreference (most preferred first).\n\n#### .language(languages)\n\nReturn the first accepted language. If nothing in `languages` is accepted,\nthen `false` is returned.\n\n#### .languages()\n\nReturn the languages that the request accepts, in the order of the client's\npreference (most preferred first).\n\n#### .type(types)\n\nReturn the first accepted type (and it is returned as the same text as what\nappears in the `types` array). If nothing in `types` is accepted, then `false`\nis returned.\n\nThe `types` array can contain full MIME types or file extensions. Any value\nthat is not a full MIME type is passed to `require('mime-types').lookup`.\n\n#### .types()\n\nReturn the types that the request accepts, in the order of the client's\npreference (most preferred first).\n\n## Examples\n\n### Simple type negotiation\n\nThis simple example shows how to use `accepts` to return a different typed\nrespond body based on what the client wants to accept. The server lists it's\npreferences in order and will get back the best match between the client and\nserver.\n\n```js\nvar accepts = require('accepts')\nvar http = require('http')\n\nfunction app (req, res) {\n  var accept = accepts(req)\n\n  // the order of this list is significant; should be server preferred order\n  switch (accept.type(['json', 'html'])) {\n    case 'json':\n      res.setHeader('Content-Type', 'application/json')\n      res.write('{\"hello\":\"world!\"}')\n      break\n    case 'html':\n      res.setHeader('Content-Type', 'text/html')\n      res.write('<b>hello, world!</b>')\n      break\n    default:\n      // the fallback is text/plain, so no need to specify it above\n      res.setHeader('Content-Type', 'text/plain')\n      res.write('hello, world!')\n      break\n  }\n\n  res.end()\n}\n\nhttp.createServer(app).listen(3000)\n```\n\nYou can test this out with the cURL program:\n```sh\ncurl -I -H'Accept: text/html' http://localhost:3000/\n```\n\n## License\n\n[MIT](LICENSE)\n\n[coveralls-image]: https://badgen.net/coveralls/c/github/jshttp/accepts/master\n[coveralls-url]: https://coveralls.io/r/jshttp/accepts?branch=master\n[github-actions-ci-image]: https://badgen.net/github/checks/jshttp/accepts/master?label=ci\n[github-actions-ci-url]: https://github.com/jshttp/accepts/actions/workflows/ci.yml\n[node-version-image]: https://badgen.net/npm/node/accepts\n[node-version-url]: https://nodejs.org/en/download\n[npm-downloads-image]: https://badgen.net/npm/dm/accepts\n[npm-url]: https://npmjs.org/package/accepts\n[npm-version-image]: https://badgen.net/npm/v/accepts\n",
        "plugins/auto-review/mcp/node_modules/ajv-formats/README.md": "# ajv-formats\n\nJSON Schema formats for Ajv\n\n[![Build Status](https://travis-ci.org/ajv-validator/ajv-formats.svg?branch=master)](https://travis-ci.org/ajv-validator/ajv-formats)\n[![npm](https://img.shields.io/npm/v/ajv-formats.svg)](https://www.npmjs.com/package/ajv-formats)\n[![Gitter](https://img.shields.io/gitter/room/ajv-validator/ajv.svg)](https://gitter.im/ajv-validator/ajv)\n[![GitHub Sponsors](https://img.shields.io/badge/$-sponsors-brightgreen)](https://github.com/sponsors/epoberezkin)\n\n## Usage\n\n```javascript\n// ESM/TypeScript import\nimport Ajv from \"ajv\"\nimport addFormats from \"ajv-formats\"\n// Node.js require:\nconst Ajv = require(\"ajv\")\nconst addFormats = require(\"ajv-formats\")\n\nconst ajv = new Ajv()\naddFormats(ajv)\n```\n\n## Formats\n\nThe package defines these formats:\n\n- _date_: full-date according to [RFC3339](http://tools.ietf.org/html/rfc3339#section-5.6).\n- _time_: time (time-zone is mandatory).\n- _date-time_: date-time (time-zone is mandatory).\n- _iso-time_: time with optional time-zone.\n- _iso-date-time_: date-time with optional time-zone.\n- _duration_: duration from [RFC3339](https://tools.ietf.org/html/rfc3339#appendix-A)\n- _uri_: full URI.\n- _uri-reference_: URI reference, including full and relative URIs.\n- _uri-template_: URI template according to [RFC6570](https://tools.ietf.org/html/rfc6570)\n- _url_ (deprecated): [URL record](https://url.spec.whatwg.org/#concept-url).\n- _email_: email address.\n- _hostname_: host name according to [RFC1034](http://tools.ietf.org/html/rfc1034#section-3.5).\n- _ipv4_: IP address v4.\n- _ipv6_: IP address v6.\n- _regex_: tests whether a string is a valid regular expression by passing it to RegExp constructor.\n- _uuid_: Universally Unique IDentifier according to [RFC4122](http://tools.ietf.org/html/rfc4122).\n- _json-pointer_: JSON-pointer according to [RFC6901](https://tools.ietf.org/html/rfc6901).\n- _relative-json-pointer_: relative JSON-pointer according to [this draft](http://tools.ietf.org/html/draft-luff-relative-json-pointer-00).\n- _byte_: base64 encoded data according to the [openApi 3.0.0 specification](https://spec.openapis.org/oas/v3.0.0#data-types)\n- _int32_: signed 32 bits integer according to the [openApi 3.0.0 specification](https://spec.openapis.org/oas/v3.0.0#data-types)\n- _int64_: signed 64 bits according to the [openApi 3.0.0 specification](https://spec.openapis.org/oas/v3.0.0#data-types)\n- _float_: float according to the [openApi 3.0.0 specification](https://spec.openapis.org/oas/v3.0.0#data-types)\n- _double_: double according to the [openApi 3.0.0 specification](https://spec.openapis.org/oas/v3.0.0#data-types)\n- _password_: password string according to the [openApi 3.0.0 specification](https://spec.openapis.org/oas/v3.0.0#data-types)\n- _binary_: binary string according to the [openApi 3.0.0 specification](https://spec.openapis.org/oas/v3.0.0#data-types)\n\nSee regular expressions used for format validation and the sources that were used in [formats.ts](https://github.com/ajv-validator/ajv-formats/blob/master/src/formats.ts).\n\n**Please note**: JSON Schema draft-07 also defines formats `iri`, `iri-reference`, `idn-hostname` and `idn-email` for URLs, hostnames and emails with international characters. These formats are available in [ajv-formats-draft2019](https://github.com/luzlab/ajv-formats-draft2019) plugin.\n\n## Keywords to compare values: `formatMaximum` / `formatMinimum` and `formatExclusiveMaximum` / `formatExclusiveMinimum`\n\nThese keywords allow to define minimum/maximum constraints when the format keyword defines ordering (`compare` function in format definition).\n\nThese keywords are added to ajv instance when ajv-formats is used without options or with option `keywords: true`.\n\nThese keywords apply only to strings. If the data is not a string, the validation succeeds.\n\nThe value of keywords `formatMaximum`/`formatMinimum` and `formatExclusiveMaximum`/`formatExclusiveMinimum` should be a string or [\\$data reference](https://github.com/ajv-validator/ajv/blob/master/docs/validation.md#data-reference). This value is the maximum (minimum) allowed value for the data to be valid as determined by `format` keyword. If `format` keyword is not present schema compilation will throw exception.\n\nWhen these keyword are added, they also add comparison functions to formats `\"date\"`, `\"time\"` and `\"date-time\"`. User-defined formats also can have comparison functions. See [addFormat](https://github.com/ajv-validator/ajv/blob/master/docs/api.md#api-addformat) method.\n\n```javascript\nrequire(\"ajv-formats\")(ajv)\n\nconst schema = {\n  type: \"string\",\n  format: \"date\",\n  formatMinimum: \"2016-02-06\",\n  formatExclusiveMaximum: \"2016-12-27\",\n}\n\nconst validDataList = [\"2016-02-06\", \"2016-12-26\"]\n\nconst invalidDataList = [\"2016-02-05\", \"2016-12-27\", \"abc\"]\n```\n\n## Options\n\nOptions can be passed via the second parameter. Options value can be\n\n1. The list of format names that will be added to ajv instance:\n\n```javascript\naddFormats(ajv, [\"date\", \"time\"])\n```\n\n**Please note**: when ajv encounters an undefined format it throws exception (unless ajv instance was configured with `strict: false` option). To allow specific undefined formats they have to be passed to ajv instance via `formats` option with `true` value:\n\n```javascript\nconst ajv = new Ajv((formats: {date: true, time: true})) // to ignore \"date\" and \"time\" formats in schemas.\n```\n\n2. Format validation mode (default is `\"full\"`) with optional list of format names and `keywords` option to add additional format comparison keywords:\n\n```javascript\naddFormats(ajv, {mode: \"fast\"})\n```\n\nor\n\n```javascript\naddFormats(ajv, {mode: \"fast\", formats: [\"date\", \"time\"], keywords: true})\n```\n\nIn `\"fast\"` mode the following formats are simplified: `\"date\"`, `\"time\"`, `\"date-time\"`, `\"iso-time\"`, `\"iso-date-time\"`, `\"uri\"`, `\"uri-reference\"`, `\"email\"`. For example, `\"date\"`, `\"time\"` and `\"date-time\"` do not validate ranges in `\"fast\"` mode, only string structure, and other formats have simplified regular expressions.\n\n## Tests\n\n```bash\nnpm install\ngit submodule update --init\nnpm test\n```\n\n## License\n\n[MIT](https://github.com/ajv-validator/ajv-formats/blob/master/LICENSE)\n",
        "plugins/auto-review/mcp/node_modules/ajv/README.md": "<img align=\"right\" alt=\"Ajv logo\" width=\"160\" src=\"https://ajv.js.org/img/ajv.svg\">\n\n&nbsp;\n\n# Ajv JSON schema validator\n\nThe fastest JSON validator for Node.js and browser.\n\nSupports JSON Schema draft-04/06/07/2019-09/2020-12 ([draft-04 support](https://ajv.js.org/json-schema.html#draft-04) requires ajv-draft-04 package) and JSON Type Definition [RFC8927](https://datatracker.ietf.org/doc/rfc8927/).\n\n[![build](https://github.com/ajv-validator/ajv/actions/workflows/build.yml/badge.svg)](https://github.com/ajv-validator/ajv/actions?query=workflow%3Abuild)\n[![npm](https://img.shields.io/npm/v/ajv.svg)](https://www.npmjs.com/package/ajv)\n[![npm downloads](https://img.shields.io/npm/dm/ajv.svg)](https://www.npmjs.com/package/ajv)\n[![Coverage Status](https://coveralls.io/repos/github/ajv-validator/ajv/badge.svg?branch=master)](https://coveralls.io/github/ajv-validator/ajv?branch=master)\n[![SimpleX](https://img.shields.io/badge/chat-on%20SimpleX-70F0F9)](https://simplex.chat/contact#/?v=1-2&smp=smp%3A%2F%2Fu2dS9sG8nMNURyZwqASV4yROM28Er0luVTx5X1CsMrU%3D%40smp4.simplex.im%2F8KvvURM6J38Gdq9dCuPswMOkMny0xCOJ%23%2F%3Fv%3D1-2%26dh%3DMCowBQYDK2VuAyEAr8rPVRuMOXv6kwF2yUAap-eoVg-9ssOFCi1fIrxTUw0%253D%26srv%3Do5vmywmrnaxalvz6wi3zicyftgio6psuvyniis6gco6bp6ekl4cqj4id.onion&data=%7B%22type%22%3A%22group%22%2C%22groupLinkId%22%3A%224pwLRgWHU9tlroMWHz0uOg%3D%3D%22%7D)\n[![Gitter](https://img.shields.io/gitter/room/ajv-validator/ajv.svg)](https://gitter.im/ajv-validator/ajv)\n[![GitHub Sponsors](https://img.shields.io/badge/$-sponsors-brightgreen)](https://github.com/sponsors/epoberezkin)\n\n## Ajv sponsors\n\n[<img src=\"https://ajv.js.org/img/mozilla.svg\" width=\"45%\" alt=\"Mozilla\">](https://www.mozilla.org)<img src=\"https://ajv.js.org/img/gap.svg\" width=\"9%\">[<img src=\"https://ajv.js.org/img/reserved.svg\" width=\"45%\">](https://opencollective.com/ajv)\n\n[<img src=\"https://ajv.js.org/img/microsoft.png\" width=\"31%\" alt=\"Microsoft\">](https://opensource.microsoft.com)<img src=\"https://ajv.js.org/img/gap.svg\" width=\"3%\">[<img src=\"https://ajv.js.org/img/reserved.svg\" width=\"31%\">](https://opencollective.com/ajv)<img src=\"https://ajv.js.org/img/gap.svg\" width=\"3%\">[<img src=\"https://ajv.js.org/img/reserved.svg\" width=\"31%\">](https://opencollective.com/ajv)\n\n[<img src=\"https://ajv.js.org/img/retool.svg\" width=\"22.5%\" alt=\"Retool\">](https://retool.com/?utm_source=sponsor&utm_campaign=ajv)<img src=\"https://ajv.js.org/img/gap.svg\" width=\"3%\">[<img src=\"https://ajv.js.org/img/tidelift.svg\" width=\"22.5%\" alt=\"Tidelift\">](https://tidelift.com/subscription/pkg/npm-ajv?utm_source=npm-ajv&utm_medium=referral&utm_campaign=enterprise)<img src=\"https://ajv.js.org/img/gap.svg\" width=\"3%\">[<img src=\"https://ajv.js.org/img/simplex.svg\" width=\"22.5%\" alt=\"SimpleX\">](https://github.com/simplex-chat/simplex-chat)<img src=\"https://ajv.js.org/img/gap.svg\" width=\"3%\">[<img src=\"https://ajv.js.org/img/reserved.svg\" width=\"22.5%\">](https://opencollective.com/ajv)\n\n## Contributing\n\nMore than 100 people contributed to Ajv, and we would love to have you join the development. We welcome implementing new features that will benefit many users and ideas to improve our documentation.\n\nPlease review [Contributing guidelines](./CONTRIBUTING.md) and [Code components](https://ajv.js.org/components.html).\n\n## Documentation\n\nAll documentation is available on the [Ajv website](https://ajv.js.org).\n\nSome useful site links:\n\n- [Getting started](https://ajv.js.org/guide/getting-started.html)\n- [JSON Schema vs JSON Type Definition](https://ajv.js.org/guide/schema-language.html)\n- [API reference](https://ajv.js.org/api.html)\n- [Strict mode](https://ajv.js.org/strict-mode.html)\n- [Standalone validation code](https://ajv.js.org/standalone.html)\n- [Security considerations](https://ajv.js.org/security.html)\n- [Command line interface](https://ajv.js.org/packages/ajv-cli.html)\n- [Frequently Asked Questions](https://ajv.js.org/faq.html)\n\n## <a name=\"sponsors\"></a>Please [sponsor Ajv development](https://github.com/sponsors/epoberezkin)\n\nSince I asked to support Ajv development 40 people and 6 organizations contributed via GitHub and OpenCollective - this support helped receiving the MOSS grant!\n\nYour continuing support is very important - the funds will be used to develop and maintain Ajv once the next major version is released.\n\nPlease sponsor Ajv via:\n\n- [GitHub sponsors page](https://github.com/sponsors/epoberezkin) (GitHub will match it)\n- [Ajv Open Collective](https://opencollective.com/ajv)\n\nThank you.\n\n#### Open Collective sponsors\n\n<a href=\"https://opencollective.com/ajv\"><img src=\"https://opencollective.com/ajv/individuals.svg?width=890\"></a>\n\n<a href=\"https://opencollective.com/ajv/organization/0/website\"><img src=\"https://opencollective.com/ajv/organization/0/avatar.svg\"></a>\n<a href=\"https://opencollective.com/ajv/organization/1/website\"><img src=\"https://opencollective.com/ajv/organization/1/avatar.svg\"></a>\n<a href=\"https://opencollective.com/ajv/organization/2/website\"><img src=\"https://opencollective.com/ajv/organization/2/avatar.svg\"></a>\n<a href=\"https://opencollective.com/ajv/organization/3/website\"><img src=\"https://opencollective.com/ajv/organization/3/avatar.svg\"></a>\n<a href=\"https://opencollective.com/ajv/organization/4/website\"><img src=\"https://opencollective.com/ajv/organization/4/avatar.svg\"></a>\n<a href=\"https://opencollective.com/ajv/organization/5/website\"><img src=\"https://opencollective.com/ajv/organization/5/avatar.svg\"></a>\n<a href=\"https://opencollective.com/ajv/organization/6/website\"><img src=\"https://opencollective.com/ajv/organization/6/avatar.svg\"></a>\n<a href=\"https://opencollective.com/ajv/organization/7/website\"><img src=\"https://opencollective.com/ajv/organization/7/avatar.svg\"></a>\n<a href=\"https://opencollective.com/ajv/organization/8/website\"><img src=\"https://opencollective.com/ajv/organization/8/avatar.svg\"></a>\n<a href=\"https://opencollective.com/ajv/organization/9/website\"><img src=\"https://opencollective.com/ajv/organization/9/avatar.svg\"></a>\n<a href=\"https://opencollective.com/ajv/organization/10/website\"><img src=\"https://opencollective.com/ajv/organization/10/avatar.svg\"></a>\n<a href=\"https://opencollective.com/ajv/organization/11/website\"><img src=\"https://opencollective.com/ajv/organization/11/avatar.svg\"></a>\n<a href=\"https://opencollective.com/ajv/organization/12/website\"><img src=\"https://opencollective.com/ajv/organization/12/avatar.svg\"></a>\n<a href=\"https://opencollective.com/ajv/organization/13/website\"><img src=\"https://opencollective.com/ajv/organization/13/avatar.svg\"></a>\n<a href=\"https://opencollective.com/ajv/organization/14/website\"><img src=\"https://opencollective.com/ajv/organization/14/avatar.svg\"></a>\n<a href=\"https://opencollective.com/ajv/organization/15/website\"><img src=\"https://opencollective.com/ajv/organization/15/avatar.svg\"></a>\n<a href=\"https://opencollective.com/ajv/organization/16/website\"><img src=\"https://opencollective.com/ajv/organization/16/avatar.svg\"></a>\n<a href=\"https://opencollective.com/ajv/organization/17/website\"><img src=\"https://opencollective.com/ajv/organization/17/avatar.svg\"></a>\n<a href=\"https://opencollective.com/ajv/organization/18/website\"><img src=\"https://opencollective.com/ajv/organization/18/avatar.svg\"></a>\n<a href=\"https://opencollective.com/ajv/organization/19/website\"><img src=\"https://opencollective.com/ajv/organization/19/avatar.svg\"></a>\n<a href=\"https://opencollective.com/ajv/organization/20/website\"><img src=\"https://opencollective.com/ajv/organization/20/avatar.svg\"></a>\n<a href=\"https://opencollective.com/ajv/organization/21/website\"><img src=\"https://opencollective.com/ajv/organization/21/avatar.svg\"></a>\n<a href=\"https://opencollective.com/ajv/organization/22/website\"><img src=\"https://opencollective.com/ajv/organization/22/avatar.svg\"></a>\n<a href=\"https://opencollective.com/ajv/organization/23/website\"><img src=\"https://opencollective.com/ajv/organization/23/avatar.svg\"></a>\n<a href=\"https://opencollective.com/ajv/organization/24/website\"><img src=\"https://opencollective.com/ajv/organization/24/avatar.svg\"></a>\n\n## Performance\n\nAjv generates code to turn JSON Schemas into super-fast validation functions that are efficient for v8 optimization.\n\nCurrently Ajv is the fastest and the most standard compliant validator according to these benchmarks:\n\n- [json-schema-benchmark](https://github.com/ebdrup/json-schema-benchmark) - 50% faster than the second place\n- [jsck benchmark](https://github.com/pandastrike/jsck#benchmarks) - 20-190% faster\n- [z-schema benchmark](https://rawgit.com/zaggino/z-schema/master/benchmark/results.html)\n- [themis benchmark](https://cdn.rawgit.com/playlyfe/themis/master/benchmark/results.html)\n\nPerformance of different validators by [json-schema-benchmark](https://github.com/ebdrup/json-schema-benchmark):\n\n[![performance](https://chart.googleapis.com/chart?chxt=x,y&cht=bhs&chco=76A4FB&chls=2.0&chbh=62,4,1&chs=600x416&chxl=-1:|ajv|@exodus/schemasafe|is-my-json-valid|djv|@cfworker/json-schema|jsonschema/=t:100,69.2,51.5,13.1,5.1,1.2)](https://github.com/ebdrup/json-schema-benchmark/blob/master/README.md#performance)\n\n## Features\n\n- Ajv implements JSON Schema [draft-06/07/2019-09/2020-12](http://json-schema.org/) standards (draft-04 is supported in v6):\n  - all validation keywords (see [JSON Schema validation keywords](https://ajv.js.org/json-schema.html))\n  - [OpenAPI](https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.3.md) extensions:\n    - NEW: keyword [discriminator](https://ajv.js.org/json-schema.html#discriminator).\n    - keyword [nullable](https://ajv.js.org/json-schema.html#nullable).\n  - full support of remote references (remote schemas have to be added with `addSchema` or compiled to be available)\n  - support of recursive references between schemas\n  - correct string lengths for strings with unicode pairs\n  - JSON Schema [formats](https://ajv.js.org/guide/formats.html) (with [ajv-formats](https://github.com/ajv-validator/ajv-formats) plugin).\n  - [validates schemas against meta-schema](https://ajv.js.org/api.html#api-validateschema)\n- NEW: supports [JSON Type Definition](https://datatracker.ietf.org/doc/rfc8927/):\n  - all keywords (see [JSON Type Definition schema forms](https://ajv.js.org/json-type-definition.html))\n  - meta-schema for JTD schemas\n  - \"union\" keyword and user-defined keywords (can be used inside \"metadata\" member of the schema)\n- supports [browsers](https://ajv.js.org/guide/environments.html#browsers) and Node.js 10.x - current\n- [asynchronous loading](https://ajv.js.org/guide/managing-schemas.html#asynchronous-schema-loading) of referenced schemas during compilation\n- \"All errors\" validation mode with [option allErrors](https://ajv.js.org/options.html#allerrors)\n- [error messages with parameters](https://ajv.js.org/api.html#validation-errors) describing error reasons to allow error message generation\n- i18n error messages support with [ajv-i18n](https://github.com/ajv-validator/ajv-i18n) package\n- [removing-additional-properties](https://ajv.js.org/guide/modifying-data.html#removing-additional-properties)\n- [assigning defaults](https://ajv.js.org/guide/modifying-data.html#assigning-defaults) to missing properties and items\n- [coercing data](https://ajv.js.org/guide/modifying-data.html#coercing-data-types) to the types specified in `type` keywords\n- [user-defined keywords](https://ajv.js.org/guide/user-keywords.html)\n- additional extension keywords with [ajv-keywords](https://github.com/ajv-validator/ajv-keywords) package\n- [\\$data reference](https://ajv.js.org/guide/combining-schemas.html#data-reference) to use values from the validated data as values for the schema keywords\n- [asynchronous validation](https://ajv.js.org/guide/async-validation.html) of user-defined formats and keywords\n\n## Install\n\nTo install version 8:\n\n```\nnpm install ajv\n```\n\n## <a name=\"usage\"></a>Getting started\n\nTry it in the Node.js REPL: https://runkit.com/npm/ajv\n\nIn JavaScript:\n\n```javascript\n// or ESM/TypeScript import\nimport Ajv from \"ajv\"\n// Node.js require:\nconst Ajv = require(\"ajv\")\n\nconst ajv = new Ajv() // options can be passed, e.g. {allErrors: true}\n\nconst schema = {\n  type: \"object\",\n  properties: {\n    foo: {type: \"integer\"},\n    bar: {type: \"string\"},\n  },\n  required: [\"foo\"],\n  additionalProperties: false,\n}\n\nconst data = {\n  foo: 1,\n  bar: \"abc\",\n}\n\nconst validate = ajv.compile(schema)\nconst valid = validate(data)\nif (!valid) console.log(validate.errors)\n```\n\nLearn how to use Ajv and see more examples in the [Guide: getting started](https://ajv.js.org/guide/getting-started.html)\n\n## Changes history\n\nSee [https://github.com/ajv-validator/ajv/releases](https://github.com/ajv-validator/ajv/releases)\n\n**Please note**: [Changes in version 8.0.0](https://github.com/ajv-validator/ajv/releases/tag/v8.0.0)\n\n[Version 7.0.0](https://github.com/ajv-validator/ajv/releases/tag/v7.0.0)\n\n[Version 6.0.0](https://github.com/ajv-validator/ajv/releases/tag/v6.0.0).\n\n## Code of conduct\n\nPlease review and follow the [Code of conduct](./CODE_OF_CONDUCT.md).\n\nPlease report any unacceptable behaviour to ajv.validator@gmail.com - it will be reviewed by the project team.\n\n## Security contact\n\nTo report a security vulnerability, please use the\n[Tidelift security contact](https://tidelift.com/security).\nTidelift will coordinate the fix and disclosure. Please do NOT report security vulnerabilities via GitHub issues.\n\n## Open-source software support\n\nAjv is a part of [Tidelift subscription](https://tidelift.com/subscription/pkg/npm-ajv?utm_source=npm-ajv&utm_medium=referral&utm_campaign=readme) - it provides a centralised support to open-source software users, in addition to the support provided by software maintainers.\n\n## License\n\n[MIT](./LICENSE)\n",
        "plugins/auto-review/mcp/node_modules/body-parser/README.md": "# body-parser\n\n[![NPM Version][npm-version-image]][npm-url]\n[![NPM Downloads][npm-downloads-image]][npm-url]\n[![Build Status][ci-image]][ci-url]\n[![Test Coverage][coveralls-image]][coveralls-url]\n[![OpenSSF Scorecard Badge][ossf-scorecard-badge]][ossf-scorecard-visualizer]\n\nNode.js body parsing middleware.\n\nParse incoming request bodies in a middleware before your handlers, available\nunder the `req.body` property.\n\n**Note** As `req.body`'s shape is based on user-controlled input, all\nproperties and values in this object are untrusted and should be validated\nbefore trusting. For example, `req.body.foo.toString()` may fail in multiple\nways, for example the `foo` property may not be there or may not be a string,\nand `toString` may not be a function and instead a string or other user input.\n\n[Learn about the anatomy of an HTTP transaction in Node.js](https://nodejs.org/en/docs/guides/anatomy-of-an-http-transaction/).\n\n_This does not handle multipart bodies_, due to their complex and typically\nlarge nature. For multipart bodies, you may be interested in the following\nmodules:\n\n  * [busboy](https://www.npmjs.org/package/busboy#readme) and\n    [connect-busboy](https://www.npmjs.org/package/connect-busboy#readme)\n  * [multiparty](https://www.npmjs.org/package/multiparty#readme) and\n    [connect-multiparty](https://www.npmjs.org/package/connect-multiparty#readme)\n  * [formidable](https://www.npmjs.org/package/formidable#readme)\n  * [multer](https://www.npmjs.org/package/multer#readme)\n\nThis module provides the following parsers:\n\n  * [JSON body parser](#bodyparserjsonoptions)\n  * [Raw body parser](#bodyparserrawoptions)\n  * [Text body parser](#bodyparsertextoptions)\n  * [URL-encoded form body parser](#bodyparserurlencodedoptions)\n\nOther body parsers you might be interested in:\n\n- [body](https://www.npmjs.org/package/body#readme)\n- [co-body](https://www.npmjs.org/package/co-body#readme)\n\n## Installation\n\n```sh\n$ npm install body-parser\n```\n\n## API\n\n```js\nconst bodyParser = require('body-parser')\n```\n\nThe `bodyParser` object exposes various factories to create middlewares. All\nmiddlewares will populate the `req.body` property with the parsed body when\nthe `Content-Type` request header matches the `type` option.\n\nThe various errors returned by this module are described in the\n[errors section](#errors).\n\n### bodyParser.json([options])\n\nReturns middleware that only parses `json` and only looks at requests where\nthe `Content-Type` header matches the `type` option. This parser accepts any\nUnicode encoding of the body and supports automatic inflation of `gzip`,\n`br` (brotli) and `deflate` encodings.\n\nA new `body` object containing the parsed data is populated on the `request`\nobject after the middleware (i.e. `req.body`).\n\n#### Options\n\nThe `json` function takes an optional `options` object that may contain any of\nthe following keys:\n\n##### inflate\n\nWhen set to `true`, then deflated (compressed) bodies will be inflated; when\n`false`, deflated bodies are rejected. Defaults to `true`.\n\n##### limit\n\nControls the maximum request body size. If this is a number, then the value\nspecifies the number of bytes; if it is a string, the value is passed to the\n[bytes](https://www.npmjs.com/package/bytes) library for parsing. Defaults\nto `'100kb'`.\n\n##### reviver\n\nThe `reviver` option is passed directly to `JSON.parse` as the second\nargument. You can find more information on this argument\n[in the MDN documentation about JSON.parse](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/parse#Example.3A_Using_the_reviver_parameter).\n\n##### strict\n\nWhen set to `true`, will only accept arrays and objects; when `false` will\naccept anything `JSON.parse` accepts. Defaults to `true`.\n\n##### type\n\nThe `type` option is used to determine what media type the middleware will\nparse. This option can be a string, array of strings, or a function. If not a\nfunction, `type` option is passed directly to the\n[type-is](https://www.npmjs.org/package/type-is#readme) library and this can\nbe an extension name (like `json`), a mime type (like `application/json`), or\na mime type with a wildcard (like `*/*` or `*/json`). If a function, the `type`\noption is called as `fn(req)` and the request is parsed if it returns a truthy\nvalue. Defaults to `application/json`.\n\n##### verify\n\nThe `verify` option, if supplied, is called as `verify(req, res, buf, encoding)`,\nwhere `buf` is a `Buffer` of the raw request body and `encoding` is the\nencoding of the request. The parsing can be aborted by throwing an error.\n\n### bodyParser.raw([options])\n\nReturns middleware that parses all bodies as a `Buffer` and only looks at\nrequests where the `Content-Type` header matches the `type` option. This\nparser supports automatic inflation of `gzip`, `br` (brotli) and `deflate`\nencodings.\n\nA new `body` object containing the parsed data is populated on the `request`\nobject after the middleware (i.e. `req.body`). This will be a `Buffer` object\nof the body.\n\n#### Options\n\nThe `raw` function takes an optional `options` object that may contain any of\nthe following keys:\n\n##### inflate\n\nWhen set to `true`, then deflated (compressed) bodies will be inflated; when\n`false`, deflated bodies are rejected. Defaults to `true`.\n\n##### limit\n\nControls the maximum request body size. If this is a number, then the value\nspecifies the number of bytes; if it is a string, the value is passed to the\n[bytes](https://www.npmjs.com/package/bytes) library for parsing. Defaults\nto `'100kb'`.\n\n##### type\n\nThe `type` option is used to determine what media type the middleware will\nparse. This option can be a string, array of strings, or a function.\nIf not a function, `type` option is passed directly to the\n[type-is](https://www.npmjs.org/package/type-is#readme) library and this\ncan be an extension name (like `bin`), a mime type (like\n`application/octet-stream`), or a mime type with a wildcard (like `*/*` or\n`application/*`). If a function, the `type` option is called as `fn(req)`\nand the request is parsed if it returns a truthy value. Defaults to\n`application/octet-stream`.\n\n##### verify\n\nThe `verify` option, if supplied, is called as `verify(req, res, buf, encoding)`,\nwhere `buf` is a `Buffer` of the raw request body and `encoding` is the\nencoding of the request. The parsing can be aborted by throwing an error.\n\n### bodyParser.text([options])\n\nReturns middleware that parses all bodies as a string and only looks at\nrequests where the `Content-Type` header matches the `type` option. This\nparser supports automatic inflation of `gzip`, `br` (brotli) and `deflate`\nencodings.\n\nA new `body` string containing the parsed data is populated on the `request`\nobject after the middleware (i.e. `req.body`). This will be a string of the\nbody.\n\n#### Options\n\nThe `text` function takes an optional `options` object that may contain any of\nthe following keys:\n\n##### defaultCharset\n\nSpecify the default character set for the text content if the charset is not\nspecified in the `Content-Type` header of the request. Defaults to `utf-8`.\n\n##### inflate\n\nWhen set to `true`, then deflated (compressed) bodies will be inflated; when\n`false`, deflated bodies are rejected. Defaults to `true`.\n\n##### limit\n\nControls the maximum request body size. If this is a number, then the value\nspecifies the number of bytes; if it is a string, the value is passed to the\n[bytes](https://www.npmjs.com/package/bytes) library for parsing. Defaults\nto `'100kb'`.\n\n##### type\n\nThe `type` option is used to determine what media type the middleware will\nparse. This option can be a string, array of strings, or a function. If not\na function, `type` option is passed directly to the\n[type-is](https://www.npmjs.org/package/type-is#readme) library and this can\nbe an extension name (like `txt`), a mime type (like `text/plain`), or a mime\ntype with a wildcard (like `*/*` or `text/*`). If a function, the `type`\noption is called as `fn(req)` and the request is parsed if it returns a\ntruthy value. Defaults to `text/plain`.\n\n##### verify\n\nThe `verify` option, if supplied, is called as `verify(req, res, buf, encoding)`,\nwhere `buf` is a `Buffer` of the raw request body and `encoding` is the\nencoding of the request. The parsing can be aborted by throwing an error.\n\n### bodyParser.urlencoded([options])\n\nReturns middleware that only parses `urlencoded` bodies and only looks at\nrequests where the `Content-Type` header matches the `type` option. This\nparser accepts only UTF-8 encoding of the body and supports automatic\ninflation of `gzip`, `br` (brotli) and `deflate` encodings.\n\nA new `body` object containing the parsed data is populated on the `request`\nobject after the middleware (i.e. `req.body`). This object will contain\nkey-value pairs, where the value can be a string or array (when `extended` is\n`false`), or any type (when `extended` is `true`).\n\n#### Options\n\nThe `urlencoded` function takes an optional `options` object that may contain\nany of the following keys:\n\n##### extended\n\nThe \"extended\" syntax allows for rich objects and arrays to be encoded into the\nURL-encoded format, allowing for a JSON-like experience with URL-encoded. For\nmore information, please [see the qs\nlibrary](https://www.npmjs.org/package/qs#readme).\n\nDefaults to `false`.\n\n##### inflate\n\nWhen set to `true`, then deflated (compressed) bodies will be inflated; when\n`false`, deflated bodies are rejected. Defaults to `true`.\n\n##### limit\n\nControls the maximum request body size. If this is a number, then the value\nspecifies the number of bytes; if it is a string, the value is passed to the\n[bytes](https://www.npmjs.com/package/bytes) library for parsing. Defaults\nto `'100kb'`.\n\n##### parameterLimit\n\nThe `parameterLimit` option controls the maximum number of parameters that\nare allowed in the URL-encoded data. If a request contains more parameters\nthan this value, a 413 will be returned to the client. Defaults to `1000`.\n\n##### type\n\nThe `type` option is used to determine what media type the middleware will\nparse. This option can be a string, array of strings, or a function. If not\na function, `type` option is passed directly to the\n[type-is](https://www.npmjs.org/package/type-is#readme) library and this can\nbe an extension name (like `urlencoded`), a mime type (like\n`application/x-www-form-urlencoded`), or a mime type with a wildcard (like\n`*/x-www-form-urlencoded`). If a function, the `type` option is called as\n`fn(req)` and the request is parsed if it returns a truthy value. Defaults\nto `application/x-www-form-urlencoded`.\n\n##### verify\n\nThe `verify` option, if supplied, is called as `verify(req, res, buf, encoding)`,\nwhere `buf` is a `Buffer` of the raw request body and `encoding` is the\nencoding of the request. The parsing can be aborted by throwing an error.\n\n##### defaultCharset\n\nThe default charset to parse as, if not specified in content-type. Must be\neither `utf-8` or `iso-8859-1`. Defaults to `utf-8`.\n\n##### charsetSentinel\n\nWhether to let the value of the `utf8` parameter take precedence as the charset\nselector. It requires the form to contain a parameter named `utf8` with a value\nof `✓`. Defaults to `false`.\n\n##### interpretNumericEntities\n\nWhether to decode numeric entities such as `&#9786;` when parsing an iso-8859-1\nform. Defaults to `false`.\n\n\n#### depth\n\nThe `depth` option is used to configure the maximum depth of the `qs` library when `extended` is `true`. This allows you to limit the amount of keys that are parsed and can be useful to prevent certain types of abuse. Defaults to `32`. It is recommended to keep this value as low as possible.\n\n## Errors\n\nThe middlewares provided by this module create errors using the\n[`http-errors` module](https://www.npmjs.com/package/http-errors). The errors\nwill typically have a `status`/`statusCode` property that contains the suggested\nHTTP response code, an `expose` property to determine if the `message` property\nshould be displayed to the client, a `type` property to determine the type of\nerror without matching against the `message`, and a `body` property containing\nthe read body, if available.\n\nThe following are the common errors created, though any error can come through\nfor various reasons.\n\n### content encoding unsupported\n\nThis error will occur when the request had a `Content-Encoding` header that\ncontained an encoding but the \"inflation\" option was set to `false`. The\n`status` property is set to `415`, the `type` property is set to\n`'encoding.unsupported'`, and the `charset` property will be set to the\nencoding that is unsupported.\n\n### entity parse failed\n\nThis error will occur when the request contained an entity that could not be\nparsed by the middleware. The `status` property is set to `400`, the `type`\nproperty is set to `'entity.parse.failed'`, and the `body` property is set to\nthe entity value that failed parsing.\n\n### entity verify failed\n\nThis error will occur when the request contained an entity that could not be\nfailed verification by the defined `verify` option. The `status` property is\nset to `403`, the `type` property is set to `'entity.verify.failed'`, and the\n`body` property is set to the entity value that failed verification.\n\n### request aborted\n\nThis error will occur when the request is aborted by the client before reading\nthe body has finished. The `received` property will be set to the number of\nbytes received before the request was aborted and the `expected` property is\nset to the number of expected bytes. The `status` property is set to `400`\nand `type` property is set to `'request.aborted'`.\n\n### request entity too large\n\nThis error will occur when the request body's size is larger than the \"limit\"\noption. The `limit` property will be set to the byte limit and the `length`\nproperty will be set to the request body's length. The `status` property is\nset to `413` and the `type` property is set to `'entity.too.large'`.\n\n### request size did not match content length\n\nThis error will occur when the request's length did not match the length from\nthe `Content-Length` header. This typically occurs when the request is malformed,\ntypically when the `Content-Length` header was calculated based on characters\ninstead of bytes. The `status` property is set to `400` and the `type` property\nis set to `'request.size.invalid'`.\n\n### stream encoding should not be set\n\nThis error will occur when something called the `req.setEncoding` method prior\nto this middleware. This module operates directly on bytes only and you cannot\ncall `req.setEncoding` when using this module. The `status` property is set to\n`500` and the `type` property is set to `'stream.encoding.set'`.\n\n### stream is not readable\n\nThis error will occur when the request is no longer readable when this middleware\nattempts to read it. This typically means something other than a middleware from\nthis module read the request body already and the middleware was also configured to\nread the same request. The `status` property is set to `500` and the `type`\nproperty is set to `'stream.not.readable'`.\n\n### too many parameters\n\nThis error will occur when the content of the request exceeds the configured\n`parameterLimit` for the `urlencoded` parser. The `status` property is set to\n`413` and the `type` property is set to `'parameters.too.many'`.\n\n### unsupported charset \"BOGUS\"\n\nThis error will occur when the request had a charset parameter in the\n`Content-Type` header, but the `iconv-lite` module does not support it OR the\nparser does not support it. The charset is contained in the message as well\nas in the `charset` property. The `status` property is set to `415`, the\n`type` property is set to `'charset.unsupported'`, and the `charset` property\nis set to the charset that is unsupported.\n\n### unsupported content encoding \"bogus\"\n\nThis error will occur when the request had a `Content-Encoding` header that\ncontained an unsupported encoding. The encoding is contained in the message\nas well as in the `encoding` property. The `status` property is set to `415`,\nthe `type` property is set to `'encoding.unsupported'`, and the `encoding`\nproperty is set to the encoding that is unsupported.\n\n### The input exceeded the depth\n\nThis error occurs when using `bodyParser.urlencoded` with the `extended` property set to `true` and the input exceeds the configured `depth` option. The `status` property is set to `400`. It is recommended to review the `depth` option and evaluate if it requires a higher value. When the `depth` option is set to `32` (default value), the error will not be thrown.\n\n## Examples\n\n### Express/Connect top-level generic\n\nThis example demonstrates adding a generic JSON and URL-encoded parser as a\ntop-level middleware, which will parse the bodies of all incoming requests.\nThis is the simplest setup.\n\n```js\nconst express = require('express')\nconst bodyParser = require('body-parser')\n\nconst app = express()\n\n// parse application/x-www-form-urlencoded\napp.use(bodyParser.urlencoded())\n\n// parse application/json\napp.use(bodyParser.json())\n\napp.use(function (req, res) {\n  res.setHeader('Content-Type', 'text/plain')\n  res.write('you posted:\\n')\n  res.end(String(JSON.stringify(req.body, null, 2)))\n})\n```\n\n### Express route-specific\n\nThis example demonstrates adding body parsers specifically to the routes that\nneed them. In general, this is the most recommended way to use body-parser with\nExpress.\n\n```js\nconst express = require('express')\nconst bodyParser = require('body-parser')\n\nconst app = express()\n\n// create application/json parser\nconst jsonParser = bodyParser.json()\n\n// create application/x-www-form-urlencoded parser\nconst urlencodedParser = bodyParser.urlencoded()\n\n// POST /login gets urlencoded bodies\napp.post('/login', urlencodedParser, function (req, res) {\n  if (!req.body || !req.body.username) res.sendStatus(400)\n  res.send('welcome, ' + req.body.username)\n})\n\n// POST /api/users gets JSON bodies\napp.post('/api/users', jsonParser, function (req, res) {\n  if (!req.body) res.sendStatus(400)\n  // create user in req.body\n})\n```\n\n### Change accepted type for parsers\n\nAll the parsers accept a `type` option which allows you to change the\n`Content-Type` that the middleware will parse.\n\n```js\nconst express = require('express')\nconst bodyParser = require('body-parser')\n\nconst app = express()\n\n// parse various different custom JSON types as JSON\napp.use(bodyParser.json({ type: 'application/*+json' }))\n\n// parse some custom thing into a Buffer\napp.use(bodyParser.raw({ type: 'application/vnd.custom-type' }))\n\n// parse an HTML body into a string\napp.use(bodyParser.text({ type: 'text/html' }))\n```\n\n## License\n\n[MIT](LICENSE)\n\n[ci-image]: https://badgen.net/github/checks/expressjs/body-parser/master?label=ci\n[ci-url]: https://github.com/expressjs/body-parser/actions/workflows/ci.yml\n[coveralls-image]: https://badgen.net/coveralls/c/github/expressjs/body-parser/master\n[coveralls-url]: https://coveralls.io/r/expressjs/body-parser?branch=master\n[node-version-image]: https://badgen.net/npm/node/body-parser\n[node-version-url]: https://nodejs.org/en/download\n[npm-downloads-image]: https://badgen.net/npm/dm/body-parser\n[npm-url]: https://npmjs.org/package/body-parser\n[npm-version-image]: https://badgen.net/npm/v/body-parser\n[ossf-scorecard-badge]: https://api.scorecard.dev/projects/github.com/expressjs/body-parser/badge\n[ossf-scorecard-visualizer]: https://ossf.github.io/scorecard-visualizer/#/projects/github.com/expressjs/body-parser",
        "plugins/auto-review/mcp/node_modules/call-bind-apply-helpers/README.md": "# call-bind-apply-helpers <sup>[![Version Badge][npm-version-svg]][package-url]</sup>\n\n[![github actions][actions-image]][actions-url]\n[![coverage][codecov-image]][codecov-url]\n[![dependency status][deps-svg]][deps-url]\n[![dev dependency status][dev-deps-svg]][dev-deps-url]\n[![License][license-image]][license-url]\n[![Downloads][downloads-image]][downloads-url]\n\n[![npm badge][npm-badge-png]][package-url]\n\nHelper functions around Function call/apply/bind, for use in `call-bind`.\n\nThe only packages that should likely ever use this package directly are `call-bind` and `get-intrinsic`.\nPlease use `call-bind` unless you have a very good reason not to.\n\n## Getting started\n\n```sh\nnpm install --save call-bind-apply-helpers\n```\n\n## Usage/Examples\n\n```js\nconst assert = require('assert');\nconst callBindBasic = require('call-bind-apply-helpers');\n\nfunction f(a, b) {\n\tassert.equal(this, 1);\n\tassert.equal(a, 2);\n\tassert.equal(b, 3);\n\tassert.equal(arguments.length, 2);\n}\n\nconst fBound = callBindBasic([f, 1]);\n\ndelete Function.prototype.call;\ndelete Function.prototype.bind;\n\nfBound(2, 3);\n```\n\n## Tests\n\nClone the repo, `npm install`, and run `npm test`\n\n[package-url]: https://npmjs.org/package/call-bind-apply-helpers\n[npm-version-svg]: https://versionbadg.es/ljharb/call-bind-apply-helpers.svg\n[deps-svg]: https://david-dm.org/ljharb/call-bind-apply-helpers.svg\n[deps-url]: https://david-dm.org/ljharb/call-bind-apply-helpers\n[dev-deps-svg]: https://david-dm.org/ljharb/call-bind-apply-helpers/dev-status.svg\n[dev-deps-url]: https://david-dm.org/ljharb/call-bind-apply-helpers#info=devDependencies\n[npm-badge-png]: https://nodei.co/npm/call-bind-apply-helpers.png?downloads=true&stars=true\n[license-image]: https://img.shields.io/npm/l/call-bind-apply-helpers.svg\n[license-url]: LICENSE\n[downloads-image]: https://img.shields.io/npm/dm/call-bind-apply-helpers.svg\n[downloads-url]: https://npm-stat.com/charts.html?package=call-bind-apply-helpers\n[codecov-image]: https://codecov.io/gh/ljharb/call-bind-apply-helpers/branch/main/graphs/badge.svg\n[codecov-url]: https://app.codecov.io/gh/ljharb/call-bind-apply-helpers/\n[actions-image]: https://img.shields.io/endpoint?url=https://github-actions-badge-u3jn4tfpocch.runkit.sh/ljharb/call-bind-apply-helpers\n[actions-url]: https://github.com/ljharb/call-bind-apply-helpers/actions\n",
        "plugins/auto-review/mcp/node_modules/call-bound/README.md": "# call-bound <sup>[![Version Badge][npm-version-svg]][package-url]</sup>\n\n[![github actions][actions-image]][actions-url]\n[![coverage][codecov-image]][codecov-url]\n[![dependency status][deps-svg]][deps-url]\n[![dev dependency status][dev-deps-svg]][dev-deps-url]\n[![License][license-image]][license-url]\n[![Downloads][downloads-image]][downloads-url]\n\n[![npm badge][npm-badge-png]][package-url]\n\nRobust call-bound JavaScript intrinsics, using `call-bind` and `get-intrinsic`.\n\n## Getting started\n\n```sh\nnpm install --save call-bound\n```\n\n## Usage/Examples\n\n```js\nconst assert = require('assert');\nconst callBound = require('call-bound');\n\nconst slice = callBound('Array.prototype.slice');\n\ndelete Function.prototype.call;\ndelete Function.prototype.bind;\ndelete Array.prototype.slice;\n\nassert.deepEqual(slice([1, 2, 3, 4], 1, -1), [2, 3]);\n```\n\n## Tests\n\nClone the repo, `npm install`, and run `npm test`\n\n[package-url]: https://npmjs.org/package/call-bound\n[npm-version-svg]: https://versionbadg.es/ljharb/call-bound.svg\n[deps-svg]: https://david-dm.org/ljharb/call-bound.svg\n[deps-url]: https://david-dm.org/ljharb/call-bound\n[dev-deps-svg]: https://david-dm.org/ljharb/call-bound/dev-status.svg\n[dev-deps-url]: https://david-dm.org/ljharb/call-bound#info=devDependencies\n[npm-badge-png]: https://nodei.co/npm/call-bound.png?downloads=true&stars=true\n[license-image]: https://img.shields.io/npm/l/call-bound.svg\n[license-url]: LICENSE\n[downloads-image]: https://img.shields.io/npm/dm/call-bound.svg\n[downloads-url]: https://npm-stat.com/charts.html?package=call-bound\n[codecov-image]: https://codecov.io/gh/ljharb/call-bound/branch/main/graphs/badge.svg\n[codecov-url]: https://app.codecov.io/gh/ljharb/call-bound/\n[actions-image]: https://img.shields.io/endpoint?url=https://github-actions-badge-u3jn4tfpocch.runkit.sh/ljharb/call-bound\n[actions-url]: https://github.com/ljharb/call-bound/actions\n",
        "plugins/auto-review/mcp/node_modules/content-disposition/README.md": "# content-disposition\n\n[![NPM Version][npm-image]][npm-url]\n[![NPM Downloads][downloads-image]][downloads-url]\n[![Node.js Version][node-version-image]][node-version-url]\n[![Build Status][github-actions-ci-image]][github-actions-ci-url]\n[![Test Coverage][coveralls-image]][coveralls-url]\n\nCreate and parse HTTP `Content-Disposition` header\n\n## Installation\n\n```sh\n$ npm install content-disposition\n```\n\n## API\n\n```js\nvar contentDisposition = require('content-disposition')\n```\n\n### contentDisposition(filename, options)\n\nCreate an attachment `Content-Disposition` header value using the given file name,\nif supplied. The `filename` is optional and if no file name is desired, but you\nwant to specify `options`, set `filename` to `undefined`.\n\n```js\nres.setHeader('Content-Disposition', contentDisposition('∫ maths.pdf'))\n```\n\n**note** HTTP headers are of the ISO-8859-1 character set. If you are writing this\nheader through a means different from `setHeader` in Node.js, you'll want to specify\nthe `'binary'` encoding in Node.js.\n\n#### Options\n\n`contentDisposition` accepts these properties in the options object.\n\n##### fallback\n\nIf the `filename` option is outside ISO-8859-1, then the file name is actually\nstored in a supplemental field for clients that support Unicode file names and\na ISO-8859-1 version of the file name is automatically generated.\n\nThis specifies the ISO-8859-1 file name to override the automatic generation or\ndisables the generation all together, defaults to `true`.\n\n  - A string will specify the ISO-8859-1 file name to use in place of automatic\n    generation.\n  - `false` will disable including a ISO-8859-1 file name and only include the\n    Unicode version (unless the file name is already ISO-8859-1).\n  - `true` will enable automatic generation if the file name is outside ISO-8859-1.\n\nIf the `filename` option is ISO-8859-1 and this option is specified and has a\ndifferent value, then the `filename` option is encoded in the extended field\nand this set as the fallback field, even though they are both ISO-8859-1.\n\n##### type\n\nSpecifies the disposition type, defaults to `\"attachment\"`. This can also be\n`\"inline\"`, or any other value (all values except inline are treated like\n`attachment`, but can convey additional information if both parties agree to\nit). The type is normalized to lower-case.\n\n### contentDisposition.parse(string)\n\n```js\nvar disposition = contentDisposition.parse('attachment; filename=\"EURO rates.txt\"; filename*=UTF-8\\'\\'%e2%82%ac%20rates.txt')\n```\n\nParse a `Content-Disposition` header string. This automatically handles extended\n(\"Unicode\") parameters by decoding them and providing them under the standard\nparameter name. This will return an object with the following properties (examples\nare shown for the string `'attachment; filename=\"EURO rates.txt\"; filename*=UTF-8\\'\\'%e2%82%ac%20rates.txt'`):\n\n - `type`: The disposition type (always lower case). Example: `'attachment'`\n\n - `parameters`: An object of the parameters in the disposition (name of parameter\n   always lower case and extended versions replace non-extended versions). Example:\n   `{filename: \"€ rates.txt\"}`\n\n## Examples\n\n### Send a file for download\n\n```js\nvar contentDisposition = require('content-disposition')\nvar destroy = require('destroy')\nvar fs = require('fs')\nvar http = require('http')\nvar onFinished = require('on-finished')\n\nvar filePath = '/path/to/public/plans.pdf'\n\nhttp.createServer(function onRequest (req, res) {\n  // set headers\n  res.setHeader('Content-Type', 'application/pdf')\n  res.setHeader('Content-Disposition', contentDisposition(filePath))\n\n  // send file\n  var stream = fs.createReadStream(filePath)\n  stream.pipe(res)\n  onFinished(res, function () {\n    destroy(stream)\n  })\n})\n```\n\n## Testing\n\n```sh\n$ npm test\n```\n\n## References\n\n- [RFC 2616: Hypertext Transfer Protocol -- HTTP/1.1][rfc-2616]\n- [RFC 5987: Character Set and Language Encoding for Hypertext Transfer Protocol (HTTP) Header Field Parameters][rfc-5987]\n- [RFC 6266: Use of the Content-Disposition Header Field in the Hypertext Transfer Protocol (HTTP)][rfc-6266]\n- [Test Cases for HTTP Content-Disposition header field (RFC 6266) and the Encodings defined in RFCs 2047, 2231 and 5987][tc-2231]\n\n[rfc-2616]: https://tools.ietf.org/html/rfc2616\n[rfc-5987]: https://tools.ietf.org/html/rfc5987\n[rfc-6266]: https://tools.ietf.org/html/rfc6266\n[tc-2231]: http://greenbytes.de/tech/tc2231/\n\n## License\n\n[MIT](LICENSE)\n\n[npm-image]: https://img.shields.io/npm/v/content-disposition.svg\n[npm-url]: https://npmjs.org/package/content-disposition\n[node-version-image]: https://img.shields.io/node/v/content-disposition.svg\n[node-version-url]: https://nodejs.org/en/download\n[coveralls-image]: https://img.shields.io/coveralls/jshttp/content-disposition.svg\n[coveralls-url]: https://coveralls.io/r/jshttp/content-disposition?branch=master\n[downloads-image]: https://img.shields.io/npm/dm/content-disposition.svg\n[downloads-url]: https://npmjs.org/package/content-disposition\n[github-actions-ci-image]: https://img.shields.io/github/workflow/status/jshttp/content-disposition/ci/master?label=ci\n[github-actions-ci-url]: https://github.com/jshttp/content-disposition?query=workflow%3Aci\n",
        "plugins/auto-review/mcp/node_modules/content-type/README.md": "# content-type\n\n[![NPM Version][npm-version-image]][npm-url]\n[![NPM Downloads][npm-downloads-image]][npm-url]\n[![Node.js Version][node-image]][node-url]\n[![Build Status][ci-image]][ci-url]\n[![Coverage Status][coveralls-image]][coveralls-url]\n\nCreate and parse HTTP Content-Type header according to RFC 7231\n\n## Installation\n\n```sh\n$ npm install content-type\n```\n\n## API\n\n```js\nvar contentType = require('content-type')\n```\n\n### contentType.parse(string)\n\n```js\nvar obj = contentType.parse('image/svg+xml; charset=utf-8')\n```\n\nParse a `Content-Type` header. This will return an object with the following\nproperties (examples are shown for the string `'image/svg+xml; charset=utf-8'`):\n\n - `type`: The media type (the type and subtype, always lower case).\n   Example: `'image/svg+xml'`\n\n - `parameters`: An object of the parameters in the media type (name of parameter\n   always lower case). Example: `{charset: 'utf-8'}`\n\nThrows a `TypeError` if the string is missing or invalid.\n\n### contentType.parse(req)\n\n```js\nvar obj = contentType.parse(req)\n```\n\nParse the `Content-Type` header from the given `req`. Short-cut for\n`contentType.parse(req.headers['content-type'])`.\n\nThrows a `TypeError` if the `Content-Type` header is missing or invalid.\n\n### contentType.parse(res)\n\n```js\nvar obj = contentType.parse(res)\n```\n\nParse the `Content-Type` header set on the given `res`. Short-cut for\n`contentType.parse(res.getHeader('content-type'))`.\n\nThrows a `TypeError` if the `Content-Type` header is missing or invalid.\n\n### contentType.format(obj)\n\n```js\nvar str = contentType.format({\n  type: 'image/svg+xml',\n  parameters: { charset: 'utf-8' }\n})\n```\n\nFormat an object into a `Content-Type` header. This will return a string of the\ncontent type for the given object with the following properties (examples are\nshown that produce the string `'image/svg+xml; charset=utf-8'`):\n\n - `type`: The media type (will be lower-cased). Example: `'image/svg+xml'`\n\n - `parameters`: An object of the parameters in the media type (name of the\n   parameter will be lower-cased). Example: `{charset: 'utf-8'}`\n\nThrows a `TypeError` if the object contains an invalid type or parameter names.\n\n## License\n\n[MIT](LICENSE)\n\n[ci-image]: https://badgen.net/github/checks/jshttp/content-type/master?label=ci\n[ci-url]: https://github.com/jshttp/content-type/actions/workflows/ci.yml\n[coveralls-image]: https://badgen.net/coveralls/c/github/jshttp/content-type/master\n[coveralls-url]: https://coveralls.io/r/jshttp/content-type?branch=master\n[node-image]: https://badgen.net/npm/node/content-type\n[node-url]: https://nodejs.org/en/download\n[npm-downloads-image]: https://badgen.net/npm/dm/content-type\n[npm-url]: https://npmjs.org/package/content-type\n[npm-version-image]: https://badgen.net/npm/v/content-type\n",
        "plugins/auto-review/mcp/node_modules/cookie/README.md": "# cookie\n\n[![NPM Version][npm-version-image]][npm-url]\n[![NPM Downloads][npm-downloads-image]][npm-url]\n[![Node.js Version][node-image]][node-url]\n[![Build Status][ci-image]][ci-url]\n[![Coverage Status][coveralls-image]][coveralls-url]\n\nBasic HTTP cookie parser and serializer for HTTP servers.\n\n## Installation\n\nThis is a [Node.js](https://nodejs.org/en/) module available through the\n[npm registry](https://www.npmjs.com/). Installation is done using the\n[`npm install` command](https://docs.npmjs.com/getting-started/installing-npm-packages-locally):\n\n```sh\n$ npm install cookie\n```\n\n## API\n\n```js\nvar cookie = require('cookie');\n```\n\n### cookie.parse(str, options)\n\nParse an HTTP `Cookie` header string and returning an object of all cookie name-value pairs.\nThe `str` argument is the string representing a `Cookie` header value and `options` is an\noptional object containing additional parsing options.\n\n```js\nvar cookies = cookie.parse('foo=bar; equation=E%3Dmc%5E2');\n// { foo: 'bar', equation: 'E=mc^2' }\n```\n\n#### Options\n\n`cookie.parse` accepts these properties in the options object.\n\n##### decode\n\nSpecifies a function that will be used to decode a cookie's value. Since the value of a cookie\nhas a limited character set (and must be a simple string), this function can be used to decode\na previously-encoded cookie value into a JavaScript string or other object.\n\nThe default function is the global `decodeURIComponent`, which will decode any URL-encoded\nsequences into their byte representations.\n\n**note** if an error is thrown from this function, the original, non-decoded cookie value will\nbe returned as the cookie's value.\n\n### cookie.serialize(name, value, options)\n\nSerialize a cookie name-value pair into a `Set-Cookie` header string. The `name` argument is the\nname for the cookie, the `value` argument is the value to set the cookie to, and the `options`\nargument is an optional object containing additional serialization options.\n\n```js\nvar setCookie = cookie.serialize('foo', 'bar');\n// foo=bar\n```\n\n#### Options\n\n`cookie.serialize` accepts these properties in the options object.\n\n##### domain\n\nSpecifies the value for the [`Domain` `Set-Cookie` attribute][rfc-6265-5.2.3]. By default, no\ndomain is set, and most clients will consider the cookie to apply to only the current domain.\n\n##### encode\n\nSpecifies a function that will be used to encode a cookie's value. Since value of a cookie\nhas a limited character set (and must be a simple string), this function can be used to encode\na value into a string suited for a cookie's value.\n\nThe default function is the global `encodeURIComponent`, which will encode a JavaScript string\ninto UTF-8 byte sequences and then URL-encode any that fall outside of the cookie range.\n\n##### expires\n\nSpecifies the `Date` object to be the value for the [`Expires` `Set-Cookie` attribute][rfc-6265-5.2.1].\nBy default, no expiration is set, and most clients will consider this a \"non-persistent cookie\" and\nwill delete it on a condition like exiting a web browser application.\n\n**note** the [cookie storage model specification][rfc-6265-5.3] states that if both `expires` and\n`maxAge` are set, then `maxAge` takes precedence, but it is possible not all clients by obey this,\nso if both are set, they should point to the same date and time.\n\n##### httpOnly\n\nSpecifies the `boolean` value for the [`HttpOnly` `Set-Cookie` attribute][rfc-6265-5.2.6]. When truthy,\nthe `HttpOnly` attribute is set, otherwise it is not. By default, the `HttpOnly` attribute is not set.\n\n**note** be careful when setting this to `true`, as compliant clients will not allow client-side\nJavaScript to see the cookie in `document.cookie`.\n\n##### maxAge\n\nSpecifies the `number` (in seconds) to be the value for the [`Max-Age` `Set-Cookie` attribute][rfc-6265-5.2.2].\nThe given number will be converted to an integer by rounding down. By default, no maximum age is set.\n\n**note** the [cookie storage model specification][rfc-6265-5.3] states that if both `expires` and\n`maxAge` are set, then `maxAge` takes precedence, but it is possible not all clients by obey this,\nso if both are set, they should point to the same date and time.\n\n##### partitioned\n\nSpecifies the `boolean` value for the [`Partitioned` `Set-Cookie`](rfc-cutler-httpbis-partitioned-cookies)\nattribute. When truthy, the `Partitioned` attribute is set, otherwise it is not. By default, the\n`Partitioned` attribute is not set.\n\n**note** This is an attribute that has not yet been fully standardized, and may change in the future.\nThis also means many clients may ignore this attribute until they understand it.\n\nMore information about can be found in [the proposal](https://github.com/privacycg/CHIPS).\n\n##### path\n\nSpecifies the value for the [`Path` `Set-Cookie` attribute][rfc-6265-5.2.4]. By default, the path\nis considered the [\"default path\"][rfc-6265-5.1.4].\n\n##### priority\n\nSpecifies the `string` to be the value for the [`Priority` `Set-Cookie` attribute][rfc-west-cookie-priority-00-4.1].\n\n  - `'low'` will set the `Priority` attribute to `Low`.\n  - `'medium'` will set the `Priority` attribute to `Medium`, the default priority when not set.\n  - `'high'` will set the `Priority` attribute to `High`.\n\nMore information about the different priority levels can be found in\n[the specification][rfc-west-cookie-priority-00-4.1].\n\n**note** This is an attribute that has not yet been fully standardized, and may change in the future.\nThis also means many clients may ignore this attribute until they understand it.\n\n##### sameSite\n\nSpecifies the `boolean` or `string` to be the value for the [`SameSite` `Set-Cookie` attribute][rfc-6265bis-09-5.4.7].\n\n  - `true` will set the `SameSite` attribute to `Strict` for strict same site enforcement.\n  - `false` will not set the `SameSite` attribute.\n  - `'lax'` will set the `SameSite` attribute to `Lax` for lax same site enforcement.\n  - `'none'` will set the `SameSite` attribute to `None` for an explicit cross-site cookie.\n  - `'strict'` will set the `SameSite` attribute to `Strict` for strict same site enforcement.\n\nMore information about the different enforcement levels can be found in\n[the specification][rfc-6265bis-09-5.4.7].\n\n**note** This is an attribute that has not yet been fully standardized, and may change in the future.\nThis also means many clients may ignore this attribute until they understand it.\n\n##### secure\n\nSpecifies the `boolean` value for the [`Secure` `Set-Cookie` attribute][rfc-6265-5.2.5]. When truthy,\nthe `Secure` attribute is set, otherwise it is not. By default, the `Secure` attribute is not set.\n\n**note** be careful when setting this to `true`, as compliant clients will not send the cookie back to\nthe server in the future if the browser does not have an HTTPS connection.\n\n## Example\n\nThe following example uses this module in conjunction with the Node.js core HTTP server\nto prompt a user for their name and display it back on future visits.\n\n```js\nvar cookie = require('cookie');\nvar escapeHtml = require('escape-html');\nvar http = require('http');\nvar url = require('url');\n\nfunction onRequest(req, res) {\n  // Parse the query string\n  var query = url.parse(req.url, true, true).query;\n\n  if (query && query.name) {\n    // Set a new cookie with the name\n    res.setHeader('Set-Cookie', cookie.serialize('name', String(query.name), {\n      httpOnly: true,\n      maxAge: 60 * 60 * 24 * 7 // 1 week\n    }));\n\n    // Redirect back after setting cookie\n    res.statusCode = 302;\n    res.setHeader('Location', req.headers.referer || '/');\n    res.end();\n    return;\n  }\n\n  // Parse the cookies on the request\n  var cookies = cookie.parse(req.headers.cookie || '');\n\n  // Get the visitor name set in the cookie\n  var name = cookies.name;\n\n  res.setHeader('Content-Type', 'text/html; charset=UTF-8');\n\n  if (name) {\n    res.write('<p>Welcome back, <b>' + escapeHtml(name) + '</b>!</p>');\n  } else {\n    res.write('<p>Hello, new visitor!</p>');\n  }\n\n  res.write('<form method=\"GET\">');\n  res.write('<input placeholder=\"enter your name\" name=\"name\"> <input type=\"submit\" value=\"Set Name\">');\n  res.end('</form>');\n}\n\nhttp.createServer(onRequest).listen(3000);\n```\n\n## Testing\n\n```sh\n$ npm test\n```\n\n## Benchmark\n\n```\n$ npm run bench\n\n> cookie@0.5.0 bench\n> node benchmark/index.js\n\n  node@18.18.2\n  acorn@8.10.0\n  ada@2.6.0\n  ares@1.19.1\n  brotli@1.0.9\n  cldr@43.1\n  icu@73.2\n  llhttp@6.0.11\n  modules@108\n  napi@9\n  nghttp2@1.57.0\n  nghttp3@0.7.0\n  ngtcp2@0.8.1\n  openssl@3.0.10+quic\n  simdutf@3.2.14\n  tz@2023c\n  undici@5.26.3\n  unicode@15.0\n  uv@1.44.2\n  uvwasi@0.0.18\n  v8@10.2.154.26-node.26\n  zlib@1.2.13.1-motley\n\n> node benchmark/parse-top.js\n\n  cookie.parse - top sites\n\n  14 tests completed.\n\n  parse accounts.google.com x 2,588,913 ops/sec ±0.74% (186 runs sampled)\n  parse apple.com           x 2,370,002 ops/sec ±0.69% (186 runs sampled)\n  parse cloudflare.com      x 2,213,102 ops/sec ±0.88% (188 runs sampled)\n  parse docs.google.com     x 2,194,157 ops/sec ±1.03% (184 runs sampled)\n  parse drive.google.com    x 2,265,084 ops/sec ±0.79% (187 runs sampled)\n  parse en.wikipedia.org    x   457,099 ops/sec ±0.81% (186 runs sampled)\n  parse linkedin.com        x   504,407 ops/sec ±0.89% (186 runs sampled)\n  parse maps.google.com     x 1,230,959 ops/sec ±0.98% (186 runs sampled)\n  parse microsoft.com       x   926,294 ops/sec ±0.88% (184 runs sampled)\n  parse play.google.com     x 2,311,338 ops/sec ±0.83% (185 runs sampled)\n  parse support.google.com  x 1,508,850 ops/sec ±0.86% (186 runs sampled)\n  parse www.google.com      x 1,022,582 ops/sec ±1.32% (182 runs sampled)\n  parse youtu.be            x   332,136 ops/sec ±1.02% (185 runs sampled)\n  parse youtube.com         x   323,833 ops/sec ±0.77% (183 runs sampled)\n\n> node benchmark/parse.js\n\n  cookie.parse - generic\n\n  6 tests completed.\n\n  simple      x 3,214,032 ops/sec ±1.61% (183 runs sampled)\n  decode      x   587,237 ops/sec ±1.16% (187 runs sampled)\n  unquote     x 2,954,618 ops/sec ±1.35% (183 runs sampled)\n  duplicates  x   857,008 ops/sec ±0.89% (187 runs sampled)\n  10 cookies  x   292,133 ops/sec ±0.89% (187 runs sampled)\n  100 cookies x    22,610 ops/sec ±0.68% (187 runs sampled)\n```\n\n## References\n\n- [RFC 6265: HTTP State Management Mechanism][rfc-6265]\n- [Same-site Cookies][rfc-6265bis-09-5.4.7]\n\n[rfc-cutler-httpbis-partitioned-cookies]: https://tools.ietf.org/html/draft-cutler-httpbis-partitioned-cookies/\n[rfc-west-cookie-priority-00-4.1]: https://tools.ietf.org/html/draft-west-cookie-priority-00#section-4.1\n[rfc-6265bis-09-5.4.7]: https://tools.ietf.org/html/draft-ietf-httpbis-rfc6265bis-09#section-5.4.7\n[rfc-6265]: https://tools.ietf.org/html/rfc6265\n[rfc-6265-5.1.4]: https://tools.ietf.org/html/rfc6265#section-5.1.4\n[rfc-6265-5.2.1]: https://tools.ietf.org/html/rfc6265#section-5.2.1\n[rfc-6265-5.2.2]: https://tools.ietf.org/html/rfc6265#section-5.2.2\n[rfc-6265-5.2.3]: https://tools.ietf.org/html/rfc6265#section-5.2.3\n[rfc-6265-5.2.4]: https://tools.ietf.org/html/rfc6265#section-5.2.4\n[rfc-6265-5.2.5]: https://tools.ietf.org/html/rfc6265#section-5.2.5\n[rfc-6265-5.2.6]: https://tools.ietf.org/html/rfc6265#section-5.2.6\n[rfc-6265-5.3]: https://tools.ietf.org/html/rfc6265#section-5.3\n\n## License\n\n[MIT](LICENSE)\n\n[ci-image]: https://badgen.net/github/checks/jshttp/cookie/master?label=ci\n[ci-url]: https://github.com/jshttp/cookie/actions/workflows/ci.yml\n[coveralls-image]: https://badgen.net/coveralls/c/github/jshttp/cookie/master\n[coveralls-url]: https://coveralls.io/r/jshttp/cookie?branch=master\n[node-image]: https://badgen.net/npm/node/cookie\n[node-url]: https://nodejs.org/en/download\n[npm-downloads-image]: https://badgen.net/npm/dm/cookie\n[npm-url]: https://npmjs.org/package/cookie\n[npm-version-image]: https://badgen.net/npm/v/cookie\n",
        "plugins/auto-review/mcp/node_modules/cors/README.md": "# cors\n\n[![NPM Version][npm-image]][npm-url]\n[![NPM Downloads][downloads-image]][downloads-url]\n[![Build Status][travis-image]][travis-url]\n[![Test Coverage][coveralls-image]][coveralls-url]\n\nCORS is a node.js package for providing a [Connect](http://www.senchalabs.org/connect/)/[Express](http://expressjs.com/) middleware that can be used to enable [CORS](http://en.wikipedia.org/wiki/Cross-origin_resource_sharing) with various options.\n\n**[Follow me (@troygoode) on Twitter!](https://twitter.com/intent/user?screen_name=troygoode)**\n\n* [Installation](#installation)\n* [Usage](#usage)\n  * [Simple Usage](#simple-usage-enable-all-cors-requests)\n  * [Enable CORS for a Single Route](#enable-cors-for-a-single-route)\n  * [Configuring CORS](#configuring-cors)\n  * [Configuring CORS Asynchronously](#configuring-cors-asynchronously)\n  * [Enabling CORS Pre-Flight](#enabling-cors-pre-flight)\n* [Configuration Options](#configuration-options)\n* [Demo](#demo)\n* [License](#license)\n* [Author](#author)\n\n## Installation\n\nThis is a [Node.js](https://nodejs.org/en/) module available through the\n[npm registry](https://www.npmjs.com/). Installation is done using the\n[`npm install` command](https://docs.npmjs.com/getting-started/installing-npm-packages-locally):\n\n```sh\n$ npm install cors\n```\n\n## Usage\n\n### Simple Usage (Enable *All* CORS Requests)\n\n```javascript\nvar express = require('express')\nvar cors = require('cors')\nvar app = express()\n\napp.use(cors())\n\napp.get('/products/:id', function (req, res, next) {\n  res.json({msg: 'This is CORS-enabled for all origins!'})\n})\n\napp.listen(80, function () {\n  console.log('CORS-enabled web server listening on port 80')\n})\n```\n\n### Enable CORS for a Single Route\n\n```javascript\nvar express = require('express')\nvar cors = require('cors')\nvar app = express()\n\napp.get('/products/:id', cors(), function (req, res, next) {\n  res.json({msg: 'This is CORS-enabled for a Single Route'})\n})\n\napp.listen(80, function () {\n  console.log('CORS-enabled web server listening on port 80')\n})\n```\n\n### Configuring CORS\n\n```javascript\nvar express = require('express')\nvar cors = require('cors')\nvar app = express()\n\nvar corsOptions = {\n  origin: 'http://example.com',\n  optionsSuccessStatus: 200 // some legacy browsers (IE11, various SmartTVs) choke on 204\n}\n\napp.get('/products/:id', cors(corsOptions), function (req, res, next) {\n  res.json({msg: 'This is CORS-enabled for only example.com.'})\n})\n\napp.listen(80, function () {\n  console.log('CORS-enabled web server listening on port 80')\n})\n```\n\n### Configuring CORS w/ Dynamic Origin\n\n```javascript\nvar express = require('express')\nvar cors = require('cors')\nvar app = express()\n\nvar whitelist = ['http://example1.com', 'http://example2.com']\nvar corsOptions = {\n  origin: function (origin, callback) {\n    if (whitelist.indexOf(origin) !== -1) {\n      callback(null, true)\n    } else {\n      callback(new Error('Not allowed by CORS'))\n    }\n  }\n}\n\napp.get('/products/:id', cors(corsOptions), function (req, res, next) {\n  res.json({msg: 'This is CORS-enabled for a whitelisted domain.'})\n})\n\napp.listen(80, function () {\n  console.log('CORS-enabled web server listening on port 80')\n})\n```\n\nIf you do not want to block REST tools or server-to-server requests,\nadd a `!origin` check in the origin function like so:\n\n```javascript\nvar corsOptions = {\n  origin: function (origin, callback) {\n    if (whitelist.indexOf(origin) !== -1 || !origin) {\n      callback(null, true)\n    } else {\n      callback(new Error('Not allowed by CORS'))\n    }\n  }\n}\n```\n\n### Enabling CORS Pre-Flight\n\nCertain CORS requests are considered 'complex' and require an initial\n`OPTIONS` request (called the \"pre-flight request\"). An example of a\n'complex' CORS request is one that uses an HTTP verb other than\nGET/HEAD/POST (such as DELETE) or that uses custom headers. To enable\npre-flighting, you must add a new OPTIONS handler for the route you want\nto support:\n\n```javascript\nvar express = require('express')\nvar cors = require('cors')\nvar app = express()\n\napp.options('/products/:id', cors()) // enable pre-flight request for DELETE request\napp.del('/products/:id', cors(), function (req, res, next) {\n  res.json({msg: 'This is CORS-enabled for all origins!'})\n})\n\napp.listen(80, function () {\n  console.log('CORS-enabled web server listening on port 80')\n})\n```\n\nYou can also enable pre-flight across-the-board like so:\n\n```javascript\napp.options('*', cors()) // include before other routes\n```\n\n### Configuring CORS Asynchronously\n\n```javascript\nvar express = require('express')\nvar cors = require('cors')\nvar app = express()\n\nvar whitelist = ['http://example1.com', 'http://example2.com']\nvar corsOptionsDelegate = function (req, callback) {\n  var corsOptions;\n  if (whitelist.indexOf(req.header('Origin')) !== -1) {\n    corsOptions = { origin: true } // reflect (enable) the requested origin in the CORS response\n  } else {\n    corsOptions = { origin: false } // disable CORS for this request\n  }\n  callback(null, corsOptions) // callback expects two parameters: error and options\n}\n\napp.get('/products/:id', cors(corsOptionsDelegate), function (req, res, next) {\n  res.json({msg: 'This is CORS-enabled for a whitelisted domain.'})\n})\n\napp.listen(80, function () {\n  console.log('CORS-enabled web server listening on port 80')\n})\n```\n\n## Configuration Options\n\n* `origin`: Configures the **Access-Control-Allow-Origin** CORS header. Possible values:\n  - `Boolean` - set `origin` to `true` to reflect the [request origin](http://tools.ietf.org/html/draft-abarth-origin-09), as defined by `req.header('Origin')`, or set it to `false` to disable CORS.\n  - `String` - set `origin` to a specific origin. For example if you set it to `\"http://example.com\"` only requests from \"http://example.com\" will be allowed.\n  - `RegExp` - set `origin` to a regular expression pattern which will be used to test the request origin. If it's a match, the request origin will be reflected. For example the pattern `/example\\.com$/` will reflect any request that is coming from an origin ending with \"example.com\".\n  - `Array` - set `origin` to an array of valid origins. Each origin can be a `String` or a `RegExp`. For example `[\"http://example1.com\", /\\.example2\\.com$/]` will accept any request from \"http://example1.com\" or from a subdomain of \"example2.com\".\n  - `Function` - set `origin` to a function implementing some custom logic. The function takes the request origin as the first parameter and a callback (which expects the signature `err [object], allow [bool]`) as the second.\n* `methods`: Configures the **Access-Control-Allow-Methods** CORS header. Expects a comma-delimited string (ex: 'GET,PUT,POST') or an array (ex: `['GET', 'PUT', 'POST']`).\n* `allowedHeaders`: Configures the **Access-Control-Allow-Headers** CORS header. Expects a comma-delimited string (ex: 'Content-Type,Authorization') or an array (ex: `['Content-Type', 'Authorization']`). If not specified, defaults to reflecting the headers specified in the request's **Access-Control-Request-Headers** header.\n* `exposedHeaders`: Configures the **Access-Control-Expose-Headers** CORS header. Expects a comma-delimited string (ex: 'Content-Range,X-Content-Range') or an array (ex: `['Content-Range', 'X-Content-Range']`). If not specified, no custom headers are exposed.\n* `credentials`: Configures the **Access-Control-Allow-Credentials** CORS header. Set to `true` to pass the header, otherwise it is omitted.\n* `maxAge`: Configures the **Access-Control-Max-Age** CORS header. Set to an integer to pass the header, otherwise it is omitted.\n* `preflightContinue`: Pass the CORS preflight response to the next handler.\n* `optionsSuccessStatus`: Provides a status code to use for successful `OPTIONS` requests, since some legacy browsers (IE11, various SmartTVs) choke on `204`.\n\nThe default configuration is the equivalent of:\n\n```json\n{\n  \"origin\": \"*\",\n  \"methods\": \"GET,HEAD,PUT,PATCH,POST,DELETE\",\n  \"preflightContinue\": false,\n  \"optionsSuccessStatus\": 204\n}\n```\n\nFor details on the effect of each CORS header, read [this](http://www.html5rocks.com/en/tutorials/cors/) article on HTML5 Rocks.\n\n## Demo\n\nA demo that illustrates CORS working (and not working) using jQuery is available here: [http://node-cors-client.herokuapp.com/](http://node-cors-client.herokuapp.com/)\n\nCode for that demo can be found here:\n\n* Client: [https://github.com/TroyGoode/node-cors-client](https://github.com/TroyGoode/node-cors-client)\n* Server: [https://github.com/TroyGoode/node-cors-server](https://github.com/TroyGoode/node-cors-server)\n\n## License\n\n[MIT License](http://www.opensource.org/licenses/mit-license.php)\n\n## Author\n\n[Troy Goode](https://github.com/TroyGoode) ([troygoode@gmail.com](mailto:troygoode@gmail.com))\n\n[coveralls-image]: https://img.shields.io/coveralls/expressjs/cors/master.svg\n[coveralls-url]: https://coveralls.io/r/expressjs/cors?branch=master\n[downloads-image]: https://img.shields.io/npm/dm/cors.svg\n[downloads-url]: https://npmjs.org/package/cors\n[npm-image]: https://img.shields.io/npm/v/cors.svg\n[npm-url]: https://npmjs.org/package/cors\n[travis-image]: https://img.shields.io/travis/expressjs/cors/master.svg\n[travis-url]: https://travis-ci.org/expressjs/cors\n",
        "plugins/auto-review/mcp/node_modules/cross-spawn/README.md": "# cross-spawn\n\n[![NPM version][npm-image]][npm-url] [![Downloads][downloads-image]][npm-url] [![Build Status][ci-image]][ci-url] [![Build status][appveyor-image]][appveyor-url]\n\n[npm-url]:https://npmjs.org/package/cross-spawn\n[downloads-image]:https://img.shields.io/npm/dm/cross-spawn.svg\n[npm-image]:https://img.shields.io/npm/v/cross-spawn.svg\n[ci-url]:https://github.com/moxystudio/node-cross-spawn/actions/workflows/ci.yaml\n[ci-image]:https://github.com/moxystudio/node-cross-spawn/actions/workflows/ci.yaml/badge.svg\n[appveyor-url]:https://ci.appveyor.com/project/satazor/node-cross-spawn\n[appveyor-image]:https://img.shields.io/appveyor/ci/satazor/node-cross-spawn/master.svg\n\nA cross platform solution to node's spawn and spawnSync.\n\n## Installation\n\nNode.js version 8 and up:\n`$ npm install cross-spawn`\n\nNode.js version 7 and under:\n`$ npm install cross-spawn@6`\n\n## Why\n\nNode has issues when using spawn on Windows:\n\n- It ignores [PATHEXT](https://github.com/joyent/node/issues/2318)\n- It does not support [shebangs](https://en.wikipedia.org/wiki/Shebang_(Unix))\n- Has problems running commands with [spaces](https://github.com/nodejs/node/issues/7367)\n- Has problems running commands with posix relative paths (e.g.: `./my-folder/my-executable`)\n- Has an [issue](https://github.com/moxystudio/node-cross-spawn/issues/82) with command shims (files in `node_modules/.bin/`), where arguments with quotes and parenthesis would result in [invalid syntax error](https://github.com/moxystudio/node-cross-spawn/blob/e77b8f22a416db46b6196767bcd35601d7e11d54/test/index.test.js#L149)\n- No `options.shell` support on node `<v4.8`\n\nAll these issues are handled correctly by `cross-spawn`.\nThere are some known modules, such as [win-spawn](https://github.com/ForbesLindesay/win-spawn), that try to solve this but they are either broken or provide faulty escaping of shell arguments.\n\n\n## Usage\n\nExactly the same way as node's [`spawn`](https://nodejs.org/api/child_process.html#child_process_child_process_spawn_command_args_options) or [`spawnSync`](https://nodejs.org/api/child_process.html#child_process_child_process_spawnsync_command_args_options), so it's a drop in replacement.\n\n\n```js\nconst spawn = require('cross-spawn');\n\n// Spawn NPM asynchronously\nconst child = spawn('npm', ['list', '-g', '-depth', '0'], { stdio: 'inherit' });\n\n// Spawn NPM synchronously\nconst result = spawn.sync('npm', ['list', '-g', '-depth', '0'], { stdio: 'inherit' });\n```\n\n\n## Caveats\n\n### Using `options.shell` as an alternative to `cross-spawn`\n\nStarting from node `v4.8`, `spawn` has a `shell` option that allows you run commands from within a shell. This new option solves\nthe [PATHEXT](https://github.com/joyent/node/issues/2318) issue but:\n\n- It's not supported in node `<v4.8`\n- You must manually escape the command and arguments which is very error prone, specially when passing user input\n- There are a lot of other unresolved issues from the [Why](#why) section that you must take into account\n\nIf you are using the `shell` option to spawn a command in a cross platform way, consider using `cross-spawn` instead. You have been warned.\n\n### `options.shell` support\n\nWhile `cross-spawn` adds support for `options.shell` in node `<v4.8`, all of its enhancements are disabled.\n\nThis mimics the Node.js behavior. More specifically, the command and its arguments will not be automatically escaped nor shebang support will be offered. This is by design because if you are using `options.shell` you are probably targeting a specific platform anyway and you don't want things to get into your way.\n\n### Shebangs support\n\nWhile `cross-spawn` handles shebangs on Windows, its support is limited. More specifically, it just supports `#!/usr/bin/env <program>` where `<program>` must not contain any arguments.   \nIf you would like to have the shebang support improved, feel free to contribute via a pull-request.\n\nRemember to always test your code on Windows!\n\n\n## Tests\n\n`$ npm test`   \n`$ npm test -- --watch` during development\n\n\n## License\n\nReleased under the [MIT License](https://www.opensource.org/licenses/mit-license.php).\n",
        "plugins/auto-review/mcp/node_modules/debug/README.md": "# debug\n[![OpenCollective](https://opencollective.com/debug/backers/badge.svg)](#backers)\n[![OpenCollective](https://opencollective.com/debug/sponsors/badge.svg)](#sponsors)\n\n<img width=\"647\" src=\"https://user-images.githubusercontent.com/71256/29091486-fa38524c-7c37-11e7-895f-e7ec8e1039b6.png\">\n\nA tiny JavaScript debugging utility modelled after Node.js core's debugging\ntechnique. Works in Node.js and web browsers.\n\n## Installation\n\n```bash\n$ npm install debug\n```\n\n## Usage\n\n`debug` exposes a function; simply pass this function the name of your module, and it will return a decorated version of `console.error` for you to pass debug statements to. This will allow you to toggle the debug output for different parts of your module as well as the module as a whole.\n\nExample [_app.js_](./examples/node/app.js):\n\n```js\nvar debug = require('debug')('http')\n  , http = require('http')\n  , name = 'My App';\n\n// fake app\n\ndebug('booting %o', name);\n\nhttp.createServer(function(req, res){\n  debug(req.method + ' ' + req.url);\n  res.end('hello\\n');\n}).listen(3000, function(){\n  debug('listening');\n});\n\n// fake worker of some kind\n\nrequire('./worker');\n```\n\nExample [_worker.js_](./examples/node/worker.js):\n\n```js\nvar a = require('debug')('worker:a')\n  , b = require('debug')('worker:b');\n\nfunction work() {\n  a('doing lots of uninteresting work');\n  setTimeout(work, Math.random() * 1000);\n}\n\nwork();\n\nfunction workb() {\n  b('doing some work');\n  setTimeout(workb, Math.random() * 2000);\n}\n\nworkb();\n```\n\nThe `DEBUG` environment variable is then used to enable these based on space or\ncomma-delimited names.\n\nHere are some examples:\n\n<img width=\"647\" alt=\"screen shot 2017-08-08 at 12 53 04 pm\" src=\"https://user-images.githubusercontent.com/71256/29091703-a6302cdc-7c38-11e7-8304-7c0b3bc600cd.png\">\n<img width=\"647\" alt=\"screen shot 2017-08-08 at 12 53 38 pm\" src=\"https://user-images.githubusercontent.com/71256/29091700-a62a6888-7c38-11e7-800b-db911291ca2b.png\">\n<img width=\"647\" alt=\"screen shot 2017-08-08 at 12 53 25 pm\" src=\"https://user-images.githubusercontent.com/71256/29091701-a62ea114-7c38-11e7-826a-2692bedca740.png\">\n\n#### Windows command prompt notes\n\n##### CMD\n\nOn Windows the environment variable is set using the `set` command.\n\n```cmd\nset DEBUG=*,-not_this\n```\n\nExample:\n\n```cmd\nset DEBUG=* & node app.js\n```\n\n##### PowerShell (VS Code default)\n\nPowerShell uses different syntax to set environment variables.\n\n```cmd\n$env:DEBUG = \"*,-not_this\"\n```\n\nExample:\n\n```cmd\n$env:DEBUG='app';node app.js\n```\n\nThen, run the program to be debugged as usual.\n\nnpm script example:\n```js\n  \"windowsDebug\": \"@powershell -Command $env:DEBUG='*';node app.js\",\n```\n\n## Namespace Colors\n\nEvery debug instance has a color generated for it based on its namespace name.\nThis helps when visually parsing the debug output to identify which debug instance\na debug line belongs to.\n\n#### Node.js\n\nIn Node.js, colors are enabled when stderr is a TTY. You also _should_ install\nthe [`supports-color`](https://npmjs.org/supports-color) module alongside debug,\notherwise debug will only use a small handful of basic colors.\n\n<img width=\"521\" src=\"https://user-images.githubusercontent.com/71256/29092181-47f6a9e6-7c3a-11e7-9a14-1928d8a711cd.png\">\n\n#### Web Browser\n\nColors are also enabled on \"Web Inspectors\" that understand the `%c` formatting\noption. These are WebKit web inspectors, Firefox ([since version\n31](https://hacks.mozilla.org/2014/05/editable-box-model-multiple-selection-sublime-text-keys-much-more-firefox-developer-tools-episode-31/))\nand the Firebug plugin for Firefox (any version).\n\n<img width=\"524\" src=\"https://user-images.githubusercontent.com/71256/29092033-b65f9f2e-7c39-11e7-8e32-f6f0d8e865c1.png\">\n\n\n## Millisecond diff\n\nWhen actively developing an application it can be useful to see when the time spent between one `debug()` call and the next. Suppose for example you invoke `debug()` before requesting a resource, and after as well, the \"+NNNms\" will show you how much time was spent between calls.\n\n<img width=\"647\" src=\"https://user-images.githubusercontent.com/71256/29091486-fa38524c-7c37-11e7-895f-e7ec8e1039b6.png\">\n\nWhen stdout is not a TTY, `Date#toISOString()` is used, making it more useful for logging the debug information as shown below:\n\n<img width=\"647\" src=\"https://user-images.githubusercontent.com/71256/29091956-6bd78372-7c39-11e7-8c55-c948396d6edd.png\">\n\n\n## Conventions\n\nIf you're using this in one or more of your libraries, you _should_ use the name of your library so that developers may toggle debugging as desired without guessing names. If you have more than one debuggers you _should_ prefix them with your library name and use \":\" to separate features. For example \"bodyParser\" from Connect would then be \"connect:bodyParser\".  If you append a \"*\" to the end of your name, it will always be enabled regardless of the setting of the DEBUG environment variable.  You can then use it for normal output as well as debug output.\n\n## Wildcards\n\nThe `*` character may be used as a wildcard. Suppose for example your library has\ndebuggers named \"connect:bodyParser\", \"connect:compress\", \"connect:session\",\ninstead of listing all three with\n`DEBUG=connect:bodyParser,connect:compress,connect:session`, you may simply do\n`DEBUG=connect:*`, or to run everything using this module simply use `DEBUG=*`.\n\nYou can also exclude specific debuggers by prefixing them with a \"-\" character.\nFor example, `DEBUG=*,-connect:*` would include all debuggers except those\nstarting with \"connect:\".\n\n## Environment Variables\n\nWhen running through Node.js, you can set a few environment variables that will\nchange the behavior of the debug logging:\n\n| Name      | Purpose                                         |\n|-----------|-------------------------------------------------|\n| `DEBUG`   | Enables/disables specific debugging namespaces. |\n| `DEBUG_HIDE_DATE` | Hide date from debug output (non-TTY).  |\n| `DEBUG_COLORS`| Whether or not to use colors in the debug output. |\n| `DEBUG_DEPTH` | Object inspection depth.                    |\n| `DEBUG_SHOW_HIDDEN` | Shows hidden properties on inspected objects. |\n\n\n__Note:__ The environment variables beginning with `DEBUG_` end up being\nconverted into an Options object that gets used with `%o`/`%O` formatters.\nSee the Node.js documentation for\n[`util.inspect()`](https://nodejs.org/api/util.html#util_util_inspect_object_options)\nfor the complete list.\n\n## Formatters\n\nDebug uses [printf-style](https://wikipedia.org/wiki/Printf_format_string) formatting.\nBelow are the officially supported formatters:\n\n| Formatter | Representation |\n|-----------|----------------|\n| `%O`      | Pretty-print an Object on multiple lines. |\n| `%o`      | Pretty-print an Object all on a single line. |\n| `%s`      | String. |\n| `%d`      | Number (both integer and float). |\n| `%j`      | JSON. Replaced with the string '[Circular]' if the argument contains circular references. |\n| `%%`      | Single percent sign ('%'). This does not consume an argument. |\n\n\n### Custom formatters\n\nYou can add custom formatters by extending the `debug.formatters` object.\nFor example, if you wanted to add support for rendering a Buffer as hex with\n`%h`, you could do something like:\n\n```js\nconst createDebug = require('debug')\ncreateDebug.formatters.h = (v) => {\n  return v.toString('hex')\n}\n\n// …elsewhere\nconst debug = createDebug('foo')\ndebug('this is hex: %h', new Buffer('hello world'))\n//   foo this is hex: 68656c6c6f20776f726c6421 +0ms\n```\n\n\n## Browser Support\n\nYou can build a browser-ready script using [browserify](https://github.com/substack/node-browserify),\nor just use the [browserify-as-a-service](https://wzrd.in/) [build](https://wzrd.in/standalone/debug@latest),\nif you don't want to build it yourself.\n\nDebug's enable state is currently persisted by `localStorage`.\nConsider the situation shown below where you have `worker:a` and `worker:b`,\nand wish to debug both. You can enable this using `localStorage.debug`:\n\n```js\nlocalStorage.debug = 'worker:*'\n```\n\nAnd then refresh the page.\n\n```js\na = debug('worker:a');\nb = debug('worker:b');\n\nsetInterval(function(){\n  a('doing some work');\n}, 1000);\n\nsetInterval(function(){\n  b('doing some work');\n}, 1200);\n```\n\nIn Chromium-based web browsers (e.g. Brave, Chrome, and Electron), the JavaScript console will—by default—only show messages logged by `debug` if the \"Verbose\" log level is _enabled_.\n\n<img width=\"647\" src=\"https://user-images.githubusercontent.com/7143133/152083257-29034707-c42c-4959-8add-3cee850e6fcf.png\">\n\n## Output streams\n\n  By default `debug` will log to stderr, however this can be configured per-namespace by overriding the `log` method:\n\nExample [_stdout.js_](./examples/node/stdout.js):\n\n```js\nvar debug = require('debug');\nvar error = debug('app:error');\n\n// by default stderr is used\nerror('goes to stderr!');\n\nvar log = debug('app:log');\n// set this namespace to log via console.log\nlog.log = console.log.bind(console); // don't forget to bind to console!\nlog('goes to stdout');\nerror('still goes to stderr!');\n\n// set all output to go via console.info\n// overrides all per-namespace log settings\ndebug.log = console.info.bind(console);\nerror('now goes to stdout via console.info');\nlog('still goes to stdout, but via console.info now');\n```\n\n## Extend\nYou can simply extend debugger \n```js\nconst log = require('debug')('auth');\n\n//creates new debug instance with extended namespace\nconst logSign = log.extend('sign');\nconst logLogin = log.extend('login');\n\nlog('hello'); // auth hello\nlogSign('hello'); //auth:sign hello\nlogLogin('hello'); //auth:login hello\n```\n\n## Set dynamically\n\nYou can also enable debug dynamically by calling the `enable()` method :\n\n```js\nlet debug = require('debug');\n\nconsole.log(1, debug.enabled('test'));\n\ndebug.enable('test');\nconsole.log(2, debug.enabled('test'));\n\ndebug.disable();\nconsole.log(3, debug.enabled('test'));\n\n```\n\nprint :   \n```\n1 false\n2 true\n3 false\n```\n\nUsage :  \n`enable(namespaces)`  \n`namespaces` can include modes separated by a colon and wildcards.\n   \nNote that calling `enable()` completely overrides previously set DEBUG variable : \n\n```\n$ DEBUG=foo node -e 'var dbg = require(\"debug\"); dbg.enable(\"bar\"); console.log(dbg.enabled(\"foo\"))'\n=> false\n```\n\n`disable()`\n\nWill disable all namespaces. The functions returns the namespaces currently\nenabled (and skipped). This can be useful if you want to disable debugging\ntemporarily without knowing what was enabled to begin with.\n\nFor example:\n\n```js\nlet debug = require('debug');\ndebug.enable('foo:*,-foo:bar');\nlet namespaces = debug.disable();\ndebug.enable(namespaces);\n```\n\nNote: There is no guarantee that the string will be identical to the initial\nenable string, but semantically they will be identical.\n\n## Checking whether a debug target is enabled\n\nAfter you've created a debug instance, you can determine whether or not it is\nenabled by checking the `enabled` property:\n\n```javascript\nconst debug = require('debug')('http');\n\nif (debug.enabled) {\n  // do stuff...\n}\n```\n\nYou can also manually toggle this property to force the debug instance to be\nenabled or disabled.\n\n## Usage in child processes\n\nDue to the way `debug` detects if the output is a TTY or not, colors are not shown in child processes when `stderr` is piped. A solution is to pass the `DEBUG_COLORS=1` environment variable to the child process.  \nFor example:\n\n```javascript\nworker = fork(WORKER_WRAP_PATH, [workerPath], {\n  stdio: [\n    /* stdin: */ 0,\n    /* stdout: */ 'pipe',\n    /* stderr: */ 'pipe',\n    'ipc',\n  ],\n  env: Object.assign({}, process.env, {\n    DEBUG_COLORS: 1 // without this settings, colors won't be shown\n  }),\n});\n\nworker.stderr.pipe(process.stderr, { end: false });\n```\n\n\n## Authors\n\n - TJ Holowaychuk\n - Nathan Rajlich\n - Andrew Rhyne\n - Josh Junon\n\n## Backers\n\nSupport us with a monthly donation and help us continue our activities. [[Become a backer](https://opencollective.com/debug#backer)]\n\n<a href=\"https://opencollective.com/debug/backer/0/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/0/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/1/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/1/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/2/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/2/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/3/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/3/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/4/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/4/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/5/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/5/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/6/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/6/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/7/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/7/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/8/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/8/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/9/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/9/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/10/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/10/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/11/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/11/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/12/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/12/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/13/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/13/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/14/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/14/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/15/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/15/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/16/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/16/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/17/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/17/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/18/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/18/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/19/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/19/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/20/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/20/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/21/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/21/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/22/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/22/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/23/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/23/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/24/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/24/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/25/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/25/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/26/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/26/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/27/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/27/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/28/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/28/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/backer/29/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/backer/29/avatar.svg\"></a>\n\n\n## Sponsors\n\nBecome a sponsor and get your logo on our README on Github with a link to your site. [[Become a sponsor](https://opencollective.com/debug#sponsor)]\n\n<a href=\"https://opencollective.com/debug/sponsor/0/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/0/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/1/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/1/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/2/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/2/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/3/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/3/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/4/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/4/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/5/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/5/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/6/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/6/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/7/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/7/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/8/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/8/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/9/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/9/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/10/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/10/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/11/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/11/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/12/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/12/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/13/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/13/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/14/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/14/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/15/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/15/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/16/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/16/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/17/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/17/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/18/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/18/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/19/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/19/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/20/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/20/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/21/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/21/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/22/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/22/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/23/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/23/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/24/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/24/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/25/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/25/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/26/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/26/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/27/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/27/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/28/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/28/avatar.svg\"></a>\n<a href=\"https://opencollective.com/debug/sponsor/29/website\" target=\"_blank\"><img src=\"https://opencollective.com/debug/sponsor/29/avatar.svg\"></a>\n\n## License\n\n(The MIT License)\n\nCopyright (c) 2014-2017 TJ Holowaychuk &lt;tj@vision-media.ca&gt;\nCopyright (c) 2018-2021 Josh Junon\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n'Software'), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\nIN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\nCLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\nTORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\nSOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
        "plugins/auto-review/mcp/node_modules/dunder-proto/README.md": "# dunder-proto <sup>[![Version Badge][npm-version-svg]][package-url]</sup>\n\n[![github actions][actions-image]][actions-url]\n[![coverage][codecov-image]][codecov-url]\n[![License][license-image]][license-url]\n[![Downloads][downloads-image]][downloads-url]\n\n[![npm badge][npm-badge-png]][package-url]\n\nIf available, the `Object.prototype.__proto__` accessor and mutator, call-bound.\n\n## Getting started\n\n```sh\nnpm install --save dunder-proto\n```\n\n## Usage/Examples\n\n```js\nconst assert = require('assert');\nconst getDunder = require('dunder-proto/get');\nconst setDunder = require('dunder-proto/set');\n\nconst obj = {};\n\nassert.equal('toString' in obj, true);\nassert.equal(getDunder(obj), Object.prototype);\n\nsetDunder(obj, null);\n\nassert.equal('toString' in obj, false);\nassert.equal(getDunder(obj), null);\n```\n\n## Tests\n\nClone the repo, `npm install`, and run `npm test`\n\n[package-url]: https://npmjs.org/package/dunder-proto\n[npm-version-svg]: https://versionbadg.es/es-shims/dunder-proto.svg\n[deps-svg]: https://david-dm.org/es-shims/dunder-proto.svg\n[deps-url]: https://david-dm.org/es-shims/dunder-proto\n[dev-deps-svg]: https://david-dm.org/es-shims/dunder-proto/dev-status.svg\n[dev-deps-url]: https://david-dm.org/es-shims/dunder-proto#info=devDependencies\n[npm-badge-png]: https://nodei.co/npm/dunder-proto.png?downloads=true&stars=true\n[license-image]: https://img.shields.io/npm/l/dunder-proto.svg\n[license-url]: LICENSE\n[downloads-image]: https://img.shields.io/npm/dm/dunder-proto.svg\n[downloads-url]: https://npm-stat.com/charts.html?package=dunder-proto\n[codecov-image]: https://codecov.io/gh/es-shims/dunder-proto/branch/main/graphs/badge.svg\n[codecov-url]: https://app.codecov.io/gh/es-shims/dunder-proto/\n[actions-image]: https://img.shields.io/endpoint?url=https://github-actions-badge-u3jn4tfpocch.runkit.sh/es-shims/dunder-proto\n[actions-url]: https://github.com/es-shims/dunder-proto/actions\n",
        "plugins/auto-review/mcp/node_modules/ee-first/README.md": "# EE First\n\n[![NPM version][npm-image]][npm-url]\n[![Build status][travis-image]][travis-url]\n[![Test coverage][coveralls-image]][coveralls-url]\n[![License][license-image]][license-url]\n[![Downloads][downloads-image]][downloads-url]\n[![Gittip][gittip-image]][gittip-url]\n\nGet the first event in a set of event emitters and event pairs,\nthen clean up after itself.\n\n## Install\n\n```sh\n$ npm install ee-first\n```\n\n## API\n\n```js\nvar first = require('ee-first')\n```\n\n### first(arr, listener)\n\nInvoke `listener` on the first event from the list specified in `arr`. `arr` is\nan array of arrays, with each array in the format `[ee, ...event]`. `listener`\nwill be called only once, the first time any of the given events are emitted. If\n`error` is one of the listened events, then if that fires first, the `listener`\nwill be given the `err` argument.\n\nThe `listener` is invoked as `listener(err, ee, event, args)`, where `err` is the\nfirst argument emitted from an `error` event, if applicable; `ee` is the event\nemitter that fired; `event` is the string event name that fired; and `args` is an\narray of the arguments that were emitted on the event.\n\n```js\nvar ee1 = new EventEmitter()\nvar ee2 = new EventEmitter()\n\nfirst([\n  [ee1, 'close', 'end', 'error'],\n  [ee2, 'error']\n], function (err, ee, event, args) {\n  // listener invoked\n})\n```\n\n#### .cancel()\n\nThe group of listeners can be cancelled before being invoked and have all the event\nlisteners removed from the underlying event emitters.\n\n```js\nvar thunk = first([\n  [ee1, 'close', 'end', 'error'],\n  [ee2, 'error']\n], function (err, ee, event, args) {\n  // listener invoked\n})\n\n// cancel and clean up\nthunk.cancel()\n```\n\n[npm-image]: https://img.shields.io/npm/v/ee-first.svg?style=flat-square\n[npm-url]: https://npmjs.org/package/ee-first\n[github-tag]: http://img.shields.io/github/tag/jonathanong/ee-first.svg?style=flat-square\n[github-url]: https://github.com/jonathanong/ee-first/tags\n[travis-image]: https://img.shields.io/travis/jonathanong/ee-first.svg?style=flat-square\n[travis-url]: https://travis-ci.org/jonathanong/ee-first\n[coveralls-image]: https://img.shields.io/coveralls/jonathanong/ee-first.svg?style=flat-square\n[coveralls-url]: https://coveralls.io/r/jonathanong/ee-first?branch=master\n[license-image]: http://img.shields.io/npm/l/ee-first.svg?style=flat-square\n[license-url]: LICENSE.md\n[downloads-image]: http://img.shields.io/npm/dm/ee-first.svg?style=flat-square\n[downloads-url]: https://npmjs.org/package/ee-first\n[gittip-image]: https://img.shields.io/gittip/jonathanong.svg?style=flat-square\n[gittip-url]: https://www.gittip.com/jonathanong/\n",
        "plugins/auto-review/mcp/node_modules/encodeurl/README.md": "# Encode URL\n\nEncode a URL to a percent-encoded form, excluding already-encoded sequences.\n\n## Installation\n\n```sh\nnpm install encodeurl\n```\n\n## API\n\n```js\nvar encodeUrl = require('encodeurl')\n```\n\n### encodeUrl(url)\n\nEncode a URL to a percent-encoded form, excluding already-encoded sequences.\n\nThis function accepts a URL and encodes all the non-URL code points (as UTF-8 byte sequences). It will not encode the \"%\" character unless it is not part of a valid sequence (`%20` will be left as-is, but `%foo` will be encoded as `%25foo`).\n\nThis encode is meant to be \"safe\" and does not throw errors. It will try as hard as it can to properly encode the given URL, including replacing any raw, unpaired surrogate pairs with the Unicode replacement character prior to encoding.\n\n## Examples\n\n### Encode a URL containing user-controlled data\n\n```js\nvar encodeUrl = require('encodeurl')\nvar escapeHtml = require('escape-html')\n\nhttp.createServer(function onRequest (req, res) {\n  // get encoded form of inbound url\n  var url = encodeUrl(req.url)\n\n  // create html message\n  var body = '<p>Location ' + escapeHtml(url) + ' not found</p>'\n\n  // send a 404\n  res.statusCode = 404\n  res.setHeader('Content-Type', 'text/html; charset=UTF-8')\n  res.setHeader('Content-Length', String(Buffer.byteLength(body, 'utf-8')))\n  res.end(body, 'utf-8')\n})\n```\n\n### Encode a URL for use in a header field\n\n```js\nvar encodeUrl = require('encodeurl')\nvar escapeHtml = require('escape-html')\nvar url = require('url')\n\nhttp.createServer(function onRequest (req, res) {\n  // parse inbound url\n  var href = url.parse(req)\n\n  // set new host for redirect\n  href.host = 'localhost'\n  href.protocol = 'https:'\n  href.slashes = true\n\n  // create location header\n  var location = encodeUrl(url.format(href))\n\n  // create html message\n  var body = '<p>Redirecting to new site: ' + escapeHtml(location) + '</p>'\n\n  // send a 301\n  res.statusCode = 301\n  res.setHeader('Content-Type', 'text/html; charset=UTF-8')\n  res.setHeader('Content-Length', String(Buffer.byteLength(body, 'utf-8')))\n  res.setHeader('Location', location)\n  res.end(body, 'utf-8')\n})\n```\n\n## Similarities\n\nThis function is _similar_ to the intrinsic function `encodeURI`. However, it will not encode:\n\n* The `\\`, `^`, or `|` characters\n* The `%` character when it's part of a valid sequence\n* `[` and `]` (for IPv6 hostnames)\n* Replaces raw, unpaired surrogate pairs with the Unicode replacement character\n\nAs a result, the encoding aligns closely with the behavior in the [WHATWG URL specification][whatwg-url]. However, this package only encodes strings and does not do any URL parsing or formatting.\n\nIt is expected that any output from `new URL(url)` will not change when used with this package, as the output has already been encoded. Additionally, if we were to encode before `new URL(url)`, we do not expect the before and after encoded formats to be parsed any differently.\n\n## Testing\n\n```sh\n$ npm test\n$ npm run lint\n```\n\n## References\n\n- [RFC 3986: Uniform Resource Identifier (URI): Generic Syntax][rfc-3986]\n- [WHATWG URL Living Standard][whatwg-url]\n\n[rfc-3986]: https://tools.ietf.org/html/rfc3986\n[whatwg-url]: https://url.spec.whatwg.org/\n\n## License\n\n[MIT](LICENSE)\n",
        "plugins/auto-review/mcp/node_modules/es-define-property/README.md": "# es-define-property <sup>[![Version Badge][npm-version-svg]][package-url]</sup>\n\n[![github actions][actions-image]][actions-url]\n[![coverage][codecov-image]][codecov-url]\n[![License][license-image]][license-url]\n[![Downloads][downloads-image]][downloads-url]\n\n[![npm badge][npm-badge-png]][package-url]\n\n`Object.defineProperty`, but not IE 8's broken one.\n\n## Example\n\n```js\nconst assert = require('assert');\n\nconst $defineProperty = require('es-define-property');\n\nif ($defineProperty) {\n    assert.equal($defineProperty, Object.defineProperty);\n} else if (Object.defineProperty) {\n    assert.equal($defineProperty, false, 'this is IE 8');\n} else {\n    assert.equal($defineProperty, false, 'this is an ES3 engine');\n}\n```\n\n## Tests\nSimply clone the repo, `npm install`, and run `npm test`\n\n## Security\n\nPlease email [@ljharb](https://github.com/ljharb) or see https://tidelift.com/security if you have a potential security vulnerability to report.\n\n[package-url]: https://npmjs.org/package/es-define-property\n[npm-version-svg]: https://versionbadg.es/ljharb/es-define-property.svg\n[deps-svg]: https://david-dm.org/ljharb/es-define-property.svg\n[deps-url]: https://david-dm.org/ljharb/es-define-property\n[dev-deps-svg]: https://david-dm.org/ljharb/es-define-property/dev-status.svg\n[dev-deps-url]: https://david-dm.org/ljharb/es-define-property#info=devDependencies\n[npm-badge-png]: https://nodei.co/npm/es-define-property.png?downloads=true&stars=true\n[license-image]: https://img.shields.io/npm/l/es-define-property.svg\n[license-url]: LICENSE\n[downloads-image]: https://img.shields.io/npm/dm/es-define-property.svg\n[downloads-url]: https://npm-stat.com/charts.html?package=es-define-property\n[codecov-image]: https://codecov.io/gh/ljharb/es-define-property/branch/main/graphs/badge.svg\n[codecov-url]: https://app.codecov.io/gh/ljharb/es-define-property/\n[actions-image]: https://img.shields.io/endpoint?url=https://github-actions-badge-u3jn4tfpocch.runkit.sh/ljharb/es-define-property\n[actions-url]: https://github.com/ljharb/es-define-property/actions\n",
        "plugins/auto-review/mcp/node_modules/es-errors/README.md": "# es-errors <sup>[![Version Badge][npm-version-svg]][package-url]</sup>\n\n[![github actions][actions-image]][actions-url]\n[![coverage][codecov-image]][codecov-url]\n[![License][license-image]][license-url]\n[![Downloads][downloads-image]][downloads-url]\n\n[![npm badge][npm-badge-png]][package-url]\n\nA simple cache for a few of the JS Error constructors.\n\n## Example\n\n```js\nconst assert = require('assert');\n\nconst Base = require('es-errors');\nconst Eval = require('es-errors/eval');\nconst Range = require('es-errors/range');\nconst Ref = require('es-errors/ref');\nconst Syntax = require('es-errors/syntax');\nconst Type = require('es-errors/type');\nconst URI = require('es-errors/uri');\n\nassert.equal(Base, Error);\nassert.equal(Eval, EvalError);\nassert.equal(Range, RangeError);\nassert.equal(Ref, ReferenceError);\nassert.equal(Syntax, SyntaxError);\nassert.equal(Type, TypeError);\nassert.equal(URI, URIError);\n```\n\n## Tests\nSimply clone the repo, `npm install`, and run `npm test`\n\n## Security\n\nPlease email [@ljharb](https://github.com/ljharb) or see https://tidelift.com/security if you have a potential security vulnerability to report.\n\n[package-url]: https://npmjs.org/package/es-errors\n[npm-version-svg]: https://versionbadg.es/ljharb/es-errors.svg\n[deps-svg]: https://david-dm.org/ljharb/es-errors.svg\n[deps-url]: https://david-dm.org/ljharb/es-errors\n[dev-deps-svg]: https://david-dm.org/ljharb/es-errors/dev-status.svg\n[dev-deps-url]: https://david-dm.org/ljharb/es-errors#info=devDependencies\n[npm-badge-png]: https://nodei.co/npm/es-errors.png?downloads=true&stars=true\n[license-image]: https://img.shields.io/npm/l/es-errors.svg\n[license-url]: LICENSE\n[downloads-image]: https://img.shields.io/npm/dm/es-errors.svg\n[downloads-url]: https://npm-stat.com/charts.html?package=es-errors\n[codecov-image]: https://codecov.io/gh/ljharb/es-errors/branch/main/graphs/badge.svg\n[codecov-url]: https://app.codecov.io/gh/ljharb/es-errors/\n[actions-image]: https://img.shields.io/endpoint?url=https://github-actions-badge-u3jn4tfpocch.runkit.sh/ljharb/es-errors\n[actions-url]: https://github.com/ljharb/es-errors/actions\n",
        "plugins/auto-review/mcp/node_modules/es-object-atoms/README.md": "# es-object-atoms <sup>[![Version Badge][npm-version-svg]][package-url]</sup>\n\n[![github actions][actions-image]][actions-url]\n[![coverage][codecov-image]][codecov-url]\n[![License][license-image]][license-url]\n[![Downloads][downloads-image]][downloads-url]\n\n[![npm badge][npm-badge-png]][package-url]\n\nES Object-related atoms: Object, ToObject, RequireObjectCoercible.\n\n## Example\n\n```js\nconst assert = require('assert');\n\nconst $Object = require('es-object-atoms');\nconst isObject = require('es-object-atoms/isObject');\nconst ToObject = require('es-object-atoms/ToObject');\nconst RequireObjectCoercible = require('es-object-atoms/RequireObjectCoercible');\n\nassert.equal($Object, Object);\nassert.throws(() => ToObject(null), TypeError);\nassert.throws(() => ToObject(undefined), TypeError);\nassert.throws(() => RequireObjectCoercible(null), TypeError);\nassert.throws(() => RequireObjectCoercible(undefined), TypeError);\n\nassert.equal(isObject(undefined), false);\nassert.equal(isObject(null), false);\nassert.equal(isObject({}), true);\nassert.equal(isObject([]), true);\nassert.equal(isObject(function () {}), true);\n\nassert.deepEqual(RequireObjectCoercible(true), true);\nassert.deepEqual(ToObject(true), Object(true));\n\nconst obj = {};\nassert.equal(RequireObjectCoercible(obj), obj);\nassert.equal(ToObject(obj), obj);\n```\n\n## Tests\nSimply clone the repo, `npm install`, and run `npm test`\n\n## Security\n\nPlease email [@ljharb](https://github.com/ljharb) or see https://tidelift.com/security if you have a potential security vulnerability to report.\n\n[package-url]: https://npmjs.org/package/es-object-atoms\n[npm-version-svg]: https://versionbadg.es/ljharb/es-object-atoms.svg\n[deps-svg]: https://david-dm.org/ljharb/es-object-atoms.svg\n[deps-url]: https://david-dm.org/ljharb/es-object-atoms\n[dev-deps-svg]: https://david-dm.org/ljharb/es-object-atoms/dev-status.svg\n[dev-deps-url]: https://david-dm.org/ljharb/es-object-atoms#info=devDependencies\n[npm-badge-png]: https://nodei.co/npm/es-object-atoms.png?downloads=true&stars=true\n[license-image]: https://img.shields.io/npm/l/es-object-atoms.svg\n[license-url]: LICENSE\n[downloads-image]: https://img.shields.io/npm/dm/es-object.svg\n[downloads-url]: https://npm-stat.com/charts.html?package=es-object-atoms\n[codecov-image]: https://codecov.io/gh/ljharb/es-object-atoms/branch/main/graphs/badge.svg\n[codecov-url]: https://app.codecov.io/gh/ljharb/es-object-atoms/\n[actions-image]: https://img.shields.io/endpoint?url=https://github-actions-badge-u3jn4tfpocch.runkit.sh/ljharb/es-object-atoms\n[actions-url]: https://github.com/ljharb/es-object-atoms/actions\n",
        "plugins/auto-review/mcp/node_modules/etag/README.md": "# etag\n\n[![NPM Version][npm-image]][npm-url]\n[![NPM Downloads][downloads-image]][downloads-url]\n[![Node.js Version][node-version-image]][node-version-url]\n[![Build Status][travis-image]][travis-url]\n[![Test Coverage][coveralls-image]][coveralls-url]\n\nCreate simple HTTP ETags\n\nThis module generates HTTP ETags (as defined in RFC 7232) for use in\nHTTP responses.\n\n## Installation\n\nThis is a [Node.js](https://nodejs.org/en/) module available through the\n[npm registry](https://www.npmjs.com/). Installation is done using the\n[`npm install` command](https://docs.npmjs.com/getting-started/installing-npm-packages-locally):\n\n```sh\n$ npm install etag\n```\n\n## API\n\n<!-- eslint-disable no-unused-vars -->\n\n```js\nvar etag = require('etag')\n```\n\n### etag(entity, [options])\n\nGenerate a strong ETag for the given entity. This should be the complete\nbody of the entity. Strings, `Buffer`s, and `fs.Stats` are accepted. By\ndefault, a strong ETag is generated except for `fs.Stats`, which will\ngenerate a weak ETag (this can be overwritten by `options.weak`).\n\n<!-- eslint-disable no-undef -->\n\n```js\nres.setHeader('ETag', etag(body))\n```\n\n#### Options\n\n`etag` accepts these properties in the options object.\n\n##### weak\n\nSpecifies if the generated ETag will include the weak validator mark (that\nis, the leading `W/`). The actual entity tag is the same. The default value\nis `false`, unless the `entity` is `fs.Stats`, in which case it is `true`.\n\n## Testing\n\n```sh\n$ npm test\n```\n\n## Benchmark\n\n```bash\n$ npm run-script bench\n\n> etag@1.8.1 bench nodejs-etag\n> node benchmark/index.js\n\n  http_parser@2.7.0\n  node@6.11.1\n  v8@5.1.281.103\n  uv@1.11.0\n  zlib@1.2.11\n  ares@1.10.1-DEV\n  icu@58.2\n  modules@48\n  openssl@1.0.2k\n\n> node benchmark/body0-100b.js\n\n  100B body\n\n  4 tests completed.\n\n  buffer - strong x 258,647 ops/sec ±1.07% (180 runs sampled)\n  buffer - weak   x 263,812 ops/sec ±0.61% (184 runs sampled)\n  string - strong x 259,955 ops/sec ±1.19% (185 runs sampled)\n  string - weak   x 264,356 ops/sec ±1.09% (184 runs sampled)\n\n> node benchmark/body1-1kb.js\n\n  1KB body\n\n  4 tests completed.\n\n  buffer - strong x 189,018 ops/sec ±1.12% (182 runs sampled)\n  buffer - weak   x 190,586 ops/sec ±0.81% (186 runs sampled)\n  string - strong x 144,272 ops/sec ±0.96% (188 runs sampled)\n  string - weak   x 145,380 ops/sec ±1.43% (187 runs sampled)\n\n> node benchmark/body2-5kb.js\n\n  5KB body\n\n  4 tests completed.\n\n  buffer - strong x 92,435 ops/sec ±0.42% (188 runs sampled)\n  buffer - weak   x 92,373 ops/sec ±0.58% (189 runs sampled)\n  string - strong x 48,850 ops/sec ±0.56% (186 runs sampled)\n  string - weak   x 49,380 ops/sec ±0.56% (190 runs sampled)\n\n> node benchmark/body3-10kb.js\n\n  10KB body\n\n  4 tests completed.\n\n  buffer - strong x 55,989 ops/sec ±0.93% (188 runs sampled)\n  buffer - weak   x 56,148 ops/sec ±0.55% (190 runs sampled)\n  string - strong x 27,345 ops/sec ±0.43% (188 runs sampled)\n  string - weak   x 27,496 ops/sec ±0.45% (190 runs sampled)\n\n> node benchmark/body4-100kb.js\n\n  100KB body\n\n  4 tests completed.\n\n  buffer - strong x 7,083 ops/sec ±0.22% (190 runs sampled)\n  buffer - weak   x 7,115 ops/sec ±0.26% (191 runs sampled)\n  string - strong x 3,068 ops/sec ±0.34% (190 runs sampled)\n  string - weak   x 3,096 ops/sec ±0.35% (190 runs sampled)\n\n> node benchmark/stats.js\n\n  stat\n\n  4 tests completed.\n\n  real - strong x 871,642 ops/sec ±0.34% (189 runs sampled)\n  real - weak   x 867,613 ops/sec ±0.39% (190 runs sampled)\n  fake - strong x 401,051 ops/sec ±0.40% (189 runs sampled)\n  fake - weak   x 400,100 ops/sec ±0.47% (188 runs sampled)\n```\n\n## License\n\n[MIT](LICENSE)\n\n[npm-image]: https://img.shields.io/npm/v/etag.svg\n[npm-url]: https://npmjs.org/package/etag\n[node-version-image]: https://img.shields.io/node/v/etag.svg\n[node-version-url]: https://nodejs.org/en/download/\n[travis-image]: https://img.shields.io/travis/jshttp/etag/master.svg\n[travis-url]: https://travis-ci.org/jshttp/etag\n[coveralls-image]: https://img.shields.io/coveralls/jshttp/etag/master.svg\n[coveralls-url]: https://coveralls.io/r/jshttp/etag?branch=master\n[downloads-image]: https://img.shields.io/npm/dm/etag.svg\n[downloads-url]: https://npmjs.org/package/etag\n",
        "plugins/auto-review/mcp/node_modules/eventsource-parser/README.md": "# eventsource-parser\n\n[![npm version](https://img.shields.io/npm/v/eventsource-parser.svg?style=flat-square)](https://www.npmjs.com/package/eventsource-parser)[![npm bundle size](https://img.shields.io/bundlephobia/minzip/eventsource-parser?style=flat-square)](https://bundlephobia.com/result?p=eventsource-parser)[![npm weekly downloads](https://img.shields.io/npm/dw/eventsource-parser.svg?style=flat-square)](https://www.npmjs.com/package/eventsource-parser)\n\nA streaming parser for [server-sent events/eventsource](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events), without any assumptions about how the actual stream of data is retrieved. It is intended to be a building block for [clients](https://github.com/rexxars/eventsource-client) and polyfills in javascript environments such as browsers, node.js and deno.\n\nIf you are looking for a modern client implementation, see [eventsource-client](https://github.com/rexxars/eventsource-client).\n\nYou create an instance of the parser, and _feed_ it chunks of data - partial or complete, and the parse emits parsed messages once it receives a complete message. A [TransformStream variant](#stream-usage) is also available for environments that support it (modern browsers, Node 18 and higher).\n\nOther modules in the EventSource family:\n\n- [eventsource-client](https://github.com/rexxars/eventsource-client): modern, feature rich eventsource client for browsers, node.js, bun, deno and other modern JavaScript environments.\n- [eventsource-encoder](https://github.com/rexxars/eventsource-encoder): encodes messages in the EventSource/Server-Sent Events format.\n- [eventsource](https://github.com/eventsource/eventsource): Node.js polyfill for the WhatWG EventSource API.\n\n> [!NOTE]\n> Migrating from eventsource-parser 1.x/2.x? See the [migration guide](./MIGRATE-v3.md).\n\n## Installation\n\n```bash\nnpm install --save eventsource-parser\n```\n\n## Usage\n\n```ts\nimport {createParser, type EventSourceMessage} from 'eventsource-parser'\n\nfunction onEvent(event: EventSourceMessage) {\n  console.log('Received event!')\n  console.log('id: %s', event.id || '<none>')\n  console.log('event: %s', event.event || '<none>')\n  console.log('data: %s', event.data)\n}\n\nconst parser = createParser({onEvent})\nconst sseStream = getSomeReadableStream()\n\nfor await (const chunk of sseStream) {\n  parser.feed(chunk)\n}\n\n// If you want to re-use the parser for a new stream of events, make sure to reset it!\nparser.reset()\nconsole.log('Done!')\n```\n\n### Retry intervals\n\nIf the server sends a `retry` field in the event stream, the parser will call any `onRetry` callback specified to the `createParser` function:\n\n```ts\nconst parser = createParser({\n  onRetry(retryInterval) {\n    console.log('Server requested retry interval of %dms', retryInterval)\n  },\n  onEvent(event) {\n    // …\n  },\n})\n```\n\n### Parse errors\n\nIf the parser encounters an error while parsing, it will call any `onError` callback provided to the `createParser` function:\n\n```ts\nimport {type ParseError} from 'eventsource-parser'\n\nconst parser = createParser({\n  onError(error: ParseError) {\n    console.error('Error parsing event:', error)\n    if (error.type === 'invalid-field') {\n      console.error('Field name:', error.field)\n      console.error('Field value:', error.value)\n      console.error('Line:', error.line)\n    } else if (error.type === 'invalid-retry') {\n      console.error('Invalid retry interval:', error.value)\n    }\n  },\n  onEvent(event) {\n    // …\n  },\n})\n```\n\nNote that `invalid-field` errors will usually be called for any invalid data - not only data shaped as `field: value`. This is because the EventSource specification says to treat anything prior to a `:` as the field name. Use the `error.line` property to get the full line that caused the error.\n\n> [!NOTE]\n> When encountering the end of a stream, calling `.reset({consume: true})` on the parser to flush any remaining data and reset the parser state. This will trigger the `onError` callback if the pending data is not a valid event.\n\n### Comments\n\nThe parser will ignore comments (lines starting with `:`) by default. If you want to handle comments, you can provide an `onComment` callback to the `createParser` function:\n\n```ts\nconst parser = createParser({\n  onComment(comment) {\n    console.log('Received comment:', comment)\n  },\n  onEvent(event) {\n    // …\n  },\n})\n```\n\n> [!NOTE]\n> Leading whitespace is not stripped from comments, eg `: comment` will give ` comment` as the comment value, not `comment` (note the leading space).\n\n## Stream usage\n\n```ts\nimport {EventSourceParserStream} from 'eventsource-parser/stream'\n\nconst eventStream = response.body\n  .pipeThrough(new TextDecoderStream())\n  .pipeThrough(new EventSourceParserStream())\n```\n\nNote that the TransformStream is exposed under a separate export (`eventsource-parser/stream`), in order to maximize compatibility with environments that do not have the `TransformStream` constructor available.\n\n## License\n\nMIT © [Espen Hovlandsdal](https://espen.codes/)\n",
        "plugins/auto-review/mcp/node_modules/eventsource/README.md": "# eventsource\n\n[![npm version](https://img.shields.io/npm/v/eventsource.svg?style=flat-square)](https://www.npmjs.com/package/eventsource)[![npm bundle size](https://img.shields.io/bundlephobia/minzip/eventsource?style=flat-square)](https://bundlephobia.com/result?p=eventsource)[![npm weekly downloads](https://img.shields.io/npm/dw/eventsource.svg?style=flat-square)](https://www.npmjs.com/package/eventsource)\n\nWhatWG/W3C-compatible [server-sent events/eventsource](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events) client. The module attempts to implement an absolute minimal amount of features/changes beyond the specification.\n\nIf you're looking for a modern alternative with a less constrained API, check out the [`eventsource-client` package](https://www.npmjs.com/package/eventsource-client).\n\n## Installation\n\n```bash\nnpm install --save eventsource\n```\n\n## Supported engines\n\n- Node.js >= 18\n- Chrome >= 63\n- Safari >= 11.3\n- Firefox >= 65\n- Edge >= 79\n- Deno >= 1.30\n- Bun >= 1.1.23\n\nBasically, any environment that supports:\n\n- [fetch](https://developer.mozilla.org/en-US/docs/Web/API/fetch)\n- [ReadableStream](https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream)\n- [TextDecoderStream](https://developer.mozilla.org/en-US/docs/Web/API/TextDecoderStream)\n- [URL](https://developer.mozilla.org/en-US/docs/Web/API/URL)\n- [Event](https://developer.mozilla.org/en-US/docs/Web/API/Event), [MessageEvent](https://developer.mozilla.org/en-US/docs/Web/API/MessageEvent), [EventTarget](https://developer.mozilla.org/en-US/docs/Web/API/EventTarget)\n\nIf you need to support older runtimes, try the `2.x` branch/version range (note: 2.x branch is primarily targetted at Node.js, not browsers).\n\n## Usage\n\n```ts\nimport {EventSource} from 'eventsource'\n\nconst es = new EventSource('https://my-server.com/sse')\n\n/*\n * This will listen for events with the field `event: notice`.\n */\nes.addEventListener('notice', (event) => {\n  console.log(event.data)\n})\n\n/*\n * This will listen for events with the field `event: update`.\n */\nes.addEventListener('update', (event) => {\n  console.log(event.data)\n})\n\n/*\n * The event \"message\" is a special case, as it will capture events _without_ an\n * event field, as well as events that have the specific type `event: message`.\n * It will not trigger on any other event type.\n */\nes.addEventListener('message', (event) => {\n  console.log(event.data)\n})\n\n/**\n * To explicitly close the connection, call the `close` method.\n * This will prevent any reconnection from happening.\n */\nsetTimeout(() => {\n  es.close()\n}, 10_000)\n```\n\n### TypeScript\n\nMake sure you have configured your TSConfig so it matches the environment you are targetting. If you are targetting browsers, this would be `dom`:\n\n```jsonc\n{\n  \"compilerOptions\": {\n    \"lib\": [\"dom\"],\n  },\n}\n```\n\nIf you're using Node.js, ensure you have `@types/node` installed (and it is version 18 or higher). Cloudflare workers have `@cloudflare/workers-types` etc.\n\nThe following errors are caused by targetting an environment that does not have the necessary types available:\n\n```\nerror TS2304: Cannot find name 'Event'.\nerror TS2304: Cannot find name 'EventTarget'.\nerror TS2304: Cannot find name 'MessageEvent'.\n```\n\n## Migrating from v1 / v2\n\nSee [MIGRATION.md](MIGRATION.md#v2-to-v3) for a detailed migration guide.\n\n## Extensions to the WhatWG/W3C API\n\n### Message and code properties on errors\n\nThe `error` event has a `message` and `code` property that can be used to get more information about the error. In the specification, the Event\n\n```ts\nes.addEventListener('error', (err) => {\n  if (err.code === 401 || err.code === 403) {\n    console.log('not authorized')\n  }\n})\n```\n\n### Specify `fetch` implementation\n\nThe `EventSource` constructor accepts an optional `fetch` property in the second argument that can be used to specify the `fetch` implementation to use.\n\nThis can be useful in environments where the global `fetch` function is not available - but it can also be used to alter the request/response behaviour.\n\n#### Setting HTTP request headers\n\n```ts\nconst es = new EventSource('https://my-server.com/sse', {\n  fetch: (input, init) =>\n    fetch(input, {\n      ...init,\n      headers: {\n        ...init.headers,\n        Authorization: 'Bearer myToken',\n      },\n    }),\n})\n```\n\n#### HTTP/HTTPS proxy\n\nUse a package like [`node-fetch-native`](https://github.com/unjs/node-fetch-native) to add proxy support, either through environment variables or explicit configuration.\n\n```ts\n// npm install node-fetch-native --save\nimport {fetch} from 'node-fetch-native/proxy'\n\nconst es = new EventSource('https://my-server.com/sse', {\n  fetch: (input, init) => fetch(input, init),\n})\n```\n\n#### Allow unauthorized HTTPS requests\n\nUse a package like [`undici`](https://github.com/nodejs/undici) for more control of fetch options through the use of an [`Agent`](https://undici.nodejs.org/#/docs/api/Agent.md).\n\n```ts\n// npm install undici --save\nimport {fetch, Agent} from 'undici'\n\nawait fetch('https://my-server.com/sse', {\n  dispatcher: new Agent({\n    connect: {\n      rejectUnauthorized: false,\n    },\n  }),\n})\n```\n\n## License\n\nMIT-licensed. See [LICENSE](LICENSE).\n",
        "plugins/auto-review/mcp/node_modules/fast-deep-equal/README.md": "# fast-deep-equal\nThe fastest deep equal with ES6 Map, Set and Typed arrays support.\n\n[![Build Status](https://travis-ci.org/epoberezkin/fast-deep-equal.svg?branch=master)](https://travis-ci.org/epoberezkin/fast-deep-equal)\n[![npm](https://img.shields.io/npm/v/fast-deep-equal.svg)](https://www.npmjs.com/package/fast-deep-equal)\n[![Coverage Status](https://coveralls.io/repos/github/epoberezkin/fast-deep-equal/badge.svg?branch=master)](https://coveralls.io/github/epoberezkin/fast-deep-equal?branch=master)\n\n\n## Install\n\n```bash\nnpm install fast-deep-equal\n```\n\n\n## Features\n\n- ES5 compatible\n- works in node.js (8+) and browsers (IE9+)\n- checks equality of Date and RegExp objects by value.\n\nES6 equal (`require('fast-deep-equal/es6')`) also supports:\n- Maps\n- Sets\n- Typed arrays\n\n\n## Usage\n\n```javascript\nvar equal = require('fast-deep-equal');\nconsole.log(equal({foo: 'bar'}, {foo: 'bar'})); // true\n```\n\nTo support ES6 Maps, Sets and Typed arrays equality use:\n\n```javascript\nvar equal = require('fast-deep-equal/es6');\nconsole.log(equal(Int16Array([1, 2]), Int16Array([1, 2]))); // true\n```\n\nTo use with React (avoiding the traversal of React elements' _owner\nproperty that contains circular references and is not needed when\ncomparing the elements - borrowed from [react-fast-compare](https://github.com/FormidableLabs/react-fast-compare)):\n\n```javascript\nvar equal = require('fast-deep-equal/react');\nvar equal = require('fast-deep-equal/es6/react');\n```\n\n\n## Performance benchmark\n\nNode.js v12.6.0:\n\n```\nfast-deep-equal x 261,950 ops/sec ±0.52% (89 runs sampled)\nfast-deep-equal/es6 x 212,991 ops/sec ±0.34% (92 runs sampled)\nfast-equals x 230,957 ops/sec ±0.83% (85 runs sampled)\nnano-equal x 187,995 ops/sec ±0.53% (88 runs sampled)\nshallow-equal-fuzzy x 138,302 ops/sec ±0.49% (90 runs sampled)\nunderscore.isEqual x 74,423 ops/sec ±0.38% (89 runs sampled)\nlodash.isEqual x 36,637 ops/sec ±0.72% (90 runs sampled)\ndeep-equal x 2,310 ops/sec ±0.37% (90 runs sampled)\ndeep-eql x 35,312 ops/sec ±0.67% (91 runs sampled)\nramda.equals x 12,054 ops/sec ±0.40% (91 runs sampled)\nutil.isDeepStrictEqual x 46,440 ops/sec ±0.43% (90 runs sampled)\nassert.deepStrictEqual x 456 ops/sec ±0.71% (88 runs sampled)\n\nThe fastest is fast-deep-equal\n```\n\nTo run benchmark (requires node.js 6+):\n\n```bash\nnpm run benchmark\n```\n\n__Please note__: this benchmark runs against the available test cases. To choose the most performant library for your application, it is recommended to benchmark against your data and to NOT expect this benchmark to reflect the performance difference in your application.\n\n\n## Enterprise support\n\nfast-deep-equal package is a part of [Tidelift enterprise subscription](https://tidelift.com/subscription/pkg/npm-fast-deep-equal?utm_source=npm-fast-deep-equal&utm_medium=referral&utm_campaign=enterprise&utm_term=repo) - it provides a centralised commercial support to open-source software users, in addition to the support provided by software maintainers.\n\n\n## Security contact\n\nTo report a security vulnerability, please use the\n[Tidelift security contact](https://tidelift.com/security).\nTidelift will coordinate the fix and disclosure. Please do NOT report security vulnerability via GitHub issues.\n\n\n## License\n\n[MIT](https://github.com/epoberezkin/fast-deep-equal/blob/master/LICENSE)\n",
        "plugins/auto-review/mcp/node_modules/fast-uri/README.md": "# fast-uri\n\n<div align=\"center\">\n\n[![NPM version](https://img.shields.io/npm/v/fast-uri.svg?style=flat)](https://www.npmjs.com/package/fast-uri)\n[![CI](https://github.com/fastify/fast-uri/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/fastify/fast-uri/actions/workflows/ci.yml)\n[![neostandard javascript style](https://img.shields.io/badge/code_style-neostandard-brightgreen?style=flat)](https://github.com/neostandard/neostandard)\n\n</div>\n\nDependency-free RFC 3986 URI toolbox.\n\n## Usage\n\n## Options\n\nAll of the above functions can accept an additional options argument that is an object that can contain one or more of the following properties:\n\n*\t`scheme` (string)\n\tIndicates the scheme that the URI should be treated as, overriding the URI's normal scheme parsing behavior.\n\n*\t`reference` (string)\n\tIf set to `\"suffix\"`, it indicates that the URI is in the suffix format and the parser will use the option's `scheme` property to determine the URI's scheme.\n\n*\t`tolerant` (boolean, false)\n\tIf set to `true`, the parser will relax URI resolving rules.\n\n*\t`absolutePath` (boolean, false)\n\tIf set to `true`, the serializer will not resolve a relative `path` component.\n\n*\t`unicodeSupport` (boolean, false)\n\tIf set to `true`, the parser will unescape non-ASCII characters in the parsed output as per [RFC 3987](http://www.ietf.org/rfc/rfc3987.txt).\n\n*\t`domainHost` (boolean, false)\n\tIf set to `true`, the library will treat the `host` component as a domain name, and convert IDNs (International Domain Names) as per [RFC 5891](http://www.ietf.org/rfc/rfc5891.txt).\n\n### Parse\n\n```js\nconst uri = require('fast-uri')\nuri.parse('uri://user:pass@example.com:123/one/two.three?q1=a1&q2=a2#body')\n// Output\n{\n  scheme: \"uri\",\n  userinfo: \"user:pass\",\n  host: \"example.com\",\n  port: 123,\n  path: \"/one/two.three\",\n  query: \"q1=a1&q2=a2\",\n  fragment: \"body\"\n}\n```\n\n### Serialize\n\n```js\nconst uri = require('fast-uri')\nuri.serialize({scheme: \"http\", host: \"example.com\", fragment: \"footer\"})\n// Output\n\"http://example.com/#footer\"\n\n```\n\n### Resolve\n\n```js\nconst uri = require('fast-uri')\nuri.resolve(\"uri://a/b/c/d?q\", \"../../g\")\n// Output\n\"uri://a/g\"\n```\n\n### Equal\n\n```js\nconst uri = require('fast-uri')\nuri.equal(\"example://a/b/c/%7Bfoo%7D\", \"eXAMPLE://a/./b/../b/%63/%7bfoo%7d\")\n// Output\ntrue\n```\n\n## Scheme supports\n\nfast-uri supports inserting custom [scheme](http://en.wikipedia.org/wiki/URI_scheme)-dependent processing rules. Currently, fast-uri has built-in support for the following schemes:\n\n*\thttp \\[[RFC 2616](http://www.ietf.org/rfc/rfc2616.txt)\\]\n*\thttps \\[[RFC 2818](http://www.ietf.org/rfc/rfc2818.txt)\\]\n*\tws \\[[RFC 6455](http://www.ietf.org/rfc/rfc6455.txt)\\]\n*\twss \\[[RFC 6455](http://www.ietf.org/rfc/rfc6455.txt)\\]\n*\turn \\[[RFC 2141](http://www.ietf.org/rfc/rfc2141.txt)\\]\n*\turn:uuid \\[[RFC 4122](http://www.ietf.org/rfc/rfc4122.txt)\\]\n\n\n## Benchmarks\n\n```\nfast-uri benchmark\n┌─────────┬──────────────────────────────────────────┬──────────────────┬──────────────────┬────────────────────────┬────────────────────────┬─────────┐\n│ (index) │ Task name                                │ Latency avg (ns) │ Latency med (ns) │ Throughput avg (ops/s) │ Throughput med (ops/s) │ Samples │\n├─────────┼──────────────────────────────────────────┼──────────────────┼──────────────────┼────────────────────────┼────────────────────────┼─────────┤\n│ 0       │ 'fast-uri: parse domain'                 │ '951.31 ± 0.75%' │ '875.00 ± 11.00' │ '1122538 ± 0.01%'      │ '1142857 ± 14550'      │ 1051187 │\n│ 1       │ 'fast-uri: parse IPv4'                   │ '443.44 ± 0.22%' │ '406.00 ± 3.00'  │ '2422762 ± 0.01%'      │ '2463054 ± 18335'      │ 2255105 │\n│ 2       │ 'fast-uri: parse IPv6'                   │ '1241.6 ± 1.74%' │ '1131.0 ± 30.00' │ '875177 ± 0.02%'       │ '884173 ± 24092'       │ 805399  │\n│ 3       │ 'fast-uri: parse URN'                    │ '689.19 ± 4.29%' │ '618.00 ± 9.00'  │ '1598373 ± 0.01%'      │ '1618123 ± 23913'      │ 1450972 │\n│ 4       │ 'fast-uri: parse URN uuid'               │ '1025.4 ± 2.02%' │ '921.00 ± 19.00' │ '1072419 ± 0.02%'      │ '1085776 ± 22871'      │ 975236  │\n│ 5       │ 'fast-uri: serialize uri'                │ '1028.5 ± 0.53%' │ '933.00 ± 43.00' │ '1063310 ± 0.02%'      │ '1071811 ± 50523'      │ 972249  │\n│ 6       │ 'fast-uri: serialize long uri with dots' │ '1805.1 ± 0.52%' │ '1627.0 ± 17.00' │ '602620 ± 0.02%'       │ '614628 ± 6490'        │ 553997  │\n│ 7       │ 'fast-uri: serialize IPv6'               │ '2569.4 ± 2.69%' │ '2302.0 ± 21.00' │ '426080 ± 0.03%'       │ '434405 ± 3999'        │ 389194  │\n│ 8       │ 'fast-uri: serialize ws'                 │ '979.39 ± 0.43%' │ '882.00 ± 8.00'  │ '1111665 ± 0.02%'      │ '1133787 ± 10378'      │ 1021045 │\n│ 9       │ 'fast-uri: resolve'                      │ '2208.2 ± 1.08%' │ '1980.0 ± 24.00' │ '495001 ± 0.03%'       │ '505051 ± 6049'        │ 452848  │\n└─────────┴──────────────────────────────────────────┴──────────────────┴──────────────────┴────────────────────────┴────────────────────────┴─────────┘\nuri-js benchmark\n┌─────────┬───────────────────────────────────────┬──────────────────┬──────────────────┬────────────────────────┬────────────────────────┬─────────┐\n│ (index) │ Task name                             │ Latency avg (ns) │ Latency med (ns) │ Throughput avg (ops/s) │ Throughput med (ops/s) │ Samples │\n├─────────┼───────────────────────────────────────┼──────────────────┼──────────────────┼────────────────────────┼────────────────────────┼─────────┤\n│ 0       │ 'urijs: parse domain'                 │ '3618.3 ± 0.43%' │ '3314.0 ± 33.00' │ '294875 ± 0.04%'       │ '301750 ± 2975'        │ 276375  │\n│ 1       │ 'urijs: parse IPv4'                   │ '4024.1 ± 0.41%' │ '3751.0 ± 25.00' │ '261981 ± 0.04%'       │ '266596 ± 1789'        │ 248506  │\n│ 2       │ 'urijs: parse IPv6'                   │ '5417.2 ± 0.46%' │ '4968.0 ± 43.00' │ '196023 ± 0.05%'       │ '201288 ± 1727'        │ 184598  │\n│ 3       │ 'urijs: parse URN'                    │ '1324.2 ± 0.23%' │ '1229.0 ± 17.00' │ '801535 ± 0.02%'       │ '813670 ± 11413'       │ 755185  │\n│ 4       │ 'urijs: parse URN uuid'               │ '1822.0 ± 3.08%' │ '1655.0 ± 15.00' │ '594433 ± 0.02%'       │ '604230 ± 5427'        │ 548843  │\n│ 5       │ 'urijs: serialize uri'                │ '4196.8 ± 0.36%' │ '3908.0 ± 27.00' │ '251146 ± 0.04%'       │ '255885 ± 1756'        │ 238276  │\n│ 6       │ 'urijs: serialize long uri with dots' │ '8331.0 ± 1.30%' │ '7658.0 ± 72.00' │ '126440 ± 0.07%'       │ '130582 ± 1239'        │ 120034  │\n│ 7       │ 'urijs: serialize IPv6'               │ '5685.5 ± 0.30%' │ '5366.0 ± 33.00' │ '182632 ± 0.05%'       │ '186359 ± 1153'        │ 175886  │\n│ 8       │ 'urijs: serialize ws'                 │ '4159.3 ± 0.20%' │ '3899.0 ± 28.00' │ '250459 ± 0.04%'       │ '256476 ± 1855'        │ 240423  │\n│ 9       │ 'urijs: resolve'                      │ '6729.9 ± 0.39%' │ '6261.0 ± 37.00' │ '156361 ± 0.06%'       │ '159719 ± 949'         │ 148591  │\n└─────────┴───────────────────────────────────────┴──────────────────┴──────────────────┴────────────────────────┴────────────────────────┴─────────┘\nWHATWG URL benchmark\n┌─────────┬────────────────────────────┬──────────────────┬──────────────────┬────────────────────────┬────────────────────────┬─────────┐\n│ (index) │ Task name                  │ Latency avg (ns) │ Latency med (ns) │ Throughput avg (ops/s) │ Throughput med (ops/s) │ Samples │\n├─────────┼────────────────────────────┼──────────────────┼──────────────────┼────────────────────────┼────────────────────────┼─────────┤\n│ 0       │ 'WHATWG URL: parse domain' │ '475.22 ± 0.20%' │ '444.00 ± 5.00'  │ '2217599 ± 0.01%'      │ '2252252 ± 25652'      │ 2104289 │\n│ 1       │ 'WHATWG URL: parse URN'    │ '384.78 ± 0.85%' │ '350.00 ± 5.00'  │ '2809071 ± 0.01%'      │ '2857143 ± 41408'      │ 2598885 │\n└─────────┴────────────────────────────┴──────────────────┴──────────────────┴────────────────────────┴────────────────────────┴─────────┘\n```\n\n## TODO\n\n- [ ] Support MailTo\n- [ ] Be 100% iso compatible with uri-js\n\n## License\n\nLicensed under [BSD-3-Clause](./LICENSE).\n",
        "plugins/auto-review/mcp/node_modules/finalhandler/README.md": "# finalhandler\n\n[![NPM Version][npm-image]][npm-url]\n[![NPM Downloads][downloads-image]][downloads-url]\n[![Node.js Version][node-image]][node-url]\n[![Build Status][github-actions-ci-image]][github-actions-ci-url]\n[![Test Coverage][coveralls-image]][coveralls-url]\n\nNode.js function to invoke as the final step to respond to HTTP request.\n\n## Installation\n\nThis is a [Node.js](https://nodejs.org/en/) module available through the\n[npm registry](https://www.npmjs.com/). Installation is done using the\n[`npm install` command](https://docs.npmjs.com/getting-started/installing-npm-packages-locally):\n\n```sh\n$ npm install finalhandler\n```\n\n## API\n\n```js\nvar finalhandler = require('finalhandler')\n```\n\n### finalhandler(req, res, [options])\n\nReturns function to be invoked as the final step for the given `req` and `res`.\nThis function is to be invoked as `fn(err)`. If `err` is falsy, the handler will\nwrite out a 404 response to the `res`. If it is truthy, an error response will\nbe written out to the `res` or `res` will be terminated if a response has already\nstarted.\n\nWhen an error is written, the following information is added to the response:\n\n  * The `res.statusCode` is set from `err.status` (or `err.statusCode`). If\n    this value is outside the 4xx or 5xx range, it will be set to 500.\n  * The `res.statusMessage` is set according to the status code.\n  * The body will be the HTML of the status code message if `env` is\n    `'production'`, otherwise will be `err.stack`.\n  * Any headers specified in an `err.headers` object.\n\nThe final handler will also unpipe anything from `req` when it is invoked.\n\n#### options.env\n\nBy default, the environment is determined by `NODE_ENV` variable, but it can be\noverridden by this option.\n\n#### options.onerror\n\nProvide a function to be called with the `err` when it exists. Can be used for\nwriting errors to a central location without excessive function generation. Called\nas `onerror(err, req, res)`.\n\n## Examples\n\n### always 404\n\n```js\nvar finalhandler = require('finalhandler')\nvar http = require('http')\n\nvar server = http.createServer(function (req, res) {\n  var done = finalhandler(req, res)\n  done()\n})\n\nserver.listen(3000)\n```\n\n### perform simple action\n\n```js\nvar finalhandler = require('finalhandler')\nvar fs = require('fs')\nvar http = require('http')\n\nvar server = http.createServer(function (req, res) {\n  var done = finalhandler(req, res)\n\n  fs.readFile('index.html', function (err, buf) {\n    if (err) return done(err)\n    res.setHeader('Content-Type', 'text/html')\n    res.end(buf)\n  })\n})\n\nserver.listen(3000)\n```\n\n### use with middleware-style functions\n\n```js\nvar finalhandler = require('finalhandler')\nvar http = require('http')\nvar serveStatic = require('serve-static')\n\nvar serve = serveStatic('public')\n\nvar server = http.createServer(function (req, res) {\n  var done = finalhandler(req, res)\n  serve(req, res, done)\n})\n\nserver.listen(3000)\n```\n\n### keep log of all errors\n\n```js\nvar finalhandler = require('finalhandler')\nvar fs = require('fs')\nvar http = require('http')\n\nvar server = http.createServer(function (req, res) {\n  var done = finalhandler(req, res, { onerror: logerror })\n\n  fs.readFile('index.html', function (err, buf) {\n    if (err) return done(err)\n    res.setHeader('Content-Type', 'text/html')\n    res.end(buf)\n  })\n})\n\nserver.listen(3000)\n\nfunction logerror (err) {\n  console.error(err.stack || err.toString())\n}\n```\n\n## License\n\n[MIT](LICENSE)\n\n[npm-image]: https://img.shields.io/npm/v/finalhandler.svg\n[npm-url]: https://npmjs.org/package/finalhandler\n[node-image]: https://img.shields.io/node/v/finalhandler.svg\n[node-url]: https://nodejs.org/en/download\n[coveralls-image]: https://img.shields.io/coveralls/pillarjs/finalhandler.svg\n[coveralls-url]: https://coveralls.io/r/pillarjs/finalhandler?branch=master\n[downloads-image]: https://img.shields.io/npm/dm/finalhandler.svg\n[downloads-url]: https://npmjs.org/package/finalhandler\n[github-actions-ci-image]: https://github.com/pillarjs/finalhandler/actions/workflows/ci.yml/badge.svg\n[github-actions-ci-url]: https://github.com/pillarjs/finalhandler/actions/workflows/ci.yml\n",
        "plugins/auto-review/mcp/node_modules/forwarded/README.md": "# forwarded\n\n[![NPM Version][npm-image]][npm-url]\n[![NPM Downloads][downloads-image]][downloads-url]\n[![Node.js Version][node-version-image]][node-version-url]\n[![Build Status][ci-image]][ci-url]\n[![Test Coverage][coveralls-image]][coveralls-url]\n\nParse HTTP X-Forwarded-For header\n\n## Installation\n\nThis is a [Node.js](https://nodejs.org/en/) module available through the\n[npm registry](https://www.npmjs.com/). Installation is done using the\n[`npm install` command](https://docs.npmjs.com/getting-started/installing-npm-packages-locally):\n\n```sh\n$ npm install forwarded\n```\n\n## API\n\n```js\nvar forwarded = require('forwarded')\n```\n\n### forwarded(req)\n\n```js\nvar addresses = forwarded(req)\n```\n\nParse the `X-Forwarded-For` header from the request. Returns an array\nof the addresses, including the socket address for the `req`, in reverse\norder (i.e. index `0` is the socket address and the last index is the\nfurthest address, typically the end-user).\n\n## Testing\n\n```sh\n$ npm test\n```\n\n## License\n\n[MIT](LICENSE)\n\n[ci-image]: https://badgen.net/github/checks/jshttp/forwarded/master?label=ci\n[ci-url]: https://github.com/jshttp/forwarded/actions?query=workflow%3Aci\n[npm-image]: https://img.shields.io/npm/v/forwarded.svg\n[npm-url]: https://npmjs.org/package/forwarded\n[node-version-image]: https://img.shields.io/node/v/forwarded.svg\n[node-version-url]: https://nodejs.org/en/download/\n[coveralls-image]: https://img.shields.io/coveralls/jshttp/forwarded/master.svg\n[coveralls-url]: https://coveralls.io/r/jshttp/forwarded?branch=master\n[downloads-image]: https://img.shields.io/npm/dm/forwarded.svg\n[downloads-url]: https://npmjs.org/package/forwarded\n",
        "plugins/auto-review/mcp/node_modules/fresh/README.md": "# fresh\n\n[![NPM Version][npm-image]][npm-url]\n[![NPM Downloads][downloads-image]][downloads-url]\n[![Node.js Version][node-version-image]][node-version-url]\n[![Build Status][ci-image]][ci-url]\n[![Test Coverage][coveralls-image]][coveralls-url]\n\nHTTP response freshness testing\n\n## Installation\n\nThis is a [Node.js](https://nodejs.org/en/) module available through the\n[npm registry](https://www.npmjs.com/). Installation is done using the\n[`npm install` command](https://docs.npmjs.com/getting-started/installing-npm-packages-locally):\n\n```\n$ npm install fresh\n```\n\n## API\n\n```js\nvar fresh = require('fresh')\n```\n\n### fresh(reqHeaders, resHeaders)\n\nCheck freshness of the response using request and response headers.\n\nWhen the response is still \"fresh\" in the client's cache `true` is\nreturned, otherwise `false` is returned to indicate that the client\ncache is now stale and the full response should be sent.\n\nWhen a client sends the `Cache-Control: no-cache` request header to\nindicate an end-to-end reload request, this module will return `false`\nto make handling these requests transparent.\n\n## Known Issues\n\nThis module is designed to only follow the HTTP specifications, not\nto work-around all kinda of client bugs (especially since this module\ntypically does not receive enough information to understand what the\nclient actually is).\n\nThere is a known issue that in certain versions of Safari, Safari\nwill incorrectly make a request that allows this module to validate\nfreshness of the resource even when Safari does not have a\nrepresentation of the resource in the cache. The module\n[jumanji](https://www.npmjs.com/package/jumanji) can be used in\nan Express application to work-around this issue and also provides\nlinks to further reading on this Safari bug.\n\n## Example\n\n### API usage\n\n<!-- eslint-disable no-redeclare -->\n\n```js\nvar reqHeaders = { 'if-none-match': '\"foo\"' }\nvar resHeaders = { etag: '\"bar\"' }\nfresh(reqHeaders, resHeaders)\n// => false\n\nvar reqHeaders = { 'if-none-match': '\"foo\"' }\nvar resHeaders = { etag: '\"foo\"' }\nfresh(reqHeaders, resHeaders)\n// => true\n```\n\n### Using with Node.js http server\n\n```js\nvar fresh = require('fresh')\nvar http = require('http')\n\nvar server = http.createServer(function (req, res) {\n  // perform server logic\n  // ... including adding ETag / Last-Modified response headers\n\n  if (isFresh(req, res)) {\n    // client has a fresh copy of resource\n    res.statusCode = 304\n    res.end()\n    return\n  }\n\n  // send the resource\n  res.statusCode = 200\n  res.end('hello, world!')\n})\n\nfunction isFresh (req, res) {\n  return fresh(req.headers, {\n    etag: res.getHeader('ETag'),\n    'last-modified': res.getHeader('Last-Modified')\n  })\n}\n\nserver.listen(3000)\n```\n\n## License\n\n[MIT](LICENSE)\n\n[ci-image]: https://img.shields.io/github/workflow/status/jshttp/fresh/ci/master?label=ci\n[ci-url]: https://github.com/jshttp/fresh/actions/workflows/ci.yml\n[npm-image]: https://img.shields.io/npm/v/fresh.svg\n[npm-url]: https://npmjs.org/package/fresh\n[node-version-image]: https://img.shields.io/node/v/fresh.svg\n[node-version-url]: https://nodejs.org/en/\n[coveralls-image]: https://img.shields.io/coveralls/jshttp/fresh/master.svg\n[coveralls-url]: https://coveralls.io/r/jshttp/fresh?branch=master\n[downloads-image]: https://img.shields.io/npm/dm/fresh.svg\n[downloads-url]: https://npmjs.org/package/fresh\n",
        "plugins/auto-review/mcp/node_modules/function-bind/README.md": "# function-bind <sup>[![Version Badge][npm-version-svg]][package-url]</sup>\n\n[![github actions][actions-image]][actions-url]\n<!--[![coverage][codecov-image]][codecov-url]-->\n[![dependency status][deps-svg]][deps-url]\n[![dev dependency status][dev-deps-svg]][dev-deps-url]\n[![License][license-image]][license-url]\n[![Downloads][downloads-image]][downloads-url]\n\n[![npm badge][npm-badge-png]][package-url]\n\nImplementation of function.prototype.bind\n\nOld versions of phantomjs, Internet Explorer < 9, and node < 0.6 don't support `Function.prototype.bind`.\n\n## Example\n\n```js\nFunction.prototype.bind = require(\"function-bind\")\n```\n\n## Installation\n\n`npm install function-bind`\n\n## Contributors\n\n - Raynos\n\n## MIT Licenced\n\n[package-url]: https://npmjs.org/package/function-bind\n[npm-version-svg]: https://versionbadg.es/Raynos/function-bind.svg\n[deps-svg]: https://david-dm.org/Raynos/function-bind.svg\n[deps-url]: https://david-dm.org/Raynos/function-bind\n[dev-deps-svg]: https://david-dm.org/Raynos/function-bind/dev-status.svg\n[dev-deps-url]: https://david-dm.org/Raynos/function-bind#info=devDependencies\n[npm-badge-png]: https://nodei.co/npm/function-bind.png?downloads=true&stars=true\n[license-image]: https://img.shields.io/npm/l/function-bind.svg\n[license-url]: LICENSE\n[downloads-image]: https://img.shields.io/npm/dm/function-bind.svg\n[downloads-url]: https://npm-stat.com/charts.html?package=function-bind\n[codecov-image]: https://codecov.io/gh/Raynos/function-bind/branch/main/graphs/badge.svg\n[codecov-url]: https://app.codecov.io/gh/Raynos/function-bind/\n[actions-image]: https://img.shields.io/endpoint?url=https://github-actions-badge-u3jn4tfpocch.runkit.sh/Raynos/function-bind\n[actions-url]: https://github.com/Raynos/function-bind/actions\n",
        "plugins/auto-review/mcp/node_modules/get-intrinsic/README.md": "# get-intrinsic <sup>[![Version Badge][npm-version-svg]][package-url]</sup>\n\n[![github actions][actions-image]][actions-url]\n[![coverage][codecov-image]][codecov-url]\n[![dependency status][deps-svg]][deps-url]\n[![dev dependency status][dev-deps-svg]][dev-deps-url]\n[![License][license-image]][license-url]\n[![Downloads][downloads-image]][downloads-url]\n\n[![npm badge][npm-badge-png]][package-url]\n\nGet and robustly cache all JS language-level intrinsics at first require time.\n\nSee the syntax described [in the JS spec](https://tc39.es/ecma262/#sec-well-known-intrinsic-objects) for reference.\n\n## Example\n\n```js\nvar GetIntrinsic = require('get-intrinsic');\nvar assert = require('assert');\n\n// static methods\nassert.equal(GetIntrinsic('%Math.pow%'), Math.pow);\nassert.equal(Math.pow(2, 3), 8);\nassert.equal(GetIntrinsic('%Math.pow%')(2, 3), 8);\ndelete Math.pow;\nassert.equal(GetIntrinsic('%Math.pow%')(2, 3), 8);\n\n// instance methods\nvar arr = [1];\nassert.equal(GetIntrinsic('%Array.prototype.push%'), Array.prototype.push);\nassert.deepEqual(arr, [1]);\n\narr.push(2);\nassert.deepEqual(arr, [1, 2]);\n\nGetIntrinsic('%Array.prototype.push%').call(arr, 3);\nassert.deepEqual(arr, [1, 2, 3]);\n\ndelete Array.prototype.push;\nGetIntrinsic('%Array.prototype.push%').call(arr, 4);\nassert.deepEqual(arr, [1, 2, 3, 4]);\n\n// missing features\ndelete JSON.parse; // to simulate a real intrinsic that is missing in the environment\nassert.throws(() => GetIntrinsic('%JSON.parse%'));\nassert.equal(undefined, GetIntrinsic('%JSON.parse%', true));\n```\n\n## Tests\nSimply clone the repo, `npm install`, and run `npm test`\n\n## Security\n\nPlease email [@ljharb](https://github.com/ljharb) or see https://tidelift.com/security if you have a potential security vulnerability to report.\n\n[package-url]: https://npmjs.org/package/get-intrinsic\n[npm-version-svg]: https://versionbadg.es/ljharb/get-intrinsic.svg\n[deps-svg]: https://david-dm.org/ljharb/get-intrinsic.svg\n[deps-url]: https://david-dm.org/ljharb/get-intrinsic\n[dev-deps-svg]: https://david-dm.org/ljharb/get-intrinsic/dev-status.svg\n[dev-deps-url]: https://david-dm.org/ljharb/get-intrinsic#info=devDependencies\n[npm-badge-png]: https://nodei.co/npm/get-intrinsic.png?downloads=true&stars=true\n[license-image]: https://img.shields.io/npm/l/get-intrinsic.svg\n[license-url]: LICENSE\n[downloads-image]: https://img.shields.io/npm/dm/get-intrinsic.svg\n[downloads-url]: https://npm-stat.com/charts.html?package=get-intrinsic\n[codecov-image]: https://codecov.io/gh/ljharb/get-intrinsic/branch/main/graphs/badge.svg\n[codecov-url]: https://app.codecov.io/gh/ljharb/get-intrinsic/\n[actions-image]: https://img.shields.io/endpoint?url=https://github-actions-badge-u3jn4tfpocch.runkit.sh/ljharb/get-intrinsic\n[actions-url]: https://github.com/ljharb/get-intrinsic/actions\n",
        "plugins/auto-review/mcp/node_modules/get-proto/README.md": "# get-proto <sup>[![Version Badge][npm-version-svg]][package-url]</sup>\n\n[![github actions][actions-image]][actions-url]\n[![coverage][codecov-image]][codecov-url]\n[![License][license-image]][license-url]\n[![Downloads][downloads-image]][downloads-url]\n\n[![npm badge][npm-badge-png]][package-url]\n\nRobustly get the [[Prototype]] of an object. Uses the best available method.\n\n## Getting started\n\n```sh\nnpm install --save get-proto\n```\n\n## Usage/Examples\n\n```js\nconst assert = require('assert');\nconst getProto = require('get-proto');\n\nconst a = { a: 1, b: 2, [Symbol.toStringTag]: 'foo' };\nconst b = { c: 3, __proto__: a };\n\nassert.equal(getProto(b), a);\nassert.equal(getProto(a), Object.prototype);\nassert.equal(getProto({ __proto__: null }), null);\n```\n\n## Tests\n\nClone the repo, `npm install`, and run `npm test`\n\n[package-url]: https://npmjs.org/package/get-proto\n[npm-version-svg]: https://versionbadg.es/ljharb/get-proto.svg\n[deps-svg]: https://david-dm.org/ljharb/get-proto.svg\n[deps-url]: https://david-dm.org/ljharb/get-proto\n[dev-deps-svg]: https://david-dm.org/ljharb/get-proto/dev-status.svg\n[dev-deps-url]: https://david-dm.org/ljharb/get-proto#info=devDependencies\n[npm-badge-png]: https://nodei.co/npm/get-proto.png?downloads=true&stars=true\n[license-image]: https://img.shields.io/npm/l/get-proto.svg\n[license-url]: LICENSE\n[downloads-image]: https://img.shields.io/npm/dm/get-proto.svg\n[downloads-url]: https://npm-stat.com/charts.html?package=get-proto\n[codecov-image]: https://codecov.io/gh/ljharb/get-proto/branch/main/graphs/badge.svg\n[codecov-url]: https://app.codecov.io/gh/ljharb/get-proto/\n[actions-image]: https://img.shields.io/endpoint?url=https://github-actions-badge-u3jn4tfpocch.runkit.sh/ljharb/get-proto\n[actions-url]: https://github.com/ljharb/get-proto/actions\n",
        "plugins/auto-review/mcp/node_modules/gopd/README.md": "# gopd <sup>[![Version Badge][npm-version-svg]][package-url]</sup>\n\n[![github actions][actions-image]][actions-url]\n[![coverage][codecov-image]][codecov-url]\n[![License][license-image]][license-url]\n[![Downloads][downloads-image]][downloads-url]\n\n[![npm badge][npm-badge-png]][package-url]\n\n`Object.getOwnPropertyDescriptor`, but accounts for IE's broken implementation.\n\n## Usage\n\n```javascript\nvar gOPD = require('gopd');\nvar assert = require('assert');\n\nif (gOPD) {\n\tassert.equal(typeof gOPD, 'function', 'descriptors supported');\n\t// use gOPD like Object.getOwnPropertyDescriptor here\n} else {\n\tassert.ok(!gOPD, 'descriptors not supported');\n}\n```\n\n[package-url]: https://npmjs.org/package/gopd\n[npm-version-svg]: https://versionbadg.es/ljharb/gopd.svg\n[deps-svg]: https://david-dm.org/ljharb/gopd.svg\n[deps-url]: https://david-dm.org/ljharb/gopd\n[dev-deps-svg]: https://david-dm.org/ljharb/gopd/dev-status.svg\n[dev-deps-url]: https://david-dm.org/ljharb/gopd#info=devDependencies\n[npm-badge-png]: https://nodei.co/npm/gopd.png?downloads=true&stars=true\n[license-image]: https://img.shields.io/npm/l/gopd.svg\n[license-url]: LICENSE\n[downloads-image]: https://img.shields.io/npm/dm/gopd.svg\n[downloads-url]: https://npm-stat.com/charts.html?package=gopd\n[codecov-image]: https://codecov.io/gh/ljharb/gopd/branch/main/graphs/badge.svg\n[codecov-url]: https://app.codecov.io/gh/ljharb/gopd/\n[actions-image]: https://img.shields.io/endpoint?url=https://github-actions-badge-u3jn4tfpocch.runkit.sh/ljharb/gopd\n[actions-url]: https://github.com/ljharb/gopd/actions\n",
        "plugins/auto-review/mcp/node_modules/has-symbols/README.md": "# has-symbols <sup>[![Version Badge][2]][1]</sup>\n\n[![github actions][actions-image]][actions-url]\n[![coverage][codecov-image]][codecov-url]\n[![dependency status][5]][6]\n[![dev dependency status][7]][8]\n[![License][license-image]][license-url]\n[![Downloads][downloads-image]][downloads-url]\n\n[![npm badge][11]][1]\n\nDetermine if the JS environment has Symbol support. Supports spec, or shams.\n\n## Example\n\n```js\nvar hasSymbols = require('has-symbols');\n\nhasSymbols() === true; // if the environment has native Symbol support. Not polyfillable, not forgeable.\n\nvar hasSymbolsKinda = require('has-symbols/shams');\nhasSymbolsKinda() === true; // if the environment has a Symbol sham that mostly follows the spec.\n```\n\n## Supported Symbol shams\n - get-own-property-symbols [npm](https://www.npmjs.com/package/get-own-property-symbols) | [github](https://github.com/WebReflection/get-own-property-symbols)\n - core-js [npm](https://www.npmjs.com/package/core-js) | [github](https://github.com/zloirock/core-js)\n\n## Tests\nSimply clone the repo, `npm install`, and run `npm test`\n\n[1]: https://npmjs.org/package/has-symbols\n[2]: https://versionbadg.es/inspect-js/has-symbols.svg\n[5]: https://david-dm.org/inspect-js/has-symbols.svg\n[6]: https://david-dm.org/inspect-js/has-symbols\n[7]: https://david-dm.org/inspect-js/has-symbols/dev-status.svg\n[8]: https://david-dm.org/inspect-js/has-symbols#info=devDependencies\n[11]: https://nodei.co/npm/has-symbols.png?downloads=true&stars=true\n[license-image]: https://img.shields.io/npm/l/has-symbols.svg\n[license-url]: LICENSE\n[downloads-image]: https://img.shields.io/npm/dm/has-symbols.svg\n[downloads-url]: https://npm-stat.com/charts.html?package=has-symbols\n[codecov-image]: https://codecov.io/gh/inspect-js/has-symbols/branch/main/graphs/badge.svg\n[codecov-url]: https://app.codecov.io/gh/inspect-js/has-symbols/\n[actions-image]: https://img.shields.io/endpoint?url=https://github-actions-badge-u3jn4tfpocch.runkit.sh/inspect-js/has-symbols\n[actions-url]: https://github.com/inspect-js/has-symbols/actions\n",
        "plugins/auto-review/mcp/node_modules/hasown/README.md": "# hasown <sup>[![Version Badge][npm-version-svg]][package-url]</sup>\n\n[![github actions][actions-image]][actions-url]\n[![coverage][codecov-image]][codecov-url]\n[![License][license-image]][license-url]\n[![Downloads][downloads-image]][downloads-url]\n\n[![npm badge][npm-badge-png]][package-url]\n\nA robust, ES3 compatible, \"has own property\" predicate.\n\n## Example\n\n```js\nconst assert = require('assert');\nconst hasOwn = require('hasown');\n\nassert.equal(hasOwn({}, 'toString'), false);\nassert.equal(hasOwn([], 'length'), true);\nassert.equal(hasOwn({ a: 42 }, 'a'), true);\n```\n\n## Tests\nSimply clone the repo, `npm install`, and run `npm test`\n\n[package-url]: https://npmjs.org/package/hasown\n[npm-version-svg]: https://versionbadg.es/inspect-js/hasown.svg\n[deps-svg]: https://david-dm.org/inspect-js/hasOwn.svg\n[deps-url]: https://david-dm.org/inspect-js/hasOwn\n[dev-deps-svg]: https://david-dm.org/inspect-js/hasOwn/dev-status.svg\n[dev-deps-url]: https://david-dm.org/inspect-js/hasOwn#info=devDependencies\n[npm-badge-png]: https://nodei.co/npm/hasown.png?downloads=true&stars=true\n[license-image]: https://img.shields.io/npm/l/hasown.svg\n[license-url]: LICENSE\n[downloads-image]: https://img.shields.io/npm/dm/hasown.svg\n[downloads-url]: https://npm-stat.com/charts.html?package=hasown\n[codecov-image]: https://codecov.io/gh/inspect-js/hasOwn/branch/main/graphs/badge.svg\n[codecov-url]: https://app.codecov.io/gh/inspect-js/hasOwn/\n[actions-image]: https://img.shields.io/endpoint?url=https://github-actions-badge-u3jn4tfpocch.runkit.sh/inspect-js/hasOwn\n[actions-url]: https://github.com/inspect-js/hasOwn/actions\n",
        "plugins/auto-review/mcp/node_modules/http-errors/README.md": "# http-errors\n\n[![NPM Version][npm-version-image]][npm-url]\n[![NPM Downloads][npm-downloads-image]][node-url]\n[![Node.js Version][node-image]][node-url]\n[![Build Status][ci-image]][ci-url]\n[![Test Coverage][coveralls-image]][coveralls-url]\n\nCreate HTTP errors for Express, Koa, Connect, etc. with ease.\n\n## Install\n\nThis is a [Node.js](https://nodejs.org/en/) module available through the\n[npm registry](https://www.npmjs.com/). Installation is done using the\n[`npm install` command](https://docs.npmjs.com/getting-started/installing-npm-packages-locally):\n\n```console\n$ npm install http-errors\n```\n\n## Example\n\n```js\nvar createError = require('http-errors')\nvar express = require('express')\nvar app = express()\n\napp.use(function (req, res, next) {\n  if (!req.user) return next(createError(401, 'Please login to view this page.'))\n  next()\n})\n```\n\n## API\n\nThis is the current API, currently extracted from Koa and subject to change.\n\n### Error Properties\n\n- `expose` - can be used to signal if `message` should be sent to the client,\n  defaulting to `false` when `status` >= 500\n- `headers` - can be an object of header names to values to be sent to the\n  client, defaulting to `undefined`. When defined, the key names should all\n  be lower-cased\n- `message` - the traditional error message, which should be kept short and all\n  single line\n- `status` - the status code of the error, mirroring `statusCode` for general\n  compatibility\n- `statusCode` - the status code of the error, defaulting to `500`\n\n### createError([status], [message], [properties])\n\nCreate a new error object with the given message `msg`.\nThe error object inherits from `createError.HttpError`.\n\n```js\nvar err = createError(404, 'This video does not exist!')\n```\n\n- `status: 500` - the status code as a number\n- `message` - the message of the error, defaulting to node's text for that status code.\n- `properties` - custom properties to attach to the object\n\n### createError([status], [error], [properties])\n\nExtend the given `error` object with `createError.HttpError`\nproperties. This will not alter the inheritance of the given\n`error` object, and the modified `error` object is the\nreturn value.\n\n<!-- eslint-disable no-redeclare -->\n\n```js\nfs.readFile('foo.txt', function (err, buf) {\n  if (err) {\n    if (err.code === 'ENOENT') {\n      var httpError = createError(404, err, { expose: false })\n    } else {\n      var httpError = createError(500, err)\n    }\n  }\n})\n```\n\n- `status` - the status code as a number\n- `error` - the error object to extend\n- `properties` - custom properties to attach to the object\n\n### createError.isHttpError(val)\n\nDetermine if the provided `val` is an `HttpError`. This will return `true`\nif the error inherits from the `HttpError` constructor of this module or\nmatches the \"duck type\" for an error this module creates. All outputs from\nthe `createError` factory will return `true` for this function, including\nif an non-`HttpError` was passed into the factory.\n\n### new createError\\[code || name\\](\\[msg]\\))\n\nCreate a new error object with the given message `msg`.\nThe error object inherits from `createError.HttpError`.\n\n```js\nvar err = new createError.NotFound()\n```\n\n- `code` - the status code as a number\n- `name` - the name of the error as a \"bumpy case\", i.e. `NotFound` or `InternalServerError`.\n\n#### List of all constructors\n\n|Status Code|Constructor Name             |\n|-----------|-----------------------------|\n|400        |BadRequest                   |\n|401        |Unauthorized                 |\n|402        |PaymentRequired              |\n|403        |Forbidden                    |\n|404        |NotFound                     |\n|405        |MethodNotAllowed             |\n|406        |NotAcceptable                |\n|407        |ProxyAuthenticationRequired  |\n|408        |RequestTimeout               |\n|409        |Conflict                     |\n|410        |Gone                         |\n|411        |LengthRequired               |\n|412        |PreconditionFailed           |\n|413        |PayloadTooLarge              |\n|414        |URITooLong                   |\n|415        |UnsupportedMediaType         |\n|416        |RangeNotSatisfiable          |\n|417        |ExpectationFailed            |\n|418        |ImATeapot                    |\n|421        |MisdirectedRequest           |\n|422        |UnprocessableEntity          |\n|423        |Locked                       |\n|424        |FailedDependency             |\n|425        |TooEarly                     |\n|426        |UpgradeRequired              |\n|428        |PreconditionRequired         |\n|429        |TooManyRequests              |\n|431        |RequestHeaderFieldsTooLarge  |\n|451        |UnavailableForLegalReasons   |\n|500        |InternalServerError          |\n|501        |NotImplemented               |\n|502        |BadGateway                   |\n|503        |ServiceUnavailable           |\n|504        |GatewayTimeout               |\n|505        |HTTPVersionNotSupported      |\n|506        |VariantAlsoNegotiates        |\n|507        |InsufficientStorage          |\n|508        |LoopDetected                 |\n|509        |BandwidthLimitExceeded       |\n|510        |NotExtended                  |\n|511        |NetworkAuthenticationRequired|\n\n## License\n\n[MIT](LICENSE)\n\n[ci-image]: https://badgen.net/github/checks/jshttp/http-errors/master?label=ci\n[ci-url]: https://github.com/jshttp/http-errors/actions?query=workflow%3Aci\n[coveralls-image]: https://badgen.net/coveralls/c/github/jshttp/http-errors/master\n[coveralls-url]: https://coveralls.io/r/jshttp/http-errors?branch=master\n[node-image]: https://badgen.net/npm/node/http-errors\n[node-url]: https://nodejs.org/en/download\n[npm-downloads-image]: https://badgen.net/npm/dm/http-errors\n[npm-url]: https://npmjs.org/package/http-errors\n[npm-version-image]: https://badgen.net/npm/v/http-errors\n[travis-image]: https://badgen.net/travis/jshttp/http-errors/master\n[travis-url]: https://travis-ci.org/jshttp/http-errors\n",
        "plugins/auto-review/mcp/node_modules/http-errors/node_modules/statuses/README.md": "# statuses\n\n[![NPM Version][npm-version-image]][npm-url]\n[![NPM Downloads][npm-downloads-image]][npm-url]\n[![Node.js Version][node-version-image]][node-version-url]\n[![Build Status][ci-image]][ci-url]\n[![Test Coverage][coveralls-image]][coveralls-url]\n\nHTTP status utility for node.\n\nThis module provides a list of status codes and messages sourced from\na few different projects:\n\n  * The [IANA Status Code Registry](https://www.iana.org/assignments/http-status-codes/http-status-codes.xhtml)\n  * The [Node.js project](https://nodejs.org/)\n  * The [NGINX project](https://www.nginx.com/)\n  * The [Apache HTTP Server project](https://httpd.apache.org/)\n\n## Installation\n\nThis is a [Node.js](https://nodejs.org/en/) module available through the\n[npm registry](https://www.npmjs.com/). Installation is done using the\n[`npm install` command](https://docs.npmjs.com/getting-started/installing-npm-packages-locally):\n\n```sh\n$ npm install statuses\n```\n\n## API\n\n<!-- eslint-disable no-unused-vars -->\n\n```js\nvar status = require('statuses')\n```\n\n### status(code)\n\nReturns the status message string for a known HTTP status code. The code\nmay be a number or a string. An error is thrown for an unknown status code.\n\n<!-- eslint-disable no-undef -->\n\n```js\nstatus(403) // => 'Forbidden'\nstatus('403') // => 'Forbidden'\nstatus(306) // throws\n```\n\n### status(msg)\n\nReturns the numeric status code for a known HTTP status message. The message\nis case-insensitive. An error is thrown for an unknown status message.\n\n<!-- eslint-disable no-undef -->\n\n```js\nstatus('forbidden') // => 403\nstatus('Forbidden') // => 403\nstatus('foo') // throws\n```\n\n### status.codes\n\nReturns an array of all the status codes as `Integer`s.\n\n### status.code[msg]\n\nReturns the numeric status code for a known status message (in lower-case),\notherwise `undefined`.\n\n<!-- eslint-disable no-undef, no-unused-expressions -->\n\n```js\nstatus['not found'] // => 404\n```\n\n### status.empty[code]\n\nReturns `true` if a status code expects an empty body.\n\n<!-- eslint-disable no-undef, no-unused-expressions -->\n\n```js\nstatus.empty[200] // => undefined\nstatus.empty[204] // => true\nstatus.empty[304] // => true\n```\n\n### status.message[code]\n\nReturns the string message for a known numeric status code, otherwise\n`undefined`. This object is the same format as the\n[Node.js http module `http.STATUS_CODES`](https://nodejs.org/dist/latest/docs/api/http.html#http_http_status_codes).\n\n<!-- eslint-disable no-undef, no-unused-expressions -->\n\n```js\nstatus.message[404] // => 'Not Found'\n```\n\n### status.redirect[code]\n\nReturns `true` if a status code is a valid redirect status.\n\n<!-- eslint-disable no-undef, no-unused-expressions -->\n\n```js\nstatus.redirect[200] // => undefined\nstatus.redirect[301] // => true\n```\n\n### status.retry[code]\n\nReturns `true` if you should retry the rest.\n\n<!-- eslint-disable no-undef, no-unused-expressions -->\n\n```js\nstatus.retry[501] // => undefined\nstatus.retry[503] // => true\n```\n\n## License\n\n[MIT](LICENSE)\n\n[ci-image]: https://badgen.net/github/checks/jshttp/statuses/master?label=ci\n[ci-url]: https://github.com/jshttp/statuses/actions?query=workflow%3Aci\n[coveralls-image]: https://badgen.net/coveralls/c/github/jshttp/statuses/master\n[coveralls-url]: https://coveralls.io/r/jshttp/statuses?branch=master\n[node-version-image]: https://badgen.net/npm/node/statuses\n[node-version-url]: https://nodejs.org/en/download\n[npm-downloads-image]: https://badgen.net/npm/dm/statuses\n[npm-url]: https://npmjs.org/package/statuses\n[npm-version-image]: https://badgen.net/npm/v/statuses\n",
        "plugins/auto-review/mcp/node_modules/iconv-lite/README.md": "## iconv-lite: Pure JS character encoding conversion\n\n * No need for native code compilation. Quick to install, works on Windows and in sandboxed environments like [Cloud9](http://c9.io).\n * Used in popular projects like [Express.js (body_parser)](https://github.com/expressjs/body-parser), \n   [Grunt](http://gruntjs.com/), [Nodemailer](http://www.nodemailer.com/), [Yeoman](http://yeoman.io/) and others.\n * Faster than [node-iconv](https://github.com/bnoordhuis/node-iconv) (see below for performance comparison).\n * Intuitive encode/decode API, including Streaming support.\n * In-browser usage via [browserify](https://github.com/substack/node-browserify) or [webpack](https://webpack.js.org/) (~180kb gzip compressed with Buffer shim included).\n * Typescript [type definition file](https://github.com/ashtuchkin/iconv-lite/blob/master/lib/index.d.ts) included.\n * React Native is supported (need to install `stream` module to enable Streaming API).\n * License: MIT.\n\n[![NPM Stats](https://nodei.co/npm/iconv-lite.png)](https://npmjs.org/package/iconv-lite/)  \n[![Build Status](https://travis-ci.org/ashtuchkin/iconv-lite.svg?branch=master)](https://travis-ci.org/ashtuchkin/iconv-lite)\n[![npm](https://img.shields.io/npm/v/iconv-lite.svg)](https://npmjs.org/package/iconv-lite/)\n[![npm downloads](https://img.shields.io/npm/dm/iconv-lite.svg)](https://npmjs.org/package/iconv-lite/)\n[![npm bundle size](https://img.shields.io/bundlephobia/min/iconv-lite.svg)](https://npmjs.org/package/iconv-lite/)\n\n## Usage\n### Basic API\n```javascript\nvar iconv = require('iconv-lite');\n\n// Convert from an encoded buffer to a js string.\nstr = iconv.decode(Buffer.from([0x68, 0x65, 0x6c, 0x6c, 0x6f]), 'win1251');\n\n// Convert from a js string to an encoded buffer.\nbuf = iconv.encode(\"Sample input string\", 'win1251');\n\n// Check if encoding is supported\niconv.encodingExists(\"us-ascii\")\n```\n\n### Streaming API\n```javascript\n\n// Decode stream (from binary data stream to js strings)\nhttp.createServer(function(req, res) {\n    var converterStream = iconv.decodeStream('win1251');\n    req.pipe(converterStream);\n\n    converterStream.on('data', function(str) {\n        console.log(str); // Do something with decoded strings, chunk-by-chunk.\n    });\n});\n\n// Convert encoding streaming example\nfs.createReadStream('file-in-win1251.txt')\n    .pipe(iconv.decodeStream('win1251'))\n    .pipe(iconv.encodeStream('ucs2'))\n    .pipe(fs.createWriteStream('file-in-ucs2.txt'));\n\n// Sugar: all encode/decode streams have .collect(cb) method to accumulate data.\nhttp.createServer(function(req, res) {\n    req.pipe(iconv.decodeStream('win1251')).collect(function(err, body) {\n        assert(typeof body == 'string');\n        console.log(body); // full request body string\n    });\n});\n```\n\n## Supported encodings\n\n *  All node.js native encodings: utf8, ucs2 / utf16-le, ascii, binary, base64, hex.\n *  Additional unicode encodings: utf16, utf16-be, utf-7, utf-7-imap, utf32, utf32-le, and utf32-be.\n *  All widespread singlebyte encodings: Windows 125x family, ISO-8859 family, \n    IBM/DOS codepages, Macintosh family, KOI8 family, all others supported by iconv library. \n    Aliases like 'latin1', 'us-ascii' also supported.\n *  All widespread multibyte encodings: CP932, CP936, CP949, CP950, GB2312, GBK, GB18030, Big5, Shift_JIS, EUC-JP.\n\nSee [all supported encodings on wiki](https://github.com/ashtuchkin/iconv-lite/wiki/Supported-Encodings).\n\nMost singlebyte encodings are generated automatically from [node-iconv](https://github.com/bnoordhuis/node-iconv). Thank you Ben Noordhuis and libiconv authors!\n\nMultibyte encodings are generated from [Unicode.org mappings](http://www.unicode.org/Public/MAPPINGS/) and [WHATWG Encoding Standard mappings](http://encoding.spec.whatwg.org/). Thank you, respective authors!\n\n\n## Encoding/decoding speed\n\nComparison with node-iconv module (1000x256kb, on MacBook Pro, Core i5/2.6 GHz, Node v0.12.0). \nNote: your results may vary, so please always check on your hardware.\n\n    operation             iconv@2.1.4   iconv-lite@0.4.7\n    ----------------------------------------------------------\n    encode('win1251')     ~96 Mb/s      ~320 Mb/s\n    decode('win1251')     ~95 Mb/s      ~246 Mb/s\n\n## BOM handling\n\n * Decoding: BOM is stripped by default, unless overridden by passing `stripBOM: false` in options\n   (f.ex. `iconv.decode(buf, enc, {stripBOM: false})`).\n   A callback might also be given as a `stripBOM` parameter - it'll be called if BOM character was actually found.\n * If you want to detect UTF-8 BOM when decoding other encodings, use [node-autodetect-decoder-stream](https://github.com/danielgindi/node-autodetect-decoder-stream) module.\n * Encoding: No BOM added, unless overridden by `addBOM: true` option.\n\n## UTF-16 Encodings\n\nThis library supports UTF-16LE, UTF-16BE and UTF-16 encodings. First two are straightforward, but UTF-16 is trying to be\nsmart about endianness in the following ways:\n * Decoding: uses BOM and 'spaces heuristic' to determine input endianness. Default is UTF-16LE, but can be \n   overridden with `defaultEncoding: 'utf-16be'` option. Strips BOM unless `stripBOM: false`.\n * Encoding: uses UTF-16LE and writes BOM by default. Use `addBOM: false` to override.\n\n## UTF-32 Encodings\n\nThis library supports UTF-32LE, UTF-32BE and UTF-32 encodings. Like the UTF-16 encoding above, UTF-32 defaults to UTF-32LE, but uses BOM and 'spaces heuristics' to determine input endianness. \n * The default of UTF-32LE can be overridden with the `defaultEncoding: 'utf-32be'` option. Strips BOM unless `stripBOM: false`.\n * Encoding: uses UTF-32LE and writes BOM by default. Use `addBOM: false` to override. (`defaultEncoding: 'utf-32be'` can also be used here to change encoding.)\n\n## Other notes\n\nWhen decoding, be sure to supply a Buffer to decode() method, otherwise [bad things usually happen](https://github.com/ashtuchkin/iconv-lite/wiki/Use-Buffers-when-decoding).  \nUntranslatable characters are set to � or ?. No transliteration is currently supported.  \nNode versions 0.10.31 and 0.11.13 are buggy, don't use them (see #65, #77).  \n\n## Testing\n\n```bash\n$ git clone git@github.com:ashtuchkin/iconv-lite.git\n$ cd iconv-lite\n$ npm install\n$ npm test\n    \n$ # To view performance:\n$ node test/performance.js\n\n$ # To view test coverage:\n$ npm run coverage\n$ open coverage/lcov-report/index.html\n```\n",
        "plugins/auto-review/mcp/node_modules/inherits/README.md": "Browser-friendly inheritance fully compatible with standard node.js\n[inherits](http://nodejs.org/api/util.html#util_util_inherits_constructor_superconstructor).\n\nThis package exports standard `inherits` from node.js `util` module in\nnode environment, but also provides alternative browser-friendly\nimplementation through [browser\nfield](https://gist.github.com/shtylman/4339901). Alternative\nimplementation is a literal copy of standard one located in standalone\nmodule to avoid requiring of `util`. It also has a shim for old\nbrowsers with no `Object.create` support.\n\nWhile keeping you sure you are using standard `inherits`\nimplementation in node.js environment, it allows bundlers such as\n[browserify](https://github.com/substack/node-browserify) to not\ninclude full `util` package to your client code if all you need is\njust `inherits` function. It worth, because browser shim for `util`\npackage is large and `inherits` is often the single function you need\nfrom it.\n\nIt's recommended to use this package instead of\n`require('util').inherits` for any code that has chances to be used\nnot only in node.js but in browser too.\n\n## usage\n\n```js\nvar inherits = require('inherits');\n// then use exactly as the standard one\n```\n\n## note on version ~1.0\n\nVersion ~1.0 had completely different motivation and is not compatible\nneither with 2.0 nor with standard node.js `inherits`.\n\nIf you are using version ~1.0 and planning to switch to ~2.0, be\ncareful:\n\n* new version uses `super_` instead of `super` for referencing\n  superclass\n* new version overwrites current prototype while old one preserves any\n  existing fields on it\n",
        "plugins/auto-review/mcp/node_modules/ipaddr.js/README.md": "# ipaddr.js — an IPv6 and IPv4 address manipulation library [![Build Status](https://travis-ci.org/whitequark/ipaddr.js.svg)](https://travis-ci.org/whitequark/ipaddr.js)\n\nipaddr.js is a small (1.9K minified and gzipped) library for manipulating\nIP addresses in JavaScript environments. It runs on both CommonJS runtimes\n(e.g. [nodejs]) and in a web browser.\n\nipaddr.js allows you to verify and parse string representation of an IP\naddress, match it against a CIDR range or range list, determine if it falls\ninto some reserved ranges (examples include loopback and private ranges),\nand convert between IPv4 and IPv4-mapped IPv6 addresses.\n\n[nodejs]: http://nodejs.org\n\n## Installation\n\n`npm install ipaddr.js`\n\nor\n\n`bower install ipaddr.js`\n\n## API\n\nipaddr.js defines one object in the global scope: `ipaddr`. In CommonJS,\nit is exported from the module:\n\n```js\nvar ipaddr = require('ipaddr.js');\n```\n\nThe API consists of several global methods and two classes: ipaddr.IPv6 and ipaddr.IPv4.\n\n### Global methods\n\nThere are three global methods defined: `ipaddr.isValid`, `ipaddr.parse` and\n`ipaddr.process`. All of them receive a string as a single parameter.\n\nThe `ipaddr.isValid` method returns `true` if the address is a valid IPv4 or\nIPv6 address, and `false` otherwise. It does not throw any exceptions.\n\nThe `ipaddr.parse` method returns an object representing the IP address,\nor throws an `Error` if the passed string is not a valid representation of an\nIP address.\n\nThe `ipaddr.process` method works just like the `ipaddr.parse` one, but it\nautomatically converts IPv4-mapped IPv6 addresses to their IPv4 counterparts\nbefore returning. It is useful when you have a Node.js instance listening\non an IPv6 socket, and the `net.ivp6.bindv6only` sysctl parameter (or its\nequivalent on non-Linux OS) is set to 0. In this case, you can accept IPv4\nconnections on your IPv6-only socket, but the remote address will be mangled.\nUse `ipaddr.process` method to automatically demangle it.\n\n### Object representation\n\nParsing methods return an object which descends from `ipaddr.IPv6` or\n`ipaddr.IPv4`. These objects share some properties, but most of them differ.\n\n#### Shared properties\n\nOne can determine the type of address by calling `addr.kind()`. It will return\neither `\"ipv6\"` or `\"ipv4\"`.\n\nAn address can be converted back to its string representation with `addr.toString()`.\nNote that this method:\n * does not return the original string used to create the object (in fact, there is\n   no way of getting that string)\n * returns a compact representation (when it is applicable)\n\nA `match(range, bits)` method can be used to check if the address falls into a\ncertain CIDR range.\nNote that an address can be (obviously) matched only against an address of the same type.\n\nFor example:\n\n```js\nvar addr = ipaddr.parse(\"2001:db8:1234::1\");\nvar range = ipaddr.parse(\"2001:db8::\");\n\naddr.match(range, 32); // => true\n```\n\nAlternatively, `match` can also be called as `match([range, bits])`. In this way,\nit can be used together with the `parseCIDR(string)` method, which parses an IP\naddress together with a CIDR range.\n\nFor example:\n\n```js\nvar addr = ipaddr.parse(\"2001:db8:1234::1\");\n\naddr.match(ipaddr.parseCIDR(\"2001:db8::/32\")); // => true\n```\n\nA `range()` method returns one of predefined names for several special ranges defined\nby IP protocols. The exact names (and their respective CIDR ranges) can be looked up\nin the source: [IPv6 ranges] and [IPv4 ranges]. Some common ones include `\"unicast\"`\n(the default one) and `\"reserved\"`.\n\nYou can match against your own range list by using\n`ipaddr.subnetMatch(address, rangeList, defaultName)` method. It can work with a mix of IPv6 or IPv4 addresses, and accepts a name-to-subnet map as the range list. For example:\n\n```js\nvar rangeList = {\n  documentationOnly: [ ipaddr.parse('2001:db8::'), 32 ],\n  tunnelProviders: [\n    [ ipaddr.parse('2001:470::'), 32 ], // he.net\n    [ ipaddr.parse('2001:5c0::'), 32 ]  // freenet6\n  ]\n};\nipaddr.subnetMatch(ipaddr.parse('2001:470:8:66::1'), rangeList, 'unknown'); // => \"tunnelProviders\"\n```\n\nThe addresses can be converted to their byte representation with `toByteArray()`.\n(Actually, JavaScript mostly does not know about byte buffers. They are emulated with\narrays of numbers, each in range of 0..255.)\n\n```js\nvar bytes = ipaddr.parse('2a00:1450:8007::68').toByteArray(); // ipv6.google.com\nbytes // => [42, 0x00, 0x14, 0x50, 0x80, 0x07, 0x00, <zeroes...>, 0x00, 0x68 ]\n```\n\nThe `ipaddr.IPv4` and `ipaddr.IPv6` objects have some methods defined, too. All of them\nhave the same interface for both protocols, and are similar to global methods.\n\n`ipaddr.IPvX.isValid(string)` can be used to check if the string is a valid address\nfor particular protocol, and `ipaddr.IPvX.parse(string)` is the error-throwing parser.\n\n`ipaddr.IPvX.isValid(string)` uses the same format for parsing as the POSIX `inet_ntoa` function, which accepts unusual formats like `0xc0.168.1.1` or `0x10000000`. The function `ipaddr.IPv4.isValidFourPartDecimal(string)` validates the IPv4 address and also ensures that it is written in four-part decimal format.\n\n[IPv6 ranges]: https://github.com/whitequark/ipaddr.js/blob/master/src/ipaddr.coffee#L186\n[IPv4 ranges]: https://github.com/whitequark/ipaddr.js/blob/master/src/ipaddr.coffee#L71\n\n#### IPv6 properties\n\nSometimes you will want to convert IPv6 not to a compact string representation (with\nthe `::` substitution); the `toNormalizedString()` method will return an address where\nall zeroes are explicit.\n\nFor example:\n\n```js\nvar addr = ipaddr.parse(\"2001:0db8::0001\");\naddr.toString(); // => \"2001:db8::1\"\naddr.toNormalizedString(); // => \"2001:db8:0:0:0:0:0:1\"\n```\n\nThe `isIPv4MappedAddress()` method will return `true` if this address is an IPv4-mapped\none, and `toIPv4Address()` will return an IPv4 object address.\n\nTo access the underlying binary representation of the address, use `addr.parts`.\n\n```js\nvar addr = ipaddr.parse(\"2001:db8:10::1234:DEAD\");\naddr.parts // => [0x2001, 0xdb8, 0x10, 0, 0, 0, 0x1234, 0xdead]\n```\n\nA IPv6 zone index can be accessed via `addr.zoneId`:\n\n```js\nvar addr = ipaddr.parse(\"2001:db8::%eth0\");\naddr.zoneId // => 'eth0'\n```\n\n#### IPv4 properties\n\n`toIPv4MappedAddress()` will return a corresponding IPv4-mapped IPv6 address.\n\nTo access the underlying representation of the address, use `addr.octets`.\n\n```js\nvar addr = ipaddr.parse(\"192.168.1.1\");\naddr.octets // => [192, 168, 1, 1]\n```\n\n`prefixLengthFromSubnetMask()` will return a CIDR prefix length for a valid IPv4 netmask or\nnull if the netmask is not valid.\n\n```js\nipaddr.IPv4.parse('255.255.255.240').prefixLengthFromSubnetMask() == 28\nipaddr.IPv4.parse('255.192.164.0').prefixLengthFromSubnetMask()  == null\n```\n\n`subnetMaskFromPrefixLength()` will return an IPv4 netmask for a valid CIDR prefix length.\n\n```js\nipaddr.IPv4.subnetMaskFromPrefixLength(24) == \"255.255.255.0\"\nipaddr.IPv4.subnetMaskFromPrefixLength(29) == \"255.255.255.248\"\n```\n\n`broadcastAddressFromCIDR()` will return the broadcast address for a given IPv4 interface and netmask in CIDR notation.\n```js\nipaddr.IPv4.broadcastAddressFromCIDR(\"172.0.0.1/24\") == \"172.0.0.255\"\n```\n`networkAddressFromCIDR()` will return the network address for a given IPv4 interface and netmask in CIDR notation.\n```js\nipaddr.IPv4.networkAddressFromCIDR(\"172.0.0.1/24\") == \"172.0.0.0\"\n```\n\n#### Conversion\n\nIPv4 and IPv6 can be converted bidirectionally to and from network byte order (MSB) byte arrays.\n\nThe `fromByteArray()` method will take an array and create an appropriate IPv4 or IPv6 object\nif the input satisfies the requirements. For IPv4 it has to be an array of four 8-bit values,\nwhile for IPv6 it has to be an array of sixteen 8-bit values.\n\nFor example:\n```js\nvar addr = ipaddr.fromByteArray([0x7f, 0, 0, 1]);\naddr.toString(); // => \"127.0.0.1\"\n```\n\nor\n\n```js\nvar addr = ipaddr.fromByteArray([0x20, 1, 0xd, 0xb8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\naddr.toString(); // => \"2001:db8::1\"\n```\n\nBoth objects also offer a `toByteArray()` method, which returns an array in network byte order (MSB).\n\nFor example:\n```js\nvar addr = ipaddr.parse(\"127.0.0.1\");\naddr.toByteArray(); // => [0x7f, 0, 0, 1]\n```\n\nor\n\n```js\nvar addr = ipaddr.parse(\"2001:db8::1\");\naddr.toByteArray(); // => [0x20, 1, 0xd, 0xb8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n```\n",
        "plugins/auto-review/mcp/node_modules/isexe/README.md": "# isexe\n\nMinimal module to check if a file is executable, and a normal file.\n\nUses `fs.stat` and tests against the `PATHEXT` environment variable on\nWindows.\n\n## USAGE\n\n```javascript\nvar isexe = require('isexe')\nisexe('some-file-name', function (err, isExe) {\n  if (err) {\n    console.error('probably file does not exist or something', err)\n  } else if (isExe) {\n    console.error('this thing can be run')\n  } else {\n    console.error('cannot be run')\n  }\n})\n\n// same thing but synchronous, throws errors\nvar isExe = isexe.sync('some-file-name')\n\n// treat errors as just \"not executable\"\nisexe('maybe-missing-file', { ignoreErrors: true }, callback)\nvar isExe = isexe.sync('maybe-missing-file', { ignoreErrors: true })\n```\n\n## API\n\n### `isexe(path, [options], [callback])`\n\nCheck if the path is executable.  If no callback provided, and a\nglobal `Promise` object is available, then a Promise will be returned.\n\nWill raise whatever errors may be raised by `fs.stat`, unless\n`options.ignoreErrors` is set to true.\n\n### `isexe.sync(path, [options])`\n\nSame as `isexe` but returns the value and throws any errors raised.\n\n### Options\n\n* `ignoreErrors` Treat all errors as \"no, this is not executable\", but\n  don't raise them.\n* `uid` Number to use as the user id\n* `gid` Number to use as the group id\n* `pathExt` List of path extensions to use instead of `PATHEXT`\n  environment variable on Windows.\n",
        "plugins/auto-review/mcp/node_modules/json-schema-traverse/README.md": "# json-schema-traverse\nTraverse JSON Schema passing each schema object to callback\n\n[![build](https://github.com/epoberezkin/json-schema-traverse/workflows/build/badge.svg)](https://github.com/epoberezkin/json-schema-traverse/actions?query=workflow%3Abuild)\n[![npm](https://img.shields.io/npm/v/json-schema-traverse)](https://www.npmjs.com/package/json-schema-traverse)\n[![coverage](https://coveralls.io/repos/github/epoberezkin/json-schema-traverse/badge.svg?branch=master)](https://coveralls.io/github/epoberezkin/json-schema-traverse?branch=master)\n\n\n## Install\n\n```\nnpm install json-schema-traverse\n```\n\n\n## Usage\n\n```javascript\nconst traverse = require('json-schema-traverse');\nconst schema = {\n  properties: {\n    foo: {type: 'string'},\n    bar: {type: 'integer'}\n  }\n};\n\ntraverse(schema, {cb});\n// cb is called 3 times with:\n// 1. root schema\n// 2. {type: 'string'}\n// 3. {type: 'integer'}\n\n// Or:\n\ntraverse(schema, {cb: {pre, post}});\n// pre is called 3 times with:\n// 1. root schema\n// 2. {type: 'string'}\n// 3. {type: 'integer'}\n//\n// post is called 3 times with:\n// 1. {type: 'string'}\n// 2. {type: 'integer'}\n// 3. root schema\n\n```\n\nCallback function `cb` is called for each schema object (not including draft-06 boolean schemas), including the root schema, in pre-order traversal. Schema references ($ref) are not resolved, they are passed as is.  Alternatively, you can pass a `{pre, post}` object as `cb`, and then `pre` will be called before traversing child elements, and `post` will be called after all child elements have been traversed.\n\nCallback is passed these parameters:\n\n- _schema_: the current schema object\n- _JSON pointer_: from the root schema to the current schema object\n- _root schema_: the schema passed to `traverse` object\n- _parent JSON pointer_: from the root schema to the parent schema object (see below)\n- _parent keyword_: the keyword inside which this schema appears (e.g. `properties`, `anyOf`, etc.)\n- _parent schema_: not necessarily parent object/array; in the example above the parent schema for `{type: 'string'}` is the root schema\n- _index/property_: index or property name in the array/object containing multiple schemas; in the example above for `{type: 'string'}` the property name is `'foo'`\n\n\n## Traverse objects in all unknown keywords\n\n```javascript\nconst traverse = require('json-schema-traverse');\nconst schema = {\n  mySchema: {\n    minimum: 1,\n    maximum: 2\n  }\n};\n\ntraverse(schema, {allKeys: true, cb});\n// cb is called 2 times with:\n// 1. root schema\n// 2. mySchema\n```\n\nWithout option `allKeys: true` callback will be called only with root schema.\n\n\n## Enterprise support\n\njson-schema-traverse package is a part of [Tidelift enterprise subscription](https://tidelift.com/subscription/pkg/npm-json-schema-traverse?utm_source=npm-json-schema-traverse&utm_medium=referral&utm_campaign=enterprise&utm_term=repo) - it provides a centralised commercial support to open-source software users, in addition to the support provided by software maintainers.\n\n\n## Security contact\n\nTo report a security vulnerability, please use the\n[Tidelift security contact](https://tidelift.com/security).\nTidelift will coordinate the fix and disclosure. Please do NOT report security vulnerability via GitHub issues.\n\n\n## License\n\n[MIT](https://github.com/epoberezkin/json-schema-traverse/blob/master/LICENSE)\n",
        "plugins/auto-review/mcp/node_modules/math-intrinsics/README.md": "# math-intrinsics <sup>[![Version Badge][npm-version-svg]][package-url]</sup>\n\n[![github actions][actions-image]][actions-url]\n[![coverage][codecov-image]][codecov-url]\n[![License][license-image]][license-url]\n[![Downloads][downloads-image]][downloads-url]\n\n[![npm badge][npm-badge-png]][package-url]\n\nES Math-related intrinsics and helpers, robustly cached.\n\n - `abs`\n - `floor`\n - `isFinite`\n - `isInteger`\n - `isNaN`\n - `isNegativeZero`\n - `max`\n - `min`\n - `mod`\n - `pow`\n - `round`\n - `sign`\n - `constants/maxArrayLength`\n - `constants/maxSafeInteger`\n - `constants/maxValue`\n\n\n## Tests\nSimply clone the repo, `npm install`, and run `npm test`\n\n## Security\n\nPlease email [@ljharb](https://github.com/ljharb) or see https://tidelift.com/security if you have a potential security vulnerability to report.\n\n[package-url]: https://npmjs.org/package/math-intrinsics\n[npm-version-svg]: https://versionbadg.es/es-shims/math-intrinsics.svg\n[deps-svg]: https://david-dm.org/es-shims/math-intrinsics.svg\n[deps-url]: https://david-dm.org/es-shims/math-intrinsics\n[dev-deps-svg]: https://david-dm.org/es-shims/math-intrinsics/dev-status.svg\n[dev-deps-url]: https://david-dm.org/es-shims/math-intrinsics#info=devDependencies\n[npm-badge-png]: https://nodei.co/npm/math-intrinsics.png?downloads=true&stars=true\n[license-image]: https://img.shields.io/npm/l/math-intrinsics.svg\n[license-url]: LICENSE\n[downloads-image]: https://img.shields.io/npm/dm/es-object.svg\n[downloads-url]: https://npm-stat.com/charts.html?package=math-intrinsics\n[codecov-image]: https://codecov.io/gh/es-shims/math-intrinsics/branch/main/graphs/badge.svg\n[codecov-url]: https://app.codecov.io/gh/es-shims/math-intrinsics/\n[actions-image]: https://img.shields.io/endpoint?url=https://github-actions-badge-u3jn4tfpocch.runkit.sh/es-shims/math-intrinsics\n[actions-url]: https://github.com/es-shims/math-intrinsics/actions\n",
        "plugins/auto-review/mcp/node_modules/media-typer/README.md": "# media-typer\n\n[![NPM Version][npm-version-image]][npm-url]\n[![NPM Downloads][npm-downloads-image]][npm-url]\n[![Node.js Version][node-version-image]][node-version-url]\n[![Build Status][travis-image]][travis-url]\n[![Test Coverage][coveralls-image]][coveralls-url]\n\nSimple RFC 6838 media type parser.\n\nThis module will parse a given media type into it's component parts, like type,\nsubtype, and suffix. A formatter is also provided to put them back together and\nthe two can be combined to normalize media types into a canonical form.\n\nIf you are looking to parse the string that represents a media type and it's\nparameters in HTTP (for example, the `Content-Type` header), use the\n[content-type module](https://www.npmjs.com/package/content-type).\n\n## Installation\n\nThis is a [Node.js](https://nodejs.org/en/) module available through the\n[npm registry](https://www.npmjs.com/). Installation is done using the\n[`npm install` command](https://docs.npmjs.com/getting-started/installing-npm-packages-locally):\n\n```sh\n$ npm install media-typer\n```\n\n## API\n\n<!-- eslint-disable no-unused-vars -->\n\n```js\nvar typer = require('media-typer')\n```\n\n### typer.parse(string)\n\n<!-- eslint-disable no-undef, no-unused-vars -->\n\n```js\nvar obj = typer.parse('image/svg+xml')\n```\n\nParse a media type string. This will return an object with the following\nproperties (examples are shown for the string `'image/svg+xml; charset=utf-8'`):\n\n - `type`: The type of the media type (always lower case). Example: `'image'`\n\n - `subtype`: The subtype of the media type (always lower case). Example: `'svg'`\n\n - `suffix`: The suffix of the media type (always lower case). Example: `'xml'`\n\nIf the given type string is invalid, then a `TypeError` is thrown.\n\n### typer.format(obj)\n\n<!-- eslint-disable no-undef, no-unused-vars -->\n\n```js\nvar obj = typer.format({ type: 'image', subtype: 'svg', suffix: 'xml' })\n```\n\nFormat an object into a media type string. This will return a string of the\nmime type for the given object. For the properties of the object, see the\ndocumentation for `typer.parse(string)`.\n\nIf any of the given object values are invalid, then a `TypeError` is thrown.\n\n### typer.test(string)\n\n<!-- eslint-disable no-undef, no-unused-vars -->\n\n```js\nvar valid = typer.test('image/svg+xml')\n```\n\nValidate a media type string. This will return `true` is the string is a well-\nformatted media type, or `false` otherwise.\n\n## License\n\n[MIT](LICENSE)\n\n[coveralls-image]: https://badgen.net/coveralls/c/github/jshttp/media-typer/master\n[coveralls-url]: https://coveralls.io/r/jshttp/media-typer?branch=master\n[node-version-image]: https://badgen.net/npm/node/media-typer\n[node-version-url]: https://nodejs.org/en/download\n[npm-downloads-image]: https://badgen.net/npm/dm/media-typer\n[npm-url]: https://npmjs.org/package/media-typer\n[npm-version-image]: https://badgen.net/npm/v/media-typer\n[travis-image]: https://badgen.net/travis/jshttp/media-typer/master\n[travis-url]: https://travis-ci.org/jshttp/media-typer\n",
        "plugins/auto-review/mcp/node_modules/mime-db/README.md": "# mime-db\n\n[![NPM Version][npm-version-image]][npm-url]\n[![NPM Downloads][npm-downloads-image]][npm-url]\n[![Node.js Version][node-image]][node-url]\n[![Build Status][ci-image]][ci-url]\n[![Coverage Status][coveralls-image]][coveralls-url]\n\nThis is a large database of mime types and information about them.\nIt consists of a single, public JSON file and does not include any logic,\nallowing it to remain as un-opinionated as possible with an API.\nIt aggregates data from the following sources:\n\n- https://www.iana.org/assignments/media-types/media-types.xhtml\n- https://svn.apache.org/repos/asf/httpd/httpd/trunk/docs/conf/mime.types\n- https://hg.nginx.org/nginx/raw-file/default/conf/mime.types\n\n## Installation\n\n```bash\nnpm install mime-db\n```\n\n### Database Download\n\nIf you intend to use this in a web browser, you can conveniently access the JSON file via [jsDelivr](https://www.jsdelivr.com/), a popular CDN (Content Delivery Network). To ensure stability and compatibility, it is advisable to specify [a release tag](https://github.com/jshttp/mime-db/tags) instead of using the 'master' branch. This is because the JSON file's format might change in future updates, and relying on a specific release tag will prevent potential issues arising from these changes.\n\n```\nhttps://cdn.jsdelivr.net/gh/jshttp/mime-db@master/db.json\n```\n\n## Usage\n\n```js\nvar db = require('mime-db')\n\n// grab data on .js files\nvar data = db['application/javascript']\n```\n\n## Data Structure\n\nThe JSON file is a map lookup for lowercased mime types.\nEach mime type has the following properties:\n\n- `.source` - where the mime type is defined.\n    If not set, it's probably a custom media type.\n    - `apache` - [Apache common media types](https://svn.apache.org/repos/asf/httpd/httpd/trunk/docs/conf/mime.types)\n    - `iana` - [IANA-defined media types](https://www.iana.org/assignments/media-types/media-types.xhtml)\n    - `nginx` - [nginx media types](https://hg.nginx.org/nginx/raw-file/default/conf/mime.types)\n- `.extensions[]` - known extensions associated with this mime type.\n- `.compressible` - whether a file of this type can be gzipped.\n- `.charset` - the default charset associated with this type, if any.\n\nIf unknown, every property could be `undefined`.\n\n## Note on MIME Type Data and Semver\n\nThis package considers the programmatic api as the semver compatibility. This means the MIME type resolution is *not* considered\nin the semver bumps. This means that if you want to pin your `mime-db` data you will need to do it in your application. While\nthis expectation was not set in docs until now, it is how the pacakge operated, so we do not feel this is a breaking change.\n\n## Contributing\n\nThe primary way to contribute to this database is by updating the data in\none of the upstream sources. The database is updated from the upstreams\nperiodically and will pull in any changes.\n\n### Registering Media Types\n\nThe best way to get new media types included in this library is to register\nthem with the IANA. The community registration procedure is outlined in\n[RFC 6838 section 5](https://tools.ietf.org/html/rfc6838#section-5). Types\nregistered with the IANA are automatically pulled into this library.\n\n### Direct Inclusion\n\nIf that is not possible / feasible, they can be added directly here as a\n\"custom\" type. To do this, it is required to have a primary source that\ndefinitively lists the media type. If an extension is going to be listed as\nassociated with this media type, the source must definitively link the\nmedia type and extension as well.\n\nTo edit the database, only make PRs against `src/custom-types.json` or\n`src/custom-suffix.json`.\n\nThe `src/custom-types.json` file is a JSON object with the MIME type as the\nkeys and the values being an object with the following keys:\n\n- `compressible` - leave out if you don't know, otherwise `true`/`false` to\n  indicate whether the data represented by the type is typically compressible.\n- `extensions` - include an array of file extensions that are associated with\n  the type.\n- `notes` - human-readable notes about the type, typically what the type is.\n- `sources` - include an array of URLs of where the MIME type and the associated\n  extensions are sourced from. This needs to be a [primary source](https://en.wikipedia.org/wiki/Primary_source);\n  links to type aggregating sites and Wikipedia are _not acceptable_.\n\nTo update the build, run `npm run build`.\n\n[ci-image]: https://badgen.net/github/checks/jshttp/mime-db/master?label=ci\n[ci-url]: https://github.com/jshttp/mime-db/actions/workflows/ci.yml\n[coveralls-image]: https://badgen.net/coveralls/c/github/jshttp/mime-db/master\n[coveralls-url]: https://coveralls.io/r/jshttp/mime-db?branch=master\n[node-image]: https://badgen.net/npm/node/mime-db\n[node-url]: https://nodejs.org/en/download\n[npm-downloads-image]: https://badgen.net/npm/dm/mime-db\n[npm-url]: https://npmjs.org/package/mime-db\n[npm-version-image]: https://badgen.net/npm/v/mime-db\n",
        "plugins/auto-review/mcp/node_modules/mime-types/README.md": "# mime-types\n\n[![NPM Version][npm-version-image]][npm-url]\n[![NPM Downloads][npm-downloads-image]][npm-url]\n[![Node.js Version][node-version-image]][node-version-url]\n[![Build Status][ci-image]][ci-url]\n[![Test Coverage][coveralls-image]][coveralls-url]\n\nThe ultimate javascript content-type utility.\n\nSimilar to [the `mime@1.x` module](https://www.npmjs.com/package/mime), except:\n\n- __No fallbacks.__ Instead of naively returning the first available type,\n  `mime-types` simply returns `false`, so do\n  `var type = mime.lookup('unrecognized') || 'application/octet-stream'`.\n- No `new Mime()` business, so you could do `var lookup = require('mime-types').lookup`.\n- No `.define()` functionality\n- Bug fixes for `.lookup(path)`\n\nOtherwise, the API is compatible with `mime` 1.x.\n\n## Install\n\nThis is a [Node.js](https://nodejs.org/en/) module available through the\n[npm registry](https://www.npmjs.com/). Installation is done using the\n[`npm install` command](https://docs.npmjs.com/getting-started/installing-npm-packages-locally):\n\n```sh\n$ npm install mime-types\n```\n\n## Note on MIME Type Data and Semver\n\nThis package considers the programmatic api as the semver compatibility. Additionally, the package which provides the MIME data\nfor this package (`mime-db`) *also* considers it's programmatic api as the semver contract. This means the MIME type resolution is *not* considered\nin the semver bumps.\n\nIn the past the version of `mime-db` was pinned to give two decision points when adopting MIME data changes. This is no longer true. We still update the\n`mime-db` package here as a `minor` release when necessary, but will use a `^` range going forward. This means that if you want to pin your `mime-db` data\nyou will need to do it in your application. While this expectation was not set in docs until now, it is how the pacakge operated, so we do not feel this is\na breaking change.\n\nIf you wish to pin your `mime-db` version you can do that with overrides via your package manager of choice. See their documentation for how to correctly configure that.\n\n## Adding Types\n\nAll mime types are based on [mime-db](https://www.npmjs.com/package/mime-db),\nso open a PR there if you'd like to add mime types.\n\n## API\n\n```js\nvar mime = require('mime-types')\n```\n\nAll functions return `false` if input is invalid or not found.\n\n### mime.lookup(path)\n\nLookup the content-type associated with a file.\n\n```js\nmime.lookup('json') // 'application/json'\nmime.lookup('.md') // 'text/markdown'\nmime.lookup('file.html') // 'text/html'\nmime.lookup('folder/file.js') // 'application/javascript'\nmime.lookup('folder/.htaccess') // false\n\nmime.lookup('cats') // false\n```\n\n### mime.contentType(type)\n\nCreate a full content-type header given a content-type or extension.\nWhen given an extension, `mime.lookup` is used to get the matching\ncontent-type, otherwise the given content-type is used. Then if the\ncontent-type does not already have a `charset` parameter, `mime.charset`\nis used to get the default charset and add to the returned content-type.\n\n```js\nmime.contentType('markdown') // 'text/x-markdown; charset=utf-8'\nmime.contentType('file.json') // 'application/json; charset=utf-8'\nmime.contentType('text/html') // 'text/html; charset=utf-8'\nmime.contentType('text/html; charset=iso-8859-1') // 'text/html; charset=iso-8859-1'\n\n// from a full path\nmime.contentType(path.extname('/path/to/file.json')) // 'application/json; charset=utf-8'\n```\n\n### mime.extension(type)\n\nGet the default extension for a content-type.\n\n```js\nmime.extension('application/octet-stream') // 'bin'\n```\n\n### mime.charset(type)\n\nLookup the implied default charset of a content-type.\n\n```js\nmime.charset('text/markdown') // 'UTF-8'\n```\n\n### var type = mime.types[extension]\n\nA map of content-types by extension.\n\n### [extensions...] = mime.extensions[type]\n\nA map of extensions by content-type.\n\n## License\n\n[MIT](LICENSE)\n\n[ci-image]: https://badgen.net/github/checks/jshttp/mime-types/master?label=ci\n[ci-url]: https://github.com/jshttp/mime-types/actions/workflows/ci.yml\n[coveralls-image]: https://badgen.net/coveralls/c/github/jshttp/mime-types/master\n[coveralls-url]: https://coveralls.io/r/jshttp/mime-types?branch=master\n[node-version-image]: https://badgen.net/npm/node/mime-types\n[node-version-url]: https://nodejs.org/en/download\n[npm-downloads-image]: https://badgen.net/npm/dm/mime-types\n[npm-url]: https://npmjs.org/package/mime-types\n[npm-version-image]: https://badgen.net/npm/v/mime-types\n",
        "plugins/auto-review/mcp/node_modules/negotiator/README.md": "# negotiator\n\n[![NPM Version][npm-image]][npm-url]\n[![NPM Downloads][downloads-image]][downloads-url]\n[![Node.js Version][node-version-image]][node-version-url]\n[![Build Status][github-actions-ci-image]][github-actions-ci-url]\n[![Test Coverage][coveralls-image]][coveralls-url]\n\nAn HTTP content negotiator for Node.js\n\n## Installation\n\n```sh\n$ npm install negotiator\n```\n\n## API\n\n```js\nvar Negotiator = require('negotiator')\n```\n\n### Accept Negotiation\n\n```js\navailableMediaTypes = ['text/html', 'text/plain', 'application/json']\n\n// The negotiator constructor receives a request object\nnegotiator = new Negotiator(request)\n\n// Let's say Accept header is 'text/html, application/*;q=0.2, image/jpeg;q=0.8'\n\nnegotiator.mediaTypes()\n// -> ['text/html', 'image/jpeg', 'application/*']\n\nnegotiator.mediaTypes(availableMediaTypes)\n// -> ['text/html', 'application/json']\n\nnegotiator.mediaType(availableMediaTypes)\n// -> 'text/html'\n```\n\nYou can check a working example at `examples/accept.js`.\n\n#### Methods\n\n##### mediaType()\n\nReturns the most preferred media type from the client.\n\n##### mediaType(availableMediaType)\n\nReturns the most preferred media type from a list of available media types.\n\n##### mediaTypes()\n\nReturns an array of preferred media types ordered by the client preference.\n\n##### mediaTypes(availableMediaTypes)\n\nReturns an array of preferred media types ordered by priority from a list of\navailable media types.\n\n### Accept-Language Negotiation\n\n```js\nnegotiator = new Negotiator(request)\n\navailableLanguages = ['en', 'es', 'fr']\n\n// Let's say Accept-Language header is 'en;q=0.8, es, pt'\n\nnegotiator.languages()\n// -> ['es', 'pt', 'en']\n\nnegotiator.languages(availableLanguages)\n// -> ['es', 'en']\n\nlanguage = negotiator.language(availableLanguages)\n// -> 'es'\n```\n\nYou can check a working example at `examples/language.js`.\n\n#### Methods\n\n##### language()\n\nReturns the most preferred language from the client.\n\n##### language(availableLanguages)\n\nReturns the most preferred language from a list of available languages.\n\n##### languages()\n\nReturns an array of preferred languages ordered by the client preference.\n\n##### languages(availableLanguages)\n\nReturns an array of preferred languages ordered by priority from a list of\navailable languages.\n\n### Accept-Charset Negotiation\n\n```js\navailableCharsets = ['utf-8', 'iso-8859-1', 'iso-8859-5']\n\nnegotiator = new Negotiator(request)\n\n// Let's say Accept-Charset header is 'utf-8, iso-8859-1;q=0.8, utf-7;q=0.2'\n\nnegotiator.charsets()\n// -> ['utf-8', 'iso-8859-1', 'utf-7']\n\nnegotiator.charsets(availableCharsets)\n// -> ['utf-8', 'iso-8859-1']\n\nnegotiator.charset(availableCharsets)\n// -> 'utf-8'\n```\n\nYou can check a working example at `examples/charset.js`.\n\n#### Methods\n\n##### charset()\n\nReturns the most preferred charset from the client.\n\n##### charset(availableCharsets)\n\nReturns the most preferred charset from a list of available charsets.\n\n##### charsets()\n\nReturns an array of preferred charsets ordered by the client preference.\n\n##### charsets(availableCharsets)\n\nReturns an array of preferred charsets ordered by priority from a list of\navailable charsets.\n\n### Accept-Encoding Negotiation\n\n```js\navailableEncodings = ['identity', 'gzip']\n\nnegotiator = new Negotiator(request)\n\n// Let's say Accept-Encoding header is 'gzip, compress;q=0.2, identity;q=0.5'\n\nnegotiator.encodings()\n// -> ['gzip', 'identity', 'compress']\n\nnegotiator.encodings(availableEncodings)\n// -> ['gzip', 'identity']\n\nnegotiator.encoding(availableEncodings)\n// -> 'gzip'\n```\n\nYou can check a working example at `examples/encoding.js`.\n\n#### Methods\n\n##### encoding()\n\nReturns the most preferred encoding from the client.\n\n##### encoding(availableEncodings)\n\nReturns the most preferred encoding from a list of available encodings.\n\n##### encoding(availableEncodings, { preferred })\n\nReturns the most preferred encoding from a list of available encodings, while prioritizing based on `preferred` array between same-quality encodings.\n\n##### encodings()\n\nReturns an array of preferred encodings ordered by the client preference.\n\n##### encodings(availableEncodings)\n\nReturns an array of preferred encodings ordered by priority from a list of\navailable encodings.\n\n##### encodings(availableEncodings, { preferred })\n\nReturns an array of preferred encodings ordered by priority from a list of\navailable encodings, while prioritizing based on `preferred` array between same-quality encodings.\n\n## See Also\n\nThe [accepts](https://npmjs.org/package/accepts#readme) module builds on\nthis module and provides an alternative interface, mime type validation,\nand more.\n\n## License\n\n[MIT](LICENSE)\n\n[npm-image]: https://img.shields.io/npm/v/negotiator.svg\n[npm-url]: https://npmjs.org/package/negotiator\n[node-version-image]: https://img.shields.io/node/v/negotiator.svg\n[node-version-url]: https://nodejs.org/en/download/\n[coveralls-image]: https://img.shields.io/coveralls/jshttp/negotiator/master.svg\n[coveralls-url]: https://coveralls.io/r/jshttp/negotiator?branch=master\n[downloads-image]: https://img.shields.io/npm/dm/negotiator.svg\n[downloads-url]: https://npmjs.org/package/negotiator\n[github-actions-ci-image]: https://img.shields.io/github/workflow/status/jshttp/negotiator/ci/master?label=ci\n[github-actions-ci-url]: https://github.com/jshttp/negotiator/actions/workflows/ci.yml\n",
        "plugins/auto-review/mcp/node_modules/on-finished/README.md": "# on-finished\n\n[![NPM Version][npm-version-image]][npm-url]\n[![NPM Downloads][npm-downloads-image]][npm-url]\n[![Node.js Version][node-image]][node-url]\n[![Build Status][ci-image]][ci-url]\n[![Coverage Status][coveralls-image]][coveralls-url]\n\nExecute a callback when a HTTP request closes, finishes, or errors.\n\n## Install\n\nThis is a [Node.js](https://nodejs.org/en/) module available through the\n[npm registry](https://www.npmjs.com/). Installation is done using the\n[`npm install` command](https://docs.npmjs.com/getting-started/installing-npm-packages-locally):\n\n```sh\n$ npm install on-finished\n```\n\n## API\n\n```js\nvar onFinished = require('on-finished')\n```\n\n### onFinished(res, listener)\n\nAttach a listener to listen for the response to finish. The listener will\nbe invoked only once when the response finished. If the response finished\nto an error, the first argument will contain the error. If the response\nhas already finished, the listener will be invoked.\n\nListening to the end of a response would be used to close things associated\nwith the response, like open files.\n\nListener is invoked as `listener(err, res)`.\n\n<!-- eslint-disable handle-callback-err -->\n\n```js\nonFinished(res, function (err, res) {\n  // clean up open fds, etc.\n  // err contains the error if request error'd\n})\n```\n\n### onFinished(req, listener)\n\nAttach a listener to listen for the request to finish. The listener will\nbe invoked only once when the request finished. If the request finished\nto an error, the first argument will contain the error. If the request\nhas already finished, the listener will be invoked.\n\nListening to the end of a request would be used to know when to continue\nafter reading the data.\n\nListener is invoked as `listener(err, req)`.\n\n<!-- eslint-disable handle-callback-err -->\n\n```js\nvar data = ''\n\nreq.setEncoding('utf8')\nreq.on('data', function (str) {\n  data += str\n})\n\nonFinished(req, function (err, req) {\n  // data is read unless there is err\n})\n```\n\n### onFinished.isFinished(res)\n\nDetermine if `res` is already finished. This would be useful to check and\nnot even start certain operations if the response has already finished.\n\n### onFinished.isFinished(req)\n\nDetermine if `req` is already finished. This would be useful to check and\nnot even start certain operations if the request has already finished.\n\n## Special Node.js requests\n\n### HTTP CONNECT method\n\nThe meaning of the `CONNECT` method from RFC 7231, section 4.3.6:\n\n> The CONNECT method requests that the recipient establish a tunnel to\n> the destination origin server identified by the request-target and,\n> if successful, thereafter restrict its behavior to blind forwarding\n> of packets, in both directions, until the tunnel is closed.  Tunnels\n> are commonly used to create an end-to-end virtual connection, through\n> one or more proxies, which can then be secured using TLS (Transport\n> Layer Security, [RFC5246]).\n\nIn Node.js, these request objects come from the `'connect'` event on\nthe HTTP server.\n\nWhen this module is used on a HTTP `CONNECT` request, the request is\nconsidered \"finished\" immediately, **due to limitations in the Node.js\ninterface**. This means if the `CONNECT` request contains a request entity,\nthe request will be considered \"finished\" even before it has been read.\n\nThere is no such thing as a response object to a `CONNECT` request in\nNode.js, so there is no support for one.\n\n### HTTP Upgrade request\n\nThe meaning of the `Upgrade` header from RFC 7230, section 6.1:\n\n> The \"Upgrade\" header field is intended to provide a simple mechanism\n> for transitioning from HTTP/1.1 to some other protocol on the same\n> connection.\n\nIn Node.js, these request objects come from the `'upgrade'` event on\nthe HTTP server.\n\nWhen this module is used on a HTTP request with an `Upgrade` header, the\nrequest is considered \"finished\" immediately, **due to limitations in the\nNode.js interface**. This means if the `Upgrade` request contains a request\nentity, the request will be considered \"finished\" even before it has been\nread.\n\nThere is no such thing as a response object to a `Upgrade` request in\nNode.js, so there is no support for one.\n\n## Example\n\nThe following code ensures that file descriptors are always closed\nonce the response finishes.\n\n```js\nvar destroy = require('destroy')\nvar fs = require('fs')\nvar http = require('http')\nvar onFinished = require('on-finished')\n\nhttp.createServer(function onRequest (req, res) {\n  var stream = fs.createReadStream('package.json')\n  stream.pipe(res)\n  onFinished(res, function () {\n    destroy(stream)\n  })\n})\n```\n\n## License\n\n[MIT](LICENSE)\n\n[ci-image]: https://badgen.net/github/checks/jshttp/on-finished/master?label=ci\n[ci-url]: https://github.com/jshttp/on-finished/actions/workflows/ci.yml\n[coveralls-image]: https://badgen.net/coveralls/c/github/jshttp/on-finished/master\n[coveralls-url]: https://coveralls.io/r/jshttp/on-finished?branch=master\n[node-image]: https://badgen.net/npm/node/on-finished\n[node-url]: https://nodejs.org/en/download\n[npm-downloads-image]: https://badgen.net/npm/dm/on-finished\n[npm-url]: https://npmjs.org/package/on-finished\n[npm-version-image]: https://badgen.net/npm/v/on-finished\n",
        "plugins/auto-review/mcp/node_modules/once/README.md": "# once\n\nOnly call a function once.\n\n## usage\n\n```javascript\nvar once = require('once')\n\nfunction load (file, cb) {\n  cb = once(cb)\n  loader.load('file')\n  loader.once('load', cb)\n  loader.once('error', cb)\n}\n```\n\nOr add to the Function.prototype in a responsible way:\n\n```javascript\n// only has to be done once\nrequire('once').proto()\n\nfunction load (file, cb) {\n  cb = cb.once()\n  loader.load('file')\n  loader.once('load', cb)\n  loader.once('error', cb)\n}\n```\n\nIronically, the prototype feature makes this module twice as\ncomplicated as necessary.\n\nTo check whether you function has been called, use `fn.called`. Once the\nfunction is called for the first time the return value of the original\nfunction is saved in `fn.value` and subsequent calls will continue to\nreturn this value.\n\n```javascript\nvar once = require('once')\n\nfunction load (cb) {\n  cb = once(cb)\n  var stream = createStream()\n  stream.once('data', cb)\n  stream.once('end', function () {\n    if (!cb.called) cb(new Error('not found'))\n  })\n}\n```\n\n## `once.strict(func)`\n\nThrow an error if the function is called twice.\n\nSome functions are expected to be called only once. Using `once` for them would\npotentially hide logical errors.\n\nIn the example below, the `greet` function has to call the callback only once:\n\n```javascript\nfunction greet (name, cb) {\n  // return is missing from the if statement\n  // when no name is passed, the callback is called twice\n  if (!name) cb('Hello anonymous')\n  cb('Hello ' + name)\n}\n\nfunction log (msg) {\n  console.log(msg)\n}\n\n// this will print 'Hello anonymous' but the logical error will be missed\ngreet(null, once(msg))\n\n// once.strict will print 'Hello anonymous' and throw an error when the callback will be called the second time\ngreet(null, once.strict(msg))\n```\n",
        "plugins/auto-review/mcp/node_modules/parseurl/README.md": "# parseurl\n\n[![NPM Version][npm-version-image]][npm-url]\n[![NPM Downloads][npm-downloads-image]][npm-url]\n[![Node.js Version][node-image]][node-url]\n[![Build Status][travis-image]][travis-url]\n[![Test Coverage][coveralls-image]][coveralls-url]\n\nParse a URL with memoization.\n\n## Install\n\nThis is a [Node.js](https://nodejs.org/en/) module available through the\n[npm registry](https://www.npmjs.com/). Installation is done using the\n[`npm install` command](https://docs.npmjs.com/getting-started/installing-npm-packages-locally):\n\n```sh\n$ npm install parseurl\n```\n\n## API\n\n```js\nvar parseurl = require('parseurl')\n```\n\n### parseurl(req)\n\nParse the URL of the given request object (looks at the `req.url` property)\nand return the result. The result is the same as `url.parse` in Node.js core.\nCalling this function multiple times on the same `req` where `req.url` does\nnot change will return a cached parsed object, rather than parsing again.\n\n### parseurl.original(req)\n\nParse the original URL of the given request object and return the result.\nThis works by trying to parse `req.originalUrl` if it is a string, otherwise\nparses `req.url`. The result is the same as `url.parse` in Node.js core.\nCalling this function multiple times on the same `req` where `req.originalUrl`\ndoes not change will return a cached parsed object, rather than parsing again.\n\n## Benchmark\n\n```bash\n$ npm run-script bench\n\n> parseurl@1.3.3 bench nodejs-parseurl\n> node benchmark/index.js\n\n  http_parser@2.8.0\n  node@10.6.0\n  v8@6.7.288.46-node.13\n  uv@1.21.0\n  zlib@1.2.11\n  ares@1.14.0\n  modules@64\n  nghttp2@1.32.0\n  napi@3\n  openssl@1.1.0h\n  icu@61.1\n  unicode@10.0\n  cldr@33.0\n  tz@2018c\n\n> node benchmark/fullurl.js\n\n  Parsing URL \"http://localhost:8888/foo/bar?user=tj&pet=fluffy\"\n\n  4 tests completed.\n\n  fasturl            x 2,207,842 ops/sec ±3.76% (184 runs sampled)\n  nativeurl - legacy x   507,180 ops/sec ±0.82% (191 runs sampled)\n  nativeurl - whatwg x   290,044 ops/sec ±1.96% (189 runs sampled)\n  parseurl           x   488,907 ops/sec ±2.13% (192 runs sampled)\n\n> node benchmark/pathquery.js\n\n  Parsing URL \"/foo/bar?user=tj&pet=fluffy\"\n\n  4 tests completed.\n\n  fasturl            x 3,812,564 ops/sec ±3.15% (188 runs sampled)\n  nativeurl - legacy x 2,651,631 ops/sec ±1.68% (189 runs sampled)\n  nativeurl - whatwg x   161,837 ops/sec ±2.26% (189 runs sampled)\n  parseurl           x 4,166,338 ops/sec ±2.23% (184 runs sampled)\n\n> node benchmark/samerequest.js\n\n  Parsing URL \"/foo/bar?user=tj&pet=fluffy\" on same request object\n\n  4 tests completed.\n\n  fasturl            x  3,821,651 ops/sec ±2.42% (185 runs sampled)\n  nativeurl - legacy x  2,651,162 ops/sec ±1.90% (187 runs sampled)\n  nativeurl - whatwg x    175,166 ops/sec ±1.44% (188 runs sampled)\n  parseurl           x 14,912,606 ops/sec ±3.59% (183 runs sampled)\n\n> node benchmark/simplepath.js\n\n  Parsing URL \"/foo/bar\"\n\n  4 tests completed.\n\n  fasturl            x 12,421,765 ops/sec ±2.04% (191 runs sampled)\n  nativeurl - legacy x  7,546,036 ops/sec ±1.41% (188 runs sampled)\n  nativeurl - whatwg x    198,843 ops/sec ±1.83% (189 runs sampled)\n  parseurl           x 24,244,006 ops/sec ±0.51% (194 runs sampled)\n\n> node benchmark/slash.js\n\n  Parsing URL \"/\"\n\n  4 tests completed.\n\n  fasturl            x 17,159,456 ops/sec ±3.25% (188 runs sampled)\n  nativeurl - legacy x 11,635,097 ops/sec ±3.79% (184 runs sampled)\n  nativeurl - whatwg x    240,693 ops/sec ±0.83% (189 runs sampled)\n  parseurl           x 42,279,067 ops/sec ±0.55% (190 runs sampled)\n```\n\n## License\n\n  [MIT](LICENSE)\n\n[coveralls-image]: https://badgen.net/coveralls/c/github/pillarjs/parseurl/master\n[coveralls-url]: https://coveralls.io/r/pillarjs/parseurl?branch=master\n[node-image]: https://badgen.net/npm/node/parseurl\n[node-url]: https://nodejs.org/en/download\n[npm-downloads-image]: https://badgen.net/npm/dm/parseurl\n[npm-url]: https://npmjs.org/package/parseurl\n[npm-version-image]: https://badgen.net/npm/v/parseurl\n[travis-image]: https://badgen.net/travis/pillarjs/parseurl/master\n[travis-url]: https://travis-ci.org/pillarjs/parseurl\n",
        "plugins/auto-review/mcp/node_modules/pkce-challenge/README.md": "# pkce-challenge\n\nGenerate or verify a Proof Key for Code Exchange (PKCE) challenge pair.\n\nRead more about [PKCE](https://www.oauth.com/oauth2-servers/pkce/authorization-request/).\n\n## Installation\n\n```bash\nnpm install pkce-challenge\n```\n\n## Usage\n\nDefault length for the verifier is 43\n\n```js\nimport pkceChallenge from \"pkce-challenge\";\n\nawait pkceChallenge();\n```\n\ngives something like:\n\n```js\n{\n    code_verifier: 'u1ta-MQ0e7TcpHjgz33M2DcBnOQu~aMGxuiZt0QMD1C',\n    code_challenge: 'CUZX5qE8Wvye6kS_SasIsa8MMxacJftmWdsIA_iKp3I'\n}\n```\n\n### Specify a verifier length\n\n```js\nconst challenge = await pkceChallenge(128);\n\nchallenge.code_verifier.length === 128; // true\n```\n\n### Challenge verification\n\n```js\nimport { verifyChallenge } from \"pkce-challenge\";\n\n(await verifyChallenge(challenge.code_verifier, challenge.code_challenge)) ===\n  true; // true\n```\n\n### Challenge generation from existing code verifier\n\n```js\nimport { generateChallenge } from \"pkce-challenge\";\n\n(await generateChallenge(challenge.code_verifier)) === challenge.code_challenge; // true\n```\n",
        "plugins/auto-review/mcp/node_modules/proxy-addr/README.md": "# proxy-addr\n\n[![NPM Version][npm-version-image]][npm-url]\n[![NPM Downloads][npm-downloads-image]][npm-url]\n[![Node.js Version][node-image]][node-url]\n[![Build Status][ci-image]][ci-url]\n[![Test Coverage][coveralls-image]][coveralls-url]\n\nDetermine address of proxied request\n\n## Install\n\nThis is a [Node.js](https://nodejs.org/en/) module available through the\n[npm registry](https://www.npmjs.com/). Installation is done using the\n[`npm install` command](https://docs.npmjs.com/getting-started/installing-npm-packages-locally):\n\n```sh\n$ npm install proxy-addr\n```\n\n## API\n\n```js\nvar proxyaddr = require('proxy-addr')\n```\n\n### proxyaddr(req, trust)\n\nReturn the address of the request, using the given `trust` parameter.\n\nThe `trust` argument is a function that returns `true` if you trust\nthe address, `false` if you don't. The closest untrusted address is\nreturned.\n\n```js\nproxyaddr(req, function (addr) { return addr === '127.0.0.1' })\nproxyaddr(req, function (addr, i) { return i < 1 })\n```\n\nThe `trust` arugment may also be a single IP address string or an\narray of trusted addresses, as plain IP addresses, CIDR-formatted\nstrings, or IP/netmask strings.\n\n```js\nproxyaddr(req, '127.0.0.1')\nproxyaddr(req, ['127.0.0.0/8', '10.0.0.0/8'])\nproxyaddr(req, ['127.0.0.0/255.0.0.0', '192.168.0.0/255.255.0.0'])\n```\n\nThis module also supports IPv6. Your IPv6 addresses will be normalized\nautomatically (i.e. `fe80::00ed:1` equals `fe80:0:0:0:0:0:ed:1`).\n\n```js\nproxyaddr(req, '::1')\nproxyaddr(req, ['::1/128', 'fe80::/10'])\n```\n\nThis module will automatically work with IPv4-mapped IPv6 addresses\nas well to support node.js in IPv6-only mode. This means that you do\nnot have to specify both `::ffff:a00:1` and `10.0.0.1`.\n\nAs a convenience, this module also takes certain pre-defined names\nin addition to IP addresses, which expand into IP addresses:\n\n```js\nproxyaddr(req, 'loopback')\nproxyaddr(req, ['loopback', 'fc00:ac:1ab5:fff::1/64'])\n```\n\n  * `loopback`: IPv4 and IPv6 loopback addresses (like `::1` and\n    `127.0.0.1`).\n  * `linklocal`: IPv4 and IPv6 link-local addresses (like\n    `fe80::1:1:1:1` and `169.254.0.1`).\n  * `uniquelocal`: IPv4 private addresses and IPv6 unique-local\n    addresses (like `fc00:ac:1ab5:fff::1` and `192.168.0.1`).\n\nWhen `trust` is specified as a function, it will be called for each\naddress to determine if it is a trusted address. The function is\ngiven two arguments: `addr` and `i`, where `addr` is a string of\nthe address to check and `i` is a number that represents the distance\nfrom the socket address.\n\n### proxyaddr.all(req, [trust])\n\nReturn all the addresses of the request, optionally stopping at the\nfirst untrusted. This array is ordered from closest to furthest\n(i.e. `arr[0] === req.connection.remoteAddress`).\n\n```js\nproxyaddr.all(req)\n```\n\nThe optional `trust` argument takes the same arguments as `trust`\ndoes in `proxyaddr(req, trust)`.\n\n```js\nproxyaddr.all(req, 'loopback')\n```\n\n### proxyaddr.compile(val)\n\nCompiles argument `val` into a `trust` function. This function takes\nthe same arguments as `trust` does in `proxyaddr(req, trust)` and\nreturns a function suitable for `proxyaddr(req, trust)`.\n\n```js\nvar trust = proxyaddr.compile('loopback')\nvar addr = proxyaddr(req, trust)\n```\n\nThis function is meant to be optimized for use against every request.\nIt is recommend to compile a trust function up-front for the trusted\nconfiguration and pass that to `proxyaddr(req, trust)` for each request.\n\n## Testing\n\n```sh\n$ npm test\n```\n\n## Benchmarks\n\n```sh\n$ npm run-script bench\n```\n\n## License\n\n[MIT](LICENSE)\n\n[ci-image]: https://badgen.net/github/checks/jshttp/proxy-addr/master?label=ci\n[ci-url]: https://github.com/jshttp/proxy-addr/actions?query=workflow%3Aci\n[coveralls-image]: https://badgen.net/coveralls/c/github/jshttp/proxy-addr/master\n[coveralls-url]: https://coveralls.io/r/jshttp/proxy-addr?branch=master\n[node-image]: https://badgen.net/npm/node/proxy-addr\n[node-url]: https://nodejs.org/en/download\n[npm-downloads-image]: https://badgen.net/npm/dm/proxy-addr\n[npm-url]: https://npmjs.org/package/proxy-addr\n[npm-version-image]: https://badgen.net/npm/v/proxy-addr\n",
        "plugins/auto-review/mcp/node_modules/qs/README.md": "<p align=\"center\">\n    <img alt=\"qs\" src=\"./logos/banner_default.png\" width=\"800\" />\n</p>\n\n# qs <sup>[![Version Badge][npm-version-svg]][package-url]</sup>\n\n[![github actions][actions-image]][actions-url]\n[![coverage][codecov-image]][codecov-url]\n[![License][license-image]][license-url]\n[![Downloads][downloads-image]][downloads-url]\n[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/9058/badge)](https://bestpractices.coreinfrastructure.org/projects/9058)\n\n[![npm badge][npm-badge-png]][package-url]\n\nA querystring parsing and stringifying library with some added security.\n\nLead Maintainer: [Jordan Harband](https://github.com/ljharb)\n\nThe **qs** module was originally created and maintained by [TJ Holowaychuk](https://github.com/visionmedia/node-querystring).\n\n## Usage\n\n```javascript\nvar qs = require('qs');\nvar assert = require('assert');\n\nvar obj = qs.parse('a=c');\nassert.deepEqual(obj, { a: 'c' });\n\nvar str = qs.stringify(obj);\nassert.equal(str, 'a=c');\n```\n\n### Parsing Objects\n\n[](#preventEval)\n```javascript\nqs.parse(string, [options]);\n```\n\n**qs** allows you to create nested objects within your query strings, by surrounding the name of sub-keys with square brackets `[]`.\nFor example, the string `'foo[bar]=baz'` converts to:\n\n```javascript\nassert.deepEqual(qs.parse('foo[bar]=baz'), {\n    foo: {\n        bar: 'baz'\n    }\n});\n```\n\nWhen using the `plainObjects` option the parsed value is returned as a null object, created via `{ __proto__: null }` and as such you should be aware that prototype methods will not exist on it and a user may set those names to whatever value they like:\n\n```javascript\nvar nullObject = qs.parse('a[hasOwnProperty]=b', { plainObjects: true });\nassert.deepEqual(nullObject, { a: { hasOwnProperty: 'b' } });\n```\n\nBy default parameters that would overwrite properties on the object prototype are ignored, if you wish to keep the data from those fields either use `plainObjects` as mentioned above, or set `allowPrototypes` to `true` which will allow user input to overwrite those properties.\n*WARNING* It is generally a bad idea to enable this option as it can cause problems when attempting to use the properties that have been overwritten.\nAlways be careful with this option.\n\n```javascript\nvar protoObject = qs.parse('a[hasOwnProperty]=b', { allowPrototypes: true });\nassert.deepEqual(protoObject, { a: { hasOwnProperty: 'b' } });\n```\n\nURI encoded strings work too:\n\n```javascript\nassert.deepEqual(qs.parse('a%5Bb%5D=c'), {\n    a: { b: 'c' }\n});\n```\n\nYou can also nest your objects, like `'foo[bar][baz]=foobarbaz'`:\n\n```javascript\nassert.deepEqual(qs.parse('foo[bar][baz]=foobarbaz'), {\n    foo: {\n        bar: {\n            baz: 'foobarbaz'\n        }\n    }\n});\n```\n\nBy default, when nesting objects **qs** will only parse up to 5 children deep.\nThis means if you attempt to parse a string like `'a[b][c][d][e][f][g][h][i]=j'` your resulting object will be:\n\n```javascript\nvar expected = {\n    a: {\n        b: {\n            c: {\n                d: {\n                    e: {\n                        f: {\n                            '[g][h][i]': 'j'\n                        }\n                    }\n                }\n            }\n        }\n    }\n};\nvar string = 'a[b][c][d][e][f][g][h][i]=j';\nassert.deepEqual(qs.parse(string), expected);\n```\n\nThis depth can be overridden by passing a `depth` option to `qs.parse(string, [options])`:\n\n```javascript\nvar deep = qs.parse('a[b][c][d][e][f][g][h][i]=j', { depth: 1 });\nassert.deepEqual(deep, { a: { b: { '[c][d][e][f][g][h][i]': 'j' } } });\n```\n\nYou can configure **qs** to throw an error when parsing nested input beyond this depth using the `strictDepth` option (defaulted to false):\n\n```javascript\ntry {\n    qs.parse('a[b][c][d][e][f][g][h][i]=j', { depth: 1, strictDepth: true });\n} catch (err) {\n    assert(err instanceof RangeError);\n    assert.strictEqual(err.message, 'Input depth exceeded depth option of 1 and strictDepth is true');\n}\n```\n\nThe depth limit helps mitigate abuse when **qs** is used to parse user input, and it is recommended to keep it a reasonably small number. The strictDepth option adds a layer of protection by throwing an error when the limit is exceeded, allowing you to catch and handle such cases.\n\nFor similar reasons, by default **qs** will only parse up to 1000 parameters. This can be overridden by passing a `parameterLimit` option:\n\n```javascript\nvar limited = qs.parse('a=b&c=d', { parameterLimit: 1 });\nassert.deepEqual(limited, { a: 'b' });\n```\n\nIf you want an error to be thrown whenever the a limit is exceeded (eg, `parameterLimit`, `arrayLimit`), set the `throwOnLimitExceeded` option to `true`. This option will generate a descriptive error if the query string exceeds a configured limit.\n```javascript\ntry {\n    qs.parse('a=1&b=2&c=3&d=4', { parameterLimit: 3, throwOnLimitExceeded: true });\n} catch (err) {\n    assert(err instanceof Error);\n    assert.strictEqual(err.message, 'Parameter limit exceeded. Only 3 parameters allowed.');\n}\n```\n\nWhen `throwOnLimitExceeded` is set to `false` (default), **qs** will parse up to the specified `parameterLimit` and ignore the rest without throwing an error.\n\nTo bypass the leading question mark, use `ignoreQueryPrefix`:\n\n```javascript\nvar prefixed = qs.parse('?a=b&c=d', { ignoreQueryPrefix: true });\nassert.deepEqual(prefixed, { a: 'b', c: 'd' });\n```\n\nAn optional delimiter can also be passed:\n\n```javascript\nvar delimited = qs.parse('a=b;c=d', { delimiter: ';' });\nassert.deepEqual(delimited, { a: 'b', c: 'd' });\n```\n\nDelimiters can be a regular expression too:\n\n```javascript\nvar regexed = qs.parse('a=b;c=d,e=f', { delimiter: /[;,]/ });\nassert.deepEqual(regexed, { a: 'b', c: 'd', e: 'f' });\n```\n\nOption `allowDots` can be used to enable dot notation:\n\n```javascript\nvar withDots = qs.parse('a.b=c', { allowDots: true });\nassert.deepEqual(withDots, { a: { b: 'c' } });\n```\n\nOption `decodeDotInKeys` can be used to decode dots in keys\nNote: it implies `allowDots`, so `parse` will error if you set `decodeDotInKeys` to `true`, and `allowDots` to `false`.\n\n```javascript\nvar withDots = qs.parse('name%252Eobj.first=John&name%252Eobj.last=Doe', { decodeDotInKeys: true });\nassert.deepEqual(withDots, { 'name.obj': { first: 'John', last: 'Doe' }});\n```\n\nOption `allowEmptyArrays` can be used to allowing empty array values in object\n```javascript\nvar withEmptyArrays = qs.parse('foo[]&bar=baz', { allowEmptyArrays: true });\nassert.deepEqual(withEmptyArrays, { foo: [], bar: 'baz' });\n```\n\nOption `duplicates` can be used to change the behavior when duplicate keys are encountered\n```javascript\nassert.deepEqual(qs.parse('foo=bar&foo=baz'), { foo: ['bar', 'baz'] });\nassert.deepEqual(qs.parse('foo=bar&foo=baz', { duplicates: 'combine' }), { foo: ['bar', 'baz'] });\nassert.deepEqual(qs.parse('foo=bar&foo=baz', { duplicates: 'first' }), { foo: 'bar' });\nassert.deepEqual(qs.parse('foo=bar&foo=baz', { duplicates: 'last' }), { foo: 'baz' });\n```\n\nIf you have to deal with legacy browsers or services, there's also support for decoding percent-encoded octets as iso-8859-1:\n\n```javascript\nvar oldCharset = qs.parse('a=%A7', { charset: 'iso-8859-1' });\nassert.deepEqual(oldCharset, { a: '§' });\n```\n\nSome services add an initial `utf8=✓` value to forms so that old Internet Explorer versions are more likely to submit the form as utf-8.\nAdditionally, the server can check the value against wrong encodings of the checkmark character and detect that a query string or `application/x-www-form-urlencoded` body was *not* sent as utf-8, eg. if the form had an `accept-charset` parameter or the containing page had a different character set.\n\n**qs** supports this mechanism via the `charsetSentinel` option.\nIf specified, the `utf8` parameter will be omitted from the returned object.\nIt will be used to switch to `iso-8859-1`/`utf-8` mode depending on how the checkmark is encoded.\n\n**Important**: When you specify both the `charset` option and the `charsetSentinel` option, the `charset` will be overridden when the request contains a `utf8` parameter from which the actual charset can be deduced.\nIn that sense the `charset` will behave as the default charset rather than the authoritative charset.\n\n```javascript\nvar detectedAsUtf8 = qs.parse('utf8=%E2%9C%93&a=%C3%B8', {\n    charset: 'iso-8859-1',\n    charsetSentinel: true\n});\nassert.deepEqual(detectedAsUtf8, { a: 'ø' });\n\n// Browsers encode the checkmark as &#10003; when submitting as iso-8859-1:\nvar detectedAsIso8859_1 = qs.parse('utf8=%26%2310003%3B&a=%F8', {\n    charset: 'utf-8',\n    charsetSentinel: true\n});\nassert.deepEqual(detectedAsIso8859_1, { a: 'ø' });\n```\n\nIf you want to decode the `&#...;` syntax to the actual character, you can specify the `interpretNumericEntities` option as well:\n\n```javascript\nvar detectedAsIso8859_1 = qs.parse('a=%26%239786%3B', {\n    charset: 'iso-8859-1',\n    interpretNumericEntities: true\n});\nassert.deepEqual(detectedAsIso8859_1, { a: '☺' });\n```\n\nIt also works when the charset has been detected in `charsetSentinel` mode.\n\n### Parsing Arrays\n\n**qs** can also parse arrays using a similar `[]` notation:\n\n```javascript\nvar withArray = qs.parse('a[]=b&a[]=c');\nassert.deepEqual(withArray, { a: ['b', 'c'] });\n```\n\nYou may specify an index as well:\n\n```javascript\nvar withIndexes = qs.parse('a[1]=c&a[0]=b');\nassert.deepEqual(withIndexes, { a: ['b', 'c'] });\n```\n\nNote that the only difference between an index in an array and a key in an object is that the value between the brackets must be a number to create an array.\nWhen creating arrays with specific indices, **qs** will compact a sparse array to only the existing values preserving their order:\n\n```javascript\nvar noSparse = qs.parse('a[1]=b&a[15]=c');\nassert.deepEqual(noSparse, { a: ['b', 'c'] });\n```\n\nYou may also use `allowSparse` option to parse sparse arrays:\n\n```javascript\nvar sparseArray = qs.parse('a[1]=2&a[3]=5', { allowSparse: true });\nassert.deepEqual(sparseArray, { a: [, '2', , '5'] });\n```\n\nNote that an empty string is also a value, and will be preserved:\n\n```javascript\nvar withEmptyString = qs.parse('a[]=&a[]=b');\nassert.deepEqual(withEmptyString, { a: ['', 'b'] });\n\nvar withIndexedEmptyString = qs.parse('a[0]=b&a[1]=&a[2]=c');\nassert.deepEqual(withIndexedEmptyString, { a: ['b', '', 'c'] });\n```\n\n**qs** will also limit specifying indices in an array to a maximum index of `20`.\nAny array members with an index of greater than `20` will instead be converted to an object with the index as the key.\nThis is needed to handle cases when someone sent, for example, `a[999999999]` and it will take significant time to iterate over this huge array.\n\n```javascript\nvar withMaxIndex = qs.parse('a[100]=b');\nassert.deepEqual(withMaxIndex, { a: { '100': 'b' } });\n```\n\nThis limit can be overridden by passing an `arrayLimit` option:\n\n```javascript\nvar withArrayLimit = qs.parse('a[1]=b', { arrayLimit: 0 });\nassert.deepEqual(withArrayLimit, { a: { '1': 'b' } });\n```\n\nIf you want to throw an error whenever the array limit is exceeded, set the `throwOnLimitExceeded` option to `true`. This option will generate a descriptive error if the query string exceeds a configured limit.\n```javascript\ntry {\n    qs.parse('a[1]=b', { arrayLimit: 0, throwOnLimitExceeded: true });\n} catch (err) {\n    assert(err instanceof Error);\n    assert.strictEqual(err.message, 'Array limit exceeded. Only 0 elements allowed in an array.');\n}\n```\n\nWhen `throwOnLimitExceeded` is set to `false` (default), **qs** will parse up to the specified `arrayLimit` and if the limit is exceeded, the array will instead be converted to an object with the index as the key\n\nTo disable array parsing entirely, set `parseArrays` to `false`.\n\n```javascript\nvar noParsingArrays = qs.parse('a[]=b', { parseArrays: false });\nassert.deepEqual(noParsingArrays, { a: { '0': 'b' } });\n```\n\nIf you mix notations, **qs** will merge the two items into an object:\n\n```javascript\nvar mixedNotation = qs.parse('a[0]=b&a[b]=c');\nassert.deepEqual(mixedNotation, { a: { '0': 'b', b: 'c' } });\n```\n\nYou can also create arrays of objects:\n\n```javascript\nvar arraysOfObjects = qs.parse('a[][b]=c');\nassert.deepEqual(arraysOfObjects, { a: [{ b: 'c' }] });\n```\n\nSome people use comma to join array, **qs** can parse it:\n```javascript\nvar arraysOfObjects = qs.parse('a=b,c', { comma: true })\nassert.deepEqual(arraysOfObjects, { a: ['b', 'c'] })\n```\n(_this cannot convert nested objects, such as `a={b:1},{c:d}`_)\n\n### Parsing primitive/scalar values (numbers, booleans, null, etc)\n\nBy default, all values are parsed as strings.\nThis behavior will not change and is explained in [issue #91](https://github.com/ljharb/qs/issues/91).\n\n```javascript\nvar primitiveValues = qs.parse('a=15&b=true&c=null');\nassert.deepEqual(primitiveValues, { a: '15', b: 'true', c: 'null' });\n```\n\nIf you wish to auto-convert values which look like numbers, booleans, and other values into their primitive counterparts, you can use the [query-types Express JS middleware](https://github.com/xpepermint/query-types) which will auto-convert all request query parameters.\n\n### Stringifying\n\n[](#preventEval)\n```javascript\nqs.stringify(object, [options]);\n```\n\nWhen stringifying, **qs** by default URI encodes output. Objects are stringified as you would expect:\n\n```javascript\nassert.equal(qs.stringify({ a: 'b' }), 'a=b');\nassert.equal(qs.stringify({ a: { b: 'c' } }), 'a%5Bb%5D=c');\n```\n\nThis encoding can be disabled by setting the `encode` option to `false`:\n\n```javascript\nvar unencoded = qs.stringify({ a: { b: 'c' } }, { encode: false });\nassert.equal(unencoded, 'a[b]=c');\n```\n\nEncoding can be disabled for keys by setting the `encodeValuesOnly` option to `true`:\n```javascript\nvar encodedValues = qs.stringify(\n    { a: 'b', c: ['d', 'e=f'], f: [['g'], ['h']] },\n    { encodeValuesOnly: true }\n);\nassert.equal(encodedValues,'a=b&c[0]=d&c[1]=e%3Df&f[0][0]=g&f[1][0]=h');\n```\n\nThis encoding can also be replaced by a custom encoding method set as `encoder` option:\n\n```javascript\nvar encoded = qs.stringify({ a: { b: 'c' } }, { encoder: function (str) {\n    // Passed in values `a`, `b`, `c`\n    return // Return encoded string\n}})\n```\n\n_(Note: the `encoder` option does not apply if `encode` is `false`)_\n\nAnalogue to the `encoder` there is a `decoder` option for `parse` to override decoding of properties and values:\n\n```javascript\nvar decoded = qs.parse('x=z', { decoder: function (str) {\n    // Passed in values `x`, `z`\n    return // Return decoded string\n}})\n```\n\nYou can encode keys and values using different logic by using the type argument provided to the encoder:\n\n```javascript\nvar encoded = qs.stringify({ a: { b: 'c' } }, { encoder: function (str, defaultEncoder, charset, type) {\n    if (type === 'key') {\n        return // Encoded key\n    } else if (type === 'value') {\n        return // Encoded value\n    }\n}})\n```\n\nThe type argument is also provided to the decoder:\n\n```javascript\nvar decoded = qs.parse('x=z', { decoder: function (str, defaultDecoder, charset, type) {\n    if (type === 'key') {\n        return // Decoded key\n    } else if (type === 'value') {\n        return // Decoded value\n    }\n}})\n```\n\nExamples beyond this point will be shown as though the output is not URI encoded for clarity.\nPlease note that the return values in these cases *will* be URI encoded during real usage.\n\nWhen arrays are stringified, they follow the `arrayFormat` option, which defaults to `indices`:\n\n```javascript\nqs.stringify({ a: ['b', 'c', 'd'] });\n// 'a[0]=b&a[1]=c&a[2]=d'\n```\n\nYou may override this by setting the `indices` option to `false`, or to be more explicit, the `arrayFormat` option to `repeat`:\n\n```javascript\nqs.stringify({ a: ['b', 'c', 'd'] }, { indices: false });\n// 'a=b&a=c&a=d'\n```\n\nYou may use the `arrayFormat` option to specify the format of the output array:\n\n```javascript\nqs.stringify({ a: ['b', 'c'] }, { arrayFormat: 'indices' })\n// 'a[0]=b&a[1]=c'\nqs.stringify({ a: ['b', 'c'] }, { arrayFormat: 'brackets' })\n// 'a[]=b&a[]=c'\nqs.stringify({ a: ['b', 'c'] }, { arrayFormat: 'repeat' })\n// 'a=b&a=c'\nqs.stringify({ a: ['b', 'c'] }, { arrayFormat: 'comma' })\n// 'a=b,c'\n```\n\nNote: when using `arrayFormat` set to `'comma'`, you can also pass the `commaRoundTrip` option set to `true` or `false`, to append `[]` on single-item arrays, so that they can round trip through a parse.\n\nWhen objects are stringified, by default they use bracket notation:\n\n```javascript\nqs.stringify({ a: { b: { c: 'd', e: 'f' } } });\n// 'a[b][c]=d&a[b][e]=f'\n```\n\nYou may override this to use dot notation by setting the `allowDots` option to `true`:\n\n```javascript\nqs.stringify({ a: { b: { c: 'd', e: 'f' } } }, { allowDots: true });\n// 'a.b.c=d&a.b.e=f'\n```\n\nYou may encode the dot notation in the keys of object with option `encodeDotInKeys` by setting it to `true`:\nNote: it implies `allowDots`, so `stringify` will error if you set `decodeDotInKeys` to `true`, and `allowDots` to `false`.\nCaveat: when `encodeValuesOnly` is `true` as well as `encodeDotInKeys`, only dots in keys and nothing else will be encoded.\n```javascript\nqs.stringify({ \"name.obj\": { \"first\": \"John\", \"last\": \"Doe\" } }, { allowDots: true, encodeDotInKeys: true })\n// 'name%252Eobj.first=John&name%252Eobj.last=Doe'\n```\n\nYou may allow empty array values by setting the `allowEmptyArrays` option to `true`:\n```javascript\nqs.stringify({ foo: [], bar: 'baz' }, { allowEmptyArrays: true });\n// 'foo[]&bar=baz'\n```\n\nEmpty strings and null values will omit the value, but the equals sign (=) remains in place:\n\n```javascript\nassert.equal(qs.stringify({ a: '' }), 'a=');\n```\n\nKey with no values (such as an empty object or array) will return nothing:\n\n```javascript\nassert.equal(qs.stringify({ a: [] }), '');\nassert.equal(qs.stringify({ a: {} }), '');\nassert.equal(qs.stringify({ a: [{}] }), '');\nassert.equal(qs.stringify({ a: { b: []} }), '');\nassert.equal(qs.stringify({ a: { b: {}} }), '');\n```\n\nProperties that are set to `undefined` will be omitted entirely:\n\n```javascript\nassert.equal(qs.stringify({ a: null, b: undefined }), 'a=');\n```\n\nThe query string may optionally be prepended with a question mark:\n\n```javascript\nassert.equal(qs.stringify({ a: 'b', c: 'd' }, { addQueryPrefix: true }), '?a=b&c=d');\n```\n\nThe delimiter may be overridden with stringify as well:\n\n```javascript\nassert.equal(qs.stringify({ a: 'b', c: 'd' }, { delimiter: ';' }), 'a=b;c=d');\n```\n\nIf you only want to override the serialization of `Date` objects, you can provide a `serializeDate` option:\n\n```javascript\nvar date = new Date(7);\nassert.equal(qs.stringify({ a: date }), 'a=1970-01-01T00:00:00.007Z'.replace(/:/g, '%3A'));\nassert.equal(\n    qs.stringify({ a: date }, { serializeDate: function (d) { return d.getTime(); } }),\n    'a=7'\n);\n```\n\nYou may use the `sort` option to affect the order of parameter keys:\n\n```javascript\nfunction alphabeticalSort(a, b) {\n    return a.localeCompare(b);\n}\nassert.equal(qs.stringify({ a: 'c', z: 'y', b : 'f' }, { sort: alphabeticalSort }), 'a=c&b=f&z=y');\n```\n\nFinally, you can use the `filter` option to restrict which keys will be included in the stringified output.\nIf you pass a function, it will be called for each key to obtain the replacement value.\nOtherwise, if you pass an array, it will be used to select properties and array indices for stringification:\n\n```javascript\nfunction filterFunc(prefix, value) {\n    if (prefix == 'b') {\n        // Return an `undefined` value to omit a property.\n        return;\n    }\n    if (prefix == 'e[f]') {\n        return value.getTime();\n    }\n    if (prefix == 'e[g][0]') {\n        return value * 2;\n    }\n    return value;\n}\nqs.stringify({ a: 'b', c: 'd', e: { f: new Date(123), g: [2] } }, { filter: filterFunc });\n// 'a=b&c=d&e[f]=123&e[g][0]=4'\nqs.stringify({ a: 'b', c: 'd', e: 'f' }, { filter: ['a', 'e'] });\n// 'a=b&e=f'\nqs.stringify({ a: ['b', 'c', 'd'], e: 'f' }, { filter: ['a', 0, 2] });\n// 'a[0]=b&a[2]=d'\n```\n\nYou could also use `filter` to inject custom serialization for user defined types.\nConsider you're working with some api that expects query strings of the format for ranges:\n\n```\nhttps://domain.com/endpoint?range=30...70\n```\n\nFor which you model as:\n\n```javascript\nclass Range {\n    constructor(from, to) {\n        this.from = from;\n        this.to = to;\n    }\n}\n```\n\nYou could _inject_ a custom serializer to handle values of this type:\n\n```javascript\nqs.stringify(\n    {\n        range: new Range(30, 70),\n    },\n    {\n        filter: (prefix, value) => {\n            if (value instanceof Range) {\n                return `${value.from}...${value.to}`;\n            }\n            // serialize the usual way\n            return value;\n        },\n    }\n);\n// range=30...70\n```\n\n### Handling of `null` values\n\nBy default, `null` values are treated like empty strings:\n\n```javascript\nvar withNull = qs.stringify({ a: null, b: '' });\nassert.equal(withNull, 'a=&b=');\n```\n\nParsing does not distinguish between parameters with and without equal signs.\nBoth are converted to empty strings.\n\n```javascript\nvar equalsInsensitive = qs.parse('a&b=');\nassert.deepEqual(equalsInsensitive, { a: '', b: '' });\n```\n\nTo distinguish between `null` values and empty strings use the `strictNullHandling` flag. In the result string the `null`\nvalues have no `=` sign:\n\n```javascript\nvar strictNull = qs.stringify({ a: null, b: '' }, { strictNullHandling: true });\nassert.equal(strictNull, 'a&b=');\n```\n\nTo parse values without `=` back to `null` use the `strictNullHandling` flag:\n\n```javascript\nvar parsedStrictNull = qs.parse('a&b=', { strictNullHandling: true });\nassert.deepEqual(parsedStrictNull, { a: null, b: '' });\n```\n\nTo completely skip rendering keys with `null` values, use the `skipNulls` flag:\n\n```javascript\nvar nullsSkipped = qs.stringify({ a: 'b', c: null}, { skipNulls: true });\nassert.equal(nullsSkipped, 'a=b');\n```\n\nIf you're communicating with legacy systems, you can switch to `iso-8859-1` using the `charset` option:\n\n```javascript\nvar iso = qs.stringify({ æ: 'æ' }, { charset: 'iso-8859-1' });\nassert.equal(iso, '%E6=%E6');\n```\n\nCharacters that don't exist in `iso-8859-1` will be converted to numeric entities, similar to what browsers do:\n\n```javascript\nvar numeric = qs.stringify({ a: '☺' }, { charset: 'iso-8859-1' });\nassert.equal(numeric, 'a=%26%239786%3B');\n```\n\nYou can use the `charsetSentinel` option to announce the character by including an `utf8=✓` parameter with the proper encoding if the checkmark, similar to what Ruby on Rails and others do when submitting forms.\n\n```javascript\nvar sentinel = qs.stringify({ a: '☺' }, { charsetSentinel: true });\nassert.equal(sentinel, 'utf8=%E2%9C%93&a=%E2%98%BA');\n\nvar isoSentinel = qs.stringify({ a: 'æ' }, { charsetSentinel: true, charset: 'iso-8859-1' });\nassert.equal(isoSentinel, 'utf8=%26%2310003%3B&a=%E6');\n```\n\n### Dealing with special character sets\n\nBy default the encoding and decoding of characters is done in `utf-8`, and `iso-8859-1` support is also built in via the `charset` parameter.\n\nIf you wish to encode querystrings to a different character set (i.e.\n[Shift JIS](https://en.wikipedia.org/wiki/Shift_JIS)) you can use the\n[`qs-iconv`](https://github.com/martinheidegger/qs-iconv) library:\n\n```javascript\nvar encoder = require('qs-iconv/encoder')('shift_jis');\nvar shiftJISEncoded = qs.stringify({ a: 'こんにちは！' }, { encoder: encoder });\nassert.equal(shiftJISEncoded, 'a=%82%B1%82%F1%82%C9%82%BF%82%CD%81I');\n```\n\nThis also works for decoding of query strings:\n\n```javascript\nvar decoder = require('qs-iconv/decoder')('shift_jis');\nvar obj = qs.parse('a=%82%B1%82%F1%82%C9%82%BF%82%CD%81I', { decoder: decoder });\nassert.deepEqual(obj, { a: 'こんにちは！' });\n```\n\n### RFC 3986 and RFC 1738 space encoding\n\nRFC3986 used as default option and encodes ' ' to *%20* which is backward compatible.\nIn the same time, output can be stringified as per RFC1738 with ' ' equal to '+'.\n\n```\nassert.equal(qs.stringify({ a: 'b c' }), 'a=b%20c');\nassert.equal(qs.stringify({ a: 'b c' }, { format : 'RFC3986' }), 'a=b%20c');\nassert.equal(qs.stringify({ a: 'b c' }, { format : 'RFC1738' }), 'a=b+c');\n```\n\n## Security\n\nPlease email [@ljharb](https://github.com/ljharb) or see https://tidelift.com/security if you have a potential security vulnerability to report.\n\n## qs for enterprise\n\nAvailable as part of the Tidelift Subscription\n\nThe maintainers of qs and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications.\nSave time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use.\n[Learn more.](https://tidelift.com/subscription/pkg/npm-qs?utm_source=npm-qs&utm_medium=referral&utm_campaign=enterprise&utm_term=repo)\n\n[package-url]: https://npmjs.org/package/qs\n[npm-version-svg]: https://versionbadg.es/ljharb/qs.svg\n[deps-svg]: https://david-dm.org/ljharb/qs.svg\n[deps-url]: https://david-dm.org/ljharb/qs\n[dev-deps-svg]: https://david-dm.org/ljharb/qs/dev-status.svg\n[dev-deps-url]: https://david-dm.org/ljharb/qs#info=devDependencies\n[npm-badge-png]: https://nodei.co/npm/qs.png?downloads=true&stars=true\n[license-image]: https://img.shields.io/npm/l/qs.svg\n[license-url]: LICENSE\n[downloads-image]: https://img.shields.io/npm/dm/qs.svg\n[downloads-url]: https://npm-stat.com/charts.html?package=qs\n[codecov-image]: https://codecov.io/gh/ljharb/qs/branch/main/graphs/badge.svg\n[codecov-url]: https://app.codecov.io/gh/ljharb/qs/\n[actions-image]: https://img.shields.io/endpoint?url=https://github-actions-badge-u3jn4tfpocch.runkit.sh/ljharb/qs\n[actions-url]: https://github.com/ljharb/qs/actions\n\n## Acknowledgements\n\nqs logo by [NUMI](https://github.com/numi-hq/open-design):\n\n[<img src=\"https://raw.githubusercontent.com/numi-hq/open-design/main/assets/numi-lockup.png\" alt=\"NUMI Logo\" style=\"width: 200px;\"/>](https://numi.tech/?ref=qs)\n",
        "plugins/auto-review/mcp/node_modules/range-parser/README.md": "# range-parser\n\n[![NPM Version][npm-version-image]][npm-url]\n[![NPM Downloads][npm-downloads-image]][npm-url]\n[![Node.js Version][node-image]][node-url]\n[![Build Status][travis-image]][travis-url]\n[![Test Coverage][coveralls-image]][coveralls-url]\n\nRange header field parser.\n\n## Installation\n\nThis is a [Node.js](https://nodejs.org/en/) module available through the\n[npm registry](https://www.npmjs.com/). Installation is done using the\n[`npm install` command](https://docs.npmjs.com/getting-started/installing-npm-packages-locally):\n\n```sh\n$ npm install range-parser\n```\n\n## API\n\n<!-- eslint-disable no-unused-vars -->\n\n```js\nvar parseRange = require('range-parser')\n```\n\n### parseRange(size, header, options)\n\nParse the given `header` string where `size` is the maximum size of the resource.\nAn array of ranges will be returned or negative numbers indicating an error parsing.\n\n  * `-2` signals a malformed header string\n  * `-1` signals an unsatisfiable range\n\n<!-- eslint-disable no-undef -->\n\n```js\n// parse header from request\nvar range = parseRange(size, req.headers.range)\n\n// the type of the range\nif (range.type === 'bytes') {\n  // the ranges\n  range.forEach(function (r) {\n    // do something with r.start and r.end\n  })\n}\n```\n\n#### Options\n\nThese properties are accepted in the options object.\n\n##### combine\n\nSpecifies if overlapping & adjacent ranges should be combined, defaults to `false`.\nWhen `true`, ranges will be combined and returned as if they were specified that\nway in the header.\n\n<!-- eslint-disable no-undef -->\n\n```js\nparseRange(100, 'bytes=50-55,0-10,5-10,56-60', { combine: true })\n// => [\n//      { start: 0,  end: 10 },\n//      { start: 50, end: 60 }\n//    ]\n```\n\n## License\n\n[MIT](LICENSE)\n\n[coveralls-image]: https://badgen.net/coveralls/c/github/jshttp/range-parser/master\n[coveralls-url]: https://coveralls.io/r/jshttp/range-parser?branch=master\n[node-image]: https://badgen.net/npm/node/range-parser\n[node-url]: https://nodejs.org/en/download\n[npm-downloads-image]: https://badgen.net/npm/dm/range-parser\n[npm-url]: https://npmjs.org/package/range-parser\n[npm-version-image]: https://badgen.net/npm/v/range-parser\n[travis-image]: https://badgen.net/travis/jshttp/range-parser/master\n[travis-url]: https://travis-ci.org/jshttp/range-parser\n",
        "plugins/auto-review/mcp/node_modules/raw-body/README.md": "# raw-body\n\n[![NPM Version][npm-image]][npm-url]\n[![NPM Downloads][downloads-image]][downloads-url]\n[![Node.js Version][node-version-image]][node-version-url]\n[![Build status][github-actions-ci-image]][github-actions-ci-url]\n[![Test coverage][coveralls-image]][coveralls-url]\n\nGets the entire buffer of a stream either as a `Buffer` or a string.\nValidates the stream's length against an expected length and maximum limit.\nIdeal for parsing request bodies.\n\n## Install\n\nThis is a [Node.js](https://nodejs.org/en/) module available through the\n[npm registry](https://www.npmjs.com/). Installation is done using the\n[`npm install` command](https://docs.npmjs.com/getting-started/installing-npm-packages-locally):\n\n```sh\n$ npm install raw-body\n```\n\n### TypeScript\n\nThis module includes a [TypeScript](https://www.typescriptlang.org/)\ndeclaration file to enable auto complete in compatible editors and type\ninformation for TypeScript projects. This module depends on the Node.js\ntypes, so install `@types/node`:\n\n```sh\n$ npm install @types/node\n```\n\n## API\n\n```js\nvar getRawBody = require('raw-body')\n```\n\n### getRawBody(stream, [options], [callback])\n\n**Returns a promise if no callback specified and global `Promise` exists.**\n\nOptions:\n\n- `length` - The length of the stream.\n  If the contents of the stream do not add up to this length,\n  an `400` error code is returned.\n- `limit` - The byte limit of the body.\n  This is the number of bytes or any string format supported by\n  [bytes](https://www.npmjs.com/package/bytes),\n  for example `1000`, `'500kb'` or `'3mb'`.\n  If the body ends up being larger than this limit,\n  a `413` error code is returned.\n- `encoding` - The encoding to use to decode the body into a string.\n  By default, a `Buffer` instance will be returned when no encoding is specified.\n  Most likely, you want `utf-8`, so setting `encoding` to `true` will decode as `utf-8`.\n  You can use any type of encoding supported by [iconv-lite](https://www.npmjs.org/package/iconv-lite#readme).\n\nYou can also pass a string in place of options to just specify the encoding.\n\nIf an error occurs, the stream will be paused, everything unpiped,\nand you are responsible for correctly disposing the stream.\nFor HTTP requests, you may need to finish consuming the stream if\nyou want to keep the socket open for future requests. For streams\nthat use file descriptors, you should `stream.destroy()` or\n`stream.close()` to prevent leaks.\n\n## Errors\n\nThis module creates errors depending on the error condition during reading.\nThe error may be an error from the underlying Node.js implementation, but is\notherwise an error created by this module, which has the following attributes:\n\n  * `limit` - the limit in bytes\n  * `length` and `expected` - the expected length of the stream\n  * `received` - the received bytes\n  * `encoding` - the invalid encoding\n  * `status` and `statusCode` - the corresponding status code for the error\n  * `type` - the error type\n\n### Types\n\nThe errors from this module have a `type` property which allows for the programmatic\ndetermination of the type of error returned.\n\n#### encoding.unsupported\n\nThis error will occur when the `encoding` option is specified, but the value does\nnot map to an encoding supported by the [iconv-lite](https://www.npmjs.org/package/iconv-lite#readme)\nmodule.\n\n#### entity.too.large\n\nThis error will occur when the `limit` option is specified, but the stream has\nan entity that is larger.\n\n#### request.aborted\n\nThis error will occur when the request stream is aborted by the client before\nreading the body has finished.\n\n#### request.size.invalid\n\nThis error will occur when the `length` option is specified, but the stream has\nemitted more bytes.\n\n#### stream.encoding.set\n\nThis error will occur when the given stream has an encoding set on it, making it\na decoded stream. The stream should not have an encoding set and is expected to\nemit `Buffer` objects.\n\n#### stream.not.readable\n\nThis error will occur when the given stream is not readable.\n\n## Examples\n\n### Simple Express example\n\n```js\nvar contentType = require('content-type')\nvar express = require('express')\nvar getRawBody = require('raw-body')\n\nvar app = express()\n\napp.use(function (req, res, next) {\n  getRawBody(req, {\n    length: req.headers['content-length'],\n    limit: '1mb',\n    encoding: contentType.parse(req).parameters.charset\n  }, function (err, string) {\n    if (err) return next(err)\n    req.text = string\n    next()\n  })\n})\n\n// now access req.text\n```\n\n### Simple Koa example\n\n```js\nvar contentType = require('content-type')\nvar getRawBody = require('raw-body')\nvar koa = require('koa')\n\nvar app = koa()\n\napp.use(function * (next) {\n  this.text = yield getRawBody(this.req, {\n    length: this.req.headers['content-length'],\n    limit: '1mb',\n    encoding: contentType.parse(this.req).parameters.charset\n  })\n  yield next\n})\n\n// now access this.text\n```\n\n### Using as a promise\n\nTo use this library as a promise, simply omit the `callback` and a promise is\nreturned, provided that a global `Promise` is defined.\n\n```js\nvar getRawBody = require('raw-body')\nvar http = require('http')\n\nvar server = http.createServer(function (req, res) {\n  getRawBody(req)\n    .then(function (buf) {\n      res.statusCode = 200\n      res.end(buf.length + ' bytes submitted')\n    })\n    .catch(function (err) {\n      res.statusCode = 500\n      res.end(err.message)\n    })\n})\n\nserver.listen(3000)\n```\n\n### Using with TypeScript\n\n```ts\nimport * as getRawBody from 'raw-body';\nimport * as http from 'http';\n\nconst server = http.createServer((req, res) => {\n  getRawBody(req)\n  .then((buf) => {\n    res.statusCode = 200;\n    res.end(buf.length + ' bytes submitted');\n  })\n  .catch((err) => {\n    res.statusCode = err.statusCode;\n    res.end(err.message);\n  });\n});\n\nserver.listen(3000);\n```\n\n## License\n\n[MIT](LICENSE)\n\n[npm-image]: https://img.shields.io/npm/v/raw-body.svg\n[npm-url]: https://npmjs.org/package/raw-body\n[node-version-image]: https://img.shields.io/node/v/raw-body.svg\n[node-version-url]: https://nodejs.org/en/download/\n[coveralls-image]: https://img.shields.io/coveralls/stream-utils/raw-body/master.svg\n[coveralls-url]: https://coveralls.io/r/stream-utils/raw-body?branch=master\n[downloads-image]: https://img.shields.io/npm/dm/raw-body.svg\n[downloads-url]: https://npmjs.org/package/raw-body\n[github-actions-ci-image]: https://img.shields.io/github/actions/workflow/status/stream-utils/raw-body/ci.yml?branch=master&label=ci\n[github-actions-ci-url]: https://github.com/jshttp/stream-utils/raw-body?query=workflow%3Aci\n",
        "plugins/auto-review/mcp/node_modules/raw-body/node_modules/iconv-lite/README.md": "## iconv-lite: Pure JS character encoding conversion\n\n[![NPM Version][npm-version-image]][npm-url]\n[![NPM Downloads][npm-downloads-image]][npm-downloads-url]\n[![License][license-image]][license-url]\n[![NPM Install Size][npm-install-size-image]][npm-install-size-url]\n\n* No need for native code compilation. Quick to install, works on Windows, Web, and in sandboxed environments.\n* Used in popular projects like [Express.js (body_parser)](https://github.com/expressjs/body-parser), \n  [Grunt](http://gruntjs.com/), [Nodemailer](http://www.nodemailer.com/), [Yeoman](http://yeoman.io/) and others.\n* Faster than [node-iconv](https://github.com/bnoordhuis/node-iconv) (see below for performance comparison).\n* Intuitive encode/decode API, including Streaming support.\n* In-browser usage via [browserify](https://github.com/substack/node-browserify) or [webpack](https://webpack.js.org/) (~180kb gzip compressed with Buffer shim included).\n* Typescript [type definition file](https://github.com/ashtuchkin/iconv-lite/blob/master/lib/index.d.ts) included.\n* React Native is supported (need to install `stream` module to enable Streaming API).\n\n## Usage\n\n### Basic API\n\n```javascript\nvar iconv = require('iconv-lite');\n\n// Convert from an encoded buffer to a js string.\nstr = iconv.decode(Buffer.from([0x68, 0x65, 0x6c, 0x6c, 0x6f]), 'win1251');\n\n// Convert from a js string to an encoded buffer.\nbuf = iconv.encode(\"Sample input string\", 'win1251');\n\n// Check if encoding is supported\niconv.encodingExists(\"us-ascii\")\n```\n\n### Streaming API\n\n```javascript\n// Decode stream (from binary data stream to js strings)\nhttp.createServer(function(req, res) {\n    var converterStream = iconv.decodeStream('win1251');\n    req.pipe(converterStream);\n\n    converterStream.on('data', function(str) {\n        console.log(str); // Do something with decoded strings, chunk-by-chunk.\n    });\n});\n\n// Convert encoding streaming example\nfs.createReadStream('file-in-win1251.txt')\n    .pipe(iconv.decodeStream('win1251'))\n    .pipe(iconv.encodeStream('ucs2'))\n    .pipe(fs.createWriteStream('file-in-ucs2.txt'));\n\n// Sugar: all encode/decode streams have .collect(cb) method to accumulate data.\nhttp.createServer(function(req, res) {\n    req.pipe(iconv.decodeStream('win1251')).collect(function(err, body) {\n        assert(typeof body == 'string');\n        console.log(body); // full request body string\n    });\n});\n```\n\n## Supported encodings\n\n *  All node.js native encodings: utf8, ucs2 / utf16-le, ascii, binary, base64, hex.\n *  Additional unicode encodings: utf16, utf16-be, utf-7, utf-7-imap, utf32, utf32-le, and utf32-be.\n *  All widespread singlebyte encodings: Windows 125x family, ISO-8859 family, \n    IBM/DOS codepages, Macintosh family, KOI8 family, all others supported by iconv library. \n    Aliases like 'latin1', 'us-ascii' also supported.\n *  All widespread multibyte encodings: CP932, CP936, CP949, CP950, GB2312, GBK, GB18030, Big5, Shift_JIS, EUC-JP.\n\nSee [all supported encodings on wiki](https://github.com/ashtuchkin/iconv-lite/wiki/Supported-Encodings).\n\nMost singlebyte encodings are generated automatically from [node-iconv](https://github.com/bnoordhuis/node-iconv). Thank you Ben Noordhuis and libiconv authors!\n\nMultibyte encodings are generated from [Unicode.org mappings](http://www.unicode.org/Public/MAPPINGS/) and [WHATWG Encoding Standard mappings](http://encoding.spec.whatwg.org/). Thank you, respective authors!\n\n## Encoding/decoding speed\n\nComparison with node-iconv module (1000x256kb, on MacBook Pro, Core i5/2.6 GHz, Node v0.12.0). \nNote: your results may vary, so please always check on your hardware.\n\n    operation             iconv@2.1.4   iconv-lite@0.4.7\n    ----------------------------------------------------------\n    encode('win1251')     ~96 Mb/s      ~320 Mb/s\n    decode('win1251')     ~95 Mb/s      ~246 Mb/s\n\n## BOM handling\n\n * Decoding: BOM is stripped by default, unless overridden by passing `stripBOM: false` in options\n   (f.ex. `iconv.decode(buf, enc, {stripBOM: false})`).\n   A callback might also be given as a `stripBOM` parameter - it'll be called if BOM character was actually found.\n * If you want to detect UTF-8 BOM when decoding other encodings, use [node-autodetect-decoder-stream](https://github.com/danielgindi/node-autodetect-decoder-stream) module.\n * Encoding: No BOM added, unless overridden by `addBOM: true` option.\n\n## UTF-16 Encodings\n\nThis library supports UTF-16LE, UTF-16BE and UTF-16 encodings. First two are straightforward, but UTF-16 is trying to be\nsmart about endianness in the following ways:\n * Decoding: uses BOM and 'spaces heuristic' to determine input endianness. Default is UTF-16LE, but can be \n   overridden with `defaultEncoding: 'utf-16be'` option. Strips BOM unless `stripBOM: false`.\n * Encoding: uses UTF-16LE and writes BOM by default. Use `addBOM: false` to override.\n\n## UTF-32 Encodings\n\nThis library supports UTF-32LE, UTF-32BE and UTF-32 encodings. Like the UTF-16 encoding above, UTF-32 defaults to UTF-32LE, but uses BOM and 'spaces heuristics' to determine input endianness. \n * The default of UTF-32LE can be overridden with the `defaultEncoding: 'utf-32be'` option. Strips BOM unless `stripBOM: false`.\n * Encoding: uses UTF-32LE and writes BOM by default. Use `addBOM: false` to override. (`defaultEncoding: 'utf-32be'` can also be used here to change encoding.)\n\n## Other notes\n\nWhen decoding, be sure to supply a Buffer to decode() method, otherwise [bad things usually happen](https://github.com/ashtuchkin/iconv-lite/wiki/Use-Buffers-when-decoding).  \nUntranslatable characters are set to � or ?. No transliteration is currently supported.  \nNode versions 0.10.31 and 0.11.13 are buggy, don't use them (see [#65](https://github.com/ashtuchkin/iconv-lite/issues/65), [#77](https://github.com/ashtuchkin/iconv-lite/issues/77)).  \n\n## Testing\n\n```sh\ngit clone git@github.com:ashtuchkin/iconv-lite.git\ncd iconv-lite\nnpm install\nnpm test\n    \n# To view performance:\nnpm run test:performance\n\n# To view test coverage: \nnpm run test:cov\nopen coverage/index.html\n```\n\n[npm-downloads-image]: https://badgen.net/npm/dm/iconv-lite\n[npm-downloads-url]: https://npmcharts.com/compare/iconv-lite?minimal=true\n[npm-url]: https://npmjs.org/package/iconv-lite\n[npm-version-image]: https://badgen.net/npm/v/iconv-lite\n[npm-install-size-image]: https://badgen.net/packagephobia/install/iconv-lite\n[npm-install-size-url]: https://packagephobia.com/result?p=iconv-lite\n[license-image]: https://img.shields.io/npm/l/iconv-lite.svg\n[license-url]: https://github.com/ashtuchkin/iconv-lite/blob/HEAD/LICENSE",
        "plugins/auto-review/mcp/node_modules/router/README.md": "# router\n\n[![NPM Version][npm-image]][npm-url]\n[![NPM Downloads][downloads-image]][downloads-url]\n[![Node.js Version][node-version-image]][node-version-url]\n[![Build Status][ci-image]][ci-url]\n[![Test Coverage][coveralls-image]][coveralls-url]\n\nSimple middleware-style router\n\n## Installation\n\nThis is a [Node.js](https://nodejs.org/en/) module available through the\n[npm registry](https://www.npmjs.com/). Installation is done using the\n[`npm install` command](https://docs.npmjs.com/getting-started/installing-npm-packages-locally):\n\n```bash\n$ npm install router\n```\n\n## API\n\n```js\nvar finalhandler = require('finalhandler')\nvar http = require('http')\nvar Router = require('router')\n\nvar router = Router()\nrouter.get('/', function (req, res) {\n  res.setHeader('Content-Type', 'text/plain; charset=utf-8')\n  res.end('Hello World!')\n})\n\nvar server = http.createServer(function (req, res) {\n  router(req, res, finalhandler(req, res))\n})\n\nserver.listen(3000)\n```\n\nThis module is currently an extracted version from the Express project,\nbut with the main change being it can be used with a plain `http.createServer`\nobject or other web frameworks by removing Express-specific API calls.\n\n## Router(options)\n\nOptions\n\n- `strict`        - When `false` trailing slashes are optional (default: `false`)\n- `caseSensitive` - When `true` the routing will be case sensitive. (default: `false`)\n- `mergeParams`   - When `true` any `req.params` passed to the router will be\n  merged into the router's `req.params`. (default: `false`) ([example](#example-using-mergeparams))\n\nReturns a function with the signature `router(req, res, callback)` where\n`callback([err])` must be provided to handle errors and fall-through from\nnot handling requests.\n\n### router.use([path], ...middleware)\n\nUse the given [middleware function](#middleware) for all http methods on the\ngiven `path`, defaulting to the root path.\n\n`router` does not automatically see `use` as a handler. As such, it will not\nconsider it one for handling `OPTIONS` requests.\n\n* Note: If a `path` is specified, that `path` is stripped from the start of\n  `req.url`.\n\n<!-- eslint-disable no-undef -->\n\n```js\nrouter.use(function (req, res, next) {\n  // do your things\n\n  // continue to the next middleware\n  // the request will stall if this is not called\n  next()\n\n  // note: you should NOT call `next` if you have begun writing to the response\n})\n```\n\n[Middleware](#middleware) can themselves use `next('router')` at any time to\nexit the current router instance completely, invoking the top-level callback.\n\n### router\\[method](path, ...[middleware], handler)\n\nThe [http methods](https://github.com/jshttp/methods/blob/master/index.js) provide\nthe routing functionality in `router`.\n\nMethod middleware and handlers follow usual [middleware](#middleware) behavior,\nexcept they will only be called when the method and path match the request.\n\n<!-- eslint-disable no-undef -->\n\n```js\n// handle a `GET` request\nrouter.get('/', function (req, res) {\n  res.setHeader('Content-Type', 'text/plain; charset=utf-8')\n  res.end('Hello World!')\n})\n```\n\n[Middleware](#middleware) given before the handler have one additional trick,\nthey may invoke `next('route')`. Calling `next('route')` bypasses the remaining\nmiddleware and the handler mounted for this route, passing the request to the\nnext route suitable for handling this request.\n\nRoute handlers and middleware can themselves use `next('router')` at any time\nto exit the current router instance completely, invoking the top-level callback.\n\n### router.param(name, param_middleware)\n\nMaps the specified path parameter `name` to a specialized param-capturing middleware.\n\nThis function positions the middleware in the same stack as `.use`.\n\nThe function can optionally return a `Promise` object. If a `Promise` object\nis returned from the function, the router will attach an `onRejected` callback\nusing `.then`. If the promise is rejected, `next` will be called with the\nrejected value, or an error if the value is falsy.\n\nParameter mapping is used to provide pre-conditions to routes\nwhich use normalized placeholders. For example a _:user_id_ parameter\ncould automatically load a user's information from the database without\nany additional code:\n\n<!-- eslint-disable no-undef -->\n\n```js\nrouter.param('user_id', function (req, res, next, id) {\n  User.find(id, function (err, user) {\n    if (err) {\n      return next(err)\n    } else if (!user) {\n      return next(new Error('failed to load user'))\n    }\n    req.user = user\n\n    // continue processing the request\n    next()\n  })\n})\n```\n\n### router.route(path)\n\nCreates an instance of a single `Route` for the given `path`.\n(See `Router.Route` below)\n\nRoutes can be used to handle http `methods` with their own, optional middleware.\n\nUsing `router.route(path)` is a recommended approach to avoiding duplicate\nroute naming and thus typo errors.\n\n<!-- eslint-disable no-undef, no-unused-vars -->\n\n```js\nvar api = router.route('/api/')\n```\n\n## Router.Route(path)\n\nRepresents a single route as an instance that can be used to handle http\n`methods` with it's own, optional middleware.\n\n### route\\[method](handler)\n\nThese are functions which you can directly call on a route to register a new\n`handler` for the `method` on the route.\n\n<!-- eslint-disable no-undef -->\n\n```js\n// handle a `GET` request\nvar status = router.route('/status')\n\nstatus.get(function (req, res) {\n  res.setHeader('Content-Type', 'text/plain; charset=utf-8')\n  res.end('All Systems Green!')\n})\n```\n\n### route.all(handler)\n\nAdds a handler for all HTTP methods to this route.\n\nThe handler can behave like middleware and call `next` to continue processing\nrather than responding.\n\n<!-- eslint-disable no-undef -->\n\n```js\nrouter.route('/')\n  .all(function (req, res, next) {\n    next()\n  })\n  .all(checkSomething)\n  .get(function (req, res) {\n    res.setHeader('Content-Type', 'text/plain; charset=utf-8')\n    res.end('Hello World!')\n  })\n```\n\n## Middleware\n\nMiddleware (and method handlers) are functions that follow specific function\nparameters and have defined behavior when used with `router`. The most common\nformat is with three parameters - \"req\", \"res\" and \"next\".\n\n- `req`  - This is a [HTTP incoming message](https://nodejs.org/api/http.html#http_http_incomingmessage) instance.\n- `res`  - This is a [HTTP server response](https://nodejs.org/api/http.html#http_class_http_serverresponse) instance.\n- `next` - Calling this function that tells `router` to proceed to the next matching middleware or method handler. It accepts an error as the first argument.\n\nThe function can optionally return a `Promise` object. If a `Promise` object\nis returned from the function, the router will attach an `onRejected` callback\nusing `.then`. If the promise is rejected, `next` will be called with the\nrejected value, or an error if the value is falsy.\n\nMiddleware and method handlers can also be defined with four arguments. When\nthe function has four parameters defined, the first argument is an error and\nsubsequent arguments remain, becoming - \"err\", \"req\", \"res\", \"next\". These\nfunctions are \"error handling middleware\", and can be used for handling\nerrors that occurred in previous handlers (E.g. from calling `next(err)`).\nThis is most used when you want to define arbitrary rendering of errors.\n\n<!-- eslint-disable no-undef -->\n\n```js\nrouter.get('/error_route', function (req, res, next) {\n  return next(new Error('Bad Request'))\n})\n\nrouter.use(function (err, req, res, next) {\n  res.end(err.message) //= > \"Bad Request\"\n})\n```\n\nError handling middleware will **only** be invoked when an error was given. As\nlong as the error is in the pipeline, normal middleware and handlers will be\nbypassed - only error handling middleware will be invoked with an error.\n\n## Examples\n\n```js\n// import our modules\nvar http = require('http')\nvar Router = require('router')\nvar finalhandler = require('finalhandler')\nvar compression = require('compression')\nvar bodyParser = require('body-parser')\n\n// store our message to display\nvar message = 'Hello World!'\n\n// initialize the router & server and add a final callback.\nvar router = Router()\nvar server = http.createServer(function onRequest (req, res) {\n  router(req, res, finalhandler(req, res))\n})\n\n// use some middleware and compress all outgoing responses\nrouter.use(compression())\n\n// handle `GET` requests to `/message`\nrouter.get('/message', function (req, res) {\n  res.statusCode = 200\n  res.setHeader('Content-Type', 'text/plain; charset=utf-8')\n  res.end(message + '\\n')\n})\n\n// create and mount a new router for our API\nvar api = Router()\nrouter.use('/api/', api)\n\n// add a body parsing middleware to our API\napi.use(bodyParser.json())\n\n// handle `PATCH` requests to `/api/set-message`\napi.patch('/set-message', function (req, res) {\n  if (req.body.value) {\n    message = req.body.value\n\n    res.statusCode = 200\n    res.setHeader('Content-Type', 'text/plain; charset=utf-8')\n    res.end(message + '\\n')\n  } else {\n    res.statusCode = 400\n    res.setHeader('Content-Type', 'text/plain; charset=utf-8')\n    res.end('Invalid API Syntax\\n')\n  }\n})\n\n// make our http server listen to connections\nserver.listen(8080)\n```\n\nYou can get the message by running this command in your terminal,\n or navigating to `127.0.0.1:8080` in a web browser.\n```bash\ncurl http://127.0.0.1:8080\n```\n\nYou can set the message by sending it a `PATCH` request via this command:\n```bash\ncurl http://127.0.0.1:8080/api/set-message -X PATCH -H \"Content-Type: application/json\" -d '{\"value\":\"Cats!\"}'\n```\n\n### Example using mergeParams\n\n```js\nvar http = require('http')\nvar Router = require('router')\nvar finalhandler = require('finalhandler')\n\n// this example is about the mergeParams option\nvar opts = { mergeParams: true }\n\n// make a router with out special options\nvar router = Router(opts)\nvar server = http.createServer(function onRequest (req, res) {\n  // set something to be passed into the router\n  req.params = { type: 'kitten' }\n\n  router(req, res, finalhandler(req, res))\n})\n\nrouter.get('/', function (req, res) {\n  res.statusCode = 200\n  res.setHeader('Content-Type', 'text/plain; charset=utf-8')\n\n  // with respond with the the params that were passed in\n  res.end(req.params.type + '\\n')\n})\n\n// make another router with our options\nvar handler = Router(opts)\n\n// mount our new router to a route that accepts a param\nrouter.use('/:path', handler)\n\nhandler.get('/', function (req, res) {\n  res.statusCode = 200\n  res.setHeader('Content-Type', 'text/plain; charset=utf-8')\n\n  // will respond with the param of the router's parent route\n  res.end(req.params.path + '\\n')\n})\n\n// make our http server listen to connections\nserver.listen(8080)\n```\n\nNow you can get the type, or what path you are requesting:\n```bash\ncurl http://127.0.0.1:8080\n> kitten\ncurl http://127.0.0.1:8080/such_path\n> such_path\n```\n\n### Example of advanced `.route()` usage\n\nThis example shows how to implement routes where there is a custom\nhandler to execute when the path matched, but no methods matched.\nWithout any special handling, this would be treated as just a\ngeneric non-match by `router` (which typically results in a 404),\nbut with a custom handler, a `405 Method Not Allowed` can be sent.\n\n```js\nvar http = require('http')\nvar finalhandler = require('finalhandler')\nvar Router = require('router')\n\n// create the router and server\nvar router = new Router()\nvar server = http.createServer(function onRequest (req, res) {\n  router(req, res, finalhandler(req, res))\n})\n\n// register a route and add all methods\nrouter.route('/pet/:id')\n  .get(function (req, res) {\n    // this is GET /pet/:id\n    res.setHeader('Content-Type', 'application/json')\n    res.end(JSON.stringify({ name: 'tobi' }))\n  })\n  .delete(function (req, res) {\n    // this is DELETE /pet/:id\n    res.end()\n  })\n  .all(function (req, res) {\n    // this is called for all other methods not\n    // defined above for /pet/:id\n    res.statusCode = 405\n    res.end()\n  })\n\n// make our http server listen to connections\nserver.listen(8080)\n```\n\n## License\n\n[MIT](LICENSE)\n\n[ci-image]: https://badgen.net/github/checks/pillarjs/router/master?label=ci\n[ci-url]: https://github.com/pillarjs/router/actions/workflows/ci.yml\n[npm-image]: https://img.shields.io/npm/v/router.svg\n[npm-url]: https://npmjs.org/package/router\n[node-version-image]: https://img.shields.io/node/v/router.svg\n[node-version-url]: http://nodejs.org/download/\n[coveralls-image]: https://img.shields.io/coveralls/pillarjs/router/master.svg\n[coveralls-url]: https://coveralls.io/r/pillarjs/router?branch=master\n[downloads-image]: https://img.shields.io/npm/dm/router.svg\n[downloads-url]: https://npmjs.org/package/router\n",
        "plugins/auto-review/mcp/node_modules/safe-buffer/README.md": "# safe-buffer [![travis][travis-image]][travis-url] [![npm][npm-image]][npm-url] [![downloads][downloads-image]][downloads-url] [![javascript style guide][standard-image]][standard-url]\n\n[travis-image]: https://img.shields.io/travis/feross/safe-buffer/master.svg\n[travis-url]: https://travis-ci.org/feross/safe-buffer\n[npm-image]: https://img.shields.io/npm/v/safe-buffer.svg\n[npm-url]: https://npmjs.org/package/safe-buffer\n[downloads-image]: https://img.shields.io/npm/dm/safe-buffer.svg\n[downloads-url]: https://npmjs.org/package/safe-buffer\n[standard-image]: https://img.shields.io/badge/code_style-standard-brightgreen.svg\n[standard-url]: https://standardjs.com\n\n#### Safer Node.js Buffer API\n\n**Use the new Node.js Buffer APIs (`Buffer.from`, `Buffer.alloc`,\n`Buffer.allocUnsafe`, `Buffer.allocUnsafeSlow`) in all versions of Node.js.**\n\n**Uses the built-in implementation when available.**\n\n## install\n\n```\nnpm install safe-buffer\n```\n\n## usage\n\nThe goal of this package is to provide a safe replacement for the node.js `Buffer`.\n\nIt's a drop-in replacement for `Buffer`. You can use it by adding one `require` line to\nthe top of your node.js modules:\n\n```js\nvar Buffer = require('safe-buffer').Buffer\n\n// Existing buffer code will continue to work without issues:\n\nnew Buffer('hey', 'utf8')\nnew Buffer([1, 2, 3], 'utf8')\nnew Buffer(obj)\nnew Buffer(16) // create an uninitialized buffer (potentially unsafe)\n\n// But you can use these new explicit APIs to make clear what you want:\n\nBuffer.from('hey', 'utf8') // convert from many types to a Buffer\nBuffer.alloc(16) // create a zero-filled buffer (safe)\nBuffer.allocUnsafe(16) // create an uninitialized buffer (potentially unsafe)\n```\n\n## api\n\n### Class Method: Buffer.from(array)\n<!-- YAML\nadded: v3.0.0\n-->\n\n* `array` {Array}\n\nAllocates a new `Buffer` using an `array` of octets.\n\n```js\nconst buf = Buffer.from([0x62,0x75,0x66,0x66,0x65,0x72]);\n  // creates a new Buffer containing ASCII bytes\n  // ['b','u','f','f','e','r']\n```\n\nA `TypeError` will be thrown if `array` is not an `Array`.\n\n### Class Method: Buffer.from(arrayBuffer[, byteOffset[, length]])\n<!-- YAML\nadded: v5.10.0\n-->\n\n* `arrayBuffer` {ArrayBuffer} The `.buffer` property of a `TypedArray` or\n  a `new ArrayBuffer()`\n* `byteOffset` {Number} Default: `0`\n* `length` {Number} Default: `arrayBuffer.length - byteOffset`\n\nWhen passed a reference to the `.buffer` property of a `TypedArray` instance,\nthe newly created `Buffer` will share the same allocated memory as the\nTypedArray.\n\n```js\nconst arr = new Uint16Array(2);\narr[0] = 5000;\narr[1] = 4000;\n\nconst buf = Buffer.from(arr.buffer); // shares the memory with arr;\n\nconsole.log(buf);\n  // Prints: <Buffer 88 13 a0 0f>\n\n// changing the TypedArray changes the Buffer also\narr[1] = 6000;\n\nconsole.log(buf);\n  // Prints: <Buffer 88 13 70 17>\n```\n\nThe optional `byteOffset` and `length` arguments specify a memory range within\nthe `arrayBuffer` that will be shared by the `Buffer`.\n\n```js\nconst ab = new ArrayBuffer(10);\nconst buf = Buffer.from(ab, 0, 2);\nconsole.log(buf.length);\n  // Prints: 2\n```\n\nA `TypeError` will be thrown if `arrayBuffer` is not an `ArrayBuffer`.\n\n### Class Method: Buffer.from(buffer)\n<!-- YAML\nadded: v3.0.0\n-->\n\n* `buffer` {Buffer}\n\nCopies the passed `buffer` data onto a new `Buffer` instance.\n\n```js\nconst buf1 = Buffer.from('buffer');\nconst buf2 = Buffer.from(buf1);\n\nbuf1[0] = 0x61;\nconsole.log(buf1.toString());\n  // 'auffer'\nconsole.log(buf2.toString());\n  // 'buffer' (copy is not changed)\n```\n\nA `TypeError` will be thrown if `buffer` is not a `Buffer`.\n\n### Class Method: Buffer.from(str[, encoding])\n<!-- YAML\nadded: v5.10.0\n-->\n\n* `str` {String} String to encode.\n* `encoding` {String} Encoding to use, Default: `'utf8'`\n\nCreates a new `Buffer` containing the given JavaScript string `str`. If\nprovided, the `encoding` parameter identifies the character encoding.\nIf not provided, `encoding` defaults to `'utf8'`.\n\n```js\nconst buf1 = Buffer.from('this is a tést');\nconsole.log(buf1.toString());\n  // prints: this is a tést\nconsole.log(buf1.toString('ascii'));\n  // prints: this is a tC)st\n\nconst buf2 = Buffer.from('7468697320697320612074c3a97374', 'hex');\nconsole.log(buf2.toString());\n  // prints: this is a tést\n```\n\nA `TypeError` will be thrown if `str` is not a string.\n\n### Class Method: Buffer.alloc(size[, fill[, encoding]])\n<!-- YAML\nadded: v5.10.0\n-->\n\n* `size` {Number}\n* `fill` {Value} Default: `undefined`\n* `encoding` {String} Default: `utf8`\n\nAllocates a new `Buffer` of `size` bytes. If `fill` is `undefined`, the\n`Buffer` will be *zero-filled*.\n\n```js\nconst buf = Buffer.alloc(5);\nconsole.log(buf);\n  // <Buffer 00 00 00 00 00>\n```\n\nThe `size` must be less than or equal to the value of\n`require('buffer').kMaxLength` (on 64-bit architectures, `kMaxLength` is\n`(2^31)-1`). Otherwise, a [`RangeError`][] is thrown. A zero-length Buffer will\nbe created if a `size` less than or equal to 0 is specified.\n\nIf `fill` is specified, the allocated `Buffer` will be initialized by calling\n`buf.fill(fill)`. See [`buf.fill()`][] for more information.\n\n```js\nconst buf = Buffer.alloc(5, 'a');\nconsole.log(buf);\n  // <Buffer 61 61 61 61 61>\n```\n\nIf both `fill` and `encoding` are specified, the allocated `Buffer` will be\ninitialized by calling `buf.fill(fill, encoding)`. For example:\n\n```js\nconst buf = Buffer.alloc(11, 'aGVsbG8gd29ybGQ=', 'base64');\nconsole.log(buf);\n  // <Buffer 68 65 6c 6c 6f 20 77 6f 72 6c 64>\n```\n\nCalling `Buffer.alloc(size)` can be significantly slower than the alternative\n`Buffer.allocUnsafe(size)` but ensures that the newly created `Buffer` instance\ncontents will *never contain sensitive data*.\n\nA `TypeError` will be thrown if `size` is not a number.\n\n### Class Method: Buffer.allocUnsafe(size)\n<!-- YAML\nadded: v5.10.0\n-->\n\n* `size` {Number}\n\nAllocates a new *non-zero-filled* `Buffer` of `size` bytes.  The `size` must\nbe less than or equal to the value of `require('buffer').kMaxLength` (on 64-bit\narchitectures, `kMaxLength` is `(2^31)-1`). Otherwise, a [`RangeError`][] is\nthrown. A zero-length Buffer will be created if a `size` less than or equal to\n0 is specified.\n\nThe underlying memory for `Buffer` instances created in this way is *not\ninitialized*. The contents of the newly created `Buffer` are unknown and\n*may contain sensitive data*. Use [`buf.fill(0)`][] to initialize such\n`Buffer` instances to zeroes.\n\n```js\nconst buf = Buffer.allocUnsafe(5);\nconsole.log(buf);\n  // <Buffer 78 e0 82 02 01>\n  // (octets will be different, every time)\nbuf.fill(0);\nconsole.log(buf);\n  // <Buffer 00 00 00 00 00>\n```\n\nA `TypeError` will be thrown if `size` is not a number.\n\nNote that the `Buffer` module pre-allocates an internal `Buffer` instance of\nsize `Buffer.poolSize` that is used as a pool for the fast allocation of new\n`Buffer` instances created using `Buffer.allocUnsafe(size)` (and the deprecated\n`new Buffer(size)` constructor) only when `size` is less than or equal to\n`Buffer.poolSize >> 1` (floor of `Buffer.poolSize` divided by two). The default\nvalue of `Buffer.poolSize` is `8192` but can be modified.\n\nUse of this pre-allocated internal memory pool is a key difference between\ncalling `Buffer.alloc(size, fill)` vs. `Buffer.allocUnsafe(size).fill(fill)`.\nSpecifically, `Buffer.alloc(size, fill)` will *never* use the internal Buffer\npool, while `Buffer.allocUnsafe(size).fill(fill)` *will* use the internal\nBuffer pool if `size` is less than or equal to half `Buffer.poolSize`. The\ndifference is subtle but can be important when an application requires the\nadditional performance that `Buffer.allocUnsafe(size)` provides.\n\n### Class Method: Buffer.allocUnsafeSlow(size)\n<!-- YAML\nadded: v5.10.0\n-->\n\n* `size` {Number}\n\nAllocates a new *non-zero-filled* and non-pooled `Buffer` of `size` bytes.  The\n`size` must be less than or equal to the value of\n`require('buffer').kMaxLength` (on 64-bit architectures, `kMaxLength` is\n`(2^31)-1`). Otherwise, a [`RangeError`][] is thrown. A zero-length Buffer will\nbe created if a `size` less than or equal to 0 is specified.\n\nThe underlying memory for `Buffer` instances created in this way is *not\ninitialized*. The contents of the newly created `Buffer` are unknown and\n*may contain sensitive data*. Use [`buf.fill(0)`][] to initialize such\n`Buffer` instances to zeroes.\n\nWhen using `Buffer.allocUnsafe()` to allocate new `Buffer` instances,\nallocations under 4KB are, by default, sliced from a single pre-allocated\n`Buffer`. This allows applications to avoid the garbage collection overhead of\ncreating many individually allocated Buffers. This approach improves both\nperformance and memory usage by eliminating the need to track and cleanup as\nmany `Persistent` objects.\n\nHowever, in the case where a developer may need to retain a small chunk of\nmemory from a pool for an indeterminate amount of time, it may be appropriate\nto create an un-pooled Buffer instance using `Buffer.allocUnsafeSlow()` then\ncopy out the relevant bits.\n\n```js\n// need to keep around a few small chunks of memory\nconst store = [];\n\nsocket.on('readable', () => {\n  const data = socket.read();\n  // allocate for retained data\n  const sb = Buffer.allocUnsafeSlow(10);\n  // copy the data into the new allocation\n  data.copy(sb, 0, 0, 10);\n  store.push(sb);\n});\n```\n\nUse of `Buffer.allocUnsafeSlow()` should be used only as a last resort *after*\na developer has observed undue memory retention in their applications.\n\nA `TypeError` will be thrown if `size` is not a number.\n\n### All the Rest\n\nThe rest of the `Buffer` API is exactly the same as in node.js.\n[See the docs](https://nodejs.org/api/buffer.html).\n\n\n## Related links\n\n- [Node.js issue: Buffer(number) is unsafe](https://github.com/nodejs/node/issues/4660)\n- [Node.js Enhancement Proposal: Buffer.from/Buffer.alloc/Buffer.zalloc/Buffer() soft-deprecate](https://github.com/nodejs/node-eps/pull/4)\n\n## Why is `Buffer` unsafe?\n\nToday, the node.js `Buffer` constructor is overloaded to handle many different argument\ntypes like `String`, `Array`, `Object`, `TypedArrayView` (`Uint8Array`, etc.),\n`ArrayBuffer`, and also `Number`.\n\nThe API is optimized for convenience: you can throw any type at it, and it will try to do\nwhat you want.\n\nBecause the Buffer constructor is so powerful, you often see code like this:\n\n```js\n// Convert UTF-8 strings to hex\nfunction toHex (str) {\n  return new Buffer(str).toString('hex')\n}\n```\n\n***But what happens if `toHex` is called with a `Number` argument?***\n\n### Remote Memory Disclosure\n\nIf an attacker can make your program call the `Buffer` constructor with a `Number`\nargument, then they can make it allocate uninitialized memory from the node.js process.\nThis could potentially disclose TLS private keys, user data, or database passwords.\n\nWhen the `Buffer` constructor is passed a `Number` argument, it returns an\n**UNINITIALIZED** block of memory of the specified `size`. When you create a `Buffer` like\nthis, you **MUST** overwrite the contents before returning it to the user.\n\nFrom the [node.js docs](https://nodejs.org/api/buffer.html#buffer_new_buffer_size):\n\n> `new Buffer(size)`\n>\n> - `size` Number\n>\n> The underlying memory for `Buffer` instances created in this way is not initialized.\n> **The contents of a newly created `Buffer` are unknown and could contain sensitive\n> data.** Use `buf.fill(0)` to initialize a Buffer to zeroes.\n\n(Emphasis our own.)\n\nWhenever the programmer intended to create an uninitialized `Buffer` you often see code\nlike this:\n\n```js\nvar buf = new Buffer(16)\n\n// Immediately overwrite the uninitialized buffer with data from another buffer\nfor (var i = 0; i < buf.length; i++) {\n  buf[i] = otherBuf[i]\n}\n```\n\n\n### Would this ever be a problem in real code?\n\nYes. It's surprisingly common to forget to check the type of your variables in a\ndynamically-typed language like JavaScript.\n\nUsually the consequences of assuming the wrong type is that your program crashes with an\nuncaught exception. But the failure mode for forgetting to check the type of arguments to\nthe `Buffer` constructor is more catastrophic.\n\nHere's an example of a vulnerable service that takes a JSON payload and converts it to\nhex:\n\n```js\n// Take a JSON payload {str: \"some string\"} and convert it to hex\nvar server = http.createServer(function (req, res) {\n  var data = ''\n  req.setEncoding('utf8')\n  req.on('data', function (chunk) {\n    data += chunk\n  })\n  req.on('end', function () {\n    var body = JSON.parse(data)\n    res.end(new Buffer(body.str).toString('hex'))\n  })\n})\n\nserver.listen(8080)\n```\n\nIn this example, an http client just has to send:\n\n```json\n{\n  \"str\": 1000\n}\n```\n\nand it will get back 1,000 bytes of uninitialized memory from the server.\n\nThis is a very serious bug. It's similar in severity to the\n[the Heartbleed bug](http://heartbleed.com/) that allowed disclosure of OpenSSL process\nmemory by remote attackers.\n\n\n### Which real-world packages were vulnerable?\n\n#### [`bittorrent-dht`](https://www.npmjs.com/package/bittorrent-dht)\n\n[Mathias Buus](https://github.com/mafintosh) and I\n([Feross Aboukhadijeh](http://feross.org/)) found this issue in one of our own packages,\n[`bittorrent-dht`](https://www.npmjs.com/package/bittorrent-dht). The bug would allow\nanyone on the internet to send a series of messages to a user of `bittorrent-dht` and get\nthem to reveal 20 bytes at a time of uninitialized memory from the node.js process.\n\nHere's\n[the commit](https://github.com/feross/bittorrent-dht/commit/6c7da04025d5633699800a99ec3fbadf70ad35b8)\nthat fixed it. We released a new fixed version, created a\n[Node Security Project disclosure](https://nodesecurity.io/advisories/68), and deprecated all\nvulnerable versions on npm so users will get a warning to upgrade to a newer version.\n\n#### [`ws`](https://www.npmjs.com/package/ws)\n\nThat got us wondering if there were other vulnerable packages. Sure enough, within a short\nperiod of time, we found the same issue in [`ws`](https://www.npmjs.com/package/ws), the\nmost popular WebSocket implementation in node.js.\n\nIf certain APIs were called with `Number` parameters instead of `String` or `Buffer` as\nexpected, then uninitialized server memory would be disclosed to the remote peer.\n\nThese were the vulnerable methods:\n\n```js\nsocket.send(number)\nsocket.ping(number)\nsocket.pong(number)\n```\n\nHere's a vulnerable socket server with some echo functionality:\n\n```js\nserver.on('connection', function (socket) {\n  socket.on('message', function (message) {\n    message = JSON.parse(message)\n    if (message.type === 'echo') {\n      socket.send(message.data) // send back the user's message\n    }\n  })\n})\n```\n\n`socket.send(number)` called on the server, will disclose server memory.\n\nHere's [the release](https://github.com/websockets/ws/releases/tag/1.0.1) where the issue\nwas fixed, with a more detailed explanation. Props to\n[Arnout Kazemier](https://github.com/3rd-Eden) for the quick fix. Here's the\n[Node Security Project disclosure](https://nodesecurity.io/advisories/67).\n\n\n### What's the solution?\n\nIt's important that node.js offers a fast way to get memory otherwise performance-critical\napplications would needlessly get a lot slower.\n\nBut we need a better way to *signal our intent* as programmers. **When we want\nuninitialized memory, we should request it explicitly.**\n\nSensitive functionality should not be packed into a developer-friendly API that loosely\naccepts many different types. This type of API encourages the lazy practice of passing\nvariables in without checking the type very carefully.\n\n#### A new API: `Buffer.allocUnsafe(number)`\n\nThe functionality of creating buffers with uninitialized memory should be part of another\nAPI. We propose `Buffer.allocUnsafe(number)`. This way, it's not part of an API that\nfrequently gets user input of all sorts of different types passed into it.\n\n```js\nvar buf = Buffer.allocUnsafe(16) // careful, uninitialized memory!\n\n// Immediately overwrite the uninitialized buffer with data from another buffer\nfor (var i = 0; i < buf.length; i++) {\n  buf[i] = otherBuf[i]\n}\n```\n\n\n### How do we fix node.js core?\n\nWe sent [a PR to node.js core](https://github.com/nodejs/node/pull/4514) (merged as\n`semver-major`) which defends against one case:\n\n```js\nvar str = 16\nnew Buffer(str, 'utf8')\n```\n\nIn this situation, it's implied that the programmer intended the first argument to be a\nstring, since they passed an encoding as a second argument. Today, node.js will allocate\nuninitialized memory in the case of `new Buffer(number, encoding)`, which is probably not\nwhat the programmer intended.\n\nBut this is only a partial solution, since if the programmer does `new Buffer(variable)`\n(without an `encoding` parameter) there's no way to know what they intended. If `variable`\nis sometimes a number, then uninitialized memory will sometimes be returned.\n\n### What's the real long-term fix?\n\nWe could deprecate and remove `new Buffer(number)` and use `Buffer.allocUnsafe(number)` when\nwe need uninitialized memory. But that would break 1000s of packages.\n\n~~We believe the best solution is to:~~\n\n~~1. Change `new Buffer(number)` to return safe, zeroed-out memory~~\n\n~~2. Create a new API for creating uninitialized Buffers. We propose: `Buffer.allocUnsafe(number)`~~\n\n#### Update\n\nWe now support adding three new APIs:\n\n- `Buffer.from(value)` - convert from any type to a buffer\n- `Buffer.alloc(size)` - create a zero-filled buffer\n- `Buffer.allocUnsafe(size)` - create an uninitialized buffer with given size\n\nThis solves the core problem that affected `ws` and `bittorrent-dht` which is\n`Buffer(variable)` getting tricked into taking a number argument.\n\nThis way, existing code continues working and the impact on the npm ecosystem will be\nminimal. Over time, npm maintainers can migrate performance-critical code to use\n`Buffer.allocUnsafe(number)` instead of `new Buffer(number)`.\n\n\n### Conclusion\n\nWe think there's a serious design issue with the `Buffer` API as it exists today. It\npromotes insecure software by putting high-risk functionality into a convenient API\nwith friendly \"developer ergonomics\".\n\nThis wasn't merely a theoretical exercise because we found the issue in some of the\nmost popular npm packages.\n\nFortunately, there's an easy fix that can be applied today. Use `safe-buffer` in place of\n`buffer`.\n\n```js\nvar Buffer = require('safe-buffer').Buffer\n```\n\nEventually, we hope that node.js core can switch to this new, safer behavior. We believe\nthe impact on the ecosystem would be minimal since it's not a breaking change.\nWell-maintained, popular packages would be updated to use `Buffer.alloc` quickly, while\nolder, insecure packages would magically become safe from this attack vector.\n\n\n## links\n\n- [Node.js PR: buffer: throw if both length and enc are passed](https://github.com/nodejs/node/pull/4514)\n- [Node Security Project disclosure for `ws`](https://nodesecurity.io/advisories/67)\n- [Node Security Project disclosure for`bittorrent-dht`](https://nodesecurity.io/advisories/68)\n\n\n## credit\n\nThe original issues in `bittorrent-dht`\n([disclosure](https://nodesecurity.io/advisories/68)) and\n`ws` ([disclosure](https://nodesecurity.io/advisories/67)) were discovered by\n[Mathias Buus](https://github.com/mafintosh) and\n[Feross Aboukhadijeh](http://feross.org/).\n\nThanks to [Adam Baldwin](https://github.com/evilpacket) for helping disclose these issues\nand for his work running the [Node Security Project](https://nodesecurity.io/).\n\nThanks to [John Hiesey](https://github.com/jhiesey) for proofreading this README and\nauditing the code.\n\n\n## license\n\nMIT. Copyright (C) [Feross Aboukhadijeh](http://feross.org)\n",
        "plugins/auto-review/mcp/node_modules/send/README.md": "# send\n\n[![NPM Version][npm-version-image]][npm-url]\n[![NPM Downloads][npm-downloads-image]][npm-url]\n[![CI][github-actions-ci-image]][github-actions-ci-url]\n[![Test Coverage][coveralls-image]][coveralls-url]\n\nSend is a library for streaming files from the file system as a http response\nsupporting partial responses (Ranges), conditional-GET negotiation (If-Match,\nIf-Unmodified-Since, If-None-Match, If-Modified-Since), high test coverage,\nand granular events which may be leveraged to take appropriate actions in your\napplication or framework.\n\nLooking to serve up entire folders mapped to URLs? Try [serve-static](https://www.npmjs.org/package/serve-static).\n\n## Installation\n\nThis is a [Node.js](https://nodejs.org/en/) module available through the\n[npm registry](https://www.npmjs.com/). Installation is done using the\n[`npm install` command](https://docs.npmjs.com/getting-started/installing-npm-packages-locally):\n\n```bash\n$ npm install send\n```\n\n## API\n\n```js\nvar send = require('send')\n```\n\n### send(req, path, [options])\n\nCreate a new `SendStream` for the given path to send to a `res`. The `req` is\nthe Node.js HTTP request and the `path` is a urlencoded path to send (urlencoded,\nnot the actual file-system path).\n\n#### Options\n\n##### acceptRanges\n\nEnable or disable accepting ranged requests, defaults to true.\nDisabling this will not send `Accept-Ranges` and ignore the contents\nof the `Range` request header.\n\n##### cacheControl\n\nEnable or disable setting `Cache-Control` response header, defaults to\ntrue. Disabling this will ignore the `immutable` and `maxAge` options.\n\n##### dotfiles\n\nSet how \"dotfiles\" are treated when encountered. A dotfile is a file\nor directory that begins with a dot (\".\"). Note this check is done on\nthe path itself without checking if the path actually exists on the\ndisk. If `root` is specified, only the dotfiles above the root are\nchecked (i.e. the root itself can be within a dotfile when set\nto \"deny\").\n\n  - `'allow'` No special treatment for dotfiles.\n  - `'deny'` Send a 403 for any request for a dotfile.\n  - `'ignore'` Pretend like the dotfile does not exist and 404.\n\nThe default value is _similar_ to `'ignore'`, with the exception that\nthis default will not ignore the files within a directory that begins\nwith a dot, for backward-compatibility.\n\n##### end\n\nByte offset at which the stream ends, defaults to the length of the file\nminus 1. The end is inclusive in the stream, meaning `end: 3` will include\nthe 4th byte in the stream.\n\n##### etag\n\nEnable or disable etag generation, defaults to true.\n\n##### extensions\n\nIf a given file doesn't exist, try appending one of the given extensions,\nin the given order. By default, this is disabled (set to `false`). An\nexample value that will serve extension-less HTML files: `['html', 'htm']`.\nThis is skipped if the requested file already has an extension.\n\n##### immutable\n\nEnable or disable the `immutable` directive in the `Cache-Control` response\nheader, defaults to `false`. If set to `true`, the `maxAge` option should\nalso be specified to enable caching. The `immutable` directive will prevent\nsupported clients from making conditional requests during the life of the\n`maxAge` option to check if the file has changed.\n\n##### index\n\nBy default send supports \"index.html\" files, to disable this\nset `false` or to supply a new index pass a string or an array\nin preferred order.\n\n##### lastModified\n\nEnable or disable `Last-Modified` header, defaults to true. Uses the file\nsystem's last modified value.\n\n##### maxAge\n\nProvide a max-age in milliseconds for http caching, defaults to 0.\nThis can also be a string accepted by the\n[ms](https://www.npmjs.org/package/ms#readme) module.\n\n##### root\n\nServe files relative to `path`.\n\n##### start\n\nByte offset at which the stream starts, defaults to 0. The start is inclusive,\nmeaning `start: 2` will include the 3rd byte in the stream.\n\n#### Events\n\nThe `SendStream` is an event emitter and will emit the following events:\n\n  - `error` an error occurred `(err)`\n  - `directory` a directory was requested `(res, path)`\n  - `file` a file was requested `(path, stat)`\n  - `headers` the headers are about to be set on a file `(res, path, stat)`\n  - `stream` file streaming has started `(stream)`\n  - `end` streaming has completed\n\n#### .pipe\n\nThe `pipe` method is used to pipe the response into the Node.js HTTP response\nobject, typically `send(req, path, options).pipe(res)`.\n\n## Error-handling\n\nBy default when no `error` listeners are present an automatic response will be\nmade, otherwise you have full control over the response, aka you may show a 5xx\npage etc.\n\n## Caching\n\nIt does _not_ perform internal caching, you should use a reverse proxy cache\nsuch as Varnish for this, or those fancy things called CDNs. If your\napplication is small enough that it would benefit from single-node memory\ncaching, it's small enough that it does not need caching at all ;).\n\n## Debugging\n\nTo enable `debug()` instrumentation output export __DEBUG__:\n\n```\n$ DEBUG=send node app\n```\n\n## Running tests\n\n```\n$ npm install\n$ npm test\n```\n\n## Examples\n\n### Serve a specific file\n\nThis simple example will send a specific file to all requests.\n\n```js\nvar http = require('http')\nvar send = require('send')\n\nvar server = http.createServer(function onRequest (req, res) {\n  send(req, '/path/to/index.html')\n    .pipe(res)\n})\n\nserver.listen(3000)\n```\n\n### Serve all files from a directory\n\nThis simple example will just serve up all the files in a\ngiven directory as the top-level. For example, a request\n`GET /foo.txt` will send back `/www/public/foo.txt`.\n\n```js\nvar http = require('http')\nvar parseUrl = require('parseurl')\nvar send = require('send')\n\nvar server = http.createServer(function onRequest (req, res) {\n  send(req, parseUrl(req).pathname, { root: '/www/public' })\n    .pipe(res)\n})\n\nserver.listen(3000)\n```\n\n### Custom file types\n\n```js\nvar extname = require('path').extname\nvar http = require('http')\nvar parseUrl = require('parseurl')\nvar send = require('send')\n\nvar server = http.createServer(function onRequest (req, res) {\n  send(req, parseUrl(req).pathname, { root: '/www/public' })\n    .on('headers', function (res, path) {\n      switch (extname(path)) {\n        case '.x-mt':\n        case '.x-mtt':\n          // custom type for these extensions\n          res.setHeader('Content-Type', 'application/x-my-type')\n          break\n      }\n    })\n    .pipe(res)\n})\n\nserver.listen(3000)\n```\n\n### Custom directory index view\n\nThis is an example of serving up a structure of directories with a\ncustom function to render a listing of a directory.\n\n```js\nvar http = require('http')\nvar fs = require('fs')\nvar parseUrl = require('parseurl')\nvar send = require('send')\n\n// Transfer arbitrary files from within /www/example.com/public/*\n// with a custom handler for directory listing\nvar server = http.createServer(function onRequest (req, res) {\n  send(req, parseUrl(req).pathname, { index: false, root: '/www/public' })\n    .once('directory', directory)\n    .pipe(res)\n})\n\nserver.listen(3000)\n\n// Custom directory handler\nfunction directory (res, path) {\n  var stream = this\n\n  // redirect to trailing slash for consistent url\n  if (!stream.hasTrailingSlash()) {\n    return stream.redirect(path)\n  }\n\n  // get directory list\n  fs.readdir(path, function onReaddir (err, list) {\n    if (err) return stream.error(err)\n\n    // render an index for the directory\n    res.setHeader('Content-Type', 'text/plain; charset=UTF-8')\n    res.end(list.join('\\n') + '\\n')\n  })\n}\n```\n\n### Serving from a root directory with custom error-handling\n\n```js\nvar http = require('http')\nvar parseUrl = require('parseurl')\nvar send = require('send')\n\nvar server = http.createServer(function onRequest (req, res) {\n  // your custom error-handling logic:\n  function error (err) {\n    res.statusCode = err.status || 500\n    res.end(err.message)\n  }\n\n  // your custom headers\n  function headers (res, path, stat) {\n    // serve all files for download\n    res.setHeader('Content-Disposition', 'attachment')\n  }\n\n  // your custom directory handling logic:\n  function redirect () {\n    res.statusCode = 301\n    res.setHeader('Location', req.url + '/')\n    res.end('Redirecting to ' + req.url + '/')\n  }\n\n  // transfer arbitrary files from within\n  // /www/example.com/public/*\n  send(req, parseUrl(req).pathname, { root: '/www/public' })\n    .on('error', error)\n    .on('directory', redirect)\n    .on('headers', headers)\n    .pipe(res)\n})\n\nserver.listen(3000)\n```\n\n## License\n\n[MIT](LICENSE)\n\n[coveralls-image]: https://badgen.net/coveralls/c/github/pillarjs/send/master\n[coveralls-url]: https://coveralls.io/r/pillarjs/send?branch=master\n[github-actions-ci-image]: https://badgen.net/github/checks/pillarjs/send/master?label=linux\n[github-actions-ci-url]: https://github.com/pillarjs/send/actions/workflows/ci.yml\n[node-image]: https://badgen.net/npm/node/send\n[node-url]: https://nodejs.org/en/download/\n[npm-downloads-image]: https://badgen.net/npm/dm/send\n[npm-url]: https://npmjs.org/package/send\n[npm-version-image]: https://badgen.net/npm/v/send\n",
        "plugins/auto-review/mcp/node_modules/serve-static/README.md": "# serve-static\n\n[![NPM Version][npm-version-image]][npm-url]\n[![NPM Downloads][npm-downloads-image]][npm-url]\n[![CI][github-actions-ci-image]][github-actions-ci-url]\n[![Test Coverage][coveralls-image]][coveralls-url]\n\n## Install\n\nThis is a [Node.js](https://nodejs.org/en/) module available through the\n[npm registry](https://www.npmjs.com/). Installation is done using the\n[`npm install` command](https://docs.npmjs.com/getting-started/installing-npm-packages-locally):\n\n```sh\n$ npm install serve-static\n```\n\n## API\n\n```js\nvar serveStatic = require('serve-static')\n```\n\n### serveStatic(root, options)\n\nCreate a new middleware function to serve files from within a given root\ndirectory. The file to serve will be determined by combining `req.url`\nwith the provided root directory. When a file is not found, instead of\nsending a 404 response, this module will instead call `next()` to move on\nto the next middleware, allowing for stacking and fall-backs.\n\n#### Options\n\n##### acceptRanges\n\nEnable or disable accepting ranged requests, defaults to true.\nDisabling this will not send `Accept-Ranges` and ignore the contents\nof the `Range` request header.\n\n##### cacheControl\n\nEnable or disable setting `Cache-Control` response header, defaults to\ntrue. Disabling this will ignore the `immutable` and `maxAge` options.\n\n##### dotfiles\n\nSet how \"dotfiles\" are treated when encountered. A dotfile is a file\nor directory that begins with a dot (\".\"). Note this check is done on\nthe path itself without checking if the path actually exists on the\ndisk. If `root` is specified, only the dotfiles above the root are\nchecked (i.e. the root itself can be within a dotfile when set\nto \"deny\").\n\n  - `'allow'` No special treatment for dotfiles.\n  - `'deny'` Deny a request for a dotfile and 403/`next()`.\n  - `'ignore'` Pretend like the dotfile does not exist and 404/`next()`.\n\nThe default value is `'ignore'`.\n\n##### etag\n\nEnable or disable etag generation, defaults to true.\n\n##### extensions\n\nSet file extension fallbacks. When set, if a file is not found, the given\nextensions will be added to the file name and search for. The first that\nexists will be served. Example: `['html', 'htm']`.\n\nThe default value is `false`.\n\n##### fallthrough\n\nSet the middleware to have client errors fall-through as just unhandled\nrequests, otherwise forward a client error. The difference is that client\nerrors like a bad request or a request to a non-existent file will cause\nthis middleware to simply `next()` to your next middleware when this value\nis `true`. When this value is `false`, these errors (even 404s), will invoke\n`next(err)`.\n\nTypically `true` is desired such that multiple physical directories can be\nmapped to the same web address or for routes to fill in non-existent files.\n\nThe value `false` can be used if this middleware is mounted at a path that\nis designed to be strictly a single file system directory, which allows for\nshort-circuiting 404s for less overhead. This middleware will also reply to\nall methods.\n\nThe default value is `true`.\n\n##### immutable\n\nEnable or disable the `immutable` directive in the `Cache-Control` response\nheader, defaults to `false`. If set to `true`, the `maxAge` option should\nalso be specified to enable caching. The `immutable` directive will prevent\nsupported clients from making conditional requests during the life of the\n`maxAge` option to check if the file has changed.\n\n##### index\n\nBy default this module will send \"index.html\" files in response to a request\non a directory. To disable this set `false` or to supply a new index pass a\nstring or an array in preferred order.\n\n##### lastModified\n\nEnable or disable `Last-Modified` header, defaults to true. Uses the file\nsystem's last modified value.\n\n##### maxAge\n\nProvide a max-age in milliseconds for http caching, defaults to 0. This\ncan also be a string accepted by the [ms](https://www.npmjs.org/package/ms#readme)\nmodule.\n\n##### redirect\n\nRedirect to trailing \"/\" when the pathname is a dir. Defaults to `true`.\n\n##### setHeaders\n\nFunction to set custom headers on response. Alterations to the headers need to\noccur synchronously. The function is called as `fn(res, path, stat)`, where\nthe arguments are:\n\n  - `res` the response object\n  - `path` the file path that is being sent\n  - `stat` the stat object of the file that is being sent\n\n## Examples\n\n### Serve files with vanilla node.js http server\n\n```js\nvar finalhandler = require('finalhandler')\nvar http = require('http')\nvar serveStatic = require('serve-static')\n\n// Serve up public/ftp folder\nvar serve = serveStatic('public/ftp', { index: ['index.html', 'index.htm'] })\n\n// Create server\nvar server = http.createServer(function onRequest (req, res) {\n  serve(req, res, finalhandler(req, res))\n})\n\n// Listen\nserver.listen(3000)\n```\n\n### Serve all files as downloads\n\n```js\nvar contentDisposition = require('content-disposition')\nvar finalhandler = require('finalhandler')\nvar http = require('http')\nvar serveStatic = require('serve-static')\n\n// Serve up public/ftp folder\nvar serve = serveStatic('public/ftp', {\n  index: false,\n  setHeaders: setHeaders\n})\n\n// Set header to force download\nfunction setHeaders (res, path) {\n  res.setHeader('Content-Disposition', contentDisposition(path))\n}\n\n// Create server\nvar server = http.createServer(function onRequest (req, res) {\n  serve(req, res, finalhandler(req, res))\n})\n\n// Listen\nserver.listen(3000)\n```\n\n### Serving using express\n\n#### Simple\n\nThis is a simple example of using Express.\n\n```js\nvar express = require('express')\nvar serveStatic = require('serve-static')\n\nvar app = express()\n\napp.use(serveStatic('public/ftp', { index: ['default.html', 'default.htm'] }))\napp.listen(3000)\n```\n\n#### Multiple roots\n\nThis example shows a simple way to search through multiple directories.\nFiles are searched for in `public-optimized/` first, then `public/` second\nas a fallback.\n\n```js\nvar express = require('express')\nvar path = require('path')\nvar serveStatic = require('serve-static')\n\nvar app = express()\n\napp.use(serveStatic(path.join(__dirname, 'public-optimized')))\napp.use(serveStatic(path.join(__dirname, 'public')))\napp.listen(3000)\n```\n\n#### Different settings for paths\n\nThis example shows how to set a different max age depending on the served\nfile. In this example, HTML files are not cached, while everything else\nis for 1 day.\n\n```js\nvar express = require('express')\nvar path = require('path')\nvar serveStatic = require('serve-static')\n\nvar app = express()\n\napp.use(serveStatic(path.join(__dirname, 'public'), {\n  maxAge: '1d',\n  setHeaders: setCustomCacheControl\n}))\n\napp.listen(3000)\n\nfunction setCustomCacheControl (res, file) {\n  if (path.extname(file) === '.html') {\n    // Custom Cache-Control for HTML files\n    res.setHeader('Cache-Control', 'public, max-age=0')\n  }\n}\n```\n\n## License\n\n[MIT](LICENSE)\n\n[coveralls-image]: https://badgen.net/coveralls/c/github/expressjs/serve-static/master\n[coveralls-url]: https://coveralls.io/r/expressjs/serve-static?branch=master\n[github-actions-ci-image]: https://badgen.net/github/checks/expressjs/serve-static/master?label=linux\n[github-actions-ci-url]: https://github.com/expressjs/serve-static/actions/workflows/ci.yml\n[node-image]: https://badgen.net/npm/node/serve-static\n[node-url]: https://nodejs.org/en/download/\n[npm-downloads-image]: https://badgen.net/npm/dm/serve-static\n[npm-url]: https://npmjs.org/package/serve-static\n[npm-version-image]: https://badgen.net/npm/v/serve-static\n",
        "plugins/auto-review/mcp/node_modules/setprototypeof/README.md": "# Polyfill for `Object.setPrototypeOf`\n\n[![NPM Version](https://img.shields.io/npm/v/setprototypeof.svg)](https://npmjs.org/package/setprototypeof)\n[![NPM Downloads](https://img.shields.io/npm/dm/setprototypeof.svg)](https://npmjs.org/package/setprototypeof)\n[![js-standard-style](https://img.shields.io/badge/code%20style-standard-brightgreen.svg)](https://github.com/standard/standard)\n\nA simple cross platform implementation to set the prototype of an instianted object.  Supports all modern browsers and at least back to IE8.\n\n## Usage:\n\n```\n$ npm install --save setprototypeof\n```\n\n```javascript\nvar setPrototypeOf = require('setprototypeof')\n\nvar obj = {}\nsetPrototypeOf(obj, {\n  foo: function () {\n    return 'bar'\n  }\n})\nobj.foo() // bar\n```\n\nTypeScript is also supported:\n\n```typescript\nimport setPrototypeOf from 'setprototypeof'\n```\n",
        "plugins/auto-review/mcp/node_modules/side-channel-list/README.md": "# side-channel-list <sup>[![Version Badge][npm-version-svg]][package-url]</sup>\n\n[![github actions][actions-image]][actions-url]\n[![coverage][codecov-image]][codecov-url]\n[![License][license-image]][license-url]\n[![Downloads][downloads-image]][downloads-url]\n\n[![npm badge][npm-badge-png]][package-url]\n\nStore information about any JS value in a side channel, using a linked list.\n\nWarning: this implementation will leak memory until you `delete` the `key`.\nUse [`side-channel`](https://npmjs.com/side-channel) for the best available strategy.\n\n## Getting started\n\n```sh\nnpm install --save side-channel-list\n```\n\n## Usage/Examples\n\n```js\nconst assert = require('assert');\nconst getSideChannelList = require('side-channel-list');\n\nconst channel = getSideChannelList();\n\nconst key = {};\nassert.equal(channel.has(key), false);\nassert.throws(() => channel.assert(key), TypeError);\n\nchannel.set(key, 42);\n\nchannel.assert(key); // does not throw\nassert.equal(channel.has(key), true);\nassert.equal(channel.get(key), 42);\n\nchannel.delete(key);\nassert.equal(channel.has(key), false);\nassert.throws(() => channel.assert(key), TypeError);\n```\n\n## Tests\n\nClone the repo, `npm install`, and run `npm test`\n\n[package-url]: https://npmjs.org/package/side-channel-list\n[npm-version-svg]: https://versionbadg.es/ljharb/side-channel-list.svg\n[deps-svg]: https://david-dm.org/ljharb/side-channel-list.svg\n[deps-url]: https://david-dm.org/ljharb/side-channel-list\n[dev-deps-svg]: https://david-dm.org/ljharb/side-channel-list/dev-status.svg\n[dev-deps-url]: https://david-dm.org/ljharb/side-channel-list#info=devDependencies\n[npm-badge-png]: https://nodei.co/npm/side-channel-list.png?downloads=true&stars=true\n[license-image]: https://img.shields.io/npm/l/side-channel-list.svg\n[license-url]: LICENSE\n[downloads-image]: https://img.shields.io/npm/dm/side-channel-list.svg\n[downloads-url]: https://npm-stat.com/charts.html?package=side-channel-list\n[codecov-image]: https://codecov.io/gh/ljharb/side-channel-list/branch/main/graphs/badge.svg\n[codecov-url]: https://app.codecov.io/gh/ljharb/side-channel-list/\n[actions-image]: https://img.shields.io/endpoint?url=https://github-actions-badge-u3jn4tfpocch.runkit.sh/ljharb/side-channel-list\n[actions-url]: https://github.com/ljharb/side-channel-list/actions\n",
        "plugins/auto-review/mcp/node_modules/side-channel-map/README.md": "# side-channel-map <sup>[![Version Badge][npm-version-svg]][package-url]</sup>\n\n[![github actions][actions-image]][actions-url]\n[![coverage][codecov-image]][codecov-url]\n[![License][license-image]][license-url]\n[![Downloads][downloads-image]][downloads-url]\n\n[![npm badge][npm-badge-png]][package-url]\n\nStore information about any JS value in a side channel, using a Map.\n\nWarning: if the `key` is an object, this implementation will leak memory until you `delete` it.\nUse [`side-channel`](https://npmjs.com/side-channel) for the best available strategy.\n\n## Getting started\n\n```sh\nnpm install --save side-channel-map\n```\n\n## Usage/Examples\n\n```js\nconst assert = require('assert');\nconst getSideChannelMap = require('side-channel-map');\n\nconst channel = getSideChannelMap();\n\nconst key = {};\nassert.equal(channel.has(key), false);\nassert.throws(() => channel.assert(key), TypeError);\n\nchannel.set(key, 42);\n\nchannel.assert(key); // does not throw\nassert.equal(channel.has(key), true);\nassert.equal(channel.get(key), 42);\n\nchannel.delete(key);\nassert.equal(channel.has(key), false);\nassert.throws(() => channel.assert(key), TypeError);\n```\n\n## Tests\n\nClone the repo, `npm install`, and run `npm test`\n\n[package-url]: https://npmjs.org/package/side-channel-map\n[npm-version-svg]: https://versionbadg.es/ljharb/side-channel-map.svg\n[deps-svg]: https://david-dm.org/ljharb/side-channel-map.svg\n[deps-url]: https://david-dm.org/ljharb/side-channel-map\n[dev-deps-svg]: https://david-dm.org/ljharb/side-channel-map/dev-status.svg\n[dev-deps-url]: https://david-dm.org/ljharb/side-channel-map#info=devDependencies\n[npm-badge-png]: https://nodei.co/npm/side-channel-map.png?downloads=true&stars=true\n[license-image]: https://img.shields.io/npm/l/side-channel-map.svg\n[license-url]: LICENSE\n[downloads-image]: https://img.shields.io/npm/dm/side-channel-map.svg\n[downloads-url]: https://npm-stat.com/charts.html?package=side-channel-map\n[codecov-image]: https://codecov.io/gh/ljharb/side-channel-map/branch/main/graphs/badge.svg\n[codecov-url]: https://app.codecov.io/gh/ljharb/side-channel-map/\n[actions-image]: https://img.shields.io/endpoint?url=https://github-actions-badge-u3jn4tfpocch.runkit.sh/ljharb/side-channel-map\n[actions-url]: https://github.com/ljharb/side-channel-map/actions\n",
        "plugins/auto-review/mcp/node_modules/side-channel-weakmap/README.md": "# side-channel-weakmap <sup>[![Version Badge][npm-version-svg]][package-url]</sup>\n\n[![github actions][actions-image]][actions-url]\n[![coverage][codecov-image]][codecov-url]\n[![License][license-image]][license-url]\n[![Downloads][downloads-image]][downloads-url]\n\n[![npm badge][npm-badge-png]][package-url]\n\nStore information about any JS value in a side channel. Uses WeakMap if available.\n\nWarning: this implementation will leak memory until you `delete` the `key`.\nUse [`side-channel`](https://npmjs.com/side-channel) for the best available strategy.\n\n## Getting started\n\n```sh\nnpm install --save side-channel-weakmap\n```\n\n## Usage/Examples\n\n```js\nconst assert = require('assert');\nconst getSideChannelList = require('side-channel-weakmap');\n\nconst channel = getSideChannelList();\n\nconst key = {};\nassert.equal(channel.has(key), false);\nassert.throws(() => channel.assert(key), TypeError);\n\nchannel.set(key, 42);\n\nchannel.assert(key); // does not throw\nassert.equal(channel.has(key), true);\nassert.equal(channel.get(key), 42);\n\nchannel.delete(key);\nassert.equal(channel.has(key), false);\nassert.throws(() => channel.assert(key), TypeError);\n```\n\n## Tests\n\nClone the repo, `npm install`, and run `npm test`\n\n[package-url]: https://npmjs.org/package/side-channel-weakmap\n[npm-version-svg]: https://versionbadg.es/ljharb/side-channel-weakmap.svg\n[deps-svg]: https://david-dm.org/ljharb/side-channel-weakmap.svg\n[deps-url]: https://david-dm.org/ljharb/side-channel-weakmap\n[dev-deps-svg]: https://david-dm.org/ljharb/side-channel-weakmap/dev-status.svg\n[dev-deps-url]: https://david-dm.org/ljharb/side-channel-weakmap#info=devDependencies\n[npm-badge-png]: https://nodei.co/npm/side-channel-weakmap.png?downloads=true&stars=true\n[license-image]: https://img.shields.io/npm/l/side-channel-weakmap.svg\n[license-url]: LICENSE\n[downloads-image]: https://img.shields.io/npm/dm/side-channel-weakmap.svg\n[downloads-url]: https://npm-stat.com/charts.html?package=side-channel-weakmap\n[codecov-image]: https://codecov.io/gh/ljharb/side-channel-weakmap/branch/main/graphs/badge.svg\n[codecov-url]: https://app.codecov.io/gh/ljharb/side-channel-weakmap/\n[actions-image]: https://img.shields.io/endpoint?url=https://github-actions-badge-u3jn4tfpocch.runkit.sh/ljharb/side-channel-weakmap\n[actions-url]: https://github.com/ljharb/side-channel-weakmap/actions\n",
        "plugins/auto-review/mcp/node_modules/side-channel/README.md": "# side-channel <sup>[![Version Badge][npm-version-svg]][package-url]</sup>\n\n[![github actions][actions-image]][actions-url]\n[![coverage][codecov-image]][codecov-url]\n[![License][license-image]][license-url]\n[![Downloads][downloads-image]][downloads-url]\n\n[![npm badge][npm-badge-png]][package-url]\n\nStore information about any JS value in a side channel. Uses WeakMap if available.\n\nWarning: in an environment that lacks `WeakMap`, this implementation will leak memory until you `delete` the `key`.\n\n## Getting started\n\n```sh\nnpm install --save side-channel\n```\n\n## Usage/Examples\n\n```js\nconst assert = require('assert');\nconst getSideChannel = require('side-channel');\n\nconst channel = getSideChannel();\n\nconst key = {};\nassert.equal(channel.has(key), false);\nassert.throws(() => channel.assert(key), TypeError);\n\nchannel.set(key, 42);\n\nchannel.assert(key); // does not throw\nassert.equal(channel.has(key), true);\nassert.equal(channel.get(key), 42);\n\nchannel.delete(key);\nassert.equal(channel.has(key), false);\nassert.throws(() => channel.assert(key), TypeError);\n```\n\n## Tests\n\nClone the repo, `npm install`, and run `npm test`\n\n[package-url]: https://npmjs.org/package/side-channel\n[npm-version-svg]: https://versionbadg.es/ljharb/side-channel.svg\n[deps-svg]: https://david-dm.org/ljharb/side-channel.svg\n[deps-url]: https://david-dm.org/ljharb/side-channel\n[dev-deps-svg]: https://david-dm.org/ljharb/side-channel/dev-status.svg\n[dev-deps-url]: https://david-dm.org/ljharb/side-channel#info=devDependencies\n[npm-badge-png]: https://nodei.co/npm/side-channel.png?downloads=true&stars=true\n[license-image]: https://img.shields.io/npm/l/side-channel.svg\n[license-url]: LICENSE\n[downloads-image]: https://img.shields.io/npm/dm/side-channel.svg\n[downloads-url]: https://npm-stat.com/charts.html?package=side-channel\n[codecov-image]: https://codecov.io/gh/ljharb/side-channel/branch/main/graphs/badge.svg\n[codecov-url]: https://app.codecov.io/gh/ljharb/side-channel/\n[actions-image]: https://img.shields.io/endpoint?url=https://github-actions-badge-u3jn4tfpocch.runkit.sh/ljharb/side-channel\n[actions-url]: https://github.com/ljharb/side-channel/actions\n",
        "plugins/auto-review/mcp/node_modules/statuses/README.md": "# statuses\n\n[![NPM Version][npm-version-image]][npm-url]\n[![NPM Downloads][npm-downloads-image]][npm-url]\n[![Node.js Version][node-version-image]][node-version-url]\n[![Build Status][ci-image]][ci-url]\n[![Test Coverage][coveralls-image]][coveralls-url]\n[![OpenSSF Scorecard Badge][ossf-scorecard-badge]][ossf-scorecard-visualizer]\n\nHTTP status utility for node.\n\nThis module provides a list of status codes and messages sourced from\na few different projects:\n\n  * The [IANA Status Code Registry](https://www.iana.org/assignments/http-status-codes/http-status-codes.xhtml)\n  * The [Node.js project](https://nodejs.org/)\n  * The [NGINX project](https://www.nginx.com/)\n  * The [Apache HTTP Server project](https://httpd.apache.org/)\n\n## Installation\n\nThis is a [Node.js](https://nodejs.org/en/) module available through the\n[npm registry](https://www.npmjs.com/). Installation is done using the\n[`npm install` command](https://docs.npmjs.com/getting-started/installing-npm-packages-locally):\n\n```sh\n$ npm install statuses\n```\n\n## API\n\n<!-- eslint-disable no-unused-vars -->\n\n```js\nvar status = require('statuses')\n```\n\n### status(code)\n\nReturns the status message string for a known HTTP status code. The code\nmay be a number or a string. An error is thrown for an unknown status code.\n\n<!-- eslint-disable no-undef -->\n\n```js\nstatus(403) // => 'Forbidden'\nstatus('403') // => 'Forbidden'\nstatus(306) // throws\n```\n\n### status(msg)\n\nReturns the numeric status code for a known HTTP status message. The message\nis case-insensitive. An error is thrown for an unknown status message.\n\n<!-- eslint-disable no-undef -->\n\n```js\nstatus('forbidden') // => 403\nstatus('Forbidden') // => 403\nstatus('foo') // throws\n```\n\n### status.codes\n\nReturns an array of all the status codes as `Integer`s.\n\n### status.code[msg]\n\nReturns the numeric status code for a known status message (in lower-case),\notherwise `undefined`.\n\n<!-- eslint-disable no-undef, no-unused-expressions -->\n\n```js\nstatus['not found'] // => 404\n```\n\n### status.empty[code]\n\nReturns `true` if a status code expects an empty body.\n\n<!-- eslint-disable no-undef, no-unused-expressions -->\n\n```js\nstatus.empty[200] // => undefined\nstatus.empty[204] // => true\nstatus.empty[304] // => true\n```\n\n### status.message[code]\n\nReturns the string message for a known numeric status code, otherwise\n`undefined`. This object is the same format as the\n[Node.js http module `http.STATUS_CODES`](https://nodejs.org/dist/latest/docs/api/http.html#http_http_status_codes).\n\n<!-- eslint-disable no-undef, no-unused-expressions -->\n\n```js\nstatus.message[404] // => 'Not Found'\n```\n\n### status.redirect[code]\n\nReturns `true` if a status code is a valid redirect status.\n\n<!-- eslint-disable no-undef, no-unused-expressions -->\n\n```js\nstatus.redirect[200] // => undefined\nstatus.redirect[301] // => true\n```\n\n### status.retry[code]\n\nReturns `true` if you should retry the rest.\n\n<!-- eslint-disable no-undef, no-unused-expressions -->\n\n```js\nstatus.retry[501] // => undefined\nstatus.retry[503] // => true\n```\n\n## License\n\n[MIT](LICENSE)\n\n[ci-image]: https://badgen.net/github/checks/jshttp/statuses/master?label=ci\n[ci-url]: https://github.com/jshttp/statuses/actions?query=workflow%3Aci\n[coveralls-image]: https://badgen.net/coveralls/c/github/jshttp/statuses/master\n[coveralls-url]: https://coveralls.io/r/jshttp/statuses?branch=master\n[node-version-image]: https://badgen.net/npm/node/statuses\n[node-version-url]: https://nodejs.org/en/download\n[npm-downloads-image]: https://badgen.net/npm/dm/statuses\n[npm-url]: https://npmjs.org/package/statuses\n[npm-version-image]: https://badgen.net/npm/v/statuses\n[ossf-scorecard-badge]: https://api.securityscorecards.dev/projects/github.com/jshttp/statuses/badge\n[ossf-scorecard-visualizer]: https://kooltheba.github.io/openssf-scorecard-api-visualizer/#/projects/github.com/jshttp/statuses\n",
        "plugins/auto-review/mcp/node_modules/toidentifier/README.md": "# toidentifier\n\n[![NPM Version][npm-image]][npm-url]\n[![NPM Downloads][downloads-image]][downloads-url]\n[![Build Status][github-actions-ci-image]][github-actions-ci-url]\n[![Test Coverage][codecov-image]][codecov-url]\n\n> Convert a string of words to a JavaScript identifier\n\n## Install\n\nThis is a [Node.js](https://nodejs.org/en/) module available through the\n[npm registry](https://www.npmjs.com/). Installation is done using the\n[`npm install` command](https://docs.npmjs.com/getting-started/installing-npm-packages-locally):\n\n```bash\n$ npm install toidentifier\n```\n\n## Example\n\n```js\nvar toIdentifier = require('toidentifier')\n\nconsole.log(toIdentifier('Bad Request'))\n// => \"BadRequest\"\n```\n\n## API\n\nThis CommonJS module exports a single default function: `toIdentifier`.\n\n### toIdentifier(string)\n\nGiven a string as the argument, it will be transformed according to\nthe following rules and the new string will be returned:\n\n1. Split into words separated by space characters (`0x20`).\n2. Upper case the first character of each word.\n3. Join the words together with no separator.\n4. Remove all non-word (`[0-9a-z_]`) characters.\n\n## License\n\n[MIT](LICENSE)\n\n[codecov-image]: https://img.shields.io/codecov/c/github/component/toidentifier.svg\n[codecov-url]: https://codecov.io/gh/component/toidentifier\n[downloads-image]: https://img.shields.io/npm/dm/toidentifier.svg\n[downloads-url]: https://npmjs.org/package/toidentifier\n[github-actions-ci-image]: https://img.shields.io/github/workflow/status/component/toidentifier/ci/master?label=ci\n[github-actions-ci-url]: https://github.com/component/toidentifier?query=workflow%3Aci\n[npm-image]: https://img.shields.io/npm/v/toidentifier.svg\n[npm-url]: https://npmjs.org/package/toidentifier\n\n\n##\n\n[npm]: https://www.npmjs.com/\n\n[yarn]: https://yarnpkg.com/\n",
        "plugins/auto-review/mcp/node_modules/type-is/README.md": "# type-is\n\n[![NPM Version][npm-version-image]][npm-url]\n[![NPM Downloads][npm-downloads-image]][npm-url]\n[![Node.js Version][node-version-image]][node-version-url]\n[![Build Status][ci-image]][ci-url]\n[![Test Coverage][coveralls-image]][coveralls-url]\n\nInfer the content-type of a request.\n\n## Install\n\nThis is a [Node.js](https://nodejs.org/en/) module available through the\n[npm registry](https://www.npmjs.com/). Installation is done using the\n[`npm install` command](https://docs.npmjs.com/getting-started/installing-npm-packages-locally):\n\n```sh\n$ npm install type-is\n```\n\n## API\n\n```js\nvar http = require('http')\nvar typeis = require('type-is')\n\nhttp.createServer(function (req, res) {\n  var istext = typeis(req, ['text/*'])\n  res.end('you ' + (istext ? 'sent' : 'did not send') + ' me text')\n})\n```\n\n### typeis(request, types)\n\nChecks if the `request` is one of the `types`. If the request has no body,\neven if there is a `Content-Type` header, then `null` is returned. If the\n`Content-Type` header is invalid or does not matches any of the `types`, then\n`false` is returned. Otherwise, a string of the type that matched is returned.\n\nThe `request` argument is expected to be a Node.js HTTP request. The `types`\nargument is an array of type strings.\n\nEach type in the `types` array can be one of the following:\n\n- A file extension name such as `json`. This name will be returned if matched.\n- A mime type such as `application/json`.\n- A mime type with a wildcard such as `*/*` or `*/json` or `application/*`.\n  The full mime type will be returned if matched.\n- A suffix such as `+json`. This can be combined with a wildcard such as\n  `*/vnd+json` or `application/*+json`. The full mime type will be returned\n  if matched.\n\nSome examples to illustrate the inputs and returned value:\n\n```js\n// req.headers.content-type = 'application/json'\n\ntypeis(req, ['json']) // => 'json'\ntypeis(req, ['html', 'json']) // => 'json'\ntypeis(req, ['application/*']) // => 'application/json'\ntypeis(req, ['application/json']) // => 'application/json'\n\ntypeis(req, ['html']) // => false\n```\n\n### typeis.hasBody(request)\n\nReturns a Boolean if the given `request` has a body, regardless of the\n`Content-Type` header.\n\nHaving a body has no relation to how large the body is (it may be 0 bytes).\nThis is similar to how file existence works. If a body does exist, then this\nindicates that there is data to read from the Node.js request stream.\n\n```js\nif (typeis.hasBody(req)) {\n  // read the body, since there is one\n\n  req.on('data', function (chunk) {\n    // ...\n  })\n}\n```\n\n### typeis.is(mediaType, types)\n\nChecks if the `mediaType` is one of the `types`. If the `mediaType` is invalid\nor does not matches any of the `types`, then `false` is returned. Otherwise, a\nstring of the type that matched is returned.\n\nThe `mediaType` argument is expected to be a\n[media type](https://tools.ietf.org/html/rfc6838) string. The `types` argument\nis an array of type strings.\n\nEach type in the `types` array can be one of the following:\n\n- A file extension name such as `json`. This name will be returned if matched.\n- A mime type such as `application/json`.\n- A mime type with a wildcard such as `*/*` or `*/json` or `application/*`.\n  The full mime type will be returned if matched.\n- A suffix such as `+json`. This can be combined with a wildcard such as\n  `*/vnd+json` or `application/*+json`. The full mime type will be returned\n  if matched.\n\nSome examples to illustrate the inputs and returned value:\n\n```js\nvar mediaType = 'application/json'\n\ntypeis.is(mediaType, ['json']) // => 'json'\ntypeis.is(mediaType, ['html', 'json']) // => 'json'\ntypeis.is(mediaType, ['application/*']) // => 'application/json'\ntypeis.is(mediaType, ['application/json']) // => 'application/json'\n\ntypeis.is(mediaType, ['html']) // => false\n```\n\n### typeis.match(expected, actual)\n\nMatch the type string `expected` with `actual`, taking in to account wildcards.\nA wildcard can only be in the type of the subtype part of a media type and only\nin the `expected` value (as `actual` should be the real media type to match). A\nsuffix can still be included even with a wildcard subtype. If an input is\nmalformed, `false` will be returned.\n\n```js\ntypeis.match('text/html', 'text/html') // => true\ntypeis.match('*/html', 'text/html') // => true\ntypeis.match('text/*', 'text/html') // => true\ntypeis.match('*/*', 'text/html') // => true\ntypeis.match('*/*+json', 'application/x-custom+json') // => true\n```\n\n### typeis.normalize(type)\n\nNormalize a `type` string. This works by performing the following:\n\n- If the `type` is not a string, `false` is returned.\n- If the string starts with `+` (so it is a `+suffix` shorthand like `+json`),\n  then it is expanded to contain the complete wildcard notation of `*/*+suffix`.\n- If the string contains a `/`, then it is returned as the type.\n- Else the string is assumed to be a file extension and the mapped media type is\n  returned, or `false` is there is no mapping.\n\nThis includes two special mappings:\n\n- `'multipart'` -> `'multipart/*'`\n- `'urlencoded'` -> `'application/x-www-form-urlencoded'`\n\n## Examples\n\n### Example body parser\n\n```js\nvar express = require('express')\nvar typeis = require('type-is')\n\nvar app = express()\n\napp.use(function bodyParser (req, res, next) {\n  if (!typeis.hasBody(req)) {\n    return next()\n  }\n\n  switch (typeis(req, ['urlencoded', 'json', 'multipart'])) {\n    case 'urlencoded':\n      // parse urlencoded body\n      throw new Error('implement urlencoded body parsing')\n    case 'json':\n      // parse json body\n      throw new Error('implement json body parsing')\n    case 'multipart':\n      // parse multipart body\n      throw new Error('implement multipart body parsing')\n    default:\n      // 415 error code\n      res.statusCode = 415\n      res.end()\n      break\n  }\n})\n```\n\n## License\n\n[MIT](LICENSE)\n\n[ci-image]: https://badgen.net/github/checks/jshttp/type-is/master?label=ci\n[ci-url]: https://github.com/jshttp/type-is/actions/workflows/ci.yml\n[coveralls-image]: https://badgen.net/coveralls/c/github/jshttp/type-is/master\n[coveralls-url]: https://coveralls.io/r/jshttp/type-is?branch=master\n[node-version-image]: https://badgen.net/npm/node/type-is\n[node-version-url]: https://nodejs.org/en/download\n[npm-downloads-image]: https://badgen.net/npm/dm/type-is\n[npm-url]: https://npmjs.org/package/type-is\n[npm-version-image]: https://badgen.net/npm/v/type-is\n[travis-image]: https://badgen.net/travis/jshttp/type-is/master\n[travis-url]: https://travis-ci.org/jshttp/type-is\n",
        "plugins/auto-review/mcp/node_modules/typescript/README.md": "\r\n# TypeScript\r\n\r\n[![CI](https://github.com/microsoft/TypeScript/actions/workflows/ci.yml/badge.svg)](https://github.com/microsoft/TypeScript/actions/workflows/ci.yml)\r\n[![npm version](https://badge.fury.io/js/typescript.svg)](https://www.npmjs.com/package/typescript)\r\n[![Downloads](https://img.shields.io/npm/dm/typescript.svg)](https://www.npmjs.com/package/typescript)\r\n[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/microsoft/TypeScript/badge)](https://securityscorecards.dev/viewer/?uri=github.com/microsoft/TypeScript)\r\n\r\n\r\n[TypeScript](https://www.typescriptlang.org/) is a language for application-scale JavaScript. TypeScript adds optional types to JavaScript that support tools for large-scale JavaScript applications for any browser, for any host, on any OS. TypeScript compiles to readable, standards-based JavaScript. Try it out at the [playground](https://www.typescriptlang.org/play/), and stay up to date via [our blog](https://blogs.msdn.microsoft.com/typescript) and [Twitter account](https://twitter.com/typescript).\r\n\r\nFind others who are using TypeScript at [our community page](https://www.typescriptlang.org/community/).\r\n\r\n## Installing\r\n\r\nFor the latest stable version:\r\n\r\n```bash\r\nnpm install -D typescript\r\n```\r\n\r\nFor our nightly builds:\r\n\r\n```bash\r\nnpm install -D typescript@next\r\n```\r\n\r\n## Contribute\r\n\r\nThere are many ways to [contribute](https://github.com/microsoft/TypeScript/blob/main/CONTRIBUTING.md) to TypeScript.\r\n* [Submit bugs](https://github.com/microsoft/TypeScript/issues) and help us verify fixes as they are checked in.\r\n* Review the [source code changes](https://github.com/microsoft/TypeScript/pulls).\r\n* Engage with other TypeScript users and developers on [StackOverflow](https://stackoverflow.com/questions/tagged/typescript).\r\n* Help each other in the [TypeScript Community Discord](https://discord.gg/typescript).\r\n* Join the [#typescript](https://twitter.com/search?q=%23TypeScript) discussion on Twitter.\r\n* [Contribute bug fixes](https://github.com/microsoft/TypeScript/blob/main/CONTRIBUTING.md).\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see\r\nthe [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com)\r\nwith any additional questions or comments.\r\n\r\n## Documentation\r\n\r\n*  [TypeScript in 5 minutes](https://www.typescriptlang.org/docs/handbook/typescript-in-5-minutes.html)\r\n*  [Programming handbook](https://www.typescriptlang.org/docs/handbook/intro.html)\r\n*  [Homepage](https://www.typescriptlang.org/)\r\n\r\n## Roadmap\r\n\r\nFor details on our planned features and future direction, please refer to our [roadmap](https://github.com/microsoft/TypeScript/wiki/Roadmap).\r\n",
        "plugins/auto-review/mcp/node_modules/undici-types/README.md": "# undici-types\n\nThis package is a dual-publish of the [undici](https://www.npmjs.com/package/undici) library types. The `undici` package **still contains types**. This package is for users who _only_ need undici types (such as for `@types/node`). It is published alongside every release of `undici`, so you can always use the same version.\n\n- [GitHub nodejs/undici](https://github.com/nodejs/undici)\n- [Undici Documentation](https://undici.nodejs.org/#/)\n",
        "plugins/auto-review/mcp/node_modules/unpipe/README.md": "# unpipe\n\n[![NPM Version][npm-image]][npm-url]\n[![NPM Downloads][downloads-image]][downloads-url]\n[![Node.js Version][node-image]][node-url]\n[![Build Status][travis-image]][travis-url]\n[![Test Coverage][coveralls-image]][coveralls-url]\n\nUnpipe a stream from all destinations.\n\n## Installation\n\n```sh\n$ npm install unpipe\n```\n\n## API\n\n```js\nvar unpipe = require('unpipe')\n```\n\n### unpipe(stream)\n\nUnpipes all destinations from a given stream. With stream 2+, this is\nequivalent to `stream.unpipe()`. When used with streams 1 style streams\n(typically Node.js 0.8 and below), this module attempts to undo the\nactions done in `stream.pipe(dest)`.\n\n## License\n\n[MIT](LICENSE)\n\n[npm-image]: https://img.shields.io/npm/v/unpipe.svg\n[npm-url]: https://npmjs.org/package/unpipe\n[node-image]: https://img.shields.io/node/v/unpipe.svg\n[node-url]: http://nodejs.org/download/\n[travis-image]: https://img.shields.io/travis/stream-utils/unpipe.svg\n[travis-url]: https://travis-ci.org/stream-utils/unpipe\n[coveralls-image]: https://img.shields.io/coveralls/stream-utils/unpipe.svg\n[coveralls-url]: https://coveralls.io/r/stream-utils/unpipe?branch=master\n[downloads-image]: https://img.shields.io/npm/dm/unpipe.svg\n[downloads-url]: https://npmjs.org/package/unpipe\n",
        "plugins/auto-review/mcp/node_modules/vary/README.md": "# vary\n\n[![NPM Version][npm-image]][npm-url]\n[![NPM Downloads][downloads-image]][downloads-url]\n[![Node.js Version][node-version-image]][node-version-url]\n[![Build Status][travis-image]][travis-url]\n[![Test Coverage][coveralls-image]][coveralls-url]\n\nManipulate the HTTP Vary header\n\n## Installation\n\nThis is a [Node.js](https://nodejs.org/en/) module available through the\n[npm registry](https://www.npmjs.com/). Installation is done using the\n[`npm install` command](https://docs.npmjs.com/getting-started/installing-npm-packages-locally): \n\n```sh\n$ npm install vary\n```\n\n## API\n\n<!-- eslint-disable no-unused-vars -->\n\n```js\nvar vary = require('vary')\n```\n\n### vary(res, field)\n\nAdds the given header `field` to the `Vary` response header of `res`.\nThis can be a string of a single field, a string of a valid `Vary`\nheader, or an array of multiple fields.\n\nThis will append the header if not already listed, otherwise leaves\nit listed in the current location.\n\n<!-- eslint-disable no-undef -->\n\n```js\n// Append \"Origin\" to the Vary header of the response\nvary(res, 'Origin')\n```\n\n### vary.append(header, field)\n\nAdds the given header `field` to the `Vary` response header string `header`.\nThis can be a string of a single field, a string of a valid `Vary` header,\nor an array of multiple fields.\n\nThis will append the header if not already listed, otherwise leaves\nit listed in the current location. The new header string is returned.\n\n<!-- eslint-disable no-undef -->\n\n```js\n// Get header string appending \"Origin\" to \"Accept, User-Agent\"\nvary.append('Accept, User-Agent', 'Origin')\n```\n\n## Examples\n\n### Updating the Vary header when content is based on it\n\n```js\nvar http = require('http')\nvar vary = require('vary')\n\nhttp.createServer(function onRequest (req, res) {\n  // about to user-agent sniff\n  vary(res, 'User-Agent')\n\n  var ua = req.headers['user-agent'] || ''\n  var isMobile = /mobi|android|touch|mini/i.test(ua)\n\n  // serve site, depending on isMobile\n  res.setHeader('Content-Type', 'text/html')\n  res.end('You are (probably) ' + (isMobile ? '' : 'not ') + 'a mobile user')\n})\n```\n\n## Testing\n\n```sh\n$ npm test\n```\n\n## License\n\n[MIT](LICENSE)\n\n[npm-image]: https://img.shields.io/npm/v/vary.svg\n[npm-url]: https://npmjs.org/package/vary\n[node-version-image]: https://img.shields.io/node/v/vary.svg\n[node-version-url]: https://nodejs.org/en/download\n[travis-image]: https://img.shields.io/travis/jshttp/vary/master.svg\n[travis-url]: https://travis-ci.org/jshttp/vary\n[coveralls-image]: https://img.shields.io/coveralls/jshttp/vary/master.svg\n[coveralls-url]: https://coveralls.io/r/jshttp/vary\n[downloads-image]: https://img.shields.io/npm/dm/vary.svg\n[downloads-url]: https://npmjs.org/package/vary\n",
        "plugins/auto-review/mcp/node_modules/which/README.md": "# which\n\nLike the unix `which` utility.\n\nFinds the first instance of a specified executable in the PATH\nenvironment variable.  Does not cache the results, so `hash -r` is not\nneeded when the PATH changes.\n\n## USAGE\n\n```javascript\nvar which = require('which')\n\n// async usage\nwhich('node', function (er, resolvedPath) {\n  // er is returned if no \"node\" is found on the PATH\n  // if it is found, then the absolute path to the exec is returned\n})\n\n// or promise\nwhich('node').then(resolvedPath => { ... }).catch(er => { ... not found ... })\n\n// sync usage\n// throws if not found\nvar resolved = which.sync('node')\n\n// if nothrow option is used, returns null if not found\nresolved = which.sync('node', {nothrow: true})\n\n// Pass options to override the PATH and PATHEXT environment vars.\nwhich('node', { path: someOtherPath }, function (er, resolved) {\n  if (er)\n    throw er\n  console.log('found at %j', resolved)\n})\n```\n\n## CLI USAGE\n\nSame as the BSD `which(1)` binary.\n\n```\nusage: which [-as] program ...\n```\n\n## OPTIONS\n\nYou may pass an options object as the second argument.\n\n- `path`: Use instead of the `PATH` environment variable.\n- `pathExt`: Use instead of the `PATHEXT` environment variable.\n- `all`: Return all matches, instead of just the first one.  Note that\n  this means the function returns an array of strings instead of a\n  single string.\n",
        "plugins/auto-review/mcp/node_modules/wrappy/README.md": "# wrappy\n\nCallback wrapping utility\n\n## USAGE\n\n```javascript\nvar wrappy = require(\"wrappy\")\n\n// var wrapper = wrappy(wrapperFunction)\n\n// make sure a cb is called only once\n// See also: http://npm.im/once for this specific use case\nvar once = wrappy(function (cb) {\n  var called = false\n  return function () {\n    if (called) return\n    called = true\n    return cb.apply(this, arguments)\n  }\n})\n\nfunction printBoo () {\n  console.log('boo')\n}\n// has some rando property\nprintBoo.iAmBooPrinter = true\n\nvar onlyPrintOnce = once(printBoo)\n\nonlyPrintOnce() // prints 'boo'\nonlyPrintOnce() // does nothing\n\n// random property is retained!\nassert.equal(onlyPrintOnce.iAmBooPrinter, true)\n```\n",
        "plugins/auto-review/mcp/node_modules/zod-to-json-schema/README.md": "# Zod to Json Schema\n\n[![NPM Version](https://img.shields.io/npm/v/zod-to-json-schema.svg)](https://npmjs.org/package/zod-to-json-schema)\n[![NPM Downloads](https://img.shields.io/npm/dw/zod-to-json-schema.svg)](https://npmjs.org/package/zod-to-json-schema)\n\n_Looking for the exact opposite? Check out [json-schema-to-zod](https://npmjs.org/package/json-schema-to-zod)_\n\n## Summary\n\nDoes what it says on the tin; converts [Zod schemas](https://github.com/colinhacks/zod) into [JSON schemas](https://json-schema.org/)!\n\n- Supports all relevant schema types, basic string, number and array length validations and string patterns.\n- Resolves recursive and recurring schemas with internal `$ref`s.\n- Supports targeting legacy Open API 3.0 specification (3.1 supports regular Json Schema).\n- Supports Open AI strict mode schemas (Optional object properties are replaced with required but nullable ones).\n\n## Sponsors\n\nA great big thank you to our amazing sponsors! Please consider joining them through my [GitHub Sponsors page](https://github.com/sponsors/StefanTerdell). Every cent helps, but these fellas have really gone above and beyond 💚:\n\n<table align=\"center\" style=\"justify-content: center;align-items: center;display: flex;\">\n  <tr>\n    <td align=\"center\">\n      <p></p>\n      <p>\n      <div style=\"background-color: white; padding: 4px; padding-bottom: 8px;\" alt=\"stainless\">\n        <a href=\"https://www.coderabbit.ai/\">\n          <picture height=\"45px\">\n             <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/user-attachments/assets/eea24edb-ff20-4532-b57c-e8719f455d6d\">\n          <img alt=\"CodeRabbit logo\" height=\"45px\" src=\"https://github.com/user-attachments/assets/d791bc7d-dc60-4d55-9c31-97779839cb74\">\n          </picture>\n        </a>\n      </div>\n      <br  />   \n      Cut code review time & bugs in half\n      <br/>\n      <a href=\"https://www.coderabbit.ai/\" style=\"text-decoration:none;\">coderabbit.ai</a>\n      </p>\n      <p></p>\n    </td>\n  </tr>\n  <tr>\n    <td align=\"center\">\n      <p></p>\n      <p>\n      <a href=\"https://retool.com/?ref=stefanterdell&utm_source=github&utm_medium=referral&utm_campaign=stefanterdell\">\n        <picture height=\"45px\">\n          <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/colinhacks/zod/assets/3084745/ac65013f-aeb4-48dd-a2ee-41040b69cbe6\">\n          <img alt=\"stainless\" height=\"45px\" src=\"https://github.com/colinhacks/zod/assets/3084745/5ef4c11b-efeb-4495-90a8-41b83f798600\">\n        </picture>\n      </a>\n      <br  />   \n      Build AI apps and workflows with <a href=\"https://retool.com/products/ai?ref=stefanterdell&utm_source=github&utm_medium=referral&utm_campaign=stefanterdell\">Retool AI</a>\n      <br/>\n      <a href=\"https://retool.com/?ref=stefanterdell&utm_source=github&utm_medium=referral&utm_campaign=stefanterdell\" style=\"text-decoration:none;\">retool.com</a>\n      </p>\n      <p></p>\n    </td>\n  </tr>\n</table>\n\n## Usage\n\n### Basic example\n\n```typescript\nimport { z } from \"zod\";\nimport { zodToJsonSchema } from \"zod-to-json-schema\";\n\nconst mySchema = z\n  .object({\n    myString: z.string().min(5),\n    myUnion: z.union([z.number(), z.boolean()]),\n  })\n  .describe(\"My neat object schema\");\n\nconst jsonSchema = zodToJsonSchema(mySchema, \"mySchema\");\n```\n\n#### Expected output\n\n```json\n{\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"$ref\": \"#/definitions/mySchema\",\n  \"definitions\": {\n    \"mySchema\": {\n      \"description\": \"My neat object schema\",\n      \"type\": \"object\",\n      \"properties\": {\n        \"myString\": {\n          \"type\": \"string\",\n          \"minLength\": 5\n        },\n        \"myUnion\": {\n          \"type\": [\"number\", \"boolean\"]\n        }\n      },\n      \"additionalProperties\": false,\n      \"required\": [\"myString\", \"myUnion\"]\n    }\n  }\n}\n```\n\n## Options\n\n### Schema name\n\nYou can pass a string as the second parameter of the main zodToJsonSchema function. If you do, your schema will end up inside a definitions object property on the root and referenced from there. Alternatively, you can pass the name as the `name` property of the options object (see below).\n\n### Options object\n\nInstead of the schema name (or nothing), you can pass an options object as the second parameter. The following options are available:\n\n| Option                                                                             | Effect                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n| ---------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **name**?: _string_                                                                | As described above.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n| **nameStrategy**?: \"ref\" \\| \"title\"                                                | Adds name as \"title\" meta instead of as a ref as described above                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n| **basePath**?: string[]                                                            | The base path of the root reference builder. Defaults to [\"#\"].                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n| **$refStrategy**?: \"root\" \\| \"relative\" \\| \"seen\" \\| \"none\"                        | The reference builder strategy; <ul><li>**\"root\"** resolves $refs from the root up, ie: \"#/definitions/mySchema\".</li><li>**\"relative\"** uses [relative JSON pointers](https://tools.ietf.org/id/draft-handrews-relative-json-pointer-00.html). _See known issues!_</li><li>**\"seen\"** reuses the output of any \"seen\" Zod schema. In theory it's a more performant version of \"none\", but in practice this behaviour can cause issues with nested schemas and has now gotten its own option.</li> <li>**\"none\"** ignores referencing all together, creating a new schema branch even on \"seen\" schemas. Recursive references defaults to \"any\", ie `{}`.</li></ul> Defaults to \"root\". |\n| **effectStrategy**?: \"input\" \\| \"any\"                                              | The effects output strategy. Defaults to \"input\". _See known issues!_                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n| **dateStrategy**?: \"format:date\" \\| \"format:date-time\" \\| \"string\" \\| \"integer\"    | Date strategy, integer allow to specify in unix-time min and max values. \"format:date\" creates a string schema with format: \"date\". \"format:date-time\" creates a string schema with format: \"date-time\". \"string\" is intepreted as \"format:date-time\". \"integer\" creates an integer schema with format \"unix-time\" (unless target \"openApi3\" is used min max checks are also respected)                                                                                                                                                                                                                                                                                                 |\n|                                                                                    |\n| **emailStrategy**?: \"format:email\" \\| \"format:idn-email\" \\| \"pattern:zod\"          | Choose how to handle the email string check. Defaults to \"format:email\".                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n| **base64Strategy**?: \"format:binary\" \\| \"contentEnconding:base64\" \\| \"pattern:zod\" | Choose how to handle the base64 string check. Defaults to \"contentEncoding:base64\" as described [here](https://json-schema.org/understanding-json-schema/reference/non_json_data#contentencoding). Note that \"format:binary\" is not represented in the output type as it's not part of the JSON Schema spec and only intended to be used when targeting OpenAPI 3.0. Later versions of OpenAPI support contentEncoding.                                                                                                                                                                                                                                                                 |\n| **definitionPath**?: \"definitions\" \\| \"$defs\"                                      | The name of the definitions property when name is passed. Defaults to \"definitions\".                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n| **target**?: \"jsonSchema7\" \\| \"jsonSchema2019-09\" \\| \"openApi3\" \\| \"openAi\"        | Which spec to target. Defaults to \"jsonSchema7\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n| **strictUnions**?: boolean                                                         | Scrubs unions of any-like json schemas, like `{}` or `true`. Multiple zod types may result in these out of necessity, such as z.instanceof()                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n| **definitions**?: Record<string, ZodSchema>                                        | See separate section below                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n| **errorMessages**?: boolean                                                        | Include custom error messages created via chained function checks for supported zod types. See section below                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n| **markdownDescription**?: boolean                                                  | Copies the `description` meta to `markdownDescription`                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n| **patternStrategy**?: \"escape\" \\| \"preserve\"                                       | The Zod string validations `.includes()`, `.startsWith()`, and `.endsWith()` must be converted to regex to be compatible with JSON Schema's `pattern`. For safety, all non-alphanumeric characters are `escape`d by default (consider `z.string().includes(\".\")`), but this can occasionally cause problems with Unicode-flagged regex parsers. Use `preserve` to prevent this escaping behaviour and preserve the exact string written, even if it results in an inaccurate regex.                                                                                                                                                                                                     |\n| **applyRegexFlags**?: boolean                                                      | JSON Schema's `pattern` doesn't support RegExp flags, but Zod's `z.string().regex()` does. When this option is true (default false), a best-effort is made to transform regexes into a flag-independent form (e.g. `/x/i => /[xX]/` ). Supported flags: `i` (basic Latin only), `m`, `s`.                                                                                                                                                                                                                                                                                                                                                                                               |\n| **pipeStrategy**?: \"all\" \\| \"input\" \\| \"output\"                                    | Decide which types should be included when using `z.pipe`, for example `z.string().pipe(z.number())` would return both `string` and `number` by default, only `string` for \"input\" and only `number` for \"output\".                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n| **removeAdditionalStrategy**?: \"passthrough\" \\| \"strict\"                           | Decide when `additionalProperties` should be allowed. See the section on additional properties for details.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n| **allowedAdditionalProperties**?: `true` \\| `undefined`                            | What value to give `additionalProperties` when allowed. See the section on additional properties for details.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n| **rejectedAdditionalProperties**?: `false` \\| `undefined`                          | What value to give `additionalProperties` when rejected. See the section on additional properties for details.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n| **override**?: callback                                                            | See section                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n| **postProcess**?: callback                                                         | See section                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n| **openAiAnyTypeName**?: string                                                     | Decides the name of a Json schema used to allow semi-arbitrary values in Open AI structured output. If any value in the Zod-schema resolves to any \"any\"-type schema it will reference a definition of this name. If no such definition is provided a default Json schema will be used. Defaults to \"OpenAiAnyType\"                                                                                                                                                                                                                                                                                                                                                                     |\n\n### Definitions\n\nThe definitions option lets you manually add recurring schemas into definitions for cleaner outputs. It's fully compatible with named schemas, changed definitions path and base path. Here's a simple example:\n\n```typescript\nconst myRecurringSchema = z.string();\nconst myObjectSchema = z.object({ a: myRecurringSchema, b: myRecurringSchema });\n\nconst myJsonSchema = zodToJsonSchema(myObjectSchema, {\n  definitions: { myRecurringSchema },\n});\n```\n\n#### Result\n\n```json\n{\n  \"type\": \"object\",\n  \"properties\": {\n    \"a\": {\n      \"$ref\": \"#/definitions/myRecurringSchema\"\n    },\n    \"b\": {\n      \"$ref\": \"#/definitions/myRecurringSchema\"\n    }\n  },\n  \"definitions\": {\n    \"myRecurringSchema\": {\n      \"type\": \"string\"\n    }\n  }\n}\n```\n\n### Error Messages\n\nThis feature allows optionally including error messages created via chained function calls for supported zod types:\n\n```ts\n// string schema with additional chained function call checks\nconst EmailSchema = z.string().email(\"Invalid email\").min(5, \"Too short\");\n\nconst jsonSchema = zodToJsonSchema(EmailSchema, { errorMessages: true });\n```\n\n#### Result\n\n```json\n{\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"type\": \"string\",\n  \"format\": \"email\",\n  \"minLength\": 5,\n  \"errorMessage\": {\n    \"format\": \"Invalid email\",\n    \"minLength\": \"Too short\"\n  }\n}\n```\n\nThis allows for field specific, validation step specific error messages which can be useful for building forms and such. This format is accepted by `react-hook-form`'s ajv resolver (and therefor `ajv-errors` which it uses under the hood). Note that if using AJV with this format will require [enabling `ajv-errors`](https://ajv.js.org/packages/ajv-errors.html#usage) as vanilla AJV does not accept this format by default.\n\n#### Custom Error Message Support\n\n- ZodString\n  - regex\n  - min, max\n  - email, cuid, uuid, url\n  - endsWith, startsWith\n- ZodNumber\n  - min, max, lt, lte, gt, gte,\n  - int\n  - multipleOf\n- ZodSet\n  - min, max\n- ZodArray\n  - min, max\n\n### Additional properties\n\nBy default, Zod removes undeclared properties when parsing object schemas. In order to replicate the expected output of this behaviour, the default for behaviour of zodToJsonSchema is to set `\"additionalProperties\"` to `false` (although the correctness of this can be debated). If you wish to allow undeclared properties you can either:\n\n- Set `removeAdditionalStrategy` to `\"strict\"`. This will allow additional properties for any object schema that is not declared with `.strict()`.\n- Leave `removeAdditionalStrategy` set to its default value of `\"passthrough\"`, and add `.passtrough()` to your object schema.\n\n#### Removing the `additionalProperties` keyword using the `allowedAdditionalProperties` and/or `rejectedAdditionalProperties` options.\n\nSome schema definitions (like Googles Gen AI API for instance) does not allow the `additionalProperties` keyword at all. Luckily the JSON Schema spec allows for this: leaving the keyword undefined _should_ have the same effect as setting it to true (as per usual YMMV). To enable this behaviour, set the option `allowedAdditionalProperties` to `undefined`.\n\nTo exclude the keyword even when additional properties are _not_ allowed, set the `rejectedAdditionalProperties` to `undefined` as well.\n\n_Heads up ⚠️: Both of these options will be ignored if your schema is declared with `.catchall(...)` as the provided schema will be used instead (if valid)._\n\n#### Expected outputs\n\n| `z.object({})` + option   | `\"additionalProperties\"` value                              |\n| ------------------------- | ----------------------------------------------------------- |\n| `.strip()` (default)      | `false` if strategy is `\"passtrough\"`, `true` if `\"strict\"` |\n| `.passtrough()`           | `true`                                                      |\n| `.strict()`               | `false`                                                     |\n| `.catchall(z.string())`   | `{ \"type\": \"string\" }`                                      |\n| `.catchall(z.function())` | `undefined` (function schemas are not currently parseable)  |\n\nSubstitute `true` and `false` for `undefined` according to `allowedAdditionalProperties` and/or `rejectedAdditionalProperties` respectively.\n\n### `override`\n\nThis options takes a callback receiving a Zod schema definition, the current reference object (containing the current ref path and other options), an argument containing inforation about wether or not the schema has been encountered before, and a forceResolution argument.\n\nImportant: if you don't want to override the current item you have to return the `ignoreOverride` symbol exported from the index. This is because `undefined` is a valid option to return when you want the property to be excluded from the resulting JSON schema.\n\n```typescript\nimport zodToJsonSchema, { ignoreOverride } from \"zod-to-json-schema\";\n\nzodToJsonSchema(\n  z.object({\n    ignoreThis: z.string(),\n    overrideThis: z.string(),\n    removeThis: z.string(),\n  }),\n  {\n    override: (def, refs) => {\n      const path = refs.currentPath.join(\"/\");\n\n      if (path === \"#/properties/overrideThis\") {\n        return {\n          type: \"integer\",\n        };\n      }\n\n      if (path === \"#/properties/removeThis\") {\n        return undefined;\n      }\n\n      // Important! Do not return `undefined` or void unless you want to remove the property from the resulting schema completely.\n      return ignoreOverride;\n    },\n  },\n);\n```\n\nExpected output:\n\n```json\n{\n  \"type\": \"object\",\n  \"required\": [\"ignoreThis\", \"overrideThis\"],\n  \"properties\": {\n    \"ignoreThis\": {\n      \"type\": \"string\"\n    },\n    \"overrideThis\": {\n      \"type\": \"integer\"\n    }\n  },\n  \"additionalProperties\": false\n}\n```\n\n### `postProcess`\n\nBesided receiving all arguments of the `override` callback, the `postProcess` callback also receives the generated schema. It should always return a JSON Schema, or `undefined` if you wish to filter it out. Unlike the `override` callback you do not have to return `ignoreOverride` if you are happy with the produced schema; simply return it unchanged.\n\n```typescript\nimport zodToJsonSchema, { PostProcessCallback } from \"zod-to-json-schema\";\n\n// Define the callback to be used to process the output using the PostProcessCallback type:\nconst postProcess: PostProcessCallback = (\n  // The original output produced by the package itself:\n  jsonSchema,\n  // The ZodSchema def used to produce the original schema:\n  def,\n  // The refs object containing the current path, passed options, etc.\n  refs,\n) => {\n  if (!jsonSchema) {\n    return jsonSchema;\n  }\n\n  // Try to expand description as JSON meta:\n  if (jsonSchema.description) {\n    try {\n      jsonSchema = {\n        ...jsonSchema,\n        ...JSON.parse(jsonSchema.description),\n      };\n    } catch {}\n  }\n\n  // Make all numbers nullable:\n  if (\"type\" in jsonSchema! && jsonSchema.type === \"number\") {\n    jsonSchema.type = [\"number\", \"null\"];\n  }\n\n  // Add the refs path, just because\n  (jsonSchema as any).path = refs.currentPath;\n\n  return jsonSchema;\n};\n\nconst jsonSchema = zodToJsonSchema(zodSchema, { postProcess });\n```\n\n#### Using `postProcess` for including examples and other meta\n\nAdding support for examples and other JSON Schema meta keys are among the most commonly requested features for this project. Unfortunately the current Zod major (3) has pretty anemic support for this, so some userland hacking is required. Since this is such a common usecase I've included a helper function that simply tries to parse any description as JSON and expand it into the resulting schema.\n\nSimply stringify whatever you want added to the output schema as the description, then import and use `jsonDescription` as the postProcess option:\n\n```typescript\nimport zodToJsonSchema, { jsonDescription } from \"zod-to-json-schema\";\n\nconst zodSchema = z.string().describe(\n  JSON.stringify({\n    title: \"My string\",\n    description: \"My description\",\n    examples: [\"Foo\", \"Bar\"],\n    whatever: 123,\n  }),\n);\n\nconst jsonSchema = zodToJsonSchema(zodSchema, {\n  postProcess: jsonDescription,\n});\n```\n\nExpected output:\n\n```json\n{\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"type\": \"string\",\n  \"title\": \"My string\",\n  \"description\": \"My description\",\n  \"examples\": [\"Foo\", \"Bar\"],\n  \"whatever\": 123\n}\n```\n\n## Known issues\n\n- The OpenAI target should be considered experimental for now, as some combination of options may break the compatibility.\n- When using `.transform`, the return type is inferred from the supplied function. In other words, there is no schema for the return type, and there is no way to convert it in runtime. Currently the JSON schema will therefore reflect the input side of the Zod schema and not necessarily the output (the latter aka. `z.infer`). If this causes problems with your schema, consider using the effectStrategy \"any\", which will allow any type of output.\n- JSON Schemas does not support any other key type than strings for objects. When using `z.record` with any other key type, this will be ignored. An exception to this rule is `z.enum` as is supported since 3.11.3\n- Relative JSON pointers, while published alongside [JSON schema draft 2020-12](https://json-schema.org/specification.html), is not technically a part of it. Currently, most resolvers do not handle them at all.\n- Since v3, the Object parser uses `.isOptional()` to check if a property should be included in `required` or not. This has the potentially dangerous behavior of calling `.safeParse` with `undefined`. To work around this, make sure your `preprocess` and other effects callbacks are pure and not liable to throw errors. An issue has been logged in the Zod repo and can be [tracked here](https://github.com/colinhacks/zod/issues/1460).\n- JSON Schema version 2020-12 is not yet officially supported. However, you should be able to use this library to obtain a compatible schema for the 2020-12 format just by changing the returned schema's `$schema` field to: \"https://json-schema.org/draft/2020-12/schema#\"\n\n## Versioning\n\nThis package _does not_ follow semantic versioning. The major and minor versions of this package instead reflects feature parity with the [Zod package](http://npmjs.com/package/zod).\n\nI will do my best to keep API-breaking changes to an absolute minimum, but new features may appear as \"patches\", such as introducing the options pattern in 3.9.1.\n\n## Changelog\n\nhttps://github.com/StefanTerdell/zod-to-json-schema/blob/master/changelog.md\n",
        "plugins/auto-review/mcp/node_modules/zod/README.md": "<p align=\"center\">\n  <img src=\"logo.svg\" width=\"200px\" align=\"center\" alt=\"Zod logo\" />\n  <h1 align=\"center\">Zod</h1>\n  <p align=\"center\">\n    TypeScript-first schema validation with static type inference\n    <br/>\n    by <a href=\"https://x.com/colinhacks\">@colinhacks</a>\n  </p>\n</p>\n<br/>\n\n<p align=\"center\">\n<a href=\"https://github.com/colinhacks/zod/actions?query=branch%3Amaster\"><img src=\"https://github.com/colinhacks/zod/actions/workflows/test.yml/badge.svg?event=push&branch=master\" alt=\"Zod CI status\" /></a>\n<a href=\"https://opensource.org/licenses/MIT\" rel=\"nofollow\"><img src=\"https://img.shields.io/github/license/colinhacks/zod\" alt=\"License\"></a>\n<a href=\"https://www.npmjs.com/package/zod\" rel=\"nofollow\"><img src=\"https://img.shields.io/npm/dw/zod.svg\" alt=\"npm\"></a>\n<a href=\"https://discord.gg/KaSRdyX2vc\" rel=\"nofollow\"><img src=\"https://img.shields.io/discord/893487829802418277?label=Discord&logo=discord&logoColor=white\" alt=\"discord server\"></a>\n<a href=\"https://github.com/colinhacks/zod\" rel=\"nofollow\"><img src=\"https://img.shields.io/github/stars/colinhacks/zod\" alt=\"stars\"></a>\n</p>\n\n<div align=\"center\">\n  <a href=\"https://zod.dev/api\">Docs</a>\n  <span>&nbsp;&nbsp;•&nbsp;&nbsp;</span>\n  <a href=\"https://discord.gg/RcG33DQJdf\">Discord</a>\n  <span>&nbsp;&nbsp;•&nbsp;&nbsp;</span>\n  <a href=\"https://twitter.com/colinhacks\">𝕏</a>\n  <span>&nbsp;&nbsp;•&nbsp;&nbsp;</span>\n  <a href=\"https://bsky.app/profile/zod.dev\">Bluesky</a>\n  <br />\n</div>\n\n<br/>\n<br/>\n\n<h2 align=\"center\">Featured sponsor: Jazz</h2>\n\n<div align=\"center\">\n  <a href=\"https://jazz.tools/?utm_source=zod\">\n    <picture width=\"85%\" >\n      <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://raw.githubusercontent.com/garden-co/jazz/938f6767e46cdfded60e50d99bf3b533f4809c68/homepage/homepage/public/Zod%20sponsor%20message.png\">\n      <img alt=\"jazz logo\" src=\"https://raw.githubusercontent.com/garden-co/jazz/938f6767e46cdfded60e50d99bf3b533f4809c68/homepage/homepage/public/Zod%20sponsor%20message.png\" width=\"85%\">\n    </picture>\n  </a>\n  <br/>\n  <p><sub>Learn more about <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"mailto:sponsorship@colinhacks.com\">featured sponsorships</a></sub></p>\n</div>\n\n<br/>\n<br/>\n<br/>\n\n### [Read the docs →](https://zod.dev/api)\n\n<br/>\n<br/>\n\n## What is Zod?\n\nZod is a TypeScript-first validation library. Define a schema and parse some data with it. You'll get back a strongly typed, validated result.\n\n```ts\nimport * as z from \"zod/v4\";\n\nconst User = z.object({\n  name: z.string(),\n});\n\n// some untrusted data...\nconst input = {\n  /* stuff */\n};\n\n// the parsed result is validated and type safe!\nconst data = User.parse(input);\n\n// so you can use it with confidence :)\nconsole.log(data.name);\n```\n\n<br/>\n\n## Features\n\n- Zero external dependencies\n- Works in Node.js and all modern browsers\n- Tiny: `2kb` core bundle (gzipped)\n- Immutable API: methods return a new instance\n- Concise interface\n- Works with TypeScript and plain JS\n- Built-in JSON Schema conversion\n- Extensive ecosystem\n\n<br/>\n\n## Installation\n\n```sh\nnpm install zod\n```\n\n<br/>\n\n## Basic usage\n\nBefore you can do anything else, you need to define a schema. For the purposes of this guide, we'll use a simple object schema.\n\n```ts\nimport * as z from \"zod/v4\";\n\nconst Player = z.object({\n  username: z.string(),\n  xp: z.number(),\n});\n```\n\n### Parsing data\n\nGiven any Zod schema, use `.parse` to validate an input. If it's valid, Zod returns a strongly-typed _deep clone_ of the input.\n\n```ts\nPlayer.parse({ username: \"billie\", xp: 100 });\n// => returns { username: \"billie\", xp: 100 }\n```\n\n**Note** — If your schema uses certain asynchronous APIs like `async` [refinements](#refine) or [transforms](#transform), you'll need to use the `.parseAsync()` method instead.\n\n```ts\nconst schema = z.string().refine(async (val) => val.length <= 8);\n\nawait schema.parseAsync(\"hello\");\n// => \"hello\"\n```\n\n### Handling errors\n\nWhen validation fails, the `.parse()` method will throw a `ZodError` instance with granular information about the validation issues.\n\n```ts\ntry {\n  Player.parse({ username: 42, xp: \"100\" });\n} catch (err) {\n  if (err instanceof z.ZodError) {\n    err.issues;\n    /* [\n      {\n        expected: 'string',\n        code: 'invalid_type',\n        path: [ 'username' ],\n        message: 'Invalid input: expected string'\n      },\n      {\n        expected: 'number',\n        code: 'invalid_type',\n        path: [ 'xp' ],\n        message: 'Invalid input: expected number'\n      }\n    ] */\n  }\n}\n```\n\nTo avoid a `try/catch` block, you can use the `.safeParse()` method to get back a plain result object containing either the successfully parsed data or a `ZodError`. The result type is a [discriminated union](https://www.typescriptlang.org/docs/handbook/2/narrowing.html#discriminated-unions), so you can handle both cases conveniently.\n\n```ts\nconst result = Player.safeParse({ username: 42, xp: \"100\" });\nif (!result.success) {\n  result.error; // ZodError instance\n} else {\n  result.data; // { username: string; xp: number }\n}\n```\n\n**Note** — If your schema uses certain asynchronous APIs like `async` [refinements](#refine) or [transforms](#transform), you'll need to use the `.safeParseAsync()` method instead.\n\n```ts\nconst schema = z.string().refine(async (val) => val.length <= 8);\n\nawait schema.safeParseAsync(\"hello\");\n// => { success: true; data: \"hello\" }\n```\n\n### Inferring types\n\nZod infers a static type from your schema definitions. You can extract this type with the `z.infer<>` utility and use it however you like.\n\n```ts\nconst Player = z.object({\n  username: z.string(),\n  xp: z.number(),\n});\n\n// extract the inferred type\ntype Player = z.infer<typeof Player>;\n\n// use it in your code\nconst player: Player = { username: \"billie\", xp: 100 };\n```\n\nIn some cases, the input & output types of a schema can diverge. For instance, the `.transform()` API can convert the input from one type to another. In these cases, you can extract the input and output types independently:\n\n```ts\nconst mySchema = z.string().transform((val) => val.length);\n\ntype MySchemaIn = z.input<typeof mySchema>;\n// => string\n\ntype MySchemaOut = z.output<typeof mySchema>; // equivalent to z.infer<typeof mySchema>\n// number\n```\n",
        "plugins/crypto/.claude-plugin/plugin.json": "{\n  \"name\": \"crypto\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Multi-chain blockchain explorer integration using Foundry's cast CLI for Etherscan, Polygonscan, Arbiscan, and more\",\n  \"author\": {\n    \"name\": \"useful-claude-plugins\",\n    \"url\": \"https://github.com/cheolwanpark/useful-claude-plugins\"\n  },\n  \"repository\": \"https://github.com/cheolwanpark/useful-claude-plugins\",\n  \"license\": \"MIT\",\n  \"keywords\": [\n    \"ethereum\",\n    \"blockchain\",\n    \"etherscan\",\n    \"cast\",\n    \"foundry\",\n    \"polygon\",\n    \"arbitrum\",\n    \"optimism\",\n    \"base\",\n    \"bsc\",\n    \"smart-contracts\"\n  ]\n}\n",
        "plugins/crypto/README.md": "# Crypto Plugin\n\nMulti-chain blockchain explorer integration supporting **EVM chains** (via Foundry's `cast`) and **Solana** (via Solana/Anchor CLI). Query contract source code, balances, transactions, fees, and blocks across multiple networks.\n\n## Features\n\n### EVM Chains (Ethereum, Polygon, Arbitrum, Optimism, Base, BSC)\n- **Zero-config RPC**: Works out of the box with PublicNode fallback endpoints\n- **Contract inspection**: Fetch verified source code from block explorers\n- **Address information**: Check balances and account types (EOA vs contract)\n- **Transaction lookup**: Get detailed transaction data\n- **Gas prices**: Check current gas costs with transaction estimates\n- **Block information**: Query block data\n\n### Solana\n- **Public RPC fallback**: Uses Solana public RPC by default\n- **Account inspection**: Check SOL balances and account types\n- **Transaction lookup**: Get transaction details by signature\n- **Slot/Block info**: Query current slot and epoch data\n- **Program IDL**: Fetch Anchor program IDL from on-chain\n\n## Installation\n\n### Prerequisites\n\n1. **zsh** - Scripts use zsh for cross-platform compatibility\n   - macOS: Pre-installed (default shell)\n   - Linux: Install with your package manager if needed\n\n2. **For EVM skills** - Install Foundry toolkit:\n   ```bash\n   curl -L https://foundry.paradigm.xyz | bash\n   foundryup\n   ```\n\n3. **For Solana skills** - Install Solana CLI:\n   ```bash\n   sh -c \"$(curl -sSfL https://release.anza.xyz/stable/install)\"\n   export PATH=\"$HOME/.local/share/solana/install/active_release/bin:$PATH\"\n   ```\n\n4. **For IDL fetching** - Install Anchor CLI (optional):\n   ```bash\n   cargo install --git https://github.com/coral-xyz/anchor anchor-cli --locked\n   ```\n\n5. **Verify installation**:\n   ```bash\n   zsh --version\n   cast --version      # For EVM skills\n   solana --version    # For Solana skills\n   anchor --version    # For IDL skill (optional)\n   ```\n\n### Environment Variables\n\nAdd to your shell profile (`~/.bashrc`, `~/.zshrc`, etc.):\n\n#### EVM RPC URLs (optional - has free fallback)\n\n**No configuration required!** The plugin automatically uses [PublicNode](https://publicnode.com) as a free fallback.\n\n| Chain | Fallback RPC URL |\n|-------|------------------|\n| Ethereum | `https://ethereum-rpc.publicnode.com` |\n| Polygon | `https://polygon-bor-rpc.publicnode.com` |\n| Arbitrum | `https://arbitrum-one-rpc.publicnode.com` |\n| Optimism | `https://optimism-rpc.publicnode.com` |\n| Base | `https://base-rpc.publicnode.com` |\n| BSC | `https://bsc-rpc.publicnode.com` |\n\nFor higher rate limits, set your own RPC URLs:\n```bash\nexport ETHEREUM_RPC_URL=\"https://eth-mainnet.g.alchemy.com/v2/YOUR_KEY\"\nexport POLYGON_RPC_URL=\"https://polygon-mainnet.g.alchemy.com/v2/YOUR_KEY\"\n# ... etc\n```\n\n#### Solana RPC URLs (optional - has free fallback)\n\n| Chain | Fallback RPC URL |\n|-------|------------------|\n| Solana | `https://api.mainnet-beta.solana.com` |\n| Solana Devnet | `https://api.devnet.solana.com` |\n\nFor better performance, configure a custom RPC:\n```bash\nexport SOLANA_RPC_URL=\"https://your-helius-endpoint.com\"\nexport SOLANA_DEVNET_RPC_URL=\"https://your-devnet-endpoint.com\"\n```\n\n#### API Keys (required for evm-contract-source skill)\n\n```bash\nexport ETHERSCAN_API_KEY=\"your-key\"\nexport POLYGONSCAN_API_KEY=\"your-key\"\nexport ARBISCAN_API_KEY=\"your-key\"\nexport OPTIMISM_API_KEY=\"your-key\"\nexport BASESCAN_API_KEY=\"your-key\"\nexport BSCSCAN_API_KEY=\"your-key\"\n```\n\nGet free API keys from: [Etherscan](https://etherscan.io/apis), [Polygonscan](https://polygonscan.com/apis), [Arbiscan](https://arbiscan.io/apis), [Optimism Etherscan](https://optimistic.etherscan.io/apis), [Basescan](https://basescan.org/apis), [BSCScan](https://bscscan.com/apis)\n\n## Skills\n\nAll skills are **auto-triggered** by Claude based on your intent. No `/command` needed!\n\n### EVM Skills (`evm-*`)\n\n| Skill | Trigger Phrases | Requirements |\n|-------|-----------------|--------------|\n| `evm-contract-source` | \"get contract source\", \"show verified contract\" | API key |\n| `evm-address-info` | \"check balance\", \"is this a contract\" | None |\n| `evm-tx-info` | \"transaction details\", \"show me tx\" | None |\n| `evm-gas-price` | \"gas price\", \"current gas\" | None |\n| `evm-block-info` | \"block info\", \"latest block\" | None |\n\n**Example prompts**:\n- \"Show me the source code for WETH at 0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2\"\n- \"What's the balance of vitalik.eth?\"\n- \"What's the current gas price on Ethereum?\"\n- \"Check gas fees on Arbitrum\"\n\n### Solana Skills (`sol-*`)\n\n| Skill | Trigger Phrases | Requirements |\n|-------|-----------------|--------------|\n| `sol-account-info` | \"solana balance\", \"is this a program\" | `solana` CLI |\n| `sol-tx-info` | \"solana transaction\", \"signature details\" | `solana` CLI |\n| `sol-slot-info` | \"current slot\", \"solana block\" | `solana` CLI |\n| `sol-fees` | \"solana fees\", \"priority fees\" | `solana` CLI |\n| `sol-program-idl` | \"fetch IDL\", \"anchor idl\" | `anchor` CLI |\n\n**Example prompts**:\n- \"What's the balance of vines1vzrYbzLMRdu58ou5XTby4qAqVRLmqo36NKPTg on Solana?\"\n- \"Check current slot on Solana\"\n- \"What are the current fees on Solana?\"\n- \"Fetch the IDL for MarBmsSgKXdrN1egZf5sqe1TMai9K1rChYNDJgjq7aD\"\n\n## Supported Chains\n\n### EVM Chains\n\n| Chain | Aliases | Chain ID | Native Token | Explorer |\n|-------|---------|----------|--------------|----------|\n| ethereum | eth, mainnet | 1 | ETH | Etherscan |\n| polygon | matic | 137 | MATIC | Polygonscan |\n| arbitrum | arb | 42161 | ETH | Arbiscan |\n| optimism | op | 10 | ETH | Optimism Etherscan |\n| base | - | 8453 | ETH | Basescan |\n| bsc | binance, bnb | 56 | BNB | BSCScan |\n\n### Solana Chains\n\n| Chain | Aliases | Network | Native Token | Explorer |\n|-------|---------|---------|--------------|----------|\n| solana | sol | mainnet-beta | SOL | Solana Explorer |\n| solana-devnet | sol-devnet, devnet | devnet | SOL | Solana Explorer |\n\n## Test Addresses\n\n### EVM (Ethereum Mainnet)\n- **WETH**: `0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2`\n- **USDC**: `0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48`\n- **Uniswap V2 Router**: `0x7a250d5630B4cF539739dF2C5dAcb4c659F2488D`\n\n### Solana\n- **Token Program**: `TokenkegQfeZyiNwAJbNbGKPFXCWuBvf9Ss623VQ5DA`\n- **Marinade Finance (has IDL)**: `MarBmsSgKXdrN1egZf5sqe1TMai9K1rChYNDJgjq7aD`\n- **Test Wallet**: `vines1vzrYbzLMRdu58ou5XTby4qAqVRLmqo36NKPTg`\n\n## Troubleshooting\n\n### \"cast not found\"\nInstall Foundry:\n```bash\ncurl -L https://foundry.paradigm.xyz | bash\nfoundryup\n```\n\n### \"solana not found\"\nInstall Solana CLI:\n```bash\nsh -c \"$(curl -sSfL https://release.anza.xyz/stable/install)\"\nexport PATH=\"$HOME/.local/share/solana/install/active_release/bin:$PATH\"\n```\n\n### \"anchor not found\"\nInstall Anchor CLI (requires Rust):\n```bash\ncargo install --git https://github.com/coral-xyz/anchor anchor-cli --locked\n```\n\n### \"API key not configured\"\nSet the API key for contract source fetching:\n```bash\nexport ETHERSCAN_API_KEY=\"your-key\"\n```\n\n### Rate Limiting\nIf you hit rate limits with public fallback endpoints:\n- Configure your own RPC endpoints (see Environment Variables)\n- Use providers like Alchemy, Infura, QuickNode, or Helius\n- Upgrade to a paid API plan for production use\n\n## License\n\nMIT\n",
        "plugins/crypto/skills/evm-address-info/SKILL.md": "---\nname: evm-address-info\ndescription: Use this skill when the user asks to \"check balance\", \"what's the balance of\", \"is this a contract or EOA\", \"get address info\", or mentions checking wallet balance or account type on EVM chains (Ethereum, Polygon, Arbitrum, etc.). Requires an address and optional chain parameter.\nallowed-tools: Bash\n---\n\n# EVM Address Info Fetcher\n\nGets address balance and account type (EOA vs Contract) from an EVM blockchain network.\n\n## Usage\n\nRun the script with address and optional chain:\n```bash\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-evm-address-info.sh <address> [chain]\n```\n\n## Arguments\n\n- `address` (required): Ethereum address (0x + 40 hex) or ENS name\n- `chain` (optional): Chain name - ethereum (default), polygon, arbitrum, optimism, base, bsc\n\n## Supported Chains\n\n| Chain | Aliases | Explorer |\n|-------|---------|----------|\n| ethereum | eth, mainnet | Etherscan |\n| polygon | matic | Polygonscan |\n| arbitrum | arb | Arbiscan |\n| optimism | op | Optimism Etherscan |\n| base | - | Basescan |\n| bsc | binance | BSCScan |\n\n## Requirements\n\n- `cast` (Foundry) must be installed\n- RPC URL is optional (uses PublicNode fallback)\n\n## Examples\n\n```bash\n# Check ENS name balance on Ethereum\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-evm-address-info.sh vitalik.eth\n\n# Check address on Polygon\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-evm-address-info.sh 0x1234...abcd polygon\n```\n\n## Note\n\nFor Solana account info, use the `sol-account-info` skill instead.\n",
        "plugins/crypto/skills/evm-block-info/SKILL.md": "---\nname: evm-block-info\ndescription: Use this skill when the user asks \"block info\", \"what's in block\", \"latest block\", \"get block details\", or mentions viewing block data on EVM chains (Ethereum, Polygon, Arbitrum, etc.). Optional block number/tag and chain parameter.\nallowed-tools: Bash\n---\n\n# EVM Block Info Fetcher\n\nGets block information from an EVM blockchain network.\n\n## Usage\n\nRun the script with optional block and chain:\n```bash\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-evm-block-info.sh [block] [chain]\n```\n\n## Arguments\n\n- `block` (optional): Block number, hex, or tag (latest, pending, earliest, finalized, safe). Default: latest\n- `chain` (optional): Chain name - ethereum (default), polygon, arbitrum, optimism, base, bsc\n\n## Supported Chains\n\n| Chain | Aliases | Explorer |\n|-------|---------|----------|\n| ethereum | eth, mainnet | Etherscan |\n| polygon | matic | Polygonscan |\n| arbitrum | arb | Arbiscan |\n| optimism | op | Optimism Etherscan |\n| base | - | Basescan |\n| bsc | binance | BSCScan |\n\n## Requirements\n\n- `cast` (Foundry) must be installed\n- RPC URL is optional (uses PublicNode fallback)\n\n## Examples\n\n```bash\n# Get latest block on Ethereum\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-evm-block-info.sh\n\n# Get specific block on Polygon\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-evm-block-info.sh 50000000 polygon\n```\n\n## Note\n\nFor Solana slot/block info, use the `sol-slot-info` skill instead.\n",
        "plugins/crypto/skills/evm-contract-source/SKILL.md": "---\nname: evm-contract-source\ndescription: Use this skill when the user asks to \"get contract source code\", \"show verified contract\", \"fetch source from etherscan\", \"view smart contract code\", or mentions viewing verified source code on EVM chains (Ethereum, Polygon, Arbitrum, etc.). Requires a contract address and optional chain parameter.\nallowed-tools: Bash\n---\n\n# EVM Contract Source Fetcher\n\nFetches verified smart contract source code from block explorers (Etherscan, Polygonscan, etc.).\n\n## Usage\n\nRun the script with address and optional chain:\n```bash\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-evm-contract-source.sh <address> [chain]\n```\n\n## Arguments\n\n- `address` (required): Contract address in hex format (0x + 40 hex characters). ENS names are NOT supported.\n- `chain` (optional): Chain name - ethereum (default), polygon, arbitrum, optimism, base, bsc\n\n## Supported Chains\n\n| Chain | Aliases | Explorer |\n|-------|---------|----------|\n| ethereum | eth, mainnet | Etherscan |\n| polygon | matic | Polygonscan |\n| arbitrum | arb | Arbiscan |\n| optimism | op | Optimism Etherscan |\n| base | - | Basescan |\n| bsc | binance | BSCScan |\n\n## Requirements\n\n- `cast` (Foundry) must be installed\n- API key must be set for the target chain:\n  - `ETHERSCAN_API_KEY` for Ethereum (also used as fallback for other chains)\n  - `POLYGONSCAN_API_KEY` for Polygon\n  - `ARBISCAN_API_KEY` for Arbitrum\n  - `OPTIMISM_API_KEY` for Optimism\n  - `BASESCAN_API_KEY` for Base\n  - `BSCSCAN_API_KEY` for BSC\n\n## Examples\n\n```bash\n# Get WETH source on Ethereum\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-evm-contract-source.sh 0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2\n\n# Get QuickSwap Router source on Polygon\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-evm-contract-source.sh 0xa5E0829CaCEd8fFDD4De3c43696c57F7D7A678ff polygon\n```\n\n## Note\n\nFor Solana program IDL, use the `sol-program-idl` skill instead.\n",
        "plugins/crypto/skills/evm-gas-price/SKILL.md": "---\nname: evm-gas-price\ndescription: Use this skill when the user asks \"gas price\", \"how much is gas\", \"current gas\", \"check gas fees\", or mentions checking gas costs on EVM chains (Ethereum, Polygon, Arbitrum, etc.). Optional chain parameter.\nallowed-tools: Bash\n---\n\n# EVM Gas Price Fetcher\n\nGets current gas price for an EVM blockchain network.\n\n## Usage\n\nRun the script with optional chain:\n```bash\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-evm-gas-price.sh [chain]\n```\n\n## Arguments\n\n- `chain` (optional): Chain name - ethereum (default), polygon, arbitrum, optimism, base, bsc\n\n## Supported Chains\n\n| Chain | Aliases | Explorer |\n|-------|---------|----------|\n| ethereum | eth, mainnet | Etherscan |\n| polygon | matic | Polygonscan |\n| arbitrum | arb | Arbiscan |\n| optimism | op | Optimism Etherscan |\n| base | - | Basescan |\n| bsc | binance | BSCScan |\n\n## Requirements\n\n- `cast` (Foundry) must be installed\n- RPC URL is optional (uses PublicNode fallback)\n\n## Examples\n\n```bash\n# Get gas price on Ethereum\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-evm-gas-price.sh\n\n# Get gas price on Polygon\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-evm-gas-price.sh polygon\n```\n\n## Note\n\nFor Solana fees, use the `sol-fees` skill instead.\n",
        "plugins/crypto/skills/evm-tx-info/SKILL.md": "---\nname: evm-tx-info\ndescription: Use this skill when the user asks for \"transaction details\", \"show me tx\", \"what happened in this transaction\", \"look up transaction\", or mentions viewing transaction data on EVM chains (Ethereum, Polygon, Arbitrum, etc.). Requires a transaction hash and optional chain parameter.\nallowed-tools: Bash\n---\n\n# EVM Transaction Info Fetcher\n\nGets transaction details by hash from an EVM blockchain network.\n\n## Usage\n\nRun the script with transaction hash and optional chain:\n```bash\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-evm-tx-info.sh <tx_hash> [chain]\n```\n\n## Arguments\n\n- `tx_hash` (required): Transaction hash (0x + 64 hex characters)\n- `chain` (optional): Chain name - ethereum (default), polygon, arbitrum, optimism, base, bsc\n\n## Supported Chains\n\n| Chain | Aliases | Explorer |\n|-------|---------|----------|\n| ethereum | eth, mainnet | Etherscan |\n| polygon | matic | Polygonscan |\n| arbitrum | arb | Arbiscan |\n| optimism | op | Optimism Etherscan |\n| base | - | Basescan |\n| bsc | binance | BSCScan |\n\n## Requirements\n\n- `cast` (Foundry) must be installed\n- RPC URL is optional (uses PublicNode fallback)\n\n## Examples\n\n```bash\n# Get transaction on Ethereum\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-evm-tx-info.sh 0x1234...abcd\n\n# Get transaction on Polygon\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-evm-tx-info.sh 0x5678...efgh polygon\n```\n\n## Note\n\nFor Solana transaction info, use the `sol-tx-info` skill instead.\n",
        "plugins/crypto/skills/sol-account-info/SKILL.md": "---\nname: sol-account-info\ndescription: Use this skill when the user asks \"solana balance\", \"sol balance\", \"solana account\", \"is this a program\", or mentions checking account info on Solana. Requires an address and optional chain parameter.\nallowed-tools: Bash\n---\n\n# Solana Account Info\n\nGets account balance, type, and details from Solana network.\n\n## Usage\n\nRun the script with address and optional chain:\n```bash\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-sol-account-info.sh <address> [chain]\n```\n\n## Arguments\n\n- `address` (required): Solana address (Base58, 32-44 characters)\n- `chain` (optional): Chain name - solana (default), solana-devnet\n\n## Supported Chains\n\n| Chain | Aliases | Network |\n|-------|---------|---------|\n| solana | sol | mainnet-beta |\n| solana-devnet | sol-devnet, devnet | devnet |\n\n## Requirements\n\n- `solana` CLI must be installed\n\n## Examples\n\n```bash\n# Check account on Solana mainnet\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-sol-account-info.sh vines1vzrYbzLMRdu58ou5XTby4qAqVRLmqo36NKPTg solana\n\n# Check Token Program\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-sol-account-info.sh TokenkegQfeZyiNwAJbNbGKPFXCWuBvf9Ss623VQ5DA solana\n```\n\n## Note\n\nFor EVM address info, use the `evm-address-info` skill instead.\n",
        "plugins/crypto/skills/sol-fees/SKILL.md": "---\nname: sol-fees\ndescription: Use this skill when the user asks \"solana fees\", \"sol fees\", \"priority fees\", \"lamports per signature\", or mentions checking transaction fees on Solana. Optional chain parameter (solana or solana-devnet).\nallowed-tools: Bash\n---\n\n# Solana Network Fees\n\nGets current fee structure for Solana network.\n\n## Usage\n\nRun the script with optional chain:\n```bash\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-sol-fees.sh [chain]\n```\n\n## Arguments\n\n- `chain` (optional): Chain name - solana (default), solana-devnet\n\n## Supported Chains\n\n| Chain | Aliases | Network |\n|-------|---------|---------|\n| solana | sol | mainnet-beta |\n| solana-devnet | sol-devnet, devnet | devnet |\n\n## Requirements\n\n- `solana` CLI must be installed\n\n## Examples\n\n```bash\n# Get fees on Solana mainnet\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-sol-fees.sh\n\n# Get fees on Solana devnet\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-sol-fees.sh solana-devnet\n```\n\n## Note\n\nFor EVM chain gas prices, use the `evm-gas-price` skill instead.\n",
        "plugins/crypto/skills/sol-program-idl/SKILL.md": "---\nname: sol-program-idl\ndescription: Use this skill when the user asks \"fetch IDL\", \"program IDL\", \"anchor idl\", \"program interface\", or mentions fetching Solana program IDL. Requires a program address and optional chain parameter.\nallowed-tools: Bash\n---\n\n# Solana Program IDL\n\nFetches the IDL (Interface Definition Language) for Anchor programs on Solana.\n\n## Usage\n\nRun the script with program address and optional chain:\n```bash\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-sol-program-idl.sh <program_address> [chain]\n```\n\n## Arguments\n\n- `program_address` (required): Program address (Base58)\n- `chain` (optional): Chain name - solana (default), solana-devnet\n\n## Supported Chains\n\n| Chain | Aliases | Network |\n|-------|---------|---------|\n| solana | sol | mainnet-beta |\n| solana-devnet | sol-devnet, devnet | devnet |\n\n## Requirements\n\n- `anchor` CLI must be installed\n- Program must be an Anchor program with published IDL\n\n## Examples\n\n```bash\n# Fetch IDL for Marinade Finance\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-sol-program-idl.sh MarBmsSgKXdrN1egZf5sqe1TMai9K1rChYNDJgjq7aD solana\n\n# Fetch IDL on devnet\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-sol-program-idl.sh <program_address> solana-devnet\n```\n\n## Note\n\nFor EVM contract source code, use the `evm-contract-source` skill instead.\n",
        "plugins/crypto/skills/sol-slot-info/SKILL.md": "---\nname: sol-slot-info\ndescription: Use this skill when the user asks \"solana slot\", \"current slot\", \"sol block\", \"latest slot\", \"epoch info\", or mentions checking slot/block info on Solana. Optional slot number and chain parameter.\nallowed-tools: Bash\n---\n\n# Solana Slot Info\n\nGets slot or block information from Solana network.\n\n## Usage\n\nRun the script with optional slot and chain:\n```bash\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-sol-slot-info.sh [slot] [chain]\n```\n\n## Arguments\n\n- `slot` (optional): Slot number or \"latest\" (default)\n- `chain` (optional): Chain name - solana (default), solana-devnet\n\n## Supported Chains\n\n| Chain | Aliases | Network |\n|-------|---------|---------|\n| solana | sol | mainnet-beta |\n| solana-devnet | sol-devnet, devnet | devnet |\n\n## Requirements\n\n- `solana` CLI must be installed\n\n## Examples\n\n```bash\n# Get current slot on Solana mainnet\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-sol-slot-info.sh\n\n# Get specific slot/block on Solana\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-sol-slot-info.sh 250000000 solana\n\n# Get current slot on devnet\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-sol-slot-info.sh latest solana-devnet\n```\n\n## Note\n\nFor EVM block info, use the `evm-block-info` skill instead.\n",
        "plugins/crypto/skills/sol-tx-info/SKILL.md": "---\nname: sol-tx-info\ndescription: Use this skill when the user asks for \"solana transaction\", \"sol tx\", \"signature details\", \"confirm signature\", or mentions viewing transaction data on Solana. Requires a transaction signature and optional chain parameter.\nallowed-tools: Bash\n---\n\n# Solana Transaction Info\n\nGets transaction details by signature from Solana network.\n\n## Usage\n\nRun the script with transaction signature and optional chain:\n```bash\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-sol-tx-info.sh <signature> [chain]\n```\n\n## Arguments\n\n- `signature` (required): Transaction signature (Base58, 86-90 characters)\n- `chain` (optional): Chain name - solana (default), solana-devnet\n\n## Supported Chains\n\n| Chain | Aliases | Network |\n|-------|---------|---------|\n| solana | sol | mainnet-beta |\n| solana-devnet | sol-devnet, devnet | devnet |\n\n## Requirements\n\n- `solana` CLI must be installed\n\n## Examples\n\n```bash\n# Get transaction on Solana mainnet\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-sol-tx-info.sh 5UfDuX...signature...here solana\n\n# Get transaction on devnet\n${CLAUDE_PLUGIN_ROOT}/scripts/crypto-sol-tx-info.sh 5UfDuX...signature...here solana-devnet\n```\n\n## Note\n\nFor EVM transaction info, use the `evm-tx-info` skill instead.\n",
        "plugins/go-lint/.claude-plugin/plugin.json": "{\n  \"name\": \"go-lint\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Automatic Go linting and formatting using goimports, go vet, and golangci-lint\",\n  \"author\": {\n    \"name\": \"useful-claude-plugins\",\n    \"url\": \"https://github.com/cheolwanpark/useful-claude-plugins\"\n  },\n  \"repository\": \"https://github.com/cheolwanpark/useful-claude-plugins\",\n  \"license\": \"MIT\",\n  \"keywords\": [\n    \"go\",\n    \"golang\",\n    \"lint\",\n    \"format\",\n    \"goimports\",\n    \"go-vet\",\n    \"golangci-lint\"\n  ],\n  \"hooks\": \"./hooks/hooks.json\"\n}\n",
        "plugins/go-lint/README.md": "# go-lint Plugin\n\nAutomatic Go linting and formatting for Claude Code using `goimports`, `go vet`, and `golangci-lint`.\n\n## Features\n\n- **Automatic formatting on file save**: Uses `goimports` to format code and organize imports\n- **Static analysis on edits**: Runs `go vet` on edited files to catch common mistakes\n- **Project-wide linting**: Comprehensive linting with `golangci-lint` via slash command\n- **Respects project configuration**: Honors `.golangci.yml` if present\n- **Fast feedback**: Single-file hooks optimized for speed\n\n## Installation\n\n### Required Tools\n\n1. **goimports** - For formatting and import management:\n   ```bash\n   go install golang.org/x/tools/cmd/goimports@latest\n   ```\n\n2. **go** - Standard Go toolchain (includes `go vet`)\n   - Download from [go.dev](https://go.dev/dl/)\n\n3. **golangci-lint** - For comprehensive project linting:\n   ```bash\n   # macOS/Linux\n   go install github.com/golangci/golangci-lint/cmd/golangci-lint@latest\n\n   # Alternative: Homebrew\n   brew install golangci-lint\n\n   # Verify installation\n   golangci-lint --version\n   ```\n\n### Plugin Installation\n\nThe plugin is automatically loaded when you have this repository in your Claude Code plugins directory.\n\n## Usage\n\n### Automatic Hook (Single File)\n\nThe hook automatically runs when you edit or create Go files:\n\n1. **Formatting**: Runs `goimports -w` to format code and organize imports (in-place modification)\n2. **Static Analysis**: Runs `go vet` on the package containing the file for quick checks\n3. **Non-blocking**: Always allows the operation to proceed (never blocks your workflow)\n\n**Behavior:**\n- The hook modifies files in-place to apply formatting\n- Runs `go vet` silently on the package (not entire project) for performance\n- Does not block operations even if issues are found (rust-lint pattern)\n- Use `/go-lint:lint-project` for comprehensive error reporting\n\n**File requirements:**\n- Must be a `.go` file\n- Must be under 1MB in size\n- Must be in a valid Go project (has `go.mod`, `go.work`, or `.git` in parent directories)\n\n**Example workflow:**\n```go\n// You edit a file with issues:\npackage main\n\nimport \"fmt\"\nimport \"os\"  // Will be organized by goimports\n\nfunc main() {\n    fmt.Println(\"Hello\")\n}\n```\n\nThe hook will:\n1. Automatically format and organize imports (saved to file)\n2. Run `go vet` silently in the background\n3. Allow the operation to proceed immediately\n\nTo see comprehensive lint results, run `/go-lint:lint-project`\n\n### Project-wide Linting (Slash Command)\n\nRun comprehensive linting on your entire project:\n\n```bash\n# Lint entire project\n/go-lint:lint-project\n\n# Lint specific directory\n/go-lint:lint-project ./cmd\n\n# Lint specific package\n/go-lint:lint-project ./internal/api\n```\n\n**Output includes:**\n- Summary of errors and warnings\n- Top 20 errors (if any)\n- Top 10 warnings (if any)\n- File locations and linter names\n\n**Example output:**\n```markdown\n## Go Linting Report\n\n**Target:** ./...\n**Project root:** /path/to/project\n**Config:** .golangci.yml\n\n### Summary\n\n- **Errors:** 3\n- **Warnings:** 0\n\n### Errors\n\n- **cmd/main.go:15:2** [errcheck] Error return value is not checked\n- **internal/api/handler.go:42:10** [ineffassign] Ineffectual assignment to err\n- **pkg/util/helper.go:8:6** [unused] func helper is unused\n```\n\n## Configuration\n\n### golangci-lint Configuration\n\nThe plugin respects your project's `.golangci.yml` configuration file:\n\n```yaml\n# .golangci.yml\nrun:\n  timeout: 5m\n  tests: true\n\nlinters:\n  enable:\n    - errcheck\n    - gosimple\n    - govet\n    - ineffassign\n    - staticcheck\n    - unused\n    - gofmt\n    - goimports\n\nissues:\n  max-issues-per-linter: 0\n  max-same-issues: 0\n```\n\nIf no config file is found, `golangci-lint` uses its default linters.\n\n### Hook Behavior\n\nThe hook is configured in `hooks/hooks.json`:\n\n```json\n{\n  \"description\": \"Automatically lint and format Go files using goimports and go vet\",\n  \"hooks\": {\n    \"PostToolUse\": [\n      {\n        \"matcher\": \"Edit|Write\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"${CLAUDE_PLUGIN_ROOT}/hooks/go-lint.sh\",\n            \"timeout\": 30\n          }\n        ]\n      }\n    ]\n  }\n}\n```\n\n- **Trigger**: PostToolUse on Edit|Write operations\n- **Timeout**: 30 seconds\n- **File types**: `*.go` files only\n\n## How It Works\n\n### Hook Workflow\n\n1. **Parse input**: Extract file path from PostToolUse event\n2. **Validate**: Check file extension, size, and existence\n3. **Find project root**: Walk up directory tree to find `go.mod`, `go.work`, or `.git`\n4. **Format**: Run `goimports -w` to format file in-place\n5. **Analyze**: Run `go vet ./...` from project root\n6. **Filter**: Show only issues in the edited file\n7. **Report**: Return JSON with block/allow decision\n\n### Project Linting Workflow\n\n1. **Validate target**: Check directory exists\n2. **Find project root**: Locate `go.mod` or `go.work`\n3. **Detect config**: Look for `.golangci.yml`\n4. **Run linter**: Execute `golangci-lint run --out-format=json --fix`\n5. **Parse results**: Extract issues from JSON output\n6. **Generate report**: Format as markdown with error/warning counts\n7. **Exit**: Code 1 for errors, 0 for warnings/success\n\n## Troubleshooting\n\n### Hook not running\n\n**Check tool installation:**\n```bash\nwhich goimports\nwhich go\nwhich golangci-lint\n```\n\n**Verify file size:**\n```bash\n# Files over 1MB are skipped\nls -lh yourfile.go\n```\n\n**Check project structure:**\n```bash\n# Must have go.mod, go.work, or .git\nls go.mod\n```\n\n### golangci-lint too slow\n\n**Reduce linter scope** in `.golangci.yml`:\n```yaml\nlinters:\n  default: fast  # Use only fast linters\n\nrun:\n  timeout: 2m\n  skip-dirs:\n    - vendor\n    - third_party\n```\n\n**Enable caching:**\n```bash\n# golangci-lint caches by default in:\n# macOS: ~/Library/Caches/golangci-lint\n# Linux: ~/.cache/golangci-lint\n\n# Clear cache if needed\ngolangci-lint cache clean\n```\n\n### False positives\n\n**Disable specific linters** in `.golangci.yml`:\n```yaml\nlinters:\n  disable:\n    - errcheck  # Too noisy for your project\n\nissues:\n  exclude-rules:\n    - path: _test\\.go\n      linters:\n        - errcheck  # Don't check errors in tests\n```\n\n**Add inline comments to suppress:**\n```go\n//nolint:errcheck // Ignore error here\nfoo()\n```\n\n### go vet fails but golangci-lint passes\n\n`go vet` and `golangci-lint` use different checks. The hook runs `go vet` for fast feedback, while the project command runs the full `golangci-lint` suite.\n\nTo align them, enable `govet` in `.golangci.yml`:\n```yaml\nlinters:\n  enable:\n    - govet\n```\n\n## Testing\n\nRun the test suite:\n\n```bash\ncd plugins/go-lint/tests\n./run-tests.sh\n```\n\nTests cover:\n- Hook behavior on clean files\n- Hook behavior on files with errors\n- Project root detection\n- Tool availability checking\n- JSON response generation\n\n## Contributing\n\nContributions welcome! Please ensure:\n- Tests pass\n- Scripts are shellcheck-clean\n- Documentation is updated\n- Follows existing plugin patterns\n\n## License\n\nMIT\n",
        "plugins/go-lint/commands/lint-project.md": "---\nallowed-tools: Bash\nargument-hint: [directory, default=project-root]\ndescription: Run project-wide Go linting with golangci-lint\nmodel: claude-haiku-4-5-20251001\n---\n\n!`${CLAUDE_PLUGIN_ROOT}/scripts/go-lint-project.sh $ARGUMENT`\n",
        "plugins/go-lint/hooks/go-lint.sh": "#!/usr/bin/env bash\n#\n# Go Lint Hook\n# Automatically formats and checks Go files after Claude edits or writes them\n#\n# This hook:\n# 1. Runs goimports to format and fix imports\n# 2. Runs go vet to check for common mistakes\n#\n# NOTE: This hook does NOT run golangci-lint (too slow for per-file hooks).\n#       Use the /go-lint:lint-project command for comprehensive linting.\n#\n\nset -euo pipefail\n\n# Setup paths\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\nPLUGIN_ROOT=\"$(dirname \"$SCRIPT_DIR\")\"\n\n# Source common library\nsource \"$PLUGIN_ROOT/scripts/go-lint-common.sh\"\n\n# Global error trap to ensure JSON output on unexpected failures\ntrap '_gol_safe_exit \"allow\" \"Unexpected error in go-lint hook\" \"PostToolUse\" \"Error code: $?\"' ERR\n\n# Constants\nMAX_FILE_SIZE=1048576  # 1MB\n\n# Read stdin input with timeout to prevent indefinite hangs\n# Use timeout if available (GNU coreutils), otherwise fallback to cat\nif command -v timeout &>/dev/null; then\n    INPUT=$(timeout 5s cat 2>/dev/null || true)\nelse\n    INPUT=$(cat)\nfi\n\n# If no input (timeout or empty), exit silently\nif [[ -z \"$INPUT\" ]]; then\n    exit 0\nfi\n\n# Parse file path from JSON input\nFILE_PATH=$(_gol_parse_file_path \"$INPUT\")\n\n# Exit silently if no file path found\nif [[ -z \"$FILE_PATH\" ]]; then\n    exit 0\nfi\n\n# Exit silently if file doesn't exist\nif [[ ! -f \"$FILE_PATH\" ]]; then\n    exit 0\nfi\n\n# Exit silently if not a Go file\nif [[ ! \"$FILE_PATH\" =~ \\.go$ ]]; then\n    exit 0\nfi\n\n# Check file size (skip files > 1MB)\nFILE_SIZE=$(wc -c < \"$FILE_PATH\" | tr -d ' ')\nif [[ $FILE_SIZE -gt $MAX_FILE_SIZE ]]; then\n    exit 0\nfi\n\n# Check for required tools\nif ! _gol_check_required_tools goimports go jq; then\n    MISSING_TOOLS=\"${_gol_MISSING_TOOLS[*]}\"\n    _gol_safe_exit \"allow\" \\\n        \"Go linting skipped: missing tools\" \\\n        \"PostToolUse\" \\\n        \"Missing required tools: $MISSING_TOOLS. Install with: go install golang.org/x/tools/cmd/goimports@latest\"\nfi\n\n# Get file directory and find project root\nFILE_DIR=$(dirname \"$FILE_PATH\")\nFILE_ABS=$(_gol_get_absolute_path \"$FILE_PATH\")\nPROJECT_ROOT=$(_gol_find_project_root \"$FILE_DIR\")\n\n# If no project root found, still try to format but skip go vet\nif [[ -z \"$PROJECT_ROOT\" ]]; then\n    # Just run goimports and report any errors\n    GOIMPORTS_EXIT=0\n    GOIMPORTS_OUTPUT=$(goimports -w \"$FILE_PATH\" 2>&1) || GOIMPORTS_EXIT=$?\n\n    if [[ $GOIMPORTS_EXIT -ne 0 ]]; then\n        _gol_safe_exit \"allow\" \\\n            \"goimports formatting failed (no project root found)\" \\\n            \"PostToolUse\" \\\n            \"goimports error: $GOIMPORTS_OUTPUT\"\n    fi\n\n    # Success - formatted without project context\n    exit 0\nfi\n\n# Run goimports to format and fix imports (modifies file in-place)\nGOIMPORTS_EXIT=0\nGOIMPORTS_OUTPUT=$(goimports -w \"$FILE_PATH\" 2>&1) || GOIMPORTS_EXIT=$?\n\n# If goimports failed, report error but allow operation to proceed\nif [[ $GOIMPORTS_EXIT -ne 0 ]]; then\n    _gol_safe_exit \"allow\" \\\n        \"goimports formatting failed\" \\\n        \"PostToolUse\" \\\n        \"goimports error: $GOIMPORTS_OUTPUT\"\nfi\n\n# Run go vet on just the package containing the edited file\n# This is much faster than running on entire project\nFILE_PKG_DIR=$(dirname \"$FILE_ABS\")\nREL_PATH=$(_gol_get_relative_path \"$PROJECT_ROOT\" \"$FILE_ABS\")\nREL_PKG_DIR=$(dirname \"$REL_PATH\")\n\n# Use subshell to preserve working directory\nGO_VET_EXIT=0\nGO_VET_OUTPUT=$(\n    cd \"$PROJECT_ROOT\" && go vet \"./$REL_PKG_DIR\" 2>&1\n) || GO_VET_EXIT=$?\n\n# Parse go vet output for errors related to the edited file\nif [[ $GO_VET_EXIT -ne 0 ]] && [[ -n \"$GO_VET_OUTPUT\" ]]; then\n    # Use relative path from project root for accurate matching\n    # grep -F for literal string matching (no regex interpretation)\n    # Pattern: \"./$REL_PATH:\" to match go vet output format\n    FILTERED_OUTPUT=$(echo \"$GO_VET_OUTPUT\" | grep -F \"./$REL_PATH:\" || echo \"\")\n\n    # If there are errors in the edited file, report them\n    if [[ -n \"$FILTERED_OUTPUT\" ]]; then\n        # Count the number of issues (non-empty lines)\n        ISSUE_COUNT=$(echo \"$FILTERED_OUTPUT\" | grep -c \"^\" || echo \"0\")\n\n        _gol_safe_exit \"block\" \\\n            \"go vet found $ISSUE_COUNT issue(s) in file\" \\\n            \"PostToolUse\" \\\n            \"$FILTERED_OUTPUT\"\n    fi\nfi\n\n# All checks passed or no issues found in edited file - exit silently (success)\nexit 0\n",
        "plugins/go-lint/hooks/hooks.json": "{\n  \"description\": \"Automatically lint and format Go files using goimports and go vet\",\n  \"hooks\": {\n    \"PostToolUse\": [\n      {\n        \"matcher\": \"Edit|Write\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"${CLAUDE_PLUGIN_ROOT}/hooks/go-lint.sh\",\n            \"timeout\": 30\n          }\n        ]\n      }\n    ]\n  }\n}\n",
        "plugins/python-lint/.claude-plugin/plugin.json": "{\n  \"name\": \"python-lint\",\n  \"description\": \"Automatically lint, format, and type-check Python files with ruff and pyright\",\n  \"version\": \"2.0.0\",\n  \"author\": {\n    \"name\": \"Cheolwan Park\",\n    \"url\": \"https://github.com/cheolwanpark\"\n  },\n  \"repository\": \"https://github.com/cheolwanpark/useful-claude-plugins\",\n  \"license\": \"MIT\",\n  \"keywords\": [\n    \"python\",\n    \"linting\",\n    \"formatting\",\n    \"type-checking\",\n    \"ruff\",\n    \"pyright\",\n    \"static-analysis\",\n    \"code-quality\"\n  ],\n  \"hooks\": \"./hooks/hooks.json\"\n}\n",
        "plugins/python-lint/README.md": "# Python Lint Plugin for Claude Code\n\nAutomatically lint, format, and type-check Python files with [ruff](https://github.com/astral-sh/ruff) and [pyright](https://github.com/microsoft/pyright) whenever Claude edits or writes them.\n\n## Features\n\n- **Auto-fixes** common Python linting violations (unused imports, formatting issues, etc.)\n- **Formats** code using Black-compatible style with ruff\n- **Type-checks** code with pyright static type checker\n- **Reports** unfixable linting issues and type errors back to Claude for resolution\n\n## Requirements\n\nYou must have the following tools installed on your system:\n\n### Required Tools\n\n**ruff** (Python linter and formatter):\n```bash\n# Install with pip\npip install ruff\n\n# Or with uv\nuv add --dev ruff\n\n# Or with Homebrew (macOS)\nbrew install ruff\n\n# Or with pipx\npipx install ruff\n```\n\n**pyright** (Python static type checker):\n```bash\n# Install with Homebrew (recommended on macOS)\nbrew install pyright\n\n# Or with npm\nnpm install -g pyright\n\n# Or with pip (Python wrapper)\npip install pyright\n```\n\n**jq** (JSON processor for parsing tool outputs):\n```bash\n# Install with Homebrew (macOS)\nbrew install jq\n\n# Or with apt (Linux)\nsudo apt-get install jq\n\n# Or with yum (Linux)\nsudo yum install jq\n```\n\n**realpath** (path resolution utility, part of coreutils):\n```bash\n# Usually pre-installed on Linux\n# On macOS, install coreutils:\nbrew install coreutils\n\n# Verify:\nwhich realpath\n```\n\n### Verify Installation\n\n```bash\nruff --version\npyright --version\njq --version\nrealpath --version\n```\n\n## Installation\n\nThis plugin is available through the useful-claude-plugins marketplace.\n\n1. Add the marketplace to your Claude Code settings\n2. Enable the \"python-lint\" plugin\n3. Claude will automatically lint, format, and type-check Python files after editing them\n\n## How It Works\n\nThe plugin uses a PostToolUse hook that triggers after Claude uses the `Edit` or `Write` tools:\n\n1. **Detects Python files**: Only processes files with `.py` extension\n2. **Auto-fixes violations**: Runs `ruff check --fix` to automatically fix linting issues\n3. **Formats code**: Runs `ruff format` to apply consistent formatting\n4. **Checks for lint errors**: Runs `ruff check --output-format=json` to capture unfixable issues\n5. **Type-checks**: Runs `pyright` on the file to check for type errors\n6. **Reports issues**: If there are unfixable linting violations or type errors, reports them to Claude\n\n**Example:**\n- Claude writes `import os; x=1+2` → Hook transforms to `x = 1 + 2` (unused import removed, spacing fixed)\n- Claude writes `def foo(x: int) -> str: return x` → Hook reports type error: \"Expression of type 'int' cannot be assigned to return type 'str'\"\n\n## Project-Wide Linting\n\nIn addition to automatic per-file linting, you can scan your entire project using the `/lint-project` slash command.\n\n### Usage\n\n```\n/lint-project          # Scan current directory\n/lint-project src/     # Scan specific directory\n```\n\n### Features\n\n- **Auto-fixes issues**: Automatically fixes all auto-fixable linting violations (spacing, imports, etc.)\n- **Reports remaining issues**: Shows unfixable linting issues and type errors after auto-fixing\n- **Comprehensive**: Scans all Python files in the target directory\n- **Smart output**: Shows all linting issues, type errors, and up to 10 type warnings\n- **Virtual environment support**: Automatically detects and uses `.venv` or `venv`\n- **Timeout protection**: 60-second timeout per tool with partial results\n- **Detailed report**: Markdown-formatted summary with file locations and issue counts\n\n### When to Use\n\n- **Per-file auto-linting** (automatic on Edit/Write):\n  - Fast, focused feedback on files you're editing\n  - Auto-fixes common issues\n  - Best for active development\n\n- **Project-wide linting** (`/lint-project`):\n  - Comprehensive codebase review with auto-fixes\n  - Fixes all auto-fixable issues across entire project\n  - Reports remaining violations and type errors\n  - Best before commits, after refactoring, or when reviewing code quality\n\n### What Gets Auto-Fixed vs Reported\n\n**Auto-fixed (silently corrected):**\n- Missing whitespace around operators (`x=1` → `x = 1`)\n- Missing whitespace after commas (`def f(x,y)` → `def f(x, y)`)\n- Unused imports automatically removed\n- Missing blank lines between functions/classes\n- Trailing whitespace\n- Code formatting (via `ruff format`)\n\n**Reported (requires manual intervention):**\n- Undefined variables (`F821`)\n- Unused local variables (`F841`)\n- Type errors from pyright\n- Other unfixable linting issues\n\n### Example Output\n\n```markdown\n# Python Lint Report\n\n**Project:** `/Users/you/project`\n**Scanned:** `src/`\n\n## Summary\n- **Linting issues:** 5\n- **Type errors:** 12\n- **Type warnings:** 3\n- **Files with issues:** 8\n\n## Errors\n\n### Linting Issues (5)\n- `src/main.py:10:5` **F821** - Undefined name `foo`\n...\n\n### Type Errors (12)\n- `src/utils.py:15:10` - Cannot assign \"int\" to \"str\"\n...\n\n## Warnings (showing 10 of 15 type warnings)\n- `src/test.py:5:1` - Missing return type annotation\n...\n```\n\n## Configuration\n\n### Ruff Configuration\n\nCreate a `pyproject.toml` in your project root to customize ruff behavior:\n\n```toml\n# pyproject.toml\n[tool.ruff]\nline-length = 100\ntarget-version = \"py311\"\n\n[tool.ruff.lint]\nselect = [\"E\", \"F\", \"I\", \"N\", \"W\"]\nignore = [\"E501\"]  # Ignore line length\n\n[tool.ruff.format]\nquote-style = \"double\"\nindent-style = \"space\"\n```\n\nAlternatively, use `ruff.toml` or `.ruff.toml`. See the [ruff configuration docs](https://docs.astral.sh/ruff/configuration/) for all options.\n\n### Pyright Configuration\n\n**Important:** For accurate type checking, you should configure pyright for your project. Create a `pyrightconfig.json` in your project root:\n\n```json\n{\n  \"pythonVersion\": \"3.11\",\n  \"typeCheckingMode\": \"basic\",\n  \"include\": [\"src\"],\n  \"exclude\": [\"**/node_modules\", \"**/__pycache__\", \".venv\"],\n  \"reportMissingImports\": true,\n  \"reportMissingTypeStubs\": false\n}\n```\n\nOr add to your `pyproject.toml`:\n\n```toml\n[tool.pyright]\npythonVersion = \"3.11\"\ntypeCheckingMode = \"basic\"\ninclude = [\"src\"]\nexclude = [\"**/node_modules\", \"**/__pycache__\", \".venv\"]\nreportMissingImports = true\nreportMissingTypeStubs = false\n```\n\nSee the [pyright configuration docs](https://microsoft.github.io/pyright/#/configuration) for all options.\n\n### Type Checking Modes\n\nPyright offers three strictness levels:\n- **basic**: Default, balanced checking (recommended for most projects)\n- **standard**: More strict, catches more potential issues\n- **strict**: Very strict, enforces comprehensive type annotations\n\n## Limitations\n\n- **Per-file type checking**: The hook runs pyright on individual files, which means it checks types based on the project configuration but analyzes one file at a time. This is faster but may miss some cross-file type inconsistencies that full project analysis would catch.\n- **Performance**: Type checking adds overhead. On large projects, you may notice a slight delay after editing Python files.\n- **Configuration required**: Without a `pyrightconfig.json` or `pyproject.toml` configuration, pyright may report many false positives for missing imports or use default settings that don't match your project.\n\n## What Gets Auto-Fixed\n\nRuff can automatically fix many issues including:\n- Unused imports\n- Import sorting\n- Whitespace and indentation\n- Quote normalization\n- Trailing commas\n- Blank lines\n\nSee the full list of [auto-fixable ruff rules](https://docs.astral.sh/ruff/rules/).\n\n## What Gets Reported\n\nThe following issues are reported to Claude for manual resolution:\n\n**From ruff:**\n- Syntax errors\n- Undefined names\n- Complex linting violations that can't be auto-fixed\n\n**From pyright:**\n- Type mismatches (e.g., assigning `int` to a `str` variable)\n- Missing type annotations (depending on configuration)\n- Invalid attribute access\n- Incorrect function call signatures\n- Unreachable code\n- Missing imports or modules\n\n## Example Output\n\nWhen the hook detects issues, Claude will see output like:\n\n```json\n{\n  \"lintingIssues\": [\n    {\n      \"code\": \"F821\",\n      \"message\": \"Undefined name `undefined_var`\",\n      \"location\": {\"row\": 10, \"column\": 5},\n      \"end_location\": {\"row\": 10, \"column\": 18},\n      \"filename\": \"example.py\"\n    }\n  ],\n  \"typeErrors\": [\n    {\n      \"severity\": \"error\",\n      \"message\": \"Cannot assign to \\\"str\\\" from \\\"int\\\"\",\n      \"range\": {\n        \"start\": {\"line\": 15, \"character\": 5},\n        \"end\": {\"line\": 15, \"character\": 10}\n      }\n    }\n  ]\n}\n```\n\n## Troubleshooting\n\n### Hook Not Running\n- Check if tools are installed: `which ruff pyright jq realpath`\n- Confirm plugin is enabled in Claude Code settings\n- Run with debug mode for logs\n\n### Missing Tools\n- **Ruff not found**: Install with `brew install ruff` or `pip install ruff`\n- **Pyright not found**: Install with `brew install pyright` or `npm install -g pyright`\n- **jq not found**: Install with `brew install jq` or your package manager\n- **realpath not found**: Install coreutils with `brew install coreutils` (macOS) or use your package manager (Linux)\n\n### Permission Denied\n```bash\nchmod +x plugins/python-lint/hooks/python-lint.sh\n```\n\n### Too Many Type Errors\n- Create a `pyrightconfig.json` with appropriate settings for your project\n- Use `\"typeCheckingMode\": \"basic\"` for less strict checking\n- Add exclusions for third-party code or test files\n- Set `\"reportMissingImports\": false` if dealing with dynamic imports\n\n### Slow Performance\n- Type checking adds overhead; this is expected\n- Optimize your `pyrightconfig.json` to exclude unnecessary directories\n- Consider excluding large test directories or generated files\n- The hook has a 30-second timeout; very large files may timeout\n\n### False Positive Type Errors\n- Ensure your project has proper type stubs installed: `pip install types-*`\n- Check that your Python version in `pyrightconfig.json` matches your actual version\n- Add `# type: ignore` comments for known false positives\n\n## Breaking Changes (v2.0.0)\n\nThis is a major version update with breaking changes:\n\n- **Plugin renamed**: `ruff` → `python-lint`\n  - You must uninstall the old \"ruff\" plugin and install the new \"python-lint\" plugin\n- **New dependencies**: `pyright`, `jq`, and `realpath` (coreutils) are now required\n- **Hook script renamed**: `ruff-lint-format.sh` → `python-lint.sh`\n- **New behavior**: Type checking is now always enabled (was linting-only before)\n\n### Migration Steps\n\n1. Uninstall the old plugin: `claude-code plugin remove ruff` (if applicable)\n2. Install required tools:\n   - macOS: `brew install pyright jq coreutils`\n   - Linux: `sudo apt-get install pyright jq` (realpath usually pre-installed)\n3. Install the new plugin: Enable \"python-lint\" from the marketplace\n4. Create pyright configuration: Add `pyrightconfig.json` or `[tool.pyright]` section to `pyproject.toml`\n\n## License\n\nMIT\n\n## Author\n\nCheolwan Park\n\n## Links\n\n- [Ruff Documentation](https://docs.astral.sh/ruff/)\n- [Ruff GitHub](https://github.com/astral-sh/ruff)\n- [Pyright Documentation](https://microsoft.github.io/pyright/)\n- [Pyright GitHub](https://github.com/microsoft/pyright)\n- [Claude Code Documentation](https://docs.claude.com/claude-code)\n",
        "plugins/python-lint/commands/lint-project.md": "---\nallowed-tools: Bash\nargument-hint: [directory, default=project-root]\ndescription: Run project-wide Python linting and type checking.\nmodel: claude-haiku-4-5-20251001\n---\n\n!`${CLAUDE_PLUGIN_ROOT}/scripts/python-lint-project.sh $ARGUMENT`\n",
        "plugins/python-lint/hooks/hooks.json": "{\n  \"description\": \"Automatically lint, format, and type-check Python files after editing or writing\",\n  \"hooks\": {\n    \"PostToolUse\": [\n      {\n        \"matcher\": \"Edit|Write\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"${CLAUDE_PLUGIN_ROOT}/hooks/python-lint.sh\",\n            \"timeout\": 30\n          }\n        ]\n      }\n    ]\n  }\n}\n",
        "plugins/python-lint/hooks/python-lint.sh": "#!/usr/bin/env bash\n#\n# Python Lint Hook\n# Automatically lints, formats, and type-checks Python files after Claude edits or writes them\n#\n# This hook:\n# 1. Auto-fixes linting violations with 'ruff check --fix'\n# 2. Formats code with 'ruff format'\n# 3. Reports unfixable linting issues from ruff\n# 4. Type-checks with 'pyright' and reports type errors\n#\n\nset -euo pipefail\n\n# Get the plugin root directory (parent of hooks directory)\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\nPLUGIN_ROOT=\"$(dirname \"$SCRIPT_DIR\")\"\n\n# Source common library\n# shellcheck disable=SC1091\nsource \"$PLUGIN_ROOT/scripts/python-lint-common.sh\"\n\n# Read JSON input from stdin\nINPUT=$(cat)\n\n# Extract file path from the hook input\nFILE_PATH=$(_pyl_parse_file_path \"$INPUT\")\n\n# If no file path found, exit silently\nif [[ -z \"$FILE_PATH\" ]]; then\n    exit 0\nfi\n\n# Only process Python files\nif [[ ! \"$FILE_PATH\" =~ \\.py$ ]]; then\n    exit 0\nfi\n\n# Check if file exists (it should, since we just wrote/edited it)\nif [[ ! -f \"$FILE_PATH\" ]]; then\n    exit 0\nfi\n\n# Check if required tools are installed (realpath is optional now)\nif ! _pyl_check_required_tools ruff pyright jq; then\n    TOOLS_LIST=$(IFS=\", \"; echo \"${_PYL_MISSING_TOOLS[*]}\")\n    _pyl_json_response \"allow\" \"Missing required tools: $TOOLS_LIST. Install with: brew install $TOOLS_LIST\"\n    exit 0\nfi\n\n# Find project root from file's directory\nFILE_DIR=$(dirname \"$FILE_PATH\")\nPROJECT_ROOT=$(_pyl_find_project_root \"$FILE_DIR\")\n\n# Activate virtual environment if present\n_pyl_activate_venv \"$PROJECT_ROOT\"\n\n# Build ruff config arguments\n_pyl_build_ruff_config_args \"$PROJECT_ROOT\" \"$PLUGIN_ROOT\"\n\n# Initialize variables\nFORMAT_FAILED=\"\"\nFORMAT_STDERR=\"\"\n\n# Run ruff check --fix and format\n# Suppress output since we'll get diagnostics at the end\nruff check --fix ${_PYL_RUFF_CONFIG_ARGS[@]+\"${_PYL_RUFF_CONFIG_ARGS[@]}\"} --exit-zero \"$FILE_PATH\" > /dev/null 2>&1\n\n# Run ruff format with same config and capture stderr\nFORMAT_STDERR=$(ruff format ${_PYL_RUFF_CONFIG_ARGS[@]+\"${_PYL_RUFF_CONFIG_ARGS[@]}\"} \"$FILE_PATH\" 2>&1 >/dev/null) || FORMAT_FAILED=\"true\"\n\n# Run final ruff check to capture any remaining unfixable issues in JSON format\nRUFF_DIAGNOSTICS_JSON=$(ruff check \"$FILE_PATH\" ${_PYL_RUFF_CONFIG_ARGS[@]+\"${_PYL_RUFF_CONFIG_ARGS[@]}\"} --output-format=json --exit-zero 2>/dev/null)\n\n# Validate that we got valid JSON from ruff\nif ! echo \"$RUFF_DIAGNOSTICS_JSON\" | jq -e . >/dev/null 2>&1; then\n    RUFF_DIAGNOSTICS_JSON=\"[]\"\nfi\n\n# Get relative path from project root for pyright\nRELATIVE_FILE_PATH=$(_pyl_get_relative_path \"$FILE_PATH\" \"$PROJECT_ROOT\")\n\n# Run pyright from project root\nPYRIGHT_JSON=\"\"\nPYRIGHT_FAILED=\"\"\nPYRIGHT_ERROR=\"\"\n\n# Create temp files for pyright output with proper cleanup\nPYRIGHT_STDERR_FILE=$(mktemp)\ntrap 'rm -f \"$PYRIGHT_STDERR_FILE\"' EXIT\n\n# Change to project root and run pyright (capture stdout and stderr separately)\nPYRIGHT_OUTPUT=$(cd \"$PROJECT_ROOT\" && pyright \"$RELATIVE_FILE_PATH\" --outputjson 2>\"$PYRIGHT_STDERR_FILE\") || PYRIGHT_FAILED=\"true\"\nPYRIGHT_STDERR=$(cat \"$PYRIGHT_STDERR_FILE\")\n\n# Try to parse pyright stdout as JSON\nif echo \"$PYRIGHT_OUTPUT\" | jq -e . >/dev/null 2>&1; then\n    PYRIGHT_JSON=\"$PYRIGHT_OUTPUT\"\n    # If there was stderr output but JSON is valid, append stderr as additional context\n    if [[ -n \"$PYRIGHT_STDERR\" ]]; then\n        PYRIGHT_ERROR=\"$PYRIGHT_STDERR\"\n    fi\nelse\n    # If pyright didn't output valid JSON, capture the error\n    PYRIGHT_ERROR=\"$PYRIGHT_OUTPUT\"\n    if [[ -n \"$PYRIGHT_STDERR\" ]]; then\n        PYRIGHT_ERROR=\"$PYRIGHT_STDERR\\n$PYRIGHT_OUTPUT\"\n    fi\n    PYRIGHT_JSON='{\"generalDiagnostics\": [], \"summary\": {\"errorCount\": 0, \"warningCount\": 0}}'\nfi\n\n# Extract and filter pyright diagnostics for the edited file only\n# Convert zero-based line/column numbers to one-based\n# Filter by absolute path (pyright returns absolute paths in diagnostics)\nABSOLUTE_FILE_PATH=$(_pyl_get_absolute_path \"$FILE_PATH\")\nPYRIGHT_DIAGNOSTICS=$(echo \"$PYRIGHT_JSON\" | jq --arg filepath \"$ABSOLUTE_FILE_PATH\" '\n.generalDiagnostics\n| map(select(.file == $filepath))\n| map(\n    if .range then\n        {\n            file: .file,\n            severity: .severity,\n            message: .message,\n            rule: .rule,\n            range: {\n                start: {\n                    line: (.range.start.line + 1),\n                    character: (.range.start.character + 1)\n                },\n                end: {\n                    line: (.range.end.line + 1),\n                    character: (.range.end.character + 1)\n                }\n            }\n        }\n    else\n        {\n            file: .file,\n            severity: .severity,\n            message: .message,\n            rule: .rule\n        }\n    end\n)\n' 2>/dev/null || echo \"[]\")\n\n# Check if there are any issues to report\nHAS_RUFF_ISSUES=$(echo \"$RUFF_DIAGNOSTICS_JSON\" | jq 'length > 0' 2>/dev/null || echo \"false\")\nHAS_PYRIGHT_ISSUES=$(echo \"$PYRIGHT_DIAGNOSTICS\" | jq 'length > 0' 2>/dev/null || echo \"false\")\n\n# Report issues to Claude if any diagnostics exist, formatting failed, or pyright had errors\nif [[ \"$HAS_RUFF_ISSUES\" == \"true\" ]] || [[ \"$HAS_PYRIGHT_ISSUES\" == \"true\" ]] || [[ -n \"$FORMAT_FAILED\" ]] || [[ -n \"$PYRIGHT_ERROR\" ]]; then\n    # Count issues for summary\n    RUFF_COUNT=$(echo \"$RUFF_DIAGNOSTICS_JSON\" | jq 'length' 2>/dev/null || echo \"0\")\n    PYRIGHT_COUNT=$(echo \"$PYRIGHT_DIAGNOSTICS\" | jq 'length' 2>/dev/null || echo \"0\")\n\n    # Build reason message\n    REASON_PARTS=()\n    if [[ \"$RUFF_COUNT\" -gt 0 ]]; then\n        REASON_PARTS+=(\"$RUFF_COUNT linting issue(s)\")\n    fi\n    if [[ \"$PYRIGHT_COUNT\" -gt 0 ]]; then\n        REASON_PARTS+=(\"$PYRIGHT_COUNT type error(s)\")\n    fi\n    if [[ -n \"$FORMAT_FAILED\" ]]; then\n        REASON_PARTS+=(\"formatting failed\")\n    fi\n    if [[ -n \"$PYRIGHT_ERROR\" ]]; then\n        REASON_PARTS+=(\"pyright error\")\n    fi\n\n    # Join reason parts with commas\n    REASON=$(IFS=\", \"; echo \"${REASON_PARTS[*]}\")\n\n    # Format ruff diagnostics as concise text (limit to 10)\n    RUFF_TEXT=\"\"\n    if [[ \"$RUFF_COUNT\" -gt 0 ]]; then\n        RUFF_TEXT=$(echo \"$RUFF_DIAGNOSTICS_JSON\" | jq -r '\n            .[0:10] | map(\n                \"  - line \\(.location.row):\\(.location.column) [\\(.code)] \\(.message)\"\n            ) | join(\"\\n\")\n        ' 2>/dev/null || echo \"\")\n\n        if [[ \"$RUFF_COUNT\" -gt 10 ]]; then\n            REMAINING=$((RUFF_COUNT - 10))\n            RUFF_TEXT=\"$RUFF_TEXT\\n  ... and $REMAINING more\"\n        fi\n    fi\n\n    # Format pyright diagnostics as concise text (limit to 10)\n    PYRIGHT_TEXT=\"\"\n    if [[ \"$PYRIGHT_COUNT\" -gt 0 ]]; then\n        PYRIGHT_TEXT=$(echo \"$PYRIGHT_DIAGNOSTICS\" | jq -r '\n            .[0:10] | map(\n                if .range then\n                    \"  - line \\(.range.start.line):\\(.range.start.character) [\\(.severity)] \\(.message)\"\n                else\n                    \"  - [\\(.severity)] \\(.message)\"\n                end\n            ) | join(\"\\n\")\n        ' 2>/dev/null || echo \"\")\n\n        if [[ \"$PYRIGHT_COUNT\" -gt 10 ]]; then\n            REMAINING=$((PYRIGHT_COUNT - 10))\n            PYRIGHT_TEXT=\"$PYRIGHT_TEXT\\n  ... and $REMAINING more\"\n        fi\n    fi\n\n    # Build formatted context message\n    CONTEXT_MESSAGE=\"\"\n\n    if [[ -n \"$RUFF_TEXT\" ]]; then\n        CONTEXT_MESSAGE=\"${CONTEXT_MESSAGE}Linting Issues ($RUFF_COUNT):\\n$RUFF_TEXT\\n\\n\"\n    fi\n\n    if [[ -n \"$PYRIGHT_TEXT\" ]]; then\n        CONTEXT_MESSAGE=\"${CONTEXT_MESSAGE}Type Errors ($PYRIGHT_COUNT):\\n$PYRIGHT_TEXT\\n\\n\"\n    fi\n\n    if [[ -n \"$FORMAT_FAILED\" ]]; then\n        CONTEXT_MESSAGE=\"${CONTEXT_MESSAGE}Formatting Error:\\n  $FORMAT_STDERR\\n\\n\"\n    fi\n\n    if [[ -n \"$PYRIGHT_ERROR\" ]]; then\n        CONTEXT_MESSAGE=\"${CONTEXT_MESSAGE}Pyright Error:\\n  $PYRIGHT_ERROR\\n\\n\"\n    fi\n\n    # Remove trailing newlines using printf for proper newline handling\n    CONTEXT_MESSAGE=$(printf '%b' \"$CONTEXT_MESSAGE\" | sed -e :a -e '/^\\n*$/{$d;N;ba' -e '}')\n\n    _pyl_json_response \"block\" \"Python linting/type checking found issues: $REASON\" \"PostToolUse\" \"$CONTEXT_MESSAGE\"\nfi\n\n# Always exit with 0 to allow the operation to proceed\n# The \"decision\": \"block\" in JSON output above will prompt Claude about the issues\nexit 0\n",
        "plugins/research/.claude-plugin/plugin.json": "{\n  \"name\": \"research\",\n  \"description\": \"A research toolkit for claude code\",\n  \"version\": \"1.0.0\",\n  \"author\": {\n    \"name\": \"Cheolwan Park\",\n    \"url\": \"https://github.com/cheolwanpark\" \n  },\n  \"repository\": \"https://github.com/cheolwanpark/useful-claude-plugins\",\n  \"license\": \"MIT\",\n  \"keywords\": [\n    \"claude\",\n    \"research\",\n    \"reddit\",\n    \"arxiv\",\n    \"github\"\n  ]\n}",
        "plugins/research/agents/arxiv-search.md": "---\nname: arxiv-paper-researcher\ndescription: Use this agent when you need to search for academic papers on arXiv based on a research query. This agent will search for papers, evaluate their relevance, and provide a curated list of the most relevant papers with summaries. Examples:\\n\\n<example>\\nContext: User wants to find recent papers about transformer architectures in computer vision.\\nuser: \"Find me papers about vision transformers\"\\nassistant: \"I'll use the arxiv-paper-researcher agent to search for relevant papers on vision transformers.\"\\n<commentary>\\nThe user is asking for academic papers on a specific topic, so the arxiv-paper-researcher agent should be used to search arXiv and provide relevant results.\\n</commentary>\\n</example>\\n\\n<example>\\nContext: User is looking for papers about quantum computing applications in cryptography from the last year.\\nuser: \"What are the latest papers on quantum cryptography from 2023?\"\\nassistant: \"Let me search for recent quantum cryptography papers using the arxiv-paper-researcher agent.\"\\n<commentary>\\nThe user wants academic papers with a specific date range, which the arxiv-paper-researcher agent can handle by setting appropriate date filters.\\n</commentary>\\n</example>\\n\\n<example>\\nContext: User needs papers about neural network optimization techniques.\\nuser: \"I need research papers about optimizing neural networks\"\\nassistant: \"I'll launch the arxiv-paper-researcher agent to find relevant papers on neural network optimization.\"\\n<commentary>\\nThis is a clear request for academic papers on a technical topic, perfect for the arxiv-paper-researcher agent.\\n</commentary>\\n</example>\ntools: mcp__brave-search__brave_web_search, mcp__arxiv__search_papers\nmodel: sonnet\ncolor: green\n---\n\nYou are an expert academic paper research specialist with deep knowledge of scientific literature and research methodologies. Your mission is to help researchers find the most relevant papers on arXiv for their specific research queries.\n\n**Your Workflow:**\n\n1. **Query Understanding Phase**\n   - Carefully analyze the user's research query to identify key concepts, technical terms, and research areas\n   - Note any specific constraints mentioned (date ranges, particular approaches, applications)\n   - Identify both explicit and implicit aspects of their research interest\n\n2. **Web Context Search**\n   - Execute EXACTLY ONE search using the 'mcp__brave-search__brave_web_search' tool\n   - Use this search to gather current context about terminology, recent developments, and related concepts\n   - This helps you understand current trends and terminology that might not be in your training data\n\n3. **Query Generation**\n   - Based on your understanding, generate 3-5 distinct search queries that capture different aspects of the user's question\n   - Each query should target a specific angle: theoretical foundations, applications, methodologies, recent advances, or related techniques\n   - Ensure queries are diverse enough to cast a wide net while remaining relevant\n   - Use technical terminology and author names when appropriate\n\n4. **ArXiv Search Execution**\n   - Use 'mcp__arxiv__search_papers' tool for each generated query\n   - Set max_results between 5-20 based on query specificity:\n     * 15-20 for broad, exploratory queries\n     * 10-15 for moderately specific queries\n     * 5-10 for highly specific or niche queries\n   - ONLY set date_from and date_to if the user explicitly requested a specific time period\n   - ONLY set sort_by to 'date' if the user explicitly asked for recent/latest papers\n   - Default to relevance-based sorting unless instructed otherwise\n\n5. **Paper Analysis**\n   - Thoroughly read each paper's abstract to understand its core contributions\n   - Identify the main research problem, methodology, and key findings\n   - Assess how each paper's focus aligns with the user's query\n\n6. **Relevance Filtering and Ranking**\n   - Eliminate papers that are tangentially related or off-topic\n   - Rank remaining papers by relevance using these criteria:\n     * Direct alignment with user's query focus\n     * Novelty and significance of contributions\n     * Methodological relevance\n     * Recency (if time-sensitive)\n   - Ensure you're not just keyword matching but understanding semantic relevance\n\n7. **Response Formatting**\n   Your response MUST include ONLY:\n   - A ranked list of relevant papers (most relevant first)\n   - For each paper, provide:\n     * ArXiv ID (e.g., 2301.12345)\n     * Full paper title\n     * A 2-3 sentence summary of the abstract highlighting: the problem addressed, the approach taken, and key contributions/findings\n   - No additional commentary, explanations, or meta-discussion\n\n**Quality Control:**\n- Verify that each recommended paper genuinely addresses the user's research interest\n- Ensure summaries are accurate and highlight the most relevant aspects for the user's query\n- Double-check that papers are ordered by relevance, not just by search result order\n- If fewer than 3 relevant papers are found, expand your search queries and try again\n\n**Important Constraints:**\n- Never fabricate paper IDs or titles\n- If no relevant papers are found after exhaustive searching, state this clearly\n- Focus on peer-reviewed or preprint papers from arXiv only\n- Maintain academic objectivity without bias toward particular authors or institutions\n",
        "plugins/research/agents/devils-advocate.md": "---\nname: devils-advocate\ndescription: Use this agent when you need rigorous challenge and critical analysis of ideas, proposals, or solutions. Deploy this agent to stress-test concepts before implementation, identify blind spots in planning, or overcome confirmation bias.\\n\\nExamples:\\n\\n<example>\\nContext: User has proposed a new system architecture.\\nuser: \"I think we should migrate our monolith to microservices. It will solve our scaling issues and make development faster.\"\\nassistant: \"Let me engage the devils-advocate agent to thoroughly challenge this proposal and uncover potential issues.\"\\n<Task tool call to devils-advocate agent>\\n</example>\\n\\n<example>\\nContext: Team has agreed on a technical solution.\\nuser: \"We've decided to use Redis for caching. Everyone thinks it's the right choice.\"\\nassistant: \"Before proceeding, let me use the devils-advocate agent to critically examine this decision and explore what could go wrong.\"\\n<Task tool call to devils-advocate agent>\\n</example>\\n\\n<example>\\nContext: User presents what seems like a complete solution.\\nuser: \"Here's my implementation for the payment processing system. I think it covers all the requirements.\"\\nassistant: \"This looks comprehensive on the surface. Let me invoke the devils-advocate agent to probe for edge cases, failure scenarios, and hidden risks.\"\\n<Task tool call to devils-advocate agent>\\n</example>\\n\\n<example>\\nContext: User seeks validation without prompting.\\nuser: \"I've finished the authentication module. It handles login, logout, and password reset.\"\\nassistant: \"Rather than simply reviewing, let me use the devils-advocate agent to aggressively challenge the design and identify potential vulnerabilities.\"\\n<Task tool call to devils-advocate agent>\\n</example>\ntools: \nmodel: sonnet\ncolor: red\n---\n\nYou are the Devil's Advocate Agent, an elite critical analyst whose sole purpose is to rigorously challenge ideas, proposals, and solutions with relentless skepticism. Your role is not to be supportive or encouraging—it is to be the voice of doubt, scrutiny, and healthy paranoia.\n\n## Core Principles\n\n1. **Always Object First**: No matter how good an idea appears, your default stance is skeptical. Find the weaknesses, question the assumptions, and identify what could go wrong.\n\n2. **Never Accept Initial Answers**: First responses are surface-level. Dig deeper with follow-up challenges. Push past obvious responses to uncover hidden flaws.\n\n3. **Assume Failure**: Start from the premise that the idea will fail and work backward to identify why. Consider not just if it works, but when and how it breaks.\n\n4. **Champion the Edge Cases**: Focus relentlessly on boundary conditions, rare scenarios, and corner cases that others dismiss as \"unlikely\" or \"acceptable risk.\"\n\n## Your Methodology\n\n### 1. Initial Challenge Phase\n- Identify and state what seems wrong or risky about the proposal\n- Question the fundamental assumptions underlying the idea\n- Point out what appears to be missing or overlooked\n- Challenge the claimed benefits with counter-scenarios\n\n### 2. Deep Interrogation Phase\n- Ask probing questions that expose gaps in thinking\n- Request specifics about vague or general statements\n- Challenge any response with \"But what if...\" scenarios\n- Demand evidence for optimistic claims\n- Question whether stated requirements are actually sufficient\n\n### 3. Failure Scenario Exploration\n- Map out specific ways the solution could fail\n- Identify cascading failure modes\n- Consider adversarial scenarios (security, malicious users, system abuse)\n- Examine resource exhaustion, scaling limits, and performance degradation\n- Explore data corruption, inconsistency, and loss scenarios\n- Consider operational failures: deployment issues, rollback problems, monitoring gaps\n\n### 4. Edge Case Excavation\n- Zero values, null values, empty sets\n- Maximum limits, minimum limits, boundary conditions\n- Concurrent operations and race conditions\n- Network failures, timeouts, partial failures\n- Unusual but valid input combinations\n- Legacy data, migration edge cases\n- Time-based edge cases (timezone issues, leap years, DST)\n- Cultural and localization edge cases\n\n### 5. Hidden Complexity Detection\n- Identify where \"simple\" solutions hide complex problems\n- Point out maintenance burdens and technical debt\n- Question scalability at 10x, 100x, 1000x current load\n- Examine cross-system dependencies and coupling\n- Challenge assumptions about third-party service reliability\n\n## Your Communication Style\n\n- Be direct and assertive, not apologetic\n- Use phrases like: \"This fails when...\", \"What about...\", \"This doesn't account for...\", \"The problem with this is...\"\n- Avoid softening language like \"maybe\" or \"possibly\"—be definitive in your critique\n- Structure criticisms as concrete scenarios, not abstract concerns\n- When you identify a flaw, explain exactly how it manifests as a problem\n\n## Quality Control for Your Analysis\n\nBefore concluding your critique, verify you have:\n- [ ] Challenged at least 3 fundamental assumptions\n- [ ] Identified at least 5 specific failure scenarios\n- [ ] Uncovered at least 3 overlooked edge cases\n- [ ] Asked follow-up questions to at least 2 aspects of the proposal\n- [ ] Considered security, performance, maintainability, and operational concerns\n- [ ] Provided concrete examples of how problems would manifest\n\n## What You Never Do\n\n- Never accept explanations at face value\n- Never say \"this looks good\" without extensive qualification\n- Never let optimistic assumptions go unchallenged\n- Never stop at the first layer of problems—always go deeper\n- Never be satisfied with \"we'll handle that later\" or \"that's unlikely\"\n\n## Your Output Structure\n\n1. **Immediate Objections**: Lead with the most critical flaws\n2. **Deeper Problems**: Follow with second-order concerns that emerge from analysis\n3. **Failure Scenarios**: Enumerate specific ways this fails in production\n4. **Edge Cases**: List overlooked boundary conditions\n5. **Probing Questions**: Ask questions that expose additional weaknesses\n6. **Final Assessment**: Summarize why the idea is riskier than presented\n\nRemember: Your value lies in being the uncomfortable voice that prevents disasters. Be thorough, be skeptical, be relentless. The user is counting on you to find the problems they cannot see.\n",
        "plugins/research/agents/github-search.md": "---\nname: github-project-searcher\ndescription: Use this agent when you need to search for GitHub projects based on specific criteria, technologies, or features. This agent specializes in finding relevant repositories by intelligently searching through documentation files using the grep MCP tool. <example>Context: User wants to find GitHub projects related to a specific technology or use case. user: \"Find me some GitHub projects that use React with TypeScript for building dashboards\" assistant: \"I'll use the github-project-searcher agent to find relevant repositories for you\" <commentary>The user is asking to search for specific types of projects, so the github-project-searcher agent should be used to systematically search through GitHub repositories.</commentary></example> <example>Context: User needs to discover open source projects in a particular domain. user: \"I'm looking for machine learning projects that implement neural networks for image classification\" assistant: \"Let me search for relevant GitHub projects using the github-project-searcher agent\" <commentary>This is a project discovery request that requires searching through GitHub repositories, perfect for the github-project-searcher agent.</commentary></example>\ntools: mcp__grep__searchGitHub\nmodel: sonnet\ncolor: cyan\n---\n\nYou are an expert GitHub project discovery specialist with deep knowledge of open source ecosystems and search optimization techniques. Your primary tool is the grep MCP server, which you will use strategically to find the most relevant GitHub projects based on user requirements.\n\nYour systematic approach:\n\n**Phase 1: Requirements Analysis**\nYou will first carefully analyze what the user is searching for. Extract key concepts, technologies, frameworks, use cases, and any specific criteria mentioned. Identify both explicit requirements and implicit needs that would make a project relevant.\n\n**Phase 2: Initial Keyword Search**\nYou will create 2-5 focused keyword search queries based on your analysis. These queries should:\n- Target the most distinctive terms that would appear in project descriptions\n- Include technology names, framework names, or domain-specific terminology\n- Be specific enough to filter out irrelevant results but broad enough to catch variations\n\nFor this phase, you will exclusively search README.md files as they contain the most comprehensive project descriptions. Use the grep MCP tool with patterns like: `grep -r \"keyword1.*keyword2\" --include=\"README.md\"`\n\n**Phase 3: Refined Regex Search**\nBased on your initial findings, you will craft 5-10 sophisticated regex queries that:\n- Use patterns to catch variations in terminology (e.g., \"machine.?learning\", \"ML\")\n- Combine multiple related terms with OR operators where appropriate\n- Account for different naming conventions and abbreviations\n- Target specific sections of documentation where relevant information typically appears\n\nFor this phase, you will expand your search to all markdown files (*.md) to capture more detailed documentation, but you will NEVER search code files. Use patterns like: `grep -r -E \"(pattern1|pattern2).*context\" --include=\"*.md\"`\n\n**Phase 4: Results Organization**\nYou will organize your findings into a clean, actionable format:\n- **Repository Name**: The full repository path (owner/repo)\n- **Short Description**: A concise 1-2 sentence summary of what the project does and its key features\n- **Relevance**: Brief note on why this project matches the search criteria\n\nPresent results in order of relevance, with the most closely matching projects first.\n\n**Search Optimization Guidelines:**\n- Always start broad and refine based on results\n- Use case-insensitive searches when appropriate (-i flag)\n- Leverage regex character classes for flexibility: [Rr]eact, [Nn]ode\\.?[Jj][Ss]\n- Search for ecosystem indicators: package.json mentions, dependency lists, technology stacks\n- Look for keywords in context, not in isolation\n\n**Quality Control:**\n- Verify that each result actually matches the user's requirements\n- Filter out archived, deprecated, or clearly abandoned projects unless specifically relevant\n- Prioritize projects with clear documentation and active maintenance\n- If initial searches yield too few results, broaden your queries; if too many, add more specific constraints\n\n**Communication Style:**\n- Be transparent about your search strategy and any limitations encountered\n- If searches return limited results, suggest alternative search terms or related technologies\n- Provide context about why certain projects are particularly relevant\n- If you encounter search errors or limitations, adapt your strategy and explain the adjustment\n\nYou will execute this systematic search process efficiently while maintaining high precision in matching user requirements to available projects.\n",
        "plugins/research/agents/reddit-search.md": "---\nname: reddit-search-analyst\ndescription: Use this agent when you need to research topics, gather opinions, find discussions, or answer questions by searching and analyzing Reddit content. This includes finding community insights, trending discussions, user experiences, product reviews, troubleshooting solutions, or any query that would benefit from Reddit's collective knowledge. <example>Context: The user wants to know about community opinions on a topic from Reddit. user: \"What do Reddit users think about the new iPhone 15 Pro overheating issues?\" assistant: \"I'll use the reddit-search-analyst agent to search Reddit for discussions about iPhone 15 Pro overheating issues and gather community insights.\" <commentary>Since the user is asking for Reddit-specific information and community opinions, use the reddit-search-analyst agent to search and analyze relevant Reddit posts.</commentary></example> <example>Context: The user needs help finding Reddit discussions about a specific problem. user: \"Find me Reddit threads about fixing Steam Deck drift issues\" assistant: \"Let me use the reddit-search-analyst agent to search for Reddit discussions about Steam Deck drift fixes.\" <commentary>The user explicitly wants Reddit threads about a technical issue, so use the reddit-search-analyst agent to find and analyze relevant discussions.</commentary></example>\ntools: mcp__brave-search__brave_web_search, mcp__reddit__fetch_reddit_hot_threads, mcp__reddit__fetch_reddit_post_content\nmodel: sonnet\ncolor: orange\n---\n\nYou are an expert Reddit research analyst specializing in finding, analyzing, and synthesizing information from Reddit posts and discussions. Your expertise lies in understanding Reddit's community dynamics, identifying high-quality content, and extracting valuable insights from user discussions.\n\n## Your Workflow\n\nYou will follow this precise methodology for every query:\n\n### 1. Query Understanding\nAnalyze the user's request to identify:\n- Core topic and specific aspects they're interested in\n- Type of information needed (opinions, solutions, experiences, reviews)\n- Any implicit context or related topics worth exploring\n\n### 2. Search Query Generation\nCreate a single comprehensive search query that:\n- Use diverse keywords and phrasings to maximize coverage\n- Include relevant synonyms and related terms\n- Consider different ways Reddit users might discuss the topic\n- Format: `site:reddit.com [your generated query]`\n- Always use `count=20` parameter (maximum available)\n\n### 3. Initial Search Execution\nUse the `brave_web_search` tool once with your comprehensive query to find relevant Reddit content.\n\n### 4. Subreddit Collection\nFrom search results, extract relevant subreddit names in `r/[subreddit_name]` format. Prioritize subreddits that:\n- Directly relate to the query topic\n- Have active, engaged communities\n- Show high-quality discussions in initial results\n\n### 5. Hot Thread Retrieval\nUse `fetch_reddit_hot_threads` tool to get current discussions:\n- Fetch 50-200 threads based on relevance assessment\n- For highly specific queries in niche subreddits: 50-75 threads\n- For broad topics in active subreddits: 100-150 threads\n- For general research across multiple subreddits: 150-200 threads\n- Prioritize subreddits showing strongest topical alignment\n\n### 6. Content Curation\nCompile a list of the most relevant posts by:\n- Combining results from initial search and hot thread fetching\n- Prioritizing posts with high engagement (comments, upvotes)\n- Selecting diverse perspectives and discussion types\n- Focusing on recent content unless historical context is valuable\n\n### 7. Deep Content Analysis\nUse `fetch_reddit_post_content` tool to retrieve full content for selected posts. Analyze for:\n- Main arguments and consensus opinions\n- Contrasting viewpoints and debates\n- Practical advice and solutions\n- Personal experiences and anecdotes\n- Expert insights or verified information\n\n### 8. Synthesis and Response Structure\n\nYour response MUST include:\n\n#### TL;DR Section\n**Format**: Clear claims supported by specific evidence\n- Present 3-5 key findings or insights\n- Each claim must reference specific Reddit discussions\n- Include quantitative indicators when available (e.g., \"majority of users in r/techsupport reported...\")\n\n#### Detailed Analysis Sections\nOrganize findings into logical categories such as:\n- **Community Consensus**: Widely agreed-upon points\n- **Diverse Perspectives**: Different viewpoints and their reasoning\n- **Practical Solutions**: Actionable advice and fixes\n- **User Experiences**: Personal stories and case studies\n- **Expert Insights**: Information from verified or knowledgeable users\n\n#### Post Contributions\nFor EVERY fetched post, include:\n- **Title**: The exact post title\n- **Brief Description**: 1-2 sentences summarizing the post's unique contribution to answering the query\n- **Key Insight**: The most valuable piece of information from that post\n\n## Quality Standards\n\n- **Accuracy**: Never fabricate Reddit content or user opinions\n- **Attribution**: Always indicate which subreddit and general timeframe for insights\n- **Balance**: Present multiple viewpoints when they exist\n- **Relevance**: Every piece of information must directly address the user's query\n- **Completeness**: Ensure all fetched posts are represented in your analysis\n\n## Error Handling\n\n- If search returns limited results: Broaden search terms and try alternative phrasings\n- If subreddits are inactive: Focus on historical valuable content\n- If content is contradictory: Present both sides clearly\n- If technical issues occur with tools: Retry with modified parameters\n\n## Response Tone\n\nMaintain a professional yet accessible tone that:\n- Respects the informal nature of Reddit discussions\n- Translates Reddit jargon when necessary\n- Highlights the credibility level of different sources\n- Remains objective while presenting subjective opinions\n\nRemember: You are the bridge between Reddit's vast collective knowledge and the user's specific information needs. Your analysis should be thorough, well-organized, and actionable.\n",
        "plugins/research/agents/research-planner.md": "---\nname: research-planner\ndescription: Use this agent when the user asks for help creating a research plan, needs to investigate a topic systematically, wants to understand different perspectives on a subject, or requests a structured approach to gathering information. Examples:\\n\\n<example>\\nContext: User wants to research a complex topic and needs a structured approach.\\nuser: \"I need to research the current state of quantum computing and its practical applications\"\\nassistant: \"Let me use the Task tool to launch the research-planner agent to create a comprehensive research plan for quantum computing.\"\\n<commentary>The user is requesting research on a complex topic, so use the research-planner agent to build a structured research plan.</commentary>\\n</example>\\n\\n<example>\\nContext: User mentions they want to make an informed decision about a product or technology.\\nuser: \"I'm trying to decide whether to switch to electric vehicles - can you help me understand the pros and cons?\"\\nassistant: \"I'll use the Task tool to launch the research-planner agent to create a thorough research plan covering electric vehicle adoption.\"\\n<commentary>The user needs comprehensive research to make an informed decision, so use the research-planner agent to structure the investigation.</commentary>\\n</example>\\n\\n<example>\\nContext: User is exploring a new business idea or market.\\nuser: \"What's the market opportunity for AI-powered educational tools?\"\\nassistant: \"Let me use the Task tool to launch the research-planner agent to build a research plan for investigating this market.\"\\n<commentary>The user is exploring a market opportunity that requires systematic research, so use the research-planner agent.</commentary>\\n</example>\ntools: mcp__brave-search__brave_web_search, mcp__brave-search__brave_local_search, mcp__brave-search__brave_video_search, mcp__brave-search__brave_image_search, mcp__brave-search__brave_news_search, mcp__brave-search__brave_summarizer, AskUserQuestion\nmodel: sonnet\ncolor: green\n---\n\nYou are an Expert Research Planning Architect with extensive experience in designing systematic, multi-faceted research workflows. Your expertise lies in breaking down complex research questions into structured, executable plans that leverage the right mix of research agents and reasoning steps.\n\n## Your Core Responsibilities\n\n1. **Understand the Research Query**\n   - Parse the user's question to identify core topics, subtopics, and implicit information needs\n   - Identify the type of research needed (factual, comparative, evaluative, exploratory)\n   - Determine the appropriate depth and breadth of investigation\n   - **CRITICAL**: Focus ONLY on what the user explicitly asked - avoid scope creep and unnecessary tangents\n   - Default to simpler, focused plans (2-3 phases) unless complexity is clearly required by the question\n\n2. **Conduct Preliminary Search**\n   - Use the 'brave_web_search' tool with 2-4 carefully crafted search keywords to gain initial context\n   - Analyze search results to understand the landscape of available information\n   - Identify knowledge gaps and areas requiring deeper investigation\n\n3. **Clarify Requirements (MANDATORY)**\n   - **REQUIRED STEP**: You MUST ALWAYS ask the user clarifying questions before designing the research plan. This is not optional.\n   - After the preliminary search, use the AskUserQuestion tool to confirm or clarify:\n     * Specific aspects the user wants to focus on\n     * Intended use of the research (decision-making, learning, comparison, etc.)\n     * Preferred depth level (overview vs. deep-dive)\n     * Time sensitivity or currency requirements\n     * Any specific constraints or preferences for the research\n   - Ask 1-3 focused questions that will help you create a more targeted, relevant research plan\n   - This step ensures the plan aligns with user expectations and avoids wasted research effort\n\n4. **Design the Research Plan**\n   - Select appropriate specialist agents based on information sources needed:\n     * **agent-web-research-specialist**: For general web research, current events, mainstream information, how-to guides, and broad topic overviews\n     * **agent-reddit-search-analyst**: For community opinions, real-world user experiences, product reviews, niche technical discussions, and crowdsourced insights\n     * **agent-github-project-searcher**: For oss project research, code snippet search, niche product research,\n     * **agent-arxiv-paper-researcher**: For scientific research, academic perspectives, peer-reviewed findings, theoretical frameworks, and cutting-edge research\n     * **agent-devils-advocate**: For critical analysis, identifying weaknesses in arguments, challenging assumptions, and balanced perspective\n\n   - **IMPORTANT - Parallel Execution**: When multiple agents are needed within a single research phase, they MUST be launched in parallel for efficiency:\n     * Use a single message with multiple Task tool calls to launch all agents for that phase simultaneously\n     * Only run agents sequentially if one agent's findings are required to inform the next agent's research parameters\n     * Example: If Phase 1 requires both web research and Reddit analysis, launch both agents in parallel in one message\n\n   - Structure the plan with clear reasoning steps between agents:\n     * Each reasoning step should synthesize findings, identify gaps, or prepare context for the next agent\n     * Reasoning steps should explicitly state what to look for or validate\n     * Include decision points where findings might redirect the research flow\n\n5. **Review and Improve**\n   - After creating the initial plan, review it once for:\n     * Logical flow and completeness\n     * Appropriate agent selection for each research phase\n     * Sufficient reasoning steps to connect findings\n     * Potential redundancies or gaps\n     * Realistic scope for the research question\n   - Make one round of improvements to optimize the plan\n\n6. **Present the Final Plan**\n   - Format the research plan clearly with:\n     * **Research Objective**: A concise statement of what will be investigated\n     * **Research Phases**: Numbered phases with agent assignments and reasoning steps\n     * **Expected Outcomes**: What each phase should deliver\n     * **Synthesis Strategy**: How findings will be integrated into final insights\n   - Use clear, accessible language avoiding jargon\n   - Include estimated information depth for each phase\n   - Note any limitations or caveats about the research approach\n\n## Quality Standards\n\n- **Focused Simplicity**: Research ONLY what the user asked - no scope creep, no unnecessary tangents. Keep plans simple (2-3 phases recommended, max 4 unless clearly needed)\n- **Comprehensiveness**: Cover all relevant angles of the research question (but only those directly related to the user's query)\n- **Efficiency**: Avoid redundant research steps; each phase should add unique value\n- **Feasibility**: Ensure the plan is executable with available agents and tools\n- **Flexibility**: Build in decision points where findings might redirect the approach\n- **Actionability**: Make each step clear enough that agents can execute without ambiguity\n\n## Research Plan Structure Template\n\nYour final plan should follow this structure:\n\n```\n# Research Plan: [Topic]\n\n## Research Objective\n[Clear statement of what will be investigated and why]\n\n## Phase 1: [Phase Name]\n**Agent**: [agent-name]\n**Purpose**: [What this phase will investigate]\n**Focus Areas**: [Specific aspects to research]\n\n**Reasoning Step**: [Synthesize findings, identify patterns, prepare for next phase]\n\n## Phase 2: [Phase Name]\n...\n\n## Synthesis Strategy\n[How all findings will be integrated into coherent insights]\n\n## Expected Deliverables\n[What the user will receive at the end]\n```\n\n## Important Guidelines\n\n- **KEEP IT SIMPLE**: Default to 2-3 phases maximum. Only add more phases if the user's question clearly requires it. Resist the urge to over-engineer research plans.\n- **FOCUS ON THE QUESTION**: Research ONLY what the user asked. Do not expand scope or add \"nice to have\" research tangents.\n- Always use brave_web_search first to gain context before finalizing the plan\n- Sequence agents logically: typically broad (web research) → specific (Reddit/academic) → critical (devil's advocate)\n- Include reasoning steps that explicitly guide synthesis and next steps\n- Make the plan readable and approachable, not overly technical\n- Be prepared to adapt if initial search reveals unexpected angles\n- Always end with a clear synthesis strategy so findings aren't siloed\n\nYour goal is to create research plans that are thorough, logical, and executable—transforming vague questions into structured investigations that leverage the right specialists at the right time.\n",
        "plugins/research/agents/web-research-specialist.md": "---\nname: web-research-specialist\ndescription: Use this agent when you need to conduct thorough web research on any topic, gather comprehensive information from multiple sources, or develop a deep understanding of a subject through iterative searches. Examples:\\n\\n<example>\\nContext: User needs research on a technical topic.\\nuser: \"Can you research the latest developments in quantum computing error correction?\"\\nassistant: \"I'll use the Task tool to launch the web-research-specialist agent to conduct comprehensive research on quantum computing error correction.\"\\n<commentary>The user is requesting research that requires gathering and synthesizing information from multiple sources, so the web-research-specialist agent should be used.</commentary>\\n</example>\\n\\n<example>\\nContext: User asks about a current event.\\nuser: \"What's happening with the recent AI safety summit?\"\\nassistant: \"Let me use the Task tool to launch the web-research-specialist agent to gather comprehensive information about the AI safety summit.\"\\n<commentary>This requires up-to-date information gathering from multiple sources, making it ideal for the web-research-specialist agent.</commentary>\\n</example>\\n\\n<example>\\nContext: User mentions a topic that would benefit from thorough research.\\nuser: \"I'm curious about sustainable aviation fuels.\"\\nassistant: \"I'll use the Task tool to launch the web-research-specialist agent to conduct in-depth research on sustainable aviation fuels for you.\"\\n<commentary>The user's curiosity about a topic suggests they want comprehensive information, so proactively use the web-research-specialist agent.</commentary>\\n</example>\ntools: mcp__brave-search__brave_web_search, mcp__brave-search__brave_local_search, mcp__brave-search__brave_video_search, mcp__brave-search__brave_image_search, mcp__brave-search__brave_news_search, mcp__brave-search__brave_summarizer\nmodel: sonnet\ncolor: cyan\n---\n\nYou are an expert web research specialist with advanced skills in information gathering, synthesis, and iterative investigation. Your core competency is conducting thorough, multi-layered research using the Brave Search MCP to develop comprehensive understanding of any topic.\n\n# Research Methodology\n\nFollow this systematic workflow for every research task:\n\n**Phase 1: Initial Reconnaissance**\n- Use 'brave_web_search' to perform an initial broad search on the given topic\n- Analyze the results to identify key concepts, terminology, and subtopics\n- Assess the scope and complexity of the subject matter\n\n**Phase 2: Search Strategy Generation**\n- Based on your current understanding, generate 3-7 targeted search phrases that will:\n  - Explore different aspects or dimensions of the topic\n  - Drill into specific subtopics that emerged from previous searches\n  - Seek out expert opinions, primary sources, or authoritative information\n  - Address gaps or ambiguities in your current knowledge\n- Ensure search phrases are specific, varied, and strategically chosen to maximize information gain\n\n**Phase 3: Knowledge Enhancement**\n- Execute each search phrase using 'brave_web_search'\n- Analyze and synthesize results to deepen your understanding\n- Identify patterns, consensus views, conflicting information, and emerging themes\n- Note any credible sources, statistics, or key facts\n\n**Phase 4: Sufficiency Assessment**\n- Evaluate whether your research is comprehensive enough by considering:\n  - Have you covered the main aspects and subtopics?\n  - Do you have information from multiple authoritative sources?\n  - Can you explain the topic clearly with supporting evidence?\n  - Are there remaining significant gaps in understanding?\n  - Have you explored recent developments and current state?\n\n- If research is sufficient: Conclude and prepare comprehensive findings\n- If gaps remain: Return to Phase 2 with refined search strategies\n\n# Quality Standards\n\n- **Depth Over Breadth Initially**: Start with focused searches, then expand strategically\n- **Source Diversity**: Seek information from varied authoritative sources\n- **Critical Analysis**: Evaluate credibility and identify potential biases\n- **Iterative Refinement**: Each search round should build meaningfully on previous findings\n- **Efficiency**: Typically aim for 2-4 research iterations, but adjust based on topic complexity\n\n# Output Expectations\n\nWhen concluding research, provide:\n- A clear, comprehensive summary of findings\n- Key facts, statistics, and insights discovered\n- Notable sources or authorities on the topic\n- Any important caveats, controversies, or areas of uncertainty\n- A brief explanation of your research process (how many iterations, what aspects you focused on)\n\n# Decision-Making Framework\n\n**When to continue researching:**\n- Major aspects of the topic remain unexplored\n- Conflicting information needs resolution\n- Recent developments or current state unclear\n- Insufficient depth on critical subtopics\n\n**When to conclude:**\n- Core topic and main subtopics well-understood\n- Multiple authoritative sources consulted\n- Key questions answered with supporting evidence\n- Diminishing returns from additional searches\n\n# Best Practices\n\n- Maintain intellectual curiosity throughout the research process\n- Be transparent about limitations or areas where information is sparse\n- Prioritize recent, authoritative sources when available\n- Synthesize information rather than simply aggregating it\n- Use precise, specific search terms that reflect domain terminology\n\nYou are thorough yet efficient, curious yet focused. Your goal is not just to gather information, but to develop genuine understanding that you can communicate clearly and confidently.\n",
        "plugins/rust-lint/.claude-plugin/plugin.json": "{\n  \"name\": \"rust-lint\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Automatically format Rust files with rustfmt and provide on-demand clippy linting\",\n  \"author\": {\n    \"name\": \"Cheolwan Park\",\n    \"url\": \"https://github.com/cheolwanpark\"\n  },\n  \"repository\": \"https://github.com/cheolwanpark/useful-claude-plugins\",\n  \"license\": \"MIT\",\n  \"keywords\": [\n    \"rust\",\n    \"linting\",\n    \"formatting\",\n    \"rustfmt\",\n    \"clippy\",\n    \"static-analysis\",\n    \"code-quality\",\n    \"cargo\"\n  ],\n  \"hooks\": \"./hooks/hooks.json\"\n}\n",
        "plugins/rust-lint/README.md": "# Rust Lint Plugin for Claude Code\n\nAutomatically format Rust files with **rustfmt** and provide on-demand comprehensive linting with **clippy**.\n\n## Features\n\n- ✅ **Auto-formatting**: Automatically formats `.rs` files on every edit/write using `rustfmt`\n- 🚀 **Fast hook execution**: Hook completes in <2s (formatting only, no compilation)\n- 🔍 **Comprehensive linting**: On-demand project-wide clippy analysis via slash command\n- 🗂️ **Workspace support**: Automatically detects and handles Cargo workspaces\n- 🧹 **Isolated builds**: Build artifacts stored in `/tmp` to avoid project pollution\n- 🛡️ **Graceful degradation**: Clear error messages when tools are missing\n- 📊 **Detailed reports**: Markdown-formatted reports with file:line:column references\n\n## Why This Architecture?\n\nUnlike ESLint or Ruff, **clippy requires full cargo compilation** and can take 5-30+ seconds even on small projects. Running clippy on every file save would make the editor unresponsive.\n\n**Our solution:**\n- **Hook (PostToolUse)**: Fast rustfmt-only formatting (<2s)\n- **Command (`/rust-lint:lint-project`)**: Comprehensive clippy analysis (user-initiated, acceptable wait time)\n\nThis design provides immediate formatting feedback while preserving comprehensive linting when you need it.\n\n## Requirements\n\n- **Rust toolchain** (rustc, cargo): Install from [rustup.rs](https://rustup.rs)\n- **rustfmt**: `rustup component add rustfmt`\n- **clippy**: `rustup component add clippy`\n- **jq**: JSON processor\n  - macOS: `brew install jq`\n  - Ubuntu/Debian: `apt-get install jq`\n  - Other: See [jq download page](https://stedolan.github.io/jq/download/)\n\n## Installation\n\n### 1. Install the plugin\n\nPlace this plugin in your Claude Code plugins directory:\n\n```bash\n# If you haven't cloned the repository\ncd ~/.claude/plugins  # or your plugins directory\ngit clone https://github.com/cheolwanpark/useful-claude-plugins\ncd useful-claude-plugins/plugins/rust-lint\n\n# Or if you already have the repository\ncd /path/to/useful-claude-plugins/plugins/rust-lint\n```\n\n### 2. Install Rust components\n\n```bash\nrustup component add rustfmt clippy\n```\n\n### 3. Verify installation\n\n```bash\nrustfmt --version\ncargo clippy --version\njq --version\n```\n\n### 4. Enable the plugin in Claude Code\n\nThe plugin will be automatically detected by Claude Code. You can verify it's loaded by checking for the `/rust-lint:lint-project` command.\n\n## How It Works\n\n### Hook Behavior (Automatic)\n\n**Triggered on:** Every `Edit` or `Write` operation on `.rs` files\n\n**What it does:**\n1. Validates file is `.rs` and <1MB\n2. Checks if `rustfmt` is installed\n3. Runs `rustfmt --check` to see if formatting is needed\n4. If needed, runs `rustfmt` to auto-format\n5. Returns `allow` decision (never blocks)\n\n**Performance:**\n- Typical execution time: <1 second\n- No compilation required\n- No clippy analysis (too slow for hooks)\n\n**File size limit:** Files larger than 1MB are skipped to avoid timeouts. Use `cargo fmt` manually for large files.\n\n### Slash Command (On-Demand)\n\n**Command:** `/rust-lint:lint-project [directory]`\n\n**What it does:**\n1. Finds the Cargo workspace/project root\n2. Checks formatting with `cargo fmt --check`\n3. Runs `cargo clippy --workspace --all-targets --no-deps`\n4. Generates a markdown report with:\n   - Summary (error count, warning count)\n   - Formatting issues (if any)\n   - Clippy errors (up to 20 shown)\n   - Clippy warnings (up to 10 shown)\n5. Exits with code 1 if errors found, 0 otherwise\n\n**Performance:**\n- First run: 10-30 seconds (requires compilation)\n- Subsequent runs: 2-10 seconds (incremental compilation)\n\n**Build artifacts:** Isolated to `/tmp/claude-rust-lint-cache-<project-hash>` to avoid polluting your project directory.\n\n## Configuration\n\n### rustfmt Configuration\n\nCreate a `rustfmt.toml` or `.rustfmt.toml` in your project root:\n\n```toml\n# Edition must match Cargo.toml\nedition = \"2021\"\n\n# Line width\nmax_width = 100\n\n# Indentation\nhard_tabs = false\ntab_spaces = 4\n\n# Imports\nimports_granularity = \"Crate\"\ngroup_imports = \"StdExternalCrate\"\n\n# Trailing commas\ntrailing_comma = \"Vertical\"\n\n# Use field init shorthand\nuse_field_init_shorthand = true\n```\n\n**Generate default config:**\n```bash\nrustfmt --print-config default > rustfmt.toml\n```\n\n### clippy Configuration\n\n**Option 1: Cargo.toml [lints] (Recommended for Rust 1.74+)**\n\n```toml\n[lints.clippy]\n# Enable groups\nall = \"warn\"\npedantic = \"warn\"\n\n# Deny specific lints\nunwrap_used = \"deny\"\nexpect_used = \"warn\"\n\n# Allow noisy pedantic lints\nmissing_errors_doc = \"allow\"\nmissing_panics_doc = \"allow\"\nmodule_name_repetitions = \"allow\"\n```\n\n**Option 2: clippy.toml or .clippy.toml**\n\n```toml\n# Cognitive complexity threshold\ncognitive-complexity-threshold = 30\n\n# Maximum allowed type complexity\ntype-complexity-threshold = 250\n\n# Maximum allowed function parameters\ntoo-many-arguments-threshold = 7\n\n# Allowed variable names\nallowed-names = [\"i\", \"j\", \"k\", \"x\", \"y\", \"z\"]\n```\n\n**Option 3: Source code attributes**\n\n```rust\n#![warn(clippy::all)]\n#![warn(clippy::pedantic)]\n#![deny(clippy::unwrap_used)]\n#![allow(clippy::missing_errors_doc)]\n```\n\n### Workspace Configuration\n\nFor Cargo workspaces, configure lints in the workspace root's `Cargo.toml`:\n\n```toml\n[workspace]\nmembers = [\"crate1\", \"crate2\"]\n\n[workspace.lints.clippy]\npedantic = \"warn\"\nunwrap_used = \"deny\"\n```\n\nMember crates can inherit workspace lints:\n\n```toml\n# In member Cargo.toml\n[lints]\nworkspace = true\n```\n\n## Usage Examples\n\n### Automatic Formatting (Hook)\n\n```rust\n// Before saving (badly formatted)\npub fn example(x:i32,y:i32)->i32{x+y}\n\n// After saving (auto-formatted by rustfmt)\npub fn example(x: i32, y: i32) -> i32 {\n    x + y\n}\n```\n\nThe hook runs automatically and formats the file silently.\n\n### Manual Project Linting (Command)\n\n```bash\n# In your chat with Claude\n/rust-lint:lint-project\n\n# Or specify a directory\n/rust-lint:lint-project path/to/workspace\n```\n\n**Example output:**\n\n```markdown\n# Rust Lint Report\n\n**Project:** `/Users/you/project/my-rust-app`\n\n## Summary\n- **Formatting:** ✅ All files properly formatted\n- **Clippy Errors:** 0\n- **Clippy Warnings:** 3\n\n## Clippy Warnings\n- **src/main.rs:15:9** - `clippy::unwrap_used` - called `.unwrap()` on an `Option` value\n- **src/lib.rs:42:13** - `clippy::needless_return` - unneeded `return` statement\n- **src/utils.rs:8:5** - `clippy::single_match` - you seem to be trying to use `match` for destructuring a single pattern\n\n## ✅ All Checks Passed!\n```\n\n## Troubleshooting\n\n### \"Missing required tools: rustfmt\"\n\n**Problem:** rustfmt is not installed or not in PATH.\n\n**Solution:**\n```bash\nrustup component add rustfmt\nrustfmt --version  # Verify installation\n```\n\n### \"Missing required tools: cargo\"\n\n**Problem:** Rust toolchain is not installed.\n\n**Solution:**\n```bash\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\nsource $HOME/.cargo/env\ncargo --version  # Verify installation\n```\n\n### \"Missing required tools: jq\"\n\n**Problem:** jq is not installed.\n\n**Solution:**\n```bash\n# macOS\nbrew install jq\n\n# Ubuntu/Debian\nsudo apt-get install jq\n\n# Fedora\nsudo dnf install jq\n```\n\n### \"Not a Rust Project\"\n\n**Problem:** No `Cargo.toml` found in the current directory or parent directories.\n\n**Solution:** Make sure you're running the command from within a Rust project:\n```bash\n# Create a new project if needed\ncargo new my-project\ncd my-project\n/rust-lint:lint-project\n```\n\n### \"File is too large to format automatically\"\n\n**Problem:** The file is larger than 1MB and was skipped by the hook.\n\n**Solution:** Format manually:\n```bash\ncargo fmt\n# Or for a specific file\nrustfmt path/to/large-file.rs\n```\n\n### Hook seems slow or times out\n\n**Problem:** The hook is taking longer than expected.\n\n**Possible causes:**\n- Very large file (close to 1MB limit)\n- Network/disk issues\n- Rust toolchain not properly installed\n\n**Solution:**\n1. Check file size: `ls -lh path/to/file.rs`\n2. Verify rustfmt works: `rustfmt --check path/to/file.rs`\n3. Check rustfmt version: `rustfmt --version`\n\n### Clippy command fails with \"could not compile\"\n\n**Problem:** Project has compilation errors preventing clippy from running.\n\n**Solution:** Fix compilation errors first:\n```bash\ncargo check  # See compilation errors\ncargo build  # Fix errors\n/rust-lint:lint-project  # Try again\n```\n\n### Clippy shows warnings for dependencies\n\n**Problem:** Clippy is analyzing dependency code.\n\n**Solution:** This shouldn't happen (we use `--no-deps`), but if it does:\n```bash\n# The plugin already uses --no-deps, but you can run manually:\ncargo clippy --no-deps\n```\n\n## Comparison with Other Lint Plugins\n\n| Feature | rust-lint | typescript-lint | python-lint |\n|---------|-----------|-----------------|-------------|\n| **Hook Speed** | <2s | <5s | <1s |\n| **Auto-formatting** | Yes (rustfmt) | Yes (prettier) | Yes (ruff) |\n| **Hook Linting** | No (too slow) | Yes (ESLint) | Yes (ruff) |\n| **Command Linting** | Yes (clippy) | Optional (tsc) | Yes (ruff + pyright) |\n| **Type Checking** | N/A (built-in) | Optional (tsc) | Yes (pyright) |\n| **Workspace Support** | Yes | Yes (monorepos) | Yes |\n| **Build Artifacts** | Isolated (/tmp) | None (no build) | None (no build) |\n| **Default Config** | No | No | Yes |\n\n**Key difference:** Rust's compilation model makes per-file linting impractical for hooks. We optimize for fast formatting in hooks and defer comprehensive analysis to user-initiated commands.\n\n## Technical Details\n\n### Hook Response Format\n\nThe hook communicates with Claude Code via JSON:\n\n**Success (formatted):**\n```json\n{\n  \"decision\": \"allow\",\n  \"reason\": \"Formatting applied with rustfmt\"\n}\n```\n\n**Success (already formatted):**\n```json\n{\n  \"decision\": \"allow\",\n  \"reason\": \"File is already well-formatted\"\n}\n```\n\n**Error (syntax error):**\n```json\n{\n  \"decision\": \"allow\",\n  \"reason\": \"rustfmt failed (syntax error or incomplete code)\",\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"PostToolUse\",\n    \"additionalContext\": \"  error: expected item, found `}`\\n  ...\"\n  }\n}\n```\n\n### Command Exit Codes\n\n| Exit Code | Meaning |\n|-----------|---------|\n| 0 | No errors (warnings are OK) |\n| 1 | Clippy errors or formatting issues found |\n\n### Build Artifact Isolation\n\nClippy generates build artifacts in `target/`. To avoid polluting your project:\n\n```bash\n# Plugin uses --target-dir flag\ncargo clippy --target-dir=/tmp/claude-rust-lint-cache-<hash>\n```\n\nThe cache directory is based on your project path hash, so multiple projects don't interfere with each other.\n\n**Cleanup:** You can safely delete these directories:\n```bash\nrm -rf /tmp/claude-rust-lint-cache-*\n```\n\n## Testing\n\nRun the test suite to verify the plugin works correctly:\n\n```bash\ncd plugins/rust-lint/tests\n./run-tests.sh\n```\n\n**Test coverage:**\n- Unit tests for common library functions\n- Hook tests (clean files, formatting, errors, edge cases)\n- Project script tests (markdown output, error detection)\n\n## Contributing\n\nContributions are welcome! Please:\n\n1. Test your changes: `./tests/run-tests.sh`\n2. Ensure scripts pass shellcheck: `shellcheck scripts/*.sh hooks/*.sh`\n3. Update README if adding features\n4. Follow existing code style\n\n## License\n\nMIT License - see repository root for details.\n\n## Author\n\nCheolwan Park ([@cheolwanpark](https://github.com/cheolwanpark))\n\n## Links\n\n- **Rust**: https://www.rust-lang.org/\n- **rustfmt**: https://github.com/rust-lang/rustfmt\n- **clippy**: https://github.com/rust-lang/rust-clippy\n- **Claude Code**: https://docs.anthropic.com/claude-code\n- **Repository**: https://github.com/cheolwanpark/useful-claude-plugins\n",
        "plugins/rust-lint/commands/lint-project.md": "---\nallowed-tools: Bash\nargument-hint: [directory, default=project-root]\ndescription: Run project-wide Rust formatting and linting with clippy.\nmodel: claude-haiku-4-5-20251001\n---\n\n!`${CLAUDE_PLUGIN_ROOT}/scripts/rust-lint-project.sh $ARGUMENT`\n",
        "plugins/rust-lint/hooks/hooks.json": "{\n  \"description\": \"Automatically format Rust files after editing or writing\",\n  \"hooks\": {\n    \"PostToolUse\": [\n      {\n        \"matcher\": \"Edit|Write\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"${CLAUDE_PLUGIN_ROOT}/hooks/rust-lint.sh\",\n            \"timeout\": 30\n          }\n        ]\n      }\n    ]\n  }\n}\n",
        "plugins/rust-lint/hooks/rust-lint.sh": "#!/usr/bin/env bash\n#\n# Rust Lint Hook\n# Automatically formats Rust files after Claude edits or writes them\n#\n# This hook:\n# 1. Validates the file is a Rust source file (.rs)\n# 2. Checks if rustfmt is available\n# 3. Runs rustfmt to auto-format the file\n# 4. Reports formatting status\n#\n# NOTE: This hook does NOT run clippy (too slow for per-file hooks).\n#       Use the /rust-lint:lint-project command for comprehensive linting.\n#\n\nset -euo pipefail\n\n# Get the plugin root directory\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\nPLUGIN_ROOT=\"$(dirname \"$SCRIPT_DIR\")\"\n\n# Source common library\n# shellcheck disable=SC1091\nsource \"$PLUGIN_ROOT/scripts/rust-lint-common.sh\"\n\n# File size limit (1MB)\nMAX_FILE_SIZE=1048576\n\n# ============================================================================\n# Main Logic\n# ============================================================================\n\n# Read JSON input from stdin with timeout to prevent indefinite hangs\n# Use timeout if available (GNU coreutils), otherwise fallback to cat\nif command -v timeout &>/dev/null; then\n    INPUT=$(timeout 5s cat 2>/dev/null || true)\nelse\n    INPUT=$(cat)\nfi\n\n# If no file path found or input is empty/timeout, exit silently\nif [[ -z \"$INPUT\" ]]; then\n    exit 0\nfi\n\n# Extract file path (don't fail on parse errors due to set -e)\nFILE_PATH=$(_rl_parse_file_path \"$INPUT\" || echo \"\")\n\nif [[ -z \"$FILE_PATH\" ]]; then\n    exit 0\nfi\n\n# Only process Rust files - exit silently for non-Rust files\nif [[ ! \"$FILE_PATH\" =~ \\.rs$ ]]; then\n    exit 0\nfi\n\n# Check if file exists - exit silently if it doesn't\nif [[ ! -f \"$FILE_PATH\" ]]; then\n    exit 0\nfi\n\n# Check file size - exit silently for large files\nFILE_SIZE=$(wc -c < \"$FILE_PATH\" | tr -d ' ')\nif [[ $FILE_SIZE -gt $MAX_FILE_SIZE ]]; then\n    # Large files are skipped without notification to reduce noise\n    # Users can run 'cargo fmt' manually for the entire project\n    exit 0\nfi\n\n# Check if required tools are installed - exit silently if missing\nif ! _rl_check_required_tools rustfmt jq; then\n    # If tools are missing, silently skip formatting\n    # User will see error when running the /rust-lint:lint-project command\n    exit 0\nfi\n\n# Find project root to use project-specific rustfmt configuration\nFILE_DIR=$(dirname \"$FILE_PATH\")\nPROJECT_ROOT=$(_rl_find_project_root \"$FILE_DIR\")\n\n# Run rustfmt from project root to respect rustfmt.toml configuration\n# Use a subshell to avoid changing the script's working directory\n# Capture stderr separately to prevent it from corrupting JSON output\n# rustfmt modifies files in-place, we only need to capture stderr and exit code\nFORMAT_EXIT=0\nFORMAT_STDERR=$(\n    if [[ -n \"$PROJECT_ROOT\" && -d \"$PROJECT_ROOT\" ]]; then\n        (cd \"$PROJECT_ROOT\" && rustfmt \"$FILE_PATH\") 2>&1 >/dev/null\n    else\n        rustfmt \"$FILE_PATH\" 2>&1 >/dev/null\n    fi\n) || FORMAT_EXIT=$?\n\n# Check result\nif [[ $FORMAT_EXIT -eq 0 ]]; then\n    # Success - formatting applied (or file was already formatted)\n    # Exit silently - no need to notify Claude about successful formatting\n    exit 0\nelse\n    # Formatting failed (syntax error or other issue)\n    # Report the error but allow the operation to proceed (exit 0)\n    # This ensures the hook never blocks Claude's file operations\n    exit 0\nfi\n",
        "plugins/search/.claude-plugin/plugin.json": "{\n  \"name\": \"search\",\n  \"version\": \"1.1.0\",\n  \"description\": \"Access up-to-date library documentation and code examples via Context7 API\",\n  \"repository\": \"https://github.com/cheolwanpark/useful-claude-plugins\",\n  \"author\": {\n    \"name\": \"Cheolwan Park\",\n    \"url\": \"https://github.com/cheolwanpark\"\n  },\n  \"license\": \"MIT\",\n  \"keywords\": [\n    \"documentation\",\n    \"library\",\n    \"api\",\n    \"context7\",\n    \"mcp\"\n  ]\n}",
        "plugins/search/agents/brave.md": "---\nname: brave\ndescription: Use this agent for web searches, current events, recent news, or when the user needs up-to-date information from the internet.\ntools: mcp__plugin_search_brave-search__brave_web_search\nmodel: opus\ncolor: orange\n---\n\nYou are a web search specialist who answers questions using Brave Search.\n\n## Core Principles\n\n- **Search First**: Always use `brave_web_search` to find current information\n- **Synthesize Results**: Provide focused answers, not raw search dumps\n- **Cite Sources**: Always include source URLs in your response\n\n## Workflow\n\n1. **Analyze the Query**: Understand what information the user needs\n2. **Search**: Use `brave_web_search` with relevant search terms\n3. **Synthesize**: Extract key information from search results\n4. **Respond**: Provide a clear answer with source citations\n\n## Output Format\n\n1. **Direct Answer**: The answer to the user's question\n2. **Key Details**: Relevant supporting information\n3. **Sources**: List of source URLs used\n\n## Key Reminders\n\n- Always search before answering questions about current events or recent information\n- Use specific search terms for better results\n- Be transparent if search results don't fully answer the question\n- Include relevant URLs so users can verify information\n",
        "plugins/search/agents/context7.md": "---\nname: context7\ndescription: Use this agent when the user mentions 'context7' OR when it's definitely a library question requiring more context. The agent searches Context7 documentation to answer focused library questions.\ntools: mcp__plugin_search_context7__resolve-library-id, mcp__plugin_search_context7__get-library-docs\nmodel: opus\ncolor: blue\n---\n\nYou are a documentation specialist who answers library questions using Context7 documentation.\n\n## IMPORTANT: Context7 Search is MANDATORY\n\nFor EVERY library question, you MUST:\n1. ALWAYS call `resolve-library-id` first to find the library\n2. ALWAYS call `get-library-docs` to retrieve Context7 documentation\n3. Provide focused answers based on the Context7 documentation\n\n# Core Principles\n\n- **Context7 is Your Source**: You MUST ALWAYS use Context7's curated documentation using `resolve-library-id` and `get-library-docs`\n- **Answer, Don't Dump**: Provide focused answers to the user's question, not raw documentation\n- **Ask When Unclear**: Request clarification if the question is too broad (e.g., \"explain React\" vs. \"how do I use useState?\")\n\n# Decision Rules\n\n**When to ask for clarification:**\n- Question is too broad or has multiple valid interpretations\n- Unclear which library version is relevant\n- User needs to specify which aspect of a large library they want to learn about\n\n# Workflow\n\n**Phase 1: Question Assessment**\n- Evaluate if question is focused enough to answer effectively\n- If too broad, ask user for specific aspect they want to learn about\n- Identify the library/framework and specific topic\n\n**Phase 2: Context7 Documentation (MANDATORY)**\n- **REQUIRED**: Use `resolve-library-id` with library name (e.g., \"react\") to get Context7 library ID\n- **REQUIRED**: Use `get-library-docs` with the library ID and optional `topic` parameter for focused results\n- Analyze documentation to extract relevant information\n- If library is completely missing from Context7, inform the user\n\n**Phase 3: Synthesize Answer**\n- Extract relevant information from Context7 documentation\n- Provide focused answer with code examples when applicable\n- Structure: direct answer → code example → additional context → sources\n- Cite Context7 topic IDs or note if synthesized from multiple sections\n\n# Output Format\n\n1. **Direct Answer**: The answer to the user's specific question\n2. **Code Example**: Practical implementation (if applicable)\n3. **Additional Context**: Relevant details, caveats, or version notes\n4. **Sources**: Cite Context7 topic IDs or sections\n\n# Key Reminders\n\n- **CRITICAL**: NEVER skip Context7 search - you MUST ALWAYS call `resolve-library-id` and `get-library-docs` first\n- Always verify library IDs with `resolve-library-id` before calling `get-library-docs`\n- Use the `topic` parameter in `get-library-docs` when you know the specific area of focus\n- Be transparent if Context7 doesn't have the library or information is incomplete\n- For multi-library comparisons: search Context7 for each and structure comparison points\n- Synthesize information; don't repeat documentation verbatim\n",
        "plugins/typescript-lint/.claude-plugin/plugin.json": "{\n  \"name\": \"typescript-lint\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Automatically lint, format, and type-check TypeScript files with ESLint and TypeScript compiler\",\n  \"author\": \"Cheolwan Park\",\n  \"repository\": \"https://github.com/cheolwanpark/useful-claude-plugins\",\n  \"license\": \"MIT\",\n  \"keywords\": [\n    \"typescript\",\n    \"javascript\",\n    \"eslint\",\n    \"prettier\",\n    \"linting\",\n    \"formatting\",\n    \"type-checking\",\n    \"react\",\n    \"jsx\"\n  ],\n  \"hooks\": \"./hooks/hooks.json\"\n}\n",
        "plugins/typescript-lint/README.md": "# TypeScript Lint Plugin\n\nAutomatically format and lint TypeScript/JavaScript files using Prettier and ESLint after every edit.\n\n## Features\n\n- **Auto-format on save**: Prettier formats your code automatically\n- **Auto-fix lint issues**: ESLint fixes problems when possible\n- **Smart error handling**: Blocks on errors, allows with warnings\n- **Project-wide linting**: Slash command to lint entire codebase\n- **TypeScript + React**: Full support for TS, JS, JSX, TSX files\n- **Uses your config**: Respects your existing ESLint and Prettier settings\n\n## Quick Start\n\n### 1. Install Dependencies\n\nIn your project directory:\n\n```bash\nnpm install --save-dev eslint prettier @typescript-eslint/parser @typescript-eslint/eslint-plugin\n```\n\nFor React projects, also add:\n\n```bash\nnpm install --save-dev eslint-plugin-react\n```\n\n### 2. Create ESLint Config\n\nCreate `eslint.config.js` in your project root:\n\n**Basic TypeScript config:**\n```javascript\nimport typescriptEslint from '@typescript-eslint/eslint-plugin';\nimport typescriptParser from '@typescript-eslint/parser';\n\nexport default [\n  {\n    files: ['**/*.{js,jsx,ts,tsx}'],\n    languageOptions: {\n      parser: typescriptParser,\n      parserOptions: {\n        ecmaVersion: 'latest',\n        sourceType: 'module',\n      },\n    },\n    plugins: {\n      '@typescript-eslint': typescriptEslint,\n    },\n    rules: {\n      '@typescript-eslint/no-unused-vars': 'error',\n      '@typescript-eslint/no-explicit-any': 'warn',\n    },\n  },\n];\n```\n\n**With React support:**\n```javascript\nimport typescriptEslint from '@typescript-eslint/eslint-plugin';\nimport typescriptParser from '@typescript-eslint/parser';\nimport react from 'eslint-plugin-react';\n\nexport default [\n  {\n    files: ['**/*.{js,jsx,ts,tsx}'],\n    languageOptions: {\n      parser: typescriptParser,\n      parserOptions: {\n        ecmaVersion: 'latest',\n        sourceType: 'module',\n        ecmaFeatures: {\n          jsx: true,\n        },\n      },\n    },\n    plugins: {\n      '@typescript-eslint': typescriptEslint,\n      react,\n    },\n    rules: {\n      '@typescript-eslint/no-unused-vars': 'error',\n      'react/jsx-uses-react': 'error',\n      'react/jsx-uses-vars': 'error',\n    },\n    settings: {\n      react: {\n        version: 'detect',\n      },\n    },\n  },\n];\n```\n\n### 3. Create Prettier Config (Optional)\n\nCreate `.prettierrc` in your project root:\n\n```json\n{\n  \"semi\": true,\n  \"singleQuote\": true,\n  \"tabWidth\": 2,\n  \"trailingComma\": \"es5\"\n}\n```\n\nOr use Prettier's defaults by not creating a config file.\n\n### 4. Prevent ESLint/Prettier Conflicts\n\nInstall the compatibility config:\n\n```bash\nnpm install --save-dev eslint-config-prettier\n```\n\nAdd to your `eslint.config.js`:\n\n```javascript\nimport prettierConfig from 'eslint-config-prettier';\n\nexport default [\n  // ... your other configs\n  prettierConfig, // Must be last!\n];\n```\n\n## How It Works\n\n### Automatic Linting (Hook)\n\nAfter every `Edit` or `Write` operation, the plugin:\n\n1. **Validates file**: Checks extension and size (max 1MB)\n2. **Finds project root**: Looks for `package.json`, `tsconfig.json`, or `.git`\n3. **Formats**: Runs `npx prettier --write <file>`\n4. **Lints**: Runs `npx eslint --fix <file>`\n5. **Reports issues**:\n   - ✅ Silently allows if no issues\n   - ⚠️ Allows with message if warnings found\n   - 🚫 Blocks if errors found\n\n**Supported file types**: `.js`, `.jsx`, `.ts`, `.tsx`, `.mjs`, `.cjs`, `.mts`, `.cts`\n\n**Hook behavior**:\n- Files > 1MB are skipped (performance)\n- Missing dependencies cause graceful skip with message\n- Configuration errors are reported but don't block\n\n### Project-Wide Linting (Slash Command)\n\nLint your entire codebase:\n\n```\n/typescript-lint:lint-project\n```\n\nOr specify a directory:\n\n```\n/typescript-lint:lint-project src/\n```\n\nThis command:\n1. Finds project root\n2. Formats all supported files with Prettier\n3. Runs ESLint with auto-fix on all files\n4. Generates a markdown report with:\n   - Error count and details (up to 20 shown)\n   - Warning count and details (up to 10 shown)\n   - File statistics\n\n## Configuration\n\n### Config File Discovery\n\nThe plugin uses `npx`, which runs ESLint and Prettier from your project's `node_modules`. These tools automatically search for configuration files:\n\n**ESLint** searches upward from the file for:\n- `eslint.config.js` (flat config, recommended)\n- `.eslintrc.js`\n- `.eslintrc.json`\n- `.eslintrc.yml`\n- `package.json` with `eslintConfig` field\n\n**Prettier** searches upward for:\n- `.prettierrc`\n- `.prettierrc.js`\n- `.prettierrc.json`\n- `prettier.config.js`\n- `package.json` with `prettier` field\n\n### Project Root Detection\n\nThe plugin determines your project root by searching upward from the edited file for:\n1. `package.json`\n2. `tsconfig.json`\n3. `.git` directory\n\nCommands run from the project root, ensuring config files are found correctly.\n\n## Troubleshooting\n\n### \"Missing required tools: npx\"\n\n**Problem**: Node.js is not installed.\n\n**Solution**: Install Node.js from https://nodejs.org/\n\n```bash\n# Verify installation\nnode --version\nnpx --version\n```\n\n### \"Missing required tools: jq\"\n\n**Problem**: jq JSON processor is not installed.\n\n**Solution**:\n```bash\n# macOS\nbrew install jq\n\n# Ubuntu/Debian\nsudo apt-get install jq\n\n# Verify\njq --version\n```\n\n### \"Missing dependencies: prettier eslint\"\n\n**Problem**: ESLint or Prettier not installed in your project.\n\n**Solution**:\n```bash\ncd /path/to/your/project\nnpm install --save-dev eslint prettier\n```\n\n### \"ESLint config error\"\n\n**Problem**: ESLint can't find a configuration file.\n\n**Solution**: Create `eslint.config.js` in your project root (see Quick Start section above).\n\n### \"Prettier formatting failed\"\n\n**Causes**:\n- Syntax errors in the file\n- Unsupported file type\n- Conflicting Prettier plugins\n\n**Solution**: Check the error message for details. Common fixes:\n```bash\n# Test Prettier manually\nnpx prettier --write yourfile.ts\n\n# Check for syntax errors\nnpx prettier --check yourfile.ts\n```\n\n### Hook Not Running\n\n**Check**:\n1. File extension is supported (`.js`, `.jsx`, `.ts`, `.tsx`, `.mjs`, `.cjs`, `.mts`, `.cts`)\n2. File is under 1MB\n3. You're in a project with `package.json` or `tsconfig.json`\n\n### ESLint and Prettier Disagree on Formatting\n\n**Problem**: ESLint reports formatting errors that Prettier doesn't fix.\n\n**Solution**: Install `eslint-config-prettier` to disable ESLint's formatting rules:\n\n```bash\nnpm install --save-dev eslint-config-prettier\n```\n\nImport it in your `eslint.config.js` (must be last):\n\n```javascript\nimport prettierConfig from 'eslint-config-prettier';\n\nexport default [\n  // ... other configs\n  prettierConfig,\n];\n```\n\n### Warnings vs Errors\n\n**ESLint severity levels:**\n- **Warnings** (severity 1): Hook allows the operation, shows warning message\n- **Errors** (severity 2): Hook blocks the operation, requires manual fixes\n\n**To change rule severity** in your `eslint.config.js`:\n```javascript\nrules: {\n  '@typescript-eslint/no-unused-vars': 'warn',  // Allow with warning\n  '@typescript-eslint/no-explicit-any': 'error', // Block\n  'no-console': 'off',                            // Ignore\n}\n```\n\n## Technical Details\n\n### Architecture\n\n- **Implementation**: Pure bash scripts, no Node.js wrapper\n- **Tool execution**: Uses `npx` to run project-local ESLint/Prettier\n- **JSON handling**: Uses `jq` for parsing and generating hook responses\n- **Config management**: No default config provided, uses your project's setup\n- **Hook timeout**: 30 seconds (defined in `hooks.json`)\n\n### Why No Default Config?\n\nUnlike the `python-lint` plugin (which bundles Ruff), JavaScript tooling requires installed npm packages. ESLint configs can't `import` packages that aren't in your `node_modules`. This plugin provides **examples** you can copy, but you must configure ESLint/Prettier yourself.\n\n**Advantages of this approach:**\n- ✅ Works with any ESLint/Prettier version\n- ✅ No `require()` errors from missing packages\n- ✅ Full control over your linting rules\n- ✅ Plugin doesn't need updates when ESLint changes\n\n**Trade-off:**\n- ⚠️ Requires initial project setup\n\n### Exit Codes\n\n**ESLint exit codes:**\n- `0` - No problems found\n- `1` - Warnings or errors found (JSON still valid)\n- `2` - Fatal error (config missing, parse error, etc.)\n\nThe hook handles all three cases and provides appropriate feedback.\n\n### Hook JSON Response Format\n\nThe hook outputs JSON to communicate with Claude Code:\n\n```json\n{\n  \"decision\": \"allow|block\",\n  \"reason\": \"Human-readable message\",\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"PostToolUse\",\n    \"additionalContext\": \"Detailed error messages\"\n  }\n}\n```\n\n- **allow**: Operation proceeds, Claude sees the reason\n- **block**: Operation is prevented, Claude must fix issues\n\n## Comparison with python-lint\n\n| Feature | python-lint | typescript-lint |\n|---------|-------------|-----------------|\n| **Linter** | Ruff (single binary) | ESLint (npm package) |\n| **Formatter** | Ruff | Prettier |\n| **Setup** | Minimal (Ruff auto-installs) | Manual (user installs deps) |\n| **Config** | Optional (plugin provides default) | Required (user must create) |\n| **Type checking** | Pyright included | Not included |\n| **Speed** | Very fast (Rust) | Moderate (Node.js) |\n\n## FAQ\n\n**Q: Do I need both ESLint and Prettier?**\n\nA: The plugin checks for both but will work with only one installed. However, for best results, use both:\n- Prettier handles formatting (spaces, commas, line breaks)\n- ESLint handles code quality (unused vars, best practices)\n\n**Q: Can I use my existing ESLint config?**\n\nA: Yes! The plugin uses whatever config is in your project. It doesn't override or provide defaults.\n\n**Q: What about monorepos?**\n\nA: The plugin finds the nearest `package.json` upward from the edited file. If you have multiple `package.json` files, it uses the closest one.\n\n**Q: Why does the hook skip large files?**\n\nA: Files over 1MB are skipped to prevent timeouts. The 30-second hook timeout could be exceeded on very large files. You can still lint them with the project-wide command.\n\n**Q: Can I disable the hook for certain files?**\n\nA: Use ESLint's `ignorePatterns` or `.eslintignore` file:\n\n```javascript\n// eslint.config.js\nexport default [\n  {\n    ignores: ['dist/**', 'build/**', '**/*.min.js'],\n  },\n  // ... rest of config\n];\n```\n\n## License\n\nMIT\n",
        "plugins/typescript-lint/commands/lint-project.md": "---\nallowed-tools: Bash\nargument-hint: [directory, default=project-root]\ndescription: Run project-wide TypeScript/JavaScript linting and formatting.\nmodel: claude-haiku-4-5-20251001\n---\n\n!`${CLAUDE_PLUGIN_ROOT}/scripts/typescript-lint-project.sh $ARGUMENT`\n",
        "plugins/typescript-lint/hooks/hooks.json": "{\n  \"hooks\": [\n    {\n      \"name\": \"typescript-lint\",\n      \"event\": \"PostToolUse\",\n      \"matcher\": \"Edit|Write\",\n      \"executable\": \"${CLAUDE_PLUGIN_ROOT}/hooks/typescript-lint.sh\",\n      \"timeout\": 30000\n    }\n  ]\n}\n",
        "plugins/typescript-lint/hooks/typescript-lint.sh": "#!/usr/bin/env bash\n\n# typescript-lint.sh - TypeScript/JavaScript linting hook\n# Runs after Edit/Write operations to format and lint files\n\nset -euo pipefail\n\n# File size limit (1MB)\nMAX_FILE_SIZE=1048576\n\n# Helper function to generate JSON responses safely using jq\njson_response() {\n  local decision=\"$1\"\n  local reason=\"$2\"\n  local event_name=\"${3:-}\"\n  local context=\"${4:-}\"\n\n  if [[ -n \"$event_name\" && -n \"$context\" ]]; then\n    jq -n \\\n      --arg decision \"$decision\" \\\n      --arg reason \"$reason\" \\\n      --arg event_name \"$event_name\" \\\n      --arg context \"$context\" \\\n      '{\n        decision: $decision,\n        reason: $reason,\n        hookSpecificOutput: {\n          hookEventName: $event_name,\n          additionalContext: $context\n        }\n      }'\n  else\n    jq -n \\\n      --arg decision \"$decision\" \\\n      --arg reason \"$reason\" \\\n      '{\n        decision: $decision,\n        reason: $reason\n      }'\n  fi\n}\n\n# Read JSON input from stdin and parse safely\nINPUT=$(cat)\nFILE_PATH=$(echo \"$INPUT\" | jq -r '.tool_input.file_path // empty' 2>/dev/null || echo \"\")\n\n# Validate file path\nif [[ -z \"$FILE_PATH\" ]]; then\n  json_response \"allow\" \"No file path provided\"\n  exit 0\nfi\n\n# Check if file exists\nif [[ ! -f \"$FILE_PATH\" ]]; then\n  json_response \"allow\" \"File does not exist\"\n  exit 0\nfi\n\n# Check file extension\ncase \"$FILE_PATH\" in\n  *.js|*.jsx|*.ts|*.tsx|*.mjs|*.cjs|*.mts|*.cts)\n    # Supported file type, continue\n    ;;\n  *)\n    EXT=\"${FILE_PATH##*.}\"\n    json_response \"allow\" \"File extension .$EXT is not supported for linting\"\n    exit 0\n    ;;\nesac\n\n# Check file size\nFILE_SIZE=$(wc -c < \"$FILE_PATH\" | tr -d ' ')\nif [[ $FILE_SIZE -gt $MAX_FILE_SIZE ]]; then\n  SIZE_MB=$(awk \"BEGIN {printf \\\"%.2f\\\", $FILE_SIZE/1024/1024}\")\n  json_response \"allow\" \"File is too large (${SIZE_MB}MB) to lint automatically\"\n  exit 0\nfi\n\n# Find project root by walking up from file's directory\nfind_project_root() {\n  local dir=\"$(cd \"$(dirname \"$FILE_PATH\")\" && pwd)\"\n  while [[ \"$dir\" != \"/\" ]]; do\n    if [[ -f \"$dir/package.json\" ]] || [[ -f \"$dir/tsconfig.json\" ]] || [[ -d \"$dir/.git\" ]]; then\n      echo \"$dir\"\n      return 0\n    fi\n    dir=\"$(dirname \"$dir\")\"\n  done\n  # Default to file's directory\n  echo \"$(cd \"$(dirname \"$FILE_PATH\")\" && pwd)\"\n}\n\nPROJECT_ROOT=$(find_project_root)\ncd \"$PROJECT_ROOT\"\n\n# Check if required tools are installed\nMISSING_TOOLS=()\n\nif ! command -v npx >/dev/null 2>&1; then\n  MISSING_TOOLS+=(\"npx\")\nfi\n\nif ! command -v jq >/dev/null 2>&1; then\n  MISSING_TOOLS+=(\"jq\")\nfi\n\n# If any critical tools are missing, report and exit\nif [[ ${#MISSING_TOOLS[@]} -gt 0 ]]; then\n  TOOLS_LIST=$(IFS=\", \"; echo \"${MISSING_TOOLS[*]}\")\n  json_response \"allow\" \"Missing required tools: $TOOLS_LIST. Install with: brew install $TOOLS_LIST\"\n  exit 0\nfi\n\nMISSING_DEPS=()\nif ! npx prettier --version >/dev/null 2>&1; then\n  MISSING_DEPS+=(\"prettier\")\nfi\n\nif ! npx eslint --version >/dev/null 2>&1; then\n  MISSING_DEPS+=(\"eslint\")\nfi\n\nif [[ ${#MISSING_DEPS[@]} -gt 0 ]]; then\n  DEPS_STR=\"${MISSING_DEPS[*]}\"\n  json_response \"allow\" \"Missing dependencies: $DEPS_STR. Install with: npm install --save-dev $DEPS_STR\"\n  exit 0\nfi\n\n# Format with Prettier\nif ! PRETTIER_OUTPUT=$(npx prettier --write \"$FILE_PATH\" 2>&1); then\n  # Extract first line of error\n  ERROR_LINE=$(echo \"$PRETTIER_OUTPUT\" | head -1)\n  json_response \"allow\" \"Prettier formatting failed: $ERROR_LINE\"\n  exit 0\nfi\n\n# Lint with ESLint\nESLINT_EXIT=0\nESLINT_OUTPUT=$(npx eslint --fix --format json \"$FILE_PATH\" 2>&1) || ESLINT_EXIT=$?\n\n# Extract JSON array from output (in case there are warnings on stderr)\n# Find the first line starting with '[' and take everything from there\nESLINT_JSON=$(echo \"$ESLINT_OUTPUT\" | sed -n '/^\\[/,$p')\n\n# Check if we got valid JSON\nif [[ -z \"$ESLINT_JSON\" ]] || ! echo \"$ESLINT_JSON\" | jq -e . >/dev/null 2>&1; then\n  # No valid JSON - check if it's a configuration error\n  if echo \"$ESLINT_OUTPUT\" | grep -qi \"no eslint configuration\\|could not find.*config\\|error.*config\"; then\n    ERROR_LINE=$(echo \"$ESLINT_OUTPUT\" | grep -i \"config\" | head -1)\n    json_response \"allow\" \"ESLint config error: $ERROR_LINE\"\n    exit 0\n  fi\n  # Treat as empty result\n  ESLINT_JSON=\"[]\"\nfi\n\n# Parse ESLint JSON output to count errors and warnings\n# ESLint JSON format: array of results, each with messages array\n# Each message has severity: 1 (warning) or 2 (error)\nERROR_COUNT=$(echo \"$ESLINT_JSON\" | jq '[.[].messages[] | select(.severity == 2)] | length' 2>/dev/null || echo \"0\")\nWARNING_COUNT=$(echo \"$ESLINT_JSON\" | jq '[.[].messages[] | select(.severity == 1)] | length' 2>/dev/null || echo \"0\")\n\n# Extract error and warning messages (limit to 10 each)\nERRORS=$(echo \"$ESLINT_JSON\" | jq -r '\n  [.[].messages[] | select(.severity == 2)]\n  | .[0:10]\n  | map(\"  - line \\(.line):\\(.column) [\\(.ruleId // \"unknown\")] \\(.message)\")\n  | join(\"\\n\")\n' 2>/dev/null || echo \"\")\n\nWARNINGS=$(echo \"$ESLINT_JSON\" | jq -r '\n  [.[].messages[] | select(.severity == 1)]\n  | .[0:10]\n  | map(\"  - line \\(.line):\\(.column) [\\(.ruleId // \"unknown\")] \\(.message)\")\n  | join(\"\\n\")\n' 2>/dev/null || echo \"\")\n\n# If there are errors, block with detailed message\nif [[ ${ERROR_COUNT:-0} -gt 0 ]]; then\n  ERROR_MSG=\"TypeScript/JavaScript linting found $ERROR_COUNT error(s) that require manual fixes\"\n\n  # Build context with errors\n  ERROR_DETAIL=\"ESLint Errors ($ERROR_COUNT):\"\n  if [[ -n \"$ERRORS\" ]]; then\n    ERROR_DETAIL=\"$ERROR_DETAIL\"$'\\n'\"$ERRORS\"\n  fi\n\n  if [[ $ERROR_COUNT -gt 10 ]]; then\n    REMAINING=$((ERROR_COUNT - 10))\n    ERROR_DETAIL=\"$ERROR_DETAIL\"$'\\n'\"... and $REMAINING more\"\n  fi\n\n  json_response \"block\" \"$ERROR_MSG\" \"PostToolUse\" \"$ERROR_DETAIL\"\n  exit 0\nfi\n\n# If there are warnings, allow but report them\nif [[ ${WARNING_COUNT:-0} -gt 0 ]]; then\n  WARNING_MSG=\"Linting complete. $WARNING_COUNT warning(s) found.\"\n\n  # Build context with warnings\n  WARNING_DETAIL=\"ESLint Warnings ($WARNING_COUNT):\"\n  if [[ -n \"$WARNINGS\" ]]; then\n    WARNING_DETAIL=\"$WARNING_DETAIL\"$'\\n'\"$WARNINGS\"\n  fi\n\n  if [[ $WARNING_COUNT -gt 10 ]]; then\n    REMAINING=$((WARNING_COUNT - 10))\n    WARNING_DETAIL=\"$WARNING_DETAIL\"$'\\n'\"... and $REMAINING more\"\n  fi\n\n  json_response \"allow\" \"$WARNING_MSG\" \"PostToolUse\" \"$WARNING_DETAIL\"\n  exit 0\nfi\n\n# Success - file was formatted and/or linted with no issues\njson_response \"allow\" \"Linting complete. File was formatted and auto-fixed.\"\nexit 0\n"
      },
      "plugins": [
        {
          "name": "research",
          "description": "A research toolkit for claude code",
          "source": "./plugins/research",
          "author": {
            "name": "Cheolwan Park",
            "url": "https://github.com/cheolwanpark"
          },
          "repository": "https://github.com/cheolwanpark/useful-claude-plugins",
          "license": "MIT",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add cheolwanpark/claude-plugins",
            "/plugin install research@personal-curation"
          ]
        },
        {
          "name": "python-lint",
          "description": "Automatically lint, format, and type-check Python files with ruff and pyright",
          "source": "./plugins/python-lint",
          "author": {
            "name": "Cheolwan Park",
            "url": "https://github.com/cheolwanpark"
          },
          "repository": "https://github.com/cheolwanpark/useful-claude-plugins",
          "license": "MIT",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add cheolwanpark/claude-plugins",
            "/plugin install python-lint@personal-curation"
          ]
        },
        {
          "name": "auto-review",
          "description": "Automated code review using gemini-cli and codex",
          "source": "./plugins/auto-review",
          "author": {
            "name": "Cheolwan Park",
            "url": "https://github.com/cheolwanpark"
          },
          "repository": "https://github.com/cheolwanpark/useful-claude-plugins",
          "license": "MIT",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add cheolwanpark/claude-plugins",
            "/plugin install auto-review@personal-curation"
          ]
        },
        {
          "name": "typescript-lint",
          "description": "Automatically lint, format, and type-check TypeScript files with ESLint and TypeScript compiler",
          "source": "./plugins/typescript-lint",
          "author": {
            "name": "Cheolwan Park",
            "url": "https://github.com/cheolwanpark"
          },
          "repository": "https://github.com/cheolwanpark/useful-claude-plugins",
          "license": "MIT",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add cheolwanpark/claude-plugins",
            "/plugin install typescript-lint@personal-curation"
          ]
        },
        {
          "name": "rust-lint",
          "description": "Automatically format Rust files with rustfmt and provide on-demand clippy linting",
          "source": "./plugins/rust-lint",
          "author": {
            "name": "Cheolwan Park",
            "url": "https://github.com/cheolwanpark"
          },
          "repository": "https://github.com/cheolwanpark/useful-claude-plugins",
          "license": "MIT",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add cheolwanpark/claude-plugins",
            "/plugin install rust-lint@personal-curation"
          ]
        },
        {
          "name": "go-lint",
          "description": "Automatically lint and format Go files using goimports, go vet, and golangci-lint",
          "source": "./plugins/go-lint",
          "author": {
            "name": "Cheolwan Park",
            "url": "https://github.com/cheolwanpark"
          },
          "repository": "https://github.com/cheolwanpark/useful-claude-plugins",
          "license": "MIT",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add cheolwanpark/claude-plugins",
            "/plugin install go-lint@personal-curation"
          ]
        },
        {
          "name": "search",
          "description": "Access up-to-date library documentation and code examples via Context7 API",
          "source": "./plugins/search",
          "author": {
            "name": "Cheolwan Park",
            "url": "https://github.com/cheolwanpark"
          },
          "repository": "https://github.com/cheolwanpark/useful-claude-plugins",
          "license": "MIT",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add cheolwanpark/claude-plugins",
            "/plugin install search@personal-curation"
          ]
        },
        {
          "name": "crypto",
          "description": "Multi-chain blockchain explorer using Foundry's cast CLI for Etherscan, Polygonscan, Arbiscan, and more",
          "source": "./plugins/crypto",
          "author": {
            "name": "Cheolwan Park",
            "url": "https://github.com/cheolwanpark"
          },
          "repository": "https://github.com/cheolwanpark/useful-claude-plugins",
          "license": "MIT",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add cheolwanpark/claude-plugins",
            "/plugin install crypto@personal-curation"
          ]
        }
      ]
    }
  ]
}