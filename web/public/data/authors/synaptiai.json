{
  "author": {
    "id": "synaptiai",
    "display_name": "Synapti.ai",
    "avatar_url": "https://avatars.githubusercontent.com/u/201232789?v=4"
  },
  "marketplaces": [
    {
      "name": "synapti-marketplace",
      "version": null,
      "description": "Synapti plugin marketplace",
      "repo_full_name": "synaptiai/synapti-marketplace",
      "repo_url": "https://github.com/synaptiai/synapti-marketplace",
      "repo_description": "The Synapti Marketplace is a curated collection of Claude Code plugins designed for AI-augmented development + advanced analytical and research tasks. Each plugin provides specialized agents, skills, and commands that extend Claude Code's capabilities in specific domains.",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-01-28T16:07:24Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"synapti-marketplace\",\n  \"owner\": {\n    \"name\": \"Daniel Bentes\",\n    \"email\": \"daniel.bentes@synapti.ai\"\n  },\n  \"metadata\": {\n    \"description\": \"Synapti plugin marketplace\",\n    \"version\": \"2.7.0\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"decipon\",\n      \"source\": \"./plugins/decipon\",\n      \"description\": \"NCI manipulation detection with deep research fact-checking - analyzes content for propaganda, disinformation, and manipulation patterns across 20 categories with integrated claim verification\",\n      \"version\": \"1.5.0\",\n      \"author\": {\n        \"name\": \"Daniel Bentes\"\n      },\n      \"homepage\": \"https://github.com/synaptiai/synapti-marketplace\",\n      \"repository\": \"https://github.com/synaptiai/synapti-marketplace\",\n      \"license\": \"MIT\",\n      \"category\": \"analysis\",\n      \"keywords\": [\n        \"manipulation-detection\",\n        \"disinformation\",\n        \"propaganda\",\n        \"fact-checking\",\n        \"deep-research\",\n        \"claim-verification\",\n        \"media-literacy\",\n        \"nci-protocol\",\n        \"narrative-credibility-index\"\n      ],\n      \"tags\": [\n        \"psyops\",\n        \"fact-checking\",\n        \"deep-research\",\n        \"claim-verification\",\n        \"media-literacy\",\n        \"nci-protocol\",\n        \"narrative-credibility-index\"\n      ]\n    },\n    {\n      \"name\": \"gh-workflow\",\n      \"source\": \"./plugins/gh-workflow\",\n      \"description\": \"Generic GitHub workflow commands for issue management, PR creation, code review, and releases. Works with any repository by auto-detecting settings.\",\n      \"version\": \"1.2.0\",\n      \"author\": {\n        \"name\": \"Daniel Bentes\"\n      },\n      \"homepage\": \"https://github.com/synaptiai/synapti-marketplace\",\n      \"repository\": \"https://github.com/synaptiai/synapti-marketplace\",\n      \"license\": \"MIT\",\n      \"category\": \"workflow\",\n      \"keywords\": [\n        \"github\",\n        \"workflow\",\n        \"git\",\n        \"pr\",\n        \"pull-request\",\n        \"issue\",\n        \"code-review\",\n        \"release\",\n        \"automation\"\n      ],\n      \"tags\": [\n        \"github\",\n        \"workflow\",\n        \"git\",\n        \"automation\",\n        \"development\"\n      ]\n    },\n    {\n      \"name\": \"context-ledger\",\n      \"source\": \"./plugins/context-ledger\",\n      \"description\": \"Evidence-based product development with traceable decisions, constrained spec generation, and impact-aware updates. Forces auditability through semantic IDs and quality gates.\",\n      \"version\": \"1.0.0\",\n      \"author\": {\n        \"name\": \"Daniel Bentes\"\n      },\n      \"homepage\": \"https://github.com/synaptiai/synapti-marketplace\",\n      \"repository\": \"https://github.com/synaptiai/synapti-marketplace\",\n      \"license\": \"MIT\",\n      \"category\": \"product-development\",\n      \"keywords\": [\n        \"product-development\",\n        \"evidence-based\",\n        \"decision-ledger\",\n        \"traceability\",\n        \"prd\",\n        \"architecture\",\n        \"risk-management\",\n        \"constrained-generation\",\n        \"semantic-ids\",\n        \"quality-gates\"\n      ],\n      \"tags\": [\n        \"product-development\",\n        \"evidence-based\",\n        \"decisions\",\n        \"traceability\",\n        \"planning\"\n      ]\n    },\n    {\n      \"name\": \"agent-capability-standard\",\n      \"source\": \"./plugins/agent-capability-standard\",\n      \"description\": \"Grounded Agency: 36 atomic capabilities with typed contracts, safety-by-construction, and grounded reasoning for reliable AI agents\",\n      \"version\": \"1.1.1\",\n      \"author\": {\n        \"name\": \"Daniel Bentes\"\n      },\n      \"homepage\": \"https://github.com/synaptiai/agent-capability-standard\",\n      \"repository\": \"https://github.com/synaptiai/agent-capability-standard\",\n      \"license\": \"Apache-2.0\",\n      \"category\": \"agent-framework\",\n      \"keywords\": [\n        \"ai-agents\",\n        \"capability-ontology\",\n        \"grounded-agency\",\n        \"workflow-dsl\",\n        \"safety\",\n        \"checkpoints\",\n        \"provenance\",\n        \"trust-model\",\n        \"world-modeling\"\n      ],\n      \"tags\": [\n        \"agents\",\n        \"safety\",\n        \"workflows\",\n        \"validation\",\n        \"grounded-agency\"\n      ]\n    }\n  ]\n}\n",
        "README.md": "# Synapti Plugin Marketplace\n\n> Agentic harnesses for Claude Code — specialized AI agents for complex analytical tasks\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)\n[![Claude Code](https://img.shields.io/badge/Claude%20Code-Plugin-orange.svg)](https://claude.com/claude-code)\n[![Plugins](https://img.shields.io/badge/Plugins-4-green.svg)](#available-plugins)\n\n## About the Marketplace\n\nThe **Synapti Plugin Marketplace** is a curated collection of Claude Code plugins designed for advanced analytical and research tasks. Each plugin provides specialized agents, skills, and commands that extend Claude Code's capabilities in specific domains.\n\n### How to Use\n\n1. Add the marketplace: `claude plugin marketplace add synaptiai/synapti-marketplace`\n2. Browse the [Available Plugins](#available-plugins) below\n3. Install using `claude plugin install <plugin-name>`\n4. Use plugin commands with the `/plugin:command` syntax\n\n---\n\n## Available Plugins\n\n| Plugin | Category | Description | Version |\n|--------|----------|-------------|---------|\n| [Agent Capability Standard ↗](https://github.com/synaptiai/agent-capability-standard) | Standards, Agent Development | Technical specification for AI agents with structural reliability. 99 atomic capabilities across 8 layers with reference workflows and safety-by-construction patterns. | 1.0.0 |\n| [Context Ledger](./plugins/context-ledger/) | Product Development | Evidence-based product development with traceable decisions, explicit trade-offs, and constrained spec generation. | 1.0.0 |\n| [Decipon](./plugins/decipon/) | Content Analysis, Deep Research | Detects manipulation, propaganda, and disinformation patterns using the NCI Protocol. Analyzes content across 20 indicators with fact-checking capabilities. | 1.3.1 |\n| [gh-workflow](./plugins/gh-workflow/) | Workflow, Automation | Generic GitHub workflow commands for issue management, PR creation, code review, and releases. Works with any repository by auto-detecting settings. | 1.2.0 |\n\n### When to Use Each Plugin\n\n| I want to... | Use |\n|--------------|-----|\n| Design agents with formal capability contracts | [Agent Capability Standard](#featured-agent-capability-standard) |\n| Validate agent workflows for completeness | [Agent Capability Standard](#featured-agent-capability-standard) |\n| Ensure safety-by-construction patterns in agents | [Agent Capability Standard](#featured-agent-capability-standard) |\n| Build a product with evidence-backed decisions | [Context Ledger](#featured-context-ledger) `/ledger-full` |\n| Research all aspects of a product idea in parallel | [Context Ledger](#featured-context-ledger) `/ledger-research` |\n| Make explicit decisions with documented trade-offs | [Context Ledger](#featured-context-ledger) `/ledger-decide` |\n| Generate PRDs where every section traces to evidence | [Context Ledger](#featured-context-ledger) `/ledger-spec` |\n| Analyze articles, social media posts, or news for manipulation | [Decipon](#featured-decipon) `/decipon:analyze` |\n| Quickly triage content before deeper analysis | [Decipon](#featured-decipon) `/decipon:score` |\n| Research a complex topic with verified sources | [Decipon](#featured-decipon) `/decipon:deep-research` |\n| Fact-check claims in content | [Decipon](#featured-decipon) `/decipon:verify` |\n| Check my workflow status (issues, PRs, reviews) | [gh-workflow](#featured-gh-workflow) `/gh-workflow:gh-status` |\n| Create well-structured GitHub issues | [gh-workflow](#featured-gh-workflow) `/gh-workflow:gh-issue` |\n| Start implementing a GitHub issue | [gh-workflow](#featured-gh-workflow) `/gh-workflow:gh-start` |\n| Commit changes with context-aware classification | [gh-workflow](#featured-gh-workflow) `/gh-workflow:gh-commit` |\n| Create a PR with full review and reviewer suggestions | [gh-workflow](#featured-gh-workflow) `/gh-workflow:gh-pr` |\n| Review a pull request systematically | [gh-workflow](#featured-gh-workflow) `/gh-workflow:gh-review` |\n| Create releases with changelogs | [gh-workflow](#featured-gh-workflow) `/gh-workflow:gh-release` |\n\n---\n\n## Claude Desktop Compatibility\n\nSkills from this marketplace are also available for **Claude Desktop** users. Desktop-compatible skill packages are attached to each [GitHub Release](https://github.com/synaptiai/synapti-marketplace/releases).\n\n### What's Different?\n\n| Feature | Claude Code | Claude Desktop |\n|---------|-------------|----------------|\n| Installation | `claude plugin install` | Upload ZIP in Settings |\n| Commands | Full `/plugin:command` syntax | Skills only |\n| Agents | Supported | Not supported |\n| Frontmatter | All fields | `name`, `description` only |\n\n### How to Install Desktop Skills\n\n1. Go to the [Releases page](https://github.com/synaptiai/synapti-marketplace/releases)\n2. Download the `.zip` file for the skill you want (e.g., `deep-research.zip`)\n3. Open Claude Desktop → Settings → Skills\n4. Upload the ZIP file\n\n### Available Desktop Skills\n\n| Skill | Plugin | Description |\n|-------|--------|-------------|\n| `deep-research.zip` | Decipon | Comprehensive research using Time-Tested Diffusion methodology |\n| `nci-analysis.zip` | Decipon | NCI Protocol for manipulation detection |\n| `repo-config.zip` | gh-workflow | Dynamic repository configuration |\n| `suggest-users.zip` | gh-workflow | Reviewer and assignee suggestions based on expertise |\n\n> **Note**: Desktop packages are automatically generated during releases. They contain the same skill content with Claude Code-specific frontmatter fields (`context`, `agent`, `hooks`, etc.) removed for compatibility.\n\n---\n\n## Featured: Context Ledger\n\n**Context Ledger** provides evidence-based product development — from initial research through implementation planning — where every requirement traces back to explicit decisions and documented evidence.\n\n### Why Context Ledger?\n\nTraditional product development starts with vibes and ends with specs that nobody trusts:\n- **Specs drift from reality** — PRDs reference decisions that were never formally made\n- **Assumptions hide in prose** — Trade-offs buried in paragraph 47 of a 200-page doc\n- **Evidence disappears** — \"Studies show...\" but which studies? From when?\n\n### Key Insight\n\n> If you can't trace every spec requirement back to evidence and an explicit decision, you're shipping guesswork. Context Ledger enforces traceability at every stage.\n\n### What Makes It Different\n\n| Feature | Benefit |\n|---------|---------|\n| **Evidence Objects** | Atomic, traceable research with confidence scores and assumptions |\n| **Decision Ledger** | Every decision documents alternatives, wins, loses, and risks created |\n| **Constrained Specs** | PRDs cannot exist without DEC-* references — no vibes allowed |\n| **Quality Gates** | Pipeline won't proceed until evidence and decision minimums are met |\n| **Impact Reports** | Updates show exactly what downstream artifacts need regeneration |\n\n### Commands\n\n| Command | What It Does |\n|---------|-------------|\n| `/ledger-full` | Run complete pipeline end-to-end with mode selection |\n| `/ledger-init` | Initialize workspace with brief and pillar map |\n| `/ledger-research` | Parallel evidence collection across 8 pillars |\n| `/ledger-synthesize` | Per-pillar + cross-pillar synthesis |\n| `/ledger-decide` | Make explicit decisions with trade-offs |\n| `/ledger-spec` | Generate constrained PRD + architecture |\n| `/ledger-plan` | Create implementation plan with milestones |\n| `/ledger-update` | Apply learnings with impact report |\n\n### Execution Modes\n\n| Mode | Parallelism | Best For |\n|------|-------------|----------|\n| `--mode optimizer` | 3 agents/pillar | Standard projects, overnight runs |\n| `--mode tokenburner` | 30+ agents/pillar | Hackathons, rapid exploration |\n| `--mode ralph` | Stop hook autonomous | Walk-away overnight execution |\n\nAdd `--self-improve` to any mode for gap analysis loops.\n\n### Installation\n\n```bash\n# Add the marketplace (one-time setup)\nclaude plugin marketplace add synaptiai/synapti-marketplace\n\n# Install the plugin\nclaude plugin install context-ledger\n```\n\n### The Complete Pipeline\n\n```\n/ledger-init → /ledger-research → /ledger-synthesize → /ledger-decide → /ledger-spec → /ledger-plan\n     │              │                    │                   │               │             │\n     ▼              ▼                    ▼                   ▼               ▼             ▼\n  Brief +       Evidence            Synthesis           Decisions        PRD +          Plan\n  Pillars       Objects               Files              + Risks        Arch           + Tests\n```\n\n**[Full Context Ledger Documentation →](./plugins/context-ledger/README.md)**\n\n---\n\n## Featured: Decipon\n\n**Decipon** implements the **NCI (Narrative Credibility Index) Protocol** — a pattern-based system for detecting manipulation, propaganda, and disinformation in content. Unlike fact-checkers, Decipon analyzes *how* content tries to influence people, not whether claims are true or false.\n\n### Key Insight\n\n> A factually accurate article can still use manipulation techniques. A false claim can be presented without manipulation. Decipon detects the **techniques**, not the truth value.\n\n### Installation\n\n```bash\n# Add the marketplace (one-time setup)\nclaude plugin marketplace add synaptiai/synapti-marketplace\n\n# Install the plugin\nclaude plugin install decipon\n```\n\n### Commands\n\n| Command | Description |\n|---------|-------------|\n| `/decipon:score <content>` | Quick manipulation score (0-100) for rapid triage |\n| `/decipon:analyze <content>` | Full 20-category NCI analysis with dual perspectives |\n| `/decipon:verify <content>` | Fact-check claims using deep research methodology |\n| `/decipon:report <content>` | Generate formal JSON/Markdown report for archiving |\n| `/decipon:deep-research <topic>` | Comprehensive research using Time-Tested Diffusion |\n| `/decipon:quick-research <question>` | Quick research with source verification |\n| `/decipon:critique <content>` | Red team adversarial critique |\n\n### Recommended Workflow\n\n```\n┌─────────┐     ┌─────────┐     ┌─────────┐     ┌─────────┐\n│  Score  │ ──▶ │ Analyze │ ──▶ │ Verify  │ ──▶ │ Report  │\n│ (0-100) │     │(if >25) │     │(if >50) │     │(archive)│\n└─────────┘     └─────────┘     └─────────┘     └─────────┘\n```\n\n### Severity Scale\n\n| Score | Indicator | Recommended Action |\n|-------|-----------|-------------------|\n| 0-25 | Low [·] | Normal consumption |\n| 26-50 | Moderate [!] | Verify key claims |\n| 51-75 | High [!!] | Cross-reference sources, strong skepticism |\n| 76-100 | Severe [!!!] | Likely manipulation |\n\n### The NCI Framework\n\nAnalyzes 20 manipulation categories across 5 composite factors:\n\n| Factor | Weight | What It Detects |\n|--------|--------|-----------------|\n| Emotional Manipulation | 25% | Fear, urgency, manufactured outrage |\n| Suspicious Timing | 20% | Convenient emergence, beneficiary patterns |\n| Uniform Messaging | 20% | Coordinated talking points, bandwagon effects |\n| Tribal Division | 15% | Us-vs-them framing, false dilemmas |\n| Missing Information | 20% | Context gaps, cherry-picking, logical fallacies |\n\n**[Full Decipon Documentation →](./plugins/decipon/README.md)**\n\n---\n\n## Featured: gh-workflow\n\n**gh-workflow** provides a complete GitHub development workflow — from issue creation through releases — that works with any repository without hardcoded configuration.\n\n### Why gh-workflow?\n\nTraditional approaches to GitHub automation often break when:\n- Repository settings change (branch renamed, labels modified)\n- Teams customize their workflow conventions\n- Commands assume specific project structures\n\n**gh-workflow solves this through dynamic detection** — every command discovers your repository's actual configuration at runtime.\n\n### Key Insight\n\n> Issues that specify implementation details (\"add a component to src/views/\") become obsolete when code is refactored. **Solution-agnostic issues** describe *what* should happen, not *how* — surviving any refactoring.\n\n### What Makes It Different\n\n| Feature | Benefit |\n|---------|---------|\n| **Dynamic Detection** | Auto-detects default branch, labels, and repo settings — no hardcoding |\n| **Solution-Agnostic Issues** | Issues describe requirements, not implementation — survives refactoring |\n| **Interactive Workflows** | Guided prompts at decision points prevent mistakes |\n| **Complete Lifecycle** | Single plugin covers issues → implementation → review → merge → release |\n\n### Commands\n\n| Command | What It Does |\n|---------|-------------|\n| `/gh-workflow:gh-status` | View workflow status (assigned issues, open PRs, review requests) |\n| `/gh-workflow:gh-issue` | Create issues that focus on requirements, not implementation |\n| `/gh-workflow:gh-start <N>` | Assign issue, create branch, implement with task tracking |\n| `/gh-workflow:gh-commit` | Context-aware commits with change classification |\n| `/gh-workflow:gh-pr` | Create PR with full review and reviewer suggestions |\n| `/gh-workflow:gh-review <N>` | Systematic PR review with checklist and feedback |\n| `/gh-workflow:gh-address <N>` | Address review comments on a PR |\n| `/gh-workflow:gh-merge <N>` | Safely merge approved PRs |\n| `/gh-workflow:gh-release` | Create releases with automatic changelog generation |\n| `/gh-workflow:gh-setup` | Generate project-specific workflow configuration |\n\n### Installation\n\n```bash\n# Add the marketplace (one-time setup)\nclaude plugin marketplace add synaptiai/synapti-marketplace\n\n# Install the plugin\nclaude plugin install gh-workflow\n```\n\n### The Complete Development Cycle\n\n```\n/gh-status → /gh-issue → /gh-start → /gh-commit → /gh-pr → /gh-review → /gh-address → /gh-merge → /gh-release\n     │            │            │            │          │          │            │            │            │\n     ▼            ▼            ▼            ▼          ▼          ▼            ▼            ▼            ▼\n  View        Create      Branch +    Context-   Full PR    Review      Address      Merge       Tag +\n  status      issue      implement    aware      review       PR       comments       PR       changelog\n                                     commits    + suggest\n```\n\n**[Full gh-workflow Documentation →](./plugins/gh-workflow/README.md)**\n\n---\n\n## Featured: Agent Capability Standard\n\n**Agent Capability Standard** is a technical specification for building AI agents with structural reliability. It implements \"Grounded Agency\" — a framework ensuring agents operate with evidence-backed claims rather than hallucinations.\n\n> **External Repository**: This plugin is maintained at [synaptiai/agent-capability-standard](https://github.com/synaptiai/agent-capability-standard) and included as a git submodule.\n\n### Why Agent Capability Standard?\n\nMost AI agents today operate with:\n- **Hallucinated capabilities** — claiming skills they can't verify\n- **Opaque decision-making** — no audit trail for actions taken\n- **Brittle error handling** — mutations without rollback options\n- **Implicit contracts** — undefined inputs/outputs between components\n\n### Key Insight\n\n> If an agent can't prove it has a capability, it shouldn't claim to have it. Agent Capability Standard enforces grounded capabilities with explicit contracts and audit trails.\n\n### What Makes It Different\n\n| Feature | Benefit |\n|---------|---------|\n| **99 Atomic Capabilities** | Minimal, composable building blocks across 8 functional layers |\n| **Typed Contracts** | Explicit input/output schemas between capabilities |\n| **Safety-by-Construction** | Mutations require checkpoints; rollback always possible |\n| **Audit Trails** | Complete action lineage and provenance for every operation |\n| **Reference Workflows** | Battle-tested patterns for common agent tasks |\n\n### The 8 Capability Layers\n\n| Layer | Count | Purpose |\n|-------|-------|---------|\n| Perception | 4 | Inspection, searching, retrieval, reception |\n| Modeling | 45 | Detection, identification, estimation, forecasting |\n| Reasoning | 20 | Comparison, planning, decision-making, critique |\n| Action | 12 | Plan execution, generation, transformation |\n| Safety | 7 | Verification, checkpointing, rollback, auditing |\n| Meta | 6 | Discovery, prioritization |\n| Memory | 2 | Persistence, recall |\n| Coordination | 3 | Delegation, synchronization |\n\n### Reference Workflows\n\n| Workflow | Purpose |\n|----------|---------|\n| `debug_code_change` | Systematic debugging with evidence collection |\n| `world_model_build` | Construct grounded world models |\n| `capability_gap_analysis` | Identify missing capabilities |\n| `digital_twin_bootstrap` | Initialize agent mirrors |\n| `digital_twin_sync_loop` | Maintain synchronized state |\n\n### Installation\n\n```bash\n# Add the marketplace (one-time setup)\nclaude plugin marketplace add synaptiai/synapti-marketplace\n\n# Install the plugin\nclaude plugin install agent-capability-standard\n```\n\n**[Full Agent Capability Standard Documentation →](https://github.com/synaptiai/agent-capability-standard)**\n\n---\n\n## Repository Structure\n\n```\nsynapti-marketplace/\n├── README.md                          # This file\n├── .claude-plugin/\n│   └── marketplace.json               # Marketplace configuration\n└── plugins/\n    ├── agent-capability-standard/     # AI agent standards (submodule)\n    │   ├── .claude-plugin/\n    │   │   └── plugin.json            # Plugin metadata\n    │   ├── README.md                  # Full specification\n    │   ├── spec/                      # YAML specifications\n    │   └── tools/                     # Validation scripts\n    │\n    ├── context-ledger/                # Evidence-based product development\n    │   ├── .claude-plugin/\n    │   │   └── plugin.json            # Plugin metadata\n    │   ├── README.md                  # Full plugin documentation\n    │   ├── agents/                    # 5 specialized agents\n    │   ├── commands/                  # 8 pipeline commands\n    │   ├── skills/                    # 5 methodology skills\n    │   └── templates/                 # Evidence/decision templates\n    │\n    ├── decipon/                       # Content analysis plugin\n    │   ├── .claude-plugin/\n    │   │   └── plugin.json            # Plugin metadata\n    │   ├── README.md                  # Full plugin documentation\n    │   ├── agents/                    # 5 specialized AI agents\n    │   ├── commands/                  # 7 user-facing commands\n    │   └── skills/                    # 2 methodology implementations\n    │\n    └── gh-workflow/                   # GitHub workflow plugin\n        ├── .claude-plugin/\n        │   └── plugin.json            # Plugin metadata\n        ├── README.md                  # Full plugin documentation\n        ├── agents/                    # 4 specialized agents\n        │   ├── code-reviewer.md       # Code quality review\n        │   ├── convention-checker.md  # Git convention validation\n        │   ├── implementation-planner.md # Task breakdown\n        │   └── test-runner.md         # Quality gate runner\n        ├── commands/                  # 10 workflow commands\n        │   ├── gh-status.md           # View workflow status\n        │   ├── gh-issue.md            # Create issues\n        │   ├── gh-start.md            # Start work on issue\n        │   ├── gh-commit.md           # Context-aware commits\n        │   ├── gh-pr.md               # Create PR with review\n        │   ├── gh-review.md           # Review PRs\n        │   ├── gh-address.md          # Address PR comments\n        │   ├── gh-merge.md            # Merge approved PRs\n        │   ├── gh-release.md          # Create releases\n        │   └── gh-setup.md            # Setup workflow config\n        ├── skills/                    # Dynamic configuration\n        │   ├── repo-config/           # Repository settings\n        │   ├── capability-discovery/  # Environment detection\n        │   └── suggest-users/         # Reviewer/assignee suggestions\n        └── templates/                 # Issue/PR templates\n```\n\n---\n\n## For Plugin Developers\n\nWant to contribute a plugin to the marketplace?\n\n### Plugin Structure Requirements\n\nEach plugin must include:\n\n```\nyour-plugin/\n├── .claude-plugin/\n│   └── plugin.json       # Required: name, version, description\n├── README.md             # Documentation\n├── agents/               # AI agent definitions (optional)\n├── commands/             # User-facing commands (optional)\n└── skills/               # Skill implementations (optional)\n```\n\n### plugin.json Format\n\n```json\n{\n  \"name\": \"your-plugin\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Brief description of what your plugin does\",\n  \"author\": { \"name\": \"Your Name\" },\n  \"license\": \"MIT\",\n  \"keywords\": [\"relevant\", \"keywords\"]\n}\n```\n\n### Submission Process\n\n1. Fork this repository\n2. Add your plugin to `plugins/`\n3. Update `.claude-plugin/marketplace.json` with your plugin entry\n4. Submit a pull request with documentation\n\n---\n\n## License\n\nThis project is licensed under the MIT License.\n\n## Credits\n\n**Author:** Daniel Bentes\n\n**Organization:** [Synapti](https://synapti.ai)\n\n**Repository:** [github.com/synaptiai/synapti-marketplace](https://github.com/synaptiai/synapti-marketplace)\n\n---\n\n<p align=\"center\">\n  <sub>Built for the Claude Code ecosystem</sub>\n</p>\n",
        "plugins/decipon/README.md": "# Decipon - Content Analysis & Deep Research Plugin\n\nA Claude Code plugin combining two powerful capabilities:\n\n1. **NCI Protocol** — Detects manipulation, propaganda, and disinformation patterns across 20 indicators\n2. **Deep Research** — Comprehensive research using Time-Tested Diffusion methodology with source verification\n\n---\n\n## Why Decipon?\n\n### The Problem with Traditional Fact-Checking\n\nMost content evaluation tools ask: \"Is this true or false?\" But this binary framing misses crucial nuances:\n\n- **Factually accurate content can still manipulate** — statistics can be cherry-picked, context can be omitted, emotional triggers can be exploited, all while every claim is technically true\n- **False claims can be presented without manipulation** — genuine mistakes, outdated information, and honest errors aren't propaganda\n- **Truth verification is slow and often impossible** — by the time claims are verified, the narrative has already spread\n\n### What Decipon Does Differently\n\nDecipon asks a different question: **\"How is this content trying to influence me?\"**\n\nThis pattern-based approach:\n- **Works instantly** — no external fact-checking databases required\n- **Catches sophisticated manipulation** — identifies techniques even when claims are true\n- **Provides actionable guidance** — severity levels with clear recommended actions\n- **Generates balanced perspectives** — shows both manipulative and legitimate interpretations\n\n### Who Benefits\n\n| Role | How Decipon Helps |\n|------|-------------------|\n| **Journalists** | Quick triage of sources, identify propaganda campaigns |\n| **Researchers** | Systematic analysis framework, reproducible methodology |\n| **Analysts** | Detect influence operations, track narrative patterns |\n| **Educators** | Teach media literacy with concrete examples |\n| **Anyone online** | Develop critical thinking about content consumption |\n\n---\n\n## Design Philosophy\n\n### Pattern Detection, Not Truth Arbitration\n\nDecipon deliberately avoids declaring content \"true\" or \"false.\" Instead, it identifies **manipulation techniques** — the rhetorical and psychological methods used to influence audiences. This design choice reflects several principles:\n\n1. **Truth is often unknowable in real-time** — verification takes time; manipulation detection doesn't\n2. **Techniques reveal intent** — heavy use of manipulation patterns suggests persuasion goals beyond information sharing\n3. **Users make final judgments** — Decipon provides evidence and scores; users decide what to believe\n\n### Dual Perspectives by Default\n\nEvery analysis generates two interpretations:\n- **Manipulative interpretation** — how this content could be designed to deceive\n- **Legitimate interpretation** — how this content could be genuine despite surface patterns\n\nThis forces intellectual honesty. Content that scores \"high risk\" might still be legitimate; content that scores \"low risk\" might still mislead. The dual perspective prevents false certainty.\n\n### Tiered Depth for Different Needs\n\nNot every piece of content needs a 20-category deep dive:\n- **Quick triage** (`/score`) — 5 seconds, single number, rapid filtering\n- **Full analysis** (`/analyze`) — comprehensive breakdown when scores warrant attention\n- **Verification** (`/verify`) — fact-checking integration when claims need confirmation\n- **Formal report** (`/report`) — archival documentation for serious concerns\n\n---\n\n## Overview\n\n### NCI Analysis\n\nDecipon analyzes content (text or URLs) across 20 manipulation indicators grouped into 5 composite factors:\n\n| Factor | Weight | Categories |\n|--------|--------|------------|\n| Emotional Manipulation | 25% | Base emotional triggers, urgency, novelty, repetition, manufactured outrage |\n| Suspicious Timing | 20% | Timing correlation, beneficiary analysis, historical parallels |\n| Uniform Messaging | 20% | Message uniformity, bandwagon effects, rapid shifts |\n| Tribal Division | 15% | Us-vs-them framing, simplistic narratives, false dilemmas |\n| Missing Information | 20% | Context gaps, authority issues, dissent suppression, cherry-picking, fallacies, framing |\n\n### Deep Research\n\nDecipon also provides standalone deep research capabilities using Time-Tested Diffusion methodology:\n- Iterative refinement through critique → research → refine cycles\n- Source scoring with confidence levels (1-100)\n- Contradiction detection and resolution\n- Comprehensive reports with methodology transparency\n\n## Installation\n\n```bash\n# Add the marketplace (one-time setup)\nclaude plugin marketplace add synaptiai/synapti-marketplace\n\n# Install the plugin\nclaude plugin install decipon\n```\n\n## Commands\n\n### `/decipon:analyze <content>`\n\nFull NCI analysis with 20-category scoring and dual perspectives.\n\n```bash\n/decipon:analyze https://example.com/article\n/decipon:analyze \"BREAKING: Shocking report reveals what they don't want you to know!\"\n```\n\n**What's Good About /analyze:**\n1. **Complete picture** — Scores all 20 manipulation categories with specific evidence from the content\n2. **Dual perspective generation** — Forces consideration of both manipulative and legitimate interpretations\n3. **Automatic deep research triggers** — When scores exceed thresholds, verification is recommended\n4. **Evidence-grounded** — Every score backed by specific quotes and patterns, not subjective impressions\n\n### `/decipon:score <content>`\n\nQuick manipulation score (0-100) for rapid triage.\n\n```bash\n/decipon:score https://example.com/article\n```\n\n**What's Good About /score:**\n1. **Instant filtering** — Get a single number in seconds to decide if deeper analysis is worthwhile\n2. **Batch processing** — Quickly triage multiple pieces of content before committing time\n3. **Clear thresholds** — Severity indicators ([·], [!], [!!], [!!!]) with recommended actions\n4. **Gateway to depth** — Low scores mean move on; high scores trigger full analysis\n\n### `/decipon:verify <content>`\n\nVerify factual claims using deep research methodology. Fact-checks key assertions and can update NCI scores.\n\n```bash\n/decipon:verify https://example.com/article\n/decipon:verify --claims \"90% of experts agree\" \"Studies show...\"\n```\n\n**What's Good About /verify:**\n1. **Bridges patterns to facts** — Combines manipulation detection with truth verification\n2. **Automatic claim extraction** — Identifies key factual assertions without manual selection\n3. **Score adjustment** — Updates NCI scores based on verification findings\n4. **Source confidence tracking** — Shows reliability of verification sources (1-100 scale)\n\n### `/decipon:report <content> [--format json|markdown] [--output filename]`\n\nGenerate formal report for sharing/archiving.\n\n```bash\n/decipon:report https://example.com/article --format json --output analysis.json\n```\n\n**What's Good About /report:**\n1. **Archival quality** — Structured format suitable for records and evidence\n2. **Shareable** — Export to JSON for systems or Markdown for humans\n3. **Complete methodology** — Includes analysis parameters for reproducibility\n4. **Timestamped** — Documents when analysis was performed\n\n### `/decipon:deep-research <topic>`\n\nConduct comprehensive research using Time-Tested Diffusion methodology.\n\n```bash\n/decipon:deep-research \"Current state of nuclear fusion energy\"\n```\n\n**What's Good About /deep-research:**\n1. **Iterative refinement** — Multiple cycles of critique → research → improve, like academic peer review\n2. **Contradiction tracking** — Explicitly identifies when sources disagree and attempts resolution\n3. **Source scoring** — Every fact tagged with confidence level and source type\n4. **Quality thresholds** — Continues refining until comprehensiveness and accuracy reach acceptable levels\n5. **Methodology transparency** — Report includes how research was conducted, not just conclusions\n\n### `/decipon:quick-research <question>`\n\nQuick research with source verification (2-3 searches, lighter than deep-research).\n\n```bash\n/decipon:quick-research \"When did NIF achieve fusion ignition?\"\n```\n\n**What's Good About /quick-research:**\n1. **Right-sized for simple questions** — 2-3 searches instead of 5-10+\n2. **Still verifies sources** — Maintains confidence scoring even for quick lookups\n3. **Clear scope** — Single-pass research for factual questions, not complex analysis\n4. **Escalation path** — Easy to upgrade to deep-research if complexity warrants\n\n### `/decipon:critique <content>`\n\nRed team adversarial critique of a document or claim.\n\n```bash\n/decipon:critique /path/to/document.md\n/decipon:critique \"90% of experts agree that...\"\n```\n\n**What's Good About /critique:**\n1. **Adversarial by design** — Actively tries to find weaknesses, not confirm strengths\n2. **Systematic weakness categories** — Logic flaws, evidence gaps, missing perspectives, accuracy issues\n3. **Severity scoring** — Prioritizes which weaknesses matter most\n4. **Actionable fixes** — Suggests how to address each identified weakness\n5. **Quality assurance** — Use on your own research reports before sharing\n\n## Recommended Workflow\n\n1. **Quick triage**: `/decipon:score` - Get initial manipulation score\n2. **Full analysis**: `/decipon:analyze` - If score > 25 (Moderate or higher)\n3. **Fact-check**: `/decipon:verify` - If score > 50 (High or higher)\n4. **Document**: `/decipon:report` - For formal records\n\n## Severity Scale\n\n| Score | Indicator | Risk Level |\n|-------|-----------|------------|\n| 0-25 | [·] | Low - Normal consumption |\n| 26-50 | [!] | Moderate - Verify claims |\n| 51-75 | [!!] | High - Cross-reference, strong skepticism |\n| 76-100 | [!!!] | Severe - Likely manipulation |\n\n## Key Features\n\n- **Pattern-based detection**: Identifies manipulation techniques regardless of truth value\n- **Dual perspectives**: Generates both manipulative and legitimate interpretations\n- **Evidence-grounded**: Every score backed by specific quotes/patterns\n- **URL support**: Fetches and analyzes web content via WebFetch\n- **Deep research**: Comprehensive research with iterative refinement and source verification\n- **Interactive workflows**: Structured dialogues using AskUserQuestion tool for better collaboration\n\n---\n\n## Interactive User Experience\n\nAll Decipon commands, agents, and skills use Claude Code's **AskUserQuestion tool** to enable structured, interactive dialogues at key decision points. This creates a better user experience through clear options with tradeoffs rather than open-ended questions.\n\n### When Interactive Dialogue Triggers\n\n| Trigger | Example |\n|---------|---------|\n| **Ambiguous input** | `/analyze` without content → asks for URL, text, or file |\n| **Borderline scores** | Score 35-55 → offers full analysis, verification, or accept |\n| **Multiple options** | 8 claims found → asks which to prioritize for verification |\n| **Contradictions** | Sources disagree → presents resolution options |\n| **Quality checkpoints** | After iteration 2 → continue refining or finalize? |\n\n### Example Interaction\n\n```\nUser: /analyze https://example.com/article\n\nClaude: Analyzing content...\n\nScore: 48/100 [!] (Moderate)\n\n[Uses AskUserQuestion tool]\nQuestion: \"This content scores 48 (Moderate) - in the borderline range. What next?\"\nOptions:\n  1. Run full analysis for detailed breakdown (Recommended)\n  2. Verify key claims with fact-checking\n  3. Generate formal report for sharing\n  4. Score is sufficient, no further action\n\nUser selects: Option 2\n\nClaude: [Proceeds to verify claims using deep research methodology]\n```\n\n### Benefits\n\n- **Clearer user intent**: Reduces misinterpretation of ambiguous requests\n- **Informed decisions**: Users see tradeoffs for each option\n- **Appropriate depth**: User controls triage vs. comprehensive analysis\n- **Transparent workflows**: Users understand what's happening and why\n\n---\n\n## Deep Research Methodology\n\nDecipon includes a complete deep research capability using **Time-Tested Diffusion** — an iterative methodology that treats research like a diffusion process: start with noise (rough draft), apply guidance (research brief), and denoise through cycles of critique → research → refine.\n\n### When to Use Deep Research\n\n| Use Case | Command |\n|----------|---------|\n| Complex questions requiring multiple sources | `/decipon:deep-research` |\n| State-of-the-art surveys | `/decipon:deep-research` |\n| Due diligence investigations | `/decipon:deep-research` |\n| Quick factual verification | `/decipon:quick-research` |\n| Adversarial critique of documents | `/decipon:critique` |\n\n### The Deep Research Workflow\n\n```\n1. Clarify scope (if ambiguous)\n2. Write research brief (guidance signal)\n3. Generate initial draft from knowledge (noisy starting point)\n4. Red team critique (identify gaps and weaknesses)\n5. Targeted web search with reflection\n6. Score sources and track contradictions\n7. Refine draft (denoise)\n8. Evaluate quality (score < 7? repeat 4-7, max 3 cycles)\n9. Finalize report\n```\n\n### Key Principles\n\n**Think After Every Search**: After each search, pause and reflect:\n- What key facts did I find?\n- What gaps remain?\n- Do sources agree or conflict?\n- Is another search needed?\n\n**Source Scoring (1-100)**:\n| Source Type | Confidence Range |\n|-------------|------------------|\n| Peer-reviewed, official docs | 85-100 |\n| Government/institutional | 75-90 |\n| Major news (Reuters, AP) | 70-85 |\n| Industry publications | 50-75 |\n| Blogs, forums | 20-50 |\n\n**Contradiction Handling**:\n1. Note contradictions explicitly\n2. Check publication dates (prefer recent)\n3. Evaluate source authority\n4. Search for tie-breaker sources\n5. If unresolved, present both views with confidence levels\n\n### Output Format\n\n```markdown\n# Research Report\n\n## Executive Summary\n[Key findings in 2-3 paragraphs]\n\n## Findings\n[Organized by research questions, with inline citations]\n\n## Methodology\n[Sources consulted, confidence levels, unresolved contradictions]\n\n## Limitations\n[Gaps, uncertainties, disputed claims]\n\n## Sources\n[Numbered list with confidence indicators]\n```\n\n### Quick Research vs Deep Research\n\n| Aspect | Quick Research | Deep Research |\n|--------|----------------|---------------|\n| Search budget | 2-3 searches | 5-10 searches |\n| Iterations | Single pass | Up to 3 refinement cycles |\n| Use when | Simple verification | Complex multi-faceted questions |\n| Output | Brief answer with sources | Comprehensive report |\n\n---\n\n## Architecture\n\n### Context Isolation\n\nDecipon leverages Claude Code's **forked context** feature for heavy analysis operations. Skills run in isolated sub-agent contexts, keeping the main conversation clean while performing multi-step analysis.\n\n```\n┌─────────────────────────────────────────────────┐\n│              Main Conversation                   │\n│  (stays clean, receives final results only)     │\n└──────────────────────┬──────────────────────────┘\n                       │ invokes\n          ┌────────────┴────────────┐\n          ▼                         ▼\n┌──────────────────┐      ┌──────────────────┐\n│  nci-analysis    │      │ deep-research    │\n│  skill (forked)  │      │ skill (forked)   │\n│                  │      │                  │\n│ - 20 categories  │      │ - Research brief │\n│ - Calculations   │      │ - 3 iterations   │\n│ - Perspectives   │      │ - Source scoring │\n└──────────────────┘      └──────────────────┘\n```\n\n### Benefits\n\n- **Reduced context usage** — Heavy analysis doesn't pollute main conversation\n- **Better isolation** — Skills do multi-step work independently\n- **Clean results** — Final reports returned without intermediate noise\n\n### Skills\n\n| Skill | Context | Agent | Purpose |\n|-------|---------|-------|---------|\n| `nci-manipulation-analysis` | `fork` | `general-purpose` | 20-category manipulation detection |\n| `conducting-deep-research` | `fork` | `general-purpose` | Time-Tested Diffusion methodology |\n\n### Agents\n\nThe plugin includes specialized agents, each designed for a specific analytical task:\n\n| Agent | Tools | Skills | Purpose |\n|-------|-------|--------|---------|\n| `deep-researcher` | Read, Write, Bash, Grep, Glob, WebSearch, WebFetch, AskUserQuestion | `conducting-deep-research` | Comprehensive research using TTD methodology |\n| `fact-checker` | Read, Bash, Grep, Glob, WebSearch, WebFetch, AskUserQuestion | `conducting-deep-research` | Verification specialist for claims |\n| `nci-analyzer` | Read, WebFetch, Grep, AskUserQuestion | `nci-manipulation-analysis` | Full NCI content analysis |\n| `claim-verifier` | Read, Grep, Glob, WebSearch, WebFetch, AskUserQuestion | `conducting-deep-research`, `nci-manipulation-analysis` | Verifies claims with both methodologies |\n| `perspective-generator` | Read, Grep, AskUserQuestion | `nci-manipulation-analysis` | Balanced dual perspectives |\n\n#### When to Use Each Agent\n\n| Scenario | Agent | Why |\n|----------|-------|-----|\n| \"I need to understand a complex topic thoroughly\" | `deep-researcher` | Multi-iteration research with source verification |\n| \"Is this specific claim true?\" | `fact-checker` | Focused verification with confidence scoring |\n| \"How manipulative is this content?\" | `nci-analyzer` | Full 20-category analysis with severity assessment |\n| \"I want both pattern analysis AND fact verification\" | `claim-verifier` | Combines NCI scoring with deep research |\n| \"Give me both sides of this content\" | `perspective-generator` | Balanced manipulative/legitimate interpretations |\n\n#### What Makes Each Agent Valuable\n\n**deep-researcher** — Goes beyond simple search by using iterative refinement. Each cycle: critique the current draft, research gaps, improve. Results in reports that have been stress-tested before delivery.\n\n**fact-checker** — Specializes in verification rather than discovery. When you already know what claims need checking, this agent focuses on finding authoritative sources that confirm or contradict.\n\n**nci-analyzer** — The core manipulation detection engine. Systematically evaluates content against 20 categories of manipulation techniques, generating quantified scores with specific evidence.\n\n**claim-verifier** — The hybrid specialist. Combines manipulation pattern detection with factual verification, useful when you need both \"how is this trying to influence me?\" and \"are the claims actually true?\"\n\n**perspective-generator** — Forces intellectual honesty by generating both charitable (legitimate) and critical (manipulative) interpretations of content, preventing confirmation bias in either direction.\n\n### Agent Skill Auto-Loading\n\nWhen an agent starts, it automatically loads its configured skills. This ensures:\n- **Consistent methodology** — Agents always have access to their skill workflows\n- **Reduced setup** — No manual skill invocation needed\n- **Cross-skill integration** — `claim-verifier` loads both skills for hybrid analysis\n\n## Deep Research + NCI Integration\n\nDeep research integrates directly with NCI analysis for automated fact-checking. When analyzing content, deep research is **automatically triggered** based on NCI scores.\n\n### Analysis Workflow (7 Steps)\n\n```\n1. Input Processing (text or URL)\n2. Score all 20 categories (1-5 scale)\n3. Calculate 5 composite factors\n4. Calculate overall score (0-100)\n5. Check deep research triggers ← Automatic verification\n6. Generate perspectives (manipulative + legitimate)\n7. Output report (includes verification results)\n```\n\n### Automatic Triggers\n\nDeep research is automatically triggered when ANY condition is met:\n\n| Trigger | Threshold | Verification Focus |\n|---------|-----------|-------------------|\n| Overall NCI Score | > 40 | Verify key claims |\n| Suspicious Timing | > 3 | Correlate events, timeline |\n| Authority Issues (Cat 16) | > 3 | Verify credentials |\n| Cherry-Picking (Cat 18) | > 3 | Find omitted context |\n| Historical Parallels | > 2 | Research precedent campaigns |\n\n### When Triggers Met\n\n1. Extract 3-5 key factual claims\n2. Invoke `fact-checker` agent\n3. Apply deep research methodology\n4. Track verification results\n5. Adjust NCI scores based on findings\n\n### Verification Capabilities\n\n- **Claim extraction**: Identifies key factual assertions\n- **Source evaluation**: Scores source confidence (1-100)\n- **Contradiction handling**: Tracks and resolves conflicting sources\n- **Score adjustment**: Updates NCI scores based on verification findings\n\n### Output Includes Verification\n\nWhen deep research is triggered, the report includes:\n\n```markdown\n## Claim Verification\n| Claim | Status | Confidence | Source |\n|-------|--------|------------|--------|\n| \"90% of experts...\" | CONTRADICTED | 85% | reuters.com |\n| \"Studies show...\" | VERIFIED | 90% | nature.com |\n\n**Score Adjustment**: 55 → 62 (+7 due to verification)\n```\n\n### Source Confidence Scale\n\n| Source Type | Confidence |\n|-------------|------------|\n| Peer-reviewed research | 85-100 |\n| Official documentation | 85-95 |\n| Government/institutional | 75-90 |\n| Major news (Reuters, AP) | 70-85 |\n| Industry publications | 50-75 |\n| Blogs/forums | 20-50 |\n\n## The 20 Categories\n\n### Emotional Manipulation\n1. Base Emotional Triggers - Fear, anger, hope exploitation\n2. Urgency Creation - Artificial time pressure\n3. Novelty/Exclusivity - \"Only we know\" framing\n4. Strategic Repetition - Key phrase hammering\n5. Manufactured Outrage - Anger amplification\n\n### Suspicious Timing\n6. Timing Correlation - Convenient narrative emergence\n7. Beneficiary Analysis - Who gains from belief\n8. Historical Parallels - Matches known campaigns\n\n### Uniform Messaging\n9. Message Uniformity - Identical talking points\n10. Bandwagon Effects - Social proof manipulation\n11. Rapid Narrative Shifts - Coordinated pivots\n\n### Tribal Division\n12. Us-vs-Them Framing - Enemy creation\n13. Simplistic Narratives - False simplicity\n14. False Dilemmas - Binary choice forcing\n\n### Missing Information\n15. Context Gaps - Strategic omissions\n16. Authority Issues - Credential manipulation\n17. Dissent Suppression - Alternative silencing\n18. Cherry-Picking - Selective evidence\n19. Logical Fallacies - Reasoning errors\n20. Framing/Priming - Perspective manipulation\n\n## Methodology\n\nThe NCI Protocol uses pattern recognition rather than truth evaluation:\n- Scores indicate manipulation risk, not accuracy\n- Low scores don't mean \"true\"\n- High scores don't mean \"false\"\n- Focus is on HOW content persuades, not WHAT it claims\n\n## Examples\n\nThe `examples/` folder contains real outputs demonstrating Decipon's capabilities:\n\n### Deep Research Report\n**[psyops-research-report-2025.md](examples/psyops-research-report-2025.md)**\n\nA comprehensive research report on the current state of psychological operations (PSYOP) techniques, produced using the `/decipon:deep-research` command. Demonstrates:\n- Time-Tested Diffusion methodology in action\n- Multi-source synthesis with confidence ratings\n- Balanced coverage of multiple state actors (Russia, China, Iran, US, Israel)\n- Structured findings with executive summary\n- Full source tracking with confidence levels (1-100)\n\n### Red Team Critique\n**[psyops-critique-2025.md](examples/psyops-critique-2025.md)**\n\nAn adversarial critique of the research report above, produced using the `/decipon:critique` command. Demonstrates:\n- Systematic weakness identification across 4 categories (Logic, Evidence, Coverage, Accuracy)\n- Severity scoring (1-10) with prioritization\n- Actionable fix recommendations\n- Quality assurance for research outputs\n\n### NCI Manipulation Analysis\n**[psyops-research-report-2025-nci-analysis.md](examples/psyops-research-report-2025-nci-analysis.md)**\n\nA full NCI analysis of the PSYOP research report, produced using the `/decipon:analyze` command. Demonstrates:\n- Complete 20-category scoring with evidence for each category\n- Composite factor calculations with weighted formulas\n- Overall manipulation score: **11/100 [·]** (Low risk)\n- Dual perspective generation (manipulative vs legitimate interpretations)\n- Deep research trigger checking\n- Visual \"Information Nutrition Label\" format\n\nKey finding: The research report scored low for manipulation despite covering manipulation techniques, demonstrating the NCI's ability to distinguish educational content from propaganda.\n\n### Example Workflow\n\n```bash\n# 1. Generate comprehensive research\n/decipon:deep-research \"Current state of psyops techniques\"\n\n# 2. Red team the output for weaknesses\n/decipon:critique @research-report.md\n\n# 3. Analyze for manipulation patterns (meta-analysis)\n/decipon:analyze @research-report.md\n\n# 4. Iterate based on critique and analysis findings\n```\n\n---\n\n## Real-World Scenarios\n\n### Scenario 1: News Article Triage\n\n**Situation:** A breaking news article is circulating on social media with alarming claims. You want to assess it quickly before sharing.\n\n```bash\n/decipon:score https://news-site.com/breaking-story\n\n# Output: 62/100 [!!] (High)\n# \"Recommend: Cross-reference sources, strong skepticism\"\n```\n\n**Next step:** The high score warrants deeper investigation.\n\n```bash\n/decipon:analyze https://news-site.com/breaking-story\n```\n\n**What you learn:** The article uses heavy emotional language (Category 1: 4/5), creates artificial urgency (Category 2: 4/5), and lacks source attribution (Category 16: 4/5). The dual perspective reveals the content could be legitimate reporting on an emotional topic, but the pattern of techniques suggests amplification for engagement.\n\n### Scenario 2: Due Diligence Research\n\n**Situation:** You're evaluating a company for investment and need comprehensive background research.\n\n```bash\n/decipon:deep-research \"TechCorp Inc business history and reputation\"\n```\n\n**What you get:**\n- Multi-source synthesis from news, regulatory filings, industry publications\n- Confidence scores for each finding (peer-reviewed sources: 85-100, industry blogs: 20-50)\n- Explicit tracking of contradictions between sources\n- Quality-checked output after up to 3 refinement cycles\n\n### Scenario 3: Content Creator Quality Check\n\n**Situation:** You've written a research report and want to ensure it's credible and doesn't inadvertently use manipulation techniques.\n\n```bash\n# First, critique for weaknesses\n/decipon:critique @my-research-report.md\n\n# Then, analyze for unintentional manipulation patterns\n/decipon:analyze @my-research-report.md\n```\n\n**What you learn:** The critique identifies logical gaps and missing perspectives. The NCI analysis confirms your report scores low for manipulation (educational content typically scores 5-20), but flags one area where emotional language crept in unintentionally.\n\n### Scenario 4: Viral Claim Investigation\n\n**Situation:** A specific claim is going viral: \"Studies show that X causes Y in 90% of cases.\"\n\n```bash\n/decipon:verify \"Studies show that X causes Y in 90% of cases\"\n```\n\n**What you get:**\n- Automatic extraction of verifiable assertions\n- Deep research verification of each claim\n- Source confidence ratings\n- Status: VERIFIED / PARTIALLY TRUE / CONTRADICTED / UNVERIFIABLE\n- Adjustment to any existing NCI scores based on findings\n\n## License\n\nMIT License - See LICENSE file for details.\n\n## Author\n\nDaniel Bentes\n\n## Repository\n\nhttps://github.com/synaptiai/synapti-marketplace\n",
        "plugins/gh-workflow/README.md": "# gh-workflow\n\nGeneric GitHub workflow commands for Claude Code. Provides a complete development workflow from issue creation through release.\n\n---\n\n## Why gh-workflow?\n\n### The Problem with Hardcoded Workflows\n\nMost GitHub automation tools embed assumptions about your repository:\n- Branch names like `main` or `master` are hardcoded\n- Labels are assumed to exist\n- PR templates are project-specific\n- Commands break when you customize your workflow\n\nThis creates fragile automation that works in demos but fails in real projects with real conventions.\n\n### What gh-workflow Does Differently\n\nEvery command **discovers your repository's actual configuration at runtime**:\n- Default branch? Detected via `gh repo view`\n- Available labels? Fetched via `gh label list`\n- Repository name? Queried, not assumed\n\nThis means the same commands work across all your repositories without modification.\n\n### The Solution-Agnostic Philosophy\n\nTraditional issue tracking often fails because issues describe **how** to implement something rather than **what** needs to be achieved:\n\n| Brittle Issue | Solution-Agnostic Issue |\n|---------------|------------------------|\n| \"Add DateFilter component to src/components/views/\" | \"Users can filter results by date\" |\n| \"Refactor UserService to use dependency injection\" | \"Authentication should be testable in isolation\" |\n| \"Update the onClick handler in Button.tsx\" | \"Click actions should provide feedback\" |\n\n**Why this matters:** When you refactor your codebase, solution-agnostic issues remain valid. Issues that specify file paths become obsolete the moment code moves.\n\ngh-workflow's `/gh-issue` command guides you toward solution-agnostic issue creation, ensuring your backlog survives refactoring.\n\n---\n\n## Design Philosophy\n\n### Interactive at Decision Points\n\nEvery command uses the **AskUserQuestion tool** at moments where your input matters:\n- Which branch type? (feature vs fix vs docs)\n- Which labels to apply?\n- Ready to create this PR?\n\nThis isn't just confirmation prompts — it's structured decision-making that prevents mistakes while keeping you in control.\n\n### Findings First, Questions Second\n\n**Critical principle:** Before asking for any decision, commands must display the findings that inform that decision.\n\n```\n❌ Wrong: \"What review decision would you like to submit?\"\n   (User hasn't seen what the review found)\n\n✅ Right: \"Here are the review findings: [detailed list]\n          Now, what review decision would you like to submit?\"\n```\n\nUsers need to see the evidence before making decisions. Every decision prompt follows the pattern:\n1. **First**, display the complete findings/preview\n2. **Then**, invoke the AskUserQuestion tool with options\n\n### Complete Lifecycle Coverage\n\nRather than a collection of unrelated commands, gh-workflow provides an integrated workflow:\n\n```\nIssue → Branch → Implementation → PR → Review → Merge → Release\n```\n\nEach step knows about the others. `/gh-start` reads the issue you're implementing. `/gh-review` knows what the PR is supposed to accomplish. This context-awareness improves quality at every stage.\n\n### Safety Without Friction\n\nIrreversible actions (force push, branch deletion, release creation) require explicit approval. But routine operations flow smoothly with sensible defaults.\n\n---\n\n## Features\n\n- **Zero Configuration**: Commands auto-detect repository settings (default branch, labels, etc.)\n- **Interactive**: Uses the AskUserQuestion tool for guided workflows\n- **Portable**: Works with any GitHub repository without hardcoding\n- **Customizable**: `/gh-setup` generates project-specific configurations\n- **Quality Checks**: Detects tech stack and runs appropriate lint/test commands\n- **Safety Hooks**: Prevents irreversible actions without explicit user approval\n- **Task-Based Tracking**: Uses TaskCreate/TaskUpdate for implementation and review progress\n- **Multi-Faceted Review**: Structured review with P1/P2/P3 prioritization\n- **Capability Discovery**: Dynamically discovers available agents, skills, and quality commands\n- **Self-Review Gates**: Mandatory code and test review before PR creation\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `/gh-workflow:gh-issue` | Create a new GitHub issue with solution-agnostic principles |\n| `/gh-workflow:gh-start <N>` | Start work on issue #N (branch, implement, ready for PR) |\n| `/gh-workflow:gh-commit` | Context-aware commits with change classification |\n| `/gh-workflow:gh-pr` | Create PR with full review and reviewer suggestions |\n| `/gh-workflow:gh-review <N>` | Review PR #N with checklist and feedback |\n| `/gh-workflow:gh-address <N>` | Address review comments on PR #N |\n| `/gh-workflow:gh-merge <N>` | Merge approved PR #N |\n| `/gh-workflow:gh-release [type]` | Create a release (patch/minor/major) |\n| `/gh-workflow:gh-status` | Show workflow status overview (assigned issues, open PRs, review requests) |\n| `/gh-workflow:gh-setup` | Analyze repo and generate workflow configuration |\n\n### Command Benefits\n\n#### `/gh-issue` — Create Issues\n\n**What's Good About /gh-issue:**\n1. **Duplicate detection** — Searches existing issues before creating, preventing redundant work\n2. **Solution-agnostic enforcement** — Guides you away from implementation details that become stale\n3. **Structured templates** — Consistent format (Context, Objective, Acceptance Criteria) across all issues\n4. **Label validation** — Fetches actual available labels, prevents typos and missing labels\n\n#### `/gh-start` — Start Work\n\n**What's Good About /gh-start:**\n1. **Complete workflow** — One command handles: assign issue, pull latest main, create branch, implement\n2. **Branch naming conventions** — Enforces consistent naming (feature/issue-N, fix/issue-N, docs/issue-N)\n3. **Task-based implementation** — Creates tasks from acceptance criteria and tracks progress\n4. **Capability discovery** — Discovers available agents and skills before implementation\n5. **Self-review gates** — Mandatory code review, test review, and pre-PR gate\n6. **Parallel execution** — Maximizes efficiency with parallel API calls and file reads\n7. **Flexible ending** — Choose to create PR immediately, defer to `/gh-pr`, or continue working\n\n#### `/gh-commit` — Context-Aware Commits\n\n**What's Good About /gh-commit:**\n1. **Change classification** — Automatically classifies changes as in-context, uncertain, or out-of-context\n2. **External change flagging** — Flags unrelated files (config, editor settings) before committing\n3. **Multiple commits support** — Groups related changes for atomic commits\n4. **Branch context awareness** — Uses branch name, linked issue, and active tasks for classification\n5. **Conventional commits** — Enforces commit message conventions (feat:, fix:, docs:, etc.)\n\n#### `/gh-pr` — Create Pull Request\n\n**What's Good About /gh-pr:**\n1. **Full code review** — Mandatory code review with P1/P2/P3 prioritized findings before PR\n2. **Convention check** — Validates commit messages and branch naming\n3. **Reviewer suggestions** — Suggests reviewers based on CODEOWNERS, file expertise, and workload\n4. **Quality gates** — Runs lint, test, and type-check commands before PR\n5. **Preview before creation** — Shows complete PR preview and requires explicit approval\n6. **Decoupled from gh-start** — Can be run independently after any commit workflow\n\n#### `/gh-review` — Review PRs\n\n**What's Good About /gh-review:**\n1. **Context-aware** — Reads the linked issue to understand what the PR should accomplish\n2. **Structured checklist** — Systematic review categories prevent overlooking important aspects\n3. **Interactive feedback** — Guides through approval, request changes, or comment-only decisions\n4. **Quality gates** — Detects tech stack and suggests appropriate lint/test commands to run\n5. **Multi-faceted review** — Creates tasks for each review facet (code quality, conventions, security, tests, requirements)\n6. **Prioritized findings** — Categorizes issues as P1 (critical), P2 (important), P3 (suggestions)\n7. **Finding synthesis** — Consolidates all findings into a structured summary with decision logic\n8. **Parallel execution** — Reads multiple files and creates tasks in parallel for efficiency\n\n#### `/gh-address` — Address Comments\n\n**What's Good About /gh-address:**\n1. **Comment aggregation** — Pulls all review comments into a single actionable list\n2. **Systematic resolution** — Track which comments have been addressed\n3. **Conversation continuity** — Maintains context of the review discussion\n4. **Task-based tracking** — Creates tasks for each feedback item and tracks resolution\n5. **Post-address review gate** — Re-runs code review and quality checks after fixes\n6. **Quality verification** — Ensures fixes don't introduce new issues before pushing\n\n#### `/gh-merge` — Merge PRs\n\n**What's Good About /gh-merge:**\n1. **Safety checks** — Verifies PR is approved and checks are passing\n2. **Branch cleanup** — Optionally deletes feature branch after merge\n3. **Merge strategy selection** — Choose squash, merge commit, or rebase based on preference\n\n#### `/gh-release` — Create Releases\n\n**What's Good About /gh-release:**\n1. **Semantic versioning** — Guided selection of patch/minor/major increment\n2. **Automatic changelog** — Generates release notes from merged PRs since last release\n3. **Tag creation** — Creates git tag and GitHub release in one step\n4. **Version consistency** — Updates version numbers in project files if detected\n\n#### `/gh-status` — Workflow Overview\n\n**What's Good About /gh-status:**\n1. **Quick overview** — See all your assigned issues, open PRs, and review requests in one view\n2. **Attention flags** — Highlights PRs with unaddressed feedback or failing checks\n3. **No context switching** — Get status without leaving your terminal\n4. **Read-only** — Safe to run anytime, doesn't modify anything\n\n#### `/gh-setup` — Configure Workflow\n\n**What's Good About /gh-setup:**\n1. **One-time setup** — Analyzes your repo and generates project-specific configuration\n2. **Tech stack detection** — Identifies Python, TypeScript, Go, Ruby and configures appropriate quality commands\n3. **Template generation** — Creates customized issue/PR templates based on your conventions\n4. **Non-destructive** — Shows preview of changes before writing any files\n\n## Quick Start\n\n### 1. Run Setup (Recommended)\n\n```\n/gh-workflow:gh-setup\n```\n\nThis analyzes your repository and generates a customized workflow configuration in your `.claude/CLAUDE.md` or `CLAUDE.md` file.\n\n### 2. Or Use Directly\n\nCommands work without setup by auto-detecting your repository's settings:\n\n```\n/gh-workflow:gh-issue Add user authentication\n```\n\n## Workflow Overview\n\n```\n┌─────────────────┐\n│  /gh-status     │ View assigned issues, PRs, review requests\n└────────┬────────┘\n         ▼\n┌─────────────────┐\n│  /gh-issue      │ Create issue with context, objectives, criteria\n└────────┬────────┘\n         ▼\n┌─────────────────┐\n│  /gh-start N    │ Assign issue, create branch, implement\n└────────┬────────┘\n         ▼\n┌─────────────────┐\n│  /gh-commit     │ Context-aware commits (optional, can repeat)\n└────────┬────────┘\n         ▼\n┌─────────────────┐\n│  /gh-pr         │ Full review, reviewer suggestions, create PR\n└────────┬────────┘\n         ▼\n┌─────────────────┐\n│  /gh-review N   │ Review PR, provide feedback\n└────────┬────────┘\n         ▼\n┌─────────────────┐\n│  /gh-address N  │ Address review comments (if any)\n└────────┬────────┘\n         ▼\n┌─────────────────┐\n│  /gh-merge N    │ Merge approved PR, delete branch\n└────────┬────────┘\n         ▼\n┌─────────────────┐\n│  /gh-release    │ Create release with changelog\n└─────────────────┘\n```\n\n## Key Principles\n\n### Dynamic Configuration\n\nCommands never hardcode values. Instead, they detect:\n- **Default branch**: `gh repo view --json defaultBranchRef`\n- **Repository name**: `gh repo view --json nameWithOwner`\n- **Available labels**: `gh label list`\n\n### Solution-Agnostic Issues\n\nIssues describe WHAT, not HOW:\n- ✅ \"User can filter results by date\"\n- ❌ \"Add DateFilter component to src/components/\"\n\nThis ensures issues remain valid even when implementation details change.\n\n### Interactive Workflows\n\nEvery command uses the **AskUserQuestion tool** at decision points:\n- Label selection\n- Branch type choice\n- PR approval\n- Review decisions\n\n## Customization\n\n### Project-Specific Overrides\n\nAfter running `/gh-setup`, you can customize:\n\n1. **CLAUDE.md**: Edit the workflow section for project-specific conventions\n2. **Local commands**: Copy commands to `.claude/commands/` for customization\n3. **Labels**: Create additional labels specific to your project\n\n### Templates\n\nThe `templates/` directory contains:\n- `CLAUDE-workflow.md` - Workflow section template\n- `issue-template.md` - Issue body structure\n- `pr-template.md` - PR body structure\n\n## Requirements\n\n- GitHub CLI (`gh`) installed and authenticated\n- Git repository with GitHub remote\n- Claude Code with plugin support\n\n## Agents\n\nThe plugin includes specialized agents for different aspects of the workflow:\n\n### code-reviewer\n\nGeneric code quality reviewer that analyzes:\n- Logic correctness and edge cases\n- Security patterns and vulnerabilities\n- Error handling assessment\n- Code quality and best practices\n\n### convention-checker\n\nValidates Git conventions including:\n- Commit message format (conventional commits)\n- Branch naming patterns\n- PR format compliance\n- Issue linkage verification\n\n### test-runner\n\nDiscovers and executes project-specific quality commands:\n- Tech stack detection (Python, Node, Go, Rust)\n- Command discovery from CLAUDE.md\n- Lint, test, and type-check execution\n- Result reporting with failure details\n\n### implementation-planner\n\nAnalyzes issues and creates task breakdowns:\n- Parses acceptance criteria from issues\n- Creates tasks using TaskCreate\n- Identifies dependencies between tasks\n- Tracks implementation progress\n\n## Skills\n\n### repo-config\n\nProvides dynamic repository configuration detection. Used internally by all commands to:\n- Detect default branch\n- Get repository info for API calls\n- Fetch available labels\n\n### capability-discovery\n\nDiscovers available capabilities in the user's environment:\n- Scans for custom agents and skills\n- Parses CLAUDE.md for quality commands\n- Detects tech stack\n- Enables dynamic workflow adaptation\n\n### suggest-users\n\nProvides intelligent user suggestions for reviewers and assignees:\n- Matches CODEOWNERS file patterns\n- Analyzes recent PR activity and file contributors\n- Balances workload across team members\n- Used by `/gh-pr`, `/gh-review`, `/gh-address`, and `/gh-issue`\n\n## Hooks\n\nThe plugin includes safety hooks that:\n- **Pre-push verification**: Ensures user approval before irreversible git operations\n- **Post-commit reminders**: Reminds about running quality checks after commits\n\n## Tech Stack Detection\n\nThe `/gh-setup` command detects your project's tech stack and generates appropriate quality checklists:\n\n| Stack | Detection | Quality Commands |\n|-------|-----------|-----------------|\n| Python | `pyproject.toml`, `ruff.toml` | `ruff check`, `pytest` |\n| TypeScript | `package.json`, `tsconfig.json` | `npm run lint`, `npm test` |\n| Go | `go.mod` | `go vet`, `go test` |\n| Ruby | `Gemfile`, `.rubocop.yml` | `rubocop`, `rspec` |\n\n## Examples\n\n### Check Workflow Status\n\n```\n/gh-workflow:gh-status\n```\n\n### Create an Issue\n\n```\n/gh-workflow:gh-issue Add dark mode support to the dashboard\n```\n\n### Start Work on an Issue\n\n```\n/gh-workflow:gh-start 42\n```\n\n### Review a PR\n\n```\n/gh-workflow:gh-review 15\n```\n\n### Create a Release\n\n```\n/gh-workflow:gh-release minor\n```\n\n---\n\n## Real-World Scenarios\n\n### Scenario 1: Feature Development Cycle\n\n**Situation:** You have a feature request from a stakeholder.\n\n```bash\n# 1. Create a well-structured issue\n/gh-workflow:gh-issue Users need to export their data as CSV\n\n# 2. Start work (assigns issue, creates branch, begins implementation)\n/gh-workflow:gh-start 42\n\n# 3. Commit changes as you work (context-aware)\n/gh-workflow:gh-commit\n\n# 4. Create PR with full review and reviewer suggestions\n/gh-workflow:gh-pr\n\n# 5. Reviewer reviews the PR\n# (reviewer uses /gh-review 15)\n\n# 6. Address any feedback\n/gh-workflow:gh-address 15\n\n# 7. Merge when approved\n/gh-workflow:gh-merge 15\n```\n\n**Result:** Complete audit trail from stakeholder request to merged code, with consistent structure at every step.\n\n### Scenario 2: Bug Fix with Urgency\n\n**Situation:** Production bug reported, needs quick turnaround.\n\n```bash\n# 1. Create issue (duplicate check ensures we're not re-solving old bugs)\n/gh-workflow:gh-issue Users see error when clicking submit button\n\n# 2. Branch type selection guides toward fix/ prefix\n/gh-workflow:gh-start 43\n# → Creates: fix/issue-43-submit-error\n\n# 3. Fast implementation, PR created\n# → PR title includes \"fixes #43\" for auto-close\n\n# 4. Emergency merge (after quick review)\n/gh-workflow:gh-merge 16\n```\n\n**Result:** Bug fix with proper tracking, even under time pressure.\n\n### Scenario 3: Release Preparation\n\n**Situation:** Sprint complete, time to release.\n\n```bash\n/gh-workflow:gh-release minor\n```\n\n**What happens:**\n1. Detects last release tag\n2. Collects all merged PRs since then\n3. Generates changelog from PR titles/descriptions\n4. Prompts for version confirmation (1.2.0 → 1.3.0)\n5. Creates git tag and GitHub release\n\n**Result:** Professional release notes without manual changelog maintenance.\n\n---\n\n## Team Workflow Benefits\n\n### For Individual Developers\n\n- **Less context switching** — One command handles the full workflow instead of multiple manual git/gh operations\n- **Consistent quality** — Templates and checklists ensure nothing is forgotten\n- **Fewer mistakes** — Interactive prompts catch issues before they become problems\n\n### For Teams\n\n- **Uniform issue quality** — Every issue follows the same structure\n- **Predictable branches** — Naming conventions make branch purpose clear\n- **Traceable history** — PRs link to issues, releases link to PRs\n- **Onboarding efficiency** — New team members follow the same guided workflow\n\n### For Projects\n\n- **Refactoring-safe backlog** — Solution-agnostic issues remain valid when code moves\n- **Audit compliance** — Complete trail from requirement to release\n- **Reduced friction** — Less time on process, more time on implementation\n\n## License\n\nMIT\n",
        "plugins/context-ledger/README.md": "# Context Ledger - Evidence-Based Product Development\n\nA Claude Code plugin for structured product development with traceable evidence, explicit decisions, and constrained spec generation.\n\n---\n\n## Why Context Ledger?\n\n### The Problem with Traditional Product Planning\n\nMost product development starts with vibes and ends with specs that nobody trusts:\n\n- **Specs drift from reality** — PRDs reference decisions that were never formally made\n- **Assumptions hide in prose** — Trade-offs buried in paragraph 47 of a 200-page doc\n- **Evidence disappears** — \"Studies show...\" but which studies? From when?\n- **Updates break everything** — New learnings require manual diff of every downstream doc\n\n### What Context Ledger Does Differently\n\nContext Ledger asks: **\"Can you trace every spec requirement back to evidence and an explicit decision?\"**\n\nThis constraint-based approach:\n- **Forces explicit decisions** — No spec section without a `DEC-*` reference\n- **Traces to evidence** — Every decision cites `EV-*` evidence objects\n- **Surfaces trade-offs** — Decisions must list wins, loses, and created risks\n- **Produces impact reports** — Updates show what downstream artifacts need regeneration\n\n### Who Benefits\n\n| Role | How Context Ledger Helps |\n|------|--------------------------|\n| **Product Managers** | Evidence-backed PRDs with explicit trade-off documentation |\n| **Engineers** | Architecture decisions with clear reasoning and risk awareness |\n| **Executives** | Decision audits showing how conclusions were reached |\n| **Teams** | Shared understanding through structured artifacts, not tribal knowledge |\n\n---\n\n## Design Philosophy\n\n### Auditability Over Convenience\n\nEvery claim traces back to its source. If you can't cite the evidence, it doesn't go in the spec.\n\n### Explicit Decisions Over Implicit Assumptions\n\nMost product failures stem from hidden assumptions. Context Ledger makes trade-offs visible:\n- What alternatives were considered?\n- What are we giving up?\n- What risks does this create?\n\n### Constrained Generation Over Free-Form Writing\n\nSpecs cannot be generated without meeting quality gates:\n- Evidence gate: ≥5 evidence objects per pillar before synthesis\n- Decision gate: DECISIONS.yaml must exist before spec generation\n- Spec gate: Every PRD section must reference at least one `DEC-*`\n\n### Impact-Aware Updates\n\nChanges produce diffs, not silent rewrites. Every update includes an impact report showing what must be regenerated.\n\n---\n\n## The Pipeline\n\n### Phase 1 — Context Build (PARALLEL)\nGenerate pillar map, collect evidence in parallel across 8 pillars.\n\n**Output**: Evidence Objects in `02-evidence/...`\n\n### Phase 2 — Synthesis (LAYERED)\nPer-pillar synthesis → cross-pillar synthesis → decisions + risks.\n\n**Output**:\n- `03-synthesis/...`\n- `04-decisions/DECISIONS.yaml`\n- `05-risks/RISKS.yaml`\n\n### Phase 3 — Build (CONSTRAINED)\nGenerate PRD, architecture, plan — only from decisions + evidence.\n\n**Output**:\n- `06-prd/PRD.md`\n- `07-architecture/ARCHITECTURE.md`\n- `08-plan/PLAN.md`\n\n---\n\n## Installation\n\n```bash\n# Add the marketplace (one-time setup)\nclaude plugin marketplace add synaptiai/synapti-marketplace\n\n# Install the plugin\nclaude plugin install context-ledger\n```\n\n---\n\n## Commands\n\n### Full Pipeline (Recommended)\n\n#### `/ledger-full <brief>`\n\nRun the complete Context Ledger pipeline from brief to implementation plan in one command.\n\n```bash\n# Standard overnight run\n/ledger-full \"Build a task management app for remote teams\" --mode optimizer\n\n# With self-improvement loops\n/ledger-full \"Task management app\" --mode optimizer --self-improve\n\n# Maximum speed hackathon\n/ledger-full \"AI code review assistant\" --mode tokenburner\n\n# Fully autonomous (walk away overnight)\n/ledger-full \"Healthcare portal with HIPAA\" --mode ralph --max-iterations 50\n\n# Ralph + self-improve (maximum autonomy)\n/ledger-full \"Complex fintech app\" --mode ralph --self-improve --max-iterations 100\n```\n\n**What's Good About /ledger-full:**\n1. **Single command, complete output** — Goes from idea to implementation plan without manual phase transitions\n2. **Mode flexibility** — Choose between sustainable (`optimizer`), fast (`tokenburner`), or autonomous (`ralph`) execution\n3. **Self-improvement loops** — Optional `--self-improve` flag fills evidence gaps and resolves contradictions automatically\n4. **Quality gate enforcement** — Cannot skip evidence, decision, or spec gates; ensures receipts at every stage\n5. **Walk-away capable** — Ralph mode with stop hooks enables overnight autonomous execution\n6. **Minimal interaction** — Only asks questions during decision phase; everything else runs autonomously\n\n### Individual Commands\n\n#### `/ledger-init <brief>`\n\nInitialize a Context Ledger workspace with structured brief and pillar configuration.\n\n```bash\n/ledger-init Build a task management app for remote software teams with Slack integration\n```\n\n**What's Good About /ledger-init:**\n1. **Structured brief parsing** — Extracts goals, constraints, and target users from free-form input\n2. **Pillar prioritization** — Identifies which research areas matter most for your specific project\n3. **Directory scaffold** — Creates the complete 10-folder workspace structure automatically\n4. **Validation gates** — Won't proceed if brief lacks goals or constraints, ensuring quality from the start\n\n---\n\n#### `/ledger-research`\n\nParallel evidence collection across 8 research pillars (market, users, tech, competitors, design, legal, ops, economics).\n\n```bash\n/ledger-research\n/ledger-research --pillars market,users,competitors\n```\n\n**What's Good About /ledger-research:**\n1. **True parallelism** — 8 agents research simultaneously, dramatically faster than sequential research\n2. **Atomic evidence objects** — Each finding is structured YAML with confidence scores and assumptions\n3. **Semantic IDs** — Evidence gets readable IDs like `EV-market-pricing-smb-wtp` that humans can reference\n4. **Quality gates** — Enforces minimum 5 evidence objects per pillar before proceeding\n5. **Source traceability** — Every claim links to its source with retrieval date\n\n---\n\n#### `/ledger-synthesize`\n\nTransform raw evidence into pillar syntheses, then cross-synthesize to identify conflicts and emergent insights.\n\n```bash\n/ledger-synthesize\n```\n\n**What's Good About /ledger-synthesize:**\n1. **Two-layer synthesis** — Per-pillar patterns first, then cross-pillar connections and conflicts\n2. **Contradiction surfacing** — Explicitly identifies where evidence disagrees, forcing resolution\n3. **Decision candidates** — Generates preliminary decisions from synthesis, not from vibes\n4. **Pattern recognition** — Identifies themes across evidence that individual pieces don't reveal\n\n---\n\n#### `/ledger-decide`\n\nMake explicit decisions with documented alternatives, trade-offs, and risk implications.\n\n```bash\n/ledger-decide\n```\n\n**What's Good About /ledger-decide:**\n1. **Forced alternatives** — Every decision must document what options were considered and rejected\n2. **Trade-off documentation** — Explicit wins and loses, not just the happy path\n3. **Risk linkage** — Decisions automatically create risk entries when they create new vulnerabilities\n4. **Evidence requirements** — Each decision must cite minimum 2 evidence IDs, preventing gut-feel choices\n5. **Interactive workflow** — Presents decisions with evidence for user approval, not autonomous guessing\n\n---\n\n#### `/ledger-spec`\n\nGenerate constrained PRD and architecture documents where every section cites decisions.\n\n```bash\n/ledger-spec\n```\n\n**What's Good About /ledger-spec:**\n1. **Constraint enforcement** — PRD sections cannot exist without DEC-* references; no vibes allowed\n2. **Automatic validation** — Spec gate checks that all sections cite decisions before completing\n3. **Risk cross-referencing** — Architecture sections reference relevant RISK-* entries\n4. **Coverage tracking** — Reports which decisions are covered and which need spec sections\n5. **No drift** — Specs stay anchored to decisions, which stay anchored to evidence\n\n---\n\n#### `/ledger-plan`\n\nGenerate implementation plan with backlog, milestones, and test plan linked to decisions and risks.\n\n```bash\n/ledger-plan\n```\n\n**What's Good About /ledger-plan:**\n1. **Decision-linked items** — Every backlog item traces to the decisions that require it\n2. **Risk-aware sequencing** — High-risk items get earlier attention and explicit mitigations\n3. **Test plan generation** — Acceptance criteria derived from decisions, not invented\n4. **Milestone structure** — Logical groupings based on decision dependencies\n\n---\n\n#### `/ledger-update <new-evidence>`\n\nApply new learnings and generate impact report showing what needs regeneration.\n\n```bash\n/ledger-update \"User interviews revealed onboarding completion rate of 23%\"\n```\n\n**What's Good About /ledger-update:**\n1. **Impact analysis** — Shows exactly which decisions, specs, and plans are affected by new evidence\n2. **Diff generation** — Documents what changed, not silent rewrites\n3. **Regeneration guidance** — Identifies which artifacts need updates vs. which remain valid\n4. **Audit trail** — Maintains history of how understanding evolved over time\n\n---\n\n## Execution Modes\n\nThe `/ledger-full` command supports three modes + one flag:\n\n### `--mode optimizer`\n\n**Sustainable execution.** 3 agents per pillar (24 total), balanced throughput.\n\nBest for: Standard projects, overnight runs, production use.\n\n### `--mode tokenburner`\n\n**Maximum parallelism.** 30+ agents per pillar (240+ total), burns through tokens fast.\n\nBest for: Hackathons, time-critical projects, rapid exploration.\n\n### `--mode ralph`\n\n**Fully autonomous execution** using Ralph Loop's stop hook mechanism. Same prompt re-fed on each exit until `<promise>LEDGER_COMPLETE</promise>` is output.\n\nBest for: Walk-away overnight runs, complex autonomous projects.\n\n### `--self-improve` (Flag)\n\n**Can combine with any mode.** Enables within-pipeline gap analysis loops:\n- Analyzes research for missing evidence\n- Checks synthesis for unresolved contradictions\n- Loops back when gaps found\n\n| Scenario | Recommended |\n|----------|-------------|\n| Standard project | `--mode optimizer` |\n| Hackathon / rapid prototyping | `--mode tokenburner` |\n| Walk-away overnight run | `--mode ralph --max-iterations 50` |\n| Complex regulated project | `--mode ralph --self-improve --max-iterations 100` |\n| High-stakes production planning | `--mode optimizer --self-improve` |\n\n---\n\n## Semantic ID Scheme\n\nAll artifacts use self-describing semantic IDs with optional `-2`, `-3` disambiguators.\n\n### Why Semantic IDs\n- **Readable + speakable** in meetings and docs\n- **Predictable structure** so humans can guess IDs\n- **Still unique** with `-n` suffix when collisions happen\n- **Max 40 chars** after prefix\n\n### ID Formats\n\n| Type | Format | Examples |\n|------|--------|----------|\n| Evidence | `EV-<pillar>-<topic>-<descriptor>[-n]` | `EV-market-pricing-smb-wtp`, `EV-users-onboarding-dropoff` |\n| Decision | `DEC-<area>-<decision>[-n]` | `DEC-scope-power-users-first`, `DEC-ux-single-summary-box` |\n| Risk | `RISK-<area>-<risk>[-n]` | `RISK-retention-expert-depth-churn`, `RISK-legal-gdpr-processing-basis` |\n\n---\n\n## Ledger Workspace Structure\n\nDefault: `~/project/ledger/` (overridable)\n\n```\nledger/\n├── 00-brief/           # 5-sentence brief + goals + constraints\n├── 01-pillars/         # pillar map, scope, priorities\n├── 02-evidence/        # Evidence Objects (per pillar)\n│   ├── market/\n│   ├── users/\n│   ├── tech/\n│   ├── competitors/\n│   ├── design/\n│   ├── legal/\n│   ├── ops/\n│   └── economics/\n├── 03-synthesis/       # per-pillar syntheses + CROSS-SYNTHESIS.md\n├── 04-decisions/       # DECISIONS.yaml\n├── 05-risks/           # RISKS.yaml\n├── 06-prd/             # PRD.md\n├── 07-architecture/    # ARCHITECTURE.md\n├── 08-plan/            # PLAN.md\n├── 09-brand/           # personas, tone, UI refs, tokens\n└── 10-gtm-ops/         # pricing, unit economics, launch checklist\n```\n\n---\n\n## Evidence Objects\n\nEvidence objects force atomic, traceable research output.\n\n### Schema\n```yaml\nid: EV-market-pricing-smb-wtp\npillar: market\nsource:\n  type: url | pdf | interview | internal-doc | experiment | dataset\n  ref: \"https://...\"\n  retrieved_at: 2026-01-21\nclaim: \"SMB segment willingness-to-pay peaks at $29/mo.\"\nquote: \"<short excerpt or summary>\"\nconfidence: 0.0-1.0\nassumptions:\n  - \"Survey sample excludes enterprise accounts\"\nnotes: \"Why it matters, how it may fail, what to verify next.\"\ntags:\n  - pricing\n  - smb\n```\n\n### Quality Rules\n- Claims must be **falsifiable** (not vibes)\n- **Confidence is mandatory** (even if subjective)\n- **Assumptions must be listed**\n- **ID auto-suggested** from claim text\n\n---\n\n## Decision Ledger\n\nThe heart of the system. Every decision must document:\n\n### Schema\n```yaml\n- id: DEC-scope-power-users-first\n  decision: \"Target power users before SMB\"\n  status: accepted | provisional | rejected\n  owner: \"user\"\n  created_at: 2026-01-21\n  alternatives:\n    - \"SMB-first\"\n    - \"Enterprise-first\"\n  evidence:\n    - EV-market-pricing-smb-wtp\n    - EV-users-power-user-retention\n  tradeoffs:\n    wins:\n      - \"Faster iteration cycles\"\n      - \"Lower sales friction\"\n    loses:\n      - \"Lower initial ARPA\"\n      - \"Potentially higher churn\"\n  risks:\n    - RISK-retention-expert-depth-churn\n  implications:\n    - \"MVP UX must optimize for expert workflows\"\n```\n\n---\n\n## Quality Gates\n\n| Gate | Requirement |\n|------|-------------|\n| **Evidence gate** | Each pillar needs ≥5 Evidence Objects before synthesis |\n| **Decision gate** | No spec generation until DECISIONS.yaml exists with ≥2 evidence IDs per decision |\n| **Spec gate** | No PRD/architecture sections without DEC-* references |\n\n---\n\n## Impact Reports\n\nUpdates produce structured impact analysis:\n\n```markdown\n# Impact Report\n\n## What Changed\n- Evidence added/updated:\n  - EV-market-pricing-enterprise-wtp (new)\n  - EV-users-onboarding-dropoff (updated confidence: 0.7 → 0.9)\n- Decisions updated:\n  - DEC-scope-power-users-first (status: provisional → accepted)\n\n## What Is Affected\n- PRD sections: 2, 4\n- Architecture sections: Data model\n- Plan items: Epic 1\n\n## Recommended Actions\n- [ ] Regenerate PRD section 2\n- [ ] Review RISK-retention-expert-depth-churn mitigations\n```\n\n---\n\n## Constraint Enforcement\n\n### Citation Format\n\nSpecs must cite decisions using parseable references:\n\n**Section headings:**\n```markdown\n## 2. MVP scope (DEC-scope-power-users-first, DEC-ux-single-summary-box)\n```\n\n**Inline:**\n```markdown\nWe will prioritize workflow X because it reduces drop-off. (DEC-scope-power-users-first)\n```\n\n---\n\n## What Makes This Different\n\nMost \"context\" tooling is a dump of notes.\n\n**Context Ledger is:**\n- Structured evidence with confidence scores\n- Explicit decisions with trade-offs and alternatives\n- Explicit risks with triggers and mitigations\n- Constrained generation (specs must cite decisions)\n- Impact-aware updates (changes produce diffs)\n\n**It's a lightweight system for building products with receipts.**\n\n---\n\n## License\n\nMIT License - See LICENSE file for details.\n\n## Author\n\nDaniel Bentes\n\n## Repository\n\nhttps://github.com/synaptiai/synapti-marketplace\n"
      },
      "plugins": [
        {
          "name": "decipon",
          "source": "./plugins/decipon",
          "description": "NCI manipulation detection with deep research fact-checking - analyzes content for propaganda, disinformation, and manipulation patterns across 20 categories with integrated claim verification",
          "version": "1.5.0",
          "author": {
            "name": "Daniel Bentes"
          },
          "homepage": "https://github.com/synaptiai/synapti-marketplace",
          "repository": "https://github.com/synaptiai/synapti-marketplace",
          "license": "MIT",
          "category": "analysis",
          "keywords": [
            "manipulation-detection",
            "disinformation",
            "propaganda",
            "fact-checking",
            "deep-research",
            "claim-verification",
            "media-literacy",
            "nci-protocol",
            "narrative-credibility-index"
          ],
          "tags": [
            "psyops",
            "fact-checking",
            "deep-research",
            "claim-verification",
            "media-literacy",
            "nci-protocol",
            "narrative-credibility-index"
          ],
          "categories": [
            "analysis",
            "claim-verification",
            "deep-research",
            "disinformation",
            "fact-checking",
            "manipulation-detection",
            "media-literacy",
            "narrative-credibility-index",
            "nci-protocol",
            "propaganda",
            "psyops"
          ],
          "install_commands": [
            "/plugin marketplace add synaptiai/synapti-marketplace",
            "/plugin install decipon@synapti-marketplace"
          ]
        },
        {
          "name": "gh-workflow",
          "source": "./plugins/gh-workflow",
          "description": "Generic GitHub workflow commands for issue management, PR creation, code review, and releases. Works with any repository by auto-detecting settings.",
          "version": "1.2.0",
          "author": {
            "name": "Daniel Bentes"
          },
          "homepage": "https://github.com/synaptiai/synapti-marketplace",
          "repository": "https://github.com/synaptiai/synapti-marketplace",
          "license": "MIT",
          "category": "workflow",
          "keywords": [
            "github",
            "workflow",
            "git",
            "pr",
            "pull-request",
            "issue",
            "code-review",
            "release",
            "automation"
          ],
          "tags": [
            "github",
            "workflow",
            "git",
            "automation",
            "development"
          ],
          "categories": [
            "automation",
            "code-review",
            "development",
            "git",
            "github",
            "issue",
            "pr",
            "pull-request",
            "release",
            "workflow"
          ],
          "install_commands": [
            "/plugin marketplace add synaptiai/synapti-marketplace",
            "/plugin install gh-workflow@synapti-marketplace"
          ]
        },
        {
          "name": "context-ledger",
          "source": "./plugins/context-ledger",
          "description": "Evidence-based product development with traceable decisions, constrained spec generation, and impact-aware updates. Forces auditability through semantic IDs and quality gates.",
          "version": "1.0.0",
          "author": {
            "name": "Daniel Bentes"
          },
          "homepage": "https://github.com/synaptiai/synapti-marketplace",
          "repository": "https://github.com/synaptiai/synapti-marketplace",
          "license": "MIT",
          "category": "product-development",
          "keywords": [
            "product-development",
            "evidence-based",
            "decision-ledger",
            "traceability",
            "prd",
            "architecture",
            "risk-management",
            "constrained-generation",
            "semantic-ids",
            "quality-gates"
          ],
          "tags": [
            "product-development",
            "evidence-based",
            "decisions",
            "traceability",
            "planning"
          ],
          "categories": [
            "architecture",
            "constrained-generation",
            "decision-ledger",
            "decisions",
            "evidence-based",
            "planning",
            "prd",
            "product-development",
            "quality-gates",
            "risk-management",
            "semantic-ids",
            "traceability"
          ],
          "install_commands": [
            "/plugin marketplace add synaptiai/synapti-marketplace",
            "/plugin install context-ledger@synapti-marketplace"
          ]
        },
        {
          "name": "agent-capability-standard",
          "source": "./plugins/agent-capability-standard",
          "description": "Grounded Agency: 36 atomic capabilities with typed contracts, safety-by-construction, and grounded reasoning for reliable AI agents",
          "version": "1.1.1",
          "author": {
            "name": "Daniel Bentes"
          },
          "homepage": "https://github.com/synaptiai/agent-capability-standard",
          "repository": "https://github.com/synaptiai/agent-capability-standard",
          "license": "Apache-2.0",
          "category": "agent-framework",
          "keywords": [
            "ai-agents",
            "capability-ontology",
            "grounded-agency",
            "workflow-dsl",
            "safety",
            "checkpoints",
            "provenance",
            "trust-model",
            "world-modeling"
          ],
          "tags": [
            "agents",
            "safety",
            "workflows",
            "validation",
            "grounded-agency"
          ],
          "categories": [
            "agent-framework",
            "agents",
            "ai-agents",
            "capability-ontology",
            "checkpoints",
            "grounded-agency",
            "provenance",
            "safety",
            "trust-model",
            "validation",
            "workflow-dsl",
            "workflows",
            "world-modeling"
          ],
          "install_commands": [
            "/plugin marketplace add synaptiai/synapti-marketplace",
            "/plugin install agent-capability-standard@synapti-marketplace"
          ]
        }
      ]
    }
  ]
}