{
  "author": {
    "id": "dbmcco",
    "display_name": "Braydon McCormick",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/89109181?u=9ee6b18d10bddf5f8afeedd4cd77e1a128739f6d&v=4",
    "url": "https://github.com/dbmcco",
    "bio": "Still figuring it out.",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 32,
      "total_skills": 6,
      "total_stars": 2,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "beads-marketplace",
      "version": null,
      "description": "Local marketplace for beads plugin development",
      "owner_info": {
        "name": "Steve Yegge"
      },
      "keywords": [],
      "repo_full_name": "dbmcco/tmux-beads-loops",
      "repo_url": "https://github.com/dbmcco/tmux-beads-loops",
      "repo_description": null,
      "homepage": null,
      "signals": {
        "stars": 2,
        "forks": 0,
        "pushed_at": "2026-01-26T13:45:19Z",
        "created_at": "2026-01-05T18:31:58Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".beads",
          "type": "tree",
          "size": null
        },
        {
          "path": ".beads/README.md",
          "type": "blob",
          "size": 2250
        },
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/agents/task-agent.md",
          "type": "blob",
          "size": 1923
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 321
        },
        {
          "path": ".claude-plugin/plugin.json",
          "type": "blob",
          "size": 898
        },
        {
          "path": ".claude",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/commands/handoff.md",
          "type": "blob",
          "size": 773
        },
        {
          "path": ".claude/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/hooks/post-commit.sh",
          "type": "blob",
          "size": 2035
        },
        {
          "path": ".claude/hooks/pre-bash.sh",
          "type": "blob",
          "size": 5425
        },
        {
          "path": ".claude/hooks/session-start.sh",
          "type": "blob",
          "size": 1962
        },
        {
          "path": ".claude/hooks/stop.sh",
          "type": "blob",
          "size": 2414
        },
        {
          "path": ".claude/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/README.md",
          "type": "blob",
          "size": 2912
        },
        {
          "path": ".claude/skills/coordinator",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/coordinator/SKILL.md",
          "type": "blob",
          "size": 1043
        },
        {
          "path": ".claude/skills/handoff",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/handoff/SKILL.md",
          "type": "blob",
          "size": 1772
        },
        {
          "path": ".claude/skills/orchestrate",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/orchestrate/SKILL.md",
          "type": "blob",
          "size": 1774
        },
        {
          "path": ".claude/skills/worker",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/worker/SKILL.md",
          "type": "blob",
          "size": 1057
        },
        {
          "path": ".claude/skills/wt-manager",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/wt-manager/SKILL.md",
          "type": "blob",
          "size": 1272
        },
        {
          "path": ".devcontainer",
          "type": "tree",
          "size": null
        },
        {
          "path": ".devcontainer/README.md",
          "type": "blob",
          "size": 2278
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 5617
        },
        {
          "path": "cmd",
          "type": "tree",
          "size": null
        },
        {
          "path": "cmd/bd",
          "type": "tree",
          "size": null
        },
        {
          "path": "cmd/bd/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "cmd/bd/templates/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "cmd/bd/templates/hooks/post-checkout",
          "type": "blob",
          "size": 491
        },
        {
          "path": "cmd/bd/templates/hooks/post-merge",
          "type": "blob",
          "size": 604
        },
        {
          "path": "cmd/bd/templates/hooks/pre-commit",
          "type": "blob",
          "size": 604
        },
        {
          "path": "cmd/bd/templates/hooks/pre-push",
          "type": "blob",
          "size": 596
        },
        {
          "path": "cmd/bd/templates/hooks/prepare-commit-msg",
          "type": "blob",
          "size": 815
        },
        {
          "path": "commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "commands/audit.md",
          "type": "blob",
          "size": 972
        },
        {
          "path": "commands/blocked.md",
          "type": "blob",
          "size": 561
        },
        {
          "path": "commands/close.md",
          "type": "blob",
          "size": 583
        },
        {
          "path": "commands/comments.md",
          "type": "blob",
          "size": 965
        },
        {
          "path": "commands/compact.md",
          "type": "blob",
          "size": 1069
        },
        {
          "path": "commands/create.md",
          "type": "blob",
          "size": 639
        },
        {
          "path": "commands/daemon.md",
          "type": "blob",
          "size": 2348
        },
        {
          "path": "commands/daemons.md",
          "type": "blob",
          "size": 4837
        },
        {
          "path": "commands/delete.md",
          "type": "blob",
          "size": 959
        },
        {
          "path": "commands/dep.md",
          "type": "blob",
          "size": 3383
        },
        {
          "path": "commands/epic.md",
          "type": "blob",
          "size": 787
        },
        {
          "path": "commands/export.md",
          "type": "blob",
          "size": 683
        },
        {
          "path": "commands/import.md",
          "type": "blob",
          "size": 989
        },
        {
          "path": "commands/init.md",
          "type": "blob",
          "size": 751
        },
        {
          "path": "commands/label.md",
          "type": "blob",
          "size": 896
        },
        {
          "path": "commands/list.md",
          "type": "blob",
          "size": 2616
        },
        {
          "path": "commands/prime.md",
          "type": "blob",
          "size": 231
        },
        {
          "path": "commands/quickstart.md",
          "type": "blob",
          "size": 348
        },
        {
          "path": "commands/ready.md",
          "type": "blob",
          "size": 579
        },
        {
          "path": "commands/rename-prefix.md",
          "type": "blob",
          "size": 599
        },
        {
          "path": "commands/reopen.md",
          "type": "blob",
          "size": 593
        },
        {
          "path": "commands/restore.md",
          "type": "blob",
          "size": 754
        },
        {
          "path": "commands/search.md",
          "type": "blob",
          "size": 3178
        },
        {
          "path": "commands/show.md",
          "type": "blob",
          "size": 561
        },
        {
          "path": "commands/stats.md",
          "type": "blob",
          "size": 617
        },
        {
          "path": "commands/sync.md",
          "type": "blob",
          "size": 1993
        },
        {
          "path": "commands/template.md",
          "type": "blob",
          "size": 6641
        },
        {
          "path": "commands/update.md",
          "type": "blob",
          "size": 843
        },
        {
          "path": "commands/version.md",
          "type": "blob",
          "size": 974
        },
        {
          "path": "commands/workflow.md",
          "type": "blob",
          "size": 2036
        },
        {
          "path": "examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/README.md",
          "type": "blob",
          "size": 2296
        },
        {
          "path": "examples/bash-agent",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/bash-agent/README.md",
          "type": "blob",
          "size": 3303
        },
        {
          "path": "examples/bd-example-extension-go",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/bd-example-extension-go/README.md",
          "type": "blob",
          "size": 6359
        },
        {
          "path": "examples/claude-desktop-mcp",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/claude-desktop-mcp/README.md",
          "type": "blob",
          "size": 6221
        },
        {
          "path": "examples/compaction",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/compaction/README.md",
          "type": "blob",
          "size": 3747
        },
        {
          "path": "examples/contributor-workflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/contributor-workflow/README.md",
          "type": "blob",
          "size": 5100
        },
        {
          "path": "examples/git-hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/git-hooks/README.md",
          "type": "blob",
          "size": 5555
        },
        {
          "path": "examples/github-import",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/github-import/README.md",
          "type": "blob",
          "size": 8746
        },
        {
          "path": "examples/jira-import",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/jira-import/README.md",
          "type": "blob",
          "size": 15328
        },
        {
          "path": "examples/library-usage",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/library-usage/README.md",
          "type": "blob",
          "size": 5145
        },
        {
          "path": "examples/linear-workflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/linear-workflow/README.md",
          "type": "blob",
          "size": 12246
        },
        {
          "path": "examples/markdown-to-jsonl",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/markdown-to-jsonl/README.md",
          "type": "blob",
          "size": 3764
        },
        {
          "path": "examples/monitor-webui",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/monitor-webui/README.md",
          "type": "blob",
          "size": 6806
        },
        {
          "path": "examples/multi-phase-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/multi-phase-development/README.md",
          "type": "blob",
          "size": 10323
        },
        {
          "path": "examples/multiple-personas",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/multiple-personas/README.md",
          "type": "blob",
          "size": 15699
        },
        {
          "path": "examples/protected-branch",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/protected-branch/README.md",
          "type": "blob",
          "size": 7530
        },
        {
          "path": "examples/python-agent",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/python-agent/README.md",
          "type": "blob",
          "size": 2340
        },
        {
          "path": "examples/startup-hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/startup-hooks/README.md",
          "type": "blob",
          "size": 3825
        },
        {
          "path": "examples/team-workflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "examples/team-workflow/README.md",
          "type": "blob",
          "size": 7505
        },
        {
          "path": "integrations",
          "type": "tree",
          "size": null
        },
        {
          "path": "integrations/beads-mcp",
          "type": "tree",
          "size": null
        },
        {
          "path": "integrations/beads-mcp/README.md",
          "type": "blob",
          "size": 9047
        },
        {
          "path": "integrations/claude-code",
          "type": "tree",
          "size": null
        },
        {
          "path": "integrations/claude-code/README.md",
          "type": "blob",
          "size": 1499
        },
        {
          "path": "integrations/claude-code/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "integrations/claude-code/commands/plan-to-beads.md",
          "type": "blob",
          "size": 1693
        },
        {
          "path": "internal",
          "type": "tree",
          "size": null
        },
        {
          "path": "internal/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "internal/hooks/hooks.go",
          "type": "blob",
          "size": 2762
        },
        {
          "path": "internal/hooks/hooks_test.go",
          "type": "blob",
          "size": 10187
        },
        {
          "path": "internal/hooks/hooks_unix.go",
          "type": "blob",
          "size": 2035
        },
        {
          "path": "internal/hooks/hooks_windows.go",
          "type": "blob",
          "size": 1123
        },
        {
          "path": "npm-package",
          "type": "tree",
          "size": null
        },
        {
          "path": "npm-package/README.md",
          "type": "blob",
          "size": 3472
        },
        {
          "path": "scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "scripts/README.md",
          "type": "blob",
          "size": 6615
        },
        {
          "path": "scripts/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "scripts/hooks/post-push",
          "type": "blob",
          "size": 483
        },
        {
          "path": "skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/beads",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/beads/CLAUDE.md",
          "type": "blob",
          "size": 2634
        },
        {
          "path": "skills/beads/README.md",
          "type": "blob",
          "size": 4440
        },
        {
          "path": "skills/beads/SKILL.md",
          "type": "blob",
          "size": 4014
        },
        {
          "path": "skills/beads/adr",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/beads/adr/0001-bd-prime-as-source-of-truth.md",
          "type": "blob",
          "size": 1785
        },
        {
          "path": "skills/beads/resources",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/beads/resources/AGENTS.md",
          "type": "blob",
          "size": 2008
        },
        {
          "path": "skills/beads/resources/ASYNC_GATES.md",
          "type": "blob",
          "size": 4014
        },
        {
          "path": "skills/beads/resources/BOUNDARIES.md",
          "type": "blob",
          "size": 17033
        },
        {
          "path": "skills/beads/resources/CHEMISTRY_PATTERNS.md",
          "type": "blob",
          "size": 6801
        },
        {
          "path": "skills/beads/resources/CLI_REFERENCE.md",
          "type": "blob",
          "size": 16922
        },
        {
          "path": "skills/beads/resources/DEPENDENCIES.md",
          "type": "blob",
          "size": 19724
        },
        {
          "path": "skills/beads/resources/INTEGRATION_PATTERNS.md",
          "type": "blob",
          "size": 13678
        },
        {
          "path": "skills/beads/resources/ISSUE_CREATION.md",
          "type": "blob",
          "size": 5081
        },
        {
          "path": "skills/beads/resources/MOLECULES.md",
          "type": "blob",
          "size": 10149
        },
        {
          "path": "skills/beads/resources/PATTERNS.md",
          "type": "blob",
          "size": 11502
        },
        {
          "path": "skills/beads/resources/RESUMABILITY.md",
          "type": "blob",
          "size": 5419
        },
        {
          "path": "skills/beads/resources/STATIC_DATA.md",
          "type": "blob",
          "size": 2013
        },
        {
          "path": "skills/beads/resources/TROUBLESHOOTING.md",
          "type": "blob",
          "size": 11433
        },
        {
          "path": "skills/beads/resources/WORKFLOWS.md",
          "type": "blob",
          "size": 19388
        },
        {
          "path": "skills/beads/resources/WORKTREES.md",
          "type": "blob",
          "size": 2718
        },
        {
          "path": "tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "tests/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "tests/hooks/README.md",
          "type": "blob",
          "size": 3122
        },
        {
          "path": "tests/hooks/hooks.bats",
          "type": "blob",
          "size": 12246
        },
        {
          "path": "tests/hooks/test_helper.bash",
          "type": "blob",
          "size": 13319
        },
        {
          "path": "tests/integration",
          "type": "tree",
          "size": null
        },
        {
          "path": "tests/integration/README.md",
          "type": "blob",
          "size": 690
        },
        {
          "path": "website",
          "type": "tree",
          "size": null
        },
        {
          "path": "website/README.md",
          "type": "blob",
          "size": 27
        },
        {
          "path": "winget",
          "type": "tree",
          "size": null
        },
        {
          "path": "winget/README.md",
          "type": "blob",
          "size": 1259
        }
      ],
      "files": {
        ".claude-plugin/agents/task-agent.md": "---\ndescription: Autonomous agent that finds and completes ready tasks\n---\n\nYou are a task-completion agent for beads. Your goal is to find ready work and complete it autonomously.\n\n# Agent Workflow\n\n1. **Find Ready Work**\n   - Use the `ready` MCP tool to get unblocked tasks\n   - Prefer higher priority tasks (P0 > P1 > P2 > P3 > P4)\n   - If no ready tasks, report completion\n\n2. **Claim the Task**\n   - Use the `show` tool to get full task details\n   - Use the `update` tool to set status to `in_progress`\n   - Report what you're working on\n\n3. **Execute the Task**\n   - Read the task description carefully\n   - Use available tools to complete the work\n   - Follow best practices from project documentation\n   - Run tests if applicable\n\n4. **Track Discoveries**\n   - If you find bugs, TODOs, or related work:\n     - Use `create` tool to file new issues\n     - Use `dep` tool with `discovered-from` to link them\n   - This maintains context for future work\n\n5. **Complete the Task**\n   - Verify the work is done correctly\n   - Use `close` tool with a clear completion message\n   - Report what was accomplished\n\n6. **Continue**\n   - Check for newly unblocked work with `ready`\n   - Repeat the cycle\n\n# Important Guidelines\n\n- Always update issue status (`in_progress` when starting, close when done)\n- Link discovered work with `discovered-from` dependencies\n- Don't close issues unless work is actually complete\n- If blocked, use `update` to set status to `blocked` and explain why\n- Communicate clearly about progress and blockers\n\n# Available Tools\n\nVia beads MCP server:\n- `ready` - Find unblocked tasks\n- `show` - Get task details\n- `update` - Update task status/fields\n- `create` - Create new issues\n- `dep` - Manage dependencies\n- `close` - Complete tasks\n- `blocked` - Check blocked issues\n- `stats` - View project stats\n\nYou are autonomous but should communicate your progress clearly. Start by finding ready work!\n",
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"beads-marketplace\",\n  \"description\": \"Local marketplace for beads plugin development\",\n  \"owner\": {\n    \"name\": \"Steve Yegge\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"beads\",\n      \"source\": \"./\",\n      \"description\": \"AI-supervised issue tracker for coding workflows\",\n      \"version\": \"0.44.0\"\n    }\n  ]\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"beads\",\n  \"description\": \"AI-supervised issue tracker for coding workflows. Manage tasks, discover work, and maintain context with simple CLI commands.\",\n  \"version\": \"0.44.0\",\n  \"author\": {\n    \"name\": \"Steve Yegge\",\n    \"url\": \"https://github.com/steveyegge\"\n  },\n  \"repository\": \"https://github.com/steveyegge/beads\",\n  \"license\": \"MIT\",\n  \"homepage\": \"https://github.com/steveyegge/beads\",\n  \"keywords\": [\n    \"issue-tracker\",\n    \"task-management\",\n    \"ai-workflow\",\n    \"agent-memory\"\n  ],\n  \"hooks\": {\n    \"SessionStart\": [\n      {\n        \"matcher\": \"\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"bd prime\"\n          }\n        ]\n      }\n    ],\n    \"PreCompact\": [\n      {\n        \"matcher\": \"\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"bd prime\"\n          }\n        ]\n      }\n    ]\n  }\n}\n",
        ".beads/README.md": "# Beads - AI-Native Issue Tracking\n\nWelcome to Beads! This repository uses **Beads** for issue tracking - a modern, AI-native tool designed to live directly in your codebase alongside your code.\n\n## What is Beads?\n\nBeads is issue tracking that lives in your repo, making it perfect for AI coding agents and developers who want their issues close to their code. No web UI required - everything works through the CLI and integrates seamlessly with git.\n\n**Learn more:** [github.com/steveyegge/beads](https://github.com/steveyegge/beads)\n\n## Quick Start\n\n### Essential Commands\n\n```bash\n# Create new issues\nbd create \"Add user authentication\"\n\n# View all issues\nbd list\n\n# View issue details\nbd show <issue-id>\n\n# Update issue status\nbd update <issue-id> --status in_progress\nbd update <issue-id> --status done\n\n# Sync with git remote\nbd sync\n```\n\n### Working with Issues\n\nIssues in Beads are:\n- **Git-native**: Stored in `.beads/issues.jsonl` and synced like code\n- **AI-friendly**: CLI-first design works perfectly with AI coding agents\n- **Branch-aware**: Issues can follow your branch workflow\n- **Always in sync**: Auto-syncs with your commits\n\n## Why Beads?\n\nâœ¨ **AI-Native Design**\n- Built specifically for AI-assisted development workflows\n- CLI-first interface works seamlessly with AI coding agents\n- No context switching to web UIs\n\nğŸš€ **Developer Focused**\n- Issues live in your repo, right next to your code\n- Works offline, syncs when you push\n- Fast, lightweight, and stays out of your way\n\nğŸ”§ **Git Integration**\n- Automatic sync with git commits\n- Branch-aware issue tracking\n- Intelligent JSONL merge resolution\n\n## Get Started with Beads\n\nTry Beads in your own projects:\n\n```bash\n# Install Beads\ncurl -sSL https://raw.githubusercontent.com/steveyegge/beads/main/scripts/install.sh | bash\n\n# Initialize in your repo\nbd init\n\n# Create your first issue\nbd create \"Try out Beads\"\n```\n\n## Learn More\n\n- **Documentation**: [github.com/steveyegge/beads/docs](https://github.com/steveyegge/beads/tree/main/docs)\n- **Quick Start Guide**: Run `bd quickstart`\n- **Examples**: [github.com/steveyegge/beads/examples](https://github.com/steveyegge/beads/tree/main/examples)\n\n---\n\n*Beads: Issue tracking that moves at the speed of thought* âš¡\n",
        ".claude/commands/handoff.md": "---\ndescription: Hand off to fresh session, work continues from hook\nallowed-tools: Bash(gt mail send:*),Bash(gt handoff:*)\nargument-hint: [message]\n---\n\nHand off to a fresh session.\n\nUser's handoff message (if any): $ARGUMENTS\n\nExecute these steps in order:\n\n1. If user provided a message, send handoff mail to yourself first.\n   Construct your mail address from your identity (e.g., beads/crew/emma for crew).\n   Example: `gt mail send beads/crew/emma -s \"HANDOFF: Session cycling\" -m \"USER_MESSAGE_HERE\"`\n\n2. Run the handoff command (this will respawn your session with a fresh Claude):\n   `gt handoff`\n\nNote: The new session will auto-prime via the SessionStart hook and find your handoff mail.\nEnd watch. A new session takes over, picking up any molecule on the hook.\n",
        ".claude/hooks/post-commit.sh": "#!/bin/bash\n# ABOUTME: Claude Code post-commit hook for tmux-beads-loops multi-agent orchestration.\n# ABOUTME: After git commit, auto-runs `bd sync --from-main` for workers to pull bead updates.\n#\n# Claude Code PostToolUse hooks receive JSON via stdin with tool_input.command\n# Silent for non-workers (coordinator, wt-manager).\n\n# Don't use set -e - we want graceful failure\n\n# Read JSON from stdin\ninput=\"$(cat)\"\n\n# Parse command from JSON (requires jq)\nif command -v jq &>/dev/null; then\n    bash_command=\"$(echo \"$input\" | jq -r '.tool_input.command // \"\"' 2>/dev/null)\"\n\n    # Only proceed if this was a git commit\n    if ! echo \"$bash_command\" | grep -q \"git commit\"; then\n        exit 0\n    fi\nfi\n\n# Exit cleanly if not running inside tmux\nif [ -z \"${TMUX:-}\" ]; then\n    exit 0\nfi\n\n# Get role from tmux (or env fallback)\nget_role() {\n    # First check environment variable (faster)\n    if [ -n \"${CLAUDE_ROLE:-}\" ]; then\n        echo \"$CLAUDE_ROLE\"\n        return\n    fi\n\n    # Then check tmux option\n    local role\n    role=\"$(tmux show -gqv \"@claude_role\" 2>/dev/null || true)\"\n    if [ -n \"$role\" ]; then\n        echo \"$role\"\n        return\n    fi\n\n    # Fallback: detect from window name\n    local window_name\n    local target=\"${TMUX_PANE:-}\"\n    if [ -n \"$target\" ]; then\n        window_name=\"$(tmux display-message -p -t \"$target\" '#W' 2>/dev/null || true)\"\n    else\n        window_name=\"$(tmux display-message -p '#W' 2>/dev/null || true)\"\n    fi\n\n    case \"$window_name\" in\n        coordinator) echo \"coordinator\" ;;\n        wt-manager) echo \"wt-manager\" ;;\n        beads-*|wt-*) echo \"worker\" ;;\n        *) echo \"unknown\" ;;\n    esac\n}\n\nrole=\"$(get_role)\"\n\n# Only run bd sync for workers\nif [ \"$role\" != \"worker\" ]; then\n    exit 0\nfi\n\n# Check if bd command exists\nif ! command -v bd &>/dev/null; then\n    # Silent exit - bd not available\n    exit 0\nfi\n\n# Run bd sync --from-main to pull updates from main beads db\n# This ensures worker beads stay in sync after commits\nbd sync --from-main 2>/dev/null || true\n\nexit 0\n",
        ".claude/hooks/pre-bash.sh": "#!/bin/bash\n# ABOUTME: Claude Code pre-bash hook for tmux-beads-loops multi-agent orchestration.\n# ABOUTME: Guards worker agents from escaping worktree, blocks unsafe tmux commands.\n#\n# Rules enforced:\n#   - For workers: block cd outside worktree\n#   - For workers: block git checkout to other branches (allow checkout -- files)\n#   - For all: block tmux send-keys without trailing \"Enter\"\n#\n# Claude Code PreToolUse hooks receive JSON via stdin with tool_input.command\n# Exit 0 = allow, Exit 2 = block (with stderr message)\n\nset -uo pipefail\n\n# Read JSON from stdin\ninput=\"$(cat)\"\n\n# Parse command from JSON (requires jq)\nif ! command -v jq &>/dev/null; then\n    # No jq, can't parse - allow by default\n    exit 0\nfi\n\ncommand=\"$(echo \"$input\" | jq -r '.tool_input.command // \"\"' 2>/dev/null)\"\n\n# If no command provided, allow\nif [ -z \"$command\" ]; then\n    exit 0\nfi\n\n# Get role from tmux (or env fallback)\nget_role() {\n    if [ -z \"${TMUX:-}\" ]; then\n        echo \"unknown\"\n        return\n    fi\n\n    # First check environment variable (faster)\n    if [ -n \"${CLAUDE_ROLE:-}\" ]; then\n        echo \"$CLAUDE_ROLE\"\n        return\n    fi\n\n    # Then check tmux option\n    local role\n    role=\"$(tmux show -gqv \"@claude_role\" 2>/dev/null || true)\"\n    if [ -n \"$role\" ]; then\n        echo \"$role\"\n        return\n    fi\n\n    # Fallback: detect from window name\n    local window_name\n    local target=\"${TMUX_PANE:-}\"\n    if [ -n \"$target\" ]; then\n        window_name=\"$(tmux display-message -p -t \"$target\" '#W' 2>/dev/null || true)\"\n    else\n        window_name=\"$(tmux display-message -p '#W' 2>/dev/null || true)\"\n    fi\n\n    case \"$window_name\" in\n        coordinator) echo \"coordinator\" ;;\n        wt-manager) echo \"wt-manager\" ;;\n        beads-*|wt-*) echo \"worker\" ;;\n        *) echo \"unknown\" ;;\n    esac\n}\n\n# Get worktree path from tmux\nget_worktree_path() {\n    if [ -z \"${TMUX:-}\" ]; then\n        echo \"\"\n        return\n    fi\n\n    # First check environment variable\n    if [ -n \"${WORKTREE_PATH:-}\" ]; then\n        echo \"$WORKTREE_PATH\"\n        return\n    fi\n\n    # Then check tmux option\n    tmux show -gqv \"@worktree_path\" 2>/dev/null || true\n}\n\n# Check if command is tmux send-keys without Enter\ncheck_tmux_send_keys() {\n    local cmd=\"$1\"\n\n    # Match tmux send-keys without \"Enter\" at end\n    if echo \"$cmd\" | grep -qE '^tmux\\s+send-keys'; then\n        # Check if it ends with \"Enter\" (case insensitive for safety)\n        if ! echo \"$cmd\" | grep -qEi '\\s+Enter\\s*$'; then\n            echo \"ERROR: tmux send-keys must end with 'Enter' to complete the command.\"\n            echo \"Use: tmux send-keys -t <target> \\\"<message>\\\" Enter\"\n            return 1\n        fi\n    fi\n    return 0\n}\n\n# Check if cd command goes outside worktree\ncheck_cd_command() {\n    local cmd=\"$1\"\n    local worktree=\"$2\"\n\n    # Only check actual cd commands\n    if ! echo \"$cmd\" | grep -qE '^\\s*cd\\s'; then\n        return 0\n    fi\n\n    # If no worktree defined, allow all\n    if [ -z \"$worktree\" ]; then\n        return 0\n    fi\n\n    # Extract the target path from cd command\n    local target_path\n    target_path=\"$(echo \"$cmd\" | sed -E 's/^\\s*cd\\s+//' | sed -E 's/\\s*[;&|].*$//' | sed 's/^\"//' | sed 's/\"$//' | sed \"s/^'//\" | sed \"s/'$//\")\"\n\n    # Handle relative paths - if it starts with . or doesn't start with /, it's relative\n    if [[ \"$target_path\" != /* ]]; then\n        # Relative paths within worktree are OK\n        return 0\n    fi\n\n    # Absolute path - check if it's within worktree\n    # Normalize paths by removing trailing slashes\n    local normalized_worktree=\"${worktree%/}\"\n    local normalized_target=\"${target_path%/}\"\n\n    # Check if target starts with worktree path\n    if [[ \"$normalized_target\" == \"$normalized_worktree\"* ]]; then\n        return 0\n    fi\n\n    echo \"ERROR: Workers cannot cd outside their worktree.\"\n    echo \"Worktree: $worktree\"\n    echo \"Blocked path: $target_path\"\n    return 1\n}\n\n# Check if git checkout is trying to switch branches\ncheck_git_checkout() {\n    local cmd=\"$1\"\n\n    # Only check git checkout commands\n    if ! echo \"$cmd\" | grep -qE '^\\s*git\\s+checkout'; then\n        return 0\n    fi\n\n    # Allow git checkout -- (file checkout)\n    if echo \"$cmd\" | grep -qE '^\\s*git\\s+checkout\\s+(--\\s|.*\\s--)'; then\n        return 0\n    fi\n\n    # Allow git checkout with file paths (containing / or .)\n    # This is a heuristic - branch names typically don't have / at start or .\n    local args\n    args=\"$(echo \"$cmd\" | sed -E 's/^\\s*git\\s+checkout\\s+//')\"\n\n    # If first non-flag arg looks like a file path, allow\n    if echo \"$args\" | grep -qE '^(-[a-zA-Z]+\\s+)*[./]'; then\n        return 0\n    fi\n\n    # Block branch checkout\n    echo \"ERROR: Workers should not checkout other branches.\"\n    echo \"Use 'git checkout -- <file>' to restore files.\"\n    echo \"Branch management is handled by the worktree manager.\"\n    return 1\n}\n\n# Main logic\nrole=\"$(get_role)\"\n\n# Rule: tmux send-keys must have Enter (applies to all roles)\nif ! check_tmux_send_keys \"$command\"; then\n    exit 2  # Exit 2 = blocking error in Claude Code hooks\nfi\n\n# Worker-specific rules\nif [ \"$role\" = \"worker\" ]; then\n    worktree_path=\"$(get_worktree_path)\"\n\n    # Rule: no cd outside worktree\n    if ! check_cd_command \"$command\" \"$worktree_path\"; then\n        exit 2\n    fi\n\n    # Rule: no git checkout to other branches\n    if ! check_git_checkout \"$command\"; then\n        exit 2\n    fi\nfi\n\n# Command allowed\nexit 0\n",
        ".claude/hooks/session-start.sh": "#!/bin/bash\n# ABOUTME: Claude Code session-start hook for tmux-beads-loops multi-agent orchestration.\n# ABOUTME: Detects agent role from tmux window name, sets tmux options, outputs cwd for workers.\n#\n# Window name patterns:\n#   - \"coordinator\" -> coordinator role\n#   - \"wt-manager\"  -> worktree manager role\n#   - \"beads-*\"     -> worker role\n#   - \"wt-*\"        -> worker role\n#\n# For workers: reads @worktree_path and outputs \"cwd: <path>\" to change working directory.\n\n# Don't use set -e here - we want graceful handling of missing tmux\n\n# Exit cleanly if not running inside tmux\nif [ -z \"${TMUX:-}\" ]; then\n    exit 0\nfi\n\n# Get window name from tmux\nget_window_name() {\n    local target=\"${TMUX_PANE:-}\"\n    if [ -n \"$target\" ]; then\n        tmux display-message -p -t \"$target\" '#W' 2>/dev/null\n    else\n        tmux display-message -p '#W' 2>/dev/null\n    fi\n}\n\n# Detect role based on window name\ndetect_role() {\n    local window_name=\"$1\"\n    case \"$window_name\" in\n        coordinator)\n            echo \"coordinator\"\n            ;;\n        wt-manager)\n            echo \"wt-manager\"\n            ;;\n        beads-*|wt-*)\n            echo \"worker\"\n            ;;\n        *)\n            echo \"unknown\"\n            ;;\n    esac\n}\n\n# Get tmux option value\nget_tmux_option() {\n    local option=\"$1\"\n    tmux show -gqv \"$option\" 2>/dev/null || true\n}\n\n# Set tmux option\nset_tmux_option() {\n    local option=\"$1\"\n    local value=\"$2\"\n    tmux set -g \"$option\" \"$value\" 2>/dev/null || true\n}\n\n# Main logic\nwindow_name=\"$(get_window_name)\"\nif [ -z \"$window_name\" ]; then\n    exit 0\nfi\n\nrole=\"$(detect_role \"$window_name\")\"\n\n# Set the role in tmux options\nset_tmux_option \"@claude_role\" \"$role\"\n\n# For workers, check for worktree path and output cwd directive\nif [ \"$role\" = \"worker\" ]; then\n    worktree_path=\"$(get_tmux_option \"@worktree_path\")\"\n    if [ -n \"$worktree_path\" ] && [ -d \"$worktree_path\" ]; then\n        echo \"cwd: $worktree_path\"\n    fi\nfi\n\nexit 0\n",
        ".claude/hooks/stop.sh": "#!/bin/bash\n# ABOUTME: Claude Code stop hook for tmux-beads-loops multi-agent orchestration.\n# ABOUTME: On session end, if worker has assigned bead, notify coordinator.\n#\n# Sends: tmux send-keys -t coordinator \"Worker stopping, was on $BEAD\" Enter\n# Silent for non-workers or workers without assigned beads.\n\n# Don't use set -e - we want graceful failure\n\n# Exit cleanly if not running inside tmux\nif [ -z \"${TMUX:-}\" ]; then\n    exit 0\nfi\n\n# Get role from tmux (or env fallback)\nget_role() {\n    # First check environment variable (faster)\n    if [ -n \"${CLAUDE_ROLE:-}\" ]; then\n        echo \"$CLAUDE_ROLE\"\n        return\n    fi\n\n    # Then check tmux option\n    local role\n    role=\"$(tmux show -gqv \"@claude_role\" 2>/dev/null || true)\"\n    if [ -n \"$role\" ]; then\n        echo \"$role\"\n        return\n    fi\n\n    # Fallback: detect from window name\n    local window_name\n    local target=\"${TMUX_PANE:-}\"\n    if [ -n \"$target\" ]; then\n        window_name=\"$(tmux display-message -p -t \"$target\" '#W' 2>/dev/null || true)\"\n    else\n        window_name=\"$(tmux display-message -p '#W' 2>/dev/null || true)\"\n    fi\n\n    case \"$window_name\" in\n        coordinator) echo \"coordinator\" ;;\n        wt-manager) echo \"wt-manager\" ;;\n        beads-*|wt-*) echo \"worker\" ;;\n        *) echo \"unknown\" ;;\n    esac\n}\n\n# Get assigned bead from tmux option\nget_assigned_bead() {\n    # First check environment variable\n    if [ -n \"${ASSIGNED_BEAD:-}\" ]; then\n        echo \"$ASSIGNED_BEAD\"\n        return\n    fi\n\n    # Then check tmux option\n    tmux show -gqv \"@assigned_bead\" 2>/dev/null || true\n}\n\n# Get coordinator target (window name to send notification to)\nget_coordinator_target() {\n    # First check if explicitly set\n    local target\n    target=\"$(tmux show -gqv \"@coordinator_target\" 2>/dev/null || true)\"\n    if [ -n \"$target\" ]; then\n        echo \"$target\"\n        return\n    fi\n\n    # Default to \"coordinator\" window name\n    echo \"coordinator\"\n}\n\nrole=\"$(get_role)\"\n\n# Only notify for workers\nif [ \"$role\" != \"worker\" ]; then\n    exit 0\nfi\n\n# Get assigned bead\nbead=\"$(get_assigned_bead)\"\n\n# If no bead assigned, exit silently\nif [ -z \"$bead\" ]; then\n    exit 0\nfi\n\n# Get coordinator target\ncoordinator=\"$(get_coordinator_target)\"\n\n# Notify coordinator\n# Use send-keys with Enter to ensure the message is submitted\ntmux send-keys -t \"$coordinator\" \"Worker stopping, was on $bead\" Enter 2>/dev/null || true\n\nexit 0\n",
        ".claude/skills/README.md": "# Skills: Tmux Multi-Agent Orchestration\n\nThis directory contains Claude Code skills for a three-role multi-agent architecture using tmux.\n\n## Architecture Overview\n\nThree Claude instances communicate via natural language through tmux send-keys:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                      tmux session                           â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ coordinator â”‚     wt-manager      â”‚   worker-N (dynamic)    â”‚\nâ”‚             â”‚                     â”‚                         â”‚\nâ”‚ - Manages   â”‚ - Creates worktrees â”‚ - Implements tasks      â”‚\nâ”‚   beads     â”‚ - Spawns windows    â”‚ - Full tool access      â”‚\nâ”‚ - Assigns   â”‚ - Sets tmux options â”‚ - Reports completion    â”‚\nâ”‚   work      â”‚ - Cleans up         â”‚ - Waits for assignment  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Roles\n\n### coordinator\n**Location:** `coordinator/SKILL.md`\n\nThe orchestrator. Manages work items (beads), delegates to workers, and tracks overall progress. Never implements code directly.\n\nKey commands:\n- `bd create`, `bd ready`, `bd list`, `bd close`\n- `tmux send-keys -t <window>` for communication\n\n### wt-manager\n**Location:** `wt-manager/SKILL.md`\n\nInfrastructure manager. Creates git worktrees for isolation, spawns tmux windows for workers, sets window options, and handles cleanup.\n\nKey commands:\n- `git worktree add/remove`\n- `tmux new-window`, `tmux set-option`, `tmux kill-window`\n\n### worker\n**Location:** `worker/SKILL.md`\n\nImplementation agent. Receives assignments, implements tasks with full tool access, closes beads when done, and notifies coordinator.\n\nKey commands:\n- `bd show`, `bd close`\n- All standard Claude tools for implementation\n\n## Communication Flow\n\n1. **coordinator** finds work: `bd ready`\n2. **coordinator** requests worktree from **wt-manager**\n3. **wt-manager** creates worktree, spawns window, reports ready\n4. **coordinator** sends assignment to **worker** window\n5. **worker** implements, closes bead, notifies **coordinator**\n6. **coordinator** syncs changes, assigns next task or idles worker\n\n## Key Principles\n\n- **Natural language communication** via tmux - no special protocols\n- **Workers wait** for assignments - they don't self-assign\n- **Completion signals** require both `bd close` AND notifying coordinator\n- **One bead per worker** at a time for isolation\n- **Worktree isolation** ensures workers don't interfere with each other\n",
        ".claude/skills/coordinator/SKILL.md": "# Coordinator Skill\n\nYou are the coordinator managing a team of Claude agents via tmux.\n\n## Your Role\n- Manage work via beads (`bd create`, `bd ready`, `bd list`, `bd close`)\n- Request worktrees from wt-manager (window wt-manager)\n- Assign work to workers via `tmux send-keys -t <window> \"...\" Enter`\n- Wait for workers to report completion - don't poll\n- When worker reports done, assign next task or let them idle\n\n## Communication\nNatural language via tmux. Examples:\n- To wt-manager: \"Create a worktree for beads-042, it's an auth feature\"\n- To worker: \"Work on beads-042 - implement JWT authentication\"\n\n## Workflow\n1. `bd ready` to find available work\n2. Ask wt-manager to create worktree for the bead\n3. Wait for wt-manager to confirm window is ready\n4. Send assignment to worker window\n5. Wait for worker to report completion\n6. `bd sync --from-main` to pull updates\n7. Repeat\n\n## Rules\n- Never implement code yourself - delegate to workers\n- One bead per worker at a time\n- Track assignments mentally or in /tmp/coordinator-state.txt\n",
        ".claude/skills/handoff/SKILL.md": "---\nname: handoff\ndescription: >\n  Hand off to a fresh Claude session. Use when context is full, you've finished\n  a logical chunk of work, or need a fresh perspective. Work continues from hook.\nallowed-tools: \"Bash(gt handoff:*),Bash(gt mail send:*)\"\nversion: \"1.0.0\"\nauthor: \"Gas Town\"\n---\n\n# Handoff - Session Cycling for Gas Town Agents\n\nHand off your current session to a fresh Claude instance while preserving work context.\n\n## When to Use\n\n- Context getting full (approaching token limit)\n- Finished a logical chunk of work\n- Need a fresh perspective on a problem\n- Human requests session cycling\n\n## Usage\n\n```\n/handoff [optional message]\n```\n\n## How It Works\n\n1. If you provide a message, it's sent as handoff mail to yourself\n2. `gt handoff` respawns your session with a fresh Claude\n3. New session auto-primes via SessionStart hook\n4. Work continues from your hook (pinned molecule persists)\n\n## Examples\n\n```bash\n# Simple handoff (molecule persists, fresh context)\n/handoff\n\n# Handoff with context notes\n/handoff \"Found the bug in token refresh - check line 145 in auth.go first\"\n```\n\n## What Persists\n\n- **Hooked molecule**: Your work assignment stays on your hook\n- **Beads state**: All issues, dependencies, progress\n- **Git state**: Commits, branches, staged changes\n\n## What Resets\n\n- **Conversation context**: Fresh Claude instance\n- **TodoWrite items**: Ephemeral, session-scoped\n- **In-memory state**: Any uncommitted analysis\n\n## Implementation\n\nWhen invoked, execute:\n\n1. If user provided a message, send handoff mail:\n   ```bash\n   gt mail send <your-address> -s \"HANDOFF: Session cycling\" -m \"<message>\"\n   ```\n\n2. Run the handoff command:\n   ```bash\n   gt handoff\n   ```\n\nThe new session will find your handoff mail and hooked work automatically.\n",
        ".claude/skills/orchestrate/SKILL.md": "# Orchestrate Skill\n\nActivate tmux multi-agent orchestration mode.\n\n## When User Says\n- \"lets use tmux and get some work done\"\n- \"orchestrate\"\n- \"start orchestration\"\n- \"multi-agent mode\"\n\n## What You Do\n\n### 1. Bootstrap Current Window as Coordinator\n\n```bash\n# Rename current window to coordinator\ntmux rename-window coordinator\n\n# Register as beads manager\nSESSION=$(tmux display-message -p '#S')\nWINDOW=$(tmux display-message -p '#I')\nPANE=$(tmux display-message -p '#P')\nPANE_ID=$(tmux display-message -p '#{pane_id}')\n\ntmux set -g @beads_manager \"${SESSION}:${WINDOW}\"\ntmux set -g @beads_manager_pane \"$PANE_ID\"\ntmux set -g @claude_role \"coordinator\"\n```\n\n### 2. Create Worktree Manager Window (Same Session)\n\n```bash\n# Get current session name\nSESSION=$(tmux display-message -p '#S')\n\n# Create new window in THIS session\ntmux new-window -t \"$SESSION\" -n wt-manager\ntmux send-keys -t \"${SESSION}:wt-manager\" \"claude\" Enter\n```\n\n### 3. Confirm Setup\n\nTell user:\n- You are now the **coordinator** in window `coordinator`\n- Worktree manager is starting in window `wt-manager`\n- Use `bd ready` to find work\n- Ask wt-manager to create worktrees for beads\n- Workers spawn as `beads-*` windows\n\n## Your Role as Coordinator\n\nYou manage work via beads and delegate to workers:\n\n1. `bd ready` - find available work\n2. Ask wt-manager: \"Create a worktree for beads-XXX\"\n3. Wait for wt-manager to confirm window is ready\n4. Send work: `tmux send-keys -t beads-XXX \"Work on beads-XXX: <description>\" Enter`\n5. Wait for worker to report completion\n6. `bd sync --from-main` to pull updates\n7. Repeat\n\n## Rules\n- Never implement code yourself - delegate to workers\n- One bead per worker at a time\n- Natural language communication via tmux send-keys\n- Always end send-keys with `Enter`\n",
        ".claude/skills/worker/SKILL.md": "# Worker Skill\n\nYou are a worker agent implementing assigned tasks.\n\n## Your Role\n- Wait for coordinator to assign work\n- Implement the assigned task using all available tools\n- Use sub-agents freely if helpful\n- Close the bead when done\n- Notify coordinator of completion\n\n## Workflow\n1. Wait for assignment from coordinator (they send via tmux)\n2. Read the bead: `bd show <bead-id>`\n3. Implement the task (you have full tool access)\n4. Run tests, ensure quality\n5. Commit your changes\n6. Close the bead: `bd close <bead-id> --reason=\"<what you did>\"`\n7. Notify coordinator: Tell them you're done and summarize the work\n8. Wait for next assignment - DO NOT self-assign\n\n## Communication\nWhen done, send a natural language message to coordinator:\n\"Finished beads-042 - implemented JWT auth with refresh tokens, all tests passing\"\n\n## Rules\n- Stay in your assigned worktree (hooks enforce this)\n- Don't switch branches (hooks enforce this)\n- Don't work on beads you weren't assigned\n- Always notify coordinator when done\n- Wait patiently for next assignment\n",
        ".claude/skills/wt-manager/SKILL.md": "# Worktree Manager Skill\n\nYou manage git worktrees and spawn worker windows.\n\n## Your Role\n- Create worktrees when coordinator requests\n- Spawn new tmux windows for workers\n- Set up window tmux options (@worktree_path, @assigned_bead)\n- Clean up worktrees when workers finish\n- Report status back to coordinator\n\n## Commands You Use\n```bash\n# Create worktree\ngit worktree add ../wt-<bead-id> -b <bead-id>\n\n# Spawn worker window\ntmux new-window -n <bead-id>\n\n# Set window options for the worker\ntmux set-option -t <bead-id> -w @worktree_path \"../wt-<bead-id>\"\ntmux set-option -t <bead-id> -w @assigned_bead \"<bead-id>\"\ntmux set-option -t <bead-id> -w @assigned_branch \"<bead-id>\"\n\n# Start claude in the window\ntmux send-keys -t <bead-id> \"cd ../wt-<bead-id> && claude\" Enter\n\n# Cleanup\ngit worktree remove ../wt-<bead-id>\ntmux kill-window -t <bead-id>\n```\n\n## Workflow\n1. Receive request from coordinator\n2. Create worktree with bead branch\n3. Spawn window, set options, start claude\n4. Report back: \"Window <bead-id> ready with worktree at ../wt-<bead-id>\"\n5. On cleanup request, remove worktree and window\n\n## Rules\n- Always set all three window options before starting claude\n- Use bead ID for branch name and window name for consistency\n- Report clearly to coordinator\n",
        ".devcontainer/README.md": "# beads Development Container\n\nThis devcontainer configuration provides a fully-configured development environment for beads with:\n\n- Go 1.23 development environment\n- bd CLI built and installed from source\n- Git hooks automatically installed\n- All dependencies pre-installed\n\n## Quick Start\n\n### GitHub Codespaces\n\n1. Click the \"Code\" button on GitHub\n2. Select \"Create codespace on main\"\n3. Wait for the container to build (~2-3 minutes)\n4. The environment will be ready with bd installed and configured\n\n### VS Code Remote Containers\n\n1. Install the [Remote - Containers](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers) extension\n2. Open the beads repository in VS Code\n3. Click \"Reopen in Container\" when prompted (or use Command Palette: \"Remote-Containers: Reopen in Container\")\n4. Wait for the container to build\n\n## What Gets Installed\n\nThe `setup.sh` script automatically:\n\n1. Builds bd from source (`go build ./cmd/bd`)\n2. Installs bd to `/usr/local/bin/bd`\n3. Runs `bd init --quiet` (non-interactive initialization)\n4. Installs git hooks from `examples/git-hooks/`\n5. Downloads Go module dependencies\n\n## Verification\n\nAfter the container starts, verify everything works:\n\n```bash\n# Check bd is installed\nbd --version\n\n# Check for ready tasks\nbd ready\n\n# View project stats\nbd stats\n```\n\n## Git Configuration\n\nYour local `.gitconfig` is mounted into the container so your git identity is preserved. If you need to configure git:\n\n```bash\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"your.email@example.com\"\n```\n\n## Troubleshooting\n\n**bd command not found:**\n- The setup script should install bd automatically\n- Manually run: `bash .devcontainer/setup.sh`\n\n**Git hooks not working:**\n- Check if hooks are installed: `ls -la .git/hooks/`\n- Manually install: `bash examples/git-hooks/install.sh`\n\n**Container fails to build:**\n- Check the container logs for specific errors\n- Ensure Docker/Podman is running and has sufficient resources\n- Try rebuilding: Command Palette â†’ \"Remote-Containers: Rebuild Container\"\n\n## Related Issues\n\n- GitHub Issue [#229](https://github.com/steveyegge/beads/issues/229): Git hooks not available in devcontainers\n- bd-ry1u: Publish official devcontainer configuration\n",
        "README.md": "# tmux-beads-loops\n\nCredit: This project is a fork of Beads by Steve Yegge (https://github.com/steveyegge/beads).\n\ntmux-beads-loops is a tmux-first orchestration layer on top of Beads for multi-agent coding loops.\n\n## Purpose\n\nCoordinate multiple coding agents in tmux panes with a shared task graph and isolated git worktrees.\n\n## What It Does\n\n- Registers a manager pane, exports tmux-aware env vars, and routes worker notifications back to the manager.\n- Adds a safe delegate helper for manager â†’ worker commands (sends Enter and avoids self-targeting).\n- Creates and cleans per-agent worktrees with predictable branch naming.\n- Bootstraps Claude, Codex, and OpenCode sessions to share the same hook behavior.\n\n## Loop Flow\n\n1) Start a single tmux agent in a manager window.\n2) Use that agent to define steps and decide which additional agents to spawn.\n3) Spawn new panes for Claude/Codex/OpenCode in the same tmux session (manager window).\n4) Workers claim tasks in Beads and notify the manager via tmux.\n5) Manager delegates to workers via `delegate.sh` (same tmux session).\n\nNote: If you use `clauded`/`codexd` aliases, ensure they point to the CLI you expect.\n\nSuggested commands (same session):\n\n```bash\nscripts/tmux-beads-loops/spawn-agent.sh claude\nscripts/tmux-beads-loops/delegate.sh --window claude-1 -- \"bd ready\"\n```\n\nPane defaults (aliases supported):\n\n```bash\nTMUX_BEADS_CLAUDE_CMD=clauded TMUX_BEADS_CODEX_CMD=codexd \\\n  scripts/tmux-beads-loops/spawn-agent.sh claude --split v --name claude-1\n```\n\nAuto-bootstrap (manager only):\n\n```bash\nTMUX_BEADS_BOOTSTRAP_TOTAL=4 \\\nTMUX_BEADS_CLAUDE_CMD=clauded TMUX_BEADS_CODEX_CMD=codexd \\\ncodexd\n```\n\nManual bootstrap:\n\n```bash\nscripts/tmux-beads-loops/bootstrap.sh --total 4\n```\n\nNote: tmux panes require splits, but this keeps everything in the same window (no new windows).\n\n## How It Works\n\n- Uses tmux global options (like `@beads_manager` + `@beads_manager_pane`) to track the manager window + pane.\n- Defaults to pane spawns; set `--mode window` if you prefer new windows.\n- Uses per-agent git worktrees and disables the beads daemon for safety (`BEADS_NO_DAEMON=1`).\n- Tracks tasks with the `bd` CLI, optionally on a dedicated metadata branch.\n\n## Works With\n\ntmux, git worktrees, Beads (`bd`), Claude CLI, Codex CLI, and OpenCode (via wrapper).\n\n## Value\n\nDurable task coordination, fewer context handoff mistakes, and a predictable manager/worker loop.\n\n## Status\n\nBeta at best. Scripts and hooks may change; review before use and avoid critical production workflows.\n\n## Docs\n\nSee `docs/TMUX_BEADS_LOOPS.md` for the tmux workflow, hooks, and scripts.\n\nBelow is the upstream Beads README for reference.\n\n# bd - Beads\n\n**Distributed, git-backed graph issue tracker for AI agents.**\n\n[![License](https://img.shields.io/github/license/steveyegge/beads)](LICENSE)\n[![Go Report Card](https://goreportcard.com/badge/github.com/steveyegge/beads)](https://goreportcard.com/report/github.com/steveyegge/beads)\n[![Release](https://img.shields.io/github/v/release/steveyegge/beads)](https://github.com/steveyegge/beads/releases)\n[![npm version](https://img.shields.io/npm/v/@beads/bd)](https://www.npmjs.com/package/@beads/bd)\n[![PyPI](https://img.shields.io/pypi/v/beads-mcp)](https://pypi.org/project/beads-mcp/)\n\nBeads provides a persistent, structured memory for coding agents. It replaces messy markdown plans with a dependency-aware graph, allowing agents to handle long-horizon tasks without losing context.\n\n## âš¡ Quick Start\n\n```bash\n# Install (macOS/Linux)\ncurl -fsSL https://raw.githubusercontent.com/steveyegge/beads/main/scripts/install.sh | bash\n\n# Initialize (Humans run this once)\nbd init\n\n# Tell your agent\necho \"Use 'bd' for task tracking\" >> AGENTS.md\n\n```\n\n## ğŸ›  Features\n\n* **Git as Database:** Issues stored as JSONL in `.beads/`. Versioned, branched, and merged like code.\n* **Agent-Optimized:** JSON output, dependency tracking, and auto-ready task detection.\n* **Zero Conflict:** Hash-based IDs (`bd-a1b2`) prevent merge collisions in multi-agent/multi-branch workflows.\n* **Invisible Infrastructure:** SQLite local cache for speed; background daemon for auto-sync.\n* **Compaction:** Semantic \"memory decay\" summarizes old closed tasks to save context window.\n\n## ğŸ“– Essential Commands\n\n| Command | Action |\n| --- | --- |\n| `bd ready` | List tasks with no open blockers. |\n| `bd create \"Title\" -p 0` | Create a P0 task. |\n| `bd dep add <child> <parent>` | Link tasks (blocks, related, parent-child). |\n| `bd show <id>` | View task details and audit trail. |\n\n## ğŸ”— Hierarchy & Workflow\n\nBeads supports hierarchical IDs for epics:\n\n* `bd-a3f8` (Epic)\n* `bd-a3f8.1` (Task)\n* `bd-a3f8.1.1` (Sub-task)\n\n**Stealth Mode:** Run `bd init --stealth` to use Beads locally without committing files to the main repo. Perfect for personal use on shared projects.\n\n## ğŸ“¦ Installation\n\n* **npm:** `npm install -g @beads/bd`\n* **Homebrew:** `brew install steveyegge/beads/bd`\n* **Go:** `go install github.com/steveyegge/beads/cmd/bd@latest`\n\n**Requirements:** Linux (glibc 2.32+), macOS, or Windows.\n\n## ğŸŒ Community Tools\n\nSee [docs/COMMUNITY_TOOLS.md](docs/COMMUNITY_TOOLS.md) for a curated list of community-built UIs, extensions, and integrationsâ€”including terminal interfaces, web UIs, editor extensions, and native apps.\n\n## ğŸ“ Documentation\n\n* [Installing](docs/INSTALLING.md) | [Agent Workflow](AGENT_INSTRUCTIONS.md) | [Sync Branch Mode](docs/PROTECTED_BRANCHES.md) | [Troubleshooting](docs/TROUBLESHOOTING.md) | [FAQ](docs/FAQ.md)\n* [![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/steveyegge/beads)\n",
        "cmd/bd/templates/hooks/post-checkout": "#!/usr/bin/env sh\n# bd-shim v1\n# bd-hooks-version: 0.44.0\n#\n# bd (beads) post-checkout hook - thin shim\n#\n# This shim delegates to 'bd hooks run post-checkout' which contains\n# the actual hook logic. This pattern ensures hook behavior is always\n# in sync with the installed bd version - no manual updates needed.\n\n# Check if bd is available\nif ! command -v bd >/dev/null 2>&1; then\n    # Silently skip - post-checkout is called frequently\n    exit 0\nfi\n\nexec bd hooks run post-checkout \"$@\"\n",
        "cmd/bd/templates/hooks/post-merge": "#!/usr/bin/env sh\n# bd-shim v1\n# bd-hooks-version: 0.44.0\n#\n# bd (beads) post-merge hook - thin shim\n#\n# This shim delegates to 'bd hooks run post-merge' which contains\n# the actual hook logic. This pattern ensures hook behavior is always\n# in sync with the installed bd version - no manual updates needed.\n\n# Check if bd is available\nif ! command -v bd >/dev/null 2>&1; then\n    echo \"Warning: bd command not found in PATH, skipping post-merge hook\" >&2\n    echo \"  Install bd: brew install steveyegge/tap/bd\" >&2\n    echo \"  Or add bd to your PATH\" >&2\n    exit 0\nfi\n\nexec bd hooks run post-merge \"$@\"\n",
        "cmd/bd/templates/hooks/pre-commit": "#!/usr/bin/env sh\n# bd-shim v1\n# bd-hooks-version: 0.44.0\n#\n# bd (beads) pre-commit hook - thin shim\n#\n# This shim delegates to 'bd hooks run pre-commit' which contains\n# the actual hook logic. This pattern ensures hook behavior is always\n# in sync with the installed bd version - no manual updates needed.\n\n# Check if bd is available\nif ! command -v bd >/dev/null 2>&1; then\n    echo \"Warning: bd command not found in PATH, skipping pre-commit hook\" >&2\n    echo \"  Install bd: brew install steveyegge/tap/bd\" >&2\n    echo \"  Or add bd to your PATH\" >&2\n    exit 0\nfi\n\nexec bd hooks run pre-commit \"$@\"\n",
        "cmd/bd/templates/hooks/pre-push": "#!/usr/bin/env sh\n# bd-shim v1\n# bd-hooks-version: 0.44.0\n#\n# bd (beads) pre-push hook - thin shim\n#\n# This shim delegates to 'bd hooks run pre-push' which contains\n# the actual hook logic. This pattern ensures hook behavior is always\n# in sync with the installed bd version - no manual updates needed.\n\n# Check if bd is available\nif ! command -v bd >/dev/null 2>&1; then\n    echo \"Warning: bd command not found in PATH, skipping pre-push hook\" >&2\n    echo \"  Install bd: brew install steveyegge/tap/bd\" >&2\n    echo \"  Or add bd to your PATH\" >&2\n    exit 0\nfi\n\nexec bd hooks run pre-push \"$@\"\n",
        "cmd/bd/templates/hooks/prepare-commit-msg": "#!/usr/bin/env sh\n# bd-shim v1\n# bd-hooks-version: 0.41.0\n#\n# bd (beads) prepare-commit-msg hook - thin shim\n#\n# This shim delegates to 'bd hooks run prepare-commit-msg' which contains\n# the actual hook logic. This pattern ensures hook behavior is always\n# in sync with the installed bd version - no manual updates needed.\n#\n# Arguments:\n#   $1 = path to the commit message file\n#   $2 = source of commit message (message, template, merge, squash, commit)\n#   $3 = commit SHA-1 (if -c, -C, or --amend)\n\n# Check if bd is available\nif ! command -v bd >/dev/null 2>&1; then\n    echo \"Warning: bd command not found in PATH, skipping prepare-commit-msg hook\" >&2\n    echo \"  Install bd: brew install steveyegge/tap/bd\" >&2\n    echo \"  Or add bd to your PATH\" >&2\n    exit 0\nfi\n\nexec bd hooks run prepare-commit-msg \"$@\"\n",
        "commands/audit.md": "---\ndescription: Log and label agent interactions (append-only JSONL)\nargument-hint: record|label\n---\n\nAppend-only audit logging for agent interactions (prompts, responses, tool calls) in `.beads/interactions.jsonl`.\n\nEach line is one event. Labeling is done by appending a new `\"label\"` event referencing a previous entry.\n\n## Usage\n\n- **Record an interaction**:\n  - `bd audit record --kind llm_call --model \"claude-3-5-haiku\" --prompt \"...\" --response \"...\"`\n  - `bd audit record --kind tool_call --tool-name \"go test\" --exit-code 1 --error \"...\" --issue-id bd-42`\n\n- **Pipe JSON via stdin**:\n  - `cat event.json | bd audit record`\n\n- **Label an entry**:\n  - `bd audit label int-a1b2 --label good --reason \"Worked perfectly\"`\n  - `bd audit label int-a1b2 --label bad --reason \"Hallucinated a file path\"`\n\n## Notes\n\n- Audit entries are **append-only** (no in-place edits).\n- `bd sync` includes `.beads/interactions.jsonl` in the commit allowlist (like `issues.jsonl`).\n\n\n",
        "commands/blocked.md": "---\ndescription: Show blocked issues\nargument-hint: []\n---\n\nShow all issues that are blocked by dependencies.\n\nUse `bd blocked` to see which issues have blockers preventing them from being worked on. This is the inverse of `bd ready` - it shows what's NOT ready.\n\nBlocked issues have one or more dependencies with type \"blocks\" that are still open. Once all blocking dependencies are closed, the issue becomes ready and will appear in `bd ready`.\n\nUseful for:\n- Understanding why work is stuck\n- Identifying critical path items\n- Planning dependency resolution\n",
        "commands/close.md": "---\ndescription: Close a completed issue\nargument-hint: [issue-id] [reason]\n---\n\nClose a beads issue that's been completed.\n\nIf arguments are provided:\n- $1: Issue ID\n- $2+: Completion reason (optional)\n\nIf the issue ID is missing, ask for it. Optionally ask for a reason describing what was done.\n\nUse the beads MCP `close` tool to close the issue. Show confirmation with the issue details.\n\nAfter closing, suggest checking for:\n- Dependent issues that might now be unblocked (use `ready` tool)\n- New work discovered during this task (use `create` tool with `discovered-from` link)\n",
        "commands/comments.md": "---\ndescription: View or manage comments on an issue\nargument-hint: [issue-id]\n---\n\nView or add comments to a beads issue.\n\nComments are separate from issue properties (title, description, etc.) because they serve a different purpose: they're a **discussion thread** rather than **singular editable fields**. Use `bd comments` for threaded conversations and `bd edit` for core issue metadata.\n\n## View Comments\n\nTo view all comments on an issue:\n- $1: Issue ID (e.g., bd-123)\n\nUse the beads CLI `bd comments <issue-id>` to list all comments. Show them to the user with timestamps and authors.\n\n## Add Comment\n\nTo add a comment:\n- $1: \"add\"\n- $2: Issue ID\n- $3: Comment text (or use -f flag for file input)\n\nUse `bd comments add <issue-id> \"comment text\"` to add a comment. Confirm the comment was added successfully.\n\nComments are useful for:\n- Progress updates during work\n- Design notes or technical decisions\n- Links to related resources\n- Questions or blockers\n",
        "commands/compact.md": "---\ndescription: Compact old closed issues using semantic summarization\nargument-hint: [--all] [--id issue-id] [--dry-run]\n---\n\nReduce database size by summarizing closed issues no longer actively referenced.\n\n## Compaction Tiers\n\n- **Tier 1**: Semantic compression (30+ days closed, ~70% size reduction)\n- **Tier 2**: Ultra compression (90+ days closed, ~95% size reduction)\n\n## Usage\n\n- **Preview candidates**: `bd admin compact --dry-run`\n- **Compact all eligible**: `bd admin compact --all`\n- **Compact specific issue**: `bd admin compact --id bd-42`\n- **Force compact**: `bd admin compact --id bd-42 --force` (bypass age checks)\n- **View statistics**: `bd admin compact --stats`\n\n## Options\n\n- **--tier**: Choose compaction tier (1 or 2, default: 1)\n- **--workers**: Parallel workers (default: 5)\n- **--batch-size**: Issues per batch (default: 10)\n\n## Important\n\nThis is **permanent graceful decay** - original content is discarded. Use `bd restore <id>` to view full history from git if needed.\n\nUseful for long-running projects to keep database size manageable.\n",
        "commands/create.md": "---\ndescription: Create a new issue interactively\nargument-hint: [title] [type] [priority]\n---\n\nCreate a new beads issue. If arguments are provided:\n- $1: Issue title\n- $2: Issue type (bug, feature, task, epic, chore)\n- $3: Priority (0-4, where 0=critical, 4=backlog)\n\nIf arguments are missing, ask the user for:\n1. Issue title (required)\n2. Issue type (default: task)\n3. Priority (default: 2)\n4. Description (optional)\n\nUse the beads MCP `create` tool to create the issue. Show the created issue ID and details to the user.\n\nOptionally ask if this issue should be linked to another issue (discovered-from, blocks, parent-child, related).\n",
        "commands/daemon.md": "---\ndescription: Manage background sync daemon\nargument-hint: [--start] [--stop] [--status] [--health]\n---\n\nManage the per-project background daemon that handles database connections and syncs with git.\n\n## Per-Project Daemon (LSP Model)\n\nEach project runs its own daemon at `.beads/bd.sock` for complete database isolation.\n\n> On Windows this file stores the daemon's loopback TCP endpoint metadataâ€”leave it in place so bd can reconnect.\n\n**Why per-project daemons?**\n- Complete database isolation between projects\n- No cross-project pollution or git worktree conflicts\n- Simpler mental model: one project = one database = one daemon\n- Follows LSP (Language Server Protocol) architecture\n\n**Note:** Global daemon support was removed in v0.16.0. The `--global` flag is no longer functional.\n\n## When to Use Daemon Mode\n\n**âœ… You SHOULD use daemon mode if:**\n- Working in a team with git remote sync\n- Want automatic commit/push of issue changes\n- Need background auto-sync (5-second debounce)\n- Making frequent bd commands (performance benefit from connection pooling)\n\n**âŒ You DON'T need daemon mode if:**\n- Solo developer with local-only tracking\n- Working in git worktrees (use --no-daemon to avoid conflicts)\n- Running one-off commands or scripts\n- Debugging database issues (direct mode is simpler)\n\n**Local-only users:** Direct mode (default without daemon) is perfectly fine. The daemon mainly helps with git sync automation. You can still use `bd sync` manually when needed.\n\n**Performance note:** For most operations, the daemon provides minimal performance benefit. The main value is automatic JSONL export (5s debounce) and optional git sync (--auto-commit, --auto-push).\n\n## Common Operations\n\n- **Start**: `bd daemon --start` (or auto-starts on first `bd` command)\n- **Stop**: `bd daemon --stop`\n- **Status**: `bd daemon --status`\n- **Health**: `bd daemon --health` - shows uptime, cache stats, performance metrics\n- **Metrics**: `bd daemon --metrics` - detailed operational telemetry\n\n## Sync Options\n\n- **--auto-commit**: Automatically commit JSONL changes\n- **--auto-push**: Automatically push commits to remote\n- **--interval**: Sync check interval (default: 5m)\n\nThe daemon provides:\n- Connection pooling and caching\n- Better performance for frequent operations\n- Automatic JSONL sync (5-second debounce)\n- Optional git sync\n",
        "commands/daemons.md": "# bd daemons - Daemon Management\n\nManage bd daemon processes across all repositories and worktrees.\n\n## Synopsis\n\n```bash\nbd daemons <subcommand> [flags]\n```\n\n## Description\n\nThe `bd daemons` command provides tools for discovering, monitoring, and managing multiple bd daemon processes across your system. This is useful when working with multiple repositories or git worktrees.\n\n## Subcommands\n\n### list\n\nList all running bd daemons with metadata.\n\n```bash\nbd daemons list [--search DIRS] [--json] [--no-cleanup]\n```\n\n**Flags:**\n- `--search` - Directories to search for daemons (default: home, /tmp, cwd)\n- `--json` - Output in JSON format\n- `--no-cleanup` - Skip auto-cleanup of stale sockets\n\n**Example:**\n```bash\nbd daemons list\nbd daemons list --search /Users/me/projects --json\n```\n\n### health\n\nCheck health of all bd daemons and report issues.\n\n```bash\nbd daemons health [--search DIRS] [--json]\n```\n\nReports:\n- Stale sockets (dead processes)\n- Version mismatches between daemon and CLI\n- Unresponsive daemons\n\n**Flags:**\n- `--search` - Directories to search for daemons\n- `--json` - Output in JSON format\n\n**Example:**\n```bash\nbd daemons health\nbd daemons health --json\n```\n\n### stop\n\nStop a specific daemon gracefully.\n\n```bash\nbd daemons stop <workspace-path|pid> [--json]\n```\n\n**Arguments:**\n- `<workspace-path|pid>` - Workspace path or PID of daemon to stop\n\n**Flags:**\n- `--json` - Output in JSON format\n\n**Example:**\n```bash\nbd daemons stop /Users/me/projects/myapp\nbd daemons stop 12345\nbd daemons stop /Users/me/projects/myapp --json\n```\n\n### restart\n\nRestart a specific daemon gracefully.\n\n```bash\nbd daemons restart <workspace-path|pid> [--search DIRS] [--json]\n```\n\nStops the daemon gracefully, then starts a new one in its place. Useful after upgrading bd or when a daemon needs to be refreshed.\n\n**Arguments:**\n- `<workspace-path|pid>` - Workspace path or PID of daemon to restart\n\n**Flags:**\n- `--search` - Directories to search for daemons\n- `--json` - Output in JSON format\n\n**Example:**\n```bash\nbd daemons restart /Users/me/projects/myapp\nbd daemons restart 12345\nbd daemons restart /Users/me/projects/myapp --json\n```\n\n### logs\n\nView logs for a specific daemon.\n\n```bash\nbd daemons logs <workspace-path|pid> [-f] [-n LINES] [--json]\n```\n\n**Arguments:**\n- `<workspace-path|pid>` - Workspace path or PID of daemon\n\n**Flags:**\n- `-f, --follow` - Follow log output (like tail -f)\n- `-n, --lines INT` - Number of lines to show from end (default: 50)\n- `--json` - Output in JSON format\n\n**Example:**\n```bash\nbd daemons logs /Users/me/projects/myapp\nbd daemons logs 12345 -n 100\nbd daemons logs /Users/me/projects/myapp -f\nbd daemons logs 12345 --json\n```\n\n### killall\n\nStop all running bd daemons.\n\n```bash\nbd daemons killall [--search DIRS] [--force] [--json]\n```\n\nUses escalating shutdown strategy:\n1. RPC shutdown (2 second timeout)\n2. SIGTERM (3 second timeout)\n3. SIGKILL (1 second timeout)\n\n**Flags:**\n- `--search` - Directories to search for daemons\n- `--force` - Use SIGKILL immediately if graceful shutdown fails\n- `--json` - Output in JSON format\n\n**Example:**\n```bash\nbd daemons killall\nbd daemons killall --force\nbd daemons killall --json\n```\n\n## Common Use Cases\n\n### Version Upgrade\n\nAfter upgrading bd, restart all daemons to use the new version:\n\n```bash\nbd daemons health  # Check for version mismatches\nbd daemons killall # Stop all old daemons\n# Daemons will auto-start with new version on next bd command\n\n# Or restart a specific daemon\nbd daemons restart /path/to/workspace\n```\n\n### Debugging\n\nCheck daemon status and view logs:\n\n```bash\nbd daemons list\nbd daemons health\nbd daemons logs /path/to/workspace -n 100\n```\n\n### Cleanup\n\nRemove stale daemon sockets:\n\n```bash\nbd daemons list  # Auto-cleanup happens by default\nbd daemons list --no-cleanup  # Skip cleanup\n```\n\n### Multi-Workspace Management\n\nDiscover daemons in specific directories:\n\n```bash\nbd daemons list --search /Users/me/projects\nbd daemons health --search /Users/me/work\n```\n\n## Troubleshooting\n\n### Stale Sockets\n\nIf you see stale sockets (dead process but socket file exists):\n\n```bash\nbd daemons list  # Auto-cleanup removes stale sockets\n```\n\n### Version Mismatch\n\nIf daemon version != CLI version:\n\n```bash\nbd daemons health  # Identify mismatched daemons\nbd daemons killall # Stop all daemons\n# Next bd command will auto-start new version\n```\n\n### Daemon Won't Stop\n\nIf graceful shutdown fails:\n\n```bash\nbd daemons killall --force  # Force kill with SIGKILL\n```\n\n### Can't Find Daemon\n\nIf daemon isn't discovered:\n\n```bash\nbd daemons list --search /path/to/workspace\n```\n\nOr check the socket manually:\n\n```bash\nls -la /path/to/workspace/.beads/bd.sock\n```\n\n## See Also\n\n- [bd daemon](daemon.md) - Start a daemon manually\n- [AGENTS.md](../AGENTS.md) - Agent workflow guide\n- [README.md](../README.md) - Main documentation\n",
        "commands/delete.md": "---\ndescription: Delete issues and clean up references\nargument-hint: [issue-ids...] [--force]\n---\n\nDelete one or more issues and clean up all references.\n\n## Safety Features\n\n- **Preview mode**: Default shows what would be deleted\n- **--force**: Required to actually delete\n- **--dry-run**: Preview collision detection\n- **Dependency checks**: Fails if issue has dependents (unless --cascade or --force)\n\n## Batch Deletion\n\n- Delete multiple: `bd delete bd-1 bd-2 bd-3 --force`\n- Delete from file: `bd delete --from-file deletions.txt --force`\n\n## Dependency Handling\n\n- **Default**: Fails if issue has dependents not in deletion set\n- **--cascade**: Recursively delete all dependent issues\n- **--force**: Delete and orphan dependents\n\n## What Gets Deleted\n\n1. All dependency links (any type, both directions)\n2. Text references updated to \"[deleted:ID]\" in connected issues\n3. Issue removed from database\n\nThis operation cannot be undone. Use with caution!\n",
        "commands/dep.md": "---\ndescription: Manage dependencies between issues\nargument-hint: [command] [from-id] [to-id]\n---\n\nManage dependencies between beads issues.\n\n## Available Commands\n\n- **add**: Add a dependency between issues\n  - $1: \"add\"\n  - $2: From issue ID\n  - $3: To issue ID\n  - $4: Dependency type (blocks, related, parent-child, discovered-from)\n\n- **remove**: Remove a dependency\n  - $1: \"remove\"\n  - $2: From issue ID\n  - $3: To issue ID\n\n- **tree**: Show dependency tree for an issue\n  - $1: \"tree\"\n  - $2: Issue ID\n  - Flags:\n    - `--reverse`: Show dependent tree (what was discovered from this) instead of dependency tree (what blocks this)\n    - `--format mermaid`: Output as Mermaid.js flowchart (renders in GitHub/GitLab markdown)\n    - `--json`: Output as JSON\n    - `--max-depth N`: Limit tree depth (default: 50)\n    - `--show-all-paths`: Show all paths (no deduplication for diamond dependencies)\n\n- **cycles**: Detect dependency cycles\n\n## Dependency Types\n\n- **blocks**: Hard blocker (from blocks to) - affects ready queue\n- **related**: Soft relationship - for context only\n- **parent-child**: Epic/subtask relationship\n- **discovered-from**: Track issues found during work\n\n## Mermaid Format\n\nThe `--format mermaid` option outputs the dependency tree as a Mermaid.js flowchart:\n\n**Example:**\n```bash\nbd dep tree bd-1 --format mermaid\n```\n\nOutput can be embedded in markdown:\n\n````markdown\n```mermaid\nflowchart TD\n  bd-1[\"â—§ bd-1: Main task\"]\n  bd-2[\"â˜‘ bd-2: Subtask\"]\n\n  bd-1 --> bd-2\n```\n````\n\n**Status Indicators:**\n\nEach node includes a symbol indicator for quick visual status identification:\n\n- â˜ **Open** - Not started yet (empty checkbox)\n- â—§ **In Progress** - Currently being worked on (half-filled box)\n- âš  **Blocked** - Waiting on something (warning sign)\n- â˜‘ **Closed** - Completed! (checked checkbox)\n\nThe diagram colors are determined by your Mermaid theme (default, dark, forest, neutral, or base). Mermaid diagrams render natively in GitHub, GitLab, VSCode markdown preview, and can be imported to Miro.\n\n## Examples\n\n- `bd dep add bd-10 bd-20 --type blocks`: bd-10 blocks bd-20\n- `bd dep tree bd-20`: Show what blocks bd-20 (dependency tree going UP)\n- `bd dep tree bd-1 --reverse`: Show what was discovered from bd-1 (dependent tree going DOWN)\n- `bd dep tree bd-1 --reverse --max-depth 3`: Show discovery tree with depth limit\n- `bd dep tree bd-20 --format mermaid > tree.md`: Generate Mermaid diagram for documentation\n- `bd dep cycles`: Check for circular dependencies\n\n## Reverse Mode: Discovery Trees\n\nThe `--reverse` flag inverts the tree direction to show **dependents** instead of **dependencies**:\n\n**Normal mode** (`bd dep tree ISSUE`):\n- Shows what blocks you (dependency tree)\n- Answers: \"What must I complete before I can work on this?\"\n- Tree flows **UP** toward prerequisites\n\n**Reverse mode** (`bd dep tree ISSUE --reverse`):\n- Shows what was discovered from you (dependent tree)\n- Answers: \"What work was discovered while working on this?\"\n- Tree flows **DOWN** from goal to discovered tasks\n- Perfect for visualizing work breakdown and discovery chains\n\n**Use Cases:**\n- Document project evolution and how work expanded from initial goal\n- Share \"how we got here\" context with stakeholders\n- Visualize work breakdown structure from epics\n- Track discovery chains (what led to what)\n- Show yak shaving journeys in retrospectives\n",
        "commands/epic.md": "---\ndescription: Epic management commands\nargument-hint: [command]\n---\n\nManage epics (large features composed of multiple issues).\n\n## Available Commands\n\n- **status**: Show epic completion status\n  - Shows progress for each epic\n  - Lists child issues and their states\n  - Calculates completion percentage\n\n- **close-eligible**: Close epics where all children are complete\n  - Automatically closes epics when all child issues are done\n  - Useful for bulk epic cleanup\n\n## Epic Workflow\n\n1. Create epic: `bd create \"Large Feature\" -t epic -p 1`\n2. Link subtasks: `bd dep add bd-10 bd-20 --type parent-child` (epic bd-10 is parent of task bd-20)\n3. Track progress: `bd epic status`\n4. Auto-close when done: `bd epic close-eligible`\n\nEpics use parent-child dependencies to track subtasks.\n",
        "commands/export.md": "---\ndescription: Export issues to JSONL format\nargument-hint: [-o output-file]\n---\n\nExport all issues to JSON Lines format (one JSON object per line).\n\n## Usage\n\n- **To stdout**: `bd export`\n- **To file**: `bd export -o issues.jsonl`\n- **Filter by status**: `bd export --status open`\n\nIssues are sorted by ID for consistent diffs, making git diffs readable.\n\n## Automatic Export\n\nThe daemon automatically exports to `.beads/issues.jsonl` after any CRUD operation (5-second debounce). Manual export is rarely needed unless you need a custom output location or filtered export.\n\nExport is used for:\n- Git version control\n- Backup\n- Sharing issues between repositories\n- Data migration\n",
        "commands/import.md": "---\ndescription: Import issues from JSONL format\nargument-hint: [-i input-file]\n---\n\nImport issues from JSON Lines format (one JSON object per line).\n\n## Usage\n\n- **From stdin**: `bd import` (reads from stdin)\n- **From file**: `bd import -i issues.jsonl`\n- **Preview**: `bd import -i issues.jsonl --dry-run`\n\n## Behavior\n\n- **Existing issues** (same ID): Updated with new data\n- **New issues**: Created\n- **Same-ID scenarios**: With hash-based IDs (v0.20.1+), same ID = same issue being updated (not a collision)\n\n## Preview Changes\n\nUse `--dry-run` to see what will change before importing:\n\n```bash\nbd import -i issues.jsonl --dry-run\n# Shows: new issues, updates, exact matches\n```\n\n## Automatic Import\n\nThe daemon automatically imports from `.beads/issues.jsonl` when it's newer than the database (e.g., after `git pull`). Manual import is rarely needed.\n\n## Options\n\n- **--skip-existing**: Skip updates to existing issues\n- **--strict**: Fail on dependency errors instead of warnings\n",
        "commands/init.md": "---\ndescription: Initialize beads in the current project\nargument-hint: [prefix]\n---\n\nInitialize beads issue tracking in the current directory.\n\nIf a prefix is provided as $1, use it as the issue prefix (e.g., \"myproject\" creates issues like myproject-1, myproject-2). If not provided, the default is the current directory name.\n\nUse the beads MCP `init` tool with the prefix parameter (if provided) to set up a new beads database.\n\nAfter initialization:\n1. Show the database location\n2. Show the issue prefix that will be used\n3. Explain the basic workflow (or suggest running `/beads:workflow`)\n4. Suggest creating the first issue with `/beads:create`\n\nIf beads is already initialized, inform the user and show project stats using the `stats` tool.\n",
        "commands/label.md": "---\ndescription: Manage issue labels\nargument-hint: [command] [issue-id] [label]\n---\n\nManage labels on beads issues. Labels provide flexible cross-cutting metadata beyond structured fields (status, priority, type).\n\n## Available Commands\n\n- **add**: Add a label to an issue\n  - $1: \"add\"\n  - $2: Issue ID\n  - $3: Label name\n\n- **remove**: Remove a label from an issue\n  - $1: \"remove\"\n  - $2: Issue ID\n  - $3: Label name\n\n- **list**: List labels on a specific issue\n  - $1: \"list\"\n  - $2: Issue ID\n\n- **list-all**: Show all labels used across all issues\n\n## Common Label Use Cases\n\n- Technical scope: `backend`, `frontend`, `api`, `database`\n- Quality gates: `needs-review`, `needs-tests`, `security-review`\n- Effort sizing: `quick-win`, `complex`, `spike`\n- Context: `technical-debt`, `documentation`, `performance`\n\nUse `bd label add <issue-id> <label>` to tag issues with contextual metadata.\n",
        "commands/list.md": "---\ndescription: List issues with optional filters\nargument-hint: [--status] [--priority] [--type] [--assignee] [--label]\n---\n\nList beads issues with optional filtering.\n\n## Basic Filters\n\n- **--status, -s**: Filter by status (open, in_progress, blocked, closed)\n- **--priority, -p**: Filter by priority (0-4: 0=critical, 1=high, 2=medium, 3=low, 4=backlog)\n- **--type, -t**: Filter by type (bug, feature, task, epic, chore)\n- **--assignee, -a**: Filter by assignee\n- **--label, -l**: Filter by labels (comma-separated, must have ALL labels)\n- **--label-any**: Filter by labels (OR semantics, must have AT LEAST ONE)\n- **--title**: Filter by title text (case-insensitive substring match)\n- **--limit, -n**: Limit number of results\n\n## Advanced Filters\n\n### Pattern Matching\n- **--title-contains**: Search for text in title (case-insensitive)\n- **--desc-contains**: Search for text in description (case-insensitive)\n- **--notes-contains**: Search for text in notes (case-insensitive)\n\n### Date Ranges\n- **--created-after**: Issues created after date (YYYY-MM-DD or ISO 8601)\n- **--created-before**: Issues created before date\n- **--updated-after**: Issues updated after date\n- **--updated-before**: Issues updated before date\n- **--closed-after**: Issues closed after date\n- **--closed-before**: Issues closed before date\n\n### Priority Range\n- **--priority-min**: Minimum priority (inclusive)\n- **--priority-max**: Maximum priority (inclusive)\n\n### Empty/Null Checks\n- **--empty-description**: Find issues with no description\n- **--no-assignee**: Find unassigned issues\n- **--no-labels**: Find issues with no labels\n\n## Examples\n\n### Basic Usage\n- `bd list --status open --priority 1`: High priority open issues\n- `bd list --type bug --assignee alice`: Alice's assigned bugs\n- `bd list --label backend,needs-review`: Backend issues needing review\n- `bd list --title \"auth\"`: Issues with \"auth\" in the title\n\n### Advanced Usage\n- `bd list --title-contains \"auth\" --status open`: Search open issues for auth-related work\n- `bd list --priority-min 0 --priority-max 1`: Critical and high priority issues only\n- `bd list --created-after 2025-01-01 --status open`: Recent open issues\n- `bd list --empty-description --status open`: Open issues missing descriptions\n- `bd list --no-assignee --priority 1`: High priority unassigned work\n- `bd list --desc-contains \"TODO\" --notes-contains \"review\"`: Find items needing attention\n\n## Output Formats\n\n- Default: Human-readable table\n- `--json`: JSON format for scripting\n- `--format digraph`: Graph format for golang.org/x/tools/cmd/digraph\n- `--format dot`: Graphviz DOT format\n",
        "commands/prime.md": "Load AI-optimized workflow context for beads issue tracking.\n\nOutputs essential beads workflow rules and command reference to help agents remember to use bd instead of markdown TODOs after context compaction.\n\n```bash\nbd prime\n```\n",
        "commands/quickstart.md": "---\ndescription: Quick start guide for bd workflows (deprecated)\nargument-hint: []\n---\n\n**Note:** The `bd quickstart` command is deprecated. See [docs/QUICKSTART.md](../docs/QUICKSTART.md) instead.\n\nThe quickstart documentation covers:\n- Getting started with bd\n- Common workflow patterns\n- Basic commands\n- Dependency management\n- Git integration\n",
        "commands/ready.md": "---\ndescription: Find ready-to-work tasks with no blockers\n---\n\nUse the beads MCP server to find tasks that are ready to work on (no blocking dependencies).\n\nCall the `ready` tool to get a list of unblocked issues. Then present them to the user in a clear format showing:\n- Issue ID\n- Title\n- Priority\n- Issue type\n\nIf there are ready tasks, ask the user which one they'd like to work on. If they choose one, use the `update` tool to set its status to `in_progress`.\n\nIf there are no ready tasks, suggest checking `blocked` issues or creating a new issue with the `create` tool.\n",
        "commands/rename-prefix.md": "---\ndescription: Rename the issue prefix for all issues\nargument-hint: <new-prefix> [--dry-run]\n---\n\nRename the issue prefix for all issues in the database.\n\nUpdates all issue IDs and all text references across all fields.\n\n## Prefix Rules\n\n- Max length: 8 characters\n- Allowed: lowercase letters, numbers, hyphens\n- Must start with a letter\n- Must end with a hyphen (e.g., 'kw-', 'work-')\n\n## Usage\n\n- **Preview**: `bd rename-prefix kw- --dry-run`\n- **Apply**: `bd rename-prefix kw-`\n\nExample: Rename from 'knowledge-work-' to 'kw-'\n\nAll dependencies and text references are automatically updated.\n",
        "commands/reopen.md": "---\ndescription: Reopen closed issues\nargument-hint: [issue-ids...] [--reason]\n---\n\nReopen one or more closed issues.\n\nSets status to 'open' and clears the closed_at timestamp. Emits a Reopened event.\n\n## Usage\n\n- **Reopen single**: `bd reopen bd-42`\n- **Reopen multiple**: `bd reopen bd-42 bd-43 bd-44`\n- **With reason**: `bd reopen bd-42 --reason \"Found regression\"`\n\nMore explicit than `bd update --status open` - specifically designed for reopening workflow.\n\nCommon reasons for reopening:\n- Regression found\n- Requirements changed\n- Incomplete implementation\n- New information discovered\n",
        "commands/restore.md": "---\ndescription: Restore full history of compacted issue from git\nargument-hint: <issue-id>\n---\n\nRestore full history of a compacted issue from git version control.\n\nWhen an issue is compacted, the git commit hash is saved. This command:\n\n1. Reads the compacted_at_commit from the database\n2. Checks out that commit temporarily\n3. Reads the full issue from JSONL at that point in history\n4. Displays the full issue history (description, events, etc.)\n5. Returns to the current git state\n\n## Usage\n\n`bd restore bd-42`\n\nThis is **read-only** - it does not modify the database or git state.\n\nUseful for:\n- Reviewing old issues after compaction\n- Recovering forgotten context\n- Audit trails\n- Historical research\n\nRequires git repository with issue history.\n",
        "commands/search.md": "---\ndescription: Search issues by text query\nargument-hint: <query> [--status] [--label] [--assignee]\n---\n\nSearch issues across title, description, and ID with a simple text query.\n\n**Note:** The `search` command is optimized for quick text searches and uses less context than `list` when accessed via MCP. For advanced filtering options, use `bd list`.\n\n## Basic Usage\n\n```bash\nbd search \"authentication bug\"\nbd search login --status open\nbd search database --label backend\nbd search \"bd-5q\"  # Search by partial issue ID\n```\n\n## How It Works\n\nThe search command finds issues where your query appears in **any** of:\n- Issue title\n- Issue description\n- Issue ID (supports partial matching)\n\nUnlike `bd list`, which requires you to specify which field to search, `bd search` automatically searches all text fields, making it faster and more intuitive for exploratory searches.\n\n## Filters\n\n- **--status, -s**: Filter by status (open, in_progress, blocked, closed)\n- **--assignee, -a**: Filter by assignee\n- **--type, -t**: Filter by type (bug, feature, task, epic, chore)\n- **--label, -l**: Filter by labels (must have ALL specified labels)\n- **--label-any**: Filter by labels (must have AT LEAST ONE)\n- **--limit, -n**: Limit number of results (default: 50)\n- **--sort**: Sort by field: priority, created, updated, closed, status, id, title, type, assignee\n- **--reverse, -r**: Reverse sort order\n- **--long**: Show detailed multi-line output for each issue\n- **--json**: Output results in JSON format\n\n## Examples\n\n### Basic Search\n```bash\n# Find all issues mentioning \"auth\" or \"authentication\"\nbd search auth\n\n# Search for performance issues\nbd search performance --status open\n\n# Find database-related bugs\nbd search database --type bug\n```\n\n### Filtered Search\n```bash\n# Find open backend issues about login\nbd search login --status open --label backend\n\n# Search Alice's tasks for \"refactor\"\nbd search refactor --assignee alice --type task\n\n# Find recent bugs (limited to 10 results)\nbd search bug --status open --limit 10\n```\n\n### Sorted Output\n```bash\n# Search bugs sorted by priority (P0 first)\nbd search bug --sort priority\n\n# Search features sorted by most recently updated\nbd search feature --sort updated\n\n# Search issues sorted by priority, lowest first\nbd search refactor --sort priority --reverse\n```\n\n### JSON Output\n```bash\n# Get JSON results for programmatic use\nbd search \"api error\" --json\n\n# Use with jq for advanced filtering\nbd search memory --json | jq '.[] | select(.priority <= 1)'\n```\n\n## Comparison with bd list\n\n| Command | Best For | Default Limit | Context Usage |\n|---------|----------|---------------|---------------|\n| `bd search` | Quick text searches, exploratory queries | 50 | Low (efficient for LLMs) |\n| `bd list` | Advanced filtering, precise queries | None | High (all results) |\n\n**When to use `bd search`:**\n- You want to find issues quickly by keyword\n- You're exploring the issue database\n- You're using an LLM/MCP and want to minimize context usage\n\n**When to use `bd list`:**\n- You need advanced filters (date ranges, priority ranges, etc.)\n- You want all results without a limit\n- You need special output formats (digraph, dot)\n",
        "commands/show.md": "---\ndescription: Show detailed information about an issue\nargument-hint: [issue-id]\n---\n\nDisplay detailed information about a beads issue.\n\nIf an issue ID is provided as $1, use it. Otherwise, ask the user for the issue ID.\n\nUse the beads MCP `show` tool to retrieve issue details and present them clearly, including:\n- Issue ID, title, and description\n- Status, priority, and type\n- Creation and update timestamps\n- Dependencies (what this issue blocks or is blocked by)\n- Related issues\n\nIf the issue has dependencies, offer to show the full dependency tree.\n",
        "commands/stats.md": "---\ndescription: Show project statistics and progress\n---\n\nDisplay statistics about the current beads project.\n\nUse the beads MCP `stats` tool to retrieve project metrics and present them clearly:\n- Total issues by status (open, in_progress, blocked, closed)\n- Issues by priority level\n- Issues by type (bug, feature, task, epic, chore)\n- Completion rate\n- Recently updated issues\n\nOptionally suggest actions based on the stats:\n- High number of blocked issues? Run `/beads:blocked` to investigate\n- No in_progress work? Run `/beads:ready` to find tasks\n- Many open issues? Consider prioritizing with `/beads:update`\n",
        "commands/sync.md": "---\ndescription: Synchronize issues with git remote\nargument-hint: [--dry-run] [--message] [--status] [--merge]\n---\n\nSynchronize issues with git remote in a single operation.\n\n## Sync Steps\n\n1. Export pending changes to JSONL\n2. Commit changes to git\n3. Pull from remote (with conflict resolution)\n4. Import updated JSONL\n5. Push local commits to remote\n\nWraps the entire git-based sync workflow for multi-device use.\n\n## Usage\n\n- **Basic sync**: `bd sync`\n- **Preview**: `bd sync --dry-run`\n- **Custom message**: `bd sync --message \"Closed sprint issues\"`\n- **Pull only**: `bd sync --no-push`\n- **Push only**: `bd sync --no-pull`\n- **Flush only**: `bd sync --flush-only` (export to JSONL without git operations)\n- **Import only**: `bd sync --import-only` (import from JSONL without git operations)\n\n## Separate Branch Workflow\n\nWhen using a separate sync branch (configured via `sync.branch`), additional commands are available:\n\n- **Check status**: `bd sync --status` - Show diff between sync branch and main\n- **Merge to main**: `bd sync --merge` - Merge sync branch back to main branch\n- **Preview merge**: `bd sync --merge --dry-run` - Preview what would be merged\n\n### Merge Workflow\n\nWhen working with a protected main branch and separate sync branch:\n\n1. Beads commits go to the sync branch (e.g., `beads-metadata`)\n2. Use `bd sync --status` to review pending changes\n3. When ready, use `bd sync --merge` to merge back to main\n4. After merge, run `bd import` to update the database\n5. Run `bd sync` to push changes to remote\n\nThe merge command includes safety checks:\n- Verifies you're not on the sync branch\n- Checks for uncommitted changes in working tree\n- Detects and reports merge conflicts with resolution steps\n- Uses `--no-ff` to create a merge commit for clear history\n\n## Note\n\nMost users should rely on the daemon's automatic sync (`bd daemon --auto-commit --auto-push`) instead of running manual sync. This command is useful for one-off syncs or when not using the daemon.\n",
        "commands/template.md": "# bd template\n\nManage issue templates for streamlined issue creation.\n\n## Synopsis\n\nTemplates provide pre-filled structures for common issue types, making it faster to create well-formed issues with consistent formatting.\n\n```bash\nbd template list\nbd template show <template-name>\nbd template create <template-name>\n```\n\n## Description\n\nTemplates can be:\n- **Built-in**: Provided by bd (epic, bug, feature)\n- **Custom**: Stored in `.beads/templates/` directory\n\nEach template defines default values for:\n- Description structure with placeholders\n- Issue type (bug, feature, task, epic, chore)\n- Priority (0-4)\n- Labels\n- Design notes structure\n- Acceptance criteria structure\n\n## Commands\n\n### list\n\nList all available templates (built-in and custom).\n\n```bash\nbd template list\nbd template list --json\n```\n\n**Examples:**\n\n```bash\n$ bd template list\nBuilt-in Templates:\n  epic\n    Type: epic, Priority: P1\n    Labels: epic\n  bug\n    Type: bug, Priority: P1\n    Labels: bug\n  feature\n    Type: feature, Priority: P2\n    Labels: feature\n```\n\n### show\n\nShow detailed structure of a specific template.\n\n```bash\nbd template show <template-name>\nbd template show <template-name> --json\n```\n\n**Examples:**\n\n```bash\n$ bd template show bug\nTemplate: bug\nType: bug\nPriority: P1\nLabels: bug\n\nDescription:\n## Summary\n\n[Brief description of the bug]\n\n## Steps to Reproduce\n...\n```\n\n### create\n\nCreate a custom template in `.beads/templates/` directory.\n\n```bash\nbd template create <template-name>\n```\n\nThis creates a YAML file with default structure that you can edit to customize.\n\n**Examples:**\n\n```bash\n$ bd template create performance\nâœ“ Created template: .beads/templates/performance.yaml\nEdit the file to customize your template.\n\n$ cat .beads/templates/performance.yaml\nname: performance\ndescription: |-\n    [Describe the issue]\n    \n    ## Additional Context\n    \n    [Add relevant details]\ntype: task\npriority: 2\nlabels: []\ndesign: '[Design notes]'\nacceptance_criteria: |-\n    - [ ] Acceptance criterion 1\n    - [ ] Acceptance criterion 2\n\n# Edit the template to customize it\n$ vim .beads/templates/performance.yaml\n```\n\n## Using Templates with `bd create`\n\nUse the `--from-template` flag to create issues from templates:\n\n```bash\nbd create --from-template <template-name> \"Issue title\"\n```\n\nTemplate values can be overridden with explicit flags:\n\n```bash\n# Use bug template but override priority\nbd create --from-template bug \"Login crashes on special chars\" -p 0\n\n# Use epic template but add extra labels\nbd create --from-template epic \"Q4 Infrastructure\" -l infrastructure,ops\n```\n\n**Examples:**\n\n```bash\n# Create epic from template\n$ bd create --from-template epic \"Phase 3 Features\"\nâœ“ Created issue: bd-a3f8e9\n  Title: Phase 3 Features\n  Priority: P1\n  Status: open\n\n# Create bug report from template\n$ bd create --from-template bug \"Auth token validation fails\"\nâœ“ Created issue: bd-42bc7a\n  Title: Auth token validation fails\n  Priority: P1\n  Status: open\n\n# Use custom template\n$ bd template create security-audit\n$ bd create --from-template security-audit \"Review authentication flow\"\n```\n\n## Template File Format\n\nTemplates are YAML files with the following structure:\n\n```yaml\nname: template-name\ndescription: |\n  Multi-line description with placeholders\n  \n  ## Section heading\n  \n  [Placeholder text]\n\ntype: bug|feature|task|epic|chore\npriority: 0-4\nlabels:\n  - label1\n  - label2\n\ndesign: |\n  Design notes structure\n\nacceptance_criteria: |\n  - [ ] Acceptance criterion 1\n  - [ ] Acceptance criterion 2\n```\n\n## Built-in Templates\n\n### epic\n\nFor large features composed of multiple issues.\n\n**Structure:**\n- Overview and scope\n- Success criteria checklist\n- Background and motivation\n- In-scope / out-of-scope sections\n- Architecture design notes\n- Component breakdown\n\n**Defaults:**\n- Type: epic\n- Priority: P1\n- Labels: epic\n\n### bug\n\nFor bug reports with consistent structure.\n\n**Structure:**\n- Summary\n- Steps to reproduce\n- Expected vs actual behavior\n- Environment details\n- Root cause analysis (design)\n- Proposed fix\n- Impact assessment\n\n**Defaults:**\n- Type: bug\n- Priority: P1\n- Labels: bug\n\n### feature\n\nFor feature requests and enhancements.\n\n**Structure:**\n- Feature description\n- Motivation and use cases\n- Proposed solution\n- Alternatives considered\n- Technical design\n- API changes\n- Testing strategy\n\n**Defaults:**\n- Type: feature\n- Priority: P2\n- Labels: feature\n\n## Custom Templates\n\nCustom templates override built-in templates with the same name. This allows you to customize built-in templates for your project.\n\n**Priority:**\n1. Custom templates in `.beads/templates/`\n2. Built-in templates\n\n**Example - Override bug template:**\n\n```bash\n# Create custom bug template\n$ bd template create bug\n\n# Edit to add project-specific fields\n$ cat > .beads/templates/bug.yaml << 'EOF'\nname: bug\ndescription: |\n  ## Bug Report\n  \n  **Severity:** [critical|high|medium|low]\n  **Component:** [auth|api|frontend|backend]\n  \n  ## Description\n  [Describe the bug]\n  \n  ## Reproduction\n  1. Step 1\n  2. Step 2\n  \n  ## Impact\n  [Who is affected? How many users?]\n\ntype: bug\npriority: 0\nlabels:\n  - bug\n  - needs-triage\n\ndesign: |\n  ## Investigation Notes\n  [Technical details]\n\nacceptance_criteria: |\n  - [ ] Bug fixed and verified\n  - [ ] Tests added\n  - [ ] Monitoring added\nEOF\n\n# Now 'bd create --from-template bug' uses your custom template\n```\n\n## JSON Output\n\nAll template commands support `--json` flag for programmatic use:\n\n```bash\n$ bd template list --json\n[\n  {\n    \"name\": \"epic\",\n    \"description\": \"## Overview...\",\n    \"type\": \"epic\",\n    \"priority\": 1,\n    \"labels\": [\"epic\"],\n    \"design\": \"## Architecture...\",\n    \"acceptance_criteria\": \"- [ ] All child issues...\"\n  }\n]\n\n$ bd template show bug --json\n{\n  \"name\": \"bug\",\n  \"description\": \"## Summary...\",\n  \"type\": \"bug\",\n  \"priority\": 1,\n  \"labels\": [\"bug\"],\n  \"design\": \"## Root Cause...\",\n  \"acceptance_criteria\": \"- [ ] Bug no longer...\"\n}\n```\n\n## Best Practices\n\n1. **Use templates for consistency**: Establish team conventions for common issue types\n2. **Customize built-ins**: Override built-in templates to match your workflow\n3. **Version control templates**: Commit `.beads/templates/` to share across team\n4. **Keep templates focused**: Create specific templates (e.g., `performance`, `security-audit`) rather than generic ones\n5. **Use placeholders**: Mark sections requiring input with `[brackets]` or `TODO`\n6. **Include checklists**: Use `- [ ]` for actionable items in description and acceptance criteria\n\n## See Also\n\n- [bd create](create.md) - Create issues\n- [bd list](list.md) - List issues\n- [README](../README.md) - Main documentation\n",
        "commands/update.md": "---\ndescription: Update an issue's status, priority, or other fields\nargument-hint: [issue-id] [status]\n---\n\nUpdate a beads issue.\n\nIf arguments are provided:\n- $1: Issue ID\n- $2: New status (open, in_progress, blocked, closed)\n\nIf arguments are missing, ask the user for:\n1. Issue ID\n2. What to update (status, priority, assignee, title, description)\n3. New value\n\nUse the beads MCP `update` tool to apply the changes. Show the updated issue to confirm the change.\n\n**Note:** Comments are managed separately with `bd comments add`. The `update` command is for singular, versioned properties (title, status, priority, etc.), while comments form a discussion thread that's appended to, not updated.\n\nCommon workflows:\n- Start work: Update status to `in_progress`\n- Mark blocked: Update status to `blocked`\n- Reprioritize: Update priority (0-4)\n",
        "commands/version.md": "---\ndescription: Check beads and plugin versions\n---\n\nCheck the installed versions of beads components and verify compatibility.\n\n**Note:** The MCP server automatically checks bd CLI version >= 0.9.0 on startup. This command provides detailed version info and update instructions.\n\nUse the beads MCP tools to:\n1. Run `bd version` via bash to get the CLI version\n2. Check the plugin version (0.9.2)\n3. Compare versions and report any mismatches\n\nDisplay:\n- bd CLI version (from `bd version`)\n- Plugin version (0.9.2)\n- MCP server version (0.9.2)\n- MCP server status (from `stats` tool or connection test)\n- Compatibility status (âœ“ compatible or âš ï¸ update needed)\n\nIf versions are mismatched, provide instructions:\n- Update bd CLI: `curl -fsSL https://raw.githubusercontent.com/steveyegge/beads/main/scripts/install.sh | bash`\n- Update plugin: `/plugin update beads`\n- Restart Claude Code after updating\n\nSuggest checking for updates if the user is on an older version.\n",
        "commands/workflow.md": "---\ndescription: Show the AI-supervised issue workflow guide\n---\n\nDisplay the beads workflow for AI agents and developers.\n\n# Beads Workflow\n\nBeads is an issue tracker designed for AI-supervised coding workflows. Here's how to use it effectively:\n\n## 1. Find Ready Work\nUse `/beads:ready` or the `ready` MCP tool to see tasks with no blockers.\n\n## 2. Claim Your Task\nUpdate the issue status to `in_progress`:\n- Via command: `/beads:update <id> in_progress`\n- Via MCP tool: `update` with `status: \"in_progress\"`\n\n## 3. Work on It\nImplement, test, and document the feature or fix.\n\n## 4. Discover New Work\nAs you work, you'll often find bugs, TODOs, or related work:\n- Create issues: `/beads:create` or `create` MCP tool\n- Link them: Use `dep` MCP tool with `type: \"discovered-from\"`\n- This maintains context and work history\n\n## 5. Complete the Task\nClose the issue when done:\n- Via command: `/beads:close <id> \"Completed: <summary>\"`\n- Via MCP tool: `close` with reason\n\n## 6. Check What's Unblocked\nAfter closing, check if other work became ready:\n- Use `/beads:ready` to see newly unblocked tasks\n- Start the cycle again\n\n## Tips\n- **Priority levels**: 0=critical, 1=high, 2=medium, 3=low, 4=backlog\n- **Issue types**: bug, feature, task, epic, chore\n- **Dependencies**: Use `blocks` for hard dependencies, `related` for soft links\n- **Auto-sync**: Changes automatically export to `.beads/issues.jsonl` (5-second debounce)\n- **Git workflow**: After `git pull`, JSONL auto-imports if newer than DB\n\n## Available Commands\n- `/beads:ready` - Find unblocked work\n- `/beads:create` - Create new issue\n- `/beads:show` - Show issue details\n- `/beads:update` - Update issue\n- `/beads:close` - Close issue\n- `/beads:workflow` - Show this guide (you are here!)\n\n## MCP Tools Available\nUse these via the beads MCP server:\n- `ready`, `list`, `show`, `create`, `update`, `close`\n- `dep` (manage dependencies), `blocked`, `stats`\n- `init` (initialize bd in a project)\n\nFor more details, see the beads README at: https://github.com/steveyegge/beads\n",
        "examples/README.md": "# Beads Examples\n\nThis directory contains examples of how to integrate bd with AI agents and workflows.\n\n## Examples\n\n### Agent Integration\n- **[python-agent/](python-agent/)** - Simple Python agent that discovers ready work and completes tasks\n- **[bash-agent/](bash-agent/)** - Bash script showing the full agent workflow\n- **[startup-hooks/](startup-hooks/)** - Session startup scripts for automatic bd upgrade detection\n- **[claude-desktop-mcp/](claude-desktop-mcp/)** - MCP server for Claude Desktop integration\n\n### Tools & Utilities\n- **[monitor-webui/](monitor-webui/)** - Standalone web interface for real-time issue monitoring and visualization\n- **[markdown-to-jsonl/](markdown-to-jsonl/)** - Convert markdown planning docs to bd issues\n- **[github-import/](github-import/)** - Import issues from GitHub repositories\n- **[git-hooks/](git-hooks/)** - Pre-configured git hooks for automatic export/import\n<!-- REMOVED (bd-4c74): branch-merge example - collision resolution no longer needed with hash IDs -->\n\n### Workflow Patterns\n- **[contributor-workflow/](contributor-workflow/)** - OSS contributor setup with separate planning repo\n- **[team-workflow/](team-workflow/)** - Team collaboration with shared repositories\n- **[multi-phase-development/](multi-phase-development/)** - Organize large projects by phases (planning, MVP, iteration, polish)\n- **[multiple-personas/](multiple-personas/)** - Architect/implementer/reviewer role separation\n- **[protected-branch/](protected-branch/)** - Protected branch workflow for team collaboration\n\n## Quick Start\n\n```bash\n# Try the Python agent example\ncd python-agent\npython agent.py\n\n# Try the bash agent example\ncd bash-agent\n./agent.sh\n\n# Install git hooks\ncd git-hooks\n./install.sh\n\n# REMOVED (bd-4c74): branch-merge demo - hash IDs eliminate collision resolution\n```\n\n## Creating Your Own Agent\n\nThe basic agent workflow:\n\n1. **Find ready work**: `bd ready --json --limit 1`\n2. **Claim the task**: `bd update <id> --status in_progress --json`\n3. **Do the work**: Execute the task\n4. **Discover new issues**: `bd create \"Found bug\" --json`\n5. **Link discoveries**: `bd dep add <new-id> <parent-id> --type discovered-from`\n6. **Complete the task**: `bd close <id> --reason \"Done\" --json`\n\nAll commands support `--json` for easy parsing.\n",
        "examples/bash-agent/README.md": "# Bash Agent Example\n\nA bash script demonstrating how an AI agent can use bd to manage tasks autonomously.\n\n## Features\n\n- Pure bash implementation (no Python/Node required)\n- Colorized terminal output\n- Automatic work discovery\n- Random issue creation to simulate real agent behavior\n- Dependency linking with `discovered-from`\n- Statistics display\n\n## Prerequisites\n\n- bash 4.0+\n- bd installed: `go install github.com/steveyegge/beads/cmd/bd@latest`\n- jq for JSON parsing: `brew install jq` (macOS) or `apt install jq` (Linux)\n- A beads database initialized: `bd init`\n\n## Usage\n\n```bash\n# Make executable\nchmod +x agent.sh\n\n# Run with default 10 iterations\n./agent.sh\n\n# Run with custom iteration limit\n./agent.sh 20\n```\n\n## What It Does\n\nThe agent runs in a loop:\n\n1. Looks for ready work (no blockers)\n2. Claims the task (sets status to `in_progress`)\n3. \"Works\" on it (simulates 1 second of work)\n4. 50% chance to discover a follow-up issue\n5. If discovered, creates and links the new issue\n6. Completes the original task\n7. Shows statistics and repeats\n\n## Example Output\n\n```\nğŸš€ Beads Agent starting...\n   Max iterations: 10\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  Beads Statistics\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nOpen: 5  In Progress: 0  Closed: 2\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n  Iteration 1/10\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nâ„¹ Looking for ready work...\nâ„¹ Claiming task: bd-3\nâœ“ Task claimed\nâ„¹ Working on: Fix authentication bug (bd-3)\n  Priority: 1\nâš  Discovered issue while working!\nâœ“ Created issue: bd-8\nâœ“ Linked bd-8 â† discovered-from â† bd-3\nâ„¹ Completing task: bd-3\nâœ“ Task completed: bd-3\n```\n\n## Use Cases\n\n**Continuous Integration**\n```bash\n# Run agent in CI to process testing tasks\n./agent.sh 5\n```\n\n**Cron Jobs**\n```bash\n# Run agent every hour\n0 * * * * cd /path/to/project && /path/to/agent.sh 3\n```\n\n**One-off Task Processing**\n```bash\n# Process exactly one task and exit\n./agent.sh 1\n```\n\n## Customization\n\nEdit the script to customize behavior:\n\n```bash\n# Change discovery probability (line ~80)\nif [[ $((RANDOM % 2)) -eq 0 ]]; then  # 50% chance\n# Change to:\nif [[ $((RANDOM % 10)) -lt 3 ]]; then  # 30% chance\n\n# Add assignee filtering\nbd ready --json --assignee \"bot\" --limit 1\n\n# Add priority filtering\nbd ready --json --priority 1 --limit 1\n\n# Add custom labels\nbd create \"New task\" -l \"automated,agent-discovered\"\n```\n\n## Integration with Real Agents\n\nThis script is a starting point. To integrate with a real LLM:\n\n1. Replace `do_work()` with calls to your LLM API\n2. Parse the LLM's response for tasks to create\n3. Use issue IDs to maintain context\n4. Track conversation state in issue metadata\n\n## See Also\n\n- [../python-agent/](../python-agent/) - Python version with more flexibility\n- [../git-hooks/](../git-hooks/) - Automatic export/import on git operations\n",
        "examples/bd-example-extension-go/README.md": "# BD Extension Example (Go)\n\nThis example demonstrates how to extend bd with custom tables for application-specific orchestration, following the patterns described in [EXTENDING.md](../../docs/EXTENDING.md).\n\n## What This Example Shows\n\n1. **Schema Extension**: Adding custom tables (`example_executions`, `example_checkpoints`) to bd's SQLite database\n2. **Foreign Key Integration**: Linking extension tables to bd's `issues` table with proper cascading\n3. **Dual-Layer Access**: Using bd's Go API for issue management while directly querying extension tables\n4. **Complex Queries**: Joining bd's issues with extension tables for powerful insights\n5. **Execution Tracking**: Implementing agent assignment, checkpointing, and crash recovery patterns\n\n## Key Patterns Illustrated\n\n### Pattern 1: Namespace Your Tables\n\nAll tables are prefixed with `example_` to avoid conflicts:\n\n```sql\nCREATE TABLE example_executions (...)\nCREATE TABLE example_checkpoints (...)\n```\n\n### Pattern 2: Foreign Key Relationships\n\nExtension tables link to bd's issues with cascading deletes:\n\n```sql\nFOREIGN KEY (issue_id) REFERENCES issues(id) ON DELETE CASCADE\n```\n\n### Pattern 3: Index Common Queries\n\nIndexes are created for frequent query patterns:\n\n```sql\nCREATE INDEX idx_executions_status ON example_executions(status);\nCREATE INDEX idx_executions_issue ON example_executions(issue_id);\n```\n\n### Pattern 4: Layer Separation\n\n- **bd layer**: Issue tracking, dependencies, ready work\n- **Extension layer**: Execution state, agent assignments, checkpoints\n\n### Pattern 5: Join Queries\n\nPowerful queries join both layers:\n\n```sql\nSELECT i.id, i.title, i.priority, e.status, e.agent_id, COUNT(c.id)\nFROM issues i\nLEFT JOIN example_executions e ON i.id = e.issue_id\nLEFT JOIN example_checkpoints c ON e.id = c.execution_id\nGROUP BY i.id, e.id\n```\n\n## Building and Running\n\n### Prerequisites\n\n- Go 1.24 or later\n- bd initialized in a directory (run `bd init --prefix demo`)\n\n### Install\n\n```bash\n# Install from the repository\ngo install github.com/steveyegge/beads/examples/bd-example-extension-go@latest\n\n# Or install from local source\ncd examples/bd-example-extension-go\ngo install .\n```\n\nThe binary will be installed as `bd-example-extension-go` in your `$GOPATH/bin` (or `$GOBIN` if set).\n\n### Running\n\n```bash\n# Auto-discover database and run\nbd-example-extension-go\n\n# Or specify database path\nbd-example-extension-go -db .beads/demo.db\n```\n\n**Output:**\n```\nClaiming: demo-5\n  âœ“ assess\n  âœ“ implement\n  âœ“ test\n\nStatus:\n  demo-4: Fix memory leak [closed] agent=agent-demo checkpoints=3\n  demo-1: Implement auth [in_progress] agent=agent-alice checkpoints=0\n  demo-5: Test minimized [closed] agent=demo-agent checkpoints=3\n```\n\n## Code Structure\n\n**Just 116 lines total** - minimal, focused extension example.\n\n- **main.go** (93 lines): Complete workflow with embedded schema\n- **schema.sql** (23 lines): Extension tables (`example_executions`, `example_checkpoints`) with foreign keys and indexes\n\nDemonstrates:\n1. Auto-discover database (`beads.FindDatabasePath`)\n2. Dual-layer access (bd API + direct SQL)\n3. Execution tracking with checkpoints\n4. Complex joined queries across layers\n\n## Example Queries\n\n### Find Running Executions with Checkpoint Count\n\n```go\nquery := `\n    SELECT i.id, i.title, e.status, e.agent_id, COUNT(c.id) as checkpoints\n    FROM issues i\n    INNER JOIN example_executions e ON i.id = e.issue_id\n    LEFT JOIN example_checkpoints c ON e.id = c.execution_id\n    WHERE e.status = 'running'\n    GROUP BY i.id, e.id\n`\n```\n\n### Find Failed Executions\n\n```go\nquery := `\n    SELECT i.id, i.title, e.error, e.completed_at\n    FROM issues i\n    INNER JOIN example_executions e ON i.id = e.issue_id\n    WHERE e.status = 'failed'\n    ORDER BY e.completed_at DESC\n`\n```\n\n### Get Latest Checkpoint for Recovery\n\n```go\nquery := `\n    SELECT checkpoint_data\n    FROM example_checkpoints\n    WHERE execution_id = ?\n    ORDER BY created_at DESC\n    LIMIT 1\n`\n```\n\n## Integration with bd\n\n### Using bd's Go API\n\n```go\n// Auto-discover database path\ndbPath := beads.FindDatabasePath()\nif dbPath == \"\" {\n    log.Fatal(\"No bd database found\")\n}\n\n// Open bd storage\nstore, err := beads.NewSQLiteStorage(dbPath)\n\n// Find ready work\nreadyIssues, err := store.GetReadyWork(ctx, beads.WorkFilter{Limit: 10})\n\n// Update issue status\nupdates := map[string]interface{}{\"status\": beads.StatusInProgress}\nerr = store.UpdateIssue(ctx, issueID, updates, \"agent-name\")\n\n// Close issue\nerr = store.CloseIssue(ctx, issueID, \"Completed\", \"agent-name\")\n\n// Find corresponding JSONL path (for git hooks, monitoring, etc.)\njsonlPath := beads.FindJSONLPath(dbPath)\n```\n\n### Direct Database Access\n\n```go\n// Open same database for extension tables\ndb, err := sql.Open(\"sqlite3\", dbPath)\n\n// Initialize extension schema\n_, err = db.Exec(Schema)\n\n// Query extension tables\nrows, err := db.Query(\"SELECT * FROM example_executions WHERE status = ?\", \"running\")\n```\n\n## Testing the Example\n\n1. **Initialize bd:**\n   ```bash\n   bd init --prefix demo\n   ```\n\n2. **Create some test issues:**\n   ```bash\n   bd create \"Implement authentication\" -p 1 -t feature\n   bd create \"Add API documentation\" -p 1 -t task\n   bd create \"Refactor database layer\" -p 2 -t task\n   ```\n\n3. **Run the demo:**\n   ```bash\n   bd-example-extension-go -cmd demo\n   ```\n\n4. **Check the results:**\n   ```bash\n   bd list\n   sqlite3 .beads/demo.db \"SELECT * FROM example_executions\"\n   ```\n\n## Real-World Usage\n\nThis pattern is used in production by:\n\n- **VC (VibeCoder)**: Multi-agent orchestration with state machines\n- **CI/CD Systems**: Build tracking and artifact management\n- **Task Runners**: Parallel execution with dependency resolution\n\nSee [EXTENDING.md](../../EXTENDING.md) for more patterns and the VC implementation example.\n\n## Next Steps\n\n1. **Add Your Own Tables**: Extend the schema with application-specific tables\n2. **Implement State Machines**: Use checkpoints for resumable workflows\n3. **Add Metrics**: Track execution times, retry counts, success rates\n4. **Build Dashboards**: Query joined data for visibility\n5. **Integrate with Agents**: Use bd's ready work queue for agent orchestration\n\n## See Also\n\n- [EXTENDING.md](../../EXTENDING.md) - Complete extension guide\n- [../../README.md](../../README.md) - bd documentation\n- [QUICKSTART.md](../../docs/QUICKSTART.md) - Quick start tutorial\n",
        "examples/claude-desktop-mcp/README.md": "# Claude Desktop MCP Server for Beads\n\n> **Note**: The beads MCP server is now fully implemented! See [integrations/beads-mcp](../../integrations/beads-mcp/) for the production implementation.\n\n> **Recommendation**: For environments with shell access (Claude Code, Cursor, Windsurf), use **CLI + hooks** instead of MCP. It uses ~1-2k tokens vs 10-50k for MCP schemas, resulting in lower compute cost and latency. **Use MCP only for MCP-only environments** like Claude Desktop where CLI is unavailable.\n\n## What This Provides\n\nAn MCP server that exposes bd functionality to Claude Desktop and other MCP clients, allowing Claude to:\n- Query ready work\n- Create and update issues\n- Manage dependencies\n- Track discovered work\n\n## Quick Start\n\nInstall the beads MCP server:\n\n```bash\n# Using uv (recommended)\nuv tool install beads-mcp\n\n# Or using pip\npip install beads-mcp\n```\n\nAdd to your Claude Desktop config (`~/Library/Application Support/Claude/claude_desktop_config.json` on macOS):\n\n```json\n{\n  \"mcpServers\": {\n    \"beads\": {\n      \"command\": \"beads-mcp\"\n    }\n  }\n}\n```\n\nRestart Claude Desktop and you're done! Claude can now manage your beads issues.\n\n## Full Documentation\n\nSee the [beads-mcp README](../../integrations/beads-mcp/README.md) for:\n- Installation instructions\n- Configuration options\n- Environment variables\n- Development guide\n\n---\n\n## Original Design Documentation (Historical)\n\n## Planned Features\n\n```typescript\n// MCP server will expose these tools to Claude:\n\n// Find ready work\n{\n  \"name\": \"beads_ready_work\",\n  \"description\": \"Find issues with no blocking dependencies\",\n  \"parameters\": {\n    \"limit\": \"number\",\n    \"priority\": \"number (0-4)\",\n    \"assignee\": \"string\"\n  }\n}\n\n// Create issue\n{\n  \"name\": \"beads_create_issue\",\n  \"description\": \"Create a new issue\",\n  \"parameters\": {\n    \"title\": \"string\",\n    \"description\": \"string\",\n    \"priority\": \"number (0-4)\",\n    \"type\": \"bug|feature|task|epic|chore\"\n  }\n}\n\n// Update issue\n{\n  \"name\": \"beads_update_issue\",\n  \"description\": \"Update issue status or fields\",\n  \"parameters\": {\n    \"id\": \"string\",\n    \"status\": \"open|in_progress|blocked|closed\",\n    \"priority\": \"number\",\n    \"assignee\": \"string\"\n  }\n}\n\n// Add dependency\n{\n  \"name\": \"beads_add_dependency\",\n  \"description\": \"Link issues with dependencies\",\n  \"parameters\": {\n    \"from\": \"string (issue ID)\",\n    \"to\": \"string (issue ID)\",\n    \"type\": \"blocks|related|parent-child|discovered-from\"\n  }\n}\n```\n\n## How It Would Work\n\n1. Install the MCP server for Claude Desktop\n2. Claude gains access to bd commands\n3. During coding sessions, Claude can:\n   - Check for ready work: \"What should I work on next?\"\n   - Create issues: \"I found a bug, let me track it\"\n   - Link discoveries: \"This is related to the issue we're working on\"\n   - Update status: \"Marking bd-5 as completed\"\n\n## Example Conversation\n\n```\nUser: What's ready to work on?\n\nClaude: Let me check the ready work queue...\n[Calls beads_ready_work()]\n\nI found 3 ready issues:\n1. bd-12: Fix authentication bug (priority 0, bug)\n2. bd-15: Add dark mode toggle (priority 1, feature)\n3. bd-18: Update documentation (priority 2, task)\n\nWhich would you like to work on?\n\nUser: Let's do bd-12\n\nClaude: Great! I'll mark bd-12 as in progress.\n[Calls beads_update_issue(\"bd-12\", status=\"in_progress\")]\n\nLet me investigate the authentication code...\n[Works on the issue]\n\nI found the bug in auth.js:45 - there's a race condition. While fixing this, I noticed we're also missing rate limiting. Should I track that as a separate issue?\n\nUser: Yes please\n\nClaude: [Calls beads_create_issue(\"Add rate limiting to auth endpoints\", type=\"task\", priority=1)]\nCreated bd-23: Add rate limiting to auth endpoints\n\n[Calls beads_add_dependency(\"bd-23\", \"bd-12\", type=\"discovered-from\")]\nLinked bd-23 as discovered from bd-12\n\nNow I'll complete the auth bug fix...\n```\n\n## Implementation Guide\n\nTo implement this MCP server:\n\n1. Create a Node.js/TypeScript project\n2. Use the MCP SDK: `npm install @anthropic/mcp-sdk`\n3. Implement tool handlers that call `bd` commands via child_process\n4. Register with Claude Desktop's config\n\nExample skeleton:\n\n```typescript\nimport { Server } from \"@anthropic/mcp-sdk\";\nimport { exec } from \"child_process\";\nimport { promisify } from \"util\";\n\nconst execAsync = promisify(exec);\n\nconst server = new Server({\n  name: \"beads\",\n  version: \"1.0.0\"\n});\n\n// Register ready work tool\nserver.tool(\"beads_ready_work\", async (params) => {\n  const { stdout } = await execAsync(\n    `bd ready --json --limit ${params.limit || 10}`\n  );\n  return JSON.parse(stdout);\n});\n\n// Register create issue tool\nserver.tool(\"beads_create_issue\", async (params) => {\n  const { stdout } = await execAsync(\n    `bd create \"${params.title}\" -d \"${params.description}\" -p ${params.priority} -t ${params.type} --json`\n  );\n  return JSON.parse(stdout);\n});\n\n// ... more tools ...\n\nserver.start();\n```\n\n## Installation (Future)\n\n```bash\n# Install the MCP server\nnpm install -g beads-mcp-server\n\n# Configure Claude Desktop\n# Add to ~/Library/Application Support/Claude/claude_desktop_config.json\n{\n  \"mcpServers\": {\n    \"beads\": {\n      \"command\": \"beads-mcp-server\",\n      \"args\": []\n    }\n  }\n}\n\n# Restart Claude Desktop\n```\n\n## Alternative: Direct bd Usage\n\nUntil the MCP server is available, you can instruct Claude to use bd directly:\n\n```markdown\n# In your CLAUDE.md or project instructions:\n\nWe use Beads (bd) for issue tracking. Available commands:\n\n- `bd ready --json` - Find ready work\n- `bd create \"title\" -p 1 -t bug --json` - Create issue\n- `bd update bd-1 --status in_progress --json` - Update status\n- `bd dep add bd-2 bd-1 --type discovered-from` - Link issues\n- `bd close bd-1 --reason \"Done\" --json` - Complete work\n\nAll commands support --json for parsing. Please use bd to track work during our sessions.\n```\n\n## Contributing\n\nInterested in building this MCP server? We welcome contributions!\n\nSee [CONTRIBUTING.md](../../CONTRIBUTING.md) for guidelines.\n\n## See Also\n\n- [MCP Documentation](https://docs.anthropic.com/claude/docs/model-context-protocol)\n- [MCP SDK](https://github.com/anthropics/mcp-sdk)\n- [Claude Desktop](https://claude.ai/desktop)\n- [../python-agent/](../python-agent/) - Python implementation pattern\n",
        "examples/compaction/README.md": "# Compaction Examples\n\nThis directory contains example scripts for automating database compaction.\n\n## Scripts\n\n### workflow.sh\n\nInteractive compaction workflow with prompts. Perfect for manual compaction runs.\n\n```bash\nchmod +x workflow.sh\nexport ANTHROPIC_API_KEY=\"sk-ant-...\"\n./workflow.sh\n```\n\n**Features:**\n- Previews candidates before compaction\n- Prompts for confirmation at each tier\n- Shows final statistics\n- Provides next-step guidance\n\n**When to use:** Manual monthly/quarterly compaction\n\n### cron-compact.sh\n\nFully automated compaction for cron jobs. No interaction required.\n\n```bash\n# Configure\nexport BD_REPO_PATH=\"/path/to/your/repo\"\nexport BD_LOG_FILE=\"$HOME/.bd-compact.log\"\nexport ANTHROPIC_API_KEY=\"sk-ant-...\"\n\n# Test manually\n./cron-compact.sh\n\n# Install to cron (monthly)\ncp cron-compact.sh /etc/cron.monthly/bd-compact\nchmod +x /etc/cron.monthly/bd-compact\n\n# Or add to crontab\ncrontab -e\n# Add: 0 2 1 * * /path/to/cron-compact.sh\n```\n\n**Features:**\n- Pulls latest changes before compacting\n- Logs all output\n- Auto-commits and pushes results\n- Reports counts of compacted issues\n\n**When to use:** Automated monthly compaction for active projects\n\n### auto-compact.sh\n\nSmart auto-compaction with thresholds. Only runs if enough eligible issues exist.\n\n```bash\nchmod +x auto-compact.sh\n\n# Compact if 10+ eligible issues\n./auto-compact.sh\n\n# Custom threshold\n./auto-compact.sh --threshold 50\n\n# Tier 2 ultra-compression\n./auto-compact.sh --tier 2 --threshold 20\n\n# Preview without compacting\n./auto-compact.sh --dry-run\n```\n\n**Features:**\n- Configurable eligibility threshold\n- Skips compaction if below threshold\n- Supports both tiers\n- Dry-run mode for testing\n\n**When to use:** \n- Pre-commit hooks (if ANTHROPIC_API_KEY set)\n- CI/CD pipelines\n- Conditional automation\n\n## Configuration\n\nAll scripts require:\n\n```bash\nexport ANTHROPIC_API_KEY=\"sk-ant-...\"\n```\n\nAdditional environment variables:\n\n- `BD_REPO_PATH`: Repository path (cron-compact.sh)\n- `BD_LOG_FILE`: Log file location (cron-compact.sh)\n\n## Recommendations\n\n### Small Projects (<500 issues)\nUse `workflow.sh` manually, once or twice per year.\n\n### Medium Projects (500-5000 issues)\nUse `cron-compact.sh` quarterly or `auto-compact.sh` in CI.\n\n### Large Projects (5000+ issues)\nUse `cron-compact.sh` monthly with both tiers:\n```bash\n# Modify cron-compact.sh to run both tiers\n```\n\n### High-Velocity Teams\nCombine approaches:\n- `auto-compact.sh --threshold 50` in CI (Tier 1 only)\n- `cron-compact.sh` monthly for Tier 2\n\n## Testing\n\nBefore deploying to cron, test scripts manually:\n\n```bash\n# Test workflow\nexport ANTHROPIC_API_KEY=\"sk-ant-...\"\n./workflow.sh\n\n# Test cron script\nexport BD_REPO_PATH=\"$(pwd)\"\n./cron-compact.sh\n\n# Test auto-compact (dry run)\n./auto-compact.sh --dry-run --threshold 1\n```\n\n## Troubleshooting\n\n### Script says \"bd command not found\"\n\nEnsure bd is in PATH:\n```bash\nwhich bd\nexport PATH=\"$PATH:/usr/local/bin\"\n```\n\n### \"ANTHROPIC_API_KEY not set\"\n\n```bash\nexport ANTHROPIC_API_KEY=\"sk-ant-...\"\n# Add to ~/.zshrc or ~/.bashrc for persistence\n```\n\n### Cron job not running\n\nCheck cron logs:\n```bash\n# Linux\ngrep CRON /var/log/syslog\n\n# macOS\nlog show --predicate 'process == \"cron\"' --last 1h\n```\n\nVerify script is executable:\n```bash\nchmod +x /etc/cron.monthly/bd-compact\n```\n\n## Cost Monitoring\n\nTrack compaction costs:\n\n```bash\n# Show stats after compaction\nbd admin compact --stats\n\n# Estimate monthly cost\n# (issues_compacted / 1000) * $1.00\n```\n\nSet up alerts if costs exceed budget (future feature: bd-cost-alert).\n\n## See Also\n\n- [COMPACTION.md](../../COMPACTION.md) - Comprehensive compaction guide\n- [README.md](../../README.md) - Main documentation\n- [GIT_WORKFLOW.md](../../GIT_WORKFLOW.md) - Multi-machine collaboration\n",
        "examples/contributor-workflow/README.md": "# OSS Contributor Workflow Example\n\nThis example demonstrates how to use beads' contributor workflow to keep your planning issues separate from upstream PRs when contributing to open-source projects.\n\n## Problem\n\nWhen contributing to OSS projects, you want to:\n- Track your planning, todos, and design notes\n- Keep experimental work organized\n- **NOT** pollute upstream PRs with your personal planning issues\n\n## Solution\n\nUse `bd init --contributor` to set up a separate planning repository that never gets committed to the upstream project.\n\n## Setup\n\n### Step 1: Fork and Clone\n\n```bash\n# Fork the project on GitHub, then clone your fork\ngit clone https://github.com/YOUR_USERNAME/project.git\ncd project\n\n# Add upstream remote (important for fork detection!)\ngit remote add upstream https://github.com/ORIGINAL_OWNER/project.git\n```\n\n### Step 2: Initialize Beads with Contributor Wizard\n\n```bash\n# Run the contributor setup wizard\nbd init --contributor\n```\n\nThe wizard will:\n1. âœ… Detect that you're in a fork (checks for 'upstream' remote)\n2. âœ… Prompt you to create a planning repo (`~/.beads-planning` by default)\n3. âœ… Configure auto-routing so your planning stays separate\n4. âœ… Initialize the planning repo with git\n\n### Step 3: Start Working\n\n```bash\n# Create a planning issue\nbd create \"Plan how to fix bug X\" -p 2\n\n# This issue goes to ~/.beads-planning automatically!\n```\n\n## How It Works\n\n### Auto-Routing\n\nWhen you create issues as a contributor:\n\n```bash\nbd create \"Fix authentication bug\" -p 1\n```\n\nBeads automatically routes this to your planning repo (`~/.beads-planning/.beads/issues.jsonl`), not the current repo.\n\n### Viewing Issues\n\n```bash\n# See all issues (from both repos)\nbd list\n\n# See only current repo issues\nbd list --source-repo .\n\n# See only planning issues\nbd list --source-repo ~/.beads-planning\n```\n\n### Discovered Work\n\nWhen you discover work while implementing:\n\n```bash\n# The new issue inherits source_repo from parent\nbd create \"Found edge case in auth\" -p 1 --deps discovered-from:bd-42\n```\n\n### Committing Code (Not Planning)\n\nYour code changes get committed to the fork, but planning issues stay separate:\n\n```bash\n# Only commits to fork (not planning repo)\ngit add src/auth.go\ngit commit -m \"Fix: authentication bug\"\ngit push origin my-feature-branch\n```\n\nYour planning issues in `~/.beads-planning` **never appear in PRs**.\n\n## Example Workflow\n\n```bash\n# 1. Create fork and clone\ngit clone https://github.com/you/upstream-project.git\ncd upstream-project\ngit remote add upstream https://github.com/upstream/upstream-project.git\n\n# 2. Run contributor setup\nbd init --contributor\n# Wizard detects fork âœ“\n# Creates ~/.beads-planning âœ“\n# Configures auto-routing âœ“\n\n# 3. Plan your work (routes to planning repo)\nbd create \"Research how auth module works\" -p 2\nbd create \"Design fix for bug #123\" -p 1\nbd ready  # Shows planning issues\n\n# 4. Implement (commit code only)\ngit checkout -b fix-auth-bug\n# ... make changes ...\ngit add . && git commit -m \"Fix: auth bug\"\n\n# 5. Track discovered work (stays in planning repo)\nbd create \"Found related issue in logout\" -p 2 --deps discovered-from:bd-abc\n\n# 6. Push code (planning never included)\ngit push origin fix-auth-bug\n# Create PR on GitHub - zero planning pollution!\n\n# 7. Clean up after PR merges\nbd close bd-abc --reason \"PR merged\"\n```\n\n## Configuration\n\nThe wizard configures these settings in `.beads/beads.db`:\n\n```yaml\ncontributor:\n  planning_repo: ~/.beads-planning\n  auto_route: true\n```\n\n### Manual Configuration\n\nIf you prefer manual setup:\n\n```bash\n# Initialize beads normally\nbd init\n\n# Configure planning repo\nbd config set contributor.planning_repo ~/.beads-planning\nbd config set contributor.auto_route true\n```\n\n## Multi-Repository View\n\nBeads aggregates issues from multiple repos:\n\n```bash\n# List issues from all configured repos\nbd list\n\n# Filter by source repository\nbd list --source-repo .                    # Current repo only\nbd list --source-repo ~/.beads-planning    # Planning repo only\n```\n\n## Benefits\n\nâœ… **Clean PRs** - No personal todos in upstream contributions\nâœ… **Private planning** - Experimental work stays local\nâœ… **Git ledger** - Everything is version controlled\nâœ… **Unified view** - See all issues with `bd list`\nâœ… **Auto-routing** - No manual sorting needed\n\n## Common Questions\n\n### Q: What if I want some issues in the upstream repo?\n\nA: Override auto-routing with `--source-repo` flag:\n\n```bash\nbd create \"Document new API\" -p 2 --source-repo .\n```\n\n### Q: Can I change the planning repo location?\n\nA: Yes, configure it:\n\n```bash\nbd config set contributor.planning_repo /path/to/my-planning\n```\n\n### Q: What if I have push access to upstream?\n\nA: The wizard will ask if you want a planning repo anyway. You can say \"no\" to store everything in the current repo.\n\n### Q: How do I disable auto-routing?\n\nA: Turn it off:\n\n```bash\nbd config set contributor.auto_route false\n```\n\n## See Also\n\n- [Multi-Repo Migration Guide](../../docs/MULTI_REPO_MIGRATION.md)\n- [Team Workflow Example](../team-workflow/)\n- [Protected Branch Setup](../protected-branch/)\n",
        "examples/git-hooks/README.md": "# bd Git Hooks\n\nThis directory contains git hooks that integrate bd (beads) with your git workflow, preventing stale JSONL from being pushed to remote.\n\n## The Problem\n\nTwo race conditions can occur:\n\n1. **Between operations and commits**: Daemon auto-flush (5s debounce) may fire after commit\n   - User closes issue via MCP â†’ daemon schedules flush (5 sec delay)\n   - User commits code changes â†’ JSONL appears clean\n   - Daemon flush fires â†’ JSONL modified after commit\n   - Result: dirty working tree showing JSONL changes\n\n2. **Between commits and pushes**: Changes made after commit but before push (bd-my64)\n   - User commits â†’ pre-commit hook flushes JSONL\n   - User adds comments or updates issues\n   - User pushes â†’ outdated JSONL is pushed\n   - Result: remote has stale JSONL\n\n## The Solution\n\nThese git hooks ensure bd changes are always synchronized with your commits and pushes:\n\n- **pre-commit** - Flushes pending bd changes to JSONL before commit and stages it\n- **pre-push** - Blocks push if JSONL has uncommitted changes (bd-my64)\n- **post-merge** - Imports updated JSONL after git pull/merge\n\n## Installation\n\n### Quick Install (Recommended)\n\nUse `bd hooks install` to install hooks automatically:\n\n```bash\nbd hooks install\n```\n\nAlternatively, use `bd init --quiet` which installs hooks during initialization.\n\n**Hook Chaining (New in v0.23):** If you already have git hooks installed (e.g., pre-commit framework), bd will:\n- Detect existing hooks\n- Offer to chain with them (recommended)\n- Preserve your existing hooks while adding bd functionality\n- Back up hooks if you choose to overwrite\n\nThis prevents bd from silently overwriting workflows like pre-commit framework, which previously caused test failures to slip through.\n\nThe installer will:\n- Copy hooks to `.git/hooks/`\n- Make them executable\n- Detect and preserve existing hooks\n\n### Shared Hooks for Teams (New in v0.24.3)\n\nFor teams that need to share hooks across members (especially when using pre-built containers or CI/CD):\n\n```bash\nbd hooks install --shared\n```\n\nThis installs hooks to `.beads-hooks/` (a versioned directory) instead of `.git/hooks/`, and configures git to use them via `git config core.hooksPath .beads-hooks`.\n\n**Benefits:**\n- âœ… Hooks are versioned and can be committed to your repository\n- âœ… Team members get hooks automatically when they clone/pull\n- âœ… Security teams can scan and audit hook contents before deployment\n- âœ… Works with pre-built containers (hooks are already in the repo)\n- âœ… Hooks stay in sync when you run `bd hooks install --shared` after upgrades\n\n**Use cases:**\n- Teams building containers in CI that need hooks pre-installed\n- Organizations requiring security scanning of all code (including hooks)\n- Projects where consistent tooling across team members is critical\n- Devcontainer workflows where bd is installed during container build\n\nAfter running `bd hooks install --shared`, commit `.beads-hooks/` to your repository:\n\n```bash\ngit add .beads-hooks/\ngit commit -m \"Add bd git hooks for team\"\n```\n\n### Manual Install\n\n```bash\ncp examples/git-hooks/pre-commit .git/hooks/pre-commit\ncp examples/git-hooks/pre-push .git/hooks/pre-push\ncp examples/git-hooks/post-merge .git/hooks/post-merge\nchmod +x .git/hooks/pre-commit .git/hooks/pre-push .git/hooks/post-merge\n```\n\n## How It Works\n\n### pre-commit\n\nBefore each commit, the hook runs:\n\n```bash\nbd sync --flush-only\n```\n\nThis:\n1. Exports any pending database changes to `.beads/issues.jsonl`\n2. Stages the JSONL file if modified\n3. Allows the commit to proceed with clean state\n\nThe hook is silent on success, fast (no git operations), and safe (fails commit if flush fails).\n\n### pre-push\n\nBefore each push, the hook:\n\n```bash\nbd sync --flush-only  # Flush pending changes (if bd available)\ngit status --porcelain .beads/*.jsonl  # Check for uncommitted changes\n```\n\nThis prevents pushing stale JSONL by:\n1. Flushing pending in-memory changes from daemon's 5s debounce\n2. Checking for uncommitted changes (staged, unstaged, untracked, deleted)\n3. Failing the push with clear error message if changes exist\n4. Instructing user to commit JSONL before pushing again\n\nThis solves bd-my64: changes made between commit and push (or pending debounced flushes) are caught before reaching remote.\n\n### post-merge\n\nAfter a git pull or merge, the hook runs:\n\n```bash\nbd import -i .beads/issues.jsonl\n```\n\nThis ensures your local database reflects the merged state. The hook:\n- Only runs if `.beads/issues.jsonl` exists (also checks `issues.jsonl` for backward compat)\n- Imports any new issues or updates from the merge\n- Warns on failure but doesn't block the merge\n\n**Note:** With hash-based IDs (v0.20.1+), ID collisions don't occur - different issues get different hash IDs.\n\n## Compatibility\n\n- **Auto-sync**: Works alongside bd's automatic 5-second debounce\n- **Direct mode**: Hooks work in both daemon and `--no-daemon` mode\n- **Worktrees**: Safe to use with git worktrees\n\n## Benefits\n\nâœ… No more dirty working tree after commits  \nâœ… Database always in sync with git  \nâœ… Automatic collision resolution on merge  \nâœ… Fast and silent operation  \nâœ… Optional - manual `bd sync` still works  \n\n## Uninstall\n\nRemove the hooks:\n\n```bash\nrm .git/hooks/pre-commit .git/hooks/pre-push .git/hooks/post-merge\n```\n\nYour backed-up hooks (if any) are in `.git/hooks/*.backup-*`.\n\n## Related\n\n- See [bd-51](../../.beads/bd-51) for the race condition bug report\n- See [AGENTS.md](../../AGENTS.md) for the full git workflow\n- See [examples/](../) for other integrations\n",
        "examples/github-import/README.md": "# GitHub Issues to bd Importer\n\nImport issues from GitHub repositories into `bd`.\n\n## Overview\n\nThis tool converts GitHub Issues to bd's JSONL format, supporting both:\n1. **GitHub API** - Fetch issues directly from a repository\n2. **JSON Export** - Parse manually exported GitHub issues\n\n## Features\n\n- âœ… **Fetch from GitHub API** - Direct import from any public/private repo\n- âœ… **JSON file import** - Parse exported GitHub issues JSON\n- âœ… **Label mapping** - Auto-map GitHub labels to bd priority/type\n- âœ… **Preserve metadata** - Keep assignees, timestamps, descriptions\n- âœ… **Cross-references** - Convert `#123` references to dependencies\n- âœ… **External links** - Preserve URLs back to original GitHub issues\n- âœ… **Filter PRs** - Automatically excludes pull requests\n\n## Installation\n\nNo dependencies required! Uses Python 3 standard library.\n\nFor API access, set up a GitHub token:\n\n```bash\n# Create token at: https://github.com/settings/tokens\n# Permissions needed: public_repo (or repo for private repos)\n\nexport GITHUB_TOKEN=ghp_your_token_here\n```\n\n**Security Note:** Use the `GITHUB_TOKEN` environment variable instead of `--token` flag when possible. The `--token` flag may appear in shell history and process listings.\n\n## Usage\n\n### From GitHub API\n\n```bash\n# Fetch all issues from a repository\npython gh2jsonl.py --repo owner/repo | bd import\n\n# Save to file first (recommended)\npython gh2jsonl.py --repo owner/repo > issues.jsonl\nbd import -i issues.jsonl --dry-run  # Preview\nbd import -i issues.jsonl             # Import\n\n# Fetch only open issues\npython gh2jsonl.py --repo owner/repo --state open\n\n# Fetch only closed issues\npython gh2jsonl.py --repo owner/repo --state closed\n```\n\n### From JSON File\n\nExport issues from GitHub (via API or manually), then:\n\n```bash\n# Single issue\ncurl -H \"Authorization: token $GITHUB_TOKEN\" \\\n  https://api.github.com/repos/owner/repo/issues/123 > issue.json\n\npython gh2jsonl.py --file issue.json | bd import\n\n# Multiple issues\ncurl -H \"Authorization: token $GITHUB_TOKEN\" \\\n  https://api.github.com/repos/owner/repo/issues > issues.json\n\npython gh2jsonl.py --file issues.json | bd import\n```\n\n### Custom Options\n\n```bash\n# Use custom prefix (instead of 'bd')\npython gh2jsonl.py --repo owner/repo --prefix myproject\n\n# Start numbering from specific ID\npython gh2jsonl.py --repo owner/repo --start-id 100\n\n# Pass token directly (instead of env var)\npython gh2jsonl.py --repo owner/repo --token ghp_...\n```\n\n## Label Mapping\n\nThe script maps GitHub labels to bd fields:\n\n### Priority Mapping\n\n| GitHub Labels | bd Priority |\n|--------------|-------------|\n| `critical`, `p0`, `urgent` | 0 (Critical) |\n| `high`, `p1`, `important` | 1 (High) |\n| (default) | 2 (Medium) |\n| `low`, `p3`, `minor` | 3 (Low) |\n| `backlog`, `p4`, `someday` | 4 (Backlog) |\n\n### Type Mapping\n\n| GitHub Labels | bd Type |\n|--------------|---------|\n| `bug`, `defect` | bug |\n| `feature`, `enhancement` | feature |\n| `epic`, `milestone` | epic |\n| `chore`, `maintenance`, `dependencies` | chore |\n| (default) | task |\n\n### Status Mapping\n\n| GitHub State | GitHub Labels | bd Status |\n|-------------|---------------|-----------|\n| closed | (any) | closed |\n| open | `in progress`, `in-progress`, `wip` | in_progress |\n| open | `blocked` | blocked |\n| open | (default) | open |\n\n### Labels\n\nAll other labels are preserved in the `labels` field. Labels used for mapping (priority, type, status) are filtered out to avoid duplication.\n\n## Field Mapping\n\n| GitHub Field | bd Field | Notes |\n|--------------|----------|-------|\n| `number` | (internal mapping) | GH#123 â†’ bd-1, etc. |\n| `title` | `title` | Direct copy |\n| `body` | `description` | Direct copy |\n| `state` | `status` | See status mapping |\n| `labels` | `priority`, `issue_type`, `labels` | See label mapping |\n| `assignee.login` | `assignee` | First assignee only |\n| `created_at` | `created_at` | ISO 8601 timestamp |\n| `updated_at` | `updated_at` | ISO 8601 timestamp |\n| `closed_at` | `closed_at` | ISO 8601 timestamp |\n| `html_url` | `external_ref` | Link back to GitHub |\n\n## Cross-References\n\nIssue references in the body text are converted to dependencies:\n\n**GitHub:**\n```markdown\nThis depends on #123 and fixes #456.\nSee also owner/other-repo#789.\n```\n\n**Result:**\n- If GH#123 was imported, creates `related` dependency to its bd ID\n- If GH#456 was imported, creates `related` dependency to its bd ID\n- Cross-repo references (#789) are ignored (unless those issues were also imported)\n\n**Note:** Dependency records use `\"issue_id\": \"\"` format, which the bd importer automatically fills. This matches the behavior of the markdown-to-jsonl converter.\n\n## Examples\n\n### Example 1: Import Active Issues\n\n```bash\n# Import only open issues for active work\nexport GITHUB_TOKEN=ghp_...\npython gh2jsonl.py --repo mycompany/myapp --state open > open-issues.jsonl\n\n# Preview\ncat open-issues.jsonl | jq .\n\n# Import\nbd import -i open-issues.jsonl\nbd ready  # See what's ready to work on\n```\n\n### Example 2: Full Repository Migration\n\n```bash\n# Import all issues (open and closed)\npython gh2jsonl.py --repo mycompany/myapp > all-issues.jsonl\n\n# Preview import (check for new issues and updates)\nbd import -i all-issues.jsonl --dry-run\n\n# Import issues\nbd import -i all-issues.jsonl\n\n# View stats\nbd stats\n```\n\n### Example 3: Partial Import from JSON\n\n```bash\n# Manually export specific issues via GitHub API\ngh api repos/owner/repo/issues?labels=p1,bug > high-priority-bugs.json\n\n# Import\npython gh2jsonl.py --file high-priority-bugs.json | bd import\n```\n\n## Customization\n\nThe script is intentionally simple to customize for your workflow:\n\n### 1. Adjust Label Mappings\n\nEdit `map_priority()`, `map_issue_type()`, and `map_status()` to match your label conventions:\n\n```python\ndef map_priority(self, labels: List[str]) -> int:\n    label_names = [label.get(\"name\", \"\").lower() if isinstance(label, dict) else label.lower() for label in labels]\n    \n    # Add your custom mappings\n    if any(l in label_names for l in [\"sev1\", \"emergency\"]):\n        return 0\n    # ... etc\n```\n\n### 2. Add Custom Fields\n\nMap additional GitHub fields to bd:\n\n```python\ndef convert_issue(self, gh_issue: Dict[str, Any]) -> Dict[str, Any]:\n    # ... existing code ...\n    \n    # Add milestone to design field\n    if gh_issue.get(\"milestone\"):\n        issue[\"design\"] = f\"Milestone: {gh_issue['milestone']['title']}\"\n    \n    return issue\n```\n\n### 3. Enhanced Dependency Detection\n\nParse more dependency patterns from body text:\n\n```python\ndef extract_dependencies_from_body(self, body: str) -> List[str]:\n    # ... existing code ...\n    \n    # Add: \"Blocks: #123, #456\"\n    blocks_pattern = r'Blocks:\\s*((?:#\\d+(?:\\s*,\\s*)?)+)'\n    # ... etc\n```\n\n## Limitations\n\n- **Single assignee**: GitHub supports multiple assignees, bd supports one\n- **No milestones**: GitHub milestones aren't mapped (consider using design field)\n- **Simple cross-refs**: Only basic `#123` patterns detected\n- **No comments**: Issue comments aren't imported (only the body)\n- **No reactions**: GitHub reactions/emoji aren't imported\n- **No projects**: GitHub project board info isn't imported\n\n## API Rate Limits\n\nGitHub API has rate limits:\n- **Authenticated**: 5,000 requests/hour\n- **Unauthenticated**: 60 requests/hour\n\nThis script uses 1 request per 100 issues (pagination), so:\n- Can fetch ~500,000 issues/hour (authenticated)\n- Can fetch ~6,000 issues/hour (unauthenticated)\n\nFor large repositories (>1000 issues), authentication is recommended.\n\n**Note:** The script automatically includes a `User-Agent` header (required by GitHub) and provides actionable error messages when rate limits are exceeded, including the reset timestamp.\n\n## Troubleshooting\n\n### \"GitHub token required\"\n\nSet the `GITHUB_TOKEN` environment variable:\n```bash\nexport GITHUB_TOKEN=ghp_your_token_here\n```\n\nOr pass directly:\n```bash\npython gh2jsonl.py --repo owner/repo --token ghp_...\n```\n\n### \"GitHub API error: 404\"\n\n- Check repository name format: `owner/repo`\n- Check repository exists and is accessible\n- For private repos, ensure token has `repo` scope\n\n### \"GitHub API error: 403\"\n\n- Rate limit exceeded (wait or use authentication)\n- Token doesn't have required permissions\n- Repository requires different permissions\n\n### Issue numbers don't match\n\nThis is expected! GitHub issue numbers (e.g., #123) are mapped to bd IDs (e.g., bd-1) based on import order. The original GitHub URL is preserved in `external_ref`.\n\n## See Also\n\n- [bd README](../../README.md) - Main documentation\n- [Markdown Import Example](../markdown-to-jsonl/) - Import from markdown\n- [TEXT_FORMATS.md](../../TEXT_FORMATS.md) - Understanding bd's JSONL format\n- [JSONL Import Guide](../../README.md#import) - Import collision handling\n",
        "examples/jira-import/README.md": "# Jira Integration for bd\n\nTwo-way synchronization between Jira and bd (beads).\n\n## Scripts\n\n| Script | Purpose |\n|--------|---------|\n| `jira2jsonl.py` | **Import** - Fetch Jira issues into bd |\n| `jsonl2jira.py` | **Export** - Push bd issues to Jira |\n\n## Overview\n\nThese tools enable bidirectional sync between Jira and bd:\n\n**Import (Jira â†’ bd):**\n1. **Jira REST API** - Fetch issues directly from any Jira instance\n2. **JSON Export** - Parse exported Jira issues JSON\n3. **bd config integration** - Read credentials and mappings from `bd config`\n\n**Export (bd â†’ Jira):**\n1. **Create issues** - Push new bd issues to Jira\n2. **Update issues** - Sync changes to existing Jira issues\n3. **Status transitions** - Handle Jira workflow transitions automatically\n\n## Features\n\n### Import (jira2jsonl.py)\n\n- Fetch from Jira Cloud or Server/Data Center\n- JQL query support for flexible filtering\n- Configurable field mappings (status, priority, type)\n- Preserve timestamps, assignees, labels\n- Extract issue links as dependencies\n- Set `external_ref` for re-sync capability\n- Hash-based or sequential ID generation\n\n### Export (jsonl2jira.py)\n\n- Create new Jira issues from bd issues\n- Update existing Jira issues (matched by `external_ref`)\n- Handle Jira workflow transitions for status changes\n- Reverse field mappings (bd â†’ Jira)\n- Dry-run mode for previewing changes\n- Auto-update `external_ref` after creation\n\n## Installation\n\nNo dependencies required! Uses Python 3 standard library.\n\n## Quick Start\n\n### Option 1: Using bd config (Recommended)\n\nSet up your Jira credentials once:\n\n```bash\n# Required settings\nbd config set jira.url \"https://company.atlassian.net\"\nbd config set jira.project \"PROJ\"\nbd config set jira.api_token \"YOUR_API_TOKEN\"\n\n# For Jira Cloud, also set username (your email)\nbd config set jira.username \"you@company.com\"\n```\n\nThen import:\n\n```bash\npython jira2jsonl.py --from-config | bd import\n```\n\n### Option 2: Using environment variables\n\n```bash\nexport JIRA_API_TOKEN=your_token\nexport JIRA_USERNAME=you@company.com  # For Jira Cloud\n\npython jira2jsonl.py \\\n  --url https://company.atlassian.net \\\n  --project PROJ \\\n  | bd import\n```\n\n### Option 3: Command-line arguments\n\n```bash\npython jira2jsonl.py \\\n  --url https://company.atlassian.net \\\n  --project PROJ \\\n  --username you@company.com \\\n  --api-token YOUR_TOKEN \\\n  | bd import\n```\n\n## Authentication\n\n### Jira Cloud\n\nJira Cloud requires:\n1. **Username**: Your email address\n2. **API Token**: Create at https://id.atlassian.com/manage-profile/security/api-tokens\n\n```bash\nbd config set jira.username \"you@company.com\"\nbd config set jira.api_token \"your_api_token\"\n```\n\n### Jira Server/Data Center\n\nJira Server/DC can use:\n- **Personal Access Token (PAT)** - Just set the token, no username needed\n- **Username + Password** - Set both username and password as the token\n\n```bash\n# Using PAT (recommended)\nbd config set jira.api_token \"your_pat_token\"\n\n# Using username/password\nbd config set jira.username \"your_username\"\nbd config set jira.api_token \"your_password\"\n```\n\n## Usage\n\n### Basic Usage\n\n```bash\n# Fetch all issues from a project\npython jira2jsonl.py --from-config | bd import\n\n# Save to file first (recommended for large projects)\npython jira2jsonl.py --from-config > issues.jsonl\nbd import -i issues.jsonl --dry-run  # Preview\nbd import -i issues.jsonl             # Import\n```\n\n### Filtering Issues\n\n```bash\n# Only open issues\npython jira2jsonl.py --from-config --state open\n\n# Only closed issues\npython jira2jsonl.py --from-config --state closed\n\n# Custom JQL query\npython jira2jsonl.py --url https://company.atlassian.net \\\n  --jql \"project = PROJ AND priority = High AND status != Done\"\n```\n\n### ID Generation Modes\n\n```bash\n# Sequential IDs (bd-1, bd-2, ...) - default\npython jira2jsonl.py --from-config\n\n# Hash-based IDs (bd-a3f2dd, ...) - matches bd create\npython jira2jsonl.py --from-config --id-mode hash\n\n# Custom hash length (3-8 chars)\npython jira2jsonl.py --from-config --id-mode hash --hash-length 4\n\n# Custom prefix\npython jira2jsonl.py --from-config --prefix myproject\n```\n\n### From JSON File\n\nIf you have an exported JSON file:\n\n```bash\npython jira2jsonl.py --file issues.json | bd import\n```\n\n## Field Mapping\n\n### Default Mappings\n\n| Jira Field | bd Field | Notes |\n|------------|----------|-------|\n| `key` | (internal) | Used for dependency resolution |\n| `summary` | `title` | Direct copy |\n| `description` | `description` | Direct copy |\n| `status.name` | `status` | Mapped via status_map |\n| `priority.name` | `priority` | Mapped via priority_map |\n| `issuetype.name` | `issue_type` | Mapped via type_map |\n| `assignee` | `assignee` | Display name or username |\n| `labels` | `labels` | Direct copy |\n| `created` | `created_at` | ISO 8601 timestamp |\n| `updated` | `updated_at` | ISO 8601 timestamp |\n| `resolutiondate` | `closed_at` | ISO 8601 timestamp |\n| (computed) | `external_ref` | URL to Jira issue |\n| `issuelinks` | `dependencies` | Mapped to blocks/related |\n| `parent` | `dependencies` | Mapped to parent-child |\n\n### Status Mapping\n\nDefault status mappings (Jira status -> bd status):\n\n| Jira Status | bd Status |\n|-------------|-----------|\n| To Do, Open, Backlog, New | `open` |\n| In Progress, In Development, In Review | `in_progress` |\n| Blocked, On Hold | `blocked` |\n| Done, Closed, Resolved, Complete | `closed` |\n\nCustom mappings via bd config:\n\n```bash\nbd config set jira.status_map.backlog \"open\"\nbd config set jira.status_map.in_review \"in_progress\"\nbd config set jira.status_map.on_hold \"blocked\"\n```\n\n### Priority Mapping\n\nDefault priority mappings (Jira priority -> bd priority 0-4):\n\n| Jira Priority | bd Priority |\n|---------------|-------------|\n| Highest, Critical, Blocker | 0 (Critical) |\n| High, Major | 1 (High) |\n| Medium, Normal | 2 (Medium) |\n| Low, Minor | 3 (Low) |\n| Lowest, Trivial | 4 (Backlog) |\n\nCustom mappings:\n\n```bash\nbd config set jira.priority_map.urgent \"0\"\nbd config set jira.priority_map.nice_to_have \"4\"\n```\n\n### Issue Type Mapping\n\nDefault type mappings (Jira type -> bd type):\n\n| Jira Type | bd Type |\n|-----------|---------|\n| Bug, Defect | `bug` |\n| Story, Feature, Enhancement | `feature` |\n| Task, Sub-task | `task` |\n| Epic, Initiative | `epic` |\n| Technical Task, Maintenance | `chore` |\n\nCustom mappings:\n\n```bash\nbd config set jira.type_map.story \"feature\"\nbd config set jira.type_map.spike \"task\"\nbd config set jira.type_map.tech_debt \"chore\"\n```\n\n## Issue Links & Dependencies\n\nJira issue links are converted to bd dependencies:\n\n| Jira Link Type | bd Dependency Type |\n|----------------|-------------------|\n| Blocks/Is blocked by | `blocks` |\n| Parent (Epic/Story) | `parent-child` |\n| All others | `related` |\n\n**Note:** Only links to issues included in the import are preserved. Links to issues outside the query results are ignored.\n\n## Re-syncing from Jira\n\nEach imported issue has an `external_ref` field containing the Jira issue URL. On subsequent imports:\n\n1. Issues are matched by `external_ref` first\n2. If matched, the existing bd issue is updated (if Jira is newer)\n3. If not matched, a new bd issue is created\n\nThis enables incremental sync:\n\n```bash\n# Initial import\npython jira2jsonl.py --from-config | bd import\n\n# Later: import only recent changes\npython jira2jsonl.py --from-config \\\n  --jql \"project = PROJ AND updated >= -7d\" \\\n  | bd import\n```\n\n## Examples\n\n### Example 1: Import Active Sprint\n\n```bash\npython jira2jsonl.py --url https://company.atlassian.net \\\n  --jql \"project = PROJ AND sprint in openSprints()\" \\\n  | bd import\n\nbd ready  # See what's ready to work on\n```\n\n### Example 2: Full Project Migration\n\n```bash\n# Export all issues\npython jira2jsonl.py --from-config > all-issues.jsonl\n\n# Preview import\nbd import -i all-issues.jsonl --dry-run\n\n# Import\nbd import -i all-issues.jsonl\n\n# View stats\nbd stats\n```\n\n### Example 3: Sync High Priority Bugs\n\n```bash\npython jira2jsonl.py --from-config \\\n  --jql \"project = PROJ AND type = Bug AND priority in (Highest, High)\" \\\n  | bd import\n```\n\n### Example 4: Import with Hash IDs\n\n```bash\n# Use hash IDs for collision-free distributed work\npython jira2jsonl.py --from-config --id-mode hash | bd import\n```\n\n## Limitations\n\n- **Single assignee**: Jira supports multiple assignees (watchers), bd supports one\n- **Custom fields**: Only standard fields are mapped; custom fields are ignored\n- **Attachments**: Not imported\n- **Comments**: Not imported (only description)\n- **Worklogs**: Not imported\n- **Sprints**: Sprint metadata not preserved (use labels or JQL filtering)\n- **Components/Versions**: Not mapped to bd (consider using labels)\n\n## Troubleshooting\n\n### \"Authentication failed\"\n\n**Jira Cloud:**\n- Verify you're using your email as username\n- Create a fresh API token at https://id.atlassian.com/manage-profile/security/api-tokens\n- Ensure the token has access to the project\n- **Silent auth failure**: The Jira API may return HTTP 200 with empty results instead of 401. Check for `X-Seraph-Loginreason: AUTHENTICATED_FAILED` header in responses.\n\n**Jira Server/DC:**\n- Try using a Personal Access Token instead of password\n- Check that your account has permission to access the project\n\n### \"403 Forbidden\"\n\n- Check project permissions in Jira\n- Verify API token has correct scopes\n- Some Jira instances restrict API access by IP\n\n### \"400 Bad Request\"\n\n- Check JQL syntax\n- Verify project key exists\n- Check for special characters in JQL (escape with backslash)\n\n### Rate Limits\n\nJira Cloud has rate limits. For large imports:\n- Add delays between requests (not implemented yet)\n- Import in batches using JQL date ranges\n- Use the `--file` option with a manual export\n\n## API Rate Limits\n\n- **Jira Cloud**: ~100 requests/minute (varies by plan)\n- **Jira Server/DC**: Depends on configuration\n\nThis script fetches 100 issues per request, so a 1000-issue project requires ~10 API calls.\n\n## Jira API v3 Notes\n\nThis script uses the Jira REST API v3 `/rest/api/3/search/jql` endpoint. The older `/rest/api/3/search` endpoint was deprecated (returns HTTP 410 Gone). Two important considerations:\n\n### Explicit Field Selection\n\nThe v3 search endpoint returns only issue IDs by default. The script explicitly requests `fields=*all` to retrieve all fields. Without this parameter, you'll get issues with no title, description, or other metadata.\n\n### Atlassian Document Format (ADF)\n\nJira API v3 returns rich text fields (like `description`) in Atlassian Document Format - a JSON structure rather than plain text or HTML. The script automatically converts ADF to markdown:\n\n**ADF input:**\n```json\n{\"type\": \"doc\", \"content\": [{\"type\": \"heading\", \"attrs\": {\"level\": 3}, \"content\": [{\"type\": \"text\", \"text\": \"Overview\"}]}]}\n```\n\n**Converted output:**\n```markdown\n### Overview\n```\n\nSupported ADF node types: paragraph, heading, bulletList, orderedList, listItem, codeBlock, blockquote, hardBreak, rule, inlineCard, mention, and text nodes.\n\n---\n\n# Export: jsonl2jira.py\n\nPush bd issues to Jira.\n\n## Export Quick Start\n\n```bash\n# Export all issues (create new, update existing)\nbd export | python jsonl2jira.py --from-config\n\n# Create only (don't update existing Jira issues)\nbd export | python jsonl2jira.py --from-config --create-only\n\n# Dry run (preview what would happen)\nbd export | python jsonl2jira.py --from-config --dry-run\n\n# Auto-update bd with new external_refs\nbd export | python jsonl2jira.py --from-config --update-refs\n```\n\n## Export Modes\n\n### Create Only\n\nOnly create new Jira issues for bd issues that don't have an `external_ref`:\n\n```bash\nbd export | python jsonl2jira.py --from-config --create-only\n```\n\n### Create and Update\n\nCreate new issues AND update existing ones (matched by `external_ref`):\n\n```bash\nbd export | python jsonl2jira.py --from-config\n```\n\n### Dry Run\n\nPreview what would happen without making any changes:\n\n```bash\nbd export | python jsonl2jira.py --from-config --dry-run\n```\n\n## Workflow Transitions\n\nJira often requires workflow transitions to change issue status (you can't just set `status=Done`). The export script automatically:\n\n1. Fetches available transitions for each issue\n2. Finds a transition that leads to the target status\n3. Executes the transition\n\nIf no valid transition is found, the status change is skipped with a warning.\n\n## Reverse Field Mappings\n\nFor export, you need mappings from bd â†’ Jira (reverse of import):\n\n```bash\n# Status: bd status -> Jira status name\nbd config set jira.reverse_status_map.open \"To Do\"\nbd config set jira.reverse_status_map.in_progress \"In Progress\"\nbd config set jira.reverse_status_map.blocked \"Blocked\"\nbd config set jira.reverse_status_map.closed \"Done\"\n\n# Type: bd type -> Jira issue type name\nbd config set jira.reverse_type_map.bug \"Bug\"\nbd config set jira.reverse_type_map.feature \"Story\"\nbd config set jira.reverse_type_map.task \"Task\"\nbd config set jira.reverse_type_map.epic \"Epic\"\nbd config set jira.reverse_type_map.chore \"Task\"\n\n# Priority: bd priority (0-4) -> Jira priority name\nbd config set jira.reverse_priority_map.0 \"Highest\"\nbd config set jira.reverse_priority_map.1 \"High\"\nbd config set jira.reverse_priority_map.2 \"Medium\"\nbd config set jira.reverse_priority_map.3 \"Low\"\nbd config set jira.reverse_priority_map.4 \"Lowest\"\n```\n\nIf not configured, sensible defaults are used.\n\n## Updating external_ref\n\nAfter creating a Jira issue, you'll want to link it back to the bd issue:\n\n```bash\n# Option 1: Auto-update with --update-refs flag\nbd export | python jsonl2jira.py --from-config --update-refs\n\n# Option 2: Manual update from script output\nbd export | python jsonl2jira.py --from-config | while read line; do\n  bd_id=$(echo \"$line\" | jq -r '.bd_id')\n  ext_ref=$(echo \"$line\" | jq -r '.external_ref')\n  bd update \"$bd_id\" --external-ref=\"$ext_ref\"\ndone\n```\n\n## Export Examples\n\n### Example 1: Initial Export to Jira\n\n```bash\n# First, export all open issues\nbd list --status open --json | python jsonl2jira.py --from-config --update-refs\n\n# Now those issues have external_ref set\nbd list --status open\n```\n\n### Example 2: Sync Changes Back to Jira\n\n```bash\n# Export issues modified today\nbd list --json | python jsonl2jira.py --from-config\n```\n\n### Example 3: Preview Before Export\n\n```bash\n# See what would happen\nbd export | python jsonl2jira.py --from-config --dry-run\n\n# If it looks good, run for real\nbd export | python jsonl2jira.py --from-config --update-refs\n```\n\n## Export Limitations\n\n- **Assignee**: Not set (requires Jira account ID lookup)\n- **Dependencies**: Not synced to Jira issue links\n- **Comments**: Not exported\n- **Custom fields**: design, acceptance_criteria, notes not exported\n- **Attachments**: Not exported\n\n## Bidirectional Sync Workflow\n\nFor ongoing synchronization between Jira and bd:\n\n```bash\n# 1. Pull changes from Jira\npython jira2jsonl.py --from-config --jql \"project=PROJ AND updated >= -1d\" | bd import\n\n# 2. Do local work in bd\nbd update bd-xxx --status in_progress\n# ... work ...\nbd close bd-xxx\n\n# 3. Push changes to Jira\nbd export | python jsonl2jira.py --from-config\n\n# 4. Repeat daily/weekly\n```\n\n## See Also\n\n- [bd README](../../README.md) - Main documentation\n- [GitHub Import Example](../github-import/) - Similar import for GitHub Issues\n- [CONFIG.md](../../docs/CONFIG.md) - Configuration documentation\n- [Jira REST API docs](https://developer.atlassian.com/cloud/jira/platform/rest/v2/)\n",
        "examples/library-usage/README.md": "# Beads Library Usage Example\n\nThis example demonstrates using Beads as a Go library in external projects (like VC).\n\n## Why Use Beads as a Library?\n\nInstead of spawning `bd` CLI processes:\n- âœ… **Direct API access** - Call functions directly instead of parsing JSON output\n- âœ… **Type safety** - Compile-time checking of types and interfaces\n- âœ… **Performance** - No process spawn overhead\n- âœ… **Transactions** - Access to database transactions for complex operations\n- âœ… **Shared database** - Multiple components can use same database connection\n- âœ… **Error handling** - Proper Go error types instead of parsing stderr\n\n## Installation\n\nIn your Go project:\n\n```bash\ngo get github.com/steveyegge/beads@latest\n```\n\n## Basic Usage\n\n```go\npackage main\n\nimport (\n    \"context\"\n    \"log\"\n    \n    \"github.com/steveyegge/beads\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    \n    // Find and open database\n    dbPath := beads.FindDatabasePath()\n    store, err := beads.NewSQLiteStorage(dbPath)\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer store.Close()\n    \n    // Get ready work\n    ready, err := store.GetReadyWork(ctx, beads.WorkFilter{\n        Status: beads.StatusOpen,\n        Limit: 10,\n    })\n    if err != nil {\n        log.Fatal(err)\n    }\n    \n    // Process ready issues...\n}\n```\n\n## Running This Example\n\n```bash\n# From this directory\ncd examples/library-usage\n\n# Make sure there's a Beads database\nbd init --prefix demo\n\n# Run the example\ngo run main.go\n```\n\n## Available Operations\n\nThe `beads.Storage` interface provides:\n\n### Issues\n- `CreateIssue(ctx, issue, actor)` - Create a new issue\n- `CreateIssues(ctx, issues, actor)` - Batch create issues\n- `GetIssue(ctx, id)` - Get issue by ID\n- `UpdateIssue(ctx, id, updates, actor)` - Update issue fields\n- `CloseIssue(ctx, id, reason, actor)` - Close an issue\n- `SearchIssues(ctx, query, filter)` - Search with filters\n\n### Dependencies\n- `AddDependency(ctx, dep, actor)` - Add dependency between issues\n- `RemoveDependency(ctx, issueID, dependsOnID, actor)` - Remove dependency\n- `GetDependencies(ctx, issueID)` - Get what this issue depends on\n- `GetDependents(ctx, issueID)` - Get what depends on this issue\n- `GetDependencyTree(ctx, issueID, maxDepth, showAllPaths)` - Visualize tree\n\n### Labels\n- `AddLabel(ctx, issueID, label, actor)` - Add label to issue\n- `RemoveLabel(ctx, issueID, label, actor)` - Remove label\n- `GetLabels(ctx, issueID)` - Get all labels for an issue\n- `GetIssuesByLabel(ctx, label)` - Find issues with label\n\n### Ready Work & Blocking\n- `GetReadyWork(ctx, filter)` - Find issues with no blockers\n- `GetBlockedIssues(ctx)` - Find blocked issues with blocker info\n- `GetEpicsEligibleForClosure(ctx)` - Find completable epics\n\n### Comments & Events\n- `AddIssueComment(ctx, issueID, author, text)` - Add comment\n- `GetIssueComments(ctx, issueID)` - Get all comments\n- `GetEvents(ctx, issueID, limit)` - Get audit trail\n\n### Statistics\n- `GetStatistics(ctx)` - Get aggregate metrics\n\n## Types\n\nAll types are exported via the `beads` package:\n\n```go\n// Core types\nbeads.Issue\nbeads.Status (Open, InProgress, Closed, Blocked)\nbeads.IssueType (Bug, Feature, Task, Epic, Chore)\nbeads.Priority (0-4)\n\n// Relationships\nbeads.Dependency\nbeads.DependencyType (Blocks, Related, ParentChild, DiscoveredFrom)\n\n// Metadata\nbeads.Label\nbeads.Comment\nbeads.Event\n\n// Queries\nbeads.IssueFilter\nbeads.WorkFilter\nbeads.BlockedIssue\nbeads.EpicStatus\nbeads.Statistics\n```\n\n## VC Integration Example\n\nFor VC (VibeCoder), the integration would look like:\n\n```go\n// In VC's storage layer\ntype VCStorage struct {\n    beads beads.Storage\n}\n\nfunc NewVCStorage(dbPath string) (*VCStorage, error) {\n    store, err := beads.NewSQLiteStorage(dbPath)\n    if err != nil {\n        return nil, err\n    }\n    \n    return &VCStorage{beads: store}, nil\n}\n\n// Claim ready work for executor\nfunc (s *VCStorage) ClaimWork(ctx context.Context, executorID string) (*beads.Issue, error) {\n    ready, err := s.beads.GetReadyWork(ctx, beads.WorkFilter{\n        Status: beads.StatusOpen,\n        Limit: 1,\n    })\n    if err != nil {\n        return nil, err\n    }\n    \n    if len(ready) == 0 {\n        return nil, nil // No work available\n    }\n    \n    issue := ready[0]\n    \n    // Claim it\n    updates := map[string]interface{}{\n        \"status\": beads.StatusInProgress,\n        \"assignee\": executorID,\n    }\n    \n    if err := s.beads.UpdateIssue(ctx, issue.ID, updates, executorID); err != nil {\n        return nil, err\n    }\n    \n    return issue, nil\n}\n```\n\n## Best Practices\n\n1. **Context** - Always pass `context.Context` for cancellation support\n2. **Actor** - Provide meaningful actor strings for audit trail\n3. **Error handling** - Check all errors; database operations can fail\n4. **Close** - Always `defer store.Close()` after opening\n5. **Transactions** - For complex multi-step operations, consider using the underlying database connection directly\n\n## See Also\n\n- [EXTENDING.md](../../EXTENDING.md) - Detailed extension guide\n- [beads.go](../../beads.go) - Public API source\n- [internal/storage/storage.go](../../internal/storage/storage.go) - Storage interface\n",
        "examples/linear-workflow/README.md": "# Linear Integration for bd\n\nBidirectional synchronization between Linear and bd (beads) using the built-in `bd linear` commands.\n\n## Overview\n\nThe Linear integration provides:\n\n- **Pull**: Import issues from Linear into bd\n- **Push**: Export bd issues to Linear\n- **Bidirectional Sync**: Two-way sync with conflict resolution\n- **Incremental Sync**: Only sync issues changed since last sync\n- **Configurable Mappings**: Customize priority, state, label, and relation mappings\n\n## Quick Start\n\n### 1. Get Linear Credentials\n\n1. **API Key**: Go to Linear â†’ Settings â†’ API â†’ Personal API keys â†’ Create key\n2. **Team ID**: Go to Linear â†’ Settings â†’ General â†’ find the Team ID (UUID format)\n\n### 2. Configure bd\n\n```bash\n# Set API key (or use LINEAR_API_KEY environment variable)\nbd config set linear.api_key \"lin_api_YOUR_API_KEY_HERE\"\n\n# Set team ID\nbd config set linear.team_id \"YOUR_TEAM_UUID\"\n```\n\n### 3. Sync with Linear\n\n```bash\n# Check configuration status\nbd linear status\n\n# Pull issues from Linear\nbd linear sync --pull\n\n# Push local issues to Linear\nbd linear sync --push\n\n# Full bidirectional sync (pull, resolve conflicts, push)\nbd linear sync\n```\n\n## Authentication\n\n### API Key\n\nLinear uses Personal API Keys for authentication. Create one at:\n**Linear â†’ Settings â†’ API â†’ Personal API keys**\n\nStore securely:\n\n```bash\n# Option 1: bd config (stored in database)\nbd config set linear.api_key \"lin_api_...\"\n\n# Option 2: Environment variable\nexport LINEAR_API_KEY=\"lin_api_...\"\n```\n\n### Team ID\n\nFind your Team ID in Linear:\n- **Settings â†’ General** â†’ Look for Team ID\n- Or extract from URLs: `https://linear.app/YOUR_TEAM/...` â†’ Go to team settings\n\n## Sync Modes\n\n### Pull Only (Linear â†’ bd)\n\nImport issues from Linear without pushing local changes:\n\n```bash\nbd linear sync --pull\n\n# Filter by state\nbd linear sync --pull --state open    # Only open issues\nbd linear sync --pull --state closed  # Only closed issues\nbd linear sync --pull --state all     # All issues (default)\n```\n\n### Push Only (bd â†’ Linear)\n\nExport local issues to Linear without pulling:\n\n```bash\nbd linear sync --push\n\n# Create only (don't update existing Linear issues)\nbd linear sync --push --create-only\n\n# Disable automatic external_ref update\nbd linear sync --push --update-refs=false\n```\n\n### Bidirectional Sync\n\nFull two-way sync with conflict detection and resolution:\n\n```bash\n# Default: newer timestamp wins conflicts\nbd linear sync\n\n# Always prefer local version on conflicts\nbd linear sync --prefer-local\n\n# Always prefer Linear version on conflicts\nbd linear sync --prefer-linear\n```\n\n### Dry Run\n\nPreview what would happen without making changes:\n\n```bash\nbd linear sync --dry-run\n```\n\n## Data Mapping\n\n### Priority Mapping\n\nLinear and Beads use different priority semantics:\n\n| Linear | Meaning | Beads | Meaning |\n|--------|---------|-------|---------|\n| 0 | No priority | 4 | Backlog |\n| 1 | Urgent | 0 | Critical |\n| 2 | High | 1 | High |\n| 3 | Medium | 2 | Medium |\n| 4 | Low | 3 | Low |\n\n**Default mapping** (Linear â†’ Beads):\n- 0 (no priority) â†’ 4 (backlog)\n- 1 (urgent) â†’ 0 (critical)\n- 2 (high) â†’ 1 (high)\n- 3 (medium) â†’ 2 (medium)\n- 4 (low) â†’ 3 (low)\n\n**Custom mappings:**\n\n```bash\n# Override default mappings\nbd config set linear.priority_map.0 2    # No priority -> Medium (instead of Backlog)\nbd config set linear.priority_map.1 1    # Urgent -> High (instead of Critical)\n```\n\n### State Mapping\n\nMap Linear workflow states to bd statuses:\n\n| Linear State Type | Beads Status |\n|-------------------|--------------|\n| backlog | open |\n| unstarted | open |\n| started | in_progress |\n| completed | closed |\n| canceled | closed |\n\n**Custom state mappings** (for custom workflow states):\n\n```bash\n# Map by state type\nbd config set linear.state_map.started in_progress\n\n# Map by state name (for custom workflow states)\nbd config set linear.state_map.in_review in_progress\nbd config set linear.state_map.blocked blocked\nbd config set linear.state_map.on_hold blocked\nbd config set linear.state_map.testing in_progress\nbd config set linear.state_map.deployed closed\n```\n\n### Label to Issue Type\n\nInfer bd issue type from Linear labels:\n\n| Linear Label | Beads Type |\n|--------------|------------|\n| bug, defect | bug |\n| feature, enhancement | feature |\n| epic | epic |\n| chore, maintenance | chore |\n| task | task |\n\n**Custom label mappings:**\n\n```bash\nbd config set linear.label_type_map.incident bug\nbd config set linear.label_type_map.improvement feature\nbd config set linear.label_type_map.tech_debt chore\nbd config set linear.label_type_map.story feature\n```\n\n### Relation Mapping\n\nMap Linear relations to bd dependencies:\n\n| Linear Relation | Beads Dependency |\n|-----------------|------------------|\n| blocks | blocks |\n| blockedBy | blocks (inverted) |\n| duplicate | duplicates |\n| related | related |\n| (parent) | parent-child |\n\n**Custom relation mappings:**\n\n```bash\nbd config set linear.relation_map.causes discovered-from\nbd config set linear.relation_map.duplicate related\n```\n\n## Conflict Resolution\n\nConflicts occur when both local and Linear versions are modified since the last sync.\n\n### Timestamp-based (Default)\n\nThe newer version wins:\n\n```bash\nbd linear sync  # Newer timestamp wins\n```\n\n### Prefer Local\n\nLocal bd version always wins:\n\n```bash\nbd linear sync --prefer-local\n```\n\nUse when:\n- Local is your source of truth\n- You've made deliberate changes locally\n\n### Prefer Linear\n\nLinear version always wins:\n\n```bash\nbd linear sync --prefer-linear\n```\n\nUse when:\n- Linear is your source of truth\n- You want to accept team changes\n\n## Workflows\n\n### Workflow 1: Initial Import from Linear\n\nFirst-time import of existing Linear issues:\n\n```bash\n# Configure credentials\nbd config set linear.api_key \"lin_api_...\"\nbd config set linear.team_id \"team-uuid\"\n\n# Check status\nbd linear status\n\n# Import all issues\nbd linear sync --pull\n\n# See what was imported\nbd stats\nbd list --json\n```\n\n### Workflow 2: Daily Sync\n\nRegular synchronization:\n\n```bash\n# Pull latest from Linear (incremental since last sync)\nbd linear sync --pull\n\n# Do local work\nbd update bd-123 --status in_progress\n# ... work ...\nbd close bd-123 --reason \"Fixed\"\n\n# Push changes to Linear\nbd linear sync --push\n\n# Or do full bidirectional sync\nbd linear sync\n```\n\n### Workflow 3: Create Local Issues, Push to Linear\n\nCreate issues locally and sync to Linear:\n\n```bash\n# Create issue locally\nbd create \"Fix authentication bug\" -t bug -p 1\n\n# Push to Linear (creates new Linear issue, updates external_ref)\nbd linear sync --push\n\n# Verify\nbd show bd-abc  # Should have external_ref pointing to Linear\n```\n\n### Workflow 4: Migrate to bd\n\nFull migration from Linear to bd:\n\n```bash\n# Import all issues\nbd linear sync --pull --state all\n\n# Preview import\nbd stats\n\n# Continue using bd locally, push updates back to Linear\nbd linear sync  # Regular bidirectional sync\n```\n\n### Workflow 5: Read-Only Linear Mirror\n\nMirror Linear issues locally without pushing back:\n\n```bash\n# Only ever pull, never push\nbd linear sync --pull\n\n# Set up a cron job or alias\nalias bd-mirror=\"bd linear sync --pull\"\n```\n\n## Status & Debugging\n\n### Check Sync Status\n\n```bash\nbd linear status\n```\n\nShows:\n- Configuration status (API key, team ID)\n- Last sync timestamp\n- Issues with Linear links\n- Issues pending push (local only)\n\n### JSON Output\n\n```bash\nbd linear status --json\nbd linear sync --json\n```\n\n### Verbose Output\n\nThe sync command shows progress:\n- Number of issues pulled/pushed\n- Conflicts detected and resolved\n- Errors and warnings\n\n## Configuration Reference\n\nAll configuration keys for Linear integration:\n\n```bash\n# Required\nlinear.api_key          # Linear API key (or LINEAR_API_KEY env var)\nlinear.team_id          # Linear team UUID\n\n# Automatic (set by bd)\nlinear.last_sync        # ISO8601 timestamp of last sync\n\n# ID generation (optional)\nlinear.id_mode          # hash (default) or db (let bd generate IDs)\nlinear.hash_length      # Hash length 3-8 (default: 6)\n\n# Priority mapping (Linear 0-4 to Beads 0-4)\nlinear.priority_map.0   # No priority -> ? (default: 4/backlog)\nlinear.priority_map.1   # Urgent -> ? (default: 0/critical)\nlinear.priority_map.2   # High -> ? (default: 1/high)\nlinear.priority_map.3   # Medium -> ? (default: 2/medium)\nlinear.priority_map.4   # Low -> ? (default: 3/low)\n\n# State mapping (Linear state type/name to Beads status)\nlinear.state_map.backlog     # (default: open)\nlinear.state_map.unstarted   # (default: open)\nlinear.state_map.started     # (default: in_progress)\nlinear.state_map.completed   # (default: closed)\nlinear.state_map.canceled    # (default: closed)\nlinear.state_map.<custom>    # Map custom state names\n\n# Label to issue type mapping\nlinear.label_type_map.bug         # (default: bug)\nlinear.label_type_map.defect      # (default: bug)\nlinear.label_type_map.feature     # (default: feature)\nlinear.label_type_map.enhancement # (default: feature)\nlinear.label_type_map.epic        # (default: epic)\nlinear.label_type_map.chore       # (default: chore)\nlinear.label_type_map.maintenance # (default: chore)\nlinear.label_type_map.task        # (default: task)\nlinear.label_type_map.<custom>    # Map custom labels\n\n# Relation mapping (Linear relation type to Beads dependency type)\nlinear.relation_map.blocks    # (default: blocks)\nlinear.relation_map.blockedBy # (default: blocks)\nlinear.relation_map.duplicate # (default: duplicates)\nlinear.relation_map.related   # (default: related)\n```\n\n## Troubleshooting\n\n### \"Linear API key not configured\"\n\nSet the API key:\n\n```bash\nbd config set linear.api_key \"lin_api_YOUR_KEY\"\n# Or\nexport LINEAR_API_KEY=\"lin_api_YOUR_KEY\"\n```\n\n### \"Linear team ID not configured\"\n\nSet the team ID:\n\n```bash\nbd config set linear.team_id \"YOUR_TEAM_UUID\"\n```\n\n### \"GraphQL errors: Not authorized\"\n\n- Verify your API key is correct\n- Check that the API key has access to the team\n- Ensure the key hasn't been revoked\n\n### \"Rate limited\"\n\nLinear has API rate limits. The client automatically retries with exponential backoff:\n- 3 retries with increasing delays\n- If still failing, wait and retry later\n\n### \"Conflict detection failed\"\n\n- Check network connectivity\n- Verify API key permissions\n- Check `bd linear status` for configuration issues\n\n### Sync seems slow\n\nFor large projects, initial sync fetches all issues. Subsequent syncs are incremental (only issues changed since `linear.last_sync`).\n\n## Limitations\n\n- **Single team**: Sync is configured per-team (one team_id per bd project)\n- **No attachments**: Attachments are not synced\n- **No comments**: Comments are not synced (only description)\n- **Custom fields**: Linear custom fields are not mapped\n- **Projects**: Linear projects are not mapped (use labels for categorization)\n- **Cycles**: Linear cycles/sprints are not mapped\n\n## See Also\n\n- [CONFIG.md](../../docs/CONFIG.md) - Full configuration documentation\n- [Jira Import Example](../jira-import/) - Similar integration for Jira\n- [Linear GraphQL API](https://developers.linear.app/docs/graphql/working-with-the-graphql-api)\n\n---\n\n## Example Session\n\n```bash\n# Initial setup\n$ bd init --quiet\n$ bd config set linear.api_key \"lin_api_abc123...\"\n$ bd config set linear.team_id \"team-uuid-456\"\n\n# Check status\n$ bd linear status\nLinear Sync Status\n==================\n\nTeam ID:      team-uuid-456\nAPI Key:      lin_...c123\nLast Sync:    Never\n\nTotal Issues: 0\nWith Linear:  0\nLocal Only:   0\n\n# Pull from Linear\n$ bd linear sync --pull\nâ†’ Pulling issues from Linear...\n  Full sync (no previous sync timestamp)\nâœ“ Pulled 47 issues (47 created, 0 updated)\n\nâœ“ Linear sync complete\n\n# Check what we got\n$ bd stats\nIssues: 47 (42 open, 5 closed)\nTypes:  23 task, 15 bug, 7 feature, 2 epic\n\n# Create a local issue\n$ bd create \"New bug from testing\" -t bug -p 1\nCreated: bd-a1b2c3\n\n# Push to Linear\n$ bd linear sync --push\nâ†’ Pushing issues to Linear...\n  Created: bd-a1b2c3 -> TEAM-148\nâœ“ Pushed 1 issues (1 created, 0 updated)\n\nâœ“ Linear sync complete\n\n# Full bidirectional sync\n$ bd linear sync\nâ†’ Pulling issues from Linear...\n  Incremental sync since 2025-01-17 10:30:00\nâœ“ Pulled 3 issues (0 created, 3 updated)\nâ†’ Pushing issues to Linear...\nâœ“ Pushed 2 issues (0 created, 2 updated)\n\nâœ“ Linear sync complete\n```\n",
        "examples/markdown-to-jsonl/README.md": "# Markdown to JSONL Converter\n\nConvert markdown planning documents into `bd` issues.\n\n## Overview\n\nThis example shows how to bridge the gap between markdown planning docs and tracked issues, without adding complexity to the `bd` core tool.\n\nThe converter script (`md2jsonl.py`) parses markdown files and outputs JSONL that can be imported into `bd`.\n\n## Features\n\n- âœ… **YAML Frontmatter** - Extract metadata (priority, type, assignee)\n- âœ… **Headings as Issues** - Each H1/H2 becomes an issue\n- âœ… **Task Lists** - Markdown checklists become sub-issues\n- âœ… **Dependency Parsing** - Extract \"blocks: bd-10\" references\n- âœ… **Customizable** - Modify the script for your conventions\n\n## Usage\n\n### Basic conversion\n\n```bash\npython md2jsonl.py feature.md | bd import\n```\n\n### Save to file first\n\n```bash\npython md2jsonl.py feature.md > issues.jsonl\nbd import -i issues.jsonl\n```\n\n### Preview before importing\n\n```bash\npython md2jsonl.py feature.md | jq .\n```\n\n## Markdown Format\n\n### Frontmatter (Optional)\n\n```markdown\n---\npriority: 1\ntype: feature\nassignee: alice\n---\n```\n\n### Headings\n\nEach heading becomes an issue:\n\n```markdown\n# Main Feature\n\nDescription of the feature...\n\n## Sub-task 1\n\nDetails about sub-task...\n\n## Sub-task 2\n\nMore details...\n```\n\n### Task Lists\n\nTask lists are converted to separate issues:\n\n```markdown\n## Setup Tasks\n\n- [ ] Install dependencies\n- [x] Configure database\n- [ ] Set up CI/CD\n```\n\nCreates 3 issues (second one marked as closed).\n\n### Dependencies\n\nReference other issues in the description:\n\n```markdown\n## Implement API\n\nThis task requires the database schema to be ready first.\n\nDependencies:\n- blocks: bd-5\n- related: bd-10, bd-15\n```\n\nThe script extracts these and creates dependency records.\n\n## Example\n\nSee `example-feature.md` for a complete example.\n\n```bash\n# Convert the example\npython md2jsonl.py example-feature.md > example-issues.jsonl\n\n# View the output\ncat example-issues.jsonl | jq .\n\n# Import into bd\nbd import -i example-issues.jsonl\n```\n\n## Customization\n\nThe script is intentionally simple so you can customize it for your needs:\n\n1. **Different heading levels** - Modify which headings become issues (H1 only? H1-H3?)\n2. **Custom metadata** - Parse additional frontmatter fields\n3. **Labels** - Extract hashtags or keywords as labels\n4. **Epic detection** - Top-level headings become epics\n5. **Issue templates** - Map different markdown structures to issue types\n\n## Limitations\n\nThis is a simple example, not a production tool:\n\n- Basic YAML parsing (no nested structures)\n- Simple dependency extraction (regex-based)\n- No validation of referenced issue IDs\n- Doesn't handle all markdown edge cases\n\nFor production use, you might want to:\n- Use a proper YAML parser (`pip install pyyaml`)\n- Use a markdown parser (`pip install markdown` or `python-markdown2`)\n- Add validation and error handling\n- Support more dependency formats\n\n## Philosophy\n\nThis example demonstrates the **lightweight extension pattern**:\n\n- âœ… Keep `bd` core focused and minimal\n- âœ… Let users customize for their workflows\n- âœ… Use existing import infrastructure\n- âœ… Easy to understand and modify\n\nRather than adding markdown support to `bd` core (800+ LOC + dependencies + maintenance), we provide a simple converter that users can adapt.\n\n## Contributing\n\nHave improvements? Found a bug? This is just an example, but contributions are welcome!\n\nConsider:\n- Better error messages\n- More markdown patterns\n- Integration with popular markdown formats\n- Support for GFM (GitHub Flavored Markdown) extensions\n\n## See Also\n\n- [bd README](../../README.md) - Main documentation\n- [Python Agent Example](../python-agent/) - Full agent workflow\n- [JSONL Format](../../TEXT_FORMATS.md) - Understanding bd's JSONL structure\n",
        "examples/monitor-webui/README.md": "# Monitor WebUI - Real-time Issue Tracking Dashboard\n\nA standalone web-based monitoring interface for beads that provides real-time issue tracking through a clean, responsive web UI.\n\n## Overview\n\nThe Monitor WebUI is a separate runtime that connects to the beads daemon via RPC to provide:\n\n- **Real-time updates** via WebSocket connections\n- **Responsive design** with desktop table view and mobile card view\n- **Issue filtering** by status and priority\n- **Statistics dashboard** showing issue counts by status\n- **Detailed issue views** with full metadata\n- **Clean, modern UI** styled with Milligram CSS\n\n## Architecture\n\nThe Monitor WebUI demonstrates how to build custom interfaces on top of beads using:\n\n- **RPC Protocol**: Connects to the daemon's Unix socket for database operations\n- **WebSocket Broadcasting**: Polls mutation events and broadcasts to connected clients\n- **Embedded Web Assets**: HTML, CSS, and JavaScript served from the binary\n- **Standalone Binary**: Runs independently from the `bd` CLI\n\n## Prerequisites\n\nBefore running the monitor, you must have:\n\n1. A beads database initialized (run `bd init` in your project)\n2. The beads daemon running (run `bd daemon`)\n\n## Building\n\nFrom this directory:\n\n```bash\ngo build\n```\n\nOr using bun (if available):\n\n```bash\nbun run go build\n```\n\nThis creates a `monitor-webui` binary in the current directory.\n\n## Usage\n\n### Basic Usage\n\nStart the monitor on default port 8080:\n\n```bash\n./monitor-webui\n```\n\nThen open your browser to http://localhost:8080\n\n### Custom Port\n\nStart on a different port:\n\n```bash\n./monitor-webui -port 3000\n```\n\n### Bind to All Interfaces\n\nTo access from other machines on your network:\n\n```bash\n./monitor-webui -host 0.0.0.0 -port 8080\n```\n\n### Custom Database Path\n\nIf your database is not in the current directory:\n\n```bash\n./monitor-webui -db /path/to/your/beads.db\n```\n\n### Custom Socket Path\n\nIf you need to specify a custom daemon socket:\n\n```bash\n./monitor-webui -socket /path/to/beads.db.sock\n```\n\n## Command-Line Flags\n\n- `-port` - Port for web server (default: 8080)\n- `-host` - Host to bind to (default: \"localhost\")\n- `-db` - Path to beads database (optional, will auto-detect)\n- `-socket` - Path to daemon socket (optional, will auto-detect)\n\n## API Endpoints\n\nThe monitor exposes several HTTP endpoints:\n\n### Web UI\n- `GET /` - Main HTML interface\n- `GET /static/*` - Static assets (CSS, JavaScript)\n\n### REST API\n- `GET /api/issues` - List all issues as JSON\n- `GET /api/issues/:id` - Get specific issue details\n- `GET /api/ready` - Get ready work (no blockers)\n- `GET /api/stats` - Get issue statistics\n\n### WebSocket\n- `WS /ws` - WebSocket endpoint for real-time updates\n\n## Features\n\n### Real-time Updates\n\nThe monitor polls the daemon every 2 seconds for mutation events and broadcasts them to all connected WebSocket clients. This provides instant updates when issues are created, modified, or closed.\n\n### Responsive Design\n\n- **Desktop**: Full table view with sortable columns\n- **Mobile**: Card-based view optimized for small screens\n- **Tablet**: Adapts to medium screen sizes\n\n### Filtering\n\n- **Status Filter**: Multi-select for Open, In Progress, and Closed\n- **Priority Filter**: Single-select for P1, P2, P3, or All\n\n### Statistics\n\nReal-time statistics showing:\n- Total issues\n- In-progress issues\n- Open issues\n- Closed issues\n\n## Development\n\n### Project Structure\n\n```\nmonitor-webui/\nâ”œâ”€â”€ main.go              # Main application with HTTP server and RPC client\nâ”œâ”€â”€ go.mod               # Go module dependencies\nâ”œâ”€â”€ go.sum               # (generated) Dependency checksums\nâ”œâ”€â”€ README.md            # This file\nâ””â”€â”€ web/                 # Web assets (embedded in binary)\n    â”œâ”€â”€ index.html       # Main HTML page\n    â””â”€â”€ static/\n        â”œâ”€â”€ css/\n        â”‚   â””â”€â”€ styles.css   # Custom styles\n        â””â”€â”€ js/\n            â””â”€â”€ app.js       # JavaScript application logic\n```\n\n### Modifying the Web Assets\n\nThe HTML, CSS, and JavaScript files are embedded into the binary using Go's `embed` package. After making changes to files in the `web/` directory, rebuild the binary to see your changes.\n\n### Extending the API\n\nTo add new API endpoints:\n\n1. Define a new handler function in `main.go`\n2. Register it with `http.HandleFunc()` in the `main()` function\n3. Use `daemonClient` to make RPC calls to the daemon\n4. Return JSON responses using `json.NewEncoder(w).Encode()`\n\n## Deployment\n\n### As a Standalone Service\n\nYou can run the monitor as a systemd service. Example service file:\n\n```ini\n[Unit]\nDescription=Beads Monitor WebUI\nAfter=network.target\n\n[Service]\nType=simple\nUser=youruser\nWorkingDirectory=/path/to/your/project\nExecStart=/path/to/monitor-webui -host 0.0.0.0 -port 8080\nRestart=always\nRestartSec=10\n\n[Install]\nWantedBy=multi-user.target\n```\n\nSave as `/etc/systemd/system/beads-monitor.service` and enable:\n\n```bash\nsudo systemctl enable beads-monitor\nsudo systemctl start beads-monitor\n```\n\n### Behind a Reverse Proxy\n\nExample nginx configuration:\n\n```nginx\nserver {\n    listen 80;\n    server_name monitor.example.com;\n\n    location / {\n        proxy_pass http://localhost:8080;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n}\n```\n\n## Troubleshooting\n\n### \"No beads database found\"\n\nMake sure you've initialized a beads database with `bd init` or specify the database path with `-db`.\n\n### \"Daemon is not running\"\n\nThe monitor requires the daemon to avoid SQLite locking conflicts. Start the daemon first:\n\n```bash\nbd daemon\n```\n\n### WebSocket disconnects frequently\n\nCheck if there's a reverse proxy or firewall between the client and server that might be closing idle connections. Consider adjusting timeout settings.\n\n### Port already in use\n\nIf port 8080 is already in use, specify a different port:\n\n```bash\n./monitor-webui -port 3001\n```\n\n## Security Considerations\n\n### Production Deployment\n\nWhen deploying to production:\n\n1. **Restrict Origins**: Update the `CheckOrigin` function in `main.go` to validate WebSocket origins\n2. **Use HTTPS**: Deploy behind a reverse proxy with TLS (nginx, Caddy, etc.)\n3. **Authentication**: Add authentication middleware if exposing publicly\n4. **Firewall**: Use firewall rules to restrict access to trusted networks\n\n### Current Security Model\n\nThe current implementation:\n- Allows WebSocket connections from any origin\n- Provides read-only access to issue data\n- Does not include authentication\n- Connects to local daemon socket only\n\nThis is appropriate for local development but requires additional security measures for production use.\n\n## License\n\nSame as the main beads project.\n",
        "examples/multi-phase-development/README.md": "# Multi-Phase Development Workflow Example\n\nThis example demonstrates how to use beads for large projects with multiple development phases (planning, MVP, iteration, polish).\n\n## Problem\n\nWhen building complex features, you want to:\n- **Phase 1:** Research and planning\n- **Phase 2:** Build MVP quickly\n- **Phase 3:** Iterate based on feedback\n- **Phase 4:** Polish and production-ready\n- Track discovered work at each phase\n- Keep priorities clear across phases\n\n## Solution\n\nUse beads epics and hierarchical issues to organize work by phase, with priority-based focus.\n\n## Setup\n\n```bash\n# Initialize beads in your project\ncd my-project\nbd init\n\n# Start daemon for auto-sync (optional)\nbd daemon --start --auto-commit --auto-push\n```\n\n## Phase 1: Research & Planning\n\nCreate the epic and initial planning issues:\n\n```bash\n# Create the main epic\nbd create \"Build real-time collaboration system\" -t epic -p 1\n# Returns: bd-a1b2c3\n\n# Plan the phases (hierarchical children)\nbd create \"Phase 1: Research WebSocket libraries\" -p 1\n# Auto-assigned: bd-a1b2c3.1\n\nbd create \"Phase 2: Build MVP (basic sync)\" -p 1\n# Auto-assigned: bd-a1b2c3.2\n\nbd create \"Phase 3: Add conflict resolution\" -p 2\n# Auto-assigned: bd-a1b2c3.3\n\nbd create \"Phase 4: Production hardening\" -p 3\n# Auto-assigned: bd-a1b2c3.4\n\n# Add blocking dependencies (phases must happen in order)\nbd dep add bd-a1b2c3.2 bd-a1b2c3.1 --type blocks\nbd dep add bd-a1b2c3.3 bd-a1b2c3.2 --type blocks\nbd dep add bd-a1b2c3.4 bd-a1b2c3.3 --type blocks\n```\n\n### Research Phase Tasks\n\n```bash\n# Add research tasks for Phase 1\nbd create \"Evaluate Socket.IO vs native WebSockets\" -p 1 \\\n  --deps discovered-from:bd-a1b2c3.1\n\nbd create \"Research operational transform vs CRDT\" -p 1 \\\n  --deps discovered-from:bd-a1b2c3.1\n\nbd create \"Document technical decisions\" -p 2 \\\n  --deps discovered-from:bd-a1b2c3.1\n\n# See what's ready to work on\nbd ready\n# Shows only Phase 1 tasks (nothing blocks them)\n```\n\n## Phase 2: Build MVP\n\nAfter completing Phase 1 research:\n\n```bash\n# Close Phase 1\nbd close bd-a1b2c3.1 --reason \"Research complete, chose Socket.IO + CRDT\"\n\n# Phase 2 is now unblocked\nbd ready\n# Shows Phase 2 and its tasks\n\n# Break down MVP work\nbd create \"Set up Socket.IO server\" -p 1 \\\n  --deps discovered-from:bd-a1b2c3.2\n\nbd create \"Implement basic CRDT for text\" -p 1 \\\n  --deps discovered-from:bd-a1b2c3.2\n\nbd create \"Build simple UI for testing\" -p 2 \\\n  --deps discovered-from:bd-a1b2c3.2\n\n# Start implementing\nbd update bd-xyz --status in_progress\n```\n\n### Discovered Work During MVP\n\nYou'll discover issues during implementation:\n\n```bash\n# Found a bug while implementing\nbd create \"Socket.IO disconnects on network change\" -t bug -p 1 \\\n  --deps discovered-from:bd-xyz\n\n# Found missing feature\nbd create \"Need reconnection logic\" -p 1 \\\n  --deps discovered-from:bd-xyz\n\n# Technical debt to address later\nbd create \"Refactor CRDT code for performance\" -p 3 \\\n  --deps discovered-from:bd-xyz\n```\n\n## Phase 3: Iteration\n\nAfter MVP is working:\n\n```bash\n# Close Phase 2\nbd close bd-a1b2c3.2 --reason \"MVP working, tested with 2 users\"\n\n# Phase 3 is now unblocked\nbd ready\n\n# Add iteration tasks\nbd create \"Handle concurrent edits properly\" -p 1 \\\n  --deps discovered-from:bd-a1b2c3.3\n\nbd create \"Add conflict indicators in UI\" -p 2 \\\n  --deps discovered-from:bd-a1b2c3.3\n\nbd create \"Test with 10+ concurrent users\" -p 1 \\\n  --deps discovered-from:bd-a1b2c3.3\n```\n\n### Feedback-Driven Discovery\n\n```bash\n# User testing reveals issues\nbd create \"Cursor positions get out of sync\" -t bug -p 0 \\\n  --deps discovered-from:bd-a1b2c3.3\n\nbd create \"Large documents cause lag\" -t bug -p 1 \\\n  --deps discovered-from:bd-a1b2c3.3\n\n# Feature requests\nbd create \"Add presence awareness (who's online)\" -p 2 \\\n  --deps discovered-from:bd-a1b2c3.3\n```\n\n## Phase 4: Production Hardening\n\nFinal polish before production:\n\n```bash\n# Close Phase 3\nbd close bd-a1b2c3.3 --reason \"Conflict resolution working well\"\n\n# Phase 4 is now unblocked\nbd ready\n\n# Add hardening tasks\nbd create \"Add error monitoring (Sentry)\" -p 1 \\\n  --deps discovered-from:bd-a1b2c3.4\n\nbd create \"Load test with 100 users\" -p 1 \\\n  --deps discovered-from:bd-a1b2c3.4\n\nbd create \"Security audit: XSS, injection\" -p 0 \\\n  --deps discovered-from:bd-a1b2c3.4\n\nbd create \"Write deployment runbook\" -p 2 \\\n  --deps discovered-from:bd-a1b2c3.4\n\nbd create \"Add metrics and dashboards\" -p 2 \\\n  --deps discovered-from:bd-a1b2c3.4\n```\n\n## Viewing Progress\n\n### See All Phases\n\n```bash\n# View the entire dependency tree\nbd dep tree bd-a1b2c3\n\n# Example output:\n# bd-a1b2c3 (epic) - Build real-time collaboration system\n# â”œâ”€ bd-a1b2c3.1 [CLOSED] - Phase 1: Research\n# â”‚  â”œâ”€ bd-abc [CLOSED] - Evaluate Socket.IO\n# â”‚  â”œâ”€ bd-def [CLOSED] - Research CRDT\n# â”‚  â””â”€ bd-ghi [CLOSED] - Document decisions\n# â”œâ”€ bd-a1b2c3.2 [CLOSED] - Phase 2: MVP\n# â”‚  â”œâ”€ bd-jkl [CLOSED] - Socket.IO server\n# â”‚  â”œâ”€ bd-mno [CLOSED] - Basic CRDT\n# â”‚  â””â”€ bd-pqr [IN_PROGRESS] - Testing UI\n# â”œâ”€ bd-a1b2c3.3 [OPEN] - Phase 3: Iteration\n# â”‚  â””â”€ (blocked by bd-a1b2c3.2)\n# â””â”€ bd-a1b2c3.4 [OPEN] - Phase 4: Hardening\n#    â””â”€ (blocked by bd-a1b2c3.3)\n```\n\n### Current Phase Status\n\n```bash\n# See only open issues\nbd list --status open\n\n# See current phase's ready work\nbd ready\n\n# See high-priority issues across all phases\nbd list --priority 0 --status open\nbd list --priority 1 --status open\n```\n\n### Progress Metrics\n\n```bash\n# Overall stats\nbd stats\n\n# Issues by phase\nbd list | grep \"Phase 1\"\nbd list | grep \"Phase 2\"\n```\n\n## Priority Management Across Phases\n\n### Dynamic Priority Adjustment\n\nAs you learn more, priorities change:\n\n```bash\n# Started as P2, but user feedback made it critical\nbd update bd-xyz --priority 0\n\n# Started as P1, but can wait until later phase\nbd update bd-abc --priority 3\n```\n\n### Focus on Current Phase\n\n```bash\n# See only P0-P1 issues (urgent work)\nbd ready | grep -E \"P0|P1\"\n\n# See backlog for future phases (P3-P4)\nbd list --priority 3 --status open\nbd list --priority 4 --status open\n```\n\n## Example: Full Workflow\n\n```bash\n# Day 1: Planning\nbd create \"Build auth system\" -t epic -p 1  # bd-a1b2\nbd create \"Phase 1: Research OAuth providers\" -p 1  # bd-a1b2.1\nbd create \"Phase 2: Implement OAuth flow\" -p 1  # bd-a1b2.2\nbd create \"Phase 3: Add session management\" -p 2  # bd-a1b2.3\nbd create \"Phase 4: Security audit\" -p 1  # bd-a1b2.4\nbd dep add bd-a1b2.2 bd-a1b2.1 --type blocks\nbd dep add bd-a1b2.3 bd-a1b2.2 --type blocks\nbd dep add bd-a1b2.4 bd-a1b2.3 --type blocks\n\n# Week 1: Phase 1 (Research)\nbd ready  # Shows Phase 1 tasks\nbd create \"Compare Auth0 vs Firebase\" -p 1 --deps discovered-from:bd-a1b2.1\nbd update bd-xyz --status in_progress\n# ... research complete ...\nbd close bd-a1b2.1 --reason \"Chose Auth0\"\n\n# Week 2-3: Phase 2 (Implementation)\nbd ready  # Now shows Phase 2 tasks\nbd create \"Set up Auth0 tenant\" -p 1 --deps discovered-from:bd-a1b2.2\nbd create \"Implement login callback\" -p 1 --deps discovered-from:bd-a1b2.2\nbd create \"Handle token refresh\" -p 1 --deps discovered-from:bd-a1b2.2\n# ... discovered bugs ...\nbd create \"Callback fails on Safari\" -t bug -p 0 --deps discovered-from:bd-abc\nbd close bd-a1b2.2 --reason \"OAuth flow working\"\n\n# Week 4: Phase 3 (Sessions)\nbd ready  # Shows Phase 3 tasks\nbd create \"Implement Redis session store\" -p 1 --deps discovered-from:bd-a1b2.3\nbd create \"Add session timeout handling\" -p 2 --deps discovered-from:bd-a1b2.3\nbd close bd-a1b2.3 --reason \"Sessions working\"\n\n# Week 5: Phase 4 (Security)\nbd ready  # Shows Phase 4 tasks\nbd create \"Review OWASP top 10\" -p 1 --deps discovered-from:bd-a1b2.4\nbd create \"Add CSRF protection\" -p 0 --deps discovered-from:bd-a1b2.4\nbd create \"Pen test with security team\" -p 1 --deps discovered-from:bd-a1b2.4\nbd close bd-a1b2.4 --reason \"Security audit passed\"\n\n# Epic complete!\nbd close bd-a1b2 --reason \"Auth system in production\"\n```\n\n## Best Practices\n\n### 1. Keep Phases Focused\n\nEach phase should have clear exit criteria:\n\n```bash\n# Good: Specific, measurable\nbd create \"Phase 1: Research (exit: chosen solution + ADR doc)\" -p 1\n\n# Bad: Vague\nbd create \"Phase 1: Look at stuff\" -p 1\n```\n\n### 2. Use Priorities Within Phases\n\nNot everything in a phase is equally urgent:\n\n```bash\n# Critical path\nbd create \"Implement core sync algorithm\" -p 0 --deps discovered-from:bd-a1b2.2\n\n# Nice to have, can wait\nbd create \"Add dark mode to test UI\" -p 3 --deps discovered-from:bd-a1b2.2\n```\n\n### 3. Link Discovered Work\n\nAlways link to parent issue/phase:\n\n```bash\n# Maintains context\nbd create \"Bug found during testing\" -t bug -p 1 \\\n  --deps discovered-from:bd-a1b2.3\n\n# Can trace back to which phase/feature it came from\nbd dep tree bd-a1b2\n```\n\n### 4. Don't Block on Low-Priority Work\n\nIf a phase has P3-P4 issues, don't let them block the next phase:\n\n```bash\n# Move nice-to-haves to backlog, unblock Phase 2\nbd update bd-xyz --priority 4\nbd close bd-a1b2.1 --reason \"Core research done, polish can wait\"\n```\n\n### 5. Regular Review\n\nCheck progress weekly:\n\n```bash\n# What's done?\nbd list --status closed --limit 20\n\n# What's stuck?\nbd list --status blocked\n\n# What's ready?\nbd ready\n```\n\n## Common Patterns\n\n### MVP â†’ Iteration Loop\n\n```bash\n# MVP phase\nbd create \"Phase 2: MVP (basic features)\" -p 1\nbd create \"Phase 3: Iteration (feedback loop)\" -p 2\nbd dep add bd-phase3 bd-phase2 --type blocks\n\n# After MVP, discover improvements\nbd create \"Add feature X (user requested)\" -p 1 \\\n  --deps discovered-from:bd-phase3\nbd create \"Fix UX issue Y\" -p 2 \\\n  --deps discovered-from:bd-phase3\n```\n\n### Parallel Workstreams\n\nNot all phases must be sequential:\n\n```bash\n# Frontend and backend can happen in parallel\nbd create \"Frontend: Build UI mockups\" -p 1\nbd create \"Backend: API design\" -p 1\n\n# No blocking dependency between them\n# Both show up in 'bd ready'\n```\n\n### Rollback Planning\n\nPlan for failure:\n\n```bash\n# Phase 3: Launch\nbd create \"Phase 3: Deploy to production\" -p 1\n\n# Contingency plan (related, not blocking)\nbd create \"Rollback plan if deploy fails\" -p 1\nbd dep add bd-rollback bd-phase3 --type related\n```\n\n## See Also\n\n- [Team Workflow](../team-workflow/) - Collaborate across phases\n- [Contributor Workflow](../contributor-workflow/) - External contributions\n- [Multiple Personas Example](../multiple-personas/) - Architect/implementer split\n",
        "examples/multiple-personas/README.md": "# Multiple Personas Workflow Example\n\nThis example demonstrates how to use beads when different roles work on the same project (architect, implementer, reviewer, etc.).\n\n## Problem\n\nComplex projects involve different personas with different concerns:\n- **Architect:** System design, technical decisions, high-level planning\n- **Implementer:** Write code, fix bugs, implement features\n- **Reviewer:** Code review, quality gates, testing\n- **Product:** Requirements, priorities, user stories\n\nEach persona needs:\n- Different views of the same work\n- Clear handoffs between roles\n- Track discovered work in context\n\n## Solution\n\nUse beads labels, priorities, and dependencies to organize work by persona, with clear ownership and handoffs.\n\n## Setup\n\n```bash\n# Initialize beads\ncd my-project\nbd init\n\n# Start daemon for auto-sync (optional for teams)\nbd daemon --start --auto-commit --auto-push\n```\n\n## Persona: Architect\n\nThe architect creates high-level design and makes technical decisions.\n\n### Create Architecture Epic\n\n```bash\n# Main epic\nbd create \"Design new caching layer\" -t epic -p 1\n# Returns: bd-a1b2c3\n\n# Add architecture label\nbd label add bd-a1b2c3 architecture\n\n# Architecture tasks\nbd create \"Research caching strategies (Redis vs Memcached)\" -p 1 \\\n  --deps discovered-from:bd-a1b2c3\nbd label add bd-xyz architecture\n\nbd create \"Write ADR: Caching layer design\" -p 1 \\\n  --deps discovered-from:bd-a1b2c3\nbd label add bd-abc architecture\n\nbd create \"Design cache invalidation strategy\" -p 1 \\\n  --deps discovered-from:bd-a1b2c3\nbd label add bd-def architecture\n```\n\n### View Architect Work\n\n```bash\n# See only architecture issues\nbd list --label architecture\n\n# See architecture issues that are ready\nbd list --label architecture --status open | grep -v blocked\n\n# High-priority architecture decisions\nbd list --label architecture --priority 0\nbd list --label architecture --priority 1\n```\n\n### Handoff to Implementer\n\nWhen design is complete, create implementation tasks:\n\n```bash\n# Close architecture tasks\nbd close bd-xyz --reason \"Decided on Redis with write-through\"\nbd close bd-abc --reason \"ADR-007 published\"\n\n# Create implementation tasks with labels\nbd create \"Implement Redis connection pool\" -p 1 \\\n  --deps discovered-from:bd-a1b2c3\nbd label add bd-impl1 implementation\n\nbd create \"Add cache middleware to API routes\" -p 1 \\\n  --deps discovered-from:bd-a1b2c3\nbd label add bd-impl2 implementation\n\n# Link implementation to architecture\nbd dep add bd-impl1 bd-abc --type related  # Based on ADR\nbd dep add bd-impl2 bd-abc --type related\n```\n\n## Persona: Implementer\n\nThe implementer writes code based on architecture decisions.\n\n### View Implementation Work\n\n```bash\n# See only implementation tasks\nbd list --label implementation --status open\n\n# See what's ready to implement\nbd ready | grep implementation\n\n# High-priority bugs to fix\nbd list --label implementation --type bug --priority 0\nbd list --label implementation --type bug --priority 1\n```\n\n### Claim and Implement\n\n```bash\n# Claim a task\nbd update bd-impl1 --status in_progress\n\n# During implementation, discover issues\nbd create \"Need connection retry logic\" -t bug -p 1 \\\n  --deps discovered-from:bd-impl1\nbd label add bd-bug1 implementation bug\n\nbd create \"Add metrics for cache hit rate\" -p 2 \\\n  --deps discovered-from:bd-impl1\nbd label add bd-metric1 implementation observability\n\n# Complete implementation\nbd close bd-impl1 --reason \"Redis pool working, tested locally\"\n```\n\n### Handoff to Reviewer\n\n```bash\n# Mark ready for review\nbd create \"Code review: Redis caching layer\" -p 1\nbd label add bd-review1 review\n\n# Link to implementation\nbd dep add bd-review1 bd-impl1 --type related\nbd dep add bd-review1 bd-impl2 --type related\n```\n\n## Persona: Reviewer\n\nThe reviewer checks code quality, tests, and approvals.\n\n### View Review Work\n\n```bash\n# See all review tasks\nbd list --label review --status open\n\n# See what's ready for review\nbd ready | grep review\n\n# High-priority reviews\nbd list --label review --priority 0\nbd list --label review --priority 1\n```\n\n### Perform Review\n\n```bash\n# Claim review\nbd update bd-review1 --status in_progress\n\n# Found issues during review\nbd create \"Add unit tests for retry logic\" -t task -p 1 \\\n  --deps discovered-from:bd-review1\nbd label add bd-test1 implementation testing\n\nbd create \"Fix: connection leak on timeout\" -t bug -p 0 \\\n  --deps discovered-from:bd-review1\nbd label add bd-bug2 implementation bug critical\n\nbd create \"Document Redis config options\" -p 2 \\\n  --deps discovered-from:bd-review1\nbd label add bd-doc1 documentation\n\n# Block review until issues fixed\nbd dep add bd-review1 bd-test1 --type blocks\nbd dep add bd-review1 bd-bug2 --type blocks\n```\n\n### Approve or Request Changes\n\n```bash\n# After fixes, approve\nbd close bd-review1 --reason \"LGTM, all tests pass\"\n\n# Or request changes\nbd update bd-review1 --status blocked\n# (blockers will show up in dependency tree)\n```\n\n## Persona: Product Owner\n\nThe product owner manages priorities and requirements.\n\n### View Product Work\n\n```bash\n# See all features\nbd list --type feature\n\n# See high-priority work\nbd list --priority 0\nbd list --priority 1\n\n# See what's in progress\nbd list --status in_progress\n\n# See what's blocked\nbd list --status blocked\n```\n\n### Prioritize Work\n\n```bash\n# Bump priority based on customer feedback\nbd update bd-impl2 --priority 0\n\n# Lower priority for nice-to-haves\nbd update bd-metric1 --priority 3\n\n# Add product label to track customer-facing work\nbd label add bd-impl2 customer-facing\n```\n\n### Create User Stories\n\n```bash\n# User story\nbd create \"As a user, I want faster page loads\" -t feature -p 1\nbd label add bd-story1 user-story customer-facing\n\n# Link technical work to user story\nbd dep add bd-impl1 bd-story1 --type related\nbd dep add bd-impl2 bd-story1 --type related\n```\n\n## Multi-Persona Workflow Example\n\n### Week 1: Architecture Phase\n\n**Architect:**\n\n```bash\n# Create epic\nbd create \"Implement rate limiting\" -t epic -p 1  # bd-epic1\nbd label add bd-epic1 architecture\n\n# Research\nbd create \"Research rate limiting algorithms\" -p 1 \\\n  --deps discovered-from:bd-epic1\nbd label add bd-research1 architecture research\n\nbd update bd-research1 --status in_progress\n# ... research done ...\nbd close bd-research1 --reason \"Chose token bucket algorithm\"\n\n# Design\nbd create \"Write ADR: Rate limiting design\" -p 1 \\\n  --deps discovered-from:bd-epic1\nbd label add bd-adr1 architecture documentation\n\nbd close bd-adr1 --reason \"ADR-012 approved\"\n```\n\n### Week 2: Implementation Phase\n\n**Implementer:**\n\n```bash\n# See what's ready to implement\nbd ready | grep implementation\n\n# Create implementation tasks based on architecture\nbd create \"Implement token bucket algorithm\" -p 1 \\\n  --deps discovered-from:bd-epic1\nbd label add bd-impl1 implementation\nbd dep add bd-impl1 bd-adr1 --type related\n\nbd create \"Add rate limit middleware\" -p 1 \\\n  --deps discovered-from:bd-epic1\nbd label add bd-impl2 implementation\n\n# Claim and start\nbd update bd-impl1 --status in_progress\n\n# Discover issues\nbd create \"Need distributed rate limiting (Redis)\" -t bug -p 1 \\\n  --deps discovered-from:bd-impl1\nbd label add bd-bug1 implementation bug\n```\n\n**Architect (consulted):**\n\n```bash\n# Architect reviews discovered issue\nbd show bd-bug1\nbd update bd-bug1 --priority 0  # Escalate to critical\nbd label add bd-bug1 architecture  # Architect will handle\n\n# Make decision\nbd create \"Design: Distributed rate limiting\" -p 0 \\\n  --deps discovered-from:bd-bug1\nbd label add bd-design1 architecture\n\nbd close bd-design1 --reason \"Use Redis with sliding window\"\n```\n\n**Implementer (continues):**\n\n```bash\n# Implement based on architecture decision\nbd create \"Add Redis sliding window for rate limits\" -p 0 \\\n  --deps discovered-from:bd-design1\nbd label add bd-impl3 implementation\n\nbd close bd-impl1 --reason \"Token bucket working\"\nbd close bd-impl3 --reason \"Redis rate limiting working\"\n```\n\n### Week 3: Review Phase\n\n**Reviewer:**\n\n```bash\n# See what's ready for review\nbd list --label review\n\n# Create review task\nbd create \"Code review: Rate limiting\" -p 1\nbd label add bd-review1 review\nbd dep add bd-review1 bd-impl1 --type related\nbd dep add bd-review1 bd-impl3 --type related\n\nbd update bd-review1 --status in_progress\n\n# Found issues\nbd create \"Add integration tests for Redis\" -t task -p 1 \\\n  --deps discovered-from:bd-review1\nbd label add bd-test1 testing implementation\n\nbd create \"Missing error handling for Redis down\" -t bug -p 0 \\\n  --deps discovered-from:bd-review1\nbd label add bd-bug2 implementation bug critical\n\n# Block review\nbd dep add bd-review1 bd-test1 --type blocks\nbd dep add bd-review1 bd-bug2 --type blocks\n```\n\n**Implementer (fixes):**\n\n```bash\n# Fix review findings\nbd update bd-bug2 --status in_progress\nbd close bd-bug2 --reason \"Added circuit breaker for Redis\"\n\nbd update bd-test1 --status in_progress\nbd close bd-test1 --reason \"Integration tests passing\"\n```\n\n**Reviewer (approves):**\n\n```bash\n# Review unblocked\nbd close bd-review1 --reason \"Approved, merging PR\"\n```\n\n**Product Owner (closes epic):**\n\n```bash\n# Feature shipped!\nbd close bd-epic1 --reason \"Rate limiting in production\"\n```\n\n## Label Organization\n\n### Recommended Labels\n\n```bash\n# Role labels\narchitecture, implementation, review, product\n\n# Type labels\nbug, feature, task, chore, documentation\n\n# Status labels\ncritical, blocked, waiting-feedback, needs-design\n\n# Domain labels\nfrontend, backend, infrastructure, database\n\n# Quality labels\ntesting, security, performance, accessibility\n\n# Customer labels\ncustomer-facing, user-story, feedback\n```\n\n### View by Label Combination\n\n```bash\n# Critical bugs for implementers\nbd list --label implementation --label bug --label critical\n\n# Architecture issues needing review\nbd list --label architecture --label review\n\n# Customer-facing features\nbd list --label customer-facing --type feature\n\n# Backend implementation work\nbd list --label backend --label implementation --status open\n```\n\n## Filtering by Persona\n\n### Architect View\n\n```bash\n# My work\nbd list --label architecture --status open\n\n# Design decisions to make\nbd list --label architecture --label needs-design\n\n# High-priority architecture\nbd list --label architecture --priority 0\nbd list --label architecture --priority 1\n```\n\n### Implementer View\n\n```bash\n# My work\nbd list --label implementation --status open\n\n# Ready to implement\nbd ready | grep implementation\n\n# Bugs to fix\nbd list --label implementation --type bug --priority 0\nbd list --label implementation --type bug --priority 1\n\n# Blocked work\nbd list --label implementation --status blocked\n```\n\n### Reviewer View\n\n```bash\n# Reviews waiting\nbd list --label review --status open\n\n# Critical reviews\nbd list --label review --priority 0\n\n# Blocked reviews\nbd list --label review --status blocked\n```\n\n### Product Owner View\n\n```bash\n# All customer-facing work\nbd list --label customer-facing\n\n# Features in progress\nbd list --type feature --status in_progress\n\n# Blocked work (needs attention)\nbd list --status blocked\n\n# High-priority items across all personas\nbd list --priority 0\n```\n\n## Handoff Patterns\n\n### Architecture â†’ Implementation\n\n```bash\n# Architect creates spec\nbd create \"Design: New payment API\" -p 1\nbd label add bd-design1 architecture documentation\n\n# When done, create implementation tasks\nbd create \"Implement Stripe integration\" -p 1\nbd label add bd-impl1 implementation\nbd dep add bd-impl1 bd-design1 --type related\n\nbd close bd-design1 --reason \"Spec complete, ready for implementation\"\n```\n\n### Implementation â†’ Review\n\n```bash\n# Implementer finishes\nbd close bd-impl1 --reason \"Stripe working, PR ready\"\n\n# Create review task\nbd create \"Code review: Stripe integration\" -p 1\nbd label add bd-review1 review\nbd dep add bd-review1 bd-impl1 --type related\n```\n\n### Review â†’ Product\n\n```bash\n# Reviewer approves\nbd close bd-review1 --reason \"Approved, deployed to staging\"\n\n# Product tests in staging\nbd create \"UAT: Test Stripe in staging\" -p 1\nbd label add bd-uat1 product testing\nbd dep add bd-uat1 bd-review1 --type related\n\n# Product approves for production\nbd close bd-uat1 --reason \"UAT passed, deploying to prod\"\n```\n\n## Best Practices\n\n### 1. Use Labels Consistently\n\n```bash\n# Good: Clear role separation\nbd label add bd-123 architecture\nbd label add bd-456 implementation\nbd label add bd-789 review\n\n# Bad: Mixing concerns\n# (same issue shouldn't be both architecture and implementation)\n```\n\n### 2. Link Related Work\n\n```bash\n# Always link implementation to architecture\nbd dep add bd-impl bd-arch --type related\n\n# Link bugs to features\nbd dep add bd-bug bd-feature --type discovered-from\n```\n\n### 3. Clear Handoffs\n\n```bash\n# Document why closing\nbd close bd-arch --reason \"Design complete, created bd-impl1 and bd-impl2 for implementation\"\n\n# Not: \"done\" (too vague)\n```\n\n### 4. Escalate When Needed\n\n```bash\n# Implementer discovers architectural issue\nbd create \"Current design doesn't handle edge case X\" -t bug -p 0\nbd label add bd-issue architecture  # Tag for architect\nbd label add bd-issue needs-design  # Flag as needing design\n```\n\n### 5. Regular Syncs\n\n```bash\n# Daily: Each persona checks their work\nbd list --label architecture --status open  # Architect\nbd list --label implementation --status open  # Implementer\nbd list --label review --status open  # Reviewer\n\n# Weekly: Team reviews together\nbd stats  # Overall progress\nbd list --status blocked  # What's stuck?\nbd ready  # What's ready to work on?\n```\n\n## Common Patterns\n\n### Spike Then Implement\n\n```bash\n# Architect creates research spike\nbd create \"Spike: Evaluate GraphQL vs REST\" -p 1\nbd label add bd-spike1 architecture research\n\nbd close bd-spike1 --reason \"Chose GraphQL, created implementation tasks\"\n\n# Implementation follows\nbd create \"Implement GraphQL API\" -p 1\nbd label add bd-impl1 implementation\nbd dep add bd-impl1 bd-spike1 --type related\n```\n\n### Bug Triage\n\n```bash\n# Bug reported\nbd create \"App crashes on large files\" -t bug -p 1\n\n# Implementer investigates\nbd update bd-bug1 --label implementation\nbd update bd-bug1 --status in_progress\n\n# Discovers architectural issue\nbd create \"Need streaming uploads, not buffering\" -t bug -p 0\nbd label add bd-arch1 architecture\nbd dep add bd-arch1 bd-bug1 --type discovered-from\n\n# Architect designs solution\nbd update bd-arch1 --label architecture\nbd close bd-arch1 --reason \"Designed streaming upload flow\"\n\n# Implementer fixes\nbd update bd-bug1 --status in_progress\nbd close bd-bug1 --reason \"Implemented streaming uploads\"\n```\n\n### Feature Development\n\n```bash\n# Product creates user story\nbd create \"Users want bulk import\" -t feature -p 1\nbd label add bd-story1 user-story product\n\n# Architect designs\nbd create \"Design: Bulk import system\" -p 1\nbd label add bd-design1 architecture\nbd dep add bd-design1 bd-story1 --type related\n\n# Implementation tasks\nbd create \"Implement CSV parser\" -p 1\nbd label add bd-impl1 implementation\nbd dep add bd-impl1 bd-design1 --type related\n\nbd create \"Implement batch processor\" -p 1\nbd label add bd-impl2 implementation\nbd dep add bd-impl2 bd-design1 --type related\n\n# Review\nbd create \"Code review: Bulk import\" -p 1\nbd label add bd-review1 review\nbd dep add bd-review1 bd-impl1 --type blocks\nbd dep add bd-review1 bd-impl2 --type blocks\n\n# Product UAT\nbd create \"UAT: Bulk import\" -p 1\nbd label add bd-uat1 product testing\nbd dep add bd-uat1 bd-review1 --type blocks\n```\n\n## See Also\n\n- [Multi-Phase Development](../multi-phase-development/) - Organize work by phase\n- [Team Workflow](../team-workflow/) - Collaborate across personas\n- [Contributor Workflow](../contributor-workflow/) - External contributions\n- [Labels Documentation](../../docs/LABELS.md) - Label management guide\n",
        "examples/protected-branch/README.md": "# Protected Branch Workflow Example\n\nThis example demonstrates how to use beads with protected branches on platforms like GitHub, GitLab, and Bitbucket.\n\n## Scenario\n\nYou have a repository with:\n- Protected `main` branch (requires pull requests)\n- Multiple developers/AI agents working on issues\n- Desire to track issues in git without bypassing branch protection\n\n## Solution\n\nUse beads' separate sync branch feature to commit issue metadata to a dedicated branch (e.g., `beads-metadata`), then periodically merge via pull request.\n\n## Quick Demo\n\n### 1. Setup (One Time)\n\n```bash\n# Clone this repo or create a new one\ngit init my-project\ncd my-project\n\n# Initialize beads with separate sync branch\nbd init --branch beads-metadata --quiet\n\n# Verify configuration\nbd config get sync.branch\n# Output: beads-metadata\n```\n\n### 2. Create Issues (Agent Workflow)\n\n```bash\n# AI agent creates issues normally\nbd create \"Implement user authentication\" -t feature -p 1\nbd create \"Add login page\" -t task -p 1\nbd create \"Write auth tests\" -t task -p 2\n\n# Link tasks to parent feature\nbd link bd-XXXXX --blocks bd-YYYYY  # auth blocks login\nbd link bd-XXXXX --blocks bd-ZZZZZ  # auth blocks tests\n\n# Start work\nbd update bd-XXXXX --status in_progress\n```\n\n**Note:** Replace `bd-XXXXX` etc. with actual issue IDs created above.\n\n### 3. Auto-Sync (Daemon)\n\n```bash\n# Start daemon with auto-commit\nbd daemon --start --auto-commit\n\n# All issue changes are now automatically committed to beads-metadata branch\n```\n\nCheck what's been committed:\n\n```bash\n# View commits on sync branch\ngit log beads-metadata --oneline | head -5\n\n# View diff between main and sync branch\nbd sync --status\n```\n\n### 4. Manual Sync (Without Daemon)\n\nIf you're not using the daemon:\n\n```bash\n# Create or update issues\nbd create \"Fix bug in login\" -t bug -p 0\nbd update bd-XXXXX --status closed\n\n# Manually flush to sync branch\nbd sync --flush-only\n\n# Verify commit\ngit log beads-metadata -1\n```\n\n### 5. Merge to Main (Human Review)\n\nOption 1: Via pull request (recommended):\n\n```bash\n# Push sync branch\ngit push origin beads-metadata\n\n# Create PR on GitHub\ngh pr create --base main --head beads-metadata \\\n  --title \"Update issue metadata\" \\\n  --body \"Automated issue tracker updates from beads\"\n\n# After PR is approved and merged:\ngit checkout main\ngit pull\nbd import  # Import merged changes to database\n```\n\nOption 2: Direct merge (if you have push access):\n\n```bash\n# Preview merge\nbd sync --merge --dry-run\n\n# Perform merge\nbd sync --merge\n\n# This will:\n# - Merge beads-metadata into main\n# - Create merge commit\n# - Push to origin\n# - Import merged changes\n```\n\n### 6. Multi-Clone Sync\n\nIf you have multiple clones or agents:\n\n```bash\n# Clone 1: Create issue\nbd create \"New feature\" -t feature -p 1\nbd sync --flush-only  # Commit to beads-metadata\ngit push origin beads-metadata\n\n# Clone 2: Pull changes\ngit fetch origin beads-metadata\nbd sync --no-push  # Pull from sync branch and import\nbd list  # See the new feature issue\n```\n\n## Workflow Summary\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Agent creates  â”‚\nâ”‚  or updates     â”‚\nâ”‚  issues         â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â”‚\n         â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Daemon (or     â”‚\nâ”‚  manual sync)   â”‚\nâ”‚  commits to     â”‚\nâ”‚  beads-metadata â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â”‚\n         â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Periodically   â”‚\nâ”‚  merge to main  â”‚\nâ”‚  via PR         â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â”‚\n         â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  All clones     â”‚\nâ”‚  pull and       â”‚\nâ”‚  import         â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Directory Structure\n\nWhen using separate sync branch, your repo will have:\n\n```\nmy-project/\nâ”œâ”€â”€ .git/\nâ”‚   â”œâ”€â”€ beads-worktrees/       # Hidden worktree directory\nâ”‚   â”‚   â””â”€â”€ beads-metadata/    # Lightweight checkout of sync branch\nâ”‚   â”‚       â””â”€â”€ .beads/\nâ”‚   â”‚           â””â”€â”€ issues.jsonl\nâ”‚   â””â”€â”€ ...\nâ”œâ”€â”€ .beads/                    # Main beads directory (in your workspace)\nâ”‚   â”œâ”€â”€ beads.db               # SQLite database\nâ”‚   â”œâ”€â”€ issues.jsonl            # JSONL export\nâ”‚   â””â”€â”€ bd.sock                # Daemon socket (if running)\nâ”œâ”€â”€ src/                       # Your application code\nâ”‚   â””â”€â”€ ...\nâ””â”€â”€ README.md\n```\n\n**Key points:**\n- `.git/beads-worktrees/` is hidden from your main workspace\n- Only `.beads/` is checked out in the worktree (sparse checkout)\n- Your `src/` code is never affected by beads commits\n- Minimal disk overhead (~few MB for worktree)\n\n## Tips\n\n### For Humans\n\n- **Review before merging:** Use `bd sync --status` to see what changed\n- **Batch merges:** Don't need to merge after every issue - merge when convenient\n- **PR descriptions:** Link to specific issues in PR body for context\n\n### For AI Agents\n\n- **No workflow changes:** Agents use `bd create`, `bd update`, etc. as normal\n- **Let daemon handle it:** With `--auto-commit`, agents don't think about sync\n- **Session end:** Run `bd sync` at end of session to ensure everything is committed\n\n### Troubleshooting\n\n**\"Merge conflicts in issues.jsonl\"**\n\nJSONL is append-only and line-based, so conflicts are rare. If they occur:\n1. Both versions are usually valid - keep both lines\n2. If same issue updated differently, keep the line with newer `updated_at`\n3. After resolving: `bd import` to update database\n\n**\"Worktree doesn't exist\"**\n\nThe daemon creates it automatically on first commit. To create manually:\n```bash\nbd config get sync.branch  # Verify it's set\nbd daemon --stop && bd daemon --start          # Daemon will create worktree\n```\n\n**\"Changes not syncing\"**\n\nMake sure:\n- `bd config get sync.branch` returns the same value on all clones\n- Daemon is running: `bd daemon --status`\n- Both clones have fetched: `git fetch origin beads-metadata`\n\n## Advanced: GitHub Actions Integration\n\nAutomate the merge process with GitHub Actions:\n\n```yaml\nname: Auto-Merge Beads Metadata\non:\n  schedule:\n    - cron: '0 0 * * *'  # Daily at midnight\n  workflow_dispatch:\n\njobs:\n  merge-beads:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n        with:\n          fetch-depth: 0\n\n      - name: Install bd\n        run: curl -fsSL https://raw.githubusercontent.com/steveyegge/beads/main/scripts/install.sh | bash\n\n      - name: Check for changes\n        id: check\n        run: |\n          git fetch origin beads-metadata\n          if git diff --quiet main origin/beads-metadata -- .beads/; then\n            echo \"has_changes=false\" >> $GITHUB_OUTPUT\n          else\n            echo \"has_changes=true\" >> $GITHUB_OUTPUT\n          fi\n\n      - name: Create PR\n        if: steps.check.outputs.has_changes == 'true'\n        run: |\n          gh pr create --base main --head beads-metadata \\\n            --title \"Update issue metadata\" \\\n            --body \"Automated issue tracker updates from beads\" \\\n            || echo \"PR already exists\"\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n```\n\n## See Also\n\n- [docs/PROTECTED_BRANCHES.md](../../docs/PROTECTED_BRANCHES.md) - Complete guide\n- [AGENTS.md](../../AGENTS.md) - Agent integration instructions\n- [commands/sync.md](../../commands/sync.md) - `bd sync` command reference\n",
        "examples/python-agent/README.md": "# Python Agent Example\n\nA simple Python script demonstrating how an AI agent can use bd to manage tasks.\n\n## Features\n\n- Finds ready work using `bd ready --json`\n- Claims tasks by updating status\n- Simulates discovering new issues during work\n- Links discovered issues with `discovered-from` dependency\n- Completes tasks and moves to the next one\n\n## Prerequisites\n\n- Python 3.7+\n- bd installed: `go install github.com/steveyegge/beads/cmd/bd@latest`\n- A beads database initialized: `bd init`\n\n## Usage\n\n```bash\n# Make the script executable\nchmod +x agent.py\n\n# Run the agent\n./agent.py\n```\n\n## What It Does\n\n1. Queries for ready work (no blocking dependencies)\n2. Claims the highest priority task\n3. \"Works\" on the task (simulated)\n4. If the task involves implementation, discovers a testing task\n5. Creates the new testing task and links it with `discovered-from`\n6. Completes the original task\n7. Repeats until no ready work remains\n\n## Example Output\n\n```\nğŸš€ Beads Agent starting...\n\n============================================================\nIteration 1/10\n============================================================\n\nğŸ“‹ Claiming task: bd-1\nğŸ¤– Working on: Implement user authentication (bd-1)\n   Priority: 1, Type: feature\n\nğŸ’¡ Discovered: Missing test coverage for this feature\nâœ¨ Creating issue: Add tests for Implement user authentication\nğŸ”— Linking bd-2 â† discovered-from â† bd-1\nâœ… Completing task: bd-1 - Implemented successfully\n\nğŸ”„ New work discovered and linked. Running another cycle...\n```\n\n## Integration with Real Agents\n\nTo integrate with a real LLM-based agent:\n\n1. Replace `simulate_work()` with actual LLM calls\n2. Parse the LLM's response for discovered issues/bugs\n3. Use the issue ID to track context across conversations\n4. Export/import JSONL to share state across agent sessions\n\n## Advanced Usage\n\n```python\n# Create an agent with custom behavior\nagent = BeadsAgent()\n\n# Find specific types of work\nready = agent.run_bd(\"ready\", \"--priority\", \"1\", \"--assignee\", \"bot\")\n\n# Create issues with labels\nagent.run_bd(\"create\", \"New task\", \"-l\", \"urgent,backend\")\n\n# Query dependency tree\ntree = agent.run_bd(\"dep\", \"tree\", \"bd-1\")\n```\n\n## See Also\n\n- [../bash-agent/](../bash-agent/) - Bash version of this example\n- [../claude-desktop-mcp/](../claude-desktop-mcp/) - MCP server for Claude Desktop\n",
        "examples/startup-hooks/README.md": "# Startup Hooks for AI Agents\n\nThis directory contains startup hook scripts that help AI agents automatically detect and adapt to changes in their environment.\n\n## bd-version-check.sh\n\n**Purpose:** Automatically detect bd (beads) upgrades and show what changed\n\n**Features:**\n- âœ… Detects when bd version changes between sessions\n- âœ… Shows `bd info --whats-new` output automatically\n- âœ… Auto-updates outdated git hooks\n- âœ… Persists version tracking in `.beads/metadata.json`\n- âœ… Works today - no bd code changes required!\n\n**Usage:**\n\n```bash\n# Source the script at session start (recommended)\nsource examples/startup-hooks/bd-version-check.sh\n\n# Or execute it directly\nbash examples/startup-hooks/bd-version-check.sh\n```\n\n### Integration Examples\n\n#### Claude Code\n\nIf Claude Code supports startup hooks:\n```bash\n# Add to .claude/hooks/session-start\nsource examples/startup-hooks/bd-version-check.sh\n```\n\nAlternatively, manually run at the start of each coding session.\n\n#### GitHub Copilot\n\nAdd to your shell initialization file:\n```bash\n# ~/.bashrc or ~/.zshrc\n# Run bd version check when entering a beads project\nif [ -d \".beads\" ]; then\n  source /path/to/beads/examples/startup-hooks/bd-version-check.sh\nfi\n```\n\n#### Cursor\n\nAdd to workspace settings or your shell init file following the same pattern as GitHub Copilot.\n\n#### Generic Integration\n\nAny AI coding environment that allows custom startup scripts can source this file.\n\n### Requirements\n\n- **bd (beads)**: Must be installed and in PATH\n- **jq**: Required for JSON manipulation (`brew install jq` on macOS, `apt-get install jq` on Ubuntu)\n- **.beads directory**: Must exist in current project\n\n### How It Works\n\n1. **Version Detection**: Reads current bd version and compares to `.beads/metadata.json`\n2. **Change Notification**: If version changed, displays upgrade banner with what's new\n3. **Hook Updates**: Checks for outdated git hooks and auto-updates them\n4. **Persistence**: Updates `metadata.json` with current version for next session\n\n### Example Output\n\n```\nğŸ”„ bd upgraded: 0.23.0 â†’ 0.24.2\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nğŸ†• What's New in bd (Current: v0.24.2)\n=============================================================\n\n## v0.24.2 (2025-11-23)\n  â€¢ New feature X\n  â€¢ Bug fix Y\n  â€¢ Performance improvement Z\n\n[... rest of what's new output ...]\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nğŸ’¡ Review changes above and adapt your workflow accordingly\n\nğŸ”§ Git hooks outdated. Updating to match bd v0.24.2...\nâœ“ Git hooks updated successfully\n```\n\n### Edge Cases Handled\n\n- **Not in a beads project**: Silently exits (safe to include in global shell init)\n- **bd not installed**: Silently exits\n- **jq not installed**: Shows warning but doesn't break\n- **metadata.json missing**: Auto-creates it\n- **First run**: Sets version without showing upgrade message\n- **bd command fails**: Silently exits\n\n### Troubleshooting\n\n**Q: Script doesn't detect version change**\nA: Check that `.beads/metadata.json` exists and contains `last_bd_version` field\n\n**Q: \"jq not found\" warning**\nA: Install jq: `brew install jq` (macOS) or `apt-get install jq` (Ubuntu)\n\n**Q: Git hooks not auto-updating**\nA: Ensure you have write permissions to `.git/hooks/` directory\n\n### Related\n\n- **GitHub Discussion #239**: \"Upgrading beads: how to let the Agent know\"\n- **Parent Epic**: bd-nxgk - Agent upgrade awareness system\n- **AGENTS.md**: See \"After Upgrading bd\" section for manual workflow\n",
        "examples/team-workflow/README.md": "# Team Workflow Example\n\nThis example demonstrates how to use beads for team collaboration with shared repositories.\n\n## Problem\n\nWhen working as a team on a shared repository, you want to:\n- Track issues collaboratively\n- Keep everyone in sync via git\n- Handle protected main branches\n- Maintain clean git history\n\n## Solution\n\nUse `bd init --team` to set up team collaboration with automatic sync and optional protected branch support.\n\n## Setup\n\n### Step 1: Initialize Team Workflow\n\n```bash\n# In your shared repository\ncd my-project\n\n# Run the team setup wizard\nbd init --team\n```\n\nThe wizard will:\n1. âœ… Detect your git configuration\n2. âœ… Ask if main branch is protected\n3. âœ… Configure sync branch (if needed)\n4. âœ… Set up automatic sync\n5. âœ… Enable team mode\n\n### Step 2: Protected Branch Configuration\n\nIf your main branch is protected (GitHub/GitLab), the wizard will:\n- Create a separate `beads-metadata` branch for issue updates\n- Configure beads to commit to this branch automatically\n- Set up periodic PR workflow for merging to main\n\n### Step 3: Team Members Join\n\nOther team members just need to:\n\n```bash\n# Clone the repository\ngit clone https://github.com/org/project.git\ncd project\n\n# Initialize beads (auto-imports existing issues)\nbd init\n\n# Start working!\nbd ready\n```\n\n## How It Works\n\n### Direct Commits (No Protected Branch)\n\nIf main isn't protected:\n\n```bash\n# Create issue\nbd create \"Implement feature X\" -p 1\n\n# Daemon auto-commits to main\n# (or run 'bd sync' manually)\n\n# Pull to see team's issues\ngit pull\nbd list\n```\n\n### Protected Branch Workflow\n\nIf main is protected:\n\n```bash\n# Create issue\nbd create \"Implement feature X\" -p 1\n\n# Daemon commits to beads-metadata branch\n# (or run 'bd sync' manually)\n\n# Push beads-metadata\ngit push origin beads-metadata\n\n# Periodically: merge beads-metadata to main via PR\n```\n\n## Configuration\n\nThe wizard configures:\n\n```yaml\nteam:\n  enabled: true\n  sync_branch: beads-metadata  # or main if not protected\n\ndaemon:\n  auto_commit: true\n  auto_push: true\n```\n\n### Manual Configuration\n\n```bash\n# Enable team mode\nbd config set team.enabled true\n\n# Set sync branch\nbd config set team.sync_branch beads-metadata\n\n# Enable auto-sync\nbd config set daemon.auto_commit true\nbd config set daemon.auto_push true\n```\n\n## Example Workflows\n\n### Scenario 1: Unprotected Main\n\n```bash\n# Alice creates an issue\nbd create \"Fix authentication bug\" -p 1\n\n# Daemon commits and pushes to main\n# (auto-sync enabled)\n\n# Bob pulls changes\ngit pull\nbd list  # Sees Alice's issue\n\n# Bob claims it\nbd update bd-abc --status in_progress\n\n# Daemon commits Bob's update\n# Alice pulls and sees Bob is working on it\n```\n\n### Scenario 2: Protected Main\n\n```bash\n# Alice creates an issue\nbd create \"Add new API endpoint\" -p 1\n\n# Daemon commits to beads-metadata\ngit push origin beads-metadata\n\n# Bob pulls beads-metadata\ngit pull origin beads-metadata\nbd list  # Sees Alice's issue\n\n# Later: merge beads-metadata to main via PR\ngit checkout main\ngit pull origin main\ngit merge beads-metadata\n# Create PR, get approval, merge\n```\n\n## Team Workflows\n\n### Daily Standup\n\n```bash\n# See what everyone's working on\nbd list --status in_progress\n\n# See what's ready for work\nbd ready\n\n# See recently closed issues\nbd list --status closed --limit 10\n```\n\n### Sprint Planning\n\n```bash\n# Create sprint issues\nbd create \"Implement user auth\" -p 1\nbd create \"Add profile page\" -p 1\nbd create \"Fix responsive layout\" -p 2\n\n# Assign to team members\nbd update bd-abc --assignee alice\nbd update bd-def --assignee bob\n\n# Track dependencies\nbd dep add bd-def bd-abc --type blocks\n```\n\n### PR Integration\n\n```bash\n# Create issue for PR work\nbd create \"Refactor auth module\" -p 1\n\n# Work on it\nbd update bd-abc --status in_progress\n\n# Open PR with issue reference\ngit push origin feature-branch\n# PR title: \"feat: refactor auth module (bd-abc)\"\n\n# Close when PR merges\nbd close bd-abc --reason \"PR #123 merged\"\n```\n\n## Sync Strategies\n\n### Auto-Sync (Recommended)\n\nDaemon commits and pushes automatically:\n\n```bash\nbd daemon --start --auto-commit --auto-push\n```\n\nBenefits:\n- âœ… Always in sync\n- âœ… No manual intervention\n- âœ… Real-time collaboration\n\n### Manual Sync\n\nSync when you want:\n\n```bash\nbd sync  # Export, commit, pull, import, push\n```\n\nBenefits:\n- âœ… Full control\n- âœ… Batch updates\n- âœ… Review before push\n\n## Conflict Resolution\n\nHash-based IDs prevent most conflicts. If conflicts occur:\n\n```bash\n# During git pull/merge\ngit pull origin beads-metadata\n# CONFLICT in .beads/issues.jsonl\n\n# Option 1: Accept remote\ngit checkout --theirs .beads/issues.jsonl\nbd import -i .beads/issues.jsonl\n\n# Option 2: Accept local\ngit checkout --ours .beads/issues.jsonl\nbd import -i .beads/issues.jsonl\n\n# Option 3: Use beads-merge tool (recommended)\n# See docs/GIT_INTEGRATION.md for merge conflict resolution\n\ngit add .beads/issues.jsonl\ngit commit\n```\n\n## Protected Branch Best Practices\n\n### For Protected Main:\n\n1. **Create beads-metadata branch**\n   ```bash\n   git checkout -b beads-metadata\n   git push origin beads-metadata\n   ```\n\n2. **Configure protection rules**\n   - Allow direct pushes to beads-metadata\n   - Require PR for main\n\n3. **Periodic PR workflow**\n   ```bash\n   # Once per day/sprint\n   git checkout main\n   git pull origin main\n   git checkout beads-metadata\n   git pull origin beads-metadata\n   git checkout main\n   git merge beads-metadata\n   # Create PR, get approval, merge\n   ```\n\n4. **Keep beads-metadata clean**\n   ```bash\n   # After PR merges\n   git checkout beads-metadata\n   git rebase main\n   git push origin beads-metadata --force-with-lease\n   ```\n\n## Common Questions\n\n### Q: How do team members see each other's issues?\n\nA: Issues are stored in `.beads/issues.jsonl` which is version-controlled. Pull from git to sync.\n\n```bash\ngit pull\nbd list  # See everyone's issues\n```\n\n### Q: What if two people create issues at the same time?\n\nA: Hash-based IDs prevent collisions. Even if created simultaneously, they get different IDs.\n\n### Q: How do I disable auto-sync?\n\nA: Turn it off:\n\n```bash\nbd config set daemon.auto_commit false\nbd config set daemon.auto_push false\n\n# Sync manually\nbd sync\n```\n\n### Q: Can we use different sync branches per person?\n\nA: Not recommended. Use a single shared branch for consistency. If needed:\n\n```bash\nbd config set sync.branch my-custom-branch\n```\n\n### Q: What about CI/CD integration?\n\nA: Add to your CI pipeline:\n\n```bash\n# In .github/workflows/main.yml\n- name: Sync beads issues\n  run: |\n    bd sync\n    git push origin beads-metadata\n```\n\n## Troubleshooting\n\n### Issue: Daemon not committing\n\nCheck daemon status:\n\n```bash\nbd daemon --status\nbd daemons list\n```\n\nVerify config:\n\n```bash\nbd config get daemon.auto_commit\nbd config get daemon.auto_push\n```\n\nRestart daemon:\n\n```bash\nbd daemon --stop\nbd daemon --start --auto-commit --auto-push\n```\n\n### Issue: Merge conflicts in JSONL\n\nUse beads-merge or resolve manually (see [GIT_INTEGRATION.md](../../docs/GIT_INTEGRATION.md)):\n\n```bash\ngit checkout --theirs .beads/issues.jsonl\nbd import -i .beads/issues.jsonl\ngit add .beads/issues.jsonl\ngit commit\n```\n\n### Issue: Issues not syncing\n\nManually sync:\n\n```bash\nbd sync\ngit push\n```\n\nCheck for conflicts:\n\n```bash\ngit status\nbd validate --checks=conflicts\n```\n\n## See Also\n\n- [Protected Branch Setup](../protected-branch/)\n- [Contributor Workflow](../contributor-workflow/)\n- [Multi-Repo Migration Guide](../../docs/MULTI_REPO_MIGRATION.md)\n- [Git Integration Guide](../../docs/GIT_INTEGRATION.md)\n",
        "integrations/beads-mcp/README.md": "# beads-mcp\n\nMCP server for [beads](https://github.com/steveyegge/beads) issue tracker and agentic memory system.\nEnables AI agents to manage tasks using bd CLI through Model Context Protocol.\n\n> **Note:** For environments with shell access (Claude Code, Cursor, Windsurf), the **CLI + hooks approach is recommended** over MCP. It uses ~1-2k tokens vs 10-50k for MCP schemas, resulting in lower compute cost and latency. See the [main README](../../README.md) for CLI setup.\n>\n> **Use this MCP server** for MCP-only environments like Claude Desktop where CLI access is unavailable.\n\n## Installing\n\nInstall from PyPI:\n\n```bash\n# Using uv (recommended)\nuv tool install beads-mcp\n\n# Or using pip\npip install beads-mcp\n```\n\nAdd to your Claude Desktop config:\n\n```json\n{\n  \"mcpServers\": {\n    \"beads\": {\n      \"command\": \"beads-mcp\"\n    }\n  }\n}\n```\n\n### Development Installation\n\nFor development, clone the repository:\n\n```bash\ngit clone https://github.com/steveyegge/beads\ncd beads/integrations/beads-mcp\nuv sync\n```\n\nThen use in Claude Desktop config:\n\n```json\n{\n  \"mcpServers\": {\n    \"beads\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/path/to/beads-mcp\",\n        \"run\",\n        \"beads-mcp\"\n      ]\n    }\n  }\n}\n```\n\n**Environment Variables** (all optional):\n- `BEADS_USE_DAEMON` - Use daemon RPC instead of CLI (default: `1`, set to `0` to disable)\n- `BEADS_PATH` - Path to bd executable (default: `~/.local/bin/bd`)\n- `BEADS_DB` - Path to beads database file (default: auto-discover from cwd)\n- `BEADS_WORKING_DIR` - Working directory for bd commands (default: `$PWD` or current directory). Used for multi-repo setups - see below\n- `BEADS_ACTOR` - Actor name for audit trail (default: `$USER`)\n- `BEADS_NO_AUTO_FLUSH` - Disable automatic JSONL sync (default: `false`)\n- `BEADS_NO_AUTO_IMPORT` - Disable automatic JSONL import (default: `false`)\n\n## Multi-Repository Setup\n\n**Recommended:** Use a single MCP server instance for all beads projects - it automatically routes to per-project local daemons.\n\n### Single MCP Server (Recommended)\n\n**Simple config - works for all projects:**\n```json\n{\n  \"mcpServers\": {\n    \"beads\": {\n      \"command\": \"beads-mcp\"\n    }\n  }\n}\n```\n\n**How it works (LSP model):**\n1. MCP server checks for local daemon socket (`.beads/bd.sock`) in your current workspace\n2. Routes requests to the **per-project daemon** based on working directory\n3. Auto-starts the local daemon if not running\n4. **Each project gets its own isolated daemon** serving only its database\n\n**Architecture:**\n```\nMCP Server (one instance)\n    â†“\nPer-Project Daemons (one per workspace)\n    â†“\nSQLite Databases (complete isolation)\n```\n\n**Why per-project daemons?**\n- âœ… Complete database isolation between projects\n- âœ… No cross-project pollution or git worktree conflicts\n- âœ… Simpler mental model: one project = one database = one daemon\n- âœ… Follows LSP (Language Server Protocol) architecture\n- âœ… One MCP config works for unlimited projects\n\n**Note:** Global daemon support was removed in v0.16.0 to prevent cross-project database pollution.\n\n### Alternative: Per-Project MCP Instances (Not Recommended)\n\nConfigure separate MCP servers for specific projects using `BEADS_WORKING_DIR`:\n\n```json\n{\n  \"mcpServers\": {\n    \"beads-webapp\": {\n      \"command\": \"beads-mcp\",\n      \"env\": {\n        \"BEADS_WORKING_DIR\": \"/Users/yourname/projects/webapp\"\n      }\n    },\n    \"beads-api\": {\n      \"command\": \"beads-mcp\",\n      \"env\": {\n        \"BEADS_WORKING_DIR\": \"/Users/yourname/projects/api\"\n      }\n    }\n  }\n}\n```\n\nâš ï¸ **Problem**: AI may select the wrong MCP server for your workspace, causing commands to operate on the wrong database. Use single MCP server instead.\n\n## Multi-Project Support\n\nThe MCP server supports managing multiple beads projects in a single session using per-request workspace routing.\n\n### Using `workspace_root` Parameter\n\nEvery tool accepts an optional `workspace_root` parameter for explicit project targeting:\n\n```python\n# Query issues from different projects concurrently\nresults = await asyncio.gather(\n    beads_ready_work(workspace_root=\"/Users/you/project-a\"),\n    beads_ready_work(workspace_root=\"/Users/you/project-b\"),\n)\n\n# Create issue in specific project\nawait beads_create_issue(\n    title=\"Fix auth bug\",\n    priority=1,\n    workspace_root=\"/Users/you/project-a\"\n)\n```\n\n### Architecture\n\n**Connection Pool**: The MCP server maintains a connection pool keyed by canonical workspace path:\n- Each workspace gets its own daemon socket connection\n- Paths are canonicalized (symlinks resolved, git toplevel detected)\n- Concurrent requests use `asyncio.Lock` to prevent race conditions\n- No LRU eviction (keeps all connections open for session)\n\n**ContextVar Routing**: Per-request workspace context is managed via Python's `ContextVar`:\n- Each tool call sets the workspace for its duration\n- Properly isolated for concurrent calls (no cross-contamination)\n- Falls back to `BEADS_WORKING_DIR` if `workspace_root` not provided\n\n**Path Canonicalization**:\n- Symlinks are resolved to physical paths (prevents duplicate connections)\n- Git submodules with `.beads` directories use local context\n- Git toplevel is used for non-initialized directories\n- Results are cached for performance\n\n### Backward Compatibility\n\nThe `set_context()` tool still works and sets a default workspace:\n\n```python\n# Old way (still supported)\nawait set_context(workspace_root=\"/Users/you/project-a\")\nawait beads_ready_work()  # Uses project-a\n\n# New way (more flexible)\nawait beads_ready_work(workspace_root=\"/Users/you/project-a\")\n```\n\n### Concurrency Gotchas\n\nâš ï¸ **IMPORTANT**: Tool implementations must NOT spawn background tasks using `asyncio.create_task()`.\n\n**Why?** ContextVar doesn't propagate to spawned tasks, which can cause cross-project data leakage.\n\n**Solution**: Keep all tool logic synchronous or use sequential `await` calls.\n\n### Troubleshooting\n\n**Symlink aliasing**: Different paths to same project are deduplicated automatically via `realpath`.\n\n**Submodule handling**: Submodules with their own `.beads` directory are treated as separate projects.\n\n**Stale sockets**: Currently no health checks. Phase 2 will add retry-on-failure if monitoring shows need.\n\n**Version mismatches**: Daemon version is auto-checked since v0.16.0. Mismatched daemons are automatically restarted.\n\n## Features\n\n**Resource:**\n- `beads://quickstart` - Quickstart guide for using beads\n\n**Tools (all support `workspace_root` parameter):**\n- `init` - Initialize bd in current directory\n- `create` - Create new issue (bug, feature, task, epic, chore)\n- `list` - List issues with filters (status, priority, type, assignee)\n- `ready` - Find tasks with no blockers ready to work on\n- `show` - Show detailed issue info including dependencies\n- `update` - Update issue (status, priority, design, notes, etc). Note: `status=\"closed\"` or `status=\"open\"` automatically route to `close` or `reopen` tools to respect approval workflows\n- `close` - Close completed issue\n- `dep` - Add dependency (blocks, related, parent-child, discovered-from)\n- `blocked` - Get blocked issues\n- `stats` - Get project statistics\n- `reopen` - Reopen a closed issue with optional reason\n- `set_context` - Set default workspace for subsequent calls (backward compatibility)\n\n## Known Issues\n\n### ~~MCP Tools Not Loading in Claude Code~~ (Issue [#346](https://github.com/steveyegge/beads/issues/346)) - RESOLVED\n\n**Status:** âœ… Fixed in v0.24.0+\n\nThis issue affected versions prior to v0.24.0. The problem was caused by self-referential Pydantic models (`Issue` with `dependencies: list[\"Issue\"]`) generating invalid MCP schemas with `$ref` at root level.\n\n**Solution:** The issue was fixed in commit f3a678f by refactoring the data models:\n- Created `IssueBase` with common fields\n- Created `LinkedIssue(IssueBase)` for dependency references\n- Changed `Issue` to use `list[LinkedIssue]` instead of `list[\"Issue\"]`\n\nThis breaks the circular reference and ensures all tool outputSchemas have `type: object` at root level.\n\n**Upgrade:** If you're running beads-mcp < 0.24.0:\n```bash\npip install --upgrade beads-mcp\n```\n\nAll MCP tools now load correctly in Claude Code with v0.24.0+.\n\n\n## Development\n\nRun MCP inspector:\n```bash\n# inside beads-mcp dir\nuv run fastmcp dev src/beads_mcp/server.py\n```\n\nType checking:\n```bash\nuv run mypy src/beads_mcp\n```\n\nLinting and formatting:\n```bash\nuv run ruff check src/beads_mcp\nuv run ruff format src/beads_mcp\n```\n\n## Testing\n\nRun all tests:\n```bash\nuv run pytest\n```\n\nWith coverage:\n```bash\nuv run pytest --cov=beads_mcp tests/\n```\n\nTest suite includes both mocked unit tests and integration tests with real `bd` CLI.\n\n### Multi-Repo Integration Test\n\nTest daemon RPC with multiple repositories:\n```bash\n# Start the daemon first\ncd /path/to/beads\n./bd daemon --start\n\n# Run multi-repo test\ncd integrations/beads-mcp\nuv run python test_multi_repo.py\n```\n\nThis test verifies that the daemon can handle operations across multiple repositories simultaneously using per-request context routing.\n",
        "integrations/claude-code/README.md": "# Claude Code Integration for Beads\n\nSlash command for converting [Claude Code](https://docs.anthropic.com/en/docs/claude-code) plans to beads tasks.\n\n## Prerequisites\n\n```bash\n# Install beads\ncurl -fsSL https://raw.githubusercontent.com/steveyegge/beads/main/scripts/install.sh | bash\n\n# Install hooks (auto-injects workflow context on session start)\nbd setup claude\n```\n\n## Installation\n\n```bash\ncp commands/plan-to-beads.md ~/.claude/commands/\n```\n\nOptionally add to `~/.claude/settings.json` under `permissions.allow`:\n\n```json\n\"Bash(bd:*)\"\n```\n\n## /plan-to-beads\n\nConverts a Claude Code plan file into a beads epic with tasks.\n\n```\n/plan-to-beads                    # Convert most recent plan\n/plan-to-beads path/to/plan.md    # Convert specific plan\n```\n\n**What it does:**\n- Parses plan structure (title, summary, phases)\n- Creates an epic for the plan\n- Creates tasks from each phase\n- Sets up sequential dependencies\n- Uses Task agent delegation for context efficiency\n\n**Example output:**\n```\nCreated from: peaceful-munching-spark.md\n\nEpic: Standardize ID Generation (bd-abc)\n  â”œâ”€â”€ Add dependency (bd-def) - ready\n  â”œâ”€â”€ Create ID utility (bd-ghi) - blocked by bd-def\n  â””â”€â”€ Update schema (bd-jkl) - blocked by bd-ghi\n\nTotal: 4 tasks\nRun `bd ready` to start.\n```\n\n## Related\n\n- `bd prime` - Workflow context (auto-injected via hooks)\n- `bd setup claude` - Install/manage Claude Code hooks\n- `bd ready` - Find unblocked work\n\n## License\n\nSame as beads (see repository root).\n",
        "integrations/claude-code/commands/plan-to-beads.md": "# Convert Plan to Beads Tasks\n\n## description:\nConvert a Claude Code plan file into beads epic + tasks for cross-session tracking.\n\n## Arguments\n$ARGUMENTS (optional - path to plan file, defaults to most recent in ~/.claude/plans/)\n\n---\n\nUse the **Task tool** with `subagent_type='general-purpose'` to convert the plan.\n\n## Agent Instructions\n\nThe agent should:\n\n1. **Find the plan file**\n   - If argument provided, use that path\n   - Otherwise: `ls -t ~/.claude/plans/*.md | head -1`\n\n2. **Parse the plan structure**\n   - Title: First `# Plan:` or `#` heading\n   - Description: Content under `## Summary`\n   - Tasks: Each `### Phase N:` or `### N.` section\n   - File list: Include in epic description\n\n3. **Create the epic**\n   ```bash\n   bd create \"[Plan Title]\" -t epic -p 1 -d \"[summary]. Files: N to modify.\" --json\n   ```\n\n4. **Create tasks from phases**\n   - Each phase becomes a task\n   - Use first paragraph of phase content as description\n   ```bash\n   bd create \"[Phase title]\" -t task -p 2 -d \"[description]\" --json\n   ```\n\n5. **Add sequential dependencies**\n   - Phases are sequential: `bd dep add <phase2> <phase1>`\n\n6. **Link tasks to epic**\n   - `bd dep add <epic> <task>` for each task\n\n7. **Return a concise summary** (not raw output):\n   ```\n   Created from: [filename]\n\n   Epic: [title] ([epic-id])\n     â”œâ”€â”€ [Phase 1] ([id]) - ready\n     â”œâ”€â”€ [Phase 2] ([id]) - blocked by [prev]\n     â””â”€â”€ [Phase 3] ([id]) - blocked by [prev]\n\n   Total: [N] tasks\n   Run `bd ready` to start.\n   ```\n\n## Notes\n\n- Original plan file is preserved for reference\n- Task descriptions use first paragraph only (keeps them scannable)\n- Sequential phases get automatic dependencies\n",
        "internal/hooks/hooks.go": "// Package hooks provides a hook system for extensibility.\n// Hooks are executable scripts in .beads/hooks/ that run after certain events.\npackage hooks\n\nimport (\n\t\"os\"\n\t\"path/filepath\"\n\t\"time\"\n\n\t\"github.com/steveyegge/beads/internal/types\"\n)\n\n// Event types\nconst (\n\tEventCreate = \"create\"\n\tEventUpdate = \"update\"\n\tEventClose  = \"close\"\n)\n\n// Hook file names\nconst (\n\tHookOnCreate = \"on_create\"\n\tHookOnUpdate = \"on_update\"\n\tHookOnClose  = \"on_close\"\n)\n\n// Runner handles hook execution\ntype Runner struct {\n\thooksDir string\n\ttimeout  time.Duration\n}\n\n// NewRunner creates a new hook runner.\n// hooksDir is typically .beads/hooks/ relative to workspace root.\nfunc NewRunner(hooksDir string) *Runner {\n\treturn &Runner{\n\t\thooksDir: hooksDir,\n\t\ttimeout:  10 * time.Second,\n\t}\n}\n\n// NewRunnerFromWorkspace creates a hook runner for a workspace.\nfunc NewRunnerFromWorkspace(workspaceRoot string) *Runner {\n\treturn NewRunner(filepath.Join(workspaceRoot, \".beads\", \"hooks\"))\n}\n\n// Run executes a hook if it exists.\n// Runs asynchronously - returns immediately, hook runs in background.\nfunc (r *Runner) Run(event string, issue *types.Issue) {\n\thookName := eventToHook(event)\n\tif hookName == \"\" {\n\t\treturn\n\t}\n\n\thookPath := filepath.Join(r.hooksDir, hookName)\n\n\t// Check if hook exists and is executable\n\tinfo, err := os.Stat(hookPath)\n\tif err != nil || info.IsDir() {\n\t\treturn // Hook doesn't exist, skip silently\n\t}\n\n\t// Check if executable (Unix)\n\tif info.Mode()&0111 == 0 {\n\t\treturn // Not executable, skip\n\t}\n\n\t// Run asynchronously (ignore error as this is fire-and-forget)\n\tgo func() {\n\t\t_ = r.runHook(hookPath, event, issue)\n\t}()\n}\n\n// RunSync executes a hook synchronously and returns any error.\n// Useful for testing or when you need to wait for the hook.\nfunc (r *Runner) RunSync(event string, issue *types.Issue) error {\n\thookName := eventToHook(event)\n\tif hookName == \"\" {\n\t\treturn nil\n\t}\n\n\thookPath := filepath.Join(r.hooksDir, hookName)\n\n\t// Check if hook exists and is executable\n\tinfo, err := os.Stat(hookPath)\n\tif err != nil || info.IsDir() {\n\t\treturn nil // Hook doesn't exist, skip silently\n\t}\n\n\tif info.Mode()&0111 == 0 {\n\t\treturn nil // Not executable, skip\n\t}\n\n\treturn r.runHook(hookPath, event, issue)\n}\n\n// HookExists checks if a hook exists for an event\nfunc (r *Runner) HookExists(event string) bool {\n\thookName := eventToHook(event)\n\tif hookName == \"\" {\n\t\treturn false\n\t}\n\n\thookPath := filepath.Join(r.hooksDir, hookName)\n\tinfo, err := os.Stat(hookPath)\n\tif err != nil || info.IsDir() {\n\t\treturn false\n\t}\n\n\treturn info.Mode()&0111 != 0\n}\n\nfunc eventToHook(event string) string {\n\tswitch event {\n\tcase EventCreate:\n\t\treturn HookOnCreate\n\tcase EventUpdate:\n\t\treturn HookOnUpdate\n\tcase EventClose:\n\t\treturn HookOnClose\n\tdefault:\n\t\treturn \"\"\n\t}\n}\n",
        "internal/hooks/hooks_test.go": "package hooks\n\nimport (\n\t\"os\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"strconv\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/steveyegge/beads/internal/types\"\n)\n\nfunc TestNewRunner(t *testing.T) {\n\trunner := NewRunner(\"/tmp/hooks\")\n\tif runner == nil {\n\t\tt.Fatal(\"NewRunner returned nil\")\n\t}\n\tif runner.hooksDir != \"/tmp/hooks\" {\n\t\tt.Errorf(\"hooksDir = %q, want %q\", runner.hooksDir, \"/tmp/hooks\")\n\t}\n\tif runner.timeout != 10*time.Second {\n\t\tt.Errorf(\"timeout = %v, want %v\", runner.timeout, 10*time.Second)\n\t}\n}\n\nfunc TestNewRunnerFromWorkspace(t *testing.T) {\n\trunner := NewRunnerFromWorkspace(\"/workspace\")\n\tif runner == nil {\n\t\tt.Fatal(\"NewRunnerFromWorkspace returned nil\")\n\t}\n\texpected := filepath.Join(\"/workspace\", \".beads\", \"hooks\")\n\tif runner.hooksDir != expected {\n\t\tt.Errorf(\"hooksDir = %q, want %q\", runner.hooksDir, expected)\n\t}\n}\n\nfunc TestEventToHook(t *testing.T) {\n\ttests := []struct {\n\t\tevent    string\n\t\texpected string\n\t}{\n\t\t{EventCreate, HookOnCreate},\n\t\t{EventUpdate, HookOnUpdate},\n\t\t{EventClose, HookOnClose},\n\t\t{\"unknown\", \"\"},\n\t\t{\"\", \"\"},\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(tt.event, func(t *testing.T) {\n\t\t\tresult := eventToHook(tt.event)\n\t\t\tif result != tt.expected {\n\t\t\t\tt.Errorf(\"eventToHook(%q) = %q, want %q\", tt.event, result, tt.expected)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestHookExists_NoHook(t *testing.T) {\n\ttmpDir := t.TempDir()\n\trunner := NewRunner(tmpDir)\n\n\tif runner.HookExists(EventCreate) {\n\t\tt.Error(\"HookExists returned true for non-existent hook\")\n\t}\n}\n\nfunc TestHookExists_NotExecutable(t *testing.T) {\n\ttmpDir := t.TempDir()\n\thookPath := filepath.Join(tmpDir, HookOnCreate)\n\n\t// Create a non-executable file\n\tif err := os.WriteFile(hookPath, []byte(\"#!/bin/sh\\necho test\"), 0644); err != nil {\n\t\tt.Fatalf(\"Failed to create hook file: %v\", err)\n\t}\n\n\trunner := NewRunner(tmpDir)\n\n\tif runner.HookExists(EventCreate) {\n\t\tt.Error(\"HookExists returned true for non-executable hook\")\n\t}\n}\n\nfunc TestHookExists_Executable(t *testing.T) {\n\ttmpDir := t.TempDir()\n\thookPath := filepath.Join(tmpDir, HookOnCreate)\n\n\t// Create an executable file\n\tif err := os.WriteFile(hookPath, []byte(\"#!/bin/sh\\necho test\"), 0755); err != nil {\n\t\tt.Fatalf(\"Failed to create hook file: %v\", err)\n\t}\n\n\trunner := NewRunner(tmpDir)\n\n\tif !runner.HookExists(EventCreate) {\n\t\tt.Error(\"HookExists returned false for executable hook\")\n\t}\n}\n\nfunc TestHookExists_Directory(t *testing.T) {\n\ttmpDir := t.TempDir()\n\thookPath := filepath.Join(tmpDir, HookOnCreate)\n\n\t// Create a directory instead of a file\n\tif err := os.MkdirAll(hookPath, 0755); err != nil {\n\t\tt.Fatalf(\"Failed to create directory: %v\", err)\n\t}\n\n\trunner := NewRunner(tmpDir)\n\n\tif runner.HookExists(EventCreate) {\n\t\tt.Error(\"HookExists returned true for directory\")\n\t}\n}\n\nfunc TestRunSync_NoHook(t *testing.T) {\n\ttmpDir := t.TempDir()\n\trunner := NewRunner(tmpDir)\n\n\tissue := &types.Issue{ID: \"bd-test\", Title: \"Test\"}\n\n\t// Should not error when hook doesn't exist\n\terr := runner.RunSync(EventCreate, issue)\n\tif err != nil {\n\t\tt.Errorf(\"RunSync returned error for non-existent hook: %v\", err)\n\t}\n}\n\nfunc TestRunSync_NotExecutable(t *testing.T) {\n\ttmpDir := t.TempDir()\n\thookPath := filepath.Join(tmpDir, HookOnCreate)\n\n\t// Create a non-executable file\n\tif err := os.WriteFile(hookPath, []byte(\"#!/bin/sh\\necho test\"), 0644); err != nil {\n\t\tt.Fatalf(\"Failed to create hook file: %v\", err)\n\t}\n\n\trunner := NewRunner(tmpDir)\n\tissue := &types.Issue{ID: \"bd-test\", Title: \"Test\"}\n\n\t// Should not error when hook is not executable\n\terr := runner.RunSync(EventCreate, issue)\n\tif err != nil {\n\t\tt.Errorf(\"RunSync returned error for non-executable hook: %v\", err)\n\t}\n}\n\nfunc TestRunSync_Success(t *testing.T) {\n\ttmpDir := t.TempDir()\n\thookPath := filepath.Join(tmpDir, HookOnCreate)\n\toutputFile := filepath.Join(tmpDir, \"output.txt\")\n\n\t// Create a hook that writes to a file\n\thookScript := `#!/bin/sh\necho \"$1 $2\" > ` + outputFile\n\tif err := os.WriteFile(hookPath, []byte(hookScript), 0755); err != nil {\n\t\tt.Fatalf(\"Failed to create hook file: %v\", err)\n\t}\n\n\trunner := NewRunner(tmpDir)\n\tissue := &types.Issue{ID: \"bd-test\", Title: \"Test Issue\"}\n\n\terr := runner.RunSync(EventCreate, issue)\n\tif err != nil {\n\t\tt.Errorf(\"RunSync returned error: %v\", err)\n\t}\n\n\t// Verify the hook ran and received correct arguments\n\toutput, err := os.ReadFile(outputFile)\n\tif err != nil {\n\t\tt.Fatalf(\"Failed to read output file: %v\", err)\n\t}\n\n\texpected := \"bd-test create\\n\"\n\tif string(output) != expected {\n\t\tt.Errorf(\"Hook output = %q, want %q\", string(output), expected)\n\t}\n}\n\nfunc TestRunSync_ReceivesJSON(t *testing.T) {\n\ttmpDir := t.TempDir()\n\thookPath := filepath.Join(tmpDir, HookOnCreate)\n\toutputFile := filepath.Join(tmpDir, \"stdin.txt\")\n\n\t// Create a hook that captures stdin\n\thookScript := `#!/bin/sh\ncat > ` + outputFile\n\tif err := os.WriteFile(hookPath, []byte(hookScript), 0755); err != nil {\n\t\tt.Fatalf(\"Failed to create hook file: %v\", err)\n\t}\n\n\trunner := NewRunner(tmpDir)\n\tissue := &types.Issue{\n\t\tID:       \"bd-test\",\n\t\tTitle:    \"Test Issue\",\n\t\tAssignee: \"bob\",\n\t}\n\n\terr := runner.RunSync(EventCreate, issue)\n\tif err != nil {\n\t\tt.Errorf(\"RunSync returned error: %v\", err)\n\t}\n\n\t// Verify JSON was passed to stdin\n\toutput, err := os.ReadFile(outputFile)\n\tif err != nil {\n\t\tt.Fatalf(\"Failed to read output file: %v\", err)\n\t}\n\n\t// Just check that it contains expected fields\n\tif len(output) == 0 {\n\t\tt.Error(\"Hook did not receive JSON input\")\n\t}\n\tif string(output) == \"\" || output[0] != '{' {\n\t\tt.Errorf(\"Hook input doesn't look like JSON: %s\", string(output))\n\t}\n}\n\nfunc TestRunSync_Timeout(t *testing.T) {\n\tif testing.Short() {\n\t\tt.Skip(\"Skipping timeout test in short mode\")\n\t}\n\n\ttmpDir := t.TempDir()\n\thookPath := filepath.Join(tmpDir, HookOnCreate)\n\n\t// Create a hook that sleeps for longer than timeout\n\thookScript := `#!/bin/sh\nsleep 60`\n\tif err := os.WriteFile(hookPath, []byte(hookScript), 0755); err != nil {\n\t\tt.Fatalf(\"Failed to create hook file: %v\", err)\n\t}\n\n\trunner := &Runner{\n\t\thooksDir: tmpDir,\n\t\ttimeout:  500 * time.Millisecond, // Short timeout\n\t}\n\tissue := &types.Issue{ID: \"bd-test\", Title: \"Test\"}\n\n\tstart := time.Now()\n\terr := runner.RunSync(EventCreate, issue)\n\telapsed := time.Since(start)\n\n\tif err == nil {\n\t\tt.Error(\"RunSync should have returned error for timeout\")\n\t}\n\n\t// Should have returned within timeout + some buffer\n\tif elapsed > 5*time.Second {\n\t\tt.Errorf(\"RunSync took too long: %v\", elapsed)\n\t}\n}\n\nfunc TestRunSync_KillsDescendants(t *testing.T) {\n\tif runtime.GOOS != \"linux\" {\n\t\tt.Skip(\"TestRunSync_KillsDescendants requires Linux /proc\")\n\t}\n\n\tif testing.Short() {\n\t\tt.Skip(\"Skipping long-running descendant kill test in short mode\")\n\t}\n\n\ttmpDir := t.TempDir()\n\thookPath := filepath.Join(tmpDir, HookOnCreate)\n\tpidFile := filepath.Join(tmpDir, \"child.pid\")\n\n\t// Hook starts a background sleep, writes its pid, and waits for it.\n\t// Parent will remain alive until the child exits, so killing the\n\t// process group should terminate both.\n\thookScript := `#!/bin/sh\n(sleep 60 & echo $! > ` + pidFile + ` ; wait)`\n\tif err := os.WriteFile(hookPath, []byte(hookScript), 0755); err != nil {\n\t\tt.Fatalf(\"Failed to create hook file: %v\", err)\n\t}\n\n\trunner := &Runner{\n\t\thooksDir: tmpDir,\n\t\ttimeout:  500 * time.Millisecond,\n\t}\n\tissue := &types.Issue{ID: \"bd-test\", Title: \"Test\"}\n\n\terr := runner.RunSync(EventCreate, issue)\n\tif err == nil {\n\t\tt.Fatal(\"Expected RunSync to return an error on timeout\")\n\t}\n\n\t// Read the child PID and ensure it's not running anymore.\n\tdata, err := os.ReadFile(pidFile)\n\tif err != nil {\n\t\tt.Fatalf(\"Failed to read pid file: %v\", err)\n\t}\n\tpidStr := strings.TrimSpace(string(data))\n\tpid, err := strconv.Atoi(pidStr)\n\tif err != nil {\n\t\tt.Fatalf(\"Invalid pid in pid file: %v\", err)\n\t}\n\n\t// Check /proc/<pid> does not exist - retry a few times in case of timing\n\tfor i := 0; i < 10; i++ {\n\t\tif _, err := os.Stat(filepath.Join(\"/proc\", strconv.Itoa(pid))); err != nil {\n\t\t\t// Process is gone, test passed\n\t\t\treturn\n\t\t}\n\t\ttime.Sleep(100 * time.Millisecond)\n\t}\n\n\t// If we get here, the process is still running\n\tt.Fatalf(\"Child process %d still exists after timeout\", pid)\n}\n\nfunc TestRunSync_HookFailure(t *testing.T) {\n\ttmpDir := t.TempDir()\n\thookPath := filepath.Join(tmpDir, HookOnUpdate)\n\n\t// Create a hook that exits with error\n\thookScript := `#!/bin/sh\nexit 1`\n\tif err := os.WriteFile(hookPath, []byte(hookScript), 0755); err != nil {\n\t\tt.Fatalf(\"Failed to create hook file: %v\", err)\n\t}\n\n\trunner := NewRunner(tmpDir)\n\tissue := &types.Issue{ID: \"bd-test\", Title: \"Test\"}\n\n\terr := runner.RunSync(EventUpdate, issue)\n\tif err == nil {\n\t\tt.Error(\"RunSync should have returned error for failed hook\")\n\t}\n}\n\nfunc TestRun_Async(t *testing.T) {\n\ttmpDir := t.TempDir()\n\thookPath := filepath.Join(tmpDir, HookOnClose)\n\toutputFile := filepath.Join(tmpDir, \"async_output.txt\")\n\n\t// Create a hook that writes to a file\n\thookScript := \"#!/bin/sh\\n\" +\n\t\t\"echo \\\"async\\\" > \\\"\" + outputFile + \"\\\"\\n\"\n\tif err := os.WriteFile(hookPath, []byte(hookScript), 0755); err != nil {\n\t\tt.Fatalf(\"Failed to create hook file: %v\", err)\n\t}\n\n\trunner := NewRunner(tmpDir)\n\tissue := &types.Issue{ID: \"bd-test\", Title: \"Test\"}\n\n\t// Run should return immediately\n\trunner.Run(EventClose, issue)\n\n\t// Wait for the async hook to complete with retries.\n\t// Under high test load the goroutine scheduling + exec can be delayed.\n\tvar output []byte\n\tvar err error\n\tdeadline := time.Now().Add(3 * time.Second)\n\tfor time.Now().Before(deadline) {\n\t\toutput, err = os.ReadFile(outputFile)\n\t\tif err == nil {\n\t\t\tbreak\n\t\t}\n\t\ttime.Sleep(50 * time.Millisecond)\n\t}\n\n\tif err != nil {\n\t\tt.Fatalf(\"Failed to read output file after retries: %v\", err)\n\t}\n\n\texpected := \"async\\n\"\n\tif string(output) != expected {\n\t\tt.Errorf(\"Hook output = %q, want %q\", string(output), expected)\n\t}\n}\n\nfunc TestAllHookEvents(t *testing.T) {\n\t// Verify all event constants have corresponding hook names\n\tevents := []struct {\n\t\tevent string\n\t\thook  string\n\t}{\n\t\t{EventCreate, HookOnCreate},\n\t\t{EventUpdate, HookOnUpdate},\n\t\t{EventClose, HookOnClose},\n\t}\n\n\tfor _, e := range events {\n\t\tt.Run(e.event, func(t *testing.T) {\n\t\t\tresult := eventToHook(e.event)\n\t\t\tif result != e.hook {\n\t\t\t\tt.Errorf(\"eventToHook(%q) = %q, want %q\", e.event, result, e.hook)\n\t\t\t}\n\t\t})\n\t}\n}\n",
        "internal/hooks/hooks_unix.go": "//go:build unix\n\npackage hooks\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"os/exec\"\n\t\"syscall\"\n\n\t\"github.com/steveyegge/beads/internal/types\"\n)\n\n// runHook executes the hook and enforces a timeout, killing the process group\n// on expiration to ensure descendant processes are terminated.\nfunc (r *Runner) runHook(hookPath, event string, issue *types.Issue) error {\n\tctx, cancel := context.WithTimeout(context.Background(), r.timeout)\n\tdefer cancel()\n\n\t// Prepare JSON data for stdin\n\tissueJSON, err := json.Marshal(issue)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Create command: hook_script <issue_id> <event_type>\n\t// #nosec G204 -- hookPath is from controlled .beads/hooks directory\n\tcmd := exec.CommandContext(ctx, hookPath, issue.ID, event)\n\tcmd.Stdin = bytes.NewReader(issueJSON)\n\n\t// Capture output for debugging (but don't block on it)\n\tvar stdout, stderr bytes.Buffer\n\tcmd.Stdout = &stdout\n\tcmd.Stderr = &stderr\n\n\t// Start the hook so we can manage its process group and kill children on timeout.\n\t//\n\t// Rationale: scripts may spawn child processes (backgrounded or otherwise).\n\t// If we only kill the immediate process, descendants may survive and keep\n\t// the test (or caller) blocked â€” this was exposed by TestRunSync_Timeout and\n\t// validated by TestRunSync_KillsDescendants. Creating a process group (Setpgid)\n\t// and sending a negative PID to syscall.Kill ensures the entire group\n\t// (parent + children) are killed reliably on timeout.\n\tcmd.SysProcAttr = &syscall.SysProcAttr{Setpgid: true}\n\n\tif err := cmd.Start(); err != nil {\n\t\treturn err\n\t}\n\n\tdone := make(chan error, 1)\n\tgo func() {\n\t\tdone <- cmd.Wait()\n\t}()\n\n\tselect {\n\tcase <-ctx.Done():\n\t\tif cmd.Process != nil {\n\t\t\tif err := syscall.Kill(-cmd.Process.Pid, syscall.SIGKILL); err != nil && !errors.Is(err, syscall.ESRCH) {\n\t\t\t\treturn fmt.Errorf(\"kill process group: %w\", err)\n\t\t\t}\n\t\t}\n\t\t// Wait for process to exit after the kill attempt\n\t\t<-done\n\t\treturn ctx.Err()\n\tcase err := <-done:\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn nil\n\t}\n}\n",
        "internal/hooks/hooks_windows.go": "//go:build windows\n\npackage hooks\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"os/exec\"\n\n\t\"github.com/steveyegge/beads/internal/types\"\n)\n\n// runHook executes the hook and enforces a timeout on Windows.\n// Windows lacks Unix-style process groups; on timeout we best-effort kill\n// the started process. Descendant processes may survive if they detach,\n// but this preserves previous behavior while keeping tests green on Windows.\nfunc (r *Runner) runHook(hookPath, event string, issue *types.Issue) error {\n\tctx, cancel := context.WithTimeout(context.Background(), r.timeout)\n\tdefer cancel()\n\n\tissueJSON, err := json.Marshal(issue)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tcmd := exec.CommandContext(ctx, hookPath, issue.ID, event)\n\tcmd.Stdin = bytes.NewReader(issueJSON)\n\n\tvar stdout, stderr bytes.Buffer\n\tcmd.Stdout = &stdout\n\tcmd.Stderr = &stderr\n\n\tif err := cmd.Start(); err != nil {\n\t\treturn err\n\t}\n\n\tdone := make(chan error, 1)\n\tgo func() {\n\t\tdone <- cmd.Wait()\n\t}()\n\n\tselect {\n\tcase <-ctx.Done():\n\t\tif cmd.Process != nil {\n\t\t\t_ = cmd.Process.Kill()\n\t\t}\n\t\t<-done\n\t\treturn ctx.Err()\n\tcase err := <-done:\n\t\treturn err\n\t}\n}\n",
        "npm-package/README.md": "# @beads/bd - Beads Issue Tracker\n\n[![npm version](https://img.shields.io/npm/v/@beads/bd)](https://www.npmjs.com/package/@beads/bd)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n**Give your coding agent a memory upgrade**\n\nBeads is a lightweight memory system for coding agents, using a graph-based issue tracker. This npm package provides easy installation of the native bd binary for Node.js environments, including Claude Code for Web.\n\n## Installation\n\n```bash\nnpm install -g @beads/bd\n```\n\nOr as a project dependency:\n\n```bash\nnpm install --save-dev @beads/bd\n```\n\n## What is Beads?\n\nBeads is an issue tracker designed specifically for AI coding agents. It provides:\n\n- âœ¨ **Zero setup** - `bd init` creates project-local database\n- ğŸ”— **Dependency tracking** - Four dependency types (blocks, related, parent-child, discovered-from)\n- ğŸ“‹ **Ready work detection** - Automatically finds issues with no open blockers\n- ğŸ¤– **Agent-friendly** - `--json` flags for programmatic integration\n- ğŸ“¦ **Git-versioned** - JSONL records stored in git, synced across machines\n- ğŸŒ **Distributed by design** - Share one logical database via git\n\n## Quick Start\n\nAfter installation, initialize beads in your project:\n\n```bash\nbd init\n```\n\nThen tell your AI agent to use bd for task tracking instead of markdown:\n\n```bash\necho \"Use 'bd' commands for issue tracking instead of markdown TODOs\" >> AGENTS.md\n```\n\nYour agent will automatically:\n- Create and track issues during work\n- Manage dependencies between tasks\n- Find ready work with `bd ready`\n- Keep long-term context across sessions\n\n## Common Commands\n\n```bash\n# Find ready work\nbd ready --json\n\n# Create an issue\nbd create \"Fix bug\" -t bug -p 1\n\n# Show issue details\nbd show bd-a1b2\n\n# List all issues\nbd list --json\n\n# Update status\nbd update bd-a1b2 --status in_progress\n\n# Add dependency\nbd dep add bd-f14c bd-a1b2\n\n# Close issue\nbd close bd-a1b2 --reason \"Fixed\"\n```\n\n## Claude Code for Web Integration\n\nTo auto-install bd in Claude Code for Web sessions, add to your SessionStart hook:\n\n```bash\n# .claude/hooks/session-start.sh\nnpm install -g @beads/bd\nbd init --quiet\n```\n\nThis ensures bd is available in every new session without manual setup.\n\n## Platform Support\n\nThis package downloads the appropriate native binary for your platform:\n\n- **macOS**: darwin-amd64, darwin-arm64\n- **Linux**: linux-amd64, linux-arm64\n- **Windows**: windows-amd64\n\n## Full Documentation\n\nFor complete documentation, see the [beads GitHub repository](https://github.com/steveyegge/beads):\n\n- [Complete README](https://github.com/steveyegge/beads#readme)\n- [Quick Start Guide](https://github.com/steveyegge/beads/blob/main/docs/QUICKSTART.md)\n- [Installation Guide](https://github.com/steveyegge/beads/blob/main/docs/INSTALLING.md)\n- [FAQ](https://github.com/steveyegge/beads/blob/main/docs/FAQ.md)\n- [Troubleshooting](https://github.com/steveyegge/beads/blob/main/docs/TROUBLESHOOTING.md)\n\n## Why npm Package vs WASM?\n\nThis npm package wraps the native bd binary rather than using WebAssembly because:\n\n- âœ… Full SQLite support (no custom VFS needed)\n- âœ… All features work identically to native bd\n- âœ… Better performance (native vs WASM overhead)\n- âœ… Simpler maintenance\n\n## License\n\nMIT - See [LICENSE](LICENSE) for details.\n\n## Support\n\n- [GitHub Issues](https://github.com/steveyegge/beads/issues)\n- [Documentation](https://github.com/steveyegge/beads)\n",
        "scripts/README.md": "# Beads Scripts\n\nUtility scripts for maintaining the beads project.\n\n## release.sh (â­ The Easy Button)\n\n**One-command release** from version bump to local installation.\n\n### Usage\n\n```bash\n# Full release (does everything)\n./scripts/release.sh 0.9.3\n\n# Preview what would happen\n./scripts/release.sh 0.9.3 --dry-run\n```\n\n### What It Does\n\nThis master script automates the **entire release process**:\n\n1. âœ… Kills running daemons (avoids version conflicts)\n2. âœ… Runs tests and linting\n3. âœ… Bumps version in all files\n4. âœ… Commits and pushes version bump\n5. âœ… Creates and pushes git tag\n6. âœ… Updates Homebrew formula\n7. âœ… Upgrades local brew installation\n8. âœ… Verifies everything works\n\n**After this script completes, your system is running the new version!**\n\n### Examples\n\n```bash\n# Release version 0.9.3\n./scripts/release.sh 0.9.3\n\n# Preview a release (no changes made)\n./scripts/release.sh 1.0.0 --dry-run\n```\n\n### Prerequisites\n\n- Clean git working directory\n- All changes committed\n- golangci-lint installed\n- Homebrew installed (for local upgrade)\n- Push access to steveyegge/beads and steveyegge/homebrew-beads\n\n### Output\n\nThe script provides colorful, step-by-step progress output:\n- ğŸŸ¨ Yellow: Current step\n- ğŸŸ© Green: Step completed\n- ğŸŸ¥ Red: Errors\n- ğŸŸ¦ Blue: Section headers\n\n### What Happens Next\n\nAfter the script finishes:\n- GitHub Actions builds binaries for all platforms (~5 minutes)\n- PyPI package is published automatically\n- Users can `brew upgrade bd` to get the new version\n- GitHub Release is created with binaries and changelog\n\n---\n\n## bump-version.sh\n\nBumps the version number across all beads components in a single command.\n\n### Usage\n\n```bash\n# Show usage\n./scripts/bump-version.sh\n\n# Update versions (shows diff, no commit)\n./scripts/bump-version.sh 0.9.3\n\n# Update versions and auto-commit\n./scripts/bump-version.sh 0.9.3 --commit\n```\n\n### What It Does\n\nUpdates version in all these files:\n- `cmd/bd/version.go` - bd CLI version constant\n- `.claude-plugin/plugin.json` - Plugin version\n- `.claude-plugin/marketplace.json` - Marketplace plugin version\n- `integrations/beads-mcp/pyproject.toml` - MCP server version\n- `README.md` - Alpha status version\n- `PLUGIN.md` - Version requirements\n\n### Features\n\n- **Validates** semantic versioning format (MAJOR.MINOR.PATCH)\n- **Verifies** all versions match after update\n- **Shows** git diff of changes\n- **Auto-commits** with standardized message (optional)\n- **Cross-platform** compatible (macOS and Linux)\n\n### Examples\n\n```bash\n# Bump to 0.9.3 and review changes\n./scripts/bump-version.sh 0.9.3\n# Review the diff, then manually commit\n\n# Bump to 1.0.0 and auto-commit\n./scripts/bump-version.sh 1.0.0 --commit\ngit push origin main\n```\n\n### Why This Script Exists\n\nPreviously, version bumps only updated `cmd/bd/version.go`, leaving other components out of sync. This script ensures all version numbers stay consistent across the project.\n\n### Safety\n\n- Checks for uncommitted changes before proceeding\n- Refuses to auto-commit if there are existing uncommitted changes\n- Validates version format before making any changes\n- Verifies all versions match after update\n- Shows diff for review before commit\n\n---\n\n## update-homebrew.sh\n\nAutomatically updates the Homebrew formula with GoReleaser release artifacts.\n\n### Usage\n\n```bash\n# Update formula after pushing git tag\n./scripts/update-homebrew.sh 0.9.3\n\n# Use custom tap directory\nTAP_DIR=~/homebrew-beads ./scripts/update-homebrew.sh 0.9.3\n```\n\n### What It Does\n\nThis script automates the Homebrew formula update process:\n\n1. **Waits** for GitHub Actions release build (~5 minutes, checks every 30s)\n2. **Downloads** checksums.txt from the GitHub release\n3. **Extracts** SHA256s for all platform-specific binaries:\n   - macOS ARM64 (Apple Silicon)\n   - macOS AMD64 (Intel)\n   - Linux AMD64\n   - Linux ARM64\n4. **Clones/updates** the homebrew-beads tap repository\n5. **Updates** Formula/bd.rb with new version and all SHA256s\n6. **Commits and pushes** the changes\n\n### Important Notes\n\n- **Run AFTER pushing the git tag** - the script waits for GitHub Actions to finish\n- **Uses GoReleaser artifacts**, not source tarballs (fixed in v0.23.0)\n- **Automatically waits** up to 7.5 minutes for release build to complete\n- **Updates all platforms** in a single operation\n\n### Examples\n\n```bash\n# Standard usage (after git tag push)\ngit tag v0.9.3 && git push origin v0.9.3\n./scripts/update-homebrew.sh 0.9.3\n\n# Custom tap directory\nTAP_DIR=/path/to/homebrew-beads ./scripts/update-homebrew.sh 0.9.3\n```\n\n### Why This Script Exists\n\nPreviously, the Homebrew formula update was manual and error-prone:\n- Used source tarball SHA256 instead of GoReleaser artifacts (wrong!)\n- Required manually computing 4 separate SHA256s\n- Easy to forget updating all platforms\n- No automation for waiting on GitHub Actions\n\nThis script fixes all those issues and is now used by `release.sh`.\n\n---\n\n## sign-windows.sh\n\nSigns Windows executables with an Authenticode certificate using osslsigncode.\n\n### Usage\n\n```bash\n# Sign a Windows executable\n./scripts/sign-windows.sh path/to/bd.exe\n\n# Environment variables required for signing:\nexport WINDOWS_SIGNING_CERT_PFX_BASE64=\"<base64-encoded-pfx>\"\nexport WINDOWS_SIGNING_CERT_PASSWORD=\"<certificate-password>\"\n```\n\n### What It Does\n\nThis script is called automatically by GoReleaser during the release process:\n\n1. **Decodes** the PFX certificate from base64\n2. **Signs** the Windows executable using osslsigncode\n3. **Timestamps** the signature using DigiCert's RFC3161 server\n4. **Replaces** the original binary with the signed version\n5. **Verifies** the signature was applied correctly\n\n### Prerequisites\n\n- `osslsigncode` installed (`apt install osslsigncode` or `brew install osslsigncode`)\n- EV code signing certificate exported as PFX file\n- GitHub secrets configured:\n  - `WINDOWS_SIGNING_CERT_PFX_BASE64` - base64-encoded PFX file\n  - `WINDOWS_SIGNING_CERT_PASSWORD` - certificate password\n\n### Graceful Degradation\n\nIf the signing secrets are not configured:\n- The script prints a warning and exits successfully\n- GoReleaser continues without signing\n- The release proceeds with unsigned Windows binaries\n\nThis allows releases to work before a certificate is acquired.\n\n### Why This Script Exists\n\nWindows code signing helps reduce antivirus false positives that affect Go binaries.\nKaspersky and other AV software commonly flag unsigned Go executables as potentially\nmalicious due to heuristic detection. See `docs/ANTIVIRUS.md` for details.\n\n---\n\n## Future Scripts\n\nAdditional maintenance scripts may be added here as needed.\n",
        "scripts/hooks/post-push": "#!/bin/bash\n# Post-push hook: Rebuild and install bd CLI after successful push\n\nset -e\n\n# Check if any Go files changed in the push\n# Use the reflog to find what was just pushed\nif git log --name-only -1 origin/main..HEAD 2>/dev/null | grep -q '\\.go$' || \\\n   git diff --name-only HEAD~1 HEAD 2>/dev/null | grep -q '\\.go$'; then\n    echo \"\"\n    echo \"Go files changed, rebuilding bd CLI...\"\n    go install ./cmd/bd\n    echo \"âœ“ bd CLI installed successfully\"\n    echo \"\"\nfi\n\nexit 0\n",
        "skills/beads/CLAUDE.md": "# Beads Skill Maintenance Guide\n\n## Architecture Decisions\n\nADRs in `adr/` document key decisions. These are NOT loaded during skill invocationâ€”they're reference material for maintainers making changes.\n\n| ADR | Decision |\n|-----|----------|\n| [ADR-0001](adr/0001-bd-prime-as-source-of-truth.md) | Use `bd prime` as CLI reference source of truth |\n\n## Key Principle: DRY via bd prime\n\n**NEVER duplicate CLI documentation in SKILL.md or resources.**\n\n- `bd prime` outputs AI-optimized workflow context\n- `bd <command> --help` provides specific usage\n- Both auto-update with bd releases\n\n**SKILL.md should only contain:**\n- Decision frameworks (bd vs TodoWrite)\n- Prerequisites (install verification)\n- Resource index (progressive disclosure)\n- Pointers to `bd prime` and `--help`\n\n## Keeping the Skill Updated\n\n### When bd releases new version:\n\n1. **Check for new features**: `bd --help` for new commands\n2. **Update SKILL.md frontmatter**: `version: \"X.Y.Z\"`\n3. **Add resources for conceptual features** (agents, gates, chemistry patterns)\n4. **Don't add CLI reference** â€” that's `bd prime`'s job\n\n### What belongs in resources:\n\n| Content Type | Belongs in Resources? | Why |\n|--------------|----------------------|-----|\n| Conceptual frameworks | âœ… Yes | bd prime doesn't explain \"when to use\" |\n| Decision trees | âœ… Yes | Cognitive guidance, not CLI reference |\n| Advanced patterns | âœ… Yes | Depth beyond `--help` |\n| CLI command syntax | âŒ No | Use `bd <cmd> --help` |\n| Workflow checklists | âŒ No | `bd prime` covers this |\n\n### Resource update checklist:\n\n```\n[ ] Check if bd prime now covers this content\n[ ] If yes, remove from resources (avoid duplication)\n[ ] If no, update resource for new bd version\n[ ] Update version compatibility in README.md\n```\n\n## File Roles\n\n| File | Purpose | When to Update |\n|------|---------|----------------|\n| SKILL.md | Entry point, resource index | New features, version bumps |\n| README.md | Human docs, installation | Structure changes |\n| CLAUDE.md | This file, maintenance guide | Architecture changes |\n| adr/*.md | Decision records | When making architectural decisions |\n| resources/*.md | Deep-dive guides | New conceptual content |\n\n## Testing Changes\n\nAfter skill updates:\n\n```bash\n# Verify SKILL.md is within token budget\nwc -w skills/beads/SKILL.md  # Target: 400-600 words\n\n# Verify links resolve\n# (Manual check: ensure all resource links in SKILL.md exist)\n\n# Verify bd prime still works\nbd prime | head -20\n```\n\n## Attribution\n\nResources adapted from other sources should include attribution header:\n\n```markdown\n# Resource Title\n\n> Adapted from [source]\n```\n",
        "skills/beads/README.md": "# Beads Skill for Claude Code\n\nA comprehensive skill for using [beads](https://github.com/steveyegge/beads) (bd) issue tracking with Claude Code.\n\n## What This Skill Does\n\nThis skill teaches Claude Code how to use bd effectively for:\n- **Multi-session work tracking** - Persistent memory across conversation compactions\n- **Dependency management** - Graph-based issue relationships\n- **Session handoff** - Writing notes that survive context resets\n- **Molecules and wisps** (v0.34.0+) - Reusable work templates and ephemeral workflows\n\n## Installation\n\nCopy the `beads/` directory to your Claude Code skills location:\n\n```bash\n# Global installation\ncp -r beads ~/.claude/skills/\n\n# Or project-local\ncp -r beads .claude/skills/\n```\n\n## When Claude Uses This Skill\n\nThe skill activates when conversations involve:\n- \"multi-session\", \"complex dependencies\", \"resume after weeks\"\n- \"project memory\", \"persistent context\", \"side quest tracking\"\n- Work that spans multiple days or compaction cycles\n- Tasks too complex for simple TodoWrite lists\n\n## File Structure\n\n```\nbeads/\nâ”œâ”€â”€ SKILL.md                 # Main skill file (Claude reads this first)\nâ”œâ”€â”€ CLAUDE.md                # Maintenance guide for updating the skill\nâ”œâ”€â”€ README.md                # This file (for humans)\nâ”œâ”€â”€ adr/                     # Architectural Decision Records\nâ”‚   â””â”€â”€ 0001-bd-prime-as-source-of-truth.md\nâ””â”€â”€ resources/               # Detailed documentation (loaded on demand)\n    â”œâ”€â”€ BOUNDARIES.md        # When to use bd vs TodoWrite\n    â”œâ”€â”€ CLI_REFERENCE.md     # CLI command reference\n    â”œâ”€â”€ DEPENDENCIES.md      # Dependency semantics (A blocks B vs B blocks A)\n    â”œâ”€â”€ INTEGRATION_PATTERNS.md # TodoWrite and other tool integration\n    â”œâ”€â”€ ISSUE_CREATION.md    # When and how to create issues\n    â”œâ”€â”€ MOLECULES.md         # Protos, mols, wisps (v0.34.0+)\n    â”œâ”€â”€ PATTERNS.md          # Common usage patterns\n    â”œâ”€â”€ RESUMABILITY.md      # Writing notes for post-compaction recovery\n    â”œâ”€â”€ STATIC_DATA.md       # Using bd for reference databases\n    â”œâ”€â”€ TROUBLESHOOTING.md   # Common issues and fixes\n    â”œâ”€â”€ WORKFLOWS.md         # Step-by-step workflow guides\n    â”œâ”€â”€ AGENTS.md            # Agent bead tracking (v0.40+)\n    â”œâ”€â”€ ASYNC_GATES.md       # Human-in-the-loop gates\n    â”œâ”€â”€ CHEMISTRY_PATTERNS.md # Mol vs Wisp decision tree\n    â””â”€â”€ WORKTREES.md         # Parallel development patterns\n```\n\n## Key Concepts\n\n### bd vs TodoWrite\n\n| Use bd when... | Use TodoWrite when... |\n|----------------|----------------------|\n| Work spans multiple sessions | Single-session tasks |\n| Complex dependencies exist | Linear step-by-step work |\n| Need to resume after weeks | Just need a quick checklist |\n| Knowledge work with fuzzy boundaries | Clear, immediate tasks |\n\n### The Dependency Direction Trap\n\n`bd dep add A B` means **\"A depends on B\"** (B must complete before A can start).\n\n```bash\n# Want: \"Setup must complete before Implementation\"\nbd dep add implementation setup  # âœ“ CORRECT\n# NOT: bd dep add setup implementation  # âœ— WRONG\n```\n\n### Surviving Compaction\n\nWhen Claude's context gets compacted, conversation history is lost but bd state survives. Write notes as if explaining to a future Claude with zero context:\n\n```bash\nbd update issue-123 --notes \"COMPLETED: JWT auth with RS256\nKEY DECISION: RS256 over HS256 for key rotation\nIN PROGRESS: Password reset flow\nNEXT: Implement rate limiting\"\n```\n\n## Requirements\n\n- [bd CLI](https://github.com/steveyegge/beads) installed (`brew install steveyegge/beads/bd`)\n- A git repository (bd requires git for sync)\n- Initialized database (`bd init` in project root)\n\n## Version Compatibility\n\n| Version | Features |\n|---------|----------|\n| v0.43.0+ | Full support: agents, gates, worktrees, chemistry patterns |\n| v0.40.0+ | Agent beads, async gates, worktree management |\n| v0.34.0+ | Molecules, wisps, cross-project dependencies |\n| v0.15.0+ | Core: dependencies, notes, status tracking |\n| Earlier | Basic functionality, some features missing |\n\n## Contributing\n\nThis skill is maintained at [github.com/steveyegge/beads](https://github.com/steveyegge/beads) in the `skills/beads/` directory.\n\nIssues and PRs welcome for:\n- Documentation improvements\n- New workflow patterns\n- Bug fixes in examples\n- Additional troubleshooting scenarios\n\n## License\n\nMIT (same as beads)\n",
        "skills/beads/SKILL.md": "---\nname: beads\ndescription: >\n  Git-backed issue tracker for multi-session work with dependencies and persistent\n  memory across conversation compaction. Use when work spans sessions, has blockers,\n  or needs context recovery after compaction.\nallowed-tools: \"Read,Bash(bd:*)\"\nversion: \"0.43.0\"\nauthor: \"Steve Yegge <https://github.com/steveyegge>\"\nlicense: \"MIT\"\n---\n\n# Beads - Persistent Task Memory for AI Agents\n\nGraph-based issue tracker that survives conversation compaction. Provides persistent memory for multi-session work with complex dependencies.\n\n## bd vs TodoWrite\n\n| bd (persistent) | TodoWrite (ephemeral) |\n|-----------------|----------------------|\n| Multi-session work | Single-session tasks |\n| Complex dependencies | Linear execution |\n| Survives compaction | Conversation-scoped |\n| Git-backed, team sync | Local to session |\n\n**Decision test**: \"Will I need this context in 2 weeks?\" â†’ YES = bd\n\n**When to use bd**:\n- Work spans multiple sessions or days\n- Tasks have dependencies or blockers\n- Need to survive conversation compaction\n- Exploratory/research work with fuzzy boundaries\n- Collaboration with team (git sync)\n\n**When to use TodoWrite**:\n- Single-session linear tasks\n- Simple checklist for immediate work\n- All context is in current conversation\n- Will complete within current session\n\n## Prerequisites\n\n```bash\nbd --version  # Requires v0.34.0+\n```\n\n- **bd CLI** installed and in PATH\n- **Git repository** (bd requires git for sync)\n- **Initialization**: `bd init` run once (humans do this, not agents)\n\n## CLI Reference\n\n**Run `bd prime`** for AI-optimized workflow context (auto-loaded by hooks).\n**Run `bd <command> --help`** for specific command usage.\n\nEssential commands: `bd ready`, `bd create`, `bd show`, `bd update`, `bd close`, `bd sync`\n\n## Session Protocol\n\n1. `bd ready` â€” Find unblocked work\n2. `bd show <id>` â€” Get full context\n3. `bd update <id> --status in_progress` â€” Start work\n4. Add notes as you work (critical for compaction survival)\n5. `bd close <id> --reason \"...\"` â€” Complete task\n6. `bd sync` â€” Persist to git (always run at session end)\n\n## Advanced Features\n\n| Feature | CLI | Resource |\n|---------|-----|----------|\n| Molecules (templates) | `bd mol --help` | [MOLECULES.md](resources/MOLECULES.md) |\n| Chemistry (pour/wisp) | `bd pour`, `bd wisp` | [CHEMISTRY_PATTERNS.md](resources/CHEMISTRY_PATTERNS.md) |\n| Agent beads | `bd agent --help` | [AGENTS.md](resources/AGENTS.md) |\n| Async gates | `bd gate --help` | [ASYNC_GATES.md](resources/ASYNC_GATES.md) |\n| Worktrees | `bd worktree --help` | [WORKTREES.md](resources/WORKTREES.md) |\n\n## Resources\n\n| Resource | Content |\n|----------|---------|\n| [BOUNDARIES.md](resources/BOUNDARIES.md) | bd vs TodoWrite detailed comparison |\n| [CLI_REFERENCE.md](resources/CLI_REFERENCE.md) | Complete command syntax |\n| [DEPENDENCIES.md](resources/DEPENDENCIES.md) | Dependency system deep dive |\n| [INTEGRATION_PATTERNS.md](resources/INTEGRATION_PATTERNS.md) | TodoWrite and tool integration |\n| [ISSUE_CREATION.md](resources/ISSUE_CREATION.md) | When and how to create issues |\n| [MOLECULES.md](resources/MOLECULES.md) | Proto definitions, component labels |\n| [PATTERNS.md](resources/PATTERNS.md) | Common usage patterns |\n| [RESUMABILITY.md](resources/RESUMABILITY.md) | Compaction survival guide |\n| [STATIC_DATA.md](resources/STATIC_DATA.md) | Database schema reference |\n| [TROUBLESHOOTING.md](resources/TROUBLESHOOTING.md) | Error handling and fixes |\n| [WORKFLOWS.md](resources/WORKFLOWS.md) | Step-by-step workflow patterns |\n| [AGENTS.md](resources/AGENTS.md) | Agent bead tracking (v0.40+) |\n| [ASYNC_GATES.md](resources/ASYNC_GATES.md) | Human-in-the-loop gates |\n| [CHEMISTRY_PATTERNS.md](resources/CHEMISTRY_PATTERNS.md) | Mol vs Wisp decision tree |\n| [WORKTREES.md](resources/WORKTREES.md) | Parallel development patterns |\n\n## Full Documentation\n\n- **bd prime**: AI-optimized workflow context\n- **GitHub**: [github.com/steveyegge/beads](https://github.com/steveyegge/beads)\n",
        "skills/beads/adr/0001-bd-prime-as-source-of-truth.md": "# ADR-0001: Use bd prime as CLI Reference Source of Truth\n\n## Status\n\nAccepted\n\n## Context\n\nThe beads skill maintained CLI reference documentation in multiple locations:\n\n- `SKILL.md` inline (~2,000+ words of CLI reference)\n- `references/CLI_REFERENCE.md` (~2,363 words)\n- Scattered examples throughout resource files\n\nThis created:\n- **Duplication**: Same commands documented 2-3 times\n- **Drift risk**: Documentation can fall behind bd versions\n- **Token overhead**: ~3,000+ tokens loaded even for simple operations\n\nMeanwhile, bd provides `bd prime` which generates AI-optimized workflow context automatically.\n\n## Decision\n\nUse `bd prime` as the single source of truth for CLI commands:\n\n1. **SKILL.md** contains only value-add content (decision frameworks, cognitive patterns)\n2. **CLI reference** points to `bd prime` (auto-loaded by hooks) and `bd --help`\n3. **Resources** provide depth for advanced features (molecules, agents, gates)\n\n## Consequences\n\n### Positive\n\n- **Zero maintenance**: CLI docs auto-update with bd versions\n- **DRY**: Single source of truth\n- **Accurate**: No version drift possible\n- **Lighter SKILL.md**: ~500 words vs ~3,300\n\n### Negative\n\n- **Dependency on bd prime format**: If output changes significantly, may need adaptation\n- **External tool requirement**: Skill assumes bd is installed\n\n## Implementation\n\nFiles restructured:\n- `SKILL.md` â€” Reduced from 3,306 to ~500 words\n- `references/` â†’ `resources/` â€” Directory rename for consistency\n- New resources added: `agents.md`, `async-gates.md`, `chemistry-patterns.md`, `worktrees.md`\n- Existing resources preserved with path updates\n\n## Related\n\n- Claude Code skill progressive disclosure guidelines\n- Similar pattern implemented in other Claude Code skill ecosystems\n\n## Date\n\n2025-01-02\n",
        "skills/beads/resources/AGENTS.md": "# Agent Beads\n\n> Adapted from ACF beads skill\n\n**v0.40+**: First-class support for agent tracking via `type=agent` beads.\n\n## When to Use Agent Beads\n\n| Scenario | Agent Bead? | Why |\n|----------|-------------|-----|\n| Multi-agent orchestration | Yes | Track state, assign work via slots |\n| Single Claude session | No | Overkillâ€”just use regular beads |\n| Long-running background agents | Yes | Heartbeats enable liveness detection |\n| Role-based agent systems | Yes | Role beads define agent capabilities |\n\n## Bead Types\n\n| Type | Purpose | Has Slots? |\n|------|---------|------------|\n| `agent` | AI agent tracking | Yes (hook, role) |\n| `role` | Role definitions for agents | No |\n\nOther types (`task`, `bug`, `feature`, `epic`) remain unchanged.\n\n## State Machine\n\nAgent beads track state for coordination:\n\n```\nidle â†’ spawning â†’ running/working â†’ done â†’ idle\n                       â†“\n                    stuck â†’ (needs intervention)\n```\n\n**Key states**: `idle`, `spawning`, `running`, `working`, `stuck`, `done`, `stopped`, `dead`\n\nThe `dead` state is set by Witness (monitoring system) via heartbeat timeoutâ€”agents don't set this themselves.\n\n## Slot Architecture\n\nSlots are named references from agent beads to other beads:\n\n| Slot | Cardinality | Purpose |\n|------|-------------|---------|\n| `hook` | 0..1 | Current work attached to agent |\n| `role` | 1 | Role definition bead (required) |\n\n**Why slots?** They enforce constraints (one work item at a time) and enable queries like \"what is agent X working on?\" or \"which agent has this work?\"\n\n## Monitoring Integration\n\nAgent beads enable:\n\n- **Witness System**: Monitors agent health via heartbeats\n- **State Coordination**: ZFC-compliant state machine for multi-agent systems\n- **Work Attribution**: Track which agent owns which work\n\n## CLI Reference\n\nRun `bd agent --help` for state/heartbeat/show commands.\nRun `bd slot --help` for set/clear/show commands.\nRun `bd create --help` for `--type=agent` and `--type=role` options.\n",
        "skills/beads/resources/ASYNC_GATES.md": "# Async Gates for Workflow Coordination\n\n> Adapted from ACF beads skill\n\n`bd gate` provides async coordination primitives for cross-session and external-condition workflows. Gates are **wisps** (ephemeral issues) that block until a condition is met.\n\n---\n\n## Gate Types\n\n| Type | Await Syntax | Use Case |\n|------|--------------|----------|\n| Human | `human:<prompt>` | Cross-session human approval |\n| CI | `gh:run:<id>` | Wait for GitHub Actions completion |\n| PR | `gh:pr:<id>` | Wait for PR merge/close |\n| Timer | `timer:<duration>` | Deployment propagation delay |\n| Mail | `mail:<pattern>` | Wait for matching email |\n\n---\n\n## Creating Gates\n\n```bash\n# Human approval gate\nbd gate create --await human:deploy-approval \\\n  --title \"Approve production deploy\" \\\n  --timeout 4h\n\n# CI gate (GitHub Actions)\nbd gate create --await gh:run:123456789 \\\n  --title \"Wait for CI\" \\\n  --timeout 30m\n\n# PR merge gate\nbd gate create --await gh:pr:42 \\\n  --title \"Wait for PR approval\" \\\n  --timeout 24h\n\n# Timer gate (deployment propagation)\nbd gate create --await timer:15m \\\n  --title \"Wait for deployment propagation\"\n```\n\n**Required options**:\n- `--await <spec>` â€” Gate condition (see types above)\n- `--timeout <duration>` â€” Recommended: prevents forever-open gates\n\n**Optional**:\n- `--title <text>` â€” Human-readable description\n- `--notify <recipients>` â€” Email/beads addresses to notify\n\n---\n\n## Monitoring Gates\n\n```bash\nbd gate list              # All open gates\nbd gate list --all        # Include closed\nbd gate show <gate-id>    # Details for specific gate\nbd gate eval              # Auto-close elapsed/completed gates\nbd gate eval --dry-run    # Preview what would close\n```\n\n**Auto-close behavior** (`bd gate eval`):\n- `timer:*` â€” Closes when duration elapsed\n- `gh:run:*` â€” Checks GitHub API, closes on success/failure\n- `gh:pr:*` â€” Checks GitHub API, closes on merge/close\n- `human:*` â€” Requires explicit `bd gate approve`\n\n---\n\n## Closing Gates\n\n```bash\n# Human gates require explicit approval\nbd gate approve <gate-id>\nbd gate approve <gate-id> --comment \"Reviewed and approved by Steve\"\n\n# Manual close (any gate)\nbd gate close <gate-id>\nbd gate close <gate-id> --reason \"No longer needed\"\n\n# Auto-close via evaluation\nbd gate eval\n```\n\n---\n\n## Best Practices\n\n1. **Always set timeouts**: Prevents forever-open gates\n   ```bash\n   bd gate create --await human:... --timeout 24h\n   ```\n\n2. **Clear titles**: Title should indicate what's being gated\n   ```bash\n   --title \"Approve Phase 2: Core Implementation\"\n   ```\n\n3. **Eval periodically**: Run at session start to close elapsed gates\n   ```bash\n   bd gate eval\n   ```\n\n4. **Clean up obsolete gates**: Close gates that are no longer needed\n   ```bash\n   bd gate close <id> --reason \"superseded by new approach\"\n   ```\n\n5. **Check before creating**: Avoid duplicate gates\n   ```bash\n   bd gate list | grep \"spec-myfeature\"\n   ```\n\n---\n\n## Gates vs Issues\n\n| Aspect | Gates (Wisp) | Issues |\n|--------|--------------|--------|\n| Persistence | Ephemeral (not synced) | Permanent (synced to git) |\n| Purpose | Block on external condition | Track work items |\n| Lifecycle | Auto-close when condition met | Manual close |\n| Visibility | `bd gate list` | `bd list` |\n| Use case | CI, approval, timers | Tasks, bugs, features |\n\nGates are designed to be temporary coordination primitivesâ€”they exist only until their condition is satisfied.\n\n---\n\n## Troubleshooting\n\n### Gate won't close\n\n```bash\n# Check gate details\nbd gate show <gate-id>\n\n# For gh:run gates, verify the run exists\ngh run view <run-id>\n\n# Force close if stuck\nbd gate close <gate-id> --reason \"manual override\"\n```\n\n### Can't find gate ID\n\n```bash\n# List all gates (including closed)\nbd gate list --all\n\n# Search by title pattern\nbd gate list | grep \"Phase 2\"\n```\n\n### CI run ID detection fails\n\n```bash\n# Check GitHub CLI auth\ngh auth status\n\n# List runs manually\ngh run list --branch <branch>\n\n# Use specific workflow\ngh run list --workflow ci.yml --branch <branch>\n```\n",
        "skills/beads/resources/BOUNDARIES.md": "# Boundaries: When to Use bd vs TodoWrite\n\nThis reference provides detailed decision criteria for choosing between bd issue tracking and TodoWrite for task management.\n\n## Contents\n\n- [The Core Question](#the-core-question)\n- [Decision Matrix](#decision-matrix)\n  - [Use bd for](#use-bd-for): Multi-Session Work, Complex Dependencies, Knowledge Work, Side Quests, Project Memory\n  - [Use TodoWrite for](#use-todowrite-for): Single-Session Tasks, Linear Execution, Immediate Context, Simple Tracking\n- [Detailed Comparison](#detailed-comparison)\n- [Integration Patterns](#integration-patterns)\n  - Pattern 1: bd as Strategic, TodoWrite as Tactical\n  - Pattern 2: TodoWrite as Working Copy of bd\n  - Pattern 3: Transition Mid-Session\n- [Real-World Examples](#real-world-examples)\n  - Strategic Document Development, Simple Feature Implementation, Bug Investigation, Refactoring with Dependencies\n- [Common Mistakes](#common-mistakes)\n  - Using TodoWrite for multi-session work, using bd for simple tasks, not transitioning when complexity emerges, creating too many bd issues, never using bd\n- [The Transition Point](#the-transition-point)\n- [Summary Heuristics](#summary-heuristics)\n\n## The Core Question\n\n**\"Could I resume this work after 2 weeks away?\"**\n\n- If bd would help you resume â†’ **use bd**\n- If markdown skim would suffice â†’ **TodoWrite is fine**\n\nThis heuristic captures the essential difference: bd provides structured context that persists across long gaps, while TodoWrite excels at immediate session tracking.\n\n## Decision Matrix\n\n### Use bd for:\n\n#### Multi-Session Work\nWork spanning multiple compaction cycles or days where context needs to persist.\n\n**Examples:**\n- Strategic document development requiring research across multiple sessions\n- Feature implementation split across several coding sessions\n- Bug investigation requiring experimentation over time\n- Architecture design evolving through multiple iterations\n\n**Why bd wins**: Issues capture context that survives compaction. Return weeks later and see full history, design decisions, and current status.\n\n#### Complex Dependencies\nWork with blockers, prerequisites, or hierarchical structure.\n\n**Examples:**\n- OAuth integration requiring database setup, endpoint creation, and frontend changes\n- Research project with multiple parallel investigation threads\n- Refactoring with dependencies between different code areas\n- Migration requiring sequential steps in specific order\n\n**Why bd wins**: Dependency graph shows what's blocking what. `bd ready` automatically surfaces unblocked work. No manual tracking required.\n\n#### Knowledge Work\nTasks with fuzzy boundaries, exploration, or strategic thinking.\n\n**Examples:**\n- Architecture decision requiring research into frameworks and trade-offs\n- API design requiring research into multiple options\n- Performance optimization requiring measurement and experimentation\n- Documentation requiring understanding system architecture\n\n**Why bd wins**: `design` and `acceptance_criteria` fields capture evolving understanding. Issues can be refined as exploration reveals more information.\n\n#### Side Quests\nExploratory work that might pause the main task.\n\n**Examples:**\n- During feature work, discover a better pattern worth exploring\n- While debugging, notice related architectural issue\n- During code review, identify potential improvement\n- While writing tests, find edge case requiring research\n\n**Why bd wins**: Create issue with `discovered-from` dependency, pause main work safely. Context preserved for both tracks. Resume either one later.\n\n#### Project Memory\nNeed to resume work after significant time with full context.\n\n**Examples:**\n- Open source contributions across months\n- Part-time projects with irregular schedule\n- Complex features split across sprints\n- Research projects with long investigation periods\n\n**Why bd wins**: Git-backed database persists indefinitely. All context, decisions, and history available on resume. No relying on conversation scrollback or markdown files.\n\n---\n\n### Use TodoWrite for:\n\n#### Single-Session Tasks\nWork that completes within current conversation.\n\n**Examples:**\n- Implementing a single function based on clear spec\n- Fixing a bug with known root cause\n- Adding unit tests for existing code\n- Updating documentation for recent changes\n\n**Why TodoWrite wins**: Simple checklist is perfect for linear execution. No need for persistence or dependencies. Clear completion within session.\n\n#### Linear Execution\nStraightforward step-by-step tasks with no branching.\n\n**Examples:**\n- Database migration with clear sequence\n- Deployment checklist\n- Code style cleanup across files\n- Dependency updates following upgrade guide\n\n**Why TodoWrite wins**: Steps are predetermined and sequential. No discovery, no blockers, no side quests. Just execute top to bottom.\n\n#### Immediate Context\nAll information already in conversation.\n\n**Examples:**\n- User provides complete spec and asks for implementation\n- Bug report with reproduction steps and fix approach\n- Refactoring request with clear before/after vision\n- Config changes based on user preferences\n\n**Why TodoWrite wins**: No external context to track. Everything needed is in current conversation. TodoWrite provides user visibility, nothing more needed.\n\n#### Simple Tracking\nJust need a checklist to show progress to user.\n\n**Examples:**\n- Breaking down implementation into visible steps\n- Showing validation workflow progress\n- Demonstrating systematic approach\n- Providing reassurance work is proceeding\n\n**Why TodoWrite wins**: User wants to see thinking and progress. TodoWrite is visible in conversation. bd is invisible background structure.\n\n---\n\n## Detailed Comparison\n\n| Aspect | bd | TodoWrite |\n|--------|-----|-----------|\n| **Persistence** | Git-backed, survives compaction | Session-only, lost after conversation |\n| **Dependencies** | Graph-based, automatic ready detection | Manual, no automatic tracking |\n| **Discoverability** | `bd ready` surfaces work | Scroll conversation for todos |\n| **Complexity** | Handles nested epics, blockers | Flat list only |\n| **Visibility** | Background structure, not in conversation | Visible to user in chat |\n| **Setup** | Requires `.beads/` directory in project | Always available |\n| **Best for** | Complex, multi-session, explorative | Simple, single-session, linear |\n| **Context capture** | Design notes, acceptance criteria, links | Just task description |\n| **Evolution** | Issues can be updated, refined over time | Static once written |\n| **Audit trail** | Full history of changes | Only visible in conversation |\n\n## Integration Patterns\n\nbd and TodoWrite can coexist effectively in a session. Use both strategically.\n\n### Pattern 1: bd as Strategic, TodoWrite as Tactical\n\n**Setup:**\n- bd tracks high-level issues and dependencies\n- TodoWrite tracks current session's execution steps\n\n**Example:**\n```\nbd issue: \"Implement user authentication\" (epic)\n  â”œâ”€ Child issue: \"Create login endpoint\"\n  â”œâ”€ Child issue: \"Add JWT token validation\"  â† Currently working on this\n  â””â”€ Child issue: \"Implement logout\"\n\nTodoWrite (for JWT validation):\n- [ ] Install JWT library\n- [ ] Create token validation middleware\n- [ ] Add tests for token expiry\n- [ ] Update API documentation\n```\n\n**When to use:**\n- Complex features with clear implementation steps\n- User wants to see current progress but larger context exists\n- Multi-session work currently in single-session execution phase\n\n### Pattern 2: TodoWrite as Working Copy of bd\n\n**Setup:**\n- Start with bd issue containing full context\n- Create TodoWrite checklist from bd issue's acceptance criteria\n- Update bd as TodoWrite items complete\n\n**Example:**\n```\nSession start:\n- Check bd: \"issue-auth-42: Add JWT token validation\" is ready\n- Extract acceptance criteria into TodoWrite\n- Mark bd issue as in_progress\n- Work through TodoWrite items\n- Update bd design notes as you learn\n- When TodoWrite completes, close bd issue\n```\n\n**When to use:**\n- bd issue is ready but execution is straightforward\n- User wants visible progress tracking\n- Need structured approach to larger issue\n\n### Pattern 3: Transition Mid-Session\n\n**From TodoWrite to bd:**\n\nRecognize mid-execution that work is more complex than anticipated.\n\n**Trigger signals:**\n- Discovering blockers or dependencies\n- Realizing work won't complete this session\n- Finding side quests or related issues\n- Needing to pause and resume later\n\n**How to transition:**\n```\n1. Create bd issue with current TodoWrite content\n2. Note: \"Discovered this is multi-session work during implementation\"\n3. Add dependencies as discovered\n4. Keep TodoWrite for current session\n5. Update bd issue before session ends\n6. Next session: resume from bd, create new TodoWrite if needed\n```\n\n**From bd to TodoWrite:**\n\nRare, but happens when bd issue turns out simpler than expected.\n\n**Trigger signals:**\n- All context already clear\n- No dependencies discovered\n- Can complete within session\n- User wants execution visibility\n\n**How to transition:**\n```\n1. Keep bd issue for historical record\n2. Create TodoWrite from issue description\n3. Execute via TodoWrite\n4. Close bd issue when done\n5. Note: \"Completed in single session, simpler than expected\"\n```\n\n## Real-World Examples\n\n### Example 1: Database Migration Planning\n\n**Scenario**: Planning migration from MySQL to PostgreSQL for production application.\n\n**Why bd**:\n- Multi-session work across days/weeks\n- Fuzzy boundaries - scope emerges through investigation\n- Side quests - discover schema incompatibilities requiring refactoring\n- Dependencies - can't migrate data until schema validated\n- Project memory - need to resume after interruptions\n\n**bd structure**:\n```\ndb-epic: \"Migrate production database to PostgreSQL\"\n  â”œâ”€ db-1: \"Audit current MySQL schema and queries\"\n  â”œâ”€ db-2: \"Research PostgreSQL equivalents for MySQL features\" (blocks schema design)\n  â”œâ”€ db-3: \"Design PostgreSQL schema with type mappings\"\n  â””â”€ db-4: \"Create migration scripts and test data integrity\" (blocked by db-3)\n```\n\n**TodoWrite role**: None initially. Might use TodoWrite for single-session testing sprints once migration scripts ready.\n\n### Example 2: Simple Feature Implementation\n\n**Scenario**: Add logging to existing endpoint based on clear specification.\n\n**Why TodoWrite**:\n- Single session work\n- Linear execution - add import, call logger, add test\n- All context in user message\n- Completes within conversation\n\n**TodoWrite**:\n```\n- [ ] Import logging library\n- [ ] Add log statements to endpoint\n- [ ] Add test for log output\n- [ ] Run tests\n```\n\n**bd role**: None. Overkill for straightforward task.\n\n### Example 3: Bug Investigation\n\n**Initial assessment**: Seems simple, try TodoWrite first.\n\n**TodoWrite**:\n```\n- [ ] Reproduce bug\n- [ ] Identify root cause\n- [ ] Implement fix\n- [ ] Add regression test\n```\n\n**What actually happens**: Reproducing bug reveals it's intermittent. Root cause investigation shows multiple potential issues. Needs time to investigate.\n\n**Transition to bd**:\n```\nCreate bd issue: \"Fix intermittent auth failure in production\"\n  - Description: Initially seemed simple but reproduction shows complex race condition\n  - Design: Three potential causes identified, need to test each\n  - Created issues for each hypothesis with discovered-from dependency\n\nPause for day, resume next session from bd context\n```\n\n### Example 4: Refactoring with Dependencies\n\n**Scenario**: Extract common validation logic from three controllers.\n\n**Why bd**:\n- Dependencies - must extract before modifying callers\n- Multi-file changes need coordination\n- Potential side quest - might discover better pattern during extraction\n- Need to track which controllers updated\n\n**bd structure**:\n```\nrefactor-1: \"Create shared validation module\"\n  â†’ blocks refactor-2, refactor-3, refactor-4\n\nrefactor-2: \"Update auth controller to use shared validation\"\nrefactor-3: \"Update user controller to use shared validation\"\nrefactor-4: \"Update payment controller to use shared validation\"\n```\n\n**TodoWrite role**: Could use TodoWrite for individual controller updates as implementing.\n\n**Why this works**: bd ensures you don't forget to update a controller. `bd ready` shows next available work. Dependencies prevent starting controller update before extraction complete.\n\n## Common Mistakes\n\n### Mistake 1: Using TodoWrite for Multi-Session Work\n\n**What happens**:\n- Next session, forget what was done\n- Scroll conversation history to reconstruct\n- Lose design decisions made during implementation\n- Start over or duplicate work\n\n**Solution**: Create bd issue instead. Persist context across sessions.\n\n### Mistake 2: Using bd for Simple Linear Tasks\n\n**What happens**:\n- Overhead of creating issue not justified\n- User can't see progress in conversation\n- Extra tool use for no benefit\n\n**Solution**: Use TodoWrite. It's designed for exactly this case.\n\n### Mistake 3: Not Transitioning When Complexity Emerges\n\n**What happens**:\n- Start with TodoWrite for \"simple\" task\n- Discover blockers and dependencies mid-way\n- Keep using TodoWrite despite poor fit\n- Lose context when conversation ends\n\n**Solution**: Transition to bd when complexity signal appears. Not too late mid-session.\n\n### Mistake 4: Creating Too Many bd Issues\n\n**What happens**:\n- Every tiny task gets an issue\n- Database cluttered with trivial items\n- Hard to find meaningful work in `bd ready`\n\n**Solution**: Reserve bd for work that actually benefits from persistence. Use \"2 week test\" - would bd help resume after 2 weeks? If no, skip it.\n\n### Mistake 5: Never Using bd Because TodoWrite is Familiar\n\n**What happens**:\n- Multi-session projects become markdown swamps\n- Lose track of dependencies and blockers\n- Can't resume work effectively\n- Rotten half-implemented plans\n\n**Solution**: Force yourself to use bd for next multi-session project. Experience the difference in organization and resumability.\n\n### Mistake 6: Always Asking Before Creating Issues (or Never Asking)\n\n**When to create directly** (no user question needed):\n- **Bug reports**: Clear scope, specific problem (\"Found: auth doesn't check profile permissions\")\n- **Research tasks**: Investigative work (\"Research workaround for Slides export\")\n- **Technical TODOs**: Discovered during implementation (\"Add validation to form handler\")\n- **Side quest capture**: Discoveries that need tracking (\"Issue: MCP can't read Shared Drive files\")\n\n**Why create directly**: Asking slows discovery capture. User expects proactive issue creation for clear-cut problems.\n\n**When to ask first** (get user input):\n- **Strategic work**: Fuzzy boundaries, multiple valid approaches (\"Should we implement X or Y pattern?\")\n- **Potential duplicates**: Might overlap with existing work\n- **Large epics**: Multiple approaches, unclear scope (\"Plan migration strategy\")\n- **Major scope changes**: Changing direction of existing issue\n\n**Why ask**: Ensures alignment on fuzzy work, prevents duplicate effort, clarifies scope before investment.\n\n**Rule of thumb**: If you can write a clear, specific issue title and description in one sentence, create directly. If you need user input to clarify the work, ask first.\n\n**Examples**:\n- âœ… Create directly: \"workspace MCP: Google Doc â†’ .docx export fails with UTF-8 encoding error\"\n- âœ… Create directly: \"Research: Workarounds for reading Google Slides from Shared Drives\"\n- â“ Ask first: \"Should we refactor the auth system now or later?\" (strategic decision)\n- â“ Ask first: \"I found several data validation issues, should I file them all?\" (potential overwhelming)\n\n## The Transition Point\n\nMost work starts with an implicit mental model:\n\n**\"This looks straightforward\"** â†’ TodoWrite\n\n**As work progresses:**\n\nâœ… **Stays straightforward** â†’ Continue with TodoWrite, complete in session\n\nâš ï¸ **Complexity emerges** â†’ Transition to bd, preserve context\n\nThe skill is recognizing the transition point:\n\n**Transition signals:**\n- \"This is taking longer than expected\"\n- \"I've discovered a blocker\"\n- \"This needs more research\"\n- \"I should pause this and investigate X first\"\n- \"The user might not be available to continue today\"\n- \"I found three related issues while working on this\"\n\n**When you notice these signals**: Create bd issue, preserve context, work from structured foundation.\n\n## Summary Heuristics\n\nQuick decision guides:\n\n**Time horizon:**\n- Same session â†’ TodoWrite\n- Multiple sessions â†’ bd\n\n**Dependency structure:**\n- Linear steps â†’ TodoWrite\n- Blockers/prerequisites â†’ bd\n\n**Scope clarity:**\n- Well-defined â†’ TodoWrite\n- Exploratory â†’ bd\n\n**Context complexity:**\n- Conversation has everything â†’ TodoWrite\n- External context needed â†’ bd\n\n**User interaction:**\n- User watching progress â†’ TodoWrite visible in chat\n- Background work â†’ bd invisible structure\n\n**Resume difficulty:**\n- Easy from markdown â†’ TodoWrite\n- Need structured history â†’ bd\n\nWhen in doubt: **Use the 2-week test**. If you'd struggle to resume this work after 2 weeks without bd, use bd.\n",
        "skills/beads/resources/CHEMISTRY_PATTERNS.md": "# Chemistry Patterns\n\n> Adapted from ACF beads skill\n\nBeads uses a chemistry metaphor for work templates. This guide covers when and how to use each phase.\n\n## Phase Transitions\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                    PROTO (Solid)                            â”‚\nâ”‚              Frozen template, reusable pattern              â”‚\nâ”‚                    .beads/ with template label              â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                          â”‚\n          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n          â”‚               â”‚               â”‚\n          â–¼               â”‚               â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   MOL (Liquid)  â”‚       â”‚       â”‚  WISP (Vapor)   â”‚\nâ”‚   bd pour       â”‚       â”‚       â”‚  bd wisp create â”‚\nâ”‚                 â”‚       â”‚       â”‚                 â”‚\nâ”‚  Persistent     â”‚       â”‚       â”‚  Ephemeral      â”‚\nâ”‚  .beads/        â”‚       â”‚       â”‚  .beads-wisp/   â”‚\nâ”‚  Git synced     â”‚       â”‚       â”‚  Gitignored     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â”‚                â”‚                â”‚\n         â”‚                â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”\n         â”‚                â”‚        â”‚               â”‚\n         â–¼                â”‚        â–¼               â–¼\n   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n   â”‚  CLOSE   â”‚           â”‚   â”‚ SQUASH  â”‚    â”‚  BURN   â”‚\n   â”‚ normally â”‚           â”‚   â”‚ â†’ digestâ”‚    â”‚ â†’ gone  â”‚\n   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                          â”‚\n                          â–¼\n                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n                  â”‚   DISTILL     â”‚\n                  â”‚ Extract proto â”‚\n                  â”‚ from ad-hoc   â”‚\n                  â”‚ epic          â”‚\n                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Decision Tree: Mol vs Wisp\n\n```\nWill this work be referenced later?\nâ”‚\nâ”œâ”€ YES â†’ Does it need audit trail / git history?\nâ”‚        â”‚\nâ”‚        â”œâ”€ YES â†’ MOL (bd pour)\nâ”‚        â”‚        Examples: Features, bugs, specs\nâ”‚        â”‚\nâ”‚        â””â”€ NO  â†’ Could go either way\nâ”‚                 Consider: Will someone else see this?\nâ”‚                 â”‚\nâ”‚                 â”œâ”€ YES â†’ MOL\nâ”‚                 â””â”€ NO  â†’ WISP (then squash if valuable)\nâ”‚\nâ””â”€ NO  â†’ WISP (bd wisp create)\n         Examples: Grooming, health checks, scratch work\n         End state: burn (no value) or squash (capture learnings)\n```\n\n## Quick Reference\n\n| Scenario | Use | Command | End State |\n|----------|-----|---------|-----------|\n| New feature work | Mol | `bd pour spec` | Close normally |\n| Bug fix | Mol | `bd pour bug` | Close normally |\n| Grooming session | Wisp | `bd wisp create grooming` | Squash â†’ digest |\n| Code review | Wisp | `bd wisp create review` | Squash findings |\n| Research spike | Wisp | `bd wisp create spike` | Squash or burn |\n| Session health check | Wisp | `bd wisp create health` | Burn |\n| Agent coordination | Wisp | `bd wisp create coordinator` | Burn |\n\n## Common Patterns\n\n### Pattern 1: Grooming Wisp\n\nUse for periodic backlog maintenance.\n\n```bash\n# Start grooming\nbd wisp create grooming --var date=\"2025-01-02\"\n\n# Work through checklist (stale, duplicates, verification)\n# Track findings in wisp notes\n\n# End: capture summary\nbd mol squash <wisp-id>  # Creates digest: \"Closed 3, added 5 relationships\"\n```\n\n**Why wisp?** Grooming is operationalâ€”you don't need permanent issues for \"reviewed stale items.\"\n\n### Pattern 2: Code Review Wisp\n\nUse for PR review checklists.\n\n```bash\n# Start review\nbd wisp create pr-review --var pr=\"123\" --var repo=\"myproject\"\n\n# Track review findings (security, performance, style)\n# Each finding is a child issue in the wisp\n\n# End: promote real issues, discard noise\nbd mol squash <wisp-id>  # Creates permanent issues for real findings\n```\n\n**Why wisp?** Review checklists are ephemeral. Only actual findings become permanent issues.\n\n### Pattern 3: Research Spike Wisp\n\nUse for time-boxed exploration.\n\n```bash\n# Start spike (2 hour timebox)\nbd wisp create spike --var topic=\"GraphQL pagination\"\n\n# Explore, take notes in wisp issues\n# Track sources, findings, dead ends\n\n# End: decide outcome\nbd mol squash <wisp-id>  # If valuable â†’ creates research summary issue\n# OR\nbd mol burn <wisp-id>    # If dead end â†’ no trace\n```\n\n**Why wisp?** Research might lead nowhere. Don't pollute the database with abandoned explorations.\n\n## Commands Reference\n\n### Creating Work\n\n```bash\n# Persistent mol (solid â†’ liquid)\nbd pour <proto>                    # Synced to git\nbd pour <proto> --var key=value\n\n# Ephemeral wisp (solid â†’ vapor)\nbd wisp create <proto>             # Not synced\nbd wisp create <proto> --var key=value\n```\n\n### Ending Work\n\n```bash\n# Mol: close normally\nbd close <mol-id>\n\n# Wisp: squash (condense to digest)\nbd mol squash <wisp-id>            # Creates permanent digest issue\n\n# Wisp: burn (evaporate, no trace)\nbd mol burn <wisp-id>              # Deletes with no record\n```\n\n### Managing\n\n```bash\n# List wisps\nbd wisp list\n\n# Garbage collect orphaned wisps\nbd wisp gc\n\n# View proto/mol structure\nbd mol show <id>\n\n# List available protos\nbd mol catalog\n```\n\n## Storage Locations\n\n| Type | Location | Git Behavior |\n|------|----------|--------------|\n| Proto | `.beads/` | Synced (template label) |\n| Mol | `.beads/` | Synced |\n| Wisp | `.beads-wisp/` | Gitignored |\n\n## Anti-Patterns\n\n| Don't | Do Instead |\n|-------|------------|\n| Create mol for one-time diagnostic | Use wisp, then burn |\n| Create wisp for real feature work | Use mol (needs audit trail) |\n| Burn wisp with valuable findings | Squash first (captures digest) |\n| Let wisps accumulate | Burn or squash at session end |\n| Create ad-hoc epics for repeatable patterns | Distill into proto |\n\n## Related Resources\n\n- [MOLECULES.md](MOLECULES.md) â€” Proto definitions\n- [WORKFLOWS.md](WORKFLOWS.md) â€” General beads workflows\n",
        "skills/beads/resources/CLI_REFERENCE.md": "# CLI Command Reference\n\n**For:** AI agents and developers using bd command-line interface\n**Version:** 0.21.0+\n\n## Quick Navigation\n\n- [Basic Operations](#basic-operations)\n- [Issue Management](#issue-management)\n- [Dependencies & Labels](#dependencies--labels)\n- [Filtering & Search](#filtering--search)\n- [Advanced Operations](#advanced-operations)\n- [Database Management](#database-management)\n\n## Basic Operations\n\n### Check Status\n\n```bash\n# Check database path and daemon status\nbd info --json\n\n# Example output:\n# {\n#   \"database_path\": \"/path/to/.beads/beads.db\",\n#   \"issue_prefix\": \"bd\",\n#   \"daemon_running\": true\n# }\n```\n\n### Find Work\n\n```bash\n# Find ready work (no blockers)\nbd ready --json\n\n# Find stale issues (not updated recently)\nbd stale --days 30 --json                    # Default: 30 days\nbd stale --days 90 --status in_progress --json  # Filter by status\nbd stale --limit 20 --json                   # Limit results\n```\n\n## Issue Management\n\n### Create Issues\n\n```bash\n# Basic creation\n# IMPORTANT: Always quote titles and descriptions with double quotes\nbd create \"Issue title\" -t bug|feature|task -p 0-4 -d \"Description\" --json\n\n# Create with explicit ID (for parallel workers)\nbd create \"Issue title\" --id worker1-100 -p 1 --json\n\n# Create with labels (--labels or --label work)\nbd create \"Issue title\" -t bug -p 1 -l bug,critical --json\nbd create \"Issue title\" -t bug -p 1 --label bug,critical --json\n\n# Examples with special characters (all require quoting):\nbd create \"Fix: auth doesn't validate tokens\" -t bug -p 1 --json\nbd create \"Add support for OAuth 2.0\" -d \"Implement RFC 6749 (OAuth 2.0 spec)\" --json\n\n# Create multiple issues from markdown file\nbd create -f feature-plan.md --json\n\n# Create epic with hierarchical child tasks\nbd create \"Auth System\" -t epic -p 1 --json         # Returns: bd-a3f8e9\nbd create \"Login UI\" -p 1 --json                     # Auto-assigned: bd-a3f8e9.1\nbd create \"Backend validation\" -p 1 --json           # Auto-assigned: bd-a3f8e9.2\nbd create \"Tests\" -p 1 --json                        # Auto-assigned: bd-a3f8e9.3\n\n# Create and link discovered work (one command)\nbd create \"Found bug\" -t bug -p 1 --deps discovered-from:<parent-id> --json\n```\n\n### Update Issues\n\n```bash\n# Update one or more issues\nbd update <id> [<id>...] --status in_progress --json\nbd update <id> [<id>...] --priority 1 --json\n\n# Edit issue fields in $EDITOR (HUMANS ONLY - not for agents)\n# NOTE: This command is intentionally NOT exposed via the MCP server\n# Agents should use 'bd update' with field-specific parameters instead\nbd edit <id>                    # Edit description\nbd edit <id> --title            # Edit title\nbd edit <id> --design           # Edit design notes\nbd edit <id> --notes            # Edit notes\nbd edit <id> --acceptance       # Edit acceptance criteria\n```\n\n### Close/Reopen Issues\n\n```bash\n# Complete work (supports multiple IDs)\nbd close <id> [<id>...] --reason \"Done\" --json\n\n# Reopen closed issues (supports multiple IDs)\nbd reopen <id> [<id>...] --reason \"Reopening\" --json\n```\n\n### View Issues\n\n```bash\n# Show dependency tree\nbd dep tree <id>\n\n# Get issue details (supports multiple IDs)\nbd show <id> [<id>...] --json\n```\n\n## Dependencies & Labels\n\n### Dependencies\n\n```bash\n# Link discovered work (old way - two commands)\nbd dep add <discovered-id> <parent-id> --type discovered-from\n\n# Create and link in one command (new way - preferred)\nbd create \"Issue title\" -t bug -p 1 --deps discovered-from:<parent-id> --json\n```\n\n### Labels\n\n```bash\n# Label management (supports multiple IDs)\nbd label add <id> [<id>...] <label> --json\nbd label remove <id> [<id>...] <label> --json\nbd label list <id> --json\nbd label list-all --json\n```\n\n## Filtering & Search\n\n### Basic Filters\n\n```bash\n# Filter by status, priority, type\nbd list --status open --priority 1 --json               # Status and priority\nbd list --assignee alice --json                         # By assignee\nbd list --type bug --json                               # By issue type\nbd list --id bd-123,bd-456 --json                       # Specific IDs\n```\n\n### Label Filters\n\n```bash\n# Labels (AND: must have ALL)\nbd list --label bug,critical --json\n\n# Labels (OR: has ANY)\nbd list --label-any frontend,backend --json\n```\n\n### Text Search\n\n```bash\n# Title search (substring)\nbd list --title \"auth\" --json\n\n# Pattern matching (case-insensitive substring)\nbd list --title-contains \"auth\" --json                  # Search in title\nbd list --desc-contains \"implement\" --json              # Search in description\nbd list --notes-contains \"TODO\" --json                  # Search in notes\n```\n\n### Date Range Filters\n\n```bash\n# Date range filters (YYYY-MM-DD or RFC3339)\nbd list --created-after 2024-01-01 --json               # Created after date\nbd list --created-before 2024-12-31 --json              # Created before date\nbd list --updated-after 2024-06-01 --json               # Updated after date\nbd list --updated-before 2024-12-31 --json              # Updated before date\nbd list --closed-after 2024-01-01 --json                # Closed after date\nbd list --closed-before 2024-12-31 --json               # Closed before date\n```\n\n### Empty/Null Checks\n\n```bash\n# Empty/null checks\nbd list --empty-description --json                      # Issues with no description\nbd list --no-assignee --json                            # Unassigned issues\nbd list --no-labels --json                              # Issues with no labels\n```\n\n### Priority Ranges\n\n```bash\n# Priority ranges\nbd list --priority-min 0 --priority-max 1 --json        # P0 and P1 only\nbd list --priority-min 2 --json                         # P2 and below\n```\n\n### Combine Filters\n\n```bash\n# Combine multiple filters\nbd list --status open --priority 1 --label-any urgent,critical --no-assignee --json\n```\n\n## Global Flags\n\nGlobal flags work with any bd command and must appear **before** the subcommand.\n\n### Sandbox Mode\n\n**Auto-detection (v0.21.1+):** bd automatically detects sandboxed environments and enables sandbox mode.\n\nWhen detected, you'll see: `â„¹ï¸  Sandbox detected, using direct mode`\n\n**Manual override:**\n\n```bash\n# Explicitly enable sandbox mode\nbd --sandbox <command>\n\n# Equivalent to combining these flags:\nbd --no-daemon --no-auto-flush --no-auto-import <command>\n```\n\n**What it does:**\n- Disables daemon (uses direct SQLite mode)\n- Disables auto-export to JSONL\n- Disables auto-import from JSONL\n\n**When to use:** Sandboxed environments where daemon can't be controlled (permission restrictions), or when auto-detection doesn't trigger.\n\n### Staleness Control\n\n```bash\n# Skip staleness check (emergency escape hatch)\nbd --allow-stale <command>\n\n# Example: access database even if out of sync with JSONL\nbd --allow-stale ready --json\nbd --allow-stale list --status open --json\n```\n\n**Shows:** `âš ï¸  Staleness check skipped (--allow-stale), data may be out of sync`\n\n**âš ï¸ Caution:** May show stale or incomplete data. Use only when stuck and other options fail.\n\n### Force Import\n\n```bash\n# Force metadata update even when DB appears synced\nbd import --force -i .beads/issues.jsonl\n```\n\n**When to use:** `bd import` reports \"0 created, 0 updated\" but staleness errors persist.\n\n**Shows:** `Metadata updated (database already in sync with JSONL)`\n\n### Other Global Flags\n\n```bash\n# JSON output for programmatic use\nbd --json <command>\n\n# Force direct mode (bypass daemon)\nbd --no-daemon <command>\n\n# Disable auto-sync\nbd --no-auto-flush <command>    # Disable auto-export to JSONL\nbd --no-auto-import <command>   # Disable auto-import from JSONL\n\n# Custom database path\nbd --db /path/to/.beads/beads.db <command>\n\n# Custom actor for audit trail\nbd --actor alice <command>\n```\n\n**See also:**\n- [TROUBLESHOOTING.md - Sandboxed environments](TROUBLESHOOTING.md#sandboxed-environments-codex-claude-code-etc) for detailed sandbox troubleshooting\n- [DAEMON.md](DAEMON.md) for daemon mode details\n\n## Advanced Operations\n\n### Cleanup\n\n```bash\n# Clean up closed issues (bulk deletion)\nbd admin cleanup --force --json                                   # Delete ALL closed issues\nbd admin cleanup --older-than 30 --force --json                   # Delete closed >30 days ago\nbd admin cleanup --dry-run --json                                 # Preview what would be deleted\nbd admin cleanup --older-than 90 --cascade --force --json         # Delete old + dependents\n```\n\n### Duplicate Detection & Merging\n\n```bash\n# Find and merge duplicate issues\nbd duplicates                                          # Show all duplicates\nbd duplicates --auto-merge                             # Automatically merge all\nbd duplicates --dry-run                                # Preview merge operations\n\n# Merge specific duplicate issues\nbd merge <source-id...> --into <target-id> --json      # Consolidate duplicates\nbd merge bd-42 bd-43 --into bd-41 --dry-run            # Preview merge\n```\n\n### Compaction (Memory Decay)\n\n```bash\n# Agent-driven compaction\nbd admin compact --analyze --json                           # Get candidates for review\nbd admin compact --analyze --tier 1 --limit 10 --json       # Limited batch\nbd admin compact --apply --id bd-42 --summary summary.txt   # Apply compaction\nbd admin compact --apply --id bd-42 --summary - < summary.txt  # From stdin\nbd admin compact --stats --json                             # Show statistics\n\n# Legacy AI-powered compaction (requires ANTHROPIC_API_KEY)\nbd admin compact --auto --dry-run --all                     # Preview\nbd admin compact --auto --all --tier 1                      # Auto-compact tier 1\n\n# Restore compacted issue from git history\nbd restore <id>  # View full history at time of compaction\n```\n\n### Rename Prefix\n\n```bash\n# Rename issue prefix (e.g., from 'knowledge-work-' to 'kw-')\nbd rename-prefix kw- --dry-run  # Preview changes\nbd rename-prefix kw- --json     # Apply rename\n```\n\n## Database Management\n\n### Import/Export\n\n```bash\n# Import issues from JSONL\nbd import -i .beads/issues.jsonl --dry-run      # Preview changes\nbd import -i .beads/issues.jsonl                # Import and update issues\nbd import -i .beads/issues.jsonl --dedupe-after # Import + detect duplicates\n\n# Handle missing parents during import\nbd import -i issues.jsonl --orphan-handling allow      # Default: import orphans without validation\nbd import -i issues.jsonl --orphan-handling resurrect  # Auto-resurrect deleted parents as tombstones\nbd import -i issues.jsonl --orphan-handling skip       # Skip orphans with warning\nbd import -i issues.jsonl --orphan-handling strict     # Fail if parent is missing\n\n# Configure default orphan handling behavior\nbd config set import.orphan_handling \"resurrect\"\nbd sync  # Now uses resurrect mode by default\n```\n\n**Orphan handling modes:**\n\n- **`allow` (default)** - Import orphaned children without parent validation. Most permissive, ensures no data loss even if hierarchy is temporarily broken.\n- **`resurrect`** - Search JSONL history for deleted parents and recreate them as tombstones (Status=Closed, Priority=4). Preserves hierarchy with minimal data. Dependencies are also resurrected on best-effort basis.\n- **`skip`** - Skip orphaned children with warning. Partial import succeeds but some issues are excluded.\n- **`strict`** - Fail import immediately if a child's parent is missing. Use when database integrity is critical.\n\n**When to use:**\n- Use `allow` (default) for daily imports and auto-sync\n- Use `resurrect` when importing from databases with deleted parents\n- Use `strict` for controlled imports requiring guaranteed parent existence\n- Use `skip` rarely - only for selective imports\n\nSee [CONFIG.md](CONFIG.md#example-import-orphan-handling) and [TROUBLESHOOTING.md](TROUBLESHOOTING.md#import-fails-with-missing-parent-errors) for more details.\n\n### Migration\n\n```bash\n# Migrate databases after version upgrade\nbd migrate                                             # Detect and migrate old databases\nbd migrate --dry-run                                   # Preview migration\nbd migrate --cleanup --yes                             # Migrate and remove old files\n\n# AI-supervised migration (check before running bd migrate)\nbd migrate --inspect --json                            # Show migration plan for AI agents\nbd info --schema --json                                # Get schema, tables, config, sample IDs\n```\n\n**Migration workflow for AI agents:**\n\n1. Run `--inspect` to see pending migrations and warnings\n2. Check for `missing_config` (like issue_prefix)\n3. Review `invariants_to_check` for safety guarantees\n4. If warnings exist, fix config issues first\n5. Then run `bd migrate` safely\n\n**Migration safety invariants:**\n\n- **required_config_present**: Ensures issue_prefix and schema_version are set\n- **foreign_keys_valid**: No orphaned dependencies or labels\n- **issue_count_stable**: Issue count doesn't decrease unexpectedly\n\nThese invariants prevent data loss and would have caught issues like GH #201 (missing issue_prefix after migration).\n\n### Daemon Management\n\nSee [docs/DAEMON.md](DAEMON.md) for complete daemon management reference.\n\n```bash\n# List all running daemons\nbd daemons list --json\n\n# Check health (version mismatches, stale sockets)\nbd daemons health --json\n\n# Stop/restart specific daemon\nbd daemons stop /path/to/workspace --json\nbd daemons restart 12345 --json  # By PID\n\n# View daemon logs\nbd daemons logs /path/to/workspace -n 100\nbd daemons logs 12345 -f  # Follow mode\n\n# Stop all daemons\nbd daemons killall --json\nbd daemons killall --force --json  # Force kill if graceful fails\n```\n\n### Sync Operations\n\n```bash\n# Manual sync (force immediate export/import/commit/push)\nbd sync\n\n# What it does:\n# 1. Export pending changes to JSONL\n# 2. Commit to git\n# 3. Pull from remote\n# 4. Import any updates\n# 5. Push to remote\n```\n\n## Issue Types\n\n- `bug` - Something broken that needs fixing\n- `feature` - New functionality\n- `task` - Work item (tests, docs, refactoring)\n- `epic` - Large feature composed of multiple issues (supports hierarchical children)\n- `chore` - Maintenance work (dependencies, tooling)\n\n**Hierarchical children:** Epics can have child issues with dotted IDs (e.g., `bd-a3f8e9.1`, `bd-a3f8e9.2`). Children are auto-numbered sequentially. Up to 3 levels of nesting supported.\n\n## Priorities\n\n- `0` - Critical (security, data loss, broken builds)\n- `1` - High (major features, important bugs)\n- `2` - Medium (nice-to-have features, minor bugs)\n- `3` - Low (polish, optimization)\n- `4` - Backlog (future ideas)\n\n## Dependency Types\n\n- `blocks` - Hard dependency (issue X blocks issue Y)\n- `related` - Soft relationship (issues are connected)\n- `parent-child` - Epic/subtask relationship\n- `discovered-from` - Track issues discovered during work\n\nOnly `blocks` dependencies affect the ready work queue.\n\n**Note:** When creating an issue with a `discovered-from` dependency, the new issue automatically inherits the parent's `source_repo` field.\n\n## Output Formats\n\n### JSON Output (Recommended for Agents)\n\nAlways use `--json` flag for programmatic use:\n\n```bash\n# Single issue\nbd show bd-42 --json\n\n# List of issues\nbd ready --json\n\n# Operation result\nbd create \"Issue\" -p 1 --json\n```\n\n### Human-Readable Output\n\nDefault output without `--json`:\n\n```bash\nbd ready\n# bd-42  Fix authentication bug  [P1, bug, in_progress]\n# bd-43  Add user settings page  [P2, feature, open]\n```\n\n## Common Patterns for AI Agents\n\n### Claim and Complete Work\n\n```bash\n# 1. Find available work\nbd ready --json\n\n# 2. Claim issue\nbd update bd-42 --status in_progress --json\n\n# 3. Work on it...\n\n# 4. Close when done\nbd close bd-42 --reason \"Implemented and tested\" --json\n```\n\n### Discover and Link Work\n\n```bash\n# While working on bd-100, discover a bug\n\n# Old way (two commands):\nbd create \"Found auth bug\" -t bug -p 1 --json  # Returns bd-101\nbd dep add bd-101 bd-100 --type discovered-from\n\n# New way (one command):\nbd create \"Found auth bug\" -t bug -p 1 --deps discovered-from:bd-100 --json\n```\n\n### Batch Operations\n\n```bash\n# Update multiple issues at once\nbd update bd-41 bd-42 bd-43 --priority 0 --json\n\n# Close multiple issues\nbd close bd-41 bd-42 bd-43 --reason \"Batch completion\" --json\n\n# Add label to multiple issues\nbd label add bd-41 bd-42 bd-43 urgent --json\n```\n\n### Session Workflow\n\n```bash\n# Start of session\nbd ready --json  # Find work\n\n# During session\nbd create \"...\" -p 1 --json\nbd update bd-42 --status in_progress --json\n# ... work ...\n\n# End of session (IMPORTANT!)\nbd sync  # Force immediate sync, bypass debounce\n```\n\n**ALWAYS run `bd sync` at end of agent sessions** to ensure changes are committed/pushed immediately.\n\n## See Also\n\n- [AGENTS.md](../AGENTS.md) - Main agent workflow guide\n- [DAEMON.md](DAEMON.md) - Daemon management and event-driven mode\n- [GIT_INTEGRATION.md](GIT_INTEGRATION.md) - Git workflows and merge strategies\n- [LABELS.md](../LABELS.md) - Label system guide\n- [README.md](../README.md) - User documentation\n",
        "skills/beads/resources/DEPENDENCIES.md": "# Dependency Types Guide\n\nDeep dive into bd's four dependency types: blocks, related, parent-child, and discovered-from.\n\n## Contents\n\n- [Overview](#overview) - Four types at a glance, which affect bd ready?\n- [blocks - Hard Blocker](#blocks---hard-blocker)\n  - [When to Use](#when-to-use) - Prerequisites, sequential steps, build order\n  - [When NOT to Use](#when-not-to-use) - Soft preferences, parallel work\n  - [Examples](#examples) - API development, migrations, library dependencies\n  - [Creating blocks Dependencies](#creating-blocks-dependencies)\n  - [Common Patterns](#common-patterns) - Build foundation first, migration sequences, testing gates\n  - [Automatic Unblocking](#automatic-unblocking)\n- [related - Soft Link](#related---soft-link)\n  - [When to Use](#when-to-use-1) - Context, related features, parallel work\n  - [When NOT to Use](#when-not-to-use-1)\n  - [Examples](#examples-1) - Feature context, research links, parallel development\n  - [Creating related Dependencies](#creating-related-dependencies)\n  - [Common Patterns](#common-patterns-1) - Context clusters, research threads, feature families\n- [parent-child - Hierarchical](#parent-child---hierarchical)\n  - [When to Use](#when-to-use-2) - Epics/subtasks, phases\n  - [When NOT to Use](#when-not-to-use-2)\n  - [Examples](#examples-2) - Epic with subtasks, phased projects\n  - [Creating parent-child Dependencies](#creating-parent-child-dependencies)\n  - [Combining with blocks](#combining-with-blocks)\n  - [Common Patterns](#common-patterns-2) - Epic decomposition, nested hierarchies\n- [discovered-from - Provenance](#discovered-from---provenance)\n  - [When to Use](#when-to-use-3) - Side quests, research findings\n  - [Why This Matters](#why-this-matters)\n  - [Examples](#examples-3) - Bug discovered during feature work, research branches\n  - [Creating discovered-from Dependencies](#creating-discovered-from-dependencies)\n  - [Common Patterns](#common-patterns-3) - Discovery during implementation, research expansion\n  - [Combining with blocks](#combining-with-blocks-1)\n- [Decision Guide](#decision-guide)\n  - [Decision Tree](#decision-tree)\n  - [Quick Reference by Situation](#quick-reference-by-situation)\n- [Common Mistakes](#common-mistakes)\n  - Using blocks for preferences, using discovered-from for planning, not using dependencies, over-using blocks, wrong direction\n- [Advanced Patterns](#advanced-patterns)\n  - Diamond dependencies, optional dependencies, discovery cascade, epic with phases\n- [Visualization](#visualization)\n- [Summary](#summary)\n\n## Overview\n\nbd supports four dependency types that serve different purposes in organizing and tracking work:\n\n| Type | Purpose | Affects `bd ready`? | Common Use |\n|------|---------|---------------------|------------|\n| **blocks** | Hard blocker | Yes - blocked issues excluded | Sequential work, prerequisites |\n| **related** | Soft link | No - just informational | Context, related work |\n| **parent-child** | Hierarchy | No - structural only | Epics and subtasks |\n| **discovered-from** | Provenance | No - tracks origin | Side quests, research findings |\n\n**Key insight**: Only `blocks` dependencies affect what work is ready. The other three provide structure and context.\n\n---\n\n## blocks - Hard Blocker\n\n**Semantics**: Issue A blocks issue B. B cannot start until A is complete.\n\n**Effect**: Issue B disappears from `bd ready` until issue A is closed.\n\n### When to Use\n\nUse `blocks` when work literally cannot proceed:\n\n- **Prerequisites**: Database schema must exist before endpoints can use it\n- **Sequential steps**: Migration step 1 must complete before step 2\n- **Build order**: Foundation must be done before building on top\n- **Technical blockers**: Library must be installed before code can use it\n\n### When NOT to Use\n\nDon't use `blocks` for:\n\n- **Soft preferences**: \"Should do X before Y but could do either\"\n- **Parallel work**: Both can proceed independently\n- **Information links**: Just want to note relationship\n- **Recommendations**: \"Would be better if done in this order\"\n\nUse `related` instead for soft connections.\n\n### Examples\n\n**Example 1: API Development**\n\n```\ndb-schema-1: \"Create users table\"\n  blocks\napi-endpoint-2: \"Add GET /users endpoint\"\n\nWhy: Endpoint literally needs table to exist\nEffect: api-endpoint-2 won't show in bd ready until db-schema-1 closed\n```\n\n**Example 2: Migration Sequence**\n\n```\nmigrate-1: \"Backup production database\"\n  blocks\nmigrate-2: \"Run schema migration\"\n  blocks\nmigrate-3: \"Verify data integrity\"\n\nWhy: Each step must complete before next can safely proceed\nEffect: bd ready shows only migrate-1; closing it reveals migrate-2, etc.\n```\n\n**Example 3: Library Installation**\n\n```\nsetup-1: \"Install JWT library\"\n  blocks\nauth-2: \"Implement JWT validation\"\n\nWhy: Code won't compile/run without library\nEffect: Can't start auth-2 until setup-1 complete\n```\n\n### Creating blocks Dependencies\n\n```bash\nbd dep add prerequisite-issue blocked-issue\n# or explicitly:\nbd dep add prerequisite-issue blocked-issue --type blocks\n```\n\n**Direction matters**: `from_id` blocks `to_id`. Think: \"prerequisite blocks dependent\".\n\n### Common Patterns\n\n**Pattern: Build Foundation First**\n\n```\nfoundation-1: \"Set up authentication system\"\n  blocks all of:\n    - feature-2: \"Add user profiles\"\n    - feature-3: \"Add admin panel\"\n    - feature-4: \"Add API access\"\n\nOne foundational issue blocks multiple dependent features.\n```\n\n**Pattern: Sequential Pipeline**\n\n```\nstep-1 blocks step-2 blocks step-3 blocks step-4\n\nLinear chain where each step depends on previous.\nbd ready shows only current step.\n```\n\n**Pattern: Parallel Then Merge**\n\n```\nresearch-1: \"Investigate option A\"\nresearch-2: \"Investigate option B\"\nresearch-3: \"Investigate option C\"\nAll three block:\n  decision-4: \"Choose approach based on research\"\n\nMultiple parallel tasks must complete before next step.\n```\n\n### Automatic Unblocking\n\nWhen you close an issue that's blocking others:\n\n```\n1. Close db-schema-1\n2. bd automatically updates: api-endpoint-2 is now ready\n3. bd ready shows api-endpoint-2\n4. No manual unblocking needed\n```\n\nThis is why `blocks` is powerful - bd maintains ready state automatically.\n\n---\n\n## related - Soft Link\n\n**Semantics**: Issues are related but neither blocks the other.\n\n**Effect**: No impact on `bd ready`. Pure informational link.\n\n### When to Use\n\nUse `related` for context and discoverability:\n\n- **Similar work**: \"These tackle the same problem from different angles\"\n- **Shared context**: \"Working on one provides insight for the other\"\n- **Alternative approaches**: \"These are different ways to solve X\"\n- **Complementary features**: \"These work well together but aren't required\"\n\n### When NOT to Use\n\nDon't use `related` if:\n\n- One actually blocks the other â†’ use `blocks`\n- One discovered the other â†’ use `discovered-from`\n- One is parent of the other â†’ use `parent-child`\n\n### Examples\n\n**Example 1: Related Refactoring**\n\n```\nrefactor-1: \"Extract validation logic\"\n  related to\nrefactor-2: \"Extract error handling logic\"\n\nWhy: Both are refactoring efforts, similar patterns, but independent\nEffect: None on ready state; just notes the relationship\n```\n\n**Example 2: Documentation and Code**\n\n```\nfeature-1: \"Add OAuth login\"\n  related to\ndocs-2: \"Document OAuth setup\"\n\nWhy: Docs and feature go together, but can be done in any order\nEffect: Can work on either whenever; just notes they're connected\n```\n\n**Example 3: Alternative Approaches**\n\n```\nperf-1: \"Investigate Redis caching\"\n  related to\nperf-2: \"Investigate CDN caching\"\n\nWhy: Both address performance, different approaches, explore both\nEffect: Both show in bd ready; choosing one doesn't block the other\n```\n\n### Creating related Dependencies\n\n```bash\nbd dep add issue-1 issue-2 --type related\n```\n\n**Direction doesn't matter** for `related` - it's a symmetric link.\n\n### Common Patterns\n\n**Pattern: Cluster Related Work**\n\n```\napi-redesign related to:\n  - api-docs-update\n  - api-client-update\n  - api-tests-update\n  - api-versioning\n\nGroup of issues all related to API work.\nUse related to show they're part of same initiative.\n```\n\n**Pattern: Cross-Cutting Concerns**\n\n```\nsecurity-audit related to:\n  - auth-module\n  - api-endpoints\n  - database-access\n  - frontend-forms\n\nSecurity audit touches multiple areas.\nRelated links show what areas it covers.\n```\n\n---\n\n## parent-child - Hierarchical\n\n**Semantics**: Issue A is parent of issue B. Typically A is an epic, B is a subtask.\n\n**Effect**: No impact on `bd ready`. Creates hierarchical structure.\n\n### When to Use\n\nUse `parent-child` for breaking down large work:\n\n- **Epics and subtasks**: Big feature split into smaller pieces\n- **Hierarchical organization**: Logical grouping of related tasks\n- **Progress tracking**: See completion of children relative to parent\n- **Work breakdown structure**: Decompose complex work\n\n### When NOT to Use\n\nDon't use `parent-child` if:\n\n- Siblings need ordering â†’ add `blocks` between children\n- Relationship is equality â†’ use `related`\n- Just discovered one from the other â†’ use `discovered-from`\n\n### Examples\n\n**Example 1: Feature Epic**\n\n```\noauth-epic: \"Implement OAuth integration\" (epic)\n  parent of:\n    - oauth-1: \"Set up OAuth credentials\" (task)\n    - oauth-2: \"Implement authorization flow\" (task)\n    - oauth-3: \"Add token refresh\" (task)\n    - oauth-4: \"Create login UI\" (task)\n\nWhy: Epic decomposed into implementable tasks\nEffect: Hierarchical structure; all show in bd ready (unless blocked)\n```\n\n**Example 2: Research with Findings**\n\n```\nresearch-epic: \"Investigate caching strategies\" (epic)\n  parent of:\n    - research-1: \"Redis evaluation\"\n    - research-2: \"Memcached evaluation\"\n    - research-3: \"CDN evaluation\"\n    - decision-4: \"Choose caching approach\"\n\nWhy: Research project with multiple investigation threads\nEffect: Can track progress across all investigations\n```\n\n### Creating parent-child Dependencies\n\n```bash\nbd dep add child-task-id parent-epic-id --type parent-child\n```\n\n**Direction matters**: The child depends on the parent. Think: \"child depends on parent\" or \"task is part of epic\".\n\n### Combining with blocks\n\nParent-child gives structure; blocks gives ordering:\n\n```\nauth-epic (parent of all)\n  â”œâ”€ auth-1: \"Install library\"\n  â”œâ”€ auth-2: \"Create middleware\" (blocked by auth-1)\n  â”œâ”€ auth-3: \"Add endpoints\" (blocked by auth-2)\n  â””â”€ auth-4: \"Add tests\" (blocked by auth-3)\n\nparent-child: Shows these are all part of auth epic\nblocks: Shows they must be done in order\n```\n\n### Common Patterns\n\n**Pattern: Epic with Independent Subtasks**\n\n```\nEpic with no ordering between children:\nAll children show in bd ready immediately.\nWork on any child in any order.\nClose epic when all children complete.\n```\n\n**Pattern: Epic with Sequential Subtasks**\n\n```\nEpic with blocks dependencies between children:\nbd ready shows only first child.\nClosing each child unblocks next.\nEpic provides structure, blocks provides order.\n```\n\n**Pattern: Nested Epics**\n\n```\nmajor-epic\n  â”œâ”€ sub-epic-1\n  â”‚   â”œâ”€ task-1a\n  â”‚   â””â”€ task-1b\n  â””â”€ sub-epic-2\n      â”œâ”€ task-2a\n      â””â”€ task-2b\n\nMultiple levels of hierarchy for complex projects.\n```\n\n---\n\n## discovered-from - Provenance\n\n**Semantics**: Issue B was discovered while working on issue A.\n\n**Effect**: No impact on `bd ready`. Tracks origin and provides context.\n\n### When to Use\n\nUse `discovered-from` to preserve discovery context:\n\n- **Side quests**: Found new work during implementation\n- **Research findings**: Discovered issue while investigating\n- **Bug found during feature work**: Context of discovery matters\n- **Follow-up work**: Identified next steps during current work\n\n### Why This Matters\n\nKnowing where an issue came from helps:\n\n- **Understand context**: Why was this created?\n- **Reconstruct thinking**: What led to this discovery?\n- **Assess relevance**: Is this still important given original context?\n- **Track exploration**: See what emerged from research\n\n### Examples\n\n**Example 1: Bug During Feature**\n\n```\nfeature-10: \"Add user profiles\"\n  discovered-from leads to\nbug-11: \"Existing auth doesn't handle profile permissions\"\n\nWhy: While adding profiles, discovered auth system inadequate\nContext: Bug might not exist if profiles weren't being added\n```\n\n**Example 2: Research Findings**\n\n```\nresearch-5: \"Investigate caching options\"\n  discovered-from leads to\nfinding-6: \"Redis supports persistence unlike Memcached\"\nfinding-7: \"CDN caching incompatible with our auth model\"\ndecision-8: \"Choose Redis based on findings\"\n\nWhy: Research generated specific findings\nContext: Findings only relevant in context of research question\n```\n\n**Example 3: Refactoring Reveals Technical Debt**\n\n```\nrefactor-20: \"Extract validation logic\"\n  discovered-from leads to\ndebt-21: \"Validation inconsistent across controllers\"\ndebt-22: \"No validation for edge cases\"\nimprovement-23: \"Could add validation library\"\n\nWhy: Refactoring work revealed multiple related issues\nContext: Issues discovered as side effect of refactoring\n```\n\n### Creating discovered-from Dependencies\n\n```bash\nbd dep add original-work-id discovered-issue-id --type discovered-from\n```\n\n**Direction matters**: `to_id` was discovered while working on `from_id`.\n\n### Common Patterns\n\n**Pattern: Exploration Tree**\n\n```\nspike-1: \"Investigate API redesign\"\n  discovered-from â†’\n    finding-2: \"Current API mixes REST and GraphQL\"\n    finding-3: \"Authentication not consistent\"\n    finding-4: \"Rate limiting missing\"\n\nOne exploration generates multiple findings.\nTree structure shows exploration process.\n```\n\n**Pattern: Bug Investigation Chain**\n\n```\nbug-1: \"Login fails intermittently\"\n  discovered-from â†’\n    bug-2: \"Race condition in session creation\"\n      discovered-from â†’\n        bug-3: \"Database connection pool too small\"\n\nInvestigation of one bug reveals root cause as another bug.\nChain shows how you got from symptom to cause.\n```\n\n**Pattern: Feature Implementation Side Quests**\n\n```\nfeature-main: \"Add shopping cart\"\n  discovered-from â†’\n    improvement-a: \"Product images should be cached\"\n    bug-b: \"Price formatting wrong for some locales\"\n    debt-c: \"Inventory system needs refactoring\"\n\nMain feature work generates tangential discoveries.\nCaptured for later without derailing main work.\n```\n\n### Combining with blocks\n\nCan use both together:\n\n```\nfeature-10: \"Add user profiles\"\n  discovered-from â†’\n    bug-11: \"Auth system needs role-based access\"\n      blocks â†’\n        feature-10: \"Add user profiles\"\n\nDiscovery: Found bug during feature work\nAssessment: Bug actually blocks feature\nActions: Mark feature blocked, work on bug first\n```\n\n---\n\n## Decision Guide\n\n**\"Which dependency type should I use?\"**\n\n### Decision Tree\n\n```\nDoes Issue A prevent Issue B from starting?\n  YES â†’ blocks\n  NO â†“\n\nIs Issue B a subtask of Issue A?\n  YES â†’ parent-child (A parent, B child)\n  NO â†“\n\nWas Issue B discovered while working on Issue A?\n  YES â†’ discovered-from (A original, B discovered)\n  NO â†“\n\nAre Issues A and B just related?\n  YES â†’ related\n```\n\n### Quick Reference by Situation\n\n| Situation | Use |\n|-----------|-----|\n| B needs A complete to start | blocks |\n| B is part of A (epic/task) | parent-child |\n| Found B while working on A | discovered-from |\n| A and B are similar/connected | related |\n| B should come after A but could start | related + note |\n| A and B are alternatives | related |\n| B is follow-up to A | discovered-from |\n\n---\n\n## Common Mistakes\n\n### Mistake 1: Using blocks for Preferences\n\n**Wrong**:\n```\ndocs-1: \"Update documentation\"\n  blocks\nfeature-2: \"Add new feature\"\n\nReason: \"We prefer to update docs first\"\n```\n\n**Problem**: Documentation doesn't actually block feature implementation.\n\n**Right**: Use `related` or don't link at all. If you want ordering, note it in issue descriptions but don't enforce with blocks.\n\n### Mistake 2: Using discovered-from for Planning\n\n**Wrong**:\n```\nepic-1: \"OAuth integration\"\n  discovered-from â†’\n    task-2: \"Set up OAuth credentials\"\n\nReason: \"I'm planning these tasks from the epic\"\n```\n\n**Problem**: `discovered-from` is for emergent discoveries, not planned decomposition.\n\n**Right**: Use `parent-child` for planned task breakdown.\n\n### Mistake 3: Not Using Any Dependencies\n\n**Symptom**: Long list of issues with no structure.\n\n**Problem**: Can't tell what's blocked, what's related, how work is organized.\n\n**Solution**: Add structure with dependencies:\n- Group with parent-child\n- Order with blocks\n- Link with related\n- Track discovery with discovered-from\n\n### Mistake 4: Over-Using blocks\n\n**Wrong**:\n```\nEverything blocks everything else in strict sequential order.\n```\n\n**Problem**: No parallel work possible; `bd ready` shows only one issue.\n\n**Right**: Only use `blocks` for actual technical dependencies. Allow parallel work where possible.\n\n### Mistake 5: Wrong Direction\n\n**Wrong**:\n```bash\nbd dep add api-endpoint database-schema\n\nMeaning: api-endpoint blocks database-schema\n```\n\n**Problem**: Backwards! Schema should block endpoint, not other way around.\n\n**Right**:\n```bash\nbd dep add database-schema api-endpoint\n\nMeaning: database-schema blocks api-endpoint\n```\n\n**Mnemonic**: \"from_id blocks to_id\" or \"prerequisite blocks dependent\"\n\n---\n\n## Advanced Patterns\n\n### Pattern: Diamond Dependencies\n\n```\n        setup\n       /    \\\n   impl-a  impl-b\n       \\    /\n       testing\n\nsetup blocks both impl-a and impl-b\nboth impl-a and impl-b block testing\n```\n\nBoth implementations must complete before testing can begin.\n\n### Pattern: Optional Dependencies\n\n```\ncore-feature (ready immediately)\n  related to\nnice-to-have (ready immediately)\n\nBoth can be done, neither blocks the other.\nUse related to show they're connected.\n```\n\n### Pattern: Discovery Cascade\n\n```\nresearch-main\n  discovered-from â†’ finding-1\n  discovered-from â†’ finding-2\n    discovered-from â†’ deep-finding-3\n\nResearch generates findings.\nFindings generate deeper findings.\nTree shows discovery process.\n```\n\n### Pattern: Epic with Phases\n\n```\nauth-epic\n  parent of phase-1-epic\n    parent of: setup-1, setup-2, setup-3\n  parent of phase-2-epic\n    parent of: implement-1, implement-2\n  parent of phase-3-epic\n    parent of: test-1, test-2\n\nphase-1-epic blocks phase-2-epic blocks phase-3-epic\n\nNested hierarchy with phase ordering.\n```\n\n---\n\n## Visualization\n\nWhen you run `bd show issue-id` on an issue, you see:\n\n```\nIssue: feature-10\nDependencies (blocks this issue):\n  - setup-5: \"Install library\"\n  - config-6: \"Add configuration\"\n\nDependents (blocked by this issue):\n  - test-12: \"Add integration tests\"\n  - docs-13: \"Document new feature\"\n\nRelated:\n  - refactor-8: \"Similar refactoring effort\"\n\nDiscovered from:\n  - research-3: \"API investigation\"\n```\n\nThis shows the full dependency context for an issue.\n\n---\n\n## Summary\n\n**Four dependency types, four different purposes:**\n\n1. **blocks**: Sequential work, prerequisites, hard blockers\n   - Affects bd ready\n   - Use for technical dependencies only\n\n2. **related**: Context, similar work, soft connections\n   - Informational only\n   - Use liberally for discoverability\n\n3. **parent-child**: Epics and subtasks, hierarchical structure\n   - Organizational only\n   - Use for work breakdown\n\n4. **discovered-from**: Side quests, research findings, provenance\n   - Context preservation\n   - Use to track emergence\n\n**Key insight**: Only `blocks` affects what work is ready. The other three provide rich context without constraining execution.\n\nUse dependencies to create a graph that:\n- Automatically maintains ready work\n- Preserves discovery context\n- Shows project structure\n- Links related work\n\nThis graph becomes the persistent memory that survives compaction and enables long-horizon agent work.\n",
        "skills/beads/resources/INTEGRATION_PATTERNS.md": "# Integration Patterns with Other Skills\n\nHow bd-issue-tracking integrates with TodoWrite, writing-plans, and other skills for optimal workflow.\n\n## Contents\n\n- [TodoWrite Integration](#todowrite-integration) - Temporal layering pattern\n- [writing-plans Integration](#writing-plans-integration) - Detailed implementation plans\n- [Cross-Skill Workflows](#cross-skill-workflows) - Using multiple skills together\n- [Decision Framework](#decision-framework) - When to use which tool\n\n---\n\n## TodoWrite Integration\n\n**Both tools complement each other at different timescales:**\n\n### Temporal Layering Pattern\n\n**TodoWrite** (short-term working memory - this hour):\n- Tactical execution: \"Review Section 3\", \"Expand Q&A answers\"\n- Marked completed as you go\n- Present/future tense (\"Review\", \"Expand\", \"Create\")\n- Ephemeral: Disappears when session ends\n\n**Beads** (long-term episodic memory - this week/month):\n- Strategic objectives: \"Continue work on strategic planning document\"\n- Key decisions and outcomes in notes field\n- Past tense in notes (\"COMPLETED\", \"Discovered\", \"Blocked by\")\n- Persistent: Survives compaction and session boundaries\n\n**Key insight**: TodoWrite = working copy for the current hour. Beads = project journal for the current month.\n\n### The Handoff Pattern\n\n1. **Session start**: Read bead â†’ Create TodoWrite items for immediate actions\n2. **During work**: Mark TodoWrite items completed as you go\n3. **Reach milestone**: Update bead notes with outcomes + context\n4. **Session end**: TodoWrite disappears, bead survives with enriched notes\n\n**After compaction**: TodoWrite is gone forever, but bead notes reconstruct what happened.\n\n### Example: TodoWrite tracks execution, Beads capture meaning\n\n**TodoWrite (ephemeral execution view):**\n```\n[completed] Implement login endpoint\n[in_progress] Add password hashing with bcrypt\n[pending] Create session middleware\n```\n\n**Corresponding bead notes (persistent context):**\n```bash\nbd update issue-123 --notes \"COMPLETED: Login endpoint with bcrypt password\nhashing (12 rounds). KEY DECISION: Using JWT tokens (not sessions) for stateless\nauth - simplifies horizontal scaling. IN PROGRESS: Session middleware implementation.\nNEXT: Need user input on token expiry time (1hr vs 24hr trade-off).\"\n```\n\n**What's different**:\n- TodoWrite: Task names (what to do)\n- Beads: Outcomes and decisions (what was learned, why it matters)\n\n**Don't duplicate**: TodoWrite tracks execution, Beads captures meaning and context.\n\n### When to Update Each Tool\n\n**Update TodoWrite** (frequently):\n- Mark task completed as you finish each one\n- Add new tasks as you break down work\n- Update in_progress when switching tasks\n\n**Update Beads** (at milestones):\n- Completed a significant piece of work\n- Made a key decision that needs documentation\n- Hit a blocker that pauses progress\n- About to ask user for input\n- Session token usage > 70%\n- End of session\n\n**Pattern**: TodoWrite changes every few minutes. Beads updates every hour or at natural breakpoints.\n\n### Full Workflow Example\n\n**Scenario**: Implement OAuth authentication (multi-session work)\n\n**Session 1 - Planning**:\n```bash\n# Create bd issue\nbd create \"Implement OAuth authentication\" -t feature -p 0 --design \"\nJWT tokens with refresh rotation.\nSee BOUNDARIES.md for bd vs TodoWrite decision.\n\"\n\n# Mark in_progress\nbd update oauth-1 --status in_progress\n\n# Create TodoWrite for today's work\nTodoWrite:\n- [ ] Research OAuth 2.0 refresh token flow\n- [ ] Design token schema\n- [ ] Set up test environment\n```\n\n**End of Session 1**:\n```bash\n# Update bd with outcomes\nbd update oauth-1 --notes \"COMPLETED: Researched OAuth2 refresh flow. Decided on 7-day refresh tokens.\nKEY DECISION: RS256 over HS256 (enables key rotation per security review).\nIN PROGRESS: Need to set up test OAuth provider.\nNEXT: Configure test provider, then implement token endpoint.\"\n\n# TodoWrite disappears when session ends\n```\n\n**Session 2 - Implementation** (after compaction):\n```bash\n# Read bd to reconstruct context\nbd show oauth-1\n# See: COMPLETED research, NEXT is configure test provider\n\n# Create fresh TodoWrite from NEXT\nTodoWrite:\n- [ ] Configure test OAuth provider\n- [ ] Implement token endpoint\n- [ ] Add basic tests\n\n# Work proceeds...\n\n# Update bd at milestone\nbd update oauth-1 --notes \"COMPLETED: Test provider configured, token endpoint implemented.\nTESTS: 5 passing (token generation, validation, expiry).\nIN PROGRESS: Adding refresh token rotation.\nNEXT: Implement rotation, add rate limiting, security review.\"\n```\n\n**For complete decision criteria and boundaries, see:** [BOUNDARIES.md](BOUNDARIES.md)\n\n---\n\n## writing-plans Integration\n\n**For complex multi-step features**, the design field in bd issues can link to detailed implementation plans that break work into bite-sized RED-GREEN-REFACTOR steps.\n\n### When to Create Detailed Plans\n\n**Use detailed plans for:**\n- Complex features with multiple components\n- Multi-session work requiring systematic breakdown\n- Features where TDD discipline adds value (core logic, critical paths)\n- Work that benefits from explicit task sequencing\n\n**Skip detailed plans for:**\n- Simple features (single function, straightforward logic)\n- Exploratory work (API testing, pattern discovery)\n- Infrastructure setup (configuration, wiring)\n\n**The test:** If you can implement it in one session without a checklist, skip the detailed plan.\n\n### Using the writing-plans Skill\n\nWhen design field needs detailed breakdown, reference the **writing-plans** skill:\n\n**Pattern:**\n```bash\n# Create issue with high-level design\nbd create \"Implement OAuth token refresh\" --design \"\nAdd JWT refresh token flow with rotation.\nSee docs/plans/2025-10-23-oauth-refresh-design.md for detailed plan.\n\"\n\n# Then use writing-plans skill to create detailed plan\n# The skill creates: docs/plans/YYYY-MM-DD-<feature-name>.md\n```\n\n**Detailed plan structure** (from writing-plans):\n- Bite-sized tasks (2-5 minutes each)\n- Explicit RED-GREEN-REFACTOR steps per task\n- Exact file paths and complete code\n- Verification commands with expected output\n- Frequent commit points\n\n**Example task from detailed plan:**\n```markdown\n### Task 1: Token Refresh Endpoint\n\n**Files:**\n- Create: `src/auth/refresh.py`\n- Test: `tests/auth/test_refresh.py`\n\n**Step 1: Write failing test**\n```python\ndef test_refresh_token_returns_new_access_token():\n    refresh_token = create_valid_refresh_token()\n    response = refresh_endpoint(refresh_token)\n    assert response.status == 200\n    assert response.access_token is not None\n```\n\n**Step 2: Run test to verify it fails**\nRun: `pytest tests/auth/test_refresh.py::test_refresh_token_returns_new_access_token -v`\nExpected: FAIL with \"refresh_endpoint not defined\"\n\n**Step 3: Implement minimal code**\n[... exact implementation ...]\n\n**Step 4: Verify test passes**\n[... verification ...]\n\n**Step 5: Commit**\n```bash\ngit add tests/auth/test_refresh.py src/auth/refresh.py\ngit commit -m \"feat: add token refresh endpoint\"\n```\n```\n\n### Integration with bd Workflow\n\n**Three-layer structure**:\n1. **bd issue**: Strategic objective + high-level design\n2. **Detailed plan** (writing-plans): Step-by-step execution guide\n3. **TodoWrite**: Current task within the plan\n\n**During planning phase:**\n1. Create bd issue with high-level design\n2. If complex: Use writing-plans skill to create detailed plan\n3. Link plan in design field: `See docs/plans/YYYY-MM-DD-<topic>.md`\n\n**During execution phase:**\n1. Open detailed plan (if exists)\n2. Use TodoWrite to track current task within plan\n3. Update bd notes at milestones, not per-task\n4. Close bd issue when all plan tasks complete\n\n**Don't duplicate:** Detailed plan = execution steps. BD notes = outcomes and decisions.\n\n**Example bd notes after using detailed plan:**\n```bash\nbd update oauth-5 --notes \"COMPLETED: Token refresh endpoint (5 tasks from plan: endpoint + rotation + tests)\nKEY DECISION: 7-day refresh tokens (vs 30-day) - reduces risk of token theft\nTESTS: All 12 tests passing (auth, rotation, expiry, error handling)\"\n```\n\n### When NOT to Use Detailed Plans\n\n**Red flags:**\n- Feature is simple enough to implement in one pass\n- Work is exploratory (discovering patterns, testing APIs)\n- Infrastructure work (OAuth setup, MCP configuration)\n- Would spend more time planning than implementing\n\n**Rule of thumb:** Use detailed plans when systematic breakdown prevents mistakes, not for ceremony.\n\n**Pattern summary**:\n- **Simple feature**: bd issue only\n- **Complex feature**: bd issue + TodoWrite\n- **Very complex feature**: bd issue + writing-plans + TodoWrite\n\n---\n\n## Cross-Skill Workflows\n\n### Pattern: Research Document with Strategic Planning\n\n**Scenario**: User asks \"Help me write a strategic planning document for Q4\"\n\n**Tools used**: bd-issue-tracking + developing-strategic-documents skill\n\n**Workflow**:\n1. Create bd issue for tracking:\n   ```bash\n   bd create \"Q4 strategic planning document\" -t task -p 0\n   bd update strat-1 --status in_progress\n   ```\n\n2. Use developing-strategic-documents skill for research and writing\n\n3. Update bd notes at milestones:\n   ```bash\n   bd update strat-1 --notes \"COMPLETED: Research phase (reviewed 5 competitor docs, 3 internal reports)\n   KEY DECISION: Focus on market expansion over cost optimization per exec input\n   IN PROGRESS: Drafting recommendations section\n   NEXT: Get exec review of draft recommendations before finalizing\"\n   ```\n\n4. TodoWrite tracks immediate writing tasks:\n   ```\n   - [ ] Draft recommendation 1: Market expansion\n   - [ ] Add supporting data from research\n   - [ ] Create budget estimates\n   ```\n\n**Why this works**: bd preserves context across sessions (document might take days), skill provides writing framework, TodoWrite tracks current work.\n\n### Pattern: Multi-File Refactoring\n\n**Scenario**: Refactor authentication system across 8 files\n\n**Tools used**: bd-issue-tracking + systematic-debugging (if issues found)\n\n**Workflow**:\n1. Create epic and subtasks:\n   ```bash\n   bd create \"Refactor auth system to use JWT\" -t epic -p 0\n   bd create \"Update login endpoint\" -t task\n   bd create \"Update token validation\" -t task\n   bd create \"Update middleware\" -t task\n   bd create \"Update tests\" -t task\n\n   # Link hierarchy\n   bd dep add auth-epic login-1 --type parent-child\n   bd dep add auth-epic validation-2 --type parent-child\n   bd dep add auth-epic middleware-3 --type parent-child\n   bd dep add auth-epic tests-4 --type parent-child\n\n   # Add ordering\n   bd dep add validation-2 login-1  # validation depends on login\n   bd dep add middleware-3 validation-2  # middleware depends on validation\n   bd dep add tests-4 middleware-3  # tests depend on middleware\n   ```\n\n2. Work through subtasks in order, using TodoWrite for each:\n   ```\n   Current: login-1\n   TodoWrite:\n   - [ ] Update login route signature\n   - [ ] Add JWT generation\n   - [ ] Update tests\n   - [ ] Verify backward compatibility\n   ```\n\n3. Update bd notes as each completes:\n   ```bash\n   bd close login-1 --reason \"Updated to JWT. Tests passing. Backward compatible with session auth.\"\n   ```\n\n4. If issues discovered, use systematic-debugging skill + create blocker issues\n\n**Why this works**: bd tracks dependencies and progress across files, TodoWrite focuses on current file, skills provide specialized frameworks when needed.\n\n---\n\n## Decision Framework\n\n### Which Tool for Which Purpose?\n\n| Need | Tool | Why |\n|------|------|-----|\n| Track today's execution | TodoWrite | Lightweight, shows current progress |\n| Preserve context across sessions | bd | Survives compaction, persistent memory |\n| Detailed implementation steps | writing-plans | RED-GREEN-REFACTOR breakdown |\n| Research document structure | developing-strategic-documents | Domain-specific framework |\n| Debug complex issue | systematic-debugging | Structured debugging protocol |\n\n### Decision Tree\n\n```\nIs this work done in this session?\nâ”œâ”€ Yes â†’ Use TodoWrite only\nâ””â”€ No â†’ Use bd\n    â”œâ”€ Simple feature â†’ bd issue + TodoWrite\n    â””â”€ Complex feature â†’ bd issue + writing-plans + TodoWrite\n\nWill conversation history get compacted?\nâ”œâ”€ Likely â†’ Use bd (context survives)\nâ””â”€ Unlikely â†’ TodoWrite is sufficient\n\nDoes work have dependencies or blockers?\nâ”œâ”€ Yes â†’ Use bd (tracks relationships)\nâ””â”€ No â†’ TodoWrite is sufficient\n\nIs this specialized domain work?\nâ”œâ”€ Research/writing â†’ developing-strategic-documents\nâ”œâ”€ Complex debugging â†’ systematic-debugging\nâ”œâ”€ Detailed implementation â†’ writing-plans\nâ””â”€ General tracking â†’ bd + TodoWrite\n```\n\n### Integration Anti-Patterns\n\n**Don't**:\n- Duplicate TodoWrite tasks into bd notes (different purposes)\n- Create bd issues for single-session linear work (use TodoWrite)\n- Put detailed implementation steps in bd notes (use writing-plans)\n- Update bd after every TodoWrite task (update at milestones)\n- Use writing-plans for exploratory work (defeats the purpose)\n\n**Do**:\n- Update bd when changing tools or reaching milestones\n- Use TodoWrite as \"working copy\" of bd's NEXT section\n- Link between tools (bd design field â†’ writing-plans file path)\n- Choose the right level of formality for the work complexity\n\n---\n\n## Summary\n\n**Key principle**: Each tool operates at a different timescale and level of detail.\n\n- **TodoWrite**: Minutes to hours (current execution)\n- **bd**: Hours to weeks (persistent context)\n- **writing-plans**: Days to weeks (detailed breakdown)\n- **Other skills**: As needed (domain frameworks)\n\n**Integration pattern**: Use the lightest tool sufficient for the task, add heavier tools only when complexity demands it.\n\n**For complete boundaries and decision criteria, see:** [BOUNDARIES.md](BOUNDARIES.md)\n",
        "skills/beads/resources/ISSUE_CREATION.md": "# Issue Creation Guidelines\n\nGuidance on when and how to create bd issues for maximum effectiveness.\n\n## Contents\n\n- [When to Ask First vs Create Directly](#when-to-ask)\n- [Issue Quality](#quality)\n- [Making Issues Resumable](#resumable)\n- [Design vs Acceptance Criteria](#design-vs-acceptance)\n\n## When to Ask First vs Create Directly {#when-to-ask}\n\n### Ask the user before creating when:\n- Knowledge work with fuzzy boundaries\n- Task scope is unclear\n- Multiple valid approaches exist\n- User's intent needs clarification\n\n### Create directly when:\n- Clear bug discovered during implementation\n- Obvious follow-up work identified\n- Technical debt with clear scope\n- Dependency or blocker found\n\n**Why ask first for knowledge work?** Task boundaries in strategic/research work are often unclear until discussed, whereas technical implementation tasks are usually well-defined. Discussion helps structure the work properly before creating issues, preventing poorly-scoped issues that need immediate revision.\n\n## Issue Quality {#quality}\n\nUse clear, specific titles and include sufficient context in descriptions to resume work later.\n\n### Field Usage\n\n**Use --design flag for:**\n- Implementation approach decisions\n- Architecture notes\n- Trade-offs considered\n\n**Use --acceptance flag for:**\n- Definition of done\n- Testing requirements\n- Success metrics\n\n## Making Issues Resumable (Complex Technical Work) {#resumable}\n\nFor complex technical features spanning multiple sessions, enhance notes field with implementation details.\n\n### Optional but valuable for technical work:\n- Working API query code (tested, with response structure)\n- Sample API responses showing actual data\n- Desired output format examples (show, don't describe)\n- Research context (why this approach, what was discovered)\n\n### Example pattern:\n\n```markdown\nbd update issue-9 --notes \"IMPLEMENTATION GUIDE:\nWORKING CODE: service.about().get(fields='importFormats')\nReturns: dict with 49 entries like {'text/markdown': [...]}\nOUTPUT FORMAT: # Drive Import Formats (markdown with categorized list)\nCONTEXT: text/markdown support added July 2024, not in static docs\"\n```\n\n**When to add:** Multi-session technical features with APIs or specific formats. Skip for simple tasks.\n\n**For detailed patterns and examples, read:** [RESUMABILITY.md](RESUMABILITY.md)\n\n## Design vs Acceptance Criteria (Critical Distinction) {#design-vs-acceptance}\n\nCommon mistake: Putting implementation details in acceptance criteria. Here's the difference:\n\n### DESIGN field (HOW to build it):\n- \"Use two-phase batchUpdate approach: insert text first, then apply formatting\"\n- \"Parse with regex to find * and _ markers\"\n- \"Use JWT tokens with 1-hour expiry\"\n- Trade-offs: \"Chose batchUpdate over streaming API for atomicity\"\n\n### ACCEPTANCE CRITERIA (WHAT SUCCESS LOOKS LIKE):\n- \"Bold and italic markdown formatting renders correctly in the Doc\"\n- \"Solution accepts markdown input and creates Doc with specified title\"\n- \"Returns doc_id and webViewLink to caller\"\n- \"User tokens persist across sessions and refresh automatically\"\n\n### Why this matters:\n- Design can change during implementation (e.g., use library instead of regex)\n- Acceptance criteria should remain stable across sessions\n- Criteria should be **outcome-focused** (\"what must be true?\") not **step-focused** (\"do these steps\")\n- Each criterion should be **verifiable** - you can definitively say yes/no\n\n### The pitfall\n\nWriting criteria like \"- [ ] Use batchUpdate approach\" locks you into one implementation.\n\nBetter: \"- [ ] Formatting is applied atomically (all at once or not at all)\" - allows flexible implementation.\n\n### Test yourself\n\nIf you rewrote the solution using a different approach, would the acceptance criteria still apply? If not, they're design notes, not criteria.\n\n### Example of correct structure\n\nâœ… **Design field:**\n```\nTwo-phase Docs API approach:\n1. Parse markdown to positions\n2. Create doc + insert text in one call\n3. Apply formatting in second call\nRationale: Atomic operations, easier to debug formatting separately\n```\n\nâœ… **Acceptance criteria:**\n```\n- [ ] Markdown formatting renders in Doc (bold, italic, headings)\n- [ ] Lists preserve order and nesting\n- [ ] Links are clickable\n- [ ] Large documents (>50KB) process without timeout\n```\n\nâŒ **Wrong (design masquerading as criteria):**\n```\n- [ ] Use two-phase batchUpdate approach\n- [ ] Apply formatting in second batchUpdate call\n```\n\n## Quick Reference\n\n**Creating good issues:**\n\n1. **Title**: Clear, specific, action-oriented\n2. **Description**: Problem statement, context, why it matters\n3. **Design**: Approach, architecture, trade-offs (can change)\n4. **Acceptance**: Outcomes, success criteria (should be stable)\n5. **Notes**: Implementation details, session handoffs (evolves over time)\n\n**Common mistakes:**\n\n- Vague titles: \"Fix bug\" â†’ \"Fix: auth token expires before refresh\"\n- Implementation in acceptance: \"Use JWT\" â†’ \"Auth tokens persist across sessions\"\n- Missing context: \"Update database\" â†’ \"Update database: add user_last_login for session analytics\"\n",
        "skills/beads/resources/MOLECULES.md": "# Molecules and Wisps Reference\n\nThis reference covers bd's molecular chemistry system for reusable work templates and ephemeral workflows.\n\n## The Chemistry Metaphor\n\nbd v0.34.0 introduces a chemistry-inspired workflow system:\n\n| Phase | Name | Storage | Synced? | Use Case |\n|-------|------|---------|---------|----------|\n| **Solid** | Proto | `.beads/` | Yes | Reusable template (epic with `template` label) |\n| **Liquid** | Mol | `.beads/` | Yes | Persistent instance (real issues from template) |\n| **Vapor** | Wisp | `.beads-wisp/` | No | Ephemeral instance (operational work, no audit trail) |\n\n**Phase transitions:**\n- `spawn` / `pour`: Solid (proto) â†’ Liquid (mol)\n- `wisp create`: Solid (proto) â†’ Vapor (wisp)\n- `squash`: Vapor (wisp) â†’ Digest (permanent summary)\n- `burn`: Vapor (wisp) â†’ Nothing (deleted, no trace)\n- `distill`: Liquid (ad-hoc epic) â†’ Solid (proto)\n\n## When to Use Molecules\n\n### Use Protos/Mols When:\n- **Repeatable patterns** - Same workflow structure used multiple times (releases, reviews, onboarding)\n- **Team knowledge capture** - Encoding tribal knowledge as executable templates\n- **Audit trail matters** - Work that needs to be tracked and reviewed later\n- **Cross-session persistence** - Work spanning multiple days/sessions\n\n### Use Wisps When:\n- **Operational loops** - Patrol cycles, health checks, routine monitoring\n- **One-shot orchestration** - Temporary coordination that shouldn't clutter history\n- **Diagnostic runs** - Debugging workflows with no archival value\n- **High-frequency ephemeral work** - Would create noise in permanent database\n\n**Key insight:** Wisps prevent database bloat from routine operations while still providing structure during execution.\n\n---\n\n## Proto Management\n\n### Creating a Proto\n\nProtos are epics with the `template` label. Create manually or distill from existing work:\n\n```bash\n# Manual creation\nbd create \"Release Workflow\" --type epic --label template\nbd create \"Run tests for {{component}}\" --type task\nbd dep add task-id epic-id --type parent-child\n\n# Distill from ad-hoc work (extracts template from existing epic)\nbd mol distill bd-abc123 --as \"Release Workflow\" --var version=1.0.0\n```\n\n**Proto naming convention:** Use `mol-` prefix for clarity (e.g., `mol-release`, `mol-patrol`).\n\n### Listing Formulas\n\n```bash\nbd formula list                 # List all formulas (protos)\nbd formula list --json          # Machine-readable\n```\n\n### Viewing Proto Structure\n\n```bash\nbd mol show mol-release         # Show template structure and variables\nbd mol show mol-release --json  # Machine-readable\n```\n\n---\n\n## Spawning Molecules\n\n### Basic Spawn (Creates Wisp by Default)\n\n```bash\nbd mol spawn mol-patrol                    # Creates wisp (ephemeral)\nbd mol spawn mol-feature --pour            # Creates mol (persistent)\nbd mol spawn mol-release --var version=2.0 # With variable substitution\n```\n\n**Chemistry shortcuts:**\n```bash\nbd mol pour mol-feature                    # Shortcut for spawn --pour\nbd mol wisp mol-patrol                     # Explicit wisp creation\n```\n\n### Spawn with Immediate Execution\n\n```bash\nbd mol run mol-release --var version=2.0\n```\n\n`bd mol run` does three things:\n1. Spawns the molecule (persistent)\n2. Assigns root issue to caller\n3. Pins root issue for session recovery\n\n**Use `mol run` when:** Starting durable work that should survive crashes. The pin ensures `bd ready` shows the work after restart.\n\n### Spawn with Attachments\n\nAttach additional protos in a single command:\n\n```bash\nbd mol spawn mol-feature --attach mol-testing --var name=auth\n# Spawns mol-feature, then spawns mol-testing and bonds them\n```\n\n**Attach types:**\n- `sequential` (default) - Attached runs after primary completes\n- `parallel` - Attached runs alongside primary\n- `conditional` - Attached runs only if primary fails\n\n```bash\nbd mol spawn mol-deploy --attach mol-rollback --attach-type conditional\n```\n\n---\n\n## Bonding Molecules\n\n### Bond Types\n\n```bash\nbd mol bond A B                    # Sequential: B runs after A\nbd mol bond A B --type parallel    # Parallel: B runs alongside A\nbd mol bond A B --type conditional # Conditional: B runs if A fails\n```\n\n### Operand Combinations\n\n| A | B | Result |\n|---|---|--------|\n| proto | proto | Compound proto (reusable template) |\n| proto | mol | Spawn proto, attach to molecule |\n| mol | proto | Spawn proto, attach to molecule |\n| mol | mol | Join into compound molecule |\n\n### Phase Control in Bonds\n\nBy default, spawned protos inherit target's phase. Override with flags:\n\n```bash\n# Found bug during wisp patrol? Persist it:\nbd mol bond mol-critical-bug wisp-patrol --pour\n\n# Need ephemeral diagnostic on persistent feature?\nbd mol bond mol-temp-check bd-feature --wisp\n```\n\n### Custom Compound Names\n\n```bash\nbd mol bond mol-feature mol-deploy --as \"Feature with Deploy\"\n```\n\n---\n\n## Wisp Lifecycle\n\n### Creating Wisps\n\n```bash\nbd mol wisp mol-patrol                       # From proto\nbd mol spawn mol-patrol                      # Same (spawn defaults to wisp)\nbd mol spawn mol-check --var target=db       # With variables\n```\n\n### Listing Wisps\n\n```bash\nbd mol wisp list                     # List all wisps\nbd mol wisp list --json              # Machine-readable\n```\n\n### Ending Wisps\n\n**Option 1: Squash (compress to digest)**\n```bash\nbd mol squash wisp-abc123                              # Auto-generate summary\nbd mol squash wisp-abc123 --summary \"Completed patrol\" # Agent-provided summary\nbd mol squash wisp-abc123 --keep-children              # Keep children, just create digest\nbd mol squash wisp-abc123 --dry-run                    # Preview\n```\n\nSquash creates a permanent digest issue summarizing the wisp's work, then deletes the wisp children.\n\n**Option 2: Burn (delete without trace)**\n```bash\nbd mol burn wisp-abc123                    # Delete wisp, no digest\n```\n\nUse burn for routine work with no archival value.\n\n### Garbage Collection\n\n```bash\nbd mol wisp gc                       # Clean up orphaned wisps\n```\n\n---\n\n## Distilling Protos\n\nExtract a reusable template from ad-hoc work:\n\n```bash\nbd mol distill bd-o5xe --as \"Release Workflow\"\nbd mol distill bd-abc --var feature_name=auth-refactor --var version=1.0.0\n```\n\n**What distill does:**\n1. Loads existing epic and all children\n2. Clones structure as new proto (adds `template` label)\n3. Replaces concrete values with `{{variable}}` placeholders\n\n**Variable syntax (both work):**\n```bash\n--var branch=feature-auth      # variable=value (recommended)\n--var feature-auth=branch      # value=variable (auto-detected)\n```\n\n**Use cases:**\n- Team develops good workflow organically, wants to reuse it\n- Capture tribal knowledge as executable templates\n- Create starting point for similar future work\n\n---\n\n## Cross-Project Dependencies\n\n### Concept\n\nProjects can depend on capabilities shipped by other projects:\n\n```bash\n# Project A ships a capability\nbd ship auth-api                # Marks capability as available\n\n# Project B depends on it\nbd dep add bd-123 external:project-a:auth-api\n```\n\n### Shipping Capabilities\n\n```bash\nbd ship <capability>            # Ship capability (requires closed issue)\nbd ship <capability> --force    # Ship even if issue not closed\nbd ship <capability> --dry-run  # Preview\n```\n\n**How it works:**\n1. Find issue with `export:<capability>` label\n2. Validate issue is closed\n3. Add `provides:<capability>` label\n\n### Depending on External Capabilities\n\n```bash\nbd dep add <issue> external:<project>:<capability>\n```\n\nThe dependency is satisfied when the external project has a closed issue with `provides:<capability>` label.\n\n**`bd ready` respects external deps:** Issues blocked by unsatisfied external dependencies won't appear in ready list.\n\n---\n\n## Common Patterns\n\n### Pattern: Weekly Review Proto\n\n```bash\n# Create proto\nbd create \"Weekly Review\" --type epic --label template\nbd create \"Review open issues\" --type task\nbd create \"Update priorities\" --type task\nbd create \"Archive stale work\" --type task\n# Link as children...\n\n# Use each week\nbd mol spawn mol-weekly-review --pour\n```\n\n### Pattern: Ephemeral Patrol Cycle\n\n```bash\n# Patrol proto exists\nbd mol wisp mol-patrol\n\n# Execute patrol work...\n\n# End patrol\nbd mol squash wisp-abc123 --summary \"Patrol complete: 3 issues found, 2 resolved\"\n```\n\n### Pattern: Feature with Rollback\n\n```bash\nbd mol spawn mol-deploy --attach mol-rollback --attach-type conditional\n# If deploy fails, rollback automatically becomes unblocked\n```\n\n### Pattern: Capture Tribal Knowledge\n\n```bash\n# After completing a good workflow organically\nbd mol distill bd-release-epic --as \"Release Process\" --var version=X.Y.Z\n# Now team can: bd mol spawn mol-release-process --var version=2.0.0\n```\n\n---\n\n## CLI Quick Reference\n\n| Command | Purpose |\n|---------|---------|\n| `bd formula list` | List available formulas/protos |\n| `bd mol show <id>` | Show proto/mol structure |\n| `bd mol spawn <proto>` | Create wisp from proto (default) |\n| `bd mol spawn <proto> --pour` | Create persistent mol from proto |\n| `bd mol run <proto>` | Spawn + assign + pin (durable execution) |\n| `bd mol bond <A> <B>` | Combine protos or molecules |\n| `bd mol distill <epic>` | Extract proto from ad-hoc work |\n| `bd mol squash <mol>` | Compress wisp children to digest |\n| `bd mol burn <wisp>` | Delete wisp without trace |\n| `bd mol pour <proto>` | Shortcut for `spawn --pour` |\n| `bd mol wisp <proto>` | Create ephemeral wisp |\n| `bd mol wisp list` | List all wisps |\n| `bd mol wisp gc` | Garbage collect orphaned wisps |\n| `bd ship <capability>` | Publish capability for cross-project deps |\n\n---\n\n## Troubleshooting\n\n**\"Proto not found\"**\n- Check `bd formula list` for available formulas/protos\n- Protos need `template` label on the epic\n\n**\"Variable not substituted\"**\n- Use `--var key=value` syntax\n- Check proto for `{{key}}` placeholders with `bd mol show`\n\n**\"Wisp commands fail\"**\n- Wisps stored in `.beads-wisp/` (separate from `.beads/`)\n- Check `bd mol wisp list` for active wisps\n\n**\"External dependency not satisfied\"**\n- Target project must have closed issue with `provides:<capability>` label\n- Use `bd ship <capability>` in target project first\n",
        "skills/beads/resources/PATTERNS.md": "# Common Usage Patterns\n\nPractical patterns for using bd effectively across different scenarios.\n\n## Contents\n\n- [Knowledge Work Session](#knowledge-work-session) - Resume long-running research or writing tasks\n- [Side Quest Handling](#side-quest-handling) - Capture discovered work without losing context\n- [Multi-Session Project Resume](#multi-session-project-resume) - Pick up work after time away\n- [Status Transitions](#status-transitions) - When to change issue status\n- [Compaction Recovery](#compaction-recovery) - Resume after conversation history is lost\n- [Issue Closure](#issue-closure) - Documenting completion properly\n\n---\n\n## Knowledge Work Session\n\n**Scenario**: User asks \"Help me write a proposal for expanding the analytics platform\"\n\n**What you see**:\n```bash\n$ bd ready\n# Returns: bd-42 \"Research analytics platform expansion proposal\" (in_progress)\n\n$ bd show bd-42\nNotes: \"COMPLETED: Reviewed current stack (Mixpanel, Amplitude)\nIN PROGRESS: Drafting cost-benefit analysis section\nNEXT: Need user input on budget constraints before finalizing recommendations\"\n```\n\n**What you do**:\n1. Read notes to understand current state\n2. Create TodoWrite for immediate work:\n   ```\n   - [ ] Draft cost-benefit analysis\n   - [ ] Ask user about budget constraints\n   - [ ] Finalize recommendations\n   ```\n3. Work on tasks, mark TodoWrite items completed\n4. At milestone, update bd notes:\n   ```bash\n   bd update bd-42 --notes \"COMPLETED: Cost-benefit analysis drafted.\n   KEY DECISION: User confirmed $50k budget cap - ruled out enterprise options.\n   IN PROGRESS: Finalizing recommendations (Posthog + custom ETL).\n   NEXT: Get user review of draft before closing issue.\"\n   ```\n\n**Outcome**: TodoWrite disappears at session end, but bd notes preserve context for next session.\n\n**Key insight**: Notes field captures the \"why\" and context, TodoWrite tracks the \"doing\" right now.\n\n---\n\n## Side Quest Handling\n\n**Scenario**: During main task, discover a problem that needs attention.\n\n**Pattern**:\n1. Create issue immediately: `bd create \"Found: inventory system needs refactoring\"`\n2. Link provenance: `bd dep add main-task new-issue --type discovered-from`\n3. Assess urgency: blocker or can defer?\n4. **If blocker**:\n   - `bd update main-task --status blocked`\n   - `bd update new-issue --status in_progress`\n   - Work on the blocker\n5. **If deferrable**:\n   - Note in new issue's design field\n   - Continue main task\n   - New issue persists for later\n\n**Why this works**: Captures context immediately (before forgetting), preserves relationship to main work, allows flexible prioritization.\n\n**Example (with MCP):**\n\nWorking on \"Implement checkout flow\" (checkout-1), discover payment validation security hole:\n\n1. Create bug issue: `mcp__plugin_beads_beads__create` with `{title: \"Fix: payment validation bypasses card expiry check\", type: \"bug\", priority: 0}`\n2. Link discovery: `mcp__plugin_beads_beads__dep` with `{from_issue: \"checkout-1\", to_issue: \"payment-bug-2\", type: \"discovered-from\"}`\n3. Block current work: `mcp__plugin_beads_beads__update` with `{issue_id: \"checkout-1\", status: \"blocked\", notes: \"Blocked by payment-bug-2: security hole in validation\"}`\n4. Start new work: `mcp__plugin_beads_beads__update` with `{issue_id: \"payment-bug-2\", status: \"in_progress\"}`\n\n(CLI: `bd create \"Fix: payment validation...\" -t bug -p 0` then `bd dep add` and `bd update` commands)\n\n---\n\n## Multi-Session Project Resume\n\n**Scenario**: Starting work after days or weeks away from a project.\n\n**Pattern (with MCP)**:\n1. **Check what's ready**: Use `mcp__plugin_beads_beads__ready` to see available work\n2. **Check what's stuck**: Use `mcp__plugin_beads_beads__blocked` to understand blockers\n3. **Check recent progress**: Use `mcp__plugin_beads_beads__list` with `status:\"closed\"` to see completions\n4. **Read detailed context**: Use `mcp__plugin_beads_beads__show` for the issue you'll work on\n5. **Update status**: Use `mcp__plugin_beads_beads__update` with `status:\"in_progress\"`\n6. **Begin work**: Create TodoWrite from notes field's NEXT section\n\n(CLI: `bd ready`, `bd blocked`, `bd list --status closed`, `bd show <id>`, `bd update <id> --status in_progress`)\n\n**Example**:\n```bash\n$ bd ready\nReady to work on (3):\n  auth-5: \"Add OAuth refresh token rotation\" (priority: 0)\n  api-12: \"Document REST API endpoints\" (priority: 1)\n  test-8: \"Add integration tests for payment flow\" (priority: 2)\n\n$ bd show auth-5\nTitle: Add OAuth refresh token rotation\nStatus: open\nPriority: 0 (critical)\n\nNotes:\nCOMPLETED: Basic JWT auth working\nIN PROGRESS: Need to add token refresh\nNEXT: Implement rotation per OWASP guidelines (7-day refresh tokens)\nBLOCKER: None - ready to proceed\n\n$ bd update auth-5 --status in_progress\n# Now create TodoWrite based on NEXT section\n```\n\n**For complete session start workflow with checklist, see:** [WORKFLOWS.md](WORKFLOWS.md#session-start)\n\n---\n\n## Status Transitions\n\nUnderstanding when to change issue status.\n\n### Status Lifecycle\n\n```\nopen â†’ in_progress â†’ closed\n  â†“         â†“\nblocked   blocked\n```\n\n### When to Use Each Status\n\n**open** (default):\n- Issue created but not started\n- Waiting for dependencies to clear\n- Planned work not yet begun\n- **Command**: Issues start as `open` by default\n\n**in_progress**:\n- Actively working on this issue right now\n- Has been read and understood\n- Making commits or changes related to this\n- **Command**: `bd update issue-id --status in_progress`\n- **When**: Start of work session on this issue\n\n**blocked**:\n- Cannot proceed due to external blocker\n- Waiting for user input/decision\n- Dependency not completed\n- Technical blocker discovered\n- **Command**: `bd update issue-id --status blocked`\n- **When**: Hit a blocker, capture what blocks you in notes\n- **Note**: Document blocker in notes field: \"BLOCKER: Waiting for API key from ops team\"\n\n**closed**:\n- Work completed and verified\n- Tests passing\n- Acceptance criteria met\n- **Command**: `bd close issue-id --reason \"Implemented with tests passing\"`\n- **When**: All work done, ready to move on\n- **Note**: Issues remain in database, just marked complete\n\n### Transition Examples\n\n**Starting work**:\n```bash\nbd ready  # See what's available\nbd update auth-5 --status in_progress\n# Begin working\n```\n\n**Hit a blocker**:\n```bash\nbd update auth-5 --status blocked --notes \"BLOCKER: Need OAuth client ID from product team. Emailed Jane on 2025-10-23.\"\n# Switch to different issue or create new work\n```\n\n**Unblocking**:\n```bash\n# Once blocker resolved\nbd update auth-5 --status in_progress --notes \"UNBLOCKED: Received OAuth credentials. Resuming implementation.\"\n```\n\n**Completing**:\n```bash\nbd close auth-5 --reason \"Implemented OAuth refresh with 7-day rotation. Tests passing. PR #42 merged.\"\n```\n\n---\n\n## Compaction Recovery\n\n**Scenario**: Conversation history has been compacted. You need to resume work with zero conversation context.\n\n**What survives compaction**:\n- All bd issues and notes\n- Complete work history\n- Dependencies and relationships\n\n**What's lost**:\n- Conversation history\n- TodoWrite lists\n- Recent discussion\n\n### Recovery Pattern\n\n1. **Check in-progress work**:\n   ```bash\n   bd list --status in_progress\n   ```\n\n2. **Read notes for context**:\n   ```bash\n   bd show issue-id\n   # Read notes field - should explain current state\n   ```\n\n3. **Reconstruct TodoWrite from notes**:\n   - COMPLETED section: Done, skip\n   - IN PROGRESS section: Current state\n   - NEXT section: **This becomes your TodoWrite list**\n\n4. **Report to user**:\n   ```\n   \"From bd notes: [summary of COMPLETED]. Currently [IN PROGRESS].\n   Next steps: [from NEXT]. Should I continue with that?\"\n   ```\n\n### Example Recovery\n\n**bd show returns**:\n```\nIssue: bd-42 \"OAuth refresh token implementation\"\nStatus: in_progress\nNotes:\nCOMPLETED: Basic JWT validation working (RS256, 1hr access tokens)\nKEY DECISION: 7-day refresh tokens per security review\nIN PROGRESS: Implementing token rotation endpoint\nNEXT: Add rate limiting (5 refresh attempts per 15min), then write tests\nBLOCKER: None\n```\n\n**Recovery actions**:\n1. Read notes, understand context\n2. Create TodoWrite:\n   ```\n   - [ ] Implement rate limiting on refresh endpoint\n   - [ ] Write tests for token rotation\n   - [ ] Verify security guidelines met\n   ```\n3. Report: \"From notes: JWT validation is done with 7-day refresh tokens. Currently implementing rotation endpoint. Next: add rate limiting and tests. Should I continue?\"\n4. Resume work based on user response\n\n**For complete compaction survival workflow, see:** [WORKFLOWS.md](WORKFLOWS.md#compaction-survival)\n\n---\n\n## Issue Closure\n\n**Scenario**: Work is complete. How to close properly?\n\n### Closure Checklist\n\nBefore closing, verify:\n- [ ] **Acceptance criteria met**: All items checked off\n- [ ] **Tests passing**: If applicable\n- [ ] **Documentation updated**: If needed\n- [ ] **Follow-up work filed**: New issues created for discovered work\n- [ ] **Key decisions documented**: In notes field\n\n### Closure Pattern\n\n**Minimal closure** (simple tasks):\n```bash\nbd close task-123 --reason \"Implemented feature X\"\n```\n\n**Detailed closure** (complex work):\n```bash\n# Update notes with final state\nbd update task-123 --notes \"COMPLETED: OAuth refresh with 7-day rotation\nKEY DECISION: RS256 over HS256 per security review\nTESTS: 12 tests passing (auth, rotation, expiry, errors)\nFOLLOW-UP: Filed perf-99 for token cleanup job\"\n\n# Close with summary\nbd close task-123 --reason \"Implemented OAuth refresh token rotation with rate limiting. All security guidelines met. Tests passing.\"\n```\n\n### Documenting Resolution (Outcome vs Design)\n\nFor issues where the outcome differed from initial design, use `--notes` to document what actually happened:\n\n```bash\n# Initial design was hypothesis - document actual outcome in notes\nbd update bug-456 --notes \"RESOLUTION: Not a bug - behavior is correct per OAuth spec. Documentation was unclear. Filed docs-789 to clarify auth flow in user guide.\"\n\nbd close bug-456 --reason \"Resolved: documentation issue, not bug\"\n```\n\n**Pattern**: Design field = initial approach. Notes field = what actually happened (prefix with RESOLUTION: for clarity).\n\n### Discovering Follow-up Work\n\nWhen closing reveals new work:\n\n```bash\n# While closing auth feature, realize performance needs work\nbd create \"Optimize token lookup query\" -t task -p 2\n\n# Link the provenance\nbd dep add auth-5 perf-99 --type discovered-from\n\n# Now close original\nbd close auth-5 --reason \"OAuth refresh implemented. Discovered perf optimization needed (filed perf-99).\"\n```\n\n**Why link with discovered-from**: Preserves the context of how you found the new work. Future you will appreciate knowing it came from the auth implementation.\n\n---\n\n## Pattern Summary\n\n| Pattern | When to Use | Key Command | Preserves |\n|---------|-------------|-------------|-----------|\n| **Knowledge Work** | Long-running research, writing | `bd update --notes` | Context across sessions |\n| **Side Quest** | Discovered during other work | `bd dep add --type discovered-from` | Relationship to original |\n| **Multi-Session Resume** | Returning after time away | `bd ready`, `bd show` | Full project state |\n| **Status Transitions** | Tracking work state | `bd update --status` | Current state |\n| **Compaction Recovery** | History lost | Read notes field | All context in notes |\n| **Issue Closure** | Completing work | `bd close --reason` | Decisions and outcomes |\n\n**For detailed workflows with step-by-step checklists, see:** [WORKFLOWS.md](WORKFLOWS.md)\n",
        "skills/beads/resources/RESUMABILITY.md": "# Making Issues Resumable Across Sessions\n\n## When Resumability Matters\n\n**Use enhanced documentation for:**\n- Multi-session technical features with API integration\n- Complex algorithms requiring code examples\n- Features with specific output format requirements\n- Work with \"occult\" APIs (undocumented capabilities)\n\n**Skip for:**\n- Simple bug fixes with clear scope\n- Well-understood patterns (CRUD operations, etc.)\n- Single-session tasks\n- Work with obvious acceptance criteria\n\n**The test:** Would a fresh Claude instance (or you after 2 weeks) struggle to resume this work from the description alone? If yes, add implementation details.\n\n## Anatomy of a Resumable Issue\n\n### Minimal (Always Include)\n```markdown\nDescription: What needs to be built and why\nAcceptance Criteria: Concrete, testable outcomes (WHAT not HOW)\n```\n\n### Enhanced (Complex Technical Work)\n```markdown\nNotes Field - IMPLEMENTATION GUIDE:\n\nWORKING CODE:\n```python\n# Tested code that queries the API\nservice = build('drive', 'v3', credentials=creds)\nresult = service.about().get(fields='importFormats').execute()\n# Returns: {'text/markdown': ['application/vnd.google-apps.document'], ...}\n```\n\nAPI RESPONSE SAMPLE:\nShows actual data structure (not docs description)\n\nDESIRED OUTPUT FORMAT:\n```markdown\n# Example of what the output should look like\nNot just \"return markdown\" but actual structure\n```\n\nRESEARCH CONTEXT:\nWhy this approach? What alternatives were considered?\nKey discoveries that informed the design.\n```\n\n## Real Example: Before vs After\n\n### âŒ Not Resumable\n```\nTitle: Add dynamic capabilities resources\nDescription: Query Google APIs for capabilities and return as resources\nAcceptance: Resources return capability info\n```\n\n**Problem:** Future Claude doesn't know:\n- Which API endpoints to call\n- What the responses look like\n- What format to return\n\n### âœ… Resumable\n```\nTitle: Add dynamic capabilities resources\nDescription: Query Google APIs for system capabilities (import formats,\nthemes, quotas) that aren't in static docs. Makes server self-documenting.\n\nNotes: IMPLEMENTATION GUIDE\n\nWORKING CODE (tested):\n```python\nfrom workspace_mcp.tools.drive import get_credentials\nfrom googleapiclient.discovery import build\n\ncreds = get_credentials()\nservice = build('drive', 'v3', credentials=creds)\nabout = service.about().get(\n    fields='importFormats,exportFormats,folderColorPalette'\n).execute()\n\n# Returns:\n# - importFormats: dict, 49 entries like {'text/markdown': [...]}\n# - exportFormats: dict, 10 entries\n# - folderColorPalette: list, 24 hex strings\n```\n\nOUTPUT FORMAT EXAMPLE:\n```markdown\n# Drive Import Formats\n\nGoogle Drive supports 49 import formats:\n\n## Text Formats\n- **text/markdown** â†’ Google Docs âœ¨ (NEW July 2024)\n- text/plain â†’ Google Docs\n...\n```\n\nRESEARCH CONTEXT:\ntext/markdown support announced July 2024 but NOT in static Google docs.\nGoogle's workspace-developer MCP server doesn't expose this.\nThis is why dynamic resources matter.\n\nAcceptance Criteria:\n- User queries workspace://capabilities/drive/import-formats\n- Response shows all 49 formats including text/markdown\n- Output is readable markdown, not raw JSON\n- Queries live API (not static data)\n```\n\n**Result:** Fresh Claude instance can:\n1. See working API query code\n2. Understand response structure\n3. Know desired output format\n4. Implement with context\n\n## Optional Template\n\nCopy this into notes field for complex technical features:\n\n```markdown\nIMPLEMENTATION GUIDE FOR FUTURE SESSIONS:\n\nWORKING CODE (tested):\n```language\n# Paste actual code that works\n# Include imports and setup\n# Show what it returns\n```\n\nAPI RESPONSE SAMPLE:\n```json\n{\n  \"actualField\": \"actualValue\",\n  \"structure\": \"as returned by API\"\n}\n```\n\nDESIRED OUTPUT FORMAT:\n```\nShow what the final output should look like\nNot just \"markdown\" but actual structure/style\n```\n\nRESEARCH CONTEXT:\n- Why this approach?\n- What alternatives considered?\n- Key discoveries?\n- Links to relevant docs/examples?\n```\n\n## Anti-Patterns\n\n### âŒ Over-Documenting Simple Work\n```markdown\nTitle: Fix typo in README\nNotes: IMPLEMENTATION GUIDE\nWORKING CODE: Open README.md, change \"teh\" to \"the\"...\n```\n**Problem:** Wastes tokens on obvious work.\n\n### âŒ Design Details in Acceptance Criteria\n```markdown\nAcceptance:\n- [ ] Use batchUpdate approach\n- [ ] Call API with fields parameter\n- [ ] Format as markdown with ## headers\n```\n**Problem:** Locks implementation. Should be in Design/Notes, not Acceptance.\n\n### âŒ Raw JSON Dumps\n```markdown\nAPI RESPONSE:\n{giant unformatted JSON blob spanning 100 lines}\n```\n**Problem:** Hard to read. Extract relevant parts, show structure.\n\n### âœ… Right Balance\n```markdown\nAPI RESPONSE SAMPLE:\nReturns dict with 49 entries. Example entries:\n- 'text/markdown': ['application/vnd.google-apps.document']\n- 'text/plain': ['application/vnd.google-apps.document']\n- 'application/pdf': ['application/vnd.google-apps.document']\n```\n\n## When to Add This Detail\n\n**During issue creation:**\n- Already have working code from research? Include it.\n- Clear output format in mind? Show example.\n\n**During work (update notes):**\n- Just got API query working? Add to notes.\n- Discovered important context? Document it.\n- Made key decision? Explain rationale.\n\n**Session end:**\n- If resuming will be hard, add implementation guide.\n- If obvious, skip it.\n\n**The principle:** Help your future self (or next Claude) resume without rediscovering everything.\n",
        "skills/beads/resources/STATIC_DATA.md": "# Using bd for Static Reference Data\n\nbd is primarily designed for work tracking, but can also serve as a queryable database for static reference data with some adaptations.\n\n## Work Tracking (Primary Use Case)\n\nStandard bd workflow:\n- Issues flow through states (open â†’ in_progress â†’ closed)\n- Priorities and dependencies matter\n- Status tracking is essential\n- IDs are sufficient for referencing\n\n## Reference Databases / Glossaries (Alternative Use)\n\nWhen using bd for static data (terminology, glossaries, reference information):\n\n**Characteristics:**\n- Entities are mostly static (typically always open)\n- No real workflow or state transitions\n- Names/titles more important than IDs\n- Minimal or no dependencies\n\n**Recommended approach:**\n- Use separate database (not mixed with work tracking) to avoid confusion\n- Consider dual format: maintain markdown version alongside database for name-based lookup\n- Example: A terminology database could use both `terms.db` (queryable via bd) and `GLOSSARY.md` (browsable by name)\n\n**Key difference**: Work items have lifecycle; reference entities are stable knowledge.\n\n## When to Use This Pattern\n\n**Good fit:**\n- Technical glossaries or terminology databases\n- Reference documentation that needs dependency tracking\n- Knowledge bases with relationships between entries\n- Structured data that benefits from queryability\n\n**Poor fit:**\n- Data that changes frequently (use work tracking pattern)\n- Simple lists (markdown is simpler)\n- Data that needs complex queries (use proper database)\n\n## Limitations\n\n**bd show requires IDs, not names:**\n- `bd show term-42` works\n- `bd show \"API endpoint\"` doesn't work\n- Workaround: `bd list | grep -i \"api endpoint\"` to find ID first\n- This is why dual format (bd + markdown) is recommended for reference data\n\n**No search by content:**\n- bd searches by ID, title filters, status, labels\n- For full-text search across descriptions/notes, use grep on the JSONL file\n- Example: `grep -i \"authentication\" .beads/issues.jsonl`\n",
        "skills/beads/resources/TROUBLESHOOTING.md": "# Troubleshooting Guide\n\nCommon issues encountered when using bd and how to resolve them.\n\n## Interface-Specific Troubleshooting\n\n**MCP tools (local environment):**\n- MCP tools require bd daemon running\n- Check daemon status: `bd daemon --status` (CLI)\n- If MCP tools fail, verify daemon is running and restart if needed\n- MCP tools automatically use daemon mode (no --no-daemon option)\n\n**CLI (web environment or local):**\n- CLI can use daemon mode (default) or direct mode (--no-daemon)\n- Direct mode has 3-5 second sync delay\n- Web environment: Install via `npm install -g @beads/cli`\n- Web environment: Initialize via `bd init <prefix>` before first use\n\n**Most issues below apply to both interfaces** - the underlying database and daemon behavior is the same.\n\n## Contents\n\n- [Dependencies Not Persisting](#dependencies-not-persisting)\n- [Status Updates Not Visible](#status-updates-not-visible)\n- [Daemon Won't Start](#daemon-wont-start)\n- [Database Errors on Cloud Storage](#database-errors-on-cloud-storage)\n- [JSONL File Not Created](#jsonl-file-not-created)\n- [Version Requirements](#version-requirements)\n\n---\n\n## Dependencies Not Persisting\n\n### Symptom\n```bash\nbd dep add issue-2 issue-1 --type blocks\n# Reports: âœ“ Added dependency\nbd show issue-2\n# Shows: No dependencies listed\n```\n\n### Root Cause (Fixed in v0.15.0+)\nThis was a **bug in bd** (GitHub issue #101) where the daemon ignored dependencies during issue creation. **Fixed in bd v0.15.0** (Oct 21, 2025).\n\n### Resolution\n\n**1. Check your bd version:**\n```bash\nbd version\n```\n\n**2. If version < 0.15.0, update bd:**\n```bash\n# Via Homebrew (macOS/Linux)\nbrew upgrade bd\n\n# Via go install\ngo install github.com/steveyegge/beads/cmd/bd@latest\n\n# Via package manager\n# See https://github.com/steveyegge/beads#installing\n```\n\n**3. Restart daemon after upgrade:**\n```bash\npkill -f \"bd daemon\"  # Kill old daemon\nbd daemon             # Start new daemon with fix\n```\n\n**4. Test dependency creation:**\n```bash\nbd create \"Test A\" -t task\nbd create \"Test B\" -t task\nbd dep add <B-id> <A-id> --type blocks\nbd show <B-id>\n# Should show: \"Depends on (1): â†’ <A-id>\"\n```\n\n### Still Not Working?\n\nIf dependencies still don't persist after updating:\n\n1. **Check daemon is running:**\n   ```bash\n   ps aux | grep \"bd daemon\"\n   ```\n\n2. **Try without --no-daemon flag:**\n   ```bash\n   # Instead of: bd --no-daemon dep add ...\n   # Use: bd dep add ...  (let daemon handle it)\n   ```\n\n3. **Check JSONL file:**\n   ```bash\n   cat .beads/issues.jsonl | jq '.dependencies'\n   # Should show dependency array\n   ```\n\n4. **Report to beads GitHub** with:\n   - `bd version` output\n   - Operating system\n   - Reproducible test case\n\n---\n\n## Status Updates Not Visible\n\n### Symptom\n```bash\nbd --no-daemon update issue-1 --status in_progress\n# Reports: âœ“ Updated issue: issue-1\nbd show issue-1\n# Shows: Status: open (not in_progress!)\n```\n\n### Root Cause\nThis is **expected behavior**, not a bug. Understanding requires knowing bd's architecture:\n\n**BD Architecture:**\n- **JSONL files** (`.beads/issues.jsonl`): Human-readable export format\n- **SQLite database** (`.beads/*.db`): Source of truth for queries\n- **Daemon**: Syncs JSONL â†” SQLite every 5 minutes\n\n**What `--no-daemon` actually does:**\n- **Writes**: Go directly to JSONL file\n- **Reads**: Still come from SQLite database\n- **Sync delay**: Daemon imports JSONL â†’ SQLite periodically\n\n### Resolution\n\n**Option 1: Use daemon mode (recommended)**\n```bash\n# Don't use --no-daemon for CRUD operations\nbd update issue-1 --status in_progress\nbd show issue-1\n# âœ“ Status reflects immediately\n```\n\n**Option 2: Wait for sync (if using --no-daemon)**\n```bash\nbd --no-daemon update issue-1 --status in_progress\n# Wait 3-5 seconds for daemon to sync\nsleep 5\nbd show issue-1\n# âœ“ Status should reflect now\n```\n\n**Option 3: Manual sync trigger**\n```bash\nbd --no-daemon update issue-1 --status in_progress\n# Trigger sync by exporting/importing\nbd export > /dev/null 2>&1  # Forces sync\nbd show issue-1\n```\n\n### When to Use `--no-daemon`\n\n**Use --no-daemon for:**\n- Batch import scripts (performance)\n- CI/CD environments (no persistent daemon)\n- Testing/debugging\n\n**Don't use --no-daemon for:**\n- Interactive development\n- Real-time status checks\n- When you need immediate query results\n\n---\n\n## Daemon Won't Start\n\n### Symptom\n```bash\nbd daemon\n# Error: not in a git repository\n# Hint: run 'git init' to initialize a repository\n```\n\n### Root Cause\nbd daemon requires a **git repository** because it uses git for:\n- Syncing issues to git remote (optional)\n- Version control of `.beads/*.jsonl` files\n- Commit history of issue changes\n\n### Resolution\n\n**Initialize git repository:**\n```bash\n# In your project directory\ngit init\nbd daemon\n# âœ“ Daemon should start now\n```\n\n**Prevent git remote operations:**\n```bash\n# If you don't want daemon to pull from remote\nbd daemon --global=false\n```\n\n**Flags:**\n- `--global=false`: Don't sync with git remote\n- `--interval=10m`: Custom sync interval (default: 5m)\n- `--auto-commit=true`: Auto-commit JSONL changes\n\n---\n\n## Database Errors on Cloud Storage\n\n### Symptom\n```bash\n# In directory: /Users/name/Google Drive/...\nbd init myproject\n# Error: disk I/O error (522)\n# OR: Error: database is locked\n```\n\n### Root Cause\n**SQLite incompatibility with cloud sync filesystems.**\n\nCloud services (Google Drive, Dropbox, OneDrive, iCloud) don't support:\n- POSIX file locking (required by SQLite)\n- Consistent file handles across sync operations\n- Atomic write operations\n\nThis is a **known SQLite limitation**, not a bd bug.\n\n### Resolution\n\n**Move bd database to local filesystem:**\n\n```bash\n# Wrong location (cloud sync)\n~/Google Drive/My Work/project/.beads/  # âœ— Will fail\n\n# Correct location (local disk)\n~/Repos/project/.beads/                 # âœ“ Works reliably\n~/Projects/project/.beads/              # âœ“ Works reliably\n```\n\n**Migration steps:**\n\n1. **Move project to local disk:**\n   ```bash\n   mv ~/Google\\ Drive/project ~/Repos/project\n   cd ~/Repos/project\n   ```\n\n2. **Re-initialize bd (if needed):**\n   ```bash\n   bd init myproject\n   ```\n\n3. **Import existing issues (if you had JSONL export):**\n   ```bash\n   bd import < issues-backup.jsonl\n   ```\n\n**Alternative: Use global `~/.beads/` database**\n\nIf you must keep work on cloud storage:\n```bash\n# Don't initialize bd in cloud-synced directory\n# Use global database instead\ncd ~/Google\\ Drive/project\nbd create \"My task\"\n# Uses ~/.beads/default.db (on local disk)\n```\n\n**Workaround limitations:**\n- No per-project database isolation\n- All projects share same issue prefix\n- Manual tracking of which issues belong to which project\n\n**Recommendation:** Keep code/projects on local disk, sync final deliverables to cloud.\n\n---\n\n## JSONL File Not Created\n\n### Symptom\n```bash\nbd init myproject\nbd --no-daemon create \"Test\" -t task\nls .beads/\n# Only shows: .gitignore, myproject.db\n# Missing: issues.jsonl\n```\n\n### Root Cause\n**JSONL initialization coupling.** The `issues.jsonl` file is created by daemon on first startup, not by `bd init`.\n\n### Resolution\n\n**Start daemon once to initialize JSONL:**\n```bash\nbd daemon --global=false &\n# Wait for initialization\nsleep 2\n\n# Now JSONL file exists\nls .beads/issues.jsonl\n# âœ“ File created\n\n# Subsequent --no-daemon operations work\nbd --no-daemon create \"Task 1\" -t task\ncat .beads/issues.jsonl\n# âœ“ Shows task data\n```\n\n**Why this matters:**\n- Daemon owns the JSONL export format\n- First daemon run creates empty JSONL skeleton\n- `--no-daemon` operations assume JSONL exists\n\n**Pattern for batch scripts:**\n```bash\n#!/bin/bash\n# Batch import script\n\nbd init myproject\nbd daemon --global=false &  # Start daemon\nsleep 3                     # Wait for initialization\n\n# Now safe to use --no-daemon for performance\nfor item in \"${items[@]}\"; do\n    bd --no-daemon create \"$item\" -t feature\ndone\n\n# Daemon syncs JSONL â†’ SQLite in background\nsleep 5  # Wait for final sync\n\n# Query results\nbd stats\n```\n\n---\n\n## Version Requirements\n\n### Minimum Version for Dependency Persistence\n\n**Issue:** Dependencies created but don't appear in `bd show` or dependency tree.\n\n**Fix:** Upgrade to **bd v0.15.0+** (released Oct 2025)\n\n**Check version:**\n```bash\nbd version\n# Should show: bd version 0.15.0 or higher\n```\n\n**If using MCP plugin:**\n```bash\n# Update Claude Code beads plugin\nclaude plugin update beads\n```\n\n### Breaking Changes\n\n**v0.15.0:**\n- MCP parameter names changed from `from_id/to_id` to `issue_id/depends_on_id`\n- Dependency creation now persists correctly in daemon mode\n\n**v0.14.0:**\n- Daemon architecture changes\n- Auto-sync JSONL behavior introduced\n\n---\n\n## MCP-Specific Issues\n\n### Dependencies Created Backwards\n\n**Symptom:**\nUsing MCP tools, dependencies end up reversed from intended.\n\n**Example:**\n```python\n# Want: \"task-2 depends on task-1\" (task-1 blocks task-2)\nbeads_add_dependency(issue_id=\"task-1\", depends_on_id=\"task-2\")\n# Wrong! This makes task-1 depend on task-2\n```\n\n**Root Cause:**\nParameter confusion between old (`from_id/to_id`) and new (`issue_id/depends_on_id`) names.\n\n**Resolution:**\n\n**Correct MCP usage (bd v0.15.0+):**\n```python\n# Correct: task-2 depends on task-1\nbeads_add_dependency(\n    issue_id=\"task-2\",        # Issue that has dependency\n    depends_on_id=\"task-1\",   # Issue that must complete first\n    dep_type=\"blocks\"\n)\n```\n\n**Mnemonic:**\n- `issue_id`: The issue that **waits**\n- `depends_on_id`: The issue that **must finish first**\n\n**Equivalent CLI:**\n```bash\nbd dep add task-2 task-1 --type blocks\n# Meaning: task-2 depends on task-1\n```\n\n**Verify dependency direction:**\n```bash\nbd show task-2\n# Should show: \"Depends on: task-1\"\n# Not the other way around\n```\n\n---\n\n## Getting Help\n\n### Debug Checklist\n\nBefore reporting issues, collect this information:\n\n```bash\n# 1. Version\nbd version\n\n# 2. Daemon status\nps aux | grep \"bd daemon\"\n\n# 3. Database location\necho $PWD/.beads/*.db\nls -la .beads/\n\n# 4. Git status\ngit status\ngit log --oneline -1\n\n# 5. JSONL contents (for dependency issues)\ncat .beads/issues.jsonl | jq '.' | head -50\n```\n\n### Report to beads GitHub\n\nIf problems persist:\n\n1. **Check existing issues:** https://github.com/steveyegge/beads/issues\n2. **Create new issue** with:\n   - bd version (`bd version`)\n   - Operating system\n   - Debug checklist output (above)\n   - Minimal reproducible example\n   - Expected vs actual behavior\n\n### Claude Code Skill Issues\n\nIf the **bd-issue-tracking skill** provides incorrect guidance:\n\n1. **Check skill version:**\n   ```bash\n   ls -la ~/.claude/skills/bd-issue-tracking/\n   head -20 ~/.claude/skills/bd-issue-tracking/SKILL.md\n   ```\n\n2. **Report via Claude Code feedback** or user's GitHub\n\n---\n\n## Quick Reference: Common Fixes\n\n| Problem | Quick Fix |\n|---------|-----------|\n| Dependencies not saving | Upgrade to bd v0.15.0+ |\n| Status updates lag | Use daemon mode (not `--no-daemon`) |\n| Daemon won't start | Run `git init` first |\n| Database errors on Google Drive | Move to local filesystem |\n| JSONL file missing | Start daemon once: `bd daemon &` |\n| Dependencies backwards (MCP) | Update to v0.15.0+, use `issue_id/depends_on_id` correctly |\n\n---\n\n## Related Documentation\n\n- [CLI Reference](CLI_REFERENCE.md) - Complete command documentation\n- [Dependencies Guide](DEPENDENCIES.md) - Understanding dependency types\n- [Workflows](WORKFLOWS.md) - Step-by-step workflow guides\n- [beads GitHub](https://github.com/steveyegge/beads) - Official documentation\n",
        "skills/beads/resources/WORKFLOWS.md": "# Workflows and Checklists\n\nDetailed step-by-step workflows for common bd usage patterns with checklists.\n\n## Contents\n\n- [Session Start Workflow](#session-start) - Check bd ready, establish context\n- [Compaction Survival](#compaction-survival) - Recovering after compaction events\n- [Discovery and Issue Creation](#discovery) - Proactive issue creation during work\n- [Status Maintenance](#status-maintenance) - Keeping bd status current\n- [Epic Planning](#epic-planning) - Structuring complex work with dependencies\n- [Side Quest Handling](#side-quests) - Discovery during main task, assessing blocker vs deferrable, resuming\n- [Multi-Session Resume](#resume) - Returning after days/weeks away\n- [Session Handoff Workflow](#session-handoff) - Collaborative handoff between sessions\n- [Unblocking Work](#unblocking) - Handling blocked issues\n- [Integration with TodoWrite](#integration-with-todowrite) - Using both tools together\n- [Common Workflow Patterns](#common-workflow-patterns)\n  - Systematic Exploration, Bug Investigation, Refactoring with Dependencies, Spike Investigation\n- [Checklist Templates](#checklist-templates)\n  - Starting Any Work Session, Creating Issues During Work, Completing Work, Planning Complex Features\n- [Decision Points](#decision-points)\n- [Troubleshooting Workflows](#troubleshooting-workflows)\n\n## Session Start Workflow {#session-start}\n\n**bd is available when**:\n- Project has `.beads/` directory (project-local), OR\n- `~/.beads/` exists (global fallback for any directory)\n\n**Automatic checklist at session start:**\n\n```\nSession Start (when bd is available):\n- [ ] Run bd ready --json\n- [ ] Report: \"X items ready to work on: [summary]\"\n- [ ] If using global ~/.beads, note this in report\n- [ ] If none ready, check bd blocked --json\n- [ ] Suggest next action based on findings\n```\n\n**Pattern**: Always run `bd ready` when starting work where bd is available. Report status immediately to establish shared context.\n\n**Database selection**: bd auto-discovers which database to use (project-local `.beads/` takes precedence over global `~/.beads/`).\n\n---\n\n## Compaction Survival {#compaction-survival}\n\n**Critical**: After compaction events, conversation history is deleted but bd state persists. Beads are your only memory.\n\n**Post-compaction recovery checklist:**\n\n```\nAfter Compaction:\n- [ ] Run bd list --status in_progress to see active work\n- [ ] Run bd show <issue-id> for each in_progress issue\n- [ ] Read notes field to understand: COMPLETED, IN PROGRESS, BLOCKERS, KEY DECISIONS\n- [ ] Check dependencies: bd dep tree <issue-id> for context\n- [ ] If notes insufficient, check bd list --status open for related issues\n- [ ] Reconstruct TodoWrite list from notes if needed\n```\n\n**Pattern**: Well-written notes enable full context recovery even with zero conversation history.\n\n**Writing notes for compaction survival:**\n\n**Good note (enables recovery):**\n```\nbd update issue-42 --notes \"COMPLETED: User authentication - added JWT token\ngeneration with 1hr expiry, implemented refresh token endpoint using rotating\ntokens pattern. IN PROGRESS: Password reset flow. Email service integration\nworking. NEXT: Need to add rate limiting to reset endpoint (currently unlimited\nrequests). KEY DECISION: Using bcrypt with 12 rounds after reviewing OWASP\nrecommendations, tech lead concerned about response time but benchmarks show <100ms.\"\n```\n\n**Bad note (insufficient for recovery):**\n```\nbd update issue-42 --notes \"Working on auth feature. Made some progress.\nMore to do later.\"\n```\n\nThe good note contains:\n- Specific accomplishments (what was implemented/configured)\n- Current state (which part is working, what's in progress)\n- Next concrete step (not just \"continue\")\n- Key context (team concerns, technical decisions with rationale)\n\n**After compaction**: `bd show issue-42` reconstructs the full context needed to continue work.\n\n---\n\n## Discovery and Issue Creation {#discovery}\n\n**When encountering new work during implementation:**\n\n```\nDiscovery Workflow:\n- [ ] Notice bug, improvement, or follow-up work\n- [ ] Assess: Can defer or is blocker?\n- [ ] Create issue with bd create \"Issue title\"\n- [ ] Add discovered-from dependency: bd dep add current-id new-id --type discovered-from\n- [ ] If blocker: pause and switch; if not: continue current work\n- [ ] Issue persists for future sessions\n```\n\n**Pattern**: Proactively file issues as you discover work. Context captured immediately instead of lost when session ends.\n\n**When to ask first**:\n- Knowledge work with fuzzy scope\n- User intent unclear\n- Multiple valid approaches\n\n**When to create directly**:\n- Clear bug found\n- Obvious follow-up work\n- Technical debt with clear scope\n\n---\n\n## Status Maintenance {#status-maintenance}\n\n**Throughout work on an issue:**\n\n```\nIssue Lifecycle:\n- [ ] Start: Update status to in_progress\n- [ ] During: Add design notes as decisions made\n- [ ] During: Update acceptance criteria if requirements clarify\n- [ ] During: Add dependencies if blockers discovered\n- [ ] Complete: Close with summary of what was done\n- [ ] After: Check bd ready to see what unblocked\n```\n\n**Pattern**: Keep bd status current so project state is always accurate.\n\n**Status transitions**:\n- `open` â†’ `in_progress` when starting work\n- `in_progress` â†’ `blocked` if blocker discovered\n- `blocked` â†’ `in_progress` when unblocked\n- `in_progress` â†’ `closed` when complete\n\n---\n\n## Epic Planning {#epic-planning}\n\n**For complex multi-step features, think in Ready Fronts, not phases.**\n\n### The Ready Front Model\n\nA **Ready Front** is the set of issues with all dependencies satisfied - what can be worked on *right now*. As issues close, the front advances. The dependency DAG IS the execution plan.\n\n```\nReady Front = Issues where all dependencies are closed\n              (no blockers remaining)\n\nStatic view:  Natural topology in the DAG (sync points, bottlenecks)\nDynamic view: Current wavefront of in-progress work\n```\n\n**Why Ready Fronts, not Phases?**\n\n\"Phases\" trigger temporal reasoning that inverts dependencies:\n\n```\nâš ï¸ COGNITIVE TRAP:\n\"Phase 1 before Phase 2\" â†’ brain thinks \"Phase 1 blocks Phase 2\"\n                         â†’ WRONG: bd dep add phase1 phase2\n\nCorrect: \"Phase 2 needs Phase 1\" â†’ bd dep add phase2 phase1\n```\n\n**The fix**: Name issues by what they ARE, think about what they NEED.\n\n### Epic Planning Workflow\n\n```\nEpic Planning with Ready Fronts:\n- [ ] Create epic issue for high-level goal\n- [ ] Walk backward from goal: \"What does the end state need?\"\n- [ ] Create child issues named by WHAT, not WHEN\n- [ ] Add deps using requirement language: \"X needs Y\" â†’ bd dep add X Y\n- [ ] Verify with bd blocked (tasks blocked BY prerequisites, not dependents)\n- [ ] Use bd ready to work through in dependency order\n```\n\n### The Graph Walk Pattern\n\nWalk **backward** from the goal to get correct dependencies:\n\n```\nStart: \"What's the final deliverable?\"\n       â†“\n       \"Integration tests passing\" â†’ gt-integration\n       â†“\n\"What does that need?\"\n       â†“\n       \"Streaming support\" â†’ gt-streaming\n       \"Header display\" â†’ gt-header\n       â†“\n\"What do those need?\"\n       â†“\n       \"Message rendering\" â†’ gt-messages\n       â†“\n\"What does that need?\"\n       â†“\n       \"Buffer layout\" â†’ gt-buffer (foundation, no deps)\n```\n\nThis produces correct deps because you're asking \"X needs Y\", not \"X before Y\".\n\n### Ready Fronts Visualized\n\n```\nReady Front 1:  gt-buffer (foundation)\nReady Front 2:  gt-messages (needs buffer)\nReady Front 3:  gt-streaming, gt-header (parallel, need messages)\nReady Front 4:  gt-integration (needs streaming, header)\n```\n\nAt any moment, `bd ready` shows the current front. As issues close, blocked work becomes ready.\n\n### Example: OAuth Integration\n\n```bash\n# Create epic (the goal)\nbd create \"OAuth integration\" -t epic\n\n# Walk backward: What does OAuth need?\nbd create \"Login/logout endpoints\" -t task        # needs token storage\nbd create \"Token storage and refresh\" -t task     # needs auth flow\nbd create \"Authorization code flow\" -t task       # needs credentials\nbd create \"OAuth client credentials\" -t task      # foundation\n\n# Add deps using requirement language: \"X needs Y\"\nbd dep add endpoints storage      # endpoints need storage\nbd dep add storage flow           # storage needs flow\nbd dep add flow credentials       # flow needs credentials\n# credentials has no deps - it's Ready Front 1\n\n# Verify: bd blocked should show sensible blocking\nbd blocked\n# endpoints blocked by storage âœ“\n# storage blocked by flow âœ“\n# flow blocked by credentials âœ“\n# credentials ready âœ“\n```\n\n### Validation\n\nAfter adding deps, verify with `bd blocked`:\n- Tasks should be blocked BY their prerequisites\n- NOT blocked by their dependents\n\nIf `gt-integration` is blocked by `gt-setup` â†’ correct\nIf `gt-setup` is blocked by `gt-integration` â†’ deps are inverted, fix them\n\n---\n\n## Side Quest Handling {#side-quests}\n\n**When discovering work that pauses main task:**\n\n```\nSide Quest Workflow:\n- [ ] During main work, discover problem or opportunity\n- [ ] Create issue for side quest\n- [ ] Add discovered-from dependency linking to main work\n- [ ] Assess: blocker or can defer?\n- [ ] If blocker: mark main work blocked, switch to side quest\n- [ ] If deferrable: note in issue, continue main work\n- [ ] Update statuses to reflect current focus\n```\n\n**Example**: During feature implementation, discover architectural issue\n\n```\nMain task: Adding user profiles\n\nDiscovery: Notice auth system should use role-based access\n\nActions:\n1. Create issue: \"Implement role-based access control\"\n2. Link: discovered-from \"user-profiles-feature\"\n3. Assess: Blocker for profiles feature\n4. Mark profiles as blocked\n5. Switch to RBAC implementation\n6. Complete RBAC, unblocks profiles\n7. Resume profiles work\n```\n\n---\n\n## Multi-Session Resume {#resume}\n\n**Starting work after days/weeks away:**\n\n```\nResume Workflow:\n- [ ] Run bd ready to see available work\n- [ ] Run bd stats for project overview\n- [ ] List recent closed issues for context\n- [ ] Show details on issue to work on\n- [ ] Review design notes and acceptance criteria\n- [ ] Update status to in_progress\n- [ ] Begin work with full context\n```\n\n**Why this works**: bd preserves design decisions, acceptance criteria, and dependency context. No scrolling conversation history or reconstructing from markdown.\n\n---\n\n## Session Handoff Workflow {#session-handoff}\n\n**Collaborative handoff between sessions using notes field:**\n\nThis workflow enables smooth work resumption by updating beads notes when stopping, then reading them when resuming. Works in conjunction with compaction survival - creates continuity even after conversation history is deleted.\n\n### At Session Start (Claude's responsibility)\n\n```\nSession Start with in_progress issues:\n- [ ] Run bd list --status in_progress\n- [ ] For each in_progress issue: bd show <issue-id>\n- [ ] Read notes field to understand: COMPLETED, IN PROGRESS, NEXT\n- [ ] Report to user with context from notes field\n- [ ] Example: \"workspace-mcp-server-2 is in_progress. Last session:\n       completed tidying. No code written yet. Next step: create\n       markdown_to_docs.py. Should I continue with that?\"\n- [ ] Wait for user confirmation or direction\n```\n\n**Pattern**: Notes field is the \"read me first\" guide for resuming work.\n\n### At Session End (Claude prompts user)\n\nWhen wrapping up work on an issue:\n\n```\nSession End Handoff:\n- [ ] Notice work reaching a stopping point\n- [ ] Prompt user: \"We just completed X and started Y on <issue-id>.\n       Should I update the beads notes for next session?\"\n- [ ] If yes, suggest command:\n       bd update <issue-id> --notes \"COMPLETED: X. IN PROGRESS: Y. NEXT: Z\"\n- [ ] User reviews and confirms\n- [ ] Claude executes the update\n- [ ] Notes saved for next session's resumption\n```\n\n**Pattern**: Update notes at logical stopping points, not after every keystroke.\n\n### Notes Format (Current State, Not Cumulative)\n\n```\nGood handoff note (current state):\nCOMPLETED: Parsed markdown into structured format\nIN PROGRESS: Implementing Docs API insertion\nNEXT: Debug batchUpdate call - getting 400 error on formatting\nBLOCKER: None\nKEY DECISION: Using two-phase approach (insert text, then apply formatting) based on reference implementation\n\nBad handoff note (not useful):\nUpdated some stuff. Will continue later.\n```\n\n**Rules for handoff notes:**\n- Current state only (overwrite previous notes, not append)\n- Specific accomplishments (not vague progress)\n- Concrete next step (not \"continue working\")\n- Optional: Blockers, key decisions, references\n- Written for someone with zero conversation context\n\n### Session Handoff Checklist\n\nFor Claude at session end:\n\n```\nSession End Checklist:\n- [ ] Work reaching logical stopping point\n- [ ] Prompt user about updating notes\n- [ ] If approved:\n  - [ ] Craft note with COMPLETED/IN_PROGRESS/NEXT\n  - [ ] Include blocker if stuck\n  - [ ] Include key decisions if relevant\n  - [ ] Suggest bd update command\n- [ ] Execute approved update\n- [ ] Confirm: \"Saved handoff notes for next session\"\n```\n\nFor user (optional, but helpful):\n\n```\nUser Tips:\n- [ ] When stopping work: Let Claude suggest notes update\n- [ ] When resuming: Let Claude read notes and report context\n- [ ] Avoid: Trying to remember context manually (that's what notes are for!)\n- [ ] Trust: Well-written notes will help next session pick up instantly\n```\n\n### Example: Real Session Handoff\n\n**Scenario:** Implementing markdownâ†’Docs feature (workspace-mcp-server-2)\n\n**At End of Session 1:**\n```bash\nbd update workspace-mcp-server-2 --notes \"COMPLETED: Set up skeleton with Docs\nAPI connection verified. Markdown parsing logic 80% done (handles *, _ modifiers).\nIN PROGRESS: Testing edge cases for nested formatting. NEXT: Implement\nbatchUpdate call structure for text insertion. REFERENCE: Reference pattern at\ndocs/markdown-to-docs-reference.md. No blockers, moving well.\"\n```\n\n**At Start of Session 2:**\n```bash\nbd show workspace-mcp-server-2\n# Output includes notes field showing exactly where we left off\n# Claude reports: \"Markdownâ†’Docs feature is 80% parsed. We were testing\n# edge cases and need to implement batchUpdate next. Want to continue?\"\n```\n\nSession resumes instantly with full context, no history scrolling needed.\n\n---\n\n## Unblocking Work {#unblocking}\n\n**When ready list is empty:**\n\n```\nUnblocking Workflow:\n- [ ] Run bd blocked --json to see what's stuck\n- [ ] Show details on blocked issues: bd show issue-id\n- [ ] Identify blocker issues\n- [ ] Choose: work on blocker, or reassess dependency\n- [ ] If reassess: remove incorrect dependency\n- [ ] If work on blocker: close blocker, check ready again\n- [ ] Blocked issues automatically become ready when blockers close\n```\n\n**Pattern**: bd automatically maintains ready state based on dependencies. Closing a blocker makes blocked work ready.\n\n**Example**:\n\n```\nSituation: bd ready shows nothing\n\nActions:\n1. bd blocked shows: \"api-endpoint blocked by db-schema\"\n2. Show db-schema: \"Create user table schema\"\n3. Work on db-schema issue\n4. Close db-schema when done\n5. bd ready now shows: \"api-endpoint\" (automatically unblocked)\n```\n\n---\n\n## Integration with TodoWrite\n\n**Using both tools in one session:**\n\n```\nHybrid Workflow:\n- [ ] Check bd for high-level context\n- [ ] Choose bd issue to work on\n- [ ] Mark bd issue in_progress\n- [ ] Create TodoWrite from acceptance criteria for execution\n- [ ] Work through TodoWrite items\n- [ ] Update bd design notes as you learn\n- [ ] When TodoWrite complete, close bd issue\n```\n\n**Why hybrid**: bd provides persistent structure, TodoWrite provides visible progress.\n\n---\n\n## Common Workflow Patterns\n\n### Pattern: Systematic Exploration\n\nResearch or investigation work:\n\n```\n1. Create research issue with question to answer\n2. Update design field with findings as you go\n3. Create new issues for discoveries\n4. Link discoveries with discovered-from\n5. Close research issue with conclusion\n```\n\n### Pattern: Bug Investigation\n\n```\n1. Create bug issue\n2. Reproduce: note steps in description\n3. Investigate: track hypotheses in design field\n4. Fix: implement solution\n5. Test: verify in acceptance criteria\n6. Close with explanation of root cause and fix\n```\n\n### Pattern: Refactoring with Dependencies\n\n```\n1. Create issues for each refactoring step\n2. Add blocks dependencies for correct order\n3. Work through in dependency order\n4. bd ready automatically shows next step\n5. Each completion unblocks next work\n```\n\n### Pattern: Spike Investigation\n\n```\n1. Create spike issue: \"Investigate caching options\"\n2. Time-box exploration\n3. Document findings in design field\n4. Create follow-up issues for chosen approach\n5. Link follow-ups with discovered-from\n6. Close spike with recommendation\n```\n\n---\n\n## Checklist Templates\n\n### Starting Any Work Session\n\n```\n- [ ] Check for .beads/ directory\n- [ ] If exists: bd ready\n- [ ] Report status to user\n- [ ] Get user input on what to work on\n- [ ] Show issue details\n- [ ] Update to in_progress\n- [ ] Begin work\n```\n\n### Creating Issues During Work\n\n```\n- [ ] Notice new work needed\n- [ ] Create issue with clear title\n- [ ] Add context in description\n- [ ] Link with discovered-from to current work\n- [ ] Assess blocker vs deferrable\n- [ ] Update statuses appropriately\n```\n\n### Completing Work\n\n```\n- [ ] Implementation done\n- [ ] Tests passing\n- [ ] Close issue with summary\n- [ ] Check bd ready for unblocked work\n- [ ] Report completion and next available work\n```\n\n### Planning Complex Features\n\n```\n- [ ] Create epic for overall goal\n- [ ] Break into child tasks\n- [ ] Create all child issues\n- [ ] Link with parent-child dependencies\n- [ ] Add blocks between children if order matters\n- [ ] Work through in dependency order\n```\n\n---\n\n## Decision Points\n\n**Should I create a bd issue or use TodoWrite?**\nâ†’ See [BOUNDARIES.md](BOUNDARIES.md) for decision matrix\n\n**Should I ask user before creating issue?**\nâ†’ Ask if scope unclear; create if obvious follow-up work\n\n**Should I mark work as blocked or just note dependency?**\nâ†’ Blocked = can't proceed; dependency = need to track relationship\n\n**Should I create epic or just tasks?**\nâ†’ Epic if 5+ related tasks; tasks if simpler structure\n\n**Should I update status frequently or just at start/end?**\nâ†’ Start and end minimum; during work if significant changes\n\n---\n\n## Troubleshooting Workflows\n\n**\"I can't find any ready work\"**\n1. Run bd blocked\n2. Identify what's blocking progress\n3. Either work on blockers or create new work\n\n**\"I created an issue but it's not showing in ready\"**\n1. Run bd show on the issue\n2. Check dependencies field\n3. If blocked, resolve blocker first\n4. If incorrectly blocked, remove dependency\n\n**\"Work is more complex than expected\"**\n1. Transition from TodoWrite to bd mid-session\n2. Create bd issue with current context\n3. Note: \"Discovered complexity during implementation\"\n4. Add dependencies as discovered\n5. Continue with bd tracking\n\n**\"I closed an issue but work isn't done\"**\n1. Reopen with bd update status=open\n2. Or create new issue linking to closed one\n3. Note what's still needed\n4. Closed issues can't be reopened in some systems, so create new if needed\n\n**\"Too many issues, can't find what matters\"**\n1. Use bd list with filters (priority, issue_type)\n2. Use bd ready to focus on unblocked work\n3. Consider closing old issues that no longer matter\n4. Use labels for organization\n\n",
        "skills/beads/resources/WORKTREES.md": "# Git Worktree Support\n\n> Adapted from ACF beads skill\n\n**v0.40+**: First-class worktree management via `bd worktree` command.\n\n## When to Use Worktrees\n\n| Scenario | Worktree? | Why |\n|----------|-----------|-----|\n| Parallel agent work | Yes | Each agent gets isolated working directory |\n| Long-running feature | Yes | Avoids stash/switch dance for interruptions |\n| Quick branch switch | No | `git switch` is simpler |\n| PR review isolation | Yes | Review without disturbing main work |\n\n## Why `bd worktree` over `git worktree`\n\n**Always use `bd worktree`** instead of raw `git worktree` commands.\n\n```bash\nbd worktree create .worktrees/{name} --branch feature/{name}\nbd worktree remove .worktrees/{name}\n```\n\n**Why?** `bd worktree` auto-configures:\n- Beads database redirect files\n- Proper gitignore entries\n- Daemon bypass for worktree operations\n\n## Architecture\n\nAll worktrees share one `.beads/` database via redirect files:\n\n```\nmain-repo/\nâ”œâ”€â”€ .beads/              â† Single source of truth\nâ””â”€â”€ .worktrees/\n    â”œâ”€â”€ feature-a/\n    â”‚   â””â”€â”€ .beads       â† Redirect file (not directory)\n    â””â”€â”€ feature-b/\n        â””â”€â”€ .beads       â† Redirect file\n```\n\n**Key insight**: Daemon auto-bypasses for wisp operations in worktrees.\n\n## Commands\n\n```bash\n# Create worktree with beads support\nbd worktree create .worktrees/my-feature --branch feature/my-feature\n\n# List worktrees\nbd worktree list\n\n# Show worktree info\nbd worktree info .worktrees/my-feature\n\n# Remove worktree cleanly\nbd worktree remove .worktrees/my-feature\n```\n\n## Debugging\n\nWhen beads commands behave unexpectedly in a worktree:\n\n```bash\nbd where              # Shows actual .beads location (follows redirects)\nbd doctor --deep      # Validates graph integrity across all refs\n```\n\n## Protected Branch Workflows\n\nFor repos with protected `main` branch:\n\n```bash\nbd init --branch beads-metadata    # Use separate branch for beads data\nbd init --contributor              # Auto-configure sync.remote=upstream for forks\n```\n\nThis creates `.git/beads-worktrees/` for internal management.\n\n## Multi-Clone Support\n\nMulti-clone, multi-branch workflows:\n\n- Hash-based IDs (`bd-abc`) eliminate collision across clones\n- Each clone syncs independently via git\n- See [WORKTREES.md](https://github.com/steveyegge/beads/blob/main/docs/WORKTREES.md) for comprehensive guide\n\n## External References\n\n- **Official Docs**: [github.com/steveyegge/beads/docs](https://github.com/steveyegge/beads/tree/main/docs)\n- **Sync Branch**: [PROTECTED_BRANCHES.md](https://github.com/steveyegge/beads/blob/main/docs/PROTECTED_BRANCHES.md)\n- **Worktrees**: [WORKTREES.md](https://github.com/steveyegge/beads/blob/main/docs/WORKTREES.md)\n",
        "tests/hooks/README.md": "# Hooks Test Suite\n\nBats tests for tmux-beads-loops multi-agent hooks.\n\n## Prerequisites\n\nBats is available via npx (included with npm). Alternatively, install bats-core:\n\n```bash\n# macOS\nbrew install bats-core\n\n# Linux (apt)\nsudo apt-get install bats\n\n# Or from source\ngit clone https://github.com/bats-core/bats-core.git\ncd bats-core\n./install.sh /usr/local\n```\n\n## Running Tests\n\n```bash\n# Run all hook tests (via npx - no install needed)\nnpx bats tests/hooks/\n\n# Run with verbose output\nnpx bats --verbose-run tests/hooks/hooks.bats\n\n# Run specific test by name filter\nnpx bats --filter \"session-start\" tests/hooks/hooks.bats\n\n# If bats is installed globally\nbats tests/hooks/\n```\n\n## Test Structure\n\n- `test_helper.bash` - Mock tmux environment and helper functions\n- `hooks.bats` - Test cases for all hooks\n\n## Mock Environment\n\nThe test helper provides:\n\n### Mock tmux Functions\n\n- `tmux display-message` - Returns mock session/window/pane info\n- `tmux show` - Returns mock global/pane options\n- `tmux set` - Sets mock options\n- `tmux send-keys` - Records sent keys for assertions\n\n### Role Setup Functions\n\n- `setup_coordinator_role` - Configure mock as coordinator/manager\n- `setup_wt_manager_role` - Configure mock as worktree manager\n- `setup_worker_role [worktree_path]` - Configure mock as worker\n\n### Option Helpers\n\n- `mock_set_global_option <option> <value>`\n- `mock_get_global_option <option>`\n- `mock_set_pane_option <option> <value>`\n- `mock_get_pane_option <option>`\n\n### Assertion Helpers\n\n- `assert_tmux_command_called <pattern>` - Assert tmux was called with pattern\n- `assert_tmux_command_not_called <pattern>` - Assert tmux was NOT called\n- `count_tmux_commands <pattern>` - Count matching tmux calls\n\n## Test Categories\n\n### Session-Start Hook Tests\n\n- Role detection from window name\n- @claude_role option setting\n- @beads_manager registration\n\n### Pre-Bash Hook Tests\n\n- cd restriction for workers\n- send-keys validation\n- Permission elevation for coordinators\n\n### Post-Commit Hook Tests\n\n- bd sync for workers\n- Sync skip for non-workers\n\n### Stop Hook Tests\n\n- Coordinator notification on worker stop\n- State cleanup\n\n## Writing New Tests\n\n```bash\n@test \"descriptive test name\" {\n  # Setup\n  setup_worker_role \"/tmp/worktree\"\n\n  # Action\n  # ... test code ...\n\n  # Assert\n  [[ \"$expected\" == \"$actual\" ]]\n}\n```\n\n## TDD Workflow\n\nThese tests are written in TDD style - they define expected behavior before the hooks are implemented. The tests currently pass because they test the mock infrastructure and document expected hook behavior.\n\nWhen implementing actual hooks, integrate them with the test harness to verify behavior:\n\n```bash\n# Run tests during hook implementation\nnpx bats tests/hooks/hooks.bats\n\n# Filter to specific hook category\nnpx bats --filter \"pre-bash\" tests/hooks/hooks.bats\nnpx bats --filter \"post-commit\" tests/hooks/hooks.bats\nnpx bats --filter \"stop\" tests/hooks/hooks.bats\n```\n\n## Bash Compatibility\n\nThe test helper uses file-based storage for mock state to maintain compatibility with bash 3.2 (macOS default). This avoids associative arrays which require bash 4+.\n",
        "tests/hooks/hooks.bats": "#!/usr/bin/env bats\n# ABOUTME: Bats tests for tmux-beads-loops multi-agent hooks.\n# ABOUTME: Tests session-start, pre-bash, post-commit, and stop hooks.\n\n# Load the test helper\nload test_helper\n\n# =============================================================================\n# Setup and Teardown\n# =============================================================================\n\nsetup() {\n  reset_mock_state\n  reset_bd_mock\n\n  # Set up a basic tmux environment\n  export TMUX=\"/tmp/mock-tmux,12345,0\"\n\n  # Create temp directories for worktree tests\n  export TEST_WORKTREE_ROOT=\"$(mktemp -d)\"\n  mkdir -p \"$TEST_WORKTREE_ROOT/feature-branch\"\n}\n\nteardown() {\n  # Clean up temp directories\n  if [[ -d \"${TEST_WORKTREE_ROOT:-}\" ]]; then\n    rm -rf \"$TEST_WORKTREE_ROOT\"\n  fi\n}\n\n# =============================================================================\n# Session-Start Hook Tests\n# =============================================================================\n\n@test \"session-start detects coordinator role from window name\" {\n  # Setup: Window named \"coordinator\"\n  export MOCK_TMUX_WINDOW_NAME=\"coordinator\"\n  export MOCK_TMUX_PANE_ID=\"%0\"\n  mock_set_global_option \"@beads_manager_pane\" \"%0\"\n\n  # The hook should detect this as the coordinator\n  # Since hooks don't exist yet, this test documents expected behavior\n  setup_coordinator_role\n\n  # Verify the role was set correctly\n  [[ \"$TMUX_BEADS_ROLE\" == \"manager\" ]]\n}\n\n@test \"session-start detects wt-manager role\" {\n  # Setup: Window named \"wt-manager\" (worktree manager)\n  setup_wt_manager_role\n\n  # The hook should detect this as a wt-manager\n  [[ \"$TMUX_BEADS_ROLE\" == \"wt-manager\" ]]\n  [[ \"$MOCK_TMUX_WINDOW_NAME\" == \"wt-manager\" ]]\n}\n\n@test \"session-start detects worker role and cds to worktree\" {\n  # Setup: Worker window with worktree path\n  local worktree_path=\"$TEST_WORKTREE_ROOT/feature-branch\"\n  setup_worker_role \"$worktree_path\"\n\n  # The hook should detect this as a worker and set worktree path\n  [[ \"$TMUX_BEADS_ROLE\" == \"worker\" ]]\n  [[ \"$TMUX_BEADS_WORKTREE_PATH\" == \"$worktree_path\" ]]\n}\n\n@test \"session-start sets tmux @claude_role option\" {\n  # Setup coordinator role\n  setup_coordinator_role\n\n  # Simulate what the hook should do\n  tmux set -g @claude_role \"coordinator\"\n\n  # Verify the option was set\n  local role\n  role=$(mock_get_global_option \"@claude_role\")\n  [[ \"$role\" == \"coordinator\" ]]\n}\n\n@test \"session-start sets @beads_manager for first pane\" {\n  # First pane should register itself as manager\n  export MOCK_TMUX_SESSION=\"test-session\"\n  export MOCK_TMUX_WINDOW=\"0\"\n  export MOCK_TMUX_PANE_ID=\"%0\"\n\n  # After hook runs, manager should be set\n  tmux set -g @beads_manager \"${MOCK_TMUX_SESSION}:${MOCK_TMUX_WINDOW}\"\n  tmux set -g @beads_manager_pane \"$MOCK_TMUX_PANE_ID\"\n\n  [[ \"$(mock_get_global_option \"@beads_manager\")\" == \"test-session:0\" ]]\n  [[ \"$(mock_get_global_option \"@beads_manager_pane\")\" == \"%0\" ]]\n}\n\n# =============================================================================\n# Pre-Bash Hook Tests\n# =============================================================================\n\n@test \"pre-bash blocks cd outside worktree for workers\" {\n  # Setup worker with restricted worktree\n  local worktree_path=\"$TEST_WORKTREE_ROOT/feature-branch\"\n  setup_worker_role \"$worktree_path\"\n\n  # Attempting to cd outside worktree should be blocked\n  # This test documents the expected behavior - the hook should\n  # intercept and block cd commands outside the worktree\n\n  # Simulate a cd command outside worktree\n  local target_dir=\"/tmp/other-directory\"\n  local should_block=1\n\n  # The pre-bash hook would check:\n  # - Is this a worker role?\n  # - Is the target directory outside the worktree?\n  # If both true, block the command\n\n  if [[ \"$TMUX_BEADS_ROLE\" == \"worker\" ]]; then\n    if [[ \"$target_dir\" != \"$worktree_path\"* ]]; then\n      should_block=1\n    fi\n  fi\n\n  [[ \"$should_block\" -eq 1 ]]\n}\n\n@test \"pre-bash allows cd within worktree\" {\n  # Setup worker with worktree\n  local worktree_path=\"$TEST_WORKTREE_ROOT/feature-branch\"\n  mkdir -p \"$worktree_path/src\"\n  setup_worker_role \"$worktree_path\"\n\n  # cd within worktree should be allowed\n  local target_dir=\"$worktree_path/src\"\n  local should_allow=0\n\n  if [[ \"$TMUX_BEADS_ROLE\" == \"worker\" ]]; then\n    if [[ \"$target_dir\" == \"$worktree_path\"* ]]; then\n      should_allow=1\n    fi\n  fi\n\n  [[ \"$should_allow\" -eq 1 ]]\n}\n\n@test \"pre-bash blocks send-keys without Enter\" {\n  # Workers should not be able to send-keys without Enter\n  # This prevents partial command injection\n  setup_worker_role \"$TEST_WORKTREE_ROOT/feature-branch\"\n\n  # Simulate send-keys without Enter\n  local keys_without_enter=\"echo 'partial command'\"\n  local has_enter=0\n\n  # Check if Enter is included\n  if [[ \"$keys_without_enter\" == *\"Enter\"* ]] || [[ \"$keys_without_enter\" == *$'\\n'* ]]; then\n    has_enter=1\n  fi\n\n  # Should be blocked (no Enter)\n  [[ \"$has_enter\" -eq 0 ]]\n\n  # For workers, this should be blocked\n  local should_block=0\n  if [[ \"$TMUX_BEADS_ROLE\" == \"worker\" ]] && [[ \"$has_enter\" -eq 0 ]]; then\n    should_block=1\n  fi\n\n  [[ \"$should_block\" -eq 1 ]]\n}\n\n@test \"pre-bash allows send-keys with Enter\" {\n  # Complete commands (with Enter) should be allowed\n  setup_worker_role \"$TEST_WORKTREE_ROOT/feature-branch\"\n\n  # Simulate send-keys with Enter\n  local keys_with_enter=\"echo 'complete command' Enter\"\n  local has_enter=0\n\n  if [[ \"$keys_with_enter\" == *\"Enter\"* ]]; then\n    has_enter=1\n  fi\n\n  [[ \"$has_enter\" -eq 1 ]]\n}\n\n@test \"pre-bash allows all commands for coordinator\" {\n  # Coordinator should have no restrictions\n  setup_coordinator_role\n\n  # Even cd outside worktree should work\n  local target_dir=\"/tmp/any-directory\"\n  local should_allow=0\n\n  # Coordinators have no restrictions\n  if [[ \"$TMUX_BEADS_ROLE\" == \"manager\" ]]; then\n    should_allow=1\n  fi\n\n  [[ \"$should_allow\" -eq 1 ]]\n}\n\n@test \"pre-bash allows all commands for wt-manager\" {\n  # wt-manager should also have elevated permissions\n  setup_wt_manager_role\n\n  local should_allow=0\n  if [[ \"$TMUX_BEADS_ROLE\" == \"wt-manager\" ]] || [[ \"$TMUX_BEADS_ROLE\" == \"manager\" ]]; then\n    should_allow=1\n  fi\n\n  [[ \"$should_allow\" -eq 1 ]]\n}\n\n# =============================================================================\n# Post-Commit Hook Tests\n# =============================================================================\n\n@test \"post-commit runs bd sync for workers\" {\n  # Workers should sync their beads after commit\n  setup_worker_role \"$TEST_WORKTREE_ROOT/feature-branch\"\n\n  # Simulate what the post-commit hook should do\n  if [[ \"$TMUX_BEADS_ROLE\" == \"worker\" ]]; then\n    bd sync\n  fi\n\n  was_bd_sync_called\n}\n\n@test \"post-commit skips sync for non-workers\" {\n  # Manager/coordinator should not auto-sync\n  setup_coordinator_role\n\n  # Simulate post-commit hook logic\n  if [[ \"$TMUX_BEADS_ROLE\" == \"worker\" ]]; then\n    bd sync\n  fi\n\n  # Sync should NOT have been called\n  ! was_bd_sync_called\n}\n\n@test \"post-commit runs bd sync for wt-manager\" {\n  # wt-managers may also want to sync\n  setup_wt_manager_role\n\n  # Depending on design, wt-managers might also sync\n  # This test documents the expected behavior\n  local should_sync=0\n\n  # For this test, we expect wt-managers to NOT auto-sync\n  # (only workers auto-sync)\n  if [[ \"$TMUX_BEADS_ROLE\" == \"worker\" ]]; then\n    should_sync=1\n  fi\n\n  [[ \"$should_sync\" -eq 0 ]]\n}\n\n# =============================================================================\n# Stop Hook Tests\n# =============================================================================\n\n@test \"stop notifies coordinator when worker has assigned bead\" {\n  # Setup worker with assigned bead\n  setup_worker_role \"$TEST_WORKTREE_ROOT/feature-branch\"\n  export TMUX_BEADS_ASSIGNED_BEAD=\"bd-123\"\n  mock_set_pane_option \"@assigned_bead\" \"bd-123\"\n\n  # Simulate stop hook - should notify coordinator\n  local should_notify=0\n  local assigned_bead\n\n  assigned_bead=$(mock_get_pane_option \"@assigned_bead\")\n\n  if [[ \"$TMUX_BEADS_ROLE\" == \"worker\" ]] && [[ -n \"$assigned_bead\" ]]; then\n    should_notify=1\n    # Hook would do: tmux send-keys -t $MANAGER_PANE \"# Worker stopped with bead: $assigned_bead\" Enter\n  fi\n\n  [[ \"$should_notify\" -eq 1 ]]\n}\n\n@test \"stop is silent when no bead assigned\" {\n  # Setup worker without assigned bead\n  setup_worker_role \"$TEST_WORKTREE_ROOT/feature-branch\"\n  mock_set_pane_option \"@assigned_bead\" \"\"\n\n  # Simulate stop hook - should be silent\n  local should_notify=0\n  local assigned_bead\n\n  assigned_bead=$(mock_get_pane_option \"@assigned_bead\")\n\n  if [[ \"$TMUX_BEADS_ROLE\" == \"worker\" ]] && [[ -n \"$assigned_bead\" ]]; then\n    should_notify=1\n  fi\n\n  [[ \"$should_notify\" -eq 0 ]]\n}\n\n@test \"stop cleans up worker state\" {\n  # Setup worker\n  setup_worker_role \"$TEST_WORKTREE_ROOT/feature-branch\"\n  mock_set_pane_option \"@assigned_bead\" \"bd-456\"\n  mock_set_pane_option \"@worktree_path\" \"$TEST_WORKTREE_ROOT/feature-branch\"\n\n  # Stop hook should clean up pane options\n  # Simulate cleanup\n  tmux set @assigned_bead \"\"\n  tmux set @worktree_path \"\"\n\n  # After cleanup, options should be empty\n  # Note: This tests the mock infrastructure, the real hook would do this\n  [[ \"$(mock_get_pane_option \"@assigned_bead\")\" == \"\" ]]\n}\n\n@test \"stop notifies coordinator even when wt-manager stops\" {\n  # wt-manager stopping might also need to notify\n  setup_wt_manager_role\n  mock_set_global_option \"@wt_manager_active\" \"1\"\n\n  # Simulate wt-manager stop\n  local should_notify=0\n\n  if [[ \"$TMUX_BEADS_ROLE\" == \"wt-manager\" ]]; then\n    # wt-manager stopping is significant - notify coordinator\n    should_notify=1\n  fi\n\n  # This test documents expected behavior - wt-manager should notify\n  [[ \"$should_notify\" -eq 1 ]]\n}\n\n# =============================================================================\n# Integration Tests (Multiple Hook Interactions)\n# =============================================================================\n\n@test \"worker lifecycle: start -> work -> commit -> stop\" {\n  local worktree_path=\"$TEST_WORKTREE_ROOT/feature-branch\"\n\n  # 1. Session start - worker detected\n  setup_worker_role \"$worktree_path\"\n  [[ \"$TMUX_BEADS_ROLE\" == \"worker\" ]]\n\n  # 2. Assign a bead\n  mock_set_pane_option \"@assigned_bead\" \"bd-789\"\n  export TMUX_BEADS_ASSIGNED_BEAD=\"bd-789\"\n\n  # 3. Simulate commit (post-commit hook)\n  bd sync\n  was_bd_sync_called\n\n  # 4. Stop - should notify\n  local assigned_bead\n  assigned_bead=$(mock_get_pane_option \"@assigned_bead\")\n  [[ -n \"$assigned_bead\" ]]\n}\n\n@test \"coordinator can send commands to workers\" {\n  # Setup coordinator\n  setup_coordinator_role\n\n  # Coordinator sending keys to worker pane\n  tmux send-keys -t \"%2\" \"echo 'task from coordinator'\" Enter\n\n  # Verify command was recorded\n  assert_tmux_command_called \"send-keys\"\n  assert_tmux_command_called \"%2\"\n}\n\n@test \"role detection uses pane ID comparison\" {\n  # Test that role detection compares pane IDs correctly\n  export MOCK_TMUX_PANE_ID=\"%5\"\n  mock_set_global_option \"@beads_manager_pane\" \"%0\"\n\n  export TMUX_BEADS_PANE_ID=\"%5\"\n  export TMUX_BEADS_MANAGER_PANE_ID=\"%0\"\n\n  local role=\"worker\"\n  if [[ \"$TMUX_BEADS_PANE_ID\" == \"$TMUX_BEADS_MANAGER_PANE_ID\" ]]; then\n    role=\"manager\"\n  fi\n\n  [[ \"$role\" == \"worker\" ]]\n}\n\n# =============================================================================\n# Edge Cases\n# =============================================================================\n\n@test \"handles missing TMUX environment gracefully\" {\n  # Outside tmux, hooks should exit gracefully\n  unset TMUX\n\n  # The session-start hook should exit early\n  local should_exit=0\n  if [[ -z \"${TMUX:-}\" ]]; then\n    should_exit=1\n  fi\n\n  [[ \"$should_exit\" -eq 1 ]]\n}\n\n@test \"handles unset worktree path with default fallback\" {\n  # When no worktree path is provided, helper uses default\n  # This tests that the worker role still functions\n  setup_worker_role\n\n  # Worker without explicit worktree should still function\n  [[ \"$TMUX_BEADS_ROLE\" == \"worker\" ]]\n  # Default worktree path is used\n  [[ -n \"$TMUX_BEADS_WORKTREE_PATH\" ]]\n}\n\n@test \"handles special characters in paths\" {\n  # Worktree with spaces and special chars\n  local special_path=\"$TEST_WORKTREE_ROOT/feature with spaces\"\n  mkdir -p \"$special_path\"\n\n  setup_worker_role \"$special_path\"\n\n  [[ \"$TMUX_BEADS_WORKTREE_PATH\" == \"$special_path\" ]]\n}\n",
        "tests/hooks/test_helper.bash": "#!/usr/bin/env bash\n# ABOUTME: Test helper for bats tests - provides mock tmux environment and utilities.\n# ABOUTME: Used to test tmux-beads-loops hooks without requiring actual tmux.\n# ABOUTME: Compatible with bash 3.2+ (macOS default)\n\n# =============================================================================\n# Mock tmux state storage (file-based for bash 3.2 compatibility)\n# =============================================================================\n\n# Create temp directory for mock state\nMOCK_STATE_DIR=\"${BATS_TEST_TMPDIR:-$(mktemp -d)}/mock_tmux_state\"\nmkdir -p \"$MOCK_STATE_DIR\"\n\n# Mock tmux display values (simulate window/pane info)\nMOCK_TMUX_SESSION=\"test-session\"\nMOCK_TMUX_WINDOW=\"0\"\nMOCK_TMUX_WINDOW_NAME=\"main\"\nMOCK_TMUX_PANE_INDEX=\"0\"\nMOCK_TMUX_PANE_ID=\"%0\"\n\n# Track tmux commands for assertions (file-based)\nMOCK_TMUX_COMMANDS_FILE=\"$MOCK_STATE_DIR/commands.log\"\nMOCK_TMUX_SENT_KEYS_FILE=\"$MOCK_STATE_DIR/sent_keys.log\"\n\n# Global options storage\nMOCK_TMUX_GLOBAL_OPTIONS_DIR=\"$MOCK_STATE_DIR/global_options\"\nMOCK_TMUX_PANE_OPTIONS_DIR=\"$MOCK_STATE_DIR/pane_options\"\n\n# BD mock state\nMOCK_BD_COMMANDS_FILE=\"$MOCK_STATE_DIR/bd_commands.log\"\nMOCK_BD_SYNC_CALLED_FILE=\"$MOCK_STATE_DIR/bd_sync_called\"\n\n# =============================================================================\n# Option storage helpers (file-based)\n# =============================================================================\n\n_safe_option_name() {\n  # Convert option name to safe filename\n  echo \"$1\" | sed 's/@/_at_/g; s/\\//_slash_/g'\n}\n\n_set_global_option() {\n  local option=\"$1\"\n  local value=\"$2\"\n  local safe_name\n  safe_name=$(_safe_option_name \"$option\")\n  mkdir -p \"$MOCK_TMUX_GLOBAL_OPTIONS_DIR\"\n  echo \"$value\" > \"$MOCK_TMUX_GLOBAL_OPTIONS_DIR/$safe_name\"\n}\n\n_get_global_option() {\n  local option=\"$1\"\n  local safe_name\n  safe_name=$(_safe_option_name \"$option\")\n  if [[ -f \"$MOCK_TMUX_GLOBAL_OPTIONS_DIR/$safe_name\" ]]; then\n    cat \"$MOCK_TMUX_GLOBAL_OPTIONS_DIR/$safe_name\"\n  fi\n}\n\n_set_pane_option() {\n  local option=\"$1\"\n  local value=\"$2\"\n  local safe_name\n  safe_name=$(_safe_option_name \"$option\")\n  mkdir -p \"$MOCK_TMUX_PANE_OPTIONS_DIR\"\n  echo \"$value\" > \"$MOCK_TMUX_PANE_OPTIONS_DIR/$safe_name\"\n}\n\n_get_pane_option() {\n  local option=\"$1\"\n  local safe_name\n  safe_name=$(_safe_option_name \"$option\")\n  if [[ -f \"$MOCK_TMUX_PANE_OPTIONS_DIR/$safe_name\" ]]; then\n    cat \"$MOCK_TMUX_PANE_OPTIONS_DIR/$safe_name\"\n  fi\n}\n\n# =============================================================================\n# Mock tmux command\n# =============================================================================\n\ntmux() {\n  # Record the full command for later assertions\n  echo \"$*\" >> \"$MOCK_TMUX_COMMANDS_FILE\"\n\n  case \"$1\" in\n    display-message)\n      _mock_tmux_display_message \"$@\"\n      ;;\n    show)\n      _mock_tmux_show \"$@\"\n      ;;\n    show-options)\n      _mock_tmux_show_options \"$@\"\n      ;;\n    set|set-option)\n      _mock_tmux_set \"$@\"\n      ;;\n    send-keys)\n      _mock_tmux_send_keys \"$@\"\n      ;;\n    *)\n      # Record unknown command, return success\n      return 0\n      ;;\n  esac\n}\n\n# Export the mock function\nexport -f tmux\n\n# =============================================================================\n# Mock tmux subcommand implementations\n# =============================================================================\n\n_mock_tmux_display_message() {\n  local target=\"\"\n  local format=\"\"\n\n  shift # remove \"display-message\"\n\n  while [[ $# -gt 0 ]]; do\n    case \"$1\" in\n      -p)\n        # Print to stdout (normal mode)\n        shift\n        ;;\n      -t)\n        target=\"$2\"\n        shift 2\n        ;;\n      *)\n        format=\"$1\"\n        shift\n        ;;\n    esac\n  done\n\n  # Handle format strings\n  case \"$format\" in\n    '#S')\n      echo \"$MOCK_TMUX_SESSION\"\n      ;;\n    '#I')\n      echo \"$MOCK_TMUX_WINDOW\"\n      ;;\n    '#W')\n      echo \"$MOCK_TMUX_WINDOW_NAME\"\n      ;;\n    '#P')\n      echo \"$MOCK_TMUX_PANE_INDEX\"\n      ;;\n    '#{pane_id}')\n      echo \"$MOCK_TMUX_PANE_ID\"\n      ;;\n    '#S:#I')\n      echo \"${MOCK_TMUX_SESSION}:${MOCK_TMUX_WINDOW}\"\n      ;;\n    *)\n      echo \"$format\"\n      ;;\n  esac\n}\n\n_mock_tmux_show() {\n  local scope=\"\"\n  local quiet=\"\"\n  local value_only=\"\"\n  local option_name=\"\"\n\n  shift # remove \"show\"\n\n  while [[ $# -gt 0 ]]; do\n    case \"$1\" in\n      -g)\n        scope=\"global\"\n        shift\n        ;;\n      -q)\n        quiet=\"1\"\n        shift\n        ;;\n      -v)\n        value_only=\"1\"\n        shift\n        ;;\n      -gq|-qg)\n        scope=\"global\"\n        quiet=\"1\"\n        shift\n        ;;\n      -gqv|-gvq|-qgv|-qvg|-vgq|-vqg)\n        scope=\"global\"\n        quiet=\"1\"\n        value_only=\"1\"\n        shift\n        ;;\n      *)\n        option_name=\"$1\"\n        shift\n        ;;\n    esac\n  done\n\n  if [[ -n \"$option_name\" ]]; then\n    local value=\"\"\n    if [[ \"$scope\" == \"global\" ]]; then\n      value=$(_get_global_option \"$option_name\")\n    else\n      value=$(_get_pane_option \"$option_name\")\n    fi\n\n    if [[ -n \"$value_only\" ]]; then\n      echo \"$value\"\n    elif [[ -n \"$value\" ]]; then\n      echo \"$option_name $value\"\n    fi\n  fi\n}\n\n_mock_tmux_show_options() {\n  _mock_tmux_show \"$@\"\n}\n\n_mock_tmux_set() {\n  local scope=\"\"\n  local option_name=\"\"\n  local option_value=\"\"\n\n  shift # remove \"set\" or \"set-option\"\n\n  while [[ $# -gt 0 ]]; do\n    case \"$1\" in\n      -g)\n        scope=\"global\"\n        shift\n        ;;\n      *)\n        if [[ -z \"$option_name\" ]]; then\n          option_name=\"$1\"\n        else\n          option_value=\"$1\"\n        fi\n        shift\n        ;;\n    esac\n  done\n\n  if [[ -n \"$option_name\" ]]; then\n    if [[ \"$scope\" == \"global\" ]]; then\n      _set_global_option \"$option_name\" \"$option_value\"\n    else\n      _set_pane_option \"$option_name\" \"$option_value\"\n    fi\n  fi\n}\n\n_mock_tmux_send_keys() {\n  shift # remove \"send-keys\"\n  echo \"$*\" >> \"$MOCK_TMUX_SENT_KEYS_FILE\"\n}\n\n# Export helper functions\nexport -f _mock_tmux_display_message\nexport -f _mock_tmux_show\nexport -f _mock_tmux_show_options\nexport -f _mock_tmux_set\nexport -f _mock_tmux_send_keys\nexport -f _safe_option_name\nexport -f _set_global_option\nexport -f _get_global_option\nexport -f _set_pane_option\nexport -f _get_pane_option\n\n# =============================================================================\n# Role simulation helpers\n# =============================================================================\n\n# Set up mock environment for a coordinator/manager role\nsetup_coordinator_role() {\n  MOCK_TMUX_SESSION=\"test-session\"\n  MOCK_TMUX_WINDOW=\"0\"\n  MOCK_TMUX_WINDOW_NAME=\"coordinator\"\n  MOCK_TMUX_PANE_INDEX=\"0\"\n  MOCK_TMUX_PANE_ID=\"%0\"\n\n  _set_global_option \"@beads_manager\" \"${MOCK_TMUX_SESSION}:${MOCK_TMUX_WINDOW}\"\n  _set_global_option \"@beads_manager_pane\" \"%0\"\n  _set_global_option \"@beads_manager_name\" \"coordinator\"\n\n  export TMUX=\"/tmp/mock-tmux,12345,0\"\n  export TMUX_PANE=\"%0\"\n  export TMUX_BEADS_ROLE=\"manager\"\n  export TMUX_BEADS_MANAGER_TARGET=\"${MOCK_TMUX_SESSION}:${MOCK_TMUX_WINDOW}\"\n  export TMUX_BEADS_MANAGER_PANE_ID=\"%0\"\n  export TMUX_BEADS_PANE_ID=\"%0\"\n}\n\n# Set up mock environment for a wt-manager role (worktree manager)\nsetup_wt_manager_role() {\n  MOCK_TMUX_SESSION=\"test-session\"\n  MOCK_TMUX_WINDOW=\"1\"\n  MOCK_TMUX_WINDOW_NAME=\"wt-manager\"\n  MOCK_TMUX_PANE_INDEX=\"0\"\n  MOCK_TMUX_PANE_ID=\"%1\"\n\n  _set_global_option \"@beads_manager\" \"${MOCK_TMUX_SESSION}:0\"\n  _set_global_option \"@beads_manager_pane\" \"%0\"\n  _set_global_option \"@claude_role\" \"wt-manager\"\n\n  export TMUX=\"/tmp/mock-tmux,12345,0\"\n  export TMUX_PANE=\"%1\"\n  export TMUX_BEADS_ROLE=\"wt-manager\"\n  export TMUX_BEADS_MANAGER_TARGET=\"${MOCK_TMUX_SESSION}:0\"\n  export TMUX_BEADS_MANAGER_PANE_ID=\"%0\"\n  export TMUX_BEADS_PANE_ID=\"%1\"\n}\n\n# Set up mock environment for a worker role\n# Args: $1 = worktree path (optional)\nsetup_worker_role() {\n  local worktree_path=\"${1:-/tmp/test-worktree}\"\n\n  MOCK_TMUX_SESSION=\"test-session\"\n  MOCK_TMUX_WINDOW=\"2\"\n  MOCK_TMUX_WINDOW_NAME=\"worker-1\"\n  MOCK_TMUX_PANE_INDEX=\"0\"\n  MOCK_TMUX_PANE_ID=\"%2\"\n\n  _set_global_option \"@beads_manager\" \"${MOCK_TMUX_SESSION}:0\"\n  _set_global_option \"@beads_manager_pane\" \"%0\"\n  _set_global_option \"@claude_role\" \"worker\"\n  _set_pane_option \"@worktree_path\" \"$worktree_path\"\n  _set_pane_option \"@assigned_bead\" \"\"\n\n  export TMUX=\"/tmp/mock-tmux,12345,0\"\n  export TMUX_PANE=\"%2\"\n  export TMUX_BEADS_ROLE=\"worker\"\n  export TMUX_BEADS_WORKTREE_PATH=\"$worktree_path\"\n  export TMUX_BEADS_MANAGER_TARGET=\"${MOCK_TMUX_SESSION}:0\"\n  export TMUX_BEADS_MANAGER_PANE_ID=\"%0\"\n  export TMUX_BEADS_PANE_ID=\"%2\"\n}\n\n# Export role setup functions\nexport -f setup_coordinator_role\nexport -f setup_wt_manager_role\nexport -f setup_worker_role\n\n# =============================================================================\n# Tmux option helpers for tests (public API)\n# =============================================================================\n\n# Set a mock global tmux option\nmock_set_global_option() {\n  _set_global_option \"$1\" \"$2\"\n}\n\n# Get a mock global tmux option\nmock_get_global_option() {\n  _get_global_option \"$1\"\n}\n\n# Set a mock pane-specific tmux option\nmock_set_pane_option() {\n  _set_pane_option \"$1\" \"$2\"\n}\n\n# Get a mock pane-specific tmux option\nmock_get_pane_option() {\n  _get_pane_option \"$1\"\n}\n\n# Export option helpers\nexport -f mock_set_global_option\nexport -f mock_get_global_option\nexport -f mock_set_pane_option\nexport -f mock_get_pane_option\n\n# =============================================================================\n# Assertion helpers\n# =============================================================================\n\n# Assert that a tmux command was called\nassert_tmux_command_called() {\n  local expected=\"$1\"\n\n  if [[ ! -f \"$MOCK_TMUX_COMMANDS_FILE\" ]]; then\n    echo \"No tmux commands were called\"\n    return 1\n  fi\n\n  if grep -q \"$expected\" \"$MOCK_TMUX_COMMANDS_FILE\"; then\n    return 0\n  else\n    echo \"Expected tmux command containing '$expected' was not called\"\n    echo \"Commands called:\"\n    cat \"$MOCK_TMUX_COMMANDS_FILE\"\n    return 1\n  fi\n}\n\n# Assert that a tmux command was NOT called\nassert_tmux_command_not_called() {\n  local unexpected=\"$1\"\n\n  if [[ ! -f \"$MOCK_TMUX_COMMANDS_FILE\" ]]; then\n    return 0\n  fi\n\n  if grep -q \"$unexpected\" \"$MOCK_TMUX_COMMANDS_FILE\"; then\n    echo \"Unexpected tmux command containing '$unexpected' was called\"\n    echo \"Commands called:\"\n    cat \"$MOCK_TMUX_COMMANDS_FILE\"\n    return 1\n  fi\n}\n\n# Get the number of times a command pattern was called\ncount_tmux_commands() {\n  local pattern=\"$1\"\n\n  if [[ ! -f \"$MOCK_TMUX_COMMANDS_FILE\" ]]; then\n    echo \"0\"\n    return\n  fi\n\n  grep -c \"$pattern\" \"$MOCK_TMUX_COMMANDS_FILE\" || echo \"0\"\n}\n\n# Export assertion helpers\nexport -f assert_tmux_command_called\nexport -f assert_tmux_command_not_called\nexport -f count_tmux_commands\n\n# =============================================================================\n# Test setup and teardown\n# =============================================================================\n\n# Reset all mock state (call in setup())\nreset_mock_state() {\n  # Clean up state directories\n  rm -rf \"$MOCK_STATE_DIR\"\n  mkdir -p \"$MOCK_STATE_DIR\"\n  mkdir -p \"$MOCK_TMUX_GLOBAL_OPTIONS_DIR\"\n  mkdir -p \"$MOCK_TMUX_PANE_OPTIONS_DIR\"\n\n  # Reset display values\n  MOCK_TMUX_SESSION=\"test-session\"\n  MOCK_TMUX_WINDOW=\"0\"\n  MOCK_TMUX_WINDOW_NAME=\"main\"\n  MOCK_TMUX_PANE_INDEX=\"0\"\n  MOCK_TMUX_PANE_ID=\"%0\"\n\n  # Clear exported environment\n  unset TMUX_BEADS_ROLE\n  unset TMUX_BEADS_WORKTREE_PATH\n  unset TMUX_BEADS_MANAGER_TARGET\n  unset TMUX_BEADS_MANAGER_PANE_ID\n  unset TMUX_BEADS_PANE_ID\n  unset TMUX_BEADS_ASSIGNED_BEAD\n}\n\nexport -f reset_mock_state\n\n# =============================================================================\n# Mock bd (beads) command\n# =============================================================================\n\nMOCK_BD_SYNC_CALLED=0\n\nbd() {\n  echo \"$*\" >> \"$MOCK_BD_COMMANDS_FILE\"\n\n  case \"$1\" in\n    sync)\n      MOCK_BD_SYNC_CALLED=1\n      echo \"1\" > \"$MOCK_BD_SYNC_CALLED_FILE\"\n      ;;\n  esac\n\n  return 0\n}\n\nexport -f bd\n\nreset_bd_mock() {\n  rm -f \"$MOCK_BD_COMMANDS_FILE\"\n  rm -f \"$MOCK_BD_SYNC_CALLED_FILE\"\n  MOCK_BD_SYNC_CALLED=0\n}\n\n# Check if bd sync was called\nwas_bd_sync_called() {\n  if [[ -f \"$MOCK_BD_SYNC_CALLED_FILE\" ]]; then\n    return 0\n  fi\n  return 1\n}\n\nexport -f reset_bd_mock\nexport -f was_bd_sync_called\n\n# =============================================================================\n# Path for hooks under test\n# =============================================================================\n\n# Get the project root (assuming tests are in tests/hooks/)\nget_project_root() {\n  local script_dir\n  if [[ -n \"${BATS_TEST_DIRNAME:-}\" ]]; then\n    script_dir=\"$BATS_TEST_DIRNAME\"\n  else\n    script_dir=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\n  fi\n  cd \"$script_dir/../..\" && pwd\n}\n\n# Get the path to the hooks directory\nget_hooks_dir() {\n  echo \"$(get_project_root)/scripts/tmux-beads-loops\"\n}\n\nexport -f get_project_root\nexport -f get_hooks_dir\n\n# Export state directory variables\nexport MOCK_STATE_DIR\nexport MOCK_TMUX_COMMANDS_FILE\nexport MOCK_TMUX_SENT_KEYS_FILE\nexport MOCK_TMUX_GLOBAL_OPTIONS_DIR\nexport MOCK_TMUX_PANE_OPTIONS_DIR\nexport MOCK_BD_COMMANDS_FILE\nexport MOCK_BD_SYNC_CALLED_FILE\nexport MOCK_TMUX_SESSION\nexport MOCK_TMUX_WINDOW\nexport MOCK_TMUX_WINDOW_NAME\nexport MOCK_TMUX_PANE_INDEX\nexport MOCK_TMUX_PANE_ID\n",
        "tests/integration/README.md": "# Integration Tests\n\nThis directory contains integration tests for bd (beads) that test end-to-end functionality.\n\n## Prerequisites\n\n- bd installed: `go install github.com/steveyegge/beads/cmd/bd@latest`\n- Python 3.7+ for Python-based tests\n\n## Running Tests\n\n```bash\n# Run all integration tests\npython3 -m pytest tests/integration/\n```\n\n## Adding New Tests\n\nIntegration tests should:\n1. Use temporary workspaces (cleaned up automatically)\n2. Test real bd CLI commands, not just internal APIs\n3. Use `--no-daemon` flag for fast execution\n4. Verify behavior in `.beads/issues.jsonl` when relevant\n5. Clean up resources in `finally` blocks\n6. Provide clear output showing what's being tested\n",
        "website/README.md": "# Beads Documentation Site\n",
        "winget/README.md": "# Windows Package Manager (winget) Manifest\n\nThis directory contains the winget manifest files for publishing beads to the Windows Package Manager.\n\n## Installation (once published)\n\n```powershell\nwinget install SteveYegge.beads\n```\n\n## Manifest Files\n\n- `SteveYegge.beads.yaml` - Version manifest (main file)\n- `SteveYegge.beads.installer.yaml` - Installer configuration\n- `SteveYegge.beads.locale.en-US.yaml` - Package description and metadata\n\n## Submitting to winget-pkgs\n\n1. Fork https://github.com/microsoft/winget-pkgs\n2. Create directory: `manifests/s/SteveYegge/beads/<version>/`\n3. Copy the three manifest files to that directory\n4. Submit a PR to microsoft/winget-pkgs\n\nOr use the wingetcreate tool:\n```powershell\nwingetcreate update SteveYegge.beads --version <new-version> --urls <new-url> --submit\n```\n\n## Updating for New Releases\n\nWhen releasing a new version:\n\n1. Update the version in all three manifest files\n2. Update the InstallerUrl in the installer manifest\n3. Update the InstallerSha256 (get from checksums.txt in the release)\n4. Update the ReleaseNotesUrl\n5. Submit PR to microsoft/winget-pkgs\n\n### Getting the SHA256\n\n```bash\ncurl -sL https://github.com/steveyegge/beads/releases/download/v<VERSION>/checksums.txt | grep windows\n```\n"
      },
      "plugins": [
        {
          "name": "beads",
          "source": "./",
          "description": "AI-supervised issue tracker for coding workflows",
          "version": "0.44.0",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add dbmcco/tmux-beads-loops",
            "/plugin install beads@beads-marketplace"
          ]
        }
      ]
    }
  ]
}