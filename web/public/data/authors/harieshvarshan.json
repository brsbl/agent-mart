{
  "author": {
    "id": "HarieshVarshan",
    "display_name": "Hariesh Varshan",
    "avatar_url": "https://avatars.githubusercontent.com/u/58946243?v=4"
  },
  "marketplaces": [
    {
      "name": "vrshn-claude-marketplace",
      "version": null,
      "description": "MCP server for Jira, Confluence, and Bitbucket integration - search, read, create, and manage issues, pages, and pull requests",
      "repo_full_name": "HarieshVarshan/Vrshn-Claude-Marketplace",
      "repo_url": "https://github.com/HarieshVarshan/Vrshn-Claude-Marketplace",
      "repo_description": null,
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-02-17T11:59:39Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n    \"name\": \"vrshn-claude-marketplace\",\n    \"owner\": {\n        \"name\": \"Harieshvarshan\",\n        \"email\": \"harieshvarshan@example.com\"\n    },\n    \"plugins\": [\n        {\n            \"name\": \"atlassian-mcp\",\n            \"description\": \"MCP server for Jira, Confluence, and Bitbucket integration - search, read, create, and manage issues, pages, and pull requests\",\n            \"source\": \"./atlassian-mcp\"\n        },\n        {\n            \"name\": \"talk2docs\",\n            \"description\": \"Local document semantic search - index and search PDF, DOCX, XLSX, PPTX, and more using ChromaDB and Ollama embeddings\",\n            \"source\": \"./talk2docs\"\n        },\n        {\n            \"name\": \"klocwork-mcp\",\n            \"description\": \"MCP server for Klocwork project management - list projects, search issues, manage modules and permissions\",\n            \"source\": \"./klocwork-mcp\"\n        },\n        {\n            \"name\": \"bitbucket-mcp\",\n            \"description\": \"MCP server for Bitbucket Server/Data Center - manage PRs, repos, branches, and permissions\",\n            \"source\": \"./bitbucket-mcp\"\n        },\n        {\n            \"name\": \"confluence-mcp\",\n            \"description\": \"MCP server for Confluence Data Center - manage pages, spaces, attachments, and search\",\n            \"source\": \"./confluence-mcp\"\n        },\n        {\n            \"name\": \"jenkins-mcp\",\n            \"description\": \"MCP server for Jenkins CI/CD - manage jobs, builds, nodes, and artifacts\",\n            \"source\": \"./jenkins-mcp\"\n        },\n        {\n            \"name\": \"jira-mcp\",\n            \"description\": \"MCP server for Jira Data Center - manage issues, projects, sprints, and workflows\",\n            \"source\": \"./jira-mcp\"\n        },\n        {\n            \"name\": \"mcp-excalidraw\",\n            \"description\": \"MCP server for Excalidraw - create, edit, and manage diagrams with a live canvas, element CRUD, layout, scene awareness, and file I/O\",\n            \"source\": \"./mcp_excalidraw\"\n        }\n    ]\n}\n",
        "README.md": "# Vrshn Claude Marketplace\n\nA collection of MCP (Model Context Protocol) server plugins for Claude Code.\n\n## Available Plugins\n\n| Plugin | Description |\n|--------|-------------|\n| [atlassian-mcp](./atlassian-mcp/) | Jira, Confluence, and Bitbucket integration - search, read, create, and manage issues, pages, and pull requests |\n| [talk2docs](./talk2docs/) | Local document semantic search using ChromaDB and Ollama embeddings |\n\n## Quick Start\n\n### Step 1: Add This Marketplace to Claude Code\n\nOpen or create `~/.claude/settings.json` and add the marketplace configuration:\n\n```json\n{\n  \"marketplaces\": [\n    {\n      \"name\": \"Vrshn Marketplace\",\n      \"url\": \"https://bitbucket.itg.ti.com/projects/vrshn/repos/vrshn-claude-marketplace/raw/.claude-plugin/marketplace.json?at=refs/heads/master\"\n    }\n  ]\n}\n```\n\nIf you already have other settings in the file, just add the `marketplaces` array alongside them.\n\n### Step 2: Clone the Repository\n\n```bash\ngit clone ssh://git@bitbucket.itg.ti.com/vrshn/vrshn-claude-marketplace.git\ncd vrshn-claude-marketplace\n```\n\n### Step 3: Install a Plugin\n\nChoose which plugin to install and follow the setup instructions below.\n\n---\n\n## Plugin Setup Instructions\n\n### Atlassian MCP Setup\n\nThis plugin provides tools for Jira, Confluence, and Bitbucket.\n\n#### 1. Install Dependencies\n\n```bash\ncd atlassian-mcp\npython -m venv venv\nsource venv/bin/activate  # Linux/Mac\n# or: venv\\Scripts\\activate  # Windows\npip install -r requirements.txt\n```\n\n#### 2. Configure Credentials\n\nCreate the credentials file:\n\n```bash\nmkdir -p ~/.config/atlassian\nchmod 700 ~/.config/atlassian\n\ncat > ~/.config/atlassian/.env << 'EOF'\n# Jira credentials\nJIRA_URL=https://jira.your-company.com\nJIRA_USERNAME=your_username\nJIRA_TOKEN=your_personal_access_token\n\n# Confluence credentials\nCONFLUENCE_URL=https://confluence.your-company.com\nCONFLUENCE_USERNAME=your_username\nCONFLUENCE_TOKEN=your_personal_access_token\n\n# Bitbucket credentials\nBITBUCKET_URL=https://bitbucket.your-company.com\nBITBUCKET_USERNAME=your_username\nBITBUCKET_TOKEN=your_personal_access_token\nEOF\n\nchmod 600 ~/.config/atlassian/.env\n```\n\n#### 3. Get Personal Access Tokens\n\n**Jira:**\n1. Go to Avatar > Profile > Personal Access Tokens\n2. Click \"Create token\"\n3. Copy the token value\n\n**Confluence:**\n1. Go to Avatar > Settings > Personal Access Tokens\n2. Click \"Create token\"\n3. Copy the token value\n\n**Bitbucket:**\n1. Go to Avatar > Manage Account > Personal Access Tokens\n2. Click \"Create token\"\n3. Select \"Repository Read\" permission (and Write if needed)\n4. Copy the token value\n\n#### 4. Register with Claude Code\n\n```bash\n# Make sure you're in the atlassian-mcp directory with venv activated\nclaude mcp add --transport stdio --scope user atlassian \\\n  --env ATLASSIAN_CONFIG=~/.config/atlassian/.env \\\n  -- $(pwd)/venv/bin/python $(pwd)/mcp_server.py\n```\n\n#### 5. Verify Installation\n\nRestart Claude Code and try:\n- \"Get issue PROJ-123 from Jira\"\n- \"Search for open bugs assigned to me\"\n- \"Get the latest PR in my-project/my-repo\"\n\n---\n\n### Talk2Docs Setup\n\nThis plugin provides semantic search across local documents.\n\n#### 1. Install Ollama\n\n```bash\n# Install Ollama (Linux)\ncurl -fsSL https://ollama.com/install.sh | sh\n\n# Pull the embedding model\nollama pull nomic-embed-text\n\n# Start Ollama service\nollama serve\n```\n\n#### 2. Install Dependencies\n\n```bash\ncd talk2docs\npython -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\n```\n\n#### 3. Index Your Documents\n\n```bash\n# Index a folder of documents\npython index.py /path/to/your/documents\n\n# Index specific files\npython index.py file1.pdf file2.docx\n\n# Force re-index existing documents\npython index.py --force /path/to/documents\n\n# Filter by extension\npython index.py /path/to/documents --ext pdf docx\n\n# Use parallel processing for faster indexing\npython index.py /path/to/documents -p 4 -w 8\n```\n\n#### 4. Register with Claude Code\n\n```bash\n# Make sure you're in the talk2docs directory with venv activated\nclaude mcp add --transport stdio --scope user ldoc-search \\\n  --env CHROMA_DB_PATH=$(pwd)/chroma_db \\\n  --env OLLAMA_MODEL=nomic-embed-text \\\n  -- $(pwd)/venv/bin/python $(pwd)/mcp_server.py\n```\n\n#### 5. Verify Installation\n\nRestart Claude Code and try:\n- \"Search my documents for deployment guide\"\n- \"List all indexed documents\"\n- \"Get index statistics\"\n\n---\n\n## Managing MCP Servers\n\n```bash\n# List registered MCP servers\nclaude mcp list\n\n# Remove an MCP server\nclaude mcp remove atlassian\nclaude mcp remove ldoc-search\n\n# Check MCP server status\nclaude mcp status\n```\n\n## Plugin Details\n\n### Atlassian MCP Tools\n\n**Jira:**\n- `jira_get_issue` - Get issue details by key or URL\n- `jira_search` - Search issues using JQL\n- `jira_create_issue` - Create new issues\n- `jira_add_comment` - Add comments to issues\n- `jira_transition_issue` - Change issue status\n\n**Confluence:**\n- `confluence_get_page` - Get page content by ID or URL\n- `confluence_get_page_by_title` - Get page by space and title\n- `confluence_search` - Search pages using CQL\n- `confluence_get_space_pages` - List pages in a space\n\n**Bitbucket:**\n- `bitbucket_get_pr` - Get pull request details\n- `bitbucket_get_pr_diff` - Get PR code changes\n- `bitbucket_list_prs` - List repository PRs\n- `bitbucket_add_pr_comment` - Comment on PRs\n- `bitbucket_get_file` - Get file content from repo\n- `bitbucket_list_branches` - List repository branches\n\n### Talk2Docs Tools\n\n- `search_pdfs` - Semantic search across indexed documents\n- `list_indexed_documents` - List all indexed documents with chunk counts\n- `get_index_stats` - Get index statistics\n\n**Supported Formats:** PDF, DOCX, XLSX, PPTX, ODT, ODS, ODP, TXT, MD, HTML, CSV, JSON, XML\n\n---\n\n## Troubleshooting\n\n### MCP Server Not Responding\n\n1. Check if the server is registered: `claude mcp list`\n2. Test the server directly: `python mcp_server.py` (should sit quietly if working)\n3. Check for error messages in Claude Code output\n\n### Atlassian Authentication Errors\n\n1. Verify token hasn't expired\n2. Check URLs don't have trailing slashes\n3. Ensure correct permissions on token\n\n### Talk2Docs Search Returns No Results\n\n1. Verify documents are indexed: `python manage_index.py list`\n2. Check Ollama is running: `curl http://localhost:11434/api/tags`\n3. Try re-indexing: `python index.py --force /path/to/docs`\n\n---\n\n## Creating Your Own Plugin\n\nEach plugin follows this structure:\n\n```\nplugin-name/\n├── .claude-plugin/\n│   └── plugin.json       # Plugin metadata\n├── mcp-servers.json      # MCP server configuration\n├── mcp_server.py         # MCP server implementation\n├── requirements.txt      # Python dependencies\n└── README.md             # Plugin documentation\n```\n\n**plugin.json format:**\n```json\n{\n    \"name\": \"plugin-name\",\n    \"description\": \"What your plugin does\",\n    \"version\": \"1.0.0\",\n    \"author\": {\n        \"name\": \"Your Name\",\n        \"email\": \"your@email.com\"\n    },\n    \"mcpServers\": \"./mcp-servers.json\"\n}\n```\n\n**mcp-servers.json format:**\n```json\n{\n    \"mcpServers\": {\n        \"server-name\": {\n            \"type\": \"stdio\",\n            \"command\": \"python\",\n            \"args\": [\"${CLAUDE_PLUGIN_ROOT}/mcp_server.py\"],\n            \"env\": {}\n        }\n    }\n}\n```\n\n## License\n\nMIT\n",
        "atlassian-mcp/README.md": "# Atlassian MCP Server\n\nA Model Context Protocol (MCP) server that provides Claude with access to Jira, Confluence, and Bitbucket. This enables Claude to search, read, create, and manage issues, pages, and pull requests directly from conversations.\n\n## Features\n\n### Jira Tools\n- **jira_get_issue** - Get issue details by key or URL\n- **jira_search** - Search issues using JQL\n- **jira_create_issue** - Create new issues\n- **jira_add_comment** - Add comments to issues\n- **jira_transition_issue** - Change issue status\n\n### Confluence Tools\n- **confluence_get_page** - Get page content by ID or URL\n- **confluence_get_page_by_title** - Get page by space and title\n- **confluence_search** - Search pages using text or CQL\n- **confluence_get_space_pages** - List all pages in a space\n\n### Bitbucket Tools\n- **bitbucket_get_pr** - Get pull request details\n- **bitbucket_get_pr_diff** - Get PR diff/changes\n- **bitbucket_list_prs** - List repository PRs\n- **bitbucket_add_pr_comment** - Add comments to PRs\n- **bitbucket_get_file** - Get file content from repo\n- **bitbucket_list_branches** - List repository branches\n\n## Prerequisites\n\n1. **Python 3.10+**\n2. **Atlassian Personal Access Tokens** for each service you want to use\n\n## Installation\n\n### 1. Set Up Python Virtual Environment\n\nThe plugin requires a Python virtual environment with dependencies installed at a **fixed location** (`~/.local/share/atlassian-mcp/`). This follows the [XDG Base Directory Specification](https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html) for user application data.\n\n```bash\n# Create the directory and virtual environment\nmkdir -p ~/.local/share/atlassian-mcp\ncd ~/.local/share/atlassian-mcp\npython -m venv venv\n\n# Activate and install dependencies\nsource venv/bin/activate\npip install mcp requests python-dotenv\n```\n\n#### Dependencies\n\n| Package | Purpose |\n|---------|---------|\n| `mcp` | Model Context Protocol SDK for building MCP servers |\n| `requests` | HTTP client for Atlassian REST API calls |\n| `python-dotenv` | Load credentials from `.env` configuration file |\n\n### 2. Configure Credentials\n\nCreate `~/.config/atlassian/.env`:\n\n```bash\nmkdir -p ~/.config/atlassian\nchmod 700 ~/.config/atlassian\n\ncat > ~/.config/atlassian/.env << 'EOF'\n# Jira credentials\nJIRA_URL=https://jira.your-company.com\nJIRA_USERNAME=your_username\nJIRA_TOKEN=your_personal_access_token\n\n# Confluence credentials\nCONFLUENCE_URL=https://confluence.your-company.com\nCONFLUENCE_USERNAME=your_username\nCONFLUENCE_TOKEN=your_personal_access_token\n\n# Bitbucket credentials\nBITBUCKET_URL=https://bitbucket.your-company.com\nBITBUCKET_USERNAME=your_username\nBITBUCKET_TOKEN=your_personal_access_token\nEOF\n\nchmod 600 ~/.config/atlassian/.env\n```\n\n### 3. Create Personal Access Tokens\n\n#### Jira\n1. Go to **Avatar > Profile > Personal Access Tokens**\n2. Click **Create token**\n3. Copy the token value\n\n#### Confluence\n1. Go to **Avatar > Settings > Personal Access Tokens**\n2. Click **Create token**\n3. Copy the token value\n\n#### Bitbucket\n1. Go to **Avatar > Manage Account > Personal Access Tokens**\n2. Click **Create token**\n3. Select **Repository Read** permission (and Write if needed)\n4. Copy the token value\n\n## Claude Integration\n\n### Option 1: Plugin Marketplace (Recommended)\n\nIf you have the marketplace configured:\n\n```bash\n# Install the plugin\nclaude plugin install atlassian-mcp\n\n# Restart Claude Code to load the MCP server\n```\n\nThe plugin will automatically use the virtual environment at `~/.local/share/atlassian-mcp/venv/`.\n\n### Option 2: Manual MCP Registration\n\nIf not using the marketplace, register the MCP server manually:\n\n```bash\nclaude mcp add --transport stdio --scope user atlassian \\\n  --env ATLASSIAN_CONFIG=~/.config/atlassian/.env \\\n  -- ~/.local/share/atlassian-mcp/venv/bin/python /path/to/atlassian-mcp/mcp_server.py\n```\n\n## Usage Examples\n\nOnce registered, you can use these tools in conversations with Claude:\n\n### Jira Examples\n\n```\n\"Get the details of PROJ-123\"\n\"Search for all open bugs assigned to me in project MYPROJ\"\n\"Create a new task in PROJ with summary 'Fix login issue'\"\n\"Add a comment to PROJ-456 saying 'This is fixed in PR #789'\"\n\"Move PROJ-123 to 'In Progress'\"\n```\n\n### Confluence Examples\n\n```\n\"Get the page at https://confluence.company.com/pages/viewpage.action?pageId=123456\"\n\"Find all pages about 'deployment guide' in the DOCS space\"\n\"List all pages in the TEAM space\"\n\"Get the page titled 'Getting Started' in space DOCS\"\n```\n\n### Bitbucket Examples\n\n```\n\"Get PR #42 from project MYPROJ repo my-service\"\n\"Show me the diff for that PR\"\n\"List all open PRs in MYPROJ/my-service\"\n\"Add a comment to PR #42 saying 'LGTM!'\"\n\"Get the content of src/main.py from MYPROJ/my-service\"\n```\n\n## Architecture\n\n```\natlassian-mcp/\n├── .claude-plugin/\n│   └── plugin.json         # Plugin metadata\n├── mcp-servers.json        # MCP server configuration\n├── mcp_server.py           # Main MCP server (entry point)\n├── atlassian_client.py     # API clients for Jira, Confluence, Bitbucket\n├── requirements.txt        # Python dependencies\n└── README.md               # This file\n```\n\n## Troubleshooting\n\n### Connection Issues\n\n1. **Check token validity**: Tokens may expire\n2. **Verify URLs**: Ensure URLs don't have trailing slashes in config\n3. **Proxy settings**: If behind a corporate proxy, you may need to set HTTP_PROXY/HTTPS_PROXY\n\n### Authentication Errors\n\n- **Jira/Confluence**: Use Bearer token authentication\n- **Bitbucket Server**: Uses Basic auth with username:token\n\n### Debug Mode\n\nRun the server directly to see errors:\n```bash\npython mcp_server.py\n```\n\n## License\n\nMIT\n",
        "talk2docs/README.md": "# Document MCP Server\n\nMCP server for semantic search across documents using Ollama embeddings and ChromaDB.\n\n## Supported Formats\n\n| Format | Extension | Description |\n|--------|-----------|-------------|\n| PDF | `.pdf` | PDF documents |\n| Word | `.docx`, `.doc` | Microsoft Word |\n| Excel | `.xlsx`, `.xls` | Microsoft Excel |\n| PowerPoint | `.pptx` | Microsoft PowerPoint |\n| OpenDocument | `.odt`, `.ods`, `.odp` | LibreOffice/OpenOffice |\n| Text | `.txt`, `.md` | Plain text, Markdown |\n| Web | `.html`, `.htm` | HTML pages |\n| Data | `.csv`, `.json`, `.xml` | Structured data |\n\n## Prerequisites\n\n1. **Python 3.10+**\n2. **Ollama** - for local embeddings\n\n## Setup\n\n### 1. Install Ollama\n\n```bash\ncurl -fsSL https://ollama.com/install.sh | sh\n\n# Pull embedding model\nollama pull nomic-embed-text\n\n# Verify\nollama list\n```\n\n**Important:** Ollama must be running for both indexing and searching (it converts text to embeddings).\n\n**Start Ollama:**\n```bash\n# Option 1: Run manually (foreground) - Ctrl+C to stop\nollama serve\n\n# Option 2: Run as background process\nnohup ollama serve > /dev/null 2>&1 &\n\n# Option 3: Run as systemd service (recommended for always-on)\nsudo systemctl enable ollama\nsudo systemctl start ollama\n```\n\n**Stop Ollama:**\n```bash\n# For Option 1: Press Ctrl+C in the terminal\n\n# For Option 2: Kill background process\npkill ollama\n# or find and kill specific PID\npgrep ollama && kill $(pgrep ollama)\n\n# For Option 3: Stop systemd service\nsudo systemctl stop ollama\n# To disable auto-start on boot\nsudo systemctl disable ollama\n\n# Verify no ollama processes remain\npgrep -a ollama\n```\n\n### 2. Create Virtual Environment\n\n```bash\ncd /home/harieshvarshan/ti/SWATI/vrshn-marketplace/ldoc-mcp-server\n\npython -m venv venv\nsource venv/bin/activate\n\npip install -r requirements.txt\n```\n\n### 3. Index Your Documents\n\n```bash\n# Index all supported documents in a folder\npython index.py ./docs\n\n# Index specific files\npython index.py report.pdf data.xlsx presentation.pptx\n\n# Index specific file types only\npython index.py ./docs --ext pdf docx xlsx\n\n# Force re-index\npython index.py --force updated_doc.pdf\npython index.py --force ./docs\n\n# Faster indexing with parallelism (see Performance section below)\npython index.py ./docs -w 16              # 16 embedding workers\npython index.py ./docs -p 4               # 4 documents in parallel\npython index.py ./docs -p 4 -w 8          # Combined: 4 docs × 8 workers\n\n# Batched embedding (more efficient for large document sets)\npython index.py ./docs --batch            # Batch mode: embed every 5000 chunks\npython index.py ./docs -b -B 10000        # Custom batch size of 10000 chunks\n```\n\n### 4. Configure Claude Code\n\n```bash\nclaude mcp add --transport stdio --scope user ldoc-search \\\n  --env CHROMA_DB_PATH=/home/harieshvarshan/ti/SWATI/vrshn-marketplace/ldoc-mcp-server/chroma_db \\\n  --env PYTHONPATH=/home/harieshvarshan/ti/SWATI/vrshn-marketplace/ldoc-mcp-server \\\n  -- /home/harieshvarshan/ti/SWATI/vrshn-marketplace/ldoc-mcp-server/venv/bin/python \\\n  /home/harieshvarshan/ti/SWATI/vrshn-marketplace/ldoc-mcp-server/mcp_server.py\n```\n\n### 5. Verify & Restart Claude Code\n\n```bash\n# Verify MCP server is registered\nclaude mcp list\n\n# Restart Claude Code and check /mcp\n/exit\nclaude\n/mcp\n```\n\n> For detailed setup instructions, troubleshooting, and what happens after reboot, see [local_mcp_server_claude_integration_guide.md](local_mcp_server_claude_integration_guide.md)\n>\n> To understand the vector embedding system behind the scenes, see [behind_the_scenes.md](behind_the_scenes.md)\n\n## Usage\n\n### CLI Tools\n\n```bash\n# Index files or directories (unified interface)\npython index.py ./docs                        # Index all documents in folder\npython index.py file1.pdf file2.docx          # Index specific files\npython index.py ./docs --ext pdf docx         # Index only specific formats\npython index.py --force updated_doc.pdf       # Force re-index a file\npython index.py --force ./docs                # Force re-index entire folder\n\n# Manage index\npython manage_index.py list              # List all documents\npython manage_index.py stats             # Show statistics\npython manage_index.py search \"query\"    # Search from CLI\npython manage_index.py remove doc.pdf    # Remove a document\npython manage_index.py rename old.pdf new.pdf  # Rename (no re-embedding)\npython manage_index.py clear             # Clear entire index\n\n# Test document extraction\npython document_extractor.py myfile.docx\n```\n\n### In Claude CLI\n\nOnce configured, ask Claude:\n- \"Search the documents for DMA configuration\"\n- \"What do my documents say about clock topology?\"\n- \"List all indexed documents\"\n- \"Search for budget data in the spreadsheets\"\n\n## Do I Need to Restart Claude Code?\n\n**No restart needed** after indexing new documents. The MCP server queries ChromaDB dynamically on each search request.\n\n| Action | Restart Required? |\n|--------|-------------------|\n| Add new documents | No |\n| Update existing documents (re-index) | No |\n| Remove documents | No |\n| Rename documents | No |\n| Change MCP server config | **Yes** |\n| Change MCP server code | **Yes** |\n\nNew/updated documents are searchable immediately after indexing:\n```bash\npython index.py new_report.docx\n# Immediately searchable - no restart needed\n```\n\n## Index Limits & Maintenance\n\nThere's **no hard limit** on documents, but consider these factors:\n\n| Factor | Consideration |\n|--------|---------------|\n| ChromaDB capacity | Can handle millions of chunks |\n| Disk space | `chroma_db/` folder grows with each document |\n| Embedding speed | ~2-5 seconds per chunk during indexing |\n| Query speed | Stays fast (efficient vector indexing) |\n\n### Check Current Usage\n\n```bash\n# See index statistics\npython manage_index.py stats\n\n# Check database size on disk\ndu -sh chroma_db/\n```\n\n### Maintenance Tips\n\n```bash\n# Remove old/outdated documents\npython manage_index.py remove old_doc.pdf\n\n# Rename a document (no re-embedding needed)\npython manage_index.py rename old_name.pdf new_name.pdf\n\n# Re-index updated files\npython index.py --force updated_doc.docx\n\n# Clear and rebuild entire index (if needed)\npython manage_index.py clear\npython index.py ./docs\n```\n\nFor typical use (hundreds to a few thousand documents), you won't hit any issues.\n\n## Performance & Parallelism\n\nIndexing can be slow for large documents. Use these options to speed it up:\n\n### CLI Options\n\n| Option | Description | Default |\n|--------|-------------|---------|\n| `-w, --workers` | Parallel embedding requests per document | 8 |\n| `-p, --parallel` | Number of documents to process simultaneously | 1 |\n| `-b, --batch` | Enable batched embedding mode (accumulate chunks) | off |\n| `-B, --batch-size` | Number of chunks to accumulate before embedding | 5000 |\n\n### Examples\n\n```bash\n# Default: 8 workers, 1 document at a time\npython index.py ./docs\n\n# More embedding workers (good for single large files)\npython index.py large_doc.pdf -w 16\n\n# Multiple documents in parallel (good for many small files)\npython index.py ./docs -p 4\n\n# Maximum parallelism (4 docs × 8 workers = 32 concurrent requests)\npython index.py ./docs -p 4 -w 8\n\n# Batched embedding (efficient for large document sets)\npython index.py ./docs --batch            # Embed every 5000 chunks\npython index.py ./docs -b -B 10000        # Custom batch size\npython index.py ./docs -b -w 16           # Batch mode with more workers\n\n# Using environment variable\nOLLAMA_WORKERS=16 python index.py ./docs\n```\n\n### Recommendations\n\n| Scenario | Recommended Settings |\n|----------|---------------------|\n| Single large document (>10K chunks) | `-w 16` or higher |\n| Many small documents | `-p 4` with default workers |\n| Mixed documents | `-p 2 -w 8` |\n| Large document sets (100+ files) | `--batch` or `-b -B 10000` |\n| Limited CPU/RAM | `-w 4 -p 1` (reduce parallelism) |\n\n### Performance Comparison\n\n| Setting | Concurrent Ollama Requests | Use Case |\n|---------|---------------------------|----------|\n| Default (`-w 8 -p 1`) | 8 | Balanced |\n| `-w 16` | 16 | Large single file |\n| `-p 4` | 32 (4 × 8) | Many files |\n| `-p 4 -w 4` | 16 | Memory constrained |\n| `--batch` | 8 (batched) | Large document sets |\n| `-b -w 16` | 16 (batched) | Optimal for 100+ files |\n\n**Note:** If Ollama starts timing out or your system becomes unresponsive, reduce the parallelism.\n\n### Batched Embedding Mode\n\nThe `--batch` flag enables a more efficient embedding strategy for large document sets:\n\n- **Without batch mode**: Each document's chunks are embedded immediately after extraction\n- **With batch mode**: Chunks are accumulated across documents and embedded in batches of 5000 (configurable with `-B`)\n\nThis reduces overhead when indexing many documents, as embedding is a costly operation. The batch is automatically flushed at the end of indexing.\n\n## MCP Tools Exposed\n\n| Tool | Description |\n|------|-------------|\n| `search_pdfs` | Semantic search across all indexed documents |\n| `list_indexed_documents` | List all indexed documents with chunk counts |\n| `get_index_stats` | Get index statistics |\n\n## Environment Variables\n\n| Variable | Default | Description |\n|----------|---------|-------------|\n| `CHROMA_DB_PATH` | `./chroma_db` | Vector database directory |\n| `OLLAMA_MODEL` | `nomic-embed-text` | Ollama embedding model |\n| `OLLAMA_WORKERS` | `8` | Parallel embedding requests to Ollama |\n\n## Project Structure\n\n```\nldoc-mcp-server/\n├── index.py              # Unified indexing (files, folders, updates)\n├── document_extractor.py # Multi-format text extraction\n├── chunker.py            # Text chunking\n├── vector_store.py       # ChromaDB + Ollama embeddings\n├── manage_index.py       # Index management (list, search, remove)\n├── mcp_server.py         # MCP server\n├── requirements.txt\n├── chroma_db/            # Vector database (auto-created)\n└── docs/                 # Put documents here\n```\n\n## Troubleshooting\n\n| Issue | Solution |\n|-------|----------|\n| Ollama connection refused | Run `ollama serve` |\n| Model not found | Run `ollama pull nomic-embed-text` |\n| MCP not showing in `/mcp` | Run `claude mcp list` to verify, then restart Claude Code |\n| Import errors | Ensure PYTHONPATH is set in env config |\n| Unsupported format | Check supported formats above |\n| .doc files not extracting | Install `antiword` or `catdoc` for legacy Word support |\n\nSee [local_mcp_server_claude_integration_guide.md](local_mcp_server_claude_integration_guide.md) for detailed troubleshooting.\n\n## Adding New Format Support\n\nTo add support for a new file format:\n\n1. Edit `document_extractor.py`\n2. Add extension to `SUPPORTED_EXTENSIONS` dict\n3. Create `_extract_<format>()` function\n4. Add to `extractors` dict in `extract_text()`\n\n\n## TODOs\n1. ~~since we support multiple file formats instead of pdf-mcp-server can be rename it as ldoc-mcp-server and also update claude mcp as ldoc-mcp so that nothing breaks.~~ ✅ Done\n2. ~~add progress bar and time taken while embedding files. (for each files and also overall)~~ ✅ Done\n3. how to use this standalone without claude?\n4. how to make this the chromadb and mcp-server available to my entire team, I dont want them to know about how to add embeddings, i just want them to use with whatever I have trained and stored in db at any point in time?\n5. I understand where are limitation to how big the db can be? So in large system as it grows how do we scale this?\n6. I have more budget what all can I improve in this project to make it even better or the best?",
        "mcp_excalidraw/README.md": "# Excalidraw MCP Server & Agent Skill\n\n[![CI](https://github.com/yctimlin/mcp_excalidraw/actions/workflows/ci.yml/badge.svg)](https://github.com/yctimlin/mcp_excalidraw/actions/workflows/ci.yml)\n[![Docker Build & Push](https://github.com/yctimlin/mcp_excalidraw/actions/workflows/docker.yml/badge.svg)](https://github.com/yctimlin/mcp_excalidraw/actions/workflows/docker.yml)\n[![NPM Version](https://img.shields.io/npm/v/mcp-excalidraw-server)](https://www.npmjs.com/package/mcp-excalidraw-server)\n[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)\n\nRun a live Excalidraw canvas and control it from AI agents. This repo provides:\n\n- **MCP Server**: Connect via Model Context Protocol (Claude Desktop, Cursor, Codex CLI, etc.)\n- **Agent Skill**: Portable skill for Claude Code, Codex CLI, and other skill-enabled agents\n\nKeywords: Excalidraw agent skill, Excalidraw MCP server, AI diagramming, Claude Code skill, Codex CLI skill, Claude Desktop MCP, Cursor MCP, Mermaid to Excalidraw.\n\n## Demo\n\n![MCP Excalidraw Demo](demo.gif)\n\n*AI agent creates a complete architecture diagram from a single prompt (4x speed). [Watch full video on YouTube](https://youtu.be/ufW78Amq5qA)*\n\n## Table of Contents\n\n- [Demo](#demo)\n- [What It Is](#what-it-is)\n- [How We Differ from the Official Excalidraw MCP](#how-we-differ-from-the-official-excalidraw-mcp)\n- [What's New](#whats-new)\n- [Quick Start (Local)](#quick-start-local)\n- [Quick Start (Docker)](#quick-start-docker)\n- [Configure MCP Clients](#configure-mcp-clients)\n  - [Claude Desktop](#claude-desktop)\n  - [Claude Code](#claude-code)\n  - [Cursor](#cursor)\n  - [Codex CLI](#codex-cli)\n  - [OpenCode](#opencode)\n  - [Antigravity (Google)](#antigravity-google)\n- [Agent Skill (Optional)](#agent-skill-optional)\n- [MCP Tools (26 Total)](#mcp-tools-26-total)\n- [Testing](#testing)\n- [Troubleshooting](#troubleshooting)\n- [Known Issues / TODO](#known-issues--todo)\n- [Development](#development)\n\n## What It Is\n\nThis repo contains two separate processes:\n\n- Canvas server: web UI + REST API + WebSocket updates (default `http://localhost:3000`)\n- MCP server: exposes MCP tools over stdio; syncs to the canvas via `EXPRESS_SERVER_URL`\n\n## How We Differ from the Official Excalidraw MCP\n\nExcalidraw now has an [official MCP](https://github.com/excalidraw/excalidraw-mcp) — it's great for quick, prompt-to-diagram generation rendered inline in chat. We solve a different problem.\n\n| | Official Excalidraw MCP | This Project |\n|---|---|---|\n| **Approach** | Prompt in, diagram out (one-shot) | Programmatic element-level control (26 tools) |\n| **State** | Stateless — each call is independent | Persistent live canvas with real-time sync |\n| **Element CRUD** | No | Full create / read / update / delete per element |\n| **AI sees the canvas** | No | `describe_scene` (structured text) + `get_canvas_screenshot` (image) |\n| **Iterative refinement** | No — regenerate the whole diagram | Draw → look → adjust → look again, element by element |\n| **Layout tools** | No | `align_elements`, `distribute_elements`, `group / ungroup` |\n| **File I/O** | No | `export_scene` / `import_scene` (.excalidraw JSON) |\n| **Snapshot & rollback** | No | `snapshot_scene` / `restore_snapshot` |\n| **Mermaid conversion** | No | `create_from_mermaid` |\n| **Shareable URLs** | Yes | Yes — `export_to_excalidraw_url` |\n| **Design guide** | `read_me` cheat sheet | `read_diagram_guide` (colors, sizing, layout, anti-patterns) |\n| **Viewport control** | Camera animations | `set_viewport` (zoom-to-fit, center on element, manual zoom) |\n| **Live canvas UI** | Rendered inline in chat | Standalone Excalidraw app synced via WebSocket |\n| **Multi-agent** | Single user | Multiple agents can draw on the same canvas concurrently |\n| **Works without MCP** | No | Yes — REST API fallback via agent skill |\n\n**TL;DR** — The official MCP generates diagrams. We give AI agents a full canvas toolkit to build, inspect, and iteratively refine diagrams — including the ability to see what they drew.\n\n## What's New\n\n### v2.0 — Canvas Toolkit\n\n- 13 new MCP tools (26 total): `get_element`, `clear_canvas`, `export_scene`, `import_scene`, `export_to_image`, `duplicate_elements`, `snapshot_scene`, `restore_snapshot`, `describe_scene`, `get_canvas_screenshot`, `read_diagram_guide`, `export_to_excalidraw_url`, `set_viewport`\n- **Closed feedback loop**: AI can now inspect the canvas (`describe_scene`) and see it (`get_canvas_screenshot` returns an image) — enabling iterative refinement\n- **Design guide**: `read_diagram_guide` returns best-practice color palettes, sizing rules, layout patterns, and anti-patterns — dramatically improves AI-generated diagram quality\n- **Shareable URLs**: `export_to_excalidraw_url` encrypts and uploads the scene to excalidraw.com, returns a shareable link anyone can open\n- **Viewport control**: `set_viewport` with `scrollToContent`, `scrollToElementId`, or manual zoom/offset — agents can auto-fit diagrams after creation\n- **File I/O**: export/import full `.excalidraw` JSON files\n- **Snapshots**: save and restore named canvas states\n- **Skill fallback**: Agent skill auto-detects MCP vs REST API mode, gracefully falls back to HTTP endpoints when MCP server isn't configured\n- Fixed all previously known issues: `align_elements` / `distribute_elements` fully implemented, points type normalization, removed invalid `label` type, removed HTTP transport dead code, `ungroup_elements` now errors on failure\n\n### v1.x\n\n- Agent skill: `skills/excalidraw-skill/` (portable instructions + helper scripts for export/import and repeatable CRUD)\n- Better testing loop: MCP Inspector CLI examples + browser screenshot checks (`agent-browser`)\n- Bugfixes: batch create now preserves element ids (fixes update/delete after batch); frontend entrypoint fixed (`main.tsx`)\n\n## Quick Start (Local)\n\nPrereqs: Node >= 18, npm\n\n```bash\nnpm ci\nnpm run build\n```\n\nTerminal 1: start the canvas\n```bash\nHOST=0.0.0.0 PORT=3000 npm run canvas\n```\n\nOpen `http://localhost:3000`.\n\nTerminal 2: run the MCP server (stdio)\n```bash\nEXPRESS_SERVER_URL=http://localhost:3000 node dist/index.js\n```\n\n## Quick Start (Docker)\n\nCanvas server:\n```bash\ndocker run -d -p 3000:3000 --name mcp-excalidraw-canvas ghcr.io/yctimlin/mcp_excalidraw-canvas:latest\n```\n\nMCP server (stdio) is typically launched by your MCP client (Claude Desktop/Cursor/etc.). If you want a local container for it, use the image `ghcr.io/yctimlin/mcp_excalidraw:latest` and set `EXPRESS_SERVER_URL` to point at the canvas.\n\n## Configure MCP Clients\n\nThe MCP server runs over stdio and can be configured with any MCP-compatible client. Below are configurations for both **local** (requires cloning and building) and **Docker** (pull-and-run) setups.\n\n### Environment Variables\n\n| Variable | Description | Default |\n|----------|-------------|---------|\n| `EXPRESS_SERVER_URL` | URL of the canvas server | `http://localhost:3000` |\n| `ENABLE_CANVAS_SYNC` | Enable real-time canvas sync | `true` |\n\n---\n\n### Claude Desktop\n\nConfig location:\n- macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n- Windows: `%APPDATA%\\Claude\\claude_desktop_config.json`\n- Linux: `~/.config/Claude/claude_desktop_config.json`\n\n**Local (node)**\n```json\n{\n  \"mcpServers\": {\n    \"excalidraw\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/mcp_excalidraw/dist/index.js\"],\n      \"env\": {\n        \"EXPRESS_SERVER_URL\": \"http://localhost:3000\",\n        \"ENABLE_CANVAS_SYNC\": \"true\"\n      }\n    }\n  }\n}\n```\n\n**Docker**\n```json\n{\n  \"mcpServers\": {\n    \"excalidraw\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\", \"-i\", \"--rm\",\n        \"-e\", \"EXPRESS_SERVER_URL=http://host.docker.internal:3000\",\n        \"-e\", \"ENABLE_CANVAS_SYNC=true\",\n        \"ghcr.io/yctimlin/mcp_excalidraw:latest\"\n      ]\n    }\n  }\n}\n```\n\n---\n\n### Claude Code\n\nUse the `claude mcp add` command to register the MCP server.\n\n**Local (node)** - User-level (available across all projects):\n```bash\nclaude mcp add excalidraw --scope user \\\n  -e EXPRESS_SERVER_URL=http://localhost:3000 \\\n  -e ENABLE_CANVAS_SYNC=true \\\n  -- node /absolute/path/to/mcp_excalidraw/dist/index.js\n```\n\n**Local (node)** - Project-level (shared via `.mcp.json`):\n```bash\nclaude mcp add excalidraw --scope project \\\n  -e EXPRESS_SERVER_URL=http://localhost:3000 \\\n  -e ENABLE_CANVAS_SYNC=true \\\n  -- node /absolute/path/to/mcp_excalidraw/dist/index.js\n```\n\n**Docker**\n```bash\nclaude mcp add excalidraw --scope user \\\n  -- docker run -i --rm \\\n  -e EXPRESS_SERVER_URL=http://host.docker.internal:3000 \\\n  -e ENABLE_CANVAS_SYNC=true \\\n  ghcr.io/yctimlin/mcp_excalidraw:latest\n```\n\n**Manage servers:**\n```bash\nclaude mcp list              # List configured servers\nclaude mcp remove excalidraw # Remove a server\n```\n\n---\n\n### Cursor\n\nConfig location: `.cursor/mcp.json` in your project root (or `~/.cursor/mcp.json` for global config)\n\n**Local (node)**\n```json\n{\n  \"mcpServers\": {\n    \"excalidraw\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/mcp_excalidraw/dist/index.js\"],\n      \"env\": {\n        \"EXPRESS_SERVER_URL\": \"http://localhost:3000\",\n        \"ENABLE_CANVAS_SYNC\": \"true\"\n      }\n    }\n  }\n}\n```\n\n**Docker**\n```json\n{\n  \"mcpServers\": {\n    \"excalidraw\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\", \"-i\", \"--rm\",\n        \"-e\", \"EXPRESS_SERVER_URL=http://host.docker.internal:3000\",\n        \"-e\", \"ENABLE_CANVAS_SYNC=true\",\n        \"ghcr.io/yctimlin/mcp_excalidraw:latest\"\n      ]\n    }\n  }\n}\n```\n\n---\n\n### Codex CLI\n\nUse the `codex mcp add` command to register the MCP server.\n\n**Local (node)**\n```bash\ncodex mcp add excalidraw \\\n  --env EXPRESS_SERVER_URL=http://localhost:3000 \\\n  --env ENABLE_CANVAS_SYNC=true \\\n  -- node /absolute/path/to/mcp_excalidraw/dist/index.js\n```\n\n**Docker**\n```bash\ncodex mcp add excalidraw \\\n  -- docker run -i --rm \\\n  -e EXPRESS_SERVER_URL=http://host.docker.internal:3000 \\\n  -e ENABLE_CANVAS_SYNC=true \\\n  ghcr.io/yctimlin/mcp_excalidraw:latest\n```\n\n**Manage servers:**\n```bash\ncodex mcp list              # List configured servers\ncodex mcp remove excalidraw # Remove a server\n```\n\n---\n\n### OpenCode\n\nConfig location: `~/.config/opencode/opencode.json` or project-level `opencode.json`\n\n**Local (node)**\n```json\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"mcp\": {\n    \"excalidraw\": {\n      \"type\": \"local\",\n      \"command\": [\"node\", \"/absolute/path/to/mcp_excalidraw/dist/index.js\"],\n      \"enabled\": true,\n      \"environment\": {\n        \"EXPRESS_SERVER_URL\": \"http://localhost:3000\",\n        \"ENABLE_CANVAS_SYNC\": \"true\"\n      }\n    }\n  }\n}\n```\n\n**Docker**\n```json\n{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"mcp\": {\n    \"excalidraw\": {\n      \"type\": \"local\",\n      \"command\": [\"docker\", \"run\", \"-i\", \"--rm\", \"-e\", \"EXPRESS_SERVER_URL=http://host.docker.internal:3000\", \"-e\", \"ENABLE_CANVAS_SYNC=true\", \"ghcr.io/yctimlin/mcp_excalidraw:latest\"],\n      \"enabled\": true\n    }\n  }\n}\n```\n\n---\n\n### Antigravity (Google)\n\nConfig location: `~/.gemini/antigravity/mcp_config.json`\n\n**Local (node)**\n```json\n{\n  \"mcpServers\": {\n    \"excalidraw\": {\n      \"command\": \"node\",\n      \"args\": [\"/absolute/path/to/mcp_excalidraw/dist/index.js\"],\n      \"env\": {\n        \"EXPRESS_SERVER_URL\": \"http://localhost:3000\",\n        \"ENABLE_CANVAS_SYNC\": \"true\"\n      }\n    }\n  }\n}\n```\n\n**Docker**\n```json\n{\n  \"mcpServers\": {\n    \"excalidraw\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\", \"-i\", \"--rm\",\n        \"-e\", \"EXPRESS_SERVER_URL=http://host.docker.internal:3000\",\n        \"-e\", \"ENABLE_CANVAS_SYNC=true\",\n        \"ghcr.io/yctimlin/mcp_excalidraw:latest\"\n      ]\n    }\n  }\n}\n```\n\n---\n\n### Notes\n\n- **Docker networking**: Use `host.docker.internal` to reach the canvas server running on your host machine. On Linux, you may need `--add-host=host.docker.internal:host-gateway` or use `172.17.0.1`.\n- **Canvas server**: Must be running before the MCP server connects. Start it with `npm run canvas` (local) or `docker run -d -p 3000:3000 ghcr.io/yctimlin/mcp_excalidraw-canvas:latest` (Docker).\n- **Absolute paths**: When using local node setup, replace `/absolute/path/to/mcp_excalidraw` with the actual path where you cloned and built the repo.\n- **In-memory storage**: The canvas server stores elements in memory. Restarting the server will clear all elements. Use the export/import scripts if you need persistence.\n\n## Agent Skill (Optional)\n\nThis repo includes a skill at `skills/excalidraw-skill/` that provides:\n\n- **Workflow playbook** (`SKILL.md`): step-by-step guidance for drawing, refining, and exporting diagrams\n- **Cheatsheet** (`references/cheatsheet.md`): MCP tool and REST API reference\n- **Helper scripts** (`scripts/*.cjs`): export, import, clear, healthcheck, CRUD operations\n\nThe skill complements the MCP server by giving your AI agent structured workflows to follow.\n\n### Install The Skill (Codex CLI example)\n\n```bash\nmkdir -p ~/.codex/skills\ncp -R skills/excalidraw-skill ~/.codex/skills/excalidraw-skill\n```\n\nTo update an existing installation, remove the old folder first (`rm -rf ~/.codex/skills/excalidraw-skill`) then re-copy.\n\n### Install The Skill (Claude Code)\n\n**User-level** (available across all your projects):\n```bash\nmkdir -p ~/.claude/skills\ncp -R skills/excalidraw-skill ~/.claude/skills/excalidraw-skill\n```\n\n**Project-level** (scoped to a specific project, can be committed to the repo):\n```bash\nmkdir -p /path/to/your/project/.claude/skills\ncp -R skills/excalidraw-skill /path/to/your/project/.claude/skills/excalidraw-skill\n```\n\nThen invoke the skill in Claude Code with `/excalidraw-skill`.\n\nTo update an existing installation, remove the old folder first then re-copy.\n\n### Use The Skill Scripts\n\nAll scripts respect `EXPRESS_SERVER_URL` (default `http://localhost:3000`) or accept `--url`.\n\n```bash\nEXPRESS_SERVER_URL=http://127.0.0.1:3000 node skills/excalidraw-skill/scripts/healthcheck.cjs\nEXPRESS_SERVER_URL=http://127.0.0.1:3000 node skills/excalidraw-skill/scripts/export-elements.cjs --out diagram.elements.json\nEXPRESS_SERVER_URL=http://127.0.0.1:3000 node skills/excalidraw-skill/scripts/import-elements.cjs --in diagram.elements.json --mode batch\n```\n\n### When The Skill Is Useful\n\n- Repository workflow: export elements as JSON, commit it, and re-import later.\n- Reliable refactors: clear + re-import in `sync` mode to make canvas match a file.\n- Automated smoke tests: create/update/delete a known element to validate a deployment.\n- Repeatable diagrams: keep a library of element JSON snippets and import them.\n\nSee `skills/excalidraw-skill/SKILL.md` and `skills/excalidraw-skill/references/cheatsheet.md`.\n\n## MCP Tools (26 Total)\n\n| Category | Tools |\n|---|---|\n| **Element CRUD** | `create_element`, `get_element`, `update_element`, `delete_element`, `query_elements`, `batch_create_elements`, `duplicate_elements` |\n| **Layout** | `align_elements`, `distribute_elements`, `group_elements`, `ungroup_elements`, `lock_elements`, `unlock_elements` |\n| **Scene Awareness** | `describe_scene`, `get_canvas_screenshot` |\n| **File I/O** | `export_scene`, `import_scene`, `export_to_image`, `export_to_excalidraw_url`, `create_from_mermaid` |\n| **State Management** | `clear_canvas`, `snapshot_scene`, `restore_snapshot` |\n| **Viewport** | `set_viewport` |\n| **Design Guide** | `read_diagram_guide` |\n| **Resources** | `get_resource` |\n\nFull schemas are discoverable via `tools/list` or in `skills/excalidraw-skill/references/cheatsheet.md`.\n\n## Testing\n\n### Canvas Smoke Test (HTTP)\n\n```bash\ncurl http://localhost:3000/health\n```\n\n### MCP Smoke Test (MCP Inspector)\n\nList tools:\n```bash\nnpx @modelcontextprotocol/inspector --cli \\\n  -e EXPRESS_SERVER_URL=http://localhost:3000 \\\n  -e ENABLE_CANVAS_SYNC=true -- \\\n  node dist/index.js --method tools/list\n```\n\nCreate a rectangle:\n```bash\nnpx @modelcontextprotocol/inspector --cli \\\n  -e EXPRESS_SERVER_URL=http://localhost:3000 \\\n  -e ENABLE_CANVAS_SYNC=true -- \\\n  node dist/index.js --method tools/call --tool-name create_element \\\n  --tool-arg type=rectangle --tool-arg x=100 --tool-arg y=100 \\\n  --tool-arg width=300 --tool-arg height=200\n```\n\n### Frontend Screenshots (agent-browser)\n\nIf you use `agent-browser` for UI checks:\n```bash\nagent-browser install\nagent-browser open http://127.0.0.1:3000\nagent-browser wait --load networkidle\nagent-browser screenshot /tmp/canvas.png\n```\n\n## Troubleshooting\n\n- Canvas not updating: confirm `EXPRESS_SERVER_URL` points at the running canvas server.\n- Updates/deletes fail after batch creation: ensure you are on a build that includes the batch id preservation fix (merged via PR #34).\n\n## Known Issues / TODO\n\nAll previously listed bugs have been fixed in v2.0. Remaining items:\n\n- [ ] **Persistent storage**: Elements are stored in-memory — restarting the server clears everything. Use `export_scene` / snapshots as a workaround.\n- [ ] **Image export requires a browser**: `export_to_image` and `get_canvas_screenshot` rely on the frontend doing the actual rendering. The canvas UI must be open in a browser.\n\nContributions welcome!\n\n## Development\n\n```bash\nnpm run type-check\nnpm run build\n```\n"
      },
      "plugins": [
        {
          "name": "atlassian-mcp",
          "description": "MCP server for Jira, Confluence, and Bitbucket integration - search, read, create, and manage issues, pages, and pull requests",
          "source": "./atlassian-mcp",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add HarieshVarshan/Vrshn-Claude-Marketplace",
            "/plugin install atlassian-mcp@vrshn-claude-marketplace"
          ]
        },
        {
          "name": "talk2docs",
          "description": "Local document semantic search - index and search PDF, DOCX, XLSX, PPTX, and more using ChromaDB and Ollama embeddings",
          "source": "./talk2docs",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add HarieshVarshan/Vrshn-Claude-Marketplace",
            "/plugin install talk2docs@vrshn-claude-marketplace"
          ]
        },
        {
          "name": "klocwork-mcp",
          "description": "MCP server for Klocwork project management - list projects, search issues, manage modules and permissions",
          "source": "./klocwork-mcp",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add HarieshVarshan/Vrshn-Claude-Marketplace",
            "/plugin install klocwork-mcp@vrshn-claude-marketplace"
          ]
        },
        {
          "name": "bitbucket-mcp",
          "description": "MCP server for Bitbucket Server/Data Center - manage PRs, repos, branches, and permissions",
          "source": "./bitbucket-mcp",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add HarieshVarshan/Vrshn-Claude-Marketplace",
            "/plugin install bitbucket-mcp@vrshn-claude-marketplace"
          ]
        },
        {
          "name": "confluence-mcp",
          "description": "MCP server for Confluence Data Center - manage pages, spaces, attachments, and search",
          "source": "./confluence-mcp",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add HarieshVarshan/Vrshn-Claude-Marketplace",
            "/plugin install confluence-mcp@vrshn-claude-marketplace"
          ]
        },
        {
          "name": "jenkins-mcp",
          "description": "MCP server for Jenkins CI/CD - manage jobs, builds, nodes, and artifacts",
          "source": "./jenkins-mcp",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add HarieshVarshan/Vrshn-Claude-Marketplace",
            "/plugin install jenkins-mcp@vrshn-claude-marketplace"
          ]
        },
        {
          "name": "jira-mcp",
          "description": "MCP server for Jira Data Center - manage issues, projects, sprints, and workflows",
          "source": "./jira-mcp",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add HarieshVarshan/Vrshn-Claude-Marketplace",
            "/plugin install jira-mcp@vrshn-claude-marketplace"
          ]
        },
        {
          "name": "mcp-excalidraw",
          "description": "MCP server for Excalidraw - create, edit, and manage diagrams with a live canvas, element CRUD, layout, scene awareness, and file I/O",
          "source": "./mcp_excalidraw",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add HarieshVarshan/Vrshn-Claude-Marketplace",
            "/plugin install mcp-excalidraw@vrshn-claude-marketplace"
          ]
        }
      ]
    }
  ]
}