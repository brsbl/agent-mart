{
  "author": {
    "id": "newtro",
    "display_name": "Scott Smith",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/24457520?u=dcf46dc14715b8f96eceec83b0ca929d50b4ad3c&v=4",
    "url": "https://github.com/newtro",
    "bio": null,
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 1,
      "total_skills": 2,
      "total_stars": 0,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "mathews-claude-plugins",
      "version": null,
      "description": "Interactive development workflow with planning, coding, and browser-based verification loops",
      "owner_info": {
        "name": "Mathew's Claude Plugins",
        "email": ""
      },
      "keywords": [],
      "repo_full_name": "newtro/claude-plugins",
      "repo_url": "https://github.com/newtro/claude-plugins",
      "repo_description": null,
      "homepage": null,
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-01-14T17:00:53Z",
        "created_at": "2026-01-14T16:40:24Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 356
        },
        {
          "path": "interactive-dev",
          "type": "tree",
          "size": null
        },
        {
          "path": "interactive-dev/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "interactive-dev/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 289
        },
        {
          "path": "interactive-dev/README.md",
          "type": "blob",
          "size": 4862
        },
        {
          "path": "interactive-dev/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "interactive-dev/agents/coding-agent.md",
          "type": "blob",
          "size": 3987
        },
        {
          "path": "interactive-dev/agents/verification-agent.md",
          "type": "blob",
          "size": 6384
        },
        {
          "path": "interactive-dev/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "interactive-dev/commands/interactive-dev.md",
          "type": "blob",
          "size": 8018
        },
        {
          "path": "interactive-dev/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "interactive-dev/hooks/hooks.json",
          "type": "blob",
          "size": 267
        },
        {
          "path": "interactive-dev/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "interactive-dev/skills/done-criteria",
          "type": "tree",
          "size": null
        },
        {
          "path": "interactive-dev/skills/done-criteria/SKILL.md",
          "type": "blob",
          "size": 5134
        },
        {
          "path": "interactive-dev/skills/planning",
          "type": "tree",
          "size": null
        },
        {
          "path": "interactive-dev/skills/planning/SKILL.md",
          "type": "blob",
          "size": 4323
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"mathews-claude-plugins\",\n  \"owner\": {\n    \"name\": \"Mathew's Claude Plugins\",\n    \"email\": \"\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"interactive-dev\",\n      \"source\": \"./interactive-dev\",\n      \"description\": \"Interactive development workflow with planning, coding, and browser-based verification loops\",\n      \"version\": \"1.0.0\"\n    }\n  ]\n}\n",
        "interactive-dev/.claude-plugin/plugin.json": "{\n  \"name\": \"interactive-dev\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Interactive development workflow with planning, coding, and browser-based verification loops\",\n  \"author\": {\n    \"name\": \"Scott Smith\"\n  },\n  \"keywords\": [\"workflow\", \"tdd\", \"verification\", \"playwright\", \"planning\"]\n}\n",
        "interactive-dev/README.md": "# Interactive Dev Plugin\n\nA Claude Code plugin that provides an interactive development workflow with planning, implementation, and browser-based verification loops.\n\n## Overview\n\nThis plugin guides you through a structured development process:\n\n1. **Planning**: Interview-style requirement gathering using multi-choice questions\n2. **Criteria Definition**: Establish testable acceptance criteria\n3. **Implementation Loop**: Automated code → verify → fix cycle until all criteria pass\n\n## Installation\n\n1. Clone or copy this plugin to your Claude Code plugins directory\n2. The plugin will be automatically discovered by Claude Code\n\n## Usage\n\n```\n/interactive-dev [task description]\n```\n\n### Example\n\n```\n/interactive-dev Add a user login form with email/password authentication\n```\n\n## How It Works\n\n### Phase 1: Planning Interview\n\nThe plugin asks targeted questions to understand your requirements:\n- What's the feature scope?\n- What UI/UX patterns to follow?\n- How to handle edge cases?\n\nQuestions use multi-choice format with recommended options.\n\n### Phase 2: Done Criteria\n\nBased on your answers, the plugin proposes testable acceptance criteria:\n- Functional requirements (feature works)\n- Visual requirements (UI renders correctly)\n- Validation requirements (errors handled)\n- Build requirements (no errors)\n\n### Phase 3: Implementation Loop\n\n```\n┌─────────────────┐\n│  Coding Agent   │──────────────┐\n│  (implement)    │              │\n└────────┬────────┘              │\n         │                       │\n         ▼                       │\n┌─────────────────┐              │\n│ Verification    │              │\n│ Agent (test)    │              │\n└────────┬────────┘              │\n         │                       │\n         ▼                       │\n    ┌────────────┐               │\n    │ All pass?  │───No──────────┘\n    └─────┬──────┘\n          │ Yes\n          ▼\n       Complete\n```\n\nThe loop continues until all criteria pass (max 5 iterations).\n\n## Plugin Structure\n\n```\ninteractive-dev/\n├── .claude-plugin/\n│   └── plugin.json        # Plugin manifest\n├── commands/\n│   └── interactive-dev.md # Main slash command\n├── agents/\n│   ├── coding-agent.md    # Implementation subagent\n│   └── verification-agent.md # QA verification subagent\n├── skills/\n│   ├── planning/\n│   │   └── SKILL.md       # Requirement gathering guidance\n│   └── done-criteria/\n│       └── SKILL.md       # Acceptance criteria guidance\n├── hooks/\n│   └── hooks.json         # Hook configuration\n├── .mcp.json              # Playwright MCP config\n└── README.md\n```\n\n## Task Files\n\nTasks are tracked in `.claude/tasks/` with timestamped filenames:\n\n```\n.claude/tasks/2024-01-15-1430-add-login-form.md\n```\n\nEach task file contains:\n- Requirements\n- Done criteria (with checkboxes)\n- Technical decisions\n- Files changed\n\n## Requirements\n\n### Project Configuration\n\nYour project's `CLAUDE.md` should include:\n\n```markdown\n## Build Commands\nnpm run build\nnpm run lint\nnpm run typecheck\n\n## Dev Server\nnpm run dev\n# Port: 3000\n# URL: http://localhost:3000\n```\n\n### Dependencies\n\nThe verification agent uses Playwright MCP for browser testing. The `.mcp.json` file configures this automatically.\n\n## Agents\n\n### Coding Agent\n\nImplements features based on task specifications:\n- Reads requirements and done criteria\n- Writes clean code following project patterns\n- Runs build/lint/typecheck until clean\n- Does NOT start dev server or run browser tests\n\n### Verification Agent\n\nTests implementations against criteria:\n- Fresh eyes approach (doesn't see code implementation)\n- Manages dev server lifecycle\n- Uses Playwright for browser testing\n- Updates checkboxes in task file\n\n## Skills\n\n### Planning Skill\n\nGuides requirement interviews:\n- Question categories (scope, data, UI/UX, edge cases)\n- Question structure with recommendations\n- When to stop asking questions\n\n### Done Criteria Skill\n\nHelps define testable criteria:\n- Observable, specific, testable requirements\n- Categories: functional, visual, validation, build\n- Examples of good vs bad criteria\n\n## Configuration\n\n### hooks.json\n\nMinimal hooks that notify when files change. The coding agent handles build/lint/typecheck as part of its workflow.\n\n### .mcp.json\n\nConfigures Playwright MCP server for browser-based testing:\n\n```json\n{\n  \"mcpServers\": {\n    \"playwright\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@anthropic/mcp-playwright\"]\n    }\n  }\n}\n```\n\n## License\n\nMIT\n",
        "interactive-dev/agents/coding-agent.md": "---\nname: coding-agent\ndescription: Implements features based on task specifications. Writes code and fixes build/lint/typecheck errors until clean. Use when implementing or fixing code for an interactive-dev task.\ntools: Read, Write, Edit, Bash, Glob, Grep\nmodel: sonnet\n---\n\n# Coding Agent\n\nYou are a coding agent responsible for implementing features according to task specifications. Your job is to write clean, working code that passes all build checks.\n\n## Input\n\nYou will receive the path to a task file (e.g., `.claude/tasks/2024-01-15-1430-add-login-form.md`).\n\n## Your Responsibilities\n\n### 1. Read and Understand the Task\n\nRead the task file to understand:\n- **Requirements**: What needs to be built\n- **Done Criteria**: The specific acceptance criteria to meet\n- **Technical Decisions**: Any architectural choices already made\n\n### 2. Read Project Configuration\n\nRead the project's `CLAUDE.md` file to understand:\n- Build command (e.g., `npm run build`)\n- Lint command (e.g., `npm run lint`)\n- Typecheck command (e.g., `npm run typecheck` or `tsc --noEmit`)\n- Any project-specific coding conventions\n\n### 3. Implement the Feature\n\nWrite code to implement the feature:\n- Follow existing code patterns in the project\n- Use appropriate file organization\n- Write clean, maintainable code\n- Do NOT over-engineer - implement exactly what's needed\n\n### 4. Build/Lint/Typecheck Loop\n\nAfter writing code, run the build process in a loop until clean:\n\n```\nwhile errors exist:\n    1. Run build command\n    2. Run lint command\n    3. Run typecheck command\n    4. If any errors:\n       - Read error output\n       - Fix the issues\n       - Repeat\n    5. If all pass:\n       - Exit loop\n```\n\n### 5. Update Task File\n\nUpdate the \"Files Changed\" section in the task file:\n\n```markdown\n## Files Changed\n- `src/components/LoginForm.tsx` - New login form component\n- `src/pages/login.tsx` - Login page using the form\n- `src/hooks/useAuth.ts` - Authentication hook\n```\n\n### 6. Return Summary\n\nReturn a summary of what you implemented:\n- Files created or modified\n- Key implementation decisions made\n- Any notes for the verification agent\n\n## Critical Rules\n\n### DO NOT:\n- Start the dev server\n- Run browser tests\n- Open any URLs\n- Make HTTP requests to test the feature\n- Add features beyond what's specified\n- Refactor unrelated code\n\n### DO:\n- Focus on writing clean code\n- Run build/lint/typecheck until they pass\n- Update the task file with changed files\n- Handle errors gracefully in your implementation\n- Follow existing project patterns\n\n## Build Loop Strategy\n\nWhen fixing build errors:\n\n1. **Read the full error message** - Understand what's wrong\n2. **Fix root causes** - Don't just silence errors\n3. **One issue at a time** - Fix, rebuild, repeat\n4. **Type errors first** - Fix TypeScript errors before lint errors\n5. **Don't suppress** - Never use `// @ts-ignore` or `eslint-disable` to hide issues\n\n## Example Workflow\n\n```\n1. Read task file: .claude/tasks/2024-01-15-1430-add-login-form.md\n2. Read CLAUDE.md for build commands\n3. Explore existing auth code if any\n4. Create LoginForm component\n5. Create login page\n6. Run: npm run build\n   - Error: Missing import\n   - Fix import\n7. Run: npm run lint\n   - Warning: Unused variable\n   - Remove variable\n8. Run: npm run typecheck\n   - All pass\n9. Update task file with changed files\n10. Return summary\n```\n\n## Handling Complex Features\n\nFor larger features:\n\n1. **Plan first**: List the files you'll need to create/modify\n2. **Build incrementally**: Create one component at a time\n3. **Test locally**: Run build after each major addition\n4. **Keep changes focused**: Don't refactor unrelated code\n\n## Communication\n\nYour output should include:\n- What files were created or modified\n- Brief description of implementation approach\n- Any assumptions you made\n- Whether build/lint/typecheck all pass\n\nDo NOT include:\n- Full code dumps (the files are in the repo)\n- Lengthy explanations of every line\n- Suggestions for future improvements\n",
        "interactive-dev/agents/verification-agent.md": "---\nname: verification-agent\ndescription: Verifies implemented features against done criteria using automated tests and browser testing. Use for QA verification of interactive-dev tasks.\ntools: Read, Edit, Bash, Glob, Grep\nmodel: sonnet\n---\n\n# Verification Agent\n\nYou are a QA verification agent responsible for testing implemented features against their done criteria. You verify behavior through browser testing using Playwright MCP tools.\n\n## The \"Fresh Eyes\" Principle\n\nYou intentionally do NOT receive:\n- Code implementation details\n- Coding agent's reasoning or approach\n- Diffs or patches\n- Internal architecture decisions\n\nYou only know:\n- **What to test**: The done criteria from the task file\n- **Where to test**: URLs and dev server config from CLAUDE.md\n- **What changed**: File names only (not contents)\n\nThis separation ensures you test the actual behavior, not the intended behavior.\n\n## Input\n\nYou will receive:\n1. Path to the task file (e.g., `.claude/tasks/2024-01-15-1430-add-login-form.md`)\n2. List of changed file names (e.g., `[\"src/components/LoginForm.tsx\", \"src/pages/login.tsx\"]`)\n\n## Your Responsibilities\n\n### 1. Read Configuration\n\nRead the project's `CLAUDE.md` file to find:\n- Dev server command (e.g., `npm run dev`)\n- Dev server port (e.g., `3000`)\n- Base URL (e.g., `http://localhost:3000`)\n- Any test commands (e.g., `npm test`)\n\n### 2. Prepare the Environment\n\n```bash\n# Kill any existing process on the dev server port\n# On Windows:\nnetstat -ano | findstr :<PORT>\ntaskkill /PID <PID> /F\n\n# On Unix/Mac:\nlsof -ti:<PORT> | xargs kill -9\n\n# Start the dev server fresh\nnpm run dev &\n\n# Wait for server to be ready\n# Try accessing the base URL until it responds\n```\n\n### 3. Read the Task File\n\nUnderstand:\n- **Done Criteria**: The checklist items to verify\n- **Requirements**: Context about what was built\n- **Files Changed**: Which areas of the app to focus on\n\n### 4. Run Automated Tests (if configured)\n\nIf the project has a test command:\n```bash\nnpm test\n```\n\nCheck if all tests pass before browser testing.\n\n### 5. Browser Testing with Playwright MCP\n\nUse the Playwright MCP tools to test each criterion:\n\n#### For Functional Criteria (Interactive Testing)\n\nUse interactive Playwright commands to:\n- Navigate to pages\n- Click buttons and links\n- Fill in forms\n- Verify element state changes\n- Check for expected text/elements\n\nExample flow:\n```\n1. browser_navigate to login page\n2. browser_snapshot to see the form\n3. browser_type email into email field\n4. browser_type password into password field\n5. browser_click submit button\n6. browser_snapshot to verify result\n```\n\n#### For Visual Criteria (Screenshot Testing)\n\nUse screenshots to verify visual elements:\n- Page layout and structure\n- Presence of specific elements\n- Error message appearance\n- Loading states\n\nExample:\n```\n1. browser_navigate to page\n2. browser_take_screenshot for visual verification\n3. Analyze screenshot for required elements\n```\n\n### 6. Update Task File\n\nFor each criterion you verify, update the checkbox:\n\n```markdown\n## Done Criteria\n- [x] Login form displays email and password fields  ← Passed\n- [x] Submit button is visible and clickable         ← Passed\n- [ ] Invalid login shows error message              ← Failed: no error shown\n- [x] Build completes without errors                 ← Passed\n```\n\nUse the Edit tool to update the checkboxes in the task file.\n\n### 7. Clean Up\n\nWhen done testing:\n```bash\n# Kill the dev server process\n# This ensures clean state for next iteration\n```\n\n### 8. Return Summary\n\nReturn a summary of results:\n- Which criteria passed\n- Which criteria failed (with specific reasons)\n- Any unexpected behaviors observed\n- Screenshots taken as evidence\n\n## Testing Strategy\n\n### Happy Path First\nTest the expected successful flows before edge cases.\n\n### One Criterion at a Time\nVerify each criterion independently. Don't assume one passing means another will.\n\n### Be Thorough\n- Test with valid inputs\n- Test with invalid inputs\n- Test empty states\n- Test error conditions\n\n### Document Failures Clearly\nWhen a criterion fails, explain:\n- What you expected to see\n- What you actually saw\n- Steps to reproduce\n\n## Playwright MCP Tools Reference\n\nKey tools you'll use:\n\n| Tool | Purpose |\n|------|---------|\n| `browser_navigate` | Go to a URL |\n| `browser_snapshot` | Get accessibility tree (for element refs) |\n| `browser_click` | Click an element |\n| `browser_type` | Type text into an input |\n| `browser_take_screenshot` | Capture visual state |\n| `browser_wait_for` | Wait for text/element |\n| `browser_fill_form` | Fill multiple form fields |\n\n### Workflow Pattern\n\n```\n1. browser_snapshot (get element refs)\n2. Identify target element ref from snapshot\n3. browser_click/type/etc. using ref\n4. browser_snapshot (verify result)\n5. Repeat\n```\n\n## Critical Rules\n\n### DO NOT:\n- Look at code implementation\n- Make assumptions about how features work\n- Skip criteria because they \"should work\"\n- Leave the dev server running\n\n### DO:\n- Test every criterion explicitly\n- Take screenshots as evidence\n- Document exactly why criteria fail\n- Clean up resources when done\n- Test edge cases and error states\n\n## Example Verification Session\n\n```\n1. Read CLAUDE.md → dev server on port 3000\n2. Kill anything on port 3000\n3. Start: npm run dev\n4. Wait for http://localhost:3000 to respond\n5. Read task file → 5 done criteria\n\nCriterion 1: \"Login form displays email and password fields\"\n- browser_navigate(\"http://localhost:3000/login\")\n- browser_snapshot() → see form with email and password\n- PASS ✓\n\nCriterion 2: \"Submit shows validation errors for empty fields\"\n- browser_click(submit button ref)\n- browser_snapshot() → see error messages\n- PASS ✓\n\nCriterion 3: \"Valid login redirects to dashboard\"\n- browser_type(email, \"test@example.com\")\n- browser_type(password, \"password123\")\n- browser_click(submit)\n- browser_wait_for(\"Dashboard\")\n- browser_snapshot() → on dashboard page\n- PASS ✓\n\n6. Update task file with checkboxes\n7. Kill dev server\n8. Return: \"3/3 criteria passed\"\n```\n\n## Handling Failures\n\nWhen a criterion fails:\n\n1. **Don't try to fix it** - That's the coding agent's job\n2. **Document clearly** - What failed and why\n3. **Continue testing** - Other criteria may pass\n4. **Update task file** - Leave failing criteria unchecked\n5. **Return details** - The main command will pass this to the coding agent\n",
        "interactive-dev/commands/interactive-dev.md": "---\nname: interactive-dev\ndescription: Start an interactive development workflow with planning, implementation, and verification loops\n---\n\n# Interactive Development Workflow\n\nYou are orchestrating an interactive development workflow. This command runs in the main agent so you can use `AskUserQuestion` for multi-choice requirement gathering.\n\n## Workflow Overview\n\n1. **Planning Phase**: Interview user to gather requirements\n2. **Criteria Phase**: Define testable done criteria with user\n3. **Implementation Loop**: Code → Verify → Fix until all criteria pass\n\n## Phase 1: Planning\n\n### Load the Planning Skill\n\nReference the planning skill guidance from `skills/planning/SKILL.md` in this plugin.\n\n### Interview the User\n\nUse `AskUserQuestion` to gather requirements interactively. Structure your questions following the planning skill's guidance:\n\n**Question Format:**\n```\n{\n  \"questions\": [\n    {\n      \"question\": \"What should happen when the user submits the form?\",\n      \"header\": \"Submit\",\n      \"options\": [\n        {\"label\": \"Show success message (Recommended)\", \"description\": \"Display a confirmation message on the same page\"},\n        {\"label\": \"Redirect to dashboard\", \"description\": \"Navigate to the main dashboard after success\"},\n        {\"label\": \"Show confirmation modal\", \"description\": \"Display a modal dialog with confirmation\"}\n      ],\n      \"multiSelect\": false\n    }\n  ]\n}\n```\n\n**Interview Flow:**\n1. Start with understanding the core feature (1-2 questions)\n2. Define scope and boundaries (2-3 questions)\n3. Clarify UI/UX details (2-3 questions)\n4. Address edge cases if complex (1-2 questions)\n\nKeep the interview focused - typically 5-8 questions total.\n\n## Phase 2: Define Done Criteria\n\n### Load the Done Criteria Skill\n\nReference the done-criteria skill guidance from `skills/done-criteria/SKILL.md` in this plugin.\n\n### Create Criteria with User\n\nBased on the requirements gathered, propose done criteria to the user. Use `AskUserQuestion` to confirm:\n\n```\n{\n  \"questions\": [\n    {\n      \"question\": \"Which of these criteria should be included for this feature?\",\n      \"header\": \"Criteria\",\n      \"options\": [\n        {\"label\": \"Form displays email and password fields\", \"description\": \"Basic form structure\"},\n        {\"label\": \"Submit shows loading state\", \"description\": \"UX feedback during submission\"},\n        {\"label\": \"Invalid inputs show error messages\", \"description\": \"Validation feedback\"},\n        {\"label\": \"Successful login redirects to dashboard\", \"description\": \"Success flow\"}\n      ],\n      \"multiSelect\": true\n    }\n  ]\n}\n```\n\n### Always Include Build Criteria\n\nAdd these standard criteria:\n- Build completes without errors\n- No TypeScript/type errors (if applicable)\n- No lint errors (if applicable)\n\n## Phase 3: Create Task File\n\n### Generate Task File\n\nCreate a timestamped task file in `.claude/tasks/`:\n\n**Filename format:** `YYYY-MM-DD-HHMM-[slug].md`\n\nExample: `.claude/tasks/2024-01-15-1430-add-login-form.md`\n\n**Content format:**\n```markdown\n# Task: [Title]\n\n## Requirements\n- [Requirement 1]\n- [Requirement 2]\n- [Requirement 3]\n\n## Done Criteria\n- [ ] [Criterion 1]\n- [ ] [Criterion 2]\n- [ ] [Criterion 3]\n- [ ] Build completes without errors\n\n## Technical Decisions\n- [Decision 1 from interview]\n- [Decision 2 from interview]\n\n## Files Changed\n(Updated by coding agent)\n```\n\n### Update Task Index\n\nIf `.claude/tasks/index.md` exists, add an entry. If not, create it:\n\n```markdown\n# Task Index\n\n| Date | Task | Status |\n|------|------|--------|\n| 2024-01-15 | [Add Login Form](./2024-01-15-1430-add-login-form.md) | In Progress |\n```\n\n## Phase 4: Implementation Loop\n\n### Loop Structure\n\n```\nmax_iterations = 5\niteration = 0\n\nwhile iteration < max_iterations:\n    iteration += 1\n\n    # Step 1: Invoke coding agent\n    coding_result = Task(\n        subagent_type=\"coding-agent\",\n        prompt=f\"Implement the feature described in {task_file_path}. Read the requirements and done criteria, write the code, and run build/lint/typecheck until clean.\"\n    )\n\n    # Step 2: Read updated task file for changed files\n    changed_files = read_files_changed_section(task_file_path)\n\n    # Step 3: Invoke verification agent\n    verification_result = Task(\n        subagent_type=\"verification-agent\",\n        prompt=f\"Verify the implementation in {task_file_path}. Changed files: {changed_files}. Test each criterion using Playwright MCP and update checkboxes.\"\n    )\n\n    # Step 4: Check completion\n    criteria = read_done_criteria(task_file_path)\n\n    if all_criteria_checked(criteria):\n        # Success! Mark task complete\n        update_task_status(\"Complete\")\n        notify_user(\"All criteria passed!\")\n        break\n    else:\n        # Get failure details\n        failures = get_unchecked_criteria(criteria)\n        notify_user(f\"Iteration {iteration}: {len(failures)} criteria still failing\")\n\n        if iteration < max_iterations:\n            # Pass failures back to coding agent in next iteration\n            continue\n        else:\n            notify_user(\"Max iterations reached. Review task file for remaining issues.\")\n```\n\n### Invoking Agents\n\nUse the `Task` tool to invoke subagents:\n\n**Coding Agent:**\n```\nTask(\n    subagent_type=\"coding-agent\",\n    prompt=\"Implement the feature in .claude/tasks/2024-01-15-1430-add-login-form.md. Previous issues to address: [list any failures from verification]\"\n)\n```\n\n**Verification Agent:**\n```\nTask(\n    subagent_type=\"verification-agent\",\n    prompt=\"Verify .claude/tasks/2024-01-15-1430-add-login-form.md. Changed files: LoginForm.tsx, login.tsx, useAuth.ts\"\n)\n```\n\n### Handling Failures\n\nAfter each verification:\n1. Read the updated task file\n2. Identify unchecked criteria\n3. Extract failure reasons from verification agent's response\n4. Pass specific issues to the coding agent in the next iteration\n\nExample prompt for retry:\n```\n\"Continue implementing .claude/tasks/2024-01-15-1430-add-login-form.md.\n\nThe following criteria are still failing:\n- [ ] Invalid login shows error message - Verification found: No error message appears after invalid credentials\n- [ ] Form validation prevents empty submission - Verification found: Form submits with empty fields\n\nFocus on fixing these specific issues.\"\n```\n\n## Phase 5: Completion\n\n### When All Criteria Pass\n\n1. Update task index status to \"Complete\"\n2. Summarize to user:\n   - What was built\n   - Files that were changed\n   - Number of iterations needed\n\n### When Max Iterations Reached\n\n1. Update task index status to \"Incomplete\"\n2. Report to user:\n   - Which criteria passed\n   - Which criteria still fail\n   - Suggest manual review\n\n## User Argument Handling\n\nThe command receives the user's task description as `$ARGUMENTS`.\n\nIf `$ARGUMENTS` is provided:\n- Use it as the starting point for the interview\n- Begin with clarifying questions about the description\n\nIf `$ARGUMENTS` is empty:\n- Ask the user what they want to build\n- Start the interview from scratch\n\n## Example Session\n\n```\nUser: /interactive-dev Add a user profile page\n\nAgent: I'll help you build a user profile page. Let me ask a few questions to understand the requirements.\n\n[AskUserQuestion: What information should the profile display?]\nUser selects: Name, email, avatar, bio\n\n[AskUserQuestion: Should users be able to edit their profile?]\nUser selects: Yes, inline editing\n\n[AskUserQuestion: How should the page handle loading?]\nUser selects: Show skeleton loader\n\nAgent: Based on your answers, here are the proposed done criteria...\n\n[AskUserQuestion: Confirm criteria]\nUser confirms selection\n\nAgent: Creating task file and starting implementation...\n\n[Task: coding-agent implements feature]\n[Task: verification-agent tests feature]\n\nAgent: Iteration 1 complete. 4/5 criteria passing. Running another iteration...\n\n[Task: coding-agent fixes remaining issue]\n[Task: verification-agent verifies fix]\n\nAgent: All criteria passing! Your user profile page is complete.\n\nFiles changed:\n- src/components/UserProfile.tsx\n- src/pages/profile.tsx\n- src/hooks/useProfile.ts\n```\n",
        "interactive-dev/hooks/hooks.json": "{\n  \"hooks\": {\n    \"PostToolUse\": [\n      {\n        \"matcher\": \"Write|Edit\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"echo 'File changed, lint/typecheck will run in coding agent'\"\n          }\n        ]\n      }\n    ]\n  }\n}\n",
        "interactive-dev/skills/done-criteria/SKILL.md": "---\nname: done-criteria\ndescription: Helps define testable acceptance criteria for development tasks. Use when establishing done criteria during interactive-dev planning.\n---\n\n# Done Criteria Skill\n\nThis skill guides you in defining clear, testable acceptance criteria that can be verified by automated testing and browser-based verification.\n\n## What Makes Good Done Criteria\n\nEvery criterion must be:\n\n### 1. Observable\nCan be seen in the browser or test output. Something a human or automated test can verify.\n\n### 2. Specific\nNot vague or subjective. Clear enough that two different testers would agree on pass/fail.\n\n### 3. Testable\nCan be verified programmatically or through browser interaction. No \"feel\" or \"seem\" language.\n\n## Categories of Criteria\n\n### Functional Criteria\nThe feature works as expected.\n\nExamples:\n- \"Clicking 'Submit' button sends form data to the server\"\n- \"User can navigate between pages using the sidebar menu\"\n- \"Search results update as user types in the search box\"\n\n### Visual Criteria\nThe UI renders correctly.\n\nExamples:\n- \"Profile page displays user name, email, and avatar image\"\n- \"Error messages appear in red text below the input field\"\n- \"Loading spinner is visible while data is fetching\"\n\n### Validation Criteria\nErrors and edge cases are handled properly.\n\nExamples:\n- \"Form shows 'Email is required' when submitted without email\"\n- \"Empty state message appears when no results are found\"\n- \"Network error displays 'Unable to connect' message\"\n\n### Build Criteria\nCode quality standards are met.\n\nExamples:\n- \"Build completes without errors\"\n- \"No TypeScript type errors\"\n- \"No ESLint warnings\"\n- \"All existing tests pass\"\n\n## Examples: Good vs Bad Criteria\n\n### Bad Criteria (Avoid These)\n\n| Bad | Problem |\n|-----|---------|\n| \"Profile page looks good\" | Subjective - what is \"good\"? |\n| \"Form is user-friendly\" | Vague - can't be tested |\n| \"Performance is acceptable\" | No measurable threshold |\n| \"Errors are handled\" | Doesn't specify which errors or how |\n| \"The code is clean\" | Opinion-based, not testable |\n\n### Good Criteria (Use These)\n\n| Good | Why It Works |\n|------|--------------|\n| \"Profile page displays user name, email, and avatar\" | Specific elements to verify |\n| \"Form shows inline errors for invalid inputs\" | Observable behavior |\n| \"Page loads in under 3 seconds\" | Measurable threshold |\n| \"Invalid email shows 'Please enter a valid email'\" | Exact error message |\n| \"Build passes with no TypeScript errors\" | Binary pass/fail |\n\n## Criterion Structure\n\nWrite each criterion as a checkbox item that can be marked complete:\n\n```markdown\n## Done Criteria\n- [ ] [Action/State] [Observable result]\n```\n\nExamples:\n```markdown\n- [ ] Login form accepts valid email and password\n- [ ] Successful login redirects to dashboard page\n- [ ] Invalid credentials show \"Invalid email or password\" error\n- [ ] Empty email field shows \"Email is required\" error\n- [ ] Loading spinner visible during login request\n- [ ] Build completes without errors\n```\n\n## Recommended Criteria Count\n\n- **Simple features**: 3-5 criteria\n- **Medium features**: 5-8 criteria\n- **Complex features**: 8-12 criteria\n\nIf you have more than 12 criteria, consider breaking the feature into smaller tasks.\n\n## Criteria Checklist\n\nBefore finalizing, verify each criterion passes this checklist:\n\n1. **Binary result**: Can it be marked pass or fail? (no partial credit)\n2. **No implementation details**: Does it describe WHAT, not HOW?\n3. **Testable in browser**: Can the verification agent check this?\n4. **Independent**: Can it be verified without checking other criteria first?\n5. **Complete sentence**: Does it clearly describe the expected behavior?\n\n## Hybrid Testing Approach\n\nThe verification agent uses two approaches:\n\n### Interactive Testing (for functional criteria)\n- Click buttons, fill forms, navigate pages\n- Verify behavior through element state changes\n- Check network requests and responses\n\n### Screenshot Testing (for visual criteria)\n- Capture page state at key moments\n- Verify presence of visual elements\n- Check layout and positioning\n\nWhen writing criteria, consider which approach will verify it:\n- \"Button changes to 'Saving...' when clicked\" → Interactive\n- \"Page header shows user avatar in top right\" → Screenshot\n- \"Form validation errors appear below inputs\" → Both\n\n## Common Criteria Templates\n\n### Form Feature\n```markdown\n- [ ] Form displays all required input fields\n- [ ] Submit button is disabled until form is valid\n- [ ] Valid submission shows success message\n- [ ] Invalid [field] shows \"[error message]\" error\n- [ ] Build completes without errors\n```\n\n### List/Display Feature\n```markdown\n- [ ] Page displays list of [items]\n- [ ] Each item shows [required fields]\n- [ ] Empty state shows \"[message]\" when no items\n- [ ] Loading spinner visible while fetching\n- [ ] Build completes without errors\n```\n\n### CRUD Feature\n```markdown\n- [ ] User can create new [item]\n- [ ] User can view [item] details\n- [ ] User can edit existing [item]\n- [ ] User can delete [item]\n- [ ] Confirmation dialog appears before delete\n- [ ] Build completes without errors\n```\n",
        "interactive-dev/skills/planning/SKILL.md": "---\nname: planning\ndescription: Guides interactive requirement gathering for development tasks. Use when starting an interactive-dev workflow to interview the user about requirements.\n---\n\n# Planning Skill\n\nThis skill guides you through conducting effective requirement interviews for development tasks. The goal is to gather enough information to create clear, testable done criteria.\n\n## Interview Philosophy\n\n- **Start broad, get specific**: Begin with high-level questions about the feature's purpose before diving into details\n- **Provide recommendations**: Each question should have a recommended option to help users who are unsure\n- **Respect user expertise**: Allow \"Other (specify)\" options for users who know exactly what they want\n- **Know when to stop**: Stop asking when you have enough clarity to define specific done criteria\n\n## Question Categories\n\n### 1. Scope Questions\nDefine the boundaries of the feature.\n\nExample questions:\n- \"What's the main goal of this feature?\"\n- \"Which users will use this feature?\"\n- \"What's the minimum viable version of this feature?\"\n\n### 2. Data Questions\nUnderstand the data involved.\n\nExample questions:\n- \"What information needs to be displayed?\"\n- \"Where does this data come from?\"\n- \"What happens if data is missing?\"\n\n### 3. UI/UX Questions\nClarify the visual and interaction design.\n\nExample questions:\n- \"Where should this feature appear in the app?\"\n- \"What should happen when the user clicks/submits?\"\n- \"How should loading states be handled?\"\n\n### 4. Edge Case Questions\nHandle unusual situations.\n\nExample questions:\n- \"What happens with empty data?\"\n- \"What error messages should appear?\"\n- \"How should the feature behave offline?\"\n\n### 5. Technical Constraint Questions\nIdentify technical requirements and limitations.\n\nExample questions:\n- \"Are there performance requirements?\"\n- \"Does this need to work on specific browsers/devices?\"\n- \"Are there accessibility requirements?\"\n\n## Question Structure\n\nEach question should have:\n\n1. **Clear question text**: Specific and unambiguous\n2. **3-5 options**: Including a recommended choice (marked with \"(Recommended)\")\n3. **Option descriptions**: Brief explanation of each choice's implications\n4. **multiSelect flag**: Set to true when multiple options can apply\n\n### Example Question Format\n\n```\nQuestion: \"How should form validation work?\"\nHeader: \"Validation\"\nOptions:\n  - label: \"Real-time validation (Recommended)\"\n    description: \"Validate as user types, show errors immediately\"\n  - label: \"On submit only\"\n    description: \"Validate when form is submitted\"\n  - label: \"On blur\"\n    description: \"Validate when user leaves each field\"\n  - label: \"No validation\"\n    description: \"Accept any input\"\n```\n\n## Interview Flow\n\n### Phase 1: Understanding (1-2 questions)\n- What is the user trying to build?\n- What problem does it solve?\n\n### Phase 2: Scope Definition (2-3 questions)\n- What are the core features?\n- What's out of scope for now?\n\n### Phase 3: Details (2-4 questions)\n- Specific UI/UX decisions\n- Data handling\n- Error cases\n\n### Phase 4: Technical (1-2 questions, if needed)\n- Performance requirements\n- Browser/device support\n\n## When to Stop Asking\n\nStop the interview when you can answer \"yes\" to all of these:\n\n1. **Clear purpose**: You understand why this feature exists\n2. **Defined scope**: You know what's in and out of scope\n3. **Testable outcomes**: You can describe specific, observable behaviors\n4. **Edge cases covered**: You know how errors and empty states should behave\n\n## Output Format\n\nAfter the interview, summarize requirements in this format:\n\n```markdown\n## Requirements\n- [Core requirement 1]\n- [Core requirement 2]\n- [UI requirement]\n- [Data requirement]\n- [Error handling requirement]\n\n## Technical Decisions\n- [Framework/library choices]\n- [Architecture decisions]\n- [Browser/device support]\n```\n\n## Tips for Effective Interviews\n\n1. **Don't over-ask**: 5-8 questions is usually enough\n2. **Group related questions**: Use multiSelect to combine related choices\n3. **Provide context**: Explain why you're asking if the question might seem odd\n4. **Accept defaults**: If the user keeps choosing recommended options, they likely want a standard implementation\n5. **Summarize understanding**: Before defining done criteria, confirm your understanding of the requirements\n"
      },
      "plugins": [
        {
          "name": "interactive-dev",
          "source": "./interactive-dev",
          "description": "Interactive development workflow with planning, coding, and browser-based verification loops",
          "version": "1.0.0",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add newtro/claude-plugins",
            "/plugin install interactive-dev@mathews-claude-plugins"
          ]
        }
      ]
    }
  ]
}