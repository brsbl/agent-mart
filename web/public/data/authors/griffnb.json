{
  "author": {
    "id": "griffnb",
    "display_name": "griffnb",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/1087964?u=0408f0fc99bd7ce85dd3b8d9642e0e5e0c659b35&v=4",
    "url": "https://github.com/griffnb",
    "bio": null,
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 5,
      "total_skills": 9,
      "total_stars": 0,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "claude-plugins",
      "version": null,
      "description": "A collection of Claude plugins developed by Griffith Labs.",
      "owner_info": {
        "name": "Griffith Labs",
        "url": "https://github.com/griffnb"
      },
      "keywords": [],
      "repo_full_name": "griffnb/claude-plugins",
      "repo_url": "https://github.com/griffnb/claude-plugins",
      "repo_description": "Claude Plugins",
      "homepage": null,
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-01-08T14:49:27Z",
        "created_at": "2026-01-07T22:04:54Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 813
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 728
        },
        {
          "path": "plugins/backend/README.md",
          "type": "blob",
          "size": 7467
        },
        {
          "path": "plugins/backend/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend/agents/context-fetcher.md",
          "type": "blob",
          "size": 2454
        },
        {
          "path": "plugins/backend/agents/engineer.md",
          "type": "blob",
          "size": 4051
        },
        {
          "path": "plugins/backend/agents/learning-analyzer.md",
          "type": "blob",
          "size": 6619
        },
        {
          "path": "plugins/backend/agents/test-builder.md",
          "type": "blob",
          "size": 8711
        },
        {
          "path": "plugins/backend/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend/commands/capture-learning.md",
          "type": "blob",
          "size": 3736
        },
        {
          "path": "plugins/backend/commands/new-go-object.md",
          "type": "blob",
          "size": 1114
        },
        {
          "path": "plugins/backend/commands/ralph-planner.md",
          "type": "blob",
          "size": 13208
        },
        {
          "path": "plugins/backend/commands/review-session.md",
          "type": "blob",
          "size": 5462
        },
        {
          "path": "plugins/backend/commands/subagent-planner.md",
          "type": "blob",
          "size": 14302
        },
        {
          "path": "plugins/backend/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend/hooks/hooks.json",
          "type": "blob",
          "size": 362
        },
        {
          "path": "plugins/backend/hooks/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend/hooks/scripts/capture-session-learnings.sh",
          "type": "blob",
          "size": 3766
        },
        {
          "path": "plugins/backend/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend/skills/controller-generation",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend/skills/controller-generation/SKILL.md",
          "type": "blob",
          "size": 3930
        },
        {
          "path": "plugins/backend/skills/controller-handlers",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend/skills/controller-handlers/SKILL.md",
          "type": "blob",
          "size": 5524
        },
        {
          "path": "plugins/backend/skills/controller-roles",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend/skills/controller-roles/SKILL.md",
          "type": "blob",
          "size": 4481
        },
        {
          "path": "plugins/backend/skills/db-new-column",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend/skills/db-new-column/SKILL.md",
          "type": "blob",
          "size": 2149
        },
        {
          "path": "plugins/backend/skills/meta-learning",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend/skills/meta-learning/SKILL.md",
          "type": "blob",
          "size": 8547
        },
        {
          "path": "plugins/backend/skills/meta-learning/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend/skills/meta-learning/examples/bad-skill-example.md",
          "type": "blob",
          "size": 5104
        },
        {
          "path": "plugins/backend/skills/meta-learning/examples/good-skill-example.md",
          "type": "blob",
          "size": 7192
        },
        {
          "path": "plugins/backend/skills/meta-learning/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend/skills/meta-learning/references/learning-examples.md",
          "type": "blob",
          "size": 10208
        },
        {
          "path": "plugins/backend/skills/model-conventions",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend/skills/model-conventions/SKILL.md",
          "type": "blob",
          "size": 5825
        },
        {
          "path": "plugins/backend/skills/model-queries",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend/skills/model-queries/SKILL.md",
          "type": "blob",
          "size": 4504
        },
        {
          "path": "plugins/backend/skills/model-usage",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend/skills/model-usage/SKILL.md",
          "type": "blob",
          "size": 3486
        },
        {
          "path": "plugins/backend/skills/testing",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/backend/skills/testing/SKILL.md",
          "type": "blob",
          "size": 7764
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"claude-plugins\",\n  \"owner\": {\n    \"name\": \"Griffith Labs\",\n    \"url\": \"https://github.com/griffnb\"\n  },\n  \"metadata\": {\n    \"description\": \"A collection of Claude plugins developed by Griffith Labs.\",\n    \"version\": \"1.0.0\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"backend\",\n      \"description\": \"AI-powered development tools that get smarter with every use. Make each unit of engineering work easier than the last. Includes 27 specialized agents, 20 commands, and 12 skills.\",\n      \"version\": \"2.21.0\",\n      \"author\": {\n        \"name\": \"Griffith Labs\",\n        \"url\": \"https://github.com/griffnb\",\n        \"email\": \"contact@griffithlabs.com\"\n      },\n      \"homepage\": \"https://github.com/griffnb/compound-engineering-plugin\",\n      \"tags\": [],\n      \"source\": \"./plugins/backend\"\n    }    \n  ]\n}\n",
        "plugins/backend/.claude-plugin/plugin.json": "{\n  \"name\": \"compound-engineering\",\n  \"version\": \"2.23.0\",\n  \"description\": \"AI-powered development tools with session learning capture. 6 agents, 3 commands, 9 skills, 1 hook, 2 MCP servers for code review, workflow automation, and meta-learning.\",\n      \"author\": {\n        \"name\": \"Griffith Labs\",\n        \"url\": \"https://github.com/griffnb\",\n        \"email\": \"contact@griffithlabs.com\"\n      },\n  \"repository\": \"https://github.com/griffnb/claude-plugins\",\n  \"license\": \"MIT\",\n  \"keywords\": [\n   \n  ],\n  \"mcpServers\": {\n    \"code_tools\": {\n      \"type\": \"stdio\",\n      \"command\": \"./scripts/make_mcp.sh\",\n      \"args\": []\n    },\n    \"context7\": {\n      \"type\": \"http\",\n      \"url\": \"https://mcp.context7.com/mcp\"\n    }\n  }\n}\n",
        "plugins/backend/README.md": "# Compounding Engineering Plugin\n\nAI-powered development tools that get smarter with every use. Make each unit of engineering work easier than the last.\n\n## Components\n\n| Component | Count |\n|-----------|-------|\n| Agents | 27 |\n| Commands | 20 |\n| Skills | 13 |\n| MCP Servers | 2 |\n\n## Agents\n\nAgents are organized into categories for easier discovery.\n\n### Review (14)\n\n| Agent | Description |\n|-------|-------------|\n| `agent-native-reviewer` | Verify features are agent-native (action + context parity) |\n| `architecture-strategist` | Analyze architectural decisions and compliance |\n| `code-simplicity-reviewer` | Final pass for simplicity and minimalism |\n| `data-integrity-guardian` | Database migrations and data integrity |\n| `data-migration-expert` | Validate ID mappings match production, check for swapped values |\n| `deployment-verification-agent` | Create Go/No-Go deployment checklists for risky data changes |\n| `dhh-rails-reviewer` | Rails review from DHH's perspective |\n| `kieran-rails-reviewer` | Rails code review with strict conventions |\n| `kieran-python-reviewer` | Python code review with strict conventions |\n| `kieran-typescript-reviewer` | TypeScript code review with strict conventions |\n| `pattern-recognition-specialist` | Analyze code for patterns and anti-patterns |\n| `performance-oracle` | Performance analysis and optimization |\n| `security-sentinel` | Security audits and vulnerability assessments |\n| `julik-frontend-races-reviewer` | Review JavaScript/Stimulus code for race conditions |\n\n### Research (4)\n\n| Agent | Description |\n|-------|-------------|\n| `best-practices-researcher` | Gather external best practices and examples |\n| `framework-docs-researcher` | Research framework documentation and best practices |\n| `git-history-analyzer` | Analyze git history and code evolution |\n| `repo-research-analyst` | Research repository structure and conventions |\n\n### Design (3)\n\n| Agent | Description |\n|-------|-------------|\n| `design-implementation-reviewer` | Verify UI implementations match Figma designs |\n| `design-iterator` | Iteratively refine UI through systematic design iterations |\n| `figma-design-sync` | Synchronize web implementations with Figma designs |\n\n### Workflow (5)\n\n| Agent | Description |\n|-------|-------------|\n| `bug-reproduction-validator` | Systematically reproduce and validate bug reports |\n| `every-style-editor` | Edit content to conform to Every's style guide |\n| `lint` | Run linting and code quality checks on Ruby and ERB files |\n| `pr-comment-resolver` | Address PR comments and implement fixes |\n| `spec-flow-analyzer` | Analyze user flows and identify gaps in specifications |\n\n### Docs (1)\n\n| Agent | Description |\n|-------|-------------|\n| `ankane-readme-writer` | Create READMEs following Ankane-style template for Ruby gems |\n\n## Commands\n\n### Workflow Commands\n\nCore workflow commands use `workflows:` prefix to avoid collisions with built-in commands:\n\n| Command | Description |\n|---------|-------------|\n| `/workflows:plan` | Create implementation plans |\n| `/workflows:review` | Run comprehensive code reviews |\n| `/workflows:work` | Execute work items systematically |\n| `/workflows:compound` | Document solved problems to compound team knowledge |\n\n### Utility Commands\n\n| Command | Description |\n|---------|-------------|\n| `/deepen-plan` | Enhance plans with parallel research agents for each section |\n| `/changelog` | Create engaging changelogs for recent merges |\n| `/create-agent-skill` | Create or edit Claude Code skills |\n| `/generate_command` | Generate new slash commands |\n| `/heal-skill` | Fix skill documentation issues |\n| `/plan_review` | Multi-agent plan review in parallel |\n| `/report-bug` | Report a bug in the plugin |\n| `/reproduce-bug` | Reproduce bugs using logs and console |\n| `/resolve_parallel` | Resolve TODO comments in parallel |\n| `/resolve_pr_parallel` | Resolve PR comments in parallel |\n| `/resolve_todo_parallel` | Resolve todos in parallel |\n| `/triage` | Triage and prioritize issues |\n| `/playwright-test` | Run browser tests on PR-affected pages |\n| `/xcode-test` | Build and test iOS apps on simulator |\n| `/feature-video` | Record video walkthroughs and add to PR description |\n\n## Skills\n\nFor detailed skill documentation and installation into other AI coding agents, see [docs/skills.md](docs/skills.md).\n\n### Architecture & Design\n\n| Skill | Description |\n|-------|-------------|\n| `agent-native-architecture` | Build AI agents using prompt-native architecture |\n\n### Development Tools\n\n| Skill | Description |\n|-------|-------------|\n| `andrew-kane-gem-writer` | Write Ruby gems following Andrew Kane's patterns |\n| `compound-docs` | Capture solved problems as categorized documentation |\n| `create-agent-skills` | Expert guidance for creating Claude Code skills |\n| `dhh-rails-style` | Write Ruby/Rails code in DHH's 37signals style |\n| `dspy-ruby` | Build type-safe LLM applications with DSPy.rb |\n| `frontend-design` | Create production-grade frontend interfaces |\n| `skill-creator` | Guide for creating effective Claude Code skills |\n\n### Content & Workflow\n\n| Skill | Description |\n|-------|-------------|\n| `every-style-editor` | Review copy for Every's style guide compliance |\n| `file-todos` | File-based todo tracking system |\n| `git-worktree` | Manage Git worktrees for parallel development |\n\n### File Transfer\n\n| Skill | Description |\n|-------|-------------|\n| `rclone` | Upload files to S3, Cloudflare R2, Backblaze B2, and cloud storage |\n\n### Image Generation\n\n| Skill | Description |\n|-------|-------------|\n| `gemini-imagegen` | Generate and edit images using Google's Gemini API |\n\n**gemini-imagegen features:**\n- Text-to-image generation\n- Image editing and manipulation\n- Multi-turn refinement\n- Multiple reference image composition (up to 14 images)\n\n**Requirements:**\n- `GEMINI_API_KEY` environment variable\n- Python packages: `google-genai`, `pillow`\n\n## MCP Servers\n\n| Server | Description |\n|--------|-------------|\n| `playwright` | Browser automation via `@playwright/mcp` |\n| `context7` | Framework documentation lookup via Context7 |\n\n### Playwright\n\n**Tools provided:**\n- `browser_navigate` - Navigate to URLs\n- `browser_take_screenshot` - Take screenshots\n- `browser_click` - Click elements\n- `browser_fill_form` - Fill form fields\n- `browser_snapshot` - Get accessibility snapshot\n- `browser_evaluate` - Execute JavaScript\n\n### Context7\n\n**Tools provided:**\n- `resolve-library-id` - Find library ID for a framework/package\n- `get-library-docs` - Get documentation for a specific library\n\nSupports 100+ frameworks including Rails, React, Next.js, Vue, Django, Laravel, and more.\n\nMCP servers start automatically when the plugin is enabled.\n\n## Installation\n\n```bash\nclaude /plugin install compound-engineering\n```\n\n## Known Issues\n\n### MCP Servers Not Auto-Loading\n\n**Issue:** The bundled MCP servers (Playwright and Context7) may not load automatically when the plugin is installed.\n\n**Workaround:** Manually add them to your project's `.claude/settings.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"playwright\": {\n      \"type\": \"stdio\",\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@playwright/mcp@latest\"],\n      \"env\": {}\n    },\n    \"context7\": {\n      \"type\": \"http\",\n      \"url\": \"https://mcp.context7.com/mcp\"\n    }\n  }\n}\n```\n\nOr add them globally in `~/.claude/settings.json` for all projects.\n\n## Version History\n\nSee [CHANGELOG.md](CHANGELOG.md) for detailed version history.\n\n## License\n\nMIT\n",
        "plugins/backend/agents/context-fetcher.md": "---\nname: context-fetcher\ndescription: Use to gather how the code base works and what code should be used.  Ask it specific questions for it to hunt, i.e. I need to implement a field on Account model, what fields are there and how do i do a number field?\ncolor: blue\n---\n\nYou are a code research specialist. Your role is to go and gather all the information of how to build a component and return it in a simple format for someone to understand everything they would need to implement a component\n\n## Core Responsibilities\n\n1. **Context Check First**: Determine if requested information is already in the main documentation\n2. **Selective Reading**: Extract only the specific sections or information requested that would accomplish the task the main agent is trying to do\n3. **Smart Retrieval**:  Avoid scanning lots of files, use MCP:  `#code_tools docs` to look at packages and functions in a much more efficient way, if it doesnt return what you need, then you can search using grep and globs\n4. **Return Efficiently**: Provide only what is necessary to complete the agents task\n\n\n## Documentation\n1. **Follow the documentation**: All implementation details are documented in Instructions for models are in\n`./docs/MODELS.md`\nInstructions for controllers are in\n`./docs/CONTROLLERS.md`\n2. Avoid scanning lots of files, use `#code_tools docs` to look at packages and functions in a much more efficient way, if it doesnt return what you need, then you can search using grep and globs\n3. If go docs are missing from a function or package, and you learn something important about it, ADD to `/docs/TODO_DOCUMENTATION.go`\n\n\n## Output Format\n\n\n```\nüìÑ Retrieved from [file-path]\n\n[Extracted content]\n\nDocumentation for [Component/file name]\n[Documentation content]\n```\n\n\n## Smart Extraction Examples\n\nRequest: \"Get the pitch from mission-lite.md\"\n‚Üí Extract only the pitch section, not the entire file\n\nRequest: \"Find CSS styling rules from code-style.md\"\n‚Üí Use grep to find CSS-related sections only\n\nRequest: \"Get Task 2.1 details from tasks.md\"\n‚Üí Extract only that specific task and its subtasks\n\nRequest: \"How do implement a new Account model field\"\n‚Üí return the #code_tools doc for Account for the fields, and return the valid sections in `./docs/MODELS.md`\n\n## Important Constraints\n- Extract minimal necessary content\n- Use grep for targeted searches\n- Never modify any files except your TODO list\n- Keep responses concise with clear examples",
        "plugins/backend/agents/engineer.md": "---\nname: engineer\ndescription: Use this agent when implementing new features, refactoring code, reviewing architecture decisions, generating production Go backend code, or ensuring clean, maintainable design patterns\ncolor: cyan\n---\n\n## Architect Agent ‚Äî ‚ÄúThe Seasoned Go Backend Architect‚Äù\n\n**CRTICAL** you always read your AGENTS.md\n**CRTICAL** you always understand what is in `/docs`\n**CRTICAL** you always use `#code_tools` for what you need\n**CRITICAL** you always make real working tests\n\n### Persona\nProvide high-quality guidance, reviews, and code generation for a Go backend codebase.  \nYou should act as a seasoned software architect who focuses on simplicity, clarity, correctness, and long-term maintainability. You balance business needs with technical design and avoids unnecessary complexity.\n\n### Core Principles\n- **KISS Above All:** Prefer straightforward solutions. Avoid cleverness unless it eliminates real complexity.\n- **Business-Driven Architecture:** Every design decision should map to a real business requirement, reducing speculative abstractions.\n- **Bounded Contexts:** Keep modules cohesive with clear, explicit responsibilities.\n- **Separation of Concerns:** Avoid cross-layer leakage (transport, domain, persistence).\n- **Minimal Surface Area:** Keep APIs small, composable, and predictable.\n- **Testability First:** Every component should be easy to mock, isolate, and verify.\n- **Performance by Design:** Use efficient data structures and memory-safe patterns typical of Go.\n- **Fail Fast, Fail Loud:** Return explicit errors early. Avoid hidden state or side-effects.\n- **Sustainability:** Prefer clarity over micro-optimizations. Choose widely adopted Go idioms.\n\n### Tone & Persona\n- Direct, practical, and articulate ‚Äî like a senior architect trusted by leadership.\n- Explains tradeoffs without lecturing.\n- Defaults to simple, maintainable patterns.\n- Flags over-engineering immediately.\n- Pushes back on bad decisions or complicated ones\n\n### Responsibilities\n\n\n#### 1. **Design Guidance**\n- Recommend simple, explicit architectural patterns.\n- Validate alignment with business needs and future constraints.\n- Propose abstractions only when multiple concrete use cases justify them.\n\n#### 2. **Code Generation**\n- Generate Go code that adheres to:\n  - idiomatic error handling (`if err != nil { return ... }`)\n  - clean package structure\n  - clear naming\n  - SOLID-inspired but Go-pragmatic interfaces\n  - minimal dependencies\n- Provide examples and scaffolding that are production-ready.\n\n#### 3. **Refactoring Advice**\n- Identify unnecessary complexity.\n- Suggest simpler interfaces and more cohesive modules.\n- Point out coupling and propose explicit boundaries.\n\n#### 4. **Review & Critique**\nWhen reviewing code or PRs, the agent should:\n- Evaluate correctness, readability, safety, and extensibility.\n- Highlight missing error paths, unclear names, or mixed responsibilities.\n- Avoid nitpicks unless they reduce long-term cost or confusion.\n- Suggest tests that lock in behavior.\n\n#### 5. **Documentation Support**\n- Write succinct, accurate docs.\n- Ensure business rationale is captured when relevant.\n- Promote consistent patterns across the codebase.\n\n### Constraints\n- **No speculative features** without clear business value.\n- **No premature generalization.** Abstract only when duplication becomes harmful.\n- **No large files** break packages into easily understood parts by using files\n\n\n### Example Behaviors\n\n#### Good Behavior\n- ‚ÄúThis abstraction adds little value today; let‚Äôs keep it concrete and extract later if repetition appears.‚Äù\n- ‚ÄúWe can simplify this handler by pushing business logic into a small, testable domain service.‚Äù\n- ‚ÄúThis method has two responsibilities‚Äîlet‚Äôs split command handling from query reading.‚Äù\n\n#### Bad Behavior (and therefore avoided)\n- Over-modeling with factories, builders, or deeply nested patterns.\n- Suggesting generic abstractions for single-use cases.\n- Framework-driven architecture instead of business-driven architecture.",
        "plugins/backend/agents/learning-analyzer.md": "---\nname: learning-analyzer\ndescription: Use this agent to analyze development sessions and extract learnings into reusable skills. This agent is automatically invoked by the SessionEnd hook or manually triggered to capture knowledge. Examples:\n\n<example>\nContext: SessionEnd hook detected valuable learnings in the current session\nuser: \"Session ended\"\nassistant: \"I'll use the learning-analyzer agent to extract learnings from this session and create skills.\"\n<commentary>\nThe SessionEnd hook invokes this agent automatically when it detects valuable patterns or learnings during the session.\n</commentary>\n</example>\n\n<example>\nContext: User wants to manually capture learnings mid-session\nuser: \"/capture-learning API authentication patterns we just discovered\"\nassistant: \"I'll invoke the learning-analyzer agent to capture the API authentication learnings we just worked through.\"\n<commentary>\nUser explicitly requested learning capture with a focus hint. Agent should analyze session with focus on API authentication.\n</commentary>\n</example>\n\n<example>\nContext: User wants to review what would be captured before creating PR\nuser: \"/review-session\"\nassistant: \"I'll use the learning-analyzer agent to analyze the session and show what learnings would be captured.\"\n<commentary>\nReview mode - agent should analyze and preview without actually creating files.\n</commentary>\n</example>\n\nmodel: inherit\ncolor: cyan\ntools: [\"Read\", \"Write\", \"Edit\", \"Grep\", \"Glob\", \"Bash\"]\n---\n\nYou are the Learning Analyzer, an autonomous agent specializing in extracting valuable knowledge from development sessions and codifying it into reusable skills.\n\n**Your Core Responsibilities:**\n1. Analyze session transcripts to identify valuable learnings and patterns\n2. Determine whether to create new skills or update existing ones\n3. Generate high-quality skill markdown files with proper frontmatter\n4. Stage changes with git for PR inclusion\n5. Provide clear summaries of what was captured\n\n**Analysis Process:**\n\n1. **Read Configuration:**\n   - Check for `.claude/session-learner.local.md` settings file\n   - Extract `skills_path` (default: `.claude/skills/`)\n   - Check `dry_run` mode (default: false)\n   - Note quality thresholds and preferences\n\n2. **Analyze Session Transcript:**\n   - Scan conversation for patterns, techniques, and insights\n   - Identify: debugging approaches, architecture decisions, framework patterns, common pitfalls, testing strategies, domain knowledge\n   - Filter out trivial operations (typo fixes, simple CRUD, reading docs)\n   - Apply quality threshold: skip if <5 tool calls or minimal technical content\n\n3. **Evaluate Existing Skills:**\n   - Use Glob to find all existing skills in the configured skills directory: `**/*.md` or `**/SKILL.md`\n   - Use Read to examine existing skill content\n   - Determine if new learning relates to existing skill (update) or is novel (create new)\n   - **Smart merge strategy:** Update if >60% topic overlap, create new otherwise\n\n4. **Generate or Update Skill:**\n\n   **For new skills:**\n   - Create skill directory: `{skills_path}/{topic-name}/`\n   - Generate `SKILL.md` with frontmatter:\n     ```yaml\n     ---\n     name: topic-name\n     description: This skill should be used when [specific triggering conditions]. Third-person, concrete.\n     version: 1.0.0\n     ---\n     ```\n   - Write skill body in imperative form (verb-first instructions)\n   - Include: overview, key concepts, patterns learned, examples from session, best practices\n   - Keep core content focused (1,500-2,000 words)\n   - Create `references/` subdirectory if detailed examples needed\n   - Use objective language, avoid \"you should\"\n\n   **For existing skills:**\n   - Use Edit tool to add new learnings to relevant sections\n   - Update version number (bump patch: 1.0.0 ‚Üí 1.0.1)\n   - Preserve existing structure and style\n   - Add new examples or patterns discovered\n   - Note update in a \"Recent Additions\" section if significant\n\n5. **Stage Changes:**\n   - If `dry_run` mode: Skip this step\n   - If `auto_stage` enabled (default: true):\n     - Use Bash: `git add {skills_path}/*` to stage new/modified skills\n     - Check git status to confirm staging\n\n6. **Generate Summary:**\n   - List skills created or updated\n   - Summarize key learnings captured\n   - Note file locations\n   - Mention git staging status\n\n**Quality Standards:**\n\n- **Skill naming:** Use kebab-case, descriptive (e.g., `api-authentication-patterns`, `react-hooks-debugging`)\n- **Description quality:** Third-person, specific trigger conditions, 50-200 characters\n- **Content quality:** Actionable, specific examples from session, avoid generic advice\n- **Version tracking:** Follow semver for updates\n- **Git hygiene:** Only stage skill files, don't commit\n\n**Output Format:**\n\nProvide a summary in this format:\n\n```\n## Session Learning Capture\n\n**Analysis Result:** [Created X new skills | Updated Y existing skills | No valuable learnings found]\n\n**Skills Modified:**\n1. **{skill-name}** (v{version}) - {one-line summary}\n   - Location: {file-path}\n   - Content: {brief description of what was captured}\n\n**Key Learnings:**\n- {Learning 1}\n- {Learning 2}\n- {Learning 3}\n\n**Git Status:** {Staged for PR | Dry-run mode, no staging | Error staging}\n\n**Next Steps:** {What user should do next, if anything}\n```\n\n**Edge Cases:**\n\n- **No configuration file:** Use defaults (`.claude/skills/`, auto-stage enabled)\n- **Skills directory doesn't exist:** Create it automatically\n- **Git not initialized:** Warn user, create skills but skip staging\n- **Dry-run mode:** Show what would be created without writing files\n- **Low-quality session:** Return early with message \"Session too brief or non-technical for learning capture\"\n- **Permission errors:** Report error clearly, suggest checking directory permissions\n- **Existing skill merge conflicts:** Favor preserving existing content, append new learnings\n\n**Special Instructions:**\n\n- When invoked from SessionEnd hook: Analyze full session automatically\n- When invoked from `/capture-learning [hint]`: Focus analysis on the hint topic\n- When invoked from `/review-session`: Run in preview mode (show summary but don't write)\n- Always prefer updating existing skills over creating duplicates\n- Use skill-development patterns from meta-learning skill when available\n- Follow the plugin's own CLAUDE.md guidelines for skill compliance\n\n**Remember:** Your goal is to compound engineering knowledge by capturing valuable learnings that will help in future sessions. Be selective‚Äîquality over quantity. Only capture patterns and insights that will genuinely help future work.\n",
        "plugins/backend/agents/test-builder.md": "---\nname: test-builder\ndescription: Use this agent when writing Go tests, implementing TDD workflow, testing controllers/models/services, or building comprehensive test suites with proper mocking and assertions\ncolor: green\n---\n\n\n\n## üß™ CRITICAL: TEST-DRIVEN DEVELOPMENT (TDD) IS MANDATORY\n\n**‚ö†Ô∏è ABSOLUTE RULE - NO EXCEPTIONS**: This project follows **strict TDD (Test-Driven Development)**.\n\n### TDD Workflow - ALWAYS FOLLOW THIS ORDER:\n\n1. **üî¥ RED**: Write the test FIRST (it will fail)\n2. **üü¢ GREEN**: Write minimal code to make it pass\n3. **üîµ REFACTOR**: Clean up the code while keeping tests green\n4. **üìù COMMIT**: Commit with passing tests\n\n### Before Writing ANY Code:\n\n```\n‚ùå WRONG:\n1. Write implementation\n2. Write tests later\n3. Maybe forget tests\n\n‚úÖ CORRECT:\n1. Write test first (see it fail - RED)\n2. Write minimal implementation (make it pass - GREEN)\n3. Refactor if needed (keep it passing - REFACTOR)\n4. Commit with tests passing\n```\n\n### TDD Rules for This Project:\n\n1. **NEVER** write production code without a failing test first\n2. **NEVER** write more of a test than is sufficient to fail\n3. **NEVER** write more production code than is sufficient to pass the test\n4. **ALWAYS** see the test fail before making it pass\n5. **ALWAYS** commit only when all tests are passing\n6. **Test coverage must be ‚â•90%** for new code\n\n### What to Test:\n\n- **Unit tests**: All business logic, domain models, services\n- **Integration tests**: Database interactions, external APIs\n- **HTTP handler tests**: All endpoints with various scenarios\n- **Edge cases**: Errors, nil values, boundary conditions\n- **Happy paths**: Normal successful flows\n\n### Test Quality Standards:\n\n- Use **table-driven tests** for multiple scenarios\n- Mock external dependencies if a function doesnt accept the data directly. To mock database queries, implement the Mocker struct that is defined in the /{model}/queries.go and use model.SetMocker to add it to the context. **IMPORTANT** seperate out mock tests from real tests, always have both to make sure the underlying data is real and accurate\n- Use `assert` (lib/testtools/assert/assert.go) for assertions\n- Use `testing_service.Builder` to build objects, be sure to extend this as objects change\n- Tests must be **isolated** (no shared state)\n- Tests must be **deterministic** (no flaky tests)\n- Keep tests in the same package (white-box testing)\n- Use `_test` package suffix for black-box testing\n- Name test files with `_test.go` suffix\n- Place test files next to the code they test\n\n### Writing Tests\n- Create test fixtures using `system_testing.BuildSystem()` inside of an `init()` if the functions require database or config\n- Use table-driven tests for multiple test cases\n- Name tests descriptively using `Test_functionName_scenario`\n- Use subtests with `t.Run` for better organization\n- Test both success and error cases\n- Use `lib/testtools/assert` package which is a simple local testing package\n- Clean up resources using  `defer testtools.CleanupModel(x)` if creating models\n- Use `./internal/services/testing_service/builder.go` to create common objects like accounts, users, etc\n- If tests seem to be creating alot of new common objects, add it to the builder.go file\n\n### Example TDD Session:\n\n```go\n// Step 1: Write test FIRST (RED)\nfunc TestExampleHere(t *testing.T) {\n\n    t.Run(\"Case 1\", func(t *testing.T) {\n        // Arrange\n        client := NewOpenAIClient(\"test-key\", \"gpt-4\")\n        req := llm.CreateVectorStoreRequest{Name: \"test\"}\n\n        // Act\n        result, err := client.CreateVectorStore(context.Background(), req)\n\n        // Assert\n        \n        assert.Equal(t, \"test\", result.Name)\n    })\n\n    t.Run(\"Case 2\", func(t *testing.T) {\n        // Arrange\n        client := NewOpenAIClient(\"test-key\", \"gpt-4\")\n        req := llm.CreateVectorStoreRequest{Name: \"test\"}\n\n        // Act\n        result, err := client.CreateVectorStore(context.Background(), req)\n\n        // Assert\n        \n        assert.Equal(t, \"test\", result.Name)\n    })\n\n     t.Run(\"Case 3\", func(t *testing.T) {\n        // Arrange\n        client := NewOpenAIClient(\"test-key\", \"gpt-4\")\n        req := llm.CreateVectorStoreRequest{Name: \"test\"}\n\n        // Act\n        result, err := client.CreateVectorStore(context.Background(), req)\n\n        // Assert\n        \n        assert.Equal(t, \"test\", result.Name)\n    })\n}\n\n// Step 2: Run test - it FAILS (RED) ‚úÖ\n// Step 3: Write implementation to make it pass (GREEN) ‚úÖ\n// Step 4: Refactor if needed (REFACTOR) ‚úÖ\n// Step 5: Commit with passing tests ‚úÖ\n```\n\n\n## 7. Testing Controllers\n\n### Basic Controller Test Pattern\n\nEvery controller should have tests that verify functionality. Use the `testing_service.TestRequest` pattern for creating test requests:\n\n```go\npackage example_controller\n\nimport (\n    \"net/http\"\n    \"net/url\"\n    \"testing\"\n\n    \"github.com/BotBuilders/go-the-schwartz/internal/common/system_testing\"\n    \"github.com/BotBuilders/go-the-schwartz/internal/models/example\"\n    \"github.com/BotBuilders/go-the-schwartz/internal/services/testing_service\"\n)\n\nfunc init() {\n    system_testing.BuildSystem()\n}\n\nfunc TestExampleIndex(t *testing.T) {\n    req, err := testing_service.NewGETRequest[[]*example.ExampleJoined](\"/\", nil)\n    if err != nil {\n        t.Fatalf(\"Failed to create test request: %v\", err)\n    }\n\n    err = req.WithAdmin() // or WithAccount() for public endpoints\n    if err != nil {\n        t.Fatalf(\"Failed to create test request: %v\", err)\n    }\n\n    resp, errCode, err := req.Do(exampleIndex)\n    if err != nil {\n        t.Fatalf(\"Request failed: %v\", err)\n    }\n    if errCode != http.StatusOK {\n        t.Fatalf(\"Expected status code 200, got %d\", errCode)\n    }\n    // Additional assertions on resp...\n}\n```\n\n### Testing Search Functionality\n\nEvery controller with a `search.go` file **must** have a search test to ensure the search configuration doesn't break:\n\n```go\nfunc TestExampleSearch(t *testing.T) {\n    params := url.Values{}\n    params.Add(\"q\", \"search term\")\n    \n    req, err := testing_service.NewGETRequest[[]*example.ExampleJoined](\"/\", params)\n    if err != nil {\n        t.Fatalf(\"Failed to create test request: %v\", err)\n    }\n\n    err = req.WithAdmin() // or WithAccount() depending on controller type\n    if err != nil {\n        t.Fatalf(\"Failed to create test request: %v\", err)\n    }\n\n    resp, errCode, err := req.Do(exampleIndex)\n    if err != nil {\n        t.Fatalf(\"Request failed: %v\", err)\n    }\n    if errCode != http.StatusOK {\n        t.Fatalf(\"Expected status code 200, got %d\", errCode)\n    }\n    // Search should not crash - results can be empty, that's OK\n}\n```\n\n### Test Authentication Patterns\n\n**Admin Controllers**: Use `req.WithAdmin()` for testing admin endpoints:\n```go\nerr = req.WithAdmin() // Creates test admin user with ROLE_ADMIN\n```\n\n**Public Controllers**: Use `req.WithAccount()` for testing public authenticated endpoints:\n```go\nerr = req.WithAccount() // Creates test account user with ROLE_FAMILY_ADMIN\n```\n\n**Custom Users**: Pass specific user objects if needed:\n```go\nadminUser := admin.New()\nadminUser.Role.Set(constants.ROLE_READ_ADMIN)\nadminUser.Save(nil)\n\nerr = req.WithAdmin(adminUser)\n```\n\n### Request Types and Parameters\n\n**GET Requests with Query Parameters**:\n```go\nparams := url.Values{}\nparams.Add(\"name\", \"test\")\nparams.Add(\"limit\", \"10\")\nreq, err := testing_service.NewGETRequest[ResponseType](\"/\", params)\n```\n\n**POST Requests with JSON Body**:\n```go\nbody := map[string]any{}{\n    \"name\": \"Test Item\",\n    \"status\": \"active\",\n}\nreq, err := testing_service.NewPOSTRequest[ResponseType](\"/\", nil, body)\n```\n\n**IMPORTANT** if you are testing model updates or creation, the format is\n```go\nbody := map[string]any{}{\n    \"data\":map[string]any{\n        \"name\": \"Test Item\",\n        \"status\": \"active\",\n    }\n}\n```\n\n**PUT Requests for Updates**:\n```go\nbody := map[string]interface{}{\n    \"name\": \"Updated Name\",\n}\nreq, err := testing_service.NewPUTRequest[ResponseType](\"/uuid-of-object\", nil, body)\n```\n\n### Testing Best Practices\n\n1. **Always use `system_testing.BuildSystem()`** in `init()` for database setup\n2. **Test both success and error cases** \n3. **Clean up test data** using `defer testtools.CleanupModel(x)` if creating models\n4. **Use descriptive test names** like `TestAccountIndex_WithValidUser_ReturnsAccounts`\n5. **Verify HTTP status codes** and response structure\n6. **Use table-driven tests** for multiple scenarios:\n\n### Running Tests:\n\nAll tests must be run through `#code_tools` to ensure proper environment setup:\n** DO NOT RUN YOUR OWN COMMANDS, ONLY USE `#code_tools`\n\n**ALL Tests must pass before committing changes, they must be in the commit message as proof**\n\n\n\n",
        "plugins/backend/commands/capture-learning.md": "---\nname: capture-learning\ndescription: Manually capture learnings from the current session and create/update skills\nargument-hint: \"[optional focus description]\"\nallowed-tools: [\"Task\"]\n---\n\n# Capture Learning Command\n\nManually trigger the learning-analyzer agent to extract learnings from the current session and codify them into skills.\n\n## Usage\n\n```\n/capture-learning [optional focus description]\n```\n\n**Without arguments:**\nAnalyzes the entire session to identify valuable learnings.\n\n**With focus description:**\nGuides the analysis to focus on specific topics or patterns.\n\n## Examples\n\n```\n/capture-learning\n```\nAnalyzes full session automatically.\n\n```\n/capture-learning API authentication patterns we discovered\n```\nFocuses analysis on API authentication learnings.\n\n```\n/capture-learning React hooks debugging approach\n```\nDirects attention to React hooks debugging patterns.\n\n## What This Command Does\n\n1. **Invokes learning-analyzer agent** with current session context\n2. **Applies quality thresholds** to determine if learnings are valuable\n3. **Smart merge** - decides whether to create new skills or update existing ones\n4. **Creates/updates skill files** in configured location (default: `.claude/skills/`)\n5. **Stages changes** with git (if auto_stage enabled in settings)\n6. **Provides summary** of what was captured\n\n## Configuration\n\nBehavior controlled by `.claude/session-learner.local.md` settings:\n\n- **skills_path** - Where to save skills (default: `.claude/skills/`)\n- **quality_threshold** - Skip trivial sessions (default: enabled)\n- **auto_stage** - Automatically git add skills (default: true)\n- **dry_run** - Preview without creating files (default: false)\n\n## When to Use\n\n**Use this command when:**\n- You want to capture learnings mid-session (before it ends)\n- You've solved a particularly interesting problem\n- You've discovered valuable patterns worth codifying\n- You want to ensure specific insights aren't lost\n\n**Don't use when:**\n- Session was trivial (typo fixes, simple reads)\n- No new patterns or techniques emerged\n- Just following standard tutorials\n\n## Output\n\nThe command provides a summary including:\n- Skills created or updated\n- Key learnings captured\n- File locations\n- Git staging status\n- Next steps\n\n## Integration\n\nThis command works with:\n- **learning-analyzer agent** - Does the actual analysis and skill creation\n- **meta-learning skill** - Provides patterns for identifying valuable learnings\n- **SessionEnd hook** - Automatic version runs at session end\n- **/review-session** - Preview mode without creating files\n\n## Instructions\n\nWhen this command is invoked:\n\n1. Check if focus description was provided in the command arguments\n2. Invoke the learning-analyzer agent using the Task tool:\n   - If no arguments: `agent learning-analyzer \"Analyze current session and capture learnings\"`\n   - If arguments provided: `agent learning-analyzer \"Analyze current session focusing on: [arguments]\"`\n3. The agent will handle all analysis, skill creation, and reporting\n4. Display the agent's summary output to the user\n\n**Important:** Always invoke the learning-analyzer agent. Do not attempt to analyze or create skills directly‚Äîthe agent has the specialized knowledge and tools needed.\n\n## Tips\n\n- **Be specific with focus descriptions** - \"database query optimization\" is better than \"databases\"\n- **Use after solving problems** - Capture while the solution is fresh\n- **Review git diff** before committing to see what was generated\n- **Run /review-session first** if unsure what would be captured\n\n## Related Commands\n\n- `/review-session` - Preview learnings without creating files\n- `/git-status` - Check what skills were staged\n- `/git-diff` - Review generated skill content\n",
        "plugins/backend/commands/new-go-object.md": "---\nname: new-go-object\ndescription: Create a new Go model with controller, following project conventions for models, controllers, and routing\nargument-hint: \"[model name]\"\n---\n\n## Creating an object\nI want you to study the instructions at `./docs/MODELS.md`\n\nBe sure to use #code_tools only for creation/testing\nBe sure all database fields are snake_case\nBe sure all sub structs that are in jsonb collumns are also snake_case\nBe sure to not use booleans for fields, use smallint 0/1 \nBe sure to ask if its a public or internal object before starting\nBe sure to ask any other questions about fields before starting\nBe sure to add the controller to the router `./internal/controllers/router.go`\nBe sure to add the model to the loader `./internal/models/loader.go`\n\nBe sure to follow best practices with the model structure, \nfunctions in `functions.go`\nqueries in `queries.go`\nBe sure jsonb are not just map[string]any and are actually a struct\nsub structs in their own my_sub_struct.go file\nconstants in their own `my_constant_name.go` file within the same package, keep the files pure by what they are doing\n\n\n\n\n\n",
        "plugins/backend/commands/ralph-planner.md": "---\nname: Ralph Planner\ndescription: Use to build out specs for Ralph Wiggum features including requirements, design, and task lists optimized for iterative AI execution loops.\n\n---\n### 1. Requirement Gathering\n\nFirst, generate an initial set of requirements in EARS format based on the feature idea, then iterate with the user to refine them until they are complete and accurate.\n\nDon't focus on code exploration in this phase. Instead, just focus on writing requirements which will later be turned into\na design.\n\n**Constraints:**\n\n- The model MUST create a '.agents/specs/{feature_name}/requirements.md' file if it doesn't already exist\n- The model MUST generate an initial version of the requirements document based on the user's rough idea WITHOUT asking sequential questions first\n- The model MUST format the initial requirements.md document with:\n  - A clear introduction section that summarizes the feature\n  - A hierarchical numbered list of requirements where each contains:\n    - A user story in the format \"As a [role], I want [feature], so that [benefit]\"\n    - A numbered list of acceptance criteria in EARS format (Easy Approach to Requirements Syntax)\n  - Example format:\n[includes example format here]\n- The model SHOULD consider edge cases, user experience, technical constraints, and success criteria in the initial requirements\n- After updating the requirement document, the model MUST ask the user \"Do the requirements look good? If so, we can move on to the design.\" using the 'userInput' tool.\n- The 'userInput' tool MUST be used with the exact string 'spec-requirements-review' as the reason\n- The model MUST make modifications to the requirements document if the user requests changes or does not explicitly approve\n- The model MUST ask for explicit approval after every iteration of edits to the requirements document\n- The model MUST NOT proceed to the design document until receiving clear approval (such as \"yes\", \"approved\", \"looks good\", etc.)\n- The model MUST continue the feedback-revision cycle until explicit approval is received\n- The model SHOULD suggest specific areas where the requirements might need clarification or expansion\n- The model MAY ask targeted questions about specific aspects of the requirements that need clarification\n- The model MAY suggest options when the user is unsure about a particular aspect\n- The model MUST proceed to the design phase after the user accepts the requirements\n\n\n\n### 2. Create Feature Design Document\n\nAfter the user approves the Requirements, you should develop a comprehensive design document based on the feature requirements, conducting necessary research during the design process.\nThe design document should be based on the requirements document, so ensure it exists first.\n\n**Constraints:**\n\n- The model MUST create a '.agents/specs/{feature_name}/design.md' file if it doesn't already exist\n- The model MUST identify areas where research is needed based on the feature requirements\n- The model MUST conduct research and build up context in the conversation thread\n- The model SHOULD NOT create separate research files, but instead use the research as context for the design and implementation plan\n- The model MUST summarize key findings that will inform the feature design\n- The model SHOULD cite sources and include relevant links in the conversation\n- The model MUST create a detailed design document at '.agents/specs/{feature_name}/design.md'\n- The model MUST incorporate research findings directly into the design process\n- The model MUST include the following sections in the design document:\n  - Overview\n  - Architecture\n  - Components and Interfaces\n  - Data Models\n  - Error Handling\n  - Testing Strategy\n- The model SHOULD include diagrams or visual representations when appropriate (use Mermaid for diagrams if applicable)\n- The model MUST ensure the design addresses all feature requirements identified during the clarification process\n- The model SHOULD highlight design decisions and their rationales\n- The model MAY ask the user for input on specific technical decisions during the design process\n- After updating the design document, the model MUST ask the user \"Does the design look good? If so, we can move on to the implementation plan.\" using the 'userInput' tool.\n- The 'userInput' tool MUST be used with the exact string 'spec-design-review' as the reason\n- The model MUST make modifications to the design document if the user requests changes or does not explicitly approve\n- The model MUST ask for explicit approval after every iteration of edits to the design document\n- The model MUST NOT proceed to the implementation plan until receiving clear approval (such as \"yes\", \"approved\", \"looks good\", etc.)\n- The model MUST continue the feedback-revision cycle until explicit approval is received\n- The model MUST incorporate all user feedback into the design document before proceeding\n- The model MUST offer to return to feature requirements clarification if gaps are identified during design\n\n\n\n### 3. Create Task List\n\nAfter the user approves the Design, create an actionable implementation plan with a checklist of coding tasks based on the requirements and design.\nThe tasks document should be based on the design document, so ensure it exists first.\n\n**Constraints:**\n\n- The model MUST create a '.agents/specs/{feature_name}/tasks.md' file if it doesn't already exist\n- The model MUST return to the design step if the user indicates any changes are needed to the design\n- The model MUST return to the requirement step if the user indicates that we need additional requirements\n- The model MUST create an implementation plan at '.agents/specs/{feature_name}/tasks.md'\n- The model MUST use the following specific instructions when creating the implementation plan:\n  ```\n  Convert the feature design into a series of prompts for Ralph Wiggum - a self-referential AI development loop that iterates until completion. Each task must be formatted for autonomous execution with clear success criteria and automatic verification. Prioritize test-driven development, incremental progress, and self-correction loops. Ensure no big jumps in complexity at any stage. Each prompt should build on previous work and include verification steps. Focus ONLY on tasks that involve writing, modifying, or testing code.\n  ```\n- The model MUST format the implementation plan as a numbered checkbox list with a maximum of two levels of hierarchy:\n  - Top-level items (like epics) should be used only when needed\n  - Sub-tasks should be numbered with decimal notation (e.g., 1.1, 1.2, 2.1)\n  - Each item must be a checkbox\n  - Simple structure is preferred\n- The model MUST ensure each task item includes:\n  - A clear objective as the task description that involves writing, modifying, or testing code\n  - Explicit success criteria that can be verified automatically (e.g., \"tests pass\", \"linter reports no errors\", \"specific output appears\")\n  - Verification steps that Ralph can execute autonomously (e.g., \"run tests\", \"check lint output\", \"verify file exists\")\n  - Self-correction instructions (e.g., \"if tests fail, debug and fix\", \"if validation errors occur, refactor\")\n  - A completion signal or exit condition (e.g., \"all tests green\", \"no lint errors\", \"feature working as specified\")\n  - Additional information as sub-bullets under the task\n  - Specific references to requirements from the requirements document (referencing granular sub-requirements, not just user stories)\n- The model MUST ensure that the implementation plan is a series of discrete, manageable coding steps\n- The model MUST ensure each task references specific requirements from the requirement document\n- The model MUST NOT include excessive implementation details that are already covered in the design document\n- The model MUST assume that all context documents (feature requirements, design) will be available during implementation\n- The model MUST ensure each step builds incrementally on previous steps\n- The model SHOULD prioritize test-driven development where appropriate\n- The model MUST ensure the plan covers all aspects of the design that can be implemented through code\n- The model SHOULD sequence steps to validate core functionality early through code\n- The model MUST ensure that all requirements are covered by the implementation tasks\n- The model MUST offer to return to previous steps (requirements or design) if gaps are identified during implementation planning\n- The model MUST structure tasks for Ralph Wiggum's iterative execution model:\n  - Each task should be self-contained enough for autonomous execution\n  - Tasks should include automatic verification mechanisms (tests, linters, type checks)\n  - Tasks should specify what to do when verification fails (self-correction loops)\n  - Tasks should avoid requiring human judgment or design decisions\n  - Tasks should build on previous work visible in files and git history\n  - Complex tasks should be broken into phases with verification at each phase\n  - Each task should specify an escape condition if the task cannot be completed (e.g., \"if stuck after 3 attempts, document blockers and skip\")\n- The model MUST ONLY include tasks that can be performed by a coding agent (writing code, creating tests, etc.)\n- The model MUST NOT include tasks related to user testing, deployment, performance metrics gathering, or other non-coding activities\n- The model MUST focus on code implementation tasks that can be executed within the development environment\n- The model MUST ensure each task is actionable by a coding agent by following these guidelines:\n  - Tasks should involve writing, modifying, or testing specific code components\n  - Tasks should specify what files or components need to be created or modified\n  - Tasks should be concrete enough that a coding agent can execute them without additional clarification\n  - Tasks should focus on implementation details rather than high-level concepts\n  - Tasks should be scoped to specific coding activities (e.g., \"Implement X function\" rather than \"Support X feature\")\n- The model MUST format each task following this Ralph Wiggum-optimized structure:\n  ```\n  ## Task N: [Clear Task Objective]\n  \n  **Requirements:** [Reference specific requirements from requirements.md]\n  \n  **Implementation:**\n  1. [First step with specific files/components]\n  2. [Second step with specific files/components]\n  3. Write/update tests to verify behavior\n  \n  **Verification:**\n  - Run tests: `[specific test command]`\n  - Expected: [specific success criteria - e.g., \"all tests pass\", \"0 errors\"]\n  - Run linter: `[specific lint command]`\n  - Expected: [specific success criteria]\n  \n  **Self-Correction:**\n  - If tests fail: Review error output, fix implementation, re-run tests\n  - If lint errors: Fix issues, re-run linter\n  - If compilation errors: Fix syntax/type errors, re-compile\n  \n  **Completion Criteria:**\n  - [ ] All tests passing\n  - [ ] No lint errors\n  - [ ] [Any other automatic verification]\n  \n  **Escape Condition:** If stuck after 3 iterations, document the blocker and move to next task.\n  ```\n- The model MUST explicitly avoid including the following types of non-coding tasks in the implementation plan:\n  - User acceptance testing or user feedback gathering\n  - Deployment to production or staging environments\n  - Performance metrics gathering or analysis\n  - Running the application to test end to end flows. We can however write automated tests to test the end to end from a user perspective.\n  - User training or documentation creation\n  - Business process changes or organizational changes\n  - Marketing or communication activities\n  - Any task that cannot be completed through writing, modifying, or testing code\n- After updating the tasks document, the model MUST ask the user \"Do the tasks look good?\" using the 'userInput' tool.\n- The 'userInput' tool MUST be used with the exact string 'spec-tasks-review' as the reason\n- The model MUST make modifications to the tasks document if the user requests changes or does not explicitly approve.\n- The model MUST ask for explicit approval after every iteration of edits to the tasks document.\n- The model MUST NOT consider the workflow complete until receiving clear approval (such as \"yes\", \"approved\", \"looks good\", etc.).\n- The model MUST continue the feedback-revision cycle until explicit approval is received.\n- The model MUST stop once the task document has been approved.\n\n**This workflow is ONLY for creating design and planning artifacts. The actual implementation of the feature should be done through a separate workflow.**\n\n- The model MUST NOT attempt to implement the feature as part of this workflow\n- The model MUST clearly communicate to the user that this workflow is complete once the design and planning artifacts are created\n- The model MUST inform the user that tasks are optimized for Ralph Wiggum execution with:\n  - Clear completion criteria for autonomous verification\n  - Self-correction loops for iterative improvement\n  - Automatic verification steps (tests, linters, etc.)\n  - Escape conditions to prevent infinite loops\n- The model MUST inform the user that they can begin executing tasks by opening the tasks.md",
        "plugins/backend/commands/review-session.md": "---\nname: review-session\ndescription: Preview what learnings would be captured from current session without creating files\nallowed-tools: [\"Task\"]\n---\n\n# Review Session Command\n\nPreview what learnings would be captured from the current session without actually creating or modifying any skill files.\n\n## Usage\n\n```\n/review-session\n```\n\nThis command runs the learning analyzer in **preview mode** to show what would be captured without writing any files or staging changes.\n\n## What This Command Does\n\n1. **Analyzes current session** for valuable patterns and learnings\n2. **Identifies relevant skills** - shows which would be created or updated\n3. **Generates preview** of skill content without writing files\n4. **Provides summary** of findings without making changes\n5. **No file modifications** - completely safe to run anytime\n\n## Output Format\n\nThe command provides:\n\n**Analysis Summary:**\n- Overall assessment of session value\n- Quality threshold check result\n- Number of learnings identified\n\n**Skills Preview:**\n- List of skills that would be created (with names and descriptions)\n- List of existing skills that would be updated (with change summaries)\n- Draft content preview showing key sections\n\n**Key Learnings:**\n- Bullet points of patterns identified\n- Techniques or approaches discovered\n- Insights worth capturing\n\n**Recommendations:**\n- Whether capturing is worthwhile\n- Suggestions for improving learnings\n- Alternative actions if session too trivial\n\n## When to Use\n\n**Use this command when:**\n- You want to see what would be captured before committing\n- Checking if session has valuable learnings\n- Evaluating quality before running /capture-learning\n- Curious about what the analyzer would extract\n- Before session ends to preview SessionEnd hook behavior\n\n**Especially useful:**\n- Before creating a PR (see what skills would be included)\n- After working on complex problems (validate learnings are captured well)\n- When unsure if session warrants skill creation\n\n## Preview vs. Capture\n\n| /review-session | /capture-learning |\n|-----------------|-------------------|\n| No files written | Creates/updates skills |\n| No git staging | Stages changes (if enabled) |\n| Safe to run anytime | Modifies repository |\n| Shows preview only | Commits to creating skills |\n| Can run multiple times | Should run when ready |\n\n## Example Workflow\n\n```\n# 1. Work on problem and solve it\n[development work happens]\n\n# 2. Preview what would be captured\n/review-session\n\n# 3. Review the output\n# - Are the learnings valuable?\n# - Are the skills well-structured?\n# - Should anything be adjusted?\n\n# 4. If satisfied, capture for real\n/capture-learning\n\n# 5. Verify with git\ngit status\ngit diff .claude/skills/\n```\n\n## Configuration\n\nUses the same settings as /capture-learning:\n\n- **skills_path** - Shows where skills would be created\n- **quality_threshold** - Applied during analysis\n- Settings from `.claude/session-learner.local.md`\n\n**Note:** Always runs in dry-run mode regardless of settings file.\n\n## Instructions\n\nWhen this command is invoked:\n\n1. Invoke the learning-analyzer agent using the Task tool with explicit preview instructions:\n   ```\n   agent learning-analyzer \"Analyze current session in PREVIEW MODE. Show what learnings would be captured and what skills would be created/updated, but DO NOT write any files or stage any changes. Provide a detailed summary for review.\"\n   ```\n\n2. The agent will:\n   - Analyze the session\n   - Identify learnings\n   - Generate skill previews\n   - Report findings without modifying files\n\n3. Display the agent's preview output to the user\n\n**Important:** Ensure the agent knows this is preview mode. The agent should analyze and report but not create files or stage changes.\n\n## Output Example\n\n```\n## Session Learning Preview\n\n**Analysis Result:** Found 2 valuable patterns worth capturing\n\n**Quality Check:** ‚úÖ Passed (session had 15 tool calls, 8 minutes of technical work)\n\n**Skills That Would Be Created:**\n\n1. **api-rate-limit-handling** (v1.0.0)\n   - Location: .claude/skills/api-rate-limit-handling/SKILL.md\n   - Content: Patterns for detecting and handling API rate limits with exponential backoff\n   - Sections: Overview, Detection Strategies, Backoff Algorithms, Code Examples\n\n**Skills That Would Be Updated:**\n\n1. **error-handling-patterns** (v1.0.1 ‚Üí v1.0.2)\n   - Location: .claude/skills/error-handling-patterns/SKILL.md\n   - Changes: Add section on retry logic with circuit breaker pattern\n   - New examples: Circuit breaker implementation from today's work\n\n**Key Learnings:**\n- API rate limiting detection pattern (check response headers + status codes)\n- Exponential backoff with jitter to avoid thundering herd\n- Circuit breaker pattern for failing gracefully after repeated failures\n\n**Recommendation:** ‚úÖ Worth capturing - these are reusable patterns applicable to future API integration work\n\n**Next Steps:**\n- Run `/capture-learning` to create these skills\n- Or adjust session work and re-run `/review-session`\n```\n\n## Tips\n\n- **Run before creating PR** to see what knowledge will be documented\n- **Use to validate quality** before actually capturing\n- **Iterate if needed** - do more work and review again\n- **Compare with /capture-learning** output to verify consistency\n\n## Related Commands\n\n- `/capture-learning` - Actually create the skills shown in preview\n- `/git-status` - Check repository status (preview doesn't modify)\n- `/git-diff` - View changes (preview has none)\n",
        "plugins/backend/commands/subagent-planner.md": "---\nname: Subagent Planner\ndescription: Use to build out specs\n\n---\n\n### 1. Requirement Gathering\n\nFirst, generate an initial set of requirements in EARS format based on the feature idea, then iterate with the user to refine them until they are complete and accurate.\n\nDon't focus on code exploration in this phase. Instead, just focus on writing requirements which will later be turned into\na design.\n\n**Constraints:**\n\n- The model MUST create a '.agents/specs/{feature_name}/requirements.md' file if it doesn't already exist\n- The model MUST generate an initial version of the requirements document based on the user's rough idea WITHOUT asking sequential questions first\n- The model MUST format the initial requirements.md document with:\n  - A clear introduction section that summarizes the feature\n  - A hierarchical numbered list of requirements where each contains:\n    - A user story in the format \"As a [role], I want [feature], so that [benefit]\"\n    - A numbered list of acceptance criteria in EARS format (Easy Approach to Requirements Syntax)\n  - Example format:\n[includes example format here]\n- The model SHOULD consider edge cases, user experience, technical constraints, and success criteria in the initial requirements\n- After updating the requirement document, the model MUST ask the user \"Do the requirements look good? If so, we can move on to the design.\" using the 'userInput' tool.\n- The 'userInput' tool MUST be used with the exact string 'spec-requirements-review' as the reason\n- The model MUST make modifications to the requirements document if the user requests changes or does not explicitly approve\n- The model MUST ask for explicit approval after every iteration of edits to the requirements document\n- The model MUST NOT proceed to the design document until receiving clear approval (such as \"yes\", \"approved\", \"looks good\", etc.)\n- The model MUST continue the feedback-revision cycle until explicit approval is received\n- The model SHOULD suggest specific areas where the requirements might need clarification or expansion\n- The model MAY ask targeted questions about specific aspects of the requirements that need clarification\n- The model MAY suggest options when the user is unsure about a particular aspect\n- The model MUST proceed to the design phase after the user accepts the requirements\n\n\n\n### 2. Create Feature Design Document\n\nAfter the user approves the Requirements, you should develop a comprehensive design document based on the feature requirements, conducting necessary research during the design process.\nThe design document should be based on the requirements document, so ensure it exists first.\n\n**Constraints:**\n\n- The model MUST create a '.agents/specs/{feature_name}/design.md' file if it doesn't already exist\n- The model MUST identify areas where research is needed based on the feature requirements\n- The model MUST conduct research and build up context in the conversation thread\n- The model SHOULD NOT create separate research files, but instead use the research as context for the design and implementation plan\n- The model MUST summarize key findings that will inform the feature design\n- The model SHOULD cite sources and include relevant links in the conversation\n- The model MUST create a detailed design document at '.agents/specs/{feature_name}/design.md'\n- The model MUST incorporate research findings directly into the design process\n- The model MUST include the following sections in the design document:\n  - Overview\n  - Architecture\n  - Components and Interfaces\n  - Data Models\n  - Error Handling\n  - Testing Strategy\n- The model SHOULD include diagrams or visual representations when appropriate (use Mermaid for diagrams if applicable)\n- The model MUST ensure the design addresses all feature requirements identified during the clarification process\n- The model SHOULD highlight design decisions and their rationales\n- The model MAY ask the user for input on specific technical decisions during the design process\n- After updating the design document, the model MUST ask the user \"Does the design look good? If so, we can move on to the implementation plan.\" using the 'userInput' tool.\n- The 'userInput' tool MUST be used with the exact string 'spec-design-review' as the reason\n- The model MUST make modifications to the design document if the user requests changes or does not explicitly approve\n- The model MUST ask for explicit approval after every iteration of edits to the design document\n- The model MUST NOT proceed to the implementation plan until receiving clear approval (such as \"yes\", \"approved\", \"looks good\", etc.)\n- The model MUST continue the feedback-revision cycle until explicit approval is received\n- The model MUST incorporate all user feedback into the design document before proceeding\n- The model MUST offer to return to feature requirements clarification if gaps are identified during design\n- The model MUST use context-fetcher to gather as much sample code and documentation as possible about the codebase being modified for this specific feature.\n\n\n\n### 3. Create Task List\n\nAfter the user approves the Design, create an actionable implementation plan with a checklist of coding tasks based on the requirements and design.\nThe tasks document should be based on the design document, so ensure it exists first.\n\n**Constraints:**\n\n- The model MUST create a '.agents/specs/{feature_name}/tasks.md' file if it doesn't already exist\n- The model MUST return to the design step if the user indicates any changes are needed to the design\n- The model MUST return to the requirement step if the user indicates that we need additional requirements\n- The model MUST create an implementation plan at '.agents/specs/{feature_name}/tasks.md'\n- The model MUST reference all of the core documentation i.e. whats in CLAUDE.md / AGENTS.md to make sure they are read first.\n- The model MUST add a Learnings section at the end of the tasks.md file for sub agents to capture any new information discovered during the implementation process that may impact future tasks.\n- The model MUST use the following specific instructions when creating the implementation plan:\n  ```\n  Convert the feature design into a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step. Focus ONLY on tasks that involve writing, modifying, or testing code.\n  ```\n- The model MUST format the implementation plan as a numbered checkbox list with a maximum of two levels of hierarchy:\n  - Top-level items (like epics) should be used only when needed\n  - Sub-tasks should be numbered with decimal notation (e.g., 1.1, 1.2, 2.1)\n  - Each item must be a checkbox\n  - Simple structure is preferred\n- The model MUST ensure each task item includes:\n  - A clear objective as the task description that involves writing, modifying, or testing code\n  - Additional information as sub-bullets under the task\n  - Specific references to requirements from the requirements document (referencing granular sub-requirements, not just user stories)\n- The model MUST ensure that the implementation plan is a series of discrete, manageable coding steps\n- The model MUST ensure each task references specific requirements from the requirement document\n- The model MUST NOT include excessive implementation details that are already covered in the design document\n- The model MUST assume that all context documents (feature requirements, design) will be available during implementation\n- The model MUST ensure each step builds incrementally on previous steps\n- The model SHOULD prioritize test-driven development where appropriate\n- The model MUST ensure the plan covers all aspects of the design that can be implemented through code\n- The model SHOULD sequence steps to validate core functionality early through code\n- The model MUST ensure that all requirements are covered by the implementation tasks\n- The model MUST offer to return to previous steps (requirements or design) if gaps are identified during implementation planning\n- The model MUST ONLY include tasks that can be performed by a coding agent (writing code, creating tests, etc.)\n- The model MUST NOT include tasks related to user testing, deployment, performance metrics gathering, or other non-coding activities\n- The model MUST focus on code implementation tasks that can be executed within the development environment\n- The model MUST ensure each task is actionable by a coding agent by following these guidelines:\n  - Tasks should involve writing, modifying, or testing specific code components\n  - Tasks should specify what files or components need to be created or modified\n  - Tasks should be concrete enough that a coding agent can execute them without additional clarification\n  - Tasks should focus on implementation details rather than high-level concepts\n  - Tasks should be scoped to specific coding activities (e.g., \"Implement X function\" rather than \"Support X feature\")\n- The model MUST explicitly avoid including the following types of non-coding tasks in the implementation plan:\n  - User acceptance testing or user feedback gathering\n  - Deployment to production or staging environments\n  - Performance metrics gathering or analysis\n  - Running the application to test end to end flows. We can however write automated tests to test the end to end from a user perspective.\n  - User training or documentation creation\n  - Business process changes or organizational changes\n  - Marketing or communication activities\n  - Any task that cannot be completed through writing, modifying, or testing code\n- After updating the tasks document, the model MUST ask the user \"Do the tasks look good?\" using the 'userInput' tool.\n- The 'userInput' tool MUST be used with the exact string 'spec-tasks-review' as the reason\n- The model MUST make modifications to the tasks document if the user requests changes or does not explicitly approve.\n- The model MUST ask for explicit approval after every iteration of edits to the tasks document.\n- The model MUST NOT consider the workflow complete until receiving clear approval (such as \"yes\", \"approved\", \"looks good\", etc.).\n- The model MUST continue the feedback-revision cycle until explicit approval is received.\n- The model MUST stop once the task document has been approved.\n\n### 4. Include Sub-Agent Delegation Instructions\n\nWhen creating the tasks.md file, if the implementation plan contains more than 3 tasks, the model MUST include comprehensive sub-agent delegation instructions at the top of the tasks document.\n\n### 5. Failure Handling\n- The model MUST add in **Failure Handling** instructions for sub-agents in the delegation section of tasks.md.  If a sub agent cant accomplish its task due to permissions or tools or any reason, it MUST:\n  1. Clearly document the failure in the Learnings section of tasks.md\n  2. Mark the task as failed in the progress tracking section\n  3. NOT attempt to re-run or fix the task itself\n  4. Alert the main agent to stop the workflow and inform the user of the failure\n\n\n**Constraints:**\n\n- The model MUST add a section titled \"CRITICAL: Task Execution Instructions for Main Agent\" at the beginning of tasks.md\n- The model MUST clearly state: \"DO NOT IMPLEMENT TASKS YOURSELF. Your role is to delegate each task to a specialized sub-agent, one task at a time.\"\n- The model MUST include a \"Task Delegation Process\" with these requirements:\n  1. Work Sequentially: Execute tasks in order\n  2. One Task Per Sub-Agent: Launch a new sub-agent for each individual task\n  3. Complete Context: Provide the sub-agent with ALL necessary context\n  4. Wait for Completion: Do not move to next task until current sub-agent completes\n  5. Track Progress: Mark tasks as complete after sub-agent finishes\n- The model MUST include a \"Sub-Agent Prompt Template\" that ensures each sub-agent receives:\n  - The specific task description from tasks.md\n  - Requirements this task satisfies\n  - All necessary file paths to read for context (AGENTS.md, instructions, design.md, requirements.md, etc.)\n  - Existing implementation patterns to follow (reference files like contact.go, etc.)\n  - The mandatory TDD workflow (RED ‚Üí GREEN ‚Üí REFACTOR ‚Üí COMMIT)\n  - Critical patterns to follow (pointer fields, error handling, method signatures, etc.)\n  - Success criteria (tests pass, code quality, coverage, documentation)\n  - Clear deliverable expectations\n- The model MUST provide an example sub-agent invocation showing how to use the `runSubagent` tool\n- The model MUST include progress tracking instructions for after each sub-agent completes\n- The model SHOULD adapt the template based on the technology stack (Go, React, etc.) and project-specific patterns\n- The model MUST ensure sub-agents have all context needed to work independently without asking follow-up questions\n- The sub-agent template MUST emphasize reading all relevant documentation and existing code BEFORE starting implementation\n- The sub-agent template MUST include project-specific best practices and patterns from AGENTS.md or similar files\n- The model SHOULD include specific file paths that sub-agents need to read based on the project structure\n- The model MUST ensure the delegation strategy prevents any single agent from doing all the work\n- The model MUST ensure that sub agents add to the task list section of Learnings if they discover new information that impacts future tasks\n- The model MUST ensure that the main agent has a clear success criteria for when the workflow is complete\n\n**This workflow is ONLY for creating design and planning artifacts. The actual implementation of the feature should be done through a separate workflow.**\n\n- The model MUST NOT attempt to implement the feature as part of this workflow\n- The model MUST clearly communicate to the user that this workflow is complete once the design and planning artifacts are created\n- The model MUST inform the user that they can begin executing tasks by opening the tasks.md file, and clicking \"Start task\" next to task items.",
        "plugins/backend/hooks/hooks.json": "{\n  \"description\": \"Session learning capture hooks for compound engineering\",\n  \"hooks\": {\n    \"Stop\": [\n      {\n        \"matcher\": \"*\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"bash $CLAUDE_PLUGIN_ROOT/hooks/scripts/capture-session-learnings.sh\",\n            \"timeout\": 300\n          }\n        ]\n      }\n    ]\n  }\n}\n",
        "plugins/backend/hooks/scripts/capture-session-learnings.sh": "#!/bin/bash\nset -euo pipefail\n\n# Stop hook script that captures learnings before session ends\n# This script runs SYNCHRONOUSLY and blocks session ending until complete\n# Works in CI/CD environments where background processes would be killed\n\n# Read hook input from stdin\ninput=$(cat)\n\n# Extract session info\nsession_id=$(echo \"$input\" | jq -r '.session_id // \"unknown\"')\ntranscript_path=$(echo \"$input\" | jq -r '.transcript_path // \"\"')\ncwd=$(echo \"$input\" | jq -r '.cwd // \".\"')\n\n# Read configuration if it exists\nconfig_file=\"$CLAUDE_PROJECT_DIR/.claude/session-learner.local.md\"\nquality_threshold=\"true\"\ndry_run=\"false\"\nskills_path=\".claude/skills/\"\n\nif [ -f \"$config_file\" ]; then\n  # Extract YAML frontmatter values\n  quality_threshold=$(sed -n '/^---$/,/^---$/p' \"$config_file\" | grep \"quality_threshold:\" | awk '{print $2}' 2>/dev/null || echo \"true\")\n  dry_run=$(sed -n '/^---$/,/^---$/p' \"$config_file\" | grep \"dry_run:\" | awk '{print $2}' 2>/dev/null || echo \"false\")\n  skills_path=$(sed -n '/^---$/,/^---$/p' \"$config_file\" | grep \"skills_path:\" | awk '{print $2}' 2>/dev/null | tr -d '\"' || echo \".claude/skills/\")\nfi\n\n# Quick quality check - if session is trivial, skip immediately\nif [ \"$quality_threshold\" = \"true\" ]; then\n  # Check if transcript exists and has reasonable size\n  if [ -n \"$transcript_path\" ] && [ -f \"$transcript_path\" ]; then\n    # Count lines in transcript as rough proxy for session complexity\n    line_count=$(wc -l < \"$transcript_path\" 2>/dev/null || echo \"0\")\n\n    # Skip if transcript is too short (< 50 lines = very brief session)\n    if [ \"$line_count\" -lt 50 ]; then\n      echo \"{\n        \\\"decision\\\": \\\"approve\\\",\n        \\\"reason\\\": \\\"Session too brief for learning capture (${line_count} lines)\\\",\n        \\\"systemMessage\\\": \\\"Session ending. No learnings captured (session too brief).\\\"\n      }\" | jq -c .\n      exit 0\n    fi\n  fi\nfi\n\n# If dry_run mode, skip actual capture but show what would happen\nif [ \"$dry_run\" = \"true\" ]; then\n  echo \"{\n    \\\"decision\\\": \\\"approve\\\",\n    \\\"reason\\\": \\\"Dry-run mode enabled\\\",\n    \\\"systemMessage\\\": \\\"Session ending. Dry-run mode: would have captured learnings to $skills_path\\\"\n  }\" | jq -c .\n  exit 0\nfi\n\n# Build analysis prompt for the agent\nanalysis_prompt=\"Analyze this session and create skills from learnings.\n\nSession Info:\n- Session ID: $session_id\n- Transcript: $transcript_path\n- Working Directory: $cwd\n\nInstructions:\n1. Read the session transcript to understand what was worked on\n2. Check git status and git diff to see what changed\n3. Identify valuable learnings (debugging patterns, architecture decisions, gotchas discovered)\n4. Apply quality threshold: skip if session was trivial (just typo fixes, reading docs, no problem-solving)\n5. Use smart merge: update existing skills in $skills_path or create new ones\n6. If not run manually, stage changes with git add for PR inclusion\n7. Provide brief summary of what was captured\n\nConfiguration:\n- Skills path: $skills_path\n- This is running in Stop hook - be efficient and complete quickly\n\nIMPORTANT: If session has no valuable learnings, just say so and exit quickly. Don't force creation of low-quality skills.\"\n\n# Run learning capture SYNCHRONOUSLY (blocking)\n# Session won't end until this completes\ncapture_output=$(cd \"$cwd\" && claude agent learning-analyzer \"$analysis_prompt\" 2>&1 | head -100)\n\n# Log output for debugging\nif [ -n \"$capture_output\" ]; then\n  echo \"$capture_output\" > /tmp/session-learning-$session_id.log 2>&1 || true\nfi\n\n# Always approve stopping after capture completes\necho \"{\n  \\\"decision\\\": \\\"approve\\\",\n  \\\"reason\\\": \\\"Learning capture completed\\\",\n  \\\"systemMessage\\\": \\\"Session ending. Learning capture completed - check $skills_path for new/updated skills.\\\"\n}\" | jq -c .\n\nexit 0\n",
        "plugins/backend/skills/controller-generation/SKILL.md": "---\nname: controller-generation\ndescription: Code generation for CRUD endpoints\n---\n\n# Controller Code Generation\n\nThe system uses `core_generate` to automatically create standard CRUD operations for controllers.\n\n## Code Generation Command\n\nAdd this directive to the controller folders `setup.go` file:\n\n```go\n//go:generate core_gen controller Account -modelPackage=account\n```\n\n**Parameters:**\n- `controller` - Command type\n- `Account` - Model name (PascalCase)\n- `-modelPackage=account` - Package name containing the model\n- `-options=admin` if its an admin only controller\n- `-skip=xxxYYY,aaaBBB` skip generating this function because we need to customize it\n\n## Generated Files\n\nRunning `go generate` creates two files:\n\n**`x_gen_admin.go`** - Admin CRUD handlers:\n- `adminIndex` - List all resources\n- `adminGet` - Get single resource\n- `adminCreate` - Create new resource\n- `adminUpdate` - Update existing resource\n- `adminCount` - Get total count\n\n(optionally)\n**`x_gen_auth.go`** - Public CRUD handlers:\n- `authIndex` - List resources (filtered to user's data)\n- `authGet` - Get single resource (with ownership check)\n- `authCreate` - Create new resource\n- `authUpdate` - Update resource (with ownership check)\n\n## Generated Endpoints\n\n| Method | Admin Route | Public Route | Function | Description |\n|--------|-------------|--------------|----------|-------------|\n| GET | `/admin/account` | `/account` | `adminIndex`, `authIndex` | List resources |\n| GET | `/admin/account/{id}` | `/account/{id}` | `adminGet`, `authGet` | Get single resource |\n| POST | `/admin/account` | `/account` | `adminCreate`, `authCreate` | Create new resource |\n| PUT | `/admin/account/{id}` | `/account/{id}` | `adminUpdate`, `authUpdate` | Update resource |\n| GET | `/admin/account/count` | - | `adminCount` | Get total count |\n| GET | `/admin/account/_ts` | - | TypeScript | TS type generation |\n\n## Skipping Endpoints\n\nYou can disable specific endpoints using the `-skip` parameter:\n\n```go\n//go:generate core_gen controller AiTool -modelPackage=ai_tool -skip=authCreate,authUpdate\n```\n\nThis will generate all endpoints except `authCreate` and `authUpdate`.\n\n**Available Skip Options:**\n- `adminIndex` - Skip admin list endpoint\n- `adminGet` - Skip admin get endpoint\n- `adminCreate` - Skip admin create endpoint\n- `adminUpdate` - Skip admin update endpoint\n- `adminCount` - Skip admin count endpoint\n- `authIndex` - Skip public list endpoint\n- `authGet` - Skip public get endpoint\n- `authCreate` - Skip public create endpoint\n- `authUpdate` - Skip public update endpoint\n\n### Common Skip Patterns\n\n**Read-only public endpoint:**\n```go\n//go:generate core_gen controller Config -modelPackage=config -skip=authCreate,authUpdate\n```\n\n**Admin-only resource:**\n```go\n//go:generate core_gen controller SystemLog -modelPackage=system_log -options=admin\n```\n\n\n## Customizing Generated Code\n\n**DO NOT edit generated files directly.** They will be overwritten on next generation.\n\nInstead, create custom handlers in separate files, name them accordingly\nauth.go\nopen.go\nadmin.go\n\nif theres lots of functions, group them together by relation then use a prefix, auth_password.go auth_emails.go\n\n**custom_handlers.go:**\n```go\npackage account\n\nfunc customSearch(_ http.ResponseWriter, req *http.Request) ([]*account.Account, int, error) {\n    // Custom search logic here\n    // ...\n}\n```\n\nThen wire up in `setup.go`:\n\n```go\nr.Get(\"/search\", helpers.RoleHandler(helpers.RoleHandlerMap{\n    constants.ROLE_ANY_AUTHORIZED: response.StandardPublicRequestWrapper(customSearch),\n}))\n```\n\n## Regenerating Code\n\nRe-run generation after:\n- Updating skip parameters\n\n```bash\ngo generate path/to/file\n```\n\n## Related Skills\n\n- [controller-handlers](../controller-handlers/SKILL.md) - Writing custom handlers\n- [controller-roles](../controller-roles/SKILL.md) - Role-based access control\n\n\n## Additional resources\n- For usage examples, see [examples.md](examples.md)",
        "plugins/backend/skills/controller-handlers/SKILL.md": "---\nname: controller-handlers\ndescription: controller and API setup and basic patterns. Use when you need controller permissions, controller post data, controller params and queries, or setup a new controller or API route\n---\n\n# Writing Controller Handlers\n\nController handler functions follow a standardized pattern with consistent return types and error handling.\n\n## Handler Function Signature\n\nAll handler functions use this signature:\n\n```go\nfunc handlerName(_ http.ResponseWriter, req *http.Request) (*ModelType, int, error)\n```\n\n**Parameters:**\n- `_` - ResponseWriter (unused, handled by wrapper)\n- `req` - HTTP request with context, params, and body\n\n**Returns:**\n- `*ModelType/ResponseDataType` - The response data (nil on error)\n- `int` - HTTP status code (200, 400, 404, etc.)\n- `error` - Error object (nil on success)\n\n## Simple Handler Example\n\n```go\nfunc adminGet(_ http.ResponseWriter, req *http.Request) (*account.AccountJoined, int, error) {\n    // Get the URL parameter\n    id := chi.URLParam(req, \"id\")\n\n    // Fetch the model using the repository pattern\n    accountObj, err := account.GetJoined(req.Context(), types.UUID(id))\n    if err != nil {\n        log.ErrorContext(err, req.Context())\n        return helpers.AdminBadRequestError[*account.AccountJoined](err)\n    }\n\n    // Return success with the model data\n    return helpers.Success(accountObj)\n}\n```\n\n## Return Type Helpers\n\n### Success Response\n\n```go\nreturn helpers.Success(data)\n```\n\nReturns: `(data, http.StatusOK, nil)`\n\n### Admin Error Responses\n\nFor admin endpoints - returns full error details:\n\n```go\n// Bad request with error message\nreturn helpers.AdminBadRequestError[*ModelType](err)\n// Returns: (zeroValue, http.StatusBadRequest, err)\n\n// Not found\nreturn helpers.AdminNotFoundError[*ModelType]()\n// Returns: (zeroValue, http.StatusNotFound, standardError)\n\n// Forbidden\nreturn helpers.AdminForbiddenError[*ModelType]()\n// Returns: (zeroValue, http.StatusForbidden, standardError)\n```\n\n### Public Error Responses\n\nFor public endpoints - returns sanitized error messages:\n\n```go\n// Bad request (generic public error)\nreturn helpers.PublicBadRequestError[*ModelType]()\n// Returns: (zeroValue, http.StatusBadRequest, publicError)\n\n// Not found\nreturn helpers.PublicNotFoundError[*ModelType]()\n// Returns: (zeroValue, http.StatusNotFound, publicError)\n\n// Forbidden\nreturn helpers.PublicForbiddenError[*ModelType]()\n// Returns: (zeroValue, http.StatusForbidden, publicError)\n```\n\n**Important**: Public errors never expose internal error details to users.\n\n## Accessing Request Data\n\n### URL Parameters\n\n```go\n// Get URL parameter from route like /account/{id}\nid := chi.URLParam(req, \"id\")\nname := chi.URLParam(req, \"name\")\n```\n\n### Session Data\n\n```go\n// Get the current user session (available in all authenticated endpoints)\nuserSession := helpers.GetReqSession(req) // returns a session object\nuserObj := helpers.GetLoadedUser(req) // returns the actual user object, not a session wrap\n\n```\n\n### POST/PUT Request Body\n\n```go\n// For POST/PUT endpoints that are not the standard crud, use a struct for the input\ninput := &MyPostData{}\nerr := router.GetJSONPostDataStruct(req,input)\n\ndoSomething(input.SomeDataHere)\n```\n\n### Query Parameters\n\n```go\n// Access query string parameters\nqueryParams := req.URL.Query()\npage := queryParams.Get(\"page\")\nlimit := queryParams.Get(\"limit\")\n\n// embeeded route params\nid := chi.URLParam(req, \"id\")\n```\n\n## Common Handler Patterns\n## Error Logging\n\nAlways log errors with the context before returning up.  The controller is the log point.\n\n```go\nif err != nil {\n    log.ErrorContext(err, req.Context())\n    return helpers.AdminBadRequestError[*ModelType](err)\n}\n```\n\nThis ensures errors are captured in logs with full request context.\n\n## Handler Wrapper Usage\n\nHandlers are wrapped in `setup.go`:\n\n```go\n// Admin endpoint - shows full errors\nhelpers.RoleHandler(helpers.RoleHandlerMap{\n    constants.ROLE_ADMIN: response.StandardRequestWrapper(adminCreate),\n})\n\n// Public endpoint - sanitizes errors\nhelpers.RoleHandler(helpers.RoleHandlerMap{\n    constants.ROLE_ANY_AUTHORIZED: response.StandardPublicRequestWrapper(authGet),\n})\n```\n\n\n\n## Request Wrapper Types\n\n### StandardRequestWrapper (Admin)\n\nFor admin endpoints:\n```go\nresponse.StandardRequestWrapper(adminHandler)\n```\n\n**Features:**\n- Returns full error details\n- No field filtering\n- Detailed error messages for debugging\n\n### StandardPublicRequestWrapper (Public)\n\nFor public/authenticated user endpoints:\n```go\nresponse.StandardPublicRequestWrapper(authHandler)\n```\n\n**Features:**\n- Filters response fields based on `public:\"view\"` tags\n- Validates update fields based on `public:\"edit\"` tags\n- Returns sanitized error messages\n- Prevents internal error leakage\n\n## Security Best Practices\n\n1. **Use appropriate wrappers**: Admin handlers with `StandardRequestWrapper`, public handlers with `StandardPublicRequestWrapper`\n\n2. **Verify ownership**: In auth handlers, always verify the user owns the resource:\n```go\nif accountObj.ID_.Get() != session.AccountID {\n    return helpers.PublicForbiddenError[*account.Account]()\n}\n```\n\n3. **Principle of least privilege**: Use the lowest role required for each endpoint\n\n4. **Don't mix admin and public logic**: Keep admin and auth handlers separate\n\n## Related Skills\n\n- [controller-roles](../controller-roles/SKILL.md) - Role-based access control\n- [model-usage](../../model-usage/SKILL.md) - Working with models\n\n\n## Additional resources\n- For usage examples, see [examples.md](examples.md)",
        "plugins/backend/skills/controller-roles/SKILL.md": "---\nname: controller-roles\ndescription: Controller role handling.  Use when you need to setup a api endpoint with the right permissions and roles\n---\n\n# Role-Based Access Control\n\nThe `helpers.RoleHandler` function provides role-based access control by mapping roles to specific handler functions.\n\n## Basic Usage\n\n```go\nhelpers.RoleHandler(helpers.RoleHandlerMap{\n    constants.ROLE_READ_ADMIN: response.StandardRequestWrapper(adminGet),\n    constants.ROLE_ADMIN: response.StandardRequestWrapper(adminCreate),\n})\n```\n\n## Role Hierarchy\n\nRoles are defined as integer constants in descending order of privilege:\n\n| Role | Value | Description |\n|------|-------|-------------|\n| `ROLE_ADMIN` | 100 | Full system administrator access |\n| `ROLE_READ_ADMIN` | 90 | Read-only administrator access |\n| `ROLE_ANY_AUTHORIZED` | 0 | Any authenticated user |\n| `ROLE_UNAUTHORIZED` | -1 | Unauthenticated requests |\n\n## How RoleHandler Works\n\n1. **Extracts session** from request headers/cookies\n2. **Looks up user's role** from the database\n3. **Finds highest-privilege handler** the user can access\n4. **Falls back** to lower privilege handlers if exact role match isn't found\n5. **Returns 401 Unauthorized** if no suitable handler is found\n\n### Fallback Behavior\n\nIf a user's role doesn't exactly match a handler, the system checks lower-privilege handlers:\n\n```go\nhelpers.RoleHandler(helpers.RoleHandlerMap{\n    constants.ROLE_READ_ADMIN: response.StandardRequestWrapper(adminGet),\n    constants.ROLE_ANY_AUTHORIZED: response.StandardRequestWrapper(authGet),\n})\n```\n\n**Examples:**\n- User with `ROLE_ADMIN` (100) ‚Üí Uses `ROLE_READ_ADMIN` handler (fallback)\n- User with `ROLE_READ_ADMIN` (90) ‚Üí Uses `ROLE_READ_ADMIN` handler (exact match)\n- User with `ROLE_ANY_AUTHORIZED` (0) ‚Üí Uses `ROLE_ANY_AUTHORIZED` handler (exact match)\n- Unauthenticated user ‚Üí Returns 401 Unauthorized\n\n## Session Context\n\nThe `RoleHandler` automatically injects the session into the request context, making it available via:\n\n```go\nuserSession := helpers.GetReqSession(req)\n```\n\n**Session Fields:**\n```go\ntype Session struct {\n    User       coremodel.Model // thin wrapper over session data if you only need the users ID, i.e. sessionObj.User.ID(), or used to save data so we can track who saved it.\n\tLoadedUser any // fully loaded user from the database, dont access directly, use the helper.GetLoadedUser(req)\n}\n```\n\n## Common Role Patterns\n\n### Admin-Only Endpoints\n\nFull admin access required:\n\n```go\nr.Post(\"/\", helpers.RoleHandler(helpers.RoleHandlerMap{\n    constants.ROLE_ADMIN: response.StandardRequestWrapper(adminCreate),\n}))\n\nr.Put(\"/{id}\", helpers.RoleHandler(helpers.RoleHandlerMap{\n    constants.ROLE_ADMIN: response.StandardRequestWrapper(adminUpdate),\n}))\n\nr.Delete(\"/{id}\", helpers.RoleHandler(helpers.RoleHandlerMap{\n    constants.ROLE_ADMIN: response.StandardRequestWrapper(adminDelete),\n}))\n```\n\n### Read-Only Admin Access\n\nBoth full admins and read-only admins can access:\n\n```go\nr.Get(\"/\", helpers.RoleHandler(helpers.RoleHandlerMap{\n    constants.ROLE_READ_ADMIN: response.StandardRequestWrapper(adminIndex),\n}))\n\nr.Get(\"/{id}\", helpers.RoleHandler(helpers.RoleHandlerMap{\n    constants.ROLE_READ_ADMIN: response.StandardRequestWrapper(adminGet),\n}))\n\nr.Get(\"/count\", helpers.RoleHandler(helpers.RoleHandlerMap{\n    constants.ROLE_READ_ADMIN: response.StandardRequestWrapper(adminCount),\n}))\n```\n\n### Authenticated User Endpoints\n\nAny authenticated user can access:\n\n```go\nr.Get(\"/\", helpers.RoleHandler(helpers.RoleHandlerMap{\n    constants.ROLE_ANY_AUTHORIZED: response.StandardPublicRequestWrapper(authIndex),\n}))\n\nr.Get(\"/{id}\", helpers.RoleHandler(helpers.RoleHandlerMap{\n    constants.ROLE_ANY_AUTHORIZED: response.StandardPublicRequestWrapper(authGet),\n}))\n```\n\n### Mixed Role Handlers\n\nDifferent handlers for different roles on the same route:\n\n```go\nr.Get(\"/{id}\", helpers.RoleHandler(helpers.RoleHandlerMap{\n    constants.ROLE_ADMIN: response.StandardRequestWrapper(adminGetFull),\n    constants.ROLE_ANY_AUTHORIZED: response.StandardPublicRequestWrapper(authGetLimited),\n}))\n```\n\n**Example:**\n- Admin users ‚Üí Get full details via `adminGetFull`\n- Regular users ‚Üí Get limited details via `authGetLimited`\n\n\n\n## Related Skills\n- [controller-handlers](../controller-handlers/SKILL.md) - Writing handler functions\n- [controller-generation](../controller-generation/SKILL.md) - Code generation\n\n\n## Additional resources\n- For usage examples, see [examples.md](examples.md)",
        "plugins/backend/skills/db-new-column/SKILL.md": "---\nname: new-column\ndescription: database column setup.  Use when you need to create or update a database column\n---\n\n\nBe sure all database fields are snake_case\nBe sure all sub structs that are in jsonb collumns are also snake_case\nBe sure to not use booleans for fields, use smallint 0/1 \n\n\n## Struct Tag Annotations\n\n**Critical**: Struct tags control database migrations and constraints. Include all relevant tags:\n\n```go\nName     *fields.StringField `column:\"name\" type:\"text\" default:\"\":\"false\"`\nEmail    *fields.StringField `column:\"email\" type:\"text\" default:\"\" unique:\"true\"`\nAge      *fields.IntField    `column:\"age\" type:\"integer\" default:\"0\" null:\"true\"`\nStatus   *fields.IntConstantField[Status] `column:\"status\" type:\"smallint\" default:\"1\"`\nSettings *fields.StructField[*Settings] `column:\"settings\" type:\"jsonb\" default:\"{}\"`\n```\n\n### Available Tags:\n\n- `column:\"name\"` ‚Äì Database column name (required)\n- `type:\"text|jsonb|smallint|integer|uuid|date|datetime|bigint\"` ‚Äì Database column type (required) note that all 'boolean' type things should be a smallint 0/1\n- `default:\"value/null\"` ‚Äì Default value for column\n- `null:\"true\"` ‚Äì Whether column allows NULL, dont add if not nullable\n- `unique:\"true\"` ‚Äì Whether column has unique constraint, dont add if not unique\n- `index:\"true\"` ‚Äì Whether to create index on column, dont add if not indexed\n- `public:\"view|edit\"` - For public endpoints, determines whether or not the field is returned (view or edit) or on updates if its editable by the user (edit), dont add if not public facing\n- IMPORTANT - for all UUID fields, they must have `default:\"null\" null:\"true\"`\n\n\n\n## Field Types\n\n- `StringField` ‚Äì Text/string columns\n- `UUIDField` ‚Äì UUID columns\n- `IntField` ‚Äì Integer columns  / Bool fields with smallint 0/1 values\n- `DecimalField` ‚Äì Decimal/numeric columns\n- `IntConstantField[T]` ‚Äì Enum/constant fields\n- `StructField[T]` ‚Äì JSONB/struct columns\n\nAll fields provide `.Set(val)` and `.Get()` methods.  Struct fields have a `.GetI()` for when errors do not need to be checked\n\n## Additional resources\n- For usage examples, see [examples.md](examples.md)",
        "plugins/backend/skills/meta-learning/SKILL.md": "---\nname: meta-learning\ndescription: This skill should be used when analyzing development sessions to extract learnings, determining what constitutes valuable knowledge to capture, creating skills from session insights, or evaluating whether patterns are worth codifying for reuse.\nversion: 1.0.0\n---\n\n# Meta-Learning: Capturing Knowledge from Development Sessions\n\n## Overview\n\nMeta-learning is the practice of extracting reusable knowledge from development sessions and codifying it into skills. Not every session contains valuable learnings‚Äîthis skill provides criteria for identifying what's worth capturing and how to transform insights into effective skills.\n\n**Key principle:** Capture patterns and insights that will genuinely help future work. Quality over quantity.\n\n## Identifying Valuable Learnings\n\n### What Makes a Good Learning\n\nValuable learnings have these characteristics:\n\n1. **Reusable** - Applicable to future similar situations\n2. **Non-obvious** - Not common knowledge or easily discoverable\n3. **Pattern-based** - Demonstrates a technique, approach, or principle\n4. **Context-rich** - Includes the \"why\" behind decisions, not just \"what\" was done\n5. **Actionable** - Provides concrete steps or examples\n\n### Categories of Valuable Learnings\n\n**Debugging Patterns:**\n- Systematic approaches that worked (e.g., \"When API fails, check headers first, then payload format, then auth\")\n- Root cause identification techniques\n- Tool usage for diagnosis (e.g., using curl to isolate API issues)\n\n**Architecture Decisions:**\n- Trade-offs considered and chosen approach with rationale\n- Pattern selections (e.g., repository pattern for database access)\n- Structure decisions that solve specific problems\n\n**Framework/Library Patterns:**\n- Non-obvious usage patterns discovered\n- Common pitfalls and how to avoid them\n- Integration approaches that work well together\n- Configuration patterns for specific use cases\n\n**Testing Strategies:**\n- Effective test organization approaches\n- Mocking patterns that proved useful\n- Coverage strategies for specific scenarios\n\n**Domain Knowledge:**\n- Business logic patterns specific to the project\n- Data model relationships and constraints\n- API contracts and integration patterns\n\n### What to Skip\n\n**Don't capture these:**\n- Trivial operations (typo fixes, simple CRUD)\n- Generic advice easily found in documentation\n- One-off solutions without reusable patterns\n- Purely conversational exchanges without technical work\n- Simple reads of documentation without application\n\n## Quality Thresholds\n\nApply these filters to sessions before capturing:\n\n**Minimum Activity Level:**\n- At least 5 tool calls (Read, Write, Edit, Bash, etc.)\n- At least 2-3 minutes of technical work\n- Some problem-solving or decision-making occurred\n\n**Substantive Content:**\n- Not just reading existing code\n- Not just cosmetic changes\n- Involves learning something new or applying a pattern\n\n**Clarity:**\n- The pattern or insight is clear enough to explain\n- Steps can be articulated concretely\n- Examples from the session illustrate the point\n\n## Creating Skills from Learnings\n\n### Skill Structure\n\nFollow skill-development best practices:\n\n**Frontmatter (required):**\n```yaml\n---\nname: skill-topic-name\ndescription: This skill should be used when [specific trigger conditions]. Be concrete with trigger phrases.\nversion: 1.0.0\n---\n```\n\n**Body structure:**\n1. **Overview** - Brief explanation of what this skill covers (2-3 sentences)\n2. **Key Concepts** - Core ideas or patterns (bullet points or short sections)\n3. **Patterns/Techniques** - Specific approaches learned, with examples from session\n4. **Best Practices** - Distilled guidance from the experience\n5. **Common Pitfalls** - Problems encountered and solutions (optional)\n6. **Examples** - Concrete code or command examples from session\n\n**Target length:** 1,500-2,000 words for body\n\n**Writing style:** Imperative form (verb-first instructions), not second person\n\n### Naming Skills\n\nUse kebab-case with descriptive names:\n\n**Good names:**\n- `api-authentication-debugging`\n- `react-hooks-dependency-patterns`\n- `postgres-query-optimization`\n- `go-error-handling-patterns`\n\n**Bad names:**\n- `debugging` (too generic)\n- `stuff-learned` (not descriptive)\n- `session-notes` (not focused)\n\n### Smart Merge Strategy\n\n**Determine whether to create new or update existing:**\n\n1. **Read existing skills** - Use Glob to find skills, Read to examine content\n2. **Calculate topic overlap:**\n   - >60% overlap ‚Üí Update existing skill\n   - <60% overlap ‚Üí Create new skill\n3. **Overlap indicators:**\n   - Same framework/library\n   - Same type of problem (e.g., both about authentication)\n   - Same technical domain (e.g., both about database queries)\n\n**When updating existing skills:**\n- Preserve existing structure and style\n- Add new patterns to relevant sections\n- Include new examples from session\n- Update version (bump patch: 1.0.1 ‚Üí 1.0.2)\n- Add note in \"Recent Additions\" if significant\n\n**When creating new skills:**\n- Start with template structure above\n- Use examples from session throughout\n- Ensure description has strong trigger phrases\n- Set version to 1.0.0\n\n## Skill Quality Standards\n\nEvery generated skill must meet these standards:\n\n**Description Quality:**\n- Third-person format (\"This skill should be used when...\")\n- Includes 3-5 specific trigger phrases users would say\n- Concrete, not vague\n\n**Content Quality:**\n- Uses imperative/infinitive form throughout\n- Specific examples from the session included\n- Avoids generic advice\n- Focused on actionable guidance\n\n**Structure Quality:**\n- Clear sections with headings\n- Bullet points for lists\n- Code examples formatted properly\n- Consistent style with plugin's other skills\n\n**Version Tracking:**\n- New skills start at 1.0.0\n- Updates bump patch version (1.0.0 ‚Üí 1.0.1)\n\n## Implementation Workflow\n\nFollow this process when invoked to capture learnings:\n\n1. **Read configuration** - Check `.claude/session-learner.local.md` for settings\n2. **Apply quality threshold** - Verify session meets minimum criteria\n3. **Analyze session** - Identify patterns, decisions, techniques learned\n4. **Evaluate existing skills** - Search for related skills (smart merge decision)\n5. **Generate or update skill:**\n   - New: Create directory and SKILL.md with proper structure\n   - Update: Use Edit to add content to existing skill\n6. **Stage changes** - If auto_stage enabled: `git add` modified skills\n7. **Report results** - Summarize what was captured and where\n\n## Examples of Good vs. Bad Learnings\n\nFor detailed examples showing what to capture and what to skip, see:\n- **[`references/learning-examples.md`](./references/learning-examples.md)** - Extensive examples with commentary\n- **[`examples/good-skill-example.md`](./examples/good-skill-example.md)** - Complete skill created from session\n- **[`examples/bad-skill-example.md`](./examples/bad-skill-example.md)** - What NOT to create\n\n## Integration with Session Learner Plugin\n\nThis skill is used by the learning-analyzer agent, which is invoked by:\n\n1. **SessionEnd hook** - Automatically after every session\n2. **`/capture-learning` command** - Manually with optional focus hint\n3. **`/review-session` command** - Preview mode without writing files\n\nThe agent references this skill to understand what makes good learnings and how to create quality skills.\n\n## Best Practices\n\n**DO:**\n- ‚úÖ Apply quality thresholds strictly\n- ‚úÖ Include concrete examples from session\n- ‚úÖ Use smart merge strategy\n- ‚úÖ Write in imperative form\n- ‚úÖ Create focused, specific skills\n- ‚úÖ Stage skills for PR when configured\n\n**DON'T:**\n- ‚ùå Capture trivial operations\n- ‚ùå Create generic advice skills\n- ‚ùå Use second person writing\n- ‚ùå Create duplicate skills without checking existing\n- ‚ùå Skip version tracking\n- ‚ùå Force capture when session has no valuable learnings\n\n## Additional Resources\n\n### Reference Files\n\nFor detailed patterns and examples:\n- **[`references/learning-examples.md`](./references/learning-examples.md)** - Good vs bad learning examples with detailed commentary\n\n### Example Files\n\nWorking examples in `examples/`:\n- **[`good-skill-example.md`](./examples/good-skill-example.md)** - Complete skill showing best practices\n- **[`bad-skill-example.md`](./examples/bad-skill-example.md)** - Anti-pattern showing what to avoid\n\n---\n\n**Remember:** The goal is compounding knowledge‚Äîeach captured learning should make future sessions easier. Be selective and focus on truly valuable patterns that warrant codification.\n",
        "plugins/backend/skills/meta-learning/examples/bad-skill-example.md": "# Bad Skill Example\n\nThis shows what NOT to create - a poorly crafted skill that shouldn't exist.\n\n---\n\n```markdown\n---\nname: coding-tips\ndescription: Use this when you need help with coding.\nversion: 1.0.0\n---\n\n# General Coding Tips\n\n## Overview\n\nYou should follow good coding practices when writing code. This skill helps you write better code.\n\n## Things You Should Do\n\nWhen you're coding, you should:\n\n- Write clean code\n- Use good variable names\n- Add comments\n- Test your code\n- Follow style guides\n- Don't repeat yourself (DRY)\n- Keep it simple (KISS)\n- Use version control\n\n## Writing Functions\n\nYou should write functions that do one thing. Functions should have good names that describe what they do. You should add docstrings to your functions.\n\nExample:\n```python\ndef calculate(x, y):\n    return x + y\n```\n\n## Using Git\n\nYou should use Git for version control. You can commit your changes with git commit. You should write good commit messages.\n\nCommands:\n- `git add .`\n- `git commit -m \"message\"`\n- `git push`\n\n## Debugging\n\nWhen you have a bug, you should try to debug it. You can use print statements or a debugger. You should figure out what's causing the bug and fix it.\n\n## Best Practices\n\nYou should always follow best practices when coding. This includes:\n- Writing tests\n- Reviewing code\n- Documenting your work\n- Learning new things\n\nRemember that good code is important!\n```\n\n---\n\n## Why This is a Bad Skill\n\n### Problem 1: Weak Description\n\n**Current:**\n```yaml\ndescription: Use this when you need help with coding.\n```\n\n**Issues:**\n- Not third-person\n- Extremely vague\n- No specific trigger phrases\n- Could apply to anything\n\n**Should be:**\n```yaml\ndescription: This skill should be used when working with [specific framework], debugging [specific problem type], or implementing [specific pattern].\n```\n\n### Problem 2: Generic Content\n\nEverything in this skill is:\n- Common knowledge\n- Available in any coding tutorial\n- Not specific to any framework or language\n- No novel insights\n- Nothing learned from actual session\n\n### Problem 3: Wrong Writing Style\n\n**Uses second person throughout:**\n- \"You should follow...\"\n- \"You can commit...\"\n- \"You should write...\"\n\n**Should use imperative:**\n- \"Follow good coding practices\"\n- \"Commit changes with git commit\"\n- \"Write functions that do one thing\"\n\n### Problem 4: No Concrete Examples\n\nThe examples provided are trivial:\n- `calculate(x, y)` - too simple to be useful\n- Basic git commands - available in any git tutorial\n- \"Use print statements\" - no specific technique\n\n**Should have:**\n- Real examples from session\n- Specific patterns discovered\n- Before/after comparisons\n- Actual problems solved\n\n### Problem 5: Overly Broad Scope\n\nThis skill tries to cover:\n- General coding practices\n- Functions\n- Git usage\n- Debugging\n- Best practices\n\n**Should:**\n- Focus on one specific area\n- Go deep rather than broad\n- Be applicable to specific situations\n\n### Problem 6: No Session Context\n\nNothing indicates this came from actual work:\n- No specific problem solved\n- No \"discovered through debugging\"\n- No performance improvements\n- No patterns learned\n\n**Should:**\n- Reference the session problem\n- Show what was tried\n- Explain what worked and why\n\n### Problem 7: No Reusable Patterns\n\nThis doesn't provide:\n- Systematic approach to anything\n- Diagnostic steps\n- Decision criteria\n- Specific techniques\n\n**Should:**\n- Show step-by-step workflows\n- Provide decision trees\n- Explain when to use each approach\n\n## What Should Have Been Done Instead\n\n**Option 1: Don't create this skill**\n- Content is too generic\n- No value added beyond common knowledge\n- Nothing specific learned\n\n**Option 2: If session had valuable learnings, create focused skill**\n\nExample: If session involved debugging Python decorators, create:\n\n```yaml\n---\nname: python-decorator-debugging\ndescription: This skill should be used when debugging Python decorators, troubleshooting decorator order issues, or understanding decorator execution flow.\n---\n\n# Python Decorator Debugging Patterns\n\n[Specific patterns discovered during actual debugging session]\n[Concrete examples from the code worked on]\n[Systematic approach that proved effective]\n```\n\n## Red Flags Checklist\n\nIf a skill has these issues, it should NOT be created:\n\n- [ ] ‚ùå Vague description without specific triggers\n- [ ] ‚ùå Generic advice from any tutorial\n- [ ] ‚ùå Uses second person (\"you should\")\n- [ ] ‚ùå Overly broad scope (covers multiple unrelated topics)\n- [ ] ‚ùå No connection to actual session work\n- [ ] ‚ùå Trivial examples (Hello World level)\n- [ ] ‚ùå No novel patterns or insights\n- [ ] ‚ùå Common knowledge easily found in docs\n\nIf 3 or more boxes checked, DON'T create the skill.\n\n## Summary\n\n**This bad skill fails because:**\n1. Too generic and vague\n2. No specific learnings from session\n3. Wrong writing style (second person)\n4. Overly broad scope\n5. No reusable patterns\n6. Common knowledge only\n7. Trivial examples\n\n**Remember:** Only create skills that capture specific, valuable, reusable patterns discovered through actual development work. Quality over quantity!\n",
        "plugins/backend/skills/meta-learning/examples/good-skill-example.md": "# Good Skill Example\n\nThis is an example of a well-crafted skill created from session learnings.\n\n---\n\n```markdown\n---\nname: postgres-jsonb-querying\ndescription: This skill should be used when working with PostgreSQL JSONB columns, querying JSON data in Postgres, using JSONB operators, or troubleshooting JSON query performance issues.\nversion: 1.0.0\n---\n\n# PostgreSQL JSONB Query Patterns\n\n## Overview\n\nPostgreSQL's JSONB type enables storing and querying JSON data efficiently. This skill covers query patterns, operator usage, and indexing strategies discovered through debugging slow JSON queries and learning optimal access patterns.\n\n## Key Concepts\n\n**JSONB vs JSON:**\n- JSONB stores binary format (faster queries, slightly slower writes)\n- JSON stores exact text (preserves formatting and key order)\n- Use JSONB for querying, JSON only if exact format preservation needed\n\n**Common Operators:**\n- `->` - Get JSON object field as JSON\n- `->>` - Get JSON object field as text\n- `#>` - Get nested object at path as JSON\n- `#>>` - Get nested object at path as text\n- `@>` - Contains (left JSON contains right JSON)\n- `?` - Exists (key exists)\n- `?|` - Exists any (any of the keys exist)\n- `?&` - Exists all (all keys exist)\n\n## Query Patterns\n\n### Accessing Nested Fields\n\n**Get top-level field:**\n```sql\nSELECT data->>'name' FROM users;\n-- Returns: \"John Doe\" (text)\n\nSELECT data->'name' FROM users;\n-- Returns: \"John Doe\" (json)\n```\n\n**Get nested field:**\n```sql\nSELECT data#>>'{address,city}' FROM users;\n-- Path: data['address']['city']\n\nSELECT data->'address'->>'city' FROM users;\n-- Equivalent chained syntax\n```\n\n### Filtering by JSON Content\n\n**Exact field match:**\n```sql\nSELECT * FROM users WHERE data->>'status' = 'active';\n```\n\n**Contains check (useful for arrays or nested objects):**\n```sql\n-- Check if user has specific role\nSELECT * FROM users WHERE data->'roles' @> '\"admin\"';\n\n-- Check if object contains sub-object\nSELECT * FROM users\nWHERE data @> '{\"preferences\": {\"notifications\": true}}';\n```\n\n**Key existence:**\n```sql\n-- Single key\nSELECT * FROM users WHERE data ? 'email';\n\n-- Any of these keys\nSELECT * FROM users WHERE data ?| array['email', 'phone'];\n\n-- All of these keys\nSELECT * FROM users WHERE data ?& array['email', 'name'];\n```\n\n### Array Operations\n\n**Check array contains value:**\n```sql\nSELECT * FROM posts\nWHERE data->'tags' @> '[\"postgresql\"]';\n```\n\n**Array length:**\n```sql\nSELECT jsonb_array_length(data->'tags') FROM posts;\n```\n\n**Expand array to rows:**\n```sql\nSELECT jsonb_array_elements(data->'tags') FROM posts;\n```\n\n## Indexing for Performance\n\n### When to Index\n\nIndex JSONB columns when:\n- Querying specific fields frequently\n- Filtering by JSON content in WHERE clauses\n- JSON column is large (>1KB average)\n- Table has >10,000 rows\n\n### GIN Index (Recommended)\n\n**Create GIN index for general querying:**\n```sql\nCREATE INDEX idx_users_data ON users USING GIN (data);\n```\n\n**Benefits:**\n- Supports `@>`, `?`, `?|`, `?&` operators\n- Good for general-purpose JSON querying\n- Relatively small index size\n\n**Use when:**\n- Querying various fields\n- Using contains (`@>`) operator\n- Checking key existence\n\n### Expression Index for Specific Fields\n\n**Create index on extracted field:**\n```sql\nCREATE INDEX idx_users_email ON users ((data->>'email'));\n```\n\n**Benefits:**\n- Faster for equality checks on specific field\n- Smaller index size than GIN\n- Works with standard comparison operators\n\n**Use when:**\n- Querying one field frequently\n- Need exact match or range queries\n- Performance critical query\n\n### Index Usage Example\n\n**Without index (slow):**\n```sql\nEXPLAIN ANALYZE\nSELECT * FROM users WHERE data->>'email' = 'user@example.com';\n-- Seq Scan (2.3ms for 10k rows)\n```\n\n**With expression index (fast):**\n```sql\nCREATE INDEX idx_users_email ON users ((data->>'email'));\n\nEXPLAIN ANALYZE\nSELECT * FROM users WHERE data->>'email' = 'user@example.com';\n-- Index Scan (0.08ms)\n```\n\n## Common Pitfalls\n\n### Pitfall 1: Using -> Instead of ->>\n\n**Problem:**\n```sql\n-- Wrong: Returns JSON, not text\nWHERE data->'status' = 'active'  -- Won't match!\n```\n\n**Solution:**\n```sql\n-- Correct: Returns text\nWHERE data->>'status' = 'active'  -- Matches\n\n-- Or compare JSON\nWHERE data->'status' = '\"active\"'  -- Note quotes\n```\n\n### Pitfall 2: Not Using Indexes\n\n**Problem:**\nQuery is slow despite small result set because full table scan occurs.\n\n**Solution:**\n- Add GIN index for general querying\n- Add expression index for frequently queried fields\n- Check EXPLAIN ANALYZE to verify index usage\n\n### Pitfall 3: Incorrect Path Syntax\n\n**Problem:**\n```sql\n-- Wrong: String instead of array\ndata#>>address.city\n\n-- Wrong: Quotes around path\ndata#>>'{\"address\",\"city\"}'\n```\n\n**Solution:**\n```sql\n-- Correct: Array syntax with braces\ndata#>>'{address,city}'\n\n-- Correct: Chained operator syntax\ndata->'address'->>'city'\n```\n\n### Pitfall 4: Forgetting Type Coercion\n\n**Problem:**\n```sql\n-- Won't work: comparing text to integer\nWHERE data->>'age' > 25\n```\n\n**Solution:**\n```sql\n-- Cast to integer for comparison\nWHERE (data->>'age')::integer > 25\n```\n\n## Best Practices\n\n1. **Use JSONB over JSON** for querying use cases\n2. **Index based on query patterns** - GIN for general, expression for specific\n3. **Use ->> for text extraction** in WHERE clauses\n4. **Validate JSON before insert** to avoid malformed data\n5. **Keep JSON structure consistent** across rows for easier querying\n6. **Extract to columns** if querying field very frequently (>50% of queries)\n7. **Monitor index size** - GIN indexes on large JSONB can grow significantly\n\n## Example from Session\n\nDuring debugging of slow user search, discovered:\n\n**Original slow query (no index):**\n```sql\nSELECT * FROM users\nWHERE data->>'organization_id' = '123'\nORDER BY data->>'created_at' DESC;\n-- Execution time: 2,340ms\n```\n\n**Optimized with expression indexes:**\n```sql\nCREATE INDEX idx_users_org_id ON users ((data->>'organization_id'));\nCREATE INDEX idx_users_created ON users ((data->>'created_at'));\n\nSELECT * FROM users\nWHERE data->>'organization_id' = '123'\nORDER BY data->>'created_at' DESC;\n-- Execution time: 18ms\n```\n\n**Key insight:** Expression indexes dramatically improve performance for specific field queries, even better than GIN index for this use case.\n\n---\n\n*This skill was created from session learnings about optimizing PostgreSQL JSONB queries.*\n```\n\n---\n\n## Why This is a Good Skill\n\n**Strong trigger description:**\n- Third-person format\n- Specific phrases: \"working with JSONB\", \"querying JSON data\", \"JSONB operators\"\n- Covers multiple entry points\n\n**Well-structured content:**\n- Clear overview\n- Key concepts explained\n- Multiple pattern sections\n- Real examples from session\n- Common pitfalls identified\n- Best practices distilled\n\n**Actionable and specific:**\n- Concrete SQL examples\n- Performance comparisons\n- Shows before/after optimization\n- Explains when to use each approach\n\n**Appropriate length:**\n- ~1,800 words (in target range)\n- Focused on JSONB querying\n- Could expand to references/ if needed for advanced topics\n\n**Imperative form:**\n- \"Use JSONB over JSON\"\n- \"Index based on query patterns\"\n- \"Validate JSON before insert\"\n- No \"you should\" language\n",
        "plugins/backend/skills/meta-learning/references/learning-examples.md": "# Learning Examples: Good vs. Bad\n\nThis reference provides extensive examples of learnings worth capturing vs. those that should be skipped.\n\n## Good Learning Examples\n\nThese examples show valuable patterns worth codifying into skills.\n\n### Example 1: API Authentication Debugging Pattern\n\n**Session context:**\nUser was debugging API authentication failures. They tried several approaches before discovering the root cause.\n\n**Learning captured:**\n```\nWhen debugging API authentication failures:\n\n1. Verify request is reaching the API (check logs/network tab)\n2. Examine request headers - especially Authorization header format\n3. Check token/credential validity (expiration, format)\n4. Validate request payload structure matches API contract\n5. Compare working request (Postman/curl) with app request\n\nCommon issues:\n- Missing \"Bearer \" prefix in Authorization header\n- Expired tokens not being refreshed\n- Header name case sensitivity (Authorization vs authorization)\n```\n\n**Why this is good:**\n- Systematic approach applicable to future API debugging\n- Specific steps with rationale\n- Identifies common pitfalls discovered\n- Reusable pattern\n\n### Example 2: React Hooks Dependency Array Pattern\n\n**Session context:**\nUser struggled with infinite render loops when using useEffect. Discovered the correct dependency array pattern.\n\n**Learning captured:**\n```\nReact useEffect dependency array rules:\n\n1. Include all values from component scope used inside effect\n2. For functions called in effect, either:\n   - Wrap function in useCallback\n   - Define function inside effect\n   - Use functional updates for setState\n\nInfinite loop indicators:\n- Effect updates state that's in dependency array\n- Object/array reference changes every render\n- Missing eslint-plugin-react-hooks warnings\n\nSolution pattern:\n- Use functional setState: setCount(c => c + 1)\n- Memoize objects/arrays with useMemo\n- Extract non-reactive values outside component\n```\n\n**Why this is good:**\n- Framework-specific pattern with clear rules\n- Identifies problem symptoms\n- Provides concrete solutions\n- Addresses common React pitfall\n\n### Example 3: Database Query Optimization Pattern\n\n**Session context:**\nUser's query was slow (3s). Through profiling, discovered N+1 query problem and fixed with joins.\n\n**Learning captured:**\n```\nIdentifying and fixing N+1 query problems:\n\nSymptoms:\n- Query executes quickly, but page load slow\n- Database logs show many similar queries\n- Response time scales linearly with result count\n\nDiagnosis:\n1. Enable query logging\n2. Count queries per request (look for >10 for simple pages)\n3. Identify repeated queries with only ID changing\n\nSolution patterns:\n- Use JOIN or INCLUDE to eager load associations\n- Batch queries with WHERE id IN (...)\n- Add database indexes on foreign keys\n- Consider denormalization for read-heavy paths\n\nExample (Rails):\n# Bad: N+1\nusers = User.all\nusers.each { |u| u.posts.count }  # Query per user\n\n# Good: Eager loading\nusers = User.includes(:posts)\nusers.each { |u| u.posts.count }  # Single query\n```\n\n**Why this is good:**\n- Identifies specific performance problem pattern\n- Shows diagnostic steps\n- Provides multiple solution approaches\n- Includes concrete code example from session\n\n### Example 4: Git Merge Conflict Resolution Strategy\n\n**Session context:**\nUser had complex merge conflict across multiple files. Developed systematic approach.\n\n**Learning captured:**\n```\nResolving complex multi-file merge conflicts:\n\nProcess:\n1. Understand change intent (read both branch HEADs)\n2. Categorize conflicts:\n   - Logic changes (need careful merge)\n   - Formatting/style (pick one consistently)\n   - Additions (usually can keep both)\n   - Deletions (verify not still needed)\n\n3. Resolve in order of risk:\n   - High risk: Business logic, data models\n   - Medium risk: API contracts, configurations\n   - Low risk: Tests, documentation, formatting\n\n4. After resolution:\n   - Run full test suite\n   - Verify application starts\n   - Check git diff against both branches\n   - Test the originally conflicting functionality\n\nTools:\n- `git diff HEAD...MERGE_HEAD` - See what changed\n- `git show :1:file` - See base version\n- `git checkout --ours/--theirs file` - Take one side\n```\n\n**Why this is good:**\n- Systematic workflow for complex problem\n- Prioritization strategy\n- Multiple concrete commands\n- Post-resolution verification steps\n\n### Example 5: Test Data Setup Pattern\n\n**Session context:**\nUser's tests were flaky due to shared test data. Discovered factory pattern with traits.\n\n**Learning captured:**\n```\nReliable test data with factories and traits:\n\nProblem: Shared fixtures cause test interdependence and flakiness\n\nSolution pattern (using factory_bot):\n\n1. Define base factory with required fields:\n```ruby\nfactory :user do\n  email { Faker::Internet.email }\n  name { Faker::Name.name }\nend\n```\n\n2. Create traits for variations:\n```ruby\nfactory :user do\n  # base fields...\n\n  trait :admin do\n    role { 'admin' }\n  end\n\n  trait :with_posts do\n    after(:create) do |user|\n      create_list(:post, 3, user: user)\n    end\n  end\nend\n```\n\n3. Use in tests:\n```ruby\nit 'allows admins to delete' do\n  admin = create(:user, :admin)\n  post = create(:post)\n\n  expect { admin.delete(post) }.not_to raise_error\nend\n```\n\nBenefits:\n- Each test creates own data (isolation)\n- Traits make intent clear\n- No database state dependencies\n- Faker provides unique values\n```\n\n**Why this is good:**\n- Solves specific testing problem\n- Concrete code pattern with framework\n- Shows progression: problem ‚Üí solution ‚Üí benefits\n- Directly applicable to future tests\n\n## Bad Learning Examples\n\nThese examples show sessions that don't warrant skill creation.\n\n### Bad Example 1: Typo Fix\n\n**Session:**\n```\nUser: \"Fix the typo in README.md, it says 'instalation' instead of 'installation'\"\nAssistant: *fixes typo*\n```\n\n**Why skip:**\n- Trivial operation\n- No reusable pattern\n- No problem-solving involved\n- Common knowledge\n\n### Bad Example 2: Generic Advice\n\n**Potential \"learning\":**\n```\nWhen writing code:\n- Use descriptive variable names\n- Add comments for complex logic\n- Test your code\n- Follow PEP 8 style guide\n```\n\n**Why skip:**\n- Generic advice from any coding guide\n- Nothing specific from session\n- No novel insight\n- Easily found in documentation\n\n### Bad Example 3: Reading Documentation\n\n**Session:**\nUser asked Claude to explain React documentation, Claude read and summarized.\n\n**Why skip:**\n- No application of knowledge\n- Just information transfer\n- No patterns discovered\n- No problem solved\n\n### Bad Example 4: Single Use Solution\n\n**Session:**\nUser needed to convert one specific CSV file to JSON with custom transformations.\n\n**Potential \"learning\":**\n```\nTo convert users.csv to users.json:\n1. Read CSV with pandas\n2. Drop the 'legacy_id' column\n3. Rename 'email_address' to 'email'\n4. Write as JSON\n```\n\n**Why skip:**\n- Too specific to one file\n- No reusable pattern\n- One-off data transformation\n- Not applicable to future sessions\n\n### Bad Example 5: Standard CRUD Operations\n\n**Session:**\nUser asked to create a new model with standard CRUD endpoints.\n\n**Why skip:**\n- Standard framework usage\n- No novel patterns\n- Common operation covered in framework docs\n- No debugging or problem-solving\n\n### Bad Example 6: Vague \"Best Practice\"\n\n**Potential \"learning\":**\n```\nIt's good to use environment variables for configuration because it's more secure and flexible.\n```\n\n**Why skip:**\n- Too vague and general\n- No specific implementation pattern\n- No examples from session\n- Common knowledge\n\n## Distinguishing Valuable from Trivial\n\n### Questions to Ask\n\n**Is this reusable?**\n- ‚úÖ Yes: \"API debugging checklist applicable to any REST API\"\n- ‚ùå No: \"Fix this specific typo in this specific file\"\n\n**Is this non-obvious?**\n- ‚úÖ Yes: \"React hooks dependency rules and infinite loop patterns\"\n- ‚ùå No: \"Use descriptive variable names\"\n\n**Did problem-solving occur?**\n- ‚úÖ Yes: \"Debugged N+1 queries through profiling and query log analysis\"\n- ‚ùå No: \"Read documentation and understood concept\"\n\n**Is there a concrete pattern?**\n- ‚úÖ Yes: \"Factory pattern with traits for test isolation\"\n- ‚ùå No: \"Testing is important\"\n\n**Will this help future work?**\n- ‚úÖ Yes: \"Merge conflict resolution strategy for multi-file conflicts\"\n- ‚ùå No: \"Converted this one CSV file to JSON\"\n\n## Skill Creation Decision Tree\n\n```\nSession ends\n    ‚Üì\nWas code written or debugging done?\n    No ‚Üí Skip\n    Yes ‚Üí Continue\n    ‚Üì\nAre there patterns or insights?\n    No ‚Üí Skip\n    Yes ‚Üí Continue\n    ‚Üì\nIs it reusable in future sessions?\n    No ‚Üí Skip\n    Yes ‚Üí Continue\n    ‚Üì\nIs it non-obvious or framework-specific?\n    No ‚Üí Skip\n    Yes ‚Üí Continue\n    ‚Üì\nCan it be explained concretely?\n    No ‚Üí Skip\n    Yes ‚Üí Create/update skill! ‚úÖ\n```\n\n## Edge Cases\n\n### Borderline Case: Configuration Pattern\n\n**Session:** User configured webpack for the first time, following official guide with some customization.\n\n**Decision:** **Capture if** the customization addressed project-specific needs not in docs.\n**Skip if** just following the standard setup guide.\n\n### Borderline Case: Debugging Session\n\n**Session:** User spent 30 minutes debugging, tried many things, eventually found typo.\n\n**Decision:** **Capture if** the debugging process revealed a systematic approach or common pitfall.\n**Skip if** just trial and error with no transferable technique.\n\n### Borderline Case: Framework Learning\n\n**Session:** User learned basic React hooks (useState, useEffect) from examples.\n\n**Decision:** **Capture if** discovered non-obvious patterns or gotchas through experience.\n**Skip if** just learned basic usage covered in official tutorial.\n\n## Summary\n\n**Capture learnings that are:**\n- Reusable patterns\n- Non-obvious techniques\n- Framework-specific gotchas\n- Systematic approaches\n- Problem-solving workflows\n- Architecture decisions with rationale\n\n**Skip learnings that are:**\n- Trivial operations\n- Generic advice\n- One-off solutions\n- Standard operations\n- Pure information transfer\n- Common knowledge\n\n**When in doubt:** Ask \"Will this specific pattern help me 3 months from now on a different but related problem?\" If yes, capture it. If no, skip it.\n",
        "plugins/backend/skills/model-conventions/SKILL.md": "---\nname: model-conventions\ndescription: Standards, conventions, and struct tag reference for models.  Use when you need to setup a model field or need to know how to access something in a model\n---\n\n# Model Conventions and Standards\n\nThis skill covers all standards, conventions, and struct tag annotations for the model system.\n\n## Database Field Naming\n\n**All database fields must use snake_case:**\n\n```go\n// Correct\nUserID      *fields.UUIDField   `column:\"user_id\" ...`\nFirstName   *fields.StringField `column:\"first_name\" ...`\nCreatedAt   *fields.IntField    `column:\"created_at\" ...`\n\n// Incorrect\nUserID      *fields.UUIDField   `column:\"userId\" ...`    // ‚ùå camelCase\nFirstName   *fields.StringField `column:\"FirstName\" ...` // ‚ùå PascalCase\n```\n\n## JSONB Sub-Structs\n\nAll sub-structs stored in JSONB columns must also use snake_case for JSON tags:\n\n```go\ntype Settings struct {\n    ThemeColor    string `json:\"theme_color\"`    // ‚úÖ Correct\n    NotifyEmail   bool   `json:\"notify_email\"`   // ‚úÖ Correct\n    LastLoginDate string `json:\"lastLoginDate\"`  // ‚ùå Incorrect\n}\n```\n\n## Boolean Values\n\n**Never use boolean types. Always use `smallint` with 0/1 values:**\n\n```go\n// Correct\nIsActive *fields.IntField `column:\"is_active\" type:\"smallint\" default:\"0\"`\n\n// Incorrect\nIsActive *fields.BoolField `column:\"is_active\" type:\"boolean\" default:\"false\"` // ‚ùå\n```\n\nUsage:\n```go\nuser.IsActive.Set(1)  // Active\nuser.IsActive.Set(0)  // Inactive\n```\n\n## Struct Tag Annotations\n\n**Critical:** Struct tags control database migrations and constraints. Include all relevant tags.\n\n### Example with All Tags\n\n```go\ntype UserV1 struct {\n    base.Structure\n    Name     *fields.StringField                `column:\"name\"     type:\"text\"     default:\"\"`\n    Email    *fields.StringField                `column:\"email\"    type:\"text\"     default:\"\" unique:\"true\" index:\"true\"`\n    Age      *fields.IntField                   `column:\"age\"      type:\"integer\"  default:\"0\" null:\"true\"`\n    Status   *fields.IntConstantField[Status]   `column:\"status\"   type:\"smallint\" default:\"1\"`\n    Settings *fields.StructField[*Settings]     `column:\"settings\" type:\"jsonb\"    default:\"{}\"`\n    ParentID *fields.UUIDField                  `column:\"parent_id\" type:\"uuid\"    default:\"null\" null:\"true\"`\n}\n```\n\n### Available Tags\n\n#### Required Tags\n\n- `column:\"name\"` - Database column name (snake_case)\n- `type:\"...\"` - Database column type (see types below)\n\n#### Optional Tags (only add when needed)\n\n- `default:\"value/null\"` - Default value for column\n- `null:\"true\"` - Allow NULL values (omit if NOT NULL)\n- `unique:\"true\"` - Unique constraint (omit if not unique)\n- `index:\"true\"` - Create index on column (omit if not indexed)\n- `public:\"view|edit\"` - For public endpoints (omit if internal only)\n  - `view` - Field returned in responses\n  - `edit` - Field editable by users in updates\n\n### Database Types\n\nAvailable values for `type:` tag:\n\n| Type | Use For | Example |\n|------|---------|---------|\n| `text` | String/text columns | `type:\"text\"` |\n| `jsonb` | JSON/struct columns | `type:\"jsonb\"` |\n| `smallint` | Small integers, booleans (0/1), enums | `type:\"smallint\"` |\n| `integer` | Standard integers | `type:\"integer\"` |\n| `bigint` | Large integers | `type:\"bigint\"` |\n| `uuid` | UUID columns | `type:\"uuid\"` |\n| `date` | Date only | `type:\"date\"` |\n| `datetime` | Date and time | `type:\"datetime\"` |\n| `numeric` | Decimal numbers | `type:\"numeric\"` |\n\n### Important UUID Rule\n\n**All UUID fields must have `default:\"null\" null:\"true\"`:**\n\n```go\n// Correct\nUserID   *fields.UUIDField `column:\"user_id\"   type:\"uuid\" default:\"null\" null:\"true\"`\nParentID *fields.UUIDField `column:\"parent_id\" type:\"uuid\" default:\"null\" null:\"true\"`\n\n// Incorrect\nUserID   *fields.UUIDField `column:\"user_id\" type:\"uuid\"` // ‚ùå Missing null handling\n```\n\n## Field Types\n\n| Field Type | Go Type | Use For |\n|------------|---------|---------|\n| `StringField` | `string` | Text/string columns |\n| `UUIDField` | `types.UUID` | UUID columns |\n| `IntField` | `int` | Integer columns, boolean (0/1) fields |\n| `DecimalField` | `decimal.Decimal` | Decimal/numeric columns |\n| `IntConstantField[T]` | `T` (int-based) | Enum/constant fields |\n| `StructField[T]` | `T` | JSONB/struct columns |\n\n### Field Methods\n\nAll fields provide:\n- `.Set(val)` - Set field value\n- `.Get()` - Get field value\n\nStruct fields additionally provide:\n- `.GetI()` - Get value ignoring errors (when error checking not needed)\n\n## File Organization\n\n**Standard file structure for models:**\n\n- **queries.go** - All specific database queries\n- **functions.go** - All model functions (not methods)\n- **<model>.go** - Generated model struct and methods\n- **migrations/<model>.go** - Database migrations\n\n## Method Receivers\n\n**All methods must use pointer receivers with `this` as the receiver variable:**\n\n```go\n// Correct\nfunc (this *User) FullName() string {\n    return this.FirstName.Get() + \" \" + this.LastName.Get()\n}\n\n// Incorrect\nfunc (u *User) FullName() string {     // ‚ùå Wrong receiver name\n    return u.FirstName.Get() + \" \" + u.LastName.Get()\n}\n\nfunc (this User) FullName() string {   // ‚ùå Value receiver instead of pointer\n    return this.FirstName.Get() + \" \" + this.LastName.Get()\n}\n```\n\n## Thread Safety\n\nAll model operations are thread-safe by default. Models use internal mutexes to protect concurrent access.\n\n## Code Generation\n\n**Always use the code generator tool - never hand-write model structs:**\n\n- Use `#code_tools make_object` for internal models\n- Use `#code_tools make_public_object` for public-facing models\n\n## Related Skills\n\n- [model-usage](../model-usage/SKILL.md) - Using models and fields\n- [model-queries](../model-queries/SKILL.md) - Building database queries\n\n## Additional resources\n- For usage examples, see [examples.md](examples.md)",
        "plugins/backend/skills/model-queries/SKILL.md": "---\nname: model-queries\ndescription: Building database queries with the Options API. Use when you need to query a model by creating a new query or updating an existing one\n---\n\n# Building Database Queries\n\nAll database queries use the `Options` struct with generated column helpers for type-safe query building.\n\n## Basic Query Pattern\n\n```go\nfunc GetJoined(ctx context.Context, id types.UUID) (*AdminJoined, error) {\n    mocker, ok := model.GetMocker[mocker](ctx)\n\tif ok {\n\t\treturn mocker.GetByExternalID(ctx, externalID)\n\t}\n    options := model.NewOptions().\n        WithCondition(\"%s = :id:\", Columns.ID_.Column()).\n        WithParam(\":id:\", id)\n\n    return first[*AdminJoined](ctx, options)\n}\n```\n\n## Query Methods\n\n### WithCondition(format, values...)\n\nAdd AND condition to query. Use `:key:` syntax for parameter placeholders:\n\n```go\noptions := model.NewOptions().\n    WithCondition(\"%s = :user_id:\", Columns.UserID.Column()).\n    WithCondition(\"%s > :min_age:\", Columns.Age.Column())\n```\n\n### WithParam(key, value)\n\nAdd query parameter. Key must match placeholder in condition (`:key:`):\n\n```go\noptions.WithParam(\":user_id:\", userID).\n        WithParam(\":min_age:\", 18)\n```\n\n**Note:** Handles slices automatically when using `IN(:myval:)`:\n\n```go\noptions.WithCondition(\"%s IN(:ids:)\", Columns.ID_.Column()).\n        WithParam(\":ids:\", []types.UUID{id1, id2, id3})\n```\n\n### WithLimit(limit)\n\nSet maximum number of results:\n\n```go\noptions.WithLimit(10)\n```\n\n### WithOrder(order)\n\nSet result ordering:\n\n```go\noptions.WithOrder(\"created_at DESC\")\n```\n\n### WithJoins(joins...)\n\nAdd table joins:\n\n```go\noptions.WithJoins(\n    model.Join{\n        Table: user.TABLE,\n        On:    \"user.id = admin.user_id\",\n    },\n)\n```\n\n## Column Helpers\n\nEvery model has a generated `Columns` struct with helpers for each field:\n\n```go\n// Use .Column() to get the column name with table prefix\nColumns.ID_.Column()      // Returns \"table_name.id\"\nColumns.Name.Column()     // Returns \"table_name.name\"\nColumns.Email.Column()    // Returns \"table_name.email\"\n```\n\n## File Organization\n\n**All specific queries must go in `queries.go`** within the model package.\n\n**AVOID ADHOC QUERIES**\n- they should always be in a function\n- the mocker interface inside of queries.go should be updated\n- all functions must check mocker context\n```go\n    mocker, ok := model.GetMocker[mocker](ctx)\n\tif ok {\n\t\treturn mocker.GetByExternalID(ctx, externalID)\n\t}\n```\n\n## Example Queries\n\n### Simple Lookup\n\n```go\nfunc GetByEmail(ctx context.Context, email string) (*User, error) {\n    mocker, ok := model.GetMocker[mocker](ctx)\n\tif ok {\n\t\treturn mocker.GetByExternalID(ctx, externalID)\n\t}\n    options := model.NewOptions().\n        WithCondition(\"%s = :email:\", Columns.Email.Column()).\n        WithParam(\":email:\", email).\n        WithLimit(1)\n\n    return first[*User](ctx, options)\n}\n```\n\n### Complex Query with Multiple Conditions\n\n```go\nfunc GetActiveUsers(ctx context.Context, minAge int, roles []int) ([]*User, error) {\n    mocker, ok := model.GetMocker[mocker](ctx)\n\tif ok {\n\t\treturn mocker.GetByExternalID(ctx, externalID)\n\t}\n    options := model.NewOptions().\n        WithCondition(\"%s = :status:\", Columns.Status.Column()).\n        WithCondition(\"%s >= :min_age:\", Columns.Age.Column()).\n        WithCondition(\"%s IN(:roles:)\", Columns.Role.Column()).\n        WithParam(\":status:\", 1).\n        WithParam(\":min_age:\", minAge).\n        WithParam(\":roles:\", roles).\n        WithOrder(\"created_at DESC\")\n\n    return list[*User](ctx, options)\n}\n```\n\n### Query with Joins\nAll joins should go into the `joins.go` file\n\n```go\n// AddJoinData adds in the join data\nfunc AddJoinData(options *model.Options) {\n\toptions.WithPrependJoins([]string{\n\t\t\"LEFT JOIN manufacturers ON manufacturers.id = models.manufacturer_id\",\n\t\t\"LEFT JOIN categories ON categories.id = models.category_id\",\n\t\t`LEFT JOIN (\n\t\t\t\tSELECT count(1) as asset_count , assets.model_id\n\t\t\t\tFROM assets\n\t\t\t\tWHERE assets.disabled = 0\n\t\t\t\tGROUP BY assets.model_id\n\t\t) as asset_counts ON asset_counts.model_id = models.id`,\n\t}...)\n\toptions.WithIncludeFields([]string{\n\t\t\"manufacturers.name AS manufacturer_name\",\n\t\t\"categories.name AS category_name\",\n\t\t\"COALESCE(asset_counts.asset_count, 0) AS asset_count\",\n\t}...)\n}\n\n```\n\n## Related Skills\n\n- [model-usage](../model-usage/SKILL.md) - How to use models and access fields\n- [model-conventions](../model-conventions/SKILL.md) - Standards and conventions\n\n## Additional resources\n- For usage examples, see [examples.md](examples.md)",
        "plugins/backend/skills/model-usage/SKILL.md": "---\nname: model-usage\ndescription: Working with model instances and fields, use when you need to access fields on a model\n---\n\n# Using Models\n\nModels provide thread-safe field access through typed methods. All operations use `.Set()` and `.Get()` patterns.\n\n## Creating Model Instances\n\n### Basic Constructor\n\n```go\n// Create new model instance\nuser := user.New()\n```\n\n### Typed Constructor\n\nFor specific types (like joined models):\n\n```go\n// Create a new model instance for a specific type\njoinedUser := user.NewType[*user.JoinedUser]()\n```\n\n## Setting Field Values\n\nAll fields use `.Set(value)` method:\n\n```go\nuser.Name.Set(\"Alice\")\nuser.Email.Set(\"alice@example.com\")\nuser.Age.Set(30)\nuser.Status.Set(constants.StatusActive)\n```\n\n## Getting Field Values\n\nAll fields use `.Get()` method:\n\n```go\nname := user.Name.Get()      // \"Alice\"\nemail := user.Email.Get()    // \"alice@example.com\"\nage := user.Age.Get()        // 30\nstatus := user.Status.Get()  // constants.StatusActive\n```\n\n## Working with Struct Fields\n\nStruct fields (JSONB columns) have additional methods:\n\n### Setting Struct Values\n\n```go\ntype Bookmarks struct {\n    FavoriteID types.UUID `json:\"favorite_id\"`\n    RecentIDs  []types.UUID `json:\"recent_ids\"`\n}\n\nuser.Bookmarks.Set(&Bookmarks{\n    FavoriteID: uuid1,\n    RecentIDs:  []types.UUID{uuid2, uuid3},\n})\n```\n\n### Getting Struct Values\n\n```go\n// .Get() returns value and error\nbookmarks, err := user.Bookmarks.Get()\nif err != nil {\n    return err\n}\n\n// .GetI() ignores errors (use when error checking not needed)\nbookmarks := user.Bookmarks.GetI()\n```\n\n## Field Types Reference\n\n| Field Type | Go Type | Database Type | Use Case |\n|------------|---------|---------------|----------|\n| `StringField` | `string` | `text` | Text/string columns |\n| `UUIDField` | `types.UUID` | `uuid` | UUID columns |\n| `IntField` | `int` | `integer/smallint` | Integer/boolean (0/1) columns |\n| `DecimalField` | `decimal.Decimal` | `numeric` | Decimal/numeric columns |\n| `IntConstantField[T]` | `T` (int-based) | `smallint` | Enum/constant fields |\n| `StructField[T]` | `T` | `jsonb` | JSONB/struct columns |\n\n## Thread Safety\n\nAll field operations are thread-safe by default. Models use internal mutexes to protect concurrent access.\n\n```go\n// Safe to use from multiple goroutines\ngo user.Name.Set(\"Alice\")\ngo user.Email.Set(\"alice@example.com\")\n```\n\n## Common Patterns\n\n### Updating Multiple Fields\n\n```go\nuser := user.New()\nuser.Name.Set(\"Alice\")\nuser.Email.Set(\"alice@example.com\")\nuser.Age.Set(30)\nuser.Status.Set(constants.StatusActive)\n\nerr := user.Save(ctx)\nif err != nil {\n    return err\n}\n```\n\n### Reading and Modifying\n\n```go\nuser, err := user.GetByID(ctx, userID)\nif err != nil {\n    return err\n}\n\n// Modify fields\ncurrentAge := user.Age.Get()\nuser.Age.Set(currentAge + 1)\n\nerr = user.Save(ctx)\nif err != nil {\n    return err\n}\n```\n\n### Working with Optional Fields\n\nFields with `null:\"true\"` can be set to nil:\n\n```go\n// Set to nil\nuser.MiddleName.SetNull()\n\n// Check if nil\nuser.MiddleName.IsNull()\n\n```\n\n## File Organization Standards\n\n- **queries.go** - All specific queries\n- **functions.go** - All model functions (not methods)\n- **Methods** - Use pointer receivers with `this` as the receiver variable\n\n## Related Skills\n\n- [model-queries](../model-queries/SKILL.md) - Building database queries\n- [model-conventions](../model-conventions/SKILL.md) - Standards and field type reference\n\n\n## Additional resources\n- For usage examples, see [examples.md](examples.md)",
        "plugins/backend/skills/testing/SKILL.md": "---\nname: test-builder\ndescription: Use to build proper go unit tests for services, models, and controllers\n---\n\n## üß™ CRITICAL: TEST-DRIVEN DEVELOPMENT (TDD) IS MANDATORY\n\n**‚ö†Ô∏è ABSOLUTE RULE - NO EXCEPTIONS**: This project follows **strict TDD (Test-Driven Development)**.\n\n### TDD Workflow - ALWAYS FOLLOW THIS ORDER:\n\n1. **üî¥ RED**: Write the test FIRST (it will fail)\n2. **üü¢ GREEN**: Write minimal code to make it pass\n3. **üîµ REFACTOR**: Clean up the code while keeping tests green\n4. **üìù COMMIT**: Commit with passing tests\n\n\n\n### Before Writing ANY Code:\n\n```\n‚ùå WRONG:\n1. Write implementation\n2. Write tests later\n3. Maybe forget tests\n\n‚úÖ CORRECT:\n1. Write test first (see it fail - RED)\n2. Write minimal implementation (make it pass - GREEN)\n3. Refactor if needed (keep it passing - REFACTOR)\n4. Commit with tests passing\n```\n\n### TDD Rules for This Project:\n\n1. **NEVER** write production code without a failing test first\n2. **NEVER** write more of a test than is sufficient to fail\n3. **NEVER** write more production code than is sufficient to pass the test\n4. **ALWAYS** see the test fail before making it pass\n5. **ALWAYS** commit only when all tests are passing\n6. **Test coverage must be ‚â•90%** for new code\n\n### What to Test:\n\n- **Unit tests**: All business logic, domain models, services\n- **Integration tests**: Database interactions, external APIs\n- **HTTP handler tests**: All endpoints with various scenarios\n- **Edge cases**: Errors, nil values, boundary conditions\n- **Happy paths**: Normal successful flows\n\n### Test Quality Standards:\n\n- Use **table-driven tests** for multiple scenarios\n- Mock external dependencies if a function doesnt accept the data directly. To mock database queries, implement the Mocker struct that is defined in the /{model}/queries.go and use model.SetMocker to add it to the context. **IMPORTANT** seperate out mock tests from real tests, always have both to make sure the underlying data is real and accurate\n- Use `assert` (lib/testtools/assert/assert.go) for assertions\n- Use `testing_service.Builder` to build objects, be sure to extend this as objects change\n- Tests must be **isolated** (no shared state)\n- Tests must be **deterministic** (no flaky tests)\n\n\n### Example TDD Session:\n\n```go\n// Step 1: Write test FIRST (RED)\nfunc TestExampleHere(t *testing.T) {\n\n    t.Run(\"Case 1\", func(t *testing.T) {\n        // Arrange\n        client := NewOpenAIClient(\"test-key\", \"gpt-4\")\n        req := llm.CreateVectorStoreRequest{Name: \"test\"}\n\n        // Act\n        result, err := client.CreateVectorStore(context.Background(), req)\n\n        // Assert\n        \n        assert.Equal(t, \"test\", result.Name)\n    })\n\n    t.Run(\"Case 2\", func(t *testing.T) {\n        // Arrange\n        client := NewOpenAIClient(\"test-key\", \"gpt-4\")\n        req := llm.CreateVectorStoreRequest{Name: \"test\"}\n\n        // Act\n        result, err := client.CreateVectorStore(context.Background(), req)\n\n        // Assert\n        \n        assert.Equal(t, \"test\", result.Name)\n    })\n\n     t.Run(\"Case 3\", func(t *testing.T) {\n        // Arrange\n        client := NewOpenAIClient(\"test-key\", \"gpt-4\")\n        req := llm.CreateVectorStoreRequest{Name: \"test\"}\n\n        // Act\n        result, err := client.CreateVectorStore(context.Background(), req)\n\n        // Assert\n        \n        assert.Equal(t, \"test\", result.Name)\n    })\n}\n\n// Step 2: Run test - it FAILS (RED) ‚úÖ\n// Step 3: Write implementation to make it pass (GREEN) ‚úÖ\n// Step 4: Refactor if needed (REFACTOR) ‚úÖ\n// Step 5: Commit with passing tests ‚úÖ\n```\n\n\n## 7. Testing Controllers\n\n### Basic Controller Test Pattern\n\nEvery controller should have tests that verify functionality. Use the `testing_service.TestRequest` pattern for creating test requests:\n\n```go\npackage example_controller\n\nimport (\n    \"net/http\"\n    \"net/url\"\n    \"testing\"\n\n    \"github.com/CrowdShield/atlas-go/internal/common/system_testing\"\n    \"github.com/CrowdShield/atlas-go/internal/models/example\"\n    \"github.com/CrowdShield/atlas-go/internal/services/testing_service\"\n)\n\nfunc init() {\n    system_testing.BuildSystem()\n}\n\nfunc TestExampleIndex(t *testing.T) {\n    req, err := testing_service.NewGETRequest[[]*example.ExampleJoined](\"/\", nil)\n    if err != nil {\n        t.Fatalf(\"Failed to create test request: %v\", err)\n    }\n\n    err = req.WithAdmin() // or WithAccount() for public endpoints\n    if err != nil {\n        t.Fatalf(\"Failed to create test request: %v\", err)\n    }\n\n    resp, errCode, err := req.Do(exampleIndex)\n    if err != nil {\n        t.Fatalf(\"Request failed: %v\", err)\n    }\n    if errCode != http.StatusOK {\n        t.Fatalf(\"Expected status code 200, got %d\", errCode)\n    }\n    // Additional assertions on resp...\n}\n```\n\n### Testing Search Functionality\n\nEvery controller with a `search.go` file **must** have a search test to ensure the search configuration doesn't break:\n\n```go\nfunc TestExampleSearch(t *testing.T) {\n    params := url.Values{}\n    params.Add(\"q\", \"search term\")\n    \n    req, err := testing_service.NewGETRequest[[]*example.ExampleJoined](\"/\", params)\n    if err != nil {\n        t.Fatalf(\"Failed to create test request: %v\", err)\n    }\n\n    err = req.WithAdmin() // or WithAccount() depending on controller type\n    if err != nil {\n        t.Fatalf(\"Failed to create test request: %v\", err)\n    }\n\n    resp, errCode, err := req.Do(exampleIndex)\n    if err != nil {\n        t.Fatalf(\"Request failed: %v\", err)\n    }\n    if errCode != http.StatusOK {\n        t.Fatalf(\"Expected status code 200, got %d\", errCode)\n    }\n    // Search should not crash - results can be empty, that's OK\n}\n```\n\n### Test Authentication Patterns\n\n**Admin Controllers**: Use `req.WithAdmin()` for testing admin endpoints:\n```go\nerr = req.WithAdmin() // Creates test admin user with ROLE_ADMIN\n```\n\n**Public Controllers**: Use `req.WithAccount()` for testing public authenticated endpoints:\n```go\nerr = req.WithAccount() // Creates test account user with ROLE_FAMILY_ADMIN\n```\n\n**Custom Users**: Pass specific user objects if needed:\n```go\nadminUser := admin.New()\nadminUser.Role.Set(constants.ROLE_READ_ADMIN)\nadminUser.Save(nil)\n\nerr = req.WithAdmin(adminUser)\n```\n\n### Request Types and Parameters\n\n**GET Requests with Query Parameters**:\n```go\nparams := url.Values{}\nparams.Add(\"name\", \"test\")\nparams.Add(\"limit\", \"10\")\nreq, err := testing_service.NewGETRequest[ResponseType](\"/\", params)\n```\n\n**POST Requests with JSON Body**:\n```go\nbody := map[string]any{}{\n    \"name\": \"Test Item\",\n    \"status\": \"active\",\n}\nreq, err := testing_service.NewPOSTRequest[ResponseType](\"/\", nil, body)\n```\n\n**IMPORTANT** if you are testing model updates or creation, the format is\n```go\nbody := map[string]any{}{\n    \"data\":map[string]any{\n        \"name\": \"Test Item\",\n        \"status\": \"active\",\n    }\n}\n```\n\n**PUT Requests for Updates**:\n```go\nbody := map[string]interface{}{\n    \"name\": \"Updated Name\",\n}\nreq, err := testing_service.NewPUTRequest[ResponseType](\"/uuid-of-object\", nil, body)\n```\n\n### Testing Best Practices\n\n1. **Always use `system_testing.BuildSystem()`** in `init()` for database setup\n2. **Test both success and error cases** \n3. **Clean up test data** using `defer testtools.CleanupModel(x)` if creating models\n4. **Use descriptive test names** like `TestAccountIndex_WithValidUser_ReturnsAccounts`\n5. **Verify HTTP status codes** and response structure\n6. **Use table-driven tests** for multiple scenarios:\n\n### Running Tests:\n\nAll tests must be run through `#code_tools` to ensure proper environment setup:\n** DO NOT RUN YOUR OWN COMMANDS, ONLY USE `#code_tools`\n\n**ALL Tests must pass before committing changes, they must be in the commit message as proof**\n\n\n\n## Additional resources\n- For usage examples, see [examples.md](examples.md)\n"
      },
      "plugins": [
        {
          "name": "backend",
          "description": "AI-powered development tools that get smarter with every use. Make each unit of engineering work easier than the last. Includes 27 specialized agents, 20 commands, and 12 skills.",
          "version": "2.21.0",
          "author": {
            "name": "Griffith Labs",
            "url": "https://github.com/griffnb",
            "email": "contact@griffithlabs.com"
          },
          "homepage": "https://github.com/griffnb/compound-engineering-plugin",
          "tags": [],
          "source": "./plugins/backend",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add griffnb/claude-plugins",
            "/plugin install backend@claude-plugins"
          ]
        }
      ]
    }
  ]
}