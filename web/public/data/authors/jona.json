{
  "author": {
    "id": "jona",
    "display_name": "Jonathan",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/306797?u=981a359900f1fff5a270763d7088fb0dccd512d2&v=4",
    "url": "https://github.com/jona",
    "bio": null,
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 0,
      "total_skills": 18,
      "total_stars": 0,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "ycombinator-skills",
      "version": null,
      "description": "Y Combinator startup frameworks for Claude",
      "owner_info": {
        "name": "Jonathan"
      },
      "keywords": [],
      "repo_full_name": "jona/ycombinator-skills",
      "repo_url": "https://github.com/jona/ycombinator-skills",
      "repo_description": "Y Combinator startup frameworks for Claude",
      "homepage": "https://scrb.dev",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-01-28T17:57:46Z",
        "created_at": "2026-01-27T21:57:29Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 1214
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 2599
        },
        {
          "path": "skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/agi-framework-chollet",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/agi-framework-chollet/SKILL.md",
          "type": "blob",
          "size": 7690
        },
        {
          "path": "skills/ai-accelerated-building-ng",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/ai-accelerated-building-ng/SKILL.md",
          "type": "blob",
          "size": 8046
        },
        {
          "path": "skills/ai-product-building-heller",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/ai-product-building-heller/SKILL.md",
          "type": "blob",
          "size": 9174
        },
        {
          "path": "skills/ai-scaling-laws-amodei",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/ai-scaling-laws-amodei/SKILL.md",
          "type": "blob",
          "size": 7124
        },
        {
          "path": "skills/ai-scientific-discovery-jumper",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/ai-scientific-discovery-jumper/SKILL.md",
          "type": "blob",
          "size": 8648
        },
        {
          "path": "skills/ai-search-strategy-srinivas",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/ai-search-strategy-srinivas/SKILL.md",
          "type": "blob",
          "size": 5600
        },
        {
          "path": "skills/ai-startup-insights-altman",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/ai-startup-insights-altman/SKILL.md",
          "type": "blob",
          "size": 8755
        },
        {
          "path": "skills/ai-startup-questions-fisher",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/ai-startup-questions-fisher/SKILL.md",
          "type": "blob",
          "size": 6426
        },
        {
          "path": "skills/b2b-ai-startup-levie",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/b2b-ai-startup-levie/SKILL.md",
          "type": "blob",
          "size": 9615
        },
        {
          "path": "skills/design-tool-scaling-field",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/design-tool-scaling-field/SKILL.md",
          "type": "blob",
          "size": 6996
        },
        {
          "path": "skills/developer-tools-strategy-truell",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/developer-tools-strategy-truell/SKILL.md",
          "type": "blob",
          "size": 8598
        },
        {
          "path": "skills/enterprise-ai-strategy-nadella",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/enterprise-ai-strategy-nadella/SKILL.md",
          "type": "blob",
          "size": 7252
        },
        {
          "path": "skills/first-principles-thinking-musk",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/first-principles-thinking-musk/SKILL.md",
          "type": "blob",
          "size": 8286
        },
        {
          "path": "skills/robotics-ai-learning-finn",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/robotics-ai-learning-finn/SKILL.md",
          "type": "blob",
          "size": 6263
        },
        {
          "path": "skills/software-democratization-masad",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/software-democratization-masad/SKILL.md",
          "type": "blob",
          "size": 6788
        },
        {
          "path": "skills/software-paradigms-karpathy",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/software-paradigms-karpathy/SKILL.md",
          "type": "blob",
          "size": 10832
        },
        {
          "path": "skills/spatial-intelligence-li",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/spatial-intelligence-li/SKILL.md",
          "type": "blob",
          "size": 8580
        },
        {
          "path": "skills/yc-startup-fundamentals",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/yc-startup-fundamentals/SKILL.md",
          "type": "blob",
          "size": 8208
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"ycombinator-skills\",\n  \"metadata\": {\n    \"description\": \"Y Combinator startup frameworks for Claude\",\n    \"version\": \"1.0.0\"\n  },\n  \"owner\": {\n    \"name\": \"Jonathan\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"ycombinator-skills\",\n      \"description\": \"Apply proven startup strategies and frameworks from YC speakers\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./skills/agi-framework-chollet\",\n        \"./skills/ai-accelerated-building-ng\",\n        \"./skills/ai-product-building-heller\",\n        \"./skills/ai-scaling-laws-amodei\",\n        \"./skills/ai-scientific-discovery-jumper\",\n        \"./skills/ai-search-strategy-srinivas\",\n        \"./skills/ai-startup-insights-altman\",\n        \"./skills/ai-startup-questions-fisher\",\n        \"./skills/b2b-ai-startup-levie\",\n        \"./skills/design-tool-scaling-field\",\n        \"./skills/developer-tools-strategy-truell\",\n        \"./skills/enterprise-ai-strategy-nadella\",\n        \"./skills/first-principles-thinking-musk\",\n        \"./skills/robotics-ai-learning-finn\",\n        \"./skills/software-democratization-masad\",\n        \"./skills/software-paradigms-karpathy\",\n        \"./skills/spatial-intelligence-li\"\n      ]\n    }\n  ]\n}\n",
        "README.md": "# YCombinator Skills\n\nApply proven startup strategies and frameworks popularized by Y Combinator guest speakers and founders.\n\n## Installation\n\nAdd this marketplace to Claude Code:\n\n```bash\n/plugin marketplace add jona/ycombinator-skills\n```\n\nThen install the skills:\n\n```bash\n/plugin install ycombinator-skills\n```\n\n## Available Skills\n\n| Skill | Description |\n|-------|-------------|\n| agi-framework-chollet | François Chollet's framework for understanding intelligence and AGI paths |\n| ai-accelerated-building-ng | Andrew Ng's AI-accelerated startup development strategies |\n| ai-product-building-heller | Jake Heller's Casetext playbook for AI products ($650M exit) |\n| ai-scaling-laws-amodei | Dario Amodei on AI scaling laws and capability forecasting |\n| ai-scientific-discovery-jumper | John Jumper on AI for scientific research breakthroughs |\n| ai-search-strategy-srinivas | Aravind Srinivas on building AI search and agentic browsers |\n| ai-startup-insights-altman | Sam Altman's guidance for AI startup founders |\n| ai-startup-questions-fisher | Jordan Fisher's strategic questioning framework for AI startups |\n| b2b-ai-startup-levie | Aaron Levie on B2B AI startup defensibility and timing |\n| design-tool-scaling-field | Dylan Field on scaling design tools and Figma's journey |\n| developer-tools-strategy-truell | Michael Truell on building developer tools (Cursor) |\n| enterprise-ai-strategy-nadella | Satya Nadella's enterprise AI deployment frameworks |\n| first-principles-thinking-musk | Elon Musk's first principles reasoning for ambitious projects |\n| robotics-ai-learning-finn | Chelsea Finn on general-purpose robot learning |\n| software-democratization-masad | Amjad Masad on AI agents and software democratization |\n| software-paradigms-karpathy | Andrej Karpathy's Software 1.0/2.0/3.0 framework |\n| spatial-intelligence-li | Fei-Fei Li on spatial intelligence and 3D world modeling |\n| yc-startup-fundamentals | Y Combinator methodology for team formation, MVP, growth, and fundraising |\n\n## Structure\n\n```\nycombinator-skills/\n├── .claude-plugin/\n│   ├── plugin.json          # Plugin manifest\n│   └── marketplace.json     # Marketplace catalog\n├── skills/                   # Individual skills\n│   ├── agi-framework-chollet/\n│   ├── ai-accelerated-building-ng/\n│   ├── ai-product-building-heller/\n│   └── ...\n├── registry/                 # Searchable skill index\n├── scripts/                  # Validation and build tools\n└── docs/                     # Documentation\n```\n\n## License\n\nMIT\n",
        "skills/agi-framework-chollet/SKILL.md": "---\nname: agi-framework-chollet\ndescription: Provides François Chollet's framework for understanding intelligence, AGI development paths, and the limitations of current AI approaches. Use this skill when users ask about- (1) What intelligence really means and how to define AGI, (2) Why scaling pre-training alone won't achieve AGI, (3) The difference between memorized skills and fluid intelligence, (4) Test-time adaptation and its role in AGI, (5) The ARC benchmark and what it measures, (6) Type 1 vs Type 2 abstraction in AI systems, (7) Program synthesis approaches to intelligence, (8) Evaluating claims about AGI progress, or (9) Understanding the conceptual foundations needed for building generally intelligent systems.\n---\n\n# François Chollet's Framework for AGI\n\nThis skill encapsulates François Chollet's theoretical framework for understanding intelligence and the path to AGI, based on his analysis of AI progress and the ARC benchmark.\n\n## Core Concepts\n\n### Two Definitions of Intelligence\n\n**Minsky-style view (task-based):**\n- AI performs tasks normally done by humans\n- Corporate AGI definition: \"model that could perform most economically valuable tasks\"\n- Focus on capability benchmarks\n\n**McCarthy-style view (adaptation-based):**\n- Intelligence is the ability to understand something new on the fly\n- Focus on fluid reasoning, not memorized skills\n- Measures generalization to novel situations\n\n**Key distinction:** Memorized skills (static, task-specific) vs. fluid general intelligence (dynamic, adaptable).\n\n### The Pre-Training Scaling Era (2020-2024)\n\n**What worked:**\n- Self-supervised text modeling at scale\n- Predictable benchmark improvements with more compute/data\n- Crushing performance on traditional benchmarks\n\n**Why it plateaued for AGI:**\n- Benchmarks measured memorized skills, not fluid intelligence\n- 50,000x scale-up (2019→2024) yielded only 0%→10% on ARC\n- Humans score >95% on ARC with no training\n- Confusion between benchmark performance and true understanding\n\n### Test-Time Adaptation Era (2024+)\n\n**Core principle:** Models modify their own behavior dynamically based on specific data encountered during inference.\n\n**Key techniques:**\n- Test-time training\n- Program synthesis\n- Chain-of-thought synthesis\n- Self-reprogramming for tasks at hand\n\n**Evidence of progress:**\n- OpenAI's O3 (fine-tuned on ARC) achieved human-level ARC performance\n- All high-performing ARC approaches use test-time adaptation\n\n### Type 1 vs Type 2 Abstraction\n\n**Type 1 (Perceptual):**\n- Pattern recognition from raw sensory data\n- Continuous, gradient-based learning\n- What deep learning excels at\n\n**Type 2 (Discrete/Programmatic):**\n- Symbolic, compositional reasoning\n- Discrete program-like structures\n- Requires on-the-fly recombination of concepts\n\n**AGI requirement:** Both types working together—deep learning for perception, program search for reasoning.\n\n## Analytical Workflows\n\n### Evaluate AGI Claims\n\nWhen assessing claims about AGI progress:\n\n1. Identify the benchmark being used\n2. Determine if it measures memorized skills or fluid intelligence\n3. Check if the model was trained on similar data\n4. Ask: \"Would performance hold on genuinely novel problems?\"\n5. Look for test-time adaptation vs. pure pre-training\n\n**Red flags:**\n- Claims based solely on traditional benchmarks\n- No evaluation on out-of-distribution tasks\n- Conflating task performance with general intelligence\n\n### Analyze AI System Architecture\n\nWhen examining an AI system's potential for general intelligence:\n\n1. Assess pre-training approach\n   - What knowledge is baked in?\n   - How task-specific is the training?\n\n2. Evaluate test-time capabilities\n   - Can the system adapt during inference?\n   - Does it use chain-of-thought or program synthesis?\n   - Can it modify its behavior for novel problems?\n\n3. Check for both abstraction types\n   - Type 1: Perceptual pattern matching\n   - Type 2: Discrete symbolic reasoning\n\n4. Determine generalization potential\n   - How does it perform on ARC-style tasks?\n   - Can it handle problems outside training distribution?\n\n### Assess Intelligence Metrics\n\nWhen evaluating whether a metric truly measures intelligence:\n\n1. Apply the Chollet criteria:\n   - Does it require understanding novel situations?\n   - Can it be solved by memorization?\n   - Is the solution space too narrow?\n\n2. Check for the \"ARC test\":\n   - Would 50,000x more compute dramatically improve scores?\n   - If no, the metric likely measures fluid intelligence\n   - If yes, it may just measure knowledge retrieval\n\n3. Consider human baseline:\n   - Humans with no training should outperform on true intelligence tests\n   - Large gap between human and AI suggests memorization-based approach\n\n## Key Frameworks\n\n### The Compute Cost Trajectory\n\nHistorical pattern since 1940:\n- Compute cost falls ~100x per decade\n- No sign of stopping\n- Implication: Compute alone doesn't solve intelligence\n\n### Why Pre-Training Scaling Failed for AGI\n\n```\nScaling pre-training → Better benchmark scores\nBetter benchmark scores ≠ General intelligence\nGeneral intelligence requires → Novel problem adaptation\nNovel problem adaptation requires → Test-time learning\n```\n\n### The AGI Architecture Hypothesis\n\n```\nAGI = Deep Learning (Type 1) + Program Search (Type 2)\n     + Test-Time Adaptation\n     \nWhere:\n- Deep Learning handles perception and pattern matching\n- Program Search handles discrete reasoning and composition\n- Test-Time Adaptation enables on-the-fly learning\n```\n\n## Common Questions\n\n### \"Is AGI already here with O3?\"\n\nEvaluate by asking:\n- Was the model fine-tuned specifically on ARC-like data?\n- Does performance generalize to other novel reasoning tasks?\n- Is it truly adapting or just better memorization?\n\nO3 shows promising signs but fine-tuning on ARC means true generalization is uncertain.\n\n### \"What's missing from current LLMs?\"\n\nKey gaps:\n- True test-time learning (not just prompting)\n- Program synthesis capabilities\n- Type 2 discrete abstraction\n- Generalization without task-specific fine-tuning\n\n### \"How should we measure AGI progress?\"\n\nUse metrics that:\n- Cannot be solved by memorization\n- Require novel problem understanding\n- Show ceiling effects with scale alone\n- Demonstrate human-like fluid reasoning\n\nARC exemplifies these properties.\n\n## Terminology Reference\n\n| Term | Definition |\n|------|------------|\n| Fluid intelligence | Ability to understand novel situations without prior training |\n| Memorized skills | Static, task-specific capabilities from training |\n| Test-time adaptation | Model modifying behavior during inference |\n| ARC | Abstraction and Reasoning Corpus benchmark |\n| Type 1 abstraction | Perceptual, continuous pattern recognition |\n| Type 2 abstraction | Discrete, programmatic reasoning |\n| Program synthesis | Generating programs to solve problems |\n| Scaling laws | Predictable performance gains from more compute/data |\n\n## Application Guidelines\n\n### When Discussing AGI Timelines\n\n1. Distinguish capability claims from intelligence claims\n2. Ask what benchmarks support the claim\n3. Check for test-time adaptation in the architecture\n4. Consider whether the system generalizes beyond training\n\n### When Designing AI Systems for Generalization\n\n1. Include test-time adaptation mechanisms\n2. Don't rely solely on pre-training scale\n3. Incorporate program synthesis where possible\n4. Test on out-of-distribution problems like ARC\n5. Balance Type 1 and Type 2 capabilities\n\n### When Evaluating AI Research Directions\n\nPrioritize approaches that:\n- Enable learning at inference time\n- Combine neural and symbolic methods\n- Demonstrate novel problem-solving\n- Go beyond benchmark optimization",
        "skills/ai-accelerated-building-ng/SKILL.md": "---\nname: ai-accelerated-building-ng\ndescription: Apply Andrew Ng's startup building principles and AI-accelerated development strategies from AI Fund's experience launching ~1 startup per month. Use when users ask about startup execution speed, AI coding tools for faster prototyping, agentic AI workflows, evaluating AI startup opportunities, or building AI applications. Triggers include questions about how to build startups faster, AI technology stack layers, where AI opportunities exist, implementing agentic workflows, or applying lessons from successful AI venture studios.\n---\n\n# Andrew Ng: Building Faster with AI\n\nGuidance for applying Andrew Ng's principles on startup execution speed and AI-accelerated development, based on AI Fund's experience building approximately one startup per month.\n\n## Core Thesis\n\n**Execution speed is the strongest predictor of startup success.** AI coding tools enable 10x faster prototyping, shifting bottlenecks from implementation to product management and user feedback.\n\n## AI Stack Layers\n\nUnderstand where opportunities exist in the AI technology stack:\n\n```\nLayer 5: Applications        ← Biggest opportunities (must generate revenue for all layers below)\nLayer 4: Orchestration       ← New layer enabling easier app building (agentic coordination)\nLayer 3: Foundation Models   ← High PR/hype but dependent on app layer revenue\nLayer 2: Cloud Infrastructure\nLayer 1: Semiconductors\n```\n\n**Key insight:** Media focuses on technology layers, but by definition, the application layer must generate the most value to sustain the entire stack.\n\n## Agentic AI Workflows\n\n### Why Agentic Approaches Matter\n\nTraditional LLM usage forces linear generation (first word to last, no backspace). Humans don't write well this way—neither does AI.\n\n**Agentic workflow pattern:**\n1. Generate outline/plan\n2. Conduct research (web fetches, document retrieval)\n3. Write first draft\n4. Self-critique the draft\n5. Revise based on critique\n6. Iterate until quality threshold met\n\nThis iterative loop is slower but produces dramatically better results.\n\n### When to Use Agentic Workflows\n\nApply agentic approaches for:\n- Complex compliance document analysis\n- Medical diagnosis reasoning\n- Legal document interpretation\n- Any task requiring research + synthesis + revision\n\n### Implementing Agentic Workflows\n\n```\n┌─────────────────────────────────────────────┐\n│           Agentic Workflow Loop             │\n├─────────────────────────────────────────────┤\n│                                             │\n│    ┌──────────┐                             │\n│    │  PLAN    │ ← Define task, create       │\n│    └────┬─────┘   outline or approach       │\n│         │                                   │\n│         ▼                                   │\n│    ┌──────────┐                             │\n│    │ RESEARCH │ ← Fetch context, retrieve   │\n│    └────┬─────┘   documents, web search     │\n│         │                                   │\n│         ▼                                   │\n│    ┌──────────┐                             │\n│    │  DRAFT   │ ← Generate initial output   │\n│    └────┬─────┘                             │\n│         │                                   │\n│         ▼                                   │\n│    ┌──────────┐                             │\n│    │ CRITIQUE │ ← Self-evaluate against     │\n│    └────┬─────┘   requirements              │\n│         │                                   │\n│         ▼                                   │\n│    ┌──────────┐     No                      │\n│    │ GOOD     │────────┐                    │\n│    │ ENOUGH?  │        │                    │\n│    └────┬─────┘        │                    │\n│         │ Yes          │                    │\n│         ▼              │                    │\n│    ┌──────────┐   ┌────┴─────┐              │\n│    │  OUTPUT  │   │  REVISE  │──────┐       │\n│    └──────────┘   └──────────┘      │       │\n│                        ▲            │       │\n│                        └────────────┘       │\n│                                             │\n└─────────────────────────────────────────────┘\n```\n\n## Startup Execution Speed Principles\n\n### Speed as Success Predictor\n\nHigh-velocity execution correlates with startup success. AI Fund observes this across their portfolio of monthly startup launches.\n\n### AI-Enabled Acceleration\n\nCurrent AI coding tools enable approximately **10x faster prototyping**:\n- Rapid MVP development\n- Faster iteration cycles\n- Reduced time from idea to testable product\n\n### Shifted Bottlenecks\n\nWhen implementation accelerates 10x, new bottlenecks emerge:\n1. **Product management decisions** - What to build becomes more important than how fast you can build\n2. **User feedback collection** - Getting real user input becomes the limiting factor\n3. **Idea validation** - Testing concrete ideas matters more than coding speed\n\n### Best Practices for Speed\n\n1. **Start with concrete ideas** - Vague concepts slow execution; specific features accelerate it\n2. **Use AI coding assistants** - Leverage tools for rapid prototyping\n3. **Iterate in 2-3 month cycles** - Best practices change frequently; stay current\n4. **Focus on customer conversations** - Speed includes talking to users, not just writing code\n5. **Design features and pricing early** - AI Fund teams do this alongside coding\n\n## Evaluating AI Startup Opportunities\n\n### Application Layer Focus\n\nWhen evaluating where to build:\n\n| Layer | Opportunity Size | Competition | Barrier |\n|-------|------------------|-------------|---------|\n| Applications | Largest by definition | Growing | Domain expertise |\n| Orchestration | Medium, emerging | Moderate | Technical depth |\n| Foundation Models | Large but concentrated | Intense | Capital-intensive |\n\n### Opportunity Identification Framework\n\n1. **Find existing workflows** that can be improved with agentic AI\n2. **Identify domains** where iterative reasoning adds significant value\n3. **Look for tasks** currently requiring expensive human expertise\n4. **Target applications** that can generate revenue to justify AI costs\n\n### Validated Use Cases from AI Fund\n\nDomains where agentic workflows have proven valuable:\n- Compliance document processing\n- Medical diagnosis support\n- Legal document reasoning\n- Any domain requiring research → synthesis → revision\n\n## Quick Reference: Building Faster\n\n### Before Starting a Project\n\n- [ ] Define concrete, specific features (not vague concepts)\n- [ ] Identify the workflow to implement or improve\n- [ ] Determine if agentic approach is needed (complex reasoning, research, revision)\n- [ ] Set up AI coding assistant for rapid prototyping\n\n### During Development\n\n- [ ] Use iterative agentic loops for quality-critical outputs\n- [ ] Prototype quickly, then gather user feedback\n- [ ] Let product decisions (not coding speed) drive priorities\n- [ ] Revisit approach every 2-3 months as tools improve\n\n### Evaluating Progress\n\n- [ ] Measure execution velocity, not just output quality\n- [ ] Track time from idea to testable prototype\n- [ ] Monitor where bottlenecks actually occur\n- [ ] Adjust based on real user feedback, not assumptions",
        "skills/ai-product-building-heller/SKILL.md": "---\nname: ai-product-building-heller\ndescription: Guide for building successful AI startups based on Jake Heller's Casetext journey ($650M exit). Use when users need help with- (1) Selecting AI startup ideas by identifying jobs people pay humans to do, (2) Building reliable AI products through systematic evaluation and prompt iteration, (3) Pricing AI products based on value delivered, (4) Marketing AI products through product quality rather than sales tactics, (5) Understanding the assistance/replacement/unthinkable framework for AI opportunities, (6) Creating evaluation frameworks for AI prompts, or (7) Bridging the trust gap with enterprise customers for AI products.\n---\n\n# AI Startup Building Framework\n\nBuild successful AI startups by picking ideas based on existing paid work, iterating obsessively on evaluation, and letting product quality drive growth.\n\n## Core Principles\n\n### Job-as-Market Framework\n\nInstead of inventing what people might want, identify what people currently pay other people to do. This eliminates product-market fit risk.\n\n**Key insight**: AI has made finding product-market fit easier—we already know what people want because they're paying humans to do it.\n\n### TAM Expansion\n\nTraditional SaaS: `TAM = software seats × subscription price`\n\nAI products: `TAM = combined salaries of all workers doing the job being replaced/assisted`\n\nThis means 10-1000x larger markets than traditional SaaS.\n\n## Idea Selection Workflow\n\n### Step 1: Identify Target Jobs\n\nLook for jobs people are already outsourcing or paying humans to do:\n\n- Customer support representatives\n- Insurance adjusters\n- Paralegals and legal researchers\n- Personal trainers\n- Executive assistants\n- Data entry clerks\n- Content moderators\n\n**Best signal**: Jobs being outsourced to other countries indicate price sensitivity and clear task definition—prime AI targets.\n\n### Step 2: Categorize the Opportunity\n\nClassify your idea into one of three categories:\n\n| Category | Description | Example | Complexity |\n|----------|-------------|---------|------------|\n| **Assistance** | Help professionals do tasks faster | AI legal research for lawyers | Medium |\n| **Replacement** | Become the service provider directly | AI-powered customer support | High |\n| **Previously Unthinkable** | Tasks too expensive for humans at scale | Personalized tutoring for every student | Highest |\n\n**Decision guidance**:\n- Start with assistance if entering a regulated industry (law, medicine, finance)\n- Consider replacement for commoditized services with clear quality metrics\n- Pursue unthinkable only with strong technical differentiation\n\n### Step 3: Validate Domain Expertise\n\nYou must understand how professionals actually do the work. Ask:\n\n- What are the specific steps in this workflow?\n- Where do humans make judgment calls?\n- What does \"good\" look like to an expert?\n- What mistakes would be unacceptable?\n\nIf you cannot answer these questions, partner with domain experts or spend time learning the profession deeply.\n\n## Building Reliable AI Products\n\n### Workflow Decomposition\n\nBreak professional tasks into specific steps. For each step, decide:\n\n```\nIs this step deterministic?\n├── Yes → Implement as code (no LLM needed)\n└── No → Does it require judgment?\n    ├── Yes → Create a prompt with evaluation\n    └── No → Can it be rule-based?\n        ├── Yes → Implement as code\n        └── No → Create a prompt with evaluation\n```\n\n**Mental model**: Each prompt represents injecting human-level intelligence at a specific decision point.\n\n### Best Expert Framework\n\nDesign AI workflows by asking: \"How would the best person in this field approach this task if they had unlimited time and 1000 AI instances working simultaneously?\"\n\nThis reframes constraints—you're not limited by human availability or time pressure.\n\n## Evaluation Framework\n\n### The Eval-Driven Development Process\n\nMost AI products fail because builders stop at 60-70% accuracy demos. Follow this process instead:\n\n#### Phase 1: Initial Development (12 evals per prompt)\n\n1. Write initial prompt\n2. Create 12 diverse test cases covering:\n   - Common scenarios (6 cases)\n   - Edge cases (3 cases)\n   - Adversarial inputs (3 cases)\n3. Run evaluations\n4. Iterate until all 12 pass\n\n#### Phase 2: Expansion (reach 100 evals)\n\n1. Add 10 more test cases after achieving 100% on initial set\n2. Identify failure patterns\n3. Iterate on prompt until new tests pass\n4. Repeat until you have 100 evaluations per prompt\n\n#### Phase 3: Holdout Validation\n\n1. Keep 20% of evaluations as a holdout set\n2. Never look at holdout results during development\n3. Use holdout only for final validation\n4. If holdout fails, return to Phase 2\n\n### Evaluation Criteria\n\nFor each test case, define:\n\n```yaml\ntest_case:\n  input: \"The specific input to test\"\n  expected_behavior: \"What the output should contain/do\"\n  failure_conditions:\n    - \"Specific failure mode 1\"\n    - \"Specific failure mode 2\"\n  pass_threshold: 0.97  # 97% minimum for production\n```\n\n### The Two-Week Grind\n\n**Critical insight**: The willingness to spend two weeks sleeplessly iterating on a single prompt separates successful products from demos.\n\nWhen accuracy matters (finance, medicine, law):\n- Block two weeks for prompt refinement\n- Accept no compromises below 97% accuracy\n- Document every iteration and why it failed\n\n### Converting Complaints to Tests\n\nPost-beta launch workflow:\n\n1. Receive customer complaint\n2. Reproduce the issue\n3. Create new test case capturing the failure\n4. Add to evaluation suite\n5. Iterate until test passes\n6. Verify no regression on existing tests\n\nReal user behavior is your best evaluation source.\n\n## Pricing AI Products\n\n### Value-Based Pricing\n\nPrice based on value delivered, not SaaS conventions:\n\n```\nAI Product Price = (Human cost for equivalent work) × (0.1 to 0.5)\n```\n\n**Example**: If a paralegal costs $50/hour and takes 4 hours for research ($200 total), price AI at $20-100 per equivalent task.\n\n### Discovery Process\n\nAsk customers directly: \"How would you like to pay for this?\"\n\nCommon models:\n- Per-task pricing (for discrete, measurable outputs)\n- Seat-based (for ongoing assistance tools)\n- Usage-based (for variable consumption patterns)\n- Outcome-based (for replacement products)\n\n### Avoiding PRR Trap\n\n**Pilot Recurring Revenue (PRR)**: Revenue from pilot programs that may not convert to real ARR.\n\nWarning signs:\n- Pilots that keep extending without conversion\n- Usage metrics that don't match payment\n- Customers who praise but don't deploy\n\nFocus on actual customer adoption and usage, not pilot revenue.\n\n## Marketing and Sales\n\n### Product-is-Everything Principle\n\nYour product isn't just pixels on screen—it includes:\n- Customer support quality\n- Onboarding experience\n- Training materials\n- Customer success interactions\n- Founder involvement in early deals\n\nGreat products generate word-of-mouth. Product quality drives marketing success more than marketing investment.\n\n### Bridging the Trust Gap\n\nEnterprise buyers face uncertainty moving from controllable humans (trainable, fireable) to unknown AI.\n\n**Trust-building tactics**:\n\n1. **Side-by-side comparisons**: Offer head-to-head tests against existing human services during pilots\n2. **Controlled pilots**: Let customers test with real work in controlled environment\n3. **Published studies**: Create case studies with measurable outcomes\n4. **Gradual rollout**: Start with low-risk tasks, expand as trust builds\n\n### Forward Deployed Engineers\n\nFor enterprise customers, place engineers who sit with customers to:\n- Ensure products work in their specific environment\n- Gather real feedback on failure modes\n- Build relationship and trust\n- Identify expansion opportunities\n\n## Building Defensibility\n\nDefensibility comes from accumulated iteration complexity, not proprietary models.\n\nSources of defensibility:\n- Thousands of evaluations refined over years\n- Deep understanding of domain-specific edge cases\n- Integrated workflows that are painful to switch\n- Brand trust built through consistent quality\n- Data flywheel from customer usage\n\n## Common Mistakes to Avoid\n\n| Mistake | Why It Fails | Better Approach |\n|---------|--------------|-----------------|\n| Stopping at 70% accuracy | Unusable for professional work | Iterate until 97%+ |\n| Using agent frameworks without understanding | Adds complexity without reliability | Build simple, testable pipelines |\n| Over-investing in sales vs. product | Unsustainable growth | Let product quality drive growth |\n| Pricing like SaaS | Leaves value on table | Price based on human cost replacement |\n| Ignoring domain expertise | Miss critical failure modes | Partner with or become domain experts |\n| Counting PRR as real revenue | Inflates metrics, hides problems | Track actual deployment and usage |\n\n## Quick Reference: Evaluation Tools\n\n**Promptfoo** (open source, command line):\n- Run batch evaluations\n- Compare prompt versions\n- Track regression over time\n\nBasic usage pattern:\n```bash\npromptfoo eval --config eval_config.yaml\n```\n\nStructure evaluations in YAML with inputs, expected outputs, and grading criteria.",
        "skills/ai-scaling-laws-amodei/SKILL.md": "---\nname: ai-scaling-laws-amodei\ndescription: Strategic guidance on AI scaling laws, capability trajectories, and building products at the frontier of AI capabilities. Use when users ask about AI scaling trends, capability forecasting, planning AI product development timelines, understanding pretraining vs reinforcement learning phases, interpreting AI benchmark improvements, deciding when to build AI products that don't quite work yet, or strategizing around rapidly advancing AI capabilities. Also triggers for questions about task horizon doubling, Jevons paradox in AI, or how to position products for future model improvements.\n---\n\n# Scaling and the Road to Human-Level AI\n\nStrategic framework for understanding AI scaling laws and building products that leverage predictable AI capability improvements.\n\n## Core Concepts\n\n### Two Phases of AI Training\n\n**Pretraining**: Models learn to predict the next token by imitating human-written text, understanding underlying correlations in data.\n\n**Reinforcement Learning (RL)**: Models are optimized based on human feedback, reinforcing helpful/honest/harmless behaviors and discouraging harmful ones.\n\nScaling laws exist for both phases—performance improves predictably with increased compute, data, and parameters.\n\n### Key Metrics\n\n- **Task Horizon**: Length/complexity of tasks AI can complete, measured in equivalent human time\n- **Elo Scores**: Rating system measuring model preference comparisons\n- **Context Window**: Amount of information processable in a single conversation\n\n### Scaling Law Reliability\n\nScaling laws have held across 5+ orders of magnitude with physics-level precision. When scaling appears broken, assume training implementation issues first, not fundamental limits.\n\n## Strategic Decision Framework\n\n### Assess Current AI Capabilities\n\nUse the two-axis capability framework:\n1. **Y-axis (Flexibility)**: What modalities can the model handle?\n2. **X-axis (Task Horizon)**: What equivalent human-time tasks can it complete?\n\nCurrent trajectory: Task horizons double approximately every 7 months.\n\n### Product Timing Strategy\n\n```\nCurrent capability assessment:\n├── Works reliably now → Build and ship immediately\n├── Works 70-80% of time → Viable for error-tolerant use cases\n├── Works marginally → Build now, ship when next model releases\n└── Doesn't work at all → Wait 1-2 model generations\n```\n\n**Key insight**: Build products that don't quite work yet with current AI capabilities. Target capabilities slightly beyond current models—future models will make marginal products work.\n\n### Use Case Selection Criteria\n\nPrioritize applications where:\n- 70-80% accuracy is acceptable\n- Breadth of knowledge matters more than deep focus on one hard problem\n- Cross-domain synthesis creates value (biology + psychology + history)\n- Human review can catch and correct errors\n\nDeprioritize applications requiring:\n- Near-perfect accuracy on first attempt\n- Deep specialized reasoning without verification\n- Tasks where errors compound catastrophically\n\n## Human-AI Collaboration Model\n\n### Role Division\n\nPosition humans as managers and sanity-checkers:\n- AI generates options and drafts\n- Humans verify, select, and course-correct\n- AI's judgment-generation gap is smaller than humans'\n\n### Leverage AI's Strengths\n\n**Breadth over depth**: AI excels at synthesizing information across many domains simultaneously. Target applications requiring:\n- Literature synthesis across fields\n- Pattern recognition across diverse data sources\n- Rapid exploration of solution spaces\n\n### Practical Workflow\n\n1. Define the task scope and success criteria\n2. Have AI generate initial approach/draft\n3. Review for sanity and strategic alignment\n4. Iterate with targeted corrections\n5. Use AI to refine based on feedback\n\n## Forecasting AI Capabilities\n\n### Timeline Estimation Method\n\n```\nTo estimate when a capability becomes viable:\n\n1. Identify current task horizon (what length tasks work reliably)\n2. Apply 7-month doubling rule\n3. Calculate generations needed:\n   - Hour-long tasks → Day-long tasks: ~3 doublings (~21 months)\n   - Day-long tasks → Week-long tasks: ~3 doublings (~21 months)\n   - Week-long tasks → Month-long tasks: ~4 doublings (~28 months)\n```\n\n### Self-Correction Multiplier\n\nEach improvement in a model's ability to notice and correct its own mistakes roughly doubles task horizon length. Factor this into capability forecasts.\n\n## Integration Strategy\n\n### Avoid the Steam Engine Mistake\n\nDon't just replace existing processes with AI equivalents. Redesign entire systems around AI capabilities (electricity adoption analogy—factories were redesigned around electric motors, not just swapping steam for electric).\n\n### Accelerate Adoption\n\nUse AI to integrate AI into products and businesses. The bottleneck is adoption speed, not capability. When facing integration challenges:\n1. Have AI analyze your current workflow\n2. Identify substitution points and redesign opportunities\n3. Prototype with AI assistance\n4. Iterate rapidly\n\n### Jevons Paradox Awareness\n\nExpect that increased AI efficiency leads to increased consumption, not decreased cost. Plan for:\n- More AI usage as capabilities improve\n- New use cases emerging from better performance\n- Expanding scope rather than shrinking budgets\n\n## Diagnostic Framework\n\n### When Scaling Appears Broken\n\nBefore concluding a capability limit exists:\n1. Verify training/prompting methodology\n2. Check for data quality issues\n3. Test with alternative approaches\n4. Compare against scaling law predictions\n\n**Default assumption**: Implementation issues, not fundamental limits.\n\n### Evaluating Model Improvements\n\nCompare new models against:\n- Expected scaling law trajectory\n- Task horizon benchmarks\n- Cross-domain performance consistency\n\nDeviations from smooth improvement suggest training issues worth investigating.\n\n## Example Applications\n\n### Product Development Decision\n\n**Scenario**: Building an AI code review tool\n\n```\nAssessment:\n- Current models: Reliable for single-file reviews (~minutes)\n- Target capability: Full PR reviews with context (~hours)\n- Gap: ~2-3 doublings needed\n\nDecision: Build now with single-file scope, architecture for expansion.\nShip current capability, expand automatically as models improve.\n```\n\n### Capability Targeting\n\n**Scenario**: Choosing between deep analysis vs broad synthesis features\n\n```\nAI strength analysis:\n- Deep focus on one hard problem: Human-competitive, not superior\n- Synthesizing across 10 domains: Clear AI advantage\n\nDecision: Prioritize cross-domain synthesis features.\nExample: Research assistant that connects findings across biology,\npsychology, and economics papers simultaneously.\n```\n\n### Timeline Planning\n\n**Scenario**: When will AI handle week-long research projects reliably?\n\n```\nCurrent state (2024): Hour-long tasks reliable\nDoubling rate: ~7 months\n\nCalculation:\n- Hour → Day: 3 doublings = 21 months\n- Day → Week: 3 doublings = 21 months\n- Total: ~42 months (rough estimate)\n\nPlanning implication: Build infrastructure now, expect capability 2027-2028.\n```",
        "skills/ai-scientific-discovery-jumper/SKILL.md": "---\nname: ai-scientific-discovery-jumper\ndescription: Guidance for building AI systems for scientific discovery, based on lessons from AlphaFold's development. Use when designing ML systems for scientific domains, planning validation strategies using blind benchmarks, deciding how to release scientific AI tools for maximum impact, evaluating data acquisition vs architectural research investment, building tools for domain expert adoption, structuring ML research projects with compute budgeting, or assessing when a scientific AI tool has crossed the relevance threshold for real-world use.\n---\n\n# AI for Scientific Discovery\n\nPrinciples and workflows for building AI systems that accelerate scientific research, derived from the development of AlphaFold at DeepMind.\n\n## Core Principles\n\n### Research Ideas as Multipliers\n\nResearch and architectural innovation multiply the value of data and compute rather than adding linearly.\n\n**Key insight**: AlphaFold2 trained on 1% of available data outperformed AlphaFold1 trained on 100% of data. This demonstrates that ideas can provide 100x leverage over data alone.\n\n**Implication**: When building ML systems for scientific domains, prioritize research iteration over data acquisition. Most compute budget should account for failed research iterations, not final model training.\n\n### Many Mid-Scale Ideas\n\nBreakthroughs come from accumulating many medium-sized innovations, not one revolutionary idea.\n\n**Key insight**: In AlphaFold ablation studies, no single component explained more than 10% of the system's improvement. The breakthrough emerged from combining numerous architectural innovations.\n\n**Implication**: Avoid searching for a single \"magic bullet\" solution. Instead, systematically develop and integrate multiple complementary improvements.\n\n### Biological Relevance Threshold\n\nReal-world impact requires crossing a threshold where predictions become useful to domain experts who don't care about ML metrics.\n\n**Key insight**: Experimental biologists adopted AlphaFold not because of benchmark scores, but because predictions matched their private experimental data at a useful accuracy level.\n\n**Implication**: Define success by domain expert utility, not benchmark performance. Track adoption signals from target users, not just technical metrics.\n\n## Workflow: Designing Scientific AI Systems\n\n### Step 1: Understand the Domain Problem\n\n1. Identify the core scientific question (e.g., \"How does a linear amino acid chain fold into a 3D structure?\")\n2. Map existing experimental methods and their limitations\n3. Determine what accuracy level constitutes \"useful\" for practitioners\n4. Identify available data sources and their characteristics\n\n### Step 2: Evaluate Off-the-Shelf Approaches\n\n1. Test standard ML architectures on the problem\n2. Document where generic approaches fail or underperform\n3. Identify domain-specific constraints that require custom solutions\n4. Establish baseline performance for comparison\n\n**Warning**: Off-the-shelf ML approaches are typically insufficient for scientific breakthroughs. Expect to develop domain-specific innovations.\n\n### Step 3: Invest in Research Iteration\n\n1. Allocate majority of compute budget to experimentation, not final training\n2. Design fast iteration cycles to test architectural hypotheses\n3. Track ideas systematically—expect most to fail\n4. Look for compounding improvements from combining innovations\n\n### Step 4: Validate with Blind Benchmarks\n\nUse held-out test sets where answers are unknown to prevent overfitting:\n\n```\nValidation Strategy:\n├── Training data: Known structures (e.g., Protein Data Bank)\n├── Validation data: Subset of known structures, held out\n└── Blind test: Problems with unpublished answers\n    └── Example: CASP competition (biennial, ~100 proteins, answers unreleased)\n```\n\n**Critical**: True capability can only be measured on problems where answers are unknown to everyone, including system developers.\n\n### Step 5: Cross the Relevance Threshold\n\n1. Identify domain experts willing to test against their private data\n2. Track word-of-mouth adoption signals\n3. Measure whether users validate predictions independently\n4. Monitor for emergent use cases you didn't anticipate\n\n## Workflow: Releasing Scientific AI Tools\n\n### Accessibility Over Capability\n\nA tool's impact depends more on ease of access than raw capability.\n\n**Example**: AlphaFold's database of 200 million pre-computed predictions drove adoption far more than open-source code alone.\n\n### Release Strategy Checklist\n\n```\n□ Code release (minimum viable)\n  - Open source the model and training code\n  - Provide documentation for technical users\n\n□ Pre-computed results (high impact)\n  - Generate predictions for common use cases\n  - Host accessible database\n  - Enable non-technical users to benefit\n\n□ API access (broader reach)\n  - Remove computational barriers\n  - Enable integration into existing workflows\n\n□ User interface (maximum accessibility)\n  - Build tools for domain experts without ML expertise\n  - Focus on their workflow, not your architecture\n```\n\n### Anticipate Emergent Capabilities\n\nPower users will discover capabilities you didn't design for.\n\n**Example**: Protein interaction prediction emerged from AlphaFold 2 days after release—a capability the team hadn't explicitly built or tested.\n\n**Action**: After release, monitor novel use cases and validate whether they work reliably.\n\n## Decision Framework: Data vs Research Investment\n\nWhen allocating resources between data acquisition and research:\n\n```\nPrioritize DATA when:\n├── Problem is well-understood\n├── Standard architectures perform reasonably\n├── Diminishing returns not yet observed\n└── Data collection is feasible and affordable\n\nPrioritize RESEARCH when:\n├── Off-the-shelf approaches fundamentally fail\n├── Domain constraints require custom solutions\n├── Data is expensive or limited\n└── Existing approaches hit performance ceiling\n```\n\n**Default bias**: Lean toward research investment. The AlphaFold case demonstrates that architectural innovation can provide orders of magnitude more value than data scaling.\n\n## Validation Checklist for Scientific AI\n\nBefore claiming a system works for real-world use:\n\n```\n□ Blind benchmark validation\n  - Test on problems with unknown answers\n  - Use established domain competitions if available\n  - Avoid overfitting to published test sets\n\n□ Ablation studies\n  - Remove each component systematically\n  - Measure contribution to overall performance\n  - Verify no single idea explains >50% of improvement\n\n□ Domain expert validation\n  - Find practitioners with private test data\n  - Track whether they adopt the tool\n  - Monitor word-of-mouth signals\n\n□ Relevance threshold assessment\n  - Define \"useful\" accuracy for domain experts\n  - Measure whether system crosses this threshold\n  - Distinguish benchmark improvement from practical utility\n```\n\n## Key Concepts Reference\n\n| Concept | Definition | Relevance |\n|---------|------------|-----------|\n| Blind benchmark | Evaluation where answers are unknown to all participants | Prevents overfitting, validates true capability |\n| Ablation study | Systematic removal of components to measure contribution | Identifies which innovations matter |\n| Relevance threshold | Accuracy level where predictions become useful to practitioners | Defines real-world success |\n| Equivariance | Neural network property where outputs transform predictably with inputs | Important for physical/geometric domains |\n| Self-distillation | Using model predictions as additional training data | Technique for improving with limited labeled data |\n\n## Anti-Patterns to Avoid\n\n### Benchmark Obsession\nOptimizing for published benchmarks while missing what domain experts actually need.\n\n**Fix**: Define success by practitioner adoption, not leaderboard position.\n\n### Data Hoarding\nAssuming more data will solve fundamental architectural limitations.\n\n**Fix**: Test whether 10x more data would plausibly help before investing in collection.\n\n### Capability Without Accessibility\nBuilding powerful tools that domain experts can't use.\n\n**Fix**: Release in the most accessible format possible—pre-computed results often beat open-source code.\n\n### Single Big Idea Hunting\nSearching for one revolutionary insight instead of accumulating improvements.\n\n**Fix**: Track many mid-scale ideas; expect breakthroughs from combinations.\n\n### Closed Validation\nTesting only on data where you know the answers.\n\n**Fix**: Participate in blind benchmarks; seek domain experts with private test data.",
        "skills/ai-search-strategy-srinivas/SKILL.md": "---\nname: ai-search-strategy-srinivas\ndescription: Knowledge base containing insights from Aravind Srinivas (Perplexity CEO) on building AI-powered search products, competitive strategy against well-funded incumbents, and the future of agentic browsers. Use this skill when users ask about Perplexity's strategy, AI search product development, competing with Google/OpenAI/Anthropic, building answer engines, agentic browser concepts, startup competitive moats, or when analyzing the AI search market landscape. Also use when discussing how to position AI products against incumbents or when exploring the \"cognitive operating system\" concept for browsers.\n---\n\n# Aravind Srinivas: Perplexity's Race to Build Agentic Search\n\n## Overview\n\nThis skill contains strategic insights from a Y Combinator AI Startup School fireside chat with Perplexity CEO Aravind Srinivas. The content covers Perplexity's evolution from a Twitter search tool to an AI answer engine, their strategic bet on building an AI browser, and how they compete against well-funded players like Google, OpenAI, and Anthropic.\n\n## Key Strategic Insights\n\n### Perplexity's Evolution\n\n- Started as a Twitter search tool\n- Evolved into an AI-powered answer engine\n- Current focus: Building an AI browser as a \"cognitive operating system\"\n\n### The Browser Bet\n\nPerplexity's major strategic bet is building an AI browser that serves as more than a chatbot:\n\n**Core concept:** One omnibox for:\n- Navigation\n- Informational queries\n- Agentic tasks\n\n**Key features:**\n- AI assistant on new tab page\n- Sidecar assistant on any page\n- Parallel task execution (like cloud processes)\n- Integration with personal accounts (email, calendar, Amazon, social media)\n- Research capabilities (real estate, markets, etc.)\n\n**Positioning:** \"Cognitive operating system\" rather than just another browser\n\n### Competitive Moat Analysis\n\nAravind's perspective on sustainable competitive advantage:\n\n**Primary moat: Speed**\n> \"The only moat you have is speed. You have to innovate. You have to move faster than everybody else. And it's like running a marathon, but at an extremely high velocity.\"\n\n**Secondary moat: Accuracy**\n- Accuracy at the answer level\n- Accuracy at the task level\n- Orchestration of different tools\n\n**On competition:**\n- Expects OpenAI to build their own browser\n- Expects Anthropic to build their own browser\n- Google already has Chrome\n- Browser is harder to copy than \"yet another chat tool\"\n\n### Response to Competitive Threats\n\nAravind's mindset on competitor moves:\n\n> \"I read all the Twitter comments every time. Google IEL, last year was AI overview and Perplexity is dead. And then it was AI mode and Perplexity is dead. And I read all of that too. And it's always fun. I love it, actually.\"\n\n**Key principle:** When something is worth doing, well-funded players will copy it:\n- Perplexity pioneered answers with sources → everyone now does it\n- Cursor pioneered AI coding → OpenAI buying competitors, Claude Code, Google tools\n- Natural market dynamic when there's money to be made\n\n### Focus Philosophy\n\n> \"There's only a limited amount of things you can be world-class at, whether it's building great models or building one or two really good products.\"\n\n**Perplexity's choice:** Focus entirely on the answer/search/browser experience rather than trying to compete on model development.\n\n## Frameworks for Analysis\n\n### When Analyzing AI Search Products\n\nEvaluate products on:\n1. **Answer accuracy** - Quality of responses with citations\n2. **Source transparency** - Clear attribution and references\n3. **Task orchestration** - Ability to coordinate multiple tools\n4. **Speed** - Response latency and iteration velocity\n5. **Integration depth** - Connection to personal data and services\n\n### When Evaluating Startup Competitive Position\n\nApply Aravind's framework:\n1. **Identify what you can be world-class at** - Pick one thing\n2. **Accept that success attracts copycats** - It's natural and expected\n3. **Speed as primary moat** - Innovate faster than everyone else\n4. **Build what's harder to copy** - Browser > chat tool in difficulty to replicate\n\n### When Discussing \"Cognitive Operating System\" Concept\n\nKey differentiators from traditional browsers:\n- Each query/prompt as its own process (evolution from Chrome's tab-as-process model)\n- Asynchronous task execution\n- Personal context integration\n- Research and agentic capabilities unified in one interface\n\n## Common Questions This Skill Addresses\n\n**\"What is Perplexity's strategy?\"**\n→ Building an AI browser as a cognitive operating system, focusing on speed and accuracy as primary moats\n\n**\"How does Perplexity compete with Google/OpenAI?\"**\n→ Speed of innovation, focus on one thing (search/answers), building harder-to-copy products (browser vs chat)\n\n**\"What is an agentic browser?\"**\n→ Browser where queries run as parallel processes, integrating personal data, enabling research and task completion\n\n**\"What's Perplexity's moat?\"**\n→ Speed and accuracy; explicit acknowledgment that features will be copied by well-funded competitors\n\n**\"How should AI startups think about competition from incumbents?\"**\n→ Focus on one thing, move faster, build what's harder to copy, accept that success attracts imitation\n\n## Usage Notes\n\n- Content reflects Aravind's perspective as of the interview date\n- Strategic insights are most valuable for understanding AI search market dynamics\n- Apply competitive frameworks with awareness that market conditions evolve rapidly\n- Browser/agentic concepts represent Perplexity's bet, not proven market outcomes",
        "skills/ai-startup-insights-altman/SKILL.md": "---\nname: ai-startup-insights-altman\ndescription: Strategic guidance for AI startup founders based on Sam Altman's insights from OpenAI's journey. Use this skill when users ask about starting an AI company, evaluating AI startup ideas, hiring for early-stage AI startups, building products with reasoning models, finding defensibility in AI, or navigating the current AI landscape. Triggers include questions like \"Should I start an AI company?\", \"How do I hire for my AI startup?\", \"Is my AI startup idea good?\", \"How do I compete with OpenAI/big tech?\", \"What should I build with AI?\", or \"How do I find product-market fit in AI?\"\n---\n\n# Sam Altman: AI Startup Strategy\n\nStrategic frameworks and tactical advice for AI founders, distilled from Sam Altman's insights on OpenAI's journey from 8-person research lab to building ChatGPT.\n\n## Core Thesis\n\nThis is the best time in technology history to start a company because AI has created unprecedented opportunities. Startups that pursue unique, contrarian ideas while iterating faster than incumbents will capture the massive value gap between current model capabilities and existing products.\n\n## Key Concepts\n\n### Product Overhang\nThe gap between what AI models can do and products built to leverage those capabilities. Model capabilities far exceed current product innovation—this is where opportunity lives.\n\n### Zero Billion Dollar Startup\nA startup with no revenue targeting a market that could be massive if successful. Both zero-million and zero-billion dollar startups start the same way: a few people in a room trying to get the first thing to work.\n\n### Clock Cycle Disruption\nWhen industry pace accelerates dramatically, startups gain advantage over incumbents. Big companies can't iterate as fast when everything is changing.\n\n### Interface Melting Away\nFuture state where computer interaction becomes seamless and proactive—persistent AI assistance integrated across all data and devices.\n\n## Evaluating AI Startup Ideas\n\n### The Contrarian Filter\n\nAsk these questions in order:\n\n1. **Is this idea contrarian?** If everyone agrees it's a good idea, the market is likely crowded\n2. **Do you have evidence or conviction you're right?** Contrarian and wrong is just wrong\n3. **Could this be big if it works?** Pick markets with massive upside potential\n4. **Are you competing with the top 5 ideas everyone else is building?** If yes, reconsider\n\n### What NOT to Build\n\n- ChatGPT clones or thin wrappers\n- Ideas where you're competing with obvious applications everyone is pursuing\n- Products that don't leverage new capabilities (reasoning, agents, multimodal)\n\n### What TO Build\n\n- Products exploiting the product overhang (capabilities > current products)\n- Applications for reasoning models (O3/O4 class)—the interaction model is fundamentally different\n- AI for science—highest-impact applications with compounding returns\n- Tools that reduce coordination costs by empowering individuals\n\n### Idea Evaluation Template\n\n```\n## Startup Idea Assessment\n\n**Idea:** [One sentence description]\n\n### Contrarian Check\n- [ ] Most people would disagree this is a good idea\n- [ ] I have specific evidence/conviction for why I'm right\n- [ ] This is NOT one of the obvious top 5 AI applications\n\n### Market Potential\n- [ ] If this works, the market could be massive\n- [ ] I can articulate a path from zero to significant scale\n\n### Capability Match\n- [ ] This leverages capabilities that didn't exist 12-24 months ago\n- [ ] This isn't possible without current AI models\n- [ ] I'm building for where models are going, not just where they are\n\n### Competitive Position\n- [ ] Big companies would be slow to respond to this\n- [ ] The clock cycle change favors fast iteration\n- [ ] I can concentrate talent around this mission\n```\n\n## Hiring for Early-Stage AI Startups\n\n### The Slope vs Y-Intercept Framework\n\nPrioritize rate of growth over current position.\n\n**Evaluation Order:**\n1. Look at most impressive things accomplished BEFORE looking at resume\n2. Assess learning velocity and adaptability\n3. Check credentials last (if at all)\n\n### Early-Stage Hiring Criteria\n\n**Hire:**\n- Young, scrappy people who get stuff done\n- Those with impressive accomplishments relative to their experience\n- People who resonate with contrarian missions\n- Builders who ship\n\n**Avoid:**\n- Very senior administrators (save for later stages)\n- People who need structure before they can execute\n- Those optimizing for credentials over impact\n\n### Hiring Evaluation Process\n\n1. **Pre-screen:** What's the most impressive thing this person has done?\n2. **Dig deeper:** Was this self-directed or assigned? What obstacles did they overcome?\n3. **Mission fit:** Do they light up when discussing the contrarian vision?\n4. **Execution test:** Give a small, ambiguous project. How do they handle it?\n5. **Credentials:** Only now consider resume, schools, previous companies\n\n### Interview Questions\n\n- \"What's the most impressive thing you've built or accomplished?\"\n- \"Tell me about a time you pursued something others thought was a bad idea\"\n- \"How do you decide what to work on when no one is telling you?\"\n- \"What would you build if you had unlimited resources but only 3 months?\"\n\n## Building Products with Reasoning Models\n\n### Key Insight\n\nReasoning models (O3, O4 class) require a fundamentally different interaction model. Don't just swap in a smarter model—redesign the product.\n\n### Design Principles for Reasoning Models\n\n1. **Longer time horizons:** Users can wait minutes for genuinely valuable output\n2. **Higher stakes tasks:** Worth the latency for complex analysis, research, planning\n3. **Multi-step workflows:** Break complex problems into reasoning chains\n4. **Verification loops:** Let the model check its own work\n\n### Product Categories by Model Type\n\n**Fast models (GPT-4 class):** Chat, quick queries, real-time interaction\n**Reasoning models (O3/O4 class):** Deep research, complex analysis, agentic tasks, code generation\n\n## Finding Defensibility\n\n### The Timing Principle\n\nDefensibility comes AFTER product-market fit, not before.\n\n**Sequence:**\n1. Build something uniquely good\n2. Get users (you're \"the only good thing\")\n3. Use the window to build moats\n4. Then worry about defensibility\n\n### Sources of Defensibility (Seven Powers Framework)\n\nConsider these after achieving product-market fit:\n- Scale economies\n- Network effects\n- Counter-positioning\n- Switching costs\n- Branding\n- Cornered resource\n- Process power\n\n### The Concentrated Talent Moat\n\nContrarian missions attract concentrated talent. When you're doing a one-of-one thing:\n- Smart people who believe in it have nowhere else to go\n- You get the 1% who resonate deeply, not the 99% who think you're crazy\n- This concentration compounds over time\n\n## Navigating Setbacks\n\n### The Conviction Test\n\nExpect to be told you're wrong by people you admire. This is genuinely hard but essential.\n\n**Resilience Framework:**\n1. Acknowledge the criticism has merit (99% of people aren't stupid)\n2. Examine your evidence/conviction for the contrarian position\n3. If conviction holds, continue. If not, pivot.\n4. Repeat for years.\n\n### OpenAI's Early Challenges\n\n- AGI sounded crazy in 2015\n- DeepMind seemed impossibly far ahead\n- No ideas for products, no revenue, no path to revenue\n- Sitting around whiteboards trying to think of papers to write\n- ChatGPT was \"completely in the realm of science fiction\"\n\n**Lesson:** What seems improbable now may look obvious later. The improbability is a feature, not a bug—it's why others aren't doing it.\n\n## The Future of AI Interfaces\n\n### Where Things Are Going\n\n- Interface \"melts away\" into persistent AI assistance\n- Proactive, not just reactive\n- Integrated across all data and devices\n- AI companions that know your context\n\n### Implications for Builders\n\n- Don't optimize for current interface paradigms\n- Build for a world where AI is ambient\n- Consider what becomes possible when AI is always present\n- Think about AI as reducing coordination costs, empowering individuals\n\n## Mental Models Reference\n\n### Contrarian but Right\nSeek opportunities where you disagree with conventional wisdom but have evidence you're correct. The intersection is small but valuable.\n\n### Clock Cycle Disruption\nWhen industry pace changes dramatically, startups iterate faster than incumbents. This is when giants fall and new companies rise.\n\n### Transistor Analogy\nAI is like the transistor—a fundamental discovery that society will figure out how to apply across all domains. Don't try to predict all applications; focus on what you can build now.\n\n### Nail-then-Scale\nPerfect the core AI capability first, then extend to adjacent applications. Don't spread too thin before the foundation is solid.",
        "skills/ai-startup-questions-fisher/SKILL.md": "---\nname: ai-startup-questions-fisher\ndescription: Strategic questioning framework for AI startup founders navigating AGI uncertainty. Use when founders or entrepreneurs need to evaluate AI startup ideas, assess defensibility in a rapidly changing landscape, plan strategy assuming 2-3 year AGI timelines, determine what problems remain hard when AI capabilities expand, or think through hiring/product/go-to-market decisions in the AI era. Triggers include questions like \"Should I start this AI company?\", \"How do I plan for AGI?\", \"What's defensible in AI?\", \"How should AI change my startup strategy?\", or \"What questions should I ask before building an AI product?\"\n---\n\n# AI Startup Strategic Questioning Framework\n\nFramework for founders to navigate extreme uncertainty in the AI era by asking fundamental questions about defensibility, trust, timing, and what remains hard.\n\n## Core Philosophy\n\nThe AI landscape changes faster than traditional planning horizons allow. Stop planning for 6 months ahead—plan for 2-3 years when AGI may arrive. Embrace confusion as a signal that something interesting is happening.\n\n**Key insight**: Founders must focus on everything while focus is everything. This paradox makes founders uniquely suited to grapple with AI's biggest questions.\n\n## Strategic Questioning Process\n\n### Step 1: Assess the Timing Question\n\nAsk these questions about timing and market position:\n\n1. \"What will AI be capable of in 2-3 years, not 6 months?\"\n2. \"Am I building for today's capabilities or tomorrow's?\"\n3. \"Is this the last window to build something that changes the world?\"\n4. \"What's my advantage if I can't see 5 years ahead anymore?\"\n\n**Output**: Document assumptions about AI capability trajectory and how they affect your thesis.\n\n### Step 2: Evaluate Defensibility\n\nChallenge traditional moats with these questions:\n\n1. \"What happens to my product when the next foundation model ships?\"\n2. \"Does my defensibility come from data, distribution, or something AI can't replicate?\"\n3. \"If AGI arrives in 3 years, does my company still matter?\"\n4. \"What do I have that a well-funded competitor with better models doesn't?\"\n\n**Defensibility categories to examine**:\n- Data network effects (does usage make the product better?)\n- Trust relationships (do customers need a human in the loop?)\n- Regulatory positioning (are there compliance moats?)\n- Integration depth (how painful is switching?)\n\n### Step 3: Identify What Remains Hard\n\nFocus on problems that stay hard even as AI improves:\n\n1. \"What can't be solved by throwing more compute at it?\"\n2. \"What requires trust, accountability, or human judgment?\"\n3. \"What problems have regulatory or legal constraints AI can't navigate alone?\"\n4. \"Where do customers need someone to blame when things go wrong?\"\n\n**Categories of durable difficulty**:\n- High-stakes decisions requiring accountability\n- Relationship-dependent sales and partnerships\n- Physically constrained operations\n- Regulated industries requiring human oversight\n\n### Step 4: Rethink Team and Hiring\n\nQuestion traditional hiring assumptions:\n\n1. \"How does AI change what roles I need to hire?\"\n2. \"Should I hire fewer people and use AI for more?\"\n3. \"What human skills become more valuable, not less?\"\n4. \"How do I build a team that adapts as AI capabilities shift?\"\n\n### Step 5: Challenge Your Go-to-Market\n\nQuestion distribution and sales strategy:\n\n1. \"Does my go-to-market depend on capabilities that will be commoditized?\"\n2. \"Am I selling AI or solving a problem that happens to use AI?\"\n3. \"What's my moat if the AI layer becomes interchangeable?\"\n4. \"How do I build trust with customers in a hype-saturated market?\"\n\n## Question Framework Template\n\nUse this template when evaluating any AI startup decision:\n\n```markdown\n## Decision: [What you're deciding]\n\n### Capability Questions\n- What AI capabilities does this assume?\n- How might those capabilities change in 6/12/24 months?\n- What breaks if the assumption is wrong?\n\n### Defensibility Questions\n- What's the moat if this works?\n- Can a better-funded competitor with better models replicate this?\n- What do we have that's hard to copy?\n\n### Trust Questions\n- Do customers need a human accountable for this?\n- What's the cost of AI being wrong here?\n- How do we build trust in an uncertain landscape?\n\n### Timing Questions\n- Why now and not 2 years ago or 2 years from now?\n- Is this a shrinking or expanding window?\n- What changes if AGI arrives in 3 years?\n\n### Team Questions\n- What human skills does this require?\n- How does AI augment vs. replace those skills?\n- What happens to this role in 2 years?\n```\n\n## Common Pitfalls to Question\n\n### The \"AI Wrapper\" Trap\nAsk: \"Am I just wrapping an API that will be commoditized?\"\n\nSigns of danger:\n- Primary value is prompt engineering\n- No proprietary data or workflows\n- Switching costs are low\n\n### The \"Current Capabilities\" Trap\nAsk: \"Am I building for GPT-4 or for what comes next?\"\n\nSigns of danger:\n- Product relies on current model limitations\n- No plan for capability improvements making features obsolete\n- Competing on capabilities that will be table stakes\n\n### The \"Ignoring Trust\" Trap\nAsk: \"Do I understand why customers might not trust pure AI solutions?\"\n\nSigns of danger:\n- Assuming AI accuracy alone drives adoption\n- Underestimating need for human oversight\n- Missing regulatory or liability concerns\n\n## Example Application\n\n**Scenario**: Evaluating an AI legal document review startup\n\n**Capability Questions**:\n- Current: AI can review documents but misses nuance\n- 2-year projection: Near-human accuracy likely\n- Risk: Accuracy alone won't differentiate\n\n**Defensibility Questions**:\n- Data moat: Do we accumulate proprietary training data?\n- Trust moat: Law firms need accountability—who's liable for AI errors?\n- Integration moat: How deep are we in existing workflows?\n\n**Conclusion questions**:\n- \"Is our moat the AI or the trust relationship with law firms?\"\n- \"What do we offer when document review AI is commoditized?\"\n- \"Are we building a tool or a trusted service?\"\n\n## The Meta-Question\n\nAlways return to the foundational question:\n\n> \"Everything's changing. How should that impact everything about my life—and my startup?\"\n\nThis isn't a question to answer once. Revisit it regularly as the landscape shifts. The founders who thrive will be those comfortable operating in permanent uncertainty while still making decisive moves.",
        "skills/b2b-ai-startup-levie/SKILL.md": "---\nname: b2b-ai-startup-levie\ndescription: Strategic framework for evaluating and building B2B AI startups based on Aaron Levie's insights from building Box through the cloud transformation. Use when founders or advisors need to - (1) Evaluate AI startup ideas for defensibility and market timing, (2) Design pricing models for AI products (consumption vs seat-based), (3) Analyze competitive positioning against incumbents, (4) Identify high-value AI opportunities in enterprise unstructured data, (5) Assess whether to target \"core\" vs \"context\" business functions, (6) Understand the 2024-2027 AI startup window dynamics, or (7) Apply Innovator's Dilemma and Crossing the Chasm frameworks to AI market entry.\n---\n\n# Aaron Levie: Why Startups Win in the AI Era\n\nStrategic frameworks and tactical guidance for building B2B AI startups during the 2024-2027 window.\n\n## Core Thesis\n\nAI creates a once-in-a-decade window for startups to build transformative companies by targeting enterprise work that was previously uneconomical to automate. This window closes approximately 2027.\n\n**Key insight**: Target work categories where AI fundamentally changes economics, not incremental \"X with AI\" improvements to existing software that incumbents will address.\n\n## The Opportunity Framework\n\n### Structured vs Unstructured Data\n\n| Data Type    | Examples                                              | Historical Automation                   | AI Opportunity          |\n| ------------ | ----------------------------------------------------- | --------------------------------------- | ----------------------- |\n| Structured   | Customer IDs, invoice numbers, revenue figures        | Fully automated by traditional software | Marginal improvement    |\n| Unstructured | Documents, contracts, presentations, marketing assets | Never automated                         | **Massive opportunity** |\n\n**Action**: Focus AI efforts on unstructured data workflows where software never could automate before.\n\n### The Nouns and Verbs Exercise\n\nList all human activities (eat, sleep, travel, watch, read, write, analyze) and identify:\n\n1. Which problems technology has already solved\n2. Which remain unsolved\n3. Which AI now makes economically viable to solve\n\n## Market Timing Assessment\n\n### The Window (2024-2027)\n\n```\n2008-2014: Consumer/enterprise \"nouns and verbs\" solved\n2024-2027: AI startup window open ← WE ARE HERE\nPost-2027: Markets saturated, harder to enter\n```\n\n**Evaluate timing with**:\n\n- Is this problem newly economical to solve with AI?\n- Would this have been possible 2 years ago?\n- Will incumbents address this within 18 months?\n\n## Competitive Positioning\n\n### Core vs Context Framework (Geoffrey Moore)\n\n| Type    | Definition                  | Who Builds It      | Examples                                           |\n| ------- | --------------------------- | ------------------ | -------------------------------------------------- |\n| Core    | Differentiates the company  | In-house or custom | Trading algorithms, proprietary analytics          |\n| Context | Necessary but non-strategic | Buy from vendors   | HR systems, expense reporting, document management |\n\n**Strategic insight**: Enterprises will NOT build custom AI for \"context\" functions due to maintenance burden and liability. They only build for \"core\" differentiating activities.\n\n**Action**: Target \"context\" functions—enterprises will buy, not build.\n\n### Incumbent Analysis Workflow\n\n1. **List competitor capabilities** (be generous in assumptions)\n2. **Assume they execute perfectly** on AI integration\n3. **Identify remaining gaps**:\n   - Speed to market (your advantage)\n   - Organizational constraints (their disadvantage)\n   - Technical debt (their disadvantage)\n   - Incentive misalignment (their disadvantage)\n4. **Design strategy that wins even if their AI agents are excellent**\n\nExample analysis for competing with Workday:\n\n```\nWorkday strengths: Existing customer base, data access, brand trust\nWorkday constraints: Can't cannibalize seat revenue, slow product cycles\nYour opportunity: Consumption-based model for work Workday doesn't automate\nWin condition: Target workflows Workday has no incentive to automate\n```\n\n## Pricing Model Design\n\n### Seat-Based vs Consumption-Based\n\n| Model             | Characteristics            | Constraints                          | Best For         |\n| ----------------- | -------------------------- | ------------------------------------ | ---------------- |\n| Seat-based        | Per user/license           | Limited by job function demographics | Traditional SaaS |\n| Consumption-based | Per unit of work processed | Scales with usage                    | AI products      |\n\n### Recommended AI Pricing Structure\n\n```\nBase: Subscription floor (predictable revenue)\nVariable: Consumption above baseline (captures growth)\nMargin target: 80-90% gross margin\n```\n\n**Token-to-Value Stack Assessment**:\n\n```\nRaw AI token cost: $X\nYour price: Should be >> 2X token cost\nSoftware value above tokens: This determines your margin\n```\n\n**Warning signs of price compression**:\n\n- Margin approaching 2x token costs\n- No proprietary workflow above AI layer\n- Easily replicable with raw API calls\n\n**Action**: Build substantial software layers above AI tokens to maintain margins.\n\n## Startup Idea Evaluation\n\n### Quick Assessment Checklist\n\n- [ ] Does AI fundamentally change the economics? (Not just \"faster/cheaper\")\n- [ ] Is this unstructured data or context work? (Not already automated)\n- [ ] Would incumbents face disincentives to build this?\n- [ ] Can you build 80%+ margin above token costs?\n- [ ] Is the timing right? (Not too early, not too late)\n\n### Red Flags\n\n- \"X with AI\" positioning (incremental improvement)\n- Targeting structured data already in databases\n- Competing directly with incumbent's core product\n- Thin wrapper over AI APIs with no proprietary workflow\n- Targeting \"core\" enterprise functions (they'll build in-house)\n\n### Green Flags\n\n- New category of work now economically viable\n- Unstructured data transformation\n- \"Context\" function incumbents won't prioritize\n- Clear consumption-based monetization path\n- 18+ month lead time before incumbent response\n\n## Founder Preparation\n\n### Required Reading (Complete Before Starting)\n\n1. **Innovator's Dilemma** (Clayton Christensen)\n   - Key takeaway: Successful companies fail to adopt disruptive tech serving niche markets\n   - Application: Identify where incumbents are structurally unable to respond\n\n2. **Crossing the Chasm** (Geoffrey Moore)\n   - Key takeaway: Gap between early adopters and mainstream requires different strategies\n   - Application: Plan distinct go-to-market for each phase\n\n3. **Blue Ocean Strategy**\n   - Key takeaway: Create uncontested market space rather than competing in existing markets\n   - Application: Define category where you don't compete head-to-head\n\n### Team Composition\n\n- Find a co-founder even if not technical\n- AI enables small teams to act like large companies\n- Prioritize great design in enterprise software (differentiation opportunity)\n\n## AI Impact Mental Model\n\n### What AI Does NOT Do\n\n- Eliminate jobs wholesale\n- Make all enterprise software obsolete\n- Enable enterprises to build everything custom\n\n### What AI DOES Do\n\n- Frees human time for strategic work\n- Makes previously uneconomical work viable\n- Shifts value capture from seat count to work volume\n- Creates leverage for small teams\n\n**Reframe**: \"AI is coming for jobs\" → \"AI eliminates non-strategic activities humans shouldn't be doing\"\n\n## Quick Reference: Decision Trees\n\n### Should I Build This AI Product?\n\n```\nIs the work currently automated by software?\n├─ Yes → Likely incremental improvement, incumbents will address\n└─ No → Continue evaluation\n   │\n   Is this \"core\" or \"context\" for target customers?\n   ├─ Core → They'll build in-house, risky market\n   └─ Context → Continue evaluation\n      │\n      Can you build 80%+ margin above token costs?\n      ├─ No → Thin wrapper, will face price compression\n      └─ Yes → Strong candidate, assess timing\n```\n\n### How Should I Price This?\n\n```\nWhat's the natural unit of work?\n├─ Documents processed\n├─ Queries answered\n├─ Workflows completed\n└─ [Define your consumption unit]\n   │\n   Set subscription floor at: Expected base usage\n   Set variable rate at: Captures 80%+ margin above token cost\n   Validate: Revenue grows with customer value, not headcount\n```\n\n## Examples from Box's Journey\n\n### Cloud Transformation Parallels\n\n| Cloud Era (2005-2015)                            | AI Era (2023-2027)                                |\n| ------------------------------------------------ | ------------------------------------------------- |\n| Had to convince people cloud was coming          | Everyone already believes AI is coming            |\n| Mobile + cloud created new IT architecture       | AI + agents create new work architecture          |\n| Freemium → enterprise pivot worked               | Consumption + subscription hybrid emerging        |\n| Competed by being cheaper/faster than incumbents | Compete by automating what incumbents can't/won't |\n\n### Key Lesson from Box\n\nBox pivoted from consumer to enterprise because:\n\n1. Consumer platforms would give away storage free\n2. Couldn't monetize against bundled offerings\n3. Enterprise had clear value prop: cheaper, faster, easier than incumbents\n\n**AI application**: Don't compete where AI is commoditized. Find enterprise workflows where your AI solution creates clear, monetizable value above raw AI capabilities.\n",
        "skills/design-tool-scaling-field/SKILL.md": "---\nname: design-tool-scaling-field\ndescription: Strategic guidance for design-focused founders and product leaders based on Dylan Field's experience scaling Figma from a WebGL experiment to an 8-product company with 1700 employees. Use when seeking advice on founding design-tool companies, evaluating product-market fit signals, making early startup decisions (launching, pricing, pivoting), understanding how AI changes design's value proposition, integrating designers into AI product development, or applying mental models for startup leadership and product strategy. Triggered by questions about design entrepreneurship, startup scaling, product-market pull vs fit, cold outreach strategies, roadmap planning, or the future of design in AI era.\n---\n\n# Dylan Field: Scaling Figma and the Future of Design\n\nStrategic insights from Figma's founder on building design companies, recognizing product-market pull, and positioning design in the AI era.\n\n## Core Thesis\n\nDesign becomes the primary differentiator as AI makes development easier. Designers must step into founder and leadership roles to capture this value.\n\n## Key Mental Models\n\n### Product-Market Pull vs Product-Market Fit\n\nProduct-market fit is necessary but insufficient. Look for **product-market pull**:\n\n| Signal | Product-Market Fit | Product-Market Pull |\n|--------|-------------------|---------------------|\n| User engagement | Users find value | Users are obsessive |\n| Feedback tone | \"This is useful\" | \"I see where this is going\" |\n| Behavior | Regular usage | Users pull features out of you |\n| Vision | Solves current problem | Users buy into future vision |\n\n**Application**: When evaluating early traction, passionate negative feedback (\"this isn't ready yet\") may indicate pull—users care enough to be frustrated because they see the potential.\n\n### Asymmetric Risk Evaluation\n\nFrame decisions by downside and upside:\n\n```\nDownside (worst case): Is this acceptable?\n  → Working with smart people, learning, returning to previous state\n\nUpside (best case): Is this significant?\n  → Building something meaningful at scale\n\nIf downside is acceptable and upside is significant → proceed\n```\n\n### The Startup Leadership Cycle\n\n```\n1. Identify what you're doing most\n2. Get someone else to help with it\n3. Find resources if needed\n4. Repeat\n```\n\nApply this continuously as you scale. Your role should constantly evolve.\n\n### Extract Behavior Into Products\n\nWhen users develop workarounds or emergent behaviors in your product:\n\n1. Notice the pattern\n2. Validate it's widespread\n3. Spin it into a dedicated product\n\n**Example**: FigJam emerged from observing how users were using Figma for brainstorming.\n\n## Actionable Workflows\n\n### Cold Outreach for Early Users and Feedback\n\n**When to use**: Seeking early users, mentorship, or expert feedback.\n\n1. Identify people you genuinely admire\n2. Research their specific work you respect\n3. Write concise email with:\n   - Specific reference to their work\n   - Clear ask (feedback, 15-minute call)\n   - Why you reached out to them specifically\n4. Send without overthinking\n5. Follow up once if no response\n\n**Key insight**: People respond more than you expect. Dylan credits cold emails for critical early relationships.\n\n### Launch and Monetization Timing\n\n**Default bias**: Launch and charge money faster than feels comfortable.\n\n**Figma's mistake**: Waited 5 years to monetize. Don't repeat this.\n\n```\nIf asking \"Should we launch yet?\"\n  → Probably yes\n\nIf asking \"Should we start charging?\"\n  → Probably yes\n\nIf asking \"Is the product ready?\"\n  → Ship it, get feedback, iterate\n```\n\n**Exception**: Deep technical infrastructure (like WebGL rendering engine) may require longer development before launch.\n\n### Roadmap Planning\n\n**Maximum cadence**: 1-3 months\n\n```\nWhen presented with epic roadmap:\n1. Challenge any item planned beyond 3 months\n2. Ask: \"What can we ship in the next month?\"\n3. Slim down to what delivers value fastest\n4. Reassess after each cycle\n```\n\n**Anti-pattern**: Multi-year roadmaps with detailed specifications. The market and technology change too fast.\n\n### Multi-Signal Synthesis for User Understanding\n\nCombine multiple signals to understand user needs:\n\n```\n1. Support requests → What's broken or confusing\n2. Qualitative interviews → Deep context and emotion\n3. User observation → What they do vs what they say\n4. Data analysis → Patterns at scale\n5. Social media signals → Unfiltered reactions\n```\n\nNo single signal is sufficient. Synthesize across all channels.\n\n## AI and Design Strategy\n\n### Design's Increasing Value\n\nAs AI makes development faster and easier:\n\n- Supply of \"built things\" increases\n- Craft, point of view, and attention to detail become differentiators\n- Design becomes the scarce, valuable resource\n\n**Implication**: Invest in design capabilities. They compound in value as AI improves.\n\n### Integrating Designers into AI Development\n\n**Key practice**: Embed designers in AI research teams.\n\n```\nTraditional: Researchers build → Designers polish UI\nBetter: Designers contribute to model evals\n\nWhy: Designers understand end users better than researchers.\nThey can evaluate whether outputs actually serve user needs.\n```\n\n### Current AI Era Framing\n\nWe are in the \"MS-DOS era\" of AI:\n- Current interfaces (chat boxes) are primitive\n- Massive design opportunities exist\n- Looking back, today's AI UX will seem laughably basic\n\n**Opportunity**: Design the next paradigm of AI interaction.\n\n## Founder Mindset Principles\n\n### Seek Rejection Actively\n\n```\nReframe rejection:\n- Not: \"They said no, my idea is bad\"\n- Instead: \"They said no, what data can I extract?\"\n\nMine rejection for:\n- Specific objections to address\n- Market timing signals\n- Positioning adjustments\n```\n\n### Give Yourself Time\n\nFigma would not exist if they had stopped at 6 months.\n\n```\nBefore starting:\n1. Calculate minimum runway needed\n2. Add buffer for pivots and exploration\n3. Secure that runway before starting\n4. Protect the time—don't let arbitrary deadlines kill good ideas\n```\n\n### Evaluate Surprising Decisions Charitably\n\nWhen successful people make decisions you don't understand:\n\n```\nDefault assumption: You're missing something\nNot: They're making a mistake\n\nAction: Ask questions to understand their reasoning\n```\n\n## Key Quotes and Principles\n\n- \"Keep simple things simple, make complex things possible\" — Balance accessibility with power\n- \"Designers need to be founders\" — Design leadership is underrepresented in company formation\n- \"Seek rejection and mine it for data\" — Feedback, even negative, is valuable signal\n- \"Give yourself enough runway/time\" — Many good ideas die from artificial constraints\n\n## Technology Context\n\n| Term | Definition |\n|------|------------|\n| WebGL | JavaScript API for GPU-accelerated 2D/3D graphics in browsers |\n| WebGPU | WebGL's successor with more modern GPU access |\n| MCP Server | Model Context Protocol—allows AI tools to access external data/designs |",
        "skills/developer-tools-strategy-truell/SKILL.md": "---\nname: developer-tools-strategy-truell\ndescription: Strategic guidance for building developer tools and AI-first products, derived from Michael Truell's experience building Cursor. Use when- (1) Evaluating whether to enter a market with established competitors, (2) Deciding between product improvement vs growth engineering investment, (3) Architecting AI-assisted developer tools, (4) Choosing between building custom infrastructure vs using existing solutions, (5) Navigating early user feedback that conflicts with product vision, (6) Assessing startup opportunities in AI/developer tools space, (7) Planning technical product launches and distribution strategies.\n---\n\n# Building Developer Tools & AI Products: Cursor Case Study\n\nStrategic framework for building AI-first developer tools based on Michael Truell's approach to building Cursor into a $100M ARR company competing against GitHub Copilot.\n\n## Core Philosophy\n\n### The Consistent Beliefs Framework\n\nTake technology beliefs to their logical conclusion and build for that end state:\n\n1. Identify your core belief about where technology is heading\n2. Ask: \"If this is true, what does the world look like in 5 years?\"\n3. Evaluate competitors: Are they building for that end state or incrementally improving?\n4. Build for the extreme version of your belief\n\n**Example from Cursor:**\n- Belief: All coding will flow through AI models\n- Observation: Competitors had great products but weren't aiming for full automation\n- Action: Build assuming all coding gets automated, not just assisted\n\n### Product-Growth Feedback Loop\n\nIn developer tools with strong word-of-mouth:\n\n```\nProduct Quality → User Satisfaction → Organic Sharing → Growth\n```\n\n**When to apply:** Developer tools, technical products, B2B with technical buyers\n\n**Key insight:** Product improvements drive growth more effectively than growth engineering in markets where:\n- Users are technical and evaluate products critically\n- Word-of-mouth is the primary distribution channel\n- Switching costs are moderate (users can try alternatives easily)\n\n## Decision Frameworks\n\n### Market Entry Assessment\n\nUse when evaluating whether to enter a market with established competitors:\n\n```\n1. BELIEF ALIGNMENT\n   □ Do you have genuine conviction about the future of this space?\n   □ Are you excited to work on this regardless of market size?\n   □ Would you work on this even if it seemed \"impossible\"?\n\n2. COMPETITOR COMMITMENT ANALYSIS\n   □ Are incumbents building for the extreme version of the trend?\n   □ Are they constrained by existing business models?\n   □ Do they have organizational incentives to move slowly?\n\n3. CAPABILITY GAP\n   □ What would you build that they aren't building?\n   □ Can you move faster due to fewer constraints?\n   □ Do you have unique insights from failed projects in this space?\n```\n\n**Red flags (avoid the market):**\n- Entering based on \"armchair MBA thinking\" (market looks big, competitors seem beatable)\n- No genuine excitement about the problem\n- Competitors are already building for the extreme end state\n\n### Build vs. Buy vs. Fork Decision\n\nUse when architecting technical products:\n\n```\nSTART WITH EXISTING SOLUTIONS\n├── Can you fork established open source? (VS Code, Code Mirror)\n│   └── Yes → Fork and customize\n│       └── Only build custom when product-necessary\n│\n├── Can you use API models? (OpenAI, Anthropic)\n│   └── Yes → Start with APIs\n│       └── Build own models when:\n│           ├── You have unique product data\n│           ├── Data enables measurable improvement\n│           └── Scale justifies investment\n│\n└── Must you build from scratch?\n    └── Only if: existing solutions fundamentally can't support your vision\n```\n\n**Cursor's path:**\n1. Forked VS Code (didn't rebuild editor)\n2. Started with API models (didn't train own models initially)\n3. Built own models when product data enabled improvement\n\n### Early User Feedback Navigation\n\nUse when users request features that conflict with product vision:\n\n```\nFEEDBACK TYPE          | RESPONSE\n-----------------------|------------------------------------------\nPulls toward niche     | Resist. Stay horizontal.\n\"Add X for enterprise\" | Evaluate: Does this serve the core vision?\n\"Specialize for Y\"     | Ask: Would this limit future expansion?\nQuality complaints     | Prioritize. Product quality drives growth.\nCore workflow friction | Fix immediately. This is your product.\n```\n\n**Warning signs of dangerous feedback:**\n- Early users want you to specialize for their specific use case\n- Requests that would make you \"the AI coding tool for X industry\"\n- Features that add complexity without serving the automation vision\n\n## Technical Architecture Patterns\n\n### AI-Assisted Coding Tool Components\n\nKey capabilities that differentiate modern AI coding tools:\n\n| Component | Description | Implementation Priority |\n|-----------|-------------|------------------------|\n| Next edit prediction | Predict user's next action proactively | High - differentiator |\n| Codebase awareness | Understand full project context | High - table stakes |\n| Inline suggestions | Autocomplete within editor flow | Medium - competitive parity |\n| Chat interface | Conversational coding assistance | Medium - expected feature |\n\n### Complexity Budget Management\n\nEnd-user applications have limited cognitive overhead capacity:\n\n```\nCOMPLEXITY BUDGET ALLOCATION:\n\nEssential (must be simple):\n├── Core editing workflow\n├── AI suggestion acceptance/rejection\n└── Basic navigation\n\nAcceptable complexity:\n├── Advanced features behind progressive disclosure\n├── Configuration for power users\n└── Integrations that stay out of the way\n\nOver budget (avoid):\n├── Required setup steps before value\n├── Mandatory learning before productivity\n└── Interruptions to flow state\n```\n\n## Startup Execution Patterns\n\n### Pre-Launch Distribution (Technical Products)\n\nBuild audience through genuine technical engagement:\n\n1. **Create technical content** that demonstrates expertise\n2. **Engage authentically** with the developer community\n3. **Share learnings** from building (not just marketing)\n4. **Build in public** when possible\n\n**What doesn't work:**\n- Growth hacking without product quality\n- Marketing-first approach for developer tools\n- Artificial scarcity or hype\n\n### Failed Project Value Extraction\n\nPrevious failures are preparation, not waste:\n\n```\nFROM FAILED PROJECTS, EXTRACT:\n├── Technical skills learned\n├── Collaboration patterns with co-founders\n├── Domain knowledge accumulated\n├── Emotional readiness to take on \"impossible\" problems\n└── Clear understanding of what doesn't work\n```\n\n**Cursor co-founders worked together on multiple failed projects before Cursor.**\n\n### Resource Allocation Framework\n\nFor developer tools startups:\n\n```\nPHASE 1 (Pre-product-market fit):\n├── 90% Product improvement\n├── 10% Distribution/marketing\n└── 0% Growth engineering\n\nPHASE 2 (Early traction):\n├── 80% Product improvement\n├── 15% Distribution\n└── 5% Growth optimization\n\nPHASE 3 (Scaling):\n├── 60% Product improvement\n├── 25% Distribution\n└── 15% Growth infrastructure\n```\n\n## Mental Models Reference\n\n### Armchair MBA Thinking (Anti-Pattern)\n\nMaking startup decisions based on theoretical market analysis:\n- \"This market is big\"\n- \"Competitors seem beatable\"\n- \"The timing is right\"\n\n**Better approach:** Choose based on genuine excitement and unique insight.\n\n### The Long Messy Middle\n\nThe transition period where humans and AI collaborate:\n- Full automation is the end state\n- Current state requires human-AI collaboration\n- Build tools that serve both states\n- Don't optimize only for today's workflow\n\n### Desperation as Catalyst\n\nFailed projects create emotional conditions for bold moves:\n- After multiple failures, \"impossible\" competitors seem less scary\n- Desperation enables taking on GitHub/Microsoft\n- Previous failures reduce fear of failure\n\n## Key Principles Summary\n\n1. **Build for extreme beliefs** - Competitors often don't fully commit to stated beliefs\n2. **Product over growth** - Quality improvements drive growth in developer tools\n3. **Resist niche pressure** - Stay horizontal despite early user pull\n4. **Start pragmatic** - Fork, use APIs, build custom only when necessary\n5. **Value failed projects** - They build skills and emotional readiness\n6. **Genuine distribution** - Technical engagement beats growth hacking",
        "skills/enterprise-ai-strategy-nadella/SKILL.md": "---\nname: enterprise-ai-strategy-nadella\ndescription: Strategic AI thinking frameworks and mental models from Satya Nadella's perspective on platform shifts, AI deployment, and building successful AI products. Use when evaluating AI strategy decisions, assessing platform opportunities, thinking through AI product positioning, considering enterprise AI deployment challenges, evaluating talent and team capabilities, or needing frameworks for justifying AI investments in terms of economic surplus. Triggers on questions about AI platform strategy, change management for AI adoption, building AI scaffolding layers, evaluating AI opportunities, or thinking through AI's societal implications.\n---\n\n# Satya Nadella AI Strategy Frameworks\n\nStrategic frameworks and mental models for AI platform thinking, deployment strategy, and building successful AI products.\n\n## Core Thesis\n\nAI represents the fourth major platform shift in computing (after client-server, web, mobile-cloud). Success is measured not by model capabilities but by whether it creates genuine economic surplus—earning the social permission to consume the energy it requires.\n\n## Platform Opportunity Assessment\n\n### Three-Layer Platform Model\n\nEvaluate AI opportunities across three layers:\n\n1. **Infrastructure layer** - System software, compute optimization, training infrastructure\n2. **Model layer** - Treat as \"SQL for AI\"—a stable abstraction to build upon\n3. **Application layer** - Where differentiation happens through scaffolding, memory, and tool use\n\n### Platform Compounding Principle\n\nEach platform generation builds on the previous:\n- Cloud infrastructure → AI supercomputers → Models → Products\n- Rate of AI diffusion is fast because it compounds on cloud/mobile foundations\n- Identify what existing platform capabilities your AI product leverages\n\n### The SQL Moment Test\n\nAsk: \"Is the model like SQL, or is it the app itself?\"\n\n**Model = SQL (build on top):**\n- Model provides stable capabilities\n- Differentiation comes from scaffolding layer\n- Build memory, tools use, entitlements as first-class systems\n\n**Model = App (vertically integrated):**\n- Model + scaffolding + tool calling in infinite loop IS the product\n- Less room for application-layer differentiation\n- Risk of commoditization as model capabilities improve\n\n## AI Product Strategy\n\n### Scaffolding Layer Requirements\n\nBuild these as first-class systems, not afterthoughts:\n\n1. **Memory system** - Persistent context across interactions\n2. **Tools use** - Integration with external systems and APIs\n3. **Entitlements system** - What actions the agent has permission to take\n\n### Feedback Loop Architecture\n\nCreate closed loops from product usage back to model improvement:\n\n```\nUser Interaction → Product Analytics → Post-training Data → Model Improvement → Better Product\n```\n\n### Identify Drudgery Reduction Opportunities\n\nApply the \"Martian Observer Test\":\n\n1. Imagine an outside observer watching current work practices\n2. Identify repetitive, low-value tasks that prevent flow states\n3. Target AI at returning people to meaningful synthesis work\n\n**Under-hyped opportunities:**\n- Knowledge work drudgery reduction\n- Returning professionals to expert judgment tasks\n- Enabling flow states by eliminating administrative burden\n\n## Enterprise AI Deployment\n\n### Change Management Framework\n\nChange management is the biggest deployment barrier, not technology.\n\n**Dual transformation required:**\n1. **Work artifacts** - What people produce changes\n2. **Workflows** - How they produce it changes\n\nBoth must be addressed for successful adoption.\n\n### Forward Deployment Engineering\n\nInvest in technical personnel who:\n- Work directly with customers on implementation\n- Adapt products to specific industry workflows\n- Understand domain context deeply\n\n### Industry Research Protocol\n\nBefore building AI products for knowledge workers:\n\n1. Go undercover in target industries\n2. Observe actual workflows (not stated workflows)\n3. Identify where expertise is wasted on administrative tasks\n4. Map the full work artifact + workflow transformation needed\n\n## Economic Surplus Framework\n\n### Social Permission Principle\n\nAI must earn societal consent to consume energy resources by demonstrating:\n- Measurable economic surplus at community level\n- Measurable economic surplus at country level\n- Improvement in lives globally\n\n### Surplus Measurement Approach\n\nEvaluate AI investments by asking:\n- What surplus does this create for the user/customer?\n- Can communities and countries measure the benefit?\n- Does this justify the energy consumption required?\n\n**Valid surplus indicators:**\n- Productivity gains in knowledge work\n- Access to expertise previously unavailable\n- Reduction in time spent on low-value tasks\n- Educational outcome improvements\n\n## Talent and Team Evaluation\n\n### Clarity-Energy-Problem Solving Framework\n\nEvaluate people on three qualities:\n\n1. **Clarity in uncertainty** - Brings structure when others are confused\n2. **Energy creation** - Generates motivation across constituents\n3. **Over-constrained problem solving** - Finds paths when resources are limited\n\nThese qualities matter at every career stage, not just leadership.\n\n### Software Engineering Evolution\n\nSoftware engineering transforms but doesn't disappear:\n- Engineers become architects\n- Humans maintain meta-cognition over repositories\n- Review agent change logs\n- Bear legal liability for outputs\n\n**New role: Full Stack Builders**\n- Combines design, front-end engineering, and product functions\n- Enabled by AI tooling that handles implementation details\n\n## Decision Frameworks\n\n### Three Dimensions of Microsoft (Adapted for Any Company)\n\nEvaluate strategic decisions through three lenses:\n1. **Platform company** - What platforms are you building/enabling?\n2. **Product company** - What end-user products result?\n3. **Partner company** - How does this enable ecosystem partners?\n\n### Privacy-Security-Sovereignty Stack\n\nFor AI systems handling sensitive data, address nested concerns:\n\n```\nNational Sovereignty\n└── Organizational Security\n    └── Individual Privacy\n```\n\nEach outer layer constrains the inner layers.\n\n## Actionable Protocols\n\n### AI Product Opportunity Evaluation\n\n1. Identify the drudgery in target knowledge work\n2. Map current work artifacts and workflows\n3. Define how both will transform with AI\n4. Estimate change management requirements\n5. Calculate potential economic surplus\n6. Assess forward deployment engineering needs\n\n### Platform Layer Decision\n\nWhen choosing where to build:\n\n1. **Infrastructure** - Golden age for systems software; high barrier, high defensibility\n2. **Model** - Treat as SQL; don't differentiate here unless you're a model company\n3. **Scaffolding** - Memory, tools, entitlements; high differentiation opportunity\n4. **Application** - Domain-specific products; requires deep industry understanding\n\n### Career Development Principle\n\n> \"Don't wait for the next role to do your best work; treat your current opportunity as the greatest job you could have and expand it.\"\n\nApply by:\n- Bringing clarity to current role ambiguity\n- Creating energy among current collaborators\n- Solving the over-constrained problems in front of you now",
        "skills/first-principles-thinking-musk/SKILL.md": "---\nname: first-principles-thinking-musk\ndescription: Strategic thinking frameworks and mental models from Elon Musk for evaluating ambitious projects, applying first principles reasoning, and navigating transformative technology decisions. Use when someone asks about evaluating startup ideas, tackling seemingly impossible problems, applying first principles thinking, making career decisions about transformative technology, understanding AI timeline predictions, assessing risk/reward for ambitious ventures, managing ego and feedback loops, or decomposing complex problems into solvable components.\n---\n\n# Elon Musk: Strategic Thinking Frameworks\n\nApply Elon Musk's mental models and decision-making frameworks to ambitious problems, startup evaluation, and navigating transformative technology.\n\n## Core Mental Models\n\n### First Principles Material Analysis\n\nBreak down any problem to its fundamental physical or logical elements rather than reasoning by analogy.\n\n**Process:**\n1. Identify the problem everyone says is \"impossible\" or \"too expensive\"\n2. List the constituent physical/material elements required\n3. Calculate the theoretical cost floor by summing commodity prices of raw materials\n4. Compare theoretical floor to current market price\n5. If large gap exists, the problem is solvable through engineering\n\n**Example - Battery Costs:**\n```\nProblem: \"Batteries are too expensive for electric vehicles\"\n\nConstituent materials:\n- Cobalt: $X/kg\n- Nickel: $Y/kg  \n- Aluminum: $Z/kg\n- Carbon: $W/kg\n- Polymers: $V/kg\n\nTheoretical floor: Sum of material costs = $A/kWh\nCurrent market price: $B/kWh\nGap ratio: B/A = optimization opportunity\n```\n\n### Utility Area Under Curve\n\nEvaluate any project by calculating the integral of usefulness multiplied by number of people affected.\n\n**Formula:**\n```\nTotal Utility = Usefulness × Number of People Helped × Duration\n```\n\n**Application:**\n1. Estimate how useful the solution is (1-10 scale)\n2. Estimate how many people it helps\n3. Estimate duration of impact\n4. Multiply for rough utility score\n5. Compare across potential projects\n\n**Example evaluation:**\n```\nProject A: Social app feature\n- Usefulness: 3/10\n- People: 10 million\n- Duration: 2 years\n- Score: 60 million utility-years\n\nProject B: Medical diagnostic tool\n- Usefulness: 9/10\n- People: 500,000\n- Duration: 10 years\n- Score: 45 million utility-years\n\nDecision: Consider Project A despite lower usefulness per person\n```\n\n### Thinking in the Limit\n\nExtrapolate variables to minimum or maximum values to understand system behavior and constraints.\n\n**Process:**\n1. Identify the key variable in your problem\n2. Ask: \"What happens when this approaches zero?\"\n3. Ask: \"What happens when this approaches infinity?\"\n4. Use limit behavior to understand constraints and opportunities\n\n**Example - Humanoid Robots:**\n```\nVariable: Number of humanoid robots\n\nAt limit → ∞:\n- Robots outnumber humans\n- Physical labor becomes free\n- Economic value shifts to intelligence/creativity\n- Human intelligence < 1% of total intelligence\n\nImplication: Plan for world where physical labor has zero marginal cost\n```\n\n### Ego-to-Validity Ratio\n\nMaintain a ratio of self-importance to actual capability below 1.0 to preserve feedback loops to reality.\n\n**Self-assessment:**\n```\nEgo-to-Validity Ratio = Perceived Capability / Actual Capability\n\nIf ratio > 1.0: Feedback loop broken, reality distortion active\nIf ratio < 1.0: Healthy humility, learning possible\nIf ratio = 1.0: Accurate self-assessment\n```\n\n**Corrective actions when ratio > 1.0:**\n1. Internalize responsibility for failures (not external factors)\n2. Seek critical feedback actively\n3. List recent mistakes and their causes\n4. Compare predictions to outcomes\n\n## Decision Frameworks\n\n### Spectator vs. Participant Choice\n\nWhen transformative technology will happen regardless of your involvement, choose participation over observation.\n\n**Decision tree:**\n```\n1. Will this transformation happen regardless of my involvement?\n   - No → Evaluate whether to make it happen\n   - Yes → Continue to step 2\n\n2. Do I have relevant skills to contribute?\n   - No → Acquire skills or support from sidelines\n   - Yes → Continue to step 3\n\n3. Can I influence the outcome positively?\n   - No → Find adjacent contribution\n   - Yes → Participate actively\n```\n\n**Example - AI Development:**\n```\nTransformation: Digital superintelligence\nInevitability: High (1-2 years by prediction)\nRelevant skills: Engineering, product, safety research\nInfluence potential: Yes, through building truth-seeking AI\n\nDecision: Participate in AI development rather than observe\n```\n\n### Timeline Decomposition\n\nWhen told something will take 18-24 months, decompose into parallel workstreams.\n\n**Process:**\n1. List all steps in the \"18-24 month\" timeline\n2. Identify dependencies (what must happen sequentially)\n3. Identify parallelizable work\n4. Assign parallel workstreams to operate 24/7\n5. Compress critical path only\n\n**Example - Data Center Build:**\n```\nTraditional timeline: 18 months\n\nDecomposition:\n- Permitting: 3 months (sequential, start immediately)\n- Equipment ordering: 2 months (parallel with permitting)\n- Site preparation: 2 months (parallel with above)\n- Building construction: 4 months (after permits)\n- Equipment installation: 2 months (parallel with construction end)\n- Testing: 1 month\n\nCompressed timeline: 8 months with 24/7 execution\n```\n\n### Board Control Preservation\n\nAvoid giving board control to customers or investors who may constrain technology potential.\n\n**Warning signs:**\n- Customer wants board seat tied to contract\n- Investor demands veto on product direction\n- Early partner wants exclusivity on future applications\n\n**Protective measures:**\n1. Maintain founder voting control through share structure\n2. Separate customer contracts from governance\n3. Set clear boundaries on investor involvement in product decisions\n\n## AI Timeline and Safety Framework\n\n### Current Predictions (as of video date)\n\n```\nDigital Superintelligence: 1-2 years\n- Definition: AI smarter than any human at anything\n- Certainty: High (\"if not this year, next year for sure\")\n\nRisk Assessment:\n- Annihilation probability: 10-20%\n- Positive outcome probability: 80-90%\n\nGlobal AI Structure:\n- Total deep AI intelligences: 5-10 globally\n- US-based: ~4\n- Humanoid robots: Will outnumber all other robots by 10x\n```\n\n### Truth-Seeking as Safety Principle\n\nThe single most important factor for AI safety is rigorous truth-seeking.\n\n**Implementation criteria:**\n1. AI must pursue truth even when uncomfortable\n2. AI must not optimize for user approval over accuracy\n3. AI must acknowledge uncertainty explicitly\n4. AI must be correctable when wrong\n\n**Red flags in AI systems:**\n- Refuses to engage with factual questions\n- Prioritizes sentiment over accuracy\n- Cannot be corrected or updated\n- Optimizes for user happiness over truth\n\n## Startup Evaluation Workflow\n\nWhen evaluating a startup idea or career decision:\n\n1. **Calculate utility area under curve**\n   - How useful is this? (1-10)\n   - How many people does it help?\n   - What's the duration of impact?\n\n2. **Apply first principles analysis**\n   - What are the constituent elements?\n   - What's the theoretical cost/difficulty floor?\n   - Is there a large gap from current state?\n\n3. **Check ego-to-validity ratio**\n   - Am I honest about my capabilities?\n   - Am I internalizing failures?\n   - Is my feedback loop intact?\n\n4. **Apply spectator vs. participant test**\n   - Will this happen regardless of me?\n   - Can I influence it positively?\n   - Should I participate or observe?\n\n5. **Decompose timeline**\n   - What's the stated timeline?\n   - What can be parallelized?\n   - What's the true critical path?\n\n## Key Principles\n\n- Prefer \"engineer\" over \"researcher\" unless there's fundamental algorithmic breakthrough\n- If you can't get hired at the company doing what you want, start your own\n- Sleep in the office and shower at the YMCA if that's what it takes\n- When faced with a choice between observing transformation or participating, participate\n- Apply physics tools (first principles, thinking in the limit) to any field\n- Keep companies lean and avoid capture by legacy players on your board\n- Usefulness is the goal, not glory—let great be a byproduct of useful",
        "skills/robotics-ai-learning-finn/SKILL.md": "---\nname: robotics-ai-learning-finn\ndescription: Reference guide for Physical Intelligence's approach to building general-purpose foundation models for robotics. Use when discussing Physical Intelligence (Pi) research methodology, explaining foundation model approaches to robotics (pre-training + post-training paradigm), comparing robotics data sources, understanding why scale alone is insufficient for robot learning, discussing pi-zero model architecture, explaining robot generalization to unseen environments, or answering questions about Chelsea Finn's work on general-purpose robotics.\n---\n\n# Chelsea Finn: Building Robots That Can Do Anything\n\nReference material from Chelsea Finn's YC presentation on Physical Intelligence's approach to developing general-purpose robots.\n\n## Core Thesis\n\nGeneral-purpose foundation models for robotics can outperform purpose-built solutions by leveraging diverse real-world robot data with a pre-training + post-training paradigm.\n\n**Key insight:** Scale is necessary but not sufficient. Data quality, diversity, and embodiment alignment matter more than raw volume.\n\n## The Problem with Traditional Robotics\n\nEach robotics application traditionally requires building an entire company:\n\n- Custom hardware development\n- Bespoke software systems\n- Unique movement primitives\n- Application-specific edge case handling\n\nThis approach has limited robotics deployment in daily life.\n\n## Physical Intelligence's Approach\n\n### Goal\n\nDevelop a general-purpose model enabling any robot to do any task in any environment.\n\n### Why Generalist Models\n\nFollows the foundation model pattern from language:\n- Coding assistants aren't trained only on code\n- Models trained on diverse data generalize better\n- Transfer learning enables new capabilities\n\n## Data Source Analysis\n\n### Industrial Automation Data\n\n**Characteristics:**\n- Massive scale available\n- Highly repetitive tasks\n- Controlled environments\n\n**Limitations:**\n- Lacks behavioral diversity\n- Cannot generalize to disaster zones, sandwich-making, or grocery bagging\n- Task variety is extremely narrow\n\n### YouTube/Human Video Data\n\n**Characteristics:**\n- Massive scale\n- Diverse human behaviors\n- Real-world scenarios\n\n**Limitations:**\n- Observation ≠ skill acquisition (watching Wimbledon doesn't make you a tennis player)\n- Embodiment gap between humans and robots\n- No action labels or motor commands\n\n### Simulation Data\n\n**Characteristics:**\n- Unlimited scale possible\n- Full control over scenarios\n- Complete action labels\n\n**Limitations:**\n- Lacks realism\n- Sim-to-real transfer gap\n- Physics approximations fail in edge cases\n\n### Teleoperation Data (Physical Intelligence's Choice)\n\n**Characteristics:**\n- Real robot embodiment\n- Real physics and environments\n- Diverse task demonstrations\n- Action labels from leader arms\n\n**Example:** Teleoperator using leader arms to control robot lighting a candle with a match.\n\n## Pi-Zero Foundation Model\n\n### Training Paradigm\n\n```\n┌─────────────────────────────────────────────────────┐\n│                   PRE-TRAINING                       │\n│  Large-scale diverse robot data                      │\n│  Multiple tasks, environments, robot morphologies    │\n└─────────────────────┬───────────────────────────────┘\n                      │\n                      ▼\n┌─────────────────────────────────────────────────────┐\n│                  POST-TRAINING                       │\n│  Curated high-quality demonstrations                 │\n│  Specific task refinement                            │\n└─────────────────────────────────────────────────────┘\n```\n\n### Demonstrated Capabilities\n\n1. **Dexterous long-horizon tasks**\n   - Unloading dryer\n   - Folding laundry\n   - Lighting candles with matches\n\n2. **Zero-shot environment generalization**\n   - Succeeding in never-before-seen locations\n   - Adapting to novel object arrangements\n\n3. **Open-ended prompt response**\n   - Natural language task specification\n   - Handling interjections mid-task\n\n## Key Principles\n\n### Scale is Subordinate to Problem-Solving\n\nScale is necessary for open-world generalization but insufficient alone:\n\n| Factor | Importance |\n|--------|------------|\n| Data scale | Required but not sufficient |\n| Data diversity | Critical for generalization |\n| Embodiment alignment | Essential for transfer |\n| Real-world physics | Enables deployment |\n\n### Pre-training + Post-training Pattern\n\nMirrors language model development:\n\n1. **Pre-training phase:** Broad capabilities from diverse data\n2. **Post-training phase:** Refined performance from curated demonstrations\n\n### Lessons Beyond Robotics\n\nThe findings apply to physical world AI generally:\n- Observation alone doesn't create capability\n- Domain-appropriate data beats generic scale\n- Foundation + fine-tuning enables specialization\n\n## Comparing Approaches\n\n| Approach | Scale | Diversity | Realism | Embodiment Match |\n|----------|-------|-----------|---------|------------------|\n| Industrial automation | ✓✓✓ | ✗ | ✓✓✓ | ✓✓✓ |\n| YouTube videos | ✓✓✓ | ✓✓✓ | ✓✓✓ | ✗ |\n| Simulation | ✓✓✓ | ✓✓ | ✗ | ✓✓ |\n| Teleoperation | ✓ | ✓✓ | ✓✓✓ | ✓✓✓ |\n\n## When to Reference This Material\n\nUse this knowledge when:\n- Explaining why robotics has been slow to deploy in daily life\n- Discussing foundation model approaches to physical AI\n- Comparing data collection strategies for robot learning\n- Understanding Physical Intelligence's competitive advantage\n- Explaining pre-training + post-training paradigms in robotics\n- Discussing generalization in embodied AI systems\n\n## Source\n\nChelsea Finn presentation at Y Combinator, discussing Physical Intelligence's first-year results and methodology for developing general-purpose robotics foundation models.",
        "skills/software-democratization-masad/SKILL.md": "---\nname: software-democratization-masad\ndescription: Provides strategic insights on AI-driven software democratization and agent-based development trends from Replit's perspective. Use when discussing the future of software engineering, AI agent infrastructure requirements, democratization of coding, or when analyzing how AI will transform software creation from expert-only to universal access. Triggers include questions about software engineering automation trends, agent sandbox environments, SWE-bench benchmarks, or strategic implications of AI coding assistants for startups and enterprises.\n---\n\n# Future of Software Creation: AI Agents & Democratization\n\nStrategic framework based on Replit CEO Amjad Masad's analysis of how AI agents will transform software creation from an expert-only activity to universal access.\n\n## Core Thesis\n\nSoftware creation is undergoing the same transition as computing did from mainframes to PCs:\n- **Mainframes → PCs**: Expert-only → Universal access\n- **Traditional coding → AI agents**: Expert-only → Universal access\n\nThe bottleneck to universal software creation is code itself. AI agents remove this bottleneck.\n\n## Historical Pattern Recognition\n\nApply this pattern when analyzing technology democratization:\n\n```\nPhase 1: Expert-only (requires years of training)\nPhase 2: Early consumer adoption (dismissed as \"toys\")\nPhase 3: Killer application emerges (Excel for PCs)\nPhase 4: Universal adoption, runs world economy\n```\n\nExample analysis:\n- Mainframes → PCs: \"Mac paint was a toy\" → Excel → PCs run data centers\n- Software engineering → AI agents: \"Agents barely work\" → [killer app emerging] → Everyone creates software\n\n## AI Agent Capability Trajectory\n\n### SWE-bench Progress Model\n\nTrack agent capability using software engineering benchmarks:\n\n| Year | Capability Level | Practical Implication |\n|------|-----------------|----------------------|\n| 2022 | Barely functional | Research curiosity |\n| 2023 | Started working | Early adopter value |\n| 2024 | 50-70% SWE-bench | Production-viable |\n| Current | 70-80% SWE-bench | Mainstream adoption |\n\n**Key insight**: Benchmark saturation ≠ full automation, but indicates strong trajectory toward useful software engineering agents.\n\n### Strategic Implications for Builders\n\n1. **Accept temporary product limitations** - Build \"crappy products today\" because models improve every 2 months\n2. **Bet on trajectory, not current state** - If benchmarks show consistent improvement, commit resources\n3. **Infrastructure is the moat** - Code generation is commoditizing; agent habitat is the differentiator\n\n## Agent Infrastructure Requirements\n\n### The Agent Habitat Framework\n\nCode generation is the easy part. Differentiation comes from the execution environment:\n\n```\nAgent Habitat Requirements:\n├── Sandboxed VM (cloud-based, not local)\n│   └── Protects user systems from agent errors\n├── Scalability\n│   └── Support millions of concurrent users\n├── Language universality\n│   └── Every programming language\n│   └── Every package ecosystem\n├── Standard Linux environment\n│   └── Shell access\n│   └── File read/write\n│   └── System package installation\n│   └── Language package managers\n└── Openness\n    └── Avoid constrained environments\n    └── Match training environment (standard Linux)\n```\n\n### Environment Checklist\n\nWhen evaluating or building agent infrastructure:\n\n- [ ] Cloud-based sandbox (not user's machine)\n- [ ] Shell access enabled\n- [ ] File system read/write\n- [ ] System package installation (apt, yum)\n- [ ] Language package managers (npm, pip, cargo)\n- [ ] Multi-language support\n- [ ] Horizontal scalability\n- [ ] Matches agent training environment\n\n## Strategic Analysis Framework\n\n### Assessing AI Impact on Software Roles\n\nApply the democratization thesis to evaluate role transformation:\n\n**Before AI agents:**\n- 4-6 years college education required\n- 2-3 years on-job training\n- Specialized career path\n- Bottleneck to business execution\n\n**After AI agents:**\n- Natural language interface\n- Generalist employees solve problems directly\n- Reduced handoff between business and technical\n- Software becomes expression of intent\n\n### Startup Strategy Implications\n\nWhen advising on AI startup strategy:\n\n1. **Timing**: Current moment favors agent-focused products despite limitations\n2. **Patience curve**: 2-month improvement cycles mean viable products emerge from early investments\n3. **Moat analysis**: Infrastructure/habitat > code generation capability\n4. **Market positioning**: Target the transition from expert-only to universal access\n\n## Decision Trees\n\n### Should You Build an Agent Product Now?\n\n```\nIs the underlying capability showing consistent benchmark improvement?\n├── Yes → Build now, accept current limitations\n│   └── Models improve faster than product development cycles\n└── No → Wait or choose different approach\n```\n\n### Agent vs Traditional Development Tool\n\n```\nTarget user is a software expert?\n├── Yes → Traditional tooling may suffice\n└── No → Agent-first approach\n    └── Remove code as the interface\n    └── Focus on intent expression\n```\n\n## Key Predictions to Monitor\n\nTrack these indicators for strategic planning:\n\n1. **SWE-bench scores**: Approaching saturation indicates capability plateau\n2. **Agent sandbox providers**: Infrastructure consolidation signals market maturity\n3. **Non-programmer software creation**: Leading indicator of democratization\n4. **Enterprise agent adoption**: Lagging indicator confirming trend\n\n## Application Examples\n\n### Analyzing a Software Tool's Future\n\n**Input**: \"Will traditional IDEs remain relevant?\"\n\n**Analysis framework**:\n1. Apply mainframe→PC pattern: IDEs are expert tools\n2. Check if agent alternatives emerging: Yes\n3. Identify \"Excel moment\": When non-programmers ship production software\n4. Prediction: IDEs evolve to agent orchestration or decline\n\n### Evaluating Agent Startup Viability\n\n**Input**: \"Should we build an AI coding assistant?\"\n\n**Analysis framework**:\n1. Check current benchmark trajectory: Strong improvement\n2. Assess infrastructure differentiation: What's our habitat advantage?\n3. Timeline alignment: Can we build in 2-month improvement windows?\n4. Market position: Expert enhancement or democratization play?\n\n## Summary Principles\n\n1. **Democratization is inevitable** - Historical pattern repeats\n2. **Code is the bottleneck** - Removing it unlocks universal creation\n3. **Infrastructure differentiates** - Agent habitat > agent capability\n4. **Build ahead of capability** - Models catch up to products\n5. **Generalists win** - Specialized roles compress as barriers fall",
        "skills/software-paradigms-karpathy/SKILL.md": "---\nname: software-paradigms-karpathy\ndescription: Explains Andrej Karpathy's framework for understanding the three paradigms of software (1.0- traditional code, 2.0- neural network weights, 3.0- LLM prompts). Use when users ask about software paradigm shifts, the evolution of programming, how LLMs fit into software development history, Software 1.0/2.0/3.0 distinctions, prompt engineering as programming, or when they need to explain or apply Karpathy's mental model for understanding modern AI development. Also useful when discussing how to think about building software in the AI era, choosing between traditional code vs neural nets vs LLM prompts, or explaining the significance of \"programming in English.\"\n---\n\n# Software Is Changing (Again) - Karpathy Framework\n\nThis skill provides Andrej Karpathy's framework for understanding the fundamental shift in how software is written and deployed in the AI era.\n\n## Core Mental Model: Three Software Paradigms\n\n### Software 1.0: Traditional Code\n- **What it is**: Human-written instructions (Python, C++, JavaScript, etc.)\n- **How it's created**: Developers write explicit logic\n- **Where it lives**: GitHub, traditional repositories\n- **Example**: Writing Python to classify sentiment with explicit rules\n\n### Software 2.0: Neural Network Weights\n- **What it is**: Parameters of trained neural networks\n- **How it's created**: Curate datasets → run optimizer → produce weights\n- **Where it lives**: Hugging Face (the \"GitHub of Software 2.0\"), Model Atlas\n- **Example**: Training a neural network on labeled sentiment data\n- **Key insight**: You don't write this code directly; you tune it through data\n\n### Software 3.0: LLM Prompts\n- **What it is**: Natural language instructions that program LLMs\n- **How it's created**: Write prompts in English (or other natural languages)\n- **Where it lives**: Embedded in applications, prompt libraries\n- **Example**: Few-shot prompting an LLM with sentiment examples\n- **Key insight**: Programming computers in our native language\n\n## Paradigm Selection Guide\n\nDetermine which paradigm to use for a given task:\n\n### Use Software 1.0 (Traditional Code) When:\n- Logic is deterministic and well-defined\n- Performance/latency is critical\n- Behavior must be exactly reproducible\n- Compliance requires auditable logic\n- The problem has clear algorithmic solutions\n\n### Use Software 2.0 (Neural Networks) When:\n- Pattern recognition is required (images, audio, signals)\n- Training data is abundant and high-quality\n- Fixed-function transformation is needed (image → categories)\n- Latency requires optimized, compiled models\n- The task is well-scoped and doesn't require reasoning\n\n### Use Software 3.0 (LLM Prompts) When:\n- Flexibility and generalization matter\n- Tasks require reasoning or common sense\n- Rapid iteration is more important than optimization\n- The problem involves natural language understanding\n- You need to handle edge cases gracefully\n\n## The LLM as Operating System Mental Model\n\nKarpathy frames LLMs as a new kind of operating system, comparable to computing circa 1960s:\n\n```\nTraditional OS                    LLM \"OS\"\n─────────────────────────────────────────────────────\nCPU                          →    LLM inference engine\nRAM                          →    Context window\nDisk storage                 →    Training data / weights\nPrograms                     →    Prompts\nSystem calls                 →    Tool use / function calling\nMulti-tasking                →    Agentic loops\n```\n\n### Implications of This Model:\n- Context window is precious (like early RAM limitations)\n- Prompt engineering is systems programming\n- Tool use extends capabilities (like syscalls extend programs)\n- We're all learning to \"program\" this new OS together\n\n## Practical Framework: Analyzing a Software Task\n\nWhen approaching any software task, evaluate across all three paradigms:\n\n### Step 1: Characterize the Task\n```\nQuestions to ask:\n- Is the input/output well-defined or open-ended?\n- How much does context/reasoning matter?\n- What's the latency requirement?\n- How often will the logic need to change?\n- What data is available for training?\n```\n\n### Step 2: Map to Paradigm Strengths\n\n| Characteristic | Best Paradigm |\n|----------------|---------------|\n| Deterministic logic | 1.0 |\n| Perceptual processing | 2.0 |\n| Flexible reasoning | 3.0 |\n| Sub-millisecond latency | 1.0 or optimized 2.0 |\n| Rapid prototyping | 3.0 |\n| Large-scale pattern matching | 2.0 |\n\n### Step 3: Consider Hybrid Approaches\n\nModern systems often combine paradigms:\n\n```\nExample: Tesla Autopilot Stack (as described by Karpathy)\n\n┌─────────────────────────────────────────┐\n│           Software 1.0 (C++)            │  ← Vehicle control, safety systems\n├─────────────────────────────────────────┤\n│        Software 2.0 (Neural Nets)       │  ← Perception, prediction\n├─────────────────────────────────────────┤\n│     Inputs: Cameras, Sensors, Maps      │\n└─────────────────────────────────────────┘\n```\n\n```\nExample: Modern AI Application\n\n┌─────────────────────────────────────────┐\n│      Software 3.0 (LLM Prompts)         │  ← Reasoning, user interaction\n├─────────────────────────────────────────┤\n│   Software 2.0 (Embeddings, Classifiers)│  ← Retrieval, routing\n├─────────────────────────────────────────┤\n│      Software 1.0 (Python/APIs)         │  ← Orchestration, I/O, tools\n└─────────────────────────────────────────┘\n```\n\n## Explaining the Paradigm Shift\n\nWhen communicating these concepts to others:\n\n### For Technical Audiences:\n- Emphasize that neural network weights ARE code (just compiled differently)\n- Draw parallels to compilation: data → optimizer → weights ≈ source → compiler → binary\n- Highlight that prompt engineering is a legitimate programming discipline\n\n### For Non-Technical Audiences:\n- Focus on \"programming in English\" as the key innovation\n- Use the OS analogy: LLMs are like a new kind of computer we're learning to use\n- Emphasize that software hasn't changed this fundamentally in 70 years\n\n### Key Talking Points:\n1. \"Software 1.0 is code you write. Software 2.0 is code you train. Software 3.0 is code you describe.\"\n2. \"Hugging Face is to neural networks what GitHub is to traditional code.\"\n3. \"We're at the 1960s of LLM computing—everything is being figured out in real-time.\"\n\n## Historical Context\n\n### Why This Matters Now:\n- Neural networks were previously seen as \"just another classifier\" (like decision trees)\n- The key shift: neural networks became **programmable** with LLMs\n- Fixed-function (image → category) evolved to general-purpose (prompt → response)\n\n### The Significance of English as Programming Language:\n- First time computers are programmed in natural human language\n- Dramatically lowers barrier to \"programming\"\n- Changes who can build software and how\n\n## Common Questions and Responses\n\n**Q: Is prompt engineering \"real\" programming?**\nA: Yes. Prompts are programs that control a new type of computer (the LLM). The programming language happens to be English, but it still requires systematic thinking about inputs, outputs, and behavior.\n\n**Q: Will Software 3.0 replace 1.0 and 2.0?**\nA: No. Each paradigm has strengths. The trend is toward hybrid systems that combine all three appropriately.\n\n**Q: Where should I focus my learning?**\nA: Understand all three paradigms. The most valuable skill is knowing when to apply each and how to combine them effectively.\n\n**Q: How do I think about the \"code\" I see now that mixes Python and English prompts?**\nA: This is the new normal. Modern codebases increasingly contain Software 1.0 (orchestration logic), Software 2.0 (model weights/calls), and Software 3.0 (prompts) interleaved together.\n\n## Quick Reference: Paradigm Comparison\n\n```\n┌────────────┬─────────────────┬─────────────────┬─────────────────┐\n│            │  Software 1.0   │  Software 2.0   │  Software 3.0   │\n├────────────┼─────────────────┼─────────────────┼─────────────────┤\n│ Medium     │ Code (Python,   │ Weights         │ Prompts         │\n│            │ C++, etc.)      │ (parameters)    │ (English)       │\n├────────────┼─────────────────┼─────────────────┼─────────────────┤\n│ Created by │ Writing logic   │ Training on     │ Describing      │\n│            │                 │ data            │ behavior        │\n├────────────┼─────────────────┼─────────────────┼─────────────────┤\n│ Repository │ GitHub          │ Hugging Face    │ (emerging)      │\n├────────────┼─────────────────┼─────────────────┼─────────────────┤\n│ Debugging  │ Step through    │ Inspect         │ Iterate on      │\n│            │ code            │ activations     │ prompts         │\n├────────────┼─────────────────┼─────────────────┼─────────────────┤\n│ Iteration  │ Edit code       │ Retrain model   │ Edit prompt     │\n│            │                 │ (LoRA, etc.)    │                 │\n└────────────┴─────────────────┴─────────────────┴─────────────────┘\n```",
        "skills/spatial-intelligence-li/SKILL.md": "---\nname: spatial-intelligence-li\ndescription: Knowledge base on spatial intelligence as the next frontier in AI, based on Fei-Fei Li's insights from her Y Combinator AI Startup School talk. Use this skill when users ask about spatial intelligence concepts, 3D world modeling, the evolution of computer vision from ImageNet to World Labs, AI research strategy and problem selection, or when seeking advice on AI entrepreneurship and founding AI companies. Also trigger when discussing the relationship between vision/spatial understanding and AGI, differentiating generative vs discriminative models in 3D contexts, or exploring the data-algorithm-compute trinity for AI breakthroughs.\n---\n\n# Fei-Fei Li: Spatial Intelligence Knowledge Base\n\n## Core Thesis\n\nAGI will not be complete without spatial intelligence—the ability to understand, generate, reason about, and interact with 3D worlds. This represents the hardest and most important unsolved problem in AI.\n\n## Key Concepts\n\n### Spatial Intelligence\n\nThe multifaceted ability encompassing:\n\n1. **Understanding 3D world structure** - Perceiving depth, objects, relationships\n2. **Generating 3D worlds** - Creating novel 3D environments and content\n3. **Reasoning about 3D space** - Making inferences about spatial relationships\n4. **Navigating and interacting** - Moving through and manipulating physical world\n5. **Communicating spatially** - Describing and understanding spatial language\n\n### Why Spatial Intelligence is Fundamental\n\nUse evolutionary evidence to explain importance:\n\n- Vision took ~540 million years to evolve (Cambrian explosion)\n- Language took ~300-500 million years\n- What evolution spent longest developing is likely most fundamental to intelligence\n- Visual/spatial intelligence predates and underlies linguistic intelligence\n\n### World Models\n\nAI models that capture 3D structure and spatial intelligence, going beyond:\n- Flat pixels (2D image understanding)\n- Language tokens (text-only reasoning)\n- To represent true physical reality\n\n### Generation-Reconstruction Continuum\n\n3D AI applications exist on a spectrum:\n\n```\nPure Generation <-------------------------> Pure Reconstruction\n   |                                                    |\nGaming, Metaverse,                              Robotics,\nCreative content                           Physical manipulation\n   |                                                    |\n   +------ Most applications fall somewhere between ----+\n```\n\nWorld models must serve the entire continuum.\n\n## The Data-Algorithm-Compute Trinity\n\nMajor AI breakthroughs require convergence of three elements:\n\n| Element | ImageNet Revolution Example |\n|---------|----------------------------|\n| Data | ImageNet dataset (14M+ labeled images) |\n| Algorithm | Convolutional Neural Networks (CNNs, published 1980s) |\n| Compute | GPUs enabling parallel processing |\n\n**Key insight**: CNNs existed for decades before working. The algorithm was ready—data and compute were not.\n\n## Technical References\n\n### Foundational Technologies for Spatial AI\n\n| Technology | Description | Use Case |\n|------------|-------------|----------|\n| NeRF (Neural Radiance Fields) | Neural network representing 3D scenes as continuous volumetric functions | Novel view synthesis, 3D reconstruction |\n| Gaussian Splatting | Point-based 3D representation using Gaussian primitives | Real-time rendering, efficient 3D capture |\n| Differentiable Rendering | Rendering that allows gradient backpropagation | Learning 3D from 2D supervision |\n| Pulsar | Point-based neural rendering (Christoph Lassner) | Efficient 3D scene representation |\n\n### Discriminative vs Generative Models\n\n| Approach | Function | 3D Application |\n|----------|----------|----------------|\n| Discriminative | Classify, recognize patterns | Object detection, scene understanding |\n| Generative | Create new content | 3D world generation, content creation |\n\nThe tension between these represents different approaches to spatial AI.\n\n## AI Research Strategy\n\n### Problem Selection Framework\n\nWhen choosing PhD research or startup ideas:\n\n1. **Avoid collision courses** - Don't compete where industry scaling advantages dominate\n2. **Find compute-immune problems** - Focus on areas where throwing more compute alone won't solve it\n3. **Embrace delusional problems** - If a problem seems impossibly hard, that's often a good sign\n4. **Follow curiosity** - Burning curiosity sustains multi-year research efforts\n\n### The Delusional Problem Mindset\n\n```\n\"My entire career is going after problems that are just so hard, \nbordering delusional... if they were easy, someone would have solved them.\"\n```\n\nApply this framework:\n1. Identify problems others dismiss as impossible\n2. Ask: \"What would need to be true for this to work?\"\n3. Find the leverage points (data, algorithm, or compute gaps)\n4. Commit fully despite uncertainty\n\n## AI Entrepreneurship Advice\n\n### Ground Zero Mindset\n\nWhen starting a company:\n- Forget past achievements\n- Forget what others think of you\n- Hunker down and build\n- Focus entirely on building from scratch\n\n### Open Source Strategy\n\nDecide based on business model alignment:\n\n| Scenario | Recommendation |\n|----------|---------------|\n| Research acceleration needed | Open source to enable global collaboration |\n| Network effects valuable | Open source to build ecosystem |\n| Proprietary advantage critical | Selective openness |\n| Community contribution beneficial | Open source with contribution model |\n\n**ImageNet example**: Open sourcing enabled AlexNet's emergence and accelerated the entire field.\n\n### Hiring for AI Teams\n\n**Primary trait to seek**: Intellectual fearlessness\n\nCharacteristics:\n- Courage to embrace impossibly hard problems\n- Willingness to go all-in on uncertain bets\n- Comfort with ambiguity and potential failure\n- Driven by curiosity over career optimization\n\n### Graduate School Decision Framework\n\nPursue a PhD only if:\n- Driven by burning curiosity about a specific problem\n- Cannot imagine doing anything else\n- The research question obsesses you\n- Willing to accept opportunity cost\n\nDo not pursue if:\n- Primarily for credentials or career advancement\n- Uncertain about research interests\n- Industry experience would serve goals better\n\n## Handling Imposter Syndrome\n\nWhen feeling like a minority or outsider:\n\n```\n\"Don't over-index on feeling like a minority... \nthat moment will pass if you focus on the work.\"\n```\n\nApply:\n1. Acknowledge the feeling without dwelling\n2. Redirect attention to the problem at hand\n3. Let results speak over time\n4. Build community with fellow researchers\n\n## Historical Context\n\n### The ImageNet Story (2007-2012)\n\nTimeline for understanding AI breakthrough patterns:\n\n| Year | Event |\n|------|-------|\n| 2007 | ImageNet conceived at Princeton |\n| 2009 | Initial CVPR poster publication |\n| 2009-2011 | Open sourced, challenge created, ~30% error rate |\n| 2012 | AlexNet achieves breakthrough, error drops dramatically |\n\n**Key decisions that enabled success**:\n1. Open sourcing from the beginning\n2. Creating competitive challenge to attract talent\n3. Patience through years of modest results\n4. Betting on data-driven paradigm shift\n\n### AI Timeline Perspective\n\n| Era | Focus |\n|-----|-------|\n| 1956 | Dartmouth Conference - \"machines that think\" |\n| 1980s | CNNs published (Yann LeCun et al.) |\n| 2009 | ImageNet dataset |\n| 2012 | Deep learning revolution (AlexNet) |\n| 2015 | Image captioning breakthroughs |\n| 2020s | Spatial intelligence frontier |\n\n## Applying These Insights\n\n### When Explaining Spatial Intelligence\n\n1. Start with evolutionary argument (540M years for vision)\n2. Distinguish from language-only AI\n3. Describe the generation-reconstruction continuum\n4. Reference concrete technologies (NeRF, Gaussian Splatting)\n\n### When Advising AI Researchers\n\n1. Assess their curiosity level and problem obsession\n2. Guide toward compute-immune research areas\n3. Encourage intellectual fearlessness\n4. Emphasize the data-algorithm-compute trinity\n\n### When Discussing AI Startups\n\n1. Apply ground zero mindset\n2. Evaluate open source strategy for their context\n3. Emphasize hiring for intellectual fearlessness\n4. Frame problems in terms of the trinity convergence\n\n## Key Organizations and Resources\n\n| Resource | Description |\n|----------|-------------|\n| World Labs (worldlabs.ai) | Fei-Fei Li's spatial intelligence startup |\n| Stanford HAI | Human-Centered AI Institute |\n| ImageNet (imagenet.org) | Original dataset |\n| CVPR, ICCV | Primary computer vision conferences |\n| \"The Worlds I See\" | Fei-Fei Li's book |",
        "skills/yc-startup-fundamentals/SKILL.md": "---\nname: yc-startup-fundamentals\ndescription: Y Combinator startup methodology covering team formation, MVP development, growth strategies, fundraising, PR, operations, and hiring. Trigger when users ask about starting a startup, forming a founding team, building an MVP, achieving product-market fit, raising venture capital, startup fundraising strategy, doing PR for startups, startup hiring decisions, startup operations, or when they need guidance on early-stage company building. Also trigger when users mention YC, Y Combinator, startup acceleration, or reference startup fundamentals like runway, burn rate, or co-founder dynamics.\n---\n\n# YC Startup Fundamentals\n\nComplete Y Combinator startup methodology distilled into actionable frameworks for early-stage company building.\n\n## Core Principle\n\nStarting a successful startup requires the right team composition, extreme frugality, rapid iteration, and relentless focus on growth—not complex strategies or large amounts of capital.\n\n## Team Formation\n\n### Requirements Before Starting\n\nAssemble these elements before developing any idea:\n\n- **2-4 co-founders** (not 1, not 5+)\n- **At least 50% engineers** on founding team\n- **Each founder has ~1 year runway** saved (ramen-level living, not comfortable lifestyle)\n- **All founders have quit their jobs** (full commitment required)\n\nNo idea is required at this stage. Team composition matters more than the initial concept.\n\n### Why This Matters\n\nMost companies fail at team composition first, MVP execution second. Get the team right before anything else.\n\n## Idea Generation\n\n### Process\n\n1. Start brainstorming with teammates (not solo)\n2. Let one member's kernel of an idea emerge\n3. Discuss before solidifying so everyone buys in\n4. Ensure shared ownership of the concept\n\n### Idea Selection Criteria\n\n**Frequency Filter** - Prioritize problems by how often they occur:\n\n| Frequency | Priority | Example |\n|-----------|----------|---------|\n| Daily | High | Transportation (Uber - 3x/day) |\n| Weekly | High | Grocery shopping |\n| Monthly | Low | Paying rent |\n| Yearly | Avoid | Buying a car (once every 7 years) |\n\n**Personal Connection** - Either:\n- Solve your own problem, OR\n- Solve a problem you deeply understand through direct exposure\n\n### Market Research\n\nSpend exactly one hour:\n1. Confirm billions of dollars being made in the market\n2. Use your competitors' products directly\n3. Stop researching after this—more analysis creates paralysis\n\n## Legal Setup\n\nFor US investment eligibility:\n- Incorporate as Delaware C Corp\n- Use Clerky.com (~$250)\n- This is the only structure US VCs will fund\n\n## MVP Development\n\n### Timeline\n\n**Maximum 2 months from start to launch.** No exceptions.\n\nWhen asked \"why does it take longer than 2 months?\" there should be no valid answer.\n\n### Mindset\n\n- You learn nothing until real users see your product\n- Iteration before launch is wasted effort\n- \"Launch\" is the single most common advice given to YC companies\n- Perfect is the enemy of shipped\n\n### What MVP Means\n\nThe fastest possible version you can get into users' hands—ideally 2 weeks to 2 months. Strip features until only the core value proposition remains.\n\n## Growth Strategy\n\nGrowth is the #1 metric investors use to decide whether to fund you. Not team, not experience, not existing investors.\n\n### Three Growth Paths\n\n**1. Paid Ads (Least Preferred)**\n- Expensive and unsustainable early\n- Use only for validation, not primary growth\n\n**2. Reference Customers (B2B)**\n- Provide exceptional service to select customers\n- They spread word-of-mouth within their industry\n- Quality of service creates organic referrals\n\n**3. Usage Equals Sharing (Consumer)**\n- Design product so using it inherently creates sharing\n- Not a share button—the core action must create exposure\n- Build sharing into day-one product design\n- Example: Every Instagram post is shareable content\n\n### Consumer Product Test\n\nAsk: \"Does using my product automatically expose it to non-users?\"\n\nIf sharing requires a separate action, redesign the core experience.\n\n## PR Strategy\n\n### Core Principle\n\nPR is exactly like business development:\n1. Get warm introduction\n2. Deliver structured pitch\n3. Build relationship\n4. Follow up consistently\n5. Provide something of value\n\n### Do It Yourself\n\n99% of early-stage PR can be done without a firm. PR firms are one of the biggest money-wasters for startups.\n\n### Execution Steps\n\n1. **Build reporter list** - Identify journalists covering your space\n2. **Get warm intros** - Use network connections, not cold outreach\n3. **Pitch real news** - Have something genuinely newsworthy\n4. **Build relationships** - Treat reporters as long-term contacts\n5. **Follow up** - Persistence matters, but respect boundaries\n\n## Fundraising\n\n### Prerequisite Paradox\n\nStructure your company so you don't need money. Investors give money to founders who don't need it. Desperation repels capital.\n\n### Creating FOMO\n\n**Compressed Timeline Strategy:**\n1. Line up all investor meetings\n2. Schedule within same 1-2 week window\n3. Create perception of competitive demand\n4. Let fear of missing out drive decisions\n\n### What Investors Actually Evaluate\n\n| Factor | Importance |\n|--------|------------|\n| Growth metrics | Primary |\n| Team composition | Secondary |\n| Past experience | Tertiary |\n| Fancy existing investors | Minimal |\n\nShow growth charts. Everything else is supporting material.\n\n## Operations\n\n### #1 Problem: Spending Too Much Money\n\nExcessive spending kills more startups than any other operational issue.\n\n### Monthly Expense Review\n\n1. Download every expense from bank account\n2. Review line by line\n3. Challenge each expense: \"Is this essential?\"\n4. Eliminate ruthlessly\n\n### Frugality Examples\n\nSmall teams achieve massive scale:\n- **Socialcam**: 3 founders, 20M downloads, no employees\n- **Instagram**: Under 20 employees at $1B acquisition\n\nThe goal is proving the model works, not building an empire prematurely.\n\n## Hiring\n\n### The Average Intelligence Test\n\nOnly hire someone if they increase the average intelligence/capability of the entire company.\n\nIf a hire doesn't raise the bar, don't make the hire.\n\n### Transparency in Offers\n\nTell candidates exactly:\n- How much stock they're getting\n- Total shares outstanding\n- Whether salary is below market (and why)\n\nHonesty builds trust and filters for mission-aligned candidates.\n\n### Hiring Velocity\n\nHire slowly. Each person added changes company dynamics. Premature scaling is a leading cause of startup death.\n\n## Quick Reference Checklists\n\n### Pre-Launch Checklist\n\n- [ ] 2-4 co-founders assembled\n- [ ] 50%+ of team are engineers\n- [ ] Each founder has 1 year ramen-budget runway\n- [ ] All founders have quit other jobs\n- [ ] Delaware C Corp incorporated\n- [ ] MVP scope defined (2-month max build)\n- [ ] Launch date set\n\n### Growth Readiness Checklist\n\n- [ ] Core product in users' hands\n- [ ] Usage metrics being tracked\n- [ ] Growth strategy selected (ads/reference customers/usage=sharing)\n- [ ] For consumer: sharing built into core product action\n- [ ] For B2B: reference customer pipeline identified\n\n### Fundraising Readiness Checklist\n\n- [ ] Growth metrics documented and trending up\n- [ ] Can demonstrate not needing money to survive\n- [ ] Investor target list compiled\n- [ ] Warm intro paths identified\n- [ ] 1-2 week meeting window scheduled\n\n### Monthly Operations Checklist\n\n- [ ] All expenses downloaded and reviewed\n- [ ] Non-essential spending eliminated\n- [ ] Runway recalculated\n- [ ] Team size justified against growth\n\n## Common Mistakes to Avoid\n\n1. **Solo founding** - Find 1-3 co-founders\n2. **All-business teams** - Need 50%+ engineers\n3. **Comfortable runway assumptions** - Plan for ramen, not comfort\n4. **Researching instead of building** - One hour market research max\n5. **Iterating before launching** - Ship in 2 months or less\n6. **Adding share buttons instead of designing sharing in** - Usage must equal sharing\n7. **Hiring PR firms** - Do it yourself\n8. **Spreading investor meetings over months** - Compress to 1-2 weeks\n9. **Spending money you've raised** - Stay frugal regardless of bank balance\n10. **Hiring to feel like a \"real company\"** - Small teams win\n"
      },
      "plugins": [
        {
          "name": "ycombinator-skills",
          "description": "Apply proven startup strategies and frameworks from YC speakers",
          "source": "./",
          "strict": false,
          "skills": [
            "./skills/agi-framework-chollet",
            "./skills/ai-accelerated-building-ng",
            "./skills/ai-product-building-heller",
            "./skills/ai-scaling-laws-amodei",
            "./skills/ai-scientific-discovery-jumper",
            "./skills/ai-search-strategy-srinivas",
            "./skills/ai-startup-insights-altman",
            "./skills/ai-startup-questions-fisher",
            "./skills/b2b-ai-startup-levie",
            "./skills/design-tool-scaling-field",
            "./skills/developer-tools-strategy-truell",
            "./skills/enterprise-ai-strategy-nadella",
            "./skills/first-principles-thinking-musk",
            "./skills/robotics-ai-learning-finn",
            "./skills/software-democratization-masad",
            "./skills/software-paradigms-karpathy",
            "./skills/spatial-intelligence-li"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add jona/ycombinator-skills",
            "/plugin install ycombinator-skills@ycombinator-skills"
          ]
        }
      ]
    }
  ]
}