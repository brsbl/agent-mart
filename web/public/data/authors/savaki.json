{
  "author": {
    "id": "savaki",
    "display_name": "Matt Ho",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/108710?v=4",
    "url": "https://github.com/savaki",
    "bio": null,
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 0,
      "total_skills": 2,
      "total_stars": 0,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "savaki-marketplace",
      "version": null,
      "description": "Serverless CloudFormation deployment automation with support for single and multi-account deployments via AWS Step Functions",
      "owner_info": {
        "name": "Matt Ho",
        "url": "https://github.com/savaki"
      },
      "keywords": [],
      "repo_full_name": "savaki/savaki-marketplace",
      "repo_url": "https://github.com/savaki/savaki-marketplace",
      "repo_description": null,
      "homepage": null,
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2025-10-26T07:39:39Z",
        "created_at": "2025-10-19T00:30:52Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 445
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/aws-deployer",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/aws-deployer/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/aws-deployer/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 695
        },
        {
          "path": "plugins/aws-deployer/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/aws-deployer/skills/deploy-to-github",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/aws-deployer/skills/deploy-to-github/SKILL.md",
          "type": "blob",
          "size": 17465
        },
        {
          "path": "plugins/aws-deployer/skills/setup-deployer",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/aws-deployer/skills/setup-deployer/SKILL.md",
          "type": "blob",
          "size": 13640
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"savaki-marketplace\",\n  \"owner\": {\n    \"name\": \"Matt Ho\",\n    \"url\": \"https://github.com/savaki\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"aws-deployer\",\n      \"source\": \"./plugins/aws-deployer\",\n      \"description\": \"Serverless CloudFormation deployment automation with support for single and multi-account deployments via AWS Step Functions\",\n      \"version\": \"1.0.0\",\n      \"author\": {\n        \"name\": \"Matt Ho\"\n      }\n    }\n  ]\n}",
        "plugins/aws-deployer/.claude-plugin/plugin.json": "{\n  \"name\": \"aws-deployer\",\n  \"description\": \"Skills for setting up and configuring AWS Deployer - a serverless CloudFormation deployment automation system with support for single and multi-account deployments via AWS Step Functions\",\n  \"version\": \"1.0.0\",\n  \"author\": {\n    \"name\": \"Matt Ho\",\n    \"email\": \"matt.ho@gmail.com\",\n    \"url\": \"https://github.com/savaki\"\n  },\n  \"homepage\": \"https://github.com/savaki/aws-deployer\",\n  \"repository\": \"https://github.com/savaki/aws-deployer\",\n  \"license\": \"MIT\",\n  \"keywords\": [\n    \"aws\",\n    \"cloudformation\",\n    \"deployment\",\n    \"automation\",\n    \"serverless\",\n    \"step-functions\",\n    \"multi-account\",\n    \"ci-cd\"\n  ],\n  \"skills\": \"./skills/\"\n}\n",
        "plugins/aws-deployer/skills/deploy-to-github/SKILL.md": "---\nname: deploy-to-github\ndescription: Set up GitHub Actions to deploy this repository via AWS Deployer - creates workflow, updates CloudFormation template with required parameters, and generates parameter files.\n---\n\n# Set Up GitHub Actions Deployment for AWS Deployer\n\nThis skill automatically configures a GitHub repository to deploy via **AWS Deployer** ([github.com/savaki/aws-deployer](https://github.com/savaki/aws-deployer)).\n\n## Prerequisites\n\n- AWS Deployer infrastructure is already set up (use `setup-deployer` skill if not)\n- Working directory is a Git repository with a GitHub remote\n- Repository has a `cloudformation.template` file (will be created if missing)\n- Optional: `S3_ARTIFACT_BUCKET` environment variable set to your artifacts bucket\n- Optional: `AWS_REGION` environment variable set to your AWS region\n\n## Your Task\n\nWhen this skill is invoked, you will **configure** the repository for GitHub Actions deployment by:\n\n1. **Detecting repository information** - Extract repo name from `.git/config`\n2. **Getting configuration** - Check environment variables (`S3_ARTIFACT_BUCKET`, `AWS_REGION`) first, ask only if not set\n3. **Detecting build system** - Identify build command from project files\n4. **Creating/updating GitHub workflow** - Generate `.github/workflows/deploy.yml`\n5. **Updating CloudFormation template** - Ensure required parameters exist\n6. **Creating parameter files** - Generate base and environment-specific templates\n7. **Explaining OIDC setup** - Provide instructions for running `aws-deployer setup-github` and configuring GitHub secrets\n\n**Important**:\n- Check environment variables first: `S3_ARTIFACT_BUCKET` and `AWS_REGION`\n- Only ask for values if environment variables are not set\n- Default AWS region to `us-west-2` if not set\n- Do NOT run the `aws-deployer setup-github` command. Explain to the user how to run it.\n- Explain that THREE GitHub secrets are required: `AWS_ROLE_ARN`, `S3_ARTIFACT_BUCKET`, and `AWS_REGION`.\n\n## Step 1: Detect Repository Information\n\nExtract the repository owner and name from Git configuration:\n\n```bash\n# Get the remote URL\ngit config --get remote.origin.url\n```\n\nParse the result to extract `owner/repo`:\n- `https://github.com/foo/bar.git` → `foo/bar`\n- `git@github.com:foo/bar.git` → `foo/bar`\n\nStore as `REPO_FULL_NAME` (e.g., `foo/bar`)\n\n## Step 2: Get Configuration\n\n**S3 Bucket**:\n1. Check if `S3_ARTIFACT_BUCKET` environment variable is set\n   ```bash\n   echo $S3_ARTIFACT_BUCKET\n   ```\n2. If set, use that value\n3. If not set, ask the user for the S3 artifacts bucket name\n   - Example: `my-artifacts-bucket`\n   - This will be stored as a GitHub secret `S3_ARTIFACT_BUCKET`\n\n**AWS Region**:\n1. Check if `AWS_REGION` environment variable is set\n   ```bash\n   echo $AWS_REGION\n   ```\n2. If set, use that value\n3. If not set, ask the user to confirm the AWS region, providing options:\n   - Default: `us-west-2`\n   - Other common options: `us-east-1`, `us-east-2`, `eu-west-1`, `ap-southeast-1`\n   - Allow custom input\n\n**Initial Environment**: Default to `dev` (don't ask)\n\n## Step 3: Detect Build Command\n\nCheck for common build files and infer the build command:\n\n- `Makefile` with `build` target → `make build`\n- `package.json` with `build` script → `npm run build`\n- `go.mod` → `go build ./...`\n- `pom.xml` → `mvn package`\n- `build.gradle` → `gradle build`\n\nIf multiple or none found, ask the user for the build command.\n\n## Step 4: Create/Update GitHub Workflow\n\nCreate `.github/workflows/deploy.yml`:\n\n```yaml\nname: Deploy to AWS\n\non:\n  push:\n    branches:\n      - main\n      - develop\n  workflow_dispatch:\n\npermissions:\n  id-token: write\n  contents: read\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Configure AWS credentials\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}\n          aws-region: ${{ secrets.AWS_REGION }}\n\n      - name: Set version variables\n        id: version\n        run: |\n          REPO=\"<repo-owner>/<repo-name>\"\n          BRANCH=\"${{ github.ref_name }}\"\n          SHA_SHORT=\"${{ github.sha }}\"\n          SHA_SHORT=\"${SHA_SHORT:0:6}\"\n          VERSION=\"${{ github.run_number }}.${SHA_SHORT}\"\n          S3_PREFIX=\"${REPO}/${BRANCH}/${VERSION}\"\n\n          echo \"repo=${REPO}\" >> $GITHUB_OUTPUT\n          echo \"branch=${BRANCH}\" >> $GITHUB_OUTPUT\n          echo \"version=${VERSION}\" >> $GITHUB_OUTPUT\n          echo \"s3_prefix=${S3_PREFIX}\" >> $GITHUB_OUTPUT\n\n      - name: Build application\n        run: |\n          <build-command>\n\n      - name: Generate CloudFormation parameters\n        run: |\n          cat > cloudformation-params.json <<EOF\n          {\n            \"Env\": \"dev\",\n            \"Version\": \"${{ steps.version.outputs.version }}\",\n            \"S3Bucket\": \"${{ secrets.S3_ARTIFACT_BUCKET }}\",\n            \"S3Prefix\": \"${{ steps.version.outputs.s3_prefix }}\"\n          }\n          EOF\n\n      - name: Upload to S3\n        run: |\n          S3_PATH=\"s3://${{ secrets.S3_ARTIFACT_BUCKET }}/${{ steps.version.outputs.s3_prefix }}/\"\n\n          # Upload CloudFormation template\n          aws s3 cp cloudformation.template \"${S3_PATH}\"\n\n          # Upload parameters\n          aws s3 cp cloudformation-params.json \"${S3_PATH}\"\n\n          # Upload environment-specific parameters if they exist\n          if [ -f cloudformation-params.dev.json ]; then\n            aws s3 cp cloudformation-params.dev.json \"${S3_PATH}\"\n          fi\n          if [ -f cloudformation-params.prd.json ]; then\n            aws s3 cp cloudformation-params.prd.json \"${S3_PATH}\"\n          fi\n\n          # Upload any build artifacts as needed\n          # Example: aws s3 cp build/function.zip \"${S3_PATH}\"\n\n      - name: Deployment info\n        run: |\n          echo \"✓ Deployed version: ${{ steps.version.outputs.version }}\"\n          echo \"✓ S3 path: s3://${{ secrets.S3_ARTIFACT_BUCKET }}/${{ steps.version.outputs.s3_prefix }}/\"\n          echo \"✓ Environment: dev\"\n```\n\n**Replace placeholders**:\n- `<repo-owner>/<repo-name>`: Full repository name from Git (e.g., `mycompany/my-app`)\n- `<build-command>`: Detected or user-provided build command\n\n**Note**: The workflow uses `${{ secrets.AWS_REGION }}` which will be configured as a GitHub secret.\n\n## Step 5: Update CloudFormation Template\n\nIf `cloudformation.template` exists, read it and check for required parameters.\n\nIf any of these parameters are missing, add them:\n\n```yaml\nParameters:\n  Env:\n    Type: String\n    Default: dev\n    Description: Environment name (dev, staging, prd)\n    AllowedValues:\n      - dev\n      - staging\n      - prd\n\n  Version:\n    Type: String\n    Description: Build version in format {build_number}.{commit_hash}\n\n  S3Bucket:\n    Type: String\n    Description: Artifacts bucket name\n\n  S3Prefix:\n    Type: String\n    Description: S3 path to artifacts in format {repo}/{branch}/{version}\n```\n\nIf `cloudformation.template` doesn't exist, create a simple example:\n\n```yaml\nAWSTemplateFormatVersion: '2010-09-09'\nDescription: Deployment for <repo-name>\n\nParameters:\n  Env:\n    Type: String\n    Default: dev\n    Description: Environment name (dev, stg, prd, etc)\n\n  Version:\n    Type: String\n    Description: Build version in format {build_number}.{commit_hash}\n\n  S3Bucket:\n    Type: String\n    Description: Artifacts bucket name\n\n  S3Prefix:\n    Type: String\n    Description: S3 path to artifacts in format {repo}/{branch}/{version}\n\nResources:\n  # TODO: Add your infrastructure resources here\n  # Example:\n  # MyBucket:\n  #   Type: AWS::S3::Bucket\n  #   Properties:\n  #     BucketName: !Sub '${Env}-<repo-name>-${AWS::AccountId}'\n  #     Tags:\n  #       - Key: Version\n  #         Value: !Ref Version\n  #       - Key: Environment\n  #         Value: !Ref Env\n```\n\n**Common usage patterns**:\n\n### Lambda Function\n```yaml\nMyFunction:\n  Type: AWS::Lambda::Function\n  Properties:\n    FunctionName: !Sub '${Env}-my-function'\n    Code:\n      S3Bucket: !Ref S3Bucket\n      S3Key: !Sub '${S3Prefix}/function.zip'\n    Environment:\n      Variables:\n        VERSION: !Ref Version\n```\n\n### ECS Task Definition\n```yaml\nTaskDefinition:\n  Type: AWS::ECS::TaskDefinition\n  Properties:\n    Family: !Sub '${Env}-my-service'\n    ContainerDefinitions:\n      - Name: app\n        Image: !Sub '${AWS::AccountId}.dkr.ecr.${AWS::Region}.amazonaws.com/my-app:${Version}'\n```\n\n## Step 6: Create Parameter Files\n\n### Base Parameters File\n\nCreate `cloudformation-params.json` as a template:\n\n```json\n{\n  \"Env\": \"dev\",\n  \"Version\": \"1.000000\",\n  \"S3Bucket\": \"<bucket-name>\",\n  \"S3Prefix\": \"<repo-owner>/<repo-name>/main/1.000000\"\n}\n```\n\nReplace:\n- `<bucket-name>`: S3 bucket name provided by user\n- `<repo-owner>/<repo-name>`: Full repo name from Git\n\n**Note**: The GitHub workflow dynamically generates this file during deployment, but this template file:\n1. Shows the structure for reference\n2. Can be used for local testing (users can modify values manually)\n\n### Environment-Specific Parameter Files\n\nEnvironment-specific parameter files allow you to override or add parameters per environment. They merge with the base `cloudformation-params.json`.\n\n**How they work**:\n- AWS Deployer loads `cloudformation-params.json` first\n- Then merges `cloudformation-params.<env>.json` if it exists\n- Environment-specific values override base values\n\n**When to use them**:\n- Different instance sizes per environment (t3.micro in dev, m5.large in prod)\n- Feature flags (debug mode enabled only in dev)\n- Environment-specific endpoints or domains\n- Different scaling parameters\n\nCreate **`cloudformation-params.dev.json`**:\n```json\n{\n}\n```\n\nCreate **`cloudformation-params.prd.json`**:\n```json\n{\n}\n```\n\n**Example with actual parameters**:\n\nIf your CloudFormation template has:\n```yaml\nParameters:\n  InstanceType:\n    Type: String\n    Default: t3.micro\n  EnableDebugMode:\n    Type: String\n    Default: \"false\"\n```\n\nYou might use:\n\n`cloudformation-params.dev.json`:\n```json\n{\n  \"InstanceType\": \"t3.micro\",\n  \"EnableDebugMode\": \"true\"\n}\n```\n\n`cloudformation-params.prd.json`:\n```json\n{\n  \"InstanceType\": \"m5.large\",\n  \"EnableDebugMode\": \"false\"\n}\n```\n\n## Step 7: Explain GitHub OIDC Setup\n\nAfter creating all files, explain to the user how to set up GitHub OIDC authentication and configure the required secrets. Make sure to clearly communicate that they need to:\n1. Run the `aws-deployer setup-github` CLI command (you do NOT run it for them)\n2. Manually add the `AWS_REGION` GitHub secret\n3. Verify all three secrets are configured: `AWS_ROLE_ARN`, `S3_ARTIFACT_BUCKET`, `AWS_REGION`\n\nProvide the following instructions:\n\n---\n\n## Next: Configure GitHub OIDC Authentication\n\nYour repository is now configured for AWS Deployer! Before the GitHub Actions workflow can run, you need to set up GitHub OIDC authentication and configure GitHub secrets.\n\n**Required GitHub Secrets:**\nYour workflow requires THREE GitHub secrets to be configured:\n1. **`AWS_ROLE_ARN`** - IAM role for GitHub OIDC authentication\n2. **`S3_ARTIFACT_BUCKET`** - S3 bucket for storing deployment artifacts\n3. **`AWS_REGION`** - AWS region where the deployer is running\n\n### Step 1: Set Up GitHub OIDC with AWS\n\nYou need to run the `aws-deployer setup-github` CLI command to configure GitHub OIDC authentication.\n\n**Prerequisites:**\n\n1. **GitHub Personal Access Token (PAT)** stored in AWS Secrets Manager:\n\n   ```bash\n   # Create a PAT at https://github.com/settings/tokens with 'repo' scope\n   # Then store it in Secrets Manager:\n   aws secretsmanager create-secret \\\n     --name github/pat-token \\\n     --secret-string '{\"github_pat\":\"ghp_xxxxxxxxxxxxx\"}' \\\n     --region <region>\n   ```\n\n2. **AWS Deployer CLI** built and available:\n\n   ```bash\n   # Build the CLI if not already available\n   cd /path/to/aws-deployer\n   make build-cli\n   ```\n\n**Run the setup command:**\n\n```bash\naws-deployer setup-github \\\n  --role-name github-actions-<short-repo-name> \\\n  --repo <repo-owner>/<repo-name> \\\n  --bucket <bucket-name> \\\n  --github-token-secret github/pat-token \\\n  --region <region>\n```\n\n**For your repository:**\n```bash\naws-deployer setup-github \\\n  --role-name github-actions-<short-repo-name> \\\n  --repo <full-repo-name> \\\n  --bucket <bucket-name> \\\n  --github-token-secret github/pat-token \\\n  --region <region>\n```\n\n**What this command does:**\n1. Creates GitHub OIDC provider in AWS (if it doesn't exist)\n2. Creates IAM role `github-actions-<repo-name>` with S3 upload permissions\n3. Adds `AWS_ROLE_ARN` secret to your GitHub repository\n4. Adds `S3_ARTIFACT_BUCKET` secret to your GitHub repository\n\n### Step 2: Add Required GitHub Secrets\n\nAfter running the `aws-deployer setup-github` command, verify that these GitHub secrets exist. You may need to add `AWS_REGION` manually:\n\n**Required secrets:**\n- **`AWS_ROLE_ARN`** - Created by `aws-deployer setup-github` command\n- **`S3_ARTIFACT_BUCKET`** - Created by `aws-deployer setup-github` command\n- **`AWS_REGION`** - **Must be added manually**\n\n**To add AWS_REGION manually:**\n\n1. Go to `https://github.com/<owner>/<repo>/settings/secrets/actions`\n2. Click \"New repository secret\"\n3. Name: `AWS_REGION`\n4. Value: `<region>` (e.g., `us-west-2`)\n5. Click \"Add secret\"\n\n**Verify all secrets exist:**\n\nGo to `https://github.com/<owner>/<repo>/settings/secrets/actions` and confirm:\n- ✓ `AWS_ROLE_ARN` - IAM role ARN for GitHub OIDC\n- ✓ `S3_ARTIFACT_BUCKET` - S3 bucket name (e.g., `<bucket-name>`)\n- ✓ `AWS_REGION` - AWS region (e.g., `<region>`)\n\n### Step 3: Test the Workflow\n\nOnce all secrets are configured:\n\n1. **Push a commit** or click \"Run workflow\" in the Actions tab\n2. **Monitor the deployment** in GitHub Actions\n3. **Check AWS Step Functions** for execution status\n\n---\n\n## Monitoring Deployments\n\nAfter pushing code, monitor the deployment:\n\n### GitHub Actions\n- Check the Actions tab: `https://github.com/<owner>/<repo>/actions`\n- Review workflow logs for any errors\n\n### AWS Step Functions\n```bash\n# Get state machine ARN\nSTATE_MACHINE_ARN=$(aws ssm get-parameter \\\n  --name \"/<env>/aws-deployer/state-machine-arn\" \\\n  --query 'Parameter.Value' \\\n  --output text)\n\n# List recent executions\naws stepfunctions list-executions \\\n  --state-machine-arn \"${STATE_MACHINE_ARN}\" \\\n  --max-results 10\n```\n\n### Lambda Logs\n```bash\n# S3 trigger logs\naws logs tail /aws/lambda/<env>-aws-deployer-s3-trigger --follow\n\n# Build trigger logs\naws logs tail /aws/lambda/<env>-aws-deployer-trigger-build --follow\n```\n\n### DynamoDB Build Records\n```bash\n# Check build history\naws dynamodb query \\\n  --table-name <env>-aws-deployer--builds \\\n  --key-condition-expression \"pk = :pk\" \\\n  --expression-attribute-values '{\":pk\":{\"S\":\"<repo-name>/dev\"}}'\n```\n\n## Troubleshooting\n\n### \"Error: Could not assume role with OIDC\"\n\n**Cause**: GitHub OIDC not configured or secrets missing\n\n**Fix**:\n1. Run the `aws-deployer setup-github` command shown above\n2. Verify all required secrets exist in GitHub repository settings:\n   - `AWS_ROLE_ARN`\n   - `S3_ARTIFACT_BUCKET`\n   - `AWS_REGION`\n3. Check IAM role trust policy allows your repository\n\n```bash\naws iam get-role --role-name github-actions-<repo-name> \\\n  --query 'Role.AssumeRolePolicyDocument'\n```\n\n### \"S3_ARTIFACT_BUCKET secret not found\"\n\n**Cause**: GitHub secret not configured\n\n**Fix**: Run the `aws-deployer setup-github` command to create the secret, or manually add it:\n1. Go to `https://github.com/<owner>/<repo>/settings/secrets/actions`\n2. Click \"New repository secret\"\n3. Name: `S3_ARTIFACT_BUCKET`\n4. Value: Your S3 bucket name\n\n### S3 Upload Succeeds but Deployment Doesn't Start\n\n**Cause**: S3 trigger Lambda not configured or wrong S3 path\n\n**Fix**:\n```bash\n# Check S3 files were uploaded\naws s3 ls s3://<bucket-name>/<repo-owner>/<repo-name>/ --recursive\n\n# Check S3 trigger Lambda logs\naws logs tail /aws/lambda/<env>-aws-deployer-s3-trigger --since 10m\n```\n\n### CloudFormation Stack Fails\n\n**Check stack events**:\n```bash\n# List stacks for this repo\naws cloudformation describe-stacks \\\n  --query 'Stacks[?contains(StackName, `<repo-name>`)].{Name:StackName, Status:StackStatus}'\n\n# Get detailed errors\naws cloudformation describe-stack-events \\\n  --stack-name <env>-<repo-name> \\\n  --max-items 20\n```\n\n## Files Created\n\nAfter running this skill, you should have:\n\n- [ ] `.github/workflows/deploy.yml` - GitHub Actions workflow\n- [ ] `cloudformation.template` - CloudFormation template with required parameters\n- [ ] `cloudformation-params.json` - Base parameters template\n- [ ] `cloudformation-params.dev.json` - Dev environment parameters (empty initially)\n- [ ] `cloudformation-params.prd.json` - Production environment parameters (empty initially)\n\n## Summary\n\nThis skill configured your repository for AWS Deployer by:\n\n1. ✓ Detecting repository information from Git\n2. ✓ Getting S3 bucket and AWS region (from environment variables or by asking)\n3. ✓ Creating GitHub Actions workflow\n4. ✓ Ensuring CloudFormation template has required parameters\n5. ✓ Creating parameter files for local testing\n\n**Next steps**:\n1. Run `aws-deployer setup-github` command to configure GitHub OIDC\n2. Add `AWS_REGION` GitHub secret manually\n3. Verify all three secrets exist: `AWS_ROLE_ARN`, `S3_ARTIFACT_BUCKET`, `AWS_REGION`\n4. Push a commit to trigger your first deployment\n5. Add your infrastructure resources to `cloudformation.template`\n6. Add environment-specific parameters if needed\n\nFor infrastructure setup, use the `setup-deployer` skill.\n",
        "plugins/aws-deployer/skills/setup-deployer/SKILL.md": "---\nname: setup-deployer\ndescription: Interactive guide for installing and configuring AWS Deployer infrastructure - builds Lambda functions, deploys CloudFormation stacks, and sets up multi-account targets and GitHub OIDC integration.\n---\n\n# AWS Deployer Setup and Configuration\n\nThis skill guides users through the complete setup and configuration of **AWS Deployer** ([github.com/savaki/aws-deployer](https://github.com/savaki/aws-deployer)), a serverless CloudFormation deployment automation system that orchestrates infrastructure deployments using AWS Step Functions, Lambda, and DynamoDB.\n\n## What is AWS Deployer?\n\nAWS Deployer is a serverless system that automates CloudFormation deployments across single or multiple AWS accounts. It:\n- Monitors S3 for CloudFormation templates and automatically deploys them\n- Uses Step Functions to orchestrate complex multi-stage deployments\n- Supports promotion workflows (dev → staging → production)\n- Integrates with GitHub Actions via OIDC for secure CI/CD\n- Provides optional web UI for deployment monitoring\n\n## Your Task\n\nWhen this skill is invoked, you are helping the user set up AWS Deployer from scratch. Your role is to **interactively guide** them through the complete setup process:\n\n1. **Gather requirements** - Ask about their deployment needs (single vs multi-account, custom domain, etc.)\n2. **Verify prerequisites** - Ensure they have AWS CLI, Go, S3 bucket, and necessary permissions\n3. **Build the project** - Guide them to compile all Lambda functions\n4. **Deploy infrastructure** - Help construct and execute the CloudFormation deployment command\n5. **Configure targets** - Set up deployment targets for multi-account mode (if applicable)\n6. **Setup GitHub integration** - Configure OIDC roles and secrets for CI/CD\n7. **Verify setup** - Confirm all infrastructure is deployed correctly\n\n**Important**: This is an **interactive, step-by-step process**. Don't just provide all the instructions at once. Ask questions, wait for responses, verify each step is complete before moving to the next one, and adapt to the user's specific needs.\n\n## Prerequisites Check\n\nBefore starting, verify the user has:\n\n- AWS CLI installed and configured with appropriate credentials\n- Go 1.24+ installed\n- An S3 bucket for artifacts (ask for bucket name or help create one)\n- IAM permissions to create:\n  - Lambda functions\n  - Step Functions state machines\n  - DynamoDB tables\n  - IAM roles and policies\n  - CloudFormation stacks\n- For multi-account: IAM roles in target accounts\n- For custom domain: Route 53 hosted zone in the deployment account managing the domain's nameservers\n\n## Setup Process\n\n### 1. Gather Requirements\n\nAsk the user:\n\n1. **Environment name**: What environment are they setting up? (dev, stg, prd)\n2. **Deployment mode**: Single-account or multi-account deployments?\n3. **S3 bucket**: Do they have an existing artifacts bucket, or should one be created?\n4. **Custom domain**: Do they want to set up a custom domain for the API Gateway? (optional)\n   - **Important**: The AWS account must manage the domain's nameservers via Route 53\n   - The Route 53 hosted zone must already exist\n   - They'll need the Hosted Zone ID\n5. **Authorization**: Should access be restricted to specific email addresses? (optional)\n6. **AWS Region**: Which region to deploy to? (default: us-east-1)\n\n### 2. Build the Project\n\nGuide the user to build all Lambda functions:\n\n```bash\nmake build\n```\n\nVerify the build succeeded by checking for `.zip` files in the `build/` directory.\n\n### 3. Set Up Custom Domain Prerequisites (Optional)\n\nIf the user wants a custom domain, guide them through these prerequisites:\n\n**Verify Route 53 Hosted Zone:**\n```bash\n# List hosted zones to find the Zone ID\naws route53 list-hosted-zones-by-name --dns-name example.com\n\n# Verify nameservers are properly configured\naws route53 get-hosted-zone --id <ZONE_ID>\n```\n\n**Important**: The domain's nameservers at the registrar must point to the AWS Route 53 nameservers shown in the hosted zone.\n\n**Create/Verify ACM Certificate:**\n```bash\n# Request a certificate (if not already exists)\naws acm request-certificate \\\n  --domain-name deployer.example.com \\\n  --validation-method DNS \\\n  --region <region>\n\n# List certificates to find the ARN\naws acm list-certificates --region <region>\n\n# Get certificate details and validation records\naws acm describe-certificate --certificate-arn <CERTIFICATE_ARN> --region <region>\n```\n\n**Important**:\n- The ACM certificate must be in the same region as the deployment\n- DNS validation records must be added to Route 53\n- Wait for certificate status to be `ISSUED` before deploying\n\n**Verify Certificate is Issued:**\n```bash\naws acm describe-certificate \\\n  --certificate-arn <CERTIFICATE_ARN> \\\n  --region <region> \\\n  --query 'Certificate.Status' \\\n  --output text\n```\n\nShould return `ISSUED` before proceeding.\n\n### 4. Deploy Infrastructure\n\nHelp construct the deployment command based on their requirements:\n\n**Basic deployment:**\n```bash\nENV=dev S3_BUCKET=<bucket-name> make deploy\n```\n\n**With custom domain:**\n```bash\nENV=prd \\\n  S3_BUCKET=<bucket-name> \\\n  ZONE_ID=Z1234567890ABC \\\n  DOMAIN_NAME=deployer.example.com \\\n  CERTIFICATE_ARN=arn:aws:acm:us-east-1:123456789012:certificate/abc-123 \\\n  make deploy\n```\n\n**With all optional parameters:**\n```bash\nENV=prd \\\n  S3_BUCKET=<bucket-name> \\\n  DEPLOYMENT_MODE=multi \\\n  ALLOWED_EMAIL=admin@example.com \\\n  ZONE_ID=Z1234567890ABC \\\n  DOMAIN_NAME=deployer.example.com \\\n  CERTIFICATE_ARN=arn:aws:acm:... \\\n  make deploy\n```\n\nMonitor the CloudFormation deployment and help troubleshoot any errors.\n\n### 5. Verify Infrastructure\n\nAfter deployment, verify the CloudFormation stack deployed successfully:\n\n```bash\n# Check CloudFormation stack status\naws cloudformation describe-stacks \\\n  --stack-name <env>-aws-deployer \\\n  --query 'Stacks[0].StackStatus' \\\n  --output text\n```\n\nShould return `CREATE_COMPLETE` or `UPDATE_COMPLETE`.\n\nIf the stack deployed successfully, all resources (Lambda functions, DynamoDB tables, Step Functions, Parameter Store) are configured automatically.\n\n### 6. Set Up Deployment Targets (Multi-Account Mode Only)\n\nIf using multi-account mode, configure deployment targets:\n\n**Build the CLI:**\n```bash\nmake build-cli\n```\n\n**Configure initial environment:**\n```bash\naws-deployer targets config \\\n  --env <env> \\\n  --default \\\n  --initial-env dev\n```\n\n**Set up deployment targets for each environment:**\n\nNote: `--downstream-env` specifies where this environment promotes TO (the next environment in the pipeline).\n\nFor dev (promotes to staging):\n```bash\naws-deployer targets set \\\n  --env <env> \\\n  --target-env dev \\\n  --default \\\n  --accounts \"123456789012\" \\\n  --regions \"us-east-1\" \\\n  --downstream-env \"staging\"\n```\n\nFor staging (promotes to prd):\n```bash\naws-deployer targets set \\\n  --env <env> \\\n  --target-env staging \\\n  --default \\\n  --accounts \"123456789012\" \\\n  --regions \"us-east-1,us-west-2\" \\\n  --downstream-env \"prd\"\n```\n\nFor production (final environment, no promotion):\n```bash\naws-deployer targets set \\\n  --env <env> \\\n  --target-env prd \\\n  --default \\\n  --accounts \"123456789012,987654321098\" \\\n  --regions \"us-east-1,us-west-2,eu-west-1\"\n```\n\n**Verify target configuration:**\n```bash\naws-deployer targets list --env <env>\n```\n\n### 7. Set Up GitHub Repository for CI/CD\n\nFor each repository that will use AWS Deployer:\n\n**Prerequisites:**\n- GitHub Personal Access Token (PAT) with `repo` scope stored in AWS Secrets Manager\n- Your AWS credentials must have `secretsmanager:GetSecretValue` permission for the GitHub PAT secret\n\n**Create the GitHub PAT secret (if not already exists):**\n```bash\n# Create the secret with your GitHub PAT\naws secretsmanager create-secret \\\n  --name github/pat-token \\\n  --secret-string '{\"github_pat\":\"ghp_xxxxxxxxxxxxx\"}'\n```\n\n**Create GitHub OIDC role and secrets:**\n```bash\naws-deployer setup-github \\\n  --role-name github-actions-<repo-name> \\\n  --repo owner/repository-name \\\n  --bucket <artifacts-bucket> \\\n  --github-token-secret github/pat-token\n```\n\nThis creates:\n- IAM OIDC provider for GitHub\n- IAM role with S3 access scoped to the repository path\n- GitHub repository secret with the role ARN (using the PAT from Secrets Manager)\n\n**Provide the user with a sample GitHub Actions workflow:**\n\n```yaml\nname: Deploy to AWS\non: [push]\n\npermissions:\n  id-token: write\n  contents: read\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Configure AWS Credentials\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}\n          aws-region: us-east-1\n\n      - name: Build and package\n        run: |\n          # Build your application and create CloudFormation template\n          # Generate cloudformation-params.json with standard parameters\n\n          REPO=\"<repo>\"\n          BRANCH=\"${{ github.ref_name }}\"\n          SHA_SHORT=\"${{ github.sha }}\"\n          SHA_SHORT=\"${SHA_SHORT:0:6}\"\n          VERSION=\"${{ github.run_number }}.${SHA_SHORT}\"\n          S3_PREFIX=\"${REPO}/${BRANCH}/${VERSION}\"\n\n          cat > cloudformation-params.json <<EOF\n          {\n            \"Env\": \"dev\",\n            \"Version\": \"${VERSION}\",\n            \"S3Bucket\": \"<bucket>\",\n            \"S3Prefix\": \"${S3_PREFIX}\"\n          }\n          EOF\n\n      - name: Upload to S3\n        run: |\n          REPO=\"<repo>\"\n          BRANCH=\"${{ github.ref_name }}\"\n          SHA_SHORT=\"${{ github.sha }}\"\n          SHA_SHORT=\"${SHA_SHORT:0:6}\"\n          VERSION=\"${{ github.run_number }}.${SHA_SHORT}\"\n          S3_PATH=\"s3://<bucket>/${REPO}/${BRANCH}/${VERSION}/\"\n\n          aws s3 cp cloudformation.template \"${S3_PATH}\"\n          aws s3 cp cloudformation-params.json \"${S3_PATH}\"\n```\n\n**Important**: Your CloudFormation templates should always expect these standard parameters:\n- `Env` - Environment name (dev, staging, prd)\n- `Version` - Build version in format `{build_number}.{commit_hash}`\n- `S3Bucket` - Artifacts bucket name\n- `S3Prefix` - S3 path to artifacts in format `{repo}/{branch}/{version}`\n\n### 8. Multi-Account IAM Setup (Multi-Account Mode Only)\n\nFor multi-account deployments, set up IAM roles in target accounts:\n\n```bash\naws-deployer setup-aws \\\n  --account-id <target-account-id> \\\n  --admin-account-id <deployer-account-id> \\\n  --role-name AWSCloudFormationStackSetExecutionRole\n```\n\nThis creates the execution role that CloudFormation StackSets need in each target account.\n\n## Troubleshooting\n\nHelp the user diagnose common issues:\n\n### S3 Trigger Not Working\n- Verify S3 bucket notification is configured correctly\n- Check Lambda permissions to be invoked by S3\n- Review S3 trigger Lambda logs\n\n### Step Function Not Starting\n- Verify `state-machine-arn` in Parameter Store\n- Check DynamoDB stream configuration\n- Review trigger-build Lambda logs\n\n### Multi-Account Deployment Failures\n- Verify target accounts are configured in DynamoDB\n- Check IAM execution roles exist in target accounts\n- Verify StackSet administration role has permissions\n- Review check-stackset-status Lambda logs for detailed errors\n\n### Lock Acquisition Timeouts\n- Check if another deployment is running\n- Verify lock TTL hasn't expired prematurely\n- Review acquire-lock Lambda logs\n\n### Parameter Store Access Issues\n- Verify Lambda IAM roles have `ssm:GetParameter*` permissions\n- Check parameter paths match the environment name\n- Consider using `DISABLE_SSM=true` for local development\n\n## Completion Verification\n\nVerify the setup is complete by checking the CloudFormation stack status:\n\n```bash\n# Check stack status\naws cloudformation describe-stacks \\\n  --stack-name <env>-aws-deployer \\\n  --query 'Stacks[0].StackStatus' \\\n  --output text\n```\n\nShould return `CREATE_COMPLETE` or `UPDATE_COMPLETE`.\n\n**If the CloudFormation stack deployed successfully, all infrastructure resources are automatically created:**\n- Lambda functions with correct IAM permissions\n- DynamoDB tables (builds, targets, deployments, locks)\n- Step Function state machines (single and multi-account)\n- S3 bucket notification configuration\n- Parameter Store values\n- API Gateway and custom domain (if configured)\n\n**Additional verification for multi-account setups:**\n- [ ] Deployment targets configured (if using multi-account mode)\n- [ ] Target account IAM roles created (if using multi-account mode)\n\n**Additional verification for GitHub integration:**\n- [ ] GitHub repository configured with OIDC role\n- [ ] Test deployment completed successfully\n\n## Next Steps\n\nAfter setup is complete, guide the user to:\n\n1. Use the `deploy` skill to test their first deployment\n2. Review CLAUDE.md for development workflow\n3. Read MULTI.md for multi-account deployment details (if applicable)\n4. Explore DEPLOYMENT_TARGETS.md for advanced target configuration\n5. Set up monitoring and alerting for Step Functions\n6. Configure additional repositories for automated deployments\n\n## Reference Commands\n\nKeep these handy for the user:\n\n```bash\n# View build history\naws dynamodb query \\\n  --table-name <env>-aws-deployer--builds \\\n  --key-condition-expression \"pk = :pk\" \\\n  --expression-attribute-values '{\":pk\":{\"S\":\"<repo>/<env>\"}}'\n\n# Update Parameter Store\naws ssm put-parameter \\\n  --name \"/<env>/aws-deployer/<param>\" \\\n  --value \"<value>\" \\\n  --overwrite\n\n# View Step Function executions\naws stepfunctions list-executions \\\n  --state-machine-arn <arn> \\\n  --max-results 10\n\n# Tail Lambda logs\naws logs tail /aws/lambda/<env>-aws-deployer-<function> --follow\n\n# Update Lambda code\nmake update-lambda-code\n\n# Full redeployment\nmake clean-version && make deploy\n```\n"
      },
      "plugins": [
        {
          "name": "aws-deployer",
          "source": "./plugins/aws-deployer",
          "description": "Serverless CloudFormation deployment automation with support for single and multi-account deployments via AWS Step Functions",
          "version": "1.0.0",
          "author": {
            "name": "Matt Ho"
          },
          "categories": [],
          "install_commands": [
            "/plugin marketplace add savaki/savaki-marketplace",
            "/plugin install aws-deployer@savaki-marketplace"
          ]
        }
      ]
    }
  ]
}