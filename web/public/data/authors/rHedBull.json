{
  "author": {
    "id": "rHedBull",
    "display_name": "Hendrik  Wirthwein",
    "avatar_url": "https://avatars.githubusercontent.com/u/65466619?u=5790aeb7a6d887e8bcd3c1be403b70123ffdc7ce&v=4"
  },
  "marketplaces": [
    {
      "name": "ai-trainer-marketplace",
      "version": "1.0.0",
      "description": "Neural network training coach plugins",
      "repo_full_name": "rHedBull/ai-trainer",
      "repo_url": "https://github.com/rHedBull/ai-trainer",
      "repo_description": null,
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-01-15T11:35:17Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"$schema\": \"https://anthropic.com/claude-code/marketplace.schema.json\",\n  \"name\": \"ai-trainer-marketplace\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Neural network training coach plugins\",\n  \"owner\": {\n    \"name\": \"rHedBull\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"neural-trainer\",\n      \"description\": \"Comprehensive neural network training coach for Transformers - training, tuning, debugging, and scaling guidance\",\n      \"version\": \"0.1.0\",\n      \"category\": \"development\",\n      \"source\": {\n        \"type\": \"url\",\n        \"url\": \"https://github.com/rHedBull/ai-trainer.git\"\n      },\n      \"homepage\": \"https://github.com/rHedBull/ai-trainer\"\n    }\n  ]\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"neural-trainer\",\n  \"version\": \"0.1.0\",\n  \"description\": \"Comprehensive neural network training coach for Transformers - training, tuning, debugging, and scaling guidance\",\n  \"author\": {\n    \"name\": \"rHedBull\"\n  }\n}\n",
        "README.md": "# Neural Trainer\n\nA Claude Code plugin that serves as a comprehensive neural network training coach, focused on Transformers.\n\n## Features\n\n- **Training guidance** - Best practices for training neural networks with mandatory monitoring\n- **Debugging assistance** - Systematic diagnosis of training problems (loss plateau, NaN, gradient issues)\n- **Scaling law expertise** - Compute-optimal training decisions based on Chinchilla and Kaplan research\n- **Hyperparameter tuning** - Experiment design and hyperparameter search strategies\n- **Fine-tuning guidance** - LoRA, QLoRA, RLHF, and DPO configuration\n\n## Installation\n\n```bash\n/plugin marketplace add rHedBull/ai-trainer\n/plugin install neural-trainer@ai-trainer-marketplace\n```\n\n## Skills\n\n| Skill | Description |\n|-------|-------------|\n| `/neural-trainer:train` | Execute training with mandatory monitoring and best-practice defaults |\n| `/neural-trainer:train-debug` | Interactive diagnostic workflow for training problems |\n| `/neural-trainer:experiment-plan` | Design rigorous experiments before running them |\n| `/neural-trainer:scaling-analysis` | Run scaling experiments to understand model/data/compute relationships |\n| `/neural-trainer:hyperparam-sweep` | Systematically search hyperparameter space |\n| `/neural-trainer:interpret-curves` | Analyze training logs and explain what's happening |\n| `/neural-trainer:monitor` | View training progress in real-time |\n| `/neural-trainer:run-validation` | Evaluate model checkpoints |\n\n## Agents\n\nThese agents activate automatically based on conversation context:\n\n| Agent | Triggers On |\n|-------|-------------|\n| **diagnostician** | Loss plateau, NaN, gradient explosion/vanishing, training instability |\n| **scaling-advisor** | Scaling laws, compute-optimal training, model size decisions, Chinchilla |\n| **optimization-guru** | Learning rate, optimizers, schedules, warmup, weight decay |\n| **fine-tuning-advisor** | LoRA, QLoRA, RLHF, DPO, catastrophic forgetting |\n\n## Knowledge Base\n\nThe plugin includes comprehensive documentation on:\n\n- **Scaling Laws** - Kaplan and Chinchilla research, compute-optimal ratios\n- **Optimizer Guide** - AdamW, SGD, Lion, learning rate schedules\n- **Transformer Training** - Architecture considerations, initialization, stability tips\n- **Common Failures** - Loss plateau, gradient issues, NaN debugging, overfitting\n- **Fine-Tuning Techniques** - Full fine-tuning, LoRA, QLoRA, RLHF, DPO\n\n## Requirements\n\n- Claude Code CLI\n- Local GPU for training execution (the plugin runs training via shell commands)\n\n## Target Users\n\nIntermediate to experienced ML practitioners who know the fundamentals but need expert-level guidance on:\n- Edge cases and debugging\n- Optimization strategies\n- Scaling decisions\n- Fine-tuning configuration\n\n## License\n\nMIT\n"
      },
      "plugins": [
        {
          "name": "neural-trainer",
          "description": "Comprehensive neural network training coach for Transformers - training, tuning, debugging, and scaling guidance",
          "version": "0.1.0",
          "category": "development",
          "source": {
            "type": "url",
            "url": "https://github.com/rHedBull/ai-trainer.git"
          },
          "homepage": "https://github.com/rHedBull/ai-trainer",
          "categories": [
            "development"
          ],
          "install_commands": [
            "/plugin marketplace add rHedBull/ai-trainer",
            "/plugin install neural-trainer@ai-trainer-marketplace"
          ]
        }
      ]
    }
  ]
}