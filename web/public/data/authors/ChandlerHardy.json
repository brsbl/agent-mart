{
  "author": {
    "id": "ChandlerHardy",
    "display_name": "Chandler Hardy",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/22085966?u=0a9fefc73379c62b418a08db3d52241197672f97&v=4",
    "url": "https://github.com/ChandlerHardy",
    "bio": "Hello, I'm Chandler, a dedicated full-stack developer with a focus on front-end technologies like TypeScript, and React.js",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 0,
      "total_skills": 6,
      "total_stars": 0,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "chronicle-skills",
      "version": null,
      "description": "Skills for working with Chronicle - a local-first development session recorder",
      "owner_info": {
        "name": "Chandler Hardy",
        "email": "hardych04@gmail.com"
      },
      "keywords": [],
      "repo_full_name": "ChandlerHardy/chronicle",
      "repo_url": "https://github.com/ChandlerHardy/chronicle",
      "repo_description": "A development session recorder for tracking multi-AI workflows, git commits, and generating intelligent summaries",
      "homepage": null,
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2025-11-06T23:02:24Z",
        "created_at": "2025-10-19T16:58:41Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 878
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 45740
        },
        {
          "path": "chronicle-skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "chronicle-skills/README.md",
          "type": "blob",
          "size": 8392
        },
        {
          "path": "chronicle-skills/chronicle-assistant-guide",
          "type": "tree",
          "size": null
        },
        {
          "path": "chronicle-skills/chronicle-assistant-guide/SKILL.md",
          "type": "blob",
          "size": 11893
        },
        {
          "path": "chronicle-skills/chronicle-context-retriever",
          "type": "tree",
          "size": null
        },
        {
          "path": "chronicle-skills/chronicle-context-retriever/SKILL.md",
          "type": "blob",
          "size": 8667
        },
        {
          "path": "chronicle-skills/chronicle-project-tracker",
          "type": "tree",
          "size": null
        },
        {
          "path": "chronicle-skills/chronicle-project-tracker/SKILL.md",
          "type": "blob",
          "size": 13137
        },
        {
          "path": "chronicle-skills/chronicle-remote-summarizer",
          "type": "tree",
          "size": null
        },
        {
          "path": "chronicle-skills/chronicle-remote-summarizer/SKILL.md",
          "type": "blob",
          "size": 12292
        },
        {
          "path": "chronicle-skills/chronicle-session-documenter",
          "type": "tree",
          "size": null
        },
        {
          "path": "chronicle-skills/chronicle-session-documenter/SKILL.md",
          "type": "blob",
          "size": 9846
        },
        {
          "path": "chronicle-skills/chronicle-workflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "chronicle-skills/chronicle-workflow/SKILL.md",
          "type": "blob",
          "size": 6358
        },
        {
          "path": "docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/legacy",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/legacy/README.md",
          "type": "blob",
          "size": 1137
        },
        {
          "path": "templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "templates/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "templates/hooks/post-tool-use.sh",
          "type": "blob",
          "size": 2282
        },
        {
          "path": "templates/hooks/stop.sh",
          "type": "blob",
          "size": 1511
        },
        {
          "path": "templates/hooks/user-prompt-submit.sh",
          "type": "blob",
          "size": 10668
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"chronicle-skills\",\n  \"owner\": {\n    \"name\": \"Chandler Hardy\",\n    \"email\": \"hardych04@gmail.com\"\n  },\n  \"metadata\": {\n    \"description\": \"Skills for working with Chronicle - a local-first development session recorder\",\n    \"version\": \"1.0.0\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"chronicle-workflow-skills\",\n      \"description\": \"Complete Chronicle workflow skills including session documentation, context retrieval, and development tracking\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./chronicle-skills/chronicle-workflow\",\n        \"./chronicle-skills/chronicle-session-documenter\",\n        \"./chronicle-skills/chronicle-context-retriever\",\n        \"./chronicle-skills/chronicle-project-tracker\",\n        \"./chronicle-skills/chronicle-remote-summarizer\",\n        \"./chronicle-skills/chronicle-assistant-guide\"\n      ]\n    }\n  ]\n}\n",
        "README.md": "# Chronicle - AI Session Recorder\n\n<p align=\"center\">\n  <img src=\"public/chronicle_paragraph.png\" alt=\"Chronicle - Local-first development session recorder with AI-powered search\" width=\"800\">\n</p>\n\n> **Give your AI assistants a memory. Track every decision, search past conversations, and never lose context across sessions.**\n\n## ğŸŒ… Project Sunset Notice\n\n**November 2025: Chronicle has been officially sunset.**\n\nAfter a successful development journey, we've decided to end active development of Chronicle. The project achieved all its core goals and demonstrated that AI session recording provides immense value - with a proven **2,700x ROI** from real-world usage data.\n\n### Why the Sunset?\n\nThe primary motivation for ending Chronicle's development is the discovery of the **episodic-memory skill** in the superpowers repository, which provides a more comprehensive and integrated solution for conversation memory across AI platforms. Rather than maintaining two overlapping solutions, we recommend users transition to the episodic-memory system for future needs.\n\n### What This Means\n\n- âœ… **The codebase remains available** for reference, learning, and adaptation\n- âœ… **All features are stable and functional** - you can continue using Chronicle if it meets your needs\n- âœ… **Comprehensive documentation** preserves all architectural decisions and implementation patterns\n- âŒ **No new features or bug fixes** will be implemented\n- âŒ **No active maintenance or support** will be provided\n\n### Recommended Alternative\n\nFor new users or those seeking similar functionality, we highly recommend exploring:\n\n- **episodic-memory skill** (superpowers repository) - Cross-platform conversation memory with advanced search capabilities\n- **Built-in AI tool memory** - Many AI assistants are adding native session memory features\n\n### Legacy\n\nChronicle pioneered the concept of AI session recording and demonstrated:\n- AI-powered session summarization with chunked processing\n- MCP server integration for AI queryable databases\n- Database-tracked project management with milestone linking\n- Cross-platform session organization and search\n- The value of persistent AI memory in development workflows\n\n**Thank you to everyone who used, contributed to, and supported Chronicle!** ğŸ¯\n\n[![Tests](https://img.shields.io/badge/tests-140%20passing-brightgreen)]()\n[![Python](https://img.shields.io/badge/python-3.11%2B-blue)]()\n[![License](https://img.shields.io/badge/license-MIT-blue)]()\n[![MCP](https://img.shields.io/badge/MCP-enabled-purple)]()\n[![Phase](https://img.shields.io/badge/phase-6%20complete-success)]()\n[![Status](https://img.shields.io/badge/status-sunset-important)]()\n\n---\n\n## ğŸ’¡ Value Proposition\n\n**The Problem:** You spend hours discussing architecture decisions with Claude Code on Monday. On Friday, you switch to a new project and Claude has zero memory of what you decided. You waste time re-explaining context, rediscovering solutions, and repeating conversations across different AI tools.\n\n**Chronicle solves this** by creating a searchable, AI-powered memory system for all your development work:\n\n- ğŸ§  **Persistent AI Memory** - Your AI assistants can query Chronicle to remember what you discussed last week, last month, or last year\n- ğŸ” **Cross-Session Intelligence** - \"How did I implement authentication in that other project?\" â†’ Instant answer from past sessions\n- ğŸ“Š **Development Insights** - See patterns in your workflow, track time across projects, generate weekly summaries\n- ğŸ¤ **Multi-AI Coordination** - Claude, Gemini, and Qwen can all access the same knowledge base\n- ğŸ”’ **100% Local** - Everything stays on your machine. No cloud sync, no data sharing, full privacy.\n\n**Perfect for:**\n- **Solo Developers** - Never forget why you made that architectural decision 3 months ago\n- **Consultants & Contractors** - Track billable hours, generate client reports, document decisions\n- **Multi-Project Engineers** - \"What did I do on ProjectX last week?\" â†’ Instant answer\n- **AI Power Users** - Get the most out of Claude, Gemini, Cursor, etc. with persistent context\n- **Teams** - Build institutional knowledge from AI-assisted development\n- **Open Source Maintainers** - Document discussions and decisions for contributors\n\n---\n\n## ğŸ¬ Quick Demo\n\n```bash\n# Day 1: Work on authentication\n$ chronicle start claude\n> You discuss OAuth2 implementation with Claude for 2 hours\n> Make several commits\n$ exit\n\n# Day 30: Different project, need to remember\n$ chronicle start claude\nYou: \"How did I implement OAuth2 in that other project?\"\n\nClaude: [Uses Chronicle MCP server]\n        â†’ search_sessions(\"OAuth2\")\n        â†’ get_session_summary(session_id=5)\n\nClaude: \"In session 5 from last month, you implemented OAuth2 with\n         the 'authorization_code' flow. Key decisions:\n         - Used Auth0 for identity provider\n         - Stored tokens in httpOnly cookies\n         - Implemented refresh token rotation\n         Files: src/auth/oauth.ts, src/middleware/auth.ts\"\n\nYou: \"Perfect! Do the same thing for this project\"\n# No time wasted re-explaining context! ğŸ¯\n```\n\n---\n\n## ğŸ¯ The Problem (Detailed)\n\nModern developers use multiple AI coding assistants, but face critical challenges:\n\n**Memory Loss**\n- âŒ Each AI session starts from scratch with zero context\n- âŒ \"What did we decide about authentication 2 weeks ago?\" ğŸ¤·\n- âŒ Repeat the same explanations across different AI tools\n- âŒ Lost context when switching between Claude Code, Gemini CLI, Cursor\n\n**Tracking Difficulty**\n- âŒ No record of decisions made during AI-assisted development\n- âŒ Hard to remember which AI tool helped with which feature\n- âŒ Can't search through past AI conversations\n- âŒ Lost connection between commits and the AI sessions that created them\n\n**Multi-Project Chaos**\n- âŒ Work on 5 different projects? Good luck remembering what you did where\n- âŒ Client asks \"what did we build last sprint?\" â†’ scramble through git logs\n- âŒ No easy way to generate weekly summaries or progress reports\n\n## âœ¨ The Solution\n\nChronicle is a **local-first development memory system** that gives AI assistants persistent context:\n\n**Core Features:**\n- ğŸ¯ **Full Session Recording** - Complete transcripts of Claude Code, Gemini CLI, Qwen Code sessions\n- ğŸ”— **Commit Linking** - Automatically connects git commits to the AI sessions that created them\n- ğŸ¤– **AI-Powered Summaries** - Intelligent summaries with key decisions, blockers, and file changes\n- ğŸ” **Instant Search** - Find past conversations, decisions, and implementations in seconds\n- ğŸ“Š **Multi-Project Tracking** - Automatically organizes work by repository\n- ğŸ”Œ **MCP Server** - AI assistants can query Chronicle database directly via Model Context Protocol\n- ğŸ“ **Obsidian Integration** - Optional export to markdown vault for knowledge graph visualization\n- ğŸ”’ **100% Local** - Everything stored in SQLite on your machine (no cloud required)\n\n---\n\n## ğŸš€ Quick Start\n\n### Installation\n\n#### Standard Installation (with MCP server support)\n\n```bash\n# Clone and install with MCP support\ngit clone https://github.com/ChandlerHardy/chronicle\ncd chronicle\npython3 -m pip install -e \".[mcp]\"\n\n# Initialize Chronicle\nchronicle init\n\n# Interactive setup (API configuration + optional Claude Code hooks)\nchronicle setup\n\n# Add a repository to track\nchronicle add-repo /path/to/your/project\n```\n\n#### Minimal Installation (CLI only, no MCP server)\n\nFor environments where you can't install Rust dependencies (e.g., restricted FreeBSD systems), you can install Chronicle without MCP support:\n\n```bash\n# Clone and install without MCP dependencies\ngit clone https://github.com/ChandlerHardy/chronicle\ncd chronicle\npython3 -m pip install -e .\n\n# All CLI commands work normally\nchronicle init\nchronicle setup  # Unified interactive setup (API + optional hooks)\nchronicle start claude\nchronicle sessions\nchronicle search \"your query\"\n```\n\n**Note:** Without MCP support, AI assistants cannot query Chronicle directly. All features work via CLI.\n\n#### Ubuntu/Debian Troubleshooting\n\nOn Ubuntu/Debian systems, you may encounter these issues:\n\n**Issue 1: \"externally-managed-environment\" error**\n\n```bash\n# Solution: Use --break-system-packages or create virtual environment\npython3 -m pip install -e \".[mcp]\" --break-system-packages\n\n# Or create virtual environment (recommended)\npython3 -m venv chronicle-venv\nsource chronicle-venv/bin/activate\npython3 -m pip install -e \".[mcp]\"\n```\n\n**Issue 2: \"Command 'chronicle' not found\" after installation**\n\nThis happens because pip installs scripts in `~/.local/bin` which isn't in PATH:\n\n```bash\n# Add local bin to PATH (temporary)\nexport PATH=\"$HOME/.local/bin:$PATH\"\n\n# Add permanently to shell profile\necho 'export PATH=\"$HOME/.local/bin:$PATH\"' >> ~/.bashrc\nsource ~/.bashrc\n\n# Verify correct chronicle is installed\nwhich chronicle  # Should show /home/user/.local/bin/chronicle\n```\n\n**Issue 3: Installing wrong \"chronicle\" package**\n\nUbuntu has an unrelated package called `chronicle` (a blog generator). If you accidentally install it:\n\n```bash\n# Remove the wrong package\nsudo apt remove chronicle\n\n# Then use the PATH fix above to access the correct one\n```\n\n### Basic Usage\n\n```bash\n# View today's activity (commits + AI interactions)\nchronicle show today\n\n# Start an interactive AI session (auto-recorded)\nchronicle start claude      # Claude Code\nchronicle start gemini      # Gemini CLI\nchronicle start qwen        # Qwen Code CLI\n\n# View all sessions\nchronicle sessions\nchronicle sessions --limit 20                   # Show more sessions\nchronicle sessions --repo /path/to/project      # Filter by repository\n\n# Search sessions with FTS5 full-text search (supports boolean operators!)\nchronicle search-sessions \"gemini model\"              # Any word (broader results, implicit OR)\nchronicle search-sessions \"gemini AND model\"          # Both words required (explicit AND)\nchronicle search-sessions \"gemini OR claude\" --all    # Either word (explicit OR)\nchronicle search-sessions \"testing NOT deprecated\"    # Exclude deprecated\nchronicle search-sessions '\"data corruption\"'         # Exact phrase only\n\n# View a session with AI-generated summary\nchronicle session 5\n\n# AI-powered summaries of your work\nchronicle summarize today                       # Today's accomplishments\nchronicle summarize week                        # Weekly digest\nchronicle summarize today --repo /path/repo     # Per-project summaries\n\n# See combined timeline\nchronicle timeline today\n\n# Search history\nchronicle search \"authentication\"\n```\n\n### Updating Chronicle\n\nChronicle includes a built-in update command that handles everything automatically:\n\n```bash\n# Check for and install updates\nchronicle update\n\n# Check what's available without installing\nchronicle update --check-only\n```\n\n**What it does:**\n- âœ… Checks for new commits from GitHub\n- âœ… Shows what's changed (commit log)\n- âœ… Pulls latest code\n- âœ… Auto-detects if dependencies changed\n- âœ… Reinstalls with correct mode (MCP or minimal)\n- âœ… Auto-migrates database if schema changed\n\n**Manual update:**\n```bash\ncd /path/to/chronicle\ngit pull origin main\npip install -e \".[mcp]\"  # Or: pip install -e .\n```\n\n---\n\n## ğŸ“– Core Concepts\n\n### Chronicle vs CLAUDE.md\n\n**CLAUDE.md** is static project documentation:\n- âœ… Project structure, conventions, tech stack\n- âœ… Written manually, read by AI at session start\n- âœ… Describes \"how this project works\"\n\n**Chronicle** is dynamic session recording:\n- âœ… Automatic tracking of what you actually did\n- âœ… Cross-AI session history (Claude, Gemini, Qwen)\n- âœ… Searchable timeline of decisions and changes\n- âœ… Describes \"what happened and why\"\n\n**They're complementary!** CLAUDE.md tells the AI about your project, Chronicle tells YOU what you did.\n\n---\n\n## ğŸ® Features\n\n### âœ… Phase 1: Git Commit Tracking (COMPLETE)\n\nTrack git commits and link them to development activity:\n\n```bash\nchronicle add-repo /path/to/project    # Import commits\nchronicle show today                    # View today's commits\nchronicle search \"bug fix\"              # Search commit messages\nchronicle stats /path/to/project        # Repository statistics\n```\n\n**Features:**\n- Auto-scan git repositories for commits\n- Store commit metadata (SHA, message, files, author, timestamp)\n- Prevent duplicates\n- Search by message content\n- Filter by date range\n\n---\n\n### âœ… Phase 2: AI Interaction Tracking (COMPLETE)\n\n#### Interactive Session Wrapper\n\nRecord full AI coding sessions with transcript capture:\n\n```bash\nchronicle start claude      # Start Claude Code session\nchronicle start gemini      # Start Gemini CLI session\nchronicle start qwen        # Start Qwen Code CLI session\n\n# Work normally in the AI tool...\n# Full transcript is recorded automatically\n\nexit                        # Session saved!\n\nchronicle sessions          # List all sessions\nchronicle session 5         # View session details\n```\n\n**Features:**\n- Full terminal transcript capture using Unix `script` command\n- Records all input/output from AI conversations\n- Automatic timestamp tracking\n- Session duration calculation\n- Automatic summarization (generated when you view the session)\n\n#### One-Shot AI Commands\n\nFor quick questions to Gemini or Qwen:\n\n```bash\nchronicle ask \"How do I optimize this query?\" --tool gemini\nchronicle ask \"Review this code for bugs\" --tool qwen\nchronicle ask \"Test question\" --tool gemini --log-only\n```\n\n#### CLI Commands\n\n```bash\nchronicle ai today              # View today's AI interactions\nchronicle ai yesterday          # Yesterday's interactions\nchronicle ai week               # Last 7 days\n\nchronicle ai-stats              # Usage statistics with charts\nchronicle ai-stats --days 30    # Last 30 days\n\nchronicle timeline today        # Combined commits + AI interactions\n```\n\n**Features:**\n- AI interaction logging (prompt, response, duration)\n- Auto-link interactions to commits (30-minute window)\n- Multi-tool support (Claude Code, Gemini CLI, Qwen Code)\n- Beautiful terminal output with tool-specific emojis (ğŸ¯ Claude, âœ¨ Gemini, ğŸ”® Qwen)\n- Usage statistics with visual charts\n\n---\n\n### ğŸ”§ Configuration System (COMPLETE)\n\nManage Chronicle settings with YAML config:\n\n```bash\nchronicle config --list                          # View all settings\nchronicle config ai.gemini_api_key              # View API key (masked)\nchronicle config ai.gemini_api_key YOUR_KEY     # Set API key\nchronicle config ai.default_model               # View default model\n```\n\n**Config file:** `~/.ai-session/config.yaml`\n\n**Available settings:**\n- `ai.gemini_api_key` - Gemini API key for summarization\n- `ai.default_model` - Default Gemini model (gemini-2.0-flash-exp)\n- `ai.summarization_provider` - Summarization provider (gemini or ollama)\n- `ai.ollama_model` - Ollama model name (qwen2.5:32b)\n- `ai.ollama_host` - Ollama host URL (http://localhost:11434)\n- `ai.auto_summarize_sessions` - Auto-summarize when viewing session (disabled by default)\n- `retention.raw_data_days` - How long to keep raw transcripts (7 days)\n- `retention.summaries_days` - How long to keep summaries (90 days)\n\n**Security:**\n- API keys masked in display\n- Environment variable support (`GEMINI_API_KEY`)\n- Config file excluded from git (`.gitignore`)\n\n---\n\n### âœ… Claude Code Hooks & Workflow Automation (COMPLETE)\n\nAutomatically enforce Chronicle best practices with Claude Code hooks:\n\n```bash\n# Set up hooks for workflow automation (included in unified setup)\nchronicle setup --hooks-only\n\n# Hooks will now automatically:\n# - Remind you to search Chronicle before implementing\n# - Recommend relevant skills for your task\n# - Check if you're writing tests first (TDD)\n# - Verify session tracking status\n# - Check for superpowers skills availability\n```\n\n**What gets installed:**\n- **Hook scripts** in `~/.claude/hooks/` - UserPromptSubmit, Stop, PostToolUse\n- **Settings configuration** in `~/.claude/settings.json` - Registers hooks with Claude Code\n- **Universal CLAUDE.md** in `~/.claude/CLAUDE.md` - Development best practices\n\n**Hook Behaviors:**\n- **UserPromptSubmit Hook**: Injects \"Search Chronicle First\" reminders and skill recommendations\n- **Stop Hook**: Post-response quality checks (session tracking, TDD compliance)\n- **PostToolUse Hook**: Tracks edited files for future build checking\n- **Superpowers Integration**: Checks for TDD skill availability and provides installation guidance\n\n**Universal Directives:**\nThe `~/.claude/CLAUDE.md` contains comprehensive development guidelines:\n- âœ… **Search First Mandate** - 2,700x ROI proven from real sessions\n- âœ… **Skills Integration** - Auto-recommend Chronicle skills\n- âœ… **TDD Enforcement** - Write tests before implementation (with superpowers TDD skill)\n- âœ… **MCP over CLI** - Use structured MCP tools instead of parsing CLI output\n- âœ… **Roadmap Checking** - Avoid duplicate work\n\n**Superpowers Skills Integration:**\n- ğŸ§ª **TDD Skill Auto-Activation** (Priority 95) - Comprehensive test-driven development enforcement\n- ğŸ“‹ **Installation Checking** - Automatically verifies superpowers marketplace and skills availability\n- ğŸ”§ **Guided Setup** - Provides clear installation instructions when skills are missing\n\n**Benefits:**\n- ğŸ¯ **50% token reduction** vs always-active agents\n- ğŸ”§ **Automatic enforcement** - No need to remember best practices\n- ğŸ“‹ **Quality checks** - Catches common mistakes before they happen\n- ğŸ”„ **Cross-platform** - Works on macOS, Linux, and FreeBSD\n\n**Usage:**\nAfter running `chronicle setup` (or `chronicle setup --hooks-only`), restart Claude Code. The hooks will automatically activate based on your prompts and provide contextual reminders.\n\n**For FreeBSD Systems:**\nThe setup command will check for superpowers skills availability. If missing:\n1. Run `/plugin install superpowers-marketplace` in Claude Code\n2. Run `/plugin install superpowers@superpowers-marketplace`\n3. Restart Claude Code\n4. TDD skill will now auto-activate when implementing features\n\n---\n\n### âœ… Phase 3: AI Summarization (COMPLETE)\n\nAI-powered summarization with multiple provider options:\n\n#### Setup\n\n**Option 1: Gemini (Cloud, 1M token context)**\n```bash\n# Configure Gemini API key\nchronicle config ai.gemini_api_key YOUR_KEY\nchronicle config ai.summarization_provider gemini\nchronicle config ai.default_model gemini-2.0-flash-exp\n\n# Test connection\nchronicle test-gemini\n```\n\n**Option 2: Ollama (Local, unlimited)**\n```bash\n# Install and run Ollama first: https://ollama.ai\nollama pull qwen2.5:32b\n\n# Configure Chronicle\nchronicle config ai.summarization_provider ollama\nchronicle config ai.ollama_model qwen2.5:32b\nchronicle config ai.ollama_host http://localhost:11434\n```\n\n#### View Session with Auto-Summary\n\n```bash\nchronicle sessions              # List all sessions\nchronicle session 5             # View session #5\n\n# First time: Automatically generates AI summary\n# Subsequent views: Shows cached summary (instant!)\n```\n\n#### Summarize Large Sessions with Qwen/Gemini CLI\n\nFor large sessions that exceed Gemini API rate limits, use Qwen CLI or Gemini CLI directly:\n\n```bash\nchronicle summarize-session 8              # Use Qwen CLI (default, 2000 req/day)\nchronicle summarize-session 8 --provider gemini  # Use Gemini CLI\n```\n\nThis bypasses API token-per-minute limits by calling the CLI tools directly.\n\n#### Generate Daily/Weekly Summaries\n\n```bash\nchronicle summarize today       # AI summary of today's work\nchronicle summarize week        # AI summary of last 7 days\n```\n\n**Features:**\n- **Multi-provider support** - Choose between Gemini (cloud, 1M context) or Ollama (local, unlimited)\n- **Transcript cleaning** - Removes ANSI codes and duplicates (typically 50-90% size reduction)\n- **Automatic summarization** - AI summary generated when you view the session\n- **Auto-caching** - Generate once, view instantly forever\n- **Intelligent prompts** - Extracts key decisions, files modified, blockers\n- **Markdown formatting** - Beautiful, structured summaries\n- **Multi-source analysis** - Analyzes both git commits and AI sessions\n\n**Example Summary:**\n```\n## What Was Built\n- Implemented Phase 3 summarization with Gemini API integration\n- Added chronicle session command with auto-summarization\n\n## Key Decisions\n- Automatic summarization triggered when viewing sessions\n- Cached summaries in database for instant retrieval\n\n## Files/Components Modified\n- backend/cli/commands.py\n- backend/cli/formatters.py\n- backend/services/summarizer.py\n```\n\n---\n\n### ğŸ—‚ï¸ Multi-Project Organization\n\nChronicle automatically tracks which repository each session belongs to:\n\n#### Automatic Repository Detection\n\nWhen you start a session, Chronicle automatically:\n- Detects your current working directory\n- Finds the git repository root (if in a git repo)\n- Associates the session with that project\n\n```bash\ncd /Users/you/repos/my-app\nchronicle start claude\n# Session automatically tagged with \"my-app\" repository\n```\n\n#### Filter by Repository\n\nView sessions, timelines, and summaries for specific projects:\n\n```bash\n# View sessions for a specific project\nchronicle sessions --repo /Users/you/repos/my-app\n\n# Summarize work on specific project\nchronicle summarize today --repo /Users/you/repos/my-app\nchronicle summarize week --repo /Users/you/repos/other-project\n\n# Timeline for specific project\nchronicle timeline today --repo /Users/you/repos/my-app\n```\n\n**Benefits:**\n- Track work across multiple projects separately\n- \"What did I do on project X this week?\"\n- Organize sessions by codebase\n- Perfect for contractors juggling multiple clients\n\n---\n\n### âœ… Phase 4: MCP Server + AI Integration (COMPLETE)\n\nGive your AI assistants the ability to query Chronicle's database directly!\n\n#### Chronicle MCP Server\n\nThe Chronicle MCP (Model Context Protocol) server allows **any MCP-compatible AI** (Claude Code, ChatGPT, etc.) to query your Chronicle database and retrieve past sessions, commits, and decisions.\n\n**Setup:**\n\n1. **Install Chronicle with MCP support:**\n   ```bash\n   pip install -e .\n   ```\n\n2. **Configure MCP client** (e.g., `~/.mcp.json`):\n   ```json\n   {\n     \"mcpServers\": {\n       \"chronicle\": {\n         \"command\": \"python3\",\n         \"args\": [\"/path/to/chronicle/scripts/chronicle-mcp\"]\n       }\n     }\n   }\n   ```\n\n3. **Restart your AI tool** (Claude Code, etc.)\n\n4. **Verify:** Type `/mcp` to see available servers\n\n**Available MCP Tools:**\n\nThe Chronicle MCP server provides 21 tools that AI assistants can use:\n\n**Session & Commit Queries:**\n| Tool | Purpose | Example |\n|------|---------|---------|\n| `get_sessions` | List recent sessions | \"Show me sessions from this week\" |\n| `get_session_summary` | Get session details | \"What happened in session 15?\" |\n| `search_sessions` | Search session content | \"Find where we discussed authentication\" |\n| `get_sessions_summaries` | Batch retrieve summaries | \"Get summaries for sessions 5, 6, 7\" |\n| `get_commits` | List git commits | \"Show commits from the my-app repo\" |\n| `search_commits` | Search commit messages | \"Find bug fix commits\" |\n| `get_timeline` | Combined view | \"Show me today's work\" |\n| `get_stats` | Usage statistics | \"How much did I use AI tools this month?\" |\n\n**Project Management (CRUD Operations):**\n| Tool | Purpose | Example |\n|------|---------|---------|\n| `get_milestones` | List milestones | \"Show in-progress features\" |\n| `get_milestone` | Get milestone details | \"What's milestone 3 about?\" |\n| `create_milestone` | Create new milestone | \"Plan new authentication feature\" |\n| `update_milestone` | Edit milestone | \"Update priority to 1\" |\n| `delete_milestone` | Remove milestone | \"Delete test milestone\" |\n| `update_milestone_status` | Change status | \"Mark as completed\" |\n| `get_next_steps` | List TODOs | \"What should I work on?\" |\n| `create_next_step` | Add TODO | \"Create task to write tests\" |\n| `update_next_step` | Edit TODO | \"Change priority\" |\n| `delete_next_step` | Remove TODO | \"Delete obsolete task\" |\n| `complete_next_step` | Mark done | \"Mark step 5 as done\" |\n| `uncomplete_next_step` | Reopen TODO | \"Reopen completed task\" |\n| `get_roadmap` | Project overview | \"Show current roadmap\" |\n\n**Real-World Example:**\n\n```\nYou: \"How did I implement caching in that other project last month?\"\n\nClaude: [Uses Chronicle MCP]\n         â†’ search_sessions(\"caching\")\n         â†’ get_session_summary(session_id=42)\n\nClaude: \"In session 42 from September 15th, you implemented Redis\n         caching for the API endpoints. Here's what you decided...\"\n```\n\n**Benefits:**\n- ğŸ§  AI assistants have persistent memory across sessions\n- ğŸ” Instant context retrieval from past work\n- ğŸ“Š AI can analyze patterns in your workflow\n- ğŸ¤ Works with any MCP-compatible AI tool\n- ğŸ”’ 100% local (no data leaves your machine)\n\n**Documentation:** See [MCP_SERVER.md](MCP_SERVER.md) for full details.\n\n---\n\n### ğŸ¯ Claude Skills Integration\n\nFor Claude Code users, Chronicle provides pre-built **Claude Skills** that automate common workflows:\n\n**Available Skills:**\n\n1. **chronicle-session-documenter**\n   - Automatically documents sessions to Obsidian vault\n   - Creates structured markdown notes with metadata\n   - Links related sessions, commits, and repos\n\n2. **chronicle-context-retriever**\n   - Searches past sessions for relevant context\n   - Triggered by questions like \"how did I...\" or \"what did we...\"\n   - Provides summaries of past decisions\n\n3. **chronicle-workflow**\n   - Complete Chronicle workflow guidance\n   - Best practices for multi-project tracking\n   - Helps set up and optimize Chronicle usage\n\n**Installation:**\n```bash\n# One-time setup in Claude Code\n/plugin marketplace add ChandlerHardy/chronicle\n/plugin install chronicle-workflow-skills@chronicle-skills\n```\n\n**How It Works:**\n\nSkills are \"smart prompt templates\" that automatically trigger when relevant:\n\n```\nYou: \"Document session 15 to my Obsidian vault\"\n\nClaude: [Automatically uses chronicle-session-documenter skill]\n        â†’ Retrieves session summary\n        â†’ Creates markdown note with frontmatter\n        â†’ Adds wikilinks to related sessions\n        â†’ Saves to vault at Chronicle/Sessions/Session-15.md\n```\n\n**Documentation:** See `chronicle-skills/README.md` for details.\n\n---\n\n### ğŸ¤– Intelligent Agents (Cross-Platform)\n\nChronicle includes two **specialized agents** that proactively enforce best practices. Unlike skills (Claude Code only), **agent prompts work across platforms** - adaptable for Cursor, Windsurf, and other AI assistants.\n\n**Available Agents:**\n\n1. **Chronicle Advocate Agent**\n   - Reminds to search Chronicle before implementing (2,700x ROI!)\n   - Checks if session is being tracked\n   - Enforces MCP usage over slow CLI commands\n   - Suggests organizing sessions with titles/tags\n   - Prevents repeating work from past sessions\n\n2. **TDD Advocate Agent**\n   - Encourages test-driven development workflow\n   - Reminds to write tests before implementation\n   - Runs pytest after code changes\n   - Ensures all tests pass before commits\n   - Celebrates test successes âœ…\n\n**Setup (Claude Code):**\n```bash\n# Use the /agents command in Claude Code\n/agents\n# Select \"Create new agent\"\n# Copy prompts from AGENTS.md\n# Restart Claude Code to activate\n```\n\n**Key Advantage:** Agent prompts are portable! The same prompt works in:\n- Claude Code (via `/agents`)\n- Cursor (via `.cursorrules`)\n- Windsurf (via project config)\n- Any AI tool with custom instructions\n\n**Documentation:** See **[AGENTS.md](AGENTS.md)** for full prompts and cross-platform setup.\n\n---\n\n### ğŸ“ Obsidian Integration (Optional)\n\nExport Chronicle sessions to Obsidian for visual knowledge graphs and bidirectional linking.\n\n**Setup:**\n\nConfigure the Obsidian MCP server in `~/.mcp.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"obsidian\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"@mauricio.wolff/mcp-obsidian@latest\",\n        \"/path/to/your/obsidian/vault\"\n      ]\n    }\n  }\n}\n```\n\n**Features:**\n- Export sessions as markdown notes with YAML frontmatter\n- Wikilinks between related sessions and commits\n- Tag-based organization for Obsidian graph view\n- Repository-based folder structure\n- Search entire vault from Claude Code\n\n**Example Vault Structure:**\n```\nChronicle/\nâ”œâ”€â”€ Repos/\nâ”‚   â”œâ”€â”€ my-app/\nâ”‚   â”‚   â”œâ”€â”€ Sessions/\nâ”‚   â”‚   â”‚   â”œâ”€â”€ Session-15.md\nâ”‚   â”‚   â”‚   â””â”€â”€ Session-16.md\nâ”‚   â”‚   â””â”€â”€ Commits/\nâ”‚   â””â”€â”€ other-project/\nâ”‚       â””â”€â”€ Sessions/\nâ””â”€â”€ Daily/\n    â””â”€â”€ 2025-10-20.md\n```\n\n**Coming Soon:** `chronicle export obsidian` command for batch export.\n\n---\n\n## ğŸ“Š Example Outputs\n\n### Daily Summary\n\n```bash\n$ chronicle show today\n\nDevelopment Session - October 19, 2025\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\nâ”‚ Session Statistics                                       â”‚\nâ”‚ â€¢ Commits: 5                                             â”‚\nâ”‚ â€¢ Files Changed: 12                                      â”‚\nâ”‚ â€¢ Repositories: 2                                        â”‚\nâ”‚ â€¢ Authors: 1                                             â”‚\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n\nCommits\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n10:30 AM [abc1234] Add user authentication\n   â†’ src/auth.ts\n   â†’ src/middleware.ts\n\n02:15 PM [def5678] Update README with usage examples\n   â†’ README.md\n```\n\n### AI Interaction Timeline\n\n```bash\n$ chronicle ai today\n\nAI Interactions Today\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n02:30 PM âœ¨ Gemini\n   \"How do I implement caching in Python?\"\n   â†’ You can use functools.lru_cache decorator...\n   â± 2.3s\n   âœ“ Linked to commit abc1234\n\n01:45 PM ğŸ”® Qwen\n   \"Review this authentication code\"\n   â†’ The code looks good overall. Consider adding rate limiting...\n   â± 3.1s\n```\n\n### AI Usage Statistics\n\n```bash\n$ chronicle ai-stats --days 7\n\nAI Tool Usage (Last 7 days)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nâ”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ AI Tool  â”ƒ  Interactions â”ƒ   Percentage â”ƒ  Avg Duration â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ Claude   â”‚            15 â”‚        65.2% â”‚         4.2s  â”‚\nâ”‚          â”‚               â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ â”‚               â”‚\nâ”‚ Gemini   â”‚             6 â”‚        26.1% â”‚         2.1s  â”‚\nâ”‚          â”‚               â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚               â”‚\nâ”‚ Qwen     â”‚             2 â”‚         8.7% â”‚         3.5s  â”‚\nâ”‚          â”‚               â”‚ â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚               â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nTotal interactions: 23\n```\n\n### Combined Timeline\n\n```bash\n$ chronicle timeline today\n\nCombined Development Timeline\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n02:30 PM âœ¨ Gemini\n   \"How do I implement caching in Python?\"\n\n02:25 PM [abc1234] Add caching to API endpoints\n   â†’ api/cache.py\n   â†’ api/endpoints.py\n\n01:45 PM ğŸ¯ Claude (Session, 45m)\n   \"Built authentication system\"\n   â†’ src/auth.ts\n   â†’ src/middleware.ts\n   âœ“ Linked to commit def5678\n\n01:30 PM [def5678] Implement JWT authentication\n   â†’ auth/jwt.ts\n```\n\n---\n\n## ğŸ—‚ï¸ Database Schema\n\nChronicle uses SQLite for local-first storage at `~/.ai-session/sessions.db`:\n\n### Tables\n\n**commits** - Git commit tracking\n- timestamp, SHA, message, files_changed (JSON)\n- branch, author, repo_path\n\n**ai_interactions** - AI tool interactions\n- timestamp, ai_tool, prompt, response_summary\n- duration_ms, files_mentioned (JSON)\n- is_session, session_transcript, summary_generated\n- related_commit_id (foreign key)\n\n**daily_summaries** - Daily development summaries (Phase 3)\n- date, summary, topics (JSON), files_affected (JSON)\n- commits_count, ai_interactions_count, key_decisions (JSON)\n\n### Data Storage\n\n- **Database:** `~/.ai-session/sessions.db`\n- **Session transcripts:** `~/.ai-session/sessions/session_N.log`\n- **Session metadata:** `~/.ai-session/sessions/session_N.meta`\n- **Configuration:** `~/.ai-session/config.yaml`\n\n---\n\n## ğŸ§ª Testing\n\nChronicle has comprehensive test coverage:\n\n```bash\n# Run all tests\npytest\n\n# Run with coverage\npytest --cov=backend tests/\n\n# Current status: 140 passing tests, 1 skipped\n# Test modules:\n# - test_ai_tracker.py: 13 tests (AI interaction logging)\n# - test_claude_provider.py: 44 tests (Claude Code provider)\n# - test_cli_commands.py: 17 tests (CLI command interface)\n# - test_git_monitor.py: 8 tests (Git commit tracking)\n# - test_import_export.py: 15 tests (Data import/export, 1 skipped)\n# - test_project_tracking.py: 9 tests (Project milestones & next steps)\n# - test_session_manager.py: 22 tests (Session recording & management)\n# - test_summarizer.py: 15 tests (AI summarization)\n```\n\n---\n\n## ğŸ›£ï¸ Roadmap\n\n### âœ… Phase 1: Git Tracking (COMPLETE)\n- [x] Git commit monitoring\n- [x] CLI query interface\n- [x] Search and statistics\n- [x] Comprehensive test coverage\n\n### âœ… Phase 2: AI Tracking (COMPLETE)\n- [x] AI interaction logging\n- [x] Session wrapper for Claude/Gemini/Qwen\n- [x] Multi-AI timeline view\n- [x] Usage statistics\n- [x] Configuration system\n- [x] Comprehensive test coverage\n\n### âœ… Phase 3: Summarization (COMPLETE)\n- [x] Gemini API integration\n- [x] Ollama local LLM support\n- [x] `chronicle session` command with auto-summarization\n- [x] `chronicle summarize today/week` commands\n- [x] Chunked summarization for unlimited session sizes\n- [x] Automatic summarization with caching\n- [x] Intelligent prompt engineering\n- [x] Markdown-formatted summaries\n- [x] Multi-project tracking and filtering\n\n### âœ… Phase 4: MCP Server + AI Integration (COMPLETE)\n- [x] Chronicle MCP server with 21 tools (8 query + 13 project management)\n- [x] Full CRUD operations for milestones and next steps\n- [x] FastMCP framework integration\n- [x] Read/write database access for AI tools\n- [x] Support for any MCP-compatible AI (Claude, ChatGPT, etc.)\n- [x] Obsidian MCP server integration\n- [x] Claude Skills marketplace integration\n- [x] 3 pre-built skills (documenter, retriever, workflow)\n- [x] Multi-repository session organization\n- [x] Comprehensive documentation (MCP_SERVER.md)\n\n### âœ… Phase 5: Project Tracking & Meta-Development (COMPLETE)\n\n**Chronicle now tracks its own development!** Database-backed milestones and next steps eliminate manual documentation updates.\n\n#### The Innovation: Database-Tracked TODOs\n\nInstead of maintaining DEVELOPMENT_HISTORY.md manually, Chronicle tracks project state in its database:\n\n```bash\n# Plan a feature\nchronicle milestone \"Add authentication\" \\\n  --description \"Implement OAuth2 with Auth0\" \\\n  --type feature \\\n  --priority 1 \\\n  --tags \"backend,auth,security\"\n\n# Break down into actionable tasks\nchronicle next-step \"Design auth flow\" --priority 1 --effort medium --milestone 1\nchronicle next-step \"Implement OAuth2 client\" --priority 1 --effort large --milestone 1\nchronicle next-step \"Add token refresh\" --priority 2 --effort medium --milestone 1\nchronicle next-step \"Write integration tests\" --priority 2 --effort small --milestone 1\nchronicle next-step \"Update API documentation\" --priority 3 --effort small --milestone 1\n\n# Mark milestone as active\nchronicle milestone-status 1 in_progress\n\n# As you work, link sessions to the milestone\nchronicle start claude\n# ... work on authentication ...\nexit\nchronicle link-session 18 --milestone 1\n\n# Complete tasks as you finish them\nchronicle next-step-complete 1\nchronicle next-step-complete 2\n\n# View project progress anytime\nchronicle roadmap\n```\n\n**Output:**\n```\nChronicle Development Roadmap\n\nğŸš§ In Progress\n  â€¢ Add authentication (feature, 3 sessions)\n\nğŸ”œ Next Steps\n  â€¢ [P2] Add token refresh [medium]\n  â€¢ [P2] Write integration tests [small]\n  â€¢ [P3] Update API documentation [small]\n\nğŸ“Š Milestones: 5/12 completed | Next Steps: 2/5 done\n```\n\n#### Why This Is Revolutionary\n\n**Before (manual documentation):**\n- âŒ Manually update DEVELOPMENT_HISTORY.md after every feature\n- âŒ Forget to document work-in-progress\n- âŒ Can't query \"what's next?\" programmatically\n- âŒ No link between sessions and features\n- âŒ Documentation becomes stale\n\n**After (database-tracked):**\n- âœ… **Queryable by AI** - \"What should I work on next?\" â†’ Instant answer from database\n- âœ… **Auto-linked** - Sessions automatically connect to milestones\n- âœ… **Real-time roadmap** - `chronicle roadmap` shows current state\n- âœ… **Report generation** - Query completed milestones for weekly summaries\n- âœ… **Dogfooding** - Chronicle tracks building Chronicle!\n\n#### CLI Commands\n\n**Milestones:**\n```bash\nchronicle milestone <title>                    # Create milestone\nchronicle milestones                           # List all milestones\nchronicle milestones --status in_progress      # Filter by status\nchronicle milestones --type feature            # Filter by type\nchronicle milestone-show <id>                  # View details\nchronicle milestone-status <id> <status>       # Update status\nchronicle milestone-complete <id>              # Mark complete\n```\n\n**Next Steps:**\n```bash\nchronicle next-step <description>              # Add TODO\nchronicle next-steps                           # List pending\nchronicle next-steps --all                     # Include completed\nchronicle next-steps --milestone <id>          # Filter by milestone\nchronicle next-step-complete <id>              # Mark done\n```\n\n**Project Management:**\n```bash\nchronicle link-session <session_id> --milestone <id>   # Link session\nchronicle roadmap                                      # View progress\nchronicle roadmap --days 30                            # Last 30 days\n```\n\n#### MCP Tools (AI-Queryable)\n\nAI assistants can query and manage project state via Chronicle MCP server:\n\n```python\n# Read Operations\nmilestones = mcp__chronicle__get_milestones(status=\"in_progress\")\nroadmap = mcp__chronicle__get_roadmap(days=7)\nsteps = mcp__chronicle__get_next_steps(milestone_id=1, completed=False)\n\n# Create Operations\nnew_milestone = mcp__chronicle__create_milestone(\n    title=\"Add export feature\",\n    description=\"Export sessions to PDF/Markdown\",\n    milestone_type=\"feature\",\n    priority=2,\n    tags=\"phase-7,export\"\n)\nnew_step = mcp__chronicle__create_next_step(\n    description=\"Write export logic\",\n    priority=1,\n    effort=\"large\",\n    category=\"feature\",\n    milestone_id=4\n)\n\n# Update Operations\nmcp__chronicle__update_milestone(milestone_id=4, priority=1, tags=\"urgent,export\")\nmcp__chronicle__update_next_step(step_id=12, effort=\"medium\", category=\"optimization\")\nmcp__chronicle__update_milestone_status(milestone_id=1, new_status=\"completed\")\n\n# Complete/Reopen\nmcp__chronicle__complete_next_step(step_id=5)\nmcp__chronicle__uncomplete_next_step(step_id=5)  # Reopen if needed\n\n# Delete Operations (with confirmation)\nmcp__chronicle__delete_next_step(step_id=99, confirm=True)\nmcp__chronicle__delete_milestone(milestone_id=99, confirm=True)\n```\n\n**AI Use Cases:**\n- \"What should I work on next?\" â†’ Queries roadmap, suggests highest priority\n- \"What's the status of authentication work?\" â†’ Finds milestone, shows linked sessions\n- \"Generate a weekly progress report\" â†’ Queries completed milestones, summarizes\n- \"Mark this session as working on feature X\" â†’ Auto-links session to milestone\n\n#### Chronicle Skills\n\n**New: chronicle-project-tracker**\n- Complete workflow for planning features\n- Querying roadmap via MCP\n- Linking sessions to milestones\n- Generating progress reports\n- Auto-documentation patterns\n\nUse: \"What's in our roadmap?\" or \"Plan a new feature\" â†’ Skill loads automatically\n\n#### Database Schema\n\n**project_milestones:**\n- `id`, `title`, `description`\n- `status` - planned, in_progress, completed, archived\n- `milestone_type` - feature, bugfix, optimization, documentation\n- `priority` - 1 (highest) to 5 (lowest)\n- `related_sessions` - JSON array of session IDs\n- `related_commits` - JSON array of commit SHAs\n- `tags` - JSON array for filtering\n\n**next_steps:**\n- `id`, `description`, `priority`\n- `estimated_effort` - small, medium, large\n- `category` - feature, optimization, fix, docs\n- `completed` - boolean\n- `related_milestone_id` - FK to milestone\n\n#### Example: Real Meta-Development\n\nChronicle used itself to build this feature:\n\n```bash\n# Created milestone #1\nchronicle milestone \"Add project tracking to Chronicle\" \\\n  --type feature --priority 1 --tags \"phase-5,meta,dogfooding\"\n\n# Broke down work\nchronicle next-step \"Design database schema\" --priority 1 --effort medium --milestone 1\nchronicle next-step \"Add CLI commands\" --priority 1 --effort large --milestone 1\nchronicle next-step \"Add MCP tools\" --priority 1 --effort medium --milestone 1\nchronicle next-step \"Create Chronicle Skills\" --priority 2 --effort medium --milestone 1\nchronicle next-step \"Write tests\" --priority 2 --effort small --milestone 1\n\n# Marked in progress\nchronicle milestone-status 1 in_progress\n\n# As work completed\nchronicle next-step-complete 1  # Schema done\nchronicle next-step-complete 2  # CLI done\nchronicle next-step-complete 3  # MCP tools done\nchronicle next-step-complete 4  # Skills done\nchronicle next-step-complete 5  # Tests done (25 passing!)\n\n# Finished!\nchronicle milestone-complete 1\n\n# Result\nchronicle roadmap\n# âœ… Completed (last 7 days)\n#   â€¢ Add project tracking to Chronicle (Oct 22)\n# ğŸ“Š Milestones: 1/1 completed | Next Steps: 5/5 done\n```\n\n**Chronicle now uses Chronicle to build Chronicle!** ğŸ¯\n\n---\n\n### ğŸ”® Future Phases\n- [ ] Next.js web dashboard with roadmap visualization\n- [ ] Timeline UI showing milestones + sessions + commits\n- [ ] `chronicle export obsidian` - Batch export with milestone linking\n- [ ] Blog post generator from weekly summaries\n- [ ] Auto-generate DEVELOPMENT_HISTORY.md from milestones\n- [ ] Team features (shared Chronicle databases)\n- [ ] VS Code extension\n- [ ] GitHub Actions integration for PR descriptions\n\n---\n\n## ğŸ—ï¸ Architecture\n\n### Local-First Design\n\nChronicle is designed to be **private and fast**:\n- âœ… All data stored in local SQLite database\n- âœ… No cloud sync required (optional in future)\n- âœ… Works offline\n- âœ… Full control over your data\n\n### Automatic Summarization\n\nSessions are recorded immediately, summaries are generated automatically when you view them:\n\n```\nSession Start\n    â†“\nRecord full transcript â†’ Save to DB (fast!)\n    â†“\nOn first view â†’ Generate summary with Gemini\n    â†“\nCache summary for future views\n```\n\n**Benefits:**\n- Fast session exit (no waiting for summarization)\n- Automatic summarization when you view sessions\n- Can work offline (view raw transcripts)\n\n---\n\n## ğŸ¤ Contributing\n\nChronicle is open source! Contributions welcome.\n\n**Ideas for contributions:**\n- Add support for more AI CLIs (Cursor, GitHub Copilot, Windsurf, etc.)\n- Build the `chronicle export obsidian` command\n- Create the Next.js dashboard (Phase 5)\n- Improve test coverage (especially MCP server tests)\n- Add MCP resources (expose session transcripts as MCP resources)\n- Build prompt templates for common Chronicle queries\n\n---\n\n## ğŸ“ License\n\nMIT License - see [LICENSE](LICENSE)\n\n---\n\n## ğŸ™ Acknowledgments\n\n**Built with:**\n- [Claude Code](https://claude.com/claude-code) - AI coding assistant (and tracked by Chronicle itself! ğŸ¯)\n- [Google Gemini](https://ai.google.dev/) - AI summarization\n- [FastMCP](https://gofastmcp.com/) - MCP server framework\n- [Model Context Protocol](https://modelcontextprotocol.io/) - AI tool integration standard\n- Python 3.11+ - Core logic\n- SQLite - Local storage\n- Click - CLI framework\n- Rich - Terminal formatting\n- GitPython - Git integration\n- SQLAlchemy - ORM\n\n---\n\n## ğŸ“š Documentation\n\n- **[AGENTS.md](AGENTS.md)** - Chronicle Advocate & TDD Advocate agents (cross-platform)\n- **[MCP_SERVER.md](MCP_SERVER.md)** - Chronicle MCP server guide (setup, tools, examples)\n- **[CLAUDE.md](CLAUDE.md)** - Development context for AI assistants\n- [Project Specification](AI_SESSION_RECORDER_SPEC.md) - Full specification and roadmap\n- [Changelog](CHANGELOG.md) - Version history\n- [Chronicle Skills](chronicle-skills/README.md) - Claude Skills documentation\n- [Example Context](example/CLAUDE.md) - Example from Crooked Finger project\n\n---\n\n**Chronicle: Never lose context again.** ğŸ¯\n\n*Track your AI-assisted development journey, compare approaches, and build institutional knowledge across all your AI coding assistants.*\n",
        "chronicle-skills/README.md": "# Chronicle Skills for Claude\n\nThis directory contains [Claude Skills](https://support.claude.com/en/articles/12512176-what-are-skills) that teach Claude how to work effectively with Chronicle - a local-first development session recorder.\n\n## Available Skills\n\n### âš¡ chronicle-assistant-guide\n**Purpose:** Universal AI assistant directives for using Chronicle across ALL projects\n\n**LOAD THIS FIRST!** Provides:\n- Pre-flight checklist (search first, use MCP, check roadmap)\n- Real examples of time saved by searching first (2,700x ROI!)\n- MCP tool reference\n- Best practices and common workflows\n\n**Use when:** Always! This skill should be loaded in every Chronicle-enabled project.\n\n**Key benefit:** Project-agnostic - works across all repos with Chronicle MCP configured. No need to duplicate directives in each project's CLAUDE.md.\n\n### ğŸ“ chronicle-session-documenter\n**Purpose:** Document development sessions to Obsidian vault\n\nAutomatically creates structured Obsidian notes from Chronicle sessions, including:\n- AI-generated summaries\n- Metadata (date, duration, repo, tags)\n- Wikilinks to related sessions and commits\n- Organized in `Chronicle/Sessions/` directory\n\n**Use when:** Completing a session and want to build a searchable knowledge base.\n\n### ğŸ” chronicle-context-retriever\n**Purpose:** Search and retrieve context from past work\n\nSearches Chronicle's database to find:\n- Past approaches to similar problems\n- Previous decisions and rationale\n- Blockers encountered and solutions\n- Related sessions by topic, time, or repository\n\n**Use when:** Need context before starting work or want to recall past decisions.\n\n**Note:** Works with MCP (fast structured queries) or CLI commands (portable).\n\n### ğŸ”„ chronicle-workflow\n**Purpose:** Complete Chronicle workflow guidance\n\nEnd-to-end workflow for:\n- Starting Chronicle-tracked sessions\n- Best practices during development\n- Post-session summarization and documentation\n- Multi-project tracking\n- Integration with Obsidian knowledge base\n\n**Use when:** Starting a new session or want comprehensive project tracking.\n\n### ğŸ¯ chronicle-project-tracker\n**Purpose:** Manage project development with database-tracked milestones and roadmap\n\nUse Chronicle's built-in project tracking to:\n- Plan features with milestones\n- Break down work into next steps\n- Link sessions to milestones automatically\n- View project roadmap and progress\n- Generate development reports\n- Eliminate manual documentation updates\n\n**Use when:** Planning features, tracking progress, viewing roadmap, or managing meta-development.\n\n### ğŸŒ chronicle-remote-summarizer\n**Purpose:** Automate cross-system summarization workflow\n\nExport sessions from remote systems (like FreeBSD dev machines) and import/summarize on your local machine with Gemini API. Supports:\n- One-line SSH pipe workflow for seamless summarization\n- Manual 3-step workflow for unreliable connections\n- Auto-cleanup of temporary sessions (no pollution)\n- Batch processing multiple sessions\n\n**Use when:** You have Chronicle sessions on a remote system without Gemini API access and need to summarize them locally.\n\n**Common scenario:** FreeBSD development server (no Gemini API) â†’ macOS laptop (has API key)\n\n## Installation\n\n### Option 1: Local Directory (Recommended for Development)\n\n1. Clone this repository or copy the `chronicle-skills/` directory\n2. In Claude Code, load a skill:\n   ```\n   /skill add /path/to/chronicle/chronicle-skills/chronicle-workflow\n   ```\n\n### Option 2: Individual Skills\n\n**Recommended: Load the assistant guide first**\n```\n/skill add /path/to/chronicle/chronicle-skills/chronicle-assistant-guide\n```\n\nThen load specific skills as needed:\n```\n/skill add /path/to/chronicle/chronicle-skills/chronicle-session-documenter\n/skill add /path/to/chronicle/chronicle-skills/chronicle-context-retriever\n/skill add /path/to/chronicle/chronicle-skills/chronicle-workflow\n/skill add /path/to/chronicle/chronicle-skills/chronicle-project-tracker\n/skill add /path/to/chronicle/chronicle-skills/chronicle-remote-summarizer\n```\n\n## Portability\n\n**All Chronicle skills work with or without the MCP server!**\n\n- **With MCP (Preferred):** Fast, structured JSON queries directly from the database\n- **Without MCP (Portable):** CLI commands work everywhere Chronicle is installed\n\nThis means Chronicle skills work on:\n- âœ… Claude Code with MCP configured (optimal performance)\n- âœ… Minimal Chronicle installations (CLI-only)\n- âœ… Remote systems (FreeBSD, minimal environments)\n- âœ… Any platform where Python runs\n\nSkills automatically adapt by showing both MCP and CLI approaches with decision trees for choosing the best available tool.\n\n## Prerequisites\n\n### Required\n\n1. **Chronicle installed:**\n   ```bash\n   pip install -e .  # From chronicle repo root\n   ```\n\n2. **Gemini API Key** (for AI summarization):\n   ```bash\n   chronicle config ai.gemini_api_key YOUR_KEY\n   ```\n\n### Optional (Recommended for Best Performance)\n\n3. **Chronicle MCP Server configured** (for faster context retrieval & project tracking):\n   - Project-local config at `.mcp.json` in your repo:\n   ```json\n   {\n     \"mcpServers\": {\n       \"chronicle\": {\n         \"command\": \"python3\",\n         \"args\": [\"-m\", \"backend.mcp.server\"]\n       }\n     }\n   }\n   ```\n   - Or global config at `~/.mcp.json` for all projects\n   - Restart Claude Code after adding MCP config\n   - **Note:** Skills work without MCP, just slower (~100ms vs ~10ms queries)\n\n### Optional\n\n4. **Obsidian MCP Server** (for session documenter only):\n   - Global config at `~/.mcp.json`:\n   ```json\n   {\n     \"mcpServers\": {\n       \"obsidian\": {\n         \"command\": \"npx\",\n         \"args\": [\n           \"@mauricio.wolff/mcp-obsidian@latest\",\n           \"/path/to/your/obsidian/vault\"\n         ]\n       }\n     }\n   }\n   ```\n   - Only needed if you want to document sessions to Obsidian vault\n\n5. **Git repository** (for commit tracking)\n6. **Obsidian vault** (for knowledge base features with session documenter)\n\n## Usage Examples\n\n### Example 1: Document a Completed Session\n\n```\nUser: \"Document session 15 to my Obsidian vault\"\n\nClaude: [Loads chronicle-session-documenter skill]\n- Queries Chronicle database for session 15\n- Retrieves AI summary if available\n- Creates structured note at Chronicle/Sessions/Session-15.md\n- Includes metadata, summary, files modified, and wikilinks\n```\n\n### Example 2: Retrieve Context Before Starting Work\n\n```\nUser: \"How did I implement authentication last time?\"\n\nClaude: [Loads chronicle-context-retriever skill]\n- Searches Chronicle database for \"authentication\" sessions (fast!)\n- Gets full summaries for relevant sessions\n- Extracts implementation approach and decisions\n- Presents summary with session IDs for reference\n```\n\n### Example 3: Start a New Tracked Session\n\n```\nUser: \"I'm starting work on the API refactor\"\n\nClaude: [Loads chronicle-workflow skill]\n- Checks if current session is tracked (likely not)\n- Guides: \"Exit and run: chronicle start claude\"\n- Explains workflow and best practices\n- Reminds about commit linking and documentation\n```\n\n## Skill Design Philosophy\n\nThese skills follow Chronicle's core principles:\n\n1. **Local-First** - All data stays on your machine\n2. **Non-Intrusive** - Work naturally, Chronicle tracks passively\n3. **Context-Aware** - Understand multi-project development\n4. **Knowledge Building** - Create searchable development history\n5. **AI-Assisted** - Automatic summarization and context retrieval\n\n## How Skills Work\n\nEach skill is a directory containing a `SKILL.md` file with:\n- **YAML Frontmatter** - Name and description\n- **Markdown Instructions** - What Claude should do when skill is active\n- **Examples & Guidelines** - Patterns and best practices\n\nClaude loads skills dynamically when their description matches the current task.\n\n## Contributing\n\nWant to improve these skills?\n\n1. Edit the `SKILL.md` file in the relevant skill directory\n2. Test with Claude Code: `/skill reload`\n3. Submit a PR with your improvements\n\n## Learn More\n\n- [Chronicle Documentation](../CLAUDE.md)\n- [What are Claude Skills?](https://support.claude.com/en/articles/12512176-what-are-skills)\n- [Creating Custom Skills](https://support.claude.com/en/articles/12512198-creating-custom-skills)\n- [Chronicle + Obsidian Integration Guide](../CLAUDE.md#-current-work-phase-4---obsidian-integration)\n\n## License\n\nApache 2.0 (same as Chronicle project)\n",
        "chronicle-skills/chronicle-assistant-guide/SKILL.md": "---\nname: chronicle-assistant-guide\ndescription: Project-agnostic guidance for AI assistants using Chronicle. Provides search-first directives, best practices, and workflow patterns across ALL Chronicle-tracked projects. Works with or without MCP server.\n---\n\n# Chronicle Assistant Guide\n\n> **Purpose**: Universal directives for AI assistants using Chronicle\n> **Scope**: Works across ALL projects (with MCP server OR CLI-only)\n> **Priority**: Load this FIRST when Chronicle is available\n\n---\n\n## Auto-Activation\n\n> **This skill auto-activates!** (Milestone #13)\n>\n> Prompts like \"how do I use chronicle?\" automatically trigger this skill. Lower priority than other skills.\n>\n> **Trigger patterns:** how to use chronicle, chronicle help, chronicle guide\n> **See:** `docs/HOOKS.md` for full details\n\n---\n\n## âš¡ CRITICAL: Pre-Flight Checklist\n\n**Before starting ANY Chronicle-related task, run through this checklist:**\n\n1. âœ… **SEARCH FIRST**: Search Chronicle's history\n   - **With MCP**: `mcp__chronicle__search_sessions(query=\"relevant keywords\", limit=5)`\n   - **Without MCP**: `chronicle search \"relevant keywords\" --limit 5`\n   - Has this been done before?\n   - What context exists about this feature/issue?\n   - What approaches failed or succeeded?\n\n2. âœ… **Check Skills**: Is there a Chronicle skill for this task?\n   - `chronicle-workflow` - Session workflow guidance\n   - `chronicle-session-documenter` - Document to Obsidian\n   - `chronicle-context-retriever` - Search past work\n   - `chronicle-project-tracker` - Roadmap and milestones\n\n3. âœ… **Prefer MCP over CLI**: Use best available tool\n   - **MCP available?** â†’ Fast (<10ms), structured JSON, no subprocess overhead\n   - **CLI only?** â†’ Still works, slightly slower (~100ms), parse formatted output\n   - Both provide the same data, choose based on environment\n\n4. âœ… **Check roadmap**: View current milestones and next steps\n   - **With MCP**: `mcp__chronicle__get_roadmap(days=7)`\n   - **Without MCP**: `chronicle roadmap --days 7`\n   - Is this already tracked as a milestone?\n   - Are there related next steps?\n\n**Why this matters:** Chronicle dogfoods itself. Every mistake we make is recorded. Learn from history!\n\n---\n\n## ğŸ¯ Core Directives\n\n### 1. ALWAYS Search Chronicle Before Implementing\n\n**The Rule (use whichever is available):**\n\n**Option 1: MCP (if available)**\n```python\n# Before implementing ANY feature:\nmcp__chronicle__search_sessions(query=\"feature name\", limit=5)\n\n# Before debugging:\nmcp__chronicle__search_sessions(query=\"error or symptom\", limit=5)\n\n# When user questions something:\nmcp__chronicle__search_sessions(query=\"topic keywords\", limit=5)\n```\n\n**Option 2: CLI (always works)**\n```bash\n# Before implementing ANY feature:\nchronicle search \"feature name\" --limit 5\n\n# Before debugging:\nchronicle search \"error or symptom\" --limit 5\n\n# When user questions something:\nchronicle search \"topic keywords\" --limit 5\n```\n\n**Real examples from Chronicle's own history:**\n\n**Example 1: Session 21 transcript cleaning confusion**\n```\nUser: \"I can't believe there's no cleaning to be done on session 21\"\nâŒ Without search: Spent time debugging, confused why 0% reduction\nâœ… With search: Would have found Session 13 implemented transcript cleaning\nâ†’ Result: Immediately understood cleaning happens at storage time\nâ†’ Time saved: 15+ minutes of debugging\n```\n\n**Example 2: Sessions 30 & 31 - Duplicate MCP optimization**\n```\nSession 30 (Oct 24): Fixed MCP response size by excluding summaries from get_sessions()\nSession 31 (Oct 24): SAME issue - MCP responses too large, same fix needed\n\nâŒ What happened: Session 31 didn't search for \"MCP response size\"\nâœ… What should have happened: Search finds Session 30's solution immediately\nâ†’ Result: Could have referenced Session 30's approach instead of rediscovering\nâ†’ Time saved: 10+ minutes of diagnosis and implementation\n```\n\n**Example 3: Skill documentation update (Session 32)**\n```\nTask: Update chronicle-session-documenter skill with MCP tool instructions\nâŒ What I did: Jumped straight to editing SKILL.md without searching\nâœ… What I should have done: Search \"skill documentation update\" first\nâ†’ Result: Might have found context about skill format standards\nâ†’ Lesson: Even when search finds nothing, the habit prevents future mistakes\n```\n\n**Cost Calculator:**\n```\nTime to search:        <1 second\nTime saved (average):  10-20 minutes per incident\nIncidents so far:      3+ documented cases\nTotal time wasted:     ~45+ minutes that could have been saved\nCost of skipping:      45 minutes / 1 second = 2,700x ROI on searching!\n```\n\n**Make it a reflex:** The 1-second search is ALWAYS worth it. No exceptions.\n\n---\n\n### 2. Prefer MCP Tools, Fall Back to CLI\n\n**Priority Order:**\n1. âœ… **Chronicle Skills** (best - handles complex workflows)\n2. âœ… **MCP tools** (fastest - if MCP server available)\n3. âœ… **CLI commands** (portable - works everywhere Chronicle is installed)\n\n**Why MCP is preferred when available:**\n- **Speed**: MCP queries database directly (<10ms), CLI spawns subprocess (~100ms)\n- **Programmatic**: Returns structured JSON, not formatted text\n- **Reliable**: No parsing of human-readable output\n- **Efficient**: No terminal formatting overhead\n\n**When to use CLI:**\n- MCP server not configured (e.g., minimal installations, FreeBSD, remote systems)\n- User explicitly requests CLI output\n- Testing CLI functionality\n\n**Examples:**\n\n**With MCP Available:**\n```python\n# Fast, structured responses\nroadmap = mcp__chronicle__get_roadmap(days=7)\nsessions = mcp__chronicle__search_sessions(query=\"storage\", limit=5)\nsummary = mcp__chronicle__get_session_summary(session_id=16)\n```\n\n**Without MCP (CLI Fallback):**\n```bash\n# Portable, works everywhere\nchronicle roadmap --days 7\nchronicle search \"storage\" --limit 5\nchronicle session 16\n```\n\n**Decision Pattern:**\n```\nNeed Chronicle data\nâ”œâ”€ MCP available? â†’ Use mcp__chronicle__<tool>()\nâ””â”€ MCP not available? â†’ Use chronicle <command>\n```\n\n---\n\n## ğŸ“š Available Tools (MCP + CLI)\n\n> **Note**: All operations below work with BOTH MCP tools and CLI commands. Use MCP for speed when available, CLI for portability.\n\n**Session & Commit Tracking:**\n\n**MCP Approach:**\n```python\n# List sessions (summaries excluded by default for performance)\nmcp__chronicle__get_sessions(limit=10, tool=\"claude-code\", repo_path=\"/path\", days=7)\nmcp__chronicle__get_sessions(limit=10, include_summaries=True)  # Optional: include summaries\n\n# Get single session details with full summary\nmcp__chronicle__get_session_summary(session_id=16)\n\n# Batch retrieve summaries for multiple sessions\nmcp__chronicle__get_sessions_summaries(session_ids=[15, 16, 17])\n\n# Search and other queries\nmcp__chronicle__search_sessions(query=\"MCP server\", limit=10)\nmcp__chronicle__get_commits(limit=20, repo_path=\"/path\", days=7)\nmcp__chronicle__search_commits(query=\"retry logic\", limit=20)\nmcp__chronicle__get_timeline(days=1, repo_path=\"/path\")\nmcp__chronicle__get_stats(days=7)\n```\n\n**CLI Equivalents:**\n```bash\n# List and view sessions\nchronicle sessions --limit 10 --tool claude-code\nchronicle session 16  # Get details with summary\n\n# Search\nchronicle search \"MCP server\" --limit 10\n\n# Commits and timeline\nchronicle show today --limit 20\nchronicle timeline today\n\n# Statistics\nchronicle stats --days 7\n```\n\n**Project Tracking:**\n\n**MCP Approach:**\n```python\nmcp__chronicle__get_milestones(status=\"in_progress\", milestone_type=\"feature\", limit=20)\nmcp__chronicle__get_milestone(milestone_id=1)\nmcp__chronicle__get_next_steps(completed=False, milestone_id=1, limit=20)\nmcp__chronicle__get_roadmap(days=7)\nmcp__chronicle__update_milestone_status(milestone_id=1, new_status=\"completed\")\nmcp__chronicle__complete_next_step(step_id=1)\n```\n\n**CLI Equivalents:**\n```bash\n# Milestones\nchronicle milestones --status in_progress\nchronicle milestone 1\n\n# Roadmap and next steps\nchronicle roadmap --days 7\nchronicle next-steps --pending\n\n# Updates\nchronicle milestone-status 1 completed\nchronicle complete-step 1\n```\n\n---\n\n## ğŸ”„ Typical Workflows\n\n### Starting a New Task\n\n**With MCP:**\n```python\n# 1. Search for related past work\nresults = mcp__chronicle__search_sessions(query=\"authentication\", limit=5)\n\n# 2. Check roadmap\nroadmap = mcp__chronicle__get_roadmap(days=7)\n\n# 3. If needed, check specific session\nif results:\n    session = mcp__chronicle__get_session_summary(session_id=results[0][\"id\"])\n\n# 4. Now implement with full context\n```\n\n**With CLI:**\n```bash\n# 1. Search for related past work\nchronicle search \"authentication\" --limit 5\n\n# 2. Check roadmap\nchronicle roadmap --days 7\n\n# 3. View specific session details\nchronicle session <id>\n\n# 4. Now implement with full context\n```\n\n### Debugging an Issue\n\n**With MCP:**\n```python\n# 1. Search for error message or symptom\nresults = mcp__chronicle__search_sessions(query=\"hang freeze stuck\", limit=5)\n\n# 2. Get full context from relevant session\nif results:\n    session = mcp__chronicle__get_session_summary(session_id=results[0][\"id\"])\n    # Read how it was solved before\n```\n\n**With CLI:**\n```bash\n# 1. Search for error message or symptom\nchronicle search \"hang freeze stuck\" --limit 5\n\n# 2. View relevant session\nchronicle session <id>\n# Read how it was solved before\n```\n\n### Understanding Project History\n\n**With MCP:**\n```python\n# Get overview\nstats = mcp__chronicle__get_stats(days=30)\ntimeline = mcp__chronicle__get_timeline(days=7)\n\n# Find specific work\nsessions = mcp__chronicle__search_sessions(query=\"optimization\", limit=10)\n```\n\n**With CLI:**\n```bash\n# Get overview\nchronicle stats --days 30\nchronicle timeline week\n\n# Find specific work\nchronicle search \"optimization\" --limit 10\n```\n\n---\n\n## ğŸš« Common Mistakes to Avoid\n\n**âŒ DON'T:**\n- Jump straight to implementing without searching\n- Ignore the CLI when MCP isn't available\n- Forget to check the roadmap\n- Ignore related sessions in search results\n\n**âœ… DO:**\n- Search first, implement second (MCP or CLI)\n- Use best available tool (MCP preferred, CLI fallback)\n- Check roadmap before creating new milestones\n- Read summaries of related sessions for context\n\n---\n\n## ğŸ“ Chronicle Quick Reference\n\n**Session Organization (Phase 6):**\n```bash\n# Organize sessions (use CLI for these)\nchronicle rename-session 32 \"Feature Implementation\"\nchronicle tag-session 32 optimization,phase-6\nchronicle link-session 32 --related-to 30,31\nchronicle auto-title 31  # AI-generated title\nchronicle graph --sessions 28-32  # Visualize relationships\n```\n\n**Current State:**\n- Database: `~/.ai-session/sessions.db` (SQLite)\n- Transcripts: `~/.ai-session/sessions/*.cleaned` (file-based)\n- Configuration: `~/.ai-session/config.yaml`\n- MCP Server: Provides 15+ tools for querying Chronicle\n\n**Storage:**\n- Summaries: Generated automatically in background after session ends\n- Titles: Can be set manually or AI-generated\n- Tags: JSON array for categorization\n- Relationships: parent_session_id, related_session_ids\n\n---\n\n## ğŸ’¡ Pro Tips\n\n1. **Always search before implementing** - Chronicle has 100+ hours of documented work\n2. **Use batch operations** - `get_sessions_summaries()` for multiple sessions at once\n3. **Filter aggressively** - Use repo_path, days, tool filters to narrow results\n4. **Check session organization** - Look for titles/tags to understand session purpose\n5. **Follow the graph** - Use `chronicle graph` to see session relationships\n6. **Trust the summaries** - They're generated by AI and usually accurate\n7. **Update roadmap** - Complete next steps and milestones as you work\n\n---\n\n## ğŸ”— Related Resources\n\n- **Project CLAUDE.md**: May have project-specific directives\n- **Chronicle Skills**: Use `chronicle-workflow`, `chronicle-context-retriever`, etc.\n- **MCP Documentation**: See `MCP_SERVER.md` in Chronicle repo\n\n---\n\n**Remember:** This skill applies to ALL projects using Chronicle. The directives here are universal best practices for AI assistants.\n",
        "chronicle-skills/chronicle-context-retriever/SKILL.md": "---\nname: chronicle-context-retriever\ndescription: Search and retrieve context from past development sessions using Chronicle data. Works with MCP (fast, structured) or CLI commands (portable). Use when user asks about previous work, wants to recall past decisions, needs to understand codebase history, or wants to avoid repeating past approaches.\n---\n\n# Chronicle Context Retriever\n\nThis skill helps you search and retrieve context from past development sessions using Chronicle's database. Works with both MCP server (fast, structured JSON) or CLI commands (portable, everywhere).\n\n## Auto-Activation\n\n> **This skill auto-activates!** (Milestone #13)\n>\n> Prompts like \"how did I implement auth?\" or \"what did I do yesterday?\" automatically trigger this skill. No manual loading needed!\n>\n> **Trigger patterns:** how did I, what did I do, find sessions about, search past work\n> **See:** `docs/HOOKS.md` for full details\n\n## When to Use This Skill\n\nUse this skill when:\n- User asks \"what did I do yesterday/last week?\"\n- Need to recall how a feature was implemented\n- Want to understand why a decision was made\n- Looking for similar past work or patterns\n- Avoiding repeating past mistakes or approaches\n- Need context before starting related work\n\n## How It Works\n\n**Option 1: With MCP (Preferred)**\n1. **Parse User Query** - Understand what context is needed\n2. **Search Chronicle** - `mcp__chronicle__search_sessions()` returns structured JSON (fast!)\n3. **Get Details** - `mcp__chronicle__get_session_summary()` for full summaries\n4. **Extract Information** - Parse JSON for decisions, blockers, solutions\n5. **Present Context** - Summarize findings with session IDs\n\n**Option 2: With CLI (Portable)**\n1. **Parse User Query** - Understand what context is needed\n2. **Search Chronicle** - `chronicle search \"keywords\"` returns formatted output\n3. **Get Details** - `chronicle session <id>` for full summaries\n4. **Extract Information** - Parse CLI output for key details\n5. **Present Context** - Summarize findings with session IDs\n\n**Decision Tree:**\n```\nSearch past work\nâ”œâ”€ MCP available? â†’ Use mcp__chronicle__search_sessions() for fast JSON\nâ””â”€ CLI only? â†’ Use `chronicle search` and parse output\n```\n\n## Search Strategies\n\n### â­ Two-Phase Search Workflow (RECOMMENDED)\n\nThe most effective way to search Chronicle is using a two-phase approach:\n\n**Phase 1: Broad Discovery**\n- Use OR search (implicit or explicit) to cast a wide net\n- Find the relevant area/timeframe\n- Get 5-10 potential sessions\n\n**Phase 2: Deep Dive**\n- Review session summaries to identify most relevant ones\n- Use precise AND searches to narrow down\n- Extract specific information needed\n\n**Example workflow:**\n```python\n# Phase 1: Broad OR search (multiple words = implicit OR)\nresults = mcp__chronicle__search_sessions(query=\"hooks json output\", limit=10)\n# â†’ Returns sessions 108, 109, 110, 111, 112 (any word matches)\n\n# Review the results - which sessions look most relevant?\n# Get full summaries for promising sessions\nsummaries = mcp__chronicle__get_sessions_summaries(session_ids=[110, 111, 112])\n\n# Phase 2: After reading summaries, dig deeper with AND\n# Now you know the exact terms to search for\nprecise_results = mcp__chronicle__search_sessions(\n    query=\"hookSpecificOutput AND decision/reason/systemMessage\",\n    limit=5\n)\n# â†’ Returns only sessions with BOTH terms (precise match)\n```\n\n**Why this works:**\n- âœ… Phase 1 finds the general area (prevents missing relevant sessions)\n- âœ… Phase 2 finds exact solutions (prevents information overload)\n- âœ… 2-3 searches total vs 10+ narrow searches that might miss context\n- âœ… ROI: 1-2 minutes to find exact solution vs 10-20 minutes reinventing\n\n### By Topic/Keywords\n\n**With MCP:**\n```python\n# Search session summaries and prompts for keywords\nmcp__chronicle__search_sessions(query=\"authentication\", limit=10)\nmcp__chronicle__search_sessions(query=\"database migration\", limit=5)\n```\n\n**With CLI:**\n```bash\n# Search sessions\nchronicle search \"authentication\" --limit 10\nchronicle search \"database migration\" --limit 5\n```\n\n### By Time Period\n\n**With MCP:**\n```python\n# Get sessions from specific time periods\nmcp__chronicle__get_sessions(days=7, limit=20)  # Last week\nmcp__chronicle__get_timeline(days=1)  # Yesterday with commits\n```\n\n**With CLI:**\n```bash\n# View recent sessions\nchronicle sessions --days 7 --limit 20\nchronicle timeline yesterday  # Yesterday with commits\n```\n\n### By Repository\n\n**With MCP:**\n```python\n# Filter sessions by repository path\nmcp__chronicle__get_sessions(repo_path=\"/Users/.../my-app\", limit=20)\n```\n\n**With CLI:**\n```bash\n# Sessions command supports repo filtering via config\nchronicle sessions --limit 20  # Defaults to current repo\n```\n\n### By Tool\n\n**With MCP:**\n```python\n# Filter by AI tool used\nmcp__chronicle__get_sessions(tool=\"claude-code\", limit=10)\nmcp__chronicle__get_sessions(tool=\"gemini-cli\", limit=10)\n```\n\n**With CLI:**\n```bash\n# Filter by tool\nchronicle sessions --tool claude-code --limit 10\nchronicle sessions --tool gemini-cli --limit 10\n```\n\n## Example Queries\n\n### \"How did I implement authentication last time?\"\n\n**With MCP:**\n```python\n# Search for authentication-related sessions\nsessions = mcp__chronicle__search_sessions(query=\"authentication\", limit=5)\n# Get full details of relevant sessions\nfor session in sessions:\n    details = mcp__chronicle__get_session_summary(session_id=session[\"id\"])\n# Extract implementation approach and decisions\n```\n\n**With CLI:**\n```bash\n# Search for authentication work\nchronicle search \"authentication\" --limit 5\n\n# View specific session details\nchronicle session <id>\n# Parse output for approach and decisions\n```\n\n### \"What was the blocker we hit with the database migration?\"\n\n**With MCP:**\n```python\n# Search for database migration issues\nsessions = mcp__chronicle__search_sessions(query=\"database migration blocker\", limit=5)\n# Find relevant session and extract problem + solution\n```\n\n**With CLI:**\n```bash\n# Search for migration blockers\nchronicle search \"database migration blocker\" --limit 5\n\n# View session with blocker\nchronicle session <id>\n```\n\n### \"Show me all work on the user-dashboard feature\"\n\n**With MCP:**\n```python\n# Search for user-dashboard work\nsessions = mcp__chronicle__search_sessions(query=\"user-dashboard\", limit=10)\n# List chronological sessions and summarize progress\n```\n\n**With CLI:**\n```bash\n# Search for dashboard work\nchronicle search \"user-dashboard\" --limit 10\n\n# View sessions chronologically\nchronicle sessions --limit 10\n```\n\n## Response Format\n\nWhen retrieving context, structure the response like:\n\n```markdown\n## Context from Past Sessions\n\n### Session {id} - {date}\n**What was done:** {summary}\n**Key decision:** {decision and rationale}\n**Outcome:** {result}\n**Related:** [[Session-{id}]]\n\n### Session {id} - {date}\n...\n\n## Relevant for Current Work\n- {How this context applies}\n- {What to keep in mind}\n- {What to avoid based on past experience}\n```\n\n## Tools to Use (MCP or CLI)\n\n### Chronicle Database Operations\n\n**MCP Approach (Preferred):**\n- `mcp__chronicle__search_sessions` - Search session summaries and prompts (fast JSON)\n- `mcp__chronicle__get_session_summary` - Get full summary for specific session\n- `mcp__chronicle__get_sessions` - List sessions with filters (tool, repo, days)\n- `mcp__chronicle__get_timeline` - Get sessions + commits for time period\n- `mcp__chronicle__search_commits` - Search git commit messages\n- `mcp__chronicle__get_commits` - List commits with filters\n\n**CLI Alternatives (Portable):**\n- `chronicle search \"query\"` - Search sessions by keywords\n- `chronicle session <id>` - Get full session summary\n- `chronicle sessions --limit 10` - List recent sessions\n- `chronicle timeline today` - View sessions + commits\n- `chronicle search \"commit message\"` - Search commits\n- `chronicle show today` - List recent commits\n\n### Obsidian Vault Operations (Optional)\n\n**Only if user wants vault notes:**\n- `mcp__obsidian__search_notes` - Find documented sessions in vault\n- `mcp__obsidian__read_note` - Read Obsidian note for session\n\n## Tips\n\n- **Chronicle database first!** - Faster than Obsidian vault search\n- **MCP when available** - Structured JSON is easier to parse than CLI output\n- **CLI works everywhere** - Use as reliable fallback when MCP not configured\n- Always search broadly first, then narrow down with specific session IDs\n- Check multiple related sessions for patterns\n- Look at both successful and blocked approaches\n- Note dates and repositories to understand context evolution\n- Combine timeline views to see commits + sessions together\n- When using CLI, parse output carefully for session IDs and summaries\n",
        "chronicle-skills/chronicle-project-tracker/SKILL.md": "---\nname: chronicle-project-tracker\ndescription: Manage Chronicle project development using database-tracked milestones, next steps, and roadmap visualization. Works with MCP tools (fast, structured) or CLI commands (portable). Use when planning features, tracking progress, viewing roadmap, or linking sessions to milestones. Eliminates manual DEVELOPMENT_HISTORY.md updates.\n---\n\n# Chronicle Project Tracker\n\nThis skill helps you manage project development meta-state using Chronicle's built-in project tracking features. Use MCP tools for programmatic access or CLI commands for portability.\n\n## Auto-Activation\n\n> **This skill auto-activates!** (Milestone #13)\n>\n> Prompts like \"what's next?\" or \"show roadmap\" automatically trigger this skill. No manual loading needed!\n>\n> **Trigger patterns:** what's next, show roadmap, create milestone, track progress\n> **See:** `docs/HOOKS.md` for full details\n\n## When to Use This Skill\n\nUse this skill when:\n- Planning new features or milestones\n- Tracking development progress\n- Viewing project roadmap\n- Linking sessions to milestones\n- Checking what's in progress or planned\n- Answering \"what should I work on next?\"\n- Generating progress reports\n\n## Available Tools (MCP + CLI)\n\n### MCP Tools (Programmatic Access)\n\n**Query Tools:**\n- `mcp__chronicle__get_milestones(status, milestone_type, limit)` - List milestones\n- `mcp__chronicle__get_milestone(milestone_id)` - Get milestone details\n- `mcp__chronicle__get_next_steps(completed, milestone_id, limit)` - List next steps\n- `mcp__chronicle__get_roadmap(days)` - View project roadmap\n\n**Update Tools:**\n- `mcp__chronicle__update_milestone_status(milestone_id, new_status)` - Update status\n- `mcp__chronicle__complete_next_step(step_id)` - Mark step complete\n\n### CLI Commands (Portable)\n\n**See \"CLI Commands Reference\" section below for full list.**\n\nKey commands:\n- `chronicle milestones` - List milestones\n- `chronicle roadmap` - View roadmap\n- `chronicle next-steps` - List next steps\n- `chronicle milestone-complete <id>` - Mark complete\n\n## Workflow: Planning a New Feature\n\nWhen user wants to add a new feature:\n\n1. **Check existing roadmap** to avoid duplicates:\n   ```python\n   roadmap = mcp__chronicle__get_roadmap(days=30)\n   # Review planned milestones\n   ```\n\n2. **Create milestone** via CLI (user runs this):\n   ```bash\n   chronicle milestone \"Feature name\" \\\n     --description \"What it does\" \\\n     --type feature \\\n     --priority 1 \\\n     --tags \"phase-5,api,backend\"\n   ```\n\n3. **Break down into next steps**:\n   ```bash\n   chronicle next-step \"Design API endpoints\" --priority 1 --effort medium --milestone <ID>\n   chronicle next-step \"Write tests\" --priority 2 --effort small --milestone <ID>\n   chronicle next-step \"Document in README\" --priority 3 --effort small --milestone <ID>\n   ```\n\n4. **Update status when starting work**:\n   ```python\n   mcp__chronicle__update_milestone_status(milestone_id=1, new_status=\"in_progress\")\n   ```\n\n## Workflow: Session Linking\n\nWhen completing a development session:\n\n1. **Get session ID** from recent sessions:\n   ```python\n   sessions = mcp__chronicle__get_sessions(limit=5)\n   latest_session_id = sessions[0]['id']\n   ```\n\n2. **Find active milestone**:\n   ```python\n   milestones = mcp__chronicle__get_milestones(status=\"in_progress\")\n   active_milestone_id = milestones[0]['id']\n   ```\n\n3. **Link them** (user runs this):\n   ```bash\n   chronicle link-session <session_id> --milestone <milestone_id>\n   ```\n\n4. **Complete next steps** as work progresses:\n   ```python\n   mcp__chronicle__complete_next_step(step_id=1)\n   ```\n\n## Workflow: Generating Progress Reports\n\nWhen user asks \"what did I accomplish this week?\":\n\n1. **Get roadmap**:\n   ```python\n   roadmap = mcp__chronicle__get_roadmap(days=7)\n   ```\n\n2. **Extract info**:\n   - `roadmap['recently_completed']` - Milestones completed in last 7 days\n   - `roadmap['in_progress']` - Current active work\n   - `roadmap['summary']` - Statistics\n\n3. **Get linked sessions** for each completed milestone:\n   ```python\n   for milestone in roadmap['recently_completed']:\n       milestone_details = mcp__chronicle__get_milestone(milestone['id'])\n       sessions = milestone_details['linked_sessions']\n       # Summarize work done\n   ```\n\n4. **Format report** showing:\n   - Completed milestones with linked sessions\n   - Git commits from those sessions\n   - Time spent (from session durations)\n   - Key files modified\n\n## Workflow: Viewing Roadmap\n\nWhen user asks \"what's next?\" or \"show me the roadmap\":\n\n```python\n# Get full roadmap\nroadmap = mcp__chronicle__get_roadmap(days=7)\n\n# Present in organized format:\nprint(\"ğŸš§ IN PROGRESS:\")\nfor m in roadmap['in_progress']:\n    print(f\"  - {m['title']} ({len(m['related_sessions'])} sessions)\")\n\nprint(\"\\nğŸ“‹ PLANNED (High Priority):\")\nfor m in roadmap['planned_high_priority']:\n    print(f\"  - [P{m['priority']}] {m['title']}\")\n\nprint(\"\\nğŸ”œ NEXT STEPS:\")\nfor step in roadmap['pending_next_steps']:\n    effort = f\" [{step['estimated_effort']}]\" if step['estimated_effort'] else \"\"\n    print(f\"  - [P{step['priority']}] {step['description']}{effort}\")\n\nprint(\"\\nâœ… RECENTLY COMPLETED:\")\nfor m in roadmap['recently_completed']:\n    print(f\"  - {m['title']} ({m['completed_at']})\")\n```\n\n## Workflow: Completing a Milestone\n\nWhen all work for a milestone is done:\n\n1. **Verify all next steps completed**:\n   ```python\n   steps = mcp__chronicle__get_next_steps(milestone_id=<ID>, completed=False)\n   if len(steps['next_steps']) == 0:\n       # All done!\n   ```\n\n2. **Mark milestone complete** (user runs):\n   ```bash\n   chronicle milestone-complete <ID>\n   ```\n\n3. **Auto-generates documentation** by querying:\n   ```python\n   milestone = mcp__chronicle__get_milestone(<ID>)\n   # Has all linked sessions, commits, duration\n   # Can auto-update DEVELOPMENT_HISTORY.md or export to Obsidian\n   ```\n\n## Querying Examples\n\n### \"What features are in progress?\"\n```python\nmilestones = mcp__chronicle__get_milestones(status=\"in_progress\")\nfor m in milestones['milestones']:\n    sessions = len(m['related_sessions'])\n    print(f\"{m['title']}: {sessions} sessions so far\")\n```\n\n### \"What's the highest priority work?\"\n```python\nroadmap = mcp__chronicle__get_roadmap()\ntop_planned = roadmap['planned_high_priority'][0]\nprint(f\"Next up: {top_planned['title']} (P{top_planned['priority']})\")\n```\n\n### \"Show me all optimization work\"\n```python\nmilestones = mcp__chronicle__get_milestones(milestone_type=\"optimization\")\n```\n\n### \"What work did session 16 contribute to?\"\n```python\n# Get all milestones\nall_milestones = mcp__chronicle__get_milestones(limit=100)\nfor m in all_milestones['milestones']:\n    if 16 in m['related_sessions']:\n        print(f\"Session 16 worked on: {m['title']}\")\n```\n\n## Statistics & Reports\n\n### Weekly Progress Report\n```python\nroadmap = mcp__chronicle__get_roadmap(days=7)\n\ncompleted_count = len(roadmap['recently_completed'])\nin_progress_count = len(roadmap['in_progress'])\n\nprint(f\"Week of {date}:\")\nprint(f\"âœ… {completed_count} milestones completed\")\nprint(f\"ğŸš§ {in_progress_count} milestones in progress\")\nprint(f\"â° {roadmap['summary']['total_next_steps'] - roadmap['summary']['completed_next_steps']} pending tasks\")\n```\n\n### Milestone Velocity\n```python\n# Get all completed milestones\ncompleted = mcp__chronicle__get_milestones(status=\"completed\", limit=100)\n\n# Calculate average time from creation to completion\ndurations = []\nfor m in completed['milestones']:\n    created = datetime.fromisoformat(m['created_at'])\n    completed_at = datetime.fromisoformat(m['completed_at'])\n    durations.append((completed_at - created).days)\n\navg_days = sum(durations) / len(durations)\nprint(f\"Average milestone completion time: {avg_days:.1f} days\")\n```\n\n## Auto-Documentation Pattern\n\nInstead of manually updating DEVELOPMENT_HISTORY.md:\n\n```python\n# Query completed milestones\ncompleted = mcp__chronicle__get_milestones(status=\"completed\")\n\n# For each milestone, get details\nfor milestone in completed['milestones']:\n    details = mcp__chronicle__get_milestone(milestone['id'])\n\n    # Extract:\n    # - Title, description\n    # - Related sessions (with summaries)\n    # - Related commits (with messages)\n    # - Duration (from session data)\n    # - Files modified (from commits)\n\n    # Generate markdown section\n    md = f\"### {details['title']}\\n\"\n    md += f\"{details['description']}\\n\\n\"\n    md += f\"**Status**: {details['status']}\\n\"\n    md += f\"**Sessions**: {len(details['linked_sessions'])}\\n\"\n    md += f\"**Commits**: {len(details['linked_commits'])}\\n\"\n\n    # Could write to DEVELOPMENT_HISTORY.md or Obsidian\n```\n\n## Integration with Other Skills\n\n### With chronicle-workflow\nAfter completing a session, use this skill to:\n- Link session to active milestone\n- Mark next steps as complete\n- Check roadmap for what to work on next\n\n### With chronicle-session-documenter\nWhen documenting a session to Obsidian:\n- Include milestone information\n- Add wikilinks to related milestones\n- Tag with milestone tags\n\n### With chronicle-context-retriever\nWhen searching past work:\n- Filter by milestone\n- Find all sessions for a feature\n- See historical progress on similar work\n\n## CLI Commands Reference\n\n**Milestones:**\n```bash\nchronicle milestone \"Title\" --description \"Desc\" --type feature --priority 1 --tags \"tag1,tag2\"\nchronicle milestones --status in_progress\nchronicle milestone-show <ID>\nchronicle milestone-status <ID> in_progress\nchronicle milestone-complete <ID>\n```\n\n**Next Steps:**\n```bash\nchronicle next-step \"Description\" --priority 1 --effort medium --category feature --milestone <ID>\nchronicle next-steps --milestone <ID>\nchronicle next-step-complete <ID>\n```\n\n**Linking:**\n```bash\nchronicle link-session <session_id> --milestone <ID>\n```\n\n**Roadmap:**\n```bash\nchronicle roadmap --days 7\n```\n\n## Database Tables\n\n### project_milestones\n- `id` - Unique ID\n- `title` - Milestone name\n- `description` - Details\n- `status` - planned, in_progress, completed, archived\n- `milestone_type` - feature, bugfix, optimization, documentation\n- `priority` - 1 (highest) to 5 (lowest)\n- `created_at` - Creation timestamp\n- `completed_at` - Completion timestamp\n- `related_sessions` - JSON array of session IDs\n- `related_commits` - JSON array of commit SHAs\n- `tags` - JSON array of tags\n\n### next_steps\n- `id` - Unique ID\n- `description` - What needs to be done\n- `priority` - 1 (highest) to 5 (lowest)\n- `estimated_effort` - small, medium, large\n- `category` - feature, optimization, fix, docs\n- `created_by` - session_16, manual, ai-suggestion\n- `completed` - 0 or 1\n- `created_at` - Creation timestamp\n- `completed_at` - Completion timestamp\n- `related_milestone_id` - FK to milestone\n\n## Pro Tips\n\n1. **Start milestones early** - Link sessions as you go\n2. **Use priority levels** - Helps roadmap show what's important\n3. **Tag milestones** - Makes filtering easier (e.g., \"phase-5\", \"api\", \"frontend\")\n4. **Break down features** - Create next steps for each milestone\n5. **Link sessions retroactively** - After work is done, link to milestone\n6. **Query before planning** - Check roadmap to avoid duplicate work\n7. **Use milestone types** - Distinguishes features from bugfixes\n8. **Complete next steps** - Helps track progress within a milestone\n9. **Auto-document** - Query completed milestones to generate reports\n10. **Review roadmap weekly** - Stay aligned on priorities\n\n## Benefits Over Manual Documentation\n\n**Before (manual DEVELOPMENT_HISTORY.md):**\n- Manual updates required\n- Easy to forget to document\n- Hard to query programmatically\n- No linking between sessions/commits/features\n- Becomes stale quickly\n\n**After (database-tracked milestones):**\n- Automatic tracking via MCP tools\n- Queryable (e.g., \"what's in progress?\")\n- Sessions auto-link to milestones\n- Commits auto-link to sessions\n- Real-time roadmap view\n- Can generate reports on-demand\n- Powers AI-driven development insights\n\n## Example: Meta-Development\n\nChronicle uses Chronicle to track its own development:\n\n```bash\n# Milestone #1: Add project tracking to Chronicle\nchronicle milestone \"Add project tracking to Chronicle\" \\\n  --description \"Database-tracked milestones and next steps\" \\\n  --type feature \\\n  --priority 1 \\\n  --tags \"phase-5,project-tracking,meta\"\n\n# Break down work\nchronicle next-step \"Design database schema\" --priority 1 --effort medium --milestone 1\nchronicle next-step \"Add CLI commands\" --priority 1 --effort large --milestone 1\nchronicle next-step \"Add MCP tools\" --priority 1 --effort medium --milestone 1\nchronicle next-step \"Create Chronicle Skills\" --priority 2 --effort medium --milestone 1\nchronicle next-step \"Write tests\" --priority 2 --effort small --milestone 1\nchronicle next-step \"Update documentation\" --priority 3 --effort small --milestone 1\n\n# Mark in progress\nchronicle milestone-status 1 in_progress\n\n# As work completes\nchronicle next-step-complete 1\nchronicle next-step-complete 2\n# ... etc\n\n# Link current session\nchronicle link-session 18 --milestone 1\n\n# When done\nchronicle milestone-complete 1\n\n# Generate report\nchronicle milestone-show 1\n```\n\nThis skill represents Chronicle's dogfooding: using Chronicle to build Chronicle!\n",
        "chronicle-skills/chronicle-remote-summarizer/SKILL.md": "---\nname: chronicle-remote-summarizer\ndescription: Automate cross-system summarization workflow for Chronicle sessions. Export sessions from remote systems (like FreeBSD) and import/summarize on local machine with Gemini API. Use when you have sessions on a system without Gemini API access and need to summarize them on another machine.\n---\n\n# Chronicle Remote Summarizer\n\nThis skill automates the workflow for summarizing Chronicle sessions across different systems (e.g., FreeBSD dev machine â†’ Mac with Gemini API).\n\n## Auto-Activation\n\n> **This skill auto-activates!** (Milestone #13)\n>\n> Prompts like \"summarize session on remote\" or \"import session from FreeBSD\" automatically trigger this skill!\n>\n> **Trigger patterns:** remote, freebsd, import session, summarize on remote\n> **See:** `docs/HOOKS.md` for full details\n\n## When to Use This Skill\n\nUse this skill when:\n- You have Chronicle sessions on a remote system without Gemini API configured\n- You want to summarize those sessions on your local machine (which has Gemini API)\n- You need to transfer the summary back to the original system\n- You're working across multiple development environments (FreeBSD, Linux, macOS)\n\n**Common scenario**: FreeBSD development server (no Gemini API) â†’ macOS laptop (has Gemini API key)\n\n## How It Works\n\nChronicle provides `import-and-summarize --quiet` which:\n1. Creates temporary session with negative ID (e.g., `-3`)\n2. Generates AI summary using Gemini\n3. **Auto-cleanup**: Deletes temporary session and files\n4. Outputs **clean JSON** to stdout (no status messages with `--quiet`)\n\n**No pollution between systems** - the remote session stays on the remote system, only the summary is transferred.\n\n## Recommended Workflow: One-Line Command\n\n**Prerequisites:**\n- SSH access from local machine to remote machine\n- Chronicle installed on both systems\n- Gemini API key configured on local machine (`chronicle config ai.gemini_api_key YOUR_KEY`)\n- **Optional**: Remote system configured in Chronicle config (automates hostname/path)\n\n**Step 1: Configure Remote System (One-Time Setup)**\n\n```bash\n# Configure FreeBSD remote system\nchronicle config remote_systems.freebsd.hostname \"chandlerhardy-dev.aws0.pla-net.cc\"\nchronicle config remote_systems.freebsd.chronicle_path \"/home/chandlerhardy/.local/bin/chronicle\"\n\n# Verify configuration\nchronicle config --list | grep freebsd\n```\n\n**Step 2: Use the Skill**\n\nWhen Claude uses this skill and finds remote system configuration, it will automatically construct the command:\n\n```bash\nssh chandlerhardy-dev.aws0.pla-net.cc \"/home/chandlerhardy/.local/bin/chronicle export-session 7\" | chronicle import-and-summarize --quiet 2>&1 | grep -A 999999 '^{$' | ssh chandlerhardy-dev.aws0.pla-net.cc \"/home/chandlerhardy/.local/bin/chronicle import-summary\"\n```\n\n**If no config found**, Claude will ask for the hostname and construct the command interactively:\n\n**Command (Manual):**\n```bash\nssh <remote-host> \"chronicle export-session <id>\" | chronicle import-and-summarize --quiet 2>&1 | grep -A 999999 '^{$' | ssh <remote-host> \"chronicle import-summary\"\n```\n\n**Example:**\n```bash\nssh freebsd \"chronicle export-session 7\" | chronicle import-and-summarize --quiet 2>&1 | grep -A 999999 '^{$' | ssh freebsd \"chronicle import-summary\"\n```\n\n**Note:** The `grep -A 999999 '^{$'` filters out Google library warnings that can leak through even with `--quiet` and `2>/dev/null`.\n\n**What this does:**\n1. **Remote â†’ Local**: Export session 7 as JSON\n2. **Local**: Import, summarize with Gemini, auto-cleanup temporary session\n3. **Local â†’ Remote**: Send summary JSON back\n4. **Remote**: Update session 7 with the summary\n\n**Why `--quiet` works:**\n- Suppresses ALL status messages from summarizer\n- Outputs ONLY clean JSON to stdout (essential for piping)\n- No need to manually extract JSON from verbose output\n- `2>/dev/null` suppresses Google library warnings (harmless)\n\n**Time:** Typically 30-60 seconds for large sessions (depends on transcript size)\n\n## Alternative: Manual 3-Step Workflow\n\nIf SSH pipes hang or you need to inspect intermediate files:\n\n### Step 1: Export session from remote\n```bash\nssh <remote-host> \"chronicle export-session <id>\" > /tmp/session_<id>.json\n```\n\n**Example:**\n```bash\nssh freebsd \"chronicle export-session 7\" > /tmp/session_7.json\n```\n\n### Step 2: Summarize locally (transient)\n```bash\ncat /tmp/session_<id>.json | chronicle import-and-summarize --quiet 2>/dev/null > /tmp/summary.json\n```\n\n**Example:**\n```bash\ncat /tmp/session_7.json | chronicle import-and-summarize --quiet 2>/dev/null > /tmp/summary.json\n```\n\n**What happens:**\n- Creates temporary session (negative ID like `-3`)\n- Generates summary with Gemini\n- **Auto-cleanup**: Deletes temporary session and transcript files\n- Outputs summary JSON to `/tmp/summary.json`\n\n### Step 3: Send summary back to remote\n```bash\ncat /tmp/summary.json | ssh <remote-host> \"chronicle import-summary\"\n```\n\n**Example:**\n```bash\ncat /tmp/summary.json | ssh freebsd \"chronicle import-summary\"\n```\n\n**Result:**\n- âœ… Summary stored in remote database linked to original session\n- âœ… Local system stays clean (temporary session auto-deleted)\n- âœ… No data pollution between systems\n\n## What Actually Happens (Under the Hood)\n\n**On `import-and-summarize --quiet`:**\n\n1. **Import**: Reads session JSON from stdin\n2. **Create Temporary Session**:\n   - Assigns negative ID (e.g., `-1`, `-2`, `-3`)\n   - Stores transcript in `~/.ai-session/sessions/session_-3.cleaned`\n   - Creates database entry with `is_session=True`\n3. **Summarize**:\n   - Runs `summarize_session_chunked()` with Gemini API\n   - Processes large transcripts in chunks (10,000 lines per chunk)\n   - Updates session with AI-generated summary\n4. **Output JSON**:\n   ```json\n   {\n     \"version\": \"1.0\",\n     \"original_id\": 7,\n     \"summary\": \"AI-generated summary...\",\n     \"summary_generated\": true,\n     \"keywords\": [\"feature\", \"implementation\", \"testing\"]\n   }\n   ```\n5. **Auto-Cleanup**:\n   - Deletes transcript file (`session_-3.cleaned`)\n   - Deletes database entry (temporary session)\n   - **Only the summary JSON remains** (piped to stdout)\n\n**On `import-summary` (remote side):**\n\n1. **Read JSON**: Reads summary from stdin\n2. **Find Session**: Looks up session by `original_id` (e.g., 7)\n3. **Update**: Sets `response_summary`, `summary_generated=True`, `keywords`\n4. **Done**: Session 7 now has the AI summary\n\n## Session Examples\n\n**Tested with:**\n- Session 1: 16.3 minutes, system test\n- Session 2: 66.7 minutes, large session\n- Session 4: 23KB JSON export\n\nAll sessions work perfectly with this workflow.\n\n## Troubleshooting\n\n### SSH Pipes Hang\n\n**Symptom:** Command hangs indefinitely\n\n**Solution:** Use manual 3-step workflow instead:\n```bash\n# Step 1: Export to file\nssh freebsd \"chronicle export-session 7\" > /tmp/session.json\n\n# Step 2: Process locally\ncat /tmp/session.json | chronicle import-and-summarize --quiet > /tmp/summary.json\n\n# Step 3: Send back\ncat /tmp/summary.json | ssh freebsd \"chronicle import-summary\"\n```\n\n### Gemini API Not Configured\n\n**Symptom:** `ImportError: google-generativeai package not installed`\n\n**Solution:** Configure Gemini API key on local machine:\n```bash\nchronicle config ai.gemini_api_key YOUR_API_KEY_HERE\n```\n\nGet free API key: https://ai.google.dev/\n\n### Session Not Found\n\n**Symptom:** `Session 7 not found`\n\n**Solution:** Check session exists on remote:\n```bash\nssh freebsd \"chronicle sessions --limit 20\"\n```\n\n### Summary Already Exists\n\n**Behavior:** `import-and-summarize` will **overwrite** existing summaries\n\n**Note:** This is by design - you can re-summarize sessions if needed.\n\n## Tips\n\n- **Use `--quiet` flag**: Essential for piping - suppresses status messages\n- **Suppress stderr**: Add `2>/dev/null` to hide Google library warnings\n- **Check SSH paths**: Remote Chronicle might be in `~/.local/bin/chronicle`\n- **Inspect files**: Use 3-step workflow to save intermediate JSON for debugging\n- **Large sessions**: 10K+ line transcripts are chunked automatically (no action needed)\n- **Network failures**: Use 3-step workflow for unreliable connections\n- **Batch processing**: You can script this to process multiple sessions\n\n## How Claude Should Use This Skill\n\n**When invoked, Claude should:**\n\n1. **Check for remote system config:**\n   ```bash\n   chronicle config --list | grep remote_systems\n   ```\n\n2. **If config exists** (e.g., `remote_systems.freebsd.hostname`):\n   - Read hostname: `chronicle config remote_systems.freebsd.hostname`\n   - Read chronicle path: `chronicle config remote_systems.freebsd.chronicle_path`\n   - Construct command automatically\n   - Announce: \"Found FreeBSD config, using: `<hostname>`\"\n\n3. **If no config exists:**\n   - Ask user: \"What's the hostname of your remote system?\"\n   - Ask: \"What's the path to chronicle on the remote? (default: chronicle)\"\n   - Optionally suggest: \"I can save this to config for future use\"\n   - Construct command with user-provided values\n\n4. **Run the command** and monitor output\n\n5. **Confirm success** or handle errors\n\n## Example Usage\n\n**User:** \"I have session 7 on my FreeBSD dev machine that needs summarization, but FreeBSD doesn't have Gemini API. Can you summarize it here on my Mac?\"\n\n**Assistant (with config):**\n1. Checks config: `chronicle config remote_systems.freebsd.hostname`\n2. Finds: `chandlerhardy-dev.aws0.pla-net.cc`\n3. Announces: \"Found FreeBSD config, using chandlerhardy-dev.aws0.pla-net.cc\"\n4. Runs the command:\n   ```bash\n   ssh chandlerhardy-dev.aws0.pla-net.cc \"/home/chandlerhardy/.local/bin/chronicle export-session 7\" | chronicle import-and-summarize --quiet 2>&1 | grep -A 999999 '^{$' | ssh chandlerhardy-dev.aws0.pla-net.cc \"/home/chandlerhardy/.local/bin/chronicle import-summary\"\n   ```\n5. Confirms: \"Session 7 summarized successfully and summary imported back to FreeBSD\"\n\n**Assistant (without config):**\n1. Checks config: `chronicle config --list | grep remote_systems`\n2. No FreeBSD config found\n3. Asks: \"What's your FreeBSD hostname?\"\n4. User provides: `chandlerhardy-dev.aws0.pla-net.cc`\n5. Asks: \"What's the path to chronicle on FreeBSD? (press Enter for default 'chronicle')\"\n6. User provides: `/home/chandlerhardy/.local/bin/chronicle`\n7. Suggests: \"I can save this to config for future use. Would you like me to?\"\n8. Runs the command with provided values\n9. If user agrees, saves config for next time\n\n**If one-liner hangs:**\n1. Falls back to 3-step workflow\n2. Exports to `/tmp/session_7.json`\n3. Processes locally â†’ `/tmp/summary.json`\n4. Imports summary back to remote\n5. Confirms success\n\n## Advanced Usage\n\n### Batch Summarize Multiple Sessions\n\n```bash\n# List unsummarized sessions on remote\nssh freebsd \"chronicle sessions --limit 50\" | grep \"No summary\"\n\n# For each session ID (7, 8, 9):\nfor id in 7 8 9; do\n  echo \"Summarizing session $id...\"\n  ssh freebsd \"chronicle export-session $id\" | \\\n    chronicle import-and-summarize --quiet 2>/dev/null | \\\n    ssh freebsd \"chronicle import-summary\"\ndone\n```\n\n### Inspect Summary Before Importing\n\n```bash\n# Export and summarize\nssh freebsd \"chronicle export-session 7\" | \\\n  chronicle import-and-summarize --quiet 2>/dev/null > /tmp/summary.json\n\n# Review summary\ncat /tmp/summary.json | jq '.summary'\n\n# If satisfied, import\ncat /tmp/summary.json | ssh freebsd \"chronicle import-summary\"\n```\n\n### Debug Verbose Output\n\nIf you need to see what's happening, remove `--quiet`:\n\n```bash\nssh freebsd \"chronicle export-session 7\" | chronicle import-and-summarize\n# Shows: \"Importing session...\", \"Summarizing...\", \"Cleaning up...\", then JSON\n```\n\n**Note:** Without `--quiet`, JSON is NOT at line 1, so it won't pipe cleanly to `import-summary`.\n\n## Related Commands\n\n- `chronicle export-session <id>` - Export session as JSON\n- `chronicle import-session` - Import session (permanent, gets new ID)\n- `chronicle import-and-summarize` - Import + summarize + auto-cleanup (transient)\n- `chronicle import-summary` - Update existing session with summary\n- `chronicle session <id>` - View session details and summary\n\n## See Also\n\n- **REMOTE_SUMMARIZE_WORKFLOW.md** - Full workflow documentation with examples\n- **tests/test_import_export.py** - 17 tests covering all import/export scenarios\n- **chronicle-session-documenter** - Document sessions to Obsidian vault after summarization\n",
        "chronicle-skills/chronicle-session-documenter/SKILL.md": "---\nname: chronicle-session-documenter\ndescription: Document AI-assisted development sessions to Obsidian vault using Chronicle data. Works with MCP (fastest) or CLI commands (portable). Use when completing a coding session, creating development logs, or maintaining a knowledge base of past work. Automatically creates structured notes with metadata, summaries, and wikilinks.\n---\n\n# Chronicle Session Documenter\n\nThis skill helps you document development sessions to your Obsidian vault using Chronicle's database. Works with both MCP server (fast, structured) or CLI commands (portable, everywhere).\n\n## Auto-Activation\n\n> **This skill auto-activates!** (Milestone #13)\n>\n> Prompts like \"document session 75\" or \"export to Obsidian\" automatically trigger a recommendation to use this skill. No need to manually load it!\n>\n> **Trigger patterns:** document session, export to obsidian, save to vault\n> **See:** `docs/HOOKS.md` for full details\n\n## When to Use This Skill\n\nUse this skill when:\n- A development session has just completed\n- User wants to document what was accomplished in a session\n- Creating a development log or journal entry\n- Building a searchable knowledge base of past work\n- Need to link related sessions, commits, or decisions\n\n## How It Works\n\n**Option 1: With MCP (Preferred)**\n1. **Query Chronicle** - `mcp__chronicle__get_session_summary(session_id)` â†’ Get structured JSON with full summary\n2. **Create Note** - `mcp__obsidian__write_note(...)` â†’ Write directly to Obsidian vault\n3. **Link Work** - Use session relationships from JSON to create wikilinks\n\n**Option 2: With CLI (Portable)**\n1. **Query Chronicle** - `chronicle session <id>` â†’ Get formatted session details and summary\n2. **Parse Output** - Extract summary, files, duration from CLI output\n3. **Create Note** - `mcp__obsidian__write_note(...)` OR manually create note file\n4. **Link Work** - Use parsed data to create wikilinks\n\n**Decision Tree:**\n```\nDocument session to Obsidian\nâ”œâ”€ MCP available? â†’ Use mcp__chronicle__get_session_summary() + mcp__obsidian__write_note()\nâ””â”€ CLI only? â†’ Use `chronicle session <id>`, parse output, write note\n```\n\n**Note**: Summaries are automatically generated in background when session ends (may still be processing for recent sessions)\n\n## Note Structure\n\nCreate notes in `Chronicle/Sessions/Session-{id}.md` with this format:\n\n```markdown\n---\nsession_id: {id}\ndate: \"{YYYY-MM-DD}\"\nstarted: \"{HH:MM AM/PM}\"\nduration_minutes: {minutes}\nai_tool: \"{tool}\"\nrepo: \"{repo_name}\"\ntags: [\"chronicle-session\", \"{ai_tool}\", \"{topics}\"]\n---\n\n# Session {id} - {Brief Title}\n\n**Duration:** {duration}\n**Repository:** [[{repo_name}]]\n**Tool:** {AI Tool Name}\n\n## Summary\n{AI-generated summary from Chronicle}\n\n## What Was Accomplished\n- {Key accomplishment 1}\n- {Key accomplishment 2}\n\n## Key Technical Decisions\n- {Decision 1 and rationale}\n\n## Files Created or Modified\n- `path/to/file.py` - {what changed}\n\n## Issues & Blockers\n- {Any problems encountered}\n\n## Related\n- Previous: [[Session-{prev_id}]]\n- Commits: [[Commit-{sha}]]\n- Repository: [[{repo_name}]]\n```\n\n## Workflow Examples\n\n### Option 1: With MCP (Fast, Structured)\n\n**After completing a session:**\n\n```python\n# Step 1: Get session data from Chronicle MCP\nsession_data = mcp__chronicle__get_session_summary(session_id=10)\n\n# Step 2: Extract key information\nsession_id = session_data[\"id\"]\ntimestamp = session_data[\"timestamp\"]  # \"2025-10-24T14:30:00\"\ntool = session_data[\"tool\"]  # \"claude-code\"\nduration = session_data[\"duration_minutes\"]  # 45\nrepo_path = session_data[\"repo_path\"]  # \"/Users/.../my-project\"\nsummary = session_data[\"summary\"]  # AI-generated summary (multi-paragraph)\n\n# Step 3: Format note content\nnote_content = f\"\"\"# Session {session_id} - {brief_title}\n\n**Duration:** {duration} minutes\n**Repository:** [[{repo_name}]]\n**Tool:** {tool_emoji} {tool_name}\n\n## Summary\n{summary}\n\n## What Was Accomplished\n- {extracted_accomplishments}\n\n## Key Technical Decisions\n- {extracted_decisions}\n\n## Files Created or Modified\n- {extracted_files}\n\n## Issues & Blockers\n- {extracted_blockers}\n\n## Related\n- Previous: [[Session-{prev_id}]]\n\"\"\"\n\n# Step 4: Prepare frontmatter\nfrontmatter = {\n    \"session_id\": session_id,\n    \"date\": \"2025-10-24\",\n    \"started\": \"14:30\",\n    \"duration_minutes\": duration,\n    \"ai_tool\": tool,\n    \"repo\": repo_name,\n    \"tags\": [\"chronicle-session\", tool, \"feature-work\"]\n}\n\n# Step 5: Write to Obsidian vault (if MCP available)\nmcp__obsidian__write_note(\n    path=\"Chronicle/Sessions/Session-10.md\",\n    content=note_content,\n    frontmatter=frontmatter,\n    mode=\"overwrite\"\n)\n```\n\n### Option 2: With CLI (Portable, No MCP Required)\n\n**After completing a session:**\n\n```bash\n# Step 1: Get session data from Chronicle CLI\nchronicle session 10 > /tmp/session_10.txt\n\n# Step 2: Parse the output to extract:\n# - Session ID, timestamp, tool, duration\n# - Repository path\n# - AI-generated summary\n# - Files mentioned\n# - Keywords/tags\n\n# Step 3: Create note content using parsed data\n# (Similar structure to MCP approach above)\n\n# Step 4: If Obsidian MCP available, use it to write note:\n# mcp__obsidian__write_note(...)\n#\n# OR manually create file in Obsidian vault:\n# Write to ~/Documents/Obsidian/Chronicle/Sessions/Session-10.md\n```\n\n**Note**: CLI approach requires parsing Chronicle's formatted output, which is less elegant but fully portable to any system with Chronicle installed.\n\n## Example Usage\n\n**User:** \"Can you document session 10 to my Obsidian vault?\"\n\n**Assistant (with MCP):**\n1. Calls `mcp__chronicle__get_session_summary(session_id=10)`\n2. Parses structured JSON to extract accomplishments, decisions, files, blockers\n3. Creates structured Markdown content with wikilinks\n4. Calls `mcp__obsidian__write_note(...)` to save to vault\n5. Confirms: \"Documented Session 10 to Chronicle/Sessions/Session-10.md\"\n\n**Assistant (without MCP):**\n1. Runs `chronicle session 10` to get formatted output\n2. Parses CLI output to extract summary and metadata\n3. Creates structured Markdown content with wikilinks\n4. Either uses `mcp__obsidian__write_note(...)` if available, or creates file manually\n5. Confirms: \"Documented Session 10 to Chronicle/Sessions/Session-10.md\"\n\n## Tools to Use (MCP or CLI)\n\n### Chronicle Database Operations\n\n**MCP Approach (Preferred):**\n- `mcp__chronicle__get_session_summary(session_id)` - Get full session details with AI summary\n- `mcp__chronicle__get_sessions(limit, days, tool, repo_path)` - List recent sessions to find session ID\n- `mcp__chronicle__search_sessions(query, limit)` - Search for sessions by keyword\n- `mcp__chronicle__get_commits(repo_path, days, limit)` - Get related commits for linking\n- `mcp__chronicle__get_sessions_summaries(session_ids)` - Batch get summaries (up to 20 at once)\n\n**CLI Alternatives:**\n- `chronicle session <id>` - Get session details with summary\n- `chronicle sessions --limit 10` - List recent sessions\n- `chronicle search \"keyword\" --limit 10` - Search sessions\n- `chronicle show today` - Get commits for linking\n\n### Obsidian Vault Operations\n\n**MCP Approach (Preferred):**\n- `mcp__obsidian__write_note(path, content, frontmatter, mode)` - Write note to vault\n- `mcp__obsidian__read_note(path)` - Check if note already exists (optional)\n- `mcp__obsidian__list_directory(path)` - List existing session notes (optional)\n\n**Manual Alternative (No MCP):**\n- Create file directly: `~/Documents/Obsidian/<vault>/Chronicle/Sessions/Session-<id>.md`\n- Write YAML frontmatter + markdown content manually\n\n## Tips\n\n- **Summary generation is automatic** - Summarization starts in background immediately when session ends (may take a few minutes for large sessions)\n- **Parse summaries intelligently** - AI summaries often have sections like \"Accomplishments:\", \"Technical Decisions:\", \"Issues/Blockers:\"\n- **Use wikilinks** - Link to `[[Session-{id}]]`, `[[{repo_name}]]`, `[[Commit-{short_sha}]]` for navigation\n- **Extract repo name** - Parse from `repo_path`: `/Users/.../my-app` â†’ `my-app`\n- **Handle missing data** - Some sessions may not have summaries yet (still processing in background), or durations (still running)\n- **Batch document** - Use `get_sessions()` to find recent sessions, then document each in loop\n- **Check existing notes** - Use `read_note()` to avoid overwriting manually edited notes (ask user first)\n- **Tool emojis** - Use ğŸ¯ for claude-code, âœ¨ for gemini-cli, ğŸ”® for qwen-cli\n- **Frontmatter tags** - Always include `[\"chronicle-session\", \"{tool}\", ...]` for filtering in Obsidian\n- **Date formatting** - Parse ISO timestamp `2025-10-24T14:30:00` â†’ date: \"2025-10-24\", started: \"14:30\"\n\n## Common Patterns\n\n### Document Today's Sessions\n\n**With MCP:**\n```python\n# Get today's sessions\nsessions = mcp__chronicle__get_sessions(days=1, limit=20)\n# Document each to vault\nfor session in sessions:\n    if session[\"is_session\"]:  # Only full sessions, not one-shots\n        document_to_vault(session[\"id\"])\n```\n\n**With CLI:**\n```bash\n# List today's sessions\nchronicle sessions --days 1 --limit 20\n\n# Manually document each one\nchronicle session 10  # View details\n# Parse and create Obsidian note\n```\n\n### Document Specific Session\n\n**With MCP:**\n```python\n# Direct documentation\nsession = mcp__chronicle__get_session_summary(session_id=10)\n# Create note from structured data\n```\n\n**With CLI:**\n```bash\n# Get session details\nchronicle session 10\n\n# Parse output and create note\n```\n\n### Find and Document Sessions About a Topic\n\n**With MCP:**\n```python\n# Search first\nresults = mcp__chronicle__search_sessions(query=\"authentication\", limit=5)\n# Document each match\nfor result in results:\n    document_to_vault(result[\"id\"])\n```\n\n**With CLI:**\n```bash\n# Search for sessions\nchronicle search \"authentication\" --limit 5\n\n# Document each match\nchronicle session <id>\n# Create note from parsed output\n```",
        "chronicle-skills/chronicle-workflow/SKILL.md": "---\nname: chronicle-workflow\ndescription: Complete workflow for tracking development work with Chronicle - session recording, git tracking, AI summarization, and Obsidian documentation. Works with CLI commands (portable) or MCP tools (faster). Use when starting a new development session, setting up project tracking, or when user wants comprehensive session management.\n---\n\n# Chronicle Workflow\n\nThis skill guides you through the complete Chronicle workflow for tracking and documenting development work. Primarily uses CLI commands for portability, with optional MCP tools for faster programmatic access.\n\n## Auto-Activation\n\n> **This skill auto-activates!** (Milestone #13)\n>\n> Prompts like \"start a new session\" or \"is this tracked?\" automatically trigger this skill. No manual loading needed!\n>\n> **Trigger patterns:** start session, is this tracked, chronicle workflow, setup\n> **See:** `docs/HOOKS.md` for full details\n\n## When to Use This Skill\n\nUse this skill when:\n- User is starting a new development session\n- Setting up Chronicle for the first time\n- Want to ensure all work is being tracked\n- Need guidance on Chronicle best practices\n- Building a comprehensive development knowledge base\n\n## Complete Workflow\n\n### 1. Session Start (If Not Already Tracking)\n\n**Check if in Chronicle session:**\n- Current session is likely NOT being tracked unless started with `chronicle start claude`\n- To track current work, user must exit and restart with Chronicle\n\n**Guide user:**\n```bash\n# Exit current session\nexit\n\n# Start new Chronicle-tracked session\nchronicle start claude\n\n# Or for other tools:\nchronicle start gemini\n```\n\n**Important:** Chronicle sessions must be started explicitly - they don't auto-track.\n\n### 2. During Development\n\n**Best Practices:**\n- Work naturally - Chronicle captures everything automatically\n- Make frequent git commits with descriptive messages\n- Chronicle links commits to sessions automatically (Â±30 min window)\n\n**Available Commands (don't interrupt work to run these):**\n```bash\nchronicle sessions              # List recent sessions\nchronicle show today           # See today's commits\nchronicle timeline today       # Combined view\n```\n\n### 3. Session End\n\n**Automatic on Exit:**\n- Full transcript captured to `~/.ai-session/sessions/session_N.log`\n- Metadata saved (duration, timestamp, repo)\n- Session record created in database\n\n**What happens:**\n```\nğŸ“Š Session #{id} complete! Duration: {minutes} minutes\nğŸ’¾ Full transcript saved\nâœ¨ Use 'chronicle session {id}' to view\n```\n\n### 4. Post-Session Documentation\n\n**Generate Summary (Automatic on first view):**\n```bash\n# View session and auto-generate summary\nchronicle session {id}\n\n# For very large sessions (>50K lines)\nchronicle summarize-chunked {id}\n```\n\n**Document to Obsidian:**\nUse the `chronicle-session-documenter` skill or manually:\n```\n\"Document session {id} to my Obsidian vault\"\n```\n\n### 5. Retrieval & Context\n\n**Find Past Work:**\nUse the `chronicle-context-retriever` skill:\n```\n\"How did I implement authentication last time?\"\n\"What was the blocker with database migrations?\"\n\"Show me all work on the API refactor\"\n```\n\n**Browse Sessions (CLI):**\n```bash\n# Filter by repo\nchronicle sessions --repo /path/to/project\n\n# View timeline\nchronicle timeline week\n\n# Search sessions\nchronicle search \"authentication\" --limit 5\n```\n\n**Browse Sessions (MCP - if available):**\n```python\n# Faster programmatic access\nsessions = mcp__chronicle__get_sessions(repo_path=\"/path/to/project\", limit=20)\nresults = mcp__chronicle__search_sessions(query=\"authentication\", limit=5)\n```\n\n## Workflow Patterns\n\n### Pattern 1: Quick Feature Work\n```\n1. chronicle start claude\n2. [Make changes, commit]\n3. exit\n4. [Summary auto-generates on next view]\n```\n\n### Pattern 2: Multi-Session Project\n```\n1. chronicle start claude (Day 1)\n2. [Work, commit]\n3. exit\n4. Document to Obsidian\n5. chronicle start claude (Day 2)\n6. \"What did I do yesterday?\" (retrieves context)\n7. [Continue work]\n```\n\n### Pattern 3: Research & Context\n```\n1. \"Show me all sessions about X\" (context retriever)\n2. Review past approaches and decisions\n3. chronicle start claude\n4. [Implement with informed approach]\n```\n\n## Multi-Project Tracking\n\n**Automatic Detection:**\n- Sessions detect working directory and git repo\n- Stored in database for filtering\n\n**Filter by Project:**\n```bash\nchronicle sessions --repo /path/to/project\nchronicle timeline today --repo /path/to/project\nchronicle summarize today --repo /path/to/project\n```\n\n## Key Features to Highlight\n\n### Chunked Summarization\n- Handles sessions of **unlimited size**\n- Tested with 83,000+ line sessions\n- Uses rolling summaries (10,000 lines/chunk)\n- No rate limit issues\n\n### Obsidian Integration\n- Full MCP server integration\n- Create structured session notes\n- Search past work\n- Build knowledge graph\n- Wikilinks between sessions/commits/repos\n\n### Local-First\n- Everything stored locally (`~/.ai-session/`)\n- SQLite database\n- No data leaves your machine (except AI summarization)\n\n## Common Questions\n\n**Q: \"Is this session being tracked?\"**\nA: Only if started with `chronicle start claude`. Must be explicit.\n\n**Q: \"Can I track a session retroactively?\"**\nA: No - must start with Chronicle from the beginning.\n\n**Q: \"How do I see what I did yesterday?\"**\nA: Use `chronicle timeline yesterday` or search Obsidian vault\n\n**Q: \"How do I link commits to sessions?\"**\nA: Automatic! Commits within Â±30 minutes of session are linked.\n\n## Database Location\n\nAll data stored at:\n```\n~/.ai-session/\nâ”œâ”€â”€ sessions.db              # Main database\nâ”œâ”€â”€ sessions/\nâ”‚   â”œâ”€â”€ session_N.log       # Transcripts\nâ”‚   â””â”€â”€ session_N.meta      # Metadata\nâ””â”€â”€ config.yaml             # Configuration\n```\n\n## Pro Tips\n\n1. **Start Chronicle early** - Can't retroactively track\n2. **Commit frequently** - Better session-commit linking\n3. **Document important sessions** - Build knowledge base in Obsidian\n4. **Search before building** - Use context retriever to avoid repeating work\n5. **Use tags in Obsidian** - Makes finding past work easier\n6. **Review summaries** - Helps remember key decisions\n\n## Integration with Other Skills\n\n- Use `chronicle-session-documenter` after completing sessions\n- Use `chronicle-context-retriever` when starting related work\n- Combine with git workflows for comprehensive tracking\n",
        "docs/legacy/README.md": "# Legacy Documentation\n\nThis directory contains deprecated documentation files that have been superseded by newer, more focused guides.\n\n## Archived Files\n\n### GEMINI.md (Deprecated)\n**Superseded by:** `CLAUDE.md` and `docs/GEMINI_MODELS.md`\n\n**Reason:** Original assistant guide for Gemini CLI. Most content merged into CLAUDE.md (which covers Claude Code). Model-specific details extracted to docs/GEMINI_MODELS.md for better organization.\n\n### AI_ASSISTANT_GUIDE.md (Deprecated)\n**Superseded by:** `CLAUDE.md` and universal `~/.claude/CLAUDE.md`\n\n**Reason:** Generic assistant guide that overlapped heavily with CLAUDE.md. Universal directives moved to user's global `~/.claude/CLAUDE.md`, project-specific content consolidated in `CLAUDE.md`.\n\n## Migration Timeline\n\n- **October 2025**: Progressive disclosure refactor (Milestone #14)\n- Legacy files moved to this directory for reference\n- All references updated to point to new documentation structure\n\n---\n\n**Note:** These files are kept for historical reference but should not be used for current development. See [CLAUDE.md](../../CLAUDE.md) for up-to-date development guidance.\n",
        "templates/hooks/post-tool-use.sh": "#!/bin/bash\n\n# Chronicle PostToolUse Hook\n# Tracks edited files and enforces skills over MCP tools\n\nset -euo pipefail\n\n# Read JSON input from stdin\ninput_json=$(cat)\n\n# Get script directory and log file\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\nLOG_FILE=\"$SCRIPT_DIR/../edit-log.txt\"\n\n# Get current timestamp\ntimestamp=$(date '+%Y-%m-%d %H:%M:%S')\n\n# Function to output skill recommendations\noutput_skill_recommendation() {\n    local message=\"$1\"\n    jq -n \\\n        --arg msg \"$message\" \\\n        '{\n            \"decision\": \"approve\",\n            \"reason\": $msg,\n            \"systemMessage\": $msg\n        }'\n}\n\n# Extract relevant information from the hook input\ntool_name=$(echo \"$input_json\" | jq -r '.tool_name // \"unknown\"')\n\nif [[ \"$tool_name\" != \"unknown\" ]]; then\n    # Log the tool usage with timestamp\n    echo \"[$timestamp] Tool: $tool_name\" >> \"$LOG_FILE\"\n\n    # Check for MCP tools that should have used skills instead\n    case \"$tool_name\" in\n        \"mcp__chronicle__search_sessions\"|\"mcp__chronicle__get_session_summary\"|\"mcp__chronicle__get_current_session\")\n            # These Chronicle MCP tools should use skills instead\n            recommendation=\"âš ï¸ SKILLS PREFERRED OVER MCP TOOLS\n\nYou used $tool_name - consider using skills instead:\n\nğŸ” For searching past sessions: Use chronicle-context-retriever skill\n   - Complete workflow guidance\n   - Better context extraction\n   - Structured output with examples\n\nğŸ“Š For project tracking: Use chronicle-project-tracker skill\n   - Database-tracked milestones\n   - Roadmap visualization\n\nğŸ”„ For Chronicle workflows: Use chronicle-workflow skill\n   - Session tracking guidance\n   - Best practices\n\nğŸ“ For documenting sessions: Use chronicle-session-documenter skill\n   - Obsidian integration\n   - Structured note creation\n\nğŸ’¡ Skills provide complete workflows, not just individual operations\nğŸ’¡ Skills work even when MCP server is unavailable (CLI fallback)\nğŸ’¡ Skills include best practices and error handling\n\nLoad skills with: Skill(command=\\\"skill-name\\\")\"\n            output_skill_recommendation \"$recommendation\"\n            ;;\n        \"Edit\"|\"Write\"|\"NotebookEdit\")\n            echo \"[$timestamp] File edit detected: $tool_name\" >> \"$LOG_FILE\"\n            ;;\n    esac\nfi\n\nexit 0",
        "templates/hooks/stop.sh": "#!/bin/bash\n\n# Chronicle Stop Hook\n# Post-response quality checks and reminders\n\nset -euo pipefail\n\n# Read JSON input from stdin\ninput_json=$(cat)\n\n# Function to output messages to Claude\noutput_message() {\n    local message=\"$1\"\n    jq -n \\\n        --arg msg \"$message\" \\\n        '{\n            \"decision\": \"approve\",\n            \"reason\": $msg,\n            \"systemMessage\": $msg\n        }'\n}\n\n# Build quality checklist\nchecklist=\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nğŸ“‹ QUALITY SELF-CHECK\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\"\n\n# Session tracking reminder - let chronicle-assistant-guide skill handle this\nchecklist+=\"â“ Session tracking: Use chronicle-assistant-guide skill\n   ğŸ’¡ The chronicle-assistant-guide skill provides complete workflow guidance\n\"\n\n# Add TDD reminder (always show)\nchecklist+=\"\nğŸ§ª Did you write tests first? (TDD red-green-refactor)\n\"\n\n# Add search reminder (always show)\nchecklist+=\"\nğŸ” Did you search Chronicle first?\n   ğŸ’¡ Use chronicle-context-retriever skill: 'How did I implement X last time?'\n   âš¡ 2,700x ROI - 1 second vs 20 minutes\n\"\n\nchecklist+=\"\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\"\n\n# Output the checklist to both stderr (to ensure visibility) and proper JSON format\necho \"$checklist\" >&2\noutput_message \"$checklist\"\n\nexit 0",
        "templates/hooks/user-prompt-submit.sh": "#!/bin/bash\n\n# Chronicle UserPromptSubmit Hook\n# Processes user prompts and injects skill recommendations and reminders\n\nset -euo pipefail\n\n# Read JSON input from stdin\ninput_json=$(cat)\nuser_prompt=$(echo \"$input_json\" | jq -r '.prompt // empty')\n\n# Flag to track if specific skill has been triggered\nskill_triggered=false\n\n# Array to track all checks performed (for debug output)\ndeclare -a checks_performed=()\n\n# Function to output JSON with system message and reasoning\noutput_context() {\n    local message=\"$1\"\n    local reasoning=\"$2\"\n    local trigger=\"$3\"\n\n    # Create detailed output with reasoning\n    local detailed_reason=\"ğŸ¤” HOOK REASONING:\nTrigger: $trigger\nAnalysis: $reasoning\nDecision: Inject skill recommendation\n\nğŸ“‹ Context: $message\"\n\n    # Set flag that a specific skill has been triggered\n    skill_triggered=true\n\n    jq -n \\\n        --arg msg \"$message\" \\\n        --arg reason \"$detailed_reason\" \\\n        '{\n            \"decision\": \"approve\",\n            \"reason\": $reason,\n            \"systemMessage\": $msg\n        }'\n}\n\n# Function to output debug reasoning when nothing triggered\noutput_debug_reasoning() {\n    local prompt_preview=\"${user_prompt:0:60}\"\n    if [[ ${#user_prompt} -gt 60 ]]; then\n        prompt_preview=\"${prompt_preview}...\"\n    fi\n\n    # Build checks summary with actual newlines (like stop.sh does)\n    local checks_summary=\"ğŸ” HOOK ANALYSIS (Debug Mode)\n\nPrompt: \\\"${prompt_preview}\\\"\n\nChecks performed:\n\"\n    for check in \"${checks_performed[@]}\"; do\n        checks_summary+=\"${check}\n\"\n    done\n\n    checks_summary+=\"\nDecision: Approve without injection (no triggers matched)\"\n\n    # Include in BOTH reason (for logging) and systemMessage (for display)\n    jq -n \\\n        --arg reason \"$checks_summary\" \\\n        --arg msg \"$checks_summary\" \\\n        '{\n            \"decision\": \"approve\",\n            \"reason\": $reason,\n            \"systemMessage\": $msg\n        }'\n}\n\n# Get script directory - note: when run from ~/.claude/hooks/, we need to find Chronicle project\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\n\n# Chronicle is a global tool - prioritize global configuration\nif [[ -f \"$HOME/.claude/config/skill-rules.json\" ]]; then\n    # Primary: Global config (installed by setup-hooks)\n    CONFIG_FILE=\"$HOME/.claude/config/skill-rules.json\"\nelif [[ -f \"/Users/chandlerhardy/repos/chronicle/templates/skill-rules.json\" ]]; then\n    # Fallback: Chronicle repo templates (for development)\n    CONFIG_FILE=\"/Users/chandlerhardy/repos/chronicle/templates/skill-rules.json\"\nelse\n    # Final fallback - search from current directory\n    PROJECT_ROOT=\"$(pwd)\"\n    while [[ \"$PROJECT_ROOT\" != \"/\" ]] && [[ ! -f \"$PROJECT_ROOT/templates/skill-rules.json\" ]]; do\n        PROJECT_ROOT=\"$(dirname \"$PROJECT_ROOT\")\"\n    done\n    CONFIG_FILE=\"$PROJECT_ROOT/templates/skill-rules.json\"\nfi\n\n# Check if skill rules config exists\nif [[ ! -f \"$CONFIG_FILE\" ]]; then\n    # Fallback to basic search reminder\n    if echo \"$user_prompt\" | grep -iqE \"(implement|add|create|build|fix|debug|write|can't believe|why (isn't|doesn't|won't|can't)|this should|I (want|need) to (build|add|implement|create)|let's (build|add|implement|create))\"; then\n        if ! echo \"$user_prompt\" | grep -iqE \"(read|view|show|explain|what is|search.*chronicle|mcp__chronicle)\"; then\n            output_context \"ğŸ” SEARCH CHRONICLE FIRST\n\nâš ï¸ Before implementing, use chronicle-context-retriever skill:\n'How did I implement X last time?' or 'What was the blocker with Y?'\n\nWHY: 2,700x ROI - 1 second vs 20 minutes\nProof: Sessions 21, 30, 31 show reinventing wastes time\" \\\n                \"User prompt contains implementation keywords but no search/reading keywords. Pattern matches development work that should first check Chronicle for prior implementations to avoid reinventing solutions.\" \\\n                \"Implementation keywords detected (no config file)\"\n            exit 0\n        fi\n    fi\n    exit 0\nfi\n\n# TDD skill triggers (highest priority - 95)\ntdd_phrases=\"(let'?s (implement|add|build|write|create|fix|debug|resolve)|yeah let'?s (implement|add|build|write|create|fix|debug|resolve)|(I want|we should|can you)( to)? (implement|add|build|write|create|fix|debug|resolve)|(write|add|create) (a |the |some )?(function|class|method|feature|code))\"\ntdd_excludes=\"(test|write.*test|TDD|red-green-refactor|what (does|is)|how (does|do)|show me|explain)\"\n\nif echo \"$user_prompt\" | grep -iqE \"$tdd_phrases\"; then\n    if ! echo \"$user_prompt\" | grep -iqE \"$tdd_excludes\"; then\n        checks_performed+=(\"âœ… ğŸ§ª TDD patterns - MATCHED (implement/build/write keywords found, no test exclusions)\")\n        output_context \"ğŸš¨ REQUIRED ACTION: TDD Skill Must Be Used\n\nYOU MUST use the test-driven-development skill before writing any implementation code.\n\nRequired steps:\n1. Write a failing test FIRST\n2. Watch it fail (RED)\n3. Write minimal code to pass (GREEN)\n4. Refactor if needed\n\nğŸ¯ MANDATORY: Use Skill(command=\\\"test-driven-development\\\")\n\nThis is not optional. No exceptions.\" \\\n        \"User prompt contains TDD trigger patterns (implement/build/write/create) but no test-related exclusions. This indicates new implementation work that violates TDD principles. According to TDD skill: 'NO PRODUCTION CODE WITHOUT A FAILING TEST FIRST' - this is a red flag requiring immediate intervention.\" \\\n        \"TDD violation detected\"\n        exit 0\n    else\n        checks_performed+=(\"âšª ğŸ§ª TDD patterns - no violation (keywords found but excluded: test-related context)\")\n    fi\nelse\n    checks_performed+=(\"âšª ğŸ§ª TDD patterns - no match (no implement/build/write keywords)\")\nfi\n\n# Other skill triggers with priorities\nif echo \"$user_prompt\" | grep -iqE \"(document session|export.*to obsidian|save.*to (vault|obsidian)|create (note|obsidian note) for)\"; then\n    checks_performed+=(\"âœ… ğŸ“ Obsidian export - MATCHED (document/export keywords found)\")\n    output_context \"ğŸš¨ REQUIRED ACTION: Use chronicle-session-documenter Skill\n\nYour prompt requires the chronicle-session-documenter skill.\n\nThis skill automates:\n- Fetching session summary from Chronicle\n- Creating structured Obsidian notes\n- Adding metadata, wikilinks, and tags\n\nğŸ¯ MANDATORY: Use Skill(command=\\\"chronicle-session-documenter\\\")\n\nYou must run this skill before proceeding. No exceptions.\" \\\n        \"User prompt contains keywords related to Obsidian export and session documentation. Pattern matches workflow for saving Chronicle sessions to knowledge base, which should be automated rather than done manually.\" \\\n        \"Obsidian export detected\"\n    exit 0\nelse\n    checks_performed+=(\"âšª ğŸ“ Obsidian export - no match (no document/export/vault keywords)\")\nfi\n\nif echo \"$user_prompt\" | grep -iqE \"(how did (I|we) (implement|fix|build|create|handle|solve)|what did (I|we) do (yesterday|last week|last month|before)|show me (all |past |previous )?work on|what was the blocker|when did (I|we) work on|find sessions? (about|on|for)|search (for |past )?sessions?)\"; then\n    checks_performed+=(\"âœ… ğŸ” Context retrieval - MATCHED (how did I/what did I/past work patterns found)\")\n    output_context \"ğŸš¨ REQUIRED ACTION: Use chronicle-context-retriever Skill\n\nYour prompt requires searching past development sessions.\n\nThis skill provides:\n- Search Chronicle database for relevant sessions\n- Retrieve detailed context from past work\n- Find similar problems and solutions\n- Recall previous decisions and rationale\n\nğŸ¯ MANDATORY: Use Skill(command=\\\"chronicle-context-retriever\\\")\n\nYou must run this skill before proceeding. No exceptions.\" \\\n        \"User prompt contains context retrieval patterns (how did I/what did I/show me past work). This indicates need for historical development context which should be retrieved via specialized skill rather than manual searching.\" \\\n        \"Context retrieval request\"\n    exit 0\nelse\n    checks_performed+=(\"âšª ğŸ” Context retrieval - no match (no 'how did I' or past work patterns)\")\nfi\n\nif echo \"$user_prompt\" | grep -iqE \"(what'?s next|show (me )?(the )?roadmap|what should (I|we) work on|plan (new |a )?feature|create (a )?milestone|mark.*(milestone|step).*complete|what'?s in progress|view (the )?milestones?|track progress)\"; then\n    checks_performed+=(\"âœ… ğŸ“Š Project tracking - MATCHED (roadmap/milestone/what's next keywords found)\")\n    output_context \"ğŸš¨ REQUIRED ACTION: Use chronicle-project-tracker Skill\n\nYour prompt requires project planning and tracking.\n\nThis skill manages:\n- Database-tracked milestones\n- Next steps and TODOs\n- Roadmap visualization\n- Progress reports\n- Session-to-milestone linking\n\nğŸ¯ MANDATORY: Use Skill(command=\\\"chronicle-project-tracker\\\")\n\nYou must run this skill before proceeding. No exceptions.\" \\\n        \"User prompt contains project management keywords (roadmap/milestone/what's next/progress). This indicates planning or tracking work that should use the specialized project tracking system rather than ad-hoc management.\" \\\n        \"Project tracking request\"\n    exit 0\nelse\n    checks_performed+=(\"âšª ğŸ“Š Project tracking - no match (no roadmap/milestone keywords)\")\nfi\n\n# Basic Chronicle Advocate search reminder (only if no specific skill triggered)\nif [[ \"$skill_triggered\" == \"false\" ]]; then\n    if echo \"$user_prompt\" | grep -iqE \"(implement|add|create|build|fix|debug)\"; then\n        if ! echo \"$user_prompt\" | grep -iqE \"(read|view|show|explain)\"; then\n            checks_performed+=(\"âœ… âš™ï¸ General implementation - MATCHED (implement/add/create keywords, no read/view exclusions)\")\n            output_context \"ğŸš¨ REQUIRED ACTION: Use chronicle-context-retriever Skill\n\nBefore implementing anything, you MUST search Chronicle for prior art.\n\nAsk questions like:\n'How did I implement X last time?' or 'What was the blocker with Y?'\n\nğŸ¯ MANDATORY: Use Skill(command=\\\"chronicle-context-retriever\\\")\n\nWHY: 2,700x ROI - 1 second vs 20 minutes\nProof: Sessions 21, 30, 31 show reinventing wastes time\n\nYou must run this skill before proceeding. No exceptions.\" \\\n                    \"General implementation keywords detected without specific skill matches. Default behavior: recommend Chronicle search to avoid reinventing solutions and leverage prior work.\" \\\n                    \"General implementation detected\"\n            exit 0\n        else\n            checks_performed+=(\"âšª âš™ï¸ General implementation - has exclusions (implementation keywords found but excluded: read/view/show/explain)\")\n        fi\n    else\n        checks_performed+=(\"âšª âš™ï¸ General implementation - no match (no implement/add/create keywords)\")\n    fi\nfi\n\n# No triggers matched - output debug reasoning\noutput_debug_reasoning\nexit 0"
      },
      "plugins": [
        {
          "name": "chronicle-workflow-skills",
          "description": "Complete Chronicle workflow skills including session documentation, context retrieval, and development tracking",
          "source": "./",
          "strict": false,
          "skills": [
            "./chronicle-skills/chronicle-workflow",
            "./chronicle-skills/chronicle-session-documenter",
            "./chronicle-skills/chronicle-context-retriever",
            "./chronicle-skills/chronicle-project-tracker",
            "./chronicle-skills/chronicle-remote-summarizer",
            "./chronicle-skills/chronicle-assistant-guide"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add ChandlerHardy/chronicle",
            "/plugin install chronicle-workflow-skills@chronicle-skills"
          ]
        }
      ]
    }
  ]
}