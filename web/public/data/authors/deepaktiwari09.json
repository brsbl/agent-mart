{
  "author": {
    "id": "deepaktiwari09",
    "display_name": "Deepak Kumar Tiwari",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/82175716?u=a7fec5396d28a2e41f1cf9f1188bdc95b3e44141&v=4",
    "url": "https://github.com/deepaktiwari09",
    "bio": "Lead Software Developer in Websenor Infotech",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 8,
      "total_skills": 1,
      "total_stars": 1,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "dt-workspace-marketplace",
      "version": null,
      "description": "AI-powered workflow documentation generator from SOW documents - generates comprehensive project docs with BDD features, API contracts, database schemas",
      "owner_info": {
        "name": "Deepak Tiwari",
        "email": "deepaktiwari3020@gmail.com"
      },
      "keywords": [],
      "repo_full_name": "deepaktiwari09/dt-workspace-plugin",
      "repo_url": "https://github.com/deepaktiwari09/dt-workspace-plugin",
      "repo_description": "AI-powered workflow documentation generator plugin for Claude Code - generates project docs from SOW files",
      "homepage": null,
      "signals": {
        "stars": 1,
        "forks": 0,
        "pushed_at": "2025-12-16T16:21:06Z",
        "created_at": "2025-12-16T16:18:21Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 635
        },
        {
          "path": ".claude-plugin/plugin.json",
          "type": "blob",
          "size": 333
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 3544
        },
        {
          "path": "agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "agents/doc-completer.md",
          "type": "blob",
          "size": 3060
        },
        {
          "path": "agents/sow-analyzer.md",
          "type": "blob",
          "size": 3132
        },
        {
          "path": "commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "commands/clean.md",
          "type": "blob",
          "size": 1824
        },
        {
          "path": "commands/diagram.md",
          "type": "blob",
          "size": 2600
        },
        {
          "path": "commands/export.md",
          "type": "blob",
          "size": 2342
        },
        {
          "path": "commands/init.md",
          "type": "blob",
          "size": 1527
        },
        {
          "path": "commands/populate.md",
          "type": "blob",
          "size": 2688
        },
        {
          "path": "commands/presets.md",
          "type": "blob",
          "size": 3439
        },
        {
          "path": "commands/scaffold.md",
          "type": "blob",
          "size": 3291
        },
        {
          "path": "commands/sync.md",
          "type": "blob",
          "size": 2304
        },
        {
          "path": "skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/workflow-generator",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/workflow-generator/SKILL.md",
          "type": "blob",
          "size": 5336
        },
        {
          "path": "skills/workflow-generator/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/workflow-generator/references/presets.md",
          "type": "blob",
          "size": 6541
        },
        {
          "path": "skills/workflow-generator/references/sow-format.md",
          "type": "blob",
          "size": 3662
        },
        {
          "path": "skills/workflow-generator/references/templates.md",
          "type": "blob",
          "size": 3763
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"dt-workspace-marketplace\",\n  \"owner\": {\n    \"name\": \"Deepak Tiwari\",\n    \"email\": \"deepaktiwari3020@gmail.com\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"dt-workspace\",\n      \"source\": \"./\",\n      \"description\": \"AI-powered workflow documentation generator from SOW documents - generates comprehensive project docs with BDD features, API contracts, database schemas\",\n      \"version\": \"1.0.0\",\n      \"category\": \"documentation\",\n      \"tags\": [\"sow\", \"documentation\", \"workflow\", \"bdd\", \"api\", \"scaffold\"],\n      \"author\": {\n        \"name\": \"Deepak Tiwari\",\n        \"email\": \"deepaktiwari3020@gmail.com\"\n      }\n    }\n  ]\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"dt-workspace\",\n  \"version\": \"1.0.0\",\n  \"description\": \"AI-powered workflow documentation generator from SOW documents - generates comprehensive project documentation with BDD features, API contracts, database schemas, and more\",\n  \"author\": {\n    \"name\": \"Deepak Tiwari\",\n    \"email\": \"deepaktiwari3020@gmail.com\"\n  }\n}\n",
        "README.md": "# DT-Workspace Plugin\n\nAI-powered workflow documentation generator for Claude Code. Generate comprehensive project documentation from Statement of Work (SOW) documents.\n\n## Features\n\n- **SOW Analysis**: Extract structured module definitions from requirements documents\n- **Multi-Preset Support**: 9 architecture presets (microservices, serverless, monolith, etc.)\n- **Complete Documentation**: API contracts, database schemas, BDD features, and more\n- **AI Completion**: Fill documentation placeholders with context-aware content\n- **ER Diagrams**: Generate entity-relationship diagrams in multiple formats\n\n## Installation\n\n### Option 1: Plugin Directory\n```bash\nclaude --plugin-dir /path/to/dt-workspace-plugin\n```\n\n### Option 2: Copy to Project\n```bash\ncp -r dt-workspace-plugin/.claude-plugin your-project/\n```\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `/dt-workspace:init` | Initialize project configuration |\n| `/dt-workspace:scaffold` | Generate documentation from SOW |\n| `/dt-workspace:populate` | Fill placeholders with AI content |\n| `/dt-workspace:export` | Export templates for customization |\n| `/dt-workspace:sync` | Rebuild config from filesystem |\n| `/dt-workspace:diagram` | Generate ER diagrams |\n| `/dt-workspace:clean` | Delete generated documentation |\n| `/dt-workspace:presets` | List available presets |\n\n## Quick Start\n\n1. **Initialize project**:\n   ```\n   /dt-workspace:init\n   ```\n\n2. **Create SOW file** (`sow.md`) with your requirements\n\n3. **Generate documentation**:\n   ```\n   /dt-workspace:scaffold\n   ```\n\n4. **Complete placeholders**:\n   ```\n   /dt-workspace:populate\n   ```\n\n## Available Presets\n\n| Preset | Architecture |\n|--------|--------------|\n| `microservices` | NestJS with Kafka, WebSocket, PostgreSQL |\n| `monolith` | Layered architecture, shared database |\n| `serverless` | AWS Lambda, API Gateway, DynamoDB |\n| `supabase` | Supabase with PostgreSQL, Auth, Storage |\n| `firebase` | Firebase/Firestore, Cloud Functions |\n| `nextjs-fullstack` | Next.js App Router, Server Components |\n| `graphql-federation` | Apollo Federation with subgraphs |\n| `kubernetes` | K8s deployments, Helm charts |\n| `event-sourcing` | CQRS with event store |\n\n## Generated Structure\n\n```\nworkflows/\n├── README.md                    # Project index\n├── <platform>/\n│   ├── timeline.md              # Development sequence\n│   └── <module>/\n│       ├── README.md            # Module overview\n│       ├── user-flows/          # User journeys\n│       ├── technical-specs.md   # Architecture\n│       ├── api-contracts.md     # API documentation\n│       ├── database-schema.md   # Data models\n│       ├── security-specs.md    # Security controls\n│       ├── error-handling.md    # Error codes\n│       └── features/            # BDD Gherkin files\n```\n\n## Configuration\n\nThe `.dt-workspace` config file:\n\n```json\n{\n  \"version\": \"1.0.0\",\n  \"projectName\": \"My Project\",\n  \"sowPath\": \"./sow.md\",\n  \"defaultPreset\": \"microservices\",\n  \"outputDirectory\": \"./workflows\",\n  \"generatedPaths\": {\n    \"platforms\": {}\n  }\n}\n```\n\n## Template Customization\n\nExport and customize templates:\n\n```\n/dt-workspace:export --preset microservices\n```\n\nTemplates saved to `.dt-templates/<preset>/` for editing.\n\n## Agents\n\n- **sow-analyzer**: Analyzes SOW documents and extracts modules\n- **doc-completer**: Fills documentation placeholders with detailed content\n\n## Author\n\nDeepak Tiwari <deepaktiwari3020@gmail.com>\n\n## License\n\nMIT\n",
        "agents/doc-completer.md": "---\nmodel: sonnet\ntools: [\"Read\", \"Write\", \"Glob\", \"Grep\"]\nwhenToUse: |\n  Use this agent to fill documentation placeholders with detailed, context-aware content.\n  <example>\n  Context: User has generated documentation with placeholders\n  user: 'Fill in the placeholders in my API contracts document'\n  assistant: 'I'll use the doc-completer agent to analyze your documentation and fill in the [To be documented] sections'\n  </example>\n  <example>\n  Context: User wants to complete specific documentation\n  user: 'Complete the database schema documentation for the user module'\n  assistant: 'Let me use the doc-completer agent to generate detailed database schema content'\n  </example>\n---\n\n# Documentation Completer Agent\n\nYou are an expert technical writer who fills documentation placeholders with detailed, production-ready content.\n\n## Your Task\n\nRead documentation files with placeholders like `[To be documented]` and replace them with comprehensive, context-appropriate content.\n\n## Process\n\n1. **Gather Context**:\n   - Read the SOW file for requirements\n   - Read module README for context\n   - Understand the preset/architecture being used\n   - Note related modules and dependencies\n\n2. **Identify Placeholders**:\n   - `[To be documented]`\n   - `[API endpoints to be documented]`\n   - `[Schema to be documented here]`\n   - Any `[text]` indicating incomplete content\n\n3. **Generate Content** based on document type:\n\n### API Contracts\n- REST endpoints with methods, paths, descriptions\n- Request/response schemas with types\n- Authentication requirements\n- Error responses with codes\n- Example requests/responses\n\n### Database Schema\n- Table definitions with all columns\n- Data types and constraints\n- Primary/foreign key relationships\n- Indexes for performance\n- Migration scripts\n\n### Technical Specs\n- Architecture overview with diagrams (Mermaid)\n- Service interactions and data flow\n- Technology stack justification\n- Scalability considerations\n- Performance requirements\n\n### User Flows\n- Step-by-step user journeys\n- Decision points and branches\n- Error handling paths\n- Success criteria\n- UI/UX considerations\n\n### Real-time Events\n- Event names and schemas\n- Kafka topic configurations\n- WebSocket event patterns\n- Event ordering and delivery guarantees\n\n### Security Specs\n- Authentication mechanisms\n- Authorization rules (RBAC/ABAC)\n- Data encryption (at rest/in transit)\n- Input validation\n- OWASP compliance\n\n### Error Handling\n- Error code taxonomy\n- HTTP status code mapping\n- User-friendly messages\n- Logging and monitoring\n- Recovery strategies\n\n## Output Guidelines\n\n- **Be specific** - Use realistic names, types, and values\n- **Be consistent** - Follow patterns established in existing docs\n- **Be complete** - Fill ALL placeholders, don't leave any\n- **Be practical** - Generate production-ready content\n- **Maintain format** - Preserve markdown structure and headings\n\n## After Completion\n\n1. Create backup of original file (`file.md.backup`)\n2. Write completed content to original file\n3. Report what was filled and any concerns\n",
        "agents/sow-analyzer.md": "---\nmodel: sonnet\ntools: [\"Read\", \"Write\", \"Glob\", \"Grep\"]\nwhenToUse: |\n  Use this agent to analyze Statement of Work (SOW) documents and extract structured module definitions.\n  <example>\n  Context: User has a SOW document and wants to understand its structure\n  user: 'Analyze my SOW file and extract the modules'\n  assistant: 'I'll use the sow-analyzer agent to parse your SOW document and extract module definitions'\n  </example>\n  <example>\n  Context: User wants to see what modules are in their requirements\n  user: 'What modules are defined in sow.md?'\n  assistant: 'Let me use the sow-analyzer agent to analyze your SOW and identify all modules'\n  </example>\n---\n\n# SOW Analyzer Agent\n\nYou are an expert at analyzing Statement of Work (SOW) documents and extracting structured module definitions for software projects.\n\n## Your Task\n\nAnalyze SOW markdown documents and extract comprehensive module definitions that can be used for documentation generation.\n\n## Analysis Process\n\n1. **Read the SOW document** thoroughly\n2. **Identify project metadata**:\n   - Project name\n   - Target platforms (web, mobile, admin, etc.)\n   - Overall scope and goals\n\n3. **Extract modules** - For each distinct module/feature area:\n   - Create kebab-case ID from name\n   - Determine which platform(s) it belongs to\n   - Write concise description (1-2 sentences)\n   - List all features within the module\n   - Identify technical components\n\n4. **Map technical requirements**:\n   - Backend services needed\n   - Database types and purposes\n   - Message queue topics (Kafka/RabbitMQ)\n   - Real-time events (WebSocket/SSE)\n   - Cloud services (AWS/GCP/Azure)\n   - External integrations\n\n## Output Format\n\nReturn a JSON object with this exact structure:\n\n```json\n{\n  \"projectName\": \"Project Name from SOW\",\n  \"platforms\": [\"web-application\", \"mobile-app\", \"admin-panel\"],\n  \"modules\": [\n    {\n      \"id\": \"user-authentication\",\n      \"name\": \"User Authentication\",\n      \"platform\": \"web-application\",\n      \"description\": \"Handle user registration, login, and session management\",\n      \"features\": [\n        \"User Registration\",\n        \"Email Verification\",\n        \"Login/Logout\",\n        \"Password Reset\",\n        \"Social Login\"\n      ],\n      \"services\": [\"auth-service\", \"email-service\"],\n      \"databases\": [\"PostgreSQL (user data)\", \"Redis (sessions)\"],\n      \"kafkaTopics\": [\"user.registered\", \"user.verified\"],\n      \"websocketEvents\": [\"session.expired\"],\n      \"awsServices\": [\"SES\", \"Cognito\"]\n    }\n  ]\n}\n```\n\n## Guidelines\n\n- **Be comprehensive** but don't invent features not mentioned in SOW\n- **Use consistent naming**: kebab-case for IDs, Title Case for names\n- **Group related features** into logical modules\n- **Identify cross-platform modules** - same module may appear on multiple platforms\n- **Extract implicit requirements** - if SOW mentions \"real-time updates\", include WebSocket\n- **Map to appropriate services** - payment features need payment service, etc.\n\n## After Analysis\n\n1. Display a summary of findings\n2. Save the JSON to `.dt-workspace-analysis.json` if requested\n3. Suggest next steps (run scaffold command)\n",
        "commands/clean.md": "---\ndescription: \"Delete generated documentation and reset config. Removes output directory and clears generatedPaths.\"\nargument-hint: \"[--force]\"\nallowed-tools: [\"Read\", \"Write\", \"Bash\", \"Glob\"]\n---\n\n# Clean Generated Documentation\n\nDelete all generated documentation and reset the configuration.\n\n## Steps\n\n### 1. Load Configuration\n\nRead `.dt-workspace` config to get output directory and generated paths.\n\n### 2. Show What Will Be Deleted\n\nDisplay summary of what will be removed:\n```\nFiles to be deleted:\n- <output>/README.md\n- <output>/web-application/ (X modules, Y files)\n- <output>/mobile-app/ (Z modules, W files)\n\nTotal: N files in M directories\n```\n\n### 3. Confirm Deletion\n\nUnless --force flag is provided, ask for confirmation:\n- \"This will permanently delete all generated documentation. Continue? (y/N)\"\n\n### 4. Delete Files\n\nRemove the output directory and all contents:\n```bash\nrm -rf <outputDirectory>\n```\n\n### 5. Update Configuration\n\nReset generatedPaths in `.dt-workspace`:\n```json\n{\n  \"generatedPaths\": {\n    \"platforms\": {}\n  },\n  \"lastGenerated\": null\n}\n```\n\n### 6. Display Summary\n\n```\nCLEAN COMPLETE\n\nDeleted: <output>/\nFiles removed: X\nDirectories removed: Y\n\nConfig updated: .dt-workspace\n- generatedPaths cleared\n- lastGenerated reset\n\nTo regenerate:\n1. Ensure SOW file exists\n2. Run /dt-workspace:scaffold\n```\n\n## Safety Features\n\n- Requires explicit confirmation (unless --force)\n- Only deletes configured output directory\n- Preserves .dt-workspace config file\n- Preserves .dt-templates custom templates\n- Preserves SOW file\n\n## Use Cases\n\n1. **Fresh start**: Regenerate all documentation from scratch\n2. **Preset change**: Clean before switching to different preset\n3. **SOW update**: After major SOW changes, regenerate everything\n4. **Cleanup**: Remove generated docs from version control\n",
        "commands/diagram.md": "---\ndescription: \"Generate ER diagrams from database schemas. Creates Mermaid, PlantUML, or ASCII diagrams.\"\nargument-hint: \"[--format <mermaid|plantuml|ascii>] [--platform <platform>] [--module <module>]\"\nallowed-tools: [\"Read\", \"Write\", \"Glob\", \"Grep\"]\n---\n\n# Generate ER Diagrams\n\nGenerate Entity-Relationship diagrams from database schema documentation.\n\n## Steps\n\n### 1. Load Configuration\n\nRead `.dt-workspace` config and validate generatedPaths exists.\n\n### 2. Select Target\n\nIf arguments provided, use them. Otherwise, use AskUserQuestion:\n1. Select platform\n2. Select module (or \"all\" for entire platform)\n\n### 3. Select Format\n\nIf --format provided, use it. Otherwise, ask:\n- **mermaid** (default) - GitHub/GitLab compatible\n- **plantuml** - PlantUML syntax\n- **ascii** - Text-based diagram\n\n### 4. Read Database Schemas\n\nFor each selected module:\n1. Read `database-schema.md`\n2. Extract table definitions, columns, relationships\n\n### 5. Generate Diagram\n\n**Mermaid Format**:\n```mermaid\nerDiagram\n    USER {\n        uuid id PK\n        string email UK\n        string password_hash\n        timestamp created_at\n    }\n    ORDER {\n        uuid id PK\n        uuid user_id FK\n        decimal total\n        string status\n    }\n    USER ||--o{ ORDER : places\n```\n\n**PlantUML Format**:\n```plantuml\n@startuml\nentity User {\n  * id : UUID <<PK>>\n  --\n  * email : VARCHAR(255) <<UK>>\n  * password_hash : VARCHAR(255)\n  created_at : TIMESTAMP\n}\nentity Order {\n  * id : UUID <<PK>>\n  --\n  * user_id : UUID <<FK>>\n  * total : DECIMAL\n  status : VARCHAR(50)\n}\nUser ||--o{ Order\n@enduml\n```\n\n**ASCII Format**:\n```\n+----------------+       +----------------+\n|     USER       |       |     ORDER      |\n+----------------+       +----------------+\n| id (PK)        |<----->| id (PK)        |\n| email (UK)     |       | user_id (FK)   |\n| password_hash  |       | total          |\n| created_at     |       | status         |\n+----------------+       +----------------+\n```\n\n### 6. Write Output\n\nCreate diagram file:\n- `<module>/er-diagram.md` (contains diagram code block)\n- Or append to existing `database-schema.md`\n\n### 7. Display Summary\n\n```\nER DIAGRAM GENERATED\n\nFormat: <format>\nModule: <module>\nOutput: <path>/er-diagram.md\n\nTables: X\nRelationships: Y\n\nTo view:\n- Mermaid: Render in GitHub/GitLab or mermaid.live\n- PlantUML: Use plantuml.com or IDE plugin\n- ASCII: View directly in any text editor\n```\n\n## Diagram Conversion\n\nTo convert between formats, specify source and target:\n\n```\n/dt-workspace:diagram --convert --from mermaid --to plantuml\n```\n\nReads existing diagram and converts to new format.\n",
        "commands/export.md": "---\ndescription: \"Export built-in templates for customization. Creates .dt-templates directory with Handlebars templates.\"\nargument-hint: \"[--preset <preset>]\"\nallowed-tools: [\"Read\", \"Write\", \"Bash\", \"Glob\"]\n---\n\n# Export Templates\n\nExport built-in Handlebars templates to `.dt-templates/` for customization.\n\n## Steps\n\n### 1. Select Preset\n\nIf --preset argument provided, use it. Otherwise, use AskUserQuestion:\n- microservices\n- monolith\n- serverless\n- supabase\n- firebase\n- nextjs-fullstack\n- graphql-federation\n- kubernetes\n- event-sourcing\n- all (export all presets)\n\n### 2. Check Existing Templates\n\nCheck if `.dt-templates/<preset>/` exists:\n- If exists, ask for confirmation to overwrite\n- If --force flag, skip confirmation\n\n### 3. Create Template Directory\n\n```bash\nmkdir -p .dt-templates/<preset>\n```\n\n### 4. Generate Template Files\n\nCreate Handlebars templates for the preset. Each preset needs:\n\n**template.config.json**:\n```json\n{\n  \"preset\": \"<preset>\",\n  \"description\": \"Preset description\",\n  \"documentTypes\": [...],\n  \"platformDocumentTypes\": [...],\n  \"featureTemplate\": \"feature-file.hbs\",\n  \"mainReadmeTemplate\": \"main-readme.hbs\"\n}\n```\n\n**Common templates**:\n- module-readme.hbs\n- user-flows-index.hbs\n- user-flows-single.hbs\n- technical-specs.hbs\n- api-contracts.hbs\n- database-schema.hbs\n- security-specs.hbs\n- testing-strategy.hbs\n- error-handling.hbs\n- feature-file.hbs\n- main-readme.hbs\n- platform-timeline.hbs\n\n**Preset-specific templates**:\n- realtime-events.hbs (microservices)\n- module-interactions.hbs (monolith)\n- event-sources.hbs, iam-policies.hbs (serverless)\n- etc.\n\n### 5. Display Summary\n\n```\nTEMPLATES EXPORTED\n\nLocation: .dt-templates/<preset>/\nFiles: X templates\n\nTemplate files:\n- template.config.json\n- module-readme.hbs\n- api-contracts.hbs\n- ...\n\nUsage:\n1. Edit templates in .dt-templates/<preset>/\n2. Run /dt-workspace:scaffold - custom templates auto-used\n3. Only override templates you need to change\n```\n\n## Template Customization\n\nTemplates use Handlebars syntax with variables:\n- `{{module.id}}`, `{{module.name}}`, `{{module.description}}`\n- `{{module.features}}`, `{{module.services}}`, `{{module.databases}}`\n- `{{preset}}`, `{{projectName}}`\n\nHelpers:\n- `{{capitalize text}}` - kebab-case to Title Case\n- `{{add index 1}}` - arithmetic\n- `{{#if}}`, `{{#each}}`, `{{#eq}}` - conditionals\n",
        "commands/init.md": "---\ndescription: \"Initialize dt-workspace project configuration. Creates .dt-workspace config file with project settings.\"\nargument-hint: \"[project-name]\"\nallowed-tools: [\"Read\", \"Write\", \"Glob\", \"Bash\"]\n---\n\n# Initialize DT-Workspace Project\n\nInitialize a new dt-workspace configuration for documentation generation.\n\n## Steps\n\n1. **Check for existing config**: Look for `.dt-workspace` file in current directory\n2. **If exists**: Ask user if they want to overwrite\n3. **Gather information** using AskUserQuestion:\n   - Project name (default: directory name or argument)\n   - SOW file path (default: ./sow.md)\n   - Preset selection (microservices/monolith/serverless/supabase/firebase/nextjs-fullstack/graphql-federation/kubernetes/event-sourcing)\n   - Output directory (default: ./workflows)\n\n4. **Create .dt-workspace file**:\n```json\n{\n  \"version\": \"1.0.0\",\n  \"projectName\": \"<from user>\",\n  \"sowPath\": \"<from user>\",\n  \"defaultPreset\": \"<from user>\",\n  \"outputDirectory\": \"<from user>\",\n  \"generatedAt\": \"<ISO timestamp>\",\n  \"generatedPaths\": {\n    \"platforms\": {}\n  }\n}\n```\n\n5. **Verify SOW file exists**: Check if sowPath file exists, warn if not\n\n6. **Display summary**:\n   - Configuration created\n   - Next steps: ensure SOW file exists, run scaffold command\n\n## Output Format\n\n```\nDT-WORKSPACE INITIALIZED\n\nConfiguration: .dt-workspace\nProject: <name>\nSOW Path: <path>\nPreset: <preset>\nOutput: <directory>\n\nNext steps:\n1. Ensure SOW file exists at <sowPath>\n2. Run /dt-workspace:scaffold to generate documentation\n```\n",
        "commands/populate.md": "---\ndescription: \"Fill documentation placeholders with AI-generated content. Completes [To be documented] sections in generated files.\"\nargument-hint: \"[--platform <platform>] [--module <module>]\"\nallowed-tools: [\"Read\", \"Write\", \"Glob\", \"Grep\"]\n---\n\n# Populate Documentation Placeholders\n\nFill `[To be documented]` placeholders in generated documentation with detailed, context-aware content.\n\n## Prerequisites\n\n- `.dt-workspace` config with `generatedPaths`\n- Generated documentation (run `/dt-workspace:scaffold` first)\n\n## Steps\n\n### 1. Load Configuration\n\nRead `.dt-workspace` and validate `generatedPaths.platforms` exists.\n\n### 2. Select Target\n\nIf arguments provided, use them. Otherwise, use AskUserQuestion:\n\n1. **Select Platform**: List available platforms from config\n2. **Select Module**: List modules in selected platform\n3. **Select Files**: Checkbox for which files to complete:\n   - user-flows/*.md\n   - technical-specs.md\n   - api-contracts.md\n   - database-schema.md\n   - realtime-events.md (if exists)\n   - security-specs.md\n   - error-handling.md\n\n### 3. Read Context\n\nFor each selected file:\n1. Read SOW file (config.sowPath)\n2. Read module README.md for context\n3. Read current file content\n\n### 4. Detect Placeholders\n\nLook for patterns:\n- `[To be documented]`\n- `[...to be documented...]`\n- `[...to be filled...]`\n- Any `[text]` indicating incomplete content (not markdown links)\n\n### 5. Fill Placeholders\n\nFor each file with placeholders:\n\n1. **Create backup**: `<file>.backup`\n2. **Generate content**: Replace placeholders with detailed content based on:\n   - SOW requirements\n   - Module context (features, services, databases)\n   - File type (API contracts need endpoints, database-schema needs tables)\n   - Preset patterns\n3. **Write updated file**\n\n### 6. Display Summary\n\n```\nCOMPLETION SUMMARY\n\nPlatform: <platform>\nModule: <module>\n\n✓ Processed: X files\n○ Skipped: Y files (no placeholders)\n✗ Errors: Z files\n\nBackup files created with .backup extension\nModule location: <path>\n\nNext steps:\n1. Review completed documentation\n2. Remove .backup files if satisfied\n3. Commit changes\n```\n\n## Placeholder Filling Guidelines\n\n### API Contracts\n- Generate realistic REST endpoints\n- Include request/response schemas\n- Add authentication requirements\n- Document error responses\n\n### Database Schema\n- Create table definitions with columns\n- Add relationships and foreign keys\n- Include indexes and constraints\n- Document migrations\n\n### Technical Specs\n- Architecture diagrams (mermaid)\n- Service interactions\n- Data flow descriptions\n- Technology choices\n\n### User Flows\n- Step-by-step user journeys\n- Decision points\n- Error scenarios\n- Success criteria\n",
        "commands/presets.md": "---\ndescription: \"List available template presets with descriptions. Shows all supported architecture patterns.\"\nallowed-tools: [\"Read\"]\n---\n\n# List Available Presets\n\nDisplay all available template presets with their descriptions and use cases.\n\n## Output\n\n```\nDT-WORKSPACE PRESETS\n\nAvailable template presets for documentation generation:\n\n┌─────────────────────┬────────────────────────────────────────────────────────┐\n│ Preset              │ Description                                            │\n├─────────────────────┼────────────────────────────────────────────────────────┤\n│ microservices       │ NestJS microservices with Kafka, WebSocket, PostgreSQL │\n│ monolith            │ Single application with layered architecture           │\n│ serverless          │ AWS Lambda, API Gateway, DynamoDB                      │\n│ supabase            │ Supabase with PostgreSQL, Auth, Storage, Edge Funcs    │\n│ firebase            │ Firebase/Firestore with Cloud Functions                │\n│ nextjs-fullstack    │ Next.js App Router with Server Components, Prisma      │\n│ graphql-federation  │ Apollo Federation with subgraphs                       │\n│ kubernetes          │ K8s deployments with Helm charts                       │\n│ event-sourcing      │ Event-sourced architecture with CQRS                   │\n└─────────────────────┴────────────────────────────────────────────────────────┘\n\nUsage:\n  /dt-workspace:init              # Select preset during init\n  /dt-workspace:scaffold --preset <name>   # Override default preset\n\nCustom presets:\n  Export templates: /dt-workspace:export --preset <name>\n  Edit in: .dt-templates/<preset>/\n```\n\n## Preset Details\n\n### microservices (default)\nBest for: Distributed systems, high scalability needs\nDocuments: Kafka events, WebSocket specs, service boundaries\n\n### monolith\nBest for: Startups, MVPs, simpler deployments\nDocuments: Module interactions, layered architecture, shared resources\n\n### serverless\nBest for: Event-driven, pay-per-use, auto-scaling needs\nDocuments: Lambda specs, IAM policies, event sources\n\n### supabase\nBest for: Rapid development, real-time apps, PostgreSQL preference\nDocuments: RLS policies, Edge Functions, Realtime subscriptions\n\n### firebase\nBest for: Mobile-first, real-time sync, Google ecosystem\nDocuments: Firestore rules, Cloud Functions, Auth flows\n\n### nextjs-fullstack\nBest for: React apps, SSR/SSG, modern web development\nDocuments: Server Components, Server Actions, caching strategies\n\n### graphql-federation\nBest for: Large teams, domain-driven design, unified API\nDocuments: Subgraph boundaries, federation directives, gateway config\n\n### kubernetes\nBest for: Container orchestration, cloud-native apps\nDocuments: K8s resources, Helm charts, networking, observability\n\n### event-sourcing\nBest for: Audit trails, temporal queries, complex domains\nDocuments: Event schemas, aggregates, projections, sagas\n",
        "commands/scaffold.md": "---\ndescription: \"Generate workflow documentation from SOW file. Creates organized project documentation with BDD features, API specs, database schemas.\"\nargument-hint: \"[sow-file] [--preset <preset>]\"\nallowed-tools: [\"Read\", \"Write\", \"Glob\", \"Bash\", \"Grep\"]\n---\n\n# Scaffold Workflow Documentation\n\nGenerate comprehensive workflow documentation from a Statement of Work (SOW) document.\n\n## Prerequisites\n\n- `.dt-workspace` config file must exist (run `/dt-workspace:init` first)\n- SOW markdown file must exist\n\n## Steps\n\n### 1. Load Configuration\n\nRead `.dt-workspace` config file. If not found, instruct user to run init first.\n\n### 2. Determine Settings\n\n- SOW file: argument > config.sowPath\n- Preset: --preset argument > config.defaultPreset > \"microservices\"\n- Output: config.outputDirectory > \"./workflows\"\n\n### 3. Read and Analyze SOW\n\nRead the SOW file and extract structured module definitions:\n\n```json\n{\n  \"projectName\": \"From SOW\",\n  \"platforms\": [\"web-application\", \"mobile-app\"],\n  \"modules\": [\n    {\n      \"id\": \"module-id\",\n      \"name\": \"Module Name\",\n      \"platform\": \"web-application\",\n      \"description\": \"Description\",\n      \"features\": [\"feature-1\", \"feature-2\"],\n      \"services\": [\"service-name\"],\n      \"databases\": [\"PostgreSQL\"],\n      \"kafkaTopics\": [\"topic.name\"],\n      \"websocketEvents\": [\"event.name\"],\n      \"awsServices\": [\"S3\"]\n    }\n  ]\n}\n```\n\n### 4. Generate Documentation Structure\n\nFor each platform and module, create:\n\n```\n<output>/\n├── README.md                    # Main index with all modules\n├── <platform>/\n│   ├── timeline.md              # Platform development timeline\n│   └── <module-id>/\n│       ├── README.md            # Module overview\n│       ├── user-flows/          # User journey scenarios\n│       │   ├── index.md\n│       │   └── <feature>.md\n│       ├── technical-specs.md\n│       ├── api-contracts.md\n│       ├── database-schema.md\n│       ├── [preset-specific].md # realtime-events, etc.\n│       ├── security-specs.md\n│       ├── testing-strategy.md\n│       ├── error-handling.md\n│       └── features/\n│           └── <feature>.feature\n```\n\n### 5. Generate Content\n\nFor each document, generate content based on preset templates with placeholders:\n- Use `[To be documented]` for sections needing AI completion\n- Include module context (features, services, databases)\n- Follow preset-specific patterns\n\n### 6. Update Config\n\nUpdate `.dt-workspace` with generated paths:\n\n```json\n{\n  \"lastGenerated\": \"<ISO timestamp>\",\n  \"generatedPaths\": {\n    \"platforms\": {\n      \"web-application\": {\n        \"path\": \"./workflows/web-application\",\n        \"modules\": [\n          {\"id\": \"module-id\", \"name\": \"Module Name\", \"path\": \"./workflows/web-application/module-id\"}\n        ]\n      }\n    }\n  }\n}\n```\n\n### 7. Display Summary\n\n```\nGENERATION COMPLETE\n\nProject: <name>\nPreset: <preset>\nLocation: <output>\n\nModules: X\nFiles: Y\nDirectories: Z\n\nNext steps:\n1. Review generated files\n2. Run /dt-workspace:populate to fill placeholders\n3. Update BDD scenarios with specific test cases\n```\n\n## Preset Templates\n\nBased on selected preset, generate appropriate documents. See skill references for preset details.\n",
        "commands/sync.md": "---\ndescription: \"Rebuild .dt-workspace config from existing documentation. Scans output directory and reconstructs generatedPaths.\"\nallowed-tools: [\"Read\", \"Write\", \"Glob\", \"Bash\"]\n---\n\n# Sync Configuration\n\nScan the output directory and rebuild `generatedPaths` in `.dt-workspace` config. Useful when:\n- Config was lost or corrupted\n- Documentation was manually reorganized\n- Migrating from another setup\n\n## Steps\n\n### 1. Load Configuration\n\nRead `.dt-workspace` config. If not found, create minimal config first.\n\n### 2. Scan Output Directory\n\nScan `config.outputDirectory` (default: ./workflows) for:\n\n```\n<output>/\n├── README.md\n├── <platform-1>/\n│   ├── timeline.md\n│   └── <module-1>/\n│       └── README.md\n│   └── <module-2>/\n│       └── README.md\n├── <platform-2>/\n│   └── ...\n```\n\n### 3. Detect Platforms\n\nFind all directories in output that contain module subdirectories:\n- Platform directories have `timeline.md` or module subdirectories\n- Module directories have `README.md`\n\n### 4. Extract Module Information\n\nFor each module directory:\n1. Read `README.md` to extract module name\n2. Use directory name as module ID\n3. Record path relative to project root\n\n### 5. Rebuild generatedPaths\n\n```json\n{\n  \"generatedPaths\": {\n    \"platforms\": {\n      \"<platform>\": {\n        \"path\": \"./<output>/<platform>\",\n        \"modules\": [\n          {\n            \"id\": \"<module-id>\",\n            \"name\": \"<Module Name from README>\",\n            \"path\": \"./<output>/<platform>/<module-id>\"\n          }\n        ]\n      }\n    }\n  }\n}\n```\n\n### 6. Update Config\n\nWrite updated config to `.dt-workspace`:\n- Preserve existing settings (projectName, sowPath, preset, etc.)\n- Update generatedPaths\n- Update lastGenerated timestamp\n\n### 7. Display Summary\n\n```\nSYNC COMPLETE\n\nOutput Directory: <path>\n\nPlatforms Found: X\n├── web-application (Y modules)\n├── mobile-app (Z modules)\n└── admin-panel (W modules)\n\nTotal Modules: N\n\nConfig updated: .dt-workspace\n```\n\n## Use Cases\n\n1. **Lost config**: Recreate `.dt-workspace` from existing docs\n2. **Manual changes**: After reorganizing documentation structure\n3. **Migration**: After moving documentation to new location\n4. **Verification**: Ensure config matches actual file structure\n",
        "skills/workflow-generator/SKILL.md": "---\ndescription: \"Use this skill when user asks to generate workflow documentation, analyze SOW files, create project structure from requirements, scaffold documentation, or work with dt-workspace features. Triggers on: 'generate documentation', 'analyze SOW', 'scaffold project', 'create workflow docs', 'dt-workspace', 'from SOW file', 'module documentation'.\"\n---\n\n# Workflow Documentation Generator\n\nGenerate comprehensive workflow documentation from Statement of Work (SOW) documents. This skill enables creating organized project documentation including BDD feature files, API contracts, database schemas, and technical specifications.\n\n## Core Workflow\n\n### 1. Initialize Project Configuration\n\nBefore generating documentation, create a `.dt-workspace` config file:\n\n```json\n{\n  \"version\": \"1.0.0\",\n  \"projectName\": \"Project Name\",\n  \"sowPath\": \"./sow.md\",\n  \"defaultPreset\": \"microservices\",\n  \"outputDirectory\": \"./workflows\",\n  \"generatedAt\": \"ISO timestamp\",\n  \"generatedPaths\": {\n    \"platforms\": {}\n  }\n}\n```\n\n### 2. Analyze SOW Document\n\nExtract structured module definitions from SOW markdown. Return JSON with:\n\n```json\n{\n  \"projectName\": \"From SOW\",\n  \"platforms\": [\"web-application\", \"mobile-app\", \"admin-panel\"],\n  \"modules\": [\n    {\n      \"id\": \"kebab-case-id\",\n      \"name\": \"Human Readable Name\",\n      \"platform\": \"web-application\",\n      \"description\": \"Module purpose\",\n      \"features\": [\"feature-1\", \"feature-2\"],\n      \"services\": [\"service-name\"],\n      \"databases\": [\"PostgreSQL (purpose)\"],\n      \"kafkaTopics\": [\"topic.name\"],\n      \"websocketEvents\": [\"event.name\"],\n      \"awsServices\": [\"S3\", \"Lambda\"]\n    }\n  ]\n}\n```\n\n### 3. Generate Documentation Structure\n\nCreate organized output:\n\n```\nworkflows/\n├── README.md                    # Main index\n├── <platform>/\n│   ├── timeline.md              # Development sequence\n│   └── <module-id>/\n│       ├── README.md            # Module overview\n│       ├── user-flows/          # User journey scenarios\n│       ├── technical-specs.md   # Architecture specs\n│       ├── api-contracts.md     # API documentation\n│       ├── database-schema.md   # Data models\n│       ├── realtime-events.md   # Events (microservices)\n│       ├── security-specs.md    # Security controls\n│       ├── testing-strategy.md  # Test approach\n│       ├── error-handling.md    # Error codes\n│       └── features/            # BDD Gherkin files\n│           └── <feature>.feature\n```\n\n## Available Presets\n\nSelect preset based on architecture:\n\n| Preset | Use Case |\n|--------|----------|\n| `microservices` | NestJS microservices with Kafka, WebSocket, PostgreSQL |\n| `monolith` | Single application with layered architecture |\n| `serverless` | AWS Lambda, API Gateway, DynamoDB |\n| `supabase` | Supabase backend with PostgreSQL, Auth, Storage |\n| `firebase` | Firebase/Firestore with Cloud Functions |\n| `nextjs-fullstack` | Next.js with App Router, Server Actions |\n| `graphql-federation` | Apollo Federation with subgraphs |\n| `kubernetes` | K8s deployments with Helm charts |\n| `event-sourcing` | Event-sourced architecture with CQRS |\n\n## SOW Analysis Prompt\n\nUse this prompt to analyze SOW documents:\n\n```\nAnalyze this Statement of Work (SOW) to extract structured module definitions.\n\nFor each module, extract:\n- Module ID (kebab-case)\n- Module name (title case)\n- Description (1-2 sentences)\n- Features list\n- Technical components:\n  * Backend services\n  * Databases (type and purpose)\n  * Message queues (Kafka/RabbitMQ topics)\n  * Real-time events (WebSocket/SSE)\n  * Cloud services (AWS/GCP/Azure)\n\nReturn ONLY valid JSON with structure:\n{\n  \"projectName\": \"string\",\n  \"platforms\": [\"string\"],\n  \"modules\": [{\n    \"id\": \"string\",\n    \"name\": \"string\",\n    \"platform\": \"string\",\n    \"description\": \"string\",\n    \"features\": [\"string\"],\n    \"services\": [\"string\"],\n    \"databases\": [\"string\"],\n    \"kafkaTopics\": [\"string\"],\n    \"websocketEvents\": [\"string\"],\n    \"awsServices\": [\"string\"]\n  }]\n}\n\nBe comprehensive but don't invent features not in the SOW.\n```\n\n## Document Templates\n\nEach preset generates specific documents. See `references/presets.md` for details.\n\n### Common Documents (All Presets)\n- **README.md** - Module overview with features\n- **user-flows/** - User journey scenarios (split by feature)\n- **technical-specs.md** - Architecture specifications\n- **api-contracts.md** - REST/GraphQL API documentation\n- **database-schema.md** - Data models and relationships\n- **error-handling.md** - Error codes and handling\n\n### Preset-Specific Documents\n- **realtime-events.md** (microservices) - Kafka/WebSocket events\n- **module-interactions.md** (monolith) - Internal module communication\n- **event-sources.md** (serverless) - Lambda triggers\n- **iam-policies.md** (serverless) - IAM roles and permissions\n\n## Placeholder Pattern\n\nGenerated docs use placeholders for AI completion:\n\n```markdown\n[To be documented]\n[API endpoints to be documented]\n[Schema to be documented here]\n```\n\nUse the populate command to fill these with AI-generated content.\n\n## Reference Files\n\n- `references/presets.md` - Detailed preset configurations\n- `references/sow-format.md` - SOW document format guide\n- `references/templates.md` - Template customization guide\n",
        "skills/workflow-generator/references/presets.md": "# Template Presets Reference\n\n## Microservices Preset\n\n**Architecture**: NestJS microservices with Kafka, WebSocket, PostgreSQL, MongoDB, AWS\n\n**Documents Generated**:\n| Document | Description |\n|----------|-------------|\n| README.md | Module overview with features and technical components |\n| user-flows/ | Detailed user journey scenarios (split by feature) |\n| technical-specs.md | NestJS microservices architecture and specifications |\n| api-contracts.md | Complete API endpoint specifications with OpenAPI format |\n| database-schema.md | Database models, migrations, and relationships |\n| realtime-events.md | Kafka topics, WebSocket events, and event schemas |\n| security-specs.md | Authentication, authorization, and security controls |\n| testing-strategy.md | Unit, integration, and E2E testing approach |\n| error-handling.md | Error codes, handling strategies, and monitoring |\n| features/*.feature | BDD Gherkin feature files |\n| timeline.md | Platform-level development timeline |\n\n---\n\n## Monolith Preset\n\n**Architecture**: Single application with layered architecture (Presentation/Business/Data)\n\n**Documents Generated**:\n| Document | Description |\n|----------|-------------|\n| README.md | Module overview |\n| user-flows/ | User journey scenarios |\n| technical-specs.md | Layered architecture specifications |\n| api-contracts.md | API documentation |\n| database-schema.md | Shared database models |\n| module-interactions.md | Internal module communication patterns |\n| security-specs.md | Security controls |\n| testing-strategy.md | Testing approach |\n| error-handling.md | Error handling |\n| features/*.feature | BDD feature files |\n| timeline.md | Development timeline |\n\n---\n\n## Serverless Preset\n\n**Architecture**: AWS Lambda, API Gateway, DynamoDB, S3, SQS, EventBridge\n\n**Documents Generated**:\n| Document | Description |\n|----------|-------------|\n| README.md | Module overview |\n| user-flows/ | User journey scenarios |\n| technical-specs.md | Lambda function specifications |\n| api-contracts.md | API Gateway endpoints |\n| database-schema.md | DynamoDB table designs |\n| event-sources.md | S3, SQS, EventBridge, DynamoDB Stream triggers |\n| iam-policies.md | Lambda IAM roles and policies |\n| security-specs.md | Security controls |\n| testing-strategy.md | Testing approach (including local testing) |\n| error-handling.md | Error handling with cold start considerations |\n| features/*.feature | BDD feature files |\n| timeline.md | Development timeline |\n\n---\n\n## Supabase Preset\n\n**Architecture**: Supabase with PostgreSQL, Auth, Storage, Edge Functions\n\n**Documents Generated**:\n| Document | Description |\n|----------|-------------|\n| README.md | Module overview |\n| user-flows/ | User journey scenarios |\n| technical-specs.md | Supabase architecture |\n| api-contracts.md | REST API and RPC functions |\n| database-schema.md | PostgreSQL with RLS policies |\n| auth-flows.md | Supabase Auth integration |\n| storage-specs.md | Supabase Storage buckets |\n| realtime-specs.md | Supabase Realtime subscriptions |\n| edge-functions.md | Deno Edge Functions |\n| features/*.feature | BDD feature files |\n| timeline.md | Development timeline |\n\n---\n\n## Firebase Preset\n\n**Architecture**: Firebase/Firestore with Cloud Functions, Auth, Storage\n\n**Documents Generated**:\n| Document | Description |\n|----------|-------------|\n| README.md | Module overview |\n| user-flows/ | User journey scenarios |\n| technical-specs.md | Firebase architecture |\n| api-contracts.md | Callable functions and REST endpoints |\n| database-schema.md | Firestore collections and security rules |\n| auth-flows.md | Firebase Auth integration |\n| storage-specs.md | Cloud Storage rules |\n| cloud-functions.md | Cloud Functions specifications |\n| features/*.feature | BDD feature files |\n| timeline.md | Development timeline |\n\n---\n\n## Next.js Fullstack Preset\n\n**Architecture**: Next.js App Router with Server Components, Server Actions, Prisma\n\n**Documents Generated**:\n| Document | Description |\n|----------|-------------|\n| README.md | Module overview |\n| user-flows/ | User journey scenarios |\n| technical-specs.md | Next.js architecture (RSC, Server Actions) |\n| api-contracts.md | Route handlers and Server Actions |\n| database-schema.md | Prisma schema |\n| component-specs.md | React component specifications |\n| state-management.md | Client/server state patterns |\n| caching-strategy.md | Next.js caching and revalidation |\n| features/*.feature | BDD feature files |\n| timeline.md | Development timeline |\n\n---\n\n## GraphQL Federation Preset\n\n**Architecture**: Apollo Federation with subgraphs, gateway, and distributed schema\n\n**Documents Generated**:\n| Document | Description |\n|----------|-------------|\n| README.md | Module overview |\n| user-flows/ | User journey scenarios |\n| technical-specs.md | Federation architecture |\n| schema-specs.md | GraphQL schema with federation directives |\n| resolver-specs.md | Resolver implementations |\n| database-schema.md | Database models |\n| subgraph-specs.md | Subgraph boundaries and entities |\n| gateway-specs.md | Gateway configuration |\n| features/*.feature | BDD feature files |\n| timeline.md | Development timeline |\n\n---\n\n## Kubernetes Preset\n\n**Architecture**: Kubernetes deployments with Helm charts, services, ingress\n\n**Documents Generated**:\n| Document | Description |\n|----------|-------------|\n| README.md | Module overview |\n| user-flows/ | User journey scenarios |\n| technical-specs.md | Service architecture |\n| api-contracts.md | API documentation |\n| database-schema.md | Database models |\n| k8s-resources.md | Deployment, Service, ConfigMap, Secret specs |\n| helm-charts.md | Helm chart structure and values |\n| networking.md | Ingress, Service Mesh configurations |\n| observability.md | Logging, metrics, tracing |\n| features/*.feature | BDD feature files |\n| timeline.md | Development timeline |\n\n---\n\n## Event Sourcing Preset\n\n**Architecture**: Event-sourced architecture with CQRS, event store, projections\n\n**Documents Generated**:\n| Document | Description |\n|----------|-------------|\n| README.md | Module overview |\n| user-flows/ | User journey scenarios |\n| technical-specs.md | CQRS/ES architecture |\n| api-contracts.md | Command and Query APIs |\n| event-schema.md | Domain events and versioning |\n| aggregate-specs.md | Aggregate root specifications |\n| projection-specs.md | Read model projections |\n| saga-specs.md | Process managers and sagas |\n| event-store.md | Event store configuration |\n| features/*.feature | BDD feature files |\n| timeline.md | Development timeline |\n",
        "skills/workflow-generator/references/sow-format.md": "# SOW Document Format Guide\n\n## Recommended Structure\n\nA well-structured SOW document helps generate better documentation. Follow this format:\n\n```markdown\n# Project Name\n\n## Overview\nBrief project description and goals.\n\n## Platforms\n- Web Application\n- Mobile App (iOS/Android)\n- Admin Panel\n\n## Modules\n\n### 1. User Management\n**Platform**: Web Application, Mobile App\n\n**Description**: Handle user registration, authentication, and profile management.\n\n**Features**:\n- User Registration\n- Email Verification\n- Login/Logout\n- Password Reset\n- Profile Management\n- Social Login (Google, Apple)\n\n**Technical Requirements**:\n- JWT authentication\n- OAuth 2.0 integration\n- PostgreSQL for user data\n- Redis for session management\n- Email service integration (SendGrid)\n\n### 2. Product Catalog\n**Platform**: Web Application, Mobile App, Admin Panel\n\n**Description**: Manage product listings, categories, and inventory.\n\n**Features**:\n- Product Listing\n- Category Management\n- Search & Filters\n- Product Details\n- Inventory Tracking\n\n**Technical Requirements**:\n- Elasticsearch for search\n- PostgreSQL for product data\n- S3 for product images\n- Redis caching\n\n### 3. Order Management\n...\n\n## Non-Functional Requirements\n- Performance: Response time < 200ms\n- Scalability: Support 10,000 concurrent users\n- Availability: 99.9% uptime\n- Security: OWASP compliance\n\n## Integration Points\n- Payment Gateway: Stripe\n- Email Service: SendGrid\n- SMS Service: Twilio\n- Analytics: Mixpanel\n```\n\n## Key Elements for Analysis\n\n### Module Definition\nEach module should include:\n1. **Clear name** - Descriptive, action-oriented\n2. **Platform assignment** - Which platforms use this module\n3. **Description** - 1-2 sentences explaining purpose\n4. **Features list** - Specific capabilities\n5. **Technical requirements** - Databases, services, integrations\n\n### Feature Naming\nUse consistent, descriptive feature names:\n- Good: \"User Registration\", \"Password Reset\", \"Order Checkout\"\n- Bad: \"Feature 1\", \"Login stuff\", \"Handle orders\"\n\n### Technical Components\nExplicitly mention:\n- **Databases**: PostgreSQL, MongoDB, Redis, Elasticsearch\n- **Message Queues**: Kafka topics, RabbitMQ queues\n- **Real-time**: WebSocket events, SSE streams\n- **Cloud Services**: AWS S3, Lambda, SQS, etc.\n- **External APIs**: Payment, email, SMS services\n\n## Example SOW Snippets\n\n### E-commerce Module\n```markdown\n### Shopping Cart\n**Platform**: Web Application, Mobile App\n\n**Description**: Real-time shopping cart with persistent storage and promotions.\n\n**Features**:\n- Add/Remove Items\n- Quantity Updates\n- Save for Later\n- Promo Code Application\n- Cart Persistence\n- Real-time Price Updates\n\n**Technical Requirements**:\n- Redis for cart storage\n- PostgreSQL for saved carts\n- Kafka for inventory updates\n- WebSocket for real-time sync\n```\n\n### Real-time Messaging Module\n```markdown\n### Chat System\n**Platform**: Mobile App\n\n**Description**: Real-time messaging between users with media support.\n\n**Features**:\n- Direct Messaging\n- Group Chats\n- Media Sharing\n- Read Receipts\n- Typing Indicators\n- Push Notifications\n\n**Technical Requirements**:\n- WebSocket for real-time\n- MongoDB for message storage\n- S3 for media files\n- Redis for presence\n- Kafka for event streaming\n- FCM/APNS for push notifications\n```\n\n## Tips for Better Analysis\n\n1. **Be specific** - Instead of \"database\", specify \"PostgreSQL for users, MongoDB for logs\"\n2. **Group related features** - Keep related functionality in same module\n3. **Define boundaries** - Clear separation between modules\n4. **Include integrations** - External services and APIs\n5. **Mention real-time needs** - WebSocket, SSE, polling requirements\n",
        "skills/workflow-generator/references/templates.md": "# Template Customization Guide\n\n## Template Override System\n\nCustom templates are stored in `.dt-templates/<preset>/` directory:\n\n```\n.dt-templates/\n├── microservices/\n│   ├── template.config.json\n│   ├── module-readme.hbs\n│   ├── api-contracts.hbs\n│   └── ... (other templates)\n└── monolith/\n    └── ...\n```\n\n## Template Resolution Order\n\n1. User templates: `.dt-templates/<preset>/<template>.hbs`\n2. Built-in templates: `dist/templates/<preset>/<template>.hbs`\n\nOverride specific templates while keeping others as defaults.\n\n## Handlebars Template Syntax\n\n### Available Variables\n\n```handlebars\n{{module.id}}           <!-- kebab-case-id -->\n{{module.name}}         <!-- Human Readable Name -->\n{{module.description}}  <!-- Module description -->\n{{module.platform}}     <!-- web-application -->\n{{module.features}}     <!-- Array of feature names -->\n{{module.services}}     <!-- Array of service names -->\n{{module.databases}}    <!-- Array of database descriptions -->\n{{module.kafkaTopics}}  <!-- Array of Kafka topics -->\n{{module.websocketEvents}} <!-- Array of WebSocket events -->\n{{module.awsServices}}  <!-- Array of AWS services -->\n\n{{preset}}              <!-- Current preset name -->\n{{projectName}}         <!-- Project name from config -->\n```\n\n### Built-in Helpers\n\n```handlebars\n{{capitalize module.id}}     <!-- Kebab Case Id -->\n{{add @index 1}}             <!-- 1-based index -->\n{{#eq value \"test\"}}...{{/eq}}\n{{#ne value \"test\"}}...{{/ne}}\n{{#gt value 5}}...{{/gt}}\n{{#lt value 5}}...{{/lt}}\n```\n\n### Iteration\n\n```handlebars\n{{#each module.features}}\n## Feature: {{this}}\n{{/each}}\n\n{{#each module.features as |feature index|}}\n{{add index 1}}. {{feature}}\n{{/each}}\n```\n\n### Conditionals\n\n```handlebars\n{{#if module.kafkaTopics}}\n## Kafka Topics\n{{#each module.kafkaTopics}}\n- `{{this}}`\n{{/each}}\n{{/if}}\n\n{{#unless module.services}}\nNo services defined.\n{{/unless}}\n```\n\n## Example Custom Template\n\n### Custom module-readme.hbs\n\n```handlebars\n# {{module.name}}\n\n> {{module.description}}\n\n## Platform\n**{{module.platform}}**\n\n## Features\n\n{{#each module.features}}\n- [ ] {{this}}\n{{/each}}\n\n## Technical Stack\n\n{{#if module.databases}}\n### Databases\n{{#each module.databases}}\n- {{this}}\n{{/each}}\n{{/if}}\n\n{{#if module.services}}\n### Services\n{{#each module.services}}\n- `{{this}}`\n{{/each}}\n{{/if}}\n\n{{#if module.awsServices}}\n### AWS Services\n{{#each module.awsServices}}\n- {{this}}\n{{/each}}\n{{/if}}\n\n---\n*Generated by dt-workspace*\n```\n\n## template.config.json Structure\n\n```json\n{\n  \"preset\": \"microservices\",\n  \"description\": \"Preset description\",\n  \"documentTypes\": [\n    {\n      \"name\": \"README.md\",\n      \"template\": \"module-readme.hbs\",\n      \"description\": \"Module overview\"\n    },\n    {\n      \"name\": \"user-flows\",\n      \"template\": \"user-flows-single.hbs\",\n      \"indexTemplate\": \"user-flows-index.hbs\",\n      \"description\": \"User journey scenarios\",\n      \"splitBy\": \"features\",\n      \"directory\": true\n    }\n  ],\n  \"platformDocumentTypes\": [\n    {\n      \"name\": \"timeline.md\",\n      \"template\": \"platform-timeline.hbs\",\n      \"description\": \"Development timeline\"\n    }\n  ],\n  \"featureTemplate\": \"feature-file.hbs\",\n  \"mainReadmeTemplate\": \"main-readme.hbs\"\n}\n```\n\n## Creating Custom Presets\n\n1. Create directory: `.dt-templates/my-preset/`\n2. Create `template.config.json` with document types\n3. Create `.hbs` templates for each document\n4. Use with `--preset my-preset`\n\n## Placeholder Conventions\n\nUse consistent placeholders for AI completion:\n\n```markdown\n[To be documented]\n[API endpoints to be documented]\n[Schema to be documented here]\n[Security requirements to be documented]\n[Performance metrics to be documented]\n```\n\nPattern: `[<context> to be documented]`\n"
      },
      "plugins": [
        {
          "name": "dt-workspace",
          "source": "./",
          "description": "AI-powered workflow documentation generator from SOW documents - generates comprehensive project docs with BDD features, API contracts, database schemas",
          "version": "1.0.0",
          "category": "documentation",
          "tags": [
            "sow",
            "documentation",
            "workflow",
            "bdd",
            "api",
            "scaffold"
          ],
          "author": {
            "name": "Deepak Tiwari",
            "email": "deepaktiwari3020@gmail.com"
          },
          "categories": [
            "api",
            "bdd",
            "documentation",
            "scaffold",
            "sow",
            "workflow"
          ],
          "install_commands": [
            "/plugin marketplace add deepaktiwari09/dt-workspace-plugin",
            "/plugin install dt-workspace@dt-workspace-marketplace"
          ]
        }
      ]
    }
  ]
}