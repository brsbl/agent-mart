{
  "author": {
    "id": "Devil-SX",
    "display_name": "DeVIL",
    "avatar_url": "https://avatars.githubusercontent.com/u/77198466?u=09989dd63abf00c3941a516255effa4dbf710f58&v=4"
  },
  "marketplaces": [
    {
      "name": "torchbit",
      "version": null,
      "description": "Torchbit: Utilities for deep learning accelerator development, including testbench reporting, data conversion, and tiling tools",
      "repo_full_name": "Devil-SX/torchbit",
      "repo_url": "https://github.com/Devil-SX/torchbit",
      "repo_description": "utils for dl accelerator developing",
      "signals": {
        "stars": 1,
        "forks": 0,
        "pushed_at": "2026-02-11T07:48:00Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"torchbit\",\n  \"owner\": {\n    \"name\": \"ShuchengDu\",\n    \"email\": \"shuchengdu@ust.hk\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"torchbit\",\n      \"source\": \"./\",\n      \"description\": \"Torchbit: Utilities for deep learning accelerator development, including testbench reporting, data conversion, and tiling tools\",\n      \"version\": \"2.4.2\",\n      \"author\": {\n        \"name\": \"ShuchengDu\",\n        \"email\": \"shuchengdu@ust.hk\"\n      },\n      \"homepage\": \"https://github.com/Devil-SX/torchbit\",\n      \"repository\": \"https://github.com/Devil-SX/torchbit\",\n      \"license\": \"MIT\",\n      \"keywords\": [\n        \"deep-learning\",\n        \"accelerator\",\n        \"cocotb\",\n        \"torchbit\",\n        \"testbench\",\n        \"verification\"\n      ],\n      \"category\": \"development\",\n      \"strict\": false,\n      \"skills\": \"./skills/\"\n    }\n  ]\n}\n",
        "README.md": "<h1 align=\"center\">Torchbit</h1>\n\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/version-2.4.2-blue\" alt=\"version\">\n  <img src=\"https://img.shields.io/badge/Python-3838_lines-3776AB?logo=python&logoColor=white\" alt=\"Python\">\n  <img src=\"https://img.shields.io/badge/Markdown-214_lines-083fa1\" alt=\"Markdown\">\n  <img src=\"https://img.shields.io/badge/SystemVerilog-18_lines-dc382c\" alt=\"SystemVerilog\">\n</p>\n\n<p align=\"center\">\n  <a href=\"./README.md\">English</a> | <a href=\"./README.zh-CN.md\">简体中文</a>\n</p>\n\nTorchbit provides utilities for deep learning accelerator verification, facilitating the conversion of PyTorch tensors into Cocotb-compatible formats.\n\n**Why Torchbit?** AI accelerator development should prioritize Python.\n\n- All data rearrangement, tiling, and padding should be implemented using advanced tensor processing libraries like `einops` and `torch` in Python, rather than using `for` loops in Verilog or C++.\n- Compatibility with `torch` is the top priority, ensuring seamless integration with the algorithmic Golden Model.\n\n![logo](logo.jpg)\n\n# Features\n\n- **Rapidly build torch-native test frameworks:**\n    - Map any `torch` data type to `cocotb` framework stimuli.\n    - Abstract the Tensor mapping process based on `einops`.\n    - Includes reusable components (e.g., Buffer, FIFO).\n- **Fast debugging** (currently under development).\n\n# Get Started\n\n## Installation\n\n```bash\npip install git+https://github.com/Devil-SX/torchbit.git\n```\n\nThe main branch is currently maintained for environments using `cocotb >= 2.x`, Verilator >= 5.036, and VCS.\n\n\n\n## Compatibility\n\n| OS | Cocotb  | Simulator | Status | Notes |\n|----|---------|-----------|--------|-------|\n| WSL Ubuntu 22.04 | 2.0.0 | Verilator 5.038 | ✅ |  |\n| WSL Ubuntu 22.04 | 2.0.0 | Verilator 5.036 | ❌ | fst assert failed, see [this issue](https://github.com/cocotb/cocotb/issues/4522) |\n| CentOS 7 | 2.0.0 | VCS | ✅ |  |\n\n\n# Philosophy\n\nTensor processing involves two key aspects: value processing and shape processing. Value processing deals with mapping various torch-supported data formats (float, signed, unsigned, brain-float) to Verilog bits. Shape processing includes complex Tilling transformations and other processes. For underlying value transformation principles, refer to [value.md](./doc/en/value.md). For tilling design principles, refer to [tilling_schedule.md](./doc/en/tilling_schedule.md).\n\n# Basic Datatypes\n\nTorchbit defines two sets of terminology for the software side (PyTorch) and the hardware side (Cocotb/HDL), connected by conversion methods.\n\n## Terminology\n\n| | PyTorch (Software) | Cocotb / HDL (Hardware) |\n|---|---|---|\n| **Single** | **Array** — 1D Tensor | **Logic** — packed integer for any signal |\n| | | **Vector** — Array wrapper, SIMD parallel interface |\n| | | **BitStruct** — field-defined interface |\n| **Sequence** | **Matrix** — 2D Tensor | **LogicSequence** — sequence of Logic values |\n| | | **VectorSequence** — sequence of Vectors |\n\n## Transaction: Single Value Conversion\n\n[Vector](./torchbit/core/vector.py) is the core bridge between PyTorch Arrays and HDL Logic values. `BitStruct` defines custom field layouts that also convert to/from Logic.\n\n![Transaction](./doc/pic/01_transaction.png)\n\n### Array → Logic (drive a signal)\n\n```python\nfrom torchbit.core import Vector, array_to_logic\n\nx = torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0], dtype=torch.float32)\n\n# Step by step\nvec = Vector.from_array(x)          # Array → Vector\ndut.io_din.value = vec.to_logic()   # Vector → Logic\n\n# One-liner shortcut\ndut.io_din.value = array_to_logic(x)\n```\n\n### Logic → Array (read a signal)\n\n```python\nfrom torchbit.core import Vector, logic_to_array\n\n# Step by step\nvec = Vector.from_logic(dut.io_dout.value, 5, torch.float32)\nx = vec.to_array()                   # Logic → Vector → Array\n\n# One-liner shortcut\nx = logic_to_array(dut.io_dout.value, 5, torch.float32)\n```\n\n> **Backward compatibility:** `from_tensor`/`to_tensor`, `from_cocotb`/`to_cocotb`, `to_int`, `tensor_to_cocotb`/`cocotb_to_tensor` are all preserved as aliases.\n\n## Sequence: Batch Value Conversion\n\nFor sequences of values (e.g., multiple clock cycles), `VectorSequence` bridges PyTorch 2D Matrices and HDL LogicSequences.\n\n![Sequence](./doc/pic/04_sequence.png)\n\n```python\nfrom torchbit.core import VectorSequence\n\nmatrix = torch.randn(256, 4)                     # 2D Matrix\nvs = VectorSequence.from_matrix(matrix)           # Matrix → VectorSequence\nlogic_seq = vs.to_logic_sequence()                # VectorSequence → LogicSequence\nrestored = VectorSequence.from_logic_sequence(logic_seq, 4, torch.float32)\n```\n\n> **Backward compatibility:** `from_tensor`/`to_tensor`, `to_int_sequence`/`from_int_sequence` are preserved as aliases.\n\n## Tensor ↔ LogicSequence via TileMapping\n\nIn real hardware, a high-dimensional Tensor (e.g., `c h w`) needs to be reshaped and serialized into a time-ordered sequence of packed values for transmission. `TileMapping` handles this end-to-end:\n\n```\nTensor  ──rearrange──►  Matrix (2D)  ──pack rows──►  LogicSequence\n (c h w)     einops       (c, h*w)      Vector          [int, ...]\n```\n\nThe conversion decomposes into two stages:\n\n1. **Rearrange** (shape): `einops.rearrange` reshapes the Tensor into a 2D Matrix, where each row represents one clock cycle's data (spatial dimension) and the number of rows equals the number of clock cycles (temporal dimension).\n2. **Pack** (value): Each row of the Matrix is packed into a single integer via `Vector`, producing a `LogicSequence`.\n\n```python\nfrom torchbit.tiling import TileMapping, array_to_logic_seq, logic_seq_to_array\n\nmapping = TileMapping(\n    dtype=torch.float32,\n    sw_einops=\"c h w\",\n    hw_einops=\"c (h w)\",\n    hw_temp_dim={\"c\": 3},\n    hw_spat_dim={\"h\": 32, \"w\": 32},\n)\n\ntensor = torch.randn(3, 32, 32)\n\n# Tensor → LogicSequence (high-level shortcut)\nseq = array_to_logic_seq(tensor, mapping)\n\n# LogicSequence → Tensor\nrestored = logic_seq_to_array(seq, mapping)\nassert torch.allclose(tensor, restored)\n```\n\nYou can also use the low-level shortcuts without a TileMapping, operating directly on a 2D Matrix:\n\n```python\nfrom torchbit.tiling import matrix_to_logic_seq, logic_seq_to_matrix\n\nmatrix = torch.randn(256, 4)\nseq = matrix_to_logic_seq(matrix)                            # Matrix → LogicSequence\nrestored = logic_seq_to_matrix(seq, 4, torch.float32)        # LogicSequence → Matrix\n```\n\n> **Backward compatibility:** `tensor_to_cocotb_seq`/`cocotb_seq_to_tensor` are preserved as aliases for `array_to_logic_seq`/`logic_seq_to_array`.\n\n## Tools Overview\n\n![Driver & Monitor](./doc/pic/02_driver_monitor.png)\n\n- **Driver**: Feeds a `LogicSequence` into DUT via front-door (data + valid) signals.\n- **PoolMonitor / FIFOMonitor**: Collects DUT output into a `LogicSequence` via front-door signals.\n\n![Buffer](./doc/pic/03_buffer.png)\n\n- **Buffer**: Memory model with both front-door (HDL) and back-door (software) access.\n- **TileMapping**: Rearranges a Tensor into a Matrix, then packs into a `LogicSequence`.\n- **AddressMapping**: Generates address sequences for back-door memory access.\n\n# Running with Verilator/VCS Using Built-in Runner\n\n`torchbit.runner` includes pre-built Cocotb launch wrappers that configure common simulator parameters. You can either write your testbench using standard Cocotb interfaces or leverage Torchbit's helper functions.\n\nFirst, create your main test file (`top_test.py`) and a source file list. The file list can use paths relative to any location.\n\n```python\n# top_test.py\nfrom torchbit.runner import (\n    Runner,\n    FileConfig,\n    BuildConfig,\n    DEFAULT_VCS_BUILD_CONFIG, # DEFAULT_VERILATOR_BUILD_CONFIG if use verilator\n    read_filelist\n)\nimport cocotb\n\n# User Modifiable Variables\nfile_config_name = \"my_design_name\" # Name used to identify the build_dir, can be set to the top module name.\nfilelist_path = \"path to filelist\" # Path to your Verilog/SystemVerilog filelist.\nfilelist_base_path = \"path relative to filelist\" # Base path for relative paths in the filelist.\ntop_design_name = \"top_module_name\" # The name of your top-level design module.\n# include_dirs = [\"inc_dir1\", \"inc_dir2\"] # Add include directories if you have any.\noutput_dir = \"output_files\" # The parent directory where output files should be generated.\n\n\n\nTOP_FILE_CONFIG = FileConfig(\n    name=file_config_name,\n    sources=read_filelist(filelist_path, base_path=filelist_base_path),\n    top_design=top_design_name,\n    includes=include_dirs\n)\n\nTOP_RUNNER = Runner(\n    file_config=TOP_FILE_CONFIG,\n    build_config=DEFAULT_VCS_BUILD_CONFIG,\n    current_dir=output_dir\n)\n\n@cocotb.test()\nasync def testbench():\n    # writing your testbench here\n\nif __name__ == \"__main__\":\n    TOP_RUNNER.test(\"top_test\")\n\n```\n\nThen, simply run `python top_test.py`. After execution, a `sim_xx` folder will be generated under `output_dir`. Inside this directory, you will find the compiled files and corresponding waveforms. If using Verilator, the waveform file is `dump.fst`; if using VCS, it is `dump.fsdb`.\n\nThe `.fsdb` file stores the runtime database. You can view the corresponding source code directly by running `verdi -ssf dump.fsdb`.\n\n\n\n"
      },
      "plugins": [
        {
          "name": "torchbit",
          "source": "./",
          "description": "Torchbit: Utilities for deep learning accelerator development, including testbench reporting, data conversion, and tiling tools",
          "version": "2.4.2",
          "author": {
            "name": "ShuchengDu",
            "email": "shuchengdu@ust.hk"
          },
          "homepage": "https://github.com/Devil-SX/torchbit",
          "repository": "https://github.com/Devil-SX/torchbit",
          "license": "MIT",
          "keywords": [
            "deep-learning",
            "accelerator",
            "cocotb",
            "torchbit",
            "testbench",
            "verification"
          ],
          "category": "development",
          "strict": false,
          "skills": "./skills/",
          "categories": [
            "accelerator",
            "cocotb",
            "deep-learning",
            "development",
            "testbench",
            "torchbit",
            "verification"
          ],
          "install_commands": [
            "/plugin marketplace add Devil-SX/torchbit",
            "/plugin install torchbit@torchbit"
          ]
        }
      ]
    }
  ]
}