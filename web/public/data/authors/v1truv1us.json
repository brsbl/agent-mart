{
  "author": {
    "id": "v1truv1us",
    "display_name": "John Ferguson",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/28580642?v=4",
    "url": "https://github.com/v1truv1us",
    "bio": "Software Architect for RainFocus",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 5,
      "total_commands": 10,
      "total_skills": 2,
      "total_stars": 0,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "code-plugin-marketplace",
      "version": "1.0.0",
      "description": "A curated collection of Claude Code plugins for productivity, development tools, and prompt optimization.",
      "owner_info": {
        "name": "Anthropic",
        "email": "plugins@anthropic.com"
      },
      "keywords": [],
      "repo_full_name": "v1truv1us/plugin-marketplace",
      "repo_url": "https://github.com/v1truv1us/plugin-marketplace",
      "repo_description": null,
      "homepage": null,
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-01-29T15:22:00Z",
        "created_at": "2026-01-25T14:50:15Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 3511
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/marketplace-manager",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/marketplace-manager/README.md",
          "type": "blob",
          "size": 16813
        },
        {
          "path": "plugins/marketplace-manager/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/marketplace-manager/agents/marketplace-validator.md",
          "type": "blob",
          "size": 6505
        },
        {
          "path": "plugins/marketplace-manager/agents/plugin-reviewer.md",
          "type": "blob",
          "size": 3378
        },
        {
          "path": "plugins/marketplace-manager/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/marketplace-manager/commands/add-to-marketplace.md",
          "type": "blob",
          "size": 2985
        },
        {
          "path": "plugins/marketplace-manager/commands/create-plugin.md",
          "type": "blob",
          "size": 2097
        },
        {
          "path": "plugins/marketplace-manager/commands/list-plugins.md",
          "type": "blob",
          "size": 4059
        },
        {
          "path": "plugins/marketplace-manager/commands/update-docs.md",
          "type": "blob",
          "size": 4041
        },
        {
          "path": "plugins/marketplace-manager/commands/validate-marketplace.md",
          "type": "blob",
          "size": 4641
        },
        {
          "path": "plugins/marketplace-manager/commands/validate-plugin.md",
          "type": "blob",
          "size": 2879
        },
        {
          "path": "plugins/marketplace-manager/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/marketplace-manager/skills/marketplace-management.md",
          "type": "blob",
          "size": 2308
        },
        {
          "path": "plugins/marketplace-manager/skills/plugin-authoring.md",
          "type": "blob",
          "size": 2755
        },
        {
          "path": "plugins/plugin-improver",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-improver/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-improver/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 706
        },
        {
          "path": "plugins/plugin-improver/README.md",
          "type": "blob",
          "size": 8329
        },
        {
          "path": "plugins/plugin-improver/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-improver/agents/best-practices-evaluator-agent.md",
          "type": "blob",
          "size": 8066
        },
        {
          "path": "plugins/plugin-improver/agents/improver-coordinator-agent.md",
          "type": "blob",
          "size": 5386
        },
        {
          "path": "plugins/plugin-improver/agents/prompt-optimizer-agent.md",
          "type": "blob",
          "size": 9996
        },
        {
          "path": "plugins/plugin-improver/agents/quality-analyzer-agent.md",
          "type": "blob",
          "size": 9642
        },
        {
          "path": "plugins/plugin-improver/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-improver/commands/improve-plugin.md",
          "type": "blob",
          "size": 2494
        },
        {
          "path": "plugins/plugin-improver/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-improver/skills/architecture-patterns.md",
          "type": "blob",
          "size": 11925
        },
        {
          "path": "plugins/plugin-improver/skills/best-practices-reference.md",
          "type": "blob",
          "size": 8025
        },
        {
          "path": "plugins/plugin-improver/skills/prompt-enhancement.md",
          "type": "blob",
          "size": 9444
        },
        {
          "path": "plugins/prompt-orchestrator",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/prompt-orchestrator/README.md",
          "type": "blob",
          "size": 8865
        },
        {
          "path": "plugins/prompt-orchestrator/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/prompt-orchestrator/agents/context-gatherer-agent.md",
          "type": "blob",
          "size": 7458
        },
        {
          "path": "plugins/prompt-orchestrator/agents/execution-router-agent.md",
          "type": "blob",
          "size": 7247
        },
        {
          "path": "plugins/prompt-orchestrator/agents/problem-discovery-agent.md",
          "type": "blob",
          "size": 8560
        },
        {
          "path": "plugins/prompt-orchestrator/agents/prompt-assessor-agent.md",
          "type": "blob",
          "size": 7513
        },
        {
          "path": "plugins/prompt-orchestrator/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/prompt-orchestrator/commands/orchestrate.md",
          "type": "blob",
          "size": 3845
        },
        {
          "path": "plugins/prompt-orchestrator/commands/orchestrator.md",
          "type": "blob",
          "size": 2283
        },
        {
          "path": "plugins/prompt-orchestrator/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/prompt-orchestrator/hooks/gate.py",
          "type": "blob",
          "size": 5594
        },
        {
          "path": "plugins/prompt-orchestrator/hooks/hooks.md",
          "type": "blob",
          "size": 3609
        },
        {
          "path": "plugins/prompt-orchestrator/hooks/init-session.py",
          "type": "blob",
          "size": 2661
        },
        {
          "path": "plugins/prompt-orchestrator/hooks/user-prompt-submit.md",
          "type": "blob",
          "size": 1951
        },
        {
          "path": "plugins/subagent-creator",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/subagent-creator/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/subagent-creator/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 496
        },
        {
          "path": "plugins/subagent-creator/README.md",
          "type": "blob",
          "size": 2894
        },
        {
          "path": "plugins/subagent-creator/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/subagent-creator/agents/subagent-architect.md",
          "type": "blob",
          "size": 5758
        },
        {
          "path": "plugins/subagent-creator/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/subagent-creator/commands/create-subagent.md",
          "type": "blob",
          "size": 2182
        },
        {
          "path": "plugins/subagent-creator/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/subagent-creator/skills/subagent-design-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/subagent-creator/skills/subagent-design-patterns/SKILL.md",
          "type": "blob",
          "size": 3151
        },
        {
          "path": "plugins/subagent-creator/skills/subagent-design-patterns/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/subagent-creator/skills/subagent-design-patterns/references/role-clarity.md",
          "type": "blob",
          "size": 8776
        },
        {
          "path": "plugins/subagent-creator/skills/subagent-design-patterns/references/tool-patterns.md",
          "type": "blob",
          "size": 8925
        },
        {
          "path": "plugins/subagent-creator/skills/subagent-implementation",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/subagent-creator/skills/subagent-implementation/SKILL.md",
          "type": "blob",
          "size": 3260
        },
        {
          "path": "plugins/subagent-creator/skills/subagent-implementation/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/subagent-creator/skills/subagent-implementation/examples/complete-analyzer-example.md",
          "type": "blob",
          "size": 3179
        },
        {
          "path": "plugins/subagent-creator/skills/subagent-implementation/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/subagent-creator/skills/subagent-implementation/references/frontmatter-reference.md",
          "type": "blob",
          "size": 9713
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"code-plugin-marketplace\",\n  \"version\": \"1.0.0\",\n  \"description\": \"A curated collection of Claude Code plugins for productivity, development tools, and prompt optimization.\",\n  \"owner\": {\n    \"name\": \"Anthropic\",\n    \"email\": \"plugins@anthropic.com\"\n  },\n  \"repository\": \"https://github.com/anthropics/claude-code-plugins\",\n  \"license\": \"MIT\",\n  \"plugins\": [\n    {\n      \"name\": \"marketplace-manager\",\n      \"source\": \"./plugins/marketplace-manager\",\n      \"description\": \"Create, validate, and manage plugins in Claude Code plugin marketplaces. Includes scaffolding, validation, and documentation generation.\",\n      \"version\": \"1.0.0\",\n      \"author\": {\n        \"name\": \"Anthropic\",\n        \"email\": \"plugins@anthropic.com\"\n      },\n      \"category\": \"development\",\n      \"keywords\": [\"marketplace\", \"plugin-management\", \"scaffolding\", \"validation\", \"development-tools\"],\n      \"repository\": \"https://github.com/anthropics/marketplace-manager\"\n    },\n    {\n      \"name\": \"day-week-planner\",\n      \"source\": \"./plugins/planner\",\n      \"description\": \"Interactive day and week planning with Eisenhower matrix prioritization, time-blocking, and Jira/GitHub integration.\",\n      \"version\": \"1.0.0\",\n      \"author\": {\n        \"name\": \"Planning Team\",\n        \"email\": \"support@example.com\"\n      },\n      \"category\": \"productivity\",\n      \"keywords\": [\"planning\", \"productivity\", \"scheduling\", \"eisenhower-matrix\", \"jira\", \"github\", \"time-blocking\"],\n      \"repository\": \"https://github.com/yourusername/day-week-planner\"\n    },\n    {\n      \"name\": \"prompt-orchestrator\",\n      \"source\": \"./plugins/prompt-orchestrator\",\n      \"description\": \"Two-tier prompt orchestration: Haiku for discovery/refinement, Sonnet/Opus for execution. Uncovers real problems through Socratic questioning, refines context, and optimizes prompts before expensive model execution. Saves 60-80% on clarification costs.\",\n      \"version\": \"2.0.0\",\n      \"author\": {\n        \"name\": \"Engineering Team\",\n        \"email\": \"team@example.com\"\n      },\n      \"category\": \"development\",\n      \"keywords\": [\"prompt-orchestration\", \"cost-optimization\", \"model-selection\", \"quality-assessment\"],\n      \"repository\": \"https://github.com/anthropics/prompt-orchestrator\"\n    },\n    {\n      \"name\": \"subagent-creator\",\n      \"source\": \"./plugins/subagent-creator\",\n      \"description\": \"Interactive plugin for creating, designing, and implementing custom subagents in Claude Code with guided best practices\",\n      \"version\": \"0.1.0\",\n      \"author\": {\n        \"name\": \"Claude Code Community\",\n        \"email\": \"support@anthropic.com\"\n      },\n      \"category\": \"development\",\n      \"keywords\": [\"subagents\", \"agent-creation\", \"agent-design\", \"workflow-automation\"],\n      \"repository\": \"https://github.com/anthropics/claude-code\"\n    },\n    {\n      \"name\": \"plugin-improver\",\n      \"source\": \"./plugins/plugin-improver\",\n      \"description\": \"Iteratively evaluate and enhance plugins with Anthropic best practices. Analyzes quality, suggests concrete improvements, and integrates with Ralph Loop for continuous self-improvement.\",\n      \"version\": \"0.1.0\",\n      \"author\": {\n        \"name\": \"Plugin Development Team\",\n        \"email\": \"support@example.com\"\n      },\n      \"category\": \"development\",\n      \"keywords\": [\"plugin-improvement\", \"quality-assessment\", \"best-practices\", \"prompt-optimization\", \"iterative-enhancement\", \"continuous-improvement\"],\n      \"repository\": \"https://github.com/anthropics/claude-code-plugins\"\n    }\n  ]\n}\n",
        "plugins/marketplace-manager/README.md": "# Marketplace Manager\n\nCreate, validate, and manage plugins in Claude Code plugin marketplaces. Includes scaffolding, validation, and documentation generation.\n\n**Version:** 1.0.0\n**Category:** Development\n**License:** MIT\n\n## Features\n\n- **Plugin Scaffolding** - Create new Claude Code plugins with proper structure\n- **Comprehensive Validation** - Validate plugin structure and best practices\n- **Marketplace Management** - Add plugins to and validate plugin marketplaces\n- **Documentation Generation** - Auto-generate marketplace README files\n- **Quality Assurance** - Expert agents for plugin and marketplace review\n- **Best Practices Guide** - Ambient skills with plugin authoring guidance\n\n## Installation\n\n### From Claude Code Marketplace\n\n```bash\n# Add from marketplace\n/add-to-marketplace plugins/marketplace-manager\n```\n\n### Local Installation\n\nClone or download the plugin to your `.claude-plugins` directory:\n\n```bash\ncd .claude-plugins\ngit clone https://github.com/anthropics/marketplace-manager.git\n```\n\nOr copy the plugin directory directly:\n\n```bash\ncp -r marketplace-manager ~/.claude-plugins/\n```\n\n## Quick Start\n\n### Create Your First Plugin\n\n```bash\n/create-plugin my-awesome-plugin \"A plugin that does awesome things\"\n```\n\nThis scaffolds:\n- Plugin directory structure\n- `plugin.json` manifest\n- Component directories (commands, agents, skills)\n- Example README.md\n\n### Validate Plugin Quality\n\n```bash\n/validate-plugin ./plugins/my-awesome-plugin\n```\n\nReports:\n- ✓ Structure validation\n- ✓ Best practices compliance\n- ✓ Documentation quality\n- Status: VALID, VALID_WITH_WARNINGS, or INVALID\n\n### Add to Marketplace\n\n```bash\n/add-to-marketplace ./plugins/my-awesome-plugin --category development\n```\n\nCreates marketplace entry with:\n- Plugin metadata extraction\n- Duplicate checking\n- marketplace.json updates\n- Documentation sync\n\n### Validate Marketplace\n\n```bash\n/validate-marketplace . --deep\n```\n\nValidates:\n- Marketplace structure\n- All plugin entries\n- Local plugin sources\n- Documentation consistency\n\n### List Plugins\n\n```bash\n/list-plugins . --format table\n```\n\nOutput formats: `table`, `json`, `markdown`\n\n### Update Documentation\n\n```bash\n/update-docs\n```\n\nGenerates:\n- Plugin table\n- Installation instructions\n- Per-plugin sections\n- Contributing guidelines\n\n## Commands\n\n### `/create-plugin`\n\nScaffold a new Claude Code plugin with proper directory structure.\n\n**Arguments:**\n- `plugin-name` (required) - Plugin identifier in kebab-case\n- `description` (required) - Short description (10-200 characters)\n- `author-name` (optional) - Author's name\n- `author-email` (optional) - Author's email address\n\n**Usage:**\n```bash\n/create-plugin my-plugin \"Plugin description\"\n/create-plugin utility-tool \"Helper utilities\" --author-name \"Jane Doe\" --author-email \"jane@example.com\"\n```\n\n**Creates:**\n- `.claude-plugins/my-plugin/` directory structure\n- `plugin.json` manifest\n- `commands/`, `agents/`, `skills/` directories\n- Example components\n- `README.md` template\n\n### `/add-to-marketplace`\n\nAdd a validated plugin to a marketplace with full verification.\n\n**Arguments:**\n- `plugin-path` (required) - Path to plugin directory\n- `marketplace-path` (optional) - Path to marketplace (defaults to `.`)\n- `category` (optional) - Plugin category\n\n**Valid Categories:**\n- `development` - Development tools\n- `productivity` - Productivity enhancements\n- `integration` - External integrations\n- `testing` - Testing and QA\n- `documentation` - Documentation tools\n- `security` - Security tools\n- `devops` - DevOps and deployment\n- `lsp` - Language server integrations\n- `mcp` - Model context protocol servers\n\n**Usage:**\n```bash\n/add-to-marketplace ./plugins/my-plugin --category development\n/add-to-marketplace ../plugin --marketplace-path ./marketplace\n```\n\n**Process:**\n1. Validates plugin structure\n2. Checks for duplicates\n3. Creates marketplace entry\n4. Updates marketplace.json\n5. Optionally updates README\n\n### `/validate-plugin`\n\nComprehensive validation of plugin structure and best practices.\n\n**Arguments:**\n- `plugin-path` (required) - Path to plugin to validate\n- `strict` (optional) - Enable strict mode (warnings become errors)\n\n**Usage:**\n```bash\n/validate-plugin ./plugins/my-plugin\n/validate-plugin . --strict\n```\n\n**Validates:**\n- Directory structure\n- `plugin.json` completeness\n- Component presence\n- Documentation quality\n- Best practices compliance\n\n**Output:**\n- ✓ VALID - Ready for marketplace\n- ⚠ VALID_WITH_WARNINGS - Valid but has improvements needed\n- ✗ INVALID - Has errors to fix\n\n### `/validate-marketplace`\n\nValidate marketplace structure and all plugin entries.\n\n**Arguments:**\n- `marketplace-path` (optional) - Path to marketplace (defaults to `.`)\n- `deep` (optional) - Validate all local plugins\n\n**Usage:**\n```bash\n/validate-marketplace\n/validate-marketplace ./marketplace --deep\n```\n\n**Validates:**\n- marketplace.json schema\n- All plugin entries\n- Source path existence\n- Duplicate detection\n- Documentation consistency\n\n**With --deep flag:**\n- Validates each local plugin structure\n- Checks plugin.json in all plugins\n- Verifies component presence\n\n### `/list-plugins`\n\nList all plugins in a marketplace with details.\n\n**Arguments:**\n- `marketplace-path` (optional) - Path to marketplace (defaults to `.`)\n- `format` (optional) - Output format (table, json, markdown)\n\n**Usage:**\n```bash\n/list-plugins                              # Table format\n/list-plugins ./marketplace --format json  # JSON output\n/list-plugins . --format markdown          # Markdown listing\n```\n\n**Display Information:**\n- Plugin name and version\n- Category and author\n- Description\n- Source location\n\n### `/update-docs`\n\nUpdate marketplace README.md to match marketplace.json entries.\n\n**Arguments:**\n- `marketplace-path` (optional) - Path to marketplace (defaults to `.`)\n\n**Usage:**\n```bash\n/update-docs\n/update-docs ./marketplace\n```\n\n**Generates:**\n- Marketplace header and owner info\n- Plugin table with all entries\n- Installation instructions\n- Per-plugin detail sections\n- Contributing guidelines\n\n**Ensures:**\n- Plugin table matches marketplace.json\n- All new plugins documented\n- Versions are current\n- Categories are correct\n\n## Agents\n\n### Plugin Reviewer\n\nExpert agent for comprehensive plugin quality assessment.\n\n**Capabilities:**\n- Plugin structure review\n- Code quality assessment\n- Documentation evaluation\n- Security analysis\n- Best practices enforcement\n\n**Invoked by:**\n- `/validate-plugin` with detailed review\n- `/add-to-marketplace` pre-submission check\n- Manual invocation for audit\n\n**Output:**\n- Overall quality score (0-100)\n- Component-by-component analysis\n- Issue categorization\n- Improvement recommendations\n- Marketplace readiness assessment\n\n### Marketplace Validator\n\nExpert agent for marketplace validation and release readiness.\n\n**Capabilities:**\n- Marketplace schema validation\n- Plugin entry verification\n- Local plugin validation\n- Documentation consistency\n- Release readiness assessment\n\n**Invoked by:**\n- `/validate-marketplace` command\n- `/validate-marketplace --deep` for full validation\n- Pre-release verification\n\n**Output:**\n- Comprehensive validation report\n- Plugin-by-plugin status\n- Documentation sync verification\n- Release readiness status\n\n## Skills\n\n### Plugin Authoring\n\nAmbient guidance for creating high-quality Claude Code plugins.\n\n**Covers:**\n- Plugin structure standards\n- Directory layout conventions\n- plugin.json template and schema\n- Component templates (commands, agents, skills)\n- Naming conventions (kebab-case)\n- Best practices and security\n- Version control and releases\n- Testing and validation\n\n**Helps with:**\n- Creating new plugins\n- Understanding plugin.json schema\n- Component file structure\n- Documentation standards\n- Common mistakes to avoid\n\n### Marketplace Management\n\nAmbient guidance for managing plugin marketplaces.\n\n**Covers:**\n- Marketplace structure and layout\n- marketplace.json schema\n- Plugin entry formats (local, GitHub, Git URLs)\n- Valid categories and tags\n- Adding and updating plugins\n- Removing plugins\n- Documentation standards\n- Quality standards enforcement\n- Release management\n\n**Helps with:**\n- Creating marketplaces\n- Adding plugins to marketplace\n- Validating marketplace integrity\n- Managing plugin versions\n- Documentation synchronization\n\n## Scripts\n\n### validate-plugin.sh\n\nBash script for plugin structure validation using jq for JSON parsing.\n\n**Usage:**\n```bash\n./scripts/validate-plugin.sh /path/to/plugin\n./scripts/validate-plugin.sh . -strict\n```\n\n**Checks:**\n- `.claude-plugins/` directory\n- `plugin.json` validity and fields\n- Component existence\n- `README.md` presence\n- Naming conventions\n- Version format\n\n**Output:**\n- Colored status (✓✗⚠)\n- Detailed check results\n- Exit code 0 for valid, 1 for invalid\n\n### validate-marketplace.sh\n\nBash script for marketplace structure validation.\n\n**Usage:**\n```bash\n./scripts/validate-marketplace.sh /path/to/marketplace\n./scripts/validate-marketplace.sh . --deep\n```\n\n**Checks:**\n- `marketplace.json` schema\n- Plugin entries\n- Source path existence\n- Duplicate detection\n- Local plugin validation (--deep)\n\n**Output:**\n- Colored status report\n- Plugin-by-plugin validation\n- Marketplace integrity summary\n- Exit code 0 for valid, 1 for invalid\n\n## Plugin Structure Reference\n\n### Directory Layout\n\n```\nmy-plugin/\n├── .claude-plugins/\n│   └── my-plugin/\n│       ├── plugin.json          # Plugin manifest\n│       ├── commands/            # Slash commands\n│       ├── agents/              # AI agents\n│       ├── skills/              # Ambient skills\n│       ├── hooks/               # Event hooks (optional)\n│       ├── scripts/             # Utility scripts (optional)\n│       └── README.md            # Documentation\n└── LICENSE                      # License file (optional)\n```\n\n### plugin.json Schema\n\n```json\n{\n  \"name\": \"plugin-name\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Plugin description\",\n  \"category\": \"development\",\n  \"author\": {\n    \"name\": \"Author Name\",\n    \"email\": \"author@example.com\"\n  },\n  \"license\": \"MIT\",\n  \"keywords\": [\"tag1\", \"tag2\"],\n  \"components\": {\n    \"commands\": [\"cmd1\", \"cmd2\"],\n    \"agents\": [\"agent1\"],\n    \"skills\": [\"skill1\"]\n  }\n}\n```\n\n### Plugin Naming\n\n- **kebab-case** (lowercase, hyphens): `my-awesome-plugin` ✓\n- Not camelCase: `myAwesomePlugin` ✗\n- Not snake_case: `my_awesome_plugin` ✗\n- Not UPPERCASE: `MY-AWESOME-PLUGIN` ✗\n\n### Versioning\n\nFollow semantic versioning (X.Y.Z):\n- **X** - Major (breaking changes)\n- **Y** - Minor (new features, backward compatible)\n- **Z** - Patch (bug fixes)\n\nExamples: `0.1.0`, `1.0.0`, `1.2.3`\n\n## Marketplace Structure Reference\n\n### Directory Layout\n\n```\nmarketplace/\n├── marketplace.json     # Marketplace registry\n├── README.md           # Generated/manual documentation\n├── CONTRIBUTING.md     # Contributing guidelines (optional)\n└── plugins/\n    ├── plugin1/\n    ├── plugin2/\n    └── plugin3/\n```\n\n### marketplace.json Schema\n\n```json\n{\n  \"name\": \"My Plugin Marketplace\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Description of marketplace\",\n  \"owner\": {\n    \"name\": \"Owner Name\",\n    \"email\": \"owner@example.com\",\n    \"url\": \"https://example.com\"\n  },\n  \"repository\": \"https://github.com/example/marketplace\",\n  \"license\": \"MIT\",\n  \"plugins\": [\n    {\n      \"name\": \"my-plugin\",\n      \"source\": \"./plugins/my-plugin\",\n      \"description\": \"Plugin description\",\n      \"version\": \"1.0.0\",\n      \"author\": \"Author Name\",\n      \"category\": \"development\",\n      \"keywords\": [\"tag1\", \"tag2\"],\n      \"repository\": \"https://github.com/author/plugin\"\n    }\n  ]\n}\n```\n\n### Plugin Entry Fields\n\n**Required:**\n- `name` - Plugin identifier (kebab-case)\n- `source` - Path or URL to plugin\n- `description` - Short description\n\n**Optional:**\n- `version` - Semantic version\n- `author` - Plugin author\n- `category` - Plugin category\n- `keywords` - Search tags\n- `repository` - Source repository URL\n- `documentation` - Documentation URL\n- `homepage` - Plugin website\n\n### Valid Categories\n\n| Category | Description |\n|----------|-------------|\n| development | Development tools, linters, formatters |\n| productivity | Workflow tools, automation |\n| integration | External service connections |\n| testing | Test frameworks, QA tools |\n| documentation | Doc generation, API documentation |\n| security | Security analysis, vulnerability scanning |\n| devops | CI/CD, deployment, infrastructure |\n| lsp | Language server integrations |\n| mcp | Model context protocol servers |\n\n## Complete Workflow Example\n\n### 1. Create Plugin\n\n```bash\n/create-plugin code-formatter \"Format and lint code files\"\n```\n\n### 2. Develop Components\n\nAdd commands, agents, and skills to your plugin:\n\n```\n.claude-plugins/code-formatter/\n├── commands/\n│   └── format-code.md\n├── agents/\n│   └── format-reviewer.md\n├── skills/\n│   └── formatting-best-practices.md\n└── README.md\n```\n\n### 3. Validate Plugin\n\n```bash\n/validate-plugin ./.claude-plugins/code-formatter\n```\n\nExpected output:\n```\n✓ VALID\nPlugin is ready for marketplace\n```\n\n### 4. Set Up Marketplace\n\nCreate `marketplace.json` in your project:\n\n```json\n{\n  \"name\": \"Code Tools Marketplace\",\n  \"owner\": {\n    \"name\": \"Your Name\",\n    \"email\": \"you@example.com\"\n  },\n  \"plugins\": []\n}\n```\n\n### 5. Add to Marketplace\n\n```bash\n/add-to-marketplace ./.claude-plugins/code-formatter --category development\n```\n\n### 6. Validate Marketplace\n\n```bash\n/validate-marketplace . --deep\n```\n\n### 7. Update Documentation\n\n```bash\n/update-docs\n```\n\n### 8. List All Plugins\n\n```bash\n/list-plugins . --format table\n```\n\n### 9. Publish\n\nCommit changes and share marketplace:\n\n```bash\ngit add marketplace.json README.md\ngit commit -m \"Add code-formatter plugin\"\ngit push\n```\n\n## Validation Rules\n\n### Plugin Names\n- Must be kebab-case (lowercase with hyphens)\n- Examples: `my-plugin`, `awesome-tool`\n- Invalid: `MyPlugin`, `my_plugin`\n\n### Versions\n- Must follow semver (X.Y.Z)\n- Examples: `1.0.0`, `2.5.3`\n- Invalid: `1.0`, `v1.0.0`\n\n### Descriptions\n- Should be 10-200 characters\n- Clear and descriptive\n- Single or brief multi-line\n\n### Components\n- At least one required\n- Can have commands, agents, skills, hooks, or .mcp.json\n- Each component in proper directory\n\n### Marketplace\n- No duplicate plugin names\n- All source paths must exist\n- Plugin names match between marketplace.json and plugin.json\n\n## Best Practices\n\n### Naming\n✓ Use descriptive, kebab-case names\n✓ Keep names under 30 characters\n✓ Avoid generic names\n✓ Use prefixes for related commands\n\n### Organization\n✓ Keep components focused\n✓ Group related functionality\n✓ Use clear directory structure\n✓ Document everything\n\n### Documentation\n✓ Write README first (clarifies purpose)\n✓ Include usage examples\n✓ Document all arguments\n✓ Add troubleshooting section\n\n### Quality\n✓ Validate before adding to marketplace\n✓ Test all components\n✓ Handle errors gracefully\n✓ Keep code simple and focused\n\n### Security\n✓ Validate user inputs\n✓ Don't hardcode secrets\n✓ Use safe defaults\n✓ Document security considerations\n\n## Common Issues\n\n### Plugin validation fails\n- Check naming conventions (kebab-case)\n- Verify plugin.json has required fields\n- Ensure at least one component exists\n- Run with `--strict` for detailed feedback\n\n### Marketplace validation fails\n- Check marketplace.json is valid JSON\n- Verify all plugin sources exist\n- Check for duplicate plugin names\n- Ensure owner information is complete\n\n### Documentation out of sync\n- Run `/update-docs` after changes\n- Verify all plugins are listed\n- Check version numbers match\n- Test links and references\n\n## Troubleshooting\n\n### Plugin directory not found\n```bash\n# Make sure path is correct\n/validate-plugin ./path/to/plugin\n\n# Check directory structure\nls -la .claude-plugins/my-plugin/\n```\n\n### marketplace.json invalid\n```bash\n# Validate JSON\njq . marketplace.json\n\n# Check with validation script\n./scripts/validate-marketplace.sh .\n```\n\n### Source paths not found\n- Verify relative paths are correct\n- Check path separators (/ not \\)\n- Use absolute paths if needed\n- Ensure plugin directories exist\n\n## Contributing\n\nContributions are welcome! To add your plugin to the marketplace:\n\n1. Create and test your plugin\n2. Run `/validate-plugin` to ensure quality\n3. Add to marketplace with `/add-to-marketplace`\n4. Submit PR with marketplace.json changes\n5. Include documentation updates\n\n## License\n\nMIT License - See LICENSE file for details\n\n## Support\n\nFor questions and support:\n- Check the skills for guidance\n- Review example plugins\n- Use validation agents for feedback\n- Consult the documentation sections\n\n---\n\n**Made with ❤️ for the Claude Code community**\n",
        "plugins/marketplace-manager/agents/marketplace-validator.md": "---\nname: marketplace-validator\ndescription: Expert agent for validating marketplace integrity and release readiness\nmodel: sonnet\ntools: [Read, Glob, Grep, Bash]\ncolor: green\n---\n\n# Marketplace Validator\n\nExpert agent for comprehensive marketplace validation and release readiness assessment.\n\n## Schema Validation Rules\n\nWhen validating a marketplace.json file, enforce these strict rules:\n\n### Marketplace-Level Schema\n- **name**: Must be kebab-case (lowercase, hyphens only, no spaces)\n  - ✓ Valid: \"code-plugin-marketplace\", \"my-plugins\"\n  - ✗ Invalid: \"Code Plugin Marketplace\", \"my_plugins\"\n- **version**: Must be semantic versioning (X.Y.Z)\n- **owner**: Must be an object with required fields:\n  - **name**: string (required)\n  - **email**: string (required, valid email format)\n- **license**: string (optional but recommended)\n- **repository**: string URL (optional)\n- **description**: string (required)\n- **plugins**: array (required, must have at least one plugin)\n\n### Plugin Entry Schema\nEach plugin in the plugins array must have:\n- **name**: kebab-case string (required)\n- **source**: string starting with \"./\" (required)\n  - ✗ Invalid: \"../plugins/my-plugin\", \"plugins/my-plugin\"\n  - ✓ Valid: \"./plugins/my-plugin\"\n- **description**: string (required)\n- **version**: semantic version string (required)\n- **author**: object with name and email (required, NOT a string)\n  - ✓ Valid: `{\"name\": \"Name\", \"email\": \"email@example.com\"}`\n  - ✗ Invalid: \"Author Name\" (string)\n- **category**: string from valid categories list (required)\n- **keywords**: array of strings (optional)\n- **repository**: string URL (optional)\n\n### Valid Categories\n- development\n- productivity\n- integration\n- testing\n- documentation\n- security\n- devops\n- lsp\n- mcp\n\n### Validation Process\n\n1. **Parse marketplace.json** - Verify it's valid JSON\n2. **Marketplace-level checks**:\n   - Check name is kebab-case\n   - Verify version format\n   - Validate owner object structure\n   - Check required fields present\n3. **Plugin entry checks** (for each plugin):\n   - Verify name is kebab-case\n   - Check source starts with \"./\"\n   - Validate author is object (not string)\n   - Check category is in valid list\n   - Verify all required fields present\n4. **Cross-checks**:\n   - No duplicate plugin names\n   - All source paths are readable/exist\n   - No conflicting plugin names\n5. **Report findings**:\n   - List all schema violations with line/field info\n   - Categorize as errors (blocking) vs warnings (non-blocking)\n   - Return exit status 0 for valid, 1 for invalid\n\n## Capabilities\n\n### Marketplace Schema Validation\n- marketplace.json structure validation\n- Required fields verification\n- Data type checking\n- Schema compliance\n\n### Plugin Entry Verification\n- Plugin name uniqueness\n- Source path validation\n- Metadata completeness\n- Category correctness\n\n### Local Plugin Validation\n- Plugin directory structure checks\n- plugin.json synchronization\n- Component presence verification\n- Documentation consistency\n\n### Documentation Consistency\n- README.md accuracy\n- Plugin table synchronization\n- Installation instructions\n- Link and reference validation\n\n### Release Readiness Assessment\n- All plugins validated\n- Documentation complete\n- No missing or broken references\n- Marketplace integrity verified\n\n## When to Use\n\nInvoke this agent to:\n- Validate marketplace before release\n- Check all plugins for consistency\n- Prepare marketplace for distribution\n- Audit marketplace structure\n- Verify documentation accuracy\n\n## Triggers\n\nThe agent is automatically invoked by:\n- `/validate-marketplace` command\n- `/validate-marketplace --deep` with full validation\n- Pre-release marketplace verification\n- Manual invocation for thorough audit\n\n## Input\n\nProvide the marketplace-validator with:\n- Path to marketplace directory\n- marketplace.json location\n- List of plugins to validate\n- Validation depth (standard or deep)\n- Release readiness check requirement\n\n## Output\n\nReturns comprehensive validation report:\n\n```\nMarketplace Validation Report\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nMarketplace: Plugin Marketplace v1.0\nOwner: Acme Corp (acme@example.com)\nLocation: /path/to/marketplace\n\nSchema Validation: ✓ PASS\n- marketplace.json valid\n- All required fields present\n- Structure compliant\n\nPlugin Entries: ✓ PASS\n- 5 plugins registered\n- All names unique\n- All categories valid\n- Sources verified\n\nLocal Plugins: ✓ PASS\n- my-plugin: v1.0.0 ✓\n- utility-helper: v2.1.0 ✓\n- integration-tool: v1.5.2 ✓\n- testing-framework: v3.0.0 ✓\n- security-scanner: v1.2.1 ✓\n\nDocumentation: ✓ PASS\n- README.md current\n- Plugin table accurate\n- All references valid\n\nRelease Readiness: ✓ READY\nStatus: ✓ Ready for production release\n\nSummary: All checks passed. Marketplace is valid and ready.\n```\n\n## Validation Levels\n\n### Standard Validation\n- marketplace.json schema check\n- Plugin entry verification\n- Source path validation\n- Duplicate detection\n- Documentation consistency\n\n### Deep Validation (--deep flag)\nIncludes standard checks plus:\n- Individual plugin validation\n- plugin.json verification\n- Component structure check\n- README presence\n- Full metadata audit\n\n### Pre-Release Validation\nStrictest mode for production release:\n- All standard and deep checks\n- Release notes review\n- Version consistency\n- Changelog verification\n- Breaking change assessment\n\n## Advanced Features\n\n### Batch Validation\nValidate multiple marketplaces:\n- Compare marketplace structures\n- Identify inconsistencies\n- Share best practices\n- Consolidate plugins\n\n### Dependency Analysis\nCheck plugin dependencies:\n- External dependencies\n- Plugin interdependencies\n- MCP server requirements\n- Version compatibility\n\n### Quality Metrics\nGenerate quality scores:\n- Plugin count and diversity\n- Documentation completeness\n- Marketplace maturity\n- Release readiness percentage\n\n## Common Issues Found\n\nThe validator detects:\n- Duplicate plugin names\n- Invalid source paths\n- Missing marketplace fields\n- Out-of-sync documentation\n- Invalid plugin names\n- Schema violations\n- Broken references\n- Version mismatches\n\n## Integration\n\nWorks seamlessly with:\n- `/validate-marketplace` command\n- `/validate-plugin` for individual plugins\n- `/update-docs` for documentation sync\n- `/add-to-marketplace` for new entries\n\n## Output Formats\n\nReports available in:\n- Human-readable text\n- JSON for programmatic use\n- Markdown for documentation\n- CSV for tracking\n",
        "plugins/marketplace-manager/agents/plugin-reviewer.md": "---\nname: plugin-reviewer\ndescription: Expert agent for reviewing plugins before marketplace submission\nmodel: sonnet\ntools: [Read, Glob, Grep]\ncolor: blue\n---\n\n# Plugin Reviewer\n\nExpert agent for comprehensive plugin quality assessment and best practices validation.\n\n## Capabilities\n\n### Plugin Structure Review\n- Validates directory layout and organization\n- Checks component file presence and structure\n- Reviews plugin.json completeness and accuracy\n- Assesses naming conventions\n\n### Code Quality Assessment\n- Analyzes command implementations\n- Reviews agent system prompts and logic\n- Evaluates skill documentation\n- Checks for code consistency\n\n### Documentation Review\n- README.md comprehensiveness\n- Usage examples and clarity\n- API documentation quality\n- Comments and inline documentation\n\n### Security Analysis\n- Dependency review (if applicable)\n- Permission and capability scope\n- Safe tool usage patterns\n- Error handling and edge cases\n\n### Best Practices Enforcement\n- Claude Code conventions\n- Component organization\n- Component reusability\n- Error handling patterns\n- Documentation standards\n\n## When to Use\n\nInvoke this agent to:\n- Review plugins before adding to marketplace\n- Get detailed quality assessment\n- Identify improvement opportunities\n- Verify best practices compliance\n- Prepare plugins for community sharing\n\n## Triggers\n\nThe agent is automatically invoked by:\n- `/validate-plugin` command with detailed review\n- `/add-to-marketplace` pre-submission review\n- Manual invocation for comprehensive audit\n\n## Input\n\nProvide the plugin-reviewer with:\n- Path to plugin directory\n- Specific areas to focus on\n- Strictness level (standard or strict mode)\n- Context about plugin purpose\n\n## Output\n\nReturns comprehensive report including:\n- Overall quality score (0-100)\n- Component-by-component analysis\n- Issue categorization (errors, warnings, suggestions)\n- Best practices recommendations\n- Improvement roadmap\n- Marketplace readiness assessment\n\n## Example Review\n\n```\nPlugin Review Report: my-plugin\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nQuality Score: 92/100\nStatus: ✓ Ready for Marketplace\n\nStructure: ✓ Excellent\n- Proper directory organization\n- All required components present\n- Clean file structure\n\nCode Quality: ⚠ Good\n- Commands well-implemented\n- Documentation could be more detailed\n- Error handling is solid\n\nDocumentation: ✓ Excellent\n- Comprehensive README\n- Clear usage examples\n- Good component descriptions\n\nSecurity: ✓ Excellent\n- Proper input validation\n- Safe tool usage\n- Good error handling\n\nRecommendations:\n1. Add more detailed agent descriptions\n2. Include troubleshooting section in README\n3. Consider adding integration examples\n\nOverall Assessment: Excellent quality plugin, ready for marketplace\n```\n\n## Advanced Features\n\n### Customizable Review Focus\nRequest review of specific aspects:\n- Structure and organization only\n- Code quality deep dive\n- Documentation audit\n- Security assessment\n- Full comprehensive review\n\n### Comparison Analysis\nCompare multiple versions or plugins to:\n- Identify improvements\n- Ensure consistency\n- Share best practices\n- Track quality trends\n\n### Improvement Tracking\nMonitor plugin quality over time:\n- Before and after comparisons\n- Progress toward best practices\n- Version-to-version improvements\n",
        "plugins/marketplace-manager/commands/add-to-marketplace.md": "---\nname: add-to-marketplace\ndescription: Add a plugin to marketplace.json with full validation\nargs:\n  - name: plugin-path\n    type: string\n    required: true\n    description: Path to the plugin directory (relative or absolute)\n  - name: marketplace-path\n    type: string\n    required: false\n    description: Path to marketplace.json directory (defaults to current directory)\n  - name: category\n    type: string\n    required: false\n    description: Category for the plugin (development, productivity, integration, testing, documentation, security, devops, lsp, mcp)\n---\n\n# Add to Marketplace\n\nThis command adds a validated plugin to a marketplace.json file, managing all entries and metadata.\n\n## What It Does\n\n1. **Validates Plugin Structure**\n   - Checks that plugin directory exists and is valid\n   - Verifies plugin.json has required fields\n   - Confirms at least one component exists\n\n2. **Checks for Duplicates**\n   - Ensures no plugin with the same name exists in marketplace\n   - Verifies source path is unique\n\n3. **Creates Marketplace Entry**\n   - Extracts plugin metadata from plugin.json\n   - Adds name, description, version, author, source, and category\n   - Generates entry with all required fields\n\n4. **Updates Marketplace**\n   - Adds plugin to marketplace.json\n   - Validates the updated marketplace structure\n   - Creates marketplace.json if it doesn't exist\n\n5. **Optional Documentation Update**\n   - Updates README.md with new plugin information\n   - Regenerates plugin table\n   - Updates installation instructions\n\n## Usage\n\n```bash\n# Add plugin from current directory structure\n/add-to-marketplace ./.claude-plugins/my-plugin\n\n# Add with specific marketplace location and category\n/add-to-marketplace ./plugins/my-plugin --marketplace-path ./marketplace --category development\n\n# Add to parent directory marketplace\n/add-to-marketplace ../my-plugin --marketplace-path . --category productivity\n```\n\n## Requirements\n\nBefore adding to marketplace, plugin must have:\n- Valid plugin.json with name, version, description\n- At least one component (commands, agents, skills, hooks, or .mcp.json)\n- README.md file\n- Proper kebab-case naming\n\n## Marketplace Entry Format\n\n```json\n{\n  \"name\": \"my-plugin\",\n  \"source\": \"./.claude-plugins/my-plugin\",\n  \"description\": \"Plugin description\",\n  \"version\": \"1.0.0\",\n  \"author\": \"Author Name\",\n  \"category\": \"development\"\n}\n```\n\n## Valid Categories\n\n- **development** - Development tools and utilities\n- **productivity** - Productivity enhancements\n- **integration** - External integrations\n- **testing** - Testing and quality assurance\n- **documentation** - Documentation tools\n- **security** - Security and compliance\n- **devops** - DevOps and deployment\n- **lsp** - Language server integrations\n- **mcp** - Model context protocol servers\n\n## Next Steps\n\nAfter adding to marketplace:\n- Run `/validate-marketplace` to verify integrity\n- Run `/update-docs` to generate README\n- Commit marketplace.json changes to version control\n",
        "plugins/marketplace-manager/commands/create-plugin.md": "---\nname: create-plugin\ndescription: Scaffold a new Claude Code plugin with proper directory structure\nargs:\n  - name: plugin-name\n    type: string\n    required: true\n    description: Name of the plugin in kebab-case (e.g., my-awesome-plugin)\n  - name: description\n    type: string\n    required: true\n    description: Short description of the plugin (10-200 characters)\n  - name: author-name\n    type: string\n    required: false\n    description: Author's name (defaults to current user)\n  - name: author-email\n    type: string\n    required: false\n    description: Author's email address\n---\n\n# Create Plugin\n\nThis command scaffolds a new Claude Code plugin with the proper directory structure and standard files.\n\n## What Gets Created\n\n- `.claude-plugins/{plugin-name}/plugin.json` - Plugin manifest with metadata\n- `.claude-plugins/{plugin-name}/commands/` - Directory for slash commands\n- `.claude-plugins/{plugin-name}/agents/` - Directory for AI agents\n- `.claude-plugins/{plugin-name}/skills/` - Directory for ambient skills\n- `.claude-plugins/{plugin-name}/README.md` - Plugin documentation\n- Example component files showing proper structure\n\n## Usage\n\n```bash\n/create-plugin my-awesome-plugin \"A plugin that does awesome things\"\n\n/create-plugin utility-helper \"Helper utilities\" --author-name \"John Doe\" --author-email \"john@example.com\"\n```\n\n## Validation\n\nAfter creation, the command will:\n1. Verify the plugin directory was created\n2. Validate plugin.json structure and required fields\n3. Check that example components exist\n4. Generate a creation report\n\n## Plugin Name Rules\n\n- Must be kebab-case (lowercase letters, numbers, hyphens only)\n- Cannot contain special characters or spaces\n- Should be descriptive and unique\n- Will be used as the directory name\n\n## Next Steps\n\nAfter creation, you can:\n- Edit the plugin.json to add more metadata\n- Create commands in `commands/` directory\n- Create agents in `agents/` directory\n- Create skills in `skills/` directory\n- Run `/validate-plugin` to ensure everything meets standards\n- Run `/add-to-marketplace` to add to a plugin marketplace\n",
        "plugins/marketplace-manager/commands/list-plugins.md": "---\nname: list-plugins\ndescription: List all plugins in a marketplace with their details\nargs:\n  - name: marketplace-path\n    type: string\n    required: false\n    description: Path to marketplace directory (defaults to current directory)\n  - name: format\n    type: string\n    required: false\n    description: Output format (table, json, markdown) - defaults to table\n---\n\n# List Plugins\n\nThis command displays all plugins in a marketplace with their metadata in various formats.\n\n## Output Formats\n\n### Table Format (default)\n```\nPlugin Marketplace: My Plugin Marketplace\nOwner: Acme Corp (acme@example.com)\n\n╔════════════════════════════════════════════════════════════════════════════╗\n║ Name                    │ Version │ Category      │ Description            ║\n╠════════════════════════════════════════════════════════════════════════════╣\n║ my-plugin               │ 1.0.0   │ development   │ My awesome plugin      ║\n║ utility-helper          │ 2.1.0   │ productivity  │ Helpful utilities      ║\n║ integration-tool        │ 1.5.2   │ integration   │ External integrations  ║\n║ testing-framework       │ 3.0.0   │ testing       │ Testing and QA         ║\n║ security-scanner        │ 1.2.1   │ security      │ Security analysis      ║\n╚════════════════════════════════════════════════════════════════════════════╝\n\nTotal: 5 plugins\n```\n\n### JSON Format\n```json\n{\n  \"marketplace\": \"My Plugin Marketplace\",\n  \"owner\": {\n    \"name\": \"Acme Corp\",\n    \"email\": \"acme@example.com\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"my-plugin\",\n      \"version\": \"1.0.0\",\n      \"category\": \"development\",\n      \"description\": \"My awesome plugin\",\n      \"author\": \"Jane Doe\",\n      \"source\": \"./plugins/my-plugin\"\n    }\n  ],\n  \"total\": 5\n}\n```\n\n### Markdown Format\n```markdown\n# My Plugin Marketplace\n\n**Owner:** Acme Corp (acme@example.com)\n\n## Available Plugins\n\n1. **my-plugin** v1.0.0 [development]\n   - Description: My awesome plugin\n   - Author: Jane Doe\n\n2. **utility-helper** v2.1.0 [productivity]\n   - Description: Helpful utilities\n   - Author: John Smith\n\n3. **integration-tool** v1.5.2 [integration]\n   - Description: External integrations\n   - Author: Jane Doe\n```\n\n## Usage\n\n```bash\n# List plugins in default table format\n/list-plugins\n\n# List from specific marketplace\n/list-plugins ./marketplace\n\n# Get JSON output for programmatic use\n/list-plugins . --format json\n\n# Generate markdown listing\n/list-plugins ./marketplace --format markdown\n```\n\n## Filtering and Sorting\n\nYou can pipe the output for further processing:\n\n```bash\n# Filter by category (with shell)\n/list-plugins --format json | grep \"development\"\n\n# Export to file\n/list-plugins --format markdown > marketplace-listing.md\n\n# Get plugin count\n/list-plugins --format json | jq '.total'\n```\n\n## Display Information\n\nEach plugin shows:\n- **Name** - Plugin identifier (kebab-case)\n- **Version** - Semantic version number\n- **Category** - Plugin category\n- **Description** - Short description\n- **Author** - Plugin author name\n- **Source** - Location of plugin code\n\n## Categories\n\n- **development** - Development tools\n- **productivity** - Productivity enhancements\n- **integration** - External integrations\n- **testing** - Testing and QA\n- **documentation** - Documentation tools\n- **security** - Security tools\n- **devops** - DevOps and deployment\n- **lsp** - Language server integrations\n- **mcp** - Model context protocol servers\n\n## Sorted Output\n\nTable format is automatically sorted by:\n1. Category\n2. Plugin name\n\nThis makes it easy to browse plugins by type.\n",
        "plugins/marketplace-manager/commands/update-docs.md": "---\nname: update-docs\ndescription: Update marketplace README.md to match current marketplace.json entries\nargs:\n  - name: marketplace-path\n    type: string\n    required: false\n    description: Path to marketplace directory (defaults to current directory)\n---\n\n# Update Docs\n\nThis command automatically generates and updates marketplace documentation to reflect the current marketplace.json entries.\n\n## What Gets Generated\n\n### README.md Updates\n- **Marketplace header** - Name and description\n- **Owner information** - Contact and details\n- **Plugin table** - All plugins with versions and categories\n- **Installation section** - How to install each plugin\n- **Plugin details** - Full description for each plugin\n- **Contributing section** - Guidelines for adding plugins\n\n## Generated Structure\n\nThe command creates or updates README.md with:\n\n```markdown\n# Marketplace Name\n\nBrief marketplace description\n\n**Owner:** Name (email@example.com)\n\n## Quick Start\n\nInstallation instructions and getting started guide.\n\n## Plugins\n\n| Name | Version | Category | Description |\n|------|---------|----------|-------------|\n| plugin-name | 1.0.0 | development | Plugin description |\n\n## Installation\n\n### From Marketplace\nEach plugin installation instruction with commands.\n\n### Local Installation\nInstructions for installing from local sources.\n\n## Plugin Details\n\n### plugin-name (v1.0.0)\nFull description and usage details.\n\n## Contributing\n\nGuidelines for submitting new plugins.\n```\n\n## Usage\n\n```bash\n# Update README in current directory\n/update-docs\n\n# Update README for specific marketplace\n/update-docs ./marketplace\n\n# Update and maintain existing README sections\n/update-docs . --preserve-custom\n```\n\n## Documentation Sync\n\nThe command ensures:\n- Plugin table matches marketplace.json exactly\n- All new plugins are documented\n- Removed plugins are no longer listed\n- Versions are current\n- Categories are correct\n\n## Features\n\n### Plugin Table Generation\n- Extracts plugin data from marketplace.json\n- Creates formatted markdown table\n- Sorts by category then name\n- Includes version and description\n\n### Installation Commands\n- Generates per-plugin installation instructions\n- Includes marketplace path references\n- Provides both direct and manual installation options\n\n### Plugin Descriptions\n- Pulls full descriptions from marketplace.json\n- Shows version and author information\n- Lists plugin category\n- Provides plugin source location\n\n### Contributing Guidelines\n- Adds plugin submission instructions\n- References validate-plugin command\n- Links to add-to-marketplace workflow\n- Provides structure template\n\n## Generated Example\n\n```markdown\n# My Plugin Marketplace\n\nA curated marketplace of Claude Code plugins.\n\n**Owner:** Acme Corp (plugins@acme.com)\n\n## Available Plugins\n\n| Name | Version | Category | Description |\n|------|---------|----------|-------------|\n| my-plugin | 1.0.0 | development | My awesome plugin |\n| utility-helper | 2.1.0 | productivity | Helper utilities |\n\n## Installation\n\n### my-plugin\n```bash\n# Clone or add to marketplace\ngit clone https://github.com/acme/my-plugin.git\n```\n\n### utility-helper\n```bash\n# Add from marketplace\ncd .claude-plugins && git clone https://github.com/acme/utility-helper.git\n```\n\n## Contributing\n\nTo add your plugin:\n1. Validate with `/validate-plugin`\n2. Add to marketplace with `/add-to-marketplace`\n3. Update docs with `/update-docs`\n```\n\n## Options\n\n### Preserve Custom Sections\nUse `--preserve-custom` to keep custom README sections:\n- Keep introduction\n- Keep contributing guidelines\n- Preserve custom formatting\n- Only update plugin table and details\n\n## Next Steps\n\nAfter updating docs:\n- Review generated README for accuracy\n- Commit changes to version control\n- Share updated marketplace\n- Announce new plugins to users\n\n## Tips\n\n- Run `/list-plugins --format markdown` to see plugin list before updating\n- Review generated README to ensure formatting is correct\n- Use `/validate-marketplace` before updating docs\n- Commit and push README changes with plugin updates\n",
        "plugins/marketplace-manager/commands/validate-marketplace.md": "---\nname: validate-marketplace\ndescription: Validate marketplace structure and all plugin entries\nargs:\n  - name: marketplace-path\n    type: string\n    required: false\n    description: Path to marketplace directory (defaults to current directory)\n  - name: deep\n    type: boolean\n    required: false\n    description: Enable deep validation to check all local plugins\n---\n\n# Validate Marketplace\n\nThis command validates the integrity of a plugin marketplace and all its entries.\n\n## Validation Checks\n\n### Marketplace Schema\n- ✓ marketplace.json exists and is valid JSON\n- ✓ Required fields present: name, owner.name, owner.email, plugins (array)\n- ✓ Marketplace name is kebab-case (no spaces)\n- ✓ Owner is an object with name and email (not a string)\n- ✓ Version follows semantic versioning (X.Y.Z)\n\n### Plugin Entry Validation\n- ✓ Each plugin has required fields: name, source, description, version, author, category\n- ✓ Plugin names are unique (no duplicates)\n- ✓ Plugin names match kebab-case convention\n- ✓ Plugin source paths start with \"./\" (not \"../\")\n- ✓ Plugin author is an object {name, email} (not a string)\n- ✓ Plugin category is in valid list\n- ✓ Local source paths exist and are valid plugins\n\n### Documentation Consistency\n- ✓ README.md references match marketplace entries\n- ✓ Plugin table is up-to-date\n- ✓ Installation commands are correct\n\n### Deep Validation (--deep flag)\nWhen enabled, also validates:\n- ✓ Each local plugin's structure and components\n- ✓ Plugin.json integrity for all local plugins\n- ✓ README.md present in each plugin\n- ✓ All plugin names match between marketplace.json and plugin.json\n\n## Output Format\n\n### Standard Report\n```\nMarketplace Validation Report\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nMarketplace: Plugin Marketplace v1.0\nOwner: Acme Corp (acme@example.com)\nPlugins: 5 total\n\nPlugin Status:\n✓ my-plugin v1.0.0\n✓ utility-helper v2.1.0\n✓ integration-tool v1.5.2\n✓ testing-framework v3.0.0\n✓ security-scanner v1.2.1\n\nSummary: All checks passed - marketplace ready for release\n```\n\n### Status Levels\n- **✓ VALID** - All plugins and marketplace structure valid\n- **⚠ VALID_WITH_WARNINGS** - Valid but has non-blocking warnings\n- **✗ INVALID** - Errors found, must fix before release\n\n## Usage\n\n```bash\n# Validate marketplace in current directory\n/validate-marketplace\n\n# Validate specific marketplace with deep checks\n/validate-marketplace ./marketplace --deep\n\n# Validate and check all local plugins\n/validate-marketplace . --deep\n```\n\n## Common Issues\n\n**Marketplace name not kebab-case**: Name contains spaces or mixed case\n- ✗ Invalid: \"Claude Code Plugin Marketplace\"\n- ✓ Valid: \"code-plugin-marketplace\"\n- Fix: Use lowercase letters, hyphens, and numbers only\n\n**Author as string instead of object**: Author must be an object with name and email\n- ✗ Invalid: `\"author\": \"Anthropic\"`\n- ✓ Valid: `\"author\": {\"name\": \"Anthropic\", \"email\": \"contact@example.com\"}`\n- Fix: Convert all author strings to {name, email} objects\n\n**Source paths don't start with \"./\"**: Paths must start with ./\n- ✗ Invalid: `\"source\": \"../plugins/my-plugin\"`, `\"source\": \"plugins/my-plugin\"`\n- ✓ Valid: `\"source\": \"./plugins/my-plugin\"`\n- Fix: Update all source paths to start with \"./\"\n\n**Duplicate plugin names**: Each plugin must have unique name\n- Check marketplace.json for name conflicts\n- Verify plugin.json names match marketplace entries\n\n**Invalid source paths**: Local plugins must exist\n- Verify paths are relative and correct\n- Check that plugin directories are readable\n- Ensure plugin.json exists in each directory\n\n**Missing owner information**: Marketplace requires owner\n- Add name and email to marketplace.json root as an object, not a string\n\n**Schema errors**: marketplace.json structure issues\n- Verify JSON is valid (use a JSON validator)\n- Check required fields are present\n- Ensure plugins array is properly formatted\n- Verify all data types match schema\n\n## marketplace.json Template\n\n```json\n{\n  \"name\": \"My Plugin Marketplace\",\n  \"owner\": {\n    \"name\": \"Your Name\",\n    \"email\": \"your@email.com\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"my-plugin\",\n      \"source\": \"./plugins/my-plugin\",\n      \"description\": \"Plugin description\",\n      \"version\": \"1.0.0\",\n      \"author\": \"Author Name\",\n      \"category\": \"development\"\n    }\n  ]\n}\n```\n\n## Next Steps\n\nAfter validation passes:\n- Run `/update-docs` to generate README\n- Run `/list-plugins` to see marketplace summary\n- Commit marketplace.json to version control\n- Share marketplace with the community\n",
        "plugins/marketplace-manager/commands/validate-plugin.md": "---\nname: validate-plugin\ndescription: Comprehensive validation of plugin structure and best practices\nargs:\n  - name: plugin-path\n    type: string\n    required: true\n    description: Path to the plugin directory to validate\n  - name: strict\n    type: boolean\n    required: false\n    description: Enable strict mode for additional checks (warnings become errors)\n---\n\n# Validate Plugin\n\nThis command performs comprehensive validation of a plugin's structure and adherence to Claude Code plugin best practices.\n\n## Validation Checks\n\n### Required Structure\n- ✓ `.claude-plugins/` directory exists\n- ✓ `plugin.json` file exists\n- ✓ At least one component directory (commands/, agents/, skills/, hooks/)\n- ✓ README.md file exists\n\n### plugin.json Validation\n- ✓ Valid JSON syntax\n- ✓ Required fields present: name, version, description\n- ✓ Plugin name in kebab-case (lowercase, hyphens only)\n- ✓ Version follows semver (X.Y.Z format)\n- ✓ Description between 10-200 characters\n- ✓ Optional fields properly formatted: author, license, keywords\n\n### Component Validation\n- ✓ Commands have proper YAML frontmatter\n- ✓ Agents have proper structure\n- ✓ Skills are properly formatted\n- ✓ Hook files follow conventions\n\n### Best Practices\n- ✓ README.md includes usage examples\n- ✓ All commands are documented\n- ✓ Plugin has clear purpose and description\n- ✓ Author information is present\n\n## Output Format\n\n### Standard Report\n```\nPlugin Validation Report\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nPlugin: my-plugin v1.0.0\nStatus: ✓ VALID\n\nChecks:\n✓ Directory structure valid\n✓ plugin.json complete\n✓ All components found\n✓ Documentation present\n✓ Best practices met\n\nSummary: All checks passed\n```\n\n### Status Levels\n- **✓ VALID** - All checks passed, ready for marketplace\n- **⚠ VALID_WITH_WARNINGS** - Passed but has best practice warnings\n- **✗ INVALID** - Failed required checks, cannot add to marketplace\n\n## Usage\n\n```bash\n# Validate plugin in current directory\n/validate-plugin .\n\n# Validate with strict mode (warnings = errors)\n/validate-plugin ./my-plugin --strict\n\n# Validate and get detailed report\n/validate-plugin ../other-plugin\n```\n\n## Common Issues\n\n**Invalid name format**: Plugin names must be kebab-case\n- ✗ MyPlugin, my_plugin, MY-PLUGIN\n- ✓ my-plugin, awesome-tool\n\n**Invalid version**: Must follow X.Y.Z format\n- ✗ 1.0, 1.0.0.0, v1.0.0\n- ✓ 1.0.0, 0.1.0, 2.5.3\n\n**Missing components**: At least one required\n- Commands, agents, skills, hooks, or .mcp.json\n\n## Next Steps\n\nAfter validation passes:\n- Run `/add-to-marketplace` to add to a marketplace\n- Run `/update-docs` to generate documentation\n- Share plugin with the community\n\nIf issues found:\n- Review error messages carefully\n- Fix identified problems\n- Re-run validation to confirm\n",
        "plugins/marketplace-manager/skills/marketplace-management.md": "# Marketplace Management\n\nConcise guidance for managing plugin marketplaces. Use validation commands for detailed checks.\n\n## Core Concepts\n\n**Structure**: `marketplace.json` registry + `plugins/` directory containing plugin subdirectories\n**Location**: Place `marketplace.json` at root or in `.claude-plugin/` directory\n**Validation**: Always run `/validate-marketplace` before releases\n\n## marketplace.json Quick Reference\n\n```json\n{\n  \"name\": \"my-marketplace\",\n  \"owner\": { \"name\": \"...\", \"email\": \"...\" },\n  \"plugins\": [\n    {\n      \"name\": \"plugin-name\",\n      \"source\": \"./plugins/plugin-name\",\n      \"description\": \"What it does\"\n    }\n  ]\n}\n```\n\n### Required Fields\n- **name**: Marketplace identifier\n- **owner.name** and **owner.email**: Contact info\n- **plugins**: Array with name, source, description per entry\n\n### Plugin Entry Fields\n| Field | Required | Format |\n|-------|----------|--------|\n| name | Yes | kebab-case |\n| source | Yes | `./path` (local) or URL (remote) |\n| description | Yes | 10-200 chars |\n| version | No | semver X.Y.Z |\n| category | No | see categories below |\n| author | No | `{name, email}` object |\n\n### Valid Categories\n`development` | `productivity` | `integration` | `testing` | `documentation` | `security` | `devops` | `lsp` | `mcp`\n\n## Common Workflows\n\n### Add Plugin\n```bash\n/validate-plugin ./plugins/new-plugin    # Validate first\n/add-to-marketplace ./plugins/new-plugin # Add entry\n/validate-marketplace --deep             # Verify\n```\n\n### Release Checklist\n1. All plugins pass `/validate-plugin`\n2. Marketplace passes `/validate-marketplace --deep`\n3. README.md is current\n4. Version bumped if changed\n\n## Quick Fixes\n\n**\"marketplace.json not found\"**\n→ Ensure file exists at root or `.claude-plugin/marketplace.json`\n\n**\"Plugin name not kebab-case\"**\n→ Use lowercase-with-hyphens: `my-plugin` not `MyPlugin`\n\n**\"Source path not found\"**\n→ Local paths must start with `./` and exist\n\n**\"Duplicate plugin name\"**\n→ Each name must be unique in plugins array\n\n## Commands Reference\n- `/validate-marketplace [path] [--deep]` - Check marketplace integrity\n- `/validate-plugin <path>` - Check single plugin\n- `/add-to-marketplace <path>` - Add plugin entry\n- `/list-plugins [--format json|table]` - List all plugins\n- `/update-docs` - Regenerate README\n",
        "plugins/marketplace-manager/skills/plugin-authoring.md": "# Plugin Authoring\n\nConcise guidance for creating Claude Code plugins. Use `/create-plugin` for scaffolding.\n\n## Plugin Structure\n\n```\nmy-plugin/\n├── .claude-plugin/\n│   ├── plugin.json    # Required manifest\n│   ├── commands/      # Slash commands (*.md)\n│   ├── agents/        # AI agents (*.md)\n│   ├── skills/        # Ambient skills (*.md)\n│   ├── hooks/         # Event hooks (*.md)\n│   ├── .mcp.json      # MCP server config\n│   └── README.md      # Required documentation\n└── LICENSE\n```\n\n**Note**: Use `.claude-plugin/` (singular), not `.claude-plugins/`\n\n## plugin.json Template\n\n```json\n{\n  \"name\": \"my-plugin\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Brief description (10-200 chars)\",\n  \"author\": { \"name\": \"Your Name\", \"email\": \"you@email.com\" },\n  \"category\": \"development\",\n  \"license\": \"MIT\"\n}\n```\n\n### Required Fields\n- **name**: kebab-case identifier\n- **version**: semver format X.Y.Z\n- **description**: 10-200 characters\n\n## Naming Conventions\n\n**Everything uses kebab-case**: lowercase letters and hyphens only\n\n| Component | Valid | Invalid |\n|-----------|-------|---------|\n| Plugin | `my-plugin` | `MyPlugin`, `my_plugin` |\n| Command | `run-tests` | `runTests`, `run_tests` |\n| Agent | `code-reviewer` | `CodeReviewer` |\n| Skill | `best-practices` | `bestPractices` |\n\n## Component Templates\n\n### Command (commands/my-command.md)\n```markdown\n---\nname: my-command\ndescription: What this command does\nargs:\n  - name: input\n    type: string\n    required: true\n    description: Input description\n---\n\n# My Command\n\nBrief description and usage instructions.\n```\n\n### Agent (agents/my-agent.md)\n```markdown\n---\nname: my-agent\ndescription: What this agent does\nmodel: sonnet\ntools: [Read, Glob, Grep]\n---\n\n# My Agent\n\nPurpose: Clear statement of role\n\nWhen to use: Key use cases\n\nOutput: What it produces\n```\n\n### Skill (skills/my-skill.md)\n```markdown\n# My Skill\n\nPurpose: What expertise this provides\n\n## Key Guidance\n- Essential point 1\n- Essential point 2\n- Essential point 3\n```\n\n## Valid Categories\n`development` | `productivity` | `integration` | `testing` | `documentation` | `security` | `devops` | `lsp` | `mcp`\n\n## Version Rules (semver)\n- **Major (X.0.0)**: Breaking changes\n- **Minor (0.X.0)**: New features, backward compatible\n- **Patch (0.0.X)**: Bug fixes\n\n## Publishing Checklist\n\n1. `/validate-plugin ./my-plugin` passes\n2. README.md has usage examples\n3. All components have descriptions\n4. Version follows semver\n5. Category is valid\n\n## Common Mistakes\n\n- Using `.claude-plugins/` instead of `.claude-plugin/`\n- CamelCase or snake_case names\n- Missing required fields in plugin.json\n- No README.md\n- Description too short/long (need 10-200 chars)\n",
        "plugins/plugin-improver/.claude-plugin/plugin.json": "{\n  \"name\": \"plugin-improver\",\n  \"version\": \"0.1.0\",\n  \"description\": \"Iteratively evaluate and enhance plugins with Anthropic best practices. Analyzes quality, suggests concrete improvements, and integrates with Ralph Loop for continuous self-improvement.\",\n  \"author\": {\n    \"name\": \"Plugin Development Team\",\n    \"email\": \"support@example.com\"\n  },\n  \"homepage\": \"https://github.com/anthropics/claude-code\",\n  \"repository\": \"https://github.com/anthropics/claude-code-plugins\",\n  \"license\": \"MIT\",\n  \"keywords\": [\n    \"plugin-improvement\",\n    \"quality-assessment\",\n    \"best-practices\",\n    \"prompt-optimization\",\n    \"iterative-enhancement\",\n    \"plugin-evaluation\",\n    \"continuous-improvement\"\n  ]\n}\n",
        "plugins/plugin-improver/README.md": "# Plugin Improver\n\n**Iteratively evaluate and enhance plugins with Anthropic best practices.** Analyzes quality, suggests concrete improvements, and integrates with Ralph Loop for continuous self-improvement.\n\n## Overview\n\nPlugin Improver is a meta-plugin that helps you continuously improve other plugins in your marketplace. It provides:\n\n- **Comprehensive Quality Assessment** - Multi-dimensional evaluation across best practices, code quality, and prompt clarity\n- **Actionable Recommendations** - Concrete before/after code examples for every suggestion\n- **Ralph Loop Integration** - Continuous improvement through automated iterative enhancement\n- **Best Practices Alignment** - Reference implementation of Anthropic standards and conventions\n\n## Quick Start\n\n### Basic Usage\n\n```bash\n/improver:improve-plugin plugin-name\n```\n\nThis will:\n1. Analyze your plugin's structure, standards compliance, and quality\n2. Launch specialized evaluation agents\n3. Generate a comprehensive improvement report\n4. Suggest concrete improvements with code examples\n\n### With Ralph Loop\n\n```bash\n/ralph-loop:ralph-loop \"improve plugins in my marketplace\"\n```\n\nThe Ralph Loop will iteratively:\n1. Evaluate each plugin in your marketplace\n2. Apply improvements from the evaluation\n3. Generate new reports showing progress\n4. Track quality metrics over time\n\n## What Gets Evaluated\n\n### Best Practices Compliance (30% of score)\n- Plugin structure and organization\n- plugin.json manifest validity\n- YAML frontmatter standards\n- Component naming conventions\n- Documentation completeness\n\n### Code Quality (35% of score)\n- Architecture and separation of concerns\n- Error handling and robustness\n- Context efficiency and performance\n- Maintainability and clarity\n- Design patterns and anti-patterns\n\n### Prompt Quality (35% of score)\n- Skill descriptions and trigger phrases\n- Agent system prompts and processes\n- Command guidance clarity\n- Consistency and tone across components\n- Completeness and accuracy\n\n## Example Output\n\n```\n# Plugin Improvement Report: my-plugin\n\n## Executive Summary\nOverall Quality Score: 72/100\nStatus: Important Improvements Needed\n\n## Evaluation Results\n\n### Best Practices Compliance: 68/100\n- ✅ Directory structure organized\n- ⚠️ Some skill trigger phrases too generic\n- ❌ Missing CLAUDE.md documentation\n\n### Code Quality: 75/100\n- ✅ Good error handling patterns\n- ⚠️ Context efficiency could improve\n- ⚠️ Some command logic could delegate to agents\n\n### Prompt Quality: 70/100\n- ⚠️ Agent roles are generic\n- ⚠️ Command guidance could be clearer\n- ❌ Trigger phrases lack specificity\n\n## Important Improvements\n\n### 1. Enhance Trigger Phrases (Impact: High)\n**Location**: skills/prioritization-skill.md\n\nBEFORE:\n```yaml\ntrigger-phrases:\n  - \"help with priorities\"\n  - \"improve\"\n  - \"organize\"\n```\n\nAFTER:\n```yaml\ntrigger-phrases:\n  - \"prioritize my tasks\"\n  - \"what should I do first\"\n  - \"organize my workload\"\n  - \"which tasks matter most\"\n```\n\n**Why**: Specific phrases improve discovery and reduce false positives.\n\n### 2. Clarify Agent Role (Impact: High)\n**Location**: agents/prioritization-agent.md\n\nBEFORE:\n```markdown\nYou are an assistant that helps with task prioritization.\n```\n\nAFTER:\n```markdown\nYou are a prioritization specialist using the Eisenhower matrix to classify tasks by urgency and importance.\n```\n\n**Why**: Specific role enables better analysis and prevents generic responses.\n\n### 3. Add CLAUDE.md Documentation (Impact: Medium)\n**Location**: Create plugins/my-plugin/CLAUDE.md\n\nSee `references/` for template and examples.\n\n**Why**: Helps other developers understand plugin architecture and make changes.\n\n## Ralph Loop Integration\n\nWhen running with Ralph Loop:\n\n1. **Initial Assessment** - Comprehensive evaluation of all plugins\n2. **Improvement Suggestions** - Concrete recommendations with examples\n3. **Implementation** - Apply suggested improvements to plugins\n4. **Re-evaluation** - Measure quality improvements\n5. **Iteration** - Continue improving across multiple cycles\n\nEach iteration tracks:\n- Quality score changes\n- Number of improvements applied\n- Categories where most progress was made\n- Remaining issues to address\n\n## Key Features\n\n### Multi-Agent Evaluation\n- **Best Practices Evaluator** - Checks structure and conventions\n- **Quality Analyzer** - Assesses code and architecture\n- **Prompt Optimizer** - Evaluates clarity and specificity\n\n### Reusable Knowledge\n- **best-practices-reference** - Anthropic standards checklist\n- **prompt-enhancement** - Techniques for improving clarity\n- **architecture-patterns** - Design patterns and guidance\n\n### Comprehensive Feedback\n- Specific file references (file:line-number)\n- Before/after code examples\n- Clear explanations of WHY changes matter\n- Actionable implementation steps\n\n## Commands\n\n### improve-plugin [plugin-name]\n\nEvaluate a plugin and generate improvement recommendations.\n\n```bash\n/improver:improve-plugin planner\n/improver:improve-plugin prompt-orchestrator\n```\n\nProvides:\n- Quality score breakdown\n- Critical issues (must fix)\n- Important improvements (should fix)\n- Optional enhancements (nice to have)\n- Implementation roadmap\n\n## Agents\n\n### improver-coordinator\nOrchestrates the multi-agent evaluation workflow and synthesizes results.\n\n### best-practices-evaluator\nAssesses plugin structure, standards compliance, and conventions.\n\n### quality-analyzer\nAnalyzes code architecture, error handling, and design patterns.\n\n### prompt-optimizer\nEvaluates skill descriptions, agent system prompts, and command guidance.\n\n## Skills\n\n### best-practices-reference\nComprehensive checklist of Anthropic plugin standards and conventions.\n\n### prompt-enhancement\nTechniques for improving clarity, specificity, and effectiveness of plugin prompts.\n\n### architecture-patterns\nDesign patterns, structural guidance, and plugin architecture best practices.\n\n## Installation\n\n1. Clone this plugin into your plugins directory:\n```bash\ncp -r plugin-improver ~/.claude-plugin/plugin-improver\n```\n\n2. Or add to your marketplace:\n```bash\ncp -r plugin-improver plugins/plugin-improver\n```\n\n3. Restart Claude Code to load the plugin.\n\n## Configuration\n\nPlugin Improver works out of the box. No configuration required.\n\nOptional: Use with Ralph Loop for continuous improvement:\n```bash\n/ralph-loop:ralph-loop \"improve plugins\" --max-iterations 10\n```\n\n## Ralph Loop Usage\n\n### Start Continuous Improvement Loop\n\n```bash\n/ralph-loop:ralph-loop \"iteratively improve all plugins in my marketplace using plugin-improver\"\n```\n\n### Track Progress\n\nMonitor improvements over time in `.improvements/` directory:\n- `plugin-[name]-evaluation.md` - Latest evaluation report\n- `scores.json` - Quality score history\n\n### Example Loop Results\n\n**Iteration 1**: Overall quality 65/100\n- 3 critical issues found\n- 12 important improvements suggested\n\n**Iteration 2**: Overall quality 73/100\n- Critical issues addressed\n- 8 important improvements remaining\n\n**Iteration 3**: Overall quality 81/100\n- Most improvements implemented\n- Polish and refinement remaining\n\n## Best Practices\n\n### Regular Evaluation\n- Run `/improver:improve-plugin` after adding new commands/agents/skills\n- Use as part of your development workflow\n- Track scores over time\n\n### Concrete Implementation\n- Apply suggested improvements incrementally\n- Test changes before committing\n- Reference the before/after examples provided\n\n### Ralph Loop Iteration\n- Start with automated improvement loop\n- Manually review and refine as needed\n- Track progress metrics over time\n\n## Troubleshooting\n\n### \"Plugin not found\"\nCheck that the plugin directory exists and path is correct.\n\n### \"Score lower than expected\"\n- Review the detailed findings in the report\n- Focus on critical issues first\n- Use suggestions as a roadmap\n\n### \"Ralph Loop not completing\"\nEnsure you set `--max-iterations N` to avoid infinite loop.\n\n## Contributing\n\nImprovements and suggestions welcome! This plugin is designed to be iteratively enhanced.\n\n## License\n\nMIT\n\n## See Also\n\n- [Anthropic Plugin Development Guide](https://github.com/anthropics/claude-code)\n- [prompt-orchestrator](../prompt-orchestrator) - Prompt quality optimization\n- [marketplace-manager](../marketplace-manager) - Plugin distribution\n- [subagent-creator](../subagent-creator) - Agent design guidance\n",
        "plugins/plugin-improver/agents/best-practices-evaluator-agent.md": "---\nname: best-practices-evaluator\ndescription: Evaluates plugin compliance with Anthropic best practices, standards, and conventions\nwhen-to-invoke: When coordinator agent needs to assess architectural and structural compliance\n---\n\n# Best Practices Evaluator Agent\n\nYou are a **plugin standards auditor** specializing in evaluating plugin architecture, structure, and compliance with Anthropic best practices and conventions.\n\n## Your Core Responsibilities\n\n1. **Standards Compliance** - Verify adherence to Anthropic plugin patterns\n2. **Structure Validation** - Check plugin organization and file structure\n3. **Metadata Assessment** - Validate plugin.json and frontmatter\n4. **Convention Alignment** - Ensure naming, formatting, and patterns match standards\n5. **Scoring** - Generate dimension-specific quality scores with evidence\n\n## Evaluation Framework\n\n### 1. Plugin Structure (20 points)\n\n**Criteria**:\n- ✅ Plugin directory contains plugin.json\n- ✅ All referenced components exist\n- ✅ Organized in standard directories: commands/, agents/, skills/, hooks/\n- ✅ No orphaned files or incomplete components\n\n**Scoring**:\n- 20/20: All components properly organized\n- 15/20: Minor organization issues\n- 10/20: Missing component directories\n- 5/20: Inconsistent structure\n- 0/20: Critical structure problems\n\n### 2. Plugin Manifest (15 points)\n\n**Validate plugin.json**:\n```json\n{\n  \"name\": \"[kebab-case-name]\",           // ✅ Required, kebab-case\n  \"version\": \"[semver]\",                  // ✅ Required, valid semver\n  \"description\": \"[50-150 chars]\",        // ✅ Required, concise\n  \"author\": { \"name\": \"\", \"email\": \"\" },  // ✅ Required\n  \"license\": \"MIT\",                       // ✅ Recommended\n  \"keywords\": [\"relevant\", \"terms\"],      // ✅ Recommended, 3-7 words\n  \"commands\": { \"id\": \"path/to.md\" },    // ✅ Auto-discovered, paths valid\n  \"agents\": { \"id\": \"path/to.md\" },      // ✅ Auto-discovered, paths valid\n  \"skills\": { \"id\": \"path/to.md\" }       // ✅ Auto-discovered, paths valid\n}\n```\n\n**Scoring**:\n- 15/15: All fields present, valid format, correct conventions\n- 12/15: Missing optional fields\n- 9/15: Some invalid values or format issues\n- 6/15: Multiple fields missing or malformed\n- 0/15: Invalid JSON or critical fields missing\n\n### 3. Command Standards (15 points)\n\n**YAML Frontmatter**:\n```yaml\n---\nname: command-id                    # ✅ Kebab-case, matches plugin.json\ndescription: Short user description # ✅ 1-2 sentences, action-oriented\nargument-hint: \"[optional]\"        # ✅ If arguments used\nallowed-tools: [Tool1, Tool2]      # ✅ If restricted access needed\n---\n```\n\n**Content Quality**:\n- ✅ Clear purpose and workflow\n- ✅ Phase-by-phase guidance (for complex commands)\n- ✅ Examples or use cases\n- ✅ Error handling or edge cases\n- ✅ References to related commands/agents/skills\n\n**Scoring**:\n- 15/15: Well-structured, clear, complete\n- 12/15: Good structure, minor clarity issues\n- 9/15: Adequate, could be clearer\n- 6/15: Unclear or incomplete\n- 0/15: Confusing or malformed\n\n### 4. Agent Standards (15 points)\n\n**YAML Frontmatter**:\n```yaml\n---\nname: agent-id                           # ✅ Kebab-case\ndescription: What this agent specializes in\nwhen-to-invoke: Conditions triggering agent  # ✅ Critical for auto-invocation\ntools: [Tool1, Tool2]                   # ✅ If access restrictions\n---\n```\n\n**System Prompt Quality**:\n- ✅ Clear role definition\n- ✅ Specific responsibilities\n- ✅ Analysis process steps\n- ✅ Quality standards\n- ✅ Output format specification\n- ✅ Edge case handling\n\n**Scoring**:\n- 15/15: Comprehensive, clear, well-structured\n- 12/15: Good coverage, minor gaps\n- 9/15: Adequate system prompt\n- 6/15: Unclear responsibilities or process\n- 0/15: Missing critical elements\n\n### 5. Skill Standards (15 points)\n\n**YAML Frontmatter**:\n```yaml\n---\nname: skill-id                      # ✅ Kebab-case\ndescription: What this skill teaches\ntrigger-phrases:                    # ✅ Critical for discovery\n  - \"natural language trigger\"\n  - \"user might say this\"\n---\n```\n\n**Content Structure**:\n- ✅ Core concept (100-150 words)\n- ✅ Progressive disclosure (if complex)\n- ✅ References/ subdirectory for detailed docs\n- ✅ Clear examples or templates\n- ✅ When to use guidance\n\n**Scoring**:\n- 15/15: Excellent progressive disclosure and examples\n- 12/15: Good structure with some gaps\n- 9/15: Adequate coverage\n- 6/15: Basic info, could be clearer\n- 0/15: Incomplete or confusing\n\n### 6. Documentation (10 points)\n\n**Files Present**:\n- ✅ README.md with installation and usage\n- ✅ CLAUDE.md with development guidance\n- ✅ Clear inline comments in complex code\n- ✅ Examples or templates included\n\n**Quality**:\n- ✅ Accurate and up-to-date\n- ✅ Accessible to developers\n- ✅ References to related docs\n\n**Scoring**:\n- 10/10: Comprehensive, clear, well-organized\n- 8/10: Good documentation with minor gaps\n- 6/10: Adequate, could be more detailed\n- 4/10: Minimal documentation\n- 0/10: Missing critical docs\n\n### 7. Naming & Conventions (10 points)\n\n**Check Consistency**:\n- ✅ Files use kebab-case or descriptive names\n- ✅ Commands/agents/skills use consistent IDs\n- ✅ Variable/property names are clear\n- ✅ No misleading abbreviations\n\n**Scoring**:\n- 10/10: Consistent throughout\n- 8/10: Mostly consistent\n- 6/10: Some inconsistencies\n- 4/10: Inconsistent naming\n- 0/10: Confusing or non-standard names\n\n## Scoring Calculation\n\n```\nBest Practices Score = (\n  structure * 20 +\n  manifest * 15 +\n  commands * 15 +\n  agents * 15 +\n  skills * 15 +\n  documentation * 10 +\n  naming * 10\n) / 100\n```\n\n## Detailed Checklist\n\n**Plugin Structure** ✓\n- [ ] plugin.json exists and is valid JSON\n- [ ] commands/ directory exists and contains .md files\n- [ ] agents/ directory exists and contains .md files\n- [ ] skills/ directory exists and contains .md files\n- [ ] README.md documents usage\n- [ ] CLAUDE.md documents development\n\n**Manifest Validation** ✓\n- [ ] Name is kebab-case and matches directory\n- [ ] Version is valid semver (e.g., 0.1.0)\n- [ ] Description is 50-150 characters\n- [ ] Author has name and email\n- [ ] Keywords are relevant (3-7 items)\n- [ ] All referenced files exist\n\n**Command Conventions** ✓\n- [ ] Each .md file has YAML frontmatter\n- [ ] name field is present and kebab-case\n- [ ] description is concise and action-oriented\n- [ ] Content is clear and well-organized\n- [ ] References related agents/skills where applicable\n\n**Agent Conventions** ✓\n- [ ] YAML frontmatter present with name, description\n- [ ] when-to-invoke clearly specified\n- [ ] System prompt has role, responsibilities, process\n- [ ] Quality standards defined\n- [ ] Output format specified\n\n**Skill Conventions** ✓\n- [ ] YAML frontmatter with name, description\n- [ ] trigger-phrases defined and natural-sounding\n- [ ] Core concept explained clearly\n- [ ] Progressive disclosure used if complex\n- [ ] Examples or references included\n\n## Output Format\n\nProvide evaluation results:\n\n```markdown\n## Best Practices Evaluation\n\n**Overall Score: __ / 100**\n\n### Score Breakdown\n\n| Dimension | Score | Status |\n|-----------|-------|--------|\n| Structure | __/20 | ✅/⚠️/❌ |\n| Manifest | __/15 | ✅/⚠️/❌ |\n| Commands | __/15 | ✅/⚠️/❌ |\n| Agents | __/15 | ✅/⚠️/❌ |\n| Skills | __/15 | ✅/⚠️/❌ |\n| Documentation | __/10 | ✅/⚠️/❌ |\n| Naming | __/10 | ✅/⚠️/❌ |\n\n### Key Findings\n\n**Strengths**:\n- [Positive patterns observed]\n\n**Areas for Improvement**:\n- [Specific compliance issues]\n\n### Evidence & Recommendations\n\n[For each issue, provide]:\n1. What was found\n2. Why it matters\n3. How to fix it\n4. Code example if applicable\n```\n\n## Integration\n\n- Coordinate with **quality-analyzer** for code-level issues\n- Coordinate with **prompt-optimizer** for clarity improvements\n- Reference **best-practices-reference** skill for standards\n- Feed results into coordinator agent for synthesis\n\n---\n\nWhen responding, provide clear scoring with evidence and specific remediation steps for any non-compliance issues.\n",
        "plugins/plugin-improver/agents/improver-coordinator-agent.md": "---\nname: improver-coordinator\ndescription: Orchestrates comprehensive plugin evaluation by coordinating specialized evaluation agents\nwhen-to-invoke: When user runs improve-plugin command or Ralph Loop triggers plugin evaluation\n---\n\n# Plugin Improver Coordinator Agent\n\nYou are a **plugin evaluation coordinator** specializing in systematically analyzing plugin quality and orchestrating specialized improvement agents.\n\n## Your Core Responsibilities\n\n1. **Structure Analysis** - Map plugin components and dependencies\n2. **Agent Orchestration** - Route specialized evaluation tasks to appropriate agents\n3. **Results Integration** - Combine evaluation scores into coherent quality assessment\n4. **Report Generation** - Create actionable improvement recommendations with code examples\n5. **Progress Tracking** - Track quality metrics over time for iterative improvement\n\n## Evaluation Process\n\n### Phase 1: Plugin Structure Discovery\n\nRead and analyze the plugin directory:\n\n```bash\n# Discover plugin structure\nls -la plugins/{plugin-name}/\ncat plugins/{plugin-name}/plugin.json\nfind plugins/{plugin-name}/ -name \"*.md\" -type f | sort\n```\n\n**Document**:\n- Plugin metadata (name, version, description)\n- All components: commands, agents, skills, hooks\n- File count and organization\n- Dependencies or integrations\n\n### Phase 2: Multi-Dimensional Evaluation\n\nLaunch specialized agents in parallel:\n\n**Best Practices Evaluator**\n- Assesses against Anthropic plugin standards\n- Checks structure, naming, conventions\n- Validates YAML frontmatter\n- Score: 0-100\n\n**Quality Analyzer**\n- Analyzes code patterns and architecture\n- Reviews error handling strategies\n- Evaluates context efficiency\n- Score: 0-100\n\n**Prompt Optimizer**\n- Evaluates skill descriptions and clarity\n- Assesses agent system prompts\n- Reviews command guidance text\n- Checks trigger phrase quality\n- Score: 0-100\n\n### Phase 3: Score Integration\n\nCalculate overall quality metric:\n\n```\nOverall Score = (\n  best_practices_score * 0.30 +\n  quality_score * 0.35 +\n  prompt_score * 0.35\n) * 100\n```\n\n**Interpretation**:\n- 0-59: Critical issues block usage\n- 60-74: Important improvements needed\n- 75-89: Good, optimization recommended\n- 90-100: Excellent, production-ready\n\n### Phase 4: Improvement Prioritization\n\nCategorize findings:\n\n1. **Critical** (Must Fix)\n   - Blocking issues\n   - Security concerns\n   - Documentation gaps\n   - Non-compliant patterns\n\n2. **Important** (Should Fix)\n   - Quality improvements\n   - Clarity enhancements\n   - Performance optimizations\n   - Best practice alignment\n\n3. **Optional** (Nice to Have)\n   - Polish and refinement\n   - Advanced patterns\n   - Future-proofing\n   - Community standards\n\n### Phase 5: Report Generation\n\nCreate comprehensive improvement report with sections:\n\n1. **Executive Summary**\n   - Overall quality score\n   - Key findings\n   - Recommended priority order\n\n2. **Dimension Scores**\n   - Best practices: __ / 100\n   - Code quality: __ / 100\n   - Prompt quality: __ / 100\n\n3. **Critical Issues** (if any)\n   - Issue description\n   - Impact on usage\n   - Code example of fix\n\n4. **Important Improvements** (top 5-10)\n   - Improvement description\n   - BEFORE code snippet\n   - AFTER code snippet\n   - Why this improves quality\n\n5. **Optional Enhancements**\n   - Enhancement description\n   - Benefit explanation\n\n6. **Implementation Guide**\n   - Step-by-step improvement plan\n   - Which files to modify\n   - Testing recommendations\n\n## Quality Standards\n\n**For Each Evaluation**:\n- ✅ Provide specific, actionable recommendations\n- ✅ Include code examples (BEFORE/AFTER)\n- ✅ Explain WHY each improvement matters\n- ✅ Respect existing patterns when suggesting changes\n- ✅ Consider difficulty and effort of implementation\n\n**Score Justification**:\n- Each score must be backed by specific evidence\n- Reference Anthropic patterns and best practices\n- Acknowledge plugin's strengths\n- Balance criticism with constructive feedback\n\n## Output Format\n\n```markdown\n# Plugin Improvement Report: [plugin-name]\n\n## Executive Summary\nOverall Quality Score: __/100\nStatus: [Critical Issues | Important Improvements | Production-Ready]\n\n## Evaluation Results\n\n### Best Practices Compliance: __ / 100\n[Key findings]\n\n### Code Quality: __ / 100\n[Key findings]\n\n### Prompt Quality: __ / 100\n[Key findings]\n\n## Critical Issues\n[If any, list with impact and fix]\n\n## Important Improvements\n[Top priority improvements with examples]\n\n## Optional Enhancements\n[Polish and refinement suggestions]\n\n## Implementation Roadmap\n1. [Step 1]\n2. [Step 2]\n3. [Step 3]\n```\n\n## Edge Cases\n\n**Plugin Not Found**: Confirm plugin directory path and structure\n**Missing Components**: Note as quality issue, suggest minimum structure\n**Conflicting Patterns**: Reference Anthropic docs to resolve\n**Subjective Quality**: Use scoring rubric to standardize assessment\n**Ralph Loop Context**: Save results to `.improvements/` directory for tracking\n\n## Integration Points\n\n- **marketplace-manager plugin**: Reuse validation patterns\n- **subagent-creator plugin**: Agent design guidance\n- **prompt-orchestrator plugin**: Prompt quality assessment\n- **Ralph Loop**: Continuous improvement iteration\n\n---\n\nWhen responding to the user, always provide the complete evaluation report in a structured format that enables immediate understanding of plugin quality and actionable next steps for improvement.\n",
        "plugins/plugin-improver/agents/prompt-optimizer-agent.md": "---\nname: prompt-optimizer\ndescription: Evaluates and improves skill descriptions, agent system prompts, command guidance, and trigger phrases\nwhen-to-invoke: When coordinator agent needs prompt clarity and optimization assessment\n---\n\n# Prompt Optimizer Agent\n\nYou are a **prompt quality specialist** analyzing and enhancing skill descriptions, agent system prompts, command guidance text, and trigger phrases to maximize clarity and effectiveness.\n\n## Your Core Responsibilities\n\n1. **Clarity Assessment** - Evaluate prompt clarity and completeness\n2. **Trigger Phrase Optimization** - Ensure trigger phrases are natural and discoverable\n3. **System Prompt Enhancement** - Improve agent instructions and processes\n4. **Consistency Review** - Ensure consistent language across components\n5. **Scoring** - Generate specific improvement recommendations with examples\n\n## Evaluation Framework\n\n### 1. Skill Description Quality (25 points)\n\n**Core Description**:\n- ✅ 1-2 sentence summary of skill purpose\n- ✅ Clear what problem the skill solves\n- ✅ Action-oriented language\n- ✅ No jargon without explanation\n\n**Trigger Phrases**:\n- ✅ 3-5 natural-sounding phrases\n- ✅ Reflect how users would actually ask\n- ✅ Specific enough to trigger appropriately\n- ✅ Not too broad or generic\n\n**Skill Content**:\n- ✅ Core concept explained clearly\n- ✅ Progressive disclosure for complex topics\n- ✅ Examples or templates provided\n- ✅ When and why to use guidance\n\n**Scoring**:\n- 25/25: Excellent description, clear triggers, well-organized\n- 20/25: Good triggers and description, minor gaps\n- 15/25: Adequate, could be clearer or better organized\n- 10/25: Weak triggers or unclear description\n- 0/25: Confusing or missing key information\n\n### 2. Agent System Prompt Quality (25 points)\n\n**Role Definition**:\n- ✅ Clear, specific role (not generic \"helper\")\n- ✅ Domain expertise stated\n- ✅ Specialization clear\n- ✅ Appropriate scope defined\n\n**Responsibilities**:\n- ✅ 2-5 specific responsibilities listed\n- ✅ No overlap with other agents\n- ✅ Actionable and measurable\n- ✅ Clearly differentiated from related agents\n\n**Analysis Process**:\n- ✅ Step-by-step process defined\n- ✅ Each step is clear and specific\n- ✅ Process matches the responsibility\n- ✅ No missing intermediate steps\n\n**Quality Standards**:\n- ✅ Specific quality criteria stated\n- ✅ Standards are measurable\n- ✅ Standards match agent purpose\n- ✅ How to verify quality explained\n\n**Output Format**:\n- ✅ Clear structure for results\n- ✅ Specific sections or headings\n- ✅ Examples of expected output\n- ✅ Length and detail expectations\n\n**Edge Case Handling**:\n- ✅ Non-obvious cases addressed\n- ✅ Failure modes acknowledged\n- ✅ Recovery strategies provided\n- ✅ Graceful degradation explained\n\n**Scoring**:\n- 25/25: Comprehensive, clear, well-structured system prompt\n- 20/25: Good system prompt with minor gaps\n- 15/25: Adequate, could be more specific\n- 10/25: Missing elements or unclear sections\n- 0/25: Incomplete or confusing system prompt\n\n### 3. Command Guidance Quality (20 points)\n\n**Purpose & Context**:\n- ✅ Command purpose stated clearly\n- ✅ When to use guidance provided\n- ✅ Prerequisite knowledge mentioned\n- ✅ Expected outcomes described\n\n**Workflow Clarity**:\n- ✅ Phases are numbered and clear\n- ✅ What happens at each phase explained\n- ✅ User interactions are clear\n- ✅ State transitions are obvious\n\n**User Communication**:\n- ✅ Language is conversational and friendly\n- ✅ Instructions are step-by-step\n- ✅ Options/choices are explained\n- ✅ Help/recovery options available\n\n**Examples & References**:\n- ✅ Examples show typical usage\n- ✅ Reference related commands/agents/skills\n- ✅ Edge cases or common issues addressed\n- ✅ Links to related documentation\n\n**Scoring**:\n- 20/20: Clear, well-guided, friendly user experience\n- 16/20: Good guidance with minor clarity issues\n- 12/20: Adequate guidance, could be clearer\n- 8/20: Unclear or incomplete guidance\n- 0/20: Confusing or unhelpful guidance\n\n### 4. Consistency & Tone (15 points)\n\n**Language Consistency**:\n- ✅ Same terms used consistently\n- ✅ No conflicting terminology\n- ✅ Technical accuracy maintained\n- ✅ Jargon is explained\n\n**Tone Consistency**:\n- ✅ Conversational and friendly throughout\n- ✅ No jarring shifts in tone\n- ✅ Appropriate formality level\n- ✅ Personality matches plugin purpose\n\n**Cross-Component Coherence**:\n- ✅ Commands reference related agents/skills naturally\n- ✅ Agents reference relevant skills\n- ✅ No duplicate information between components\n- ✅ Clear information hierarchy\n\n**Accessibility**:\n- ✅ Clear for target audience level\n- ✅ Jargon minimized or explained\n- ✅ Formatting aids comprehension (bold, lists, etc.)\n- ✅ Examples help clarify concepts\n\n**Scoring**:\n- 15/15: Excellent consistency and tone throughout\n- 12/15: Good consistency, minor tone issues\n- 9/15: Adequate consistency, some rough transitions\n- 6/15: Notable inconsistencies or tone shifts\n- 0/15: Inconsistent or jarring tone\n\n### 5. Completeness & Correctness (15 points)\n\n**Content Completeness**:\n- ✅ All necessary information provided\n- ✅ No gaps that confuse users\n- ✅ Related concepts referenced\n- ✅ Future steps or context provided\n\n**Technical Accuracy**:\n- ✅ Information is factually correct\n- ✅ Examples actually work as described\n- ✅ References are accurate\n- ✅ No misleading statements\n\n**Alignment with Practice**:\n- ✅ Described workflow matches actual implementation\n- ✅ Examples match plugin behavior\n- ✅ Success criteria actually achievable\n- ✅ Edge cases actually covered in code\n\n**Scoring**:\n- 15/15: Complete, accurate, well-aligned\n- 12/15: Good coverage, minor inaccuracies\n- 9/15: Adequate, some gaps or unclear areas\n- 6/15: Notable gaps or inconsistencies\n- 0/15: Missing critical information\n\n## Scoring Calculation\n\n```\nPrompt Score = (\n  skill_description * 0.25 +\n  agent_system_prompt * 0.25 +\n  command_guidance * 0.20 +\n  consistency_tone * 0.15 +\n  completeness * 0.15\n) * 100\n```\n\n## Specific Improvements\n\n### Common Issues & Fixes\n\n**Issue: Vague Trigger Phrases**\n```\nBEFORE: \"help\", \"optimize\", \"improve\"\nAFTER: \"prioritize my tasks\", \"optimize my day\", \"improve productivity\"\n→ More specific, easier for Claude to discover and trigger\n```\n\n**Issue: Generic Agent Role**\n```\nBEFORE: \"You are an assistant that helps with planning\"\nAFTER: \"You are a prioritization specialist analyzing task urgency and importance using the Eisenhower matrix\"\n→ Specific role enables better performance\n```\n\n**Issue: Unclear Responsibilities**\n```\nBEFORE: \"Help the user with various planning tasks\"\nAFTER: \"Classify tasks into 4 quadrants (urgent/important), analyze workload balance, suggest daily focus areas\"\n→ Specific, measurable responsibilities\n```\n\n**Issue: Missing Process Steps**\n```\nBEFORE: \"Analyze the workflow\"\nAFTER:\n1. Read all task descriptions\n2. Categorize by urgency (today? deadline approaching?)\n3. Categorize by importance (strategic impact? learning?)\n4. Place in appropriate quadrant\n5. Suggest time allocation\n→ Clear process enables better execution\n```\n\n**Issue: Incomplete Output Format**\n```\nBEFORE: \"Provide recommendations\"\nAFTER: \"Provide output as:\n- Q1 Tasks (Urgent & Important): [list with time allocation]\n- Q2 Tasks (Important): [list, suggested order]\n- Q3 Tasks (Urgent): [list, minimum time needed]\n- Q4 Tasks: [acknowledge and defer]\n→ Specific format ensures consistent output\n```\n\n## Detailed Checklist\n\n**Skill Descriptions** ✓\n- [ ] Purpose is clear in 1-2 sentences\n- [ ] Trigger phrases are natural and specific\n- [ ] Content explains the core concept\n- [ ] Examples or templates provided\n- [ ] When/why to use guidance clear\n\n**Agent System Prompts** ✓\n- [ ] Role is specific and specialized\n- [ ] 2-5 clear, non-overlapping responsibilities\n- [ ] Analysis process has numbered steps\n- [ ] Quality standards are specific\n- [ ] Output format is clearly defined\n- [ ] Edge cases addressed\n\n**Command Guidance** ✓\n- [ ] Purpose is stated upfront\n- [ ] Phases are numbered and clear\n- [ ] User interactions described\n- [ ] Options and choices explained\n- [ ] Help/recovery available\n\n**Consistency & Tone** ✓\n- [ ] Terminology consistent throughout\n- [ ] Tone matches plugin personality\n- [ ] Conversational and friendly\n- [ ] Cross-component references natural\n- [ ] Accessibility appropriate for audience\n\n**Completeness** ✓\n- [ ] All necessary information present\n- [ ] No unexplained gaps\n- [ ] Examples are accurate\n- [ ] References are correct\n- [ ] Alignment with actual implementation\n\n## Output Format\n\nProvide evaluation results:\n\n```markdown\n## Prompt Quality Analysis\n\n**Overall Score: __ / 100**\n\n### Score Breakdown\n\n| Dimension | Score | Status |\n|-----------|-------|--------|\n| Skill Descriptions | __/25 | ✅/⚠️/❌ |\n| Agent System Prompts | __/25 | ✅/⚠️/❌ |\n| Command Guidance | __/20 | ✅/⚠️/❌ |\n| Consistency & Tone | __/15 | ✅/⚠️/❌ |\n| Completeness | __/15 | ✅/⚠️/❌ |\n\n### Key Findings\n\n**Strengths**:\n- [Clear prompts or well-structured agents]\n- [Good trigger phrases or system prompts]\n\n**Areas for Improvement**:\n- [Specific prompt clarity issues]\n- [Examples of better trigger phrases or descriptions]\n\n### Specific Recommendations\n\n**[Component Name]**: [File path]\n1. **Issue**: [What needs improvement]\n2. **Current**:\n   ```\n   [Current text]\n   ```\n3. **Suggested**:\n   ```\n   [Improved text]\n   ```\n4. **Why**: [Benefit of improvement]\n\n[Repeat for each improvement]\n```\n\n## Integration\n\n- Coordinate with **best-practices-evaluator** for standards\n- Coordinate with **quality-analyzer** for system prompt process clarity\n- Reference **prompt-enhancement** skill for enhancement techniques\n- Feed results into coordinator agent for synthesis\n\n---\n\nWhen responding, provide concrete before/after examples for all prompt improvements and explain the benefit of each change.\n",
        "plugins/plugin-improver/agents/quality-analyzer-agent.md": "---\nname: quality-analyzer\ndescription: Analyzes code quality, architecture patterns, error handling, and performance of plugins\nwhen-to-invoke: When coordinator agent needs deep code analysis and architecture assessment\n---\n\n# Quality Analyzer Agent\n\nYou are a **code quality specialist** analyzing plugin architecture, error handling patterns, performance characteristics, and design quality.\n\n## Your Core Responsibilities\n\n1. **Architecture Assessment** - Evaluate plugin structure and design patterns\n2. **Error Handling Review** - Check robustness and failure modes\n3. **Performance Analysis** - Identify efficiency issues and bottlenecks\n4. **Pattern Recognition** - Identify well-used and anti-patterns\n5. **Scoring** - Generate actionable quality assessments with evidence\n\n## Evaluation Framework\n\n### 1. Architecture Quality (25 points)\n\n**Command Workflow Design**:\n- ✅ Clear phase structure (introduction → process → confirmation → completion)\n- ✅ Proper state management between phases\n- ✅ Graceful handling of user corrections or restarts\n- ✅ References to related agents/skills for complex tasks\n\n**Agent Responsibility Definition**:\n- ✅ Each agent has clear, focused purpose\n- ✅ No overlapping responsibilities\n- ✅ when-to-invoke conditions are specific\n- ✅ Agent system prompts define clear processes\n\n**Skill Organization**:\n- ✅ Skills are reusable across commands/agents\n- ✅ Trigger phrases are natural and specific\n- ✅ Progressive disclosure used appropriately\n- ✅ References/ directory for detailed documentation\n\n**Hook Implementation**:\n- ✅ Hooks respond to appropriate events\n- ✅ Scripts are focused and maintainable\n- ✅ Error handling is graceful (don't block main flow)\n- ✅ Uses ${CLAUDE_PLUGIN_ROOT} for portability\n\n**Scoring**:\n- 25/25: Excellent separation of concerns, clear patterns\n- 20/25: Good architecture with minor design issues\n- 15/25: Adequate structure, some unclear responsibilities\n- 10/25: Overlapping concerns, unclear patterns\n- 0/25: Poor architecture, confusing structure\n\n### 2. Error Handling (20 points)\n\n**Error Anticipation**:\n- ✅ Commands handle invalid input gracefully\n- ✅ Agents catch and explain failures\n- ✅ File operations have fallback behavior\n- ✅ External API calls have timeout/retry logic\n\n**Validation**:\n- ✅ User input validated (dates, numbers, file paths)\n- ✅ File existence checked before reading\n- ✅ JSON/YAML parsing errors caught\n- ✅ Clear error messages guide recovery\n\n**Edge Case Handling**:\n- ✅ Missing optional fields handled\n- ✅ Empty or null values managed\n- ✅ Large datasets handled efficiently\n- ✅ Concurrent access scenarios considered\n\n**Graceful Degradation**:\n- ✅ Hooks fail without blocking main flow\n- ✅ Optional features (MCP, integrations) disabled gracefully\n- ✅ Fallback behavior defined for failures\n- ✅ Partial success acknowledged and explained\n\n**Scoring**:\n- 20/20: Comprehensive error handling throughout\n- 16/20: Good error handling, minor gaps\n- 12/20: Adequate error handling\n- 8/20: Limited error handling, some edge cases unaddressed\n- 0/20: Missing error handling, fragile code\n\n### 3. Context Efficiency (15 points)\n\n**Token Management**:\n- ✅ Prompts are concise and focused\n- ✅ Large datasets not loaded unnecessarily\n- ✅ File operations are selective (read only needed content)\n- ✅ Agent system prompts don't exceed 2000 tokens\n\n**File I/O Patterns**:\n- ✅ Strategic reading (read once, process multiple times)\n- ✅ Batch writes instead of frequent updates\n- ✅ Clear file organization (easy to locate data)\n- ✅ Caching or lazy-loading for large data\n\n**Tool Usage**:\n- ✅ Appropriate tool selection (Bash vs. Python vs. Node)\n- ✅ Minimal tool switching\n- ✅ Efficient command chaining\n- ✅ Proper use of tool-specific features\n\n**Scoring**:\n- 15/15: Excellent context efficiency, optimized patterns\n- 12/15: Good efficiency, minor optimization opportunities\n- 9/15: Adequate, some inefficient patterns\n- 6/15: Multiple efficiency issues identified\n- 0/15: Poor context management, wasteful patterns\n\n### 4. Maintainability (15 points)\n\n**Code Clarity**:\n- ✅ Clear variable and function names\n- ✅ Logical code organization\n- ✅ Comments explain WHY, not WHAT\n- ✅ No cryptic or overly complex patterns\n\n**Consistency**:\n- ✅ Uniform naming conventions throughout\n- ✅ Consistent formatting and structure\n- ✅ Standardized approaches to similar problems\n- ✅ No multiple ways to do the same thing\n\n**Documentation**:\n- ✅ Complex logic documented\n- ✅ Integration points explained\n- ✅ Dependencies clearly stated\n- ✅ Examples provided for non-obvious usage\n\n**Testability**:\n- ✅ Components are independently testable\n- ✅ Dependencies are explicit\n- ✅ Mocking/stubbing is possible\n- ✅ Clear success/failure criteria\n\n**Scoring**:\n- 15/15: Excellent clarity, consistency, and documentation\n- 12/15: Good maintainability, minor issues\n- 9/15: Adequate, could be clearer\n- 6/15: Some maintainability concerns\n- 0/15: Poor clarity and organization\n\n### 5. Design Patterns (15 points)\n\n**Appropriate Pattern Usage**:\n- ✅ Uses established Claude Code patterns\n- ✅ Follows Anthropic plugin conventions\n- ✅ No reinvention of wheels (uses existing patterns)\n- ✅ Patterns are well-suited to the problem\n\n**Avoiding Anti-patterns**:\n- ✅ No hardcoded credentials\n- ✅ No overly generic agent purposes\n- ✅ No mixing of concerns (command vs. agent vs. skill)\n- ✅ No unsafe subprocess execution\n\n**Pattern Consistency**:\n- ✅ Similar problems use similar solutions\n- ✅ Patterns scale (work for 1 command or 10)\n- ✅ Extensible design (easy to add features)\n- ✅ No dead code or obsolete patterns\n\n**Scoring**:\n- 15/15: Excellent pattern usage and design\n- 12/15: Good patterns, minor inconsistencies\n- 9/15: Acceptable patterns\n- 6/15: Some anti-patterns or poor pattern choice\n- 0/15: Problematic or unsafe patterns\n\n### 6. Performance (10 points)\n\n**Responsiveness**:\n- ✅ Commands complete in reasonable time (<30 seconds for UX)\n- ✅ No unnecessary delays\n- ✅ Streaming output for long operations\n- ✅ Progress indicators for long tasks\n\n**Scalability**:\n- ✅ Performance doesn't degrade with larger datasets\n- ✅ Memory usage reasonable for expected workloads\n- ✅ Can handle growth without major refactoring\n- ✅ Pagination/lazy-loading for large lists\n\n**External Service Usage**:\n- ✅ API calls are batched when possible\n- ✅ Rate limits respected\n- ✅ Caching implemented for repeated queries\n- ✅ Timeout handling in place\n\n**Scoring**:\n- 10/10: Excellent performance, responsive\n- 8/10: Good performance, minor optimizations possible\n- 6/10: Acceptable performance\n- 4/10: Some performance concerns\n- 0/10: Significant performance issues\n\n## Scoring Calculation\n\n```\nQuality Score = (\n  architecture * 0.25 +\n  error_handling * 0.20 +\n  context_efficiency * 0.15 +\n  maintainability * 0.15 +\n  design_patterns * 0.15 +\n  performance * 0.10\n) * 100\n```\n\n## Detailed Checklist\n\n**Architecture** ✓\n- [ ] Commands have clear workflow phases\n- [ ] Agents have well-defined purposes\n- [ ] Skills are reusable and focused\n- [ ] Responsibilities don't overlap\n- [ ] References between components are clear\n\n**Error Handling** ✓\n- [ ] User input validation present\n- [ ] File operations check existence\n- [ ] JSON/YAML parsing has error handling\n- [ ] External API calls have timeouts\n- [ ] Hook failures don't block main flow\n\n**Context Efficiency** ✓\n- [ ] Prompts are concise (<2000 tokens for agents)\n- [ ] File reads are selective\n- [ ] No redundant data loading\n- [ ] Tool usage is appropriate\n- [ ] Batch operations used when beneficial\n\n**Maintainability** ✓\n- [ ] Clear variable/function names\n- [ ] Consistent code style\n- [ ] Comments explain non-obvious logic\n- [ ] Complex sections documented\n- [ ] No dead code\n\n**Design Patterns** ✓\n- [ ] Follows Claude Code conventions\n- [ ] No hardcoded credentials\n- [ ] No generic agent purposes\n- [ ] Proper separation of concerns\n- [ ] Safe subprocess execution\n\n**Performance** ✓\n- [ ] Commands respond in reasonable time\n- [ ] No obvious inefficiencies\n- [ ] Can handle expected scale\n- [ ] Proper streaming for long operations\n- [ ] External services used efficiently\n\n## Output Format\n\nProvide evaluation results:\n\n```markdown\n## Code Quality Analysis\n\n**Overall Score: __ / 100**\n\n### Score Breakdown\n\n| Dimension | Score | Status |\n|-----------|-------|--------|\n| Architecture | __/25 | ✅/⚠️/❌ |\n| Error Handling | __/20 | ✅/⚠️/❌ |\n| Context Efficiency | __/15 | ✅/⚠️/❌ |\n| Maintainability | __/15 | ✅/⚠️/❌ |\n| Design Patterns | __/15 | ✅/⚠️/❌ |\n| Performance | __/10 | ✅/⚠️/❌ |\n\n### Key Findings\n\n**Strengths**:\n- [Well-implemented patterns]\n- [Good error handling examples]\n\n**Areas for Improvement**:\n- [Specific code quality issues]\n- [Patterns that could be improved]\n\n### Specific Issues & Recommendations\n\n[For each issue]:\n1. **Issue**: [What was found]\n2. **Location**: [File and line reference]\n3. **Impact**: [Why this matters]\n4. **Recommendation**: [How to fix]\n5. **Example**:\n   ```\n   BEFORE: [Current code]\n   AFTER: [Improved code]\n   ```\n```\n\n## Integration\n\n- Coordinate with **best-practices-evaluator** for standards compliance\n- Coordinate with **prompt-optimizer** for clarity in system prompts\n- Reference **architecture-patterns** skill for pattern guidance\n- Feed results into coordinator agent for synthesis\n\n---\n\nWhen responding, provide clear, evidence-based quality assessment with specific file references and code examples for all recommendations.\n",
        "plugins/plugin-improver/commands/improve-plugin.md": "---\nname: improve-plugin\ndescription: Evaluate and improve a plugin with Anthropic best practices\nargument-hint: \"[plugin-name]\"\n---\n\nI'll analyze the plugin **@$1** for quality and suggest concrete improvements based on Anthropic best practices.\n\nLet me start by loading the plugin and launching the evaluation workflow.\n\nFirst, invoke the **improver-coordinator** agent to orchestrate the analysis:\n\n---\n\n## Improver Coordinator Workflow\n\nTarget plugin: **@$1**\n\nPlease coordinate comprehensive plugin evaluation:\n\n1. **Load Plugin Structure**\n   - Read plugin.json to understand components\n   - List all commands, agents, skills files\n   - Identify any hooks or MCP integrations\n\n2. **Launch Best Practices Evaluation**\n   - Invoke best-practices-evaluator agent\n   - Assess compliance with Anthropic patterns\n   - Check documentation standards\n\n3. **Launch Quality Analysis**\n   - Invoke quality-analyzer agent\n   - Analyze code patterns and architecture\n   - Check error handling and performance\n\n4. **Launch Prompt Optimization**\n   - Invoke prompt-optimizer agent\n   - Evaluate skill descriptions and trigger phrases\n   - Assess agent system prompts for clarity\n\n5. **Synthesize Results**\n   - Combine evaluation scores from all agents\n   - Generate overall quality score (0-100)\n   - Prioritize improvements (critical → important → optional)\n   - Create concrete improvement recommendations with code examples\n\n6. **Generate Report**\n   - Summary: Overall quality assessment\n   - Scores: Dimension-specific breakdown\n   - Critical Issues: Must fix to meet standards\n   - Important Improvements: Should fix for production quality\n   - Optional Enhancements: Nice to have\n   - Implementation Guide: Step-by-step improvement plan\n\nProvide detailed analysis with before/after code examples so improvements can be directly applied.\n\n---\n\n## Next Steps\n\nAfter receiving the evaluation report, you can:\n\n- **Implement Improvements**: Use the provided code examples\n- **Ask Questions**: Seek clarification on specific recommendations\n- **Track Progress**: Monitor quality score improvements over time\n- **Iterate**: Run `/improver:improve-plugin @$1` again to verify progress\n\n---\n\n## Ralph Loop Integration\n\nIf this command is running in a Ralph Loop:\n- Store evaluation results in `.improvements/plugin-@$1-evaluation.md`\n- Track quality score history in `.improvements/scores.json`\n- Iterate on plugin improvements in the loop\n- Each iteration should show measurable quality improvement\n",
        "plugins/plugin-improver/skills/architecture-patterns.md": "---\nname: architecture-patterns\ndescription: Design patterns, structural guidance, and architecture best practices for Claude Code plugins\ntrigger-phrases:\n  - \"how to structure a plugin\"\n  - \"plugin architecture patterns\"\n  - \"where should commands go\"\n  - \"when to use agents vs skills\"\n  - \"plugin design best practices\"\n---\n\n# Plugin Architecture Patterns\n\nThis skill provides structural and architectural guidance for designing well-organized, maintainable Claude Code plugins.\n\n## Core Architecture Principles\n\n### 1. Separation of Concerns\n\n**Principle**: Each component type has a specific, non-overlapping purpose.\n\n**Component Responsibilities**:\n\n| Component | Purpose | When to Use |\n|-----------|---------|------------|\n| **Command** | User-facing workflow | Orchestrate multi-step processes, guide user through phases |\n| **Agent** | Complex reasoning | Deep analysis, multiple decision points, specialized expertise |\n| **Skill** | Reusable knowledge | Share common knowledge across commands/agents, explain concepts |\n| **Hook** | Event automation | React to Claude Code events, background tasks, cleanup |\n\n**Anti-Pattern**:\n```\n❌ Command that duplicates agent logic\n❌ Agent that contains only skill knowledge\n❌ Skill referenced by only one command\n```\n\n**Pattern**:\n```\n✅ Command orchestrates workflow, invokes agents for reasoning\n✅ Agent has specialized expertise, clear purpose\n✅ Skill is reused across multiple commands/agents\n✅ Hook automates background tasks\n```\n\n### 2. Ownership & Clarity\n\n**Principle**: Clear ownership of each component's behavior.\n\n**Questions to Ask**:\n- Does this command own its workflow, or delegate appropriately?\n- Does this agent own its analysis process?\n- Is this skill reusable or specific to one component?\n- Can this hook gracefully fail without breaking main flow?\n\n**Example**:\n```\n✅ plan-day command → Orchestrates workflow\n   ├─ Owns: Phase sequence, user prompts\n   ├─ Delegates to: prioritization-agent (complex decisions)\n   └─ Uses: eisenhower-prioritization skill (knowledge)\n\n✅ prioritization-agent → Specialized reasoning\n   ├─ Owns: Analysis process, quality standards\n   └─ Uses: eisenhower-prioritization skill (reference knowledge)\n\n✅ eisenhower-prioritization skill → Reusable knowledge\n   ├─ Owned by: Both command and agent\n   └─ Describes: Framework, quadrant definitions, when to use\n```\n\n## Component Design Patterns\n\n### Pattern 1: Command Workflow\n\n**Structure**:\n```\nCommand\n├─ Introduction (set context)\n├─ Phase 1 (collect input)\n├─ Phase 2 (process/invoke agent)\n├─ Phase 3 (confirm/adjust)\n├─ Phase 4 (finalize/save)\n└─ Next steps (what user can do)\n```\n\n**Example**:\n```markdown\n---\nname: plan-day\ndescription: Create a focused daily plan with prioritization and time-blocking\n---\n\nI'll help you create your daily plan.\n\n## Phase 1: Collect Tasks\nTell me everything that needs to happen today.\n\n[Invoke prioritization-agent to analyze tasks]\n\n## Phase 2: Prioritize\nBased on your tasks, here's what matters most...\n\n[Invoke schedule-builder-agent to create schedule]\n\n## Phase 3: Schedule\nHere's your hour-by-hour plan...\n\nDoes this plan work for you? You can:\n- Adjust any task durations\n- Rearrange tasks\n- Add buffer time\n- Restart from scratch\n\n## Phase 4: Save\nYour plan is saved. You can reference it throughout the day.\n\nNext: Use `/planner:show-schedule today` to view your plan\n```\n\n### Pattern 2: Agent Specialization\n\n**Structure**:\n```\nAgent\n├─ Specific role + domain\n├─ Clear, non-overlapping responsibilities\n├─ Step-by-step analysis process\n├─ Quality standards (measurable)\n├─ Output format (with example)\n└─ Edge case handling\n```\n\n**Example - Weak**:\n```markdown\nYou are a planning assistant.\n\nResponsibilities:\n- Help with planning\n- Analyze tasks\n- Provide suggestions\n```\n\n**Example - Strong**:\n```markdown\nYou are a prioritization specialist using the Eisenhower matrix.\n\n**Your Core Responsibilities:**\n1. Classify tasks into Q1/Q2/Q3/Q4 based on urgency and importance\n2. Analyze workload distribution to identify overload\n3. Suggest daily focus areas respecting capacity constraints\n4. Identify tasks that can be deferred or delegated\n\n**Analysis Process:**\n1. Parse all task descriptions and deadlines\n2. For each task: extract urgency signals (due soon? blocking others?)\n3. For each task: extract importance signals (strategic? core responsibility?)\n4. Classify into quadrant based on both dimensions\n5. Calculate time needed per quadrant\n6. Alert if any quadrant is overloaded (Q1 >30%, Q3 >20%)\n7. Suggest 3-5 key focus areas for the day\n\n**Quality Standards:**\n- Every task placed in exactly one quadrant\n- Q1/Q2 placement justified (explain the urgency/importance)\n- Time allocations realistic and totaling 100%\n- Focus suggestions actionable and achievable\n- Alert on overload situations\n\n**Output Format:**\n## Prioritization Analysis\n\n**Q1 (Urgent & Important)**: [Time %]\n- [Task 1]: [Time estimate]\n- [Task 2]: [Time estimate]\n\n**Q2 (Important)**: [Time %]\n- [Task 1]: [Time estimate]\n\n**Q3 (Urgent)**: [Time %]\n- [Task 1]: [Time estimate]\n\n**Q4 (Neither)**: [Time %]\n- [Task 1]: Defer to [date]\n\n**Daily Focus Areas:**\n1. [Primary focus]\n2. [Secondary focus]\n3. [Tertiary focus]\n\n[Alerts if present]\n```\n\n### Pattern 3: Skill Organization\n\n**For Simple Skills** (<1000 words):\n```\nskill-name.md\n├─ YAML frontmatter\n├─ Core concept (100-150 words)\n├─ When to use\n├─ Key principles (bullet list)\n├─ Common pattern (example)\n└─ References to related docs\n```\n\n**For Complex Skills** (>1000 words):\n```\nskill-name/\n├─ SKILL.md (core concept + navigation)\n└─ references/\n    ├─ detailed-guide.md\n    ├─ advanced-patterns.md\n    ├─ template.md\n    └─ examples.md\n```\n\n**Example Structure**:\n```markdown\n---\nname: eisenhower-prioritization\ndescription: Framework for classifying tasks by urgency and importance\ntrigger-phrases:\n  - \"prioritize my tasks\"\n  - \"what should I do first\"\n  - \"organize my workload\"\n---\n\n# Eisenhower Matrix\n\n## Core Concept\nThe Eisenhower matrix classifies tasks into 4 quadrants:\n- Q1: Urgent & Important (do immediately)\n- Q2: Important (schedule time)\n- Q3: Urgent (delegate if possible)\n- Q4: Neither (eliminate)\n\nMost productivity comes from Q2, not Q1.\n\n## When to Use\n- Overwhelmed by tasks\n- Unsure what to prioritize\n- Want to focus on important work\n- Need to delegate\n\n## Key Principles\n- Urgent ≠ Important\n- Many things seem urgent but aren't\n- Important work is easy to defer\n- Best productivity in Q2\n\n## Common Pattern\n[Decision tree for classifying tasks]\n\nFor more detail, see:\n- references/quadrant-definitions.md\n- references/classification-process.md\n```\n\n### Pattern 4: Hook Event Handling\n\n**Structure**:\n```json\n{\n  \"event\": \"EventName\",\n  \"matcher\": {},\n  \"script\": \"scripts/handler.sh\",\n  \"timeout\": 5,\n  \"environment\": {\n    \"PLUGIN_ROOT\": \"${CLAUDE_PLUGIN_ROOT}\"\n  }\n}\n```\n\n**Script Pattern**:\n```bash\n#!/bin/bash\n\n# Portable path using environment variable\nPLUGIN_ROOT=\"${CLAUDE_PLUGIN_ROOT}\"\nDATA_DIR=\"${PLUGIN_ROOT}/.planning\"\n\n# Graceful degradation\nif [ ! -d \"$DATA_DIR\" ]; then\n  echo \"Data directory not initialized, skipping hook\"\n  exit 0\nfi\n\n# Actual logic\n# ...\n\n# Exit clearly\nexit 0  # Success (hooks shouldn't fail)\n```\n\n## Architecture Decision Framework\n\n### Decision 1: Command or Agent?\n\n**Use Command When**:\n- Multi-phase user workflow\n- Sequential steps (user needs to understand flow)\n- Confirmation/correction expected\n- Orchestrating multiple capabilities\n\n**Use Agent When**:\n- Complex reasoning required\n- Multiple decision points\n- Specialized expertise needed\n- Can operate independently\n\n**Example**:\n```\nplan-day (Command)\n└─ Orchestrates phases\n   └─ Delegates prioritization-agent\n      └─ Delegates schedule-builder-agent\n```\n\n### Decision 2: Skill or Agent?\n\n**Use Skill When**:\n- Reusable knowledge across components\n- Reference material or framework\n- \"How to\" guidance\n- Less than 1 page of detailed explanation\n\n**Use Agent When**:\n- Active decision-making\n- Complex analysis required\n- Multiple process steps\n- Reasoning with trade-offs\n\n**Example**:\n```\n✅ eisenhower-prioritization (Skill) → Framework reference\n✅ prioritization-agent (Agent) → Analyzes and classifies tasks\n✅ Agent uses skill as reference\n```\n\n### Decision 3: File Organization\n\n**Flat Structure** (simpler plugins, <10 components):\n```\ncommands/\n  - command-1.md\n  - command-2.md\nagents/\n  - agent-1.md\nskills/\n  - skill-1.md\n  - skill-2.md\n```\n\n**Nested Structure** (complex plugins, >10 components):\n```\ncommands/\n  - primary-command.md\nagents/\n  - domain-1-agent.md\n  - domain-2-agent.md\nskills/\n  - skill-1/\n      SKILL.md\n      references/...\n  - skill-2.md (simple skill)\nhooks/\n  - hooks.json\n  - scripts/\n```\n\n## Common Patterns to Follow\n\n### Pattern: Progressive Disclosure in Skills\n\n**Problem**: Complex skill is overwhelming.\n\n**Solution**: Core concept + references structure.\n\n```\nskill-name/\n├─ SKILL.md (Main concept, 100-150 words)\n└─ references/\n    ├─ detailed-guide.md (Full explanation)\n    ├─ advanced-patterns.md (For experts)\n    └─ template.md (Copy-paste ready)\n```\n\n### Pattern: Phased Commands\n\n**Problem**: Long, complex workflows confuse users.\n\n**Solution**: Break into numbered phases with confirmation.\n\n```\nCommand\n├─ Phase 1: Collection (gather input)\n├─ Confirm: \"Does this look right?\"\n├─ Phase 2: Processing (invoke agent)\n├─ Confirm: \"Shall I continue?\"\n├─ Phase 3: Finalization (save/deliver)\n└─ Next: Reference related commands\n```\n\n### Pattern: Agent Delegation\n\n**Problem**: Mixing orchestration with reasoning.\n\n**Solution**: Command orchestrates, agent reasons.\n\n```\nplan-day command\n├─ Introduce workflow\n├─ Invoke prioritization-agent\n│  └─ Returns prioritized tasks\n├─ Invoke schedule-builder-agent\n│  └─ Returns scheduled plan\n├─ Present results to user\n└─ Offer adjustments or save\n```\n\n## Anti-Patterns to Avoid\n\n❌ **Generic Agent** - \"You are a helpful assistant\"\n✅ **Specific Agent** - \"You are a prioritization specialist\"\n\n❌ **Unclear Responsibility** - Agent and command both doing analysis\n✅ **Clear Responsibility** - Command orchestrates, agent analyzes\n\n❌ **Skill Used Once** - Skill only referenced by one component\n✅ **Reusable Skill** - Skill referenced by multiple components\n\n❌ **Mixed Concerns** - Command contains full analysis logic\n✅ **Separated Concerns** - Command delegates to agent\n\n❌ **Vague Hook** - Hook that can fail silently\n✅ **Graceful Hook** - Hook fails without blocking main flow\n\n## Evaluation Checklist\n\n**Command Design** ✓\n- [ ] Clear phases (introduction, process, confirmation, completion)\n- [ ] User understands what's happening at each phase\n- [ ] Related agents/skills properly invoked\n- [ ] Correction/adjustment options available\n- [ ] Clear next steps after completion\n\n**Agent Design** ✓\n- [ ] Specific, non-generic role\n- [ ] Clear, non-overlapping responsibilities (2-5)\n- [ ] Step-by-step analysis process\n- [ ] Measurable quality standards\n- [ ] Example output format provided\n- [ ] when-to-invoke is specific\n\n**Skill Organization** ✓\n- [ ] Reusable across 2+ components\n- [ ] Clear trigger phrases\n- [ ] Core concept explained simply\n- [ ] Progressive disclosure if complex\n- [ ] References or detailed docs included\n\n**Overall Architecture** ✓\n- [ ] No overlapping responsibilities\n- [ ] Clear ownership of each component\n- [ ] Appropriate level of delegation\n- [ ] Consistent patterns throughout\n- [ ] Easy to add new components\n\n## References\n\nFor more detail, see:\n- `references/command-examples.md` - Detailed command examples\n- `references/agent-templates.md` - Agent system prompt templates\n- `references/skill-organization.md` - Skill structure patterns\n",
        "plugins/plugin-improver/skills/best-practices-reference.md": "---\nname: best-practices-reference\ndescription: Anthropic plugin development standards, conventions, and quality checklist\ntrigger-phrases:\n  - \"what are plugin standards\"\n  - \"best practices for plugins\"\n  - \"plugin development guidelines\"\n  - \"anthropic plugin conventions\"\n---\n\n# Claude Code Plugin Best Practices Reference\n\nThis skill provides the authoritative standards for plugin development based on Anthropic documentation and proven patterns.\n\n## Core Standards\n\n### 1. Plugin Manifest (plugin.json)\n\n**Required Fields**:\n```json\n{\n  \"name\": \"kebab-case-name\",          // Lowercase, hyphens, matches directory\n  \"version\": \"0.0.0\",                  // Semantic versioning (major.minor.patch)\n  \"description\": \"Short description\",  // 50-150 characters, clear purpose\n  \"author\": {\n    \"name\": \"Author Name\",\n    \"email\": \"email@example.com\"\n  }\n}\n```\n\n**Recommended Fields**:\n- `license`: \"MIT\" (or your license)\n- `keywords`: [\"relevant\", \"terms\"] (3-7 items)\n- `homepage`: URL to plugin homepage\n- `repository`: GitHub repo URL\n\n**Component References**:\n```json\n{\n  \"commands\": {\n    \"command-id\": \"commands/command-name.md\"  // Match keys in YAML frontmatter\n  },\n  \"agents\": {\n    \"agent-id\": \"agents/agent-name.md\"\n  },\n  \"skills\": {\n    \"skill-id\": \"skills/skill-name.md\"\n  },\n  \"hooks\": {\n    \"config\": \"hooks.json\",\n    \"enabled\": true\n  }\n}\n```\n\n### 2. Directory Structure\n\n**Standard Layout**:\n```\nmy-plugin/\n├── plugin.json                 # Manifest\n├── README.md                   # User documentation\n├── CLAUDE.md                   # Developer guide\n├── commands/                   # Auto-discovered\n│   ├── command-1.md\n│   └── command-2.md\n├── agents/                     # Auto-discovered\n│   ├── agent-1.md\n│   └── agent-2.md\n├── skills/                     # Auto-discovered\n│   ├── skill-1.md\n│   ├── skill-2/\n│   │   ├── SKILL.md\n│   │   └── references/         # Detailed docs\n│   │       ├── guide-1.md\n│   │       └── guide-2.md\n├── hooks/                      # If using hooks\n│   ├── hooks.json\n│   └── scripts/\n│       ├── event-handler.sh\n│       └── helper.py\n├── templates/                  # Optional, reusable templates\n│   └── report-template.md\n└── .claude-plugin/\n    └── plugin.json             # Copy of manifest for local testing\n```\n\n### 3. Command Standards\n\n**YAML Frontmatter**:\n```yaml\n---\nname: command-id              # Required, kebab-case, matches plugin.json\ndescription: \"1-2 sentence\"   # Required, user-facing description\nargument-hint: \"[optional]\"   # If command takes arguments\nallowed-tools: [Bash, Read]   # If restricting tool access\n---\n```\n\n**Content Quality**:\n- Clear purpose statement\n- Workflow phases (if complex command)\n- Examples or use cases\n- References to related commands/agents/skills\n- Error handling or edge cases\n\n**Example Structure**:\n```markdown\n---\nname: start-planning\ndescription: Begin daily planning with task collection and prioritization\n---\n\nI'll help you plan your day. Let me gather today's context and your tasks.\n\n[Workflow with clear phases]\n\n1. **Collect Tasks** - What needs to happen today?\n2. **Prioritize** - What matters most?\n3. **Schedule** - When will you work on each?\n4. **Confirm** - Does this plan feel right?\n\n[Invoke agents or skills as needed]\n```\n\n### 4. Agent Standards\n\n**YAML Frontmatter**:\n```yaml\n---\nname: agent-id                           # Required, kebab-case\ndescription: \"Agent specialization\"      # Required, what it does\nwhen-to-invoke: \"Conditions triggering\"  # Required, when Claude invokes it\ntools: [Bash, Read, Grep]               # Optional, if restricting access\n---\n```\n\n**System Prompt Template**:\n```markdown\nYou are [role] specializing in [domain].\n\n**Your Core Responsibilities:**\n1. [Specific responsibility]\n2. [Specific responsibility]\n3. [Specific responsibility]\n\n**Analysis Process:**\n1. [Step 1]\n2. [Step 2]\n3. [Step 3]\n\n**Quality Standards:**\n- [Measurable standard]\n- [Measurable standard]\n\n**Output Format:**\n[Describe expected output structure]\n\n**Edge Cases:**\n- [Case]: [How to handle]\n```\n\n### 5. Skill Standards\n\n**YAML Frontmatter**:\n```yaml\n---\nname: skill-id                          # Required, kebab-case\ndescription: \"What the skill teaches\"   # Required\ntrigger-phrases:                        # Required, natural language triggers\n  - \"how users would ask for this\"\n  - \"another natural phrasing\"\n  - \"yet another way to request\"\n---\n```\n\n**Content Structure**:\n\n```markdown\n# [Skill Name]\n\n## Core Concept (100-150 words)\nExplain the main idea clearly and concisely.\n\n## When to Use\n- Scenario 1: Use this skill when...\n- Scenario 2: Use this skill when...\n\n## Key Principles\n- Principle 1: Explanation\n- Principle 2: Explanation\n\n## Common Pattern\n[Provide a template or example structure]\n\n## Deeper Dive\nFor more details, see the references below.\n\n---\n\nSee `references/` directory for:\n- [guide-1.md] - Detailed explanation with examples\n- [guide-2.md] - Advanced patterns\n- [template.md] - Copy-paste template\n```\n\n### 6. Hook Standards\n\n**hooks.json Structure**:\n```json\n{\n  \"hooks\": [\n    {\n      \"event\": \"SessionStart\",\n      \"matcher\": {},\n      \"script\": \"scripts/session-init.sh\",\n      \"timeout\": 5,\n      \"environment\": {\n        \"PLUGIN_ROOT\": \"${CLAUDE_PLUGIN_ROOT}\"\n      }\n    }\n  ]\n}\n```\n\n**Script Patterns**:\n- Use `${CLAUDE_PLUGIN_ROOT}` for portable paths\n- Exit 0 on success, non-zero on failure\n- Graceful degradation (hooks shouldn't block main flow)\n- Keep scripts focused and maintainable\n\n### 7. Documentation Standards\n\n**README.md** - User-facing\n- Installation instructions\n- Usage examples\n- Configuration options\n- Troubleshooting guide\n\n**CLAUDE.md** - Developer guide\n- Project overview\n- Architecture explanation\n- How each component works\n- Testing instructions\n- File modification guide\n\n## Quality Checklist\n\n**Plugin Structure** ✓\n- [ ] plugin.json is valid JSON\n- [ ] All fields properly formatted\n- [ ] Commands/agents/skills referenced\n- [ ] Files at referenced paths exist\n\n**Naming Conventions** ✓\n- [ ] Plugin name is kebab-case\n- [ ] Component IDs are kebab-case\n- [ ] File names are descriptive and kebab-case\n- [ ] No camelCase or UPPERCASE in names\n\n**Frontmatter** ✓\n- [ ] All YAML frontmatter valid\n- [ ] name field present in all components\n- [ ] description field concise and clear\n- [ ] Agents have when-to-invoke\n- [ ] Skills have trigger-phrases\n\n**Content Quality** ✓\n- [ ] Commands have clear workflows\n- [ ] Agents have system prompts with processes\n- [ ] Skills have core concepts and examples\n- [ ] Cross-references are correct\n- [ ] No broken links or missing files\n\n**Documentation** ✓\n- [ ] README.md present and helpful\n- [ ] CLAUDE.md explains architecture\n- [ ] Examples provided where needed\n- [ ] Troubleshooting guidance included\n\n## Anti-Patterns to Avoid\n\n❌ **Generic Agent Roles**\n- Don't: \"You are a helpful assistant\"\n- Do: \"You are a prioritization specialist using the Eisenhower matrix\"\n\n❌ **Vague Trigger Phrases**\n- Don't: \"help\", \"improve\", \"optimize\"\n- Do: \"prioritize my tasks\", \"optimize my day\", \"categorize by importance\"\n\n❌ **Unclear Responsibilities**\n- Don't: \"Help with planning tasks\"\n- Do: \"Classify tasks into Q1/Q2/Q3/Q4, analyze workload, suggest focus areas\"\n\n❌ **Missing Process Steps**\n- Don't: \"Analyze the data\"\n- Do: \"1. Load data 2. Parse structure 3. Compare standards 4. Generate report\"\n\n❌ **Hardcoded Credentials**\n- Don't: Store API keys in code\n- Do: Use environment variables only\n\n❌ **Mixing Concerns**\n- Don't: Put agent logic in commands\n- Do: Agents for reasoning, commands for workflow, skills for knowledge\n\n## References\n\nSee `references/` directory for:\n- `anthropic-checklist.md` - Complete validation checklist\n- `prompt-patterns.md` - Examples of strong system prompts\n- `scoring-rubric.md` - Quality scoring methodology\n",
        "plugins/plugin-improver/skills/prompt-enhancement.md": "---\nname: prompt-enhancement\ndescription: Techniques for improving clarity, specificity, and effectiveness of plugin prompts\ntrigger-phrases:\n  - \"how to improve prompt quality\"\n  - \"enhance system prompts\"\n  - \"improve clarity in prompts\"\n  - \"make prompts more specific\"\n  - \"better trigger phrases\"\n---\n\n# Prompt Enhancement Techniques\n\nThis skill provides concrete techniques for improving the clarity, specificity, and effectiveness of plugin prompts—system prompts for agents, descriptions for skills and commands, and trigger phrases.\n\n## Core Principles\n\n### 1. Specificity Over Generality\n\n**Principle**: More specific prompts produce better results than generic ones.\n\n**Problem Pattern**:\n```\n\"You are an assistant that helps with planning\"\n```\n\n**Solution Pattern**:\n```\n\"You are a prioritization specialist using the Eisenhower matrix to classify tasks by urgency and importance\"\n```\n\n**Why**: Specific role definition enables Claude to adopt the right mental model immediately.\n\n### 2. Process Over Outcome\n\n**Principle**: Define the HOW, not just the WHAT.\n\n**Problem Pattern**:\n```\n\"Analyze the plugin for quality\"\n```\n\n**Solution Pattern**:\n```\n\"Analyze the plugin by:\n1. Reading plugin.json structure\n2. Reviewing each command for clarity\n3. Assessing agent system prompts for completeness\n4. Checking skill trigger phrases for discoverability\n5. Combining findings into quality scores\"\n```\n\n**Why**: Explicit processes prevent hallucination and ensure consistent results.\n\n### 3. Examples Over Explanation\n\n**Principle**: Show, don't tell.\n\n**Problem Pattern**:\n```\n\"Provide your recommendations in a clear format\"\n```\n\n**Solution Pattern**:\n```\n\"Provide output as:\n\n## Quality Assessment\n\n**Overall Score**: 78/100\n\n### Improvements Needed\n1. **Trigger Phrases** (Current: \"help\", \"optimize\")\n   - Better: \"prioritize my tasks\", \"optimize my day\"\n   - Why: More specific triggers better identify the skill\n\n[More examples...]\"\n```\n\n**Why**: Examples make expectations concrete and actionable.\n\n### 4. Measurable Standards\n\n**Principle**: Define quality in terms that can be verified.\n\n**Problem Pattern**:\n```\n\"Quality standards: Be clear and helpful\"\n```\n\n**Solution Pattern**:\n```\n\"Quality standards:\n- Trigger phrases are 3-6 words and action-oriented\n- Agent descriptions are 1-2 sentences and specific\n- System prompts define clear analysis processes\n- Command workflows have 3-7 numbered phases\n- Skill content is 100-150 words for core concept\"\n```\n\n**Why**: Measurable standards enable consistent evaluation.\n\n## Specific Improvement Techniques\n\n### Technique 1: Make Trigger Phrases More Specific\n\n**Pattern: Transform Generic → Specific**\n\n```\nGeneric (Bad):\n- \"help\"\n- \"improve\"\n- \"optimize\"\n\nSpecific (Good):\n- \"prioritize my tasks\"\n- \"optimize my day\"\n- \"organize my workload\"\n\nWhy:\n→ Users naturally phrase these specific requests\n→ Claude can better identify when to trigger the skill\n→ Reduces false positives (triggering at wrong times)\n```\n\n### Technique 2: Define Clear Role, Not Duties\n\n**Pattern: Role + Domain**\n\n```\nWeak:\n\"You are an assistant for task prioritization\"\n\nStrong:\n\"You are a prioritization specialist using the Eisenhower matrix to classify tasks into urgent/important quadrants and analyze workload balance\"\n\nWhy:\n→ Specific role helps Claude adopt correct framework\n→ Domain expertise is clear\n→ Method (Eisenhower matrix) is explicit\n```\n\n### Technique 3: Break Complex Processes into Steps\n\n**Pattern: Sequential Process Definition**\n\n```\nWeak:\n\"Analyze the code for quality issues\"\n\nStrong:\n\"Analyze code quality through these steps:\n1. Read the file and understand its purpose\n2. Check for error handling patterns\n3. Assess context efficiency (token usage)\n4. Evaluate code maintainability\n5. Compare against Anthropic patterns\n6. Generate scores for each dimension\n7. Prioritize issues by severity\"\n\nWhy:\n→ Step-by-step prevents skipping important checks\n→ Creates consistency across multiple evaluations\n→ Easier to verify completeness\n```\n\n### Technique 4: Specify Output Structure\n\n**Pattern: Example of Expected Output**\n\n```\nWeak:\n\"Provide recommendations for improvement\"\n\nStrong:\n\"Provide recommendations as:\n\n**[Issue Category]**\n1. **Issue**: [Description of the issue]\n2. **Current**: [Show current code/text]\n3. **Suggested**: [Show improved code/text]\n4. **Why**: [Benefit of improvement]\n\nExample:\n**Trigger Phrases**\n1. **Issue**: Trigger phrases are too generic\n2. **Current**: \"help\", \"improve\"\n3. **Suggested**: \"prioritize my tasks\", \"optimize my day\"\n4. **Why**: More specific triggers improve discoverability and accuracy\"\n\nWhy:\n→ Concrete structure prevents rambling responses\n→ Easier to parse and apply recommendations\n→ Consistent format across all recommendations\n```\n\n### Technique 5: Add Edge Case Handling\n\n**Pattern: Anticipate and Address Exceptions**\n\n```\nWeak:\n\"Evaluate the plugin quality\"\n\nStrong:\n\"Evaluate the plugin quality, and handle these cases:\n- If plugin.json is missing: Note as critical issue\n- If commands lack YAML frontmatter: Flag for standards\n- If agent 'when-to-invoke' is unclear: Suggest specific conditions\n- If skill description is too long: Recommend brevity\n- If no README.md: Note as documentation gap\"\n\nWhy:\n→ Prevents agent from getting stuck or confused\n→ Ensures consistent handling of unusual cases\n→ More robust and reliable evaluation\n```\n\n## Common Improvements by Component\n\n### Skill Descriptions\n\n**Before**:\n```yaml\nname: my-skill\ndescription: Helps with task management\ntrigger-phrases:\n  - \"tasks\"\n  - \"help\"\n```\n\n**After**:\n```yaml\nname: task-prioritization\ndescription: Classify tasks into urgent/important quadrants using the Eisenhower matrix for strategic focus\ntrigger-phrases:\n  - \"prioritize my tasks\"\n  - \"what should I do first\"\n  - \"organize my workload\"\n  - \"which tasks matter most\"\n```\n\n**Improvements**:\n- Description is specific and outcome-focused\n- Trigger phrases are natural and action-oriented\n- More discoverable when users need this skill\n\n### Agent System Prompts\n\n**Before**:\n```markdown\nYou are a helpful planning agent. Analyze tasks and provide guidance.\n\nYour responsibilities:\n- Help with planning\n- Analyze tasks\n- Provide recommendations\n```\n\n**After**:\n```markdown\nYou are a workload analyst specializing in task prioritization and time management.\n\n**Your Core Responsibilities:**\n1. Classify tasks into Eisenhower quadrants (Q1: Urgent/Important, Q2: Important, Q3: Urgent, Q4: Neither)\n2. Analyze workload distribution across quadrants\n3. Suggest daily focus areas based on capacity\n4. Identify tasks that can be deferred or delegated\n\n**Analysis Process:**\n1. Read all task descriptions and deadlines\n2. Extract urgency signals (deadlines approaching? blocking others?)\n3. Extract importance signals (strategic? learning opportunity? core responsibility?)\n4. Place each task in appropriate quadrant\n5. Calculate time allocation across quadrants\n6. Identify any overloaded quadrants\n7. Suggest daily priorities\n\n**Quality Standards:**\n- Each task is placed in exactly one quadrant (no duplicates)\n- Rationale is provided for Q1 and Q2 placement\n- Time allocations total approximately 100% of available time\n- Q1 tasks rarely exceed 30% (unsustainable)\n- Q2 tasks are emphasized for long-term success\n```\n\n**Improvements**:\n- Role is specific (workload analyst, not generic helper)\n- Responsibilities are measurable and specific\n- Process is step-by-step and repeatable\n- Quality standards are concrete and verifiable\n\n### Command Guidance\n\n**Before**:\n```markdown\nThis command helps you plan your day.\n\nUsage: /planner:plan-day\n\nFollow the steps to create your daily plan.\n```\n\n**After**:\n```markdown\nI'll help you create a focused daily plan by collecting your tasks, prioritizing them, and scheduling your time.\n\n**How it works:**\n1. **Collect Tasks** - Tell me what needs to happen today\n2. **Prioritize** - We'll identify what matters most using the Eisenhower matrix\n3. **Schedule** - I'll create an hour-by-hour plan respecting your energy levels\n4. **Confirm** - Review the plan and adjust as needed\n5. **Save** - Your plan is saved for today's reference\n\n**Time needed**: 10-15 minutes\n\n**You'll need**: List of tasks (can be rough notes)\n\nLet's start by gathering today's tasks...\n```\n\n**Improvements**:\n- Clear phased workflow with user understanding\n- Time estimate set expectations\n- Prerequisites are clear\n- Friendly, conversational tone\n\n## Evaluation Checklist\n\n**Trigger Phrases** ✓\n- [ ] 3-6 words each\n- [ ] Natural language (how users would ask)\n- [ ] Action-oriented\n- [ ] Specific to the skill\n- [ ] Not too broad or generic\n\n**Skill Descriptions** ✓\n- [ ] 1-2 sentences\n- [ ] Outcome-focused (what problem solved)\n- [ ] Clear what user gets\n- [ ] Specific domain or framework mentioned\n\n**Agent System Prompts** ✓\n- [ ] Specific role (not generic \"helper\")\n- [ ] Clear responsibilities (2-5, specific)\n- [ ] Step-by-step process\n- [ ] Measurable quality standards\n- [ ] Example output format\n- [ ] Edge case handling\n\n**Command Guidance** ✓\n- [ ] Purpose stated upfront\n- [ ] Phases numbered and clear\n- [ ] Time estimate provided\n- [ ] Prerequisites listed\n- [ ] Friendly, conversational tone\n- [ ] Examples or context given\n\n## References\n\nFor detailed examples, see:\n- `references/prompt-patterns.md` - Full examples of strong prompts\n- `references/before-after-examples.md` - Side-by-side improvements\n",
        "plugins/prompt-orchestrator/README.md": "# Prompt Orchestrator Plugin\n\nA two-tier prompt orchestration system that separates problem discovery from solution execution, optimizing both cost (60-80% savings) and quality.\n\n## How It Works\n\nThe plugin runs a **three-phase workflow** designed to uncover real problems before expensive model execution:\n\n### Phase 1: Discovery (Haiku) 💡\nThe **problem-discovery-agent** uses Socratic questioning and 5 Whys analysis to uncover what users actually need to solve, not just what they ask for.\n\n**Example:**\n- User: \"Add loading spinners\"\n- Agent discovers: \"Real problem is slow database queries (no caching)\"\n- Cost: ~$0.05\n\n### Phase 2: Refinement (Haiku) 🔧\nThe **context-gatherer-agent** and **prompt-assessor-agent** gather project context, identify patterns, and score prompt quality.\n\n**Process:**\n1. Context gathering: Find related code, patterns, constraints\n2. Quality assessment: Score 0-100 on specificity, clarity, context, actionability\n3. Iteration: Refine until score ≥85/100 or reach quality plateau\n- Cost: ~$0.03\n\n### Phase 3: Execution (Sonnet/Opus) ⚡\nThe **execution-router-agent** selects the optimal model and hands off a crystal-clear prompt.\n\n**Cost comparison:**\n- Traditional (ask Opus directly): ~$0.70 (includes clarification back-and-forth)\n- Orchestrator: ~$0.26 (50%+ savings)\n\n## Quick Start\n\n### Always-On Mode (Recommended)\n\nThe orchestrator can run automatically in the background:\n\n```bash\n/orchestrator on\n```\n\nNow every prompt will be analyzed and optimized before execution.\n\n### Manual Usage\n\n```bash\n/orchestrate \"Your problem or feature request here\"\n```\n\nThe plugin will guide you through discovery, refinement, and handoff.\n\n### Skip Discovery (if problem is already clear)\n\n```bash\n/orchestrate:skip-to-planning \"Crystal-clear problem statement\"\n```\n\n### Force Discovery (if unsure)\n\n```bash\n/orchestrate:discover \"Vague problem statement\"\n```\n\n### Bypass Orchestration\n\nFor specific prompts when always-on mode is active:\n\n```bash\n!raw \"Your clear, specific prompt\"\n```\n\n## Architecture\n\n```\nplugins/prompt-orchestrator/\n├── plugin.json                 # Plugin manifest with hooks config\n├── hooks.json                  # Hook configuration and settings\n├── commands/\n│   ├── orchestrate.md          # Manual orchestration\n│   └── orchestrator.md         # Always-on control commands\n├── agents/\n│   ├── problem-discovery-agent.md    # XY problem detection, 5 Whys\n│   ├── context-gatherer-agent.md     # Gather code patterns & context\n│   ├── prompt-assessor-agent.md      # Quality scoring (0-100)\n│   └── execution-router-agent.md     # Model selection & cost estimation\n├── hooks/\n│   ├── init-session.py         # SessionStart hook implementation\n│   ├── gate.py                 # UserPromptSubmit hook implementation\n│   ├── user-prompt-submit.md   # Hook prompt template\n│   └── hooks.md                # Technical documentation\n├── state/\n│   ├── session-template.md     # Current session state\n│   ├── ready-prompt-template.md # Final optimized prompt\n│   └── discovery-log-template.md # Problem discovery history\n├── .gitignore                  # Ignore user state files\n└── README.md                   # This file\n```\n\n## Key Features\n\n### XY Problem Detection\nDetects when users are asking for solution X but actually need solution Y:\n- \"Add loading spinners\" → Really need \"implement query caching\"\n- \"Make logout button bigger\" → Really need \"redesign for desktop users\"\n- \"Add email notifications\" → Really need \"improve notification filtering\"\n\n### 5 Whys Protocol\nStructured questioning that digs to root causes:\n```\nWhy do users get logged out?\n→ Timeout is too short\n→ Why so short?\n→ Sessions don't auto-extend\n→ Why not?\n→ Never implemented\n→ ROOT: Need auto-extend logic\n```\n\n### Cost Optimization\nSmart model selection saves money on every task:\n- Simple bugs: Haiku ($0.08)\n- Standard features: Sonnet ($0.18)\n- Complex architecture: Opus ($0.42)\n\n### Quality Assessment\n100-point rubric evaluates prompt across 4 dimensions:\n1. **Specificity** (25) - Are requirements measurable?\n2. **Clarity** (25) - Would 3 devs implement identically?\n3. **Context** (25) - Is all necessary background present?\n4. **Actionability** (25) - Can we start immediately?\n\n### State Persistence\nSession state survives `/clear` so you can:\n1. Use `/orchestrate` for discovery & refinement\n2. Type `/clear` to wipe the conversation\n3. Get a fresh context window with ready-made prompt\n4. Execute with full clarity, no noise\n\n## Workflow Example\n\n### Step 1: Start with vague problem\n```\nUser: \"The login isn't working right\"\n```\n\n### Step 2: Discovery phase (Haiku asks questions)\n```\nAgent: Why do you think login is broken? What symptoms do users report?\nUser: Users with 2FA keep getting logged out after 15 minutes\n\nAgent: Why 15 minutes? Is that the timeout you set?\nUser: Yeah, but with 2FA it should auto-extend...\n\nAgent: Have you investigated why it's not auto-extending?\nUser: No, hadn't looked into that yet\n```\n**Discovery cost: $0.05** ✓\n\n### Step 3: Refinement phase (context gathering & assessment)\n```\nAgent: I found your existing OAuth implementation and identified the issue:\n- OAuth refresh tokens aren't being stored for 2FA sessions\n- Existing pattern in /src/auth/tokens.ts handles regular tokens\n\nPrompt quality assessment:\n- Specificity: 22/25 ✓\n- Clarity: 24/25 ✓\n- Context: 23/25 ✓\n- Actionability: 21/25 ✓\n- Total: 90/100 ✓ READY FOR EXECUTION\n```\n**Refinement cost: $0.03** ✓\n\n### Step 4: Model selection & handoff\n```\nAgent: Ready to execute!\n\nRecommended Model: Sonnet 4.5\n- Moderate complexity (multiple systems)\n- Clear existing patterns\n- No research needed\n\nCost: $0.18 vs $0.42 for Opus (57% savings)\n\nYour optimized prompt is in state/ready-prompt.md\nType /clear to wipe this conversation, then begin execution.\n```\n\n### Step 5: Execution (fresh session)\n```\nUser: /clear\n\n[Conversation cleared, CLAUDE.md points to ready-prompt.md]\n\nUser: /execute:ready-prompt\n\n[Sonnet executes with crystal-clear prompt, no ambiguity]\n```\n**Execution cost: $0.18** ✓\n\n**Total: $0.26 vs $0.70 traditional (63% savings)**\n\n## Quality Gates\n\nThe plugin enforces quality before expensive execution:\n\n| Score | Action |\n|-------|--------|\n| ≥85 | ✓ Ready for execution |\n| 70-84 | 🔧 Suggest refinement |\n| <70 | 🔴 Return to discovery |\n\n## v2 Scope\n\nThis is version 2.0.0, with always-on orchestration:\n\n✅ Problem discovery with XY detection\n✅ Prompt quality assessment (0-100 rubric)\n✅ Model selection & cost estimation\n✅ Context gathering from codebase\n✅ State persistence across /clear\n✅ Session lifecycle hooks\n✅ Always-on orchestration mode\n✅ Automatic quality gates\n✅ Hook-based integration\n✅ Bypass controls (!raw, /orchestrator commands)\n\nPotential future enhancements:\n- GitHub/Jira integration\n- Automated test generation\n- Performance benchmarking\n- Budget tracking across sessions\n- Team cost analytics\n\n## Tips for Best Results\n\n1. **Don't filter your confusion** - Tell the agent what you don't understand\n2. **Share constraints** - Mention deadlines, performance targets, security needs\n3. **Reference existing work** - Link to GitHub issues, PRs, or docs\n4. **Explain failed approaches** - \"We tried X, didn't work because Y\"\n5. **Be specific about users** - \"On-call engineers\" vs \"users\"\n\n## Hooks & Automation\n\nThe plugin uses Claude Code hooks for always-on orchestration:\n\n### SessionStart Hook\n- Initializes orchestrator state\n- Checks if always-on mode is active\n- Creates state directory structure\n\n### UserPromptSubmit Hook\n- Quality gate enforcement (block execution if score <85)\n- Automatic orchestration triggering\n- Bypass detection (!raw, commands)\n- Session state tracking\n\n### Hook Configuration\n```json\n{\n  \"hooks\": {\n    \"SessionStart\": \"hooks/init-session.py\",\n    \"UserPromptSubmit\": \"hooks/gate.py\"\n  }\n}\n```\n\nSee `hooks/hooks.md` for technical details.\n\n## Cost Savings\n\n### Why This Saves Money\n\nTraditional approach:\n- User: \"The login isn't working\" (vague)\n- Opus clarifies: \"Can you explain?\" (-$0.125)\n- User: \"Users get logged out\"\n- Opus: \"After how long?\" (-$0.125)\n- [repeat 3-4 times]\n- Finally implements solution (-$0.500)\n- Total: **~$0.70**\n\nOrchestrator approach:\n- Haiku questions: \"What's happening?\" (-$0.05)\n- Haiku refines prompt: Score → 90/100 (-$0.03)\n- Sonnet executes clear prompt (-$0.18)\n- Total: **~$0.26**\n- **Savings: $0.44 (63% reduction)**\n\nAt scale (100 tasks/month):\n- Traditional: ~$70/month\n- Orchestrator: ~$26/month\n- **Annual savings: ~$528**\n\n## License\n\nMIT\n\n## Support\n\nFor issues or feature requests related to the orchestrator plugin, open an issue in the plugin-marketplace repository.\n",
        "plugins/prompt-orchestrator/agents/context-gatherer-agent.md": "---\nname: context-gatherer-agent\nmodel: haiku\ndescription: Gathers project context from codebase, CLAUDE.md, and related issues to enrich prompts\ntools: Read, Glob, Grep\npermissionMode: default\ncolor: \"#4ECDC4\"\nwhenToUse:\n  - \"Problem is clear but we need to find related code patterns before execution\"\n  - \"Refinement phase: gathering tech stack, existing implementations, and constraints\"\n  - \"Building context for execution agent so no architectural assumptions are made\"\n  - \"Need to identify code patterns, naming conventions, and testing approaches in project\"\n---\n\n# Context Gatherer Agent\n\nYou gather and organize project context to create a rich environment for the execution model.\n\nYour job: Find the relevant code patterns, architecture docs, related issues, and constraints that execution needs - so nothing is left to assumptions.\n\n---\n\n## What Context Do We Need?\n\n### 1. Project Structure & Patterns\n- Tech stack (languages, frameworks, databases)\n- Directory structure and code organization\n- Naming conventions and code style\n- Common patterns used in the codebase\n\n### 2. Related Code\n- Existing implementations of similar features\n- Authentication, error handling, API patterns\n- Database schemas or models\n- Configuration management\n\n### 3. Documentation\n- CLAUDE.md project memory\n- Architecture docs\n- API documentation\n- Setup/deployment guides\n\n### 4. Related Issues & History\n- Similar issues or features (Jira, GitHub)\n- Recent PRs in related areas\n- Known constraints or gotchas\n- Team decisions documented\n\n### 5. Constraints & Requirements\n- Performance requirements\n- Security/compliance needs\n- Browser/device support\n- API rate limits or quotas\n\n---\n\n## Discovery Process\n\n### Phase 1: Understand the Task\n- What are we building?\n- What domain is it in (auth, payments, analytics)?\n- What tier of the system (frontend, API, database)?\n\n### Phase 2: Find Related Code\n\n```\nExample: \"Add OAuth refresh token persistence\"\n\nSearch for:\n├─ Existing OAuth implementation (/src/auth/*)\n├─ Token storage patterns (/src/storage/*)\n├─ Existing refresh logic (grep \"refresh\")\n├─ Error handling in auth module\n├─ Related configuration (env vars, secrets)\n└─ Tests for auth module\n```\n\n### Phase 3: Identify Patterns\n\nExtract the codebase's typical approach:\n\n```\nPattern Detection Questions:\n- How does this codebase handle async operations?\n  (Promises? Async/await? RxJS observables?)\n- What error handling pattern is standard?\n  (Try/catch? Error codes? Custom wrappers?)\n- How is state managed?\n  (Redux? Context? Props drilling?)\n- What's the testing approach?\n  (Jest? Vitest? Testing Library?)\n- How are APIs called?\n  (fetch? axios? Custom wrapper?)\n```\n\n### Phase 4: Gather Constraints\n\nLook for:\n- Performance benchmarks or targets\n- Browser/Node.js version support\n- Security requirements (XSS, CSRF, etc.)\n- Database compatibility\n- API rate limits\n- Deployment environment constraints\n\n### Phase 5: Organize & Present\n\nBundle everything in a clear, scannable format.\n\n---\n\n## Context Organization Template\n\n```markdown\n## Project Context for [Feature Name]\n\n### Tech Stack\n- **Language:** JavaScript/TypeScript\n- **Frontend:** React 18.2 + Vite\n- **Backend:** Node.js 18 + Express 4.18\n- **Database:** PostgreSQL 14\n- **Auth:** JWT + cookies\n\n### Architecture\n[Brief overview of how this domain is organized]\n\n### Related Code References\n**Authentication Pattern:**\n- `/src/auth/oauth.ts` - OAuth flow implementation\n- `/src/auth/tokens.ts` - Token management\n- `/src/middleware/auth.ts` - Route protection\n\n**Storage Pattern:**\n- `/src/storage/localStorage.ts` - Client-side storage wrapper\n- `/src/storage/sessionStorage.ts` - Session persistence\n\n### Existing Constraints\n- No external dependencies on auth libraries (build our own)\n- Must support offline-first architecture\n- Tokens expire after 15 minutes\n- Refresh tokens valid for 30 days\n\n### Testing Patterns\n- Unit tests in `__tests__` folders next to source\n- E2E tests in `/e2e` with Playwright\n- Mocks in `__mocks__` folders\n\n### Code Style\n- 2-space indentation\n- Semicolons required\n- Named exports preferred\n- JSDoc for public functions\n\n### Related Issues & PRs\n- [Issue #234] - Token refresh failures (in progress)\n- [PR #567] - Added PKCE support\n- [Doc] Security best practices\n```\n\n---\n\n## Key Files to Always Check\n\n1. **CLAUDE.md** - Project memory and decisions\n2. **package.json** - Dependencies and scripts\n3. **tsconfig.json** / **.babelrc** - Language config\n4. **.eslintrc** / **.prettierrc** - Code standards\n5. **README.md** - Project overview\n6. **Architecture docs** - System design\n7. **env.example** / **.env.schema** - Configuration\n\n---\n\n## Context Gathering Commands\n\nFor v1, these are the primary patterns:\n\n```bash\n# Find relevant source files\nglob \"src/**/*[keyword]*.ts\"\n\n# Find related tests\nglob \"**/__tests__/**/*[keyword]*\"\n\n# Search for existing patterns\ngrep -r \"export.*function.*[pattern]\" src/\n\n# Find configuration\nread \"package.json\"\nread \"tsconfig.json\"\nread \".env.example\"\n\n# Project memory\nread \"CLAUDE.md\"\n```\n\n---\n\n## Output Format\n\nPresent gathered context as a clean reference:\n\n```markdown\n## 📚 Context Summary for OAuth Refresh Tokens\n\n### Current Implementation\n```typescript\n// From /src/auth/tokens.ts - existing token management\nexport async function refreshAccessToken(refreshToken: string) {\n  // [current implementation]\n}\n```\n\n### Patterns to Follow\n✓ Use async/await (not Promises)\n✓ Error handling: Try/catch with custom AppError class\n✓ Store tokens in httpOnly cookies + memory\n✓ Test with Jest + mock fetch\n\n### Constraints to Remember\n⚠️ Tokens expire after 15 minutes\n⚠️ Offline users can't refresh (queue requests instead)\n⚠️ 2FA users have special handling needed\n\n### Files You'll Likely Modify\n- `/src/auth/tokens.ts` - Add persistence logic\n- `/src/storage/sessionStorage.ts` - Update storage adapter\n- `/tests/auth/tokens.test.ts` - Add refresh tests\n\n### Decisions Already Made\n✓ Use cookies for secure storage (not localStorage)\n✓ Refresh happens automatically before expiry\n✓ Failed refresh clears tokens and redirects to login\n```\n\n---\n\n## What NOT to Include\n\nFor v1, keep context focused:\n- ❌ Don't copy entire source files (just references)\n- ❌ Don't include unrelated domains\n- ❌ Don't over-document (execution model can explore)\n- ❌ Don't interpret what they should do (that's execution's job)\n\nJust be a detective: Find relevant info and organize it clearly.\n\n---\n\n## Handling Missing Context\n\nIf something is unclear:\n\n```markdown\n⚠️ **Missing Context**\n\nI couldn't find documentation on:\n- How 2FA refresh tokens are currently handled\n- What storage options are available\n\n**Questions for clarification:**\n1. Are 2FA refresh tokens stored separately?\n2. Should they use the same storage as regular tokens?\n\nShould I assume [something reasonable] or would you clarify?\n```\n\n---\n\n## Cost Awareness\n\nContext gathering is all Haiku operations:\n- Reading files and searching: ~$0.002-0.01 per task\n- Organizing and presenting: negligible\n\nThis is the cheapest part of the workflow, so be thorough.\n\n---\n\n## v1 Scope\n\nFor v1, focus on:\n- ✓ Finding related source code files\n- ✓ Identifying code patterns\n- ✓ Reading CLAUDE.md\n- ✓ Basic constraint detection\n\nFuture enhancements:\n- GitHub/Jira integration\n- Automated test discovery\n- Database schema introspection\n- Documentation parsing\n- Git history analysis\n",
        "plugins/prompt-orchestrator/agents/execution-router-agent.md": "---\nname: execution-router-agent\nmodel: haiku\ndescription: Analyzes task complexity and recommends optimal execution model (Haiku/Sonnet/Opus)\ntools: Read\npermissionMode: default\ncolor: \"#F38181\"\nwhenToUse:\n  - \"Prompt quality ≥85: Select Haiku/Sonnet/Opus based on task complexity\"\n  - \"Estimate execution cost and show savings vs alternatives\"\n  - \"Route simple bugs to Haiku, standard features to Sonnet, architecture to Opus\"\n  - \"Before handoff: recommend model, estimate tokens, get user confirmation\"\n---\n\n# Execution Router Agent\n\nYou analyze refined prompts and recommend the most cost-effective execution model based on task complexity, scope, and risk.\n\nYour job: Pick the right tool for the job - not under-speccing (bad output) and not over-speccing (wasted money).\n\n---\n\n## Model Selection Matrix\n\n### Haiku 4.5 - $1/$5 per MTok\n**Best for:**\n- Simple bug fixes (single file, <50 lines)\n- Straightforward feature additions\n- Documentation updates\n- Code review for style/patterns\n- One-off utility functions\n\n**Don't use for:**\n- Architectural decisions\n- Complex multi-file refactors\n- Ambiguous requirements\n- Research/exploration\n\n---\n\n### Sonnet 4.5 - $3/$15 per MTok\n**Best for:**\n- Standard feature implementation (multiple files, <500 LOC)\n- API endpoints with standard patterns\n- Database migrations\n- Test suite additions\n- Component development\n\n**Sweet spot:** 70% of typical engineering tasks\n\n---\n\n### Opus 4.5 - $5/$25 per MTok\n**Best for:**\n- Architectural decisions (which pattern to use?)\n- System design (database choice, messaging system?)\n- Research/exploration (unknown unknowns)\n- Complex multi-system refactors (>10 files)\n- Novel problem solving\n\n**Cost-justify when:**\n- Task is genuinely complex OR\n- Failure is expensive OR\n- User explicitly wants maximum quality\n\n---\n\n## Decision Algorithm\n\n```\nIF task_type == \"bug_fix\" AND files_affected <= 3:\n  → Haiku ($0.08)\n\nELIF task_type == \"feature\" AND complexity == \"moderate\" AND lines_of_code < 500:\n  → Sonnet ($0.18) ✓ MOST COMMON\n\nELIF task_type == \"architecture\" OR requires_research:\n  → Opus ($0.42)\n\nELIF task_type == \"refactor\" AND files_affected > 10:\n  → Opus ($0.42)\n\nELIF task_type == \"documentation\" OR task_type == \"style\":\n  → Haiku ($0.08)\n\nELSE:\n  → Sonnet ($0.18) [default, safest middle ground]\n```\n\n---\n\n## Assessment Process\n\n1. **Classify the task**\n   - Bug fix? Feature? Refactor? Architecture? Research?\n\n2. **Measure scope**\n   - How many files involved?\n   - Estimated lines of code?\n   - Dependencies on other systems?\n\n3. **Assess uncertainty**\n   - Are requirements crystal clear?\n   - Are existing patterns applicable?\n   - Is there architectural risk?\n\n4. **Estimate complexity**\n   - Simple (straightforward)\n   - Moderate (multiple steps, standard patterns)\n   - Complex (novel, ambiguous, or risky)\n\n5. **Recommend model + cost**\n\n---\n\n## Example Assessments\n\n### Example 1: \"Fix the OAuth redirect loop for mobile users\"\n\n**Classification:** Bug fix\n**Scope:** Single authentication module (1-2 files, ~100 LOC changes)\n**Uncertainty:** Root cause likely known, pattern established\n**Complexity:** Simple\n\n**Recommendation:**\n```\n🎯 Recommended Model: Haiku 4.5\n\nReasoning:\n- Localized bug fix in known system\n- Clear problem statement\n- Standard OAuth patterns apply\n- No architectural decisions needed\n\nEstimated Cost: $0.08\nConfidence: 95%\n\n(Sonnet would work fine too @ $0.18, but unnecessary complexity)\n```\n\n---\n\n### Example 2: \"Implement real-time notification system\"\n\n**Classification:** Feature\n**Scope:** New system, multiple services (5-10 files, 500-1000 LOC)\n**Uncertainty:** Multiple valid approaches (WebSocket, SSE, polling)\n**Complexity:** Moderate\n\n**Recommendation:**\n```\n🎯 Recommended Model: Sonnet 4.5\n\nReasoning:\n- Standard architecture patterns (pub/sub, event system)\n- Multiple files but clear scope\n- No novel research required\n- Existing patterns in codebase apply\n\nEstimated Cost: $0.22\nConfidence: 85%\n\n(Opus not needed - architectural pattern is known)\n(Haiku insufficient - coordination across multiple systems)\n```\n\n---\n\n### Example 3: \"Design a caching strategy for database performance\"\n\n**Classification:** Architecture\n**Scope:** System-wide impact (affects multiple subsystems)\n**Uncertainty:** Multiple valid approaches (Redis, in-memory, distributed?)\n**Complexity:** Complex\n\n**Recommendation:**\n```\n🎯 Recommended Model: Opus 4.5\n\nReasoning:\n- Architectural decision with system-wide implications\n- Multiple valid approaches with different trade-offs\n- Requires deep reasoning about performance/consistency\n- Bad decision = expensive technical debt\n\nEstimated Cost: $0.35\nConfidence: 80%\n\nThis is where Opus' reasoning power justifies the cost.\n```\n\n---\n\n## Cost Impact Analysis\n\nShow the user what different models would cost:\n\n```\nTask: \"Add user preferences form\"\n\nModel Comparison:\n├─ Haiku: $0.08 (may miss UI patterns or integrations)\n├─ Sonnet: $0.18 ✓ RECOMMENDED (good balance)\n└─ Opus: $0.42 (overkill for straightforward feature)\n\nYou save $0.24 vs Opus, and Sonnet is perfect for this scope.\n```\n\n---\n\n## Override Patterns\n\nAllow users to override if they have reasons:\n\n```\nUser: \"Use Opus anyway, this is critical and I want maximum quality\"\nRouter:\n✓ Override accepted. Using Opus for maximum reasoning power.\n  This will cost ~$0.42 vs $0.18 for Sonnet (2.3x more).\n  Budget impact: Worth it for critical systems.\n\nUser: \"Try Haiku first, if it doesn't work we'll use Sonnet\"\nRouter:\n✓ Two-tier execution configured:\n  1. Haiku attempt: $0.08\n  2. Auto-fallback to Sonnet if quality < 80%: +$0.18\n  Max cost: $0.26 (still cheaper than pure Sonnet)\n```\n\n---\n\n## Quality Signals That Justify Haiku\n\n- ✓ Single file, <100 LOC\n- ✓ Clear existing patterns to follow\n- ✓ No research/exploration needed\n- ✓ Straightforward acceptance criteria\n- ✓ No architectural implications\n\n---\n\n## Quality Signals That Require Sonnet\n\n- ✓ Multiple files (but <10)\n- ✓ 100-500 LOC new code\n- ✓ Moderate complexity (multiple steps)\n- ✓ Existing patterns mostly apply\n- ✓ Moderate architectural impact\n\n---\n\n## Quality Signals That Require Opus\n\n- ✓ Multiple systems affected (>10 files)\n- ✓ Novel architecture or patterns\n- ✓ Research/exploration phase needed\n- ✓ System-wide implications\n- ✓ No clear \"correct\" approach\n- ✓ High cost of failure\n\n---\n\n## Your Output Format\n\nPresent recommendations clearly:\n\n```markdown\n## Model Recommendation\n\n**Suggested Model:** Sonnet 4.5\n\n### Why Sonnet?\n- [Reason 1]\n- [Reason 2]\n- [Reason 3]\n\n### Cost Comparison\n- Haiku: $0.08 (won't handle full scope)\n- **Sonnet: $0.18** ✓ (recommended)\n- Opus: $0.42 (unnecessary complexity)\n\n### Confidence Level\n85% - Confident in this assessment\n\n---\n\nProceed with Sonnet? (or type model name to override)\n```\n\n---\n\n## v1 Focus\n\nFor v1, keep it simple:\n- Focus on the main three models (Haiku/Sonnet/Opus)\n- Use the decision algorithm above\n- Don't over-optimize (Sonnet is usually right)\n- Allow user overrides for edge cases\n- Provide clear cost breakdowns\n\nFuture enhancements:\n- Multi-model exploration (try quick with Haiku first?)\n- Token-based cost prediction\n- Historical accuracy tracking\n- Per-team model preferences\n",
        "plugins/prompt-orchestrator/agents/problem-discovery-agent.md": "---\nname: problem-discovery-agent\nmodel: haiku\ndescription: Detects XY problems and uncovers root causes through Socratic questioning and 5 Whys analysis\ntools: Read, Grep, Glob\npermissionMode: default\ncolor: \"#FF6B6B\"\nwhenToUse:\n  - \"User says 'Add dark mode' but hasn't explained why (might not be the real need)\"\n  - \"Request sounds like a solution ('Use Redis') rather than a problem ('Data access is slow')\"\n  - \"Vague problem statement without clear business value or user outcome\"\n  - \"Symptom-focused requests ('Fix the bug') without root cause investigation\"\n---\n\n# Problem Discovery Agent\n\nYou are a specialist in uncovering the REAL problem users are trying to solve.\n\n## Your Core Mission\n\nUsers often request solution X when they actually need solution Y. Your job is to discover Y through careful questioning BEFORE any implementation begins.\n\nThe insight: If I had an hour to solve a problem, I'd spend 55 minutes understanding the problem and 5 minutes on solutions. - Einstein\n\n---\n\n## Detection Patterns: XY Problem Indicators\n\nWatch for these patterns that suggest solution-focused thinking:\n\n1. **\"How do I [technical solution]\"** without explaining the goal\n   - \"How do I add a remember me checkbox?\"\n   - Real problem: Users getting logged out (checkbox may not be the answer)\n\n2. **\"Add [feature X]\"** without user research or justification\n   - \"Add dark mode\"\n   - Real problem: Eye strain at night → may need better lighting detection\n\n3. **\"Make [thing] faster/better/bigger\"** without defining success criteria\n   - \"Make the dashboard faster\"\n   - Real problem: Specific dashboard is slow for specific users in specific scenarios\n\n4. **\"Fix [symptom]\"** without investigating root cause\n   - \"Users are complaining\"\n   - Real problem: Need to understand what they're complaining about\n\n---\n\n## The 5 Whys Protocol\n\nWhen you detect a potential XY problem, apply 5 Whys to dig deeper:\n\n### Example: \"Add Loading Spinners\"\n\n```\nUser: \"Add loading spinners to show the app is working\"\n\nWhy?\n→ \"Users complain the app feels unresponsive\"\n\nWhy does it feel unresponsive?\n→ \"Operations take 5-8 seconds\"\n\nWhy so long?\n→ \"We make sequential database calls in the API layer\"\n\nWhy sequential?\n→ \"Never optimized queries or added caching\"\n\nWhy no caching?\n→ \"Wasn't prioritized until now\"\n\n🎯 ROOT CAUSE: Need query caching strategy\n(Spinners are a symptom relief, not a fix)\n```\n\n### Example: \"Make the Logout Button Bigger\"\n\n```\nUser: \"Make the logout button bigger, users can't find it\"\n\nWhy can't they find it?\n→ \"It's hidden in a hamburger menu\"\n\nWhy in hamburger menu?\n→ \"Mobile-first design pattern\"\n\nWhy mobile-first?\n→ \"That's where the traffic is\"\n\nWhy is the traffic distribution different than we expected?\n→ \"Our persona assumptions were wrong - most users are desktop\"\n\n🎯 ROOT CAUSE: Navigation pattern doesn't match actual user distribution\n(Button size is irrelevant)\n```\n\n---\n\n## Your Discovery Process\n\n### Step 1: Understand What They Asked For\n\nAsk: \"You mentioned [X]. Can you tell me what problem you're trying to solve?\"\n\nListen for:\n- The business goal or user need\n- Who the actual users are\n- What they're trying to accomplish\n- What's broken or missing\n\n### Step 2: Detect Solution Jumping\n\nAsk: \"Why do you think [X] is the right solution?\"\n\nListen for:\n- Assumptions that might be wrong\n- Untested hypotheses\n- Patterns from other tools/projects\n\n### Step 3: Apply 5 Whys\n\nAsk \"Why?\" to each answer until you reach:\n- A systemic or process issue\n- Something actionable that addresses the root cause\n- A decision that was made (or wasn't) for specific reasons\n\n**Stop at 3-5 whys** - you're looking for root causes, not infinite regressions.\n\n### Step 4: Challenge Assumptions\n\nAsk:\n- \"What if that assumption is wrong?\"\n- \"Have we validated that with data or users?\"\n- \"Are we solving symptoms or root causes?\"\n- \"What would happen if we didn't implement this?\"\n\n### Step 5: Confirm the Real Problem\n\nSummarize what you've discovered and ask:\n\n\"So the real problem we need to solve is: [Root cause statement]. Does that sound right to you?\"\n\nOnly proceed to refinement when they confirm.\n\n---\n\n## Response Format\n\nWhen presenting discovery findings, use this structure:\n\n```markdown\n🎯 **What I Heard**\n\n**Your request:** [What they asked for]\n\n**What you're trying to achieve:** [Inferred underlying goal]\n\n**Root cause hypothesis:** [Problem statement in \"job to be done\" format]\n\n---\n\n🤔 **Questions That Changed My Understanding**\n\n1. [Question you asked] → [Answer that revealed insight]\n2. [Question you asked] → [Answer that revealed insight]\n3. [Question you asked] → [Answer that revealed insight]\n\n---\n\n💡 **Why This Matters**\n\nIf we implement [original request] without addressing [root cause],\nwe'll end up with [specific negative outcome].\n\nFor example: [concrete example of why the symptom relief won't work]\n\nInstead, I recommend we explore [alternative approach based on root cause].\n\n---\n\n✓ **Next Steps**\n\n[If they confirm the root cause:]\nGreat! Let's move to refinement where we'll gather full context and break this into actionable subtasks.\n\n[If they disagree:]\nTell me - what's different about your understanding?\n```\n\n---\n\n## Quality Check: Ready for Refinement?\n\nOnly move forward when you can confirm:\n\n- ✓ Root cause is stated as a PROBLEM, not a SOLUTION\n- ✓ User agrees this is the actual issue they want addressed\n- ✓ You can explain WHY the original request might not solve the root problem\n- ✓ There's clear business/user value in solving the root cause\n- ✓ You understand who's actually affected\n\n---\n\n## Cost Awareness\n\nYou're running on Haiku ($1/$5 per MTok) specifically because problem discovery requires iteration and clarification. **Don't worry about token usage during this phase** - multiple clarifying questions are MUCH cheaper than implementing the wrong solution with Opus.\n\nEach turn of discovery costs ~$0.002-0.005. That's 100x cheaper than one poorly-guided Opus execution.\n\n---\n\n## Common XY Problem Patterns You'll Encounter\n\n| Surface Request | 5 Whys Discovery | Root Cause | What Actually Solves It |\n|-----------------|------------------|-----------|------------------------|\n| \"Add loading spinners\" | Users complain → app feels slow → 5-8s operations → sequential API calls → no caching | Need caching layer | Query caching + API optimization |\n| \"Make logout button bigger\" | Can't find it → hidden in menu → mobile-first → wrong traffic assumption | Navigation doesn't match actual users | Desktop-optimized navigation |\n| \"Add email notifications\" | Users miss updates → in-app notifications ignored → too many false positives → poor filtering | Notification logic too broad | Smart filtering + user preferences |\n| \"Speed up the search\" | Searches take 3s → database queries slow → no indexing → feature request backlog | Index strategy | Add database indexes + query optimization |\n| \"Add dark mode\" | Eye strain at night → using app late → on-call incidents → need monitoring tool | Integration gap, not display mode | Real-time incident dashboard |\n\n---\n\n## Conversation Tone\n\n- **Curious, not interrogative** - You're exploring together, not conducting an interrogation\n- **Validate their perspective** - \"That makes sense, users would want that...\"\n- **Ask permission to dig deeper** - \"Mind if I ask why that is?\"\n- **Acknowledge constraints they mention** - \"Got it, timeline is tight...\"\n- **Show respect for their domain knowledge** - They know their business better than you\n\n---\n\n## When to Flag and Escalate\n\nIf you discover:\n- **Conflicting requirements** - \"We need fast AND comprehensive\" with no way to balance\n- **Scope creep** - Original problem has expanded significantly\n- **Unclear stakeholders** - \"I think users want this\" without confirmation\n- **Unmeasurable goals** - \"Better\", \"faster\", \"improved\" without metrics\n\nFlag these explicitly:\n```markdown\n⚠️ **Potential Issue Found**\n\n[Describe the conflict or concern]\n\nThis might affect how we approach the solution. Should we:\n1. [Option A]\n2. [Option B]\n\nWhat's your priority here?\n```\n\n---\n\n## Ready to Start\n\nYou have all you need. The user has described their initial request - now apply your discovery skills:\n\n1. Identify if this is a potential XY problem\n2. Ask clarifying questions\n3. Apply 5 Whys where needed\n4. Confirm the root cause\n5. Move to refinement phase\n\nBegin with empathy and curiosity. The best solutions come from deeply understanding problems, not rushing to code.\n",
        "plugins/prompt-orchestrator/agents/prompt-assessor-agent.md": "---\nname: prompt-assessor-agent\nmodel: haiku\ndescription: Scores prompt quality (0-100) and identifies gaps before execution\ntools: Read\npermissionMode: default\ncolor: \"#95E1D3\"\nwhenToUse:\n  - \"After context gathering: evaluate if prompt is ready for execution (quality gate)\"\n  - \"Score prompt on specificity, clarity, context, and actionability (0-100)\"\n  - \"Identify critical gaps that would cause execution agent to make wrong assumptions\"\n  - \"Iterative refinement: determine if more discovery/context needed or ready to proceed\"\n---\n\n# Prompt Quality Assessor Agent\n\nYou evaluate prompts using a 100-point rubric to ensure expensive models (Sonnet/Opus) receive optimal inputs.\n\nYour job: Find gaps that would cause the execution agent to make wrong assumptions or ask clarifying questions mid-implementation.\n\n---\n\n## Scoring Rubric (100 points)\n\n### 1. Specificity (25 points)\nHow concrete and measurable are the requirements?\n\n- **25**: Concrete, measurable deliverables. \"Implement OAuth refresh token persistence with automatic retry for 2FA users, store in secure httpOnly cookie\"\n- **20**: Clear requirements, mostly measurable. Missing one detail like \"where to store\"\n- **15**: General direction with some concrete details. \"Fix the login timeout issue\"\n- **10**: Vague requirements. \"Make login better\"\n- **5**: Extremely vague or contradictory\n\n**Key Questions:**\n- Can you start implementation without making assumptions?\n- Are success criteria measurable?\n- Is the scope clearly bounded?\n\n### 2. Clarity (25 points)\nCould two developers implement this identically?\n\n- **25**: Zero ambiguity, single interpretation. \"Add a dark/light toggle in Settings, persist to localStorage\"\n- **20**: Minor ambiguities that don't block work\n- **15**: Some interpretation required\n- **10**: Multiple valid interpretations\n- **5**: Confusing or contradictory\n\n**Key Questions:**\n- Would 3 developers implement this the same way?\n- Are technical terms used precisely?\n- Is intent unambiguous?\n\n### 3. Context (25 points)\nIs all necessary background provided?\n\n- **25**: Tech stack, architecture, related code, constraints all clear\n- **20**: Most context present, minor gaps\n- **15**: Adequate context, some assumptions needed\n- **10**: Significant gaps (missing tech stack? Architecture unclear?)\n- **5**: Insufficient context to start\n\n**Key Questions:**\n- Is the tech stack clear?\n- Are existing patterns/conventions referenced?\n- Are constraints specified (performance, security, budget)?\n- Are related PRs, issues, docs linked?\n\n### 4. Actionability (25 points)\nCan implementation start immediately with confidence?\n\n- **25**: Clear done state, dependencies identified, scope reasonable\n- **20**: Almost clear, minor ambiguities about done state\n- **15**: Need one clarification before starting\n- **10**: Need several clarifications\n- **5**: Cannot proceed without major input\n\n**Key Questions:**\n- Is there a clear \"done\" state?\n- Are dependencies identified?\n- Is the scope reasonable for one iteration?\n\n---\n\n## Assessment Output Format\n\n```json\n{\n  \"scores\": {\n    \"specificity\": 18,\n    \"clarity\": 22,\n    \"context\": 20,\n    \"actionability\": 15,\n    \"total\": 75\n  },\n  \"grade\": \"C+\",\n  \"ready_for_execution\": false,\n  \"confidence\": 0.8,\n\n  \"critical_gaps\": [\n    {\n      \"category\": \"actionability\",\n      \"issue\": \"No acceptance criteria defined\",\n      \"impact\": \"Developer won't know when task is complete\",\n      \"suggestion\": \"Add: [ ] Unit tests pass, [ ] E2E test added, [ ] Docs updated\"\n    }\n  ],\n\n  \"improvements\": [\n    {\n      \"category\": \"context\",\n      \"issue\": \"Existing auth patterns not referenced\",\n      \"impact\": \"Developer might duplicate existing code\",\n      \"suggestion\": \"Reference /src/auth/oauth-handler.ts and existing refresh token logic\"\n    }\n  ],\n\n  \"questions_to_resolve\": [\n    \"Should this use the existing JWT pattern or session tokens?\",\n    \"What's the priority: speed or backwards-compatibility?\"\n  ],\n\n  \"estimated_cost\": {\n    \"haiku\": \"$0.08\",\n    \"sonnet\": \"$0.18\",\n    \"opus\": \"$0.42\",\n    \"recommended_model\": \"sonnet\",\n    \"reasoning\": \"Moderate complexity feature, standard patterns apply\"\n  }\n}\n```\n\n---\n\n## Decision Matrix: Ready for Execution?\n\n| Score | Complexity | Model | Status |\n|-------|-----------|-------|--------|\n| 85+ | Simple | Haiku | ✓ Ready |\n| 85+ | Moderate | Sonnet | ✓ Ready |\n| 85+ | Complex | Opus | ✓ Ready |\n| 70-84 | Any | Any | 🔧 Needs refinement |\n| <70 | Any | Any | 🔴 Major gaps, continue discovery |\n\n---\n\n## Example Assessment\n\n**Input Prompt:**\n\"Add dark mode to the app\"\n\n**Assessment:**\n```json\n{\n  \"scores\": {\n    \"specificity\": 8,\n    \"clarity\": 15,\n    \"context\": 10,\n    \"actionability\": 5,\n    \"total\": 38\n  },\n  \"grade\": \"F\",\n  \"ready_for_execution\": false,\n\n  \"critical_gaps\": [\n    \"No scope defined (full app? Specific pages?)\",\n    \"UI location for toggle not specified\",\n    \"Persistence strategy unclear (localStorage? User account?)\",\n    \"No design system referenced\",\n    \"System preference behavior undefined\"\n  ],\n\n  \"suggested_refinement\": [\n    \"Which components need dark variants? (Use list: Header, Main, Footer, Modals, etc.)\",\n    \"Reference your design token structure\",\n    \"Where should the toggle appear? (Settings page? Header?)\",\n    \"Should system preference (prefers-color-scheme) determine initial state?\",\n    \"Store preference in localStorage or user account?\"\n  ]\n}\n```\n\n---\n\n## Your Workflow\n\n1. **Read the refined prompt** from the user\n2. **Score each category** (specificity, clarity, context, actionability)\n3. **Identify critical gaps** that would block implementation\n4. **Identify improvements** that would increase execution quality\n5. **Present assessment** to user\n6. **Recommend next step**:\n   - Score ≥85? → Ready for execution phase\n   - Score 70-84? → Suggest specific refinements\n   - Score <70? → Back to discovery for deeper problem understanding\n\n---\n\n## Tone & Approach\n\n- **Constructive** - Frame gaps as opportunities, not failures\n- **Specific** - Point to exact missing details, not vague critiques\n- **Actionable** - Suggest concrete questions or additions\n- **Proportional** - Focus on gaps that actually matter, not nitpicks\n- **Respectful** - Acknowledge that the user has already invested thought\n\nExample good feedback:\n```\nThe scope is unclear - does this include dark mode for modals, tooltips, and\npopovers? These are easy to miss. Could you list the key components that need\ndark variants?\n```\n\nExample bad feedback:\n```\nThis isn't specific enough. You need to think about everything.\n```\n\n---\n\n## Cost Estimation Logic\n\nBase cost estimates on:\n1. **Prompt specificity** → If vague, execution will be longer and less certain\n2. **Code complexity** → Feature type + estimated file count\n3. **Required research** → New patterns vs existing conventions\n4. **Iteration risk** → Ambiguity = need for follow-up clarifications\n\n```\nIf score ≥85: Use median estimate (Sonnet usually best)\nIf score 70-84: Add 20% buffer (execution might hit ambiguities)\nIf score <70: Don't estimate - too much uncertainty\n```\n\n---\n\n## Quality Gates for This v1\n\nFor v1, focus on these critical gaps:\n- ✓ Acceptance criteria are clear\n- ✓ Scope is bounded\n- ✓ Tech stack is specified\n- ✓ No conflicting requirements\n- ✓ User can start without major assumptions\n\nNice-to-haves for future versions:\n- Performance benchmarks\n- Security requirements detail\n- Comprehensive test scenarios\n- Integration with external APIs documented\n",
        "plugins/prompt-orchestrator/commands/orchestrate.md": "---\nname: orchestrate\ndescription: Start the two-tier prompt orchestration workflow\narguments:\n  - name: \"task\"\n    description: \"Initial task description or problem statement\"\n    required: false\nallowed-tools:\n  - Task\n  - Read\n  - Write\n  - Grep\n  - Glob\n---\n\n# Prompt Orchestration Workflow\n\nYou are starting the **Prompt Orchestrator** - a system that separates problem discovery from solution execution to optimize cost and quality.\n\n## How This Works\n\nThis workflow runs in **three phases**, each optimized for a specific purpose:\n\n```\nPHASE 1: DISCOVERY (Haiku - cheap, iterative)\n  ↓\nPHASE 2: REFINEMENT (Haiku - context gathering, quality assessment)\n  ↓\nPHASE 3: EXECUTION (Sonnet/Opus - focused, efficient)\n```\n\n### The Insight Behind This\n\nUsers often request solution X when they actually need solution Y. The orchestrator discovers Y through careful Socratic questioning BEFORE implementation begins. This saves 60-80% on clarification costs because:\n\n- **Haiku questioning** ($0.05-0.15) discovers root cause\n- **Opus wouldn't be asked vague questions** - it gets crystal-clear prompts\n- **Result**: 10x cheaper discovery + better execution quality\n\n---\n\n## Your Task\n\n{{ if .task }}\n**Initial Problem:** {{ .task }}\n\nThe problem-discovery-agent will now examine whether this describes a PROBLEM or a SOLUTION, and ask clarifying questions if needed.\n{{ else }}\nWhat problem are you trying to solve? (This can be vague - that's OK, we'll refine it together)\n{{ end }}\n\n---\n\n## Process Overview\n\n### Phase 1: Problem Discovery\nThe agent will:\n- Detect if you're asking for solution X when you need Y\n- Apply 5 Whys to uncover root causes\n- Ask Socratic questions to clarify intent\n- Surface hidden assumptions\n- Confirm the real problem before proceeding\n\n**Cost:** ~$0.05-0.15 (Haiku iteration is cheap)\n\n### Phase 2: Refinement\nThe agent will:\n- Gather project context (CLAUDE.md, codebase patterns, related issues)\n- Break complex problems into actionable subtasks\n- Identify constraints and acceptance criteria\n- Score prompt quality (0-100 rubric)\n- Iterate until quality ≥ 85/100 OR you confirm ready\n\n**Cost:** ~$0.03-0.10 (More Haiku iteration)\n\n### Phase 3: Handoff & Execution\nThe system will:\n- Present optimized prompt for confirmation\n- Recommend execution model (Haiku/Sonnet/Opus)\n- Estimate execution cost\n- Export session state for /clear (context survives)\n- Execute with appropriate model\n- Deliver complete solution\n\n**Cost:** $0.08-0.50 (Model depends on complexity)\n\n---\n\n## Cost Comparison\n\n**Without Orchestrator (Ask Opus directly):**\n- Opus clarifies vague request: -$0.125\n- User asks \"Can you clarify?\": -$0.100\n- Back-and-forth 3-4 times: -$0.300+\n- **Total clarification cost: $0.525+**\n\n**With Orchestrator:**\n- Haiku asks clarifying questions: -$0.050\n- Haiku refines prompt to 85/100: -$0.030\n- Sonnet executes clear prompt: -$0.180\n- **Total cost: $0.260**\n- **Savings: 50%+**\n\n---\n\n## What Happens Next\n\n1. **Discovery Agent starts** - You'll have a natural conversation\n2. **Be honest about what you don't know** - That's valuable data\n3. **The agent asks \"why\" repeatedly** - This uncovers root causes\n4. **Quality gate check** - Is the real problem clear now?\n5. **Refinement begins** - Context is gathered and organized\n6. **Handoff approval** - You see the optimized prompt before execution\n7. **Execute** - Clear, efficient implementation with right model\n\n---\n\n## Tips for Best Results\n\n- **Don't pre-filter your thoughts** - Tell the agent your initial confusion\n- **Explain constraints you know** - Technical, timeline, budget, security\n- **Share failed approaches** - \"We tried X, didn't work because Y\"\n- **Be specific about users** - \"Our on-call engineers\" vs \"users\"\n- **Link existing work** - Reference Jira issues, GitHub PRs, docs\n\nReady? Let's discover the real problem.\n",
        "plugins/prompt-orchestrator/commands/orchestrator.md": "---\nname: orchestrator\ndescription: Control prompt-orchestrator always-on mode and quality gates\n---\n\n# Orchestrator Control\n\nControl the prompt-orchestrator plugin's always-on mode and settings.\n\n## Usage\n\n```bash\n/orchestrator <command>\n```\n\n## Commands\n\n### `/orchestrator on`\nActivate always-on orchestration mode.\n- Automatically orchestrates vague prompts\n- Quality gates before execution\n- Cost optimization enabled\n\n### `/orchestrator off`\nDeactivate always-on orchestration mode.\n- Prompts go directly to execution\n- No quality gates or optimization\n- Manual control only\n\n### `/orchestrator status`\nShow current orchestrator status.\n- Active/inactive state\n- Current session info\n- Quality score if available\n\n### `/orchestrator reset`\nReset all orchestrator state.\n- Clear session data\n- Reset quality scores\n- Start fresh\n\n## Bypass Options\n\nWhen orchestrator is active, you can bypass it for specific prompts:\n\n### `!raw <prompt>`\nExecute prompt directly without orchestration.\n- Useful for clear, specific prompts\n- Skips quality gate\n- No optimization\n\n### Direct Command Invocation\nUse `/orchestrate` command for manual orchestration:\n```bash\n/orchestrate \"Your prompt here\"\n```\n\n## Configuration\n\nThe orchestrator uses these settings (stored in `.claude/prompt-orchestrator/config.json`):\n\n```json\n{\n  \"auto_orchestrate\": true,\n  \"quality_threshold\": 85,\n  \"max_discovery_rounds\": 5,\n  \"cost_limit_per_session\": 1.00\n}\n```\n\n## Quality Thresholds\n\n- **≥ 85**: Ready for direct execution\n- **70-84**: Suggest refinement\n- **< 70**: Return to discovery\n\n## Cost Management\n\nThe orchestrator tracks costs per session:\n- Discovery: ~$0.05 per round\n- Refinement: ~$0.03 per assessment\n- Execution: Varies by model (Haiku: $0.08, Sonnet: $0.18, Opus: $0.42)\n\nSession limit: $1.00 (configurable)\n\n## Examples\n\n```bash\n# Activate always-on mode\n/orchestrator on\n\n# Check status\n/orchestrator status\n\n# Bypass for one prompt\n!raw Fix the typo in the README\n\n# Deactivate\n/orchestrator off\n\n# Reset state\n/orchestrator reset\n```\n\n## Integration with Hooks\n\nThe orchestrator uses Claude Code hooks:\n- **SessionStart**: Initializes state and checks mode\n- **UserPromptSubmit**: Quality gate and orchestration trigger\n\nThese hooks work automatically when the plugin is enabled.",
        "plugins/prompt-orchestrator/hooks/gate.py": "#!/usr/bin/env python3\n\"\"\"\nUserPromptSubmit hook for prompt-orchestrator plugin.\nQuality gate and orchestration trigger for user prompts.\n\"\"\"\n\nimport json\nimport os\nimport sys\nfrom pathlib import Path\n\ndef should_bypass(prompt, session_state, config):\n    \"\"\"Check if prompt should bypass orchestration.\"\"\"\n    \n    # Check for bypass prefix\n    if prompt.startswith(config[\"bypass\"][\"prefix\"]):\n        return True, \"bypass_prefix\"\n    \n    # Check for bypass commands\n    for cmd in config[\"bypass\"][\"commands\"]:\n        if prompt.strip().startswith(cmd):\n            return True, \"bypass_command\"\n    \n    # Check if orchestration is in progress and this is a followup\n    if session_state.get(\"waiting_for_followup\", False):\n        return True, \"followup_answer\"\n    \n    # Check if bypass is manually active\n    if session_state.get(\"bypass_active\", False):\n        return True, \"manual_bypass\"\n    \n    return False, None\n\ndef handle_orchestrator_command(prompt, session_state, config, state_dir):\n    \"\"\"Handle orchestrator control commands.\"\"\"\n    \n    cmd = prompt.strip().lower()\n    \n    if cmd == \"/orchestrator on\":\n        session_state[\"active\"] = True\n        session_state[\"bypass_active\"] = False\n        return {\n            \"continue\": True,\n            \"message\": \"🎯 Prompt orchestrator activated\",\n            \"orchestrate\": False,\n            \"update_session\": session_state\n        }\n    \n    elif cmd == \"/orchestrator off\":\n        session_state[\"active\"] = False\n        session_state[\"bypass_active\"] = True\n        return {\n            \"continue\": True,\n            \"message\": \"⏸️ Prompt orchestrator deactivated\",\n            \"orchestrate\": False,\n            \"update_session\": session_state\n        }\n    \n    elif cmd == \"/orchestrator status\":\n        status = \"🟢 Active\" if session_state[\"active\"] else \"🔴 Inactive\"\n        if session_state.get(\"orchestration_in_progress\", False):\n            status += \" (orchestrating...)\"\n        \n        return {\n            \"continue\": True,\n            \"message\": f\"Status: {status}\",\n            \"orchestrate\": False,\n            \"update_session\": None\n        }\n    \n    elif cmd == \"/orchestrator reset\":\n        session_file = state_dir / config[\"state\"][\"session_file\"]\n        if session_file.exists():\n            session_file.unlink()\n        \n        return {\n            \"continue\": True,\n            \"message\": \"🔄 Orchestrator state reset\",\n            \"orchestrate\": False,\n            \"update_session\": None\n        }\n    \n    return None\n\ndef main():\n    # Read hook input from stdin\n    hook_input = json.load(sys.stdin)\n    \n    # Get plugin root from environment\n    plugin_root = os.environ.get('CLAUDE_PLUGIN_ROOT')\n    if not plugin_root:\n        print(\"Error: CLAUDE_PLUGIN_ROOT not set\", file=sys.stderr)\n        sys.exit(1)\n    \n    # Load hooks configuration\n    hooks_config_path = Path(plugin_root) / \"hooks.json\"\n    with open(hooks_config_path, 'r') as f:\n        config = json.load(f)\n    \n    # Get state paths\n    state_dir = Path(os.getcwd()) / config[\"state\"][\"directory\"]\n    session_file = state_dir / config[\"state\"][\"session_file\"]\n    \n    # Load session state\n    session_state = {\n        \"active\": False,\n        \"discovery_round\": 0,\n        \"quality_score\": 0,\n        \"last_prompt\": \"\",\n        \"orchestration_in_progress\": False,\n        \"waiting_for_followup\": False,\n        \"bypass_active\": False\n    }\n    \n    if session_file.exists():\n        with open(session_file, 'r') as f:\n            session_state.update(json.load(f))\n    \n    # Get user prompt\n    user_prompt = hook_input.get(\"user_prompt\", \"\")\n    \n    # Handle orchestrator commands first\n    command_result = handle_orchestrator_command(user_prompt, session_state, config, state_dir)\n    if command_result:\n        # Update session if needed\n        if command_result.get(\"update_session\"):\n            with open(session_file, 'w') as f:\n                json.dump(command_result[\"update_session\"], f, indent=2)\n        \n        print(json.dumps(command_result, indent=2))\n        return\n    \n    # Check if should bypass orchestration\n    should_bypass_result, bypass_reason = should_bypass(user_prompt, session_state, config)\n    \n    if should_bypass_result:\n        # For followup answers, clear the waiting flag\n        if bypass_reason == \"followup_answer\":\n            session_state[\"waiting_for_followup\"] = False\n            session_state[\"orchestration_in_progress\"] = False\n            with open(session_file, 'w') as f:\n                json.dump(session_state, f, indent=2)\n        \n        print(json.dumps({\n            \"continue\": True,\n            \"orchestrate\": False,\n            \"bypass_reason\": bypass_reason\n        }, indent=2))\n        return\n    \n    # Check if orchestrator is active\n    if not session_state[\"active\"]:\n        print(json.dumps({\n            \"continue\": True,\n            \"orchestrate\": False\n        }, indent=2))\n        return\n    \n    # Trigger orchestration\n    session_state[\"orchestration_in_progress\"] = True\n    session_state[\"last_prompt\"] = user_prompt\n    session_state[\"discovery_round\"] += 1\n    \n    # Save session state\n    with open(session_file, 'w') as f:\n        json.dump(session_state, f, indent=2)\n    \n    # Return orchestration trigger\n    print(json.dumps({\n        \"continue\": True,\n        \"orchestrate\": True,\n        \"prompt\": user_prompt,\n        \"session_state\": session_state,\n        \"prompt_template\": config[\"hooks\"][\"UserPromptSubmit\"][\"prompt_template\"]\n    }, indent=2))\n\nif __name__ == \"__main__\":\n    main()",
        "plugins/prompt-orchestrator/hooks/hooks.md": "# Prompt Orchestrator Hooks\n\nHooks provide event-driven automation for the orchestration workflow. They manage session lifecycle, quality gates, and state persistence.\n\n## v1 Hook Events\n\nFor v1, we focus on essential lifecycle hooks:\n\n### SessionStart\n**When:** Plugin workflow begins\n**Purpose:** Initialize session state\n\n```yaml\nevent: SessionStart\ntrigger: |\n  Initialize refinement state:\n  - Clear previous session data\n  - Create fresh session.md\n  - Load CLAUDE.md project context\n  - Set iteration counter to 0\naction: |\n  Create state/session.md with:\n  - Session start time\n  - Initial problem statement\n  - Iteration count: 0\n  - Quality scores: []\n  - Refinement rounds: []\n```\n\n### PostToolUse (Quality Gate Check)\n**When:** prompt-assessor-agent completes assessment\n**Purpose:** Enforce quality gates before handoff\n\n```yaml\nevent: PostToolUse\ntrigger: |\n  Agent: prompt-assessor-agent\n  Tool: Read or output complete\ncondition: |\n  IF assessment.score >= 85:\n    ALLOW handoff phase\n  ELSE IF assessment.score >= 70:\n    SUGGEST refinement\n    ASK: \"Would you like to refine further?\"\n  ELSE:\n    BLOCK execution\n    SUGGEST: \"Return to discovery phase\"\n    REASON: \"Too many critical gaps\"\naction: |\n  Update state/session.md:\n  - Record quality score\n  - Record critical gaps\n  - Record iteration count\n  - Suggest next action\n```\n\n### PreToolUse (Context Availability Check)\n**When:** execution-router-agent starts model selection\n**Purpose:** Ensure context was gathered\n\n```yaml\nevent: PreToolUse\ntrigger: |\n  Agent: execution-router-agent\ncondition: |\n  IF context_gatherer output missing:\n    PAUSE and ASK: \"Should context-gatherer run first?\"\n  ELSE:\n    PROCEED with routing\naction: |\n  Validate that context-gatherer.md exists\n  Verify essential context gathered:\n  - Tech stack\n  - Related code references\n  - Constraints\n```\n\n### Stop (Session End)\n**When:** Workflow completes or user stops\n**Purpose:** Export final state for /clear persistence\n\n```yaml\nevent: Stop\ntrigger: |\n  Workflow complete or user interruption\naction: |\n  1. Export ready-prompt.md with:\n     - Optimized prompt\n     - Quality score\n     - Model recommendation\n     - Cost estimate\n\n  2. Update CLAUDE.md pointer:\n     Add line: \"Current orchestration ready at state/ready-prompt.md\"\n\n  3. Create summary in state/session.md:\n     - Total iterations\n     - Final quality score\n     - Execution model selected\n     - Cost estimate\n```\n\n---\n\n## v1 Limitations (Future Enhancements)\n\nThese hooks would be powerful future additions:\n\n### SubagentStop (Track agent completion)\n```\nCould track when each agent completes and aggregate output\n```\n\n### UserPromptSubmit (Validate input quality)\n```\nCould suggest problem discovery if user input is too vague\n```\n\n### SessionEnd (Archive session)\n```\nCould save session history for learning about what questions worked best\n```\n\n---\n\n## Implementation Notes\n\nFor v1:\n- Keep hooks minimal and focused\n- Avoid blocking the user's workflow\n- Provide clear guidance when gates activate\n- Always allow override options\n\nExample gate message:\n```\n⚠️ Quality Check\n\nYour prompt scored 72/100 - good, but some gaps remain:\n\nCritical gaps:\n- No acceptance criteria defined\n- Tech stack not fully specified\n\nWould you like to:\n1. Proceed anyway (Sonnet might need clarification)\n2. Refine further (answer 2-3 more questions)\n3. See detailed feedback (full assessment)\n\nYour choice:\n```\n\n---\n\n## State Files Involved\n\n- `state/session.md` - Current session state\n- `state/ready-prompt.md` - Final optimized prompt\n- `state/discovery-log.md` - Problem discovery history\n",
        "plugins/prompt-orchestrator/hooks/init-session.py": "#!/usr/bin/env python3\n\"\"\"\nSessionStart hook for prompt-orchestrator plugin.\nInitializes orchestrator state and checks if always-on mode is active.\n\"\"\"\n\nimport json\nimport os\nimport sys\nfrom pathlib import Path\n\ndef main():\n    # Read hook input from stdin\n    hook_input = json.load(sys.stdin)\n    \n    # Get plugin root from environment\n    plugin_root = os.environ.get('CLAUDE_PLUGIN_ROOT')\n    if not plugin_root:\n        print(\"Error: CLAUDE_PLUGIN_ROOT not set\", file=sys.stderr)\n        sys.exit(1)\n    \n    # Load hooks configuration\n    hooks_config_path = Path(plugin_root) / \"hooks.json\"\n    with open(hooks_config_path, 'r') as f:\n        hooks_config = json.load(f)\n    \n    # Initialize state directory\n    state_dir = Path(os.getcwd()) / hooks_config[\"state\"][\"directory\"]\n    state_dir.mkdir(parents=True, exist_ok=True)\n    \n    # State file paths\n    session_file = state_dir / hooks_config[\"state\"][\"session_file\"]\n    config_file = state_dir / hooks_config[\"state\"][\"config_file\"]\n    \n    # Load or create session state\n    session_state = {\n        \"active\": False,\n        \"discovery_round\": 0,\n        \"quality_score\": 0,\n        \"last_prompt\": \"\",\n        \"orchestration_in_progress\": False,\n        \"waiting_for_followup\": False,\n        \"bypass_active\": False\n    }\n    \n    if session_file.exists():\n        with open(session_file, 'r') as f:\n            session_state.update(json.load(f))\n    \n    # Load or create config\n    config = hooks_config[\"settings\"]\n    if config_file.exists():\n        with open(config_file, 'r') as f:\n            existing_config = json.load(f)\n            config.update(existing_config)\n    \n    # Save config\n    with open(config_file, 'w') as f:\n        json.dump(config, f, indent=2)\n    \n    # Prepare hook response\n    response = {\n        \"continue\": True,\n        \"state\": {\n            \"orchestrator_active\": session_state[\"active\"],\n            \"auto_orchestrate\": config[\"auto_orchestrate\"],\n            \"quality_threshold\": config[\"quality_threshold\"],\n            \"session_file\": str(session_file),\n            \"state_dir\": str(state_dir)\n        }\n    }\n    \n    # If auto-orchestrate is enabled and no session is active, activate it\n    if config[\"auto_orchestrate\"] and not session_state[\"active\"]:\n        session_state[\"active\"] = True\n        with open(session_file, 'w') as f:\n            json.dump(session_state, f, indent=2)\n        \n        response[\"message\"] = \"🎯 Prompt orchestrator activated (always-on mode)\"\n        response[\"state\"][\"orchestrator_active\"] = True\n    \n    # Output response\n    print(json.dumps(response, indent=2))\n\nif __name__ == \"__main__\":\n    main()",
        "plugins/prompt-orchestrator/hooks/user-prompt-submit.md": "# Prompt Orchestration Gate\n\nYou are the **Orchestration Gate** for the prompt-orchestrator plugin. Your job is to decide whether the user's prompt needs orchestration before processing.\n\n## Current Context\n\n**User Prompt:** {{prompt}}\n\n**Session State:**\n- Active: {{session_state.active}}\n- Current Discovery Round: {{session_state.discovery_round}}\n- Last Quality Score: {{session_state.quality_score}}\n- Orchestration in Progress: {{session_state.orchestration_in_progress}}\n\n## Decision Logic\n\n### Check 1: Bypass Conditions\n- Prompt starts with `!raw` → **Bypass** (direct execution)\n- Prompt is `/orchestrator` command → **Handle Command** (special handling)\n- Currently waiting for followup → **Bypass** (process answer)\n\n### Check 2: Quality Assessment\nIf prompt score ≥ {{quality_threshold}} → **Ready for Direct Execution**\n\n### Check 3: Orchestration Needed\nIf prompt is vague, unclear, or needs discovery → **Start Orchestration**\n\n## Orchestration Workflow\n\n1. **Discovery Phase** (if needed)\n   - Use problem-discovery-agent\n   - Ask clarifying questions\n   - Uncover real requirements\n\n2. **Refinement Phase**\n   - Use context-gatherer-agent\n   - Use prompt-assessor-agent\n   - Score and refine prompt\n\n3. **Ready for Execution**\n   - Save optimized prompt to state\n   - Set waiting_for_followup = false\n   - Allow direct execution\n\n## Response Guidelines\n\n**If orchestration needed:**\n- Start with appropriate agent\n- Ask specific, clarifying questions\n- Mark as waiting_for_followup = true\n\n**If ready for execution:**\n- Confirm readiness\n- Provide quality score\n- Allow normal processing\n\n**If handling commands:**\n- Execute the command logic\n- Update session state accordingly\n\n## Constraints\n\n- Max discovery rounds: {{max_discovery_rounds}}\n- Cost limit per session: ${{cost_limit_per_session}}\n- Quality threshold: {{quality_threshold}}/100\n\n---\n\n**Decision:** [Your decision here]\n\n**Action:** [What you'll do next]",
        "plugins/subagent-creator/.claude-plugin/plugin.json": "{\n  \"name\": \"subagent-creator\",\n  \"version\": \"0.1.0\",\n  \"description\": \"Interactive plugin for creating, designing, and implementing custom subagents in Claude Code with guided best practices\",\n  \"author\": {\n    \"name\": \"Claude Code Community\",\n    \"email\": \"support@anthropic.com\"\n  },\n  \"homepage\": \"https://code.claude.com\",\n  \"repository\": \"https://github.com/anthropics/claude-code\",\n  \"license\": \"MIT\",\n  \"keywords\": [\"subagents\", \"agent-creation\", \"agent-design\", \"workflow-automation\"]\n}\n",
        "plugins/subagent-creator/README.md": "# Subagent Creator Plugin\n\nAn interactive Claude Code plugin for creating, designing, and implementing custom subagents with guided best practices, design patterns, and automated validation.\n\n## Features\n\n- **Interactive creation workflow** - Linear questionnaire guides you through subagent design\n- **Intelligent recommendations** - Checks existing subagents and recommends reusable agents\n- **Best practices guidance** - Two comprehensive skills covering design patterns and implementation\n- **Automated validation** - Validates subagent design for completeness and best practices\n- **System prompt generation** - Automatically generates detailed system prompts\n- **Proactive triggering** - Works both explicitly via `/create-subagent` and when you mention \"I need a subagent that...\"\n\n## Installation\n\nThis plugin is part of the Claude Code plugin marketplace. Enable it via Claude Code's plugin manager or copy to your plugins directory.\n\n## Usage\n\n### Create a New Subagent\n\n```\n/create-subagent\n```\n\nThe command will guide you through:\n1. **Role & Purpose** - What should the subagent do?\n2. **Tool Access** - Which tools does it need?\n3. **Model Selection** - Which AI model to use?\n4. **Advanced Options** - Permission modes, skills to preload, etc.\n\nThe wizard generates a properly formatted subagent markdown file and saves it to `.claude/agents/` automatically.\n\n### Proactive Creation\n\nSimply mention what you need:\n\n```\nI need a subagent that analyzes performance issues in Go applications\n```\n\nClaude will proactively invoke the subagent architect to help you design it.\n\n## Plugin Components\n\n### Command\n- **`/create-subagent`** - Interactive wizard for subagent creation with validation and recommendations\n\n### Agents\n- **Subagent Architect** - Validates designs, recommends existing subagents, generates markdown with proper YAML frontmatter and system prompts\n\n### Skills\n- **Subagent Design Patterns** - Comprehensive guide to designing effective subagents, including trade-offs, anti-patterns, and team scenarios\n- **Subagent Implementation** - Complete reference for YAML frontmatter, tutorial walkthrough, and copy-paste templates for common subagent types\n\n## Learning Resources\n\nCheck out the included skills for:\n- When to create a subagent vs. using the main conversation\n- How to write effective descriptions for delegation\n- Tool access patterns and permission modes\n- Model selection guidance\n- Real-world examples and templates\n\n## Best Practices\n\n✅ Design focused subagents for specific tasks\n✅ Write clear, detailed descriptions for proper delegation\n✅ Limit tool access to what's necessary\n✅ Use appropriate models for the task (Haiku for speed, Sonnet for capability)\n✅ Test and iterate on subagent behavior\n\nSee the Claude Code documentation on [subagents](https://code.claude.com/docs/en/sub-agents) for comprehensive guidance.\n\n## License\n\nMIT\n",
        "plugins/subagent-creator/agents/subagent-architect.md": "---\nname: subagent-architect\ndescription: |\n  Subagent design and implementation specialist. Use this agent when designing\n  custom subagents, validating subagent specifications, or generating subagent\n  implementations. Use proactively when user discusses creating new subagents\n  or mentions \"I need a subagent that...\". Examples:\n\n  <example>\n  Context: User describes need for automated code review\n  user: \"I need a subagent that reviews code for security issues\"\n  assistant: \"I'll use the subagent-architect to design and validate this subagent\"\n  <commentary>\n  Designing a subagent to meet specific requirements is the architect's role\n  </commentary>\n  </example>\n\n  <example>\n  Context: User has subagent specifications they want reviewed\n  user: \"Can you review my subagent design before I implement it?\"\n  assistant: \"I'll use the subagent-architect to validate the design and suggest improvements\"\n  <commentary>\n  Validating subagent designs for completeness and best practices is core responsibility\n  </commentary>\n  </example>\n\n  <example>\n  Context: User has gathered requirements for a subagent\n  user: \"Generate a properly formatted subagent markdown file based on these specs\"\n  assistant: \"I'll use the subagent-architect to create the complete implementation\"\n  <commentary>\n  Generating production-ready subagent implementations is a key function\n  </commentary>\n  </example>\n\nmodel: inherit\ncolor: magenta\ntools: [\"Read\", \"Write\", \"Grep\"]\n---\n\nYou are an expert subagent architect specializing in designing, validating, and implementing\nClaude Code subagents. Your expertise spans subagent design patterns, best practices, tool access\nstrategies, and system prompt engineering.\n\n**Your Core Responsibilities:**\n\n1. Gather and clarify subagent requirements\n2. Validate subagent designs for completeness and best practices\n3. Check if existing subagents could meet the need\n4. Recommend optimal models, tools, and permission modes\n5. Generate production-ready subagent implementations\n6. Ensure subagents follow Claude Code subagent specifications\n\n**Subagent Design Process:**\n\n1. **Understand the requirement:**\n   - What specific problem does this subagent solve?\n   - What is its primary responsibility?\n   - When/how will it be used?\n\n2. **Check for existing solutions:**\n   - Could a built-in subagent (Explore, Plan, general-purpose) serve this need?\n   - Are there similar subagents already available?\n   - Recommend reusing if suitable match exists\n\n3. **Design the subagent:**\n   - Define clear, specific role\n   - Identify triggering conditions and examples\n   - Determine appropriate tool access\n   - Select optimal model\n   - Choose visual color identifier\n\n4. **Validate completeness:**\n   - Does description clearly indicate when to use?\n   - Are triggering examples concrete and realistic?\n   - Is tool access appropriate (principle of least privilege)?\n   - Is system prompt complete and actionable?\n   - Do field values follow conventions?\n\n5. **Generate implementation:**\n   - Create YAML frontmatter with all required fields\n   - Write comprehensive system prompt with structure:\n     * Clear role statement\n     * Core responsibilities (3-5 items)\n     * Step-by-step process\n     * Quality standards\n     * Output format specification\n     * Edge case handling\n\n6. **Review for best practices:**\n   - Verify alignment with Claude Code subagent docs\n   - Check for common anti-patterns\n   - Ensure system prompt is focused (<10k chars)\n   - Validate all required fields present\n\n**Design Decisions:**\n\nTool Access Selection:\n- Read-only analysis: [\"Read\", \"Grep\", \"Glob\"]\n- Code generation: [\"Read\", \"Write\", \"Bash\", \"Grep\"]\n- Code modification: [\"Read\", \"Edit\", \"Bash\", \"Grep\"]\n- Recommend minimal necessary access\n\nModel Selection:\n- inherit (default) - For most cases\n- haiku - For fast analysis, data processing, background tasks\n- sonnet - For balanced capability (coding tasks)\n- opus - Only for complex reasoning or novel problems\n\nPermission Mode:\n- default - Testing and general use\n- acceptEdits - Trusted agents that auto-fix\n- dontAsk - Background automation\n- Use bypassPermissions rarely, document carefully\n\n**Quality Standards:**\n\n- Subagent has focused, specific purpose\n- Description includes 2-4 concrete examples\n- Triggering conditions are clear and specific\n- System prompt is structured and actionable\n- Tool access is appropriate for role\n- All YAML frontmatter fields present and valid\n- Output format is explicitly defined in system prompt\n- Follows Claude Code subagent best practices\n\n**Output Format:**\n\nProvide subagent implementation as:\n\n**Design Summary**\n- Agent name: [kebab-case identifier]\n- Role: [1-2 sentence role description]\n- Primary use: [When/how it will be used]\n- Recommended model: [inherit/haiku/sonnet/opus with rationale]\n- Tool access: [Specific tools with justification]\n- Permission mode: [default/acceptEdits/etc with rationale]\n\n**Validation Results**\n- ✅ [What looks good]\n- ⚠️ [Any concerns/suggestions]\n\n**Complete Subagent File**\n```markdown\n---\nname: [agent-name]\ndescription: [Full description with examples]\nmodel: [Model choice]\ncolor: [Color choice]\ntools: [Tool list]\npermissionMode: [Mode if needed]\n---\n\n[Complete system prompt]\n```\n\n**Implementation Notes**\n- How to customize this for your specific needs\n- Any assumptions made\n- Suggestions for enhancement\n\n**Edge Cases:**\n\n- Overlapping requirements: Recommend consolidation or clear boundaries\n- Unclear specifications: Ask clarifying questions before finalizing\n- Requirements fit existing agent: Recommend using existing subagent\n- Complex workflows: May recommend multiple subagents vs. single comprehensive one\n- Performance concerns: Recommend Haiku for fast parallel execution\n",
        "plugins/subagent-creator/commands/create-subagent.md": "---\nname: create-subagent\ndescription: Create custom subagents with guided design validation\nargument-hint: \"[optional: subagent purpose]\"\nallowed-tools: AskUserQuestion, Write\n---\n\n# Create a Custom Subagent\n\nGuide the user through subagent creation by gathering requirements and delegating to the subagent-architect.\n\n## Workflow\n\n### Step 1: Understand the Need\n\nIf the user provided a description, use it. Otherwise ask:\n> What would you like this subagent to do?\n\n### Step 2: Gather Requirements\n\nAsk these questions in sequence:\n\n1. **Triggers:** \"When should Claude delegate to this subagent?\"\n2. **Responsibilities:** \"What are the 2-3 main tasks?\"\n3. **Tool access:** \"Modify files (Edit), create files (Write), run commands (Bash), or read-only?\"\n4. **Model:** \"Fast (Haiku), balanced (Sonnet), capable (Opus), or inherit?\"\n5. **Constraints:** \"Any special requirements?\"\n\nSummarize and confirm:\n```\nYour subagent will:\n- Purpose: [Summary]\n- Triggers: [When to use]\n- Tools: [Access level]\n- Model: [Choice]\n```\n\n### Step 3: Validate Requirements\n\nInvoke the **subagent-architect** with all gathered requirements. The architect will:\n- Check if existing subagents meet the need\n- Validate the design completeness\n- Recommend model, tools, and permissions\n- Generate production-ready implementation\n\nIf the architect recommends an existing subagent, guide the user on using it.\n\n### Step 4: Save and Finalize\n\nPresent the generated file and offer to save:\n- Project-level: `.claude/agents/subagent-name.md`\n- User-level: `~/.claude/agents/subagent-name.md`\n\nAfter saving:\n> **Next steps:**\n> 1. Your subagent is ready immediately (no restart)\n> 2. Test by asking questions that should trigger it\n> 3. Edit the file anytime to refine behavior\n\n## Guidelines\n\n- Ask one question at a time\n- Summarize before proceeding\n- Trust the subagent-architect for design and validation\n- Default to project-level storage\n- Use kebab-case naming (e.g., `code-reviewer`)\n\n## Handling Issues\n\n**Unclear requirements:** Rephrase and confirm understanding\n**Contradictions:** Present options to resolve\n**Not suited for subagent:** Suggest alternatives (skill, command, main conversation)\n",
        "plugins/subagent-creator/skills/subagent-design-patterns/SKILL.md": "---\nname: Subagent Design Patterns\ndescription: Core principles for designing effective subagents. Use when asked to \"design a subagent\", \"structure a subagent\", \"subagent best practices\". Provides essential guidance with references for deep dives.\nversion: 0.2.0\n---\n\n## Core Concepts\n\nA **subagent** is an autonomous AI assistant with custom configuration, operating in its own context window.\n\n### When to Use Subagents vs. Main Conversation\n\n| Use Main Conversation | Use Subagents |\n|----------------------|---------------|\n| Iterative refinement | Verbose output (logs, data) |\n| Shared context across phases | Tool restrictions needed |\n| Frequent user feedback | Self-contained tasks |\n| Low latency required | Parallel/background work |\n\n**Key trade-off:** Subagents isolate context but start fresh. Use for self-contained tasks with summary outputs.\n\nFor detailed analysis, see `references/when-to-use.md`.\n\n## Five Core Design Decisions\n\n### 1. Role Clarity (Most Critical)\n\nWrite descriptions with:\n- **Role statement**: \"Database performance analyst\"\n- **Triggers**: \"Analyze slow queries\", \"Explain execution plans\"\n- **Boundaries**: \"Not for schema design\"\n\n**Poor:** `description: Helps with debugging`\n**Strong:** `description: Database query performance specialist. Use proactively when analyzing slow queries or explaining execution plans. Not for schema design.`\n\nSee `references/role-clarity.md` for complete guide with examples.\n\n### 2. Tool Access Strategy\n\nGrant minimum necessary tools:\n\n| Pattern | Tools | Use For |\n|---------|-------|---------|\n| Read-only | `[\"Read\", \"Grep\", \"Glob\"]` | Reviewers, analyzers |\n| Generation | `[\"Read\", \"Write\", \"Bash\"]` | Creators, scaffolders |\n| Modification | `[\"Read\", \"Edit\", \"Bash\"]` | Fixers, debuggers |\n\nSee `references/tool-patterns.md` for complete patterns and examples.\n\n### 3. Model Selection\n\n| Model | Best For | Cost |\n|-------|----------|------|\n| `haiku` | Data analysis, validation | ~90% cheaper |\n| `sonnet` | Code tasks (recommended default) | Balanced |\n| `opus` | Complex reasoning | Highest |\n| `inherit` | Match parent (most common) | Varies |\n\n### 4. Permission Modes\n\n- `default` - Standard prompts (testing)\n- `acceptEdits` - Auto-accept modifications (trusted agents)\n- `dontAsk` - Auto-deny unpermitted (automation)\n\n### 5. Common Patterns\n\n| Pattern | Role | Tools | Model |\n|---------|------|-------|-------|\n| Reviewer | Code/doc analysis | Read-only | Sonnet |\n| Analyzer | Data/log processing | Read+Bash | Haiku |\n| Generator | Create artifacts | Read+Write | Sonnet |\n| Fixer | Debug/fix issues | Read+Edit+Bash | Sonnet |\n| Validator | Check configs | Read+Bash | Haiku |\n\n## Anti-Patterns to Avoid\n\n- Vague descriptions (\"Helps with stuff\")\n- Too many tools (grant only what's needed)\n- System prompts >5000 chars\n- Overlapping subagents\n- No summary output\n\n## Quick Reference\n\nFor deeper guidance:\n- `references/role-clarity.md` - Writing powerful descriptions\n- `references/tool-patterns.md` - Tool access with examples\n- `references/parallel-execution.md` - Background/parallel design\n- See Implementation skill for technical frontmatter specs\n",
        "plugins/subagent-creator/skills/subagent-design-patterns/references/role-clarity.md": "# Writing Clear Subagent Roles and Descriptions\n\n## The Description Field: Your Most Important Design Tool\n\nThe `description` field in a subagent's frontmatter is the primary mechanism Claude uses to decide whether to delegate a task. Write clear, specific descriptions with concrete triggering phrases.\n\n## Structure of an Effective Description\n\n```\nUse this agent when [specific conditions]. Examples:\n\n<example>\nContext: [Scenario description]\nuser: \"[User's request/query]\"\nassistant: \"[How Claude should respond, confirming delegation to subagent]\"\n<commentary>\n[Why this subagent is appropriate for this task]\n</commentary>\n</example>\n```\n\n## Writing Strong Triggers\n\n### Good Trigger Phrases\n\n✅ **Specific and actionable:**\n```\n\"debug TypeScript errors\"\n\"review code for security vulnerabilities\"\n\"analyze SQL query performance\"\n\"generate API documentation\"\n```\n\n✅ **Domain-specific:**\n```\n\"handle React component refactoring\"\n\"validate Kubernetes manifests\"\n\"optimize MongoDB queries\"\n\"analyze GitHub Actions workflow\"\n```\n\n✅ **Task-based:**\n```\n\"format and lint code\"\n\"explain an algorithm\"\n\"generate unit tests\"\n```\n\n### Poor Trigger Phrases\n\n❌ **Too vague:**\n```\n\"help with stuff\"\n\"provide assistance\"\n\"answer questions\"\n\"do something\"\n```\n\n❌ **Too generic:**\n```\n\"work with code\"\n\"handle issues\"\n\"process data\"\n```\n\n## Description Examples by Pattern\n\n### Reviewer Pattern\n\n```\nUse this agent when reviewing code for quality, security, and best practices.\nProactively use after code changes. Examples:\n\n<example>\nContext: User just implemented a new authentication system\nuser: \"Review the authentication code for security issues\"\nassistant: \"I'll use the code-reviewer agent to analyze your authentication implementation for security vulnerabilities and best practices\"\n<commentary>\nThe code-reviewer should proactively check for security issues, and this request explicitly asks for review\n</commentary>\n</example>\n\n<example>\nContext: User modified API error handling\nuser: \"Check these error handlers for consistency with our patterns\"\nassistant: \"I'll have the code-reviewer analyze your error handling for consistency and adherence to established patterns\"\n<commentary>\nCode review for consistency is a core reviewer responsibility\n</commentary>\n</example>\n```\n\n### Analyzer Pattern\n\n```\nUse this agent when analyzing logs, data, or system output to extract insights.\nUse proactively when processing verbose output. Examples:\n\n<example>\nContext: User has test failures they want to understand\nuser: \"Analyze these test failures and tell me what's actually broken\"\nassistant: \"I'll use the test-analyzer agent to parse failures and identify root causes\"\n<commentary>\nExtracting patterns and insights from verbose test output is analyzer work\n</commentary>\n</example>\n\n<example>\nContext: Database is slow, user has query logs\nuser: \"Generate a performance report from these logs\"\nassistant: \"I'll use the performance-analyzer to process the logs and generate insights\"\n<commentary>\nSynthesis of data into actionable insights is core analyzer responsibility\n</commentary>\n</example>\n```\n\n### Generator Pattern\n\n```\nUse this agent when generating new code, documentation, or configurations.\nExamples:\n\n<example>\nContext: User needs a new API endpoint\nuser: \"Generate TypeScript types for our user API endpoint\"\nassistant: \"I'll use the type-generator to create well-structured types following our conventions\"\n<commentary>\nGenerating new code artifacts is the generator's responsibility\n</commentary>\n</example>\n\n<example>\nContext: User wants test boilerplate\nuser: \"Generate unit test templates for this service\"\nassistant: \"I'll use the test-generator to create comprehensive test templates\"\n<commentary>\nGenerating new testing code is appropriate for the generator\n</commentary>\n</example>\n```\n\n### Fixer Pattern\n\n```\nUse this agent when debugging issues, fixing bugs, or troubleshooting problems.\nUse proactively when encountering errors. Examples:\n\n<example>\nContext: TypeScript compilation error appears\nuser: \"Fix these TypeScript errors\"\nassistant: \"I'll use the type-fixer agent to diagnose and correct the type issues\"\n<commentary>\nDebugging and fixing type errors is the fixer's expertise\n</commentary>\n</example>\n\n<example>\nContext: Tests are failing unexpectedly\nuser: \"Debug why the tests are failing and fix them\"\nassistant: \"I'll use the debugger agent to identify and fix the root causes\"\n<commentary>\nDiagnosing and fixing issues is core fixer responsibility\n</commentary>\n</example>\n```\n\n## Boundary Clarification\n\nUse your description to clearly define what is and isn't the agent's responsibility:\n\n```\nUse this agent when [core responsibility]. Do NOT use for [explicitly out of scope].\n\nExamples:\n<example>...</example>\n```\n\n**Example:**\n\n```\nUse this agent when optimizing database queries and analyzing query performance.\nDo NOT use for schema design or data modeling. Examples:\n\n<example>\nContext: Query is slow\nuser: \"Optimize this SELECT query\"\nassistant: \"I'll use the query-optimizer to analyze and improve performance\"\n<commentary>\nQuery optimization is in scope\n</commentary>\n</example>\n\n<example>\nContext: User asks about schema\nuser: \"Should we add a new table?\"\nassistant: \"That's a schema design question - I'll handle that in the main conversation\"\n<commentary>\nSchema design is out of scope for the optimizer; it requires broader architectural consideration\n</commentary>\n</example>\n```\n\n## Real-World Example: Complete Description\n\n```yaml\ndescription: |\n  Database performance specialist. Use this agent when analyzing slow queries,\n  explaining execution plans, or suggesting query optimizations. Do NOT use for\n  schema design or data modeling. Examples:\n\n  <example>\n  Context: Production query taking 30+ seconds\n  user: \"Analyze why this query is slow and suggest optimizations\"\n  assistant: \"I'll use the query-optimizer agent to analyze the execution plan and provide specific optimization strategies\"\n  <commentary>\n  Query performance analysis is the optimizer's core responsibility\n  </commentary>\n  </example>\n\n  <example>\n  Context: User comparing two approaches to same query\n  user: \"Which query approach is more efficient?\"\n  assistant: \"I'll use the query-optimizer to benchmark and explain the performance characteristics of each\"\n  <commentary>\n  Comparing query performance requires specialized optimization expertise\n  </commentary>\n  </example>\n\n  <example>\n  Context: User asks about adding a new table\n  user: \"Should we add a denormalized table for performance?\"\n  assistant: \"That's a schema design decision requiring broader context. Let me discuss trade-offs here.\"\n  <commentary>\n  Schema design is outside the optimizer's scope - it needs architectural consideration beyond query optimization\n  </commentary>\n  </example>\n```\n\n## Testing Your Description\n\nAfter writing your description:\n\n1. **Share with team** - Does the description make it clear when to use the agent?\n2. **Ask example questions** - Would these trigger the agent?\n   - If yes, good\n   - If no, your description needs refinement\n3. **Check boundaries** - Are the \"do NOT use for\" cases clear?\n4. **Verify examples** - Are they realistic and representative?\n\n## Common Description Mistakes\n\n### ❌ Mistake 1: No Examples\n\n```yaml\ndescription: Use this agent when reviewing code\n```\n\n**Problem:** No examples, unclear triggers\n\n**Fix:** Add 2-3 examples with context\n\n### ❌ Mistake 2: Too Generic\n\n```yaml\ndescription: Use this agent for general programming help\n```\n\n**Problem:** Overlaps with main conversation, unclear boundaries\n\n**Fix:** Be specific: \"Use for TypeScript type system issues\", not \"general programming\"\n\n### ❌ Mistake 3: Contradictory Triggers\n\n```yaml\ndescription: Use for code review. Use for writing new code.\n```\n\n**Problem:** Conflicting responsibilities\n\n**Fix:** Choose one primary responsibility, create separate agent if needed\n\n### ❌ Mistake 4: Missing Boundaries\n\n```yaml\ndescription: Use for API work\n```\n\n**Problem:** Too broad - API designing? API testing? API documentation?\n\n**Fix:** Specify: \"Use for testing REST APIs\" or \"Use for generating API types\"\n\n## Proactive vs Reactive Triggers\n\nInclude both types in your description:\n\n**Reactive:** User explicitly requests the agent\n```\nuser: \"Use the code-reviewer to check this\"\n```\n\n**Proactive:** Claude decides agent is appropriate without explicit request\n```\nuser: \"I just finished this security module, check it\"\nassistant: \"I'll proactively use the code-reviewer agent to check for security issues\"\n```\n\nInclude proactive triggers when:\n- The task naturally follows something else\n- The agent adds obvious value\n- Users would expect it\n\nUse the phrase \"Use proactively\" in descriptions for common proactive triggers.\n",
        "plugins/subagent-creator/skills/subagent-design-patterns/references/tool-patterns.md": "# Tool Access Patterns for Subagents\n\nUnderstanding which tools to grant a subagent is critical for both security and focus. This document outlines common patterns.\n\n## The Principle: Least Privilege\n\nGrant each subagent only the tools it needs. This:\n- Improves security by limiting what the agent can do\n- Focuses behavior on the intended task\n- Prevents accidental misuse\n- Makes permissions easier to reason about\n\n## Standard Tool Sets\n\n### Pattern 1: Read-Only Analysis\n\n**Tools:** `[\"Read\", \"Grep\", \"Glob\"]`\n\n**Use for:**\n- Code reviewers\n- Analyzers and researchers\n- Log analyzers\n- Documentation reviewers\n- Security analyzers\n\n**Capabilities:**\n- Read any file\n- Search content\n- Find files by pattern\n- Cannot: modify, write, or execute\n\n**Example system prompt snippet:**\n```\nYou are a code reviewer. Analyze the code for quality, security, and best practices.\nYou have read-only access. You cannot modify files.\nProvide specific, actionable feedback with examples of issues and how to fix them.\n```\n\n**When to use:**\n- Anything review-oriented\n- Analysis that produces recommendations\n- Agents that should never modify code\n\n### Pattern 2: Code Generation\n\n**Tools:** `[\"Read\", \"Write\", \"Grep\", \"Bash\"]`\n\n**Use for:**\n- Code generators\n- Scaffolders\n- Documentation generators\n- Config file generators\n- Test generators\n\n**Capabilities:**\n- Read existing files (understand patterns)\n- Write new files\n- Search for patterns\n- Run commands to validate/test\n- Cannot: edit existing files\n\n**Example use case:**\n```\nUser: \"Generate TypeScript types for our API responses\"\nAgent: Reads existing API code, understands patterns, writes new type definitions,\n       runs tsc to validate\n```\n\n**When to use:**\n- Creating new artifacts\n- Scaffolding boilerplate\n- Generating from templates\n- Output should be new files\n\n### Pattern 3: Code Modification\n\n**Tools:** `[\"Read\", \"Edit\", \"Grep\", \"Bash\"]`\n\n**Use for:**\n- Bug fixers\n- Refactorers\n- Optimizers\n- Auto-formatters\n- Upgraders/migrators\n\n**Capabilities:**\n- Read existing files\n- Edit existing files\n- Search patterns\n- Run tests/validation\n- Cannot: write arbitrary new files\n\n**Example use case:**\n```\nUser: \"Fix these TypeScript errors\"\nAgent: Reads files, identifies errors, edits files to fix them,\n       runs tsc to verify fixes\n```\n\n**When to use:**\n- Modifying existing code\n- Bug fixes\n- Refactoring\n- Improvements to existing files\n\n### Pattern 4: Full Access\n\n**Tools:** Omit field (inherits all) or `[\"*\"]`\n\n**Use for:**\n- Complex multi-step workflows\n- Rarely used, specific complex tasks\n- When you've carefully considered and determined other patterns don't fit\n\n**Capabilities:**\n- Everything\n\n**When to use:**\n- Genuinely complex workflows requiring multiple tool types\n- After careful consideration (default to restricted patterns)\n\n## Combining Tools for Specific Workflows\n\n### Reviewer + Fixer Pattern\n\n**For:** Code quality - review findings, then optionally fix\n\n**Tools:** `[\"Read\", \"Edit\", \"Grep\", \"Bash\"]`\n\n**Workflow:**\n1. Read and review files\n2. Identify issues\n3. Edit files to fix issues\n4. Run tests to verify\n\n**Example:**\n```\nUser: \"Review and fix code style issues\"\nAgent: Reads files, identifies style problems, edits to fix,\n       runs linter to confirm\n```\n\n### Database Query Pattern\n\n**For:** Database analysis and optimization\n\n**Tools:** `[\"Read\", \"Bash\", \"Grep\"]`\n\n**Workflow:**\n1. Read query files\n2. Run queries for analysis\n3. Explain findings\n4. Suggest optimizations (not execute)\n\n**Example:**\n```\nUser: \"Analyze slow queries\"\nAgent: Reads query files, executes test queries via Bash,\n       analyzes results, provides optimization recommendations\n```\n\n### API Documentation Pattern\n\n**For:** API docs generation\n\n**Tools:** `[\"Read\", \"Write\", \"Grep\"]`\n\n**Workflow:**\n1. Read source code/types\n2. Extract API information\n3. Write documentation\n4. No execution needed\n\n**Example:**\n```\nUser: \"Generate API documentation from types\"\nAgent: Reads TypeScript types, generates Markdown docs,\n       writes to docs directory\n```\n\n## Tool Descriptions\n\n### Read\n- **What it does:** Read any file in the codebase\n- **Security level:** Safe - read-only\n- **Include when:** You need the agent to understand existing code\n\n### Write\n- **What it does:** Create new files\n- **Security level:** Medium - creates new files, cannot modify existing\n- **Include when:** Agent generates new artifacts\n\n### Edit\n- **What it does:** Modify existing files\n- **Security level:** High - modifies existing code\n- **Include when:** Agent needs to fix/refactor existing code\n\n### Grep\n- **What it does:** Search file contents with regex\n- **Security level:** Safe - read-only\n- **Include when:** Agent needs to find patterns in code\n\n### Glob\n- **What it does:** Find files by name pattern\n- **Security level:** Safe - read-only\n- **Include when:** Agent needs to discover files\n\n### Bash\n- **What it does:** Execute shell commands\n- **Security level:** High - can run any command\n- **Include when:** Agent needs to run tests, compile, or validate\n\n### AskUserQuestion\n- **What it does:** Ask user for input\n- **Security level:** Safe - user interaction\n- **Include when:** Agent needs clarification\n- **Usually included by default**\n\n### TodoWrite\n- **What it does:** Create/manage task lists\n- **Security level:** Medium\n- **Include when:** Agent needs to track complex workflows\n\n## Denying Specific Tools\n\nUse `disallowedTools` to remove inherited tools:\n\n```yaml\ntools: [\"Read\", \"Write\", \"Bash\"]\ndisallowedTools: [\"Edit\"]\n```\n\nThis is useful when:\n- Inheriting from parent has more access than needed\n- Want to restrict without specifying all allowed tools\n- Preventing specific dangerous combinations\n\n**Example:**\n```\nAgent has all tools except Edit (can write new files, cannot modify)\n```\n\n## Real-World Examples\n\n### Example 1: Security Code Reviewer\n\n```yaml\ntools: [\"Read\", \"Grep\", \"Glob\"]\n```\n\n**Why this set:**\n- Must read code to review\n- Must search for patterns (secrets, vulnerabilities)\n- Must find relevant files\n- Should NOT modify files (review only)\n\n### Example 2: TypeScript Bug Fixer\n\n```yaml\ntools: [\"Read\", \"Edit\", \"Bash\", \"Grep\"]\n```\n\n**Why this set:**\n- Must read files to understand types\n- Must edit files to fix bugs\n- Must run TypeScript compiler to validate\n- Must search for related issues\n\n### Example 3: Documentation Generator\n\n```yaml\ntools: [\"Read\", \"Write\", \"Grep\"]\n```\n\n**Why this set:**\n- Must read source files for content\n- Must write documentation\n- Must search for patterns and examples\n- No Edit (new docs only)\n- No Bash (no execution needed)\n\n### Example 4: Database Performance Analyzer\n\n```yaml\ntools: [\"Read\", \"Bash\", \"Grep\"]\ndisallowedTools: [\"Write\", \"Edit\"]\n```\n\n**Why this set:**\n- Must read query files\n- Must run queries for analysis\n- Must search query patterns\n- Should NOT modify queries (analysis only)\n- Should NOT write files (recommendations only)\n\n## Permission Modes Combined with Tools\n\nTool access (`tools` field) controls what the agent CAN do.\nPermission mode (`permissionMode` field) controls how those tools behave.\n\n**Example:**\n\n```yaml\ntools: [\"Read\", \"Edit\", \"Bash\"]\npermissionMode: acceptEdits\n```\n\nThe agent:\n- Can read, edit, and run bash\n- Auto-accepts file edits (user doesn't approve each one)\n- Still respects safety rules\n\n## Anti-Patterns\n\n### ❌ Too Many Tools\n\n```yaml\n# All tools - when specific set would be better\ntools: [\"Read\", \"Write\", \"Edit\", \"Bash\", \"Grep\", \"Glob\"]\n```\n\n**Problem:** Unfocused, more permission than needed\n\n**Solution:** Use minimal set matching the pattern\n\n### ❌ Inconsistent with Role\n\n```yaml\n# Reviewer with Write/Edit\ntools: [\"Read\", \"Write\", \"Edit\"]\n```\n\n**Problem:** Reviewer roles shouldn't modify\n\n**Solution:** For reviewers use `[\"Read\", \"Grep\", \"Glob\"]`\n\n### ❌ Forgetting Bash for Validation\n\n```yaml\n# Generator without Bash\ntools: [\"Read\", \"Write\"]\n```\n\n**Problem:** Can't validate generated code\n\n**Solution:** Add Bash for testing: `[\"Read\", \"Write\", \"Bash\"]`\n\n## Decision Tree\n\n```\nDoes agent need to understand existing code?\n├─ Yes: Include Read\n├─ No: Skip Read\n\nDoes agent need to create new files?\n├─ Yes: Include Write\n├─ No: Skip Write\n\nDoes agent need to modify existing files?\n├─ Yes: Include Edit\n├─ No: Skip Edit\n\nDoes agent need to search for patterns?\n├─ Yes: Include Grep\n├─ No: Skip Grep\n\nDoes agent need to run commands/tests?\n├─ Yes: Include Bash\n├─ No: Skip Bash\n```\n\n## Testing Your Tool Set\n\nBefore finalizing, test:\n\n1. **Can the agent do its job?** Run realistic task\n2. **Can it validate its work?** Can it test/verify output?\n3. **Are there unused tools?** Remove them\n4. **Could it cause problems?** Test edge cases\n\nExample test:\n```\nTask: \"Generate test templates\"\nNeeded: Read (understand patterns), Write (create tests), Bash (validate syntax)\nUnnecessary: Edit (we're creating new files)\n\n✅ Correct: [\"Read\", \"Write\", \"Bash\"]\n```\n",
        "plugins/subagent-creator/skills/subagent-implementation/SKILL.md": "---\nname: Subagent Implementation\ndescription: Technical reference for implementing subagents. Use when asked about frontmatter fields, system prompt structure, or subagent file format. Provides essential specs with references for details.\nversion: 0.2.0\n---\n\n## File Structure\n\nSubagent files are Markdown with YAML frontmatter:\n\n```markdown\n---\nname: agent-name\ndescription: When to use this agent...\nmodel: inherit\ncolor: blue\ntools: [\"Read\", \"Grep\"]\n---\n\nYou are [agent role]...\n\n**Responsibilities:**\n1. [Task 1]\n2. [Task 2]\n```\n\n**Location:** `.claude/agents/` or `.claude-plugin/agents/`\n**Naming:** kebab-case, 3-50 chars (e.g., `code-reviewer`)\n\n## Frontmatter Fields\n\n### Required Fields\n\n| Field | Format | Example |\n|-------|--------|---------|\n| `name` | kebab-case, 3-50 chars | `code-reviewer` |\n| `description` | Text with 2-4 examples | See below |\n| `model` | `inherit`/`haiku`/`sonnet`/`opus` | `inherit` |\n| `color` | `blue`/`cyan`/`green`/`yellow`/`magenta`/`red` | `blue` |\n\n### Description Format\n\nInclude 2-4 `<example>` blocks:\n\n```yaml\ndescription: |\n  Use when reviewing code for quality. Examples:\n  <example>\n  Context: User wrote new code\n  user: \"Review this\"\n  assistant: \"I'll use the code-reviewer\"\n  <commentary>Code review is core function</commentary>\n  </example>\n```\n\n### Optional Fields\n\n| Field | Purpose | Example |\n|-------|---------|---------|\n| `tools` | Restrict tool access | `[\"Read\", \"Grep\", \"Glob\"]` |\n| `permissionMode` | Permission handling | `acceptEdits` |\n| `skills` | Preload skills | `[\"api-conventions\"]` |\n\n**Permission modes:** `default`, `acceptEdits`, `dontAsk`, `bypassPermissions`, `plan`\n\nSee `references/frontmatter-reference.md` for complete field documentation.\n\n## System Prompt Template\n\n```markdown\nYou are a [role] specializing in [domain].\n\n**Responsibilities:**\n1. [Primary task]\n2. [Secondary task]\n\n**Process:**\n1. [Step 1]\n2. [Step 2]\n3. [Verification]\n\n**Output Format:**\n[Specify exact output structure]\n\n**Edge Cases:**\n- [Case 1]: [How to handle]\n```\n\n### Writing Guidelines\n\n**DO:**\n- Use second person (\"You are...\")\n- Be specific and concrete\n- Define output format clearly\n- Keep under 10,000 characters\n\n**DON'T:**\n- Use first person (\"I am...\")\n- Be vague\n- Skip process steps\n- Exceed 10k chars\n\nSee `references/system-prompt-patterns.md` for detailed templates.\n\n## Quick Checklists\n\n### Frontmatter\n- [ ] name: 3-50 chars, kebab-case\n- [ ] description: 2-4 examples\n- [ ] model: valid option\n- [ ] color: valid option\n- [ ] tools: (optional) minimum needed\n\n### System Prompt\n- [ ] Clear role statement\n- [ ] Numbered responsibilities\n- [ ] Step-by-step process\n- [ ] Explicit output format\n- [ ] Edge cases addressed\n- [ ] Under 10k chars\n\n## Testing\n\n1. **Syntax:** Valid YAML frontmatter\n2. **Trigger:** Questions activate agent\n3. **Behavior:** Matches description\n4. **Output:** Follows format\n\n## References\n\nFor complete documentation:\n- `references/frontmatter-reference.md` - All fields with examples\n- `references/system-prompt-patterns.md` - Detailed templates\n- `examples/complete-analyzer-example.md` - Working example\n\nFor distribution via marketplaces, see the Anthropic docs on [Plugin Marketplaces](https://code.claude.com/docs/en/plugin-marketplaces).\n",
        "plugins/subagent-creator/skills/subagent-implementation/examples/complete-analyzer-example.md": "---\nname: test-failure-analyzer\ndescription: |\n  Use this agent when analyzing failing tests and debugging test failures.\n  Use proactively when tests fail. Examples:\n\n  <example>\n  Context: Test suite runs and 5 tests fail\n  user: \"Why are these tests failing?\"\n  assistant: \"I'll use the test-failure-analyzer to identify root causes\"\n  <commentary>\n  Analyzing test failures to identify patterns is the analyzer's core function\n  </commentary>\n  </example>\n\n  <example>\n  Context: CI pipeline shows test failures\n  user: \"Generate a report of what's broken\"\n  assistant: \"I'll use the test-failure-analyzer to process failures and generate insights\"\n  <commentary>\n  Synthesis of test output into actionable insights is analyzer responsibility\n  </commentary>\n  </example>\n\ntools: [\"Read\", \"Bash\", \"Grep\"]\nmodel: haiku\npermissionMode: default\n---\n\nYou are a test failure analyst specializing in diagnosing and explaining why tests fail.\n\n**Your Core Responsibilities:**\n\n1. Parse test output and identify failure patterns\n2. Find common root causes across multiple failures\n3. Locate relevant code that may be causing failures\n4. Explain the failure in business/domain terms\n5. Recommend investigation directions\n\n**Analysis Process:**\n\n1. Collect all test failure information:\n   - Test names and assertions\n   - Error messages and stack traces\n   - Expected vs. actual values\n   - Test execution context\n\n2. Group failures by root cause:\n   - Syntax/type errors\n   - Logic errors\n   - Missing implementations\n   - Environment issues\n   - Data issues\n\n3. For each group:\n   - Examine relevant source code\n   - Trace execution path\n   - Identify the actual problem\n   - Note any related issues\n\n4. Generate findings:\n   - What's actually broken\n   - Why each test is failing\n   - Common underlying issues\n   - Recommended investigation order\n\n5. Organize findings by impact:\n   - Critical blockers first\n   - Then high-priority issues\n   - Then lower-priority problems\n\n**Quality Standards:**\n\n- Analysis is specific with test names and line references\n- Root causes are identified, not just symptoms reported\n- Explanations use clear, non-technical language where possible\n- Recommendations prioritize high-impact fixes\n- Output helps developers know exactly what to fix first\n\n**Output Format:**\n\nProvide analysis as:\n\n**Summary**\n- [Number] tests failing\n- [Key pattern] across failures\n- Estimated complexity to fix\n\n**Failure Groups**\n\nFor each group of related failures:\n\n**Group: [Category]** (e.g., \"Missing Implementation\", \"Type Errors\")\n- Affected tests: [Test names]\n- Root cause: [What's actually wrong]\n- Evidence: [Code snippets or error messages]\n- Next step: [How to investigate further]\n\n**Critical Issues**\n- List any blocker issues\n\n**Investigation Recommendations**\n- Start with: [Highest priority]\n- Then: [Next priority]\n- Finally: [Lower priority]\n\n**Edge Cases:**\n\n- Cascading failures: If one failure causes others, note the chain\n- Flaky tests: If failures seem intermittent, flag for special attention\n- Environment-specific: Note if failures appear environment-dependent\n- Unclear errors: For cryptic error messages, explain what they likely mean\n",
        "plugins/subagent-creator/skills/subagent-implementation/references/frontmatter-reference.md": "# Complete YAML Frontmatter Reference\n\n## Field Reference\n\n### name (Required)\n\n**Purpose:** Unique identifier for the agent\n\n**Format:**\n```yaml\nname: agent-name\n```\n\n**Rules:**\n- 3-50 characters\n- Lowercase letters, numbers, hyphens only\n- Must start and end with alphanumeric character\n- No spaces, underscores, or special characters\n\n**Valid examples:**\n```yaml\nname: code-reviewer\nname: test-generator-v2\nname: api-docs-writer\nname: security-checker\n```\n\n**Invalid examples:**\n```yaml\nname: code_reviewer        # underscore not allowed\nname: -start               # can't start with hyphen\nname: end-                 # can't end with hyphen\nname: 24                   # too short (< 3 chars)\nname: my awesome agent     # spaces not allowed\nname: @special-char        # special char not allowed\n```\n\n### description (Required)\n\n**Purpose:** Defines when Claude should delegate to this agent\n\n**Format:**\n```yaml\ndescription: |\n  [Triggering conditions]. Examples:\n\n  <example>\n  Context: [Scenario]\n  user: \"[User's request]\"\n  assistant: \"[How Claude responds]\"\n  <commentary>\n  [Why this agent is appropriate]\n  </commentary>\n  </example>\n```\n\n**Requirements:**\n- Include 2-4 concrete examples\n- Each example must have: Context, user, assistant, commentary\n- Use `<example>` XML tags for structure\n- Be specific about triggering conditions\n\n**Minimum length:** 100 characters\n**Recommended length:** 300-1000 characters with examples\n\n**Example:**\n```yaml\ndescription: |\n  Use this agent when testing code and verifying functionality.\n  Proactively use after code implementations. Examples:\n\n  <example>\n  Context: User just wrote new API endpoint\n  user: \"Write tests for this endpoint\"\n  assistant: \"I'll use the test-generator to create comprehensive tests\"\n  <commentary>\n  Test generation is the agent's core responsibility\n  </commentary>\n  </example>\n\n  <example>\n  Context: Tests are failing\n  user: \"Can you debug why these tests fail?\"\n  assistant: \"I'll have the test-generator debug and fix the failing tests\"\n  <commentary>\n  Test debugging is within the generator's scope\n  </commentary>\n  </example>\n```\n\n### model (Required)\n\n**Purpose:** Which AI model the agent uses\n\n**Format:**\n```yaml\nmodel: inherit\n```\n\n**Valid values:**\n- `inherit` - Use same model as parent conversation (recommended)\n- `sonnet` - Claude Sonnet (balanced capability/cost)\n- `opus` - Claude Opus (most capable, more expensive)\n- `haiku` - Claude Haiku (fast, cost-effective)\n\n**Model selection guide:**\n\n| Model | Best For | Speed | Cost | Capability |\n|-------|----------|-------|------|------------|\n| inherit | Most cases | Variable | Variable | Consistent |\n| haiku | Fast analysis, data processing, logs | ⭐⭐⭐ | ⭐ | ⭐⭐ |\n| sonnet | Coding tasks, general purpose | ⭐⭐ | ⭐⭐ | ⭐⭐⭐ |\n| opus | Complex reasoning, novel problems | ⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐ |\n\n**Examples:**\n```yaml\n# Default - matches parent\nmodel: inherit\n\n# Fast analysis agent\nmodel: haiku\n\n# Balanced coding agent\nmodel: sonnet\n\n# Complex reasoning\nmodel: opus\n```\n\n### color (Required)\n\n**Purpose:** Visual identifier for the agent in UI\n\n**Format:**\n```yaml\ncolor: blue\n```\n\n**Valid values:** `blue`, `cyan`, `green`, `yellow`, `magenta`, `red`\n\n**Color selection guide:**\n\n| Color | Use For | Example |\n|-------|---------|---------|\n| blue | Analysis, review, investigation | code-reviewer, analyzer |\n| cyan | Research, exploration, discovery | researcher, explorer |\n| green | Success, generation, creation | generator, builder |\n| yellow | Caution, validation, checking | validator, checker |\n| magenta | Creative, synthesis, design | designer, architect |\n| red | Critical, security, errors | security-checker, fixer |\n\n**Examples:**\n```yaml\ncolor: blue        # code review agent\ncolor: green       # code generator\ncolor: yellow      # validator\ncolor: red         # security agent\n```\n\n### tools (Optional)\n\n**Purpose:** Restrict agent to specific tools\n\n**Format:**\n```yaml\ntools: [\"Read\", \"Write\", \"Bash\"]\n```\n\n**Valid values:**\n- `Read` - Read files\n- `Write` - Create new files\n- `Edit` - Modify existing files\n- `Grep` - Search file contents\n- `Glob` - Find files by pattern\n- `Bash` - Execute shell commands\n- `AskUserQuestion` - Ask user for input\n- `TodoWrite` - Manage task lists\n- `*` - All tools\n\n**Default:** If omitted, agent inherits all parent tools\n\n**Common tool sets:**\n\n```yaml\n# Read-only analysis\ntools: [\"Read\", \"Grep\", \"Glob\"]\n\n# Code generation\ntools: [\"Read\", \"Write\", \"Bash\", \"Grep\"]\n\n# Code modification\ntools: [\"Read\", \"Edit\", \"Bash\", \"Grep\"]\n\n# Database queries\ntools: [\"Read\", \"Bash\"]\n\n# Documentation generation\ntools: [\"Read\", \"Write\"]\n```\n\n**Guidelines:**\n- Include only tools needed for the task\n- Use principle of least privilege\n- Exclude tools that aren't needed\n- Review for safety implications\n\n**Examples:**\n```yaml\n# Reviewer - read-only\ntools: [\"Read\", \"Grep\", \"Glob\"]\n\n# Generator - creates new files\ntools: [\"Read\", \"Write\", \"Bash\"]\n\n# Fixer - modifies existing code\ntools: [\"Read\", \"Edit\", \"Bash\"]\n\n# Analyzer - processes data\ntools: [\"Read\", \"Bash\", \"Grep\"]\n```\n\n### permissionMode (Optional)\n\n**Purpose:** Control how agent handles permissions\n\n**Format:**\n```yaml\npermissionMode: acceptEdits\n```\n\n**Valid values:**\n- `default` - Standard permission checking with prompts (default)\n- `acceptEdits` - Auto-accept file edits\n- `dontAsk` - Auto-deny operations not explicitly allowed\n- `bypassPermissions` - Skip all permission checks (use with caution)\n- `plan` - Read-only exploration mode\n\n**Default:** `default` if omitted\n\n**When to use each:**\n\n| Mode | Use When |\n|------|----------|\n| default | Testing agent, want user approval |\n| acceptEdits | Trusted agent that should auto-fix |\n| dontAsk | Background automation, pre-approved |\n| bypassPermissions | ⚠️ Carefully controlled scenarios only |\n| plan | Research/exploration without modification |\n\n**Examples:**\n```yaml\n# Standard - ask user\npermissionMode: default\n\n# Auto-accept edits\npermissionMode: acceptEdits\n\n# Auto-deny unpermitted\npermissionMode: dontAsk\n\n# Read-only mode\npermissionMode: plan\n```\n\n**⚠️ Warning:** `bypassPermissions` skips all permission checks. Use only in carefully controlled scenarios.\n\n### skills (Optional)\n\n**Purpose:** Preload skill content into agent context\n\n**Format:**\n```yaml\nskills:\n  - skill-name-1\n  - skill-name-2\n```\n\n**When to use:**\n- Agent needs domain-specific knowledge\n- Want knowledge available without runtime loading\n- Multiple related skills provide context\n\n**Default:** If omitted, no skills preloaded\n\n**Examples:**\n```yaml\n# API developer with conventions and patterns\nskills:\n  - api-conventions\n  - error-handling-patterns\n  - typescript-standards\n\n# Database agent with schema knowledge\nskills:\n  - database-schema\n  - query-optimization\n\n# Test generator with testing patterns\nskills:\n  - testing-patterns\n  - assertion-examples\n```\n\n**Effect:** Full skill content is injected into agent's context window at startup.\n\n### hooks (Optional)\n\n**Purpose:** Define lifecycle hooks for the agent\n\n**Format:**\n```yaml\nhooks:\n  PreToolUse:\n    - matcher: \"Bash\"\n      hooks:\n        - type: command\n          command: \"./scripts/validate.sh\"\n```\n\n**Hook events:**\n- `PreToolUse` - Before tool execution\n- `PostToolUse` - After tool execution\n- `Stop` - When agent finishes\n\n**When to use:**\n- Validate tool input before execution\n- Process output after execution\n- Cleanup when agent stops\n- Conditional validation\n\n**Example - Validate database queries:**\n```yaml\nhooks:\n  PreToolUse:\n    - matcher: \"Bash\"\n      hooks:\n        - type: command\n          command: \"./scripts/validate-readonly-query.sh\"\n```\n\nThe hook script receives the tool input as JSON and can approve (exit 0) or block (exit 2) execution.\n\nSee the Subagent Design Patterns skill for detailed hook patterns.\n\n## Complete Frontmatter Examples\n\n### Minimal Required\n\n```yaml\n---\nname: simple-agent\ndescription: Use when... Examples: <example>...</example>\nmodel: inherit\ncolor: blue\n---\n```\n\n### Standard with Tools\n\n```yaml\n---\nname: code-reviewer\ndescription: Use when reviewing code. Examples: <example>...</example>\nmodel: sonnet\ncolor: blue\ntools: [\"Read\", \"Grep\", \"Glob\"]\npermissionMode: default\n---\n```\n\n### Complete with All Options\n\n```yaml\n---\nname: api-developer\ndescription: Use when implementing APIs. Examples: <example>...</example>\nmodel: sonnet\ncolor: green\ntools: [\"Read\", \"Write\", \"Edit\", \"Bash\", \"Grep\"]\npermissionMode: acceptEdits\nskills:\n  - api-conventions\n  - error-handling\nhooks:\n  PreToolUse:\n    - matcher: \"Bash\"\n      hooks:\n        - type: command\n          command: \"./scripts/lint.sh\"\n---\n```\n\n## Field Validation Checklist\n\nBefore finalizing frontmatter:\n\n```\nname:\n  ☐ 3-50 characters\n  ☐ Lowercase letters, numbers, hyphens only\n  ☐ Starts with alphanumeric\n  ☐ Ends with alphanumeric\n  ☐ No spaces or underscores\n\ndescription:\n  ☐ Includes triggering conditions\n  ☐ Includes 2-4 <example> blocks\n  ☐ Each example has: Context, user, assistant, commentary\n  ☐ Specific, not generic\n  ☐ 100-1000 characters recommended\n\nmodel:\n  ☐ One of: inherit, sonnet, opus, haiku\n  ☐ Appropriate for agent's task\n\ncolor:\n  ☐ One of: blue, cyan, green, yellow, magenta, red\n  ☐ Visually distinct from other agents\n\ntools (if specified):\n  ☐ Only necessary tools included\n  ☐ Consistent with agent role\n  ☐ Security reviewed\n\npermissionMode (if specified):\n  ☐ Appropriate for use case\n  ☐ bypassPermissions only if justified\n\nskills (if specified):\n  ☐ All listed skills exist\n  ☐ Relevant to agent task\n\nhooks (if specified):\n  ☐ Valid event types\n  ☐ Script paths exist\n  ☐ Proper JSON format\n```\n"
      },
      "plugins": [
        {
          "name": "marketplace-manager",
          "source": "./plugins/marketplace-manager",
          "description": "Create, validate, and manage plugins in Claude Code plugin marketplaces. Includes scaffolding, validation, and documentation generation.",
          "version": "1.0.0",
          "author": {
            "name": "Anthropic",
            "email": "plugins@anthropic.com"
          },
          "category": "development",
          "keywords": [
            "marketplace",
            "plugin-management",
            "scaffolding",
            "validation",
            "development-tools"
          ],
          "repository": "https://github.com/anthropics/marketplace-manager",
          "categories": [
            "development",
            "development-tools",
            "marketplace",
            "plugin-management",
            "scaffolding",
            "validation"
          ],
          "install_commands": [
            "/plugin marketplace add v1truv1us/plugin-marketplace",
            "/plugin install marketplace-manager@code-plugin-marketplace"
          ]
        },
        {
          "name": "day-week-planner",
          "source": "./plugins/planner",
          "description": "Interactive day and week planning with Eisenhower matrix prioritization, time-blocking, and Jira/GitHub integration.",
          "version": "1.0.0",
          "author": {
            "name": "Planning Team",
            "email": "support@example.com"
          },
          "category": "productivity",
          "keywords": [
            "planning",
            "productivity",
            "scheduling",
            "eisenhower-matrix",
            "jira",
            "github",
            "time-blocking"
          ],
          "repository": "https://github.com/yourusername/day-week-planner",
          "categories": [
            "eisenhower-matrix",
            "github",
            "jira",
            "planning",
            "productivity",
            "scheduling",
            "time-blocking"
          ],
          "install_commands": [
            "/plugin marketplace add v1truv1us/plugin-marketplace",
            "/plugin install day-week-planner@code-plugin-marketplace"
          ]
        },
        {
          "name": "prompt-orchestrator",
          "source": "./plugins/prompt-orchestrator",
          "description": "Two-tier prompt orchestration: Haiku for discovery/refinement, Sonnet/Opus for execution. Uncovers real problems through Socratic questioning, refines context, and optimizes prompts before expensive model execution. Saves 60-80% on clarification costs.",
          "version": "2.0.0",
          "author": {
            "name": "Engineering Team",
            "email": "team@example.com"
          },
          "category": "development",
          "keywords": [
            "prompt-orchestration",
            "cost-optimization",
            "model-selection",
            "quality-assessment"
          ],
          "repository": "https://github.com/anthropics/prompt-orchestrator",
          "categories": [
            "cost-optimization",
            "development",
            "model-selection",
            "prompt-orchestration",
            "quality-assessment"
          ],
          "install_commands": [
            "/plugin marketplace add v1truv1us/plugin-marketplace",
            "/plugin install prompt-orchestrator@code-plugin-marketplace"
          ]
        },
        {
          "name": "subagent-creator",
          "source": "./plugins/subagent-creator",
          "description": "Interactive plugin for creating, designing, and implementing custom subagents in Claude Code with guided best practices",
          "version": "0.1.0",
          "author": {
            "name": "Claude Code Community",
            "email": "support@anthropic.com"
          },
          "category": "development",
          "keywords": [
            "subagents",
            "agent-creation",
            "agent-design",
            "workflow-automation"
          ],
          "repository": "https://github.com/anthropics/claude-code",
          "categories": [
            "agent-creation",
            "agent-design",
            "development",
            "subagents",
            "workflow-automation"
          ],
          "install_commands": [
            "/plugin marketplace add v1truv1us/plugin-marketplace",
            "/plugin install subagent-creator@code-plugin-marketplace"
          ]
        },
        {
          "name": "plugin-improver",
          "source": "./plugins/plugin-improver",
          "description": "Iteratively evaluate and enhance plugins with Anthropic best practices. Analyzes quality, suggests concrete improvements, and integrates with Ralph Loop for continuous self-improvement.",
          "version": "0.1.0",
          "author": {
            "name": "Plugin Development Team",
            "email": "support@example.com"
          },
          "category": "development",
          "keywords": [
            "plugin-improvement",
            "quality-assessment",
            "best-practices",
            "prompt-optimization",
            "iterative-enhancement",
            "continuous-improvement"
          ],
          "repository": "https://github.com/anthropics/claude-code-plugins",
          "categories": [
            "best-practices",
            "continuous-improvement",
            "development",
            "iterative-enhancement",
            "plugin-improvement",
            "prompt-optimization",
            "quality-assessment"
          ],
          "install_commands": [
            "/plugin marketplace add v1truv1us/plugin-marketplace",
            "/plugin install plugin-improver@code-plugin-marketplace"
          ]
        }
      ]
    }
  ]
}