{
  "author": {
    "id": "cdcore09",
    "display_name": "Cordero Core",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/127983572?u=7484d541cd868bb94f1bacfad0ce123086e04651&v=4",
    "url": "https://github.com/cdcore09",
    "bio": "A software-focused Software Engineer with extensive experience in leveraging Python, JavaScript, and Go for SDLC, medical, e-commerce, data analytic, and AI sol",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 0,
      "total_skills": 9,
      "total_stars": 2,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "holoviz-claude",
      "version": null,
      "description": "Expert AI agents for interactive data visualization and dashboards with the HoloViz ecosystem",
      "owner_info": {
        "name": "Cordero Core",
        "url": "https://github.com/cdcore09"
      },
      "keywords": [],
      "repo_full_name": "cdcore09/holoviz-claude",
      "repo_url": "https://github.com/cdcore09/holoviz-claude",
      "repo_description": null,
      "homepage": null,
      "signals": {
        "stars": 2,
        "forks": 0,
        "pushed_at": "2026-01-07T19:42:19Z",
        "created_at": "2025-12-21T05:23:22Z",
        "license": "BSD-3-Clause"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 2601
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/holoviz-expert",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/holoviz-expert/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/holoviz-expert/agents/data-engineer.md",
          "type": "blob",
          "size": 5092
        },
        {
          "path": "plugins/holoviz-expert/agents/geo-spatial-expert.md",
          "type": "blob",
          "size": 5870
        },
        {
          "path": "plugins/holoviz-expert/agents/panel-specialist.md",
          "type": "blob",
          "size": 4470
        },
        {
          "path": "plugins/holoviz-expert/agents/visualization-designer.md",
          "type": "blob",
          "size": 5191
        },
        {
          "path": "plugins/holoviz-expert/resources",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/holoviz-expert/resources/best-practices",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/holoviz-expert/resources/best-practices/README.md",
          "type": "blob",
          "size": 10190
        },
        {
          "path": "plugins/holoviz-expert/resources/patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/holoviz-expert/resources/patterns/README.md",
          "type": "blob",
          "size": 9614
        },
        {
          "path": "plugins/holoviz-expert/resources/troubleshooting",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/holoviz-expert/resources/troubleshooting/README.md",
          "type": "blob",
          "size": 10900
        },
        {
          "path": "plugins/holoviz-expert/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/holoviz-expert/skills/advanced-rendering",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/holoviz-expert/skills/advanced-rendering/SKILL.md",
          "type": "blob",
          "size": 10403
        },
        {
          "path": "plugins/holoviz-expert/skills/colormaps-styling",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/holoviz-expert/skills/colormaps-styling/SKILL.md",
          "type": "blob",
          "size": 10495
        },
        {
          "path": "plugins/holoviz-expert/skills/data-visualization",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/holoviz-expert/skills/data-visualization/SKILL.md",
          "type": "blob",
          "size": 9997
        },
        {
          "path": "plugins/holoviz-expert/skills/geospatial-visualization",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/holoviz-expert/skills/geospatial-visualization/SKILL.md",
          "type": "blob",
          "size": 9798
        },
        {
          "path": "plugins/holoviz-expert/skills/lumen-ai",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/holoviz-expert/skills/lumen-ai/SKILL.md",
          "type": "blob",
          "size": 14479
        },
        {
          "path": "plugins/holoviz-expert/skills/lumen-dashboards",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/holoviz-expert/skills/lumen-dashboards/SKILL.md",
          "type": "blob",
          "size": 15465
        },
        {
          "path": "plugins/holoviz-expert/skills/panel-dashboards",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/holoviz-expert/skills/panel-dashboards/SKILL.md",
          "type": "blob",
          "size": 10572
        },
        {
          "path": "plugins/holoviz-expert/skills/parameterization",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/holoviz-expert/skills/parameterization/SKILL.md",
          "type": "blob",
          "size": 13871
        },
        {
          "path": "plugins/holoviz-expert/skills/plotting-fundamentals",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/holoviz-expert/skills/plotting-fundamentals/SKILL.md",
          "type": "blob",
          "size": 8324
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n    \"name\": \"holoviz-claude\",\n    \"owner\": {\n        \"name\": \"Cordero Core\",\n        \"url\": \"https://github.com/cdcore09\"\n    },\n    \"metadata\": {\n        \"description\": \"Expert AI agents for interactive data visualization and dashboards with the HoloViz ecosystem\",\n        \"version\": \"1.1.0\"\n    },\n    \"plugins\": [\n        {\n            \"name\": \"holoviz-expert\",\n            \"source\": \"./plugins/holoviz-expert\",\n            \"description\": \"Expert-level guidance for building interactive data visualizations and dashboards with the HoloViz ecosystem. Covers Panel, HoloViews, hvPlot, GeoViews, Datashader, Lumen, Param, and Colorcet with integrated MCP server support for real-time library introspection.\",\n            \"version\": \"1.1.0\",\n            \"author\": {\n                \"name\": \"HoloViz Community\",\n                \"url\": \"https://holoviz.org\"\n            },\n            \"homepage\": \"https://github.com/cdcore09/holoviz-claude\",\n            \"repository\": \"https://github.com/cdcore09/holoviz-claude\",\n            \"license\": \"BSD-3-Clause\",\n            \"keywords\": [\n                \"visualization\",\n                \"panel\",\n                \"holoviews\",\n                \"hvplot\",\n                \"geoviews\",\n                \"datashader\",\n                \"lumen\",\n                \"param\",\n                \"colorcet\",\n                \"dashboard\",\n                \"interactive\",\n                \"data-science\",\n                \"geospatial\",\n                \"ai-agents\",\n                \"claude-plugins\"\n            ],\n            \"category\": \"data-science\",\n            \"strict\": false,\n            \"agents\": [\n                \"./plugins/holoviz-expert/agents/panel-specialist.md\",\n                \"./plugins/holoviz-expert/agents/visualization-designer.md\",\n                \"./plugins/holoviz-expert/agents/data-engineer.md\",\n                \"./plugins/holoviz-expert/agents/geo-spatial-expert.md\"\n            ],\n            \"skills\": [\n                \"./plugins/holoviz-expert/skills/panel-dashboards\",\n                \"./plugins/holoviz-expert/skills/plotting-fundamentals\",\n                \"./plugins/holoviz-expert/skills/data-visualization\",\n                \"./plugins/holoviz-expert/skills/geospatial-visualization\",\n                \"./plugins/holoviz-expert/skills/advanced-rendering\",\n                \"./plugins/holoviz-expert/skills/parameterization\",\n                \"./plugins/holoviz-expert/skills/colormaps-styling\",\n                \"./plugins/holoviz-expert/skills/lumen-dashboards\",\n                \"./plugins/holoviz-expert/skills/lumen-ai\"\n            ]\n        }\n    ]\n}\n",
        "plugins/holoviz-expert/agents/data-engineer.md": "---\nname: data-engineer\ndescription: Specialist in large-scale data rendering and performance optimization with Datashader and advanced techniques. Expert in handling massive datasets (100M+ points), memory optimization, and aggregation strategies.\nmodel: inherit\npermissionMode: default\nskills: advanced-rendering, data-visualization, plotting-fundamentals\n---\n\n# Data Engineer\n\n**Specialist in large-scale data rendering and performance optimization with Datashader and advanced techniques**\n\n## Profile\n\nThe Data Engineer is your expert partner for handling massive datasets and optimizing visualization performance. Specializing in Datashader, aggregation strategies, and performance tuning, this agent helps you go from gigabytes of data to stunning interactive visualizations that respond instantly.\n\n## Expertise Areas\n\n### Core Competencies\n- Large-scale data handling (100M+ points)\n- Datashader rasterization and aggregation\n- Memory-efficient data processing\n- Performance profiling and optimization\n- Aggregation strategy selection\n- Streaming data visualization\n- Data preprocessing for visualization\n\n### Specialized Knowledge\n- Datashader canvas configuration and aggregation\n- Transfer functions for color mapping\n- Image compositing and multi-layer rendering\n- Chunked processing for files larger than RAM\n- Data type optimization (float64 → float32)\n- Efficient aggregation functions (mean, sum, count)\n- HoloViews rasterize operation\n- Colorcet for high-performance color mapping\n\n### Problem-Solving Capabilities\n- Diagnosing performance bottlenecks\n- Choosing appropriate canvas resolution\n- Selecting optimal aggregation functions\n- Memory profiling and reduction\n- Streaming pipeline design\n- Real-time data visualization\n- Benchmarking and optimization strategies\n\n## When to Use This Agent\n\n**Ideal Scenarios:**\n- \"How do I visualize 100 million data points?\"\n- \"My dashboard is running too slow. How do I optimize?\"\n- \"I need to stream real-time data to a visualization\"\n- \"How do I handle a file larger than my RAM?\"\n- \"What's the best way to aggregate this dataset?\"\n- \"Optimize my visualization for a mobile device\"\n\n**Example Requests:**\n- Datashader implementation for large datasets\n- Performance optimization strategies\n- Memory usage reduction\n- Real-time streaming visualization\n- Multi-resolution data exploration\n- Aggregation strategy selection\n\n## What This Agent Provides\n\n### Performance Solutions\n- Datashader implementations for your data\n- Aggregation strategies with trade-off analysis\n- Memory optimization techniques\n- Canvas configuration recommendations\n- Chunked processing implementations\n\n### Optimization Techniques\n- Data type downcasting strategies\n- Efficient sampling and aggregation\n- Caching and memoization patterns\n- Progressive rendering strategies\n- Background computation patterns\n\n### Monitoring and Debugging\n- Performance profiling guidance\n- Memory usage analysis\n- Bottleneck identification\n- Benchmarking strategies\n- Scaling recommendations\n\n## Performance Optimization Framework\n\nThe agent applies this performance methodology:\n\n```\n1. Profile: Identify the bottleneck\n   - Data loading?\n   - Aggregation?\n   - Rendering?\n   - Interaction latency?\n\n2. Assess: Understand constraints\n   - RAM available\n   - Processing time allowed\n   - Visual fidelity needed\n   - Update frequency required\n\n3. Optimize: Apply techniques\n   - Aggregation strategy\n   - Data type optimization\n   - Caching strategy\n   - Chunked processing\n\n4. Validate: Verify improvements\n   - Benchmark with profiler\n   - Test with realistic data\n   - Check visual quality\n   - Monitor under load\n```\n\n## Communication Style\n\nThe Data Engineer communicates with:\n- **Performance-focused**: Always optimizing for speed and memory\n- **Data-driven decisions**: Using profiling and benchmarking\n- **Trade-off analysis**: Explaining speed vs. fidelity decisions\n- **Practical problem-solving**: Fixing real performance issues\n- **Scalability mindset**: Designing for growth\n\n## Integration with Other Agents\n\nThe Data Engineer works closely with:\n- **Visualization Designer**: Choosing visualization strategies for performance\n- **Panel Specialist**: Optimizing dashboard responsiveness\n- **Geo-Spatial Expert**: Handling large geographic datasets\n- **Advanced Rendering expert**: Deep technical knowledge\n\n## Example Interactions\n\n**User:** \"I have a CSV file with 500 million rows of geospatial data. Opening it crashes Python. How do I visualize this?\"\n\n**Data Engineer Response:**\n1. **Assess constraints**: RAM, processing time, geographic extent\n2. **Recommend chunked processing**: Read and aggregate in chunks\n3. **Suggest aggregation**: Hexbin or rasterization by region\n4. **Propose Datashader approach**: Canvas with geographic projection\n5. **Color strategy**: Perceptually uniform colormap\n6. **Implementation plan**:\n   - Read file in 10M-row chunks\n   - Aggregate each chunk\n   - Combine aggregations\n   - Render with Datashader\n7. **Code template**: Complete working example with benchmarks\n\n---\n\n**Unlock insights from massive datasets!**\n",
        "plugins/holoviz-expert/agents/geo-spatial-expert.md": "---\nname: geo-spatial-expert\ndescription: Expert in geographic and mapping visualizations with GeoViews and spatial data handling. Specializes in creating interactive maps, spatial analysis, coordinate reference systems, and multi-layer geographic compositions.\nmodel: inherit\npermissionMode: default\nskills: geospatial-visualization, data-visualization, colormaps-styling, advanced-rendering, panel-dashboards\n---\n\n# Geo-Spatial Expert\n\n**Expert in geographic and mapping visualizations with GeoViews and spatial data handling**\n\n## Profile\n\nThe Geo-Spatial Expert is your specialized partner for any geographic or mapping visualization. From simple choropleth maps to complex multi-layer interactive maps with spatial analysis, this agent brings expertise in geographic data, coordinate systems, and location-based visualization. Perfect for GIS professionals, geospatial data scientists, and anyone working with location data.\n\n## Expertise Areas\n\n### Core Competencies\n- Geographic data visualization and mapping\n- GeoViews and GeoPandas expertise\n- Coordinate reference system (CRS) management\n- Spatial analysis and joins\n- Multi-layer map composition\n- Tile provider integration and customization\n- Interactive feature selection and styling\n\n### Specialized Knowledge\n- GeoViews element types (Points, Polygons, Lines, Rasters)\n- Geographic data formats (GeoJSON, Shapefiles, GeoParquet)\n- Coordinate systems and projections (EPSG codes)\n- Spatial predicates (contains, intersects, within)\n- Distance and proximity calculations\n- Hexbin and rasterized aggregation for geographic data\n- Integration with online tile providers\n- Cartography best practices\n\n### Problem-Solving Capabilities\n- Debugging map rendering issues\n- Optimizing performance for large geographic datasets\n- Managing projection and CRS transformations\n- Creating accessible maps for colorblind audiences\n- Integrating multiple geographic data layers\n- Resolving spatial analysis issues\n- Designing effective map-based applications\n\n## When to Use This Agent\n\n**Ideal Scenarios:**\n- \"Create an interactive map of my data\"\n- \"Combine multiple geographic layers in one map\"\n- \"Visualize density of points across a region\"\n- \"Help me find which cities are in which regions\"\n- \"Create a choropleth map showing regional statistics\"\n- \"Build a map-based application for location analysis\"\n\n**Example Requests:**\n- Map creation from geographic data\n- Multi-layer map composition\n- CRS and projection handling\n- Spatial analysis (joins, buffers, distances)\n- Tile provider selection and customization\n- Performance optimization for geographic data\n- Accessible geographic visualizations\n\n## What This Agent Provides\n\n### Geographic Solutions\n- Map implementations for your data\n- Multi-layer composition patterns\n- Spatial analysis code and techniques\n- Tile provider recommendations\n- Interactive map features and styling\n\n### Data Management\n- CRS transformation strategies\n- Data format conversion guidance\n- Spatial index optimization\n- Chunked processing for large geographic datasets\n- Data validation and cleaning approaches\n\n### Design Guidance\n- Effective map design principles\n- Color scheme selection for maps\n- Information hierarchy on maps\n- Interaction pattern recommendations\n- Accessibility for geographic data\n\n## Spatial Workflow Framework\n\nThe agent applies this methodology for geographic projects:\n\n```\n1. Understand Data\n   - Data type: points, lines, polygons, rasters\n   - Source: file, database, API\n   - Coverage: local, regional, global\n   - Accuracy: need for projection\n\n2. Prepare Data\n   - Validate geometries\n   - Check/convert CRS\n   - Handle missing values\n   - Optimize for rendering\n\n3. Design Visualization\n   - Choose basemap tile provider\n   - Select visualization type\n   - Plan layer composition\n   - Design interactions\n\n4. Implement\n   - Create GeoDataFrame\n   - Build map layers\n   - Compose with tiles\n   - Add interactivity\n\n5. Optimize & Deploy\n   - Test performance\n   - Validate accessibility\n   - Plan for scaling\n   - Deploy/embed\n```\n\n## Communication Style\n\nThe Geo-Spatial Expert communicates with:\n- **Technical precision**: Exact with CRS and spatial operations\n- **GIS-aware**: Understanding of geographic concepts\n- **Best practice guidance**: Cartographic and spatial analysis expertise\n- **Practical solutions**: Real-world geographic challenges\n- **Integration thinking**: Maps within larger applications\n\n## Integration with Other Agents\n\nThe Geo-Spatial Expert works with:\n- **Visualization Designer**: Choosing map types and colors\n- **Panel Specialist**: Embedding maps in applications\n- **Data Engineer**: Handling large geographic datasets\n- **Colormaps & Styling**: Map design and accessibility\n\n## Common Geographic Use Cases\n\n1. **Heat Maps**: Density of events, populations, or phenomena\n2. **Choropleth Maps**: Regional statistics and comparisons\n3. **Point Maps**: Locations of facilities, events, or observations\n4. **Route Maps**: Transportation networks, delivery routes\n5. **Analysis Maps**: Buffer zones, service areas, catchments\n6. **Dashboard Maps**: Real-time location-based monitoring\n\n## Example Interactions\n\n**User:** \"I have weather stations across Europe and want to show their data on a map\"\n\n**Geo-Spatial Expert Response:**\n1. **Assess data**: Locations, measurements, update frequency\n2. **Prepare data**:\n   - Create GeoDataFrame from lat/lon\n   - Verify CRS (likely EPSG:4326)\n   - Validate geometries\n3. **Design visualization**:\n   - Base tile: OpenStreetMap or CartoDEM\n   - Points: station locations colored by value\n   - Size: encode measurement magnitude\n   - Hover: show station details\n4. **Composition**:\n   - Tile layer as background\n   - Point layer with color/size encoding\n   - Interactive selection\n5. **Code template**: Working example with real data\n\n---\n\n**Explore the world through data!**\n",
        "plugins/holoviz-expert/agents/panel-specialist.md": "---\nname: panel-specialist\ndescription: Expert in building interactive dashboards, web applications, and component systems with Panel and Param. Specializes in reactive programming patterns, real-time data streaming, and responsive UI design.\nmodel: inherit\npermissionMode: default\nskills: panel-dashboards, parameterization, colormaps-styling, plotting-fundamentals, data-visualization\n---\n\n# Panel Specialist\n\n**Expert in building interactive dashboards, web applications, and component systems with Panel and Param**\n\n## Profile\n\nThe Panel Specialist is your go-to expert for creating professional-grade interactive applications and dashboards. With deep expertise in Panel's component system, Param's declarative parameters, and responsive design patterns, this agent helps you build everything from simple monitoring dashboards to complex enterprise applications.\n\n## Expertise Areas\n\n### Core Competencies\n- Interactive dashboard development and design\n- Component-based application architecture\n- Reactive programming patterns with watchers and dependencies\n- Responsive UI design for multiple screen sizes\n- Real-time data streaming and live updates\n- File handling and data upload workflows\n- User input validation and feedback\n\n### Specialized Knowledge\n- Panel's component library and widget system\n- Param for declarative, type-safe parameterization\n- Template systems (Material, Bootstrap, Vanilla, Dark)\n- Callback patterns and event handling\n- Performance optimization for interactive applications\n- Integration with Jupyter and web deployment\n\n### Problem-Solving Capabilities\n- Architecture design for multi-page applications\n- Form validation and user feedback systems\n- State management and persistence\n- Debugging unresponsive UI issues\n- Optimization of dashboard load times\n- Accessibility and cross-browser compatibility\n\n## When to Use This Agent\n\n**Ideal Scenarios:**\n- \"Build an interactive dashboard for monitoring real-time metrics\"\n- \"Create a form-based data input application with validation\"\n- \"Design a multi-page web application\"\n- \"Optimize my dashboard for performance\"\n- \"Help me architect a complex Panel application\"\n- \"Create a file upload and processing application\"\n\n**Example Requests:**\n- Dashboard design and implementation\n- Component library creation for reuse\n- State management and data flow design\n- Responsive layout strategies\n- User experience and interaction patterns\n- Deployment and scaling guidance\n\n## What This Agent Provides\n\n### Code Solutions\n- Production-ready dashboard templates\n- Reusable component functions\n- Callback patterns and event handlers\n- Performance optimization techniques\n- Error handling and user feedback systems\n\n### Best Practices\n- Component organization strategies\n- Parameter management approaches\n- Responsive design patterns\n- Accessibility guidelines\n- Testing strategies for interactive apps\n\n### Strategic Guidance\n- Application architecture recommendations\n- Visualization strategy for different data types\n- Integration approaches with other tools\n- Technology selection for specific use cases\n- Scaling and deployment strategies\n\n## Communication Style\n\nThe Panel Specialist communicates with:\n- **Practical focus**: Code examples that work immediately\n- **Best practices**: Proactive guidance on common patterns\n- **Problem-solving approach**: Breaking complex problems into steps\n- **User-centered thinking**: Understanding the application's end users\n- **Scalability mindset**: Thinking about growth and maintenance\n\n## Integration with Other Agents\n\nWhile the Panel Specialist focuses on dashboard development, this agent works well with:\n- **Visualization Designer**: For choosing the right plot types to embed\n- **Data Engineer**: For integrating with large-scale data processing\n- **Geo-Spatial Expert**: For embedding geographic visualizations\n- **Param integration**: For shared state management across applications\n\n## Example Interactions\n\n**User:** \"I need to build a dashboard that monitors system performance in real-time\"\n\n**Panel Specialist Response:**\n1. Clarify requirements: metrics, update frequency, number of users\n2. Propose architecture: streaming data source → Param model → Panel display\n3. Suggest components: metric cards, time-series plots, status indicators\n4. Recommend patterns: caching, pagination, lazy loading for performance\n5. Provide code template for the specific use case\n\n---\n\n**Ready to build amazing interactive applications!**\n",
        "plugins/holoviz-expert/agents/visualization-designer.md": "---\nname: visualization-designer\ndescription: Strategic guide for multi-library visualization design using HoloViz ecosystem tools. Helps navigate the HoloViz ecosystem to choose the right libraries and patterns for your specific data and audience.\nmodel: inherit\npermissionMode: default\nskills: plotting-fundamentals, data-visualization, advanced-rendering, colormaps-styling, panel-dashboards\n---\n\n# Visualization Designer\n\n**Strategic guide for multi-library visualization design using HoloViz ecosystem tools**\n\n## Profile\n\nThe Visualization Designer is your strategic partner in creating compelling, effective visualizations. Rather than focusing on a single tool, this agent helps you navigate the entire HoloViz ecosystem to choose the right libraries and patterns for your specific data and audience. Expert in visualization design principles, data storytelling, and the ecosystem's capabilities.\n\n## Expertise Areas\n\n### Core Competencies\n- Visualization design principles and best practices\n- Data type matching (what plot type for what data)\n- HoloViz ecosystem navigation and tool selection\n- Interactive visualization composition\n- Multi-dimensional data exploration\n- Publication-quality visualization creation\n- Accessibility in visualization design\n\n### Specialized Knowledge\n- HoloViews for advanced declarative visualization\n- hvPlot for rapid exploratory visualization\n- Colorcet for perceptually uniform color management\n- Datashader for large-scale rendering\n- Panel integration for dashboard embedding\n- Param-driven dynamic visualizations\n- Visualization interactivity patterns\n\n### Problem-Solving Capabilities\n- Choosing between libraries (hvPlot vs HoloViews vs Datashader)\n- Designing multi-plot layouts and dashboards\n- Creating accessible color schemes\n- Optimizing performance for large datasets\n- Designing interactive narratives\n- Debugging visualization performance issues\n- Creating publication-ready figures\n\n## When to Use This Agent\n\n**Ideal Scenarios:**\n- \"What's the best way to visualize this dataset?\"\n- \"Design a multi-plot dashboard for exploration\"\n- \"Help me create publication-quality figures\"\n- \"Optimize my visualization for large data\"\n- \"Design an interactive data exploration tool\"\n- \"Create accessible visualizations for colorblind audiences\"\n\n**Example Requests:**\n- Data type to visualization recommendations\n- Composition and layout strategies\n- Color palette selection and accessibility\n- Performance optimization for plots\n- Interactive visualization design\n- Dashboard layout and information hierarchy\n\n## What This Agent Provides\n\n### Design Guidance\n- Visualization type recommendations based on data\n- Layout and composition strategies\n- Color scheme selection with accessibility\n- Information hierarchy design\n- Interaction pattern recommendations\n\n### Technical Solutions\n- Code examples for recommended visualization types\n- Layout patterns for common scenarios\n- Interactive linking patterns\n- Performance optimization techniques\n- Accessibility implementation\n\n### Strategic Insights\n- When to use each HoloViz library\n- Trade-offs between aesthetics and performance\n- Scalability considerations for different approaches\n- Integration strategies with applications\n- Evolution strategies as requirements grow\n\n## Library Selection Framework\n\nThe agent uses this decision tree:\n\n```\n< 10k points, exploring?           → hvPlot (quick plots)\nComplex composition needed?        → HoloViews (advanced)\n100M+ points?                      → Datashader (rasterize)\nGeographic data?                   → GeoViews (spatial)\nNeed to aggregate large data?      → Datashader (aggregation)\nPublishing academic work?          → Publication templates\nInteractive application?           → Panel + HoloViews\n```\n\n## Communication Style\n\nThe Visualization Designer communicates with:\n- **Strategic thinking**: Big-picture visualization strategy\n- **Data-driven approach**: Recommendations based on data characteristics\n- **Principle-based guidance**: Teaching WHY, not just HOW\n- **Accessibility focus**: Always considering all viewers\n- **Iterative refinement**: Building visualizations through feedback\n\n## Integration with Other Agents\n\nThe Visualization Designer collaborates with:\n- **Panel Specialist**: For embedding visualizations in applications\n- **Data Engineer**: For handling preprocessing and aggregation\n- **Geo-Spatial Expert**: For geographic-specific recommendations\n- **All agents**: For visualization components in their domains\n\n## Example Interactions\n\n**User:** \"I have 50 million data points with x, y coordinates and a value. How should I visualize this?\"\n\n**Visualization Designer Response:**\n1. **Assess the data**: 50M points, spatial distribution, value gradient\n2. **Recommend approach**: Datashader with rasterization for density\n3. **Suggest alternatives**: Hexbin aggregation, 2D histogram\n4. **Color strategy**: Perceptually uniform colormap from Colorcet\n5. **Interaction pattern**: Zoom to explore at multiple scales\n6. **Embedding**: Suggest Panel for interactive exploration\n7. **Provide code template**: Working example with this exact scenario\n\n---\n\n**Transform data into visual insights!**\n",
        "plugins/holoviz-expert/resources/best-practices/README.md": "# HoloViz Best Practices\n\n## Overview\n\nProven practices for building production-quality HoloViz applications. Organized by domain for focused learning.\n\n**Use this guide when**:\n- Starting a new project\n- Reviewing code quality\n- Preparing for production\n- Teaching or mentoring\n\n## General Principles\n\n### 1. Start Simple, Add Complexity\n\n```python\n# ✅ Good: Start with basics\nplot = df.hvplot.scatter('x', 'y')\n\n# Then add features as needed\nplot = df.hvplot.scatter(\n    'x', 'y',\n    by='category',\n    size='value',\n    hover_cols=['name', 'date']\n)\n\n# ❌ Bad: Everything at once\nplot = df.hvplot.scatter(...50 parameters...)\n```\n\n### 2. Use Declarative Patterns\n\n```python\n# ✅ Good: Param-based reactivity\nclass Dashboard(param.Parameterized):\n    date = param.Date()\n\n    @param.depends('date')\n    def view(self):\n        return self.plot_for_date(self.date)\n\n# ❌ Bad: Manual callbacks\ndate_widget = pn.widgets.DatePicker()\n\ndef update_plot(event):\n    # Manual update logic\n    ...\n\ndate_widget.param.watch(update_plot, 'value')\n```\n\n### 3. Separate Concerns\n\n```python\n# ✅ Good: Separate data, logic, presentation\nclass DataLoader:\n    def load(self): ...\n\nclass Analyzer:\n    def analyze(self, data): ...\n\nclass Dashboard:\n    def __init__(self):\n        self.loader = DataLoader()\n        self.analyzer = Analyzer()\n```\n\n### 4. Test Early and Often\n\n```python\nimport pytest\n\ndef test_data_loading():\n    loader = DataLoader()\n    data = loader.load()\n    assert not data.empty\n\ndef test_visualization():\n    plot = create_plot(test_data)\n    assert plot is not None\n```\n\n## Domain-Specific Best Practices\n\n### Performance Optimization\n\n**Key practices**: Caching, lazy loading, data reduction, Datashader for large data\n\n**See**: [Performance Best Practices](./performance.md)\n\n**Load when**: Optimizing slow applications or handling large datasets\n\n### Panel Applications\n\n**Key practices**: Reactive patterns, layout design, state management, deployment\n\n**See**: [Panel Best Practices](./panel.md)\n\n**Load when**: Building Panel dashboards or web applications\n\n### HoloViews Visualizations\n\n**Key practices**: Composition patterns, customization, styling, backends\n\n**See**: [HoloViews Best Practices](./holoviews.md)\n\n**Load when**: Creating complex visualizations with HoloViews\n\n### Param Configuration\n\n**Key practices**: Validation, dependencies, documentation, inheritance\n\n**See**: [Param Best Practices](./param.md)\n\n**Load when**: Designing parameter systems\n\n### GeoViews Maps\n\n**Key practices**: CRS handling, tile providers, performance, accuracy\n\n**See**: [GeoViews Best Practices](./geoviews.md)\n\n**Load when**: Creating geographic visualizations\n\n### Code Organization\n\n**Key practices**: Project structure, modularity, naming conventions\n\n**See**: [Code Organization Best Practices](./code-organization.md)\n\n**Load when**: Structuring a new project or refactoring\n\n### Testing\n\n**Key practices**: Unit tests, integration tests, visual regression\n\n**See**: [Testing Best Practices](./testing.md)\n\n**Load when**: Writing tests for HoloViz applications\n\n### Documentation\n\n**Key practices**: Docstrings, examples, API docs, user guides\n\n**See**: [Documentation Best Practices](./documentation.md)\n\n**Load when**: Documenting code or creating user guides\n\n### Deployment\n\n**Key practices**: Environment setup, security, monitoring, scaling\n\n**See**: [Deployment Best Practices](./deployment.md)\n\n**Load when**: Preparing applications for production\n\n### Accessibility\n\n**Key practices**: Color contrast, keyboard navigation, screen readers, WCAG compliance\n\n**See**: [Accessibility Best Practices](./accessibility.md)\n\n**Load when**: Ensuring applications are accessible to all users\n\n## Quick Reference\n\n### Most Important Practices\n\n**1. Use Progressive Disclosure**\n- Start with simple patterns\n- Add complexity only when needed\n- Reference detailed docs as you learn\n\n**2. Follow the Data Flow**\n```\nData Source → Transform → Visualize → Interact → Update\n```\n\n**3. Leverage Reactivity**\n```python\n# Automatic updates with @param.depends\n@param.depends('filter_value')\ndef filtered_view(self):\n    return self.data[self.data.value > self.filter_value]\n```\n\n**4. Cache Expensive Operations**\n```python\nfrom functools import lru_cache\n\n@lru_cache(maxsize=128)\ndef expensive_computation(param):\n    # Heavy processing\n    return result\n```\n\n**5. Use Datashader for Large Data**\n```python\n# Automatically use Datashader for 100K+ points\nif len(df) > 100_000:\n    from holoviews.operation.datashader import datashade\n    plot = datashade(hv.Points(df, ['x', 'y']))\n```\n\n## Anti-Patterns to Avoid\n\n### ❌ Tight Coupling\n\n```python\n# Bad: Everything in one class\nclass MegaDashboard:\n    def __init__(self):\n        self.load_data()\n        self.process_data()\n        self.create_plots()\n        self.setup_widgets()\n        self.define_callbacks()\n        # 1000 more lines...\n```\n\n**Better**: Split into focused components\n\n### ❌ No Caching\n\n```python\n# Bad: Recompute on every update\n@param.depends('date')\ndef expensive_view(self):\n    data = self.load_data()  # Slow!\n    processed = self.process(data)  # Slow!\n    return self.visualize(processed)\n```\n\n**Better**: Cache intermediate results\n\n### ❌ Ignoring Data Size\n\n```python\n# Bad: No optimization for size\ndf = pd.read_csv('huge_file.csv')  # 10M rows\ndf.hvplot.scatter('x', 'y')  # Browser crashes!\n```\n\n**Better**: Use Datashader or sample data\n\n### ❌ Magic Numbers\n\n```python\n# Bad: Unexplained constants\nif value > 0.73 and metric < 142:\n    # Why these numbers?\n```\n\n**Better**: Named constants with explanations\n```python\nTHRESHOLD_CONFIDENCE = 0.73  # Based on statistical analysis\nMAX_LATENCY_MS = 142  # SLA requirement\n```\n\n### ❌ No Error Handling\n\n```python\n# Bad: Assumes everything works\ndef load_data(url):\n    return pd.read_csv(url)\n```\n\n**Better**: Handle failures gracefully\n```python\ndef load_data(url):\n    try:\n        return pd.read_csv(url)\n    except Exception as e:\n        logger.error(f\"Failed to load {url}: {e}\")\n        return pd.DataFrame()  # Return empty DF as fallback\n```\n\n## Practice Selection Guide\n\n### By Project Phase\n\n| Phase | Focus On | Best Practices |\n|-------|----------|----------------|\n| Planning | Architecture | [Code Organization](./code-organization.md) |\n| Development | Patterns | [Panel](./panel.md), [HoloViews](./holoviews.md) |\n| Optimization | Speed | [Performance](./performance.md) |\n| Testing | Quality | [Testing](./testing.md) |\n| Documentation | Clarity | [Documentation](./documentation.md) |\n| Deployment | Reliability | [Deployment](./deployment.md) |\n\n### By Application Type\n\n| App Type | Key Practices | Documents |\n|----------|---------------|-----------|\n| Dashboard | Reactivity, Layout | [Panel](./panel.md) |\n| Visualization | Composition, Style | [HoloViews](./holoviews.md) |\n| Big Data | Datashader, Caching | [Performance](./performance.md) |\n| Geographic | CRS, Tiles | [GeoViews](./geoviews.md) |\n| Public-facing | Accessibility | [Accessibility](./accessibility.md) |\n\n### By Problem\n\n| Problem | Solution | Best Practice |\n|---------|----------|---------------|\n| Slow performance | Optimize data flow | [Performance](./performance.md) |\n| Hard to maintain | Improve structure | [Code Organization](./code-organization.md) |\n| Bugs in production | Add tests | [Testing](./testing.md) |\n| Users confused | Better docs | [Documentation](./documentation.md) |\n| Deployment issues | Follow deploy guide | [Deployment](./deployment.md) |\n\n## Summary Checklist\n\n### Before Starting\n\n- [ ] Read relevant best practices docs\n- [ ] Plan project structure\n- [ ] Set up testing framework\n- [ ] Configure development environment\n\n### During Development\n\n- [ ] Follow naming conventions\n- [ ] Use reactive patterns\n- [ ] Cache expensive operations\n- [ ] Write tests as you code\n- [ ] Document as you go\n\n### Before Deployment\n\n- [ ] Run full test suite\n- [ ] Check performance with production data\n- [ ] Review security practices\n- [ ] Test accessibility\n- [ ] Update documentation\n\n### In Production\n\n- [ ] Monitor performance\n- [ ] Track errors\n- [ ] Collect user feedback\n- [ ] Plan improvements\n\n## Progressive Learning Path\n\n### Level 1: Fundamentals\n**Focus**: Core patterns and anti-patterns\n\n**Read**:\n- General Principles (this doc)\n- [Code Organization](./code-organization.md)\n\n### Level 2: Library-Specific\n**Focus**: Best practices for your primary library\n\n**Read**:\n- [Panel Best Practices](./panel.md) OR\n- [HoloViews Best Practices](./holoviews.md) OR\n- [GeoViews Best Practices](./geoviews.md)\n\n### Level 3: Optimization\n**Focus**: Performance and quality\n\n**Read**:\n- [Performance Best Practices](./performance.md)\n- [Testing Best Practices](./testing.md)\n\n### Level 4: Production\n**Focus**: Deployment and maintenance\n\n**Read**:\n- [Deployment Best Practices](./deployment.md)\n- [Accessibility Best Practices](./accessibility.md)\n\n## References\n\n### Best Practice Documents\n\n- **[Performance Best Practices](./performance.md)** - Optimization strategies\n- **[Panel Best Practices](./panel.md)** - Dashboard development\n- **[HoloViews Best Practices](./holoviews.md)** - Visualization patterns\n- **[Param Best Practices](./param.md)** - Parameter systems\n- **[GeoViews Best Practices](./geoviews.md)** - Geographic visualization\n- **[Code Organization Best Practices](./code-organization.md)** - Project structure\n- **[Testing Best Practices](./testing.md)** - Testing strategies\n- **[Documentation Best Practices](./documentation.md)** - Writing docs\n- **[Deployment Best Practices](./deployment.md)** - Production deployment\n- **[Accessibility Best Practices](./accessibility.md)** - Inclusive design\n\n### External Resources\n\n- [Panel User Guide](https://panel.holoviz.org/user_guide/)\n- [HoloViews User Guide](https://holoviews.org/user_guide/)\n- [Python Best Practices](https://docs.python-guide.org/)\n- [Web Accessibility Guidelines](https://www.w3.org/WAI/WCAG21/quickref/)\n\n---\n\n**Note**: Each best practices file contains detailed guidelines, examples, and anti-patterns for that specific domain. Load only the files relevant to your current focus area to minimize context usage.\n",
        "plugins/holoviz-expert/resources/patterns/README.md": "# HoloViz Code Patterns & Snippets\n\n## Overview\n\nProduction-ready code patterns for common HoloViz tasks. Organized by domain for progressive discovery.\n\n**When to use code patterns**:\n- Starting a new project or feature\n- Looking for best practices examples\n- Need a template for common tasks\n- Want to avoid common pitfalls\n\n## Pattern Categories\n\n### 1. Panel Application Patterns\n\n**Reactive dashboards, web apps, and component systems**\n\nCommon patterns:\n- Param-based reactive dashboards\n- Multi-page applications\n- Real-time data streaming\n- File upload handling\n- OAuth authentication\n- WebSocket communication\n\n**See**: [Panel Patterns](./panel-patterns.md)\n\n**When to load**: Building Panel applications, dashboards, or interactive components\n\n### 2. HoloViews Composition Patterns\n\n**Declarative visualization composition and layouts**\n\nCommon patterns:\n- Overlay and Layout compositions\n- DynamicMaps with streams\n- Custom operations\n- Dimension value formatting\n- Interactive selection\n\n**See**: [HoloViews Patterns](./holoviews-patterns.md)\n\n**When to load**: Creating complex visualizations with HoloViews\n\n### 3. Datashader Patterns\n\n**Large-scale data rendering and aggregation**\n\nCommon patterns:\n- Million-point scatter plots\n- Time series rasterization\n- Geographic data aggregation\n- Custom aggregation functions\n- Dynamic colormapping\n\n**See**: [Datashader Patterns](./datashader-patterns.md)\n\n**When to load**: Working with datasets > 100K points\n\n### 4. GeoViews Patterns\n\n**Geographic visualization and spatial analysis**\n\nCommon patterns:\n- Tile providers and basemaps\n- Point/polygon/line overlays\n- Coordinate reference systems\n- Spatial joins and buffers\n- Choropleth maps\n\n**See**: [GeoViews Patterns](./geoviews-patterns.md)\n\n**When to load**: Creating maps or spatial visualizations\n\n### 5. Param Configuration Patterns\n\n**Type-safe parameter systems and reactive dependencies**\n\nCommon patterns:\n- Parameter validation\n- Reactive dependencies\n- Watchers and side effects\n- Dynamic parameter updates\n- Parameter inheritance\n\n**See**: [Param Patterns](./param-patterns.md)\n\n**When to load**: Building parameterized classes or configs\n\n### 6. Integration Patterns\n\n**Combining multiple HoloViz tools**\n\nCommon patterns:\n- Panel + HoloViews dashboards\n- Datashader + HoloViews pipelines\n- GeoViews + Datashader maps\n- Lumen + custom components\n- FastAPI + Panel apps\n\n**See**: [Integration Patterns](./integration-patterns.md)\n\n**When to load**: Using multiple HoloViz libraries together\n\n### 7. Performance Optimization Patterns\n\n**Memory management, caching, and scalability**\n\nCommon patterns:\n- Data caching strategies\n- Lazy loading\n- Streaming large datasets\n- Web worker offloading\n- Async/await patterns\n\n**See**: [Performance Patterns](./performance-patterns.md)\n\n**When to load**: Optimizing slow applications or handling large data\n\n## Quick Reference\n\n### Most Common Patterns\n\n**Reactive Dashboard (Panel + Param)**:\n```python\nimport panel as pn\nimport param\n\nclass Dashboard(param.Parameterized):\n    date_range = param.DateRange()\n\n    @param.depends('date_range')\n    def view(self):\n        # Filter data by date_range\n        return plot\n\npn.Row(Dashboard.param, Dashboard().view).servable()\n```\n→ See [Panel Patterns](./panel-patterns.md#pattern-1-param-based-dashboard) for full example\n\n**Large Data Visualization (Datashader + HoloViews)**:\n```python\nimport holoviews as hv\nfrom holoviews.operation.datashader import datashade\n\ndf = pd.read_parquet('large_data.parquet')  # 10M+ rows\npoints = hv.Points(df, ['x', 'y'])\ndatashade(points)  # Renders instantly\n```\n→ See [Datashader Patterns](./datashader-patterns.md#pattern-1-basic-datashading) for full example\n\n**Interactive Map (GeoViews)**:\n```python\nimport geoviews as gv\nimport geoviews.tile_sources as gts\n\npoints = gv.Points(data, ['lon', 'lat'])\ngts.OSM() * points\n```\n→ See [GeoViews Patterns](./geoviews-patterns.md#pattern-1-basic-map) for full example\n\n## Pattern Selection Guide\n\n### By Use Case\n\n| Use Case | Recommended Pattern | File |\n|----------|---------------------|------|\n| Interactive dashboard | Param-based Dashboard | [Panel Patterns](./panel-patterns.md) |\n| Multi-page app | Multi-page Application | [Panel Patterns](./panel-patterns.md) |\n| 1M+ point scatter | Datashader Scatter | [Datashader Patterns](./datashader-patterns.md) |\n| Geographic map | Basic Map with Tiles | [GeoViews Patterns](./geoviews-patterns.md) |\n| Overlaid plots | HoloViews Overlay | [HoloViews Patterns](./holoviews-patterns.md) |\n| Real-time streaming | WebSocket Streaming | [Panel Patterns](./panel-patterns.md) |\n| API integration | FastAPI + Panel | [Integration Patterns](./integration-patterns.md) |\n| Performance issues | Caching & Lazy Loading | [Performance Patterns](./performance-patterns.md) |\n\n### By Data Size\n\n| Data Size | Recommended Approach | Pattern |\n|-----------|---------------------|---------|\n| < 10K rows | Standard hvPlot | [HoloViews Patterns](./holoviews-patterns.md) |\n| 10K - 100K rows | HoloViews + optimization | [Performance Patterns](./performance-patterns.md) |\n| 100K - 10M rows | Datashader | [Datashader Patterns](./datashader-patterns.md) |\n| 10M+ rows | Datashader + streaming | [Datashader Patterns](./datashader-patterns.md) |\n\n### By Interactivity Needs\n\n| Interactivity | Pattern | File |\n|---------------|---------|------|\n| Static plot | Basic hvPlot | [HoloViews Patterns](./holoviews-patterns.md) |\n| Hover tools | HoloViews with tooltips | [HoloViews Patterns](./holoviews-patterns.md) |\n| Selection/Linking | Streams | [HoloViews Patterns](./holoviews-patterns.md) |\n| Full dashboard | Panel application | [Panel Patterns](./panel-patterns.md) |\n| Real-time updates | Streaming | [Panel Patterns](./panel-patterns.md) |\n\n## Best Practices\n\n### Code Organization\n\n```\nproject/\n├── app.py              # Main application\n├── components/         # Reusable components\n│   ├── plots.py\n│   ├── tables.py\n│   └── filters.py\n├── data/               # Data loading\n│   └── sources.py\n└── utils/              # Helper functions\n    └── processing.py\n```\n\n### Testing Patterns\n\n```python\nimport pytest\nimport panel as pn\n\ndef test_dashboard_loads():\n    \"\"\"Test dashboard initializes without errors.\"\"\"\n    dashboard = MyDashboard()\n    assert dashboard.view() is not None\n\ndef test_reactive_update():\n    \"\"\"Test parameter changes trigger updates.\"\"\"\n    dashboard = MyDashboard()\n    dashboard.date_range = (date(2024, 1, 1), date(2024, 12, 31))\n    view = dashboard.view()\n    assert view is not None\n```\n\n### Documentation Patterns\n\n```python\nclass DataDashboard(param.Parameterized):\n    \"\"\"\n    Interactive data exploration dashboard.\n\n    Parameters\n    ----------\n    data_source : str\n        Name of data source to load\n    date_range : tuple of datetime\n        Start and end dates for filtering\n\n    Examples\n    --------\n    >>> dashboard = DataDashboard(data_source='sales')\n    >>> dashboard.servable()\n    \"\"\"\n\n    def __init__(self, **params):\n        \"\"\"Initialize dashboard with data source.\"\"\"\n        super().__init__(**params)\n```\n\n## Pattern Development Workflow\n\n1. **Identify need**: What problem are you solving?\n2. **Find similar pattern**: Check pattern files for similar use cases\n3. **Adapt pattern**: Modify for your specific requirements\n4. **Test thoroughly**: Verify edge cases and performance\n5. **Document**: Add comments explaining customizations\n\n## Contributing Patterns\n\nWhen adding new patterns to these resources:\n\n1. **Clear use case**: Explain when to use the pattern\n2. **Complete example**: Include all imports and setup\n3. **Best practices**: Follow established conventions\n4. **Performance notes**: Mention scalability considerations\n5. **Related patterns**: Link to similar or complementary patterns\n\n## References\n\n- [Panel Documentation](https://panel.holoviz.org/)\n- [HoloViews Documentation](https://holoviews.org/)\n- [Datashader Documentation](https://datashader.org/)\n- [GeoViews Documentation](https://geoviews.org/)\n- [Param Documentation](https://param.holoviz.org/)\n\n---\n\n## Pattern File Table of Contents\n\n### Detailed Pattern Files\n\n1. **[Panel Patterns](./panel-patterns.md)** (Loaded when: Building Panel apps)\n   - Param-based dashboards\n   - Multi-page applications\n   - Real-time streaming\n   - File uploads\n   - Authentication\n\n2. **[HoloViews Patterns](./holoviews-patterns.md)** (Loaded when: Composing visualizations)\n   - Overlays and layouts\n   - DynamicMaps\n   - Custom operations\n   - Interactive streams\n\n3. **[Datashader Patterns](./datashader-patterns.md)** (Loaded when: Visualizing > 100K points)\n   - Scatter plots\n   - Time series\n   - Custom aggregations\n   - Dynamic colormapping\n\n4. **[GeoViews Patterns](./geoviews-patterns.md)** (Loaded when: Creating maps)\n   - Basemaps\n   - Geographic overlays\n   - CRS handling\n   - Spatial analysis\n\n5. **[Param Patterns](./param-patterns.md)** (Loaded when: Building parameter systems)\n   - Validation\n   - Dependencies\n   - Watchers\n   - Dynamic updates\n\n6. **[Integration Patterns](./integration-patterns.md)** (Loaded when: Using multiple tools)\n   - Panel + HoloViews\n   - Datashader + HoloViews\n   - FastAPI + Panel\n   - Lumen extensions\n\n7. **[Performance Patterns](./performance-patterns.md)** (Loaded when: Optimizing performance)\n   - Caching\n   - Lazy loading\n   - Streaming\n   - Async patterns\n\n---\n\n**Note**: Each pattern file includes complete, runnable examples with explanations. Load only the files relevant to your current task to minimize context usage.\n",
        "plugins/holoviz-expert/resources/troubleshooting/README.md": "# HoloViz Troubleshooting Guide\n\n## Overview\n\nSolutions for common issues across the HoloViz ecosystem. Organized by library for quick problem resolution.\n\n**How to use this guide**:\n1. Identify which library is causing the issue\n2. Check the appropriate troubleshooting file\n3. Try common debugging strategies if issue persists\n4. Consult community resources\n\n## Library-Specific Troubleshooting\n\n### Panel Issues\n\n**Common problems**: Server won't start, widgets not updating, deployment issues, authentication problems\n\n**See**: [Panel Troubleshooting](./panel-troubleshooting.md)\n\n**Load when**: Panel server issues, widget problems, or deployment errors\n\n### HoloViews Issues\n\n**Common problems**: Plots not rendering, composition errors, dimension mismatches, backend issues\n\n**See**: [HoloViews Troubleshooting](./holoviews-troubleshooting.md)\n\n**Load when**: Visualization rendering problems or HoloViews-specific errors\n\n### Datashader Issues\n\n**Common problems**: Performance degradation, memory errors, aggregation failures, colormapping issues\n\n**See**: [Datashader Troubleshooting](./datashader-troubleshooting.md)\n\n**Load when**: Large dataset rendering problems or Datashader errors\n\n### GeoViews Issues\n\n**Common problems**: CRS errors, tile provider failures, projection mismatches, geographic data loading\n\n**See**: [GeoViews Troubleshooting](./geoviews-troubleshooting.md)\n\n**Load when**: Map rendering issues or geographic data problems\n\n### Param Issues\n\n**Common problems**: Validation errors, dependency loops, watcher not firing, parameter inheritance\n\n**See**: [Param Troubleshooting](./param-troubleshooting.md)\n\n**Load when**: Parameter system errors or reactive update issues\n\n### hvPlot Issues\n\n**Common problems**: Import errors, plot not showing, groupby failures, kind not recognized\n\n**See**: [hvPlot Troubleshooting](./hvplot-troubleshooting.md)\n\n**Load when**: hvPlot API issues or quick plotting problems\n\n## Common Error Messages\n\n### \"No module named 'X'\"\n\n**Problem**: Missing dependency\n\n**Solution**:\n```bash\n# Install missing library\npip install X\n\n# Or install with specific extra\npip install panel[recommended]\npip install lumen[ai]\n```\n\n### \"Javascript Error: <model> could not be instantiated\"\n\n**Problem**: Extension not loaded\n\n**Solution**:\n```python\nimport panel as pn\npn.extension('tabulator', 'plotly')  # Load required extensions\n```\n\n### \"BokehDeprecationWarning\"\n\n**Problem**: Using deprecated API\n\n**Solution**:\n- Check documentation for updated API\n- Update code to use new methods\n- Or suppress warnings (not recommended):\n```python\nimport warnings\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\n```\n\n### \"Object of type X is not JSON serializable\"\n\n**Problem**: Trying to serialize non-JSON-compatible object\n\n**Solution**:\n```python\n# Convert to JSON-compatible types\nimport json\nimport numpy as np\n\n# Use tolist() for numpy arrays\ndata = {\n    'values': np_array.tolist(),\n    'timestamp': datetime_obj.isoformat()\n}\n```\n\n### \"RuntimeError: There is no current event loop\"\n\n**Problem**: Async code running without event loop\n\n**Solution**:\n```python\n# Use async context\nimport asyncio\n\nasync def main():\n    # Your async code here\n    pass\n\nasyncio.run(main())\n\n# Or for Panel\npn.serve(app, port=5006)\n```\n\n## Quick Debugging Checklist\n\n### Visualization Not Showing\n\n- [ ] Extensions loaded? (`pn.extension()`, `hv.extension()`)\n- [ ] Data not empty? (check `df.head()`)\n- [ ] Correct dimensions specified? (check column names)\n- [ ] In Jupyter: cell executed and output visible?\n- [ ] In script: `.servable()` or `.show()` called?\n\n### Widget Not Updating\n\n- [ ] `@param.depends` decorator present?\n- [ ] Correct parameter names in decorator?\n- [ ] Method returns a displayable object?\n- [ ] Parameter actually changing? (add print statement)\n- [ ] No circular dependencies?\n\n### Performance Issues\n\n- [ ] Data size reasonable? (< 100K rows for most operations)\n- [ ] Using Datashader for large data?\n- [ ] Caching enabled where appropriate?\n- [ ] Unnecessary recomputation happening?\n- [ ] Memory leaks from unclosed resources?\n\n### Import Errors\n\n- [ ] All dependencies installed?\n- [ ] Correct package versions?\n- [ ] Virtual environment activated?\n- [ ] No conflicting package versions?\n- [ ] Python version compatible? (3.9+)\n\n## Debugging Strategies\n\n### 1. Enable Debug Logging\n\n```python\nimport logging\n\n# Set logging level\nlogging.basicConfig(level=logging.DEBUG)\n\n# Panel-specific logging\nimport panel as pn\npn.config.console_output = 'accumulate'\n```\n\n### 2. Isolate the Problem\n\n```python\n# Test with minimal example\nimport panel as pn\npn.extension()\n\n# Simplest possible test\npn.panel(\"Hello\").show()  # Does this work?\n```\n\n### 3. Check Versions\n\n```python\nimport panel as pn\nimport holoviews as hv\nimport datashader as ds\n\nprint(f\"Panel: {pn.__version__}\")\nprint(f\"HoloViews: {hv.__version__}\")\nprint(f\"Datashader: {ds.__version__}\")\n```\n\n### 4. Inspect Objects\n\n```python\n# Check data\nprint(df.head())\nprint(df.dtypes)\nprint(df.shape)\n\n# Check HoloViews elements\nprint(element.dimensions())\nprint(element.data)\n\n# Check Panel components\nprint(component.param)\nprint(component.param.values())\n```\n\n### 5. Use Browser DevTools\n\nFor Panel applications:\n1. Open browser DevTools (F12)\n2. Check Console for JavaScript errors\n3. Check Network tab for failed requests\n4. Check WebSocket connection status\n\n### 6. Test in Different Environments\n\n```bash\n# Test in Python shell\npython -c \"import panel; panel.__version__\"\n\n# Test in Jupyter\njupyter lab  # or jupyter notebook\n\n# Test standalone\npanel serve app.py --show\n```\n\n## Performance Profiling\n\n### Memory Profiling\n\n```python\nfrom memory_profiler import profile\n\n@profile\ndef create_dashboard():\n    # Your code here\n    pass\n\ncreate_dashboard()\n```\n\n### Time Profiling\n\n```python\nimport cProfile\nimport pstats\n\nprofiler = cProfile.Profile()\nprofiler.enable()\n\n# Your code here\n\nprofiler.disable()\nstats = pstats.Stats(profiler)\nstats.sort_stats('cumulative')\nstats.print_stats(20)\n```\n\n### Panel Performance Debugging\n\n```python\nimport panel as pn\n\n# Enable performance logging\npn.config.profiler = 'pyinstrument'  # or 'snakeviz'\n\n# Run your app\napp.servable()\n```\n\n## Getting Help\n\n### Before Asking for Help\n\n1. **Search existing issues**: Check GitHub issues and Discourse\n2. **Create minimal example**: Reduce to simplest reproducible case\n3. **Check documentation**: Review relevant docs and examples\n4. **Include versions**: List all package versions\n5. **Show error messages**: Include full error traceback\n\n### Where to Get Help\n\n**Community Forum** (Best for questions):\n- [HoloViz Discourse](https://discourse.holoviz.org)\n- Searchable history\n- Community support\n\n**GitHub Issues** (For bugs):\n- [Panel Issues](https://github.com/holoviz/panel/issues)\n- [HoloViews Issues](https://github.com/holoviz/holoviews/issues)\n- [Datashader Issues](https://github.com/holoviz/datashader/issues)\n- [GeoViews Issues](https://github.com/holoviz/geoviews/issues)\n\n**Stack Overflow** (For coding questions):\n- Tag: `holoviews`, `panel`, `datashader`\n- Good for general coding questions\n\n### Minimal Reproducible Example Template\n\n```python\n\"\"\"\nIssue: [Brief description]\n\nEnvironment:\n- Python: 3.11\n- Panel: 1.3.0\n- HoloViews: 1.18.0\n- OS: macOS / Linux / Windows\n\"\"\"\n\nimport panel as pn\nimport holoviews as hv\n\npn.extension()\nhv.extension('bokeh')\n\n# Minimal code that reproduces the issue\ndef create_issue():\n    # Your minimal example here\n    pass\n\n# Expected: [What should happen]\n# Actual: [What actually happens]\n# Error: [Full error message if any]\n```\n\n## Environment Troubleshooting\n\n### Virtual Environment Issues\n\n```bash\n# Verify environment is activated\nwhich python  # Should show venv path\n\n# Recreate environment if needed\npython -m venv fresh_env\nsource fresh_env/bin/activate  # or fresh_env\\Scripts\\activate on Windows\npip install panel holoviews\n```\n\n### Package Conflicts\n\n```bash\n# Check for conflicts\npip check\n\n# Create requirements file\npip freeze > requirements.txt\n\n# Fresh install\npip uninstall -y panel holoviews datashader\npip install panel holoviews datashader\n```\n\n### Jupyter Extension Issues\n\n```bash\n# Reinstall Jupyter extensions\njupyter labextension install @pyviz/jupyterlab_pyviz\n\n# Or for JupyterLab 3+\npip install jupyterlab_pyviz\n```\n\n## Quick Reference: Error → Solution\n\n| Error | Solution | Doc Link |\n|-------|----------|----------|\n| Plot not showing | Load extensions | [Panel](./panel-troubleshooting.md) |\n| Widget not updating | Check `@param.depends` | [Param](./param-troubleshooting.md) |\n| Memory error with large data | Use Datashader | [Datashader](./datashader-troubleshooting.md) |\n| CRS/projection error | Check coordinate systems | [GeoViews](./geoviews-troubleshooting.md) |\n| Server won't start | Check port availability | [Panel](./panel-troubleshooting.md) |\n| Import error | Install dependencies | All docs |\n| JavaScript error | Load extensions | [Panel](./panel-troubleshooting.md) |\n\n## Common Solutions by Symptom\n\n### Nothing Displays\n\n1. Check extensions loaded\n2. Verify data not empty\n3. Ensure cell executed (Jupyter)\n4. Check `.servable()` or `.show()` called\n\n**See**: [Panel Troubleshooting](./panel-troubleshooting.md#displays)\n\n### Slow Performance\n\n1. Check data size\n2. Use Datashader for large data\n3. Enable caching\n4. Profile code\n\n**See**: [Performance Patterns](../patterns/performance-patterns.md)\n\n### Unexpected Behavior\n\n1. Check parameter values\n2. Verify data types\n3. Test with simple example\n4. Enable debug logging\n\n**See**: Library-specific troubleshooting guides\n\n## Summary\n\nMost issues fall into these categories:\n1. **Missing dependencies** → Install required packages\n2. **Extensions not loaded** → Add `pn.extension()` / `hv.extension()`\n3. **Data issues** → Check data shape, types, and contents\n4. **Configuration** → Verify parameters and settings\n5. **Environment** → Check package versions and conflicts\n\n**Next steps**:\n1. Identify the specific library causing issues\n2. Check the relevant troubleshooting guide\n3. Try debugging strategies\n4. Ask community if still stuck\n\n## Library Troubleshooting References\n\n- **[Panel Troubleshooting](./panel-troubleshooting.md)** - Server, widgets, deployment\n- **[HoloViews Troubleshooting](./holoviews-troubleshooting.md)** - Plots, composition, backends\n- **[Datashader Troubleshooting](./datashader-troubleshooting.md)** - Performance, memory, aggregation\n- **[GeoViews Troubleshooting](./geoviews-troubleshooting.md)** - Maps, CRS, projections\n- **[Param Troubleshooting](./param-troubleshooting.md)** - Parameters, validation, dependencies\n- **[hvPlot Troubleshooting](./hvplot-troubleshooting.md)** - Quick plotting issues\n\n---\n\n**Note**: Each troubleshooting file contains specific error messages, solutions, and workarounds for that library. Load only the file relevant to your issue.\n",
        "plugins/holoviz-expert/skills/advanced-rendering/SKILL.md": "---\nname: advanced-rendering\ndescription: Master high-performance rendering for large datasets with Datashader. Use this skill when working with datasets exceeding 100M+ points, optimizing visualization performance, or implementing efficient rendering strategies with rasterization and colormapping techniques.\ncompatibility: Requires datashader >= 0.15.0, colorcet >= 3.1.0, holoviews >= 1.18.0, pandas >= 1.0.0, numpy >= 1.15.0\n---\n\n# Advanced Rendering Skill\n\n## Overview\n\nMaster high-performance rendering for large datasets with Datashader and optimization techniques. This skill covers handling 100M+ point datasets, performance tuning, and efficient visualization strategies.\n\n## Dependencies\n\n- datashader >= 0.15.0\n- colorcet >= 3.1.0\n- holoviews >= 1.18.0\n- pandas >= 1.0.0\n- numpy >= 1.15.0\n\n## Core Capabilities\n\n### 1. Datashader Fundamentals\n\nDatashader is designed for rasterizing large datasets:\n\n```python\nimport datashader as ds\nfrom datashader.mpl_ext import _colorize\nimport holoviews as hv\n\n# Load large dataset (can handle 100M+ points)\ndf = pd.read_csv('large_dataset.csv')  # Millions or billions of rows\n\n# Create datashader canvas\ncanvas = ds.Canvas(plot_width=800, plot_height=600)\n\n# Rasterize aggregation\nagg = canvas.points(df, 'x', 'y')\n\n# Convert to image\nimg = agg.to_array(True)\n```\n\n### 2. Efficient Point Rendering\n\n```python\nfrom holoviews.operation.datashader import datashade, aggregate, shade\n\n# Quick datashading with HoloViews\nscatter = hv.Scatter(df, 'x', 'y')\nshaded = datashade(scatter)\n\n# With custom aggregation\nagg = aggregate(scatter, width=800, height=600)\ncolored = shade(agg, cmap='viridis')\n\n# Control rasterization\nfrom holoviews.operation import rasterize\n\nrasterized = rasterize(\n    scatter,\n    aggregator=ds.count(),\n    pixel_ratio=2,\n    upsample_method='interp'\n)\n```\n\n### 3. Color Mapping and Aggregation\n\n```python\nimport datashader as ds\nfrom colorcet import cm\n\n# Count aggregation (heatmap)\ncanvas = ds.Canvas()\nagg = canvas.points(df, 'x', 'y', agg=ds.count())\n\n# Weighted aggregation\nagg = canvas.points(df, 'x', 'y', agg=ds.sum('value'))\n\n# Mean aggregation\nagg = canvas.points(df, 'x', 'y', agg=ds.mean('value'))\n\n# Custom colormapping\nimport datashader.transfer_functions as tf\n\nshaded = tf.shade(agg, cmap=cm['viridis'])\nshaded_with_spread = tf.spread(shaded, px=2)\n```\n\n### 4. Image Compositing\n\n```python\n# Combine multiple datasets\ncanvas = ds.Canvas(x_range=(0, 100), y_range=(0, 100))\n\nagg1 = canvas.points(df1, 'x', 'y')\nagg2 = canvas.points(df2, 'x', 'y')\n\n# Shade separately\nshaded1 = tf.shade(agg1, cmap=cm['reds'])\nshaded2 = tf.shade(agg2, cmap=cm['blues'])\n\n# Composite\nimport datashader.transfer_functions as tf\ncomposite = tf.composite(shaded1, shaded2)\n```\n\n### 5. Interactive Datashader with HoloViews\n\n```python\nfrom holoviews.operation.datashader import datashade\nfrom holoviews import streams\n\n# Interactive scatter with zooming\ndef create_datashaded_plot(data):\n    scatter = hv.Scatter(data, 'x', 'y')\n    return datashade(scatter, cmap='viridis')\n\n# Add interaction\nrange_stream = streams.RangeXY()\ninteractive_plot = hv.DynamicMap(\n    create_datashaded_plot,\n    streams=[range_stream]\n)\n```\n\n### 6. Time Series Data Streaming\n\n```python\n# Efficient streaming plot for time series\nfrom holoviews.operation.datashader import rasterize\nfrom holoviews import streams\n\ndef create_timeseries_plot(df_window):\n    curve = hv.Curve(df_window, 'timestamp', 'value')\n    return curve\n\n# Rasterize for efficiency\nrasterized = rasterize(\n    hv.Curve(df, 'timestamp', 'value'),\n    aggregator=ds.mean('value'),\n    width=1000,\n    height=400\n)\n```\n\n## Performance Optimization Strategies\n\n### 1. Memory Optimization\n\n```python\n# Use data types efficiently\ndf = pd.read_csv(\n    'large_file.csv',\n    dtype={\n        'x': 'float32',\n        'y': 'float32',\n        'value': 'float32',\n        'category': 'category'\n    }\n)\n\n# Chunk processing for extremely large files\nchunk_size = 1_000_000\naggregations = []\n\nfor chunk in pd.read_csv('huge.csv', chunksize=chunk_size):\n    canvas = ds.Canvas()\n    agg = canvas.points(chunk, 'x', 'y')\n    aggregations.append(agg)\n\n# Combine results\ncombined_agg = aggregations[0]\nfor agg in aggregations[1:]:\n    combined_agg = combined_agg + agg\n```\n\n### 2. Resolution and Pixel Ratio\n\n```python\n# Adjust canvas resolution based on data density\ndef auto_canvas(df, target_pixels=500000):\n    data_points = len(df)\n    aspect_ratio = (df['x'].max() - df['x'].min()) / (df['y'].max() - df['y'].min())\n\n    pixels = int(np.sqrt(target_pixels / aspect_ratio))\n    height = pixels\n    width = int(pixels * aspect_ratio)\n\n    return ds.Canvas(\n        plot_width=width,\n        plot_height=height,\n        x_range=(df['x'].min(), df['x'].max()),\n        y_range=(df['y'].min(), df['y'].max())\n    )\n\ncanvas = auto_canvas(df)\nagg = canvas.points(df, 'x', 'y')\n```\n\n### 3. Aggregation Selection\n\n```python\n# Choose appropriate aggregation for your data\ncanvas = ds.Canvas()\n\n# For counting: count()\nagg_count = canvas.points(df, 'x', 'y', agg=ds.count())\n\n# For averages: mean()\nagg_mean = canvas.points(df, 'x', 'y', agg=ds.mean('value'))\n\n# For sums: sum()\nagg_sum = canvas.points(df, 'x', 'y', agg=ds.sum('value'))\n\n# For max/min\nagg_max = canvas.points(df, 'x', 'y', agg=ds.max('value'))\n\n# For percentiles\nagg_p95 = canvas.points(df, 'x', 'y', agg=ds.count_cat('category'))\n```\n\n## Colormapping with Colorcet\n\n### 1. Perceptually Uniform Colormaps\n\n```python\nfrom colorcet import cm, cmap_d\nimport datashader.transfer_functions as tf\n\n# Use perceptually uniform colormaps\ncanvas = ds.Canvas()\nagg = canvas.points(df, 'x', 'y', agg=ds.count())\n\n# Gray scale\nshaded_gray = tf.shade(agg, cmap=cm['gray'])\n\n# Perceptual colormaps\nshaded_viridis = tf.shade(agg, cmap=cm['viridis'])\nshaded_turbo = tf.shade(agg, cmap=cm['turbo'])\n\n# Category colormaps\nshaded_color = tf.shade(agg, cmap=cm['cet_c5'])\n```\n\n### 2. Custom Color Normalization\n\n```python\n# Logarithmic normalization\nfrom datashader.transfer_functions import Log\n\ncanvas = ds.Canvas()\nagg = canvas.points(df, 'x', 'y', agg=ds.sum('value'))\n\n# Log transform for better visualization\nshaded = tf.shade(agg, norm='log', cmap=cm['viridis'])\n\n# Power law normalization\nshaded_power = tf.shade(agg, norm=ds.transfer_functions.eq_hist, cmap=cm['plasma'])\n```\n\n### 3. Multi-Band Compositing\n\n```python\n# Separate visualization of multiple datasets\ncanvas = ds.Canvas()\n\nagg_red = canvas.points(df_red, 'x', 'y')\nagg_green = canvas.points(df_green, 'x', 'y')\nagg_blue = canvas.points(df_blue, 'x', 'y')\n\n# Stack as RGB\nfrom datashader.colors import rgb\nresult = rgb(agg_red, agg_green, agg_blue)\n```\n\n## Integration with Panel and HoloViews\n\n```python\nimport panel as pn\nfrom holoviews.operation.datashader import datashade\n\n# Create interactive dashboard with datashader\nclass LargeDataViewer(param.Parameterized):\n    cmap = param.Selector(default='viridis', objects=list(cm.keys()))\n    show_spread = param.Boolean(default=False)\n\n    def __init__(self, data):\n        super().__init__()\n        self.data = data\n\n    @param.depends('cmap', 'show_spread')\n    def plot(self):\n        scatter = hv.Scatter(self.data, 'x', 'y')\n        shaded = datashade(scatter, cmap=cm[self.cmap])\n\n        if self.show_spread:\n            shaded = tf.spread(shaded, px=2)\n\n        return shaded\n\nviewer = LargeDataViewer(large_df)\n\npn.extension('material')\napp = pn.Column(\n    pn.param.ParamMethod.from_param(viewer.param),\n    viewer.plot\n)\napp.servable()\n```\n\n## Best Practices\n\n### 1. Choose the Right Tool\n```\n< 10k points:        Use standard HoloViews/hvPlot\n10k - 1M points:     Use rasterize() for dense plots\n1M - 100M points:    Use Datashader\n> 100M points:       Use Datashader with chunking\n```\n\n### 2. Appropriate Canvas Size\n```python\n# General rule: 400-1000 pixels on each axis\n# Too small: loses detail\n# Too large: slow rendering, memory waste\n\ncanvas = ds.Canvas(plot_width=800, plot_height=600)  # Good default\n```\n\n### 3. Normalize Large Value Ranges\n```python\n# When data has extreme outliers\ncanvas = ds.Canvas()\nagg = canvas.points(df, 'x', 'y', agg=ds.mean('value'))\n\n# Use appropriate normalization\nshaded = tf.shade(agg, norm='log', cmap=cm['viridis'])\n```\n\n## Common Patterns\n\n### Pattern 1: Progressive Disclosure\n```python\ndef create_progressive_plot(df):\n    # Start with aggregated view\n    agg = canvas.points(df, 'x', 'y')\n    return tf.shade(agg, cmap='viridis')\n\n# User can zoom to see more detail\n# Datashader automatically recalculates at new resolution\n```\n\n### Pattern 2: Categorical Visualization\n```python\ncanvas = ds.Canvas()\n\n# Aggregate by category\nfor category in df['category'].unique():\n    subset = df[df['category'] == category]\n    agg = canvas.points(subset, 'x', 'y', agg=ds.count())\n    shaded = tf.shade(agg, cmap=cm[f'category_{category}'])\n```\n\n### Pattern 3: Time Series Aggregation\n```python\ndef aggregate_time_series(df, time_bucket):\n    df['time_bucket'] = pd.cut(df['timestamp'], bins=time_bucket)\n\n    aggregated = df.groupby('time_bucket').agg({\n        'x': 'mean',\n        'y': 'mean',\n        'value': 'sum'\n    })\n\n    return aggregated\n```\n\n## Common Use Cases\n\n1. **Scatter Plot Analysis**: 100M+ point clouds\n2. **Time Series Visualization**: High-frequency trading data\n3. **Geospatial Heat Maps**: Global-scale location data\n4. **Scientific Visualization**: Climate model outputs\n5. **Network Analysis**: Large graph layouts\n6. **Financial Analytics**: Tick-by-tick market data\n\n## Troubleshooting\n\n### Issue: Poor Color Differentiation\n- Use perceptually uniform colormaps from colorcet\n- Apply appropriate normalization (log, power law)\n- Adjust canvas size for better resolution\n\n### Issue: Memory Issues with Large Data\n- Use chunk processing for files larger than RAM\n- Reduce data type precision (float64 → float32)\n- Aggregate before visualization\n- Use categorical data type for strings\n\n### Issue: Slow Performance\n- Reduce canvas size (fewer pixels)\n- Use simpler aggregation functions\n- Enable GPU acceleration if available\n- Profile with Python profilers to find bottlenecks\n\n## Resources\n\n- [Datashader Documentation](https://datashader.org)\n- [Colorcet Documentation](https://colorcet.holoviz.org)\n- [Datashader Examples](https://datashader.org/getting_started/index.html)\n- [Large Data Visualization Guide](https://holoviews.org/user_guide/Large_Data.html)\n",
        "plugins/holoviz-expert/skills/colormaps-styling/SKILL.md": "---\nname: colormaps-styling\ndescription: Master color management and visual styling with Colorcet. Use this skill when selecting appropriate colormaps, creating accessible and colorblind-friendly visualizations, applying consistent themes, or customizing plot aesthetics with perceptually uniform color palettes.\ncompatibility: Requires colorcet >= 3.1.0, holoviews >= 1.18.0, panel >= 1.3.0, bokeh >= 3.0.0\n---\n\n# Colormaps & Styling Skill\n\n## Overview\n\nMaster color management and visual styling with Colorcet and theme customization. Select appropriate colormaps, create accessible visualizations, and apply consistent application styling.\n\n### What is Colorcet?\n\nColorcet provides perceptually uniform colormaps designed for scientific visualization:\n\n- **Perceptually uniform**: Changes in data correspond to proportional visual changes\n- **Colorblind-friendly**: Palettes designed for accessibility\n- **Purpose-built**: Specific colormaps for different data types\n- **HoloViz integration**: Seamless use across HoloViews, Panel, and Bokeh\n\n## Quick Start\n\n### Installation\n\n```bash\npip install colorcet\n```\n\n### Basic Usage\n\n```python\nimport colorcet as cc\nfrom colorcet import cm\nimport holoviews as hv\n\nhv.extension('bokeh')\n\n# Use a colormap\ndata.hvplot.scatter('x', 'y', c='value', cmap=cm['cet_goertzel'])\n```\n\n## Core Concepts\n\n### 1. Colormap Categories\n\n**Sequential**: Single hue, increasing intensity\n```python\n# Blues, greens, reds, grays\ndata.hvplot('x', 'y', c='value', cmap=cm['cet_blues'])\n```\n\n**Diverging**: Two hues from center point\n```python\n# Emphasize positive/negative\ndata.hvplot('x', 'y', c='value', cmap=cm['cet_coolwarm'])\n```\n\n**Categorical**: Distinct colors for categories\n```python\n# Qualitative data\ndata.hvplot('x', 'y', c='category', cmap=cc.palette['tab10'])\n```\n\n**Cyclic**: Wraps around for angular data\n```python\n# Angles, directions, phases\ndata.hvplot('x', 'y', c='angle', cmap=cm['cet_cyclic_c1'])\n```\n\n**See**: [Colormap Reference](../../resources/colormaps/colormap-reference.md) for complete catalog\n\n### 2. Accessibility\n\n**Colorblind-safe palettes**:\n```python\n# Deuteranopia (red-green)\ncmap=cm['cet_d4']\n\n# Protanopia (red-green)\ncmap=cm['cet_p3']\n\n# Tritanopia (blue-yellow)\ncmap=cm['cet_t10']\n\n# Grayscale-safe\ncmap=cm['cet_gray_r']\n```\n\n**See**: [Accessibility Guide](../../resources/colormaps/accessibility.md) for comprehensive guidelines\n\n### 3. Colormap Selection Guide\n\n| Data Type | Recommended Colormap | Example |\n|-----------|---------------------|---------|\n| Single channel (positive) | `cet_blues`, `cet_gray_r` | Temperature, density |\n| Diverging (±) | `cet_coolwarm`, `cet_bwy` | Correlation, anomalies |\n| Categorical | `tab10`, `tab20` | Categories, labels |\n| Angular | `cet_cyclic_c1` | Wind direction, phase |\n| Full spectrum | `cet_goertzel` | General purpose |\n\n### 4. HoloViews Styling\n\n```python\nimport holoviews as hv\n\n# Apply colormap\nscatter = hv.Scatter(data, 'x', 'y', vdims=['value']).opts(\n    color=hv.dim('value').norm(),\n    cmap=cm['cet_goertzel'],\n    colorbar=True,\n    width=600,\n    height=400\n)\n\n# Style options\nscatter.opts(\n    size=5,\n    alpha=0.7,\n    tools=['hover'],\n    title='My Plot'\n)\n```\n\n**See**: [HoloViews Styling](../../resources/colormaps/holoviews-styling.md) for advanced customization\n\n### 5. Panel Themes\n\n```python\nimport panel as pn\n\n# Apply theme\npn.extension(design='material')\n\n# Custom theme\npn.config.theme = 'dark'\n\n# Accent color\ntemplate = pn.template.FastListTemplate(\n    title='My App',\n    accent='#00aa41'\n)\n```\n\n**See**: [Panel Themes](../../resources/colormaps/panel-themes.md) for theme customization\n\n## Common Patterns\n\n### Pattern 1: Heatmap with Diverging Colormap\n\n```python\nimport holoviews as hv\nfrom colorcet import cm\n\nheatmap = hv.HeatMap(data, ['x', 'y'], 'value').opts(\n    cmap=cm['cet_coolwarm'],\n    colorbar=True,\n    width=600,\n    height=400,\n    tools=['hover']\n)\n```\n\n### Pattern 2: Categorical Color Assignment\n\n```python\nimport panel as pn\nfrom colorcet import palette\n\ncategories = ['A', 'B', 'C', 'D']\ncolors = palette['tab10'][:len(categories)]\n\ncolor_map = dict(zip(categories, colors))\nplot = data.hvplot('x', 'y', c='category', cmap=color_map)\n```\n\n### Pattern 3: Consistent App Styling\n\n```python\nimport panel as pn\n\n# Set global theme\npn.extension(design='material')\n\n# Custom CSS\npn.config.raw_css.append(\"\"\"\n.card {\n    border-radius: 10px;\n    box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n}\n\"\"\")\n\n# Accent color throughout\naccent = '#00aa41'\ntemplate = pn.template.FastListTemplate(\n    title='My Dashboard',\n    accent=accent\n)\n```\n\n### Pattern 4: Responsive Colorbar\n\n```python\nfrom holoviews import opts\n\nplot = data.hvplot.scatter('x', 'y', c='value', cmap=cm['cet_blues']).opts(\n    colorbar=True,\n    colorbar_opts={\n        'title': 'Value',\n        'width': 10,\n        'ticker': {'desired_num_ticks': 5}\n    }\n)\n```\n\n### Pattern 5: Colorblind-Safe Visualization\n\n```python\nfrom colorcet import cm\n\n# Use colorblind-safe diverging palette\nplot = data.hvplot('x', 'y', c='value', cmap=cm['cet_d4']).opts(\n    title='Colorblind-Safe Visualization',\n    width=600,\n    height=400\n)\n\n# Alternative: Use patterns/hatching\nplot.opts(hatch_pattern='/')\n```\n\n## Best Practices\n\n### 1. Match Colormap to Data Type\n\n```python\n# ✅ Good: Sequential for positive values\ntemp_plot = data.hvplot(c='temperature', cmap=cm['cet_fire'])\n\n# ✅ Good: Diverging for centered data\ncorrelation = data.hvplot(c='correlation', cmap=cm['cet_coolwarm'])\n\n# ❌ Bad: Rainbow/jet colormap (not perceptually uniform)\nbad_plot = data.hvplot(c='value', cmap='jet')  # Avoid!\n```\n\n### 2. Consider Accessibility\n\n```python\n# ✅ Good: Colorblind-safe\nplot = data.hvplot(c='value', cmap=cm['cet_d4'])\n\n# ✅ Good: Add patterns for print/grayscale\nplot.opts(hatch_pattern='/')\n\n# ✅ Good: Test in grayscale\nplot.opts(cmap=cm['cet_gray_r'])\n```\n\n### 3. Consistent Styling\n\n```python\n# ✅ Good: Define color scheme once\nCOLORS = {\n    'primary': '#00aa41',\n    'secondary': '#616161',\n    'accent': '#ff6f00'\n}\n\n# Use throughout application\npn.template.FastListTemplate(accent=COLORS['primary'])\n```\n\n### 4. Meaningful Labels\n\n```python\n# ✅ Good: Descriptive colorbar\nplot.opts(\n    colorbar=True,\n    colorbar_opts={'title': 'Temperature (°C)'}\n)\n\n# ❌ Bad: No context\nplot.opts(colorbar=True)\n```\n\n### 5. Performance with Large Data\n\n```python\n# For large datasets, limit colormap resolution\nplot.opts(\n    cmap=cm['cet_goertzel'],\n    color_levels=256  # Reduce if performance issues\n)\n```\n\n## Configuration\n\n### Global Colormap Defaults\n\n```python\nimport holoviews as hv\nfrom colorcet import cm\n\n# Set default colormap\nhv.opts.defaults(\n    hv.opts.Image(cmap=cm['cet_goertzel']),\n    hv.opts.Scatter(cmap=cm['cet_blues'])\n)\n```\n\n### Theme Configuration\n\n```python\nimport panel as pn\n\n# Material design\npn.extension(design='material')\n\n# Dark mode\npn.config.theme = 'dark'\n\n# Custom theme JSON\npn.config.theme_json = {\n    'palette': {\n        'primary': '#00aa41',\n        'secondary': '#616161'\n    }\n}\n```\n\n## Troubleshooting\n\n### Colormap Not Showing\n\n```python\n# Check if colormap imported\nfrom colorcet import cm\nprint(cm['cet_goertzel'])  # Should print colormap\n\n# Verify data range\nprint(data['value'].min(), data['value'].max())\n\n# Explicit normalization\nplot.opts(color=hv.dim('value').norm())\n```\n\n### Colors Look Wrong\n\n- **Issue**: Perceptual non-uniformity\n- **Solution**: Use Colorcet instead of matplotlib defaults\n\n```python\n# ❌ Avoid\ncmap='jet', cmap='rainbow'\n\n# ✅ Use\ncmap=cm['cet_goertzel'], cmap=cm['cet_fire']\n```\n\n### Theme Not Applying\n\n```python\n# Ensure extension loaded with design\npn.extension(design='material')\n\n# Check theme setting\nprint(pn.config.theme)  # 'default' or 'dark'\n\n# Reload page after theme change\n```\n\n## Progressive Learning Path\n\n### Level 1: Basics\n1. Install Colorcet\n2. Use basic colormaps\n3. Apply to plots\n\n**Resources**:\n- Quick Start (this doc)\n- [Colormap Reference](../../resources/colormaps/colormap-reference.md)\n\n### Level 2: Accessibility\n1. Understand colormap categories\n2. Choose appropriate maps\n3. Test for colorblindness\n\n**Resources**:\n- [Accessibility Guide](../../resources/colormaps/accessibility.md)\n\n### Level 3: Advanced Styling\n1. Customize HoloViews opts\n2. Create custom themes\n3. Consistent branding\n\n**Resources**:\n- [HoloViews Styling](../../resources/colormaps/holoviews-styling.md)\n- [Panel Themes](../../resources/colormaps/panel-themes.md)\n\n## Additional Resources\n\n### Documentation\n- **[Colormap Reference](../../resources/colormaps/colormap-reference.md)** - Complete colormap catalog\n- **[Accessibility Guide](../../resources/colormaps/accessibility.md)** - Colorblind-friendly design\n- **[HoloViews Styling](../../resources/colormaps/holoviews-styling.md)** - Advanced customization\n- **[Panel Themes](../../resources/colormaps/panel-themes.md)** - Theme and branding\n\n### External Links\n- [Colorcet Documentation](https://colorcet.holoviz.org/)\n- [Colorcet Gallery](https://colorcet.holoviz.org/user_guide/index.html)\n- [Color Universal Design](https://jfly.uni-koeln.de/color/)\n- [WCAG Color Contrast](https://www.w3.org/WAI/WCAG21/Understanding/contrast-minimum.html)\n\n## Use Cases\n\n### Scientific Visualization\n- Temperature maps\n- Density plots\n- Correlation matrices\n- Geospatial data\n\n### Data Dashboards\n- KPI indicators\n- Time series\n- Category comparison\n- Status displays\n\n### Accessibility\n- Colorblind-friendly visualizations\n- Print-safe graphics\n- High-contrast displays\n- Grayscale compatibility\n\n### Branding\n- Corporate colors\n- Consistent styling\n- Custom themes\n- Professional appearance\n\n## Summary\n\nColorcet provides perceptually uniform, accessible colormaps for scientific visualization.\n\n**Key principles**:\n- Match colormap to data type\n- Choose colorblind-safe palettes\n- Use perceptually uniform maps\n- Maintain consistent styling\n- Test accessibility\n\n**Ideal for**:\n- Scientific visualizations\n- Accessible dashboards\n- Professional applications\n- Print publications\n\n**Colormap selection**:\n- Sequential: Single channel data\n- Diverging: Centered data (±)\n- Categorical: Qualitative categories\n- Cyclic: Angular/periodic data\n\n## Related Skills\n\n- **[Data Visualization](../data-visualization/SKILL.md)** - HoloViews visualization patterns\n- **[Panel Dashboards](../panel-dashboards/SKILL.md)** - Dashboard styling and themes\n- **[Plotting Fundamentals](../plotting-fundamentals/SKILL.md)** - Basic plotting with hvPlot\n",
        "plugins/holoviz-expert/skills/data-visualization/SKILL.md": "---\nname: data-visualization\ndescription: Master advanced declarative visualization with HoloViews. Use this skill when creating complex multi-dimensional visualizations, composing overlays and layouts, implementing interactive streams and selection, building network or hierarchical visualizations, or exploring data with dynamic maps and faceted displays.\ncompatibility: Requires holoviews >= 1.18.0, pandas >= 1.0.0, numpy >= 1.15.0, bokeh >= 3.0.0, networkx >= 2.0.0 (for network visualizations)\n---\n\n# Data Visualization Skill\n\n## Overview\n\nMaster advanced declarative visualization with HoloViews and composition patterns. This skill covers sophisticated visualization techniques for complex data exploration and presentation.\n\n## Dependencies\n\n- holoviews >= 1.18.0\n- pandas >= 1.0.0\n- numpy >= 1.15.0\n- bokeh >= 3.0.0\n- networkx >= 2.0.0 (for network visualizations)\n\n## Core Capabilities\n\n### 1. Advanced Element Composition\n\nHoloViews allows sophisticated composition of visualization elements:\n\n```python\nimport holoviews as hv\nfrom holoviews import opts\nimport pandas as pd\nimport numpy as np\n\n# Create overlaid elements\ncurve = hv.Curve(df, 'x', 'y', label='Measured')\nscatter = hv.Scatter(df_with_noise, 'x', 'y', label='Noisy')\noverlay = curve * scatter  # Multiplication overlays\n\n# Create layouts\ncol_layout = hv.Column(plot1, plot2, plot3)\nrow_layout = hv.Row(plot1, plot2, plot3)\ngrid_layout = hv.GridMatrix(data_dict)\n\n# Faceted displays\nfaceted = hv.Curve(df, 'date', 'value').facet('category')\n\n# Nested layouts\ncomplex_layout = hv.Column(\n    hv.Row(plot1, plot2),\n    hv.Row(plot3, plot4),\n    hv.Row(plot5, plot6)\n)\n```\n\n### 2. Interactive Streams and Selection\n\nCreate responsive visualizations with interactive selection:\n\n```python\nfrom holoviews import streams\n\n# Selection stream\nrange_stream = streams.RangeXY()\nscatter = hv.Scatter(df, 'x', 'y').opts(tools=['box_select'])\n\n@hv.transform\ndef selected_data(data):\n    if range_stream.selection:\n        x0, x1 = range_stream.selection[0], range_stream.selection[1]\n        y0, y1 = range_stream.selection[2], range_stream.selection[3]\n        mask = (data['x'] >= x0) & (data['x'] <= x1) & \\\n               (data['y'] >= y0) & (data['y'] <= y1)\n        return data[mask]\n    return data\n\nhistogram = selected_data.to(hv.Histogram)\nscatter_with_hist = scatter + histogram\n```\n\n### 3. Dynamic Maps for Responsive Visualization\n\n```python\n# Dynamic updating based on parameters\nfrom holoviews import DynamicMap, streams\n\ndef plot_by_category(category):\n    data = df[df['category'] == category]\n    return hv.Scatter(data, 'x', 'y', title=f'Category: {category}')\n\ncategory_stream = streams.Stream.define('category', category='A')\ndmap = DynamicMap(plot_by_category, streams=[category_stream])\n\n# Parameterized dynamic map\ndef plot_with_params(threshold=0.5):\n    filtered = df[df['value'] > threshold]\n    return hv.Scatter(filtered, 'x', 'y')\n\ndmap_param = DynamicMap(\n    plot_with_params,\n    streams=[streams.Stream.define('threshold', threshold=0.5)]\n)\n```\n\n### 4. Network and Hierarchical Visualizations\n\n```python\nimport networkx as nx\n\n# Network graph\nG = nx.karate_club_graph()\npos = nx.spring_layout(G)\nedges = [(u, v) for u, v in G.edges()]\nnodes = list(G.nodes())\n\n# Create nodes and edges visualization\nedge_plot = hv.Segments(edges, kdims=['source', 'target'])\nnode_plot = hv.Scatter(\n    [(pos[n][0], pos[n][1], n) for n in nodes],\n    kdims=['x', 'y', 'node']\n)\nnetwork = (edge_plot * node_plot).opts(\n    opts.Scatter(size=100, color='red'),\n    opts.Segments(color='gray')\n)\n\n# Treemap for hierarchical data\ntreemap = hv.TreeMap(\n    hierarchical_data,\n    label='Organization'\n).opts(tools=['hover'])\n```\n\n### 5. Statistical and Aggregate Visualizations\n\n```python\n# Aggregate with Rasterize\nfrom holoviews.operation import datashader as dshade\n\n# Box plot for comparison\nbox_plot = hv.BoxWhisker(df, kdims=['category'], vdims=['value'])\n\n# Violin plot\nviolin = hv.Violin(df, kdims=['category'], vdims=['value'])\n\n# Distribution comparison\ndist_layout = hv.Column(*[\n    df[df['category'] == cat]['value'].hvplot.hist()\n    for cat in df['category'].unique()\n])\n```\n\n### 6. Multi-Dimensional Data Exploration\n\n```python\n# HoloMap for multi-dimensional data\ndef plot_by_params(category, metric):\n    data = df[(df['category'] == category) & (df['metric'] == metric)]\n    return hv.Scatter(data, 'x', 'y', title=f'{category} - {metric}')\n\nhmap = hv.HoloMap(\n    {(cat, met): plot_by_params(cat, met)\n     for cat in categories for met in metrics},\n    kdims=['Category', 'Metric']\n)\n\n# NdLayout for structured multi-dimensional display\nndlayout = hv.NdLayout({\n    (cat, met): plot_by_params(cat, met)\n    for cat in categories for met in metrics\n}, kdims=['Category', 'Metric'])\n```\n\n## Advanced Styling and Theming\n\n### 1. Global Options\n\n```python\n# Set global defaults\nopts.defaults(\n    opts.Curve(width=700, height=400, responsive=True),\n    opts.Scatter(size=100, alpha=0.5),\n    opts.Image(cmap='viridis')\n)\n\n# Apply to multiple elements\nstyled_plots = [\n    plot.opts(\n        title='Styled Plot',\n        xlabel='X Axis',\n        ylabel='Y Axis',\n        toolbar='right',\n        active_tools=['pan', 'wheel_zoom']\n    )\n    for plot in plots\n]\n```\n\n### 2. Custom Styling\n\n```python\n# Element-specific styling\nplot = hv.Scatter(df, 'x', 'y').opts(\n    color=hv.dim('category').categorize({\n        'A': '#FF6B6B',\n        'B': '#4ECDC4',\n        'C': '#45B7D1'\n    }),\n    size=hv.dim('value').norm(min=10, max=100),\n    selection_color='red',\n    nonselection_alpha=0.1\n)\n\n# Conditional formatting\nplot.opts(\n    color=hv.dim('status').categorize({\n        'good': 'green',\n        'warning': 'orange',\n        'error': 'red'\n    })\n)\n```\n\n### 3. Interactive Legends and Annotations\n\n```python\n# Annotations\nannotated_plot = hv.Curve(df, 'x', 'y')\nannotations = [\n    hv.Text(x, y, text, fontsize=10)\n    for x, y, text in annotations_data\n]\nplot_with_annotations = annotated_plot * hv.Overlay(annotations)\n\n# Custom legend\nplot = hv.Overlay([\n    hv.Curve(df1, label='Series 1'),\n    hv.Curve(df2, label='Series 2'),\n    hv.Curve(df3, label='Series 3')\n]).opts(\n    legend_position='top_left',\n    legend_muted_alpha=0.2\n)\n```\n\n## Best Practices\n\n### 1. Performance with Large Datasets\n```python\n# Use rasterize for dense plots\nfrom holoviews.operation import rasterize\n\nlarge_scatter = hv.Scatter(large_df, 'x', 'y')\nrasterized = rasterize(large_scatter, pixel_ratio=2)\n\n# Use aggregation\naggregated = df.groupby('category')['value'].mean().hvplot.bar()\n\n# Use datashader for massive datasets (>100M points)\nfrom holoviews.operation.datashader import datashade\ndshaded = datashade(large_scatter)\n```\n\n### 2. Responsive and Accessible Plots\n```python\n# Responsive sizing\nplot = hv.Scatter(df, 'x', 'y').opts(\n    responsive=True,\n    sizing_mode='stretch_width'\n)\n\n# Accessible color palettes\nplot = hv.Scatter(df, 'x', 'y').opts(\n    color=hv.dim('value').norm(),\n    cmap='cet_gray_r'  # Perceptually uniform\n)\n\n# Clear labels\nplot.opts(\n    title='Clear Title',\n    xlabel='Independent Variable (units)',\n    ylabel='Dependent Variable (units)',\n    fontsize=14\n)\n```\n\n### 3. Composition Patterns\n\n```python\n# Avoid deep nesting\n# Bad: ((a + (b + (c + d)))\n# Good: a + b + c + d\n\n# Create helper functions\ndef create_comparison_layout(data_dict):\n    plots = [hv.Scatter(v, label=k) for k, v in data_dict.items()]\n    return hv.Column(*plots)\n\n# Modular composition\nsidebar = hv.Column(title_text, filter_widget)\nmain = hv.Row(plot1, plot2)\napp = hv.Column(sidebar, main)\n```\n\n## Common Patterns\n\n### Pattern 1: Linked Brushing\n```python\ndef create_linked_views(df):\n    scatter = hv.Scatter(df, 'x', 'y').opts(tools=['box_select'])\n\n    def get_histogram(selection):\n        if selection:\n            selected_df = df.iloc[selection.event.inds]\n        else:\n            selected_df = df\n        return hv.Histogram(selected_df['x'], bins=20)\n\n    return scatter + DynamicMap(get_histogram, streams=[streams.Selection1D()])\n```\n\n### Pattern 2: Multi-Scale Exploration\n```python\ndef create_zoomable_view(df):\n    scatter = hv.Scatter(df, 'x', 'y')\n    zoomed = scatter.opts(\n        xlim=(0, 10),\n        ylim=(0, 10)\n    )\n    return hv.Column(scatter, zoomed)\n```\n\n### Pattern 3: Faceted Analysis\n```python\ndef create_faceted_analysis(df, facet_col):\n    return df.hvplot.scatter(\n        x='x',\n        y='y',\n        by=facet_col,\n        subplots=True,\n        layout='vertical'\n    )\n```\n\n## Integration with Other HoloViz Tools\n\n- **Panel**: Embed interactive HoloViews in dashboards\n- **hvPlot**: Quick plotting that produces HoloViews objects\n- **Datashader**: Efficient rendering for large data\n- **Param**: Parameter-driven dynamic visualizations\n- **GeoViews**: Geographic data visualization building on HoloViews\n\n## Common Use Cases\n\n1. **Exploratory Data Analysis**: Multi-dimensional data exploration\n2. **Dashboard Metrics**: KPI and metric visualization\n3. **Scientific Visualization**: Complex data relationships\n4. **Financial Analysis**: Time series and correlation analysis\n5. **Report Generation**: Publication-quality visualizations\n6. **Real-time Monitoring**: Streaming data visualization\n\n## Troubleshooting\n\n### Issue: Plot Elements Overlapping\n- Use layouts instead of overlays for clarity\n- Adjust alpha transparency\n- Use complementary colors\n\n### Issue: Slow Interactive Performance\n- Use rasterize for dense plots\n- Reduce data size with aggregation\n- Use datashader for massive datasets\n- Cache plot computations\n\n### Issue: Unclear Data Relationships\n- Use multiple linked views\n- Apply faceting for categorical comparison\n- Use color and size encoding\n- Add annotations and reference lines\n\n## Resources\n\n- [HoloViews Reference](https://holoviews.org/reference/index.html)\n- [HoloViews User Guide](https://holoviews.org/user_guide/index.html)\n- [Bokeh for Customization](https://docs.bokeh.org)\n- [Datashader for Performance](https://datashader.org)\n",
        "plugins/holoviz-expert/skills/geospatial-visualization/SKILL.md": "---\nname: geospatial-visualization\ndescription: Master geographic and mapping visualizations with GeoViews. Use this skill when creating interactive maps, visualizing point/polygon/line geographic data, building choropleth maps, performing spatial analysis (joins, buffers, proximity), working with coordinate reference systems, or integrating tile providers and basemaps.\ncompatibility: Requires geoviews >= 1.11.0, geopandas >= 0.10.0, shapely >= 1.8.0, pyproj >= 3.0.0, cartopy >= 0.20.0 (optional)\n---\n\n# Geospatial Visualization Skill\n\n## Overview\n\nMaster geographic and mapping visualizations with GeoViews and spatial data handling. This skill covers creating interactive maps, analyzing geographic data, and visualizing spatial relationships.\n\n## Dependencies\n\n- geoviews >= 1.11.0\n- geopandas >= 0.10.0\n- shapely >= 1.8.0\n- cartopy >= 0.20.0 (optional)\n- pyproj >= 3.0.0\n\n## Core Capabilities\n\n### 1. Basic Geographic Visualization\n\nGeoViews extends HoloViews with geographic support:\n\n```python\nimport geoviews as gv\nimport geopandas as gpd\nfrom geoviews import tile_providers as gvts\n\n# Load geographic data\nworld = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n\n# Basic map visualization\nworld_map = gv.Polygons(world, vdims=['name', 'pop_est']).opts(\n    title='World Population',\n    height=600,\n    width=800,\n    tools=['hover']\n)\n\n# Add tile layer background\ntiled = gvts.ESRI.apply.opts(\n    alpha=0.4,\n    xaxis=None,\n    yaxis=None\n) * world_map\n```\n\n### 2. Point Data on Maps\n\n```python\n# Create point features\ncities_data = {\n    'city': ['New York', 'Los Angeles', 'Chicago'],\n    'latitude': [40.7128, 34.0522, 41.8781],\n    'longitude': [-74.0060, -118.2437, -87.6298],\n    'population': [8337000, 3990456, 2693976]\n}\n\ncities_gdf = gpd.GeoDataFrame(\n    cities_data,\n    geometry=gpd.points_from_xy(cities_data['longitude'], cities_data['latitude']),\n    crs='EPSG:4326'\n)\n\n# Visualize points\npoints = gv.Points(cities_gdf, kdims=['longitude', 'latitude'], vdims=['city', 'population'])\npoints = points.opts(\n    size=gv.dim('population').norm(min=5, max=50),\n    color='red',\n    tools=['hover', 'box_select']\n)\n\n# With tile background\nmap_with_points = gvts.CartoDEM.apply.opts(alpha=0.5) * points\n```\n\n### 3. Choropleth Maps\n\n```python\n# Color regions by data value\nchoropleth = gv.Polygons(world, vdims=['name', 'pop_est']).opts(\n    cmap='viridis',\n    color=gv.dim('pop_est').norm(),\n    colorbar=True,\n    height=600,\n    width=900,\n    tools=['hover']\n)\n\n# Add interactivity\nchoropleth = choropleth.opts(\n    hover_fill_color='red',\n    hover_fill_alpha=0.5\n)\n```\n\n### 4. Interactive Feature Selection\n\n```python\nfrom holoviews import streams\n\n# Create selectable map\nselectable_map = gv.Polygons(world).opts(\n    tools=['box_select', 'tap'],\n    selection_fill_color='red',\n    nonselection_fill_alpha=0.2\n)\n\n# Stream for selection\nselection_stream = streams.Selection1D()\n\ndef get_selected_data(index):\n    if index:\n        return world.iloc[index[0]]\n    return None\n\n# Get info about selected region\nselected_info = hv.DynamicMap(\n    lambda index: hv.Text(0, 0, str(get_selected_data(index))),\n    streams=[selection_stream]\n)\n```\n\n### 5. Vector and Raster Layers\n\n```python\n# Multiple layers\nterrain = gvts.Stamen.Terrain.apply.opts(alpha=0.3)\npoints = gv.Points(cities_gdf, kdims=['longitude', 'latitude'])\nlines = gv.Lines(routes_gdf, kdims=['longitude', 'latitude'])\n\n# Compose layers\nmap_composition = terrain * lines * points\n\n# Faceted geographic display\nfaceted_maps = gv.Polygons(world, vdims=['name', 'continent']).facet('continent')\n```\n\n### 6. Hexbin and Rasterized Aggregation\n\n```python\n# Hexbin aggregation for point data\nhexbin = gv.HexTiles(cities_gdf).opts(\n    cmap='viridis',\n    colorbar=True,\n    height=600,\n    width=800\n)\n\n# With tile background\nmap_hexbin = gvts.CartoDEM.apply.opts(alpha=0.4) * hexbin\n```\n\n## Spatial Analysis Workflows\n\n### 1. Spatial Joins\n\n```python\n# Combine different geographic layers\npoints_gdf = gpd.GeoDataFrame(\n    cities_data,\n    geometry=gpd.points_from_xy(cities_data['longitude'], cities_data['latitude']),\n    crs='EPSG:4326'\n)\n\nregions_gdf = gpd.read_file('regions.geojson')\n\n# Spatial join: which cities are in which regions\njoined = gpd.sjoin(points_gdf, regions_gdf, how='left', predicate='within')\n\n# Visualize result\njoined_map = gv.Points(joined, kdims=['longitude', 'latitude']) * \\\n             gv.Polygons(regions_gdf)\n```\n\n### 2. Buffer and Proximity Analysis\n\n```python\nfrom shapely.geometry import Point\n\n# Create buffer zones\nbuffered = cities_gdf.copy()\nbuffered['geometry'] = buffered.geometry.buffer(1.0)  # 1 degree\n\n# Visualize buffered regions\nbuffers = gv.Polygons(buffered).opts(fill_alpha=0.3)\npoints = gv.Points(cities_gdf)\n\nproximity_map = gvts.CartoDEM.apply.opts(alpha=0.3) * buffers * points\n```\n\n### 3. Distance and Route Analysis\n\n```python\n# Calculate distances between cities\nfrom shapely.geometry import LineString\n\nroutes = []\nfor i in range(len(cities_gdf) - 1):\n    start = cities_gdf.geometry.iloc[i]\n    end = cities_gdf.geometry.iloc[i + 1]\n    route = LineString([start, end])\n    distance = start.distance(end)\n    routes.append({'geometry': route, 'distance': distance})\n\nroutes_gdf = gpd.GeoDataFrame(routes, crs='EPSG:4326')\n\n# Visualize routes\nroute_lines = gv.Lines(routes_gdf, vdims=['distance']).opts(\n    color=gv.dim('distance').norm(),\n    cmap='plasma'\n)\n```\n\n## Tile Providers and Basemaps\n\n```python\n# Available tile providers\nfrom geoviews import tile_providers as gvts\n\n# Different styles\nopenstreetmap = gvts.OpenStreetMap.Mapnik\nsatellite = gvts.ESRI.WorldImagery\nterrain = gvts.Stamen.Terrain\ntoner = gvts.Stamen.Toner\n\n# Use with visualization\nmap_with_osm = gvts.OpenStreetMap.Mapnik * gv.Points(cities_gdf)\n\n# Custom styling\nbase_map = gvts.CartoDEM.apply.opts(\n    alpha=0.5,\n    xaxis=None,\n    yaxis=None\n)\n```\n\n## Best Practices\n\n### 1. Coordinate Reference Systems\n```python\n# Always specify and manage CRS\ngdf = gpd.read_file('data.geojson')\nprint(gdf.crs)\n\n# Reproject if necessary\ngdf_projected = gdf.to_crs('EPSG:3857')  # Web Mercator\n\n# When creating GeoDataFrame\ngdf = gpd.GeoDataFrame(\n    data,\n    geometry=gpd.points_from_xy(lon, lat),\n    crs='EPSG:4326'  # WGS84\n)\n```\n\n### 2. Large Dataset Optimization\n```python\n# Use rasterization for dense point clouds\nfrom holoviews.operation.datashader import rasterize\n\npoints = gv.Points(large_gdf, kdims=['x', 'y'])\nrasterized = rasterize(points)\n\n# Use tile-based rendering for massive datasets\n# Consider breaking into GeoJSON tiles\n```\n\n### 3. Interactive Map Design\n```python\n# Combine multiple interaction tools\nmap_viz = gv.Polygons(gdf).opts(\n    tools=['hover', 'box_select', 'tap'],\n    hover_fill_color='yellow',\n    hover_fill_alpha=0.2,\n    selection_fill_color='red'\n)\n\n# Add complementary visualizations\nstatistics = hv.Text(0, 0, '')  # Update based on selection\nmap_and_stats = hv.Column(map_viz, statistics)\n```\n\n### 4. Color and Scale Management\n```python\n# Use perceptually uniform colormaps\nfrom colorcet import cm\n\nmap_viz = gv.Polygons(gdf, vdims=['value']).opts(\n    color=gv.dim('value').norm(),\n    cmap=cm['viridis'],\n    colorbar=True,\n    clim=(vmin, vmax)\n)\n```\n\n## Common Patterns\n\n### Pattern 1: Multi-Layer Map Dashboard\n```python\ndef create_map_dashboard(layers_dict):\n    base_map = gvts.CartoDEM.apply.opts(alpha=0.4)\n    layers = [gv.Polygons(layers_dict[name]) for name in layers_dict]\n    return base_map * hv.Overlay(layers)\n```\n\n### Pattern 2: Dynamic Filtering Map\n```python\nfrom holoviews import DynamicMap, streams\n\nfilter_stream = streams.Stream.define('filter', year=2020)\n\ndef update_map(year):\n    filtered_gdf = world[world['year'] == year]\n    return gv.Polygons(filtered_gdf, vdims=['name', 'value'])\n\ndmap = DynamicMap(update_map, streams=[filter_stream])\n```\n\n### Pattern 3: Clustered Points Map\n```python\ndef create_clustered_map(points_gdf, zoom_levels=[1, 5, 10, 20]):\n    # Use hexbin for aggregation at different scales\n    aggregated = gv.HexTiles(points_gdf, aggregation='count')\n    return aggregated.opts(responsive=True)\n```\n\n## Integration with Other HoloViz Tools\n\n- **Panel**: Embed maps in web dashboards\n- **hvPlot**: Quick geographic plotting with `.hvplot(geo=True)`\n- **HoloViews**: Underlying visualization framework\n- **Datashader**: Efficient rendering for massive geographic datasets\n- **Param**: Parameter-driven map updates\n\n## Common Use Cases\n\n1. **Real Estate Analysis**: Property locations and market data\n2. **Climate Analysis**: Temperature, precipitation spatial patterns\n3. **Infrastructure Planning**: Network and facility location analysis\n4. **Epidemiology**: Disease spread and hotspot visualization\n5. **Transportation Analysis**: Route optimization and traffic patterns\n6. **Environmental Monitoring**: Land use, vegetation, water quality\n\n## Troubleshooting\n\n### Issue: Map Not Displaying\n- Verify CRS is correctly specified\n- Check coordinates are in correct order (longitude, latitude)\n- Ensure geometry objects are valid with `gdf.is_valid.all()`\n\n### Issue: Performance Problems with Large Datasets\n- Use rasterization for dense points\n- Simplify geometries with `gdf.geometry.simplify(tolerance)`\n- Use tile-based rendering or data pagination\n- Consider reducing zoom levels\n\n### Issue: Inaccurate Spatial Analysis\n- Verify CRS consistency across all layers\n- Use appropriate CRS for distance calculations\n- Check topology validity before operations\n- Test on sample data first\n\n## Resources\n\n- [GeoViews Documentation](https://geoviews.org)\n- [GeoPandas Documentation](https://geopandas.org)\n- [GeoJSON Specification](https://geojson.org)\n- [EPSG Coordinate Reference Systems](https://epsg.io)\n- [Cartopy for Advanced Cartography](https://scitools.org.uk/cartopy)\n",
        "plugins/holoviz-expert/skills/lumen-ai/SKILL.md": "---\nname: lumen-ai\ndescription: Master AI-powered natural language data exploration with Lumen AI. Use this skill when building conversational data analysis interfaces, enabling natural language queries to databases, creating custom AI agents for domain-specific analytics, implementing RAG with document context, or deploying self-service analytics with LLM-generated SQL and visualizations.\ncompatibility: Requires lumen >= 0.10.0 (with AI support), panel >= 1.3.0, openai or anthropic or other LLM provider libraries. Supports OpenAI, Anthropic Claude, Google Gemini, Mistral, and local models via Ollama or LlamaCPP.\n---\n\n# Lumen AI Skill\n\n## Overview\n\nLumen AI is an open-source, agent-based framework for conversational data exploration. Users ask questions in plain English and receive visualizations, SQL queries, and insights automatically generated by large language models.\n\n### What is Lumen AI?\n\nLumen AI translates natural language queries into:\n- SQL queries for database exploration\n- Interactive visualizations\n- Statistical summaries\n- Custom domain-specific analyses\n- Data-driven insights\n\n### Key Features\n\n- **Natural Language Interface**: Ask questions in plain English\n- **Multi-LLM Support**: OpenAI, Anthropic, Google, Mistral, local models\n- **Agent Architecture**: Specialized agents for SQL, charts, analyses\n- **Extensible**: Custom agents, tools, and analyses\n- **Privacy-Focused**: Full local deployment option\n- **No Vendor Lock-in**: Switch LLM providers with configuration change\n\n### Lumen AI vs Lumen Dashboards\n\n| Feature | Lumen AI | Lumen Dashboards |\n|---------|----------|------------------|\n| **Interface** | Conversational, natural language | Declarative YAML |\n| **Use Case** | Ad-hoc exploration, varying questions | Fixed dashboards, repeated views |\n| **Users** | Non-technical users, self-service | Developers, dashboard builders |\n| **Cost** | LLM API costs | No LLM costs |\n| **Flexibility** | High - generates any query | Fixed - predefined views |\n\n**Use Lumen AI when**:\n- Users need ad-hoc data exploration\n- Questions vary and aren't predictable\n- Enabling self-service analytics\n- Reducing analyst backlog\n\n**Use Lumen Dashboards when**:\n- Dashboard structure is fixed\n- Same visualizations needed repeatedly\n- No LLM costs desired\n- Full control over outputs needed\n\n## Quick Start\n\n### Installation\n\n```bash\n# Install Lumen with AI support\npip install lumen[ai]\n\n# Install LLM provider (choose one or more)\npip install openai        # OpenAI\npip install anthropic     # Anthropic Claude\n```\n\n### Launch Built-in Interface\n\n```bash\n# Set API key\nexport OPENAI_API_KEY=\"sk-...\"\n\n# Launch with dataset\nlumen-ai serve data/sales.csv\n\n# Or with database\nlumen-ai serve \"postgresql://user:pass@localhost/mydb\"\n```\n\n### Python API - Basic Example\n\n```python\nimport lumen.ai as lmai\nimport panel as pn\nfrom lumen.sources.duckdb import DuckDBSource\n\npn.extension()\n\n# Configure LLM\nlmai.llm.llm_type = \"anthropic\"\nlmai.llm.model = \"claude-3-5-sonnet-20241022\"\n\n# Load data\nsource = DuckDBSource(\n    tables=[\"./data/sales.csv\", \"./data/customers.csv\"]\n)\n\n# Create UI\nui = lmai.ExplorerUI(\n    source=source,\n    title=\"Sales Analytics AI\"\n)\n\nui.servable()\n```\n\n### Example Queries\n\nOnce running, try queries like:\n- \"What tables are available?\"\n- \"Show me total sales by region\"\n- \"Create a scatter plot of price vs quantity\"\n- \"What were the top 10 products last month?\"\n- \"Calculate average order value per customer\"\n\n## Core Concepts\n\n### 1. Agents\n\nSpecialized components that handle specific tasks:\n\n- **TableListAgent**: Shows available tables and schemas\n- **ChatAgent**: General conversation and summaries\n- **SQLAgent**: Generates and executes SQL queries\n- **hvPlotAgent**: Creates interactive visualizations\n- **VegaLiteAgent**: Publication-quality charts\n- **AnalysisAgent**: Custom domain-specific analyses\n\n**See**: [Built-in Agents Reference](../../resources/lumen-ai/agents-reference.md) for complete agent documentation.\n\n### 2. LLM Providers\n\nLumen AI works with multiple LLM providers:\n\n**Cloud Providers**:\n- OpenAI (GPT-4o, GPT-4o-mini)\n- Anthropic (Claude 3.5 Sonnet, Claude 3 Opus/Haiku)\n- Google (Gemini 1.5 Pro/Flash)\n- Mistral (Mistral Large/Medium/Small)\n\n**Local Models**:\n- Ollama (Llama 3.1, Mistral, CodeLlama)\n- LlamaCPP (custom models)\n\n**See**: [LLM Provider Configuration](../../resources/lumen-ai/llm-providers.md) for setup details and provider comparison.\n\n### 3. Memory and Context\n\nAgents share a memory system:\n- Query results persist across interactions\n- Agents can build on previous work\n- Context maintained throughout conversation\n\n### 4. Tools\n\nExtend agent capabilities:\n- **DocumentLookup**: RAG for document context\n- **TableLookup**: Schema and metadata access\n- **Custom Tools**: External APIs, calculations, etc.\n\n**See**: [Custom Tools Guide](../../resources/lumen-ai/custom-tools.md) for building tools.\n\n## Common Patterns\n\n### Pattern 1: Basic Analytics Interface\n\n```python\nimport lumen.ai as lmai\nfrom lumen.sources.duckdb import DuckDBSource\n\n# Configure LLM\nlmai.llm.llm_type = \"openai\"\nlmai.llm.model = \"gpt-4o\"\n\n# Load data\nsource = DuckDBSource(tables=[\"sales.csv\"])\n\n# Create UI\nui = lmai.ExplorerUI(\n    source=source,\n    title=\"Business Analytics\"\n)\n\nui.servable()\n```\n\n### Pattern 2: With Document Context (RAG)\n\n```python\nsource = DuckDBSource(\n    tables=[\"sales.csv\", \"products.parquet\"],\n    documents=[\n        \"./docs/data_dictionary.pdf\",\n        \"./docs/business_rules.md\"\n    ]\n)\n\nui = lmai.ExplorerUI(\n    source=source,\n    tools=[lmai.tools.DocumentLookup]\n)\n```\n\nAgents will automatically search documents for context when needed.\n\n### Pattern 3: Custom Agent\n\n```python\nfrom lumen.ai.agents import Agent\nimport param\n\nclass SentimentAgent(Agent):\n    \"\"\"Analyze sentiment in text data.\"\"\"\n\n    requires = param.List(default=[\"current_source\"])\n    provides = param.List(default=[\"sentiment_analysis\"])\n\n    purpose = \"\"\"\n    Analyzes sentiment in text columns.\n    Use when user asks about sentiment, emotions, or tone.\n    Keywords: sentiment, emotion, positive, negative, tone\n    \"\"\"\n\n    async def respond(self, query: str):\n        # Agent implementation\n        source = self.memory[\"current_source\"]\n        # ... analyze sentiment ...\n        yield \"Sentiment analysis results...\"\n\n# Use custom agent\nui = lmai.ExplorerUI(\n    source=source,\n    agents=[SentimentAgent, lmai.agents.ChatAgent]\n)\n```\n\n**See**: [Custom Agents Guide](../../resources/lumen-ai/custom-agents.md) for detailed development guide.\n\n### Pattern 4: Custom Analysis\n\n```python\nfrom lumen.ai.analyses import Analysis\nfrom lumen.pipeline import Pipeline\nimport param\n\nclass CohortAnalysis(Analysis):\n    \"\"\"Customer cohort retention analysis.\"\"\"\n\n    columns = param.List(default=[\n        'customer_id', 'signup_date', 'purchase_date'\n    ])\n\n    def __call__(self, pipeline: Pipeline):\n        # Cohort analysis logic\n        df = pipeline.data\n        # ... calculate cohorts ...\n        return results\n\n# Register analysis\nui = lmai.ExplorerUI(\n    source=source,\n    agents=[\n        lmai.agents.AnalysisAgent(analyses=[CohortAnalysis])\n    ]\n)\n```\n\n**See**: [Custom Analyses Guide](../../resources/lumen-ai/custom-analyses.md) for examples.\n\n### Pattern 5: Multi-Source Data\n\n```python\nfrom lumen.sources.duckdb import DuckDBSource\n\nsource = DuckDBSource(\n    tables={\n        \"sales\": \"./data/sales.parquet\",\n        \"customers\": \"./data/customers.csv\",\n        \"products\": \"https://data.company.com/products.csv\"\n    }\n)\n\nui = lmai.ExplorerUI(source=source)\n```\n\n## Configuration\n\n### LLM Selection\n\nQuick reference for choosing LLM:\n\n| Use Case | Provider | Model | Why |\n|----------|----------|-------|-----|\n| Production analytics | OpenAI | gpt-4o | Best balance |\n| Complex SQL | Anthropic | claude-3-5-sonnet | Superior reasoning |\n| High volume | OpenAI | gpt-4o-mini | Cost-effective |\n| Sensitive data | Ollama | llama3.1 | Local only |\n| Development | OpenAI | gpt-4o-mini | Fast, cheap |\n\n**See**: [LLM Provider Configuration](../../resources/lumen-ai/llm-providers.md) for complete setup.\n\n### Agent Selection\n\n```python\n# Use only specific agents\nagents = [\n    lmai.agents.TableListAgent,\n    lmai.agents.SQLAgent,\n    lmai.agents.hvPlotAgent,\n    # Exclude VegaLiteAgent if not needed\n]\n\nui = lmai.ExplorerUI(source=source, agents=agents)\n```\n\n### Coordinator Types\n\n**DependencyResolver** (default): Recursively resolves agent dependencies\n```python\nui = lmai.ExplorerUI(source=source, coordinator=\"dependency\")\n```\n\n**Planner**: Creates execution plan upfront\n```python\nui = lmai.ExplorerUI(source=source, coordinator=\"planner\")\n```\n\n### UI Customization\n\n```python\nui = lmai.ExplorerUI(\n    source=source,\n    title=\"Custom Analytics AI\",\n    accent_color=\"#00aa41\",\n    suggestions=[\n        \"Show me revenue trends\",\n        \"What are the top products?\",\n        \"Create customer segmentation\"\n    ]\n)\n```\n\n## Best Practices\n\n### 1. Provider Selection\n\n- **Production**: Use Anthropic Claude 3.5 Sonnet or GPT-4o\n- **Development**: Use GPT-4o-mini for cost savings\n- **Sensitive data**: Use Ollama for local deployment\n\n### 2. Security\n\n```python\nimport os\n\n# ✅ Good: Environment variables\nlmai.llm.api_key = os.getenv(\"OPENAI_API_KEY\")\n\n# ❌ Bad: Hardcoded secrets\nlmai.llm.api_key = \"sk-...\"\n```\n\n### 3. Performance\n\n```python\n# Limit table sizes for exploration\nsource = DuckDBSource(\n    tables=[\"large_table.parquet\"],\n    table_kwargs={\"large_table\": {\"nrows\": 100000}}\n)\n```\n\n### 4. User Experience\n\n```python\n# Provide example queries\nui = lmai.ExplorerUI(\n    source=source,\n    suggestions=[\n        \"Show me revenue trends\",\n        \"Top 10 products by sales\",\n        \"Customer segmentation analysis\"\n    ]\n)\n```\n\n## Deployment\n\n### Development\n\n```bash\nlumen-ai serve app.py --autoreload --show\n```\n\n### Production\n\n```bash\npanel serve app.py \\\n  --port 80 \\\n  --num-procs 4 \\\n  --allow-websocket-origin=analytics.company.com\n```\n\n### Docker\n\n```dockerfile\nFROM python:3.11-slim\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\nCOPY app.py data/ ./\nCMD [\"panel\", \"serve\", \"app.py\", \"--port\", \"5006\", \"--address\", \"0.0.0.0\"]\n```\n\n**See**: [Deployment Guide](../../resources/lumen-ai/deployment.md) for production deployment, Docker, Kubernetes, and security.\n\n## Troubleshooting\n\n### LLM Not Responding\n\n```python\n# Check API key\nimport os\nprint(os.getenv(\"OPENAI_API_KEY\"))\n\n# Test connection\ncurl https://api.openai.com/v1/models \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n```\n\n### Agent Not Selected\n\n```python\n# Debug which agent was selected\nprint(ui.agent_manager.last_selected_agent)\n\n# View agent purposes\nfor agent in ui.agents:\n    print(f\"{agent.__class__.__name__}: {agent.purpose}\")\n```\n\n### SQL Generation Errors\n\n- Add data dictionary as document for context\n- Provide example queries in agent prompts\n- Check table schemas match query expectations\n\n**See**: [Troubleshooting Guide](../../resources/lumen-ai/troubleshooting.md) for complete troubleshooting reference.\n\n## Progressive Learning Path\n\n### Level 1: Getting Started\n1. Install and launch built-in interface\n2. Try example queries\n3. Configure LLM provider\n\n**Resources**:\n- [LLM Provider Configuration](../../resources/lumen-ai/llm-providers.md)\n\n### Level 2: Python API\n1. Create basic ExplorerUI\n2. Configure agents and tools\n3. Add document context (RAG)\n\n**Resources**:\n- [Built-in Agents Reference](../../resources/lumen-ai/agents-reference.md)\n\n### Level 3: Customization\n1. Build custom agents\n2. Create custom analyses\n3. Add custom tools\n\n**Resources**:\n- [Custom Agents Guide](../../resources/lumen-ai/custom-agents.md)\n- [Custom Analyses Guide](../../resources/lumen-ai/custom-analyses.md)\n- [Custom Tools Guide](../../resources/lumen-ai/custom-tools.md)\n\n### Level 4: Production\n1. Deploy with authentication\n2. Implement monitoring\n3. Scale horizontally\n\n**Resources**:\n- [Deployment Guide](../../resources/lumen-ai/deployment.md)\n\n## Additional Resources\n\n### Documentation\n- **[LLM Provider Configuration](../../resources/lumen-ai/llm-providers.md)** - Setup for OpenAI, Anthropic, local models\n- **[Built-in Agents Reference](../../resources/lumen-ai/agents-reference.md)** - Complete agent documentation\n- **[Custom Agents Guide](../../resources/lumen-ai/custom-agents.md)** - Build specialized agents\n- **[Custom Analyses Guide](../../resources/lumen-ai/custom-analyses.md)** - Domain-specific analyses\n- **[Custom Tools Guide](../../resources/lumen-ai/custom-tools.md)** - Extend agent capabilities\n- **[Deployment Guide](../../resources/lumen-ai/deployment.md)** - Production deployment\n- **[Troubleshooting Guide](../../resources/lumen-ai/troubleshooting.md)** - Common issues and solutions\n\n### External Links\n- [Lumen AI Documentation](https://lumen.holoviz.org/lumen_ai/)\n- [Lumen AI Getting Started](https://lumen.holoviz.org/lumen_ai/getting_started/using_lumen_ai.html)\n- [GitHub Repository](https://github.com/holoviz/lumen)\n- [Community Discourse](https://discourse.holoviz.org)\n\n## Use Cases\n\n### Business Analytics\n- Ad-hoc revenue analysis\n- Customer behavior exploration\n- Sales performance tracking\n- Market segmentation\n\n### Data Science\n- Exploratory data analysis\n- Quick statistical summaries\n- Hypothesis testing\n- Pattern discovery\n\n### Operations\n- Real-time monitoring queries\n- Anomaly investigation\n- Performance metrics\n- Incident analysis\n\n### Self-Service Analytics\n- Enabling business users\n- Reducing analyst backlog\n- Democratizing data access\n- Maintaining governance\n\n## Summary\n\nLumen AI transforms data exploration through natural language interfaces powered by LLMs.\n\n**Strengths**:\n- No SQL or coding required for users\n- Flexible LLM support (cloud and local)\n- Extensible architecture\n- Privacy-focused options\n- Reduces analyst workload\n\n**Ideal for**:\n- Ad-hoc data exploration\n- Non-technical users\n- Rapid insights\n- Self-service analytics\n\n**Consider alternatives when**:\n- Fixed dashboards needed → [Lumen Dashboards](../lumen-dashboards/SKILL.md)\n- No LLM budget → Traditional BI tools\n- Highly custom logic → [Panel Dashboards](../panel-dashboards/SKILL.md)\n\n## Related Skills\n\n- **[Lumen Dashboards](../lumen-dashboards/SKILL.md)** - Declarative YAML dashboards\n- **[Panel Dashboards](../panel-dashboards/SKILL.md)** - Interactive dashboard development\n- **[Plotting Fundamentals](../plotting-fundamentals/SKILL.md)** - Quick plotting with hvPlot\n",
        "plugins/holoviz-expert/skills/lumen-dashboards/SKILL.md": "---\nname: lumen-dashboards\ndescription: Master declarative, no-code data dashboards with Lumen YAML specifications. Use this skill when building standard data exploration dashboards, connecting multiple data sources (files, databases, APIs), creating interactive filters and cross-filtering, designing responsive layouts with indicators and charts, or enabling rapid dashboard prototyping without writing code.\ncompatibility: Requires lumen >= 0.10.0, panel >= 1.3.0, holoviews >= 1.18.0, param >= 2.0.0. Supports PostgreSQL, DuckDB, SQLite, CSV, Parquet, Excel, and REST API data sources.\n---\n\n# Lumen Dashboards Skill\n\n## Overview\n\nLumen is a declarative framework for creating data dashboards through YAML specifications. Build interactive data exploration dashboards without writing code - just configuration.\n\n### What is Lumen?\n\nLumen provides a declarative approach to building data dashboards:\n\n- **No-code dashboards**: Define everything in YAML\n- **Data pipelines**: Sources → Transforms → Views\n- **Interactive exploration**: Built-in filters and cross-filtering\n- **Component library**: Reusable sources, transforms, views\n- **Live updates**: Auto-reload and real-time data\n\n### Lumen vs Panel vs Lumen AI\n\n| Feature | Lumen Dashboards | Panel | Lumen AI |\n|---------|------------------|-------|----------|\n| **Approach** | Declarative YAML | Imperative Python | Conversational |\n| **Code Required** | No | Yes | No |\n| **Use Case** | Fixed dashboards | Custom apps | Ad-hoc exploration |\n| **Flexibility** | Medium | High | High |\n| **Development Speed** | Very fast | Medium | Very fast |\n\n**Use Lumen when**:\n- Building standard data exploration dashboards\n- Working with non-programmers\n- Want rapid prototyping with configuration\n- Need reproducible dashboard specifications\n\n**Use Panel when**:\n- Need fine-grained control over components\n- Building custom application logic\n- Creating novel interactions\n\n**Use Lumen AI when**:\n- Users need ad-hoc exploration\n- Questions vary unpredictably\n- Enabling self-service analytics\n\n## Quick Start\n\n### Installation\n\n```bash\npip install lumen\n```\n\n### Your First Dashboard\n\n**File: `dashboard.yaml`**\n\n```yaml\nsources:\n  data:\n    type: file\n    tables:\n      penguins: https://datasets.holoviz.org/penguins/v1/penguins.csv\n\npipelines:\n  main:\n    source: data\n    table: penguins\n\n    filters:\n      - type: widget\n        field: species\n\nlayouts:\n  - title: Penguin Explorer\n    views:\n      - type: hvplot\n        pipeline: main\n        kind: scatter\n        x: bill_length_mm\n        y: bill_depth_mm\n        by: species\n        title: Bill Dimensions\n```\n\n**Launch:**\n```bash\nlumen serve dashboard.yaml --show\n```\n\n## Core Concepts\n\n### 1. Sources\n\nData sources provide tables for your dashboard.\n\n**Supported sources**:\n- **File**: CSV, Parquet, Excel, JSON\n- **Database**: PostgreSQL, DuckDB, SQLite\n- **REST API**: JSON endpoints\n- **Intake**: Data catalogs\n\n**Quick example**:\n```yaml\nsources:\n  mydata:\n    type: file\n    tables:\n      sales: ./data/sales.csv\n```\n\n**See**: [Data Sources Reference](../../resources/lumen-dashboards/sources.md) for comprehensive source configuration.\n\n### 2. Pipelines\n\nPipelines define data flows: Source → Filters → Transforms → Views\n\n**Basic pipeline**:\n```yaml\npipelines:\n  sales_pipeline:\n    source: mydata\n    table: sales\n\n    filters:\n      - type: widget\n        field: region\n\n    transforms:\n      - type: aggregate\n        by: ['category']\n        aggregate:\n          total_sales: {revenue: sum}\n```\n\n**Components**:\n- **Filters**: Interactive widgets for user input\n- **Transforms**: Data manipulation (filter, aggregate, sort, SQL)\n- **Views**: Visualizations and tables\n\n### 3. Filters\n\nAdd interactive controls:\n\n```yaml\nfilters:\n  # Dropdown select\n  - type: widget\n    field: category\n\n  # Multi-select\n  - type: widget\n    field: region\n    multiple: true\n\n  # Date range\n  - type: widget\n    field: date\n    widget: date_range_slider\n\n  # Numeric slider\n  - type: param\n    parameter: min_revenue\n    widget_type: FloatSlider\n    start: 0\n    end: 100000\n```\n\n### 4. Transforms\n\nProcess data in pipelines:\n\n**Common transforms**:\n- `columns`: Select specific columns\n- `query`: Filter rows with pandas query\n- `aggregate`: Group and aggregate\n- `sort`: Sort data\n- `sql`: Custom SQL queries\n\n**Example**:\n```yaml\ntransforms:\n  - type: columns\n    columns: ['date', 'region', 'revenue']\n\n  - type: query\n    query: \"revenue > 1000\"\n\n  - type: aggregate\n    by: ['region']\n    aggregate:\n      total: {revenue: sum}\n      avg: {revenue: mean}\n```\n\n**See**: [Data Transforms Reference](../../resources/lumen-dashboards/transforms.md) for all transform types.\n\n### 5. Views\n\nVisualize data:\n\n**View types**:\n- `hvplot`: Interactive plots (line, scatter, bar, etc.)\n- `table`: Data tables\n- `indicator`: KPI metrics\n- `vega`: Vega-Lite specifications\n- `altair`: Altair charts\n- `plotly`: Plotly charts\n\n**Example**:\n```yaml\nviews:\n  - type: hvplot\n    pipeline: main\n    kind: line\n    x: date\n    y: revenue\n    by: category\n\n  - type: indicator\n    pipeline: main\n    field: total_revenue\n    title: Total Sales\n    format: '${value:,.0f}'\n```\n\n**See**: [Views Reference](../../resources/lumen-dashboards/views.md) for all view types and options.\n\n### 6. Layouts\n\nArrange views on the page:\n\n```yaml\nlayouts:\n  - title: Overview\n    layout: [[0, 1, 2], [3], [4, 5]]  # Grid positions\n    views:\n      - type: indicator\n        # View 0 config...\n\n      - type: indicator\n        # View 1 config...\n\n      - type: hvplot\n        # View 2 config...\n```\n\n**Layout types**:\n- **Grid**: `[[0, 1], [2, 3]]`\n- **Tabs**: Multiple layouts become tabs\n- **Responsive**: Adapts to screen size\n\n**See**: [Layouts Reference](../../resources/lumen-dashboards/layouts.md) for advanced layout patterns.\n\n## Common Patterns\n\n### Pattern 1: KPI Dashboard\n\n```yaml\nsources:\n  metrics:\n    type: file\n    tables:\n      data: ./metrics.csv\n\npipelines:\n  kpis:\n    source: metrics\n    table: data\n    transforms:\n      - type: aggregate\n        aggregate:\n          total_revenue: {revenue: sum}\n          total_orders: {orders: sum}\n          avg_order_value: {revenue: mean}\n\nlayouts:\n  - title: KPIs\n    layout: [[0, 1, 2]]\n    views:\n      - type: indicator\n        pipeline: kpis\n        field: total_revenue\n        format: '${value:,.0f}'\n\n      - type: indicator\n        pipeline: kpis\n        field: total_orders\n        format: '{value:,.0f}'\n\n      - type: indicator\n        pipeline: kpis\n        field: avg_order_value\n        format: '${value:.2f}'\n```\n\n### Pattern 2: Filtered Exploration\n\n```yaml\npipelines:\n  explorer:\n    source: mydata\n    table: sales\n\n    filters:\n      - type: widget\n        field: region\n        label: Region\n\n      - type: widget\n        field: category\n        label: Category\n        multiple: true\n\n      - type: widget\n        field: date\n        widget: date_range_slider\n\n    views:\n      - type: hvplot\n        kind: scatter\n        x: price\n        y: quantity\n        by: category\n\n      - type: table\n        page_size: 20\n```\n\n### Pattern 3: Multi-Source Dashboard\n\n```yaml\nsources:\n  sales_db:\n    type: postgres\n    connection_string: postgresql://localhost/sales\n    tables: [orders, customers]\n\n  inventory_file:\n    type: file\n    tables:\n      stock: ./inventory.csv\n\npipelines:\n  sales_pipeline:\n    source: sales_db\n    table: orders\n\n  inventory_pipeline:\n    source: inventory_file\n    table: stock\n```\n\n### Pattern 4: Cross-Filtering\n\n```yaml\npipelines:\n  main:\n    source: data\n    table: sales\n\n    filters:\n      - type: widget\n        field: region\n\nlayouts:\n  - title: Analysis\n    views:\n      # Clicking bar filters other views\n      - type: hvplot\n        pipeline: main\n        kind: bar\n        x: category\n        y: revenue\n        selection_group: category_filter\n\n      # Responds to selection above\n      - type: hvplot\n        pipeline: main\n        kind: scatter\n        x: price\n        y: quantity\n        selection_group: category_filter\n```\n\n### Pattern 5: SQL Transform\n\n```yaml\ntransforms:\n  - type: sql\n    query: |\n      SELECT\n        region,\n        category,\n        SUM(revenue) as total_revenue,\n        COUNT(*) as order_count,\n        AVG(revenue) as avg_order_value\n      FROM table\n      WHERE date >= '2024-01-01'\n      GROUP BY region, category\n      HAVING total_revenue > 10000\n      ORDER BY total_revenue DESC\n```\n\n## Python API\n\nWhile Lumen is designed for YAML, you can also use Python:\n\n```python\nfrom lumen.sources import FileSource\nfrom lumen.pipeline import Pipeline\nfrom lumen.views import hvPlotView\nfrom lumen.dashboard import Dashboard\nimport panel as pn\n\n# Create source\nsource = FileSource(tables={'sales': './data/sales.csv'})\n\n# Create pipeline\npipeline = Pipeline(source=source, table='sales')\n\n# Create view\nview = hvPlotView(\n    pipeline=pipeline,\n    kind='scatter',\n    x='price',\n    y='quantity'\n)\n\n# Create dashboard\ndashboard = Dashboard(\n    pipelines={'main': pipeline},\n    layouts=[view]\n)\n\n# Serve\ndashboard.servable()\n```\n\n**See**: [Python API Reference](../../resources/lumen-dashboards/python-api.md) for detailed API usage.\n\n## Configuration\n\n### Global Config\n\n```yaml\nconfig:\n  title: My Dashboard\n  theme: dark  # or 'default', 'material'\n  sizing_mode: stretch_width\n  logo: ./logo.png\n  favicon: ./favicon.ico\n  layout: column  # or 'grid', 'tabs'\n```\n\n### Themes\n\n```yaml\nconfig:\n  theme: material\n  theme_json:\n    palette:\n      primary: '#00aa41'\n      secondary: '#616161'\n```\n\n### Authentication\n\n```bash\n# Serve with auth\nlumen serve dashboard.yaml \\\n  --oauth-provider=generic \\\n  --oauth-key=${OAUTH_KEY} \\\n  --oauth-secret=${OAUTH_SECRET}\n```\n\n## Deployment\n\n### Development\n\n```bash\n# Local with auto-reload\nlumen serve dashboard.yaml --autoreload --show\n\n# Specific port\nlumen serve dashboard.yaml --port 5007\n```\n\n### Production\n\n```bash\n# Production server\npanel serve dashboard.yaml \\\n  --port 80 \\\n  --num-procs 4 \\\n  --allow-websocket-origin=analytics.company.com\n```\n\n### Docker\n\n```dockerfile\nFROM python:3.11-slim\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\nCOPY dashboard.yaml data/ ./\nCMD [\"lumen\", \"serve\", \"dashboard.yaml\", \"--port\", \"5006\", \"--address\", \"0.0.0.0\"]\n```\n\n**See**: [Deployment Guide](../../resources/lumen-dashboards/deployment.md) for production deployment best practices.\n\n## Best Practices\n\n### 1. Source Organization\n\n```yaml\n# ✅ Good: Descriptive names\nsources:\n  sales_database:\n    type: postgres\n    tables: [orders, customers]\n\n  inventory_files:\n    type: file\n    tables:\n      stock: ./inventory.csv\n\n# ❌ Bad: Generic names\nsources:\n  db1:\n    type: postgres\n  file1:\n    type: file\n```\n\n### 2. Pipeline Reusability\n\n```yaml\n# Define reusable pipelines\npipelines:\n  base_sales:\n    source: data\n    table: sales\n    filters:\n      - type: widget\n        field: region\n\n  summary_sales:\n    pipeline: base_sales  # Extends base_sales\n    transforms:\n      - type: aggregate\n        by: ['category']\n        aggregate:\n          total: {revenue: sum}\n```\n\n### 3. Performance\n\n```yaml\n# Limit data size for large tables\nsources:\n  bigdata:\n    type: postgres\n    tables:\n      events: \"SELECT * FROM events WHERE date >= '2024-01-01' LIMIT 100000\"\n```\n\n### 4. User Experience\n\n```yaml\n# Provide clear labels and formatting\nfilters:\n  - type: widget\n    field: region\n    label: \"Sales Region\"  # Clear label\n\nviews:\n  - type: indicator\n    field: revenue\n    title: \"Total Revenue\"\n    format: '${value:,.0f}'  # Formatted display\n```\n\n## Troubleshooting\n\n### Dashboard Won't Load\n\n```bash\n# Check YAML syntax\npython -c \"import yaml; yaml.safe_load(open('dashboard.yaml'))\"\n\n# Run with debug logging\nlumen serve dashboard.yaml --log-level=debug\n```\n\n### Data Not Showing\n\n- Verify data source path/connection\n- Check table names match YAML config\n- Ensure columns referenced exist in data\n\n### Performance Issues\n\n- Limit query results (use SQL WHERE clauses)\n- Reduce number of rows displayed\n- Use aggregation before visualization\n\n**See**: [Troubleshooting Guide](../../resources/lumen-dashboards/troubleshooting.md) for common issues.\n\n## Progressive Learning Path\n\n### Level 1: Basics\n1. Create simple file-based dashboard\n2. Add filters\n3. Create basic views\n\n**Resources**:\n- Quick Start (this doc)\n- [Data Sources Reference](../../resources/lumen-dashboards/sources.md)\n\n### Level 2: Transforms\n1. Filter and aggregate data\n2. Use SQL transforms\n3. Chain multiple transforms\n\n**Resources**:\n- [Data Transforms Reference](../../resources/lumen-dashboards/transforms.md)\n\n### Level 3: Advanced Layouts\n1. Multi-page dashboards\n2. Cross-filtering\n3. Custom themes\n\n**Resources**:\n- [Layouts Reference](../../resources/lumen-dashboards/layouts.md)\n- [Views Reference](../../resources/lumen-dashboards/views.md)\n\n### Level 4: Production\n1. Database integration\n2. Authentication\n3. Deployment\n\n**Resources**:\n- [Deployment Guide](../../resources/lumen-dashboards/deployment.md)\n\n## Additional Resources\n\n### Documentation\n- **[Data Sources Reference](../../resources/lumen-dashboards/sources.md)** - All source types and configuration\n- **[Data Transforms Reference](../../resources/lumen-dashboards/transforms.md)** - Complete transform reference\n- **[Views Reference](../../resources/lumen-dashboards/views.md)** - All visualization types\n- **[Layouts Reference](../../resources/lumen-dashboards/layouts.md)** - Layout patterns and organization\n- **[Python API Reference](../../resources/lumen-dashboards/python-api.md)** - Programmatic dashboard creation\n- **[Deployment Guide](../../resources/lumen-dashboards/deployment.md)** - Production deployment\n- **[Examples](../../resources/lumen-dashboards/examples.md)** - Complete dashboard examples\n- **[Troubleshooting Guide](../../resources/lumen-dashboards/troubleshooting.md)** - Common issues\n\n### External Links\n- [Lumen Documentation](https://lumen.holoviz.org/)\n- [Lumen Gallery](https://lumen.holoviz.org/gallery/)\n- [GitHub Repository](https://github.com/holoviz/lumen)\n- [Community Discourse](https://discourse.holoviz.org)\n\n## Use Cases\n\n### Business Intelligence\n- Executive dashboards\n- Sales analytics\n- Financial reporting\n- Operational metrics\n\n### Data Exploration\n- Dataset overview\n- Interactive filtering\n- Drill-down analysis\n- Comparative views\n\n### Real-Time Monitoring\n- Live data feeds\n- Alert dashboards\n- System metrics\n- Performance tracking\n\n### Reporting\n- Scheduled reports\n- Standardized views\n- Shareable dashboards\n- Embedded analytics\n\n## Summary\n\nLumen enables rapid dashboard development through declarative YAML specifications.\n\n**Strengths**:\n- No Python code required\n- Fast development cycle\n- Reproducible specifications\n- Built-in interactivity\n- Standard dashboard patterns\n\n**Ideal for**:\n- Fixed dashboard layouts\n- Standard data patterns\n- Non-programmer dashboard creators\n- Rapid prototyping\n\n**Consider alternatives when**:\n- Need custom application logic → [Panel Dashboards](../panel-dashboards/SKILL.md)\n- Need ad-hoc exploration → [Lumen AI](../lumen-ai/SKILL.md)\n- Building novel interactions → [Panel Dashboards](../panel-dashboards/SKILL.md)\n\n## Related Skills\n\n- **[Lumen AI](../lumen-ai/SKILL.md)** - Conversational data exploration\n- **[Panel Dashboards](../panel-dashboards/SKILL.md)** - Custom Python dashboards\n- **[Plotting Fundamentals](../plotting-fundamentals/SKILL.md)** - Quick plotting with hvPlot\n",
        "plugins/holoviz-expert/skills/panel-dashboards/SKILL.md": "---\nname: panel-dashboards\ndescription: Master interactive dashboard and application development with Panel and Param. Use this skill when building custom web applications with Python, creating reactive component-based UIs, handling file uploads and real-time data streaming, implementing multi-page applications, or developing enterprise dashboards with templates and theming.\ncompatibility: Requires panel >= 1.3.0, param >= 2.0.0, bokeh >= 3.0.0, tornado (web server). Supports Material Design, Bootstrap, and custom themes.\n---\n\n# Panel Dashboards Skill\n\n## Overview\n\nMaster interactive dashboard and application development with Panel and Param. This skill covers building web applications, component systems, and responsive dashboards that scale from simple tools to complex enterprise applications.\n\n## Dependencies\n\n- panel >= 1.3.0\n- param >= 2.0.0\n- bokeh >= 3.0.0\n- tornado (web server)\n\n## Core Capabilities\n\n### 1. Component-Based Application Development\n\nPanel provides a comprehensive component library for building rich user interfaces:\n\n- **Layout Components**: Row, Column, Tabs, Accordion, GridBox\n- **Input Widgets**: TextInput, Select, DatePicker, RangeSlider, FileInput\n- **Output Display**: Markdown, HTML, DataFrame, Image, Video\n- **Container Controls**: Card, Alert, ProgressBar\n\n```python\nimport panel as pn\nimport param\n\npn.extension('material')\n\nclass Dashboard(param.Parameterized):\n    title = param.String(default=\"My Dashboard\")\n    refresh_interval = param.Integer(default=5000, bounds=(1000, 60000))\n\n    @param.depends('refresh_interval')\n    def view(self):\n        return pn.Column(\n            pn.pane.Markdown(f\"## {self.title}\"),\n            pn.param.ObjectSelector.from_param(self.param.refresh_interval),\n            pn.Row(self._metric_card(), self._chart())\n        )\n\n    def _metric_card(self):\n        return pn.Card(\n            \"Active Users\",\n            \"42,531\",\n            title=\"Metrics\",\n            styles={\"background\": \"#E8F4F8\"}\n        )\n\n    def _chart(self):\n        return pn.pane.Markdown(\"## Chart Placeholder\")\n\ndashboard = Dashboard()\napp = dashboard.view\n\nif __name__ == '__main__':\n    app.servable()\n```\n\n### 2. Reactive Pipelines and Watchers\n\nPanel excels at creating reactive, event-driven applications:\n\n```python\nimport panel as pn\nimport param\nimport numpy as np\n\nclass DataAnalyzer(param.Parameterized):\n    data_source = param.Selector(default='random', objects=['random', 'file'])\n    num_points = param.Integer(default=100, bounds=(10, 1000))\n    aggregation = param.Selector(default='mean', objects=['mean', 'sum', 'std'])\n\n    @param.depends('data_source', 'num_points', watch=True)\n    def _refresh_data(self):\n        if self.data_source == 'random':\n            self.data = np.random.randn(self.num_points)\n\n    @param.depends('data_source', 'num_points', 'aggregation')\n    def summary(self):\n        if not hasattr(self, 'data'):\n            self._refresh_data()\n\n        agg_func = getattr(np, self.aggregation)\n        result = agg_func(self.data)\n        return f\"{self.aggregation.capitalize()}: {result:.2f}\"\n\nanalyzer = DataAnalyzer()\n\npn.extension('material')\napp = pn.Column(\n    pn.param.ParamMethod.from_param(analyzer.param),\n    analyzer.summary\n)\n```\n\n### 3. Template and Theming\n\nPanel supports multiple templates for different application styles:\n\n- **BootstrapTemplate**: Modern Bootstrap-based design\n- **MaterialTemplate**: Material Design principles\n- **VanillaTemplate**: Clean, minimal design\n- **DarkTemplate**: Dark mode optimized\n\n```python\nimport panel as pn\nimport param\n\npn.extension('material')\n\nclass Config(param.Parameterized):\n    theme = param.Selector(default='dark', objects=['dark', 'light'])\n    sidebar_width = param.Integer(default=300, bounds=(200, 500))\n\nconfig = Config()\n\ntemplate = pn.template.MaterialTemplate(\n    title=\"Advanced Dashboard\",\n    header_background=\"#2E3440\",\n    sidebar_width=config.sidebar_width,\n    main=[pn.pane.Markdown(\"# Main Content\")],\n    sidebar=[\n        pn.param.ParamMethod.from_param(config.param)\n    ]\n)\n\ntemplate.servable()\n```\n\n### 4. File Handling and Data Upload\n\nBuild applications that accept file uploads and process data:\n\n```python\nimport panel as pn\nimport pandas as pd\n\nfile_input = pn.widgets.FileInput(accept='.csv,.xlsx')\n\n@pn.depends(file_input)\ndef process_file(file_input):\n    if file_input is None:\n        return pn.pane.Markdown(\"### Upload a file to proceed\")\n\n    if file_input.filename.endswith('.csv'):\n        df = pd.read_csv(file_input.value)\n    else:\n        df = pd.read_excel(file_input.value)\n\n    return pn.Column(\n        pn.pane.Markdown(f\"### {file_input.filename}\"),\n        pn.pane.DataFrame(df.head(10), width=800),\n        pn.pane.Markdown(f\"Shape: {df.shape}\")\n    )\n\npn.extension('material')\napp = pn.Column(\n    pn.pane.Markdown(\"# Data Upload\"),\n    file_input,\n    process_file\n)\n```\n\n### 5. Real-time Streaming and Updates\n\nCreate dashboards with live data updates:\n\n```python\nimport panel as pn\nimport param\nimport numpy as np\nfrom datetime import datetime\n\nclass LiveMonitor(param.Parameterized):\n    update_frequency = param.Integer(default=1000, bounds=(100, 5000))\n    is_running = param.Boolean(default=False)\n    current_value = param.Number(default=0)\n\n    def __init__(self, **params):\n        super().__init__(**params)\n        self._data_history = []\n\n    def start(self):\n        self.is_running = True\n        pn.state.add_periodic_callback(\n            self._update,\n            period=self.update_frequency,\n            start=True\n        )\n\n    def _update(self):\n        if self.is_running:\n            self.current_value = np.random.randn() + self.current_value * 0.95\n            self._data_history.append({\n                'timestamp': datetime.now(),\n                'value': self.current_value\n            })\n\n    def get_plot(self):\n        if not self._data_history:\n            return pn.pane.Markdown(\"No data yet...\")\n\n        import holoviews as hv\n        df = pd.DataFrame(self._data_history)\n        return hv.Curve(df, 'timestamp', 'value').opts(responsive=True)\n\nmonitor = LiveMonitor()\napp = pn.Column(\n    pn.widgets.Button.from_param(monitor.param.is_running, label=\"Start/Stop\"),\n    monitor.get_plot\n)\n```\n\n## Best Practices\n\n### 1. Parameter Organization\n- Use Param classes to organize all configurable state\n- Leverage type hints and validation in parameter definitions\n- Use watchers for side effects, depends for reactive updates\n\n### 2. Responsive Design\n- Always use `responsive=True` and `sizing_mode` options\n- Test on multiple screen sizes\n- Use GridBox or CSS Grid for complex layouts\n\n### 3. Performance Optimization\n- Lazy-load expensive components using Tabs or Accordion\n- Use caching decorators for expensive computations\n- Implement pagination for large datasets\n- Stream data rather than loading all at once\n\n### 4. Code Organization\n- Separate UI concerns from business logic using Param classes\n- Create reusable component functions\n- Use templates for consistent application structure\n- Organize related components into modules\n\n### 5. Error Handling\n- Validate input parameters with Param bounds and selectors\n- Provide clear error messages to users\n- Use try-catch blocks around external API calls\n- Implement graceful degradation for failed operations\n\n## Common Patterns\n\n### Pattern 1: Multi-Page Application\n```python\nclass MultiPageApp(param.Parameterized):\n    page = param.Selector(default='home', objects=['home', 'analytics', 'settings'])\n\n    @param.depends('page')\n    def current_view(self):\n        pages = {\n            'home': self._home_page,\n            'analytics': self._analytics_page,\n            'settings': self._settings_page,\n        }\n        return pages[self.page]()\n```\n\n### Pattern 2: Form with Validation\n```python\nclass FormValidator(param.Parameterized):\n    email = param.String(default='')\n    age = param.Integer(default=0, bounds=(0, 150))\n\n    @param.depends('email', 'age')\n    def validation_message(self):\n        if not self.email or '@' not in self.email:\n            return pn.pane.Alert(\"Invalid email\", alert_type='danger')\n        if self.age < 18:\n            return pn.pane.Alert(\"Must be 18+\", alert_type='warning')\n        return pn.pane.Alert(\"Validation passed!\", alert_type='success')\n```\n\n### Pattern 3: Data Filtering Pipeline\n```python\nclass FilteredDataView(param.Parameterized):\n    df = param.Parameter(default=None)\n    column_filter = param.String(default='')\n    value_filter = param.String(default='')\n\n    @param.depends('column_filter', 'value_filter')\n    def filtered_data(self):\n        if self.column_filter not in self.df.columns:\n            return self.df\n        return self.df[self.df[self.column_filter].astype(str).str.contains(self.value_filter)]\n```\n\n## Integration with HoloViz Ecosystem\n\nPanel integrates seamlessly with other HoloViz libraries:\n\n- **HoloViews**: Embed interactive plots in Panel applications\n- **hvPlot**: Quick plotting within Panel dashboards\n- **Param**: Unified parameter system for all interactivity\n- **GeoViews**: Embed geographic visualizations\n- **Datashader**: Render large datasets with Panel\n\n## Common Use Cases\n\n1. **Real-time Monitoring Dashboards**: Live metrics and KPI displays\n2. **Data Exploration Tools**: Interactive data analysis applications\n3. **Configuration Interfaces**: Complex multi-step configuration UIs\n4. **Data Input Applications**: Validated form-based data collection\n5. **Report Viewers**: Interactive report generation and browsing\n6. **Administrative Interfaces**: Internal tools for data management\n\n## Troubleshooting\n\n### Issue: Slow Dashboard Load Times\n- Lazy-load components using Tabs or Accordion\n- Implement caching with `@pn.cache` decorator\n- Move expensive computations to initialization\n- Profile with Panel's built-in profiling tools\n\n### Issue: Unresponsive UI During Computation\n- Use `pn.state.add_periodic_callback` for background tasks\n- Implement loading indicators during processing\n- Break long computations into smaller steps\n- Consider async/await patterns\n\n### Issue: Memory Leaks in Long-Running Apps\n- Clean up event listeners with `pn.state.clear_caches()`\n- Monitor callback registration and removal\n- Limit data history sizes in streaming applications\n- Profile with memory profilers\n\n## Resources\n\n- [Panel Documentation](https://panel.holoviz.org)\n- [Panel Gallery](https://panel.holoviz.org/gallery/index.html)\n- [Param Documentation](https://param.holoviz.org)\n- [Panel Discourse Community](https://discourse.holoviz.org)\n",
        "plugins/holoviz-expert/skills/parameterization/SKILL.md": "---\nname: parameterization\ndescription: Master declarative parameter systems with Param for type-safe configuration. Use this skill when building parameterized classes with automatic validation, creating reactive dependencies with @param.depends, implementing watchers for side effects, auto-generating UIs from parameters, or organizing application configuration with hierarchical parameter structures.\ncompatibility: Requires param >= 2.0.0, panel >= 1.3.0 (for UI generation), numpy >= 1.15.0, pandas >= 1.0.0\n---\n\n# Parameterization Skill\n\n## Overview\n\nMaster declarative parameter systems with Param and dynamic UI generation. This skill covers building flexible, type-safe, and auto-validated application logic.\n\n## Dependencies\n\n- param >= 2.0.0\n- panel >= 1.3.0 (for UI generation)\n- numpy >= 1.15.0\n- pandas >= 1.0.0\n\n## Core Capabilities\n\n### 1. Parameter Basics\n\nParam provides a framework for parameterized objects with automatic validation:\n\n```python\nimport param\nimport numpy as np\n\nclass DataProcessor(param.Parameterized):\n    # Basic parameters\n    name = param.String(default='Processor', doc='Name of processor')\n    count = param.Integer(default=10, bounds=(1, 1000), doc='Number of items')\n    scale = param.Number(default=1.0, bounds=(0.1, 10.0), doc='Scale factor')\n\n    # String choices\n    method = param.Selector(default='mean', objects=['mean', 'median', 'sum'])\n\n    # Boolean flag\n    normalize = param.Boolean(default=False)\n\n    # List or array\n    tags = param.List(default=[], item_type=str)\n    data_array = param.Array(default=np.array([]))\n\n# Instantiate and use\nprocessor = DataProcessor()\nprint(f\"Name: {processor.name}, Count: {processor.count}\")\n\n# Validate parameters automatically\nprocessor.count = 500  # OK\nprocessor.count = 2000  # Raises error: out of bounds\n```\n\n### 2. Advanced Parameter Types\n\n```python\nclass AdvancedConfig(param.Parameterized):\n    # Date/time parameters\n    date = param.Date(default='2024-01-01', doc='Start date')\n    time = param.Time(default='12:00', doc='Start time')\n    datetime = param.DateTime(default='2024-01-01 12:00:00')\n\n    # File/path parameters\n    input_file = param.Path(default=None, doc='Input file path')\n    output_dir = param.Fspath(default='.', doc='Output directory')\n\n    # Range parameter\n    value_range = param.Range(default=(0, 10), bounds=(0, 100))\n\n    # Color parameter\n    color = param.Color(default='#FF0000')\n\n    # JSON/Dict parameter\n    config = param.Dict(default={}, per_instance=True)\n\n    # DataFrame parameter\n    dataframe = param.Parameter(default=None)\n```\n\n### 3. Dynamic Dependencies with @param.depends\n\n```python\nclass DataAnalyzer(param.Parameterized):\n    data_source = param.Selector(\n        default='random',\n        objects=['random', 'sine', 'exponential']\n    )\n    amplitude = param.Number(default=1.0, bounds=(0.1, 10.0))\n    frequency = param.Number(default=1.0, bounds=(0.1, 10.0))\n    size = param.Integer(default=100, bounds=(10, 10000))\n\n    @param.depends('data_source', 'amplitude', 'frequency', 'size')\n    def get_data(self):\n        \"\"\"Automatically called when any dependency changes\"\"\"\n        np.random.seed(42)\n        x = np.linspace(0, 2*np.pi, self.size)\n\n        if self.data_source == 'random':\n            return x, np.random.randn(self.size) * self.amplitude\n        elif self.data_source == 'sine':\n            return x, self.amplitude * np.sin(self.frequency * x)\n        else:  # exponential\n            return x, self.amplitude * np.exp(self.frequency * x / 10)\n\n    @param.depends('data_source', 'amplitude', 'frequency', 'size')\n    def summary(self):\n        \"\"\"Display summary that updates automatically\"\"\"\n        x, y = self.get_data()\n        return f\"Mean: {y.mean():.2f}, Std: {y.std():.2f}\"\n\n# Use in application\nanalyzer = DataAnalyzer()\nprint(analyzer.summary)\n\n# Change parameters\nanalyzer.amplitude = 2.0\nanalyzer.frequency = 2.0\nprint(analyzer.summary)  # Updated automatically\n```\n\n### 4. Watchers for Side Effects\n\nWatchers allow you to trigger code when parameters change:\n\n```python\nclass DataModel(param.Parameterized):\n    filename = param.String(default='data.csv')\n    data = param.Parameter(default=None, precedence=-1)\n\n    @param.depends('filename', watch=True)\n    def _load_data(self):\n        \"\"\"Automatically load data when filename changes\"\"\"\n        print(f\"Loading {self.filename}...\")\n        # Load file here\n        self.data = pd.read_csv(self.filename)\n\n    # Alternative: explicit watch\n    def __init__(self, **params):\n        super().__init__(**params)\n        self.param.watch(self._on_count_change, 'count')\n\n    def _on_count_change(self, event):\n        print(f\"Count changed from {event.old} to {event.new}\")\n\nmodel = DataModel()\nmodel.filename = 'new_file.csv'  # Triggers _load_data automatically\n```\n\n### 5. Custom Validation\n\n```python\nclass ValidatedModel(param.Parameterized):\n    email = param.String(default='', doc='Email address')\n    age = param.Integer(default=0, bounds=(0, 150))\n    password = param.String(default='')\n\n    @param.validators('email')\n    def validate_email(self, value):\n        if '@' not in value:\n            raise ValueError('Invalid email address')\n        return value\n\n    @param.validators('password')\n    def validate_password(self, value):\n        if len(value) < 8:\n            raise ValueError('Password must be at least 8 characters')\n        return value\n\n    def validate_constraint(self):\n        \"\"\"Cross-parameter validation\"\"\"\n        if self.age < 18 and self.email == 'restricted@example.com':\n            raise ValueError('Minors cannot use this email')\n\nmodel = ValidatedModel()\nmodel.email = 'invalid'  # Raises ValueError\nmodel.password = 'short'  # Raises ValueError\n```\n\n### 6. Hierarchical Parameterization\n\n```python\nclass DatabaseConfig(param.Parameterized):\n    host = param.String(default='localhost')\n    port = param.Integer(default=5432, bounds=(1, 65535))\n    username = param.String(default='user')\n    password = param.String(default='')\n\nclass AppConfig(param.Parameterized):\n    app_name = param.String(default='MyApp')\n    debug = param.Boolean(default=False)\n    database = param.Parameter(default=DatabaseConfig())\n\n    @param.depends('database.host', watch=True)\n    def _on_db_change(self):\n        print(f\"Database configuration changed to {self.database.host}\")\n\nconfig = AppConfig()\nconfig.database.host = 'production.db'  # Triggers watch on parent\n```\n\n## Integration with Panel UI\n\n### 1. Automatic UI Generation\n\n```python\nimport panel as pn\n\nclass DashboardConfig(param.Parameterized):\n    title = param.String(default='Dashboard')\n    refresh_interval = param.Integer(default=5000, bounds=(1000, 60000))\n    metric = param.Selector(default='revenue', objects=['revenue', 'users', 'engagement'])\n    show_legend = param.Boolean(default=True)\n\nconfig = DashboardConfig()\n\n# Panel automatically creates UI widgets from parameters\nwidgets = pn.param.ParamMethod.from_param(config.param)\n\n# Or create individual widgets\ntitle_input = pn.param.TextInput.from_param(config.param.title)\nmetric_select = pn.param.Selector.from_param(config.param.metric)\ninterval_slider = pn.param.IntSlider.from_param(config.param.refresh_interval)\n```\n\n### 2. Reactive Dashboard\n\n```python\nimport holoviews as hv\n\nclass InteractiveDashboard(param.Parameterized):\n    metric = param.Selector(default='sales', objects=['sales', 'users', 'traffic'])\n    time_range = param.Range(default=(0, 100), bounds=(0, 100))\n    aggregation = param.Selector(default='daily', objects=['hourly', 'daily', 'weekly'])\n\n    def __init__(self, data):\n        super().__init__()\n        self.data = data\n\n    @param.depends('metric', 'time_range', 'aggregation')\n    def plot(self):\n        filtered = self.data[\n            (self.data['metric'] == self.metric) &\n            (self.data['value'] >= self.time_range[0]) &\n            (self.data['value'] <= self.time_range[1])\n        ]\n        return filtered.hvplot.line(title=f'{self.metric} ({self.aggregation})')\n\n    @param.depends('metric')\n    def summary(self):\n        subset = self.data[self.data['metric'] == self.metric]\n        return f\"Mean: {subset['value'].mean():.2f}\"\n\ndashboard = InteractiveDashboard(data_df)\n\npn.extension('material')\napp = pn.Column(\n    pn.param.ParamMethod.from_param(dashboard.param),\n    pn.Column(dashboard.plot, dashboard.summary)\n)\n```\n\n## Best Practices\n\n### 1. Parameter Organization\n```python\n# Group related parameters\nclass VideoConfig(param.Parameterized):\n    # Video inputs\n    input_file = param.Path(doc='Input video file')\n    start_frame = param.Integer(default=0, bounds=(0, None))\n    end_frame = param.Integer(default=None, bounds=(0, None))\n\n    # Processing\n    scale = param.Number(default=1.0, bounds=(0.1, 2.0))\n    quality = param.Selector(default='high', objects=['low', 'medium', 'high'])\n\n    # Output\n    output_format = param.Selector(default='mp4', objects=['mp4', 'webm', 'mov'])\n    output_path = param.Path(default='output/')\n```\n\n### 2. Use Appropriate Parameter Types\n```python\n# Bad: string for everything\nconfig = param.Parameterized(\n    count=param.String(default='10'),  # Wrong type\n    flag=param.String(default='true')  # Wrong type\n)\n\n# Good: specific types with validation\nclass ProperConfig(param.Parameterized):\n    count = param.Integer(default=10, bounds=(1, 100))\n    flag = param.Boolean(default=True)\n```\n\n### 3. Leverage Watchers for Side Effects\n```python\nclass FileProcessor(param.Parameterized):\n    input_path = param.Path(default=None)\n    output_path = param.Path(default=None)\n\n    # Use watch for file I/O and external effects\n    @param.depends('input_path', watch=True)\n    def _process_file(self):\n        if self.input_path and self.input_path.exists():\n            self._load_and_process()\n\n    # Use depends for computation\n    @param.depends('input_path')\n    def file_size(self):\n        if self.input_path:\n            return self.input_path.stat().st_size\n        return None\n```\n\n### 4. Documentation and Help\n```python\nclass WellDocumentedModel(param.Parameterized):\n    threshold = param.Number(\n        default=0.5,\n        bounds=(0, 1),\n        doc='Classification threshold. Values above this are classified as positive.',\n        label='Classification Threshold',\n        precedence=1  # Show first\n    )\n\n    @param.depends('threshold')\n    def summary(self):\n        \"\"\"Return human-readable summary\"\"\"\n        return f\"Using threshold: {self.threshold}\"\n\n# Users can access help\nhelp(WellDocumentedModel)\nmodel = WellDocumentedModel()\nprint(model.param)  # Display all parameters with documentation\n```\n\n## Common Patterns\n\n### Pattern 1: Configuration Object\n```python\nclass AppConfiguration(param.Parameterized):\n    \"\"\"Central configuration object for entire application\"\"\"\n    debug = param.Boolean(default=False)\n    log_level = param.Selector(default='INFO', objects=['DEBUG', 'INFO', 'WARNING', 'ERROR'])\n    theme = param.Selector(default='light', objects=['light', 'dark'])\n\n    @classmethod\n    def from_file(cls, path):\n        \"\"\"Load configuration from file\"\"\"\n        import json\n        with open(path) as f:\n            config = json.load(f)\n        return cls(**config)\n```\n\n### Pattern 2: Multi-Step Wizard\n```python\nclass Wizard(param.Parameterized):\n    step = param.Integer(default=0, bounds=(0, 3))\n\n    # Step 1: Data input\n    data_source = param.Selector(default='file', objects=['file', 'database', 'api'])\n\n    # Step 2: Processing\n    algorithm = param.Selector(default='mean', objects=['mean', 'median'])\n\n    # Step 3: Output\n    format = param.Selector(default='csv', objects=['csv', 'json', 'parquet'])\n\n    @param.depends('step')\n    def current_step_view(self):\n        if self.step == 0:\n            return f\"Select data source: {self.data_source}\"\n        elif self.step == 1:\n            return f\"Choose algorithm: {self.algorithm}\"\n        else:\n            return f\"Output format: {self.format}\"\n```\n\n### Pattern 3: Computed Parameters\n```python\nclass Statistics(param.Parameterized):\n    values = param.Array(default=np.array([]))\n\n    @property\n    def mean(self):\n        return np.mean(self.values)\n\n    @property\n    def std(self):\n        return np.std(self.values)\n\n    @param.depends('values')\n    def summary(self):\n        return f\"Mean: {self.mean:.2f}, Std: {self.std:.2f}\"\n```\n\n## Integration with HoloViz Ecosystem\n\n- **Panel**: Auto-generate UIs from parameters\n- **HoloViews**: Create parameter-driven visualizations\n- **hvPlot**: Quick plots responding to parameter changes\n- **Datashader**: Efficient rendering with parameterized aggregation\n\n## Common Use Cases\n\n1. **Configuration Management**: Centralized app configuration\n2. **Data Processing Pipelines**: Parameterized workflows\n3. **Scientific Simulations**: Configurable model parameters\n4. **Interactive Dashboards**: Auto-generated control panels\n5. **Machine Learning**: Hyperparameter tuning interfaces\n6. **Data Validation**: Type-safe data entry\n\n## Troubleshooting\n\n### Issue: Watcher Not Triggering\n- Use `watch=True` on the `@param.depends` decorator\n- Ensure parameter actually changes\n- Check parameter name matches exactly\n\n### Issue: Circular Dependencies\n- Avoid watchers that modify parameters they depend on\n- Use separate input and derived parameters\n- Consider separating concerns into different objects\n\n### Issue: Performance with Expensive Computations\n- Cache results with `@param.depends(..., cache_on=[])`\n- Use explicit parameter changes rather than constant updates\n- Profile with profilers to find bottlenecks\n\n## Resources\n\n- [Param Documentation](https://param.holoviz.org)\n- [Param User Guide](https://param.holoviz.org/user_guide/index.html)\n- [Panel Parameter Support](https://panel.holoviz.org/how_to/parameters/index.html)\n- [Param API Reference](https://param.holoviz.org/API/param.Parameterized.html)\n",
        "plugins/holoviz-expert/skills/plotting-fundamentals/SKILL.md": "---\nname: plotting-fundamentals\ndescription: Master quick plotting and interactive visualization with hvPlot. Use this skill when creating basic plots (line, scatter, bar, histogram, box), visualizing pandas DataFrames with minimal code, adding interactivity and hover tools, composing multiple plots in layouts, or generating publication-quality visualizations rapidly.\ncompatibility: Requires hvplot >= 0.9.0, holoviews >= 1.18.0, pandas >= 1.0.0, numpy >= 1.15.0, bokeh >= 3.0.0\n---\n\n# Plotting Fundamentals Skill\n\n## Overview\n\nMaster quick plotting and interactive visualization with hvPlot and HoloViews basics. This skill covers essential techniques for creating publication-quality plots with minimal code.\n\n## Dependencies\n\n- hvplot >= 0.9.0\n- holoviews >= 1.18.0\n- pandas >= 1.0.0\n- numpy >= 1.15.0\n- bokeh >= 3.0.0\n\n## Core Capabilities\n\n### 1. hvPlot Quick Plotting\n\nhvPlot provides an intuitive, pandas-like API for rapid visualization:\n\n```python\nimport hvplot.pandas\nimport pandas as pd\nimport numpy as np\n\n# Create sample data\ndf = pd.DataFrame({\n    'date': pd.date_range('2024-01-01', periods=100),\n    'sales': np.cumsum(np.random.randn(100)) + 100,\n    'region': np.random.choice(['North', 'South', 'East', 'West'], 100)\n})\n\n# Simple line plot\ndf.hvplot.line(x='date', y='sales', title='Sales Over Time')\n\n# Grouped plot\ndf.hvplot.line(x='date', y='sales', by='region', subplots=True)\n\n# Scatter with size and color\ndf.hvplot.scatter(x='sales', y='date', c='region', size=50)\n```\n\n### 2. Common Plot Types\n\n```python\n# Bar plot\ndf.hvplot.bar(x='region', y='sales', rot=45)\n\n# Histogram\ndf['sales'].hvplot.hist(bins=30, title='Sales Distribution')\n\n# Box plot\ndf.hvplot.box(y='sales', by='region')\n\n# Area plot\ndf.hvplot.area(x='date', y='sales')\n\n# KDE (Kernel Density Estimation)\ndf['sales'].hvplot.kde()\n\n# Hexbin (for large datasets)\ndf.hvplot.hexbin(x='sales', y='date', gridsize=20)\n```\n\n### 3. Customization Options\n\n```python\n# Apply consistent styling\nplot = df.hvplot.line(\n    x='date',\n    y='sales',\n    title='Sales Trend',\n    xlabel='Date',\n    ylabel='Sales ($)',\n    color='#2E86DE',\n    line_width=2,\n    height=400,\n    width=700,\n    responsive=True,\n    legend='top_left'\n)\n\n# Color mapping\ndf.hvplot.scatter(\n    x='sales',\n    y='date',\n    c='sales',\n    cmap='viridis',\n    s=100\n)\n\n# Multiple series\ndf.hvplot.line(\n    x='date',\n    y=['sales'],\n    title='Performance Metrics'\n)\n```\n\n### 4. Interactive Features\n\n```python\n# Hover information\ndf.hvplot.scatter(\n    x='sales',\n    y='date',\n    hover_cols=['region'],\n    tools=['hover', 'pan', 'wheel_zoom']\n)\n\n# Selection and linked views\nimport holoviews as hv\nscatter = df.hvplot.scatter(x='sales', y='date')\nscatter.opts(tools=['box_select'])\n\n# Responsive sizing\nplot = df.hvplot.line(\n    x='date',\n    y='sales',\n    responsive=True,\n    height=400\n)\n```\n\n### 5. Geographic Plotting with hvPlot\n\n```python\nimport geopandas as gpd\n\n# Quick geographic plot\ngdf = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\ngdf.hvplot(\n    c='pop_est',\n    cmap='viridis',\n    geo=True,\n    frame_width=600\n)\n\n# City points on map\ncities = gpd.GeoDataFrame({\n    'name': ['City A', 'City B'],\n    'geometry': [Point(0, 0), Point(1, 1)],\n    'population': [1000000, 500000]\n})\ncities.hvplot(\n    geo=True,\n    c='population',\n    size='population',\n    cmap='plasma'\n)\n```\n\n## HoloViews Fundamentals\n\n### 1. Basic Element Types\n\n```python\nimport holoviews as hv\nfrom holoviews import opts\n\n# Curve\ncurve = hv.Curve(df, 'date', 'sales')\n\n# Scatter\nscatter = hv.Scatter(df, 'sales', 'date')\n\n# Histogram\nhist = hv.Histogram(df['sales'].values)\n\n# Image (heatmap)\nimage = hv.Image(data)\n\n# Bars\nbars = hv.Bars(df, 'region', 'sales')\n\n# Text annotations\ntext = hv.Text(0.5, 0.5, 'Hello HoloViews')\n```\n\n### 2. Styling and Options\n\n```python\n# Using .opts() method\nplot = hv.Curve(df, 'date', 'sales').opts(\n    title='Sales Trend',\n    xlabel='Date',\n    ylabel='Sales',\n    color='#2E86DE',\n    line_width=2,\n    height=400,\n    width=700\n)\n\n# Using opts object\nopts_obj = opts.Curve(\n    title='Sales',\n    color='navy',\n    line_width=2\n)\nplot = hv.Curve(df, 'date', 'sales').opts(opts_obj)\n```\n\n### 3. Composing Visualizations\n\n```python\n# Overlaying multiple plots\noverlay = hv.Curve(df, 'date', 'sales') * hv.Scatter(df_subset, 'date', 'sales')\n\n# Side-by-side layouts\nlayout = hv.Curve(df1, 'date', 'sales') + hv.Scatter(df2, 'date', 'value')\n\n# Grid layouts\ngrid = (\n    (hv.Curve(data1) + hv.Scatter(data2)) /\n    (hv.Histogram(data3) + hv.Image(data4))\n)\n\n# Faceted views\nfaceted = hv.Curve(df, 'date', 'sales').facet('region')\n```\n\n### 4. Interactive Selection and Linking\n\n```python\n# Brush selection\ncurve_selectable = hv.Curve(df, 'date', 'sales').opts(\n    tools=['box_select'],\n    selection_fill_color='red',\n    nonselection_fill_alpha=0.2\n)\n\n# Dynamic linking with streams\nfrom holoviews import streams\n\n# Hover information\nhover = streams.Tap(source=scatter, transient=True)\n\n@hv.transform\ndef get_info(data):\n    if data.empty:\n        return hv.Text(0, 0, 'Hover to select')\n    return hv.Text(0, 0, f\"Point: {data.iloc[0].values}\")\n```\n\n## Best Practices\n\n### 1. Data Preparation\n- Always check data types before plotting\n- Handle missing values explicitly\n- Normalize columns for better visualization\n- Use appropriate data ranges\n\n### 2. Visual Design\n- Choose colors for accessibility (colorblind-friendly palettes)\n- Use title and axis labels\n- Include legends for multiple series\n- Maintain consistent styling across related plots\n\n### 3. Performance\n- Use datashader for datasets with >100k points\n- Downsample or aggregate before plotting\n- Use responsive=True for web dashboards\n- Cache expensive plot computations\n\n### 4. Code Organization\n```python\n# Create a plotting utility module\nclass PlotBuilder:\n    COLORS = {'primary': '#2E86DE', 'secondary': '#A23B72'}\n    DEFAULTS = {'height': 400, 'width': 700, 'responsive': True}\n\n    @staticmethod\n    def style_plot(plot, **kwargs):\n        return plot.opts(**{**PlotBuilder.DEFAULTS, **kwargs})\n\n# Usage\nstyled = PlotBuilder.style_plot(df.hvplot.line(x='date', y='sales'))\n```\n\n## Common Patterns\n\n### Pattern 1: Dashboard with Multiple Plots\n```python\ndef create_sales_dashboard(df):\n    return hv.Column(\n        df.hvplot.line(x='date', y='sales', title='Trend'),\n        df.hvplot.bar(x='region', y='sales', title='By Region'),\n        df['sales'].hvplot.hist(bins=20, title='Distribution')\n    )\n```\n\n### Pattern 2: Conditional Visualization\n```python\ndef plot_data(df, plot_type='line'):\n    if plot_type == 'line':\n        return df.hvplot.line(x='date', y='sales')\n    elif plot_type == 'scatter':\n        return df.hvplot.scatter(x='date', y='sales')\n    else:\n        return df.hvplot.bar(x='region', y='sales')\n```\n\n### Pattern 3: Multi-Series Plot with Legend\n```python\ndef plot_multiple_metrics(df, metrics):\n    plots = [df.hvplot.line(x='date', y=m, label=m) for m in metrics]\n    return hv.Overlay(plots)\n```\n\n## Integration with Other HoloViz Tools\n\n- **Panel**: Embed plots in dashboards\n- **HoloViews**: Advanced composition and interactivity\n- **Datashader**: Large dataset visualization\n- **Param**: Dynamic plot updates based on parameters\n\n## Common Use Cases\n\n1. **Time Series Analysis**: Trends, anomalies, forecasting\n2. **Comparative Analysis**: Category comparisons, rankings\n3. **Distribution Analysis**: Histograms, KDEs, box plots\n4. **Correlation Analysis**: Scatter plots, hexbins\n5. **Geographic Analysis**: Maps, regional data\n6. **Statistical Summaries**: Summary statistics with plots\n\n## Troubleshooting\n\n### Issue: Plot Won't Display\n- Ensure `hvplot.pandas` or `hvplot.xarray` is imported\n- Check data is not empty\n- Verify x and y columns exist in dataframe\n\n### Issue: Poor Performance with Large Data\n- Use datashader for >100k points\n- Implement aggregation or sampling\n- Use hexbin or rasterization\n\n### Issue: Unclear or Overlapping Labels\n- Rotate x-axis labels with `rot=45`\n- Use subplots with `by='column'`\n- Adjust figure size with height/width\n\n## Resources\n\n- [hvPlot Documentation](https://hvplot.holoviz.org)\n- [HoloViews Documentation](https://holoviews.org)\n- [HoloViews Gallery](https://holoviews.org/reference/index.html)\n- [Colorcet for Color Palettes](https://colorcet.holoviz.org)\n"
      },
      "plugins": [
        {
          "name": "holoviz-expert",
          "source": "./plugins/holoviz-expert",
          "description": "Expert-level guidance for building interactive data visualizations and dashboards with the HoloViz ecosystem. Covers Panel, HoloViews, hvPlot, GeoViews, Datashader, Lumen, Param, and Colorcet with integrated MCP server support for real-time library introspection.",
          "version": "1.1.0",
          "author": {
            "name": "HoloViz Community",
            "url": "https://holoviz.org"
          },
          "homepage": "https://github.com/cdcore09/holoviz-claude",
          "repository": "https://github.com/cdcore09/holoviz-claude",
          "license": "BSD-3-Clause",
          "keywords": [
            "visualization",
            "panel",
            "holoviews",
            "hvplot",
            "geoviews",
            "datashader",
            "lumen",
            "param",
            "colorcet",
            "dashboard",
            "interactive",
            "data-science",
            "geospatial",
            "ai-agents",
            "claude-plugins"
          ],
          "category": "data-science",
          "strict": false,
          "agents": [
            "./plugins/holoviz-expert/agents/panel-specialist.md",
            "./plugins/holoviz-expert/agents/visualization-designer.md",
            "./plugins/holoviz-expert/agents/data-engineer.md",
            "./plugins/holoviz-expert/agents/geo-spatial-expert.md"
          ],
          "skills": [
            "./plugins/holoviz-expert/skills/panel-dashboards",
            "./plugins/holoviz-expert/skills/plotting-fundamentals",
            "./plugins/holoviz-expert/skills/data-visualization",
            "./plugins/holoviz-expert/skills/geospatial-visualization",
            "./plugins/holoviz-expert/skills/advanced-rendering",
            "./plugins/holoviz-expert/skills/parameterization",
            "./plugins/holoviz-expert/skills/colormaps-styling",
            "./plugins/holoviz-expert/skills/lumen-dashboards",
            "./plugins/holoviz-expert/skills/lumen-ai"
          ],
          "categories": [
            "ai-agents",
            "claude-plugins",
            "colorcet",
            "dashboard",
            "data-science",
            "datashader",
            "geospatial",
            "geoviews",
            "holoviews",
            "hvplot",
            "interactive",
            "lumen",
            "panel",
            "param",
            "visualization"
          ],
          "install_commands": [
            "/plugin marketplace add cdcore09/holoviz-claude",
            "/plugin install holoviz-expert@holoviz-claude"
          ]
        }
      ]
    }
  ]
}