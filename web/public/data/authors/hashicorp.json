{
  "author": {
    "id": "hashicorp",
    "display_name": "HashiCorp",
    "type": "Organization",
    "avatar_url": "https://avatars.githubusercontent.com/u/761456?v=4",
    "url": "https://github.com/hashicorp",
    "bio": "Consistent workflows to provision, secure, connect, and run any infrastructure for any application.",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 5,
      "total_commands": 0,
      "total_skills": 13,
      "total_stars": 191,
      "total_forks": 17
    }
  },
  "marketplaces": [
    {
      "name": "hashicorp",
      "version": null,
      "description": "Official HashiCorp plugins and skills for Claude Code",
      "owner_info": {
        "name": "HashiCorp"
      },
      "keywords": [],
      "repo_full_name": "hashicorp/agent-skills",
      "repo_url": "https://github.com/hashicorp/agent-skills",
      "repo_description": null,
      "homepage": "",
      "signals": {
        "stars": 191,
        "forks": 17,
        "pushed_at": "2026-01-29T19:16:06Z",
        "created_at": "2025-11-08T02:07:20Z",
        "license": "MPL-2.0"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 2499
        },
        {
          "path": "packer",
          "type": "tree",
          "size": null
        },
        {
          "path": "packer/builders",
          "type": "tree",
          "size": null
        },
        {
          "path": "packer/builders/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "packer/builders/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 447
        },
        {
          "path": "packer/builders/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "packer/builders/skills/aws-ami-builder",
          "type": "tree",
          "size": null
        },
        {
          "path": "packer/builders/skills/aws-ami-builder/SKILL.md",
          "type": "blob",
          "size": 3663
        },
        {
          "path": "packer/builders/skills/azure-image-builder",
          "type": "tree",
          "size": null
        },
        {
          "path": "packer/builders/skills/azure-image-builder/SKILL.md",
          "type": "blob",
          "size": 4203
        },
        {
          "path": "packer/builders/skills/windows-builder",
          "type": "tree",
          "size": null
        },
        {
          "path": "packer/builders/skills/windows-builder/SKILL.md",
          "type": "blob",
          "size": 4635
        },
        {
          "path": "packer/hcp",
          "type": "tree",
          "size": null
        },
        {
          "path": "packer/hcp/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "packer/hcp/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 461
        },
        {
          "path": "packer/hcp/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "packer/hcp/skills/push-to-registry",
          "type": "tree",
          "size": null
        },
        {
          "path": "packer/hcp/skills/push-to-registry/SKILL.md",
          "type": "blob",
          "size": 4741
        },
        {
          "path": "terraform",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform/code-generation",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform/code-generation/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform/code-generation/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 855
        },
        {
          "path": "terraform/code-generation/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform/code-generation/skills/azure-verified-modules",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform/code-generation/skills/azure-verified-modules/SKILL.md",
          "type": "blob",
          "size": 16261
        },
        {
          "path": "terraform/code-generation/skills/terraform-style-guide",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform/code-generation/skills/terraform-style-guide/SKILL.md",
          "type": "blob",
          "size": 7469
        },
        {
          "path": "terraform/code-generation/skills/terraform-test",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform/code-generation/skills/terraform-test/SKILL.md",
          "type": "blob",
          "size": 40057
        },
        {
          "path": "terraform/module-generation",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform/module-generation/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform/module-generation/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 879
        },
        {
          "path": "terraform/module-generation/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform/module-generation/skills/refactor-module",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform/module-generation/skills/refactor-module/SKILL.md",
          "type": "blob",
          "size": 13404
        },
        {
          "path": "terraform/module-generation/skills/terraform-stacks",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform/module-generation/skills/terraform-stacks/SKILL.md",
          "type": "blob",
          "size": 14350
        },
        {
          "path": "terraform/module-generation/skills/terraform-stacks/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform/module-generation/skills/terraform-stacks/references/component-blocks.md",
          "type": "blob",
          "size": 12989
        },
        {
          "path": "terraform/module-generation/skills/terraform-stacks/references/deployment-blocks.md",
          "type": "blob",
          "size": 21920
        },
        {
          "path": "terraform/module-generation/skills/terraform-stacks/references/examples.md",
          "type": "blob",
          "size": 30849
        },
        {
          "path": "terraform/provider-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform/provider-development/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform/provider-development/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 544
        },
        {
          "path": "terraform/provider-development/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform/provider-development/skills/new-terraform-provider",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform/provider-development/skills/new-terraform-provider/SKILL.md",
          "type": "blob",
          "size": 896
        },
        {
          "path": "terraform/provider-development/skills/provider-actions",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform/provider-development/skills/provider-actions/SKILL.md",
          "type": "blob",
          "size": 13972
        },
        {
          "path": "terraform/provider-development/skills/provider-resources",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform/provider-development/skills/provider-resources/SKILL.md",
          "type": "blob",
          "size": 16698
        },
        {
          "path": "terraform/provider-development/skills/run-acceptance-tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "terraform/provider-development/skills/run-acceptance-tests/SKILL.md",
          "type": "blob",
          "size": 1751
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"hashicorp\",\n  \"owner\": {\n    \"name\": \"HashiCorp\"\n  },\n  \"metadata\": {\n    \"description\": \"Official HashiCorp plugins and skills for Claude Code\",\n    \"version\": \"1.0.0\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"terraform-code-generation\",\n      \"source\": \"./terraform/code-generation\",\n      \"description\": \"Terraform code generation skills including HCL generation, style guides, and testing.\",\n      \"version\": \"1.0.0\",\n      \"author\": {\n        \"name\": \"HashiCorp\"\n      },\n      \"keywords\": [\"terraform\", \"hcl\", \"infrastructure\", \"iac\", \"testing\", \"style-guide\"],\n      \"category\": \"integration\",\n      \"license\": \"MPL-2.0\",\n      \"strict\": false\n    },\n    {\n      \"name\": \"terraform-module-generation\",\n      \"source\": \"./terraform/module-generation\",\n      \"description\": \"Terraform module generation and refactoring skills including module design and Terraform Stacks.\",\n      \"version\": \"1.0.0\",\n      \"author\": {\n        \"name\": \"HashiCorp\"\n      },\n      \"keywords\": [\"terraform\", \"modules\", \"infrastructure\", \"iac\", \"stacks\", \"refactoring\"],\n      \"category\": \"integration\",\n      \"license\": \"MPL-2.0\",\n      \"strict\": false\n    },\n    {\n      \"name\": \"terraform-provider-development\",\n      \"source\": \"./terraform/provider-development\",\n      \"description\": \"Terraform provider development skills including resources, data sources, actions, and acceptance testing.\",\n      \"version\": \"1.0.0\",\n      \"author\": {\n        \"name\": \"HashiCorp\"\n      },\n      \"keywords\": [\"terraform\", \"provider\", \"plugin-framework\", \"resources\", \"testing\"],\n      \"category\": \"integration\",\n      \"license\": \"MPL-2.0\",\n      \"strict\": false\n    },\n    {\n      \"name\": \"packer-builders\",\n      \"source\": \"./packer/builders\",\n      \"description\": \"Packer builder skills for AWS, Azure, and Windows image creation.\",\n      \"version\": \"1.0.0\",\n      \"author\": {\n        \"name\": \"HashiCorp\"\n      },\n      \"keywords\": [\"packer\", \"aws\", \"azure\", \"windows\", \"ami\", \"image\", \"builder\"],\n      \"category\": \"integration\",\n      \"license\": \"MPL-2.0\",\n      \"strict\": false\n    },\n    {\n      \"name\": \"packer-hcp\",\n      \"source\": \"./packer/hcp\",\n      \"description\": \"HCP Packer registry integration for tracking and managing image metadata.\",\n      \"version\": \"1.0.0\",\n      \"author\": {\n        \"name\": \"HashiCorp\"\n      },\n      \"keywords\": [\"packer\", \"hcp-packer\", \"registry\", \"metadata\", \"image-tracking\"],\n      \"category\": \"integration\",\n      \"license\": \"MPL-2.0\",\n      \"strict\": false\n    }\n  ]\n}\n",
        "packer/builders/.claude-plugin/plugin.json": "{\n  \"name\": \"packer-builders\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Packer builder skills for AWS, Azure, and Windows image creation.\",\n  \"author\": {\n    \"name\": \"HashiCorp\",\n    \"url\": \"https://github.com/hashicorp\"\n  },\n  \"homepage\": \"https://developer.hashicorp.com/packer\",\n  \"repository\": \"https://github.com/hashicorp/agent-skills\",\n  \"license\": \"MPL-2.0\",\n  \"keywords\": [\"packer\", \"aws\", \"azure\", \"windows\", \"ami\", \"image\", \"builder\"]\n}\n",
        "packer/builders/skills/aws-ami-builder/SKILL.md": "---\nname: aws-ami-builder\ndescription: Build Amazon Machine Images (AMIs) with Packer using the amazon-ebs builder. Use when creating custom AMIs for EC2 instances.\n---\n\n# AWS AMI Builder\n\nBuild Amazon Machine Images (AMIs) using Packer's `amazon-ebs` builder.\n\n**Reference:** [Amazon EBS Builder](https://developer.hashicorp.com/packer/integrations/hashicorp/amazon/latest/components/builder/ebs)\n\n> **Note:** Building AMIs incurs AWS costs (EC2 instances, EBS storage, data transfer). Builds typically take 10-30 minutes depending on provisioning complexity.\n\n## Basic AMI Template\n\n```hcl\npacker {\n  required_plugins {\n    amazon = {\n      source  = \"github.com/hashicorp/amazon\"\n      version = \"~> 1.3\"\n    }\n  }\n}\n\nvariable \"region\" {\n  type    = string\n  default = \"us-west-2\"\n}\n\nlocals {\n  timestamp = regex_replace(timestamp(), \"[- TZ:]\", \"\")\n}\n\nsource \"amazon-ebs\" \"ubuntu\" {\n  region        = var.region\n  instance_type = \"t3.micro\"\n\n  source_ami_filter {\n    filters = {\n      name                = \"ubuntu/images/*ubuntu-jammy-22.04-amd64-server-*\"\n      root-device-type    = \"ebs\"\n      virtualization-type = \"hvm\"\n    }\n    most_recent = true\n    owners      = [\"099720109477\"] # Canonical\n  }\n\n  ssh_username = \"ubuntu\"\n  ami_name     = \"my-app-${local.timestamp}\"\n\n  tags = {\n    Name      = \"my-app\"\n    BuildDate = local.timestamp\n  }\n}\n\nbuild {\n  sources = [\"source.amazon-ebs.ubuntu\"]\n\n  provisioner \"shell\" {\n    inline = [\n      \"sudo apt-get update\",\n      \"sudo apt-get upgrade -y\",\n    ]\n  }\n}\n```\n\n## Common Source AMI Filters\n\n### Ubuntu 22.04 LTS\n```hcl\nsource_ami_filter {\n  filters = {\n    name                = \"ubuntu/images/*ubuntu-jammy-22.04-amd64-server-*\"\n    root-device-type    = \"ebs\"\n    virtualization-type = \"hvm\"\n  }\n  most_recent = true\n  owners      = [\"099720109477\"] # Canonical\n}\n```\n\n### Amazon Linux 2023\n```hcl\nsource_ami_filter {\n  filters = {\n    name                = \"al2023-ami-*-x86_64\"\n    root-device-type    = \"ebs\"\n    virtualization-type = \"hvm\"\n  }\n  most_recent = true\n  owners      = [\"amazon\"]\n}\n```\n\n## Multi-Region AMI\n\n```hcl\nsource \"amazon-ebs\" \"ubuntu\" {\n  region        = \"us-west-2\"\n  instance_type = \"t3.micro\"\n\n  source_ami_filter {\n    filters = {\n      name = \"ubuntu/images/*ubuntu-jammy-22.04-amd64-server-*\"\n    }\n    most_recent = true\n    owners      = [\"099720109477\"]\n  }\n\n  ssh_username = \"ubuntu\"\n  ami_name     = \"my-app-${local.timestamp}\"\n\n  # Copy to additional regions\n  ami_regions = [\"us-east-1\", \"us-east-2\", \"eu-west-1\"]\n}\n```\n\n## Authentication\n\nPacker uses AWS credential resolution:\n\n1. Environment variables: `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`\n2. AWS credentials file: `~/.aws/credentials`\n3. IAM instance profile (when running on EC2)\n\n```bash\nexport AWS_ACCESS_KEY_ID=\"your-access-key\"\nexport AWS_SECRET_ACCESS_KEY=\"your-secret-key\"\nexport AWS_REGION=\"us-west-2\"\n\npacker build .\n```\n\n## Build Commands\n\n```bash\n# Initialize plugins\npacker init .\n\n# Validate template\npacker validate .\n\n# Build AMI\npacker build .\n\n# Build with variables\npacker build -var \"region=us-east-1\" .\n```\n\n## Common Issues\n\n**SSH Timeout**\n- Ensure security group allows SSH (port 22)\n- Verify subnet has internet access\n\n**AMI Already Exists**\n- AMI names must be unique\n- Use timestamp in name: `my-app-${local.timestamp}`\n\n**Volume Size Too Small**\n- Check source AMI's volume size\n- Set `launch_block_device_mappings.volume_size` accordingly\n\n## References\n\n- [Amazon EBS Builder](https://developer.hashicorp.com/packer/integrations/hashicorp/amazon/latest/components/builder/ebs)\n- [AWS AMI Documentation](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html)\n",
        "packer/builders/skills/azure-image-builder/SKILL.md": "---\nname: azure-image-builder\ndescription: Build Azure managed images and Azure Compute Gallery images with Packer. Use when creating custom images for Azure VMs.\n---\n\n# Azure Image Builder\n\nBuild Azure managed images and Azure Compute Gallery images using Packer's `azure-arm` builder.\n\n**Reference:** [Azure ARM Builder](https://developer.hashicorp.com/packer/integrations/hashicorp/azure/latest/components/builder/arm)\n\n> **Note:** Building Azure images incurs costs (compute, storage, data transfer). Builds typically take 15-45 minutes depending on provisioning and OS.\n\n## Basic Managed Image\n\n```hcl\npacker {\n  required_plugins {\n    azure = {\n      source  = \"github.com/hashicorp/azure\"\n      version = \"~> 2.0\"\n    }\n  }\n}\n\nvariable \"client_id\" {\n  type      = string\n  sensitive = true\n}\n\nvariable \"client_secret\" {\n  type      = string\n  sensitive = true\n}\n\nvariable \"subscription_id\" {\n  type = string\n}\n\nvariable \"tenant_id\" {\n  type = string\n}\n\nvariable \"resource_group\" {\n  type    = string\n  default = \"packer-images-rg\"\n}\n\nlocals {\n  timestamp = regex_replace(timestamp(), \"[- TZ:]\", \"\")\n}\n\nsource \"azure-arm\" \"ubuntu\" {\n  client_id       = var.client_id\n  client_secret   = var.client_secret\n  subscription_id = var.subscription_id\n  tenant_id       = var.tenant_id\n\n  managed_image_resource_group_name = var.resource_group\n  managed_image_name                = \"my-app-${local.timestamp}\"\n\n  os_type         = \"Linux\"\n  image_publisher = \"Canonical\"\n  image_offer     = \"0001-com-ubuntu-server-jammy\"\n  image_sku       = \"22_04-lts-gen2\"\n\n  location = \"East US\"\n  vm_size  = \"Standard_B2s\"\n\n  azure_tags = {\n    Name      = \"my-app\"\n    BuildDate = local.timestamp\n  }\n}\n\nbuild {\n  sources = [\"source.azure-arm.ubuntu\"]\n\n  provisioner \"shell\" {\n    inline = [\n      \"sudo apt-get update\",\n      \"sudo apt-get upgrade -y\",\n    ]\n  }\n}\n```\n\n## Azure Compute Gallery\n\n```hcl\nsource \"azure-arm\" \"ubuntu\" {\n  client_id       = var.client_id\n  client_secret   = var.client_secret\n  subscription_id = var.subscription_id\n  tenant_id       = var.tenant_id\n\n  os_type         = \"Linux\"\n  image_publisher = \"Canonical\"\n  image_offer     = \"0001-com-ubuntu-server-jammy\"\n  image_sku       = \"22_04-lts-gen2\"\n\n  location = \"East US\"\n  vm_size  = \"Standard_B2s\"\n\n  shared_image_gallery_destination {\n    resource_group       = \"gallery-rg\"\n    gallery_name         = \"myImageGallery\"\n    image_name           = \"ubuntu-webapp\"\n    image_version        = \"1.0.${formatdate(\"YYYYMMDD\", timestamp())}\"\n    replication_regions  = [\"East US\", \"West US 2\"]\n    storage_account_type = \"Standard_LRS\"\n  }\n}\n```\n\n## Authentication\n\n### Service Principal\n```bash\n# Create service principal\naz ad sp create-for-rbac \\\n  --name \"packer-sp\" \\\n  --role Contributor \\\n  --scopes /subscriptions/<subscription-id>\n\n# Set environment variables\nexport ARM_CLIENT_ID=\"<client-id>\"\nexport ARM_CLIENT_SECRET=\"<client-secret>\"\nexport ARM_SUBSCRIPTION_ID=\"<subscription-id>\"\nexport ARM_TENANT_ID=\"<tenant-id>\"\n```\n\n### Managed Identity\n```hcl\nsource \"azure-arm\" \"ubuntu\" {\n  use_azure_cli_auth = true\n  subscription_id    = var.subscription_id\n  # ... rest of configuration\n}\n```\n\n## Build Commands\n\n```bash\n# Set authentication\nexport ARM_CLIENT_ID=\"your-client-id\"\nexport ARM_CLIENT_SECRET=\"your-client-secret\"\nexport ARM_SUBSCRIPTION_ID=\"your-subscription-id\"\nexport ARM_TENANT_ID=\"your-tenant-id\"\n\n# Initialize plugins\npacker init .\n\n# Validate template\npacker validate .\n\n# Build image\npacker build .\n```\n\n## Common Issues\n\n**Authentication Failed**\n- Verify service principal credentials\n- Ensure Contributor role on resource group\n- Check subscription and tenant IDs\n\n**Compute Gallery Version Exists**\n- Image versions are immutable\n- Use unique version numbers with date/build number\n- Cannot overwrite existing versions\n\n**Timeout During Provisioning**\n- Check network connectivity from build VM\n- Verify NSG rules allow required traffic\n- Increase timeout if needed\n\n## References\n\n- [Azure ARM Builder](https://developer.hashicorp.com/packer/integrations/hashicorp/azure/latest/components/builder/arm)\n- [Azure Compute Gallery](https://learn.microsoft.com/en-us/azure/virtual-machines/azure-compute-gallery)\n",
        "packer/builders/skills/windows-builder/SKILL.md": "---\nname: windows-builder\ndescription: Build Windows images with Packer using WinRM communicator and PowerShell provisioners. Use when creating Windows AMIs, Azure images, or VMware templates.\n---\n\n# Windows Builder\n\nPlatform-agnostic patterns for building Windows images with Packer.\n\n**Reference:** [Windows Builders](https://developer.hashicorp.com/packer/guides/windows)\n\n> **Note:** Windows builds incur significant costs and time. Expect 45-120 minutes per build due to Windows Updates. Failed builds may leave resources running - always verify cleanup.\n\n## WinRM Communicator Setup\n\nWindows requires WinRM for Packer communication.\n\n### AWS Example\n\n```hcl\nsource \"amazon-ebs\" \"windows\" {\n  region        = \"us-west-2\"\n  instance_type = \"t3.medium\"\n\n  source_ami_filter {\n    filters = {\n      name = \"Windows_Server-2022-English-Full-Base-*\"\n    }\n    most_recent = true\n    owners      = [\"amazon\"]\n  }\n\n  ami_name = \"windows-server-2022-${local.timestamp}\"\n\n  communicator   = \"winrm\"\n  winrm_username = \"Administrator\"\n  winrm_use_ssl  = true\n  winrm_insecure = true\n  winrm_timeout  = \"15m\"\n\n  user_data_file = \"scripts/setup-winrm.ps1\"\n}\n```\n\n### WinRM Setup Script (scripts/setup-winrm.ps1)\n\n```powershell\n<powershell>\n# Configure WinRM\nwinrm quickconfig -q\nwinrm set winrm/config '@{MaxTimeoutms=\"1800000\"}'\nwinrm set winrm/config/service '@{AllowUnencrypted=\"true\"}'\nwinrm set winrm/config/service/auth '@{Basic=\"true\"}'\n\n# Configure firewall\nnetsh advfirewall firewall add rule name=\"WinRM 5985\" protocol=TCP dir=in localport=5985 action=allow\nnetsh advfirewall firewall add rule name=\"WinRM 5986\" protocol=TCP dir=in localport=5986 action=allow\n\n# Restart WinRM\nnet stop winrm\nnet start winrm\n</powershell>\n```\n\n### Azure Example\n\n```hcl\nsource \"azure-arm\" \"windows\" {\n  client_id       = var.client_id\n  client_secret   = var.client_secret\n  subscription_id = var.subscription_id\n  tenant_id       = var.tenant_id\n\n  managed_image_resource_group_name = \"images-rg\"\n  managed_image_name                = \"windows-${local.timestamp}\"\n\n  os_type         = \"Windows\"\n  image_publisher = \"MicrosoftWindowsServer\"\n  image_offer     = \"WindowsServer\"\n  image_sku       = \"2022-datacenter-g2\"\n\n  location = \"East US\"\n  vm_size  = \"Standard_D2s_v3\"\n\n  # Azure auto-configures WinRM\n  communicator   = \"winrm\"\n  winrm_use_ssl  = true\n  winrm_insecure = true\n  winrm_timeout  = \"15m\"\n  winrm_username = \"packer\"\n}\n```\n\n## PowerShell Provisioners\n\n### Install Software\n\n```hcl\nbuild {\n  sources = [\"source.amazon-ebs.windows\"]\n\n  # Install Chocolatey\n  provisioner \"powershell\" {\n    inline = [\n      \"Set-ExecutionPolicy Bypass -Scope Process -Force\",\n      \"iex ((New-Object System.Net.WebClient).DownloadString('https://community.chocolatey.org/install.ps1'))\"\n    ]\n  }\n\n  # Install applications\n  provisioner \"powershell\" {\n    inline = [\n      \"choco install -y googlechrome\",\n      \"choco install -y 7zip\",\n    ]\n  }\n\n  # Install IIS\n  provisioner \"powershell\" {\n    inline = [\n      \"Install-WindowsFeature -Name Web-Server -IncludeManagementTools\"\n    ]\n  }\n}\n```\n\n### Windows Updates\n\n```hcl\nprovisioner \"powershell\" {\n  inline = [\n    \"Install-PackageProvider -Name NuGet -Force\",\n    \"Install-Module -Name PSWindowsUpdate -Force\",\n    \"Import-Module PSWindowsUpdate\",\n    \"Get-WindowsUpdate -Install -AcceptAll -AutoReboot\",\n  ]\n  timeout = \"2h\"\n}\n\n# Wait for reboots\nprovisioner \"windows-restart\" {\n  restart_timeout = \"30m\"\n}\n```\n\n## Cleanup\n\n```hcl\nprovisioner \"powershell\" {\n  inline = [\n    \"# Clear temp files\",\n    \"Remove-Item -Path 'C:\\\\Windows\\\\Temp\\\\*' -Recurse -Force -ErrorAction SilentlyContinue\",\n    \"# Clear Windows Update cache\",\n    \"Stop-Service -Name wuauserv -Force\",\n    \"Remove-Item -Path 'C:\\\\Windows\\\\SoftwareDistribution\\\\*' -Recurse -Force -ErrorAction SilentlyContinue\",\n    \"Start-Service -Name wuauserv\",\n  ]\n}\n```\n\n## Common Issues\n\n**WinRM Timeout**\n- Increase `winrm_timeout` to 15m or more\n- Verify security group allows ports 5985/5986\n- Check user data script completed successfully\n\n**PowerShell Execution Policy**\n```hcl\nprovisioner \"powershell\" {\n  inline = [\n    \"Set-ExecutionPolicy Bypass -Scope Process -Force\",\n    \"# Your commands here\",\n  ]\n}\n```\n\n**Long Build Times**\n- Windows Updates can take 1-2 hours\n- Use pre-patched base images when available\n- Set provisioner `timeout = \"2h\"`\n\n## References\n\n- [Packer Windows Builders](https://developer.hashicorp.com/packer/guides/windows)\n- [WinRM Communicator](https://developer.hashicorp.com/packer/docs/communicators/winrm)\n- [PowerShell Provisioner](https://developer.hashicorp.com/packer/docs/provisioners/powershell)\n",
        "packer/hcp/.claude-plugin/plugin.json": "{\n  \"name\": \"packer-hcp\",\n  \"version\": \"1.0.0\",\n  \"description\": \"HCP Packer registry integration for tracking and managing image metadata.\",\n  \"author\": {\n    \"name\": \"HashiCorp\",\n    \"url\": \"https://github.com/hashicorp\"\n  },\n  \"homepage\": \"https://developer.hashicorp.com/hcp/docs/packer\",\n  \"repository\": \"https://github.com/hashicorp/agent-skills\",\n  \"license\": \"MPL-2.0\",\n  \"keywords\": [\"packer\", \"hcp-packer\", \"registry\", \"metadata\", \"image-tracking\"]\n}\n",
        "packer/hcp/skills/push-to-registry/SKILL.md": "---\nname: push-to-registry\ndescription: Push Packer build metadata to HCP Packer registry for tracking and managing image lifecycle. Use when integrating Packer builds with HCP Packer for version control and governance.\n---\n\n# Push to HCP Packer Registry\n\nConfigure Packer templates to push build metadata to HCP Packer registry.\n\n**Reference:** [HCP Packer Registry](https://developer.hashicorp.com/hcp/docs/packer)\n\n> **Note:** HCP Packer is free for basic use. Builds push metadata only (not actual images), adding minimal overhead (<1 minute).\n\n## Basic Registry Configuration\n\n```hcl\npacker {\n  required_version = \">= 1.7.7\"\n}\n\nvariable \"image_name\" {\n  type    = string\n  default = \"web-server\"\n}\n\nlocals {\n  timestamp = regex_replace(timestamp(), \"[- TZ:]\", \"\")\n}\n\nsource \"amazon-ebs\" \"ubuntu\" {\n  region        = \"us-west-2\"\n  instance_type = \"t3.micro\"\n\n  source_ami_filter {\n    filters = {\n      name = \"ubuntu/images/*ubuntu-jammy-22.04-amd64-server-*\"\n    }\n    most_recent = true\n    owners      = [\"099720109477\"]\n  }\n\n  ssh_username = \"ubuntu\"\n  ami_name     = \"${var.image_name}-${local.timestamp}\"\n}\n\nbuild {\n  sources = [\"source.amazon-ebs.ubuntu\"]\n\n  hcp_packer_registry {\n    bucket_name = var.image_name\n    description = \"Ubuntu 22.04 base image for web servers\"\n\n    bucket_labels = {\n      \"os\"   = \"ubuntu\"\n      \"team\" = \"platform\"\n    }\n\n    build_labels = {\n      \"build-time\" = local.timestamp\n    }\n  }\n\n  provisioner \"shell\" {\n    inline = [\n      \"sudo apt-get update\",\n      \"sudo apt-get upgrade -y\",\n    ]\n  }\n}\n```\n\n## Authentication\n\nSet environment variables before building:\n\n```bash\nexport HCP_CLIENT_ID=\"your-service-principal-client-id\"\nexport HCP_CLIENT_SECRET=\"your-service-principal-secret\"\nexport HCP_ORGANIZATION_ID=\"your-org-id\"\nexport HCP_PROJECT_ID=\"your-project-id\"\n\npacker build .\n```\n\n### Create HCP Service Principal\n\n1. Navigate to HCP â†’ Access Control (IAM)\n2. Create Service Principal\n3. Grant \"Contributor\" role on project\n4. Generate client secret\n5. Save client ID and secret\n\n## Registry Configuration Options\n\n### bucket_name (required)\nThe image identifier. Must stay consistent across builds!\n\n```hcl\nbucket_name = \"web-server\"  # Keep this constant\n```\n\n### bucket_labels (optional)\nMetadata at bucket level. Updates with each build.\n\n```hcl\nbucket_labels = {\n  \"os\"        = \"ubuntu\"\n  \"team\"      = \"platform\"\n  \"component\" = \"web\"\n}\n```\n\n### build_labels (optional)\nMetadata for each iteration. Immutable after build completes.\n\n```hcl\nbuild_labels = {\n  \"build-time\" = local.timestamp\n  \"git-commit\" = var.git_commit\n}\n```\n\n## CI/CD Integration\n\n### GitHub Actions\n\n```yaml\nname: Build and Push to HCP Packer\n\non:\n  push:\n    branches: [main]\n\nenv:\n  HCP_CLIENT_ID: ${{ secrets.HCP_CLIENT_ID }}\n  HCP_CLIENT_SECRET: ${{ secrets.HCP_CLIENT_SECRET }}\n  HCP_ORGANIZATION_ID: ${{ secrets.HCP_ORGANIZATION_ID }}\n  HCP_PROJECT_ID: ${{ secrets.HCP_PROJECT_ID }}\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: hashicorp/setup-packer@main\n\n      - name: Build and push\n        run: |\n          packer init .\n          packer build \\\n            -var \"git_commit=${{ github.sha }}\" \\\n            .\n```\n\n## Querying in Terraform\n\n```hcl\ndata \"hcp_packer_artifact\" \"ubuntu\" {\n  bucket_name  = \"web-server\"\n  channel_name = \"production\"\n  platform     = \"aws\"\n  region       = \"us-west-2\"\n}\n\nresource \"aws_instance\" \"web\" {\n  ami           = data.hcp_packer_artifact.ubuntu.external_identifier\n  instance_type = \"t3.micro\"\n\n  tags = {\n    PackerBucket = data.hcp_packer_artifact.ubuntu.bucket_name\n  }\n}\n```\n\n## Common Issues\n\n**Authentication Failed**\n- Verify HCP_CLIENT_ID and HCP_CLIENT_SECRET\n- Ensure service principal has Contributor role\n- Check organization and project IDs\n\n**Bucket Name Mismatch**\n- Keep `bucket_name` consistent across builds\n- Don't include timestamps in bucket_name\n- Creates new bucket if name changes\n\n**Build Fails**\n- Packer fails immediately if can't push metadata\n- Prevents drift between artifacts and registry\n- Check network connectivity to HCP API\n\n## Best Practices\n\n- **Consistent bucket names** - Never change for same image type\n- **Meaningful labels** - Use for versions, teams, compliance\n- **CI/CD automation** - Automate builds and registry pushes\n- **Immutable build labels** - Put changing data (git SHA, date) in build_labels\n\n## References\n\n- [HCP Packer Documentation](https://developer.hashicorp.com/hcp/docs/packer)\n- [hcp_packer_registry Block](https://developer.hashicorp.com/packer/docs/templates/hcl_templates/blocks/build/hcp_packer_registry)\n- [HCP Terraform Provider](https://registry.terraform.io/providers/hashicorp/hcp/latest/docs/data-sources/packer_artifact)\n",
        "terraform/code-generation/.claude-plugin/plugin.json": "{\n  \"name\": \"terraform-code-generation\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Terraform code generation skills for Claude Code, including HCL generation, style guides, and testing.\",\n  \"author\": {\n    \"name\": \"HashiCorp\",\n    \"url\": \"https://github.com/hashicorp\"\n  },\n  \"homepage\": \"https://developer.hashicorp.com/terraform/language\",\n  \"repository\": \"https://github.com/hashicorp/agent-skills\",\n  \"license\": \"MPL-2.0\",\n  \"keywords\": [\"terraform\", \"hcl\", \"infrastructure\", \"iac\", \"testing\", \"style-guide\"],\n  \"mcpServers\": {\n    \"terraform\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\", \"TFE_TOKEN\",\n        \"-e\", \"TFE_ADDRESS\",\n        \"hashicorp/terraform-mcp-server\"\n      ],\n      \"env\": {\n        \"TFE_TOKEN\": \"${TFE_TOKEN}\",\n        \"TFE_ADDRESS\": \"${TFE_ADDRESS}\"\n      }\n    }\n  }\n}\n",
        "terraform/code-generation/skills/azure-verified-modules/SKILL.md": "---\nname: azure-verified-modules\ndescription: Azure Verified Modules (AVM) requirements and best practices for developing certified Azure Terraform modules. Use when creating or reviewing Azure modules that need AVM certification.\n---\n\n# Azure Verified Modules (AVM) Requirements\n\nThis guide covers the mandatory requirements for Azure Verified Modules certification. These requirements ensure consistency, quality, and maintainability across Azure Terraform modules.\n\n**References:**\n- [Azure Verified Modules](https://azure.github.io/Azure-Verified-Modules/)\n- [AVM Terraform Requirements](https://azure.github.io/Azure-Verified-Modules/specs/terraform/)\n\n## Table of Contents\n\n- [Module Cross-Referencing](#module-cross-referencing)\n- [Azure Provider Requirements](#azure-provider-requirements)\n- [Code Style Standards](#code-style-standards)\n- [Variable Requirements](#variable-requirements)\n- [Output Requirements](#output-requirements)\n- [Local Values Standards](#local-values-standards)\n- [Terraform Configuration Requirements](#terraform-configuration-requirements)\n- [Testing Requirements](#testing-requirements)\n- [Documentation Requirements](#documentation-requirements)\n- [Breaking Changes & Feature Management](#breaking-changes--feature-management)\n- [Contribution Standards](#contribution-standards)\n- [Compliance Checklist](#compliance-checklist)\n\n---\n\n## Module Cross-Referencing\n\n**Severity:** MUST | **Requirement:** TFFR1\n\nWhen building Resource or Pattern modules, module owners **MAY** cross-reference other modules. However:\n\n- Modules **MUST** be referenced using HashiCorp Terraform registry reference to a pinned version\n  - Example: `source = \"Azure/xxx/azurerm\"` with `version = \"1.2.3\"`\n- Modules **MUST NOT** use git references (e.g., `git::https://xxx.yyy/xxx.git` or `github.com/xxx/yyy`)\n- Modules **MUST NOT** contain references to non-AVM modules\n\n---\n\n## Azure Provider Requirements\n\n**Severity:** MUST | **Requirement:** TFFR3\n\nAuthors **MUST** only use the following Azure providers:\n\n| Provider | Min Version | Max Version |\n|----------|-------------|-------------|\n| azapi    | >= 2.0      | < 3.0       |\n| azurerm  | >= 4.0      | < 5.0       |\n\n**Requirements:**\n\n- Authors **MAY** select either Azurerm, Azapi, or both providers\n- **MUST** use `required_providers` block to enforce provider versions\n- **SHOULD** use pessimistic version constraint operator (`~>`)\n\n**Example:**\n\n```hcl\nterraform {\n  required_providers {\n    azurerm = {\n      source  = \"hashicorp/azurerm\"\n      version = \"~> 4.0\"\n    }\n    azapi = {\n      source  = \"Azure/azapi\"\n      version = \"~> 2.0\"\n    }\n  }\n}\n```\n\n---\n\n## Code Style Standards\n\n### Lower snake_casing\n\n**Severity:** MUST | **Requirement:** TFNFR4\n\n**MUST** use lower snake_casing for:\n\n- Locals\n- Variables\n- Outputs\n- Resources (symbolic names)\n- Modules (symbolic names)\n\nExample: `snake_casing_example`\n\n### Resource & Data Source Ordering\n\n**Severity:** SHOULD | **Requirement:** TFNFR6\n\n- Resources that are depended on **SHOULD** come first\n- Resources with dependencies **SHOULD** be defined close to each other\n\n### Count & for_each Usage\n\n**Severity:** MUST | **Requirement:** TFNFR7\n\n- Use `count` for conditional resource creation\n- **MUST** use `map(xxx)` or `set(xxx)` as resource's `for_each` collection\n- The map's key or set's element **MUST** be static literals\n\n**Example:**\n\n```hcl\nresource \"azurerm_subnet\" \"pair\" {\n  for_each             = var.subnet_map  # map(string)\n  name                 = \"${each.value}-pair\"\n  resource_group_name  = azurerm_resource_group.example.name\n  virtual_network_name = azurerm_virtual_network.example.name\n  address_prefixes     = [\"10.0.1.0/24\"]\n}\n```\n\n### Resource & Data Block Internal Ordering\n\n**Severity:** SHOULD | **Requirement:** TFNFR8\n\n**Order within resource/data blocks:**\n\n1. **Meta-arguments (top)**:\n   - `provider`\n   - `count`\n   - `for_each`\n\n2. **Arguments/blocks (middle, alphabetical)**:\n   - Required arguments\n   - Optional arguments\n   - Required nested blocks\n   - Optional nested blocks\n\n3. **Meta-arguments (bottom)**:\n   - `depends_on`\n   - `lifecycle` (with sub-order: `create_before_destroy`, `ignore_changes`, `prevent_destroy`)\n\nSeparate sections with blank lines.\n\n### Module Block Ordering\n\n**Severity:** SHOULD | **Requirement:** TFNFR9\n\n**Order within module blocks:**\n\n1. **Top meta-arguments**:\n   - `source`\n   - `version`\n   - `count`\n   - `for_each`\n\n2. **Arguments (alphabetical)**:\n   - Required arguments\n   - Optional arguments\n\n3. **Bottom meta-arguments**:\n   - `depends_on`\n   - `providers`\n\n### Lifecycle ignore_changes Syntax\n\n**Severity:** MUST | **Requirement:** TFNFR10\n\nThe `ignore_changes` attribute **MUST NOT** be enclosed in double quotes.\n\n**Good:**\n\n```hcl\nlifecycle {\n  ignore_changes = [tags]\n}\n```\n\n**Bad:**\n\n```hcl\nlifecycle {\n  ignore_changes = [\"tags\"]\n}\n```\n\n### Null Comparison for Conditional Creation\n\n**Severity:** SHOULD | **Requirement:** TFNFR11\n\nFor parameters requiring conditional resource creation, wrap with `object` type to avoid \"known after apply\" issues during plan stage.\n\n**Recommended:**\n\n```hcl\nvariable \"security_group\" {\n  type = object({\n    id = string\n  })\n  default = null\n}\n```\n\n### Dynamic Blocks for Optional Nested Objects\n\n**Severity:** MUST | **Requirement:** TFNFR12\n\nNested blocks under conditions **MUST** use this pattern:\n\n```hcl\ndynamic \"identity\" {\n  for_each = <condition> ? [<some_item>] : []\n\n  content {\n    # block content\n  }\n}\n```\n\n### Default Values with coalesce/try\n\n**Severity:** SHOULD | **Requirement:** TFNFR13\n\n**Good:**\n\n```hcl\ncoalesce(var.new_network_security_group_name, \"${var.subnet_name}-nsg\")\n```\n\n**Bad:**\n\n```hcl\nvar.new_network_security_group_name == null ? \"${var.subnet_name}-nsg\" : var.new_network_security_group_name\n```\n\n### Provider Declarations in Modules\n\n**Severity:** MUST | **Requirement:** TFNFR27\n\n- `provider` **MUST NOT** be declared in modules (except for `configuration_aliases`)\n- `provider` blocks in modules **MUST** only use `alias`\n- Provider configurations **SHOULD** be passed in by module users\n\n---\n\n## Variable Requirements\n\n### Not Allowed Variables\n\n**Severity:** MUST | **Requirement:** TFNFR14\n\nModule owners **MUST NOT** add variables like `enabled` or `module_depends_on` to control entire module operation. Boolean feature toggles for specific resources are acceptable.\n\n### Variable Definition Order\n\n**Severity:** SHOULD | **Requirement:** TFNFR15\n\nVariables **SHOULD** follow this order:\n\n1. All required fields (alphabetical)\n2. All optional fields (alphabetical)\n\n### Variable Naming Rules\n\n**Severity:** SHOULD | **Requirement:** TFNFR16\n\n- Follow [HashiCorp's naming rules](https://www.terraform.io/docs/extend/best-practices/naming.html)\n- Feature switches **SHOULD** use positive statements: `xxx_enabled` instead of `xxx_disabled`\n\n### Variables with Descriptions\n\n**Severity:** SHOULD | **Requirement:** TFNFR17\n\n- `description` **SHOULD** precisely describe the parameter's purpose and expected data type\n- Target audience is module users, not developers\n- For `object` types, use HEREDOC format\n\n### Variables with Types\n\n**Severity:** MUST | **Requirement:** TFNFR18\n\n- `type` **MUST** be defined for every variable\n- `type` **SHOULD** be as precise as possible\n- `any` **MAY** only be used with adequate reasons\n- Use `bool` instead of `string`/`number` for true/false values\n- Use concrete `object` instead of `map(any)`\n\n### Sensitive Data Variables\n\n**Severity:** SHOULD | **Requirement:** TFNFR19\n\nIf a variable's type is `object` and contains sensitive fields, the entire variable **SHOULD** be `sensitive = true`, or extract sensitive fields into separate variables.\n\n### Non-Nullable Defaults for Collections\n\n**Severity:** SHOULD | **Requirement:** TFNFR20\n\nNullable **SHOULD** be set to `false` for collection values (sets, maps, lists) when using them in loops. For scalar values, null may have semantic meaning.\n\n### Discourage Nullability by Default\n\n**Severity:** MUST | **Requirement:** TFNFR21\n\n`nullable = true` **MUST** be avoided unless there's a specific semantic need for null values.\n\n### Avoid sensitive = false\n\n**Severity:** MUST | **Requirement:** TFNFR22\n\n`sensitive = false` **MUST** be avoided (this is the default).\n\n### Sensitive Default Value Conditions\n\n**Severity:** MUST | **Requirement:** TFNFR23\n\nA default value **MUST NOT** be set for sensitive inputs (e.g., default passwords).\n\n### Handling Deprecated Variables\n\n**Severity:** MUST | **Requirement:** TFNFR24\n\n- Move deprecated variables to `deprecated_variables.tf`\n- Annotate with `DEPRECATED` at the beginning of description\n- Declare the replacement's name\n- Clean up during major version releases\n\n---\n\n## Output Requirements\n\n### Additional Terraform Outputs\n\n**Severity:** SHOULD | **Requirement:** TFFR2\n\nAuthors **SHOULD NOT** output entire resource objects as these may contain sensitive data and the schema can change with API or provider versions.\n\n**Best Practices:**\n\n- Output *computed* attributes of resources as discrete outputs (anti-corruption layer pattern)\n- **SHOULD NOT** output values that are already inputs (except `name`)\n- Use `sensitive = true` for sensitive attributes\n- For resources deployed with `for_each`, output computed attributes in a map structure\n\n**Examples:**\n\n```hcl\n# Single resource computed attribute\noutput \"foo\" {\n  description = \"MyResource foo attribute\"\n  value       = azurerm_resource_myresource.foo\n}\n\n# for_each resources\noutput \"childresource_foos\" {\n  description = \"MyResource children's foo attributes\"\n  value = {\n    for key, value in azurerm_resource_mychildresource : key => value.foo\n  }\n}\n\n# Sensitive output\noutput \"bar\" {\n  description = \"MyResource bar attribute\"\n  value       = azurerm_resource_myresource.bar\n  sensitive   = true\n}\n```\n\n### Sensitive Data Outputs\n\n**Severity:** MUST | **Requirement:** TFNFR29\n\nOutputs containing confidential data **MUST** be declared with `sensitive = true`.\n\n### Handling Deprecated Outputs\n\n**Severity:** MUST | **Requirement:** TFNFR30\n\n- Move deprecated outputs to `deprecated_outputs.tf`\n- Define new outputs in `outputs.tf`\n- Clean up during major version releases\n\n---\n\n## Local Values Standards\n\n### locals.tf Organization\n\n**Severity:** MAY | **Requirement:** TFNFR31\n\n- `locals.tf` **SHOULD** only contain `locals` blocks\n- **MAY** declare `locals` blocks next to resources for advanced scenarios\n\n### Alphabetical Local Arrangement\n\n**Severity:** MUST | **Requirement:** TFNFR32\n\nExpressions in `locals` blocks **MUST** be arranged alphabetically.\n\n### Precise Local Types\n\n**Severity:** SHOULD | **Requirement:** TFNFR33\n\nUse precise types (e.g., `number` for age, not `string`).\n\n---\n\n## Terraform Configuration Requirements\n\n### Terraform Version Requirements\n\n**Severity:** MUST | **Requirement:** TFNFR25\n\n**`terraform.tf` requirements:**\n\n- **MUST** contain only one `terraform` block\n- First line **MUST** define `required_version`\n- **MUST** include minimum version constraint\n- **MUST** include maximum major version constraint\n- **SHOULD** use `~> #.#` or `>= #.#.#, < #.#.#` format\n\n**Example:**\n\n```hcl\nterraform {\n  required_version = \"~> 1.6\"\n  required_providers {\n    azurerm = {\n      source  = \"hashicorp/azurerm\"\n      version = \"~> 4.0\"\n    }\n  }\n}\n```\n\n### Providers in required_providers\n\n**Severity:** MUST | **Requirement:** TFNFR26\n\n- `terraform` block **MUST** contain `required_providers` block\n- Each provider **MUST** specify `source` and `version`\n- Providers **SHOULD** be sorted alphabetically\n- Only include directly required providers\n- `source` **MUST** be in format `namespace/name`\n- `version` **MUST** include minimum and maximum major version constraints\n- **SHOULD** use `~> #.#` or `>= #.#.#, < #.#.#` format\n\n---\n\n## Testing Requirements\n\n### Test Tooling\n\n**Severity:** MUST | **Requirement:** TFNFR5\n\n**Required testing tools for AVM:**\n\n- Terraform (`terraform validate/fmt/test`)\n- terrafmt\n- Checkov\n- tflint (with azurerm ruleset)\n- Go (optional for custom tests)\n\n### Test Provider Configuration\n\n**Severity:** SHOULD | **Requirement:** TFNFR36\n\nFor robust testing, `prevent_deletion_if_contains_resources` **SHOULD** be explicitly set to `false` in test provider configurations.\n\n---\n\n## Documentation Requirements\n\n### Module Documentation Generation\n\n**Severity:** MUST | **Requirement:** TFNFR2\n\n- Documentation **MUST** be automatically generated via [Terraform Docs](https://github.com/terraform-docs/terraform-docs)\n- A `.terraform-docs.yml` file **MUST** be present in the module root\n\n---\n\n## Breaking Changes & Feature Management\n\n### Using Feature Toggles\n\n**Severity:** MUST | **Requirement:** TFNFR34\n\nNew resources added in minor/patch versions **MUST** have a toggle variable to avoid creation by default:\n\n```hcl\nvariable \"create_route_table\" {\n  type     = bool\n  default  = false\n  nullable = false\n}\n\nresource \"azurerm_route_table\" \"this\" {\n  count = var.create_route_table ? 1 : 0\n  # ...\n}\n```\n\n### Reviewing Potential Breaking Changes\n\n**Severity:** MUST | **Requirement:** TFNFR35\n\n**Breaking changes requiring caution:**\n\n**Resource blocks:**\n\n1. Adding new resource without conditional creation\n2. Adding arguments with non-default values\n3. Adding nested blocks without `dynamic`\n4. Renaming resources without `moved` blocks\n5. Changing `count` to `for_each` or vice versa\n\n**Variable/Output blocks:**\n\n1. Deleting/renaming variables\n2. Changing variable `type`\n3. Changing variable `default` values\n4. Changing `nullable` to false\n5. Changing `sensitive` from false to true\n6. Adding variables without `default`\n7. Deleting outputs\n8. Changing output `value`\n9. Changing output `sensitive` value\n\n---\n\n## Contribution Standards\n\n### GitHub Repository Branch Protection\n\n**Severity:** MUST | **Requirement:** TFNFR3\n\nModule owners **MUST** set branch protection policies on the default branch (typically `main`):\n\n1. Require Pull Request before merging\n2. Require approval of most recent reviewable push\n3. Dismiss stale PR approvals when new commits are pushed\n4. Require linear history\n5. Prevent force pushes\n6. Not allow deletions\n7. Require CODEOWNERS review\n8. No bypassing settings allowed\n9. Enforce for administrators\n\n---\n\n## Compliance Checklist\n\nUse this checklist when developing or reviewing Azure Verified Modules:\n\n### Module Structure\n- [ ] Module cross-references use registry sources with pinned versions\n- [ ] Azure providers (azurerm/azapi) versions meet AVM requirements\n- [ ] `.terraform-docs.yml` present in module root\n- [ ] CODEOWNERS file present\n\n### Code Style\n- [ ] All names use lower snake_casing\n- [ ] Resources ordered with dependencies first\n- [ ] `for_each` uses `map()` or `set()` with static keys\n- [ ] Resource/data/module blocks follow proper internal ordering\n- [ ] `ignore_changes` not quoted\n- [ ] Dynamic blocks used for conditional nested objects\n- [ ] `coalesce()` or `try()` used for default values\n\n### Variables\n- [ ] No `enabled` or `module_depends_on` variables\n- [ ] Variables ordered: required (alphabetical) then optional (alphabetical)\n- [ ] All variables have precise types (avoid `any`)\n- [ ] All variables have descriptions\n- [ ] Collections have `nullable = false`\n- [ ] No `sensitive = false` declarations\n- [ ] No default values for sensitive inputs\n- [ ] Deprecated variables moved to `deprecated_variables.tf`\n\n### Outputs\n- [ ] Outputs use anti-corruption layer pattern (discrete attributes)\n- [ ] Sensitive outputs marked `sensitive = true`\n- [ ] Deprecated outputs moved to `deprecated_outputs.tf`\n\n### Terraform Configuration\n- [ ] `terraform.tf` has version constraints (`~>` format)\n- [ ] `required_providers` block present with all providers\n- [ ] No `provider` declarations in module (except aliases)\n- [ ] Locals arranged alphabetically\n\n### Testing & Quality\n- [ ] Required testing tools configured\n- [ ] New resources have feature toggles\n- [ ] Breaking changes reviewed and documented\n\n---\n\n## Summary Statistics\n\n- **Functional Requirements:** 3\n- **Non-Functional Requirements:** 34\n- **Total Requirements:** 37\n\n### By Severity\n- **MUST:** 21 requirements\n- **SHOULD:** 14 requirements\n- **MAY:** 2 requirements\n\n---\n\n*Based on: Azure Verified Modules - Terraform Requirements*\n",
        "terraform/code-generation/skills/terraform-style-guide/SKILL.md": "---\nname: terraform-style-guide\ndescription: Generate Terraform HCL code following HashiCorp's official style conventions and best practices. Use when writing, reviewing, or generating Terraform configurations.\n---\n\n# Terraform Style Guide\n\nGenerate and maintain Terraform code following HashiCorp's official style conventions and best practices.\n\n**Reference:** [HashiCorp Terraform Style Guide](https://developer.hashicorp.com/terraform/language/style)\n\n## Code Generation Strategy\n\nWhen generating Terraform code:\n\n1. Start with provider configuration and version constraints\n2. Create data sources before dependent resources\n3. Build resources in dependency order\n4. Add outputs for key resource attributes\n5. Use variables for all configurable values\n\n## File Organization\n\n| File | Purpose |\n|------|---------|\n| `terraform.tf` | Terraform and provider version requirements |\n| `providers.tf` | Provider configurations |\n| `main.tf` | Primary resources and data sources |\n| `variables.tf` | Input variable declarations (alphabetical) |\n| `outputs.tf` | Output value declarations (alphabetical) |\n| `locals.tf` | Local value declarations |\n\n### Example Structure\n\n```hcl\n# terraform.tf\nterraform {\n  required_version = \">= 1.7\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n  }\n}\n\n# variables.tf\nvariable \"environment\" {\n  description = \"Target deployment environment\"\n  type        = string\n\n  validation {\n    condition     = contains([\"dev\", \"staging\", \"prod\"], var.environment)\n    error_message = \"Environment must be dev, staging, or prod.\"\n  }\n}\n\n# locals.tf\nlocals {\n  common_tags = {\n    Environment = var.environment\n    ManagedBy   = \"Terraform\"\n  }\n}\n\n# main.tf\nresource \"aws_vpc\" \"main\" {\n  cidr_block           = var.vpc_cidr\n  enable_dns_hostnames = true\n\n  tags = merge(local.common_tags, {\n    Name = \"${var.project_name}-${var.environment}-vpc\"\n  })\n}\n\n# outputs.tf\noutput \"vpc_id\" {\n  description = \"ID of the created VPC\"\n  value       = aws_vpc.main.id\n}\n```\n\n## Code Formatting\n\n### Indentation and Alignment\n\n- Use **two spaces** per nesting level (no tabs)\n- Align equals signs for consecutive arguments\n\n```hcl\nresource \"aws_instance\" \"web\" {\n  ami           = \"ami-0c55b159cbfafe1f0\"\n  instance_type = \"t2.micro\"\n  subnet_id     = \"subnet-12345678\"\n\n  tags = {\n    Name        = \"web-server\"\n    Environment = \"production\"\n  }\n}\n```\n\n### Block Organization\n\nArguments precede blocks, with meta-arguments first:\n\n```hcl\nresource \"aws_instance\" \"example\" {\n  # Meta-arguments\n  count = 3\n\n  # Arguments\n  ami           = \"ami-0c55b159cbfafe1f0\"\n  instance_type = \"t2.micro\"\n\n  # Blocks\n  root_block_device {\n    volume_size = 20\n  }\n\n  # Lifecycle last\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n```\n\n## Naming Conventions\n\n- Use **lowercase with underscores** for all names\n- Use **descriptive nouns** excluding the resource type\n- Be specific and meaningful\n\n```hcl\n# Bad\nresource \"aws_instance\" \"webAPI-aws-instance\" {}\nvariable \"name\" {}\n\n# Good\nresource \"aws_instance\" \"web_api\" {}\nvariable \"application_name\" {}\n```\n\n## Variables\n\nEvery variable must include `type` and `description`:\n\n```hcl\nvariable \"instance_type\" {\n  description = \"EC2 instance type for the web server\"\n  type        = string\n  default     = \"t2.micro\"\n\n  validation {\n    condition     = contains([\"t2.micro\", \"t2.small\", \"t2.medium\"], var.instance_type)\n    error_message = \"Instance type must be t2.micro, t2.small, or t2.medium.\"\n  }\n}\n\nvariable \"database_password\" {\n  description = \"Password for the database admin user\"\n  type        = string\n  sensitive   = true\n}\n```\n\n## Outputs\n\nEvery output must include `description`:\n\n```hcl\noutput \"instance_id\" {\n  description = \"ID of the EC2 instance\"\n  value       = aws_instance.web.id\n}\n\noutput \"database_password\" {\n  description = \"Database administrator password\"\n  value       = aws_db_instance.main.password\n  sensitive   = true\n}\n```\n\n## Dynamic Resource Creation\n\n### Prefer for_each over count\n\n```hcl\n# Bad - count for multiple resources\nresource \"aws_instance\" \"web\" {\n  count = var.instance_count\n  tags  = { Name = \"web-${count.index}\" }\n}\n\n# Good - for_each with named instances\nvariable \"instance_names\" {\n  type    = set(string)\n  default = [\"web-1\", \"web-2\", \"web-3\"]\n}\n\nresource \"aws_instance\" \"web\" {\n  for_each = var.instance_names\n  tags     = { Name = each.key }\n}\n```\n\n### count for Conditional Creation\n\n```hcl\nresource \"aws_cloudwatch_metric_alarm\" \"cpu\" {\n  count = var.enable_monitoring ? 1 : 0\n\n  alarm_name = \"high-cpu-usage\"\n  threshold  = 80\n}\n```\n\n## Security Best Practices\n\nWhen generating code, apply security hardening:\n\n- Enable encryption at rest by default\n- Configure private networking where applicable\n- Apply principle of least privilege for security groups\n- Enable logging and monitoring\n- Never hardcode credentials or secrets\n- Mark sensitive outputs with `sensitive = true`\n\n### Example: Secure S3 Bucket\n\n```hcl\nresource \"aws_s3_bucket\" \"data\" {\n  bucket = \"${var.project}-${var.environment}-data\"\n  tags   = local.common_tags\n}\n\nresource \"aws_s3_bucket_versioning\" \"data\" {\n  bucket = aws_s3_bucket.data.id\n\n  versioning_configuration {\n    status = \"Enabled\"\n  }\n}\n\nresource \"aws_s3_bucket_server_side_encryption_configuration\" \"data\" {\n  bucket = aws_s3_bucket.data.id\n\n  rule {\n    apply_server_side_encryption_by_default {\n      sse_algorithm     = \"aws:kms\"\n      kms_master_key_id = aws_kms_key.s3.arn\n    }\n  }\n}\n\nresource \"aws_s3_bucket_public_access_block\" \"data\" {\n  bucket = aws_s3_bucket.data.id\n\n  block_public_acls       = true\n  block_public_policy     = true\n  ignore_public_acls      = true\n  restrict_public_buckets = true\n}\n```\n\n## Version Pinning\n\n```hcl\nterraform {\n  required_version = \">= 1.7\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"  # Allow minor updates\n    }\n  }\n}\n```\n\n**Version constraint operators:**\n- `= 1.0.0` - Exact version\n- `>= 1.0.0` - Greater than or equal\n- `~> 1.0` - Allow rightmost component to increment\n- `>= 1.0, < 2.0` - Version range\n\n## Provider Configuration\n\n```hcl\nprovider \"aws\" {\n  region = \"us-west-2\"\n\n  default_tags {\n    tags = {\n      ManagedBy = \"Terraform\"\n      Project   = var.project_name\n    }\n  }\n}\n\n# Aliased provider for multi-region\nprovider \"aws\" {\n  alias  = \"east\"\n  region = \"us-east-1\"\n}\n```\n\n## Version Control\n\n**Never commit:**\n- `terraform.tfstate`, `terraform.tfstate.backup`\n- `.terraform/` directory\n- `*.tfplan`\n- `.tfvars` files with sensitive data\n\n**Always commit:**\n- All `.tf` configuration files\n- `.terraform.lock.hcl` (dependency lock file)\n\n## Validation Tools\n\nRun before committing:\n\n```bash\nterraform fmt -recursive\nterraform validate\n```\n\nAdditional tools:\n- `tflint` - Linting and best practices\n- `checkov` / `tfsec` - Security scanning\n\n## Code Review Checklist\n\n- [ ] Code formatted with `terraform fmt`\n- [ ] Configuration validated with `terraform validate`\n- [ ] Files organized according to standard structure\n- [ ] All variables have type and description\n- [ ] All outputs have descriptions\n- [ ] Resource names use descriptive nouns with underscores\n- [ ] Version constraints pinned explicitly\n- [ ] Sensitive values marked with `sensitive = true`\n- [ ] No hardcoded credentials or secrets\n- [ ] Security best practices applied\n\n---\n\n*Based on: [HashiCorp Terraform Style Guide](https://developer.hashicorp.com/terraform/language/style)*\n",
        "terraform/code-generation/skills/terraform-test/SKILL.md": "---\nname: terraform-test\ndescription: Comprehensive guide for writing and running Terraform tests. Use when creating test files (.tftest.hcl), writing test scenarios with run blocks, validating infrastructure behavior with assertions, mocking providers and data sources, testing module outputs and resource configurations, or troubleshooting Terraform test syntax and execution.\nmetadata:\n  copyright: Copyright IBM Corp. 2026\n  version: \"0.0.1\"\n---\n\n# Terraform Test\n\nTerraform's built-in testing framework enables module authors to validate that configuration updates don't introduce breaking changes. Tests execute against temporary resources, protecting existing infrastructure and state files.\n\n## Core Concepts\n\n**Test File**: A `.tftest.hcl` or `.tftest.json` file containing test configuration and run blocks that validate your Terraform configuration.\n\n**Test Block**: Optional configuration block that defines test-wide settings (available since Terraform 1.6.0).\n\n**Run Block**: Defines a single test scenario with optional variables, provider configurations, and assertions. Each test file requires at least one run block.\n\n**Assert Block**: Contains conditions that must evaluate to true for the test to pass. Failed assertions cause the test to fail.\n\n**Mock Provider**: Simulates provider behavior without creating real infrastructure (available since Terraform 1.7.0).\n\n**Test Modes**: Tests run in apply mode (default, creates real infrastructure) or plan mode (validates logic without creating resources).\n\n## File Structure\n\nTerraform test files use the `.tftest.hcl` or `.tftest.json` extension and are typically organized in a `tests/` directory. Use clear naming conventions to distinguish between unit tests (plan mode) and integration tests (apply mode):\n\n```\nmy-module/\nâ”œâ”€â”€ main.tf\nâ”œâ”€â”€ variables.tf\nâ”œâ”€â”€ outputs.tf\nâ””â”€â”€ tests/\n    â”œâ”€â”€ validation_unit_test.tftest.hcl      # Unit test (plan mode)\n    â”œâ”€â”€ edge_cases_unit_test.tftest.hcl      # Unit test (plan mode)\n    â””â”€â”€ full_stack_integration_test.tftest.hcl  # Integration test (apply mode - creates real resources)\n```\n\n### Test File Components\n\nA test file contains:\n- **Zero to one** `test` block (configuration settings)\n- **One to many** `run` blocks (test executions)\n- **Zero to one** `variables` block (input values)\n- **Zero to many** `provider` blocks (provider configuration)\n- **Zero to many** `mock_provider` blocks (mock provider data, since v1.7.0)\n\n**Important**: The order of `variables` and `provider` blocks doesn't matter. Terraform processes all values within these blocks at the beginning of the test operation.\n\n## Test Configuration (.tftest.hcl)\n\n### Test Block\n\nThe optional `test` block configures test-wide settings:\n\n```hcl\ntest {\n  parallel = true  # Enable parallel execution for all run blocks (default: false)\n}\n```\n\n**Test Block Attributes:**\n- `parallel` - Boolean, when set to `true`, enables parallel execution for all run blocks by default (default: `false`). Individual run blocks can override this setting.\n\n### Run Block\n\nEach `run` block executes a command against your configuration. Run blocks execute **sequentially by default**.\n\n**Basic Integration Test (Apply Mode - Default):**\n\n```hcl\nrun \"test_instance_creation\" {\n  command = apply\n\n  assert {\n    condition     = aws_instance.example.id != \"\"\n    error_message = \"Instance should be created with a valid ID\"\n  }\n\n  assert {\n    condition     = output.instance_public_ip != \"\"\n    error_message = \"Instance should have a public IP\"\n  }\n}\n```\n\n**Unit Test (Plan Mode):**\n\n```hcl\nrun \"test_default_configuration\" {\n  command = plan\n\n  assert {\n    condition     = aws_instance.example.instance_type == \"t2.micro\"\n    error_message = \"Instance type should be t2.micro by default\"\n  }\n\n  assert {\n    condition     = aws_instance.example.tags[\"Environment\"] == \"test\"\n    error_message = \"Environment tag should be 'test'\"\n  }\n}\n```\n\n**Run Block Attributes:**\n\n- `command` - Either `apply` (default) or `plan`\n- `plan_options` - Configure plan behavior (see below)\n- `variables` - Override test-level variable values\n- `module` - Reference alternate modules for testing\n- `providers` - Customize provider availability\n- `assert` - Validation conditions (multiple allowed)\n- `expect_failures` - Specify expected validation failures\n- `state_key` - Manage state file isolation (since v1.9.0)\n- `parallel` - Enable parallel execution when set to `true` (since v1.9.0)\n\n### Plan Options\n\nThe `plan_options` block configures plan command behavior:\n\n```hcl\nrun \"test_refresh_only\" {\n  command = plan\n\n  plan_options {\n    mode    = refresh-only  # \"normal\" (default) or \"refresh-only\"\n    refresh = true           # boolean, defaults to true\n    replace = [\n      aws_instance.example\n    ]\n    target = [\n      aws_instance.example\n    ]\n  }\n\n  assert {\n    condition     = aws_instance.example.instance_type == \"t2.micro\"\n    error_message = \"Instance type should be t2.micro\"\n  }\n}\n```\n\n**Plan Options Attributes:**\n- `mode` - `normal` (default) or `refresh-only`\n- `refresh` - Boolean, defaults to `true`\n- `replace` - List of resource addresses to replace\n- `target` - List of resource addresses to target\n\n### Variables Block\n\nDefine variables at the test file level (applied to all run blocks) or within individual run blocks.\n\n**Important**: Variables defined in test files take the **highest precedence**, overriding environment variables, variables files, or command-line input.\n\n**File-Level Variables:**\n\n```hcl\n# Applied to all run blocks\nvariables {\n  aws_region    = \"us-west-2\"\n  instance_type = \"t2.micro\"\n  environment   = \"test\"\n}\n\nrun \"test_with_file_variables\" {\n  command = plan\n\n  assert {\n    condition     = var.aws_region == \"us-west-2\"\n    error_message = \"Region should be us-west-2\"\n  }\n}\n```\n\n**Run Block Variables (Override File-Level):**\n\n```hcl\nvariables {\n  instance_type = \"t2.small\"\n  environment   = \"test\"\n}\n\nrun \"test_with_override_variables\" {\n  command = plan\n\n  # Override file-level variables\n  variables {\n    instance_type = \"t3.large\"\n  }\n\n  assert {\n    condition     = var.instance_type == \"t3.large\"\n    error_message = \"Instance type should be overridden to t3.large\"\n  }\n}\n```\n\n**Variables Referencing Prior Run Blocks:**\n\n```hcl\nrun \"setup_vpc\" {\n  command = apply\n}\n\nrun \"test_with_vpc_output\" {\n  command = plan\n\n  variables {\n    vpc_id = run.setup_vpc.vpc_id\n  }\n\n  assert {\n    condition     = var.vpc_id == run.setup_vpc.vpc_id\n    error_message = \"VPC ID should match setup_vpc output\"\n  }\n}\n```\n\n### Assert Block\n\nAssert blocks validate conditions within run blocks. All assertions must pass for the test to succeed.\n\n**Syntax:**\n\n```hcl\nassert {\n  condition     = <expression>\n  error_message = \"failure description\"\n}\n```\n\n**Resource Attribute Assertions:**\n\n```hcl\nrun \"test_resource_configuration\" {\n  command = plan\n\n  assert {\n    condition     = aws_s3_bucket.example.bucket == \"my-test-bucket\"\n    error_message = \"Bucket name should match expected value\"\n  }\n\n  assert {\n    condition     = aws_s3_bucket.example.versioning[0].enabled == true\n    error_message = \"Bucket versioning should be enabled\"\n  }\n\n  assert {\n    condition     = length(aws_s3_bucket.example.tags) > 0\n    error_message = \"Bucket should have at least one tag\"\n  }\n}\n```\n\n**Output Validation:**\n\n```hcl\nrun \"test_outputs\" {\n  command = plan\n\n  assert {\n    condition     = output.vpc_id != \"\"\n    error_message = \"VPC ID output should not be empty\"\n  }\n\n  assert {\n    condition     = length(output.subnet_ids) == 3\n    error_message = \"Should create exactly 3 subnets\"\n  }\n}\n```\n\n**Referencing Prior Run Block Outputs:**\n\n```hcl\nrun \"create_vpc\" {\n  command = apply\n}\n\nrun \"validate_vpc_output\" {\n  command = plan\n\n  assert {\n    condition     = run.create_vpc.vpc_id != \"\"\n    error_message = \"VPC from previous run should have an ID\"\n  }\n}\n```\n\n**Complex Conditions:**\n\n```hcl\nrun \"test_complex_validation\" {\n  command = plan\n\n  assert {\n    condition = alltrue([\n      for subnet in aws_subnet.private :\n      can(regex(\"^10\\\\.0\\\\.\", subnet.cidr_block))\n    ])\n    error_message = \"All private subnets should use 10.0.0.0/8 CIDR range\"\n  }\n\n  assert {\n    condition = alltrue([\n      for instance in aws_instance.workers :\n      contains([\"t2.micro\", \"t2.small\", \"t3.micro\"], instance.instance_type)\n    ])\n    error_message = \"Worker instances should use approved instance types\"\n  }\n}\n```\n\n### Expect Failures Block\n\nTest that certain conditions intentionally fail. The test **passes** if the specified checkable objects report an issue, and **fails** if they do not.\n\n**Checkable objects include**: Input variables, output values, check blocks, and managed resources or data sources.\n\n```hcl\nrun \"test_invalid_input_rejected\" {\n  command = plan\n\n  variables {\n    instance_count = -1\n  }\n\n  expect_failures = [\n    var.instance_count\n  ]\n}\n```\n\n**Testing Custom Conditions:**\n\n```hcl\nrun \"test_custom_condition_failure\" {\n  command = plan\n\n  variables {\n    instance_type = \"t2.nano\"  # Invalid type\n  }\n\n  expect_failures = [\n    var.instance_type\n  ]\n}\n```\n\n### Module Block\n\nTest a specific module rather than the root configuration.\n\n**Supported Module Sources:**\n- âœ… **Local modules**: `./modules/vpc`, `../shared/networking`\n- âœ… **Public Terraform Registry**: `terraform-aws-modules/vpc/aws`\n- âœ… **Private Registry (HCP Terraform)**: `app.terraform.io/org/module/provider`\n\n**Unsupported Module Sources:**\n- âŒ Git repositories: `git::https://github.com/...`\n- âŒ HTTP URLs: `https://example.com/module.zip`\n- âŒ Other remote sources (S3, GCS, etc.)\n\n**Module Block Attributes:**\n- `source` - Module source (local path or registry address)\n- `version` - Version constraint (only for registry modules)\n\n**Testing Local Modules:**\n\n```hcl\nrun \"test_vpc_module\" {\n  command = plan\n\n  module {\n    source = \"./modules/vpc\"\n  }\n\n  variables {\n    cidr_block = \"10.0.0.0/16\"\n    name       = \"test-vpc\"\n  }\n\n  assert {\n    condition     = aws_vpc.main.cidr_block == \"10.0.0.0/16\"\n    error_message = \"VPC CIDR should match input variable\"\n  }\n}\n```\n\n**Testing Public Registry Modules:**\n\n```hcl\nrun \"test_registry_module\" {\n  command = plan\n\n  module {\n    source  = \"terraform-aws-modules/vpc/aws\"\n    version = \"5.0.0\"\n  }\n\n  variables {\n    name = \"test-vpc\"\n    cidr = \"10.0.0.0/16\"\n  }\n\n  assert {\n    condition     = output.vpc_id != \"\"\n    error_message = \"VPC should be created\"\n  }\n}\n```\n\n### Provider Configuration\n\nOverride or configure providers for tests. Since Terraform 1.7.0, provider blocks can reference test variables and prior run block outputs.\n\n**Basic Provider Configuration:**\n\n```hcl\nprovider \"aws\" {\n  region = \"us-west-2\"\n}\n\nrun \"test_with_provider\" {\n  command = plan\n\n  assert {\n    condition     = aws_instance.example.availability_zone == \"us-west-2a\"\n    error_message = \"Instance should be in us-west-2 region\"\n  }\n}\n```\n\n**Multiple Provider Configurations:**\n\n```hcl\nprovider \"aws\" {\n  alias  = \"primary\"\n  region = \"us-west-2\"\n}\n\nprovider \"aws\" {\n  alias  = \"secondary\"\n  region = \"us-east-1\"\n}\n\nrun \"test_with_specific_provider\" {\n  command = plan\n\n  providers = {\n    aws = provider.aws.secondary\n  }\n\n  assert {\n    condition     = aws_instance.example.availability_zone == \"us-east-1a\"\n    error_message = \"Instance should be in us-east-1 region\"\n  }\n}\n```\n\n**Provider with Test Variables:**\n\n```hcl\nvariables {\n  aws_region = \"eu-west-1\"\n}\n\nprovider \"aws\" {\n  region = var.aws_region\n}\n```\n\n### State Key Management\n\nThe `state_key` attribute controls which state file a run block uses. By default:\n- The main configuration shares a state file across all run blocks\n- Each alternate module (referenced via `module` block) gets its own state file\n\n**Force Run Blocks to Share State:**\n\n```hcl\nrun \"create_vpc\" {\n  command = apply\n\n  module {\n    source = \"./modules/vpc\"\n  }\n\n  state_key = \"shared_state\"\n}\n\nrun \"create_subnet\" {\n  command = apply\n\n  module {\n    source = \"./modules/subnet\"\n  }\n\n  state_key = \"shared_state\"  # Shares state with create_vpc\n}\n```\n\n### Parallel Execution\n\nRun blocks execute **sequentially by default**. Enable parallel execution with `parallel = true`.\n\n**Requirements for Parallel Execution:**\n- No inter-run output references (run blocks cannot reference outputs from parallel runs)\n- Different state files (via different modules or state keys)\n- Explicit `parallel = true` attribute\n\n```hcl\nrun \"test_module_a\" {\n  command  = plan\n  parallel = true\n\n  module {\n    source = \"./modules/module-a\"\n  }\n\n  assert {\n    condition     = output.result != \"\"\n    error_message = \"Module A should produce output\"\n  }\n}\n\nrun \"test_module_b\" {\n  command  = plan\n  parallel = true\n\n  module {\n    source = \"./modules/module-b\"\n  }\n\n  assert {\n    condition     = output.result != \"\"\n    error_message = \"Module B should produce output\"\n  }\n}\n\n# This creates a synchronization point\nrun \"test_integration\" {\n  command = plan\n\n  # Waits for parallel runs above to complete\n  assert {\n    condition     = output.combined != \"\"\n    error_message = \"Integration should work\"\n  }\n}\n```\n\n## Mock Providers\n\nMock providers simulate provider behavior without creating real infrastructure (available since Terraform 1.7.0).\n\n**Basic Mock Provider:**\n\n```hcl\nmock_provider \"aws\" {\n  mock_resource \"aws_instance\" {\n    defaults = {\n      id            = \"i-1234567890abcdef0\"\n      instance_type = \"t2.micro\"\n      ami           = \"ami-12345678\"\n    }\n  }\n\n  mock_data \"aws_ami\" {\n    defaults = {\n      id = \"ami-12345678\"\n    }\n  }\n}\n\nrun \"test_with_mocks\" {\n  command = plan\n\n  assert {\n    condition     = aws_instance.example.id == \"i-1234567890abcdef0\"\n    error_message = \"Mock instance ID should match\"\n  }\n}\n```\n\n**Advanced Mock with Custom Values:**\n\n```hcl\nmock_provider \"aws\" {\n  alias = \"mocked\"\n\n  mock_resource \"aws_s3_bucket\" {\n    defaults = {\n      id     = \"test-bucket-12345\"\n      bucket = \"test-bucket\"\n      arn    = \"arn:aws:s3:::test-bucket\"\n    }\n  }\n\n  mock_data \"aws_availability_zones\" {\n    defaults = {\n      names = [\"us-west-2a\", \"us-west-2b\", \"us-west-2c\"]\n    }\n  }\n}\n\nrun \"test_with_mock_provider\" {\n  command = plan\n\n  providers = {\n    aws = provider.aws.mocked\n  }\n\n  assert {\n    condition     = length(data.aws_availability_zones.available.names) == 3\n    error_message = \"Should return 3 availability zones\"\n  }\n}\n```\n\n## Test Execution\n\n### Running Tests\n\n**Run all tests:**\n\n```bash\nterraform test\n```\n\n**Run specific test file:**\n\n```bash\nterraform test tests/defaults.tftest.hcl\n```\n\n**Run with verbose output:**\n\n```bash\nterraform test -verbose\n```\n\n**Run tests in a specific directory:**\n\n```bash\nterraform test -test-directory=integration-tests\n```\n\n**Filter tests by name:**\n\n```bash\nterraform test -filter=test_vpc_configuration\n```\n\n**Run tests without cleanup (for debugging):**\n\n```bash\nterraform test -no-cleanup\n```\n\n### Test Output\n\n**Successful test output:**\n\n```\ntests/defaults.tftest.hcl... in progress\n  run \"test_default_configuration\"... pass\n  run \"test_outputs\"... pass\ntests/defaults.tftest.hcl... tearing down\ntests/defaults.tftest.hcl... pass\n\nSuccess! 2 passed, 0 failed.\n```\n\n**Failed test output:**\n\n```\ntests/defaults.tftest.hcl... in progress\n  run \"test_default_configuration\"... fail\n    Error: Test assertion failed\n    Instance type should be t2.micro by default\n\nSuccess! 0 passed, 1 failed.\n```\n\n## Common Test Patterns (Unit Tests - Plan Mode)\n\nThe following examples demonstrate common unit test patterns using `command = plan`. These tests validate Terraform logic without creating real infrastructure, making them fast and cost-free.\n\n### Testing Module Outputs\n\n```hcl\nrun \"test_module_outputs\" {\n  command = plan\n\n  assert {\n    condition     = output.vpc_id != null\n    error_message = \"VPC ID output must be defined\"\n  }\n\n  assert {\n    condition     = can(regex(\"^vpc-\", output.vpc_id))\n    error_message = \"VPC ID should start with 'vpc-'\"\n  }\n\n  assert {\n    condition     = length(output.subnet_ids) >= 2\n    error_message = \"Should output at least 2 subnet IDs\"\n  }\n}\n```\n\n### Testing Resource Counts\n\n```hcl\nrun \"test_resource_count\" {\n  command = plan\n\n  variables {\n    instance_count = 3\n  }\n\n  assert {\n    condition     = length(aws_instance.workers) == 3\n    error_message = \"Should create exactly 3 worker instances\"\n  }\n}\n```\n\n### Testing Conditional Resources\n\n```hcl\nrun \"test_conditional_resource_created\" {\n  command = plan\n\n  variables {\n    create_nat_gateway = true\n  }\n\n  assert {\n    condition     = length(aws_nat_gateway.main) == 1\n    error_message = \"NAT gateway should be created when enabled\"\n  }\n}\n\nrun \"test_conditional_resource_not_created\" {\n  command = plan\n\n  variables {\n    create_nat_gateway = false\n  }\n\n  assert {\n    condition     = length(aws_nat_gateway.main) == 0\n    error_message = \"NAT gateway should not be created when disabled\"\n  }\n}\n```\n\n### Testing Tags\n\n```hcl\nrun \"test_resource_tags\" {\n  command = plan\n\n  variables {\n    common_tags = {\n      Environment = \"production\"\n      ManagedBy   = \"Terraform\"\n    }\n  }\n\n  assert {\n    condition     = aws_instance.example.tags[\"Environment\"] == \"production\"\n    error_message = \"Environment tag should be set correctly\"\n  }\n\n  assert {\n    condition     = aws_instance.example.tags[\"ManagedBy\"] == \"Terraform\"\n    error_message = \"ManagedBy tag should be set correctly\"\n  }\n}\n```\n\n### Sequential Tests with Dependencies\n\n```hcl\nrun \"setup_vpc\" {\n  # command defaults to apply\n\n  variables {\n    vpc_cidr = \"10.0.0.0/16\"\n  }\n\n  assert {\n    condition     = output.vpc_id != \"\"\n    error_message = \"VPC should be created\"\n  }\n}\n\nrun \"test_subnet_in_vpc\" {\n  command = plan\n\n  variables {\n    vpc_id = run.setup_vpc.vpc_id\n  }\n\n  assert {\n    condition     = aws_subnet.example.vpc_id == run.setup_vpc.vpc_id\n    error_message = \"Subnet should be created in the VPC from setup_vpc\"\n  }\n}\n```\n\n### Testing Data Sources\n\n```hcl\nrun \"test_data_source_lookup\" {\n  command = plan\n\n  assert {\n    condition     = data.aws_ami.ubuntu.id != \"\"\n    error_message = \"Should find a valid Ubuntu AMI\"\n  }\n\n  assert {\n    condition     = can(regex(\"^ami-\", data.aws_ami.ubuntu.id))\n    error_message = \"AMI ID should be in correct format\"\n  }\n}\n```\n\n### Testing Validation Rules\n\n```hcl\n# In variables.tf\nvariable \"environment\" {\n  type = string\n\n  validation {\n    condition     = contains([\"dev\", \"staging\", \"prod\"], var.environment)\n    error_message = \"Environment must be dev, staging, or prod\"\n  }\n}\n\n# In test file\nrun \"test_valid_environment\" {\n  command = plan\n\n  variables {\n    environment = \"staging\"\n  }\n\n  assert {\n    condition     = var.environment == \"staging\"\n    error_message = \"Valid environment should be accepted\"\n  }\n}\n\nrun \"test_invalid_environment\" {\n  command = plan\n\n  variables {\n    environment = \"invalid\"\n  }\n\n  expect_failures = [\n    var.environment\n  ]\n}\n```\n\n## Integration Testing\n\nFor tests that create real infrastructure (default behavior with `command = apply`):\n\n```hcl\nrun \"integration_test_full_stack\" {\n  # command defaults to apply\n\n  variables {\n    environment = \"integration-test\"\n    vpc_cidr    = \"10.100.0.0/16\"\n  }\n\n  assert {\n    condition     = aws_vpc.main.id != \"\"\n    error_message = \"VPC should be created\"\n  }\n\n  assert {\n    condition     = length(aws_subnet.private) == 2\n    error_message = \"Should create 2 private subnets\"\n  }\n\n  assert {\n    condition     = aws_instance.bastion.public_ip != \"\"\n    error_message = \"Bastion instance should have a public IP\"\n  }\n}\n\n# Cleanup happens automatically after test completes\n```\n\n## Cleanup and Destruction\n\n**Important**: Resources are destroyed in **reverse run block order** after test completion. This is critical for configurations with dependencies.\n\n**Example**: For S3 buckets containing objects, the bucket must be emptied before deletion:\n\n```hcl\nrun \"create_bucket_with_objects\" {\n  command = apply\n\n  assert {\n    condition     = aws_s3_bucket.example.id != \"\"\n    error_message = \"Bucket should be created\"\n  }\n}\n\nrun \"add_objects_to_bucket\" {\n  command = apply\n\n  assert {\n    condition     = length(aws_s3_object.files) > 0\n    error_message = \"Objects should be added\"\n  }\n}\n\n# Cleanup occurs in reverse order:\n# 1. Destroys objects (run \"add_objects_to_bucket\")\n# 2. Destroys bucket (run \"create_bucket_with_objects\")\n```\n\n**Disable Cleanup for Debugging:**\n\n```bash\nterraform test -no-cleanup\n```\n\n## Best Practices\n\n1. **Test Organization**: Organize tests by type using clear naming conventions:\n   - Unit tests (plan mode): `*_unit_test.tftest.hcl` - fast, no resources created\n   - Integration tests (apply mode): `*_integration_test.tftest.hcl` - creates real resources\n   - Example: `defaults_unit_test.tftest.hcl`, `validation_unit_test.tftest.hcl`, `full_stack_integration_test.tftest.hcl`\n   - This makes it easy to run unit tests separately from integration tests in CI/CD\n\n2. **Apply vs Plan**:\n   - Default is `command = apply` (integration testing with real resources)\n   - Use `command = plan` for unit tests (fast, no real resources)\n   - Use mocks for isolated unit testing\n\n3. **Meaningful Assertions**: Write clear, specific assertion error messages that help diagnose failures\n\n4. **Test Isolation**: Each run block should be independent when possible. Use sequential runs only when testing dependencies\n\n5. **Variable Coverage**: Test different variable combinations to validate all code paths. Remember that test variables have the highest precedence\n\n6. **Mock Providers**: Use mocks for external dependencies to speed up tests and reduce costs (requires Terraform 1.7.0+)\n\n7. **Cleanup**: Integration tests automatically destroy resources in reverse order after completion. Use `-no-cleanup` flag for debugging\n\n8. **CI Integration**: Run `terraform test` in CI/CD pipelines to catch issues early\n\n9. **Test Naming**: Use descriptive names for run blocks that explain what scenario is being tested\n\n10. **Negative Testing**: Test invalid inputs and expected failures using `expect_failures`\n\n11. **Module Support**: Remember that test files only support **local** and **registry** modules, not Git or other sources\n\n12. **Parallel Execution**: Use `parallel = true` for independent tests with different state files to speed up test execution\n\n## Advanced Features\n\n### Testing with Refresh-Only Mode\n\n```hcl\nrun \"test_refresh_only\" {\n  command = plan\n\n  plan_options {\n    mode = refresh-only\n  }\n\n  assert {\n    condition     = aws_instance.example.tags[\"Environment\"] == \"production\"\n    error_message = \"Tags should be refreshed correctly\"\n  }\n}\n```\n\n### Testing with Targeted Resources\n\n```hcl\nrun \"test_specific_resource\" {\n  command = plan\n\n  plan_options {\n    target = [\n      aws_instance.example\n    ]\n  }\n\n  assert {\n    condition     = aws_instance.example.instance_type == \"t2.micro\"\n    error_message = \"Targeted resource should be planned\"\n  }\n}\n```\n\n### Testing Multiple Modules in Parallel\n\n```hcl\nrun \"test_networking_module\" {\n  command  = plan\n  parallel = true\n\n  module {\n    source = \"./modules/networking\"\n  }\n\n  variables {\n    cidr_block = \"10.0.0.0/16\"\n  }\n\n  assert {\n    condition     = output.vpc_id != \"\"\n    error_message = \"VPC should be created\"\n  }\n}\n\nrun \"test_compute_module\" {\n  command  = plan\n  parallel = true\n\n  module {\n    source = \"./modules/compute\"\n  }\n\n  variables {\n    instance_type = \"t2.micro\"\n  }\n\n  assert {\n    condition     = output.instance_id != \"\"\n    error_message = \"Instance should be created\"\n  }\n}\n```\n\n### Custom State Management\n\n```hcl\nrun \"create_foundation\" {\n  command   = apply\n  state_key = \"foundation\"\n\n  assert {\n    condition     = aws_vpc.main.id != \"\"\n    error_message = \"Foundation VPC should be created\"\n  }\n}\n\nrun \"create_application\" {\n  command   = apply\n  state_key = \"foundation\"  # Share state with foundation\n\n  variables {\n    vpc_id = run.create_foundation.vpc_id\n  }\n\n  assert {\n    condition     = aws_instance.app.vpc_id == run.create_foundation.vpc_id\n    error_message = \"Application should use foundation VPC\"\n  }\n}\n```\n\n## Troubleshooting\n\n### Test Failures\n\n**Issue**: Assertion failures\n\n**Solution**: Review error messages, check actual vs expected values, verify variable inputs. Use `-verbose` flag for detailed output\n\n### Provider Authentication\n\n**Issue**: Tests fail due to missing credentials\n\n**Solution**: Configure provider credentials for testing, or use mock providers for unit tests (available since v1.7.0)\n\n### Resource Dependencies\n\n**Issue**: Tests fail due to missing dependencies\n\n**Solution**: Use sequential run blocks or create setup runs to establish required resources. Remember cleanup happens in reverse order\n\n### Long Test Execution\n\n**Issue**: Tests take too long to run\n\n**Solution**:\n- Use `command = plan` instead of `apply` where possible\n- Leverage mock providers\n- Use `parallel = true` for independent tests\n- Organize slow integration tests separately\n\n### State Conflicts\n\n**Issue**: Multiple tests interfere with each other\n\n**Solution**:\n- Use different modules (automatic separate state)\n- Use `state_key` attribute to control state file sharing\n- Use mock providers for isolated testing\n\n### Module Source Errors\n\n**Issue**: Test fails with unsupported module source\n\n**Solution**: Terraform test files only support **local** and **registry** modules. Convert Git or HTTP sources to local modules or use registry modules\n\n## Example Test Suite\n\nComplete example testing a VPC module, demonstrating both unit tests (plan mode) and integration tests (apply mode):\n\n```hcl\n# tests/vpc_module_unit_test.tftest.hcl\n# This file contains unit tests using command = plan (fast, no resources created)\n\nvariables {\n  environment = \"test\"\n  aws_region  = \"us-west-2\"\n}\n\n# ============================================================================\n# UNIT TESTS (Plan Mode) - Validate logic without creating resources\n# ============================================================================\n\n# Test default configuration\nrun \"test_defaults\" {\n  command = plan\n\n  variables {\n    vpc_cidr = \"10.0.0.0/16\"\n    vpc_name = \"test-vpc\"\n  }\n\n  assert {\n    condition     = aws_vpc.main.cidr_block == \"10.0.0.0/16\"\n    error_message = \"VPC CIDR should match input\"\n  }\n\n  assert {\n    condition     = aws_vpc.main.enable_dns_hostnames == true\n    error_message = \"DNS hostnames should be enabled by default\"\n  }\n\n  assert {\n    condition     = aws_vpc.main.tags[\"Name\"] == \"test-vpc\"\n    error_message = \"VPC name tag should match input\"\n  }\n}\n\n# Test subnet creation\nrun \"test_subnets\" {\n  command = plan\n\n  variables {\n    vpc_cidr        = \"10.0.0.0/16\"\n    vpc_name        = \"test-vpc\"\n    public_subnets  = [\"10.0.1.0/24\", \"10.0.2.0/24\"]\n    private_subnets = [\"10.0.10.0/24\", \"10.0.11.0/24\"]\n  }\n\n  assert {\n    condition     = length(aws_subnet.public) == 2\n    error_message = \"Should create 2 public subnets\"\n  }\n\n  assert {\n    condition     = length(aws_subnet.private) == 2\n    error_message = \"Should create 2 private subnets\"\n  }\n\n  assert {\n    condition = alltrue([\n      for subnet in aws_subnet.private :\n      subnet.map_public_ip_on_launch == false\n    ])\n    error_message = \"Private subnets should not assign public IPs\"\n  }\n}\n\n# Test outputs\nrun \"test_outputs\" {\n  command = plan\n\n  variables {\n    vpc_cidr = \"10.0.0.0/16\"\n    vpc_name = \"test-vpc\"\n  }\n\n  assert {\n    condition     = output.vpc_id != \"\"\n    error_message = \"VPC ID output should not be empty\"\n  }\n\n  assert {\n    condition     = can(regex(\"^vpc-\", output.vpc_id))\n    error_message = \"VPC ID should have correct format\"\n  }\n\n  assert {\n    condition     = output.vpc_cidr == \"10.0.0.0/16\"\n    error_message = \"VPC CIDR output should match input\"\n  }\n}\n\n# Test invalid CIDR block\nrun \"test_invalid_cidr\" {\n  command = plan\n\n  variables {\n    vpc_cidr = \"invalid\"\n    vpc_name = \"test-vpc\"\n  }\n\n  expect_failures = [\n    var.vpc_cidr\n  ]\n}\n```\n\n```hcl\n# tests/vpc_module_integration_test.tftest.hcl\n# This file contains integration tests using command = apply (creates real resources)\n\nvariables {\n  environment = \"integration-test\"\n  aws_region  = \"us-west-2\"\n}\n\n# ============================================================================\n# INTEGRATION TESTS (Apply Mode) - Creates and validates real infrastructure\n# ============================================================================\n\n# Integration test creating real VPC\nrun \"integration_test_vpc_creation\" {\n  # command defaults to apply - creates real AWS resources!\n\n  variables {\n    vpc_cidr = \"10.100.0.0/16\"\n    vpc_name = \"integration-test-vpc\"\n  }\n\n  assert {\n    condition     = aws_vpc.main.id != \"\"\n    error_message = \"VPC should be created with valid ID\"\n  }\n\n  assert {\n    condition     = aws_vpc.main.state == \"available\"\n    error_message = \"VPC should be in available state\"\n  }\n}\n```\n\n```hcl\n# tests/vpc_module_mock_test.tftest.hcl\n# This file demonstrates mock provider testing - fastest option, no credentials needed\n\n# ============================================================================\n# MOCK TESTS (Plan Mode with Mocks) - No real infrastructure or API calls\n# ============================================================================\n# Mock tests are ideal for:\n# - Testing complex logic without cloud costs\n# - Running tests without provider credentials\n# - Fast feedback in local development\n# - CI/CD pipelines without cloud access\n# - Testing with predictable data source results\n\n# Define mock provider to simulate AWS behavior\nmock_provider \"aws\" {\n  # Mock EC2 instances - returns these values instead of creating real resources\n  mock_resource \"aws_instance\" {\n    defaults = {\n      id                          = \"i-1234567890abcdef0\"\n      arn                         = \"arn:aws:ec2:us-west-2:123456789012:instance/i-1234567890abcdef0\"\n      instance_type               = \"t2.micro\"\n      ami                         = \"ami-12345678\"\n      availability_zone           = \"us-west-2a\"\n      subnet_id                   = \"subnet-12345678\"\n      vpc_security_group_ids      = [\"sg-12345678\"]\n      associate_public_ip_address = true\n      public_ip                   = \"203.0.113.1\"\n      private_ip                  = \"10.0.1.100\"\n      tags                        = {}\n    }\n  }\n\n  # Mock VPC resources\n  mock_resource \"aws_vpc\" {\n    defaults = {\n      id                       = \"vpc-12345678\"\n      arn                      = \"arn:aws:ec2:us-west-2:123456789012:vpc/vpc-12345678\"\n      cidr_block              = \"10.0.0.0/16\"\n      enable_dns_hostnames    = true\n      enable_dns_support      = true\n      instance_tenancy        = \"default\"\n      tags                    = {}\n    }\n  }\n\n  # Mock subnet resources\n  mock_resource \"aws_subnet\" {\n    defaults = {\n      id                      = \"subnet-12345678\"\n      arn                     = \"arn:aws:ec2:us-west-2:123456789012:subnet/subnet-12345678\"\n      vpc_id                  = \"vpc-12345678\"\n      cidr_block             = \"10.0.1.0/24\"\n      availability_zone       = \"us-west-2a\"\n      map_public_ip_on_launch = false\n      tags                    = {}\n    }\n  }\n\n  # Mock S3 bucket resources\n  mock_resource \"aws_s3_bucket\" {\n    defaults = {\n      id                  = \"test-bucket-12345\"\n      arn                 = \"arn:aws:s3:::test-bucket-12345\"\n      bucket              = \"test-bucket-12345\"\n      bucket_domain_name  = \"test-bucket-12345.s3.amazonaws.com\"\n      region              = \"us-west-2\"\n      tags                = {}\n    }\n  }\n\n  # Mock data sources - critical for testing modules that query existing infrastructure\n  mock_data \"aws_ami\" {\n    defaults = {\n      id                  = \"ami-0c55b159cbfafe1f0\"\n      name                = \"ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-20210430\"\n      architecture        = \"x86_64\"\n      root_device_type    = \"ebs\"\n      virtualization_type = \"hvm\"\n      owners              = [\"099720109477\"]\n    }\n  }\n\n  mock_data \"aws_availability_zones\" {\n    defaults = {\n      names = [\"us-west-2a\", \"us-west-2b\", \"us-west-2c\"]\n      zone_ids = [\"usw2-az1\", \"usw2-az2\", \"usw2-az3\"]\n    }\n  }\n\n  mock_data \"aws_vpc\" {\n    defaults = {\n      id                   = \"vpc-12345678\"\n      cidr_block          = \"10.0.0.0/16\"\n      enable_dns_hostnames = true\n      enable_dns_support   = true\n    }\n  }\n}\n\n# Test 1: Validate resource configuration with mocked values\nrun \"test_instance_with_mocks\" {\n  command = plan  # Mocks only work with plan mode\n\n  variables {\n    instance_type = \"t2.micro\"\n    ami_id        = \"ami-12345678\"\n  }\n\n  assert {\n    condition     = aws_instance.example.instance_type == \"t2.micro\"\n    error_message = \"Instance type should match input variable\"\n  }\n\n  assert {\n    condition     = aws_instance.example.id == \"i-1234567890abcdef0\"\n    error_message = \"Mock should return consistent instance ID\"\n  }\n\n  assert {\n    condition     = can(regex(\"^203\\\\.0\\\\.113\\\\.\", aws_instance.example.public_ip))\n    error_message = \"Mock public IP should be in TEST-NET-3 range\"\n  }\n}\n\n# Test 2: Validate data source behavior with mocked results\nrun \"test_data_source_with_mocks\" {\n  command = plan\n\n  assert {\n    condition     = data.aws_ami.ubuntu.id == \"ami-0c55b159cbfafe1f0\"\n    error_message = \"Mock data source should return predictable AMI ID\"\n  }\n\n  assert {\n    condition     = length(data.aws_availability_zones.available.names) == 3\n    error_message = \"Should return 3 mocked availability zones\"\n  }\n\n  assert {\n    condition = contains(\n      data.aws_availability_zones.available.names,\n      \"us-west-2a\"\n    )\n    error_message = \"Should include us-west-2a in mocked zones\"\n  }\n}\n\n# Test 3: Validate complex logic with for_each and mocks\nrun \"test_multiple_subnets_with_mocks\" {\n  command = plan\n\n  variables {\n    subnet_cidrs = {\n      \"public-a\"  = \"10.0.1.0/24\"\n      \"public-b\"  = \"10.0.2.0/24\"\n      \"private-a\" = \"10.0.10.0/24\"\n      \"private-b\" = \"10.0.11.0/24\"\n    }\n  }\n\n  # Test that all subnets are created\n  assert {\n    condition     = length(keys(aws_subnet.subnets)) == 4\n    error_message = \"Should create 4 subnets from for_each map\"\n  }\n\n  # Test that public subnets have correct naming\n  assert {\n    condition = alltrue([\n      for name, subnet in aws_subnet.subnets :\n      can(regex(\"^public-\", name)) ? subnet.map_public_ip_on_launch == true : true\n    ])\n    error_message = \"Public subnets should map public IPs on launch\"\n  }\n\n  # Test that all subnets belong to mocked VPC\n  assert {\n    condition = alltrue([\n      for subnet in aws_subnet.subnets :\n      subnet.vpc_id == \"vpc-12345678\"\n    ])\n    error_message = \"All subnets should belong to mocked VPC\"\n  }\n}\n\n# Test 4: Validate output values with mocks\nrun \"test_outputs_with_mocks\" {\n  command = plan\n\n  assert {\n    condition     = output.vpc_id == \"vpc-12345678\"\n    error_message = \"VPC ID output should match mocked value\"\n  }\n\n  assert {\n    condition     = can(regex(\"^vpc-\", output.vpc_id))\n    error_message = \"VPC ID output should have correct format\"\n  }\n\n  assert {\n    condition     = output.instance_public_ip == \"203.0.113.1\"\n    error_message = \"Instance public IP should match mock\"\n  }\n}\n\n# Test 5: Test conditional logic with mocks\nrun \"test_conditional_resources_with_mocks\" {\n  command = plan\n\n  variables {\n    create_bastion     = true\n    create_nat_gateway = false\n  }\n\n  assert {\n    condition     = length(aws_instance.bastion) == 1\n    error_message = \"Bastion should be created when enabled\"\n  }\n\n  assert {\n    condition     = length(aws_nat_gateway.nat) == 0\n    error_message = \"NAT gateway should not be created when disabled\"\n  }\n}\n\n# Test 6: Test tag propagation with mocks\nrun \"test_tag_inheritance_with_mocks\" {\n  command = plan\n\n  variables {\n    common_tags = {\n      Environment = \"test\"\n      ManagedBy   = \"Terraform\"\n      Project     = \"MockTesting\"\n    }\n  }\n\n  # Verify tags are properly merged with defaults\n  assert {\n    condition = alltrue([\n      for key in keys(var.common_tags) :\n      contains(keys(aws_instance.example.tags), key)\n    ])\n    error_message = \"All common tags should be present on instance\"\n  }\n\n  assert {\n    condition     = aws_instance.example.tags[\"Environment\"] == \"test\"\n    error_message = \"Environment tag should be set correctly\"\n  }\n}\n\n# Test 7: Test validation rules with mocks (expect_failures)\nrun \"test_invalid_cidr_with_mocks\" {\n  command = plan\n\n  variables {\n    vpc_cidr = \"192.168.0.0/8\"  # Invalid - should be /16 or /24\n  }\n\n  # Expect custom validation to fail\n  expect_failures = [\n    var.vpc_cidr\n  ]\n}\n\n# Test 8: Sequential mock tests with state sharing\nrun \"setup_vpc_with_mocks\" {\n  command = plan\n\n  variables {\n    vpc_cidr = \"10.0.0.0/16\"\n    vpc_name = \"test-vpc\"\n  }\n\n  assert {\n    condition     = aws_vpc.main.cidr_block == \"10.0.0.0/16\"\n    error_message = \"VPC CIDR should match input\"\n  }\n}\n\nrun \"test_subnet_references_vpc_with_mocks\" {\n  command = plan\n\n  variables {\n    vpc_id      = run.setup_vpc_with_mocks.vpc_id\n    subnet_cidr = \"10.0.1.0/24\"\n  }\n\n  assert {\n    condition     = aws_subnet.example.vpc_id == run.setup_vpc_with_mocks.vpc_id\n    error_message = \"Subnet should reference VPC from previous run\"\n  }\n\n  assert {\n    condition     = aws_subnet.example.vpc_id == \"vpc-12345678\"\n    error_message = \"VPC ID should match mocked value\"\n  }\n}\n```\n\n**Key Benefits of Mock Testing:**\n\n1. **No Cloud Costs**: Runs entirely locally without creating infrastructure\n2. **No Credentials Needed**: Perfect for CI/CD environments without cloud access\n3. **Fast Execution**: Tests complete in seconds, not minutes\n4. **Predictable Results**: Data sources return consistent values\n5. **Isolated Testing**: No dependencies on existing cloud resources\n6. **Safe Experimentation**: Test destructive operations without risk\n\n**Limitations of Mock Testing:**\n\n1. **Plan Mode Only**: Mocks don't work with `command = apply`\n2. **Not Real Behavior**: Mocks may not reflect actual provider API behavior\n3. **Computed Values**: Mock defaults may not match real computed attributes\n4. **Provider Updates**: Mocks need manual updates when provider schemas change\n5. **Resource Interactions**: Can't test real resource dependencies or timing issues\n\n**When to Use Mock Tests:**\n\n- âœ… Testing Terraform logic and conditionals\n- âœ… Validating variable transformations\n- âœ… Testing for_each and count expressions\n- âœ… Checking output calculations\n- âœ… Local development without cloud access\n- âœ… Fast CI/CD feedback loops\n- âŒ Validating actual provider behavior\n- âŒ Testing real resource creation side effects\n- âŒ Verifying API-level interactions\n- âŒ End-to-end integration testing\n\n## CI/CD Integration\n\n### GitHub Actions Example\n\n```yaml\nname: Terraform Tests\n\non:\n  pull_request:\n    branches: [ main ]\n  push:\n    branches: [ main ]\n\njobs:\n  terraform-test:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Setup Terraform\n        uses: hashicorp/setup-terraform@v3\n        with:\n          terraform_version: 1.9.0\n\n      - name: Terraform Format Check\n        run: terraform fmt -check -recursive\n\n      - name: Terraform Init\n        run: terraform init\n\n      - name: Terraform Validate\n        run: terraform validate\n\n      - name: Run Terraform Tests\n        run: terraform test -verbose\n        env:\n          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}\n          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n```\n\n### GitLab CI Example\n\n```yaml\nterraform-test:\n  image: hashicorp/terraform:1.9\n  stage: test\n  before_script:\n    - terraform init\n  script:\n    - terraform fmt -check -recursive\n    - terraform validate\n    - terraform test -verbose\n  only:\n    - merge_requests\n    - main\n```\n\n## References\n\nFor more information:\n- [Terraform Testing Documentation](https://developer.hashicorp.com/terraform/language/tests)\n- [Terraform Test Command Reference](https://developer.hashicorp.com/terraform/cli/commands/test)\n- [Testing Best Practices](https://developer.hashicorp.com/terraform/language/tests/best-practices)\n",
        "terraform/module-generation/.claude-plugin/plugin.json": "{\n  \"name\": \"terraform-module-generation\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Terraform module generation and refactoring skills for Claude Code, including module design and Terraform Stacks.\",\n  \"author\": {\n    \"name\": \"HashiCorp\",\n    \"url\": \"https://github.com/hashicorp\"\n  },\n  \"homepage\": \"https://developer.hashicorp.com/terraform/language/modules\",\n  \"repository\": \"https://github.com/hashicorp/agent-skills\",\n  \"license\": \"MPL-2.0\",\n  \"keywords\": [\"terraform\", \"modules\", \"infrastructure\", \"iac\", \"stacks\", \"refactoring\"],\n  \"mcpServers\": {\n    \"terraform\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\", \"TFE_TOKEN\",\n        \"-e\", \"TFE_ADDRESS\",\n        \"hashicorp/terraform-mcp-server\"\n      ],\n      \"env\": {\n        \"TFE_TOKEN\": \"${TFE_TOKEN}\",\n        \"TFE_ADDRESS\": \"${TFE_ADDRESS}\"\n      }\n    }\n  }\n}\n",
        "terraform/module-generation/skills/refactor-module/SKILL.md": "---\nname: refactor-module\ndescription: Transform monolithic Terraform configurations into reusable, maintainable modules following HashiCorp's module design principles and community best practices.\nmetadata:\n  copyright: Copyright IBM Corp. 2026\n  version: \"0.0.1\"\n---\n\n# Skill: Refactor Module\n\n## Overview\nThis skill guides AI agents in transforming monolithic Terraform configurations into reusable, maintainable modules following HashiCorp's module design principles and community best practices.\n\n## Capability Statement\nThe agent will analyze existing Terraform code and systematically refactor it into well-structured modules with:\n- Clear interface contracts (variables and outputs)\n- Proper encapsulation and abstraction\n- Versioning and documentation\n- Testing frameworks\n- Migration path for existing state\n\n## Prerequisites\n- Existing Terraform configuration to refactor\n- Understanding of resource dependencies\n- Access to current state file (for migration planning)\n- Knowledge of module registry patterns\n\n## Input Parameters\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `source_directory` | string | Yes | Path to existing Terraform configuration |\n| `module_name` | string | Yes | Name for the new module |\n| `abstraction_level` | string | No | \"simple\", \"intermediate\", \"advanced\" (default: intermediate) |\n| `preserve_state` | boolean | Yes | Whether to maintain state compatibility |\n| `target_registry` | string | No | Target module registry (local, private, public) |\n\n## Execution Steps\n\n### 1. Analysis Phase\n```markdown\n**Identify Refactoring Candidates**\n- Group resources by logical function\n- Identify repeated patterns\n- Map resource dependencies\n- Detect configuration coupling\n- Analyze variable usage patterns\n\n**Complexity Assessment**\n- Count resource relationships\n- Measure variable propagation depth\n- Identify cross-resource references\n- Evaluate state migration complexity\n```\n\n### 2. Module Design\n\n#### Interface Design\n```hcl\n# Define clear input contract\nvariable \"network_config\" {\n  description = \"Network configuration parameters\"\n  type = object({\n    cidr_block         = string\n    availability_zones = list(string)\n    enable_nat         = bool\n  })\n  \n  validation {\n    condition     = can(cidrhost(var.network_config.cidr_block, 0))\n    error_message = \"CIDR block must be valid IPv4 CIDR.\"\n  }\n}\n\n# Define output contract\noutput \"vpc_id\" {\n  description = \"ID of the created VPC\"\n  value       = aws_vpc.main.id\n}\n\noutput \"private_subnet_ids\" {\n  description = \"List of private subnet IDs\"\n  value       = { for k, v in aws_subnet.private : k => v.id }\n}\n```\n\n#### Encapsulation Strategy\n```markdown\n**What to Include in Module:**\n- Tightly coupled resources (VPC + subnets)\n- Resources with shared lifecycle\n- Configuration with clear boundaries\n\n**What to Keep Separate:**\n- Cross-cutting concerns (monitoring, tagging)\n- Resources with different lifecycles\n- Provider-specific configurations\n```\n\n### 3. Code Transformation\n\n#### Before: Monolithic Configuration\n```hcl\n# main.tf (monolithic)\nresource \"aws_vpc\" \"main\" {\n  cidr_block = \"10.0.0.0/16\"\n  enable_dns_hostnames = true\n  \n  tags = {\n    Name = \"production-vpc\"\n    Environment = \"prod\"\n  }\n}\n\nresource \"aws_subnet\" \"public_1\" {\n  vpc_id            = aws_vpc.main.id\n  cidr_block        = \"10.0.1.0/24\"\n  availability_zone = \"us-east-1a\"\n  \n  tags = {\n    Name = \"public-subnet-1\"\n    Type = \"public\"\n  }\n}\n\nresource \"aws_subnet\" \"public_2\" {\n  vpc_id            = aws_vpc.main.id\n  cidr_block        = \"10.0.2.0/24\"\n  availability_zone = \"us-east-1b\"\n  \n  tags = {\n    Name = \"public-subnet-2\"\n    Type = \"public\"\n  }\n}\n\nresource \"aws_internet_gateway\" \"main\" {\n  vpc_id = aws_vpc.main.id\n  \n  tags = {\n    Name = \"production-igw\"\n  }\n}\n\n# ... more repetitive subnet and routing resources\n```\n\n#### After: Modular Structure\n```hcl\n# modules/vpc/main.tf\nlocals {\n  subnet_count = length(var.availability_zones)\n}\n\nresource \"aws_vpc\" \"main\" {\n  cidr_block           = var.cidr_block\n  enable_dns_hostnames = var.enable_dns_hostnames\n  enable_dns_support   = var.enable_dns_support\n  \n  tags = merge(\n    var.tags,\n    {\n      Name = var.name\n    }\n  )\n}\n\nresource \"aws_subnet\" \"public\" {\n  for_each = var.create_public_subnets ? toset(var.availability_zones) : []\n  \n  vpc_id                  = aws_vpc.main.id\n  cidr_block              = cidrsubnet(var.cidr_block, 8, index(var.availability_zones, each.value))\n  availability_zone       = each.value\n  map_public_ip_on_launch = true\n  \n  tags = merge(\n    var.tags,\n    {\n      Name = \"${var.name}-public-${each.value}\"\n      Type = \"public\"\n    }\n  )\n}\n\nresource \"aws_internet_gateway\" \"main\" {\n  count  = var.create_public_subnets ? 1 : 0\n  vpc_id = aws_vpc.main.id\n  \n  tags = merge(\n    var.tags,\n    {\n      Name = \"${var.name}-igw\"\n    }\n  )\n}\n\n# modules/vpc/variables.tf\nvariable \"name\" {\n  description = \"Name prefix for all resources\"\n  type        = string\n}\n\nvariable \"cidr_block\" {\n  description = \"CIDR block for the VPC\"\n  type        = string\n  \n  validation {\n    condition     = can(cidrhost(var.cidr_block, 0))\n    error_message = \"Must be a valid IPv4 CIDR block.\"\n  }\n}\n\nvariable \"availability_zones\" {\n  description = \"List of availability zones\"\n  type        = list(string)\n}\n\nvariable \"create_public_subnets\" {\n  description = \"Whether to create public subnets\"\n  type        = bool\n  default     = true\n}\n\nvariable \"enable_dns_hostnames\" {\n  description = \"Enable DNS hostnames in the VPC\"\n  type        = bool\n  default     = true\n}\n\nvariable \"enable_dns_support\" {\n  description = \"Enable DNS support in the VPC\"\n  type        = bool\n  default     = true\n}\n\nvariable \"tags\" {\n  description = \"Tags to apply to all resources\"\n  type        = map(string)\n  default     = {}\n}\n\n# modules/vpc/outputs.tf\noutput \"vpc_id\" {\n  description = \"ID of the VPC\"\n  value       = aws_vpc.main.id\n}\n\noutput \"vpc_cidr_block\" {\n  description = \"CIDR block of the VPC\"\n  value       = aws_vpc.main.cidr_block\n}\n\noutput \"public_subnet_ids\" {\n  description = \"Map of availability zones to public subnet IDs\"\n  value       = { for k, v in aws_subnet.public : k => v.id }\n}\n\noutput \"internet_gateway_id\" {\n  description = \"ID of the internet gateway\"\n  value       = try(aws_internet_gateway.main[0].id, null)\n}\n\n# Root configuration using module\nmodule \"vpc\" {\n  source = \"./modules/vpc\"\n  \n  name               = \"production\"\n  cidr_block         = \"10.0.0.0/16\"\n  availability_zones = [\"us-east-1a\", \"us-east-1b\", \"us-east-1c\"]\n  \n  tags = {\n    Environment = \"production\"\n    ManagedBy   = \"Terraform\"\n  }\n}\n```\n\n### 4. State Migration\n\n#### Generate Migration Plan\n```hcl\n# migration.tf\n# Use moved blocks for state refactoring (Terraform 1.1+)\n\nmoved {\n  from = aws_vpc.main\n  to   = module.vpc.aws_vpc.main\n}\n\nmoved {\n  from = aws_subnet.public_1\n  to   = module.vpc.aws_subnet.public[\"us-east-1a\"]\n}\n\nmoved {\n  from = aws_subnet.public_2\n  to   = module.vpc.aws_subnet.public[\"us-east-1b\"]\n}\n\nmoved {\n  from = aws_internet_gateway.main\n  to   = module.vpc.aws_internet_gateway.main[0]\n}\n```\n\n#### Manual State Migration (Pre-1.1)\n```bash\n# Generate state migration commands\nterraform state mv aws_vpc.main module.vpc.aws_vpc.main\nterraform state mv aws_subnet.public_1 'module.vpc.aws_subnet.public[\"us-east-1a\"]'\nterraform state mv aws_subnet.public_2 'module.vpc.aws_subnet.public[\"us-east-1b\"]'\nterraform state mv aws_internet_gateway.main 'module.vpc.aws_internet_gateway.main[0]'\n```\n\n### 5. Module Documentation\n\n```markdown\n# VPC Module\n\n## Overview\nCreates a VPC with configurable public and private subnets across multiple availability zones.\n\n## Features\n- Multi-AZ subnet deployment\n- Optional NAT gateway configuration\n- VPC Flow Logs integration\n- Customizable CIDR allocation\n\n## Usage\n\n\\`\\`\\`hcl\nmodule \"vpc\" {\n  source = \"./modules/vpc\"\n  \n  name               = \"my-vpc\"\n  cidr_block         = \"10.0.0.0/16\"\n  availability_zones = [\"us-east-1a\", \"us-east-1b\"]\n  \n  create_public_subnets  = true\n  create_private_subnets = true\n  enable_nat_gateway     = true\n  \n  tags = {\n    Environment = \"production\"\n  }\n}\n\\`\\`\\`\n\n## Requirements\n\n| Name | Version |\n|------|---------|\n| terraform | >= 1.5.0 |\n| aws | ~> 5.0 |\n\n## Inputs\n\n| Name | Description | Type | Default | Required |\n|------|-------------|------|---------|----------|\n| name | Name prefix for resources | `string` | n/a | yes |\n| cidr_block | VPC CIDR block | `string` | n/a | yes |\n| availability_zones | List of AZs | `list(string)` | n/a | yes |\n\n## Outputs\n\n| Name | Description |\n|------|-------------|\n| vpc_id | VPC identifier |\n| public_subnet_ids | Map of public subnet IDs |\n| private_subnet_ids | Map of private subnet IDs |\n\n## Examples\n\nSee [examples/](./examples/) directory for complete usage examples.\n```\n\n### 6. Testing\n\nUse skill terraform-test\n\n**Test File**: A `.tftest.hcl` or `.tftest.json` file containing test configuration and run blocks that validate your Terraform configuration.\n\n**Test Block**: Optional configuration block that defines test-wide settings (available since Terraform 1.6.0).\n\n**Run Block**: Defines a single test scenario with optional variables, provider configurations, and assertions. Each test file requires at least one run block.\n\n**Assert Block**: Contains conditions that must evaluate to true for the test to pass. Failed assertions cause the test to fail.\n\n**Mock Provider**: Simulates provider behavior without creating real infrastructure (available since Terraform 1.7.0).\n\n**Test Modes**: Tests run in apply mode (default, creates real infrastructure) or plan mode (validates logic without creating resources).\n\n#### File Structure\n\nTerraform test files use the `.tftest.hcl` or `.tftest.json` extension and are typically organized in a `tests/` directory. Use clear naming conventions to distinguish between unit tests (plan mode) and integration tests (apply mode):\n\n```\nmy-module/\nâ”œâ”€â”€ main.tf\nâ”œâ”€â”€ variables.tf\nâ”œâ”€â”€ outputs.tf\nâ””â”€â”€ tests/\n    â”œâ”€â”€ unit_test.tftest.hcl      # Unit test (plan mode)\n    â””â”€â”€ integration_test.tftest.hcl  # Integration test (apply mode - creates real resources)\n```\n\n## Refactoring Patterns\n\n### Pattern 1: Resource Grouping\nExtract related resources into cohesive modules:\n- Networking (VPC, Subnets, Route Tables)\n- Compute (ASG, Launch Templates, Load Balancers)\n- Data (RDS, ElastiCache, S3)\n\n### Pattern 2: Configuration Layering\n```hcl\n# Base module with defaults\nmodule \"vpc_base\" {\n  source = \"./modules/vpc-base\"\n  # Minimal required inputs\n}\n\n# Environment-specific wrapper\nmodule \"vpc_prod\" {\n  source = \"./modules/vpc-production\"\n  # Inherits from base, adds prod-specific config\n}\n```\n\n### Pattern 3: Composition\n```hcl\n# Small, focused modules\nmodule \"vpc\" {\n  source = \"./modules/vpc\"\n}\n\nmodule \"security_groups\" {\n  source = \"./modules/security-groups\"\n  vpc_id = module.vpc.vpc_id\n}\n\nmodule \"application\" {\n  source     = \"./modules/application\"\n  vpc_id     = module.vpc.vpc_id\n  subnet_ids = module.vpc.private_subnet_ids\n  sg_ids     = module.security_groups.app_sg_ids\n}\n```\n\n## Common Pitfalls\n\n### 1. Over-Abstraction\n```hcl\n# âŒ Don't create overly generic modules\nvariable \"resources\" {\n  type = map(map(any))  # Too flexible, hard to validate\n}\n\n# âœ… Do use specific, typed interfaces\nvariable \"database_config\" {\n  type = object({\n    engine         = string\n    instance_class = string\n  })\n}\n```\n\n### 2. Tight Coupling\n```hcl\n# âŒ Don't couple modules through direct references\n# module A\noutput \"instance_id\" { value = aws_instance.app.id }\n\n# module B (in same config)\nresource \"aws_eip\" \"app\" {\n  instance = module.a.instance_id  # Tight coupling\n}\n\n# âœ… Do pass dependencies through root module\nmodule \"compute\" {\n  source = \"./modules/compute\"\n}\n\nresource \"aws_eip\" \"app\" {\n  instance = module.compute.instance_id\n}\n```\n\n### 3. State Migration Errors\nAlways test migration in non-production first:\n```bash\n# Create plan to verify no changes after migration\nterraform plan -out=migration.tfplan\n\n# Review carefully\nterraform show migration.tfplan\n\n# Apply only if plan shows no changes\nterraform apply migration.tfplan\n```\n\n## Version Control Strategy\n\n```hcl\n# Use semantic versioning for modules\nmodule \"vpc\" {\n  source  = \"git::https://github.com/org/terraform-modules.git//vpc?ref=v1.2.0\"\n  version = \"~> 1.2\"\n}\n\n# Pin to specific versions in production\n# Use version ranges in development\n```\n\n## Success Criteria\n\n- [ ] Module has single, well-defined responsibility\n- [ ] All variables have descriptions and types\n- [ ] Validation rules prevent invalid configurations\n- [ ] Outputs provide sufficient information for consumers\n- [ ] Documentation includes usage examples\n- [ ] Tests verify module behavior\n- [ ] State migration completed without resource recreation\n- [ ] No plan differences after refactoring\n\n## Related Skills\n- [Generate HCL](../generate-hcl/SKILL.md) - Create new module code\n- [Validate Configuration](../validate-configuration/SKILL.md) - Test refactored modules\n\n## Resources\n- [Terraform Module Development](https://developer.hashicorp.com/terraform/language/modules/develop)\n- [Module Best Practices](https://developer.hashicorp.com/terraform/cloud-docs/registry/design)\n\n## Revision History\n\n| Version | Date | Changes |\n|---------|------|---------|\n| 1.0.0 | 2025-11-07 | Initial skill definition |\n",
        "terraform/module-generation/skills/terraform-stacks/SKILL.md": "---\nname: terraform-stacks\ndescription: Comprehensive guide for working with HashiCorp Terraform Stacks. Use when creating, modifying, or validating Terraform Stack configurations (.tfcomponent.hcl, .tfdeploy.hcl files), working with stack components and deployments from local modules, public registry, or private registry sources, managing multi-region or multi-environment infrastructure, or troubleshooting Terraform Stacks syntax and structure.\nmetadata:\n  copyright: Copyright IBM Corp. 2026\n  version: \"0.0.1\"\n---\n\n# Terraform Stacks\n\nTerraform Stacks simplify infrastructure provisioning and management at scale by providing a configuration layer above traditional Terraform modules. Stacks enable declarative orchestration of multiple components across environments, regions, and cloud accounts.\n\n## Core Concepts\n\n**Stack**: A complete unit of infrastructure composed of components and deployments that can be managed together.\n\n**Component**: An abstraction around a Terraform module that defines infrastructure pieces. Each component specifies a source module, inputs, and providers.\n\n**Deployment**: An instance of all components in a stack with specific input values. Use deployments for different environments (dev/staging/prod), regions, or cloud accounts.\n\n**Stack Language**: A separate HCL-based language (not regular Terraform HCL) with distinct blocks and file extensions.\n\n## File Structure\n\nTerraform Stacks use specific file extensions:\n\n- **Component configuration**: `.tfcomponent.hcl`\n- **Deployment configuration**: `.tfdeploy.hcl`\n- **Provider lock file**: `.terraform.lock.hcl` (generated by CLI)\n\nAll configuration files must be at the root level of the Stack repository. HCP Terraform processes all files in dependency order.\n\n### Recommended File Organization\n\n```\nmy-stack/\nâ”œâ”€â”€ variables.tfcomponent.hcl        # Variable declarations\nâ”œâ”€â”€ providers.tfcomponent.hcl        # Provider configurations\nâ”œâ”€â”€ components.tfcomponent.hcl       # Component definitions\nâ”œâ”€â”€ outputs.tfcomponent.hcl          # Stack outputs\nâ”œâ”€â”€ deployments.tfdeploy.hcl         # Deployment definitions\nâ”œâ”€â”€ .terraform.lock.hcl              # Provider lock file (generated)\nâ””â”€â”€ modules/                         # Local modules (optional - only if using local modules)\n    â”œâ”€â”€ vpc/\n    â””â”€â”€ compute/\n```\n\n**Note**: The `modules/` directory is only required when using local module sources. Components can reference modules from:\n- Local file paths: `./modules/vpc`\n- Public registry: `terraform-aws-modules/vpc/aws`\n- Private registry: `app.terraform.io/<org-name>/vpc/aws`\n\nWhen validating Stack configurations, check component source declarations rather than assuming a local `modules/` directory must exist.\n\n## Component Configuration (.tfcomponent.hcl)\n\n### Variable Block\n\nDeclare input variables for the Stack configuration. Variables must define a `type` field and do not support the `validation` argument.\n\n```hcl\nvariable \"aws_region\" {\n  type        = string\n  description = \"AWS region for deployments\"\n  default     = \"us-west-1\"\n}\n\nvariable \"identity_token\" {\n  type        = string\n  description = \"OIDC identity token\"\n  ephemeral   = true  # Does not persist to state file\n}\n\nvariable \"instance_count\" {\n  type     = number\n  nullable = false\n}\n```\n\n### Required Providers Block\n\nWorks the same as traditional Terraform configurations:\n\n```hcl\nrequired_providers {\n  aws = {\n    source  = \"hashicorp/aws\"\n    version = \"~> 5.7.0\"\n  }\n  random = {\n    source  = \"hashicorp/random\"\n    version = \"~> 3.5.0\"\n  }\n}\n```\n\n### Provider Block\n\nProvider blocks differ from traditional Terraform:\n\n1. Support `for_each` meta-argument\n2. Define aliases in the block header (not as an argument)\n3. Accept configuration through a `config` block\n\n**Single Provider Configuration:**\n\n```hcl\nprovider \"aws\" \"this\" {\n  config {\n    region = var.aws_region\n    assume_role_with_web_identity {\n      role_arn           = var.role_arn\n      web_identity_token = var.identity_token\n    }\n  }\n}\n```\n\n**Multiple Provider Configurations with for_each:**\n\n```hcl\nprovider \"aws\" \"configurations\" {\n  for_each = var.regions\n  \n  config {\n    region = each.value\n    assume_role_with_web_identity {\n      role_arn           = var.role_arn\n      web_identity_token = var.identity_token\n    }\n  }\n}\n```\n\n### Component Block\n\nEach Stack requires at least one component block. Add a component for each module to include in the Stack.\n\n**Component Source**: Each component's `source` argument must specify one of the following source types:\n- Local file path: `./modules/vpc`\n- Public registry: `terraform-aws-modules/vpc/aws`\n- Private registry: `app.terraform.io/my-org/vpc/aws`\n- Git repository: `git::https://github.com/org/repo.git//modules/vpc?ref=v1.0.0`\n\n```hcl\ncomponent \"vpc\" {\n  source = \"./modules/vpc\"\n\n  inputs = {\n    cidr_block  = var.vpc_cidr\n    name_prefix = var.name_prefix\n  }\n\n  providers = {\n    aws = provider.aws.this\n  }\n}\n\ncomponent \"networking\" {\n  source  = \"app.terraform.io/my-org/vpc/aws\"\n  version = \"2.1.0\"\n\n  inputs = {\n    cidr_block  = var.vpc_cidr\n    environment = var.environment\n  }\n\n  providers = {\n    aws = provider.aws.this\n  }\n}\n\ncomponent \"compute\" {\n  source = \"./modules/compute\"\n\n  inputs = {\n    vpc_id          = component.vpc.vpc_id\n    subnet_ids      = component.vpc.private_subnet_ids\n    instance_type   = var.instance_type\n  }\n\n  providers = {\n    aws = provider.aws.this\n  }\n}\n```\n\n**Component with for_each for Multi-Region:**\n\n```hcl\ncomponent \"s3\" {\n  for_each = var.regions\n  \n  source = \"./modules/s3\"\n  \n  inputs = {\n    region = each.value\n    tags   = var.common_tags\n  }\n  \n  providers = {\n    aws = provider.aws.configurations[each.value]\n  }\n}\n```\n\n**Key Points:**\n- Reference component outputs using `component.<name>.<output>`\n- All inputs are provided as a single `inputs` object\n- Provider references are normal values: `provider.<type>.<alias>`\n- Dependencies are automatically inferred from component references\n\n### Output Block\n\nOutputs require a `type` argument and do not support `preconditions`:\n\n```hcl\noutput \"vpc_id\" {\n  type        = string\n  description = \"VPC ID\"\n  value       = component.vpc.vpc_id\n}\n\noutput \"endpoint_urls\" {\n  type      = map(string)\n  value     = {\n    for region, comp in component.api : region => comp.endpoint_url\n  }\n  sensitive = false\n}\n```\n\n### Locals Block\n\nWorks exactly as in traditional Terraform:\n\n```hcl\nlocals {\n  common_tags = {\n    Environment = var.environment\n    ManagedBy   = \"Terraform Stacks\"\n    Project     = var.project_name\n  }\n  \n  region_config = {\n    for region in var.regions : region => {\n      name_suffix = \"${var.environment}-${region}\"\n    }\n  }\n}\n```\n\n### Removed Block\n\nUse to safely remove components from a Stack. HCP Terraform requires the component's providers to remove it.\n\n```hcl\nremoved {\n  from   = component.old_component\n  source = \"./modules/old-module\"\n  \n  providers = {\n    aws = provider.aws.this\n  }\n}\n```\n\n## Deployment Configuration (.tfdeploy.hcl)\n\n### Identity Token Block\n\nGenerate JWT tokens for OIDC authentication with cloud providers:\n\n```hcl\nidentity_token \"aws\" {\n  audience = [\"aws.workload.identity\"]\n}\n\nidentity_token \"azure\" {\n  audience = [\"api://AzureADTokenExchange\"]\n}\n```\n\nReference tokens in deployments using `identity_token.<name>.jwt`\n\n### Locals Block\n\nDefine local values for deployment configuration:\n\n```hcl\nlocals {\n  aws_regions = [\"us-west-1\", \"us-east-1\", \"eu-west-1\"]\n  role_arn    = \"arn:aws:iam::123456789012:role/hcp-terraform-stacks\"\n}\n```\n\n### Deployment Block\n\nDefine deployment instances. Each Stack requires at least one deployment (maximum 20 per Stack).\n\n**Single Environment Deployment:**\n\n```hcl\ndeployment \"production\" {\n  inputs = {\n    aws_region     = \"us-west-1\"\n    instance_count = 3\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws.jwt\n  }\n}\n```\n\n**Multiple Environment Deployments:**\n\n```hcl\ndeployment \"development\" {\n  inputs = {\n    aws_region     = \"us-east-1\"\n    instance_count = 1\n    name_suffix    = \"dev\"\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws.jwt\n  }\n}\n\ndeployment \"staging\" {\n  inputs = {\n    aws_region     = \"us-east-1\"\n    instance_count = 2\n    name_suffix    = \"staging\"\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws.jwt\n  }\n}\n\ndeployment \"production\" {\n  inputs = {\n    aws_region     = \"us-west-1\"\n    instance_count = 5\n    name_suffix    = \"prod\"\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws.jwt\n  }\n}\n```\n\n**Destroying a Deployment:**\n\nTo safely remove a deployment:\n\n```hcl\ndeployment \"old_environment\" {\n  inputs = {\n    aws_region     = \"us-west-1\"\n    instance_count = 2\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws.jwt\n  }\n  destroy = true  # Mark for destruction\n}\n```\n\nAfter applying the plan and the deployment is destroyed, remove the deployment block from your configuration.\n\n### Deployment Group Block\n\nGroup deployments together to configure shared settings (Premium feature). **Best Practice**: Always create deployment groups for all deployments, even single deployments, to enable future auto-approval rules and maintain consistent configuration patterns.\n\n```hcl\ndeployment_group \"canary\" {\n  deployments = [\n    deployment.dev,\n    deployment.staging\n  ]\n}\n\ndeployment_group \"production\" {\n  deployments = [\n    deployment.prod_us_east,\n    deployment.prod_us_west\n  ]\n}\n```\n\n### Deployment Auto-Approve Block\n\nDefine rules that automatically approve deployment plans based on specific conditions (Premium feature):\n\n```hcl\ndeployment_auto_approve \"safe_changes\" {\n  deployment_group = deployment_group.canary\n  \n  check {\n    condition = context.plan.changes.remove == 0\n    reason    = \"Cannot auto-approve plans with resource deletions\"\n  }\n  \n  check {\n    condition = context.plan.applyable\n    reason    = \"Plan must be applyable\"\n  }\n}\n\ndeployment_auto_approve \"applyable_only\" {\n  deployment_group = deployment_group.production\n  \n  check {\n    condition = context.plan.applyable\n    reason    = \"Plan must be successful\"\n  }\n}\n```\n\n**Available Context Variables:**\n- `context.plan.applyable` - Plan succeeded without errors\n- `context.plan.changes.add` - Number of resources to add\n- `context.plan.changes.change` - Number of resources to change\n- `context.plan.changes.remove` - Number of resources to remove\n\n**Note:** `orchestrate` blocks are deprecated. Use `deployment_group` and `deployment_auto_approve` instead.\n\n### Publish Output Block\n\nExport outputs from a Stack for use in other Stacks (linked Stacks):\n\n```hcl\npublish_output \"vpc_id_network\" {\n  type  = string\n  value = deployment.network.vpc_id\n}\n\npublish_output \"subnet_ids\" {\n  type  = list(string)\n  value = deployment.network.private_subnet_ids\n}\n```\n\n### Upstream Input Block\n\nReference published outputs from another Stack:\n\n```hcl\nupstream_input \"network_stack\" {\n  type   = \"stack\"\n  source = \"app.terraform.io/my-org/my-project/networking-stack\"\n}\n\ndeployment \"application\" {\n  inputs = {\n    vpc_id     = upstream_input.network_stack.vpc_id_network\n    subnet_ids = upstream_input.network_stack.subnet_ids\n  }\n}\n```\n\n## Terraform Stacks CLI\n\n### Initialize and Validate\n\nGenerate provider lock file:\n\n```bash\nterraform stacks providers-lock\n```\n\nValidate Stack configuration:\n\n```bash\nterraform stacks validate\n```\n\n### Plan and Apply\n\nPlan a specific deployment:\n\n```bash\nterraform stacks plan --deployment=production\n```\n\nApply a deployment:\n\n```bash\nterraform stacks apply --deployment=production\n```\n\n## Common Patterns\n\n### Multi-Region Deployment\n\n```hcl\n# variables.tfcomponent.hcl\nvariable \"regions\" {\n  type = set(string)\n  default = [\"us-west-1\", \"us-east-1\", \"eu-west-1\"]\n}\n\n# providers.tfcomponent.hcl\nprovider \"aws\" \"regional\" {\n  for_each = var.regions\n  \n  config {\n    region = each.value\n    assume_role_with_web_identity {\n      role_arn           = var.role_arn\n      web_identity_token = var.identity_token\n    }\n  }\n}\n\n# components.tfcomponent.hcl\ncomponent \"regional_infra\" {\n  for_each = var.regions\n  source   = \"./modules/regional\"\n  \n  inputs = {\n    region = each.value\n  }\n  \n  providers = {\n    aws = provider.aws.regional[each.value]\n  }\n}\n```\n\n### Component Dependencies\n\nDependencies are automatically inferred when one component references another's output:\n\n```hcl\ncomponent \"database\" {\n  source = \"./modules/rds\"\n  \n  inputs = {\n    subnet_ids = component.vpc.private_subnet_ids  # Creates dependency\n  }\n  \n  providers = {\n    aws = provider.aws.this\n  }\n}\n```\n\n## Best Practices\n\n1. **Component Granularity**: Create components for logical infrastructure units that share a lifecycle\n2. **Module Compatibility**: Modules used with Stacks cannot include provider blocks (configure providers in Stack configuration)\n3. **State Isolation**: Each deployment has its own isolated state\n4. **Input Variables**: Use variables for values that differ across deployments; use locals for shared values\n5. **Provider Lock Files**: Always generate and commit `.terraform.lock.hcl` to version control\n6. **Naming Conventions**: Use descriptive names for components and deployments\n7. **Deployment Groups**: Always organize deployments into deployment groups, even if you only have one deployment. Deployment groups enable auto-approval rules, logical organization, and provide a foundation for scaling. While deployment groups are a Premium feature, organizing your configurations to use them is a best practice for all Stacks\n8. **Testing**: Test Stack configurations in dev/staging deployments before production\n\n## Troubleshooting\n\n### Circular Dependencies\n\n**Issue**: Component A references Component B, and Component B references Component A\n**Solution**: Refactor to break the circular reference or use intermediate components\n\n### Deployment Limit\n\nHCP Terraform supports maximum 20 deployments per Stack. For more instances, use multiple Stacks or `for_each` within components.\n\n## References\n\nFor detailed block specifications and advanced features, see:\n- `references/component-blocks.md` - Complete component block reference\n- `references/deployment-blocks.md` - Complete deployment block reference\n- `references/examples.md` - Complete working examples for common scenarios\n",
        "terraform/module-generation/skills/terraform-stacks/references/component-blocks.md": "# Component Configuration Block Reference\n\nComplete reference for all blocks available in Terraform Stack component configuration files (`.tfcomponent.hcl`).\n\n## Table of Contents\n\n1. [Variable Block](#variable-block)\n2. [Required Providers Block](#required-providers-block)\n3. [Provider Block](#provider-block)\n4. [Component Block](#component-block)\n5. [Output Block](#output-block)\n6. [Locals Block](#locals-block)\n7. [Removed Block](#removed-block)\n\n## Variable Block\n\nDeclares input variables for Stack configuration.\n\n### Syntax\n\n```hcl\nvariable \"variable_name\" {\n  type        = <type>\n  description = \"<description>\"\n  default     = <value>\n  sensitive   = <bool>\n  nullable    = <bool>\n  ephemeral   = <bool>\n}\n```\n\n### Arguments\n\n- **type** (required): Data type (string, number, bool, list, map, object, set, tuple, any)\n- **description** (optional): Variable description\n- **default** (optional): Default value\n- **sensitive** (optional, default false): Mark as sensitive to redact from logs\n- **nullable** (optional, default true): Whether null is allowed\n- **ephemeral** (optional, default false): Do not persist to state file\n\n### Differences from Traditional Terraform\n\n- **type** is required (not optional)\n- **validation** argument is not supported\n\n### Examples\n\n```hcl\nvariable \"aws_region\" {\n  type        = string\n  description = \"AWS region for infrastructure\"\n  default     = \"us-west-1\"\n}\n\nvariable \"instance_count\" {\n  type        = number\n  description = \"Number of instances\"\n  nullable    = false\n}\n\nvariable \"identity_token\" {\n  type        = string\n  description = \"OIDC identity token\"\n  ephemeral   = true\n}\n\nvariable \"tags\" {\n  type = map(string)\n  default = {\n    Environment = \"dev\"\n    ManagedBy   = \"Terraform\"\n  }\n}\n\nvariable \"subnet_config\" {\n  type = object({\n    cidr_block           = string\n    availability_zone    = string\n    map_public_ip        = bool\n  })\n}\n```\n\n## Required Providers Block\n\nDeclares provider dependencies.\n\n### Syntax\n\n```hcl\nrequired_providers {\n  <provider_name> = {\n    source  = \"<source>\"\n    version = \"<version_constraint>\"\n  }\n}\n```\n\n### Arguments\n\n- **source** (required): Provider source address (e.g., \"hashicorp/aws\")\n- **version** (optional): Version constraint (e.g., \"~> 5.0\")\n\n### Examples\n\n```hcl\nrequired_providers {\n  aws = {\n    source  = \"hashicorp/aws\"\n    version = \"~> 5.7.0\"\n  }\n  \n  random = {\n    source  = \"hashicorp/random\"\n    version = \"~> 3.5.0\"\n  }\n  \n  azurerm = {\n    source  = \"hashicorp/azurerm\"\n    version = \">= 3.0\"\n  }\n}\n```\n\n## Provider Block\n\nConfigures provider instances.\n\n### Syntax\n\n```hcl\nprovider \"<provider_type>\" \"<alias>\" {\n  for_each = <map_or_set>  # Optional\n  \n  config {\n    <provider_arguments>\n  }\n}\n```\n\n### Arguments\n\n- **provider_type** (label 1, required): Provider type (e.g., \"aws\", \"azurerm\")\n- **alias** (label 2, required): Unique identifier for this provider configuration\n- **for_each** (optional): Create multiple provider instances from a map or set\n- **config** (required): Nested block containing provider-specific configuration\n\n### Key Differences from Traditional Terraform\n\n1. Alias is defined in block header, not as an argument\n2. Configuration goes in a nested `config` block\n3. Supports `for_each` meta-argument\n4. Provider configurations are treated as first-class values\n\n### Examples\n\n**Single Provider:**\n\n```hcl\nprovider \"aws\" \"main\" {\n  config {\n    region = var.aws_region\n    \n    default_tags {\n      tags = var.common_tags\n    }\n  }\n}\n```\n\n**Provider with OIDC Authentication:**\n\n```hcl\nprovider \"aws\" \"authenticated\" {\n  config {\n    region = var.aws_region\n    \n    assume_role_with_web_identity {\n      role_arn           = var.role_arn\n      web_identity_token = var.identity_token\n    }\n  }\n}\n```\n\n**Multiple Providers with for_each:**\n\n```hcl\nprovider \"aws\" \"regional\" {\n  for_each = toset(var.regions)\n  \n  config {\n    region = each.value\n    \n    assume_role_with_web_identity {\n      role_arn           = var.role_arn\n      web_identity_token = var.identity_token\n    }\n  }\n}\n```\n\n**Multiple Cloud Accounts:**\n\n```hcl\nprovider \"aws\" \"accounts\" {\n  for_each = var.aws_accounts\n  \n  config {\n    region = var.default_region\n    \n    assume_role {\n      role_arn = \"arn:aws:iam::${each.value.account_id}:role/${var.role_name}\"\n    }\n  }\n}\n```\n\n## Component Block\n\nDefines infrastructure components to include in the Stack.\n\n### Syntax\n\n```hcl\ncomponent \"<component_name>\" {\n  for_each = <map_or_set>  # Optional\n  \n  source = \"<module_source>\"\n  \n  inputs = {\n    <input_name> = <value>\n  }\n  \n  providers = {\n    <provider_local_name> = provider.<type>.<alias>[<key>]\n  }\n}\n```\n\n### Arguments\n\n- **component_name** (label, required): Unique identifier for this component\n- **for_each** (optional): Create multiple component instances\n- **source** (required): Module source (see [Source Argument](#source-argument) below)\n- **version** (optional): Version constraint for registry-based sources only\n- **inputs** (required): Map of input variables for the module\n- **providers** (required): Map of provider configurations\n\n### Source Argument\n\nThe `source` argument accepts the same module sources as traditional Terraform configurations.\n\n**Local File Path:**\n```hcl\nsource = \"./modules/vpc\"\nsource = \"../shared-modules/networking\"\n```\n\n**Public Terraform Registry:**\n```hcl\nsource = \"terraform-aws-modules/vpc/aws\"\nsource = \"hashicorp/consul/aws\"\n```\nFormat: `<NAMESPACE>/<NAME>/<PROVIDER>`\n\n**Private HCP Terraform Registry:**\n```hcl\nsource = \"app.terraform.io/my-org/vpc/aws\"\nsource = \"app.terraform.io/example-corp/networking/azurerm\"\n```\nFormat: `<HOSTNAME>/<ORGANIZATION>/<MODULE_NAME>/<PROVIDER_NAME>`\n\n- **HCP Terraform (SaaS)**: Use hostname `app.terraform.io`\n- **Terraform Enterprise**: Use your instance hostname (e.g., `terraform.mycompany.com`)\n- **Generic hostname**: Use `localterraform.com` for deployments spanning multiple Terraform Enterprise instances\n\n**Git Repository:**\n```hcl\nsource = \"git::https://github.com/org/repo.git//modules/vpc?ref=v1.0.0\"\nsource = \"git::ssh://git@github.com/org/repo.git//modules/vpc?ref=main\"\n```\n\n**HTTP/HTTPS Archive:**\n```hcl\nsource = \"https://example.com/modules/vpc-module.tar.gz\"\n```\n\n### Version Argument\n\nThe `version` argument is supported only for registry-based sources (public and private registries). Local file paths and Git sources do not support the `version` argument.\n\n```hcl\ncomponent \"vpc\" {\n  source  = \"app.terraform.io/my-org/vpc/aws\"\n  version = \"~> 2.0\"  # Semantic versioning constraint\n\n  inputs = {\n    cidr_block = var.vpc_cidr\n  }\n\n  providers = {\n    aws = provider.aws.main\n  }\n}\n```\n\n**Note**: Modules sourced from local file paths always share the same version as their caller and cannot have independent version constraints.\n\n### Component References\n\nAccess component outputs using: `component.<name>.<output>`\n\nFor components with `for_each`: `component.<name>[<key>].<output>`\n\n### Examples\n\n**Basic Component (Local Module):**\n\n```hcl\ncomponent \"vpc\" {\n  source = \"./modules/vpc\"\n\n  inputs = {\n    cidr_block  = var.vpc_cidr\n    name_prefix = var.name_prefix\n  }\n\n  providers = {\n    aws = provider.aws.main\n  }\n}\n```\n\n**Component from Public Registry:**\n\n```hcl\ncomponent \"vpc\" {\n  source  = \"terraform-aws-modules/vpc/aws\"\n  version = \"~> 5.0\"\n\n  inputs = {\n    cidr            = var.vpc_cidr\n    azs             = var.availability_zones\n    private_subnets = var.private_subnet_cidrs\n    public_subnets  = var.public_subnet_cidrs\n  }\n\n  providers = {\n    aws = provider.aws.main\n  }\n}\n```\n\n**Component from Private Registry:**\n\n```hcl\ncomponent \"vpc\" {\n  source  = \"app.terraform.io/my-org/vpc/aws\"\n  version = \"2.1.0\"\n\n  inputs = {\n    cidr_block  = var.vpc_cidr\n    name_prefix = var.name_prefix\n    environment = var.environment\n  }\n\n  providers = {\n    aws = provider.aws.main\n  }\n}\n```\n\n**Component with Dependencies:**\n\n```hcl\ncomponent \"database\" {\n  source = \"./modules/rds\"\n  \n  inputs = {\n    vpc_id             = component.vpc.vpc_id\n    subnet_ids         = component.vpc.private_subnet_ids\n    security_group_ids = [component.security.database_sg_id]\n    engine_version     = var.db_engine_version\n  }\n  \n  providers = {\n    aws = provider.aws.main\n  }\n}\n```\n\n**Component with for_each (Multi-Region):**\n\n```hcl\ncomponent \"regional_s3\" {\n  for_each = toset(var.regions)\n  \n  source = \"./modules/s3\"\n  \n  inputs = {\n    region      = each.value\n    bucket_name = \"${var.app_name}-${each.value}\"\n    tags        = local.common_tags\n  }\n  \n  providers = {\n    aws = provider.aws.regional[each.value]\n  }\n}\n```\n\n**Component with Multiple Providers:**\n\n```hcl\ncomponent \"cross_region_replication\" {\n  source = \"./modules/s3-replication\"\n  \n  inputs = {\n    source_bucket = var.source_bucket\n    dest_bucket   = var.dest_bucket\n  }\n  \n  providers = {\n    aws.source = provider.aws.us_east\n    aws.dest   = provider.aws.eu_west\n  }\n}\n```\n\n**Component with for_each over Map:**\n\n```hcl\ncomponent \"applications\" {\n  for_each = var.applications\n  \n  source = \"./modules/application\"\n  \n  inputs = {\n    app_name        = each.key\n    instance_type   = each.value.instance_type\n    instance_count  = each.value.count\n    vpc_id          = component.vpc.vpc_id\n  }\n  \n  providers = {\n    aws = provider.aws.main\n  }\n}\n```\n\n## Output Block\n\nExposes values from Stack configuration.\n\n### Syntax\n\n```hcl\noutput \"<output_name>\" {\n  type        = <type>\n  description = \"<description>\"\n  value       = <expression>\n  sensitive   = <bool>\n  ephemeral   = <bool>\n}\n```\n\n### Arguments\n\n- **output_name** (label, required): Unique identifier for this output\n- **type** (required): Data type of the output\n- **description** (optional): Output description\n- **value** (required): Expression to output\n- **sensitive** (optional, default false): Mark as sensitive\n- **ephemeral** (optional, default false): Ephemeral value\n\n### Differences from Traditional Terraform\n\n- **type** is required\n- **precondition** block is not supported\n\n### Examples\n\n```hcl\noutput \"vpc_id\" {\n  type        = string\n  description = \"VPC ID\"\n  value       = component.vpc.vpc_id\n}\n\noutput \"database_endpoint\" {\n  type        = string\n  description = \"Database endpoint\"\n  value       = component.database.endpoint\n  sensitive   = true\n}\n\noutput \"regional_endpoints\" {\n  type        = map(string)\n  description = \"API endpoints by region\"\n  value       = {\n    for region, comp in component.api_gateway : region => comp.endpoint_url\n  }\n}\n\noutput \"instance_details\" {\n  type = object({\n    id         = string\n    public_ip  = string\n    private_ip = string\n  })\n  description = \"EC2 instance details\"\n  value = {\n    id         = component.compute.instance_id\n    public_ip  = component.compute.public_ip\n    private_ip = component.compute.private_ip\n  }\n}\n```\n\n## Locals Block\n\nDefines local values for reuse within the Stack configuration.\n\n### Syntax\n\n```hcl\nlocals {\n  <name> = <expression>\n}\n```\n\n### Examples\n\n```hcl\nlocals {\n  common_tags = {\n    Environment = var.environment\n    ManagedBy   = \"Terraform Stacks\"\n    Project     = var.project_name\n    CostCenter  = var.cost_center\n  }\n  \n  name_prefix = \"${var.project_name}-${var.environment}\"\n  \n  region_config = {\n    for region in var.regions : region => {\n      name_suffix    = region\n      instance_count = var.environment == \"prod\" ? 3 : 1\n    }\n  }\n  \n  availability_zones = [\n    for az in var.availability_zones : az\n    if can(regex(\"^${var.aws_region}\", az))\n  ]\n}\n```\n\n## Removed Block\n\nDeclares components to be removed from the Stack.\n\n### Syntax\n\n```hcl\nremoved {\n  from   = component.<component_name>\n  source = \"<original_module_source>\"\n  \n  providers = {\n    <provider_name> = provider.<type>.<alias>\n  }\n}\n```\n\n### Arguments\n\n- **from** (required): Reference to the component being removed\n- **source** (required): Original module source\n- **providers** (required): Provider configurations needed for removal\n\n### Important Notes\n\n- Required for safe component removal\n- Must include all providers the component used\n- Do not remove providers before removing components that use them\n\n### Examples\n\n```hcl\nremoved {\n  from   = component.old_component\n  source = \"./modules/deprecated-module\"\n  \n  providers = {\n    aws = provider.aws.main\n  }\n}\n\nremoved {\n  from   = component.legacy_regional\n  source = \"registry.terraform.io/example/legacy/aws\"\n  \n  providers = {\n    aws    = provider.aws.main\n    random = provider.random.main\n  }\n}\n```\n\n## Provider References in Component Blocks\n\n### Single Provider\n\n```hcl\nproviders = {\n  aws = provider.aws.main\n}\n```\n\n### Multiple Providers\n\n```hcl\nproviders = {\n  aws    = provider.aws.main\n  random = provider.random.main\n  tls    = provider.tls.main\n}\n```\n\n### Provider from for_each\n\n```hcl\nproviders = {\n  aws = provider.aws.regional[each.value]\n}\n```\n\n### Aliased Providers in Module\n\nIf module requires specific provider aliases:\n\n```hcl\nproviders = {\n  aws.source = provider.aws.us_east\n  aws.dest   = provider.aws.eu_west\n}\n```\n",
        "terraform/module-generation/skills/terraform-stacks/references/deployment-blocks.md": "# Deployment Configuration Block Reference\n\nComplete reference for all blocks available in Terraform Stack deployment configuration files (`.tfdeploy.hcl`).\n\n## Table of Contents\n\n1. [Identity Token Block](#identity-token-block)\n2. [Locals Block](#locals-block)\n3. [Deployment Block](#deployment-block)\n4. [Deployment Group Block](#deployment-group-block)\n5. [Deployment Auto-Approve Block](#deployment-auto-approve-block)\n6. [Publish Output Block](#publish-output-block)\n7. [Upstream Input Block](#upstream-input-block)\n\n## Identity Token Block\n\nGenerates JWT tokens for OIDC authentication with cloud providers.\n\n### Syntax\n\n```hcl\nidentity_token \"<token_name>\" {\n  audience = [<audience_strings>]\n}\n```\n\n### Arguments\n\n- **token_name** (label, required): Unique identifier for this token\n- **audience** (required): List of audience strings for the JWT\n\n### Accessing Token\n\nReference the JWT using: `identity_token.<n>.jwt`\n\n### Cloud Provider Audiences\n\n**AWS:**\n```hcl\nidentity_token \"aws\" {\n  audience = [\"aws.workload.identity\"]\n}\n```\n\n**Azure:**\n```hcl\nidentity_token \"azure\" {\n  audience = [\"api://AzureADTokenExchange\"]\n}\n```\n\n**Google Cloud:**\n```hcl\nidentity_token \"gcp\" {\n  audience = [\"//iam.googleapis.com/projects/<PROJECT_NUMBER>/locations/global/workloadIdentityPools/<POOL_ID>/providers/<PROVIDER_ID>\"]\n}\n```\n\n### Examples\n\n**Single Token:**\n\n```hcl\nidentity_token \"aws\" {\n  audience = [\"aws.workload.identity\"]\n}\n\ndeployment \"production\" {\n  inputs = {\n    identity_token = identity_token.aws.jwt\n    role_arn       = var.role_arn\n  }\n}\n```\n\n**Multiple Tokens for Different Regions:**\n\n```hcl\nidentity_token \"aws_east\" {\n  audience = [\"aws.workload.identity.east\"]\n}\n\nidentity_token \"aws_west\" {\n  audience = [\"aws.workload.identity.west\"]\n}\n\ndeployment \"east_deployment\" {\n  inputs = {\n    identity_token = identity_token.aws_east.jwt\n    role_arn       = var.east_role_arn\n  }\n}\n\ndeployment \"west_deployment\" {\n  inputs = {\n    identity_token = identity_token.aws_west.jwt\n    role_arn       = var.west_role_arn\n  }\n}\n```\n\n## Locals Block\n\nDefines local values for reuse within deployment configuration.\n\n### Syntax\n\n```hcl\nlocals {\n  <n> = <expression>\n}\n```\n\n### Examples\n\n```hcl\nlocals {\n  aws_regions = [\"us-west-1\", \"us-east-1\", \"eu-west-1\"]\n  \n  role_arn = \"arn:aws:iam::123456789012:role/hcp-terraform-stacks\"\n  \n  common_inputs = {\n    project_name = \"my-app\"\n    environment  = \"production\"\n  }\n  \n  environments = {\n    dev = {\n      region         = \"us-east-1\"\n      instance_count = 1\n      instance_type  = \"t3.micro\"\n    }\n    staging = {\n      region         = \"us-west-1\"\n      instance_count = 2\n      instance_type  = \"t3.small\"\n    }\n    prod = {\n      region         = \"us-west-1\"\n      instance_count = 5\n      instance_type  = \"t3.large\"\n    }\n  }\n}\n```\n\n## Deployment Block\n\nDefines deployment instances of the Stack.\n\n### Syntax\n\n```hcl\ndeployment \"<deployment_name>\" {\n  inputs = {\n    <input_name> = <value>\n  }\n}\n```\n\n### Arguments\n\n- **deployment_name** (label, required): Unique identifier for this deployment\n- **inputs** (required): Map of input variable values\n- **destroy** (optional, default: false): Boolean flag to destroy this deployment\n\n### Constraints\n\n- Minimum 1 deployment per Stack\n- Maximum 20 deployments per Stack\n- No meta-arguments supported (no `for_each`, `count`)\n\n### Destroying a Deployment\n\nTo safely remove a deployment from your Stack:\n\n1. Set `destroy = true` in the deployment block\n2. Apply the plan through HCP Terraform\n3. After successful destruction, remove the deployment block from your configuration\n\n**Important**: Using the `destroy` argument ensures your configuration has the provider authentication necessary to properly destroy the deployment's resources.\n\n**Example:**\n```hcl\ndeployment \"old_environment\" {\n  inputs = {\n    aws_region     = \"us-west-1\"\n    instance_count = 2\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws.jwt\n  }\n  destroy = true  # Mark for destruction\n}\n```\n\nAfter applying this plan and the deployment is destroyed, remove the entire `deployment \"old_environment\"` block from your configuration.\n\n### Examples\n\n**Single Deployment:**\n\n```hcl\ndeployment \"production\" {\n  inputs = {\n    aws_region     = \"us-west-1\"\n    instance_count = 5\n    instance_type  = \"t3.large\"\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws.jwt\n  }\n}\n```\n\n**Multiple Environment Deployments:**\n\n```hcl\ndeployment \"development\" {\n  inputs = {\n    aws_region     = \"us-east-1\"\n    instance_count = 1\n    instance_type  = \"t3.micro\"\n    name_suffix    = \"dev\"\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws.jwt\n  }\n}\n\ndeployment \"staging\" {\n  inputs = {\n    aws_region     = \"us-west-1\"\n    instance_count = 2\n    instance_type  = \"t3.small\"\n    name_suffix    = \"staging\"\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws.jwt\n  }\n}\n\ndeployment \"production\" {\n  inputs = {\n    aws_region     = \"us-west-1\"\n    instance_count = 5\n    instance_type  = \"t3.large\"\n    name_suffix    = \"prod\"\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws.jwt\n  }\n}\n```\n\n**Multi-Region Deployments:**\n\n```hcl\ndeployment \"us_prod_east\" {\n  inputs = {\n    aws_region     = \"us-east-1\"\n    instance_count = 3\n    name_suffix    = \"prod-east\"\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws_east.jwt\n  }\n}\n\ndeployment \"us_prod_west\" {\n  inputs = {\n    aws_region     = \"us-west-1\"\n    instance_count = 3\n    name_suffix    = \"prod-west\"\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws_west.jwt\n  }\n}\n\ndeployment \"eu_prod\" {\n  inputs = {\n    aws_region     = \"eu-west-1\"\n    instance_count = 3\n    name_suffix    = \"prod-eu\"\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws_eu.jwt\n  }\n}\n```\n\n**Using Locals for DRY Configuration:**\n\n```hcl\nlocals {\n  common_inputs = {\n    role_arn       = \"arn:aws:iam::123456789012:role/terraform\"\n    identity_token = identity_token.aws.jwt\n    project_name   = \"my-app\"\n  }\n}\n\ndeployment \"dev\" {\n  inputs = merge(local.common_inputs, {\n    aws_region     = \"us-east-1\"\n    instance_count = 1\n    environment    = \"dev\"\n  })\n}\n\ndeployment \"prod\" {\n  inputs = merge(local.common_inputs, {\n    aws_region     = \"us-west-1\"\n    instance_count = 5\n    environment    = \"prod\"\n  })\n}\n```\n\n## Deployment Group Block\n\nGroups deployments together to configure shared settings and auto-approval rules (HCP Terraform Premium feature).\n\n**Best Practice**: Always create deployment groups for all deployments, even when you have only a single deployment. This establishes a consistent configuration pattern, enables future auto-approval rules, and provides a foundation for scaling your Stack.\n\n### Syntax\n\n```hcl\ndeployment_group \"<group_name>\" {\n  deployments = [<deployment_references>]\n}\n```\n\n### Arguments\n\n- **group_name** (label, required): Unique identifier for this deployment group\n- **deployments** (required): List of deployment references to include in this group\n\n### Purpose\n\nDeployment groups allow you to:\n- Organize deployments logically (by environment, team, region, etc.)\n- Configure shared auto-approval rules for multiple deployments\n- Manage deployments more effectively at scale\n- Establish consistent configuration patterns across all Stacks\n\n### Examples\n\n**Single Deployment Group (Best Practice):**\n\n```hcl\ndeployment \"production\" {\n  inputs = {\n    aws_region     = \"us-west-1\"\n    instance_count = 5\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws.jwt\n  }\n}\n\ndeployment_group \"production\" {\n  deployments = [deployment.production]\n}\n```\n\n**Multiple Deployment Groups:**\n\n```hcl\ndeployment_group \"non_production\" {\n  deployments = [\n    deployment.development,\n    deployment.staging\n  ]\n}\n\ndeployment_group \"production\" {\n  deployments = [\n    deployment.prod_us_east,\n    deployment.prod_us_west,\n    deployment.prod_eu_west\n  ]\n}\n```\n\n**Environment-Based Groups:**\n\n```hcl\ndeployment_group \"development_environments\" {\n  deployments = [\n    deployment.dev_feature_a,\n    deployment.dev_feature_b,\n    deployment.dev_integration\n  ]\n}\n\ndeployment_group \"production_environments\" {\n  deployments = [\n    deployment.prod_primary,\n    deployment.prod_dr\n  ]\n}\n```\n\n**Regional Groups:**\n\n```hcl\ndeployment_group \"americas\" {\n  deployments = [\n    deployment.us_east,\n    deployment.us_west,\n    deployment.brazil\n  ]\n}\n\ndeployment_group \"europe\" {\n  deployments = [\n    deployment.eu_west,\n    deployment.eu_central\n  ]\n}\n```\n\n## Deployment Auto-Approve Block\n\nDefines rules that automatically approve deployment plans based on specific conditions (HCP Terraform Premium feature).\n\n### Syntax\n\n```hcl\ndeployment_auto_approve \"<rule_name>\" {\n  deployment_group = deployment_group.<group_name>\n  \n  check {\n    condition = <boolean_expression>\n    reason    = \"<failure_message>\"\n  }\n}\n```\n\n### Arguments\n\n- **rule_name** (label, required): Unique identifier for this auto-approve rule\n- **deployment_group** (required): Reference to the deployment group this rule applies to\n- **check** (required, one or more): Condition that must be met for auto-approval\n\n### Context Variables\n\nAccess plan information through `context` object:\n\n- `context.plan.applyable` - Boolean: plan succeeded without errors\n- `context.plan.changes.add` - Number: resources to add\n- `context.plan.changes.change` - Number: resources to change\n- `context.plan.changes.remove` - Number: resources to remove\n- `context.plan.changes.import` - Number: resources to import\n\n### Important Notes\n\n- All checks must pass for auto-approval to occur\n- If any check fails, manual approval is required\n- HCP Terraform displays the failure reason from failed checks\n- Auto-approve rules only apply to deployments in the specified deployment group\n\n### Examples\n\n**Auto-approve Successful Plans:**\n\n```hcl\ndeployment_group \"canary\" {\n  deployments = [\n    deployment.dev,\n    deployment.staging\n  ]\n}\n\ndeployment_auto_approve \"applyable_plans\" {\n  deployment_group = deployment_group.canary\n  \n  check {\n    condition = context.plan.applyable\n    reason    = \"Plan must be applyable without errors\"\n  }\n}\n```\n\n**Auto-approve Only Additions (No Changes or Deletions):**\n\n```hcl\ndeployment_group \"non_prod\" {\n  deployments = [\n    deployment.development,\n    deployment.qa\n  ]\n}\n\ndeployment_auto_approve \"additions_only\" {\n  deployment_group = deployment_group.non_prod\n  \n  check {\n    condition = context.plan.changes.change == 0\n    reason    = \"Cannot auto-approve changes to existing resources\"\n  }\n  \n  check {\n    condition = context.plan.changes.remove == 0\n    reason    = \"Cannot auto-approve resource deletions\"\n  }\n  \n  check {\n    condition = context.plan.applyable\n    reason    = \"Plan must be applyable\"\n  }\n}\n```\n\n**Auto-approve Small Changes:**\n\n```hcl\ndeployment_group \"staging\" {\n  deployments = [deployment.staging]\n}\n\ndeployment_auto_approve \"small_changes\" {\n  deployment_group = deployment_group.staging\n  \n  check {\n    condition = (\n      context.plan.changes.add + \n      context.plan.changes.change + \n      context.plan.changes.remove\n    ) <= 10\n    reason    = \"Cannot auto-approve changes affecting more than 10 resources\"\n  }\n  \n  check {\n    condition = context.plan.changes.remove == 0\n    reason    = \"Cannot auto-approve plans with deletions\"\n  }\n  \n  check {\n    condition = context.plan.applyable\n    reason    = \"Plan must be applyable\"\n  }\n}\n```\n\n**Auto-approve Non-Destructive Changes:**\n\n```hcl\ndeployment_group \"production\" {\n  deployments = [\n    deployment.prod_primary,\n    deployment.prod_secondary\n  ]\n}\n\ndeployment_auto_approve \"safe_production_changes\" {\n  deployment_group = deployment_group.production\n  \n  check {\n    condition = context.plan.changes.remove == 0\n    reason    = \"Production deletions require manual approval\"\n  }\n  \n  check {\n    condition = context.plan.applyable\n    reason    = \"Plan must be successful\"\n  }\n}\n```\n\n**Multiple Auto-Approve Rules for Different Groups:**\n\n```hcl\ndeployment_group \"development\" {\n  deployments = [deployment.dev]\n}\n\ndeployment_group \"staging\" {\n  deployments = [deployment.staging]\n}\n\ndeployment_group \"production\" {\n  deployments = [deployment.production]\n}\n\n# Auto-approve all successful dev plans\ndeployment_auto_approve \"dev_auto\" {\n  deployment_group = deployment_group.development\n  \n  check {\n    condition = context.plan.applyable\n    reason    = \"Plan must be applyable\"\n  }\n}\n\n# Auto-approve staging plans with no deletions\ndeployment_auto_approve \"staging_safe\" {\n  deployment_group = deployment_group.staging\n  \n  check {\n    condition = context.plan.changes.remove == 0\n    reason    = \"No deletions allowed in staging auto-approve\"\n  }\n  \n  check {\n    condition = context.plan.applyable\n    reason    = \"Plan must be applyable\"\n  }\n}\n\n# Production requires manual approval (no auto-approve rule defined)\n```\n\n**Graduated Rollout Pattern:**\n\n```hcl\ndeployment_group \"canary\" {\n  deployments = [deployment.canary]\n}\n\ndeployment_group \"production\" {\n  deployments = [\n    deployment.prod_us,\n    deployment.prod_eu,\n    deployment.prod_asia\n  ]\n}\n\n# Canary auto-approves with strict checks\ndeployment_auto_approve \"canary_strict\" {\n  deployment_group = deployment_group.canary\n  \n  check {\n    condition = context.plan.changes.remove == 0\n    reason    = \"Canary cannot delete resources\"\n  }\n  \n  check {\n    condition = context.plan.changes.change <= 5\n    reason    = \"Canary limited to 5 resource changes\"\n  }\n  \n  check {\n    condition = context.plan.applyable\n    reason    = \"Plan must be applyable\"\n  }\n}\n\n# Production requires manual approval after canary validation\n```\n\n## Deprecated: Orchestrate Block\n\n**Note:** The `orchestrate` block is deprecated. Use `deployment_group` and `deployment_auto_approve` blocks instead.\n\nThe `orchestrate` block was used in public beta but has been replaced by deployment groups for better scalability and flexibility:\n\n```hcl\n# âŒ DEPRECATED - Do not use\norchestrate \"auto_approve\" \"rule_name\" {\n  check {\n    condition = context.plan.applyable\n    reason    = \"Plan must be applyable\"\n  }\n}\n\n# âœ… Use deployment_group and deployment_auto_approve instead\ndeployment_group \"my_group\" {\n  deployments = [deployment.my_deployment]\n}\n\ndeployment_auto_approve \"my_rule\" {\n  deployment_group = deployment_group.my_group\n  \n  check {\n    condition = context.plan.applyable\n    reason    = \"Plan must be applyable\"\n  }\n}\n```\n\n## Publish Output Block\n\nExports outputs from a Stack for consumption by other Stacks (linked Stacks).\n\n### Syntax\n\n```hcl\npublish_output \"<output_name>\" {\n  type  = <type>\n  value = <expression>\n}\n```\n\n### Arguments\n\n- **output_name** (label, required): Unique identifier for this published output\n- **type** (required): Data type of the output\n- **value** (required): Expression to export\n\n### Accessing Deployment Outputs\n\nReference deployment outputs using: `deployment.<deployment_name>.<output_name>`\n\n### Important Notes\n\n- Must apply the Stack's deployment configuration before downstream Stacks can reference outputs\n- Published outputs create a snapshot that other Stacks can read\n- Changes to published outputs automatically trigger runs in downstream Stacks\n\n### Examples\n\n**Basic Published Output:**\n\n```hcl\npublish_output \"vpc_id\" {\n  type  = string\n  value = deployment.network.vpc_id\n}\n\npublish_output \"subnet_ids\" {\n  type  = list(string)\n  value = deployment.network.private_subnet_ids\n}\n```\n\n**Multiple Deployment Outputs:**\n\n```hcl\npublish_output \"regional_vpc_ids\" {\n  type = map(string)\n  value = {\n    us_east = deployment.us_east.vpc_id\n    us_west = deployment.us_west.vpc_id\n    eu_west = deployment.eu_west.vpc_id\n  }\n}\n```\n\n**Complex Output:**\n\n```hcl\npublish_output \"database_config\" {\n  type = object({\n    endpoint = string\n    port     = number\n    name     = string\n  })\n  value = {\n    endpoint = deployment.production.db_endpoint\n    port     = deployment.production.db_port\n    name     = deployment.production.db_name\n  }\n}\n```\n\n**Regional Endpoints:**\n\n```hcl\npublish_output \"api_endpoints\" {\n  type = map(object({\n    url    = string\n    region = string\n  }))\n  value = {\n    for env in [\"dev\", \"staging\", \"prod\"] : env => {\n      url    = deployment[env].api_url\n      region = deployment[env].region\n    }\n  }\n}\n```\n\n## Upstream Input Block\n\nReferences published outputs from another Stack (linked Stacks).\n\n### Syntax\n\n```hcl\nupstream_input \"<input_name>\" {\n  type   = \"stack\"\n  source = \"<stack_address>\"\n}\n```\n\n### Arguments\n\n- **input_name** (label, required): Local name for this upstream input\n- **type** (required): Must be \"stack\"\n- **source** (required): Full Stack address in format: `app.terraform.io/<org>/<project>/<stack-name>`\n\n### Accessing Upstream Outputs\n\nReference upstream outputs using: `upstream_input.<input_name>.<output_name>`\n\n### Important Notes\n\n- Creates a dependency on the upstream Stack\n- Upstream Stack must have applied its deployment configuration\n- Changes in upstream Stack automatically trigger downstream Stack runs\n- Only works with Stacks in the same HCP Terraform project\n\n### Examples\n\n**Basic Upstream Reference:**\n\n```hcl\nupstream_input \"network\" {\n  type   = \"stack\"\n  source = \"app.terraform.io/my-org/my-project/networking-stack\"\n}\n\ndeployment \"application\" {\n  inputs = {\n    vpc_id     = upstream_input.network.vpc_id\n    subnet_ids = upstream_input.network.subnet_ids\n  }\n}\n```\n\n**Multiple Upstream Stacks:**\n\n```hcl\nupstream_input \"network\" {\n  type   = \"stack\"\n  source = \"app.terraform.io/my-org/my-project/network-stack\"\n}\n\nupstream_input \"database\" {\n  type   = \"stack\"\n  source = \"app.terraform.io/my-org/my-project/database-stack\"\n}\n\ndeployment \"application\" {\n  inputs = {\n    vpc_id              = upstream_input.network.vpc_id\n    subnet_ids          = upstream_input.network.private_subnet_ids\n    database_endpoint   = upstream_input.database.endpoint\n    database_credentials = upstream_input.database.credentials\n  }\n}\n```\n\n**Regional Upstream Dependencies:**\n\n```hcl\nupstream_input \"regional_network\" {\n  type   = \"stack\"\n  source = \"app.terraform.io/my-org/my-project/regional-networks\"\n}\n\ndeployment \"us_east_app\" {\n  inputs = {\n    region     = \"us-east-1\"\n    vpc_id     = upstream_input.regional_network.regional_vpc_ids[\"us_east\"]\n    subnet_ids = upstream_input.regional_network.regional_subnet_ids[\"us_east\"]\n  }\n}\n\ndeployment \"eu_west_app\" {\n  inputs = {\n    region     = \"eu-west-1\"\n    vpc_id     = upstream_input.regional_network.regional_vpc_ids[\"eu_west\"]\n    subnet_ids = upstream_input.regional_network.regional_subnet_ids[\"eu_west\"]\n  }\n}\n```\n\n**Complete Linked Stack Example:**\n\nUpstream Stack (network-stack):\n```hcl\n# deployments.tfdeploy.hcl\ndeployment \"network\" {\n  inputs = {\n    vpc_cidr = \"10.0.0.0/16\"\n  }\n}\n\npublish_output \"vpc_id_network\" {\n  type  = string\n  value = deployment.network.vpc_id\n}\n\npublish_output \"private_subnet_ids\" {\n  type  = list(string)\n  value = deployment.network.private_subnet_ids\n}\n\npublish_output \"security_group_id\" {\n  type  = string\n  value = deployment.network.default_sg_id\n}\n```\n\nDownstream Stack (application-stack):\n```hcl\n# deployments.tfdeploy.hcl\nupstream_input \"networking\" {\n  type   = \"stack\"\n  source = \"app.terraform.io/my-org/my-project/network-stack\"\n}\n\ndeployment \"application\" {\n  inputs = {\n    vpc_id             = upstream_input.networking.vpc_id_network\n    subnet_ids         = upstream_input.networking.private_subnet_ids\n    security_group_id  = upstream_input.networking.security_group_id\n    instance_type      = \"t3.large\"\n  }\n}\n```\n\n## Complete Deployment Configuration Example\n\n```hcl\n# Identity tokens for cloud authentication\nidentity_token \"aws\" {\n  audience = [\"aws.workload.identity\"]\n}\n\n# Local values\nlocals {\n  role_arn    = \"arn:aws:iam::123456789012:role/terraform-stacks\"\n  project     = \"my-application\"\n  cost_center = \"engineering\"\n}\n\n# Upstream dependencies\nupstream_input \"shared_services\" {\n  type   = \"stack\"\n  source = \"app.terraform.io/my-org/my-project/shared-services\"\n}\n\n# Deployments\ndeployment \"development\" {\n  inputs = {\n    aws_region     = \"us-east-1\"\n    environment    = \"dev\"\n    instance_count = 1\n    instance_type  = \"t3.micro\"\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws.jwt\n    vpc_id         = upstream_input.shared_services.dev_vpc_id\n  }\n}\n\ndeployment \"staging\" {\n  inputs = {\n    aws_region     = \"us-west-1\"\n    environment    = \"staging\"\n    instance_count = 2\n    instance_type  = \"t3.small\"\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws.jwt\n    vpc_id         = upstream_input.shared_services.staging_vpc_id\n  }\n}\n\ndeployment \"production\" {\n  inputs = {\n    aws_region     = \"us-west-1\"\n    environment    = \"prod\"\n    instance_count = 5\n    instance_type  = \"t3.large\"\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws.jwt\n    vpc_id         = upstream_input.shared_services.prod_vpc_id\n  }\n}\n\n# Deployment groups\ndeployment_group \"non_production\" {\n  deployments = [\n    deployment.development,\n    deployment.staging\n  ]\n}\n\ndeployment_group \"production\" {\n  deployments = [\n    deployment.production\n  ]\n}\n\n# Auto-approval rules\ndeployment_auto_approve \"non_prod_auto\" {\n  deployment_group = deployment_group.non_production\n  \n  check {\n    condition = context.plan.applyable\n    reason    = \"Non-production plans must be applyable\"\n  }\n}\n\ndeployment_auto_approve \"prod_safe\" {\n  deployment_group = deployment_group.production\n  \n  check {\n    condition = context.plan.changes.remove == 0\n    reason    = \"Production cannot auto-approve deletions\"\n  }\n  \n  check {\n    condition = context.plan.applyable\n    reason    = \"Plan must be applyable\"\n  }\n}\n\n# Published outputs\npublish_output \"application_url\" {\n  type  = string\n  value = deployment.production.load_balancer_url\n}\n```\n",
        "terraform/module-generation/skills/terraform-stacks/references/examples.md": "# Terraform Stacks Complete Examples\n\nComplete, working examples for common Terraform Stacks scenarios.\n\n## Table of Contents\n\n1. [Simple Single-Region Stack](#simple-single-region-stack)\n2. [Stack with Private Registry Modules](#stack-with-private-registry-modules)\n3. [Multi-Environment Stack](#multi-environment-stack)\n4. [Multi-Region Stack](#multi-region-stack)\n5. [Linked Stacks (Cross-Stack Dependencies)](#linked-stacks-cross-stack-dependencies)\n6. [Multi-Cloud Stack](#multi-cloud-stack)\n7. [Complete AWS Production Stack](#complete-aws-production-stack)\n8. [Destroying Deployments](#destroying-deployments)\n\n## Simple Single-Region Stack\n\nBasic Stack with a single environment deployment.\n\n### File Structure\n```\nsimple-stack/\nâ”œâ”€â”€ variables.tfcomponent.hcl\nâ”œâ”€â”€ providers.tfcomponent.hcl\nâ”œâ”€â”€ components.tfcomponent.hcl\nâ”œâ”€â”€ deployments.tfdeploy.hcl\nâ””â”€â”€ modules/\n    â””â”€â”€ webapp/\n        â”œâ”€â”€ main.tf\n        â”œâ”€â”€ variables.tf\n        â””â”€â”€ outputs.tf\n```\n\n### variables.tfcomponent.hcl\n```hcl\nvariable \"aws_region\" {\n  type    = string\n  default = \"us-west-1\"\n}\n\nvariable \"identity_token\" {\n  type      = string\n  ephemeral = true\n}\n\nvariable \"role_arn\" {\n  type = string\n}\n\nvariable \"app_name\" {\n  type = string\n}\n```\n\n### providers.tfcomponent.hcl\n```hcl\nrequired_providers {\n  aws = {\n    source  = \"hashicorp/aws\"\n    version = \"~> 5.7.0\"\n  }\n}\n\nprovider \"aws\" \"main\" {\n  config {\n    region = var.aws_region\n    \n    assume_role_with_web_identity {\n      role_arn           = var.role_arn\n      web_identity_token = var.identity_token\n    }\n  }\n}\n```\n\n### components.tfcomponent.hcl\n```hcl\ncomponent \"webapp\" {\n  source = \"./modules/webapp\"\n  \n  inputs = {\n    app_name = var.app_name\n    region   = var.aws_region\n  }\n  \n  providers = {\n    aws = provider.aws.main\n  }\n}\n```\n\n### deployments.tfdeploy.hcl\n```hcl\nidentity_token \"aws\" {\n  audience = [\"aws.workload.identity\"]\n}\n\ndeployment \"production\" {\n  inputs = {\n    aws_region     = \"us-west-1\"\n    app_name       = \"my-webapp\"\n    role_arn       = \"arn:aws:iam::123456789012:role/terraform-stacks\"\n    identity_token = identity_token.aws.jwt\n  }\n}\n\n# Deployment groups\ndeployment_group \"production\" {\n  deployments = [deployment.production]\n}\n```\n\n## Stack with Private Registry Modules\n\nExample Stack using modules from a private HCP Terraform registry, combining both private and public registry sources.\n\n### File Structure\n```\nprivate-registry-stack/\nâ”œâ”€â”€ variables.tfcomponent.hcl\nâ”œâ”€â”€ providers.tfcomponent.hcl\nâ”œâ”€â”€ components.tfcomponent.hcl\nâ”œâ”€â”€ outputs.tfcomponent.hcl\nâ””â”€â”€ deployments.tfdeploy.hcl\n```\n\n### variables.tfcomponent.hcl\n```hcl\nvariable \"aws_region\" {\n  type    = string\n  default = \"us-west-2\"\n}\n\nvariable \"environment\" {\n  type = string\n}\n\nvariable \"identity_token\" {\n  type      = string\n  ephemeral = true\n}\n\nvariable \"role_arn\" {\n  type = string\n}\n\nvariable \"vpc_cidr\" {\n  type    = string\n  default = \"10.0.0.0/16\"\n}\n\nvariable \"app_name\" {\n  type = string\n}\n\nvariable \"db_password\" {\n  type      = string\n  sensitive = true\n}\n```\n\n### providers.tfcomponent.hcl\n```hcl\nrequired_providers {\n  aws = {\n    source  = \"hashicorp/aws\"\n    version = \"~> 5.7.0\"\n  }\n  random = {\n    source  = \"hashicorp/random\"\n    version = \"~> 3.5.0\"\n  }\n}\n\nprovider \"aws\" \"main\" {\n  config {\n    region = var.aws_region\n\n    assume_role_with_web_identity {\n      role_arn           = var.role_arn\n      web_identity_token = var.identity_token\n    }\n\n    default_tags {\n      tags = {\n        Environment = var.environment\n        ManagedBy   = \"Terraform Stacks\"\n        Application = var.app_name\n      }\n    }\n  }\n}\n\nprovider \"random\" \"main\" {\n  config {}\n}\n```\n\n### components.tfcomponent.hcl\n```hcl\nlocals {\n  name_prefix = \"${var.app_name}-${var.environment}\"\n  common_tags = {\n    Project     = var.app_name\n    Environment = var.environment\n  }\n}\n\n# Using a private registry module for VPC\ncomponent \"vpc\" {\n  source  = \"app.terraform.io/my-org/vpc/aws\"\n  version = \"2.1.0\"\n\n  inputs = {\n    name_prefix         = local.name_prefix\n    cidr_block          = var.vpc_cidr\n    availability_zones  = [\"${var.aws_region}a\", \"${var.aws_region}b\", \"${var.aws_region}c\"]\n    enable_nat_gateway  = true\n    single_nat_gateway  = var.environment != \"prod\"\n    tags                = local.common_tags\n  }\n\n  providers = {\n    aws = provider.aws.main\n  }\n}\n\n# Using a private registry module for security groups\ncomponent \"security_groups\" {\n  source  = \"app.terraform.io/my-org/security-groups/aws\"\n  version = \"1.5.2\"\n\n  inputs = {\n    vpc_id      = component.vpc.vpc_id\n    name_prefix = local.name_prefix\n    environment = var.environment\n  }\n\n  providers = {\n    aws = provider.aws.main\n  }\n}\n\n# Using a public registry module for RDS\ncomponent \"database\" {\n  source  = \"terraform-aws-modules/rds/aws\"\n  version = \"~> 6.0\"\n\n  inputs = {\n    identifier           = \"${local.name_prefix}-db\"\n    engine               = \"postgres\"\n    engine_version       = \"15.3\"\n    family               = \"postgres15\"\n    major_engine_version = \"15\"\n    instance_class       = var.environment == \"prod\" ? \"db.t3.large\" : \"db.t3.micro\"\n\n    allocated_storage     = var.environment == \"prod\" ? 100 : 20\n    db_name               = replace(var.app_name, \"-\", \"_\")\n    username              = \"dbadmin\"\n    password              = var.db_password\n    port                  = 5432\n\n    db_subnet_group_name   = component.vpc.database_subnet_group_name\n    vpc_security_group_ids = [component.security_groups.database_sg_id]\n\n    backup_retention_period = var.environment == \"prod\" ? 30 : 7\n    skip_final_snapshot     = var.environment != \"prod\"\n    deletion_protection     = var.environment == \"prod\"\n\n    tags = local.common_tags\n  }\n\n  providers = {\n    aws = provider.aws.main\n  }\n}\n\n# Using a private registry module for application infrastructure\ncomponent \"application\" {\n  source  = \"app.terraform.io/my-org/ecs-application/aws\"\n  version = \"3.2.1\"\n\n  inputs = {\n    name_prefix           = local.name_prefix\n    vpc_id                = component.vpc.vpc_id\n    private_subnet_ids    = component.vpc.private_subnet_ids\n    public_subnet_ids     = component.vpc.public_subnet_ids\n    app_security_group_id = component.security_groups.app_sg_id\n\n    container_image       = \"my-org/my-app:latest\"\n    container_port        = 8080\n    desired_count         = var.environment == \"prod\" ? 3 : 1\n\n    environment_variables = {\n      ENVIRONMENT    = var.environment\n      DATABASE_HOST  = component.database.db_instance_endpoint\n      DATABASE_NAME  = component.database.db_instance_name\n    }\n\n    tags = local.common_tags\n  }\n\n  providers = {\n    aws = provider.aws.main\n  }\n}\n```\n\n### outputs.tfcomponent.hcl\n```hcl\noutput \"vpc_id\" {\n  type        = string\n  description = \"VPC ID\"\n  value       = component.vpc.vpc_id\n}\n\noutput \"application_url\" {\n  type        = string\n  description = \"Application load balancer URL\"\n  value       = component.application.load_balancer_dns\n}\n\noutput \"database_endpoint\" {\n  type        = string\n  description = \"Database endpoint\"\n  value       = component.database.db_instance_endpoint\n  sensitive   = true\n}\n```\n\n### deployments.tfdeploy.hcl\n```hcl\nidentity_token \"aws\" {\n  audience = [\"aws.workload.identity\"]\n}\n\nlocals {\n  role_arn = \"arn:aws:iam::123456789012:role/terraform-stacks\"\n}\n\ndeployment \"development\" {\n  inputs = {\n    aws_region     = \"us-west-2\"\n    environment    = \"dev\"\n    app_name       = \"myapp\"\n    vpc_cidr       = \"10.0.0.0/16\"\n    db_password    = \"dev-password-change-me\"\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws.jwt\n  }\n}\n\ndeployment \"production\" {\n  inputs = {\n    aws_region     = \"us-east-1\"\n    environment    = \"prod\"\n    app_name       = \"myapp\"\n    vpc_cidr       = \"10.1.0.0/16\"\n    db_password    = \"prod-password-use-secrets-manager\"\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws.jwt\n  }\n}\n\n# Deployment groups\ndeployment_group \"development\" {\n  deployments = [deployment.development]\n}\n\ndeployment_group \"production\" {\n  deployments = [deployment.production]\n}\n```\n\n### Key Points\n\n- **Private registry modules** use the format `app.terraform.io/<org>/<module>/<provider>`\n- **Version constraints** ensure consistent module versions across environments\n- **Mixed sources**: Combining private registry modules (VPC, security groups, application) with public registry modules (RDS)\n- **Authentication**: HCP Terraform workspaces automatically authenticate to private registries; CLI users need credentials configured\n- **Terraform Enterprise**: Replace `app.terraform.io` with your instance hostname\n\n## Multi-Environment Stack\n\nStack with development, staging, and production deployments.\n\n### variables.tfcomponent.hcl\n```hcl\nvariable \"aws_region\" {\n  type = string\n}\n\nvariable \"environment\" {\n  type = string\n}\n\nvariable \"instance_count\" {\n  type = number\n}\n\nvariable \"instance_type\" {\n  type = string\n}\n\nvariable \"identity_token\" {\n  type      = string\n  ephemeral = true\n}\n\nvariable \"role_arn\" {\n  type = string\n}\n```\n\n### providers.tfcomponent.hcl\n```hcl\nrequired_providers {\n  aws = {\n    source  = \"hashicorp/aws\"\n    version = \"~> 5.7.0\"\n  }\n}\n\nprovider \"aws\" \"this\" {\n  config {\n    region = var.aws_region\n    \n    assume_role_with_web_identity {\n      role_arn           = var.role_arn\n      web_identity_token = var.identity_token\n    }\n    \n    default_tags {\n      tags = {\n        Environment = var.environment\n        ManagedBy   = \"Terraform Stacks\"\n      }\n    }\n  }\n}\n```\n\n### components.tfcomponent.hcl\n```hcl\nlocals {\n  name_prefix = \"myapp-${var.environment}\"\n}\n\ncomponent \"vpc\" {\n  source = \"./modules/vpc\"\n  \n  inputs = {\n    name_prefix = local.name_prefix\n    cidr_block  = \"10.0.0.0/16\"\n  }\n  \n  providers = {\n    aws = provider.aws.this\n  }\n}\n\ncomponent \"compute\" {\n  source = \"./modules/compute\"\n  \n  inputs = {\n    name_prefix    = local.name_prefix\n    vpc_id         = component.vpc.vpc_id\n    subnet_ids     = component.vpc.private_subnet_ids\n    instance_count = var.instance_count\n    instance_type  = var.instance_type\n  }\n  \n  providers = {\n    aws = provider.aws.this\n  }\n}\n```\n\n### outputs.tfcomponent.hcl\n```hcl\noutput \"vpc_id\" {\n  type  = string\n  value = component.vpc.vpc_id\n}\n\noutput \"load_balancer_url\" {\n  type  = string\n  value = component.compute.load_balancer_url\n}\n```\n\n### deployments.tfdeploy.hcl\n```hcl\nidentity_token \"aws\" {\n  audience = [\"aws.workload.identity\"]\n}\n\nlocals {\n  role_arn = \"arn:aws:iam::123456789012:role/terraform-stacks\"\n  \n  environments = {\n    dev = {\n      region         = \"us-east-1\"\n      instance_count = 1\n      instance_type  = \"t3.micro\"\n    }\n    staging = {\n      region         = \"us-west-1\"\n      instance_count = 2\n      instance_type  = \"t3.small\"\n    }\n    prod = {\n      region         = \"us-west-1\"\n      instance_count = 5\n      instance_type  = \"t3.large\"\n    }\n  }\n}\n\ndeployment \"development\" {\n  inputs = {\n    aws_region     = local.environments.dev.region\n    environment    = \"dev\"\n    instance_count = local.environments.dev.instance_count\n    instance_type  = local.environments.dev.instance_type\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws.jwt\n  }\n}\n\ndeployment \"staging\" {\n  inputs = {\n    aws_region     = local.environments.staging.region\n    environment    = \"staging\"\n    instance_count = local.environments.staging.instance_count\n    instance_type  = local.environments.staging.instance_type\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws.jwt\n  }\n}\n\ndeployment \"production\" {\n  inputs = {\n    aws_region     = local.environments.prod.region\n    environment    = \"prod\"\n    instance_count = local.environments.prod.instance_count\n    instance_type  = local.environments.prod.instance_type\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws.jwt\n  }\n}\n\n# Deployment groups\ndeployment_group \"development\" {\n  deployments = [deployment.development]\n}\n\ndeployment_group \"non_production\" {\n  deployments = [deployment.staging]\n}\n\ndeployment_group \"production\" {\n  deployments = [deployment.production]\n}\n\n# Auto-approve dev deployments\ndeployment_auto_approve \"dev_auto\" {\n  deployment_group = deployment_group.development\n\n  check {\n    condition = context.plan.applyable\n    reason    = \"Development plans must be applyable\"\n  }\n}\n```\n\n## Multi-Region Stack\n\nStack that deploys identical infrastructure across multiple AWS regions.\n\n### variables.tfcomponent.hcl\n```hcl\nvariable \"regions\" {\n  type = set(string)\n}\n\nvariable \"identity_token\" {\n  type      = string\n  ephemeral = true\n}\n\nvariable \"role_arn\" {\n  type = string\n}\n\nvariable \"app_name\" {\n  type = string\n}\n```\n\n### providers.tfcomponent.hcl\n```hcl\nrequired_providers {\n  aws = {\n    source  = \"hashicorp/aws\"\n    version = \"~> 5.7.0\"\n  }\n}\n\nprovider \"aws\" \"regional\" {\n  for_each = var.regions\n  \n  config {\n    region = each.value\n    \n    assume_role_with_web_identity {\n      role_arn           = var.role_arn\n      web_identity_token = var.identity_token\n    }\n    \n    default_tags {\n      tags = {\n        Region    = each.value\n        ManagedBy = \"Terraform Stacks\"\n        AppName   = var.app_name\n      }\n    }\n  }\n}\n```\n\n### components.tfcomponent.hcl\n```hcl\ncomponent \"regional_infrastructure\" {\n  for_each = var.regions\n  \n  source = \"./modules/regional-infra\"\n  \n  inputs = {\n    region      = each.value\n    app_name    = var.app_name\n    name_suffix = each.value\n  }\n  \n  providers = {\n    aws = provider.aws.regional[each.value]\n  }\n}\n\ncomponent \"global_route53\" {\n  source = \"./modules/route53\"\n  \n  inputs = {\n    app_name     = var.app_name\n    domain_name  = \"example.com\"\n    regional_lbs = {\n      for region, comp in component.regional_infrastructure :\n      region => comp.load_balancer_dns\n    }\n  }\n  \n  # Use one region's provider for global resources\n  providers = {\n    aws = provider.aws.regional[\"us-west-1\"]\n  }\n}\n```\n\n### outputs.tfcomponent.hcl\n```hcl\noutput \"regional_endpoints\" {\n  type = map(string)\n  value = {\n    for region, comp in component.regional_infrastructure :\n    region => comp.load_balancer_url\n  }\n}\n\noutput \"global_domain\" {\n  type  = string\n  value = component.global_route53.domain_name\n}\n```\n\n### deployments.tfdeploy.hcl\n```hcl\nidentity_token \"aws\" {\n  audience = [\"aws.workload.identity\"]\n}\n\nlocals {\n  regions = [\"us-west-1\", \"us-east-1\", \"eu-west-1\"]\n}\n\ndeployment \"multi_region_prod\" {\n  inputs = {\n    regions        = toset(local.regions)\n    app_name       = \"my-global-app\"\n    role_arn       = \"arn:aws:iam::123456789012:role/terraform-stacks\"\n    identity_token = identity_token.aws.jwt\n  }\n}\n\n# Deployment groups\ndeployment_group \"production\" {\n  deployments = [deployment.multi_region_prod]\n}\n```\n\n## Linked Stacks (Cross-Stack Dependencies)\n\nTwo Stacks where the application Stack depends on the network Stack.\n\n### Network Stack\n\n#### network-stack/variables.tfcomponent.hcl\n```hcl\nvariable \"vpc_cidr\" {\n  type = string\n}\n\nvariable \"environment\" {\n  type = string\n}\n\nvariable \"aws_region\" {\n  type = string\n}\n\nvariable \"identity_token\" {\n  type      = string\n  ephemeral = true\n}\n\nvariable \"role_arn\" {\n  type = string\n}\n```\n\n#### network-stack/providers.tfcomponent.hcl\n```hcl\nrequired_providers {\n  aws = {\n    source  = \"hashicorp/aws\"\n    version = \"~> 5.7.0\"\n  }\n}\n\nprovider \"aws\" \"this\" {\n  config {\n    region = var.aws_region\n    \n    assume_role_with_web_identity {\n      role_arn           = var.role_arn\n      web_identity_token = var.identity_token\n    }\n  }\n}\n```\n\n#### network-stack/components.tfcomponent.hcl\n```hcl\ncomponent \"vpc\" {\n  source = \"./modules/vpc\"\n  \n  inputs = {\n    cidr_block  = var.vpc_cidr\n    environment = var.environment\n  }\n  \n  providers = {\n    aws = provider.aws.this\n  }\n}\n\ncomponent \"security_groups\" {\n  source = \"./modules/security-groups\"\n  \n  inputs = {\n    vpc_id      = component.vpc.vpc_id\n    environment = var.environment\n  }\n  \n  providers = {\n    aws = provider.aws.this\n  }\n}\n```\n\n#### network-stack/outputs.tfcomponent.hcl\n```hcl\noutput \"vpc_id\" {\n  type  = string\n  value = component.vpc.vpc_id\n}\n\noutput \"private_subnet_ids\" {\n  type  = list(string)\n  value = component.vpc.private_subnet_ids\n}\n\noutput \"public_subnet_ids\" {\n  type  = list(string)\n  value = component.vpc.public_subnet_ids\n}\n\noutput \"app_security_group_id\" {\n  type  = string\n  value = component.security_groups.app_sg_id\n}\n```\n\n#### network-stack/deployments.tfdeploy.hcl\n```hcl\nidentity_token \"aws\" {\n  audience = [\"aws.workload.identity\"]\n}\n\nlocals {\n  role_arn = \"arn:aws:iam::123456789012:role/terraform-stacks\"\n}\n\ndeployment \"network\" {\n  inputs = {\n    aws_region     = \"us-west-1\"\n    environment    = \"production\"\n    vpc_cidr       = \"10.0.0.0/16\"\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws.jwt\n  }\n}\n\n# Publish outputs for other stacks\npublish_output \"vpc_id_network\" {\n  type  = string\n  value = deployment.network.vpc_id\n}\n\npublish_output \"private_subnet_ids\" {\n  type  = list(string)\n  value = deployment.network.private_subnet_ids\n}\n\npublish_output \"public_subnet_ids\" {\n  type  = list(string)\n  value = deployment.network.public_subnet_ids\n}\n\npublish_output \"app_security_group_id\" {\n  type  = string\n  value = deployment.network.app_security_group_id\n}\n\n# Deployment groups\ndeployment_group \"network\" {\n  deployments = [deployment.network]\n}\n```\n\n### Application Stack\n\n#### application-stack/variables.tfcomponent.hcl\n```hcl\nvariable \"vpc_id\" {\n  type = string\n}\n\nvariable \"subnet_ids\" {\n  type = list(string)\n}\n\nvariable \"security_group_id\" {\n  type = string\n}\n\nvariable \"instance_count\" {\n  type = number\n}\n\nvariable \"aws_region\" {\n  type = string\n}\n\nvariable \"identity_token\" {\n  type      = string\n  ephemeral = true\n}\n\nvariable \"role_arn\" {\n  type = string\n}\n```\n\n#### application-stack/providers.tfcomponent.hcl\n```hcl\nrequired_providers {\n  aws = {\n    source  = \"hashicorp/aws\"\n    version = \"~> 5.7.0\"\n  }\n}\n\nprovider \"aws\" \"this\" {\n  config {\n    region = var.aws_region\n    \n    assume_role_with_web_identity {\n      role_arn           = var.role_arn\n      web_identity_token = var.identity_token\n    }\n  }\n}\n```\n\n#### application-stack/components.tfcomponent.hcl\n```hcl\ncomponent \"application\" {\n  source = \"./modules/app\"\n  \n  inputs = {\n    vpc_id            = var.vpc_id\n    subnet_ids        = var.subnet_ids\n    security_group_id = var.security_group_id\n    instance_count    = var.instance_count\n  }\n  \n  providers = {\n    aws = provider.aws.this\n  }\n}\n```\n\n#### application-stack/deployments.tfdeploy.hcl\n```hcl\nidentity_token \"aws\" {\n  audience = [\"aws.workload.identity\"]\n}\n\n# Reference the network stack\nupstream_input \"network\" {\n  type   = \"stack\"\n  source = \"app.terraform.io/my-org/my-project/network-stack\"\n}\n\ndeployment \"application\" {\n  inputs = {\n    aws_region        = \"us-west-1\"\n    vpc_id            = upstream_input.network.vpc_id_network\n    subnet_ids        = upstream_input.network.private_subnet_ids\n    security_group_id = upstream_input.network.app_security_group_id\n    instance_count    = 3\n    role_arn          = \"arn:aws:iam::123456789012:role/terraform-stacks\"\n    identity_token    = identity_token.aws.jwt\n  }\n}\n\n# Deployment groups\ndeployment_group \"application\" {\n  deployments = [deployment.application]\n}\n```\n\n## Multi-Cloud Stack\n\nStack that deploys to both AWS and Azure.\n\n### variables.tfcomponent.hcl\n```hcl\nvariable \"aws_region\" {\n  type = string\n}\n\nvariable \"azure_location\" {\n  type = string\n}\n\nvariable \"aws_identity_token\" {\n  type      = string\n  ephemeral = true\n}\n\nvariable \"aws_role_arn\" {\n  type = string\n}\n\nvariable \"azure_identity_token\" {\n  type      = string\n  ephemeral = true\n}\n\nvariable \"azure_subscription_id\" {\n  type = string\n}\n\nvariable \"azure_tenant_id\" {\n  type = string\n}\n\nvariable \"azure_client_id\" {\n  type = string\n}\n\nvariable \"app_name\" {\n  type = string\n}\n```\n\n### providers.tfcomponent.hcl\n```hcl\nrequired_providers {\n  aws = {\n    source  = \"hashicorp/aws\"\n    version = \"~> 5.7.0\"\n  }\n  azurerm = {\n    source  = \"hashicorp/azurerm\"\n    version = \"~> 3.0\"\n  }\n}\n\nprovider \"aws\" \"this\" {\n  config {\n    region = var.aws_region\n    \n    assume_role_with_web_identity {\n      role_arn           = var.aws_role_arn\n      web_identity_token = var.aws_identity_token\n    }\n  }\n}\n\nprovider \"azurerm\" \"this\" {\n  config {\n    features {}\n    \n    subscription_id = var.azure_subscription_id\n    tenant_id       = var.azure_tenant_id\n    client_id       = var.azure_client_id\n    \n    use_oidc = true\n    oidc_token = var.azure_identity_token\n  }\n}\n```\n\n### components.tfcomponent.hcl\n```hcl\ncomponent \"aws_infrastructure\" {\n  source = \"./modules/aws-infra\"\n  \n  inputs = {\n    region   = var.aws_region\n    app_name = var.app_name\n  }\n  \n  providers = {\n    aws = provider.aws.this\n  }\n}\n\ncomponent \"azure_infrastructure\" {\n  source = \"./modules/azure-infra\"\n  \n  inputs = {\n    location = var.azure_location\n    app_name = var.app_name\n  }\n  \n  providers = {\n    azurerm = provider.azurerm.this\n  }\n}\n```\n\n### deployments.tfdeploy.hcl\n```hcl\nidentity_token \"aws\" {\n  audience = [\"aws.workload.identity\"]\n}\n\nidentity_token \"azure\" {\n  audience = [\"api://AzureADTokenExchange\"]\n}\n\ndeployment \"multi_cloud\" {\n  inputs = {\n    aws_region             = \"us-west-1\"\n    azure_location         = \"westus2\"\n    app_name               = \"my-multi-cloud-app\"\n    aws_role_arn           = \"arn:aws:iam::123456789012:role/terraform-stacks\"\n    aws_identity_token     = identity_token.aws.jwt\n    azure_subscription_id  = \"12345678-1234-1234-1234-123456789012\"\n    azure_tenant_id        = \"87654321-4321-4321-4321-210987654321\"\n    azure_client_id        = \"11111111-1111-1111-1111-111111111111\"\n    azure_identity_token   = identity_token.azure.jwt\n  }\n}\n\n# Deployment groups\ndeployment_group \"multi_cloud\" {\n  deployments = [deployment.multi_cloud]\n}\n```\n\n## Complete AWS Production Stack\n\nFull production-grade Stack with VPC, RDS, ECS, and monitoring.\n\n### variables.tfcomponent.hcl\n```hcl\nvariable \"aws_region\" {\n  type        = string\n  description = \"AWS region\"\n}\n\nvariable \"environment\" {\n  type        = string\n  description = \"Environment name\"\n}\n\nvariable \"vpc_cidr\" {\n  type        = string\n  description = \"VPC CIDR block\"\n}\n\nvariable \"app_name\" {\n  type        = string\n  description = \"Application name\"\n}\n\nvariable \"db_instance_class\" {\n  type        = string\n  description = \"RDS instance class\"\n}\n\nvariable \"ecs_desired_count\" {\n  type        = number\n  description = \"Desired ECS task count\"\n}\n\nvariable \"identity_token\" {\n  type      = string\n  ephemeral = true\n}\n\nvariable \"role_arn\" {\n  type = string\n}\n```\n\n### providers.tfcomponent.hcl\n```hcl\nrequired_providers {\n  aws = {\n    source  = \"hashicorp/aws\"\n    version = \"~> 5.7.0\"\n  }\n  random = {\n    source  = \"hashicorp/random\"\n    version = \"~> 3.5.0\"\n  }\n}\n\nprovider \"aws\" \"this\" {\n  config {\n    region = var.aws_region\n    \n    assume_role_with_web_identity {\n      role_arn           = var.role_arn\n      web_identity_token = var.identity_token\n    }\n    \n    default_tags {\n      tags = {\n        Environment = var.environment\n        Application = var.app_name\n        ManagedBy   = \"Terraform Stacks\"\n      }\n    }\n  }\n}\n\nprovider \"random\" \"this\" {\n  config {}\n}\n```\n\n### components.tfcomponent.hcl\n```hcl\nlocals {\n  name_prefix = \"${var.app_name}-${var.environment}\"\n}\n\ncomponent \"vpc\" {\n  source = \"./modules/vpc\"\n  \n  inputs = {\n    name_prefix = local.name_prefix\n    cidr_block  = var.vpc_cidr\n    azs_count   = 3\n  }\n  \n  providers = {\n    aws = provider.aws.this\n  }\n}\n\ncomponent \"security_groups\" {\n  source = \"./modules/security-groups\"\n  \n  inputs = {\n    name_prefix = local.name_prefix\n    vpc_id      = component.vpc.vpc_id\n  }\n  \n  providers = {\n    aws = provider.aws.this\n  }\n}\n\ncomponent \"rds\" {\n  source = \"./modules/rds\"\n  \n  inputs = {\n    name_prefix        = local.name_prefix\n    instance_class     = var.db_instance_class\n    subnet_ids         = component.vpc.private_subnet_ids\n    security_group_ids = [component.security_groups.database_sg_id]\n  }\n  \n  providers = {\n    aws    = provider.aws.this\n    random = provider.random.this\n  }\n}\n\ncomponent \"ecs_cluster\" {\n  source = \"./modules/ecs-cluster\"\n  \n  inputs = {\n    name_prefix = local.name_prefix\n  }\n  \n  providers = {\n    aws = provider.aws.this\n  }\n}\n\ncomponent \"ecs_service\" {\n  source = \"./modules/ecs-service\"\n  \n  inputs = {\n    name_prefix      = local.name_prefix\n    cluster_id       = component.ecs_cluster.cluster_id\n    desired_count    = var.ecs_desired_count\n    subnet_ids       = component.vpc.private_subnet_ids\n    security_group_id = component.security_groups.app_sg_id\n    database_endpoint = component.rds.endpoint\n  }\n  \n  providers = {\n    aws = provider.aws.this\n  }\n}\n\ncomponent \"alb\" {\n  source = \"./modules/alb\"\n  \n  inputs = {\n    name_prefix       = local.name_prefix\n    vpc_id            = component.vpc.vpc_id\n    subnet_ids        = component.vpc.public_subnet_ids\n    security_group_id = component.security_groups.alb_sg_id\n    target_group_arn  = component.ecs_service.target_group_arn\n  }\n  \n  providers = {\n    aws = provider.aws.this\n  }\n}\n\ncomponent \"cloudwatch\" {\n  source = \"./modules/cloudwatch\"\n  \n  inputs = {\n    name_prefix  = local.name_prefix\n    cluster_name = component.ecs_cluster.cluster_name\n    service_name = component.ecs_service.service_name\n  }\n  \n  providers = {\n    aws = provider.aws.this\n  }\n}\n```\n\n### outputs.tfcomponent.hcl\n```hcl\noutput \"load_balancer_url\" {\n  type        = string\n  description = \"Application load balancer URL\"\n  value       = component.alb.dns_name\n}\n\noutput \"database_endpoint\" {\n  type        = string\n  description = \"RDS endpoint\"\n  value       = component.rds.endpoint\n  sensitive   = true\n}\n\noutput \"vpc_id\" {\n  type  = string\n  value = component.vpc.vpc_id\n}\n\noutput \"ecs_cluster_name\" {\n  type  = string\n  value = component.ecs_cluster.cluster_name\n}\n```\n\n### deployments.tfdeploy.hcl\n```hcl\nidentity_token \"aws\" {\n  audience = [\"aws.workload.identity\"]\n}\n\nlocals {\n  role_arn = \"arn:aws:iam::123456789012:role/terraform-stacks\"\n}\n\ndeployment \"staging\" {\n  inputs = {\n    aws_region        = \"us-west-1\"\n    environment       = \"staging\"\n    app_name          = \"myapp\"\n    vpc_cidr          = \"10.1.0.0/16\"\n    db_instance_class = \"db.t3.small\"\n    ecs_desired_count = 2\n    role_arn          = local.role_arn\n    identity_token    = identity_token.aws.jwt\n  }\n}\n\ndeployment \"production\" {\n  inputs = {\n    aws_region        = \"us-west-1\"\n    environment       = \"production\"\n    app_name          = \"myapp\"\n    vpc_cidr          = \"10.0.0.0/16\"\n    db_instance_class = \"db.r5.large\"\n    ecs_desired_count = 5\n    role_arn          = local.role_arn\n    identity_token    = identity_token.aws.jwt\n  }\n}\n\n# Deployment groups\ndeployment_group \"staging\" {\n  deployments = [deployment.staging]\n}\n\ndeployment_group \"production\" {\n  deployments = [deployment.production]\n}\n\n# Auto-approve staging with safety checks\ndeployment_auto_approve \"staging_safe\" {\n  deployment_group = deployment_group.staging\n\n  check {\n    condition = context.plan.changes.remove == 0\n    reason    = \"Cannot auto-approve deletions in staging\"\n  }\n\n  check {\n    condition = context.plan.applyable\n    reason    = \"Plan must be applyable\"\n  }\n}\n```\n\n## Testing Configurations\n\n### Validate Stack Configuration\n```bash\nterraform stacks providers lock\nterraform stacks validate\n```\n\n### Plan Specific Deployment\n```bash\nterraform stacks plan --deployment=development\nterraform stacks plan --deployment=production\n```\n\n### Apply Deployment\n```bash\nterraform stacks apply --deployment=staging\n```\n\n## Destroying Deployments\n\nExample of safely removing a deployment from your Stack.\n\n### Scenario\n\nYou want to decommission the \"development\" deployment while keeping staging and production active.\n\n### Step 1: Mark Deployment for Destruction\n\nUpdate your `deployments.tfdeploy.hcl` file to set `destroy = true`:\n\n```hcl\nidentity_token \"aws\" {\n  audience = [\"aws.workload.identity\"]\n}\n\nlocals {\n  role_arn = \"arn:aws:iam::123456789012:role/terraform-stacks\"\n}\n\n# Mark this deployment for destruction\ndeployment \"development\" {\n  inputs = {\n    aws_region     = \"us-east-1\"\n    environment    = \"dev\"\n    instance_count = 1\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws.jwt\n  }\n  destroy = true  # This tells HCP Terraform to destroy all resources\n}\n\n# Keep these deployments active\ndeployment \"staging\" {\n  inputs = {\n    aws_region     = \"us-west-1\"\n    environment    = \"staging\"\n    instance_count = 2\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws.jwt\n  }\n}\n\ndeployment \"production\" {\n  inputs = {\n    aws_region     = \"us-west-1\"\n    environment    = \"prod\"\n    instance_count = 5\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws.jwt\n  }\n}\n\n# Deployment groups\ndeployment_group \"staging\" {\n  deployments = [deployment.staging]\n}\n\ndeployment_group \"production\" {\n  deployments = [deployment.production]\n}\n```\n\n### Step 2: Plan and Apply\n\n```bash\n# Review the destruction plan\nterraform stacks plan --deployment=development\n\n# Apply the destruction\nterraform stacks apply --deployment=development\n```\n\nHCP Terraform will destroy all resources in the development deployment.\n\n### Step 3: Remove the Deployment Block\n\nAfter the deployment is successfully destroyed, remove the entire deployment block from your configuration:\n\n```hcl\nidentity_token \"aws\" {\n  audience = [\"aws.workload.identity\"]\n}\n\nlocals {\n  role_arn = \"arn:aws:iam::123456789012:role/terraform-stacks\"\n}\n\n# deployment \"development\" block has been removed\n\ndeployment \"staging\" {\n  inputs = {\n    aws_region     = \"us-west-1\"\n    environment    = \"staging\"\n    instance_count = 2\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws.jwt\n  }\n}\n\ndeployment \"production\" {\n  inputs = {\n    aws_region     = \"us-west-1\"\n    environment    = \"prod\"\n    instance_count = 5\n    role_arn       = local.role_arn\n    identity_token = identity_token.aws.jwt\n  }\n}\n\n# Deployment groups\ndeployment_group \"staging\" {\n  deployments = [deployment.staging]\n}\n\ndeployment_group \"production\" {\n  deployments = [deployment.production]\n}\n```\n\n### Important Notes\n\n- **Provider Authentication**: The `destroy` argument ensures your configuration retains the provider authentication needed to destroy resources\n- **Do Not Remove Immediately**: Don't remove the deployment block until after the destruction is complete\n- **Verify Before Removing**: Check HCP Terraform UI to confirm all resources are destroyed before removing the block\n- **Alternative**: You could manually destroy resources through HCP Terraform UI, but using `destroy = true` is the recommended approach for maintaining infrastructure-as-code practices\n",
        "terraform/provider-development/.claude-plugin/plugin.json": "{\n  \"name\": \"terraform-provider-development\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Terraform provider development skills for Claude Code, including resources, data sources, actions, and acceptance testing.\",\n  \"author\": {\n    \"name\": \"HashiCorp\",\n    \"url\": \"https://github.com/hashicorp\"\n  },\n  \"homepage\": \"https://developer.hashicorp.com/terraform/plugin/framework\",\n  \"repository\": \"https://github.com/hashicorp/agent-skills\",\n  \"license\": \"MPL-2.0\",\n  \"keywords\": [\"terraform\", \"provider\", \"plugin-framework\", \"resources\", \"testing\"]\n}\n",
        "terraform/provider-development/skills/new-terraform-provider/SKILL.md": "---\nname: new-terraform-provider\ndescription: Use this when scaffolding a new Terraform provider.\nlicense: MPL-2.0\nmetadata:\n  copyright: Copyright IBM Corp. 2026\n  version: \"0.0.1\"\n---\n\nTo scaffold a new Terraform provider with Plugin Framework:\n\n1. If I am already in a Terraform provider workspace, then confirm that I want\n   to create a new workspace. If I do not want to create a new workspace, then\n   skip all remaining steps.\n1. Create a new workspace root directory. The root directory name should be\n   prefixed with \"terraform-provider-\". Perform all subsequent steps in this\n   new workspace.\n1. Initialize a new Go module..\n1. Run `go get -u github.com/hashicorp/terraform-plugin-framework@latest`.\n1. Write a main.go file that follows [the example](assets/main.go).\n1. Remove TODO comments from `main.go`\n1. Run `go mod tidy`\n1. Run `go build -o /dev/null`\n1. Run `go test ./...`\n\n",
        "terraform/provider-development/skills/provider-actions/SKILL.md": "---\nname: provider-actions\ndescription: Implement Terraform Provider actions using the Plugin Framework. Use when developing imperative operations that execute at lifecycle events (before/after create, update, destroy).\nmetadata:\n  copyright: Copyright IBM Corp. 2026\n  version: \"0.0.1\"\n---\n\n# Terraform Provider Actions Implementation Guide\n\n## Overview\n\nTerraform Actions enable imperative operations during the Terraform lifecycle. Actions are experimental features that allow performing provider operations at specific lifecycle events (before/after create, update, destroy).\n\n**References:**\n- [Terraform Plugin Framework](https://developer.hashicorp.com/terraform/plugin/framework)\n- [Terraform Actions RFC](https://github.com/hashicorp/terraform/blob/main/docs/plugin-protocol/actions.md)\n\n## File Structure\n\nActions follow the standard service package structure:\n\n```\ninternal/service/<service>/\nâ”œâ”€â”€ <action_name>_action.go       # Action implementation\nâ”œâ”€â”€ <action_name>_action_test.go  # Action tests\nâ””â”€â”€ service_package_gen.go        # Auto-generated service registration\n```\n\nDocumentation structure:\n```\nwebsite/docs/actions/\nâ””â”€â”€ <service>_<action_name>.html.markdown  # User-facing documentation\n```\n\nChangelog entry:\n```\n.changelog/\nâ””â”€â”€ <pr_number_or_description>.txt  # Release note entry\n```\n\n## Action Schema Definition\n\nActions use the Terraform Plugin Framework with a standard schema pattern:\n\n```go\nfunc (a *actionType) Schema(ctx context.Context, req action.SchemaRequest, resp *action.SchemaResponse) {\n    resp.Schema = schema.Schema{\n        Attributes: map[string]schema.Attribute{\n            // Required configuration parameters\n            \"resource_id\": schema.StringAttribute{\n                Required:    true,\n                Description: \"ID of the resource to operate on\",\n            },\n            // Optional parameters with defaults\n            \"timeout\": schema.Int64Attribute{\n                Optional:    true,\n                Description: \"Operation timeout in seconds\",\n                Default:     int64default.StaticInt64(1800),\n                Computed:    true,\n            },\n        },\n    }\n}\n```\n\n### Common Schema Issues\n\n**Pay special attention to the schema definition** - common issues after a first draft:\n\n1. **Type Mismatches**\n   - Using `types.String` instead of `fwtypes.String` in model structs\n   - Using `types.StringType` instead of `fwtypes.StringType` in schema\n   - Mixing framework types with plugin-framework types\n\n2. **List/Map Element Types**\n   ```go\n   // WRONG - missing ElementType\n   \"items\": schema.ListAttribute{\n       Optional: true,\n   }\n\n   // CORRECT\n   \"items\": schema.ListAttribute{\n       Optional:    true,\n       ElementType: fwtypes.StringType,\n   }\n   ```\n\n3. **Computed vs Optional**\n   - Attributes with defaults must be both `Optional: true` and `Computed: true`\n   - Don't mark action inputs as `Computed` unless they have defaults\n\n4. **Validator Imports**\n   ```go\n   // Ensure proper imports\n   \"github.com/hashicorp/terraform-plugin-framework-validators/int64validator\"\n   \"github.com/hashicorp/terraform-plugin-framework-validators/stringvalidator\"\n   ```\n\n5. **Region/Provider Attribute**\n   - Use framework-provided region handling when available\n   - Don't manually define provider-specific config in schema if framework handles it\n\n6. **Nested Attributes**\n   - Use appropriate nested object types for complex structures\n   - Ensure nested types are properly defined\n\n### Schema Validation Checklist\n\nBefore submitting, verify:\n- [ ] All attributes have descriptions\n- [ ] List/Map attributes have ElementType defined\n- [ ] Validators are imported and applied correctly\n- [ ] Model struct uses correct framework types\n- [ ] Optional attributes with defaults are marked Computed\n- [ ] Code compiles without type errors\n- [ ] Run `go build` to catch type mismatches\n\n## Action Invoke Method\n\nThe Invoke method contains the action logic:\n\n```go\nfunc (a *actionType) Invoke(ctx context.Context, req action.InvokeRequest, resp *action.InvokeResponse) {\n    var data actionModel\n    resp.Diagnostics.Append(req.Config.Get(ctx, &data)...)\n\n    // Create provider client\n    conn := a.Meta().Client(ctx)\n\n    // Progress updates for long-running operations\n    resp.Progress.Set(ctx, \"Starting operation...\")\n\n    // Implement action logic with error handling\n    // Use context for timeout management\n    // Poll for completion if async operation\n\n    resp.Progress.Set(ctx, \"Operation completed\")\n}\n```\n\n## Key Implementation Requirements\n\n### 1. Progress Reporting\n\n- Use `resp.SendProgress(action.InvokeProgressEvent{...})` for real-time updates\n- Provide meaningful progress messages during long operations\n- Update progress at key milestones\n- Include elapsed time for long operations\n\n### 2. Timeout Management\n\n- Always include configurable timeout parameter (default: 1800s)\n- Use `context.WithTimeout()` for API calls\n- Handle timeout errors gracefully\n- Validate timeout ranges (typically 60-7200 seconds)\n\n### 3. Error Handling\n\n- Add diagnostics with `resp.Diagnostics.AddError()`\n- Provide clear error messages with context\n- Include API error details when relevant\n- Map provider error types to user-friendly messages\n- Document all possible error cases\n\nExample error handling:\n```go\n// Handle specific errors\nvar notFound *types.ResourceNotFoundException\nif errors.As(err, &notFound) {\n    resp.Diagnostics.AddError(\n        \"Resource Not Found\",\n        fmt.Sprintf(\"Resource %s was not found\", resourceID),\n    )\n    return\n}\n\n// Generic error handling\nresp.Diagnostics.AddError(\n    \"Operation Failed\",\n    fmt.Sprintf(\"Could not complete operation for %s: %s\", resourceID, err),\n)\n```\n\n### 4. Provider SDK Integration\n\n- Use provider SDK clients from `a.Meta().<Service>Client(ctx)`\n- Handle pagination for list operations\n- Implement retry logic for transient failures\n- Use appropriate error types\n\n### 5. Parameter Validation\n\n- Use framework validators for input validation\n- Validate resource existence before operations\n- Check for conflicting parameters\n- Validate against provider naming requirements\n\n### 6. Polling and Waiting\n\nFor operations that require waiting for completion:\n\n```go\nresult, err := wait.WaitForStatus(ctx,\n    func(ctx context.Context) (wait.FetchResult[*ResourceType], error) {\n        // Fetch current status\n        resource, err := findResource(ctx, conn, id)\n        if err != nil {\n            return wait.FetchResult[*ResourceType]{}, err\n        }\n        return wait.FetchResult[*ResourceType]{\n            Status: wait.Status(resource.Status),\n            Value:  resource,\n        }, nil\n    },\n    wait.Options[*ResourceType]{\n        Timeout:            timeout,\n        Interval:           wait.FixedInterval(5 * time.Second),\n        SuccessStates:      []wait.Status{\"AVAILABLE\", \"COMPLETED\"},\n        TransitionalStates: []wait.Status{\"CREATING\", \"PENDING\"},\n        ProgressInterval:   30 * time.Second,\n        ProgressSink: func(fr wait.FetchResult[any], meta wait.ProgressMeta) {\n            resp.SendProgress(action.InvokeProgressEvent{\n                Message: fmt.Sprintf(\"Status: %s, Elapsed: %v\", fr.Status, meta.Elapsed.Round(time.Second)),\n            })\n        },\n    },\n)\n```\n\n## Common Action Patterns\n\n### Batch Operations\n- Process items in configurable batches\n- Report progress per batch\n- Handle partial failures gracefully\n- Support prefix/filter parameters\n\n### Command Execution\n- Submit command and get operation ID\n- Poll for completion status\n- Retrieve and report output\n- Handle timeout during polling\n- Validate resources exist before execution\n\n### Service Invocation\n- Invoke service with parameters\n- Wait for completion (if synchronous)\n- Return output/results\n- Handle service-specific errors\n\n### Resource State Changes\n- Validate current state\n- Apply state change\n- Poll for target state\n- Handle transitional states\n\n### Async Job Submission\n- Submit job with configuration\n- Get job ID\n- Optionally wait for completion\n- Report job status\n\n## Action Triggers\n\nActions are invoked via `action_trigger` lifecycle blocks in Terraform configurations:\n\n```hcl\naction \"provider_service_action\" \"name\" {\n  config {\n    parameter = value\n  }\n}\n\nresource \"terraform_data\" \"trigger\" {\n  lifecycle {\n    action_trigger {\n      events  = [after_create]\n      actions = [action.provider_service_action.name]\n    }\n  }\n}\n```\n\n### Available Trigger Events\n\n**Terraform 1.14.0 Supported Events:**\n- `before_create` - Before resource creation\n- `after_create` - After resource creation\n- `before_update` - Before resource update\n- `after_update` - After resource update\n\n**Not Supported in Terraform 1.14.0:**\n- `before_destroy` - Not available (will cause validation error)\n- `after_destroy` - Not available (will cause validation error)\n\n## Testing Actions\n\n### Acceptance Tests\n\n- Test action invocation with valid parameters\n- Test timeout scenarios\n- Test error conditions\n- Verify provider state changes\n- Test progress reporting\n- Test with custom parameters\n- Test trigger-based invocation\n\n### Test Pattern\n\n```go\nfunc TestAccServiceAction_basic(t *testing.T) {\n    ctx := acctest.Context(t)\n\n    resource.ParallelTest(t, resource.TestCase{\n        PreCheck:                 func() { acctest.PreCheck(ctx, t) },\n        ProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n        TerraformVersionChecks: []tfversion.TerraformVersionCheck{\n            tfversion.SkipBelow(tfversion.Version1_14_0),\n        },\n        Steps: []resource.TestStep{\n            {\n                Config: testAccActionConfig_basic(),\n                Check: resource.ComposeTestCheckFunc(\n                    testAccCheckResourceExists(ctx, \"provider_resource.test\"),\n                ),\n            },\n        },\n    })\n}\n```\n\n### Test Cleanup with Sweep Functions\n\nAdd sweep functions to clean up test resources:\n\n```go\nfunc sweepResources(region string) error {\n    ctx := context.Background()\n    client := /* get client for region */\n\n    input := &service.ListInput{\n        // Filter for test resources\n    }\n\n    var sweeperErrs *multierror.Error\n\n    pages := service.NewListPaginator(client, input)\n    for pages.HasMorePages() {\n        page, err := pages.NextPage(ctx)\n        if err != nil {\n            sweeperErrs = multierror.Append(sweeperErrs, err)\n            continue\n        }\n\n        for _, item := range page.Items {\n            id := item.Id\n\n            // Skip non-test resources\n            if !strings.HasPrefix(id, \"tf-acc-test\") {\n                continue\n            }\n\n            _, err := client.Delete(ctx, &service.DeleteInput{\n                Id: id,\n            })\n            if err != nil {\n                sweeperErrs = multierror.Append(sweeperErrs, err)\n            }\n        }\n    }\n\n    return sweeperErrs.ErrorOrNil()\n}\n```\n\n### Testing Best Practices\n\n**Service-Specific Prerequisites**\n- Always check for service-specific prerequisites that must be met before actions can succeed\n- Document prerequisites in action documentation and test configurations\n\n**Error Pattern Matching**\n- Terraform wraps action errors with additional context\n- Use flexible regex patterns: `regexache.MustCompile(\\`(?s)Error Title.*key phrase\\`)`\n\n**Test Patterns Not Applicable to Actions**\n1. Actions trigger on lifecycle events, not config reapplication\n2. Before/After Destroy Tests: Not supported in Terraform 1.14.0\n\n### Running Tests\n\nCompile test to check for errors:\n```bash\ngo test -c -o /dev/null ./internal/service/<service>\n```\n\nRun specific action tests:\n```bash\nTF_ACC=1 go test ./internal/service/<service> -run TestAccServiceAction_ -v\n```\n\nRun sweep to clean up test resources:\n```bash\nTF_ACC=1 go test ./internal/service/<service> -sweep=<region> -v\n```\n\n## Documentation Standards\n\nEach action documentation file must include:\n\n1. **Front Matter**\n   ```yaml\n   ---\n   subcategory: \"Service Name\"\n   layout: \"provider\"\n   page_title: \"Provider: provider_service_action\"\n   description: |-\n     Brief description of what the action does.\n   ---\n   ```\n\n2. **Header with Warnings**\n   - Beta/Alpha notice about experimental status\n   - Warning about potential unintended consequences\n   - Link to provider documentation\n\n3. **Example Usage**\n   - Basic usage example\n   - Advanced usage with all options\n   - Trigger-based example with `terraform_data`\n   - Real-world use case examples\n\n4. **Argument Reference**\n   - List all required and optional arguments\n   - Include descriptions and defaults\n   - Note any validation rules\n\n5. **Documentation Linting**\n   - Run `terrafmt fmt` before submission\n   - Verify with `terrafmt diff`\n\n## Changelog Entry Format\n\nCreate a changelog entry in `.changelog/` directory:\n\n```\n.changelog/<pr_number_or_description>.txt\n```\n\nContent format:\n```release-note:new-action\naction/provider_service_action: Brief description of the action\n```\n\n## Pre-Submission Checklist\n\nBefore submitting your action implementation:\n\n- [ ] Code compiles: `go build -o /dev/null .`\n- [ ] Tests compile: `go test -c -o /dev/null ./internal/service/<service>`\n- [ ] Code formatted: `make fmt`\n- [ ] Documentation formatted: `terrafmt fmt website/docs/actions/<action>.html.markdown`\n- [ ] Changelog entry created\n- [ ] Schema uses correct types\n- [ ] All List/Map attributes have ElementType\n- [ ] Progress updates implemented for long operations\n- [ ] Error messages include context and resource identifiers\n- [ ] Documentation includes multiple examples\n- [ ] Documentation includes prerequisites and warnings\n\n## References\n\n- [Terraform Plugin Framework Documentation](https://developer.hashicorp.com/terraform/plugin/framework)\n- [Terraform Provider Development](https://developer.hashicorp.com/terraform/plugin)\n- [terraform-plugin-framework GitHub](https://github.com/hashicorp/terraform-plugin-framework)\n- [terraform-plugin-testing](https://github.com/hashicorp/terraform-plugin-testing)\n",
        "terraform/provider-development/skills/provider-resources/SKILL.md": "---\nname: provider-resources\ndescription: Implement Terraform Provider resources and data sources using the Plugin Framework. Use when developing CRUD operations, schema design, state management, and acceptance testing for provider resources.\nmetadata:\n  copyright: Copyright IBM Corp. 2026\n  version: \"0.0.1\"\n---\n\n# Terraform Provider Resources Implementation Guide\n\n## Overview\n\nThis guide covers developing Terraform Provider resources and data sources using the Terraform Plugin Framework. Resources represent infrastructure objects that Terraform manages through Create, Read, Update, and Delete (CRUD) operations.\n\n**References:**\n- [Terraform Plugin Framework](https://developer.hashicorp.com/terraform/plugin/framework)\n- [Resource Development](https://developer.hashicorp.com/terraform/plugin/framework/resources)\n- [Data Source Development](https://developer.hashicorp.com/terraform/plugin/framework/data-sources)\n\n## File Structure\n\nResources follow the standard service package structure:\n\n```\ninternal/service/<service>/\nâ”œâ”€â”€ <resource_name>.go           # Resource implementation\nâ”œâ”€â”€ <resource_name>_test.go      # Acceptance tests\nâ”œâ”€â”€ <resource_name>_data_source.go    # Data source (if applicable)\nâ”œâ”€â”€ find.go                      # Finder functions\nâ”œâ”€â”€ exports_test.go              # Test exports\nâ””â”€â”€ service_package_gen.go       # Auto-generated registration\n```\n\nDocumentation structure:\n```\nwebsite/docs/r/\nâ””â”€â”€ <service>_<resource_name>.html.markdown  # Resource documentation\n\nwebsite/docs/d/\nâ””â”€â”€ <service>_<resource_name>.html.markdown  # Data source documentation\n```\n\n## Resource Structure\n\n### SDKv2 Resource Pattern\n\n```go\nfunc ResourceExample() *schema.Resource {\n    return &schema.Resource{\n        CreateWithoutTimeout: resourceExampleCreate,\n        ReadWithoutTimeout:   resourceExampleRead,\n        UpdateWithoutTimeout: resourceExampleUpdate,\n        DeleteWithoutTimeout: resourceExampleDelete,\n\n        Importer: &schema.ResourceImporter{\n            StateContext: schema.ImportStatePassthroughContext,\n        },\n\n        Schema: map[string]*schema.Schema{\n            \"name\": {\n                Type:         schema.TypeString,\n                Required:     true,\n                ForceNew:     true,\n                ValidateFunc: validation.StringLenBetween(1, 255),\n            },\n            \"arn\": {\n                Type:     schema.TypeString,\n                Computed: true,\n            },\n            \"tags\":     tftags.TagsSchema(),\n            \"tags_all\": tftags.TagsSchemaComputed(),\n        },\n\n        CustomizeDiff: verify.SetTagsDiff,\n    }\n}\n```\n\n### Plugin Framework Resource Pattern\n\n```go\ntype resourceExample struct {\n    framework.ResourceWithConfigure\n}\n\nfunc (r *resourceExample) Metadata(_ context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {\n    resp.TypeName = req.ProviderTypeName + \"_example\"\n}\n\nfunc (r *resourceExample) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {\n    resp.Schema = schema.Schema{\n        Attributes: map[string]schema.Attribute{\n            \"id\": framework.IDAttribute(),\n            \"name\": schema.StringAttribute{\n                Required: true,\n                PlanModifiers: []planmodifier.String{\n                    stringplanmodifier.RequiresReplace(),\n                },\n                Validators: []validator.String{\n                    stringvalidator.LengthBetween(1, 255),\n                },\n            },\n            \"arn\": schema.StringAttribute{\n                Computed: true,\n                PlanModifiers: []planmodifier.String{\n                    stringplanmodifier.UseStateForUnknown(),\n                },\n            },\n        },\n    }\n}\n```\n\n## CRUD Operations\n\n### Create Operation\n\n```go\nfunc (r *resourceExample) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {\n    var data resourceExampleModel\n    resp.Diagnostics.Append(req.Plan.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().ExampleClient(ctx)\n\n    input := &example.CreateExampleInput{\n        Name: data.Name.ValueStringPointer(),\n    }\n\n    output, err := conn.CreateExample(ctx, input)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error creating Example\",\n            fmt.Sprintf(\"Could not create example %s: %s\", data.Name.ValueString(), err),\n        )\n        return\n    }\n\n    data.ID = types.StringPointerValue(output.Id)\n    data.ARN = types.StringPointerValue(output.Arn)\n\n    resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)\n}\n```\n\n### Read Operation\n\n```go\nfunc (r *resourceExample) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {\n    var data resourceExampleModel\n    resp.Diagnostics.Append(req.State.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().ExampleClient(ctx)\n\n    output, err := findExampleByID(ctx, conn, data.ID.ValueString())\n    if tfresource.NotFound(err) {\n        resp.Diagnostics.AddWarning(\n            \"Resource not found\",\n            fmt.Sprintf(\"Example %s not found, removing from state\", data.ID.ValueString()),\n        )\n        resp.State.RemoveResource(ctx)\n        return\n    }\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error reading Example\",\n            fmt.Sprintf(\"Could not read example %s: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n\n    data.Name = types.StringPointerValue(output.Name)\n    data.ARN = types.StringPointerValue(output.Arn)\n\n    resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)\n}\n```\n\n### Update Operation\n\n```go\nfunc (r *resourceExample) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {\n    var plan, state resourceExampleModel\n    resp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)\n    resp.Diagnostics.Append(req.State.Get(ctx, &state)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().ExampleClient(ctx)\n\n    if !plan.Description.Equal(state.Description) {\n        input := &example.UpdateExampleInput{\n            Id:          plan.ID.ValueStringPointer(),\n            Description: plan.Description.ValueStringPointer(),\n        }\n\n        _, err := conn.UpdateExample(ctx, input)\n        if err != nil {\n            resp.Diagnostics.AddError(\n                \"Error updating Example\",\n                fmt.Sprintf(\"Could not update example %s: %s\", plan.ID.ValueString(), err),\n            )\n            return\n        }\n    }\n\n    resp.Diagnostics.Append(resp.State.Set(ctx, &plan)...)\n}\n```\n\n### Delete Operation\n\n```go\nfunc (r *resourceExample) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {\n    var data resourceExampleModel\n    resp.Diagnostics.Append(req.State.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().ExampleClient(ctx)\n\n    _, err := conn.DeleteExample(ctx, &example.DeleteExampleInput{\n        Id: data.ID.ValueStringPointer(),\n    })\n\n    if tfresource.NotFound(err) {\n        return\n    }\n\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error deleting Example\",\n            fmt.Sprintf(\"Could not delete example %s: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n}\n```\n\n## Schema Design\n\n### Attribute Types\n\n| Terraform Type | Framework Type | Use Case |\n|----------------|----------------|----------|\n| `string` | `schema.StringAttribute` | Names, ARNs, IDs |\n| `number` | `schema.Int64Attribute`, `schema.Float64Attribute` | Counts, sizes |\n| `bool` | `schema.BoolAttribute` | Feature flags |\n| `list` | `schema.ListAttribute` | Ordered collections |\n| `set` | `schema.SetAttribute` | Unordered unique items |\n| `map` | `schema.MapAttribute` | Key-value pairs |\n| `object` | `schema.SingleNestedAttribute` | Complex nested config |\n\n### Plan Modifiers\n\n```go\n// Force replacement when value changes\nstringplanmodifier.RequiresReplace()\n\n// Preserve unknown value during plan\nstringplanmodifier.UseStateForUnknown()\n\n// Custom plan modifier\nstringplanmodifier.RequiresReplaceIf(\n    func(ctx context.Context, req planmodifier.StringRequest, resp *stringplanmodifier.RequiresReplaceIfFuncResponse) {\n        // Custom logic\n    },\n    \"description\",\n    \"markdown description\",\n)\n```\n\n### Validators\n\n```go\n// String validators\nstringvalidator.LengthBetween(1, 255)\nstringvalidator.RegexMatches(regexp.MustCompile(`^[a-z0-9-]+$`), \"must be lowercase alphanumeric with hyphens\")\nstringvalidator.OneOf(\"option1\", \"option2\", \"option3\")\n\n// Int64 validators\nint64validator.Between(1, 100)\nint64validator.AtLeast(1)\nint64validator.AtMost(1000)\n\n// List validators\nlistvalidator.SizeAtLeast(1)\nlistvalidator.SizeAtMost(10)\n```\n\n### Sensitive Attributes\n\n```go\n\"password\": schema.StringAttribute{\n    Required:  true,\n    Sensitive: true,\n    Validators: []validator.String{\n        stringvalidator.LengthAtLeast(8),\n    },\n}\n```\n\n## State Management\n\n### Handling Resource Not Found\n\n```go\nfunc findExampleByID(ctx context.Context, conn *example.Client, id string) (*example.Example, error) {\n    input := &example.GetExampleInput{\n        Id: &id,\n    }\n\n    output, err := conn.GetExample(ctx, input)\n    if err != nil {\n        var notFound *types.ResourceNotFoundException\n        if errors.As(err, &notFound) {\n            return nil, &retry.NotFoundError{\n                LastError:   err,\n                LastRequest: input,\n            }\n        }\n        return nil, err\n    }\n\n    if output == nil || output.Example == nil {\n        return nil, tfresource.NewEmptyResultError(input)\n    }\n\n    return output.Example, nil\n}\n```\n\n### Waiting for Resource States\n\n```go\nfunc waitExampleCreated(ctx context.Context, conn *example.Client, id string, timeout time.Duration) (*example.Example, error) {\n    stateConf := &retry.StateChangeConf{\n        Pending: []string{\"CREATING\", \"PENDING\"},\n        Target:  []string{\"ACTIVE\", \"AVAILABLE\"},\n        Refresh: statusExample(ctx, conn, id),\n        Timeout: timeout,\n    }\n\n    outputRaw, err := stateConf.WaitForStateContext(ctx)\n    if output, ok := outputRaw.(*example.Example); ok {\n        return output, err\n    }\n\n    return nil, err\n}\n\nfunc statusExample(ctx context.Context, conn *example.Client, id string) retry.StateRefreshFunc {\n    return func() (interface{}, string, error) {\n        output, err := findExampleByID(ctx, conn, id)\n        if tfresource.NotFound(err) {\n            return nil, \"\", nil\n        }\n        if err != nil {\n            return nil, \"\", err\n        }\n        return output, string(output.Status), nil\n    }\n}\n```\n\n## Testing\n\n### Basic Acceptance Test\n\n```go\nfunc TestAccExampleResource_basic(t *testing.T) {\n    ctx := acctest.Context(t)\n    rName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n    resourceName := \"provider_example.test\"\n\n    resource.ParallelTest(t, resource.TestCase{\n        PreCheck:                 func() { acctest.PreCheck(ctx, t) },\n        ProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n        CheckDestroy:             testAccCheckExampleDestroy(ctx),\n        Steps: []resource.TestStep{\n            {\n                Config: testAccExampleConfig_basic(rName),\n                Check: resource.ComposeTestCheckFunc(\n                    testAccCheckExampleExists(ctx, resourceName),\n                    resource.TestCheckResourceAttr(resourceName, \"name\", rName),\n                    resource.TestCheckResourceAttrSet(resourceName, \"arn\"),\n                ),\n            },\n            {\n                ResourceName:      resourceName,\n                ImportState:       true,\n                ImportStateVerify: true,\n            },\n        },\n    })\n}\n```\n\n### Disappears Test\n\n```go\nfunc TestAccExampleResource_disappears(t *testing.T) {\n    ctx := acctest.Context(t)\n    rName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n    resourceName := \"provider_example.test\"\n\n    resource.ParallelTest(t, resource.TestCase{\n        PreCheck:                 func() { acctest.PreCheck(ctx, t) },\n        ProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n        CheckDestroy:             testAccCheckExampleDestroy(ctx),\n        Steps: []resource.TestStep{\n            {\n                Config: testAccExampleConfig_basic(rName),\n                Check: resource.ComposeTestCheckFunc(\n                    testAccCheckExampleExists(ctx, resourceName),\n                    acctest.CheckResourceDisappears(ctx, acctest.Provider, ResourceExample(), resourceName),\n                ),\n                ExpectNonEmptyPlan: true,\n            },\n        },\n    })\n}\n```\n\n### Test Helper Functions\n\n```go\nfunc testAccCheckExampleExists(ctx context.Context, name string) resource.TestCheckFunc {\n    return func(s *terraform.State) error {\n        rs, ok := s.RootModule().Resources[name]\n        if !ok {\n            return fmt.Errorf(\"Not found: %s\", name)\n        }\n\n        conn := acctest.Provider.Meta().(*conns.Client).ExampleClient(ctx)\n        _, err := findExampleByID(ctx, conn, rs.Primary.ID)\n\n        return err\n    }\n}\n\nfunc testAccCheckExampleDestroy(ctx context.Context) resource.TestCheckFunc {\n    return func(s *terraform.State) error {\n        conn := acctest.Provider.Meta().(*conns.Client).ExampleClient(ctx)\n\n        for _, rs := range s.RootModule().Resources {\n            if rs.Type != \"provider_example\" {\n                continue\n            }\n\n            _, err := findExampleByID(ctx, conn, rs.Primary.ID)\n            if tfresource.NotFound(err) {\n                continue\n            }\n            if err != nil {\n                return err\n            }\n\n            return fmt.Errorf(\"Example %s still exists\", rs.Primary.ID)\n        }\n\n        return nil\n    }\n}\n```\n\n### Running Tests\n\n```bash\n# Compile tests\ngo test -c -o /dev/null ./internal/service/<service>\n\n# Run acceptance tests\nTF_ACC=1 go test ./internal/service/<service> -run TestAccExample -v -timeout 60m\n\n# Run with specific provider version\nTF_ACC=1 go test ./internal/service/<service> -run TestAccExample -v\n\n# Run sweeper to clean up\nTF_ACC=1 go test ./internal/service/<service> -sweep=<region> -v\n```\n\n## Error Handling\n\n### Common Error Patterns\n\n```go\n// Handle specific API errors\nvar notFound *types.ResourceNotFoundException\nif errors.As(err, &notFound) {\n    // Resource doesn't exist\n}\n\nvar conflict *types.ConflictException\nif errors.As(err, &conflict) {\n    // Resource state conflict\n}\n\nvar throttle *types.ThrottlingException\nif errors.As(err, &throttle) {\n    // Rate limited - SDK handles retry\n}\n```\n\n### Diagnostics\n\n```go\n// Add error\nresp.Diagnostics.AddError(\n    \"Error creating resource\",\n    fmt.Sprintf(\"Could not create resource: %s\", err),\n)\n\n// Add warning\nresp.Diagnostics.AddWarning(\n    \"Resource modified outside Terraform\",\n    \"Resource was modified outside of Terraform, state may be inconsistent\",\n)\n\n// Add attribute error\nresp.Diagnostics.AddAttributeError(\n    path.Root(\"name\"),\n    \"Invalid name\",\n    \"Name must be lowercase alphanumeric\",\n)\n```\n\n## Documentation Standards\n\n### Resource Documentation\n\n```markdown\n---\nsubcategory: \"Service Name\"\nlayout: \"provider\"\npage_title: \"Provider: provider_example\"\ndescription: |-\n  Manages an Example resource.\n---\n\n# Resource: provider_example\n\nManages an Example resource.\n\n## Example Usage\n\n### Basic Usage\n\n\\```hcl\nresource \"provider_example\" \"example\" {\n  name = \"my-example\"\n}\n\\```\n\n## Argument Reference\n\n* `name` - (Required) Name of the example.\n* `description` - (Optional) Description of the example.\n\n## Attribute Reference\n\n* `id` - ID of the example.\n* `arn` - ARN of the example.\n\n## Import\n\nExample can be imported using the ID:\n\n\\```\n$ terraform import provider_example.example example-id-12345\n\\```\n```\n\n## Pre-Submission Checklist\n\n- [ ] Code compiles without errors\n- [ ] All tests pass locally\n- [ ] Resource has all CRUD operations implemented\n- [ ] Import is implemented and tested\n- [ ] Disappears test is included\n- [ ] Documentation is complete with examples\n- [ ] Error messages are clear and actionable\n- [ ] Sensitive attributes are marked\n- [ ] Plan modifiers are appropriate\n- [ ] Validators cover edge cases\n\n## References\n\n- [Terraform Plugin Framework](https://developer.hashicorp.com/terraform/plugin/framework)\n- [Terraform Plugin SDKv2](https://developer.hashicorp.com/terraform/plugin/sdkv2)\n- [Acceptance Testing](https://developer.hashicorp.com/terraform/plugin/testing/acceptance-tests)\n- [terraform-plugin-framework GitHub](https://github.com/hashicorp/terraform-plugin-framework)\n",
        "terraform/provider-development/skills/run-acceptance-tests/SKILL.md": "---\nname: run-acceptance-tests\ndescription: Guide for running acceptance tests for a Terraform provider. Use this when asked to run an acceptance test or to run a test with the prefix `TestAcc`.\nlicense: MPL-2.0\nmetadata:\n  copyright: Copyright IBM Corp. 2026\n  version: \"0.0.1\"\n---\n\nAn acceptance test is a Go test function with the prefix `TestAcc`.\n\nTo run a focussed acceptance test named `TestAccFeatureHappyPath`:\n\n1. Run `go test -run=TestAccFeatureHappyPath` with the following environment\n   variables:\n   - `TF_ACC=1`\n   \n   Default to non-verbose test output.\n1. The acceptance tests may require additional environment variables for\n   specific providers. If the test output indicates missing environment\n   variables, then suggest how to set up these environment variables securely.\n\nTo diagnose a failing acceptance test, use these options, in order. These\noptions are cumulative: each option includes all the options above it.\n\n1. Run the test again. Use the `-count=1` option to ensure that `go test` does\n   not use a cached result.\n1. Offer verbose `go test` output. Use the `-v` option.\n1. Offer debug-level logging. Enable debug-level logging with the environment\n   variable `TF_LOG=debug`.\n1. Offer to persist the acceptance test's Terraform workspace. Enable\n   persistance with the environment variable `TF_ACC_WORKING_DIR_PERSIST=1`.\n\nA passing acceptance test may be a false negative. To \"flip\" a passing\nacceptance test named `TestAccFeatureHappyPath`:\n\n1. Edit the value of one of the TestCheckFuncs in one of the TestSteps in the\n   TestCase.\n1. Run the acceptance test. Expect the test to fail.\n1. If the test fails, then undo the edit and report a successful flip. Else,\n   keep the edit and report an unsuccessful flip.\n"
      },
      "plugins": [
        {
          "name": "terraform-code-generation",
          "source": "./terraform/code-generation",
          "description": "Terraform code generation skills including HCL generation, style guides, and testing.",
          "version": "1.0.0",
          "author": {
            "name": "HashiCorp"
          },
          "keywords": [
            "terraform",
            "hcl",
            "infrastructure",
            "iac",
            "testing",
            "style-guide"
          ],
          "category": "integration",
          "license": "MPL-2.0",
          "strict": false,
          "categories": [
            "hcl",
            "iac",
            "infrastructure",
            "integration",
            "style-guide",
            "terraform",
            "testing"
          ],
          "install_commands": [
            "/plugin marketplace add hashicorp/agent-skills",
            "/plugin install terraform-code-generation@hashicorp"
          ]
        },
        {
          "name": "terraform-module-generation",
          "source": "./terraform/module-generation",
          "description": "Terraform module generation and refactoring skills including module design and Terraform Stacks.",
          "version": "1.0.0",
          "author": {
            "name": "HashiCorp"
          },
          "keywords": [
            "terraform",
            "modules",
            "infrastructure",
            "iac",
            "stacks",
            "refactoring"
          ],
          "category": "integration",
          "license": "MPL-2.0",
          "strict": false,
          "categories": [
            "iac",
            "infrastructure",
            "integration",
            "modules",
            "refactoring",
            "stacks",
            "terraform"
          ],
          "install_commands": [
            "/plugin marketplace add hashicorp/agent-skills",
            "/plugin install terraform-module-generation@hashicorp"
          ]
        },
        {
          "name": "terraform-provider-development",
          "source": "./terraform/provider-development",
          "description": "Terraform provider development skills including resources, data sources, actions, and acceptance testing.",
          "version": "1.0.0",
          "author": {
            "name": "HashiCorp"
          },
          "keywords": [
            "terraform",
            "provider",
            "plugin-framework",
            "resources",
            "testing"
          ],
          "category": "integration",
          "license": "MPL-2.0",
          "strict": false,
          "categories": [
            "integration",
            "plugin-framework",
            "provider",
            "resources",
            "terraform",
            "testing"
          ],
          "install_commands": [
            "/plugin marketplace add hashicorp/agent-skills",
            "/plugin install terraform-provider-development@hashicorp"
          ]
        },
        {
          "name": "packer-builders",
          "source": "./packer/builders",
          "description": "Packer builder skills for AWS, Azure, and Windows image creation.",
          "version": "1.0.0",
          "author": {
            "name": "HashiCorp"
          },
          "keywords": [
            "packer",
            "aws",
            "azure",
            "windows",
            "ami",
            "image",
            "builder"
          ],
          "category": "integration",
          "license": "MPL-2.0",
          "strict": false,
          "categories": [
            "ami",
            "aws",
            "azure",
            "builder",
            "image",
            "integration",
            "packer",
            "windows"
          ],
          "install_commands": [
            "/plugin marketplace add hashicorp/agent-skills",
            "/plugin install packer-builders@hashicorp"
          ]
        },
        {
          "name": "packer-hcp",
          "source": "./packer/hcp",
          "description": "HCP Packer registry integration for tracking and managing image metadata.",
          "version": "1.0.0",
          "author": {
            "name": "HashiCorp"
          },
          "keywords": [
            "packer",
            "hcp-packer",
            "registry",
            "metadata",
            "image-tracking"
          ],
          "category": "integration",
          "license": "MPL-2.0",
          "strict": false,
          "categories": [
            "hcp-packer",
            "image-tracking",
            "integration",
            "metadata",
            "packer",
            "registry"
          ],
          "install_commands": [
            "/plugin marketplace add hashicorp/agent-skills",
            "/plugin install packer-hcp@hashicorp"
          ]
        }
      ]
    }
  ]
}