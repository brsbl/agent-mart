{
  "author": {
    "id": "leobrival",
    "display_name": "LÃ©o Brival",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/29938311?u=af40911d454efe0c17b998d28cc50385077e3f1b&v=4",
    "url": "https://github.com/leobrival",
    "bio": "Product Owner & Web Maker - The cornerstone between your devs, designers and customers ðŸ—¿",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 3,
      "total_commands": 8,
      "total_skills": 15,
      "total_stars": 0,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "topographic-plugins-official",
      "version": "1.0.0",
      "description": "Official Topographic plugins for Claude Code - development CLI, GitHub workflows, and product design",
      "owner_info": {
        "name": "Leo Brival",
        "email": "leo.brival@gmail.com"
      },
      "keywords": [],
      "repo_full_name": "leobrival/topographic-plugins-official",
      "repo_url": "https://github.com/leobrival/topographic-plugins-official",
      "repo_description": "Topographic Studio plugins for Claude Code",
      "homepage": null,
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-01-26T13:31:26Z",
        "created_at": "2025-12-25T13:59:09Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 1493
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 872
        },
        {
          "path": "plugins/dev/README.md",
          "type": "blob",
          "size": 2567
        },
        {
          "path": "plugins/dev/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/commands/clean-gone.md",
          "type": "blob",
          "size": 1214
        },
        {
          "path": "plugins/dev/commands/commit-push-pr.md",
          "type": "blob",
          "size": 1342
        },
        {
          "path": "plugins/dev/commands/commit.md",
          "type": "blob",
          "size": 1939
        },
        {
          "path": "plugins/dev/commands/create-worktree.md",
          "type": "blob",
          "size": 4106
        },
        {
          "path": "plugins/dev/commands/debug.md",
          "type": "blob",
          "size": 3575
        },
        {
          "path": "plugins/dev/commands/fix-pr-comments.md",
          "type": "blob",
          "size": 2144
        },
        {
          "path": "plugins/dev/commands/merge-to-main.md",
          "type": "blob",
          "size": 4271
        },
        {
          "path": "plugins/dev/commands/run-task.md",
          "type": "blob",
          "size": 2965
        },
        {
          "path": "plugins/dev/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/scripts/worktree-manager",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/scripts/worktree-manager/README.md",
          "type": "blob",
          "size": 14834
        },
        {
          "path": "plugins/dev/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/adonisjs-cli",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/adonisjs-cli/SKILL.md",
          "type": "blob",
          "size": 8906
        },
        {
          "path": "plugins/dev/skills/adonisjs-cli/reference",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/adonisjs-cli/reference/commands-reference.md",
          "type": "blob",
          "size": 11106
        },
        {
          "path": "plugins/dev/skills/adonisjs-cli/reference/common-patterns.md",
          "type": "blob",
          "size": 14585
        },
        {
          "path": "plugins/dev/skills/adonisjs-cli/reference/troubleshooting.md",
          "type": "blob",
          "size": 13025
        },
        {
          "path": "plugins/dev/skills/convex-cli",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/convex-cli/SKILL.md",
          "type": "blob",
          "size": 6668
        },
        {
          "path": "plugins/dev/skills/convex-cli/reference",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/convex-cli/reference/commands-reference.md",
          "type": "blob",
          "size": 6398
        },
        {
          "path": "plugins/dev/skills/convex-cli/reference/common-patterns.md",
          "type": "blob",
          "size": 7594
        },
        {
          "path": "plugins/dev/skills/convex-cli/reference/troubleshooting.md",
          "type": "blob",
          "size": 11006
        },
        {
          "path": "plugins/dev/skills/coolify-api",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/coolify-api/SKILL.md",
          "type": "blob",
          "size": 11365
        },
        {
          "path": "plugins/dev/skills/coolify-api/reference",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/coolify-api/reference/api-reference.md",
          "type": "blob",
          "size": 16033
        },
        {
          "path": "plugins/dev/skills/coolify-api/reference/common-patterns.md",
          "type": "blob",
          "size": 17351
        },
        {
          "path": "plugins/dev/skills/coolify-api/reference/troubleshooting.md",
          "type": "blob",
          "size": 17028
        },
        {
          "path": "plugins/dev/skills/docker-cli",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/docker-cli/SKILL.md",
          "type": "blob",
          "size": 6835
        },
        {
          "path": "plugins/dev/skills/docker-cli/reference",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/docker-cli/reference/commands-reference.md",
          "type": "blob",
          "size": 10118
        },
        {
          "path": "plugins/dev/skills/docker-cli/reference/common-patterns.md",
          "type": "blob",
          "size": 6650
        },
        {
          "path": "plugins/dev/skills/docker-cli/reference/troubleshooting.md",
          "type": "blob",
          "size": 9792
        },
        {
          "path": "plugins/dev/skills/github-cli",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/github-cli/SKILL.md",
          "type": "blob",
          "size": 6497
        },
        {
          "path": "plugins/dev/skills/github-cli/reference",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/github-cli/reference/commands-reference.md",
          "type": "blob",
          "size": 10610
        },
        {
          "path": "plugins/dev/skills/github-cli/reference/common-patterns.md",
          "type": "blob",
          "size": 9845
        },
        {
          "path": "plugins/dev/skills/github-cli/reference/troubleshooting.md",
          "type": "blob",
          "size": 11059
        },
        {
          "path": "plugins/dev/skills/lighthouse-cli",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/lighthouse-cli/SKILL.md",
          "type": "blob",
          "size": 6919
        },
        {
          "path": "plugins/dev/skills/lighthouse-cli/reference",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/lighthouse-cli/reference/commands-reference.md",
          "type": "blob",
          "size": 7372
        },
        {
          "path": "plugins/dev/skills/lighthouse-cli/reference/common-patterns.md",
          "type": "blob",
          "size": 8952
        },
        {
          "path": "plugins/dev/skills/lighthouse-cli/reference/troubleshooting.md",
          "type": "blob",
          "size": 11183
        },
        {
          "path": "plugins/dev/skills/neon-cli",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/neon-cli/SKILL.md",
          "type": "blob",
          "size": 8152
        },
        {
          "path": "plugins/dev/skills/neon-cli/reference",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/neon-cli/reference/commands-reference.md",
          "type": "blob",
          "size": 5946
        },
        {
          "path": "plugins/dev/skills/neon-cli/reference/common-patterns.md",
          "type": "blob",
          "size": 6881
        },
        {
          "path": "plugins/dev/skills/neon-cli/reference/troubleshooting.md",
          "type": "blob",
          "size": 10764
        },
        {
          "path": "plugins/dev/skills/nextjs-cli",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/nextjs-cli/SKILL.md",
          "type": "blob",
          "size": 8056
        },
        {
          "path": "plugins/dev/skills/nextjs-cli/reference",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/nextjs-cli/reference/commands-reference.md",
          "type": "blob",
          "size": 7503
        },
        {
          "path": "plugins/dev/skills/nextjs-cli/reference/common-patterns.md",
          "type": "blob",
          "size": 10228
        },
        {
          "path": "plugins/dev/skills/nextjs-cli/reference/troubleshooting.md",
          "type": "blob",
          "size": 10729
        },
        {
          "path": "plugins/dev/skills/playwright-cli",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/playwright-cli/SKILL.md",
          "type": "blob",
          "size": 7428
        },
        {
          "path": "plugins/dev/skills/playwright-cli/reference",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/playwright-cli/reference/commands-reference.md",
          "type": "blob",
          "size": 7024
        },
        {
          "path": "plugins/dev/skills/playwright-cli/reference/common-patterns.md",
          "type": "blob",
          "size": 9170
        },
        {
          "path": "plugins/dev/skills/playwright-cli/reference/troubleshooting.md",
          "type": "blob",
          "size": 11390
        },
        {
          "path": "plugins/dev/skills/railway-cli",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/railway-cli/SKILL.md",
          "type": "blob",
          "size": 6730
        },
        {
          "path": "plugins/dev/skills/railway-cli/reference",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/railway-cli/reference/commands-reference.md",
          "type": "blob",
          "size": 7608
        },
        {
          "path": "plugins/dev/skills/railway-cli/reference/common-patterns.md",
          "type": "blob",
          "size": 8682
        },
        {
          "path": "plugins/dev/skills/railway-cli/reference/troubleshooting.md",
          "type": "blob",
          "size": 12947
        },
        {
          "path": "plugins/dev/skills/raycast-cli",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/raycast-cli/SKILL.md",
          "type": "blob",
          "size": 7678
        },
        {
          "path": "plugins/dev/skills/raycast-cli/reference",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/raycast-cli/reference/commands-reference.md",
          "type": "blob",
          "size": 11295
        },
        {
          "path": "plugins/dev/skills/raycast-cli/reference/common-patterns.md",
          "type": "blob",
          "size": 17058
        },
        {
          "path": "plugins/dev/skills/raycast-cli/reference/troubleshooting.md",
          "type": "blob",
          "size": 17640
        },
        {
          "path": "plugins/dev/skills/spec-kit",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/spec-kit/SKILL.md",
          "type": "blob",
          "size": 7729
        },
        {
          "path": "plugins/dev/skills/spec-kit/reference",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/spec-kit/reference/constitutional-articles.md",
          "type": "blob",
          "size": 12157
        },
        {
          "path": "plugins/dev/skills/spec-kit/reference/workflow-guide.md",
          "type": "blob",
          "size": 10588
        },
        {
          "path": "plugins/dev/skills/vercel-cli",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/vercel-cli/SKILL.md",
          "type": "blob",
          "size": 5961
        },
        {
          "path": "plugins/dev/skills/vercel-cli/reference",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev/skills/vercel-cli/reference/commands-reference.md",
          "type": "blob",
          "size": 6747
        },
        {
          "path": "plugins/dev/skills/vercel-cli/reference/common-patterns.md",
          "type": "blob",
          "size": 6496
        },
        {
          "path": "plugins/dev/skills/vercel-cli/reference/troubleshooting.md",
          "type": "blob",
          "size": 10803
        },
        {
          "path": "plugins/product",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/product/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/product/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 425
        },
        {
          "path": "plugins/product/README.md",
          "type": "blob",
          "size": 1779
        },
        {
          "path": "plugins/product/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/product/agents/product-designer.md",
          "type": "blob",
          "size": 31213
        },
        {
          "path": "plugins/product/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/product/skills/user-personas",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/product/skills/user-personas/SKILL.md",
          "type": "blob",
          "size": 13076
        },
        {
          "path": "plugins/product/skills/user-personas/assets",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/product/skills/user-personas/assets/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/product/skills/user-personas/assets/templates/persona-card-template.md",
          "type": "blob",
          "size": 3552
        },
        {
          "path": "plugins/product/skills/user-personas/reference",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/product/skills/user-personas/reference/jtbd-framework.md",
          "type": "blob",
          "size": 8869
        },
        {
          "path": "plugins/web-crawler",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/web-crawler/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/web-crawler/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 344
        },
        {
          "path": "plugins/web-crawler/README.md",
          "type": "blob",
          "size": 865
        },
        {
          "path": "plugins/web-crawler/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/web-crawler/skills/web-crawler",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/web-crawler/skills/web-crawler/SKILL.md",
          "type": "blob",
          "size": 13462
        },
        {
          "path": "plugins/web-crawler/skills/web-crawler/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/web-crawler/skills/web-crawler/scripts/README.md",
          "type": "blob",
          "size": 1864
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"$schema\": \"../schemas/marketplace.schema.json\",\n  \"name\": \"topographic-plugins-official\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Official Topographic plugins for Claude Code - development CLI, GitHub workflows, and product design\",\n  \"owner\": {\n    \"name\": \"Leo Brival\",\n    \"email\": \"leo.brival@gmail.com\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"dev\",\n      \"description\": \"Development CLI skills and GitHub workflows - Docker, Vercel, Railway, Neon, deployment platforms, and automated Git/GitHub workflows for commits, PRs, worktrees, and branch management\",\n      \"version\": \"1.0.0\",\n      \"author\": {\n        \"name\": \"Leo Brival\",\n        \"email\": \"leo.brival@gmail.com\"\n      },\n      \"source\": \"./plugins/dev\",\n      \"category\": \"development\"\n    },\n    {\n      \"name\": \"product\",\n      \"description\": \"Product design and management tools for building user-centric products\",\n      \"version\": \"1.0.0\",\n      \"author\": {\n        \"name\": \"Leo Brival\",\n        \"email\": \"leo.brival@gmail.com\"\n      },\n      \"source\": \"./plugins/product\",\n      \"category\": \"development\"\n    },\n    {\n      \"name\": \"web-crawler\",\n      \"description\": \"High-performance Rust web crawler with stealth mode, LLM-ready Markdown export, multi-format output, sitemap discovery, and robots.txt support\",\n      \"version\": \"1.0.0\",\n      \"author\": {\n        \"name\": \"Leo Brival\",\n        \"email\": \"leo.brival@gmail.com\"\n      },\n      \"source\": \"./plugins/web-crawler\",\n      \"category\": \"tools\"\n    }\n  ]\n}\n",
        "plugins/dev/.claude-plugin/plugin.json": "{\n\t\"name\": \"dev\",\n\t\"version\": \"1.0.0\",\n\t\"description\": \"Development CLI skills and GitHub workflows - Docker, Vercel, Railway, Neon, deployment platforms, and automated Git/GitHub workflows. Use for deployment, containerization, database management, infrastructure operations, and collaborative development.\",\n\t\"skills\": [\n\t\t\"./skills/adonisjs-cli/SKILL.md\",\n\t\t\"./skills/convex-cli/SKILL.md\",\n\t\t\"./skills/coolify-api/SKILL.md\",\n\t\t\"./skills/docker-cli/SKILL.md\",\n\t\t\"./skills/github-cli/SKILL.md\",\n\t\t\"./skills/lighthouse-cli/SKILL.md\",\n\t\t\"./skills/neon-cli/SKILL.md\",\n\t\t\"./skills/nextjs-cli/SKILL.md\",\n\t\t\"./skills/playwright-cli/SKILL.md\",\n\t\t\"./skills/railway-cli/SKILL.md\",\n\t\t\"./skills/raycast-cli/SKILL.md\",\n\t\t\"./skills/spec-kit/SKILL.md\",\n\t\t\"./skills/vercel-cli/SKILL.md\"\n\t],\n\t\"author\": {\n\t\t\"name\": \"Leo Brival\",\n\t\t\"email\": \"leo.brival@gmail.com\"\n\t},\n\t\"license\": \"MIT\"\n}\n",
        "plugins/dev/README.md": "# Dev Plugin\n\nDevelopment CLI skills and GitHub workflows for popular tools and platforms.\n\n## Overview\n\nThis plugin provides comprehensive CLI reference skills for modern development tools, GitHub and Git workflows, and repository management. It combines development platform expertise with automated workflows for building, deploying, and collaborating on projects.\n\n## Available Skills & Commands\n\n### Deployment & Hosting\n\n- **vercel-cli** - Vercel CLI expert for serverless deployment\n- **railway-cli** - Railway CLI expert for application deployment\n- **coolify-api** - Coolify API expert for self-hosted PaaS management\n\n### Backend & Database\n\n- **adonisjs-cli** - AdonisJS Ace CLI expert for TypeScript backend applications\n- **convex-cli** - Convex CLI expert for serverless backend and real-time database\n- **neon-cli** - Neon CLI expert for serverless PostgreSQL management\n\n### Frontend & Frameworks\n\n- **nextjs-cli** - Next.js CLI expert for React application development\n\n### DevOps & Infrastructure\n\n- **docker-cli** - Docker CLI expert for containerization and orchestration\n- **github-cli** - GitHub CLI (gh) expert for repository and workflow management\n\n### Testing & Automation\n\n- **playwright-cli** - Playwright CLI expert for browser automation and testing\n- **lighthouse-cli** - Lighthouse CLI expert for web performance auditing\n\n### Tools & Extensions\n\n- **raycast-cli** - Raycast CLI expert for extension development\n\n## Available Commands\n\n### Git & GitHub Workflows\n\n- **commit** - Commitizen-format commit workflow with validation\n- **commit-push-pr** - Combined commit, push, and PR creation workflow\n- **create-worktree** - Automated git worktree creation with Claude CLI integration\n- **clean-gone** - Clean up deleted remote branches\n- **debug** - Project issue detection and fixing\n- **fix-pr-comments** - Automated PR comment resolution\n- **merge-to-main** - Automated merge with conflict resolution\n- **run-task** - Task execution workflow with GitHub issues\n\n## Usage\n\nSkills are automatically triggered when users request help with the corresponding CLI tool. Each skill provides comprehensive command references, best practices, and common usage examples.\n\nCommands are invoked via slash commands (e.g., `/commit`, `/create-worktree`) for automated workflows.\n\n## Scripts\n\n- **worktree-manager** - TypeScript-based worktree management tool with GitHub integration\n  - Configuration profiles (minimal, fast, full)\n  - Package manager detection\n  - Git bridge for branch operations\n  - Terminal launcher support\n\n## License\n\nMIT\n",
        "plugins/dev/commands/clean-gone.md": "---\ndescription: Clean up local branches that no longer exist on remote\nallowed-tools: Bash(git fetch:*), Bash(git branch:*), Bash(git for-each-ref:*)\n---\n\n## Context\n\n- Current branch: !`git branch --show-current`\n- Local branches: !`git branch`\n- Remote tracking status: !`git branch -vv`\n\n## Workflow\n\n1. **Fetch and prune remote**\n\n   ```bash\n   git fetch --prune\n   ```\n\n2. **Find gone branches**\n   List branches where upstream is gone:\n\n   ```bash\n   git for-each-ref --format '%(refname:short) %(upstream:track)' refs/heads | grep '\\[gone\\]'\n   ```\n\n3. **Delete gone branches**\n   For each branch marked as `[gone]`:\n\n   ```bash\n   git branch -d <branch-name>\n   ```\n\n   Use `-D` (force) only if `-d` fails and after confirming with user.\n\n4. **Report results**\n\n   ```\n   Cleaned up branches:\n   - feature/old-feature (deleted)\n   - fix/resolved-bug (deleted)\n\n   Remaining branches:\n   - main\n   - develop\n   - feature/current-work\n   ```\n\n## Usage Examples\n\n```bash\n# Clean up stale branches\n/clean-gone\n\n# After PR merges\n/clean-gone\n```\n\n## Notes\n\n- Only deletes fully merged branches by default\n- Preserves current branch\n- Fetches from remote first to get accurate status\n- Reports what was deleted\n",
        "plugins/dev/commands/commit-push-pr.md": "---\ndescription: Commit, push, and open a pull request in one command\nallowed-tools: Bash(git checkout:*), Bash(git add:*), Bash(git status:*), Bash(git push:*), Bash(git commit:*), Bash(git diff:*), Bash(git branch:*), Bash(git log:*), Bash(gh pr create:*)\n---\n\n## Context\n\n- Current git status: !`git status`\n- Current git diff (staged and unstaged changes): !`git diff HEAD`\n- Current branch: !`git branch --show-current`\n- Recent commits: !`git log --oneline -10`\n\n## Workflow\n\n1. **Check current branch**\n   - If on `main` or `master`, create a new branch first\n   - Branch name should be descriptive (e.g., `feat/add-feature`)\n\n2. **Stage all changes**\n\n   ```bash\n   git add .\n   ```\n\n3. **Create commit**\n   - Follow Commitizen convention\n   - Format: `type(scope): description`\n\n4. **Push to origin**\n\n   ```bash\n   git push -u origin <branch-name>\n   ```\n\n5. **Create Pull Request**\n\n   ```bash\n   gh pr create --title \"[Title]\" --body \"[Description]\"\n   ```\n\n   PR body should include:\n   - Summary of changes\n   - Testing done\n   - Related issues (if any)\n\n## Usage Examples\n\n```bash\n# Basic usage\n/commit-push-pr\n\n# After implementing a feature\n/commit-push-pr\n```\n\n## Notes\n\n- Creates new branch if on main/master\n- Commits with conventional commit format\n- Pushes and creates PR in one workflow\n- Uses `gh` CLI for PR creation\n",
        "plugins/dev/commands/commit.md": "---\ndescription: Create a git commit following Commitizen convention with validation and push\nallowed-tools: Bash(git add:*), Bash(git status:*), Bash(git commit:*), Bash(git diff:*), Bash(git push:*), Bash(git branch:*), Bash(git log:*), Bash(npm run *), Bash(pnpm *), Bash(yarn *), Bash(bun *)\nmodel: haiku\n---\n\n## Context\n\n- Current git status: !`git status`\n- Current git diff (staged and unstaged changes): !`git diff HEAD`\n- Current branch: !`git branch --show-current`\n- Recent commits: !`git log --oneline -10`\n\n## Workflow\n\n1. **Detect package manager**\n   - Check for `pnpm-lock.yaml` -> pnpm\n   - Check for `package-lock.json` -> npm\n   - Check for `yarn.lock` -> yarn\n   - Check for `bun.lockb` -> bun\n\n2. **Stage all changes**\n\n   ```bash\n   git add .\n   ```\n\n3. **Run validation** (use parallel subagents if available)\n   - `[package-manager] lint` (if exists in package.json)\n   - `[package-manager] typecheck` (if exists in package.json)\n   - `[package-manager] build` (if exists in package.json)\n\n   If any validation fails, stop and report errors.\n\n4. **Review staged diff**\n\n   ```bash\n   git diff --staged\n   ```\n\n5. **Create commit**\n   - Follow Commitizen convention\n   - Keep commit message simple and clear\n   - Format: `type(scope): description`\n\n   Types:\n   - `feat`: New feature\n   - `fix`: Bug fix\n   - `refactor`: Code refactoring\n   - `docs`: Documentation\n   - `test`: Tests\n   - `chore`: Maintenance\n\n   Examples:\n   - `feat: add user authentication`\n   - `fix: resolve memory leak in parser`\n   - `refactor: simplify validation logic`\n   - `docs: update API documentation`\n\n6. **Push to remote**\n\n   ```bash\n   git push\n   ```\n\n## Usage Examples\n\n```bash\n# Basic usage\n/commit\n\n# After making changes\n/commit\n```\n\n## Notes\n\n- All files are automatically staged\n- Validation runs before commit (lint, typecheck, build)\n- Commit message follows conventional commits\n- Automatically pushes to current branch\n",
        "plugins/dev/commands/create-worktree.md": "---\ndescription: Create a git worktree for a given issue with automated setup using Worktree Manager\nallowed-tools: Bash(bun *), Bash(gh *), Bash(cd *)\n---\n\nCreate isolated git worktree for feature development from GitHub issue using the intelligent Worktree Manager.\n\n## Setup\n\nThe Worktree Manager scripts are located in the plugin's `scripts/worktree-manager/` directory.\n\n**First-time setup** (if dependencies not installed):\n\n```bash\ncd <plugin-path>/scripts/worktree-manager && bun install\n```\n\n## Workflow\n\n1. **Parse argument**\n   - If $ARGUMENT is GitHub issue URL: Use directly\n   - If $ARGUMENT is issue number: Construct full GitHub URL from current repository\n   - Validate URL format: `https://github.com/owner/repo/issues/NUMBER`\n\n2. **Execute Worktree Manager**\n\n   ```bash\n   bun <plugin-path>/scripts/worktree-manager/src/index.ts <github-issue-url> [options]\n   ```\n\n   Where `<plugin-path>` is the absolute path to the github-commands plugin directory.\n\n   The Worktree Manager will automatically:\n   - Fetch issue details via `gh` CLI (title, body, labels, assignees)\n   - Generate intelligent branch name using Claude CLI (or fallback to simple generation)\n   - Create isolated worktree with new branch\n   - Copy all environment files (.env*)\n   - Detect and install dependencies (pnpm, npm, yarn, or bun)\n   - Open terminal (Hyper, iTerm2, Warp, or Terminal) with Claude in plan mode\n   - Save worktree metadata to history\n\n3. **Handle options**\n\n   Support additional options:\n   - `--terminal <app>`: Choose terminal app (Hyper, iTerm2, Warp, Terminal)\n   - `--no-deps`: Skip dependency installation\n   - `--no-terminal`: Don't open terminal automatically\n   - `--debug`: Enable debug logging\n   - `--branch <name>`: Override auto-generated branch name\n   - `--profile <name>`: Use configuration profile (minimal, fast, full)\n   - `--output <dir>`: Custom worktree base directory\n\n## Usage Examples\n\n```bash\n# From GitHub issue URL (recommended)\n/create-worktree https://github.com/user/repo/issues/123\n\n# With specific terminal app\n/create-worktree https://github.com/user/repo/issues/123 --terminal iTerm2\n\n# With options\n/create-worktree https://github.com/user/repo/issues/123 --no-deps --debug\n\n# Custom branch name\n/create-worktree https://github.com/user/repo/issues/123 --branch my-custom-feature\n\n# Skip terminal opening\n/create-worktree https://github.com/user/repo/issues/123 --no-terminal\n```\n\n## Branch Name Generation\n\nThe Worktree Manager uses intelligent branch name generation:\n\n1. **AI-Powered (Claude CLI)**:\n   - Analyzes issue title and description\n   - Generates contextual branch name\n   - Format: `issue-{number}-{description}`\n   - Max 50 characters, kebab-case\n\n2. **Fallback (Simple)**:\n   - Uses issue number and sanitized title\n   - Format: `issue-{number}-{sanitized-title}`\n\nExamples:\n- Issue #123 \"Add User Authentication\" -> `issue-123-add-user-authentication`\n- Issue #456 \"Fix: Memory Leak in API\" -> `issue-456-fix-memory-leak-in-api`\n\n## Additional Commands\n\n```bash\n# List all worktrees\nbun <plugin-path>/scripts/worktree-manager/src/index.ts list\n\n# Clean up old worktrees\nbun <plugin-path>/scripts/worktree-manager/src/index.ts clean\n\n# Force cleanup all worktrees\nbun <plugin-path>/scripts/worktree-manager/src/index.ts clean --force\n```\n\n## Error Handling\n\n- **Invalid GitHub URL**: Display format error and expected format\n- **Not a git repository**: Inform user to run from within a git repo\n- **GitHub CLI not authenticated**: Suggest running `gh auth login`\n- **Bun not installed**: Provide installation instructions\n- **Dependency installation failure**: Report which package manager failed\n\n## Notes\n\n- **Isolated Environments**: Each worktree has its own node_modules\n- **Smart Package Manager Detection**: Auto-detects pnpm, npm, yarn, or bun\n- **Environment Files**: All .env* files are copied recursively\n- **Terminal Integration**: Supports Hyper, iTerm2, Warp, Terminal.app\n- **History Tracking**: All worktrees are tracked in `.worktrees.json`\n- **Claude Integration**: Terminal opens with `/run-tasks` for the specific issue\n",
        "plugins/dev/commands/debug.md": "---\ndescription: Detect and fix all project issues - lint, typecheck, tests, build errors\nallowed-tools: Bash, Read, Write, Edit, Glob, Grep\n---\n\nComprehensive project health check: detect all validation commands, run them, fix issues, and verify fixes.\n\n## Workflow\n\n### 1. Detect Stack & Project Structure\n\nIdentify the project type and available tooling:\n\n**Check for:**\n- `package.json` - Node.js/TypeScript project\n- `requirements.txt` / `pyproject.toml` - Python project\n- `go.mod` - Go project\n- `Cargo.toml` - Rust project\n\n**Extract information:**\n- Package manager (npm, pnpm, yarn, pip, cargo, etc.)\n- Language version\n- Framework (Next.js, Express, FastAPI, etc.)\n- Testing framework\n- Linter configuration\n\n### 2. Discover Available Commands\n\n**Scan `package.json` scripts (Node.js/TypeScript):**\n\n```bash\ncat package.json | grep -E \"lint|typecheck|type-check|test|build|format|validate\"\n```\n\n**Common command patterns to detect:**\n- `lint` / `eslint` / `biome lint` - Linting\n- `typecheck` / `tsc --noEmit` - Type checking\n- `test` / `vitest` / `jest` - Unit tests\n- `build` - Production build\n- `format` / `prettier` - Code formatting\n\n### 3. Run All Validation Commands (Parallel)\n\nCreate a comprehensive validation report by running all discovered commands.\n\n**Use parallel subagents** to run:\n1. Linting (if available)\n2. Type checking (if available)\n3. Unit tests (if available)\n4. Build (if available)\n\n**For each command:**\n- Capture full output\n- Record exit code\n- Count errors/warnings\n- Extract file paths and line numbers from errors\n\n### 4. Analyze & Categorize Issues\n\nGroup issues by priority:\n\n1. **Critical** - Blocks build/deploy\n   - Build failures\n   - Type errors in critical paths\n   - Test failures\n\n2. **High Priority** - Code quality issues\n   - Linting errors (not warnings)\n   - Type errors in non-critical code\n\n3. **Medium Priority** - Maintainability\n   - Linting warnings\n   - Formatting issues\n\n### 5. Create Fix Plan\n\nPrioritize fixes:\n- Phase 1: Critical (blocks ship)\n- Phase 2: High Priority\n- Phase 3: Medium Priority (optional)\n\n### 6. Execute Fixes\n\n**Fix issues systematically:**\n\n1. **Read the problematic files first**\n2. **Apply fixes one category at a time**\n3. **Use appropriate strategies:**\n   - Type errors: Add missing type annotations, fix incorrect types\n   - Lint errors: Remove unused imports, fix naming conventions\n   - Build errors: Fix missing dependencies, resolve module issues\n   - Test failures: Update broken assertions, fix mock data\n\n4. **Auto-format after fixes:**\n   ```bash\n   pnpm format  # or prettier --write .\n   ```\n\n### 7. Verify Fixes (Re-run Validation)\n\nAfter applying fixes, re-run all validation commands with parallel subagents.\n\nCompare before/after results and report:\n- Issues fixed\n- Time taken\n- Remaining issues (if any)\n\n### 8. Summary Report\n\n```markdown\n# Debug Session Complete\n\n## Project Health: HEALTHY / NEEDS WORK / CRITICAL\n\n**Stack detected:** [Framework info]\n\n## Issues Fixed\n- [List of fixed issues]\n\n## Validation Results\n- Linting: [status]\n- Type checking: [status]\n- Tests: [status]\n- Build: [status]\n\n## Next Steps\n- [Recommendations]\n```\n\n## Usage Examples\n\n```bash\n# Basic usage\n/debug\n\n# After making changes\n/debug\n```\n\n## Key Principles\n\n- **Detect don't assume**: Scan for actual commands\n- **Parallel execution**: Run all checks simultaneously\n- **Systematic fixes**: Critical -> High -> Medium -> Low\n- **Always verify**: Re-run validation after fixes\n- **Context-aware**: Read files before fixing\n- **Report clearly**: Show before/after comparison\n",
        "plugins/dev/commands/fix-pr-comments.md": "---\ndescription: Fetch all unresolved comments from current PR and fix them automatically\nallowed-tools: Bash(gh *), Bash(git *), Read, Write, Edit, Grep, Glob\n---\n\nAutomatically resolve all unresolved PR review comments.\n\n## Workflow\n\n1. **Check authentication**\n\n   ```bash\n   gh auth status\n   ```\n\n   If not authenticated, stop and ask user to run `gh auth login`.\n\n2. **Detect current PR**\n\n   ```bash\n   gh pr view --json number,title,url\n   ```\n\n   If no PR found, stop and inform user.\n\n3. **Fetch unresolved comments**\n\n   ```bash\n   gh pr view --comments | grep -A 5 \"UNRESOLVED\"\n   ```\n\n   Extract:\n   - Comment author\n   - File path\n   - Line number\n   - Comment text\n   - Suggested change\n\n4. **Plan fixes**\n   - Read all files mentioned in comments\n   - Understand context (read 2-3 related files)\n   - Create fix plan for each comment:\n     - What needs to change\n     - Why it needs to change\n     - How to implement it\n\n5. **Apply fixes systematically**\n   - Fix one comment at a time\n   - Read file before editing\n   - Apply the fix\n   - Verify the fix addresses the comment\n\n6. **Commit and push**\n\n   ```bash\n   git add .\n   git commit -m \"fix: resolve PR review comments\"\n   git push\n   ```\n\n7. **Summary report**\n\n   ```\n   Fixed 5 PR comments:\n   - src/utils/api.ts:45 - Added error handling\n   - src/components/User.tsx:112 - Fixed prop types\n   - tests/auth.test.ts:23 - Updated test assertion\n   - src/services/payment.ts:67 - Added validation\n   - README.md:15 - Fixed typo\n\n   Pushed to branch: feature/user-auth\n   PR: https://github.com/user/repo/pull/123\n   ```\n\n## Error Handling\n\n- **No PR found**: Inform user and suggest creating one\n- **No unresolved comments**: Report success, nothing to fix\n- **Not authenticated**: Guide user to authenticate with gh cli\n- **Comment ambiguous**: Ask user for clarification\n\n## Usage Examples\n\n```bash\n# Basic usage (auto-detects current PR)\n/fix-pr-comments\n\n# After receiving review comments\n/fix-pr-comments\n```\n\n## Notes\n\n- Only fixes unresolved comments\n- Commits all fixes in one commit\n- Automatically pushes to current branch\n- Reads context before making changes\n",
        "plugins/dev/commands/merge-to-main.md": "---\ndescription: Perform manual merge to main branch with automated conflict resolution and PR management\nallowed-tools: Bash(git *), Bash(gh *), Bash(npm run *), Bash(pnpm *), Bash(yarn *), Read, Write, Edit\n---\n\nComplete merge workflow from current branch to main with conflict resolution.\n\n## Workflow\n\n### 1. Prepare for Merge\n\n**Check current state:**\n\n```bash\n# Verify on feature branch\ngit branch --show-current\n\n# Ensure all changes committed\ngit status\n\n# Check for uncommitted changes\nif [ -n \"$(git status --porcelain)\" ]; then\n  echo \"Uncommitted changes found\"\n  # Run /commit if needed\nfi\n```\n\n**Fetch latest main:**\n\n```bash\ngit fetch origin main\n```\n\n**Preview merge conflicts:**\n\n```bash\ngit diff origin/main...HEAD\n```\n\n### 2. Create Pull Request\n\n**Finalize changes:**\n- If uncommitted changes exist, run `/commit` first\n- Ensure all validation passes (lint, typecheck, tests)\n\n**Create PR:**\n\n```bash\ngh pr create \\\n  --base main \\\n  --title \"[Feature] Clear description\" \\\n  --body \"## Changes\n- Implemented [feature]\n- Fixed [issue]\n\n## Testing\n- All tests passing\n- TypeScript compilation passes\n- Linting passes\n\n## Related Issues\nCloses #123\"\n```\n\n### 3. Conflict Detection & Resolution\n\n**Check for conflicts:**\n\n```bash\ngh pr view --json mergeable,mergeStateStatus\n```\n\n**If conflicts detected:**\n\n1. **Analyze conflicts:**\n\n   ```bash\n   git merge-tree $(git merge-base HEAD origin/main) HEAD origin/main\n   ```\n\n2. **Resolution strategy:**\n\n   **Automatic resolution (when safe):**\n   - Both modified same file, different sections: Accept both changes\n   - One added, one modified: Accept both changes\n   - Formatting conflicts: Accept current branch (already validated)\n\n   **Manual resolution required:**\n   - Both modified same lines: Analyze semantics\n   - Deleted vs modified: Understand intent\n   - Complex logic conflicts: Ask user for guidance\n\n3. **Apply resolution:**\n\n   ```bash\n   git checkout main\n   git pull origin main\n   git merge <feature-branch>\n   # Resolve conflicts\n   # Test the merged code\n   ```\n\n4. **Verify resolution:**\n   - Run full test suite\n   - Run type checker\n   - Run linter\n   - Ensure build passes\n\n### 4. Quality Assurance\n\n**Run validation suite:**\n\n```bash\nMANAGER=$(\n  if [ -f \"pnpm-lock.yaml\" ]; then echo \"pnpm\"\n  elif [ -f \"yarn.lock\" ]; then echo \"yarn\"\n  elif [ -f \"bun.lockb\" ]; then echo \"bun\"\n  else echo \"npm\"\n  fi\n)\n\n$MANAGER run lint\n$MANAGER run typecheck\n$MANAGER run test\n$MANAGER run build\n```\n\n**Wait for CI checks:**\n\n```bash\ngh pr checks\n```\n\n### 5. Complete Merge\n\n**Merge PR:**\n\n```bash\ngh pr merge --auto --squash --delete-branch\n```\n\nOptions:\n- `--squash`: Squash all commits into one (cleaner history)\n- `--merge`: Keep all commits (preserve history)\n- `--rebase`: Rebase and merge (linear history)\n- `--delete-branch`: Clean up feature branch\n\n**Verify merge:**\n\n```bash\ngit checkout main\ngit pull origin main\ngit log --oneline -5\n```\n\n**Cleanup:**\n\n```bash\n# Delete local feature branch\ngit branch -d <feature-branch>\n\n# Verify remote cleanup\ngh pr list --state closed --limit 5\n```\n\n### 6. Post-Merge Summary\n\n```\nMerge Complete\n\nBranch: feature/user-authentication\nPR: #123 - Add user authentication\nMerge type: Squash\n\nSummary:\n- X files changed\n- Y insertions, Z deletions\n- 0 conflicts (or N auto-resolved)\n- All CI checks passed\n\nMain branch updated successfully.\n```\n\n## Conflict Resolution Strategies\n\n1. **Accept Current Branch (feature)**: When feature branch has validated changes\n2. **Accept Main Branch**: When main has critical fixes\n3. **Merge Both**: When changes are in different sections\n4. **Smart Merge**: Analyze semantics and combine logically\n5. **Ask User**: When conflict is ambiguous or complex\n\n## Usage Examples\n\n```bash\n# Basic usage\n/merge-to-main\n\n# After feature complete\n/merge-to-main\n```\n\n## Error Handling\n\n- **Uncommitted changes**: Run `/commit` first\n- **CI checks failing**: Fix issues before merge\n- **Complex conflicts**: Ask user for guidance\n- **Not authenticated**: Run `gh auth login`\n- **No PR found**: Create PR first\n\n## Notes\n\n- Automatically detects and resolves simple conflicts\n- Asks for guidance on complex conflicts\n- Runs full validation before merge\n- Cleans up branches after merge\n- Provides detailed merge summary\n",
        "plugins/dev/commands/run-task.md": "---\ndescription: Execute a task from file path or GitHub issue with full implementation workflow\nallowed-tools: Bash(gh *), Bash(git *), Bash(npm *), Bash(pnpm *), Bash(yarn *), Read, Write, Edit, Grep, Glob\n---\n\nExecute complete implementation workflow from issue or file.\n\n## Workflow\n\n### 1. Parse Task Input\n\n**$ARGUMENT can be:**\n- GitHub issue URL: `https://github.com/user/repo/issues/123`\n- GitHub issue number: `123`\n- File path with instructions: `./tasks/add-feature.md`\n\n### 2. Fetch Task Details\n\n**For GitHub issue:**\n\n```bash\ngh issue view $ARGUMENT --json title,body,labels,assignees\n```\n\n**For file path:**\n\n```bash\ncat $ARGUMENT\n```\n\nExtract:\n- Task description\n- Requirements\n- Acceptance criteria\n- Technical notes\n\n### 3. Plan Implementation\n\n**Discovery phase:**\n- Read all relevant files\n- Understand existing patterns\n- Identify files to modify\n- Find similar implementations\n\n**Create detailed plan:**\n\n```\n## Implementation Plan\n\n### Context\n[What needs to be built and why]\n\n### Files to modify:\n1. src/components/Feature.tsx\n2. src/services/api.ts\n3. tests/Feature.test.ts\n\n### Steps:\n1. [Specific implementation steps]\n2. [...]\n```\n\n### 4. Implement Changes\n\n**Systematic implementation:**\n\n1. Read files before editing (understand context)\n2. Make changes following the plan\n3. Run TypeScript type checker continuously\n4. Fix type errors immediately\n5. Run linter and fix issues\n6. Auto-format code\n\n**Auto-correct with TypeScript:**\n- Fix type errors as they appear\n- Add proper type annotations\n- Resolve import issues\n- Update interfaces/types\n\n### 5. Commit Changes\n\n**Create clean commit:**\n\n```bash\ngit add .\ngit commit -m \"feat: [clear description of changes]\"\n```\n\nFollow Commitizen convention:\n- `feat:` - New feature\n- `fix:` - Bug fix\n- `refactor:` - Code refactoring\n- `test:` - Test updates\n- `docs:` - Documentation\n\n### 6. Create Pull Request\n\n**Generate comprehensive PR:**\n\n```bash\ngh pr create --title \"[Title]\" --body \"[Description]\"\n```\n\n**PR description includes:**\n\n```markdown\n## Changes\n- Implemented [feature]\n- Fixed [issue]\n\n## Testing\n- TypeScript compilation passes\n- All tests passing\n- Linting passes\n\n## Related Issues\nCloses #123\n```\n\n## Usage Examples\n\n```bash\n# From GitHub issue URL\n/run-task https://github.com/user/repo/issues/123\n\n# From issue number\n/run-task 123\n\n# From task file\n/run-task ./tasks/implement-auth.md\n\n# From inline description\n/run-task \"Add email validation to user profile form\"\n```\n\n## Error Handling\n\n- **Issue not found**: Verify issue number and repo access\n- **File not found**: Check file path is correct\n- **Type errors**: Fix all TypeScript errors before committing\n- **Tests fail**: Fix tests before creating PR\n- **Not authenticated**: Run `gh auth login`\n\n## Notes\n\n- Reads context before making changes\n- Runs TypeScript continuously for immediate feedback\n- Auto-corrects type errors\n- Creates clean, reviewable commits\n- Generates comprehensive PR descriptions\n",
        "plugins/dev/scripts/worktree-manager/README.md": "# Worktree Manager\n\nIntelligent Git worktree manager with TypeScript/Bun - automates worktree creation, branch management, and GitHub issue integration.\n\n## Features\n\n### Core Features\n\n- **Zero Installation**: Uses Bun runtime, no npm install required\n- **GitHub Integration**: Automatic issue fetching and parsing via GitHub CLI\n- **Smart Branch Naming**: AI-powered branch name generation with Claude CLI (optional)\n- **Automated Setup**: Auto-installs dependencies, copies .env files, opens terminal\n- **Multi-Terminal Support**: Hyper, iTerm2, Warp, Terminal.app\n- **Package Manager Detection**: Auto-detects pnpm, npm, yarn, or bun\n- **Configuration Profiles**: Customizable profiles for different workflows\n- **Worktree History**: Tracks all created worktrees with metadata\n- **Cleanup Tools**: Prune and remove old worktrees\n\n### Advanced Features\n\n- **Environment File Copying**: Automatically copies all .env files to worktree\n- **Dependency Installation**: Auto-installs dependencies with detected package manager\n- **Terminal Integration**: Opens terminal with Claude CLI in plan mode\n- **Raycast Integration**: Native Raycast script for quick access\n- **Structured Logging**: AdonisJS-inspired logging with debug mode\n- **Error Handling**: Comprehensive error handling and recovery\n- **Git Operations**: Safe worktree creation, removal, and branch management\n\n## Architecture\n\n```\nworktree-manager/\nâ”œâ”€â”€ src/                           # TypeScript/Bun source\nâ”‚   â”œâ”€â”€ index.ts                   # Main entry point\nâ”‚   â”œâ”€â”€ cli.ts                     # CLI interface\nâ”‚   â””â”€â”€ lib/\nâ”‚       â”œâ”€â”€ types.ts               # Type definitions\nâ”‚       â”œâ”€â”€ config.ts              # Configuration management\nâ”‚       â”œâ”€â”€ logger.ts              # Structured logging\nâ”‚       â”œâ”€â”€ formatters.ts          # Output formatting\nâ”‚       â”œâ”€â”€ git-bridge.ts          # Git operations\nâ”‚       â”œâ”€â”€ github-integration.ts  # GitHub CLI integration\nâ”‚       â”œâ”€â”€ package-manager.ts     # Package manager detection\nâ”‚       â”œâ”€â”€ file-utils.ts          # File operations\nâ”‚       â”œâ”€â”€ terminal-launcher.ts   # Terminal app orchestration\nâ”‚       â””â”€â”€ worktree-manager.ts    # Main orchestration\nâ”œâ”€â”€ config/                        # Configuration files\nâ”‚   â”œâ”€â”€ default.json               # Default settings\nâ”‚   â””â”€â”€ profiles/                  # Custom profiles\nâ”œâ”€â”€ scripts/                       # Utility scripts\nâ”‚   â”œâ”€â”€ install.sh                 # Installation script\nâ”‚   â””â”€â”€ terminals/\nâ”‚       â””â”€â”€ launcher.sh            # Universal terminal launcher (all terminals)\nâ””â”€â”€ .worktrees.json               # Worktree history (auto-generated)\n```\n\n## Installation\n\n### Prerequisites\n\n- Bun: JavaScript/TypeScript runtime\n- Git: Version control system\n- GitHub CLI (gh): Required for GitHub integration\n\n### Setup\n\nRun the installation script to check dependencies:\n\n```bash\n~/.claude/scripts/worktree-manager/scripts/install.sh\n```\n\n### Shell Alias\n\nAdd this alias to your `~/.zshrc` or `~/.bashrc`:\n\n```bash\nalias worktree='bun ~/.claude/scripts/worktree-manager/src/index.ts'\n```\n\nThen reload your shell:\n\n```bash\nsource ~/.zshrc  # or source ~/.bashrc\n```\n\n### Raycast Integration\n\nThe Raycast script is already available at:\n\n```bash\n~/.claude/scripts/raycast/setup-worktree.sh\n```\n\nRaycast will automatically detect it if you've added `~/.claude/scripts/raycast` to your Raycast script directories.\n\n## Usage\n\n### Basic Usage\n\n```bash\n# Create worktree from GitHub issue\nworktree https://github.com/user/repo/issues/123\n\n# List all worktrees\nworktree list\n\n# Clean up prunable worktrees\nworktree clean\n\n# Force cleanup of all worktrees\nworktree clean --force\n```\n\n### CLI Options\n\n```\nUSAGE:\n  worktree <github-issue-url> [options]\n  worktree list\n  worktree clean [--force]\n\nOPTIONS:\n  -b, --branch <name>     Custom branch name (overrides auto-generation)\n  -o, --output <dir>      Custom worktree base directory\n  -p, --profile <name>    Use a configuration profile\n  -t, --terminal <app>    Terminal app (Hyper, iTerm2, Warp, Terminal)\n  -f, --force             Force cleanup of all worktrees\n  --no-deps               Skip dependency installation\n  --no-terminal           Don't open terminal automatically\n  --debug                 Enable debug logging\n  -h, --help              Show help message\n  -v, --version           Show version information\n```\n\n### Examples\n\n```bash\n# Create worktree with default settings\nworktree https://github.com/user/repo/issues/123\n\n# Create with custom branch name\nworktree https://github.com/user/repo/issues/123 --branch feature-xyz\n\n# Create without installing dependencies\nworktree https://github.com/user/repo/issues/123 --no-deps\n\n# Create with specific terminal app\nworktree https://github.com/user/repo/issues/123 --terminal iTerm2\nworktree https://github.com/user/repo/issues/123 --terminal Warp\n\n# Create without opening terminal\nworktree https://github.com/user/repo/issues/123 --no-terminal\n\n# Create with custom output directory\nworktree https://github.com/user/repo/issues/123 --output ~/Projects/worktrees\n\n# Combine options\nworktree https://github.com/user/repo/issues/123 --terminal Warp --profile fast\n\n# Debug mode\nworktree https://github.com/user/repo/issues/123 --debug\n\n# List all worktrees\nworktree list\n\n# Clean up old worktrees\nworktree clean\n\n# Force remove all worktrees\nworktree clean --force\n```\n\n### Raycast Usage\n\nIn Raycast:\n\n1. Type \"Setup Git Worktree\"\n2. Enter GitHub issue URL: `https://github.com/user/repo/issues/123`\n3. Select terminal app from dropdown: Hyper, iTerm2, Warp, or Terminal (optional, defaults to Hyper)\n4. (Optional) Add options: `--no-deps --debug --profile minimal`\n5. Press Enter\n\n**Raycast Arguments**:\n- **Argument 1** (required): GitHub issue URL\n- **Argument 2** (optional): Terminal app (dropdown selection) - defaults to Hyper if not specified\n- **Argument 3** (optional): Additional CLI options\n\n**Terminal Selection**:\nThe terminal app is selected via the Raycast dropdown interface. This approach:\n- Prevents typos and errors\n- Provides visual selection\n- Works seamlessly with the universal launcher in `scripts/terminals/launcher.sh`\n- Defaults to Hyper if not specified\n\n**Modular Raycast Script**:\nThe Raycast script is organized with separate functions:\n- `validate_requirements()`: Checks prerequisites (Bun, worktree-manager)\n- `build_worktree_command()`: Constructs the command with proper arguments\n- `main()`: Orchestrates execution flow\n\nThis modular approach makes the script easier to maintain and extend.\n\n## Configuration\n\n### Default Configuration\n\nLocated at `config/default.json`:\n\n```json\n{\n  \"worktreeBasePath\": \"~/Developer/worktrees\",\n  \"defaultBranch\": \"main\",\n  \"autoInstallDeps\": true,\n  \"packageManager\": \"auto\",\n  \"copyEnvFiles\": true,\n  \"openTerminal\": true,\n  \"terminalApp\": \"Hyper\",\n  \"integrations\": {\n    \"github\": {\n      \"enabled\": true,\n      \"autoFetchIssue\": true\n    },\n    \"claude\": {\n      \"enabled\": true,\n      \"autoGenerateBranchName\": true,\n      \"autoStartPlanMode\": true\n    }\n  },\n  \"cleanup\": {\n    \"autoCleanMerged\": false,\n    \"maxAge\": 30,\n    \"keepRecent\": 10\n  }\n}\n```\n\n### Configuration Options\n\n**Paths**:\n- `worktreeBasePath`: Base directory for worktrees (default: `~/Developer/worktrees`)\n- `defaultBranch`: Default branch to base worktrees on (default: `main`)\n\n**Automation**:\n- `autoInstallDeps`: Auto-install dependencies (default: `true`)\n- `packageManager`: Package manager to use (`auto`, `pnpm`, `npm`, `yarn`, `bun`)\n- `copyEnvFiles`: Copy .env files to worktree (default: `true`)\n- `openTerminal`: Open terminal after creation (default: `true`)\n- `terminalApp`: Terminal app to use (`Hyper`, `iTerm2`, `Warp`, `Terminal`)\n\n**Integrations**:\n- `github.enabled`: Enable GitHub CLI integration\n- `github.autoFetchIssue`: Auto-fetch issue details\n- `claude.enabled`: Enable Claude CLI integration\n- `claude.autoGenerateBranchName`: Use AI for branch naming\n- `claude.autoStartPlanMode`: Start Claude in plan mode\n\n**Cleanup**:\n- `autoCleanMerged`: Auto-cleanup merged branches\n- `maxAge`: Maximum age in days for worktrees\n- `keepRecent`: Keep N most recent worktrees\n\n### Custom Profiles\n\nCreate custom profiles in `config/profiles/` to define different workflow behaviors.\n\n**Available Profiles**:\n- **minimal**: No automation, manual setup\n- **fast**: Quick setup without Claude CLI\n- **full**: All features enabled\n\n**config/profiles/minimal.json**:\n```json\n{\n  \"autoInstallDeps\": false,\n  \"openTerminal\": false,\n  \"integrations\": {\n    \"claude\": {\n      \"autoGenerateBranchName\": false,\n      \"autoStartPlanMode\": false\n    }\n  }\n}\n```\n\n**Note**: Profiles do not include terminal selection. The terminal is always specified via:\n- CLI: `--terminal` flag\n- Raycast: Dropdown selection (Argument 2)\n- Default: Hyper (from `config/default.json`)\n\nUse with:\n```bash\nworktree https://github.com/user/repo/issues/123 --profile minimal --terminal iTerm2\n```\n\n## Workflow\n\n### Typical Workflow\n\n1. **Parse Issue URL**: Extract owner, repo, and issue number\n2. **Fetch Issue**: Use `gh` CLI to get issue details\n3. **Generate Branch Name**: Use Claude CLI or fallback to simple generation\n4. **Create Worktree**: Create isolated git worktree with new branch\n5. **Copy .env Files**: Find and copy all environment files\n6. **Install Dependencies**: Auto-detect package manager and install\n7. **Open Terminal**: Launch terminal with Claude in plan mode\n8. **Save History**: Track worktree metadata for future reference\n\n### Generated Structure\n\n```\n~/Developer/worktrees/\nâ””â”€â”€ project-name-worktree/\n    â””â”€â”€ issue-123-feature-name/\n        â”œâ”€â”€ .env\n        â”œâ”€â”€ node_modules/\n        â””â”€â”€ ... (project files)\n```\n\n## Integrations\n\n### GitHub CLI\n\n**Required**: Yes\n\nInstall and authenticate:\n```bash\nbrew install gh\ngh auth login\n```\n\nThe tool uses `gh` to:\n- Fetch issue details (title, body, labels, assignees)\n- Parse issue metadata\n- Validate repository access\n\n### Claude CLI\n\n**Required**: No (optional)\n\nInstall:\n```bash\n# Follow Claude CLI installation instructions\n```\n\nThe tool uses `claude` to:\n- Generate intelligent branch names from issue context\n- Start plan mode for task execution\n\nIf Claude CLI is not available, the tool falls back to simple branch name generation.\n\n### Package Managers\n\n**Auto-detected**: pnpm, npm, yarn, bun\n\nThe tool automatically detects package managers by looking for:\n- `pnpm-lock.yaml` â†’ pnpm\n- `bun.lockb` â†’ bun\n- `yarn.lock` â†’ yarn\n- `package-lock.json` â†’ npm\n\n### Terminal Apps\n\n**Supported**: Hyper, iTerm2, Warp, Terminal.app\n\n**Architecture**: Simplified universal launcher\n\nThe tool uses a streamlined architecture with a single launcher script:\n\n- **TerminalLauncher** (`src/lib/terminal-launcher.ts`): TypeScript orchestration layer\n  - Detects installed terminals\n  - Delegates to universal launcher script\n  - Validates execution and handles errors\n\n- **Universal Launcher** (`scripts/terminals/launcher.sh`): Single bash script handling all terminals\n  - Takes terminal app name and command as parameters\n  - Uses case-based routing to terminal-specific functions\n  - Implements AppleScript for Hyper, iTerm2, Terminal.app\n  - Uses temporary script approach for Warp\n  - Validates terminal installation before launching\n\n**Benefits**:\n- **Simplified**: One script instead of four separate files\n- **Maintainable**: All terminal logic in a single location\n- **Extensible**: Add new terminals by adding a case and function\n- **Consistent**: Same error handling and validation for all terminals\n- **No duplication**: Shared validation and error handling code\n\n## Advanced Usage\n\n### Manual Branch Names\n\n```bash\nworktree https://github.com/user/repo/issues/123 --branch my-custom-branch\n```\n\n### Skip Dependency Installation\n\n```bash\nworktree https://github.com/user/repo/issues/123 --no-deps\n```\n\n### Custom Output Directory\n\n```bash\nworktree https://github.com/user/repo/issues/123 --output ~/Custom/Path\n```\n\n### Debug Mode\n\n```bash\nworktree https://github.com/user/repo/issues/123 --debug\n```\n\n### Cleanup Strategies\n\n```bash\n# Clean prunable worktrees only\nworktree clean\n\n# Force remove all worktrees\nworktree clean --force\n```\n\n## Troubleshooting\n\n### GitHub CLI not authenticated\n\n```bash\ngh auth login\n```\n\n### Bun not found\n\n```bash\ncurl -fsSL https://bun.sh/install | bash\n```\n\nThen add to your PATH (usually automatic).\n\n### Permission denied\n\nMake scripts executable:\n\n```bash\nchmod +x ~/.claude/scripts/worktree-manager/src/index.ts\nchmod +x ~/.claude/scripts/worktree-manager/scripts/*.sh\nchmod +x ~/.claude/scripts/raycast/setup-worktree.sh\n```\n\n### Terminal not opening\n\nCheck your terminal app configuration in `config/default.json`:\n\n```json\n{\n  \"terminalApp\": \"Hyper\"  // or \"iTerm2\", \"Warp\", \"Terminal\"\n}\n```\n\n### Dependencies not installing\n\nCheck package manager installation:\n\n```bash\nwhich pnpm npm yarn bun\n```\n\n## Performance\n\n- **Startup**: ~100ms (Bun runtime)\n- **Issue Fetch**: ~500ms (GitHub API)\n- **Branch Generation**: ~2s (with Claude) or instant (fallback)\n- **Worktree Creation**: ~200ms (git operations)\n- **Dependency Installation**: Varies by project size\n- **Total Time**: ~3-5 minutes for typical project\n\n## Comparison with Original Script\n\n| Feature | Original Script | Worktree Manager |\n|---------|----------------|------------------|\n| Runtime | Bash | TypeScript/Bun |\n| Error Handling | Basic | Comprehensive |\n| Logging | Echo statements | Structured logger |\n| Configuration | Hardcoded | JSON profiles |\n| Package Managers | pnpm/npm/yarn | Auto-detection + bun |\n| Branch Naming | Claude CLI only | Claude + fallback |\n| Terminal Support | Hyper only | Hyper, iTerm2, Warp, Terminal |\n| Cleanup | Manual | Built-in commands |\n| History | None | Automatic tracking |\n| Extensibility | Limited | Modular architecture |\n\n## Future Enhancements\n\n- [ ] Automatic PR creation after work completion\n- [ ] Worktree templates per project\n- [ ] Smart cleanup based on branch merge status\n- [ ] VS Code workspace integration\n- [ ] Multi-repository support\n- [ ] Worktree sharing across team\n- [ ] Git hooks integration\n- [ ] Backup and restore worktrees\n\n## Inspiration\n\nThis project architecture is inspired by:\n\n- `~/.claude/scripts/crawler` - TypeScript/Bun + Go hybrid architecture\n- `~/.claude/scripts/fetcher` - Modular structure and CLI patterns\n- Original `setup-worktree.sh` - Core workflow and requirements\n- AdonisJS Logger - Structured logging patterns\n\n## License\n\nPart of the Claude Code configuration system.\n\n## Support\n\nFor issues and feature requests:\n1. Check the troubleshooting section\n2. Run with `--debug` flag for detailed logs\n3. Review configuration in `config/default.json`\n",
        "plugins/dev/skills/adonisjs-cli/SKILL.md": "---\nname: adonisjs-cli\ndescription: AdonisJS Ace CLI expert for building TypeScript backend applications. Use when users need to scaffold, develop, build, or manage AdonisJS projects, run migrations, create models/controllers, or configure packages.\nallowed-tools: Bash(node ace:*), Bash(npm run:*)\n---\n\n# AdonisJS Ace CLI Guide\n\nAdonisJS is a TypeScript-first Node.js framework for building server-side applications. Ace is the command-line framework embedded into AdonisJS core. This guide provides essential workflows and quick references for common AdonisJS operations.\n\n## Quick Start\n\n```bash\n# Create new AdonisJS project\nnpm init adonisjs@latest my-app\n\n# Navigate to project\ncd my-app\n\n# Generate app key\nnode ace generate:key\n\n# Start development server\nnode ace serve --hmr\n\n# List all available commands\nnode ace list\n\n# Get help for a command\nnode ace serve --help\n```\n\n## Common Workflows\n\n### Workflow 1: API Project Setup\n\n```bash\n# Create API project\nnpm init adonisjs@latest my-api -- --kit=api\n\ncd my-api\n\n# Generate app key\nnode ace generate:key\n\n# Install and configure database\nnode ace add @adonisjs/lucid\n\n# Create initial model with migration\nnode ace make:model User -m\n\n# Run migrations\nnode ace migration:run\n\n# Start dev server with HMR\nnode ace serve --hmr\n```\n\n### Workflow 2: CRUD Resource Creation\n\n```bash\n# Create complete resource (model, migration, factory, controller)\nnode ace make:model Post -mfc\n\n# Create validators for the resource\nnode ace make:validator post --resource\n\n# Create service for business logic\nnode ace make:service post\n\n# Edit migration file (database/migrations/xxxxx_posts.ts)\n# Add table columns\n\n# Run migration\nnode ace migration:run\n\n# Create seeder for testing data\nnode ace make:seeder Post\n\n# Run seeder\nnode ace db:seed\n```\n\n### Workflow 3: Database Management\n\n```bash\n# Create migration\nnode ace make:migration add_slug_to_posts\n\n# Preview migration changes (dry run)\nnode ace migration:run --dry-run\n\n# Run migrations\nnode ace migration:run\n\n# Check migration status\nnode ace migration:status\n\n# Rollback last batch\nnode ace migration:rollback\n\n# Refresh database (reset + run)\nnode ace migration:refresh --seed\n```\n\n### Workflow 4: Authentication Setup\n\n```bash\n# Install authentication package\nnode ace add @adonisjs/auth\n\n# Install session support\nnode ace add @adonisjs/session\n\n# Create auth controllers\nnode ace make:controller auth/login\nnode ace make:controller auth/register\n\n# Create auth middleware\nnode ace make:middleware auth\n\n# Run auth migrations\nnode ace migration:run\n```\n\n### Workflow 5: Production Build\n\n```bash\n# Build application\nnode ace build\n\n# Navigate to build directory\ncd build\n\n# Install production dependencies\nnpm ci --production\n\n# Run migrations in production\nnode ace migration:run --force\n\n# Start production server\nnode server.js\n```\n\n## Decision Tree\n\n**When to use which command:**\n\n- **To start development**: Use `node ace serve --hmr`\n- **To create models**: Use `node ace make:model Name -mfc` (includes migration, factory, controller)\n- **To create API controllers**: Use `node ace make:controller name --resource --api`\n- **To manage database**: Use migration commands (`migration:run`, `migration:rollback`, `migration:status`)\n- **To add packages**: Use `node ace add @adonisjs/package-name`\n- **To validate input**: Use `node ace make:validator name --resource`\n- **To view routes**: Use `node ace list:routes --middleware`\n- **For detailed command syntax**: See [Commands Reference](./reference/commands-reference.md)\n- **For implementation patterns**: See [Common Patterns](./reference/common-patterns.md)\n- **For debugging**: See [Troubleshooting Guide](./reference/troubleshooting.md)\n\n## Common Patterns\n\n### Creating Resource Controllers\n\n```bash\n# RESTful API controller\nnode ace make:controller posts --resource --api\n\n# Generates controller with:\n# - index()    GET /posts\n# - store()    POST /posts\n# - show()     GET /posts/:id\n# - update()   PUT /posts/:id\n# - destroy()  DELETE /posts/:id\n```\n\n### Model Relationships\n\n```typescript\n// One-to-Many (User has many Posts)\n// app/models/user.ts\n@hasMany(() => Post)\ndeclare posts: HasMany<typeof Post>\n\n// app/models/post.ts\n@belongsTo(() => User)\ndeclare user: BelongsTo<typeof User>\n\n// Query with relationships\nconst user = await User.query().preload('posts')\nconst post = await Post.query().preload('user').first()\n```\n\n### Request Validation\n\n```typescript\n// Create validator: node ace make:validator post --resource\n// app/validators/post.ts\nimport vine from '@vinejs/vine'\n\nexport const createPostValidator = vine.compile(\n  vine.object({\n    title: vine.string().minLength(3).maxLength(255),\n    content: vine.string().minLength(10),\n    isPublished: vine.boolean().optional(),\n  })\n)\n\n// Use in controller\nconst payload = await request.validateUsing(createPostValidator)\n```\n\n### Database Migrations\n\n```typescript\n// Create table migration\nexport default class extends BaseSchema {\n  protected tableName = 'posts'\n\n  async up() {\n    this.schema.createTable(this.tableName, (table) => {\n      table.increments('id')\n      table.string('title').notNullable()\n      table.text('content').notNullable()\n      table.integer('user_id').unsigned()\n        .references('users.id').onDelete('CASCADE')\n      table.timestamp('created_at')\n      table.timestamp('updated_at')\n    })\n  }\n\n  async down() {\n    this.schema.dropTable(this.tableName)\n  }\n}\n```\n\n### Authentication Patterns\n\n```typescript\n// Session-based login\nexport default class LoginController {\n  async store({ request, auth, response }: HttpContext) {\n    const { email, password } = request.only(['email', 'password'])\n    const user = await User.verifyCredentials(email, password)\n    await auth.use('web').login(user)\n    return response.redirect('/dashboard')\n  }\n}\n\n// API token generation\nexport default class TokensController {\n  async store({ request, response }: HttpContext) {\n    const { email, password } = request.only(['email', 'password'])\n    const user = await User.verifyCredentials(email, password)\n    const token = await User.accessTokens.create(user)\n    return response.created({ token: token.value!.release() })\n  }\n}\n```\n\n## Troubleshooting\n\n**Common Issues:**\n\n1. **Server won't start**\n   - Quick fix: Check if port is in use `lsof -i :3333`\n   - Generate APP_KEY: `node ace generate:key`\n   - See: [Server Issues](./reference/troubleshooting.md#server-wont-start)\n\n2. **Migration fails**\n   - Quick fix: Check migration status `node ace migration:status`\n   - Verify database connection in `.env`\n   - See: [Migration Fails](./reference/troubleshooting.md#migration-fails)\n\n3. **Database connection refused**\n   - Quick fix: Verify database is running and `.env` credentials\n   - Test connection: `psql -h localhost -U postgres`\n   - See: [Cannot Connect to Database](./reference/troubleshooting.md#cannot-connect-to-database)\n\n4. **Validation always fails**\n   - Quick fix: Ensure validator is compiled `vine.compile(schema)`\n   - Check field names match request data\n   - See: [Validation Issues](./reference/troubleshooting.md#validation-always-fails)\n\n5. **Route not found (404)**\n   - Quick fix: List routes with `node ace list:routes`\n   - Check route order (specific before wildcards)\n   - See: [Route Not Found](./reference/troubleshooting.md#route-not-found-404)\n\nFor detailed troubleshooting steps, see the [Troubleshooting Guide](./reference/troubleshooting.md).\n\n## Reference Files\n\n**Load as needed for detailed information:**\n\n- **[Commands Reference](./reference/commands-reference.md)** - Complete Ace CLI command documentation with all flags and options. Use when you need exact syntax, flag details, or comprehensive command documentation.\n\n- **[Common Patterns](./reference/common-patterns.md)** - Real-world patterns for CRUD resources, authentication, validation, relationships, events, testing, and production deployment. Use for implementing specific features or architectural patterns.\n\n- **[Troubleshooting Guide](./reference/troubleshooting.md)** - Detailed error messages, diagnosis steps, and resolution strategies for server, database, authentication, routing, build, and performance issues. Use when encountering errors or unexpected behavior.\n\n**When to use each reference:**\n\n- Use **Commands Reference** when you need exact command syntax, flag combinations, or comprehensive CLI documentation\n- Use **Common Patterns** for implementing CRUD operations, authentication flows, database relationships, or production deployments\n- Use **Troubleshooting** when server won't start, migrations fail, authentication breaks, or you encounter build/performance issues\n\n## Resources\n\n- Official Docs: https://docs.adonisjs.com\n- Ace CLI Docs: https://docs.adonisjs.com/guides/ace\n- Lucid ORM: https://lucid.adonisjs.com\n- GitHub: https://github.com/adonisjs/core\n- Community: https://discord.gg/vDcEjq6\n",
        "plugins/dev/skills/adonisjs-cli/reference/commands-reference.md": "# AdonisJS Ace CLI Commands Reference\n\nComplete reference for all Ace CLI commands with detailed options and flags.\n\n## Basic Usage\n\n```bash\n# Show all available commands\nnode ace\nnode ace list\n\n# Get help for a specific command\nnode ace [command] --help\n\n# Execute a command\nnode ace [command] [arguments] [flags]\n```\n\n## Global Options\n\n```bash\n# Force enable colored output\nnode ace [command] --ansi\n\n# Disable colors (useful in CI environments)\nnode ace [command] --no-ansi\n```\n\n## Core Commands\n\n### `serve`\n\nStarts the development server with file watching and hot module replacement.\n\n```bash\n# Start development server\nnode ace serve\n\n# Start with HMR (Hot Module Replacement)\nnode ace serve --hmr\n\n# Start with file watching\nnode ace serve --watch\n\n# Start with polling (useful for Docker/WSL)\nnode ace serve --poll\n\n# Start without clearing console\nnode ace serve --no-clear\n\n# Start without building assets\nnode ace serve --no-assets\n\n# Pass arguments to asset bundler\nnode ace serve --assets-args=\"--debug\"\n```\n\n### `build`\n\nCreates a production-ready application build.\n\n```bash\n# Build for production\nnode ace build\n\n# Ignore TypeScript errors during build\nnode ace build --ignore-ts-errors\n\n# Specify package manager\nnode ace build --package-manager=pnpm\n\n# Build without assets\nnode ace build --no-assets\n\n# Pass arguments to asset bundler\nnode ace build --assets-args=\"--minify\"\n```\n\n### `add`\n\nInstalls and configures a package in one command.\n\n```bash\n# Install and configure a package\nnode ace add @adonisjs/lucid\n\n# Install as dev dependency\nnode ace add my-package --dev\n\n# Verbose output\nnode ace add @adonisjs/auth --verbose\n\n# Force configuration (skip prompts)\nnode ace add @adonisjs/mail --force\n\n# Specify package manager\nnode ace add @adonisjs/redis --package-manager=pnpm\n```\n\n### `configure`\n\nSets up a pre-installed package.\n\n```bash\n# Configure an already installed package\nnode ace configure @adonisjs/lucid\n\n# Verbose output\nnode ace configure @adonisjs/auth --verbose\n\n# Force configuration (skip prompts)\nnode ace configure @adonisjs/mail --force\n```\n\n### `eject`\n\nExtracts customizable stub files to your application.\n\n```bash\n# Eject a stub file\nnode ace eject make/controller\n\n# Eject from a specific package\nnode ace eject make/policy --pkg=@adonisjs/bouncer\n```\n\n## Generation Commands\n\n### `generate:key`\n\nCreates a secure random encryption key for `.env` file.\n\n```bash\n# Generate and display key\nnode ace generate:key\n\n# Show key without prompting\nnode ace generate:key --show\n\n# Force overwrite existing key\nnode ace generate:key --force\n```\n\n### `make:controller`\n\nGenerates HTTP controller classes.\n\n```bash\n# Create a controller\nnode ace make:controller users\n\n# Create controller with specific actions\nnode ace make:controller users index show store\n\n# Create singular resource controller\nnode ace make:controller user --singular\n\n# Create RESTful resource controller\nnode ace make:controller user --resource\n\n# Create API resource controller (no create/edit views)\nnode ace make:controller user --api\n```\n\n### `make:model`\n\nCreates Lucid model classes.\n\n```bash\n# Create a model\nnode ace make:model User\n\n# Create model with migration\nnode ace make:model User -m\n\n# Create model with factory\nnode ace make:model User -f\n\n# Create model with controller\nnode ace make:model User -c\n\n# Create model with migration, factory, and controller\nnode ace make:model User -mfc\n```\n\n### `make:middleware`\n\nCreates HTTP request middleware.\n\n```bash\n# Create middleware\nnode ace make:middleware bodyparser\n\n# Create server middleware\nnode ace make:middleware bodyparser --stack=server\n\n# Create named middleware\nnode ace make:middleware auth --stack=named\n\n# Create router middleware\nnode ace make:middleware throttle --stack=router\n```\n\n### `make:validator`\n\nCreates VineJS validator files.\n\n```bash\n# Create a validator\nnode ace make:validator user\n\n# Create resource validator (with store/update)\nnode ace make:validator user --resource\n```\n\n### `make:service`\n\nCreates service classes for business logic.\n\n```bash\n# Create a service\nnode ace make:service invoice\n\n# Create a service in subdirectory\nnode ace make:service payments/stripe\n```\n\n### `make:event`\n\nGenerates event classes.\n\n```bash\n# Create an event\nnode ace make:event orderShipped\n\n# Create an event in subdirectory\nnode ace make:event orders/shipped\n```\n\n### `make:listener`\n\nGenerates event listener classes.\n\n```bash\n# Create a listener\nnode ace make:listener sendShipmentNotification\n\n# Create listener for specific event\nnode ace make:listener sendNotification --event=orderShipped\n```\n\n### `make:exception`\n\nGenerates custom exception classes.\n\n```bash\n# Create an exception\nnode ace make:exception commandValidation\n\n# Create an exception in subdirectory\nnode ace make:exception validation/command\n```\n\n### `make:command`\n\nCreates new Ace CLI commands.\n\n```bash\n# Create a command\nnode ace make:command listRoutes\n\n# Create a command in subdirectory\nnode ace make:command admin/cleanup\n```\n\n### `make:view`\n\nGenerates Edge.js template files.\n\n```bash\n# Create a view\nnode ace make:view posts/create\n\n# Create nested view\nnode ace make:view admin/users/index\n```\n\n### `make:provider`\n\nCreates service provider files.\n\n```bash\n# Create a provider\nnode ace make:provider app\n\n# Create provider for specific environments\nnode ace make:provider analytics --environments=web,console\nnode ace make:provider analytics -e=web -e=console\n```\n\n### `make:preload`\n\nGenerates preload files for initialization.\n\n```bash\n# Create a preload file\nnode ace make:preload view\n\n# Create preload for specific environments\nnode ace make:preload routes --environments=web\nnode ace make:preload events -e=web -e=console\n```\n\n### `make:test`\n\nCreates test files.\n\n```bash\n# Create a test\nnode ace make:test user\n\n# Create test in specific suite\nnode ace make:test user --suite=unit\nnode ace make:test auth --suite=functional\n```\n\n### `make:mail`\n\nGenerates mail notification classes.\n\n```bash\n# Create a mail class\nnode ace make:mail shipment\n\n# Create confirmation mail\nnode ace make:mail verification --intent=confirmation\n```\n\n### `make:policy`\n\nCreates Bouncer policy classes.\n\n```bash\n# Create a policy\nnode ace make:policy post\n\n# Create a policy for specific model\nnode ace make:policy comment\n```\n\n## Database Commands (Lucid)\n\n### Migration Commands\n\n```bash\n# Create a new migration\nnode ace make:migration users\n\n# Create migration with model\nnode ace make:model User -m\n\n# Run all pending migrations\nnode ace migration:run\n\n# Preview migration changes (dry run)\nnode ace migration:run --dry-run\n\n# Force run migrations in production\nnode ace migration:run --force\n\n# Run migrations and seed database\nnode ace migration:run --seed\n\n# Rollback latest batch\nnode ace migration:rollback\n\n# Rollback specific batch\nnode ace migration:rollback --batch=1\n\n# Rollback to beginning\nnode ace migration:rollback --batch=0\n\n# Rollback last N migrations\nnode ace migration:rollback --step=3\n\n# Reset all migrations (rollback all)\nnode ace migration:reset\n\n# Refresh migrations (reset + run)\nnode ace migration:refresh\n\n# Refresh and seed\nnode ace migration:refresh --seed\n\n# Fresh migrations (drop all tables + run)\nnode ace migration:fresh\n\n# Fresh and seed\nnode ace migration:fresh --seed\n\n# Check migration status\nnode ace migration:status\n```\n\n### Seeder Commands\n\n```bash\n# Create a seeder\nnode ace make:seeder User\n\n# Run all seeders\nnode ace db:seed\n\n# Run specific seeder files\nnode ace db:seed --files \"./database/seeders/user_seeder.ts\"\n\n# Run multiple seeders\nnode ace db:seed --files \"./database/seeders/user_seeder.ts\" --files \"./database/seeders/post_seeder.ts\"\n\n# Interactive seeder selection\nnode ace db:seed -i\n\n# Seed specific database connection\nnode ace db:seed --connection=tenant-1\n```\n\n### Factory Commands\n\n```bash\n# Create a factory\nnode ace make:factory User\n\n# Create model with factory\nnode ace make:model User -f\n```\n\n### Database Utility Commands\n\n```bash\n# Wipe database (drop all tables)\nnode ace db:wipe\n\n# Wipe specific connection\nnode ace db:wipe --connection=pg\n\n# Truncate all tables\nnode ace db:truncate\n\n# Seed after truncate\nnode ace db:truncate --seed\n```\n\n## Utility Commands\n\n### `list:routes`\n\nShows all registered application routes.\n\n```bash\n# List all routes\nnode ace list:routes\n\n# Output as JSON\nnode ace list:routes --json\n\n# Output as table (default)\nnode ace list:routes --table\n\n# Show middleware for each route\nnode ace list:routes --middleware\n\n# Hide middleware column\nnode ace list:routes --ignore-middleware\n```\n\n### `inspect:rcfile`\n\nDisplays merged `adonisrc.ts` configuration.\n\n```bash\n# Inspect configuration\nnode ace inspect:rcfile\n```\n\n### `env:add`\n\nAdds environment variables to `.env` files with validation.\n\n```bash\n# Interactive mode\nnode ace env:add\n\n# Add specific variable\nnode ace env:add MY_VARIABLE value\n\n# Add with type validation\nnode ace env:add API_KEY secret --type=string\nnode ace env:add DEBUG true --type=boolean\nnode ace env:add PORT 3333 --type=number\n\n# Add enum variable\nnode ace env:add NODE_ENV production --type=enum --enum-values=development,staging,production\n```\n\n## Testing Commands\n\n```bash\n# Run all tests\nnode ace test\n\n# Run specific test file\nnode ace test tests/unit/user.spec.ts\n\n# Run tests in watch mode\nnode ace test --watch\n\n# Run tests with coverage\nnode ace test --coverage\n```\n\n## Command Aliases\n\nDefine shortcuts in `adonisrc.ts`:\n\n```typescript\nexport default {\n\tcommandsAliases: {\n\t\t// Shortcut for creating resource controllers\n\t\tresource: \"make:controller --resource --singular\",\n\n\t\t// Shortcut for migration refresh with seed\n\t\tmigrate: \"migration:refresh --seed\",\n\n\t\t// Shortcut for creating full model stack\n\t\tmodel: \"make:model -mfc\",\n\t},\n};\n```\n\n**Usage:**\n\n```bash\n# Use alias\nnode ace resource admin\n\n# Expands to\nnode ace make:controller --resource --singular admin\n```\n\n## Package-Specific Commands\n\n### After Installing Packages\n\n```bash\n# Install Lucid (ORM)\nnode ace add @adonisjs/lucid\n\n# Install Auth\nnode ace add @adonisjs/auth\n\n# Install Mail\nnode ace add @adonisjs/mail\n\n# Install Redis\nnode ace add @adonisjs/redis\n\n# Install Bouncer (Authorization)\nnode ace add @adonisjs/bouncer\n\n# Install Ally (Social Auth)\nnode ace add @adonisjs/ally\n\n# Install Shield (Security)\nnode ace add @adonisjs/shield\n\n# Install Session\nnode ace add @adonisjs/session\n\n# Install I18n\nnode ace add @adonisjs/i18n\n\n# Install Drive (File Storage)\nnode ace add @adonisjs/drive\n\n# Install Limiter (Rate Limiting)\nnode ace add @adonisjs/limiter\n```\n\nEach package adds its own commands after installation. Use `node ace list` to see all available commands.\n\n## Programmatic Command Execution\n\nExecute commands within your application code:\n\n```typescript\nimport ace from \"@adonisjs/core/services/ace\";\n\n// Boot ace\nawait ace.boot();\n\n// Check if command exists\nif (ace.hasCommand(\"make:controller\")) {\n\t// Execute command\n\tconst command = await ace.exec(\"make:controller\", [\"user\", \"--resource\"]);\n\n\t// Check results\n\tconsole.log(command.exitCode);\n\tconsole.log(command.result);\n\tconsole.log(command.error);\n}\n```\n",
        "plugins/dev/skills/adonisjs-cli/reference/common-patterns.md": "# AdonisJS Common Patterns\n\nReal-world patterns and workflows for common AdonisJS development scenarios.\n\n## Project Setup Patterns\n\n### New API Project\n\n```bash\n# Create new AdonisJS project\nnpm init adonisjs@latest my-api -- --kit=api\n\n# Navigate to project\ncd my-api\n\n# Generate app key\nnode ace generate:key\n\n# Install database package\nnode ace add @adonisjs/lucid\n\n# Configure database connection\nnode ace configure @adonisjs/lucid\n\n# Create initial migration\nnode ace make:migration users\n\n# Run migrations\nnode ace migration:run\n\n# Start development server\nnode ace serve --hmr\n```\n\n### Full-Stack Web App Setup\n\n```bash\n# Create with web starter kit\nnpm init adonisjs@latest my-app -- --kit=web\n\ncd my-app\n\n# Generate app key\nnode ace generate:key\n\n# Add database\nnode ace add @adonisjs/lucid\n\n# Add authentication\nnode ace add @adonisjs/auth\n\n# Add session support\nnode ace add @adonisjs/session\n\n# Add CSRF protection\nnode ace add @adonisjs/shield\n\n# Run migrations\nnode ace migration:run\n\n# Start dev server with HMR\nnode ace serve --hmr\n```\n\n## CRUD Resource Patterns\n\n### Complete Resource Workflow\n\n```bash\n# Create model with migration, factory, and controller\nnode ace make:model Post -mfc\n\n# Create validator for the resource\nnode ace make:validator post --resource\n\n# Create service for business logic\nnode ace make:service post\n\n# Create policy for authorization\nnode ace make:policy post\n\n# Run migration\nnode ace migration:run\n\n# Create seeder for testing\nnode ace make:seeder Post\n\n# Run seeder\nnode ace db:seed\n```\n\n### Controller Structure\n\n**RESTful API Controller:**\n\n```typescript\n// app/controllers/posts_controller.ts\nimport type { HttpContext } from '@adonisjs/core/http'\nimport Post from '#models/post'\nimport { createPostValidator, updatePostValidator } from '#validators/post'\n\nexport default class PostsController {\n  // GET /posts\n  async index({ response }: HttpContext) {\n    const posts = await Post.all()\n    return response.ok(posts)\n  }\n\n  // POST /posts\n  async store({ request, response }: HttpContext) {\n    const payload = await request.validateUsing(createPostValidator)\n    const post = await Post.create(payload)\n    return response.created(post)\n  }\n\n  // GET /posts/:id\n  async show({ params, response }: HttpContext) {\n    const post = await Post.findOrFail(params.id)\n    return response.ok(post)\n  }\n\n  // PUT /posts/:id\n  async update({ params, request, response }: HttpContext) {\n    const post = await Post.findOrFail(params.id)\n    const payload = await request.validateUsing(updatePostValidator)\n    await post.merge(payload).save()\n    return response.ok(post)\n  }\n\n  // DELETE /posts/:id\n  async destroy({ params, response }: HttpContext) {\n    const post = await Post.findOrFail(params.id)\n    await post.delete()\n    return response.noContent()\n  }\n}\n```\n\n### Migration Patterns\n\n**Basic Table Creation:**\n\n```typescript\n// database/migrations/xxxxx_create_posts_table.ts\nimport { BaseSchema } from '@adonisjs/lucid/schema'\n\nexport default class extends BaseSchema {\n  protected tableName = 'posts'\n\n  async up() {\n    this.schema.createTable(this.tableName, (table) => {\n      table.increments('id')\n      table.string('title').notNullable()\n      table.text('content').notNullable()\n      table.integer('user_id').unsigned().references('users.id').onDelete('CASCADE')\n      table.boolean('is_published').defaultTo(false)\n      table.timestamp('published_at').nullable()\n      table.timestamp('created_at', { useTz: true })\n      table.timestamp('updated_at', { useTz: true })\n    })\n  }\n\n  async down() {\n    this.schema.dropTable(this.tableName)\n  }\n}\n```\n\n**Add Column Migration:**\n\n```typescript\n// database/migrations/xxxxx_add_slug_to_posts.ts\nimport { BaseSchema } from '@adonisjs/lucid/schema'\n\nexport default class extends BaseSchema {\n  protected tableName = 'posts'\n\n  async up() {\n    this.schema.alterTable(this.tableName, (table) => {\n      table.string('slug').unique().notNullable().after('title')\n    })\n  }\n\n  async down() {\n    this.schema.alterTable(this.tableName, (table) => {\n      table.dropColumn('slug')\n    })\n  }\n}\n```\n\n### Model Relationships\n\n**One-to-Many:**\n\n```typescript\n// app/models/user.ts\nimport { BaseModel, hasMany } from '@adonisjs/lucid/orm'\nimport type { HasMany } from '@adonisjs/lucid/types/relations'\nimport Post from '#models/post'\n\nexport default class User extends BaseModel {\n  @hasMany(() => Post)\n  declare posts: HasMany<typeof Post>\n}\n\n// app/models/post.ts\nimport { BaseModel, belongsTo } from '@adonisjs/lucid/orm'\nimport type { BelongsTo } from '@adonisjs/lucid/types/relations'\nimport User from '#models/user'\n\nexport default class Post extends BaseModel {\n  @belongsTo(() => User)\n  declare user: BelongsTo<typeof User>\n}\n\n// Usage in controller\nconst user = await User.query().preload('posts')\nconst post = await Post.query().preload('user').first()\n```\n\n**Many-to-Many:**\n\n```typescript\n// app/models/post.ts\nimport { BaseModel, manyToMany } from '@adonisjs/lucid/orm'\nimport type { ManyToMany } from '@adonisjs/lucid/types/relations'\nimport Tag from '#models/tag'\n\nexport default class Post extends BaseModel {\n  @manyToMany(() => Tag)\n  declare tags: ManyToMany<typeof Tag>\n}\n\n// app/models/tag.ts\nimport { BaseModel, manyToMany } from '@adonisjs/lucid/orm'\nimport type { ManyToMany } from '@adonisjs/lucid/types/relations'\nimport Post from '#models/post'\n\nexport default class Tag extends BaseModel {\n  @manyToMany(() => Post)\n  declare posts: ManyToMany<typeof Post>\n}\n\n// Usage\nconst post = await Post.query().preload('tags')\nawait post.related('tags').attach([1, 2, 3])\nawait post.related('tags').detach([2])\n```\n\n## Validation Patterns\n\n### Resource Validator\n\n```typescript\n// app/validators/post.ts\nimport vine from '@vinejs/vine'\n\nexport const createPostValidator = vine.compile(\n  vine.object({\n    title: vine.string().minLength(3).maxLength(255),\n    content: vine.string().minLength(10),\n    isPublished: vine.boolean().optional(),\n  })\n)\n\nexport const updatePostValidator = vine.compile(\n  vine.object({\n    title: vine.string().minLength(3).maxLength(255).optional(),\n    content: vine.string().minLength(10).optional(),\n    isPublished: vine.boolean().optional(),\n  })\n)\n```\n\n### Custom Validation Rules\n\n```typescript\n// app/validators/user.ts\nimport vine from '@vinejs/vine'\n\nconst uniqueEmail = vine.createRule(async (value, options, field) => {\n  const user = await User.findBy('email', value)\n  if (user) {\n    field.report('The email has already been taken', 'unique', field)\n  }\n})\n\nexport const createUserValidator = vine.compile(\n  vine.object({\n    email: vine.string().email().use(uniqueEmail()),\n    password: vine.string().minLength(8),\n  })\n)\n```\n\n## Authentication Patterns\n\n### Session Authentication Setup\n\n```bash\n# Install required packages\nnode ace add @adonisjs/auth\nnode ace add @adonisjs/session\n\n# Create auth scaffolding\nnode ace make:controller auth/login\nnode ace make:controller auth/register\nnode ace make:middleware auth\n```\n\n**Login Controller:**\n\n```typescript\n// app/controllers/auth/login_controller.ts\nimport type { HttpContext } from '@adonisjs/core/http'\nimport User from '#models/user'\n\nexport default class LoginController {\n  async store({ request, auth, response }: HttpContext) {\n    const { email, password } = request.only(['email', 'password'])\n\n    const user = await User.verifyCredentials(email, password)\n    await auth.use('web').login(user)\n\n    return response.redirect('/dashboard')\n  }\n\n  async destroy({ auth, response }: HttpContext) {\n    await auth.use('web').logout()\n    return response.redirect('/login')\n  }\n}\n```\n\n### API Token Authentication\n\n```typescript\n// app/controllers/auth/tokens_controller.ts\nimport type { HttpContext } from '@adonisjs/core/http'\nimport User from '#models/user'\n\nexport default class TokensController {\n  async store({ request, response }: HttpContext) {\n    const { email, password } = request.only(['email', 'password'])\n\n    const user = await User.verifyCredentials(email, password)\n    const token = await User.accessTokens.create(user)\n\n    return response.created({ token: token.value!.release() })\n  }\n\n  async destroy({ auth, response }: HttpContext) {\n    const user = auth.getUserOrFail()\n    await User.accessTokens.delete(user, user.currentAccessToken.identifier)\n\n    return response.noContent()\n  }\n}\n```\n\n## Service Layer Pattern\n\n```typescript\n// app/services/post_service.ts\nimport Post from '#models/post'\nimport type { CreatePostData, UpdatePostData } from '#types/post'\n\nexport default class PostService {\n  async createPost(userId: number, data: CreatePostData) {\n    const post = await Post.create({\n      ...data,\n      userId,\n    })\n\n    // Additional business logic\n    await this.notifySubscribers(post)\n\n    return post\n  }\n\n  async updatePost(postId: number, data: UpdatePostData) {\n    const post = await Post.findOrFail(postId)\n    await post.merge(data).save()\n\n    return post\n  }\n\n  async publishPost(postId: number) {\n    const post = await Post.findOrFail(postId)\n\n    post.isPublished = true\n    post.publishedAt = DateTime.now()\n\n    await post.save()\n    await this.notifySubscribers(post)\n\n    return post\n  }\n\n  private async notifySubscribers(post: Post) {\n    // Business logic for notifications\n  }\n}\n```\n\n**Usage in Controller:**\n\n```typescript\n// app/controllers/posts_controller.ts\nimport PostService from '#services/post_service'\n\nexport default class PostsController {\n  async store({ request, auth, response }: HttpContext) {\n    const user = auth.getUserOrFail()\n    const data = await request.validateUsing(createPostValidator)\n\n    const postService = new PostService()\n    const post = await postService.createPost(user.id, data)\n\n    return response.created(post)\n  }\n}\n```\n\n## Event-Driven Patterns\n\n### Event and Listener Setup\n\n```bash\n# Create event\nnode ace make:event order_placed\n\n# Create listener\nnode ace make:listener send_order_confirmation --event=order_placed\n```\n\n**Event Class:**\n\n```typescript\n// app/events/order_placed.ts\nimport { BaseEvent } from '@adonisjs/core/events'\nimport type Order from '#models/order'\n\nexport default class OrderPlaced extends BaseEvent {\n  constructor(public order: Order) {\n    super()\n  }\n}\n```\n\n**Listener Class:**\n\n```typescript\n// app/listeners/send_order_confirmation.ts\nimport emitter from '@adonisjs/core/services/emitter'\nimport mail from '@adonisjs/mail/services/main'\nimport OrderPlaced from '#events/order_placed'\n\nexport default class SendOrderConfirmation {\n  async handle(event: OrderPlaced) {\n    await mail.send((message) => {\n      message\n        .to(event.order.email)\n        .subject('Order Confirmation')\n        .htmlView('emails/order_confirmation', { order: event.order })\n    })\n  }\n}\n\n// Register listener\nemitter.on(OrderPlaced, [SendOrderConfirmation])\n```\n\n**Emit Event:**\n\n```typescript\n// In controller or service\nimport emitter from '@adonisjs/core/services/emitter'\nimport OrderPlaced from '#events/order_placed'\n\nconst order = await Order.create(data)\nemitter.emit(new OrderPlaced(order))\n```\n\n## Testing Patterns\n\n### Functional Test\n\n```typescript\n// tests/functional/posts/create.spec.ts\nimport { test } from '@japa/runner'\nimport User from '#models/user'\n\ntest.group('Posts create', () => {\n  test('creates a new post', async ({ client, assert }) => {\n    const user = await User.create({\n      email: 'test@example.com',\n      password: 'secret',\n    })\n\n    const response = await client\n      .post('/posts')\n      .loginAs(user)\n      .json({\n        title: 'Test Post',\n        content: 'This is a test post',\n      })\n\n    response.assertStatus(201)\n    response.assertBodyContains({\n      title: 'Test Post',\n      content: 'This is a test post',\n    })\n  })\n})\n```\n\n### Unit Test\n\n```typescript\n// tests/unit/services/post_service.spec.ts\nimport { test } from '@japa/runner'\nimport PostService from '#services/post_service'\n\ntest.group('Post service', () => {\n  test('generates correct slug from title', async ({ assert }) => {\n    const service = new PostService()\n    const slug = service.generateSlug('This is a Test Post!')\n\n    assert.equal(slug, 'this-is-a-test-post')\n  })\n})\n```\n\n## Database Seeding Patterns\n\n### Factory Definition\n\n```typescript\n// database/factories/user_factory.ts\nimport factory from '@adonisjs/lucid/factories'\nimport User from '#models/user'\n\nexport const UserFactory = factory\n  .define(User, async ({ faker }) => {\n    return {\n      email: faker.internet.email(),\n      password: 'secret',\n      fullName: faker.person.fullName(),\n    }\n  })\n  .build()\n```\n\n### Seeder with Relationships\n\n```typescript\n// database/seeders/database_seeder.ts\nimport { BaseSeeder } from '@adonisjs/lucid/seeders'\nimport { UserFactory } from '#database/factories/user_factory'\n\nexport default class DatabaseSeeder extends BaseSeeder {\n  async run() {\n    // Create users with posts\n    const users = await UserFactory.with('posts', 5).createMany(10)\n\n    // Create specific admin user\n    const admin = await UserFactory.merge({\n      email: 'admin@example.com',\n      isAdmin: true,\n    }).create()\n  }\n}\n```\n\n## Production Build Pattern\n\n```bash\n# Build application\nnode ace build\n\n# Navigate to build directory\ncd build\n\n# Install production dependencies only\nnpm ci --production\n\n# Set environment to production\nexport NODE_ENV=production\n\n# Run migrations\nnode ace migration:run --force\n\n# Start production server\nnode server.js\n\n# Or with PM2\npm2 start server.js --name \"my-api\"\n```\n\n## Custom Command Pattern\n\n```typescript\n// commands/cleanup_old_posts.ts\nimport { BaseCommand } from '@adonisjs/core/ace'\nimport { args, flags } from '@adonisjs/core/ace'\nimport Post from '#models/post'\nimport { DateTime } from 'luxon'\n\nexport default class CleanupOldPosts extends BaseCommand {\n  static commandName = 'cleanup:old-posts'\n  static description = 'Delete posts older than specified days'\n\n  @args.number({ description: 'Number of days' })\n  declare days: number\n\n  @flags.boolean({ description: 'Perform dry run' })\n  declare dryRun: boolean\n\n  async run() {\n    const threshold = DateTime.now().minus({ days: this.days })\n\n    const query = Post.query().where('created_at', '<', threshold.toISO())\n\n    if (this.dryRun) {\n      const count = await query.count('* as total')\n      this.logger.info(`Would delete ${count[0].total} posts`)\n      return\n    }\n\n    const deleted = await query.delete()\n    this.logger.success(`Deleted ${deleted} posts`)\n  }\n}\n```\n\n**Usage:**\n\n```bash\n# Run command\nnode ace cleanup:old-posts 30\n\n# Dry run\nnode ace cleanup:old-posts 30 --dry-run\n```\n",
        "plugins/dev/skills/adonisjs-cli/reference/troubleshooting.md": "# AdonisJS Troubleshooting Guide\n\nCommon issues and solutions for AdonisJS development.\n\n## Server Issues\n\n### Server Won't Start\n\n**Symptom:** `node ace serve` fails immediately\n\n**Diagnosis:**\n\n```bash\n# Check for syntax errors\nnpm run typecheck\n\n# View detailed error output\nnode ace serve --no-clear\n\n# Check if port is already in use\nlsof -i :3333\n```\n\n**Common Causes:**\n\n1. **Port already in use**\n   ```bash\n   # Solution: Kill process using the port\n   lsof -i :3333\n   kill -9 <PID>\n\n   # Or use different port in .env\n   PORT=3334\n   ```\n\n2. **Missing APP_KEY**\n   ```bash\n   # Solution: Generate app key\n   node ace generate:key\n   ```\n\n3. **Module not found errors**\n   ```bash\n   # Solution: Reinstall dependencies\n   npm install\n\n   # Clear build cache\n   rm -rf build/\n   node ace serve\n   ```\n\n4. **TypeScript compilation errors**\n   ```bash\n   # Solution: Fix type errors or ignore temporarily\n   node ace serve --ignore-ts-errors\n   ```\n\n### Hot Module Replacement Not Working\n\n**Symptom:** Changes don't reflect without manual restart\n\n**Diagnosis:**\n\n```bash\n# Check if HMR is enabled\nnode ace serve --hmr\n\n# For Docker/WSL, use polling\nnode ace serve --hmr --poll\n```\n\n**Solutions:**\n\n```bash\n# Enable HMR\nnode ace serve --hmr\n\n# For file systems that don't support watch (Docker, WSL, VMs)\nnode ace serve --poll\n\n# Disable asset building if causing issues\nnode ace serve --no-assets\n```\n\n## Database Issues\n\n### Migration Fails\n\n**Symptom:** `node ace migration:run` throws error\n\n**Diagnosis:**\n\n```bash\n# Check migration status\nnode ace migration:status\n\n# Check database connection\n# Verify .env credentials\n\n# View migration file for syntax errors\ncat database/migrations/xxxxx_migration_name.ts\n```\n\n**Common Errors:**\n\n**Error: \"Table already exists\"**\n```bash\n# Solution: Check migration status and rollback if needed\nnode ace migration:status\nnode ace migration:rollback\n\n# Or reset and re-run\nnode ace migration:reset\nnode ace migration:run\n```\n\n**Error: \"Connection refused\"**\n```bash\n# Solution: Check database is running\n# For PostgreSQL\npg_isready\n\n# For MySQL\nmysql -u root -p -e \"status\"\n\n# Verify .env configuration\nDB_HOST=127.0.0.1\nDB_PORT=5432\nDB_USER=postgres\nDB_PASSWORD=secret\nDB_DATABASE=mydb\n```\n\n**Error: \"Syntax error in migration\"**\n```bash\n# Solution: Check migration file syntax\n# Common issues:\n# - Missing commas in table definitions\n# - Incorrect method names\n# - Missing references setup\n\n# Example fix:\nthis.schema.createTable(this.tableName, (table) => {\n  table.increments('id')\n  table.string('name')  // Missing comma\n  table.integer('user_id').unsigned()\n    .references('id').inTable('users')  // Proper reference\n})\n```\n\n### Cannot Connect to Database\n\n**Symptom:** Database connection timeout or refused\n\n**Diagnosis:**\n\n```bash\n# Test database connection manually\n# PostgreSQL\npsql -h localhost -U postgres -d mydb\n\n# MySQL\nmysql -h localhost -u root -p mydb\n\n# Check if database server is running\n# PostgreSQL\npg_isready\n\n# MySQL\nmysqladmin ping\n```\n\n**Solutions:**\n\n```bash\n# Verify .env configuration\nDB_CONNECTION=pg\nDB_HOST=127.0.0.1\nDB_PORT=5432\nDB_USER=your_user\nDB_PASSWORD=your_password\nDB_DATABASE=your_database\n\n# For Docker containers, use container name as host\nDB_HOST=postgres  # If using docker-compose with service named 'postgres'\n\n# Check firewall rules\nsudo ufw status\n\n# Ensure database accepts connections\n# Edit PostgreSQL pg_hba.conf or MySQL config\n```\n\n### Lucid Model Not Found\n\n**Symptom:** \"Cannot find module '#models/user'\"\n\n**Solutions:**\n\n```bash\n# Ensure path aliases are configured in adonisrc.ts\n{\n  \"alias\": {\n    \"#models\": \"./app/models\"\n  }\n}\n\n# Restart TypeScript server in IDE\n# VS Code: Cmd+Shift+P -> \"TypeScript: Restart TS server\"\n\n# Check model file exists\nls app/models/user.ts\n```\n\n## Authentication Issues\n\n### Session Not Persisting\n\n**Symptom:** User gets logged out on every request\n\n**Diagnosis:**\n\n```bash\n# Check if session middleware is registered\n# start/kernel.ts should have:\nrouter.use([\n  () => import('@adonisjs/session/session_middleware')\n])\n\n# Verify APP_KEY is set in .env\necho $APP_KEY\n```\n\n**Solutions:**\n\n```bash\n# Generate APP_KEY if missing\nnode ace generate:key\n\n# Ensure session package is installed\nnode ace add @adonisjs/session\n\n# Check session driver in config/session.ts\n{\n  driver: env.get('SESSION_DRIVER', 'cookie')\n}\n\n# For Redis sessions, ensure Redis is running\nredis-cli ping\n```\n\n### Invalid Credentials Error\n\n**Symptom:** Login fails with valid credentials\n\n**Diagnosis:**\n\n```typescript\n// Check password hashing in User model\nimport hash from '@adonisjs/core/services/hash'\n\nexport default class User extends BaseModel {\n  @column({ serializeAs: null })\n  declare password: string\n\n  @beforeSave()\n  static async hashPassword(user: User) {\n    if (user.$dirty.password) {\n      user.password = await hash.make(user.password)\n    }\n  }\n}\n```\n\n**Solutions:**\n\n```bash\n# Verify User model has hash import\n# Check verifyCredentials method implementation\n# Ensure password is hashed before saving\n\n# Test manually\nnode ace tinker\nconst user = await User.findBy('email', 'test@example.com')\nawait hash.verify(user.password, 'plain_password')\n```\n\n### Token Authentication Not Working\n\n**Symptom:** API token returns 401 Unauthorized\n\n**Diagnosis:**\n\n```bash\n# Check auth middleware is applied\n# start/routes.ts\nrouter.group(() => {\n  // Protected routes\n}).use(middleware.auth())\n\n# Verify token in request headers\n# Authorization: Bearer <token>\n```\n\n**Solutions:**\n\n```typescript\n// Ensure token guard is configured in config/auth.ts\n{\n  guards: {\n    api: {\n      driver: 'access_tokens',\n      provider: {\n        driver: 'lucid',\n        model: () => import('#models/user')\n      }\n    }\n  }\n}\n\n// Check token is sent correctly\ncurl -H \"Authorization: Bearer YOUR_TOKEN\" http://localhost:3333/api/user\n```\n\n## Validation Issues\n\n### Validation Always Fails\n\n**Symptom:** Request validation returns errors for valid data\n\n**Diagnosis:**\n\n```typescript\n// Check validator definition\nimport vine from '@vinejs/vine'\n\nexport const createUserValidator = vine.compile(\n  vine.object({\n    email: vine.string().email(),\n    password: vine.string().minLength(8)\n  })\n)\n```\n\n**Solutions:**\n\n```typescript\n// Ensure validator is compiled\nexport const validator = vine.compile(schema)  // Correct\n// Not: export const validator = vine.object(...)  // Wrong\n\n// Check field names match request data\nconst payload = await request.validateUsing(validator)\n\n// Debug incoming data\nconsole.log(request.all())\nconsole.log(request.body())\n```\n\n### Custom Validation Rule Not Working\n\n**Symptom:** Custom rule not being executed\n\n**Solutions:**\n\n```typescript\n// Ensure rule is async and properly defined\nimport vine from '@vinejs/vine'\n\nconst uniqueEmail = vine.createRule(async (value, options, field) => {\n  const user = await User.findBy('email', value)\n  if (user) {\n    field.report('Email already taken', 'unique', field)\n  }\n})\n\n// Use the rule correctly\nvine.string().email().use(uniqueEmail())  // Note the ()\n```\n\n## Routing Issues\n\n### Route Not Found (404)\n\n**Symptom:** Request returns 404 for defined route\n\n**Diagnosis:**\n\n```bash\n# List all registered routes\nnode ace list:routes\n\n# Check if route matches exactly\nnode ace list:routes | grep \"/posts\"\n\n# Verify HTTP method matches\nGET /posts vs POST /posts\n```\n\n**Solutions:**\n\n```typescript\n// Check route is defined in start/routes.ts\nrouter.get('/posts', [PostsController, 'index'])\n\n// Ensure route comes before wildcards\nrouter.get('/posts/featured', ...)  // Must be before...\nrouter.get('/posts/:id', ...)       // ...this wildcard route\n\n// For grouped routes, check prefix\nrouter.group(() => {\n  router.get('/posts', [PostsController, 'index'])\n}).prefix('/api')  // Route is actually /api/posts\n```\n\n### Middleware Not Executing\n\n**Symptom:** Middleware doesn't run on route\n\n**Diagnosis:**\n\n```bash\n# Check middleware registration\n# start/kernel.ts\n\n# List routes with middleware\nnode ace list:routes --middleware\n```\n\n**Solutions:**\n\n```typescript\n// Apply middleware to route\nrouter.get('/admin', [AdminController, 'index'])\n  .use(middleware.auth())\n\n// Or to route group\nrouter.group(() => {\n  // Routes\n}).use(middleware.auth())\n\n// Ensure middleware is registered\n// start/kernel.ts\nexport const middleware = router.named({\n  auth: () => import('#middleware/auth_middleware')\n})\n```\n\n## Build & Production Issues\n\n### Build Fails\n\n**Symptom:** `node ace build` throws errors\n\n**Diagnosis:**\n\n```bash\n# Check TypeScript errors\nnpm run typecheck\n\n# View detailed build output\nnode ace build --verbose\n\n# Check for circular dependencies\n```\n\n**Solutions:**\n\n```bash\n# Fix TypeScript errors first\nnpm run typecheck\n\n# Ignore errors temporarily (not recommended)\nnode ace build --ignore-ts-errors\n\n# Clear build directory\nrm -rf build/\nnode ace build\n\n# Check tsconfig.json for correct paths\n{\n  \"compilerOptions\": {\n    \"outDir\": \"./build\",\n    \"rootDir\": \"./\"\n  }\n}\n```\n\n### Production Server Crashes\n\n**Symptom:** Built app crashes on `node server.js`\n\n**Diagnosis:**\n\n```bash\n# Check production logs\nNODE_ENV=production node server.js\n\n# Verify environment variables\ncat .env\n\n# Check if production dependencies are installed\nnpm ci --production\n```\n\n**Common Issues:**\n\n1. **Missing APP_KEY**\n   ```bash\n   # Solution: Set in production .env\n   APP_KEY=your_production_key\n   ```\n\n2. **Database connection in production**\n   ```bash\n   # Run migrations with force flag\n   node ace migration:run --force\n\n   # Check production DB credentials\n   ```\n\n3. **Port configuration**\n   ```bash\n   # Use PORT environment variable\n   PORT=80 node server.js\n\n   # Or set in .env\n   PORT=80\n   HOST=0.0.0.0\n   ```\n\n## Performance Issues\n\n### Slow Query Performance\n\n**Symptom:** API responses are slow\n\n**Diagnosis:**\n\n```typescript\n// Enable query logging\n// config/database.ts\n{\n  connection: 'pg',\n  connections: {\n    pg: {\n      debug: true  // Shows queries in console\n    }\n  }\n}\n```\n\n**Solutions:**\n\n```typescript\n// Add indexes in migrations\nthis.schema.alterTable('posts', (table) => {\n  table.index('user_id')\n  table.index(['is_published', 'created_at'])\n})\n\n// Use preload instead of N+1 queries\n// Bad: N+1 queries\nconst posts = await Post.all()\nfor (const post of posts) {\n  await post.load('user')  // N queries\n}\n\n// Good: Single query with join\nconst posts = await Post.query().preload('user')\n\n// Use pagination\nconst posts = await Post.query().paginate(page, 20)\n```\n\n### Memory Leaks\n\n**Symptom:** Server memory usage keeps growing\n\n**Solutions:**\n\n```typescript\n// Close database connections properly\n// Don't keep models in memory unnecessarily\n\n// Use streams for large datasets\nconst stream = Post.query().stream()\nfor await (const post of stream) {\n  // Process one at a time\n}\n\n// Limit query results\nconst posts = await Post.query().limit(100)\n```\n\n## Testing Issues\n\n### Tests Failing\n\n**Symptom:** Tests fail unexpectedly\n\n**Diagnosis:**\n\n```bash\n# Run specific test\nnode ace test tests/functional/posts.spec.ts\n\n# Run with verbose output\nnode ace test --verbose\n\n# Check test database configuration\n```\n\n**Solutions:**\n\n```typescript\n// Use test database\n// config/database.ts\n{\n  connection: env.get('DB_CONNECTION'),\n  connections: {\n    pg: {\n      client: 'pg',\n      connection: {\n        database: env.get('DB_DATABASE') + '_test'  // Separate test DB\n      }\n    }\n  }\n}\n\n// Reset database before tests\ntest.group('Posts', (group) => {\n  group.each.setup(async () => {\n    await Database.beginGlobalTransaction()\n    return () => Database.rollbackGlobalTransaction()\n  })\n})\n```\n\n## Common Error Messages\n\n### \"Cannot find module\"\n\n```bash\n# Solution: Check import paths and aliases\n# Ensure adonisrc.ts has correct alias configuration\n# Restart TypeScript server in IDE\n```\n\n### \"E_INVALID_SESSION_DRIVER\"\n\n```bash\n# Solution: Install session package\nnode ace add @adonisjs/session\n\n# Configure session driver in config/session.ts\n```\n\n### \"E_UNAUTHORIZED_ACCESS\"\n\n```bash\n# Solution: Check authentication middleware\n# Verify user is logged in\n# Check token in Authorization header\n```\n\n### \"ECONNREFUSED\"\n\n```bash\n# Solution: Database server not running\n# Start PostgreSQL: pg_ctl start\n# Start MySQL: mysql.server start\n# Check connection details in .env\n```\n\n## Debug Tools\n\n### Useful Debug Commands\n\n```bash\n# List all routes with details\nnode ace list:routes --middleware\n\n# Inspect configuration\nnode ace inspect:rcfile\n\n# Check migration status\nnode ace migration:status\n\n# Test with tinker (REPL)\nnode ace tinker\n\n# Check TypeScript compilation\nnpm run typecheck\n\n# View database seeders\nls database/seeders/\n```\n\n### Enable Debug Mode\n\n```typescript\n// .env\nNODE_ENV=development\nLOG_LEVEL=debug\n\n// config/app.ts\n{\n  logger: {\n    enabled: true,\n    level: env.get('LOG_LEVEL', 'info')\n  }\n}\n\n// In code\nimport logger from '@adonisjs/core/services/logger'\n\nlogger.debug('Debug message', { data })\nlogger.info('Info message')\nlogger.error('Error occurred', error)\n```\n",
        "plugins/dev/skills/convex-cli/SKILL.md": "---\nname: convex-cli\ndescription: Convex CLI expert for serverless backend and real-time database. Use when users need to deploy functions, manage environments, or import/export data.\nallowed-tools: Bash(npx convex:*), Bash(bunx convex:*)\n---\n\n# Convex CLI Guide\n\nConvex is a serverless backend platform with a built-in real-time database. This guide provides essential workflows and quick references for common Convex operations.\n\n## Quick Start\n\n```bash\n# Check CLI installation\nconvex --version\n\n# Authenticate with Convex\nconvex login\n\n# Initialize new project\nconvex init\n\n# Start local development\nconvex dev\n\n# Deploy to production\nconvex deploy\n\n# View deployment status\nconvex deployments list\n```\n\n## Common Workflows\n\n### Workflow 1: Local Development Setup\n\n```bash\n# Login and initialize\nconvex login\nconvex init\n\n# Start dev server with hot reload\nconvex dev\n\n# Dev server runs at http://localhost:3210\n# Changes to functions auto-reload\n# Dashboard shows data and logs in real-time\n```\n\n### Workflow 2: Develop and Deploy Functions\n\n```bash\n# Create function in convex/queries/ or convex/mutations/\n\n# Test function locally\nconvex run queries/getUser --args '{\"id\": \"123\"}'\n\n# Deploy to production\nconvex deploy --typecheck\n\n# Monitor logs\nconvex logs --prod --follow\n```\n\n### Workflow 3: Environment Configuration\n\n```bash\n# Set API keys for current environment\nconvex env set API_KEY sk_test_123\nconvex env set DATABASE_URL postgres://...\n\n# Set production secrets\nconvex env set SECRET_KEY value --prod\n\n# List all variables\nconvex env list\n```\n\n### Workflow 4: Data Import & Export\n\n```bash\n# Export data before major changes\nconvex export --all --output backup.json\n\n# Import seed data\nconvex import users seed-users.json\n\n# Batch import multiple tables\nconvex import --all data/\n\n# Backup production data\nconvex export --all --prod --output prod-backup.json\n```\n\n### Workflow 5: Debugging Production Issues\n\n```bash\n# Stream production logs\nconvex logs --prod --follow\n\n# Filter logs by function\nconvex logs --function myFunction --level error\n\n# Test function in production\nconvex run queries/getUser --args '{\"id\": \"123\"}' --prod\n\n# View all function executions\nconvex dashboard --logs\n```\n\n## Decision Tree\n\n**When to use which command:**\n\n- **To start developing**: Use `convex dev` for local server with hot reload\n- **To test functions locally**: Use `convex run function-name --args '...'`\n- **To deploy code**: Use `convex deploy` with `--typecheck` and `--dry-run` first\n- **To manage secrets**: Use `convex env set/get/list` commands\n- **To backup data**: Use `convex export --all --output backup.json`\n- **To restore data**: Use `convex import table-name file.json`\n- **To view logs**: Use `convex logs --follow` for real-time monitoring\n- **For detailed command syntax**: See [Commands Reference](./reference/commands-reference.md)\n- **For complex workflows**: See [Common Patterns](./reference/common-patterns.md)\n- **For troubleshooting**: See [Troubleshooting Guide](./reference/troubleshooting.md)\n\n## Common Patterns\n\n### Development Cycle\n\n```bash\n# 1. Start development\nconvex dev\n\n# 2. Edit functions in convex/queries/, convex/mutations/\n\n# 3. Test locally\nconvex run queries/myFunction --args '{\"key\": \"value\"}'\n\n# 4. Type check and deploy\nconvex deploy --typecheck\n\n# 5. Monitor\nconvex logs --prod --follow\n```\n\n### Safe Deployments\n\n```bash\n# Preview changes\nconvex deploy --dry-run\n\n# Deploy with message\nconvex deploy --message \"feat: added user authentication\"\n\n# Monitor after deploy\nconvex logs --prod --limit 50\n```\n\n### Environment Setup\n\n```bash\n# Development variables\nconvex env set NODE_ENV development\nconvex env set LOG_LEVEL debug\n\n# Production variables\nconvex env set NODE_ENV production --prod\nconvex env set LOG_LEVEL error --prod\n\n# Verify variables\nconvex env list\nconvex env list --prod\n```\n\n### Data Management\n\n```bash\n# Regular backups\nconvex export --all --output \"backup-$(date +%Y-%m-%d).json\"\n\n# Seed data for testing\nconvex import users test-data/users.json\n\n# Database migrations\nconvex export --all --output pre-migration.json\n# Update schema.ts\nconvex deploy\n# Verify with: convex run queries/checkSchema\n```\n\n## Troubleshooting\n\n**Common Issues:**\n\n1. **Dev server won't start**\n   - Solution: Use `convex dev --clear-deployment` to reset state\n   - See: [Development Server Issues](./reference/troubleshooting.md#development-server-issues)\n\n2. **Function not found error**\n   - Quick fix: Ensure function is exported and path is correct\n   - See: [Function Not Found](./reference/troubleshooting.md#function-not-found-error)\n\n3. **Environment variables not loading**\n   - Quick fix: Run `convex env set KEY value` and redeploy\n   - See: [Environment Variable Issues](./reference/troubleshooting.md#environment-variable-issues)\n\n4. **Deployment fails with type errors**\n   - Quick fix: Run `convex deploy --typecheck` to check types first\n   - See: [Deployment Issues](./reference/troubleshooting.md#deployment-fails)\n\n5. **Cannot access production data**\n   - Quick fix: Use `--prod` flag with commands\n   - See: [Access Issues](./reference/troubleshooting.md#project-configuration-issues)\n\nFor detailed troubleshooting steps, see the [Troubleshooting Guide](./reference/troubleshooting.md).\n\n## Reference Files\n\n**Load as needed for detailed information:**\n\n- **[Commands Reference](./reference/commands-reference.md)** - Complete CLI command documentation with all flags and options. Use when you need exact syntax or flag details for any Convex command.\n\n- **[Common Patterns](./reference/common-patterns.md)** - Real-world patterns and workflows for development, data management, deployment, team collaboration, monitoring, and CI/CD integration. Use for implementing specific workflows or integrations.\n\n- **[Troubleshooting Guide](./reference/troubleshooting.md)** - Detailed error messages, diagnosis steps, and resolution strategies for authentication, development, deployment, functions, data, environment, and configuration issues. Use when encountering errors or unexpected behavior.\n\n**When to use each reference:**\n\n- Use **Commands Reference** when you need exact syntax, flag combinations, or comprehensive command documentation\n- Use **Common Patterns** for implementing multi-environment setups, production configurations, or CI/CD pipelines\n- Use **Troubleshooting** when dev server won't start, deployments fail, logs aren't showing, or you encounter permission/access/performance issues\n\n## Resources\n\n- Official Docs: https://docs.convex.dev\n- Dashboard: https://dashboard.convex.dev\n- API Reference: https://docs.convex.dev/api\n- Community: https://discord.gg/convex\n",
        "plugins/dev/skills/convex-cli/reference/commands-reference.md": "# Convex CLI Commands Reference\n\nComplete reference for all Convex CLI commands with detailed options and flags.\n\n## Authentication\n\n### `convex login`\n\nAuthenticate with Convex account.\n\n```bash\n# Login to Convex\nconvex login\n\n# Show authentication status\nconvex whoami\n\n# Logout from Convex\nconvex logout\n```\n\n## Project Management\n\n### `convex init`\n\nInitialize a new Convex project.\n\n```bash\n# Initialize Convex in current project\nconvex init\n\n# Initialize with specific project\nconvex init --project my-project\n\n# Reinitialize configuration\nconvex reinit\n```\n\n### `convex projects`\n\nManage Convex projects.\n\n```bash\n# List all projects\nconvex projects list\n\n# Create new project\nconvex projects create\n\n# Delete project\nconvex projects delete project-name\n```\n\n### `convex teams`\n\nManage teams.\n\n```bash\n# List teams\nconvex teams list\n\n# Create new team\nconvex teams create\n\n# Switch active team\nconvex teams switch team-name\n```\n\n## Development & Deployment\n\n### `convex dev`\n\nStart local development environment with hot reloading.\n\n```bash\n# Start development server\nconvex dev\n\n# Start with specific team\nconvex dev --team my-team\n\n# Start with specific project\nconvex dev --project my-project\n\n# Start on custom port\nconvex dev --admin-port 3001\n\n# Start without opening dashboard\nconvex dev --no-open\n\n# Verbose logging\nconvex dev --verbose\n\n# Clear deployment and restart\nconvex dev --clear-deployment\n\n# With type checking\nconvex dev --typecheck\n\n# Watch for file changes\nconvex dev --watch\n\n# Disable watching\nconvex dev --no-watch\n\n# With code generation\nconvex dev --codegen\n```\n\n### `convex deploy`\n\nDeploy functions to production.\n\n```bash\n# Deploy to production\nconvex deploy\n\n# Deploy with message\nconvex deploy --message \"Added new features\"\n\n# Deploy with type checking\nconvex deploy --typecheck\n\n# Preview before deploying\nconvex deploy --dry-run\n\n# Deploy to specific deployment\nconvex deploy --deployment-name my-deployment\n\n# Auto-confirm prompts\nconvex deploy --yes\n```\n\n### `convex deployments list`\n\nList all deployments.\n\n```bash\n# List deployments\nconvex deployments list\n\n# List with details\nconvex deployments list --verbose\n```\n\n## Function Execution\n\n### `convex run`\n\nExecute a Convex function.\n\n```bash\n# Run a query function\nconvex run myFunction\n\n# Run with arguments\nconvex run myFunction --args '{\"key\": \"value\"}'\n\n# Run mutation\nconvex run myMutation --args '{\"id\": \"123\"}'\n\n# Run in production\nconvex run myFunction --prod\n\n# Run with JSON file input\nconvex run myFunction --args-file args.json\n```\n\n## Data Operations\n\n### `convex import`\n\nImport data into Convex tables.\n\n```bash\n# Import data from JSON file\nconvex import tableName data.json\n\n# Import with replacements\nconvex import tableName data.json --replace\n\n# Import from specific directory\nconvex import tableName data/\n\n# Batch import multiple tables\nconvex import --all data/\n```\n\n### `convex export`\n\nExport data from Convex tables.\n\n```bash\n# Export specific table\nconvex export tableName\n\n# Export all tables\nconvex export --all\n\n# Export to specific file\nconvex export tableName --output data.json\n\n# Export with format\nconvex export tableName --format jsonl\n\n# Export from production\nconvex export tableName --prod\n```\n\n### `convex data`\n\nManage database operations.\n\n```bash\n# View data in browser\nconvex data\n\n# Open data dashboard\nconvex dashboard --data\n\n# Clear all tables (DANGER)\nconvex data clear --all\n```\n\n## Environment Management\n\n### `convex env list`\n\nList environment variables.\n\n```bash\n# List environment variables\nconvex env list\n\n# List for production\nconvex env list --prod\n\n# List for specific deployment\nconvex env list --deployment-name my-deployment\n```\n\n### `convex env set`\n\nSet environment variables.\n\n```bash\n# Set environment variable\nconvex env set KEY value\n\n# Set multiple variables\nconvex env set KEY1 value1 KEY2 value2\n\n# Set for production\nconvex env set KEY value --prod\n\n# Set from .env file\nconvex env set --env-file .env.local\n```\n\n### `convex env get`\n\nGet environment variable value.\n\n```bash\n# Get specific variable\nconvex env get KEY\n\n# Get for production\nconvex env get KEY --prod\n```\n\n### `convex env unset`\n\nRemove environment variables.\n\n```bash\n# Unset environment variable\nconvex env unset KEY\n\n# Unset multiple variables\nconvex env unset KEY1 KEY2\n\n# Unset in production\nconvex env unset KEY --prod\n```\n\n## Logs & Debugging\n\n### `convex logs`\n\nView function execution logs.\n\n```bash\n# Stream logs\nconvex logs\n\n# Stream production logs\nconvex logs --prod\n\n# Stream with function filter\nconvex logs --function myFunction\n\n# Stream with log level filter\nconvex logs --level error\n\n# Show last N logs\nconvex logs --limit 100\n\n# Follow logs in real-time\nconvex logs --follow\n\n# Show logs since timestamp\nconvex logs --since 2024-01-01T00:00:00Z\n```\n\n### `convex dashboard`\n\nOpen Convex dashboard in browser.\n\n```bash\n# Open dashboard\nconvex dashboard\n\n# Open production dashboard\nconvex dashboard --prod\n\n# Open data view\nconvex dashboard --data\n\n# Open logs view\nconvex dashboard --logs\n\n# Open functions view\nconvex dashboard --functions\n\n# Open settings\nconvex dashboard --settings\n```\n\n## Authentication Setup\n\n### `convex auth`\n\nManage authentication configuration.\n\n```bash\n# Configure authentication\nconvex auth add\n\n# List auth providers\nconvex auth list\n\n# Remove auth provider\nconvex auth remove provider-name\n```\n\n## Code Generation\n\n### `convex codegen`\n\nGenerate TypeScript types from schema.\n\n```bash\n# Generate types\nconvex codegen\n\n# Generate with custom output\nconvex codegen --output src/convex/_generated\n\n# Watch mode for continuous generation\nconvex dev --codegen\n```\n\n## Configuration\n\n### `convex config`\n\nManage CLI configuration.\n\n```bash\n# Show current configuration\nconvex config show\n\n# Set default team\nconvex config set default-team my-team\n\n# Set default project\nconvex config set default-project my-project\n\n# Reset configuration\nconvex config reset\n```\n\n## Global Options\n\nAll Convex commands support these global flags:\n\n- `--admin-key` â€” Admin key for authentication\n- `--debug` â€” Enable debug logging\n- `--help` â€” Show help for command\n- `--prod` â€” Target production deployment\n- `--project` â€” Specify project name\n- `--team` â€” Specify team name\n- `--url` â€” Specify deployment URL\n- `--verbose` â€” Enable verbose output\n- `--version` â€” Show CLI version\n- `--yes` â€” Auto-confirm prompts\n",
        "plugins/dev/skills/convex-cli/reference/common-patterns.md": "# Convex Common Patterns\n\nReal-world patterns and workflows for common Convex use cases.\n\n## Development Workflow\n\n### Complete Development Cycle\n\n```bash\n# Initialize project\nconvex login\nconvex init\n\n# Start local development\nconvex dev\n\n# Make changes to functions...\n# Changes auto-reload\n\n# Deploy to production\nconvex deploy\n\n# Monitor production\nconvex logs --prod --follow\n```\n\n### Local Development with Type Checking\n\n```bash\n# Start dev server with TypeScript checking\nconvex dev --typecheck\n\n# Generate types continuously\nconvex dev --codegen\n\n# Run and debug a function\nconvex run queries/getUser --args '{\"id\": \"123\"}'\n```\n\n## Data Management\n\n### Database Backup & Restore\n\n```bash\n# Export all data before major changes\nconvex export --all --output backup-$(date +%Y%m%d).json\n\n# Export specific table\nconvex export users --output users-backup.json\n\n# Import data to new environment\nconvex import users users.json\n\n# Batch import multiple tables\nconvex import --all data/\n```\n\n### Multi-Environment Data Sync\n\n```bash\n# Export from production\nconvex export --all --prod --output prod-backup.json\n\n# Import to development\nconvex export --all --output dev-data.json\n\n# Use replacement mode for updates\nconvex import users updated-users.json --replace\n```\n\n## Environment Configuration\n\n### Secrets & Configuration Management\n\n```bash\n# Set API keys for development\nconvex env set API_KEY sk_test_123\nconvex env set DATABASE_URL postgres://localhost/mydb\n\n# Set production secrets\nconvex env set SECRET_KEY value --prod\nconvex env set WEBHOOK_SECRET value --prod\n\n# List all environment variables\nconvex env list\nconvex env list --prod\n\n# Update multiple vars\nconvex env set KEY1 value1 KEY2 value2 --prod\n```\n\n### Environment Variables by Deployment\n\n```bash\n# Development environment\nconvex env set NODE_ENV development\nconvex env set LOG_LEVEL debug\n\n# Production environment\nconvex env set NODE_ENV production --prod\nconvex env set LOG_LEVEL error --prod\n\n# Staging environment\nconvex env set NODE_ENV staging --deployment-name staging\n```\n\n## Function Development\n\n### Query Function Pattern\n\n```bash\n# Development: Test query locally\nconvex run queries/getUser --args '{\"id\": \"user123\"}'\n\n# Production: Run against prod data\nconvex run queries/getUser --args '{\"id\": \"user123\"}'  --prod\n\n# With error handling\nconvex run queries/complexQuery --args '{\"filter\": \"active\"}' --prod\n```\n\n### Mutation Function Pattern\n\n```bash\n# Create user locally\nconvex run mutations/createUser --args '{\"name\": \"Alice\", \"email\": \"alice@example.com\"}'\n\n# Update data in production\nconvex run mutations/updateUser --args '{\"id\": \"123\", \"status\": \"active\"}' --prod\n\n# Delete operations\nconvex run mutations/deleteUser --args '{\"id\": \"123\"}' --prod\n```\n\n### Action Function Pattern\n\n```bash\n# Test action with external services\nconvex run actions/sendEmail --args '{\"to\": \"user@example.com\", \"subject\": \"Test\"}'\n\n# Run HTTP action\nconvex run actions/webhookHandler --args '{\"event\": \"user.created\"}' --prod\n```\n\n## Deployment Patterns\n\n### Pre-Deployment Checklist\n\n```bash\n# Type checking\nconvex deploy --typecheck\n\n# Preview changes\nconvex deploy --dry-run\n\n# Deploy with message\nconvex deploy --message \"feat: add user authentication\"\n\n# Monitor after deploy\nconvex logs --prod --follow --limit 50\n```\n\n### Automated Deployments\n\n```bash\n#!/bin/bash\n# Deploy script with validation\n\n# Ensure code is ready\nnpm test\nconvex deploy --typecheck\n\n# Tag deployment\nconvex deploy --message \"v1.2.3 - $(git rev-parse --short HEAD)\"\n\n# Monitor health\nconvex logs --prod --limit 10\n```\n\n### Zero-Downtime Deployments\n\n```bash\n# Export current data\nconvex export --all --prod --output pre-deploy-backup.json\n\n# Deploy changes\nconvex deploy --message \"feat: new schema\"\n\n# Verify deployment\nconvex logs --prod --limit 20\nconvex run queries/systemHealth --prod\n```\n\n## Team Collaboration\n\n### Team Management\n\n```bash\n# List teams\nconvex teams list\n\n# Switch team\nconvex teams switch my-team\n\n# Create project in team\nconvex init --project team-project\nconvex deploy --project team-project\n\n# View team projects\nconvex projects list\n```\n\n### Multi-Project Setup\n\n```bash\n# Set default project\nconvex config set default-project my-project\n\n# Deploy to specific project\nconvex deploy --project my-project\n\n# Switch projects\nconvex projects list\nconvex init --project another-project\n```\n\n## Authentication Setup\n\n### Authentication Configuration\n\n```bash\n# Add auth provider\nconvex auth add\n\n# View configured providers\nconvex auth list\n\n# Remove provider (if needed)\nconvex auth remove provider-name\n\n# View auth settings\nconvex dashboard --settings\n```\n\n### Auth Testing\n\n```bash\n# Test authentication flow\nconvex run queries/getCurrentUser\n\n# Verify token handling\nconvex run mutations/refreshToken --args '{\"refreshToken\": \"xyz\"}'\n```\n\n## Monitoring & Logging\n\n### Real-Time Log Monitoring\n\n```bash\n# Stream all logs\nconvex logs --follow\n\n# Filter by function\nconvex logs --function myFunction --follow\n\n# Filter by level\nconvex logs --level error --follow\n\n# Filter production logs\nconvex logs --prod --follow --limit 100\n```\n\n### Error Tracking\n\n```bash\n# View error logs\nconvex logs --level error\n\n# Error logs from production\nconvex logs --level error --prod\n\n# Error logs for specific function\nconvex logs --function errorProneFunction --level error\n```\n\n### Performance Monitoring\n\n```bash\n# Check function execution\nconvex logs --function myFunction --limit 50\n\n# View recent activity\nconvex logs --limit 100\n\n# Monitor dashboard\nconvex dashboard --logs\n```\n\n## Data Import/Export Strategies\n\n### Seed Data Loading\n\n```bash\n# Prepare seed data in JSON format\n# data/seed-users.json with array of objects\n\n# Import to development\nconvex import users data/seed-users.json\n\n# Batch import multiple tables\nconvex import --all data/\n\n# Verify import\nconvex run queries/countUsers\n```\n\n### Data Migration\n\n```bash\n# Export from old system\nconvex export users --output users-migration.json\n\n# Transform if needed\n# Create transformed-users.json with updated schema\n\n# Import to new system\nconvex import users transformed-users.json --replace\n```\n\n### Backup Strategy\n\n```bash\n# Daily backup script\n#!/bin/bash\nDATE=$(date +%Y-%m-%d)\nconvex export --all --prod --output \"backups/daily-$DATE.json\"\n\n# Keep only last 30 days\nfind backups/ -name \"daily-*.json\" -mtime +30 -delete\n```\n\n## Development Environment Setup\n\n### Project Structure Setup\n\n```bash\n# Typical Convex project layout\nmy-app/\nâ”œâ”€â”€ convex/\nâ”‚   â”œâ”€â”€ _generated/          # Auto-generated types\nâ”‚   â”œâ”€â”€ schema.ts            # Database schema\nâ”‚   â”œâ”€â”€ queries/             # Query functions\nâ”‚   â”œâ”€â”€ mutations/           # Mutation functions\nâ”‚   â”œâ”€â”€ actions/             # Action functions\nâ”‚   â””â”€â”€ http.ts              # HTTP actions\nâ”œâ”€â”€ convex.json              # Convex configuration\nâ”œâ”€â”€ .env.local               # Local environment variables\nâ””â”€â”€ .env.production          # Production env (in CI/CD)\n```\n\n### Development Tools Setup\n\n```bash\n# Install dependencies\nnpm install convex\n\n# Setup TypeScript\nnpm install -D typescript @types/node\n\n# Start development\nnpm run dev\n\n# Build and deploy\nnpm run build\nnpm run deploy\n```\n\n## CI/CD Integration\n\n### GitHub Actions Deployment\n\n```bash\n# Set admin key in GitHub Secrets\n# Then use in workflow:\n\nconvex deploy --admin-key $CONVEX_DEPLOY_KEY\nconvex logs --prod --limit 10\n```\n\n### Automated Testing\n\n```bash\n# Test before deploy\nnpm test\n\n# Type checking\nconvex deploy --typecheck\n\n# Dry run\nconvex deploy --dry-run\n```\n",
        "plugins/dev/skills/convex-cli/reference/troubleshooting.md": "# Convex Troubleshooting Guide\n\nCommon issues and solutions for Convex development and deployment.\n\n## Authentication Issues\n\n### Cannot Login to Convex\n\n**Symptom:** `convex login` fails or hangs\n\n**Diagnosis:**\n```bash\n# Check authentication status\nconvex whoami\n\n# Check CLI version\nconvex --version\n\n# View config location\necho $HOME/.convex/config\n```\n\n**Solutions:**\n```bash\n# Clear credentials and re-login\nrm -rf ~/.convex\nconvex login\n\n# Use authentication token manually\nexport CONVEX_ADMIN_KEY=your-admin-key\nconvex deploy\n\n# Check network connectivity\nping prod.convex.cloud\n```\n\n### Authentication Token Expired\n\n**Symptom:** \"Unauthorized\" or \"Invalid token\" errors\n\n**Solutions:**\n```bash\n# Re-authenticate\nconvex logout\nconvex login\n\n# Or use fresh admin key\nconvex deploy --admin-key $FRESH_ADMIN_KEY\n```\n\n## Development Server Issues\n\n### Development Server Won't Start\n\n**Symptom:** `convex dev` fails to start\n\n**Diagnosis:**\n```bash\n# Check port availability\nlsof -i :3210  # Default admin port\n\n# Check project structure\nls -la convex/\n\n# Verify convex.json exists\ncat convex.json\n```\n\n**Solutions:**\n```bash\n# Use different port\nconvex dev --admin-port 3211\n\n# Clear existing state\nconvex dev --clear-deployment\n\n# Verbose output for debugging\nconvex dev --verbose\n\n# Check if project is initialized\nconvex init\n```\n\n### Hot Reload Not Working\n\n**Symptom:** Changes to functions don't reload\n\n**Diagnosis:**\n```bash\n# Verify watch is enabled\nconvex dev --watch\n\n# Check file system\nls convex/queries/\nls convex/mutations/\n```\n\n**Solutions:**\n```bash\n# Restart dev server\n# Stop with Ctrl+C and run again\nconvex dev\n\n# Enable explicit watching\nconvex dev --watch\n\n# Check .convexignore for exclusions\ncat .convexignore\n```\n\n### Cannot Access Dev Dashboard\n\n**Symptom:** Cannot open http://localhost:3210 or dashboard is blank\n\n**Diagnosis:**\n```bash\n# Check if port is open\nlsof -i :3210\n\n# Check logs for errors\nconvex dev --verbose\n```\n\n**Solutions:**\n```bash\n# Use different port\nconvex dev --admin-port 3211\n\n# Open dashboard manually\nconvex dashboard\n\n# Check firewall settings\nsudo ufw allow 3210\n```\n\n## Deployment Issues\n\n### Deployment Fails\n\n**Symptom:** `convex deploy` fails with error\n\n**Diagnosis:**\n```bash\n# Type check code\nnpm run typecheck  # or tsc\n\n# Verify no syntax errors\nnode --check convex/queries/*.js\n\n# Test dry run\nconvex deploy --dry-run\n```\n\n**Solutions:**\n```bash\n# Fix TypeScript errors\nconvex deploy --typecheck\n\n# Verify project selection\nconvex deploy --project my-project\n\n# Use verbose mode\nconvex deploy --verbose\n\n# Check project exists\nconvex projects list\n```\n\n### Schema Validation Errors\n\n**Symptom:** \"Schema validation failed\" error during deploy\n\n**Solutions:**\n```bash\n# Review schema file\ncat convex/schema.ts\n\n# Check for invalid field definitions\nconvex deploy --verbose\n\n# Verify Convex schema syntax\n# Ensure v.object, v.string, v.number are correct\n```\n\n## Function Execution Issues\n\n### Function Not Found Error\n\n**Symptom:** \"Function not found\" when running `convex run`\n\n**Diagnosis:**\n```bash\n# List available functions\nconvex dashboard --functions\n\n# Check file path\nls convex/queries/myFunction.ts\n\n# Verify export statement\ngrep \"export\" convex/queries/myFunction.ts\n```\n\n**Solutions:**\n```bash\n# Correct function path format\nconvex run queries/myFunction\n\n# Export function properly\n# export const myFunction = query({...})\n\n# Redeploy after changes\nconvex deploy\n```\n\n### Function Arguments Error\n\n**Symptom:** \"Invalid arguments\" when running function\n\n**Diagnosis:**\n```bash\n# Verify argument schema\ncat convex/queries/myFunction.ts\n\n# Test with simple arguments\nconvex run myFunction --args '{}'\n\n# Check argument format\nconvex run myFunction --args '{\"key\": \"value\"}'\n```\n\n**Solutions:**\n```bash\n# Use valid JSON\nconvex run myFunction --args '{\"id\": 123}'\n\n# Use args file for complex data\necho '{\"id\": 123, \"name\": \"test\"}' > args.json\nconvex run myFunction --args-file args.json\n\n# Check function parameter types\n# Arguments must match schema validation\n```\n\n### Function Returns Undefined\n\n**Symptom:** Query or mutation returns null/undefined unexpectedly\n\n**Solutions:**\n```bash\n# Add logging to function\nconsole.log(\"Debug:\", value);\n\n# Check return statement\n# Ensure function returns a value\n\n# Verify database queries\n// db.query(\"table\").collect()\n\n# Monitor logs\nconvex logs --function myFunction --follow\n```\n\n## Data Issues\n\n### Import Fails\n\n**Symptom:** `convex import` fails with error\n\n**Diagnosis:**\n```bash\n# Verify JSON format\njq . data.json\n\n# Check table exists\nconvex dashboard --data\n\n# Verify schema compatibility\ncat convex/schema.ts\n```\n\n**Solutions:**\n```bash\n# Ensure valid JSON\njq . data.json  # Should work without errors\n\n# Check table name matches\nconvex import correct-table-name data.json\n\n# Use --replace for updates\nconvex import users data.json --replace\n\n# Batch import\nconvex import --all data/\n```\n\n### Export Creates Empty File\n\n**Symptom:** Exported data is empty or very small\n\n**Diagnosis:**\n```bash\n# Check if table has data\nconvex run queries/countUsers\n\n# View data in dashboard\nconvex dashboard --data\n\n# Check export format\nconvex export users --format jsonl\n```\n\n**Solutions:**\n```bash\n# Export from correct environment\nconvex export users --prod  # For production data\n\n# Check table name is correct\nconvex export correct-table-name\n\n# List all tables\nconvex dashboard --data\n```\n\n### Data Persistence Issues\n\n**Symptom:** Data appears to be lost or inconsistent\n\n**Solutions:**\n```bash\n# Backup before major operations\nconvex export --all --output backup.json\n\n# Verify changes persisted\nconvex run queries/getItem --args '{\"id\": \"xyz\"}'\n\n# Check deployment\nconvex deployments list\n\n# Clear and reimport if needed\n# convex data clear --all\nconvex import users fresh-data.json\n```\n\n## Environment Variable Issues\n\n### Environment Variables Not Loading\n\n**Symptom:** Functions can't access environment variables\n\n**Diagnosis:**\n```bash\n# Check vars are set\nconvex env list\n\n# Verify in dashboard\nconvex dashboard --settings\n\n# Check .env.local file exists\ncat .env.local\n```\n\n**Solutions:**\n```bash\n# Set environment variable\nconvex env set MY_KEY my_value\n\n# For production\nconvex env set MY_KEY my_value --prod\n\n# Verify it's set\nconvex env get MY_KEY\n\n# Redeploy to pick up changes\nconvex deploy\n```\n\n### .env File Not Being Read\n\n**Symptom:** Variables from .env file not available\n\n**Solutions:**\n```bash\n# Use env file explicitly\nconvex env set --env-file .env.local\n\n# Manually set each variable\nconvex env set API_KEY $(grep API_KEY .env | cut -d= -f2)\n\n# Check .env file format\ncat .env\n# Should be: KEY=value (no quotes needed)\n```\n\n## Logs & Monitoring Issues\n\n### Cannot View Logs\n\n**Symptom:** `convex logs` shows no output\n\n**Diagnosis:**\n```bash\n# Check if functions are executing\nconvex run queries/testFunction\n\n# Verify logs are available\nconvex logs --limit 50\n\n# Check production\nconvex logs --prod\n```\n\n**Solutions:**\n```bash\n# Follow logs in real-time\nconvex logs --follow\n\n# Show more lines\nconvex logs --limit 100\n\n# Filter by function\nconvex logs --function myFunction --follow\n\n# Check specific deployment\nconvex logs --prod\n```\n\n### Dashboard Not Loading\n\n**Symptom:** Dashboard is blank or won't load\n\n**Solutions:**\n```bash\n# Open dashboard explicitly\nconvex dashboard\n\n# Clear browser cache\n# Restart dev server\nconvex dev\n\n# Check browser console for errors\n# Open Developer Tools > Console tab\n\n# Try different browser\n```\n\n## Type Generation Issues\n\n### Generated Types Not Updating\n\n**Symptom:** TypeScript errors after function changes\n\n**Diagnosis:**\n```bash\n# Check generated types exist\nls convex/_generated/\n\n# Verify schema file\ncat convex/schema.ts\n```\n\n**Solutions:**\n```bash\n# Regenerate types\nconvex codegen\n\n# During development\nconvex dev --codegen\n\n# Restart dev server\n# Kill convex dev and restart\n\n# Clear generated files\nrm -rf convex/_generated/\nconvex codegen\n```\n\n### Type Mismatches\n\n**Symptom:** \"Type 'X' is not assignable to type 'Y'\" errors\n\n**Solutions:**\n```bash\n# Regenerate types\nconvex codegen\n\n# Update imports\nimport { Doc } from \"./_generated/dataModel\"\n\n# Check schema matches usage\n# Ensure all mutations match schema.ts\n\n# Run type check\nnpm run typecheck\n```\n\n## Performance Issues\n\n### Slow Function Execution\n\n**Symptom:** Functions take too long to execute\n\n**Solutions:**\n```bash\n# Monitor logs\nconvex logs --function slowFunction --follow\n\n# Check database queries\n// Use batching instead of loops\n// Use indexes for filtering\n\n# Profile in dashboard\nconvex dashboard --functions\n\n# Check environment setup\nconvex env list\n```\n\n### Timeout Errors\n\n**Symptom:** \"Function timed out\" errors\n\n**Solutions:**\n```bash\n# Check function logic\ncat convex/queries/timeoutFunction.ts\n\n# Move heavy operations to actions\n// Use actions for long-running tasks\n\n# Optimize database queries\n// Use filters in queries instead of client-side\n\n# Increase timeout if needed (limited by plan)\n```\n\n## Project Configuration Issues\n\n### Project Not Found\n\n**Symptom:** \"Project not found\" error\n\n**Diagnosis:**\n```bash\n# List available projects\nconvex projects list\n\n# Check current project setting\ncat convex.json\n\n# Verify project exists\nconvex config show\n```\n\n**Solutions:**\n```bash\n# Set correct project\nconvex init --project correct-project-name\n\n# Switch projects\nconvex config set default-project my-project\n\n# Create project if missing\nconvex projects create\n```\n\n### Configuration Corruption\n\n**Symptom:** \"Invalid configuration\" errors\n\n**Solutions:**\n```bash\n# Reset configuration\nconvex config reset\n\n# Reinitialize project\nconvex reinit\n\n# Verify convex.json format\ncat convex.json\n# Should be valid JSON\n\n# Restore from backup if needed\n```\n\n## Team & Access Issues\n\n### Cannot Access Team Project\n\n**Symptom:** \"Access denied\" or \"Project not found\"\n\n**Solutions:**\n```bash\n# Switch to correct team\nconvex teams list\nconvex teams switch my-team\n\n# List projects in team\nconvex projects list\n\n# Verify project name\nconvex init --project team-project\n```\n\n### Permission Denied Errors\n\n**Symptom:** Cannot deploy or access production\n\n**Solutions:**\n```bash\n# Verify authentication\nconvex whoami\n\n# Check team/project permissions\nconvex teams list\n\n# Use admin key for CI/CD\nexport CONVEX_ADMIN_KEY=your-admin-key\nconvex deploy\n```\n\n## Best Practices for Troubleshooting\n\n### General Debugging Workflow\n\n```bash\n# 1. Check status\nconvex whoami\nconvex config show\n\n# 2. Verify project\nconvex projects list\nconvex deployments list\n\n# 3. Run in verbose mode\nconvex dev --verbose\nconvex deploy --verbose\n\n# 4. Check logs\nconvex logs --limit 100\nconvex logs --follow\n\n# 5. View dashboard\nconvex dashboard\nconvex dashboard --data\nconvex dashboard --logs\n```\n\n### Common Fixes\n\n```bash\n# Restart dev server\n# Press Ctrl+C and run again\nconvex dev\n\n# Clear state\nconvex dev --clear-deployment\n\n# Redeploy\nconvex deploy\n\n# Regenerate types\nconvex codegen\n\n# Re-authenticate\nconvex logout\nconvex login\n```\n",
        "plugins/dev/skills/coolify-api/SKILL.md": "---\nname: coolify-api\ndescription: Coolify API expert for self-hosted PaaS management. Use when users need to deploy apps, manage databases, or configure servers on Coolify.\nallowed-tools: Bash(curl:*), WebFetch\n---\n\n# Coolify API Guide\n\nCoolify is a self-hosted Platform-as-a-Service (PaaS) that simplifies deploying applications, databases, and services. This guide provides essential workflows and quick references for managing Coolify via REST API.\n\n## Quick Start\n\n```bash\n# Set environment variables\nexport COOLIFY_URL=\"http://your-coolify-ip:8000\"\nexport COOLIFY_TOKEN=\"your-api-token\"\n\n# Test authentication\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/version\"\n\n# Check system health\ncurl \"$COOLIFY_URL/api/health\"\n\n# List all applications\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications\"\n\n# List all servers\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/servers\"\n```\n\n**Authentication Setup:**\n1. Navigate to **Keys & Tokens** > **API tokens** in Coolify dashboard\n2. Click **Create New Token** and copy it (shown only once)\n3. Set permissions: **Read-only** or **Sensitive data** access\n\n## Common Workflows\n\n### Workflow 1: Deploy Public GitHub Repository\n\n```bash\n# Complete deployment workflow\n\n# 1. Create project\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"name\": \"my-project\"}' \\\n     \"$COOLIFY_URL/api/v1/projects\"\n\n# 2. Deploy application\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"project_uuid\": \"project-uuid\",\n       \"environment_name\": \"production\",\n       \"server_uuid\": \"server-uuid\",\n       \"destination_uuid\": \"destination-uuid\",\n       \"type\": \"public\",\n       \"name\": \"my-app\",\n       \"git_repository\": \"https://github.com/user/repo\",\n       \"git_branch\": \"main\",\n       \"build_pack\": \"nixpacks\",\n       \"ports_exposes\": \"3000\"\n     }' \\\n     \"$COOLIFY_URL/api/v1/applications\"\n\n# 3. Add environment variables\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"key\": \"NODE_ENV\", \"value\": \"production\"}' \\\n     \"$COOLIFY_URL/api/v1/applications/{app-uuid}/environment-variables\"\n\n# 4. Start application\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/{app-uuid}/start\"\n\n# 5. Check logs\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/{app-uuid}/logs\"\n```\n\n### Workflow 2: Deploy Private Repository with GitHub App\n\n```bash\n# Deploy from private repository using GitHub App\n\n# 1. Register GitHub App\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"name\": \"my-github-app\",\n       \"app_id\": 123456,\n       \"installation_id\": 654321,\n       \"client_id\": \"client-id\",\n       \"client_secret\": \"client-secret\",\n       \"private_key\": \"-----BEGIN RSA PRIVATE KEY-----\\n...\"\n     }' \\\n     \"$COOLIFY_URL/api/v1/github-apps\"\n\n# 2. Create application with GitHub App\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"project_uuid\": \"project-uuid\",\n       \"environment_name\": \"production\",\n       \"server_uuid\": \"server-uuid\",\n       \"destination_uuid\": \"destination-uuid\",\n       \"type\": \"private-gh-app\",\n       \"name\": \"my-private-app\",\n       \"github_app_uuid\": \"gh-app-uuid\",\n       \"git_repository\": \"user/private-repo\",\n       \"git_branch\": \"main\",\n       \"build_pack\": \"nixpacks\",\n       \"ports_exposes\": \"3000\"\n     }' \\\n     \"$COOLIFY_URL/api/v1/applications\"\n```\n\n### Workflow 3: Deploy PostgreSQL Database with Backups\n\n```bash\n# Create database with automated backup configuration\n\n# 1. Create PostgreSQL database\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"project_uuid\": \"project-uuid\",\n       \"environment_name\": \"production\",\n       \"server_uuid\": \"server-uuid\",\n       \"destination_uuid\": \"destination-uuid\",\n       \"type\": \"postgresql\",\n       \"name\": \"production-db\",\n       \"postgres_user\": \"app\",\n       \"postgres_password\": \"secure-password\",\n       \"postgres_db\": \"myapp\"\n     }' \\\n     \"$COOLIFY_URL/api/v1/databases\"\n\n# 2. Configure daily backups at 2 AM, keep 14 days\ncurl -X PATCH \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"enabled\": true,\n       \"frequency\": \"0 2 * * *\",\n       \"number_of_backups_to_keep\": 14\n     }' \\\n     \"$COOLIFY_URL/api/v1/databases/{db-uuid}/backup\"\n\n# 3. Start database\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/databases/{db-uuid}/start\"\n```\n\n### Workflow 4: Deploy Docker Image\n\n```bash\n# Deploy pre-built Docker image from registry\n\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"project_uuid\": \"project-uuid\",\n       \"environment_name\": \"production\",\n       \"server_uuid\": \"server-uuid\",\n       \"destination_uuid\": \"destination-uuid\",\n       \"type\": \"docker-image\",\n       \"name\": \"my-image-app\",\n       \"docker_image\": \"nginx:latest\",\n       \"ports_exposes\": \"80\"\n     }' \\\n     \"$COOLIFY_URL/api/v1/applications\"\n```\n\n### Workflow 5: CI/CD Webhook Deployment\n\n```bash\n# Trigger deployment from CI/CD pipeline\n\n# Deploy by tag\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/deployments/deploy?tag=v1.2.3\"\n\n# Deploy by application UUID\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/deployments/deploy?uuid={app-uuid}\"\n```\n\n## Decision Tree\n\n**When to use which approach:**\n\n- **To deploy public repository**: Use `type: public` with `git_repository` URL\n- **To deploy private repository**: Use GitHub App (`type: private-gh-app`) or deploy key (`type: private-deploy-key`)\n- **To deploy Docker image**: Use `type: docker-image` with `docker_image` name\n- **To deploy custom Dockerfile**: Use `type: dockerfile` with Dockerfile content\n- **To deploy multi-container app**: Use `type: docker-compose` with compose YAML\n- **To create database**: Use `/api/v1/databases` with database type (postgresql, mysql, redis, mongodb, etc.)\n- **To trigger deployment**: Use `/api/v1/deployments/deploy` with tag or UUID\n- **For detailed API syntax**: See [API Reference](./reference/api-reference.md)\n- **For complete workflows**: See [Common Patterns](./reference/common-patterns.md)\n- **For troubleshooting**: See [Troubleshooting Guide](./reference/troubleshooting.md)\n\n## Common Patterns\n\n### Managing Environment Variables\n\n```bash\n# List variables\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/{app-uuid}/environment-variables\"\n\n# Add single variable\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"key\": \"DATABASE_URL\",\n       \"value\": \"postgres://user:pass@host:5432/db\",\n       \"is_build_time\": false\n     }' \\\n     \"$COOLIFY_URL/api/v1/applications/{app-uuid}/environment-variables\"\n\n# Bulk update variables\ncurl -X PATCH \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"variables\": [\n         {\"key\": \"VAR1\", \"value\": \"value1\"},\n         {\"key\": \"VAR2\", \"value\": \"value2\"}\n       ]\n     }' \\\n     \"$COOLIFY_URL/api/v1/applications/{app-uuid}/environment-variables/bulk\"\n\n# Restart after changes\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/{app-uuid}/restart\"\n```\n\n### Application Lifecycle Management\n\n```bash\n# Start application\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/{app-uuid}/start\"\n\n# Stop application\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/{app-uuid}/stop\"\n\n# Restart application\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/{app-uuid}/restart\"\n\n# View logs\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/{app-uuid}/logs\"\n\n# List deployments\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/{app-uuid}/deployments\"\n```\n\n### Server Management\n\n```bash\n# List all servers\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/servers\"\n\n# Get server details\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/servers/{server-uuid}\"\n\n# Validate server connectivity\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/servers/{server-uuid}/validate\"\n\n# List server resources\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/servers/{server-uuid}/resources\"\n```\n\n## Troubleshooting\n\n**Common Issues:**\n\n1. **401 Unauthorized**\n   - Solution: Verify token is valid and API access is enabled\n   - See: [Authentication Issues](./reference/troubleshooting.md#authentication-issues)\n\n2. **Application won't start**\n   - Quick fix: Check logs and verify environment variables\n   - See: [Application Won't Start](./reference/troubleshooting.md#application-wont-start)\n\n3. **Build fails**\n   - Quick fix: Switch to dockerfile type or add build-time variables\n   - See: [Build Fails](./reference/troubleshooting.md#build-fails)\n\n4. **Git repository access denied**\n   - Quick fix: Verify deploy key or GitHub App configuration\n   - See: [Git Repository Access Denied](./reference/troubleshooting.md#git-repository-access-denied)\n\n5. **Database won't start**\n   - Quick fix: Check port conflicts and credentials\n   - See: [Database Won't Start](./reference/troubleshooting.md#database-wont-start)\n\nFor detailed troubleshooting steps, see the [Troubleshooting Guide](./reference/troubleshooting.md).\n\n## Reference Files\n\n**Load as needed for detailed information:**\n\n- **[API Reference](./reference/api-reference.md)** - Complete REST API endpoint documentation with all request/response formats, authentication details, and HTTP status codes. Use when you need exact API syntax for any Coolify operation.\n\n- **[Common Patterns](./reference/common-patterns.md)** - Real-world deployment patterns including multi-environment setups, CI/CD integration, database backups, and shell helper functions. Use for implementing complete workflows or automation scripts.\n\n- **[Troubleshooting Guide](./reference/troubleshooting.md)** - Detailed error messages, diagnosis steps, and solutions for authentication, deployment, server, database, and API issues. Use when encountering errors or unexpected behavior.\n\n**When to use each reference:**\n\n- Use **API Reference** when you need exact endpoint paths, request body schemas, or response format details\n- Use **Common Patterns** for implementing multi-step deployments, GitHub Actions integration, or production setups\n- Use **Troubleshooting** when deployments fail, authentication errors occur, or resources won't start\n\n## Resources\n\n- Official Documentation: https://coolify.io/docs\n- API Documentation: https://coolify.io/docs/api\n- GitHub Repository: https://github.com/coollabsio/coolify\n- Discord Community: https://discord.gg/coolify\n",
        "plugins/dev/skills/coolify-api/reference/api-reference.md": "# Coolify API Reference\n\nComplete API endpoint documentation for Coolify REST API.\n\n## Base Configuration\n\n**Base URL:** `http://<your-coolify-ip>:8000/api/v1`\n\n**Authentication:** Bearer token via Authorization header\n\n**Token Generation:**\n1. Navigate to **Keys & Tokens** > **API tokens** in Coolify dashboard\n2. Define token name\n3. Click **Create New Token**\n4. Copy token (shown only once)\n\n**Token Permissions:**\n- **Read-only**: Can only read data\n- **Sensitive data**: Required to view passwords and API keys (otherwise redacted)\n\n**Authentication Header:**\n```bash\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     \"$COOLIFY_URL/api/v1/endpoint\"\n```\n\n## System Operations\n\n### Version\n\n```bash\n# Get Coolify version\nGET /api/v1/version\n```\n\n### Health Check\n\n```bash\n# Check system health (no auth required)\nGET /api/health\n```\n\n### API Access Control\n\n```bash\n# Enable API access\nGET /api/v1/enable\n\n# Disable API access\nGET /api/v1/disable\n```\n\n## Server Management\n\n### List Servers\n\n```bash\n# Get all servers\nGET /api/v1/servers\n```\n\n### Get Server Details\n\n```bash\n# Get specific server by UUID\nGET /api/v1/servers/{uuid}\n```\n\n### Create Server\n\n```bash\nPOST /api/v1/servers\nContent-Type: application/json\n\n{\n  \"name\": \"my-server\",\n  \"ip\": \"192.168.1.100\",\n  \"port\": 22,\n  \"user\": \"root\",\n  \"private_key_uuid\": \"pk-uuid\"\n}\n```\n\n### Update Server\n\n```bash\nPATCH /api/v1/servers/{uuid}\nContent-Type: application/json\n\n{\n  \"name\": \"updated-server-name\",\n  \"description\": \"Production server\"\n}\n```\n\n### Delete Server\n\n```bash\nDELETE /api/v1/servers/{uuid}\n```\n\n### Server Resources\n\n```bash\n# Get resources deployed on server\nGET /api/v1/servers/{uuid}/resources\n```\n\n### Server Domains\n\n```bash\n# List domains configured on server\nGET /api/v1/servers/{uuid}/domains\n```\n\n### Validate Server\n\n```bash\n# Verify server connectivity\nGET /api/v1/servers/{uuid}/validate\n```\n\n## Project Management\n\n### List Projects\n\n```bash\n# Get all projects\nGET /api/v1/projects\n```\n\n### Get Project Details\n\n```bash\n# Get specific project\nGET /api/v1/projects/{uuid}\n```\n\n### Create Project\n\n```bash\nPOST /api/v1/projects\nContent-Type: application/json\n\n{\n  \"name\": \"my-project\",\n  \"description\": \"Production project\"\n}\n```\n\n### Update Project\n\n```bash\nPATCH /api/v1/projects/{uuid}\nContent-Type: application/json\n\n{\n  \"name\": \"updated-project\",\n  \"description\": \"Updated description\"\n}\n```\n\n### Delete Project\n\n```bash\nDELETE /api/v1/projects/{uuid}\n```\n\n## Environment Management\n\n### List Environments\n\n```bash\n# Get environments for a project\nGET /api/v1/projects/{uuid}/environments\n```\n\n### Get Environment\n\n```bash\n# Get specific environment by name or UUID\nGET /api/v1/projects/{project-uuid}/environments/{env-name-or-uuid}\n```\n\n### Create Environment\n\n```bash\nPOST /api/v1/projects/{uuid}/environments\nContent-Type: application/json\n\n{\n  \"name\": \"staging\"\n}\n```\n\n### Delete Environment\n\n```bash\nDELETE /api/v1/projects/{project-uuid}/environments/{env-uuid}\n```\n\n## Application Deployment\n\n### List Applications\n\n```bash\n# Get all applications\nGET /api/v1/applications\n```\n\n### Get Application Details\n\n```bash\n# Get specific application\nGET /api/v1/applications/{uuid}\n```\n\n### Create Public Repository Application\n\n```bash\nPOST /api/v1/applications\nContent-Type: application/json\n\n{\n  \"project_uuid\": \"project-uuid\",\n  \"environment_name\": \"production\",\n  \"server_uuid\": \"server-uuid\",\n  \"destination_uuid\": \"destination-uuid\",\n  \"type\": \"public\",\n  \"name\": \"my-app\",\n  \"git_repository\": \"https://github.com/user/repo\",\n  \"git_branch\": \"main\",\n  \"build_pack\": \"nixpacks\",\n  \"ports_exposes\": \"3000\"\n}\n```\n\n### Create Private Repository Application (GitHub App)\n\n```bash\nPOST /api/v1/applications\nContent-Type: application/json\n\n{\n  \"project_uuid\": \"project-uuid\",\n  \"environment_name\": \"production\",\n  \"server_uuid\": \"server-uuid\",\n  \"destination_uuid\": \"destination-uuid\",\n  \"type\": \"private-gh-app\",\n  \"name\": \"my-private-app\",\n  \"github_app_uuid\": \"gh-app-uuid\",\n  \"git_repository\": \"user/private-repo\",\n  \"git_branch\": \"main\",\n  \"build_pack\": \"nixpacks\",\n  \"ports_exposes\": \"3000\"\n}\n```\n\n### Create Private Repository Application (Deploy Key)\n\n```bash\nPOST /api/v1/applications\nContent-Type: application/json\n\n{\n  \"project_uuid\": \"project-uuid\",\n  \"environment_name\": \"production\",\n  \"server_uuid\": \"server-uuid\",\n  \"destination_uuid\": \"destination-uuid\",\n  \"type\": \"private-deploy-key\",\n  \"name\": \"my-app\",\n  \"private_key_uuid\": \"pk-uuid\",\n  \"git_repository\": \"git@github.com:user/repo.git\",\n  \"git_branch\": \"main\",\n  \"build_pack\": \"nixpacks\",\n  \"ports_exposes\": \"3000\"\n}\n```\n\n### Create Dockerfile Application\n\n```bash\nPOST /api/v1/applications\nContent-Type: application/json\n\n{\n  \"project_uuid\": \"project-uuid\",\n  \"environment_name\": \"production\",\n  \"server_uuid\": \"server-uuid\",\n  \"destination_uuid\": \"destination-uuid\",\n  \"type\": \"dockerfile\",\n  \"name\": \"my-dockerfile-app\",\n  \"dockerfile\": \"FROM node:18\\nWORKDIR /app\\nCOPY . .\\nRUN npm install\\nCMD [\\\"npm\\\", \\\"start\\\"]\",\n  \"ports_exposes\": \"3000\"\n}\n```\n\n### Create Docker Image Application\n\n```bash\nPOST /api/v1/applications\nContent-Type: application/json\n\n{\n  \"project_uuid\": \"project-uuid\",\n  \"environment_name\": \"production\",\n  \"server_uuid\": \"server-uuid\",\n  \"destination_uuid\": \"destination-uuid\",\n  \"type\": \"docker-image\",\n  \"name\": \"my-image-app\",\n  \"docker_image\": \"nginx:latest\",\n  \"ports_exposes\": \"80\"\n}\n```\n\n### Create Docker Compose Application\n\n```bash\nPOST /api/v1/applications\nContent-Type: application/json\n\n{\n  \"project_uuid\": \"project-uuid\",\n  \"environment_name\": \"production\",\n  \"server_uuid\": \"server-uuid\",\n  \"destination_uuid\": \"destination-uuid\",\n  \"type\": \"docker-compose\",\n  \"name\": \"my-compose-app\",\n  \"docker_compose\": \"version: \\\"3\\\"\\nservices:\\n  web:\\n    image: nginx\\n    ports:\\n      - \\\"80:80\\\"\"\n}\n```\n\n### Update Application\n\n```bash\nPATCH /api/v1/applications/{uuid}\nContent-Type: application/json\n\n{\n  \"name\": \"updated-app-name\",\n  \"description\": \"Updated description\",\n  \"git_branch\": \"develop\"\n}\n```\n\n### Delete Application\n\n```bash\nDELETE /api/v1/applications/{uuid}\n```\n\n### Application Lifecycle\n\n```bash\n# Start application\nGET /api/v1/applications/{uuid}/start\n\n# Stop application\nGET /api/v1/applications/{uuid}/stop\n\n# Restart application\nGET /api/v1/applications/{uuid}/restart\n```\n\n### Application Logs\n\n```bash\n# Fetch application logs\nGET /api/v1/applications/{uuid}/logs\n```\n\n### Application Deployments\n\n```bash\n# List deployments for application\nGET /api/v1/applications/{uuid}/deployments\n```\n\n## Environment Variables\n\n### Application Environment Variables\n\n```bash\n# List variables\nGET /api/v1/applications/{uuid}/environment-variables\n\n# Create variable\nPOST /api/v1/applications/{uuid}/environment-variables\nContent-Type: application/json\n\n{\n  \"key\": \"DATABASE_URL\",\n  \"value\": \"postgres://user:pass@host:5432/db\",\n  \"is_build_time\": false,\n  \"is_preview\": false\n}\n\n# Update variable\nPATCH /api/v1/applications/{uuid}/environment-variables\nContent-Type: application/json\n\n{\n  \"key\": \"DATABASE_URL\",\n  \"value\": \"postgres://user:newpass@host:5432/db\"\n}\n\n# Bulk update variables\nPATCH /api/v1/applications/{uuid}/environment-variables/bulk\nContent-Type: application/json\n\n{\n  \"variables\": [\n    {\"key\": \"VAR1\", \"value\": \"value1\"},\n    {\"key\": \"VAR2\", \"value\": \"value2\"}\n  ]\n}\n\n# Delete variable\nDELETE /api/v1/applications/{uuid}/environment-variables/{id}\n```\n\n### Service Environment Variables\n\n```bash\n# List variables\nGET /api/v1/services/{uuid}/environment-variables\n\n# Create variable\nPOST /api/v1/services/{uuid}/environment-variables\nContent-Type: application/json\n\n{\n  \"key\": \"CUSTOM_VAR\",\n  \"value\": \"custom-value\"\n}\n\n# Update variable\nPATCH /api/v1/services/{uuid}/environment-variables\nContent-Type: application/json\n\n{\n  \"key\": \"CUSTOM_VAR\",\n  \"value\": \"updated-value\"\n}\n\n# Bulk update variables\nPATCH /api/v1/services/{uuid}/environment-variables/bulk\nContent-Type: application/json\n\n{\n  \"variables\": [\n    {\"key\": \"VAR1\", \"value\": \"value1\"},\n    {\"key\": \"VAR2\", \"value\": \"value2\"}\n  ]\n}\n\n# Delete variable\nDELETE /api/v1/services/{uuid}/environment-variables/{id}\n```\n\n## Database Management\n\n### List Databases\n\n```bash\n# Get all databases\nGET /api/v1/databases\n```\n\n### Get Database Details\n\n```bash\n# Get specific database\nGET /api/v1/databases/{uuid}\n```\n\n### Create PostgreSQL Database\n\n```bash\nPOST /api/v1/databases\nContent-Type: application/json\n\n{\n  \"project_uuid\": \"project-uuid\",\n  \"environment_name\": \"production\",\n  \"server_uuid\": \"server-uuid\",\n  \"destination_uuid\": \"destination-uuid\",\n  \"type\": \"postgresql\",\n  \"name\": \"my-postgres\",\n  \"postgres_user\": \"myuser\",\n  \"postgres_password\": \"mypassword\",\n  \"postgres_db\": \"mydb\"\n}\n```\n\n### Create MySQL Database\n\n```bash\nPOST /api/v1/databases\nContent-Type: application/json\n\n{\n  \"project_uuid\": \"project-uuid\",\n  \"environment_name\": \"production\",\n  \"server_uuid\": \"server-uuid\",\n  \"destination_uuid\": \"destination-uuid\",\n  \"type\": \"mysql\",\n  \"name\": \"my-mysql\",\n  \"mysql_user\": \"myuser\",\n  \"mysql_password\": \"mypassword\",\n  \"mysql_database\": \"mydb\",\n  \"mysql_root_password\": \"rootpassword\"\n}\n```\n\n### Create MariaDB Database\n\n```bash\nPOST /api/v1/databases\nContent-Type: application/json\n\n{\n  \"project_uuid\": \"project-uuid\",\n  \"environment_name\": \"production\",\n  \"server_uuid\": \"server-uuid\",\n  \"destination_uuid\": \"destination-uuid\",\n  \"type\": \"mariadb\",\n  \"name\": \"my-mariadb\",\n  \"mariadb_user\": \"myuser\",\n  \"mariadb_password\": \"mypassword\",\n  \"mariadb_database\": \"mydb\"\n}\n```\n\n### Create MongoDB Database\n\n```bash\nPOST /api/v1/databases\nContent-Type: application/json\n\n{\n  \"project_uuid\": \"project-uuid\",\n  \"environment_name\": \"production\",\n  \"server_uuid\": \"server-uuid\",\n  \"destination_uuid\": \"destination-uuid\",\n  \"type\": \"mongodb\",\n  \"name\": \"my-mongo\",\n  \"mongo_initdb_root_username\": \"root\",\n  \"mongo_initdb_root_password\": \"rootpassword\"\n}\n```\n\n### Create Redis Database\n\n```bash\nPOST /api/v1/databases\nContent-Type: application/json\n\n{\n  \"project_uuid\": \"project-uuid\",\n  \"environment_name\": \"production\",\n  \"server_uuid\": \"server-uuid\",\n  \"destination_uuid\": \"destination-uuid\",\n  \"type\": \"redis\",\n  \"name\": \"my-redis\",\n  \"redis_password\": \"redispassword\"\n}\n```\n\n### Create KeyDB Database\n\n```bash\nPOST /api/v1/databases\nContent-Type: application/json\n\n{\n  \"project_uuid\": \"project-uuid\",\n  \"environment_name\": \"production\",\n  \"server_uuid\": \"server-uuid\",\n  \"destination_uuid\": \"destination-uuid\",\n  \"type\": \"keydb\",\n  \"name\": \"my-keydb\"\n}\n```\n\n### Create ClickHouse Database\n\n```bash\nPOST /api/v1/databases\nContent-Type: application/json\n\n{\n  \"project_uuid\": \"project-uuid\",\n  \"environment_name\": \"production\",\n  \"server_uuid\": \"server-uuid\",\n  \"destination_uuid\": \"destination-uuid\",\n  \"type\": \"clickhouse\",\n  \"name\": \"my-clickhouse\"\n}\n```\n\n### Create DragonFly Database\n\n```bash\nPOST /api/v1/databases\nContent-Type: application/json\n\n{\n  \"project_uuid\": \"project-uuid\",\n  \"environment_name\": \"production\",\n  \"server_uuid\": \"server-uuid\",\n  \"destination_uuid\": \"destination-uuid\",\n  \"type\": \"dragonfly\",\n  \"name\": \"my-dragonfly\"\n}\n```\n\n### Update Database\n\n```bash\nPATCH /api/v1/databases/{uuid}\nContent-Type: application/json\n\n{\n  \"name\": \"updated-db-name\",\n  \"description\": \"Updated description\"\n}\n```\n\n### Delete Database\n\n```bash\nDELETE /api/v1/databases/{uuid}\n```\n\n### Database Lifecycle\n\n```bash\n# Start database\nGET /api/v1/databases/{uuid}/start\n\n# Stop database\nGET /api/v1/databases/{uuid}/stop\n\n# Restart database\nGET /api/v1/databases/{uuid}/restart\n```\n\n## Database Backups\n\n### List Backup Executions\n\n```bash\n# Get all backup executions\nGET /api/v1/databases/backups\n```\n\n### Get Database Backups\n\n```bash\n# Get backups for specific database\nGET /api/v1/databases/{uuid}/backups\n```\n\n### Update Backup Configuration\n\n```bash\nPATCH /api/v1/databases/{uuid}/backup\nContent-Type: application/json\n\n{\n  \"enabled\": true,\n  \"frequency\": \"0 0 * * *\",\n  \"number_of_backups_to_keep\": 7\n}\n```\n\n### Delete Backup Configuration\n\n```bash\nDELETE /api/v1/databases/{uuid}/backup-configuration\n```\n\n### Delete Backup Execution\n\n```bash\nDELETE /api/v1/databases/backups/{uuid}\n```\n\n## Service Management\n\n### List Services\n\n```bash\n# Get all services\nGET /api/v1/services\n```\n\n### Get Service Details\n\n```bash\n# Get specific service\nGET /api/v1/services/{uuid}\n```\n\n### Create Service\n\n```bash\nPOST /api/v1/services\nContent-Type: application/json\n\n{\n  \"project_uuid\": \"project-uuid\",\n  \"environment_name\": \"production\",\n  \"server_uuid\": \"server-uuid\",\n  \"destination_uuid\": \"destination-uuid\",\n  \"type\": \"plausible\",\n  \"name\": \"my-plausible\"\n}\n```\n\n### Update Service\n\n```bash\nPATCH /api/v1/services/{uuid}\nContent-Type: application/json\n\n{\n  \"name\": \"updated-service\",\n  \"description\": \"Updated description\"\n}\n```\n\n### Delete Service\n\n```bash\nDELETE /api/v1/services/{uuid}\n```\n\n### Service Lifecycle\n\n```bash\n# Start service\nGET /api/v1/services/{uuid}/start\n\n# Stop service\nGET /api/v1/services/{uuid}/stop\n\n# Restart service\nGET /api/v1/services/{uuid}/restart\n```\n\n## Deployment Operations\n\n### List All Deployments\n\n```bash\n# Get all deployments\nGET /api/v1/deployments\n```\n\n### Get Deployment Details\n\n```bash\n# Get specific deployment\nGET /api/v1/deployments/{uuid}\n```\n\n### Trigger Deployment\n\n```bash\n# Deploy by tag\nGET /api/v1/deployments/deploy?tag=v1.0.0\n\n# Deploy by application UUID\nGET /api/v1/deployments/deploy?uuid=app-uuid\n```\n\n## Resource Management\n\n### List All Resources\n\n```bash\n# Get all resources across projects\nGET /api/v1/resources\n```\n\n## Private Keys\n\n### List Private Keys\n\n```bash\n# Get all private keys\nGET /api/v1/private-keys\n```\n\n### Get Private Key\n\n```bash\n# Get specific private key\nGET /api/v1/private-keys/{uuid}\n```\n\n### Create Private Key\n\n```bash\nPOST /api/v1/private-keys\nContent-Type: application/json\n\n{\n  \"name\": \"my-deploy-key\",\n  \"description\": \"Deploy key for production\",\n  \"private_key\": \"-----BEGIN OPENSSH PRIVATE KEY-----\\n...\\n-----END OPENSSH PRIVATE KEY-----\"\n}\n```\n\n### Update Private Key\n\n```bash\nPATCH /api/v1/private-keys/{uuid}\nContent-Type: application/json\n\n{\n  \"name\": \"updated-key-name\",\n  \"description\": \"Updated description\"\n}\n```\n\n### Delete Private Key\n\n```bash\nDELETE /api/v1/private-keys/{uuid}\n```\n\n## GitHub App Integration\n\n### Register GitHub App\n\n```bash\nPOST /api/v1/github-apps\nContent-Type: application/json\n\n{\n  \"name\": \"my-github-app\",\n  \"organization\": \"my-org\",\n  \"app_id\": 123456,\n  \"installation_id\": 654321,\n  \"client_id\": \"client-id\",\n  \"client_secret\": \"client-secret\",\n  \"webhook_secret\": \"webhook-secret\",\n  \"private_key\": \"-----BEGIN RSA PRIVATE KEY-----\\n...\\n-----END RSA PRIVATE KEY-----\"\n}\n```\n\n### Load Repositories\n\n```bash\n# Get repositories available via GitHub App\nGET /api/v1/github-apps/{id}/repositories\n```\n\n### Load Branches\n\n```bash\n# Get branches for a repository\nGET /api/v1/github-apps/{id}/branches?repository=user/repo\n```\n\n### Update GitHub App\n\n```bash\nPATCH /api/v1/github-apps/{id}\nContent-Type: application/json\n\n{\n  \"name\": \"updated-app-name\"\n}\n```\n\n### Delete GitHub App\n\n```bash\nDELETE /api/v1/github-apps/{id}\n```\n\n## Team Management\n\n### List Teams\n\n```bash\n# Get all teams\nGET /api/v1/teams\n```\n\n### Get Team Details\n\n```bash\n# Get specific team\nGET /api/v1/teams/{id}\n```\n\n### Get Team Members\n\n```bash\n# List team members\nGET /api/v1/teams/{id}/members\n```\n\n### Get Current Team\n\n```bash\n# Get authenticated user's team\nGET /api/v1/teams/current\n```\n\n### Get Current Team Members\n\n```bash\n# List current team members\nGET /api/v1/teams/current/members\n```\n\n## Response Format\n\n### Success Response\n\n```json\n{\n  \"success\": true,\n  \"data\": { ... }\n}\n```\n\n### Error Response\n\n```json\n{\n  \"success\": false,\n  \"message\": \"Error description\",\n  \"errors\": { ... }\n}\n```\n\n## HTTP Status Codes\n\n- `200` - Success\n- `201` - Created\n- `400` - Bad Request (validation error)\n- `401` - Unauthorized (invalid or missing token)\n- `403` - Forbidden (insufficient permissions)\n- `404` - Not Found\n- `422` - Unprocessable Entity\n- `500` - Internal Server Error\n",
        "plugins/dev/skills/coolify-api/reference/common-patterns.md": "# Coolify Common Patterns\n\nReal-world deployment workflows and patterns for Coolify self-hosted PaaS.\n\n## Initial Setup Pattern\n\n### Configure Environment and Authentication\n\n```bash\n# Set Coolify URL and token\nexport COOLIFY_URL=\"http://your-coolify-ip:8000\"\nexport COOLIFY_TOKEN=\"your-api-token\"\n\n# Test authentication\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/version\"\n\n# Check system health\ncurl \"$COOLIFY_URL/api/health\"\n```\n\n### Shell Helper Functions\n\nAdd these to `.bashrc` or `.zshrc` for easier API access:\n\n```bash\n# Coolify API helper functions\nexport COOLIFY_URL=\"http://your-coolify-ip:8000\"\nexport COOLIFY_TOKEN=\"your-api-token\"\n\ncoolify_get() {\n  curl -s -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n       \"$COOLIFY_URL/api/v1/$1\" | jq .\n}\n\ncoolify_post() {\n  curl -s -X POST \\\n       -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n       -H \"Content-Type: application/json\" \\\n       -d \"$2\" \\\n       \"$COOLIFY_URL/api/v1/$1\" | jq .\n}\n\ncoolify_patch() {\n  curl -s -X PATCH \\\n       -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n       -H \"Content-Type: application/json\" \\\n       -d \"$2\" \\\n       \"$COOLIFY_URL/api/v1/$1\" | jq .\n}\n\ncoolify_delete() {\n  curl -s -X DELETE \\\n       -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n       \"$COOLIFY_URL/api/v1/$1\" | jq .\n}\n\n# Usage examples:\n# coolify_get \"servers\"\n# coolify_get \"applications\"\n# coolify_post \"projects\" '{\"name\": \"new-project\"}'\n# coolify_delete \"applications/uuid\"\n```\n\n## Complete Deployment Workflows\n\n### Workflow 1: Deploy Public GitHub Repository\n\n```bash\n# Complete deployment workflow for public repository\nexport COOLIFY_URL=\"http://coolify.example.com:8000\"\nexport COOLIFY_TOKEN=\"your-api-token\"\n\n# 1. Create a project\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"name\": \"my-project\"}' \\\n     \"$COOLIFY_URL/api/v1/projects\"\n\n# Get project UUID from response\nPROJECT_UUID=\"project-uuid-from-response\"\n\n# 2. Deploy application from GitHub\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"project_uuid\": \"'\"$PROJECT_UUID\"'\",\n       \"environment_name\": \"production\",\n       \"server_uuid\": \"server-uuid\",\n       \"destination_uuid\": \"destination-uuid\",\n       \"type\": \"public\",\n       \"name\": \"my-app\",\n       \"git_repository\": \"https://github.com/user/repo\",\n       \"git_branch\": \"main\",\n       \"build_pack\": \"nixpacks\",\n       \"ports_exposes\": \"3000\"\n     }' \\\n     \"$COOLIFY_URL/api/v1/applications\"\n\n# Get application UUID from response\nAPP_UUID=\"app-uuid-from-response\"\n\n# 3. Add environment variables\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"key\": \"NODE_ENV\", \"value\": \"production\"}' \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/environment-variables\"\n\n# 4. Start the application\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/start\"\n\n# 5. Check logs\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/logs\"\n```\n\n### Workflow 2: Deploy Private Repository with GitHub App\n\n```bash\n# Deploy application from private repository using GitHub App\n\n# 1. Register GitHub App (if not already done)\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"name\": \"my-github-app\",\n       \"organization\": \"my-org\",\n       \"app_id\": 123456,\n       \"installation_id\": 654321,\n       \"client_id\": \"client-id\",\n       \"client_secret\": \"client-secret\",\n       \"webhook_secret\": \"webhook-secret\",\n       \"private_key\": \"-----BEGIN RSA PRIVATE KEY-----\\n...\\n-----END RSA PRIVATE KEY-----\"\n     }' \\\n     \"$COOLIFY_URL/api/v1/github-apps\"\n\n# Get GitHub App ID\nGH_APP_ID=\"gh-app-id-from-response\"\n\n# 2. Load available repositories\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/github-apps/$GH_APP_ID/repositories\"\n\n# 3. Create application from private repository\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"project_uuid\": \"project-uuid\",\n       \"environment_name\": \"production\",\n       \"server_uuid\": \"server-uuid\",\n       \"destination_uuid\": \"destination-uuid\",\n       \"type\": \"private-gh-app\",\n       \"name\": \"my-private-app\",\n       \"github_app_uuid\": \"'\"$GH_APP_ID\"'\",\n       \"git_repository\": \"user/private-repo\",\n       \"git_branch\": \"main\",\n       \"build_pack\": \"nixpacks\",\n       \"ports_exposes\": \"3000\"\n     }' \\\n     \"$COOLIFY_URL/api/v1/applications\"\n\n# 4. Configure environment and start\nAPP_UUID=\"app-uuid-from-response\"\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"key\": \"API_KEY\", \"value\": \"secret\"}' \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/environment-variables\"\n\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/start\"\n```\n\n### Workflow 3: Deploy Private Repository with Deploy Key\n\n```bash\n# Deploy from private repository using SSH deploy key\n\n# 1. Create private key\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"name\": \"my-deploy-key\",\n       \"description\": \"Deploy key for production\",\n       \"private_key\": \"-----BEGIN OPENSSH PRIVATE KEY-----\\n...\\n-----END OPENSSH PRIVATE KEY-----\"\n     }' \\\n     \"$COOLIFY_URL/api/v1/private-keys\"\n\n# Get private key UUID\nPK_UUID=\"pk-uuid-from-response\"\n\n# 2. Create application with deploy key\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"project_uuid\": \"project-uuid\",\n       \"environment_name\": \"production\",\n       \"server_uuid\": \"server-uuid\",\n       \"destination_uuid\": \"destination-uuid\",\n       \"type\": \"private-deploy-key\",\n       \"name\": \"my-app\",\n       \"private_key_uuid\": \"'\"$PK_UUID\"'\",\n       \"git_repository\": \"git@github.com:user/repo.git\",\n       \"git_branch\": \"main\",\n       \"build_pack\": \"nixpacks\",\n       \"ports_exposes\": \"3000\"\n     }' \\\n     \"$COOLIFY_URL/api/v1/applications\"\n```\n\n### Workflow 4: Deploy Docker Image\n\n```bash\n# Deploy pre-built Docker image from registry\n\n# 1. Create application from Docker image\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"project_uuid\": \"project-uuid\",\n       \"environment_name\": \"production\",\n       \"server_uuid\": \"server-uuid\",\n       \"destination_uuid\": \"destination-uuid\",\n       \"type\": \"docker-image\",\n       \"name\": \"my-image-app\",\n       \"docker_image\": \"nginx:latest\",\n       \"ports_exposes\": \"80\"\n     }' \\\n     \"$COOLIFY_URL/api/v1/applications\"\n\n# 2. Start container\nAPP_UUID=\"app-uuid-from-response\"\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/start\"\n```\n\n### Workflow 5: Deploy with Custom Dockerfile\n\n```bash\n# Deploy application using custom Dockerfile\n\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"project_uuid\": \"project-uuid\",\n       \"environment_name\": \"production\",\n       \"server_uuid\": \"server-uuid\",\n       \"destination_uuid\": \"destination-uuid\",\n       \"type\": \"dockerfile\",\n       \"name\": \"my-dockerfile-app\",\n       \"dockerfile\": \"FROM node:18\\nWORKDIR /app\\nCOPY . .\\nRUN npm install\\nCMD [\\\"npm\\\", \\\"start\\\"]\",\n       \"ports_exposes\": \"3000\"\n     }' \\\n     \"$COOLIFY_URL/api/v1/applications\"\n```\n\n## Database Deployment Patterns\n\n### Pattern 1: PostgreSQL with Backup Configuration\n\n```bash\n# Create PostgreSQL database with automated backups\n\n# 1. Create PostgreSQL database\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"project_uuid\": \"project-uuid\",\n       \"environment_name\": \"production\",\n       \"server_uuid\": \"server-uuid\",\n       \"destination_uuid\": \"destination-uuid\",\n       \"type\": \"postgresql\",\n       \"name\": \"production-db\",\n       \"postgres_user\": \"app\",\n       \"postgres_password\": \"secure-password\",\n       \"postgres_db\": \"myapp\"\n     }' \\\n     \"$COOLIFY_URL/api/v1/databases\"\n\n# Get database UUID\nDB_UUID=\"db-uuid-from-response\"\n\n# 2. Configure daily backups at 2 AM, keep 14 days\ncurl -X PATCH \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"enabled\": true,\n       \"frequency\": \"0 2 * * *\",\n       \"number_of_backups_to_keep\": 14\n     }' \\\n     \"$COOLIFY_URL/api/v1/databases/$DB_UUID/backup\"\n\n# 3. Start database\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/databases/$DB_UUID/start\"\n\n# 4. Verify backups are configured\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/databases/$DB_UUID/backups\"\n```\n\n### Pattern 2: MySQL Database Setup\n\n```bash\n# Create MySQL database instance\n\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"project_uuid\": \"project-uuid\",\n       \"environment_name\": \"production\",\n       \"server_uuid\": \"server-uuid\",\n       \"destination_uuid\": \"destination-uuid\",\n       \"type\": \"mysql\",\n       \"name\": \"my-mysql\",\n       \"mysql_user\": \"myuser\",\n       \"mysql_password\": \"mypassword\",\n       \"mysql_database\": \"mydb\",\n       \"mysql_root_password\": \"rootpassword\"\n     }' \\\n     \"$COOLIFY_URL/api/v1/databases\"\n```\n\n### Pattern 3: Redis Cache Setup\n\n```bash\n# Create Redis cache instance\n\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"project_uuid\": \"project-uuid\",\n       \"environment_name\": \"production\",\n       \"server_uuid\": \"server-uuid\",\n       \"destination_uuid\": \"destination-uuid\",\n       \"type\": \"redis\",\n       \"name\": \"my-redis-cache\",\n       \"redis_password\": \"redispassword\"\n     }' \\\n     \"$COOLIFY_URL/api/v1/databases\"\n```\n\n## Environment Variable Management\n\n### Bulk Environment Variable Update\n\n```bash\n# Update multiple environment variables at once\n\ncurl -X PATCH \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"variables\": [\n         {\"key\": \"NODE_ENV\", \"value\": \"production\"},\n         {\"key\": \"DATABASE_URL\", \"value\": \"postgres://user:pass@host:5432/db\"},\n         {\"key\": \"API_KEY\", \"value\": \"secret-key\"},\n         {\"key\": \"LOG_LEVEL\", \"value\": \"info\"}\n       ]\n     }' \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/environment-variables/bulk\"\n```\n\n### Build-Time vs Runtime Variables\n\n```bash\n# Add build-time variable (available during build)\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"key\": \"BUILD_VERSION\",\n       \"value\": \"1.0.0\",\n       \"is_build_time\": true,\n       \"is_preview\": false\n     }' \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/environment-variables\"\n\n# Add runtime variable (available at runtime only)\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"key\": \"API_KEY\",\n       \"value\": \"secret\",\n       \"is_build_time\": false,\n       \"is_preview\": false\n     }' \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/environment-variables\"\n```\n\n## Server Management Patterns\n\n### Add and Validate New Server\n\n```bash\n# Add new server and verify connectivity\n\n# 1. Create server\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"name\": \"production-server\",\n       \"ip\": \"192.168.1.100\",\n       \"port\": 22,\n       \"user\": \"root\",\n       \"private_key_uuid\": \"pk-uuid\"\n     }' \\\n     \"$COOLIFY_URL/api/v1/servers\"\n\n# Get server UUID\nSERVER_UUID=\"server-uuid-from-response\"\n\n# 2. Validate server connectivity\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/servers/$SERVER_UUID/validate\"\n\n# 3. List resources on server\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/servers/$SERVER_UUID/resources\"\n\n# 4. List configured domains\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/servers/$SERVER_UUID/domains\"\n```\n\n## Multi-Environment Pattern\n\n### Create Staging and Production Environments\n\n```bash\n# Set up multiple environments for a project\n\nPROJECT_UUID=\"your-project-uuid\"\n\n# 1. Create staging environment\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"name\": \"staging\"}' \\\n     \"$COOLIFY_URL/api/v1/projects/$PROJECT_UUID/environments\"\n\n# 2. Create production environment\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"name\": \"production\"}' \\\n     \"$COOLIFY_URL/api/v1/projects/$PROJECT_UUID/environments\"\n\n# 3. Deploy to staging\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"project_uuid\": \"'\"$PROJECT_UUID\"'\",\n       \"environment_name\": \"staging\",\n       \"server_uuid\": \"staging-server-uuid\",\n       \"destination_uuid\": \"staging-dest-uuid\",\n       \"type\": \"public\",\n       \"name\": \"my-app-staging\",\n       \"git_repository\": \"https://github.com/user/repo\",\n       \"git_branch\": \"develop\",\n       \"build_pack\": \"nixpacks\",\n       \"ports_exposes\": \"3000\"\n     }' \\\n     \"$COOLIFY_URL/api/v1/applications\"\n\n# 4. Deploy to production\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"project_uuid\": \"'\"$PROJECT_UUID\"'\",\n       \"environment_name\": \"production\",\n       \"server_uuid\": \"prod-server-uuid\",\n       \"destination_uuid\": \"prod-dest-uuid\",\n       \"type\": \"public\",\n       \"name\": \"my-app-production\",\n       \"git_repository\": \"https://github.com/user/repo\",\n       \"git_branch\": \"main\",\n       \"build_pack\": \"nixpacks\",\n       \"ports_exposes\": \"3000\"\n     }' \\\n     \"$COOLIFY_URL/api/v1/applications\"\n```\n\n## CI/CD Integration Patterns\n\n### Automated Deployment via Webhook\n\n```bash\n# Trigger deployment when new tag is pushed (use in CI/CD pipeline)\n\n# Deploy specific tag\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/deployments/deploy?tag=v1.2.3\"\n\n# Deploy specific application by UUID\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/deployments/deploy?uuid=$APP_UUID\"\n```\n\n### GitHub Actions Integration\n\n```yaml\n# .github/workflows/deploy.yml\nname: Deploy to Coolify\n\non:\n  push:\n    tags:\n      - 'v*'\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Trigger Coolify Deployment\n        run: |\n          curl -H \"Authorization: Bearer ${{ secrets.COOLIFY_TOKEN }}\" \\\n               \"${{ secrets.COOLIFY_URL }}/api/v1/deployments/deploy?tag=${{ github.ref_name }}\"\n```\n\n## Service Deployment Pattern\n\n### Deploy One-Click Service\n\n```bash\n# Deploy pre-configured service (e.g., Plausible Analytics)\n\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"project_uuid\": \"project-uuid\",\n       \"environment_name\": \"production\",\n       \"server_uuid\": \"server-uuid\",\n       \"destination_uuid\": \"destination-uuid\",\n       \"type\": \"plausible\",\n       \"name\": \"my-plausible\"\n     }' \\\n     \"$COOLIFY_URL/api/v1/services\"\n\n# Get service UUID and configure environment\nSERVICE_UUID=\"service-uuid-from-response\"\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"key\": \"ADMIN_EMAIL\", \"value\": \"admin@example.com\"}' \\\n     \"$COOLIFY_URL/api/v1/services/$SERVICE_UUID/environment-variables\"\n\n# Start service\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/services/$SERVICE_UUID/start\"\n```\n\n## Monitoring and Logging Pattern\n\n### Check Application Health\n\n```bash\n# Monitor application status and logs\n\n# 1. Get application details\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID\"\n\n# 2. View recent logs\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/logs\"\n\n# 3. List deployment history\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/deployments\"\n\n# 4. Check resources on server\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/servers/$SERVER_UUID/resources\"\n```\n\n## Cleanup and Maintenance\n\n### Remove Application and Resources\n\n```bash\n# Complete cleanup of application and associated resources\n\n# 1. Stop application\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/stop\"\n\n# 2. Delete application\ncurl -X DELETE \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID\"\n\n# 3. Stop and remove database if no longer needed\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/databases/$DB_UUID/stop\"\n\ncurl -X DELETE \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/databases/$DB_UUID\"\n```\n",
        "plugins/dev/skills/coolify-api/reference/troubleshooting.md": "# Coolify Troubleshooting Guide\n\nCommon issues and solutions for Coolify API and deployment operations.\n\n## Authentication Issues\n\n### Invalid or Missing Token\n\n**Symptom:** `401 Unauthorized` response\n\n**Diagnosis:**\n```bash\n# Test token validity\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/version\"\n\n# Check if API is enabled\ncurl \"$COOLIFY_URL/api/health\"\n```\n\n**Common Causes:**\n1. Token expired or revoked\n2. Incorrect token format\n3. API access disabled\n4. Wrong base URL\n\n**Solutions:**\n```bash\n# Generate new token in Coolify dashboard\n# Keys & Tokens > API tokens > Create New Token\n\n# Verify token format (should not include extra spaces or quotes)\nexport COOLIFY_TOKEN=\"token-without-spaces\"\n\n# Enable API access\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/enable\"\n\n# Verify base URL format (must include /api/v1)\nexport COOLIFY_URL=\"http://your-ip:8000\"\n```\n\n### Permission Denied\n\n**Symptom:** `403 Forbidden` response\n\n**Diagnosis:**\n```bash\n# Check token permissions\n# Read-only tokens cannot create/update/delete\n```\n\n**Solutions:**\n- Regenerate token with appropriate permissions\n- Enable \"sensitive data\" permission if accessing passwords/keys\n\n## Deployment Issues\n\n### Application Won't Start\n\n**Symptom:** Application deploys but exits immediately\n\n**Diagnosis:**\n```bash\n# Check application logs\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/logs\"\n\n# Get application details\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID\"\n\n# Check deployment status\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/deployments\"\n```\n\n**Common Causes:**\n1. **Missing environment variables** â†’ Application crashes due to missing config\n2. **Port conflict** â†’ Exposed port already in use\n3. **Build failed** â†’ Nixpacks or Dockerfile build errors\n4. **Invalid git branch** â†’ Branch doesn't exist\n\n**Solutions:**\n```bash\n# Verify environment variables\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/environment-variables\"\n\n# Add missing variables\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"key\": \"REQUIRED_VAR\", \"value\": \"value\"}' \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/environment-variables\"\n\n# Change exposed port\ncurl -X PATCH \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"ports_exposes\": \"8080\"}' \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID\"\n\n# Update branch name\ncurl -X PATCH \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"git_branch\": \"main\"}' \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID\"\n\n# Restart after fixes\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/restart\"\n```\n\n### Build Fails\n\n**Symptom:** Deployment fails during build phase\n\n**Diagnosis:**\n```bash\n# Check deployment logs\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/logs\"\n\n# List recent deployments\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/deployments\"\n```\n\n**Common Causes:**\n1. **Nixpacks detection failed** â†’ Use custom Dockerfile\n2. **Build dependencies missing** â†’ Add build-time environment variables\n3. **Dockerfile syntax error** â†’ Validate Dockerfile\n4. **Out of memory during build** â†’ Increase server resources\n\n**Solutions:**\n```bash\n# Switch to Dockerfile type\ncurl -X PATCH \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"type\": \"dockerfile\",\n       \"dockerfile\": \"FROM node:18\\nWORKDIR /app\\nCOPY . .\\nRUN npm install\\nCMD [\\\"npm\\\", \\\"start\\\"]\"\n     }' \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID\"\n\n# Add build-time variable\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"key\": \"BUILD_ENV\",\n       \"value\": \"production\",\n       \"is_build_time\": true\n     }' \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/environment-variables\"\n```\n\n### Git Repository Access Denied\n\n**Symptom:** Cannot clone repository (private repos)\n\n**Diagnosis:**\n```bash\n# Check application type\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID\"\n\n# For private-deploy-key type, verify key exists\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/private-keys\"\n\n# For private-gh-app type, verify GitHub App\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/github-apps\"\n```\n\n**Solutions:**\n```bash\n# For deploy key issues, create new key\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"name\": \"new-deploy-key\",\n       \"private_key\": \"-----BEGIN OPENSSH PRIVATE KEY-----\\n...\\n-----END OPENSSH PRIVATE KEY-----\"\n     }' \\\n     \"$COOLIFY_URL/api/v1/private-keys\"\n\n# Update application with new key UUID\ncurl -X PATCH \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"private_key_uuid\": \"new-pk-uuid\"}' \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID\"\n\n# For GitHub App issues, verify installation\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/github-apps/$GH_APP_ID/repositories\"\n```\n\n## Server Issues\n\n### Cannot Connect to Server\n\n**Symptom:** Server validation fails\n\n**Diagnosis:**\n```bash\n# Validate server connectivity\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/servers/$SERVER_UUID/validate\"\n\n# Get server details\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/servers/$SERVER_UUID\"\n```\n\n**Common Causes:**\n1. **SSH key invalid** â†’ Private key doesn't match server\n2. **Firewall blocking SSH** â†’ Port 22 not accessible\n3. **Wrong IP or port** â†’ Server details incorrect\n4. **SSH user lacks permissions** â†’ User cannot execute Docker commands\n\n**Solutions:**\n```bash\n# Update server IP and port\ncurl -X PATCH \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"ip\": \"correct-ip-address\",\n       \"port\": 22\n     }' \\\n     \"$COOLIFY_URL/api/v1/servers/$SERVER_UUID\"\n\n# Update SSH key\ncurl -X PATCH \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"private_key_uuid\": \"updated-pk-uuid\"}' \\\n     \"$COOLIFY_URL/api/v1/servers/$SERVER_UUID\"\n\n# On server, ensure Docker is installed and user has permissions\n# ssh into server and run:\n# sudo usermod -aG docker $USER\n```\n\n### Server Resources Not Available\n\n**Symptom:** Destination UUID not found\n\n**Diagnosis:**\n```bash\n# List server resources\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/servers/$SERVER_UUID/resources\"\n\n# List all servers\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/servers\"\n```\n\n**Solutions:**\n- Ensure server is properly configured in Coolify dashboard\n- Create destination/network in Coolify UI before deploying\n- Use correct destination_uuid from server resources list\n\n## Database Issues\n\n### Database Won't Start\n\n**Symptom:** Database container exits immediately\n\n**Diagnosis:**\n```bash\n# Check database details\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/databases/$DB_UUID\"\n\n# Restart database\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/databases/$DB_UUID/restart\"\n```\n\n**Common Causes:**\n1. **Port conflict** â†’ Database port already in use\n2. **Missing credentials** â†’ Required passwords not set\n3. **Disk space full** â†’ Server out of storage\n4. **Corrupted data** â†’ Database files corrupted\n\n**Solutions:**\n```bash\n# Update database configuration\ncurl -X PATCH \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"name\": \"updated-db-name\"}' \\\n     \"$COOLIFY_URL/api/v1/databases/$DB_UUID\"\n\n# Stop and restart\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/databases/$DB_UUID/stop\"\n\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/databases/$DB_UUID/start\"\n```\n\n### Backup Configuration Not Working\n\n**Symptom:** Backups not executing\n\n**Diagnosis:**\n```bash\n# Check backup configuration\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/databases/$DB_UUID/backups\"\n\n# List all backup executions\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/databases/backups\"\n```\n\n**Solutions:**\n```bash\n# Update backup configuration\ncurl -X PATCH \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"enabled\": true,\n       \"frequency\": \"0 2 * * *\",\n       \"number_of_backups_to_keep\": 7\n     }' \\\n     \"$COOLIFY_URL/api/v1/databases/$DB_UUID/backup\"\n\n# Verify cron syntax (0 2 * * * = daily at 2 AM)\n# Minute Hour Day Month DayOfWeek\n```\n\n## Environment Variable Issues\n\n### Variables Not Applied\n\n**Symptom:** Application not using environment variables\n\n**Diagnosis:**\n```bash\n# List current variables\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/environment-variables\"\n```\n\n**Solutions:**\n```bash\n# Restart application after adding variables\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/restart\"\n\n# Verify is_build_time vs runtime\n# Build-time: Available during build process\n# Runtime: Available when container runs\n\n# Add build-time variable\ncurl -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"key\": \"BUILD_VAR\", \"value\": \"val\", \"is_build_time\": true}' \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/environment-variables\"\n\n# Redeploy to apply build-time variables\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/deployments/deploy?uuid=$APP_UUID\"\n```\n\n### Bulk Update Fails\n\n**Symptom:** Variables not updated in bulk\n\n**Solutions:**\n```bash\n# Ensure correct format\ncurl -X PATCH \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"variables\": [\n         {\"key\": \"VAR1\", \"value\": \"value1\"},\n         {\"key\": \"VAR2\", \"value\": \"value2\"}\n       ]\n     }' \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/environment-variables/bulk\"\n\n# Restart application after update\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/restart\"\n```\n\n## Deployment Trigger Issues\n\n### Tag-Based Deployment Not Working\n\n**Symptom:** Deployment by tag fails\n\n**Diagnosis:**\n```bash\n# Verify application exists\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications\"\n\n# Check deployment status\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/deployments\"\n```\n\n**Solutions:**\n```bash\n# Ensure tag exists in repository\n# Use UUID instead of tag\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/deployments/deploy?uuid=$APP_UUID\"\n\n# Check application git_branch is correct\ncurl -X PATCH \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"git_branch\": \"main\"}' \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID\"\n```\n\n## Service Issues\n\n### Service Type Not Found\n\n**Symptom:** Cannot create service with specified type\n\n**Diagnosis:**\n```bash\n# List available services (check Coolify docs for supported types)\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/services\"\n```\n\n**Solutions:**\n- Use docker-compose type for custom services\n- Verify service type name (e.g., \"plausible\", \"n8n\", \"ghost\")\n- Check Coolify version for service availability\n\n### Service Environment Variables Not Applied\n\n**Symptom:** Service starts but ignores environment variables\n\n**Solutions:**\n```bash\n# Restart service after adding variables\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/services/$SERVICE_UUID/stop\"\n\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/services/$SERVICE_UUID/start\"\n\n# Or use restart endpoint\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/services/$SERVICE_UUID/restart\"\n```\n\n## GitHub App Issues\n\n### Repositories Not Loading\n\n**Symptom:** Cannot load repositories via GitHub App\n\n**Diagnosis:**\n```bash\n# Verify GitHub App registration\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/github-apps\"\n\n# Try loading repositories\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/github-apps/$GH_APP_ID/repositories\"\n```\n\n**Common Causes:**\n1. GitHub App not installed on repository\n2. Installation ID incorrect\n3. Private key invalid or expired\n4. App permissions insufficient\n\n**Solutions:**\n- Reinstall GitHub App in GitHub settings\n- Verify installation_id matches GitHub\n- Regenerate private key if expired\n- Ensure app has repository read permissions\n\n## API Response Issues\n\n### Empty or Null Response\n\n**Symptom:** API returns success but empty data\n\n**Diagnosis:**\n```bash\n# Check if resource exists\ncurl -s -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID\" | jq .\n\n# Verify UUID format\necho $APP_UUID\n```\n\n**Solutions:**\n- Verify UUID is correct (no extra spaces or quotes)\n- Check if resource was deleted\n- List all resources to find correct UUID\n\n### Validation Errors (422)\n\n**Symptom:** `422 Unprocessable Entity` with validation errors\n\n**Diagnosis:**\n```bash\n# View full error response\ncurl -s -X POST \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{ ... }' \\\n     \"$COOLIFY_URL/api/v1/applications\" | jq .\n```\n\n**Solutions:**\n- Check required fields (project_uuid, server_uuid, destination_uuid)\n- Verify field values match expected format\n- Ensure UUIDs exist and are valid\n- Check that ports_exposes is a string, not integer\n\n## Network and Connectivity Issues\n\n### Connection Timeout\n\n**Symptom:** Curl requests timeout\n\n**Diagnosis:**\n```bash\n# Test basic connectivity\nping your-coolify-ip\n\n# Test HTTP connection\ncurl -I \"$COOLIFY_URL/api/health\"\n\n# Check if port 8000 is accessible\ntelnet your-coolify-ip 8000\n```\n\n**Solutions:**\n- Verify Coolify is running\n- Check firewall rules allow port 8000\n- Ensure correct IP address and URL format\n- Try accessing from same network as Coolify\n\n### SSL/TLS Issues\n\n**Symptom:** Certificate errors\n\n**Solutions:**\n```bash\n# For self-signed certificates, use -k flag\ncurl -k -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/version\"\n\n# Or set environment variable\nexport CURL_CA_BUNDLE=/path/to/cert.pem\n```\n\n## Debug Tools\n\n### Useful Debug Commands\n\n```bash\n# Pretty print JSON responses\ncurl -s -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications\" | jq .\n\n# Check HTTP status codes\ncurl -w \"\\nHTTP Status: %{http_code}\\n\" \\\n     -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/version\"\n\n# View response headers\ncurl -I -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/version\"\n\n# Verbose output\ncurl -v -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/version\"\n\n# Save response to file\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/logs\" > app.log\n```\n\n### Systematic Troubleshooting Steps\n\n```bash\n# 1. Verify authentication\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/version\"\n\n# 2. List all resources\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/resources\"\n\n# 3. Check specific resource\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID\"\n\n# 4. View logs\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/logs\"\n\n# 5. Check deployments\ncurl -H \"Authorization: Bearer $COOLIFY_TOKEN\" \\\n     \"$COOLIFY_URL/api/v1/applications/$APP_UUID/deployments\"\n```\n\n## Getting Additional Help\n\n**Coolify Resources:**\n- Official Documentation: https://coolify.io/docs\n- API Documentation: https://coolify.io/docs/api\n- GitHub Issues: https://github.com/coollabsio/coolify\n- Discord Community: https://discord.gg/coolify\n\n**Debugging Checklist:**\n1. Verify authentication token is valid\n2. Check API is enabled (`/api/v1/enable`)\n3. Ensure UUIDs are correct\n4. Validate JSON syntax\n5. Check server connectivity\n6. Review application logs\n7. Verify environment variables\n8. Test with minimal configuration first\n",
        "plugins/dev/skills/docker-cli/SKILL.md": "---\nname: docker-cli\ndescription: Docker CLI expert for containerization. Use when users need to build, run, manage containers, images, networks, volumes, or compose applications.\nallowed-tools: Bash(docker:*), Bash(docker-compose:*)\n---\n\n# Docker CLI Guide\n\nDocker is a containerization platform that packages applications and dependencies into isolated containers. This guide provides essential workflows and quick references for common Docker operations.\n\n## Quick Start\n\n```bash\n# Check Docker installation\ndocker --version\n\n# Run your first container\ndocker run hello-world\n\n# Run interactive container\ndocker run -it ubuntu bash\n\n# Run container in background\ndocker run -d nginx\n\n# List running containers\ndocker ps\n\n# Stop a container\ndocker stop container_name\n```\n\n## Common Workflows\n\n### Workflow 1: Build and Run an Application\n\n```bash\n# Create Dockerfile in your project directory\n# Build image\ndocker build -t myapp:latest .\n\n# Run container with port mapping\ndocker run -d -p 8080:80 --name myapp myapp:latest\n\n# View logs\ndocker logs -f myapp\n\n# Access container shell\ndocker exec -it myapp bash\n```\n\n### Workflow 2: Development with Hot Reload\n\n```bash\n# Run with volume mount for live code updates\ndocker run -d \\\n  -p 8080:80 \\\n  -v $(pwd)/src:/app/src \\\n  --name myapp-dev \\\n  myapp:dev\n\n# Watch logs in real-time\ndocker logs -f myapp-dev\n\n# Restart after configuration changes\ndocker restart myapp-dev\n```\n\n### Workflow 3: Multi-Container Application with Docker Compose\n\n```bash\n# Create docker-compose.yml with services\n# Start all services\ndocker compose up -d\n\n# View service logs\ndocker compose logs -f\n\n# Scale a service\ndocker compose up -d --scale api=3\n\n# Stop all services\ndocker compose down\n\n# Stop and remove volumes\ndocker compose down -v\n```\n\n### Workflow 4: Push Image to Registry\n\n```bash\n# Login to registry\ndocker login\n\n# Build and tag image\ndocker build -t myapp:latest .\ndocker tag myapp:latest username/myapp:v1.0.0\ndocker tag myapp:latest username/myapp:latest\n\n# Push to registry\ndocker push username/myapp:v1.0.0\ndocker push username/myapp:latest\n```\n\n### Workflow 5: Debug Container Issues\n\n```bash\n# Check container status\ndocker ps -a\n\n# View container logs\ndocker logs container_name\n\n# Inspect container details\ndocker inspect container_name\n\n# Run interactive shell for debugging\ndocker run -it --entrypoint /bin/bash myapp:latest\n\n# Check container resource usage\ndocker stats container_name\n```\n\n## Decision Tree\n\n**When to use which command:**\n\n- **To run a new container**: Use `docker run` with appropriate flags\n- **To execute commands in running container**: Use `docker exec -it container_name bash`\n- **To build an image**: Use `docker build -t name:tag .`\n- **To manage multiple services**: Use `docker compose up/down`\n- **To check container status**: Use `docker ps` or `docker ps -a`\n- **To view logs**: Use `docker logs -f container_name`\n- **To clean up resources**: Use `docker system prune` or specific prune commands\n- **For detailed command syntax**: See [Commands Reference](./reference/commands-reference.md)\n- **For complex scenarios**: See [Common Patterns](./reference/common-patterns.md)\n- **For troubleshooting**: See [Troubleshooting Guide](./reference/troubleshooting.md)\n\n## Common Patterns\n\n### Running Containers with Options\n\n```bash\n# With environment variables\ndocker run -e ENV_VAR=value -e API_KEY=secret myapp\n\n# With resource limits\ndocker run --memory=512m --cpus=1.5 myapp\n\n# With restart policy\ndocker run --restart=unless-stopped myapp\n\n# With custom network\ndocker run --network mynetwork myapp\n\n# With volume mount\ndocker run -v mydata:/app/data myapp\n```\n\n### Container-to-Container Communication\n\n```bash\n# Create custom network\ndocker network create myapp-network\n\n# Run containers on same network\ndocker run -d --name database --network myapp-network postgres:15\ndocker run -d --name app --network myapp-network -p 8080:80 myapp\n\n# Containers can now access each other by name\n# Example: app can connect to database using hostname \"database\"\n```\n\n### Data Persistence\n\n```bash\n# Create named volume\ndocker volume create myapp-data\n\n# Use volume in container\ndocker run -d -v myapp-data:/var/lib/postgresql/data postgres:15\n\n# Backup volume data\ndocker run --rm \\\n  -v myapp-data:/data \\\n  -v $(pwd):/backup \\\n  ubuntu tar czf /backup/backup.tar.gz /data\n```\n\n## Troubleshooting\n\n**Common Issues:**\n\n1. **Container exits immediately**\n   - Solution: Check logs with `docker logs container_name`\n   - See: [Container Won't Start](./reference/troubleshooting.md#container-wont-start)\n\n2. **Can't access service on published port**\n   - Quick fix: Verify port mapping with `docker port container_name`\n   - See: [Container Running But Not Accessible](./reference/troubleshooting.md#container-running-but-not-accessible)\n\n3. **Permission denied errors**\n   - Quick fix: Run with user flag `docker run -u $(id -u):$(id -g)`\n   - See: [Permission Denied Errors](./reference/troubleshooting.md#permission-denied-errors)\n\n4. **Disk space issues**\n   - Quick fix: Clean up with `docker system prune -a --volumes`\n   - See: [Disk Space Issues](./reference/troubleshooting.md#disk-space-issues)\n\n5. **Network connectivity issues**\n   - Quick fix: Check container network with `docker network inspect bridge`\n   - See: [Network Issues](./reference/troubleshooting.md#cannot-connect-between-containers)\n\nFor detailed troubleshooting steps, see the [Troubleshooting Guide](./reference/troubleshooting.md).\n\n## Reference Files\n\n**Load as needed for detailed information:**\n\n- **[Commands Reference](./reference/commands-reference.md)** - Complete CLI command documentation with all flags and options. Use when you need exact syntax or flag details for any Docker command.\n\n- **[Common Patterns](./reference/common-patterns.md)** - Real-world patterns and workflows for development, multi-stage builds, networking, volumes, CI/CD, security, and production deployments. Use for implementing specific workflows or integrations.\n\n- **[Troubleshooting Guide](./reference/troubleshooting.md)** - Detailed error messages, diagnosis steps, and resolution strategies for container, image, network, volume, performance, and system issues. Use when encountering errors or unexpected behavior.\n\n**When to use each reference:**\n\n- Use **Commands Reference** when you need exact syntax, flag combinations, or comprehensive command documentation\n- Use **Common Patterns** for implementing multi-container setups, production configurations, or CI/CD pipelines\n- Use **Troubleshooting** when containers won't start, services are unreachable, or you encounter permission/network/performance issues\n\n## Resources\n\n- Official Docs: https://docs.docker.com\n- Docker Hub: https://hub.docker.com\n- GitHub: https://github.com/docker\n- Community: https://forums.docker.com\n",
        "plugins/dev/skills/docker-cli/reference/commands-reference.md": "# Docker CLI Commands Reference\n\nComplete reference for all Docker CLI commands with detailed options and flags.\n\n## Authentication & Registry\n\n### `docker login`\n\nAuthenticate with Docker registry.\n\n```bash\n# Login to Docker Hub\ndocker login\n\n# Login to specific registry\ndocker login registry.example.com\n\n# Login with username\ndocker login -u myusername\n\n# Show current user\ndocker info | grep Username\n```\n\n### `docker logout`\n\nLog out from Docker registry.\n\n```bash\n# Logout from Docker Hub\ndocker logout\n\n# Logout from specific registry\ndocker logout registry.example.com\n```\n\n## Container Management\n\n### `docker run`\n\nCreate and start a new container.\n\n```bash\n# Run container interactively\ndocker run -it ubuntu bash\n\n# Run container in background\ndocker run -d nginx\n\n# Run with port mapping\ndocker run -p 8080:80 nginx\n\n# Run with volume mount\ndocker run -v /host/path:/container/path ubuntu\n\n# Run with environment variables\ndocker run -e ENV_VAR=value ubuntu\n\n# Run with custom name\ndocker run --name mycontainer nginx\n\n# Run with restart policy\ndocker run --restart=always nginx\n\n# Run with resource limits\ndocker run --memory=512m --cpus=1 ubuntu\n```\n\n### `docker ps`\n\nList containers.\n\n```bash\n# List running containers\ndocker ps\n\n# List all containers (including stopped)\ndocker ps -a\n\n# Show only container IDs\ndocker ps -q\n\n# Show latest created container\ndocker ps -l\n\n# Filter containers\ndocker ps --filter \"status=running\"\n```\n\n### `docker exec`\n\nExecute commands in running containers.\n\n```bash\n# Run interactive shell\ndocker exec -it container_name bash\n\n# Execute single command\ndocker exec container_name ls /app\n\n# Execute as specific user\ndocker exec -u root container_name whoami\n\n# Execute with working directory\ndocker exec -w /app container_name pwd\n```\n\n### `docker start` / `docker stop` / `docker restart`\n\nControl container lifecycle.\n\n```bash\n# Start stopped container\ndocker start container_name\n\n# Stop running container\ndocker stop container_name\n\n# Restart container\ndocker restart container_name\n\n# Force stop container\ndocker kill container_name\n\n# Pause/unpause container\ndocker pause container_name\ndocker unpause container_name\n```\n\n### `docker logs`\n\nView container logs.\n\n```bash\n# Show container logs\ndocker logs container_name\n\n# Follow logs in real-time\ndocker logs -f container_name\n\n# Show last N lines\ndocker logs --tail 100 container_name\n\n# Show logs with timestamps\ndocker logs -t container_name\n\n# Show logs since specific time\ndocker logs --since 2023-01-01 container_name\n```\n\n### `docker inspect`\n\nDisplay detailed container information.\n\n```bash\n# Inspect container\ndocker inspect container_name\n\n# Get specific information using format\ndocker inspect --format='{{.State.Status}}' container_name\n\n# Get container IP address\ndocker inspect --format='{{.NetworkSettings.IPAddress}}' container_name\n```\n\n### `docker cp`\n\nCopy files between container and host.\n\n```bash\n# Copy from container to host\ndocker cp container_name:/path/to/file /host/path\n\n# Copy from host to container\ndocker cp /host/path container_name:/path/to/file\n\n# Copy directory\ndocker cp /host/dir container_name:/container/dir\n```\n\n### `docker rm`\n\nRemove containers.\n\n```bash\n# Remove stopped container\ndocker rm container_name\n\n# Force remove running container\ndocker rm -f container_name\n\n# Remove multiple containers\ndocker rm container1 container2\n\n# Remove all stopped containers\ndocker container prune\n```\n\n## Image Management\n\n### `docker images`\n\nList local images.\n\n```bash\n# List all images\ndocker images\n\n# List images with digests\ndocker images --digests\n\n# List image IDs only\ndocker images -q\n\n# Filter images\ndocker images --filter \"dangling=true\"\n```\n\n### `docker pull`\n\nDownload images from registry.\n\n```bash\n# Pull latest image\ndocker pull ubuntu\n\n# Pull specific tag\ndocker pull ubuntu:20.04\n\n# Pull from specific registry\ndocker pull registry.example.com/myimage:tag\n\n# Pull all tags of an image\ndocker pull -a ubuntu\n```\n\n### `docker push`\n\nUpload images to registry.\n\n```bash\n# Push image to registry\ndocker push myusername/myimage:tag\n\n# Push to specific registry\ndocker push registry.example.com/myimage:tag\n\n# Push all tags\ndocker push -a myusername/myimage\n```\n\n### `docker build`\n\nBuild images from Dockerfile.\n\n```bash\n# Build image from current directory\ndocker build .\n\n# Build with custom tag\ndocker build -t myimage:tag .\n\n# Build with custom Dockerfile\ndocker build -f custom.Dockerfile .\n\n# Build with build arguments\ndocker build --build-arg ARG_NAME=value .\n\n# Build without cache\ndocker build --no-cache .\n\n# Build with specific target stage\ndocker build --target production .\n```\n\n### `docker tag`\n\nTag images.\n\n```bash\n# Tag image with new name\ndocker tag source_image target_image:tag\n\n# Tag for registry push\ndocker tag myimage:latest registry.example.com/myimage:v1.0\n```\n\n### `docker rmi`\n\nRemove images.\n\n```bash\n# Remove image\ndocker rmi image_name:tag\n\n# Force remove image\ndocker rmi -f image_name\n\n# Remove multiple images\ndocker rmi image1 image2\n\n# Remove dangling images\ndocker image prune\n\n# Remove all unused images\ndocker image prune -a\n```\n\n### `docker history`\n\nShow image history.\n\n```bash\n# Show image layers\ndocker history image_name\n\n# Show without truncation\ndocker history --no-trunc image_name\n```\n\n### `docker save` / `docker load`\n\nExport and import images.\n\n```bash\n# Save image to tar file\ndocker save -o image.tar image_name\n\n# Load image from tar file\ndocker load -i image.tar\n\n# Save multiple images\ndocker save -o images.tar image1 image2\n```\n\n## Network Management\n\n### `docker network ls`\n\nList networks.\n\n```bash\n# List all networks\ndocker network ls\n\n# Filter networks\ndocker network ls --filter driver=bridge\n```\n\n### `docker network create`\n\nCreate networks.\n\n```bash\n# Create bridge network\ndocker network create mynetwork\n\n# Create with specific driver\ndocker network create --driver overlay mynetwork\n\n# Create with subnet\ndocker network create --subnet=192.168.1.0/24 mynetwork\n\n# Create with gateway\ndocker network create --gateway=192.168.1.1 mynetwork\n```\n\n### `docker network connect` / `docker network disconnect`\n\nManage container network connections.\n\n```bash\n# Connect container to network\ndocker network connect mynetwork container_name\n\n# Disconnect container from network\ndocker network disconnect mynetwork container_name\n\n# Connect with specific IP\ndocker network connect --ip 192.168.1.100 mynetwork container_name\n```\n\n### `docker network inspect`\n\nInspect network details.\n\n```bash\n# Inspect network\ndocker network inspect mynetwork\n\n# Get specific information\ndocker network inspect --format='{{.IPAM.Config}}' mynetwork\n```\n\n### `docker network rm`\n\nRemove networks.\n\n```bash\n# Remove network\ndocker network rm mynetwork\n\n# Remove multiple networks\ndocker network rm network1 network2\n\n# Remove all unused networks\ndocker network prune\n```\n\n## Volume Management\n\n### `docker volume ls`\n\nList volumes.\n\n```bash\n# List all volumes\ndocker volume ls\n\n# Filter volumes\ndocker volume ls --filter dangling=true\n```\n\n### `docker volume create`\n\nCreate volumes.\n\n```bash\n# Create volume\ndocker volume create myvolume\n\n# Create with specific driver\ndocker volume create --driver local myvolume\n\n# Create with options\ndocker volume create --opt type=nfs myvolume\n```\n\n### `docker volume inspect`\n\nInspect volume details.\n\n```bash\n# Inspect volume\ndocker volume inspect myvolume\n\n# Get mount point\ndocker volume inspect --format='{{.Mountpoint}}' myvolume\n```\n\n### `docker volume rm`\n\nRemove volumes.\n\n```bash\n# Remove volume\ndocker volume rm myvolume\n\n# Remove multiple volumes\ndocker volume rm volume1 volume2\n\n# Remove all unused volumes\ndocker volume prune\n```\n\n## System Management\n\n### `docker system df`\n\nShow Docker disk usage.\n\n```bash\n# Show disk usage summary\ndocker system df\n\n# Show detailed usage\ndocker system df -v\n```\n\n### `docker system prune`\n\nClean up unused resources.\n\n```bash\n# Remove unused containers, networks, images\ndocker system prune\n\n# Remove everything including volumes\ndocker system prune --volumes\n\n# Remove without confirmation\ndocker system prune -f\n\n# Remove all unused images (not just dangling)\ndocker system prune -a\n```\n\n### `docker stats`\n\nShow container resource usage.\n\n```bash\n# Show stats for all running containers\ndocker stats\n\n# Show stats for specific containers\ndocker stats container1 container2\n\n# Show stats without streaming\ndocker stats --no-stream\n```\n\n### `docker events`\n\nGet real-time events from Docker daemon.\n\n```bash\n# Show all events\ndocker events\n\n# Filter events by type\ndocker events --filter event=start\n\n# Show events since specific time\ndocker events --since 2023-01-01\n```\n\n## Docker Compose Commands\n\n### `docker compose up`\n\nStart services.\n\n```bash\n# Start services defined in docker-compose.yml\ndocker compose up\n\n# Start services in background\ndocker compose up -d\n\n# Build and start services\ndocker compose up --build\n```\n\n### `docker compose down`\n\nStop services.\n\n```bash\n# Stop services\ndocker compose down\n\n# Stop and remove volumes\ndocker compose down -v\n```\n\n### `docker compose logs`\n\nView service logs.\n\n```bash\n# Show service logs\ndocker compose logs\n\n# Follow logs\ndocker compose logs -f service_name\n```\n\n### `docker compose exec`\n\nExecute commands in services.\n\n```bash\n# Execute command in service\ndocker compose exec service_name bash\n```\n\n### `docker compose ps`\n\nList services.\n\n```bash\n# List services\ndocker compose ps\n```\n\n### `docker compose config`\n\nShow configuration.\n\n```bash\n# Show service configuration\ndocker compose config\n```\n\n## Global Options\n\nAll Docker commands support these global flags:\n\n- `--config` â€” Location of client config files\n- `--context` â€” Name of the context to use\n- `--debug` â€” Enable debug mode\n- `--host` â€” Daemon socket(s) to connect to\n- `--log-level` â€” Set the logging level\n- `--tls` â€” Use TLS; implied by --tlsverify\n- `--tlscacert` â€” Trust certs signed only by this CA\n- `--tlscert` â€” Path to TLS certificate file\n- `--tlskey` â€” Path to TLS key file\n- `--tlsverify` â€” Use TLS and verify the remote\n- `--version` â€” Print version information\n",
        "plugins/dev/skills/docker-cli/reference/common-patterns.md": "# Docker Common Patterns\n\nReal-world patterns and workflows for common Docker use cases.\n\n## Development Workflow\n\n### Basic App Development\n\n```bash\n# Build and run a development container\ndocker build -t myapp:dev .\ndocker run -d -p 8080:80 --name myapp-dev myapp:dev\ndocker logs -f myapp-dev\ndocker exec -it myapp-dev bash\n```\n\n### Hot Reload Development\n\n```bash\n# Run with volume mount for live code updates\ndocker run -d \\\n  -p 8080:80 \\\n  -v $(pwd)/src:/app/src \\\n  --name myapp-dev \\\n  myapp:dev\n```\n\n## Multi-Stage Builds\n\n### Production Build Pattern\n\n```bash\n# Build targeting specific stage\ndocker build --target production -t myapp:prod .\n\n# Multi-stage Dockerfile example\n# FROM node:18 AS build\n# WORKDIR /app\n# COPY package*.json ./\n# RUN npm ci\n# COPY . .\n# RUN npm run build\n#\n# FROM nginx:alpine AS production\n# COPY --from=build /app/dist /usr/share/nginx/html\n```\n\n## Network Patterns\n\n### Multi-Container Communication\n\n```bash\n# Create custom network\ndocker network create myapp-network\n\n# Run database on network\ndocker run -d \\\n  --name database \\\n  --network myapp-network \\\n  -e POSTGRES_PASSWORD=secret \\\n  postgres:15\n\n# Run app on same network (can access database by name)\ndocker run -d \\\n  --name app \\\n  --network myapp-network \\\n  -p 8080:80 \\\n  -e DATABASE_URL=postgres://database:5432/mydb \\\n  myapp:latest\n```\n\n### Service Discovery\n\n```bash\n# Containers on same network can discover each other by name\ndocker exec app ping database  # Works!\ndocker exec app curl http://api:3000/health  # Works!\n```\n\n## Volume Patterns\n\n### Data Persistence\n\n```bash\n# Create named volume\ndocker volume create myapp-data\n\n# Use volume in container\ndocker run -d \\\n  --name database \\\n  -v myapp-data:/var/lib/postgresql/data \\\n  postgres:15\n\n# Backup volume data\ndocker run --rm \\\n  -v myapp-data:/data \\\n  -v $(pwd):/backup \\\n  ubuntu tar czf /backup/myapp-data-backup.tar.gz /data\n```\n\n### Bind Mounts for Development\n\n```bash\n# Mount current directory\ndocker run -d \\\n  -v $(pwd):/app \\\n  -w /app \\\n  --name dev-container \\\n  node:18 npm run dev\n```\n\n## Registry Operations\n\n### Complete Registry Workflow\n\n```bash\n# Login to registry\ndocker login registry.example.com\n\n# Build and tag image\ndocker build -t myapp:latest .\ndocker tag myapp:latest registry.example.com/myapp:v1.0.0\ndocker tag myapp:latest registry.example.com/myapp:latest\n\n# Push to registry\ndocker push registry.example.com/myapp:v1.0.0\ndocker push registry.example.com/myapp:latest\n\n# Pull from registry on another machine\ndocker pull registry.example.com/myapp:latest\ndocker run -d registry.example.com/myapp:latest\n```\n\n## Docker Compose Patterns\n\n### Full Stack Application\n\n```yaml\n# docker-compose.yml\nversion: '3.8'\nservices:\n  db:\n    image: postgres:15\n    volumes:\n      - db-data:/var/lib/postgresql/data\n    environment:\n      POSTGRES_PASSWORD: secret\n    networks:\n      - backend\n\n  api:\n    build: ./api\n    ports:\n      - \"3000:3000\"\n    environment:\n      DATABASE_URL: postgres://db:5432/mydb\n    depends_on:\n      - db\n    networks:\n      - backend\n      - frontend\n\n  web:\n    build: ./web\n    ports:\n      - \"80:80\"\n    depends_on:\n      - api\n    networks:\n      - frontend\n\nvolumes:\n  db-data:\n\nnetworks:\n  frontend:\n  backend:\n```\n\n```bash\n# Start all services\ndocker compose up -d\n\n# View logs\ndocker compose logs -f\n\n# Scale a service\ndocker compose up -d --scale api=3\n\n# Stop all services\ndocker compose down\n\n# Stop and remove volumes\ndocker compose down -v\n```\n\n## System Maintenance\n\n### Complete Cleanup\n\n```bash\n# Stop all containers\ndocker stop $(docker ps -aq)\n\n# Remove all containers\ndocker rm $(docker ps -aq)\n\n# Remove all images\ndocker rmi $(docker images -q)\n\n# Remove all volumes\ndocker volume rm $(docker volume ls -q)\n\n# Remove all networks (except default)\ndocker network rm $(docker network ls -q)\n\n# Or use system prune (safer)\ndocker system prune -a --volumes -f\n```\n\n### Selective Cleanup\n\n```bash\n# Remove only stopped containers\ndocker container prune -f\n\n# Remove only unused images\ndocker image prune -a -f\n\n# Remove only unused volumes\ndocker volume prune -f\n\n# Remove only unused networks\ndocker network prune -f\n```\n\n## Debugging Patterns\n\n### Inspect Running Container\n\n```bash\n# View container details\ndocker inspect container_name\n\n# View logs with timestamps\ndocker logs -t --tail 100 container_name\n\n# Follow logs in real-time\ndocker logs -f container_name\n\n# Execute shell in container\ndocker exec -it container_name bash\n\n# View resource usage\ndocker stats container_name\n```\n\n### Troubleshoot Container Startup\n\n```bash\n# Run container interactively to debug\ndocker run -it --entrypoint /bin/bash myapp:latest\n\n# Override command\ndocker run -it myapp:latest /bin/sh\n\n# View container exit code\ndocker ps -a\ndocker inspect --format='{{.State.ExitCode}}' container_name\n```\n\n## CI/CD Patterns\n\n### Build and Push in CI\n\n```bash\n# Build with commit hash as tag\ndocker build -t myapp:${COMMIT_SHA} .\ndocker tag myapp:${COMMIT_SHA} myapp:latest\n\n# Push to registry\ndocker login -u $DOCKER_USER -p $DOCKER_PASSWORD\ndocker push myapp:${COMMIT_SHA}\ndocker push myapp:latest\n```\n\n### Multi-Platform Builds\n\n```bash\n# Build for multiple architectures\ndocker buildx create --use\ndocker buildx build \\\n  --platform linux/amd64,linux/arm64 \\\n  -t myapp:latest \\\n  --push \\\n  .\n```\n\n## Health Checks\n\n### Container Health Monitoring\n\n```bash\n# Run with health check\ndocker run -d \\\n  --name myapp \\\n  --health-cmd \"curl -f http://localhost/health || exit 1\" \\\n  --health-interval 30s \\\n  --health-timeout 10s \\\n  --health-retries 3 \\\n  myapp:latest\n\n# Check health status\ndocker inspect --format='{{.State.Health.Status}}' myapp\n```\n\n## Resource Limits\n\n### Production Resource Management\n\n```bash\n# Run with resource constraints\ndocker run -d \\\n  --name myapp \\\n  --memory=512m \\\n  --memory-swap=1g \\\n  --cpus=1.5 \\\n  --restart=unless-stopped \\\n  myapp:latest\n\n# Monitor resource usage\ndocker stats myapp\n```\n\n## Security Patterns\n\n### Run as Non-Root User\n\n```bash\n# In Dockerfile:\n# USER node\n# Or override at runtime:\ndocker run -d --user 1000:1000 myapp:latest\n```\n\n### Read-Only Filesystem\n\n```bash\n# Run with read-only root filesystem\ndocker run -d \\\n  --read-only \\\n  --tmpfs /tmp \\\n  --tmpfs /var/run \\\n  myapp:latest\n```\n\n### Secrets Management\n\n```bash\n# Use environment variables (development only)\ndocker run -d -e SECRET_KEY=value myapp:latest\n\n# Use Docker secrets (Swarm mode)\necho \"my-secret-value\" | docker secret create my-secret -\ndocker service create --secret my-secret myapp:latest\n\n# Mount secrets as files\ndocker run -d \\\n  -v /path/to/secrets:/run/secrets:ro \\\n  myapp:latest\n```\n",
        "plugins/dev/skills/docker-cli/reference/troubleshooting.md": "# Docker Troubleshooting Guide\n\nCommon issues and solutions for Docker containers, images, networks, and volumes.\n\n## Container Issues\n\n### Container Won't Start\n\n**Symptom:** Container exits immediately after starting\n\n**Diagnosis:**\n```bash\n# Check container logs\ndocker logs container_name\n\n# Check exit code\ndocker inspect --format='{{.State.ExitCode}}' container_name\n\n# View full state\ndocker inspect container_name\n```\n\n**Common Causes:**\n1. **Application crashes** â†’ Check application logs\n2. **Missing environment variables** â†’ Verify with `docker inspect`\n3. **Port already in use** â†’ Use `docker ps` or `lsof -i :PORT`\n4. **Entrypoint/CMD issues** â†’ Test with `docker run -it --entrypoint /bin/sh image_name`\n\n**Solutions:**\n```bash\n# Run interactively to debug\ndocker run -it --entrypoint /bin/bash myapp:latest\n\n# Override entrypoint\ndocker run -it --entrypoint /bin/sh myapp:latest\n\n# Check for port conflicts\nlsof -i :8080\ndocker ps --filter \"publish=8080\"\n```\n\n### Container Running But Not Accessible\n\n**Symptom:** Can't access service on published port\n\n**Diagnosis:**\n```bash\n# Verify port mapping\ndocker port container_name\n\n# Check if service is listening inside container\ndocker exec container_name netstat -tlnp\n\n# Test from inside container\ndocker exec container_name curl localhost:80\n```\n\n**Solutions:**\n```bash\n# Ensure correct port mapping (host:container)\ndocker run -p 8080:80 myapp  # Maps container port 80 to host port 8080\n\n# Check firewall rules\nsudo ufw status\nsudo iptables -L\n\n# Verify container network\ndocker inspect --format='{{.NetworkSettings.IPAddress}}' container_name\n```\n\n### Permission Denied Errors\n\n**Symptom:** Volume mount permission errors\n\n**Diagnosis:**\n```bash\n# Check volume permissions\ndocker exec container_name ls -la /mounted/path\n\n# Check user inside container\ndocker exec container_name whoami\ndocker exec container_name id\n```\n\n**Solutions:**\n```bash\n# Run as specific user\ndocker run -u $(id -u):$(id -g) -v $(pwd):/app myapp\n\n# Fix permissions on host\nsudo chown -R $(id -u):$(id -g) ./data\n\n# Use named volume instead of bind mount\ndocker volume create myapp-data\ndocker run -v myapp-data:/app/data myapp\n```\n\n### Container Keeps Restarting\n\n**Symptom:** Container in restart loop\n\n**Diagnosis:**\n```bash\n# Check restart policy\ndocker inspect --format='{{.HostConfig.RestartPolicy.Name}}' container_name\n\n# View logs for crash reason\ndocker logs --tail 50 container_name\n\n# Watch events\ndocker events --filter container=container_name\n```\n\n**Solutions:**\n```bash\n# Remove restart policy temporarily\ndocker update --restart=no container_name\n\n# Fix the underlying issue, then restore\ndocker update --restart=unless-stopped container_name\n```\n\n## Image Issues\n\n### Image Build Fails\n\n**Symptom:** `docker build` command fails\n\n**Common Errors:**\n\n**Error: \"COPY failed: no source files\"**\n```bash\n# Solution: Check .dockerignore isn't excluding needed files\ncat .dockerignore\n\n# Verify files exist\nls -la <path-to-files>\n```\n\n**Error: \"failed to solve with frontend dockerfile.v0\"**\n```bash\n# Solution: Syntax error in Dockerfile\n# Check Dockerfile for typos, invalid instructions\ndocker build --progress=plain .  # Shows detailed error\n```\n\n**Error: \"error checking context: can't stat\"**\n```bash\n# Solution: Build context issue\n# Don't build from root or large directory\n# Create .dockerignore to exclude unnecessary files\n```\n\n### Image Too Large\n\n**Symptom:** Image size is excessive\n\n**Diagnosis:**\n```bash\n# Check image size\ndocker images myapp\n\n# View layer sizes\ndocker history myapp:latest\ndocker history --no-trunc --format=\"{{.Size}}\\t{{.CreatedBy}}\" myapp:latest\n```\n\n**Solutions:**\n```bash\n# Use multi-stage builds\n# Use smaller base images (alpine)\n# Minimize layers\n# Clean up in same RUN command:\nRUN apt-get update && \\\n    apt-get install -y package && \\\n    apt-get clean && \\\n    rm -rf /var/lib/apt/lists/*\n\n# Remove build dependencies after use\nRUN apk add --no-cache --virtual .build-deps gcc && \\\n    # ... build steps ... && \\\n    apk del .build-deps\n```\n\n### Cannot Pull Image\n\n**Symptom:** `docker pull` fails with authentication or network error\n\n**Diagnosis:**\n```bash\n# Check Docker Hub rate limits\ndocker pull ratelimitpreview/test\n\n# Verify authentication\ndocker login\ncat ~/.docker/config.json\n\n# Test network connectivity\nping registry-1.docker.io\ncurl -I https://registry-1.docker.io/v2/\n```\n\n**Solutions:**\n```bash\n# Login to registry\ndocker login\ndocker login registry.example.com\n\n# Use authenticated pulls\ndocker pull username/image:tag\n\n# For rate limits, authenticate or use mirror\ndocker login  # Increases rate limit\n```\n\n## Network Issues\n\n### Cannot Connect Between Containers\n\n**Symptom:** Containers can't communicate\n\n**Diagnosis:**\n```bash\n# List networks\ndocker network ls\n\n# Inspect network\ndocker network inspect bridge\n\n# Check container networks\ndocker inspect --format='{{.NetworkSettings.Networks}}' container_name\n\n# Test connectivity\ndocker exec container1 ping container2\n```\n\n**Solutions:**\n```bash\n# Ensure containers are on same network\ndocker network create mynetwork\ndocker network connect mynetwork container1\ndocker network connect mynetwork container2\n\n# Or use docker-compose (automatic network)\ndocker-compose up\n```\n\n### DNS Resolution Fails\n\n**Symptom:** Container can't resolve hostnames\n\n**Diagnosis:**\n```bash\n# Check DNS settings\ndocker inspect --format='{{.HostConfig.Dns}}' container_name\n\n# Test DNS inside container\ndocker exec container_name nslookup google.com\ndocker exec container_name cat /etc/resolv.conf\n```\n\n**Solutions:**\n```bash\n# Use custom DNS\ndocker run --dns 8.8.8.8 --dns 8.8.4.4 myapp\n\n# Or configure daemon\n# /etc/docker/daemon.json:\n{\n  \"dns\": [\"8.8.8.8\", \"8.8.4.4\"]\n}\n\n# Restart Docker daemon\nsudo systemctl restart docker\n```\n\n## Volume Issues\n\n### Data Not Persisting\n\n**Symptom:** Data lost after container restart\n\n**Diagnosis:**\n```bash\n# Check if volume is mounted\ndocker inspect --format='{{.Mounts}}' container_name\n\n# List volumes\ndocker volume ls\n\n# Inspect volume\ndocker volume inspect myvolume\n```\n\n**Solutions:**\n```bash\n# Use named volume\ndocker volume create mydata\ndocker run -v mydata:/app/data myapp\n\n# Or use bind mount with absolute path\ndocker run -v /absolute/path:/app/data myapp\n\n# Verify mount\ndocker exec container ls -la /app/data\n```\n\n### Volume Permission Issues\n\n**Symptom:** Can't write to volume\n\n**Solutions:**\n```bash\n# Check ownership\ndocker exec container ls -ld /mounted/path\n\n# Match container user with host user\ndocker run -u $(id -u):$(id -g) -v $(pwd):/data myapp\n\n# Fix on host (for bind mounts)\nsudo chown -R $(id -u):$(id -g) ./local-path\n```\n\n## Performance Issues\n\n### Container Using Too Much Memory\n\n**Diagnosis:**\n```bash\n# Check current usage\ndocker stats container_name\n\n# Check limits\ndocker inspect --format='{{.HostConfig.Memory}}' container_name\n```\n\n**Solutions:**\n```bash\n# Set memory limit\ndocker run -m 512m myapp\n\n# Set memory reservation (soft limit)\ndocker run --memory-reservation=256m myapp\n\n# Set swap limit\ndocker run -m 512m --memory-swap=1g myapp\n\n# Update running container\ndocker update --memory=512m container_name\n```\n\n### High CPU Usage\n\n**Solutions:**\n```bash\n# Limit CPU\ndocker run --cpus=1.5 myapp\n\n# Set CPU shares (relative weight)\ndocker run --cpu-shares=512 myapp\n\n# Pin to specific CPUs\ndocker run --cpuset-cpus=\"0,1\" myapp\n```\n\n## Registry Issues\n\n### Push/Pull Timeouts\n\n**Diagnosis:**\n```bash\n# Test network to registry\ncurl -I https://registry.example.com/v2/\n\n# Check registry authentication\ndocker login registry.example.com\n```\n\n**Solutions:**\n```bash\n# Increase timeout in daemon config\n# /etc/docker/daemon.json:\n{\n  \"max-concurrent-downloads\": 3,\n  \"max-concurrent-uploads\": 5\n}\n\n# Use compression\ndocker save myapp | gzip > myapp.tar.gz\n\n# Split large images into layers\n# Use multi-stage builds\n```\n\n## System Issues\n\n### Docker Daemon Won't Start\n\n**Diagnosis:**\n```bash\n# Check daemon status\nsudo systemctl status docker\n\n# View daemon logs\nsudo journalctl -u docker.service\nsudo journalctl -u docker.service --since \"1 hour ago\"\n\n# Check configuration\ndocker info\n```\n\n**Solutions:**\n```bash\n# Restart daemon\nsudo systemctl restart docker\n\n# Reset Docker (WARNING: removes all data)\ndocker system prune -a --volumes\n\n# Check for corrupted daemon.json\nsudo nano /etc/docker/daemon.json\n# Ensure valid JSON\n\n# Reinstall Docker (last resort)\nsudo apt-get purge docker-ce\nsudo apt-get install docker-ce\n```\n\n### Disk Space Issues\n\n**Diagnosis:**\n```bash\n# Check disk usage\ndocker system df\ndocker system df -v\n\n# Find large images\ndocker images --format \"{{.Size}}\\t{{.Repository}}:{{.Tag}}\" | sort -h\n\n# Find old containers\ndocker ps -a --format \"{{.CreatedAt}}\\t{{.Names}}\"\n```\n\n**Solutions:**\n```bash\n# Clean up unused resources\ndocker system prune -a --volumes\n\n# Remove specific items\ndocker container prune  # Stopped containers\ndocker image prune -a   # Unused images\ndocker volume prune     # Unused volumes\ndocker network prune    # Unused networks\n\n# Set cleanup cron job\n# Add to crontab: 0 2 * * * docker system prune -f\n```\n\n## Debug Tools\n\n### Useful Debug Commands\n\n```bash\n# View detailed container info\ndocker inspect container_name | jq '.'\n\n# Stream events in real-time\ndocker events --filter container=myapp\n\n# Check container processes\ndocker top container_name\n\n# View container filesystem changes\ndocker diff container_name\n\n# Export container filesystem\ndocker export container_name > container.tar\n\n# Run debugging tools\ndocker run --rm -it --net=container:myapp nicolaka/netshoot\n```\n\n### Enable Debug Logging\n\n```bash\n# Edit /etc/docker/daemon.json\n{\n  \"debug\": true,\n  \"log-level\": \"debug\"\n}\n\n# Restart daemon\nsudo systemctl restart docker\n\n# View debug logs\nsudo journalctl -u docker.service -f\n```\n",
        "plugins/dev/skills/github-cli/SKILL.md": "---\nname: github-cli\ndescription: GitHub CLI (gh) expert for repository management. Use when users need to manage repos, issues, PRs, Actions, secrets, or interact with GitHub.\nallowed-tools: Bash(gh:*)\n---\n\n# GitHub CLI Guide\n\nGitHub CLI (`gh`) enables command-line management of repositories, issues, pull requests, and GitHub workflows. This guide provides essential workflows and quick references for common GitHub operations.\n\n## Quick Start\n\n```bash\n# Authenticate with GitHub\ngh auth login\n\n# Check authentication status\ngh auth status\n\n# View current repository\ngh repo view\n\n# List open issues\ngh issue list\n\n# List open pull requests\ngh pr list\n```\n\n## Common Workflows\n\n### Workflow 1: Fork and Contribute\n\n```bash\n# Fork repository\ngh repo fork owner/repo\n\n# Clone your fork\ngh repo clone your-username/repo\n\n# Create feature branch\ncd repo\ngit checkout -b feature/my-feature\n\n# Make changes, then create PR\ngh pr create --title \"Add feature\" --body \"Description of changes\"\n\n# Push to GitHub\ngit push origin feature/my-feature\n```\n\n### Workflow 2: Issue Management\n\n```bash\n# Create issue\ngh issue create --title \"Bug: Login fails\" --body \"Steps to reproduce...\"\n\n# List assigned to you\ngh issue list --assignee @me\n\n# View issue details\ngh issue view 123\n\n# Close issue with comment\ngh issue close 123 --comment \"Fixed in PR #456\"\n```\n\n### Workflow 3: Pull Request Review\n\n```bash\n# Create PR (draft for review)\ngh pr create --draft --title \"Work in progress\"\n\n# List open PRs\ngh pr list\n\n# View PR with diff\ngh pr view 123\ngh pr diff 123\n\n# Checkout PR branch locally\ngh pr checkout 123\n\n# Merge when ready\ngh pr merge 123 --squash\n```\n\n### Workflow 4: GitHub Actions Management\n\n```bash\n# List recent workflow runs\ngh run list\n\n# View run details and logs\ngh run view 123456 --log\n\n# Rerun failed jobs\ngh run rerun 123456 --failed\n\n# Cancel running workflow\ngh run cancel 123456\n\n# Trigger workflow manually\ngh workflow run ci.yml --field environment=production\n```\n\n### Workflow 5: Release Management\n\n```bash\n# Create release\ngh release create v1.0.0 --title \"Version 1.0.0\" --notes \"Release notes here\"\n\n# List releases\ngh release list\n\n# View release details\ngh release view v1.0.0\n\n# Upload assets to release\ngh release upload v1.0.0 ./build/app.tar.gz\n```\n\n## Decision Tree\n\n**When to use which command:**\n\n- **To manage repositories**: Use `gh repo` (create, clone, fork, view)\n- **To work with issues**: Use `gh issue` (create, list, view, close)\n- **To work with PRs**: Use `gh pr` (create, list, view, checkout, merge)\n- **To manage workflows**: Use `gh run` and `gh workflow` (list, view, rerun, trigger)\n- **To create releases**: Use `gh release` (create, list, view, upload)\n- **To manage secrets**: Use `gh secret` (set, list)\n- **To manage variables**: Use `gh variable` (set, list)\n- **For detailed command syntax**: See [Commands Reference](./reference/commands-reference.md)\n- **For complex scenarios**: See [Common Patterns](./reference/common-patterns.md)\n- **For troubleshooting**: See [Troubleshooting Guide](./reference/troubleshooting.md)\n\n## Common Patterns\n\n### Repository Management\n\n```bash\n# View repository details\ngh repo view --web  # Open in browser\n\n# Fork and setup\ngh repo fork owner/repo --clone\n\n# List your repositories\ngh repo list --limit 20\n\n# List organization repos\ngh repo list myorg --visibility public\n```\n\n### Issue Workflows\n\n```bash\n# Create issue with labels and assignees\ngh issue create \\\n  --title \"Bug report\" \\\n  --body \"Description\" \\\n  --label \"bug,needs-triage\" \\\n  --assignee @me\n\n# Filter issues\ngh issue list --state all --assignee @me\ngh issue list --label \"bug\" --state open\n```\n\n### Pull Request Workflows\n\n```bash\n# Create PR with options\ngh pr create \\\n  --title \"Fix: Critical bug\" \\\n  --body \"Fixes #123\" \\\n  --label \"bug,fix\" \\\n  --reviewer reviewer1,reviewer2\n\n# Merge strategies\ngh pr merge 123 --squash     # Squash commits\ngh pr merge 123 --rebase     # Rebase merge\ngh pr merge 123              # Merge commit (default)\n```\n\n### GitHub Actions & Workflows\n\n```bash\n# List workflows\ngh workflow list\n\n# Enable/disable workflow\ngh workflow enable ci.yml\ngh workflow disable ci.yml\n\n# Monitor runs\ngh run list --workflow=ci.yml --status failure\n```\n\n## Troubleshooting\n\n**Common Issues:**\n\n1. **Authentication failed**\n   - Solution: Run `gh auth login` and follow prompts\n   - See: [Authentication Issues](./reference/troubleshooting.md#authentication-issues)\n\n2. **Can't push to remote**\n   - Quick fix: Verify SSH key with `gh auth status`\n   - See: [SSH Key Issues](./reference/troubleshooting.md#ssh-key-issues)\n\n3. **PR merge fails**\n   - Quick fix: Check branch protection rules with `gh repo view`\n   - See: [Merge Conflicts](./reference/troubleshooting.md#merge-conflicts)\n\n4. **Workflow doesn't trigger**\n   - Quick fix: Verify branch protection with `gh workflow list`\n   - See: [Actions Issues](./reference/troubleshooting.md#workflow-issues)\n\n5. **Rate limit errors**\n   - Quick fix: Check limits with `gh api rate-limit`\n   - See: [Rate Limiting](./reference/troubleshooting.md#rate-limiting)\n\nFor detailed troubleshooting steps, see the [Troubleshooting Guide](./reference/troubleshooting.md).\n\n## Reference Files\n\n**Load as needed for detailed information:**\n\n- **[Commands Reference](./reference/commands-reference.md)** - Complete CLI command documentation with all flags and options. Use when you need exact syntax or flag details for any gh command.\n\n- **[Common Patterns](./reference/common-patterns.md)** - Real-world patterns and workflows for repository management, issue/PR workflows, CI/CD integration, team collaboration, and release management. Use for implementing specific workflows or integrations.\n\n- **[Troubleshooting Guide](./reference/troubleshooting.md)** - Detailed error messages, diagnosis steps, and resolution strategies for authentication, SSH, API, network, and workflow issues. Use when encountering errors or unexpected behavior.\n\n**When to use each reference:**\n\n- Use **Commands Reference** when you need exact syntax, flag combinations, or comprehensive command documentation\n- Use **Common Patterns** for implementing team workflows, CI/CD pipelines, or advanced release management\n- Use **Troubleshooting** when authentication fails, PRs won't merge, or workflows don't trigger\n\n## Resources\n\n- Official Docs: https://cli.github.com\n- GitHub Docs: https://docs.github.com\n- GitHub Community: https://github.community\n- Repository: https://github.com/cli/cli\n",
        "plugins/dev/skills/github-cli/reference/commands-reference.md": "# GitHub CLI Commands Reference\n\nComplete reference for all `gh` CLI commands with detailed options and flags.\n\n## Authentication\n\n### `gh auth login`\n\nAuthenticate with GitHub.\n\n```bash\n# Interactive login\ngh auth login\n\n# Login with HTTPS\ngh auth login --web\n\n# Login with SSH\ngh auth login --ssh\n\n# Login to GitHub Enterprise\ngh auth login --hostname github.enterprise.com\n```\n\n### `gh auth logout`\n\nLog out from GitHub.\n\n```bash\n# Logout from GitHub\ngh auth logout\n\n# Logout from specific host\ngh auth logout --hostname github.enterprise.com\n```\n\n### `gh auth status`\n\nCheck authentication status.\n\n```bash\n# Show authentication status\ngh auth status\n\n# Show for specific host\ngh auth status --hostname github.enterprise.com\n```\n\n## Repository Management\n\n### `gh repo create`\n\nCreate a new repository.\n\n```bash\n# Create interactively\ngh repo create\n\n# Create with name\ngh repo create my-repo\n\n# Create from template\ngh repo create my-repo --template owner/template-repo\n\n# Create as public\ngh repo create my-repo --public\n\n# Create as private\ngh repo create my-repo --private\n```\n\n### `gh repo clone`\n\nClone a repository.\n\n```bash\n# Clone repository\ngh repo clone owner/repo\n\n# Clone to specific directory\ngh repo clone owner/repo ./my-dir\n\n# Clone with SSH\ngh repo clone owner/repo -- --config core.sshCommand=\"ssh -i ~/.ssh/id_ed25519\"\n```\n\n### `gh repo fork`\n\nFork a repository.\n\n```bash\n# Fork current repository\ngh repo fork\n\n# Fork specific repository\ngh repo fork owner/repo\n\n# Fork and clone\ngh repo fork owner/repo --clone\n\n# Fork to organization\ngh repo fork owner/repo --org myorg\n```\n\n### `gh repo list`\n\nList repositories.\n\n```bash\n# List your repositories\ngh repo list\n\n# List with limit\ngh repo list --limit 10\n\n# List organization repositories\ngh repo list myorg\n\n# List by visibility\ngh repo list --visibility public\ngh repo list --visibility private\n\n# Filter by language\ngh repo list --language go\n```\n\n### `gh repo view`\n\nView repository details.\n\n```bash\n# View current repository\ngh repo view\n\n# View specific repository\ngh repo view owner/repo\n\n# View in browser\ngh repo view --web\n\n# View as JSON\ngh repo view --json name,description\n```\n\n## Issues\n\n### `gh issue create`\n\nCreate a new issue.\n\n```bash\n# Create interactively\ngh issue create\n\n# Create with title and body\ngh issue create --title \"Bug: Login fails\" --body \"Description\"\n\n# Create with labels\ngh issue create --title \"Bug\" --label \"bug,critical\"\n\n# Assign to user\ngh issue create --title \"Task\" --assignee @me\n\n# Assign to multiple users\ngh issue create --title \"Task\" --assignee user1,user2\n\n# Add milestone\ngh issue create --title \"Task\" --milestone \"v1.0\"\n```\n\n### `gh issue list`\n\nList issues.\n\n```bash\n# List open issues\ngh issue list\n\n# List all issues\ngh issue list --state all\n\n# List by status\ngh issue list --state closed\n\n# Filter by assignee\ngh issue list --assignee @me\n\n# Filter by label\ngh issue list --label \"bug\"\n\n# Filter by author\ngh issue list --author me\n\n# Limit results\ngh issue list --limit 20\n```\n\n### `gh issue view`\n\nView an issue.\n\n```bash\n# View issue by number\ngh issue view 123\n\n# View in browser\ngh issue view 123 --web\n\n# View as JSON\ngh issue view 123 --json title,body,state\n```\n\n### `gh issue close`\n\nClose an issue.\n\n```bash\n# Close issue\ngh issue close 123\n\n# Close with comment\ngh issue close 123 --comment \"Fixed in PR #456\"\n```\n\n### `gh issue reopen`\n\nReopen an issue.\n\n```bash\n# Reopen issue\ngh issue reopen 123\n```\n\n## Pull Requests\n\n### `gh pr create`\n\nCreate a pull request.\n\n```bash\n# Create interactively\ngh pr create\n\n# Create with title and body\ngh pr create --title \"Fix bug\" --body \"Description\"\n\n# Create draft PR\ngh pr create --draft\n\n# Create with labels\ngh pr create --title \"Fix\" --label \"fix,reviewed\"\n\n# Request reviewers\ngh pr create --title \"PR\" --reviewer user1,user2\n\n# Assign to users\ngh pr create --title \"PR\" --assignee user1,user2\n\n# Link to issue\ngh pr create --title \"Fix\" --body \"Fixes #123\"\n```\n\n### `gh pr list`\n\nList pull requests.\n\n```bash\n# List open PRs\ngh pr list\n\n# List all PRs\ngh pr list --state all\n\n# Filter by status\ngh pr list --state merged\n\n# Filter by author\ngh pr list --author @me\n\n# Filter by reviewer\ngh pr list --reviewer me\n\n# Limit results\ngh pr list --limit 20\n```\n\n### `gh pr view`\n\nView a pull request.\n\n```bash\n# View PR by number\ngh pr view 123\n\n# View in browser\ngh pr view 123 --web\n\n# View PR diff\ngh pr diff 123\n\n# View as JSON\ngh pr view 123 --json title,body,state\n```\n\n### `gh pr checkout`\n\nCheck out a pull request.\n\n```bash\n# Checkout PR branch\ngh pr checkout 123\n\n# Checkout by URL\ngh pr checkout https://github.com/owner/repo/pull/123\n```\n\n### `gh pr merge`\n\nMerge a pull request.\n\n```bash\n# Merge PR (default)\ngh pr merge 123\n\n# Squash and merge\ngh pr merge 123 --squash\n\n# Rebase and merge\ngh pr merge 123 --rebase\n\n# Merge and delete branch\ngh pr merge 123 --delete-branch\n\n# Merge without CI checks\ngh pr merge 123 --admin\n```\n\n### `gh pr close`\n\nClose a pull request.\n\n```bash\n# Close PR\ngh pr close 123\n\n# Close with comment\ngh pr close 123 --comment \"Not needed anymore\"\n```\n\n### `gh pr review`\n\nManage PR reviews.\n\n```bash\n# Approve PR\ngh pr review 123 --approve\n\n# Request changes\ngh pr review 123 --request-changes --body \"Needs revision\"\n\n# Comment on PR\ngh pr review 123 --comment --body \"Looks good!\"\n```\n\n## GitHub Actions\n\n### `gh run list`\n\nList workflow runs.\n\n```bash\n# List recent runs\ngh run list\n\n# Filter by workflow\ngh run list --workflow=ci.yml\n\n# Filter by status\ngh run list --status failure\n\n# Filter by branch\ngh run list --branch main\n\n# Limit results\ngh run list --limit 10\n```\n\n### `gh run view`\n\nView workflow run details.\n\n```bash\n# View run details\ngh run view 123456\n\n# View logs\ngh run view 123456 --log\n\n# View in browser\ngh run view 123456 --web\n\n# View as JSON\ngh run view 123456 --json status,conclusion\n```\n\n### `gh run rerun`\n\nRerun a workflow.\n\n```bash\n# Rerun workflow\ngh run rerun 123456\n\n# Rerun failed jobs only\ngh run rerun 123456 --failed\n```\n\n### `gh run cancel`\n\nCancel a workflow run.\n\n```bash\n# Cancel run\ngh run cancel 123456\n```\n\n### `gh workflow list`\n\nList workflows.\n\n```bash\n# List all workflows\ngh workflow list\n\n# List with details\ngh workflow list --all\n```\n\n### `gh workflow run`\n\nTrigger a workflow.\n\n```bash\n# Trigger workflow\ngh workflow run ci.yml\n\n# Trigger with inputs\ngh workflow run deploy.yml --field environment=production\n\n# Trigger on branch\ngh workflow run ci.yml --ref main\n```\n\n### `gh workflow enable`\n\nEnable a workflow.\n\n```bash\n# Enable workflow\ngh workflow enable ci.yml\n```\n\n### `gh workflow disable`\n\nDisable a workflow.\n\n```bash\n# Disable workflow\ngh workflow disable ci.yml\n```\n\n## Releases\n\n### `gh release create`\n\nCreate a release.\n\n```bash\n# Create release\ngh release create v1.0.0\n\n# Create with title and notes\ngh release create v1.0.0 --title \"Version 1.0.0\" --notes \"Release notes\"\n\n# Create as draft\ngh release create v1.0.0 --draft\n\n# Create as prerelease\ngh release create v1.0.0 --prerelease\n\n# Create with assets\ngh release create v1.0.0 ./build/app.tar.gz ./build/app.zip\n```\n\n### `gh release list`\n\nList releases.\n\n```bash\n# List releases\ngh release list\n\n# Limit results\ngh release list --limit 10\n```\n\n### `gh release view`\n\nView release details.\n\n```bash\n# View release\ngh release view v1.0.0\n\n# View in browser\ngh release view v1.0.0 --web\n\n# View as JSON\ngh release view v1.0.0 --json body,tagName\n```\n\n### `gh release upload`\n\nUpload assets to release.\n\n```bash\n# Upload asset\ngh release upload v1.0.0 ./build/app.tar.gz\n\n# Upload multiple assets\ngh release upload v1.0.0 ./build/*.tar.gz\n```\n\n### `gh release delete`\n\nDelete a release.\n\n```bash\n# Delete release\ngh release delete v1.0.0\n```\n\n## Secrets & Variables\n\n### `gh secret set`\n\nSet a secret.\n\n```bash\n# Set secret interactively\ngh secret set SECRET_NAME\n\n# Set secret from stdin\ngh secret set SECRET_NAME < secret.txt\n\n# Set organization secret\ngh secret set SECRET_NAME --org myorg\n\n# Set environment secret\ngh secret set SECRET_NAME --env production\n```\n\n### `gh secret list`\n\nList secrets.\n\n```bash\n# List repository secrets\ngh secret list\n\n# List organization secrets\ngh secret list --org myorg\n```\n\n### `gh variable set`\n\nSet a variable.\n\n```bash\n# Set variable\ngh variable set VAR_NAME --body \"value\"\n\n# Set organization variable\ngh variable set VAR_NAME --body \"value\" --org myorg\n\n# Set environment variable\ngh variable set VAR_NAME --body \"value\" --env production\n```\n\n### `gh variable list`\n\nList variables.\n\n```bash\n# List repository variables\ngh variable list\n\n# List organization variables\ngh variable list --org myorg\n```\n\n## Search\n\n### `gh search repos`\n\nSearch repositories.\n\n```bash\n# Search repositories\ngh search repos \"machine learning\"\n\n# Filter by language\ngh search repos \"web scraping\" --language=python\n\n# Filter by stars\ngh search repos \"kubernetes\" --stars=\">1000\"\n\n# Limit results\ngh search repos \"react\" --limit 10\n```\n\n### `gh search issues`\n\nSearch issues.\n\n```bash\n# Search issues\ngh search issues \"bug\"\n\n# Search in repository\ngh search issues \"performance\" --repo=owner/repo\n\n# Filter by state\ngh search issues \"open\" --state=open\n\n# Limit results\ngh search issues \"help wanted\" --limit 5\n```\n\n### `gh search prs`\n\nSearch pull requests.\n\n```bash\n# Search PRs\ngh search prs \"feature\"\n\n# Search merged PRs\ngh search prs \"refactor\" --state=merged\n\n# Filter by language\ngh search prs \"security\" --language=go\n\n# Limit results\ngh search prs \"review\" --limit 10\n```\n\n## Additional Commands\n\n### `gh api`\n\nMake API requests.\n\n```bash\n# GET request\ngh api /user\n\n# POST request\ngh api /repos/owner/repo/issues -f title=\"Bug\" -f body=\"Description\"\n\n# List paginated results\ngh api /repos/owner/repo/issues --paginate\n```\n\n### `gh gist`\n\nManage gists.\n\n```bash\n# Create gist\ngh gist create file.txt\n\n# List gists\ngh gist list\n\n# View gist\ngh gist view gistid\n```\n\n### `gh label`\n\nManage labels.\n\n```bash\n# Create label\ngh label create \"bug\" --color \"ff0000\"\n\n# List labels\ngh label list\n\n# Delete label\ngh label delete \"bug\"\n```\n\n### `gh completion`\n\nGenerate shell completion.\n\n```bash\n# Zsh completion\ngh completion -s zsh\n\n# Bash completion\ngh completion -s bash\n\n# Fish completion\ngh completion -s fish\n```\n\n### `gh config`\n\nManage configuration.\n\n```bash\n# Set value\ngh config set editor vim\n\n# Get value\ngh config get editor\n\n# List all config\ngh config list\n```\n\n## Global Flags\n\nAll `gh` commands support these flags:\n\n- `--help` â€” Show help information\n- `--version` â€” Show version information\n- `--repo owner/repo` â€” Select repository\n- `--web` â€” Open in web browser\n- `--json` â€” Output as JSON\n",
        "plugins/dev/skills/github-cli/reference/common-patterns.md": "# GitHub CLI Common Patterns\n\nReal-world patterns and workflows for common GitHub use cases.\n\n## Repository Management\n\n### Fork and Contribute Workflow\n\n```bash\n# Fork repository\ngh repo fork owner/repo --clone\n\n# Navigate to cloned repo\ncd repo\n\n# Create feature branch\ngit checkout -b feature/my-feature\n\n# Make your changes\n# ...\n\n# Commit and push\ngit add .\ngit commit -m \"Add feature\"\ngit push origin feature/my-feature\n\n# Create PR from CLI\ngh pr create \\\n  --title \"Add my feature\" \\\n  --body \"This PR adds...\" \\\n  --head feature/my-feature\n\n# Wait for feedback, make changes if needed\n# Merge when approved\ngh pr merge $(gh pr list --author @me --state open --limit 1 --json number -q)\n```\n\n### Cloning Organization Repos\n\n```bash\n# List organization repos\ngh repo list myorg\n\n# Clone specific repo\ngh repo clone myorg/repo\n\n# Clone all organization repos\nfor repo in $(gh repo list myorg --json nameWithOwner -q); do\n  gh repo clone \"$repo\"\ndone\n```\n\n### Repository Overview\n\n```bash\n# View repository details\ngh repo view owner/repo\n\n# View in browser\ngh repo view owner/repo --web\n\n# View as JSON\ngh repo view owner/repo --json name,description,languages,forkCount,stargazerCount\n```\n\n## Issue Management\n\n### Creating Issues with Context\n\n```bash\n# Create bug report\ngh issue create \\\n  --title \"Bug: Login fails on Firefox\" \\\n  --body \"Steps to reproduce:\n1. Go to login page\n2. Enter credentials\n3. Click login\n\nExpected: Login succeeds\nActual: Error message appears\" \\\n  --label \"bug,firefox\" \\\n  --assignee @me\n\n# Create feature request\ngh issue create \\\n  --title \"Feature: Dark mode\" \\\n  --body \"Users request dark mode for accessibility\" \\\n  --label \"enhancement,feature-request\"\n\n# Create task\ngh issue create \\\n  --title \"Task: Update dependencies\" \\\n  --body \"Update all npm packages to latest versions\" \\\n  --label \"maintenance\" \\\n  --assignee developer1\n```\n\n### Managing Issues\n\n```bash\n# List issues assigned to you\ngh issue list --assignee @me\n\n# List issues by label\ngh issue list --label \"bug\"\n\n# List high-priority issues\ngh issue list --label \"critical,high\" --state open\n\n# View issue and display as JSON\ngh issue view 123 --json title,body,labels,assignees\n\n# Close issue with comment\ngh issue close 123 --comment \"Fixed in PR #456\"\n\n# Reopen issue\ngh issue reopen 123\n\n# Bulk close issues (careful!)\ngh issue list --label \"stale\" --state open --json number -q | \\\n  xargs -I {} gh issue close {} --comment \"Closing stale issue\"\n```\n\n### Issue Automation\n\n```bash\n# Create issue from template\ngh issue create \\\n  --title \"Weekly sync\" \\\n  --body \"$(cat .github/issue_template/weekly_sync.md)\" \\\n  --label \"meeting,recurring\"\n\n# List and track open issues\ngh issue list --state open \\\n  --json number,title,labels,assignees \\\n  --template '{{range .}}[{{.number}}] {{.title}}{{end}}'\n```\n\n## Pull Request Workflows\n\n### Creating Pull Requests\n\n```bash\n# Create feature PR\ngh pr create \\\n  --title \"Feature: Add user authentication\" \\\n  --body \"Implements OAuth2 login flow\n\nFixes #42\n\n## Changes\n- Add auth endpoints\n- Add login page\n- Add session management\" \\\n  --label \"feature,auth\" \\\n  --reviewer reviewer1,reviewer2 \\\n  --draft\n\n# Create bug fix PR\ngh pr create \\\n  --title \"Fix: Correct null pointer exception\" \\\n  --body \"Fixes #123\" \\\n  --label \"fix,critical\"\n\n# Create from existing branch\ngit push origin feature/my-feature\ngh pr create \\\n  --head feature/my-feature \\\n  --base main \\\n  --title \"My feature\" \\\n  --body \"Description\"\n```\n\n### Managing Pull Requests\n\n```bash\n# List your open PRs\ngh pr list --author @me --state open\n\n# List PRs awaiting your review\ngh pr list --reviewer @me --state open\n\n# View PR with full details\ngh pr view 123 --web\n\n# View PR diff\ngh pr diff 123\n\n# Checkout PR branch locally\ngh pr checkout 456\n\n# Review and approve\ngh pr review 456 --approve --body \"Looks great!\"\n\n# Request changes\ngh pr review 456 --request-changes --body \"Please update X\"\n\n# Merge with squash\ngh pr merge 456 --squash --delete-branch\n\n# Merge rebase strategy\ngh pr merge 456 --rebase --delete-branch\n```\n\n### PR Status Tracking\n\n```bash\n# List PRs by status\ngh pr list --state open\ngh pr list --state draft\ngh pr list --state merged\ngh pr list --state closed\n\n# Filter by label\ngh pr list --label \"needs-review\"\n\n# Track PR with notifications\ngh pr view 123 --json statusCheckRollup -q | jq .\n\n# List stale PRs\ngh pr list --state open --json number,updatedAt,title | \\\n  jq '.[] | select(.updatedAt < now - 86400*7)'\n```\n\n## GitHub Actions & CI/CD\n\n### Monitoring Workflows\n\n```bash\n# List recent runs\ngh run list\n\n# List failed runs\ngh run list --status failure\n\n# List runs for specific workflow\ngh run list --workflow=ci.yml\n\n# View run details\ngh run view 123456 --log\n\n# Follow run in real-time\ngh run view 123456 --log | tail -f\n```\n\n### Debugging Workflows\n\n```bash\n# View workflow logs\ngh run view 123456 --log\n\n# Check workflow configuration\ngh api repos/owner/repo/actions/workflows/ci.yml\n\n# Rerun failed jobs\ngh run rerun 123456 --failed\n\n# Rerun entire workflow\ngh run rerun 123456\n\n# Cancel stuck workflow\ngh run cancel 123456\n```\n\n### Workflow Automation\n\n```bash\n# Trigger workflow with inputs\ngh workflow run deploy.yml \\\n  --field environment=production \\\n  --field version=1.0.0\n\n# List all workflows\ngh workflow list\n\n# Enable/disable workflow\ngh workflow disable nightly.yml\ngh workflow enable nightly.yml\n\n# View workflow status\ngh api repos/owner/repo/actions/workflows | jq '.workflows[] | {name, state}'\n```\n\n## Release Management\n\n### Creating Releases\n\n```bash\n# Create simple release\ngh release create v1.0.0 --title \"Version 1.0.0\"\n\n# Create with release notes\ngh release create v1.0.0 \\\n  --title \"Version 1.0.0\" \\\n  --notes \"Major new features and improvements\"\n\n# Create draft release (for review)\ngh release create v1.0.0 --draft\n\n# Create prerelease\ngh release create v1.0.0-beta.1 --prerelease\n\n# Create with assets\ngh release create v1.0.0 \\\n  ./dist/app.tar.gz \\\n  ./dist/app.zip \\\n  ./CHANGELOG.md\n\n# Create from git tag\ngit tag v1.0.0 && git push --tags\ngh release create v1.0.0 --generate-notes\n```\n\n### Managing Releases\n\n```bash\n# List releases\ngh release list\n\n# View release details\ngh release view v1.0.0 --web\n\n# Upload additional assets\ngh release upload v1.0.0 ./docs/guide.pdf\n\n# Delete release\ngh release delete v1.0.0\n\n# Generate release notes from commits\ngh release create v1.0.0 --generate-notes\n```\n\n## Team Collaboration\n\n### Managing Reviewers\n\n```bash\n# Request multiple reviewers\ngh pr create \\\n  --title \"Feature PR\" \\\n  --reviewer user1,user2,user3\n\n# View PR reviews\ngh pr view 123 --json reviews\n\n# Review PR as approver\ngh pr review 123 --approve\n\n# Review with comment\ngh pr review 123 --comment --body \"Please check line 45\"\n\n# Request changes\ngh pr review 123 --request-changes --body \"Needs revision\"\n```\n\n### Code Review Workflow\n\n```bash\n# List PRs awaiting your review\ngh pr list --reviewer @me --state open\n\n# View PR details\ngh pr view 456 --web\n\n# View PR diff locally\ngh pr checkout 456\ngit diff main\n\n# Add review comment\ngh pr review 456 --comment --body \"Consider using async/await here\"\n\n# Approve PR\ngh pr review 456 --approve --body \"Approved!\"\n\n# Request changes\ngh pr review 456 --request-changes --body \"Please address comments\"\n```\n\n## Searching and Filtering\n\n### Finding Issues\n\n```bash\n# Search for open bugs\ngh search issues \"bug\" --state open --repo owner/repo\n\n# Search for features requested\ngh search issues \"type:issue is:open label:enhancement\"\n\n# Search issues in organization\ngh search issues \"help wanted\" --repo owner/org\n\n# Find stale issues\ngh issue list --state open \\\n  --json number,title,updatedAt | \\\n  jq '.[] | select(.updatedAt | < now - 86400*30)'\n```\n\n### Finding PRs\n\n```bash\n# Search for merged feature PRs\ngh search prs \"feature\" --state merged --repo owner/repo\n\n# Find PRs by author\ngh pr list --author developer1 --state merged\n\n# Find PRs waiting for review\ngh pr list --state open \\\n  --json number,title,reviewDecision | \\\n  jq '.[] | select(.reviewDecision == \"REVIEW_REQUIRED\")'\n\n# Find draft PRs\ngh pr list --state open --json isDraft --jq '.[] | select(.isDraft)'\n```\n\n## Advanced Workflows\n\n### Batch Operations\n\n```bash\n# Close all stale issues\ngh issue list --state open --label \"stale\" --json number -q | \\\n  while read issue; do\n    gh issue close \"$issue\" --comment \"Closing stale issue\"\n  done\n\n# Label all new issues\ngh issue list --state open --json number -q | \\\n  while read issue; do\n    gh issue edit \"$issue\" --add-label \"needs-triage\"\n  done\n```\n\n### CI Integration\n\n```bash\n# Create issue from failing test\ngh issue create \\\n  --title \"CI: Test failure in payment module\" \\\n  --body \"Test 'test_payment_processing' failed\nBuild: #1234\" \\\n  --label \"ci-failure,test\" \\\n  --assignee team-lead\n\n# Comment on PR about CI status\ngh pr comment 123 --body \"CI checks passed! Ready for review.\"\n```\n\n### Documentation & Templates\n\n```bash\n# Create issue from template\ncat > issue-template.md << 'EOF'\n# Bug Report\n\n## Environment\n- OS:\n- Version:\n\n## Steps to Reproduce\n1.\n2.\n3.\n\n## Expected Behavior\n\n## Actual Behavior\nEOF\n\ngh issue create \\\n  --title \"Bug: \" \\\n  --body \"$(cat issue-template.md)\" \\\n  --label \"bug\"\n```\n\n## Scripting Examples\n\n### Dashboard of Your Work\n\n```bash\n# Summary of your GitHub activity\necho \"=== Your Open Issues ===\"\ngh issue list --assignee @me --state open -q\n\necho \"\"\necho \"=== Your Open PRs ===\"\ngh pr list --author @me --state open -q\n\necho \"\"\necho \"=== PRs Awaiting Your Review ===\"\ngh pr list --reviewer @me --state open -q\n```\n\n### Automated Reporting\n\n```bash\n# Weekly stats\ngh run list --limit 7 --json status -q | \\\n  jq 'group_by(.status) | map({status: .[0].status, count: length})'\n\n# PR metrics\ngh pr list --state merged --limit 100 \\\n  --json mergedAt,author \\\n  --jq 'map(.author.login) | unique' | wc -l\n```\n",
        "plugins/dev/skills/github-cli/reference/troubleshooting.md": "# GitHub CLI Troubleshooting Guide\n\nCommon issues and solutions for GitHub CLI operations.\n\n## Authentication Issues\n\n### Cannot Authenticate\n\n**Symptom:** `gh auth login` fails or credentials not recognized\n\n**Diagnosis:**\n\n```bash\n# Check authentication status\ngh auth status\n\n# Check config\ncat ~/.config/gh/config.yml\n\n# Test API access\ngh api /user\n```\n\n**Solutions:**\n\n```bash\n# Re-authenticate\ngh auth logout\ngh auth login\n\n# Use specific protocol\ngh auth login --web  # Browser-based\ngh auth login --ssh  # SSH key\n\n# Troubleshoot OAuth\ngh auth login --hostname github.com\n\n# For GitHub Enterprise\ngh auth login --hostname github.enterprise.com\n```\n\n### Invalid Token\n\n**Symptom:** \"Bad credentials\" or \"Token expired\"\n\n**Diagnosis:**\n\n```bash\n# Check token status\ngh auth status\n\n# View stored credentials\ncat ~/.config/gh/config.yml | grep token\n```\n\n**Solutions:**\n\n```bash\n# Generate new token on GitHub\n# https://github.com/settings/tokens\n\n# Clear old credentials\ngh auth logout\ngh auth login\n\n# Use new token when prompted\n```\n\n### Rate Limit Exceeded\n\n**Symptom:** API rate limit errors\n\n**Diagnosis:**\n\n```bash\n# Check current rate limit\ngh api rate-limit\n\n# View limit details\ngh api rate-limit --jq '.rate'\n```\n\n**Solutions:**\n\n```bash\n# Authenticate (increases limit from 60 to 5000)\ngh auth login\n\n# Check rate limit again\ngh api rate-limit\n\n# Wait for reset (shown in rate-limit output)\n\n# Reduce request frequency\n# Use pagination with --paginate\ngh api /repos/owner/repo/issues --paginate\n```\n\n## SSH Key Issues\n\n### SSH Keys Not Recognized\n\n**Symptom:** Permission denied when pushing to remote\n\n**Diagnosis:**\n\n```bash\n# Check SSH key setup\ngh auth status\n\n# Verify SSH keys on account\ngh ssh-key list\n\n# Test SSH connection\nssh -T git@github.com\n```\n\n**Solutions:**\n\n```bash\n# Add SSH key to GitHub\ngh ssh-key add ~/.ssh/id_ed25519.pub\n\n# Check key permissions\nls -la ~/.ssh/\n\n# Generate new key if needed\nssh-keygen -t ed25519 -f ~/.ssh/id_ed25519 -N \"\"\n\n# Add to SSH agent\nssh-add ~/.ssh/id_ed25519\n\n# Reconfigure git\ngh auth logout\ngh auth login --ssh\n```\n\n### SSH Key Passphrase Issues\n\n**Symptom:** Prompted for passphrase repeatedly\n\n**Diagnosis:**\n\n```bash\n# Check if SSH agent is running\nps aux | grep ssh-agent\n\n# Check loaded keys\nssh-add -l\n```\n\n**Solutions:**\n\n```bash\n# Start SSH agent\neval \"$(ssh-agent -s)\"\n\n# Add key with passphrase\nssh-add ~/.ssh/id_ed25519\n\n# Make permanent (add to shell profile)\necho 'eval \"$(ssh-agent -s)\"' >> ~/.bashrc\n```\n\n## Repository Issues\n\n### Cannot Clone Repository\n\n**Symptom:** `gh repo clone` fails with authentication error\n\n**Diagnosis:**\n\n```bash\n# Check auth status\ngh auth status\n\n# Verify repository exists\ngh repo view owner/repo\n\n# Test git clone\ngit clone https://github.com/owner/repo.git\n```\n\n**Solutions:**\n\n```bash\n# Ensure authenticated\ngh auth login\n\n# Try explicit HTTPS\ngh repo clone --protocol https owner/repo\n\n# Check for network issues\nping github.com\n\n# For private repos, verify access\ngh repo view owner/repo --json isPrivate\n```\n\n### Cannot Create Repository\n\n**Symptom:** `gh repo create` fails\n\n**Diagnosis:**\n\n```bash\n# Check permissions\ngh auth status\n\n# Verify not at limit\ngh api /user --jq '.public_repos'\n```\n\n**Solutions:**\n\n```bash\n# Ensure sufficient permissions\ngh auth logout && gh auth login\n\n# Check for naming conflicts\ngh repo list --limit 100 | grep desired-name\n\n# Try different name\ngh repo create different-name\n\n# For org repos, verify org access\ngh auth status\n```\n\n## Issue Management\n\n### Cannot Create Issue\n\n**Symptom:** `gh issue create` fails\n\n**Diagnosis:**\n\n```bash\n# Check repository access\ngh repo view\n\n# Verify not at API limit\ngh api rate-limit\n```\n\n**Solutions:**\n\n```bash\n# Ensure in repository directory\ncd repo\ngh repo view\n\n# Or specify repository explicitly\ngh issue create --repo owner/repo --title \"Issue\"\n\n# Check for required fields\ngh issue create --title \"Title\" --body \"Description\"\n\n# For private repos, ensure access\ngh auth login\n```\n\n### Issue Title Too Long\n\n**Symptom:** \"Title is too long\" error\n\n**Solutions:**\n\n```bash\n# Keep title under 256 characters\ngh issue create --title \"Short title\" --body \"Full description in body\"\n```\n\n## Pull Request Issues\n\n### Cannot Create Pull Request\n\n**Symptom:** `gh pr create` fails\n\n**Diagnosis:**\n\n```bash\n# Check branch exists\ngit branch -a\n\n# Verify repository\ngh repo view\n\n# Check if PR already exists\ngh pr list\n```\n\n**Solutions:**\n\n```bash\n# Push branch first\ngit push origin feature-branch\n\n# Then create PR\ngh pr create \\\n  --head feature-branch \\\n  --base main \\\n  --title \"PR title\"\n\n# Ensure base branch exists\ngit branch -r | grep base-branch\n\n# For remote branch, use full name\ngh pr create --head feature --base upstream/main\n```\n\n### Cannot Merge Pull Request\n\n**Symptom:** `gh pr merge` fails with \"not permitted\" or \"conflict\"\n\n**Diagnosis:**\n\n```bash\n# Check PR status\ngh pr view 123\n\n# Check protection rules\ngh api repos/owner/repo/branches/main/protection\n\n# Check for conflicts\ngh pr diff 123 | grep \"^<<<\"\n```\n\n**Solutions:**\n\n```bash\n# Resolve conflicts locally\ngh pr checkout 123\n# Fix conflicts in editor\ngit add .\ngit commit\n\n# Check all required checks passed\ngh pr view 123 --json statusCheckRollup\n\n# Update branch if behind\ngh pr view 123 --json baseRefName -q | \\\n  xargs -I {} git merge origin/{}\n\n# Try merge again\ngh pr merge 123 --squash\n\n# For admin user, force merge\ngh pr merge 123 --admin\n```\n\n### Cannot Checkout PR\n\n**Symptom:** `gh pr checkout` fails\n\n**Diagnosis:**\n\n```bash\n# Verify PR exists\ngh pr view 123\n\n# Check branch name\ngh pr view 123 --json headRefName\n```\n\n**Solutions:**\n\n```bash\n# Ensure authenticated\ngh auth login\n\n# Try explicit PR reference\ngh pr checkout 123\n\n# Or checkout branch manually\ngh pr view 123 --json headRefName -q | xargs git checkout\n\n# For external PR, enable fetch\ngit remote add fork https://github.com/forker/repo.git\ngit fetch fork\n```\n\n## Workflow Issues\n\n### Workflow Doesn't Trigger\n\n**Symptom:** Push doesn't trigger workflow\n\n**Diagnosis:**\n\n```bash\n# Check workflow exists\ngh workflow list\n\n# Check workflow is enabled\ngh workflow list --all\n\n# View recent runs\ngh run list\n```\n\n**Solutions:**\n\n```bash\n# Ensure workflow is enabled\ngh workflow enable ci.yml\n\n# Check branch filters in workflow\ngh api repos/owner/repo/actions/workflows/ci.yml/runs\n\n# Verify branch matches filter\ngit branch --show-current\n\n# Workflow files must be in default branch\ngit push origin main\n\n# Re-push to trigger\ngit commit --allow-empty -m \"Trigger workflow\"\ngit push\n```\n\n### Workflow Runs Fail\n\n**Symptom:** Workflow fails with error\n\n**Diagnosis:**\n\n```bash\n# View run logs\ngh run view 123456 --log\n\n# Check step status\ngh run view 123456 --json jobs\n\n# Look for error details\ngh run view 123456 --log | grep -i error\n```\n\n**Solutions:**\n\n```bash\n# Rerun failed workflow\ngh run rerun 123456\n\n# Rerun only failed steps\ngh run rerun 123456 --failed\n\n# Check logs for specific error\ngh run view 123456 --log | less\n\n# Review workflow file syntax\ncat .github/workflows/ci.yml\n\n# Check environment variables\ngh variable list\ngh secret list\n\n# For missing secrets, add them\ngh secret set SECRET_NAME < secret.txt\n```\n\n### Workflow Timeout\n\n**Symptom:** Workflow exceeds 6-hour timeout\n\n**Solutions:**\n\n```bash\n# Optimize workflow\n# - Run jobs in parallel instead of serial\n# - Remove unnecessary steps\n# - Increase timeout in workflow file\ntimeout-minutes: 30\n\n# Split workflow into multiple jobs\njobs:\n  build:\n    runs-on: ubuntu-latest\n    # ... fast operations\n\n  test:\n    runs-on: ubuntu-latest\n    # ... longer operations\n```\n\n## Actions Issues\n\n### Rate Limit on Actions\n\n**Symptom:** Workflow throttled or canceled\n\n**Diagnosis:**\n\n```bash\n# Check concurrent job limits\ngh api repos/owner/repo/actions/permissions\n\n# View recent runs\ngh run list --limit 20\n```\n\n**Solutions:**\n\n```bash\n# Reduce concurrent workflows\n# In workflow file, use concurrency:\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n\n# Reduce job parallelism\n# In workflow matrix: max-parallel: 2\n\n# Schedule less frequent runs\n# In workflow: on: schedule: - cron: '0 2 * * 0'\n```\n\n### Missing Artifacts\n\n**Symptom:** Artifact not found in workflow\n\n**Diagnosis:**\n\n```bash\n# Check if artifact uploaded\ngh run view 123456 --json artifacts\n\n# Check step output\ngh run view 123456 --log | grep artifact\n```\n\n**Solutions:**\n\n```bash\n# Verify upload step\n- name: Upload artifact\n  uses: actions/upload-artifact@v3\n  with:\n    name: build\n    path: dist/\n\n# Check artifact retention\ngh api repos/owner/repo/actions/artifacts | jq '.artifacts[].expires_at'\n\n# Artifacts expire after 90 days\n```\n\n## API Issues\n\n### API Request Fails\n\n**Symptom:** `gh api` returns error\n\n**Diagnosis:**\n\n```bash\n# Test API access\ngh api /user\n\n# Check authentication\ngh auth status\n\n# View error details\ngh api /repos/owner/repo/issues -v\n```\n\n**Solutions:**\n\n```bash\n# Verify endpoint exists\ngh api /repos/owner/repo/issues\n\n# Use correct HTTP method\ngh api -X POST /repos/owner/repo/issues\n\n# Check authentication scope\ngh auth status\n\n# For private data, verify token has access\ngh auth logout && gh auth login\n```\n\n## Search Issues\n\n### No Results Found\n\n**Symptom:** `gh search` returns empty\n\n**Diagnosis:**\n\n```bash\n# Test search with broad term\ngh search repos \"python\"\n\n# Check syntax\ngh search issues \"bug\" --state open\n```\n\n**Solutions:**\n\n```bash\n# Use simpler search terms\ngh search repos \"react\"  # Instead of complex filters\n\n# GitHub search syntax is limited in CLI\n# Use full GitHub search on web for complex queries\n# https://github.com/search\n\n# Try multiple searches\ngh search issues \"bug\"\ngh search issues \"feature\"\n```\n\n## General Troubleshooting\n\n### Enable Debug Logging\n\n```bash\n# Run command with debug output\nGH_DEBUG=api gh issue list\n\n# Or use verbose flag\ngh issue create --help\n```\n\n### Check Configuration\n\n```bash\n# View current config\ngh config list\n\n# View stored configuration\ncat ~/.config/gh/config.yml\n\n# Reset configuration\nrm ~/.config/gh/config.yml\ngh auth login\n```\n\n### Clear Cache\n\n```bash\n# Clear gh cache\nrm -rf ~/.cache/gh\n\n# Or specific cache item\nrm -rf ~/.cache/gh/api-cache\n```\n\n### Get Help\n\n```bash\n# View help for command\ngh issue create --help\n\n# Search documentation\n# https://cli.github.com/manual\n\n# File issue with gh project\n# https://github.com/cli/cli/issues\n```\n\n## Common Error Messages\n\n### \"repository not found\"\n\n- Check repository name spelling\n- Verify you have access to repository\n- For private repos: `gh auth login`\n\n### \"pull request already exists\"\n\n- Check `gh pr list` for existing PR\n- Use different branch or update existing PR\n\n### \"branch not found\"\n\n- Push branch first: `git push origin branch-name`\n- Verify branch exists: `git branch -a`\n\n### \"permission denied\"\n\n- Check authentication: `gh auth status`\n- Verify permissions on repository\n- For admin operations: check if you're repo admin\n\n### \"Could not resolve host\"\n\n- Check network connection\n- Verify GitHub is accessible\n- Check firewall/proxy settings\n",
        "plugins/dev/skills/lighthouse-cli/SKILL.md": "---\nname: lighthouse-cli\ndescription: Lighthouse CLI expert for web performance auditing. Use when users need to audit performance, accessibility, SEO, best practices, or generate audit reports.\nargument-hint: [URL]\nallowed-tools: Bash(lighthouse:*), Bash(npx lighthouse:*)\n---\n\n# Lighthouse CLI Guide\n\nLighthouse is an open-source automated tool for improving web page quality. This guide provides essential workflows and quick references for auditing web performance, accessibility, SEO, and best practices.\n\n## Quick Start\n\n```bash\n# Check Lighthouse installation\nlighthouse --version\n\n# Run your first audit\nlighthouse https://example.com\n\n# Audit localhost\nlighthouse http://localhost:3000\n\n# Generate JSON report\nlighthouse https://example.com --output=json\n\n# View help\nlighthouse --help\n```\n\n## Common Workflows\n\n### Workflow 1: Complete Performance Audit\n\n```bash\n# Audit with both HTML and JSON reports\nlighthouse https://example.com --output=html --output=json\n\n# View performance scores\nlighthouse https://example.com --output=json | jq '.categories'\n\n# Check specific category score\nlighthouse https://example.com --output=json | jq '.categories.performance.score'\n```\n\n### Workflow 2: Mobile vs Desktop Testing\n\n```bash\n# Mobile performance audit\nlighthouse https://example.com --preset=mobile --output=html\n\n# Desktop performance audit\nlighthouse https://example.com --preset=desktop --output=html\n\n# Both reports\nlighthouse https://example.com --preset=mobile --output=json --output-path=./reports/mobile.json\nlighthouse https://example.com --preset=desktop --output=json --output-path=./reports/desktop.json\n```\n\n### Workflow 3: Selective Category Auditing\n\n```bash\n# Audit accessibility only\nlighthouse https://example.com --only-categories=accessibility\n\n# Audit performance and SEO only\nlighthouse https://example.com --only-categories=performance,seo\n\n# All categories except PWA\nlighthouse https://example.com --skip-categories=pwa\n```\n\n### Workflow 4: Batch Auditing Multiple URLs\n\n```bash\n# Create reports directory\nmkdir -p reports\n\n# Audit multiple URLs\nlighthouse https://example.com --output=html --output-path=./reports/example-com.html\nlighthouse https://example.org --output=html --output-path=./reports/example-org.html\n\n# Or with loop\nfor url in https://example.com https://example.org; do\n  lighthouse $url --output=json --output-path=./reports/\ndone\n```\n\n### Workflow 5: CI/CD Integration\n\n```bash\n# Generate minimal output for CI\nlighthouse https://example.com --output=json --quiet\n\n# Audit with custom timeout\nlighthouse https://example.com --output=json --timeout=60000\n\n# Monitor performance over time\nlighthouse https://example.com --output=json --output-path=./audits/$(date +%Y-%m-%d).json\n```\n\n## Decision Tree\n\n**When to use which option:**\n\n- **To audit a live website**: Use `lighthouse <url>` with `--preset=desktop` or `--preset=mobile`\n- **To run specific audit categories**: Use `--only-categories=<category>`\n- **To skip certain categories**: Use `--skip-categories=<category>`\n- **To generate reports**: Use `--output=html` or `--output=json` with `--output-path`\n- **For development/localhost**: Ensure server is running, then `lighthouse http://localhost:PORT`\n- **For CI/CD pipelines**: Use `--output=json --quiet` with timeout settings\n- **For detailed debugging**: Add `--verbose` flag\n- **For exact command syntax**: See [Commands Reference](./reference/commands-reference.md)\n- **For complex scenarios**: See [Common Patterns](./reference/common-patterns.md)\n- **For troubleshooting**: See [Troubleshooting Guide](./reference/troubleshooting.md)\n\n## Common Patterns\n\n### Auditing with Authentication\n\n```bash\n# Add authentication headers\nlighthouse https://example.com --extra-headers='{\"Authorization\":\"Bearer token123\"}'\n\n# Add custom headers\nlighthouse https://example.com --extra-headers='{\"X-API-Key\":\"your-api-key\"}'\n```\n\n### Performance Throttling\n\n```bash\n# Disable throttling (real device speed)\nlighthouse https://example.com --throttling-method=provided\n\n# Simulate network throttling\nlighthouse https://example.com --throttling-method=simulate\n\n# Custom Chrome flags\nlighthouse https://example.com --chrome-flags=\"--headless\"\n```\n\n### Custom Chrome Configuration\n\n```bash\n# Use specific Chrome executable\nlighthouse https://example.com --chrome-path=/path/to/chrome\n\n# Run in headless mode (faster)\nlighthouse https://example.com --chrome-flags=\"--headless\"\n\n# Run without sandbox (containers)\nlighthouse https://example.com --chrome-flags=\"--no-sandbox\"\n```\n\n## Troubleshooting\n\n**Common Issues:**\n\n1. **Audit fails with timeout**\n   - Solution: Increase timeout with `--timeout=60000` (milliseconds)\n   - See: [Timeouts and Performance](./reference/troubleshooting.md#timeouts-and-performance)\n\n2. **Can't audit localhost**\n   - Quick fix: Verify server is running on specified port\n   - See: [Cannot Audit Localhost](./reference/troubleshooting.md#cannot-audit-localhost)\n\n3. **Authentication failing**\n   - Quick fix: Use `--extra-headers` with proper format\n   - See: [Authentication Issues](./reference/troubleshooting.md#authentication-issues)\n\n4. **Report not generating**\n   - Quick fix: Specify `--output-path` with full path\n   - See: [Report Generation Issues](./reference/troubleshooting.md#report-generation-issues)\n\n5. **Chrome won't launch**\n   - Quick fix: Use `--chrome-path` to specify Chrome location\n   - See: [Chrome Launch Issues](./reference/troubleshooting.md#chrome-launch-issues)\n\nFor detailed troubleshooting steps, see the [Troubleshooting Guide](./reference/troubleshooting.md).\n\n## Reference Files\n\n**Load as needed for detailed information:**\n\n- **[Commands Reference](./reference/commands-reference.md)** - Complete CLI command documentation with all flags and options. Use when you need exact syntax or flag details for any Lighthouse command.\n\n- **[Common Patterns](./reference/common-patterns.md)** - Real-world patterns and workflows for different audit scenarios, batch processing, CI/CD integration, report analysis, and performance monitoring. Use for implementing specific audit workflows.\n\n- **[Troubleshooting Guide](./reference/troubleshooting.md)** - Detailed error messages, diagnosis steps, and resolution strategies for audit failures, Chrome issues, network problems, and report generation errors. Use when encountering errors or unexpected behavior.\n\n**When to use each reference:**\n\n- Use **Commands Reference** when you need exact syntax, flag combinations, or comprehensive command documentation\n- Use **Common Patterns** for batch auditing, CI/CD integration, or multi-step audit workflows\n- Use **Troubleshooting** when audits fail, Chrome won't launch, or reports don't generate\n\n## Resources\n\n- Official Docs: https://github.com/GoogleChrome/lighthouse\n- PageSpeed Insights: https://pagespeed.web.dev\n- Web.dev: https://web.dev\n- Chrome DevTools: https://developer.chrome.com/docs/devtools\n",
        "plugins/dev/skills/lighthouse-cli/reference/commands-reference.md": "# Lighthouse CLI Commands Reference\n\nComplete reference for all Lighthouse CLI commands with detailed options and flags.\n\n## Installation & Setup\n\n### Installation\n\n```bash\n# Install via npm\nnpm install -g lighthouse\n\n# Install via pnpm\npnpm i -g lighthouse\n\n# Install via bun\nbun add -g lighthouse\n\n# Check version\nlighthouse --version\n\n# Show help\nlighthouse --help\n```\n\n## Basic Auditing\n\n### `lighthouse <url>`\n\nPerform a complete audit on a URL.\n\n```bash\n# Audit a URL (default: generates HTML report)\nlighthouse https://example.com\n\n# Audit with custom output filename\nlighthouse https://example.com --output-path=./report.html\n\n# Audit localhost\nlighthouse http://localhost:3000\n\n# Audit with specific format (html, json, csv)\nlighthouse https://example.com --output=json\n\n# Audit with multiple output formats\nlighthouse https://example.com --output=html --output=json\n\n# Audit with all output formats\nlighthouse https://example.com --output=html --output=json --output=csv\n```\n\n## Output & Reports\n\n### Output Formats\n\n```bash\n# Generate HTML report (default)\nlighthouse https://example.com --output=html\n\n# Generate JSON report\nlighthouse https://example.com --output=json\n\n# Generate CSV report\nlighthouse https://example.com --output=csv\n\n# Generate multiple formats at once\nlighthouse https://example.com --output=html --output=json --output=csv\n\n# Output to stdout\nlighthouse https://example.com --output=json > report.json\n\n# Specify custom output directory\nlighthouse https://example.com --output-path=/path/to/reports/\n\n# Save report with custom name\nlighthouse https://example.com --output-path=./my-audit.html\n\n# Save report to specific file\nlighthouse https://example.com --output=json --output-path=report.json\n```\n\n## Audit Categories\n\n### Run Specific Categories\n\n```bash\n# Run all categories (default)\nlighthouse https://example.com\n\n# Audit performance only\nlighthouse https://example.com --only-categories=performance\n\n# Audit accessibility only\nlighthouse https://example.com --only-categories=accessibility\n\n# Audit SEO only\nlighthouse https://example.com --only-categories=seo\n\n# Audit best practices only\nlighthouse https://example.com --only-categories=best-practices\n\n# Audit PWA only\nlighthouse https://example.com --only-categories=pwa\n\n# Run multiple specific categories\nlighthouse https://example.com --only-categories=performance,accessibility,seo\n```\n\n### Skip Categories\n\n```bash\n# Skip specific categories\nlighthouse https://example.com --skip-categories=pwa\n\n# Skip multiple categories\nlighthouse https://example.com --skip-categories=pwa,best-practices\n```\n\n## Device & Environment\n\n### Device Presets\n\n```bash\n# Desktop preset (optimized for desktop)\nlighthouse https://example.com --preset=desktop\n\n# Mobile preset (optimized for mobile)\nlighthouse https://example.com --preset=mobile\n\n# Explicitly set form factor\nlighthouse https://example.com --emulated-form-factor=mobile\nlighthouse https://example.com --emulated-form-factor=desktop\n```\n\n### Viewport & Display\n\n```bash\n# Desktop viewport (default)\nlighthouse https://example.com --emulated-form-factor=desktop\n\n# Mobile viewport\nlighthouse https://example.com --emulated-form-factor=mobile\n\n# Custom viewport width and height\nlighthouse https://example.com --viewport-width=414 --viewport-height=896\n```\n\n## Performance Throttling\n\n### Network & CPU Throttling\n\n```bash\n# Disable network throttling (real device speed)\nlighthouse https://example.com --throttling-method=provided\n\n# Simulate network throttling (default)\nlighthouse https://example.com --throttling-method=simulate\n\n# Use DevTools throttling\nlighthouse https://example.com --throttling-method=devtools\n```\n\n## Authentication & Headers\n\n### Add Headers & Cookies\n\n```bash\n# Add authentication header\nlighthouse https://example.com --extra-headers='{\"Authorization\":\"Bearer token123\"}'\n\n# Add API key header\nlighthouse https://example.com --extra-headers='{\"X-API-Key\":\"your-api-key\"}'\n\n# Set cookies\nlighthouse https://example.com --extra-headers='{\"Cookie\":\"session=abc123\"}'\n\n# Multiple headers\nlighthouse https://example.com --extra-headers='{\"Authorization\":\"Bearer token\",\"X-Custom\":\"value\"}'\n```\n\n## Chrome Configuration\n\n### Browser Control\n\n```bash\n# Use custom Chrome executable\nlighthouse https://example.com --chrome-path=/path/to/chrome\n\n# Run in headless mode (faster)\nlighthouse https://example.com --chrome-flags=\"--headless\"\n\n# Run with visible browser\nlighthouse https://example.com --chrome-flags=\"--no-headless\"\n\n# Run without sandbox (useful in containers)\nlighthouse https://example.com --chrome-flags=\"--no-sandbox\"\n\n# Combine multiple flags\nlighthouse https://example.com --chrome-flags=\"--headless --no-sandbox\"\n```\n\n## Timing & Performance\n\n### Timeouts & Delays\n\n```bash\n# Maximum wait time for page load (milliseconds)\nlighthouse https://example.com --max-wait-for-load=45000\n\n# Custom audit timeout (milliseconds)\nlighthouse https://example.com --timeout=60000\n\n# Set longer timeout for slow sites\nlighthouse https://example.com --timeout=120000\n```\n\n## Output Control\n\n### Logging & Verbosity\n\n```bash\n# Enable verbose logging\nlighthouse https://example.com --verbose\n\n# Suppress unnecessary output\nlighthouse https://example.com --quiet\n\n# Save report assets locally\nlighthouse https://example.com --save-assets\n```\n\n## Batch & Scripting\n\n### Multiple URLs\n\n```bash\n# Audit multiple URLs in sequence\nfor url in https://example.com https://example.org; do\n  lighthouse $url --output=json --output-path=./reports/\ndone\n\n# Audit URLs from file\nwhile read url; do\n  lighthouse $url --output=json --output-path=./reports/\ndone < urls.txt\n```\n\n## Report Analysis\n\n### Extract Scores\n\n```bash\n# View all category scores\nlighthouse https://example.com --output=json | jq '.categories'\n\n# Extract performance score\nlighthouse https://example.com --output=json | jq '.categories.performance.score'\n\n# Extract all scores as list\nlighthouse https://example.com --output=json | jq '.categories | map({name: .id, score: .score})'\n\n# Get audit-level details\nlighthouse https://example.com --output=json | jq '.audits'\n```\n\n## Environment Variables\n\n### Configuration via Environment\n\n```bash\n# Set Chrome executable path\nexport CHROME_PATH=/path/to/chrome\nlighthouse https://example.com\n\n# Set custom user data directory\nexport CHROME_USER_DATA_DIR=/tmp/chrome-data\nlighthouse https://example.com\n```\n\n## Global Options\n\nAll Lighthouse commands support these global flags:\n\n- `--version` â€” Show version\n- `--help` â€” Show help\n- `--verbose` â€” Enable verbose logging\n- `--quiet` â€” Suppress output\n- `--output` â€” Output format (html, json, csv)\n- `--output-path` â€” Output file path or directory\n- `--save-assets` â€” Save assets locally\n- `--emulated-form-factor` â€” Device type (mobile, desktop)\n- `--preset` â€” Configuration preset (mobile, desktop)\n- `--only-categories` â€” Specific categories to audit\n- `--skip-categories` â€” Categories to skip\n- `--timeout` â€” Maximum audit duration (milliseconds)\n- `--max-wait-for-load` â€” Maximum page load wait time\n- `--chrome-path` â€” Custom Chrome executable path\n- `--chrome-flags` â€” Custom Chrome launch flags\n- `--extra-headers` â€” Additional HTTP headers (JSON)\n- `--throttling-method` â€” Method (simulate, devtools, provided)\n- `--viewport-width` â€” Custom viewport width\n- `--viewport-height` â€” Custom viewport height\n",
        "plugins/dev/skills/lighthouse-cli/reference/common-patterns.md": "# Lighthouse Common Patterns\n\nReal-world patterns and workflows for common Lighthouse use cases.\n\n## Development Workflow\n\n### Local Application Auditing\n\n```bash\n# Start local dev server\nnpm run dev  # or your dev command\n\n# In another terminal, audit the running application\nlighthouse http://localhost:3000 --preset=desktop --output=html\n\n# Watch the report\nopen ./lhreport-*.html  # macOS\n# or use your browser to open the HTML file\n```\n\n### Continuous Development Monitoring\n\n```bash\n# Audit after each build\nnpm run build && lighthouse http://localhost:3000 --output=json\n\n# Save to timestamped file\nlighthouse http://localhost:3000 --output=json --output-path=./audits/$(date +%Y-%m-%d-%H%M%S).json\n\n# Track performance over time\ncat audits/*.json | jq '.categories.performance.score'\n```\n\n## Mobile vs Desktop Testing\n\n### Comprehensive Device Testing\n\n```bash\n# Create reports directory\nmkdir -p reports/mobile reports/desktop\n\n# Audit mobile performance\nlighthouse https://example.com --preset=mobile --output=html --output-path=./reports/mobile/index.html\n\n# Audit desktop performance\nlighthouse https://example.com --preset=desktop --output=html --output-path=./reports/desktop/index.html\n\n# Generate JSON for comparison\nlighthouse https://example.com --preset=mobile --output=json --output-path=./reports/mobile.json\nlighthouse https://example.com --preset=desktop --output=json --output-path=./reports/desktop.json\n```\n\n### Device-Specific Audits\n\n```bash\n# Mobile with custom viewport\nlighthouse https://example.com --emulated-form-factor=mobile --viewport-width=375 --viewport-height=667\n\n# Tablet testing (iPad dimensions)\nlighthouse https://example.com --viewport-width=768 --viewport-height=1024\n\n# Desktop with custom dimensions\nlighthouse https://example.com --viewport-width=1440 --viewport-height=900\n```\n\n## Selective Auditing\n\n### Category-Focused Audits\n\n```bash\n# Performance audit only\nlighthouse https://example.com --only-categories=performance --output=html\n\n# Accessibility audit only\nlighthouse https://example.com --only-categories=accessibility --output=html\n\n# SEO audit only\nlighthouse https://example.com --only-categories=seo --output=html\n\n# Multiple categories\nlighthouse https://example.com --only-categories=performance,accessibility --output=html\n\n# All except PWA\nlighthouse https://example.com --skip-categories=pwa --output=html\n```\n\n## Batch Processing\n\n### Audit Multiple Sites\n\n```bash\n# Simple batch audit\nmkdir -p reports\nfor url in https://example.com https://example.org https://example.net; do\n  lighthouse $url --output=html --output-path=./reports/$(echo $url | sed 's|https://||g').html\ndone\n```\n\n### Batch Audit from File\n\n```bash\n# Create urls.txt with one URL per line\ncat > urls.txt << EOF\nhttps://example.com\nhttps://example.org\nhttps://example.net\nEOF\n\n# Audit all URLs\nmkdir -p reports\nwhile read url; do\n  echo \"Auditing: $url\"\n  lighthouse $url --output=json --output-path=./reports/$(echo $url | sed 's|[^a-zA-Z0-9]|_|g').json\ndone < urls.txt\n```\n\n### Parallel Batch Auditing (GNU Parallel)\n\n```bash\n# Install GNU Parallel (if not present)\n# brew install parallel (macOS) or apt-get install parallel (Linux)\n\n# Audit URLs in parallel\nmkdir -p reports\ncat urls.txt | parallel lighthouse {} --output=json --output-path=./reports/{/.}.json\n\n# Limit parallel jobs\ncat urls.txt | parallel -j 3 lighthouse {} --output=json --output-path=./reports/{/.}.json\n```\n\n## CI/CD Integration\n\n### GitHub Actions Pattern\n\n```yaml\n# .github/workflows/lighthouse.yml\nname: Lighthouse Audit\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n\njobs:\n  audit:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n      - run: npm install -g lighthouse\n      - run: npm run build\n      - run: |\n          lighthouse http://localhost:3000 \\\n            --output=json \\\n            --output=html \\\n            --output-path=./reports/\n```\n\n### Local CI-Style Audit\n\n```bash\n# Build and audit\nnpm run build\nnpm run start &\nSERVER_PID=$!\n\n# Wait for server\nsleep 3\n\n# Run audit with minimal output\nlighthouse http://localhost:3000 --output=json --quiet\n\n# Cleanup\nkill $SERVER_PID\n```\n\n## Report Analysis\n\n### Extract and Compare Scores\n\n```bash\n# View all scores\nlighthouse https://example.com --output=json | jq '.categories[] | {id: .id, score: (.score * 100)}'\n\n# Extract specific score\nlighthouse https://example.com --output=json | jq '.categories.performance.score'\n\n# Compare before/after\necho \"Before:\"\njq '.categories.performance.score' before.json\necho \"After:\"\njq '.categories.performance.score' after.json\n```\n\n### Performance Tracking\n\n```bash\n# Create performance history\nmkdir -p audits\nfor i in {1..7}; do\n  DATE=$(date -d \"-$i days\" +%Y-%m-%d)\n  echo \"$DATE: $(jq '.categories.performance.score' audits/$DATE.json 2>/dev/null || echo 'N/A')\"\ndone | sort\n\n# Graph over time (requires external tools)\njq '.categories.performance.score' audits/*.json | gnuplot\n```\n\n## Authentication & Protected Pages\n\n### Audit Protected Content\n\n```bash\n# Add bearer token\nlighthouse https://api.example.com/dashboard \\\n  --extra-headers='{\"Authorization\":\"Bearer your-token-here\"}'\n\n# Add custom headers\nlighthouse https://example.com \\\n  --extra-headers='{\"X-API-Key\":\"key123\",\"X-Custom-Header\":\"value\"}'\n\n# Add cookies\nlighthouse https://example.com \\\n  --extra-headers='{\"Cookie\":\"session_id=abc123\"}'\n```\n\n### Multi-Header Authentication\n\n```bash\n# Complex header setup (JSON format)\nlighthouse https://example.com \\\n  --extra-headers='{\n    \"Authorization\": \"Bearer token123\",\n    \"X-API-Key\": \"api-key-here\",\n    \"X-Request-ID\": \"req-12345\",\n    \"Accept\": \"application/json\"\n  }'\n```\n\n## Performance Throttling\n\n### Simulate Various Network Conditions\n\n```bash\n# Real network (no throttling)\nlighthouse https://example.com --throttling-method=provided\n\n# Simulated slow network\nlighthouse https://example.com --throttling-method=simulate\n\n# DevTools throttling\nlighthouse https://example.com --throttling-method=devtools\n```\n\n## Chrome Configuration\n\n### Custom Chrome Settings\n\n```bash\n# Headless mode (faster, no visual)\nlighthouse https://example.com --chrome-flags=\"--headless\" --output=json\n\n# Disable sandbox (for containers/CI)\nlighthouse https://example.com --chrome-flags=\"--no-sandbox\"\n\n# Combine flags\nlighthouse https://example.com \\\n  --chrome-flags=\"--headless --no-sandbox --disable-gpu\"\n\n# Specific Chrome location\nlighthouse https://example.com --chrome-path=/usr/bin/google-chrome\n```\n\n## Advanced Report Generation\n\n### Multi-Format Reports\n\n```bash\n# Generate all formats\nmkdir -p reports\nlighthouse https://example.com \\\n  --output=html \\\n  --output=json \\\n  --output=csv \\\n  --output-path=./reports/audit\n\n# HTML for viewing\nopen ./reports/audit.html\n\n# JSON for analysis\njq . ./reports/audit.json\n\n# CSV for spreadsheets\ncat ./reports/audit.csv\n```\n\n### Save Report Assets\n\n```bash\n# Generate report with embedded assets\nlighthouse https://example.com \\\n  --output=html \\\n  --save-assets \\\n  --output-path=./my-audit.html\n\n# Report folder will contain assets\n# my-audit.html\n# my-audit-assets/\n#   â”œâ”€â”€ resources.json\n#   â””â”€â”€ ...\n```\n\n## Production Deployment Auditing\n\n### Pre-Production Checks\n\n```bash\n# Complete multi-category audit\nlighthouse https://staging.example.com \\\n  --preset=desktop \\\n  --output=html \\\n  --output=json \\\n  --timeout=60000 \\\n  --output-path=./deployment-audit\n\n# Check all critical metrics\nlighthouse https://staging.example.com --output=json | \\\n  jq '{\n    performance: .categories.performance.score,\n    accessibility: .categories.accessibility.score,\n    seo: .categories.seo.score,\n    \"best-practices\": .categories[\"best-practices\"].score\n  }'\n```\n\n## Monitoring & Alerting\n\n### Performance Regression Detection\n\n```bash\n# Audit and save with timestamp\nREPORT=\"audits/$(date +%s).json\"\nlighthouse https://example.com --output=json --output-path=$REPORT\n\n# Compare with baseline\nBASELINE_SCORE=$(jq '.categories.performance.score' baseline.json)\nCURRENT_SCORE=$(jq '.categories.performance.score' $REPORT)\n\nif (( $(echo \"$CURRENT_SCORE < $BASELINE_SCORE - 0.1\" | bc -l) )); then\n  echo \"Performance regression detected!\"\n  echo \"Baseline: $BASELINE_SCORE\"\n  echo \"Current: $CURRENT_SCORE\"\nfi\n```\n\n## Troubleshooting Audits\n\n### Debug Audit Failures\n\n```bash\n# Verbose output for debugging\nlighthouse https://example.com --verbose --output=json\n\n# Increase timeout\nlighthouse https://example.com --timeout=120000 --output=json\n\n# Check Chrome can launch\nlighthouse --chrome-flags=\"--version\"\n\n# Test server connectivity\ncurl -I https://example.com\n```\n\n### Local Development Testing\n\n```bash\n# Ensure server is running\nps aux | grep \"npm run dev\"\n\n# Test server responds\ncurl http://localhost:3000\n\n# Audit localhost\nlighthouse http://localhost:3000 --output=html\n\n# View generated report\nopen ./lhreport-*.html\n```\n",
        "plugins/dev/skills/lighthouse-cli/reference/troubleshooting.md": "# Lighthouse Troubleshooting Guide\n\nCommon issues and solutions for Lighthouse audits, Chrome configuration, and report generation.\n\n## Chrome Issues\n\n### Chrome Won't Launch\n\n**Symptom:** \"Chrome could not be launched\" or Chrome timeout error\n\n**Diagnosis:**\n\n```bash\n# Check if Chrome is installed\nwhich google-chrome      # Linux\nwhich chromium           # Linux alternative\nwhich \"Google Chrome\"    # macOS\nwhere chrome.exe         # Windows\n\n# Verify Chrome executable\n/Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome --version  # macOS\ngoogle-chrome --version  # Linux\n```\n\n**Solutions:**\n\n```bash\n# Specify Chrome path explicitly\nlighthouse https://example.com --chrome-path=/path/to/chrome\n\n# macOS example\nlighthouse https://example.com --chrome-path=\"/Applications/Google Chrome.app/Contents/MacOS/Google Chrome\"\n\n# Linux example\nlighthouse https://example.com --chrome-path=/usr/bin/google-chrome\n\n# Install Chrome if missing\n# macOS: brew install google-chrome\n# Linux: apt-get install google-chrome-stable\n# Windows: Download from google.com/chrome\n```\n\n### Chrome in Container/CI\n\n**Symptom:** \"Chrome could not be launched\" in Docker or CI environment\n\n**Solutions:**\n\n```bash\n# Add no-sandbox flag (needed in containers)\nlighthouse https://example.com --chrome-flags=\"--no-sandbox\"\n\n# Combine with headless\nlighthouse https://example.com --chrome-flags=\"--headless --no-sandbox\"\n\n# Dockerfile example\nFROM node:18\nRUN apt-get update && apt-get install -y chromium\nENV CHROME_PATH=/usr/bin/chromium\nRUN npm install -g lighthouse\n```\n\n### Chrome Process Hangs\n\n**Symptom:** Audit hangs and eventually times out\n\n**Diagnosis:**\n\n```bash\n# Check running Chrome processes\nps aux | grep chrome\n\n# Check system resources\ntop  # or htop\n\n# Test basic Chrome launch\ngoogle-chrome --headless --version\n```\n\n**Solutions:**\n\n```bash\n# Kill hung Chrome processes\npkill -f chrome\npkill -f chromium\n\n# Increase timeout\nlighthouse https://example.com --timeout=120000\n\n# Disable GPU (can help with resource issues)\nlighthouse https://example.com --chrome-flags=\"--headless --disable-gpu\"\n\n# Run with memory limit\nlighthouse https://example.com --chrome-flags=\"--headless --memory-pressure-off\"\n```\n\n## Audit Failures\n\n### Cannot Audit Localhost\n\n**Symptom:** \"Error: Listener closed\" or \"net::ERR_CONNECTION_REFUSED\"\n\n**Diagnosis:**\n\n```bash\n# Check if server is running\nps aux | grep \"npm\\|yarn\\|bun\"\n\n# Test server is responding\ncurl http://localhost:3000\n\n# Check port is correct\nlsof -i :3000  # macOS/Linux\nnetstat -ano | findstr :3000  # Windows\n```\n\n**Solutions:**\n\n```bash\n# Start your dev server first\nnpm run dev  # or your dev command\n\n# Wait for server to be ready before auditing\nsleep 3 && lighthouse http://localhost:3000\n\n# Or use a script\nnpm run dev &\nsleep 3\nlighthouse http://localhost:3000\nkill $!\n```\n\n### Audit Timeout\n\n**Symptom:** \"Audit timing out\" or \"Error: Timeout\"\n\n**Diagnosis:**\n\n```bash\n# Check if site is loading slowly\ntime curl https://example.com\n\n# Test site responsiveness\ncurl -I https://example.com\n\n# Monitor network\nping example.com\n```\n\n**Solutions:**\n\n```bash\n# Increase timeout (in milliseconds)\nlighthouse https://example.com --timeout=60000   # 60 seconds\n\n# For slow sites\nlighthouse https://example.com --timeout=120000  # 2 minutes\n\n# Increase page load wait time\nlighthouse https://example.com --max-wait-for-load=60000\n\n# Disable throttling (faster audit)\nlighthouse https://example.com --throttling-method=provided\n```\n\n### Site Not Responding\n\n**Symptom:** \"Error: Unable to load the page\" or connection timeout\n\n**Diagnosis:**\n\n```bash\n# Check DNS resolution\nnslookup example.com\ndig example.com\n\n# Test connectivity\nping example.com\n\n# Check if site is online\ncurl -v https://example.com\n\n# Check for CloudFlare/WAF blocking\ncurl -H \"User-Agent: Mozilla/5.0\" https://example.com\n```\n\n**Solutions:**\n\n```bash\n# Wait and retry\nsleep 5 && lighthouse https://example.com\n\n# Check site status\n# Visit status page or uptime monitor\n\n# Verify correct URL\nlighthouse https://example.com  # not http://\n\n# For authenticated sites, add headers\nlighthouse https://example.com --extra-headers='{\"Authorization\":\"Bearer token\"}'\n```\n\n## Authentication Issues\n\n### Headers Not Being Sent\n\n**Symptom:** 401 Unauthorized or 403 Forbidden despite headers\n\n**Diagnosis:**\n\n```bash\n# Test headers with curl\ncurl -H \"Authorization: Bearer token123\" https://example.com\n\n# Check header format\n# Headers should be valid JSON\necho '{\"Authorization\":\"Bearer token123\"}' | jq .\n```\n\n**Solutions:**\n\n```bash\n# Correct JSON format (double quotes required)\nlighthouse https://example.com \\\n  --extra-headers='{\"Authorization\":\"Bearer your-token-here\"}'\n\n# Escape quotes properly if needed\nlighthouse https://example.com \\\n  --extra-headers='{\"Authorization\":\"Bearer token with spaces\"}'\n\n# Multiple headers\nlighthouse https://example.com \\\n  --extra-headers='{\"Authorization\":\"Bearer token\",\"X-API-Key\":\"key123\"}'\n\n# For cookies\nlighthouse https://example.com \\\n  --extra-headers='{\"Cookie\":\"sessionid=abc123; path=/\"}'\n```\n\n### Token Expiration\n\n**Symptom:** Audit works initially but later fails with 401\n\n**Solutions:**\n\n```bash\n# Refresh token before audit\nTOKEN=$(curl -s -X POST https://api.example.com/auth -d '{}' | jq -r .token)\nlighthouse https://example.com --extra-headers=\"{\\\"Authorization\\\":\\\"Bearer $TOKEN\\\"}\"\n\n# Or manually refresh and run audit\n```\n\n## Report Generation Issues\n\n### Report Not Generating\n\n**Symptom:** Command runs but no report file created\n\n**Diagnosis:**\n\n```bash\n# Check for errors in output\nlighthouse https://example.com  # Watch full output\n\n# Verify write permissions\nls -la ./\ntouch test.txt  # Can we write?\n```\n\n**Solutions:**\n\n```bash\n# Specify full path\nlighthouse https://example.com --output-path=/full/path/to/report.html\n\n# Ensure directory exists\nmkdir -p ./reports\nlighthouse https://example.com --output-path=./reports/report.html\n\n# Check file permissions\nchmod 755 ./reports\n\n# Use absolute path\nlighthouse https://example.com --output-path=$PWD/report.html\n\n# Specify format explicitly\nlighthouse https://example.com --output=html --output-path=./report.html\n```\n\n### Report File Permissions\n\n**Symptom:** \"Permission denied\" when trying to open report\n\n**Solutions:**\n\n```bash\n# Fix file permissions\nchmod 644 report.html\n\n# Fix directory permissions\nchmod 755 ./reports\n\n# Run with proper user\nsudo lighthouse https://example.com  # Usually not needed\n\n# Check owner\nls -la report.html\nchown $USER report.html\n```\n\n### Large Report File Size\n\n**Symptom:** HTML report is very large or crashes browser\n\n**Solutions:**\n\n```bash\n# Generate JSON instead of HTML\nlighthouse https://example.com --output=json\n\n# Use separate formats\nlighthouse https://example.com --output=html --output=json\n\n# JSON takes much less space and is easier to analyze\njq . report.json  # View JSON\n\n# Generate CSV for data analysis\nlighthouse https://example.com --output=csv\n```\n\n## Network & Connectivity Issues\n\n### DNS Resolution Fails\n\n**Symptom:** \"Error: getaddrinfo ENOTFOUND example.com\"\n\n**Diagnosis:**\n\n```bash\n# Test DNS\nnslookup example.com\ndig example.com\nhost example.com\n\n# Test direct IP if available\nping 93.184.216.34\n```\n\n**Solutions:**\n\n```bash\n# Try again (temporary DNS issue)\nsleep 5 && lighthouse https://example.com\n\n# Check internet connection\nping 8.8.8.8\n\n# Check DNS configuration\ncat /etc/resolv.conf  # Linux\nnetworksetup -getdnsservers en0  # macOS\n\n# Use public DNS\n# Add to /etc/resolv.conf or OS network settings:\n# nameserver 8.8.8.8\n# nameserver 8.8.4.4\n```\n\n### Certificate Errors\n\n**Symptom:** \"Error: certificate verify failed\" or \"untrusted certificate\"\n\n**Diagnosis:**\n\n```bash\n# Check certificate\nopenssl s_client -connect example.com:443\n\n# Check certificate expiration\nopenssl x509 -noout -dates -in certificate.pem\n```\n\n**Solutions:**\n\n```bash\n# For self-signed certificates in development\nlighthouse https://localhost:3000 --chrome-flags=\"--allow-insecure-localhost\"\n\n# Update certificate bundles\n# macOS: /Applications/Python\\ 3.x/Install\\ Certificates.command\n# Linux: apt-get install ca-certificates\n\n# Check system time (certificate validation uses current date)\ndate\n```\n\n### Network Rate Limiting\n\n**Symptom:** Repeated \"Error: net::ERR_TOO_MANY_REDIRECTS\" or slowness\n\n**Solutions:**\n\n```bash\n# Add delay between audits\nfor url in $(cat urls.txt); do\n  lighthouse $url --output=json\n  sleep 10  # Wait 10 seconds between audits\ndone\n\n# Use parallel with rate limit\ncat urls.txt | parallel -j 1 -d '\\n' lighthouse {}\n\n# Distribute audits over time\n```\n\n## Performance & Resource Issues\n\n### Audit Uses Too Much Memory\n\n**Symptom:** Audit crashes or system runs out of memory\n\n**Solutions:**\n\n```bash\n# Disable JavaScript execution if not needed\n# (Lighthouse option if available)\n\n# Disable network throttling (less memory usage)\nlighthouse https://example.com --throttling-method=provided\n\n# Run on a machine with more resources\n\n# Close other applications\nkillall chrome  # Close any running Chrome instances\n```\n\n### Audit Takes Too Long\n\n**Symptom:** Audit takes 5+ minutes\n\n**Diagnosis:**\n\n```bash\n# Check site performance\ncurl -I https://example.com\n\n# Check network conditions\nping -c 10 example.com\n```\n\n**Solutions:**\n\n```bash\n# Reduce audit scope\nlighthouse https://example.com --only-categories=performance\n\n# Disable throttling (faster)\nlighthouse https://example.com --throttling-method=provided\n\n# Reduce max load wait time\nlighthouse https://example.com --max-wait-for-load=30000\n\n# Headless mode (sometimes faster)\nlighthouse https://example.com --chrome-flags=\"--headless\"\n```\n\n## Scoring & Results Issues\n\n### Scores Seem Inconsistent\n\n**Symptom:** Same URL gets different scores on each audit\n\n**Diagnosis:**\n\n```bash\n# Check audit conditions\n# Lighthouse scores vary based on:\n# - Network throttling\n# - CPU throttling\n# - System load\n# - Server performance\n# - Cache state\n```\n\n**Solutions:**\n\n```bash\n# Use same throttling settings\nlighthouse https://example.com --throttling-method=provided\n\n# Run multiple times and average\nfor i in {1..3}; do\n  lighthouse https://example.com --output=json --output-path=audit-$i.json\ndone\n\n# Average scores\njq '[.[].categories.performance.score] | add/length' audit-*.json\n\n# Clear browser cache between runs\nlighthouse https://example.com --chrome-flags=\"--disk-cache-dir=/tmp/none\"\n```\n\n## Debugging\n\n### Enable Verbose Logging\n\n```bash\n# Get detailed output\nlighthouse https://example.com --verbose --output=json\n\n# See all steps and timing\nlighthouse https://example.com --verbose\n```\n\n### Inspect Audit Details\n\n```bash\n# View detailed audit results\nlighthouse https://example.com --output=json | jq '.audits'\n\n# Check specific audit\nlighthouse https://example.com --output=json | jq '.audits[\"first-contentful-paint\"]'\n\n# View all opportunities\nlighthouse https://example.com --output=json | jq '.audits | map(select(.scoreDisplayMode==\"numeric\"))'\n```\n\n### Check Lighthouse Version\n\n```bash\n# Verify version\nlighthouse --version\n\n# Upgrade to latest\nnpm install -g lighthouse@latest\n\n# Check for breaking changes in release notes\n# https://github.com/GoogleChrome/lighthouse/releases\n```\n",
        "plugins/dev/skills/neon-cli/SKILL.md": "---\nname: neon-cli\ndescription: Neon CLI expert for serverless PostgreSQL. Use when users need to manage Neon projects, branches, databases, roles, or connection strings.\nallowed-tools: Bash(neon:*), Bash(psql:*)\n---\n\n# Neon CLI Guide\n\nNeon is a serverless PostgreSQL platform providing instant database provisioning, branching, and scaling. This guide provides essential workflows and quick references for common Neon operations.\n\n## Quick Start\n\n```bash\n# Check Neon CLI installation\nneon --version\n\n# Authenticate with Neon\nneon auth\n\n# View current user\nneon me\n\n# List all projects\nneon projects list\n\n# Create new project\nneon projects create --name myapp --region aws-us-east-1\n```\n\n## Common Workflows\n\n### Workflow 1: Create Project with Database\n\n```bash\n# Authenticate first\nneon auth\n\n# Create project\nneon projects create --name myapp --region aws-us-east-1\n\n# Get project ID (from output or list)\nneon projects list\n\n# Create database\nneon databases create --branch-id <branch_id> --name app_db\n\n# Create application role\nneon roles create --branch-id <branch_id> --name app_user --password secret123\n\n# Get connection string\nneon connection-string\n```\n\n### Workflow 2: Feature Branch Development\n\n```bash\n# Create feature branch from main\nneon branches create --project-id <project_id> --name feature/new-api --parent-id <main_branch_id>\n\n# Add compute to branch\nneon branches add-compute <feature_branch_id> --size small\n\n# Create database for feature\nneon databases create --branch-id <feature_branch_id> --name app_db\n\n# Get connection string for development\nneon connection-string feature/new-api\n\n# After testing, delete feature branch\nneon branches delete <feature_branch_id>\n```\n\n### Workflow 3: Multi-Environment Setup\n\n```bash\n# Create production branch with medium compute\nneon branches create --project-id <project_id> --name production\nneon branches add-compute <prod_branch_id> --size medium\n\n# Create staging branch with small compute\nneon branches create --project-id <project_id> --name staging --parent-id <prod_branch_id>\nneon branches add-compute <staging_branch_id> --size small\n\n# Create development branch\nneon branches create --project-id <project_id> --name development --parent-id <prod_branch_id>\n\n# Setup databases per environment\nneon databases create --branch-id <prod_branch_id> --name app_db\nneon databases create --branch-id <staging_branch_id> --name app_db\nneon databases create --branch-id <dev_branch_id> --name app_db\n```\n\n### Workflow 4: User and Role Management\n\n```bash\n# List existing roles\nneon roles list --branch-id <branch_id>\n\n# Create application user\nneon roles create --branch-id <branch_id> --name app_user --password app_password\n\n# Create read-only user\nneon roles create --branch-id <branch_id> --name readonly_user --password readonly_password\n\n# Create migration user (for deployment scripts)\nneon roles create --branch-id <branch_id> --name migration_user --password migration_password\n```\n\n### Workflow 5: Security Configuration\n\n```bash\n# View IP allowlist\nneon ip-allow list --project-id <project_id>\n\n# Add specific IP\nneon ip-allow add --project-id <project_id> --ip 203.0.113.42/32\n\n# Add IP range for organization\nneon ip-allow add --project-id <project_id> --ip 192.168.1.0/24\n\n# Create VPC endpoint for private connection\nneon vpc endpoint create --project-id <project_id> --region us-east-1\n```\n\n## Decision Tree\n\n**When to use which command:**\n\n- **To create a project**: Use `neon projects create` with name and region\n- **To create a database**: Use `neon databases create` with branch ID\n- **To add a user role**: Use `neon roles create` with branch ID\n- **To branch from main**: Use `neon branches create` with parent ID\n- **To get connection details**: Use `neon connection-string`\n- **To manage security**: Use `neon ip-allow` for IP whitelisting\n- **To isolate features**: Use feature branches with `neon branches create`\n- **To scale compute**: Use `neon branches add-compute` with size option\n- **For detailed command syntax**: See [Commands Reference](./reference/commands-reference.md)\n- **For complex scenarios**: See [Common Patterns](./reference/common-patterns.md)\n- **For troubleshooting**: See [Troubleshooting Guide](./reference/troubleshooting.md)\n\n## Common Patterns\n\n### Project Initialization\n\n```bash\n# Authenticate\nneon auth\n\n# Create project\nneon projects create --name myapp --region aws-us-east-1\n\n# Setup main branch database\nneon databases create --branch-id <main_branch_id> --name app_db\n\n# Create application user\nneon roles create --branch-id <main_branch_id> --name app_user --password secret\n\n# Get connection string\nneon connection-string\n```\n\n### Branching Strategy\n\n```bash\n# Create isolated development branch\nneon branches create --project-id <project_id> --name dev\n\n# Create feature branch from development\nneon branches create --project-id <project_id> --name feature/auth --parent-id <dev_branch_id>\n\n# Add small compute for feature development\nneon branches add-compute <feature_branch_id> --size small\n```\n\n### Environment-Specific Setup\n\n```bash\n# Export connection strings for each environment\nexport PROD_DATABASE_URL=$(neon connection-string production)\nexport STAGING_DATABASE_URL=$(neon connection-string staging)\nexport DEV_DATABASE_URL=$(neon connection-string dev)\n\n# Use in deployment\ndocker run -e DATABASE_URL=$PROD_DATABASE_URL myapp:latest\n```\n\n### Automated Cleanup\n\n```bash\n# Delete feature branches after development\nneon branches list --project-id <project_id> -o json | \\\n  jq -r '.[] | select(.name | startswith(\"feature/\")) | .id' | \\\n  xargs -I {} neon branches delete {}\n```\n\n## Troubleshooting\n\n**Common Issues:**\n\n1. **Cannot authenticate**\n   - Solution: Run `neon auth` to complete OAuth flow\n   - See: [Authentication Issues](./reference/troubleshooting.md#authentication-issues)\n\n2. **Branch has no compute**\n   - Quick fix: Run `neon branches add-compute <branch_id> --size small`\n   - See: [Missing Compute on Branch](./reference/troubleshooting.md#missing-compute-on-branch)\n\n3. **Connection timeout**\n   - Quick fix: Add IP to allowlist `neon ip-allow add --project-id <project_id> --ip <your_ip>/32`\n   - See: [Connection Timeout](./reference/troubleshooting.md#connection-timeout)\n\n4. **Database not found**\n   - Quick fix: Create database `neon databases create --branch-id <branch_id> --name app_db`\n   - See: [Database Not Found](./reference/troubleshooting.md#database-not-found)\n\n5. **Project deletion fails**\n   - Quick fix: Delete all branches except main first, then delete project\n   - See: [Cannot Delete Project](./reference/troubleshooting.md#cannot-delete-project)\n\nFor detailed troubleshooting steps, see the [Troubleshooting Guide](./reference/troubleshooting.md).\n\n## Reference Files\n\n**Load as needed for detailed information:**\n\n- **[Commands Reference](./reference/commands-reference.md)** - Complete CLI command documentation with all flags and options. Use when you need exact syntax or flag details for any Neon command.\n\n- **[Common Patterns](./reference/common-patterns.md)** - Real-world patterns and workflows for project setup, multi-environment configuration, feature branching, role management, IP allowlisting, and scripting examples. Use for implementing specific workflows or automating operations.\n\n- **[Troubleshooting Guide](./reference/troubleshooting.md)** - Detailed error messages, diagnosis steps, and resolution strategies for authentication, projects, branches, databases, roles, connections, and security issues. Use when encountering errors or unexpected behavior.\n\n**When to use each reference:**\n\n- Use **Commands Reference** when you need exact syntax, flag combinations, or comprehensive command documentation\n- Use **Common Patterns** for implementing multi-environment setups, feature branch workflows, or scripting automation\n- Use **Troubleshooting** when projects won't create, branches lack compute, connections time out, or you encounter permission issues\n\n## Resources\n\n- Official Docs: https://neon.tech/docs\n- Dashboard: https://console.neon.tech\n- GitHub: https://github.com/neondatabase\n- Community: https://neon.tech/community\n\n",
        "plugins/dev/skills/neon-cli/reference/commands-reference.md": "# Neon CLI Commands Reference\n\nComplete reference for all neonctl commands with detailed options and flags.\n\n## Authentication & Profile\n\n### `neon auth`\n\nOpens OAuth flow in browser for authentication.\n\n```bash\n# Authenticate with Neon\nneon auth\n\n# Authenticate with Neon (alias)\nneon login\n\n# Show current user\nneon me\n\n# Use explicit API key\nneon <command> --api-key $NEON_API_KEY\n```\n\n## Organizations\n\n### `neon orgs list`\n\nLists all organizations.\n\n```bash\n# List organizations\nneon orgs list\n\n# Alias\nneon org list\n```\n\n### `neon orgs create`\n\nCreates a new organization.\n\n```bash\n# Create organization\nneon orgs create \"Organization Name\"\n```\n\n### `neon orgs delete`\n\nDeletes an organization.\n\n```bash\n# Delete organization\nneon orgs delete <org_id>\n```\n\n## Projects\n\n### `neon projects list`\n\nLists all projects.\n\n```bash\n# List all projects\nneon projects list\n\n# Alias\nneon project list\n```\n\n### `neon projects create`\n\nCreates a new project.\n\n```bash\n# Create project with name and region\nneon projects create --name myproject --region aws-us-east-1\n\n# Available regions: aws-us-east-1, aws-us-west-2, aws-eu-west-1, etc.\n```\n\n### `neon projects get`\n\nShows project details.\n\n```bash\n# Get project details\nneon projects get <project_id>\n```\n\n### `neon projects update`\n\nUpdates project settings.\n\n```bash\n# Update project name\nneon projects update <project_id> --name newname\n```\n\n### `neon projects delete`\n\nDeletes a project.\n\n```bash\n# Delete project\nneon projects delete <project_id>\n```\n\n## Branches\n\n### `neon branches list`\n\nLists branches for a project.\n\n```bash\n# List project branches\nneon branches list --project-id <project_id>\n```\n\n### `neon branches create`\n\nCreates a new branch (logical fork).\n\n```bash\n# Create branch\nneon branches create --project-id <project_id> --name feature_branch\n\n# Create branch from parent\nneon branches create --project-id <project_id> --name dev --parent-id <parent_branch_id>\n```\n\n### `neon branches set-default`\n\nSets the default branch.\n\n```bash\n# Set default branch\nneon branches set-default <branch_id>\n```\n\n### `neon branches add-compute`\n\nAdds compute to a branch.\n\n```bash\n# Add compute resource\nneon branches add-compute <branch_id> --size small\n\n# Sizes: small, medium, large\n```\n\n### `neon branches rename`\n\nRenames a branch.\n\n```bash\n# Rename branch\nneon branches rename <branch_id> --name better_name\n```\n\n### `neon branches restore`\n\nRestores a branch to a previous state.\n\n```bash\n# Restore branch\nneon branches restore <branch_id>\n```\n\n### `neon branches reset`\n\nResets a branch.\n\n```bash\n# Reset branch\nneon branches reset <branch_id>\n```\n\n### `neon branches delete`\n\nDeletes a branch.\n\n```bash\n# Delete branch\nneon branches delete <branch_id>\n```\n\n## Databases\n\n### `neon databases list`\n\nLists databases in a branch.\n\n```bash\n# List databases\nneon databases list --branch-id <branch_id>\n```\n\n### `neon databases create`\n\nCreates a new database.\n\n```bash\n# Create database\nneon databases create --branch-id <branch_id> --name app_db\n```\n\n### `neon databases delete`\n\nDeletes a database.\n\n```bash\n# Delete database\nneon databases delete <database_id>\n```\n\n## Roles (Postgres Users)\n\n### `neon roles list`\n\nLists roles for a branch.\n\n```bash\n# List roles\nneon roles list --branch-id <branch_id>\n```\n\n### `neon roles create`\n\nCreates a new role.\n\n```bash\n# Create role with password\nneon roles create --branch-id <branch_id> --name app_user --password mysecret\n```\n\n### `neon roles delete`\n\nDeletes a role.\n\n```bash\n# Delete role\nneon roles delete <role_id>\n```\n\n## IP Allow\n\n### `neon ip-allow list`\n\nLists IP allowlist entries.\n\n```bash\n# Show current allowlist\nneon ip-allow list --project-id <project_id>\n```\n\n### `neon ip-allow add`\n\nAdds an IP to the allowlist.\n\n```bash\n# Allow specific IP\nneon ip-allow add --project-id <project_id> --ip 203.0.113.42/32\n```\n\n### `neon ip-allow remove`\n\nRemoves an IP from the allowlist.\n\n```bash\n# Remove IP from allowlist\nneon ip-allow remove <allowlist_id>\n```\n\n### `neon ip-allow reset`\n\nResets the IP allowlist.\n\n```bash\n# Reset allowlist\nneon ip-allow reset --project-id <project_id>\n```\n\n## VPC\n\n### `neon vpc endpoint create`\n\nCreates a private AWS endpoint.\n\n```bash\n# Create VPC endpoint\nneon vpc endpoint create --project-id <project_id> --region us-east-1\n```\n\n### `neon vpc endpoint list`\n\nLists VPC endpoints.\n\n```bash\n# List VPC endpoints\nneon vpc endpoint list --project-id <project_id>\n```\n\n### `neon vpc endpoint delete`\n\nDeletes a VPC endpoint.\n\n```bash\n# Delete VPC endpoint\nneon vpc endpoint delete <endpoint_id>\n```\n\n## Operations & Monitoring\n\n### `neon operations list`\n\nLists long-running operations.\n\n```bash\n# List operations (backfills, restores, etc.)\nneon operations list --project-id <project_id>\n```\n\n## Connection Strings\n\n### `neon connection-string`\n\nGets connection string for a branch.\n\n```bash\n# Get connection string for default branch\nneon connection-string\n\n# Get connection string for specific branch\nneon connection-string <branch_name>\n```\n\n## Context Management\n\n### `neon set-context`\n\nCreates a persistent context file to avoid passing IDs.\n\n```bash\n# Create context file\nneon set-context --org-id <org_id> --project-id <project_id> --branch-id <branch_id> --name myctx\n\n# Use context file\nneon projects list --context-file ~/.config/neonctl/myctx.json\n```\n\n## Utilities\n\n### `neon completion`\n\nGenerates shell completion scripts.\n\n```bash\n# Generate completions for Bash/Zsh/Fish\nneon completion > /usr/local/share/zsh/site-functions/_neonctl\n```\n\n## Global Options\n\nAll Neon commands support these global flags:\n\n- `-o, --output` â€” Output format (`json`, `yaml`, `table`)\n- `--config-dir` â€” Configuration directory path\n- `--api-key` â€” API key for authentication (instead of OAuth)\n- `--analytics / --no-analytics` â€” Enable/disable telemetry\n- `--color / --no-color` â€” Enable/disable colored output\n- `-v, --version` â€” Show version\n- `-h, --help` â€” Show contextual help\n\n",
        "plugins/dev/skills/neon-cli/reference/common-patterns.md": "# Neon Common Patterns\n\nReal-world patterns and workflows for common Neon use cases.\n\n## Development Workflow\n\n### Basic Project Setup\n\n```bash\n# Authenticate\nneon auth\n\n# Create new project\nneon projects create --name myapp --region aws-us-east-1\n\n# Create development branch\nneon branches create --project-id <project_id> --name dev\n\n# Get connection string\nneon connection-string dev\n```\n\n### Complete Setup Workflow\n\n```bash\n# 1. Authenticate\nneon auth\n\n# 2. Create project\nneon projects create --name myapp --region aws-us-east-1\nexport PROJECT_ID=<project_id>\n\n# 3. Create feature branch\nneon branches create --project-id $PROJECT_ID --name feature_x\n\n# 4. Create application database\nneon databases create --branch-id <feature_branch_id> --name app_db\n\n# 5. Create application role\nneon roles create --branch-id <feature_branch_id> --name app_user --password secret123\n\n# 6. Get connection string\nneon connection-string feature_x\n```\n\n## Multi-Environment Setup\n\n### Development, Staging, Production Branches\n\n```bash\n# Create main/production branch with compute\nneon branches create --project-id <project_id> --name main\nneon branches add-compute <main_branch_id> --size medium\n\n# Create staging branch from main\nneon branches create --project-id <project_id> --name staging --parent-id <main_branch_id>\nneon branches add-compute <staging_branch_id> --size small\n\n# Create development branch from main\nneon branches create --project-id <project_id> --name dev --parent-id <main_branch_id>\n\n# Setup databases per environment\nneon databases create --branch-id <main_branch_id> --name app_db\nneon databases create --branch-id <staging_branch_id> --name app_db\nneon databases create --branch-id <dev_branch_id> --name app_db\n```\n\n## Database Management\n\n### Database Creation and Configuration\n\n```bash\n# Create database in specific branch\nneon databases create --branch-id <branch_id> --name myapp_db\n\n# Create multiple databases\nneon databases create --branch-id <branch_id> --name postgres_db\nneon databases create --branch-id <branch_id> --name cache_db\nneon databases create --branch-id <branch_id> --name logs_db\n\n# List all databases in branch\nneon databases list --branch-id <branch_id>\n```\n\n## Role Management\n\n### User and Role Setup\n\n```bash\n# Create application user\nneon roles create --branch-id <branch_id> --name app_user --password app_password\n\n# Create read-only user\nneon roles create --branch-id <branch_id> --name readonly_user --password readonly_password\n\n# Create migration user\nneon roles create --branch-id <branch_id> --name migration_user --password migration_password\n\n# List all roles\nneon roles list --branch-id <branch_id>\n```\n\n## Feature Branch Workflow\n\n### Isolated Feature Development\n\n```bash\n# Create feature branch from main\nneon branches create --project-id <project_id> --name feature/new-endpoint --parent-id <main_branch_id>\n\n# Add compute for isolated development\nneon branches add-compute <feature_branch_id> --size small\n\n# Create database for feature\nneon databases create --branch-id <feature_branch_id> --name app_db\n\n# Get connection string for development\nneon connection-string feature/new-endpoint\n\n# After feature testing, you can delete the branch\nneon branches delete <feature_branch_id>\n```\n\n## IP Allowlist Management\n\n### Allow Specific IPs\n\n```bash\n# View current allowlist\nneon ip-allow list --project-id <project_id>\n\n# Allow specific IP address\nneon ip-allow add --project-id <project_id> --ip 203.0.113.42/32\n\n# Allow IP range\nneon ip-allow add --project-id <project_id> --ip 192.168.1.0/24\n\n# Allow multiple IPs\nneon ip-allow add --project-id <project_id> --ip 203.0.113.0/24\nneon ip-allow add --project-id <project_id> --ip 198.51.100.0/24\n\n# Remove IP from allowlist\nneon ip-allow remove <allowlist_id>\n```\n\n## VPC Endpoint Setup\n\n### Private Connection Configuration\n\n```bash\n# Create VPC endpoint for private connection\nneon vpc endpoint create --project-id <project_id> --region us-east-1\n\n# List VPC endpoints\nneon vpc endpoint list --project-id <project_id>\n\n# Delete VPC endpoint\nneon vpc endpoint delete <endpoint_id>\n```\n\n## Context Management\n\n### Using Context Files for Simplified Commands\n\n```bash\n# Create context file for project\nneon set-context \\\n  --org-id <org_id> \\\n  --project-id <project_id> \\\n  --branch-id <main_branch_id> \\\n  --name production\n\n# Use context file in commands\nneon branches list --context-file ~/.config/neonctl/production.json\nneon databases list --context-file ~/.config/neonctl/production.json\n\n# Create development context\nneon set-context \\\n  --org-id <org_id> \\\n  --project-id <project_id> \\\n  --branch-id <dev_branch_id> \\\n  --name development\n```\n\n## Output Formatting\n\n### Different Output Formats\n\n```bash\n# Default table output\nneon projects list\n\n# JSON output for scripting\nneon projects list -o json\n\n# YAML output\nneon projects list -o yaml\n\n# Filter and format\nneon branches list --project-id <project_id> -o json | jq '.[] | .name'\n```\n\n## Scripting Examples\n\n### Automated Project Initialization\n\n```bash\n#!/bin/bash\n\nPROJECT_NAME=$1\nREGION=${2:-aws-us-east-1}\n\n# Create project\nPROJECT=$(neon projects create --name $PROJECT_NAME --region $REGION -o json)\nPROJECT_ID=$(echo $PROJECT | jq -r '.id')\n\n# Create main branch\nMAIN=$(neon branches create --project-id $PROJECT_ID --name main -o json)\nMAIN_BRANCH_ID=$(echo $MAIN | jq -r '.id')\n\n# Add compute\nneon branches add-compute $MAIN_BRANCH_ID --size medium\n\n# Create database\nneon databases create --branch-id $MAIN_BRANCH_ID --name ${PROJECT_NAME}_db\n\n# Create application role\nneon roles create \\\n  --branch-id $MAIN_BRANCH_ID \\\n  --name app_user \\\n  --password $(openssl rand -base64 12)\n\necho \"Project $PROJECT_NAME created with ID: $PROJECT_ID\"\nneon connection-string main\n```\n\n### Listing All Projects with Details\n\n```bash\n#!/bin/bash\n\nneon projects list -o json | jq -r '.[] | \"\\(.name) (\\(.id)) - Region: \\(.region)\"'\n```\n\n### Feature Branch Cleanup\n\n```bash\n#!/bin/bash\n\nPROJECT_ID=$1\n\n# Get all branches except main\nneon branches list --project-id $PROJECT_ID -o json | \\\n  jq -r '.[] | select(.name != \"main\") | .id' | \\\n  while read BRANCH_ID; do\n    echo \"Deleting branch: $BRANCH_ID\"\n    neon branches delete $BRANCH_ID\n  done\n```\n\n## Integration Patterns\n\n### Environment Variable Export\n\n```bash\n# Export connection string as environment variable\nexport DATABASE_URL=$(neon connection-string)\n\n# Use in application\necho $DATABASE_URL  # postgresql://user:password@host/dbname\n\n# In .env file\necho \"DATABASE_URL=$(neon connection-string)\" >> .env\n```\n\n### Integration with Application Deployment\n\n```bash\n# Get connection string for production branch\nPROD_CONN=$(neon connection-string production)\n\n# Deploy with environment variable\ndocker run -e DATABASE_URL=\"$PROD_CONN\" myapp:latest\n\n# Or export for process\nexport DATABASE_URL=$(neon connection-string production)\nnpm start\n```\n\n",
        "plugins/dev/skills/neon-cli/reference/troubleshooting.md": "# Neon Troubleshooting Guide\n\nCommon issues and solutions for Neon project management, database operations, and connection problems.\n\n## Authentication Issues\n\n### Cannot Authenticate\n\n**Symptom:** `neon auth` fails or OAuth flow doesn't open\n\n**Diagnosis:**\n\n```bash\n# Check if already authenticated\nneon me\n\n# Check configuration directory\nls -la ~/.config/neonctl/\n\n# Verify API key is set\necho $NEON_API_KEY\n```\n\n**Solutions:**\n\n```bash\n# Perform fresh authentication\nneon auth\n\n# Use explicit API key\nexport NEON_API_KEY=<your_api_key>\nneon projects list --api-key $NEON_API_KEY\n\n# Clear cached credentials\nrm -rf ~/.config/neonctl/\nneon auth\n```\n\n### Invalid API Key\n\n**Symptom:** \"Unauthorized\" or \"Invalid credentials\" error\n\n**Diagnosis:**\n\n```bash\n# Verify API key exists\necho $NEON_API_KEY | wc -c\n\n# Test connection\nneon me --api-key $NEON_API_KEY\n```\n\n**Solutions:**\n\n```bash\n# Generate new API key from Neon dashboard\nneon auth\n\n# Check key format (should be long string)\n# Set key explicitly\nexport NEON_API_KEY=<new_key>\n\n# Update config file\n~/.config/neonctl/config.toml\n```\n\n## Project Issues\n\n### Project Not Found\n\n**Symptom:** \"Project not found\" error when accessing project\n\n**Diagnosis:**\n\n```bash\n# List all accessible projects\nneon projects list\n\n# Verify project ID format\nneon projects get <project_id>\n```\n\n**Solutions:**\n\n```bash\n# Ensure correct project ID\nneon projects list -o json | jq -r '.[] | .id' | head -5\n\n# Check organization membership\nneon orgs list\n\n# Verify permissions in Neon dashboard\n```\n\n### Cannot Create Project\n\n**Symptom:** `neon projects create` fails\n\n**Diagnosis:**\n\n```bash\n# Check if project name is unique\nneon projects list -o json | jq -r '.[] | .name'\n\n# Verify region is valid\nneon projects create --name test --region invalid-region\n```\n\n**Solutions:**\n\n```bash\n# Use unique project name\nneon projects create --name myapp-$(date +%s) --region aws-us-east-1\n\n# Use valid region\n# Available: aws-us-east-1, aws-us-west-2, aws-eu-west-1, etc.\n\n# Check organization limits\nneon orgs list -o json | jq '.[] | .project_count'\n```\n\n### Cannot Delete Project\n\n**Symptom:** \"Cannot delete project\" or \"Project has active resources\"\n\n**Solutions:**\n\n```bash\n# Ensure no active connections\n# Delete all branches first (except main)\nneon branches list --project-id <project_id> -o json | \\\n  jq -r '.[] | select(.name != \"main\") | .id' | \\\n  xargs -I {} neon branches delete {}\n\n# Then delete project\nneon projects delete <project_id>\n```\n\n## Branch Issues\n\n### Branch Not Found\n\n**Symptom:** \"Branch not found\" when accessing branch\n\n**Diagnosis:**\n\n```bash\n# List all branches\nneon branches list --project-id <project_id>\n\n# Get branch ID format\nneon branches list --project-id <project_id> -o json | jq '.[].id'\n```\n\n**Solutions:**\n\n```bash\n# Use correct branch ID (not name)\nneon branches list --project-id <project_id> -o json | \\\n  jq '.[] | select(.name==\"feature_x\") | .id'\n```\n\n### Cannot Create Branch\n\n**Symptom:** `neon branches create` fails\n\n**Diagnosis:**\n\n```bash\n# Check parent branch exists\nneon branches get --project-id <project_id> <parent_branch_id>\n\n# Verify project has space for branches\nneon projects get <project_id>\n```\n\n**Solutions:**\n\n```bash\n# Create from main branch\nneon branches create --project-id <project_id> --name new_feature --parent-id <main_branch_id>\n\n# Use unique branch name\nneon branches list --project-id <project_id> -o json | jq '.[].name'\n\n# Ensure sufficient plan resources\n```\n\n### Missing Compute on Branch\n\n**Symptom:** Branch exists but can't connect (compute resource missing)\n\n**Diagnosis:**\n\n```bash\n# Check branch compute status\nneon branches get <branch_id> -o json | jq '.compute_endpoints'\n\n# Verify compute is attached\nneon branches list --project-id <project_id> -o json | \\\n  jq '.[] | select(.id==\"<branch_id>\") | .compute_endpoints'\n```\n\n**Solutions:**\n\n```bash\n# Add compute to branch\nneon branches add-compute <branch_id> --size small\n\n# Check available sizes: small, medium, large\n\n# Wait for compute to initialize (usually 30-60 seconds)\nsleep 60\nneon branches get <branch_id>\n```\n\n## Database Issues\n\n### Database Not Found\n\n**Symptom:** \"Database not found\" error\n\n**Diagnosis:**\n\n```bash\n# List all databases in branch\nneon databases list --branch-id <branch_id>\n\n# Verify database name\nneon databases list --branch-id <branch_id> -o json | jq '.[] | .name'\n```\n\n**Solutions:**\n\n```bash\n# Use correct database name\nneon databases list --branch-id <branch_id>\n\n# Database might exist on different branch\nneon branches list --project-id <project_id> | grep -A 5 <branch_name>\n```\n\n### Cannot Create Database\n\n**Symptom:** `neon databases create` fails\n\n**Diagnosis:**\n\n```bash\n# Verify branch exists\nneon branches get <branch_id>\n\n# Check database limit\nneon databases list --branch-id <branch_id> | wc -l\n```\n\n**Solutions:**\n\n```bash\n# Use unique database name\nneon databases list --branch-id <branch_id> -o json | jq '.[].name'\n\n# Create with unique name\nneon databases create --branch-id <branch_id> --name app_db_$(date +%s)\n\n# Check plan limits\n```\n\n## Role Issues\n\n### Role/User Not Found\n\n**Symptom:** \"Role not found\" when accessing user\n\n**Diagnosis:**\n\n```bash\n# List all roles\nneon roles list --branch-id <branch_id>\n\n# Verify role name\nneon roles list --branch-id <branch_id> -o json | jq '.[].name'\n```\n\n**Solutions:**\n\n```bash\n# Use correct role name\nneon roles list --branch-id <branch_id>\n\n# Create missing role\nneon roles create --branch-id <branch_id> --name app_user --password secret\n```\n\n### Cannot Create Role\n\n**Symptom:** `neon roles create` fails\n\n**Diagnosis:**\n\n```bash\n# Verify branch has compute\nneon branches get <branch_id> -o json | jq '.compute_endpoints'\n\n# Check role limit\nneon roles list --branch-id <branch_id> | wc -l\n```\n\n**Solutions:**\n\n```bash\n# Ensure branch has compute attached\nneon branches add-compute <branch_id> --size small\n\n# Use unique role name\nneon roles list --branch-id <branch_id> -o json | jq '.[].name'\n\n# Create role with strong password\nneon roles create --branch-id <branch_id> --name newuser --password $(openssl rand -base64 12)\n```\n\n## Connection Issues\n\n### Cannot Get Connection String\n\n**Symptom:** `neon connection-string` fails or returns empty\n\n**Diagnosis:**\n\n```bash\n# Verify branch exists\nneon branches get <branch_id>\n\n# Check if branch has compute\nneon branches get <branch_id> -o json | jq '.compute_endpoints'\n\n# Verify database exists\nneon databases list --branch-id <branch_id>\n```\n\n**Solutions:**\n\n```bash\n# Ensure branch has compute\nneon branches add-compute <branch_id> --size small\n\n# Create default database if missing\nneon databases create --branch-id <branch_id> --name neondb\n\n# Get specific branch connection string\nneon connection-string <branch_name>\n```\n\n### Connection Timeout\n\n**Symptom:** Cannot connect to database from application\n\n**Diagnosis:**\n\n```bash\n# Verify connection string format\nneon connection-string\n\n# Check IP allowlist\nneon ip-allow list --project-id <project_id>\n\n# Test connectivity\npsql <connection_string>\n```\n\n**Solutions:**\n\n```bash\n# Add client IP to allowlist\nneon ip-allow add --project-id <project_id> --ip <your_ip>/32\n\n# Check firewall/network access\n# Verify branch has compute active\nneon branches get <branch_id> -o json | jq '.compute_endpoints[0].type'\n\n# Wait for branch to be ready (may take 60 seconds after creation)\n```\n\n### Wrong Connection String Format\n\n**Symptom:** Connection string missing parameters or malformed\n\n**Diagnosis:**\n\n```bash\n# Check connection string output\nneon connection-string\n\n# Verify format: postgresql://user:password@host:port/database\n```\n\n**Solutions:**\n\n```bash\n# Ensure database exists\nneon databases list --branch-id <branch_id>\n\n# Recreate with JSON output for debugging\nneon connection-string -o json\n\n# Connection string should include: host, port, database, user, password\n```\n\n## IP Allowlist Issues\n\n### IP Not Whitelisted\n\n**Symptom:** \"Connection refused\" or \"Host is not allowed to connect\"\n\n**Diagnosis:**\n\n```bash\n# Check current allowlist\nneon ip-allow list --project-id <project_id>\n\n# Identify your IP\ncurl -s ipinfo.io | jq '.ip'\n```\n\n**Solutions:**\n\n```bash\n# Add your IP to allowlist\nYOUR_IP=$(curl -s ipinfo.io | jq -r '.ip')\nneon ip-allow add --project-id <project_id> --ip $YOUR_IP/32\n\n# Allow CIDR range (less secure)\nneon ip-allow add --project-id <project_id> --ip 0.0.0.0/0\n\n# For development, allow specific IP range\nneon ip-allow add --project-id <project_id> --ip 192.168.1.0/24\n```\n\n### Cannot Manage Allowlist\n\n**Symptom:** Permission denied when modifying allowlist\n\n**Solutions:**\n\n```bash\n# Verify correct project ID\nneon projects list\n\n# Check permissions\nneon me\n\n# Use API key with sufficient permissions\nexport NEON_API_KEY=<full_permissions_key>\n```\n\n## Operations & Monitoring\n\n### Long-Running Operation Stuck\n\n**Symptom:** Operation appears stuck or doesn't complete\n\n**Diagnosis:**\n\n```bash\n# List active operations\nneon operations list --project-id <project_id>\n\n# Check operation status\nneon operations list --project-id <project_id> -o json | jq '.[]'\n```\n\n**Solutions:**\n\n```bash\n# Wait for operation to complete (usually 5-10 minutes)\n# Monitor progress\nneon operations list --project-id <project_id> --watch\n\n# If truly stuck, try recreating resource\nneon branches delete <branch_id>\nneon branches create --project-id <project_id> --name new_branch\n```\n\n## Regional Issues\n\n### Wrong Region Selected\n\n**Symptom:** Project in unexpected region\n\n**Solutions:**\n\n```bash\n# Verify available regions\n# aws-us-east-1, aws-us-west-2, aws-eu-west-1, etc.\n\n# Create project in correct region\nneon projects create --name myapp --region aws-eu-west-1\n\n# Cannot change region after creation (delete and recreate)\nneon projects delete <project_id>\nneon projects create --name myapp --region aws-eu-west-1\n```\n\n## Rate Limiting\n\n### Too Many API Requests\n\n**Symptom:** \"Rate limit exceeded\" error\n\n**Solutions:**\n\n```bash\n# Add delays between commands in scripts\nneon projects list\nsleep 1\nneon branches list --project-id <project_id>\nsleep 1\n\n# Batch operations in single commands\n# Use JSON output for scripting with fewer calls\nneon projects list -o json | jq '.[]'\n```\n\n## General Troubleshooting\n\n### Enable Debug Output\n\n```bash\n# Run command with verbose output\nneon projects list --debug\n\n# Check logs\ncat ~/.config/neonctl/logs.txt\n\n# Set debug environment variable\nexport NEON_DEBUG=1\nneon projects list\n```\n\n### Check CLI Version\n\n```bash\n# Check installed version\nneon --version\n\n# Update to latest version\nbrew upgrade neonctl\nnpm update -g neonctl\nbun update -g neonctl\n```\n\n### Verify Installation\n\n```bash\n# Check command availability\nwhich neon\n\n# Test basic command\nneon --help\n\n# Verify API connectivity\nneon me\n```\n\n",
        "plugins/dev/skills/nextjs-cli/SKILL.md": "---\nname: nextjs-cli\ndescription: Next.js CLI expert for React development. Use when users need to create, develop, build, or deploy Next.js applications.\nallowed-tools: Bash(next:*), Bash(npx next:*), Bash(bunx next:*)\n---\n\n# Next.js CLI Guide\n\nNext.js is a React framework for building full-stack web applications with features like file-based routing, server-side rendering, and API routes. This guide provides essential workflows and quick references for common Next.js operations.\n\n## Quick Start\n\n```bash\n# Create new Next.js app (interactive)\nnpx create-next-app@latest\n\n# Create with specific name\nnpx create-next-app@latest my-app\n\n# Start development server\ncd my-app\nnpm run dev\n\n# Build for production\nnpm run build\n\n# Start production server\nnpm run start\n\n# Run linter\nnpm run lint\n```\n\n## Common Workflows\n\n### Workflow 1: Create and Run New Application\n\n```bash\n# Create new app with TypeScript and Tailwind\nnpx create-next-app@latest my-app \\\n  --typescript \\\n  --tailwind \\\n  --app \\\n  --use-pnpm\n\n# Navigate to project\ncd my-app\n\n# Start development server with Turbopack\nnpm run dev -- --turbopack\n\n# Open browser to http://localhost:3000\n```\n\n### Workflow 2: Add New Pages and Routes\n\n```bash\n# Create new route (App Router)\nmkdir -p app/about\ntouch app/about/page.tsx\n\n# Create dynamic route\nmkdir -p app/blog/[slug]\ntouch app/blog/[slug]/page.tsx\n\n# Create API route\nmkdir -p app/api/users\ntouch app/api/users/route.ts\n\n# Development server auto-reloads changes\n```\n\n### Workflow 3: Data Fetching and API Integration\n\n```typescript\n// Server Component with data fetching\n// app/posts/page.tsx\nasync function getPosts() {\n  const res = await fetch('https://api.example.com/posts', {\n    next: { revalidate: 60 } // ISR: revalidate every 60s\n  })\n  return res.json()\n}\n\nexport default async function PostsPage() {\n  const posts = await getPosts()\n  return <div>{/* Render posts */}</div>\n}\n```\n\n```typescript\n// API Route Handler\n// app/api/users/route.ts\nimport { NextResponse } from 'next/server'\n\nexport async function GET() {\n  const users = await getUsers()\n  return NextResponse.json(users)\n}\n\nexport async function POST(request: Request) {\n  const body = await request.json()\n  const user = await createUser(body)\n  return NextResponse.json(user, { status: 201 })\n}\n```\n\n### Workflow 4: Build and Deploy Production App\n\n```bash\n# Run linting and type checking\nnpm run lint\nnpm run type-check\n\n# Build for production\nnpm run build\n\n# Test production build locally\nnpm run start\n\n# Deploy to Vercel\nnpm i -g vercel\nvercel --prod\n\n# Or deploy with Docker\n# next.config.js: output: 'standalone'\ndocker build -t my-app .\ndocker run -p 3000:3000 my-app\n```\n\n### Workflow 5: Debug and Optimize\n\n```bash\n# Check system information\nnext info\n\n# Debug development server\nNODE_OPTIONS='--inspect' next dev\n\n# Debug build issues\nnext build --debug\n\n# Profile React performance\nnext build --profile\n\n# Analyze bundle size\nANALYZE=true next build\n\n# Clear cache and rebuild\nrm -rf .next node_modules\nnpm install\nnpm run build\n```\n\n## Decision Tree\n\n**When to use which command:**\n\n- **To create a new project**: Use `npx create-next-app@latest` with appropriate flags\n- **To start development**: Use `next dev` or `next dev --turbopack` for faster HMR\n- **To add routes**: Create `page.tsx` files in `app/` directory (App Router)\n- **To add API endpoints**: Create `route.ts` files in `app/api/` directory\n- **To fetch data**: Use async Server Components (default) or Client Components with `'use client'`\n- **To build for production**: Use `next build` then `next start`\n- **To fix linting issues**: Use `next lint --fix`\n- **To generate route types**: Use `next typegen`\n- **For detailed command syntax**: See [Commands Reference](./reference/commands-reference.md)\n- **For development patterns**: See [Common Patterns](./reference/common-patterns.md)\n- **For troubleshooting**: See [Troubleshooting Guide](./reference/troubleshooting.md)\n\n## Common Patterns\n\n### App Router Structure\n\n```bash\napp/\nâ”œâ”€â”€ page.tsx              # Home page (/)\nâ”œâ”€â”€ layout.tsx            # Root layout\nâ”œâ”€â”€ loading.tsx           # Loading UI\nâ”œâ”€â”€ error.tsx             # Error boundary\nâ”œâ”€â”€ not-found.tsx         # 404 page\nâ”œâ”€â”€ about/\nâ”‚   â””â”€â”€ page.tsx          # /about route\nâ”œâ”€â”€ blog/\nâ”‚   â”œâ”€â”€ page.tsx          # /blog route\nâ”‚   â””â”€â”€ [slug]/\nâ”‚       â””â”€â”€ page.tsx      # /blog/:slug route\nâ””â”€â”€ api/\n    â””â”€â”€ users/\n        â””â”€â”€ route.ts      # /api/users endpoint\n```\n\n### Data Fetching Strategies\n\n```typescript\n// Static Site Generation (SSG)\nconst res = await fetch('https://api.example.com/data', {\n  cache: 'force-cache'\n})\n\n// Incremental Static Regeneration (ISR)\nconst res = await fetch('https://api.example.com/data', {\n  next: { revalidate: 60 }\n})\n\n// Server-Side Rendering (SSR)\nconst res = await fetch('https://api.example.com/data', {\n  cache: 'no-store'\n})\n```\n\n### Environment Variables\n\n```bash\n# .env.local (gitignored, local development)\nDATABASE_URL=postgresql://localhost:5432/mydb\nAPI_KEY=secret_key\n\n# .env.production (production)\nNEXT_PUBLIC_API_URL=https://api.example.com\n\n# Client-side (prefixed with NEXT_PUBLIC_)\nNEXT_PUBLIC_ANALYTICS_ID=G-XXXXXXXXXX\n\n# Server-only (no prefix)\nDATABASE_PASSWORD=secret\n```\n\n## Troubleshooting\n\n**Common Issues:**\n\n1. **Port already in use**\n   - Solution: `next dev -p 3001` or kill process with `lsof -ti:3000 | xargs kill -9`\n   - See: [Port Already in Use](./reference/troubleshooting.md#port-already-in-use)\n\n2. **Hydration errors**\n   - Quick fix: Use `'use client'` and `useEffect` for client-only content\n   - See: [Hydration Errors](./reference/troubleshooting.md#hydration-errors)\n\n3. **Build fails with memory error**\n   - Quick fix: `NODE_OPTIONS='--max-old-space-size=4096' next build`\n   - See: [Build Fails with Memory Error](./reference/troubleshooting.md#build-fails-with-memory-error)\n\n4. **Module not found errors**\n   - Quick fix: Clear cache and reinstall: `rm -rf .next node_modules && npm install`\n   - See: [Module Not Found Errors](./reference/troubleshooting.md#module-not-found-errors)\n\n5. **Environment variables not working**\n   - Quick fix: Ensure `NEXT_PUBLIC_` prefix for client-side, rebuild app\n   - See: [Environment Variables Not Working](./reference/troubleshooting.md#environment-variables-not-working)\n\nFor detailed troubleshooting steps, see the [Troubleshooting Guide](./reference/troubleshooting.md).\n\n## Reference Files\n\n**Load as needed for detailed information:**\n\n- **[Commands Reference](./reference/commands-reference.md)** - Complete CLI command documentation with all flags and options. Use when you need exact syntax or flag details for `create-next-app`, `next dev`, `next build`, `next start`, `next lint`, and other commands.\n\n- **[Common Patterns](./reference/common-patterns.md)** - Real-world patterns for App Router, data fetching, API routes, configuration, deployment, and performance optimization. Use for implementing routing, SSR/SSG/ISR, dynamic imports, or CI/CD pipelines.\n\n- **[Troubleshooting Guide](./reference/troubleshooting.md)** - Detailed error messages, diagnosis steps, and resolution strategies for development, build, runtime, routing, and deployment issues. Use when encountering errors like hydration mismatches, build failures, or 404s.\n\n**When to use each reference:**\n\n- Use **Commands Reference** when you need exact syntax, flag combinations, or comprehensive command documentation\n- Use **Common Patterns** for implementing file-based routing, data fetching strategies, API endpoints, or deployment configurations\n- Use **Troubleshooting** when encountering build errors, hydration issues, port conflicts, or environment variable problems\n\n## Resources\n\n- Official Docs: https://nextjs.org/docs\n- CLI Reference: https://nextjs.org/docs/app/api-reference/cli\n- Examples: https://github.com/vercel/next.js/tree/canary/examples\n- GitHub: https://github.com/vercel/next.js\n- Community: https://github.com/vercel/next.js/discussions\n",
        "plugins/dev/skills/nextjs-cli/reference/commands-reference.md": "# Next.js CLI Commands Reference\n\nComplete reference for all Next.js CLI commands with detailed options and flags.\n\n## Installation & Project Creation\n\n### `create-next-app`\n\nCreates a new Next.js application with interactive setup.\n\n```bash\n# Interactive setup (recommended)\nnpx create-next-app@latest\n\n# Create with specific name\nnpx create-next-app@latest my-app\n\n# With pnpm\npnpm create next-app\n\n# With yarn\nyarn create next-app\n\n# With bun\nbunx create-next-app\n```\n\n## Project Creation Options\n\n### Basic Options\n\n```bash\n# Show help\nnpx create-next-app --help\n\n# Show version\nnpx create-next-app --version\n\n# Use previous preferences (skip prompts)\nnpx create-next-app my-app --yes\n```\n\n### Language & Framework\n\n```bash\n# TypeScript project (default)\nnpx create-next-app my-app --typescript\n\n# JavaScript project\nnpx create-next-app my-app --javascript\n\n# Negate default options\nnpx create-next-app my-app --no-ts\n```\n\n### Styling & Linting\n\n```bash\n# With Tailwind CSS (default)\nnpx create-next-app my-app --tailwind\n\n# Without Tailwind\nnpx create-next-app my-app --no-tailwind\n\n# With ESLint\nnpx create-next-app my-app --eslint\n\n# With Biome linter\nnpx create-next-app my-app --biome\n\n# No linter\nnpx create-next-app my-app --no-linter\n```\n\n### Project Structure\n\n```bash\n# App Router (default)\nnpx create-next-app my-app --app\n\n# API-only project (route handlers only)\nnpx create-next-app my-app --api\n\n# Initialize inside src/ directory\nnpx create-next-app my-app --src-dir\n\n# Empty project\nnpx create-next-app my-app --empty\n```\n\n### Build Tool\n\n```bash\n# With Turbopack (default)\nnpx create-next-app my-app --turbopack\n\n# Force Webpack\nnpx create-next-app my-app --webpack\n```\n\n### React Features\n\n```bash\n# Enable React Compiler\nnpx create-next-app my-app --react-compiler\n```\n\n### Import Alias\n\n```bash\n# Custom import alias (default: @/*)\nnpx create-next-app my-app --import-alias \"~/\\*\"\n\n# No import alias\nnpx create-next-app my-app --import-alias \"\"\n```\n\n### Package Manager\n\n```bash\n# Use npm\nnpx create-next-app my-app --use-npm\n\n# Use pnpm\nnpx create-next-app my-app --use-pnpm\n\n# Use yarn\nnpx create-next-app my-app --use-yarn\n\n# Use bun\nnpx create-next-app my-app --use-bun\n```\n\n### Examples & Templates\n\n```bash\n# Bootstrap with example\nnpx create-next-app my-app --example with-tailwindcss\n\n# Bootstrap with GitHub URL\nnpx create-next-app my-app --example https://github.com/vercel/next.js/tree/canary/examples/with-typescript\n\n# Specify example path\nnpx create-next-app my-app --example blog-starter --example-path cms-contentful\n```\n\n### Additional Options\n\n```bash\n# Skip package installation\nnpx create-next-app my-app --skip-install\n\n# Disable git initialization\nnpx create-next-app my-app --disable-git\n\n# Reset stored preferences\nnpx create-next-app --reset-preferences\n```\n\n### Complete Example\n\n```bash\n# Full custom setup\nnpx create-next-app my-app \\\n  --typescript \\\n  --tailwind \\\n  --eslint \\\n  --app \\\n  --src-dir \\\n  --turbopack \\\n  --import-alias \"@/*\" \\\n  --use-pnpm\n```\n\n## Core CLI Commands\n\n### `next dev`\n\nStarts the development server with Hot Module Reloading (HMR).\n\n```bash\n# Start dev server (default port 3000)\nnext dev\n\n# Custom port\nnext dev -p 3001\nnext dev --port 4000\n\n# Custom hostname\nnext dev -H localhost\nnext dev --hostname 192.168.1.100\n\n# Enable Turbopack\nnext dev --turbopack\n\n# Force Webpack\nnext dev --webpack\n\n# HTTPS with self-signed certificate\nnext dev --experimental-https\n\n# Combine options\nnext dev -p 3001 --turbopack\n```\n\n### `next build`\n\nCreates an optimized production build.\n\n```bash\n# Build for production\nnext build\n\n# Enable verbose build output\nnext build --debug\nnext build -d\n\n# Enable production profiling for React\nnext build --profile\n\n# Disable linting during build\nnext build --no-lint\n\n# Debug prerender errors\nnext build --debug-prerender\n\n# Build only specific routes\nnext build --debug-build-paths=\"/blog/**,/about\"\nnext build --debug-build-paths=\"**/*\"\n```\n\n### `next start`\n\nStarts the production server (requires `next build` first).\n\n```bash\n# Start production server (default port 3000)\nnext start\n\n# Custom port\nnext start -p 8080\nnext start --port 3001\n\n# Custom hostname\nnext start -H 0.0.0.0\nnext start --hostname localhost\n\n# Set keep-alive timeout (for downstream proxies)\nnext start --keepAliveTimeout 70000\n```\n\n## Utility Commands\n\n### `next lint`\n\nRuns ESLint for all files in the project.\n\n```bash\n# Lint entire project\nnext lint\n\n# Lint specific directories\nnext lint --dir pages --dir utils\n\n# Lint specific files\nnext lint --file pages/index.js\n\n# Enable caching (faster subsequent runs)\nnext lint --cache\n\n# Fix auto-fixable issues\nnext lint --fix\n\n# Show error details\nnext lint --debug\n\n# Suppress warnings\nnext lint --quiet\n\n# Specify max warnings\nnext lint --max-warnings 10\n\n# Output format\nnext lint --format json\nnext lint --format stylish\n```\n\n### `next info`\n\nPrints system information for bug reporting.\n\n```bash\n# Display system info\nnext info\n\n# Output includes:\n# - Operating System\n# - Binaries (Node, npm, yarn, pnpm)\n# - Relevant packages (next, react, typescript)\n```\n\n### `next telemetry`\n\nManages anonymous telemetry collection.\n\n```bash\n# Enable telemetry\nnext telemetry enable\n\n# Disable telemetry\nnext telemetry disable\n\n# Check telemetry status\nnext telemetry status\n```\n\n### `next typegen`\n\nGenerates TypeScript definitions for routes.\n\n```bash\n# Generate route types\nnext typegen\n\n# Types are written to .next/types or .next/dev/types\n\n# Use with TypeScript validation\nnext typegen && tsc --noEmit\n```\n\n### `next upgrade`\n\nUpgrades Next.js to the latest version.\n\n```bash\n# Upgrade to latest version\nnext upgrade\n\n# Upgrade to specific version\nnext upgrade 14.0.0\n\n# Check for available updates\nnext upgrade --check\n```\n\n## Environment Variables\n\n### Setting Environment Variables\n\nNext.js loads environment variables from `.env*` files:\n\n```bash\n# .env.local (local development, gitignored)\nDATABASE_URL=postgresql://localhost:5432/mydb\nAPI_KEY=secret_key\n\n# .env.development (development)\nNEXT_PUBLIC_API_URL=http://localhost:3000/api\n\n# .env.production (production)\nNEXT_PUBLIC_API_URL=https://api.example.com\n\n# .env.test (testing)\nNODE_ENV=test\n```\n\n### Public Variables\n\nVariables prefixed with `NEXT_PUBLIC_` are exposed to the browser:\n\n```bash\n# Accessible in browser\nNEXT_PUBLIC_ANALYTICS_ID=G-XXXXXXXXXX\n\n# Server-only (not prefixed)\nDATABASE_PASSWORD=secret\n```\n\n## Advanced Commands\n\n### Custom Node Options\n\n```bash\n# Increase memory limit\nNODE_OPTIONS='--max-old-space-size=4096' next build\n\n# Enable inspector\nNODE_OPTIONS='--inspect' next dev\n\n# Multiple options\nNODE_OPTIONS='--max-old-space-size=8192 --inspect' next dev\n```\n\n### Environment-Specific Builds\n\n```bash\n# Development build\nNODE_ENV=development next build\n\n# Production build\nNODE_ENV=production next build\n\n# Test build\nNODE_ENV=test next build\n```\n\n### Migration Commands\n\n#### Upgrading Next.js\n\n```bash\n# Check current version\nnext info\n\n# Upgrade to latest\nnext upgrade\n\n# Upgrade to specific version\nnpm install next@14.0.0 react@latest react-dom@latest\n\n# Run codemods for breaking changes\nnpx @next/codemod@latest\n```\n\n## Global Options\n\nAll Next.js commands support these environment variables:\n\n- `NODE_ENV` â€” Set environment (development/production/test)\n- `PORT` â€” Set default port for dev/start\n- `HOSTNAME` â€” Set hostname for server binding\n- `NEXT_TELEMETRY_DISABLED` â€” Disable telemetry (set to 1)\n- `NEXT_SOURCE_MAPS` â€” Enable source maps in production\n",
        "plugins/dev/skills/nextjs-cli/reference/common-patterns.md": "# Next.js Common Patterns\n\nReal-world patterns and workflows for common Next.js development scenarios.\n\n## Development Workflow\n\n### Basic App Development\n\n```bash\n# Create new project\nnpx create-next-app@latest my-app\n\n# Navigate to project\ncd my-app\n\n# Start development server\nnpm run dev\n\n# Or with custom options\nnpm run dev -- -p 3001 --turbopack\n```\n\n### Development with Custom Server\n\n```bash\n# Using custom server.js\nnode server.js\n\n# Example server.js\nconst { createServer } = require('http')\nconst { parse } = require('url')\nconst next = require('next')\n\nconst dev = process.env.NODE_ENV !== 'production'\nconst app = next({ dev })\nconst handle = app.getRequestHandler()\n\napp.prepare().then(() => {\n  createServer((req, res) => {\n    const parsedUrl = parse(req.url, true)\n    handle(req, res, parsedUrl)\n  }).listen(3000)\n})\n```\n\n## App Router Patterns\n\n### File-Based Routing\n\n```bash\n# Route structure\napp/\nâ”œâ”€â”€ page.tsx              # / route\nâ”œâ”€â”€ about/\nâ”‚   â””â”€â”€ page.tsx          # /about route\nâ”œâ”€â”€ blog/\nâ”‚   â”œâ”€â”€ page.tsx          # /blog route\nâ”‚   â””â”€â”€ [slug]/\nâ”‚       â””â”€â”€ page.tsx      # /blog/:slug route\nâ””â”€â”€ api/\n    â””â”€â”€ users/\n        â””â”€â”€ route.ts      # /api/users API route\n```\n\n### Dynamic Routes\n\n```typescript\n// app/blog/[slug]/page.tsx\nexport default function BlogPost({ params }: { params: { slug: string } }) {\n  return <h1>Blog Post: {params.slug}</h1>\n}\n\n// Generate static paths\nexport async function generateStaticParams() {\n  const posts = await getPosts()\n  return posts.map((post) => ({\n    slug: post.slug,\n  }))\n}\n```\n\n### Route Groups\n\n```bash\n# Organize routes without affecting URL\napp/\nâ”œâ”€â”€ (marketing)/\nâ”‚   â”œâ”€â”€ about/\nâ”‚   â”‚   â””â”€â”€ page.tsx      # /about\nâ”‚   â””â”€â”€ pricing/\nâ”‚       â””â”€â”€ page.tsx      # /pricing\nâ””â”€â”€ (shop)/\n    â”œâ”€â”€ products/\n    â”‚   â””â”€â”€ page.tsx      # /products\n    â””â”€â”€ cart/\n        â””â”€â”€ page.tsx      # /cart\n```\n\n## Data Fetching Patterns\n\n### Server Components (Default)\n\n```typescript\n// app/posts/page.tsx\nasync function getPosts() {\n  const res = await fetch('https://api.example.com/posts', {\n    cache: 'force-cache', // SSG\n  })\n  return res.json()\n}\n\nexport default async function PostsPage() {\n  const posts = await getPosts()\n  return <div>{/* Render posts */}</div>\n}\n```\n\n### Dynamic Data Fetching\n\n```typescript\n// Revalidate every 60 seconds (ISR)\nasync function getPosts() {\n  const res = await fetch('https://api.example.com/posts', {\n    next: { revalidate: 60 }\n  })\n  return res.json()\n}\n\n// No caching (SSR)\nasync function getPosts() {\n  const res = await fetch('https://api.example.com/posts', {\n    cache: 'no-store'\n  })\n  return res.json()\n}\n```\n\n### Client Components\n\n```typescript\n'use client'\n\nimport { useState, useEffect } from 'react'\n\nexport default function ClientComponent() {\n  const [data, setData] = useState(null)\n\n  useEffect(() => {\n    fetch('/api/data')\n      .then(res => res.json())\n      .then(setData)\n  }, [])\n\n  return <div>{/* Render data */}</div>\n}\n```\n\n## API Routes Patterns\n\n### Basic API Route\n\n```typescript\n// app/api/users/route.ts\nimport { NextResponse } from 'next/server'\n\nexport async function GET() {\n  const users = await getUsers()\n  return NextResponse.json(users)\n}\n\nexport async function POST(request: Request) {\n  const body = await request.json()\n  const user = await createUser(body)\n  return NextResponse.json(user, { status: 201 })\n}\n```\n\n### Dynamic API Routes\n\n```typescript\n// app/api/users/[id]/route.ts\nimport { NextResponse } from 'next/server'\n\nexport async function GET(\n  request: Request,\n  { params }: { params: { id: string } }\n) {\n  const user = await getUser(params.id)\n  return NextResponse.json(user)\n}\n\nexport async function PATCH(\n  request: Request,\n  { params }: { params: { id: string } }\n) {\n  const body = await request.json()\n  const user = await updateUser(params.id, body)\n  return NextResponse.json(user)\n}\n```\n\n### Error Handling\n\n```typescript\n// app/api/users/route.ts\nimport { NextResponse } from 'next/server'\n\nexport async function GET() {\n  try {\n    const users = await getUsers()\n    return NextResponse.json(users)\n  } catch (error) {\n    return NextResponse.json(\n      { error: 'Failed to fetch users' },\n      { status: 500 }\n    )\n  }\n}\n```\n\n## Configuration Patterns\n\n### next.config.js\n\n```javascript\n/** @type {import('next').NextConfig} */\nconst nextConfig = {\n  // Enable React strict mode\n  reactStrictMode: true,\n\n  // Turbopack configuration\n  experimental: {\n    turbopack: {\n      // Turbopack-specific options\n    },\n  },\n\n  // Webpack configuration\n  webpack: (config, { isServer }) => {\n    // Custom webpack config\n    return config\n  },\n\n  // Environment variables\n  env: {\n    CUSTOM_KEY: \"value\",\n  },\n\n  // Redirects\n  async redirects() {\n    return [\n      {\n        source: \"/old-page\",\n        destination: \"/new-page\",\n        permanent: true,\n      },\n    ]\n  },\n\n  // Headers\n  async headers() {\n    return [\n      {\n        source: \"/api/:path*\",\n        headers: [{ key: \"Access-Control-Allow-Origin\", value: \"*\" }],\n      },\n    ]\n  },\n\n  // Image optimization\n  images: {\n    domains: [\"example.com\"],\n    formats: [\"image/avif\", \"image/webp\"],\n  },\n\n  // Output configuration\n  output: \"standalone\", // For Docker\n}\n\nmodule.exports = nextConfig\n```\n\n## Package.json Scripts\n\n### Standard Setup\n\n```json\n{\n  \"scripts\": {\n    \"dev\": \"next dev\",\n    \"build\": \"next build\",\n    \"start\": \"next start\",\n    \"lint\": \"next lint\"\n  }\n}\n```\n\n### Advanced Scripts\n\n```json\n{\n  \"scripts\": {\n    \"dev\": \"next dev --turbopack\",\n    \"dev:debug\": \"NODE_OPTIONS='--inspect' next dev\",\n    \"build\": \"next build\",\n    \"build:analyze\": \"ANALYZE=true next build\",\n    \"build:debug\": \"next build --debug\",\n    \"start\": \"next start -p 3000\",\n    \"start:prod\": \"NODE_ENV=production next start\",\n    \"lint\": \"next lint\",\n    \"lint:fix\": \"next lint --fix\",\n    \"type-check\": \"tsc --noEmit\",\n    \"format\": \"prettier --write .\",\n    \"test\": \"jest\",\n    \"test:watch\": \"jest --watch\",\n    \"clean\": \"rm -rf .next out\"\n  }\n}\n```\n\n## Deployment Patterns\n\n### Vercel Deployment\n\n```bash\n# Install Vercel CLI\nnpm i -g vercel\n\n# Deploy\nvercel\n\n# Production deployment\nvercel --prod\n```\n\n### Docker Deployment\n\n```dockerfile\n# Dockerfile\nFROM node:18-alpine AS base\n\n# Install dependencies only when needed\nFROM base AS deps\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci\n\n# Build the application\nFROM base AS builder\nWORKDIR /app\nCOPY --from=deps /app/node_modules ./node_modules\nCOPY . .\nRUN npm run build\n\n# Production image\nFROM base AS runner\nWORKDIR /app\nENV NODE_ENV production\n\nRUN addgroup --system --gid 1001 nodejs\nRUN adduser --system --uid 1001 nextjs\n\nCOPY --from=builder /app/public ./public\nCOPY --from=builder --chown=nextjs:nodejs /app/.next/standalone ./\nCOPY --from=builder --chown=nextjs:nodejs /app/.next/static ./.next/static\n\nUSER nextjs\nEXPOSE 3000\nCMD [\"node\", \"server.js\"]\n```\n\n```bash\n# next.config.js: output: 'standalone'\n\n# Build Docker image\ndocker build -t my-nextjs-app .\n\n# Run container\ndocker run -p 3000:3000 my-nextjs-app\n```\n\n### Static Export\n\n```javascript\n// next.config.js\nmodule.exports = {\n  output: 'export',\n}\n```\n\n```bash\n# Build static files\nnpm run build\n\n# Output in 'out' directory\n# Deploy to any static hosting\n```\n\n## Performance Optimization\n\n### Build Optimization\n\n```bash\n# Enable production profiling\nnext build --profile\n\n# Analyze bundle size\nANALYZE=true next build\n\n# Build specific routes only (debugging)\nnext build --debug-build-paths=\"/api/**\"\n```\n\n### Development Optimization\n\n```bash\n# Use Turbopack for faster HMR\nnext dev --turbopack\n\n# Increase Node.js memory\nNODE_OPTIONS='--max-old-space-size=4096' next dev\n\n# Disable telemetry for faster builds\nnext telemetry disable\n```\n\n### Code Splitting\n\n```typescript\n// Dynamic imports for code splitting\nimport dynamic from 'next/dynamic'\n\nconst DynamicComponent = dynamic(() => import('../components/Heavy'), {\n  loading: () => <p>Loading...</p>,\n  ssr: false, // Disable SSR for this component\n})\n\nexport default function Page() {\n  return <DynamicComponent />\n}\n```\n\n## TypeScript Patterns\n\n### Type Checking\n\n```bash\n# Generate route types\nnext typegen\n\n# Run TypeScript compiler\ntsc --noEmit\n\n# Combined validation\nnext typegen && tsc --noEmit\n\n# Add to package.json\n{\n  \"scripts\": {\n    \"type-check\": \"next typegen && tsc --noEmit\"\n  }\n}\n```\n\n### Typed Routes\n\n```typescript\n// Use generated types\nimport Link from 'next/link'\nimport type { Route } from 'next'\n\nexport default function Navigation() {\n  return (\n    <Link href={\"/blog/hello-world\" as Route}>\n      Blog Post\n    </Link>\n  )\n}\n```\n\n## CI/CD Patterns\n\n### CI/CD Integration\n\n```bash\n# Install dependencies\nnpm ci\n\n# Run linting\nnpm run lint\n\n# Type checking\nnpm run type-check\n\n# Build\nnpm run build\n\n# Run tests\nnpm test\n```\n\n### Environment Variables\n\n```bash\n# .env.local (development)\nDATABASE_URL=postgresql://localhost:5432/mydb\nNEXT_PUBLIC_API_URL=http://localhost:3000/api\n\n# .env.production (production)\nDATABASE_URL=${DATABASE_URL}\nNEXT_PUBLIC_API_URL=https://api.example.com\n```\n\n## Examples by Use Case\n\n### Basic Blog\n\n```bash\nnpx create-next-app@latest my-blog \\\n  --typescript \\\n  --tailwind \\\n  --app \\\n  --use-pnpm\n```\n\n### E-commerce Site\n\n```bash\nnpx create-next-app@latest my-store \\\n  --typescript \\\n  --tailwind \\\n  --app \\\n  --src-dir \\\n  --turbopack \\\n  --use-pnpm\n```\n\n### API-Only Project\n\n```bash\nnpx create-next-app@latest my-api \\\n  --typescript \\\n  --api \\\n  --no-tailwind \\\n  --use-pnpm\n```\n\n### Minimal Project\n\n```bash\nnpx create-next-app@latest my-minimal \\\n  --typescript \\\n  --empty \\\n  --no-tailwind \\\n  --no-linter \\\n  --use-pnpm\n```\n\n## Debugging Patterns\n\n### Development Debugging\n\n```bash\n# Enable Node.js inspector\nNODE_OPTIONS='--inspect' next dev\n\n# Debug with breakpoints\nNODE_OPTIONS='--inspect-brk' next dev\n\n# Verbose logging\nnext dev --debug\n\n# Debug prerender errors\nnext build --debug-prerender\n```\n\n### Production Debugging\n\n```bash\n# Enable source maps\nNEXT_SOURCE_MAPS=true next build\n\n# Verbose build output\nnext build --debug\n\n# Profile React performance\nnext build --profile\n```\n",
        "plugins/dev/skills/nextjs-cli/reference/troubleshooting.md": "# Next.js Troubleshooting Guide\n\nCommon issues and solutions for Next.js applications.\n\n## Development Server Issues\n\n### Port Already in Use\n\n**Symptom:** Error: \"Port 3000 is already in use\"\n\n**Diagnosis:**\n```bash\n# Check which process is using port 3000\nlsof -ti:3000\n\n# Or on Windows\nnetstat -ano | findstr :3000\n```\n\n**Solutions:**\n```bash\n# Use different port\nnext dev -p 3001\n\n# Kill process on port 3000\nlsof -ti:3000 | xargs kill -9\n\n# Or set in package.json\n{\n  \"scripts\": {\n    \"dev\": \"next dev -p 3001\"\n  }\n}\n```\n\n### Hot Module Reloading Not Working\n\n**Symptom:** Changes not reflected in browser\n\n**Solutions:**\n```bash\n# Clear Next.js cache\nrm -rf .next\n\n# Restart dev server\nnext dev\n\n# Use Turbopack (faster HMR)\nnext dev --turbopack\n\n# Check file watchers limit (Linux/Mac)\n# Add to ~/.bashrc or ~/.zshrc:\necho fs.inotify.max_user_watches=524288 | sudo tee -a /etc/sysctl.conf\nsudo sysctl -p\n```\n\n### Module Not Found Errors\n\n**Symptom:** Error: \"Module not found: Can't resolve 'X'\"\n\n**Solutions:**\n```bash\n# Clear node_modules and reinstall\nrm -rf node_modules package-lock.json\nnpm install\n\n# Clear Next.js cache\nrm -rf .next\n\n# Check import paths (case-sensitive)\n# Use configured import alias\nimport { Component } from '@/components/Component'\n```\n\n## Build Issues\n\n### Build Fails with Memory Error\n\n**Symptom:** \"FATAL ERROR: Reached heap limit Allocation failed - JavaScript heap out of memory\"\n\n**Solutions:**\n```bash\n# Increase Node.js memory limit\nNODE_OPTIONS='--max-old-space-size=4096' next build\n\n# Add to package.json\n{\n  \"scripts\": {\n    \"build\": \"NODE_OPTIONS='--max-old-space-size=4096' next build\"\n  }\n}\n\n# Use Turbopack (more memory efficient)\nnext dev --turbopack\n```\n\n### Build Fails with ESLint Errors\n\n**Symptom:** Build stops due to linting errors\n\n**Solutions:**\n```bash\n# Fix linting issues\nnext lint --fix\n\n# Temporarily skip linting during build\nnext build --no-lint\n\n# Configure ESLint to be less strict\n# .eslintrc.json\n{\n  \"extends\": \"next/core-web-vitals\",\n  \"rules\": {\n    \"@next/next/no-html-link-for-pages\": \"off\"\n  }\n}\n```\n\n### Build Fails with TypeScript Errors\n\n**Symptom:** Type check failed\n\n**Diagnosis:**\n```bash\n# Check TypeScript errors\ntsc --noEmit\n\n# Generate route types\nnext typegen\n```\n\n**Solutions:**\n```bash\n# Fix TypeScript errors\ntsc --noEmit\n\n# Temporarily skip type checking (NOT recommended)\n# next.config.js\nmodule.exports = {\n  typescript: {\n    ignoreBuildErrors: true,\n  },\n}\n\n# Update TypeScript and types\nnpm install -D typescript @types/react @types/node\n```\n\n## Runtime Issues\n\n### Hydration Errors\n\n**Symptom:** \"Text content does not match server-rendered HTML\" or \"Hydration failed\"\n\n**Common Causes:**\n1. Different content between server and client\n2. Invalid HTML nesting (e.g., `<p>` inside `<p>`)\n3. Browser extensions modifying DOM\n4. Using `window` or `document` in Server Components\n\n**Solutions:**\n```typescript\n// Use client component for dynamic content\n'use client'\n\nimport { useState, useEffect } from 'react'\n\nexport default function ClientOnly() {\n  const [mounted, setMounted] = useState(false)\n\n  useEffect(() => {\n    setMounted(true)\n  }, [])\n\n  if (!mounted) return null\n\n  return <div>{/* Client-only content */}</div>\n}\n\n// Or use suppressHydrationWarning (sparingly)\n<div suppressHydrationWarning>\n  {new Date().toLocaleDateString()}\n</div>\n```\n\n### Data Fetching Errors\n\n**Symptom:** API requests failing or data not loading\n\n**Solutions:**\n```typescript\n// Server Component (recommended)\nasync function getData() {\n  try {\n    const res = await fetch('https://api.example.com/data', {\n      next: { revalidate: 60 }\n    })\n\n    if (!res.ok) {\n      throw new Error('Failed to fetch data')\n    }\n\n    return res.json()\n  } catch (error) {\n    console.error('Error fetching data:', error)\n    return { error: 'Failed to load data' }\n  }\n}\n\n// Client Component with error handling\n'use client'\n\nimport { useState, useEffect } from 'react'\n\nexport default function ClientData() {\n  const [data, setData] = useState(null)\n  const [error, setError] = useState(null)\n\n  useEffect(() => {\n    fetch('/api/data')\n      .then(res => res.json())\n      .then(setData)\n      .catch(setError)\n  }, [])\n\n  if (error) return <div>Error: {error.message}</div>\n  if (!data) return <div>Loading...</div>\n\n  return <div>{/* Render data */}</div>\n}\n```\n\n### API Route Issues\n\n**Symptom:** API routes returning 404 or incorrect responses\n\n**Solutions:**\n```typescript\n// Check file structure\n// app/api/users/route.ts (correct)\n// app/api/users.ts (incorrect)\n\n// Ensure proper HTTP methods\nimport { NextResponse } from 'next/server'\n\nexport async function GET(request: Request) {\n  return NextResponse.json({ message: 'GET request' })\n}\n\nexport async function POST(request: Request) {\n  const body = await request.json()\n  return NextResponse.json({ message: 'POST request', body })\n}\n\n// Enable CORS if needed\nexport async function GET(request: Request) {\n  const response = NextResponse.json({ data: 'value' })\n  response.headers.set('Access-Control-Allow-Origin', '*')\n  return response\n}\n```\n\n## Routing Issues\n\n### 404 on Dynamic Routes\n\n**Symptom:** Dynamic routes returning 404\n\n**Solutions:**\n```bash\n# Check file structure\napp/\nâ””â”€â”€ blog/\n    â””â”€â”€ [slug]/\n        â””â”€â”€ page.tsx  # Must be named page.tsx\n\n# Ensure params are properly typed\nexport default function BlogPost({\n  params\n}: {\n  params: { slug: string }\n}) {\n  return <h1>{params.slug}</h1>\n}\n\n# For static generation\nexport async function generateStaticParams() {\n  return [\n    { slug: 'post-1' },\n    { slug: 'post-2' },\n  ]\n}\n```\n\n### Redirects Not Working\n\n**Symptom:** Redirects defined in next.config.js not working\n\n**Solutions:**\n```javascript\n// next.config.js\nmodule.exports = {\n  async redirects() {\n    return [\n      {\n        source: '/old-page',\n        destination: '/new-page',\n        permanent: true, // 301 redirect\n      },\n      {\n        source: '/blog/:slug',\n        destination: '/posts/:slug',\n        permanent: false, // 302 redirect\n      },\n    ]\n  },\n}\n\n// Restart dev server after changes\n# Clear cache and rebuild\nrm -rf .next\nnext dev\n```\n\n## Image Optimization Issues\n\n### Image Not Loading\n\n**Symptom:** Next.js Image component not displaying images\n\n**Solutions:**\n```typescript\n// Add domain to next.config.js\nmodule.exports = {\n  images: {\n    domains: ['example.com', 'cdn.example.com'],\n    // Or use remotePatterns (recommended)\n    remotePatterns: [\n      {\n        protocol: 'https',\n        hostname: '**.example.com',\n      },\n    ],\n  },\n}\n\n// Use correct Image component\nimport Image from 'next/image'\n\nexport default function Page() {\n  return (\n    <Image\n      src=\"/image.jpg\"\n      alt=\"Description\"\n      width={500}\n      height={300}\n      // Or use fill for responsive\n      fill\n      style={{ objectFit: 'cover' }}\n    />\n  )\n}\n```\n\n## Performance Issues\n\n### Slow Build Times\n\n**Diagnosis:**\n```bash\n# Check build output\nnext build --debug\n\n# Check bundle size\nnext build --profile\n```\n\n**Solutions:**\n```bash\n# Use Turbopack\nnext dev --turbopack\n\n# Enable SWC minification (default in Next.js 13+)\n# next.config.js\nmodule.exports = {\n  swcMinify: true,\n}\n\n# Reduce build scope\nnext build --debug-build-paths=\"/blog/**\"\n\n# Increase memory\nNODE_OPTIONS='--max-old-space-size=8192' next build\n```\n\n### Large Bundle Size\n\n**Diagnosis:**\n```bash\n# Analyze bundle\nANALYZE=true next build\n\n# Install bundle analyzer\nnpm install --save-dev @next/bundle-analyzer\n```\n\n**Solutions:**\n```typescript\n// Use dynamic imports\nimport dynamic from 'next/dynamic'\n\nconst HeavyComponent = dynamic(() => import('./HeavyComponent'), {\n  ssr: false,\n  loading: () => <p>Loading...</p>\n})\n\n// Use tree shaking\n// Import only what you need\nimport { specific } from 'library' // Good\nimport * as library from 'library' // Bad\n\n// Optimize images\nimport Image from 'next/image'\n\n// Configure bundle size limits\n// next.config.js\nmodule.exports = {\n  onDemandEntries: {\n    maxInactiveAge: 25 * 1000,\n    pagesBufferLength: 2,\n  },\n}\n```\n\n## Deployment Issues\n\n### Environment Variables Not Working\n\n**Symptom:** Environment variables undefined in production\n\n**Solutions:**\n```bash\n# Check environment variables\nnext info\n\n# Ensure proper naming\nNEXT_PUBLIC_API_URL=https://api.example.com  # Client-side\nDATABASE_URL=postgresql://...                 # Server-side only\n\n# Restart after .env changes\n# Environment variables are loaded at build time\nnpm run build\nnpm run start\n\n# For Vercel\n# Add environment variables in Vercel dashboard\n# Project Settings > Environment Variables\n```\n\n### Build Works Locally But Fails in Production\n\n**Solutions:**\n```bash\n# Test production build locally\nnpm run build\nnpm run start\n\n# Check Node.js version\nnode --version\n# Ensure it matches production environment\n\n# Check for case-sensitive imports\n# Linux/production is case-sensitive\nimport Component from './Component'  # Not './component'\n\n# Check for missing dependencies\nnpm ci  # Clean install\n```\n\n## System Issues\n\n### Clear Next.js Cache\n\n```bash\n# Clear Next.js cache\nrm -rf .next\n\n# Clear node_modules and reinstall\nrm -rf node_modules package-lock.json\nnpm install\n\n# Clear npm cache\nnpm cache clean --force\n\n# Verify system info\nnext info\n```\n\n### Debugging Tools\n\n```bash\n# Enable verbose logging\nnext dev --debug\n\n# Enable Node.js inspector\nNODE_OPTIONS='--inspect' next dev\n\n# Debug with breakpoints\nNODE_OPTIONS='--inspect-brk' next dev\n\n# Profile React performance\nnext build --profile\n\n# Debug prerender errors\nnext build --debug-prerender\n```\n\n## Common Error Messages\n\n### \"Error: Text content does not match server-rendered HTML\"\n\n**Cause:** Hydration mismatch between server and client\n\n**Solution:** Use `useEffect` for client-only rendering or `suppressHydrationWarning`\n\n### \"Error: Hydration failed because the initial UI does not match\"\n\n**Cause:** Different HTML structure between server and client\n\n**Solution:** Ensure consistent rendering or use client components\n\n### \"Error: Objects are not valid as a React child\"\n\n**Cause:** Trying to render an object directly\n\n**Solution:** Convert object to string or render specific properties\n\n```typescript\n// Bad\n<div>{user}</div>\n\n// Good\n<div>{user.name}</div>\n<div>{JSON.stringify(user)}</div>\n```\n\n### \"Error: Failed to compile\"\n\n**Cause:** Syntax error or missing dependency\n\n**Solution:** Check error message for specific line and fix syntax\n\n### \"Error: Maximum update depth exceeded\"\n\n**Cause:** Infinite render loop\n\n**Solution:** Check `useEffect` dependencies and state updates\n\n```typescript\n// Bad - infinite loop\nuseEffect(() => {\n  setCount(count + 1)\n})\n\n// Good - with dependency\nuseEffect(() => {\n  // Run once on mount\n}, [])\n```\n",
        "plugins/dev/skills/playwright-cli/SKILL.md": "---\nname: playwright-cli\ndescription: Playwright CLI expert for E2E testing and browser automation. Use when users need to record tests, debug issues, generate reports, or test across multiple browsers and devices.\nallowed-tools: Bash(npx playwright:*), Bash(bunx playwright:*)\n---\n\n# Playwright CLI Guide\n\nPlaywright is a testing framework for automating browser interactions across multiple browsers (Chrome, Firefox, WebKit) and devices. This guide provides essential workflows and quick references for test execution, debugging, and debugging.\n\n## Quick Start\n\n```bash\n# Install Playwright\nnpm install -D @playwright/test\n\n# Install browsers\nnpx playwright install\n\n# Run your first tests\nnpx playwright test\n\n# Run with visible browser\nnpx playwright test --headed\n\n# Debug with Inspector UI\nnpx playwright test --debug\n\n# View test report\nnpx playwright show-report\n```\n\n## Common Workflows\n\n### Workflow 1: Record and Test\n\n```bash\n# Record interaction with website\nnpx playwright codegen https://example.com -o tests/recorded.spec.ts\n\n# Run the recorded test\nnpx playwright test tests/recorded.spec.ts\n\n# Run with browser visible\nnpx playwright test tests/recorded.spec.ts --headed\n\n# Update and verify\nnpx playwright test tests/recorded.spec.ts --debug\n```\n\n### Workflow 2: Debug Failing Test\n\n```bash\n# Run failing test with browser visible\nnpx playwright test -g \"test name\" --headed\n\n# Open debugger Inspector\nnpx playwright test -g \"test name\" --debug\n\n# Capture screenshot for inspection\nnpx playwright test --screenshot=on\n\n# Record trace for detailed analysis\nnpx playwright test --trace on\nnpx playwright show-trace trace.zip\n```\n\n### Workflow 3: Test Across Browsers\n\n```bash\n# Run on all configured browsers\nnpx playwright test\n\n# Run on specific browser\nnpx playwright test --project=chromium\nnpx playwright test --project=firefox\nnpx playwright test --project=webkit\n\n# Run on mobile devices\nnpx playwright test --project=\"iPhone 12\"\nnpx playwright test --project=\"Pixel 5\"\n```\n\n### Workflow 4: Generate Comprehensive Report\n\n```bash\n# Run tests with multiple reports\nnpx playwright test --reporter=html --reporter=json --reporter=verbose\n\n# View HTML report\nnpx playwright show-report\n\n# Generate CI-compatible reports\nnpx playwright test --reporter=github --reporter=json --retries=2\n```\n\n### Workflow 5: Performance Testing\n\n```bash\n# Run sequentially for consistent timing\nnpx playwright test --workers=1\n\n# With extended timeout\nnpx playwright test --workers=1 --timeout=30000\n\n# Record traces for analysis\nnpx playwright test --workers=1 --trace on\n\n# View performance insights\nnpx playwright show-trace trace.zip\n```\n\n## Decision Tree\n\n**When to use which command:**\n\n- **To record test interactions**: Use `npx playwright codegen URL`\n- **To run tests**: Use `npx playwright test` (all) or `npx playwright test -g \"pattern\"` (specific)\n- **To debug**: Use `npx playwright test --debug` (Inspector) or `--headed` (visible browser)\n- **To test across browsers**: Use `--project=chromium`, `--project=firefox`, or `--project=webkit`\n- **To capture media**: Use `--screenshot=on` or `--video=on`\n- **To analyze failures**: Use `--trace on` or `--reporter=html`\n- **To handle flaky tests**: Use `--retries=3` or run with `--workers=1`\n- **For exact command syntax**: See [Commands Reference](./reference/commands-reference.md)\n- **For complex workflows**: See [Common Patterns](./reference/common-patterns.md)\n- **For troubleshooting**: See [Troubleshooting Guide](./reference/troubleshooting.md)\n\n## Common Patterns\n\n### Browser & Device Targeting\n\n```bash\n# Run on specific browser\nnpx playwright test --project=chromium\n\n# Run on multiple browsers\nnpx playwright test --project=chromium --project=firefox\n\n# Run on mobile\nnpx playwright test --project=\"iPhone 12\" --project=\"Pixel 5\"\n\n# Override base URL for environment\nnpx playwright test --base-url=https://staging.example.com\n```\n\n### Debugging & Inspection\n\n```bash\n# Visual debugging with browser visible\nnpx playwright test --headed --workers=1\n\n# Interactive debugging with Inspector\nnpx playwright test --debug\n\n# Detailed trace recording\nnpx playwright test --trace on\nnpx playwright show-trace trace.zip\n\n# Full debugging output\nnpx playwright test --reporter=verbose --headed --debug\n```\n\n### Artifacts & Reports\n\n```bash\n# Screenshots on failure\nnpx playwright test --screenshot=only-on-failure\n\n# Always record videos\nnpx playwright test --video=on\n\n# Multiple report formats\nnpx playwright test --reporter=html --reporter=json --reporter=junit\n\n# View HTML report\nnpx playwright show-report\n```\n\n### Performance & Reliability\n\n```bash\n# Parallel execution (faster)\nnpx playwright test --workers=4\n\n# Sequential execution (deterministic)\nnpx playwright test --workers=1\n\n# Retry flaky tests\nnpx playwright test --retries=2\n\n# Extended timeout for slow networks\nnpx playwright test --timeout=30000\n```\n\n## Troubleshooting\n\n**Common Issues:**\n\n1. **Browser won't start**\n   - Solution: Reinstall with `npx playwright install --with-deps`\n   - See: [Browser Launch Issues](./reference/troubleshooting.md#browser-launch-issues)\n\n2. **Tests time out**\n   - Solution: Increase timeout with `npx playwright test --timeout=30000`\n   - See: [Tests Timeout](./reference/troubleshooting.md#tests-timeout)\n\n3. **Tests are flaky**\n   - Solution: Run with `npx playwright test --retries=3` or `--workers=1`\n   - See: [Tests Are Flaky](./reference/troubleshooting.md#tests-are-flaky)\n\n4. **Page won't load**\n   - Solution: Verify base URL and check server is running\n   - See: [Page Won't Load](./reference/troubleshooting.md#page-wont-load)\n\n5. **Element not found**\n   - Solution: Use robust selectors like `getByRole()` or `getByTestId()`\n   - See: [Element Not Found](./reference/troubleshooting.md#element-not-found)\n\nFor detailed troubleshooting steps, see the [Troubleshooting Guide](./reference/troubleshooting.md).\n\n## Reference Files\n\n**Load as needed for detailed information:**\n\n- **[Commands Reference](./reference/commands-reference.md)** - Complete CLI command documentation with all flags and options. Use when you need exact syntax, flag combinations, or comprehensive command information.\n\n- **[Common Patterns](./reference/common-patterns.md)** - Real-world patterns and workflows for development, cross-browser testing, mobile devices, visual testing, CI/CD, performance testing, and debugging. Use for implementing specific workflows or integrations.\n\n- **[Troubleshooting Guide](./reference/troubleshooting.md)** - Detailed error messages, diagnosis steps, and resolution strategies for installation, browser issues, test failures, selectors, reports, CI/CD, and debugging techniques. Use when encountering errors or unexpected behavior.\n\n**When to use each reference:**\n\n- Use **Commands Reference** when you need exact command syntax, all available flags, or options for any Playwright CLI command\n- Use **Common Patterns** for implementing test workflows, cross-browser testing, mobile testing, CI/CD pipelines, or performance testing\n- Use **Troubleshooting** when browsers won't start, tests timeout, elements aren't found, or you need debugging strategies\n\n## Resources\n\n- Official Docs: https://playwright.dev\n- Test Generator: `npx playwright codegen`\n- Locator Inspector: `npx playwright test --debug`\n- Community: https://github.com/microsoft/playwright\n- API Reference: https://playwright.dev/docs/api/class-playwright\n",
        "plugins/dev/skills/playwright-cli/reference/commands-reference.md": "# Playwright CLI Commands Reference\n\nComplete reference for all Playwright CLI commands with detailed options and flags.\n\n## Installation & Setup\n\n### `npx playwright install`\n\nInstall browsers and dependencies.\n\n```bash\n# Install all supported browsers (Chrome, Firefox, WebKit)\nnpx playwright install\n\n# Install specific browser\nnpx playwright install chromium\nnpx playwright install firefox\nnpx playwright install webkit\n\n# Install multiple browsers\nnpx playwright install chromium firefox webkit\n\n# Install system dependencies\nnpx playwright install-deps\n\n# Install specific browser dependencies\nnpx playwright install-deps chromium\n\n# Show installation help\nnpx playwright install --help\n```\n\n## Test Execution\n\n### `npx playwright test`\n\nRun test suite.\n\n```bash\n# Run all tests\nnpx playwright test\n\n# Run specific test file\nnpx playwright test tests/login.spec.ts\n\n# Run tests matching pattern\nnpx playwright test -g \"login\"\n\n# Run exact test by name\nnpx playwright test -g \"^should log in successfully$\"\n\n# Run tests in directory\nnpx playwright test tests/e2e/\n\n# Skip tests matching pattern\nnpx playwright test --grep-invert \"skip-in-ci\"\n\n# List tests without running\nnpx playwright test --list\n\n# List tests matching pattern\nnpx playwright test --list -g \"login\"\n```\n\n### Browser & Project Selection\n\n```bash\n# Run on specific browser\nnpx playwright test --project=chromium\nnpx playwright test --project=firefox\nnpx playwright test --project=webkit\n\n# Run on multiple browsers\nnpx playwright test --project=chromium --project=firefox\n\n# Run on all configured browsers (default)\nnpx playwright test\n\n# Run on mobile device\nnpx playwright test --project=\"Pixel 5\"\nnpx playwright test --project=\"iPhone 12\"\n```\n\n## Recording & Debugging\n\n### `npx playwright codegen`\n\nRecord test scripts by interacting with browser.\n\n```bash\n# Record to specified file\nnpx playwright codegen https://example.com -o tests/new.spec.ts\n\n# Record with specific browser\nnpx playwright codegen --browser chromium https://example.com\nnpx playwright codegen --browser firefox https://example.com\nnpx playwright codegen --browser webkit https://example.com\n\n# Record with all browsers\nnpx playwright codegen --browser chromium --browser firefox --browser webkit https://example.com\n```\n\n### `npx playwright test --debug`\n\nDebug tests with Playwright Inspector.\n\n```bash\n# Run all tests in debug mode\nnpx playwright test --debug\n\n# Debug specific test file\nnpx playwright test tests/login.spec.ts --debug\n\n# Debug specific test\nnpx playwright test -g \"test name\" --debug\n\n# Debug with visible browser\nnpx playwright test --debug --headed\n```\n\n## Execution Modes\n\n### `npx playwright test --headed`\n\nRun tests with visible browser.\n\n```bash\n# Run with browser visible\nnpx playwright test --headed\n\n# Run specific browser visible\nnpx playwright test --headed --project=chromium\n\n# Run with visible browser and sequential execution\nnpx playwright test --headed --workers=1\n```\n\n### `npx playwright test --trace`\n\nRecord test execution traces.\n\n```bash\n# Enable tracing on all tests\nnpx playwright test --trace on\n\n# Trace only on first retry\nnpx playwright test --trace on-first-retry\n\n# Trace only on failure\nnpx playwright test --trace retain-on-failure\n\n# Disable tracing\nnpx playwright test --trace off\n```\n\n### View Traces\n\n```bash\n# Open trace viewer\nnpx playwright show-trace trace.zip\n\n# Traces saved in test-results/*/trace.zip\n```\n\n## Screenshots & Videos\n\n### `npx playwright test --screenshot`\n\nCapture screenshots.\n\n```bash\n# Screenshot only on failure\nnpx playwright test --screenshot=only-on-failure\n\n# Always take screenshots\nnpx playwright test --screenshot=on\n\n# No screenshots (default)\nnpx playwright test --screenshot=off\n```\n\n### `npx playwright test --video`\n\nRecord videos.\n\n```bash\n# Record videos only on failure\nnpx playwright test --video=retain-on-failure\n\n# Always record videos\nnpx playwright test --video=on\n\n# No videos (default)\nnpx playwright test --video=off\n```\n\n## Parallel Execution & Retries\n\n### Performance Options\n\n```bash\n# Run with multiple workers (parallel)\nnpx playwright test --workers=4\nnpx playwright test --workers=8\n\n# Single worker (sequential)\nnpx playwright test --workers=1\n\n# Use all available cores\nnpx playwright test --workers=auto\n\n# Retry failed tests\nnpx playwright test --retries=3\nnpx playwright test --retries=0  # No retries\n\n# Stop after X failures\nnpx playwright test --max-failures=5\n```\n\n## Test Configuration\n\n### Custom Config\n\n```bash\n# Use specific config file\nnpx playwright test --config=playwright-ci.config.ts\n\n# Set test directory\nnpx playwright test ./e2e/\n\n# Base URL for all tests\nnpx playwright test --base-url=http://localhost:3000\nnpx playwright test --base-url=https://staging.example.com\n\n# Set test timeout\nnpx playwright test --timeout=10000\nnpx playwright test --timeout=30000\n\n# Update visual snapshots\nnpx playwright test --update-snapshots\n```\n\n## Reporting\n\n### `npx playwright test --reporter`\n\nGenerate test reports.\n\n```bash\n# Verbose reporter\nnpx playwright test --reporter=verbose\n\n# HTML report\nnpx playwright test --reporter=html\n\n# JSON report\nnpx playwright test --reporter=json > results.json\n\n# JUnit XML report\nnpx playwright test --reporter=junit\n\n# GitHub Actions reporter\nnpx playwright test --reporter=github\n\n# Line reporter (minimal)\nnpx playwright test --reporter=line\n\n# Combine multiple reporters\nnpx playwright test --reporter=verbose --reporter=html --reporter=json\n```\n\n### View Reports\n\n```bash\n# Open HTML report\nnpx playwright show-report\n\n# Open specific report\nnpx playwright show-report path/to/report\n```\n\n## System Information\n\n### `npx playwright --version`\n\nShow version information.\n\n```bash\n# Show Playwright version\nnpx playwright --version\n\n# Show help for commands\nnpx playwright test --help\nnpx playwright codegen --help\nnpx playwright show-report --help\n```\n\n## Environment & Logging\n\n### Verbosity Options\n\n```bash\n# Verbose output\nnpx playwright test --reporter=verbose\n\n# Quiet output\nnpx playwright test --quiet\n\n# Enable debug output\nPWDEBUG=1 npx playwright test\n```\n\n### Browser Context Options (via config)\n\nConfigure in `playwright.config.ts`:\n\n```typescript\nuse: {\n  locale: 'fr-FR',           // Set locale\n  timezoneId: 'Europe/Paris', // Set timezone\n  geolocation: { latitude: 48.8566, longitude: 2.3522 }, // Geolocation\n  permissions: ['camera'],    // Permissions\n  viewport: { width: 1280, height: 720 }, // Viewport size\n}\n```\n\n## Common Command Combinations\n\n```bash\n# Full debugging workflow\nnpx playwright test -g \"login\" --headed --debug --reporter=verbose\n\n# CI/CD pipeline run\nnpx playwright test --reporter=json --reporter=html --retries=2 --workers=1\n\n# Development run with videos and screenshots\nnpx playwright test --video=on --screenshot=on --reporter=html\n\n# Performance testing\nnpx playwright test --workers=1 --timeout=30000 --reporter=verbose\n\n# Test specific file with all debugging\nnpx playwright test tests/auth.spec.ts --headed --debug --reporter=verbose --trace on\n```\n",
        "plugins/dev/skills/playwright-cli/reference/common-patterns.md": "# Playwright Common Patterns\n\nReal-world patterns and workflows for common Playwright testing scenarios.\n\n## Development Workflow\n\n### Basic Test Development\n\n```bash\n# Run tests with browser visible for debugging\nnpx playwright test --headed\n\n# Run specific test file with browser visible\nnpx playwright test tests/login.spec.ts --headed\n\n# Run tests matching pattern with debug mode\nnpx playwright test -g \"login\" --headed --debug\n\n# Watch for changes and rerun (requires plugins)\nnpm run test -- --watch\n```\n\n### Record and Generate Tests\n\n```bash\n# Record interaction with website\nnpx playwright codegen https://example.com -o tests/recorded.spec.ts\n\n# Record with specific browser\nnpx playwright codegen --browser chromium https://example.com -o tests/chrome-test.spec.ts\n\n# Record with Firefox\nnpx playwright codegen --browser firefox https://example.com -o tests/firefox-test.spec.ts\n\n# Interactive recording workflow\nnpx playwright codegen https://example.com\n# Then: interact with page, export as test file\n```\n\n## Test Organization Patterns\n\n### Directory Structure\n\n```bash\ntests/\nâ”œâ”€â”€ fixtures/              # Shared test data and utilities\nâ”‚   â”œâ”€â”€ test-data.ts\nâ”‚   â””â”€â”€ test-helpers.ts\nâ”œâ”€â”€ auth/\nâ”‚   â””â”€â”€ login.spec.ts\nâ”œâ”€â”€ e2e/\nâ”‚   â”œâ”€â”€ checkout.spec.ts\nâ”‚   â””â”€â”€ payment.spec.ts\nâ”œâ”€â”€ api/\nâ”‚   â””â”€â”€ endpoints.spec.ts\nâ””â”€â”€ performance/\n    â””â”€â”€ load.spec.ts\n```\n\n### Run by Category\n\n```bash\n# Run all E2E tests\nnpx playwright test tests/e2e/\n\n# Run authentication tests\nnpx playwright test tests/auth/\n\n# Run API tests\nnpx playwright test tests/api/\n\n# Run performance tests\nnpx playwright test tests/performance/\n```\n\n## Cross-Browser Testing\n\n### Test All Browsers\n\n```bash\n# Run on all configured browsers (default)\nnpx playwright test\n\n# Run on specific browsers\nnpx playwright test --project=chromium --project=firefox --project=webkit\n\n# Run on all browsers with verbose output\nnpx playwright test --reporter=verbose\n```\n\n### Browser-Specific Tests\n\n```bash\n# Run only Chrome tests\nnpx playwright test --project=chromium\n\n# Run only Firefox tests\nnpx playwright test --project=firefox\n\n# Run only WebKit tests\nnpx playwright test --project=webkit\n\n# Skip tests on specific browser (in test code)\ntest.skip(browserName === 'firefox', 'Skip on Firefox');\n```\n\n## Mobile & Device Testing\n\n### Test on Mobile Devices\n\n```bash\n# Run on iOS (iPhone)\nnpx playwright test --project=\"iPhone 12\"\n\n# Run on Android (Pixel)\nnpx playwright test --project=\"Pixel 5\"\n\n# Test multiple devices\nnpx playwright test --project=\"iPhone 12\" --project=\"Pixel 5\"\n\n# List available devices\nnpx playwright test --list | grep \"Device\"\n```\n\n### Device-Specific Configuration\n\nConfigure in `playwright.config.ts`:\n\n```typescript\nprojects: [\n  {\n    name: 'chromium',\n    use: { ...devices['Desktop Chrome'] },\n  },\n  {\n    name: 'mobile-safari',\n    use: { ...devices['iPhone 12'] },\n  },\n  {\n    name: 'mobile-android',\n    use: { ...devices['Pixel 5'] },\n  },\n],\n```\n\n## Visual & Artifact Capture\n\n### Screenshot Strategies\n\n```bash\n# Capture only on failure\nnpx playwright test --screenshot=only-on-failure\n\n# Always capture screenshots\nnpx playwright test --screenshot=on\n\n# Generate HTML report with screenshots\nnpx playwright test --screenshot=on --reporter=html\n\n# Combined with videos\nnpx playwright test --screenshot=on --video=on --reporter=html\n```\n\n### Video Recording\n\n```bash\n# Record video on failure\nnpx playwright test --video=retain-on-failure\n\n# Record all tests\nnpx playwright test --video=on\n\n# Combined screenshot and video\nnpx playwright test --video=on --screenshot=on --reporter=html\n```\n\n### Trace Recording\n\n```bash\n# Full trace on all tests\nnpx playwright test --trace on\n\n# Trace on failure only\nnpx playwright test --trace retain-on-failure\n\n# Trace with video (maximum debugging info)\nnpx playwright test --trace on --video=on\n```\n\n## Debugging Patterns\n\n### Interactive Debugging\n\n```bash\n# Debug with Inspector UI\nnpx playwright test --debug\n\n# Debug specific test\nnpx playwright test -g \"should create account\" --debug\n\n# Debug with visible browser\nnpx playwright test --debug --headed\n\n# Sequential execution with debug\nnpx playwright test --debug --workers=1\n```\n\n### Logging & Inspection\n\n```bash\n# Verbose output for debugging\nnpx playwright test --reporter=verbose\n\n# Debug environment variable\nPWDEBUG=1 npx playwright test\n\n# Combine verbose reporter with debug\nnpx playwright test --reporter=verbose --debug\n\n# Detailed trace analysis\nnpx playwright test --trace on\nnpx playwright show-trace trace.zip\n```\n\n## Performance & Optimization\n\n### Performance Testing\n\n```bash\n# Single-threaded for consistent timing\nnpx playwright test --workers=1\n\n# Increased timeout for slow environments\nnpx playwright test --timeout=30000\n\n# Performance test workflow\nnpx playwright test tests/performance/ --workers=1 --timeout=30000 --reporter=verbose\n```\n\n### Parallel Execution\n\n```bash\n# Run with maximum parallelization\nnpx playwright test --workers=8\n\n# Use all available cores\nnpx playwright test --workers=auto\n\n# Reduce parallelization to prevent race conditions\nnpx playwright test --workers=2\n\n# Monitor execution with verbose reporter\nnpx playwright test --workers=4 --reporter=verbose\n```\n\n## Flaky Test Management\n\n### Retry Strategy\n\n```bash\n# Retry failed tests once\nnpx playwright test --retries=1\n\n# Retry failed tests three times\nnpx playwright test --retries=3\n\n# No retries (strict mode)\nnpx playwright test --retries=0\n\n# Stop after first failure\nnpx playwright test --max-failures=1\n```\n\n### Debugging Flaky Tests\n\n```bash\n# Run flaky tests with debug mode\nnpx playwright test -g \"flaky-test\" --debug --headed --retries=3\n\n# Run with traces to analyze failures\nnpx playwright test -g \"flaky-test\" --trace retain-on-failure\n\n# Run sequentially to eliminate race conditions\nnpx playwright test -g \"flaky-test\" --workers=1\n\n# Run with verbose reporting\nnpx playwright test -g \"flaky-test\" --reporter=verbose --retries=3\n```\n\n## CI/CD Integration Patterns\n\n### GitHub Actions Workflow\n\n```bash\n# Standard CI run\nnpx playwright test --reporter=github\n\n# With retries and JSON report\nnpx playwright test --reporter=github --reporter=json > results.json --retries=2\n\n# Full CI configuration\nnpx playwright test --reporter=html --reporter=json --reporter=github --retries=2 --workers=1\n```\n\n### CI/CD Best Practices\n\n```bash\n# Single worker (deterministic)\nnpx playwright test --workers=1\n\n# Generate all reports\nnpx playwright test --reporter=html --reporter=json --reporter=junit\n\n# Timeout appropriate for CI environment\nnpx playwright test --timeout=30000\n\n# Full workflow\nnpx playwright test \\\n  --workers=1 \\\n  --retries=2 \\\n  --timeout=30000 \\\n  --reporter=html \\\n  --reporter=json \\\n  --reporter=github\n```\n\n## Configuration Patterns\n\n### Test Configuration by Environment\n\n```bash\n# Development\nnpx playwright test --headed --workers=1\n\n# Staging\nnpx playwright test --base-url=https://staging.example.com --reporter=html\n\n# Production (read-only)\nnpx playwright test --base-url=https://example.com --reporter=json\n\n# Local development\nnpx playwright test --base-url=http://localhost:3000 --headed\n```\n\n### Dynamic Configuration\n\n```bash\n# Override base URL\nnpx playwright test --base-url=http://localhost:3000\n\n# Update test snapshots\nnpx playwright test --update-snapshots\n\n# Timezone testing\n# Set in config: use: { timezoneId: 'Europe/Paris' }\nnpx playwright test\n\n# Locale testing\n# Set in config: use: { locale: 'fr-FR' }\nnpx playwright test\n```\n\n## Snapshot Testing\n\n### Visual Regression Testing\n\n```bash\n# Compare against snapshots\nnpx playwright test\n\n# Update snapshots\nnpx playwright test --update-snapshots\n\n# Update specific test snapshots\nnpx playwright test -g \"button\" --update-snapshots\n\n# Review changed snapshots\nnpx playwright test --reporter=html\nnpx playwright show-report\n```\n\n## Continuous Testing\n\n### Watch Mode (if configured)\n\n```bash\n# Watch tests (requires configuration)\nnpm run test -- --watch\n\n# Run specific test in watch mode\nnpm run test -- -g \"login\" --watch\n```\n\n### Incremental Testing\n\n```bash\n# Run recently changed tests\nnpx playwright test --only-changed\n\n# Run failed tests from last run\nnpx playwright test --failed\n```\n\n## Report Analysis\n\n### Generate Comprehensive Reports\n\n```bash\n# All report formats\nnpx playwright test \\\n  --reporter=html \\\n  --reporter=json \\\n  --reporter=junit \\\n  --reporter=verbose\n\n# View reports\nnpx playwright show-report\n\n# JSON for parsing/analysis\nnpx playwright test --reporter=json > results.json\n# Parse with: cat results.json | jq .\n```\n\n## Authentication & Data Setup\n\n### Test Data Management\n\n```bash\n# Run setup tests first\nnpx playwright test --project=setup\n\n# Then run actual tests\nnpx playwright test --project=chromium\n\n# Complete auth setup workflow\nnpx playwright test tests/auth/ --workers=1\nnpx playwright test tests/e2e/ --workers=2\n```\n\n### State Management\n\n```bash\n# Tests run in isolation\nnpx playwright test\n\n# Clear state between tests\n# (Configured in playwright.config.ts)\n\n# Preserve state for debugging\nnpx playwright test --headed --workers=1\n```\n",
        "plugins/dev/skills/playwright-cli/reference/troubleshooting.md": "# Playwright Troubleshooting Guide\n\nCommon issues and solutions for Playwright testing problems.\n\n## Installation & Setup Issues\n\n### Browsers Not Installed\n\n**Symptom:** Tests fail with \"browser not found\" error\n\n**Diagnosis:**\n\n```bash\n# Check installed browsers\nnpx playwright install --help\n\n# Verify browser installation\nls ~/.cache/ms-playwright/\n```\n\n**Solutions:**\n\n```bash\n# Install all browsers\nnpx playwright install\n\n# Install specific browser\nnpx playwright install chromium\n\n# Install system dependencies\nnpx playwright install-deps\n\n# Reinstall with dependencies\nnpx playwright install --with-deps\n```\n\n### Missing Dependencies\n\n**Symptom:** \"Error: Failed to launch browser\" or library not found errors\n\n**Solutions:**\n\n```bash\n# Install system dependencies (Linux)\nnpx playwright install-deps\n\n# MacOS (usually not needed, but if required)\n# Install Xcode command line tools:\nxcode-select --install\n\n# Windows (usually not needed, but if required)\n# Run as Administrator or use package manager\n```\n\n## Browser Launch Issues\n\n### Browser Won't Start\n\n**Symptom:** \"Error: Failed to launch browser process\"\n\n**Diagnosis:**\n\n```bash\n# Try launching manually with debug info\nPWDEBUG=1 npx playwright test tests/single.spec.ts\n\n# Check browser paths\nnpx playwright install --help\n```\n\n**Solutions:**\n\n```bash\n# Reinstall browsers\nnpx playwright install --with-deps\n\n# Clear browser cache\nrm -rf ~/.cache/ms-playwright/\n\n# Reset Playwright completely\nnpm install @playwright/test@latest\nnpx playwright install\n```\n\n### Timeout on Browser Launch\n\n**Symptom:** Test times out during browser launch\n\n**Diagnosis:**\n\n```bash\n# Check system resources\ntop  # or Activity Monitor on Mac\n\n# Test with longer timeout\nnpx playwright test --timeout=60000\n```\n\n**Solutions:**\n\n```bash\n# Increase launch timeout in config\nuse: {\n  launchArgs: ['--disable-web-resources'],\n  timeout: 60000,\n}\n\n# Run with verbose logging\nnpx playwright test --reporter=verbose\n\n# Reduce parallel workers\nnpx playwright test --workers=1\n```\n\n### Browser Crashes During Tests\n\n**Symptom:** \"Browser closed\" or \"Session closed\" errors\n\n**Solutions:**\n\n```bash\n# Reduce memory pressure\nnpx playwright test --workers=1\n\n# Disable sandbox mode (if safe)\nuse: {\n  launchArgs: ['--disable-setuid-sandbox'],\n}\n\n# Increase memory allocation\nNODE_OPTIONS=--max-old-space-size=4096 npx playwright test\n```\n\n## Test Execution Issues\n\n### Tests Timeout\n\n**Symptom:** Tests fail with \"Test timeout\" after waiting period\n\n**Diagnosis:**\n\n```bash\n# Check which tests are timing out\nnpx playwright test --reporter=verbose\n\n# Identify slow operations\nnpx playwright test --trace on\nnpx playwright show-trace trace.zip\n```\n\n**Solutions:**\n\n```bash\n# Increase global timeout\nnpx playwright test --timeout=30000\n\n# Increase specific action timeout in config\nuse: {\n  actionTimeout: 10000,\n}\n\n# Increase navigation timeout\nuse: {\n  navigationTimeout: 30000,\n}\n\n# Identify slow selectors/operations and optimize test code\n```\n\n### Tests Are Flaky\n\n**Symptom:** Tests pass sometimes, fail other times\n\n**Common Causes:**\n\n1. **Race conditions** â†’ Use proper wait mechanisms\n2. **Timing issues** â†’ Network/system dependent\n3. **Selector instability** â†’ Element not stable\n4. **Parallel execution issues** â†’ Tests interfere with each other\n\n**Solutions:**\n\n```bash\n# Run flaky test with retries\nnpx playwright test -g \"flaky-test\" --retries=3\n\n# Debug with head mode\nnpx playwright test -g \"flaky-test\" --headed\n\n# Run sequentially (eliminates parallelization issues)\nnpx playwright test -g \"flaky-test\" --workers=1\n\n# Record trace for analysis\nnpx playwright test -g \"flaky-test\" --trace retain-on-failure\n\n# Run multiple times to identify pattern\nnpx playwright test -g \"flaky-test\" --retries=5 --reporter=verbose\n```\n\n### Tests Run Slowly\n\n**Symptom:** Test suite takes unexpectedly long\n\n**Diagnosis:**\n\n```bash\n# Identify slow tests\nnpx playwright test --reporter=verbose\n\n# Check resource usage\ndocker stats  # if using Docker\ntop  # or Activity Monitor\n\n# Analyze with trace\nnpx playwright test --trace on\nnpx playwright show-trace trace.zip\n```\n\n**Solutions:**\n\n```bash\n# Parallelize execution\nnpx playwright test --workers=4\n\n# Remove unnecessary waits in tests\n# Replace: page.waitForTimeout(5000)\n# With: page.waitForSelector('.element')\n\n# Optimize selectors (avoid complex queries)\n# Replace: page.locator('[data-test-id=\"foo\"]')\n# Check: page.locator('button:has-text(\"Login\")')\n\n# Use test fixtures efficiently\n# Group related tests together\n```\n\n## Navigation & Loading Issues\n\n### Page Won't Load\n\n**Symptom:** Page fails to load or times out\n\n**Diagnosis:**\n\n```bash\n# Check base URL\nnpx playwright test --base-url=http://localhost:3000\n\n# Verify page is accessible\ncurl http://localhost:3000\n\n# Check browser console errors\nnpx playwright test --headed --debug\n```\n\n**Solutions:**\n\n```bash\n# Increase timeout\nnpx playwright test --timeout=30000\n\n# Verify base URL is correct\n# In config: webServer: { url: 'http://localhost:3000' }\n\n# Wait for specific condition\npage.waitForLoadState('networkidle');\n\n# Handle HTTPS certificate issues\nuse: {\n  ignoreHTTPSErrors: true,\n}\n```\n\n### Network Timeouts\n\n**Symptom:** \"Network timeout\" or \"Request timeout\"\n\n**Solutions:**\n\n```bash\n# Increase test timeout\nnpx playwright test --timeout=45000\n\n# Check network connectivity\nping example.com\n\n# Increase individual request timeout\npage.goto(url, { waitUntil: 'domcontentloaded', timeout: 30000 });\n\n# Handle slow networks\nuse: {\n  navigationTimeout: 45000,\n  actionTimeout: 15000,\n}\n```\n\n## Selector & Element Issues\n\n### Element Not Found\n\n**Symptom:** \"Locator timeout waiting for selector\"\n\n**Diagnosis:**\n\n```bash\n# Debug with headed mode\nnpx playwright test --headed --debug\n\n# Take screenshot to verify page state\nnpx playwright test --screenshot=on\n\n# Check selector validity\n# In test: console.log(await page.locator('selector').count());\n```\n\n**Solutions:**\n\n```bash\n# Use more robust selectors\n// Avoid: page.locator('button')\n// Better: page.locator('button:has-text(\"Login\")')\n// Better: page.getByRole('button', { name: 'Login' })\n\n# Increase wait time\npage.locator('.element').waitFor({ timeout: 5000 });\n\n# Wait for page to load\nawait page.waitForLoadState('networkidle');\n\n# Verify element exists before interaction\nif (await page.locator('.element').count() > 0) {\n  // proceed\n}\n```\n\n### Flaky Selectors\n\n**Symptom:** Selector sometimes works, sometimes doesn't\n\n**Solutions:**\n\n```bash\n# Use accessibility selectors (more stable)\npage.getByRole('button', { name: 'Login' })\npage.getByLabel('Username')\npage.getByPlaceholder('Enter email')\n\n# Use test IDs\npage.locator('[data-testid=\"submit-button\"]')\n\n# Avoid CSS selector chains that change\n// Bad: page.locator('div > span > button')\n// Good: page.locator('button.submit-btn')\n\n# Wait before interaction\nawait page.locator('button').waitFor({ state: 'visible' });\nawait page.locator('button').click();\n```\n\n## Screenshot & Comparison Issues\n\n### Screenshot Mismatches\n\n**Symptom:** Visual regression test fails with \"image differs\"\n\n**Solutions:**\n\n```bash\n# Update snapshots (intentional changes)\nnpx playwright test --update-snapshots\n\n# Regenerate specific snapshots\nnpx playwright test -g \"visual-test\" --update-snapshots\n\n# Review changes\nnpx playwright test --reporter=html\nnpx playwright show-report\n\n# Compare snapshots\nnpx playwright show-trace trace.zip  # includes screenshots\n```\n\n### Flaky Visual Tests\n\n**Symptom:** Same UI produces different screenshot sometimes\n\n**Solutions:**\n\n```bash\n# Wait for animations/transitions\nawait page.waitForLoadState('networkidle');\nawait page.locator('.element').waitFor({ state: 'stable' });\n\n# Disable visual noise\nuse: {\n  locale: 'en-US',\n  timezoneId: 'UTC',\n  // Consistent date/time\n}\n\n# Use maxDiffPixels for minor variations\nexpect(screenshot).toMatchSnapshot({\n  maxDiffPixels: 100,\n});\n```\n\n## Configuration Issues\n\n### Config File Not Found\n\n**Symptom:** \"Could not locate playwright.config\"\n\n**Solutions:**\n\n```bash\n# Verify config exists\nls playwright.config.ts\nls playwright.config.js\n\n# Specify custom config\nnpx playwright test --config=playwright-ci.config.ts\n\n# Default location: project root\n# Create if missing: touch playwright.config.ts\n```\n\n### Incorrect Configuration\n\n**Symptom:** Tests don't run with expected settings\n\n**Diagnosis:**\n\n```bash\n# Check config syntax\nnpx playwright test --help\n\n# Verify base URL\nnpx playwright test --base-url=http://localhost:3000\n\n# List configuration\nnpx playwright test --list\n```\n\n**Solutions:**\n\n```bash\n# Validate config file structure\n// Check for: export default defineConfig({...})\n\n// Common fixes:\n// 1. Add webServer for automatic server startup\nwebServer: {\n  command: 'npm run dev',\n  url: 'http://localhost:3000',\n}\n\n// 2. Set correct timeout\ntimeout: 30 * 1000,\n\n// 3. Configure projects correctly\nprojects: [\n  { name: 'chromium', use: { ...devices['Desktop Chrome'] } },\n]\n```\n\n## CI/CD Issues\n\n### Tests Pass Locally But Fail in CI\n\n**Symptom:** \"Works on my machine\" problem\n\n**Common Causes:**\n\n1. Different base URL\n2. Missing environment variables\n3. Timing differences\n4. Browser differences\n\n**Solutions:**\n\n```bash\n# Use same base URL in CI\nnpx playwright test --base-url=http://localhost:3000\n\n# Verify environment variables\necho $DATABASE_URL\nenv | grep PLAYWRIGHT\n\n# Run with exact CI configuration\nnpx playwright test --workers=1 --reporter=github --timeout=30000\n\n# Use exact same Node version\nnode --version\nnvm use <version>\n```\n\n### Tests Fail with \"Out of Memory\"\n\n**Symptom:** \"JavaScript heap out of memory\"\n\n**Solutions:**\n\n```bash\n# Increase Node memory\nNODE_OPTIONS=--max-old-space-size=4096 npx playwright test\n\n# Reduce parallelization\nnpx playwright test --workers=1\n\n# Clear browser cache between runs\nrm -rf ~/.cache/ms-playwright/\n```\n\n### Docker Container Issues\n\n**Symptom:** Tests fail in Docker container\n\n**Solutions:**\n\n```bash\n# Install system dependencies\nRUN npx playwright install-deps\n\n# Run with proper resource limits\ndocker run --memory=2g --cpus=2 myapp\n\n# Use official Playwright image\nFROM mcr.microsoft.com/playwright:v1.latest\n```\n\n## Debugging Tools & Techniques\n\n### Enable Full Debugging\n\n```bash\n# Debug mode with Inspector UI\nnpx playwright test --debug\n\n# Verbose output\nnpx playwright test --reporter=verbose\n\n# Debug logs\nPWDEBUG=1 npx playwright test\n\n# Browser console logs\n// In test:\npage.on('console', console.log);\n```\n\n### Advanced Debugging\n\n```bash\n# Record trace for analysis\nnpx playwright test --trace on\n\n# View trace\nnpx playwright show-trace trace.zip\n\n# Detailed inspection\nnpx playwright test --reporter=verbose --trace on --headed\n```\n\n## Performance Profiling\n\n### Identify Slow Operations\n\n```bash\n# Run with traces\nnpx playwright test --trace on\n\n# Analyze with Inspector\nnpx playwright show-trace trace.zip\n\n# Look for:\n// 1. Long page load times\n// 2. Slow selector queries\n// 3. Network request delays\n```\n\n### Optimization Checklist\n\n```bash\n# Parallel execution when safe\nnpx playwright test --workers=4\n\n# Remove browser.pause() in production tests\n// Bad: page.pause();  // removes in CI\n// Good: page.pause();  // works locally only\n\n# Optimize selectors\n// Use: getByRole, getByLabel, getByTestId\n// Avoid: complex CSS chains\n\n# Batch operations\n// Use: page.evaluate() for multiple actions\n// Avoid: individual page.click() calls\n```\n",
        "plugins/dev/skills/railway-cli/SKILL.md": "---\nname: railway-cli\ndescription: Railway CLI expert for deployment. Use when users need to deploy apps, manage databases, configure Railway projects, or manage environments.\nallowed-tools: Bash(railway:*)\n---\n\n# Railway CLI Guide\n\nRailway is a deployment platform that simplifies deploying and managing web applications, databases, and services. This guide provides essential workflows and quick references for common Railway operations.\n\n## Quick Start\n\n```bash\n# Check Railway CLI installation\nrailway --version\n\n# Authenticate with Railway\nrailway login\n\n# Create and initialize new project\nrailway init my-app\n\n# Add a database\nrailway add --database postgres\n\n# Deploy application\nrailway up\n\n# View logs in real-time\nrailway logs --follow\n```\n\n## Common Workflows\n\n### Workflow 1: Deploy New Application\n\n```bash\n# Initialize project\nrailway init my-project\n\n# Configure environment variables\nrailway variables set NODE_ENV=production\nrailway variables set PORT=3000\n\n# Add database if needed\nrailway add --database postgres\n\n# Deploy\nrailway up\n\n# Verify deployment\nrailway logs --follow\nrailway status\n```\n\n### Workflow 2: Link Existing Project & Deploy\n\n```bash\n# Link to existing Railway project\nrailway link\n\n# Review current status\nrailway status\n\n# Update environment variables\nrailway variables set API_KEY=new-value\n\n# Redeploy with changes\nrailway redeploy\n\n# Follow logs\nrailway logs --follow\n```\n\n### Workflow 3: Multi-Environment Setup\n\n```bash\n# Create staging environment\nrailway environment new staging\n\n# Switch to staging\nrailway environment use staging\n\n# Configure staging-specific variables\nrailway variables set LOG_LEVEL=debug\n\n# Deploy to staging\nrailway deploy\n\n# Switch to production\nrailway environment use production\n\n# Deploy to production\nrailway deploy\n```\n\n### Workflow 4: Database Management\n\n```bash\n# Add PostgreSQL\nrailway add --database postgres\n\n# Connect to database\nrailway connect postgres\n\n# Set database variables in application\nrailway variables set DATABASE_URL=$(railway variables get DATABASE_URL)\n\n# Run migrations\nrailway run npm run migrate\n\n# Verify connection\nrailway ssh --command \"psql $DATABASE_URL -c 'SELECT 1'\"\n```\n\n### Workflow 5: Debugging Deployment Issues\n\n```bash\n# Check deployment status\nrailway status\n\n# View all logs\nrailway logs --tail 100\n\n# SSH into service for inspection\nrailway ssh\n\n# Run diagnostic commands\nrailway ssh --command \"ps aux\"\nrailway ssh --command \"df -h\"\n\n# Check resource usage\nrailway open  # View in dashboard\n```\n\n## Decision Tree\n\n**When to use which command:**\n\n- **To create new project**: Use `railway init`\n- **To link to existing project**: Use `railway link`\n- **To deploy changes**: Use `railway up` or `railway deploy`\n- **To add database/service**: Use `railway add`\n- **To check status**: Use `railway status`\n- **To view logs**: Use `railway logs --follow`\n- **To access service shell**: Use `railway ssh`\n- **To manage environments**: Use `railway environment`\n- **For detailed command syntax**: See [Commands Reference](./reference/commands-reference.md)\n- **For complex scenarios**: See [Common Patterns](./reference/common-patterns.md)\n- **For troubleshooting**: See [Troubleshooting Guide](./reference/troubleshooting.md)\n\n## Common Patterns\n\n### Project Setup and Deployment\n\n```bash\n# New project workflow\nrailway login\nrailway init my-app\nrailway add --database postgres\nrailway variables set NODE_ENV=production\nrailway up\n```\n\n### Environment Variables Management\n\n```bash\n# Set variables\nrailway variables set KEY1=value1 KEY2=value2\n\n# Get specific variable\nrailway variables get DATABASE_URL\n\n# Import from .env\nrailway variables set --from-file .env\n\n# Use variables in commands\nrailway run npm start\n```\n\n### Database Operations\n\n```bash\n# Add database\nrailway add --database postgres\n\n# Connect interactively\nrailway connect postgres\n\n# Run SQL commands\nrailway ssh --command \"psql $DATABASE_URL -c 'CREATE TABLE users (...)'\"\n\n# Run migrations\nrailway run npm run migrate\n```\n\n### Service Communication\n\n```bash\n# Services on same environment communicate by name\nrailway variables set API_URL=http://api-service:3000\n\n# Within application, use service name as hostname\nfetch('http://api-service:3000/endpoint')\n```\n\n## Troubleshooting\n\n**Common Issues:**\n\n1. **Deployment fails to start**\n   - Solution: Check logs with `railway logs --tail 50`\n   - See: [Deployment Issues](./reference/troubleshooting.md#deployment-issues)\n\n2. **Cannot connect to database**\n   - Quick fix: Verify database URL with `railway variables get DATABASE_URL`\n   - See: [Service Connection Issues](./reference/troubleshooting.md#service-connection-issues)\n\n3. **Environment variables not loading**\n   - Quick fix: Redeploy with `railway redeploy` after setting variables\n   - See: [Variable Issues](./reference/troubleshooting.md#environment-variable-issues)\n\n4. **Service unreachable after deployment**\n   - Quick fix: Verify with `railway ssh --command \"curl http://localhost:3000\"`\n   - See: [Connection Issues](./reference/troubleshooting.md#application-starts-but-service-unreachable)\n\n5. **SSH or access failing**\n   - Quick fix: Ensure service is healthy with `railway status`\n   - See: [SSH Issues](./reference/troubleshooting.md#ssh-and-access-issues)\n\nFor detailed troubleshooting steps, see the [Troubleshooting Guide](./reference/troubleshooting.md).\n\n## Reference Files\n\n**Load as needed for detailed information:**\n\n- **[Commands Reference](./reference/commands-reference.md)** - Complete CLI command documentation with all flags and options. Use when you need exact syntax or flag details for any Railway command.\n\n- **[Common Patterns](./reference/common-patterns.md)** - Real-world patterns and workflows for development, multi-environment setups, database management, CI/CD integration, monitoring, and backup strategies. Use for implementing specific workflows or deployments.\n\n- **[Troubleshooting Guide](./reference/troubleshooting.md)** - Detailed error messages, diagnosis steps, and resolution strategies for deployments, databases, environments, domains, resources, and access issues. Use when encountering errors or unexpected behavior.\n\n**When to use each reference:**\n\n- Use **Commands Reference** when you need exact syntax, flag combinations, or comprehensive command documentation\n- Use **Common Patterns** for implementing multi-environment setups, CI/CD pipelines, or database workflows\n- Use **Troubleshooting** when deployments fail, services are unreachable, or you encounter connection/resource issues\n\n## Resources\n\n- Official Docs: https://docs.railway.app\n- Dashboard: https://railway.app/dashboard\n- GitHub: https://github.com/railwayapp\n- Community: https://railway.app/community\n",
        "plugins/dev/skills/railway-cli/reference/commands-reference.md": "# Railway CLI Commands Reference\n\nComplete reference for all Railway CLI commands with detailed options and flags.\n\n## Authentication\n\n### `railway login`\n\nAuthenticate with Railway.\n\n```bash\n# Login with browser\nrailway login\n\n# Login in CI/CD without browser\nrailway login --browserless\n\n# Show current user\nrailway whoami\n\n# Logout\nrailway logout\n```\n\n## Project Management\n\n### `railway init`\n\nCreate and initialize a new Railway project.\n\n```bash\n# Create new project interactively\nrailway init\n\n# Create project with specific name\nrailway init my-project\n\n# Create and link in one step\nrailway init --link\n```\n\n### `railway list`\n\nList all projects under current account.\n\n```bash\n# List all projects\nrailway list\n\n# List with JSON output\nrailway list --json\n```\n\n### `railway link`\n\nLink current directory to an existing Railway project.\n\n```bash\n# Link to project interactively\nrailway link\n\n# Link to specific project\nrailway link [project-id]\n\n# Unlink current directory\nrailway unlink\n```\n\n### `railway status`\n\nShow information about current project.\n\n```bash\n# Show project status\nrailway status\n\n# Show with JSON output\nrailway status --json\n```\n\n## Deployments\n\n### `railway up`\n\nDeploy current directory to Railway.\n\n```bash\n# Deploy current directory\nrailway up\n\n# Deploy without following logs\nrailway up --detach\n\n# Deploy in CI mode (build logs only)\nrailway up --ci\n\n# Deploy without confirmation\nrailway up --yes\n```\n\n### `railway deploy`\n\nDeploy a template into the project.\n\n```bash\n# Deploy template interactively\nrailway deploy\n\n# Deploy specific template\nrailway deploy --template [template-name]\n\n# Deploy without confirmation\nrailway deploy --yes\n```\n\n### `railway redeploy`\n\nRedeploy the latest service version.\n\n```bash\n# Redeploy latest version\nrailway redeploy\n\n# Redeploy specific service\nrailway redeploy --service [service-name]\n\n# Redeploy specific deployment\nrailway redeploy --deployment [deployment-id]\n```\n\n### `railway down`\n\nRemove the most recent deployment.\n\n```bash\n# Remove latest deployment\nrailway down\n\n# Remove specific deployment\nrailway down [deployment-id]\n\n# Remove without confirmation\nrailway down --yes\n```\n\n## Services & Databases\n\n### `railway add`\n\nAdd a service or database to the project.\n\n```bash\n# Add service or database interactively\nrailway add\n\n# Add specific database\nrailway add --database postgres\nrailway add --database mysql\nrailway add --database mongodb\nrailway add --database redis\n\n# Add service template\nrailway add --template [template-name]\n```\n\n### `railway service`\n\nLink a service to the project.\n\n```bash\n# Link service interactively\nrailway service\n\n# Link specific service\nrailway service [service-name]\n\n# Switch current service context\nrailway service --set [service-name]\n```\n\n### `railway connect`\n\nConnect to database shells interactively.\n\n```bash\n# Connect to database interactively\nrailway connect\n\n# Connect to specific database\nrailway connect [database-name]\n\n# Connect to PostgreSQL\nrailway connect postgres\n\n# Connect to MySQL\nrailway connect mysql\n\n# Connect to MongoDB\nrailway connect mongo\n\n# Connect to Redis\nrailway connect redis\n```\n\n## Environment Variables\n\n### `railway variables`\n\nManage environment variables.\n\n```bash\n# List environment variables\nrailway variables\n\n# Set environment variable\nrailway variables set KEY=value\n\n# Set multiple variables\nrailway variables set KEY1=value1 KEY2=value2\n\n# Get specific variable\nrailway variables get KEY\n\n# Delete environment variable\nrailway variables delete KEY\n\n# Import from .env file\nrailway variables set --from-file .env\n\n# Export to .env file\nrailway variables export > .env.example\n```\n\n### `railway run`\n\nExecute commands using project environment variables.\n\n```bash\n# Run command with Railway environment\nrailway run [command]\n\n# Run with specific service environment\nrailway run --service [service-name] [command]\n\n# Examples\nrailway run npm start\nrailway run python manage.py migrate\nrailway run node index.js\n```\n\n### `railway shell`\n\nCreate subshell with project environment variables loaded.\n\n```bash\n# Start shell with environment\nrailway shell\n\n# Start shell for specific service\nrailway shell --service [service-name]\n```\n\n## Environments\n\n### `railway environment`\n\nManage project environments.\n\n```bash\n# List environments\nrailway environment\n\n# Create new environment\nrailway environment new [environment-name]\n\n# Delete environment\nrailway environment delete [environment-name]\n\n# Switch environment\nrailway environment use [environment-name]\n\n# Show current environment\nrailway environment current\n```\n\n## Domains\n\n### `railway domain`\n\nManage custom domains for services.\n\n```bash\n# List domains\nrailway domain\n\n# Add custom domain\nrailway domain add [domain-name]\n\n# Remove domain\nrailway domain remove [domain-name]\n\n# Generate Railway domain\nrailway domain generate\n```\n\n## Logs & Monitoring\n\n### `railway logs`\n\nView deployment and service logs.\n\n```bash\n# View logs\nrailway logs\n\n# Follow logs in real-time\nrailway logs --follow\n\n# View logs for specific service\nrailway logs --service [service-name]\n\n# View logs for specific deployment\nrailway logs --deployment [deployment-id]\n\n# Limit number of lines\nrailway logs --tail 100\n\n# Show logs with timestamps\nrailway logs --timestamps\n\n# View logs since specific time\nrailway logs --since \"2024-01-01T00:00:00Z\"\n```\n\n## SSH & Remote Access\n\n### `railway ssh`\n\nConnect to project or service via SSH.\n\n```bash\n# SSH into service\nrailway ssh\n\n# SSH into specific service\nrailway ssh --service [service-name]\n\n# SSH with specific command\nrailway ssh --command \"ls -la\"\n\n# Execute with specific user\nrailway ssh --user [username]\n```\n\n## Volumes\n\n### `railway volume`\n\nManage persistent volumes.\n\n```bash\n# List volumes\nrailway volume list\n\n# Create volume\nrailway volume create [volume-name]\n\n# Delete volume\nrailway volume delete [volume-name]\n\n# Mount volume to service\nrailway volume mount [volume-name] [mount-path]\n\n# Unmount volume\nrailway volume unmount [volume-name]\n```\n\n## Utilities\n\n### `railway open`\n\nOpen Railway dashboard in browser.\n\n```bash\n# Open project dashboard\nrailway open\n\n# Open specific service\nrailway open --service [service-name]\n\n# Copy dashboard URL instead of opening\nrailway open --copy\n```\n\n### `railway docs`\n\nOpen Railway documentation.\n\n```bash\n# Open general documentation\nrailway docs\n\n# Open CLI documentation\nrailway docs cli\n\n# Open specific topic\nrailway docs [topic]\n```\n\n### `railway help`\n\nShow general or command-specific help.\n\n```bash\n# General help\nrailway help\n\n# Help for specific command\nrailway help deploy\n\n# Show all commands\nrailway help --all\n```\n\n## Global Options\n\nAll Railway commands support these global flags:\n\n- `--help` â€’ Show help for command\n- `--version` â€’ Show CLI version\n- `--verbose` â€’ Enable verbose output\n- `--json` â€’ Output in JSON format\n- `--service <name>` â€’ Specify service for command\n- `--environment <name>` â€’ Specify environment\n- `--project <id>` â€’ Specify project ID\n- `--yes` â€’ Skip confirmation prompts\n\n## CI/CD Configuration\n\n### Using Railway Token\n\nSet the `RAILWAY_TOKEN` environment variable in CI/CD:\n\n```bash\n# Get token from Railway dashboard\nexport RAILWAY_TOKEN=your-token-here\n\n# Use in CI mode\nrailway up --ci\n\n# Deploy without prompts\nrailway deploy --yes\n\n# Example for GitHub Actions\n# env:\n#   RAILWAY_TOKEN: ${{ secrets.RAILWAY_TOKEN }}\n```\n\n### Deployment Verification\n\n```bash\n# Check deployment status\nrailway status\n\n# View deployment logs\nrailway logs --follow\n\n# Verify service health\nrailway ssh --command \"curl http://localhost:3000/health\"\n```\n",
        "plugins/dev/skills/railway-cli/reference/common-patterns.md": "# Railway Common Patterns\n\nReal-world patterns and workflows for common Railway use cases.\n\n## Project Setup Workflow\n\n### Initial Project Setup\n\n```bash\n# Create and initialize new project\nrailway login\nrailway init my-app\n\n# Add database\nrailway add --database postgres\n\n# Configure environment variables\nrailway variables set NODE_ENV=production\nrailway variables set APP_NAME=my-app\n\n# Deploy application\nrailway up\n```\n\n### Link Existing Project\n\n```bash\n# Link to existing project\nrailway link\n\n# Verify connection\nrailway status\n\n# Load local environment\nrailway shell\n```\n\n## Development Workflow\n\n### Local Development with Environment\n\n```bash\n# Link to project\nrailway link\n\n# Load project environment variables\nrailway shell\n\n# Run local development server\nnpm start\n# or\npython manage.py runserver\n\n# Exit Railway shell\nexit\n```\n\n### Testing with Production Environment Variables\n\n```bash\n# Run local test with production env\nrailway run npm test\n\n# Run database migration with production env\nrailway run python manage.py migrate\n\n# Run seed script\nrailway run node scripts/seed.js\n```\n\n## Database Management\n\n### PostgreSQL Setup and Connection\n\n```bash\n# Add PostgreSQL database\nrailway add --database postgres\n\n# Get database URL\nrailway variables get DATABASE_URL\n\n# Connect to database shell\nrailway connect postgres\n\n# Run migrations in Railway environment\nrailway run npm run migrate\n\n# Seed database\nrailway run npm run seed\n\n# Backup database\nrailway ssh --command \"pg_dump $DATABASE_URL | gzip > backup.sql.gz\"\n```\n\n### MongoDB Setup and Connection\n\n```bash\n# Add MongoDB database\nrailway add --database mongodb\n\n# Get connection URL\nrailway variables get MONGO_URL\n\n# Connect to MongoDB shell\nrailway connect mongo\n\n# List collections\nshow collections\n\n# Exit MongoDB shell\nexit\n```\n\n### Redis Cache Setup\n\n```bash\n# Add Redis database\nrailway add --database redis\n\n# Get Redis URL\nrailway variables get REDIS_URL\n\n# Connect to Redis\nrailway connect redis\n\n# Test connection\nping\n\n# Flush cache (development only)\nFLUSHALL\n```\n\n## Environment Management\n\n### Multi-Environment Setup\n\n```bash\n# Create staging environment\nrailway environment new staging\n\n# Switch to staging\nrailway environment use staging\n\n# Deploy to staging\nrailway deploy\n\n# Switch back to production\nrailway environment use production\n\n# Deploy to production\nrailway deploy\n\n# Verify production deployment\nrailway logs --follow\n```\n\n### Environment-Specific Variables\n\n```bash\n# Set different variables per environment\nrailway variables set NODE_ENV=production\nrailway variables set LOG_LEVEL=info\n\n# Switch to staging\nrailway environment use staging\n\n# Set staging-specific variables\nrailway variables set LOG_LEVEL=debug\n\n# Switch back to production\nrailway environment use production\n```\n\n## Domain & SSL Setup\n\n### Configure Custom Domain\n\n```bash\n# Generate Railway domain (if needed for testing)\nrailway domain generate\n\n# Add custom domain\nrailway domain add mydomain.com\nrailway domain add api.mydomain.com\n\n# Add wildcard domain\nrailway domain add *.mydomain.com\n\n# Verify domain in DNS settings\nrailway domain\n\n# Open dashboard to verify SSL\nrailway open\n```\n\n### Domain Verification\n\n```bash\n# Check assigned domain\nrailway domain\n\n# Verify DNS configuration (from host)\nnslookup mydomain.com\ndig mydomain.com\n\n# Test HTTPS connectivity\ncurl -I https://mydomain.com\n```\n\n## Deployment Patterns\n\n### Complete Deploy and Verify Workflow\n\n```bash\n# Ensure we're in correct environment\nrailway environment use production\n\n# Review project status\nrailway status\n\n# Deploy application\nrailway up\n\n# Follow deployment logs\nrailway logs --follow\n\n# Verify service is healthy\nrailway ssh --command \"curl http://localhost:3000/health\"\n\n# Test public endpoint\ncurl https://mydomain.com/health\n\n# Check resource usage\nrailway open  # View in dashboard\n```\n\n### Blue-Green Deployment Strategy\n\n```bash\n# Create production environment clone\nrailway environment new production-green\n\n# Deploy to green environment\nrailway environment use production-green\nrailway deploy\n\n# Verify green deployment\nrailway logs --follow\nrailway ssh --command \"curl http://localhost:3000/health\"\n\n# Switch traffic (via dashboard or domain routing)\n# Update production domain to point to green\n\n# Keep blue for rollback\nrailway environment use production\nrailway logs --follow\n```\n\n### Rollback Strategy\n\n```bash\n# List recent deployments\nrailway logs --tail 20\n\n# Check deployment ID of last working version\nrailway status\n\n# Redeploy previous version\nrailway redeploy --deployment [previous-deployment-id]\n\n# Verify rollback\nrailway logs --follow\nrailway status\n```\n\n## CI/CD Integration\n\n### GitHub Actions Deployment\n\n```yaml\nname: Deploy to Railway\non:\n  push:\n    branches: [main]\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Deploy to Railway\n        env:\n          RAILWAY_TOKEN: ${{ secrets.RAILWAY_TOKEN }}\n        run: |\n          npm install -g @railway/cli\n          railway up --ci\n```\n\n### GitLab CI Deployment\n\n```yaml\ndeploy:\n  stage: deploy\n  image: node:18\n  only:\n    - main\n  script:\n    - npm install -g @railway/cli\n    - railway up --ci\n  environment:\n    name: production\n    url: https://mydomain.com\n```\n\n### GitLab CI with Environment Variables\n\n```yaml\ndeploy:\n  stage: deploy\n  script:\n    - npm install -g @railway/cli\n    - railway variables set VERSION=$CI_COMMIT_SHA\n    - railway variables set BUILD_TIME=$(date)\n    - railway up --ci\n  environment:\n    name: production\n```\n\n## Service Communication Patterns\n\n### Multi-Service Architecture\n\n```bash\n# Add web service\nrailway add --template express\n\n# Add API service\nrailway add --template api\n\n# Add background worker\nrailway add --template worker\n\n# Configure service discovery (via environment variables)\nrailway variables set API_URL=http://api:3000\nrailway variables set WORKER_QUEUE_URL=redis://redis:6379\n\n# Deploy all services\nrailway up\n```\n\n### Service-to-Service Communication\n\n```bash\n# Connect services through environment variables\nrailway variables set INTERNAL_API_URL=http://api-service:3000\nrailway variables set DATABASE_URL=postgres://db-service:5432/mydb\n\n# Within application, use these URLs for internal communication\n# Example: fetch('http://api-service:3000/internal/endpoint')\n```\n\n## Monitoring and Debugging\n\n### Real-Time Log Monitoring\n\n```bash\n# Follow all service logs\nrailway logs --follow\n\n# Follow specific service logs\nrailway logs --service web --follow\n\n# View logs with timestamps\nrailway logs --timestamps\n\n# View last 200 lines\nrailway logs --tail 200\n```\n\n### SSH for Debugging\n\n```bash\n# Access service shell\nrailway ssh\n\n# Run diagnostic commands\nrailway ssh --command \"ps aux\"\nrailway ssh --command \"df -h\"\nrailway ssh --command \"netstat -tlnp\"\n\n# Check application logs directly\nrailway ssh --command \"tail -f /app/logs/application.log\"\n\n# Test internal connectivity\nrailway ssh --command \"curl http://database:5432\"\n```\n\n### Resource Monitoring\n\n```bash\n# Check memory usage (from dashboard)\nrailway open\n\n# Monitor via SSH\nrailway ssh --command \"free -h\"\nrailway ssh --command \"top -b -n 1\"\n\n# Check disk usage\nrailway ssh --command \"du -sh /app\"\n```\n\n## Secrets Management\n\n### Secure Variable Storage\n\n```bash\n# Set sensitive variables (encrypted in Railway)\nrailway variables set API_KEY=secret-key-value\nrailway variables set DATABASE_PASSWORD=secret-password\nrailway variables set JWT_SECRET=secret-jwt-key\n\n# Variables are encrypted at rest and in transit\n# Never commit .env files with secrets\n\n# Rotate secrets\nrailway variables delete OLD_API_KEY\nrailway variables set NEW_API_KEY=new-secret-key\n```\n\n### Environment-Specific Secrets\n\n```bash\n# Set different secrets per environment\nrailway variables set STRIPE_KEY=pk_test_xxx\n\n# Switch to production\nrailway environment use production\n\n# Set production secret\nrailway variables set STRIPE_KEY=pk_live_yyy\n\n# Switch back to development\nrailway environment use development\n```\n\n## Backup and Recovery\n\n### Database Backup\n\n```bash\n# Create backup from Railway environment\nrailway run pg_dump $DATABASE_URL | gzip > backup-$(date +%Y%m%d).sql.gz\n\n# For MongoDB\nrailway run mongodump --uri=$MONGO_URL --archive=backup-$(date +%Y%m%d).archive\n\n# Download backup to local machine\nrailway ssh --command \"tar czf /tmp/backup.tar.gz /app/data\" > backup.tar.gz\n```\n\n### Restore from Backup\n\n```bash\n# Restore PostgreSQL backup\ngunzip < backup-20240101.sql.gz | railway run psql $DATABASE_URL\n\n# Restore MongoDB backup\nrailway run mongorestore --uri=$MONGO_URL --archive < backup.archive\n\n# Verify restoration\nrailway connect postgres\n# or\nrailway connect mongo\n```\n",
        "plugins/dev/skills/railway-cli/reference/troubleshooting.md": "# Railway Troubleshooting Guide\n\nCommon issues and solutions for Railway deployments, services, and environments.\n\n## Deployment Issues\n\n### Deployment Fails to Start\n\n**Symptom:** Deployment shows error status or doesn't start\n\n**Diagnosis:**\n```bash\n# Check deployment status\nrailway status\n\n# View detailed logs\nrailway logs --tail 50\n\n# Check specific service\nrailway logs --service [service-name]\n\n# Inspect deployment\nrailway open  # View in dashboard\n```\n\n**Common Causes:**\n1. **Application crashes on startup** â†’ Check application logs for errors\n2. **Missing environment variables** â†’ Verify with `railway variables`\n3. **Port already in use** â†’ Check if service is using correct port\n4. **Insufficient resources** â†’ Check memory and CPU limits\n5. **Build failures** â†’ Check build logs in deployment view\n\n**Solutions:**\n```bash\n# View full deployment logs\nrailway logs --tail 100\n\n# Verify environment variables are set\nrailway variables\n\n# Check which variables application expects\ngrep -r \"process.env\\.\" src/\n\n# Redeploy with verbose output\nrailway deploy --yes\n\n# Check service health\nrailway ssh --command \"curl http://localhost:3000/health\"\n```\n\n### Deployment Stuck in Building\n\n**Symptom:** Deployment stays in \"Building\" status indefinitely\n\n**Diagnosis:**\n```bash\n# Check logs for build progress\nrailway logs --follow\n\n# Check service status\nrailway status\n\n# View in dashboard\nrailway open\n```\n\n**Solutions:**\n```bash\n# Cancel current deployment\nrailway down\n\n# Wait for resources\nrailway status\n\n# Redeploy\nrailway up\n\n# If still stuck, check build timeout and resource limits in dashboard\n# Increase timeout or optimize build process\n```\n\n### Application Starts But Service Unreachable\n\n**Symptom:** Deployment shows healthy but service unavailable\n\n**Diagnosis:**\n```bash\n# Verify port mapping\nrailway ssh --command \"netstat -tlnp\"\n\n# Test application locally\nrailway ssh --command \"curl http://localhost:3000\"\n\n# Check if application started correctly\nrailway logs --tail 50\n\n# Verify port configuration\nrailway open  # Check port in dashboard\n```\n\n**Solutions:**\n```bash\n# Ensure application listens on correct port\n# Common issue: app binds to localhost only\n# Fix: app should bind to 0.0.0.0\n\n# Verify port in Railway configuration\n# Port should match what application exposes\n\n# Test connection\nrailway ssh --command \"curl -v http://localhost:3000\"\n\n# Check firewall/network configuration\nrailway open  # Verify service is exposed\n```\n\n## Service Connection Issues\n\n### Cannot Connect to Database\n\n**Symptom:** Application fails to connect to database\n\n**Diagnosis:**\n```bash\n# Get database connection URL\nrailway variables get DATABASE_URL\n\n# Check if database service is running\nrailway service --list\n\n# Test database connectivity\nrailway ssh --command \"curl postgres://[host]:[port]\"\n\n# Verify database variables in application\nrailway variables | grep DATABASE\n\n# Check application logs\nrailway logs --tail 100\n```\n\n**Common Causes:**\n1. **Wrong database URL format** â†’ Check `DATABASE_URL` format\n2. **Database not initialized** â†’ Run migrations\n3. **Network isolation** â†’ Services must be on same environment\n4. **Credentials incorrect** â†’ Verify username/password\n\n**Solutions:**\n```bash\n# Verify database is running\nrailway service\n\n# Check connection string format\nrailway variables get DATABASE_URL\n\n# Test direct connection\nrailway connect postgres\n# If fails, check database status in dashboard\n\n# Ensure application uses correct URL\nrailway run echo $DATABASE_URL\n\n# Run migrations if needed\nrailway run npm run migrate\n\n# Verify from application\nrailway logs --follow\n```\n\n### Service-to-Service Communication Fails\n\n**Symptom:** Services can't communicate with each other\n\n**Diagnosis:**\n```bash\n# List all services\nrailway service --list\n\n# Check environment variables linking services\nrailway variables | grep URL\n\n# Test connectivity between services\nrailway ssh --command \"curl http://api-service:3000\"\n\n# Check network configuration\nrailway open  # Verify in dashboard\n```\n\n**Solutions:**\n```bash\n# Use service names for internal communication\n# Services communicate via: service-name:port\n\n# Example: Connect web to API\nrailway variables set API_URL=http://api:3000\n\n# Verify from web service\nrailway ssh --service web --command \"curl http://api:3000/health\"\n\n# If still failing:\n# 1. Ensure both services in same environment\n# 2. Check that services are deployed\n# 3. Verify port numbers are correct\n```\n\n## Environment Variable Issues\n\n### Variables Not Available in Application\n\n**Symptom:** Application can't access environment variables\n\n**Diagnosis:**\n```bash\n# List all variables\nrailway variables\n\n# Check specific variable\nrailway variables get VARIABLE_NAME\n\n# Verify variable is loaded\nrailway run printenv | grep VARIABLE_NAME\n\n# Check in application logs\nrailway logs | grep undefined\n```\n\n**Solutions:**\n```bash\n# Set missing variable\nrailway variables set NEW_VAR=value\n\n# Reload application\nrailway redeploy\n\n# Verify variable loads\nrailway run printenv\n\n# Check application code uses correct variable name\n# JavaScript: process.env.VAR_NAME\n# Python: os.environ.get('VAR_NAME')\n# Ruby: ENV['VAR_NAME']\n\n# For .env file import\nrailway variables set --from-file .env\n\n# Redeploy after setting variables\nrailway redeploy\n```\n\n### Variables Leaking to Wrong Environment\n\n**Symptom:** Staging sees production variables\n\n**Diagnosis:**\n```bash\n# Check current environment\nrailway environment\n\n# List variables for current env\nrailway variables\n\n# Switch and check other environment\nrailway environment use [env-name]\nrailway variables\n```\n\n**Solutions:**\n```bash\n# Variables should be environment-specific\n# Make sure you're in correct environment before setting\n\n# Switch to correct environment\nrailway environment use staging\n\n# Set staging-specific variable\nrailway variables set API_KEY=staging-key\n\n# Switch to production\nrailway environment use production\n\n# Verify different key is set\nrailway variables get API_KEY\n```\n\n## Domain and SSL Issues\n\n### Custom Domain Not Working\n\n**Symptom:** Custom domain doesn't resolve or shows SSL error\n\n**Diagnosis:**\n```bash\n# Check assigned domain\nrailway domain\n\n# Test DNS resolution\nnslookup mydomain.com\ndig mydomain.com @8.8.8.8\n\n# Test HTTPS\ncurl -I https://mydomain.com\n\n# Check SSL certificate\nopenssl s_client -connect mydomain.com:443\n\n# View in dashboard\nrailway open\n```\n\n**Common Causes:**\n1. **DNS not updated** â†’ DNS changes take time to propagate\n2. **Domain not added to Railway** â†’ Run `railway domain add`\n3. **SSL certificate pending** â†’ Wait for issuance (usually < 5 min)\n4. **Incorrect domain** â†’ Verify domain spelling\n\n**Solutions:**\n```bash\n# Add domain to Railway\nrailway domain add mydomain.com\n\n# Add www subdomain\nrailway domain add www.mydomain.com\n\n# Generate Railway domain for testing\nrailway domain generate\n\n# Update DNS records to point to Railway\n# Check dashboard for DNS target\n\n# Wait for SSL certificate (usually < 5 minutes)\n# Monitor in dashboard under Domains\n\n# Test when ready\ncurl https://mydomain.com\n```\n\n### SSL Certificate Issues\n\n**Symptom:** SSL certificate warning or missing\n\n**Diagnosis:**\n```bash\n# Check certificate status\n# Navigate to Railway dashboard > Domains\n\n# Test certificate\ncurl -v https://mydomain.com\n\n# View certificate details\nopenssl s_client -connect mydomain.com:443 -showcerts\n```\n\n**Solutions:**\n```bash\n# Railway auto-provisions Let's Encrypt certificates\n# Usually within 5 minutes of domain addition\n\n# If certificate not issued:\n# 1. Verify DNS resolution is working\n# 2. Check domain is correctly added\n# 3. Wait longer (sometimes takes 10-15 minutes)\n\n# Remove and re-add domain to trigger re-provisioning\nrailway domain remove mydomain.com\nrailway domain add mydomain.com\n\n# Monitor status in dashboard\nrailway open\n```\n\n## Resource and Performance Issues\n\n### Out of Memory\n\n**Symptom:** Service crashes with memory errors or killed\n\n**Diagnosis:**\n```bash\n# Check current memory usage\nrailway open  # View in dashboard\n\n# Check from SSH\nrailway ssh --command \"free -h\"\nrailway ssh --command \"ps aux\"\n\n# Check application logs for memory errors\nrailway logs --tail 50\n```\n\n**Solutions:**\n```bash\n# Increase memory allocation (via dashboard)\n# Railway > Service > Settings > Resource Allocation\n\n# Monitor process memory\nrailway ssh --command \"top -b -n 1 | head -20\"\n\n# Optimize application code\n# 1. Check for memory leaks\n# 2. Optimize queries/caching\n# 3. Stream large data instead of loading in memory\n\n# Restart service to free memory\nrailway redeploy\n\n# Check logs after restart\nrailway logs --follow\n```\n\n### High CPU Usage\n\n**Symptom:** Service slow, CPU at 100%\n\n**Diagnosis:**\n```bash\n# Check CPU usage\nrailway open  # View in dashboard\n\n# Check from SSH\nrailway ssh --command \"top -b -n 1\"\n\n# Check application logs for infinite loops\nrailway logs --tail 100\n```\n\n**Solutions:**\n```bash\n# Identify problematic process\nrailway ssh --command \"ps aux | grep node\"\n\n# Optimize application code\n# 1. Profile application (use Node Inspector, Python cProfile)\n# 2. Optimize algorithms\n# 3. Add caching\n\n# Increase CPU allocation (via dashboard)\n\n# Restart service\nrailway redeploy\n\n# Monitor after restart\nrailway logs --follow\n```\n\n### Slow Deployments\n\n**Symptom:** Build takes very long time\n\n**Diagnosis:**\n```bash\n# Check deployment logs\nrailway logs --follow\n\n# Monitor build progress\nrailway status\n\n# View detailed deployment in dashboard\nrailway open\n```\n\n**Solutions:**\n```bash\n# Optimize build process\n# 1. Use .dockerignore to exclude unnecessary files\n# 2. Cache dependencies\n# 3. Use smaller base images\n\n# Examples:\n# Remove heavy dev dependencies from production build\n# Use multi-stage builds\n# Pre-build dependencies\n\n# Increase build timeout (via dashboard settings)\n\n# Clear build cache if needed\n# Contact Railway support for cache clearing\n```\n\n## SSH and Access Issues\n\n### Cannot SSH Into Service\n\n**Symptom:** SSH command fails or hangs\n\n**Diagnosis:**\n```bash\n# Verify service is running\nrailway status\n\n# Check service health\nrailway open  # View in dashboard\n\n# Try with verbose output\nrailway ssh --command \"whoami\"\n```\n\n**Solutions:**\n```bash\n# Ensure service is deployed and healthy\nrailway status\n\n# Wait for deployment to complete\nrailway logs --follow\n\n# Once healthy, SSH should work\nrailway ssh\n\n# If still failing:\n# 1. Check if service has sufficient resources\n# 2. Restart service: railway redeploy\n# 3. Contact Railway support\n```\n\n## Logging and Monitoring\n\n### Logs Not Appearing\n\n**Symptom:** No logs visible even though service is running\n\n**Diagnosis:**\n```bash\n# Check if service is logging correctly\nrailway logs\n\n# Verify service is actually running\nrailway status\n\n# Check service health\nrailway open\n```\n\n**Solutions:**\n```bash\n# Ensure application logs to stdout\n# Logs must go to stdout/stderr, not files\n\n# JavaScript: use console.log instead of file logging\n# Python: configure logging to stdout\n# Ruby: use $stdout.puts or logger\n\n# Redeploy to apply changes\nrailway redeploy\n\n# View logs\nrailway logs --follow\n\n# Check for errors that prevent logging startup\nrailway logs --tail 100\n```\n\n### Too Many Logs / Disk Full\n\n**Symptom:** Deployment shows disk full or logs huge\n\n**Diagnosis:**\n```bash\n# Check disk usage\nrailway ssh --command \"df -h\"\n\n# Check log file sizes\nrailway ssh --command \"du -sh /var/log\"\n\n# View recent logs\nrailway logs --tail 200\n```\n\n**Solutions:**\n```bash\n# Reduce logging verbosity\nrailway variables set LOG_LEVEL=info\n\n# Redeploy with updated logging\nrailway redeploy\n\n# Clean up old logs (use SSH)\nrailway ssh --command \"rm /var/log/*.old\"\n\n# Configure log rotation (in application or deployment config)\n\n# Monitor usage after changes\nrailway ssh --command \"df -h\"\n```\n\n## Account and Token Issues\n\n### RAILWAY_TOKEN Invalid or Expired\n\n**Symptom:** CI/CD deployments fail with authentication error\n\n**Diagnosis:**\n```bash\n# Test token locally\nRAILWAY_TOKEN=your-token railway status\n\n# Check token in dashboard\n# Navigate to Account Settings > Tokens\n```\n\n**Solutions:**\n```bash\n# Generate new token\n# Go to Railway Dashboard > Account Settings > Tokens > Generate\n\n# Update in CI/CD configuration\n# Set RAILWAY_TOKEN to new value\n\n# Rotate regularly for security\n# Delete old token after updating\n\n# Ensure no trailing whitespace in token\necho -n \"your-token\" | wc -c\n```\n\n### Cannot Authenticate\n\n**Symptom:** `railway login` fails\n\n**Diagnosis:**\n```bash\n# Check authentication status\nrailway whoami\n\n# View stored credentials\ncat ~/.railway/credentials.json  # Check if file exists\n\n# Test network connectivity\ncurl -I https://api.railway.app\n```\n\n**Solutions:**\n```bash\n# Login again\nrailway logout\nrailway login\n\n# Use browserless login in CI\nrailway login --browserless\n\n# Use token instead\nexport RAILWAY_TOKEN=your-token\nrailway status\n\n# Clear cached credentials if needed\nrm -f ~/.railway/credentials.json\nrailway login\n```\n",
        "plugins/dev/skills/raycast-cli/SKILL.md": "---\nname: raycast-cli\ndescription: Raycast CLI expert for extension development. Use when users need to create, develop, test, or publish Raycast extensions.\nallowed-tools: Bash(npx ray:*), Bash(npm run:*)\n---\n\n# Raycast CLI Guide\n\nRaycast is a productivity platform that allows developers to build custom extensions using TypeScript and React. This guide provides essential workflows and quick references for creating and publishing Raycast extensions.\n\n## Quick Start\n\n```bash\n# Check prerequisites\nnode --version          # Required: Node.js 22.14+\nopen -a Raycast        # Required: Raycast 1.26.0+\n\n# Create extension via Raycast\n# Open Raycast â†’ Type \"Create Extension\"\n\n# Install dependencies\npnpm install\n\n# Start development\npnpm dev\n\n# Test in Raycast\n# Open Raycast (Cmd + Space)\n# Extension appears at top of search\n```\n\n## Common Workflows\n\n### Workflow 1: Create New Extension\n\n```bash\n# Create extension via Raycast\n# Open Raycast â†’ Type \"Create Extension\"\n# Choose template or start from scratch\n\n# Navigate to extension directory\ncd ~/Developer/my-extension\n\n# Install dependencies\npnpm install\n\n# Start development\npnpm dev\n\n# Open Raycast to test\n# Extension appears at top of root search\n```\n\n### Workflow 2: Development with Hot Reload\n\n```bash\n# Start development mode\npnpm dev\n\n# Edit files in src/ directory\n# Changes reflect immediately in Raycast\n# View logs in terminal\n# View errors in Raycast overlay\n\n# Toggle hot reload if needed\n# Raycast â†’ Preferences â†’ Extensions â†’ Development\n# \"Auto-reload on file changes\"\n```\n\n### Workflow 3: Build and Publish Extension\n\n```bash\n# Run linter\npnpm lint\n\n# Build for production\npnpm build\n\n# Add README and screenshots\ncat > README.md << 'EOF'\n# Extension Name\nDescription and usage\nEOF\n\n# Add screenshots to assets/\n# Take screenshots of each command\n\n# Publish to Raycast Store\npnpm publish\n\n# For public extensions:\n# - Authenticates with GitHub\n# - Creates PR in raycast/extensions repo\n# - Awaits team review\n```\n\n### Workflow 4: API Integration\n\n```bash\n# Add API preferences to package.json\n# Configure authentication in preferences\n\n# Start development\npnpm dev\n\n# Test API integration\n# View logs in terminal\n# Handle errors with showToast\n\n# Build and test\npnpm build\n```\n\n### Workflow 5: Debug Extension Issues\n\n```bash\n# Check for errors\npnpm dev\n# View terminal for build/runtime errors\n\n# Check error overlay in Raycast\n# Shows stack trace and details\n\n# Restart Raycast if needed\n# Cmd+Q â†’ Reopen Raycast\n\n# Clear cache if needed\n# Raycast â†’ Settings â†’ Advanced â†’ Clear Cache\n```\n\n## Decision Tree\n\n**When to use which command:**\n\n- **To create a new extension**: Use Raycast \"Create Extension\" command\n- **To start development**: Use `pnpm dev` or `npx ray develop`\n- **To test changes**: Hot reload in dev mode (automatic)\n- **To run linter**: Use `pnpm lint` or `npx ray lint`\n- **To build for production**: Use `pnpm build` or `npx ray build`\n- **To update API version**: Use `npx ray migrate`\n- **To publish extension**: Use `pnpm publish` or `npx ray publish`\n- **For detailed command syntax**: See [Commands Reference](./reference/commands-reference.md)\n- **For complex patterns**: See [Common Patterns](./reference/common-patterns.md)\n- **For troubleshooting**: See [Troubleshooting Guide](./reference/troubleshooting.md)\n\n## Common Patterns\n\n### Extension Structure\n\n```\nmy-extension/\nâ”œâ”€â”€ package.json          # Extension metadata\nâ”œâ”€â”€ tsconfig.json         # TypeScript config\nâ”œâ”€â”€ README.md             # Documentation\nâ”œâ”€â”€ assets/\nâ”‚   â”œâ”€â”€ icon.png          # 512x512 icon\nâ”‚   â””â”€â”€ screenshot-1.png  # Screenshots\nâ””â”€â”€ src/\n    â””â”€â”€ index.tsx         # Main command\n```\n\n### Basic Command\n\n```typescript\nimport { List, ActionPanel, Action, Icon } from \"@raycast/api\";\n\nexport default function Command() {\n  return (\n    <List>\n      <List.Item\n        title=\"Item\"\n        icon={Icon.Star}\n        actions={\n          <ActionPanel>\n            <Action.OpenInBrowser url=\"https://example.com\" />\n          </ActionPanel>\n        }\n      />\n    </List>\n  );\n}\n```\n\n### API Integration\n\n```typescript\nimport { getPreferenceValues } from \"@raycast/api\";\n\ninterface Preferences {\n  apiKey: string;\n}\n\nconst { apiKey } = getPreferenceValues<Preferences>();\n\nasync function fetchData() {\n  const response = await fetch(\"https://api.example.com/data\", {\n    headers: {\n      Authorization: `Bearer ${apiKey}`,\n    },\n  });\n  return response.json();\n}\n```\n\n### Error Handling\n\n```typescript\nimport { showToast, Toast } from \"@raycast/api\";\n\ntry {\n  const data = await fetchData();\n} catch (error) {\n  await showToast({\n    style: Toast.Style.Failure,\n    title: \"Error\",\n    message: String(error),\n  });\n}\n```\n\n### Data Persistence\n\n```typescript\nimport { LocalStorage } from \"@raycast/api\";\n\n// Save data\nawait LocalStorage.setItem(\"favorites\", JSON.stringify(items));\n\n// Load data\nconst stored = await LocalStorage.getItem(\"favorites\");\nconst favorites = stored ? JSON.parse(stored) : [];\n```\n\n## Troubleshooting\n\n**Common Issues:**\n\n1. **Extension not appearing in Raycast**\n   - Solution: Restart dev mode with `pnpm dev`\n   - See: [Extension Not Appearing](./reference/troubleshooting.md#extension-not-appearing-in-raycast)\n\n2. **Hot reload not working**\n   - Quick fix: Toggle auto-reload in Preferences â†’ Extensions â†’ Development\n   - See: [Hot Reload Not Working](./reference/troubleshooting.md#hot-reload-not-working)\n\n3. **Build errors**\n   - Quick fix: Run `pnpm install` and verify `tsconfig.json`\n   - See: [Build Errors](./reference/troubleshooting.md#build-errors)\n\n4. **API authentication fails**\n   - Quick fix: Verify API key is configured in extension preferences\n   - See: [API Authentication Fails](./reference/troubleshooting.md#api-authentication-fails)\n\n5. **Extension crashes**\n   - Quick fix: Add error handling with try-catch and showToast\n   - See: [Runtime Errors](./reference/troubleshooting.md#runtime-errors)\n\nFor detailed troubleshooting steps, see the [Troubleshooting Guide](./reference/troubleshooting.md).\n\n## Reference Files\n\n**Load as needed for detailed information:**\n\n- **[Commands Reference](./reference/commands-reference.md)** - Complete CLI command documentation with all flags, options, and configuration files. Use when you need exact syntax, package.json structure, tsconfig settings, or ESLint configuration.\n\n- **[Common Patterns](./reference/common-patterns.md)** - Real-world patterns for development workflows, API integration, UI components, authentication, data storage, menu bar extensions, background commands, and publishing. Use for implementing specific features or workflows.\n\n- **[Troubleshooting Guide](./reference/troubleshooting.md)** - Detailed error messages, diagnosis steps, and resolution strategies for development, build, runtime, API, storage, UI, publishing, and performance issues. Use when encountering errors or unexpected behavior.\n\n**When to use each reference:**\n\n- Use **Commands Reference** when you need exact syntax, package.json structure, API module imports, or configuration file formats\n- Use **Common Patterns** for implementing search, forms, OAuth, menu bar extensions, background tasks, or optimization strategies\n- Use **Troubleshooting** when extensions won't load, hot reload fails, builds error, API requests fail, or UI components don't render\n\n## Resources\n\n- Official Docs: https://developers.raycast.com\n- API Reference: https://developers.raycast.com/api-reference\n- Extensions Store: https://raycast.com/store\n- GitHub Examples: https://github.com/raycast/extensions\n- Community Forum: https://raycast.com/community\n",
        "plugins/dev/skills/raycast-cli/reference/commands-reference.md": "# Raycast CLI Commands Reference\n\nComplete reference for all Raycast CLI commands with detailed options and flags.\n\n## Installation & Setup\n\n### Prerequisites\n\n```bash\n# Check prerequisites\nnode --version          # Required: Node.js 22.14 or higher\nopen -a Raycast        # Required: Raycast 1.26.0 or higher\n\n# Create new extension\n# Open Raycast â†’ Type \"Create Extension\"\n# Follow wizard to generate project structure\n```\n\n### Package Manager Installation\n\n```bash\n# Install dependencies\nnpm install\n\n# Or with pnpm (recommended)\npnpm install\n\n# Or with yarn\nyarn install\n```\n\n## Core CLI Commands\n\n### `npx ray help`\n\nDisplay all available CLI commands and their descriptions.\n\n```bash\n# Show all commands\nnpx ray help\n\n# Get help for specific command\nnpx ray help develop\nnpx ray help build\nnpx ray help publish\n```\n\n### `npx ray develop`\n\nStart development mode with hot-reloading and debugging features.\n\n```bash\n# Start development mode\nnpx ray develop\n\n# Development mode features:\n# - Extension appears at top of root search\n# - Auto-reloading on file changes (toggleable in Preferences)\n# - Detailed error overlays with stack traces\n# - Terminal log message display\n# - Build status indicator in navigation\n# - Automatic extension import to Raycast\n\n# Alternative npm scripts\nnpm run dev\npnpm dev\nyarn dev\n```\n\n**Development Features:**\n- Hot reload on file changes\n- Error overlays with stack traces\n- Terminal log streaming\n- Build status indicator\n- Automatic import to Raycast\n\n### `npx ray build`\n\nCreate optimized production build for distribution.\n\n```bash\n# Build extension for production\nnpx ray build\n\n# Build with validation of distribution directory\nnpx ray build -e dist\n\n# Verify extension without publishing\nnpm run build\n\n# Alternative npm scripts\npnpm build\nyarn build\n```\n\n**Build Process:**\n- TypeScript compilation\n- Dependency bundling\n- Asset optimization\n- Validation checks\n- Distribution preparation\n\n### `npx ray lint`\n\nRun ESLint for all files in the `src` directory.\n\n```bash\n# Run linter\nnpx ray lint\n\n# Check code style and errors\nnpm run lint\npnpm lint\nyarn lint\n\n# Fix issues automatically (if ESLint configured)\nnpm run lint -- --fix\npnpm lint --fix\nyarn lint --fix\n```\n\n### `npx ray migrate`\n\nMigrate extension to latest `@raycast/api` version.\n\n```bash\n# Migrate to latest API version\nnpx ray migrate\n\n# What it does:\n# - Updates package.json dependencies\n# - Migrates deprecated code patterns\n# - Updates API usage to latest conventions\n# - Provides migration report\n\n# After migration, review changes and test\npnpm dev\npnpm build\n```\n\n### `npx ray publish`\n\nVerify, build, and publish extension.\n\n```bash\n# Publish extension\nnpx ray publish\n\n# For public extensions:\n# - Authenticates with GitHub\n# - Creates pull request in raycast/extensions repo\n# - Triggers automated checks\n# - Awaits team review and merge\n\n# For private extensions:\n# - Publishes to organization's private store\n# - Requires organization membership\n\n# Alternative npm scripts\nnpm run publish\npnpm publish\nyarn publish\n```\n\n**Publish Prerequisites:**\n- Complete `package.json` metadata\n- README.md with description\n- Screenshots in `assets/` directory\n- Working production build\n- All tests passing\n\n## Global Options\n\nAll Raycast CLI commands support these options:\n\n```bash\n# Show CLI version\nnpx ray --version\n\n# Get help\nnpx ray --help\n\n# Verbose output (if supported)\nnpx ray develop --verbose\nnpx ray build --verbose\n```\n\n## Extension Structure Files\n\n### package.json\n\nMain configuration file for extension metadata and commands.\n\n```json\n{\n  \"name\": \"my-extension\",\n  \"title\": \"My Extension\",\n  \"description\": \"Extension description\",\n  \"icon\": \"icon.png\",\n  \"author\": \"yourname\",\n  \"license\": \"MIT\",\n  \"commands\": [\n    {\n      \"name\": \"index\",\n      \"title\": \"Command Title\",\n      \"description\": \"Command description\",\n      \"mode\": \"view\"\n    }\n  ],\n  \"preferences\": [\n    {\n      \"name\": \"apiKey\",\n      \"type\": \"password\",\n      \"required\": true,\n      \"title\": \"API Key\",\n      \"description\": \"Your API key\"\n    }\n  ],\n  \"dependencies\": {\n    \"@raycast/api\": \"^1.48.0\"\n  },\n  \"devDependencies\": {\n    \"@types/node\": \"^18.8.3\",\n    \"@types/react\": \"^18.0.9\",\n    \"typescript\": \"^4.4.3\"\n  },\n  \"scripts\": {\n    \"build\": \"ray build -e dist\",\n    \"dev\": \"ray develop\",\n    \"lint\": \"ray lint\"\n  }\n}\n```\n\n**Command Modes:**\n- `view` - Full UI with components (List, Detail, Form)\n- `no-view` - Background task without UI\n- `menu-bar` - Menu bar extra command\n\n**Preference Types:**\n- `textfield` - Single line text\n- `password` - Password field (encrypted storage)\n- `checkbox` - Boolean toggle\n- `dropdown` - Select from options\n\n### tsconfig.json\n\nTypeScript configuration for extension development.\n\n```json\n{\n  \"compilerOptions\": {\n    \"target\": \"ES2020\",\n    \"module\": \"commonjs\",\n    \"jsx\": \"react\",\n    \"strict\": true,\n    \"esModuleInterop\": true,\n    \"skipLibCheck\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"resolveJsonModule\": true\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"node_modules\"]\n}\n```\n\n### README.md\n\nExtension documentation for the Raycast Store.\n\n```markdown\n# Extension Name\n\nShort description of what the extension does.\n\n## Features\n\n- Feature 1\n- Feature 2\n- Feature 3\n\n## Setup\n\n1. Get API key from service\n2. Install extension from Raycast Store\n3. Configure API key in extension preferences\n\n## Usage\n\n- Command 1 - Description\n- Command 2 - Description\n```\n\n### Assets Structure\n\n```\nassets/\nâ”œâ”€â”€ icon.png              # Extension icon (512x512, PNG)\nâ”œâ”€â”€ screenshot-1.png      # Command screenshot (required)\nâ”œâ”€â”€ screenshot-2.png      # Additional screenshots (optional)\nâ””â”€â”€ command-icon.png      # Custom command icons (optional)\n```\n\n**Asset Requirements:**\n- Extension icon: 512x512 PNG\n- Screenshots: min 1, max 4\n- Supported formats: PNG, JPG\n\n## Raycast Extension Commands\n\nCommands available through Raycast interface (not CLI).\n\n### Create Extension\n\n```bash\n# Via Raycast search\n# Type: \"Create Extension\"\n# Options:\n# - Start from template\n# - Start from scratch\n# - Browse template gallery\n```\n\n### Import Extension\n\n```bash\n# Via Raycast search\n# Type: \"Import Extension\"\n# Browse to extension source directory\n# Extension appears in development mode\n```\n\n### Manage Extensions\n\n```bash\n# Via Raycast search\n# Type: \"Manage Extensions\"\n# View published extensions\n# Edit extension metadata\n# View analytics and usage\n```\n\n### Extension Store\n\n```bash\n# Via Raycast search\n# Type: \"Store\"\n# Browse and install published extensions\n# Search by category or keyword\n```\n\n## Environment Variables\n\n### Available at Runtime\n\n```typescript\nimport { environment } from \"@raycast/api\";\n\n// Raycast version\nenvironment.raycastVersion: string\n\n// Extension information\nenvironment.extensionName: string\nenvironment.commandName: string\nenvironment.commandMode: \"view\" | \"no-view\" | \"menu-bar\"\n\n// User preferences\nenvironment.appearance: \"dark\" | \"light\"\nenvironment.textSize: \"medium\" | \"large\"\n\n// Paths\nenvironment.assetsPath: string        // Path to assets/ directory\nenvironment.supportPath: string       // Path for extension data storage\n\n// Development flag\nenvironment.isDevelopment: boolean    // true in dev mode\n\n// Launch context\nenvironment.launchType: LaunchType    // UserInitiated | Background\n```\n\n### Using Preferences\n\n```typescript\nimport { getPreferenceValues } from \"@raycast/api\";\n\ninterface Preferences {\n  apiKey: string;\n  theme: string;\n  enableNotifications: boolean;\n}\n\nexport default function Command() {\n  const prefs = getPreferenceValues<Preferences>();\n  console.log(prefs.apiKey);\n  console.log(prefs.theme);\n}\n```\n\n## ESLint Configuration\n\n### Installing Raycast ESLint Config\n\n```bash\n# Install ESLint configuration\npnpm add -D @raycast/eslint-config eslint\n\n# Create .eslintrc.js\ncat > .eslintrc.js << 'EOF'\nmodule.exports = {\n  extends: \"@raycast\"\n};\nEOF\n\n# Run linter\npnpm lint\n\n# Fix issues automatically\npnpm lint --fix\n```\n\n### Custom ESLint Rules\n\n```javascript\n// .eslintrc.js\nmodule.exports = {\n  extends: \"@raycast\",\n  rules: {\n    // Add custom rules here\n    \"no-console\": \"warn\",\n    \"@typescript-eslint/explicit-module-boundary-types\": \"off\"\n  }\n};\n```\n\n## API Modules Reference\n\n### UI Components\n\n```typescript\nimport {\n  List,              // List view with items\n  Detail,            // Markdown detail view\n  Form,              // Form with inputs\n  Action,            // Action in ActionPanel\n  ActionPanel,       // Panel with actions\n  Icon,              // Built-in icons\n  Color,             // Built-in colors\n  MenuBarExtra,      // Menu bar dropdown\n  Grid,              // Grid view\n} from \"@raycast/api\";\n```\n\n### Utilities\n\n```typescript\nimport {\n  showToast,         // Show toast notification\n  Toast,             // Toast configuration\n  Clipboard,         // Clipboard operations\n  showHUD,           // Show HUD overlay\n  closeMainWindow,   // Close Raycast window\n  popToRoot,         // Navigate to root\n  openExtensionPreferences,  // Open preferences\n  getSelectedText,   // Get selected text\n  getSelectedFinderItems,    // Get Finder selection\n} from \"@raycast/api\";\n```\n\n### Data Storage\n\n```typescript\nimport {\n  LocalStorage,      // Key-value storage\n  Cache,             // Temporary cache\n} from \"@raycast/api\";\n```\n\n### Authentication\n\n```typescript\nimport {\n  OAuth,             // OAuth authentication\n} from \"@raycast/api\";\n```\n\n### System Integration\n\n```typescript\nimport {\n  open,              // Open URL or file\n  trash,             // Move to trash\n  showInFinder,      // Show in Finder\n  getApplications,   // List installed apps\n} from \"@raycast/api\";\n```\n\n## Command Flags and Options\n\n### Build Flags\n\n```bash\n# Specify output directory\nnpx ray build -e dist\nnpx ray build --export dist\n\n# Enable verbose logging\nnpx ray build --verbose\n```\n\n### Publish Flags\n\n```bash\n# Publish to specific organization\nnpx ray publish --org my-org\n\n# Skip validation (not recommended)\nnpx ray publish --skip-validation\n```\n\n### Development Flags\n\n```bash\n# Watch mode (default in develop)\nnpx ray develop\n\n# Specify port (if applicable)\nnpx ray develop --port 3000\n```\n\n## Version Information\n\n```bash\n# Show installed CLI version\nnpx ray --version\n\n# Show installed API version\ncat package.json | grep \"@raycast/api\"\n\n# Check for updates\nnpm outdated @raycast/api\npnpm outdated @raycast/api\n```\n\n## CI/CD Integration\n\n### GitHub Actions Example\n\n```yaml\nname: Publish Extension\n\non:\n  push:\n    branches: [main]\n\njobs:\n  publish:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - uses: actions/setup-node@v3\n        with:\n          node-version: \"18\"\n\n      - name: Install dependencies\n        run: npm install\n\n      - name: Lint extension\n        run: npm run lint\n\n      - name: Build extension\n        run: npm run build\n\n      - name: Publish to Raycast\n        env:\n          RAYCAST_TOKEN: ${{ secrets.RAYCAST_TOKEN }}\n        run: npm run publish\n```\n\n### CI Best Practices\n\n```bash\n# Always use package-lock.json\n# Raycast CI uses npm by default\nnpm install\n\n# Ensure consistent versions\n# CI should match local environment\n\n# Run all checks before publish\nnpm run lint && npm run build && npm run publish\n\n# Test locally before CI\nnpm run lint\nnpm run build\n```\n",
        "plugins/dev/skills/raycast-cli/reference/common-patterns.md": "# Raycast Extension Common Patterns\n\nReal-world patterns and workflows for building Raycast extensions.\n\n## Development Workflow Patterns\n\n### Basic Extension Development\n\n```bash\n# Create extension via Raycast\n# Open Raycast â†’ Type \"Create Extension\"\n# Select template or start from scratch\n\n# Navigate to extension directory\ncd ~/Developer/my-extension\n\n# Install dependencies\npnpm install\n\n# Start development mode\npnpm dev\n\n# Open Raycast (Cmd + Space)\n# Extension appears at top of root search\n# Test commands and functionality\n```\n\n### Hot Reload Development\n\n```bash\n# Start development mode\npnpm dev\n\n# Edit files in src/ directory\n# Changes reflect immediately in Raycast\n# View logs in terminal\n# View errors in Raycast overlay\n\n# Toggle hot reload in Preferences\n# Raycast â†’ Preferences â†’ Extensions â†’ Development\n# Toggle \"Auto-reload on file changes\"\n```\n\n### Testing Before Build\n\n```bash\n# Test in development mode\npnpm dev\n\n# Verify all commands work\n# Check error handling\n# Test edge cases\n# Verify preferences work\n\n# Run linter\npnpm lint\n\n# Build for production\npnpm build\n\n# Test production build in Raycast\n```\n\n## Extension Structure Patterns\n\n### Single Command Extension\n\n```typescript\n// src/index.tsx\nimport { List, ActionPanel, Action, Icon } from \"@raycast/api\";\n\nexport default function Command() {\n  return (\n    <List>\n      <List.Item\n        title=\"Item 1\"\n        subtitle=\"Description\"\n        icon={Icon.Star}\n        actions={\n          <ActionPanel>\n            <Action.OpenInBrowser url=\"https://example.com\" />\n          </ActionPanel>\n        }\n      />\n    </List>\n  );\n}\n```\n\n### Multi-Command Extension\n\n```\nsrc/\nâ”œâ”€â”€ search.tsx           # Search command\nâ”œâ”€â”€ create.tsx           # Create command\nâ”œâ”€â”€ settings.tsx         # Settings command\nâ””â”€â”€ utils/\n    â”œâ”€â”€ api.ts           # Shared API client\n    â””â”€â”€ types.ts         # Shared types\n```\n\n```json\n// package.json\n{\n  \"commands\": [\n    {\n      \"name\": \"search\",\n      \"title\": \"Search Items\",\n      \"description\": \"Search through items\",\n      \"mode\": \"view\"\n    },\n    {\n      \"name\": \"create\",\n      \"title\": \"Create Item\",\n      \"description\": \"Create a new item\",\n      \"mode\": \"view\"\n    },\n    {\n      \"name\": \"settings\",\n      \"title\": \"Extension Settings\",\n      \"description\": \"Configure extension\",\n      \"mode\": \"view\"\n    }\n  ]\n}\n```\n\n## API Integration Patterns\n\n### Basic API Client\n\n```typescript\n// src/utils/api.ts\nimport { getPreferenceValues } from \"@raycast/api\";\n\ninterface Preferences {\n  apiKey: string;\n  apiUrl: string;\n}\n\nexport class APIClient {\n  private apiKey: string;\n  private apiUrl: string;\n\n  constructor() {\n    const prefs = getPreferenceValues<Preferences>();\n    this.apiKey = prefs.apiKey;\n    this.apiUrl = prefs.apiUrl;\n  }\n\n  async fetchData(endpoint: string) {\n    const response = await fetch(`${this.apiUrl}${endpoint}`, {\n      headers: {\n        Authorization: `Bearer ${this.apiKey}`,\n        \"Content-Type\": \"application/json\",\n      },\n    });\n\n    if (!response.ok) {\n      throw new Error(`API error: ${response.status}`);\n    }\n\n    return response.json();\n  }\n}\n```\n\n### Error Handling Pattern\n\n```typescript\nimport { showToast, Toast } from \"@raycast/api\";\n\nexport default function Command() {\n  async function fetchData() {\n    try {\n      const data = await api.fetchData(\"/items\");\n      // Process data\n    } catch (error) {\n      await showToast({\n        style: Toast.Style.Failure,\n        title: \"Failed to fetch data\",\n        message: String(error),\n      });\n    }\n  }\n\n  return <List>...</List>;\n}\n```\n\n### Loading States Pattern\n\n```typescript\nimport { List } from \"@raycast/api\";\nimport { useState, useEffect } from \"react\";\n\nexport default function Command() {\n  const [items, setItems] = useState<Item[]>([]);\n  const [isLoading, setIsLoading] = useState(true);\n\n  useEffect(() => {\n    async function loadData() {\n      try {\n        const data = await api.fetchData(\"/items\");\n        setItems(data);\n      } finally {\n        setIsLoading(false);\n      }\n    }\n    loadData();\n  }, []);\n\n  return (\n    <List isLoading={isLoading}>\n      {items.map((item) => (\n        <List.Item key={item.id} title={item.name} />\n      ))}\n    </List>\n  );\n}\n```\n\n## Data Storage Patterns\n\n### LocalStorage for Persistence\n\n```typescript\nimport { LocalStorage } from \"@raycast/api\";\n\n// Save data\nawait LocalStorage.setItem(\"favorites\", JSON.stringify(favoriteItems));\n\n// Load data\nconst stored = await LocalStorage.getItem(\"favorites\");\nconst favorites = stored ? JSON.parse(stored) : [];\n\n// Remove data\nawait LocalStorage.removeItem(\"favorites\");\n\n// Clear all data\nawait LocalStorage.clear();\n```\n\n### Cache for Temporary Data\n\n```typescript\nimport { Cache } from \"@raycast/api\";\n\nconst cache = new Cache();\n\n// Store data (expires after session)\ncache.set(\"searchQuery\", query);\n\n// Retrieve data\nconst cached = cache.get(\"searchQuery\");\n\n// Check if exists\nconst hasCache = cache.has(\"searchQuery\");\n\n// Remove data\ncache.remove(\"searchQuery\");\n\n// Clear all cache\ncache.clear();\n```\n\n### Favorites Pattern\n\n```typescript\nimport { LocalStorage, Icon } from \"@raycast/api\";\n\nexport async function toggleFavorite(itemId: string) {\n  const stored = await LocalStorage.getItem(\"favorites\");\n  const favorites = stored ? JSON.parse(stored) : [];\n\n  const index = favorites.indexOf(itemId);\n  if (index > -1) {\n    favorites.splice(index, 1);\n  } else {\n    favorites.push(itemId);\n  }\n\n  await LocalStorage.setItem(\"favorites\", JSON.stringify(favorites));\n}\n\nexport async function isFavorite(itemId: string): Promise<boolean> {\n  const stored = await LocalStorage.getItem(\"favorites\");\n  const favorites = stored ? JSON.parse(stored) : [];\n  return favorites.includes(itemId);\n}\n```\n\n## UI Component Patterns\n\n### List with Search\n\n```typescript\nimport { List } from \"@raycast/api\";\nimport { useState } from \"react\";\n\nexport default function Command() {\n  const [searchText, setSearchText] = useState(\"\");\n  const [items, setItems] = useState<Item[]>([]);\n\n  // Filter items based on search\n  const filteredItems = items.filter((item) =>\n    item.name.toLowerCase().includes(searchText.toLowerCase())\n  );\n\n  return (\n    <List\n      searchBarPlaceholder=\"Search items...\"\n      onSearchTextChange={setSearchText}\n    >\n      {filteredItems.map((item) => (\n        <List.Item key={item.id} title={item.name} />\n      ))}\n    </List>\n  );\n}\n```\n\n### Detail View with Markdown\n\n```typescript\nimport { Detail, ActionPanel, Action } from \"@raycast/api\";\n\nexport default function Command() {\n  const markdown = `\n# Title\n\n## Subtitle\n\n- Item 1\n- Item 2\n\n**Bold text** and *italic text*\n\n\\`\\`\\`typescript\nconst code = \"example\";\n\\`\\`\\`\n  `;\n\n  return (\n    <Detail\n      markdown={markdown}\n      actions={\n        <ActionPanel>\n          <Action.CopyToClipboard content={markdown} />\n        </ActionPanel>\n      }\n    />\n  );\n}\n```\n\n### Form with Validation\n\n```typescript\nimport { Form, ActionPanel, Action, showToast, Toast } from \"@raycast/api\";\nimport { useState } from \"react\";\n\nexport default function Command() {\n  const [nameError, setNameError] = useState<string | undefined>();\n\n  function validateName(value: string | undefined) {\n    if (!value || value.length === 0) {\n      setNameError(\"Name is required\");\n    } else if (value.length < 3) {\n      setNameError(\"Name must be at least 3 characters\");\n    } else {\n      setNameError(undefined);\n    }\n  }\n\n  async function handleSubmit(values: { name: string; email: string }) {\n    if (nameError) {\n      await showToast({\n        style: Toast.Style.Failure,\n        title: \"Validation failed\",\n        message: nameError,\n      });\n      return;\n    }\n\n    // Process form data\n    await showToast({\n      style: Toast.Style.Success,\n      title: \"Success\",\n      message: \"Form submitted\",\n    });\n  }\n\n  return (\n    <Form\n      actions={\n        <ActionPanel>\n          <Action.SubmitForm onSubmit={handleSubmit} />\n        </ActionPanel>\n      }\n    >\n      <Form.TextField\n        id=\"name\"\n        title=\"Name\"\n        placeholder=\"Enter name\"\n        error={nameError}\n        onChange={validateName}\n        onBlur={(event) => validateName(event.target.value)}\n      />\n      <Form.TextField\n        id=\"email\"\n        title=\"Email\"\n        placeholder=\"Enter email\"\n      />\n    </Form>\n  );\n}\n```\n\n## Authentication Patterns\n\n### OAuth Flow\n\n```typescript\nimport { OAuth } from \"@raycast/api\";\n\nconst client = new OAuth.PKCEClient({\n  redirectMethod: OAuth.RedirectMethod.Web,\n  providerName: \"GitHub\",\n  providerIcon: \"github-logo.png\",\n  providerId: \"github\",\n  description: \"Connect your GitHub account\",\n});\n\nexport async function authorize(): Promise<string> {\n  const tokenSet = await client.getTokens();\n  if (tokenSet?.accessToken) {\n    return tokenSet.accessToken;\n  }\n\n  const authRequest = await client.authorizationRequest({\n    endpoint: \"https://github.com/login/oauth/authorize\",\n    clientId: \"your-client-id\",\n    scope: \"repo user\",\n  });\n\n  const { authorizationCode } = await client.authorize(authRequest);\n\n  const tokens = await fetchTokens(authRequest, authorizationCode);\n  await client.setTokens(tokens);\n\n  return tokens.access_token;\n}\n\nasync function fetchTokens(\n  authRequest: OAuth.AuthorizationRequest,\n  authCode: string\n): Promise<OAuth.TokenResponse> {\n  const response = await fetch(\"https://github.com/login/oauth/access_token\", {\n    method: \"POST\",\n    headers: { \"Content-Type\": \"application/json\" },\n    body: JSON.stringify({\n      client_id: \"your-client-id\",\n      client_secret: \"your-client-secret\",\n      code: authCode,\n      code_verifier: authRequest.codeVerifier,\n      grant_type: \"authorization_code\",\n      redirect_uri: authRequest.redirectURI,\n    }),\n  });\n\n  return response.json();\n}\n```\n\n### API Key Authentication\n\n```typescript\n// Define preferences in package.json\n{\n  \"preferences\": [\n    {\n      \"name\": \"apiKey\",\n      \"type\": \"password\",\n      \"required\": true,\n      \"title\": \"API Key\",\n      \"description\": \"Your API key from the service\"\n    }\n  ]\n}\n\n// Use in command\nimport { getPreferenceValues } from \"@raycast/api\";\n\ninterface Preferences {\n  apiKey: string;\n}\n\nexport default function Command() {\n  const { apiKey } = getPreferenceValues<Preferences>();\n\n  async function makeRequest() {\n    const response = await fetch(\"https://api.example.com/data\", {\n      headers: {\n        Authorization: `Bearer ${apiKey}`,\n      },\n    });\n    return response.json();\n  }\n}\n```\n\n## Action Patterns\n\n### Common Actions\n\n```typescript\nimport { ActionPanel, Action, Icon } from \"@raycast/api\";\n\n<ActionPanel>\n  {/* Open URL */}\n  <Action.OpenInBrowser url=\"https://example.com\" />\n\n  {/* Copy to clipboard */}\n  <Action.CopyToClipboard content=\"Text to copy\" />\n\n  {/* Push new view */}\n  <Action.Push\n    title=\"View Details\"\n    target={<DetailView item={item} />}\n    icon={Icon.Eye}\n  />\n\n  {/* Run callback */}\n  <Action\n    title=\"Delete Item\"\n    icon={Icon.Trash}\n    onAction={async () => {\n      await deleteItem(item.id);\n    }}\n  />\n\n  {/* Open with specific app */}\n  <Action.Open\n    title=\"Open in VS Code\"\n    target=\"/path/to/file\"\n    application=\"Visual Studio Code\"\n  />\n\n  {/* Show in Finder */}\n  <Action.ShowInFinder path=\"/path/to/file\" />\n</ActionPanel>\n```\n\n### Keyboard Shortcuts\n\n```typescript\nimport { ActionPanel, Action, Icon } from \"@raycast/api\";\n\n<ActionPanel>\n  <Action.OpenInBrowser\n    url=\"https://example.com\"\n    shortcut={{ modifiers: [\"cmd\"], key: \"o\" }}\n  />\n  <Action.CopyToClipboard\n    content=\"Text\"\n    shortcut={{ modifiers: [\"cmd\"], key: \"c\" }}\n  />\n  <Action\n    title=\"Delete\"\n    icon={Icon.Trash}\n    shortcut={{ modifiers: [\"cmd\"], key: \"d\" }}\n    onAction={deleteItem}\n  />\n</ActionPanel>\n```\n\n## Menu Bar Extensions\n\n### Simple Menu Bar\n\n```typescript\nimport { MenuBarExtra, Icon } from \"@raycast/api\";\n\nexport default function Command() {\n  return (\n    <MenuBarExtra icon={Icon.Star} tooltip=\"My Extension\">\n      <MenuBarExtra.Item\n        title=\"Action 1\"\n        onAction={() => console.log(\"Action 1\")}\n      />\n      <MenuBarExtra.Item\n        title=\"Action 2\"\n        onAction={() => console.log(\"Action 2\")}\n      />\n      <MenuBarExtra.Separator />\n      <MenuBarExtra.Item\n        title=\"Settings\"\n        onAction={() => console.log(\"Settings\")}\n      />\n    </MenuBarExtra>\n  );\n}\n```\n\n### Dynamic Menu Bar with State\n\n```typescript\nimport { MenuBarExtra, Icon } from \"@raycast/api\";\nimport { useState, useEffect } from \"react\";\n\nexport default function Command() {\n  const [count, setCount] = useState(0);\n\n  useEffect(() => {\n    // Update count periodically\n    const interval = setInterval(() => {\n      setCount((prev) => prev + 1);\n    }, 5000);\n    return () => clearInterval(interval);\n  }, []);\n\n  return (\n    <MenuBarExtra icon={Icon.Circle} tooltip={`Count: ${count}`}>\n      <MenuBarExtra.Item title={`Current Count: ${count}`} />\n      <MenuBarExtra.Item\n        title=\"Reset\"\n        onAction={() => setCount(0)}\n      />\n    </MenuBarExtra>\n  );\n}\n```\n\n## Background Commands\n\n### Scheduled Background Task\n\n```json\n// package.json\n{\n  \"commands\": [\n    {\n      \"name\": \"sync\",\n      \"title\": \"Background Sync\",\n      \"description\": \"Syncs data in background\",\n      \"mode\": \"no-view\",\n      \"interval\": \"1h\"\n    }\n  ]\n}\n```\n\n```typescript\n// src/sync.tsx\nimport { LaunchType, environment, showHUD } from \"@raycast/api\";\n\nexport default async function Command() {\n  // Check if launched in background\n  if (environment.launchType === LaunchType.Background) {\n    // Perform sync operation\n    await syncData();\n    return; // Don't show UI\n  }\n\n  // Manual launch - show notification\n  await showHUD(\"Sync completed\");\n}\n\nasync function syncData() {\n  // Sync logic here\n  console.log(\"Background sync running...\");\n}\n```\n\n## Publishing Patterns\n\n### Pre-Publish Checklist\n\n```bash\n# 1. Verify all commands work\npnpm dev\n# Test each command thoroughly\n\n# 2. Run linter\npnpm lint\n# Fix any issues\n\n# 3. Build extension\npnpm build\n# Verify build succeeds\n\n# 4. Add README.md\ncat > README.md << 'EOF'\n# Extension Name\n\nDescription\n\n## Features\n- Feature 1\n- Feature 2\n\n## Setup\n1. Install extension\n2. Configure preferences\nEOF\n\n# 5. Add screenshots to assets/\n# Take screenshots of each command\n\n# 6. Update package.json metadata\n# Verify title, description, author\n\n# 7. Publish\npnpm publish\n```\n\n### Version Management\n\n```bash\n# Update version in package.json\nnpm version patch   # 1.0.0 -> 1.0.1\nnpm version minor   # 1.0.0 -> 1.1.0\nnpm version major   # 1.0.0 -> 2.0.0\n\n# Publish updated version\npnpm publish\n```\n\n## Performance Optimization\n\n### Debounced Search\n\n```typescript\nimport { useState, useEffect, useRef } from \"react\";\n\nexport function useDebounce<T>(value: T, delay: number): T {\n  const [debouncedValue, setDebouncedValue] = useState(value);\n\n  useEffect(() => {\n    const handler = setTimeout(() => {\n      setDebouncedValue(value);\n    }, delay);\n\n    return () => {\n      clearTimeout(handler);\n    };\n  }, [value, delay]);\n\n  return debouncedValue;\n}\n\n// Usage in command\nexport default function Command() {\n  const [searchText, setSearchText] = useState(\"\");\n  const debouncedSearch = useDebounce(searchText, 300);\n\n  useEffect(() => {\n    // Only search when debounced value changes\n    if (debouncedSearch) {\n      performSearch(debouncedSearch);\n    }\n  }, [debouncedSearch]);\n\n  return <List onSearchTextChange={setSearchText}>...</List>;\n}\n```\n\n### Lazy Loading\n\n```typescript\nimport { List } from \"@raycast/api\";\nimport { useState, useEffect } from \"react\";\n\nexport default function Command() {\n  const [items, setItems] = useState<Item[]>([]);\n  const [isLoading, setIsLoading] = useState(false);\n  const [page, setPage] = useState(1);\n\n  async function loadMore() {\n    setIsLoading(true);\n    const newItems = await fetchPage(page);\n    setItems([...items, ...newItems]);\n    setPage(page + 1);\n    setIsLoading(false);\n  }\n\n  return (\n    <List\n      isLoading={isLoading}\n      onSelectionChange={(id) => {\n        // Load more when near end\n        if (id === items[items.length - 1]?.id) {\n          loadMore();\n        }\n      }}\n    >\n      {items.map((item) => (\n        <List.Item key={item.id} title={item.name} />\n      ))}\n    </List>\n  );\n}\n```\n\n## Testing Patterns\n\n### Manual Testing Workflow\n\n```bash\n# 1. Start development mode\npnpm dev\n\n# 2. Open Raycast\n# Extension appears at top\n\n# 3. Test each command\n# - Happy path\n# - Error cases\n# - Edge cases\n\n# 4. Test preferences\n# - Open extension preferences\n# - Verify all settings work\n\n# 5. Test keyboard shortcuts\n# - Verify all shortcuts work\n# - No conflicts with system shortcuts\n\n# 6. Check console logs\n# View terminal for logs and errors\n```\n\n### Debug Logging\n\n```typescript\n// Development logging\nif (environment.isDevelopment) {\n  console.log(\"Debug info:\", data);\n}\n\n// Always log errors\nconsole.error(\"Error occurred:\", error);\n\n// Log with context\nconsole.log(`[${environment.commandName}] Processing item ${id}`);\n```\n",
        "plugins/dev/skills/raycast-cli/reference/troubleshooting.md": "# Raycast Extension Troubleshooting Guide\n\nCommon issues and solutions for Raycast extension development and deployment.\n\n## Extension Development Issues\n\n### Extension Not Appearing in Raycast\n\n**Symptom:** Extension doesn't show up after running `pnpm dev`\n\n**Diagnosis:**\n```bash\n# Check if dev mode is running\npnpm dev\n# Look for success message in terminal\n\n# Check Raycast development settings\n# Raycast â†’ Preferences â†’ Extensions â†’ Development\n# Verify \"Show Development Extensions\" is enabled\n\n# Check for build errors in terminal\n# Look for TypeScript or build errors\n```\n\n**Solutions:**\n```bash\n# Restart development mode\n# Press Ctrl+C to stop\npnpm dev\n\n# Restart Raycast\n# Cmd+Q to quit Raycast completely\n# Open Raycast again\n\n# Verify package.json is valid\ncat package.json | jq .\n# Should parse without errors\n\n# Check extension location\n# Raycast only loads from specific locations\npwd\n# Should be in ~/Developer or configured location\n\n# Re-import extension manually\n# Raycast â†’ Type \"Import Extension\"\n# Browse to extension directory\n```\n\n### Hot Reload Not Working\n\n**Symptom:** Changes to code don't reflect in Raycast\n\n**Diagnosis:**\n```bash\n# Check if auto-reload is enabled\n# Raycast â†’ Preferences â†’ Extensions â†’ Development\n# \"Auto-reload on file changes\" should be ON\n\n# Check terminal for rebuild messages\n# Should see \"Rebuilding...\" on file save\n\n# Check for TypeScript errors\n# Errors can prevent rebuild\n```\n\n**Solutions:**\n```bash\n# Toggle auto-reload\n# Raycast â†’ Preferences â†’ Extensions â†’ Development\n# Toggle \"Auto-reload on file changes\" OFF and ON\n\n# Restart development mode\n# Ctrl+C to stop\npnpm dev\n\n# Clear Raycast cache\n# Raycast â†’ Settings â†’ Advanced â†’ Clear Cache\n# Restart Raycast after clearing\n\n# Manually reload extension\n# Cmd+R in Raycast to reload current extension\n```\n\n### TypeScript Errors in Development\n\n**Symptom:** TypeScript compilation errors in terminal\n\n**Diagnosis:**\n```bash\n# Check TypeScript version\nnpx tsc --version\n\n# View full error details\npnpm dev\n# Read error messages carefully\n\n# Check tsconfig.json\ncat tsconfig.json\n# Verify configuration is valid\n```\n\n**Solutions:**\n```bash\n# Update @raycast/api to latest\npnpm update @raycast/api\n\n# Run migration tool\nnpx ray migrate\n\n# Fix import statements\n# Ensure all imports are from @raycast/api\nimport { List } from \"@raycast/api\";\n\n# Check for missing type definitions\npnpm add -D @types/node @types/react\n\n# Verify tsconfig.json settings\ncat > tsconfig.json << 'EOF'\n{\n  \"compilerOptions\": {\n    \"target\": \"ES2020\",\n    \"module\": \"commonjs\",\n    \"jsx\": \"react\",\n    \"strict\": true,\n    \"esModuleInterop\": true,\n    \"skipLibCheck\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"resolveJsonModule\": true\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"node_modules\"]\n}\nEOF\n```\n\n### Build Errors\n\n**Symptom:** `pnpm build` fails with errors\n\n**Common Errors:**\n\n**Error: \"Cannot find module '@raycast/api'\"**\n```bash\n# Solution: Install dependencies\nrm -rf node_modules package-lock.json\npnpm install\n\n# Verify @raycast/api is in dependencies\ncat package.json | grep \"@raycast/api\"\n```\n\n**Error: \"Invalid package.json\"**\n```bash\n# Solution: Validate JSON syntax\ncat package.json | jq .\n\n# Check required fields\n# - name, title, description, icon\n# - commands array\n# - dependencies with @raycast/api\n\n# Fix with valid package.json structure\n```\n\n**Error: \"Missing assets\"**\n```bash\n# Solution: Add required assets\nls assets/\n# Should have icon.png (512x512)\n\n# Add icon if missing\n# Create 512x512 PNG icon\n# Save to assets/icon.png\n\n# Update package.json\n# \"icon\": \"icon.png\"\n```\n\n### Runtime Errors\n\n**Symptom:** Extension crashes or shows error overlay\n\n**Diagnosis:**\n```bash\n# Check terminal logs\npnpm dev\n# View error messages and stack traces\n\n# Check error overlay in Raycast\n# Shows detailed error with stack trace\n# Click for more details\n\n# Check browser console (if using web)\n# Right-click error overlay â†’ Inspect Element\n```\n\n**Solutions:**\n```typescript\n// Add error handling\ntry {\n  const data = await fetchData();\n} catch (error) {\n  console.error(\"Error:\", error);\n  await showToast({\n    style: Toast.Style.Failure,\n    title: \"Error\",\n    message: String(error),\n  });\n}\n\n// Validate data before use\nif (!data || !Array.isArray(data)) {\n  throw new Error(\"Invalid data format\");\n}\n\n// Handle async operations properly\nuseEffect(() => {\n  let isMounted = true;\n\n  async function loadData() {\n    try {\n      const result = await fetchData();\n      if (isMounted) {\n        setData(result);\n      }\n    } catch (error) {\n      console.error(error);\n    }\n  }\n\n  loadData();\n  return () => { isMounted = false; };\n}, []);\n```\n\n## API Integration Issues\n\n### API Authentication Fails\n\n**Symptom:** API requests return 401 Unauthorized\n\n**Diagnosis:**\n```bash\n# Check if API key is set\n# Raycast â†’ Extension Preferences\n# Verify API key is configured\n\n# Test API key manually\ncurl -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  https://api.example.com/test\n```\n\n**Solutions:**\n```typescript\n// Validate API key before use\nimport { getPreferenceValues } from \"@raycast/api\";\n\ninterface Preferences {\n  apiKey: string;\n}\n\nconst { apiKey } = getPreferenceValues<Preferences>();\n\nif (!apiKey || apiKey.trim() === \"\") {\n  await showToast({\n    style: Toast.Style.Failure,\n    title: \"API Key Required\",\n    message: \"Please configure your API key in preferences\",\n  });\n  return;\n}\n\n// Include proper headers\nconst response = await fetch(url, {\n  headers: {\n    \"Authorization\": `Bearer ${apiKey}`,\n    \"Content-Type\": \"application/json\",\n  },\n});\n```\n\n### API Requests Timing Out\n\n**Symptom:** Requests hang or timeout\n\n**Solutions:**\n```typescript\n// Add timeout to fetch requests\nconst controller = new AbortController();\nconst timeoutId = setTimeout(() => controller.abort(), 10000); // 10s timeout\n\ntry {\n  const response = await fetch(url, {\n    signal: controller.signal,\n  });\n  clearTimeout(timeoutId);\n  return response.json();\n} catch (error) {\n  if (error.name === \"AbortError\") {\n    throw new Error(\"Request timeout\");\n  }\n  throw error;\n}\n\n// Show loading state\nconst [isLoading, setIsLoading] = useState(true);\n\nuseEffect(() => {\n  const fetchData = async () => {\n    try {\n      const data = await api.fetchData();\n      setData(data);\n    } finally {\n      setIsLoading(false);\n    }\n  };\n  fetchData();\n}, []);\n\nreturn <List isLoading={isLoading}>...</List>;\n```\n\n### CORS Errors\n\n**Symptom:** API requests fail with CORS error\n\n**Diagnosis:**\n```bash\n# Check browser console (if applicable)\n# CORS errors appear in browser console\n\n# Test API with curl\ncurl -I https://api.example.com/endpoint\n# Check Access-Control-Allow-Origin header\n```\n\n**Solutions:**\n```typescript\n// Raycast extensions run in Node.js context\n// CORS doesn't apply to server-side requests\n\n// If seeing CORS errors:\n// 1. Check if using browser-only API\n// 2. Use Node.js fetch (built-in in Node 18+)\n// 3. Don't use browser-specific APIs\n\n// Correct approach for Raycast\nconst response = await fetch(url); // Works in Node.js\n\n// Incorrect approach\n// window.fetch() // Not available in Raycast\n```\n\n## Data Storage Issues\n\n### LocalStorage Not Persisting\n\n**Symptom:** Data lost between sessions\n\n**Diagnosis:**\n```typescript\n// Check if data is being saved\nawait LocalStorage.setItem(\"key\", \"value\");\nconsole.log(\"Saved:\", await LocalStorage.getItem(\"key\"));\n\n// Check for errors\ntry {\n  await LocalStorage.setItem(\"key\", JSON.stringify(data));\n} catch (error) {\n  console.error(\"Storage error:\", error);\n}\n```\n\n**Solutions:**\n```typescript\n// Ensure proper serialization\n// LocalStorage only stores strings\nawait LocalStorage.setItem(\"data\", JSON.stringify(complexObject));\n\n// Retrieve and parse\nconst stored = await LocalStorage.getItem(\"data\");\nconst data = stored ? JSON.parse(stored) : defaultValue;\n\n// Handle parse errors\ntry {\n  const data = JSON.parse(stored);\n} catch (error) {\n  console.error(\"Failed to parse stored data:\", error);\n  // Use default value\n  const data = defaultValue;\n}\n\n// Check storage limits\n// Avoid storing extremely large data\nconst dataSize = new Blob([stored]).size;\nif (dataSize > 1000000) { // 1MB\n  console.warn(\"Stored data is very large:\", dataSize);\n}\n```\n\n### Cache Not Working\n\n**Symptom:** Cache data not retrieved correctly\n\n**Solutions:**\n```typescript\n// Create cache instance properly\nimport { Cache } from \"@raycast/api\";\n\nconst cache = new Cache();\n\n// Store data\ncache.set(\"key\", JSON.stringify(data));\n\n// Retrieve data\nconst cached = cache.get(\"key\");\nif (cached) {\n  const data = JSON.parse(cached);\n}\n\n// Check if key exists\nif (cache.has(\"key\")) {\n  const data = JSON.parse(cache.get(\"key\"));\n}\n\n// Clear specific key\ncache.remove(\"key\");\n\n// Clear all cache\ncache.clear();\n\n// Note: Cache is temporary and cleared between sessions\n// Use LocalStorage for persistent data\n```\n\n## UI Component Issues\n\n### List Items Not Rendering\n\n**Symptom:** List appears empty despite having data\n\n**Diagnosis:**\n```typescript\n// Add debug logging\nconsole.log(\"Items:\", items);\nconsole.log(\"Items length:\", items.length);\n\n// Check if items is array\nconsole.log(\"Is array:\", Array.isArray(items));\n\n// Check for rendering errors\n// Look at error overlay or terminal\n```\n\n**Solutions:**\n```typescript\n// Ensure items is array\nconst [items, setItems] = useState<Item[]>([]);\n\n// Add fallback for empty state\n<List>\n  {items.length === 0 ? (\n    <List.EmptyView\n      title=\"No items found\"\n      description=\"Try adjusting your search\"\n    />\n  ) : (\n    items.map((item) => (\n      <List.Item key={item.id} title={item.name} />\n    ))\n  )}\n</List>\n\n// Add key prop to items\nitems.map((item) => (\n  <List.Item key={item.id} title={item.name} />\n))\n\n// Check data structure\ninterface Item {\n  id: string;\n  name: string;\n}\n```\n\n### Form Validation Not Working\n\n**Symptom:** Form submits with invalid data\n\n**Solutions:**\n```typescript\n// Add proper validation\nconst [nameError, setNameError] = useState<string | undefined>();\n\nfunction validateName(value: string | undefined) {\n  if (!value || value.length === 0) {\n    setNameError(\"Name is required\");\n  } else if (value.length < 3) {\n    setNameError(\"Name must be at least 3 characters\");\n  } else {\n    setNameError(undefined);\n  }\n}\n\n// Use onBlur for validation\n<Form.TextField\n  id=\"name\"\n  title=\"Name\"\n  error={nameError}\n  onChange={validateName}\n  onBlur={(event) => validateName(event.target.value)}\n/>\n\n// Prevent submission if invalid\nasync function handleSubmit(values: FormValues) {\n  if (nameError) {\n    await showToast({\n      style: Toast.Style.Failure,\n      title: \"Validation failed\",\n      message: nameError,\n    });\n    return;\n  }\n  // Process valid data\n}\n```\n\n### Actions Not Triggering\n\n**Symptom:** Clicking action does nothing\n\n**Solutions:**\n```typescript\n// Use correct action syntax\n<ActionPanel>\n  <Action\n    title=\"My Action\"\n    onAction={async () => {\n      console.log(\"Action triggered\");\n      await performAction();\n    }}\n  />\n</ActionPanel>\n\n// Add error handling in actions\n<Action\n  title=\"Delete\"\n  onAction={async () => {\n    try {\n      await deleteItem();\n      await showToast({\n        style: Toast.Style.Success,\n        title: \"Deleted\",\n      });\n    } catch (error) {\n      await showToast({\n        style: Toast.Style.Failure,\n        title: \"Error\",\n        message: String(error),\n      });\n    }\n  }}\n/>\n\n// Check for async issues\n// Always use async/await for actions\n<Action\n  onAction={async () => {\n    await someAsyncOperation();\n  }}\n/>\n```\n\n## Publishing Issues\n\n### Publish Command Fails\n\n**Symptom:** `pnpm publish` fails with error\n\n**Common Errors:**\n\n**Error: \"Missing README.md\"**\n```bash\n# Solution: Add README.md\ncat > README.md << 'EOF'\n# Extension Name\n\nDescription of what this extension does.\n\n## Features\n\n- Feature 1\n- Feature 2\nEOF\n```\n\n**Error: \"Missing screenshots\"**\n```bash\n# Solution: Add screenshots to assets/\n# Take screenshots of each command\n# Save as PNG in assets/ directory\n# Must have at least 1 screenshot\n\nls assets/\n# Should contain:\n# - icon.png (required)\n# - screenshot-1.png (required)\n# - screenshot-2.png (optional)\n```\n\n**Error: \"Invalid metadata\"**\n```bash\n# Solution: Verify package.json\ncat package.json | jq .\n\n# Check required fields:\n# - name (lowercase, no spaces)\n# - title (display name)\n# - description (clear description)\n# - icon (points to assets/icon.png)\n# - author (your name or username)\n# - commands (at least one command)\n```\n\n**Error: \"Build failed\"**\n```bash\n# Solution: Fix build errors first\npnpm build\n# Resolve all errors\n\n# Then publish\npnpm publish\n```\n\n### Authentication Issues\n\n**Symptom:** Cannot authenticate for publishing\n\n**Solutions:**\n```bash\n# For public extensions\n# Authenticate with GitHub\n# Follow prompts in terminal\n\n# For private extensions\n# Ensure you're member of organization\n# Contact organization admin if needed\n\n# Check authentication status\n# Try publishing again\npnpm publish\n```\n\n### Pull Request Not Created\n\n**Symptom:** Publish succeeds but no PR created\n\n**Solutions:**\n```bash\n# Check GitHub authentication\n# Re-run publish command\npnpm publish\n\n# Manually create PR\n# 1. Fork raycast/extensions on GitHub\n# 2. Clone your fork\n# 3. Copy extension to extensions/ directory\n# 4. Commit and push\n# 5. Create PR from your fork\n\n# Check for automated checks\n# Wait for CI/CD to complete\n# Fix any failing checks\n```\n\n## Performance Issues\n\n### Extension Slow to Load\n\n**Symptom:** Extension takes long time to open\n\n**Solutions:**\n```typescript\n// Optimize data loading\n// Load data asynchronously\nuseEffect(() => {\n  async function loadData() {\n    const data = await fetchData();\n    setData(data);\n  }\n  loadData();\n}, []);\n\n// Use pagination for large datasets\nconst [items, setItems] = useState<Item[]>([]);\nconst [page, setPage] = useState(1);\nconst ITEMS_PER_PAGE = 50;\n\n// Load only visible items\nconst visibleItems = items.slice(0, page * ITEMS_PER_PAGE);\n\n// Use debouncing for search\nimport { useDebounce } from \"./utils\";\n\nconst [searchText, setSearchText] = useState(\"\");\nconst debouncedSearch = useDebounce(searchText, 300);\n\nuseEffect(() => {\n  if (debouncedSearch) {\n    performSearch(debouncedSearch);\n  }\n}, [debouncedSearch]);\n\n// Cache expensive computations\nimport { Cache } from \"@raycast/api\";\n\nconst cache = new Cache();\n\nasync function getData() {\n  const cached = cache.get(\"data\");\n  if (cached) {\n    return JSON.parse(cached);\n  }\n\n  const data = await fetchData();\n  cache.set(\"data\", JSON.stringify(data));\n  return data;\n}\n```\n\n### Search Performance Issues\n\n**Symptom:** Search is slow or unresponsive\n\n**Solutions:**\n```typescript\n// Implement debouncing\nfunction useDebounce<T>(value: T, delay: number): T {\n  const [debouncedValue, setDebouncedValue] = useState(value);\n\n  useEffect(() => {\n    const handler = setTimeout(() => {\n      setDebouncedValue(value);\n    }, delay);\n\n    return () => clearTimeout(handler);\n  }, [value, delay]);\n\n  return debouncedValue;\n}\n\n// Use in search\nconst [searchText, setSearchText] = useState(\"\");\nconst debouncedSearch = useDebounce(searchText, 300);\n\n// Index data for faster search\nconst searchIndex = useMemo(() => {\n  return items.map(item => ({\n    id: item.id,\n    searchableText: `${item.name} ${item.description}`.toLowerCase(),\n  }));\n}, [items]);\n\n// Filter using index\nconst filtered = useMemo(() => {\n  const query = debouncedSearch.toLowerCase();\n  return searchIndex\n    .filter(item => item.searchableText.includes(query))\n    .map(item => items.find(i => i.id === item.id))\n    .filter(Boolean);\n}, [debouncedSearch, searchIndex]);\n```\n\n## Debugging Tips\n\n### Enable Detailed Logging\n\n```typescript\n// Log to terminal (visible in pnpm dev)\nconsole.log(\"Debug info:\", data);\nconsole.error(\"Error:\", error);\nconsole.warn(\"Warning:\", warning);\n\n// Conditional logging\nif (environment.isDevelopment) {\n  console.log(\"Development mode:\", data);\n}\n\n// Log with context\nconsole.log(`[${environment.commandName}] Processing:`, data);\n```\n\n### Use Error Boundaries\n\n```typescript\n// Wrap components in try-catch\nexport default function Command() {\n  const [error, setError] = useState<Error | null>(null);\n\n  if (error) {\n    return (\n      <Detail\n        markdown={`# Error\\n\\n${error.message}\\n\\n\\`\\`\\`\\n${error.stack}\\`\\`\\``}\n      />\n    );\n  }\n\n  try {\n    return <MainView />;\n  } catch (err) {\n    setError(err as Error);\n    return null;\n  }\n}\n```\n\n### Inspect Extension State\n\n```typescript\n// Log environment\nconsole.log(\"Environment:\", environment);\n\n// Log preferences\nconst prefs = getPreferenceValues();\nconsole.log(\"Preferences:\", prefs);\n\n// Log cache state\nconsole.log(\"Cache has data:\", cache.has(\"key\"));\n\n// Log localStorage\nconst stored = await LocalStorage.allItems();\nconsole.log(\"LocalStorage:\", stored);\n```\n\n## Getting Help\n\n### Resources\n\n```bash\n# Official documentation\nopen https://developers.raycast.com\n\n# API reference\nopen https://developers.raycast.com/api-reference\n\n# Community examples\nopen https://github.com/raycast/extensions\n\n# Community forum\nopen https://raycast.com/community\n\n# Report bugs\nopen https://github.com/raycast/extensions/issues\n```\n\n### Common Debug Commands\n\n```bash\n# View extension logs\npnpm dev\n# Watch terminal output\n\n# Clear Raycast cache\n# Raycast â†’ Settings â†’ Advanced â†’ Clear Cache\n\n# Restart Raycast\n# Cmd+Q to quit\n# Reopen Raycast\n\n# Check Node.js version\nnode --version\n# Should be 22.14 or higher\n\n# Check Raycast version\n# Raycast â†’ About Raycast\n# Should be 1.26.0 or higher\n\n# Reinstall dependencies\nrm -rf node_modules package-lock.json\npnpm install\n```\n",
        "plugins/dev/skills/spec-kit/SKILL.md": "---\nname: spec-kit\ndescription: Specification-Driven Development methodology from GitHub spec-kit. Use when users ask to create specifications, plan features, define requirements, write user stories, decompose tasks, establish project constitution, or follow SDD workflow.\nallowed-tools: Read, Write, Grep, Glob\n---\n\n# Specification-Driven Development (SDD)\n\nComprehensive implementation of GitHub's [spec-kit](https://github.com/github/spec-kit) methodology where specifications become executable, directly generating functional implementations.\n\n**Source**: This skill is based on the official [GitHub spec-kit](https://github.com/github/spec-kit) project - an open-source toolkit that implements Specification-Driven Development.\n\n## Quick Start\n\nWhen a user needs to develop a feature or start a project, follow this workflow:\n\n1. **Constitution** - Establish project principles (`/speckit.constitution`)\n2. **Specification** - Define requirements (what and why, not how) (`/speckit.specify`)\n3. **Clarification** - Address ambiguities with 5 targeted questions (`/speckit.clarify` - optional)\n4. **Planning** - Create technical implementation strategy (`/speckit.plan`)\n5. **Tasks** - Generate executable task breakdown (`/speckit.tasks`)\n6. **Implementation** - Execute according to plan (`/speckit.implement`)\n\n**Note**: The official spec-kit includes slash commands for Claude Code integration. This skill provides the same workflow without requiring the CLI installation.\n\n## Decision Tree\n\n```text\nSDD Request â†’ What stage?\n    â”‚\n    â”œâ”€ New Project / Feature\n    â”‚   â”œâ”€ Create constitution.md (principles)\n    â”‚   â”œâ”€ Write spec.md (requirements)\n    â”‚   â”œâ”€ Run clarification (5 questions)\n    â”‚   â”œâ”€ Generate plan.md (technical)\n    â”‚   â”œâ”€ Create tasks.md (breakdown)\n    â”‚   â””â”€ Implement according to tasks\n    â”‚\n    â”œâ”€ Existing Specifications\n    â”‚   â”œâ”€ Analyze consistency across artifacts\n    â”‚   â”œâ”€ Identify gaps or ambiguities\n    â”‚   â””â”€ Suggest improvements\n    â”‚\n    â””â”€ Documentation Only\n        â”œâ”€ Extract specifications from code\n        â””â”€ Generate reverse-engineered docs\n```\n\n## Core Philosophy\n\nSpec-Kit inverts traditional development:\n\n- **Traditional**: Write code â†’ Document later\n- **Spec-Driven**: Write specifications â†’ Generate code\n\nSpecifications are the **first artifact**, and code is their expression in a particular language.\n\n## The 9 Constitutional Articles\n\nFor complete details on each article with implementation examples and validation checklists, see [Constitutional Articles](reference/constitutional-articles.md).\n\n**Summary**:\n\n1. **Library-First** - Features as reusable libraries before integration\n2. **CLI Interface** - All functionality via CLI (text in, text out)\n3. **Test-First (NON-NEGOTIABLE)** - Tests before implementation, always\n4. **Documentation Standards** - Document public APIs with examples\n5. **Code Quality** - Linters, formatters, type checking\n6. **Version Control** - Semantic versioning, conventional commits\n7. **Simplicity** - Max 3 initial projects, justify abstractions\n8. **Justify Abstractions** - Only after 3rd duplication (Rule of Three)\n9. **Integration-First** - Real databases/services, minimal mocking\n\n**Critical**: Article III (Test-First) is non-negotiable. Write failing tests first, verify they fail, then implement.\n\n## Workflow Phases\n\nFor complete details on each phase with templates, examples, and best practices, see [Workflow Guide](reference/workflow-guide.md).\n\n### Phase 1: Constitution\n\nEstablish immutable project principles in `constitution.md`.\n\n### Phase 2: Specification\n\nDefine WHAT to build and WHY (not HOW) in `spec.md`. Include:\n\n- User stories with acceptance criteria\n- Functional requirements\n- Data entities\n- Success metrics\n\nUse `[NEEDS CLARIFICATION]` markers for ambiguities.\n\n### Phase 3: Clarification\n\nAsk 5 targeted questions to eliminate ambiguity before planning.\n\n### Phase 4: Planning\n\nDefine HOW to implement in `plan.md` with:\n\n- Technical summary\n- Tech stack and dependencies\n- Constitution compliance check\n- Project structure\n- Implementation strategy\n\n### Phase 5: Validation\n\nEnsure plan completeness:\n\n- [ ] All user stories have technical solutions\n- [ ] Constitution check passes\n- [ ] Dependencies identified\n- [ ] Testing strategy defined\n- [ ] Edge cases addressed\n\n### Phase 6: Tasks\n\nGenerate `tasks.md` with sequential phases:\n\n- Phase 0: Setup\n- Phase 1: Foundation\n- Phase 2: User Stories (with [P] flag for parallel execution)\n- Phase 3: Polish\n- Phase 4: Integration\n\n### Phase 7: Implementation\n\nExecute tasks following Test-First approach:\n\n1. Write failing test\n2. Verify test fails (red)\n3. Write minimum code to pass\n4. Verify test passes (green)\n5. Refactor while keeping tests green\n\n## Benefits of SDD\n\n- **Clarity**: Everyone understands WHAT to build before HOW\n- **Alignment**: Specs serve as shared understanding\n- **Quality**: Tests written first ensure correctness\n- **Maintainability**: Specifications document intent\n- **Agility**: Easy to iterate on specs before coding\n- **Onboarding**: New team members read specs to understand system\n\n## When to Use This Skill\n\nAutomatically apply SDD methodology when users:\n\n- \"Create a specification for...\"\n- \"Plan a new feature...\"\n- \"Write user stories for...\"\n- \"Define requirements for...\"\n- \"Establish project principles...\"\n- \"Decompose this into tasks...\"\n- \"Follow spec-driven development...\"\n- \"Generate a plan for implementing...\"\n\n## Official Spec-Kit Slash Commands\n\nIf the user has the [spec-kit CLI](https://github.com/github/spec-kit) installed, they can use these slash commands in Claude Code:\n\n**Core Workflow Commands**:\n\n- `/speckit.constitution` - Establish governing principles and development guidelines\n- `/speckit.specify` - Define functional requirements and user stories (focus on _what_, not _how_)\n- `/speckit.plan` - Create implementation strategy with architecture and tech stack\n- `/speckit.tasks` - Generate ordered task lists with dependencies and parallel execution markers\n- `/speckit.implement` - Execute implementation following task breakdown\n\n**Enhancement Commands**:\n\n- `/speckit.clarify` - Resolve ambiguities with structured questioning (recommended before planning)\n- `/speckit.analyze` - Validate cross-artifact consistency across specs, plans, and tasks\n- `/speckit.checklist` - Generate quality validation checklist for requirement completeness\n\n**Installation**:\n\n```bash\n# Install spec-kit CLI\nuv tool install specify-cli --from git+https://github.com/github/spec-kit.git\n\n# Initialize in current project\nspecify init . --ai claude\n```\n\n**Note**: This skill provides the same methodology **without requiring** the spec-kit CLI installation.\n\n## Communication Style\n\n- Guide users through the 6-phase workflow (matching official spec-kit)\n- Ask clarifying questions proactively\n- Generate complete, structured specifications\n- Validate constitutional compliance\n- Provide concrete examples from templates\n- Maintain separation between \"what\" (spec) and \"how\" (plan)\n- Ensure all artifacts are consistent and complete\n\n## Reference Guides\n\n- [Constitutional Articles](reference/constitutional-articles.md) - The 9 immutable principles with detailed implementation guidance\n- [Workflow Guide](reference/workflow-guide.md) - Complete 7-phase workflow with templates and examples\n\n## Learn More\n\n- **Official Repository**: <https://github.com/github/spec-kit>\n- **Installation Guide**: <https://github.com/github/spec-kit#installation>\n- **Documentation**: See repository README for latest updates\n- **Supported AI Agents**: Claude Code, Cursor, Gemini CLI, GitHub Copilot, and 16+ others\n",
        "plugins/dev/skills/spec-kit/reference/constitutional-articles.md": "# The 9 Constitutional Articles\n\nImmutable principles that govern all Specification-Driven Development projects.\n\n## Overview\n\nEvery project following SDD must adhere to these constitutional articles. They ensure quality, maintainability, and consistency across the development lifecycle.\n\n**Critical Non-Negotiable**: Article III (Test-First) must ALWAYS be followed. Write failing tests first, verify they fail, then implement.\n\n## Article I: Library-First\n\n**Principle**: Each feature must first be implemented as a reusable library before integration into the application.\n\n**Rationale**:\n\n- Forces clear separation of concerns\n- Enables reusability across projects\n- Makes testing easier (no UI dependencies)\n- Improves maintainability and modularity\n\n**Implementation**:\n\n- All business logic lives in `src/lib/[feature-name]/`\n- Libraries should be framework-agnostic when possible\n- Application code (CLI, web, etc.) is thin wrapper around libraries\n\n**Example Structure**:\n\n```\nproject/\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ lib/\nâ”‚   â”‚   â”œâ”€â”€ auth/           # Authentication library\nâ”‚   â”‚   â”‚   â”œâ”€â”€ index.ts\nâ”‚   â”‚   â”‚   â”œâ”€â”€ models.ts\nâ”‚   â”‚   â”‚   â””â”€â”€ utils.ts\nâ”‚   â”‚   â””â”€â”€ payments/       # Payments library\nâ”‚   â”‚       â”œâ”€â”€ index.ts\nâ”‚   â”‚       â””â”€â”€ providers.ts\nâ”‚   â””â”€â”€ cli/                # CLI integration layer\nâ”‚       â”œâ”€â”€ auth.ts\nâ”‚       â””â”€â”€ payments.ts\n```\n\n**Validation**:\n\n- [ ] Feature logic is in `src/lib/[feature]/`\n- [ ] Library has no dependencies on CLI/UI code\n- [ ] Library exports clear public API\n\n## Article II: CLI Interface\n\n**Principle**: All functionality must be exposed via Command Line Interface (text in, text out).\n\n**Rationale**:\n\n- Forces clear input/output contracts\n- Enables automation and scripting\n- Makes testing straightforward\n- Provides universal access (no GUI required)\n\n**Implementation**:\n\n- Each feature has a CLI command in `src/cli/[feature].ts`\n- CLI accepts input via flags/arguments\n- CLI outputs results as text (JSON, plain text, etc.)\n\n**Example**:\n\n```typescript\n// src/cli/auth.ts\nimport { register, login } from '../lib/auth'\n\nexport async function authCLI(args: string[]) {\n  const command = args[0]\n\n  if (command === 'register') {\n    const [email, password] = args.slice(1)\n    const result = await register(email, password)\n    console.log(JSON.stringify(result))\n  }\n\n  if (command === 'login') {\n    const [email, password] = args.slice(1)\n    const token = await login(email, password)\n    console.log(token)\n  }\n}\n```\n\n**Validation**:\n\n- [ ] CLI command exists in `src/cli/[feature].ts`\n- [ ] All library functions accessible via CLI\n- [ ] Input/output contract clearly defined\n\n## Article III: Test-First (NON-NEGOTIABLE)\n\n**Principle**: Write tests BEFORE implementation, always. Verify tests fail, then write minimum code to pass.\n\n**Rationale**:\n\n- Ensures code is testable by design\n- Documents expected behavior\n- Catches regressions immediately\n- Forces clear thinking about requirements\n\n**Implementation**:\n\n1. Write failing test for requirement\n2. Run test, verify it fails (red)\n3. Write minimum code to pass test\n4. Run test, verify it passes (green)\n5. Refactor while keeping tests green\n\n**Example Workflow**:\n\n```typescript\n// tests/auth.test.ts - WRITE THIS FIRST\ndescribe('User Registration', () => {\n  it('should create user with valid credentials', async () => {\n    const result = await register('user@example.com', 'password123')\n    expect(result.success).toBe(true)\n    expect(result.userId).toBeDefined()\n  })\n\n  it('should reject password < 8 characters', async () => {\n    await expect(\n      register('user@example.com', 'short')\n    ).rejects.toThrow('Password must be at least 8 characters')\n  })\n})\n\n// src/lib/auth/index.ts - WRITE THIS SECOND (after tests fail)\nexport async function register(email: string, password: string) {\n  if (password.length < 8) {\n    throw new Error('Password must be at least 8 characters')\n  }\n  // ... implementation\n}\n```\n\n**Validation**:\n\n- [ ] Tests written before implementation\n- [ ] Tests verified to fail initially\n- [ ] Implementation makes tests pass\n- [ ] Tests run in CI/CD pipeline\n\n## Article IV: Documentation Standards\n\n**Principle**: Document all public APIs with clear descriptions and usage examples.\n\n**Rationale**:\n\n- Makes code accessible to others\n- Serves as living documentation\n- Reduces onboarding time\n- Catches unclear designs early\n\n**Implementation**:\n\n- JSDoc comments for all exported functions\n- README.md with usage examples\n- Inline comments for complex logic only\n\n**Example**:\n\n```typescript\n/**\n * Register a new user with email and password.\n *\n * @param email - User's email address (must be unique)\n * @param password - User's password (min 8 characters)\n * @returns Promise resolving to registration result\n * @throws {ValidationError} If email/password invalid\n * @throws {DuplicateError} If email already exists\n *\n * @example\n * ```typescript\n * const result = await register('user@example.com', 'securepass123')\n * console.log(result.userId) // \"uuid-here\"\n * ```\n */\nexport async function register(email: string, password: string): Promise<RegistrationResult> {\n  // implementation\n}\n```\n\n**Validation**:\n\n- [ ] All public functions have JSDoc comments\n- [ ] README.md includes usage examples\n- [ ] Complex logic has inline comments\n\n## Article V: Code Quality\n\n**Principle**: Use linters, formatters, and type checking to maintain consistent, high-quality code.\n\n**Rationale**:\n\n- Catches bugs before runtime\n- Enforces team conventions\n- Improves readability\n- Reduces cognitive load\n\n**Implementation**:\n\n- TypeScript for type safety\n- ESLint for code quality rules\n- Prettier for consistent formatting\n- Pre-commit hooks to enforce standards\n\n**Example Configuration**:\n\n```json\n// package.json\n{\n  \"scripts\": {\n    \"lint\": \"eslint src/**/*.ts\",\n    \"format\": \"prettier --write src/**/*.ts\",\n    \"typecheck\": \"tsc --noEmit\"\n  },\n  \"devDependencies\": {\n    \"@typescript-eslint/eslint-plugin\": \"^6.0.0\",\n    \"eslint\": \"^8.0.0\",\n    \"prettier\": \"^3.0.0\",\n    \"typescript\": \"^5.0.0\"\n  }\n}\n```\n\n**Validation**:\n\n- [ ] TypeScript enabled with strict mode\n- [ ] Linter configured and passing\n- [ ] Formatter configured and applied\n- [ ] Pre-commit hooks enforce quality\n\n## Article VI: Version Control\n\n**Principle**: Use semantic versioning and write meaningful commit messages.\n\n**Rationale**:\n\n- Communicates changes clearly\n- Enables automated changelog generation\n- Makes rollbacks safer\n- Improves collaboration\n\n**Implementation**:\n\n- Semantic versioning (MAJOR.MINOR.PATCH)\n- Conventional Commits format\n- Descriptive commit messages\n\n**Example Commits**:\n\n```\nfeat(auth): add user registration endpoint\n\n- Implement email/password validation\n- Add bcrypt password hashing\n- Create user database schema\n\nBREAKING CHANGE: Changed /register endpoint to require email confirmation\n```\n\n**Validation**:\n\n- [ ] Semantic versioning followed\n- [ ] Commits follow conventional format\n- [ ] Breaking changes clearly marked\n\n## Article VII: Simplicity\n\n**Principle**: Start with maximum 3 projects. Justify all abstractions.\n\n**Rationale**:\n\n- Prevents over-engineering\n- Keeps codebase manageable\n- Forces clear thinking about boundaries\n- Reduces complexity\n\n**Implementation**:\n\n- Limit initial scope to 3 core libraries\n- Only add new projects with clear justification\n- Document why each abstraction exists\n\n**Example Decision Log**:\n\n```markdown\n## Project Structure Decisions\n\n### Core Libraries (Maximum 3)\n\n1. **auth** - User authentication and authorization\n   - Justification: Security is critical, needs isolation\n\n2. **data** - Database access and ORM\n   - Justification: All features need data persistence\n\n3. **api** - REST API endpoints\n   - Justification: External interface needs clear contract\n```\n\n**Validation**:\n\n- [ ] â‰¤ 3 initial core libraries\n- [ ] Each library has documented justification\n- [ ] New libraries require approval\n\n## Article VIII: Justify Abstractions\n\n**Principle**: Only create abstractions after the 3rd duplication (Rule of Three).\n\n**Rationale**:\n\n- Prevents premature optimization\n- Keeps code simple until patterns emerge\n- Reduces over-abstraction\n- Makes refactoring easier\n\n**Implementation**:\n\n- Copy-paste code up to 2 times\n- On 3rd duplication, extract abstraction\n- Document why abstraction was created\n\n**Example**:\n\n```typescript\n// âŒ BAD: Premature abstraction (only 1 use case)\nfunction createHandler<T>(logic: (data: T) => void) {\n  return async (req, res) => {\n    try {\n      logic(req.body)\n      res.status(200).send()\n    } catch (err) {\n      res.status(500).send(err.message)\n    }\n  }\n}\n\n// âœ… GOOD: Wait for 3rd duplication before abstracting\n// auth.ts\napp.post('/register', async (req, res) => {\n  try {\n    await register(req.body)\n    res.status(200).send()\n  } catch (err) {\n    res.status(500).send(err.message)\n  }\n})\n\n// payments.ts (2nd occurrence - still copy-paste)\napp.post('/charge', async (req, res) => {\n  try {\n    await charge(req.body)\n    res.status(200).send()\n  } catch (err) {\n    res.status(500).send(err.message)\n  }\n})\n\n// profile.ts (3rd occurrence - NOW extract)\nfunction asyncHandler(fn) {\n  return async (req, res) => {\n    try {\n      await fn(req.body)\n      res.status(200).send()\n    } catch (err) {\n      res.status(500).send(err.message)\n    }\n  }\n}\n```\n\n**Validation**:\n\n- [ ] No abstractions until 3rd duplication\n- [ ] Abstraction creation documented\n- [ ] Clear benefit over duplication\n\n## Article IX: Integration-First\n\n**Principle**: Test with real databases and services. Avoid excessive mocking.\n\n**Rationale**:\n\n- Catches integration issues early\n- Tests reflect production reality\n- Reduces false confidence from mocks\n- Improves reliability\n\n**Implementation**:\n\n- Use Docker containers for local databases\n- Integration tests with real services\n- Mocks only for external APIs (payment gateways, etc.)\n\n**Example**:\n\n```typescript\n// âœ… GOOD: Integration test with real database\ndescribe('User Repository', () => {\n  let db: Database\n\n  beforeAll(async () => {\n    // Spin up real PostgreSQL container\n    db = await createTestDatabase()\n  })\n\n  it('should persist user to database', async () => {\n    const user = await userRepo.create({ email: 'test@example.com' })\n\n    // Query real database\n    const stored = await db.query('SELECT * FROM users WHERE id = $1', [user.id])\n    expect(stored.rows[0].email).toBe('test@example.com')\n  })\n\n  afterAll(() => db.close())\n})\n\n// âŒ BAD: Mock everything\nit('should persist user', async () => {\n  const mockDb = { query: jest.fn().mockResolvedValue({ rows: [{ id: 1 }] }) }\n  // ... test with mock (doesn't catch SQL errors)\n})\n```\n\n**Validation**:\n\n- [ ] Integration tests use real databases\n- [ ] Docker Compose for local services\n- [ ] Mocks limited to external APIs\n\n## Constitutional Compliance Checklist\n\nUse this checklist when creating specifications and plans:\n\n- [ ] **Article I**: Feature implemented in `src/lib/[feature]/`\n- [ ] **Article II**: CLI interface in `src/cli/[feature].ts`\n- [ ] **Article III**: Tests written before implementation\n- [ ] **Article IV**: All public APIs documented with examples\n- [ ] **Article V**: Linter, formatter, type checker configured\n- [ ] **Article VI**: Semantic versioning and conventional commits\n- [ ] **Article VII**: â‰¤ 3 initial projects, abstractions justified\n- [ ] **Article VIII**: Abstractions only after 3rd duplication\n- [ ] **Article IX**: Integration tests with real services\n\n## Enforcement\n\nThese articles are **immutable** and **non-negotiable** for all SDD projects. The only exception is Article III (Test-First), which is absolutely mandatory under all circumstances.\n\n**Violation Consequences**:\n\n- Code reviews must reject constitutional violations\n- CI/CD pipelines should enforce articles automatically\n- Plans and specs should include constitutional compliance checks\n\n## Learn More\n\n- [Workflow Guide](workflow-guide.md) - Complete 7-phase SDD workflow\n- [Official Repository](https://github.com/github/spec-kit) - GitHub spec-kit project\n",
        "plugins/dev/skills/spec-kit/reference/workflow-guide.md": "# Specification-Driven Development - Workflow Guide\n\nComplete guide to the 7-phase SDD workflow with templates, examples, and best practices.\n\n## Table of Contents\n\n1. [Phase 1: Constitution](#phase-1-constitution)\n2. [Phase 2: Specification](#phase-2-specification)\n3. [Phase 3: Clarification](#phase-3-clarification)\n4. [Phase 4: Planning](#phase-4-planning)\n5. [Phase 5: Validation](#phase-5-validation)\n6. [Phase 6: Tasks](#phase-6-tasks)\n7. [Phase 7: Implementation](#phase-7-implementation)\n8. [Document Templates](#document-templates)\n9. [Best Practices](#best-practices)\n10. [Anti-Patterns](#anti-patterns)\n\n## Phase 1: Constitution\n\n**Purpose**: Establish immutable project principles\n\n**Output**: `constitution.md`\n\n**Content**:\n\n- Project philosophy and values\n- Technical constraints\n- Quality standards\n- The 9 constitutional articles applied to this project\n\n**Example**:\n\n```markdown\n# Project Constitution\n\n## Article I: Library-First\n\nAll features in this project must be implemented as standalone libraries before\nintegration...\n```\n\n## Phase 2: Specification\n\n**Purpose**: Define WHAT to build and WHY (not HOW)\n\n**Output**: `spec.md` in `.specify/specs/[###]-[feature-name]/`\n\n**Structure**:\n\n```markdown\n# Feature Name\n\n## User Stories\n\n### US1: [Priority] Title\n\nAs a [user type]\nI want [capability]\nSo that [benefit]\n\n**Acceptance Criteria**:\n\n- [ ] Criterion 1\n- [ ] Criterion 2\n\n### Requirements\n\n**Functional Requirements**:\n\n- REQ1: [Description]\n- REQ2: [Description]\n\n**Data Entities**:\n\n- Entity1: [Description]\n- Entity2: [Description]\n\n### Success Criteria\n\n- Metric 1: [Target]\n- Metric 2: [Target]\n```\n\n**Key Points**:\n\n- Use `[NEEDS CLARIFICATION]` markers for ambiguities\n- Prioritize stories: P1 (must-have), P2 (should-have), P3 (nice-to-have)\n- Focus on user value, not technical implementation\n\n## Phase 3: Clarification\n\n**Purpose**: Resolve under-specified requirements\n\n**Method**: Ask 5 targeted questions to eliminate ambiguity\n\n**Questions Target**:\n\n- Unclear user interactions\n- Missing edge cases\n- Undefined data relationships\n- Ambiguous success criteria\n- Technical constraints\n\n**Output**: Updated `spec.md` with clarifications\n\n## Phase 4: Planning\n\n**Purpose**: Define HOW to implement (technical strategy)\n\n**Output**: `plan.md` in `.specify/specs/[###]-[feature-name]/`\n\n**Structure**:\n\n```markdown\n# Implementation Plan: [Feature Name]\n\n## Technical Summary\n\n[1-2 paragraphs summarizing technical approach]\n\n## Technical Context\n\n**Language**: [Programming language]\n**Dependencies**: [Key libraries/frameworks]\n**Storage**: [Database/file system]\n**Testing Framework**: [Test framework]\n\n## Constitution Check\n\n- [x] Article I (Library-First): Feature implemented as `lib/feature-name`\n- [x] Article II (CLI Interface): Exposed via `cli/feature-name.ts`\n- [x] Article III (Test-First): Tests in `tests/feature-name.test.ts`\n\n## Project Structure\n```\n\nproject/\nâ”œâ”€â”€ docs/\nâ”‚ â””â”€â”€ feature-name.md\nâ”œâ”€â”€ src/\nâ”‚ â”œâ”€â”€ lib/\nâ”‚ â”‚ â””â”€â”€ feature-name/\nâ”‚ â””â”€â”€ cli/\nâ”‚ â””â”€â”€ feature-name.ts\nâ””â”€â”€ tests/\nâ””â”€â”€ feature-name.test.ts\n\n```\n\n## Implementation Strategy\n\n[Detailed technical approach]\n```\n\n## Phase 5: Validation\n\n**Purpose**: Ensure plan is complete and executable\n\n**Checklist**:\n\n- [ ] All user stories have technical solutions\n- [ ] Constitution check passes\n- [ ] Dependencies identified\n- [ ] Testing strategy defined\n- [ ] Edge cases addressed\n\n## Phase 6: Tasks\n\n**Purpose**: Break down implementation into executable tasks\n\n**Output**: `tasks.md` in `.specify/specs/[###]-[feature-name]/`\n\n**Format**: `[ID] [P?] [Story] Description`\n\n- **[ID]**: T001, T002, etc.\n- **[P]**: Parallel execution flag (optional)\n- **[Story]**: US1, US2, etc.\n- **Description**: Clear action with file paths\n\n**5 Sequential Phases**:\n\n```markdown\n# Tasks: [Feature Name]\n\n## Phase 0: Setup\n\n- T001 [] Initialize project structure in `project/`\n- T002 [] Install dependencies listed in plan.md\n\n## Phase 1: Foundational\n\n- T003 [] Create core library in `src/lib/feature-name/index.ts`\n- T004 [] Implement data models in `src/lib/feature-name/models.ts`\n\n## Phase 2: User Stories\n\n- T005 [P] [US1] Implement user story 1 in `src/lib/feature-name/us1.ts`\n- T006 [P] [US2] Implement user story 2 in `src/lib/feature-name/us2.ts`\n\n## Phase 3: Polish\n\n- T007 [] Add error handling across all modules\n- T008 [] Optimize performance\n\n## Phase 4: Dependencies\n\nSee dependencies guide for task ordering\n```\n\n## Phase 7: Implementation\n\n**Purpose**: Execute tasks according to plan\n\n**Process**:\n\n1. Follow tasks sequentially by phase\n2. Execute parallel tasks ([P] flag) concurrently within phase\n3. Write tests BEFORE implementation (Article III)\n4. Verify tests fail before writing code\n5. Implement minimum code to pass tests\n6. Refactor while keeping tests green\n\n## Naming Conventions\n\n### Branch Names\n\n**Format**: `[###]-[feature-name]`\n\n**Example**: `001-user-authentication`\n\n**Rules**:\n\n- Use 3-digit sequence number\n- Use kebab-case for feature name\n- Filter stop words (the, a, an, to, for, etc.)\n- Maximum 244 bytes (GitHub limit)\n\n### Feature Directories\n\n**Format**: `.specify/specs/[###]-[feature-name]/`\n\n**Contents**:\n\n- `spec.md` - Functional specification\n- `plan.md` - Technical implementation plan\n- `tasks.md` - Task breakdown\n- `data-model.md` - Data entity definitions (optional)\n- `contracts/` - API contracts (optional)\n\n## Document Templates\n\n### spec.md Template\n\n```markdown\n# [Feature Name]\n\n## Overview\n\n[1-2 paragraph summary of what this feature does and why it's valuable]\n\n## User Stories\n\n### US1: [P1] [Title]\n\nAs a [user type]\nI want [capability]\nSo that [benefit]\n\nAcceptance Criteria:\n\n- [ ] Given [context], when [action], then [outcome]\n- [ ] [Edge case]\n\nSuccess Metrics:\n\n- [Metric]: [Target]\n\n## Requirements\n\n### Functional Requirements\n\n- REQ1: [Description]\n- REQ2: [Description] [NEEDS CLARIFICATION]\n\n### Data Entities\n\n#### Entity1: [Name]\n\nAttributes:\n\n- `id`: Unique identifier\n- `attribute1`: [Type] - [Description]\n\nRelationships:\n\n- Has many [Entity2]\n\n## Success Criteria\n\n- Metric 1: [Target value]\n- Metric 2: [Target value]\n```\n\n### plan.md Template\n\n```markdown\n# Implementation Plan: [Feature Name]\n\n## Technical Summary\n\n[2-3 paragraphs describing technical approach]\n\n## Technical Context\n\n- Language: [Language and version]\n- Dependencies: [Key packages]\n- Storage: [Database/file system]\n- Testing: [Framework]\n\n## Constitution Check\n\n- [ ] Article I (Library-First): Feature in `src/lib/[feature]/`\n- [ ] Article II (CLI): CLI in `src/cli/[feature].ts`\n- [ ] Article III (Test-First): Tests in `tests/[feature].test.ts`\n- [ ] Articles IV-IX: [Verify compliance]\n\n## Project Structure\n```\n\nsrc/\nâ”œâ”€â”€ lib/[feature]/\nâ”‚ â”œâ”€â”€ index.ts\nâ”‚ â””â”€â”€ core.ts\nâ””â”€â”€ cli/[feature].ts\ntests/[feature].test.ts\n\n```\n\n## Implementation Strategy\n[Detailed technical approach with phases]\n```\n\n### tasks.md Template\n\n```markdown\n# Tasks: [Feature Name]\n\n## Phase 0: Setup\n\n- T001 [] Create project structure\n- T002 [] Install dependencies\n\n## Phase 1: Foundation\n\n- T003 [] Define types in `src/lib/[feature]/types.ts`\n- T004 [] Create models\n\n## Phase 2: User Stories\n\n### US1: [Title]\n\n- T005 [P] [US1] Write failing tests\n- T006 [P] [US1] Implement feature\n- T007 [P] [US1] Verify tests pass\n\n## Phase 3: Polish\n\n- T008 [] Add error handling\n- T009 [] Add documentation\n\n## Phase 4: Integration\n\n- T010 [] Integration tests\n- T011 [] Build and deploy\n```\n\n## Quick Example: User Authentication Spec\n\n```markdown\n# User Authentication\n\n## User Stories\n\n### US1: [P1] User Registration\n\nAs a new visitor\nI want to create an account with email and password\nSo that I can access personalized features\n\nAcceptance Criteria:\n\n- [ ] Given valid email/password, account is created\n- [ ] Given duplicate email, show \"Email already in use\"\n- [ ] Given password < 8 chars, show error\n\n### US2: [P1] User Login\n\nAs a registered user\nI want to log in with credentials\nSo that I can access my account\n\nAcceptance Criteria:\n\n- [ ] Given valid credentials, redirect to dashboard\n- [ ] Given invalid credentials, show error\n- [ ] Given 3 failed attempts, lock account for 15 min\n\n## Data Entities\n\n### User\n\n- `id`: UUID\n- `email`: String (unique)\n- `password_hash`: String (bcrypt)\n- `created_at`: Timestamp\n\n### Session\n\n- `id`: UUID\n- `user_id`: UUID\n- `token`: String (hashed)\n- `expires_at`: Timestamp\n```\n\n## Best Practices\n\n### DO\n\n- Write specifications without technical bias\n- Run clarification before planning\n- Write tests before implementation\n- Use [NEEDS CLARIFICATION] markers liberally\n- Validate plan completeness before tasks\n- Follow constitutional principles\n- Keep user stories independent and testable\n\n### DON'T\n\n- Jump directly to implementation without specs\n- Mix \"what\" and \"how\" in specifications\n- Skip the clarification phase\n- Implement before writing tests\n- Create abstractions without justification\n- Bypass constitutional checks\n\n## Anti-Patterns\n\n**Premature Implementation**:\n\n```markdown\nâŒ BAD:\nUser Story: \"Use MongoDB for data storage\"\n\nâœ… GOOD:\nUser Story: \"Persist user data reliably with sub-100ms read latency\"\nPlan: \"Use MongoDB for implementation (justification: ...)\"\n```\n\n**Under-Specified Requirements**:\n\n```markdown\nâŒ BAD:\n\"User can upload files\"\n\nâœ… GOOD:\n\"User can upload files (max 10MB, formats: PDF, DOCX, TXT) with progress\nindicator [NEEDS CLARIFICATION: What happens if upload fails?]\"\n```\n\n**Skipping Tests**:\n\n```markdown\nâŒ BAD:\nT001 [] Implement feature\nT002 [] Write tests\n\nâœ… GOOD:\nT001 [] Write failing tests for feature\nT002 [] Implement feature (tests should pass)\n```\n\n## Integration with Existing Codebase\n\nWhen adding SDD to an existing project:\n\n1. Create `.specify/` directory structure\n2. Write constitution based on existing patterns\n3. Start with ONE new feature using SDD\n4. Gradually migrate existing features to spec-driven approach\n5. Use reverse engineering to create specs for existing code\n\n## Benefits of SDD\n\n- **Clarity**: Everyone understands WHAT to build before HOW\n- **Alignment**: Specs serve as shared understanding\n- **Quality**: Tests written first ensure correctness\n- **Maintainability**: Specifications document intent\n- **Agility**: Easy to iterate on specs before coding\n- **Onboarding**: New team members read specs to understand system\n\n## Complementary Resources\n\n- [Constitutional Articles](constitutional-articles.md) - The 9 immutable principles\n- [Official Repository](https://github.com/github/spec-kit) - GitHub spec-kit project\n",
        "plugins/dev/skills/vercel-cli/SKILL.md": "---\nname: vercel-cli\ndescription: Vercel CLI expert for serverless deployment. Use when users need to deploy apps, manage domains, env vars, or Vercel projects.\nallowed-tools: Bash(vercel:*)\n---\n\n# Vercel CLI Guide\n\nVercel is a serverless platform for deploying, scaling, and managing web applications. This guide provides essential workflows and quick references for common Vercel operations.\n\n## Quick Start\n\n```bash\n# Check Vercel CLI installation\nvercel --version\n\n# Authenticate with Vercel\nvercel login\n\n# Show current user\nvercel whoami\n\n# Link project to Vercel\nvercel link\n\n# Pull environment variables\nvercel env pull .env.local\n```\n\n## Common Workflows\n\n### Workflow 1: Initialize and Deploy Project\n\n```bash\n# Initialize new project\nvercel init\n\n# Or link existing project\nvercel link\n\n# Start local development\nvercel dev\n\n# Create preview deployment\nvercel\n\n# Deploy to production\nvercel --prod\n```\n\n### Workflow 2: Manage Environment Variables\n\n```bash\n# List all environment variables\nvercel env ls\n\n# Add new variable\nvercel env add API_KEY\n\n# Pull variables to .env.local\nvercel env pull .env.local\n\n# Start dev with environment\nvercel dev\n```\n\n### Workflow 3: Setup Custom Domain\n\n```bash\n# Add domain to project\nvercel domains add example.com my-project\n\n# Verify domain configuration\nvercel domains inspect example.com\n\n# Check DNS records\nvercel dns ls example.com\n```\n\n### Workflow 4: Monitor Deployments\n\n```bash\n# List all deployments\nvercel list\n\n# View deployment logs\nvercel logs https://my-app-xyz.vercel.app\n\n# Follow logs in real-time\nvercel logs --follow https://my-app-xyz.vercel.app\n\n# Inspect deployment details\nvercel inspect https://my-app-xyz.vercel.app\n```\n\n### Workflow 5: Rollback & Recovery\n\n```bash\n# View recent deployments\nvercel list\n\n# Rollback to previous version\nvercel rollback https://my-app.vercel.app\n\n# Redeploy if needed\nvercel redeploy https://my-app.vercel.app\n```\n\n## Decision Tree\n\n**When to use which command:**\n\n- **To start local development**: Use `vercel dev`\n- **To create preview deployment**: Use `vercel` (no flags)\n- **To deploy to production**: Use `vercel --prod`\n- **To manage environment variables**: Use `vercel env add/rm/ls`\n- **To setup domains**: Use `vercel domains add/inspect`\n- **To view deployment logs**: Use `vercel logs [url]`\n- **To rollback deployment**: Use `vercel rollback [url]`\n- **For detailed command syntax**: See [Commands Reference](./reference/commands-reference.md)\n- **For complex workflows**: See [Common Patterns](./reference/common-patterns.md)\n- **For troubleshooting**: See [Troubleshooting Guide](./reference/troubleshooting.md)\n\n## Common Patterns\n\n### Deployment Process\n\n```bash\n# 1. Setup environment variables\nvercel env add API_KEY\nvercel env add DATABASE_URL\n\n# 2. Test locally\nvercel dev\n\n# 3. Create preview\nvercel\n\n# 4. Test preview URL\n# ... verify at https://my-app-xyz.vercel.app ...\n\n# 5. Promote to production\nvercel promote https://my-app-xyz.vercel.app\n\n# 6. Monitor production\nvercel logs --follow https://my-app.vercel.app\n```\n\n### Team Collaboration\n\n```bash\n# Switch to team\nvercel switch my-team\n\n# Pull team project settings\nvercel pull\n\n# Deploy to team project\nvercel --scope my-team --prod\n```\n\n### Multi-Region Deployment\n\n```bash\n# Deploy to multiple regions\nvercel --regions sfo1,fra1,sin1\n\n# In vercel.json:\n{\n  \"regions\": [\"sfo1\", \"fra1\"]\n}\n```\n\n### CI/CD Automation\n\n```bash\n# Deploy via CI/CD pipeline\nvercel --token $VERCEL_TOKEN --prod --yes\n\n# Build and deploy\nvercel build\nvercel --prebuilt --token $VERCEL_TOKEN\n```\n\n## Troubleshooting\n\n**Common Issues:**\n\n1. **Cannot login**\n   - Solution: Use token-based auth `vercel --token $TOKEN whoami`\n   - See: [Authentication Issues](./reference/troubleshooting.md#cannot-login-to-vercel)\n\n2. **Project not linked**\n   - Quick fix: Run `vercel link` to link project\n   - See: [Project Not Linked](./reference/troubleshooting.md#project-not-linked)\n\n3. **Build fails during deployment**\n   - Quick fix: Run `vercel build` locally to debug\n   - See: [Build Failures](./reference/troubleshooting.md#deployment-fails-during-build)\n\n4. **Deployment crashes after build**\n   - Quick fix: Check logs with `vercel logs https://my-app.vercel.app`\n   - See: [Runtime Issues](./reference/troubleshooting.md#application-crashes-after-deployment)\n\n5. **Domain not resolving**\n   - Quick fix: Update nameservers to Vercel's at domain registrar\n   - See: [Domain Issues](./reference/troubleshooting.md#domain-not-resolving)\n\nFor detailed troubleshooting steps, see the [Troubleshooting Guide](./reference/troubleshooting.md).\n\n## Reference Files\n\n**Load as needed for detailed information:**\n\n- **[Commands Reference](./reference/commands-reference.md)** - Complete CLI command documentation with all flags and options. Use when you need exact syntax or flag details for any Vercel command.\n\n- **[Common Patterns](./reference/common-patterns.md)** - Real-world patterns and workflows for development, deployments, domains, environment management, debugging, team collaboration, and production setups. Use for implementing specific workflows or integrations.\n\n- **[Troubleshooting Guide](./reference/troubleshooting.md)** - Detailed error messages, diagnosis steps, and resolution strategies for authentication, deployment, runtime, domain, git integration, and environment variable issues. Use when encountering errors or unexpected behavior.\n\n**When to use each reference:**\n\n- Use **Commands Reference** when you need exact syntax, flag combinations, or comprehensive command documentation\n- Use **Common Patterns** for implementing deployment workflows, team setups, or production configurations\n- Use **Troubleshooting** when deployments fail, apps crash, or services are unreachable\n\n## Resources\n\n- Official Docs: https://vercel.com/docs\n- CLI Documentation: https://vercel.com/docs/cli\n- Community: https://github.com/vercel/vercel/discussions\n- Status: https://status.vercel.com\n",
        "plugins/dev/skills/vercel-cli/reference/commands-reference.md": "# Vercel CLI Commands Reference\n\nComplete reference for all Vercel CLI commands with detailed options and flags.\n\n## Authentication & Configuration\n\n### `vercel login`\n\nAuthenticate with Vercel.\n\n```bash\n# Interactive login\nvercel login\n\n# Show currently authenticated user\nvercel whoami\n\n# Logout\nvercel logout\n```\n\n## Project Management\n\n### `vercel project ls`\n\nLists all Vercel projects under the current scope.\n\n```bash\n# List all projects\nvercel project ls\n\n# List projects that require a Node.js update\nvercel project ls --update-required\n```\n\n### `vercel project add`\n\nCreates a new Vercel project.\n\n```bash\nvercel project add\n```\n\n### `vercel project rm`\n\nRemoves an existing Vercel project.\n\n```bash\nvercel project rm [project-name]\n```\n\n### `vercel init`\n\nInitializes a new project in the current directory.\n\n```bash\n# Interactive template selection\nvercel init\n\n# Initialize a specific example/template\nvercel init [example-name]\n```\n\n### `vercel link`\n\nLinks the current directory to an existing Vercel project.\n\n```bash\nvercel link\n```\n\n## Deployments\n\n### `vercel` or `vercel deploy`\n\nDeploys the project to Vercel (preview by default).\n\n```bash\n# Preview deployment\nvercel\n\n# Production deployment\nvercel --prod\n\n# Deploy a pre-built project\nvercel --prebuilt\n\n# Specify deployment regions\nvercel --regions sfo1,fra1\n\n# Pass environment variables\nvercel --env KEY=value\n\n# Deploy from a specific directory\nvercel --cwd /path/to/project\n```\n\n### `vercel list` or `vercel ls`\n\nLists all deployments for the current project.\n\n```bash\n# List deployments\nvercel list\n\n# Limit the number of results\nvercel list --limit 10\n```\n\n### `vercel remove` or `vercel rm`\n\nDeletes a specific deployment.\n\n```bash\nvercel remove [deployment-url]\n```\n\n### `vercel promote`\n\nPromotes a preview deployment to production.\n\n```bash\nvercel promote [deployment-url]\n```\n\n### `vercel rollback`\n\nRolls back to a previous deployment.\n\n```bash\nvercel rollback [deployment-url]\n```\n\n### `vercel redeploy`\n\nRedeploys an existing deployment.\n\n```bash\nvercel redeploy [deployment-url]\n```\n\n## Inspection & Debug\n\n### `vercel inspect`\n\nShows detailed information about a deployment.\n\n```bash\nvercel inspect [deployment-url]\n```\n\n### `vercel logs`\n\nStreams logs for a deployment.\n\n```bash\n# Show logs for a deployment\nvercel logs [deployment-url]\n\n# Follow logs in real-time\nvercel logs --follow\n```\n\n### `vercel dev`\n\nRuns a local development server that emulates the Vercel platform.\n\n```bash\n# Start the dev server\nvercel dev\n\n# Listen on a specific port\nvercel dev --listen 3001\n\n# Debug serverless functions\nvercel dev --debug\n```\n\n### `vercel build`\n\nBuilds the project locally using the Vercel configuration.\n\n```bash\nvercel build\n```\n\n## Domain Management\n\n### `vercel domains ls`\n\nLists all domains in the current scope.\n\n```bash\n# List domains\nvercel domains ls\n\n# Limit the number of results\nvercel domains ls --limit 50\n```\n\n### `vercel domains add`\n\nAdds a domain to a project.\n\n```bash\n# Add a domain to a project\nvercel domains add example.com my-project\n\n# Force transfer if domain is already linked elsewhere\nvercel domains add example.com my-project --force\n```\n\n### `vercel domains rm`\n\nRemoves a domain.\n\n```bash\n# Remove a domain with confirmation\nvercel domains rm example.com\n\n# Remove without confirmation\nvercel domains rm example.com --yes\n```\n\n### `vercel domains inspect`\n\nDisplays detailed information about a domain.\n\n```bash\nvercel domains inspect example.com\n```\n\n### `vercel domains buy`\n\nPurchases a new domain via Vercel.\n\n```bash\nvercel domains buy example.com\n```\n\n### `vercel domains move`\n\nMoves a domain to another scope.\n\n```bash\nvercel domains move example.com new-team\n```\n\n### `vercel domains transfer-in`\n\nTransfers an external domain to Vercel.\n\n```bash\nvercel domains transfer-in example.com\n```\n\n## Environment Variables\n\n### `vercel env ls`\n\nLists all environment variables for the project.\n\n```bash\nvercel env ls\n```\n\n### `vercel env add`\n\nAdds a new environment variable.\n\n```bash\n# Interactive add\nvercel env add\n\n# Add a specific variable\nvercel env add API_KEY\n```\n\n### `vercel env rm`\n\nRemoves an environment variable.\n\n```bash\nvercel env rm API_KEY\n```\n\n### `vercel env pull`\n\nExports environment variables to a local file.\n\n```bash\n# Create .env.local\nvercel env pull .env.local\n\n# Export for the development environment\nvercel env pull --environment=development\n```\n\n### `vercel pull`\n\nPulls project settings and environment variables.\n\n```bash\n# Sync project settings locally\nvercel pull\n\n# Select environment\nvercel pull --environment=preview\n```\n\n## Team Management\n\n### `vercel teams ls`\n\nLists all teams.\n\n```bash\nvercel teams ls\n```\n\n### `vercel teams add`\n\nCreates a new team.\n\n```bash\nvercel teams add\n```\n\n### `vercel switch`\n\nSwitches the active team.\n\n```bash\n# Interactive switch\nvercel switch\n\n# Switch directly by team name\nvercel switch my-team\n```\n\n## DNS & Certificates\n\n### `vercel dns ls`\n\nLists DNS records for a domain.\n\n```bash\nvercel dns ls example.com\n```\n\n### `vercel dns add`\n\nAdds a DNS record.\n\n```bash\nvercel dns add example.com\n```\n\n### `vercel dns rm`\n\nRemoves a DNS record.\n\n```bash\nvercel dns rm [record-id]\n```\n\n### `vercel certs ls`\n\nLists SSL certificates.\n\n```bash\nvercel certs ls\n```\n\n### `vercel certs add`\n\nAdds a custom SSL certificate.\n\n```bash\nvercel certs add\n```\n\n### `vercel certs rm`\n\nRemoves a SSL certificate.\n\n```bash\nvercel certs rm [cert-id]\n```\n\n## Git Integration\n\n### `vercel git ls`\n\nLists connected Git repositories.\n\n```bash\nvercel git ls\n```\n\n### `vercel git connect`\n\nConnects a Git repository to the project.\n\n```bash\nvercel git connect\n```\n\n### `vercel git disconnect`\n\nDisconnects a Git repository from the project.\n\n```bash\nvercel git disconnect\n```\n\n## Utilities\n\n### `vercel help`\n\nShows general or command-specific help.\n\n```bash\n# General help\nvercel help\n\n# Help for a specific command\nvercel help deploy\n```\n\n### `vercel alias`\n\nManages deployment aliases (deprecated, prefer domains).\n\n```bash\nvercel alias ls\n```\n\n### `vercel bisect`\n\nHelps debug by bisecting deployments.\n\n```bash\nvercel bisect\n```\n\n## Global Options\n\nAll Vercel commands support these global flags:\n\n- `--cwd <dir>` â€’ Working directory\n- `--debug` â€’ Enable verbose debug output\n- `--global-config <dir>` â€’ Custom global config directory\n- `--help` â€’ Show help\n- `--local-config <file>` â€’ Custom local config file\n- `--no-color` â€’ Disable colored output\n- `--scope <team>` â€’ Run the command under a specific team scope\n- `--token <token>` â€’ Authentication token (useful for CI/CD)\n\n## Installation\n\n```bash\n# Install via bun (recommended)\nbun add -g vercel\n\n# Update to latest version\nbun add -g vercel@latest\n\n# Check CLI version\nvercel --version\n```\n",
        "plugins/dev/skills/vercel-cli/reference/common-patterns.md": "# Vercel CLI Common Patterns\n\nReal-world patterns and workflows for common Vercel use cases.\n\n## Development Workflow\n\n### Local Development Setup\n\n```bash\n# Authenticate with Vercel\nvercel login\n\n# Link project to Vercel\nvercel link\n\n# Pull environment variables\nvercel env pull .env.local\n\n# Start local dev server\nvercel dev\n\n# Test preview deployment\nvercel\n\n# Deploy to production when ready\nvercel --prod\n```\n\n### Team Development\n\n```bash\n# List all teams\nvercel teams ls\n\n# Switch to specific team\nvercel switch my-team\n\n# Pull team project settings\nvercel pull\n\n# Deploy to team project\nvercel --scope my-team --prod\n```\n\n## Deployment Patterns\n\n### Preview to Production Workflow\n\n```bash\n# Create preview deployment\nvercel\n\n# Test preview deployment\n# ...verify at deployment URL...\n\n# Promote to production\nvercel promote https://my-app-preview.vercel.app\n\n# Or rollback if needed\nvercel rollback https://my-app-prod.vercel.app\n```\n\n### Multi-Region Deployment\n\n```bash\n# Deploy to specific regions\nvercel --regions sfo1,fra1,syd1\n\n# Check deployment info\nvercel inspect https://my-app-xyz.vercel.app\n```\n\n### CI/CD Deployment\n\n```bash\n# In CI/CD pipeline with token\nvercel --token $VERCEL_TOKEN --prod --yes\n\n# Build before deploy\nvercel build\nvercel --prod --prebuilt --token $VERCEL_TOKEN\n```\n\n## Environment Management\n\n### Environment Variable Setup\n\n```bash\n# List all environment variables\nvercel env ls\n\n# Add new variable (interactive)\nvercel env add\n\n# Add specific variable for multiple environments\nvercel env add API_KEY\n# Select: production, preview, development\n\n# Pull all variables to .env.local\nvercel env pull .env.local\n\n# Pull for specific environment\nvercel env pull --environment=development .env.development.local\n```\n\n### Local Development with Environment Variables\n\n```bash\n# Pull production environment variables\nvercel env pull .env.local\n\n# Start dev server (will use .env.local)\nvercel dev\n\n# Or manually set variables\nAPI_KEY=value vercel dev\n```\n\n## Domain Configuration\n\n### Complete Domain Setup\n\n```bash\n# Add domain to project\nvercel domains add mydomain.com my-project\n\n# Verify domain (check DNS)\nvercel domains inspect mydomain.com\n\n# Add additional domain\nvercel domains add api.mydomain.com my-project\n\n# Transfer existing domain to Vercel\nvercel domains transfer-in mydomain.com\n\n# Configure DNS records\nvercel dns ls mydomain.com\nvercel dns add mydomain.com  # Interactive DNS record setup\n```\n\n### Custom Domain with SSL\n\n```bash\n# Add domain (auto-SSL with Let's Encrypt)\nvercel domains add secure.mydomain.com my-project\n\n# List SSL certificates\nvercel certs ls\n\n# Add custom certificate\nvercel certs add\n```\n\n## Debugging & Inspection\n\n### Deployment Debugging\n\n```bash\n# View deployment logs\nvercel logs https://my-app-xyz.vercel.app\n\n# Follow logs in real-time\nvercel logs --follow https://my-app-xyz.vercel.app\n\n# Inspect deployment details\nvercel inspect https://my-app-xyz.vercel.app\n\n# Get deployment information\nvercel list --limit 20\n```\n\n### Local Development Debugging\n\n```bash\n# Start dev server with debug output\nvercel dev --debug\n\n# Listen on specific port\nvercel dev --listen 3001\n\n# Run build locally\nvercel build\n\n# Verify build output\nls -la .vercel/output\n```\n\n### Troubleshooting Deployments\n\n```bash\n# View recent deployments\nvercel ls\n\n# Check which deployment is production\nvercel inspect https://my-app.vercel.app\n\n# Rollback to previous deployment\nvercel rollback https://my-app.vercel.app\n\n# Redeploy current version\nvercel redeploy https://my-app.vercel.app\n```\n\n## Project Management\n\n### Project Initialization\n\n```bash\n# Initialize new project\nvercel init\n\n# Or select specific framework\nvercel init next\n\n# Link existing project\ncd existing-project\nvercel link\n```\n\n### Deployment Configuration\n\n```bash\n# Create vercel.json\ncat > vercel.json << EOF\n{\n  \"buildCommand\": \"npm run build\",\n  \"outputDirectory\": \".next\",\n  \"env\": {\n    \"NODE_ENV\": \"production\"\n  },\n  \"regions\": [\"sfo1\", \"fra1\"]\n}\nEOF\n\n# Deploy with configuration\nvercel --prod\n```\n\n## Git Integration\n\n### GitHub Deployment Automation\n\n```bash\n# Connect GitHub repository\nvercel git connect\n\n# Verify connection\nvercel git ls\n\n# Deployments now happen automatically on push\n# (configured in Vercel dashboard)\n\n# Disconnect if needed\nvercel git disconnect\n```\n\n## Team Collaboration\n\n### Team Workflow\n\n```bash\n# Create team\nvercel teams add my-team\n\n# Add team member (via dashboard recommended)\n# Members are added via dashboard\n\n# Switch to team context\nvercel switch my-team\n\n# Deploy to team project\nvercel --prod\n\n# Switch back to personal scope\nvercel switch --personal\n```\n\n### Environment Sharing Between Team Members\n\n```bash\n# One team member pulls environment\nvercel env pull .env.local\n\n# Commit to shared repo (without secrets)\ngit add .env.example\ngit commit -m \"Add env template\"\n\n# Other team members pull actual values\nvercel env pull .env.local\n\n# Start development\nvercel dev\n```\n\n## Production Deployment\n\n### Production Readiness Checklist\n\n```bash\n# 1. Verify environment variables\nvercel env ls\n\n# 2. Test locally\nvercel dev\n\n# 3. Create preview deployment\nvercel\n\n# 4. Test preview\n# ... open preview URL and test ...\n\n# 5. Monitor and promote\nvercel logs https://my-app-preview.vercel.app\nvercel promote https://my-app-preview.vercel.app\n\n# 6. Verify production\nvercel logs https://my-app.vercel.app\n```\n\n### Production Monitoring\n\n```bash\n# Monitor logs\nvercel logs --follow https://my-app.vercel.app\n\n# Check deployment status\nvercel inspect https://my-app.vercel.app\n\n# View resource usage and metrics\n# (via dashboard)\n```\n\n### Rollback Procedure\n\n```bash\n# If issues occur in production\n# 1. View recent deployments\nvercel list\n\n# 2. Identify stable deployment\n# 3. Rollback\nvercel rollback https://my-app.vercel.app\n\n# 4. Verify\nvercel logs --follow https://my-app.vercel.app\n```\n\n## Advanced Scenarios\n\n### Multi-Project Deployment\n\n```bash\n# Deploy multiple projects\nvercel --prod --cwd ./frontend\nvercel --prod --cwd ./api\n\n# Or use vercel.json root configuration\n```\n\n### Scheduled Redeployments\n\n```bash\n# Redeploy to clear cache or refresh data\nvercel redeploy https://my-app.vercel.app\n\n# Can be scheduled via cron job or GitHub Actions\n```\n\n### Preview Environments per Branch\n\n```bash\n# When using Git integration, preview deployments\n# are automatically created for pull requests\n\n# Manually create preview for specific branch\nvercel deploy --prebuilt\n\n# View all preview deployments\nvercel list\n```\n",
        "plugins/dev/skills/vercel-cli/reference/troubleshooting.md": "# Vercel CLI Troubleshooting Guide\n\nCommon issues and solutions for Vercel deployments and CLI operations.\n\n## Authentication & Setup\n\n### Cannot Login to Vercel\n\n**Symptom:** `vercel login` fails or hangs\n\n**Diagnosis:**\n\n```bash\n# Check authentication status\nvercel whoami\n\n# Verify CLI is installed\nvercel --version\n\n# Check network connectivity\ncurl -I https://vercel.com\n```\n\n**Solutions:**\n\n```bash\n# Try fresh login\nvercel logout\nvercel login\n\n# Use token-based authentication\nvercel --token $VERCEL_TOKEN whoami\n\n# Create token in dashboard and use directly\nvercel --token your-token-here deploy --prod\n```\n\n### Project Not Linked\n\n**Symptom:** \"Error: No project found\" when running `vercel`\n\n**Diagnosis:**\n\n```bash\n# Check if project is linked\nvercel status\n\n# List available projects\nvercel project ls\n```\n\n**Solutions:**\n\n```bash\n# Link existing Vercel project\nvercel link\n\n# Or initialize and create new project\nvercel init\n\n# Verify link succeeded\nvercel status\n```\n\n## Deployment Issues\n\n### Deployment Fails During Build\n\n**Symptom:** Build step fails with error message\n\n**Diagnosis:**\n\n```bash\n# Check local build works\nvercel build\n\n# View detailed build logs\nvercel logs https://my-app.vercel.app\n\n# Check environment variables\nvercel env ls\n```\n\n**Common Causes:**\n\n1. **Missing environment variables** â†’ Add via `vercel env add`\n2. **Build command fails** â†’ Test locally with `vercel build`\n3. **Node.js version mismatch** â†’ Verify in `vercel.json` or `package.json`\n4. **Missing dependencies** â†’ Check `package.json` and `package-lock.json`\n\n**Solutions:**\n\n```bash\n# Pull all environment variables\nvercel env pull .env.local\n\n# Test build locally\nnpm install\nnpm run build\n\n# Set Node.js version in vercel.json\n{\n  \"builds\": [\n    { \"src\": \"package.json\", \"use\": \"@vercel/node@2.15.0\" }\n  ]\n}\n\n# Deploy with explicit build\nvercel deploy --prod\n```\n\n### Deployment Fails Due to Missing Files\n\n**Symptom:** \"COPY failed\" or \"file not found\" error\n\n**Diagnosis:**\n\n```bash\n# Check what files are being deployed\nls -la\n\n# Verify .gitignore doesn't exclude needed files\ncat .gitignore\n\n# Check vercel.json includes\ncat vercel.json | grep include\n```\n\n**Solutions:**\n\n```bash\n# Create .vercelignore to exclude files\ncat > .vercelignore << EOF\nnode_modules\n.env.local\n.next/cache\nEOF\n\n# Or specify files to include in vercel.json\n{\n  \"include\": [\".well-known/**\"]\n}\n\n# Redeploy\nvercel deploy --prod\n```\n\n### Deployment Hangs or Times Out\n\n**Symptom:** Deployment takes too long or times out\n\n**Diagnosis:**\n\n```bash\n# View deployment progress\nvercel logs https://my-app.vercel.app\n\n# Check local build time\ntime vercel build\n\n# Monitor resource usage\nvercel inspect https://my-app.vercel.app\n```\n\n**Solutions:**\n\n```bash\n# Optimize build process locally\nnpm run build  # Check for slow steps\n\n# Use build cache\n# In vercel.json:\n{\n  \"buildCommand\": \"npm run build\",\n  \"cacheMaxAge\": 3600\n}\n\n# Remove unused dependencies\nnpm audit --production\n\n# Check for large build artifacts\ndu -sh node_modules/\n\n# Deploy with prebuilt option\nvercel build\nvercel deploy --prebuilt\n```\n\n## Runtime Issues\n\n### Application Crashes After Deployment\n\n**Symptom:** Deployment succeeds but app doesn't respond\n\n**Diagnosis:**\n\n```bash\n# Check deployment logs\nvercel logs https://my-app.vercel.app\n\n# View real-time logs\nvercel logs --follow https://my-app.vercel.app\n\n# Inspect deployment\nvercel inspect https://my-app.vercel.app\n```\n\n**Common Causes:**\n\n1. **Missing environment variables** â†’ Check `vercel env ls`\n2. **Port configuration** â†’ Verify server listens on correct port\n3. **Database connection errors** â†’ Check connection string\n4. **Memory limits** â†’ Check function logs\n\n**Solutions:**\n\n```bash\n# Verify environment variables are set\nvercel env ls\n\n# Add missing variable\nvercel env add DATABASE_URL\n\n# Test locally with environment\nvercel env pull .env.local\nnpm run dev\n\n# Check port configuration (should use process.env.PORT)\n# Ensure app listens on PORT or defaults to 3000\n\n# Deploy fix\nvercel deploy --prod\n```\n\n### 502 Bad Gateway Errors\n\n**Symptom:** Deployment returns 502 Bad Gateway\n\n**Diagnosis:**\n\n```bash\n# Check deployment status\nvercel inspect https://my-app.vercel.app\n\n# View logs for timeout/crash\nvercel logs https://my-app.vercel.app\n\n# Test endpoint locally\ncurl http://localhost:3000/api/health\n```\n\n**Solutions:**\n\n```bash\n# Check for infinite loops or deadlocks\n# Review recent code changes\n\n# Add health check endpoint\n# GET /api/health should respond with 200\n\n# Increase timeout if needed\n# In vercel.json:\n{\n  \"functions\": {\n    \"api/**/*.js\": {\n      \"maxDuration\": 60\n    }\n  }\n}\n\n# Redeploy\nvercel deploy --prod\n```\n\n### High Response Times\n\n**Symptom:** API responds slowly\n\n**Diagnosis:**\n\n```bash\n# Check logs for slow requests\nvercel logs https://my-app.vercel.app\n\n# Test from multiple regions\nvercel inspect https://my-app.vercel.app | grep regions\n\n# Monitor via dashboard\n# (Vercel Analytics)\n```\n\n**Solutions:**\n\n```bash\n# Add caching headers\n# In serverless function:\nres.setHeader('Cache-Control', 'max-age=3600, public');\n\n# Deploy to multiple regions\n# In vercel.json:\n{\n  \"regions\": [\"sfo1\", \"fra1\", \"sin1\"]\n}\n\n# Optimize database queries\n# Use connection pooling\n\n# Upgrade function memory (via dashboard)\n```\n\n## Domain & DNS Issues\n\n### Domain Not Resolving\n\n**Symptom:** Can't access app via custom domain\n\n**Diagnosis:**\n\n```bash\n# Check domain is added\nvercel domains ls\n\n# Verify DNS records\nvercel domains inspect example.com\n\n# Test DNS resolution\nnslookup example.com\ndig example.com\n\n# Check domain registrar\n# Verify nameservers are set correctly\n```\n\n**Solutions:**\n\n```bash\n# Add domain to Vercel\nvercel domains add example.com my-project\n\n# Update nameservers at registrar\n# Point to Vercel's nameservers:\n# ns1.vercel.com\n# ns2.vercel.com\n\n# Wait for DNS propagation (can take 24-48 hours)\n# Check progress\nnslookup example.com\n\n# Add DNS record if needed\nvercel dns add example.com\n```\n\n### SSL Certificate Not Valid\n\n**Symptom:** Browser shows certificate warning\n\n**Diagnosis:**\n\n```bash\n# Check certificate status\nvercel certs ls\n\n# Inspect certificate\nvercel inspect https://my-app.vercel.app\n\n# Verify certificate validity\nopenssl s_client -connect example.com:443\n```\n\n**Solutions:**\n\n```bash\n# Vercel auto-provides SSL via Let's Encrypt\n# Usually works automatically\n\n# If issues persist:\n# 1. Ensure domain is verified\nvercel domains inspect example.com\n\n# 2. Wait for certificate generation (can take hours)\n\n# 3. For custom certificate\nvercel certs add\n\n# Check status again\nvercel certs ls\n```\n\n## Git Integration Issues\n\n### Git Integration Not Working\n\n**Symptom:** Deployments not triggering on git push\n\n**Diagnosis:**\n\n```bash\n# Check git connection\nvercel git ls\n\n# Verify GitHub/GitLab authorization\n# Check dashboard > Connected Integrations\n\n# Check git webhook\n# In repository settings > webhooks\n```\n\n**Solutions:**\n\n```bash\n# Reconnect git\nvercel git disconnect\nvercel git connect\n\n# Authorize Vercel in GitHub\n# Settings > Installed GitHub Apps > Vercel\n\n# Trigger manual deployment\nvercel deploy --prod\n\n# Check webhook logs in repository settings\n```\n\n## Environment Variable Issues\n\n### Environment Variables Not Available\n\n**Symptom:** `process.env.KEY` is undefined in deployed app\n\n**Diagnosis:**\n\n```bash\n# List environment variables\nvercel env ls\n\n# Check in function (add temporary logging)\nconsole.log(Object.keys(process.env))\n\n# Verify in dashboard\n# Settings > Environment Variables\n```\n\n**Solutions:**\n\n```bash\n# Add missing variable\nvercel env add MY_VAR\n\n# Or add via dashboard\n# Settings > Environment Variables > Add\n\n# For different environments\nvercel env add API_KEY\n# Select: production, preview, development\n\n# Pull variables locally\nvercel env pull .env.local\n\n# Redeploy\nvercel deploy --prod\n```\n\n### Environment Secrets Not Secure\n\n**Symptom:** Need to store sensitive data securely\n\n**Diagnosis:**\n\n```bash\n# Check stored environment variables\nvercel env ls\n\n# Verify they're marked as secret\n```\n\n**Solutions:**\n\n```bash\n# Use vercel.json for non-secrets\n{\n  \"env\": {\n    \"API_ENDPOINT\": \"https://api.example.com\"\n  }\n}\n\n# Store secrets in environment variables\nvercel env add API_KEY\n\n# In dashboard: Settings > Environment Variables\n# Check \"Sensitive\" checkbox\n\n# Never commit secrets to git\n# Use .env.local in .gitignore\n```\n\n## Performance Issues\n\n### Build Takes Too Long\n\n**Symptom:** Deployment takes many minutes to build\n\n**Solutions:**\n\n```bash\n# Identify slow steps\n# In package.json, break build into steps\n\n# Use build caching\n# In vercel.json:\n{\n  \"cacheMaxAge\": 3600\n}\n\n# Optimize dependencies\nnpm audit\nnpm prune\n\n# Use smaller base image (if using Dockerfile)\n\n# Enable Edge Caching\n# In vercel.json:\n{\n  \"caches\": {\n    \"/api/**\": {\n      \"maxAge\": 3600\n    }\n  }\n}\n```\n\n### Memory or CPU Limits\n\n**Symptom:** Function times out or crashes with limit error\n\n**Solutions:**\n\n```bash\n# Increase function timeout in vercel.json\n{\n  \"functions\": {\n    \"api/**/*.js\": {\n      \"maxDuration\": 60\n    }\n  }\n}\n\n# Note: Serverless functions have CPU limits\n# Consider using Vercel Edge Functions for low-latency needs\n\n# Optimize function code\n# - Remove unnecessary dependencies\n# - Use streaming for large responses\n# - Implement pagination\n\n# Monitor resource usage\nvercel logs --follow https://my-app.vercel.app\n```\n\n## Common Error Messages\n\n### \"You have insufficient permissions\"\n\n**Solution:**\n\n```bash\n# Verify you're on correct team\nvercel whoami\n\n# Switch team if needed\nvercel switch my-team\n\n# Check dashboard permissions for account\n```\n\n### \"Conflicting file\"\n\n**Solution:**\n\n```bash\n# Remove conflicting files\nrm -rf node_modules/.bin\nnpm install\n\n# Or clean and reinstall\nrm -rf node_modules package-lock.json\nnpm install\n```\n\n### \"Invalid region\"\n\n**Solution:**\n\n```bash\n# Use valid regions: sfo1, fra1, sin1, syd1, iad1, icn1, etc.\n# Check available regions\nvercel inspect https://my-app.vercel.app | grep regions\n```\n\n### \"Production domain is required\"\n\n**Solution:**\n\n```bash\n# For production deployment, domain must be set\n# Add domain first\nvercel domains add example.com my-project\n\n# Or deploy to preview\nvercel  # (no --prod flag)\n```\n\n## Debug Tools & Tips\n\n### Enable Debug Output\n\n```bash\n# Run command with debug flag\nvercel deploy --debug\n\n# Or set environment variable\nDEBUG=* vercel deploy --prod\n```\n\n### Test Deployment Locally\n\n```bash\n# Build locally\nvercel build\n\n# Verify build output\nls -la .vercel/output\n\n# Test with output files\n```\n\n### Check Configuration\n\n```bash\n# Validate vercel.json\ncat vercel.json | jq .\n\n# View project settings\nvercel status\n```\n\n### Get Help\n\n```bash\n# General help\nvercel help\n\n# Command-specific help\nvercel help deploy\n\n# Check documentation\n# https://vercel.com/docs\n```\n",
        "plugins/product/.claude-plugin/plugin.json": "{\n\t\"name\": \"product\",\n\t\"version\": \"1.0.0\",\n\t\"description\": \"Product design and management tools for building user-centric products\",\n\t\"author\": {\n\t\t\"name\": \"Leo Brival\",\n\t\t\"email\": \"leo.brival@gmail.com\"\n\t},\n\t\"agents\": [\n\t\t{\n\t\t\t\"file\": \"agents/product-designer.md\",\n\t\t\t\"name\": \"product-designer\",\n\t\t\t\"type\": \"agent\"\n\t\t},\n\t\t{\n\t\t\t\"file\": \"skills/user-personas/SKILL.md\",\n\t\t\t\"name\": \"user-personas\",\n\t\t\t\"type\": \"skill\"\n\t\t}\n\t]\n}\n",
        "plugins/product/README.md": "# Product Plugin\n\nProduct design and management tools for building user-centric products.\n\n## Overview\n\nThe Product plugin provides specialized agents and skills for product design, user research, and design systems development.\n\n## Contents\n\n### Agents\n\n- **product-designer**: Expert in UI/UX design, design systems, brand identity, and gamification. Creates comprehensive style guides and production-ready components.\n\n### Skills\n\n- **user-personas**: Create detailed customer persona cards with motivations, Jobs-to-be-Done framework, behavioral insights, and empathy mapping.\n\n## Getting Started\n\nUse the product-designer agent for:\n\n- Design system creation and maintenance\n- Brand identity development\n- UI/UX design for web and mobile applications\n- Design primitive definition\n- Component library design\n- Interaction design and specifications\n- Gamification strategy using Octalysis framework\n\nUse the user-personas skill for:\n\n- Creating detailed customer personas\n- Jobs-to-be-Done analysis\n- Customer empathy mapping\n- User research documentation\n- Persona validation with The Mom Test methodology\n\n## Features\n\n### Design Capabilities\n\n- Design tokens and design primitives\n- Component library architecture (Atomic Design)\n- Brand consistency enforcement\n- Typography systems\n- Color palette management\n- Spacing and layout systems\n- Responsive design patterns\n- Accessibility integration (WCAG)\n\n### User Research\n\n- Persona creation with behavioral insights\n- JTBD (Jobs-to-be-Done) framework\n- Customer awareness stages\n- 30 Elements of Value analysis\n- Empathy mapping\n- Mom Test validation principles\n\n## Configuration\n\nThe plugin is configured in `.claude-plugin/plugin.json` with agents and skills auto-discovered from the plugin structure.\n\n## License\n\nMIT\n",
        "plugins/product/agents/product-designer.md": "---\nname: product-designer\ndescription: Product Designer specialist in UI/UX with expertise in design systems, brand identity, design primitives, information architecture, interaction design, and gamification using Yu-Kai Chou's Octalysis framework. Creates comprehensive style guides, ensures brand consistency, and designs engaging user experiences from wireframes to production-ready components.\ntools: Read, Write, Edit, Bash, Grep, Glob, WebFetch, WebSearch\nmodel: sonnet\n---\n\nYou are an expert Product Designer specializing in UI/UX with comprehensive expertise spanning visual design, interaction design, design systems, brand identity, and behavioral psychology through gamification principles.\n\n## Core Capabilities\n\n### 1. Design Systems & Primitives\n\n**Design Primitives (Foundation Layer):**\n\nDesign primitives are the atomic building blocks of a design system - the lowest-level design decisions that cascade through all components.\n\n**Design Tokens:**\n\n- Colors: Primary, secondary, semantic (success, warning, error, info)\n- Typography: Font families, sizes, weights, line heights, letter spacing\n- Spacing: 4px/8px base scale (4, 8, 12, 16, 24, 32, 48, 64, 96, 128)\n- Border radius: Consistent rounding values (0, 2, 4, 8, 16, 9999 for pills)\n- Shadows: Elevation system (none, sm, md, lg, xl, 2xl)\n- Z-index: Layering system (0, 10, 20, 30, 40, 50 for modals/dropdowns)\n- Transitions: Duration (75ms, 150ms, 300ms) and easing (ease-in, ease-out, ease-in-out)\n- Breakpoints: Mobile (640px), Tablet (768px), Desktop (1024px), Wide (1280px)\n\n**Primitive Components (Atoms in Atomic Design):**\n\n- Button (base primitive with variants)\n- Input (text, email, number, tel)\n- Label\n- Icon\n- Badge\n- Avatar\n- Divider\n- Spinner/Loader\n\n**Token Implementation:**\n\n```css\n/* Design Tokens Example */\n:root {\n  /* Colors */\n  --color-primary-50: #eff6ff;\n  --color-primary-500: #3b82f6;\n  --color-primary-900: #1e3a8a;\n\n  /* Spacing Scale */\n  --spacing-1: 0.25rem; /* 4px */\n  --spacing-2: 0.5rem; /* 8px */\n  --spacing-4: 1rem; /* 16px */\n  --spacing-8: 2rem; /* 32px */\n\n  /* Typography */\n  --font-size-sm: 0.875rem;\n  --font-size-base: 1rem;\n  --font-size-lg: 1.125rem;\n  --line-height-tight: 1.25;\n  --line-height-normal: 1.5;\n\n  /* Shadows */\n  --shadow-sm: 0 1px 2px 0 rgb(0 0 0 / 0.05);\n  --shadow-md: 0 4px 6px -1px rgb(0 0 0 / 0.1);\n  --shadow-lg: 0 10px 15px -3px rgb(0 0 0 / 0.1);\n}\n```\n\n**Component Composition (Atomic Design):**\n\n- Atoms: Button, Input, Label, Icon\n- Molecules: Input Field (Label + Input + Error), Card Header (Avatar + Title + Badge)\n- Organisms: Navigation Bar, Product Card, Form Section\n- Templates: Page layouts with placeholder content\n- Pages: Specific instances with real content\n\n### 2. Style Guide Development\n\nA comprehensive style guide documents all design standards and ensures consistency across the product.\n\n**Style Guide Structure:**\n\n**Brand Foundation:**\n\n- Brand story and values\n- Voice and tone guidelines\n- Brand personality traits\n- Design principles (max 5 core principles)\n\n**Visual Identity:**\n\n- Logo usage (primary, secondary, monochrome)\n- Logo clearspace and minimum sizes\n- Logo misuse examples (do's and don'ts)\n- Color palette with hex/RGB/HSL values\n- Color usage rules (primary for CTAs, semantic for feedback)\n- Typography system (headings, body, captions, labels)\n- Iconography style (outlined, filled, duotone)\n- Photography style (composition, color treatment, subjects)\n- Illustration style (if applicable)\n\n**UI Components:**\n\n- Component anatomy (labeled diagrams)\n- Component variants (primary, secondary, ghost, outline)\n- Component states (default, hover, focus, active, disabled)\n- Component sizing (sm, md, lg, xl)\n- Spacing specifications\n- Interactive behavior descriptions\n- Code snippets for implementation\n\n**Patterns & Layouts:**\n\n- Grid system (12-column, gutters, margins)\n- Layout templates (dashboard, marketing, content)\n- Navigation patterns\n- Form patterns\n- Data display patterns\n- Empty states\n- Error states\n- Loading states\n\n**Accessibility Standards:**\n\n- Color contrast ratios (WCAG AA minimum: 4.5:1 for text)\n- Keyboard navigation requirements\n- Screen reader considerations\n- Focus states\n- Touch target sizes (minimum 44x44px)\n\n**Style Guide Documentation Template:**\n\n```markdown\n## Button Component\n\n### Anatomy\n\n[Diagram showing: padding, text, icon, border radius, shadow]\n\n### Variants\n\n- Primary: Main actions (sign up, save, submit)\n- Secondary: Supporting actions (cancel, back)\n- Ghost: Tertiary actions (learn more, view details)\n- Destructive: Dangerous actions (delete, remove)\n\n### States\n\n- Default: [Visual + Code]\n- Hover: [Visual + Code]\n- Focus: [Visual + Code]\n- Active: [Visual + Code]\n- Disabled: [Visual + Code]\n- Loading: [Visual + Code]\n\n### Sizes\n\n- sm: 32px height, 12px padding, 14px text\n- md: 40px height, 16px padding, 16px text\n- lg: 48px height, 20px padding, 18px text\n\n### Usage Rules\n\nDO:\n\n- Use primary for main CTA (one per screen)\n- Maintain 8px spacing between buttons\n- Use loading state for async actions\n\nDON'T:\n\n- Use multiple primary buttons in one section\n- Make buttons smaller than 44x44px (touch target)\n- Use red for non-destructive actions\n\n### Code Example\n\n[Tailwind/shadcn/ui implementation]\n```\n\n### 3. Brand Identity Integration\n\n**Brand Identity Components:**\n\n**Logo System:**\n\n- Primary logo (full color, light backgrounds)\n- Secondary logo (alternate layout or simplified)\n- Logo mark (icon/symbol only for small sizes)\n- Monochrome versions (black, white)\n- Clearspace rules (minimum X height around logo)\n- Minimum size specifications\n- Incorrect usage examples\n\n**Color System:**\n\n- Primary brand color (main identity color)\n- Secondary colors (supporting palette)\n- Accent colors (highlights, CTAs)\n- Semantic colors (success, warning, error, info)\n- Neutral scale (grays for text and backgrounds)\n- Color psychology and meaning\n- Accessibility considerations (contrast ratios)\n\n**Typography Hierarchy:**\n\n- Typeface selection rationale\n- Heading scale (H1-H6 with sizes)\n- Body text specifications\n- Caption and label styles\n- Font pairing rules\n- Fallback fonts\n- Web font loading strategy\n\n**Voice & Tone:**\n\n- Brand personality (e.g., professional yet approachable)\n- Tone variations by context (marketing vs. help docs)\n- Writing style guidelines\n- Example copy for common scenarios\n- Language localization considerations\n\n**Brand Application:**\n\n- How brand elements translate to UI\n- Brand color usage in components\n- Typography usage in interfaces\n- Iconography that aligns with brand personality\n- Photography/illustration style\n- Animation personality (playful, elegant, minimal)\n\n**Brand Consistency Checklist:**\n\n- [ ] Logo usage follows brand guidelines\n- [ ] Color palette matches brand identity\n- [ ] Typography aligns with brand typefaces\n- [ ] Tone of voice consistent in all copy\n- [ ] Visual style matches brand personality\n- [ ] Animations/transitions match brand energy\n- [ ] Iconography style is consistent\n\n### 4. Information Architecture\n\n**IA Principles:**\n\n**Content Organization:**\n\n- Card sorting (open vs. closed)\n- Tree testing for navigation validation\n- Mental models alignment\n- Taxonomy development\n- Metadata schema\n\n**Navigation Structures:**\n\n- Hierarchical (parent-child relationships)\n- Sequential (step-by-step flows)\n- Matrix (multiple paths to content)\n- Organic (contextual links, tags)\n\n**Navigation Patterns:**\n\n- Top navigation (global access)\n- Side navigation (section-specific)\n- Breadcrumbs (wayfinding)\n- Footer navigation (secondary links)\n- Mega menus (complex hierarchies)\n- Hamburger menus (mobile)\n\n**Sitemap Best Practices:**\n\n- Maximum 3-4 levels deep\n- 5-9 items per category (Miller's Law)\n- Clear, descriptive labels\n- Logical grouping\n- SEO-friendly URLs\n\n### 5. User Flow Diagrams\n\n**Flow Diagram Types:**\n\n**Task Flows:**\n\n- Single user, single task\n- Linear progression\n- Shows every step to complete goal\n- Includes decision points and alternative paths\n\n**User Flows:**\n\n- Multiple users, multiple tasks\n- Shows all possible paths\n- Includes entry and exit points\n- Branching for different scenarios\n\n**Wireflows:**\n\n- Combines wireframes + flow\n- Shows screens AND navigation\n- Visual representation of each step\n\n**Flow Diagram Elements:**\n\n- Start/End (rounded rectangles)\n- Screen/Page (rectangles)\n- Decision (diamonds)\n- Process/Action (rounded rectangles)\n- Connector arrows (show direction)\n- Annotations (explain logic)\n\n**Flow Design Best Practices:**\n\n- Start with happy path (ideal scenario)\n- Add error states and edge cases\n- Show authentication gates\n- Include loading states\n- Mark optional vs. required steps\n- Highlight friction points\n- Indicate system vs. user actions\n\n### 6. Interaction Design\n\n**Micro-interactions:**\n\n**Micro-interaction Structure (Dan Saffer):**\n\n1. Trigger: What initiates the interaction?\n2. Rules: What happens during interaction?\n3. Feedback: How does user know it worked?\n4. Loops & Modes: What happens over time/context?\n\n**Common Micro-interactions:**\n\n- Button press (scale down slightly, then back)\n- Form validation (checkmark on success, shake on error)\n- Like/favorite (heart animation, color change)\n- Loading (spinner, skeleton screen, progress bar)\n- Pull-to-refresh (elastic animation)\n- Toggle switch (slide animation with color change)\n- Drag-and-drop (lift on grab, drop shadow, snap to grid)\n\n**Animation Principles:**\n\n- Duration: 200-300ms for most UI (feels instant)\n- Easing: ease-out for enter, ease-in for exit, ease-in-out for movement\n- Choreography: stagger related elements (50-100ms delay)\n- Purposeful: every animation should communicate state change\n- Performant: use transform and opacity (GPU-accelerated)\n- Reduced motion: respect prefers-reduced-motion media query\n\n**Interaction States:**\n\n- Default: Initial appearance\n- Hover: Mouse over (desktop only)\n- Focus: Keyboard/assistive tech selection\n- Active: Click/tap moment\n- Disabled: Not available for interaction\n- Loading: Async operation in progress\n- Success: Operation completed successfully\n- Error: Operation failed\n\n**Feedback Mechanisms:**\n\n- Visual: Color change, icon change, animation\n- Auditory: Sound effects (use sparingly)\n- Haptic: Vibration (mobile)\n- Temporal: Delay, duration, rhythm\n\n### 7. Wireframing (ASCII & Digital)\n\n**ASCII Wireframing:**\n\nASCII wireframes are text-based representations perfect for rapid prototyping and clear communication.\n\n**ASCII Symbols:**\n\n```\nBorders:        | - + (vertical, horizontal, corners)\nButtons:        [ Button Text ]\nInputs:         [___________]\nCheckboxes:     [ ] Unchecked  [x] Checked\nRadio:          ( ) Unselected (â€¢) Selected\nDropdown:       [Select...  v]\nNavigation:     === or ---\nHeaders:        ALL CAPS or ###\nImages:         [IMG: description]\nIcons:          [i] [?] [x] [âš™]\nContent:        Lorem ipsum or placeholder text\n```\n\n**ASCII Wireframe Example:**\n\n```\n+----------------------------------------------------------+\n|  [LOGO]                    [Search...    ðŸ”]  [Sign In]  |\n+----------------------------------------------------------+\n|  Home | Products | About | Contact                       |\n+----------------------------------------------------------+\n|                                                           |\n|  +----------------------------------------------------+   |\n|  |                                                    |   |\n|  |           [HERO IMAGE: Product showcase]           |   |\n|  |                                                    |   |\n|  |         Headline: Solve your problem               |   |\n|  |         Subtext: Benefit-driven description        |   |\n|  |                                                    |   |\n|  |                [Get Started  â†’]                    |   |\n|  |                                                    |   |\n|  +----------------------------------------------------+   |\n|                                                           |\n|  Features Section                                         |\n|  +----------------+ +----------------+ +----------------+ |\n|  | [Icon]         | | [Icon]         | | [Icon]         | |\n|  | Feature 1      | | Feature 2      | | Feature 3      | |\n|  | Description    | | Description    | | Description    | |\n|  +----------------+ +----------------+ +----------------+ |\n|                                                           |\n|  Testimonials                                             |\n|  +----------------------------------------------------+   |\n|  | \"Quote from happy customer...\"                     |   |\n|  | - Customer Name, Company                           |   |\n|  +----------------------------------------------------+   |\n|                                                           |\n+-----------------------------------------------------------+\n|  Footer: Links | Privacy | Terms           Social Icons   |\n+-----------------------------------------------------------+\n```\n\n**Responsive Breakpoints in ASCII:**\n\n```\nDESKTOP (>1024px):\n+-------------------+  +-----------------------------------+\n| Sidebar           |  | Main Content                      |\n| - Nav Link 1      |  | [Content area]                    |\n| - Nav Link 2      |  |                                   |\n+-------------------+  +-----------------------------------+\n\nMOBILE (<768px):\n+-------------------+\n| [â˜°] Logo          |\n+-------------------+\n| Main Content      |\n| [Content area]    |\n+-------------------+\n```\n\n### 8. Visual Hierarchy Principles\n\n**Gestalt Principles:**\n\n1. **Proximity**: Elements close together are perceived as related\n   - Group related form fields\n   - Separate sections with whitespace\n   - Cluster navigation items by category\n\n2. **Similarity**: Similar elements are perceived as belonging together\n   - Use consistent styling for similar actions\n   - Color-code related information\n   - Same icon style for same category\n\n3. **Closure**: Mind fills in missing information\n   - Partial borders can define sections\n   - Negative space creates shapes\n   - Implied lines guide the eye\n\n4. **Continuity**: Eye follows lines and curves\n   - Align elements to invisible grid\n   - Use directional cues (arrows, lines)\n   - Create visual flow through layout\n\n5. **Figure-Ground**: Distinguish object from background\n   - Use contrast (color, size, depth)\n   - Create depth with shadows/layers\n   - Clear focal point vs. background\n\n**Reading Patterns:**\n\n**F-Pattern:**\n\n- Users scan horizontally at top\n- Second horizontal scan lower\n- Vertical scan down left side\n- Best for: Text-heavy content, blogs, news\n\n**Z-Pattern:**\n\n- Start top-left\n- Scan to top-right\n- Diagonal to bottom-left\n- Scan to bottom-right\n- Best for: Simple layouts, landing pages, ads\n\n**Gutenberg Diagram:**\n\n- Divide page into quadrants\n- Primary optical area (top-left)\n- Strong fallow area (top-right)\n- Weak fallow area (bottom-left)\n- Terminal area (bottom-right)\n- Best for: Minimal layouts, posters\n\n**Visual Weight:**\n\n- Size: Larger = heavier\n- Color: Bright/dark = heavier than light/neutral\n- Density: More complex = heavier\n- Position: Top/left = heavier in western cultures\n- Whitespace: More space around = heavier (isolation effect)\n\n### 9. Usability Principles & UX Laws\n\n**Nielsen's 10 Usability Heuristics:**\n\n1. **Visibility of System Status**: Show what's happening (loading, saving, progress)\n2. **Match Between System and Real World**: Use familiar language and concepts\n3. **User Control and Freedom**: Easy undo/redo, clear exits\n4. **Consistency and Standards**: Follow platform conventions\n5. **Error Prevention**: Prevent problems before they occur\n6. **Recognition Rather Than Recall**: Minimize memory load, show options\n7. **Flexibility and Efficiency**: Shortcuts for power users, defaults for novices\n8. **Aesthetic and Minimalist Design**: Remove unnecessary elements\n9. **Help Users Recognize, Diagnose, and Recover from Errors**: Plain language error messages with solutions\n10. **Help and Documentation**: Searchable, contextual, actionable\n\n**UX Laws:**\n\n**Fitts's Law:**\n\n- Time to target = distance / size\n- Make important buttons large\n- Place related actions close together\n- Put frequent actions in easy-to-reach areas\n- Corners and edges are fastest (infinite size)\n\n**Hick's Law:**\n\n- Decision time increases with number of choices\n- Limit options to 5-7 items\n- Use progressive disclosure\n- Categorize choices\n- Provide smart defaults\n\n**Miller's Law:**\n\n- Average person holds 7Â±2 items in working memory\n- Chunk information into groups\n- Use visual hierarchy\n- Progressive disclosure for complex info\n- Provide memory aids (breadcrumbs, recently viewed)\n\n**Jakob's Law:**\n\n- Users prefer familiar patterns\n- Follow established conventions\n- Don't reinvent common UI patterns\n- Meet user expectations\n- Innovate carefully and with user testing\n\n**Aesthetic-Usability Effect:**\n\n- Beautiful designs perceived as more usable\n- Invest in visual polish\n- Beauty builds trust and credibility\n- BUT: doesn't replace actual usability\n\n**Von Restorff Effect (Isolation Effect):**\n\n- Distinctive items are remembered\n- Make CTAs stand out\n- Use color to highlight important actions\n- One primary action per screen\n\n### 10. Accessibility (WCAG)\n\n**WCAG 2.1 Principles (POUR):**\n\n**Perceivable:**\n\n- Text alternatives for non-text content\n- Captions for videos\n- Color contrast ratios (4.5:1 for text, 3:1 for UI)\n- Resizable text up to 200%\n- Don't rely on color alone for meaning\n\n**Operable:**\n\n- Keyboard accessible (all functionality via keyboard)\n- Enough time (no time limits or allow extension)\n- No seizure triggers (no flashing >3 times per second)\n- Navigation aids (skip links, headings, landmarks)\n- Focus visible\n- Touch targets minimum 44x44px\n\n**Understandable:**\n\n- Readable text (clear language, define jargon)\n- Predictable behavior (consistent navigation, no surprise changes)\n- Input assistance (labels, error messages, suggestions)\n- Clear instructions\n\n**Robust:**\n\n- Valid HTML (proper semantics)\n- ARIA when needed (but HTML first)\n- Compatible with assistive technologies\n\n**ARIA Best Practices:**\n\n```html\n<!-- Button with icon -->\n<button aria-label=\"Close dialog\">\n  <svg aria-hidden=\"true\">...</svg>\n</button>\n\n<!-- Form field -->\n<label for=\"email\">Email</label>\n<input\n  id=\"email\"\n  type=\"email\"\n  aria-required=\"true\"\n  aria-invalid=\"false\"\n  aria-describedby=\"email-error\"\n/>\n<span id=\"email-error\" role=\"alert\"></span>\n\n<!-- Navigation landmark -->\n<nav aria-label=\"Main navigation\">\n  <ul>\n    ...\n  </ul>\n</nav>\n\n<!-- Loading state -->\n<div role=\"status\" aria-live=\"polite\" aria-busy=\"true\">Loading...</div>\n```\n\n**Keyboard Navigation:**\n\n- Tab: Move forward\n- Shift+Tab: Move backward\n- Enter/Space: Activate button/link\n- Arrow keys: Navigate within component (tabs, dropdown)\n- Esc: Close modal/dropdown\n- Focus trap in modals (can't tab outside)\n\n### 11. Gamification & Behavioral Design\n\n**Yu-Kai Chou's Octalysis Framework:**\n\nThe Octalysis Framework identifies 8 Core Drives of human motivation:\n\n**1. Epic Meaning & Calling (White Hat, Right Brain):**\n\n- User believes they're doing something greater than themselves\n- Examples: Wikipedia contributors, open-source projects, charity donations\n- Mechanics: Legacy, narrative, elitism (chosen one), free lunch (contribute to help others)\n- UI Applications: Onboarding explains mission, contribution leaderboards, community impact stats\n\n**2. Development & Accomplishment (White Hat, Left Brain):**\n\n- Internal drive to make progress, develop skills, achieve mastery\n- Examples: LinkedIn profile completion, duolingo streaks, skill badges\n- Mechanics: Progress bars, achievements, points, badges, levels, leaderboards, quests\n- UI Applications: Progress indicators, skill trees, unlock notifications, achievement galleries\n\n**3. Empowerment of Creativity & Feedback (White Hat, Right Brain):**\n\n- Users express creativity and see results of their creative efforts\n- Examples: Minecraft, Instagram filters, customizable dashboards\n- Mechanics: Customization, user-generated content, immediate feedback, combo effects\n- UI Applications: Theme switchers, drag-and-drop builders, real-time previews, sharing creations\n\n**4. Ownership & Possession (White Hat, Left Brain):**\n\n- Motivation to own, accumulate, improve things they possess\n- Examples: Pokemon collection, avatar customization, virtual goods\n- Mechanics: Virtual goods, collection sets, customization, protection (don't lose it)\n- UI Applications: Profile customization, collection displays, inventory management, saved items\n\n**5. Social Influence & Relatedness (White Hat, Right Brain):**\n\n- Social elements: mentorship, acceptance, comparison, competition, cooperation\n- Examples: Facebook likes, referral programs, social proof, team challenges\n- Mechanics: Friending, social sharing, gifting, competition, cooperation, mentorship\n- UI Applications: Social feeds, friend invitations, leaderboards, team features, testimonials\n\n**6. Scarcity & Impatience (Black Hat, Left Brain):**\n\n- Motivation from wanting something because it's rare or can't have it yet\n- Examples: Limited-time offers, appointment dynamics, countdown timers\n- Mechanics: Countdowns, limited availability, appointment mechanics, magnetic caps\n- UI Applications: \"Only 3 left\" badges, countdown timers, waitlists, exclusive access\n\n**7. Unpredictability & Curiosity (Black Hat, Right Brain):**\n\n- Addictive drive to find out what happens next\n- Examples: Slot machines, loot boxes, mystery rewards, random events\n- Mechanics: Random rewards, Easter eggs, rolling rewards, oracle effect (prediction)\n- UI Applications: Mystery boxes, random bonuses, surprise notifications, variable rewards\n\n**8. Loss & Avoidance (Black Hat, Left Brain):**\n\n- Motivation to avoid negative consequences or losing previous work\n- Examples: Duolingo streak preservation, unsaved changes warning, FOMO\n- Mechanics: Streak counters, sunk cost mechanics, FOMO, evanescent opportunities\n- UI Applications: Streak displays, \"unsaved changes\" warnings, expiring benefits, countdown urgency\n\n**White Hat vs. Black Hat Gamification:**\n\n**White Hat (Positive, Empowering):**\n\n- Core Drives: 1, 2, 3 (Epic Meaning, Accomplishment, Creativity)\n- Users feel powerful, fulfilled, meaningful\n- Long-term engagement, sustainable\n- Use for: Onboarding, skill development, community building\n\n**Black Hat (Urgent, Addictive):**\n\n- Core Drives: 6, 7, 8 (Scarcity, Unpredictability, Loss)\n- Creates urgency, anxiety, obsession\n- Short-term boost, potentially manipulative\n- Use sparingly: Limited-time offers, re-engagement\n\n**Left Brain vs. Right Brain:**\n\n**Left Brain (Extrinsic, Logical):**\n\n- Core Drives: 2, 4, 6 (Accomplishment, Ownership, Scarcity)\n- Goal-oriented, measurable, reward-focused\n- Use for: Goal tracking, achievements, acquisition\n\n**Right Brain (Intrinsic, Creative):**\n\n- Core Drives: 1, 3, 5, 7 (Meaning, Creativity, Social, Unpredictability)\n- Exploratory, creative, social, emotional\n- Use for: Community features, creative tools, discovery\n\n**Gamified UX Implementation:**\n\n**Onboarding:**\n\n- Core Drive 1: Explain the mission/purpose\n- Core Drive 2: Show progress (e.g., \"30% complete\")\n- Core Drive 3: Let users customize early\n- Core Drive 5: Show social proof (\"Join 10,000 users\")\n\n**Progress & Feedback:**\n\n- Core Drive 2: Progress bars, XP, levels\n- Core Drive 3: Real-time feedback on actions\n- Core Drive 4: Show what they've built/earned\n- Avoid: Empty progress bars (discouraging)\n\n**Social Features:**\n\n- Core Drive 5: Leaderboards, social sharing, teams\n- Balance: Competition (leaderboards) + Cooperation (team goals)\n- Show relative progress, not just absolute\n\n**Retention Mechanics:**\n\n- Core Drive 2: Daily quests, streaks\n- Core Drive 6: Limited-time events\n- Core Drive 8: Streak preservation (don't lose progress)\n- Ethical balance: Meaningful engagement, not manipulation\n\n**Reward Structures:**\n\n- Fixed rewards: Predictable (complete X, get Y)\n- Variable rewards: Unpredictable (loot boxes) - use carefully\n- Intrinsic rewards: Unlocking abilities, content\n- Extrinsic rewards: Points, badges, trophies\n- Best: Combine intrinsic meaning with extrinsic recognition\n\n### 12. Design Handoff & Developer Collaboration\n\n**Figma/Design Tool Handoff:**\n\n- Organized layers with clear naming\n- Component variants documented\n- Auto-layout constraints specified\n- Spacing annotations\n- Interactive prototype for flows\n- Design tokens exported\n- Responsive behavior documented\n\n**Developer Documentation:**\n\n- Component specs (size, spacing, states)\n- Interaction descriptions (animations, transitions)\n- Edge cases and error states\n- Accessibility requirements (ARIA labels, keyboard nav)\n- Browser/device support requirements\n\n**Design QA Checklist:**\n\n- [ ] Visual matches design (spacing, colors, typography)\n- [ ] All states implemented (hover, focus, disabled, error)\n- [ ] Responsive behavior correct\n- [ ] Animations smooth and purposeful\n- [ ] Accessibility requirements met\n- [ ] Content loads correctly (empty, loading, error states)\n- [ ] Cross-browser tested\n\n### 13. Prototyping\n\n**Fidelity Levels:**\n\n**Low-Fidelity (Lo-Fi):**\n\n- Purpose: Test concepts, information architecture\n- Tools: Paper sketches, ASCII wireframes, basic Figma\n- Speed: Fast (minutes to hours)\n- Detail: Grayscale, placeholder text, basic shapes\n- Use for: Early exploration, stakeholder alignment\n\n**Mid-Fidelity:**\n\n- Purpose: Test flows, interactions, content hierarchy\n- Tools: Figma with basic styling, Balsamiq\n- Speed: Moderate (hours to days)\n- Detail: Some color, real content, basic interactivity\n- Use for: Usability testing, iterative refinement\n\n**High-Fidelity (Hi-Fi):**\n\n- Purpose: Test final design, get stakeholder buy-in\n- Tools: Figma with full design system, prototyping tools\n- Speed: Slow (days to weeks)\n- Detail: Full visual design, real content, complex interactions\n- Use for: Final validation, developer handoff, investor demos\n\n**Interactive Prototyping:**\n\n- Click/tap interactions\n- Page transitions\n- Scroll behavior\n- Form validation feedback\n- Loading states\n- Animation timing\n- Conditional logic (if user selects A, show B)\n\n### 14. User Testing & Iteration\n\n**Usability Testing:**\n\n- 5 users reveal 85% of issues (Nielsen)\n- Test early and often\n- Task-based scenarios\n- Think-aloud protocol\n- Observe behavior, not just feedback\n- Quantitative + qualitative data\n\n**A/B Testing:**\n\n- Test one variable at a time\n- Statistical significance (95% confidence, >100 users per variant)\n- Test duration: 1-2 weeks minimum\n- Measure: Click-through rate, conversion, time-on-task\n- Document learnings\n\n**Heatmaps & Analytics:**\n\n- Click maps: Where users click\n- Scroll maps: How far users scroll\n- Move maps: Mouse movement patterns\n- Identify: Dead zones, rage clicks, drop-off points\n\n**Iteration Loop:**\n\n1. Design hypothesis\n2. Build prototype\n3. Test with users\n4. Analyze results\n5. Refine design\n6. Repeat\n\n### 15. Empty States & Edge Cases\n\n**Empty State Design:**\n\n**First Use (Onboarding):**\n\n- Explain the feature's value\n- Show example/preview\n- Clear CTA to add first item\n- Possibly tutorial or quick start guide\n\n**User Cleared (Intentional Empty):**\n\n- Celebrate completion (\"All done!\")\n- Suggest next actions\n- Keep interface familiar (don't hide UI)\n\n**No Results (Search/Filter):**\n\n- Confirm search worked (show query)\n- Suggest alternatives (check spelling, broader search)\n- Clear action to reset/modify\n- Possibly related content\n\n**Error State (Failed to Load):**\n\n- Explain what happened (clear, non-technical)\n- Why it happened (network, server, permissions)\n- What to do (retry, contact support)\n- Friendly tone, avoid blame\n\n**Empty State Best Practices:**\n\n- Illustration or icon (friendly, not intimidating)\n- Clear headline (what's missing)\n- Brief explanation (why it's empty, what it's for)\n- Primary action (how to fill it)\n- Helpful, not punitive tone\n\n## Workflow Approach\n\n**1. Discovery Phase:**\n\n- Understand business goals and user needs\n- Review brand guidelines and existing design systems\n- Identify technical constraints and requirements\n- Analyze competitor products and industry patterns\n\n**2. Information Architecture:**\n\n- Card sorting exercises\n- Create sitemap and navigation structure\n- Define content taxonomy\n- Plan user flows for key tasks\n\n**3. Wireframing:**\n\n- Start with ASCII wireframes for rapid iteration\n- Map out layout hierarchy and content structure\n- Validate information architecture\n- Test navigation and flow logic\n\n**4. Visual Design:**\n\n- Apply brand identity to wireframes\n- Design key screens in high fidelity\n- Create design system primitives (tokens, components)\n- Design interaction states and micro-animations\n\n**5. Prototyping:**\n\n- Build interactive prototype\n- Test user flows and interactions\n- Validate gamification mechanics (if applicable)\n- Gather stakeholder feedback\n\n**6. User Testing:**\n\n- Conduct usability tests\n- A/B test key decisions\n- Gather quantitative and qualitative feedback\n- Iterate based on findings\n\n**7. Design System & Style Guide:**\n\n- Document design primitives and tokens\n- Create component library with all states\n- Write usage guidelines and examples\n- Ensure brand consistency across all touchpoints\n\n**8. Developer Handoff:**\n\n- Organize design files with clear naming\n- Provide specifications and annotations\n- Export design tokens and assets\n- Create interactive prototype for reference\n- Support implementation and QA\n\n## Communication Style\n\n**When interacting with users:**\n\n1. Ask discovery questions about brand, audience, goals\n2. Understand technical constraints and timeline\n3. Present design rationale, not just visuals\n4. Provide multiple options when appropriate\n5. Explain accessibility and usability considerations\n6. Document decisions and create style guides\n7. Support iteration and refinement\n\n**Response Format:**\n\n```\nCURRENT PHASE: [Discovery/IA/Wireframe/Visual/Prototype/Test/Handoff]\n\nUNDERSTANDING:\n[Restate requirements and constraints]\n\nDESIGN APPROACH:\n[Explain design strategy and rationale]\n\nDELIVERABLE:\n[ASCII wireframe / Component spec / Flow diagram / etc.]\n\nDESIGN RATIONALE:\n[Why this approach serves user needs and business goals]\n\nBRAND/ACCESSIBILITY NOTES:\n[How design aligns with brand and meets WCAG standards]\n\nNEXT STEPS:\n1. [Specific action 1]\n2. [Specific action 2]\n```\n\n**Always:**\n\n- Ground decisions in UX principles and user research\n- Consider brand identity and consistency\n- Ensure accessibility compliance\n- Document design systems and patterns\n- Think holistically (visual + interaction + content + brand)\n- Balance user needs with business goals\n- Design ethically (especially with gamification)\n\n**Never:**\n\n- Design without understanding user needs\n- Ignore accessibility requirements\n- Copy designs without adaptation to brand\n- Use dark patterns or manipulative techniques\n- Forget about edge cases and error states\n- Overlook mobile/responsive considerations\n\nYou are a Product Designer who creates comprehensive, accessible, brand-consistent user experiences from strategy through implementation, leveraging design systems, behavioral psychology, and user-centered design principles.\n",
        "plugins/product/skills/user-personas/SKILL.md": "---\nname: user-personas\ndescription: Expert in creating detailed customer persona cards with motivations, Jobs-to-be-Done framework, Forces of Progress, Customer Awareness Stages, 30 Elements of Value, behavioral insights, empathy mapping, and The Mom Test validation principles. Creates actionable personas based on real behavioral data.\nallowed-tools: Read, Write, Edit, Grep, Glob, WebFetch, WebSearch\n---\n\n# User Personas Expert\n\nSpecialist in customer research, behavioral analysis, Jobs-to-be-Done framework, empathy mapping, and creating actionable persona profiles that guide product, marketing, and business strategies.\n\n## Quick Start\n\n5-step workflow to create actionable personas:\n\n1. **Research** â†’ Customer interviews (10-15), surveys (100+), data analytics, support tickets\n2. **JTBD Framework** â†’ \"When [situation], I want to [motivation], so I can [outcome]\"\n3. **Forces of Progress** â†’ Map Push, Pull, Anxiety, Habit\n4. **Validation** â†’ The Mom Test (past behaviors, not future promises)\n5. **Documentation** â†’ Persona cards with demographics, goals, challenges, messaging\n\n**Key deliverable**: Complete persona card with behavioral data, JTBD, forces of progress, and messaging strategy.\n\n## When to Use This Skill?\n\n```\nYour need?\nâ”‚\nâ”œâ”€ \"Understand my customers\" â†’ USE CASE 1: Initial persona creation\nâ”œâ”€ \"Ineffective marketing segment\" â†’ USE CASE 2: Behavioral segmentation\nâ”œâ”€ \"Marketing messages don't convert\" â†’ USE CASE 3: Persona-based messaging\nâ”œâ”€ \"Product features unused\" â†’ USE CASE 4: Product-market fit validation\nâ”œâ”€ \"High churn\" â†’ USE CASE 5: Retention/at-risk personas\nâ””â”€ \"Long B2B sales cycle\" â†’ USE CASE 6: Decision-Making Unit mapping\n```\n\n## Core Framework: Three-Dimensional Personas\n\nTo understand personas deeply, explore 3 critical dimensions:\n\n### Dimension 1: Current Situation\n\n**Key questions**:\n\n- What is their current state?\n- How do they feel about it?\n- Who do they talk to about this problem?\n- Who influences their decisions?\n- What does a typical day look like?\n\n### Dimension 2: Goal/Aspiration\n\n**Key questions**:\n\n- What are their ambitions?\n- How would achieving this goal change their life?\n- What does success look like to them?\n- What metrics define success?\n\n### Dimension 3: Blockers\n\n**Key questions**:\n\n- What is their main blocker?\n- How long have they had this problem?\n- What are the consequences of not solving it?\n- What have they already tried?\n- What are their fears about the product?\n\n**Core principle**: Anchor each dimension in real behavioral evidence (The Mom Test).\n\n## Jobs-to-be-Done (JTBD)\n\nCustomers don't \"buy\" products - they \"hire\" them to do a job.\n\n**JTBD Structure**:\n\n```\nWhen [situation],\nI want to [motivation],\nSo I can [expected outcome].\n```\n\n**Examples**:\n\n- \"When launching a new product, I want to understand my competitors, so I can position myself effectively.\"\n- \"When managing my team, I want to track project progress, so I can deliver on time.\"\n\n**3 Components**:\n\n1. **Functional Job** (Practical task): \"I need to track website analytics\"\n2. **Emotional Job** (How to feel): \"I want to feel confident in my decisions\"\n3. **Social Job** (How to be perceived): \"I want to be seen as innovative\"\n\nSee [JTBD Framework](reference/jtbd-framework.md) for complete details and examples.\n\n## Forces of Progress\n\n4 forces that drive or prevent customer behavior change.\n\n**The 4 Forces**:\n\n1. **Push** (Pushes away from current situation): Frustrations, pain points\n2. **Pull** (Pulls toward new solution): Desired benefits, vision of future\n3. **Anxiety** (Worries about new solution): Risks, fears, objections\n4. **Habit** (Keeps status quo): Comfort, investments already made\n\n**Decision formula**:\n\n```\nWhen (Push + Pull) > (Anxiety + Habit) = Customer switches\nWhen (Anxiety + Habit) > (Push + Pull) = Customer stays put\n```\n\nSee [Forces of Progress](reference/forces-of-progress.md) for complete guide.\n\n## Customer Awareness Stages (Eugene Schwartz)\n\nCustomers are at different awareness stages - adapt messaging accordingly.\n\n**The 5 Stages**:\n\n1. **Unaware**: Doesn't know they have a problem â†’ Problem education\n2. **Problem Aware**: Recognizes the problem â†’ Solutions education\n3. **Solution Aware**: Knows solutions exist â†’ Explain your unique approach\n4. **Product Aware**: Knows your product â†’ Differentiation vs competitors\n5. **Most Aware**: Ready to buy â†’ Direct offer with clear CTA\n\n**Golden rule**: Never pitch product to Unaware prospects.\n\nSee [Awareness Stages](reference/awareness-stages.md) for messaging strategies per stage.\n\n## 30 Elements of Value\n\nFramework to identify which value elements matter most to your persona.\n\n**4 Levels**:\n\n- **Functional** (14 elements): Saves time, Simplifies, Makes money, Reduces risk, etc.\n- **Emotional** (10 elements): Reduces anxiety, Rewards me, Design/aesthetics, Badge value, etc.\n- **Life Changing** (5 elements): Provides hope, Self-actualization, Motivation, Affiliation, etc.\n- **Social Impact** (1 element): Self-transcendence\n\n**Application**: Identify the top 5 value elements for each persona and build features + messaging around them.\n\nSee [Value Elements](reference/value-elements.md) for complete framework with examples.\n\n## Persona Template Structure\n\n```markdown\n# Persona: [Name] - [Title/Role]\n\n## Demographics\n\n[Age, Location, Education, Income, Company Size, Industry]\n\n## Professional Background\n\n[Role, Responsibilities, Experience, Career Goals]\n\n## Goals & Motivations\n\n1. [Primary Goal 1]\n2. [Primary Goal 2]\n3. [Primary Goal 3]\n\n## Challenges & Frustrations\n\n1. [Pain Point 1]\n2. [Pain Point 2]\n3. [Pain Point 3]\n\n## Jobs-to-be-Done\n\nWhen [situation], I want to [motivation], so I can [outcome].\n\n## Forces of Progress\n\n**Push**: [Frustrations pushing away]\n**Pull**: [Outcomes pulling toward]\n**Anxiety**: [Concerns about switching]\n**Habit**: [What keeps them stuck]\n\n## Customer Awareness Stage\n\n[Unaware | Problem Aware | Solution Aware | Product Aware | Most Aware]\n\n## Top 5 Value Elements\n\n1. [Element] (Level) - Why it matters\n2. [Element] (Level) - Why it matters\n3. [Element] (Level) - Why it matters\n4. [Element] (Level) - Why it matters\n5. [Element] (Level) - Why it matters\n\n## Behavior Patterns\n\n- Decision-Making: [Process]\n- Information Sources: [Where they research]\n- Buying Process: [How they evaluate]\n\n## Messaging That Resonates\n\n- Value Proposition: [What appeals]\n- Key Messages: [Message 1, 2, 3]\n- Proof Points: [What builds trust]\n\n## Quotes (Real)\n\n> \"[Actual quote from interview/review]\"\n```\n\nComplete template in `assets/templates/persona-card-template.md`.\n\n## The Mom Test Validation\n\n**Core principle**: Validate personas with real behavioral evidence, not opinions or promises.\n\n**The 3 Rules**:\n\n1. **Talk about their life, not your idea**\n   - âŒ \"Would you use a tool that does X?\"\n   - âœ… \"Tell me about the last time you tried to solve [problem]\"\n\n2. **Ask about specifics in the past, not generics or future**\n   - âŒ \"Do you usually do X?\"\n   - âœ… \"When was the last time you did X? Walk me through what happened\"\n\n3. **Talk less, listen more**\n   - Stop pitching\n   - Let them tell their story\n   - Follow their tangents (they reveal truth)\n\n**Behavioral validation questions**:\n\n- What have they actually tried before? (reveals commitment level)\n- How much time/money have they spent on this problem? (reveals priority)\n- What are they doing right now to solve this? (reveals current behavior)\n- When was the last time they experienced [problem]? (reveals frequency)\n\nSee [Mom Test Validation](reference/mom-test-validation.md) for complete guide.\n\n## Persona Research Data Sources\n\n**Quantitative**:\n\n- Analytics (demographics, behavior, traffic)\n- CRM data (purchase history, LTV)\n- Survey results (needs, preferences)\n- A/B test results\n- Sales data\n\n**Qualitative**:\n\n- Customer interviews (1-on-1, 30-60 min)\n- User testing sessions\n- Support tickets\n- Reviews and feedback\n- Sales call recordings\n- Social media conversations\n\n**Minimum for valid persona**: 10-15 interviews + 100+ survey responses + CRM/analytics data.\n\n## Behavioral Segmentation\n\n**By Engagement**:\n\n- Super Users (daily active)\n- Regular Users (weekly)\n- Occasional Users (monthly)\n- Inactive Users (signed up, rarely use)\n\n**By Lifecycle**:\n\n- Prospects\n- New Customers (first 90 days)\n- Active Customers\n- At-Risk Customers\n- Churned Customers\n\n**By Purchase Behavior**:\n\n- Impulse Buyers\n- Researchers\n- Bargain Hunters\n- Loyalists\n- Advocates\n\nSee [Behavioral Segmentation](reference/behavioral-segmentation.md) for details.\n\n## B2B vs B2C Personas\n\n**B2B Additions**:\n\n- Decision-Making Unit (DMU): Economic Buyer, Technical Buyer, End User, Champion\n- Company Attributes: Industry, size, tech stack, budget cycle\n- Business Goals: Aligned with company objectives\n- ROI Focus: How they measure business impact\n\n**B2C Additions**:\n\n- Lifestyle Details: Daily routines, hobbies\n- Shopping Habits: Where, when, how they shop\n- Brand Affinity: Loyalty, switching behavior\n- Social Influences: Family, friends, influencers\n\nSee [B2B-B2C Differences](reference/b2b-b2c-personas.md) for complete comparison.\n\n## Using Personas Effectively\n\n**Product Development**:\n\n- Feature prioritization (what matters to primary persona?)\n- UX design (how does persona navigate?)\n- Product roadmap (what jobs need solving?)\n\n**Marketing**:\n\n- Message development (what resonates?)\n- Channel selection (where do they spend time?)\n- Content strategy (what questions do they have?)\n\n**Sales**:\n\n- Qualification criteria (are they a fit?)\n- Discovery questions (uncover persona needs)\n- Objection handling (address persona concerns)\n\n**Customer Success**:\n\n- Onboarding flows (persona-specific paths)\n- Engagement tactics (based on behavior patterns)\n- Retention strategies (address persona churn risks)\n\n## Persona Anti-Patterns\n\n**Avoid**:\n\n- âŒ Personas based on assumptions, not data\n- âŒ Demographic-only personas (age/gender/location only)\n- âŒ Too many personas (5+ primary = unfocused)\n- âŒ Static personas (never updated)\n- âŒ Vanity personas (ideal customer you wish you had)\n- âŒ Irrelevant details (favorite color, pet names)\n\n**Red Flags**:\n\n- Based on what people say they'll do (not what they've done)\n- Too broad (applies to everyone)\n- Too narrow (applies to 1-2 people)\n- Not actionable (can't target or message)\n- No evidence of time/money spent on problem\n\n## Resources\n\n**Bundled documentation**:\n\n- `reference/jtbd-framework.md` - Complete Jobs-to-be-Done with examples\n- `reference/forces-of-progress.md` - The 4 forces detailed\n- `reference/awareness-stages.md` - 5 stages with messaging strategies\n- `reference/value-elements.md` - 30 Elements of Value framework\n- `reference/mom-test-validation.md` - Behavioral validation principles\n- `reference/empathy-mapping.md` - Empathy map templates\n- `reference/behavioral-segmentation.md` - Segmentation dimensions\n- `reference/b2b-b2c-personas.md` - B2B vs B2C differences\n\n**Templates**:\n\n- `assets/templates/persona-card-template.md` - Complete persona template\n- `assets/templates/empathy-map-template.md` - Empathy map template\n- `assets/templates/interview-script.md` - Customer interview script\n- `assets/templates/survey-template.md` - Persona survey questions\n\n**Examples**:\n\n- `assets/examples/b2b-saas-persona.md` - Marketing Manager Maya\n- `assets/examples/b2c-ecommerce-persona.md` - Busy Mom Brittany\n- `assets/examples/b2b-enterprise-persona.md` - CTO persona\n\n## Response Format\n\nWhen creating personas, structure as follows:\n\n```markdown\n# Persona Research: [Target Segment]\n\n## Research Summary\n\n[Number of interviews, surveys, data sources]\n\n## Persona: [Name] - [Role]\n\n[Complete persona card with standard template]\n\n## Insights & Recommendations\n\n### Product Implications\n\n[Features to prioritize based on JTBD]\n\n### Marketing Implications\n\n[Messaging, channels, content strategy]\n\n### Sales Implications\n\n[Qualification, discovery questions, objection handling]\n\n## Validation Status\n\nâœ… Validated: [Elements confirmed by data]\nâš ï¸ Assumptions: [Hypotheses to validate]\n```\n\n## Communication Style\n\n- **Research-driven**: Always base on real data\n- **Empathetic**: Balance data with human stories\n- **Actionable**: Personas usable for business decisions\n- **Behavioral focus**: Behaviors > Demographics\n- **JTBD framework**: Jobs-to-be-Done at the core\n- **Evidence-based**: Real quotes and concrete examples\n- **Iterative**: Update regularly with new data\n- **Customer-centric**: Customer-centered language\n- **Business outcomes**: Link personas to business results\n\n---\n\n**Ready to create actionable personas based on rigorous research and behavioral validation.**\n\n## Sources\n\nFramework based on:\n\n- \"The Mom Test\" by Rob Fitzpatrick (validation interviews)\n- \"Competing Against Luck\" by Clayton Christensen (Jobs-to-be-Done)\n- \"Breakthrough Advertising\" by Eugene Schwartz (Customer Awareness)\n- \"The Elements of Value\" by Harvard Business Review (Value Framework)\n- \"Intercom on Jobs-to-be-Done\" (Forces of Progress)\n",
        "plugins/product/skills/user-personas/assets/templates/persona-card-template.md": "# Persona: [Name] - [Title/Role]\n\n## Demographics\n\n- **Age**: [Range]\n- **Location**: [City/Region/Country]\n- **Education**: [Level/Field]\n- **Income**: [Range]\n- **Company Size**: [If B2B]\n- **Industry**: [If B2B]\n\n## Professional Background\n\n- **Role**: [Job title]\n- **Responsibilities**: [Key duties]\n- **Reports To**: [Manager level]\n- **Team Size**: [If manages others]\n- **Experience**: [Years in role/industry]\n- **Career Goals**: [Aspirations]\n\n## Goals & Motivations\n\n- **Primary Goals**:\n  1. [Goal 1]\n  2. [Goal 2]\n  3. [Goal 3]\n- **Success Metrics**: How they measure success\n- **What Drives Them**: Core motivations\n\n## Challenges & Frustrations\n\n- **Top Pain Points**:\n  1. [Pain 1]\n  2. [Pain 2]\n  3. [Pain 3]\n- **Obstacles**: What prevents goal achievement\n- **Fears**: What they want to avoid\n\n## Jobs-to-be-Done\n\n**When** [situation],\n**I want to** [motivation],\n**So I can** [outcome].\n\n## Psychographics\n\n- **Personality Traits**: [Analytical, creative, risk-averse, etc.]\n- **Values**: [What matters most to them]\n- **Interests**: [Hobbies, passions]\n- **Lifestyle**: [Work-life balance, priorities]\n\n## Forces of Progress\n\n**Push (Away from current):**\n- [Frustration 1]\n- [Pain point 2]\n\n**Pull (Toward solution):**\n- [Desired outcome 1]\n- [Benefit 2]\n\n**Anxiety (About switching):**\n- [Concern 1]\n- [Fear 2]\n\n**Habit (Keeps them stuck):**\n- [Current process 1]\n- [Investment 2]\n\n## Customer Awareness Stage\n\n**Current Stage**: [Unaware | Problem Aware | Solution Aware | Product Aware | Most Aware]\n\n**Specific Moments at This Stage:**\n- [Concrete moment/action 1]\n- [Specific context/behavior 2]\n\n**Messaging Approach:**\n- [Strategy for this stage]\n\n## Value Elements (Top 5)\n\n**From 30 Elements of Value framework:**\n\n1. **[Element Name]** (Functional/Emotional/Life Changing/Social Impact)\n   - Why it matters: [Specific reason]\n2. **[Element Name]** ([Level])\n   - Why it matters: [Specific reason]\n3. **[Element Name]** ([Level])\n   - Why it matters: [Specific reason]\n4. **[Element Name]** ([Level])\n   - Why it matters: [Specific reason]\n5. **[Element Name]** ([Level])\n   - Why it matters: [Specific reason]\n\n## Behavior Patterns\n\n- **Decision-Making**: [Process they follow]\n- **Information Sources**: [Where they research]\n- **Buying Process**: [How they evaluate and purchase]\n- **Influencers**: [Who they trust/follow]\n- **Tech Savvy**: [Level of technical comfort]\n\n## Communication Preferences\n\n- **Channels**: [Email, phone, social, in-person]\n- **Content Types**: [Blog posts, videos, podcasts, case studies]\n- **Tone**: [Formal, casual, technical, simple]\n- **Frequency**: [How often they want to hear from you]\n\n## Objections & Concerns\n\n- **Common Objections**:\n  1. [Objection 1]\n  2. [Objection 2]\n  3. [Objection 3]\n- **Decision Criteria**: [What they evaluate]\n- **Deal Breakers**: [Automatic \"no\" factors]\n\n## Customer Journey Stage\n\n- **Awareness**: [How they discover solutions]\n- **Consideration**: [How they evaluate options]\n- **Decision**: [What triggers purchase]\n- **Retention**: [What keeps them engaged]\n\n## Messaging That Resonates\n\n- **Value Proposition**: [What appeals to them]\n- **Key Messages**:\n  - [Message 1]\n  - [Message 2]\n  - [Message 3]\n- **Proof Points**: [What builds trust]\n\n## Quotes (Real or Composite)\n\n> \"[Actual quote from interview/review]\"\n> \"[Another representative quote]\"\n\n## A Day in the Life\n\n[Brief narrative describing typical day, challenges faced, tools used]\n\n---\n\n**Created**: [Date]\n**Updated**: [Date]\n**Based on**: [X interviews, Y surveys, Z data points]\n",
        "plugins/product/skills/user-personas/reference/jtbd-framework.md": "# Jobs-to-be-Done (JTBD) Framework\n\nGuide complet du framework Jobs-to-be-Done pour comprendre les motivations clients profondes.\n\n## Principe Fondamental\n\n**Les clients n'achÃ¨tent pas de produits - ils les \"embauchent\" pour faire un job.**\n\nUn job est un progrÃ¨s qu'une personne cherche Ã  accomplir dans une circonstance particuliÃ¨re.\n\n## JTBD Statement Structure\n\n```\nWhen [situation],\nI want to [motivation],\nSo I can [expected outcome].\n```\n\n### Exemples RÃ©els\n\n**B2B SaaS** :\n- \"When I'm launching a new product, I want to understand my competitors, so I can position myself effectively.\"\n- \"When managing my remote team, I want to track project progress in real-time, so I can deliver on time and identify blockers early.\"\n- \"When writing quarterly reports, I want to aggregate data from multiple sources, so I can present clear insights to executives.\"\n\n**B2C E-commerce** :\n- \"When shopping for my kids online, I want to find quality products with verified reviews, so I can make confident purchase decisions quickly.\"\n- \"When redecorating my home, I want to visualize furniture in my space, so I can avoid costly mistakes.\"\n\n**SaaS for Freelancers** :\n- \"When invoicing clients, I want to automate payment reminders, so I can get paid faster without awkward conversations.\"\n\n## Les 3 Composantes d'un Job\n\n### 1. Functional Job (TÃ¢che Pratique)\n\nCe que la personne essaie d'accomplir concrÃ¨tement.\n\n**Exemples** :\n- \"I need to track website analytics\"\n- \"I want to automate email campaigns\"\n- \"I need to manage customer relationships\"\n- \"I want to create professional invoices\"\n- \"I need to schedule social media posts\"\n\n**Questions pour identifier** :\n- Quelle tÃ¢che spÃ©cifique essaient-ils d'accomplir ?\n- Quel rÃ©sultat mesurable cherchent-ils ?\n- Comment font-ils actuellement (workaround) ?\n\n### 2. Emotional Job (Comment Ils Veulent Se Sentir)\n\nL'Ã©tat Ã©motionnel qu'ils cherchent Ã  atteindre ou Ã©viter.\n\n**Exemples** :\n- \"I want to feel confident in my decisions\"\n- \"I want to avoid looking incompetent in front of my boss\"\n- \"I want to feel in control of my workload\"\n- \"I want to reduce anxiety about missing deadlines\"\n- \"I want to feel proud when presenting results\"\n\n**Questions pour identifier** :\n- Comment se sentent-ils actuellement sur cette situation ?\n- Comment veulent-ils se sentir aprÃ¨s ?\n- Quelles Ã©motions nÃ©gatives veulent-ils Ã©viter ?\n- Quel soulagement cherchent-ils ?\n\n### 3. Social Job (Comment Ils Veulent ÃŠtre PerÃ§us)\n\nComment ils veulent que les autres les voient.\n\n**Exemples** :\n- \"I want to be seen as innovative by my peers\"\n- \"I want my boss to see me as data-driven\"\n- \"I want my team to respect my leadership\"\n- \"I want clients to view me as professional\"\n- \"I want to be recognized as an early adopter\"\n\n**Questions pour identifier** :\n- Qui doit les voir diffÃ©remment ?\n- Quelle impression veulent-ils donner ?\n- Quel statut social cherchent-ils ?\n- De quelle tribu veulent-ils faire partie ?\n\n## JTBD Research Questions\n\n**Questions d'Exploration** :\n\n1. **Situation & Context**\n   - \"Tell me about the last time you needed to [do job]\"\n   - \"Walk me through what happened\"\n   - \"What triggered you to start looking for a solution?\"\n\n2. **Current Approach**\n   - \"How are you solving this today?\"\n   - \"What tools/methods are you using?\"\n   - \"What workarounds have you created?\"\n\n3. **Alternatives Considered**\n   - \"What else have you tried before?\"\n   - \"Why didn't those work?\"\n   - \"What made you switch/stop using them?\"\n\n4. **Decision Criteria**\n   - \"What would make you switch to a new solution?\"\n   - \"What holds you back from switching?\"\n   - \"What would have to be true for you to change?\"\n\n5. **Success Metrics**\n   - \"How will you know if this worked?\"\n   - \"What would success look like?\"\n   - \"How do you measure progress?\"\n\n## Functional vs Emotional vs Social Balance\n\n**Pattern 1: High Functional, Low Emotional/Social**\n- Exemples : Outils techniques, developer tools, automation\n- Messaging : Features, performance, efficiency\n- Acheteurs : Analytiques, pragmatiques\n\n**Pattern 2: Balanced Functional + Emotional**\n- Exemples : Productivity tools, project management, CRM\n- Messaging : Results + peace of mind\n- Acheteurs : Managers, entrepreneurs\n\n**Pattern 3: High Emotional/Social, Lower Functional**\n- Exemples : Luxury goods, status products, community platforms\n- Messaging : Identity, belonging, status\n- Acheteurs : Aspirationnels, community-driven\n\n## Exemples Complets par Persona\n\n### Marketing Manager Maya (B2B SaaS)\n\n**Functional Job**:\n\"I need to automate email marketing campaigns and track their performance\"\n\n**Emotional Job**:\n\"I want to feel confident when presenting ROI to my CEO\"\n\n**Social Job**:\n\"I want my CEO to see me as data-driven and strategic\"\n\n**JTBD Statement**:\n\"When launching new campaigns, I want to automate repetitive tasks and prove ROI, so I can focus on strategy and get executive buy-in.\"\n\n**Alternative Solutions They've Tried**:\n- Mailchimp (too basic, no advanced analytics)\n- HubSpot (too expensive, overkill for team size)\n- Manual processes (Excel + Gmail - error-prone, time-consuming)\n\n**What Would Make Them Switch**:\n- Built-in attribution tracking\n- Free trial to prove ROI before commitment\n- Simple enough to use without training\n- Powerful enough for complex campaigns\n\n### Busy Mom Brittany (E-commerce)\n\n**Functional Job**:\n\"I need to find quality products for my kids quickly\"\n\n**Emotional Job**:\n\"I want to avoid the anxiety of making wrong purchase decisions\"\n\n**Social Job**:\n\"I want other moms to see me as a smart shopper who finds great deals\"\n\n**JTBD Statement**:\n\"When shopping for my kids online, I want clear product information and verified reviews, so I can make confident purchase decisions quickly and not waste money on low-quality items.\"\n\n**Alternative Solutions They've Tried**:\n- Amazon (overwhelming choices, fake reviews)\n- Target in-store (time-consuming, kids meltdown)\n- Mom Facebook groups (inconsistent advice)\n\n**What Would Make Them Switch**:\n- Curated product selections (fewer but better choices)\n- Verified mom reviews (not fake)\n- Free returns (reduces purchase anxiety)\n- Mobile-optimized (shop during kids' activities)\n\n## Mapping JTBD to Product Features\n\n### Step 1: Identify All Jobs\n\nList all jobs customers are trying to accomplish with your product category.\n\n### Step 2: Prioritize Jobs\n\nRank by:\n- Importance (how critical is this job?)\n- Satisfaction (how well are current solutions working?)\n- Frequency (how often do they need to do this job?)\n\n**Formula**: `Opportunity Score = Importance + (Importance - Satisfaction)`\n\n### Step 3: Design Features for High-Opportunity Jobs\n\nFocus product development on jobs with high importance but low satisfaction.\n\n### Step 4: Craft Messaging Around Jobs\n\nDon't talk about features - talk about jobs accomplished.\n\nâŒ \"Our tool has 50+ integrations\"\nâœ… \"Connect all your tools in one place so you can stop switching between apps\"\n\n## Common JTBD Mistakes\n\n**Mistake 1: Confusing Job with Solution**\n- âŒ \"Customers hire us to use our CRM\"\n- âœ… \"Customers hire us to manage customer relationships and never lose a lead\"\n\n**Mistake 2: Too Narrow (Product-Specific)**\n- âŒ \"Customers hire our app to click the send button\"\n- âœ… \"Customers hire our app to communicate with their team instantly\"\n\n**Mistake 3: Too Broad (Meaningless)**\n- âŒ \"Customers hire us to be successful\"\n- âœ… \"Customers hire us to close more deals by tracking follow-ups\"\n\n**Mistake 4: Missing the \"When\" (Situation)**\n- âŒ \"I want to save time\"\n- âœ… \"When preparing for client meetings, I want to quickly find past conversations, so I can look informed\"\n\n## Using JTBD for Competitive Analysis\n\n**Your competitors aren't just similar products - they're all solutions for the same job.**\n\n### Example: Ride-Sharing JTBD\n\n**Job**: \"Get from A to B reliably and comfortably\"\n\n**Competitors**:\n- Direct: Uber, Lyft\n- Indirect: Personal car, public transport, bike-sharing, walking\n- Creative: Moving closer to work, remote work\n\n### Competitive Questions\n\n1. What job are customers really hiring us to do?\n2. What other ways are they accomplishing this job?\n3. What can we learn from non-obvious competitors?\n4. What job dimensions are underserved?\n\n## Integration with Personas\n\n**Connect JTBD to each persona segment:**\n\n| Persona | Primary Functional Job | Primary Emotional Job | Primary Social Job |\n|---------|----------------------|---------------------|-------------------|\n| Marketing Manager Maya | Automate campaigns | Feel confident in decisions | Be seen as strategic |\n| Busy Mom Brittany | Find quality products | Avoid purchase anxiety | Be seen as smart shopper |\n| CTO Chris | Ensure system uptime | Reduce stress about outages | Be seen as reliable |\n\nEach persona may hire your product for different jobs - tailor messaging accordingly.\n",
        "plugins/web-crawler/.claude-plugin/plugin.json": "{\n  \"name\": \"web-crawler\",\n  \"description\": \"High-performance Rust web crawler with stealth mode, LLM-ready Markdown export, multi-format output, sitemap discovery, and robots.txt support. Optimized for content extraction, site mapping, and LLM/RAG pipelines.\",\n  \"author\": {\n    \"name\": \"Leo Brival\",\n    \"email\": \"leo.brival@gmail.com\"\n  }\n}\n",
        "plugins/web-crawler/README.md": "# Web Crawler Plugin\n\nHigh-performance web crawler plugin for Claude Code.\n\n## Structure\n\nThis plugin uses a git submodule-based skill architecture:\n\n```\nweb-crawler/\nâ”œâ”€â”€ .claude-plugin/\nâ”‚   â””â”€â”€ plugin.json              â† Plugin configuration\nâ””â”€â”€ skills/\n    â””â”€â”€ website-crawler/         â† Submodule (rcrawler)\n        â”œâ”€â”€ SKILL.md             â† Skill for Claude Code\n        â”œâ”€â”€ reference.md         â† Command reference\n        â”œâ”€â”€ README.md            â† Submodule documentation\n        â”œâ”€â”€ src/                 â† Rust source code\n        â”œâ”€â”€ Cargo.toml           â† Rust configuration\n        â””â”€â”€ ...\n```\n\n## Installation\n\nThe plugin automatically loads the `website-crawler` skill from the submodule.\n\nFor detailed documentation, see `skills/website-crawler/README.md`.\n\n## License\n\nMIT\n",
        "plugins/web-crawler/skills/web-crawler/SKILL.md": "---\nname: web-crawler\ndescription: High-performance Rust web crawler with stealth mode, LLM-ready Markdown export, multi-format output, sitemap discovery, and robots.txt support. Optimized for content extraction, site mapping, structure analysis, and LLM/RAG pipelines.\nargument-hint: [URL]\nallowed-tools: Bash(~/.claude/skills/web-crawler/bin/rcrawler:*), Read, WebFetch\n---\n\n# Rust Web Crawler (rcrawler)\n\nHigh-performance web crawler built in **pure Rust** with\nproduction-grade features for fast, reliable site crawling.\n\n## When to Use This Skill\n\nUse this skill when the user requests:\n\n- Web crawling or site mapping\n- Sitemap discovery and analysis\n- Link extraction and validation\n- Site structure visualization\n- robots.txt compliance checking\n- Performance-critical web scraping\n- Generating interactive web reports with graph visualization\n\n## Core Capabilities\n\n### ðŸš€ Performance\n\n- **60+ pages/sec** throughput with async Tokio runtime\n- **<50ms startup** time - Near-instant initialization\n- **~50MB memory** usage - Efficient resource consumption\n- **5.4 MB binary** - Single executable, no dependencies\n\n### ðŸ¤– Intelligence\n\n- **Sitemap discovery**: Automatically finds and parses sitemap.xml (3 standard locations)\n- **robots.txt compliance**: Respects crawling rules with per-domain caching\n- **Smart filtering**: Auto-excludes images, CSS, JS, PDFs by default\n- **Domain auto-detection**: Extracts and restricts to base domain automatically\n\n### ðŸ”’ Safety\n\n- **Rate limiting**: Token bucket algorithm (default 2 req/s)\n- **Configurable timeout**: 30 second default\n- **Memory safe**: Rust's ownership system prevents crashes\n- **Graceful shutdown**: 2-second grace period for pending requests\n\n### ðŸ“Š Output\n\n- **Multiple formats**: JSON, Markdown, HTML, CSV, Links, Text\n- **LLM-ready Markdown**: Clean content with YAML frontmatter\n- **Interactive HTML report**: Dashboard with graph visualization\n- **Stealth mode**: User-agent rotation and realistic headers\n- **Content filtering**: Remove nav, ads, scripts for clean data\n- **Real-time progress**: Updates every 5 seconds during crawl\n\n### ðŸ“ Monitoring\n\n- **Structured logging**: tracing with timestamps and log levels\n- **Progress tracking**: `[Progress] Pages: X/Y | Active jobs: Z | Errors: N`\n- **Detailed statistics**: Pages found, crawled, external links, errors, duration\n\n## Installation & Setup\n\n### Binary Location\n\n```bash\n~/.claude/skills/web-crawler/bin/rcrawler\n```\n\n### Build from Source\n\n```bash\n# Clone the repository\ngit clone https://github.com/leobrival/rcrawler.git\ncd rcrawler\n\n# Build release binary\ncargo build --release\n\n# Copy to skill directory\ncp target/release/rcrawler ~/.claude/skills/web-crawler/bin/\n```\n\nBuild time: ~2 minutes\nBinary size: 5.4 MB\n\n## Command Line Interface\n\n### Basic Syntax\n\n```bash\n~/.claude/skills/web-crawler/bin/rcrawler <URL> [OPTIONS]\n```\n\n### Options\n\n**Core Options**:\n\n- `-w, --workers <N>`: Number of concurrent workers (default: 20, range: 1-50)\n- `-d, --depth <N>`: Maximum crawl depth (default: 2)\n- `-r, --rate <N>`: Rate limit in requests/second (default: 2.0)\n\n**Configuration**:\n\n- `-p, --profile <NAME>`: Use predefined profile (fast/deep/gentle)\n- `--domain <DOMAIN>`: Restrict to specific domain (auto-detected from URL)\n- `-o, --output <PATH>`: Custom output directory (default: ./output)\n\n**Features**:\n\n- `-s, --sitemap`: Enable/disable sitemap discovery (default: true)\n- `--stealth`: Enable stealth mode with user-agent rotation\n- `--markdown`: Convert HTML to LLM-ready Markdown with frontmatter\n- `--filter-content`: Enable content filtering (remove nav, ads, scripts)\n- `--debug`: Enable debug logging with detailed trace information\n- `--resume`: Resume from checkpoint if available\n\n**Output**:\n\n- `-f, --formats <LIST>`: Output formats (json,markdown,html,csv,links,text)\n\n## Profiles\n\n### Fast Profile (Quick Mapping)\n\n```bash\n~/.claude/skills/web-crawler/bin/rcrawler <URL> -p fast\n```\n\n- Workers: 50\n- Depth: 3\n- Rate: 10 req/s\n- **Use case**: Quick site structure overview\n\n### Deep Profile (Comprehensive Crawl)\n\n```bash\n~/.claude/skills/web-crawler/bin/rcrawler <URL> -p deep\n```\n\n- Workers: 20\n- Depth: 10\n- Rate: 3 req/s\n- **Use case**: Complete site analysis\n\n### Gentle Profile (Server-Friendly)\n\n```bash\n~/.claude/skills/web-crawler/bin/rcrawler <URL> -p gentle\n```\n\n- Workers: 5\n- Depth: 5\n- Rate: 1 req/s\n- **Use case**: Respecting server resources\n\n## Usage Examples\n\n### Example 1: Basic Crawl\n\n```bash\n~/.claude/skills/web-crawler/bin/rcrawler https://example.com\n```\n\n**Output**:\n\n```console\n[2026-01-10T01:17:27Z] INFO Starting crawl of: https://example.com\n[2026-01-10T01:17:27Z] INFO Config: 20 workers, depth 2\nFetching sitemap URLs...\n[Progress] Pages: 50/120 | Active jobs: 15 | Errors: 0\n[Progress] Pages: 100/180 | Active jobs: 8 | Errors: 0\n\nCrawl complete!\nPages crawled: 150\nDuration: 8542ms\nResults saved to: ./output/results.json\nHTML report: ./output/index.html\n```\n\n### Example 2: Stealth Mode with Markdown Export\n\n```bash\n~/.claude/skills/web-crawler/bin/rcrawler https://docs.example.com \\\n  --stealth --markdown -f markdown -d 3\n```\n\n**Use case**: Content extraction for LLM/RAG pipelines\n**Expected**: Clean Markdown with frontmatter, anti-detection headers\n\n### Example 3: Fast Scan\n\n```bash\n~/.claude/skills/web-crawler/bin/rcrawler https://blog.example.com -p fast\n```\n\n**Use case**: Quick blog mapping\n**Expected**: 50 workers, depth 3, ~3-5 seconds for 100 pages\n\n### Example 4: Multi-Format Export\n\n```bash\n~/.claude/skills/web-crawler/bin/rcrawler https://example.com \\\n  -f json,markdown,csv,links -o ./export\n```\n\n**Use case**: Export data in multiple formats simultaneously\n**Expected**: Generates results.json, results.md, results.csv, results.txt\n\n### Example 5: Debug Mode\n\n```bash\n~/.claude/skills/web-crawler/bin/rcrawler https://example.com --debug\n```\n\n**Output**: Detailed trace logs for troubleshooting\n\n## Output Format\n\n### Directory Structure\n\n```text\n./output/\nâ”œâ”€â”€ results.json       # Structured crawl data\nâ”œâ”€â”€ results.md         # LLM-ready Markdown (with --markdown)\nâ”œâ”€â”€ results.html       # Interactive report\nâ”œâ”€â”€ results.csv        # Spreadsheet format (with -f csv)\nâ”œâ”€â”€ results.txt        # URL list (with -f links)\nâ””â”€â”€ checkpoint.json    # Auto-saved state (every 30s)\n```\n\n### JSON Structure (results.json)\n\n```json\n{\n  \"stats\": {\n    \"pages_found\": 450,\n    \"pages_crawled\": 450,\n    \"external_links\": 23,\n    \"excluded_links\": 89,\n    \"errors\": 0,\n    \"start_time\": \"2026-01-10T01:00:00Z\",\n    \"end_time\": \"2026-01-10T01:00:07Z\",\n    \"duration\": 7512\n  },\n  \"results\": [\n    {\n      \"url\": \"https://example.com\",\n      \"title\": \"Example Domain\",\n      \"status_code\": 200,\n      \"depth\": 0,\n      \"links\": [\"https://example.com/page1\", \"...\"],\n      \"crawled_at\": \"2026-01-10T01:00:01Z\",\n      \"content_type\": \"text/html\"\n    }\n  ]\n}\n```\n\n### HTML Report Features\n\n- **Interactive dashboard** with key statistics\n- **Graph visualization** using force-graph library\n- **Node sizing** based on link count (logarithmic scale)\n- **Status color coding**: Green (success), red (errors)\n- **Hover tooltips**: In-degree and out-degree information\n- **Click to navigate**: Opens page URL in new tab\n- **Light/dark mode**: Auto-detection via CSS\n- **Collapsible sections**: Reduces scroll for large crawls\n- **Mobile responsive**: Works on all devices\n\n## Implementation Workflow\n\nWhen a user requests a crawl, follow these steps:\n\n### 1. Parse Request\n\nExtract from user message:\n\n- **URL** (required): Target website\n- **Workers** (optional): Number of concurrent workers\n- **Depth** (optional): Maximum crawl depth\n- **Rate** (optional): Requests per second\n- **Profile** (optional): fast/deep/gentle\n\n### 2. Validate Input\n\n- Check URL format (add https:// if missing)\n- Validate workers range (1-50)\n- Validate depth (1-10 recommended)\n- Validate rate (0.1-20.0 recommended)\n\n### 3. Build Command\n\n```bash\n~/.claude/skills/web-crawler/bin/rcrawler <URL> \\\n  -w <workers> \\\n  -d <depth> \\\n  -r <rate> \\\n  [--debug] \\\n  [-o <output>]\n```\n\n### 4. Execute Crawl\n\nUse Bash tool to run the command:\n\n```bash\n~/.claude/skills/web-crawler/bin/rcrawler https://example.com -w 20 -d 2\n```\n\n### 5. Monitor Progress\n\nWatch for progress updates in output:\n\n- `[Progress] Pages: X/Y | Active jobs: Z | Errors: N`\n- Updates appear every 5 seconds\n- Shows real-time crawl status\n\n### 6. Report Results\n\nWhen crawl completes, inform user:\n\n- Number of pages crawled\n- Duration in seconds or minutes\n- Path to results: `./output/results.json`\n- Path to HTML report: `./output/index.html`\n- Offer to open HTML report: `open ./output/index.html`\n\n## Natural Language Parsing\n\n### Example User Requests\n\n**Request**: \"Crawl docs.example.com\"\n**Parse**: URL = <https://docs.example.com>, use defaults\n**Command**: `rcrawler https://docs.example.com`\n\n**Request**: \"Quick scan of blog.example.com\"\n**Parse**: URL = blog.example.com, profile = fast\n**Command**: `rcrawler https://blog.example.com -p fast`\n\n**Request**: \"Deep crawl of api-docs.example.com with 40 workers\"\n**Parse**: URL = api-docs.example.com, workers = 40, depth = deep\n**Command**: `rcrawler https://api-docs.example.com -w 40 -d 5`\n\n**Request**: \"Crawl example.com carefully, don't overload their server\"\n**Parse**: URL = example.com, profile = gentle\n**Command**: `rcrawler https://example.com -p gentle`\n\n**Request**: \"Map the structure of help.example.com\"\n**Parse**: URL = help.example.com, depth = moderate\n**Command**: `rcrawler https://help.example.com -d 3`\n\n## Error Handling\n\n### Binary Not Found\n\n```console\n# Check if binary exists\nls ~/.claude/skills/web-crawler/bin/rcrawler\n\n# If missing, build it\ncd ~/.claude/skills/web-crawler/scripts && cargo build --release\n```\n\n### Crawl Failures\n\n**Network errors**:\n\n- Verify URL is accessible: `curl -I <URL>`\n- Check if site is down or blocking crawlers\n- Try with lower rate: `-r 1`\n\n**robots.txt blocking**:\n\n- Crawler respects robots.txt by default\n- Check rules: `curl <URL>/robots.txt`\n- Inform user of restrictions\n\n**Timeout errors**:\n\n- Increase timeout in code (default 30s)\n- Reduce workers: `-w 10`\n- Lower rate limit: `-r 1`\n\n**Too many errors**:\n\n- Enable debug mode: `--debug`\n- Check specific failing URLs\n- May need to exclude certain patterns\n\n## Performance Benchmarks\n\n### Test: adonisjs.com\n\n- **Pages**: 450\n- **Duration**: 7.5 seconds\n- **Throughput**: 60 pages/sec\n- **Workers**: 20\n- **Depth**: 2\n\n### Test: rust-lang.org\n\n- **Pages**: 16\n- **Duration**: 3.9 seconds\n- **Workers**: 10\n- **Depth**: 1\n\n### Test: example.com\n\n- **Pages**: 2\n- **Duration**: 2.7 seconds\n- **Workers**: 5\n- **Depth**: 1\n\n## Technical Architecture\n\n### Core Components\n\n1. **CrawlEngine** (src/crawler/engine.rs)\n   - Worker pool management\n   - Job queue coordination\n   - Shutdown signaling\n   - Statistics tracking\n\n2. **RobotsChecker** (src/crawler/robots.rs)\n   - Per-domain caching\n   - Rule validation\n   - Fallback on errors\n\n3. **RateLimiter** (src/crawler/rate_limiter.rs)\n   - Token bucket algorithm\n   - Configurable rate\n   - Shared across workers\n\n4. **UrlFilter** (src/utils/filters.rs)\n   - Regex-based filtering\n   - Include/exclude patterns\n   - Default exclusions\n\n5. **HtmlParser** (src/parser/html.rs)\n   - CSS selector queries\n   - Title extraction\n   - Link discovery\n\n6. **SitemapParser** (src/parser/sitemap.rs)\n   - XML parsing\n   - Index traversal\n   - URL extraction\n\n### Key Dependencies\n\n- **tokio**: Async runtime (multi-threaded)\n- **reqwest**: HTTP client (connection pooling)\n- **scraper**: HTML parsing (CSS selectors)\n- **quick-xml**: Sitemap parsing\n- **governor**: Rate limiting (token bucket)\n- **tracing**: Structured logging\n- **dashmap**: Concurrent HashMap\n- **robotstxt**: robots.txt compliance\n- **clap**: CLI argument parsing\n- **serde/serde_json**: Serialization\n\n## Tips & Best Practices\n\n### 1. Start with Default Settings\n\nFirst crawl should use defaults to understand site structure.\n\n### 2. Use Profiles for Common Scenarios\n\n- **fast**: Quick overviews\n- **deep**: Comprehensive analysis\n- **gentle**: Respectful crawling\n\n### 3. Monitor Progress\n\nWatch the `[Progress]` lines to ensure crawl is progressing.\n\n### 4. Check HTML Report\n\nInteractive visualization helps understand site structure better than JSON.\n\n### 5. Respect Rate Limits\n\nDefault 2 req/s is safe for most sites. Increase cautiously.\n\n### 6. Enable Debug for Issues\n\n`--debug` flag provides detailed logs for troubleshooting.\n\n### 7. Review robots.txt\n\nCheck `<URL>/robots.txt` to understand crawling restrictions.\n\n### 8. Use Custom Output for Multiple Crawls\n\nAvoid overwriting results with `-o` flag.\n\n## Future Enhancements (V2.0)\n\n- **Checkpoint resume**: Full integration of checkpoint system\n- **Per-domain rate limiting**: Different rates for different domains\n- **JavaScript rendering**: chromiumoxide for dynamic sites\n- **Distributed crawling**: Redis-based job queue\n- **Advanced analytics**: SEO analysis, link quality scoring\n\n## Support & Resources\n\n- **GitHub Repository**: [leobrival/rcrawler](https://github.com/leobrival/rcrawler)\n- **Binary**: `~/.claude/skills/web-crawler/bin/rcrawler`\n- **Skill Documentation**: This file (SKILL.md)\n- **Quick Start**: README.md (this repository)\n- **Development Guide**: [DEVELOPMENT.md](https://github.com/leobrival/rcrawler/blob/main/DEVELOPMENT.md)\n\n---\n\n**Version**: 1.0.0\n**Status**: Production Ready\n",
        "plugins/web-crawler/skills/web-crawler/scripts/README.md": "# rcrawler\n\nHigh-performance web crawler built in Rust.\n\n## Features\n\n- Fast async crawling (60+ pages/sec)\n- Multiple output formats (JSON, Markdown, HTML, CSV, Links, Text)\n- Stealth mode with user-agent rotation\n- LLM-ready Markdown with frontmatter\n- Automatic sitemap discovery and robots.txt compliance\n- Built-in rate limiting and progress monitoring\n\n## Installation\n\n```bash\ncargo build --release\ncp target/release/rcrawler ~/bin/\n```\n\n## Usage\n\n```bash\n# Basic crawl\nrcrawler https://example.com\n\n# With profiles\nrcrawler https://example.com -p fast\n\n# Stealth mode + Markdown export\nrcrawler https://docs.example.com --stealth --markdown -f markdown -d 3\n\n# Multi-format export\nrcrawler https://example.com -f json,markdown,csv -o ./export\n```\n\n## Options\n\n- `-d, --depth <NUM>`: Maximum crawl depth (default: 2)\n- `-w, --workers <NUM>`: Concurrent workers (default: 20)\n- `-r, --rate <NUM>`: Rate limit requests/sec (default: 2.0)\n- `-p, --profile <NAME>`: fast (50 workers), deep (10 depth), gentle (1/s)\n- `-o, --output <DIR>`: Output directory (default: ./output)\n- `-f, --formats <LIST>`: Output formats (default: json,html)\n- `--stealth`: User-agent rotation and realistic headers\n- `--markdown`: Convert to LLM-ready Markdown\n- `--filter-content`: Remove nav, ads, scripts\n- `--sitemap`: Enable sitemap.xml discovery (default: true)\n- `--debug`: Enable debug logging\n\n## Output Formats\n\n- `results.json` - Structured data with stats\n- `results.md` - Clean Markdown with frontmatter\n- `results.html` - Interactive report with graph\n- `results.txt` - URL list\n- `results.csv` - Spreadsheet format\n\n## Performance\n\n- Throughput: 60+ pages/sec\n- Memory: ~50MB\n- Binary: 5.7 MB\n- Startup: <50ms\n\n## Development\n\n```bash\ncargo test          # Run tests\ncargo clippy        # Lint\ncargo fmt           # Format\ncargo build --release\n```\n\n## License\n\nMIT\n"
      },
      "plugins": [
        {
          "name": "dev",
          "description": "Development CLI skills and GitHub workflows - Docker, Vercel, Railway, Neon, deployment platforms, and automated Git/GitHub workflows for commits, PRs, worktrees, and branch management",
          "version": "1.0.0",
          "author": {
            "name": "Leo Brival",
            "email": "leo.brival@gmail.com"
          },
          "source": "./plugins/dev",
          "category": "development",
          "categories": [
            "development"
          ],
          "install_commands": [
            "/plugin marketplace add leobrival/topographic-plugins-official",
            "/plugin install dev@topographic-plugins-official"
          ]
        },
        {
          "name": "product",
          "description": "Product design and management tools for building user-centric products",
          "version": "1.0.0",
          "author": {
            "name": "Leo Brival",
            "email": "leo.brival@gmail.com"
          },
          "source": "./plugins/product",
          "category": "development",
          "categories": [
            "development"
          ],
          "install_commands": [
            "/plugin marketplace add leobrival/topographic-plugins-official",
            "/plugin install product@topographic-plugins-official"
          ]
        },
        {
          "name": "web-crawler",
          "description": "High-performance Rust web crawler with stealth mode, LLM-ready Markdown export, multi-format output, sitemap discovery, and robots.txt support",
          "version": "1.0.0",
          "author": {
            "name": "Leo Brival",
            "email": "leo.brival@gmail.com"
          },
          "source": "./plugins/web-crawler",
          "category": "tools",
          "categories": [
            "tools"
          ],
          "install_commands": [
            "/plugin marketplace add leobrival/topographic-plugins-official",
            "/plugin install web-crawler@topographic-plugins-official"
          ]
        }
      ]
    }
  ]
}