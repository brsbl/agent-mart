{
  "author": {
    "id": "billy-enrizky",
    "display_name": "Muhammad Enrizky Brillian",
    "avatar_url": "https://avatars.githubusercontent.com/u/132111170?u=f5822b873ac6ab4e03425c39c50e2bc6900a21d1&v=4"
  },
  "marketplaces": [
    {
      "name": "openbrowser-ai",
      "version": null,
      "description": "AI-powered browser automation for Claude Code -- navigate, click, type, extract content, and automate workflows in real browsers",
      "repo_full_name": "billy-enrizky/openbrowser-ai",
      "repo_url": "https://github.com/billy-enrizky/openbrowser-ai",
      "repo_description": "OpenBrowser is a framework for intelligent browser automation. It combines direct CDP communication with a CodeAgent architecture, where the LLM writes Python code executed in a persistent namespace, to navigate, interact with, and extract information from web pages autonomously.",
      "signals": {
        "stars": 4,
        "forks": 0,
        "pushed_at": "2026-02-21T20:35:42Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"$schema\": \"https://anthropic.com/claude-code/marketplace.schema.json\",\n  \"name\": \"openbrowser-ai\",\n  \"description\": \"AI-powered browser automation for Claude Code -- navigate, click, type, extract content, and automate workflows in real browsers\",\n  \"owner\": {\n    \"name\": \"OpenBrowser Team\",\n    \"url\": \"https://github.com/billy-enrizky/openbrowser-ai\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"openbrowser\",\n      \"description\": \"Browser automation MCP server with 11 tools for navigation, interaction, content extraction, and session management. Progressive disclosure design returns minimal tokens -- 877x fewer than Playwright MCP on Wikipedia.\",\n      \"source\": \"./plugin\",\n      \"category\": \"development\",\n      \"homepage\": \"https://github.com/billy-enrizky/openbrowser-ai\"\n    }\n  ]\n}\n",
        "README.md": "# OpenBrowser\n\n**Automating Walmart Product Scraping:**\n\nhttps://github.com/user-attachments/assets/ae5d74ce-0ac6-46b0-b02b-ff5518b4b20d\n\n\n**OpenBrowserAI Automatic Flight Booking:**\n\nhttps://github.com/user-attachments/assets/632128f6-3d09-497f-9e7d-e29b9cb65e0f\n\n\n[![PyPI version](https://badge.fury.io/py/openbrowser-ai.svg)](https://pypi.org/project/openbrowser-ai/)\n[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Tests](https://github.com/billy-enrizky/openbrowser-ai/actions/workflows/test.yml/badge.svg)](https://github.com/billy-enrizky/openbrowser-ai/actions)\n\n**AI-powered browser automation using CodeAgent and CDP (Chrome DevTools Protocol)**\n\nOpenBrowser is a framework for intelligent browser automation. It combines direct CDP communication with a CodeAgent architecture, where the LLM writes Python code executed in a persistent namespace, to navigate, interact with, and extract information from web pages autonomously.\n\n## Table of Contents\n\n- [Documentation](#documentation)\n- [Key Features](#key-features)\n- [Installation](#installation)\n- [Quick Start](#quick-start)\n- [Configuration](#configuration)\n- [Supported LLM Providers](#supported-llm-providers)\n- [Claude Code Plugin](#claude-code-plugin)\n- [Codex](#codex)\n- [OpenCode](#opencode)\n- [OpenClaw](#openclaw)\n- [MCP Server](#mcp-server)\n- [MCP Benchmark: Why OpenBrowser](#mcp-benchmark-why-openbrowser)\n- [CLI Usage](#cli-usage)\n- [Project Structure](#project-structure)\n- [Backend and Frontend Deployment](#backend-and-frontend-deployment)\n- [Testing](#testing)\n- [Contributing](#contributing)\n- [License](#license)\n- [Contact](#contact)\n\n## Documentation\n\n**Full documentation**: [https://docs.openbrowser.me](https://docs.openbrowser.me)\n\n## Key Features\n\n- **CodeAgent Architecture** - LLM writes Python code in a persistent Jupyter-like namespace for browser automation\n- **Raw CDP Communication** - Direct Chrome DevTools Protocol for maximum control and speed\n- **Vision Support** - Screenshot analysis for visual understanding of pages\n- **12+ LLM Providers** - OpenAI, Anthropic, Google, Groq, AWS Bedrock, Azure OpenAI, Ollama, and more\n- **MCP Server** - Model Context Protocol support for Claude Desktop integration\n- **Video Recording** - Record browser sessions as video files\n\n## Installation\n\n```bash\npip install openbrowser-ai\n```\n\n### With Optional Dependencies\n\n```bash\n# Install with all LLM providers\npip install openbrowser-ai[all]\n\n# Install specific providers\npip install openbrowser-ai[anthropic]  # Anthropic Claude\npip install openbrowser-ai[groq]       # Groq\npip install openbrowser-ai[ollama]     # Ollama (local models)\npip install openbrowser-ai[aws]        # AWS Bedrock\npip install openbrowser-ai[azure]      # Azure OpenAI\n\n# Install with video recording support\npip install openbrowser-ai[video]\n```\n\n### Install Browser\n\n```bash\nuvx openbrowser-ai install\n# or\nplaywright install chromium\n```\n\n## Quick Start\n\n### Basic Usage\n\n```python\nimport asyncio\nfrom openbrowser import CodeAgent, ChatGoogle\n\nasync def main():\n    agent = CodeAgent(\n        task=\"Go to google.com and search for 'Python tutorials'\",\n        llm=ChatGoogle(model=\"gemini-3-flash\"),\n    )\n\n    result = await agent.run()\n    print(f\"Result: {result}\")\n\nasyncio.run(main())\n```\n\n### With Different LLM Providers\n\n```python\nfrom openbrowser import CodeAgent, ChatOpenAI, ChatAnthropic, ChatGoogle\n\n# OpenAI\nagent = CodeAgent(task=\"...\", llm=ChatOpenAI(model=\"gpt-5.2\"))\n\n# Anthropic\nagent = CodeAgent(task=\"...\", llm=ChatAnthropic(model=\"claude-sonnet-4-6\"))\n\n# Google Gemini\nagent = CodeAgent(task=\"...\", llm=ChatGoogle(model=\"gemini-3-flash\"))\n```\n\n### Using Browser Session Directly\n\n```python\nimport asyncio\nfrom openbrowser import BrowserSession, BrowserProfile\n\nasync def main():\n    profile = BrowserProfile(\n        headless=True,\n        viewport_width=1920,\n        viewport_height=1080,\n    )\n    \n    session = BrowserSession(browser_profile=profile)\n    await session.start()\n    \n    await session.navigate_to(\"https://example.com\")\n    screenshot = await session.screenshot()\n    \n    await session.stop()\n\nasyncio.run(main())\n```\n\n## Configuration\n\n### Environment Variables\n\n```bash\n# Google (recommended)\nexport GOOGLE_API_KEY=\"...\"\n\n# OpenAI\nexport OPENAI_API_KEY=\"sk-...\"\n\n# Anthropic\nexport ANTHROPIC_API_KEY=\"sk-ant-...\"\n\n# Groq\nexport GROQ_API_KEY=\"gsk_...\"\n\n# AWS Bedrock\nexport AWS_ACCESS_KEY_ID=\"...\"\nexport AWS_SECRET_ACCESS_KEY=\"...\"\nexport AWS_DEFAULT_REGION=\"us-west-2\"\n\n# Azure OpenAI\nexport AZURE_OPENAI_API_KEY=\"...\"\nexport AZURE_OPENAI_ENDPOINT=\"https://your-resource.openai.azure.com/\"\n```\n\n### BrowserProfile Options\n\n```python\nfrom openbrowser import BrowserProfile\n\nprofile = BrowserProfile(\n    headless=True,\n    viewport_width=1280,\n    viewport_height=720,\n    disable_security=False,\n    extra_chromium_args=[\"--disable-gpu\"],\n    record_video_dir=\"./recordings\",\n    proxy={\n        \"server\": \"http://proxy.example.com:8080\",\n        \"username\": \"user\",\n        \"password\": \"pass\",\n    },\n)\n```\n\n## Supported LLM Providers\n\n| Provider | Class | Models |\n|----------|-------|--------|\n| **Google** | `ChatGoogle` | gemini-3-flash, gemini-3-pro |\n| **OpenAI** | `ChatOpenAI` | gpt-5.2, o4-mini, o3 |\n| **Anthropic** | `ChatAnthropic` | claude-sonnet-4-6, claude-opus-4-6 |\n| **Groq** | `ChatGroq` | llama-4-scout, qwen3-32b |\n| **AWS Bedrock** | `ChatAWSBedrock` | anthropic.claude-sonnet-4-6, amazon.nova-pro |\n| **AWS Bedrock (Anthropic)** | `ChatAnthropicBedrock` | Claude models via Anthropic Bedrock SDK |\n| **Azure OpenAI** | `ChatAzureOpenAI` | Any Azure-deployed model |\n| **OpenRouter** | `ChatOpenRouter` | Any model on openrouter.ai |\n| **DeepSeek** | `ChatDeepSeek` | deepseek-chat, deepseek-r1 |\n| **Cerebras** | `ChatCerebras` | llama-4-scout, qwen-3-235b |\n| **Ollama** | `ChatOllama` | llama-4-scout, deepseek-r1 (local) |\n| **OCI** | `ChatOCIRaw` | Oracle Cloud GenAI models |\n| **Browser-Use** | `ChatBrowserUse` | External LLM service |\n\n## Claude Code Plugin\n\nInstall OpenBrowser as a Claude Code plugin:\n\n```bash\n# Add the marketplace (one-time)\nclaude plugin marketplace add billy-enrizky/openbrowser-ai\n\n# Install the plugin\nclaude plugin install openbrowser@openbrowser-ai\n```\n\nThis installs the MCP server and 5 built-in skills:\n\n| Skill | Description |\n|-------|-------------|\n| `web-scraping` | Extract structured data, handle pagination |\n| `form-filling` | Fill forms, login flows, multi-step wizards |\n| `e2e-testing` | Test web apps by simulating user interactions |\n| `page-analysis` | Analyze page content, structure, metadata |\n| `accessibility-audit` | Audit pages for WCAG compliance |\n\nSee [plugin/README.md](plugin/README.md) for detailed tool parameter documentation.\n\n## Codex\n\nOpenBrowser works with OpenAI Codex via native skill discovery.\n\n### Quick Install\n\nTell Codex:\n\n```\nFetch and follow instructions from https://raw.githubusercontent.com/billy-enrizky/openbrowser-ai/refs/heads/main/.codex/INSTALL.md\n```\n\n### Manual Install\n\n```bash\n# Clone the repository\ngit clone https://github.com/billy-enrizky/openbrowser-ai.git ~/.codex/openbrowser\n\n# Symlink skills for native discovery\nmkdir -p ~/.agents/skills\nln -s ~/.codex/openbrowser/plugin/skills ~/.agents/skills/openbrowser\n\n# Restart Codex\n```\n\nThen configure the MCP server in your project (see [MCP Server](#mcp-server) below).\n\nDetailed docs: [.codex/INSTALL.md](.codex/INSTALL.md)\n\n## OpenCode\n\nOpenBrowser works with [OpenCode.ai](https://opencode.ai) via plugin and skill symlinks.\n\n### Quick Install\n\nTell OpenCode:\n\n```\nFetch and follow instructions from https://raw.githubusercontent.com/billy-enrizky/openbrowser-ai/refs/heads/main/.opencode/INSTALL.md\n```\n\n### Manual Install\n\n```bash\n# Clone the repository\ngit clone https://github.com/billy-enrizky/openbrowser-ai.git ~/.config/opencode/openbrowser\n\n# Create directories\nmkdir -p ~/.config/opencode/plugins ~/.config/opencode/skills\n\n# Symlink plugin and skills\nln -s ~/.config/opencode/openbrowser/.opencode/plugins/openbrowser.js ~/.config/opencode/plugins/openbrowser.js\nln -s ~/.config/opencode/openbrowser/plugin/skills ~/.config/opencode/skills/openbrowser\n\n# Restart OpenCode\n```\n\nThen configure the MCP server in your project (see [MCP Server](#mcp-server) below).\n\nDetailed docs: [.opencode/INSTALL.md](.opencode/INSTALL.md)\n\n## OpenClaw\n\n[OpenClaw](https://openclaw.ai) does not natively support MCP servers, but the community\n[openclaw-mcp-adapter](https://github.com/androidStern-personal/openclaw-mcp-adapter) plugin\nbridges MCP servers to OpenClaw agents.\n\n1. Install the MCP adapter plugin (see its README for setup).\n\n2. Add OpenBrowser as an MCP server in `~/.openclaw/openclaw.json`:\n\n```json\n{\n  \"plugins\": {\n    \"entries\": {\n      \"mcp-adapter\": {\n        \"enabled\": true,\n        \"config\": {\n          \"servers\": [\n            {\n              \"name\": \"openbrowser\",\n              \"transport\": \"stdio\",\n              \"command\": \"uvx\",\n              \"args\": [\"openbrowser-ai[mcp]\", \"--mcp\"]\n            }\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\nThe `execute_code` tool will be registered as a native OpenClaw agent tool.\n\nFor OpenClaw plugin documentation, see [docs.openclaw.ai/tools/plugin](https://docs.openclaw.ai/tools/plugin).\n\n## MCP Server\n\nOpenBrowser includes an MCP (Model Context Protocol) server that exposes browser automation as tools for AI assistants like Claude. No external LLM API keys required. The MCP client (Claude) provides the intelligence.\n\n### Quick Setup\n\n**Claude Code**: add to your project's `.mcp.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"openbrowser\": {\n      \"command\": \"uvx\",\n      \"args\": [\"openbrowser-ai[mcp]\", \"--mcp\"]\n    }\n  }\n}\n```\n\n**Claude Desktop**: add to `~/Library/Application Support/Claude/claude_desktop_config.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"openbrowser\": {\n      \"command\": \"uvx\",\n      \"args\": [\"openbrowser-ai[mcp]\", \"--mcp\"],\n      \"env\": {\n        \"OPENBROWSER_HEADLESS\": \"true\"\n      }\n    }\n  }\n}\n```\n\n**Run directly:**\n\n```bash\nuvx openbrowser-ai[mcp] --mcp\n```\n\n### Tool\n\nThe MCP server exposes a single `execute_code` tool that runs Python code in a persistent namespace with browser automation functions. The LLM writes Python code to navigate, interact, and extract data, returning only what was explicitly requested.\n\n**Available functions** (all async, use `await`):\n\n| Category | Functions |\n|----------|-----------|\n| **Navigation** | `navigate(url, new_tab)`, `go_back()`, `wait(seconds)` |\n| **Interaction** | `click(index)`, `input_text(index, text, clear)`, `scroll(down, pages, index)`, `send_keys(keys)`, `upload_file(index, path)` |\n| **Dropdowns** | `select_dropdown(index, text)`, `dropdown_options(index)` |\n| **Tabs** | `switch(tab_id)`, `close(tab_id)` |\n| **JavaScript** | `evaluate(code)`: run JS in page context, returns Python objects |\n| **State** | `browser.get_browser_state_summary()`: get page metadata and interactive elements |\n| **CSS** | `get_selector_from_index(index)`: get CSS selector for an element |\n| **Completion** | `done(text, success)`: signal task completion |\n\n**Pre-imported libraries**: `json`, `csv`, `re`, `datetime`, `asyncio`, `Path`, `requests`, `numpy`, `pandas`, `matplotlib`, `BeautifulSoup`\n\n### Configuration\n\n| Environment Variable | Description | Default |\n|---------------------|-------------|---------|\n| `OPENBROWSER_HEADLESS` | Run browser without GUI | `false` |\n| `OPENBROWSER_ALLOWED_DOMAINS` | Comma-separated domain whitelist | (none) |\n\n## MCP Benchmark: Why OpenBrowser\n\n### E2E LLM Benchmark (6 Real-World Tasks, N=5 runs)\n\nSix real-world browser tasks run through Claude Sonnet 4.6 on AWS Bedrock (Converse API) with a server-agnostic system prompt. The LLM autonomously decides which tools to call and when the task is complete. 5 runs per server with 10,000-sample bootstrap CIs. All tasks run against live websites.\n\n| # | Task | Description | Target Site |\n|:-:|------|-------------|-------------|\n| 1 | **fact_lookup** | Navigate to a Wikipedia article and extract specific facts (creator and year) | en.wikipedia.org |\n| 2 | **form_fill** | Fill out a multi-field form (text input, radio button, checkbox) and submit | httpbin.org/forms/post |\n| 3 | **multi_page_extract** | Extract the titles of the top 5 stories from a dynamic page | news.ycombinator.com |\n| 4 | **search_navigate** | Search Wikipedia, click a result, and extract specific information | en.wikipedia.org |\n| 5 | **deep_navigation** | Navigate to a GitHub repo and find the latest release version number | github.com |\n| 6 | **content_analysis** | Analyze page structure: count headings, links, and paragraphs | example.com |\n\n<p align=\"center\">\n  <img src=\"benchmarks/benchmark_comparison.png\" alt=\"E2E LLM Benchmark: MCP Server Comparison\" width=\"800\" />\n</p>\n\n| MCP Server | Pass Rate | Duration (mean +/- std) | Tool Calls | Bedrock API Tokens |\n|------------|:---------:|------------------------:|-----------:|-------------------:|\n| **Playwright MCP** (Microsoft) | 100% | 62.7 +/- 4.8s | 9.4 +/- 0.9 | 158,787 |\n| **Chrome DevTools MCP** (Google) | 100% | 103.4 +/- 2.7s | 19.4 +/- 0.5 | 299,486 |\n| **OpenBrowser MCP** | 100% | 77.0 +/- 6.7s | 13.8 +/- 2.0 | **50,195** |\n\nOpenBrowser uses **3.2x fewer tokens** than Playwright and **6.0x fewer** than Chrome DevTools, measured via Bedrock Converse API `usage` field (the actual billed tokens including system prompt, tool schemas, conversation history, and tool results).\n\n### Cost per Benchmark Run (6 Tasks)\n\nBased on Bedrock API token usage (input + output tokens at respective rates).\n\n| Model | Playwright MCP | Chrome DevTools MCP | OpenBrowser MCP |\n|-------|---------------:|--------------------:|----------------:|\n| Claude Sonnet 4.6 ($3/$15 per M) | $0.50 | $0.92 | **$0.18** |\n| Claude Opus 4.6 ($5/$25 per M) | $0.83 | $1.53 | **$0.30** |\n\n### Why the Difference\n\nPlaywright and Chrome DevTools return full page accessibility snapshots as tool output (~124K-135K tokens for Wikipedia). The LLM reads the entire snapshot to find what it needs. MCP response sizes: Playwright 1,132,173 chars, Chrome DevTools 1,147,244 chars, OpenBrowser 7,853 chars -- a **144x difference**.\n\nOpenBrowser uses a CodeAgent architecture (single `execute_code` tool). The LLM writes Python code that processes browser state server-side and returns only extracted results (~30-1,000 chars per call). The full page content never enters the LLM context window.\n\n```\nPlaywright: navigate to Wikipedia -> 520,742 chars (full a11y tree returned to LLM)\nOpenBrowser: navigate to Wikipedia -> 42 chars (page title only, state processed in code)\n             evaluate JS for infobox -> 896 chars (just the extracted data)\n```\n\n[Full comparison with methodology](https://docs.openbrowser.me/comparison)\n\n## CLI Usage\n\n```bash\n# Run a browser automation task\nuvx openbrowser-ai -p \"Search for Python tutorials on Google\"\n\n# Install browser\nuvx openbrowser-ai install\n\n# Run MCP server\nuvx openbrowser-ai[mcp] --mcp\n```\n\n## Project Structure\n\n```\nopenbrowser-ai/\n├── .claude-plugin/            # Claude Code marketplace config\n├── .codex/                    # Codex integration\n│   └── INSTALL.md\n├── .opencode/                 # OpenCode integration\n│   ├── INSTALL.md\n│   └── plugins/openbrowser.js\n├── plugin/                    # Plugin package (skills + MCP config)\n│   ├── .claude-plugin/\n│   ├── .mcp.json\n│   └── skills/                # 5 browser automation skills\n├── src/openbrowser/\n│   ├── __init__.py            # Main exports\n│   ├── cli.py                 # CLI commands\n│   ├── config.py              # Configuration\n│   ├── actor/                 # Element interaction\n│   ├── agent/                 # LangGraph agent\n│   ├── browser/               # CDP browser control\n│   ├── code_use/              # Code agent\n│   ├── dom/                   # DOM extraction\n│   ├── llm/                   # LLM providers\n│   ├── mcp/                   # MCP server\n│   └── tools/                 # Action registry\n├── benchmarks/                # MCP benchmarks and E2E tests\n│   ├── playwright_benchmark.py\n│   ├── cdp_benchmark.py\n│   ├── openbrowser_benchmark.py\n│   └── e2e_published_test.py\n└── tests/                     # Test suite\n```\n\n## Testing\n\n```bash\n# Run unit tests\npytest tests/\n\n# Run with verbose output\npytest tests/ -v\n\n# E2E test the MCP server against the published PyPI package\nuv run python benchmarks/e2e_published_test.py\n```\n\n### Benchmarks\n\nRun individual MCP server benchmarks (JSON-RPC stdio, 5-step Wikipedia workflow):\n\n```bash\nuv run python benchmarks/openbrowser_benchmark.py   # OpenBrowser MCP\nuv run python benchmarks/playwright_benchmark.py     # Playwright MCP\nuv run python benchmarks/cdp_benchmark.py            # Chrome DevTools MCP\n```\n\nResults are written to `benchmarks/*_results.json`. See [full comparison](https://docs.openbrowser.me/comparison) for methodology.\n\n## Backend and Frontend Deployment\n\nThe project includes a FastAPI backend and a Next.js frontend, both containerized with Docker.\n\n### Prerequisites\n\n- Docker and Docker Compose\n- A `.env` file in the project root with `POSTGRES_PASSWORD` and any LLM API keys (see `backend/env.example`)\n\n### Local Development (Docker Compose)\n\n```bash\n# Start backend + PostgreSQL (frontend runs locally)\ndocker-compose -f docker-compose.dev.yml up --build\n\n# In a separate terminal, start the frontend\ncd frontend && npm install && npm run dev\n```\n\n| Service | URL | Description |\n|---------|-----|-------------|\n| Backend | http://localhost:8000 | FastAPI + WebSocket + VNC |\n| Frontend | http://localhost:3000 | Next.js dev server |\n| PostgreSQL | localhost:5432 | Chat persistence |\n| VNC | ws://localhost:6080 | Live browser view |\n\nThe dev compose mounts `backend/app/` and `src/` as volumes for hot-reload. API keys are loaded from `backend/.env` via `env_file`. The `POSTGRES_PASSWORD` is read from the root `.env` file.\n\n### Full Stack (Docker Compose)\n\n```bash\n# Start all services (backend + frontend + PostgreSQL)\ndocker-compose up --build\n```\n\nThis builds and runs both the backend and frontend containers together with PostgreSQL.\n\n### Backend\n\nThe backend is a FastAPI application in `backend/` with a Dockerfile at `backend/Dockerfile`. It includes:\n\n- REST API on port 8000\n- WebSocket endpoint at `/ws` for real-time agent communication\n- VNC support (Xvfb + x11vnc + websockify) for live browser viewing on ports 6080-6090\n- Kiosk security: Openbox window manager, Chromium enterprise policies, X11 key grabber daemon\n- Health check at `/health`\n\n```bash\n# Build the backend image\ndocker build -f backend/Dockerfile -t openbrowser-backend .\n\n# Run standalone\ndocker run -p 8000:8000 -p 6080:6080 \\\n  --env-file backend/.env \\\n  -e VNC_ENABLED=true \\\n  -e AUTH_ENABLED=false \\\n  --shm-size=2g \\\n  openbrowser-backend\n```\n\n### Frontend\n\nThe frontend is a Next.js application in `frontend/` with a Dockerfile at `frontend/Dockerfile`.\n\n```bash\n# Build the frontend image\ncd frontend && docker build -t openbrowser-frontend .\n\n# Run standalone\ndocker run -p 3000:3000 \\\n  -e NEXT_PUBLIC_API_URL=http://localhost:8000 \\\n  -e NEXT_PUBLIC_WS_URL=ws://localhost:8000/ws \\\n  openbrowser-frontend\n```\n\n### Environment Variables\n\nKey environment variables for the backend (see `backend/env.example` for the full list):\n\n| Variable | Description | Default |\n|----------|-------------|---------|\n| `GOOGLE_API_KEY` | Google/Gemini API key | (required) |\n| `DEFAULT_LLM_MODEL` | Default model for agents | `gemini-3-flash-preview` |\n| `AUTH_ENABLED` | Enable Cognito JWT auth | `false` |\n| `VNC_ENABLED` | Enable VNC browser viewing | `true` |\n| `DATABASE_URL` | PostgreSQL connection string | (optional) |\n| `POSTGRES_PASSWORD` | PostgreSQL password (root `.env`) | (required for compose) |\n\n## Contributing\n\nContributions are welcome! Please:\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Contact\n\n- **Email**: billy.suharno@gmail.com\n- **GitHub**: [@billy-enrizky](https://github.com/billy-enrizky)\n- **Repository**: [github.com/billy-enrizky/openbrowser-ai](https://github.com/billy-enrizky/openbrowser-ai)\n- **Documentation**: [https://docs.openbrowser.me](https://docs.openbrowser.me)\n\n---\n\n**Made with love for the AI automation community**\n",
        "plugin/README.md": "# OpenBrowser - Claude Code Plugin\n\nAI-powered browser automation for Claude Code. Control real web browsers directly from Claude -- navigate websites, fill forms, extract data, inspect accessibility trees, and automate multi-step workflows.\n\n## Prerequisites\n\n- **Chrome or Chromium** installed on your system\n- **Python 3.12+** with [uv](https://docs.astral.sh/uv/) package manager\n- **Claude Code** CLI\n\n## Installation\n\n### From GitHub marketplace\n\n```bash\n# Add the OpenBrowser marketplace (one-time)\nclaude plugin marketplace add billy-enrizky/openbrowser-ai\n\n# Install the plugin\nclaude plugin install openbrowser@openbrowser-ai\n```\n\nThis installs the MCP server, 5 skills, and auto-enables the plugin. Restart Claude Code to activate.\n\n### Local development\n\n```bash\n# Test from a local clone without installing\nclaude --plugin-dir /path/to/openbrowser-ai/plugin\n```\n\n### OpenClaw\n\n[OpenClaw](https://openclaw.ai) does not natively support MCP servers, but the community\n[openclaw-mcp-adapter](https://github.com/androidStern-personal/openclaw-mcp-adapter) plugin\nbridges MCP servers to OpenClaw agents.\n\n1. Install the MCP adapter plugin (see its README for setup).\n\n2. Add OpenBrowser as an MCP server in `~/.openclaw/openclaw.json`:\n\n```json\n{\n  \"plugins\": {\n    \"entries\": {\n      \"mcp-adapter\": {\n        \"enabled\": true,\n        \"config\": {\n          \"servers\": [\n            {\n              \"name\": \"openbrowser\",\n              \"transport\": \"stdio\",\n              \"command\": \"uvx\",\n              \"args\": [\"openbrowser-ai[mcp]\", \"--mcp\"]\n            }\n          ]\n        }\n      }\n    }\n  }\n}\n```\n\nThe `execute_code` tool will be registered as a native OpenClaw agent tool.\n\nFor OpenClaw plugin documentation, see [docs.openclaw.ai/tools/plugin](https://docs.openclaw.ai/tools/plugin).\n\n### Standalone MCP server (without plugin)\n\nAdd to your project's `.mcp.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"openbrowser\": {\n      \"command\": \"uvx\",\n      \"args\": [\"openbrowser-ai[mcp]\", \"--mcp\"]\n    }\n  }\n}\n```\n\n## Available Tool\n\nThe MCP server exposes a single `execute_code` tool that runs Python code in a persistent namespace with browser automation functions. The LLM writes Python code to navigate, interact, and extract data.\n\n**Functions** (all async, use `await`):\n\n| Category | Functions |\n|----------|-----------|\n| **Navigation** | `navigate(url, new_tab)`, `go_back()`, `wait(seconds)` |\n| **Interaction** | `click(index)`, `input_text(index, text, clear)`, `scroll(down, pages, index)`, `send_keys(keys)`, `upload_file(index, path)` |\n| **Dropdowns** | `select_dropdown(index, text)`, `dropdown_options(index)` |\n| **Tabs** | `switch(tab_id)`, `close(tab_id)` |\n| **JavaScript** | `evaluate(code)` -- run JS in page context, returns Python objects |\n| **State** | `browser.get_browser_state_summary()` -- page metadata and interactive elements |\n| **CSS** | `get_selector_from_index(index)` -- CSS selector for an element |\n| **Completion** | `done(text, success)` -- signal task completion |\n\n**Pre-imported libraries**: `json`, `csv`, `re`, `datetime`, `asyncio`, `Path`, `requests`, `numpy`, `pandas`, `matplotlib`, `BeautifulSoup`\n\n## Benchmark: Token Efficiency\n\n<<<<<<< HEAD\n### E2E LLM Benchmark (6 Real-World Tasks, N=5 runs)\n\nSix browser tasks run through Claude Sonnet 4.6 on AWS Bedrock (Converse API). The LLM autonomously decides which tools to call. All three servers pass **6/6 tasks**. 5 runs per server with 10,000-sample bootstrap CIs. Bedrock API tokens measured from the Converse API `usage` field.\n\n| MCP Server | Tools | Bedrock API Tokens | Tool Calls (mean) | vs OpenBrowser |\n|------------|------:|-------------------:|-----------:|---------------:|\n| **Playwright MCP** | 22 | 158,787 | 9.4 | **3.2x more tokens** |\n| **Chrome DevTools MCP** (Google) | 26 | 299,486 | 19.4 | **6.0x more tokens** |\n| **OpenBrowser MCP** | 1 | **50,195** | 13.8 | baseline |\n\n### Cost per Benchmark Run (6 Tasks)\n\nBased on Bedrock API token usage (input + output tokens at respective rates).\n\n| Model | Playwright MCP | Chrome DevTools MCP | OpenBrowser MCP |\n|-------|---------------:|--------------------:|----------------:|\n| Claude Sonnet 4.6 ($3/$15 per M) | $0.50 | $0.92 | **$0.18** |\n| Claude Opus 4.6 ($5/$25 per M) | $0.83 | $1.53 | **$0.30** |\n\n### Per-Task MCP Response Size\n\nMCP tool response sizes show the architectural difference. Playwright and Chrome DevTools dump full page snapshots; OpenBrowser returns only extracted data.\n\n| Task | Playwright MCP | Chrome DevTools MCP | OpenBrowser MCP |\n|------|---------------:|--------------------:|----------------:|\n| fact_lookup | 520,742 chars | 509,058 chars | 3,144 chars |\n| form_fill | 4,075 chars | 3,150 chars | 2,305 chars |\n| multi_page_extract | 58,392 chars | 38,880 chars | 294 chars |\n| search_navigate | 519,241 chars | 595,590 chars | 2,848 chars |\n| deep_navigation | 14,875 chars | 195 chars | 113 chars |\n| content_analysis | 485 chars | 501 chars | 499 chars |\n=======\n### E2E LLM Benchmark (6 Real-World Tasks)\n\nSix browser tasks run through Claude Sonnet 4.6 on AWS Bedrock. The LLM autonomously decides which tools to call. All three servers pass **6/6 tasks**. Token usage measured from actual MCP tool response sizes.\n\n| MCP Server | Tools | Response Tokens | Tool Calls | vs OpenBrowser |\n|------------|------:|----------------:|-----------:|---------------:|\n| **Playwright MCP** | 22 | 283,853 | 10 | **170x more tokens** |\n| **Chrome DevTools MCP** (Google) | 26 | 301,030 | 21 | **181x more tokens** |\n| **OpenBrowser MCP** | 1 | **1,665** | 20 | baseline |\n\n### Cost per Benchmark Run (6 Tasks)\n\n| Model | Playwright MCP | Chrome DevTools MCP | OpenBrowser MCP |\n|-------|---------------:|--------------------:|----------------:|\n| Claude Sonnet ($3/M) | $0.852 | $0.903 | **$0.005** |\n| Claude Opus ($15/M) | $4.258 | $4.515 | **$0.025** |\n\n### Per-Task Response Size\n\n| Task | Playwright MCP | Chrome DevTools MCP | OpenBrowser MCP |\n|------|---------------:|--------------------:|----------------:|\n| fact_lookup | 477,003 chars | 509,059 chars | 1,041 chars |\n| form_fill | 4,075 chars | 3,150 chars | 2,410 chars |\n| multi_page_extract | 58,099 chars | 38,593 chars | 513 chars |\n| search_navigate | 518,461 chars | 594,458 chars | 1,996 chars |\n| deep_navigation | 77,292 chars | 58,359 chars | 113 chars |\n| content_analysis | 493 chars | 513 chars | 594 chars |\n>>>>>>> origin/main\n\nPlaywright completes tasks in fewer tool calls (1-2 per task) because it dumps the full a11y snapshot on every navigation. OpenBrowser takes more round-trips but each response is compact -- the code extracts only what's needed.\n\n[Full comparison with methodology](https://docs.openbrowser.me/comparison)\n\n## Configuration\n\nOptional environment variables:\n\n| Variable | Description |\n|----------|-------------|\n| `OPENBROWSER_HEADLESS` | Set to `true` to run browser without GUI |\n| `OPENBROWSER_ALLOWED_DOMAINS` | Comma-separated domain whitelist |\n\nSet these in your `.mcp.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"openbrowser\": {\n      \"command\": \"uvx\",\n      \"args\": [\"openbrowser-ai[mcp]\", \"--mcp\"],\n      \"env\": {\n        \"OPENBROWSER_HEADLESS\": \"true\"\n      }\n    }\n  }\n}\n```\n\n## Skills\n\nThe plugin includes 5 built-in skills that provide guided workflows for common browser automation tasks. Each skill is triggered automatically when the user's request matches its description.\n\n| Skill | Directory | Description |\n|-------|-----------|-------------|\n| `web-scraping` | `skills/web-scraping/` | Extract structured data from websites, handle pagination, and multi-tab scraping |\n| `form-filling` | `skills/form-filling/` | Fill out web forms, handle login/registration flows, and multi-step wizards |\n| `e2e-testing` | `skills/e2e-testing/` | Test web applications end-to-end by simulating user interactions and verifying outcomes |\n| `page-analysis` | `skills/page-analysis/` | Analyze page content, structure, metadata, and interactive elements |\n| `accessibility-audit` | `skills/accessibility-audit/` | Audit pages for WCAG compliance, heading structure, labels, alt text, ARIA, and landmarks |\n\nEach skill file (`SKILL.md`) contains YAML frontmatter with trigger conditions and a step-by-step workflow using the `execute_code` tool.\n\n## Testing and Benchmarks\n\n```bash\n# E2E test the MCP server against the published PyPI package\nuv run python benchmarks/e2e_published_test.py\n\n# Run MCP benchmarks (5-step Wikipedia workflow)\nuv run python benchmarks/openbrowser_benchmark.py\nuv run python benchmarks/playwright_benchmark.py\nuv run python benchmarks/cdp_benchmark.py\n```\n\n## Troubleshooting\n\n**Browser does not launch**: Ensure Chrome or Chromium is installed and accessible from PATH.\n\n**MCP server not found**: Verify `uvx` is installed (`pip install uv`) and the MCP server starts (`uvx openbrowser-ai[mcp] --mcp`).\n\n**Session timeout**: Browser sessions auto-close after 10 minutes of inactivity. Use any tool to keep the session alive.\n\n## License\n\nMIT\n"
      },
      "plugins": [
        {
          "name": "openbrowser",
          "description": "Browser automation MCP server with 11 tools for navigation, interaction, content extraction, and session management. Progressive disclosure design returns minimal tokens -- 877x fewer than Playwright MCP on Wikipedia.",
          "source": "./plugin",
          "category": "development",
          "homepage": "https://github.com/billy-enrizky/openbrowser-ai",
          "categories": [
            "development"
          ],
          "install_commands": [
            "/plugin marketplace add billy-enrizky/openbrowser-ai",
            "/plugin install openbrowser@openbrowser-ai"
          ]
        }
      ]
    }
  ]
}