{
  "author": {
    "id": "BA-CalderonMorales",
    "display_name": "Brandon A Calderon-Morales",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/62074841?u=95af937f450fd95b7305ba61aa0157469bd408d6&v=4",
    "url": "https://github.com/BA-CalderonMorales",
    "bio": "Product-Minded Software Engineer.\r\nHusband and Father.\r\nReach out to collab!",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 2,
      "total_commands": 44,
      "total_skills": 17,
      "total_stars": 0,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "anthropic-agent-skills",
      "version": null,
      "description": "Anthropic example skills",
      "owner_info": {
        "name": "Keith Lazuka",
        "email": "klazuka@anthropic.com"
      },
      "keywords": [],
      "repo_full_name": "BA-CalderonMorales/immersive-awe-canvas",
      "repo_url": "https://github.com/BA-CalderonMorales/immersive-awe-canvas",
      "repo_description": "Lovable Experiment: A creative coding playground for crafting beautiful, interactive 3D worlds right in your browser.",
      "homepage": "https://immersive-awe-canvas.lovable.app",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-01-10T01:16:51Z",
        "created_at": "2025-06-15T01:59:16Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 1358
        },
        {
          "path": ".claude",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/agents/architecture-agent.md",
          "type": "blob",
          "size": 3688
        },
        {
          "path": ".claude/agents/code-agent.md",
          "type": "blob",
          "size": 3432
        },
        {
          "path": ".claude/agents/completion-agent.md",
          "type": "blob",
          "size": 3718
        },
        {
          "path": ".claude/agents/pseudocode-agent.md",
          "type": "blob",
          "size": 2944
        },
        {
          "path": ".claude/agents/refactor-agent.md",
          "type": "blob",
          "size": 3648
        },
        {
          "path": ".claude/agents/review-agent.md",
          "type": "blob",
          "size": 3136
        },
        {
          "path": ".claude/agents/security-agent.md",
          "type": "blob",
          "size": 3939
        },
        {
          "path": ".claude/agents/specification-agent.md",
          "type": "blob",
          "size": 4100
        },
        {
          "path": ".claude/agents/tdd-agent.md",
          "type": "blob",
          "size": 2933
        },
        {
          "path": ".claude/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/commands/analysis",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/commands/analysis/README.md",
          "type": "blob",
          "size": 222
        },
        {
          "path": ".claude/commands/analysis/bottleneck-detect.md",
          "type": "blob",
          "size": 3550
        },
        {
          "path": ".claude/commands/analysis/performance-report.md",
          "type": "blob",
          "size": 626
        },
        {
          "path": ".claude/commands/analysis/token-usage.md",
          "type": "blob",
          "size": 569
        },
        {
          "path": ".claude/commands/automation",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/commands/automation/README.md",
          "type": "blob",
          "size": 206
        },
        {
          "path": ".claude/commands/automation/auto-agent.md",
          "type": "blob",
          "size": 2589
        },
        {
          "path": ".claude/commands/automation/smart-spawn.md",
          "type": "blob",
          "size": 536
        },
        {
          "path": ".claude/commands/automation/workflow-select.md",
          "type": "blob",
          "size": 623
        },
        {
          "path": ".claude/commands/coordination",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/commands/coordination/README.md",
          "type": "blob",
          "size": 212
        },
        {
          "path": ".claude/commands/coordination/agent-spawn.md",
          "type": "blob",
          "size": 576
        },
        {
          "path": ".claude/commands/coordination/swarm-init.md",
          "type": "blob",
          "size": 2045
        },
        {
          "path": ".claude/commands/coordination/task-orchestrate.md",
          "type": "blob",
          "size": 641
        },
        {
          "path": ".claude/commands/github",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/commands/github/README.md",
          "type": "blob",
          "size": 264
        },
        {
          "path": ".claude/commands/github/code-review.md",
          "type": "blob",
          "size": 561
        },
        {
          "path": ".claude/commands/github/github-swarm.md",
          "type": "blob",
          "size": 2416
        },
        {
          "path": ".claude/commands/github/issue-triage.md",
          "type": "blob",
          "size": 586
        },
        {
          "path": ".claude/commands/github/pr-enhance.md",
          "type": "blob",
          "size": 553
        },
        {
          "path": ".claude/commands/github/repo-analyze.md",
          "type": "blob",
          "size": 607
        },
        {
          "path": ".claude/commands/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/commands/hooks/README.md",
          "type": "blob",
          "size": 238
        },
        {
          "path": ".claude/commands/hooks/post-edit.md",
          "type": "blob",
          "size": 2300
        },
        {
          "path": ".claude/commands/hooks/post-task.md",
          "type": "blob",
          "size": 2221
        },
        {
          "path": ".claude/commands/hooks/pre-edit.md",
          "type": "blob",
          "size": 2215
        },
        {
          "path": ".claude/commands/hooks/pre-task.md",
          "type": "blob",
          "size": 2212
        },
        {
          "path": ".claude/commands/hooks/session-end.md",
          "type": "blob",
          "size": 2212
        },
        {
          "path": ".claude/commands/memory",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/commands/memory/README.md",
          "type": "blob",
          "size": 204
        },
        {
          "path": ".claude/commands/memory/memory-persist.md",
          "type": "blob",
          "size": 500
        },
        {
          "path": ".claude/commands/memory/memory-search.md",
          "type": "blob",
          "size": 470
        },
        {
          "path": ".claude/commands/memory/memory-usage.md",
          "type": "blob",
          "size": 537
        },
        {
          "path": ".claude/commands/monitoring",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/commands/monitoring/README.md",
          "type": "blob",
          "size": 214
        },
        {
          "path": ".claude/commands/monitoring/agent-metrics.md",
          "type": "blob",
          "size": 433
        },
        {
          "path": ".claude/commands/monitoring/real-time-view.md",
          "type": "blob",
          "size": 503
        },
        {
          "path": ".claude/commands/monitoring/swarm-monitor.md",
          "type": "blob",
          "size": 431
        },
        {
          "path": ".claude/commands/optimization",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/commands/optimization/README.md",
          "type": "blob",
          "size": 228
        },
        {
          "path": ".claude/commands/optimization/cache-manage.md",
          "type": "blob",
          "size": 528
        },
        {
          "path": ".claude/commands/optimization/parallel-execute.md",
          "type": "blob",
          "size": 588
        },
        {
          "path": ".claude/commands/optimization/topology-optimize.md",
          "type": "blob",
          "size": 573
        },
        {
          "path": ".claude/commands/training",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/commands/training/README.md",
          "type": "blob",
          "size": 204
        },
        {
          "path": ".claude/commands/training/model-update.md",
          "type": "blob",
          "size": 508
        },
        {
          "path": ".claude/commands/training/neural-train.md",
          "type": "blob",
          "size": 500
        },
        {
          "path": ".claude/commands/training/pattern-learn.md",
          "type": "blob",
          "size": 505
        },
        {
          "path": ".claude/commands/workflows",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/commands/workflows/README.md",
          "type": "blob",
          "size": 224
        },
        {
          "path": ".claude/commands/workflows/workflow-create.md",
          "type": "blob",
          "size": 494
        },
        {
          "path": ".claude/commands/workflows/workflow-execute.md",
          "type": "blob",
          "size": 508
        },
        {
          "path": ".claude/commands/workflows/workflow-export.md",
          "type": "blob",
          "size": 511
        },
        {
          "path": ".claude/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/algorithmic-art",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/algorithmic-art/SKILL.md",
          "type": "blob",
          "size": 19769
        },
        {
          "path": ".claude/skills/brand-guidelines",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/brand-guidelines/SKILL.md",
          "type": "blob",
          "size": 2235
        },
        {
          "path": ".claude/skills/canvas-design",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/canvas-design/SKILL.md",
          "type": "blob",
          "size": 11939
        },
        {
          "path": ".claude/skills/doc-coauthoring",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/doc-coauthoring/SKILL.md",
          "type": "blob",
          "size": 15815
        },
        {
          "path": ".claude/skills/docx",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/docx/SKILL.md",
          "type": "blob",
          "size": 10150
        },
        {
          "path": ".claude/skills/docx/docx-js.md",
          "type": "blob",
          "size": 16509
        },
        {
          "path": ".claude/skills/docx/ooxml.md",
          "type": "blob",
          "size": 23572
        },
        {
          "path": ".claude/skills/frontend-design",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/frontend-design/SKILL.md",
          "type": "blob",
          "size": 4440
        },
        {
          "path": ".claude/skills/internal-comms",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/internal-comms/SKILL.md",
          "type": "blob",
          "size": 1511
        },
        {
          "path": ".claude/skills/internal-comms/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/internal-comms/examples/3p-updates.md",
          "type": "blob",
          "size": 3274
        },
        {
          "path": ".claude/skills/internal-comms/examples/company-newsletter.md",
          "type": "blob",
          "size": 3295
        },
        {
          "path": ".claude/skills/internal-comms/examples/faq-answers.md",
          "type": "blob",
          "size": 2366
        },
        {
          "path": ".claude/skills/internal-comms/examples/general-comms.md",
          "type": "blob",
          "size": 602
        },
        {
          "path": ".claude/skills/mcp-builder",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/mcp-builder/SKILL.md",
          "type": "blob",
          "size": 9092
        },
        {
          "path": ".claude/skills/mcp-builder/reference",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/mcp-builder/reference/evaluation.md",
          "type": "blob",
          "size": 21663
        },
        {
          "path": ".claude/skills/mcp-builder/reference/mcp_best_practices.md",
          "type": "blob",
          "size": 7330
        },
        {
          "path": ".claude/skills/mcp-builder/reference/node_mcp_server.md",
          "type": "blob",
          "size": 28550
        },
        {
          "path": ".claude/skills/mcp-builder/reference/python_mcp_server.md",
          "type": "blob",
          "size": 25099
        },
        {
          "path": ".claude/skills/pdf",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/pdf/SKILL.md",
          "type": "blob",
          "size": 7068
        },
        {
          "path": ".claude/skills/pdf/forms.md",
          "type": "blob",
          "size": 9438
        },
        {
          "path": ".claude/skills/pdf/reference.md",
          "type": "blob",
          "size": 16692
        },
        {
          "path": ".claude/skills/pptx",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/pptx/SKILL.md",
          "type": "blob",
          "size": 25551
        },
        {
          "path": ".claude/skills/pptx/html2pptx.md",
          "type": "blob",
          "size": 19859
        },
        {
          "path": ".claude/skills/pptx/ooxml.md",
          "type": "blob",
          "size": 10388
        },
        {
          "path": ".claude/skills/skill-creator",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/skill-creator/SKILL.md",
          "type": "blob",
          "size": 17837
        },
        {
          "path": ".claude/skills/skill-creator/references",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/skill-creator/references/output-patterns.md",
          "type": "blob",
          "size": 1813
        },
        {
          "path": ".claude/skills/skill-creator/references/workflows.md",
          "type": "blob",
          "size": 818
        },
        {
          "path": ".claude/skills/slack-gif-creator",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/slack-gif-creator/SKILL.md",
          "type": "blob",
          "size": 7841
        },
        {
          "path": ".claude/skills/theme-factory",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/theme-factory/SKILL.md",
          "type": "blob",
          "size": 3124
        },
        {
          "path": ".claude/skills/theme-factory/themes",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/theme-factory/themes/arctic-frost.md",
          "type": "blob",
          "size": 544
        },
        {
          "path": ".claude/skills/theme-factory/themes/botanical-garden.md",
          "type": "blob",
          "size": 519
        },
        {
          "path": ".claude/skills/theme-factory/themes/desert-rose.md",
          "type": "blob",
          "size": 496
        },
        {
          "path": ".claude/skills/theme-factory/themes/forest-canopy.md",
          "type": "blob",
          "size": 506
        },
        {
          "path": ".claude/skills/theme-factory/themes/golden-hour.md",
          "type": "blob",
          "size": 528
        },
        {
          "path": ".claude/skills/theme-factory/themes/midnight-galaxy.md",
          "type": "blob",
          "size": 513
        },
        {
          "path": ".claude/skills/theme-factory/themes/modern-minimalist.md",
          "type": "blob",
          "size": 549
        },
        {
          "path": ".claude/skills/theme-factory/themes/ocean-depths.md",
          "type": "blob",
          "size": 555
        },
        {
          "path": ".claude/skills/theme-factory/themes/sunset-boulevard.md",
          "type": "blob",
          "size": 558
        },
        {
          "path": ".claude/skills/theme-factory/themes/tech-innovation.md",
          "type": "blob",
          "size": 547
        },
        {
          "path": ".claude/skills/web-artifacts-builder",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/web-artifacts-builder/SKILL.md",
          "type": "blob",
          "size": 3087
        },
        {
          "path": ".claude/skills/webapp-testing",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/webapp-testing/SKILL.md",
          "type": "blob",
          "size": 3913
        },
        {
          "path": ".claude/skills/xlsx",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/skills/xlsx/SKILL.md",
          "type": "blob",
          "size": 10632
        },
        {
          "path": ".claude/template",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/template/SKILL.md",
          "type": "blob",
          "size": 140
        },
        {
          "path": ".devcontainer",
          "type": "tree",
          "size": null
        },
        {
          "path": ".devcontainer/README.md",
          "type": "blob",
          "size": 4456
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 14359
        },
        {
          "path": "client",
          "type": "tree",
          "size": null
        },
        {
          "path": "client/api",
          "type": "tree",
          "size": null
        },
        {
          "path": "client/api/README.md",
          "type": "blob",
          "size": 11136
        },
        {
          "path": "client/api/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "client/api/hooks/index.ts",
          "type": "blob",
          "size": 255
        },
        {
          "path": "client/api/hooks/use-api-backgrounds.ts",
          "type": "blob",
          "size": 1767
        },
        {
          "path": "client/api/hooks/use-api-logging.ts",
          "type": "blob",
          "size": 3137
        },
        {
          "path": "client/api/hooks/use-api-version.ts",
          "type": "blob",
          "size": 2356
        },
        {
          "path": "client/api/hooks/use-api-worlds.ts",
          "type": "blob",
          "size": 1547
        },
        {
          "path": "client/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "client/hooks/__tests__",
          "type": "tree",
          "size": null
        },
        {
          "path": "client/hooks/__tests__/useWorlds.test.ts",
          "type": "blob",
          "size": 7082
        },
        {
          "path": "client/hooks/index.ts",
          "type": "blob",
          "size": 890
        },
        {
          "path": "client/hooks/use-mobile.tsx",
          "type": "blob",
          "size": 1669
        },
        {
          "path": "client/hooks/use-toast.ts",
          "type": "blob",
          "size": 4574
        },
        {
          "path": "client/hooks/useBackgrounds.ts",
          "type": "blob",
          "size": 3601
        },
        {
          "path": "client/hooks/useBlurTransition.ts",
          "type": "blob",
          "size": 889
        },
        {
          "path": "client/hooks/useDefaultGeometries.ts",
          "type": "blob",
          "size": 2352
        },
        {
          "path": "client/hooks/useExperience.ts",
          "type": "blob",
          "size": 360
        },
        {
          "path": "client/hooks/useExperienceCallbacks.ts",
          "type": "blob",
          "size": 852
        },
        {
          "path": "client/hooks/useExperienceEffects.ts",
          "type": "blob",
          "size": 2814
        },
        {
          "path": "client/hooks/useExperienceHotkeys.ts",
          "type": "blob",
          "size": 1596
        },
        {
          "path": "client/hooks/useExperienceState.ts",
          "type": "blob",
          "size": 8286
        },
        {
          "path": "client/hooks/useExperienceTransitions.ts",
          "type": "blob",
          "size": 1940
        },
        {
          "path": "client/hooks/useFirstVisit.ts",
          "type": "blob",
          "size": 2935
        },
        {
          "path": "client/hooks/useHotkeyActions.ts",
          "type": "blob",
          "size": 2113
        },
        {
          "path": "client/hooks/useInstructions.ts",
          "type": "blob",
          "size": 1083
        },
        {
          "path": "client/hooks/useKeyboardEventHandler.ts",
          "type": "blob",
          "size": 4602
        },
        {
          "path": "client/hooks/useKeyboardShortcutsState.ts",
          "type": "blob",
          "size": 723
        },
        {
          "path": "client/hooks/useLikes.ts",
          "type": "blob",
          "size": 1775
        },
        {
          "path": "client/hooks/useOrbitControlsState.ts",
          "type": "blob",
          "size": 898
        },
        {
          "path": "client/hooks/useSceneObjects.ts",
          "type": "blob",
          "size": 5031
        },
        {
          "path": "client/hooks/useSceneSettingsViewModel.ts",
          "type": "blob",
          "size": 7397
        },
        {
          "path": "client/hooks/useSettingsPanelViewModel.ts",
          "type": "blob",
          "size": 10096
        },
        {
          "path": "client/hooks/useUserScenes.ts",
          "type": "blob",
          "size": 11393
        },
        {
          "path": "client/hooks/useWorldNavigation.ts",
          "type": "blob",
          "size": 1492
        },
        {
          "path": "client/hooks/useWorlds.ts",
          "type": "blob",
          "size": 4970
        },
        {
          "path": "database",
          "type": "tree",
          "size": null
        },
        {
          "path": "database/api",
          "type": "tree",
          "size": null
        },
        {
          "path": "database/api/README.md",
          "type": "blob",
          "size": 12860
        },
        {
          "path": "docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/README.md",
          "type": "blob",
          "size": 1188
        },
        {
          "path": "docs/api-reference",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/api-reference/README.md",
          "type": "blob",
          "size": 1158
        },
        {
          "path": "docs/archive",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/archive/memory",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/archive/memory/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/archive/memory/agents/MEMORY.md",
          "type": "blob",
          "size": 57374
        },
        {
          "path": "docs/archive/memory/agents/README.md",
          "type": "blob",
          "size": 2566
        },
        {
          "path": "docs/archive/memory/agents/RULES.md",
          "type": "blob",
          "size": 4219
        },
        {
          "path": "docs/archive/memory/agents/shared",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/archive/memory/agents/shared/common_knowledge.md",
          "type": "blob",
          "size": 3751
        },
        {
          "path": "docs/archive/memory/sessions",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/archive/memory/sessions/README.md",
          "type": "blob",
          "size": 1288
        },
        {
          "path": "docs/modules",
          "type": "tree",
          "size": null
        },
        {
          "path": "docs/modules/README.md",
          "type": "blob",
          "size": 611
        },
        {
          "path": "tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "tests/README.md",
          "type": "blob",
          "size": 8288
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"anthropic-agent-skills\",\n  \"owner\": {\n    \"name\": \"Keith Lazuka\",\n    \"email\": \"klazuka@anthropic.com\"\n  },\n  \"metadata\": {\n    \"description\": \"Anthropic example skills\",\n    \"version\": \"1.0.0\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"document-skills\",\n      \"description\": \"Collection of document processing suite including Excel, Word, PowerPoint, and PDF capabilities\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./skills/xlsx\",\n        \"./skills/docx\",\n        \"./skills/pptx\",\n        \"./skills/pdf\"\n      ]\n    },\n    {\n      \"name\": \"example-skills\",\n      \"description\": \"Collection of example skills demonstrating various capabilities including skill creation, MCP building, visual design, algorithmic art, internal communications, web testing, artifact building, Slack GIFs, and theme styling\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./skills/algorithmic-art\",\n        \"./skills/brand-guidelines\",\n        \"./skills/canvas-design\",\n        \"./skills/doc-coauthoring\",\n        \"./skills/frontend-design\",\n        \"./skills/internal-comms\",\n        \"./skills/mcp-builder\",\n        \"./skills/skill-creator\",\n        \"./skills/slack-gif-creator\",\n        \"./skills/theme-factory\",\n        \"./skills/web-artifacts-builder\",\n        \"./skills/webapp-testing\"\n      ]\n    }\n  ]\n}\n",
        ".claude/agents/architecture-agent.md": "---\nname: architecture-agent\ndescription: Use this agent when you need to design, analyze, or review software architecture. This includes system design decisions, architectural patterns, component relationships, scalability considerations, and technical design documentation. Examples: <example>Context: User is building a new microservices application and needs architectural guidance. user: 'I need to design the architecture for a new e-commerce platform with user management, inventory, and payment processing' assistant: 'I'll use the architecture-agent to help design a comprehensive system architecture for your e-commerce platform' <commentary>Since the user needs architectural design for a complex system, use the Task tool to launch the architecture-agent to provide structured architectural guidance.</commentary></example> <example>Context: User has written some code and wants to review the architectural decisions. user: 'I've implemented the user service and payment gateway integration. Can you review the architecture?' assistant: 'Let me use the architecture-agent to analyze your current implementation and provide architectural feedback' <commentary>Since the user wants architectural review of existing code, use the architecture-agent to evaluate the design decisions and suggest improvements.</commentary></example>\nmodel: sonnet\ncolor: green\n---\n\nYou are an expert software architect with deep expertise in system design, architectural patterns, and scalable software solutions. Your role is to provide comprehensive architectural guidance, analysis, and recommendations.\n\nYour core responsibilities include:\n\n1. ARCHITECTURAL DESIGN: Create well-structured system architectures that are scalable, maintainable, and aligned with business requirements. Consider factors like performance, security, reliability, and cost-effectiveness.\n\n2. PATTERN SELECTION: Recommend appropriate architectural patterns (microservices, monolithic, event-driven, layered, hexagonal, etc.) based on specific use cases and constraints.\n\n3. COMPONENT ANALYSIS: Analyze system components, their relationships, dependencies, and interactions. Identify potential bottlenecks, single points of failure, and areas for improvement.\n\n4. TECHNOLOGY EVALUATION: Assess technology choices, frameworks, databases, and infrastructure options. Provide recommendations based on technical requirements, team expertise, and project constraints.\n\n5. SCALABILITY PLANNING: Design systems that can handle growth in users, data, and functionality. Consider horizontal and vertical scaling strategies.\n\n6. SECURITY ARCHITECTURE: Integrate security considerations into architectural decisions, including authentication, authorization, data protection, and secure communication.\n\n7. DOCUMENTATION: Create clear, comprehensive architectural documentation including system diagrams, component specifications, and design rationale.\n\nYour approach should be:\n- Systematic and methodical in analyzing requirements\n- Pragmatic in balancing ideal solutions with real-world constraints\n- Clear in explaining complex architectural concepts\n- Thorough in considering non-functional requirements\n- Proactive in identifying potential issues and risks\n\nWhen reviewing existing architectures, provide specific, actionable feedback on improvements. When designing new systems, start with understanding requirements and constraints before proposing solutions. Always justify your architectural decisions with clear reasoning.\n\nYou communicate in a professional, technical manner without using emojis or casual language. Your responses should be structured, detailed, and focused on delivering practical architectural value.\n",
        ".claude/agents/code-agent.md": "---\nname: code-agent\ndescription: Use this agent when you need comprehensive code analysis, review, or improvement of existing code files. This agent should be called after writing or modifying code to ensure quality, adherence to best practices, and project standards. Examples: <example>Context: User has just implemented a new authentication function and wants it reviewed. user: 'I just wrote this login function, can you review it?' assistant: 'I'll use the code-agent to perform a thorough review of your authentication code.' <commentary>Since the user wants code review, use the Task tool to launch the code-agent to analyze the recently written code.</commentary></example> <example>Context: User has completed a feature implementation and wants quality assurance. user: 'Just finished the user registration flow, please check it over' assistant: 'Let me use the code-agent to review your registration implementation for best practices and potential issues.' <commentary>The user has completed code that needs review, so use the code-agent to analyze the implementation.</commentary></example>\nmodel: haiku\ncolor: cyan\n---\n\nYou are an expert code analyst and reviewer specializing in comprehensive code quality assessment. Your role is to analyze, review, and provide actionable feedback on code implementations with a focus on maintainability, performance, security, and adherence to best practices.\n\nYour core responsibilities:\n\n1. COMPREHENSIVE CODE ANALYSIS\n   - Examine code structure, logic flow, and implementation patterns\n   - Identify potential bugs, edge cases, and logical inconsistencies\n   - Assess code readability, maintainability, and documentation quality\n   - Evaluate adherence to established coding standards and conventions\n\n2. SECURITY AND PERFORMANCE REVIEW\n   - Identify security vulnerabilities and potential attack vectors\n   - Analyze performance implications and optimization opportunities\n   - Review error handling and edge case management\n   - Assess resource usage and memory management\n\n3. BEST PRACTICES ENFORCEMENT\n   - Ensure compliance with language-specific best practices\n   - Verify proper use of design patterns and architectural principles\n   - Check for code duplication and suggest refactoring opportunities\n   - Validate testing coverage and test quality\n\n4. ACTIONABLE RECOMMENDATIONS\n   - Provide specific, implementable suggestions for improvement\n   - Prioritize issues by severity and impact\n   - Offer alternative approaches when appropriate\n   - Include code examples for recommended changes\n\n5. PROJECT CONTEXT AWARENESS\n   - Consider project-specific requirements and constraints from CLAUDE.md\n   - Align recommendations with established project patterns\n   - Respect existing architectural decisions and coding standards\n   - Maintain consistency with the broader codebase\n\nYour analysis approach:\n- Begin by understanding the code's purpose and context\n- Systematically review each component for correctness and quality\n- Consider both immediate functionality and long-term maintainability\n- Provide clear explanations for all recommendations\n- Balance thoroughness with practical applicability\n\nWhen reviewing code, focus on recently written or modified files unless explicitly instructed to review the entire codebase. Always provide constructive feedback that helps improve code quality while respecting the developer's implementation choices where appropriate.\n",
        ".claude/agents/completion-agent.md": "---\nname: completion-agent\ndescription: Use this agent when you need to complete partially written code, fill in missing implementations, or finish incomplete functions and classes. This agent specializes in analyzing existing code structure and providing contextually appropriate completions that maintain consistency with the existing codebase patterns and style.\\n\\nExamples:\\n- Context: User has written a function signature but needs the implementation completed\\n  user: \"Here's my function signature: function calculateTotalPrice(items, taxRate) { // TODO: implement }\"\\n  assistant: \"I'll use the completion-agent to implement this function\"\\n  \\n- Context: User has a partially implemented class that needs methods completed\\n  user: \"I have this class with some methods missing, can you complete it?\"\\n  assistant: \"Let me use the completion-agent to analyze your class structure and complete the missing methods\"\\n  \\n- Context: User has incomplete test cases that need assertions filled in\\n  user: \"My test file has empty test cases that need to be completed\"\\n  assistant: \"I'll use the completion-agent to complete your test cases with appropriate assertions\"\nmodel: sonnet\ncolor: orange\n---\n\nYou are a Code Completion Specialist, an expert at analyzing partially written code and providing contextually appropriate completions. Your expertise lies in understanding code patterns, maintaining consistency with existing implementations, and filling in missing functionality with clean, efficient solutions.\n\nYour core responsibilities:\n\n1. ANALYZE EXISTING CODE STRUCTURE\n   - Examine the codebase patterns, naming conventions, and architectural decisions\n   - Identify the intended functionality from context clues, comments, and surrounding code\n   - Understand the data flow and dependencies within the existing implementation\n   - Respect established coding standards and style guidelines\n\n2. PROVIDE CONTEXTUAL COMPLETIONS\n   - Complete function implementations that align with their signatures and intended purpose\n   - Fill in missing class methods while maintaining consistency with existing methods\n   - Implement error handling patterns that match the codebase approach\n   - Add appropriate type annotations and documentation where needed\n\n3. MAINTAIN CODE QUALITY\n   - Write clean, readable, and maintainable code completions\n   - Follow established patterns for variable naming, function structure, and organization\n   - Implement proper error handling and edge case management\n   - Ensure completions integrate seamlessly with existing code\n\n4. VERIFICATION AND VALIDATION\n   - Review completions for logical consistency and correctness\n   - Ensure all code paths are handled appropriately\n   - Verify that completions don't introduce breaking changes\n   - Test completions against expected inputs and outputs when possible\n\nYour approach:\n- Always read and understand the full context before completing any code\n- Ask clarifying questions if the intended functionality is ambiguous\n- Provide explanations for complex completions or non-obvious implementation choices\n- Suggest improvements to existing code structure when appropriate\n- Maintain backward compatibility unless explicitly asked to refactor\n\nOutput format:\n- Provide the completed code with clear indicators of what was added\n- Include brief explanations for complex logic or design decisions\n- Highlight any assumptions made during completion\n- Suggest additional improvements or considerations when relevant\n\nYou excel at understanding incomplete implementations and providing completions that feel like they were written by the original author, maintaining perfect consistency with the existing codebase style and patterns.\n",
        ".claude/agents/pseudocode-agent.md": "---\nname: pseudocode-agent\ndescription: Use this agent when you need to create clear, structured pseudocode representations of algorithms, logic flows, or system designs. This agent excels at breaking down complex programming concepts into human-readable, language-agnostic pseudocode that serves as a blueprint for implementation. Examples: When designing a new sorting algorithm and need pseudocode before coding; When documenting complex business logic for team review; When planning multi-step processes that need clear logical structure; When converting existing code into pseudocode for documentation or teaching purposes.\nmodel: haiku\ncolor: purple\n---\n\nYou are a Pseudocode Specialist, an expert in creating clear, structured, and implementable pseudocode representations of algorithms, processes, and system designs. Your expertise lies in translating complex programming concepts into human-readable, language-agnostic pseudocode that serves as an effective blueprint for implementation.\n\nYour core responsibilities:\n\n1. PSEUDOCODE CREATION: Generate clean, well-structured pseudocode that follows standard conventions including proper indentation, clear variable naming, and logical flow indicators. Use standard pseudocode keywords like BEGIN, END, IF, THEN, ELSE, WHILE, FOR, FUNCTION, RETURN, INPUT, OUTPUT.\n\n2. ALGORITHM ANALYSIS: Break down complex algorithms into step-by-step logical sequences, identifying key decision points, loops, and data transformations. Ensure each step is atomic and clearly defined.\n\n3. STRUCTURE AND CLARITY: Organize pseudocode with consistent formatting, meaningful variable names, and clear comments where necessary. Use proper nesting and indentation to show program structure and control flow.\n\n4. LANGUAGE AGNOSTIC APPROACH: Create pseudocode that can be implemented in any programming language, avoiding language-specific syntax or constructs. Focus on logic and algorithm rather than implementation details.\n\n5. VALIDATION AND OPTIMIZATION: Review pseudocode for logical consistency, completeness, and efficiency. Identify potential edge cases and ensure all necessary steps are included.\n\nYour output format:\n- Use consistent indentation (2 or 4 spaces)\n- Employ clear, descriptive variable names\n- Include input/output specifications\n- Add brief explanatory comments for complex logic\n- Structure with proper BEGIN/END blocks\n- Use standard control flow keywords\n\nWhen creating pseudocode, always:\n- Start with a clear problem statement\n- Define inputs and expected outputs\n- Break complex operations into smaller, manageable steps\n- Use meaningful names for variables and functions\n- Include error handling considerations where appropriate\n- Ensure the pseudocode is complete and implementable\n\nYou maintain high standards for clarity and precision, ensuring that any developer can follow your pseudocode to create working implementations regardless of their chosen programming language.\n",
        ".claude/agents/refactor-agent.md": "---\nname: refactor-agent\ndescription: Use this agent when you need to refactor existing code to improve its structure, readability, maintainability, or performance without changing its external behavior. This agent should be called after completing a feature or when code has become complex and needs restructuring. Examples: <example>Context: User has written a large function that handles multiple responsibilities and wants to break it down. user: 'This function is getting too complex, can you help refactor it?' assistant: 'I'll use the refactor-agent to analyze and restructure this code for better maintainability.' <commentary>The user is asking for code refactoring, so use the Task tool to launch the refactor-agent to improve code structure.</commentary></example> <example>Context: User has completed a feature implementation and wants to clean up the code before moving on. user: 'I've finished implementing the user authentication feature. The code works but could be cleaner.' assistant: 'Let me use the refactor-agent to review and improve the code structure while maintaining functionality.' <commentary>Since the user wants to improve existing working code, use the refactor-agent to restructure and clean up the implementation.</commentary></example>\nmodel: sonnet\ncolor: red\n---\n\nYou are an expert code refactoring specialist with deep knowledge of software design principles, clean code practices, and language-specific idioms. Your primary responsibility is to improve existing code without changing its external behavior or functionality.\n\nYour refactoring approach follows these principles:\n\n1. ANALYZE BEFORE REFACTORING: Always read and understand the existing code thoroughly before making any changes. Identify code smells, anti-patterns, and areas for improvement.\n\n2. PRESERVE FUNCTIONALITY: Never change the external behavior of the code. All refactoring must maintain the same inputs, outputs, and side effects.\n\n3. APPLY CLEAN CODE PRINCIPLES:\n   - Extract methods/functions to reduce complexity\n   - Eliminate code duplication (DRY principle)\n   - Improve naming for clarity and intent\n   - Reduce cyclomatic complexity\n   - Separate concerns and responsibilities\n   - Follow single responsibility principle\n\n4. LANGUAGE-SPECIFIC BEST PRACTICES: Apply idioms and patterns appropriate to the programming language being refactored.\n\n5. INCREMENTAL IMPROVEMENTS: Make small, focused changes rather than large rewrites. Each refactoring step should be independently verifiable.\n\n6. MAINTAIN READABILITY: Prioritize code that is easy to read, understand, and maintain over clever or overly complex solutions.\n\n7. PERFORMANCE CONSIDERATIONS: Be mindful of performance implications, but prioritize maintainability unless performance is explicitly critical.\n\nYour refactoring process:\n1. Read and analyze the existing code structure\n2. Identify specific refactoring opportunities\n3. Plan the refactoring steps in logical order\n4. Apply refactorings incrementally\n5. Verify that functionality is preserved\n6. Explain the improvements made and their benefits\n\nWhen refactoring, focus on:\n- Breaking down large functions/methods\n- Extracting reusable components\n- Improving variable and function names\n- Eliminating nested conditionals\n- Reducing parameter lists\n- Organizing code into logical modules\n- Removing dead or unused code\n- Simplifying complex expressions\n\nAlways explain your refactoring decisions and the benefits they provide in terms of maintainability, readability, and code quality. If you encounter code that cannot be safely refactored without more context or tests, clearly communicate these limitations.\n",
        ".claude/agents/review-agent.md": "---\nname: review-agent\ndescription: Use this agent when you need comprehensive code review and analysis after writing or modifying code. Examples: <example>Context: User has just implemented a new authentication system with JWT tokens. user: 'I just finished implementing the JWT authentication system with login, logout, and token refresh endpoints' assistant: 'Let me use the review-agent to conduct a thorough code review of your authentication implementation' <commentary>Since the user has completed a significant code implementation, use the review-agent to review the authentication code for security, best practices, and potential issues.</commentary></example> <example>Context: User has refactored a large component and wants feedback. user: 'I've refactored the UserProfile component to use hooks instead of class components' assistant: 'I'll use the review-agent to review your refactored UserProfile component' <commentary>The user has made significant changes to a component, so use the review-agent to analyze the refactoring for correctness and improvements.</commentary></example>\nmodel: sonnet\ncolor: pink\n---\n\nYou are a senior code reviewer with expertise across multiple programming languages and frameworks. Your role is to conduct thorough, constructive code reviews that improve code quality, security, and maintainability.\n\nWhen reviewing code, you will:\n\n1. **Security Analysis**: Identify potential security vulnerabilities, authentication issues, data validation problems, and injection risks. Check for proper input sanitization and secure coding practices.\n\n2. **Code Quality Assessment**: Evaluate code structure, readability, maintainability, and adherence to best practices. Look for code smells, anti-patterns, and opportunities for improvement.\n\n3. **Performance Review**: Analyze for performance bottlenecks, inefficient algorithms, memory leaks, and optimization opportunities. Consider scalability implications.\n\n4. **Architecture Evaluation**: Assess architectural decisions, design patterns, separation of concerns, and overall system design. Identify potential coupling issues or violations of SOLID principles.\n\n5. **Testing Coverage**: Review test quality, coverage, and identify areas needing additional testing. Suggest test cases for edge conditions and error scenarios.\n\n6. **Documentation Review**: Evaluate code comments, documentation quality, and API documentation completeness.\n\nYour review process:\n- Read and analyze all provided code thoroughly\n- Identify both strengths and areas for improvement\n- Provide specific, actionable feedback with examples\n- Suggest concrete improvements with code snippets when helpful\n- Prioritize issues by severity (critical, major, minor)\n- Consider the broader context and project requirements\n\nFormat your reviews with clear sections for different types of feedback. Be constructive and educational in your approach, explaining the reasoning behind your suggestions. Focus on helping developers learn and improve their skills while ensuring code quality and reliability.\n\nAlways conclude with a summary of key findings and recommended next steps.\n",
        ".claude/agents/security-agent.md": "---\nname: security-agent\ndescription: Use this agent when you need to perform security analysis, vulnerability assessment, or security code review. Examples: <example>Context: User has written authentication middleware and wants to ensure it's secure. user: 'I just implemented JWT authentication middleware, can you review it for security issues?' assistant: 'I'll use the security-agent to perform a comprehensive security review of your authentication code.' <commentary>Since the user is requesting security analysis of recently written code, use the Task tool to launch the security-agent to review the authentication implementation for vulnerabilities, best practices, and security compliance.</commentary></example> <example>Context: User is implementing input validation and wants security guidance. user: 'I'm adding user input validation to my API endpoints' assistant: 'Let me use the security-agent to ensure your input validation follows security best practices and prevents common vulnerabilities.' <commentary>Since the user is working on input validation which has security implications, use the security-agent to review the implementation for injection attacks, validation bypass, and other security concerns.</commentary></example>\nmodel: sonnet\ncolor: yellow\n---\n\nYou are a cybersecurity expert specializing in application security, vulnerability assessment, and secure coding practices. Your expertise encompasses threat modeling, security architecture review, penetration testing methodologies, and compliance frameworks.\n\nYour primary responsibilities include:\n\n1. SECURITY CODE REVIEW: Analyze code for vulnerabilities including but not limited to:\n   - Injection attacks (SQL, NoSQL, LDAP, OS command, etc.)\n   - Authentication and authorization flaws\n   - Sensitive data exposure\n   - XML external entity (XXE) attacks\n   - Broken access control\n   - Security misconfigurations\n   - Cross-site scripting (XSS)\n   - Insecure deserialization\n   - Components with known vulnerabilities\n   - Insufficient logging and monitoring\n\n2. THREAT MODELING: Identify potential attack vectors and security risks in system architecture and design patterns.\n\n3. SECURITY BEST PRACTICES: Recommend secure coding practices, security controls, and defensive programming techniques.\n\n4. COMPLIANCE ASSESSMENT: Evaluate code and systems against security standards such as OWASP Top 10, NIST frameworks, and industry-specific regulations.\n\n5. VULNERABILITY PRIORITIZATION: Assess and rank security issues based on severity, exploitability, and business impact.\n\nYour analysis methodology:\n- Perform systematic code review focusing on security-critical components\n- Identify both obvious vulnerabilities and subtle security weaknesses\n- Consider the broader security context and potential attack chains\n- Provide specific, actionable remediation guidance\n- Reference relevant security standards and best practices\n- Consider both technical and business risk factors\n\nWhen reviewing code:\n- Examine input validation and sanitization\n- Verify authentication and authorization mechanisms\n- Check for proper error handling and information disclosure\n- Assess cryptographic implementations\n- Review session management\n- Analyze access controls and privilege escalation risks\n- Evaluate logging and monitoring capabilities\n\nYour output should include:\n- Clear identification of security issues with severity ratings\n- Specific code locations where vulnerabilities exist\n- Detailed explanation of potential exploitation scenarios\n- Concrete remediation steps with code examples when appropriate\n- References to relevant security standards or documentation\n- Risk assessment considering likelihood and impact\n\nAlways prioritize critical security flaws that could lead to data breaches, system compromise, or regulatory violations. Provide practical, implementable solutions that balance security with functionality and performance requirements.\n",
        ".claude/agents/specification-agent.md": "---\nname: specification-agent\ndescription: Use this agent when you need to create, analyze, or refine technical specifications for software projects. This includes requirements analysis, system specifications, API documentation, architectural specifications, and technical design documents. Examples: <example>Context: User is working on a new API project and needs detailed specifications. user: 'I need to create a comprehensive specification for our user authentication API' assistant: 'I'll use the specification-agent to create detailed API specifications with endpoints, data models, and security requirements' <commentary>Since the user needs technical specifications created, use the specification-agent to analyze requirements and create comprehensive documentation.</commentary></example> <example>Context: User has existing code that needs proper specification documentation. user: 'Can you analyze this authentication system and create proper specifications?' assistant: 'Let me use the specification-agent to analyze the existing code and generate comprehensive specifications' <commentary>The user needs analysis of existing code to create specifications, so use the specification-agent to examine the system and document its specifications properly.</commentary></example>\nmodel: haiku\n---\n\nYou are a Technical Specification Expert specializing in creating comprehensive, precise, and actionable technical specifications for software systems. Your expertise encompasses requirements analysis, system design documentation, API specifications, data modeling, and architectural documentation.\n\nYour core responsibilities:\n\n1. SPECIFICATION CREATION: Develop detailed technical specifications that include functional requirements, non-functional requirements, system constraints, data models, API endpoints, security considerations, and integration points. Ensure specifications are complete, unambiguous, and implementable.\n\n2. REQUIREMENTS ANALYSIS: Analyze user needs, business requirements, and technical constraints to extract clear, testable requirements. Identify gaps, conflicts, and ambiguities in requirements and provide recommendations for resolution.\n\n3. SYSTEM DOCUMENTATION: Create comprehensive system documentation including architecture diagrams, data flow diagrams, sequence diagrams, and component specifications. Focus on clarity and technical accuracy.\n\n4. API SPECIFICATION: Design detailed API specifications including endpoints, request/response formats, authentication methods, error handling, rate limiting, and versioning strategies. Follow industry standards like OpenAPI/Swagger when applicable.\n\n5. DATA MODELING: Define clear data models, database schemas, relationships, constraints, and data validation rules. Include data lifecycle management and migration considerations.\n\n6. QUALITY ASSURANCE: Ensure all specifications are internally consistent, complete, and aligned with best practices. Include acceptance criteria and testing considerations.\n\nYour approach:\n- Start by understanding the context, scope, and objectives of the specification\n- Ask clarifying questions when requirements are unclear or incomplete\n- Structure specifications logically with clear sections and hierarchies\n- Use precise technical language while maintaining readability\n- Include examples and use cases to illustrate complex concepts\n- Consider scalability, maintainability, and security implications\n- Provide traceability between requirements and implementation details\n- Never include decorative elements like emojis in any documentation\n\nOutput format:\n- Use clear headings and structured sections\n- Include numbered requirements for traceability\n- Provide tables for complex data relationships\n- Use code blocks for technical examples\n- Include diagrams descriptions when visual elements would be helpful\n- Maintain consistent terminology throughout\n\nWhen analyzing existing systems, examine code structure, data flows, interfaces, and dependencies to reverse-engineer comprehensive specifications. Always validate that specifications are implementable and testable.\n",
        ".claude/agents/tdd-agent.md": "---\nname: tdd-agent\ndescription: Use this agent when you need to implement test-driven development practices, write comprehensive test suites, or ensure code quality through testing. Examples: <example>Context: User has written a new function and wants to ensure it's properly tested. user: 'I just implemented a user authentication function, can you help me test it?' assistant: 'I'll use the tdd-agent to create comprehensive tests for your authentication function' <commentary>Since the user needs testing support for their new code, use the tdd-agent to implement proper TDD practices and create thorough test coverage.</commentary></example> <example>Context: User is starting a new feature and wants to follow TDD principles. user: 'I need to build a payment processing module using TDD approach' assistant: 'Let me use the tdd-agent to guide you through test-driven development for the payment module' <commentary>The user explicitly wants TDD approach, so use the tdd-agent to write tests first, then implement the feature.</commentary></example>\nmodel: sonnet\ncolor: blue\n---\n\nYou are a Test-Driven Development (TDD) specialist focused on creating robust, maintainable test suites and guiding proper TDD implementation. Your expertise lies in writing comprehensive tests, ensuring code quality through testing practices, and implementing the red-green-refactor cycle.\n\nYour primary responsibilities:\n- Write comprehensive unit, integration, and end-to-end tests\n- Guide implementation of proper TDD workflows (red-green-refactor)\n- Ensure test coverage meets quality standards\n- Create maintainable and readable test code\n- Implement proper test organization and structure\n- Validate edge cases and error conditions\n- Establish testing best practices for the codebase\n\nWhen approaching testing tasks:\n1. Analyze the code or requirements to identify all testable scenarios\n2. Write failing tests first (red phase) that define expected behavior\n3. Implement minimal code to make tests pass (green phase)\n4. Refactor code while maintaining test coverage\n5. Ensure tests are isolated, deterministic, and fast\n6. Cover happy paths, edge cases, and error conditions\n7. Use appropriate testing frameworks and tools for the technology stack\n8. Maintain clear test naming and documentation\n\nYour testing approach should be:\n- Comprehensive: Cover all critical functionality and edge cases\n- Maintainable: Write clean, readable test code that's easy to update\n- Efficient: Create fast-running tests that provide quick feedback\n- Reliable: Ensure tests are deterministic and don't produce false positives\n- Strategic: Focus on high-value tests that catch real issues\n\nAlways prioritize test quality and maintainability. Provide clear explanations of testing strategies and help establish sustainable testing practices for long-term project success. Never include decorative elements or visual formatting in your code or documentation.\n",
        ".claude/commands/analysis/README.md": "# Analysis Commands\n\nCommands for analysis operations in Claude Flow.\n\n## Available Commands\n\n- [bottleneck-detect](./bottleneck-detect.md)\n- [token-usage](./token-usage.md)\n- [performance-report](./performance-report.md)\n",
        ".claude/commands/analysis/bottleneck-detect.md": "# bottleneck detect\n\nAnalyze performance bottlenecks in swarm operations and suggest optimizations.\n\n## Usage\n\n```bash\nnpx claude-flow bottleneck detect [options]\n```\n\n## Options\n\n- `--swarm-id, -s <id>` - Analyze specific swarm (default: current)\n- `--time-range, -t <range>` - Analysis period: 1h, 24h, 7d, all (default: 1h)\n- `--threshold <percent>` - Bottleneck threshold percentage (default: 20)\n- `--export, -e <file>` - Export analysis to file\n- `--fix` - Apply automatic optimizations\n\n## Examples\n\n### Basic bottleneck detection\n\n```bash\nnpx claude-flow bottleneck detect\n```\n\n### Analyze specific swarm\n\n```bash\nnpx claude-flow bottleneck detect --swarm-id swarm-123\n```\n\n### Last 24 hours with export\n\n```bash\nnpx claude-flow bottleneck detect -t 24h -e bottlenecks.json\n```\n\n### Auto-fix detected issues\n\n```bash\nnpx claude-flow bottleneck detect --fix --threshold 15\n```\n\n## Metrics Analyzed\n\n### Communication Bottlenecks\n\n- Message queue delays\n- Agent response times\n- Coordination overhead\n- Memory access patterns\n\n### Processing Bottlenecks\n\n- Task completion times\n- Agent utilization rates\n- Parallel execution efficiency\n- Resource contention\n\n### Memory Bottlenecks\n\n- Cache hit rates\n- Memory access patterns\n- Storage I/O performance\n- Neural pattern loading\n\n### Network Bottlenecks\n\n- API call latency\n- MCP communication delays\n- External service timeouts\n- Concurrent request limits\n\n## Output Format\n\n```\n Bottleneck Analysis Report\n\n\n Summary\n Time Range: Last 1 hour\n Agents Analyzed: 6\n Tasks Processed: 42\n Critical Issues: 2\n\n Critical Bottlenecks\n1. Agent Communication (35% impact)\n    coordinator  coder-1 messages delayed by 2.3s avg\n\n2. Memory Access (28% impact)\n    Neural pattern loading taking 1.8s per access\n\n Warning Bottlenecks\n1. Task Queue (18% impact)\n    5 tasks waiting > 10s for assignment\n\n Recommendations\n1. Switch to hierarchical topology (est. 40% improvement)\n2. Enable memory caching (est. 25% improvement)\n3. Increase agent concurrency to 8 (est. 20% improvement)\n\n Quick Fixes Available\nRun with --fix to apply:\n- Enable smart caching\n- Optimize message routing\n- Adjust agent priorities\n```\n\n## Automatic Fixes\n\nWhen using `--fix`, the following optimizations may be applied:\n\n1. **Topology Optimization**\n    - Switch to more efficient topology\n    - Adjust communication patterns\n    - Reduce coordination overhead\n\n2. **Caching Enhancement**\n    - Enable memory caching\n    - Optimize cache strategies\n    - Preload common patterns\n\n3. **Concurrency Tuning**\n    - Adjust agent counts\n    - Optimize parallel execution\n    - Balance workload distribution\n\n4. **Priority Adjustment**\n    - Reorder task queues\n    - Prioritize critical paths\n    - Reduce wait times\n\n## Performance Impact\n\nTypical improvements after bottleneck resolution:\n\n- **Communication**: 30-50% faster message delivery\n- **Processing**: 20-40% reduced task completion time\n- **Memory**: 40-60% fewer cache misses\n- **Overall**: 25-45% performance improvement\n\n## Integration with Claude Code\n\n```javascript\n// Check for bottlenecks in Claude Code\nmcp__claude-flow__bottleneck_detect {\n  timeRange: \"1h\",\n  threshold: 20,\n  autoFix: false\n}\n```\n\n## See Also\n\n- `performance report` - Detailed performance analysis\n- `token usage` - Token optimization analysis\n- `swarm monitor` - Real-time monitoring\n- `cache manage` - Cache optimization\n",
        ".claude/commands/analysis/performance-report.md": "# performance-report\n\nGenerate comprehensive performance reports for swarm operations.\n\n## Usage\n\n```bash\nnpx claude-flow analysis performance-report [options]\n```\n\n## Options\n\n- `--format <type>` - Report format (json, html, markdown)\n- `--include-metrics` - Include detailed metrics\n- `--compare <id>` - Compare with previous swarm\n\n## Examples\n\n```bash\n# Generate HTML report\nnpx claude-flow analysis performance-report --format html\n\n# Compare swarms\nnpx claude-flow analysis performance-report --compare swarm-123\n\n# Full metrics report\nnpx claude-flow analysis performance-report --include-metrics --format markdown\n```\n",
        ".claude/commands/analysis/token-usage.md": "# token-usage\n\nAnalyze token usage patterns and optimize for efficiency.\n\n## Usage\n\n```bash\nnpx claude-flow analysis token-usage [options]\n```\n\n## Options\n\n- `--period <time>` - Analysis period (1h, 24h, 7d, 30d)\n- `--by-agent` - Break down by agent\n- `--by-operation` - Break down by operation type\n\n## Examples\n\n```bash\n# Last 24 hours token usage\nnpx claude-flow analysis token-usage --period 24h\n\n# By agent breakdown\nnpx claude-flow analysis token-usage --by-agent\n\n# Export detailed report\nnpx claude-flow analysis token-usage --period 7d --export tokens.csv\n```\n",
        ".claude/commands/automation/README.md": "# Automation Commands\n\nCommands for automation operations in Claude Flow.\n\n## Available Commands\n\n- [auto-agent](./auto-agent.md)\n- [smart-spawn](./smart-spawn.md)\n- [workflow-select](./workflow-select.md)\n",
        ".claude/commands/automation/auto-agent.md": "# auto agent\n\nAutomatically spawn and manage agents based on task requirements.\n\n## Usage\n\n```bash\nnpx claude-flow auto agent [options]\n```\n\n## Options\n\n- `--task, -t <description>` - Task description for agent analysis\n- `--max-agents, -m <number>` - Maximum agents to spawn (default: auto)\n- `--min-agents <number>` - Minimum agents required (default: 1)\n- `--strategy, -s <type>` - Selection strategy: optimal, minimal, balanced\n- `--no-spawn` - Analyze only, don't spawn agents\n\n## Examples\n\n### Basic auto-spawning\n\n```bash\nnpx claude-flow auto agent --task \"Build a REST API with authentication\"\n```\n\n### Constrained spawning\n\n```bash\nnpx claude-flow auto agent -t \"Debug performance issue\" --max-agents 3\n```\n\n### Analysis only\n\n```bash\nnpx claude-flow auto agent -t \"Refactor codebase\" --no-spawn\n```\n\n### Minimal strategy\n\n```bash\nnpx claude-flow auto agent -t \"Fix bug in login\" -s minimal\n```\n\n## How It Works\n\n1. **Task Analysis**\n    - Parses task description\n    - Identifies required skills\n    - Estimates complexity\n    - Determines parallelization opportunities\n\n2. **Agent Selection**\n    - Matches skills to agent types\n    - Considers task dependencies\n    - Optimizes for efficiency\n    - Respects constraints\n\n3. **Topology Selection**\n    - Chooses optimal swarm structure\n    - Configures communication patterns\n    - Sets up coordination rules\n    - Enables monitoring\n\n4. **Automatic Spawning**\n    - Creates selected agents\n    - Assigns specific roles\n    - Distributes subtasks\n    - Initiates coordination\n\n## Agent Types Selected\n\n- **Architect**: System design, architecture decisions\n- **Coder**: Implementation, code generation\n- **Tester**: Test creation, quality assurance\n- **Analyst**: Performance, optimization\n- **Researcher**: Documentation, best practices\n- **Coordinator**: Task management, progress tracking\n\n## Strategies\n\n### Optimal\n\n- Maximum efficiency\n- May spawn more agents\n- Best for complex tasks\n- Highest resource usage\n\n### Minimal\n\n- Minimum viable agents\n- Conservative approach\n- Good for simple tasks\n- Lowest resource usage\n\n### Balanced\n\n- Middle ground\n- Adaptive to complexity\n- Default strategy\n- Good performance/resource ratio\n\n## Integration with Claude Code\n\n```javascript\n// In Claude Code after auto-spawning\nmcp__claude-flow__auto_agent {\n  task: \"Build authentication system\",\n  strategy: \"balanced\",\n  maxAgents: 6\n}\n```\n\n## See Also\n\n- `agent spawn` - Manual agent creation\n- `swarm init` - Initialize swarm manually\n- `smart spawn` - Intelligent agent spawning\n- `workflow select` - Choose predefined workflows\n",
        ".claude/commands/automation/smart-spawn.md": "# smart-spawn\n\nIntelligently spawn agents based on workload analysis.\n\n## Usage\n\n```bash\nnpx claude-flow automation smart-spawn [options]\n```\n\n## Options\n\n- `--analyze` - Analyze before spawning\n- `--threshold <n>` - Spawn threshold\n- `--topology <type>` - Preferred topology\n\n## Examples\n\n```bash\n# Smart spawn with analysis\nnpx claude-flow automation smart-spawn --analyze\n\n# Set spawn threshold\nnpx claude-flow automation smart-spawn --threshold 5\n\n# Force topology\nnpx claude-flow automation smart-spawn --topology hierarchical\n```\n",
        ".claude/commands/automation/workflow-select.md": "# workflow-select\n\nAutomatically select optimal workflow based on task type.\n\n## Usage\n\n```bash\nnpx claude-flow automation workflow-select [options]\n```\n\n## Options\n\n- `--task <description>` - Task description\n- `--constraints <list>` - Workflow constraints\n- `--preview` - Preview without executing\n\n## Examples\n\n```bash\n# Select workflow for task\nnpx claude-flow automation workflow-select --task \"Deploy to production\"\n\n# With constraints\nnpx claude-flow automation workflow-select --constraints \"no-downtime,rollback\"\n\n# Preview mode\nnpx claude-flow automation workflow-select --task \"Database migration\" --preview\n```\n",
        ".claude/commands/coordination/README.md": "# Coordination Commands\n\nCommands for coordination operations in Claude Flow.\n\n## Available Commands\n\n- [swarm-init](./swarm-init.md)\n- [agent-spawn](./agent-spawn.md)\n- [task-orchestrate](./task-orchestrate.md)\n",
        ".claude/commands/coordination/agent-spawn.md": "# agent-spawn\n\nSpawn a new agent in the current swarm.\n\n## Usage\n\n```bash\nnpx claude-flow agent spawn [options]\n```\n\n## Options\n\n- `--type <type>` - Agent type (coder, researcher, analyst, tester, coordinator)\n- `--name <name>` - Custom agent name\n- `--skills <list>` - Specific skills (comma-separated)\n\n## Examples\n\n```bash\n# Spawn coder agent\nnpx claude-flow agent spawn --type coder\n\n# With custom name\nnpx claude-flow agent spawn --type researcher --name \"API Expert\"\n\n# With specific skills\nnpx claude-flow agent spawn --type coder --skills \"python,fastapi,testing\"\n```\n",
        ".claude/commands/coordination/swarm-init.md": "# swarm init\n\nInitialize a Claude Flow swarm with specified topology and configuration.\n\n## Usage\n\n```bash\nnpx claude-flow swarm init [options]\n```\n\n## Options\n\n- `--topology, -t <type>` - Swarm topology: mesh, hierarchical, ring, star (default: hierarchical)\n- `--max-agents, -m <number>` - Maximum number of agents (default: 8)\n- `--strategy, -s <type>` - Execution strategy: balanced, parallel, sequential (default: parallel)\n- `--auto-spawn` - Automatically spawn agents based on task complexity\n- `--memory` - Enable cross-session memory persistence\n- `--github` - Enable GitHub integration features\n\n## Examples\n\n### Basic initialization\n\n```bash\nnpx claude-flow swarm init\n```\n\n### Mesh topology for research\n\n```bash\nnpx claude-flow swarm init --topology mesh --max-agents 5 --strategy balanced\n```\n\n### Hierarchical for development\n\n```bash\nnpx claude-flow swarm init --topology hierarchical --max-agents 10 --strategy parallel --auto-spawn\n```\n\n### GitHub-focused swarm\n\n```bash\nnpx claude-flow swarm init --topology star --github --memory\n```\n\n## Topologies\n\n### Mesh\n\n- All agents connect to all others\n- Best for: Research, exploration, brainstorming\n- Communication: High overhead, maximum information sharing\n\n### Hierarchical\n\n- Tree structure with clear command chain\n- Best for: Development, structured tasks, large projects\n- Communication: Efficient, clear responsibilities\n\n### Ring\n\n- Agents connect in a circle\n- Best for: Pipeline processing, sequential workflows\n- Communication: Low overhead, ordered processing\n\n### Star\n\n- Central coordinator with satellite agents\n- Best for: Simple tasks, centralized control\n- Communication: Minimal overhead, clear coordination\n\n## Integration with Claude Code\n\nOnce initialized, use MCP tools in Claude Code:\n\n```javascript\nmcp__claude-flow__swarm_init { topology: \"hierarchical\", maxAgents: 8 }\n```\n\n## See Also\n\n- `agent spawn` - Create swarm agents\n- `task orchestrate` - Coordinate task execution\n- `swarm status` - Check swarm state\n- `swarm monitor` - Real-time monitoring\n",
        ".claude/commands/coordination/task-orchestrate.md": "# task-orchestrate\n\nOrchestrate complex tasks across the swarm.\n\n## Usage\n\n```bash\nnpx claude-flow task orchestrate [options]\n```\n\n## Options\n\n- `--task <description>` - Task description\n- `--strategy <type>` - Orchestration strategy\n- `--priority <level>` - Task priority (low, medium, high, critical)\n\n## Examples\n\n```bash\n# Orchestrate development task\nnpx claude-flow task orchestrate --task \"Implement user authentication\"\n\n# High priority task\nnpx claude-flow task orchestrate --task \"Fix production bug\" --priority critical\n\n# With specific strategy\nnpx claude-flow task orchestrate --task \"Refactor codebase\" --strategy parallel\n```\n",
        ".claude/commands/github/README.md": "# Github Commands\n\nCommands for github operations in Claude Flow.\n\n## Available Commands\n\n- [github-swarm](./github-swarm.md)\n- [repo-analyze](./repo-analyze.md)\n- [pr-enhance](./pr-enhance.md)\n- [issue-triage](./issue-triage.md)\n- [code-review](./code-review.md)\n",
        ".claude/commands/github/code-review.md": "# code-review\n\nAutomated code review with swarm intelligence.\n\n## Usage\n\n```bash\nnpx claude-flow github code-review [options]\n```\n\n## Options\n\n- `--pr-number <n>` - Pull request to review\n- `--focus <areas>` - Review focus (security, performance, style)\n- `--suggest-fixes` - Suggest code fixes\n\n## Examples\n\n```bash\n# Review PR\nnpx claude-flow github code-review --pr-number 456\n\n# Security focus\nnpx claude-flow github code-review --pr-number 456 --focus security\n\n# With fix suggestions\nnpx claude-flow github code-review --pr-number 456 --suggest-fixes\n```\n",
        ".claude/commands/github/github-swarm.md": "# github swarm\n\nCreate a specialized swarm for GitHub repository management.\n\n## Usage\n\n```bash\nnpx claude-flow github swarm [options]\n```\n\n## Options\n\n- `--repository, -r <owner/repo>` - Target GitHub repository\n- `--agents, -a <number>` - Number of specialized agents (default: 5)\n- `--focus, -f <type>` - Focus area: maintenance, development, review, triage\n- `--auto-pr` - Enable automatic pull request enhancements\n- `--issue-labels` - Auto-categorize and label issues\n- `--code-review` - Enable AI-powered code reviews\n\n## Examples\n\n### Basic GitHub swarm\n\n```bash\nnpx claude-flow github swarm --repository owner/repo\n```\n\n### Maintenance-focused swarm\n\n```bash\nnpx claude-flow github swarm -r owner/repo -f maintenance --issue-labels\n```\n\n### Development swarm with PR automation\n\n```bash\nnpx claude-flow github swarm -r owner/repo -f development --auto-pr --code-review\n```\n\n### Full-featured triage swarm\n\n```bash\nnpx claude-flow github swarm -r owner/repo -a 8 -f triage --issue-labels --auto-pr\n```\n\n## Agent Types\n\n### Issue Triager\n\n- Analyzes and categorizes issues\n- Suggests labels and priorities\n- Identifies duplicates and related issues\n\n### PR Reviewer\n\n- Reviews code changes\n- Suggests improvements\n- Checks for best practices\n\n### Documentation Agent\n\n- Updates README files\n- Creates API documentation\n- Maintains changelog\n\n### Test Agent\n\n- Identifies missing tests\n- Suggests test cases\n- Validates test coverage\n\n### Security Agent\n\n- Scans for vulnerabilities\n- Reviews dependencies\n- Suggests security improvements\n\n## Workflows\n\n### Issue Triage Workflow\n\n1. Scan all open issues\n2. Categorize by type and priority\n3. Apply appropriate labels\n4. Suggest assignees\n5. Link related issues\n\n### PR Enhancement Workflow\n\n1. Analyze PR changes\n2. Suggest missing tests\n3. Improve documentation\n4. Format code consistently\n5. Add helpful comments\n\n### Repository Health Check\n\n1. Analyze code quality metrics\n2. Review dependency status\n3. Check test coverage\n4. Assess documentation completeness\n5. Generate health report\n\n## Integration with Claude Code\n\nUse in Claude Code with MCP tools:\n\n```javascript\nmcp__claude-flow__github_swarm {\n  repository: \"owner/repo\",\n  agents: 6,\n  focus: \"maintenance\"\n}\n```\n\n## See Also\n\n- `repo analyze` - Deep repository analysis\n- `pr enhance` - Enhance pull requests\n- `issue triage` - Intelligent issue management\n- `code review` - Automated reviews\n",
        ".claude/commands/github/issue-triage.md": "# issue-triage\n\nIntelligent issue classification and triage.\n\n## Usage\n\n```bash\nnpx claude-flow github issue-triage [options]\n```\n\n## Options\n\n- `--repository <owner/repo>` - Target repository\n- `--auto-label` - Automatically apply labels\n- `--assign` - Auto-assign to team members\n\n## Examples\n\n```bash\n# Triage issues\nnpx claude-flow github issue-triage --repository myorg/myrepo\n\n# With auto-labeling\nnpx claude-flow github issue-triage --repository myorg/myrepo --auto-label\n\n# Full automation\nnpx claude-flow github issue-triage --repository myorg/myrepo --auto-label --assign\n```\n",
        ".claude/commands/github/pr-enhance.md": "# pr-enhance\n\nAI-powered pull request enhancements.\n\n## Usage\n\n```bash\nnpx claude-flow github pr-enhance [options]\n```\n\n## Options\n\n- `--pr-number <n>` - Pull request number\n- `--add-tests` - Add missing tests\n- `--improve-docs` - Improve documentation\n- `--check-security` - Security review\n\n## Examples\n\n```bash\n# Enhance PR\nnpx claude-flow github pr-enhance --pr-number 123\n\n# Add tests\nnpx claude-flow github pr-enhance --pr-number 123 --add-tests\n\n# Full enhancement\nnpx claude-flow github pr-enhance --pr-number 123 --add-tests --improve-docs\n```\n",
        ".claude/commands/github/repo-analyze.md": "# repo-analyze\n\nDeep analysis of GitHub repository with AI insights.\n\n## Usage\n\n```bash\nnpx claude-flow github repo-analyze [options]\n```\n\n## Options\n\n- `--repository <owner/repo>` - Repository to analyze\n- `--deep` - Enable deep analysis\n- `--include <areas>` - Include specific areas (issues, prs, code, commits)\n\n## Examples\n\n```bash\n# Basic analysis\nnpx claude-flow github repo-analyze --repository myorg/myrepo\n\n# Deep analysis\nnpx claude-flow github repo-analyze --repository myorg/myrepo --deep\n\n# Specific areas\nnpx claude-flow github repo-analyze --repository myorg/myrepo --include issues,prs\n```\n",
        ".claude/commands/hooks/README.md": "# Hooks Commands\n\nCommands for hooks operations in Claude Flow.\n\n## Available Commands\n\n- [pre-task](./pre-task.md)\n- [post-task](./post-task.md)\n- [pre-edit](./pre-edit.md)\n- [post-edit](./post-edit.md)\n- [session-end](./session-end.md)\n",
        ".claude/commands/hooks/post-edit.md": "# hook post-edit\n\nExecute post-edit processing including formatting, validation, and memory updates.\n\n## Usage\n\n```bash\nnpx claude-flow hook post-edit [options]\n```\n\n## Options\n\n- `--file, -f <path>` - File path that was edited\n- `--auto-format` - Automatically format code (default: true)\n- `--memory-key, -m <key>` - Store edit context in memory\n- `--train-patterns` - Train neural patterns from edit\n- `--validate-output` - Validate edited file\n\n## Examples\n\n### Basic post-edit hook\n\n```bash\nnpx claude-flow hook post-edit --file \"src/components/Button.jsx\"\n```\n\n### With memory storage\n\n```bash\nnpx claude-flow hook post-edit -f \"api/auth.js\" --memory-key \"auth/login-implementation\"\n```\n\n### Format and validate\n\n```bash\nnpx claude-flow hook post-edit -f \"config/webpack.js\" --auto-format --validate-output\n```\n\n### Neural training\n\n```bash\nnpx claude-flow hook post-edit -f \"utils/helpers.ts\" --train-patterns --memory-key \"utils/refactor\"\n```\n\n## Features\n\n### Auto Formatting\n\n- Language-specific formatters\n- Prettier for JS/TS/JSON\n- Black for Python\n- gofmt for Go\n- Maintains consistency\n\n### Memory Storage\n\n- Saves edit context\n- Records decisions made\n- Tracks implementation details\n- Enables knowledge sharing\n\n### Pattern Training\n\n- Learns from successful edits\n- Improves future suggestions\n- Adapts to coding style\n- Enhances coordination\n\n### Output Validation\n\n- Checks syntax correctness\n- Runs linting rules\n- Validates formatting\n- Ensures quality\n\n## Integration\n\nThis hook is automatically called by Claude Code when:\n\n- After Edit tool completes\n- Following MultiEdit operations\n- During file saves\n- After code generation\n\nManual usage in agents:\n\n```bash\n# After editing files\nnpx claude-flow hook post-edit --file \"path/to/edited.js\" --memory-key \"feature/step1\"\n```\n\n## Output\n\nReturns JSON with:\n\n```json\n{\n    \"file\": \"src/components/Button.jsx\",\n    \"formatted\": true,\n    \"formatterUsed\": \"prettier\",\n    \"lintPassed\": true,\n    \"memorySaved\": \"component/button-refactor\",\n    \"patternsTrained\": 3,\n    \"warnings\": [],\n    \"stats\": {\n        \"linesChanged\": 45,\n        \"charactersAdded\": 234\n    }\n}\n```\n\n## See Also\n\n- `hook pre-edit` - Pre-edit preparation\n- `Edit` - File editing tool\n- `memory usage` - Memory management\n- `neural train` - Pattern training\n",
        ".claude/commands/hooks/post-task.md": "# hook post-task\n\nExecute post-task cleanup, performance analysis, and memory storage.\n\n## Usage\n\n```bash\nnpx claude-flow hook post-task [options]\n```\n\n## Options\n\n- `--task-id, -t <id>` - Task identifier for tracking\n- `--analyze-performance` - Generate performance metrics (default: true)\n- `--store-decisions` - Save task decisions to memory\n- `--export-learnings` - Export neural pattern learnings\n- `--generate-report` - Create task completion report\n\n## Examples\n\n### Basic post-task hook\n\n```bash\nnpx claude-flow hook post-task --task-id \"auth-implementation\"\n```\n\n### With full analysis\n\n```bash\nnpx claude-flow hook post-task -t \"api-refactor\" --analyze-performance --generate-report\n```\n\n### Memory storage\n\n```bash\nnpx claude-flow hook post-task -t \"bug-fix-123\" --store-decisions --export-learnings\n```\n\n### Quick cleanup\n\n```bash\nnpx claude-flow hook post-task -t \"minor-update\" --analyze-performance false\n```\n\n## Features\n\n### Performance Analysis\n\n- Measures execution time\n- Tracks token usage\n- Identifies bottlenecks\n- Suggests optimizations\n\n### Decision Storage\n\n- Saves key decisions made\n- Records implementation choices\n- Stores error resolutions\n- Maintains knowledge base\n\n### Neural Learning\n\n- Exports successful patterns\n- Updates coordination models\n- Improves future performance\n- Trains on task outcomes\n\n### Report Generation\n\n- Creates completion summary\n- Documents changes made\n- Lists files modified\n- Tracks metrics achieved\n\n## Integration\n\nThis hook is automatically called by Claude Code when:\n\n- Completing a task\n- Switching to a new task\n- Ending a work session\n- After major milestones\n\nManual usage in agents:\n\n```bash\n# In agent coordination\nnpx claude-flow hook post-task --task-id \"your-task-id\" --analyze-performance true\n```\n\n## Output\n\nReturns JSON with:\n\n```json\n{\n    \"taskId\": \"auth-implementation\",\n    \"duration\": 1800000,\n    \"tokensUsed\": 45000,\n    \"filesModified\": 12,\n    \"performanceScore\": 0.92,\n    \"learningsExported\": true,\n    \"reportPath\": \"/reports/task-auth-implementation.md\"\n}\n```\n\n## See Also\n\n- `hook pre-task` - Pre-task setup\n- `performance report` - Detailed metrics\n- `memory usage` - Memory management\n- `neural patterns` - Pattern analysis\n",
        ".claude/commands/hooks/pre-edit.md": "# hook pre-edit\n\nExecute pre-edit validations and agent assignment before file modifications.\n\n## Usage\n\n```bash\nnpx claude-flow hook pre-edit [options]\n```\n\n## Options\n\n- `--file, -f <path>` - File path to be edited\n- `--auto-assign-agent` - Automatically assign best agent (default: true)\n- `--validate-syntax` - Pre-validate syntax before edit\n- `--check-conflicts` - Check for merge conflicts\n- `--backup-file` - Create backup before editing\n\n## Examples\n\n### Basic pre-edit hook\n\n```bash\nnpx claude-flow hook pre-edit --file \"src/auth/login.js\"\n```\n\n### With validation\n\n```bash\nnpx claude-flow hook pre-edit -f \"config/database.js\" --validate-syntax\n```\n\n### Manual agent assignment\n\n```bash\nnpx claude-flow hook pre-edit -f \"api/users.ts\" --auto-assign-agent false\n```\n\n### Safe editing with backup\n\n```bash\nnpx claude-flow hook pre-edit -f \"production.env\" --backup-file --check-conflicts\n```\n\n## Features\n\n### Auto Agent Assignment\n\n- Analyzes file type and content\n- Assigns specialist agents\n- TypeScript  TypeScript expert\n- Database  Data specialist\n- Tests  QA engineer\n\n### Syntax Validation\n\n- Pre-checks syntax validity\n- Identifies potential errors\n- Suggests corrections\n- Prevents broken code\n\n### Conflict Detection\n\n- Checks for git conflicts\n- Identifies concurrent edits\n- Warns about stale files\n- Suggests merge strategies\n\n### File Backup\n\n- Creates safety backups\n- Enables quick rollback\n- Tracks edit history\n- Preserves originals\n\n## Integration\n\nThis hook is automatically called by Claude Code when:\n\n- Using Edit or MultiEdit tools\n- Before file modifications\n- During refactoring operations\n- When updating critical files\n\nManual usage in agents:\n\n```bash\n# Before editing files\nnpx claude-flow hook pre-edit --file \"path/to/file.js\" --validate-syntax\n```\n\n## Output\n\nReturns JSON with:\n\n```json\n{\n    \"continue\": true,\n    \"file\": \"src/auth/login.js\",\n    \"assignedAgent\": \"auth-specialist\",\n    \"syntaxValid\": true,\n    \"conflicts\": false,\n    \"backupPath\": \".backups/login.js.bak\",\n    \"warnings\": []\n}\n```\n\n## See Also\n\n- `hook post-edit` - Post-edit processing\n- `Edit` - File editing tool\n- `MultiEdit` - Multiple edits tool\n- `agent spawn` - Manual agent creation\n",
        ".claude/commands/hooks/pre-task.md": "# hook pre-task\n\nExecute pre-task preparations and context loading.\n\n## Usage\n\n```bash\nnpx claude-flow hook pre-task [options]\n```\n\n## Options\n\n- `--description, -d <text>` - Task description for context\n- `--auto-spawn-agents` - Automatically spawn required agents (default: true)\n- `--load-memory` - Load relevant memory from previous sessions\n- `--optimize-topology` - Select optimal swarm topology\n- `--estimate-complexity` - Analyze task complexity\n\n## Examples\n\n### Basic pre-task hook\n\n```bash\nnpx claude-flow hook pre-task --description \"Implement user authentication\"\n```\n\n### With memory loading\n\n```bash\nnpx claude-flow hook pre-task -d \"Continue API development\" --load-memory\n```\n\n### Manual agent control\n\n```bash\nnpx claude-flow hook pre-task -d \"Debug issue #123\" --auto-spawn-agents false\n```\n\n### Full optimization\n\n```bash\nnpx claude-flow hook pre-task -d \"Refactor codebase\" --optimize-topology --estimate-complexity\n```\n\n## Features\n\n### Auto Agent Assignment\n\n- Analyzes task requirements\n- Determines needed agent types\n- Spawns agents automatically\n- Configures agent parameters\n\n### Memory Loading\n\n- Retrieves relevant past decisions\n- Loads previous task contexts\n- Restores agent configurations\n- Maintains continuity\n\n### Topology Optimization\n\n- Analyzes task structure\n- Selects best swarm topology\n- Configures communication patterns\n- Optimizes for performance\n\n### Complexity Estimation\n\n- Evaluates task difficulty\n- Estimates time requirements\n- Suggests agent count\n- Identifies dependencies\n\n## Integration\n\nThis hook is automatically called by Claude Code when:\n\n- Starting a new task\n- Resuming work after a break\n- Switching between projects\n- Beginning complex operations\n\nManual usage in agents:\n\n```bash\n# In agent coordination\nnpx claude-flow hook pre-task --description \"Your task here\"\n```\n\n## Output\n\nReturns JSON with:\n\n```json\n{\n    \"continue\": true,\n    \"topology\": \"hierarchical\",\n    \"agentsSpawned\": 5,\n    \"complexity\": \"medium\",\n    \"estimatedMinutes\": 30,\n    \"memoryLoaded\": true\n}\n```\n\n## See Also\n\n- `hook post-task` - Post-task cleanup\n- `agent spawn` - Manual agent creation\n- `memory usage` - Memory management\n- `swarm init` - Swarm initialization\n",
        ".claude/commands/hooks/session-end.md": "# hook session-end\n\nCleanup and persist session state before ending work.\n\n## Usage\n\n```bash\nnpx claude-flow hook session-end [options]\n```\n\n## Options\n\n- `--session-id, -s <id>` - Session identifier to end\n- `--save-state` - Save current session state (default: true)\n- `--export-metrics` - Export session metrics\n- `--generate-summary` - Create session summary\n- `--cleanup-temp` - Remove temporary files\n\n## Examples\n\n### Basic session end\n\n```bash\nnpx claude-flow hook session-end --session-id \"dev-session-2024\"\n```\n\n### With full export\n\n```bash\nnpx claude-flow hook session-end -s \"feature-auth\" --export-metrics --generate-summary\n```\n\n### Quick close\n\n```bash\nnpx claude-flow hook session-end -s \"quick-fix\" --save-state false --cleanup-temp\n```\n\n### Complete persistence\n\n```bash\nnpx claude-flow hook session-end -s \"major-refactor\" --save-state --export-metrics --generate-summary\n```\n\n## Features\n\n### State Persistence\n\n- Saves current context\n- Stores open files\n- Preserves task progress\n- Maintains decisions\n\n### Metric Export\n\n- Session duration\n- Commands executed\n- Files modified\n- Tokens consumed\n- Performance data\n\n### Summary Generation\n\n- Work accomplished\n- Key decisions made\n- Problems solved\n- Next steps identified\n\n### Cleanup Operations\n\n- Removes temp files\n- Clears caches\n- Frees resources\n- Optimizes storage\n\n## Integration\n\nThis hook is automatically called by Claude Code when:\n\n- Ending a conversation\n- Closing work session\n- Before shutdown\n- Switching contexts\n\nManual usage in agents:\n\n```bash\n# At session end\nnpx claude-flow hook session-end --session-id \"your-session\" --generate-summary\n```\n\n## Output\n\nReturns JSON with:\n\n```json\n{\n    \"sessionId\": \"dev-session-2024\",\n    \"duration\": 7200000,\n    \"saved\": true,\n    \"metrics\": {\n        \"commandsRun\": 145,\n        \"filesModified\": 23,\n        \"tokensUsed\": 85000,\n        \"tasksCompleted\": 8\n    },\n    \"summaryPath\": \"/sessions/dev-session-2024-summary.md\",\n    \"cleanedUp\": true,\n    \"nextSession\": \"dev-session-2025\"\n}\n```\n\n## See Also\n\n- `hook session-start` - Session initialization\n- `hook session-restore` - Session restoration\n- `performance report` - Detailed metrics\n- `memory backup` - State backup\n",
        ".claude/commands/memory/README.md": "# Memory Commands\n\nCommands for memory operations in Claude Flow.\n\n## Available Commands\n\n- [memory-usage](./memory-usage.md)\n- [memory-persist](./memory-persist.md)\n- [memory-search](./memory-search.md)\n",
        ".claude/commands/memory/memory-persist.md": "# memory-persist\n\nPersist memory across sessions.\n\n## Usage\n\n```bash\nnpx claude-flow memory persist [options]\n```\n\n## Options\n\n- `--export <file>` - Export to file\n- `--import <file>` - Import from file\n- `--compress` - Compress memory data\n\n## Examples\n\n```bash\n# Export memory\nnpx claude-flow memory persist --export memory-backup.json\n\n# Import memory\nnpx claude-flow memory persist --import memory-backup.json\n\n# Compressed export\nnpx claude-flow memory persist --export memory.gz --compress\n```\n",
        ".claude/commands/memory/memory-search.md": "# memory-search\n\nSearch through stored memory.\n\n## Usage\n\n```bash\nnpx claude-flow memory search [options]\n```\n\n## Options\n\n- `--query <text>` - Search query\n- `--pattern <regex>` - Pattern matching\n- `--limit <n>` - Result limit\n\n## Examples\n\n```bash\n# Search memory\nnpx claude-flow memory search --query \"authentication\"\n\n# Pattern search\nnpx claude-flow memory search --pattern \"api-.*\"\n\n# Limited results\nnpx claude-flow memory search --query \"config\" --limit 10\n```\n",
        ".claude/commands/memory/memory-usage.md": "# memory-usage\n\nManage persistent memory storage.\n\n## Usage\n\n```bash\nnpx claude-flow memory usage [options]\n```\n\n## Options\n\n- `--action <type>` - Action (store, retrieve, list, clear)\n- `--key <key>` - Memory key\n- `--value <data>` - Data to store (JSON)\n\n## Examples\n\n```bash\n# Store memory\nnpx claude-flow memory usage --action store --key \"project-config\" --value '{\"api\": \"v2\"}'\n\n# Retrieve memory\nnpx claude-flow memory usage --action retrieve --key \"project-config\"\n\n# List all keys\nnpx claude-flow memory usage --action list\n```\n",
        ".claude/commands/monitoring/README.md": "# Monitoring Commands\n\nCommands for monitoring operations in Claude Flow.\n\n## Available Commands\n\n- [swarm-monitor](./swarm-monitor.md)\n- [agent-metrics](./agent-metrics.md)\n- [real-time-view](./real-time-view.md)\n",
        ".claude/commands/monitoring/agent-metrics.md": "# agent-metrics\n\nView agent performance metrics.\n\n## Usage\n\n```bash\nnpx claude-flow agent metrics [options]\n```\n\n## Options\n\n- `--agent-id <id>` - Specific agent\n- `--period <time>` - Time period\n- `--format <type>` - Output format\n\n## Examples\n\n```bash\n# All agents metrics\nnpx claude-flow agent metrics\n\n# Specific agent\nnpx claude-flow agent metrics --agent-id agent-001\n\n# Last hour\nnpx claude-flow agent metrics --period 1h\n```\n",
        ".claude/commands/monitoring/real-time-view.md": "# real-time-view\n\nReal-time view of swarm activity.\n\n## Usage\n\n```bash\nnpx claude-flow monitoring real-time-view [options]\n```\n\n## Options\n\n- `--filter <type>` - Filter view\n- `--highlight <pattern>` - Highlight pattern\n- `--tail <n>` - Show last N events\n\n## Examples\n\n```bash\n# Start real-time view\nnpx claude-flow monitoring real-time-view\n\n# Filter errors\nnpx claude-flow monitoring real-time-view --filter errors\n\n# Highlight pattern\nnpx claude-flow monitoring real-time-view --highlight \"API\"\n```\n",
        ".claude/commands/monitoring/swarm-monitor.md": "# swarm-monitor\n\nReal-time swarm monitoring.\n\n## Usage\n\n```bash\nnpx claude-flow swarm monitor [options]\n```\n\n## Options\n\n- `--interval <ms>` - Update interval\n- `--metrics` - Show detailed metrics\n- `--export` - Export monitoring data\n\n## Examples\n\n```bash\n# Start monitoring\nnpx claude-flow swarm monitor\n\n# Custom interval\nnpx claude-flow swarm monitor --interval 5000\n\n# With metrics\nnpx claude-flow swarm monitor --metrics\n```\n",
        ".claude/commands/optimization/README.md": "# Optimization Commands\n\nCommands for optimization operations in Claude Flow.\n\n## Available Commands\n\n- [topology-optimize](./topology-optimize.md)\n- [parallel-execute](./parallel-execute.md)\n- [cache-manage](./cache-manage.md)\n",
        ".claude/commands/optimization/cache-manage.md": "# cache-manage\n\nManage operation cache for performance.\n\n## Usage\n\n```bash\nnpx claude-flow optimization cache-manage [options]\n```\n\n## Options\n\n- `--action <type>` - Action (view, clear, optimize)\n- `--max-size <mb>` - Maximum cache size\n- `--ttl <seconds>` - Time to live\n\n## Examples\n\n```bash\n# View cache stats\nnpx claude-flow optimization cache-manage --action view\n\n# Clear cache\nnpx claude-flow optimization cache-manage --action clear\n\n# Set limits\nnpx claude-flow optimization cache-manage --max-size 100 --ttl 3600\n```\n",
        ".claude/commands/optimization/parallel-execute.md": "# parallel-execute\n\nExecute tasks in parallel for maximum efficiency.\n\n## Usage\n\n```bash\nnpx claude-flow optimization parallel-execute [options]\n```\n\n## Options\n\n- `--tasks <file>` - Task list file\n- `--max-parallel <n>` - Maximum parallel tasks\n- `--strategy <type>` - Execution strategy\n\n## Examples\n\n```bash\n# Execute task list\nnpx claude-flow optimization parallel-execute --tasks tasks.json\n\n# Limit parallelism\nnpx claude-flow optimization parallel-execute --tasks tasks.json --max-parallel 5\n\n# Custom strategy\nnpx claude-flow optimization parallel-execute --strategy adaptive\n```\n",
        ".claude/commands/optimization/topology-optimize.md": "# topology-optimize\n\nOptimize swarm topology for current workload.\n\n## Usage\n\n```bash\nnpx claude-flow optimization topology-optimize [options]\n```\n\n## Options\n\n- `--analyze-first` - Analyze before optimizing\n- `--target <metric>` - Optimization target\n- `--apply` - Apply optimizations\n\n## Examples\n\n```bash\n# Analyze and suggest\nnpx claude-flow optimization topology-optimize --analyze-first\n\n# Optimize for speed\nnpx claude-flow optimization topology-optimize --target speed\n\n# Apply changes\nnpx claude-flow optimization topology-optimize --target efficiency --apply\n```\n",
        ".claude/commands/training/README.md": "# Training Commands\n\nCommands for training operations in Claude Flow.\n\n## Available Commands\n\n- [neural-train](./neural-train.md)\n- [pattern-learn](./pattern-learn.md)\n- [model-update](./model-update.md)\n",
        ".claude/commands/training/model-update.md": "# model-update\n\nUpdate neural models with new data.\n\n## Usage\n\n```bash\nnpx claude-flow training model-update [options]\n```\n\n## Options\n\n- `--model <name>` - Model to update\n- `--incremental` - Incremental update\n- `--validate` - Validate after update\n\n## Examples\n\n```bash\n# Update all models\nnpx claude-flow training model-update\n\n# Specific model\nnpx claude-flow training model-update --model agent-selector\n\n# Incremental with validation\nnpx claude-flow training model-update --incremental --validate\n```\n",
        ".claude/commands/training/neural-train.md": "# neural-train\n\nTrain neural patterns from operations.\n\n## Usage\n\n```bash\nnpx claude-flow training neural-train [options]\n```\n\n## Options\n\n- `--data <source>` - Training data source\n- `--model <name>` - Target model\n- `--epochs <n>` - Training epochs\n\n## Examples\n\n```bash\n# Train from recent ops\nnpx claude-flow training neural-train --data recent\n\n# Specific model\nnpx claude-flow training neural-train --model task-predictor\n\n# Custom epochs\nnpx claude-flow training neural-train --epochs 100\n```\n",
        ".claude/commands/training/pattern-learn.md": "# pattern-learn\n\nLearn patterns from successful operations.\n\n## Usage\n\n```bash\nnpx claude-flow training pattern-learn [options]\n```\n\n## Options\n\n- `--source <type>` - Pattern source\n- `--threshold <score>` - Success threshold\n- `--save <name>` - Save pattern set\n\n## Examples\n\n```bash\n# Learn from all ops\nnpx claude-flow training pattern-learn\n\n# High success only\nnpx claude-flow training pattern-learn --threshold 0.9\n\n# Save patterns\nnpx claude-flow training pattern-learn --save optimal-patterns\n```\n",
        ".claude/commands/workflows/README.md": "# Workflows Commands\n\nCommands for workflows operations in Claude Flow.\n\n## Available Commands\n\n- [workflow-create](./workflow-create.md)\n- [workflow-execute](./workflow-execute.md)\n- [workflow-export](./workflow-export.md)\n",
        ".claude/commands/workflows/workflow-create.md": "# workflow-create\n\nCreate reusable workflow templates.\n\n## Usage\n\n```bash\nnpx claude-flow workflow create [options]\n```\n\n## Options\n\n- `--name <name>` - Workflow name\n- `--from-history` - Create from history\n- `--interactive` - Interactive creation\n\n## Examples\n\n```bash\n# Create workflow\nnpx claude-flow workflow create --name \"deploy-api\"\n\n# From history\nnpx claude-flow workflow create --name \"test-suite\" --from-history\n\n# Interactive mode\nnpx claude-flow workflow create --interactive\n```\n",
        ".claude/commands/workflows/workflow-execute.md": "# workflow-execute\n\nExecute saved workflows.\n\n## Usage\n\n```bash\nnpx claude-flow workflow execute [options]\n```\n\n## Options\n\n- `--name <name>` - Workflow name\n- `--params <json>` - Workflow parameters\n- `--dry-run` - Preview execution\n\n## Examples\n\n```bash\n# Execute workflow\nnpx claude-flow workflow execute --name \"deploy-api\"\n\n# With parameters\nnpx claude-flow workflow execute --name \"test-suite\" --params '{\"env\": \"staging\"}'\n\n# Dry run\nnpx claude-flow workflow execute --name \"deploy-api\" --dry-run\n```\n",
        ".claude/commands/workflows/workflow-export.md": "# workflow-export\n\nExport workflows for sharing.\n\n## Usage\n\n```bash\nnpx claude-flow workflow export [options]\n```\n\n## Options\n\n- `--name <name>` - Workflow to export\n- `--format <type>` - Export format\n- `--include-history` - Include execution history\n\n## Examples\n\n```bash\n# Export workflow\nnpx claude-flow workflow export --name \"deploy-api\"\n\n# As YAML\nnpx claude-flow workflow export --name \"test-suite\" --format yaml\n\n# With history\nnpx claude-flow workflow export --name \"deploy-api\" --include-history\n```\n",
        ".claude/skills/algorithmic-art/SKILL.md": "---\nname: algorithmic-art\ndescription: Creating algorithmic art using p5.js with seeded randomness and interactive parameter exploration. Use this when users request creating art using code, generative art, algorithmic art, flow fields, or particle systems. Create original algorithmic art rather than copying existing artists' work to avoid copyright violations.\nlicense: Complete terms in LICENSE.txt\n---\n\nAlgorithmic philosophies are computational aesthetic movements that are then expressed through code. Output .md files (philosophy), .html files (interactive viewer), and .js files (generative algorithms).\n\nThis happens in two steps:\n1. Algorithmic Philosophy Creation (.md file)\n2. Express by creating p5.js generative art (.html + .js files)\n\nFirst, undertake this task:\n\n## ALGORITHMIC PHILOSOPHY CREATION\n\nTo begin, create an ALGORITHMIC PHILOSOPHY (not static images or templates) that will be interpreted through:\n- Computational processes, emergent behavior, mathematical beauty\n- Seeded randomness, noise fields, organic systems\n- Particles, flows, fields, forces\n- Parametric variation and controlled chaos\n\n### THE CRITICAL UNDERSTANDING\n- What is received: Some subtle input or instructions by the user to take into account, but use as a foundation; it should not constrain creative freedom.\n- What is created: An algorithmic philosophy/generative aesthetic movement.\n- What happens next: The same version receives the philosophy and EXPRESSES IT IN CODE - creating p5.js sketches that are 90% algorithmic generation, 10% essential parameters.\n\nConsider this approach:\n- Write a manifesto for a generative art movement\n- The next phase involves writing the algorithm that brings it to life\n\nThe philosophy must emphasize: Algorithmic expression. Emergent behavior. Computational beauty. Seeded variation.\n\n### HOW TO GENERATE AN ALGORITHMIC PHILOSOPHY\n\n**Name the movement** (1-2 words): \"Organic Turbulence\" / \"Quantum Harmonics\" / \"Emergent Stillness\"\n\n**Articulate the philosophy** (4-6 paragraphs - concise but complete):\n\nTo capture the ALGORITHMIC essence, express how this philosophy manifests through:\n- Computational processes and mathematical relationships?\n- Noise functions and randomness patterns?\n- Particle behaviors and field dynamics?\n- Temporal evolution and system states?\n- Parametric variation and emergent complexity?\n\n**CRITICAL GUIDELINES:**\n- **Avoid redundancy**: Each algorithmic aspect should be mentioned once. Avoid repeating concepts about noise theory, particle dynamics, or mathematical principles unless adding new depth.\n- **Emphasize craftsmanship REPEATEDLY**: The philosophy MUST stress multiple times that the final algorithm should appear as though it took countless hours to develop, was refined with care, and comes from someone at the absolute top of their field. This framing is essential - repeat phrases like \"meticulously crafted algorithm,\" \"the product of deep computational expertise,\" \"painstaking optimization,\" \"master-level implementation.\"\n- **Leave creative space**: Be specific about the algorithmic direction, but concise enough that the next Claude has room to make interpretive implementation choices at an extremely high level of craftsmanship.\n\nThe philosophy must guide the next version to express ideas ALGORITHMICALLY, not through static images. Beauty lives in the process, not the final frame.\n\n### PHILOSOPHY EXAMPLES\n\n**\"Organic Turbulence\"**\nPhilosophy: Chaos constrained by natural law, order emerging from disorder.\nAlgorithmic expression: Flow fields driven by layered Perlin noise. Thousands of particles following vector forces, their trails accumulating into organic density maps. Multiple noise octaves create turbulent regions and calm zones. Color emerges from velocity and density - fast particles burn bright, slow ones fade to shadow. The algorithm runs until equilibrium - a meticulously tuned balance where every parameter was refined through countless iterations by a master of computational aesthetics.\n\n**\"Quantum Harmonics\"**\nPhilosophy: Discrete entities exhibiting wave-like interference patterns.\nAlgorithmic expression: Particles initialized on a grid, each carrying a phase value that evolves through sine waves. When particles are near, their phases interfere - constructive interference creates bright nodes, destructive creates voids. Simple harmonic motion generates complex emergent mandalas. The result of painstaking frequency calibration where every ratio was carefully chosen to produce resonant beauty.\n\n**\"Recursive Whispers\"**\nPhilosophy: Self-similarity across scales, infinite depth in finite space.\nAlgorithmic expression: Branching structures that subdivide recursively. Each branch slightly randomized but constrained by golden ratios. L-systems or recursive subdivision generate tree-like forms that feel both mathematical and organic. Subtle noise perturbations break perfect symmetry. Line weights diminish with each recursion level. Every branching angle the product of deep mathematical exploration.\n\n**\"Field Dynamics\"**\nPhilosophy: Invisible forces made visible through their effects on matter.\nAlgorithmic expression: Vector fields constructed from mathematical functions or noise. Particles born at edges, flowing along field lines, dying when they reach equilibrium or boundaries. Multiple fields can attract, repel, or rotate particles. The visualization shows only the traces - ghost-like evidence of invisible forces. A computational dance meticulously choreographed through force balance.\n\n**\"Stochastic Crystallization\"**\nPhilosophy: Random processes crystallizing into ordered structures.\nAlgorithmic expression: Randomized circle packing or Voronoi tessellation. Start with random points, let them evolve through relaxation algorithms. Cells push apart until equilibrium. Color based on cell size, neighbor count, or distance from center. The organic tiling that emerges feels both random and inevitable. Every seed produces unique crystalline beauty - the mark of a master-level generative algorithm.\n\n*These are condensed examples. The actual algorithmic philosophy should be 4-6 substantial paragraphs.*\n\n### ESSENTIAL PRINCIPLES\n- **ALGORITHMIC PHILOSOPHY**: Creating a computational worldview to be expressed through code\n- **PROCESS OVER PRODUCT**: Always emphasize that beauty emerges from the algorithm's execution - each run is unique\n- **PARAMETRIC EXPRESSION**: Ideas communicate through mathematical relationships, forces, behaviors - not static composition\n- **ARTISTIC FREEDOM**: The next Claude interprets the philosophy algorithmically - provide creative implementation room\n- **PURE GENERATIVE ART**: This is about making LIVING ALGORITHMS, not static images with randomness\n- **EXPERT CRAFTSMANSHIP**: Repeatedly emphasize the final algorithm must feel meticulously crafted, refined through countless iterations, the product of deep expertise by someone at the absolute top of their field in computational aesthetics\n\n**The algorithmic philosophy should be 4-6 paragraphs long.** Fill it with poetic computational philosophy that brings together the intended vision. Avoid repeating the same points. Output this algorithmic philosophy as a .md file.\n\n---\n\n## DEDUCING THE CONCEPTUAL SEED\n\n**CRITICAL STEP**: Before implementing the algorithm, identify the subtle conceptual thread from the original request.\n\n**THE ESSENTIAL PRINCIPLE**:\nThe concept is a **subtle, niche reference embedded within the algorithm itself** - not always literal, always sophisticated. Someone familiar with the subject should feel it intuitively, while others simply experience a masterful generative composition. The algorithmic philosophy provides the computational language. The deduced concept provides the soul - the quiet conceptual DNA woven invisibly into parameters, behaviors, and emergence patterns.\n\nThis is **VERY IMPORTANT**: The reference must be so refined that it enhances the work's depth without announcing itself. Think like a jazz musician quoting another song through algorithmic harmony - only those who know will catch it, but everyone appreciates the generative beauty.\n\n---\n\n## P5.JS IMPLEMENTATION\n\nWith the philosophy AND conceptual framework established, express it through code. Pause to gather thoughts before proceeding. Use only the algorithmic philosophy created and the instructions below.\n\n###  STEP 0: READ THE TEMPLATE FIRST \n\n**CRITICAL: BEFORE writing any HTML:**\n\n1. **Read** `templates/viewer.html` using the Read tool\n2. **Study** the exact structure, styling, and Anthropic branding\n3. **Use that file as the LITERAL STARTING POINT** - not just inspiration\n4. **Keep all FIXED sections exactly as shown** (header, sidebar structure, Anthropic colors/fonts, seed controls, action buttons)\n5. **Replace only the VARIABLE sections** marked in the file's comments (algorithm, parameters, UI controls for parameters)\n\n**Avoid:**\n-  Creating HTML from scratch\n-  Inventing custom styling or color schemes\n-  Using system fonts or dark themes\n-  Changing the sidebar structure\n\n**Follow these practices:**\n-  Copy the template's exact HTML structure\n-  Keep Anthropic branding (Poppins/Lora fonts, light colors, gradient backdrop)\n-  Maintain the sidebar layout (Seed  Parameters  Colors?  Actions)\n-  Replace only the p5.js algorithm and parameter controls\n\nThe template is the foundation. Build on it, don't rebuild it.\n\n---\n\nTo create gallery-quality computational art that lives and breathes, use the algorithmic philosophy as the foundation.\n\n### TECHNICAL REQUIREMENTS\n\n**Seeded Randomness (Art Blocks Pattern)**:\n```javascript\n// ALWAYS use a seed for reproducibility\nlet seed = 12345; // or hash from user input\nrandomSeed(seed);\nnoiseSeed(seed);\n```\n\n**Parameter Structure - FOLLOW THE PHILOSOPHY**:\n\nTo establish parameters that emerge naturally from the algorithmic philosophy, consider: \"What qualities of this system can be adjusted?\"\n\n```javascript\nlet params = {\n  seed: 12345,  // Always include seed for reproducibility\n  // colors\n  // Add parameters that control YOUR algorithm:\n  // - Quantities (how many?)\n  // - Scales (how big? how fast?)\n  // - Probabilities (how likely?)\n  // - Ratios (what proportions?)\n  // - Angles (what direction?)\n  // - Thresholds (when does behavior change?)\n};\n```\n\n**To design effective parameters, focus on the properties the system needs to be tunable rather than thinking in terms of \"pattern types\".**\n\n**Core Algorithm - EXPRESS THE PHILOSOPHY**:\n\n**CRITICAL**: The algorithmic philosophy should dictate what to build.\n\nTo express the philosophy through code, avoid thinking \"which pattern should I use?\" and instead think \"how to express this philosophy through code?\"\n\nIf the philosophy is about **organic emergence**, consider using:\n- Elements that accumulate or grow over time\n- Random processes constrained by natural rules\n- Feedback loops and interactions\n\nIf the philosophy is about **mathematical beauty**, consider using:\n- Geometric relationships and ratios\n- Trigonometric functions and harmonics\n- Precise calculations creating unexpected patterns\n\nIf the philosophy is about **controlled chaos**, consider using:\n- Random variation within strict boundaries\n- Bifurcation and phase transitions\n- Order emerging from disorder\n\n**The algorithm flows from the philosophy, not from a menu of options.**\n\nTo guide the implementation, let the conceptual essence inform creative and original choices. Build something that expresses the vision for this particular request.\n\n**Canvas Setup**: Standard p5.js structure:\n```javascript\nfunction setup() {\n  createCanvas(1200, 1200);\n  // Initialize your system\n}\n\nfunction draw() {\n  // Your generative algorithm\n  // Can be static (noLoop) or animated\n}\n```\n\n### CRAFTSMANSHIP REQUIREMENTS\n\n**CRITICAL**: To achieve mastery, create algorithms that feel like they emerged through countless iterations by a master generative artist. Tune every parameter carefully. Ensure every pattern emerges with purpose. This is NOT random noise - this is CONTROLLED CHAOS refined through deep expertise.\n\n- **Balance**: Complexity without visual noise, order without rigidity\n- **Color Harmony**: Thoughtful palettes, not random RGB values\n- **Composition**: Even in randomness, maintain visual hierarchy and flow\n- **Performance**: Smooth execution, optimized for real-time if animated\n- **Reproducibility**: Same seed ALWAYS produces identical output\n\n### OUTPUT FORMAT\n\nOutput:\n1. **Algorithmic Philosophy** - As markdown or text explaining the generative aesthetic\n2. **Single HTML Artifact** - Self-contained interactive generative art built from `templates/viewer.html` (see STEP 0 and next section)\n\nThe HTML artifact contains everything: p5.js (from CDN), the algorithm, parameter controls, and UI - all in one file that works immediately in claude.ai artifacts or any browser. Start from the template file, not from scratch.\n\n---\n\n## INTERACTIVE ARTIFACT CREATION\n\n**REMINDER: `templates/viewer.html` should have already been read (see STEP 0). Use that file as the starting point.**\n\nTo allow exploration of the generative art, create a single, self-contained HTML artifact. Ensure this artifact works immediately in claude.ai or any browser - no setup required. Embed everything inline.\n\n### CRITICAL: WHAT'S FIXED VS VARIABLE\n\nThe `templates/viewer.html` file is the foundation. It contains the exact structure and styling needed.\n\n**FIXED (always include exactly as shown):**\n- Layout structure (header, sidebar, main canvas area)\n- Anthropic branding (UI colors, fonts, gradients)\n- Seed section in sidebar:\n  - Seed display\n  - Previous/Next buttons\n  - Random button\n  - Jump to seed input + Go button\n- Actions section in sidebar:\n  - Regenerate button\n  - Reset button\n\n**VARIABLE (customize for each artwork):**\n- The entire p5.js algorithm (setup/draw/classes)\n- The parameters object (define what the art needs)\n- The Parameters section in sidebar:\n  - Number of parameter controls\n  - Parameter names\n  - Min/max/step values for sliders\n  - Control types (sliders, inputs, etc.)\n- Colors section (optional):\n  - Some art needs color pickers\n  - Some art might use fixed colors\n  - Some art might be monochrome (no color controls needed)\n  - Decide based on the art's needs\n\n**Every artwork should have unique parameters and algorithm!** The fixed parts provide consistent UX - everything else expresses the unique vision.\n\n### REQUIRED FEATURES\n\n**1. Parameter Controls**\n- Sliders for numeric parameters (particle count, noise scale, speed, etc.)\n- Color pickers for palette colors\n- Real-time updates when parameters change\n- Reset button to restore defaults\n\n**2. Seed Navigation**\n- Display current seed number\n- \"Previous\" and \"Next\" buttons to cycle through seeds\n- \"Random\" button for random seed\n- Input field to jump to specific seed\n- Generate 100 variations when requested (seeds 1-100)\n\n**3. Single Artifact Structure**\n```html\n<!DOCTYPE html>\n<html>\n<head>\n  <!-- p5.js from CDN - always available -->\n  <script src=\"https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.7.0/p5.min.js\"></script>\n  <style>\n    /* All styling inline - clean, minimal */\n    /* Canvas on top, controls below */\n  </style>\n</head>\n<body>\n  <div id=\"canvas-container\"></div>\n  <div id=\"controls\">\n    <!-- All parameter controls -->\n  </div>\n  <script>\n    // ALL p5.js code inline here\n    // Parameter objects, classes, functions\n    // setup() and draw()\n    // UI handlers\n    // Everything self-contained\n  </script>\n</body>\n</html>\n```\n\n**CRITICAL**: This is a single artifact. No external files, no imports (except p5.js CDN). Everything inline.\n\n**4. Implementation Details - BUILD THE SIDEBAR**\n\nThe sidebar structure:\n\n**1. Seed (FIXED)** - Always include exactly as shown:\n- Seed display\n- Prev/Next/Random/Jump buttons\n\n**2. Parameters (VARIABLE)** - Create controls for the art:\n```html\n<div class=\"control-group\">\n    <label>Parameter Name</label>\n    <input type=\"range\" id=\"param\" min=\"...\" max=\"...\" step=\"...\" value=\"...\" oninput=\"updateParam('param', this.value)\">\n    <span class=\"value-display\" id=\"param-value\">...</span>\n</div>\n```\nAdd as many control-group divs as there are parameters.\n\n**3. Colors (OPTIONAL/VARIABLE)** - Include if the art needs adjustable colors:\n- Add color pickers if users should control palette\n- Skip this section if the art uses fixed colors\n- Skip if the art is monochrome\n\n**4. Actions (FIXED)** - Always include exactly as shown:\n- Regenerate button\n- Reset button\n- Download PNG button\n\n**Requirements**:\n- Seed controls must work (prev/next/random/jump/display)\n- All parameters must have UI controls\n- Regenerate, Reset, Download buttons must work\n- Keep Anthropic branding (UI styling, not art colors)\n\n### USING THE ARTIFACT\n\nThe HTML artifact works immediately:\n1. **In claude.ai**: Displayed as an interactive artifact - runs instantly\n2. **As a file**: Save and open in any browser - no server needed\n3. **Sharing**: Send the HTML file - it's completely self-contained\n\n---\n\n## VARIATIONS & EXPLORATION\n\nThe artifact includes seed navigation by default (prev/next/random buttons), allowing users to explore variations without creating multiple files. If the user wants specific variations highlighted:\n\n- Include seed presets (buttons for \"Variation 1: Seed 42\", \"Variation 2: Seed 127\", etc.)\n- Add a \"Gallery Mode\" that shows thumbnails of multiple seeds side-by-side\n- All within the same single artifact\n\nThis is like creating a series of prints from the same plate - the algorithm is consistent, but each seed reveals different facets of its potential. The interactive nature means users discover their own favorites by exploring the seed space.\n\n---\n\n## THE CREATIVE PROCESS\n\n**User request**  **Algorithmic philosophy**  **Implementation**\n\nEach request is unique. The process involves:\n\n1. **Interpret the user's intent** - What aesthetic is being sought?\n2. **Create an algorithmic philosophy** (4-6 paragraphs) describing the computational approach\n3. **Implement it in code** - Build the algorithm that expresses this philosophy\n4. **Design appropriate parameters** - What should be tunable?\n5. **Build matching UI controls** - Sliders/inputs for those parameters\n\n**The constants**:\n- Anthropic branding (colors, fonts, layout)\n- Seed navigation (always present)\n- Self-contained HTML artifact\n\n**Everything else is variable**:\n- The algorithm itself\n- The parameters\n- The UI controls\n- The visual outcome\n\nTo achieve the best results, trust creativity and let the philosophy guide the implementation.\n\n---\n\n## RESOURCES\n\nThis skill includes helpful templates and documentation:\n\n- **templates/viewer.html**: REQUIRED STARTING POINT for all HTML artifacts.\n  - This is the foundation - contains the exact structure and Anthropic branding\n  - **Keep unchanged**: Layout structure, sidebar organization, Anthropic colors/fonts, seed controls, action buttons\n  - **Replace**: The p5.js algorithm, parameter definitions, and UI controls in Parameters section\n  - The extensive comments in the file mark exactly what to keep vs replace\n\n- **templates/generator_template.js**: Reference for p5.js best practices and code structure principles.\n  - Shows how to organize parameters, use seeded randomness, structure classes\n  - NOT a pattern menu - use these principles to build unique algorithms\n  - Embed algorithms inline in the HTML artifact (don't create separate .js files)\n\n**Critical reminder**:\n- The **template is the STARTING POINT**, not inspiration\n- The **algorithm is where to create** something unique\n- Don't copy the flow field example - build what the philosophy demands\n- But DO keep the exact UI structure and Anthropic branding from the template",
        ".claude/skills/brand-guidelines/SKILL.md": "---\nname: brand-guidelines\ndescription: Applies Anthropic's official brand colors and typography to any sort of artifact that may benefit from having Anthropic's look-and-feel. Use it when brand colors or style guidelines, visual formatting, or company design standards apply.\nlicense: Complete terms in LICENSE.txt\n---\n\n# Anthropic Brand Styling\n\n## Overview\n\nTo access Anthropic's official brand identity and style resources, use this skill.\n\n**Keywords**: branding, corporate identity, visual identity, post-processing, styling, brand colors, typography, Anthropic brand, visual formatting, visual design\n\n## Brand Guidelines\n\n### Colors\n\n**Main Colors:**\n\n- Dark: `#141413` - Primary text and dark backgrounds\n- Light: `#faf9f5` - Light backgrounds and text on dark\n- Mid Gray: `#b0aea5` - Secondary elements\n- Light Gray: `#e8e6dc` - Subtle backgrounds\n\n**Accent Colors:**\n\n- Orange: `#d97757` - Primary accent\n- Blue: `#6a9bcc` - Secondary accent\n- Green: `#788c5d` - Tertiary accent\n\n### Typography\n\n- **Headings**: Poppins (with Arial fallback)\n- **Body Text**: Lora (with Georgia fallback)\n- **Note**: Fonts should be pre-installed in your environment for best results\n\n## Features\n\n### Smart Font Application\n\n- Applies Poppins font to headings (24pt and larger)\n- Applies Lora font to body text\n- Automatically falls back to Arial/Georgia if custom fonts unavailable\n- Preserves readability across all systems\n\n### Text Styling\n\n- Headings (24pt+): Poppins font\n- Body text: Lora font\n- Smart color selection based on background\n- Preserves text hierarchy and formatting\n\n### Shape and Accent Colors\n\n- Non-text shapes use accent colors\n- Cycles through orange, blue, and green accents\n- Maintains visual interest while staying on-brand\n\n## Technical Details\n\n### Font Management\n\n- Uses system-installed Poppins and Lora fonts when available\n- Provides automatic fallback to Arial (headings) and Georgia (body)\n- No font installation required - works with existing system fonts\n- For best results, pre-install Poppins and Lora fonts in your environment\n\n### Color Application\n\n- Uses RGB color values for precise brand matching\n- Applied via python-pptx's RGBColor class\n- Maintains color fidelity across different systems\n",
        ".claude/skills/canvas-design/SKILL.md": "---\nname: canvas-design\ndescription: Create beautiful visual art in .png and .pdf documents using design philosophy. You should use this skill when the user asks to create a poster, piece of art, design, or other static piece. Create original visual designs, never copying existing artists' work to avoid copyright violations.\nlicense: Complete terms in LICENSE.txt\n---\n\nThese are instructions for creating design philosophies - aesthetic movements that are then EXPRESSED VISUALLY. Output only .md files, .pdf files, and .png files.\n\nComplete this in two steps:\n1. Design Philosophy Creation (.md file)\n2. Express by creating it on a canvas (.pdf file or .png file)\n\nFirst, undertake this task:\n\n## DESIGN PHILOSOPHY CREATION\n\nTo begin, create a VISUAL PHILOSOPHY (not layouts or templates) that will be interpreted through:\n- Form, space, color, composition\n- Images, graphics, shapes, patterns\n- Minimal text as visual accent\n\n### THE CRITICAL UNDERSTANDING\n- What is received: Some subtle input or instructions by the user that should be taken into account, but used as a foundation; it should not constrain creative freedom.\n- What is created: A design philosophy/aesthetic movement.\n- What happens next: Then, the same version receives the philosophy and EXPRESSES IT VISUALLY - creating artifacts that are 90% visual design, 10% essential text.\n\nConsider this approach:\n- Write a manifesto for an art movement\n- The next phase involves making the artwork\n\nThe philosophy must emphasize: Visual expression. Spatial communication. Artistic interpretation. Minimal words.\n\n### HOW TO GENERATE A VISUAL PHILOSOPHY\n\n**Name the movement** (1-2 words): \"Brutalist Joy\" / \"Chromatic Silence\" / \"Metabolist Dreams\"\n\n**Articulate the philosophy** (4-6 paragraphs - concise but complete):\n\nTo capture the VISUAL essence, express how the philosophy manifests through:\n- Space and form\n- Color and material\n- Scale and rhythm\n- Composition and balance\n- Visual hierarchy\n\n**CRITICAL GUIDELINES:**\n- **Avoid redundancy**: Each design aspect should be mentioned once. Avoid repeating points about color theory, spatial relationships, or typographic principles unless adding new depth.\n- **Emphasize craftsmanship REPEATEDLY**: The philosophy MUST stress multiple times that the final work should appear as though it took countless hours to create, was labored over with care, and comes from someone at the absolute top of their field. This framing is essential - repeat phrases like \"meticulously crafted,\" \"the product of deep expertise,\" \"painstaking attention,\" \"master-level execution.\"\n- **Leave creative space**: Remain specific about the aesthetic direction, but concise enough that the next Claude has room to make interpretive choices also at a extremely high level of craftmanship.\n\nThe philosophy must guide the next version to express ideas VISUALLY, not through text. Information lives in design, not paragraphs.\n\n### PHILOSOPHY EXAMPLES\n\n**\"Concrete Poetry\"**\nPhilosophy: Communication through monumental form and bold geometry.\nVisual expression: Massive color blocks, sculptural typography (huge single words, tiny labels), Brutalist spatial divisions, Polish poster energy meets Le Corbusier. Ideas expressed through visual weight and spatial tension, not explanation. Text as rare, powerful gesture - never paragraphs, only essential words integrated into the visual architecture. Every element placed with the precision of a master craftsman.\n\n**\"Chromatic Language\"**\nPhilosophy: Color as the primary information system.\nVisual expression: Geometric precision where color zones create meaning. Typography minimal - small sans-serif labels letting chromatic fields communicate. Think Josef Albers' interaction meets data visualization. Information encoded spatially and chromatically. Words only to anchor what color already shows. The result of painstaking chromatic calibration.\n\n**\"Analog Meditation\"**\nPhilosophy: Quiet visual contemplation through texture and breathing room.\nVisual expression: Paper grain, ink bleeds, vast negative space. Photography and illustration dominate. Typography whispered (small, restrained, serving the visual). Japanese photobook aesthetic. Images breathe across pages. Text appears sparingly - short phrases, never explanatory blocks. Each composition balanced with the care of a meditation practice.\n\n**\"Organic Systems\"**\nPhilosophy: Natural clustering and modular growth patterns.\nVisual expression: Rounded forms, organic arrangements, color from nature through architecture. Information shown through visual diagrams, spatial relationships, iconography. Text only for key labels floating in space. The composition tells the story through expert spatial orchestration.\n\n**\"Geometric Silence\"**\nPhilosophy: Pure order and restraint.\nVisual expression: Grid-based precision, bold photography or stark graphics, dramatic negative space. Typography precise but minimal - small essential text, large quiet zones. Swiss formalism meets Brutalist material honesty. Structure communicates, not words. Every alignment the work of countless refinements.\n\n*These are condensed examples. The actual design philosophy should be 4-6 substantial paragraphs.*\n\n### ESSENTIAL PRINCIPLES\n- **VISUAL PHILOSOPHY**: Create an aesthetic worldview to be expressed through design\n- **MINIMAL TEXT**: Always emphasize that text is sparse, essential-only, integrated as visual element - never lengthy\n- **SPATIAL EXPRESSION**: Ideas communicate through space, form, color, composition - not paragraphs\n- **ARTISTIC FREEDOM**: The next Claude interprets the philosophy visually - provide creative room\n- **PURE DESIGN**: This is about making ART OBJECTS, not documents with decoration\n- **EXPERT CRAFTSMANSHIP**: Repeatedly emphasize the final work must look meticulously crafted, labored over with care, the product of countless hours by someone at the top of their field\n\n**The design philosophy should be 4-6 paragraphs long.** Fill it with poetic design philosophy that brings together the core vision. Avoid repeating the same points. Keep the design philosophy generic without mentioning the intention of the art, as if it can be used wherever. Output the design philosophy as a .md file.\n\n---\n\n## DEDUCING THE SUBTLE REFERENCE\n\n**CRITICAL STEP**: Before creating the canvas, identify the subtle conceptual thread from the original request.\n\n**THE ESSENTIAL PRINCIPLE**:\nThe topic is a **subtle, niche reference embedded within the art itself** - not always literal, always sophisticated. Someone familiar with the subject should feel it intuitively, while others simply experience a masterful abstract composition. The design philosophy provides the aesthetic language. The deduced topic provides the soul - the quiet conceptual DNA woven invisibly into form, color, and composition.\n\nThis is **VERY IMPORTANT**: The reference must be refined so it enhances the work's depth without announcing itself. Think like a jazz musician quoting another song - only those who know will catch it, but everyone appreciates the music.\n\n---\n\n## CANVAS CREATION\n\nWith both the philosophy and the conceptual framework established, express it on a canvas. Take a moment to gather thoughts and clear the mind. Use the design philosophy created and the instructions below to craft a masterpiece, embodying all aspects of the philosophy with expert craftsmanship.\n\n**IMPORTANT**: For any type of content, even if the user requests something for a movie/game/book, the approach should still be sophisticated. Never lose sight of the idea that this should be art, not something that's cartoony or amateur.\n\nTo create museum or magazine quality work, use the design philosophy as the foundation. Create one single page, highly visual, design-forward PDF or PNG output (unless asked for more pages). Generally use repeating patterns and perfect shapes. Treat the abstract philosophical design as if it were a scientific bible, borrowing the visual language of systematic observationdense accumulation of marks, repeated elements, or layered patterns that build meaning through patient repetition and reward sustained viewing. Add sparse, clinical typography and systematic reference markers that suggest this could be a diagram from an imaginary discipline, treating the invisible subject with the same reverence typically reserved for documenting observable phenomena. Anchor the piece with simple phrase(s) or details positioned subtly, using a limited color palette that feels intentional and cohesive. Embrace the paradox of using analytical visual language to express ideas about human experience: the result should feel like an artifact that proves something ephemeral can be studied, mapped, and understood through careful attention. This is true art. \n\n**Text as a contextual element**: Text is always minimal and visual-first, but let context guide whether that means whisper-quiet labels or bold typographic gestures. A punk venue poster might have larger, more aggressive type than a minimalist ceramics studio identity. Most of the time, font should be thin. All use of fonts must be design-forward and prioritize visual communication. Regardless of text scale, nothing falls off the page and nothing overlaps. Every element must be contained within the canvas boundaries with proper margins. Check carefully that all text, graphics, and visual elements have breathing room and clear separation. This is non-negotiable for professional execution. **IMPORTANT: Use different fonts if writing text. Search the `./canvas-fonts` directory. Regardless of approach, sophistication is non-negotiable.**\n\nDownload and use whatever fonts are needed to make this a reality. Get creative by making the typography actually part of the art itself -- if the art is abstract, bring the font onto the canvas, not typeset digitally.\n\nTo push boundaries, follow design instinct/intuition while using the philosophy as a guiding principle. Embrace ultimate design freedom and choice. Push aesthetics and design to the frontier. \n\n**CRITICAL**: To achieve human-crafted quality (not AI-generated), create work that looks like it took countless hours. Make it appear as though someone at the absolute top of their field labored over every detail with painstaking care. Ensure the composition, spacing, color choices, typography - everything screams expert-level craftsmanship. Double-check that nothing overlaps, formatting is flawless, every detail perfect. Create something that could be shown to people to prove expertise and rank as undeniably impressive.\n\nOutput the final result as a single, downloadable .pdf or .png file, alongside the design philosophy used as a .md file.\n\n---\n\n## FINAL STEP\n\n**IMPORTANT**: The user ALREADY said \"It isn't perfect enough. It must be pristine, a masterpiece if craftsmanship, as if it were about to be displayed in a museum.\"\n\n**CRITICAL**: To refine the work, avoid adding more graphics; instead refine what has been created and make it extremely crisp, respecting the design philosophy and the principles of minimalism entirely. Rather than adding a fun filter or refactoring a font, consider how to make the existing composition more cohesive with the art. If the instinct is to call a new function or draw a new shape, STOP and instead ask: \"How can I make what's already here more of a piece of art?\"\n\nTake a second pass. Go back to the code and refine/polish further to make this a philosophically designed masterpiece.\n\n## MULTI-PAGE OPTION\n\nTo create additional pages when requested, create more creative pages along the same lines as the design philosophy but distinctly different as well. Bundle those pages in the same .pdf or many .pngs. Treat the first page as just a single page in a whole coffee table book waiting to be filled. Make the next pages unique twists and memories of the original. Have them almost tell a story in a very tasteful way. Exercise full creative freedom.",
        ".claude/skills/doc-coauthoring/SKILL.md": "---\nname: doc-coauthoring\ndescription: Guide users through a structured workflow for co-authoring documentation. Use when user wants to write documentation, proposals, technical specs, decision docs, or similar structured content. This workflow helps users efficiently transfer context, refine content through iteration, and verify the doc works for readers. Trigger when user mentions writing docs, creating proposals, drafting specs, or similar documentation tasks.\n---\n\n# Doc Co-Authoring Workflow\n\nThis skill provides a structured workflow for guiding users through collaborative document creation. Act as an active guide, walking users through three stages: Context Gathering, Refinement & Structure, and Reader Testing.\n\n## When to Offer This Workflow\n\n**Trigger conditions:**\n- User mentions writing documentation: \"write a doc\", \"draft a proposal\", \"create a spec\", \"write up\"\n- User mentions specific doc types: \"PRD\", \"design doc\", \"decision doc\", \"RFC\"\n- User seems to be starting a substantial writing task\n\n**Initial offer:**\nOffer the user a structured workflow for co-authoring the document. Explain the three stages:\n\n1. **Context Gathering**: User provides all relevant context while Claude asks clarifying questions\n2. **Refinement & Structure**: Iteratively build each section through brainstorming and editing\n3. **Reader Testing**: Test the doc with a fresh Claude (no context) to catch blind spots before others read it\n\nExplain that this approach helps ensure the doc works well when others read it (including when they paste it into Claude). Ask if they want to try this workflow or prefer to work freeform.\n\nIf user declines, work freeform. If user accepts, proceed to Stage 1.\n\n## Stage 1: Context Gathering\n\n**Goal:** Close the gap between what the user knows and what Claude knows, enabling smart guidance later.\n\n### Initial Questions\n\nStart by asking the user for meta-context about the document:\n\n1. What type of document is this? (e.g., technical spec, decision doc, proposal)\n2. Who's the primary audience?\n3. What's the desired impact when someone reads this?\n4. Is there a template or specific format to follow?\n5. Any other constraints or context to know?\n\nInform them they can answer in shorthand or dump information however works best for them.\n\n**If user provides a template or mentions a doc type:**\n- Ask if they have a template document to share\n- If they provide a link to a shared document, use the appropriate integration to fetch it\n- If they provide a file, read it\n\n**If user mentions editing an existing shared document:**\n- Use the appropriate integration to read the current state\n- Check for images without alt-text\n- If images exist without alt-text, explain that when others use Claude to understand the doc, Claude won't be able to see them. Ask if they want alt-text generated. If so, request they paste each image into chat for descriptive alt-text generation.\n\n### Info Dumping\n\nOnce initial questions are answered, encourage the user to dump all the context they have. Request information such as:\n- Background on the project/problem\n- Related team discussions or shared documents\n- Why alternative solutions aren't being used\n- Organizational context (team dynamics, past incidents, politics)\n- Timeline pressures or constraints\n- Technical architecture or dependencies\n- Stakeholder concerns\n\nAdvise them not to worry about organizing it - just get it all out. Offer multiple ways to provide context:\n- Info dump stream-of-consciousness\n- Point to team channels or threads to read\n- Link to shared documents\n\n**If integrations are available** (e.g., Slack, Teams, Google Drive, SharePoint, or other MCP servers), mention that these can be used to pull in context directly.\n\n**If no integrations are detected and in Claude.ai or Claude app:** Suggest they can enable connectors in their Claude settings to allow pulling context from messaging apps and document storage directly.\n\nInform them clarifying questions will be asked once they've done their initial dump.\n\n**During context gathering:**\n\n- If user mentions team channels or shared documents:\n  - If integrations available: Inform them the content will be read now, then use the appropriate integration\n  - If integrations not available: Explain lack of access. Suggest they enable connectors in Claude settings, or paste the relevant content directly.\n\n- If user mentions entities/projects that are unknown:\n  - Ask if connected tools should be searched to learn more\n  - Wait for user confirmation before searching\n\n- As user provides context, track what's being learned and what's still unclear\n\n**Asking clarifying questions:**\n\nWhen user signals they've done their initial dump (or after substantial context provided), ask clarifying questions to ensure understanding:\n\nGenerate 5-10 numbered questions based on gaps in the context.\n\nInform them they can use shorthand to answer (e.g., \"1: yes, 2: see #channel, 3: no because backwards compat\"), link to more docs, point to channels to read, or just keep info-dumping. Whatever's most efficient for them.\n\n**Exit condition:**\nSufficient context has been gathered when questions show understanding - when edge cases and trade-offs can be asked about without needing basics explained.\n\n**Transition:**\nAsk if there's any more context they want to provide at this stage, or if it's time to move on to drafting the document.\n\nIf user wants to add more, let them. When ready, proceed to Stage 2.\n\n## Stage 2: Refinement & Structure\n\n**Goal:** Build the document section by section through brainstorming, curation, and iterative refinement.\n\n**Instructions to user:**\nExplain that the document will be built section by section. For each section:\n1. Clarifying questions will be asked about what to include\n2. 5-20 options will be brainstormed\n3. User will indicate what to keep/remove/combine\n4. The section will be drafted\n5. It will be refined through surgical edits\n\nStart with whichever section has the most unknowns (usually the core decision/proposal), then work through the rest.\n\n**Section ordering:**\n\nIf the document structure is clear:\nAsk which section they'd like to start with.\n\nSuggest starting with whichever section has the most unknowns. For decision docs, that's usually the core proposal. For specs, it's typically the technical approach. Summary sections are best left for last.\n\nIf user doesn't know what sections they need:\nBased on the type of document and template, suggest 3-5 sections appropriate for the doc type.\n\nAsk if this structure works, or if they want to adjust it.\n\n**Once structure is agreed:**\n\nCreate the initial document structure with placeholder text for all sections.\n\n**If access to artifacts is available:**\nUse `create_file` to create an artifact. This gives both Claude and the user a scaffold to work from.\n\nInform them that the initial structure with placeholders for all sections will be created.\n\nCreate artifact with all section headers and brief placeholder text like \"[To be written]\" or \"[Content here]\".\n\nProvide the scaffold link and indicate it's time to fill in each section.\n\n**If no access to artifacts:**\nCreate a markdown file in the working directory. Name it appropriately (e.g., `decision-doc.md`, `technical-spec.md`).\n\nInform them that the initial structure with placeholders for all sections will be created.\n\nCreate file with all section headers and placeholder text.\n\nConfirm the filename has been created and indicate it's time to fill in each section.\n\n**For each section:**\n\n### Step 1: Clarifying Questions\n\nAnnounce work will begin on the [SECTION NAME] section. Ask 5-10 clarifying questions about what should be included:\n\nGenerate 5-10 specific questions based on context and section purpose.\n\nInform them they can answer in shorthand or just indicate what's important to cover.\n\n### Step 2: Brainstorming\n\nFor the [SECTION NAME] section, brainstorm [5-20] things that might be included, depending on the section's complexity. Look for:\n- Context shared that might have been forgotten\n- Angles or considerations not yet mentioned\n\nGenerate 5-20 numbered options based on section complexity. At the end, offer to brainstorm more if they want additional options.\n\n### Step 3: Curation\n\nAsk which points should be kept, removed, or combined. Request brief justifications to help learn priorities for the next sections.\n\nProvide examples:\n- \"Keep 1,4,7,9\"\n- \"Remove 3 (duplicates 1)\"\n- \"Remove 6 (audience already knows this)\"\n- \"Combine 11 and 12\"\n\n**If user gives freeform feedback** (e.g., \"looks good\" or \"I like most of it but...\") instead of numbered selections, extract their preferences and proceed. Parse what they want kept/removed/changed and apply it.\n\n### Step 4: Gap Check\n\nBased on what they've selected, ask if there's anything important missing for the [SECTION NAME] section.\n\n### Step 5: Drafting\n\nUse `str_replace` to replace the placeholder text for this section with the actual drafted content.\n\nAnnounce the [SECTION NAME] section will be drafted now based on what they've selected.\n\n**If using artifacts:**\nAfter drafting, provide a link to the artifact.\n\nAsk them to read through it and indicate what to change. Note that being specific helps learning for the next sections.\n\n**If using a file (no artifacts):**\nAfter drafting, confirm completion.\n\nInform them the [SECTION NAME] section has been drafted in [filename]. Ask them to read through it and indicate what to change. Note that being specific helps learning for the next sections.\n\n**Key instruction for user (include when drafting the first section):**\nProvide a note: Instead of editing the doc directly, ask them to indicate what to change. This helps learning of their style for future sections. For example: \"Remove the X bullet - already covered by Y\" or \"Make the third paragraph more concise\".\n\n### Step 6: Iterative Refinement\n\nAs user provides feedback:\n- Use `str_replace` to make edits (never reprint the whole doc)\n- **If using artifacts:** Provide link to artifact after each edit\n- **If using files:** Just confirm edits are complete\n- If user edits doc directly and asks to read it: mentally note the changes they made and keep them in mind for future sections (this shows their preferences)\n\n**Continue iterating** until user is satisfied with the section.\n\n### Quality Checking\n\nAfter 3 consecutive iterations with no substantial changes, ask if anything can be removed without losing important information.\n\nWhen section is done, confirm [SECTION NAME] is complete. Ask if ready to move to the next section.\n\n**Repeat for all sections.**\n\n### Near Completion\n\nAs approaching completion (80%+ of sections done), announce intention to re-read the entire document and check for:\n- Flow and consistency across sections\n- Redundancy or contradictions\n- Anything that feels like \"slop\" or generic filler\n- Whether every sentence carries weight\n\nRead entire document and provide feedback.\n\n**When all sections are drafted and refined:**\nAnnounce all sections are drafted. Indicate intention to review the complete document one more time.\n\nReview for overall coherence, flow, completeness.\n\nProvide any final suggestions.\n\nAsk if ready to move to Reader Testing, or if they want to refine anything else.\n\n## Stage 3: Reader Testing\n\n**Goal:** Test the document with a fresh Claude (no context bleed) to verify it works for readers.\n\n**Instructions to user:**\nExplain that testing will now occur to see if the document actually works for readers. This catches blind spots - things that make sense to the authors but might confuse others.\n\n### Testing Approach\n\n**If access to sub-agents is available (e.g., in Claude Code):**\n\nPerform the testing directly without user involvement.\n\n### Step 1: Predict Reader Questions\n\nAnnounce intention to predict what questions readers might ask when trying to discover this document.\n\nGenerate 5-10 questions that readers would realistically ask.\n\n### Step 2: Test with Sub-Agent\n\nAnnounce that these questions will be tested with a fresh Claude instance (no context from this conversation).\n\nFor each question, invoke a sub-agent with just the document content and the question.\n\nSummarize what Reader Claude got right/wrong for each question.\n\n### Step 3: Run Additional Checks\n\nAnnounce additional checks will be performed.\n\nInvoke sub-agent to check for ambiguity, false assumptions, contradictions.\n\nSummarize any issues found.\n\n### Step 4: Report and Fix\n\nIf issues found:\nReport that Reader Claude struggled with specific issues.\n\nList the specific issues.\n\nIndicate intention to fix these gaps.\n\nLoop back to refinement for problematic sections.\n\n---\n\n**If no access to sub-agents (e.g., claude.ai web interface):**\n\nThe user will need to do the testing manually.\n\n### Step 1: Predict Reader Questions\n\nAsk what questions people might ask when trying to discover this document. What would they type into Claude.ai?\n\nGenerate 5-10 questions that readers would realistically ask.\n\n### Step 2: Setup Testing\n\nProvide testing instructions:\n1. Open a fresh Claude conversation: https://claude.ai\n2. Paste or share the document content (if using a shared doc platform with connectors enabled, provide the link)\n3. Ask Reader Claude the generated questions\n\nFor each question, instruct Reader Claude to provide:\n- The answer\n- Whether anything was ambiguous or unclear\n- What knowledge/context the doc assumes is already known\n\nCheck if Reader Claude gives correct answers or misinterprets anything.\n\n### Step 3: Additional Checks\n\nAlso ask Reader Claude:\n- \"What in this doc might be ambiguous or unclear to readers?\"\n- \"What knowledge or context does this doc assume readers already have?\"\n- \"Are there any internal contradictions or inconsistencies?\"\n\n### Step 4: Iterate Based on Results\n\nAsk what Reader Claude got wrong or struggled with. Indicate intention to fix those gaps.\n\nLoop back to refinement for any problematic sections.\n\n---\n\n### Exit Condition (Both Approaches)\n\nWhen Reader Claude consistently answers questions correctly and doesn't surface new gaps or ambiguities, the doc is ready.\n\n## Final Review\n\nWhen Reader Testing passes:\nAnnounce the doc has passed Reader Claude testing. Before completion:\n\n1. Recommend they do a final read-through themselves - they own this document and are responsible for its quality\n2. Suggest double-checking any facts, links, or technical details\n3. Ask them to verify it achieves the impact they wanted\n\nAsk if they want one more review, or if the work is done.\n\n**If user wants final review, provide it. Otherwise:**\nAnnounce document completion. Provide a few final tips:\n- Consider linking this conversation in an appendix so readers can see how the doc was developed\n- Use appendices to provide depth without bloating the main doc\n- Update the doc as feedback is received from real readers\n\n## Tips for Effective Guidance\n\n**Tone:**\n- Be direct and procedural\n- Explain rationale briefly when it affects user behavior\n- Don't try to \"sell\" the approach - just execute it\n\n**Handling Deviations:**\n- If user wants to skip a stage: Ask if they want to skip this and write freeform\n- If user seems frustrated: Acknowledge this is taking longer than expected. Suggest ways to move faster\n- Always give user agency to adjust the process\n\n**Context Management:**\n- Throughout, if context is missing on something mentioned, proactively ask\n- Don't let gaps accumulate - address them as they come up\n\n**Artifact Management:**\n- Use `create_file` for drafting full sections\n- Use `str_replace` for all edits\n- Provide artifact link after every change\n- Never use artifacts for brainstorming lists - that's just conversation\n\n**Quality over Speed:**\n- Don't rush through stages\n- Each iteration should make meaningful improvements\n- The goal is a document that actually works for readers\n",
        ".claude/skills/docx/SKILL.md": "---\nname: docx\ndescription: \"Comprehensive document creation, editing, and analysis with support for tracked changes, comments, formatting preservation, and text extraction. When Claude needs to work with professional documents (.docx files) for: (1) Creating new documents, (2) Modifying or editing content, (3) Working with tracked changes, (4) Adding comments, or any other document tasks\"\nlicense: Proprietary. LICENSE.txt has complete terms\n---\n\n# DOCX creation, editing, and analysis\n\n## Overview\n\nA user may ask you to create, edit, or analyze the contents of a .docx file. A .docx file is essentially a ZIP archive containing XML files and other resources that you can read or edit. You have different tools and workflows available for different tasks.\n\n## Workflow Decision Tree\n\n### Reading/Analyzing Content\nUse \"Text extraction\" or \"Raw XML access\" sections below\n\n### Creating New Document\nUse \"Creating a new Word document\" workflow\n\n### Editing Existing Document\n- **Your own document + simple changes**\n  Use \"Basic OOXML editing\" workflow\n\n- **Someone else's document**\n  Use **\"Redlining workflow\"** (recommended default)\n\n- **Legal, academic, business, or government docs**\n  Use **\"Redlining workflow\"** (required)\n\n## Reading and analyzing content\n\n### Text extraction\nIf you just need to read the text contents of a document, you should convert the document to markdown using pandoc. Pandoc provides excellent support for preserving document structure and can show tracked changes:\n\n```bash\n# Convert document to markdown with tracked changes\npandoc --track-changes=all path-to-file.docx -o output.md\n# Options: --track-changes=accept/reject/all\n```\n\n### Raw XML access\nYou need raw XML access for: comments, complex formatting, document structure, embedded media, and metadata. For any of these features, you'll need to unpack a document and read its raw XML contents.\n\n#### Unpacking a file\n`python ooxml/scripts/unpack.py <office_file> <output_directory>`\n\n#### Key file structures\n* `word/document.xml` - Main document contents\n* `word/comments.xml` - Comments referenced in document.xml\n* `word/media/` - Embedded images and media files\n* Tracked changes use `<w:ins>` (insertions) and `<w:del>` (deletions) tags\n\n## Creating a new Word document\n\nWhen creating a new Word document from scratch, use **docx-js**, which allows you to create Word documents using JavaScript/TypeScript.\n\n### Workflow\n1. **MANDATORY - READ ENTIRE FILE**: Read [`docx-js.md`](docx-js.md) (~500 lines) completely from start to finish. **NEVER set any range limits when reading this file.** Read the full file content for detailed syntax, critical formatting rules, and best practices before proceeding with document creation.\n2. Create a JavaScript/TypeScript file using Document, Paragraph, TextRun components (You can assume all dependencies are installed, but if not, refer to the dependencies section below)\n3. Export as .docx using Packer.toBuffer()\n\n## Editing an existing Word document\n\nWhen editing an existing Word document, use the **Document library** (a Python library for OOXML manipulation). The library automatically handles infrastructure setup and provides methods for document manipulation. For complex scenarios, you can access the underlying DOM directly through the library.\n\n### Workflow\n1. **MANDATORY - READ ENTIRE FILE**: Read [`ooxml.md`](ooxml.md) (~600 lines) completely from start to finish. **NEVER set any range limits when reading this file.** Read the full file content for the Document library API and XML patterns for directly editing document files.\n2. Unpack the document: `python ooxml/scripts/unpack.py <office_file> <output_directory>`\n3. Create and run a Python script using the Document library (see \"Document Library\" section in ooxml.md)\n4. Pack the final document: `python ooxml/scripts/pack.py <input_directory> <office_file>`\n\nThe Document library provides both high-level methods for common operations and direct DOM access for complex scenarios.\n\n## Redlining workflow for document review\n\nThis workflow allows you to plan comprehensive tracked changes using markdown before implementing them in OOXML. **CRITICAL**: For complete tracked changes, you must implement ALL changes systematically.\n\n**Batching Strategy**: Group related changes into batches of 3-10 changes. This makes debugging manageable while maintaining efficiency. Test each batch before moving to the next.\n\n**Principle: Minimal, Precise Edits**\nWhen implementing tracked changes, only mark text that actually changes. Repeating unchanged text makes edits harder to review and appears unprofessional. Break replacements into: [unchanged text] + [deletion] + [insertion] + [unchanged text]. Preserve the original run's RSID for unchanged text by extracting the `<w:r>` element from the original and reusing it.\n\nExample - Changing \"30 days\" to \"60 days\" in a sentence:\n```python\n# BAD - Replaces entire sentence\n'<w:del><w:r><w:delText>The term is 30 days.</w:delText></w:r></w:del><w:ins><w:r><w:t>The term is 60 days.</w:t></w:r></w:ins>'\n\n# GOOD - Only marks what changed, preserves original <w:r> for unchanged text\n'<w:r w:rsidR=\"00AB12CD\"><w:t>The term is </w:t></w:r><w:del><w:r><w:delText>30</w:delText></w:r></w:del><w:ins><w:r><w:t>60</w:t></w:r></w:ins><w:r w:rsidR=\"00AB12CD\"><w:t> days.</w:t></w:r>'\n```\n\n### Tracked changes workflow\n\n1. **Get markdown representation**: Convert document to markdown with tracked changes preserved:\n   ```bash\n   pandoc --track-changes=all path-to-file.docx -o current.md\n   ```\n\n2. **Identify and group changes**: Review the document and identify ALL changes needed, organizing them into logical batches:\n\n   **Location methods** (for finding changes in XML):\n   - Section/heading numbers (e.g., \"Section 3.2\", \"Article IV\")\n   - Paragraph identifiers if numbered\n   - Grep patterns with unique surrounding text\n   - Document structure (e.g., \"first paragraph\", \"signature block\")\n   - **DO NOT use markdown line numbers** - they don't map to XML structure\n\n   **Batch organization** (group 3-10 related changes per batch):\n   - By section: \"Batch 1: Section 2 amendments\", \"Batch 2: Section 5 updates\"\n   - By type: \"Batch 1: Date corrections\", \"Batch 2: Party name changes\"\n   - By complexity: Start with simple text replacements, then tackle complex structural changes\n   - Sequential: \"Batch 1: Pages 1-3\", \"Batch 2: Pages 4-6\"\n\n3. **Read documentation and unpack**:\n   - **MANDATORY - READ ENTIRE FILE**: Read [`ooxml.md`](ooxml.md) (~600 lines) completely from start to finish. **NEVER set any range limits when reading this file.** Pay special attention to the \"Document Library\" and \"Tracked Change Patterns\" sections.\n   - **Unpack the document**: `python ooxml/scripts/unpack.py <file.docx> <dir>`\n   - **Note the suggested RSID**: The unpack script will suggest an RSID to use for your tracked changes. Copy this RSID for use in step 4b.\n\n4. **Implement changes in batches**: Group changes logically (by section, by type, or by proximity) and implement them together in a single script. This approach:\n   - Makes debugging easier (smaller batch = easier to isolate errors)\n   - Allows incremental progress\n   - Maintains efficiency (batch size of 3-10 changes works well)\n\n   **Suggested batch groupings:**\n   - By document section (e.g., \"Section 3 changes\", \"Definitions\", \"Termination clause\")\n   - By change type (e.g., \"Date changes\", \"Party name updates\", \"Legal term replacements\")\n   - By proximity (e.g., \"Changes on pages 1-3\", \"Changes in first half of document\")\n\n   For each batch of related changes:\n\n   **a. Map text to XML**: Grep for text in `word/document.xml` to verify how text is split across `<w:r>` elements.\n\n   **b. Create and run script**: Use `get_node` to find nodes, implement changes, then `doc.save()`. See **\"Document Library\"** section in ooxml.md for patterns.\n\n   **Note**: Always grep `word/document.xml` immediately before writing a script to get current line numbers and verify text content. Line numbers change after each script run.\n\n5. **Pack the document**: After all batches are complete, convert the unpacked directory back to .docx:\n   ```bash\n   python ooxml/scripts/pack.py unpacked reviewed-document.docx\n   ```\n\n6. **Final verification**: Do a comprehensive check of the complete document:\n   - Convert final document to markdown:\n     ```bash\n     pandoc --track-changes=all reviewed-document.docx -o verification.md\n     ```\n   - Verify ALL changes were applied correctly:\n     ```bash\n     grep \"original phrase\" verification.md  # Should NOT find it\n     grep \"replacement phrase\" verification.md  # Should find it\n     ```\n   - Check that no unintended changes were introduced\n\n\n## Converting Documents to Images\n\nTo visually analyze Word documents, convert them to images using a two-step process:\n\n1. **Convert DOCX to PDF**:\n   ```bash\n   soffice --headless --convert-to pdf document.docx\n   ```\n\n2. **Convert PDF pages to JPEG images**:\n   ```bash\n   pdftoppm -jpeg -r 150 document.pdf page\n   ```\n   This creates files like `page-1.jpg`, `page-2.jpg`, etc.\n\nOptions:\n- `-r 150`: Sets resolution to 150 DPI (adjust for quality/size balance)\n- `-jpeg`: Output JPEG format (use `-png` for PNG if preferred)\n- `-f N`: First page to convert (e.g., `-f 2` starts from page 2)\n- `-l N`: Last page to convert (e.g., `-l 5` stops at page 5)\n- `page`: Prefix for output files\n\nExample for specific range:\n```bash\npdftoppm -jpeg -r 150 -f 2 -l 5 document.pdf page  # Converts only pages 2-5\n```\n\n## Code Style Guidelines\n**IMPORTANT**: When generating code for DOCX operations:\n- Write concise code\n- Avoid verbose variable names and redundant operations\n- Avoid unnecessary print statements\n\n## Dependencies\n\nRequired dependencies (install if not available):\n\n- **pandoc**: `sudo apt-get install pandoc` (for text extraction)\n- **docx**: `npm install -g docx` (for creating new documents)\n- **LibreOffice**: `sudo apt-get install libreoffice` (for PDF conversion)\n- **Poppler**: `sudo apt-get install poppler-utils` (for pdftoppm to convert PDF to images)\n- **defusedxml**: `pip install defusedxml` (for secure XML parsing)",
        ".claude/skills/docx/docx-js.md": "# DOCX Library Tutorial\n\nGenerate .docx files with JavaScript/TypeScript.\n\n**Important: Read this entire document before starting.** Critical formatting rules and common pitfalls are covered throughout - skipping sections may result in corrupted files or rendering issues.\n\n## Setup\nAssumes docx is already installed globally\nIf not installed: `npm install -g docx`\n\n```javascript\nconst { Document, Packer, Paragraph, TextRun, Table, TableRow, TableCell, ImageRun, Media, \n        Header, Footer, AlignmentType, PageOrientation, LevelFormat, ExternalHyperlink, \n        InternalHyperlink, TableOfContents, HeadingLevel, BorderStyle, WidthType, TabStopType, \n        TabStopPosition, UnderlineType, ShadingType, VerticalAlign, SymbolRun, PageNumber,\n        FootnoteReferenceRun, Footnote, PageBreak } = require('docx');\n\n// Create & Save\nconst doc = new Document({ sections: [{ children: [/* content */] }] });\nPacker.toBuffer(doc).then(buffer => fs.writeFileSync(\"doc.docx\", buffer)); // Node.js\nPacker.toBlob(doc).then(blob => { /* download logic */ }); // Browser\n```\n\n## Text & Formatting\n```javascript\n// IMPORTANT: Never use \\n for line breaks - always use separate Paragraph elements\n//  WRONG: new TextRun(\"Line 1\\nLine 2\")\n//  CORRECT: new Paragraph({ children: [new TextRun(\"Line 1\")] }), new Paragraph({ children: [new TextRun(\"Line 2\")] })\n\n// Basic text with all formatting options\nnew Paragraph({\n  alignment: AlignmentType.CENTER,\n  spacing: { before: 200, after: 200 },\n  indent: { left: 720, right: 720 },\n  children: [\n    new TextRun({ text: \"Bold\", bold: true }),\n    new TextRun({ text: \"Italic\", italics: true }),\n    new TextRun({ text: \"Underlined\", underline: { type: UnderlineType.DOUBLE, color: \"FF0000\" } }),\n    new TextRun({ text: \"Colored\", color: \"FF0000\", size: 28, font: \"Arial\" }), // Arial default\n    new TextRun({ text: \"Highlighted\", highlight: \"yellow\" }),\n    new TextRun({ text: \"Strikethrough\", strike: true }),\n    new TextRun({ text: \"x2\", superScript: true }),\n    new TextRun({ text: \"H2O\", subScript: true }),\n    new TextRun({ text: \"SMALL CAPS\", smallCaps: true }),\n    new SymbolRun({ char: \"2022\", font: \"Symbol\" }), // Bullet \n    new SymbolRun({ char: \"00A9\", font: \"Arial\" })   // Copyright  - Arial for symbols\n  ]\n})\n```\n\n## Styles & Professional Formatting\n\n```javascript\nconst doc = new Document({\n  styles: {\n    default: { document: { run: { font: \"Arial\", size: 24 } } }, // 12pt default\n    paragraphStyles: [\n      // Document title style - override built-in Title style\n      { id: \"Title\", name: \"Title\", basedOn: \"Normal\",\n        run: { size: 56, bold: true, color: \"000000\", font: \"Arial\" },\n        paragraph: { spacing: { before: 240, after: 120 }, alignment: AlignmentType.CENTER } },\n      // IMPORTANT: Override built-in heading styles by using their exact IDs\n      { id: \"Heading1\", name: \"Heading 1\", basedOn: \"Normal\", next: \"Normal\", quickFormat: true,\n        run: { size: 32, bold: true, color: \"000000\", font: \"Arial\" }, // 16pt\n        paragraph: { spacing: { before: 240, after: 240 }, outlineLevel: 0 } }, // Required for TOC\n      { id: \"Heading2\", name: \"Heading 2\", basedOn: \"Normal\", next: \"Normal\", quickFormat: true,\n        run: { size: 28, bold: true, color: \"000000\", font: \"Arial\" }, // 14pt\n        paragraph: { spacing: { before: 180, after: 180 }, outlineLevel: 1 } },\n      // Custom styles use your own IDs\n      { id: \"myStyle\", name: \"My Style\", basedOn: \"Normal\",\n        run: { size: 28, bold: true, color: \"000000\" },\n        paragraph: { spacing: { after: 120 }, alignment: AlignmentType.CENTER } }\n    ],\n    characterStyles: [{ id: \"myCharStyle\", name: \"My Char Style\",\n      run: { color: \"FF0000\", bold: true, underline: { type: UnderlineType.SINGLE } } }]\n  },\n  sections: [{\n    properties: { page: { margin: { top: 1440, right: 1440, bottom: 1440, left: 1440 } } },\n    children: [\n      new Paragraph({ heading: HeadingLevel.TITLE, children: [new TextRun(\"Document Title\")] }), // Uses overridden Title style\n      new Paragraph({ heading: HeadingLevel.HEADING_1, children: [new TextRun(\"Heading 1\")] }), // Uses overridden Heading1 style\n      new Paragraph({ style: \"myStyle\", children: [new TextRun(\"Custom paragraph style\")] }),\n      new Paragraph({ children: [\n        new TextRun(\"Normal with \"),\n        new TextRun({ text: \"custom char style\", style: \"myCharStyle\" })\n      ]})\n    ]\n  }]\n});\n```\n\n**Professional Font Combinations:**\n- **Arial (Headers) + Arial (Body)** - Most universally supported, clean and professional\n- **Times New Roman (Headers) + Arial (Body)** - Classic serif headers with modern sans-serif body\n- **Georgia (Headers) + Verdana (Body)** - Optimized for screen reading, elegant contrast\n\n**Key Styling Principles:**\n- **Override built-in styles**: Use exact IDs like \"Heading1\", \"Heading2\", \"Heading3\" to override Word's built-in heading styles\n- **HeadingLevel constants**: `HeadingLevel.HEADING_1` uses \"Heading1\" style, `HeadingLevel.HEADING_2` uses \"Heading2\" style, etc.\n- **Include outlineLevel**: Set `outlineLevel: 0` for H1, `outlineLevel: 1` for H2, etc. to ensure TOC works correctly\n- **Use custom styles** instead of inline formatting for consistency\n- **Set a default font** using `styles.default.document.run.font` - Arial is universally supported\n- **Establish visual hierarchy** with different font sizes (titles > headers > body)\n- **Add proper spacing** with `before` and `after` paragraph spacing\n- **Use colors sparingly**: Default to black (000000) and shades of gray for titles and headings (heading 1, heading 2, etc.)\n- **Set consistent margins** (1440 = 1 inch is standard)\n\n\n## Lists (ALWAYS USE PROPER LISTS - NEVER USE UNICODE BULLETS)\n```javascript\n// Bullets - ALWAYS use the numbering config, NOT unicode symbols\n// CRITICAL: Use LevelFormat.BULLET constant, NOT the string \"bullet\"\nconst doc = new Document({\n  numbering: {\n    config: [\n      { reference: \"bullet-list\",\n        levels: [{ level: 0, format: LevelFormat.BULLET, text: \"\", alignment: AlignmentType.LEFT,\n          style: { paragraph: { indent: { left: 720, hanging: 360 } } } }] },\n      { reference: \"first-numbered-list\",\n        levels: [{ level: 0, format: LevelFormat.DECIMAL, text: \"%1.\", alignment: AlignmentType.LEFT,\n          style: { paragraph: { indent: { left: 720, hanging: 360 } } } }] },\n      { reference: \"second-numbered-list\", // Different reference = restarts at 1\n        levels: [{ level: 0, format: LevelFormat.DECIMAL, text: \"%1.\", alignment: AlignmentType.LEFT,\n          style: { paragraph: { indent: { left: 720, hanging: 360 } } } }] }\n    ]\n  },\n  sections: [{\n    children: [\n      // Bullet list items\n      new Paragraph({ numbering: { reference: \"bullet-list\", level: 0 },\n        children: [new TextRun(\"First bullet point\")] }),\n      new Paragraph({ numbering: { reference: \"bullet-list\", level: 0 },\n        children: [new TextRun(\"Second bullet point\")] }),\n      // Numbered list items\n      new Paragraph({ numbering: { reference: \"first-numbered-list\", level: 0 },\n        children: [new TextRun(\"First numbered item\")] }),\n      new Paragraph({ numbering: { reference: \"first-numbered-list\", level: 0 },\n        children: [new TextRun(\"Second numbered item\")] }),\n      //  CRITICAL: Different reference = INDEPENDENT list that restarts at 1\n      // Same reference = CONTINUES previous numbering\n      new Paragraph({ numbering: { reference: \"second-numbered-list\", level: 0 },\n        children: [new TextRun(\"Starts at 1 again (because different reference)\")] })\n    ]\n  }]\n});\n\n//  CRITICAL NUMBERING RULE: Each reference creates an INDEPENDENT numbered list\n// - Same reference = continues numbering (1, 2, 3... then 4, 5, 6...)\n// - Different reference = restarts at 1 (1, 2, 3... then 1, 2, 3...)\n// Use unique reference names for each separate numbered section!\n\n//  CRITICAL: NEVER use unicode bullets - they create fake lists that don't work properly\n// new TextRun(\" Item\")           // WRONG\n// new SymbolRun({ char: \"2022\" }) // WRONG\n//  ALWAYS use numbering config with LevelFormat.BULLET for real Word lists\n```\n\n## Tables\n```javascript\n// Complete table with margins, borders, headers, and bullet points\nconst tableBorder = { style: BorderStyle.SINGLE, size: 1, color: \"CCCCCC\" };\nconst cellBorders = { top: tableBorder, bottom: tableBorder, left: tableBorder, right: tableBorder };\n\nnew Table({\n  columnWidths: [4680, 4680], //  CRITICAL: Set column widths at table level - values in DXA (twentieths of a point)\n  margins: { top: 100, bottom: 100, left: 180, right: 180 }, // Set once for all cells\n  rows: [\n    new TableRow({\n      tableHeader: true,\n      children: [\n        new TableCell({\n          borders: cellBorders,\n          width: { size: 4680, type: WidthType.DXA }, // ALSO set width on each cell\n          //  CRITICAL: Always use ShadingType.CLEAR to prevent black backgrounds in Word.\n          shading: { fill: \"D5E8F0\", type: ShadingType.CLEAR }, \n          verticalAlign: VerticalAlign.CENTER,\n          children: [new Paragraph({ \n            alignment: AlignmentType.CENTER,\n            children: [new TextRun({ text: \"Header\", bold: true, size: 22 })]\n          })]\n        }),\n        new TableCell({\n          borders: cellBorders,\n          width: { size: 4680, type: WidthType.DXA }, // ALSO set width on each cell\n          shading: { fill: \"D5E8F0\", type: ShadingType.CLEAR },\n          children: [new Paragraph({ \n            alignment: AlignmentType.CENTER,\n            children: [new TextRun({ text: \"Bullet Points\", bold: true, size: 22 })]\n          })]\n        })\n      ]\n    }),\n    new TableRow({\n      children: [\n        new TableCell({\n          borders: cellBorders,\n          width: { size: 4680, type: WidthType.DXA }, // ALSO set width on each cell\n          children: [new Paragraph({ children: [new TextRun(\"Regular data\")] })]\n        }),\n        new TableCell({\n          borders: cellBorders,\n          width: { size: 4680, type: WidthType.DXA }, // ALSO set width on each cell\n          children: [\n            new Paragraph({ \n              numbering: { reference: \"bullet-list\", level: 0 },\n              children: [new TextRun(\"First bullet point\")] \n            }),\n            new Paragraph({ \n              numbering: { reference: \"bullet-list\", level: 0 },\n              children: [new TextRun(\"Second bullet point\")] \n            })\n          ]\n        })\n      ]\n    })\n  ]\n})\n```\n\n**IMPORTANT: Table Width & Borders**\n- Use BOTH `columnWidths: [width1, width2, ...]` array AND `width: { size: X, type: WidthType.DXA }` on each cell\n- Values in DXA (twentieths of a point): 1440 = 1 inch, Letter usable width = 9360 DXA (with 1\" margins)\n- Apply borders to individual `TableCell` elements, NOT the `Table` itself\n\n**Precomputed Column Widths (Letter size with 1\" margins = 9360 DXA total):**\n- **2 columns:** `columnWidths: [4680, 4680]` (equal width)\n- **3 columns:** `columnWidths: [3120, 3120, 3120]` (equal width)\n\n## Links & Navigation\n```javascript\n// TOC (requires headings) - CRITICAL: Use HeadingLevel only, NOT custom styles\n//  WRONG: new Paragraph({ heading: HeadingLevel.HEADING_1, style: \"customHeader\", children: [new TextRun(\"Title\")] })\n//  CORRECT: new Paragraph({ heading: HeadingLevel.HEADING_1, children: [new TextRun(\"Title\")] })\nnew TableOfContents(\"Table of Contents\", { hyperlink: true, headingStyleRange: \"1-3\" }),\n\n// External link\nnew Paragraph({\n  children: [new ExternalHyperlink({\n    children: [new TextRun({ text: \"Google\", style: \"Hyperlink\" })],\n    link: \"https://www.google.com\"\n  })]\n}),\n\n// Internal link & bookmark\nnew Paragraph({\n  children: [new InternalHyperlink({\n    children: [new TextRun({ text: \"Go to Section\", style: \"Hyperlink\" })],\n    anchor: \"section1\"\n  })]\n}),\nnew Paragraph({\n  children: [new TextRun(\"Section Content\")],\n  bookmark: { id: \"section1\", name: \"section1\" }\n}),\n```\n\n## Images & Media\n```javascript\n// Basic image with sizing & positioning\n// CRITICAL: Always specify 'type' parameter - it's REQUIRED for ImageRun\nnew Paragraph({\n  alignment: AlignmentType.CENTER,\n  children: [new ImageRun({\n    type: \"png\", // NEW REQUIREMENT: Must specify image type (png, jpg, jpeg, gif, bmp, svg)\n    data: fs.readFileSync(\"image.png\"),\n    transformation: { width: 200, height: 150, rotation: 0 }, // rotation in degrees\n    altText: { title: \"Logo\", description: \"Company logo\", name: \"Name\" } // IMPORTANT: All three fields are required\n  })]\n})\n```\n\n## Page Breaks\n```javascript\n// Manual page break\nnew Paragraph({ children: [new PageBreak()] }),\n\n// Page break before paragraph\nnew Paragraph({\n  pageBreakBefore: true,\n  children: [new TextRun(\"This starts on a new page\")]\n})\n\n//  CRITICAL: NEVER use PageBreak standalone - it will create invalid XML that Word cannot open\n//  WRONG: new PageBreak() \n//  CORRECT: new Paragraph({ children: [new PageBreak()] })\n```\n\n## Headers/Footers & Page Setup\n```javascript\nconst doc = new Document({\n  sections: [{\n    properties: {\n      page: {\n        margin: { top: 1440, right: 1440, bottom: 1440, left: 1440 }, // 1440 = 1 inch\n        size: { orientation: PageOrientation.LANDSCAPE },\n        pageNumbers: { start: 1, formatType: \"decimal\" } // \"upperRoman\", \"lowerRoman\", \"upperLetter\", \"lowerLetter\"\n      }\n    },\n    headers: {\n      default: new Header({ children: [new Paragraph({ \n        alignment: AlignmentType.RIGHT,\n        children: [new TextRun(\"Header Text\")]\n      })] })\n    },\n    footers: {\n      default: new Footer({ children: [new Paragraph({ \n        alignment: AlignmentType.CENTER,\n        children: [new TextRun(\"Page \"), new TextRun({ children: [PageNumber.CURRENT] }), new TextRun(\" of \"), new TextRun({ children: [PageNumber.TOTAL_PAGES] })]\n      })] })\n    },\n    children: [/* content */]\n  }]\n});\n```\n\n## Tabs\n```javascript\nnew Paragraph({\n  tabStops: [\n    { type: TabStopType.LEFT, position: TabStopPosition.MAX / 4 },\n    { type: TabStopType.CENTER, position: TabStopPosition.MAX / 2 },\n    { type: TabStopType.RIGHT, position: TabStopPosition.MAX * 3 / 4 }\n  ],\n  children: [new TextRun(\"Left\\tCenter\\tRight\")]\n})\n```\n\n## Constants & Quick Reference\n- **Underlines:** `SINGLE`, `DOUBLE`, `WAVY`, `DASH`\n- **Borders:** `SINGLE`, `DOUBLE`, `DASHED`, `DOTTED`  \n- **Numbering:** `DECIMAL` (1,2,3), `UPPER_ROMAN` (I,II,III), `LOWER_LETTER` (a,b,c)\n- **Tabs:** `LEFT`, `CENTER`, `RIGHT`, `DECIMAL`\n- **Symbols:** `\"2022\"` (), `\"00A9\"` (), `\"00AE\"` (), `\"2122\"` (), `\"00B0\"` (), `\"F070\"` (), `\"F0FC\"` ()\n\n## Critical Issues & Common Mistakes\n- **CRITICAL: PageBreak must ALWAYS be inside a Paragraph** - standalone PageBreak creates invalid XML that Word cannot open\n- **ALWAYS use ShadingType.CLEAR for table cell shading** - Never use ShadingType.SOLID (causes black background).\n- Measurements in DXA (1440 = 1 inch) | Each table cell needs 1 Paragraph | TOC requires HeadingLevel styles only\n- **ALWAYS use custom styles** with Arial font for professional appearance and proper visual hierarchy\n- **ALWAYS set a default font** using `styles.default.document.run.font` - Arial recommended\n- **ALWAYS use columnWidths array for tables** + individual cell widths for compatibility\n- **NEVER use unicode symbols for bullets** - always use proper numbering configuration with `LevelFormat.BULLET` constant (NOT the string \"bullet\")\n- **NEVER use \\n for line breaks anywhere** - always use separate Paragraph elements for each line\n- **ALWAYS use TextRun objects within Paragraph children** - never use text property directly on Paragraph\n- **CRITICAL for images**: ImageRun REQUIRES `type` parameter - always specify \"png\", \"jpg\", \"jpeg\", \"gif\", \"bmp\", or \"svg\"\n- **CRITICAL for bullets**: Must use `LevelFormat.BULLET` constant, not string \"bullet\", and include `text: \"\"` for the bullet character\n- **CRITICAL for numbering**: Each numbering reference creates an INDEPENDENT list. Same reference = continues numbering (1,2,3 then 4,5,6). Different reference = restarts at 1 (1,2,3 then 1,2,3). Use unique reference names for each separate numbered section!\n- **CRITICAL for TOC**: When using TableOfContents, headings must use HeadingLevel ONLY - do NOT add custom styles to heading paragraphs or TOC will break\n- **Tables**: Set `columnWidths` array + individual cell widths, apply borders to cells not table\n- **Set table margins at TABLE level** for consistent cell padding (avoids repetition per cell)",
        ".claude/skills/docx/ooxml.md": "# Office Open XML Technical Reference\n\n**Important: Read this entire document before starting.** This document covers:\n- [Technical Guidelines](#technical-guidelines) - Schema compliance rules and validation requirements\n- [Document Content Patterns](#document-content-patterns) - XML patterns for headings, lists, tables, formatting, etc.\n- [Document Library (Python)](#document-library-python) - Recommended approach for OOXML manipulation with automatic infrastructure setup\n- [Tracked Changes (Redlining)](#tracked-changes-redlining) - XML patterns for implementing tracked changes\n\n## Technical Guidelines\n\n### Schema Compliance\n- **Element ordering in `<w:pPr>`**: `<w:pStyle>`, `<w:numPr>`, `<w:spacing>`, `<w:ind>`, `<w:jc>`\n- **Whitespace**: Add `xml:space='preserve'` to `<w:t>` elements with leading/trailing spaces\n- **Unicode**: Escape characters in ASCII content: `\"` becomes `&#8220;`\n  - **Character encoding reference**: Curly quotes `\"\"` become `&#8220;&#8221;`, apostrophe `'` becomes `&#8217;`, em-dash `` becomes `&#8212;`\n- **Tracked changes**: Use `<w:del>` and `<w:ins>` tags with `w:author=\"Claude\"` outside `<w:r>` elements\n  - **Critical**: `<w:ins>` closes with `</w:ins>`, `<w:del>` closes with `</w:del>` - never mix\n  - **RSIDs must be 8-digit hex**: Use values like `00AB1234` (only 0-9, A-F characters)\n  - **trackRevisions placement**: Add `<w:trackRevisions/>` after `<w:proofState>` in settings.xml\n- **Images**: Add to `word/media/`, reference in `document.xml`, set dimensions to prevent overflow\n\n## Document Content Patterns\n\n### Basic Structure\n```xml\n<w:p>\n  <w:r><w:t>Text content</w:t></w:r>\n</w:p>\n```\n\n### Headings and Styles\n```xml\n<w:p>\n  <w:pPr>\n    <w:pStyle w:val=\"Title\"/>\n    <w:jc w:val=\"center\"/>\n  </w:pPr>\n  <w:r><w:t>Document Title</w:t></w:r>\n</w:p>\n\n<w:p>\n  <w:pPr><w:pStyle w:val=\"Heading2\"/></w:pPr>\n  <w:r><w:t>Section Heading</w:t></w:r>\n</w:p>\n```\n\n### Text Formatting\n```xml\n<!-- Bold -->\n<w:r><w:rPr><w:b/><w:bCs/></w:rPr><w:t>Bold</w:t></w:r>\n<!-- Italic -->\n<w:r><w:rPr><w:i/><w:iCs/></w:rPr><w:t>Italic</w:t></w:r>\n<!-- Underline -->\n<w:r><w:rPr><w:u w:val=\"single\"/></w:rPr><w:t>Underlined</w:t></w:r>\n<!-- Highlight -->\n<w:r><w:rPr><w:highlight w:val=\"yellow\"/></w:rPr><w:t>Highlighted</w:t></w:r>\n```\n\n### Lists\n```xml\n<!-- Numbered list -->\n<w:p>\n  <w:pPr>\n    <w:pStyle w:val=\"ListParagraph\"/>\n    <w:numPr><w:ilvl w:val=\"0\"/><w:numId w:val=\"1\"/></w:numPr>\n    <w:spacing w:before=\"240\"/>\n  </w:pPr>\n  <w:r><w:t>First item</w:t></w:r>\n</w:p>\n\n<!-- Restart numbered list at 1 - use different numId -->\n<w:p>\n  <w:pPr>\n    <w:pStyle w:val=\"ListParagraph\"/>\n    <w:numPr><w:ilvl w:val=\"0\"/><w:numId w:val=\"2\"/></w:numPr>\n    <w:spacing w:before=\"240\"/>\n  </w:pPr>\n  <w:r><w:t>New list item 1</w:t></w:r>\n</w:p>\n\n<!-- Bullet list (level 2) -->\n<w:p>\n  <w:pPr>\n    <w:pStyle w:val=\"ListParagraph\"/>\n    <w:numPr><w:ilvl w:val=\"1\"/><w:numId w:val=\"1\"/></w:numPr>\n    <w:spacing w:before=\"240\"/>\n    <w:ind w:left=\"900\"/>\n  </w:pPr>\n  <w:r><w:t>Bullet item</w:t></w:r>\n</w:p>\n```\n\n### Tables\n```xml\n<w:tbl>\n  <w:tblPr>\n    <w:tblStyle w:val=\"TableGrid\"/>\n    <w:tblW w:w=\"0\" w:type=\"auto\"/>\n  </w:tblPr>\n  <w:tblGrid>\n    <w:gridCol w:w=\"4675\"/><w:gridCol w:w=\"4675\"/>\n  </w:tblGrid>\n  <w:tr>\n    <w:tc>\n      <w:tcPr><w:tcW w:w=\"4675\" w:type=\"dxa\"/></w:tcPr>\n      <w:p><w:r><w:t>Cell 1</w:t></w:r></w:p>\n    </w:tc>\n    <w:tc>\n      <w:tcPr><w:tcW w:w=\"4675\" w:type=\"dxa\"/></w:tcPr>\n      <w:p><w:r><w:t>Cell 2</w:t></w:r></w:p>\n    </w:tc>\n  </w:tr>\n</w:tbl>\n```\n\n### Layout\n```xml\n<!-- Page break before new section (common pattern) -->\n<w:p>\n  <w:r>\n    <w:br w:type=\"page\"/>\n  </w:r>\n</w:p>\n<w:p>\n  <w:pPr>\n    <w:pStyle w:val=\"Heading1\"/>\n  </w:pPr>\n  <w:r>\n    <w:t>New Section Title</w:t>\n  </w:r>\n</w:p>\n\n<!-- Centered paragraph -->\n<w:p>\n  <w:pPr>\n    <w:spacing w:before=\"240\" w:after=\"0\"/>\n    <w:jc w:val=\"center\"/>\n  </w:pPr>\n  <w:r><w:t>Centered text</w:t></w:r>\n</w:p>\n\n<!-- Font change - paragraph level (applies to all runs) -->\n<w:p>\n  <w:pPr>\n    <w:rPr><w:rFonts w:ascii=\"Courier New\" w:hAnsi=\"Courier New\"/></w:rPr>\n  </w:pPr>\n  <w:r><w:t>Monospace text</w:t></w:r>\n</w:p>\n\n<!-- Font change - run level (specific to this text) -->\n<w:p>\n  <w:r>\n    <w:rPr><w:rFonts w:ascii=\"Courier New\" w:hAnsi=\"Courier New\"/></w:rPr>\n    <w:t>This text is Courier New</w:t>\n  </w:r>\n  <w:r><w:t> and this text uses default font</w:t></w:r>\n</w:p>\n```\n\n## File Updates\n\nWhen adding content, update these files:\n\n**`word/_rels/document.xml.rels`:**\n```xml\n<Relationship Id=\"rId1\" Type=\"http://schemas.openxmlformats.org/officeDocument/2006/relationships/numbering\" Target=\"numbering.xml\"/>\n<Relationship Id=\"rId5\" Type=\"http://schemas.openxmlformats.org/officeDocument/2006/relationships/image\" Target=\"media/image1.png\"/>\n```\n\n**`[Content_Types].xml`:**\n```xml\n<Default Extension=\"png\" ContentType=\"image/png\"/>\n<Override PartName=\"/word/numbering.xml\" ContentType=\"application/vnd.openxmlformats-officedocument.wordprocessingml.numbering+xml\"/>\n```\n\n### Images\n**CRITICAL**: Calculate dimensions to prevent page overflow and maintain aspect ratio.\n\n```xml\n<!-- Minimal required structure -->\n<w:p>\n  <w:r>\n    <w:drawing>\n      <wp:inline>\n        <wp:extent cx=\"2743200\" cy=\"1828800\"/>\n        <wp:docPr id=\"1\" name=\"Picture 1\"/>\n        <a:graphic xmlns:a=\"http://schemas.openxmlformats.org/drawingml/2006/main\">\n          <a:graphicData uri=\"http://schemas.openxmlformats.org/drawingml/2006/picture\">\n            <pic:pic xmlns:pic=\"http://schemas.openxmlformats.org/drawingml/2006/picture\">\n              <pic:nvPicPr>\n                <pic:cNvPr id=\"0\" name=\"image1.png\"/>\n                <pic:cNvPicPr/>\n              </pic:nvPicPr>\n              <pic:blipFill>\n                <a:blip r:embed=\"rId5\"/>\n                <!-- Add for stretch fill with aspect ratio preservation -->\n                <a:stretch>\n                  <a:fillRect/>\n                </a:stretch>\n              </pic:blipFill>\n              <pic:spPr>\n                <a:xfrm>\n                  <a:ext cx=\"2743200\" cy=\"1828800\"/>\n                </a:xfrm>\n                <a:prstGeom prst=\"rect\"/>\n              </pic:spPr>\n            </pic:pic>\n          </a:graphicData>\n        </a:graphic>\n      </wp:inline>\n    </w:drawing>\n  </w:r>\n</w:p>\n```\n\n### Links (Hyperlinks)\n\n**IMPORTANT**: All hyperlinks (both internal and external) require the Hyperlink style to be defined in styles.xml. Without this style, links will look like regular text instead of blue underlined clickable links.\n\n**External Links:**\n```xml\n<!-- In document.xml -->\n<w:hyperlink r:id=\"rId5\">\n  <w:r>\n    <w:rPr><w:rStyle w:val=\"Hyperlink\"/></w:rPr>\n    <w:t>Link Text</w:t>\n  </w:r>\n</w:hyperlink>\n\n<!-- In word/_rels/document.xml.rels -->\n<Relationship Id=\"rId5\" Type=\"http://schemas.openxmlformats.org/officeDocument/2006/relationships/hyperlink\" \n              Target=\"https://www.example.com/\" TargetMode=\"External\"/>\n```\n\n**Internal Links:**\n\n```xml\n<!-- Link to bookmark -->\n<w:hyperlink w:anchor=\"myBookmark\">\n  <w:r>\n    <w:rPr><w:rStyle w:val=\"Hyperlink\"/></w:rPr>\n    <w:t>Link Text</w:t>\n  </w:r>\n</w:hyperlink>\n\n<!-- Bookmark target -->\n<w:bookmarkStart w:id=\"0\" w:name=\"myBookmark\"/>\n<w:r><w:t>Target content</w:t></w:r>\n<w:bookmarkEnd w:id=\"0\"/>\n```\n\n**Hyperlink Style (required in styles.xml):**\n```xml\n<w:style w:type=\"character\" w:styleId=\"Hyperlink\">\n  <w:name w:val=\"Hyperlink\"/>\n  <w:basedOn w:val=\"DefaultParagraphFont\"/>\n  <w:uiPriority w:val=\"99\"/>\n  <w:unhideWhenUsed/>\n  <w:rPr>\n    <w:color w:val=\"467886\" w:themeColor=\"hyperlink\"/>\n    <w:u w:val=\"single\"/>\n  </w:rPr>\n</w:style>\n```\n\n## Document Library (Python)\n\nUse the Document class from `scripts/document.py` for all tracked changes and comments. It automatically handles infrastructure setup (people.xml, RSIDs, settings.xml, comment files, relationships, content types). Only use direct XML manipulation for complex scenarios not supported by the library.\n\n**Working with Unicode and Entities:**\n- **Searching**: Both entity notation and Unicode characters work - `contains=\"&#8220;Company\"` and `contains=\"\\u201cCompany\"` find the same text\n- **Replacing**: Use either entities (`&#8220;`) or Unicode (`\\u201c`) - both work and will be converted appropriately based on the file's encoding (ascii  entities, utf-8  Unicode)\n\n### Initialization\n\n**Find the docx skill root** (directory containing `scripts/` and `ooxml/`):\n```bash\n# Search for document.py to locate the skill root\n# Note: /mnt/skills is used here as an example; check your context for the actual location\nfind /mnt/skills -name \"document.py\" -path \"*/docx/scripts/*\" 2>/dev/null | head -1\n# Example output: /mnt/skills/docx/scripts/document.py\n# Skill root is: /mnt/skills/docx\n```\n\n**Run your script with PYTHONPATH** set to the docx skill root:\n```bash\nPYTHONPATH=/mnt/skills/docx python your_script.py\n```\n\n**In your script**, import from the skill root:\n```python\nfrom scripts.document import Document, DocxXMLEditor\n\n# Basic initialization (automatically creates temp copy and sets up infrastructure)\ndoc = Document('unpacked')\n\n# Customize author and initials\ndoc = Document('unpacked', author=\"John Doe\", initials=\"JD\")\n\n# Enable track revisions mode\ndoc = Document('unpacked', track_revisions=True)\n\n# Specify custom RSID (auto-generated if not provided)\ndoc = Document('unpacked', rsid=\"07DC5ECB\")\n```\n\n### Creating Tracked Changes\n\n**CRITICAL**: Only mark text that actually changes. Keep ALL unchanged text outside `<w:del>`/`<w:ins>` tags. Marking unchanged text makes edits unprofessional and harder to review.\n\n**Attribute Handling**: The Document class auto-injects attributes (w:id, w:date, w:rsidR, w:rsidDel, w16du:dateUtc, xml:space) into new elements. When preserving unchanged text from the original document, copy the original `<w:r>` element with its existing attributes to maintain document integrity.\n\n**Method Selection Guide**:\n- **Adding your own changes to regular text**: Use `replace_node()` with `<w:del>`/`<w:ins>` tags, or `suggest_deletion()` for removing entire `<w:r>` or `<w:p>` elements\n- **Partially modifying another author's tracked change**: Use `replace_node()` to nest your changes inside their `<w:ins>`/`<w:del>`\n- **Completely rejecting another author's insertion**: Use `revert_insertion()` on the `<w:ins>` element (NOT `suggest_deletion()`)\n- **Completely rejecting another author's deletion**: Use `revert_deletion()` on the `<w:del>` element to restore deleted content using tracked changes\n\n```python\n# Minimal edit - change one word: \"The report is monthly\"  \"The report is quarterly\"\n# Original: <w:r w:rsidR=\"00AB12CD\"><w:rPr><w:rFonts w:ascii=\"Calibri\"/></w:rPr><w:t>The report is monthly</w:t></w:r>\nnode = doc[\"word/document.xml\"].get_node(tag=\"w:r\", contains=\"The report is monthly\")\nrpr = tags[0].toxml() if (tags := node.getElementsByTagName(\"w:rPr\")) else \"\"\nreplacement = f'<w:r w:rsidR=\"00AB12CD\">{rpr}<w:t>The report is </w:t></w:r><w:del><w:r>{rpr}<w:delText>monthly</w:delText></w:r></w:del><w:ins><w:r>{rpr}<w:t>quarterly</w:t></w:r></w:ins>'\ndoc[\"word/document.xml\"].replace_node(node, replacement)\n\n# Minimal edit - change number: \"within 30 days\"  \"within 45 days\"\n# Original: <w:r w:rsidR=\"00XYZ789\"><w:rPr><w:rFonts w:ascii=\"Calibri\"/></w:rPr><w:t>within 30 days</w:t></w:r>\nnode = doc[\"word/document.xml\"].get_node(tag=\"w:r\", contains=\"within 30 days\")\nrpr = tags[0].toxml() if (tags := node.getElementsByTagName(\"w:rPr\")) else \"\"\nreplacement = f'<w:r w:rsidR=\"00XYZ789\">{rpr}<w:t>within </w:t></w:r><w:del><w:r>{rpr}<w:delText>30</w:delText></w:r></w:del><w:ins><w:r>{rpr}<w:t>45</w:t></w:r></w:ins><w:r w:rsidR=\"00XYZ789\">{rpr}<w:t> days</w:t></w:r>'\ndoc[\"word/document.xml\"].replace_node(node, replacement)\n\n# Complete replacement - preserve formatting even when replacing all text\nnode = doc[\"word/document.xml\"].get_node(tag=\"w:r\", contains=\"apple\")\nrpr = tags[0].toxml() if (tags := node.getElementsByTagName(\"w:rPr\")) else \"\"\nreplacement = f'<w:del><w:r>{rpr}<w:delText>apple</w:delText></w:r></w:del><w:ins><w:r>{rpr}<w:t>banana orange</w:t></w:r></w:ins>'\ndoc[\"word/document.xml\"].replace_node(node, replacement)\n\n# Insert new content (no attributes needed - auto-injected)\nnode = doc[\"word/document.xml\"].get_node(tag=\"w:r\", contains=\"existing text\")\ndoc[\"word/document.xml\"].insert_after(node, '<w:ins><w:r><w:t>new text</w:t></w:r></w:ins>')\n\n# Partially delete another author's insertion\n# Original: <w:ins w:author=\"Jane Smith\" w:date=\"...\"><w:r><w:t>quarterly financial report</w:t></w:r></w:ins>\n# Goal: Delete only \"financial\" to make it \"quarterly report\"\nnode = doc[\"word/document.xml\"].get_node(tag=\"w:ins\", attrs={\"w:id\": \"5\"})\n# IMPORTANT: Preserve w:author=\"Jane Smith\" on the outer <w:ins> to maintain authorship\nreplacement = '''<w:ins w:author=\"Jane Smith\" w:date=\"2025-01-15T10:00:00Z\">\n  <w:r><w:t>quarterly </w:t></w:r>\n  <w:del><w:r><w:delText>financial </w:delText></w:r></w:del>\n  <w:r><w:t>report</w:t></w:r>\n</w:ins>'''\ndoc[\"word/document.xml\"].replace_node(node, replacement)\n\n# Change part of another author's insertion\n# Original: <w:ins w:author=\"Jane Smith\"><w:r><w:t>in silence, safe and sound</w:t></w:r></w:ins>\n# Goal: Change \"safe and sound\" to \"soft and unbound\"\nnode = doc[\"word/document.xml\"].get_node(tag=\"w:ins\", attrs={\"w:id\": \"8\"})\nreplacement = f'''<w:ins w:author=\"Jane Smith\" w:date=\"2025-01-15T10:00:00Z\">\n  <w:r><w:t>in silence, </w:t></w:r>\n</w:ins>\n<w:ins>\n  <w:r><w:t>soft and unbound</w:t></w:r>\n</w:ins>\n<w:ins w:author=\"Jane Smith\" w:date=\"2025-01-15T10:00:00Z\">\n  <w:del><w:r><w:delText>safe and sound</w:delText></w:r></w:del>\n</w:ins>'''\ndoc[\"word/document.xml\"].replace_node(node, replacement)\n\n# Delete entire run (use only when deleting all content; use replace_node for partial deletions)\nnode = doc[\"word/document.xml\"].get_node(tag=\"w:r\", contains=\"text to delete\")\ndoc[\"word/document.xml\"].suggest_deletion(node)\n\n# Delete entire paragraph (in-place, handles both regular and numbered list paragraphs)\npara = doc[\"word/document.xml\"].get_node(tag=\"w:p\", contains=\"paragraph to delete\")\ndoc[\"word/document.xml\"].suggest_deletion(para)\n\n# Add new numbered list item\ntarget_para = doc[\"word/document.xml\"].get_node(tag=\"w:p\", contains=\"existing list item\")\npPr = tags[0].toxml() if (tags := target_para.getElementsByTagName(\"w:pPr\")) else \"\"\nnew_item = f'<w:p>{pPr}<w:r><w:t>New item</w:t></w:r></w:p>'\ntracked_para = DocxXMLEditor.suggest_paragraph(new_item)\ndoc[\"word/document.xml\"].insert_after(target_para, tracked_para)\n# Optional: add spacing paragraph before content for better visual separation\n# spacing = DocxXMLEditor.suggest_paragraph('<w:p><w:pPr><w:pStyle w:val=\"ListParagraph\"/></w:pPr></w:p>')\n# doc[\"word/document.xml\"].insert_after(target_para, spacing + tracked_para)\n```\n\n### Adding Comments\n\n```python\n# Add comment spanning two existing tracked changes\n# Note: w:id is auto-generated. Only search by w:id if you know it from XML inspection\nstart_node = doc[\"word/document.xml\"].get_node(tag=\"w:del\", attrs={\"w:id\": \"1\"})\nend_node = doc[\"word/document.xml\"].get_node(tag=\"w:ins\", attrs={\"w:id\": \"2\"})\ndoc.add_comment(start=start_node, end=end_node, text=\"Explanation of this change\")\n\n# Add comment on a paragraph\npara = doc[\"word/document.xml\"].get_node(tag=\"w:p\", contains=\"paragraph text\")\ndoc.add_comment(start=para, end=para, text=\"Comment on this paragraph\")\n\n# Add comment on newly created tracked change\n# First create the tracked change\nnode = doc[\"word/document.xml\"].get_node(tag=\"w:r\", contains=\"old\")\nnew_nodes = doc[\"word/document.xml\"].replace_node(\n    node,\n    '<w:del><w:r><w:delText>old</w:delText></w:r></w:del><w:ins><w:r><w:t>new</w:t></w:r></w:ins>'\n)\n# Then add comment on the newly created elements\n# new_nodes[0] is the <w:del>, new_nodes[1] is the <w:ins>\ndoc.add_comment(start=new_nodes[0], end=new_nodes[1], text=\"Changed old to new per requirements\")\n\n# Reply to existing comment\ndoc.reply_to_comment(parent_comment_id=0, text=\"I agree with this change\")\n```\n\n### Rejecting Tracked Changes\n\n**IMPORTANT**: Use `revert_insertion()` to reject insertions and `revert_deletion()` to restore deletions using tracked changes. Use `suggest_deletion()` only for regular unmarked content.\n\n```python\n# Reject insertion (wraps it in deletion)\n# Use this when another author inserted text that you want to delete\nins = doc[\"word/document.xml\"].get_node(tag=\"w:ins\", attrs={\"w:id\": \"5\"})\nnodes = doc[\"word/document.xml\"].revert_insertion(ins)  # Returns [ins]\n\n# Reject deletion (creates insertion to restore deleted content)\n# Use this when another author deleted text that you want to restore\ndel_elem = doc[\"word/document.xml\"].get_node(tag=\"w:del\", attrs={\"w:id\": \"3\"})\nnodes = doc[\"word/document.xml\"].revert_deletion(del_elem)  # Returns [del_elem, new_ins]\n\n# Reject all insertions in a paragraph\npara = doc[\"word/document.xml\"].get_node(tag=\"w:p\", contains=\"paragraph text\")\nnodes = doc[\"word/document.xml\"].revert_insertion(para)  # Returns [para]\n\n# Reject all deletions in a paragraph\npara = doc[\"word/document.xml\"].get_node(tag=\"w:p\", contains=\"paragraph text\")\nnodes = doc[\"word/document.xml\"].revert_deletion(para)  # Returns [para]\n```\n\n### Inserting Images\n\n**CRITICAL**: The Document class works with a temporary copy at `doc.unpacked_path`. Always copy images to this temp directory, not the original unpacked folder.\n\n```python\nfrom PIL import Image\nimport shutil, os\n\n# Initialize document first\ndoc = Document('unpacked')\n\n# Copy image and calculate full-width dimensions with aspect ratio\nmedia_dir = os.path.join(doc.unpacked_path, 'word/media')\nos.makedirs(media_dir, exist_ok=True)\nshutil.copy('image.png', os.path.join(media_dir, 'image1.png'))\nimg = Image.open(os.path.join(media_dir, 'image1.png'))\nwidth_emus = int(6.5 * 914400)  # 6.5\" usable width, 914400 EMUs/inch\nheight_emus = int(width_emus * img.size[1] / img.size[0])\n\n# Add relationship and content type\nrels_editor = doc['word/_rels/document.xml.rels']\nnext_rid = rels_editor.get_next_rid()\nrels_editor.append_to(rels_editor.dom.documentElement,\n    f'<Relationship Id=\"{next_rid}\" Type=\"http://schemas.openxmlformats.org/officeDocument/2006/relationships/image\" Target=\"media/image1.png\"/>')\ndoc['[Content_Types].xml'].append_to(doc['[Content_Types].xml'].dom.documentElement,\n    '<Default Extension=\"png\" ContentType=\"image/png\"/>')\n\n# Insert image\nnode = doc[\"word/document.xml\"].get_node(tag=\"w:p\", line_number=100)\ndoc[\"word/document.xml\"].insert_after(node, f'''<w:p>\n  <w:r>\n    <w:drawing>\n      <wp:inline distT=\"0\" distB=\"0\" distL=\"0\" distR=\"0\">\n        <wp:extent cx=\"{width_emus}\" cy=\"{height_emus}\"/>\n        <wp:docPr id=\"1\" name=\"Picture 1\"/>\n        <a:graphic xmlns:a=\"http://schemas.openxmlformats.org/drawingml/2006/main\">\n          <a:graphicData uri=\"http://schemas.openxmlformats.org/drawingml/2006/picture\">\n            <pic:pic xmlns:pic=\"http://schemas.openxmlformats.org/drawingml/2006/picture\">\n              <pic:nvPicPr><pic:cNvPr id=\"1\" name=\"image1.png\"/><pic:cNvPicPr/></pic:nvPicPr>\n              <pic:blipFill><a:blip r:embed=\"{next_rid}\"/><a:stretch><a:fillRect/></a:stretch></pic:blipFill>\n              <pic:spPr><a:xfrm><a:ext cx=\"{width_emus}\" cy=\"{height_emus}\"/></a:xfrm><a:prstGeom prst=\"rect\"><a:avLst/></a:prstGeom></pic:spPr>\n            </pic:pic>\n          </a:graphicData>\n        </a:graphic>\n      </wp:inline>\n    </w:drawing>\n  </w:r>\n</w:p>''')\n```\n\n### Getting Nodes\n\n```python\n# By text content\nnode = doc[\"word/document.xml\"].get_node(tag=\"w:p\", contains=\"specific text\")\n\n# By line range\npara = doc[\"word/document.xml\"].get_node(tag=\"w:p\", line_number=range(100, 150))\n\n# By attributes\nnode = doc[\"word/document.xml\"].get_node(tag=\"w:del\", attrs={\"w:id\": \"1\"})\n\n# By exact line number (must be line number where tag opens)\npara = doc[\"word/document.xml\"].get_node(tag=\"w:p\", line_number=42)\n\n# Combine filters\nnode = doc[\"word/document.xml\"].get_node(tag=\"w:r\", line_number=range(40, 60), contains=\"text\")\n\n# Disambiguate when text appears multiple times - add line_number range\nnode = doc[\"word/document.xml\"].get_node(tag=\"w:r\", contains=\"Section\", line_number=range(2400, 2500))\n```\n\n### Saving\n\n```python\n# Save with automatic validation (copies back to original directory)\ndoc.save()  # Validates by default, raises error if validation fails\n\n# Save to different location\ndoc.save('modified-unpacked')\n\n# Skip validation (debugging only - needing this in production indicates XML issues)\ndoc.save(validate=False)\n```\n\n### Direct DOM Manipulation\n\nFor complex scenarios not covered by the library:\n\n```python\n# Access any XML file\neditor = doc[\"word/document.xml\"]\neditor = doc[\"word/comments.xml\"]\n\n# Direct DOM access (defusedxml.minidom.Document)\nnode = doc[\"word/document.xml\"].get_node(tag=\"w:p\", line_number=5)\nparent = node.parentNode\nparent.removeChild(node)\nparent.appendChild(node)  # Move to end\n\n# General document manipulation (without tracked changes)\nold_node = doc[\"word/document.xml\"].get_node(tag=\"w:p\", contains=\"original text\")\ndoc[\"word/document.xml\"].replace_node(old_node, \"<w:p><w:r><w:t>replacement text</w:t></w:r></w:p>\")\n\n# Multiple insertions - use return value to maintain order\nnode = doc[\"word/document.xml\"].get_node(tag=\"w:r\", line_number=100)\nnodes = doc[\"word/document.xml\"].insert_after(node, \"<w:r><w:t>A</w:t></w:r>\")\nnodes = doc[\"word/document.xml\"].insert_after(nodes[-1], \"<w:r><w:t>B</w:t></w:r>\")\nnodes = doc[\"word/document.xml\"].insert_after(nodes[-1], \"<w:r><w:t>C</w:t></w:r>\")\n# Results in: original_node, A, B, C\n```\n\n## Tracked Changes (Redlining)\n\n**Use the Document class above for all tracked changes.** The patterns below are for reference when constructing replacement XML strings.\n\n### Validation Rules\nThe validator checks that the document text matches the original after reverting Claude's changes. This means:\n- **NEVER modify text inside another author's `<w:ins>` or `<w:del>` tags**\n- **ALWAYS use nested deletions** to remove another author's insertions\n- **Every edit must be properly tracked** with `<w:ins>` or `<w:del>` tags\n\n### Tracked Change Patterns\n\n**CRITICAL RULES**:\n1. Never modify the content inside another author's tracked changes. Always use nested deletions.\n2. **XML Structure**: Always place `<w:del>` and `<w:ins>` at paragraph level containing complete `<w:r>` elements. Never nest inside `<w:r>` elements - this creates invalid XML that breaks document processing.\n\n**Text Insertion:**\n```xml\n<w:ins w:id=\"1\" w:author=\"Claude\" w:date=\"2025-07-30T23:05:00Z\" w16du:dateUtc=\"2025-07-31T06:05:00Z\">\n  <w:r w:rsidR=\"00792858\">\n    <w:t>inserted text</w:t>\n  </w:r>\n</w:ins>\n```\n\n**Text Deletion:**\n```xml\n<w:del w:id=\"2\" w:author=\"Claude\" w:date=\"2025-07-30T23:05:00Z\" w16du:dateUtc=\"2025-07-31T06:05:00Z\">\n  <w:r w:rsidDel=\"00792858\">\n    <w:delText>deleted text</w:delText>\n  </w:r>\n</w:del>\n```\n\n**Deleting Another Author's Insertion (MUST use nested structure):**\n```xml\n<!-- Nest deletion inside the original insertion -->\n<w:ins w:author=\"Jane Smith\" w:id=\"16\">\n  <w:del w:author=\"Claude\" w:id=\"40\">\n    <w:r><w:delText>monthly</w:delText></w:r>\n  </w:del>\n</w:ins>\n<w:ins w:author=\"Claude\" w:id=\"41\">\n  <w:r><w:t>weekly</w:t></w:r>\n</w:ins>\n```\n\n**Restoring Another Author's Deletion:**\n```xml\n<!-- Leave their deletion unchanged, add new insertion after it -->\n<w:del w:author=\"Jane Smith\" w:id=\"50\">\n  <w:r><w:delText>within 30 days</w:delText></w:r>\n</w:del>\n<w:ins w:author=\"Claude\" w:id=\"51\">\n  <w:r><w:t>within 30 days</w:t></w:r>\n</w:ins>\n```",
        ".claude/skills/frontend-design/SKILL.md": "---\nname: frontend-design\ndescription: Create distinctive, production-grade frontend interfaces with high design quality. Use this skill when the user asks to build web components, pages, artifacts, posters, or applications (examples include websites, landing pages, dashboards, React components, HTML/CSS layouts, or when styling/beautifying any web UI). Generates creative, polished code and UI design that avoids generic AI aesthetics.\nlicense: Complete terms in LICENSE.txt\n---\n\nThis skill guides creation of distinctive, production-grade frontend interfaces that avoid generic \"AI slop\" aesthetics. Implement real working code with exceptional attention to aesthetic details and creative choices.\n\nThe user provides frontend requirements: a component, page, application, or interface to build. They may include context about the purpose, audience, or technical constraints.\n\n## Design Thinking\n\nBefore coding, understand the context and commit to a BOLD aesthetic direction:\n- **Purpose**: What problem does this interface solve? Who uses it?\n- **Tone**: Pick an extreme: brutally minimal, maximalist chaos, retro-futuristic, organic/natural, luxury/refined, playful/toy-like, editorial/magazine, brutalist/raw, art deco/geometric, soft/pastel, industrial/utilitarian, etc. There are so many flavors to choose from. Use these for inspiration but design one that is true to the aesthetic direction.\n- **Constraints**: Technical requirements (framework, performance, accessibility).\n- **Differentiation**: What makes this UNFORGETTABLE? What's the one thing someone will remember?\n\n**CRITICAL**: Choose a clear conceptual direction and execute it with precision. Bold maximalism and refined minimalism both work - the key is intentionality, not intensity.\n\nThen implement working code (HTML/CSS/JS, React, Vue, etc.) that is:\n- Production-grade and functional\n- Visually striking and memorable\n- Cohesive with a clear aesthetic point-of-view\n- Meticulously refined in every detail\n\n## Frontend Aesthetics Guidelines\n\nFocus on:\n- **Typography**: Choose fonts that are beautiful, unique, and interesting. Avoid generic fonts like Arial and Inter; opt instead for distinctive choices that elevate the frontend's aesthetics; unexpected, characterful font choices. Pair a distinctive display font with a refined body font.\n- **Color & Theme**: Commit to a cohesive aesthetic. Use CSS variables for consistency. Dominant colors with sharp accents outperform timid, evenly-distributed palettes.\n- **Motion**: Use animations for effects and micro-interactions. Prioritize CSS-only solutions for HTML. Use Motion library for React when available. Focus on high-impact moments: one well-orchestrated page load with staggered reveals (animation-delay) creates more delight than scattered micro-interactions. Use scroll-triggering and hover states that surprise.\n- **Spatial Composition**: Unexpected layouts. Asymmetry. Overlap. Diagonal flow. Grid-breaking elements. Generous negative space OR controlled density.\n- **Backgrounds & Visual Details**: Create atmosphere and depth rather than defaulting to solid colors. Add contextual effects and textures that match the overall aesthetic. Apply creative forms like gradient meshes, noise textures, geometric patterns, layered transparencies, dramatic shadows, decorative borders, custom cursors, and grain overlays.\n\nNEVER use generic AI-generated aesthetics like overused font families (Inter, Roboto, Arial, system fonts), cliched color schemes (particularly purple gradients on white backgrounds), predictable layouts and component patterns, and cookie-cutter design that lacks context-specific character.\n\nInterpret creatively and make unexpected choices that feel genuinely designed for the context. No design should be the same. Vary between light and dark themes, different fonts, different aesthetics. NEVER converge on common choices (Space Grotesk, for example) across generations.\n\n**IMPORTANT**: Match implementation complexity to the aesthetic vision. Maximalist designs need elaborate code with extensive animations and effects. Minimalist or refined designs need restraint, precision, and careful attention to spacing, typography, and subtle details. Elegance comes from executing the vision well.\n\nRemember: Claude is capable of extraordinary creative work. Don't hold back, show what can truly be created when thinking outside the box and committing fully to a distinctive vision.\n",
        ".claude/skills/internal-comms/SKILL.md": "---\nname: internal-comms\ndescription: A set of resources to help me write all kinds of internal communications, using the formats that my company likes to use. Claude should use this skill whenever asked to write some sort of internal communications (status reports, leadership updates, 3P updates, company newsletters, FAQs, incident reports, project updates, etc.).\nlicense: Complete terms in LICENSE.txt\n---\n\n## When to use this skill\nTo write internal communications, use this skill for:\n- 3P updates (Progress, Plans, Problems)\n- Company newsletters\n- FAQ responses\n- Status reports\n- Leadership updates\n- Project updates\n- Incident reports\n\n## How to use this skill\n\nTo write any internal communication:\n\n1. **Identify the communication type** from the request\n2. **Load the appropriate guideline file** from the `examples/` directory:\n    - `examples/3p-updates.md` - For Progress/Plans/Problems team updates\n    - `examples/company-newsletter.md` - For company-wide newsletters\n    - `examples/faq-answers.md` - For answering frequently asked questions\n    - `examples/general-comms.md` - For anything else that doesn't explicitly match one of the above\n3. **Follow the specific instructions** in that file for formatting, tone, and content gathering\n\nIf the communication type doesn't match any existing guideline, ask for clarification or more context about the desired format.\n\n## Keywords\n3P updates, company newsletter, company comms, weekly update, faqs, common questions, updates, internal comms\n",
        ".claude/skills/internal-comms/examples/3p-updates.md": "## Instructions\nYou are being asked to write a 3P update. 3P updates stand for \"Progress, Plans, Problems.\" The main audience is for executives, leadership, other teammates, etc. They're meant to be very succinct and to-the-point: think something you can read in 30-60sec or less. They're also for people with some, but not a lot of context on what the team does.\n\n3Ps can cover a team of any size, ranging all the way up to the entire company. The bigger the team, the less granular the tasks should be. For example, \"mobile team\" might have \"shipped feature\" or \"fixed bugs,\" whereas the company might have really meaty 3Ps, like \"hired 20 new people\" or \"closed 10 new deals.\" \n\nThey represent the work of the team across a time period, almost always one week. They include three sections:\n1) Progress: what the team has accomplished over the next time period. Focus mainly on things shipped, milestones achieved, tasks created, etc.\n2) Plans: what the team plans to do over the next time period. Focus on what things are top-of-mind, really high priority, etc. for the team.\n3) Problems: anything that is slowing the team down. This could be things like too few people, bugs or blockers that are preventing the team from moving forward, some deal that fell through, etc.\n\nBefore writing them, make sure that you know the team name. If it's not specified, you can ask explicitly what the team name you're writing for is.\n\n\n## Tools Available\nWhenever possible, try to pull from available sources to get the information you need:\n- Slack: posts from team members with their updates - ideally look for posts in large channels with lots of reactions\n- Google Drive: docs written from critical team members with lots of views\n- Email: emails with lots of responses of lots of content that seems relevant\n- Calendar: non-recurring meetings that have a lot of importance, like product reviews, etc.\n\n\nTry to gather as much context as you can, focusing on the things that covered the time period you're writing for:\n- Progress: anything between a week ago and today\n- Plans: anything from today to the next week\n- Problems: anything between a week ago and today\n\n\nIf you don't have access, you can ask the user for things they want to cover. They might also include these things to you directly, in which case you're mostly just formatting for this particular format.\n\n## Workflow\n\n1. **Clarify scope**: Confirm the team name and time period (usually past week for Progress/Problems, next\nweek for Plans)\n2. **Gather information**: Use available tools or ask the user directly\n3. **Draft the update**: Follow the strict formatting guidelines\n4. **Review**: Ensure it's concise (30-60 seconds to read) and data-driven\n\n## Formatting\n\nThe format is always the same, very strict formatting. Never use any formatting other than this. Pick an emoji that is fun and captures the vibe of the team and update.\n\n[pick an emoji] [Team Name] (Dates Covered, usually a week)\nProgress: [1-3 sentences of content]\nPlans: [1-3 sentences of content]\nProblems: [1-3 sentences of content]\n\nEach section should be no more than 1-3 sentences: clear, to the point. It should be data-driven, and generally include metrics where possible. The tone should be very matter-of-fact, not super prose-heavy.",
        ".claude/skills/internal-comms/examples/company-newsletter.md": "## Instructions\nYou are being asked to write a company-wide newsletter update. You are meant to summarize the past week/month of a company in the form of a newsletter that the entire company will read. It should be maybe ~20-25 bullet points long. It will be sent via Slack and email, so make it consumable for that.\n\nIdeally it includes the following attributes:\n- Lots of links: pulling documents from Google Drive that are very relevant, linking to prominent Slack messages in announce channels and from executives, perhgaps referencing emails that went company-wide, highlighting significant things that have happened in the company.\n- Short and to-the-point: each bullet should probably be no longer than ~1-2 sentences\n- Use the \"we\" tense, as you are part of the company. Many of the bullets should say \"we did this\" or \"we did that\"\n\n## Tools to use\nIf you have access to the following tools, please try to use them. If not, you can also let the user know directly that their responses would be better if they gave them access.\n\n- Slack: look for messages in channels with lots of people, with lots of reactions or lots of responses within the thread\n- Email: look for things from executives that discuss company-wide announcements\n- Calendar: if there were meetings with large attendee lists, particularly things like All-Hands meetings, big company announcements, etc. If there were documents attached to those meetings, those are great links to include.\n- Documents: if there were new docs published in the last week or two that got a lot of attention, you can link them. These should be things like company-wide vision docs, plans for the upcoming quarter or half, things authored by critical executives, etc.\n- External press: if you see references to articles or press we've received over the past week, that could be really cool too.\n\nIf you don't have access to any of these things, you can ask the user for things they want to cover. In this case, you'll mostly just be polishing up and fitting to this format more directly.\n\n## Sections\nThe company is pretty big: 1000+ people. There are a variety of different teams and initiatives going on across the company. To make sure the update works well, try breaking it into sections of similar things. You might break into clusters like {product development, go to market, finance} or {recruiting, execution, vision}, or {external news, internal news} etc. Try to make sure the different areas of the company are highlighted well.\n\n## Prioritization\nFocus on:\n- Company-wide impact (not team-specific details)\n- Announcements from leadership\n- Major milestones and achievements\n- Information that affects most employees\n- External recognition or press\n\nAvoid:\n- Overly granular team updates (save those for 3Ps)\n- Information only relevant to small groups\n- Duplicate information already communicated\n\n## Example Formats\n\n:megaphone: Company Announcements\n- Announcement 1\n- Announcement 2\n- Announcement 3\n\n:dart: Progress on Priorities\n- Area 1\n    - Sub-area 1\n    - Sub-area 2\n    - Sub-area 3\n- Area 2\n    - Sub-area 1\n    - Sub-area 2\n    - Sub-area 3\n- Area 3\n    - Sub-area 1\n    - Sub-area 2\n    - Sub-area 3\n\n:pillar: Leadership Updates\n- Post 1\n- Post 2\n- Post 3\n\n:thread: Social Updates\n- Update 1\n- Update 2\n- Update 3\n",
        ".claude/skills/internal-comms/examples/faq-answers.md": "## Instructions\nYou are an assistant for answering questions that are being asked across the company. Every week, there are lots of questions that get asked across the company, and your goal is to try to summarize what those questions are. We want our company to be well-informed and on the same page, so your job is to produce a set of frequently asked questions that our employees are asking and attempt to answer them. Your singular job is to do two things:\n\n- Find questions that are big sources of confusion for lots of employees at the company, generally about things that affect a large portion of the employee base\n- Attempt to give a nice summarized answer to that question in order to minimize confusion.\n\nSome examples of areas that may be interesting to folks: recent corporate events (fundraising, new executives, etc.), upcoming launches, hiring progress, changes to vision or focus, etc.\n\n\n## Tools Available\nYou should use the company's available tools, where communication and work happens. For most companies, it looks something like this:\n- Slack: questions being asked across the company - it could be questions in response to posts with lots of responses, questions being asked with lots of reactions or thumbs up to show support, or anything else to show that a large number of employees want to ask the same things\n- Email: emails with FAQs written directly in them can be a good source as well\n- Documents: docs in places like Google Drive, linked on calendar events, etc. can also be a good source of FAQs, either directly added or inferred based on the contents of the doc\n\n## Formatting\nThe formatting should be pretty basic:\n\n- *Question*: [insert question - 1 sentence]\n- *Answer*: [insert answer - 1-2 sentence]\n\n## Guidance\nMake sure you're being holistic in your questions. Don't focus too much on just the user in question or the team they are a part of, but try to capture the entire company. Try to be as holistic as you can in reading all the tools available, producing responses that are relevant to all at the company.\n\n## Answer Guidelines\n- Base answers on official company communications when possible\n- If information is uncertain, indicate that clearly\n- Link to authoritative sources (docs, announcements, emails)\n- Keep tone professional but approachable\n- Flag if a question requires executive input or official response",
        ".claude/skills/internal-comms/examples/general-comms.md": "  ## Instructions\n  You are being asked to write internal company communication that doesn't fit into the standard formats (3P\n  updates, newsletters, or FAQs).\n\n  Before proceeding:\n  1. Ask the user about their target audience\n  2. Understand the communication's purpose\n  3. Clarify the desired tone (formal, casual, urgent, informational)\n  4. Confirm any specific formatting requirements\n\n  Use these general principles:\n  - Be clear and concise\n  - Use active voice\n  - Put the most important information first\n  - Include relevant links and references\n  - Match the company's communication style",
        ".claude/skills/mcp-builder/SKILL.md": "---\nname: mcp-builder\ndescription: Guide for creating high-quality MCP (Model Context Protocol) servers that enable LLMs to interact with external services through well-designed tools. Use when building MCP servers to integrate external APIs or services, whether in Python (FastMCP) or Node/TypeScript (MCP SDK).\nlicense: Complete terms in LICENSE.txt\n---\n\n# MCP Server Development Guide\n\n## Overview\n\nCreate MCP (Model Context Protocol) servers that enable LLMs to interact with external services through well-designed tools. The quality of an MCP server is measured by how well it enables LLMs to accomplish real-world tasks.\n\n---\n\n# Process\n\n##  High-Level Workflow\n\nCreating a high-quality MCP server involves four main phases:\n\n### Phase 1: Deep Research and Planning\n\n#### 1.1 Understand Modern MCP Design\n\n**API Coverage vs. Workflow Tools:**\nBalance comprehensive API endpoint coverage with specialized workflow tools. Workflow tools can be more convenient for specific tasks, while comprehensive coverage gives agents flexibility to compose operations. Performance varies by clientsome clients benefit from code execution that combines basic tools, while others work better with higher-level workflows. When uncertain, prioritize comprehensive API coverage.\n\n**Tool Naming and Discoverability:**\nClear, descriptive tool names help agents find the right tools quickly. Use consistent prefixes (e.g., `github_create_issue`, `github_list_repos`) and action-oriented naming.\n\n**Context Management:**\nAgents benefit from concise tool descriptions and the ability to filter/paginate results. Design tools that return focused, relevant data. Some clients support code execution which can help agents filter and process data efficiently.\n\n**Actionable Error Messages:**\nError messages should guide agents toward solutions with specific suggestions and next steps.\n\n#### 1.2 Study MCP Protocol Documentation\n\n**Navigate the MCP specification:**\n\nStart with the sitemap to find relevant pages: `https://modelcontextprotocol.io/sitemap.xml`\n\nThen fetch specific pages with `.md` suffix for markdown format (e.g., `https://modelcontextprotocol.io/specification/draft.md`).\n\nKey pages to review:\n- Specification overview and architecture\n- Transport mechanisms (streamable HTTP, stdio)\n- Tool, resource, and prompt definitions\n\n#### 1.3 Study Framework Documentation\n\n**Recommended stack:**\n- **Language**: TypeScript (high-quality SDK support and good compatibility in many execution environments e.g. MCPB. Plus AI models are good at generating TypeScript code, benefiting from its broad usage, static typing and good linting tools)\n- **Transport**: Streamable HTTP for remote servers, using stateless JSON (simpler to scale and maintain, as opposed to stateful sessions and streaming responses). stdio for local servers.\n\n**Load framework documentation:**\n\n- **MCP Best Practices**: [ View Best Practices](./reference/mcp_best_practices.md) - Core guidelines\n\n**For TypeScript (recommended):**\n- **TypeScript SDK**: Use WebFetch to load `https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/README.md`\n- [ TypeScript Guide](./reference/node_mcp_server.md) - TypeScript patterns and examples\n\n**For Python:**\n- **Python SDK**: Use WebFetch to load `https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/README.md`\n- [ Python Guide](./reference/python_mcp_server.md) - Python patterns and examples\n\n#### 1.4 Plan Your Implementation\n\n**Understand the API:**\nReview the service's API documentation to identify key endpoints, authentication requirements, and data models. Use web search and WebFetch as needed.\n\n**Tool Selection:**\nPrioritize comprehensive API coverage. List endpoints to implement, starting with the most common operations.\n\n---\n\n### Phase 2: Implementation\n\n#### 2.1 Set Up Project Structure\n\nSee language-specific guides for project setup:\n- [ TypeScript Guide](./reference/node_mcp_server.md) - Project structure, package.json, tsconfig.json\n- [ Python Guide](./reference/python_mcp_server.md) - Module organization, dependencies\n\n#### 2.2 Implement Core Infrastructure\n\nCreate shared utilities:\n- API client with authentication\n- Error handling helpers\n- Response formatting (JSON/Markdown)\n- Pagination support\n\n#### 2.3 Implement Tools\n\nFor each tool:\n\n**Input Schema:**\n- Use Zod (TypeScript) or Pydantic (Python)\n- Include constraints and clear descriptions\n- Add examples in field descriptions\n\n**Output Schema:**\n- Define `outputSchema` where possible for structured data\n- Use `structuredContent` in tool responses (TypeScript SDK feature)\n- Helps clients understand and process tool outputs\n\n**Tool Description:**\n- Concise summary of functionality\n- Parameter descriptions\n- Return type schema\n\n**Implementation:**\n- Async/await for I/O operations\n- Proper error handling with actionable messages\n- Support pagination where applicable\n- Return both text content and structured data when using modern SDKs\n\n**Annotations:**\n- `readOnlyHint`: true/false\n- `destructiveHint`: true/false\n- `idempotentHint`: true/false\n- `openWorldHint`: true/false\n\n---\n\n### Phase 3: Review and Test\n\n#### 3.1 Code Quality\n\nReview for:\n- No duplicated code (DRY principle)\n- Consistent error handling\n- Full type coverage\n- Clear tool descriptions\n\n#### 3.2 Build and Test\n\n**TypeScript:**\n- Run `npm run build` to verify compilation\n- Test with MCP Inspector: `npx @modelcontextprotocol/inspector`\n\n**Python:**\n- Verify syntax: `python -m py_compile your_server.py`\n- Test with MCP Inspector\n\nSee language-specific guides for detailed testing approaches and quality checklists.\n\n---\n\n### Phase 4: Create Evaluations\n\nAfter implementing your MCP server, create comprehensive evaluations to test its effectiveness.\n\n**Load [ Evaluation Guide](./reference/evaluation.md) for complete evaluation guidelines.**\n\n#### 4.1 Understand Evaluation Purpose\n\nUse evaluations to test whether LLMs can effectively use your MCP server to answer realistic, complex questions.\n\n#### 4.2 Create 10 Evaluation Questions\n\nTo create effective evaluations, follow the process outlined in the evaluation guide:\n\n1. **Tool Inspection**: List available tools and understand their capabilities\n2. **Content Exploration**: Use READ-ONLY operations to explore available data\n3. **Question Generation**: Create 10 complex, realistic questions\n4. **Answer Verification**: Solve each question yourself to verify answers\n\n#### 4.3 Evaluation Requirements\n\nEnsure each question is:\n- **Independent**: Not dependent on other questions\n- **Read-only**: Only non-destructive operations required\n- **Complex**: Requiring multiple tool calls and deep exploration\n- **Realistic**: Based on real use cases humans would care about\n- **Verifiable**: Single, clear answer that can be verified by string comparison\n- **Stable**: Answer won't change over time\n\n#### 4.4 Output Format\n\nCreate an XML file with this structure:\n\n```xml\n<evaluation>\n  <qa_pair>\n    <question>Find discussions about AI model launches with animal codenames. One model needed a specific safety designation that uses the format ASL-X. What number X was being determined for the model named after a spotted wild cat?</question>\n    <answer>3</answer>\n  </qa_pair>\n<!-- More qa_pairs... -->\n</evaluation>\n```\n\n---\n\n# Reference Files\n\n##  Documentation Library\n\nLoad these resources as needed during development:\n\n### Core MCP Documentation (Load First)\n- **MCP Protocol**: Start with sitemap at `https://modelcontextprotocol.io/sitemap.xml`, then fetch specific pages with `.md` suffix\n- [ MCP Best Practices](./reference/mcp_best_practices.md) - Universal MCP guidelines including:\n  - Server and tool naming conventions\n  - Response format guidelines (JSON vs Markdown)\n  - Pagination best practices\n  - Transport selection (streamable HTTP vs stdio)\n  - Security and error handling standards\n\n### SDK Documentation (Load During Phase 1/2)\n- **Python SDK**: Fetch from `https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/README.md`\n- **TypeScript SDK**: Fetch from `https://raw.githubusercontent.com/modelcontextprotocol/typescript-sdk/main/README.md`\n\n### Language-Specific Implementation Guides (Load During Phase 2)\n- [ Python Implementation Guide](./reference/python_mcp_server.md) - Complete Python/FastMCP guide with:\n  - Server initialization patterns\n  - Pydantic model examples\n  - Tool registration with `@mcp.tool`\n  - Complete working examples\n  - Quality checklist\n\n- [ TypeScript Implementation Guide](./reference/node_mcp_server.md) - Complete TypeScript guide with:\n  - Project structure\n  - Zod schema patterns\n  - Tool registration with `server.registerTool`\n  - Complete working examples\n  - Quality checklist\n\n### Evaluation Guide (Load During Phase 4)\n- [ Evaluation Guide](./reference/evaluation.md) - Complete evaluation creation guide with:\n  - Question creation guidelines\n  - Answer verification strategies\n  - XML format specifications\n  - Example questions and answers\n  - Running an evaluation with the provided scripts\n",
        ".claude/skills/mcp-builder/reference/evaluation.md": "# MCP Server Evaluation Guide\n\n## Overview\n\nThis document provides guidance on creating comprehensive evaluations for MCP servers. Evaluations test whether LLMs can effectively use your MCP server to answer realistic, complex questions using only the tools provided.\n\n---\n\n## Quick Reference\n\n### Evaluation Requirements\n- Create 10 human-readable questions\n- Questions must be READ-ONLY, INDEPENDENT, NON-DESTRUCTIVE\n- Each question requires multiple tool calls (potentially dozens)\n- Answers must be single, verifiable values\n- Answers must be STABLE (won't change over time)\n\n### Output Format\n```xml\n<evaluation>\n   <qa_pair>\n      <question>Your question here</question>\n      <answer>Single verifiable answer</answer>\n   </qa_pair>\n</evaluation>\n```\n\n---\n\n## Purpose of Evaluations\n\nThe measure of quality of an MCP server is NOT how well or comprehensively the server implements tools, but how well these implementations (input/output schemas, docstrings/descriptions, functionality) enable LLMs with no other context and access ONLY to the MCP servers to answer realistic and difficult questions.\n\n## Evaluation Overview\n\nCreate 10 human-readable questions requiring ONLY READ-ONLY, INDEPENDENT, NON-DESTRUCTIVE, and IDEMPOTENT operations to answer. Each question should be:\n- Realistic\n- Clear and concise\n- Unambiguous\n- Complex, requiring potentially dozens of tool calls or steps\n- Answerable with a single, verifiable value that you identify in advance\n\n## Question Guidelines\n\n### Core Requirements\n\n1. **Questions MUST be independent**\n   - Each question should NOT depend on the answer to any other question\n   - Should not assume prior write operations from processing another question\n\n2. **Questions MUST require ONLY NON-DESTRUCTIVE AND IDEMPOTENT tool use**\n   - Should not instruct or require modifying state to arrive at the correct answer\n\n3. **Questions must be REALISTIC, CLEAR, CONCISE, and COMPLEX**\n   - Must require another LLM to use multiple (potentially dozens of) tools or steps to answer\n\n### Complexity and Depth\n\n4. **Questions must require deep exploration**\n   - Consider multi-hop questions requiring multiple sub-questions and sequential tool calls\n   - Each step should benefit from information found in previous questions\n\n5. **Questions may require extensive paging**\n   - May need paging through multiple pages of results\n   - May require querying old data (1-2 years out-of-date) to find niche information\n   - The questions must be DIFFICULT\n\n6. **Questions must require deep understanding**\n   - Rather than surface-level knowledge\n   - May pose complex ideas as True/False questions requiring evidence\n   - May use multiple-choice format where LLM must search different hypotheses\n\n7. **Questions must not be solvable with straightforward keyword search**\n   - Do not include specific keywords from the target content\n   - Use synonyms, related concepts, or paraphrases\n   - Require multiple searches, analyzing multiple related items, extracting context, then deriving the answer\n\n### Tool Testing\n\n8. **Questions should stress-test tool return values**\n   - May elicit tools returning large JSON objects or lists, overwhelming the LLM\n   - Should require understanding multiple modalities of data:\n     - IDs and names\n     - Timestamps and datetimes (months, days, years, seconds)\n     - File IDs, names, extensions, and mimetypes\n     - URLs, GIDs, etc.\n   - Should probe the tool's ability to return all useful forms of data\n\n9. **Questions should MOSTLY reflect real human use cases**\n   - The kinds of information retrieval tasks that HUMANS assisted by an LLM would care about\n\n10. **Questions may require dozens of tool calls**\n    - This challenges LLMs with limited context\n    - Encourages MCP server tools to reduce information returned\n\n11. **Include ambiguous questions**\n    - May be ambiguous OR require difficult decisions on which tools to call\n    - Force the LLM to potentially make mistakes or misinterpret\n    - Ensure that despite AMBIGUITY, there is STILL A SINGLE VERIFIABLE ANSWER\n\n### Stability\n\n12. **Questions must be designed so the answer DOES NOT CHANGE**\n    - Do not ask questions that rely on \"current state\" which is dynamic\n    - For example, do not count:\n      - Number of reactions to a post\n      - Number of replies to a thread\n      - Number of members in a channel\n\n13. **DO NOT let the MCP server RESTRICT the kinds of questions you create**\n    - Create challenging and complex questions\n    - Some may not be solvable with the available MCP server tools\n    - Questions may require specific output formats (datetime vs. epoch time, JSON vs. MARKDOWN)\n    - Questions may require dozens of tool calls to complete\n\n## Answer Guidelines\n\n### Verification\n\n1. **Answers must be VERIFIABLE via direct string comparison**\n   - If the answer can be re-written in many formats, clearly specify the output format in the QUESTION\n   - Examples: \"Use YYYY/MM/DD.\", \"Respond True or False.\", \"Answer A, B, C, or D and nothing else.\"\n   - Answer should be a single VERIFIABLE value such as:\n     - User ID, user name, display name, first name, last name\n     - Channel ID, channel name\n     - Message ID, string\n     - URL, title\n     - Numerical quantity\n     - Timestamp, datetime\n     - Boolean (for True/False questions)\n     - Email address, phone number\n     - File ID, file name, file extension\n     - Multiple choice answer\n   - Answers must not require special formatting or complex, structured output\n   - Answer will be verified using DIRECT STRING COMPARISON\n\n### Readability\n\n2. **Answers should generally prefer HUMAN-READABLE formats**\n   - Examples: names, first name, last name, datetime, file name, message string, URL, yes/no, true/false, a/b/c/d\n   - Rather than opaque IDs (though IDs are acceptable)\n   - The VAST MAJORITY of answers should be human-readable\n\n### Stability\n\n3. **Answers must be STABLE/STATIONARY**\n   - Look at old content (e.g., conversations that have ended, projects that have launched, questions answered)\n   - Create QUESTIONS based on \"closed\" concepts that will always return the same answer\n   - Questions may ask to consider a fixed time window to insulate from non-stationary answers\n   - Rely on context UNLIKELY to change\n   - Example: if finding a paper name, be SPECIFIC enough so answer is not confused with papers published later\n\n4. **Answers must be CLEAR and UNAMBIGUOUS**\n   - Questions must be designed so there is a single, clear answer\n   - Answer can be derived from using the MCP server tools\n\n### Diversity\n\n5. **Answers must be DIVERSE**\n   - Answer should be a single VERIFIABLE value in diverse modalities and formats\n   - User concept: user ID, user name, display name, first name, last name, email address, phone number\n   - Channel concept: channel ID, channel name, channel topic\n   - Message concept: message ID, message string, timestamp, month, day, year\n\n6. **Answers must NOT be complex structures**\n   - Not a list of values\n   - Not a complex object\n   - Not a list of IDs or strings\n   - Not natural language text\n   - UNLESS the answer can be straightforwardly verified using DIRECT STRING COMPARISON\n   - And can be realistically reproduced\n   - It should be unlikely that an LLM would return the same list in any other order or format\n\n## Evaluation Process\n\n### Step 1: Documentation Inspection\n\nRead the documentation of the target API to understand:\n- Available endpoints and functionality\n- If ambiguity exists, fetch additional information from the web\n- Parallelize this step AS MUCH AS POSSIBLE\n- Ensure each subagent is ONLY examining documentation from the file system or on the web\n\n### Step 2: Tool Inspection\n\nList the tools available in the MCP server:\n- Inspect the MCP server directly\n- Understand input/output schemas, docstrings, and descriptions\n- WITHOUT calling the tools themselves at this stage\n\n### Step 3: Developing Understanding\n\nRepeat steps 1 & 2 until you have a good understanding:\n- Iterate multiple times\n- Think about the kinds of tasks you want to create\n- Refine your understanding\n- At NO stage should you READ the code of the MCP server implementation itself\n- Use your intuition and understanding to create reasonable, realistic, but VERY challenging tasks\n\n### Step 4: Read-Only Content Inspection\n\nAfter understanding the API and tools, USE the MCP server tools:\n- Inspect content using READ-ONLY and NON-DESTRUCTIVE operations ONLY\n- Goal: identify specific content (e.g., users, channels, messages, projects, tasks) for creating realistic questions\n- Should NOT call any tools that modify state\n- Will NOT read the code of the MCP server implementation itself\n- Parallelize this step with individual sub-agents pursuing independent explorations\n- Ensure each subagent is only performing READ-ONLY, NON-DESTRUCTIVE, and IDEMPOTENT operations\n- BE CAREFUL: SOME TOOLS may return LOTS OF DATA which would cause you to run out of CONTEXT\n- Make INCREMENTAL, SMALL, AND TARGETED tool calls for exploration\n- In all tool call requests, use the `limit` parameter to limit results (<10)\n- Use pagination\n\n### Step 5: Task Generation\n\nAfter inspecting the content, create 10 human-readable questions:\n- An LLM should be able to answer these with the MCP server\n- Follow all question and answer guidelines above\n\n## Output Format\n\nEach QA pair consists of a question and an answer. The output should be an XML file with this structure:\n\n```xml\n<evaluation>\n   <qa_pair>\n      <question>Find the project created in Q2 2024 with the highest number of completed tasks. What is the project name?</question>\n      <answer>Website Redesign</answer>\n   </qa_pair>\n   <qa_pair>\n      <question>Search for issues labeled as \"bug\" that were closed in March 2024. Which user closed the most issues? Provide their username.</question>\n      <answer>sarah_dev</answer>\n   </qa_pair>\n   <qa_pair>\n      <question>Look for pull requests that modified files in the /api directory and were merged between January 1 and January 31, 2024. How many different contributors worked on these PRs?</question>\n      <answer>7</answer>\n   </qa_pair>\n   <qa_pair>\n      <question>Find the repository with the most stars that was created before 2023. What is the repository name?</question>\n      <answer>data-pipeline</answer>\n   </qa_pair>\n</evaluation>\n```\n\n## Evaluation Examples\n\n### Good Questions\n\n**Example 1: Multi-hop question requiring deep exploration (GitHub MCP)**\n```xml\n<qa_pair>\n   <question>Find the repository that was archived in Q3 2023 and had previously been the most forked project in the organization. What was the primary programming language used in that repository?</question>\n   <answer>Python</answer>\n</qa_pair>\n```\n\nThis question is good because:\n- Requires multiple searches to find archived repositories\n- Needs to identify which had the most forks before archival\n- Requires examining repository details for the language\n- Answer is a simple, verifiable value\n- Based on historical (closed) data that won't change\n\n**Example 2: Requires understanding context without keyword matching (Project Management MCP)**\n```xml\n<qa_pair>\n   <question>Locate the initiative focused on improving customer onboarding that was completed in late 2023. The project lead created a retrospective document after completion. What was the lead's role title at that time?</question>\n   <answer>Product Manager</answer>\n</qa_pair>\n```\n\nThis question is good because:\n- Doesn't use specific project name (\"initiative focused on improving customer onboarding\")\n- Requires finding completed projects from specific timeframe\n- Needs to identify the project lead and their role\n- Requires understanding context from retrospective documents\n- Answer is human-readable and stable\n- Based on completed work (won't change)\n\n**Example 3: Complex aggregation requiring multiple steps (Issue Tracker MCP)**\n```xml\n<qa_pair>\n   <question>Among all bugs reported in January 2024 that were marked as critical priority, which assignee resolved the highest percentage of their assigned bugs within 48 hours? Provide the assignee's username.</question>\n   <answer>alex_eng</answer>\n</qa_pair>\n```\n\nThis question is good because:\n- Requires filtering bugs by date, priority, and status\n- Needs to group by assignee and calculate resolution rates\n- Requires understanding timestamps to determine 48-hour windows\n- Tests pagination (potentially many bugs to process)\n- Answer is a single username\n- Based on historical data from specific time period\n\n**Example 4: Requires synthesis across multiple data types (CRM MCP)**\n```xml\n<qa_pair>\n   <question>Find the account that upgraded from the Starter to Enterprise plan in Q4 2023 and had the highest annual contract value. What industry does this account operate in?</question>\n   <answer>Healthcare</answer>\n</qa_pair>\n```\n\nThis question is good because:\n- Requires understanding subscription tier changes\n- Needs to identify upgrade events in specific timeframe\n- Requires comparing contract values\n- Must access account industry information\n- Answer is simple and verifiable\n- Based on completed historical transactions\n\n### Poor Questions\n\n**Example 1: Answer changes over time**\n```xml\n<qa_pair>\n   <question>How many open issues are currently assigned to the engineering team?</question>\n   <answer>47</answer>\n</qa_pair>\n```\n\nThis question is poor because:\n- The answer will change as issues are created, closed, or reassigned\n- Not based on stable/stationary data\n- Relies on \"current state\" which is dynamic\n\n**Example 2: Too easy with keyword search**\n```xml\n<qa_pair>\n   <question>Find the pull request with title \"Add authentication feature\" and tell me who created it.</question>\n   <answer>developer123</answer>\n</qa_pair>\n```\n\nThis question is poor because:\n- Can be solved with a straightforward keyword search for exact title\n- Doesn't require deep exploration or understanding\n- No synthesis or analysis needed\n\n**Example 3: Ambiguous answer format**\n```xml\n<qa_pair>\n   <question>List all the repositories that have Python as their primary language.</question>\n   <answer>repo1, repo2, repo3, data-pipeline, ml-tools</answer>\n</qa_pair>\n```\n\nThis question is poor because:\n- Answer is a list that could be returned in any order\n- Difficult to verify with direct string comparison\n- LLM might format differently (JSON array, comma-separated, newline-separated)\n- Better to ask for a specific aggregate (count) or superlative (most stars)\n\n## Verification Process\n\nAfter creating evaluations:\n\n1. **Examine the XML file** to understand the schema\n2. **Load each task instruction** and in parallel using the MCP server and tools, identify the correct answer by attempting to solve the task YOURSELF\n3. **Flag any operations** that require WRITE or DESTRUCTIVE operations\n4. **Accumulate all CORRECT answers** and replace any incorrect answers in the document\n5. **Remove any `<qa_pair>`** that require WRITE or DESTRUCTIVE operations\n\nRemember to parallelize solving tasks to avoid running out of context, then accumulate all answers and make changes to the file at the end.\n\n## Tips for Creating Quality Evaluations\n\n1. **Think Hard and Plan Ahead** before generating tasks\n2. **Parallelize Where Opportunity Arises** to speed up the process and manage context\n3. **Focus on Realistic Use Cases** that humans would actually want to accomplish\n4. **Create Challenging Questions** that test the limits of the MCP server's capabilities\n5. **Ensure Stability** by using historical data and closed concepts\n6. **Verify Answers** by solving the questions yourself using the MCP server tools\n7. **Iterate and Refine** based on what you learn during the process\n\n---\n\n# Running Evaluations\n\nAfter creating your evaluation file, you can use the provided evaluation harness to test your MCP server.\n\n## Setup\n\n1. **Install Dependencies**\n\n   ```bash\n   pip install -r scripts/requirements.txt\n   ```\n\n   Or install manually:\n   ```bash\n   pip install anthropic mcp\n   ```\n\n2. **Set API Key**\n\n   ```bash\n   export ANTHROPIC_API_KEY=your_api_key_here\n   ```\n\n## Evaluation File Format\n\nEvaluation files use XML format with `<qa_pair>` elements:\n\n```xml\n<evaluation>\n   <qa_pair>\n      <question>Find the project created in Q2 2024 with the highest number of completed tasks. What is the project name?</question>\n      <answer>Website Redesign</answer>\n   </qa_pair>\n   <qa_pair>\n      <question>Search for issues labeled as \"bug\" that were closed in March 2024. Which user closed the most issues? Provide their username.</question>\n      <answer>sarah_dev</answer>\n   </qa_pair>\n</evaluation>\n```\n\n## Running Evaluations\n\nThe evaluation script (`scripts/evaluation.py`) supports three transport types:\n\n**Important:**\n- **stdio transport**: The evaluation script automatically launches and manages the MCP server process for you. Do not run the server manually.\n- **sse/http transports**: You must start the MCP server separately before running the evaluation. The script connects to the already-running server at the specified URL.\n\n### 1. Local STDIO Server\n\nFor locally-run MCP servers (script launches the server automatically):\n\n```bash\npython scripts/evaluation.py \\\n  -t stdio \\\n  -c python \\\n  -a my_mcp_server.py \\\n  evaluation.xml\n```\n\nWith environment variables:\n```bash\npython scripts/evaluation.py \\\n  -t stdio \\\n  -c python \\\n  -a my_mcp_server.py \\\n  -e API_KEY=abc123 \\\n  -e DEBUG=true \\\n  evaluation.xml\n```\n\n### 2. Server-Sent Events (SSE)\n\nFor SSE-based MCP servers (you must start the server first):\n\n```bash\npython scripts/evaluation.py \\\n  -t sse \\\n  -u https://example.com/mcp \\\n  -H \"Authorization: Bearer token123\" \\\n  -H \"X-Custom-Header: value\" \\\n  evaluation.xml\n```\n\n### 3. HTTP (Streamable HTTP)\n\nFor HTTP-based MCP servers (you must start the server first):\n\n```bash\npython scripts/evaluation.py \\\n  -t http \\\n  -u https://example.com/mcp \\\n  -H \"Authorization: Bearer token123\" \\\n  evaluation.xml\n```\n\n## Command-Line Options\n\n```\nusage: evaluation.py [-h] [-t {stdio,sse,http}] [-m MODEL] [-c COMMAND]\n                     [-a ARGS [ARGS ...]] [-e ENV [ENV ...]] [-u URL]\n                     [-H HEADERS [HEADERS ...]] [-o OUTPUT]\n                     eval_file\n\npositional arguments:\n  eval_file             Path to evaluation XML file\n\noptional arguments:\n  -h, --help            Show help message\n  -t, --transport       Transport type: stdio, sse, or http (default: stdio)\n  -m, --model           Claude model to use (default: claude-3-7-sonnet-20250219)\n  -o, --output          Output file for report (default: print to stdout)\n\nstdio options:\n  -c, --command         Command to run MCP server (e.g., python, node)\n  -a, --args            Arguments for the command (e.g., server.py)\n  -e, --env             Environment variables in KEY=VALUE format\n\nsse/http options:\n  -u, --url             MCP server URL\n  -H, --header          HTTP headers in 'Key: Value' format\n```\n\n## Output\n\nThe evaluation script generates a detailed report including:\n\n- **Summary Statistics**:\n  - Accuracy (correct/total)\n  - Average task duration\n  - Average tool calls per task\n  - Total tool calls\n\n- **Per-Task Results**:\n  - Prompt and expected response\n  - Actual response from the agent\n  - Whether the answer was correct (/)\n  - Duration and tool call details\n  - Agent's summary of its approach\n  - Agent's feedback on the tools\n\n### Save Report to File\n\n```bash\npython scripts/evaluation.py \\\n  -t stdio \\\n  -c python \\\n  -a my_server.py \\\n  -o evaluation_report.md \\\n  evaluation.xml\n```\n\n## Complete Example Workflow\n\nHere's a complete example of creating and running an evaluation:\n\n1. **Create your evaluation file** (`my_evaluation.xml`):\n\n```xml\n<evaluation>\n   <qa_pair>\n      <question>Find the user who created the most issues in January 2024. What is their username?</question>\n      <answer>alice_developer</answer>\n   </qa_pair>\n   <qa_pair>\n      <question>Among all pull requests merged in Q1 2024, which repository had the highest number? Provide the repository name.</question>\n      <answer>backend-api</answer>\n   </qa_pair>\n   <qa_pair>\n      <question>Find the project that was completed in December 2023 and had the longest duration from start to finish. How many days did it take?</question>\n      <answer>127</answer>\n   </qa_pair>\n</evaluation>\n```\n\n2. **Install dependencies**:\n\n```bash\npip install -r scripts/requirements.txt\nexport ANTHROPIC_API_KEY=your_api_key\n```\n\n3. **Run evaluation**:\n\n```bash\npython scripts/evaluation.py \\\n  -t stdio \\\n  -c python \\\n  -a github_mcp_server.py \\\n  -e GITHUB_TOKEN=ghp_xxx \\\n  -o github_eval_report.md \\\n  my_evaluation.xml\n```\n\n4. **Review the report** in `github_eval_report.md` to:\n   - See which questions passed/failed\n   - Read the agent's feedback on your tools\n   - Identify areas for improvement\n   - Iterate on your MCP server design\n\n## Troubleshooting\n\n### Connection Errors\n\nIf you get connection errors:\n- **STDIO**: Verify the command and arguments are correct\n- **SSE/HTTP**: Check the URL is accessible and headers are correct\n- Ensure any required API keys are set in environment variables or headers\n\n### Low Accuracy\n\nIf many evaluations fail:\n- Review the agent's feedback for each task\n- Check if tool descriptions are clear and comprehensive\n- Verify input parameters are well-documented\n- Consider whether tools return too much or too little data\n- Ensure error messages are actionable\n\n### Timeout Issues\n\nIf tasks are timing out:\n- Use a more capable model (e.g., `claude-3-7-sonnet-20250219`)\n- Check if tools are returning too much data\n- Verify pagination is working correctly\n- Consider simplifying complex questions",
        ".claude/skills/mcp-builder/reference/mcp_best_practices.md": "# MCP Server Best Practices\n\n## Quick Reference\n\n### Server Naming\n- **Python**: `{service}_mcp` (e.g., `slack_mcp`)\n- **Node/TypeScript**: `{service}-mcp-server` (e.g., `slack-mcp-server`)\n\n### Tool Naming\n- Use snake_case with service prefix\n- Format: `{service}_{action}_{resource}`\n- Example: `slack_send_message`, `github_create_issue`\n\n### Response Formats\n- Support both JSON and Markdown formats\n- JSON for programmatic processing\n- Markdown for human readability\n\n### Pagination\n- Always respect `limit` parameter\n- Return `has_more`, `next_offset`, `total_count`\n- Default to 20-50 items\n\n### Transport\n- **Streamable HTTP**: For remote servers, multi-client scenarios\n- **stdio**: For local integrations, command-line tools\n- Avoid SSE (deprecated in favor of streamable HTTP)\n\n---\n\n## Server Naming Conventions\n\nFollow these standardized naming patterns:\n\n**Python**: Use format `{service}_mcp` (lowercase with underscores)\n- Examples: `slack_mcp`, `github_mcp`, `jira_mcp`\n\n**Node/TypeScript**: Use format `{service}-mcp-server` (lowercase with hyphens)\n- Examples: `slack-mcp-server`, `github-mcp-server`, `jira-mcp-server`\n\nThe name should be general, descriptive of the service being integrated, easy to infer from the task description, and without version numbers.\n\n---\n\n## Tool Naming and Design\n\n### Tool Naming\n\n1. **Use snake_case**: `search_users`, `create_project`, `get_channel_info`\n2. **Include service prefix**: Anticipate that your MCP server may be used alongside other MCP servers\n   - Use `slack_send_message` instead of just `send_message`\n   - Use `github_create_issue` instead of just `create_issue`\n3. **Be action-oriented**: Start with verbs (get, list, search, create, etc.)\n4. **Be specific**: Avoid generic names that could conflict with other servers\n\n### Tool Design\n\n- Tool descriptions must narrowly and unambiguously describe functionality\n- Descriptions must precisely match actual functionality\n- Provide tool annotations (readOnlyHint, destructiveHint, idempotentHint, openWorldHint)\n- Keep tool operations focused and atomic\n\n---\n\n## Response Formats\n\nAll tools that return data should support multiple formats:\n\n### JSON Format (`response_format=\"json\"`)\n- Machine-readable structured data\n- Include all available fields and metadata\n- Consistent field names and types\n- Use for programmatic processing\n\n### Markdown Format (`response_format=\"markdown\"`, typically default)\n- Human-readable formatted text\n- Use headers, lists, and formatting for clarity\n- Convert timestamps to human-readable format\n- Show display names with IDs in parentheses\n- Omit verbose metadata\n\n---\n\n## Pagination\n\nFor tools that list resources:\n\n- **Always respect the `limit` parameter**\n- **Implement pagination**: Use `offset` or cursor-based pagination\n- **Return pagination metadata**: Include `has_more`, `next_offset`/`next_cursor`, `total_count`\n- **Never load all results into memory**: Especially important for large datasets\n- **Default to reasonable limits**: 20-50 items is typical\n\nExample pagination response:\n```json\n{\n  \"total\": 150,\n  \"count\": 20,\n  \"offset\": 0,\n  \"items\": [...],\n  \"has_more\": true,\n  \"next_offset\": 20\n}\n```\n\n---\n\n## Transport Options\n\n### Streamable HTTP\n\n**Best for**: Remote servers, web services, multi-client scenarios\n\n**Characteristics**:\n- Bidirectional communication over HTTP\n- Supports multiple simultaneous clients\n- Can be deployed as a web service\n- Enables server-to-client notifications\n\n**Use when**:\n- Serving multiple clients simultaneously\n- Deploying as a cloud service\n- Integration with web applications\n\n### stdio\n\n**Best for**: Local integrations, command-line tools\n\n**Characteristics**:\n- Standard input/output stream communication\n- Simple setup, no network configuration needed\n- Runs as a subprocess of the client\n\n**Use when**:\n- Building tools for local development environments\n- Integrating with desktop applications\n- Single-user, single-session scenarios\n\n**Note**: stdio servers should NOT log to stdout (use stderr for logging)\n\n### Transport Selection\n\n| Criterion | stdio | Streamable HTTP |\n|-----------|-------|-----------------|\n| **Deployment** | Local | Remote |\n| **Clients** | Single | Multiple |\n| **Complexity** | Low | Medium |\n| **Real-time** | No | Yes |\n\n---\n\n## Security Best Practices\n\n### Authentication and Authorization\n\n**OAuth 2.1**:\n- Use secure OAuth 2.1 with certificates from recognized authorities\n- Validate access tokens before processing requests\n- Only accept tokens specifically intended for your server\n\n**API Keys**:\n- Store API keys in environment variables, never in code\n- Validate keys on server startup\n- Provide clear error messages when authentication fails\n\n### Input Validation\n\n- Sanitize file paths to prevent directory traversal\n- Validate URLs and external identifiers\n- Check parameter sizes and ranges\n- Prevent command injection in system calls\n- Use schema validation (Pydantic/Zod) for all inputs\n\n### Error Handling\n\n- Don't expose internal errors to clients\n- Log security-relevant errors server-side\n- Provide helpful but not revealing error messages\n- Clean up resources after errors\n\n### DNS Rebinding Protection\n\nFor streamable HTTP servers running locally:\n- Enable DNS rebinding protection\n- Validate the `Origin` header on all incoming connections\n- Bind to `127.0.0.1` rather than `0.0.0.0`\n\n---\n\n## Tool Annotations\n\nProvide annotations to help clients understand tool behavior:\n\n| Annotation | Type | Default | Description |\n|-----------|------|---------|-------------|\n| `readOnlyHint` | boolean | false | Tool does not modify its environment |\n| `destructiveHint` | boolean | true | Tool may perform destructive updates |\n| `idempotentHint` | boolean | false | Repeated calls with same args have no additional effect |\n| `openWorldHint` | boolean | true | Tool interacts with external entities |\n\n**Important**: Annotations are hints, not security guarantees. Clients should not make security-critical decisions based solely on annotations.\n\n---\n\n## Error Handling\n\n- Use standard JSON-RPC error codes\n- Report tool errors within result objects (not protocol-level errors)\n- Provide helpful, specific error messages with suggested next steps\n- Don't expose internal implementation details\n- Clean up resources properly on errors\n\nExample error handling:\n```typescript\ntry {\n  const result = performOperation();\n  return { content: [{ type: \"text\", text: result }] };\n} catch (error) {\n  return {\n    isError: true,\n    content: [{\n      type: \"text\",\n      text: `Error: ${error.message}. Try using filter='active_only' to reduce results.`\n    }]\n  };\n}\n```\n\n---\n\n## Testing Requirements\n\nComprehensive testing should cover:\n\n- **Functional testing**: Verify correct execution with valid/invalid inputs\n- **Integration testing**: Test interaction with external systems\n- **Security testing**: Validate auth, input sanitization, rate limiting\n- **Performance testing**: Check behavior under load, timeouts\n- **Error handling**: Ensure proper error reporting and cleanup\n\n---\n\n## Documentation Requirements\n\n- Provide clear documentation of all tools and capabilities\n- Include working examples (at least 3 per major feature)\n- Document security considerations\n- Specify required permissions and access levels\n- Document rate limits and performance characteristics\n",
        ".claude/skills/mcp-builder/reference/node_mcp_server.md": "# Node/TypeScript MCP Server Implementation Guide\n\n## Overview\n\nThis document provides Node/TypeScript-specific best practices and examples for implementing MCP servers using the MCP TypeScript SDK. It covers project structure, server setup, tool registration patterns, input validation with Zod, error handling, and complete working examples.\n\n---\n\n## Quick Reference\n\n### Key Imports\n```typescript\nimport { McpServer } from \"@modelcontextprotocol/sdk/server/mcp.js\";\nimport { StreamableHTTPServerTransport } from \"@modelcontextprotocol/sdk/server/streamableHttp.js\";\nimport { StdioServerTransport } from \"@modelcontextprotocol/sdk/server/stdio.js\";\nimport express from \"express\";\nimport { z } from \"zod\";\n```\n\n### Server Initialization\n```typescript\nconst server = new McpServer({\n  name: \"service-mcp-server\",\n  version: \"1.0.0\"\n});\n```\n\n### Tool Registration Pattern\n```typescript\nserver.registerTool(\n  \"tool_name\",\n  {\n    title: \"Tool Display Name\",\n    description: \"What the tool does\",\n    inputSchema: { param: z.string() },\n    outputSchema: { result: z.string() }\n  },\n  async ({ param }) => {\n    const output = { result: `Processed: ${param}` };\n    return {\n      content: [{ type: \"text\", text: JSON.stringify(output) }],\n      structuredContent: output // Modern pattern for structured data\n    };\n  }\n);\n```\n\n---\n\n## MCP TypeScript SDK\n\nThe official MCP TypeScript SDK provides:\n- `McpServer` class for server initialization\n- `registerTool` method for tool registration\n- Zod schema integration for runtime input validation\n- Type-safe tool handler implementations\n\n**IMPORTANT - Use Modern APIs Only:**\n- **DO use**: `server.registerTool()`, `server.registerResource()`, `server.registerPrompt()`\n- **DO NOT use**: Old deprecated APIs such as `server.tool()`, `server.setRequestHandler(ListToolsRequestSchema, ...)`, or manual handler registration\n- The `register*` methods provide better type safety, automatic schema handling, and are the recommended approach\n\nSee the MCP SDK documentation in the references for complete details.\n\n## Server Naming Convention\n\nNode/TypeScript MCP servers must follow this naming pattern:\n- **Format**: `{service}-mcp-server` (lowercase with hyphens)\n- **Examples**: `github-mcp-server`, `jira-mcp-server`, `stripe-mcp-server`\n\nThe name should be:\n- General (not tied to specific features)\n- Descriptive of the service/API being integrated\n- Easy to infer from the task description\n- Without version numbers or dates\n\n## Project Structure\n\nCreate the following structure for Node/TypeScript MCP servers:\n\n```\n{service}-mcp-server/\n package.json\n tsconfig.json\n README.md\n src/\n    index.ts          # Main entry point with McpServer initialization\n    types.ts          # TypeScript type definitions and interfaces\n    tools/            # Tool implementations (one file per domain)\n    services/         # API clients and shared utilities\n    schemas/          # Zod validation schemas\n    constants.ts      # Shared constants (API_URL, CHARACTER_LIMIT, etc.)\n dist/                 # Built JavaScript files (entry point: dist/index.js)\n```\n\n## Tool Implementation\n\n### Tool Naming\n\nUse snake_case for tool names (e.g., \"search_users\", \"create_project\", \"get_channel_info\") with clear, action-oriented names.\n\n**Avoid Naming Conflicts**: Include the service context to prevent overlaps:\n- Use \"slack_send_message\" instead of just \"send_message\"\n- Use \"github_create_issue\" instead of just \"create_issue\"\n- Use \"asana_list_tasks\" instead of just \"list_tasks\"\n\n### Tool Structure\n\nTools are registered using the `registerTool` method with the following requirements:\n- Use Zod schemas for runtime input validation and type safety\n- The `description` field must be explicitly provided - JSDoc comments are NOT automatically extracted\n- Explicitly provide `title`, `description`, `inputSchema`, and `annotations`\n- The `inputSchema` must be a Zod schema object (not a JSON schema)\n- Type all parameters and return values explicitly\n\n```typescript\nimport { McpServer } from \"@modelcontextprotocol/sdk/server/mcp.js\";\nimport { z } from \"zod\";\n\nconst server = new McpServer({\n  name: \"example-mcp\",\n  version: \"1.0.0\"\n});\n\n// Zod schema for input validation\nconst UserSearchInputSchema = z.object({\n  query: z.string()\n    .min(2, \"Query must be at least 2 characters\")\n    .max(200, \"Query must not exceed 200 characters\")\n    .describe(\"Search string to match against names/emails\"),\n  limit: z.number()\n    .int()\n    .min(1)\n    .max(100)\n    .default(20)\n    .describe(\"Maximum results to return\"),\n  offset: z.number()\n    .int()\n    .min(0)\n    .default(0)\n    .describe(\"Number of results to skip for pagination\"),\n  response_format: z.nativeEnum(ResponseFormat)\n    .default(ResponseFormat.MARKDOWN)\n    .describe(\"Output format: 'markdown' for human-readable or 'json' for machine-readable\")\n}).strict();\n\n// Type definition from Zod schema\ntype UserSearchInput = z.infer<typeof UserSearchInputSchema>;\n\nserver.registerTool(\n  \"example_search_users\",\n  {\n    title: \"Search Example Users\",\n    description: `Search for users in the Example system by name, email, or team.\n\nThis tool searches across all user profiles in the Example platform, supporting partial matches and various search filters. It does NOT create or modify users, only searches existing ones.\n\nArgs:\n  - query (string): Search string to match against names/emails\n  - limit (number): Maximum results to return, between 1-100 (default: 20)\n  - offset (number): Number of results to skip for pagination (default: 0)\n  - response_format ('markdown' | 'json'): Output format (default: 'markdown')\n\nReturns:\n  For JSON format: Structured data with schema:\n  {\n    \"total\": number,           // Total number of matches found\n    \"count\": number,           // Number of results in this response\n    \"offset\": number,          // Current pagination offset\n    \"users\": [\n      {\n        \"id\": string,          // User ID (e.g., \"U123456789\")\n        \"name\": string,        // Full name (e.g., \"John Doe\")\n        \"email\": string,       // Email address\n        \"team\": string,        // Team name (optional)\n        \"active\": boolean      // Whether user is active\n      }\n    ],\n    \"has_more\": boolean,       // Whether more results are available\n    \"next_offset\": number      // Offset for next page (if has_more is true)\n  }\n\nExamples:\n  - Use when: \"Find all marketing team members\" -> params with query=\"team:marketing\"\n  - Use when: \"Search for John's account\" -> params with query=\"john\"\n  - Don't use when: You need to create a user (use example_create_user instead)\n\nError Handling:\n  - Returns \"Error: Rate limit exceeded\" if too many requests (429 status)\n  - Returns \"No users found matching '<query>'\" if search returns empty`,\n    inputSchema: UserSearchInputSchema,\n    annotations: {\n      readOnlyHint: true,\n      destructiveHint: false,\n      idempotentHint: true,\n      openWorldHint: true\n    }\n  },\n  async (params: UserSearchInput) => {\n    try {\n      // Input validation is handled by Zod schema\n      // Make API request using validated parameters\n      const data = await makeApiRequest<any>(\n        \"users/search\",\n        \"GET\",\n        undefined,\n        {\n          q: params.query,\n          limit: params.limit,\n          offset: params.offset\n        }\n      );\n\n      const users = data.users || [];\n      const total = data.total || 0;\n\n      if (!users.length) {\n        return {\n          content: [{\n            type: \"text\",\n            text: `No users found matching '${params.query}'`\n          }]\n        };\n      }\n\n      // Prepare structured output\n      const output = {\n        total,\n        count: users.length,\n        offset: params.offset,\n        users: users.map((user: any) => ({\n          id: user.id,\n          name: user.name,\n          email: user.email,\n          ...(user.team ? { team: user.team } : {}),\n          active: user.active ?? true\n        })),\n        has_more: total > params.offset + users.length,\n        ...(total > params.offset + users.length ? {\n          next_offset: params.offset + users.length\n        } : {})\n      };\n\n      // Format text representation based on requested format\n      let textContent: string;\n      if (params.response_format === ResponseFormat.MARKDOWN) {\n        const lines = [`# User Search Results: '${params.query}'`, \"\",\n          `Found ${total} users (showing ${users.length})`, \"\"];\n        for (const user of users) {\n          lines.push(`## ${user.name} (${user.id})`);\n          lines.push(`- **Email**: ${user.email}`);\n          if (user.team) lines.push(`- **Team**: ${user.team}`);\n          lines.push(\"\");\n        }\n        textContent = lines.join(\"\\n\");\n      } else {\n        textContent = JSON.stringify(output, null, 2);\n      }\n\n      return {\n        content: [{ type: \"text\", text: textContent }],\n        structuredContent: output // Modern pattern for structured data\n      };\n    } catch (error) {\n      return {\n        content: [{\n          type: \"text\",\n          text: handleApiError(error)\n        }]\n      };\n    }\n  }\n);\n```\n\n## Zod Schemas for Input Validation\n\nZod provides runtime type validation:\n\n```typescript\nimport { z } from \"zod\";\n\n// Basic schema with validation\nconst CreateUserSchema = z.object({\n  name: z.string()\n    .min(1, \"Name is required\")\n    .max(100, \"Name must not exceed 100 characters\"),\n  email: z.string()\n    .email(\"Invalid email format\"),\n  age: z.number()\n    .int(\"Age must be a whole number\")\n    .min(0, \"Age cannot be negative\")\n    .max(150, \"Age cannot be greater than 150\")\n}).strict();  // Use .strict() to forbid extra fields\n\n// Enums\nenum ResponseFormat {\n  MARKDOWN = \"markdown\",\n  JSON = \"json\"\n}\n\nconst SearchSchema = z.object({\n  response_format: z.nativeEnum(ResponseFormat)\n    .default(ResponseFormat.MARKDOWN)\n    .describe(\"Output format\")\n});\n\n// Optional fields with defaults\nconst PaginationSchema = z.object({\n  limit: z.number()\n    .int()\n    .min(1)\n    .max(100)\n    .default(20)\n    .describe(\"Maximum results to return\"),\n  offset: z.number()\n    .int()\n    .min(0)\n    .default(0)\n    .describe(\"Number of results to skip\")\n});\n```\n\n## Response Format Options\n\nSupport multiple output formats for flexibility:\n\n```typescript\nenum ResponseFormat {\n  MARKDOWN = \"markdown\",\n  JSON = \"json\"\n}\n\nconst inputSchema = z.object({\n  query: z.string(),\n  response_format: z.nativeEnum(ResponseFormat)\n    .default(ResponseFormat.MARKDOWN)\n    .describe(\"Output format: 'markdown' for human-readable or 'json' for machine-readable\")\n});\n```\n\n**Markdown format**:\n- Use headers, lists, and formatting for clarity\n- Convert timestamps to human-readable format\n- Show display names with IDs in parentheses\n- Omit verbose metadata\n- Group related information logically\n\n**JSON format**:\n- Return complete, structured data suitable for programmatic processing\n- Include all available fields and metadata\n- Use consistent field names and types\n\n## Pagination Implementation\n\nFor tools that list resources:\n\n```typescript\nconst ListSchema = z.object({\n  limit: z.number().int().min(1).max(100).default(20),\n  offset: z.number().int().min(0).default(0)\n});\n\nasync function listItems(params: z.infer<typeof ListSchema>) {\n  const data = await apiRequest(params.limit, params.offset);\n\n  const response = {\n    total: data.total,\n    count: data.items.length,\n    offset: params.offset,\n    items: data.items,\n    has_more: data.total > params.offset + data.items.length,\n    next_offset: data.total > params.offset + data.items.length\n      ? params.offset + data.items.length\n      : undefined\n  };\n\n  return JSON.stringify(response, null, 2);\n}\n```\n\n## Character Limits and Truncation\n\nAdd a CHARACTER_LIMIT constant to prevent overwhelming responses:\n\n```typescript\n// At module level in constants.ts\nexport const CHARACTER_LIMIT = 25000;  // Maximum response size in characters\n\nasync function searchTool(params: SearchInput) {\n  let result = generateResponse(data);\n\n  // Check character limit and truncate if needed\n  if (result.length > CHARACTER_LIMIT) {\n    const truncatedData = data.slice(0, Math.max(1, data.length / 2));\n    response.data = truncatedData;\n    response.truncated = true;\n    response.truncation_message =\n      `Response truncated from ${data.length} to ${truncatedData.length} items. ` +\n      `Use 'offset' parameter or add filters to see more results.`;\n    result = JSON.stringify(response, null, 2);\n  }\n\n  return result;\n}\n```\n\n## Error Handling\n\nProvide clear, actionable error messages:\n\n```typescript\nimport axios, { AxiosError } from \"axios\";\n\nfunction handleApiError(error: unknown): string {\n  if (error instanceof AxiosError) {\n    if (error.response) {\n      switch (error.response.status) {\n        case 404:\n          return \"Error: Resource not found. Please check the ID is correct.\";\n        case 403:\n          return \"Error: Permission denied. You don't have access to this resource.\";\n        case 429:\n          return \"Error: Rate limit exceeded. Please wait before making more requests.\";\n        default:\n          return `Error: API request failed with status ${error.response.status}`;\n      }\n    } else if (error.code === \"ECONNABORTED\") {\n      return \"Error: Request timed out. Please try again.\";\n    }\n  }\n  return `Error: Unexpected error occurred: ${error instanceof Error ? error.message : String(error)}`;\n}\n```\n\n## Shared Utilities\n\nExtract common functionality into reusable functions:\n\n```typescript\n// Shared API request function\nasync function makeApiRequest<T>(\n  endpoint: string,\n  method: \"GET\" | \"POST\" | \"PUT\" | \"DELETE\" = \"GET\",\n  data?: any,\n  params?: any\n): Promise<T> {\n  try {\n    const response = await axios({\n      method,\n      url: `${API_BASE_URL}/${endpoint}`,\n      data,\n      params,\n      timeout: 30000,\n      headers: {\n        \"Content-Type\": \"application/json\",\n        \"Accept\": \"application/json\"\n      }\n    });\n    return response.data;\n  } catch (error) {\n    throw error;\n  }\n}\n```\n\n## Async/Await Best Practices\n\nAlways use async/await for network requests and I/O operations:\n\n```typescript\n// Good: Async network request\nasync function fetchData(resourceId: string): Promise<ResourceData> {\n  const response = await axios.get(`${API_URL}/resource/${resourceId}`);\n  return response.data;\n}\n\n// Bad: Promise chains\nfunction fetchData(resourceId: string): Promise<ResourceData> {\n  return axios.get(`${API_URL}/resource/${resourceId}`)\n    .then(response => response.data);  // Harder to read and maintain\n}\n```\n\n## TypeScript Best Practices\n\n1. **Use Strict TypeScript**: Enable strict mode in tsconfig.json\n2. **Define Interfaces**: Create clear interface definitions for all data structures\n3. **Avoid `any`**: Use proper types or `unknown` instead of `any`\n4. **Zod for Runtime Validation**: Use Zod schemas to validate external data\n5. **Type Guards**: Create type guard functions for complex type checking\n6. **Error Handling**: Always use try-catch with proper error type checking\n7. **Null Safety**: Use optional chaining (`?.`) and nullish coalescing (`??`)\n\n```typescript\n// Good: Type-safe with Zod and interfaces\ninterface UserResponse {\n  id: string;\n  name: string;\n  email: string;\n  team?: string;\n  active: boolean;\n}\n\nconst UserSchema = z.object({\n  id: z.string(),\n  name: z.string(),\n  email: z.string().email(),\n  team: z.string().optional(),\n  active: z.boolean()\n});\n\ntype User = z.infer<typeof UserSchema>;\n\nasync function getUser(id: string): Promise<User> {\n  const data = await apiCall(`/users/${id}`);\n  return UserSchema.parse(data);  // Runtime validation\n}\n\n// Bad: Using any\nasync function getUser(id: string): Promise<any> {\n  return await apiCall(`/users/${id}`);  // No type safety\n}\n```\n\n## Package Configuration\n\n### package.json\n\n```json\n{\n  \"name\": \"{service}-mcp-server\",\n  \"version\": \"1.0.0\",\n  \"description\": \"MCP server for {Service} API integration\",\n  \"type\": \"module\",\n  \"main\": \"dist/index.js\",\n  \"scripts\": {\n    \"start\": \"node dist/index.js\",\n    \"dev\": \"tsx watch src/index.ts\",\n    \"build\": \"tsc\",\n    \"clean\": \"rm -rf dist\"\n  },\n  \"engines\": {\n    \"node\": \">=18\"\n  },\n  \"dependencies\": {\n    \"@modelcontextprotocol/sdk\": \"^1.6.1\",\n    \"axios\": \"^1.7.9\",\n    \"zod\": \"^3.23.8\"\n  },\n  \"devDependencies\": {\n    \"@types/node\": \"^22.10.0\",\n    \"tsx\": \"^4.19.2\",\n    \"typescript\": \"^5.7.2\"\n  }\n}\n```\n\n### tsconfig.json\n\n```json\n{\n  \"compilerOptions\": {\n    \"target\": \"ES2022\",\n    \"module\": \"Node16\",\n    \"moduleResolution\": \"Node16\",\n    \"lib\": [\"ES2022\"],\n    \"outDir\": \"./dist\",\n    \"rootDir\": \"./src\",\n    \"strict\": true,\n    \"esModuleInterop\": true,\n    \"skipLibCheck\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"declaration\": true,\n    \"declarationMap\": true,\n    \"sourceMap\": true,\n    \"allowSyntheticDefaultImports\": true\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"node_modules\", \"dist\"]\n}\n```\n\n## Complete Example\n\n```typescript\n#!/usr/bin/env node\n/**\n * MCP Server for Example Service.\n *\n * This server provides tools to interact with Example API, including user search,\n * project management, and data export capabilities.\n */\n\nimport { McpServer } from \"@modelcontextprotocol/sdk/server/mcp.js\";\nimport { StdioServerTransport } from \"@modelcontextprotocol/sdk/server/stdio.js\";\nimport { z } from \"zod\";\nimport axios, { AxiosError } from \"axios\";\n\n// Constants\nconst API_BASE_URL = \"https://api.example.com/v1\";\nconst CHARACTER_LIMIT = 25000;\n\n// Enums\nenum ResponseFormat {\n  MARKDOWN = \"markdown\",\n  JSON = \"json\"\n}\n\n// Zod schemas\nconst UserSearchInputSchema = z.object({\n  query: z.string()\n    .min(2, \"Query must be at least 2 characters\")\n    .max(200, \"Query must not exceed 200 characters\")\n    .describe(\"Search string to match against names/emails\"),\n  limit: z.number()\n    .int()\n    .min(1)\n    .max(100)\n    .default(20)\n    .describe(\"Maximum results to return\"),\n  offset: z.number()\n    .int()\n    .min(0)\n    .default(0)\n    .describe(\"Number of results to skip for pagination\"),\n  response_format: z.nativeEnum(ResponseFormat)\n    .default(ResponseFormat.MARKDOWN)\n    .describe(\"Output format: 'markdown' for human-readable or 'json' for machine-readable\")\n}).strict();\n\ntype UserSearchInput = z.infer<typeof UserSearchInputSchema>;\n\n// Shared utility functions\nasync function makeApiRequest<T>(\n  endpoint: string,\n  method: \"GET\" | \"POST\" | \"PUT\" | \"DELETE\" = \"GET\",\n  data?: any,\n  params?: any\n): Promise<T> {\n  try {\n    const response = await axios({\n      method,\n      url: `${API_BASE_URL}/${endpoint}`,\n      data,\n      params,\n      timeout: 30000,\n      headers: {\n        \"Content-Type\": \"application/json\",\n        \"Accept\": \"application/json\"\n      }\n    });\n    return response.data;\n  } catch (error) {\n    throw error;\n  }\n}\n\nfunction handleApiError(error: unknown): string {\n  if (error instanceof AxiosError) {\n    if (error.response) {\n      switch (error.response.status) {\n        case 404:\n          return \"Error: Resource not found. Please check the ID is correct.\";\n        case 403:\n          return \"Error: Permission denied. You don't have access to this resource.\";\n        case 429:\n          return \"Error: Rate limit exceeded. Please wait before making more requests.\";\n        default:\n          return `Error: API request failed with status ${error.response.status}`;\n      }\n    } else if (error.code === \"ECONNABORTED\") {\n      return \"Error: Request timed out. Please try again.\";\n    }\n  }\n  return `Error: Unexpected error occurred: ${error instanceof Error ? error.message : String(error)}`;\n}\n\n// Create MCP server instance\nconst server = new McpServer({\n  name: \"example-mcp\",\n  version: \"1.0.0\"\n});\n\n// Register tools\nserver.registerTool(\n  \"example_search_users\",\n  {\n    title: \"Search Example Users\",\n    description: `[Full description as shown above]`,\n    inputSchema: UserSearchInputSchema,\n    annotations: {\n      readOnlyHint: true,\n      destructiveHint: false,\n      idempotentHint: true,\n      openWorldHint: true\n    }\n  },\n  async (params: UserSearchInput) => {\n    // Implementation as shown above\n  }\n);\n\n// Main function\n// For stdio (local):\nasync function runStdio() {\n  if (!process.env.EXAMPLE_API_KEY) {\n    console.error(\"ERROR: EXAMPLE_API_KEY environment variable is required\");\n    process.exit(1);\n  }\n\n  const transport = new StdioServerTransport();\n  await server.connect(transport);\n  console.error(\"MCP server running via stdio\");\n}\n\n// For streamable HTTP (remote):\nasync function runHTTP() {\n  if (!process.env.EXAMPLE_API_KEY) {\n    console.error(\"ERROR: EXAMPLE_API_KEY environment variable is required\");\n    process.exit(1);\n  }\n\n  const app = express();\n  app.use(express.json());\n\n  app.post('/mcp', async (req, res) => {\n    const transport = new StreamableHTTPServerTransport({\n      sessionIdGenerator: undefined,\n      enableJsonResponse: true\n    });\n    res.on('close', () => transport.close());\n    await server.connect(transport);\n    await transport.handleRequest(req, res, req.body);\n  });\n\n  const port = parseInt(process.env.PORT || '3000');\n  app.listen(port, () => {\n    console.error(`MCP server running on http://localhost:${port}/mcp`);\n  });\n}\n\n// Choose transport based on environment\nconst transport = process.env.TRANSPORT || 'stdio';\nif (transport === 'http') {\n  runHTTP().catch(error => {\n    console.error(\"Server error:\", error);\n    process.exit(1);\n  });\n} else {\n  runStdio().catch(error => {\n    console.error(\"Server error:\", error);\n    process.exit(1);\n  });\n}\n```\n\n---\n\n## Advanced MCP Features\n\n### Resource Registration\n\nExpose data as resources for efficient, URI-based access:\n\n```typescript\nimport { ResourceTemplate } from \"@modelcontextprotocol/sdk/types.js\";\n\n// Register a resource with URI template\nserver.registerResource(\n  {\n    uri: \"file://documents/{name}\",\n    name: \"Document Resource\",\n    description: \"Access documents by name\",\n    mimeType: \"text/plain\"\n  },\n  async (uri: string) => {\n    // Extract parameter from URI\n    const match = uri.match(/^file:\\/\\/documents\\/(.+)$/);\n    if (!match) {\n      throw new Error(\"Invalid URI format\");\n    }\n\n    const documentName = match[1];\n    const content = await loadDocument(documentName);\n\n    return {\n      contents: [{\n        uri,\n        mimeType: \"text/plain\",\n        text: content\n      }]\n    };\n  }\n);\n\n// List available resources dynamically\nserver.registerResourceList(async () => {\n  const documents = await getAvailableDocuments();\n  return {\n    resources: documents.map(doc => ({\n      uri: `file://documents/${doc.name}`,\n      name: doc.name,\n      mimeType: \"text/plain\",\n      description: doc.description\n    }))\n  };\n});\n```\n\n**When to use Resources vs Tools:**\n- **Resources**: For data access with simple URI-based parameters\n- **Tools**: For complex operations requiring validation and business logic\n- **Resources**: When data is relatively static or template-based\n- **Tools**: When operations have side effects or complex workflows\n\n### Transport Options\n\nThe TypeScript SDK supports two main transport mechanisms:\n\n#### Streamable HTTP (Recommended for Remote Servers)\n\n```typescript\nimport { StreamableHTTPServerTransport } from \"@modelcontextprotocol/sdk/server/streamableHttp.js\";\nimport express from \"express\";\n\nconst app = express();\napp.use(express.json());\n\napp.post('/mcp', async (req, res) => {\n  // Create new transport for each request (stateless, prevents request ID collisions)\n  const transport = new StreamableHTTPServerTransport({\n    sessionIdGenerator: undefined,\n    enableJsonResponse: true\n  });\n\n  res.on('close', () => transport.close());\n\n  await server.connect(transport);\n  await transport.handleRequest(req, res, req.body);\n});\n\napp.listen(3000);\n```\n\n#### stdio (For Local Integrations)\n\n```typescript\nimport { StdioServerTransport } from \"@modelcontextprotocol/sdk/server/stdio.js\";\n\nconst transport = new StdioServerTransport();\nawait server.connect(transport);\n```\n\n**Transport selection:**\n- **Streamable HTTP**: Web services, remote access, multiple clients\n- **stdio**: Command-line tools, local development, subprocess integration\n\n### Notification Support\n\nNotify clients when server state changes:\n\n```typescript\n// Notify when tools list changes\nserver.notification({\n  method: \"notifications/tools/list_changed\"\n});\n\n// Notify when resources change\nserver.notification({\n  method: \"notifications/resources/list_changed\"\n});\n```\n\nUse notifications sparingly - only when server capabilities genuinely change.\n\n---\n\n## Code Best Practices\n\n### Code Composability and Reusability\n\nYour implementation MUST prioritize composability and code reuse:\n\n1. **Extract Common Functionality**:\n   - Create reusable helper functions for operations used across multiple tools\n   - Build shared API clients for HTTP requests instead of duplicating code\n   - Centralize error handling logic in utility functions\n   - Extract business logic into dedicated functions that can be composed\n   - Extract shared markdown or JSON field selection & formatting functionality\n\n2. **Avoid Duplication**:\n   - NEVER copy-paste similar code between tools\n   - If you find yourself writing similar logic twice, extract it into a function\n   - Common operations like pagination, filtering, field selection, and formatting should be shared\n   - Authentication/authorization logic should be centralized\n\n## Building and Running\n\nAlways build your TypeScript code before running:\n\n```bash\n# Build the project\nnpm run build\n\n# Run the server\nnpm start\n\n# Development with auto-reload\nnpm run dev\n```\n\nAlways ensure `npm run build` completes successfully before considering the implementation complete.\n\n## Quality Checklist\n\nBefore finalizing your Node/TypeScript MCP server implementation, ensure:\n\n### Strategic Design\n- [ ] Tools enable complete workflows, not just API endpoint wrappers\n- [ ] Tool names reflect natural task subdivisions\n- [ ] Response formats optimize for agent context efficiency\n- [ ] Human-readable identifiers used where appropriate\n- [ ] Error messages guide agents toward correct usage\n\n### Implementation Quality\n- [ ] FOCUSED IMPLEMENTATION: Most important and valuable tools implemented\n- [ ] All tools registered using `registerTool` with complete configuration\n- [ ] All tools include `title`, `description`, `inputSchema`, and `annotations`\n- [ ] Annotations correctly set (readOnlyHint, destructiveHint, idempotentHint, openWorldHint)\n- [ ] All tools use Zod schemas for runtime input validation with `.strict()` enforcement\n- [ ] All Zod schemas have proper constraints and descriptive error messages\n- [ ] All tools have comprehensive descriptions with explicit input/output types\n- [ ] Descriptions include return value examples and complete schema documentation\n- [ ] Error messages are clear, actionable, and educational\n\n### TypeScript Quality\n- [ ] TypeScript interfaces are defined for all data structures\n- [ ] Strict TypeScript is enabled in tsconfig.json\n- [ ] No use of `any` type - use `unknown` or proper types instead\n- [ ] All async functions have explicit Promise<T> return types\n- [ ] Error handling uses proper type guards (e.g., `axios.isAxiosError`, `z.ZodError`)\n\n### Advanced Features (where applicable)\n- [ ] Resources registered for appropriate data endpoints\n- [ ] Appropriate transport configured (stdio or streamable HTTP)\n- [ ] Notifications implemented for dynamic server capabilities\n- [ ] Type-safe with SDK interfaces\n\n### Project Configuration\n- [ ] Package.json includes all necessary dependencies\n- [ ] Build script produces working JavaScript in dist/ directory\n- [ ] Main entry point is properly configured as dist/index.js\n- [ ] Server name follows format: `{service}-mcp-server`\n- [ ] tsconfig.json properly configured with strict mode\n\n### Code Quality\n- [ ] Pagination is properly implemented where applicable\n- [ ] Large responses check CHARACTER_LIMIT constant and truncate with clear messages\n- [ ] Filtering options are provided for potentially large result sets\n- [ ] All network operations handle timeouts and connection errors gracefully\n- [ ] Common functionality is extracted into reusable functions\n- [ ] Return types are consistent across similar operations\n\n### Testing and Build\n- [ ] `npm run build` completes successfully without errors\n- [ ] dist/index.js created and executable\n- [ ] Server runs: `node dist/index.js --help`\n- [ ] All imports resolve correctly\n- [ ] Sample tool calls work as expected",
        ".claude/skills/mcp-builder/reference/python_mcp_server.md": "# Python MCP Server Implementation Guide\n\n## Overview\n\nThis document provides Python-specific best practices and examples for implementing MCP servers using the MCP Python SDK. It covers server setup, tool registration patterns, input validation with Pydantic, error handling, and complete working examples.\n\n---\n\n## Quick Reference\n\n### Key Imports\n```python\nfrom mcp.server.fastmcp import FastMCP\nfrom pydantic import BaseModel, Field, field_validator, ConfigDict\nfrom typing import Optional, List, Dict, Any\nfrom enum import Enum\nimport httpx\n```\n\n### Server Initialization\n```python\nmcp = FastMCP(\"service_mcp\")\n```\n\n### Tool Registration Pattern\n```python\n@mcp.tool(name=\"tool_name\", annotations={...})\nasync def tool_function(params: InputModel) -> str:\n    # Implementation\n    pass\n```\n\n---\n\n## MCP Python SDK and FastMCP\n\nThe official MCP Python SDK provides FastMCP, a high-level framework for building MCP servers. It provides:\n- Automatic description and inputSchema generation from function signatures and docstrings\n- Pydantic model integration for input validation\n- Decorator-based tool registration with `@mcp.tool`\n\n**For complete SDK documentation, use WebFetch to load:**\n`https://raw.githubusercontent.com/modelcontextprotocol/python-sdk/main/README.md`\n\n## Server Naming Convention\n\nPython MCP servers must follow this naming pattern:\n- **Format**: `{service}_mcp` (lowercase with underscores)\n- **Examples**: `github_mcp`, `jira_mcp`, `stripe_mcp`\n\nThe name should be:\n- General (not tied to specific features)\n- Descriptive of the service/API being integrated\n- Easy to infer from the task description\n- Without version numbers or dates\n\n## Tool Implementation\n\n### Tool Naming\n\nUse snake_case for tool names (e.g., \"search_users\", \"create_project\", \"get_channel_info\") with clear, action-oriented names.\n\n**Avoid Naming Conflicts**: Include the service context to prevent overlaps:\n- Use \"slack_send_message\" instead of just \"send_message\"\n- Use \"github_create_issue\" instead of just \"create_issue\"\n- Use \"asana_list_tasks\" instead of just \"list_tasks\"\n\n### Tool Structure with FastMCP\n\nTools are defined using the `@mcp.tool` decorator with Pydantic models for input validation:\n\n```python\nfrom pydantic import BaseModel, Field, ConfigDict\nfrom mcp.server.fastmcp import FastMCP\n\n# Initialize the MCP server\nmcp = FastMCP(\"example_mcp\")\n\n# Define Pydantic model for input validation\nclass ServiceToolInput(BaseModel):\n    '''Input model for service tool operation.'''\n    model_config = ConfigDict(\n        str_strip_whitespace=True,  # Auto-strip whitespace from strings\n        validate_assignment=True,    # Validate on assignment\n        extra='forbid'              # Forbid extra fields\n    )\n\n    param1: str = Field(..., description=\"First parameter description (e.g., 'user123', 'project-abc')\", min_length=1, max_length=100)\n    param2: Optional[int] = Field(default=None, description=\"Optional integer parameter with constraints\", ge=0, le=1000)\n    tags: Optional[List[str]] = Field(default_factory=list, description=\"List of tags to apply\", max_items=10)\n\n@mcp.tool(\n    name=\"service_tool_name\",\n    annotations={\n        \"title\": \"Human-Readable Tool Title\",\n        \"readOnlyHint\": True,     # Tool does not modify environment\n        \"destructiveHint\": False,  # Tool does not perform destructive operations\n        \"idempotentHint\": True,    # Repeated calls have no additional effect\n        \"openWorldHint\": False     # Tool does not interact with external entities\n    }\n)\nasync def service_tool_name(params: ServiceToolInput) -> str:\n    '''Tool description automatically becomes the 'description' field.\n\n    This tool performs a specific operation on the service. It validates all inputs\n    using the ServiceToolInput Pydantic model before processing.\n\n    Args:\n        params (ServiceToolInput): Validated input parameters containing:\n            - param1 (str): First parameter description\n            - param2 (Optional[int]): Optional parameter with default\n            - tags (Optional[List[str]]): List of tags\n\n    Returns:\n        str: JSON-formatted response containing operation results\n    '''\n    # Implementation here\n    pass\n```\n\n## Pydantic v2 Key Features\n\n- Use `model_config` instead of nested `Config` class\n- Use `field_validator` instead of deprecated `validator`\n- Use `model_dump()` instead of deprecated `dict()`\n- Validators require `@classmethod` decorator\n- Type hints are required for validator methods\n\n```python\nfrom pydantic import BaseModel, Field, field_validator, ConfigDict\n\nclass CreateUserInput(BaseModel):\n    model_config = ConfigDict(\n        str_strip_whitespace=True,\n        validate_assignment=True\n    )\n\n    name: str = Field(..., description=\"User's full name\", min_length=1, max_length=100)\n    email: str = Field(..., description=\"User's email address\", pattern=r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$')\n    age: int = Field(..., description=\"User's age\", ge=0, le=150)\n\n    @field_validator('email')\n    @classmethod\n    def validate_email(cls, v: str) -> str:\n        if not v.strip():\n            raise ValueError(\"Email cannot be empty\")\n        return v.lower()\n```\n\n## Response Format Options\n\nSupport multiple output formats for flexibility:\n\n```python\nfrom enum import Enum\n\nclass ResponseFormat(str, Enum):\n    '''Output format for tool responses.'''\n    MARKDOWN = \"markdown\"\n    JSON = \"json\"\n\nclass UserSearchInput(BaseModel):\n    query: str = Field(..., description=\"Search query\")\n    response_format: ResponseFormat = Field(\n        default=ResponseFormat.MARKDOWN,\n        description=\"Output format: 'markdown' for human-readable or 'json' for machine-readable\"\n    )\n```\n\n**Markdown format**:\n- Use headers, lists, and formatting for clarity\n- Convert timestamps to human-readable format (e.g., \"2024-01-15 10:30:00 UTC\" instead of epoch)\n- Show display names with IDs in parentheses (e.g., \"@john.doe (U123456)\")\n- Omit verbose metadata (e.g., show only one profile image URL, not all sizes)\n- Group related information logically\n\n**JSON format**:\n- Return complete, structured data suitable for programmatic processing\n- Include all available fields and metadata\n- Use consistent field names and types\n\n## Pagination Implementation\n\nFor tools that list resources:\n\n```python\nclass ListInput(BaseModel):\n    limit: Optional[int] = Field(default=20, description=\"Maximum results to return\", ge=1, le=100)\n    offset: Optional[int] = Field(default=0, description=\"Number of results to skip for pagination\", ge=0)\n\nasync def list_items(params: ListInput) -> str:\n    # Make API request with pagination\n    data = await api_request(limit=params.limit, offset=params.offset)\n\n    # Return pagination info\n    response = {\n        \"total\": data[\"total\"],\n        \"count\": len(data[\"items\"]),\n        \"offset\": params.offset,\n        \"items\": data[\"items\"],\n        \"has_more\": data[\"total\"] > params.offset + len(data[\"items\"]),\n        \"next_offset\": params.offset + len(data[\"items\"]) if data[\"total\"] > params.offset + len(data[\"items\"]) else None\n    }\n    return json.dumps(response, indent=2)\n```\n\n## Error Handling\n\nProvide clear, actionable error messages:\n\n```python\ndef _handle_api_error(e: Exception) -> str:\n    '''Consistent error formatting across all tools.'''\n    if isinstance(e, httpx.HTTPStatusError):\n        if e.response.status_code == 404:\n            return \"Error: Resource not found. Please check the ID is correct.\"\n        elif e.response.status_code == 403:\n            return \"Error: Permission denied. You don't have access to this resource.\"\n        elif e.response.status_code == 429:\n            return \"Error: Rate limit exceeded. Please wait before making more requests.\"\n        return f\"Error: API request failed with status {e.response.status_code}\"\n    elif isinstance(e, httpx.TimeoutException):\n        return \"Error: Request timed out. Please try again.\"\n    return f\"Error: Unexpected error occurred: {type(e).__name__}\"\n```\n\n## Shared Utilities\n\nExtract common functionality into reusable functions:\n\n```python\n# Shared API request function\nasync def _make_api_request(endpoint: str, method: str = \"GET\", **kwargs) -> dict:\n    '''Reusable function for all API calls.'''\n    async with httpx.AsyncClient() as client:\n        response = await client.request(\n            method,\n            f\"{API_BASE_URL}/{endpoint}\",\n            timeout=30.0,\n            **kwargs\n        )\n        response.raise_for_status()\n        return response.json()\n```\n\n## Async/Await Best Practices\n\nAlways use async/await for network requests and I/O operations:\n\n```python\n# Good: Async network request\nasync def fetch_data(resource_id: str) -> dict:\n    async with httpx.AsyncClient() as client:\n        response = await client.get(f\"{API_URL}/resource/{resource_id}\")\n        response.raise_for_status()\n        return response.json()\n\n# Bad: Synchronous request\ndef fetch_data(resource_id: str) -> dict:\n    response = requests.get(f\"{API_URL}/resource/{resource_id}\")  # Blocks\n    return response.json()\n```\n\n## Type Hints\n\nUse type hints throughout:\n\n```python\nfrom typing import Optional, List, Dict, Any\n\nasync def get_user(user_id: str) -> Dict[str, Any]:\n    data = await fetch_user(user_id)\n    return {\"id\": data[\"id\"], \"name\": data[\"name\"]}\n```\n\n## Tool Docstrings\n\nEvery tool must have comprehensive docstrings with explicit type information:\n\n```python\nasync def search_users(params: UserSearchInput) -> str:\n    '''\n    Search for users in the Example system by name, email, or team.\n\n    This tool searches across all user profiles in the Example platform,\n    supporting partial matches and various search filters. It does NOT\n    create or modify users, only searches existing ones.\n\n    Args:\n        params (UserSearchInput): Validated input parameters containing:\n            - query (str): Search string to match against names/emails (e.g., \"john\", \"@example.com\", \"team:marketing\")\n            - limit (Optional[int]): Maximum results to return, between 1-100 (default: 20)\n            - offset (Optional[int]): Number of results to skip for pagination (default: 0)\n\n    Returns:\n        str: JSON-formatted string containing search results with the following schema:\n\n        Success response:\n        {\n            \"total\": int,           # Total number of matches found\n            \"count\": int,           # Number of results in this response\n            \"offset\": int,          # Current pagination offset\n            \"users\": [\n                {\n                    \"id\": str,      # User ID (e.g., \"U123456789\")\n                    \"name\": str,    # Full name (e.g., \"John Doe\")\n                    \"email\": str,   # Email address (e.g., \"john@example.com\")\n                    \"team\": str     # Team name (e.g., \"Marketing\") - optional\n                }\n            ]\n        }\n\n        Error response:\n        \"Error: <error message>\" or \"No users found matching '<query>'\"\n\n    Examples:\n        - Use when: \"Find all marketing team members\" -> params with query=\"team:marketing\"\n        - Use when: \"Search for John's account\" -> params with query=\"john\"\n        - Don't use when: You need to create a user (use example_create_user instead)\n        - Don't use when: You have a user ID and need full details (use example_get_user instead)\n\n    Error Handling:\n        - Input validation errors are handled by Pydantic model\n        - Returns \"Error: Rate limit exceeded\" if too many requests (429 status)\n        - Returns \"Error: Invalid API authentication\" if API key is invalid (401 status)\n        - Returns formatted list of results or \"No users found matching 'query'\"\n    '''\n```\n\n## Complete Example\n\nSee below for a complete Python MCP server example:\n\n```python\n#!/usr/bin/env python3\n'''\nMCP Server for Example Service.\n\nThis server provides tools to interact with Example API, including user search,\nproject management, and data export capabilities.\n'''\n\nfrom typing import Optional, List, Dict, Any\nfrom enum import Enum\nimport httpx\nfrom pydantic import BaseModel, Field, field_validator, ConfigDict\nfrom mcp.server.fastmcp import FastMCP\n\n# Initialize the MCP server\nmcp = FastMCP(\"example_mcp\")\n\n# Constants\nAPI_BASE_URL = \"https://api.example.com/v1\"\n\n# Enums\nclass ResponseFormat(str, Enum):\n    '''Output format for tool responses.'''\n    MARKDOWN = \"markdown\"\n    JSON = \"json\"\n\n# Pydantic Models for Input Validation\nclass UserSearchInput(BaseModel):\n    '''Input model for user search operations.'''\n    model_config = ConfigDict(\n        str_strip_whitespace=True,\n        validate_assignment=True\n    )\n\n    query: str = Field(..., description=\"Search string to match against names/emails\", min_length=2, max_length=200)\n    limit: Optional[int] = Field(default=20, description=\"Maximum results to return\", ge=1, le=100)\n    offset: Optional[int] = Field(default=0, description=\"Number of results to skip for pagination\", ge=0)\n    response_format: ResponseFormat = Field(default=ResponseFormat.MARKDOWN, description=\"Output format\")\n\n    @field_validator('query')\n    @classmethod\n    def validate_query(cls, v: str) -> str:\n        if not v.strip():\n            raise ValueError(\"Query cannot be empty or whitespace only\")\n        return v.strip()\n\n# Shared utility functions\nasync def _make_api_request(endpoint: str, method: str = \"GET\", **kwargs) -> dict:\n    '''Reusable function for all API calls.'''\n    async with httpx.AsyncClient() as client:\n        response = await client.request(\n            method,\n            f\"{API_BASE_URL}/{endpoint}\",\n            timeout=30.0,\n            **kwargs\n        )\n        response.raise_for_status()\n        return response.json()\n\ndef _handle_api_error(e: Exception) -> str:\n    '''Consistent error formatting across all tools.'''\n    if isinstance(e, httpx.HTTPStatusError):\n        if e.response.status_code == 404:\n            return \"Error: Resource not found. Please check the ID is correct.\"\n        elif e.response.status_code == 403:\n            return \"Error: Permission denied. You don't have access to this resource.\"\n        elif e.response.status_code == 429:\n            return \"Error: Rate limit exceeded. Please wait before making more requests.\"\n        return f\"Error: API request failed with status {e.response.status_code}\"\n    elif isinstance(e, httpx.TimeoutException):\n        return \"Error: Request timed out. Please try again.\"\n    return f\"Error: Unexpected error occurred: {type(e).__name__}\"\n\n# Tool definitions\n@mcp.tool(\n    name=\"example_search_users\",\n    annotations={\n        \"title\": \"Search Example Users\",\n        \"readOnlyHint\": True,\n        \"destructiveHint\": False,\n        \"idempotentHint\": True,\n        \"openWorldHint\": True\n    }\n)\nasync def example_search_users(params: UserSearchInput) -> str:\n    '''Search for users in the Example system by name, email, or team.\n\n    [Full docstring as shown above]\n    '''\n    try:\n        # Make API request using validated parameters\n        data = await _make_api_request(\n            \"users/search\",\n            params={\n                \"q\": params.query,\n                \"limit\": params.limit,\n                \"offset\": params.offset\n            }\n        )\n\n        users = data.get(\"users\", [])\n        total = data.get(\"total\", 0)\n\n        if not users:\n            return f\"No users found matching '{params.query}'\"\n\n        # Format response based on requested format\n        if params.response_format == ResponseFormat.MARKDOWN:\n            lines = [f\"# User Search Results: '{params.query}'\", \"\"]\n            lines.append(f\"Found {total} users (showing {len(users)})\")\n            lines.append(\"\")\n\n            for user in users:\n                lines.append(f\"## {user['name']} ({user['id']})\")\n                lines.append(f\"- **Email**: {user['email']}\")\n                if user.get('team'):\n                    lines.append(f\"- **Team**: {user['team']}\")\n                lines.append(\"\")\n\n            return \"\\n\".join(lines)\n\n        else:\n            # Machine-readable JSON format\n            import json\n            response = {\n                \"total\": total,\n                \"count\": len(users),\n                \"offset\": params.offset,\n                \"users\": users\n            }\n            return json.dumps(response, indent=2)\n\n    except Exception as e:\n        return _handle_api_error(e)\n\nif __name__ == \"__main__\":\n    mcp.run()\n```\n\n---\n\n## Advanced FastMCP Features\n\n### Context Parameter Injection\n\nFastMCP can automatically inject a `Context` parameter into tools for advanced capabilities like logging, progress reporting, resource reading, and user interaction:\n\n```python\nfrom mcp.server.fastmcp import FastMCP, Context\n\nmcp = FastMCP(\"example_mcp\")\n\n@mcp.tool()\nasync def advanced_search(query: str, ctx: Context) -> str:\n    '''Advanced tool with context access for logging and progress.'''\n\n    # Report progress for long operations\n    await ctx.report_progress(0.25, \"Starting search...\")\n\n    # Log information for debugging\n    await ctx.log_info(\"Processing query\", {\"query\": query, \"timestamp\": datetime.now()})\n\n    # Perform search\n    results = await search_api(query)\n    await ctx.report_progress(0.75, \"Formatting results...\")\n\n    # Access server configuration\n    server_name = ctx.fastmcp.name\n\n    return format_results(results)\n\n@mcp.tool()\nasync def interactive_tool(resource_id: str, ctx: Context) -> str:\n    '''Tool that can request additional input from users.'''\n\n    # Request sensitive information when needed\n    api_key = await ctx.elicit(\n        prompt=\"Please provide your API key:\",\n        input_type=\"password\"\n    )\n\n    # Use the provided key\n    return await api_call(resource_id, api_key)\n```\n\n**Context capabilities:**\n- `ctx.report_progress(progress, message)` - Report progress for long operations\n- `ctx.log_info(message, data)` / `ctx.log_error()` / `ctx.log_debug()` - Logging\n- `ctx.elicit(prompt, input_type)` - Request input from users\n- `ctx.fastmcp.name` - Access server configuration\n- `ctx.read_resource(uri)` - Read MCP resources\n\n### Resource Registration\n\nExpose data as resources for efficient, template-based access:\n\n```python\n@mcp.resource(\"file://documents/{name}\")\nasync def get_document(name: str) -> str:\n    '''Expose documents as MCP resources.\n\n    Resources are useful for static or semi-static data that doesn't\n    require complex parameters. They use URI templates for flexible access.\n    '''\n    document_path = f\"./docs/{name}\"\n    with open(document_path, \"r\") as f:\n        return f.read()\n\n@mcp.resource(\"config://settings/{key}\")\nasync def get_setting(key: str, ctx: Context) -> str:\n    '''Expose configuration as resources with context.'''\n    settings = await load_settings()\n    return json.dumps(settings.get(key, {}))\n```\n\n**When to use Resources vs Tools:**\n- **Resources**: For data access with simple parameters (URI templates)\n- **Tools**: For complex operations with validation and business logic\n\n### Structured Output Types\n\nFastMCP supports multiple return types beyond strings:\n\n```python\nfrom typing import TypedDict\nfrom dataclasses import dataclass\nfrom pydantic import BaseModel\n\n# TypedDict for structured returns\nclass UserData(TypedDict):\n    id: str\n    name: str\n    email: str\n\n@mcp.tool()\nasync def get_user_typed(user_id: str) -> UserData:\n    '''Returns structured data - FastMCP handles serialization.'''\n    return {\"id\": user_id, \"name\": \"John Doe\", \"email\": \"john@example.com\"}\n\n# Pydantic models for complex validation\nclass DetailedUser(BaseModel):\n    id: str\n    name: str\n    email: str\n    created_at: datetime\n    metadata: Dict[str, Any]\n\n@mcp.tool()\nasync def get_user_detailed(user_id: str) -> DetailedUser:\n    '''Returns Pydantic model - automatically generates schema.'''\n    user = await fetch_user(user_id)\n    return DetailedUser(**user)\n```\n\n### Lifespan Management\n\nInitialize resources that persist across requests:\n\n```python\nfrom contextlib import asynccontextmanager\n\n@asynccontextmanager\nasync def app_lifespan():\n    '''Manage resources that live for the server's lifetime.'''\n    # Initialize connections, load config, etc.\n    db = await connect_to_database()\n    config = load_configuration()\n\n    # Make available to all tools\n    yield {\"db\": db, \"config\": config}\n\n    # Cleanup on shutdown\n    await db.close()\n\nmcp = FastMCP(\"example_mcp\", lifespan=app_lifespan)\n\n@mcp.tool()\nasync def query_data(query: str, ctx: Context) -> str:\n    '''Access lifespan resources through context.'''\n    db = ctx.request_context.lifespan_state[\"db\"]\n    results = await db.query(query)\n    return format_results(results)\n```\n\n### Transport Options\n\nFastMCP supports two main transport mechanisms:\n\n```python\n# stdio transport (for local tools) - default\nif __name__ == \"__main__\":\n    mcp.run()\n\n# Streamable HTTP transport (for remote servers)\nif __name__ == \"__main__\":\n    mcp.run(transport=\"streamable_http\", port=8000)\n```\n\n**Transport selection:**\n- **stdio**: Command-line tools, local integrations, subprocess execution\n- **Streamable HTTP**: Web services, remote access, multiple clients\n\n---\n\n## Code Best Practices\n\n### Code Composability and Reusability\n\nYour implementation MUST prioritize composability and code reuse:\n\n1. **Extract Common Functionality**:\n   - Create reusable helper functions for operations used across multiple tools\n   - Build shared API clients for HTTP requests instead of duplicating code\n   - Centralize error handling logic in utility functions\n   - Extract business logic into dedicated functions that can be composed\n   - Extract shared markdown or JSON field selection & formatting functionality\n\n2. **Avoid Duplication**:\n   - NEVER copy-paste similar code between tools\n   - If you find yourself writing similar logic twice, extract it into a function\n   - Common operations like pagination, filtering, field selection, and formatting should be shared\n   - Authentication/authorization logic should be centralized\n\n### Python-Specific Best Practices\n\n1. **Use Type Hints**: Always include type annotations for function parameters and return values\n2. **Pydantic Models**: Define clear Pydantic models for all input validation\n3. **Avoid Manual Validation**: Let Pydantic handle input validation with constraints\n4. **Proper Imports**: Group imports (standard library, third-party, local)\n5. **Error Handling**: Use specific exception types (httpx.HTTPStatusError, not generic Exception)\n6. **Async Context Managers**: Use `async with` for resources that need cleanup\n7. **Constants**: Define module-level constants in UPPER_CASE\n\n## Quality Checklist\n\nBefore finalizing your Python MCP server implementation, ensure:\n\n### Strategic Design\n- [ ] Tools enable complete workflows, not just API endpoint wrappers\n- [ ] Tool names reflect natural task subdivisions\n- [ ] Response formats optimize for agent context efficiency\n- [ ] Human-readable identifiers used where appropriate\n- [ ] Error messages guide agents toward correct usage\n\n### Implementation Quality\n- [ ] FOCUSED IMPLEMENTATION: Most important and valuable tools implemented\n- [ ] All tools have descriptive names and documentation\n- [ ] Return types are consistent across similar operations\n- [ ] Error handling is implemented for all external calls\n- [ ] Server name follows format: `{service}_mcp`\n- [ ] All network operations use async/await\n- [ ] Common functionality is extracted into reusable functions\n- [ ] Error messages are clear, actionable, and educational\n- [ ] Outputs are properly validated and formatted\n\n### Tool Configuration\n- [ ] All tools implement 'name' and 'annotations' in the decorator\n- [ ] Annotations correctly set (readOnlyHint, destructiveHint, idempotentHint, openWorldHint)\n- [ ] All tools use Pydantic BaseModel for input validation with Field() definitions\n- [ ] All Pydantic Fields have explicit types and descriptions with constraints\n- [ ] All tools have comprehensive docstrings with explicit input/output types\n- [ ] Docstrings include complete schema structure for dict/JSON returns\n- [ ] Pydantic models handle input validation (no manual validation needed)\n\n### Advanced Features (where applicable)\n- [ ] Context injection used for logging, progress, or elicitation\n- [ ] Resources registered for appropriate data endpoints\n- [ ] Lifespan management implemented for persistent connections\n- [ ] Structured output types used (TypedDict, Pydantic models)\n- [ ] Appropriate transport configured (stdio or streamable HTTP)\n\n### Code Quality\n- [ ] File includes proper imports including Pydantic imports\n- [ ] Pagination is properly implemented where applicable\n- [ ] Filtering options are provided for potentially large result sets\n- [ ] All async functions are properly defined with `async def`\n- [ ] HTTP client usage follows async patterns with proper context managers\n- [ ] Type hints are used throughout the code\n- [ ] Constants are defined at module level in UPPER_CASE\n\n### Testing\n- [ ] Server runs successfully: `python your_server.py --help`\n- [ ] All imports resolve correctly\n- [ ] Sample tool calls work as expected\n- [ ] Error scenarios handled gracefully",
        ".claude/skills/pdf/SKILL.md": "---\nname: pdf\ndescription: Comprehensive PDF manipulation toolkit for extracting text and tables, creating new PDFs, merging/splitting documents, and handling forms. When Claude needs to fill in a PDF form or programmatically process, generate, or analyze PDF documents at scale.\nlicense: Proprietary. LICENSE.txt has complete terms\n---\n\n# PDF Processing Guide\n\n## Overview\n\nThis guide covers essential PDF processing operations using Python libraries and command-line tools. For advanced features, JavaScript libraries, and detailed examples, see reference.md. If you need to fill out a PDF form, read forms.md and follow its instructions.\n\n## Quick Start\n\n```python\nfrom pypdf import PdfReader, PdfWriter\n\n# Read a PDF\nreader = PdfReader(\"document.pdf\")\nprint(f\"Pages: {len(reader.pages)}\")\n\n# Extract text\ntext = \"\"\nfor page in reader.pages:\n    text += page.extract_text()\n```\n\n## Python Libraries\n\n### pypdf - Basic Operations\n\n#### Merge PDFs\n```python\nfrom pypdf import PdfWriter, PdfReader\n\nwriter = PdfWriter()\nfor pdf_file in [\"doc1.pdf\", \"doc2.pdf\", \"doc3.pdf\"]:\n    reader = PdfReader(pdf_file)\n    for page in reader.pages:\n        writer.add_page(page)\n\nwith open(\"merged.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n#### Split PDF\n```python\nreader = PdfReader(\"input.pdf\")\nfor i, page in enumerate(reader.pages):\n    writer = PdfWriter()\n    writer.add_page(page)\n    with open(f\"page_{i+1}.pdf\", \"wb\") as output:\n        writer.write(output)\n```\n\n#### Extract Metadata\n```python\nreader = PdfReader(\"document.pdf\")\nmeta = reader.metadata\nprint(f\"Title: {meta.title}\")\nprint(f\"Author: {meta.author}\")\nprint(f\"Subject: {meta.subject}\")\nprint(f\"Creator: {meta.creator}\")\n```\n\n#### Rotate Pages\n```python\nreader = PdfReader(\"input.pdf\")\nwriter = PdfWriter()\n\npage = reader.pages[0]\npage.rotate(90)  # Rotate 90 degrees clockwise\nwriter.add_page(page)\n\nwith open(\"rotated.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n### pdfplumber - Text and Table Extraction\n\n#### Extract Text with Layout\n```python\nimport pdfplumber\n\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    for page in pdf.pages:\n        text = page.extract_text()\n        print(text)\n```\n\n#### Extract Tables\n```python\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    for i, page in enumerate(pdf.pages):\n        tables = page.extract_tables()\n        for j, table in enumerate(tables):\n            print(f\"Table {j+1} on page {i+1}:\")\n            for row in table:\n                print(row)\n```\n\n#### Advanced Table Extraction\n```python\nimport pandas as pd\n\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    all_tables = []\n    for page in pdf.pages:\n        tables = page.extract_tables()\n        for table in tables:\n            if table:  # Check if table is not empty\n                df = pd.DataFrame(table[1:], columns=table[0])\n                all_tables.append(df)\n\n# Combine all tables\nif all_tables:\n    combined_df = pd.concat(all_tables, ignore_index=True)\n    combined_df.to_excel(\"extracted_tables.xlsx\", index=False)\n```\n\n### reportlab - Create PDFs\n\n#### Basic PDF Creation\n```python\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.pdfgen import canvas\n\nc = canvas.Canvas(\"hello.pdf\", pagesize=letter)\nwidth, height = letter\n\n# Add text\nc.drawString(100, height - 100, \"Hello World!\")\nc.drawString(100, height - 120, \"This is a PDF created with reportlab\")\n\n# Add a line\nc.line(100, height - 140, 400, height - 140)\n\n# Save\nc.save()\n```\n\n#### Create PDF with Multiple Pages\n```python\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak\nfrom reportlab.lib.styles import getSampleStyleSheet\n\ndoc = SimpleDocTemplate(\"report.pdf\", pagesize=letter)\nstyles = getSampleStyleSheet()\nstory = []\n\n# Add content\ntitle = Paragraph(\"Report Title\", styles['Title'])\nstory.append(title)\nstory.append(Spacer(1, 12))\n\nbody = Paragraph(\"This is the body of the report. \" * 20, styles['Normal'])\nstory.append(body)\nstory.append(PageBreak())\n\n# Page 2\nstory.append(Paragraph(\"Page 2\", styles['Heading1']))\nstory.append(Paragraph(\"Content for page 2\", styles['Normal']))\n\n# Build PDF\ndoc.build(story)\n```\n\n## Command-Line Tools\n\n### pdftotext (poppler-utils)\n```bash\n# Extract text\npdftotext input.pdf output.txt\n\n# Extract text preserving layout\npdftotext -layout input.pdf output.txt\n\n# Extract specific pages\npdftotext -f 1 -l 5 input.pdf output.txt  # Pages 1-5\n```\n\n### qpdf\n```bash\n# Merge PDFs\nqpdf --empty --pages file1.pdf file2.pdf -- merged.pdf\n\n# Split pages\nqpdf input.pdf --pages . 1-5 -- pages1-5.pdf\nqpdf input.pdf --pages . 6-10 -- pages6-10.pdf\n\n# Rotate pages\nqpdf input.pdf output.pdf --rotate=+90:1  # Rotate page 1 by 90 degrees\n\n# Remove password\nqpdf --password=mypassword --decrypt encrypted.pdf decrypted.pdf\n```\n\n### pdftk (if available)\n```bash\n# Merge\npdftk file1.pdf file2.pdf cat output merged.pdf\n\n# Split\npdftk input.pdf burst\n\n# Rotate\npdftk input.pdf rotate 1east output rotated.pdf\n```\n\n## Common Tasks\n\n### Extract Text from Scanned PDFs\n```python\n# Requires: pip install pytesseract pdf2image\nimport pytesseract\nfrom pdf2image import convert_from_path\n\n# Convert PDF to images\nimages = convert_from_path('scanned.pdf')\n\n# OCR each page\ntext = \"\"\nfor i, image in enumerate(images):\n    text += f\"Page {i+1}:\\n\"\n    text += pytesseract.image_to_string(image)\n    text += \"\\n\\n\"\n\nprint(text)\n```\n\n### Add Watermark\n```python\nfrom pypdf import PdfReader, PdfWriter\n\n# Create watermark (or load existing)\nwatermark = PdfReader(\"watermark.pdf\").pages[0]\n\n# Apply to all pages\nreader = PdfReader(\"document.pdf\")\nwriter = PdfWriter()\n\nfor page in reader.pages:\n    page.merge_page(watermark)\n    writer.add_page(page)\n\nwith open(\"watermarked.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n### Extract Images\n```bash\n# Using pdfimages (poppler-utils)\npdfimages -j input.pdf output_prefix\n\n# This extracts all images as output_prefix-000.jpg, output_prefix-001.jpg, etc.\n```\n\n### Password Protection\n```python\nfrom pypdf import PdfReader, PdfWriter\n\nreader = PdfReader(\"input.pdf\")\nwriter = PdfWriter()\n\nfor page in reader.pages:\n    writer.add_page(page)\n\n# Add password\nwriter.encrypt(\"userpassword\", \"ownerpassword\")\n\nwith open(\"encrypted.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n## Quick Reference\n\n| Task | Best Tool | Command/Code |\n|------|-----------|--------------|\n| Merge PDFs | pypdf | `writer.add_page(page)` |\n| Split PDFs | pypdf | One page per file |\n| Extract text | pdfplumber | `page.extract_text()` |\n| Extract tables | pdfplumber | `page.extract_tables()` |\n| Create PDFs | reportlab | Canvas or Platypus |\n| Command line merge | qpdf | `qpdf --empty --pages ...` |\n| OCR scanned PDFs | pytesseract | Convert to image first |\n| Fill PDF forms | pdf-lib or pypdf (see forms.md) | See forms.md |\n\n## Next Steps\n\n- For advanced pypdfium2 usage, see reference.md\n- For JavaScript libraries (pdf-lib), see reference.md\n- If you need to fill out a PDF form, follow the instructions in forms.md\n- For troubleshooting guides, see reference.md\n",
        ".claude/skills/pdf/forms.md": "**CRITICAL: You MUST complete these steps in order. Do not skip ahead to writing code.**\n\nIf you need to fill out a PDF form, first check to see if the PDF has fillable form fields. Run this script from this file's directory:\n `python scripts/check_fillable_fields <file.pdf>`, and depending on the result go to either the \"Fillable fields\" or \"Non-fillable fields\" and follow those instructions.\n\n# Fillable fields\nIf the PDF has fillable form fields:\n- Run this script from this file's directory: `python scripts/extract_form_field_info.py <input.pdf> <field_info.json>`. It will create a JSON file with a list of fields in this format:\n```\n[\n  {\n    \"field_id\": (unique ID for the field),\n    \"page\": (page number, 1-based),\n    \"rect\": ([left, bottom, right, top] bounding box in PDF coordinates, y=0 is the bottom of the page),\n    \"type\": (\"text\", \"checkbox\", \"radio_group\", or \"choice\"),\n  },\n  // Checkboxes have \"checked_value\" and \"unchecked_value\" properties:\n  {\n    \"field_id\": (unique ID for the field),\n    \"page\": (page number, 1-based),\n    \"type\": \"checkbox\",\n    \"checked_value\": (Set the field to this value to check the checkbox),\n    \"unchecked_value\": (Set the field to this value to uncheck the checkbox),\n  },\n  // Radio groups have a \"radio_options\" list with the possible choices.\n  {\n    \"field_id\": (unique ID for the field),\n    \"page\": (page number, 1-based),\n    \"type\": \"radio_group\",\n    \"radio_options\": [\n      {\n        \"value\": (set the field to this value to select this radio option),\n        \"rect\": (bounding box for the radio button for this option)\n      },\n      // Other radio options\n    ]\n  },\n  // Multiple choice fields have a \"choice_options\" list with the possible choices:\n  {\n    \"field_id\": (unique ID for the field),\n    \"page\": (page number, 1-based),\n    \"type\": \"choice\",\n    \"choice_options\": [\n      {\n        \"value\": (set the field to this value to select this option),\n        \"text\": (display text of the option)\n      },\n      // Other choice options\n    ],\n  }\n]\n```\n- Convert the PDF to PNGs (one image for each page) with this script (run from this file's directory):\n`python scripts/convert_pdf_to_images.py <file.pdf> <output_directory>`\nThen analyze the images to determine the purpose of each form field (make sure to convert the bounding box PDF coordinates to image coordinates).\n- Create a `field_values.json` file in this format with the values to be entered for each field:\n```\n[\n  {\n    \"field_id\": \"last_name\", // Must match the field_id from `extract_form_field_info.py`\n    \"description\": \"The user's last name\",\n    \"page\": 1, // Must match the \"page\" value in field_info.json\n    \"value\": \"Simpson\"\n  },\n  {\n    \"field_id\": \"Checkbox12\",\n    \"description\": \"Checkbox to be checked if the user is 18 or over\",\n    \"page\": 1,\n    \"value\": \"/On\" // If this is a checkbox, use its \"checked_value\" value to check it. If it's a radio button group, use one of the \"value\" values in \"radio_options\".\n  },\n  // more fields\n]\n```\n- Run the `fill_fillable_fields.py` script from this file's directory to create a filled-in PDF:\n`python scripts/fill_fillable_fields.py <input pdf> <field_values.json> <output pdf>`\nThis script will verify that the field IDs and values you provide are valid; if it prints error messages, correct the appropriate fields and try again.\n\n# Non-fillable fields\nIf the PDF doesn't have fillable form fields, you'll need to visually determine where the data should be added and create text annotations. Follow the below steps *exactly*. You MUST perform all of these steps to ensure that the the form is accurately completed. Details for each step are below.\n- Convert the PDF to PNG images and determine field bounding boxes.\n- Create a JSON file with field information and validation images showing the bounding boxes.\n- Validate the the bounding boxes.\n- Use the bounding boxes to fill in the form.\n\n## Step 1: Visual Analysis (REQUIRED)\n- Convert the PDF to PNG images. Run this script from this file's directory:\n`python scripts/convert_pdf_to_images.py <file.pdf> <output_directory>`\nThe script will create a PNG image for each page in the PDF.\n- Carefully examine each PNG image and identify all form fields and areas where the user should enter data. For each form field where the user should enter text, determine bounding boxes for both the form field label, and the area where the user should enter text. The label and entry bounding boxes MUST NOT INTERSECT; the text entry box should only include the area where data should be entered. Usually this area will be immediately to the side, above, or below its label. Entry bounding boxes must be tall and wide enough to contain their text.\n\nThese are some examples of form structures that you might see:\n\n*Label inside box*\n```\n\n Name:                  \n\n```\nThe input area should be to the right of the \"Name\" label and extend to the edge of the box.\n\n*Label before line*\n```\nEmail: _______________________\n```\nThe input area should be above the line and include its entire width.\n\n*Label under line*\n```\n_________________________\nName\n```\nThe input area should be above the line and include the entire width of the line. This is common for signature and date fields.\n\n*Label above line*\n```\nPlease enter any special requests:\n________________________________________________\n```\nThe input area should extend from the bottom of the label to the line, and should include the entire width of the line.\n\n*Checkboxes*\n```\nAre you a US citizen? Yes   No \n```\nFor checkboxes:\n- Look for small square boxes () - these are the actual checkboxes to target. They may be to the left or right of their labels.\n- Distinguish between label text (\"Yes\", \"No\") and the clickable checkbox squares.\n- The entry bounding box should cover ONLY the small square, not the text label.\n\n### Step 2: Create fields.json and validation images (REQUIRED)\n- Create a file named `fields.json` with information for the form fields and bounding boxes in this format:\n```\n{\n  \"pages\": [\n    {\n      \"page_number\": 1,\n      \"image_width\": (first page image width in pixels),\n      \"image_height\": (first page image height in pixels),\n    },\n    {\n      \"page_number\": 2,\n      \"image_width\": (second page image width in pixels),\n      \"image_height\": (second page image height in pixels),\n    }\n    // additional pages\n  ],\n  \"form_fields\": [\n    // Example for a text field.\n    {\n      \"page_number\": 1,\n      \"description\": \"The user's last name should be entered here\",\n      // Bounding boxes are [left, top, right, bottom]. The bounding boxes for the label and text entry should not overlap.\n      \"field_label\": \"Last name\",\n      \"label_bounding_box\": [30, 125, 95, 142],\n      \"entry_bounding_box\": [100, 125, 280, 142],\n      \"entry_text\": {\n        \"text\": \"Johnson\", // This text will be added as an annotation at the entry_bounding_box location\n        \"font_size\": 14, // optional, defaults to 14\n        \"font_color\": \"000000\", // optional, RRGGBB format, defaults to 000000 (black)\n      }\n    },\n    // Example for a checkbox. TARGET THE SQUARE for the entry bounding box, NOT THE TEXT\n    {\n      \"page_number\": 2,\n      \"description\": \"Checkbox that should be checked if the user is over 18\",\n      \"entry_bounding_box\": [140, 525, 155, 540],  // Small box over checkbox square\n      \"field_label\": \"Yes\",\n      \"label_bounding_box\": [100, 525, 132, 540],  // Box containing \"Yes\" text\n      // Use \"X\" to check a checkbox.\n      \"entry_text\": {\n        \"text\": \"X\",\n      }\n    }\n    // additional form field entries\n  ]\n}\n```\n\nCreate validation images by running this script from this file's directory for each page:\n`python scripts/create_validation_image.py <page_number> <path_to_fields.json> <input_image_path> <output_image_path>\n\nThe validation images will have red rectangles where text should be entered, and blue rectangles covering label text.\n\n### Step 3: Validate Bounding Boxes (REQUIRED)\n#### Automated intersection check\n- Verify that none of bounding boxes intersect and that the entry bounding boxes are tall enough by checking the fields.json file with the `check_bounding_boxes.py` script (run from this file's directory):\n`python scripts/check_bounding_boxes.py <JSON file>`\n\nIf there are errors, reanalyze the relevant fields, adjust the bounding boxes, and iterate until there are no remaining errors. Remember: label (blue) bounding boxes should contain text labels, entry (red) boxes should not.\n\n#### Manual image inspection\n**CRITICAL: Do not proceed without visually inspecting validation images**\n- Red rectangles must ONLY cover input areas\n- Red rectangles MUST NOT contain any text\n- Blue rectangles should contain label text\n- For checkboxes:\n  - Red rectangle MUST be centered on the checkbox square\n  - Blue rectangle should cover the text label for the checkbox\n\n- If any rectangles look wrong, fix fields.json, regenerate the validation images, and verify again. Repeat this process until the bounding boxes are fully accurate.\n\n\n### Step 4: Add annotations to the PDF\nRun this script from this file's directory to create a filled-out PDF using the information in fields.json:\n`python scripts/fill_pdf_form_with_annotations.py <input_pdf_path> <path_to_fields.json> <output_pdf_path>\n",
        ".claude/skills/pdf/reference.md": "# PDF Processing Advanced Reference\n\nThis document contains advanced PDF processing features, detailed examples, and additional libraries not covered in the main skill instructions.\n\n## pypdfium2 Library (Apache/BSD License)\n\n### Overview\npypdfium2 is a Python binding for PDFium (Chromium's PDF library). It's excellent for fast PDF rendering, image generation, and serves as a PyMuPDF replacement.\n\n### Render PDF to Images\n```python\nimport pypdfium2 as pdfium\nfrom PIL import Image\n\n# Load PDF\npdf = pdfium.PdfDocument(\"document.pdf\")\n\n# Render page to image\npage = pdf[0]  # First page\nbitmap = page.render(\n    scale=2.0,  # Higher resolution\n    rotation=0  # No rotation\n)\n\n# Convert to PIL Image\nimg = bitmap.to_pil()\nimg.save(\"page_1.png\", \"PNG\")\n\n# Process multiple pages\nfor i, page in enumerate(pdf):\n    bitmap = page.render(scale=1.5)\n    img = bitmap.to_pil()\n    img.save(f\"page_{i+1}.jpg\", \"JPEG\", quality=90)\n```\n\n### Extract Text with pypdfium2\n```python\nimport pypdfium2 as pdfium\n\npdf = pdfium.PdfDocument(\"document.pdf\")\nfor i, page in enumerate(pdf):\n    text = page.get_text()\n    print(f\"Page {i+1} text length: {len(text)} chars\")\n```\n\n## JavaScript Libraries\n\n### pdf-lib (MIT License)\n\npdf-lib is a powerful JavaScript library for creating and modifying PDF documents in any JavaScript environment.\n\n#### Load and Manipulate Existing PDF\n```javascript\nimport { PDFDocument } from 'pdf-lib';\nimport fs from 'fs';\n\nasync function manipulatePDF() {\n    // Load existing PDF\n    const existingPdfBytes = fs.readFileSync('input.pdf');\n    const pdfDoc = await PDFDocument.load(existingPdfBytes);\n\n    // Get page count\n    const pageCount = pdfDoc.getPageCount();\n    console.log(`Document has ${pageCount} pages`);\n\n    // Add new page\n    const newPage = pdfDoc.addPage([600, 400]);\n    newPage.drawText('Added by pdf-lib', {\n        x: 100,\n        y: 300,\n        size: 16\n    });\n\n    // Save modified PDF\n    const pdfBytes = await pdfDoc.save();\n    fs.writeFileSync('modified.pdf', pdfBytes);\n}\n```\n\n#### Create Complex PDFs from Scratch\n```javascript\nimport { PDFDocument, rgb, StandardFonts } from 'pdf-lib';\nimport fs from 'fs';\n\nasync function createPDF() {\n    const pdfDoc = await PDFDocument.create();\n\n    // Add fonts\n    const helveticaFont = await pdfDoc.embedFont(StandardFonts.Helvetica);\n    const helveticaBold = await pdfDoc.embedFont(StandardFonts.HelveticaBold);\n\n    // Add page\n    const page = pdfDoc.addPage([595, 842]); // A4 size\n    const { width, height } = page.getSize();\n\n    // Add text with styling\n    page.drawText('Invoice #12345', {\n        x: 50,\n        y: height - 50,\n        size: 18,\n        font: helveticaBold,\n        color: rgb(0.2, 0.2, 0.8)\n    });\n\n    // Add rectangle (header background)\n    page.drawRectangle({\n        x: 40,\n        y: height - 100,\n        width: width - 80,\n        height: 30,\n        color: rgb(0.9, 0.9, 0.9)\n    });\n\n    // Add table-like content\n    const items = [\n        ['Item', 'Qty', 'Price', 'Total'],\n        ['Widget', '2', '$50', '$100'],\n        ['Gadget', '1', '$75', '$75']\n    ];\n\n    let yPos = height - 150;\n    items.forEach(row => {\n        let xPos = 50;\n        row.forEach(cell => {\n            page.drawText(cell, {\n                x: xPos,\n                y: yPos,\n                size: 12,\n                font: helveticaFont\n            });\n            xPos += 120;\n        });\n        yPos -= 25;\n    });\n\n    const pdfBytes = await pdfDoc.save();\n    fs.writeFileSync('created.pdf', pdfBytes);\n}\n```\n\n#### Advanced Merge and Split Operations\n```javascript\nimport { PDFDocument } from 'pdf-lib';\nimport fs from 'fs';\n\nasync function mergePDFs() {\n    // Create new document\n    const mergedPdf = await PDFDocument.create();\n\n    // Load source PDFs\n    const pdf1Bytes = fs.readFileSync('doc1.pdf');\n    const pdf2Bytes = fs.readFileSync('doc2.pdf');\n\n    const pdf1 = await PDFDocument.load(pdf1Bytes);\n    const pdf2 = await PDFDocument.load(pdf2Bytes);\n\n    // Copy pages from first PDF\n    const pdf1Pages = await mergedPdf.copyPages(pdf1, pdf1.getPageIndices());\n    pdf1Pages.forEach(page => mergedPdf.addPage(page));\n\n    // Copy specific pages from second PDF (pages 0, 2, 4)\n    const pdf2Pages = await mergedPdf.copyPages(pdf2, [0, 2, 4]);\n    pdf2Pages.forEach(page => mergedPdf.addPage(page));\n\n    const mergedPdfBytes = await mergedPdf.save();\n    fs.writeFileSync('merged.pdf', mergedPdfBytes);\n}\n```\n\n### pdfjs-dist (Apache License)\n\nPDF.js is Mozilla's JavaScript library for rendering PDFs in the browser.\n\n#### Basic PDF Loading and Rendering\n```javascript\nimport * as pdfjsLib from 'pdfjs-dist';\n\n// Configure worker (important for performance)\npdfjsLib.GlobalWorkerOptions.workerSrc = './pdf.worker.js';\n\nasync function renderPDF() {\n    // Load PDF\n    const loadingTask = pdfjsLib.getDocument('document.pdf');\n    const pdf = await loadingTask.promise;\n\n    console.log(`Loaded PDF with ${pdf.numPages} pages`);\n\n    // Get first page\n    const page = await pdf.getPage(1);\n    const viewport = page.getViewport({ scale: 1.5 });\n\n    // Render to canvas\n    const canvas = document.createElement('canvas');\n    const context = canvas.getContext('2d');\n    canvas.height = viewport.height;\n    canvas.width = viewport.width;\n\n    const renderContext = {\n        canvasContext: context,\n        viewport: viewport\n    };\n\n    await page.render(renderContext).promise;\n    document.body.appendChild(canvas);\n}\n```\n\n#### Extract Text with Coordinates\n```javascript\nimport * as pdfjsLib from 'pdfjs-dist';\n\nasync function extractText() {\n    const loadingTask = pdfjsLib.getDocument('document.pdf');\n    const pdf = await loadingTask.promise;\n\n    let fullText = '';\n\n    // Extract text from all pages\n    for (let i = 1; i <= pdf.numPages; i++) {\n        const page = await pdf.getPage(i);\n        const textContent = await page.getTextContent();\n\n        const pageText = textContent.items\n            .map(item => item.str)\n            .join(' ');\n\n        fullText += `\\n--- Page ${i} ---\\n${pageText}`;\n\n        // Get text with coordinates for advanced processing\n        const textWithCoords = textContent.items.map(item => ({\n            text: item.str,\n            x: item.transform[4],\n            y: item.transform[5],\n            width: item.width,\n            height: item.height\n        }));\n    }\n\n    console.log(fullText);\n    return fullText;\n}\n```\n\n#### Extract Annotations and Forms\n```javascript\nimport * as pdfjsLib from 'pdfjs-dist';\n\nasync function extractAnnotations() {\n    const loadingTask = pdfjsLib.getDocument('annotated.pdf');\n    const pdf = await loadingTask.promise;\n\n    for (let i = 1; i <= pdf.numPages; i++) {\n        const page = await pdf.getPage(i);\n        const annotations = await page.getAnnotations();\n\n        annotations.forEach(annotation => {\n            console.log(`Annotation type: ${annotation.subtype}`);\n            console.log(`Content: ${annotation.contents}`);\n            console.log(`Coordinates: ${JSON.stringify(annotation.rect)}`);\n        });\n    }\n}\n```\n\n## Advanced Command-Line Operations\n\n### poppler-utils Advanced Features\n\n#### Extract Text with Bounding Box Coordinates\n```bash\n# Extract text with bounding box coordinates (essential for structured data)\npdftotext -bbox-layout document.pdf output.xml\n\n# The XML output contains precise coordinates for each text element\n```\n\n#### Advanced Image Conversion\n```bash\n# Convert to PNG images with specific resolution\npdftoppm -png -r 300 document.pdf output_prefix\n\n# Convert specific page range with high resolution\npdftoppm -png -r 600 -f 1 -l 3 document.pdf high_res_pages\n\n# Convert to JPEG with quality setting\npdftoppm -jpeg -jpegopt quality=85 -r 200 document.pdf jpeg_output\n```\n\n#### Extract Embedded Images\n```bash\n# Extract all embedded images with metadata\npdfimages -j -p document.pdf page_images\n\n# List image info without extracting\npdfimages -list document.pdf\n\n# Extract images in their original format\npdfimages -all document.pdf images/img\n```\n\n### qpdf Advanced Features\n\n#### Complex Page Manipulation\n```bash\n# Split PDF into groups of pages\nqpdf --split-pages=3 input.pdf output_group_%02d.pdf\n\n# Extract specific pages with complex ranges\nqpdf input.pdf --pages input.pdf 1,3-5,8,10-end -- extracted.pdf\n\n# Merge specific pages from multiple PDFs\nqpdf --empty --pages doc1.pdf 1-3 doc2.pdf 5-7 doc3.pdf 2,4 -- combined.pdf\n```\n\n#### PDF Optimization and Repair\n```bash\n# Optimize PDF for web (linearize for streaming)\nqpdf --linearize input.pdf optimized.pdf\n\n# Remove unused objects and compress\nqpdf --optimize-level=all input.pdf compressed.pdf\n\n# Attempt to repair corrupted PDF structure\nqpdf --check input.pdf\nqpdf --fix-qdf damaged.pdf repaired.pdf\n\n# Show detailed PDF structure for debugging\nqpdf --show-all-pages input.pdf > structure.txt\n```\n\n#### Advanced Encryption\n```bash\n# Add password protection with specific permissions\nqpdf --encrypt user_pass owner_pass 256 --print=none --modify=none -- input.pdf encrypted.pdf\n\n# Check encryption status\nqpdf --show-encryption encrypted.pdf\n\n# Remove password protection (requires password)\nqpdf --password=secret123 --decrypt encrypted.pdf decrypted.pdf\n```\n\n## Advanced Python Techniques\n\n### pdfplumber Advanced Features\n\n#### Extract Text with Precise Coordinates\n```python\nimport pdfplumber\n\nwith pdfplumber.open(\"document.pdf\") as pdf:\n    page = pdf.pages[0]\n    \n    # Extract all text with coordinates\n    chars = page.chars\n    for char in chars[:10]:  # First 10 characters\n        print(f\"Char: '{char['text']}' at x:{char['x0']:.1f} y:{char['y0']:.1f}\")\n    \n    # Extract text by bounding box (left, top, right, bottom)\n    bbox_text = page.within_bbox((100, 100, 400, 200)).extract_text()\n```\n\n#### Advanced Table Extraction with Custom Settings\n```python\nimport pdfplumber\nimport pandas as pd\n\nwith pdfplumber.open(\"complex_table.pdf\") as pdf:\n    page = pdf.pages[0]\n    \n    # Extract tables with custom settings for complex layouts\n    table_settings = {\n        \"vertical_strategy\": \"lines\",\n        \"horizontal_strategy\": \"lines\",\n        \"snap_tolerance\": 3,\n        \"intersection_tolerance\": 15\n    }\n    tables = page.extract_tables(table_settings)\n    \n    # Visual debugging for table extraction\n    img = page.to_image(resolution=150)\n    img.save(\"debug_layout.png\")\n```\n\n### reportlab Advanced Features\n\n#### Create Professional Reports with Tables\n```python\nfrom reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph\nfrom reportlab.lib.styles import getSampleStyleSheet\nfrom reportlab.lib import colors\n\n# Sample data\ndata = [\n    ['Product', 'Q1', 'Q2', 'Q3', 'Q4'],\n    ['Widgets', '120', '135', '142', '158'],\n    ['Gadgets', '85', '92', '98', '105']\n]\n\n# Create PDF with table\ndoc = SimpleDocTemplate(\"report.pdf\")\nelements = []\n\n# Add title\nstyles = getSampleStyleSheet()\ntitle = Paragraph(\"Quarterly Sales Report\", styles['Title'])\nelements.append(title)\n\n# Add table with advanced styling\ntable = Table(data)\ntable.setStyle(TableStyle([\n    ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n    ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n    ('FONTSIZE', (0, 0), (-1, 0), 14),\n    ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n    ('BACKGROUND', (0, 1), (-1, -1), colors.beige),\n    ('GRID', (0, 0), (-1, -1), 1, colors.black)\n]))\nelements.append(table)\n\ndoc.build(elements)\n```\n\n## Complex Workflows\n\n### Extract Figures/Images from PDF\n\n#### Method 1: Using pdfimages (fastest)\n```bash\n# Extract all images with original quality\npdfimages -all document.pdf images/img\n```\n\n#### Method 2: Using pypdfium2 + Image Processing\n```python\nimport pypdfium2 as pdfium\nfrom PIL import Image\nimport numpy as np\n\ndef extract_figures(pdf_path, output_dir):\n    pdf = pdfium.PdfDocument(pdf_path)\n    \n    for page_num, page in enumerate(pdf):\n        # Render high-resolution page\n        bitmap = page.render(scale=3.0)\n        img = bitmap.to_pil()\n        \n        # Convert to numpy for processing\n        img_array = np.array(img)\n        \n        # Simple figure detection (non-white regions)\n        mask = np.any(img_array != [255, 255, 255], axis=2)\n        \n        # Find contours and extract bounding boxes\n        # (This is simplified - real implementation would need more sophisticated detection)\n        \n        # Save detected figures\n        # ... implementation depends on specific needs\n```\n\n### Batch PDF Processing with Error Handling\n```python\nimport os\nimport glob\nfrom pypdf import PdfReader, PdfWriter\nimport logging\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ndef batch_process_pdfs(input_dir, operation='merge'):\n    pdf_files = glob.glob(os.path.join(input_dir, \"*.pdf\"))\n    \n    if operation == 'merge':\n        writer = PdfWriter()\n        for pdf_file in pdf_files:\n            try:\n                reader = PdfReader(pdf_file)\n                for page in reader.pages:\n                    writer.add_page(page)\n                logger.info(f\"Processed: {pdf_file}\")\n            except Exception as e:\n                logger.error(f\"Failed to process {pdf_file}: {e}\")\n                continue\n        \n        with open(\"batch_merged.pdf\", \"wb\") as output:\n            writer.write(output)\n    \n    elif operation == 'extract_text':\n        for pdf_file in pdf_files:\n            try:\n                reader = PdfReader(pdf_file)\n                text = \"\"\n                for page in reader.pages:\n                    text += page.extract_text()\n                \n                output_file = pdf_file.replace('.pdf', '.txt')\n                with open(output_file, 'w', encoding='utf-8') as f:\n                    f.write(text)\n                logger.info(f\"Extracted text from: {pdf_file}\")\n                \n            except Exception as e:\n                logger.error(f\"Failed to extract text from {pdf_file}: {e}\")\n                continue\n```\n\n### Advanced PDF Cropping\n```python\nfrom pypdf import PdfWriter, PdfReader\n\nreader = PdfReader(\"input.pdf\")\nwriter = PdfWriter()\n\n# Crop page (left, bottom, right, top in points)\npage = reader.pages[0]\npage.mediabox.left = 50\npage.mediabox.bottom = 50\npage.mediabox.right = 550\npage.mediabox.top = 750\n\nwriter.add_page(page)\nwith open(\"cropped.pdf\", \"wb\") as output:\n    writer.write(output)\n```\n\n## Performance Optimization Tips\n\n### 1. For Large PDFs\n- Use streaming approaches instead of loading entire PDF in memory\n- Use `qpdf --split-pages` for splitting large files\n- Process pages individually with pypdfium2\n\n### 2. For Text Extraction\n- `pdftotext -bbox-layout` is fastest for plain text extraction\n- Use pdfplumber for structured data and tables\n- Avoid `pypdf.extract_text()` for very large documents\n\n### 3. For Image Extraction\n- `pdfimages` is much faster than rendering pages\n- Use low resolution for previews, high resolution for final output\n\n### 4. For Form Filling\n- pdf-lib maintains form structure better than most alternatives\n- Pre-validate form fields before processing\n\n### 5. Memory Management\n```python\n# Process PDFs in chunks\ndef process_large_pdf(pdf_path, chunk_size=10):\n    reader = PdfReader(pdf_path)\n    total_pages = len(reader.pages)\n    \n    for start_idx in range(0, total_pages, chunk_size):\n        end_idx = min(start_idx + chunk_size, total_pages)\n        writer = PdfWriter()\n        \n        for i in range(start_idx, end_idx):\n            writer.add_page(reader.pages[i])\n        \n        # Process chunk\n        with open(f\"chunk_{start_idx//chunk_size}.pdf\", \"wb\") as output:\n            writer.write(output)\n```\n\n## Troubleshooting Common Issues\n\n### Encrypted PDFs\n```python\n# Handle password-protected PDFs\nfrom pypdf import PdfReader\n\ntry:\n    reader = PdfReader(\"encrypted.pdf\")\n    if reader.is_encrypted:\n        reader.decrypt(\"password\")\nexcept Exception as e:\n    print(f\"Failed to decrypt: {e}\")\n```\n\n### Corrupted PDFs\n```bash\n# Use qpdf to repair\nqpdf --check corrupted.pdf\nqpdf --replace-input corrupted.pdf\n```\n\n### Text Extraction Issues\n```python\n# Fallback to OCR for scanned PDFs\nimport pytesseract\nfrom pdf2image import convert_from_path\n\ndef extract_text_with_ocr(pdf_path):\n    images = convert_from_path(pdf_path)\n    text = \"\"\n    for i, image in enumerate(images):\n        text += pytesseract.image_to_string(image)\n    return text\n```\n\n## License Information\n\n- **pypdf**: BSD License\n- **pdfplumber**: MIT License\n- **pypdfium2**: Apache/BSD License\n- **reportlab**: BSD License\n- **poppler-utils**: GPL-2 License\n- **qpdf**: Apache License\n- **pdf-lib**: MIT License\n- **pdfjs-dist**: Apache License",
        ".claude/skills/pptx/SKILL.md": "---\nname: pptx\ndescription: \"Presentation creation, editing, and analysis. When Claude needs to work with presentations (.pptx files) for: (1) Creating new presentations, (2) Modifying or editing content, (3) Working with layouts, (4) Adding comments or speaker notes, or any other presentation tasks\"\nlicense: Proprietary. LICENSE.txt has complete terms\n---\n\n# PPTX creation, editing, and analysis\n\n## Overview\n\nA user may ask you to create, edit, or analyze the contents of a .pptx file. A .pptx file is essentially a ZIP archive containing XML files and other resources that you can read or edit. You have different tools and workflows available for different tasks.\n\n## Reading and analyzing content\n\n### Text extraction\nIf you just need to read the text contents of a presentation, you should convert the document to markdown:\n\n```bash\n# Convert document to markdown\npython -m markitdown path-to-file.pptx\n```\n\n### Raw XML access\nYou need raw XML access for: comments, speaker notes, slide layouts, animations, design elements, and complex formatting. For any of these features, you'll need to unpack a presentation and read its raw XML contents.\n\n#### Unpacking a file\n`python ooxml/scripts/unpack.py <office_file> <output_dir>`\n\n**Note**: The unpack.py script is located at `skills/pptx/ooxml/scripts/unpack.py` relative to the project root. If the script doesn't exist at this path, use `find . -name \"unpack.py\"` to locate it.\n\n#### Key file structures\n* `ppt/presentation.xml` - Main presentation metadata and slide references\n* `ppt/slides/slide{N}.xml` - Individual slide contents (slide1.xml, slide2.xml, etc.)\n* `ppt/notesSlides/notesSlide{N}.xml` - Speaker notes for each slide\n* `ppt/comments/modernComment_*.xml` - Comments for specific slides\n* `ppt/slideLayouts/` - Layout templates for slides\n* `ppt/slideMasters/` - Master slide templates\n* `ppt/theme/` - Theme and styling information\n* `ppt/media/` - Images and other media files\n\n#### Typography and color extraction\n**When given an example design to emulate**: Always analyze the presentation's typography and colors first using the methods below:\n1. **Read theme file**: Check `ppt/theme/theme1.xml` for colors (`<a:clrScheme>`) and fonts (`<a:fontScheme>`)\n2. **Sample slide content**: Examine `ppt/slides/slide1.xml` for actual font usage (`<a:rPr>`) and colors\n3. **Search for patterns**: Use grep to find color (`<a:solidFill>`, `<a:srgbClr>`) and font references across all XML files\n\n## Creating a new PowerPoint presentation **without a template**\n\nWhen creating a new PowerPoint presentation from scratch, use the **html2pptx** workflow to convert HTML slides to PowerPoint with accurate positioning.\n\n### Design Principles\n\n**CRITICAL**: Before creating any presentation, analyze the content and choose appropriate design elements:\n1. **Consider the subject matter**: What is this presentation about? What tone, industry, or mood does it suggest?\n2. **Check for branding**: If the user mentions a company/organization, consider their brand colors and identity\n3. **Match palette to content**: Select colors that reflect the subject\n4. **State your approach**: Explain your design choices before writing code\n\n**Requirements**:\n-  State your content-informed design approach BEFORE writing code\n-  Use web-safe fonts only: Arial, Helvetica, Times New Roman, Georgia, Courier New, Verdana, Tahoma, Trebuchet MS, Impact\n-  Create clear visual hierarchy through size, weight, and color\n-  Ensure readability: strong contrast, appropriately sized text, clean alignment\n-  Be consistent: repeat patterns, spacing, and visual language across slides\n\n#### Color Palette Selection\n\n**Choosing colors creatively**:\n- **Think beyond defaults**: What colors genuinely match this specific topic? Avoid autopilot choices.\n- **Consider multiple angles**: Topic, industry, mood, energy level, target audience, brand identity (if mentioned)\n- **Be adventurous**: Try unexpected combinations - a healthcare presentation doesn't have to be green, finance doesn't have to be navy\n- **Build your palette**: Pick 3-5 colors that work together (dominant colors + supporting tones + accent)\n- **Ensure contrast**: Text must be clearly readable on backgrounds\n\n**Example color palettes** (use these to spark creativity - choose one, adapt it, or create your own):\n\n1. **Classic Blue**: Deep navy (#1C2833), slate gray (#2E4053), silver (#AAB7B8), off-white (#F4F6F6)\n2. **Teal & Coral**: Teal (#5EA8A7), deep teal (#277884), coral (#FE4447), white (#FFFFFF)\n3. **Bold Red**: Red (#C0392B), bright red (#E74C3C), orange (#F39C12), yellow (#F1C40F), green (#2ECC71)\n4. **Warm Blush**: Mauve (#A49393), blush (#EED6D3), rose (#E8B4B8), cream (#FAF7F2)\n5. **Burgundy Luxury**: Burgundy (#5D1D2E), crimson (#951233), rust (#C15937), gold (#997929)\n6. **Deep Purple & Emerald**: Purple (#B165FB), dark blue (#181B24), emerald (#40695B), white (#FFFFFF)\n7. **Cream & Forest Green**: Cream (#FFE1C7), forest green (#40695B), white (#FCFCFC)\n8. **Pink & Purple**: Pink (#F8275B), coral (#FF574A), rose (#FF737D), purple (#3D2F68)\n9. **Lime & Plum**: Lime (#C5DE82), plum (#7C3A5F), coral (#FD8C6E), blue-gray (#98ACB5)\n10. **Black & Gold**: Gold (#BF9A4A), black (#000000), cream (#F4F6F6)\n11. **Sage & Terracotta**: Sage (#87A96B), terracotta (#E07A5F), cream (#F4F1DE), charcoal (#2C2C2C)\n12. **Charcoal & Red**: Charcoal (#292929), red (#E33737), light gray (#CCCBCB)\n13. **Vibrant Orange**: Orange (#F96D00), light gray (#F2F2F2), charcoal (#222831)\n14. **Forest Green**: Black (#191A19), green (#4E9F3D), dark green (#1E5128), white (#FFFFFF)\n15. **Retro Rainbow**: Purple (#722880), pink (#D72D51), orange (#EB5C18), amber (#F08800), gold (#DEB600)\n16. **Vintage Earthy**: Mustard (#E3B448), sage (#CBD18F), forest green (#3A6B35), cream (#F4F1DE)\n17. **Coastal Rose**: Old rose (#AD7670), beaver (#B49886), eggshell (#F3ECDC), ash gray (#BFD5BE)\n18. **Orange & Turquoise**: Light orange (#FC993E), grayish turquoise (#667C6F), white (#FCFCFC)\n\n#### Visual Details Options\n\n**Geometric Patterns**:\n- Diagonal section dividers instead of horizontal\n- Asymmetric column widths (30/70, 40/60, 25/75)\n- Rotated text headers at 90 or 270\n- Circular/hexagonal frames for images\n- Triangular accent shapes in corners\n- Overlapping shapes for depth\n\n**Border & Frame Treatments**:\n- Thick single-color borders (10-20pt) on one side only\n- Double-line borders with contrasting colors\n- Corner brackets instead of full frames\n- L-shaped borders (top+left or bottom+right)\n- Underline accents beneath headers (3-5pt thick)\n\n**Typography Treatments**:\n- Extreme size contrast (72pt headlines vs 11pt body)\n- All-caps headers with wide letter spacing\n- Numbered sections in oversized display type\n- Monospace (Courier New) for data/stats/technical content\n- Condensed fonts (Arial Narrow) for dense information\n- Outlined text for emphasis\n\n**Chart & Data Styling**:\n- Monochrome charts with single accent color for key data\n- Horizontal bar charts instead of vertical\n- Dot plots instead of bar charts\n- Minimal gridlines or none at all\n- Data labels directly on elements (no legends)\n- Oversized numbers for key metrics\n\n**Layout Innovations**:\n- Full-bleed images with text overlays\n- Sidebar column (20-30% width) for navigation/context\n- Modular grid systems (33, 44 blocks)\n- Z-pattern or F-pattern content flow\n- Floating text boxes over colored shapes\n- Magazine-style multi-column layouts\n\n**Background Treatments**:\n- Solid color blocks occupying 40-60% of slide\n- Gradient fills (vertical or diagonal only)\n- Split backgrounds (two colors, diagonal or vertical)\n- Edge-to-edge color bands\n- Negative space as a design element\n\n### Layout Tips\n**When creating slides with charts or tables:**\n- **Two-column layout (PREFERRED)**: Use a header spanning the full width, then two columns below - text/bullets in one column and the featured content in the other. This provides better balance and makes charts/tables more readable. Use flexbox with unequal column widths (e.g., 40%/60% split) to optimize space for each content type.\n- **Full-slide layout**: Let the featured content (chart/table) take up the entire slide for maximum impact and readability\n- **NEVER vertically stack**: Do not place charts/tables below text in a single column - this causes poor readability and layout issues\n\n### Workflow\n1. **MANDATORY - READ ENTIRE FILE**: Read [`html2pptx.md`](html2pptx.md) completely from start to finish. **NEVER set any range limits when reading this file.** Read the full file content for detailed syntax, critical formatting rules, and best practices before proceeding with presentation creation.\n2. Create an HTML file for each slide with proper dimensions (e.g., 720pt  405pt for 16:9)\n   - Use `<p>`, `<h1>`-`<h6>`, `<ul>`, `<ol>` for all text content\n   - Use `class=\"placeholder\"` for areas where charts/tables will be added (render with gray background for visibility)\n   - **CRITICAL**: Rasterize gradients and icons as PNG images FIRST using Sharp, then reference in HTML\n   - **LAYOUT**: For slides with charts/tables/images, use either full-slide layout or two-column layout for better readability\n3. Create and run a JavaScript file using the [`html2pptx.js`](scripts/html2pptx.js) library to convert HTML slides to PowerPoint and save the presentation\n   - Use the `html2pptx()` function to process each HTML file\n   - Add charts and tables to placeholder areas using PptxGenJS API\n   - Save the presentation using `pptx.writeFile()`\n4. **Visual validation**: Generate thumbnails and inspect for layout issues\n   - Create thumbnail grid: `python scripts/thumbnail.py output.pptx workspace/thumbnails --cols 4`\n   - Read and carefully examine the thumbnail image for:\n     - **Text cutoff**: Text being cut off by header bars, shapes, or slide edges\n     - **Text overlap**: Text overlapping with other text or shapes\n     - **Positioning issues**: Content too close to slide boundaries or other elements\n     - **Contrast issues**: Insufficient contrast between text and backgrounds\n   - If issues found, adjust HTML margins/spacing/colors and regenerate the presentation\n   - Repeat until all slides are visually correct\n\n## Editing an existing PowerPoint presentation\n\nWhen edit slides in an existing PowerPoint presentation, you need to work with the raw Office Open XML (OOXML) format. This involves unpacking the .pptx file, editing the XML content, and repacking it.\n\n### Workflow\n1. **MANDATORY - READ ENTIRE FILE**: Read [`ooxml.md`](ooxml.md) (~500 lines) completely from start to finish.  **NEVER set any range limits when reading this file.**  Read the full file content for detailed guidance on OOXML structure and editing workflows before any presentation editing.\n2. Unpack the presentation: `python ooxml/scripts/unpack.py <office_file> <output_dir>`\n3. Edit the XML files (primarily `ppt/slides/slide{N}.xml` and related files)\n4. **CRITICAL**: Validate immediately after each edit and fix any validation errors before proceeding: `python ooxml/scripts/validate.py <dir> --original <file>`\n5. Pack the final presentation: `python ooxml/scripts/pack.py <input_directory> <office_file>`\n\n## Creating a new PowerPoint presentation **using a template**\n\nWhen you need to create a presentation that follows an existing template's design, you'll need to duplicate and re-arrange template slides before then replacing placeholder context.\n\n### Workflow\n1. **Extract template text AND create visual thumbnail grid**:\n   * Extract text: `python -m markitdown template.pptx > template-content.md`\n   * Read `template-content.md`: Read the entire file to understand the contents of the template presentation. **NEVER set any range limits when reading this file.**\n   * Create thumbnail grids: `python scripts/thumbnail.py template.pptx`\n   * See [Creating Thumbnail Grids](#creating-thumbnail-grids) section for more details\n\n2. **Analyze template and save inventory to a file**:\n   * **Visual Analysis**: Review thumbnail grid(s) to understand slide layouts, design patterns, and visual structure\n   * Create and save a template inventory file at `template-inventory.md` containing:\n     ```markdown\n     # Template Inventory Analysis\n     **Total Slides: [count]**\n     **IMPORTANT: Slides are 0-indexed (first slide = 0, last slide = count-1)**\n\n     ## [Category Name]\n     - Slide 0: [Layout code if available] - Description/purpose\n     - Slide 1: [Layout code] - Description/purpose\n     - Slide 2: [Layout code] - Description/purpose\n     [... EVERY slide must be listed individually with its index ...]\n     ```\n   * **Using the thumbnail grid**: Reference the visual thumbnails to identify:\n     - Layout patterns (title slides, content layouts, section dividers)\n     - Image placeholder locations and counts\n     - Design consistency across slide groups\n     - Visual hierarchy and structure\n   * This inventory file is REQUIRED for selecting appropriate templates in the next step\n\n3. **Create presentation outline based on template inventory**:\n   * Review available templates from step 2.\n   * Choose an intro or title template for the first slide. This should be one of the first templates.\n   * Choose safe, text-based layouts for the other slides.\n   * **CRITICAL: Match layout structure to actual content**:\n     - Single-column layouts: Use for unified narrative or single topic\n     - Two-column layouts: Use ONLY when you have exactly 2 distinct items/concepts\n     - Three-column layouts: Use ONLY when you have exactly 3 distinct items/concepts\n     - Image + text layouts: Use ONLY when you have actual images to insert\n     - Quote layouts: Use ONLY for actual quotes from people (with attribution), never for emphasis\n     - Never use layouts with more placeholders than you have content\n     - If you have 2 items, don't force them into a 3-column layout\n     - If you have 4+ items, consider breaking into multiple slides or using a list format\n   * Count your actual content pieces BEFORE selecting the layout\n   * Verify each placeholder in the chosen layout will be filled with meaningful content\n   * Select one option representing the **best** layout for each content section.\n   * Save `outline.md` with content AND template mapping that leverages available designs\n   * Example template mapping:\n      ```\n      # Template slides to use (0-based indexing)\n      # WARNING: Verify indices are within range! Template with 73 slides has indices 0-72\n      # Mapping: slide numbers from outline -> template slide indices\n      template_mapping = [\n          0,   # Use slide 0 (Title/Cover)\n          34,  # Use slide 34 (B1: Title and body)\n          34,  # Use slide 34 again (duplicate for second B1)\n          50,  # Use slide 50 (E1: Quote)\n          54,  # Use slide 54 (F2: Closing + Text)\n      ]\n      ```\n\n4. **Duplicate, reorder, and delete slides using `rearrange.py`**:\n   * Use the `scripts/rearrange.py` script to create a new presentation with slides in the desired order:\n     ```bash\n     python scripts/rearrange.py template.pptx working.pptx 0,34,34,50,52\n     ```\n   * The script handles duplicating repeated slides, deleting unused slides, and reordering automatically\n   * Slide indices are 0-based (first slide is 0, second is 1, etc.)\n   * The same slide index can appear multiple times to duplicate that slide\n\n5. **Extract ALL text using the `inventory.py` script**:\n   * **Run inventory extraction**:\n     ```bash\n     python scripts/inventory.py working.pptx text-inventory.json\n     ```\n   * **Read text-inventory.json**: Read the entire text-inventory.json file to understand all shapes and their properties. **NEVER set any range limits when reading this file.**\n\n   * The inventory JSON structure:\n      ```json\n        {\n          \"slide-0\": {\n            \"shape-0\": {\n              \"placeholder_type\": \"TITLE\",  // or null for non-placeholders\n              \"left\": 1.5,                  // position in inches\n              \"top\": 2.0,\n              \"width\": 7.5,\n              \"height\": 1.2,\n              \"paragraphs\": [\n                {\n                  \"text\": \"Paragraph text\",\n                  // Optional properties (only included when non-default):\n                  \"bullet\": true,           // explicit bullet detected\n                  \"level\": 0,               // only included when bullet is true\n                  \"alignment\": \"CENTER\",    // CENTER, RIGHT (not LEFT)\n                  \"space_before\": 10.0,     // space before paragraph in points\n                  \"space_after\": 6.0,       // space after paragraph in points\n                  \"line_spacing\": 22.4,     // line spacing in points\n                  \"font_name\": \"Arial\",     // from first run\n                  \"font_size\": 14.0,        // in points\n                  \"bold\": true,\n                  \"italic\": false,\n                  \"underline\": false,\n                  \"color\": \"FF0000\"         // RGB color\n                }\n              ]\n            }\n          }\n        }\n      ```\n\n   * Key features:\n     - **Slides**: Named as \"slide-0\", \"slide-1\", etc.\n     - **Shapes**: Ordered by visual position (top-to-bottom, left-to-right) as \"shape-0\", \"shape-1\", etc.\n     - **Placeholder types**: TITLE, CENTER_TITLE, SUBTITLE, BODY, OBJECT, or null\n     - **Default font size**: `default_font_size` in points extracted from layout placeholders (when available)\n     - **Slide numbers are filtered**: Shapes with SLIDE_NUMBER placeholder type are automatically excluded from inventory\n     - **Bullets**: When `bullet: true`, `level` is always included (even if 0)\n     - **Spacing**: `space_before`, `space_after`, and `line_spacing` in points (only included when set)\n     - **Colors**: `color` for RGB (e.g., \"FF0000\"), `theme_color` for theme colors (e.g., \"DARK_1\")\n     - **Properties**: Only non-default values are included in the output\n\n6. **Generate replacement text and save the data to a JSON file**\n   Based on the text inventory from the previous step:\n   - **CRITICAL**: First verify which shapes exist in the inventory - only reference shapes that are actually present\n   - **VALIDATION**: The replace.py script will validate that all shapes in your replacement JSON exist in the inventory\n     - If you reference a non-existent shape, you'll get an error showing available shapes\n     - If you reference a non-existent slide, you'll get an error indicating the slide doesn't exist\n     - All validation errors are shown at once before the script exits\n   - **IMPORTANT**: The replace.py script uses inventory.py internally to identify ALL text shapes\n   - **AUTOMATIC CLEARING**: ALL text shapes from the inventory will be cleared unless you provide \"paragraphs\" for them\n   - Add a \"paragraphs\" field to shapes that need content (not \"replacement_paragraphs\")\n   - Shapes without \"paragraphs\" in the replacement JSON will have their text cleared automatically\n   - Paragraphs with bullets will be automatically left aligned. Don't set the `alignment` property on when `\"bullet\": true`\n   - Generate appropriate replacement content for placeholder text\n   - Use shape size to determine appropriate content length\n   - **CRITICAL**: Include paragraph properties from the original inventory - don't just provide text\n   - **IMPORTANT**: When bullet: true, do NOT include bullet symbols (, -, *) in text - they're added automatically\n   - **ESSENTIAL FORMATTING RULES**:\n     - Headers/titles should typically have `\"bold\": true`\n     - List items should have `\"bullet\": true, \"level\": 0` (level is required when bullet is true)\n     - Preserve any alignment properties (e.g., `\"alignment\": \"CENTER\"` for centered text)\n     - Include font properties when different from default (e.g., `\"font_size\": 14.0`, `\"font_name\": \"Lora\"`)\n     - Colors: Use `\"color\": \"FF0000\"` for RGB or `\"theme_color\": \"DARK_1\"` for theme colors\n     - The replacement script expects **properly formatted paragraphs**, not just text strings\n     - **Overlapping shapes**: Prefer shapes with larger default_font_size or more appropriate placeholder_type\n   - Save the updated inventory with replacements to `replacement-text.json`\n   - **WARNING**: Different template layouts have different shape counts - always check the actual inventory before creating replacements\n\n   Example paragraphs field showing proper formatting:\n   ```json\n   \"paragraphs\": [\n     {\n       \"text\": \"New presentation title text\",\n       \"alignment\": \"CENTER\",\n       \"bold\": true\n     },\n     {\n       \"text\": \"Section Header\",\n       \"bold\": true\n     },\n     {\n       \"text\": \"First bullet point without bullet symbol\",\n       \"bullet\": true,\n       \"level\": 0\n     },\n     {\n       \"text\": \"Red colored text\",\n       \"color\": \"FF0000\"\n     },\n     {\n       \"text\": \"Theme colored text\",\n       \"theme_color\": \"DARK_1\"\n     },\n     {\n       \"text\": \"Regular paragraph text without special formatting\"\n     }\n   ]\n   ```\n\n   **Shapes not listed in the replacement JSON are automatically cleared**:\n   ```json\n   {\n     \"slide-0\": {\n       \"shape-0\": {\n         \"paragraphs\": [...] // This shape gets new text\n       }\n       // shape-1 and shape-2 from inventory will be cleared automatically\n     }\n   }\n   ```\n\n   **Common formatting patterns for presentations**:\n   - Title slides: Bold text, sometimes centered\n   - Section headers within slides: Bold text\n   - Bullet lists: Each item needs `\"bullet\": true, \"level\": 0`\n   - Body text: Usually no special properties needed\n   - Quotes: May have special alignment or font properties\n\n7. **Apply replacements using the `replace.py` script**\n   ```bash\n   python scripts/replace.py working.pptx replacement-text.json output.pptx\n   ```\n\n   The script will:\n   - First extract the inventory of ALL text shapes using functions from inventory.py\n   - Validate that all shapes in the replacement JSON exist in the inventory\n   - Clear text from ALL shapes identified in the inventory\n   - Apply new text only to shapes with \"paragraphs\" defined in the replacement JSON\n   - Preserve formatting by applying paragraph properties from the JSON\n   - Handle bullets, alignment, font properties, and colors automatically\n   - Save the updated presentation\n\n   Example validation errors:\n   ```\n   ERROR: Invalid shapes in replacement JSON:\n     - Shape 'shape-99' not found on 'slide-0'. Available shapes: shape-0, shape-1, shape-4\n     - Slide 'slide-999' not found in inventory\n   ```\n\n   ```\n   ERROR: Replacement text made overflow worse in these shapes:\n     - slide-0/shape-2: overflow worsened by 1.25\" (was 0.00\", now 1.25\")\n   ```\n\n## Creating Thumbnail Grids\n\nTo create visual thumbnail grids of PowerPoint slides for quick analysis and reference:\n\n```bash\npython scripts/thumbnail.py template.pptx [output_prefix]\n```\n\n**Features**:\n- Creates: `thumbnails.jpg` (or `thumbnails-1.jpg`, `thumbnails-2.jpg`, etc. for large decks)\n- Default: 5 columns, max 30 slides per grid (56)\n- Custom prefix: `python scripts/thumbnail.py template.pptx my-grid`\n  - Note: The output prefix should include the path if you want output in a specific directory (e.g., `workspace/my-grid`)\n- Adjust columns: `--cols 4` (range: 3-6, affects slides per grid)\n- Grid limits: 3 cols = 12 slides/grid, 4 cols = 20, 5 cols = 30, 6 cols = 42\n- Slides are zero-indexed (Slide 0, Slide 1, etc.)\n\n**Use cases**:\n- Template analysis: Quickly understand slide layouts and design patterns\n- Content review: Visual overview of entire presentation\n- Navigation reference: Find specific slides by their visual appearance\n- Quality check: Verify all slides are properly formatted\n\n**Examples**:\n```bash\n# Basic usage\npython scripts/thumbnail.py presentation.pptx\n\n# Combine options: custom name, columns\npython scripts/thumbnail.py template.pptx analysis --cols 4\n```\n\n## Converting Slides to Images\n\nTo visually analyze PowerPoint slides, convert them to images using a two-step process:\n\n1. **Convert PPTX to PDF**:\n   ```bash\n   soffice --headless --convert-to pdf template.pptx\n   ```\n\n2. **Convert PDF pages to JPEG images**:\n   ```bash\n   pdftoppm -jpeg -r 150 template.pdf slide\n   ```\n   This creates files like `slide-1.jpg`, `slide-2.jpg`, etc.\n\nOptions:\n- `-r 150`: Sets resolution to 150 DPI (adjust for quality/size balance)\n- `-jpeg`: Output JPEG format (use `-png` for PNG if preferred)\n- `-f N`: First page to convert (e.g., `-f 2` starts from page 2)\n- `-l N`: Last page to convert (e.g., `-l 5` stops at page 5)\n- `slide`: Prefix for output files\n\nExample for specific range:\n```bash\npdftoppm -jpeg -r 150 -f 2 -l 5 template.pdf slide  # Converts only pages 2-5\n```\n\n## Code Style Guidelines\n**IMPORTANT**: When generating code for PPTX operations:\n- Write concise code\n- Avoid verbose variable names and redundant operations\n- Avoid unnecessary print statements\n\n## Dependencies\n\nRequired dependencies (should already be installed):\n\n- **markitdown**: `pip install \"markitdown[pptx]\"` (for text extraction from presentations)\n- **pptxgenjs**: `npm install -g pptxgenjs` (for creating presentations via html2pptx)\n- **playwright**: `npm install -g playwright` (for HTML rendering in html2pptx)\n- **react-icons**: `npm install -g react-icons react react-dom` (for icons)\n- **sharp**: `npm install -g sharp` (for SVG rasterization and image processing)\n- **LibreOffice**: `sudo apt-get install libreoffice` (for PDF conversion)\n- **Poppler**: `sudo apt-get install poppler-utils` (for pdftoppm to convert PDF to images)\n- **defusedxml**: `pip install defusedxml` (for secure XML parsing)",
        ".claude/skills/pptx/html2pptx.md": "# HTML to PowerPoint Guide\n\nConvert HTML slides to PowerPoint presentations with accurate positioning using the `html2pptx.js` library.\n\n## Table of Contents\n\n1. [Creating HTML Slides](#creating-html-slides)\n2. [Using the html2pptx Library](#using-the-html2pptx-library)\n3. [Using PptxGenJS](#using-pptxgenjs)\n\n---\n\n## Creating HTML Slides\n\nEvery HTML slide must include proper body dimensions:\n\n### Layout Dimensions\n\n- **16:9** (default): `width: 720pt; height: 405pt`\n- **4:3**: `width: 720pt; height: 540pt`\n- **16:10**: `width: 720pt; height: 450pt`\n\n### Supported Elements\n\n- `<p>`, `<h1>`-`<h6>` - Text with styling\n- `<ul>`, `<ol>` - Lists (never use manual bullets , -, *)\n- `<b>`, `<strong>` - Bold text (inline formatting)\n- `<i>`, `<em>` - Italic text (inline formatting)\n- `<u>` - Underlined text (inline formatting)\n- `<span>` - Inline formatting with CSS styles (bold, italic, underline, color)\n- `<br>` - Line breaks\n- `<div>` with bg/border - Becomes shape\n- `<img>` - Images\n- `class=\"placeholder\"` - Reserved space for charts (returns `{ id, x, y, w, h }`)\n\n### Critical Text Rules\n\n**ALL text MUST be inside `<p>`, `<h1>`-`<h6>`, `<ul>`, or `<ol>` tags:**\n-  Correct: `<div><p>Text here</p></div>`\n-  Wrong: `<div>Text here</div>` - **Text will NOT appear in PowerPoint**\n-  Wrong: `<span>Text</span>` - **Text will NOT appear in PowerPoint**\n- Text in `<div>` or `<span>` without a text tag will be silently ignored\n\n**NEVER use manual bullet symbols (, -, *, etc.)** - Use `<ul>` or `<ol>` lists instead\n\n**ONLY use web-safe fonts that are universally available:**\n-  Web-safe fonts: `Arial`, `Helvetica`, `Times New Roman`, `Georgia`, `Courier New`, `Verdana`, `Tahoma`, `Trebuchet MS`, `Impact`, `Comic Sans MS`\n-  Wrong: `'Segoe UI'`, `'SF Pro'`, `'Roboto'`, custom fonts - **Might cause rendering issues**\n\n### Styling\n\n- Use `display: flex` on body to prevent margin collapse from breaking overflow validation\n- Use `margin` for spacing (padding included in size)\n- Inline formatting: Use `<b>`, `<i>`, `<u>` tags OR `<span>` with CSS styles\n  - `<span>` supports: `font-weight: bold`, `font-style: italic`, `text-decoration: underline`, `color: #rrggbb`\n  - `<span>` does NOT support: `margin`, `padding` (not supported in PowerPoint text runs)\n  - Example: `<span style=\"font-weight: bold; color: #667eea;\">Bold blue text</span>`\n- Flexbox works - positions calculated from rendered layout\n- Use hex colors with `#` prefix in CSS\n- **Text alignment**: Use CSS `text-align` (`center`, `right`, etc.) when needed as a hint to PptxGenJS for text formatting if text lengths are slightly off\n\n### Shape Styling (DIV elements only)\n\n**IMPORTANT: Backgrounds, borders, and shadows only work on `<div>` elements, NOT on text elements (`<p>`, `<h1>`-`<h6>`, `<ul>`, `<ol>`)**\n\n- **Backgrounds**: CSS `background` or `background-color` on `<div>` elements only\n  - Example: `<div style=\"background: #f0f0f0;\">` - Creates a shape with background\n- **Borders**: CSS `border` on `<div>` elements converts to PowerPoint shape borders\n  - Supports uniform borders: `border: 2px solid #333333`\n  - Supports partial borders: `border-left`, `border-right`, `border-top`, `border-bottom` (rendered as line shapes)\n  - Example: `<div style=\"border-left: 8pt solid #E76F51;\">`\n- **Border radius**: CSS `border-radius` on `<div>` elements for rounded corners\n  - `border-radius: 50%` or higher creates circular shape\n  - Percentages <50% calculated relative to shape's smaller dimension\n  - Supports px and pt units (e.g., `border-radius: 8pt;`, `border-radius: 12px;`)\n  - Example: `<div style=\"border-radius: 25%;\">` on 100x200px box = 25% of 100px = 25px radius\n- **Box shadows**: CSS `box-shadow` on `<div>` elements converts to PowerPoint shadows\n  - Supports outer shadows only (inset shadows are ignored to prevent corruption)\n  - Example: `<div style=\"box-shadow: 2px 2px 8px rgba(0, 0, 0, 0.3);\">`\n  - Note: Inset/inner shadows are not supported by PowerPoint and will be skipped\n\n### Icons & Gradients\n\n- **CRITICAL: Never use CSS gradients (`linear-gradient`, `radial-gradient`)** - They don't convert to PowerPoint\n- **ALWAYS create gradient/icon PNGs FIRST using Sharp, then reference in HTML**\n- For gradients: Rasterize SVG to PNG background images\n- For icons: Rasterize react-icons SVG to PNG images\n- All visual effects must be pre-rendered as raster images before HTML rendering\n\n**Rasterizing Icons with Sharp:**\n\n```javascript\nconst React = require('react');\nconst ReactDOMServer = require('react-dom/server');\nconst sharp = require('sharp');\nconst { FaHome } = require('react-icons/fa');\n\nasync function rasterizeIconPng(IconComponent, color, size = \"256\", filename) {\n  const svgString = ReactDOMServer.renderToStaticMarkup(\n    React.createElement(IconComponent, { color: `#${color}`, size: size })\n  );\n\n  // Convert SVG to PNG using Sharp\n  await sharp(Buffer.from(svgString))\n    .png()\n    .toFile(filename);\n\n  return filename;\n}\n\n// Usage: Rasterize icon before using in HTML\nconst iconPath = await rasterizeIconPng(FaHome, \"4472c4\", \"256\", \"home-icon.png\");\n// Then reference in HTML: <img src=\"home-icon.png\" style=\"width: 40pt; height: 40pt;\">\n```\n\n**Rasterizing Gradients with Sharp:**\n\n```javascript\nconst sharp = require('sharp');\n\nasync function createGradientBackground(filename) {\n  const svg = `<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"1000\" height=\"562.5\">\n    <defs>\n      <linearGradient id=\"g\" x1=\"0%\" y1=\"0%\" x2=\"100%\" y2=\"100%\">\n        <stop offset=\"0%\" style=\"stop-color:#COLOR1\"/>\n        <stop offset=\"100%\" style=\"stop-color:#COLOR2\"/>\n      </linearGradient>\n    </defs>\n    <rect width=\"100%\" height=\"100%\" fill=\"url(#g)\"/>\n  </svg>`;\n\n  await sharp(Buffer.from(svg))\n    .png()\n    .toFile(filename);\n\n  return filename;\n}\n\n// Usage: Create gradient background before HTML\nconst bgPath = await createGradientBackground(\"gradient-bg.png\");\n// Then in HTML: <body style=\"background-image: url('gradient-bg.png');\">\n```\n\n### Example\n\n```html\n<!DOCTYPE html>\n<html>\n<head>\n<style>\nhtml { background: #ffffff; }\nbody {\n  width: 720pt; height: 405pt; margin: 0; padding: 0;\n  background: #f5f5f5; font-family: Arial, sans-serif;\n  display: flex;\n}\n.content { margin: 30pt; padding: 40pt; background: #ffffff; border-radius: 8pt; }\nh1 { color: #2d3748; font-size: 32pt; }\n.box {\n  background: #70ad47; padding: 20pt; border: 3px solid #5a8f37;\n  border-radius: 12pt; box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.25);\n}\n</style>\n</head>\n<body>\n<div class=\"content\">\n  <h1>Recipe Title</h1>\n  <ul>\n    <li><b>Item:</b> Description</li>\n  </ul>\n  <p>Text with <b>bold</b>, <i>italic</i>, <u>underline</u>.</p>\n  <div id=\"chart\" class=\"placeholder\" style=\"width: 350pt; height: 200pt;\"></div>\n\n  <!-- Text MUST be in <p> tags -->\n  <div class=\"box\">\n    <p>5</p>\n  </div>\n</div>\n</body>\n</html>\n```\n\n## Using the html2pptx Library\n\n### Dependencies\n\nThese libraries have been globally installed and are available to use:\n- `pptxgenjs`\n- `playwright`\n- `sharp`\n\n### Basic Usage\n\n```javascript\nconst pptxgen = require('pptxgenjs');\nconst html2pptx = require('./html2pptx');\n\nconst pptx = new pptxgen();\npptx.layout = 'LAYOUT_16x9';  // Must match HTML body dimensions\n\nconst { slide, placeholders } = await html2pptx('slide1.html', pptx);\n\n// Add chart to placeholder area\nif (placeholders.length > 0) {\n    slide.addChart(pptx.charts.LINE, chartData, placeholders[0]);\n}\n\nawait pptx.writeFile('output.pptx');\n```\n\n### API Reference\n\n#### Function Signature\n```javascript\nawait html2pptx(htmlFile, pres, options)\n```\n\n#### Parameters\n- `htmlFile` (string): Path to HTML file (absolute or relative)\n- `pres` (pptxgen): PptxGenJS presentation instance with layout already set\n- `options` (object, optional):\n  - `tmpDir` (string): Temporary directory for generated files (default: `process.env.TMPDIR || '/tmp'`)\n  - `slide` (object): Existing slide to reuse (default: creates new slide)\n\n#### Returns\n```javascript\n{\n    slide: pptxgenSlide,           // The created/updated slide\n    placeholders: [                 // Array of placeholder positions\n        { id: string, x: number, y: number, w: number, h: number },\n        ...\n    ]\n}\n```\n\n### Validation\n\nThe library automatically validates and collects all errors before throwing:\n\n1. **HTML dimensions must match presentation layout** - Reports dimension mismatches\n2. **Content must not overflow body** - Reports overflow with exact measurements\n3. **CSS gradients** - Reports unsupported gradient usage\n4. **Text element styling** - Reports backgrounds/borders/shadows on text elements (only allowed on divs)\n\n**All validation errors are collected and reported together** in a single error message, allowing you to fix all issues at once instead of one at a time.\n\n### Working with Placeholders\n\n```javascript\nconst { slide, placeholders } = await html2pptx('slide.html', pptx);\n\n// Use first placeholder\nslide.addChart(pptx.charts.BAR, data, placeholders[0]);\n\n// Find by ID\nconst chartArea = placeholders.find(p => p.id === 'chart-area');\nslide.addChart(pptx.charts.LINE, data, chartArea);\n```\n\n### Complete Example\n\n```javascript\nconst pptxgen = require('pptxgenjs');\nconst html2pptx = require('./html2pptx');\n\nasync function createPresentation() {\n    const pptx = new pptxgen();\n    pptx.layout = 'LAYOUT_16x9';\n    pptx.author = 'Your Name';\n    pptx.title = 'My Presentation';\n\n    // Slide 1: Title\n    const { slide: slide1 } = await html2pptx('slides/title.html', pptx);\n\n    // Slide 2: Content with chart\n    const { slide: slide2, placeholders } = await html2pptx('slides/data.html', pptx);\n\n    const chartData = [{\n        name: 'Sales',\n        labels: ['Q1', 'Q2', 'Q3', 'Q4'],\n        values: [4500, 5500, 6200, 7100]\n    }];\n\n    slide2.addChart(pptx.charts.BAR, chartData, {\n        ...placeholders[0],\n        showTitle: true,\n        title: 'Quarterly Sales',\n        showCatAxisTitle: true,\n        catAxisTitle: 'Quarter',\n        showValAxisTitle: true,\n        valAxisTitle: 'Sales ($000s)'\n    });\n\n    // Save\n    await pptx.writeFile({ fileName: 'presentation.pptx' });\n    console.log('Presentation created successfully!');\n}\n\ncreatePresentation().catch(console.error);\n```\n\n## Using PptxGenJS\n\nAfter converting HTML to slides with `html2pptx`, you'll use PptxGenJS to add dynamic content like charts, images, and additional elements.\n\n###  Critical Rules\n\n#### Colors\n- **NEVER use `#` prefix** with hex colors in PptxGenJS - causes file corruption\n-  Correct: `color: \"FF0000\"`, `fill: { color: \"0066CC\" }`\n-  Wrong: `color: \"#FF0000\"` (breaks document)\n\n### Adding Images\n\nAlways calculate aspect ratios from actual image dimensions:\n\n```javascript\n// Get image dimensions: identify image.png | grep -o '[0-9]* x [0-9]*'\nconst imgWidth = 1860, imgHeight = 1519;  // From actual file\nconst aspectRatio = imgWidth / imgHeight;\n\nconst h = 3;  // Max height\nconst w = h * aspectRatio;\nconst x = (10 - w) / 2;  // Center on 16:9 slide\n\nslide.addImage({ path: \"chart.png\", x, y: 1.5, w, h });\n```\n\n### Adding Text\n\n```javascript\n// Rich text with formatting\nslide.addText([\n    { text: \"Bold \", options: { bold: true } },\n    { text: \"Italic \", options: { italic: true } },\n    { text: \"Normal\" }\n], {\n    x: 1, y: 2, w: 8, h: 1\n});\n```\n\n### Adding Shapes\n\n```javascript\n// Rectangle\nslide.addShape(pptx.shapes.RECTANGLE, {\n    x: 1, y: 1, w: 3, h: 2,\n    fill: { color: \"4472C4\" },\n    line: { color: \"000000\", width: 2 }\n});\n\n// Circle\nslide.addShape(pptx.shapes.OVAL, {\n    x: 5, y: 1, w: 2, h: 2,\n    fill: { color: \"ED7D31\" }\n});\n\n// Rounded rectangle\nslide.addShape(pptx.shapes.ROUNDED_RECTANGLE, {\n    x: 1, y: 4, w: 3, h: 1.5,\n    fill: { color: \"70AD47\" },\n    rectRadius: 0.2\n});\n```\n\n### Adding Charts\n\n**Required for most charts:** Axis labels using `catAxisTitle` (category) and `valAxisTitle` (value).\n\n**Chart Data Format:**\n- Use **single series with all labels** for simple bar/line charts\n- Each series creates a separate legend entry\n- Labels array defines X-axis values\n\n**Time Series Data - Choose Correct Granularity:**\n- **< 30 days**: Use daily grouping (e.g., \"10-01\", \"10-02\") - avoid monthly aggregation that creates single-point charts\n- **30-365 days**: Use monthly grouping (e.g., \"2024-01\", \"2024-02\")\n- **> 365 days**: Use yearly grouping (e.g., \"2023\", \"2024\")\n- **Validate**: Charts with only 1 data point likely indicate incorrect aggregation for the time period\n\n```javascript\nconst { slide, placeholders } = await html2pptx('slide.html', pptx);\n\n// CORRECT: Single series with all labels\nslide.addChart(pptx.charts.BAR, [{\n    name: \"Sales 2024\",\n    labels: [\"Q1\", \"Q2\", \"Q3\", \"Q4\"],\n    values: [4500, 5500, 6200, 7100]\n}], {\n    ...placeholders[0],  // Use placeholder position\n    barDir: 'col',       // 'col' = vertical bars, 'bar' = horizontal\n    showTitle: true,\n    title: 'Quarterly Sales',\n    showLegend: false,   // No legend needed for single series\n    // Required axis labels\n    showCatAxisTitle: true,\n    catAxisTitle: 'Quarter',\n    showValAxisTitle: true,\n    valAxisTitle: 'Sales ($000s)',\n    // Optional: Control scaling (adjust min based on data range for better visualization)\n    valAxisMaxVal: 8000,\n    valAxisMinVal: 0,  // Use 0 for counts/amounts; for clustered data (e.g., 4500-7100), consider starting closer to min value\n    valAxisMajorUnit: 2000,  // Control y-axis label spacing to prevent crowding\n    catAxisLabelRotate: 45,  // Rotate labels if crowded\n    dataLabelPosition: 'outEnd',\n    dataLabelColor: '000000',\n    // Use single color for single-series charts\n    chartColors: [\"4472C4\"]  // All bars same color\n});\n```\n\n#### Scatter Chart\n\n**IMPORTANT**: Scatter chart data format is unusual - first series contains X-axis values, subsequent series contain Y-values:\n\n```javascript\n// Prepare data\nconst data1 = [{ x: 10, y: 20 }, { x: 15, y: 25 }, { x: 20, y: 30 }];\nconst data2 = [{ x: 12, y: 18 }, { x: 18, y: 22 }];\n\nconst allXValues = [...data1.map(d => d.x), ...data2.map(d => d.x)];\n\nslide.addChart(pptx.charts.SCATTER, [\n    { name: 'X-Axis', values: allXValues },  // First series = X values\n    { name: 'Series 1', values: data1.map(d => d.y) },  // Y values only\n    { name: 'Series 2', values: data2.map(d => d.y) }   // Y values only\n], {\n    x: 1, y: 1, w: 8, h: 4,\n    lineSize: 0,  // 0 = no connecting lines\n    lineDataSymbol: 'circle',\n    lineDataSymbolSize: 6,\n    showCatAxisTitle: true,\n    catAxisTitle: 'X Axis',\n    showValAxisTitle: true,\n    valAxisTitle: 'Y Axis',\n    chartColors: [\"4472C4\", \"ED7D31\"]\n});\n```\n\n#### Line Chart\n\n```javascript\nslide.addChart(pptx.charts.LINE, [{\n    name: \"Temperature\",\n    labels: [\"Jan\", \"Feb\", \"Mar\", \"Apr\"],\n    values: [32, 35, 42, 55]\n}], {\n    x: 1, y: 1, w: 8, h: 4,\n    lineSize: 4,\n    lineSmooth: true,\n    // Required axis labels\n    showCatAxisTitle: true,\n    catAxisTitle: 'Month',\n    showValAxisTitle: true,\n    valAxisTitle: 'Temperature (F)',\n    // Optional: Y-axis range (set min based on data range for better visualization)\n    valAxisMinVal: 0,     // For ranges starting at 0 (counts, percentages, etc.)\n    valAxisMaxVal: 60,\n    valAxisMajorUnit: 20,  // Control y-axis label spacing to prevent crowding (e.g., 10, 20, 25)\n    // valAxisMinVal: 30,  // PREFERRED: For data clustered in a range (e.g., 32-55 or ratings 3-5), start axis closer to min value to show variation\n    // Optional: Chart colors\n    chartColors: [\"4472C4\", \"ED7D31\", \"A5A5A5\"]\n});\n```\n\n#### Pie Chart (No Axis Labels Required)\n\n**CRITICAL**: Pie charts require a **single data series** with all categories in the `labels` array and corresponding values in the `values` array.\n\n```javascript\nslide.addChart(pptx.charts.PIE, [{\n    name: \"Market Share\",\n    labels: [\"Product A\", \"Product B\", \"Other\"],  // All categories in one array\n    values: [35, 45, 20]  // All values in one array\n}], {\n    x: 2, y: 1, w: 6, h: 4,\n    showPercent: true,\n    showLegend: true,\n    legendPos: 'r',  // right\n    chartColors: [\"4472C4\", \"ED7D31\", \"A5A5A5\"]\n});\n```\n\n#### Multiple Data Series\n\n```javascript\nslide.addChart(pptx.charts.LINE, [\n    {\n        name: \"Product A\",\n        labels: [\"Q1\", \"Q2\", \"Q3\", \"Q4\"],\n        values: [10, 20, 30, 40]\n    },\n    {\n        name: \"Product B\",\n        labels: [\"Q1\", \"Q2\", \"Q3\", \"Q4\"],\n        values: [15, 25, 20, 35]\n    }\n], {\n    x: 1, y: 1, w: 8, h: 4,\n    showCatAxisTitle: true,\n    catAxisTitle: 'Quarter',\n    showValAxisTitle: true,\n    valAxisTitle: 'Revenue ($M)'\n});\n```\n\n### Chart Colors\n\n**CRITICAL**: Use hex colors **without** the `#` prefix - including `#` causes file corruption.\n\n**Align chart colors with your chosen design palette**, ensuring sufficient contrast and distinctiveness for data visualization. Adjust colors for:\n- Strong contrast between adjacent series\n- Readability against slide backgrounds\n- Accessibility (avoid red-green only combinations)\n\n```javascript\n// Example: Ocean palette-inspired chart colors (adjusted for contrast)\nconst chartColors = [\"16A085\", \"FF6B9D\", \"2C3E50\", \"F39C12\", \"9B59B6\"];\n\n// Single-series chart: Use one color for all bars/points\nslide.addChart(pptx.charts.BAR, [{\n    name: \"Sales\",\n    labels: [\"Q1\", \"Q2\", \"Q3\", \"Q4\"],\n    values: [4500, 5500, 6200, 7100]\n}], {\n    ...placeholders[0],\n    chartColors: [\"16A085\"],  // All bars same color\n    showLegend: false\n});\n\n// Multi-series chart: Each series gets a different color\nslide.addChart(pptx.charts.LINE, [\n    { name: \"Product A\", labels: [\"Q1\", \"Q2\", \"Q3\"], values: [10, 20, 30] },\n    { name: \"Product B\", labels: [\"Q1\", \"Q2\", \"Q3\"], values: [15, 25, 20] }\n], {\n    ...placeholders[0],\n    chartColors: [\"16A085\", \"FF6B9D\"]  // One color per series\n});\n```\n\n### Adding Tables\n\nTables can be added with basic or advanced formatting:\n\n#### Basic Table\n\n```javascript\nslide.addTable([\n    [\"Header 1\", \"Header 2\", \"Header 3\"],\n    [\"Row 1, Col 1\", \"Row 1, Col 2\", \"Row 1, Col 3\"],\n    [\"Row 2, Col 1\", \"Row 2, Col 2\", \"Row 2, Col 3\"]\n], {\n    x: 0.5,\n    y: 1,\n    w: 9,\n    h: 3,\n    border: { pt: 1, color: \"999999\" },\n    fill: { color: \"F1F1F1\" }\n});\n```\n\n#### Table with Custom Formatting\n\n```javascript\nconst tableData = [\n    // Header row with custom styling\n    [\n        { text: \"Product\", options: { fill: { color: \"4472C4\" }, color: \"FFFFFF\", bold: true } },\n        { text: \"Revenue\", options: { fill: { color: \"4472C4\" }, color: \"FFFFFF\", bold: true } },\n        { text: \"Growth\", options: { fill: { color: \"4472C4\" }, color: \"FFFFFF\", bold: true } }\n    ],\n    // Data rows\n    [\"Product A\", \"$50M\", \"+15%\"],\n    [\"Product B\", \"$35M\", \"+22%\"],\n    [\"Product C\", \"$28M\", \"+8%\"]\n];\n\nslide.addTable(tableData, {\n    x: 1,\n    y: 1.5,\n    w: 8,\n    h: 3,\n    colW: [3, 2.5, 2.5],  // Column widths\n    rowH: [0.5, 0.6, 0.6, 0.6],  // Row heights\n    border: { pt: 1, color: \"CCCCCC\" },\n    align: \"center\",\n    valign: \"middle\",\n    fontSize: 14\n});\n```\n\n#### Table with Merged Cells\n\n```javascript\nconst mergedTableData = [\n    [\n        { text: \"Q1 Results\", options: { colspan: 3, fill: { color: \"4472C4\" }, color: \"FFFFFF\", bold: true } }\n    ],\n    [\"Product\", \"Sales\", \"Market Share\"],\n    [\"Product A\", \"$25M\", \"35%\"],\n    [\"Product B\", \"$18M\", \"25%\"]\n];\n\nslide.addTable(mergedTableData, {\n    x: 1,\n    y: 1,\n    w: 8,\n    h: 2.5,\n    colW: [3, 2.5, 2.5],\n    border: { pt: 1, color: \"DDDDDD\" }\n});\n```\n\n### Table Options\n\nCommon table options:\n- `x, y, w, h` - Position and size\n- `colW` - Array of column widths (in inches)\n- `rowH` - Array of row heights (in inches)\n- `border` - Border style: `{ pt: 1, color: \"999999\" }`\n- `fill` - Background color (no # prefix)\n- `align` - Text alignment: \"left\", \"center\", \"right\"\n- `valign` - Vertical alignment: \"top\", \"middle\", \"bottom\"\n- `fontSize` - Text size\n- `autoPage` - Auto-create new slides if content overflows",
        ".claude/skills/pptx/ooxml.md": "# Office Open XML Technical Reference for PowerPoint\n\n**Important: Read this entire document before starting.** Critical XML schema rules and formatting requirements are covered throughout. Incorrect implementation can create invalid PPTX files that PowerPoint cannot open.\n\n## Technical Guidelines\n\n### Schema Compliance\n- **Element ordering in `<p:txBody>`**: `<a:bodyPr>`, `<a:lstStyle>`, `<a:p>`\n- **Whitespace**: Add `xml:space='preserve'` to `<a:t>` elements with leading/trailing spaces\n- **Unicode**: Escape characters in ASCII content: `\"` becomes `&#8220;`\n- **Images**: Add to `ppt/media/`, reference in slide XML, set dimensions to fit slide bounds\n- **Relationships**: Update `ppt/slides/_rels/slideN.xml.rels` for each slide's resources\n- **Dirty attribute**: Add `dirty=\"0\"` to `<a:rPr>` and `<a:endParaRPr>` elements to indicate clean state\n\n## Presentation Structure\n\n### Basic Slide Structure\n```xml\n<!-- ppt/slides/slide1.xml -->\n<p:sld>\n  <p:cSld>\n    <p:spTree>\n      <p:nvGrpSpPr>...</p:nvGrpSpPr>\n      <p:grpSpPr>...</p:grpSpPr>\n      <!-- Shapes go here -->\n    </p:spTree>\n  </p:cSld>\n</p:sld>\n```\n\n### Text Box / Shape with Text\n```xml\n<p:sp>\n  <p:nvSpPr>\n    <p:cNvPr id=\"2\" name=\"Title\"/>\n    <p:cNvSpPr>\n      <a:spLocks noGrp=\"1\"/>\n    </p:cNvSpPr>\n    <p:nvPr>\n      <p:ph type=\"ctrTitle\"/>\n    </p:nvPr>\n  </p:nvSpPr>\n  <p:spPr>\n    <a:xfrm>\n      <a:off x=\"838200\" y=\"365125\"/>\n      <a:ext cx=\"7772400\" cy=\"1470025\"/>\n    </a:xfrm>\n  </p:spPr>\n  <p:txBody>\n    <a:bodyPr/>\n    <a:lstStyle/>\n    <a:p>\n      <a:r>\n        <a:t>Slide Title</a:t>\n      </a:r>\n    </a:p>\n  </p:txBody>\n</p:sp>\n```\n\n### Text Formatting\n```xml\n<!-- Bold -->\n<a:r>\n  <a:rPr b=\"1\"/>\n  <a:t>Bold Text</a:t>\n</a:r>\n\n<!-- Italic -->\n<a:r>\n  <a:rPr i=\"1\"/>\n  <a:t>Italic Text</a:t>\n</a:r>\n\n<!-- Underline -->\n<a:r>\n  <a:rPr u=\"sng\"/>\n  <a:t>Underlined</a:t>\n</a:r>\n\n<!-- Highlight -->\n<a:r>\n  <a:rPr>\n    <a:highlight>\n      <a:srgbClr val=\"FFFF00\"/>\n    </a:highlight>\n  </a:rPr>\n  <a:t>Highlighted Text</a:t>\n</a:r>\n\n<!-- Font and Size -->\n<a:r>\n  <a:rPr sz=\"2400\" typeface=\"Arial\">\n    <a:solidFill>\n      <a:srgbClr val=\"FF0000\"/>\n    </a:solidFill>\n  </a:rPr>\n  <a:t>Colored Arial 24pt</a:t>\n</a:r>\n\n<!-- Complete formatting example -->\n<a:r>\n  <a:rPr lang=\"en-US\" sz=\"1400\" b=\"1\" dirty=\"0\">\n    <a:solidFill>\n      <a:srgbClr val=\"FAFAFA\"/>\n    </a:solidFill>\n  </a:rPr>\n  <a:t>Formatted text</a:t>\n</a:r>\n```\n\n### Lists\n```xml\n<!-- Bullet list -->\n<a:p>\n  <a:pPr lvl=\"0\">\n    <a:buChar char=\"\"/>\n  </a:pPr>\n  <a:r>\n    <a:t>First bullet point</a:t>\n  </a:r>\n</a:p>\n\n<!-- Numbered list -->\n<a:p>\n  <a:pPr lvl=\"0\">\n    <a:buAutoNum type=\"arabicPeriod\"/>\n  </a:pPr>\n  <a:r>\n    <a:t>First numbered item</a:t>\n  </a:r>\n</a:p>\n\n<!-- Second level indent -->\n<a:p>\n  <a:pPr lvl=\"1\">\n    <a:buChar char=\"\"/>\n  </a:pPr>\n  <a:r>\n    <a:t>Indented bullet</a:t>\n  </a:r>\n</a:p>\n```\n\n### Shapes\n```xml\n<!-- Rectangle -->\n<p:sp>\n  <p:nvSpPr>\n    <p:cNvPr id=\"3\" name=\"Rectangle\"/>\n    <p:cNvSpPr/>\n    <p:nvPr/>\n  </p:nvSpPr>\n  <p:spPr>\n    <a:xfrm>\n      <a:off x=\"1000000\" y=\"1000000\"/>\n      <a:ext cx=\"3000000\" cy=\"2000000\"/>\n    </a:xfrm>\n    <a:prstGeom prst=\"rect\">\n      <a:avLst/>\n    </a:prstGeom>\n    <a:solidFill>\n      <a:srgbClr val=\"FF0000\"/>\n    </a:solidFill>\n    <a:ln w=\"25400\">\n      <a:solidFill>\n        <a:srgbClr val=\"000000\"/>\n      </a:solidFill>\n    </a:ln>\n  </p:spPr>\n</p:sp>\n\n<!-- Rounded Rectangle -->\n<p:sp>\n  <p:spPr>\n    <a:prstGeom prst=\"roundRect\">\n      <a:avLst/>\n    </a:prstGeom>\n  </p:spPr>\n</p:sp>\n\n<!-- Circle/Ellipse -->\n<p:sp>\n  <p:spPr>\n    <a:prstGeom prst=\"ellipse\">\n      <a:avLst/>\n    </a:prstGeom>\n  </p:spPr>\n</p:sp>\n```\n\n### Images\n```xml\n<p:pic>\n  <p:nvPicPr>\n    <p:cNvPr id=\"4\" name=\"Picture\">\n      <a:hlinkClick r:id=\"\" action=\"ppaction://media\"/>\n    </p:cNvPr>\n    <p:cNvPicPr>\n      <a:picLocks noChangeAspect=\"1\"/>\n    </p:cNvPicPr>\n    <p:nvPr/>\n  </p:nvPicPr>\n  <p:blipFill>\n    <a:blip r:embed=\"rId2\"/>\n    <a:stretch>\n      <a:fillRect/>\n    </a:stretch>\n  </p:blipFill>\n  <p:spPr>\n    <a:xfrm>\n      <a:off x=\"1000000\" y=\"1000000\"/>\n      <a:ext cx=\"3000000\" cy=\"2000000\"/>\n    </a:xfrm>\n    <a:prstGeom prst=\"rect\">\n      <a:avLst/>\n    </a:prstGeom>\n  </p:spPr>\n</p:pic>\n```\n\n### Tables\n```xml\n<p:graphicFrame>\n  <p:nvGraphicFramePr>\n    <p:cNvPr id=\"5\" name=\"Table\"/>\n    <p:cNvGraphicFramePr>\n      <a:graphicFrameLocks noGrp=\"1\"/>\n    </p:cNvGraphicFramePr>\n    <p:nvPr/>\n  </p:nvGraphicFramePr>\n  <p:xfrm>\n    <a:off x=\"1000000\" y=\"1000000\"/>\n    <a:ext cx=\"6000000\" cy=\"2000000\"/>\n  </p:xfrm>\n  <a:graphic>\n    <a:graphicData uri=\"http://schemas.openxmlformats.org/drawingml/2006/table\">\n      <a:tbl>\n        <a:tblGrid>\n          <a:gridCol w=\"3000000\"/>\n          <a:gridCol w=\"3000000\"/>\n        </a:tblGrid>\n        <a:tr h=\"500000\">\n          <a:tc>\n            <a:txBody>\n              <a:bodyPr/>\n              <a:lstStyle/>\n              <a:p>\n                <a:r>\n                  <a:t>Cell 1</a:t>\n                </a:r>\n              </a:p>\n            </a:txBody>\n          </a:tc>\n          <a:tc>\n            <a:txBody>\n              <a:bodyPr/>\n              <a:lstStyle/>\n              <a:p>\n                <a:r>\n                  <a:t>Cell 2</a:t>\n                </a:r>\n              </a:p>\n            </a:txBody>\n          </a:tc>\n        </a:tr>\n      </a:tbl>\n    </a:graphicData>\n  </a:graphic>\n</p:graphicFrame>\n```\n\n### Slide Layouts\n\n```xml\n<!-- Title Slide Layout -->\n<p:sp>\n  <p:nvSpPr>\n    <p:nvPr>\n      <p:ph type=\"ctrTitle\"/>\n    </p:nvPr>\n  </p:nvSpPr>\n  <!-- Title content -->\n</p:sp>\n\n<p:sp>\n  <p:nvSpPr>\n    <p:nvPr>\n      <p:ph type=\"subTitle\" idx=\"1\"/>\n    </p:nvPr>\n  </p:nvSpPr>\n  <!-- Subtitle content -->\n</p:sp>\n\n<!-- Content Slide Layout -->\n<p:sp>\n  <p:nvSpPr>\n    <p:nvPr>\n      <p:ph type=\"title\"/>\n    </p:nvPr>\n  </p:nvSpPr>\n  <!-- Slide title -->\n</p:sp>\n\n<p:sp>\n  <p:nvSpPr>\n    <p:nvPr>\n      <p:ph type=\"body\" idx=\"1\"/>\n    </p:nvPr>\n  </p:nvSpPr>\n  <!-- Content body -->\n</p:sp>\n```\n\n## File Updates\n\nWhen adding content, update these files:\n\n**`ppt/_rels/presentation.xml.rels`:**\n```xml\n<Relationship Id=\"rId1\" Type=\"http://schemas.openxmlformats.org/officeDocument/2006/relationships/slide\" Target=\"slides/slide1.xml\"/>\n<Relationship Id=\"rId2\" Type=\"http://schemas.openxmlformats.org/officeDocument/2006/relationships/slideMaster\" Target=\"slideMasters/slideMaster1.xml\"/>\n```\n\n**`ppt/slides/_rels/slide1.xml.rels`:**\n```xml\n<Relationship Id=\"rId1\" Type=\"http://schemas.openxmlformats.org/officeDocument/2006/relationships/slideLayout\" Target=\"../slideLayouts/slideLayout1.xml\"/>\n<Relationship Id=\"rId2\" Type=\"http://schemas.openxmlformats.org/officeDocument/2006/relationships/image\" Target=\"../media/image1.png\"/>\n```\n\n**`[Content_Types].xml`:**\n```xml\n<Default Extension=\"png\" ContentType=\"image/png\"/>\n<Default Extension=\"jpg\" ContentType=\"image/jpeg\"/>\n<Override PartName=\"/ppt/slides/slide1.xml\" ContentType=\"application/vnd.openxmlformats-officedocument.presentationml.slide+xml\"/>\n```\n\n**`ppt/presentation.xml`:**\n```xml\n<p:sldIdLst>\n  <p:sldId id=\"256\" r:id=\"rId1\"/>\n  <p:sldId id=\"257\" r:id=\"rId2\"/>\n</p:sldIdLst>\n```\n\n**`docProps/app.xml`:** Update slide count and statistics\n```xml\n<Slides>2</Slides>\n<Paragraphs>10</Paragraphs>\n<Words>50</Words>\n```\n\n## Slide Operations\n\n### Adding a New Slide\nWhen adding a slide to the end of the presentation:\n\n1. **Create the slide file** (`ppt/slides/slideN.xml`)\n2. **Update `[Content_Types].xml`**: Add Override for the new slide\n3. **Update `ppt/_rels/presentation.xml.rels`**: Add relationship for the new slide\n4. **Update `ppt/presentation.xml`**: Add slide ID to `<p:sldIdLst>`\n5. **Create slide relationships** (`ppt/slides/_rels/slideN.xml.rels`) if needed\n6. **Update `docProps/app.xml`**: Increment slide count and update statistics (if present)\n\n### Duplicating a Slide\n1. Copy the source slide XML file with a new name\n2. Update all IDs in the new slide to be unique\n3. Follow the \"Adding a New Slide\" steps above\n4. **CRITICAL**: Remove or update any notes slide references in `_rels` files\n5. Remove references to unused media files\n\n### Reordering Slides\n1. **Update `ppt/presentation.xml`**: Reorder `<p:sldId>` elements in `<p:sldIdLst>`\n2. The order of `<p:sldId>` elements determines slide order\n3. Keep slide IDs and relationship IDs unchanged\n\nExample:\n```xml\n<!-- Original order -->\n<p:sldIdLst>\n  <p:sldId id=\"256\" r:id=\"rId2\"/>\n  <p:sldId id=\"257\" r:id=\"rId3\"/>\n  <p:sldId id=\"258\" r:id=\"rId4\"/>\n</p:sldIdLst>\n\n<!-- After moving slide 3 to position 2 -->\n<p:sldIdLst>\n  <p:sldId id=\"256\" r:id=\"rId2\"/>\n  <p:sldId id=\"258\" r:id=\"rId4\"/>\n  <p:sldId id=\"257\" r:id=\"rId3\"/>\n</p:sldIdLst>\n```\n\n### Deleting a Slide\n1. **Remove from `ppt/presentation.xml`**: Delete the `<p:sldId>` entry\n2. **Remove from `ppt/_rels/presentation.xml.rels`**: Delete the relationship\n3. **Remove from `[Content_Types].xml`**: Delete the Override entry\n4. **Delete files**: Remove `ppt/slides/slideN.xml` and `ppt/slides/_rels/slideN.xml.rels`\n5. **Update `docProps/app.xml`**: Decrement slide count and update statistics\n6. **Clean up unused media**: Remove orphaned images from `ppt/media/`\n\nNote: Don't renumber remaining slides - keep their original IDs and filenames.\n\n\n## Common Errors to Avoid\n\n- **Encodings**: Escape unicode characters in ASCII content: `\"` becomes `&#8220;`\n- **Images**: Add to `ppt/media/` and update relationship files\n- **Lists**: Omit bullets from list headers\n- **IDs**: Use valid hexadecimal values for UUIDs\n- **Themes**: Check all themes in `theme` directory for colors\n\n## Validation Checklist for Template-Based Presentations\n\n### Before Packing, Always:\n- **Clean unused resources**: Remove unreferenced media, fonts, and notes directories\n- **Fix Content_Types.xml**: Declare ALL slides, layouts, and themes present in the package\n- **Fix relationship IDs**: \n   - Remove font embed references if not using embedded fonts\n- **Remove broken references**: Check all `_rels` files for references to deleted resources\n\n### Common Template Duplication Pitfalls:\n- Multiple slides referencing the same notes slide after duplication\n- Image/media references from template slides that no longer exist\n- Font embedding references when fonts aren't included\n- Missing slideLayout declarations for layouts 12-25\n- docProps directory may not unpack - this is optional",
        ".claude/skills/skill-creator/SKILL.md": "---\nname: skill-creator\ndescription: Guide for creating effective skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations.\nlicense: Complete terms in LICENSE.txt\n---\n\n# Skill Creator\n\nThis skill provides guidance for creating effective skills.\n\n## About Skills\n\nSkills are modular, self-contained packages that extend Claude's capabilities by providing\nspecialized knowledge, workflows, and tools. Think of them as \"onboarding guides\" for specific\ndomains or tasksthey transform Claude from a general-purpose agent into a specialized agent\nequipped with procedural knowledge that no model can fully possess.\n\n### What Skills Provide\n\n1. Specialized workflows - Multi-step procedures for specific domains\n2. Tool integrations - Instructions for working with specific file formats or APIs\n3. Domain expertise - Company-specific knowledge, schemas, business logic\n4. Bundled resources - Scripts, references, and assets for complex and repetitive tasks\n\n## Core Principles\n\n### Concise is Key\n\nThe context window is a public good. Skills share the context window with everything else Claude needs: system prompt, conversation history, other Skills' metadata, and the actual user request.\n\n**Default assumption: Claude is already very smart.** Only add context Claude doesn't already have. Challenge each piece of information: \"Does Claude really need this explanation?\" and \"Does this paragraph justify its token cost?\"\n\nPrefer concise examples over verbose explanations.\n\n### Set Appropriate Degrees of Freedom\n\nMatch the level of specificity to the task's fragility and variability:\n\n**High freedom (text-based instructions)**: Use when multiple approaches are valid, decisions depend on context, or heuristics guide the approach.\n\n**Medium freedom (pseudocode or scripts with parameters)**: Use when a preferred pattern exists, some variation is acceptable, or configuration affects behavior.\n\n**Low freedom (specific scripts, few parameters)**: Use when operations are fragile and error-prone, consistency is critical, or a specific sequence must be followed.\n\nThink of Claude as exploring a path: a narrow bridge with cliffs needs specific guardrails (low freedom), while an open field allows many routes (high freedom).\n\n### Anatomy of a Skill\n\nEvery skill consists of a required SKILL.md file and optional bundled resources:\n\n```\nskill-name/\n SKILL.md (required)\n    YAML frontmatter metadata (required)\n       name: (required)\n       description: (required)\n    Markdown instructions (required)\n Bundled Resources (optional)\n     scripts/          - Executable code (Python/Bash/etc.)\n     references/       - Documentation intended to be loaded into context as needed\n     assets/           - Files used in output (templates, icons, fonts, etc.)\n```\n\n#### SKILL.md (required)\n\nEvery SKILL.md consists of:\n\n- **Frontmatter** (YAML): Contains `name` and `description` fields. These are the only fields that Claude reads to determine when the skill gets used, thus it is very important to be clear and comprehensive in describing what the skill is, and when it should be used.\n- **Body** (Markdown): Instructions and guidance for using the skill. Only loaded AFTER the skill triggers (if at all).\n\n#### Bundled Resources (optional)\n\n##### Scripts (`scripts/`)\n\nExecutable code (Python/Bash/etc.) for tasks that require deterministic reliability or are repeatedly rewritten.\n\n- **When to include**: When the same code is being rewritten repeatedly or deterministic reliability is needed\n- **Example**: `scripts/rotate_pdf.py` for PDF rotation tasks\n- **Benefits**: Token efficient, deterministic, may be executed without loading into context\n- **Note**: Scripts may still need to be read by Claude for patching or environment-specific adjustments\n\n##### References (`references/`)\n\nDocumentation and reference material intended to be loaded as needed into context to inform Claude's process and thinking.\n\n- **When to include**: For documentation that Claude should reference while working\n- **Examples**: `references/finance.md` for financial schemas, `references/mnda.md` for company NDA template, `references/policies.md` for company policies, `references/api_docs.md` for API specifications\n- **Use cases**: Database schemas, API documentation, domain knowledge, company policies, detailed workflow guides\n- **Benefits**: Keeps SKILL.md lean, loaded only when Claude determines it's needed\n- **Best practice**: If files are large (>10k words), include grep search patterns in SKILL.md\n- **Avoid duplication**: Information should live in either SKILL.md or references files, not both. Prefer references files for detailed information unless it's truly core to the skillthis keeps SKILL.md lean while making information discoverable without hogging the context window. Keep only essential procedural instructions and workflow guidance in SKILL.md; move detailed reference material, schemas, and examples to references files.\n\n##### Assets (`assets/`)\n\nFiles not intended to be loaded into context, but rather used within the output Claude produces.\n\n- **When to include**: When the skill needs files that will be used in the final output\n- **Examples**: `assets/logo.png` for brand assets, `assets/slides.pptx` for PowerPoint templates, `assets/frontend-template/` for HTML/React boilerplate, `assets/font.ttf` for typography\n- **Use cases**: Templates, images, icons, boilerplate code, fonts, sample documents that get copied or modified\n- **Benefits**: Separates output resources from documentation, enables Claude to use files without loading them into context\n\n#### What to Not Include in a Skill\n\nA skill should only contain essential files that directly support its functionality. Do NOT create extraneous documentation or auxiliary files, including:\n\n- README.md\n- INSTALLATION_GUIDE.md\n- QUICK_REFERENCE.md\n- CHANGELOG.md\n- etc.\n\nThe skill should only contain the information needed for an AI agent to do the job at hand. It should not contain auxilary context about the process that went into creating it, setup and testing procedures, user-facing documentation, etc. Creating additional documentation files just adds clutter and confusion.\n\n### Progressive Disclosure Design Principle\n\nSkills use a three-level loading system to manage context efficiently:\n\n1. **Metadata (name + description)** - Always in context (~100 words)\n2. **SKILL.md body** - When skill triggers (<5k words)\n3. **Bundled resources** - As needed by Claude (Unlimited because scripts can be executed without reading into context window)\n\n#### Progressive Disclosure Patterns\n\nKeep SKILL.md body to the essentials and under 500 lines to minimize context bloat. Split content into separate files when approaching this limit. When splitting out content into other files, it is very important to reference them from SKILL.md and describe clearly when to read them, to ensure the reader of the skill knows they exist and when to use them.\n\n**Key principle:** When a skill supports multiple variations, frameworks, or options, keep only the core workflow and selection guidance in SKILL.md. Move variant-specific details (patterns, examples, configuration) into separate reference files.\n\n**Pattern 1: High-level guide with references**\n\n```markdown\n# PDF Processing\n\n## Quick start\n\nExtract text with pdfplumber:\n[code example]\n\n## Advanced features\n\n- **Form filling**: See [FORMS.md](FORMS.md) for complete guide\n- **API reference**: See [REFERENCE.md](REFERENCE.md) for all methods\n- **Examples**: See [EXAMPLES.md](EXAMPLES.md) for common patterns\n```\n\nClaude loads FORMS.md, REFERENCE.md, or EXAMPLES.md only when needed.\n\n**Pattern 2: Domain-specific organization**\n\nFor Skills with multiple domains, organize content by domain to avoid loading irrelevant context:\n\n```\nbigquery-skill/\n SKILL.md (overview and navigation)\n reference/\n     finance.md (revenue, billing metrics)\n     sales.md (opportunities, pipeline)\n     product.md (API usage, features)\n     marketing.md (campaigns, attribution)\n```\n\nWhen a user asks about sales metrics, Claude only reads sales.md.\n\nSimilarly, for skills supporting multiple frameworks or variants, organize by variant:\n\n```\ncloud-deploy/\n SKILL.md (workflow + provider selection)\n references/\n     aws.md (AWS deployment patterns)\n     gcp.md (GCP deployment patterns)\n     azure.md (Azure deployment patterns)\n```\n\nWhen the user chooses AWS, Claude only reads aws.md.\n\n**Pattern 3: Conditional details**\n\nShow basic content, link to advanced content:\n\n```markdown\n# DOCX Processing\n\n## Creating documents\n\nUse docx-js for new documents. See [DOCX-JS.md](DOCX-JS.md).\n\n## Editing documents\n\nFor simple edits, modify the XML directly.\n\n**For tracked changes**: See [REDLINING.md](REDLINING.md)\n**For OOXML details**: See [OOXML.md](OOXML.md)\n```\n\nClaude reads REDLINING.md or OOXML.md only when the user needs those features.\n\n**Important guidelines:**\n\n- **Avoid deeply nested references** - Keep references one level deep from SKILL.md. All reference files should link directly from SKILL.md.\n- **Structure longer reference files** - For files longer than 100 lines, include a table of contents at the top so Claude can see the full scope when previewing.\n\n## Skill Creation Process\n\nSkill creation involves these steps:\n\n1. Understand the skill with concrete examples\n2. Plan reusable skill contents (scripts, references, assets)\n3. Initialize the skill (run init_skill.py)\n4. Edit the skill (implement resources and write SKILL.md)\n5. Package the skill (run package_skill.py)\n6. Iterate based on real usage\n\nFollow these steps in order, skipping only if there is a clear reason why they are not applicable.\n\n### Step 1: Understanding the Skill with Concrete Examples\n\nSkip this step only when the skill's usage patterns are already clearly understood. It remains valuable even when working with an existing skill.\n\nTo create an effective skill, clearly understand concrete examples of how the skill will be used. This understanding can come from either direct user examples or generated examples that are validated with user feedback.\n\nFor example, when building an image-editor skill, relevant questions include:\n\n- \"What functionality should the image-editor skill support? Editing, rotating, anything else?\"\n- \"Can you give some examples of how this skill would be used?\"\n- \"I can imagine users asking for things like 'Remove the red-eye from this image' or 'Rotate this image'. Are there other ways you imagine this skill being used?\"\n- \"What would a user say that should trigger this skill?\"\n\nTo avoid overwhelming users, avoid asking too many questions in a single message. Start with the most important questions and follow up as needed for better effectiveness.\n\nConclude this step when there is a clear sense of the functionality the skill should support.\n\n### Step 2: Planning the Reusable Skill Contents\n\nTo turn concrete examples into an effective skill, analyze each example by:\n\n1. Considering how to execute on the example from scratch\n2. Identifying what scripts, references, and assets would be helpful when executing these workflows repeatedly\n\nExample: When building a `pdf-editor` skill to handle queries like \"Help me rotate this PDF,\" the analysis shows:\n\n1. Rotating a PDF requires re-writing the same code each time\n2. A `scripts/rotate_pdf.py` script would be helpful to store in the skill\n\nExample: When designing a `frontend-webapp-builder` skill for queries like \"Build me a todo app\" or \"Build me a dashboard to track my steps,\" the analysis shows:\n\n1. Writing a frontend webapp requires the same boilerplate HTML/React each time\n2. An `assets/hello-world/` template containing the boilerplate HTML/React project files would be helpful to store in the skill\n\nExample: When building a `big-query` skill to handle queries like \"How many users have logged in today?\" the analysis shows:\n\n1. Querying BigQuery requires re-discovering the table schemas and relationships each time\n2. A `references/schema.md` file documenting the table schemas would be helpful to store in the skill\n\nTo establish the skill's contents, analyze each concrete example to create a list of the reusable resources to include: scripts, references, and assets.\n\n### Step 3: Initializing the Skill\n\nAt this point, it is time to actually create the skill.\n\nSkip this step only if the skill being developed already exists, and iteration or packaging is needed. In this case, continue to the next step.\n\nWhen creating a new skill from scratch, always run the `init_skill.py` script. The script conveniently generates a new template skill directory that automatically includes everything a skill requires, making the skill creation process much more efficient and reliable.\n\nUsage:\n\n```bash\nscripts/init_skill.py <skill-name> --path <output-directory>\n```\n\nThe script:\n\n- Creates the skill directory at the specified path\n- Generates a SKILL.md template with proper frontmatter and TODO placeholders\n- Creates example resource directories: `scripts/`, `references/`, and `assets/`\n- Adds example files in each directory that can be customized or deleted\n\nAfter initialization, customize or remove the generated SKILL.md and example files as needed.\n\n### Step 4: Edit the Skill\n\nWhen editing the (newly-generated or existing) skill, remember that the skill is being created for another instance of Claude to use. Include information that would be beneficial and non-obvious to Claude. Consider what procedural knowledge, domain-specific details, or reusable assets would help another Claude instance execute these tasks more effectively.\n\n#### Learn Proven Design Patterns\n\nConsult these helpful guides based on your skill's needs:\n\n- **Multi-step processes**: See references/workflows.md for sequential workflows and conditional logic\n- **Specific output formats or quality standards**: See references/output-patterns.md for template and example patterns\n\nThese files contain established best practices for effective skill design.\n\n#### Start with Reusable Skill Contents\n\nTo begin implementation, start with the reusable resources identified above: `scripts/`, `references/`, and `assets/` files. Note that this step may require user input. For example, when implementing a `brand-guidelines` skill, the user may need to provide brand assets or templates to store in `assets/`, or documentation to store in `references/`.\n\nAdded scripts must be tested by actually running them to ensure there are no bugs and that the output matches what is expected. If there are many similar scripts, only a representative sample needs to be tested to ensure confidence that they all work while balancing time to completion.\n\nAny example files and directories not needed for the skill should be deleted. The initialization script creates example files in `scripts/`, `references/`, and `assets/` to demonstrate structure, but most skills won't need all of them.\n\n#### Update SKILL.md\n\n**Writing Guidelines:** Always use imperative/infinitive form.\n\n##### Frontmatter\n\nWrite the YAML frontmatter with `name` and `description`:\n\n- `name`: The skill name\n- `description`: This is the primary triggering mechanism for your skill, and helps Claude understand when to use the skill.\n  - Include both what the Skill does and specific triggers/contexts for when to use it.\n  - Include all \"when to use\" information here - Not in the body. The body is only loaded after triggering, so \"When to Use This Skill\" sections in the body are not helpful to Claude.\n  - Example description for a `docx` skill: \"Comprehensive document creation, editing, and analysis with support for tracked changes, comments, formatting preservation, and text extraction. Use when Claude needs to work with professional documents (.docx files) for: (1) Creating new documents, (2) Modifying or editing content, (3) Working with tracked changes, (4) Adding comments, or any other document tasks\"\n\nDo not include any other fields in YAML frontmatter.\n\n##### Body\n\nWrite instructions for using the skill and its bundled resources.\n\n### Step 5: Packaging a Skill\n\nOnce development of the skill is complete, it must be packaged into a distributable .skill file that gets shared with the user. The packaging process automatically validates the skill first to ensure it meets all requirements:\n\n```bash\nscripts/package_skill.py <path/to/skill-folder>\n```\n\nOptional output directory specification:\n\n```bash\nscripts/package_skill.py <path/to/skill-folder> ./dist\n```\n\nThe packaging script will:\n\n1. **Validate** the skill automatically, checking:\n\n   - YAML frontmatter format and required fields\n   - Skill naming conventions and directory structure\n   - Description completeness and quality\n   - File organization and resource references\n\n2. **Package** the skill if validation passes, creating a .skill file named after the skill (e.g., `my-skill.skill`) that includes all files and maintains the proper directory structure for distribution. The .skill file is a zip file with a .skill extension.\n\nIf validation fails, the script will report the errors and exit without creating a package. Fix any validation errors and run the packaging command again.\n\n### Step 6: Iterate\n\nAfter testing the skill, users may request improvements. Often this happens right after using the skill, with fresh context of how the skill performed.\n\n**Iteration workflow:**\n\n1. Use the skill on real tasks\n2. Notice struggles or inefficiencies\n3. Identify how SKILL.md or bundled resources should be updated\n4. Implement changes and test again\n",
        ".claude/skills/skill-creator/references/output-patterns.md": "# Output Patterns\n\nUse these patterns when skills need to produce consistent, high-quality output.\n\n## Template Pattern\n\nProvide templates for output format. Match the level of strictness to your needs.\n\n**For strict requirements (like API responses or data formats):**\n\n```markdown\n## Report structure\n\nALWAYS use this exact template structure:\n\n# [Analysis Title]\n\n## Executive summary\n[One-paragraph overview of key findings]\n\n## Key findings\n- Finding 1 with supporting data\n- Finding 2 with supporting data\n- Finding 3 with supporting data\n\n## Recommendations\n1. Specific actionable recommendation\n2. Specific actionable recommendation\n```\n\n**For flexible guidance (when adaptation is useful):**\n\n```markdown\n## Report structure\n\nHere is a sensible default format, but use your best judgment:\n\n# [Analysis Title]\n\n## Executive summary\n[Overview]\n\n## Key findings\n[Adapt sections based on what you discover]\n\n## Recommendations\n[Tailor to the specific context]\n\nAdjust sections as needed for the specific analysis type.\n```\n\n## Examples Pattern\n\nFor skills where output quality depends on seeing examples, provide input/output pairs:\n\n```markdown\n## Commit message format\n\nGenerate commit messages following these examples:\n\n**Example 1:**\nInput: Added user authentication with JWT tokens\nOutput:\n```\nfeat(auth): implement JWT-based authentication\n\nAdd login endpoint and token validation middleware\n```\n\n**Example 2:**\nInput: Fixed bug where dates displayed incorrectly in reports\nOutput:\n```\nfix(reports): correct date formatting in timezone conversion\n\nUse UTC timestamps consistently across report generation\n```\n\nFollow this style: type(scope): brief description, then detailed explanation.\n```\n\nExamples help Claude understand the desired style and level of detail more clearly than descriptions alone.\n",
        ".claude/skills/skill-creator/references/workflows.md": "# Workflow Patterns\n\n## Sequential Workflows\n\nFor complex tasks, break operations into clear, sequential steps. It is often helpful to give Claude an overview of the process towards the beginning of SKILL.md:\n\n```markdown\nFilling a PDF form involves these steps:\n\n1. Analyze the form (run analyze_form.py)\n2. Create field mapping (edit fields.json)\n3. Validate mapping (run validate_fields.py)\n4. Fill the form (run fill_form.py)\n5. Verify output (run verify_output.py)\n```\n\n## Conditional Workflows\n\nFor tasks with branching logic, guide Claude through decision points:\n\n```markdown\n1. Determine the modification type:\n   **Creating new content?**  Follow \"Creation workflow\" below\n   **Editing existing content?**  Follow \"Editing workflow\" below\n\n2. Creation workflow: [steps]\n3. Editing workflow: [steps]\n```",
        ".claude/skills/slack-gif-creator/SKILL.md": "---\nname: slack-gif-creator\ndescription: Knowledge and utilities for creating animated GIFs optimized for Slack. Provides constraints, validation tools, and animation concepts. Use when users request animated GIFs for Slack like \"make me a GIF of X doing Y for Slack.\"\nlicense: Complete terms in LICENSE.txt\n---\n\n# Slack GIF Creator\n\nA toolkit providing utilities and knowledge for creating animated GIFs optimized for Slack.\n\n## Slack Requirements\n\n**Dimensions:**\n- Emoji GIFs: 128x128 (recommended)\n- Message GIFs: 480x480\n\n**Parameters:**\n- FPS: 10-30 (lower is smaller file size)\n- Colors: 48-128 (fewer = smaller file size)\n- Duration: Keep under 3 seconds for emoji GIFs\n\n## Core Workflow\n\n```python\nfrom core.gif_builder import GIFBuilder\nfrom PIL import Image, ImageDraw\n\n# 1. Create builder\nbuilder = GIFBuilder(width=128, height=128, fps=10)\n\n# 2. Generate frames\nfor i in range(12):\n    frame = Image.new('RGB', (128, 128), (240, 248, 255))\n    draw = ImageDraw.Draw(frame)\n\n    # Draw your animation using PIL primitives\n    # (circles, polygons, lines, etc.)\n\n    builder.add_frame(frame)\n\n# 3. Save with optimization\nbuilder.save('output.gif', num_colors=48, optimize_for_emoji=True)\n```\n\n## Drawing Graphics\n\n### Working with User-Uploaded Images\nIf a user uploads an image, consider whether they want to:\n- **Use it directly** (e.g., \"animate this\", \"split this into frames\")\n- **Use it as inspiration** (e.g., \"make something like this\")\n\nLoad and work with images using PIL:\n```python\nfrom PIL import Image\n\nuploaded = Image.open('file.png')\n# Use directly, or just as reference for colors/style\n```\n\n### Drawing from Scratch\nWhen drawing graphics from scratch, use PIL ImageDraw primitives:\n\n```python\nfrom PIL import ImageDraw\n\ndraw = ImageDraw.Draw(frame)\n\n# Circles/ovals\ndraw.ellipse([x1, y1, x2, y2], fill=(r, g, b), outline=(r, g, b), width=3)\n\n# Stars, triangles, any polygon\npoints = [(x1, y1), (x2, y2), (x3, y3), ...]\ndraw.polygon(points, fill=(r, g, b), outline=(r, g, b), width=3)\n\n# Lines\ndraw.line([(x1, y1), (x2, y2)], fill=(r, g, b), width=5)\n\n# Rectangles\ndraw.rectangle([x1, y1, x2, y2], fill=(r, g, b), outline=(r, g, b), width=3)\n```\n\n**Don't use:** Emoji fonts (unreliable across platforms) or assume pre-packaged graphics exist in this skill.\n\n### Making Graphics Look Good\n\nGraphics should look polished and creative, not basic. Here's how:\n\n**Use thicker lines** - Always set `width=2` or higher for outlines and lines. Thin lines (width=1) look choppy and amateurish.\n\n**Add visual depth**:\n- Use gradients for backgrounds (`create_gradient_background`)\n- Layer multiple shapes for complexity (e.g., a star with a smaller star inside)\n\n**Make shapes more interesting**:\n- Don't just draw a plain circle - add highlights, rings, or patterns\n- Stars can have glows (draw larger, semi-transparent versions behind)\n- Combine multiple shapes (stars + sparkles, circles + rings)\n\n**Pay attention to colors**:\n- Use vibrant, complementary colors\n- Add contrast (dark outlines on light shapes, light outlines on dark shapes)\n- Consider the overall composition\n\n**For complex shapes** (hearts, snowflakes, etc.):\n- Use combinations of polygons and ellipses\n- Calculate points carefully for symmetry\n- Add details (a heart can have a highlight curve, snowflakes have intricate branches)\n\nBe creative and detailed! A good Slack GIF should look polished, not like placeholder graphics.\n\n## Available Utilities\n\n### GIFBuilder (`core.gif_builder`)\nAssembles frames and optimizes for Slack:\n```python\nbuilder = GIFBuilder(width=128, height=128, fps=10)\nbuilder.add_frame(frame)  # Add PIL Image\nbuilder.add_frames(frames)  # Add list of frames\nbuilder.save('out.gif', num_colors=48, optimize_for_emoji=True, remove_duplicates=True)\n```\n\n### Validators (`core.validators`)\nCheck if GIF meets Slack requirements:\n```python\nfrom core.validators import validate_gif, is_slack_ready\n\n# Detailed validation\npasses, info = validate_gif('my.gif', is_emoji=True, verbose=True)\n\n# Quick check\nif is_slack_ready('my.gif'):\n    print(\"Ready!\")\n```\n\n### Easing Functions (`core.easing`)\nSmooth motion instead of linear:\n```python\nfrom core.easing import interpolate\n\n# Progress from 0.0 to 1.0\nt = i / (num_frames - 1)\n\n# Apply easing\ny = interpolate(start=0, end=400, t=t, easing='ease_out')\n\n# Available: linear, ease_in, ease_out, ease_in_out,\n#           bounce_out, elastic_out, back_out\n```\n\n### Frame Helpers (`core.frame_composer`)\nConvenience functions for common needs:\n```python\nfrom core.frame_composer import (\n    create_blank_frame,         # Solid color background\n    create_gradient_background,  # Vertical gradient\n    draw_circle,                # Helper for circles\n    draw_text,                  # Simple text rendering\n    draw_star                   # 5-pointed star\n)\n```\n\n## Animation Concepts\n\n### Shake/Vibrate\nOffset object position with oscillation:\n- Use `math.sin()` or `math.cos()` with frame index\n- Add small random variations for natural feel\n- Apply to x and/or y position\n\n### Pulse/Heartbeat\nScale object size rhythmically:\n- Use `math.sin(t * frequency * 2 * math.pi)` for smooth pulse\n- For heartbeat: two quick pulses then pause (adjust sine wave)\n- Scale between 0.8 and 1.2 of base size\n\n### Bounce\nObject falls and bounces:\n- Use `interpolate()` with `easing='bounce_out'` for landing\n- Use `easing='ease_in'` for falling (accelerating)\n- Apply gravity by increasing y velocity each frame\n\n### Spin/Rotate\nRotate object around center:\n- PIL: `image.rotate(angle, resample=Image.BICUBIC)`\n- For wobble: use sine wave for angle instead of linear\n\n### Fade In/Out\nGradually appear or disappear:\n- Create RGBA image, adjust alpha channel\n- Or use `Image.blend(image1, image2, alpha)`\n- Fade in: alpha from 0 to 1\n- Fade out: alpha from 1 to 0\n\n### Slide\nMove object from off-screen to position:\n- Start position: outside frame bounds\n- End position: target location\n- Use `interpolate()` with `easing='ease_out'` for smooth stop\n- For overshoot: use `easing='back_out'`\n\n### Zoom\nScale and position for zoom effect:\n- Zoom in: scale from 0.1 to 2.0, crop center\n- Zoom out: scale from 2.0 to 1.0\n- Can add motion blur for drama (PIL filter)\n\n### Explode/Particle Burst\nCreate particles radiating outward:\n- Generate particles with random angles and velocities\n- Update each particle: `x += vx`, `y += vy`\n- Add gravity: `vy += gravity_constant`\n- Fade out particles over time (reduce alpha)\n\n## Optimization Strategies\n\nOnly when asked to make the file size smaller, implement a few of the following methods:\n\n1. **Fewer frames** - Lower FPS (10 instead of 20) or shorter duration\n2. **Fewer colors** - `num_colors=48` instead of 128\n3. **Smaller dimensions** - 128x128 instead of 480x480\n4. **Remove duplicates** - `remove_duplicates=True` in save()\n5. **Emoji mode** - `optimize_for_emoji=True` auto-optimizes\n\n```python\n# Maximum optimization for emoji\nbuilder.save(\n    'emoji.gif',\n    num_colors=48,\n    optimize_for_emoji=True,\n    remove_duplicates=True\n)\n```\n\n## Philosophy\n\nThis skill provides:\n- **Knowledge**: Slack's requirements and animation concepts\n- **Utilities**: GIFBuilder, validators, easing functions\n- **Flexibility**: Create the animation logic using PIL primitives\n\nIt does NOT provide:\n- Rigid animation templates or pre-made functions\n- Emoji font rendering (unreliable across platforms)\n- A library of pre-packaged graphics built into the skill\n\n**Note on user uploads**: This skill doesn't include pre-built graphics, but if a user uploads an image, use PIL to load and work with it - interpret based on their request whether they want it used directly or just as inspiration.\n\nBe creative! Combine concepts (bouncing + rotating, pulsing + sliding, etc.) and use PIL's full capabilities.\n\n## Dependencies\n\n```bash\npip install pillow imageio numpy\n```\n",
        ".claude/skills/theme-factory/SKILL.md": "---\nname: theme-factory\ndescription: Toolkit for styling artifacts with a theme. These artifacts can be slides, docs, reportings, HTML landing pages, etc. There are 10 pre-set themes with colors/fonts that you can apply to any artifact that has been creating, or can generate a new theme on-the-fly.\nlicense: Complete terms in LICENSE.txt\n---\n\n\n# Theme Factory Skill\n\nThis skill provides a curated collection of professional font and color themes themes, each with carefully selected color palettes and font pairings. Once a theme is chosen, it can be applied to any artifact.\n\n## Purpose\n\nTo apply consistent, professional styling to presentation slide decks, use this skill. Each theme includes:\n- A cohesive color palette with hex codes\n- Complementary font pairings for headers and body text\n- A distinct visual identity suitable for different contexts and audiences\n\n## Usage Instructions\n\nTo apply styling to a slide deck or other artifact:\n\n1. **Show the theme showcase**: Display the `theme-showcase.pdf` file to allow users to see all available themes visually. Do not make any modifications to it; simply show the file for viewing.\n2. **Ask for their choice**: Ask which theme to apply to the deck\n3. **Wait for selection**: Get explicit confirmation about the chosen theme\n4. **Apply the theme**: Once a theme has been chosen, apply the selected theme's colors and fonts to the deck/artifact\n\n## Themes Available\n\nThe following 10 themes are available, each showcased in `theme-showcase.pdf`:\n\n1. **Ocean Depths** - Professional and calming maritime theme\n2. **Sunset Boulevard** - Warm and vibrant sunset colors\n3. **Forest Canopy** - Natural and grounded earth tones\n4. **Modern Minimalist** - Clean and contemporary grayscale\n5. **Golden Hour** - Rich and warm autumnal palette\n6. **Arctic Frost** - Cool and crisp winter-inspired theme\n7. **Desert Rose** - Soft and sophisticated dusty tones\n8. **Tech Innovation** - Bold and modern tech aesthetic\n9. **Botanical Garden** - Fresh and organic garden colors\n10. **Midnight Galaxy** - Dramatic and cosmic deep tones\n\n## Theme Details\n\nEach theme is defined in the `themes/` directory with complete specifications including:\n- Cohesive color palette with hex codes\n- Complementary font pairings for headers and body text\n- Distinct visual identity suitable for different contexts and audiences\n\n## Application Process\n\nAfter a preferred theme is selected:\n1. Read the corresponding theme file from the `themes/` directory\n2. Apply the specified colors and fonts consistently throughout the deck\n3. Ensure proper contrast and readability\n4. Maintain the theme's visual identity across all slides\n\n## Create your Own Theme\nTo handle cases where none of the existing themes work for an artifact, create a custom theme. Based on provided inputs, generate a new theme similar to the ones above. Give the theme a similar name describing what the font/color combinations represent. Use any basic description provided to choose appropriate colors/fonts. After generating the theme, show it for review and verification. Following that, apply the theme as described above.\n",
        ".claude/skills/theme-factory/themes/arctic-frost.md": "# Arctic Frost\n\nA cool and crisp winter-inspired theme that conveys clarity, precision, and professionalism.\n\n## Color Palette\n\n- **Ice Blue**: `#d4e4f7` - Light backgrounds and highlights\n- **Steel Blue**: `#4a6fa5` - Primary accent color\n- **Silver**: `#c0c0c0` - Metallic accent elements\n- **Crisp White**: `#fafafa` - Clean backgrounds and text\n\n## Typography\n\n- **Headers**: DejaVu Sans Bold\n- **Body Text**: DejaVu Sans\n\n## Best Used For\n\nHealthcare presentations, technology solutions, winter sports, clean tech, pharmaceutical content.\n",
        ".claude/skills/theme-factory/themes/botanical-garden.md": "# Botanical Garden\n\nA fresh and organic theme featuring vibrant garden-inspired colors for lively presentations.\n\n## Color Palette\n\n- **Fern Green**: `#4a7c59` - Rich natural green\n- **Marigold**: `#f9a620` - Bright floral accent\n- **Terracotta**: `#b7472a` - Earthy warm tone\n- **Cream**: `#f5f3ed` - Soft neutral backgrounds\n\n## Typography\n\n- **Headers**: DejaVu Serif Bold\n- **Body Text**: DejaVu Sans\n\n## Best Used For\n\nGarden centers, food presentations, farm-to-table content, botanical brands, natural products.\n",
        ".claude/skills/theme-factory/themes/desert-rose.md": "# Desert Rose\n\nA soft and sophisticated theme with dusty, muted tones perfect for elegant presentations.\n\n## Color Palette\n\n- **Dusty Rose**: `#d4a5a5` - Soft primary color\n- **Clay**: `#b87d6d` - Earthy accent\n- **Sand**: `#e8d5c4` - Warm neutral backgrounds\n- **Deep Burgundy**: `#5d2e46` - Rich dark contrast\n\n## Typography\n\n- **Headers**: FreeSans Bold\n- **Body Text**: FreeSans\n\n## Best Used For\n\nFashion presentations, beauty brands, wedding planning, interior design, boutique businesses.\n",
        ".claude/skills/theme-factory/themes/forest-canopy.md": "# Forest Canopy\n\nA natural and grounded theme featuring earth tones inspired by dense forest environments.\n\n## Color Palette\n\n- **Forest Green**: `#2d4a2b` - Primary dark green\n- **Sage**: `#7d8471` - Muted green accent\n- **Olive**: `#a4ac86` - Light accent color\n- **Ivory**: `#faf9f6` - Backgrounds and text\n\n## Typography\n\n- **Headers**: FreeSerif Bold\n- **Body Text**: FreeSans\n\n## Best Used For\n\nEnvironmental presentations, sustainability reports, outdoor brands, wellness content, organic products.\n",
        ".claude/skills/theme-factory/themes/golden-hour.md": "# Golden Hour\n\nA rich and warm autumnal palette that creates an inviting and sophisticated atmosphere.\n\n## Color Palette\n\n- **Mustard Yellow**: `#f4a900` - Bold primary accent\n- **Terracotta**: `#c1666b` - Warm secondary color\n- **Warm Beige**: `#d4b896` - Neutral backgrounds\n- **Chocolate Brown**: `#4a403a` - Dark text and anchors\n\n## Typography\n\n- **Headers**: FreeSans Bold\n- **Body Text**: FreeSans\n\n## Best Used For\n\nRestaurant presentations, hospitality brands, fall campaigns, cozy lifestyle content, artisan products.\n",
        ".claude/skills/theme-factory/themes/midnight-galaxy.md": "# Midnight Galaxy\n\nA dramatic and cosmic theme with deep purples and mystical tones for impactful presentations.\n\n## Color Palette\n\n- **Deep Purple**: `#2b1e3e` - Rich dark base\n- **Cosmic Blue**: `#4a4e8f` - Mystical mid-tone\n- **Lavender**: `#a490c2` - Soft accent color\n- **Silver**: `#e6e6fa` - Light highlights and text\n\n## Typography\n\n- **Headers**: FreeSans Bold\n- **Body Text**: FreeSans\n\n## Best Used For\n\nEntertainment industry, gaming presentations, nightlife venues, luxury brands, creative agencies.\n",
        ".claude/skills/theme-factory/themes/modern-minimalist.md": "# Modern Minimalist\n\nA clean and contemporary theme with a sophisticated grayscale palette for maximum versatility.\n\n## Color Palette\n\n- **Charcoal**: `#36454f` - Primary dark color\n- **Slate Gray**: `#708090` - Medium gray for accents\n- **Light Gray**: `#d3d3d3` - Backgrounds and dividers\n- **White**: `#ffffff` - Text and clean backgrounds\n\n## Typography\n\n- **Headers**: DejaVu Sans Bold\n- **Body Text**: DejaVu Sans\n\n## Best Used For\n\nTech presentations, architecture portfolios, design showcases, modern business proposals, data visualization.\n",
        ".claude/skills/theme-factory/themes/ocean-depths.md": "# Ocean Depths\n\nA professional and calming maritime theme that evokes the serenity of deep ocean waters.\n\n## Color Palette\n\n- **Deep Navy**: `#1a2332` - Primary background color\n- **Teal**: `#2d8b8b` - Accent color for highlights and emphasis\n- **Seafoam**: `#a8dadc` - Secondary accent for lighter elements\n- **Cream**: `#f1faee` - Text and light backgrounds\n\n## Typography\n\n- **Headers**: DejaVu Sans Bold\n- **Body Text**: DejaVu Sans\n\n## Best Used For\n\nCorporate presentations, financial reports, professional consulting decks, trust-building content.\n",
        ".claude/skills/theme-factory/themes/sunset-boulevard.md": "# Sunset Boulevard\n\nA warm and vibrant theme inspired by golden hour sunsets, perfect for energetic and creative presentations.\n\n## Color Palette\n\n- **Burnt Orange**: `#e76f51` - Primary accent color\n- **Coral**: `#f4a261` - Secondary warm accent\n- **Warm Sand**: `#e9c46a` - Highlighting and backgrounds\n- **Deep Purple**: `#264653` - Dark contrast and text\n\n## Typography\n\n- **Headers**: DejaVu Serif Bold\n- **Body Text**: DejaVu Sans\n\n## Best Used For\n\nCreative pitches, marketing presentations, lifestyle brands, event promotions, inspirational content.\n",
        ".claude/skills/theme-factory/themes/tech-innovation.md": "# Tech Innovation\n\nA bold and modern theme with high-contrast colors perfect for cutting-edge technology presentations.\n\n## Color Palette\n\n- **Electric Blue**: `#0066ff` - Vibrant primary accent\n- **Neon Cyan**: `#00ffff` - Bright highlight color\n- **Dark Gray**: `#1e1e1e` - Deep backgrounds\n- **White**: `#ffffff` - Clean text and contrast\n\n## Typography\n\n- **Headers**: DejaVu Sans Bold\n- **Body Text**: DejaVu Sans\n\n## Best Used For\n\nTech startups, software launches, innovation showcases, AI/ML presentations, digital transformation content.\n",
        ".claude/skills/web-artifacts-builder/SKILL.md": "---\nname: web-artifacts-builder\ndescription: Suite of tools for creating elaborate, multi-component claude.ai HTML artifacts using modern frontend web technologies (React, Tailwind CSS, shadcn/ui). Use for complex artifacts requiring state management, routing, or shadcn/ui components - not for simple single-file HTML/JSX artifacts.\nlicense: Complete terms in LICENSE.txt\n---\n\n# Web Artifacts Builder\n\nTo build powerful frontend claude.ai artifacts, follow these steps:\n1. Initialize the frontend repo using `scripts/init-artifact.sh`\n2. Develop your artifact by editing the generated code\n3. Bundle all code into a single HTML file using `scripts/bundle-artifact.sh`\n4. Display artifact to user\n5. (Optional) Test the artifact\n\n**Stack**: React 18 + TypeScript + Vite + Parcel (bundling) + Tailwind CSS + shadcn/ui\n\n## Design & Style Guidelines\n\nVERY IMPORTANT: To avoid what is often referred to as \"AI slop\", avoid using excessive centered layouts, purple gradients, uniform rounded corners, and Inter font.\n\n## Quick Start\n\n### Step 1: Initialize Project\n\nRun the initialization script to create a new React project:\n```bash\nbash scripts/init-artifact.sh <project-name>\ncd <project-name>\n```\n\nThis creates a fully configured project with:\n-  React + TypeScript (via Vite)\n-  Tailwind CSS 3.4.1 with shadcn/ui theming system\n-  Path aliases (`@/`) configured\n-  40+ shadcn/ui components pre-installed\n-  All Radix UI dependencies included\n-  Parcel configured for bundling (via .parcelrc)\n-  Node 18+ compatibility (auto-detects and pins Vite version)\n\n### Step 2: Develop Your Artifact\n\nTo build the artifact, edit the generated files. See **Common Development Tasks** below for guidance.\n\n### Step 3: Bundle to Single HTML File\n\nTo bundle the React app into a single HTML artifact:\n```bash\nbash scripts/bundle-artifact.sh\n```\n\nThis creates `bundle.html` - a self-contained artifact with all JavaScript, CSS, and dependencies inlined. This file can be directly shared in Claude conversations as an artifact.\n\n**Requirements**: Your project must have an `index.html` in the root directory.\n\n**What the script does**:\n- Installs bundling dependencies (parcel, @parcel/config-default, parcel-resolver-tspaths, html-inline)\n- Creates `.parcelrc` config with path alias support\n- Builds with Parcel (no source maps)\n- Inlines all assets into single HTML using html-inline\n\n### Step 4: Share Artifact with User\n\nFinally, share the bundled HTML file in conversation with the user so they can view it as an artifact.\n\n### Step 5: Testing/Visualizing the Artifact (Optional)\n\nNote: This is a completely optional step. Only perform if necessary or requested.\n\nTo test/visualize the artifact, use available tools (including other Skills or built-in tools like Playwright or Puppeteer). In general, avoid testing the artifact upfront as it adds latency between the request and when the finished artifact can be seen. Test later, after presenting the artifact, if requested or if issues arise.\n\n## Reference\n\n- **shadcn/ui components**: https://ui.shadcn.com/docs/components",
        ".claude/skills/webapp-testing/SKILL.md": "---\nname: webapp-testing\ndescription: Toolkit for interacting with and testing local web applications using Playwright. Supports verifying frontend functionality, debugging UI behavior, capturing browser screenshots, and viewing browser logs.\nlicense: Complete terms in LICENSE.txt\n---\n\n# Web Application Testing\n\nTo test local web applications, write native Python Playwright scripts.\n\n**Helper Scripts Available**:\n- `scripts/with_server.py` - Manages server lifecycle (supports multiple servers)\n\n**Always run scripts with `--help` first** to see usage. DO NOT read the source until you try running the script first and find that a customized solution is abslutely necessary. These scripts can be very large and thus pollute your context window. They exist to be called directly as black-box scripts rather than ingested into your context window.\n\n## Decision Tree: Choosing Your Approach\n\n```\nUser task  Is it static HTML?\n     Yes  Read HTML file directly to identify selectors\n              Success  Write Playwright script using selectors\n              Fails/Incomplete  Treat as dynamic (below)\n    \n     No (dynamic webapp)  Is the server already running?\n         No  Run: python scripts/with_server.py --help\n                Then use the helper + write simplified Playwright script\n        \n         Yes  Reconnaissance-then-action:\n            1. Navigate and wait for networkidle\n            2. Take screenshot or inspect DOM\n            3. Identify selectors from rendered state\n            4. Execute actions with discovered selectors\n```\n\n## Example: Using with_server.py\n\nTo start a server, run `--help` first, then use the helper:\n\n**Single server:**\n```bash\npython scripts/with_server.py --server \"npm run dev\" --port 5173 -- python your_automation.py\n```\n\n**Multiple servers (e.g., backend + frontend):**\n```bash\npython scripts/with_server.py \\\n  --server \"cd backend && python server.py\" --port 3000 \\\n  --server \"cd frontend && npm run dev\" --port 5173 \\\n  -- python your_automation.py\n```\n\nTo create an automation script, include only Playwright logic (servers are managed automatically):\n```python\nfrom playwright.sync_api import sync_playwright\n\nwith sync_playwright() as p:\n    browser = p.chromium.launch(headless=True) # Always launch chromium in headless mode\n    page = browser.new_page()\n    page.goto('http://localhost:5173') # Server already running and ready\n    page.wait_for_load_state('networkidle') # CRITICAL: Wait for JS to execute\n    # ... your automation logic\n    browser.close()\n```\n\n## Reconnaissance-Then-Action Pattern\n\n1. **Inspect rendered DOM**:\n   ```python\n   page.screenshot(path='/tmp/inspect.png', full_page=True)\n   content = page.content()\n   page.locator('button').all()\n   ```\n\n2. **Identify selectors** from inspection results\n\n3. **Execute actions** using discovered selectors\n\n## Common Pitfall\n\n **Don't** inspect the DOM before waiting for `networkidle` on dynamic apps\n **Do** wait for `page.wait_for_load_state('networkidle')` before inspection\n\n## Best Practices\n\n- **Use bundled scripts as black boxes** - To accomplish a task, consider whether one of the scripts available in `scripts/` can help. These scripts handle common, complex workflows reliably without cluttering the context window. Use `--help` to see usage, then invoke directly. \n- Use `sync_playwright()` for synchronous scripts\n- Always close the browser when done\n- Use descriptive selectors: `text=`, `role=`, CSS selectors, or IDs\n- Add appropriate waits: `page.wait_for_selector()` or `page.wait_for_timeout()`\n\n## Reference Files\n\n- **examples/** - Examples showing common patterns:\n  - `element_discovery.py` - Discovering buttons, links, and inputs on a page\n  - `static_html_automation.py` - Using file:// URLs for local HTML\n  - `console_logging.py` - Capturing console logs during automation",
        ".claude/skills/xlsx/SKILL.md": "---\nname: xlsx\ndescription: \"Comprehensive spreadsheet creation, editing, and analysis with support for formulas, formatting, data analysis, and visualization. When Claude needs to work with spreadsheets (.xlsx, .xlsm, .csv, .tsv, etc) for: (1) Creating new spreadsheets with formulas and formatting, (2) Reading or analyzing data, (3) Modify existing spreadsheets while preserving formulas, (4) Data analysis and visualization in spreadsheets, or (5) Recalculating formulas\"\nlicense: Proprietary. LICENSE.txt has complete terms\n---\n\n# Requirements for Outputs\n\n## All Excel files\n\n### Zero Formula Errors\n- Every Excel model MUST be delivered with ZERO formula errors (#REF!, #DIV/0!, #VALUE!, #N/A, #NAME?)\n\n### Preserve Existing Templates (when updating templates)\n- Study and EXACTLY match existing format, style, and conventions when modifying files\n- Never impose standardized formatting on files with established patterns\n- Existing template conventions ALWAYS override these guidelines\n\n## Financial models\n\n### Color Coding Standards\nUnless otherwise stated by the user or existing template\n\n#### Industry-Standard Color Conventions\n- **Blue text (RGB: 0,0,255)**: Hardcoded inputs, and numbers users will change for scenarios\n- **Black text (RGB: 0,0,0)**: ALL formulas and calculations\n- **Green text (RGB: 0,128,0)**: Links pulling from other worksheets within same workbook\n- **Red text (RGB: 255,0,0)**: External links to other files\n- **Yellow background (RGB: 255,255,0)**: Key assumptions needing attention or cells that need to be updated\n\n### Number Formatting Standards\n\n#### Required Format Rules\n- **Years**: Format as text strings (e.g., \"2024\" not \"2,024\")\n- **Currency**: Use $#,##0 format; ALWAYS specify units in headers (\"Revenue ($mm)\")\n- **Zeros**: Use number formatting to make all zeros \"-\", including percentages (e.g., \"$#,##0;($#,##0);-\")\n- **Percentages**: Default to 0.0% format (one decimal)\n- **Multiples**: Format as 0.0x for valuation multiples (EV/EBITDA, P/E)\n- **Negative numbers**: Use parentheses (123) not minus -123\n\n### Formula Construction Rules\n\n#### Assumptions Placement\n- Place ALL assumptions (growth rates, margins, multiples, etc.) in separate assumption cells\n- Use cell references instead of hardcoded values in formulas\n- Example: Use =B5*(1+$B$6) instead of =B5*1.05\n\n#### Formula Error Prevention\n- Verify all cell references are correct\n- Check for off-by-one errors in ranges\n- Ensure consistent formulas across all projection periods\n- Test with edge cases (zero values, negative numbers)\n- Verify no unintended circular references\n\n#### Documentation Requirements for Hardcodes\n- Comment or in cells beside (if end of table). Format: \"Source: [System/Document], [Date], [Specific Reference], [URL if applicable]\"\n- Examples:\n  - \"Source: Company 10-K, FY2024, Page 45, Revenue Note, [SEC EDGAR URL]\"\n  - \"Source: Company 10-Q, Q2 2025, Exhibit 99.1, [SEC EDGAR URL]\"\n  - \"Source: Bloomberg Terminal, 8/15/2025, AAPL US Equity\"\n  - \"Source: FactSet, 8/20/2025, Consensus Estimates Screen\"\n\n# XLSX creation, editing, and analysis\n\n## Overview\n\nA user may ask you to create, edit, or analyze the contents of an .xlsx file. You have different tools and workflows available for different tasks.\n\n## Important Requirements\n\n**LibreOffice Required for Formula Recalculation**: You can assume LibreOffice is installed for recalculating formula values using the `recalc.py` script. The script automatically configures LibreOffice on first run\n\n## Reading and analyzing data\n\n### Data analysis with pandas\nFor data analysis, visualization, and basic operations, use **pandas** which provides powerful data manipulation capabilities:\n\n```python\nimport pandas as pd\n\n# Read Excel\ndf = pd.read_excel('file.xlsx')  # Default: first sheet\nall_sheets = pd.read_excel('file.xlsx', sheet_name=None)  # All sheets as dict\n\n# Analyze\ndf.head()      # Preview data\ndf.info()      # Column info\ndf.describe()  # Statistics\n\n# Write Excel\ndf.to_excel('output.xlsx', index=False)\n```\n\n## Excel File Workflows\n\n## CRITICAL: Use Formulas, Not Hardcoded Values\n\n**Always use Excel formulas instead of calculating values in Python and hardcoding them.** This ensures the spreadsheet remains dynamic and updateable.\n\n###  WRONG - Hardcoding Calculated Values\n```python\n# Bad: Calculating in Python and hardcoding result\ntotal = df['Sales'].sum()\nsheet['B10'] = total  # Hardcodes 5000\n\n# Bad: Computing growth rate in Python\ngrowth = (df.iloc[-1]['Revenue'] - df.iloc[0]['Revenue']) / df.iloc[0]['Revenue']\nsheet['C5'] = growth  # Hardcodes 0.15\n\n# Bad: Python calculation for average\navg = sum(values) / len(values)\nsheet['D20'] = avg  # Hardcodes 42.5\n```\n\n###  CORRECT - Using Excel Formulas\n```python\n# Good: Let Excel calculate the sum\nsheet['B10'] = '=SUM(B2:B9)'\n\n# Good: Growth rate as Excel formula\nsheet['C5'] = '=(C4-C2)/C2'\n\n# Good: Average using Excel function\nsheet['D20'] = '=AVERAGE(D2:D19)'\n```\n\nThis applies to ALL calculations - totals, percentages, ratios, differences, etc. The spreadsheet should be able to recalculate when source data changes.\n\n## Common Workflow\n1. **Choose tool**: pandas for data, openpyxl for formulas/formatting\n2. **Create/Load**: Create new workbook or load existing file\n3. **Modify**: Add/edit data, formulas, and formatting\n4. **Save**: Write to file\n5. **Recalculate formulas (MANDATORY IF USING FORMULAS)**: Use the recalc.py script\n   ```bash\n   python recalc.py output.xlsx\n   ```\n6. **Verify and fix any errors**: \n   - The script returns JSON with error details\n   - If `status` is `errors_found`, check `error_summary` for specific error types and locations\n   - Fix the identified errors and recalculate again\n   - Common errors to fix:\n     - `#REF!`: Invalid cell references\n     - `#DIV/0!`: Division by zero\n     - `#VALUE!`: Wrong data type in formula\n     - `#NAME?`: Unrecognized formula name\n\n### Creating new Excel files\n\n```python\n# Using openpyxl for formulas and formatting\nfrom openpyxl import Workbook\nfrom openpyxl.styles import Font, PatternFill, Alignment\n\nwb = Workbook()\nsheet = wb.active\n\n# Add data\nsheet['A1'] = 'Hello'\nsheet['B1'] = 'World'\nsheet.append(['Row', 'of', 'data'])\n\n# Add formula\nsheet['B2'] = '=SUM(A1:A10)'\n\n# Formatting\nsheet['A1'].font = Font(bold=True, color='FF0000')\nsheet['A1'].fill = PatternFill('solid', start_color='FFFF00')\nsheet['A1'].alignment = Alignment(horizontal='center')\n\n# Column width\nsheet.column_dimensions['A'].width = 20\n\nwb.save('output.xlsx')\n```\n\n### Editing existing Excel files\n\n```python\n# Using openpyxl to preserve formulas and formatting\nfrom openpyxl import load_workbook\n\n# Load existing file\nwb = load_workbook('existing.xlsx')\nsheet = wb.active  # or wb['SheetName'] for specific sheet\n\n# Working with multiple sheets\nfor sheet_name in wb.sheetnames:\n    sheet = wb[sheet_name]\n    print(f\"Sheet: {sheet_name}\")\n\n# Modify cells\nsheet['A1'] = 'New Value'\nsheet.insert_rows(2)  # Insert row at position 2\nsheet.delete_cols(3)  # Delete column 3\n\n# Add new sheet\nnew_sheet = wb.create_sheet('NewSheet')\nnew_sheet['A1'] = 'Data'\n\nwb.save('modified.xlsx')\n```\n\n## Recalculating formulas\n\nExcel files created or modified by openpyxl contain formulas as strings but not calculated values. Use the provided `recalc.py` script to recalculate formulas:\n\n```bash\npython recalc.py <excel_file> [timeout_seconds]\n```\n\nExample:\n```bash\npython recalc.py output.xlsx 30\n```\n\nThe script:\n- Automatically sets up LibreOffice macro on first run\n- Recalculates all formulas in all sheets\n- Scans ALL cells for Excel errors (#REF!, #DIV/0!, etc.)\n- Returns JSON with detailed error locations and counts\n- Works on both Linux and macOS\n\n## Formula Verification Checklist\n\nQuick checks to ensure formulas work correctly:\n\n### Essential Verification\n- [ ] **Test 2-3 sample references**: Verify they pull correct values before building full model\n- [ ] **Column mapping**: Confirm Excel columns match (e.g., column 64 = BL, not BK)\n- [ ] **Row offset**: Remember Excel rows are 1-indexed (DataFrame row 5 = Excel row 6)\n\n### Common Pitfalls\n- [ ] **NaN handling**: Check for null values with `pd.notna()`\n- [ ] **Far-right columns**: FY data often in columns 50+ \n- [ ] **Multiple matches**: Search all occurrences, not just first\n- [ ] **Division by zero**: Check denominators before using `/` in formulas (#DIV/0!)\n- [ ] **Wrong references**: Verify all cell references point to intended cells (#REF!)\n- [ ] **Cross-sheet references**: Use correct format (Sheet1!A1) for linking sheets\n\n### Formula Testing Strategy\n- [ ] **Start small**: Test formulas on 2-3 cells before applying broadly\n- [ ] **Verify dependencies**: Check all cells referenced in formulas exist\n- [ ] **Test edge cases**: Include zero, negative, and very large values\n\n### Interpreting recalc.py Output\nThe script returns JSON with error details:\n```json\n{\n  \"status\": \"success\",           // or \"errors_found\"\n  \"total_errors\": 0,              // Total error count\n  \"total_formulas\": 42,           // Number of formulas in file\n  \"error_summary\": {              // Only present if errors found\n    \"#REF!\": {\n      \"count\": 2,\n      \"locations\": [\"Sheet1!B5\", \"Sheet1!C10\"]\n    }\n  }\n}\n```\n\n## Best Practices\n\n### Library Selection\n- **pandas**: Best for data analysis, bulk operations, and simple data export\n- **openpyxl**: Best for complex formatting, formulas, and Excel-specific features\n\n### Working with openpyxl\n- Cell indices are 1-based (row=1, column=1 refers to cell A1)\n- Use `data_only=True` to read calculated values: `load_workbook('file.xlsx', data_only=True)`\n- **Warning**: If opened with `data_only=True` and saved, formulas are replaced with values and permanently lost\n- For large files: Use `read_only=True` for reading or `write_only=True` for writing\n- Formulas are preserved but not evaluated - use recalc.py to update values\n\n### Working with pandas\n- Specify data types to avoid inference issues: `pd.read_excel('file.xlsx', dtype={'id': str})`\n- For large files, read specific columns: `pd.read_excel('file.xlsx', usecols=['A', 'C', 'E'])`\n- Handle dates properly: `pd.read_excel('file.xlsx', parse_dates=['date_column'])`\n\n## Code Style Guidelines\n**IMPORTANT**: When generating Python code for Excel operations:\n- Write minimal, concise Python code without unnecessary comments\n- Avoid verbose variable names and redundant operations\n- Avoid unnecessary print statements\n\n**For Excel files themselves**:\n- Add comments to cells with complex formulas or important assumptions\n- Document data sources for hardcoded values\n- Include notes for key calculations and model sections",
        ".claude/template/SKILL.md": "---\nname: template-skill\ndescription: Replace with description of the skill and when Claude should use it.\n---\n\n# Insert instructions below\n",
        ".devcontainer/README.md": "# Immersive Awe Canvas - Dev Container Setup\n\n## Overview\n\nThis dev container is configured for developing the Immersive Awe Canvas application with Node.js 20, Bun, and TypeScript.\n\n## Key Features\n\n- **Base Image**: Node.js 20 (Debian Bookworm)\n- **Package Manager**: Bun v1.1.34 (with npm/npx fallback)\n- **User**: `vscode` (UID 1001) for VS Code compatibility\n- **Locale**: Full UTF-8 locale support (en_US.UTF-8)\n- **Tools**: Git, Git LFS, GitHub CLI, TypeScript, Biome\n\n## Architecture\n\nInspired by the terminal-jarvis dev container setup:\n\n### 1. Dockerfile\n- Uses official `node:20-bookworm` base image\n- Installs and configures locales properly\n- Creates `vscode` user with sudo access\n- Installs Bun globally\n- Sets up all environment variables\n\n### 2. devcontainer.json\n- Direct Dockerfile build (no docker-compose)\n- Proper locale environment variables\n- Lifecycle scripts (postCreateCommand, postStartCommand)\n- VS Code extensions and settings\n- Port forwarding (8080, 54321)\n\n### 3. Setup Scripts\n\n#### `post-create.sh`\nRuns once when container is first created:\n- Verifies all tools are installed\n- Installs project dependencies with Bun\n- Sets up custom bash prompt\n- Configures welcome message\n- Runs initial type check and build\n- Creates `.env.local` template\n\n#### `post-start.sh`\nRuns each time the container starts:\n- Shows environment info\n- Displays git status and recent commits\n- Lists available commands\n\n#### `setup-dev-environment.sh`\nManual setup script for troubleshooting or re-running setup\n\n## Rebuild Instructions\n\nIf you experience issues with the dev container:\n\n### Option 1: Rebuild Container (Recommended)\n1. Press `F1` or `Ctrl+Shift+P`\n2. Run: `Dev Containers: Rebuild Container`\n3. Wait for the build and post-create script to complete\n\n### Option 2: Rebuild Without Cache\n1. Press `F1` or `Ctrl+Shift+P`\n2. Run: `Dev Containers: Rebuild Container Without Cache`\n3. This will force a clean rebuild\n\n### Option 3: Manual Setup\nIf the container is already running but setup didn't complete:\n```bash\nbash .devcontainer/scripts/setup-dev-environment.sh\n```\n\n## Troubleshooting\n\n### Issue: \"bun: command not found\"\n**Root Cause**: Container didn't build properly or wrong base image\n**Solution**: Rebuild container without cache\n\n### Issue: Locale warnings\n**Root Cause**: Locale not configured in container\n**Solution**: Already fixed in Dockerfile with proper locale-gen setup\n\n### Issue: Permission errors\n**Root Cause**: User mismatch between host and container\n**Solution**: Using `vscode` user (UID 1001) for compatibility\n\n### Issue: Dependencies not installed\n**Root Cause**: post-create script didn't run\n**Solution**: Run `bash .devcontainer/scripts/setup-dev-environment.sh` manually\n\n## Environment Variables\n\nThe following environment variables are set in the container:\n\n```bash\nNODE_ENV=development\nVITE_GIT_COMMIT_HASH=dev\nLANG=en_US.UTF-8\nLC_ALL=en_US.UTF-8\nLC_CTYPE=en_US.UTF-8\nLC_COLLATE=en_US.UTF-8\nLC_MESSAGES=en_US.UTF-8\n```\n\n## Ports\n\n- **8080**: Application development server\n- **54321**: Supabase local development\n\n## Differences from Docker Compose Setup\n\nThe previous setup used docker-compose.yml with features. The new setup:\n\n1.  Uses direct Dockerfile build (simpler, more control)\n2.  Proper locale configuration (no warnings)\n3.  Correct user setup (vscode instead of node)\n4.  All tools verified during build\n5.  Better aligned with terminal-jarvis proven patterns\n6.  More explicit environment variable setup\n\n## Verification\n\nAfter container starts, verify everything is working:\n\n```bash\nnode --version   # Should show v20.x.x\nnpm --version    # Should show 10.x.x\nbun --version    # Should show 1.1.34\ntsc --version    # Should show TypeScript version\nlocale           # Should show en_US.UTF-8\n```\n\n## Quick Start\n\nOnce the container is running:\n\n```bash\nbun run dev        # Start development server\nbun run build      # Build for production\nbun run test       # Run tests\nbun run typecheck  # Type checking\nbun run check      # Lint & format check\n```\n\n## Notes\n\n- The container uses `waitFor: postCreateCommand` to ensure setup completes before opening\n- Scripts are executable and use `set -e` for fail-fast behavior\n- Git LFS is configured with `--skip-smudge` for faster clones\n- All setup is idempotent - safe to re-run\n\n## Credits\n\nThis setup is inspired by the terminal-jarvis dev container configuration, which has proven to be reliable and robust.\n",
        "README.md": "# Immersive Awe Canvas\n\nA professional 3D canvas experience for exploring and manipulating interactive geometries in your browser. Built with React, Three.js, RSBuild, and modern web technologies using a modular monorepo architecture.\n\n**Live Demo:** [immersive-awe-canvas.lovable.app](https://immersive-awe-canvas.lovable.app)\n\n## Features\n\n<details>\n<summary><strong>Core 3D Experience</strong></summary>\n\n- **Multiple Scene Types:** TorusKnot, WobbleField, CrystallineSpire, DistortionSphere, MorphingIcosahedron, WavyGrid, and JellyTorus\n- **Dynamic Day/Night Themes:** Toggle between light and dark modes with per-world color schemes\n- **Smooth Animations:** Optimized 60fps animations with glitch-free geometry rendering\n- **World Navigation:** Seamless transitions between different 3D environments\n- **Anti-aliasing:** High-quality rendering with MSAA support\n\n</details>\n\n<details>\n<summary><strong>Professional Object Manipulation</strong></summary>\n\n- **Blender-Style Gizmos:** Precise transform controls with visual axis indicators\n- **Smooth Drag Controls:** Fluid object movement with lerp interpolation\n- **Object Selection:** Click-to-select with visual wireframe feedback\n- **Real-time Updates:** Immediate visual feedback during manipulation\n- **Mobile-Optimized:** Enhanced gizmo sensitivity for touch devices\n\n</details>\n\n<details>\n<summary><strong>Advanced Scene Editing</strong></summary>\n\n- **Live Scene Editor:** Professional settings panel with MVVM architecture\n- **Add/Remove Objects:** Dynamic scene composition with multiple geometry types\n- **Material Controls:** Real-time adjustment of colors, metalness, roughness, and transparency\n- **Transform Properties:** Position, rotation, and scale controls with precise input\n- **Object Management:** Organized object list with selection and property editing\n- **Collapsible Sections:** Organized UI with glassmorphism effects\n\n</details>\n\n<details>\n<summary><strong>Developer Experience</strong></summary>\n\n- **Semantic Versioning:** Automated GitHub releases following conventional commits\n- **TypeScript:** Full type safety with strict mode enabled\n- **Modern Architecture:** Modular monorepo with client/server/database/utils separation\n- **Performance Optimized:** RSBuild with tree shaking and hot module replacement\n- **Comprehensive Testing:** Vitest with 54 passing tests and proper mocking\n- **MVVM Pattern:** Clean separation of concerns with ViewModels for complex UI logic\n\n</details>\n\n<details>\n<summary><strong>User Interface</strong></summary>\n\n- **Responsive Design:** Optimized layouts for desktop, tablet, and mobile devices\n- **Keyboard Shortcuts:** Complete keyboard navigation and control system\n- **Accessibility:** Professional contrast ratios and intuitive interactions\n- **Clean Design:** Minimalist interface inspired by Excalidraw and Blender\n- **Theme Support:** Dynamic day/night mode switching\n\n</details>\n\n<details>\n<summary><strong>Technical Features</strong></summary>\n\n- **Supabase Integration:** Backend data management with type-safe APIs\n- **RSBuild:** Fast development and optimized production builds\n- **Component Library:** Comprehensive UI components with shadcn/ui and Radix UI\n- **Build Optimization:** Production-ready builds with code splitting and asset optimization\n- **GitHub Integration:** Dynamic version display from GitHub releases API\n\n</details>\n\n## Quick Start\n\n<details>\n<summary><strong>Prerequisites</strong></summary>\n\n- **Node.js 18+** - Required for development\n- **[Bun](https://bun.sh/)** - Recommended for optimal performance\n- **Git** - For version control\n\n> ** Why Bun?** We use Bun for significantly faster package installation, test execution, and build times compared to npm/yarn.\n\n</details>\n\n<details>\n<summary><strong>Installation & Setup</strong></summary>\n\n```bash\n# Clone the repository\ngit clone https://github.com/BA-CalderonMorales/immersive-awe-canvas.git\ncd immersive-awe-canvas\n\n# Install Bun (if not already installed)\ncurl -fsSL https://bun.sh/install | bash\n\n# Install dependencies\nbun install\n\n# Start development server with RSBuild\nbun run dev\n```\n\nThe development server will start at `http://localhost:8080` with hot module replacement enabled.\n\n</details>\n\n<details>\n<summary><strong>Development Commands</strong></summary>\n\n```bash\n# Core Development\nbun install          # Install all dependencies\nbun run dev          # Start RSBuild dev server (localhost:8080)\nbun run build        # Production build with RSBuild\nbun run build:dev    # Development build\nbun run preview      # Preview production build\n\n# Quality Assurance\nbun run test         # Run Vitest test suite (54 tests)\nbun run typecheck    # TypeScript validation\nbun run lint         # ESLint code analysis\n\n# Monorepo Management\nbun run install:all  # Install dependencies for all workspaces\n```\n\n</details>\n\n<details>\n<summary><strong>Alternative Package Managers</strong></summary>\n\nWhile Bun is recommended, you can use npm if needed:\n\n```bash\nnpm install\nnpm run dev\nnpm run test\nnpm run build\n```\n\n**Note:** Different package managers may yield different dependency resolution results.\n\n</details>\n\n<details>\n<summary><strong>Automated Versioning</strong></summary>\n\n** Important:** This project uses automated semantic versioning. Manual version commands are **not used**.\n\n- Versions are automatically bumped based on conventional commits\n- Use proper commit prefixes: `fix:`, `feat:`, `BREAKING CHANGE:`\n- GitHub Actions handles releases automatically\n- See `RULES.md` for detailed versioning guidelines\n\n</details>\n\n## Controls\n\n<details>\n<summary><strong>Mouse/Touch Interactions</strong></summary>\n\n- **Look Around:** Click and drag to rotate camera\n- **Zoom:** Mouse wheel or pinch gestures\n- **Select Objects:** Click on any geometry to select\n- **Gizmo Control:** Drag transform gizmos for precise movement\n- **Mobile Optimized:** Enhanced touch sensitivity for mobile devices\n\n</details>\n\n<details>\n<summary><strong>Keyboard Shortcuts</strong></summary>\n\n| Key             | Action                                   |\n| --------------- | ---------------------------------------- |\n| `Space`         | Toggle day/night theme                   |\n| `N` / `P`       | Next/previous world                      |\n| `Z`             | Toggle drag mode for object manipulation |\n| `V`             | Hide/show UI                             |\n| `E`             | Toggle settings panel                    |\n| `S` or `Ctrl+K` | Search worlds                            |\n| `H`             | Help dialog                              |\n| `G`             | Go to home                               |\n| `C`             | Copy scene configuration                 |\n| `.` (Period)    | Freeze/unfreeze animations               |\n| `Esc`           | Close dialogs                            |\n\n</details>\n\n## Architecture\n\n<details>\n<summary><strong>Technology Stack</strong></summary>\n\n- **Build System:** RSBuild with React plugin and TypeScript support\n- **Frontend:** React 18, TypeScript, Tailwind CSS\n- **3D Graphics:** Three.js, React Three Fiber, React Three Drei\n- **UI Components:** shadcn/ui, Radix UI primitives\n- **Backend:** Supabase (PostgreSQL, real-time subscriptions)\n- **Testing:** Vitest with comprehensive mocking and 54 test cases\n- **Deployment:** GitHub Actions with automated semantic releases\n- **Package Manager:** Bun for optimal performance\n\n</details>\n\n<details>\n<summary><strong>Monorepo Structure</strong></summary>\n\nThis project uses a **modular monorepo architecture** with clear separation of concerns across multiple workspaces:\n\n#### Client Workspace (`client/`)\n\nFrontend React application with modern architecture:\n\n- **Components**: Organized by feature with scene, UI, and layout components\n- **Hooks**: Custom React hooks for state management and API integration\n- **Context**: React context providers for global state (SceneObjects, Experience, etc.)\n- **Pages**: Route-based page components\n- **Types**: TypeScript definitions for client-side data structures\n- **Test**: Comprehensive test suite with Vitest (54 tests)\n\n#### Server Workspace (`server/`)\n\nBackend utilities and API integrations:\n\n- **GitHub API**: Dynamic version fetching from GitHub releases\n- **Security**: Input validation and sanitization utilities\n- **Logging**: Structured logging with different levels\n- **Validation**: Type guards and data validation functions\n- **Utils**: Server-side utility functions\n\n#### Database Workspace (`database/`)\n\nSupabase integration and database management:\n\n- **Types**: Auto-generated TypeScript types from Supabase schema\n- **Migrations**: Database schema migrations\n- **Queries**: Reusable database query functions\n- **Hooks**: React hooks for database operations\n\n#### Utils Workspace (`utils/`)\n\nShared utilities across all workspaces:\n\n- **Common Functions**: Utility functions used by both client and server\n- **Type Guards**: Shared type validation functions\n- **Constants**: Application-wide constants and configurations\n\n</details>\n\n<details>\n<summary><strong>Directory Structure</strong></summary>\n\n```\nimmersive-awe-canvas/\n client/                    # Frontend React application\n    components/           # React components organized by feature\n       scene/           # 3D scene components (objects, controls, materials)\n       ui/              # UI components (buttons, dialogs, forms)\n       layout/          # Layout components (headers, sidebars)\n    context/             # React context providers\n       ExperienceContext.tsx\n       SceneObjectsContext.tsx\n       KeyboardShortcutsContext.tsx\n    hooks/               # Custom React hooks\n       useWorlds.ts\n       use-mobile.ts\n       useExperience.ts\n    pages/               # Route-based page components\n    types/               # Client-side TypeScript definitions\n    test/                # Test files and utilities\n    lib/                 # Client-side utilities\n server/                   # Backend utilities and API integrations\n    github-api.ts        # GitHub releases API integration\n    security.ts          # Input validation and sanitization\n    logger.ts            # Structured logging utilities\n    validation.ts        # Type guards and validation\n    utils.ts             # Server-side utility functions\n database/                 # Supabase integration (future expansion)\n    types/               # Auto-generated Supabase types\n    migrations/          # Database schema migrations\n    queries/             # Reusable database queries\n utils/                    # Shared utilities across workspaces\n    typeguards.ts        # Shared type validation\n    utils.ts             # Common utility functions\n    constants.ts         # Application constants\n public/                   # Static assets\n dist/                     # Built application (generated)\n rsbuild.config.ts         # RSBuild configuration\n vitest.config.ts          # Vitest testing configuration\n package.json              # Root package.json with workspaces\n tsconfig.json             # TypeScript configuration\n```\n\n</details>\n\n<details>\n<summary><strong>Import Patterns & Usage</strong></summary>\n\n#### Client-Side Development\n\nWorking with UI components and React logic:\n\n```typescript\n// Import client components and hooks\nimport { SceneEditor } from \"@/components/scene/editor/SceneEditor\";\nimport { useSceneObjectsContext } from \"@/context/SceneObjectsContext\";\nimport { useWorlds } from \"@/hooks/useWorlds\";\nimport { SceneConfig } from \"@/types/scene\";\n```\n\n#### Server-Side Integration\n\nWorking with APIs and backend utilities:\n\n```typescript\n// Import server utilities\nimport { fetchGitHubReleases } from \"@server/github-api\";\nimport { validateInput } from \"@server/security\";\nimport { logger } from \"@server/logger\";\n```\n\n#### Shared Utilities\n\nUsing common functions across workspaces:\n\n```typescript\n// Import shared utilities\nimport { isValidString } from \"@utils/typeguards\";\nimport { formatDate } from \"@utils/utils\";\n```\n\n</details>\n\n<details>\n<summary><strong>Architecture Benefits</strong></summary>\n\n1. **Monorepo Structure**: All related code in one repository with clear workspace boundaries\n2. **Clear Separation**: Client, server, database, and utils are logically separated\n3. **Developer Experience**: Easy to navigate and understand project structure\n4. **Maintainability**: Changes are isolated to appropriate workspaces\n5. **Scalability**: Easy to add new features without architectural debt\n6. **Testing**: Comprehensive test coverage with proper mocking strategies\n7. **Type Safety**: Full TypeScript coverage across all workspaces\n\n</details>\n\n## Contributing\n\nWe welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.\n\n### Commit Standards\n\nWe use [Conventional Commits](https://www.conventionalcommits.org/) for semantic versioning:\n\n- `feat:` - New features (minor version bump)\n- `fix:` - Bug fixes (patch version bump)\n- `perf:` - Performance improvements (patch version bump)\n- `feat!:` or `BREAKING CHANGE:` - Breaking changes (major version bump)\n\n### Development Guidelines\n\n- Follow TypeScript strict mode\n- Write tests for new functionality\n- Use immutable patterns where possible\n- Keep components small and focused\n- Maintain 60fps performance standards\n\nWhen adding new features:\n\n- **UI Components/Logic**: Add to `src/modules/client/`\n- **Data Fetching/APIs**: Add to `src/modules/server/`\n- **Shared Types**: Consider where the type is primarily used\n\nThis modular approach helps maintain clean code organization and makes the codebase more approachable for new contributors.\n\n## License\n\nMIT License - see [LICENSE](LICENSE) for details.\n\n## Support\n\n- **Issues:** [GitHub Issues](../../issues) for bugs and feature requests\n- **Discussions:** [GitHub Discussions](../../discussions) for questions\n- **Documentation:** Check our comprehensive [CONTRIBUTING.md](CONTRIBUTING.md)\n",
        "client/api/README.md": "# Client API Layer Documentation\n\n## Overview\n\nThe Client API Layer provides a clean, consistent interface for all client-side API operations using the `@ba-calderonmorales/clean-api` package. This layer standardizes how the client communicates with external APIs, databases, and internal services.\n\n## Architecture\n\nThe client API layer mirrors the server API architecture with these components:\n\n1. **Configuration** (`config.ts`) - API endpoints and client setup\n2. **Clients** (`clients/`) - API communication classes\n3. **Hooks** (`hooks/`) - React hooks for API integration\n4. **Utils** (`utils/`) - Migration helpers and performance utilities\n\n## Getting Started\n\n### Basic Import\n\n```typescript\n// Import specific hooks\nimport { useAPIWorlds, useLatestVersion, useAPILogging } from '@client/api';\n\n// Import specific clients\nimport { clientVersionAPIClient, clientSupabaseAPIClient } from '@client/api';\n\n// Import migration utilities\nimport { createAPIMigration } from '@client/api';\n```\n\n## React Hooks\n\n### Data Fetching Hooks\n\n#### `useAPIWorlds()`\nReplaces the existing `useWorlds` hook with better error handling:\n\n```typescript\nimport { useAPIWorlds } from '@client/api';\n\nconst MyComponent = () => {\n    const { data: worlds, isLoading, error } = useAPIWorlds({\n        staleTime: 5 * 60 * 1000, // 5 minutes\n        enabled: true\n    });\n\n    if (error) {\n        console.error('Failed to load worlds:', error);\n    }\n\n    return <div>Found {worlds?.length} worlds</div>;\n};\n```\n\n#### `useAPIBackgrounds()`\nFetch backgrounds with React Query caching:\n\n```typescript\nimport { useAPIBackgrounds } from '@client/api';\n\nconst BackgroundSelector = () => {\n    const { data: backgrounds, isLoading } = useAPIBackgrounds();\n    \n    return (\n        <select>\n            {backgrounds?.map(bg => (\n                <option key={bg.id} value={bg.id}>{bg.name}</option>\n            ))}\n        </select>\n    );\n};\n```\n\n#### `useLatestVersion()`\nGet latest version from GitHub with caching:\n\n```typescript\nimport { useLatestVersion, useCurrentVersion } from '@client/api';\n\nconst VersionChecker = () => {\n    const currentVersion = useCurrentVersion();\n    const { data: latestVersion, isLoading } = useLatestVersion({\n        refetchInterval: 30 * 60 * 1000 // Check every 30 minutes\n    });\n\n    const hasUpdate = latestVersion && \n        latestVersion.version !== `v${currentVersion.appVersion}`;\n\n    return (\n        <div>\n            <p>Current: {currentVersion.fullVersion}</p>\n            <p>Latest: {latestVersion?.version}</p>\n            {hasUpdate && <button>Update Available!</button>}\n        </div>\n    );\n};\n```\n\n### Logging Hooks\n\n#### `useAPILogging()`\nComprehensive logging with automatic error handling:\n\n```typescript\nimport { useAPILogging } from '@client/api';\n\nconst InteractiveComponent = () => {\n    const { logUserAction, logError, logSceneInteraction } = useAPILogging();\n\n    const handleClick = async () => {\n        try {\n            // Your logic here\n            await someOperation();\n            \n            // Log successful user action\n            await logUserAction('button_clicked', 'user123', {\n                buttonId: 'main-cta',\n                timestamp: new Date().toISOString()\n            });\n        } catch (error) {\n            // Automatic error logging\n            await logError(error, 'InteractiveComponent', {\n                action: 'button_click',\n                buttonId: 'main-cta'\n            });\n        }\n    };\n\n    const handleSceneChange = (sceneData: any) => {\n        logSceneInteraction('scene_changed', sceneData, {\n            previousScene: 'world-1',\n            newScene: 'world-2'\n        });\n    };\n\n    return <button onClick={handleClick}>Interactive Button</button>;\n};\n```\n\n## Direct API Clients\n\n### Version Client\n\n```typescript\nimport { clientVersionAPIClient } from '@client/api';\n\n// Get current version (synchronous)\nconst currentVersion = clientVersionAPIClient.getCurrentVersion();\nconsole.log(currentVersion.fullVersion); // \"v1.0.0 (07-31-2025-00:30:56-CDT-dev)\"\n\n// Get latest version from GitHub (async)\nconst { data: latestVersion, error } = await clientVersionAPIClient.getLatestVersion();\nif (latestVersion) {\n    console.log('Latest version:', latestVersion.version);\n}\n\n// Check for updates\nconst updateInfo = await clientVersionAPIClient.getUpdateInfo();\nif (updateInfo.hasUpdate) {\n    console.log(`Update available: ${updateInfo.latestVersion}`);\n}\n```\n\n### Supabase Client\n\n```typescript\nimport { clientSupabaseAPIClient } from '@client/api';\n\n// Get worlds with error handling\nconst { data: worlds, error } = await clientSupabaseAPIClient.getWorlds();\nif (error) {\n    console.error('Failed to fetch worlds:', error.message);\n} else {\n    console.log('Loaded worlds:', worlds);\n}\n\n// Generic query\nconst { data: featuredItems } = await clientSupabaseAPIClient.query('worlds', {\n    filters: { is_featured: true },\n    orderBy: 'created_at:desc',\n    limit: 10\n});\n```\n\n### Logging Client\n\n```typescript\nimport { clientLoggingAPIClient } from '@client/api';\n\n// Log custom event\nawait clientLoggingAPIClient.logEvent({\n    eventType: 'custom_event',\n    eventSource: 'my-component',\n    metadata: { customData: 'value' }\n});\n\n// Log performance metric\nawait clientLoggingAPIClient.logPerformance('api_call_duration', 150, 'ms', {\n    endpoint: '/api/worlds',\n    success: true\n});\n```\n\n## Migration Guide\n\n### Migrating from Old Patterns\n\nThe client API layer provides migration utilities to help transition from existing patterns:\n\n```typescript\nimport { createAPIMigration } from '@client/api';\n\n// Create migration helper\nconst migration = createAPIMigration();\n\n// Show migration guide in console\nmigration.showMigrationGuide();\n\n// Use migration helpers for gradual transition\nconst { data: worlds } = await migration.worlds.fetchWorlds();\nconst { data: version } = await migration.version.fetchLatestRelease();\nawait migration.logging.logEvent({\n    eventType: 'migration_test',\n    eventSource: 'migration-helper'\n});\n```\n\n### Before and After Examples\n\n#### Old Way (Before Clean API)\n```typescript\n// Scattered imports and manual error handling\nimport { useWorlds } from '@/hooks/useWorlds';\nimport { logEvent } from '@/lib/logger';\nimport { fetchLatestRelease } from '@utils/github-api';\n\nconst OldComponent = () => {\n    const { data: worlds, isLoading } = useWorlds();\n    \n    useEffect(() => {\n        // Manual API calls with inconsistent error handling\n        fetchLatestRelease().then(version => {\n            console.log(version);\n        }).catch(error => {\n            console.error('Version fetch failed:', error);\n        });\n        \n        // Manual logging\n        logEvent({\n            eventType: 'component_mounted',\n            eventSource: 'OldComponent'\n        });\n    }, []);\n    \n    return <div>{worlds?.length} worlds</div>;\n};\n```\n\n#### New Way (With Clean API)\n```typescript\n// Centralized imports with consistent patterns\nimport { useAPIWorlds, useLatestVersion, useAPILogging } from '@client/api';\n\nconst NewComponent = () => {\n    const { data: worlds, isLoading, error } = useAPIWorlds();\n    const { data: version } = useLatestVersion();\n    const { logUserAction, logError } = useAPILogging();\n    \n    // Automatic error handling\n    useEffect(() => {\n        if (error) {\n            logError(error, 'NewComponent', { section: 'worlds' });\n        }\n    }, [error, logError]);\n    \n    // Enhanced logging\n    useEffect(() => {\n        logUserAction('component_mounted', undefined, {\n            component: 'NewComponent',\n            worldsCount: worlds?.length,\n            latestVersion: version?.version\n        });\n    }, [worlds, version, logUserAction]);\n    \n    return <div>{worlds?.length} worlds (Latest: {version?.version})</div>;\n};\n```\n\n## Performance Monitoring\n\nThe client API includes built-in performance monitoring:\n\n```typescript\nimport { withPerformanceMonitoring, createTimer, PerformanceTimer } from '@client/api';\n\n// Wrap functions with performance monitoring\nconst monitoredFunction = withPerformanceMonitoring(\n    async () => {\n        // Your async operation\n        await someExpensiveOperation();\n    },\n    'expensive-operation'\n);\n\n// Manual timing\nconst timer = createTimer('manual-operation');\nawait someOperation();\nawait timer.logPerformance({ success: true });\n\n// Component render monitoring\nconst ComponentWithMonitoring = () => {\n    const renderTimer = measureComponentRender('ComponentWithMonitoring');\n    \n    useEffect(() => {\n        renderTimer.log({ propsCount: Object.keys(props).length });\n    }, []);\n    \n    return <div>Monitored component</div>;\n};\n```\n\n## Error Handling Patterns\n\nThe client API provides consistent error handling across all operations:\n\n```typescript\nimport { useErrorLogging } from '@client/api';\n\nconst ComponentWithErrorHandling = () => {\n    const { logError } = useErrorLogging();\n    \n    const handleOperation = async () => {\n        try {\n            await riskyOperation();\n        } catch (error) {\n            // Automatically logs error with context\n            logError(error, 'ComponentWithErrorHandling', {\n                operation: 'riskyOperation',\n                timestamp: new Date().toISOString()\n            });\n            \n            // Handle error in UI\n            setErrorState(error.message);\n        }\n    };\n    \n    return <button onClick={handleOperation}>Safe Operation</button>;\n};\n```\n\n## Configuration\n\nThe client API can be configured through environment variables and config files:\n\n```typescript\n// Development vs Production endpoints\nconst isDev = process.env.NODE_ENV === 'development';\nconst serverBaseUrl = isDev ? 'http://localhost:3001' : 'https://api.yourapp.com';\n\n// Custom client configuration\nimport { ClientAPIClient } from '@client/api';\n\nconst customClient = new ClientAPIClient(\n    'https://custom-api.com', \n    { 'Authorization': 'Bearer token' },\n    3 // retry count\n);\n```\n\n## Testing\n\nThe client API layer includes utilities for testing:\n\n```typescript\n// Test function available in browser\nif (typeof window !== 'undefined') {\n    window.testClientAPI(); // Runs comprehensive API tests\n}\n\n// Mock clients for unit tests\nconst mockVersionClient = {\n    getCurrentVersion: () => ({ appVersion: '1.0.0' }),\n    getLatestVersion: () => Promise.resolve({ data: mockVersionData })\n};\n```\n\n## Best Practices\n\n1. **Use React Hooks** for data fetching instead of direct client calls in components\n2. **Handle Errors Consistently** using the provided error logging utilities\n3. **Monitor Performance** for expensive operations using the performance utilities\n4. **Migrate Gradually** using the migration helpers to transition from old patterns\n5. **Cache Appropriately** by configuring `staleTime` and `refetchInterval` in hooks\n6. **Log User Actions** to track application usage and debug issues\n7. **Type Safety** - All API methods return properly typed results with `APIResult<T>`\n\nThis client API layer provides a foundation for scalable, maintainable client-side API management while maintaining consistency with the server-side architecture.\n",
        "client/api/hooks/index.ts": "/**\n * Client API React Hooks\n *\n * React hooks that integrate with the Clean API architecture\n */\n\nexport * from \"./use-api-version.js\";\nexport * from \"./use-api-logging.js\";\nexport * from \"./use-api-worlds.js\";\nexport * from \"./use-api-backgrounds.js\";\n",
        "client/api/hooks/use-api-backgrounds.ts": "/**\n * Backgrounds API React Hook\n *\n * React hook for background operations using Clean API architecture\n */\n\nimport { useQuery } from \"@tanstack/react-query\";\nimport { clientSupabaseAPIClient } from \"../clients/supabase-client\";\nimport type { Database } from \"@database/supabase/types\";\n\ntype Background = Database[\"public\"][\"Tables\"][\"backgrounds\"][\"Row\"];\ntype DefaultGeometry =\n    Database[\"public\"][\"Tables\"][\"default_geometries\"][\"Row\"];\n\n/**\n * Hook to get all backgrounds with React Query caching\n */\nexport const useAPIBackgrounds = (options?: {\n    enabled?: boolean;\n    staleTime?: number;\n    refetchInterval?: number;\n}) => {\n    return useQuery<Background[]>({\n        queryKey: [\"backgrounds\"],\n        queryFn: async () => {\n            const { data, error } =\n                await clientSupabaseAPIClient.getBackgrounds();\n            if (error) throw error;\n            return data!;\n        },\n        staleTime: options?.staleTime ?? 5 * 60 * 1000, // 5 minutes\n        refetchInterval: options?.refetchInterval,\n        enabled: options?.enabled ?? true,\n    });\n};\n\n/**\n * Hook to get all default geometries with React Query caching\n */\nexport const useAPIDefaultGeometries = (options?: {\n    enabled?: boolean;\n    staleTime?: number;\n    refetchInterval?: number;\n}) => {\n    return useQuery<DefaultGeometry[]>({\n        queryKey: [\"default_geometries\"],\n        queryFn: async () => {\n            const { data, error } =\n                await clientSupabaseAPIClient.getDefaultGeometries();\n            if (error) throw error;\n            return data!;\n        },\n        staleTime: options?.staleTime ?? 5 * 60 * 1000, // 5 minutes\n        refetchInterval: options?.refetchInterval,\n        enabled: options?.enabled ?? true,\n    });\n};\n",
        "client/api/hooks/use-api-logging.ts": "/**\n * Logging API React Hook\n *\n * React hook for logging operations using Clean API architecture\n */\n\nimport { useCallback } from \"react\";\nimport {\n    clientLoggingAPIClient,\n    type LogEventParams,\n} from \"../clients/logging-client\";\n\n/**\n * Hook for logging operations\n */\nexport const useAPILogging = () => {\n    const logEvent = useCallback(async (params: LogEventParams) => {\n        return await clientLoggingAPIClient.logEvent(params);\n    }, []);\n\n    const logUserAction = useCallback(\n        async (\n            action: string,\n            userId?: string,\n            metadata?: Record<string, unknown>\n        ) => {\n            return await clientLoggingAPIClient.logUserAction(\n                action,\n                userId,\n                metadata\n            );\n        },\n        []\n    );\n\n    const logError = useCallback(\n        async (\n            error: Error | string,\n            source?: string,\n            metadata?: Record<string, unknown>\n        ) => {\n            const errorObj =\n                typeof error === \"string\" ? new Error(error) : error;\n            return await clientLoggingAPIClient.logError(\n                errorObj,\n                source,\n                metadata\n            );\n        },\n        []\n    );\n\n    const logPerformance = useCallback(\n        async (\n            metric: string,\n            value: number,\n            unit: string = \"ms\",\n            metadata?: Record<string, unknown>\n        ) => {\n            return await clientLoggingAPIClient.logPerformance(\n                metric,\n                value,\n                unit,\n                metadata\n            );\n        },\n        []\n    );\n\n    const logPageView = useCallback(\n        async (page: string, metadata?: Record<string, unknown>) => {\n            return await clientLoggingAPIClient.logPageView(page, metadata);\n        },\n        []\n    );\n\n    const logSceneInteraction = useCallback(\n        async (\n            interactionType: string,\n            sceneData?: Record<string, unknown>,\n            metadata?: Record<string, unknown>\n        ) => {\n            return await clientLoggingAPIClient.logSceneInteraction(\n                interactionType,\n                sceneData,\n                metadata\n            );\n        },\n        []\n    );\n\n    return {\n        logEvent,\n        logUserAction,\n        logError,\n        logPerformance,\n        logPageView,\n        logSceneInteraction,\n    };\n};\n\n/**\n * Hook specifically for error logging with automatic error handling\n */\nexport const useErrorLogging = () => {\n    const { logError } = useAPILogging();\n\n    const logErrorSafe = useCallback(\n        (\n            error: Error | string,\n            source?: string,\n            metadata?: Record<string, unknown>\n        ) => {\n            logError(error, source, metadata).catch(loggingError => {\n                // Fallback to console if logging fails\n                console.error(\"Failed to log error:\", loggingError);\n                console.error(\"Original error:\", error);\n            });\n        },\n        [logError]\n    );\n\n    return { logError: logErrorSafe };\n};\n",
        "client/api/hooks/use-api-version.ts": "/**\n * Version API React Hook\n *\n * React hook for version management using Clean API architecture\n */\n\nimport { useQuery } from \"@tanstack/react-query\";\nimport { clientVersionAPIClient } from \"../clients/version-client\";\nimport type { VersionInfo } from \"../clients/github-client\";\n\n/**\n * Hook to get current application version\n */\nexport const useCurrentVersion = () => {\n    return clientVersionAPIClient.getCurrentVersion();\n};\n\n/**\n * Hook to get latest version from GitHub with React Query caching\n */\nexport const useLatestVersion = (options?: {\n    enabled?: boolean;\n    staleTime?: number;\n    refetchInterval?: number;\n}) => {\n    return useQuery<VersionInfo>({\n        queryKey: [\"version\", \"latest\"],\n        queryFn: async () => {\n            const { data, error } =\n                await clientVersionAPIClient.getLatestVersion();\n            if (error) throw error;\n            return data!;\n        },\n        staleTime: options?.staleTime ?? 5 * 60 * 1000, // 5 minutes\n        refetchInterval: options?.refetchInterval ?? 30 * 60 * 1000, // 30 minutes\n        enabled: options?.enabled ?? true,\n    });\n};\n\n/**\n * Hook to get all releases from GitHub\n */\nexport const useAllReleases = (\n    limit: number = 10,\n    options?: {\n        enabled?: boolean;\n        staleTime?: number;\n    }\n) => {\n    return useQuery<VersionInfo[]>({\n        queryKey: [\"version\", \"releases\", limit],\n        queryFn: async () => {\n            const { data, error } =\n                await clientVersionAPIClient.getAllReleases(limit);\n            if (error) throw error;\n            return data!;\n        },\n        staleTime: options?.staleTime ?? 10 * 60 * 1000, // 10 minutes\n        enabled: options?.enabled ?? true,\n    });\n};\n\n/**\n * Hook to check for version updates\n */\nexport const useVersionUpdate = (options?: {\n    enabled?: boolean;\n    checkInterval?: number;\n}) => {\n    return useQuery({\n        queryKey: [\"version\", \"update-check\"],\n        queryFn: () => clientVersionAPIClient.getUpdateInfo(),\n        staleTime: 15 * 60 * 1000, // 15 minutes\n        refetchInterval: options?.checkInterval ?? 60 * 60 * 1000, // 1 hour\n        enabled: options?.enabled ?? true,\n    });\n};\n\n/**\n * Hook to clear version cache\n */\nexport const useClearVersionCache = () => {\n    return () => {\n        clientVersionAPIClient.clearCache();\n    };\n};\n",
        "client/api/hooks/use-api-worlds.ts": "/**\n * Worlds API React Hook\n *\n * React hook for world operations using Clean API architecture\n */\n\nimport { useQuery } from \"@tanstack/react-query\";\nimport { clientSupabaseAPIClient } from \"../clients/supabase-client\";\nimport type { Database } from \"@database/supabase/types\";\n\ntype World = Database[\"public\"][\"Tables\"][\"worlds\"][\"Row\"];\n\n/**\n * Hook to get all worlds with React Query caching\n */\nexport const useAPIWorlds = (options?: {\n    enabled?: boolean;\n    staleTime?: number;\n    refetchInterval?: number;\n}) => {\n    return useQuery<World[]>({\n        queryKey: [\"worlds\"],\n        queryFn: async () => {\n            const { data, error } = await clientSupabaseAPIClient.getWorlds();\n            if (error) throw error;\n            return data!;\n        },\n        staleTime: options?.staleTime ?? 5 * 60 * 1000, // 5 minutes\n        refetchInterval: options?.refetchInterval,\n        enabled: options?.enabled ?? true,\n    });\n};\n\n/**\n * Hook to get world by slug\n */\nexport const useAPIWorldBySlug = (\n    slug: string,\n    options?: {\n        enabled?: boolean;\n        staleTime?: number;\n    }\n) => {\n    return useQuery<World>({\n        queryKey: [\"worlds\", \"by-slug\", slug],\n        queryFn: async () => {\n            const { data, error } =\n                await clientSupabaseAPIClient.getWorldBySlug(slug);\n            if (error) throw error;\n            return data!;\n        },\n        staleTime: options?.staleTime ?? 10 * 60 * 1000, // 10 minutes\n        enabled: (options?.enabled ?? true) && Boolean(slug),\n    });\n};\n",
        "client/hooks/__tests__/useWorlds.test.ts": "import { QueryClient, QueryClientProvider } from \"@tanstack/react-query\";\nimport { act, renderHook, waitFor } from \"@testing-library/react\";\nimport React from \"react\";\nimport { beforeEach, describe, expect, it, vi } from \"vitest\";\n\n// Clear the global mock for this test file\nvi.unmock(\"@/hooks/useWorlds\");\n\nimport { useWorlds } from \"../useWorlds\";\n\n// Mock Supabase\nconst mockWorldsData = [\n    {\n        id: 1,\n        name: \"Genesis Torus\",\n        slug: \"genesis-torus\",\n        scene_config: { objectType: \"torusKnot\" },\n        ui_day_color: \"#ffffff\",\n        ui_night_color: \"#000000\",\n    },\n    {\n        id: 2,\n        name: \"Distortion Sphere\",\n        slug: \"distortion-sphere\",\n        scene_config: { objectType: \"distortionSphere\" },\n        ui_day_color: \"#ffffff\",\n        ui_night_color: \"#000000\",\n    },\n];\n\nvi.mock(\"@database/supabase/client\", () => ({\n    supabase: {\n        from: vi.fn(() => ({\n            select: vi.fn(() => ({\n                eq: vi.fn((field: string, value: unknown) => {\n                    if (field === \"is_featured\") {\n                        return {\n                            order: vi.fn(() =>\n                                Promise.resolve({\n                                    data: mockWorldsData,\n                                    error: null,\n                                })\n                            ),\n                            single: vi.fn(() => {\n                                // This is for fetchWorldBySlug\n                                const world = mockWorldsData.find(\n                                    w => w.slug === value\n                                );\n                                return Promise.resolve({\n                                    data: world || null,\n                                    error: world\n                                        ? null\n                                        : {\n                                              code: \"PGRST116\",\n                                              message: \"Not found\",\n                                          },\n                                });\n                            }),\n                        };\n                    }\n                    if (field === \"slug\") {\n                        return {\n                            eq: vi.fn((field2: string, _value2: unknown) => {\n                                if (field2 === \"is_featured\") {\n                                    return {\n                                        single: vi.fn(() => {\n                                            const world = mockWorldsData.find(\n                                                w => w.slug === value\n                                            );\n                                            return Promise.resolve({\n                                                data: world || null,\n                                                error: world\n                                                    ? null\n                                                    : {\n                                                          code: \"PGRST116\",\n                                                          message: \"Not found\",\n                                                      },\n                                            });\n                                        }),\n                                    };\n                                }\n                                return {};\n                            }),\n                        };\n                    }\n                    return {};\n                }),\n            })),\n        })),\n    },\n}));\n\nconst createWrapper = () => {\n    const queryClient = new QueryClient({\n        defaultOptions: {\n            queries: {\n                retry: false,\n                staleTime: Infinity,\n            },\n        },\n    });\n\n    return ({ children }: { children: React.ReactNode }) =>\n        React.createElement(\n            QueryClientProvider,\n            { client: queryClient },\n            children\n        );\n};\n\ndescribe(\"useWorlds\", () => {\n    beforeEach(() => {\n        vi.clearAllMocks();\n        vi.clearAllTimers();\n    });\n\n    it(\"should load worlds successfully\", async () => {\n        const { result } = renderHook(() => useWorlds(), {\n            wrapper: createWrapper(),\n        });\n\n        await waitFor(() => {\n            expect(result.current.isLoading).toBe(false);\n        });\n\n        expect(result.current.worlds).toHaveLength(2);\n        expect(result.current.worlds[0].name).toBe(\"Genesis Torus\");\n        expect(result.current.currentWorldIndex).toBe(0);\n        expect(result.current.worldData).toEqual(result.current.worlds[0]);\n    });\n\n    it(\"should initialize with specific world slug\", async () => {\n        const { result } = renderHook(() => useWorlds(\"distortion-sphere\"), {\n            wrapper: createWrapper(),\n        });\n\n        await waitFor(() => {\n            expect(result.current.isLoading).toBe(false);\n        });\n\n        // Wait for the useEffect to set the currentWorldIndex based on the initial slug\n        await waitFor(() => {\n            expect(result.current.currentWorldIndex).toBe(1);\n        });\n\n        expect(result.current.worldData?.slug).toBe(\"distortion-sphere\");\n    });\n\n    it(\"should handle world navigation\", async () => {\n        const { result } = renderHook(() => useWorlds(), {\n            wrapper: createWrapper(),\n        });\n\n        await waitFor(() => {\n            expect(result.current.isLoading).toBe(false);\n        });\n\n        // Ensure we start from index 0\n        expect(result.current.currentWorldIndex).toBe(0);\n\n        // Jump to second world\n        act(() => {\n            result.current.jumpToWorld(1);\n        });\n\n        // Should be transitioning immediately\n        expect(result.current.isTransitioning).toBe(true);\n\n        // Wait for the timeout in jumpToWorld to complete (1000ms + buffer)\n        await waitFor(\n            () => {\n                expect(result.current.currentWorldIndex).toBe(1);\n            },\n            { timeout: 2000 }\n        );\n\n        // Should no longer be transitioning\n        expect(result.current.isTransitioning).toBe(false);\n        expect(result.current.worldData?.slug).toBe(\"distortion-sphere\");\n    });\n\n    it(\"should handle transition state correctly\", async () => {\n        const { result } = renderHook(() => useWorlds(), {\n            wrapper: createWrapper(),\n        });\n\n        await waitFor(() => {\n            expect(result.current.isLoading).toBe(false);\n        });\n\n        expect(result.current.isTransitioning).toBe(false);\n\n        // Trigger transition\n        act(() => {\n            result.current.jumpToWorld(1);\n        });\n\n        // Should be transitioning immediately after calling jumpToWorld\n        expect(result.current.isTransitioning).toBe(true);\n\n        // Wait for transition to complete\n        await waitFor(\n            () => {\n                expect(result.current.isTransitioning).toBe(false);\n            },\n            { timeout: 2000 }\n        );\n    });\n});\n",
        "client/hooks/index.ts": "// UI State Management Hooks\nexport * from \"./use-mobile\";\nexport { toast as useToastToast, useToast } from \"./use-toast\";\n// Data Fetching Hooks\nexport * from \"./useBackgrounds\";\nexport * from \"./useBlurTransition\";\nexport * from \"./useDefaultGeometries\";\nexport * from \"./useExperience\";\nexport * from \"./useExperienceCallbacks\";\nexport * from \"./useExperienceEffects\";\nexport * from \"./useExperienceHotkeys\";\nexport * from \"./useExperienceState\";\nexport * from \"./useExperienceTransitions\";\nexport * from \"./useFirstVisit\";\nexport * from \"./useHotkeyActions\";\nexport * from \"./useInstructions\";\nexport * from \"./useKeyboardEventHandler\";\nexport * from \"./useKeyboardShortcutsState\";\nexport * from \"./useLikes\";\nexport * from \"./useOrbitControlsState\";\nexport * from \"./useSceneObjects\";\nexport * from \"./useUserScenes\";\nexport * from \"./useWorldNavigation\";\nexport * from \"./useWorlds\";\n",
        "client/hooks/use-mobile.tsx": "import * as React from \"react\";\n\nconst MOBILE_BREAKPOINT = 768;\nconst TABLET_BREAKPOINT = 1024;\n\nexport function useIsMobile() {\n    const [isMobile, setIsMobile] = React.useState<boolean | undefined>(\n        undefined\n    );\n\n    React.useEffect(() => {\n        const mql = window.matchMedia(\n            `(max-width: ${MOBILE_BREAKPOINT - 1}px)`\n        );\n        const onChange = () => {\n            setIsMobile(window.innerWidth < MOBILE_BREAKPOINT);\n        };\n        mql.addEventListener(\"change\", onChange);\n        setIsMobile(window.innerWidth < MOBILE_BREAKPOINT);\n        return () => mql.removeEventListener(\"change\", onChange);\n    }, []);\n\n    return !!isMobile;\n}\n\nexport function useIsTablet() {\n    const [isTablet, setIsTablet] = React.useState<boolean | undefined>(\n        undefined\n    );\n\n    React.useEffect(() => {\n        const mql = window.matchMedia(\n            `(min-width: ${MOBILE_BREAKPOINT}px) and (max-width: ${TABLET_BREAKPOINT - 1}px)`\n        );\n        const onChange = () => {\n            const width = window.innerWidth;\n            setIsTablet(\n                width >= MOBILE_BREAKPOINT && width < TABLET_BREAKPOINT\n            );\n        };\n        mql.addEventListener(\"change\", onChange);\n        const width = window.innerWidth;\n        setIsTablet(width >= MOBILE_BREAKPOINT && width < TABLET_BREAKPOINT);\n        return () => mql.removeEventListener(\"change\", onChange);\n    }, []);\n\n    return !!isTablet;\n}\n\nexport function useDeviceType() {\n    const isMobile = useIsMobile();\n    const isTablet = useIsTablet();\n\n    return {\n        isMobile,\n        isTablet,\n        isDesktop: !isMobile && !isTablet,\n    };\n}\n",
        "client/hooks/use-toast.ts": "import * as React from \"react\";\n\nimport type { ToastActionElement, ToastProps } from \"@/components/ui/toast\";\n\nconst TOAST_LIMIT = 1;\nconst TOAST_REMOVE_DELAY = 1000000;\n\ntype ToasterToast = ToastProps & {\n    id: string;\n    title?: React.ReactNode;\n    description?: React.ReactNode;\n    action?: ToastActionElement;\n};\n\nconst actionTypes = {\n    ADD_TOAST: \"ADD_TOAST\",\n    UPDATE_TOAST: \"UPDATE_TOAST\",\n    DISMISS_TOAST: \"DISMISS_TOAST\",\n    REMOVE_TOAST: \"REMOVE_TOAST\",\n} as const;\n\nlet count = 0;\n\nfunction genId() {\n    count = (count + 1) % Number.MAX_SAFE_INTEGER;\n    return count.toString();\n}\n\ntype ActionType = typeof actionTypes;\n\ntype Action =\n    | {\n          type: ActionType[\"ADD_TOAST\"];\n          toast: ToasterToast;\n      }\n    | {\n          type: ActionType[\"UPDATE_TOAST\"];\n          toast: Partial<ToasterToast>;\n      }\n    | {\n          type: ActionType[\"DISMISS_TOAST\"];\n          toastId?: ToasterToast[\"id\"];\n      }\n    | {\n          type: ActionType[\"REMOVE_TOAST\"];\n          toastId?: ToasterToast[\"id\"];\n      };\n\ninterface State {\n    toasts: ToasterToast[];\n}\n\nconst toastTimeouts = new Map<string, ReturnType<typeof setTimeout>>();\n\nconst addToRemoveQueue = (toastId: string) => {\n    if (toastTimeouts.has(toastId)) {\n        return;\n    }\n\n    const timeout = setTimeout(() => {\n        toastTimeouts.delete(toastId);\n        dispatch({\n            type: \"REMOVE_TOAST\",\n            toastId: toastId,\n        });\n    }, TOAST_REMOVE_DELAY);\n\n    toastTimeouts.set(toastId, timeout);\n};\n\nexport const reducer = (state: State, action: Action): State => {\n    switch (action.type) {\n        case \"ADD_TOAST\":\n            return {\n                ...state,\n                toasts: [action.toast, ...state.toasts].slice(0, TOAST_LIMIT),\n            };\n\n        case \"UPDATE_TOAST\":\n            return {\n                ...state,\n                toasts: state.toasts.map(t =>\n                    t.id === action.toast.id ? { ...t, ...action.toast } : t\n                ),\n            };\n\n        case \"DISMISS_TOAST\": {\n            const { toastId } = action;\n\n            // ! Side effects ! - This could be extracted into a dismissToast() action,\n            // but I'll keep it here for simplicity\n            if (toastId) {\n                addToRemoveQueue(toastId);\n            } else {\n                state.toasts.forEach(toast => {\n                    addToRemoveQueue(toast.id);\n                });\n            }\n\n            return {\n                ...state,\n                toasts: state.toasts.map(t =>\n                    t.id === toastId || toastId === undefined\n                        ? {\n                              ...t,\n                              open: false,\n                          }\n                        : t\n                ),\n            };\n        }\n        case \"REMOVE_TOAST\":\n            if (action.toastId === undefined) {\n                return {\n                    ...state,\n                    toasts: [],\n                };\n            }\n            return {\n                ...state,\n                toasts: state.toasts.filter(t => t.id !== action.toastId),\n            };\n    }\n};\n\nconst listeners: Array<(state: State) => void> = [];\n\nlet memoryState: State = { toasts: [] };\n\nfunction dispatch(action: Action) {\n    memoryState = reducer(memoryState, action);\n    listeners.forEach(listener => {\n        listener(memoryState);\n    });\n}\n\ntype Toast = Omit<ToasterToast, \"id\">;\n\nfunction toast({ ...props }: Toast) {\n    const id = genId();\n\n    const update = (props: ToasterToast) =>\n        dispatch({\n            type: \"UPDATE_TOAST\",\n            toast: { ...props, id },\n        });\n    const dismiss = () => dispatch({ type: \"DISMISS_TOAST\", toastId: id });\n\n    dispatch({\n        type: \"ADD_TOAST\",\n        toast: {\n            ...props,\n            id,\n            open: true,\n            onOpenChange: open => {\n                if (!open) dismiss();\n            },\n        },\n    });\n\n    return {\n        id: id,\n        dismiss,\n        update,\n    };\n}\n\nfunction useToast() {\n    const [state, setState] = React.useState<State>(memoryState);\n\n    React.useEffect(() => {\n        listeners.push(setState);\n        return () => {\n            const index = listeners.indexOf(setState);\n            if (index > -1) {\n                listeners.splice(index, 1);\n            }\n        };\n    }, []);\n\n    return {\n        ...state,\n        toast,\n        dismiss: (toastId?: string) =>\n            dispatch({ type: \"DISMISS_TOAST\", toastId }),\n    };\n}\n\nexport { useToast, toast };\n",
        "client/hooks/useBackgrounds.ts": "import { supabase } from \"@database/supabase/client\";\nimport type { Database } from \"@database/supabase/types\";\nimport { useQuery } from \"@tanstack/react-query\";\nimport { useCallback, useMemo, useState } from \"react\";\n\ntype Background = Database[\"public\"][\"Tables\"][\"backgrounds\"][\"Row\"];\n\nconst fetchBackgrounds = async (): Promise<Background[]> => {\n    const { data, error } = await supabase\n        .from(\"backgrounds\")\n        .select(\"*\")\n        .eq(\"is_featured\", true)\n        .order(\"sort_order\", { ascending: true });\n\n    if (error) throw new Error(error.message);\n\n    return data || [];\n};\n\nexport const useBackgrounds = () => {\n    const [currentBackgroundIndex, setCurrentBackgroundIndex] = useState(0);\n    const [isTransitioning, setIsTransitioning] = useState(false);\n\n    const {\n        data: backgrounds,\n        isLoading,\n        isError,\n        error,\n    } = useQuery<Background[]>({\n        queryKey: [\"backgrounds\"],\n        queryFn: fetchBackgrounds,\n    });\n\n    // Debug logging\n    console.log(\"useBackgrounds debug:\", {\n        backgrounds,\n        isLoading,\n        isError,\n        error: error?.message,\n        backgroundsLength: backgrounds?.length,\n    });\n\n    const currentBackground = useMemo(() => {\n        if (!backgrounds || backgrounds.length === 0) return null;\n        return backgrounds[currentBackgroundIndex];\n    }, [backgrounds, currentBackgroundIndex]);\n\n    const changeBackground = useCallback(\n        (direction: \"next\" | \"prev\") => {\n            if (isTransitioning || !backgrounds || backgrounds.length === 0)\n                return;\n\n            setIsTransitioning(true);\n\n            setTimeout(() => {\n                setCurrentBackgroundIndex(prevIndex => {\n                    if (!backgrounds) return 0;\n                    const newIndex =\n                        direction === \"next\"\n                            ? (prevIndex + 1) % backgrounds.length\n                            : (prevIndex - 1 + backgrounds.length) %\n                              backgrounds.length;\n                    console.log(\n                        \"Changing background from index\",\n                        prevIndex,\n                        \"to\",\n                        newIndex\n                    );\n                    return newIndex;\n                });\n\n                setTimeout(() => {\n                    setIsTransitioning(false);\n                }, 400);\n            }, 200);\n        },\n        [isTransitioning, backgrounds]\n    );\n\n    const jumpToBackground = useCallback(\n        (index: number) => {\n            if (isTransitioning || !backgrounds || backgrounds.length === 0) {\n                return;\n            }\n\n            const targetIndex = backgrounds.findIndex(bg => bg.id === index);\n            if (targetIndex === -1 || targetIndex === currentBackgroundIndex) {\n                return;\n            }\n\n            console.log(\n                \"Jumping to background index:\",\n                targetIndex,\n                \"for id:\",\n                index\n            );\n            setIsTransitioning(true);\n\n            setTimeout(() => {\n                setCurrentBackgroundIndex(targetIndex);\n                setTimeout(() => {\n                    setIsTransitioning(false);\n                }, 400);\n            }, 200);\n        },\n        [isTransitioning, backgrounds, currentBackgroundIndex]\n    );\n\n    return {\n        backgrounds,\n        isLoading,\n        isError,\n        currentBackground,\n        currentBackgroundIndex,\n        isTransitioning,\n        changeBackground,\n        jumpToBackground,\n    };\n};\n",
        "client/hooks/useBlurTransition.ts": "import { useCallback, useEffect, useState } from \"react\";\n\nexport const useBlurTransition = () => {\n    const [isBlurring, setIsBlurring] = useState(false);\n    const [isReady, setIsReady] = useState(false);\n\n    const startBlurTransition = useCallback(() => {\n        setIsBlurring(true);\n        setIsReady(false);\n    }, []);\n\n    const completeBlurTransition = useCallback(() => {\n        setIsBlurring(false);\n        setIsReady(true);\n    }, []);\n\n    // Auto-start blur on mount\n    useEffect(() => {\n        startBlurTransition();\n\n        // Simulate loading time\n        const timer = setTimeout(() => {\n            completeBlurTransition();\n        }, 800);\n\n        return () => clearTimeout(timer);\n    }, [startBlurTransition, completeBlurTransition]);\n\n    return {\n        isBlurring,\n        isReady,\n        startBlurTransition,\n        completeBlurTransition,\n    };\n};\n",
        "client/hooks/useDefaultGeometries.ts": "import { supabase } from \"@database/supabase/client\";\nimport type { Database } from \"@database/supabase/types\";\nimport { useQuery } from \"@tanstack/react-query\";\nimport { useCallback, useMemo, useState } from \"react\";\n\ntype DefaultGeometry =\n    Database[\"public\"][\"Tables\"][\"default_geometries\"][\"Row\"];\n\nconst fetchDefaultGeometries = async (): Promise<DefaultGeometry[]> => {\n    const { data, error } = await supabase\n        .from(\"default_geometries\")\n        .select(\"*\")\n        .eq(\"is_featured\", true)\n        .order(\"sort_order\", { ascending: true });\n\n    if (error) throw new Error(error.message);\n\n    return data || [];\n};\n\nexport const useDefaultGeometries = () => {\n    const [currentGeometryIndex, setCurrentGeometryIndex] = useState(0);\n\n    const {\n        data: geometries,\n        isLoading,\n        isError,\n    } = useQuery<DefaultGeometry[]>({\n        queryKey: [\"default_geometries\"],\n        queryFn: fetchDefaultGeometries,\n    });\n\n    const currentGeometry = useMemo(() => {\n        if (!geometries || geometries.length === 0) return null;\n        return geometries[currentGeometryIndex];\n    }, [geometries, currentGeometryIndex]);\n\n    const changeGeometry = useCallback(\n        (direction: \"next\" | \"prev\") => {\n            if (!geometries || geometries.length === 0) return;\n\n            setCurrentGeometryIndex(prevIndex => {\n                const newIndex =\n                    direction === \"next\"\n                        ? (prevIndex + 1) % geometries.length\n                        : (prevIndex - 1 + geometries.length) %\n                          geometries.length;\n                return newIndex;\n            });\n        },\n        [geometries]\n    );\n\n    const jumpToGeometry = useCallback(\n        (index: number) => {\n            if (!geometries || geometries.length === 0) {\n                return;\n            }\n\n            const targetIndex = geometries.findIndex(geo => geo.id === index);\n            if (targetIndex === -1 || targetIndex === currentGeometryIndex) {\n                return;\n            }\n\n            setCurrentGeometryIndex(targetIndex);\n        },\n        [geometries, currentGeometryIndex]\n    );\n\n    return {\n        geometries,\n        isLoading,\n        isError,\n        currentGeometry,\n        currentGeometryIndex,\n        changeGeometry,\n        jumpToGeometry,\n    };\n};\n",
        "client/hooks/useExperience.ts": "import { useContext } from \"react\";\nimport { ExperienceContext } from \"@/context/ExperienceContext\";\n\nexport const useExperience = () => {\n    const context = useContext(ExperienceContext);\n\n    if (context === undefined) {\n        throw new Error(\n            \"useExperience must be used within an ExperienceProvider\"\n        );\n    }\n\n    return context;\n};\n",
        "client/hooks/useExperienceCallbacks.ts": "import { useCallback } from \"react\";\nimport { useNavigate } from \"react-router-dom\";\nimport { useKeyboardShortcuts } from \"@/context/KeyboardShortcutsContext\";\nimport { logEvent } from \"@/lib/logger\";\n\nexport const useExperienceCallbacks = () => {\n    const navigate = useNavigate();\n    const { toggleVisible: toggleKeyboardShortcuts } = useKeyboardShortcuts();\n\n    const handleGoHome = useCallback(() => {\n        navigate(\"/\");\n    }, [navigate]);\n\n    const handleToggleShortcuts = useCallback(() => {\n        console.log(\"useExperienceCallbacks - handleToggleShortcuts called\");\n        toggleKeyboardShortcuts();\n        logEvent({\n            eventType: \"keyboard_shortcut\",\n            eventSource: \"toggle_shortcuts\",\n        });\n    }, [toggleKeyboardShortcuts]);\n\n    return {\n        handleGoHome,\n        handleToggleShortcuts,\n    };\n};\n",
        "client/hooks/useExperienceEffects.ts": "import type { Database } from \"@database/supabase/types\";\nimport { useEffect } from \"react\";\nimport { logEvent } from \"@/lib/logger\";\nimport { createSceneConfigFromGeometry } from \"@/lib/sceneConfigUtils\";\nimport type { SceneConfig } from \"@/types/scene\";\n\ntype DefaultGeometry =\n    Database[\"public\"][\"Tables\"][\"default_geometries\"][\"Row\"];\n\ninterface UseExperienceEffectsProps {\n    worldData: DefaultGeometry | null;\n    currentWorldId: number | null;\n    setEditableSceneConfig: (config: SceneConfig) => void;\n    setCurrentWorldId: (id: number) => void;\n    isSettingsOpen: boolean;\n    setIsSettingsOpen: (open: boolean) => void;\n    hintShownRef: React.MutableRefObject<boolean>;\n    setShowUiHint: (show: boolean) => void;\n    handleEntryTransitionEnd: () => void;\n}\n\nexport const useExperienceEffects = ({\n    worldData,\n    currentWorldId,\n    setEditableSceneConfig,\n    setCurrentWorldId,\n    isSettingsOpen,\n    setIsSettingsOpen,\n    hintShownRef,\n    setShowUiHint,\n    handleEntryTransitionEnd,\n}: UseExperienceEffectsProps) => {\n    // World data effect - updated for geometry-based system\n    useEffect(() => {\n        if (worldData && worldData.id !== currentWorldId) {\n            // Create proper scene config from geometry data\n            const sceneConfig = createSceneConfigFromGeometry(worldData);\n\n            setEditableSceneConfig(sceneConfig);\n            setCurrentWorldId(worldData.id);\n            if (isSettingsOpen) {\n                setIsSettingsOpen(false);\n            }\n\n            handleEntryTransitionEnd();\n        }\n    }, [\n        worldData,\n        currentWorldId,\n        isSettingsOpen,\n        setEditableSceneConfig,\n        setCurrentWorldId,\n        setIsSettingsOpen,\n        handleEntryTransitionEnd,\n    ]);\n\n    // Settings escape key effect\n    useEffect(() => {\n        const handleKeyDown = (event: KeyboardEvent) => {\n            if (event.code === \"Escape\" && isSettingsOpen) {\n                event.preventDefault();\n                setIsSettingsOpen(false);\n                logEvent({\n                    eventType: \"keyboard_shortcut\",\n                    eventSource: \"close_settings\",\n                });\n            }\n        };\n\n        window.addEventListener(\"keydown\", handleKeyDown);\n        return () => {\n            window.removeEventListener(\"keydown\", handleKeyDown);\n        };\n    }, [isSettingsOpen, setIsSettingsOpen]);\n\n    // Entry transition hint effect\n    const handleEntryTransitionEndWithHint = () => {\n        handleEntryTransitionEnd();\n        if (!hintShownRef.current) {\n            hintShownRef.current = true;\n            setShowUiHint(true);\n            setTimeout(() => {\n                setShowUiHint(false);\n            }, 4000);\n        }\n    };\n\n    return {\n        handleEntryTransitionEndWithHint,\n    };\n};\n",
        "client/hooks/useExperienceHotkeys.ts": "import { useEffect } from \"react\";\nimport { useHotkeyActions } from \"./useHotkeyActions\";\nimport { useKeyboardEventHandler } from \"./useKeyboardEventHandler\";\n\ninterface HotkeyCallbacks {\n    toggleTheme: () => void;\n    changeWorld: (direction: \"next\" | \"prev\") => void;\n    changeGeometry: (direction: \"next\" | \"prev\") => void;\n    openSearch: () => void;\n    goHome: () => void;\n    openHelp: () => void;\n    toggleSettings: () => void;\n    copyCode: () => void;\n    toggleUi: () => void;\n    toggleLock: () => void;\n    toggleShortcuts: () => void;\n}\n\ninterface useExperienceHotkeysProps {\n    callbacks: HotkeyCallbacks;\n    enabled: boolean;\n}\n\nexport const useExperienceHotkeys = ({\n    callbacks,\n    enabled,\n}: useExperienceHotkeysProps) => {\n    const actions = useHotkeyActions(callbacks);\n    const { handleKeyDown } = useKeyboardEventHandler({\n        onToggleTheme: actions.handleToggleTheme,\n        onChangeWorld: actions.changeWorld,\n        onChangeGeometry: actions.changeGeometry,\n        onOpenSearch: actions.openSearch,\n        onGoHome: actions.goHome,\n        onOpenHelp: actions.handleOpenHelp,\n        onToggleSettings: actions.handleToggleSettings,\n        onCopyCode: actions.copyCode,\n        onToggleUi: actions.toggleUi,\n        onToggleLock: actions.handleToggleLock,\n        onToggleShortcuts: actions.handleToggleShortcuts,\n        enabled,\n    });\n\n    useEffect(() => {\n        window.addEventListener(\"keydown\", handleKeyDown);\n\n        return () => {\n            window.removeEventListener(\"keydown\", handleKeyDown);\n        };\n    }, [handleKeyDown]);\n};\n",
        "client/hooks/useExperienceState.ts": "import { useCallback, useEffect, useRef, useState } from \"react\";\nimport { toast } from \"sonner\";\nimport { logEvent } from \"@/lib/logger\";\nimport type { SceneConfig } from \"@/types/scene\";\n\nexport const useExperienceState = () => {\n    const [editableSceneConfig, setEditableSceneConfig] =\n        useState<SceneConfig | null>(null);\n    const [isObjectLocked, setIsObjectLocked] = useState(false);\n    const [currentWorldId, setCurrentWorldId] = useState<number | null>(null);\n    const [isHelpOpen, setIsHelpOpen] = useState(false);\n    const [isSearchOpen, setIsSearchOpen] = useState(false);\n    const [isSettingsOpen, setIsSettingsOpen] = useState(false);\n    const [isDragEnabled, setIsDragEnabled] = useState(false);\n    const [isMotionFrozen, setIsMotionFrozen] = useState(false);\n\n    // Helper function for localStorage operations\n    const getStoredBoolean = (key: string, defaultValue: boolean): boolean => {\n        if (typeof window === \"undefined\") return defaultValue;\n\n        try {\n            const stored = localStorage.getItem(key);\n            return stored ? JSON.parse(stored) : defaultValue;\n        } catch {\n            return defaultValue;\n        }\n    };\n\n    // Stable UI state management with helper\n    const [isUiHidden, setIsUiHidden] = useState(() =>\n        getStoredBoolean(\"uiHidden\", true)\n    );\n    const [showUiHint, setShowUiHint] = useState(false);\n    const [hasInitialized, setHasInitialized] = useState(false);\n    const hintShownRef = useRef(false);\n\n    // Stable localStorage persistence\n    useEffect(() => {\n        if (hasInitialized && typeof window !== \"undefined\") {\n            try {\n                localStorage.setItem(\"uiHidden\", JSON.stringify(isUiHidden));\n            } catch (error) {\n                console.warn(\"Failed to save UI state to localStorage:\", error);\n            }\n        }\n    }, [isUiHidden, hasInitialized]);\n\n    // Initialize once\n    useEffect(() => {\n        if (!hasInitialized) {\n            setHasInitialized(true);\n        }\n    }, [hasInitialized]);\n\n    const toggleObjectLock = useCallback(() => {\n        setIsObjectLocked(locked => {\n            const newLockState = !locked;\n\n            // Improved toast notification with better styling and icons\n            if (newLockState) {\n                toast.success(\" Object motion locked\", {\n                    description: \"Objects will no longer rotate automatically\",\n                    duration: 2500,\n                    style: {\n                        background: \"rgba(0, 0, 0, 0.9)\",\n                        color: \"#fff\",\n                        border: \"1px solid rgba(255, 255, 255, 0.2)\",\n                        backdropFilter: \"blur(8px)\",\n                    },\n                });\n            } else {\n                toast.success(\" Object motion unlocked\", {\n                    description: \"Objects will resume automatic rotation\",\n                    duration: 2500,\n                    style: {\n                        background: \"rgba(0, 0, 0, 0.9)\",\n                        color: \"#fff\",\n                        border: \"1px solid rgba(255, 255, 255, 0.2)\",\n                        backdropFilter: \"blur(8px)\",\n                    },\n                });\n            }\n\n            return newLockState;\n        });\n    }, []);\n\n    const toggleDragEnabled = useCallback(() => {\n        setIsDragEnabled(enabled => {\n            const newState = !enabled;\n            toast.info(newState ? \"Drag Mode Enabled\" : \"Drag Mode Disabled\", {\n                description: newState\n                    ? \"You can now move objects\"\n                    : \"Camera rotation re-enabled\",\n                duration: 2500,\n                style: {\n                    background: \"rgba(0, 0, 0, 0.9)\",\n                    color: \"#fff\",\n                    border: \"1px solid rgba(255, 255, 255, 0.2)\",\n                    backdropFilter: \"blur(8px)\",\n                },\n            });\n            logEvent({\n                eventType: \"action\",\n                eventSource: \"toggle_drag_mode\",\n                metadata: { enabled: newState },\n            });\n\n            // Clear selection when disabling drag mode\n            if (!newState && typeof window !== \"undefined\") {\n                // Signal to clear selection - we'll handle this in SceneObjectsProvider\n                window.dispatchEvent(new CustomEvent(\"clearSelection\"));\n            }\n\n            return newState;\n        });\n    }, []);\n\n    const toggleMotionFreeze = useCallback(() => {\n        setIsMotionFrozen(frozen => {\n            const newState = !frozen;\n            toast.info(\n                newState ? \" Animation Frozen\" : \" Animation Resumed\",\n                {\n                    description: newState\n                        ? \"Scene motion is now paused\"\n                        : \"Scene motion has resumed\",\n                    duration: 2500,\n                    style: {\n                        background: \"rgba(0, 0, 0, 0.9)\",\n                        color: \"#fff\",\n                        border: \"1px solid rgba(255, 255, 255, 0.2)\",\n                        backdropFilter: \"blur(8px)\",\n                    },\n                }\n            );\n            logEvent({\n                eventType: \"action\",\n                eventSource: \"toggle_motion_freeze\",\n                metadata: { frozen: newState },\n            });\n            return newState;\n        });\n    }, []);\n\n    const handleCopyCode = useCallback(() => {\n        if (!editableSceneConfig) return;\n\n        try {\n            const codeString = JSON.stringify(editableSceneConfig, null, 2);\n            navigator.clipboard\n                .writeText(codeString)\n                .then(() => {\n                    toast.success(\" Scene configuration copied!\", {\n                        description: \"Ready to paste into your project\",\n                        duration: 3000,\n                        style: {\n                            background: \"rgba(0, 0, 0, 0.9)\",\n                            color: \"#fff\",\n                            border: \"1px solid rgba(34, 197, 94, 0.3)\",\n                            backdropFilter: \"blur(8px)\",\n                        },\n                    });\n                    logEvent({\n                        eventType: \"action\",\n                        eventSource: \"copy_code_success\",\n                    });\n                })\n                .catch(err => {\n                    console.error(\"Failed to copy text: \", err);\n                    toast.error(\" Failed to copy configuration\", {\n                        description: \"Please try again\",\n                        style: {\n                            background: \"rgba(0, 0, 0, 0.9)\",\n                            color: \"#fff\",\n                            border: \"1px solid rgba(239, 68, 68, 0.3)\",\n                            backdropFilter: \"blur(8px)\",\n                        },\n                    });\n                    logEvent({\n                        eventType: \"action\",\n                        eventSource: \"copy_code_failure\",\n                        metadata: { error: (err as Error).message },\n                    });\n                });\n        } catch (error) {\n            console.error(\"Failed to serialize config:\", error);\n            toast.error(\" Failed to prepare configuration\", {\n                description: \"Configuration could not be serialized\",\n                style: {\n                    background: \"rgba(0, 0, 0, 0.9)\",\n                    color: \"#fff\",\n                    border: \"1px solid rgba(239, 68, 68, 0.3)\",\n                    backdropFilter: \"blur(8px)\",\n                },\n            });\n        }\n    }, [editableSceneConfig]);\n\n    return {\n        editableSceneConfig,\n        setEditableSceneConfig,\n        isObjectLocked,\n        toggleObjectLock,\n        currentWorldId,\n        setCurrentWorldId,\n        isHelpOpen,\n        setIsHelpOpen,\n        isSearchOpen,\n        setIsSearchOpen,\n        isSettingsOpen,\n        setIsSettingsOpen,\n        isUiHidden,\n        setIsUiHidden,\n        showUiHint,\n        setShowUiHint,\n        hintShownRef,\n        handleCopyCode,\n        isDragEnabled,\n        toggleDragEnabled,\n        isMotionFrozen,\n        toggleMotionFreeze,\n    };\n};\n",
        "client/hooks/useExperienceTransitions.ts": "import { useEffect, useRef, useState } from \"react\";\n\nexport const useExperienceTransitions = (isTransitioning: boolean) => {\n    const [showEntryTransition, setShowEntryTransition] = useState(true);\n    const [showWorldTransition, setShowWorldTransition] = useState(false);\n    const [showBlurTransition, setShowBlurTransition] = useState(true);\n    const hintShownRef = useRef(false);\n\n    const handleEntryTransitionEnd = () => {\n        setShowEntryTransition(false);\n        if (!hintShownRef.current) {\n            hintShownRef.current = true;\n        }\n    };\n\n    const handleWorldTransitionEnd = () => {\n        setShowWorldTransition(false);\n    };\n\n    const handleBlurTransitionEnd = () => {\n        setShowBlurTransition(false);\n    };\n\n    // Handle world switching transitions\n    useEffect(() => {\n        if (isTransitioning) {\n            setShowBlurTransition(true);\n            setShowWorldTransition(false);\n\n            // Smooth transition sequence\n            const blurTimer = setTimeout(() => {\n                setShowBlurTransition(false);\n                setShowWorldTransition(true);\n            }, 300);\n\n            return () => clearTimeout(blurTimer);\n        } else {\n            // Smooth transition out\n            const timer = setTimeout(() => {\n                setShowWorldTransition(false);\n            }, 200);\n            return () => clearTimeout(timer);\n        }\n    }, [isTransitioning]);\n\n    // Handle initial blur transition\n    useEffect(() => {\n        if (showBlurTransition) {\n            const timer = setTimeout(() => {\n                setShowBlurTransition(false);\n            }, 1000);\n            return () => clearTimeout(timer);\n        }\n    }, [showBlurTransition]);\n\n    return {\n        showEntryTransition,\n        showWorldTransition,\n        showBlurTransition,\n        handleEntryTransitionEnd,\n        handleWorldTransitionEnd,\n        handleBlurTransitionEnd,\n    };\n};\n",
        "client/hooks/useFirstVisit.ts": "import { useEffect, useState } from \"react\";\n\nexport const useFirstVisit = () => {\n    const [isFirstVisit, setIsFirstVisit] = useState(false);\n    const [showOnboardingHints, setShowOnboardingHints] = useState(false);\n    const [isInitialized, setIsInitialized] = useState(false);\n\n    const handleFirstInteraction = () => {\n        setShowOnboardingHints(false);\n        setIsFirstVisit(false);\n\n        if (typeof window !== \"undefined\") {\n            try {\n                localStorage.setItem(\"has-visited-immersive-canvas\", \"true\");\n            } catch (error) {\n                console.warn(\"Could not save first visit state:\", error);\n            }\n        }\n    };\n\n    useEffect(() => {\n        if (typeof window !== \"undefined\") {\n            try {\n                const hasVisited = localStorage.getItem(\n                    \"has-visited-immersive-canvas\"\n                );\n                const firstVisit = !hasVisited;\n\n                setIsFirstVisit(firstVisit);\n                setShowOnboardingHints(firstVisit);\n                setIsInitialized(true);\n\n                // Mark as visited after a delay to allow onboarding to show\n                if (firstVisit) {\n                    const timer = setTimeout(() => {\n                        localStorage.setItem(\n                            \"has-visited-immersive-canvas\",\n                            \"true\"\n                        );\n                    }, 5000);\n                    return () => clearTimeout(timer);\n                }\n            } catch (error) {\n                console.warn(\n                    \"Could not access localStorage for first visit tracking:\",\n                    error\n                );\n                setIsInitialized(true);\n            }\n        }\n    }, []);\n\n    useEffect(() => {\n        if (!showOnboardingHints) return;\n\n        // Listen for any drag/pointer events on the canvas to hide onboarding\n        const handleCanvasInteraction = (e: PointerEvent) => {\n            const target = e.target as HTMLElement;\n            // Check if the interaction is on the canvas or within the canvas container\n            if (target.tagName === \"CANVAS\" || target.closest(\"canvas\")) {\n                handleFirstInteraction();\n            }\n        };\n\n        // Add event listeners for pointer events\n        document.addEventListener(\"pointermove\", handleCanvasInteraction);\n        document.addEventListener(\"pointerdown\", handleCanvasInteraction);\n\n        return () => {\n            document.removeEventListener(\n                \"pointermove\",\n                handleCanvasInteraction\n            );\n            document.removeEventListener(\n                \"pointerdown\",\n                handleCanvasInteraction\n            );\n        };\n    }, [showOnboardingHints, handleFirstInteraction]);\n\n    return {\n        isFirstVisit,\n        showOnboardingHints,\n        isInitialized,\n        handleFirstInteraction,\n    };\n};\n",
        "client/hooks/useHotkeyActions.ts": "import { useCallback } from \"react\";\nimport { logEvent } from \"@/lib/logger\";\n\ninterface HotkeyActionCallbacks {\n    toggleTheme: () => void;\n    changeWorld: (direction: \"next\" | \"prev\") => void;\n    changeGeometry: (direction: \"next\" | \"prev\") => void;\n    openSearch: () => void;\n    goHome: () => void;\n    openHelp: () => void;\n    toggleSettings: () => void;\n    copyCode: () => void;\n    toggleUi: () => void;\n    toggleLock: () => void;\n    toggleShortcuts: () => void;\n}\n\nexport const useHotkeyActions = (callbacks: HotkeyActionCallbacks) => {\n    const handleToggleTheme = useCallback(() => {\n        callbacks.toggleTheme();\n        logEvent({\n            eventType: \"keyboard_shortcut\",\n            eventSource: \"toggle_theme\",\n        });\n    }, [callbacks]);\n\n    const handleToggleShortcuts = useCallback(() => {\n        console.log(\"useHotkeyActions - handleToggleShortcuts called\");\n        callbacks.toggleShortcuts();\n        logEvent({\n            eventType: \"keyboard_shortcut\",\n            eventSource: \"toggle_shortcuts\",\n        });\n    }, [callbacks]);\n\n    const handleToggleLock = useCallback(() => {\n        callbacks.toggleLock();\n        logEvent({\n            eventType: \"keyboard_shortcut\",\n            eventSource: \"toggle_lock\",\n        });\n    }, [callbacks]);\n\n    const handleOpenHelp = useCallback(() => {\n        callbacks.openHelp();\n        logEvent({ eventType: \"keyboard_shortcut\", eventSource: \"open_help\" });\n    }, [callbacks]);\n\n    const handleToggleSettings = useCallback(() => {\n        callbacks.toggleSettings();\n        logEvent({\n            eventType: \"keyboard_shortcut\",\n            eventSource: \"toggle_settings\",\n        });\n    }, [callbacks]);\n\n    return {\n        handleToggleTheme,\n        handleToggleShortcuts,\n        handleToggleLock,\n        handleOpenHelp,\n        handleToggleSettings,\n        changeWorld: callbacks.changeWorld,\n        changeGeometry: callbacks.changeGeometry,\n        openSearch: callbacks.openSearch,\n        goHome: callbacks.goHome,\n        copyCode: callbacks.copyCode,\n        toggleUi: callbacks.toggleUi,\n    };\n};\n",
        "client/hooks/useInstructions.ts": "import { useMemo } from \"react\";\n\ninterface InstructionSet {\n    primary: string;\n    secondary: string;\n    tertiary: string;\n    welcome?: string;\n}\n\nexport const useInstructions = (\n    isFirstVisit: boolean,\n    isMobile: boolean\n): InstructionSet => {\n    return useMemo((): InstructionSet => {\n        const baseInstructions = {\n            primary: isMobile\n                ? \"Drag to look around, pinch to zoom\"\n                : \"Click and drag to explore, scroll to zoom\",\n            secondary: isMobile\n                ? \"Use navigation arrows to discover new worlds\"\n                : \"Press N/P or use arrows to travel between worlds\",\n            tertiary: isMobile\n                ? \"Tap the theme button to switch day/night\"\n                : \"Press Space or theme button to toggle day/night\",\n        };\n\n        if (isFirstVisit) {\n            return {\n                ...baseInstructions,\n                welcome: \"Welcome to your journey through immersive worlds!\",\n            };\n        }\n\n        return baseInstructions;\n    }, [isFirstVisit, isMobile]);\n};\n",
        "client/hooks/useKeyboardEventHandler.ts": "import { useCallback } from \"react\";\nimport { isUserTyping } from \"@/lib/keyboardUtils\";\n\ninterface KeyboardEventHandlerProps {\n    onToggleTheme: () => void;\n    onChangeWorld: (direction: \"next\" | \"prev\") => void;\n    onChangeGeometry: (direction: \"next\" | \"prev\") => void;\n    onOpenSearch: () => void;\n    onGoHome: () => void;\n    onOpenHelp: () => void;\n    onToggleSettings: () => void;\n    onCopyCode: () => void;\n    onToggleUi: () => void;\n    onToggleLock: () => void;\n    onToggleShortcuts: () => void;\n    enabled: boolean;\n}\n\nexport const useKeyboardEventHandler = ({\n    onToggleTheme,\n    onChangeWorld,\n    onChangeGeometry,\n    onOpenSearch,\n    onGoHome,\n    onOpenHelp,\n    onToggleSettings,\n    onCopyCode,\n    onToggleUi,\n    onToggleLock,\n    onToggleShortcuts,\n    enabled,\n}: KeyboardEventHandlerProps) => {\n    const handleKeyDown = useCallback(\n        (event: KeyboardEvent) => {\n            console.log(\n                \"KeyboardEventHandler - Key pressed:\",\n                event.code,\n                \"enabled:\",\n                enabled\n            );\n\n            if (!enabled) {\n                console.log(\"KeyboardEventHandler - Handler disabled\");\n                return;\n            }\n\n            const typing = isUserTyping();\n            console.log(\"KeyboardEventHandler - User typing:\", typing);\n\n            // Skip M key - it's handled separately in ExperienceHotkeys\n            if (event.code === \"KeyM\") {\n                console.log(\n                    \"KeyboardEventHandler - M key skipped (handled separately)\"\n                );\n                return;\n            }\n\n            switch (event.code) {\n                case \"Space\":\n                    event.preventDefault();\n                    onToggleTheme();\n                    break;\n\n                case \"KeyN\":\n                    if (!typing) {\n                        event.preventDefault();\n                        onChangeWorld(\"next\");\n                    }\n                    break;\n\n                case \"KeyP\":\n                    if (!typing) {\n                        event.preventDefault();\n                        onChangeWorld(\"prev\");\n                    }\n                    break;\n\n                case \"KeyK\":\n                    if ((event.ctrlKey || event.metaKey) && !typing) {\n                        event.preventDefault();\n                        onOpenSearch();\n                    }\n                    break;\n\n                case \"KeyG\":\n                    if (!typing) {\n                        event.preventDefault();\n                        onGoHome();\n                    }\n                    break;\n\n                case \"KeyO\":\n                    if (!typing) {\n                        event.preventDefault();\n                        if (event.shiftKey) {\n                            onChangeGeometry(\"prev\");\n                        } else {\n                            onChangeGeometry(\"next\");\n                        }\n                    }\n                    break;\n\n                case \"KeyS\":\n                    if (!typing) {\n                        event.preventDefault();\n                        onOpenSearch();\n                    }\n                    break;\n\n                case \"KeyH\":\n                    if (!typing) {\n                        event.preventDefault();\n                        onOpenHelp();\n                    }\n                    break;\n\n                case \"Escape\":\n                    if (!typing) {\n                        event.preventDefault();\n                        onToggleSettings();\n                    }\n                    break;\n\n                case \"KeyC\":\n                    if (!typing) {\n                        event.preventDefault();\n                        onCopyCode();\n                    }\n                    break;\n\n                case \"KeyV\":\n                    if (!typing) {\n                        event.preventDefault();\n                        onToggleUi();\n                    }\n                    break;\n\n                case \"Period\":\n                    if (!typing) {\n                        event.preventDefault();\n                        onToggleLock();\n                    }\n                    break;\n            }\n        },\n        [\n            enabled,\n            onToggleTheme,\n            onChangeWorld,\n            onChangeGeometry,\n            onOpenSearch,\n            onGoHome,\n            onOpenHelp,\n            onToggleSettings,\n            onCopyCode,\n            onToggleUi,\n            onToggleLock,\n        ]\n    );\n\n    return { handleKeyDown };\n};\n",
        "client/hooks/useKeyboardShortcutsState.ts": "import { useState } from \"react\";\n\nexport const useKeyboardShortcutsState = () => {\n    const [isExpanded, setIsExpanded] = useState(true);\n    const [isVisible, setIsVisible] = useState(false);\n\n    const toggleExpanded = () => {\n        console.log(\n            \"useKeyboardShortcutsState - toggleExpanded called, current:\",\n            isExpanded\n        );\n        setIsExpanded(prev => !prev);\n    };\n\n    const toggleVisible = () => {\n        console.log(\n            \"useKeyboardShortcutsState - toggleVisible called, current:\",\n            isVisible\n        );\n        setIsVisible(prev => !prev);\n    };\n\n    return {\n        isExpanded,\n        isVisible,\n        toggleExpanded,\n        toggleVisible,\n    };\n};\n",
        "client/hooks/useLikes.ts": "import { useCallback, useEffect, useState } from \"react\";\nimport { logEvent } from \"@/lib/logger\";\n\nconst LIKES_STORAGE_KEY = \"world-likes\";\n\nconst getLikesFromStorage = (): Set<number> => {\n    try {\n        const storedLikes = localStorage.getItem(LIKES_STORAGE_KEY);\n        if (storedLikes) {\n            const parsed = JSON.parse(storedLikes);\n            if (Array.isArray(parsed)) {\n                return new Set(parsed);\n            }\n        }\n    } catch (error) {\n        console.error(\"Error reading likes from localStorage\", error);\n    }\n    return new Set();\n};\n\nexport const useLikes = () => {\n    const [likedWorlds, setLikedWorlds] = useState<Set<number>>(new Set());\n\n    useEffect(() => {\n        setLikedWorlds(getLikesFromStorage());\n    }, []);\n\n    const isLiked = useCallback(\n        (worldId: number) => {\n            return likedWorlds.has(worldId);\n        },\n        [likedWorlds]\n    );\n\n    const toggleLike = useCallback(\n        (worldId: number, worldName: string) => {\n            const newLikedWorlds = new Set(likedWorlds);\n            let liked;\n            if (newLikedWorlds.has(worldId)) {\n                newLikedWorlds.delete(worldId);\n                liked = false;\n            } else {\n                newLikedWorlds.add(worldId);\n                liked = true;\n            }\n            setLikedWorlds(newLikedWorlds);\n            localStorage.setItem(\n                LIKES_STORAGE_KEY,\n                JSON.stringify(Array.from(newLikedWorlds))\n            );\n            logEvent({\n                eventType: \"world_like_toggled\",\n                eventSource: \"useLikes\",\n                metadata: { worldId, worldName, liked },\n            });\n        },\n        [likedWorlds]\n    );\n\n    return { isLiked, toggleLike };\n};\n",
        "client/hooks/useOrbitControlsState.ts": "import { useThree } from \"@react-three/fiber\";\nimport { useEffect, useRef } from \"react\";\nimport { useSceneObjectsContext } from \"@/context/SceneObjectsContext\";\n\nexport const useOrbitControlsState = () => {\n    const { isDragging, isDragEnabled } = useSceneObjectsContext();\n    const { gl } = useThree();\n    const orbitControlsRef = useRef<{ enabled: boolean } | null>(null);\n\n    useEffect(() => {\n        // Find orbit controls in the scene\n        const scene = gl.domElement.parentElement;\n        if (scene) {\n            const canvas = scene.querySelector(\"canvas\");\n            if (canvas && orbitControlsRef.current) {\n                // Disable orbit controls when dragging objects\n                orbitControlsRef.current.enabled =\n                    !isDragging && !isDragEnabled;\n            }\n        }\n    }, [isDragging, isDragEnabled, gl]);\n\n    return { orbitControlsRef };\n};\n",
        "client/hooks/useSceneObjects.ts": "import { useCallback, useEffect, useState } from \"react\";\nimport { toast } from \"sonner\";\nimport type {\n    ObjectManagerActions,\n    ObjectManagerState,\n    SceneObject,\n} from \"@/types/sceneObjects\";\n\nconst GEOMETRIES = [\n    { type: \"box\" as const, name: \"Box\" },\n    { type: \"sphere\" as const, name: \"Sphere\" },\n    { type: \"cylinder\" as const, name: \"Cylinder\" },\n    { type: \"cone\" as const, name: \"Cone\" },\n    { type: \"torus\" as const, name: \"Torus\" },\n];\n\nexport const useSceneObjects = (mainObjectColor: string = \"#ffffff\") => {\n    const [state, setState] = useState<ObjectManagerState>({\n        objects: [],\n        selectedObjectId: null,\n        isAddingObject: false,\n        availableGeometries: GEOMETRIES,\n    });\n\n    // Listen for drag mode disable to clear selection\n    useEffect(() => {\n        const handleClearSelection = () => {\n            setState(prev => ({ ...prev, selectedObjectId: null }));\n        };\n\n        window.addEventListener(\"clearSelection\", handleClearSelection);\n        return () =>\n            window.removeEventListener(\"clearSelection\", handleClearSelection);\n    }, []);\n\n    const addObject = useCallback(\n        (type: SceneObject[\"type\"]) => {\n            const newObject: SceneObject = {\n                id: `obj_${Date.now()}`,\n                type,\n                position: [\n                    (Math.random() - 0.5) * 6,\n                    (Math.random() - 0.5) * 6,\n                    (Math.random() - 0.5) * 6,\n                ],\n                rotation: [0, 0, 0],\n                scale: [1, 1, 1],\n                color: mainObjectColor,\n                material: {\n                    type: \"standard\",\n                    metalness: 0.1,\n                    roughness: 0.4,\n                    wireframe: false,\n                    transparent: false,\n                    opacity: 1,\n                },\n            };\n\n            setState(prev => ({\n                ...prev,\n                objects: [...prev.objects, newObject],\n                selectedObjectId: newObject.id,\n            }));\n\n            toast.success(`${type} added`);\n        },\n        [mainObjectColor]\n    );\n\n    const removeObject = useCallback((id: string) => {\n        setState(prev => ({\n            ...prev,\n            objects: prev.objects.filter(obj => obj.id !== id),\n            selectedObjectId:\n                prev.selectedObjectId === id ? null : prev.selectedObjectId,\n        }));\n        toast.success(\"Object removed\");\n    }, []);\n\n    const updateObject = useCallback(\n        (id: string, updates: Partial<SceneObject>) => {\n            console.log(\" updateObject called:\", { id, updates });\n            setState(prev => {\n                const updatedObjects = prev.objects.map(obj => {\n                    if (obj.id === id) {\n                        const updatedObj = { ...obj, ...updates };\n                        // Ensure arrays are properly cloned for React to detect changes\n                        if (updates.position) {\n                            updatedObj.position = [...updates.position] as [\n                                number,\n                                number,\n                                number,\n                            ];\n                        }\n                        if (updates.rotation) {\n                            updatedObj.rotation = [...updates.rotation] as [\n                                number,\n                                number,\n                                number,\n                            ];\n                        }\n                        if (updates.scale) {\n                            updatedObj.scale = [...updates.scale] as [\n                                number,\n                                number,\n                                number,\n                            ];\n                        }\n                        console.log(\" Object updated:\", {\n                            old: obj,\n                            new: updatedObj,\n                        });\n                        return updatedObj;\n                    }\n                    return obj;\n                });\n\n                return {\n                    ...prev,\n                    objects: updatedObjects,\n                };\n            });\n        },\n        []\n    );\n\n    const selectObject = useCallback((id: string | null) => {\n        setState(prev => ({ ...prev, selectedObjectId: id }));\n    }, []);\n\n    const clearObjects = useCallback(() => {\n        setState(prev => ({ ...prev, objects: [], selectedObjectId: null }));\n        toast.success(\"All objects cleared\");\n    }, []);\n\n    const actions: ObjectManagerActions = {\n        addObject,\n        removeObject,\n        updateObject,\n        selectObject,\n        clearObjects,\n        toggleAddMode: () => {}, // Simplified - no longer needed\n    };\n\n    return {\n        ...state,\n        actions,\n        selectedObject:\n            state.objects.find(obj => obj.id === state.selectedObjectId) ||\n            null,\n    };\n};\n",
        "client/hooks/useSceneSettingsViewModel.ts": "import { useCallback, useEffect, useState } from \"react\";\nimport { createConfigUpdater } from \"@/components/scene/controls/ConfigUpdateUtils\";\nimport type { SceneConfig } from \"@/types/scene\";\nimport { useBackgrounds } from \"./useBackgrounds\";\nimport { useDefaultGeometries } from \"./useDefaultGeometries\";\nimport { useExperience } from \"./useExperience\";\n\n/**\n * ViewModel for Scene Settings Panel\n * Implements MVVM pattern with proper separation of concerns\n */\nexport const useSceneSettingsViewModel = (\n    sceneConfig: SceneConfig,\n    onSceneUpdate: (config: SceneConfig) => void,\n    isMotionFrozen?: boolean,\n    onToggleMotion?: () => void\n) => {\n    const { theme } = useExperience();\n    const {\n        currentGeometry,\n        geometries,\n        jumpToGeometry,\n        currentGeometryIndex,\n    } = useDefaultGeometries();\n    const {\n        currentBackground,\n        backgrounds,\n        jumpToBackground,\n        currentBackgroundIndex,\n    } = useBackgrounds();\n\n    // Local state for UI interactions\n    const [selectedBackgroundId, setSelectedBackgroundId] = useState<\n        string | null\n    >(null);\n    const [selectedGeometryId, setSelectedGeometryId] = useState<string | null>(\n        null\n    );\n\n    // Initialize selections from current state\n    useEffect(() => {\n        if (currentBackground && !selectedBackgroundId) {\n            setSelectedBackgroundId(currentBackground.id.toString());\n        }\n        if (currentGeometry && !selectedGeometryId) {\n            setSelectedGeometryId(currentGeometry.id.toString());\n        }\n    }, [\n        currentBackground,\n        currentGeometry,\n        selectedBackgroundId,\n        selectedGeometryId,\n    ]);\n\n    // Scene update functions\n    const updateMainObjectColor = useCallback(\n        (color: string) => {\n            const updater = createConfigUpdater(sceneConfig, onSceneUpdate);\n            updater(config => {\n                config[theme].mainObjectColor = color;\n            });\n        },\n        [sceneConfig, onSceneUpdate, theme]\n    );\n\n    const updateMaterialProperty = useCallback(\n        (property: string, value: string | number | boolean) => {\n            const updater = createConfigUpdater(sceneConfig, onSceneUpdate);\n            updater(config => {\n                config[theme].material = {\n                    ...config[theme].material,\n                    [property]: value,\n                };\n            });\n        },\n        [sceneConfig, onSceneUpdate, theme]\n    );\n\n    const updateLightProperty = useCallback(\n        (\n            lightIndex: number,\n            property: string,\n            value: string | number | boolean | number[]\n        ) => {\n            const updater = createConfigUpdater(sceneConfig, onSceneUpdate);\n            updater(config => {\n                if (config[theme].lights[lightIndex]) {\n                    config[theme].lights[lightIndex] = {\n                        ...config[theme].lights[lightIndex],\n                        [property]: value,\n                    };\n                }\n            });\n        },\n        [sceneConfig, onSceneUpdate, theme]\n    );\n\n    const updateBackgroundProperty = useCallback(\n        (property: string, value: string | number | boolean) => {\n            const updater = createConfigUpdater(sceneConfig, onSceneUpdate);\n            updater(config => {\n                config[theme].background = {\n                    ...config[theme].background,\n                    [property]: value,\n                };\n            });\n        },\n        [sceneConfig, onSceneUpdate, theme]\n    );\n\n    // Background selection handler\n    const handleBackgroundChange = useCallback(\n        (backgroundId: string) => {\n            setSelectedBackgroundId(backgroundId);\n            const backgroundIndex = backgrounds?.findIndex(\n                bg => bg.id === parseInt(backgroundId)\n            );\n            if (backgroundIndex !== undefined && backgroundIndex !== -1) {\n                jumpToBackground(backgroundIndex);\n            }\n        },\n        [backgrounds, jumpToBackground]\n    );\n\n    // Geometry selection handler\n    const handleGeometryChange = useCallback(\n        (geometryId: string) => {\n            setSelectedGeometryId(geometryId);\n            const geometryIndex = geometries?.findIndex(\n                geo => geo.id === parseInt(geometryId)\n            );\n            if (geometryIndex !== undefined && geometryIndex !== -1) {\n                jumpToGeometry(geometryIndex);\n            }\n        },\n        [geometries, jumpToGeometry]\n    );\n\n    // Motion freeze handler\n    const handleToggleMotion = useCallback(() => {\n        if (onToggleMotion) {\n            onToggleMotion();\n        }\n    }, [onToggleMotion]);\n\n    // Scene reset handler\n    const handleResetScene = useCallback(() => {\n        // Reset to default scene configuration\n        const defaultConfig: SceneConfig = {\n            type: \"TorusKnot\",\n            day: {\n                mainObjectColor: \"#ffffff\",\n                material: {\n                    materialType: \"standard\",\n                    metalness: 0.5,\n                    roughness: 0.5,\n                    emissive: \"#000000\",\n                    emissiveIntensity: 0,\n                    transparent: false,\n                    opacity: 1,\n                },\n                background: {\n                    type: \"void\",\n                },\n                lights: [\n                    { type: \"ambient\", intensity: 1.5 },\n                    {\n                        type: \"directional\",\n                        position: [10, 10, 5],\n                        intensity: 1,\n                    },\n                ],\n            },\n            night: {\n                mainObjectColor: \"#ffffff\",\n                material: {\n                    materialType: \"standard\",\n                    metalness: 0.5,\n                    roughness: 0.5,\n                    emissive: \"#000000\",\n                    emissiveIntensity: 0,\n                    transparent: false,\n                    opacity: 1,\n                },\n                background: {\n                    type: \"void\",\n                },\n                lights: [\n                    { type: \"ambient\", intensity: 0.8 },\n                    {\n                        type: \"directional\",\n                        position: [10, 10, 5],\n                        intensity: 0.5,\n                    },\n                ],\n            },\n        };\n        onSceneUpdate(defaultConfig);\n    }, [onSceneUpdate]);\n\n    // Computed properties for UI\n    const themeConfig = sceneConfig[theme];\n    const availableBackgrounds = backgrounds || [];\n    const availableGeometries = geometries || [];\n\n    return {\n        // State\n        theme,\n        themeConfig,\n        isMotionFrozen: isMotionFrozen || false,\n        selectedBackgroundId,\n        selectedGeometryId,\n        currentBackground,\n        currentGeometry,\n        availableBackgrounds,\n        availableGeometries,\n        currentBackgroundIndex,\n        currentGeometryIndex,\n\n        // Actions\n        updateMainObjectColor,\n        updateMaterialProperty,\n        updateLightProperty,\n        updateBackgroundProperty,\n        handleBackgroundChange,\n        handleGeometryChange,\n        handleToggleMotion,\n        handleResetScene,\n\n        // Computed\n        sceneConfig,\n        onSceneUpdate,\n    };\n};\n",
        "client/hooks/useSettingsPanelViewModel.ts": "/**\n * Settings Panel ViewModel - Proper MVVM Implementation\n * Following TDD principles and MEMORY.md guidelines\n *\n * This ViewModel manages all settings panel state and behavior,\n * providing a clean separation between UI and business logic\n */\n\nimport { useCallback, useState } from \"react\";\nimport type { SceneConfig } from \"@/types/scene\";\nimport { useExperience } from \"./useExperience\";\n\ntype SettingsAction =\n    | { type: \"UPDATE_MAIN_COLOR\"; payload: string }\n    | {\n          type: \"UPDATE_MATERIAL_PROPERTY\";\n          payload: { property: string; value: string | number | boolean };\n      }\n    | {\n          type: \"UPDATE_LIGHT_PROPERTY\";\n          payload: {\n              lightIndex: number;\n              property: string;\n              value: string | number | boolean | number[];\n          };\n      }\n    | {\n          type: \"UPDATE_BACKGROUND_PROPERTY\";\n          payload: { property: string; value: string | number | boolean };\n      }\n    | { type: \"RESET_SCENE\" }\n    | { type: \"TOGGLE_MOTION\" };\n\ninterface SettingsPanelViewModelOptions {\n    sceneConfig: SceneConfig;\n    onSceneUpdate: (config: SceneConfig) => void;\n    isMotionFrozen?: boolean;\n    onToggleMotion?: () => void;\n}\n\n/**\n * Default scene configuration for reset functionality\n */\nconst createDefaultSceneConfig = (): SceneConfig => ({\n    type: \"TorusKnot\",\n    day: {\n        mainObjectColor: \"#ffffff\",\n        material: {\n            materialType: \"standard\",\n            metalness: 0.5,\n            roughness: 0.5,\n            emissive: \"#000000\",\n            emissiveIntensity: 0,\n            transparent: false,\n            opacity: 1,\n        },\n        background: {\n            type: \"void\",\n        },\n        lights: [\n            { type: \"ambient\", intensity: 1.5 },\n            { type: \"directional\", position: [10, 10, 5], intensity: 1 },\n        ],\n    },\n    night: {\n        mainObjectColor: \"#ffffff\",\n        material: {\n            materialType: \"standard\",\n            metalness: 0.5,\n            roughness: 0.5,\n            emissive: \"#000000\",\n            emissiveIntensity: 0,\n            transparent: false,\n            opacity: 1,\n        },\n        background: {\n            type: \"void\",\n        },\n        lights: [\n            { type: \"ambient\", intensity: 0.8 },\n            { type: \"directional\", position: [10, 10, 5], intensity: 0.5 },\n        ],\n    },\n});\n\n/**\n * Pure function to update scene config immutably\n */\nconst updateSceneConfig = (\n    currentConfig: SceneConfig,\n    action: SettingsAction,\n    theme: \"day\" | \"night\"\n): SceneConfig => {\n    switch (action.type) {\n        case \"UPDATE_MAIN_COLOR\":\n            return {\n                ...currentConfig,\n                [theme]: {\n                    ...currentConfig[theme],\n                    mainObjectColor: action.payload,\n                },\n            };\n\n        case \"UPDATE_MATERIAL_PROPERTY\":\n            return {\n                ...currentConfig,\n                [theme]: {\n                    ...currentConfig[theme],\n                    material: {\n                        ...currentConfig[theme].material,\n                        [action.payload.property]: action.payload.value,\n                    },\n                },\n            };\n\n        case \"UPDATE_LIGHT_PROPERTY\": {\n            const updatedLights = [...currentConfig[theme].lights];\n            if (updatedLights[action.payload.lightIndex]) {\n                updatedLights[action.payload.lightIndex] = {\n                    ...updatedLights[action.payload.lightIndex],\n                    [action.payload.property]: action.payload.value,\n                };\n            }\n            return {\n                ...currentConfig,\n                [theme]: {\n                    ...currentConfig[theme],\n                    lights: updatedLights,\n                },\n            };\n        }\n\n        case \"UPDATE_BACKGROUND_PROPERTY\":\n            return {\n                ...currentConfig,\n                [theme]: {\n                    ...currentConfig[theme],\n                    background: {\n                        ...currentConfig[theme].background,\n                        [action.payload.property]: action.payload.value,\n                    },\n                },\n            };\n\n        case \"RESET_SCENE\":\n            return createDefaultSceneConfig();\n\n        default:\n            return currentConfig;\n    }\n};\n\n/**\n * Settings Panel ViewModel Hook\n * Implements MVVM pattern with immutable state updates\n */\nexport const useSettingsPanelViewModel = ({\n    sceneConfig,\n    onSceneUpdate,\n    isMotionFrozen = false,\n    onToggleMotion,\n}: SettingsPanelViewModelOptions) => {\n    const { theme } = useExperience();\n\n    // Internal state for UI interactions\n    const [isDirty, setIsDirty] = useState(false);\n\n    // Helper function to dispatch scene updates\n    const dispatchSceneUpdate = useCallback(\n        (action: SettingsAction) => {\n            const updatedConfig = updateSceneConfig(sceneConfig, action, theme);\n            onSceneUpdate(updatedConfig);\n            setIsDirty(true);\n\n            // Reset dirty flag after a short delay\n            setTimeout(() => setIsDirty(false), 100);\n        },\n        [sceneConfig, onSceneUpdate, theme]\n    );\n\n    // Main object color handlers\n    const updateMainObjectColor = useCallback(\n        (color: string) => {\n            dispatchSceneUpdate({ type: \"UPDATE_MAIN_COLOR\", payload: color });\n        },\n        [dispatchSceneUpdate]\n    );\n\n    // Material property handlers\n    const updateMaterialProperty = useCallback(\n        (property: string, value: string | number | boolean) => {\n            dispatchSceneUpdate({\n                type: \"UPDATE_MATERIAL_PROPERTY\",\n                payload: { property, value },\n            });\n        },\n        [dispatchSceneUpdate]\n    );\n\n    const updateMaterialType = useCallback(\n        (materialType: string) => {\n            updateMaterialProperty(\"materialType\", materialType);\n        },\n        [updateMaterialProperty]\n    );\n\n    const updateMaterialMetalness = useCallback(\n        (metalness: number) => {\n            updateMaterialProperty(\"metalness\", metalness);\n        },\n        [updateMaterialProperty]\n    );\n\n    const updateMaterialRoughness = useCallback(\n        (roughness: number) => {\n            updateMaterialProperty(\"roughness\", roughness);\n        },\n        [updateMaterialProperty]\n    );\n\n    // Light property handlers\n    const updateLightProperty = useCallback(\n        (\n            lightIndex: number,\n            property: string,\n            value: string | number | boolean | number[]\n        ) => {\n            dispatchSceneUpdate({\n                type: \"UPDATE_LIGHT_PROPERTY\",\n                payload: { lightIndex, property, value },\n            });\n        },\n        [dispatchSceneUpdate]\n    );\n\n    const updateAmbientLightIntensity = useCallback(\n        (intensity: number) => {\n            // Find ambient light index\n            const ambientIndex = sceneConfig[theme].lights.findIndex(\n                light => light.type === \"ambient\"\n            );\n            if (ambientIndex !== -1) {\n                updateLightProperty(ambientIndex, \"intensity\", intensity);\n            }\n        },\n        [updateLightProperty, sceneConfig, theme]\n    );\n\n    const updateDirectionalLightIntensity = useCallback(\n        (intensity: number) => {\n            // Find directional light index\n            const directionalIndex = sceneConfig[theme].lights.findIndex(\n                light => light.type === \"directional\"\n            );\n            if (directionalIndex !== -1) {\n                updateLightProperty(directionalIndex, \"intensity\", intensity);\n            }\n        },\n        [updateLightProperty, sceneConfig, theme]\n    );\n\n    // Background property handlers\n    const updateBackgroundProperty = useCallback(\n        (property: string, value: string | number | boolean) => {\n            dispatchSceneUpdate({\n                type: \"UPDATE_BACKGROUND_PROPERTY\",\n                payload: { property, value },\n            });\n        },\n        [dispatchSceneUpdate]\n    );\n\n    const updateBackgroundType = useCallback(\n        (backgroundType: string) => {\n            updateBackgroundProperty(\"type\", backgroundType);\n        },\n        [updateBackgroundProperty]\n    );\n\n    // Scene management handlers\n    const resetScene = useCallback(() => {\n        dispatchSceneUpdate({ type: \"RESET_SCENE\" });\n    }, [dispatchSceneUpdate]);\n\n    const toggleMotion = useCallback(() => {\n        if (onToggleMotion) {\n            onToggleMotion();\n        }\n    }, [onToggleMotion]);\n\n    // Computed values for UI\n    const currentThemeConfig = sceneConfig[theme];\n    const mainObjectColor = currentThemeConfig.mainObjectColor;\n    const materialConfig = currentThemeConfig.material;\n    const backgroundConfig = currentThemeConfig.background;\n    const lightsConfig = currentThemeConfig.lights;\n\n    // Get specific light values for UI\n    const ambientLight = lightsConfig.find(light => light.type === \"ambient\");\n    const directionalLight = lightsConfig.find(\n        light => light.type === \"directional\"\n    );\n\n    return {\n        // State\n        theme,\n        isDirty,\n        isMotionFrozen,\n        mainObjectColor,\n        materialConfig,\n        backgroundConfig,\n        lightsConfig,\n        ambientLightIntensity: ambientLight?.intensity || 1,\n        directionalLightIntensity: directionalLight?.intensity || 1,\n\n        // Actions - Main Object\n        updateMainObjectColor,\n\n        // Actions - Material\n        updateMaterialType,\n        updateMaterialMetalness,\n        updateMaterialRoughness,\n        updateMaterialProperty,\n\n        // Actions - Lights\n        updateAmbientLightIntensity,\n        updateDirectionalLightIntensity,\n        updateLightProperty,\n\n        // Actions - Background\n        updateBackgroundType,\n        updateBackgroundProperty,\n\n        // Actions - Scene Management\n        resetScene,\n        toggleMotion,\n\n        // Computed Values\n        sceneConfig,\n        currentThemeConfig,\n    };\n};\n",
        "client/hooks/useUserScenes.ts": "/**\n * Hook for managing user-saved scenes\n * Currently uses localStorage, ready for database persistence\n */\n\nimport { useCallback, useEffect, useState } from \"react\";\nimport { toast } from \"sonner\";\nimport type {\n    UserScene,\n    UserSceneCreateInput,\n    UserScenesActions,\n    UserScenesState,\n    UserSceneUpdateInput,\n} from \"@/types/userScenes\";\n\nconst STORAGE_KEY = \"immersive-awe-user-scenes\";\n\n// Simulated database operations (ready for real DB integration)\nclass UserScenesService {\n    private async delay(ms: number = 100): Promise<void> {\n        return new Promise(resolve => setTimeout(resolve, ms));\n    }\n\n    private getStoredScenes(): UserScene[] {\n        if (typeof window === \"undefined\") return [];\n\n        try {\n            const stored = localStorage.getItem(STORAGE_KEY);\n            return stored ? JSON.parse(stored) : [];\n        } catch (error) {\n            console.error(\"Failed to load user scenes:\", error);\n            return [];\n        }\n    }\n\n    private saveStoredScenes(scenes: UserScene[]): void {\n        if (typeof window === \"undefined\") return;\n\n        try {\n            localStorage.setItem(STORAGE_KEY, JSON.stringify(scenes));\n        } catch (error) {\n            console.error(\"Failed to save user scenes:\", error);\n            throw new Error(\"Failed to save scene\");\n        }\n    }\n\n    async getAllScenes(): Promise<UserScene[]> {\n        await this.delay(); // Simulate network delay\n        return this.getStoredScenes();\n    }\n\n    async createScene(input: UserSceneCreateInput): Promise<UserScene> {\n        await this.delay();\n\n        const scenes = this.getStoredScenes();\n        const newScene: UserScene = {\n            id: `scene_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,\n            name: input.name,\n            description: input.description,\n            sceneConfig: input.sceneConfig,\n            baseGeometryId: input.baseGeometryId,\n            isPublic: input.isPublic ?? false,\n            tags: input.tags ?? [],\n            createdAt: new Date().toISOString(),\n            updatedAt: new Date().toISOString(),\n        };\n\n        scenes.push(newScene);\n        this.saveStoredScenes(scenes);\n\n        return newScene;\n    }\n\n    async updateScene(\n        id: string,\n        input: UserSceneUpdateInput\n    ): Promise<UserScene> {\n        await this.delay();\n\n        const scenes = this.getStoredScenes();\n        const sceneIndex = scenes.findIndex(s => s.id === id);\n\n        if (sceneIndex === -1) {\n            throw new Error(\"Scene not found\");\n        }\n\n        const updatedScene: UserScene = {\n            ...scenes[sceneIndex],\n            ...input,\n            updatedAt: new Date().toISOString(),\n        };\n\n        scenes[sceneIndex] = updatedScene;\n        this.saveStoredScenes(scenes);\n\n        return updatedScene;\n    }\n\n    async deleteScene(id: string): Promise<void> {\n        await this.delay();\n\n        const scenes = this.getStoredScenes();\n        const filteredScenes = scenes.filter(s => s.id !== id);\n\n        if (filteredScenes.length === scenes.length) {\n            throw new Error(\"Scene not found\");\n        }\n\n        this.saveStoredScenes(filteredScenes);\n    }\n\n    async getScene(id: string): Promise<UserScene> {\n        await this.delay();\n\n        const scenes = this.getStoredScenes();\n        const scene = scenes.find(s => s.id === id);\n\n        if (!scene) {\n            throw new Error(\"Scene not found\");\n        }\n\n        return scene;\n    }\n}\n\nconst userScenesService = new UserScenesService();\n\nexport const useUserScenes = () => {\n    const [state, setState] = useState<UserScenesState>({\n        scenes: [],\n        isLoading: false,\n        error: null,\n        selectedSceneId: null,\n    });\n\n    // Load scenes on mount\n    useEffect(() => {\n        const loadScenes = async () => {\n            setState(prev => ({ ...prev, isLoading: true, error: null }));\n\n            try {\n                const scenes = await userScenesService.getAllScenes();\n                setState(prev => ({ ...prev, scenes, isLoading: false }));\n            } catch (error) {\n                setState(prev => ({\n                    ...prev,\n                    error:\n                        error instanceof Error\n                            ? error.message\n                            : \"Failed to load scenes\",\n                    isLoading: false,\n                }));\n            }\n        };\n\n        loadScenes();\n    }, []);\n\n    const saveScene = useCallback(\n        async (input: UserSceneCreateInput): Promise<UserScene> => {\n            setState(prev => ({ ...prev, isLoading: true, error: null }));\n\n            try {\n                const newScene = await userScenesService.createScene(input);\n\n                setState(prev => ({\n                    ...prev,\n                    scenes: [...prev.scenes, newScene],\n                    isLoading: false,\n                    selectedSceneId: newScene.id,\n                }));\n\n                toast.success(\" Scene saved successfully!\", {\n                    description: `\"${newScene.name}\" has been saved to your collection`,\n                    duration: 3000,\n                });\n\n                return newScene;\n            } catch (error) {\n                const errorMessage =\n                    error instanceof Error\n                        ? error.message\n                        : \"Failed to save scene\";\n                setState(prev => ({\n                    ...prev,\n                    error: errorMessage,\n                    isLoading: false,\n                }));\n\n                toast.error(\" Failed to save scene\", {\n                    description: errorMessage,\n                });\n\n                throw error;\n            }\n        },\n        []\n    );\n\n    const updateScene = useCallback(\n        async (id: string, input: UserSceneUpdateInput): Promise<UserScene> => {\n            setState(prev => ({ ...prev, isLoading: true, error: null }));\n\n            try {\n                const updatedScene = await userScenesService.updateScene(\n                    id,\n                    input\n                );\n\n                setState(prev => ({\n                    ...prev,\n                    scenes: prev.scenes.map(s =>\n                        s.id === id ? updatedScene : s\n                    ),\n                    isLoading: false,\n                }));\n\n                toast.success(\" Scene updated successfully!\", {\n                    description: `\"${updatedScene.name}\" has been updated`,\n                });\n\n                return updatedScene;\n            } catch (error) {\n                const errorMessage =\n                    error instanceof Error\n                        ? error.message\n                        : \"Failed to update scene\";\n                setState(prev => ({\n                    ...prev,\n                    error: errorMessage,\n                    isLoading: false,\n                }));\n\n                toast.error(\" Failed to update scene\", {\n                    description: errorMessage,\n                });\n\n                throw error;\n            }\n        },\n        []\n    );\n\n    const deleteScene = useCallback(async (id: string): Promise<void> => {\n        setState(prev => ({ ...prev, isLoading: true, error: null }));\n\n        try {\n            await userScenesService.deleteScene(id);\n\n            setState(prev => ({\n                ...prev,\n                scenes: prev.scenes.filter(s => s.id !== id),\n                isLoading: false,\n                selectedSceneId:\n                    prev.selectedSceneId === id ? null : prev.selectedSceneId,\n            }));\n\n            toast.success(\" Scene deleted successfully!\");\n        } catch (error) {\n            const errorMessage =\n                error instanceof Error\n                    ? error.message\n                    : \"Failed to delete scene\";\n            setState(prev => ({\n                ...prev,\n                error: errorMessage,\n                isLoading: false,\n            }));\n\n            toast.error(\" Failed to delete scene\", {\n                description: errorMessage,\n            });\n\n            throw error;\n        }\n    }, []);\n\n    const loadScene = useCallback(async (id: string): Promise<UserScene> => {\n        try {\n            const scene = await userScenesService.getScene(id);\n            setState(prev => ({ ...prev, selectedSceneId: id }));\n            return scene;\n        } catch (error) {\n            toast.error(\" Failed to load scene\");\n            throw error;\n        }\n    }, []);\n\n    const duplicateScene = useCallback(\n        async (id: string, newName: string): Promise<UserScene> => {\n            try {\n                const originalScene = await userScenesService.getScene(id);\n                const duplicateInput: UserSceneCreateInput = {\n                    name: newName,\n                    description: originalScene.description,\n                    sceneConfig: originalScene.sceneConfig,\n                    baseGeometryId: originalScene.baseGeometryId,\n                    isPublic: false, // Duplicates are private by default\n                    tags: [...originalScene.tags],\n                };\n\n                return await saveScene(duplicateInput);\n            } catch (error) {\n                toast.error(\" Failed to duplicate scene\");\n                throw error;\n            }\n        },\n        [saveScene]\n    );\n\n    const exportScene = useCallback(async (id: string): Promise<string> => {\n        try {\n            const scene = await userScenesService.getScene(id);\n            const exportData = {\n                ...scene,\n                exportedAt: new Date().toISOString(),\n                version: \"1.0.0\",\n            };\n\n            return JSON.stringify(exportData, null, 2);\n        } catch (error) {\n            toast.error(\" Failed to export scene\");\n            throw error;\n        }\n    }, []);\n\n    const importScene = useCallback(\n        async (jsonData: string): Promise<UserScene> => {\n            try {\n                const importedData = JSON.parse(jsonData);\n\n                // Validate imported data structure\n                if (!importedData.name || !importedData.sceneConfig) {\n                    throw new Error(\"Invalid scene data format\");\n                }\n\n                const importInput: UserSceneCreateInput = {\n                    name: `${importedData.name} (Imported)`,\n                    description: importedData.description,\n                    sceneConfig: importedData.sceneConfig,\n                    baseGeometryId: importedData.baseGeometryId,\n                    isPublic: false, // Imported scenes are private by default\n                    tags: [...(importedData.tags || []), \"imported\"],\n                };\n\n                return await saveScene(importInput);\n            } catch (error) {\n                toast.error(\" Failed to import scene\", {\n                    description: \"Please check the file format and try again\",\n                });\n                throw error;\n            }\n        },\n        [saveScene]\n    );\n\n    const actions: UserScenesActions = {\n        saveScene,\n        updateScene,\n        deleteScene,\n        loadScene,\n        duplicateScene,\n        exportScene,\n        importScene,\n    };\n\n    return {\n        ...state,\n        actions,\n    };\n};\n",
        "client/hooks/useWorldNavigation.ts": "import { useCallback } from \"react\";\nimport { useNavigate } from \"react-router-dom\";\n\ninterface UseWorldNavigationProps {\n    worlds: { slug: string }[] | undefined;\n    currentWorldIndex: number;\n    jumpToWorld: (index: number) => void;\n}\n\nexport const useWorldNavigation = ({\n    worlds,\n    currentWorldIndex,\n    jumpToWorld,\n}: UseWorldNavigationProps) => {\n    const navigate = useNavigate();\n\n    const handleChangeWorld = useCallback(\n        (direction: \"next\" | \"prev\") => {\n            if (!worlds || worlds.length === 0) return;\n\n            const nextIndex =\n                direction === \"next\"\n                    ? (currentWorldIndex + 1) % worlds.length\n                    : (currentWorldIndex - 1 + worlds.length) % worlds.length;\n\n            const nextWorld = worlds[nextIndex];\n            if (nextWorld?.slug) {\n                console.log(\"Navigating to world:\", nextWorld.slug);\n                navigate(`/experience/${nextWorld.slug}`);\n            }\n        },\n        [worlds, currentWorldIndex, navigate]\n    );\n\n    const handleJumpToWorld = useCallback(\n        (index: number) => {\n            if (!worlds || !worlds[index]) return;\n\n            const world = worlds[index];\n            if (world.slug) {\n                console.log(\"Jumping to world:\", world.slug);\n                navigate(`/experience/${world.slug}`);\n            }\n        },\n        [worlds, navigate]\n    );\n\n    return {\n        handleChangeWorld,\n        handleJumpToWorld,\n    };\n};\n",
        "client/hooks/useWorlds.ts": "import { supabase } from \"@database/supabase/client\";\nimport type { Database } from \"@database/supabase/types\";\nimport { useQuery } from \"@tanstack/react-query\";\nimport { useCallback, useEffect, useMemo, useState } from \"react\";\n\ntype World = Database[\"public\"][\"Tables\"][\"worlds\"][\"Row\"];\n\nconst fetchWorlds = async (): Promise<World[]> => {\n    const { data, error } = await supabase\n        .from(\"worlds\")\n        .select(\"*\")\n        .eq(\"is_featured\", true)\n        .order(\"id\", { ascending: true });\n\n    if (error) throw new Error(error.message);\n\n    return data || [];\n};\n\nconst fetchWorldBySlug = async (slug: string): Promise<World | null> => {\n    const { data, error } = await supabase\n        .from(\"worlds\")\n        .select(\"*\")\n        .eq(\"slug\", slug)\n        .eq(\"is_featured\", true)\n        .single();\n\n    if (error) {\n        if (error.code === \"PGRST116\") return null; // Not found\n        throw new Error(error.message);\n    }\n\n    return data;\n};\n\nexport const useWorlds = (initialSlug?: string) => {\n    const [currentWorldIndex, setCurrentWorldIndex] = useState(0);\n    const [isTransitioning, setIsTransitioning] = useState(false);\n\n    const {\n        data: worlds,\n        isLoading,\n        isError,\n    } = useQuery<World[]>({\n        queryKey: [\"worlds\"],\n        queryFn: fetchWorlds,\n    });\n\n    const { data: initialWorld } = useQuery<World | null>({\n        queryKey: [\"world\", initialSlug],\n        queryFn: () =>\n            initialSlug ? fetchWorldBySlug(initialSlug) : Promise.resolve(null),\n        enabled: !!initialSlug,\n    });\n\n    // Set initial world index based on slug\n    useEffect(() => {\n        if (initialWorld && worlds) {\n            const index = worlds.findIndex(w => w.slug === initialWorld.slug);\n            if (index !== -1 && index !== currentWorldIndex) {\n                console.log(\n                    \"Setting world index to:\",\n                    index,\n                    \"for slug:\",\n                    initialWorld.slug\n                );\n                setCurrentWorldIndex(index);\n            }\n        } else if (\n            worlds &&\n            worlds.length > 0 &&\n            !initialSlug &&\n            currentWorldIndex === 0\n        ) {\n            // If no initial slug provided, default to first world (only if still at 0)\n            setCurrentWorldIndex(0);\n        }\n    }, [initialWorld, worlds, initialSlug]);\n\n    const worldData = useMemo(() => {\n        if (!worlds || worlds.length === 0) return null;\n        return worlds[currentWorldIndex];\n    }, [worlds, currentWorldIndex]);\n\n    const changeWorld = useCallback(\n        (direction: \"next\" | \"prev\") => {\n            if (isTransitioning || !worlds || worlds.length === 0) return;\n\n            setIsTransitioning(true);\n\n            setTimeout(() => {\n                setCurrentWorldIndex(prevIndex => {\n                    if (!worlds) return 0;\n                    const newIndex =\n                        direction === \"next\"\n                            ? (prevIndex + 1) % worlds.length\n                            : (prevIndex - 1 + worlds.length) % worlds.length;\n                    console.log(\n                        \"Changing world from index\",\n                        prevIndex,\n                        \"to\",\n                        newIndex\n                    );\n                    return newIndex;\n                });\n\n                setIsTransitioning(false);\n            }, 1000);\n        },\n        [isTransitioning, worlds]\n    );\n\n    const jumpToWorld = useCallback(\n        (index: number) => {\n            if (\n                isTransitioning ||\n                !worlds ||\n                worlds.length === 0 ||\n                index === currentWorldIndex\n            ) {\n                return;\n            }\n\n            setIsTransitioning(true);\n\n            setTimeout(() => {\n                setCurrentWorldIndex(index);\n                setIsTransitioning(false);\n            }, 1000);\n        },\n        [isTransitioning, worlds, currentWorldIndex]\n    );\n\n    const jumpToWorldBySlug = useCallback(\n        (slug: string) => {\n            if (!worlds) return;\n\n            const index = worlds.findIndex(w => w.slug === slug);\n\n            if (index !== -1) {\n                console.log(\n                    \"Jumping to world by slug:\",\n                    slug,\n                    \"at index:\",\n                    index\n                );\n                jumpToWorld(index);\n            }\n        },\n        [worlds, jumpToWorld]\n    );\n\n    return {\n        worlds,\n        isLoading,\n        isError,\n        worldData,\n        currentWorldIndex,\n        isTransitioning,\n        changeWorld,\n        jumpToWorld,\n        jumpToWorldBySlug,\n        initialWorld,\n    };\n};\n\nexport const useWorldBySlug = (slug: string) => {\n    return useQuery<World | null>({\n        queryKey: [\"world\", slug],\n        queryFn: () => fetchWorldBySlug(slug),\n        enabled: !!slug,\n    });\n};\n",
        "database/api/README.md": "# Database API Layer - Clean API Integration\n\nThis module integrates the structure and principles from [`ba-calderonmorales/clean-api`](https://github.com/ba-calderonmorales/clean-api) with your database operations, providing a clean, maintainable, and scalable API layer for database-related functionality.\n\n##  Architecture Overview\n\nThe database API layer follows Clean API principles:\n\n```\ndatabase/\n api/                           # Clean API integration layer\n    index.ts                  # Main exports\n    config.ts                 # API configuration and clients\n    clients/                  # API client implementations\n       edge-function-client.ts      # Supabase Edge Functions\n       supabase-rest-client.ts      # Direct Supabase REST API\n       logging-client.ts            # Database logging operations\n       github-integration-client.ts # GitHub API integration\n    utils/                    # Utility functions\n       api-helpers.ts        # Common API helpers\n       validation.ts         # Input validation\n       error-handling.ts     # Error management\n    examples/                 # Usage examples\n shared/                       # Shared utilities\n supabase/                    # Supabase-specific code\n```\n\n##  Key Features\n\n### Clean API Architecture\n- **API Buckets**: Organized endpoints by functionality (`edge-functions`, `supabase-rest`, `github`)\n- **Configuration Management**: Centralized API configuration with `APIBase`\n- **Swappable Clients**: Easy to test and customize with `APIClient` interface\n- **Type Safety**: Full TypeScript support with comprehensive interfaces\n\n### Enhanced Error Handling\n- **Structured Errors**: Consistent error types and handling\n- **Automatic Logging**: All errors are logged to the database\n- **Retry Mechanisms**: Built-in retry logic with exponential backoff\n- **Validation**: Input validation for all API operations\n\n### Security & Reliability\n- **Input Sanitization**: All inputs are sanitized before processing\n- **Rate Limiting**: Built-in rate limiting for API calls\n- **Security Headers**: Proper security headers for all responses\n- **Authentication**: Integrated with Supabase authentication\n\n##  Quick Start\n\n### Installation\n\nThe database API layer uses the existing `@ba-calderonmorales/clean-api` package:\n\n```bash\nnpm install @ba-calderonmorales/clean-api\n```\n\n### Basic Usage\n\n```typescript\nimport {\n    supabaseEdgeFunctionClient,\n    supabaseRestClient,\n    databaseLoggingClient,\n    githubIntegrationClient\n} from './database/api/index.js';\n\n// Create a GitHub issue via Edge Function\nconst issueData = {\n    issueLocation: 'Scene Component',\n    device: ['Desktop Chrome'],\n    inUS: 'yes',\n    frequency: 'sometimes',\n    expectedBehavior: 'Scene should load smoothly',\n    canContact: 'no'\n};\n\nconst result = await supabaseEdgeFunctionClient.createGithubIssue(issueData, '1.0.0');\n\n// Log an event to the database\nawait databaseLoggingClient.logInfo('User completed tutorial', { \n    userId: 'user123', \n    duration: 300 \n});\n\n// Get logs with filtering\nconst logs = await supabaseRestClient.getLogs({ \n    event_type: 'user_action' \n});\n```\n\n##  Core Components\n\n### 1. Edge Function Client\n\nInteract with Supabase Edge Functions:\n\n```typescript\nimport { supabaseEdgeFunctionClient } from './database/api/index.js';\n\n// Create GitHub issue\nawait supabaseEdgeFunctionClient.createGithubIssue(issueData, appVersion);\n\n// Process logs\nawait supabaseEdgeFunctionClient.processLogs(logData);\n\n// Validate user\nawait supabaseEdgeFunctionClient.validateUser(userData);\n```\n\n### 2. Supabase REST Client\n\nDirect Supabase database operations:\n\n```typescript\nimport { supabaseRestClient } from './database/api/index.js';\n\n// Create log entry\nconst log = await supabaseRestClient.createLog({\n    event_type: 'user_action',\n    event_source: 'client',\n    metadata: { action: 'click', element: 'button' }\n});\n\n// Get logs with filtering\nconst logs = await supabaseRestClient.getLogs({ \n    event_type: 'error' \n});\n\n// Analytics data\nconst analytics = await supabaseRestClient.getAnalytics({\n    date: '2025-01-01'\n});\n```\n\n### 3. Database Logging Client\n\nCentralized logging with automatic database persistence:\n\n```typescript\nimport { databaseLoggingClient } from './database/api/index.js';\n\n// Different log levels\nawait databaseLoggingClient.logError('Something went wrong', { \n    userId: 'user123', \n    error: 'Connection timeout' \n});\n\nawait databaseLoggingClient.logWarning('Performance issue detected', { \n    loadTime: 5000 \n});\n\nawait databaseLoggingClient.logInfo('User logged in', { \n    userId: 'user123' \n});\n\nawait databaseLoggingClient.logDebug('Debug info', { \n    state: currentState \n});\n\n// API call logging\nawait databaseLoggingClient.logApiCall(\n    'POST', \n    '/api/users', \n    requestData, \n    responseData, \n    duration, \n    success\n);\n```\n\n### 4. GitHub Integration Client\n\nDirect GitHub API operations:\n\n```typescript\nimport { githubIntegrationClient } from './database/api/index.js';\n\n// Create GitHub issue\nconst issue = await githubIntegrationClient.createIssue({\n    title: 'Bug Report',\n    body: 'Description of the bug...',\n    labels: ['bug', 'high-priority']\n});\n\n// Get issues\nconst issues = await githubIntegrationClient.getIssues({\n    state: 'open',\n    labels: 'bug'\n});\n\n// Create standardized bug report\nconst bugReport = await githubIntegrationClient.createBugReport({\n    title: 'Scene Loading Issue',\n    location: 'Experience Component',\n    expectedBehavior: 'Scene loads in under 2 seconds',\n    device: ['Desktop Chrome'],\n    frequency: 'always'\n});\n```\n\n##  Validation & Error Handling\n\n### Input Validation\n\n```typescript\nimport { \n    validateIssueData, \n    validateLogEntry, \n    validateGitHubIssueData \n} from './database/api/index.js';\n\n// Validate issue data\nconst validation = validateIssueData(issueData);\nif (!validation.isValid) {\n    console.error('Validation errors:', validation.errors);\n    return;\n}\n```\n\n### Error Handling\n\n```typescript\nimport { \n    withErrorHandling, \n    DatabaseErrorType, \n    type DatabaseError \n} from './database/api/index.js';\n\ntry {\n    const result = await withErrorHandling(\n        () => someApiOperation(),\n        'operation-name',\n        { userId: 'user123' }\n    );\n} catch (error) {\n    const dbError = error as DatabaseError;\n    \n    switch (dbError.type) {\n        case DatabaseErrorType.VALIDATION_ERROR:\n            // Handle validation error\n            break;\n        case DatabaseErrorType.NETWORK_ERROR:\n            // Handle network error\n            break;\n        default:\n            // Handle other errors\n    }\n}\n```\n\n### Retry Mechanisms\n\n```typescript\nimport { withRetry } from './database/api/index.js';\n\nconst result = await withRetry(\n    () => unstableApiCall(),\n    { \n        maxAttempts: 3, \n        delay: 1000, \n        backoffFactor: 2 \n    }\n);\n```\n\n##  Configuration\n\n### Environment Variables\n\n```bash\n# Supabase Configuration\nSUPABASE_URL=https://your-project.supabase.co\nSUPABASE_ANON_KEY=your-anon-key\n\n# GitHub Integration\nGITHUB_REPO=your-username/your-repo\nGITHUB_ACCESS_TOKEN=your-github-token\n```\n\n### Custom Configuration\n\n```typescript\nimport { \n    supabaseEdgeFunctionAPI, \n    supabaseRestAPI, \n    githubIntegrationAPI \n} from './database/api/config.js';\n\n// Add custom routes\nsupabaseEdgeFunctionAPI.addRoute('customFunction', '/custom-function');\n\n// Set custom configuration\nsupabaseRestAPI.setConfig('timeout', 10000);\n\n// Custom headers\ngithubIntegrationAPI.setConfig('headers', {\n    ...githubIntegrationAPI.config.headers,\n    'X-Custom-Header': 'value'\n});\n```\n\n##  Logging & Analytics\n\n### Automatic API Logging\n\n```typescript\nimport { logApiOperation } from './database/api/index.js';\n\n// Automatically log API operations with timing\nconst result = await logApiOperation(\n    'user-authentication',\n    () => authenticateUser(credentials),\n    { method: 'login', userId: 'user123' }\n);\n```\n\n### Bulk Operations\n\n```typescript\n// Example: Process multiple log entries\nconst operations = [\n    { type: 'user_login', data: loginData },\n    { type: 'scene_load', data: sceneData },\n    { type: 'interaction', data: interactionData }\n];\n\nfor (const operation of operations) {\n    try {\n        await supabaseRestClient.createLog({\n            event_type: operation.type,\n            event_source: 'bulk-processor',\n            metadata: operation.data\n        });\n    } catch (error) {\n        await databaseLoggingClient.logError(\n            `Bulk operation failed: ${operation.type}`,\n            { error: error.message }\n        );\n    }\n}\n```\n\n##  Testing\n\nThe integrated system supports easy testing with mocks:\n\n```typescript\n// Test setup\nconst mockClient = {\n    request: jest.fn()\n};\n\n// Mock successful response\nmockClient.request.mockResolvedValue({\n    message: 'Success',\n    data: testData\n});\n\n// Test your functions\nconst result = await yourFunction();\nexpect(result).toEqual(expectedResult);\n```\n\n##  Performance & Monitoring\n\n### Built-in Performance Monitoring\n\nAll API calls are automatically monitored for:\n- **Response Time**: How long each API call takes\n- **Success Rate**: Percentage of successful vs failed calls\n- **Error Types**: Categorization of different error types\n- **Retry Attempts**: How often retries are needed\n\n### Metrics Collection\n\n```typescript\n// Metrics are automatically logged to the database\n// Query them like this:\nconst performanceMetrics = await supabaseRestClient.getLogs({\n    event_source: 'api-client',\n    event_type: 'info'\n});\n\n// Analyze API performance\nconst apiCalls = performanceMetrics.filter(log => \n    log.metadata?.duration && log.metadata?.success !== undefined\n);\n```\n\n##  Integration with Existing Code\n\n### Client API Integration\n\nYour existing client API can seamlessly use the database API:\n\n```typescript\n// client/api/clients/database-client.ts\nimport { \n    supabaseEdgeFunctionClient,\n    databaseLoggingClient \n} from '../../../database/api/index.js';\n\nexport class ClientDatabaseAPI {\n    async reportIssue(issueData: IssueData) {\n        try {\n            const result = await supabaseEdgeFunctionClient.createGithubIssue(\n                issueData, \n                process.env.APP_VERSION\n            );\n            \n            await databaseLoggingClient.logInfo('Issue reported successfully', {\n                issueUrl: result.data?.issue?.html_url\n            });\n            \n            return result;\n        } catch (error) {\n            await databaseLoggingClient.logError('Failed to report issue', {\n                error: error.message,\n                issueData: issueData.issueLocation\n            });\n            throw error;\n        }\n    }\n}\n```\n\n### Server Integration\n\nYour server can use the same API layer:\n\n```typescript\n// server/api/database.ts\nimport { \n    supabaseRestClient,\n    databaseLoggingClient,\n    withErrorHandling \n} from '../../database/api/index.js';\n\nexport async function getServerLogs(filters: any) {\n    return withErrorHandling(\n        () => supabaseRestClient.getLogs(filters),\n        'get-server-logs',\n        { source: 'server', filters }\n    );\n}\n```\n\n##  Examples\n\nSee the `database/api/examples/` directory for comprehensive usage examples including:\n\n- **usage-examples.ts**: Practical examples for all major operations\n- **enhanced-github-issue-edge-function.ts**: Enhanced edge function implementation\n\n##  Future Enhancements\n\nThe integrated structure enables easy extension:\n\n1. **Additional API Clients**: Add new clients for other services\n2. **Advanced Caching**: Implement caching layers using the same patterns\n3. **Real-time Features**: Add WebSocket support using clean-api structure\n4. **Analytics Dashboard**: Build analytics using the logged data\n5. **Performance Optimization**: Add request batching and connection pooling\n\n##  Migration Guide\n\nTo migrate existing code to use the integrated system:\n\n1. **Replace direct API calls** with the corresponding client methods\n2. **Add validation** using the provided validation functions\n3. **Wrap operations** with error handling utilities\n4. **Update imports** to use the centralized database API exports\n\n### Before:\n```typescript\nconst response = await fetch('/api/logs', {\n    method: 'POST',\n    body: JSON.stringify(logData)\n});\n```\n\n### After:\n```typescript\nimport { supabaseRestClient } from './database/api/index.js';\n\nconst log = await supabaseRestClient.createLog(logData);\n```\n\nThis integration provides a robust, scalable, and maintainable foundation for all your database API operations while maintaining consistency with clean-api principles.\n",
        "docs/README.md": "# Immersive AWE Canvas Documentation\n\n## Overview\n\nWelcome to the documentation for the Immersive AWE Canvas project. This documentation provides comprehensive information about the project's architecture, modules, and usage.\n\n## Directory Structure\n\n- `modules/`: Detailed documentation for individual modules\n- `guides/`: User and developer guides\n- `api-reference/`: Detailed API documentation\n- `architecture/`: System design and architectural documents\n\n## Quick Links\n\n- [Architecture Overview](./architecture.md) - System design and architectural principles\n- [Server API Module](./modules/server-api.md) - Layered API architecture documentation\n- [Server API Reference](./api-reference/server-api.md) - Complete API reference\n- [Module Documentation](./modules/README.md) - Individual module guides\n- [API Reference](./api-reference/README.md) - Detailed API documentation\n- [Developer Guides](./guides/README.md) - Development and contribution guides\n\n## Contributing\n\nPlease read our [Contributing Guidelines](../CONTRIBUTING.md) before making contributions to the documentation.\n\n## License\n\nThis project is licensed under the terms specified in the [LICENSE](../LICENSE) file.",
        "docs/api-reference/README.md": "# API Reference Documentation\n\nThis directory contains detailed API reference documentation for all project modules.\n\n## Available APIs\n\n- [Server API Reference](./server-api.md) - Complete reference for the layered server API\n\n## Documentation Format\n\nEach API reference includes:\n- Complete method signatures and parameters\n- Return types and response formats\n- Usage examples for each endpoint\n- Error handling patterns\n- Type definitions and interfaces\n\n## Quick Navigation\n\n### Controllers\n- [VersionController](./server-api.md#versioncontroller) - Version management endpoints\n- [LoggingController](./server-api.md#loggingcontroller) - Event logging endpoints\n\n### Services  \n- [VersionService](./server-api.md#versionservice) - Version business logic\n- [LoggingService](./server-api.md#loggingservice) - Logging business logic\n\n### Clients\n- [GitHubAPIClient](./server-api.md#githubapiclient) - GitHub API integration\n- [SupabaseAPIClient](./server-api.md#supabaseapiclient) - Database operations\n\n## Navigation\n\n- [Back to Main Documentation](../README.md)\n- [Architecture Overview](../architecture.md)\n- [Module Documentation](../modules/README.md)\n",
        "docs/archive/memory/agents/MEMORY.md": "# Development Guidelines for All LLMs/agents\n\n## Core Philosophy\n\n**TEST-DRIVEN DEVELOPMENT IS NON-NEGOTIABLE.** Every single line of production code must be written in response to a failing test. No exceptions. This is not a suggestion or a preference - it is the fundamental practice that enables all other principles in this document.\n\nI follow Test-Driven Development (TDD) with a strong emphasis on behavior-driven testing and functional programming principles. All work should be done in small, incremental changes that maintain a working state throughout development.\n\n## Quick Reference\n\n**Key Principles:**\n\n- Write tests first (TDD)\n- Test behavior, not implementation\n- No `any` types or type assertions\n- Immutable data only\n- Small, pure functions\n- TypeScript strict mode always\n- Use real schemas/types in tests, never redefine them\n\n**Preferred Tools:**\n\n- **Language**: TypeScript (strict mode)\n- **Testing**: Vitest + React Testing Library\n- **State Management**: Prefer immutable patterns\n- **Package Manager/Runtime**: Bun (for install, run, test, and build)\n- **Version Management**: Semantic-release with conventional commits\n\n## Version Management & Release Process\n\n### Critical Version Management Rules\n\n**AUTOMATED VERSIONING ONLY**: Never manually bump versions. All versioning is handled by semantic-release based on conventional commits.\n\n**CONVENTIONAL COMMITS ARE MANDATORY**: Every commit must follow conventional commit format:\n\n**PATCH** version bumps (0.0.1  0.0.2):\n\n- `chore:`  maintenance and tooling changes\n- `perf:`  performance improvements\n- `docs:`  documentation updates\n- `style:`  code formatting and style changes\n- `test:`  test additions and improvements\n- `hotfix:`  emergency bug fixes\n\n**MINOR** version bumps (0.0.1  0.1.0):\n\n- `fix:`  bug fixes and corrections\n- `feat:`  new features and functionality\n\n**MAJOR** version bumps (0.1.0  1.0.0):\n\n- `breaking:`  breaking changes\n- `refactor:`  code restructuring (potentially breaking)\n\n### Version Reset Protocol\n\n**When version reset is needed** (e.g., premature v1.0.0 release):\n\n1. **Delete GitHub releases**: `gh release delete vX.X.X --yes`\n2. **Delete local git tags**: `git tag -d vX.X.X`\n3. **Delete remote git tags**: `git push origin --delete vX.X.X`\n4. **Create trigger commit**: `git commit --allow-empty -m \"feat: initialize project at vX.X.X\"`\n5. **Push to trigger workflow**: `git push`\n\n### CI/CD Workflow Requirements\n\n**CRITICAL**: Always use `bun run test` in GitHub Actions, never `bun test` directly:\n\n- `bun test` uses Bun's built-in test runner (incompatible with Vitest syntax)\n- `bun run test` uses the npm script which runs Vitest properly\n- Test files use Vitest syntax (`vi.mock`, `vi.fn()`) which requires Vitest runner\n\n**Workflow Files**:\n\n- `semantic-release.yml`: Automated releases on main branch push\n- `manage-releases.yml`: Manual release/tag deletion for version resets\n\n### Version Monitoring Commands\n\n```bash\n# Check current state\ngh release list\ngit tag -l\n\n# Monitor workflows\ngh run list --workflow=semantic-release.yml\ngh run watch\n\n# Trigger manual release management\ngh workflow run manage-releases.yml --field action=delete-tag --field tag=vX.X.X\n```\n\n## Testing Principles\n\n### Behavior-Driven Testing\n\n- **No \"unit tests\"** - this term is not helpful. Tests should verify expected behavior, treating implementation as a black box\n- Test through the public API exclusively - internals should be invisible to tests\n- No 1:1 mapping between test files and implementation files\n- Tests that examine internal implementation details are wasteful and should be avoided\n- **Coverage targets**: 100% coverage should be expected at all times, but these tests must ALWAYS be based on business behaviour, not implementation details\n- Tests must document expected business behaviour\n\n### Testing Tools\n\n- **Vitest** for testing framework\n- **React Testing Library** for React components\n- **MSW (Mock Service Worker)** for API mocking when needed\n- All test code must follow the same TypeScript strict mode rules as production code\n\n### Test Organization\n\n```\nsrc/\n  features/\n    payment/\n      payment-processor.ts\n      payment-validator.ts\n      payment-processor.test.ts // The validator is an implementation detail. Validation is fully covered, but by testing the expected business behaviour, treating the validation code itself as an implementation detail\n```\n\n### Test Data Pattern\n\nUse factory functions with optional overrides for test data:\n\n```typescript\nconst getMockPaymentPostPaymentRequest = (\n    overrides?: Partial<PostPaymentsRequestV3>\n): PostPaymentsRequestV3 => {\n    return {\n        CardAccountId: \"1234567890123456\",\n        Amount: 100,\n        Source: \"Web\",\n        AccountStatus: \"Normal\",\n        LastName: \"Doe\",\n        DateOfBirth: \"1980-01-01\",\n        PayingCardDetails: {\n            Cvv: \"123\",\n            Token: \"token\",\n        },\n        AddressDetails: getMockAddressDetails(),\n        Brand: \"Visa\",\n        ...overrides,\n    };\n};\n\nconst getMockAddressDetails = (\n    overrides?: Partial<AddressDetails>\n): AddressDetails => {\n    return {\n        HouseNumber: \"123\",\n        HouseName: \"Test House\",\n        AddressLine1: \"Test Address Line 1\",\n        AddressLine2: \"Test Address Line 2\",\n        City: \"Test City\",\n        ...overrides,\n    };\n};\n```\n\nKey principles:\n\n- Always return complete objects with sensible defaults\n- Accept optional `Partial<T>` overrides\n- Build incrementally - extract nested object factories as needed\n- Compose factories for complex objects\n- Consider using a test data builder pattern for very complex objects\n\n## TypeScript Guidelines\n\n### Strict Mode Requirements\n\n```json\n// tsconfig.json\n{\n    \"compilerOptions\": {\n        \"strict\": true,\n        \"noImplicitAny\": true,\n        \"strictNullChecks\": true,\n        \"strictFunctionTypes\": true,\n        \"strictBindCallApply\": true,\n        \"strictPropertyInitialization\": true,\n        \"noImplicitThis\": true,\n        \"alwaysStrict\": true,\n        \"noUnusedLocals\": true,\n        \"noUnusedParameters\": true,\n        \"noImplicitReturns\": true,\n        \"noFallthroughCasesInSwitch\": true\n    }\n}\n```\n\n- **No `any`** - ever. Use `unknown` if type is truly unknown\n- **No type assertions** (`as SomeType`) unless absolutely necessary with clear justification\n- **No `@ts-ignore`** or `@ts-expect-error` without explicit explanation\n- These rules apply to test code as well as production code\n\n### Type Definitions\n\n- **Prefer `type` over `interface`** in all cases\n- Use explicit typing where it aids clarity, but leverage inference where appropriate\n- Utilize utility types effectively (`Pick`, `Omit`, `Partial`, `Required`, etc.)\n- Create domain-specific types (e.g., `UserId`, `PaymentId`) for type safety\n- Use Zod or any other [Standard Schema](https://standardschema.dev/) compliant schema library to create types, by creating schemas first\n\n```typescript\n// Good\ntype UserId = string & { readonly brand: unique symbol };\ntype PaymentAmount = number & { readonly brand: unique symbol };\n\n// Avoid\ntype UserId = string;\ntype PaymentAmount = number;\n```\n\n#### Schema-First Development with Zod\n\nAlways define your schemas first, then derive types from them:\n\n```typescript\nimport { z } from \"zod\";\n\n// Define schemas first - these provide runtime validation\nconst AddressDetailsSchema = z.object({\n    houseNumber: z.string(),\n    houseName: z.string().optional(),\n    addressLine1: z.string().min(1),\n    addressLine2: z.string().optional(),\n    city: z.string().min(1),\n    postcode: z.string().regex(/^[A-Z]{1,2}\\d[A-Z\\d]? ?\\d[A-Z]{2}$/i),\n});\n\nconst PayingCardDetailsSchema = z.object({\n    cvv: z.string().regex(/^\\d{3,4}$/),\n    token: z.string().min(1),\n});\n\nconst PostPaymentsRequestV3Schema = z.object({\n    cardAccountId: z.string().length(16),\n    amount: z.number().positive(),\n    source: z.enum([\"Web\", \"Mobile\", \"API\"]),\n    accountStatus: z.enum([\"Normal\", \"Restricted\", \"Closed\"]),\n    lastName: z.string().min(1),\n    dateOfBirth: z.string().regex(/^\\d{4}-\\d{2}-\\d{2}$/),\n    payingCardDetails: PayingCardDetailsSchema,\n    addressDetails: AddressDetailsSchema,\n    brand: z.enum([\"Visa\", \"Mastercard\", \"Amex\"]),\n});\n\n// Derive types from schemas\ntype AddressDetails = z.infer<typeof AddressDetailsSchema>;\ntype PayingCardDetails = z.infer<typeof PayingCardDetailsSchema>;\ntype PostPaymentsRequestV3 = z.infer<typeof PostPaymentsRequestV3Schema>;\n\n// Use schemas at runtime boundaries\nexport const parsePaymentRequest = (data: unknown): PostPaymentsRequestV3 => {\n    return PostPaymentsRequestV3Schema.parse(data);\n};\n\n// Example of schema composition for complex domains\nconst BaseEntitySchema = z.object({\n    id: z.string().uuid(),\n    createdAt: z.date(),\n    updatedAt: z.date(),\n});\n\nconst CustomerSchema = BaseEntitySchema.extend({\n    email: z.string().email(),\n    tier: z.enum([\"standard\", \"premium\", \"enterprise\"]),\n    creditLimit: z.number().positive(),\n});\n\ntype Customer = z.infer<typeof CustomerSchema>;\n```\n\n#### Schema Usage in Tests\n\n**CRITICAL**: Tests must use real schemas and types from the main project, not redefine their own.\n\n```typescript\n//  WRONG - Defining schemas in test files\nconst ProjectSchema = z.object({\n    id: z.string(),\n    workspaceId: z.string(),\n    ownerId: z.string().nullable(),\n    name: z.string(),\n    createdAt: z.coerce.date(),\n    updatedAt: z.coerce.date(),\n});\n\n//  CORRECT - Import schemas from the shared schema package\nimport { ProjectSchema, type Project } from \"@your-org/schemas\";\n```\n\n**Why this matters:**\n\n- **Type Safety**: Ensures tests use the same types as production code\n- **Consistency**: Changes to schemas automatically propagate to tests\n- **Maintainability**: Single source of truth for data structures\n- **Prevents Drift**: Tests can't accidentally diverge from real schemas\n\n**Implementation:**\n\n- All domain schemas should be exported from a shared schema package or module\n- Test files should import schemas from the shared location\n- If a schema isn't exported yet, add it to the exports rather than duplicating it\n- Mock data factories should use the real types derived from real schemas\n\n```typescript\n//  CORRECT - Test factories using real schemas\nimport { ProjectSchema, type Project } from \"@your-org/schemas\";\n\nconst getMockProject = (overrides?: Partial<Project>): Project => {\n    const baseProject = {\n        id: \"proj_123\",\n        workspaceId: \"ws_456\",\n        ownerId: \"user_789\",\n        name: \"Test Project\",\n        createdAt: new Date(),\n        updatedAt: new Date(),\n    };\n\n    const projectData = { ...baseProject, ...overrides };\n\n    // Validate against real schema to catch type mismatches\n    return ProjectSchema.parse(projectData);\n};\n```\n\n## Code Style\n\n### Functional Programming\n\nI follow a \"functional light\" approach:\n\n- **No data mutation** - work with immutable data structures\n- **Pure functions** wherever possible\n- **Composition** as the primary mechanism for code reuse\n- Avoid heavy FP abstractions (no need for complex monads or pipe/compose patterns) unless there is a clear advantage to using them\n- Use array methods (`map`, `filter`, `reduce`) over imperative loops\n\n#### Examples of Functional Patterns\n\n```typescript\n// Good - Pure function with immutable updates\nconst applyDiscount = (order: Order, discountPercent: number): Order => {\n    return {\n        ...order,\n        items: order.items.map(item => ({\n            ...item,\n            price: item.price * (1 - discountPercent / 100),\n        })),\n        totalPrice: order.items.reduce(\n            (sum, item) => sum + item.price * (1 - discountPercent / 100),\n            0\n        ),\n    };\n};\n\n// Good - Composition over complex logic\nconst processOrder = (order: Order): ProcessedOrder => {\n    return pipe(\n        order,\n        validateOrder,\n        applyPromotions,\n        calculateTax,\n        assignWarehouse\n    );\n};\n\n// When heavy FP abstractions ARE appropriate:\n// - Complex async flows that benefit from Task/IO types\n// - Error handling chains that benefit from Result/Either types\n// Example with Result type for complex error handling:\ntype Result<T, E = Error> =\n    | { success: true; data: T }\n    | { success: false; error: E };\n\nconst chainPaymentOperations = (\n    payment: Payment\n): Result<Receipt, PaymentError> => {\n    return pipe(\n        validatePayment(payment),\n        chain(authorizePayment),\n        chain(capturePayment),\n        map(generateReceipt)\n    );\n};\n```\n\n### Code Structure\n\n- **No nested if/else statements** - use early returns, guard clauses, or composition\n- **Avoid deep nesting** in general (max 2 levels)\n- Keep functions small and focused on a single responsibility\n- Prefer flat, readable code over clever abstractions\n\n### Naming Conventions\n\n- **Functions**: `camelCase`, verb-based (e.g., `calculateTotal`, `validatePayment`)\n- **Types**: `PascalCase` (e.g., `PaymentRequest`, `UserProfile`)\n- **Constants**: `UPPER_SNAKE_CASE` for true constants, `camelCase` for configuration\n- **Files**: `kebab-case.ts` for all TypeScript files\n- **Test files**: `*.test.ts` or `*.spec.ts`\n\n### No Comments in Code\n\nCode should be self-documenting through clear naming and structure. Comments indicate that the code itself is not clear enough.\n\n```typescript\n// Avoid: Comments explaining what the code does\nconst calculateDiscount = (price: number, customer: Customer): number => {\n    // Check if customer is premium\n    if (customer.tier === \"premium\") {\n        // Apply 20% discount for premium customers\n        return price * 0.8;\n    }\n    // Regular customers get 10% discount\n    return price * 0.9;\n};\n\n// Good: Self-documenting code with clear names\nconst PREMIUM_DISCOUNT_MULTIPLIER = 0.8;\nconst STANDARD_DISCOUNT_MULTIPLIER = 0.9;\n\nconst isPremiumCustomer = (customer: Customer): boolean => {\n    return customer.tier === \"premium\";\n};\n\nconst calculateDiscount = (price: number, customer: Customer): number => {\n    const discountMultiplier = isPremiumCustomer(customer)\n        ? PREMIUM_DISCOUNT_MULTIPLIER\n        : STANDARD_DISCOUNT_MULTIPLIER;\n\n    return price * discountMultiplier;\n};\n\n// Avoid: Complex logic with comments\nconst processPayment = (payment: Payment): ProcessedPayment => {\n    // First validate the payment\n    if (!validatePayment(payment)) {\n        throw new Error(\"Invalid payment\");\n    }\n\n    // Check if we need to apply 3D secure\n    if (payment.amount > 100 && payment.card.type === \"credit\") {\n        // Apply 3D secure for credit cards over 100\n        const securePayment = apply3DSecure(payment);\n        // Process the secure payment\n        return executePayment(securePayment);\n    }\n\n    // Process the payment\n    return executePayment(payment);\n};\n\n// Good: Extract to well-named functions\nconst requires3DSecure = (payment: Payment): boolean => {\n    const SECURE_PAYMENT_THRESHOLD = 100;\n    return (\n        payment.amount > SECURE_PAYMENT_THRESHOLD &&\n        payment.card.type === \"credit\"\n    );\n};\n\nconst processPayment = (payment: Payment): ProcessedPayment => {\n    if (!validatePayment(payment)) {\n        throw new PaymentValidationError(\"Invalid payment\");\n    }\n\n    const securedPayment = requires3DSecure(payment)\n        ? apply3DSecure(payment)\n        : payment;\n\n    return executePayment(securedPayment);\n};\n```\n\n**Exception**: JSDoc comments for public APIs are acceptable when generating documentation, but the code should still be self-explanatory without them.\n\n### Prefer Options Objects\n\nUse options objects for function parameters as the default pattern. Only use positional parameters when there's a clear, compelling reason (e.g., single-parameter pure functions, well-established conventions like `map(item => item.value)`).\n\n```typescript\n// Avoid: Multiple positional parameters\nconst createPayment = (\n    amount: number,\n    currency: string,\n    cardId: string,\n    customerId: string,\n    description?: string,\n    metadata?: Record<string, unknown>,\n    idempotencyKey?: string\n): Payment => {\n    // implementation\n};\n\n// Calling it is unclear\nconst payment = createPayment(\n    100,\n    \"GBP\",\n    \"card_123\",\n    \"cust_456\",\n    undefined,\n    { orderId: \"order_789\" },\n    \"key_123\"\n);\n\n// Good: Options object with clear property names\ntype CreatePaymentOptions = {\n    amount: number;\n    currency: string;\n    cardId: string;\n    customerId: string;\n    description?: string;\n    metadata?: Record<string, unknown>;\n    idempotencyKey?: string;\n};\n\nconst createPayment = (options: CreatePaymentOptions): Payment => {\n    const {\n        amount,\n        currency,\n        cardId,\n        customerId,\n        description,\n        metadata,\n        idempotencyKey,\n    } = options;\n\n    // implementation\n};\n\n// Clear and readable at call site\nconst payment = createPayment({\n    amount: 100,\n    currency: \"GBP\",\n    cardId: \"card_123\",\n    customerId: \"cust_456\",\n    metadata: { orderId: \"order_789\" },\n    idempotencyKey: \"key_123\",\n});\n\n// Avoid: Boolean flags as parameters\nconst fetchCustomers = (\n    includeInactive: boolean,\n    includePending: boolean,\n    includeDeleted: boolean,\n    sortByDate: boolean\n): Customer[] => {\n    // implementation\n};\n\n// Confusing at call site\nconst customers = fetchCustomers(true, false, false, true);\n\n// Good: Options object with clear intent\ntype FetchCustomersOptions = {\n    includeInactive?: boolean;\n    includePending?: boolean;\n    includeDeleted?: boolean;\n    sortBy?: \"date\" | \"name\" | \"value\";\n};\n\nconst fetchCustomers = (options: FetchCustomersOptions = {}): Customer[] => {\n    const {\n        includeInactive = false,\n        includePending = false,\n        includeDeleted = false,\n        sortBy = \"name\",\n    } = options;\n\n    // implementation\n};\n\n// Self-documenting at call site\nconst customers = fetchCustomers({\n    includeInactive: true,\n    sortBy: \"date\",\n});\n\n// Good: Configuration objects for complex operations\ntype ProcessOrderOptions = {\n    order: Order;\n    shipping: {\n        method: \"standard\" | \"express\" | \"overnight\";\n        address: Address;\n    };\n    payment: {\n        method: PaymentMethod;\n        saveForFuture?: boolean;\n    };\n    promotions?: {\n        codes?: string[];\n        autoApply?: boolean;\n    };\n};\n\nconst processOrder = (options: ProcessOrderOptions): ProcessedOrder => {\n    const { order, shipping, payment, promotions = {} } = options;\n\n    // Clear access to nested options\n    const orderWithPromotions = promotions.autoApply\n        ? applyAvailablePromotions(order)\n        : order;\n\n    return executeOrder({\n        ...orderWithPromotions,\n        shippingMethod: shipping.method,\n        paymentMethod: payment.method,\n    });\n};\n\n// Acceptable: Single parameter for simple transforms\nconst double = (n: number): number => n * 2;\nconst getName = (user: User): string => user.name;\n\n// Acceptable: Well-established patterns\nconst numbers = [1, 2, 3];\nconst doubled = numbers.map(n => n * 2);\nconst users = fetchUsers();\nconst names = users.map(user => user.name);\n```\n\n**Guidelines for options objects:**\n\n- Default to options objects unless there's a specific reason not to\n- Always use for functions with optional parameters\n- Destructure options at the start of the function for clarity\n- Provide sensible defaults using destructuring\n- Keep related options grouped (e.g., all shipping options together)\n- Consider breaking very large options objects into nested groups\n\n**When positional parameters are acceptable:**\n\n- Single-parameter pure functions\n- Well-established functional patterns (map, filter, reduce callbacks)\n- Mathematical operations where order is conventional\n\n## Development Workflow\n\n### TDD Process - THE FUNDAMENTAL PRACTICE\n\n**CRITICAL**: TDD is not optional. Every feature, every bug fix, every change MUST follow this process:\n\nFollow Red-Green-Refactor strictly:\n\n1. **Red**: Write a failing test for the desired behavior. NO PRODUCTION CODE until you have a failing test.\n2. **Green**: Write the MINIMUM code to make the test pass. Resist the urge to write more than needed.\n3. **Refactor**: Assess the code for improvement opportunities. If refactoring would add value, clean up the code while keeping tests green. If the code is already clean and expressive, move on.\n\n**Common TDD Violations to Avoid:**\n\n- Writing production code without a failing test first\n- Writing multiple tests before making the first one pass\n- Writing more production code than needed to pass the current test\n- Skipping the refactor assessment step when code could be improved\n- Adding functionality \"while you're there\" without a test driving it\n\n**Remember**: If you're typing production code and there isn't a failing test demanding that code, you're not doing TDD.\n\n#### TDD Example Workflow\n\n```typescript\n// Step 1: Red - Start with the simplest behavior\ndescribe(\"Order processing\", () => {\n    it(\"should calculate total with shipping cost\", () => {\n        const order = createOrder({\n            items: [{ price: 30, quantity: 1 }],\n            shippingCost: 5.99,\n        });\n\n        const processed = processOrder(order);\n\n        expect(processed.total).toBe(35.99);\n        expect(processed.shippingCost).toBe(5.99);\n    });\n});\n\n// Step 2: Green - Minimal implementation\nconst processOrder = (order: Order): ProcessedOrder => {\n    const itemsTotal = order.items.reduce(\n        (sum, item) => sum + item.price * item.quantity,\n        0\n    );\n\n    return {\n        ...order,\n        shippingCost: order.shippingCost,\n        total: itemsTotal + order.shippingCost,\n    };\n};\n\n// Step 3: Red - Add test for free shipping behavior\ndescribe(\"Order processing\", () => {\n    it(\"should calculate total with shipping cost\", () => {\n        // ... existing test\n    });\n\n    it(\"should apply free shipping for orders over \\u00a350\", () => {\n        const order = createOrder({\n            items: [{ price: 60, quantity: 1 }],\n            shippingCost: 5.99,\n        });\n\n        const processed = processOrder(order);\n\n        expect(processed.shippingCost).toBe(0);\n        expect(processed.total).toBe(60);\n    });\n});\n\n// Step 4: Green - NOW we can add the conditional because both paths are tested\nconst processOrder = (order: Order): ProcessedOrder => {\n    const itemsTotal = order.items.reduce(\n        (sum, item) => sum + item.price * item.quantity,\n        0\n    );\n\n    const shippingCost = itemsTotal > 50 ? 0 : order.shippingCost;\n\n    return {\n        ...order,\n        shippingCost,\n        total: itemsTotal + shippingCost,\n    };\n};\n\n// Step 5: Add edge case tests to ensure 100% behavior coverage\ndescribe(\"Order processing\", () => {\n    // ... existing tests\n\n    it(\"should charge shipping for orders exactly at \\u00a350\", () => {\n        const order = createOrder({\n            items: [{ price: 50, quantity: 1 }],\n            shippingCost: 5.99,\n        });\n\n        const processed = processOrder(order);\n\n        expect(processed.shippingCost).toBe(5.99);\n        expect(processed.total).toBe(55.99);\n    });\n});\n\n// Step 6: Refactor - Extract constants and improve readability\nconst FREE_SHIPPING_THRESHOLD = 50;\n\nconst calculateItemsTotal = (items: OrderItem[]): number => {\n    return items.reduce((sum, item) => sum + item.price * item.quantity, 0);\n};\n\nconst qualifiesForFreeShipping = (itemsTotal: number): boolean => {\n    return itemsTotal > FREE_SHIPPING_THRESHOLD;\n};\n\nconst processOrder = (order: Order): ProcessedOrder => {\n    const itemsTotal = calculateItemsTotal(order.items);\n    const shippingCost = qualifiesForFreeShipping(itemsTotal)\n        ? 0\n        : order.shippingCost;\n\n    return {\n        ...order,\n        shippingCost,\n        total: itemsTotal + shippingCost,\n    };\n};\n```\n\n### Refactoring - The Critical Third Step\n\nEvaluating refactoring opportunities is not optional - it's the third step in the TDD cycle. After achieving a green state and committing your work, you MUST assess whether the code can be improved. However, only refactor if there's clear value - if the code is already clean and expresses intent well, move on to the next test.\n\n#### What is Refactoring?\n\nRefactoring means changing the internal structure of code without changing its external behavior. The public API remains unchanged, all tests continue to pass, but the code becomes cleaner, more maintainable, or more efficient. Remember: only refactor when it genuinely improves the code - not all code needs refactoring.\n\n#### When to Refactor\n\n- **Always assess after green**: Once tests pass, before moving to the next test, evaluate if refactoring would add value\n- **When you see duplication**: But understand what duplication really means (see DRY below)\n- **When names could be clearer**: Variable names, function names, or type names that don't clearly express intent\n- **When structure could be simpler**: Complex conditional logic, deeply nested code, or long functions\n- **When patterns emerge**: After implementing several similar features, useful abstractions may become apparent\n\n**Remember**: Not all code needs refactoring. If the code is already clean, expressive, and well-structured, commit and move on.\n\n#### Refactoring Guidelines\n\n##### 1. Commit Before Refactoring\n\nAlways commit your working code before starting any refactoring. This gives you a safe point to return to:\n\n```bash\ngit add .\ngit commit -m \"feat: add payment validation\"\n# Now safe to refactor\n```\n\n##### 2. Look for Useful Abstractions Based on Semantic Meaning\n\nCreate abstractions only when code shares the same semantic meaning and purpose. Don't abstract based on structural similarity alone - **duplicate code is far cheaper than the wrong abstraction**.\n\n```typescript\n// Similar structure, DIFFERENT semantic meaning - DO NOT ABSTRACT\nconst validatePaymentAmount = (amount: number): boolean => {\n    return amount > 0 && amount <= 10000;\n};\n\nconst validateTransferAmount = (amount: number): boolean => {\n    return amount > 0 && amount <= 10000;\n};\n\n// These might have the same structure today, but they represent different\n// business concepts that will likely evolve independently.\n// Payment limits might change based on fraud rules.\n// Transfer limits might change based on account type.\n// Abstracting them couples unrelated business rules.\n\n// Similar structure, SAME semantic meaning - SAFE TO ABSTRACT\nconst formatUserDisplayName = (firstName: string, lastName: string): string => {\n    return `${firstName} ${lastName}`.trim();\n};\n\nconst formatCustomerDisplayName = (\n    firstName: string,\n    lastName: string\n): string => {\n    return `${firstName} ${lastName}`.trim();\n};\n\nconst formatEmployeeDisplayName = (\n    firstName: string,\n    lastName: string\n): string => {\n    return `${firstName} ${lastName}`.trim();\n};\n\n// These all represent the same concept: \"how we format a person's name for display\"\n// They share semantic meaning, not just structure\nconst formatPersonDisplayName = (\n    firstName: string,\n    lastName: string\n): string => {\n    return `${firstName} ${lastName}`.trim();\n};\n\n// Replace all call sites throughout the codebase:\n// Before:\n// const userLabel = formatUserDisplayName(user.firstName, user.lastName);\n// const customerName = formatCustomerDisplayName(customer.firstName, customer.lastName);\n// const employeeTag = formatEmployeeDisplayName(employee.firstName, employee.lastName);\n\n// After:\n// const userLabel = formatPersonDisplayName(user.firstName, user.lastName);\n// const customerName = formatPersonDisplayName(customer.firstName, customer.lastName);\n// const employeeTag = formatPersonDisplayName(employee.firstName, employee.lastName);\n\n// Then remove the original functions as they're no longer needed\n```\n\n**Questions to ask before abstracting:**\n\n- Do these code blocks represent the same concept or different concepts that happen to look similar?\n- If the business rules for one change, should the others change too?\n- Would a developer reading this abstraction understand why these things are grouped together?\n- Am I abstracting based on what the code IS (structure) or what it MEANS (semantics)?\n\n**Remember**: It's much easier to create an abstraction later when the semantic relationship becomes clear than to undo a bad abstraction that couples unrelated concepts.\n\n##### 3. Understanding DRY - It's About Knowledge, Not Code\n\nDRY (Don't Repeat Yourself) is about not duplicating **knowledge** in the system, not about eliminating all code that looks similar.\n\n```typescript\n// This is NOT a DRY violation - different knowledge despite similar code\nconst validateUserAge = (age: number): boolean => {\n    return age >= 18 && age <= 100;\n};\n\nconst validateProductRating = (rating: number): boolean => {\n    return rating >= 1 && rating <= 5;\n};\n\nconst validateYearsOfExperience = (years: number): boolean => {\n    return years >= 0 && years <= 50;\n};\n\n// These functions have similar structure (checking numeric ranges), but they\n// represent completely different business rules:\n// - User age has legal requirements (18+) and practical limits (100)\n// - Product ratings follow a 1-5 star system\n// - Years of experience starts at 0 with a reasonable upper bound\n// Abstracting them would couple unrelated business concepts and make future\n// changes harder. What if ratings change to 1-10? What if legal age changes?\n\n// Another example of code that looks similar but represents different knowledge:\nconst formatUserDisplayName = (user: User): string => {\n    return `${user.firstName} ${user.lastName}`.trim();\n};\n\nconst formatAddressLine = (address: Address): string => {\n    return `${address.street} ${address.number}`.trim();\n};\n\nconst formatCreditCardLabel = (card: CreditCard): string => {\n    return `${card.type} ${card.lastFourDigits}`.trim();\n};\n\n// Despite the pattern \"combine two strings with space and trim\", these represent\n// different domain concepts with different future evolution paths\n\n// This IS a DRY violation - same knowledge in multiple places\nclass Order {\n    calculateTotal(): number {\n        const itemsTotal = this.items.reduce(\n            (sum, item) => sum + item.price,\n            0\n        );\n        const shippingCost = itemsTotal > 50 ? 0 : 5.99; // Knowledge duplicated!\n        return itemsTotal + shippingCost;\n    }\n}\n\nclass OrderSummary {\n    getShippingCost(itemsTotal: number): number {\n        return itemsTotal > 50 ? 0 : 5.99; // Same knowledge!\n    }\n}\n\nclass ShippingCalculator {\n    calculate(orderAmount: number): number {\n        if (orderAmount > 50) return 0; // Same knowledge again!\n        return 5.99;\n    }\n}\n\n// Refactored - knowledge in one place\nconst FREE_SHIPPING_THRESHOLD = 50;\nconst STANDARD_SHIPPING_COST = 5.99;\n\nconst calculateShippingCost = (itemsTotal: number): number => {\n    return itemsTotal > FREE_SHIPPING_THRESHOLD ? 0 : STANDARD_SHIPPING_COST;\n};\n\n// Now all classes use the single source of truth\nclass Order {\n    calculateTotal(): number {\n        const itemsTotal = this.items.reduce(\n            (sum, item) => sum + item.price,\n            0\n        );\n        return itemsTotal + calculateShippingCost(itemsTotal);\n    }\n}\n```\n\n##### 4. Maintain External APIs During Refactoring\n\nRefactoring must never break existing consumers of your code:\n\n```typescript\n// Original implementation\nexport const processPayment = (payment: Payment): ProcessedPayment => {\n    // Complex logic all in one function\n    if (payment.amount <= 0) {\n        throw new Error(\"Invalid amount\");\n    }\n\n    if (payment.amount > 10000) {\n        throw new Error(\"Amount too large\");\n    }\n\n    // ... 50 more lines of validation and processing\n\n    return result;\n};\n\n// Refactored - external API unchanged, internals improved\nexport const processPayment = (payment: Payment): ProcessedPayment => {\n    validatePaymentAmount(payment.amount);\n    validatePaymentMethod(payment.method);\n\n    const authorizedPayment = authorizePayment(payment);\n    const capturedPayment = capturePayment(authorizedPayment);\n\n    return generateReceipt(capturedPayment);\n};\n\n// New internal functions - not exported\nconst validatePaymentAmount = (amount: number): void => {\n    if (amount <= 0) {\n        throw new Error(\"Invalid amount\");\n    }\n\n    if (amount > 10000) {\n        throw new Error(\"Amount too large\");\n    }\n};\n\n// Tests continue to pass without modification because external API unchanged\n```\n\n##### 5. Verify and Commit After Refactoring\n\n**CRITICAL**: After every refactoring:\n\n1. Run all tests - they must pass without modification\n2. Run static analysis (linting, type checking) - must pass\n3. Commit the refactoring separately from feature changes\n\n```bash\n# After refactoring\nnpm test          # All tests must pass\nnpm run lint      # All linting must pass\nnpm run typecheck # TypeScript must be happy\n\n# Only then commit\ngit add .\ngit commit -m \"refactor: extract payment validation helpers\"\n```\n\n#### Refactoring Checklist\n\nBefore considering refactoring complete, verify:\n\n- [ ] The refactoring actually improves the code (if not, don't refactor)\n- [ ] All tests still pass without modification\n- [ ] All static analysis tools pass (linting, type checking)\n- [ ] No new public APIs were added (only internal ones)\n- [ ] Code is more readable than before\n- [ ] Any duplication removed was duplication of knowledge, not just code\n- [ ] No speculative abstractions were created\n- [ ] The refactoring is committed separately from feature changes\n\n#### Example Refactoring Session\n\n```typescript\n// After getting tests green with minimal implementation:\ndescribe(\"Order processing\", () => {\n    it(\"calculates total with items and shipping\", () => {\n        const order = { items: [{ price: 30 }, { price: 20 }], shipping: 5 };\n        expect(calculateOrderTotal(order)).toBe(55);\n    });\n\n    it(\"applies free shipping over \\u00a350\", () => {\n        const order = { items: [{ price: 30 }, { price: 25 }], shipping: 5 };\n        expect(calculateOrderTotal(order)).toBe(55);\n    });\n});\n\n// Green implementation (minimal):\nconst calculateOrderTotal = (order: Order): number => {\n    const itemsTotal = order.items.reduce((sum, item) => sum + item.price, 0);\n    const shipping = itemsTotal > 50 ? 0 : order.shipping;\n    return itemsTotal + shipping;\n};\n\n// Commit the working version\n// git commit -m \"feat: implement order total calculation with free shipping\"\n\n// Assess refactoring opportunities:\n// - The variable names could be clearer\n// - The free shipping threshold is a magic number\n// - The calculation logic could be extracted for clarity\n// These improvements would add value, so proceed with refactoring:\n\nconst FREE_SHIPPING_THRESHOLD = 50;\n\nconst calculateItemsTotal = (items: OrderItem[]): number => {\n    return items.reduce((sum, item) => sum + item.price, 0);\n};\n\nconst calculateShipping = (\n    baseShipping: number,\n    itemsTotal: number\n): number => {\n    return itemsTotal > FREE_SHIPPING_THRESHOLD ? 0 : baseShipping;\n};\n\nconst calculateOrderTotal = (order: Order): number => {\n    const itemsTotal = calculateItemsTotal(order.items);\n    const shipping = calculateShipping(order.shipping, itemsTotal);\n    return itemsTotal + shipping;\n};\n\n// Run tests - they still pass!\n// Run linting - all clean!\n// Run type checking - no errors!\n\n// Now commit the refactoring\n// git commit -m \"refactor: extract order total calculation helpers\"\n```\n\n##### Example: When NOT to Refactor\n\n```typescript\n// After getting this test green:\ndescribe(\"Discount calculation\", () => {\n    it(\"should apply 10% discount\", () => {\n        const originalPrice = 100;\n        const discountedPrice = applyDiscount(originalPrice, 0.1);\n        expect(discountedPrice).toBe(90);\n    });\n});\n\n// Green implementation:\nconst applyDiscount = (price: number, discountRate: number): number => {\n    return price * (1 - discountRate);\n};\n\n// Assess refactoring opportunities:\n// - Code is already simple and clear\n// - Function name clearly expresses intent\n// - Implementation is a straightforward calculation\n// - No magic numbers or unclear logic\n// Conclusion: No refactoring needed. This is fine as-is.\n\n// Commit and move to the next test\n// git commit -m \"feat: add discount calculation\"\n```\n\n### Commit Guidelines\n\n- Each commit should represent a complete, working change\n- Use conventional commits format:\n    ```\n    feat: add payment validation\n    fix: correct date formatting in payment processor\n    refactor: extract payment validation logic\n    test: add edge cases for payment validation\n    chore: update dependencies\n    breaking: major API change\n    ```\n- Include test changes with feature changes in the same commit\n\n### Semantic Versioning\n\n- **patch:** `chore:*`\n- **minor:** `fix:*`, `feat:*`, `perf:*`\n- **major:** `breaking:*`\n\n### Pull Request Standards\n\n- Every PR must have all tests passing\n- All linting and quality checks must pass\n- Work in small increments that maintain a working state\n- PRs should be focused on a single feature or fix\n- Include description of the behavior change, not implementation details\n\n### Pre-commit Hooks\n\nUse the included `.pre-commit-config.yaml` to run `npm test` and commitlint on every commit. Install hooks with:\n\n```bash\nnpx pre-commit install\n```\n\nCommits will be blocked if tests fail or commit messages do not follow the conventional format.\n\n## Working with Claude\n\n### Expectations\n\nWhen working with my code:\n\n1. **ALWAYS FOLLOW TDD** - No production code without a failing test. This is not negotiable.\n2. **Think deeply** before making any edits\n3. **Understand the full context** of the code and requirements\n4. **Ask clarifying questions** when requirements are ambiguous\n5. **Think from first principles** - don't make assumptions\n6. **Assess refactoring after every green** - Look for opportunities to improve code structure, but only refactor if it adds value\n7. **Keep project docs current** - update them whenever you introduce meaningful changes\n\n### Code Changes\n\nWhen suggesting or making changes:\n\n- **Start with a failing test** - always. No exceptions.\n- After making tests pass, always assess refactoring opportunities (but only refactor if it adds value)\n- After refactoring, verify all tests and static analysis pass, then commit\n- Respect the existing patterns and conventions\n- Maintain test coverage for all behavior changes\n- Keep changes small and incremental\n- Ensure all TypeScript strict mode requirements are met\n- Provide rationale for significant design decisions\n\n**If you find yourself writing production code without a failing test, STOP immediately and write the test first.**\n\n### Communication\n\n- Be explicit about trade-offs in different approaches\n- Explain the reasoning behind significant design decisions\n- Flag any deviations from these guidelines with justification\n- Suggest improvements that align with these principles\n- When unsure, ask for clarification rather than assuming\n\n## Example Patterns\n\n### Error Handling\n\nUse Result types or early returns:\n\n```typescript\n// Good - Result type pattern\ntype Result<T, E = Error> =\n    | { success: true; data: T }\n    | { success: false; error: E };\n\nconst processPayment = (\n    payment: Payment\n): Result<ProcessedPayment, PaymentError> => {\n    if (!isValidPayment(payment)) {\n        return { success: false, error: new PaymentError(\"Invalid payment\") };\n    }\n\n    if (!hasSufficientFunds(payment)) {\n        return {\n            success: false,\n            error: new PaymentError(\"Insufficient funds\"),\n        };\n    }\n\n    return { success: true, data: executePayment(payment) };\n};\n\n// Also good - early returns with exceptions\nconst processPayment = (payment: Payment): ProcessedPayment => {\n    if (!isValidPayment(payment)) {\n        throw new PaymentError(\"Invalid payment\");\n    }\n\n    if (!hasSufficientFunds(payment)) {\n        throw new PaymentError(\"Insufficient funds\");\n    }\n\n    return executePayment(payment);\n};\n```\n\n### Testing Behavior\n\n```typescript\n// Good - tests behavior through public API\ndescribe(\"PaymentProcessor\", () => {\n    it(\"should decline payment when insufficient funds\", () => {\n        const payment = getMockPaymentPostPaymentRequest({ Amount: 1000 });\n        const account = getMockAccount({ Balance: 500 });\n\n        const result = processPayment(payment, account);\n\n        expect(result.success).toBe(false);\n        expect(result.error.message).toBe(\"Insufficient funds\");\n    });\n\n    it(\"should process valid payment successfully\", () => {\n        const payment = getMockPaymentPostPaymentRequest({ Amount: 100 });\n        const account = getMockAccount({ Balance: 500 });\n\n        const result = processPayment(payment, account);\n\n        expect(result.success).toBe(true);\n        expect(result.data.remainingBalance).toBe(400);\n    });\n});\n\n// Avoid - testing implementation details\ndescribe(\"PaymentProcessor\", () => {\n    it(\"should call checkBalance method\", () => {\n        // This tests implementation, not behavior\n    });\n});\n```\n\n#### Achieving 100% Coverage Through Business Behavior\n\nExample showing how validation code gets 100% coverage without testing it directly:\n\n```typescript\n// payment-validator.ts (implementation detail)\nexport const validatePaymentAmount = (amount: number): boolean => {\n    return amount > 0 && amount <= 10000;\n};\n\nexport const validateCardDetails = (card: PayingCardDetails): boolean => {\n    return /^\\d{3,4}$/.test(card.cvv) && card.token.length > 0;\n};\n\n// payment-processor.ts (public API)\nexport const processPayment = (\n    request: PaymentRequest\n): Result<Payment, PaymentError> => {\n    // Validation is used internally but not exposed\n    if (!validatePaymentAmount(request.amount)) {\n        return { success: false, error: new PaymentError(\"Invalid amount\") };\n    }\n\n    if (!validateCardDetails(request.payingCardDetails)) {\n        return {\n            success: false,\n            error: new PaymentError(\"Invalid card details\"),\n        };\n    }\n\n    // Process payment...\n    return { success: true, data: executedPayment };\n};\n\n// payment-processor.test.ts\ndescribe(\"Payment processing\", () => {\n    // These tests achieve 100% coverage of validation code\n    // without directly testing the validator functions\n\n    it(\"should reject payments with negative amounts\", () => {\n        const payment = getMockPaymentPostPaymentRequest({ amount: -100 });\n        const result = processPayment(payment);\n\n        expect(result.success).toBe(false);\n        expect(result.error.message).toBe(\"Invalid amount\");\n    });\n\n    it(\"should reject payments exceeding maximum amount\", () => {\n        const payment = getMockPaymentPostPaymentRequest({ amount: 10001 });\n        const result = processPayment(payment);\n\n        expect(result.success).toBe(false);\n        expect(result.error.message).toBe(\"Invalid amount\");\n    });\n\n    it(\"should reject payments with invalid CVV format\", () => {\n        const payment = getMockPaymentPostPaymentRequest({\n            payingCardDetails: { cvv: \"12\", token: \"valid-token\" },\n        });\n        const result = processPayment(payment);\n\n        expect(result.success).toBe(false);\n        expect(result.error.message).toBe(\"Invalid card details\");\n    });\n\n    it(\"should process valid payments successfully\", () => {\n        const payment = getMockPaymentPostPaymentRequest({\n            amount: 100,\n            payingCardDetails: { cvv: \"123\", token: \"valid-token\" },\n        });\n        const result = processPayment(payment);\n\n        expect(result.success).toBe(true);\n        expect(result.data.status).toBe(\"completed\");\n    });\n});\n```\n\n### React Component Testing\n\n```typescript\n// Good - testing user-visible behavior\ndescribe(\"PaymentForm\", () => {\n  it(\"should show error when submitting invalid amount\", async () => {\n    render(<PaymentForm />);\n\n    const amountInput = screen.getByLabelText(\"Amount\");\n    const submitButton = screen.getByRole(\"button\", { name: \"Submit Payment\" });\n\n    await userEvent.type(amountInput, \"-100\");\n    await userEvent.click(submitButton);\n\n    expect(screen.getByText(\"Amount must be positive\")).toBeInTheDocument();\n  });\n});\n```\n\n## Common Patterns to Avoid\n\n### Anti-patterns\n\n```typescript\n// Avoid: Mutation\nconst addItem = (items: Item[], newItem: Item) => {\n    items.push(newItem); // Mutates array\n    return items;\n};\n\n// Prefer: Immutable update\nconst addItem = (items: Item[], newItem: Item): Item[] => {\n    return [...items, newItem];\n};\n\n// Avoid: Nested conditionals\nif (user) {\n    if (user.isActive) {\n        if (user.hasPermission) {\n            // do something\n        }\n    }\n}\n\n// Prefer: Early returns\nif (!user || !user.isActive || !user.hasPermission) {\n    return;\n}\n// do something\n\n// Avoid: Large functions\nconst processOrder = (order: Order) => {\n    // 100+ lines of code\n};\n\n// Prefer: Composed small functions\nconst processOrder = (order: Order) => {\n    const validatedOrder = validateOrder(order);\n    const pricedOrder = calculatePricing(validatedOrder);\n    const finalOrder = applyDiscounts(pricedOrder);\n    return submitOrder(finalOrder);\n};\n```\n\n## Software Engineering Laws\n\nThe following classic software engineering laws guide decision-making. Each law\nincludes expanded interpretations and real-world examples in the project wiki.\n\n- **Murphy's Law**  anything that can go wrong will go wrong.\n- **Brook's Law**  adding people to a late project makes it later.\n- **Hofstadter's Law**  everything takes longer than expected.\n- **Conway's Law**  system design mirrors communication structures.\n- **Postel's Law**  be conservative in what you send, liberal in what you\n  accept.\n- **Pareto Principle**  80% of consequences come from 20% of causes.\n- **The Peter Principle**  employees rise to their level of incompetence.\n- **Kerckhoffs's Principle**  security should rely only on key secrecy.\n- **Linus's Law**  given enough eyes, all bugs are shallow.\n- **Moore's Law**  computing power doubles roughly every two years.\n- **Wirth's Law**  software gets slower faster than hardware improves.\n- **Ninety-ninety Rule**  the last 10% of code takes 90% of the time.\n- **Knuth's Optimization Principle**  premature optimization is the root of\n  all evil.\n- **Norvig's Law**  tech beyond 50% penetration will never double again.\n\n## Resources and References\n\n- [TypeScript Handbook](https://www.typescriptlang.org/docs/handbook/intro.html)\n- [Testing Library Principles](https://testing-library.com/docs/guiding-principles)\n- [Kent C. Dodds Testing JavaScript](https://testingjavascript.com/)\n- [Functional Programming in TypeScript](https://gcanti.github.io/fp-ts/)\n\n## Summary\n\nThe key is to write clean, testable, functional code that evolves through small, safe increments. Every change should be driven by a test that describes the desired behavior, and the implementation should be the simplest thing that makes that test pass. When in doubt, favor simplicity and readability over cleverness.\n\n## Hosting Environments\n\nWe have two environments for this project: one deployed via GitHub Pages and another using lovable.app. Do not modify configuration files for these setups unless absolutely necessary.\n\n## 3D Immersive Workspace Design Guide\n\n### Project Vision\n\nCreate workspaces with a large quantity of 3D art that people can play with and iterate on. Each scene should serve as an immersive, interactive environment that inspires creativity and experimentation.\n\n### Core Design Principles\n\n#### 1. Visual Impact Requirements\n\n- **Unique**: Each scene must have distinct visual identity and geometry\n- **Immersive**: Users should feel transported to another world\n- **Captivating**: Immediate visual appeal that holds attention\n- **Intuitive**: Easy to understand and interact with\n- **Eery**: Subtle otherworldly atmosphere\n- **Awesome**: Inspiring sense of wonder\n- **Fun**: Engaging and playful interactions\n\n#### 2. Technical Standards\n\n- **Visibility**: All objects must be clearly visible and well-lit\n- **Performance**: Smooth 60fps experience across devices\n- **Responsiveness**: Objects react meaningfully to interactions\n- **Scalability**: Works on both desktop and mobile\n\n#### 3. Geometry Diversity Strategy\n\nUtilize the full spectrum of Three.js geometries:\n\n- **Basic**: BoxGeometry, SphereGeometry, PlaneGeometry\n- **Complex**: TorusKnotGeometry, IcosahedronGeometry, DodecahedronGeometry\n- **Parametric**: LatheGeometry, ExtrudeGeometry, TubeGeometry\n- **Organic**: ConvexGeometry (with custom shapes)\n- **Artistic**: PolyhedronGeometry, TetrahedronGeometry, OctahedronGeometry\n\n#### 4. Material & Lighting Philosophy\n\n- **Day Theme**: Bright, energetic, exploratory mood\n- **Night Theme**: Mysterious, contemplative, ambient mood\n- **Dynamic Materials**: MeshDistortMaterial, MeshWobbleMaterial for life\n- **Lighting Drama**: Animated lights that enhance atmosphere\n- **Color Psychology**: Intentional color choices that evoke emotion\n\n#### 5. Background & Environment Design\n\n- **Contextual**: Backgrounds that support the main geometry's story\n- **Layered**: Multiple depth levels for visual richness\n- **Interactive**: Environments that respond to user presence\n- **Atmospheric**: Fog, particles, and effects that create mood\n\n#### 6. Animation & Interaction Standards\n\n- **Organic Motion**: Natural, fluid animations that feel alive\n- **Mouse Responsiveness**: Meaningful reactions to cursor movement\n- **Lock State**: Clear visual feedback when motion is frozen\n- **Smoothness**: All transitions use easing and interpolation\n\n### Scene-Specific Guidelines\n\n#### Current Scene Analysis & Improvements Needed:\n\n1. **Genesis Torus**:  Good baseline - complex geometry, interesting materials\n2. **Distortion Sphere**:  Too simple - needs more visual complexity\n3. **Wobble Field**:  Basic sphere - needs complete redesign\n4. **Crystalline Spire**:  Too dark/unclear - needs better visibility\n5. **Quantum Foam**:  Basic sphere - needs particle systems and complexity\n6. **Echoing Void**:  Too dark - needs dramatic lighting and geometry\n7. **Solar Flare**:  Basic sphere - needs fire/energy effects\n8. **Gravity Well**:  Invisible/unclear - needs strong visual presence\n\n### Implementation Strategy\n\n#### Phase 1: Geometry Revolution\n\nReplace basic spheres with complex, meaningful geometries that tell a story.\n\n#### Phase 2: Material Magic\n\nImplement advanced materials that bring scenes to life with dynamic properties.\n\n#### Phase 3: Environmental Storytelling\n\nCreate backgrounds and lighting that support each scene's unique narrative.\n\n#### Phase 4: Interactive Polish\n\nAdd subtle interactions and animations that reward exploration.\n\n### Asset Guidelines\n\n- **Free Use Only**: Ensure all assets are freely available\n- **Performance First**: Optimize geometry complexity for real-time rendering\n- **Consistent Style**: Maintain cohesive visual language across scenes\n- **Scalable Complexity**: Design works at multiple LOD levels\n\n### Success Metrics\n\n- Visual impact: \"Wow\" factor on first view\n- Engagement: Users want to interact and explore\n- Performance: Smooth experience across devices\n- Uniqueness: Each scene feels completely different\n- Memorability: Scenes are distinctive and memorable\n\nThis document should guide all scene development decisions to ensure we create truly captivating 3D workspaces.\n\n---\n\n## Recent Development Session Summary (January 2025)\n\n### Major Accomplishments\n\n#### 1. **WebGL Shader Compilation Issues - RESOLVED**\n- **Problem**: Multiple shader compilation errors in background effects causing Three.js warnings\n- **Root Cause**: ShaderLibrary template string interpolation not working in production builds\n- **Solution**: Inlined all GLSL shader functions directly into shader code\n- **Files Fixed**: \n  - `EnhancedGeometryShader.tsx`\n  - `EnhancedAuroraBackground.tsx` \n  - `VolumetricLighting.tsx`\n- **Result**: All WebGL compilation errors eliminated\n\n#### 2. **Background Visual Enhancement - COMPLETED**\n- **New Component**: `CinematicBackground.tsx` - A spectacular atmospheric background with:\n  - Dynamic particle systems (2000+ particles)\n  - Complex noise-based atmospheric rendering\n  - Multi-layered visual effects with depth\n  - Cinematic wide-screen aspect ratio\n  - HSV color mixing for dynamic palettes\n  - Real-time animation and particle motion\n- **Integration**: Added \"cinematic\" background type to BackgroundRegistry\n- **Configuration**: Enhanced WobbleField scenes to use cinematic backgrounds by default\n- **Impact**: Significantly improved visual appeal and immersiveness\n\n#### 3. **Critical Test Fix - useWorlds Hook Navigation**\n- **Problem**: Race condition in `useWorlds` hook causing navigation tests to fail\n- **Root Cause**: `useEffect` dependency array included `currentWorldIndex`, causing it to reset after `jumpToWorld()` calls\n- **Solution**: \n  - Removed `currentWorldIndex` from `useEffect` dependencies\n  - Added condition to only reset index when still in initial state\n  - Enhanced test reliability with proper timer handling\n- **Result**: All 57 tests passing, including previously failing navigation tests\n\n#### 4. **Code Quality & Formatting**\n- **Biome Integration**: Successfully applied Biome formatting rules\n- **Style Consistency**: All code now follows consistent formatting standards\n- **Quality Assurance**: Format checks passing with zero violations\n\n### Technical Details\n\n#### Shader Compilation Fix Strategy\nThe WebGL shader compilation issue required a fundamental change in how we handle shader code:\n\n```typescript\n// BEFORE (broken in production):\nconst fragmentShader = `\n  ${ShaderLibrary.noise.hash3}\n  // ... rest of shader\n`;\n\n// AFTER (working solution):\nconst fragmentShader = `\n  float hash(float n) {\n    return fract(sin(n) * 43758.5453);\n  }\n  // ... inlined shader functions\n`;\n```\n\nThis ensures all shader functions are available at compile time regardless of build environment.\n\n#### useWorlds Hook Race Condition\nThe navigation bug was subtle but critical:\n\n```typescript\n// PROBLEMATIC CODE:\nuseEffect(() => {\n    // This effect runs when currentWorldIndex changes\n    if (worlds && !initialSlug) {\n        setCurrentWorldIndex(0); // Resets index after jumpToWorld!\n    }\n}, [initialWorld, worlds, initialSlug, currentWorldIndex]); //  Problem dependency\n\n// FIXED CODE:\nuseEffect(() => {\n    // Only runs when data loads, not when index changes\n    if (worlds && !initialSlug && currentWorldIndex === 0) {\n        setCurrentWorldIndex(0); // Only reset if still initial\n    }\n}, [initialWorld, worlds, initialSlug]); //  Removed currentWorldIndex\n```\n\n#### CinematicBackground Architecture\nThe new cinematic background uses advanced GLSL techniques:\n- **Fractal Noise**: Multi-octave noise for atmospheric depth\n- **HSV Color Space**: Dynamic color mixing in HSV for better control\n- **Particle Physics**: WebGL point sprites with animated movement\n- **Depth-based Mixing**: Color changes based on elevation/position\n- **Performance Optimization**: Efficient shader operations for 60fps\n\n### Files Modified\n1. `client/hooks/useWorlds.ts` - Fixed race condition\n2. `client/hooks/__tests__/useWorlds.test.ts` - Enhanced test reliability\n3. `client/components/scene/effects/CinematicBackground.tsx` - New spectacular background\n4. `client/components/scene/backgrounds/BackgroundRegistry.tsx` - Added cinematic type\n5. `client/types/scene.ts` - Added cinematic background configuration\n6. `client/lib/sceneConfigUtils.ts` - Enhanced WobbleField defaults\n7. Multiple shader components - Fixed WebGL compilation issues\n\n### Commits Made\n1. `feat: fix WebGL shader compilation and enhance background effects` - Major fixes and enhancements\n2. `fix: resolve useWorlds hook navigation test race condition` - Critical test fix\n3. `style: apply Biome formatting to useWorlds hook` - Code formatting compliance\n\n### Development Insights\n\n#### Lessons Learned\n1. **Template Strings in Shaders**: Build-time template interpolation can fail in production - prefer inline GLSL\n2. **useEffect Dependencies**: Be very careful with dependency arrays, especially when state updates can trigger unwanted re-runs\n3. **Test Timing**: Race conditions in hooks require careful test design with proper state verification\n\n#### Best Practices Reinforced\n1. **TDD Approach**: All fixes were driven by failing tests first\n2. **Incremental Changes**: Each fix was isolated and tested independently\n3. **Documentation**: All changes documented for future reference\n4. **Quality Gates**: Format checks and linting maintained throughout\n\n### Next Session Priorities\n1. **Performance Monitoring**: Add PerformanceMonitor component usage tracking\n2. **Background Expansion**: Create more cinematic background variants\n3. **Shader Library**: Consider creating a proper shader library system\n4. **Mobile Optimization**: Test cinematic backgrounds on mobile devices\n5. **User Experience**: Gather feedback on new visual enhancements\n\n### Technical Debt Addressed\n-  WebGL shader compilation warnings eliminated\n-  Test suite reliability improved (100% pass rate)\n-  Code formatting standardized\n-  Race condition in navigation fixed\n\n### Outstanding Items\n-  VS Code Biome integration (low priority)\n-  Remaining 145 Biome linting issues (gradual resolution)\n-  Mobile performance testing for new effects\n-  Additional background variants development\n",
        "docs/archive/memory/agents/README.md": "# Agent Memory Storage\n\n## Purpose\n\nThis directory stores consolidated agent memory, development guidelines, workflow rules, and persistent state information for Claude Code and Claude Flow swarm orchestration systems.\n\n## Consolidated Structure\n\n```\nmemory/agents/\n MEMORY.md               # Comprehensive development guidelines and session history\n RULES.md                # Repository workflow rules and commit standards  \n README.md               # This file - explains the memory system\n shared/                 # Cross-agent shared resources (when needed)\n    common_knowledge.md # Shared knowledge across agents\n    global_config.json  # Global agent configurations\n swarm_instances/        # Individual swarm instance data (created dynamically)\n     swarm_001/\n        coordination.json   # Swarm coordination state\n        agent_roster.json  # Active agents and their roles\n        memory_snapshots/  # Point-in-time memory captures\n     ...\n```\n\n## Key Files\n\n- **MEMORY.md**: Master development guidelines, TDD principles, coding standards, and session history\n- **RULES.md**: Repository-specific workflow rules, commit standards, and CI/CD guidelines\n- **claude-flow-data.json**: Persistent swarm coordination data (at memory root level)\n\n## Swarm Integration\n\nThis memory system supports both individual Claude Code sessions and Claude Flow swarm orchestration:\n\n### Individual Sessions\n- Claude Code reads MEMORY.md for development guidelines\n- Session-specific data goes to `memory/sessions/`\n- Persistent decisions and learnings are documented in MEMORY.md\n\n### Swarm Operations  \n- Claude Flow coordinates multiple agents using the shared memory system\n- Each swarm instance gets isolated coordination data\n- Agents share knowledge through the memory/agents/shared/ directory\n- Cross-session coordination data persists in claude-flow-data.json\n\n## Usage Guidelines\n\n1. **Centralized Guidelines**: All agents reference MEMORY.md for consistent development practices\n2. **Session Isolation**: Individual sessions use memory/sessions/ for temporary data\n3. **Swarm Coordination**: Dynamic swarm data goes to swarm_instances/ subdirectories\n4. **Shared Knowledge**: Use shared/ directory for cross-agent information that should persist\n5. **Documentation**: Update MEMORY.md with significant learnings and session summaries\n\n## Last Updated\n\n2025-01-22T03:48:00.000Z - Consolidated agents/ directory into memory/agents/ structure\n",
        "docs/archive/memory/agents/RULES.md": "# Repository Workflow Rules\n\nThese rules keep development consistent across the project. The document is intentionally brief so it can be referenced often.\n\n## General Principles\n\n- Follow Test-Driven Development. Write tests before production code and keep changes small.\n- Use strict TypeScript and prefer immutable patterns.\n- When looking for solutions, consult **context7** and the guidance in **MEMORY.md**. Do not copy text from MEMORY.md into this file.\n- Keep the **Software Engineering Laws** section of **MEMORY.md** in mind when\n  planning features or processes.\n- Avoid modifying App.tsx or rsbuild.config deployment settings unless absolutely necessary to keep the live sites accessible.\n\n## Local Workflow\n\n**Recommended:** Use bun for optimal performance. Use these scripts during feature work:\n\n- `bun install`  install dependencies\n- `bun run dev`  run the development server\n- `bun run test`  run the full test suite\n- `bun run typecheck`  run TypeScript checks\n- `bun run build`  build release artifacts\n\n**Alternative:** If using npm (may yield different results):\n\n- `npm install`, `npm run dev`, `npm run test`, `npm run typecheck`, `npm run build`\n\nRun `bun install`, `bun run test`, `bun run typecheck`, and `bun run build` before pushing changes. CI uses the same commands.\n\n## Commit Standards\n\nCommits must use [Conventional Commits](https://www.conventionalcommits.org/en/v1.0.0/). Examples:\n\n```\nfeat: add dark mode toggle\nfix: handle null todo values\nchore: update dependencies\nperf: optimize render performance\ndocs: update API documentation\n```\n\n### Semantic Versioning Rules\n\n**IMPORTANT**: Project follows semantic versioning starting from v0.0.1. Version bumps are automated via semantic-release.\n\n**PATCH** version bumps (e.g., 0.0.1  0.0.2):\n\n- `chore:` commits - maintenance and tooling changes\n- `perf:` commits - performance improvements\n- `docs:` commits - documentation updates\n- `style:` commits - code formatting and style changes\n- `test:` commits - test additions and improvements\n- `hotfix:` commits - emergency bug fixes\n\n**MINOR** version bumps (e.g., 0.0.1  0.1.0):\n\n- `fix:` commits - bug fixes and corrections\n- `feat:` commits - new features and functionality\n\n**MAJOR** version bumps (e.g., 0.1.0  1.0.0):\n\n- `breaking:` commits - breaking changes\n- `refactor:` commits - code restructuring (potentially breaking)\n\n**Version Reset Policy**: If project needs version reset, use the manage-releases.yml workflow or manual deletion of releases/tags, then create a `feat:` commit to trigger new initial release.\n\n## Version Management\n\n### Automated Versioning\n\nVersions are **automatically** managed by semantic-release based on conventional commits. Manual version commands are **not used**.\n\n### GitHub Workflows\n\n- **semantic-release.yml**: Automatically creates releases on push to main\n- **manage-releases.yml**: Manual workflow for deleting releases/tags (version reset)\n\n### Version Reset Process\n\nIf version reset is needed (e.g., premature v1.0.0):\n\n1. **Delete releases**: `gh release delete vX.X.X --yes`\n2. **Delete local tags**: `git tag -d vX.X.X`\n3. **Delete remote tags**: `git push origin --delete vX.X.X`\n4. **Create trigger commit**: `git commit --allow-empty -m \"feat: initialize project at vX.X.X\"`\n5. **Push to trigger release**: `git push`\n\n### Version Monitoring\n\n```bash\n# Check current releases\ngh release list\n\n# Monitor workflow progress\ngh run list --workflow=semantic-release.yml\ngh run watch\n\n# Check git tags\ngit tag -l\n```\n\n## Pull Requests\n\nPrefix PR titles to show intent:\n\n- **Feature:**   merge into `develop`\n- **Bugfix:**   merge into `develop`\n- **Cleanup:**   merge into `develop`\n- **Pipeline:**   merge into `develop`\n- **Hotfix:**   merge directly to `main`\n\nInclude a **Codex CI** section summarising `install`, `build`, `typecheck`, and `test` results.\n\nAfter merging into `develop`, automatically open a PR that merges `develop` into `main` so changes can be tested against the main branch.\n\n## Continuous Integration\n\nAll dependencies must be installed with `npm ci` in CI jobs. The Super-Linter runs on every pull request via `.github/workflows/super-linter.yml`.\n",
        "docs/archive/memory/agents/shared/common_knowledge.md": "# Shared Agent Knowledge\n\n## Purpose\n\nThis file contains knowledge and insights that should be shared across all agents in the swarm orchestration system.\n\n## Project-Specific Knowledge\n\n### Immersive Awe Canvas - 3D Workspace Platform\n\n#### Core Technologies\n- **Frontend**: React + TypeScript + Three.js (React Three Fiber)\n- **Styling**: Tailwind CSS + shadcn/ui components\n- **Build System**: Rsbuild (Webpack-based)\n- **Testing**: Vitest + React Testing Library\n- **Package Manager**: Bun (preferred) / npm (fallback)\n- **Code Quality**: Biome (formatting + linting)\n\n#### Architecture Patterns\n- **Scene Objects**: Dynamic 3D objects with customizable materials and animations\n- **Background Effects**: Shader-based atmospheric backgrounds (Void, Aurora, Plasma, Cinematic, etc.)\n- **Navigation**: World-based navigation system with smooth transitions\n- **State Management**: React Context + custom hooks pattern\n- **Testing Strategy**: Behavior-driven testing following TDD principles\n\n#### Key Development Insights\n\n##### WebGL/Shader Development\n- Template string interpolation in shaders fails in production builds\n- Always inline GLSL functions directly in shader code\n- Use `precision mediump float;` declarations for compatibility\n- Test shaders across different devices and contexts\n\n##### React Hook Patterns  \n- Be careful with useEffect dependency arrays - avoid state that causes unwanted re-runs\n- Use functional state updates for async operations (setTimeout, promises)\n- Race conditions can occur when effects trigger from state changes they also cause\n\n##### Testing Strategies\n- Use fake timers carefully - they can interfere with React Testing Library's waitFor\n- Test behavior through public APIs, not implementation details\n- Mock external dependencies (Supabase, Three.js) consistently across tests\n\n##### Performance Considerations\n- Particle systems should be optimized for 60fps (limit particle count)\n- Use React.memo for expensive component re-renders\n- Batch state updates where possible\n- Monitor WebGL context limits on mobile devices\n\n#### Common Pitfalls & Solutions\n\n1. **Shader Compilation Issues**\n   - Problem: `THREE.WebGLProgram: Shader Error - Fragment shader is not compiled`\n   - Solution: Inline all shader functions, avoid template interpolation\n\n2. **Hook Dependencies**\n   - Problem: useEffect runs unexpectedly causing state resets\n   - Solution: Carefully audit dependency arrays, remove state that causes cycles\n\n3. **Test Timing Issues**\n   - Problem: Tests fail intermittently due to timing\n   - Solution: Use proper waitFor patterns, avoid fake timers with complex hooks\n\n4. **Build vs Development Differences**\n   - Problem: Code works in dev but fails in production\n   - Solution: Test with production builds, avoid dynamic imports in shaders\n\n## Cross-Agent Coordination\n\n### Swarm Roles\n- **Coordinator**: Overall project oversight and task distribution\n- **Researcher**: Investigate solutions, gather requirements, analyze problems  \n- **Coder**: Implement features following TDD practices\n- **Tester**: Focus on test quality, coverage, and reliability\n- **Reviewer**: Code review, architecture decisions, refactoring opportunities\n\n### Communication Protocols\n- All agents should reference MEMORY.md for consistent development practices\n- Use conventional commit messages for all changes\n- Document significant decisions and rationale in session summaries\n- Share learnings through this common_knowledge.md file\n\n### Quality Standards\n- 100% test coverage through behavior-driven testing\n- TypeScript strict mode compliance\n- Biome formatting and linting standards\n- TDD red-green-refactor cycle adherence\n\n## Last Updated\n\n2025-01-22T03:48:00.000Z - Initial shared knowledge documentation",
        "docs/archive/memory/sessions/README.md": "# Session Memory Storage\n\n## Purpose\n\nThis directory stores session-based memory data, conversation history, and contextual information for development sessions using the Claude-Flow orchestration system.\n\n## Structure\n\nSessions are organized by date and session ID for easy retrieval:\n\n```\nmemory/sessions/\n 2024-01-10/\n    session_001/\n       metadata.json        # Session metadata and configuration\n       conversation.md      # Full conversation history\n       decisions.md         # Key decisions and rationale\n       artifacts/           # Generated files and outputs\n       coordination_state/  # Coordination system snapshots\n    ...\n shared/\n     patterns.md              # Common session patterns\n     templates/               # Session template files\n```\n\n## Usage Guidelines\n\n1. **Session Isolation**: Each session gets its own directory\n2. **Metadata Completeness**: Always fill out session metadata\n3. **Conversation Logging**: Document all significant interactions\n4. **Artifact Organization**: Structure generated files clearly\n5. **State Preservation**: Snapshot coordination state regularly\n\n## Last Updated\n\n2025-07-17T01:27:20.566Z\n",
        "docs/modules/README.md": "# Modules Documentation\n\nThis directory contains detailed documentation for individual project modules.\n\n## Available Modules\n\n- [Server API Module](./server-api.md) - Layered API architecture for backend operations\n\n## Overview\n\nEach module document provides:\n- Architecture overview and design principles\n- Detailed usage examples and patterns\n- Configuration and setup instructions\n- Development guidelines and best practices\n- Future enhancement roadmap\n\n## Navigation\n\n- [Back to Main Documentation](../README.md)\n- [Architecture Overview](../architecture.md)\n- [API Reference](../api-reference/README.md)\n",
        "tests/README.md": "# API Testing Module\n\nA comprehensive testing module that unifies and validates both the layered architecture and seamless integration of server and client API layers.\n\n##  Purpose\n\nThis module combines the functionality of both previous test files:\n- **test-architecture.ts** - Server layered architecture testing\n- **test-seamless-integration.ts** - Cross-layer integration testing\n\nInto a single, comprehensive testing system that validates the entire API ecosystem.\n\n##  Architecture\n\n```\ntests/\n index.ts                       # Module exports\n api-test-runner.ts             # Main unified test runner class\n test-config.ts                 # Configuration and utilities\n run-api-tests.ts               # Test execution script\n test-architecture.ts           # Legacy server architecture test\n test-seamless-integration.ts   # Legacy integration test\n README.md                      # This documentation\n```\n\n##  Test Suites\n\n### 1. **Server Architecture** \nTests the server-side layered API components:\n- Version Service (`getAppVersion`, `getBuildInfo`, `getFullVersion`)\n- GitHub API Client (server-side)\n- Logging Service (server-side)\n\n### 2. **Client Architecture** \nTests the client-side API layer:\n- Client Version API Client\n- Client GitHub API Client  \n- Client Logging API Client\n\n### 3. **Shared Utilities** \nTests the shared cross-layer utilities:\n- Shared GitHub Client\n- Shared Version Manager\n- Performance Monitor\n\n### 4. **Seamless Integration** \nTests server/client interface consistency:\n- Cross-layer type consistency\n- Environment detection\n- Same method signatures and results\n\n### 5. **Cross-Layer Consistency** \nTests data consistency across all layers:\n- Version consistency between server/client/shared\n- Configuration consistency\n- Error handling consistency\n\n##  Usage\n\n### Quick Start\n\n```bash\n# Using npm/bun scripts (recommended)\nnpm run test:api                   # Run all comprehensive tests\nnpm run test:api:quick            # Quick validation only  \nnpm run test:api:export           # Export results to JSON\nnpm run test:architecture         # Run legacy architecture test only\nnpm run test:integration          # Run legacy integration test only\n\n# Direct execution (if you prefer)\nnpx tsx tests/run-api-tests.ts                # Run all tests\nnpx tsx tests/run-api-tests.ts --quick        # Quick validation only\nnpx tsx tests/run-api-tests.ts --export       # Export results to JSON\nnpx tsx tests/run-api-tests.ts --help         # Show help\n```\n\n### Programmatic Usage\n\n```typescript\nimport { APITestRunner, runQuickAPITest } from './tests';\n\n// Option 1: Simple boolean result\nconst allPassed = await runQuickAPITest();\nconsole.log('All tests passed:', allPassed);\n\n// Option 2: Detailed test runner\nconst runner = new APITestRunner();\nconst results = await runner.runAllTests();\n\n// Access detailed results\nfor (const suite of results) {\n    console.log(`${suite.name}: ${suite.results.length} tests, ${suite.duration}ms`);\n    \n    const failed = suite.results.filter(r => !r.passed);\n    if (failed.length > 0) {\n        console.log('Failed tests:', failed.map(f => f.name));\n    }\n}\n```\n\n### Custom Configuration\n\n```typescript\nimport { APITestRunner, defaultTestConfig } from './tests';\n\n// Customize test configuration\nconst customConfig = {\n    ...defaultTestConfig,\n    timeout: 60000,           // 60 seconds\n    enabledSuites: [          // Only run specific suites\n        'Server Architecture',\n        'Seamless Integration'\n    ],\n    verbose: false,           // Minimal output\n    mockExternalCalls: true   // Mock GitHub API calls\n};\n\nconst runner = new APITestRunner();\n// runner.setConfig(customConfig); // If implemented\nconst results = await runner.runAllTests();\n```\n\n##  Test Results\n\n### Result Structure\n\n```typescript\ninterface TestResult {\n    name: string;        // Test name\n    passed: boolean;     // Pass/fail status\n    details?: string;    // Additional details\n    error?: string;      // Error message if failed\n}\n\ninterface TestSuite {\n    name: string;           // Suite name\n    results: TestResult[];  // Individual test results\n    duration: number;       // Execution time in ms\n}\n```\n\n### Sample Output\n\n```\n Running Comprehensive API Tests...\n\n Testing Server Layered Architecture:\n   Version Service: 1.0.0\n   GitHub API: v4.0.2\n\n Testing Client API Architecture:\n   Client Version API: 1.0.0\n   Client GitHub API: v4.0.2\n\n Testing Shared Utilities:\n   Shared GitHub Client: v4.0.2\n   Shared Version Manager: 1.0.0\n   Performance Monitor: 12ms\n\n Testing Seamless Integration:\n   Type Consistency: Identical results\n   Environment Detection: Server\n\n Testing Cross-Layer Consistency:\n   Version Consistency: All layers match\n\n Test Summary:\n\n Server Architecture: 2/2 (145ms)\n Client Architecture: 2/2 (238ms)\n Shared Utilities: 3/3 (156ms)\n Seamless Integration: 2/2 (89ms)\n Cross-Layer Consistency: 1/1 (23ms)\n\n Overall: 10/10 tests passed (651ms)\n All tests passed! API architecture is working perfectly.\n```\n\n##  Configuration Options\n\n### Test Execution\n- `timeout`: Maximum time per test (default: 30s)\n- `retries`: Number of retry attempts (default: 1)\n- `parallel`: Run tests in parallel (default: false)\n\n### Test Selection\n- `enabledSuites`: Which test suites to run\n- `skipSlowTests`: Skip performance-intensive tests\n\n### Output\n- `verbose`: Detailed output (default: true)\n- `exportResults`: Export to JSON file\n- `outputFormat`: console, json, or xml\n\n### API Settings\n- `mockExternalCalls`: Mock GitHub API calls for offline testing\n- `testDataPath`: Path to test data files\n\n##  Key Differences from Original Files\n\n| Feature | **test-architecture.ts** | **test-seamless-integration.ts** | **New Unified Module** |\n|---------|---------------------------|-----------------------------------|-------------------------|\n| **Scope** | Server-only testing | Shared utilities only | **Complete ecosystem** |\n| **Structure** | Simple function | Simple function | **Class-based with suites** |\n| **Results** | Console output only | Console output only | **Structured results + export** |\n| **Configuration** | Hardcoded | Hardcoded | **Configurable** |\n| **Error Handling** | Basic try/catch | Basic try/catch | **Detailed error tracking** |\n| **Performance** | No timing | Basic timing | **Per-suite timing** |\n| **Extensibility** | Not extensible | Not extensible | **Modular and extensible** |\n\n##  Benefits of Unified Module\n\n1. **Comprehensive Coverage**: Tests entire API ecosystem in one run\n2. **Structured Results**: Detailed, exportable test results\n3. **Configuration**: Customizable test execution\n4. **Performance Tracking**: Per-suite execution timing\n5. **Error Analysis**: Detailed error reporting and analysis\n6. **CI/CD Ready**: JSON export for automated systems\n7. **Maintainable**: Single source of truth for all API testing\n8. **Extensible**: Easy to add new test suites\n\n##  Migration Path\n\n### From test-architecture.ts:\n```typescript\n// Old approach\nimport { versionService, loggingService, githubAPIClient } from './server/api';\nawait testArchitecture();\n\n// New approach  \nimport { APITestRunner } from './tests';\nconst runner = new APITestRunner();\nawait runner.runAllTests(); // Includes server architecture + more\n```\n\n### From test-seamless-integration.ts:\n```typescript\n// Old approach\nimport { sharedGitHubClient, sharedVersionManager } from './shared';\nawait testSeamlessIntegration();\n\n// New approach\nimport { runQuickAPITest } from './tests';\nconst allPassed = await runQuickAPITest(); // Includes integration + more\n```\n\nThe unified testing module provides a comprehensive, maintainable, and extensible solution for validating your entire API architecture while maintaining all the functionality of both original test files.\n"
      },
      "plugins": [
        {
          "name": "document-skills",
          "description": "Collection of document processing suite including Excel, Word, PowerPoint, and PDF capabilities",
          "source": "./",
          "strict": false,
          "skills": [
            "./skills/xlsx",
            "./skills/docx",
            "./skills/pptx",
            "./skills/pdf"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add BA-CalderonMorales/immersive-awe-canvas",
            "/plugin install document-skills@anthropic-agent-skills"
          ]
        },
        {
          "name": "example-skills",
          "description": "Collection of example skills demonstrating various capabilities including skill creation, MCP building, visual design, algorithmic art, internal communications, web testing, artifact building, Slack GIFs, and theme styling",
          "source": "./",
          "strict": false,
          "skills": [
            "./skills/algorithmic-art",
            "./skills/brand-guidelines",
            "./skills/canvas-design",
            "./skills/doc-coauthoring",
            "./skills/frontend-design",
            "./skills/internal-comms",
            "./skills/mcp-builder",
            "./skills/skill-creator",
            "./skills/slack-gif-creator",
            "./skills/theme-factory",
            "./skills/web-artifacts-builder",
            "./skills/webapp-testing"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add BA-CalderonMorales/immersive-awe-canvas",
            "/plugin install example-skills@anthropic-agent-skills"
          ]
        }
      ]
    }
  ]
}