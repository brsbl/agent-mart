{
  "author": {
    "id": "zscole",
    "display_name": "zak",
    "avatar_url": "https://avatars.githubusercontent.com/u/20308948?u=55e5cfb112530ca0be9cc308e5ff99e60e798bd2&v=4"
  },
  "marketplaces": [
    {
      "name": "adversarial-spec",
      "version": null,
      "description": "Adversarial spec development through multi-model debate",
      "repo_full_name": "zscole/adversarial-spec",
      "repo_url": "https://github.com/zscole/adversarial-spec",
      "repo_description": "A Claude Code plugin that iteratively refines product specifications by debating between multiple LLMs until all models reach consensus.",
      "signals": {
        "stars": 468,
        "forks": 41,
        "pushed_at": "2026-01-22T06:33:17Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"adversarial-spec\",\n  \"owner\": {\n    \"name\": \"zscole\"\n  },\n  \"metadata\": {\n    \"description\": \"Adversarial spec development through multi-model debate\",\n    \"version\": \"1.0.0\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"adversarial-spec\",\n      \"description\": \"Iteratively refine product specs through multi-model debate until consensus\",\n      \"source\": \"./\",\n      \"keywords\": [\"spec\", \"prd\", \"technical-specification\", \"llm\", \"debate\", \"consensus\"],\n      \"skills\": [\"./skills/adversarial-spec\"]\n    }\n  ]\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"adversarial-spec\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Iteratively refine product specs through multi-model debate until consensus. Claude actively participates alongside GPT, Gemini, Grok, and other models. Includes interview mode, early agreement verification, and optional Telegram integration.\",\n  \"author\": {\n    \"name\": \"zscole\"\n  },\n  \"repository\": \"https://github.com/zscole/adversarial-spec\",\n  \"keywords\": [\"spec\", \"prd\", \"technical-specification\", \"llm\", \"debate\", \"consensus\"]\n}\n",
        "README.md": "# adversarial-spec\n\nA Claude Code plugin that iteratively refines product specifications through multi-model debate until consensus is reached.\n\n**Key insight:** A single LLM reviewing a spec will miss things. Multiple LLMs debating a spec will catch gaps, challenge assumptions, and surface edge cases that any one model would overlook. The result is a document that has survived rigorous adversarial review.\n\n**Claude is an active participant**, not just an orchestrator. Claude provides independent critiques, challenges opponent models, and contributes substantive improvements alongside external models.\n\n## Quick Start\n\n```bash\n# 1. Add the marketplace and install the plugin\nclaude plugin marketplace add zscole/adversarial-spec\nclaude plugin install adversarial-spec\n\n# 2. Set at least one API key\nexport OPENAI_API_KEY=\"sk-...\"\n# Or use OpenRouter for access to multiple providers with one key\nexport OPENROUTER_API_KEY=\"sk-or-...\"\n\n# 3. Run it\n/adversarial-spec \"Build a rate limiter service with Redis backend\"\n```\n\n## How It Works\n\n```\nYou describe product --> Claude drafts spec --> Multiple LLMs critique in parallel\n        |                                              |\n        |                                              v\n        |                              Claude synthesizes + adds own critique\n        |                                              |\n        |                                              v\n        |                              Revise and repeat until ALL agree\n        |                                              |\n        +--------------------------------------------->|\n                                                       v\n                                            User review period\n                                                       |\n                                                       v\n                                            Final document output\n```\n\n1. Describe your product concept or provide an existing document\n2. (Optional) Start with an in-depth interview to capture requirements\n3. Claude drafts the initial document (PRD or tech spec)\n4. Document is sent to opponent models (GPT, Gemini, Grok, etc.) for parallel critique\n5. Claude provides independent critique alongside opponent feedback\n6. Claude synthesizes all feedback and revises\n7. Loop continues until ALL models AND Claude agree\n8. User review period: request changes or run additional cycles\n9. Final converged document is output\n\n## Requirements\n\n- Python 3.10+\n- `litellm` package: `pip install litellm`\n- API key for at least one LLM provider\n\n## Supported Models\n\n| Provider   | Env Var                | Example Models                               |\n|------------|------------------------|----------------------------------------------|\n| OpenAI     | `OPENAI_API_KEY`       | `gpt-4o`, `gpt-4-turbo`, `o1`                |\n| Anthropic  | `ANTHROPIC_API_KEY`    | `claude-sonnet-4-20250514`, `claude-opus-4-20250514` |\n| Google     | `GEMINI_API_KEY`       | `gemini/gemini-2.0-flash`, `gemini/gemini-pro` |\n| xAI        | `XAI_API_KEY`          | `xai/grok-3`, `xai/grok-beta`                |\n| Mistral    | `MISTRAL_API_KEY`      | `mistral/mistral-large`, `mistral/codestral` |\n| Groq       | `GROQ_API_KEY`         | `groq/llama-3.3-70b-versatile`               |\n| OpenRouter | `OPENROUTER_API_KEY`   | `openrouter/openai/gpt-4o`, `openrouter/anthropic/claude-3.5-sonnet` |\n| Codex CLI  | ChatGPT subscription   | `codex/gpt-5.2-codex`, `codex/gpt-5.1-codex-max` |\n| Gemini CLI | Google account         | `gemini-cli/gemini-3-pro-preview`, `gemini-cli/gemini-3-flash-preview` |\n| Deepseek   | `DEEPSEEK_API_KEY`     | `deepseek/deepseek-chat`                     |\n| Zhipu      | `ZHIPUAI_API_KEY`      | `zhipu/glm-4`, `zhipu/glm-4-plus`            |\n\nCheck which keys are configured:\n\n```bash\npython3 \"$(find ~/.claude -name debate.py -path '*adversarial-spec*' 2>/dev/null | head -1)\" providers\n```\n\n## AWS Bedrock Support\n\nFor enterprise users who need to route all model calls through AWS Bedrock (e.g., for security compliance or inference gateway requirements):\n\n```bash\n# Enable Bedrock mode\npython3 \"$(find ~/.claude -name debate.py -path '*adversarial-spec*' 2>/dev/null | head -1)\" bedrock enable --region us-east-1\n\n# Add models enabled in your Bedrock account\npython3 \"$(find ~/.claude -name debate.py -path '*adversarial-spec*' 2>/dev/null | head -1)\" bedrock add-model claude-3-sonnet\npython3 \"$(find ~/.claude -name debate.py -path '*adversarial-spec*' 2>/dev/null | head -1)\" bedrock add-model claude-3-haiku\n\n# Check configuration\npython3 \"$(find ~/.claude -name debate.py -path '*adversarial-spec*' 2>/dev/null | head -1)\" bedrock status\n\n# Disable Bedrock mode\npython3 \"$(find ~/.claude -name debate.py -path '*adversarial-spec*' 2>/dev/null | head -1)\" bedrock disable\n```\n\nWhen Bedrock is enabled, **all model calls route through Bedrock** - no direct API calls are made. Use friendly names like `claude-3-sonnet` which are automatically mapped to Bedrock model IDs.\n\nConfiguration is stored at `~/.claude/adversarial-spec/config.json`.\n\n## OpenRouter Support\n\n[OpenRouter](https://openrouter.ai) provides unified access to multiple LLM providers through a single API. This is useful for:\n- Accessing models from multiple providers with one API key\n- Comparing models across different providers\n- Automatic fallback and load balancing\n- Cost optimization across providers\n\n**Setup:**\n\n```bash\n# Get your API key from https://openrouter.ai/keys\nexport OPENROUTER_API_KEY=\"sk-or-...\"\n\n# Use OpenRouter models (prefix with openrouter/)\npython3 debate.py critique --models openrouter/openai/gpt-4o,openrouter/anthropic/claude-3.5-sonnet < spec.md\n```\n\n**Popular OpenRouter models:**\n- `openrouter/openai/gpt-4o` - GPT-4o via OpenRouter\n- `openrouter/anthropic/claude-3.5-sonnet` - Claude 3.5 Sonnet\n- `openrouter/google/gemini-2.0-flash` - Gemini 2.0 Flash\n- `openrouter/meta-llama/llama-3.3-70b-instruct` - Llama 3.3 70B\n- `openrouter/qwen/qwen-2.5-72b-instruct` - Qwen 2.5 72B\n\nSee the full model list at [openrouter.ai/models](https://openrouter.ai/models).\n\n## Codex CLI Support\n\n[Codex CLI](https://github.com/openai/codex) allows ChatGPT Pro subscribers to use OpenAI models without separate API credits. Models prefixed with `codex/` are routed through the Codex CLI.\n\n**Setup:**\n\n```bash\n# Install Codex CLI (requires ChatGPT Pro subscription)\nnpm install -g @openai/codex\n\n# Use Codex models (prefix with codex/)\npython3 debate.py critique --models codex/gpt-5.2-codex,gemini/gemini-2.0-flash < spec.md\n```\n\n**Reasoning effort:**\n\nControl how much thinking time the model uses with `--codex-reasoning`:\n\n```bash\n# Available levels: low, medium, high, xhigh (default: xhigh)\npython3 debate.py critique --models codex/gpt-5.2-codex --codex-reasoning high < spec.md\n```\n\nHigher reasoning effort produces more thorough analysis but uses more tokens.\n\n**Available Codex models:**\n- `codex/gpt-5.2-codex` - GPT-5.2 via Codex CLI\n- `codex/gpt-5.1-codex-max` - GPT-5.1 Max via Codex CLI\n\nCheck Codex CLI installation status:\n\n```bash\npython3 \"$(find ~/.claude -name debate.py -path '*adversarial-spec*' 2>/dev/null | head -1)\" providers\n```\n\n## Gemini CLI Support\n\n[Gemini CLI](https://github.com/google-gemini/gemini-cli) allows Google account holders to use Gemini models without separate API credits. Models prefixed with `gemini-cli/` are routed through the Gemini CLI.\n\n**Setup:**\n\n```bash\n# Install Gemini CLI\nnpm install -g @google/gemini-cli && gemini auth\n\n# Use Gemini CLI models (prefix with gemini-cli/)\npython3 debate.py critique --models gemini-cli/gemini-3-pro-preview < spec.md\n```\n\n**Available Gemini CLI models:**\n- `gemini-cli/gemini-3-pro-preview` - Gemini 3 Pro via CLI\n- `gemini-cli/gemini-3-flash-preview` - Gemini 3 Flash via CLI\n\nCheck Gemini CLI installation status:\n\n```bash\npython3 \"$(find ~/.claude -name debate.py -path '*adversarial-spec*' 2>/dev/null | head -1)\" providers\n```\n\n## OpenAI-Compatible Endpoints\n\nFor models that expose an OpenAI-compatible API (local LLMs, self-hosted models, alternative providers), set `OPENAI_API_BASE`:\n\n```bash\n# Point to a custom endpoint\nexport OPENAI_API_KEY=\"your-key\"\nexport OPENAI_API_BASE=\"https://your-endpoint.com/v1\"\n\n# Use with any model name\npython3 debate.py critique --models gpt-4o < spec.md\n```\n\nThis works with:\n- Local LLM servers (Ollama, vLLM, text-generation-webui)\n- OpenAI-compatible providers\n- Self-hosted inference endpoints\n\n## Usage\n\n**Start from scratch:**\n\n```\n/adversarial-spec \"Build a rate limiter service with Redis backend\"\n```\n\n**Refine an existing document:**\n\n```\n/adversarial-spec ./docs/my-spec.md\n```\n\nYou will be prompted for:\n\n1. **Document type**: PRD (business/product focus) or tech spec (engineering focus)\n2. **Interview mode**: Optional in-depth requirements gathering session\n3. **Opponent models**: Comma-separated list (e.g., `gpt-4o,gemini/gemini-2.0-flash,xai/grok-3`)\n\nMore models = more perspectives = stricter convergence.\n\n## Document Types\n\n### PRD (Product Requirements Document)\n\nFor stakeholders, PMs, and designers.\n\n**Sections:** Executive Summary, Problem Statement, Target Users/Personas, User Stories, Functional Requirements, Non-Functional Requirements, Success Metrics, Scope (In/Out), Dependencies, Risks\n\n**Critique focuses on:** Clear problem definition, well-defined personas, measurable success criteria, explicit scope boundaries, no technical implementation details\n\n### Technical Specification\n\nFor developers and architects.\n\n**Sections:** Overview, Goals/Non-Goals, System Architecture, Component Design, API Design (full schemas), Data Models, Infrastructure, Security, Error Handling, Performance/SLAs, Observability, Testing Strategy, Deployment Strategy\n\n**Critique focuses on:** Complete API contracts, data model coverage, security threat mitigation, error handling, specific performance targets, no ambiguity for engineers\n\n## Core Features\n\n### Interview Mode\n\nBefore the debate begins, opt into an in-depth interview session to capture requirements upfront.\n\n**Covers:** Problem context, users/stakeholders, functional requirements, technical constraints, UI/UX, tradeoffs, risks, success criteria\n\nThe interview uses probing follow-up questions and challenges assumptions. After completion, Claude synthesizes answers into a complete spec before starting the adversarial debate.\n\n### Claude's Active Participation\n\nEach round, Claude:\n\n1. Reviews opponent critiques for validity\n2. Provides independent critique (what did opponents miss?)\n3. States agreement/disagreement with specific points\n4. Synthesizes all feedback into revisions\n\nDisplay format:\n\n```\n--- Round N ---\nOpponent Models:\n- [GPT-4o]: critiqued: missing rate limit config\n- [Gemini]: agreed\n\nClaude's Critique:\nSecurity section lacks input validation strategy. Adding OWASP top 10 coverage.\n\nSynthesis:\n- Accepted from GPT-4o: rate limit configuration\n- Added by Claude: input validation, OWASP coverage\n- Rejected: none\n```\n\n### Early Agreement Verification\n\nIf a model agrees within the first 2 rounds, Claude is skeptical. The model is pressed to:\n\n- Confirm it read the entire document\n- List specific sections reviewed\n- Explain why it agrees\n- Identify any remaining concerns\n\nThis prevents false convergence from models that rubber-stamp without thorough review.\n\n### User Review Period\n\nAfter all models agree, you enter a review period with three options:\n\n1. **Accept as-is**: Document is complete\n2. **Request changes**: Claude updates the spec, you iterate without a full debate cycle\n3. **Run another cycle**: Send the updated spec through another adversarial debate\n\n### Additional Review Cycles\n\nRun multiple cycles with different strategies:\n\n- First cycle with fast models (gpt-4o), second with stronger models (o1)\n- First cycle for structure/completeness, second for security focus\n- Fresh perspective after user-requested changes\n\n### PRD to Tech Spec Flow\n\nWhen a PRD reaches consensus, you're offered the option to continue directly into a Technical Specification based on the PRD. This creates a complete documentation pair in a single session.\n\n## Advanced Features\n\n### Critique Focus Modes\n\nDirect models to prioritize specific concerns:\n\n```bash\n--focus security      # Auth, input validation, encryption, vulnerabilities\n--focus scalability   # Horizontal scaling, sharding, caching, capacity\n--focus performance   # Latency targets, throughput, query optimization\n--focus ux            # User journeys, error states, accessibility\n--focus reliability   # Failure modes, circuit breakers, disaster recovery\n--focus cost          # Infrastructure costs, resource efficiency\n```\n\n### Model Personas\n\nHave models critique from specific professional perspectives:\n\n```bash\n--persona security-engineer      # Thinks like an attacker\n--persona oncall-engineer        # Cares about debugging at 3am\n--persona junior-developer       # Flags ambiguity and tribal knowledge\n--persona qa-engineer            # Missing test scenarios\n--persona site-reliability       # Deployment, monitoring, incidents\n--persona product-manager        # User value, success metrics\n--persona data-engineer          # Data models, ETL implications\n--persona mobile-developer       # API design for mobile\n--persona accessibility-specialist  # WCAG, screen readers\n--persona legal-compliance       # GDPR, CCPA, regulatory\n```\n\nCustom personas also work: `--persona \"fintech compliance officer\"`\n\n### Context Injection\n\nInclude existing documents for models to consider:\n\n```bash\n--context ./existing-api.md --context ./schema.sql\n```\n\nUse cases:\n- Existing API documentation the new spec must integrate with\n- Database schemas the spec must work with\n- Design documents or prior specs for consistency\n- Compliance requirements documents\n\n### Session Persistence and Resume\n\nLong debates can crash or need to pause. Sessions save state automatically:\n\n```bash\n# Start a named session\necho \"spec\" | python3 debate.py critique --models gpt-4o --session my-feature-spec\n\n# Resume where you left off\npython3 debate.py critique --resume my-feature-spec\n\n# List all sessions\npython3 debate.py sessions\n```\n\nSessions save:\n- Current spec state\n- Round number\n- All configuration (models, focus, persona, etc.)\n- History of previous rounds\n\nSessions are stored in `~/.config/adversarial-spec/sessions/`.\n\n### Auto-Checkpointing\n\nWhen using sessions, each round's spec is saved to `.adversarial-spec-checkpoints/`:\n\n```\n.adversarial-spec-checkpoints/\n├── my-feature-spec-round-1.md\n├── my-feature-spec-round-2.md\n└── my-feature-spec-round-3.md\n```\n\nUse these to rollback if a revision makes things worse.\n\n### Preserve Intent Mode\n\nConvergence can sand off novel ideas when models interpret \"unusual\" as \"wrong\". The `--preserve-intent` flag makes removal expensive:\n\n```bash\n--preserve-intent\n```\n\nWhen enabled, models must:\n\n1. **Quote exactly** what they want to remove or substantially change\n2. **Justify the harm** - not just \"unnecessary\" but what concrete problem it causes\n3. **Distinguish error from preference** - only remove things that are factually wrong, contradictory, or risky\n4. **Ask before removing** unusual but functional choices: \"Was this intentional?\"\n\nThis shifts the default from \"sand off anything unusual\" to \"add protective detail while preserving distinctive choices.\"\n\nUse when:\n- Your spec contains intentional unconventional choices\n- You want models to challenge your ideas, not homogenize them\n- Previous rounds removed things you wanted to keep\n\n### Cost Tracking\n\nEvery critique round displays token usage and estimated cost:\n\n```\n=== Cost Summary ===\nTotal tokens: 12,543 in / 3,221 out\nTotal cost: $0.0847\n\nBy model:\n  gpt-4o: $0.0523 (8,234 in / 2,100 out)\n  gemini/gemini-2.0-flash: $0.0324 (4,309 in / 1,121 out)\n```\n\n### Saved Profiles\n\nSave frequently used configurations:\n\n```bash\n# Create a profile\npython3 debate.py save-profile strict-security \\\n  --models gpt-4o,gemini/gemini-2.0-flash \\\n  --focus security \\\n  --doc-type tech\n\n# Use a profile\npython3 debate.py critique --profile strict-security < spec.md\n\n# List profiles\npython3 debate.py profiles\n```\n\nProfiles are stored in `~/.config/adversarial-spec/profiles/`.\n\n### Diff Between Rounds\n\nSee exactly what changed between spec versions:\n\n```bash\npython3 debate.py diff --previous round1.md --current round2.md\n```\n\n### Export to Task List\n\nExtract actionable tasks from a finalized spec:\n\n```bash\ncat spec-output.md | python3 debate.py export-tasks --models gpt-4o --doc-type prd\n```\n\nOutput includes title, type, priority, description, and acceptance criteria.\n\nUse `--json` for structured output suitable for importing into issue trackers.\n\n## Telegram Integration (Optional)\n\nGet notified on your phone and inject feedback during the debate.\n\n**Setup:**\n\n1. Message @BotFather on Telegram, send `/newbot`, follow prompts\n2. Copy the bot token\n3. Run: `python3 \"$(find ~/.claude -name telegram_bot.py -path '*adversarial-spec*' 2>/dev/null | head -1)\" setup`\n4. Message your bot, run setup again to get your chat ID\n5. Set environment variables:\n\n```bash\nexport TELEGRAM_BOT_TOKEN=\"...\"\nexport TELEGRAM_CHAT_ID=\"...\"\n```\n\n**Features:**\n\n- Async notifications when rounds complete (includes cost)\n- 60-second window to reply with feedback (incorporated into next round)\n- Final document sent to Telegram when debate concludes\n\n## Output\n\nFinal document is:\n\n- Complete, following full structure for document type\n- Vetted by all models until unanimous agreement\n- Ready for stakeholders without further editing\n\nOutput locations:\n\n- Printed to terminal\n- Written to `spec-output.md` (PRD) or `tech-spec-output.md` (tech spec)\n- Sent to Telegram (if enabled)\n\nDebate summary includes rounds completed, cycles run, models involved, Claude's contributions, cost, and key refinements made.\n\n## CLI Reference\n\n```bash\n# Core commands\ndebate.py critique --models MODEL_LIST --doc-type TYPE [OPTIONS] < spec.md\ndebate.py critique --resume SESSION_ID\ndebate.py diff --previous OLD.md --current NEW.md\ndebate.py export-tasks --models MODEL --doc-type TYPE [--json] < spec.md\n\n# Info commands\ndebate.py providers      # List providers and API key status\ndebate.py focus-areas    # List focus areas\ndebate.py personas       # List personas\ndebate.py profiles       # List saved profiles\ndebate.py sessions       # List saved sessions\n\n# Profile management\ndebate.py save-profile NAME --models ... [--focus ...] [--persona ...]\n\n# Bedrock management\ndebate.py bedrock status                      # Show Bedrock configuration\ndebate.py bedrock enable --region REGION      # Enable Bedrock mode\ndebate.py bedrock disable                     # Disable Bedrock mode\ndebate.py bedrock add-model MODEL             # Add model to available list\ndebate.py bedrock remove-model MODEL          # Remove model from list\ndebate.py bedrock list-models                 # List built-in model mappings\n```\n\n**Options:**\n- `--models, -m` - Comma-separated model list (auto-detects from available API keys if not specified)\n- `--doc-type, -d` - prd or tech\n- `--codex-reasoning` - Reasoning effort for Codex models (low, medium, high, xhigh; default: xhigh)\n- `--focus, -f` - Focus area (security, scalability, performance, ux, reliability, cost)\n- `--persona` - Professional persona\n- `--context, -c` - Context file (repeatable)\n- `--profile` - Load saved profile\n- `--preserve-intent` - Require justification for removals\n- `--session, -s` - Session ID for persistence and checkpointing\n- `--resume` - Resume a previous session\n- `--press, -p` - Anti-laziness check\n- `--telegram, -t` - Enable Telegram\n- `--json, -j` - JSON output\n\n## File Structure\n\n```\nadversarial-spec/\n├── .claude-plugin/\n│   └── plugin.json           # Plugin metadata\n├── README.md\n├── LICENSE\n└── skills/\n    └── adversarial-spec/\n        ├── SKILL.md          # Skill definition and process\n        └── scripts/\n            ├── debate.py     # Multi-model debate orchestration\n            └── telegram_bot.py   # Telegram notifications\n```\n\n## License\n\nMIT\n"
      },
      "plugins": [
        {
          "name": "adversarial-spec",
          "description": "Iteratively refine product specs through multi-model debate until consensus",
          "source": "./",
          "keywords": [
            "spec",
            "prd",
            "technical-specification",
            "llm",
            "debate",
            "consensus"
          ],
          "skills": [
            "./skills/adversarial-spec"
          ],
          "categories": [
            "consensus",
            "debate",
            "llm",
            "prd",
            "spec",
            "technical-specification"
          ],
          "install_commands": [
            "/plugin marketplace add zscole/adversarial-spec",
            "/plugin install adversarial-spec@adversarial-spec"
          ]
        }
      ]
    }
  ]
}