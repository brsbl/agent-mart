{
  "author": {
    "id": "abagames",
    "display_name": "ABA Games",
    "avatar_url": "https://avatars.githubusercontent.com/u/2502899?u=103cf106bc0d632ad730dce3b2e975dd59221302&v=4"
  },
  "marketplaces": [
    {
      "name": "criticalthink",
      "version": null,
      "description": "Critical thinking command for Claude Code - helps analyze AI responses for assumptions, logical flaws, and overlooked risks",
      "repo_full_name": "abagames/slash-criticalthink",
      "repo_url": "https://github.com/abagames/slash-criticalthink",
      "repo_description": "The `criticalthink` command is a custom command that embeds healthy skepticism into the dialogue process itself as a countermeasure against AI's \"confirmation bias\" and humans' \"authority bias\" of blindly trusting AI responses.",
      "signals": {
        "stars": 89,
        "forks": 7,
        "pushed_at": "2025-10-11T00:16:31Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"criticalthink\",\n  \"owner\": {\n    \"name\": \"abagames\"\n  },\n  \"metadata\": {\n    \"description\": \"Critical thinking command for Claude Code - helps analyze AI responses for assumptions, logical flaws, and overlooked risks\",\n    \"version\": \"1.0.0\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"criticalthink\",\n      \"source\": \"./\",\n      \"description\": \"Critical thinking analysis command for AI-generated responses\",\n      \"version\": \"1.0.0\",\n      \"author\": {\n        \"name\": \"abagames\"\n      },\n      \"homepage\": \"https://github.com/abagames/slash-criticalthink\",\n      \"repository\": \"https://github.com/abagames/slash-criticalthink\",\n      \"license\": \"MIT\",\n      \"keywords\": [\n        \"critical-thinking\",\n        \"analysis\",\n        \"reasoning\",\n        \"assumptions\",\n        \"logic\",\n        \"risk-assessment\",\n        \"ai-safety\",\n        \"quality-assurance\"\n      ],\n      \"category\": \"essentials\",\n      \"strict\": false,\n      \"commands\": [\n        \"./criticalthink.md\"\n      ]\n    }\n  ]\n}\n",
        "README.md": "# slash-criticalthink\n\nEnglish | [日本語](README_ja.md)\n\n## Overview\n\nModern LLMs (Large Language Models) excel at generating confident, plausible-sounding responses. However, these responses often ignore real-world constraints or contain logical flaws.\n\nThe `criticalthink` command is a custom command that embeds healthy skepticism into the dialogue process itself as a countermeasure against AI's \"confirmation bias\" and humans' \"authority bias\" of blindly trusting AI responses. By having the AI critically analyze its own previous response, it reveals hidden assumptions and overlooked risks.\n\n### Target Audience\n\n- Developers who routinely use coding agents (Claude Code / Codex CLI, etc.)\n- Engineers who want to critically verify AI suggestions rather than accepting them at face value\n\n## Setup\n\n### Option 1: Manual Installation\n\n1. Place the command file in the appropriate directory for your tool:\n\n   - **Claude Code**: `.claude/commands/criticalthink.md` (in project root or home directory)\n   - **Codex CLI**: `~/.codex/prompts/criticalthink.md` (in home directory)\n   - **Gemini CLI**: `.gemini/commands/criticalthink.toml` (in project root)\n\n2. Create directory and copy file:\n\n   For Claude Code:\n\n   ```bash\n   mkdir -p .claude/commands\n   cp criticalthink.md .claude/commands/\n   ```\n\n   For Codex CLI:\n\n   ```bash\n   mkdir -p ~/.codex/prompts\n   cp criticalthink.md ~/.codex/prompts/\n   ```\n\n   For Gemini CLI:\n\n   ```bash\n   mkdir -p .gemini/commands\n   cp commands/criticalthink.toml .gemini/commands/\n   ```\n\n### Option 2: Install via Plugin Marketplace (for Claude Code)\n\nRun these commands inside Claude Code:\n\n1. Add this repository to your plugin marketplace:\n\n   ```\n   /plugin marketplace add https://github.com/abagames/slash-criticalthink.git\n   ```\n\n2. Install the criticalthink command:\n\n   ```\n   /plugin install criticalthink\n   ```\n\n### Option 3: Install as Gemini CLI Extension (for Gemini CLI)\n\nInstall directly from GitHub:\n\n```bash\ngemini extensions install https://github.com/abagames/slash-criticalthink\n```\n\n### Verify Installation\n\nAfter installation, restart your tool and verify it works:\n\n```\nUser: What is 2 + 2?\nAI: 4\nUser: /criticalthink\n```\n\nIf critical analysis begins, it's working\n\n## Usage\n\n### Basic Usage\n\nType `/criticalthink` immediately after the AI generates a response. The AI will analyze its previous response from the following perspectives:\n\n- Validity of assumptions\n- Logical consistency\n- Overlooked risks\n- AI-specific failure patterns (problem avoidance, happy path bias, over-engineering, hallucination, etc.)\n\n### Usage Examples\n\n#### Case 1: When receiving a complex architecture proposal\n\n```\nUser: I want to implement microservices, how should I design it?\nClaude: I propose a configuration with Kubernetes + Istio + gRPC as follows...\n       [Detailed design proposal]\nUser: /criticalthink\nClaude: ### 1. Core Thesis & Confidence Score (Initial)\n       - **1-1. Core Thesis:** A Kubernetes-based full-stack solution\n         is optimal for microservices architecture\n       - **1-2. Initial Confidence:** 8/10\n\n       ### 2. Foundational Analysis: Assumptions & Context\n       - **2-1. High-Impact Assumptions:**\n         1. Team has Kubernetes operational experience\n         2. Traffic scale justifies orchestration adoption\n         3. Initial investment and learning costs are acceptable\n       ...\n```\n\n#### Case 2: When receiving a response claiming a \"perfect solution\"\n\n```\nUser: How should I implement rate limiting for this API?\nClaude: You can implement it perfectly with Redis + Sliding Window algorithm.\n       With the following code...\nUser: /criticalthink\nClaude: ### 3. AI-Specific Pitfall Analysis\n       - **3-2. \"Happy Path\" Bias:** Fail\n         Reason: No consideration of fallback strategy during Redis failure\n       - **4-1. Overlooked Risks:**\n         1. Redis becomes a SPOF (Single Point of Failure)\n         2. Network latency affects all requests\n         3. Redis memory usage estimation not performed\n       ...\n```\n\n#### Case 3: When proposed major refactoring of existing code\n\n```\nUser: I want to modernize this legacy code\nClaude: Let's rewrite everything in TypeScript + React Hooks...\nUser: /criticalthink\nClaude: ### 3. AI-Specific Pitfall Analysis\n       - **3-3. Over-Engineering:** Fail\n         Reason: Proposing complete rewrite instead of gradual migration\n       - **4-2. Alternative Scenarios:**\n         Gradual migration strategy: First add type definition files (.d.ts),\n         then gradually TypeScript-ify starting from critical paths.\n         This approach reduces business risk and costs.\n       ...\n```\n\n#### Case 4: When receiving informational summaries without verification\n\n```\nUser: Review the README.md\nClaude: This README describes slash-criticalthink, a custom command for AI coding assistants...\n       [Summary of contents]\nUser: /criticalthink\nClaude: ### 2. Foundational Analysis: Assumptions & Context\n       - **2-1. High-Impact Assumptions:**\n         1. The user wanted a summary rather than specific information extraction\n         2. The criticalthink.md file actually exists in this repository\n         3. The user has context about what slash commands are\n       - **2-2. Contextual Integrity:** I assumed the user's intent without clarification:\n         \"Review\" could mean summarize, analyze quality, check for errors, verify\n         completeness, or prepare to use/modify.\n\n       ### 3. AI-Specific Pitfall Analysis\n       - **3-2. \"Happy Path\" Bias:** Fail\n         Reason: Didn't verify whether criticalthink.md actually exists or check\n         if .claude/commands/ directory is present\n\n       ### 5. Synthesis & Revised Recommendation\n       - **5-3. Actionable Next Step:** First, clarify what aspect of the README\n         you want reviewed: (a) content summary (already done), (b) verify the\n         slash command is installed and working, (c) critique the documentation\n         quality, or (d) help you set it up/use it.\n```\n\n### Removing Unnecessary Analysis from History (Recommended)\n\nSince the `/criticalthink` command makes the AI self-criticize, **erroneous concerns or overly negative analysis may remain in the dialogue history and distort the AI's subsequent thinking** (context contamination).\n\nTo avoid this, the following workflow is recommended:\n\n1. Receive a proposal from the AI\n2. Run `/criticalthink` for critical analysis\n3. Review the analysis results\n4. **If the analysis is unnecessary, press `Esc-Esc` to rewind to your previous message** and return to before running `/criticalthink` (removing the critical analysis from history)\n5. Continue with a new question or request improvements from the AI\n\nThis allows you to benefit from critical thinking while avoiding context contamination.\n\n## Design Philosophy\n\n### General Framework\n\nBased on a general critical thinking framework applicable to any claim.\n\n- **Identify the claim:** Identify the key points of the AI's own response\n- **Extract assumptions:** Expose implicit assumptions behind the response\n- **Verify logical fallacies:** Look for logical leaps or contradictions\n- **Present alternatives:** Offer alternative perspectives or solutions not considered\n\n### AI-Specific Failure Pattern Analysis\n\nThe general framework alone risked falling into \"formal and superficial criticism.\" To overcome this, we incorporated failure patterns specific to LLMs and coding agents into the analysis items.\n\n- **Problem avoidance:** Is it pretending to solve core problems with mocks or placeholders?\n- **Happy path fixation:** Is it ignoring error handling or edge cases?\n- **Over-engineering:** Is it proposing unnecessary libraries or complex solutions?\n- **Hallucination:** Is it fabricating non-existent functions or APIs?\n- **Context ignorance:** Is it ignoring constraints from previous dialogue?\n\nFor these items, the command asks the AI for explicit Pass/Fail self-evaluation.\n\n## Caveats and Limitations\n\n### Use as Training Wheels for Thinking\n\nThis command is a guideline for finding gaps in your own thinking. Use AI's critical analysis not as the \"correct answer\" but as a tool to gain new perspectives.\n\n### Responsibility\n\nThe final judgment is always made by humans. AI's criticism is also just one generated artifact that should be critically examined. Pay special attention to:\n\n- AI cannot fully recognize errors in its own responses\n- Critical analysis itself may introduce new biases\n- May include overly conservative warnings (alerts for areas that are actually fine)\n\n### Spirit of Mutual Criticism\n\nUsers doubt AI responses while simultaneously using AI (and commands) to doubt their own assumptions and biases. This mutual criticism process leads to more robust decision-making.\n\n### Performance Impact\n\nCritical analysis consumes additional tokens and increases response time. Rather than applying it to all responses, selective use is recommended before important decisions such as:\n\n- Architecture decisions\n- Large-scale refactoring\n- Security or performance-related implementations\n- Introduction of external dependencies\n\n## Related Work: Comparison with CQoT\n\nThe approach of introducing a self-critical process to AI to improve its reasoning capabilities has also attracted attention in academic research. Particularly notable is the paper \"Critical-Questions-of-Thought (CQoT)\" by Federico Castagna et al.\n\n### Shared Purpose\n\nCQoT and `/criticalthink` share the common purpose of \"improving the quality and reliability of output by having AI perform metacognitive self-evaluation.\" Both introduce a step to verify the reasoning process behind responses rather than simply generating a single answer and stopping.\n\n### Fundamental Differences in Approach\n\nWhile sharing a common purpose, they differ in their objectives and methodologies.\n\n| Comparison    | **CQoT (Academic Paper)**                                                          | **`/criticalthink` (This Tool)**                                                                |\n| :------------ | :--------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------- |\n| **Main Goal** | **Pursuit of Logical Soundness**                                                   | **Verification of Practical Viability**                                                         |\n| **Domain**    | Math problems, logic puzzles, etc., **domains with clear correct answers**         | Software design, refactoring, etc., **domains with trade-offs**                                 |\n| **Timing**    | **Integrated, automated pipeline before** answer generation                        | **Post-hoc analysis tool after** answer generation                                              |\n| **Criteria**  | Universal logical principles<br>(e.g., Are premises clear? Is conclusion derived?) | AI and development-specific failure patterns<br>(e.g., happy path bias, over-engineering, SPOF) |\n\n### Uniqueness of `/criticalthink`\n\nIn summary, while CQoT aims to make AI a better **\"logician,\"** `/criticalthink` aims to make AI a wiser **\"design review partner\"** for developers. This tool specializes in uncovering real-world risks, costs, and trade-offs—including alternative approaches—that cannot be measured by theoretical correctness alone, which developers face in practice. While CQoT is a closed-loop system that automatically corrects flaws in the reasoning process, `/criticalthink` is an open-loop tool that provides insights for humans to make final judgments.\n"
      },
      "plugins": [
        {
          "name": "criticalthink",
          "source": "./",
          "description": "Critical thinking analysis command for AI-generated responses",
          "version": "1.0.0",
          "author": {
            "name": "abagames"
          },
          "homepage": "https://github.com/abagames/slash-criticalthink",
          "repository": "https://github.com/abagames/slash-criticalthink",
          "license": "MIT",
          "keywords": [
            "critical-thinking",
            "analysis",
            "reasoning",
            "assumptions",
            "logic",
            "risk-assessment",
            "ai-safety",
            "quality-assurance"
          ],
          "category": "essentials",
          "strict": false,
          "commands": [
            "./criticalthink.md"
          ],
          "categories": [
            "ai-safety",
            "analysis",
            "assumptions",
            "critical-thinking",
            "essentials",
            "logic",
            "quality-assurance",
            "reasoning",
            "risk-assessment"
          ],
          "install_commands": [
            "/plugin marketplace add abagames/slash-criticalthink",
            "/plugin install criticalthink@criticalthink"
          ]
        }
      ]
    }
  ]
}