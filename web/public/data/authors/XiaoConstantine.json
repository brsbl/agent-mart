{
  "author": {
    "id": "XiaoConstantine",
    "display_name": "Xiao",
    "avatar_url": "https://avatars.githubusercontent.com/u/3046977?u=e3cb3c71bdab9a3e3f84b32acd0dcb6a9ae417c8&v=4"
  },
  "marketplaces": [
    {
      "name": "sgrep",
      "version": null,
      "description": "Smart semantic + hybrid code search",
      "repo_full_name": "XiaoConstantine/sgrep",
      "repo_url": "https://github.com/XiaoConstantine/sgrep",
      "repo_description": "CLI for semantic grep",
      "signals": {
        "stars": 8,
        "forks": 2,
        "pushed_at": "2026-01-20T00:10:40Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"$schema\": \"https://anthropic.com/claude-code/marketplace.schema.json\",\n  \"name\": \"sgrep\",\n  \"owner\": {\n    \"name\": \"XiaoConstantine\",\n    \"email\": \"constantine124@gmail.com\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"sgrep\",\n      \"source\": \"./plugins/sgrep\",\n      \"description\": \"Smart semantic + hybrid code search\",\n      \"version\": \"0.1.0\",\n      \"author\": {\n        \"name\": \"Xiao Cui\"\n      },\n      \"skills\": [\"./skills/sgrep\"]\n    }\n  ]\n}\n",
        "README.md": "# sgrep - Smart Grep for Code\n\n**Semantic + hybrid code search that complements `ripgrep` and `ast-grep`.**\n\n```\n┌─────────────────────────────────────────────────────────────────┐\n│  ripgrep (rg)     │  ast-grep (sg)    │  sgrep              │\n│  ─────────────    │  ──────────────   │  ──────             │\n│  Exact text/regex │  AST patterns     │  Semantic + hybrid  │\n│  \"findUser\"       │  $fn($args)       │  \"auth validation\"  │\n└─────────────────────────────────────────────────────────────────┘\n```\n\n## Why sgrep?\n\nCoding agents (Amp, Claude Code, Cursor) waste tokens on failed `grep` attempts when searching for concepts rather than exact strings. `sgrep` understands **what you mean**, not just what you type.\n\n```bash\n# ❌ Agent tries 10+ grep patterns, burns 2000 tokens\nrg \"authenticate\" && rg \"auth\" && rg \"login\" && rg \"session\" ...\n\n# ✅ One semantic query, 50 tokens\nsgrep \"how does user authentication work\"\n```\n\n## Installation\n\n### Homebrew (macOS/Linux)\n\n```bash\nbrew tap XiaoConstantine/tap\nbrew install sgrep\n```\n\n### Quick Install (curl)\n\n```bash\ncurl -fsSL https://raw.githubusercontent.com/XiaoConstantine/sgrep/main/install.sh | bash\n```\n\n### Go Install\n\n```bash\ngo install github.com/XiaoConstantine/sgrep/cmd/sgrep@latest\n```\n\n### From Source\n\n```bash\ngit clone https://github.com/XiaoConstantine/sgrep.git\ncd sgrep\n\n# Default build (uses libSQL with DiskANN vector search)\ngo build -o sgrep ./cmd/sgrep\n\n# Alternative: sqlite-vec backend\ngo build -tags=sqlite_vec -o sgrep ./cmd/sgrep\n```\n\n**Requirements**: llama.cpp (for the embedding server)\n```bash\nbrew install llama.cpp   # macOS\n# or build from source: https://github.com/ggerganov/llama.cpp\n```\n\n### As Library\n\n```bash\ngo get github.com/XiaoConstantine/sgrep@latest\n```\n\n## Quick Start\n\n```bash\n# One-time setup: downloads embedding model (~130MB)\nsgrep setup\n\n# Index your codebase (auto-starts embedding server)\nsgrep index .\n\n# Semantic search (quick)\nsgrep \"error handling for database connections\"\n\n# Hybrid + ColBERT (recommended - best accuracy)\nsgrep --hybrid --colbert \"JWT token validation logic\"\nsgrep --hybrid --colbert \"how are API rate limits implemented\"\n\n# Hybrid with custom weights\nsgrep --hybrid --colbert \"authentication middleware\" --semantic-weight 0.5 --bm25-weight 0.5\n\n# Watch mode (background indexing)\nsgrep watch .\n```\n\nThe embedding server starts automatically when needed and stays running as a daemon.\n\n## Conversation Search\n\nSearch across conversations from Claude Code, Codex CLI, Cursor, and OpenCode.\n\n```bash\n# Index conversations (auto-starts embedding server)\nsgrep conv index\n\n# Index a single agent\nsgrep conv index --source claude\nsgrep conv index --source codex\nsgrep conv index --source cursor\nsgrep conv index --source opencode\n\n# Watch mode (auto-index new conversations)\nsgrep conv index --watch\n\n# Search conversations\nsgrep conv \"authentication\"\nsgrep conv \"JWT token\" --hybrid\nsgrep conv \"database migration\" --agent claude --since 7d\n\n# View, export, or resume a session\nsgrep conv view <session_id>\nsgrep conv export <session_id> -o conversation.md\nsgrep conv resume <session_id>\n\n# Extract context for injection into new session\nsgrep conv context <session_id>\n\n# Copy to clipboard\nsgrep conv copy <session_id>\n\n# Check index status\nsgrep conv status\n```\n\n**Watch mode** monitors conversation directories for all agents and automatically indexes new sessions as they're created. This ensures your conversation search stays up-to-date without manual re-indexing.\n\nConversations are stored at `~/.sgrep/conversations/conv.db`. Re-running\n`sgrep conv index` backfills missing embeddings for existing sessions.\n\n## Hybrid Search\n\nHybrid search combines **semantic understanding** with **lexical matching (BM25)** for improved accuracy. This helps when:\n- Searching for specific technical terms (e.g., \"JWT\", \"OAuth\", \"mutex\")\n- The query contains exact function/variable names\n- Semantic search alone misses exact keyword matches\n\n```bash\n# Default: semantic-only search\nsgrep \"authentication\"\n\n# Hybrid: semantic (60%) + BM25 (40%) - default weights\nsgrep --hybrid \"authentication\"\n\n# Custom weights: more emphasis on exact matches\nsgrep --hybrid --semantic-weight 0.4 --bm25-weight 0.6 \"parseAST\"\n```\n\n**Note**: Hybrid search requires building with FTS5 support (see [From Source](#from-source)). The FTS5 index is created automatically on first hybrid search - no re-indexing needed.\n\n## Multi-Stage Retrieval Pipeline\n\nsgrep uses a sophisticated multi-stage retrieval pipeline for maximum accuracy:\n\n```\nQuery: \"authentication middleware\"\n         ↓\n┌─────────────────────────────────────────────────────────────────┐\n│ Stage 1: Hybrid Retrieval (--hybrid)                            │\n│ ┌───────────────┐    ┌───────────────┐                         │\n│ │   Semantic    │    │     BM25      │                         │\n│ │  (DiskANN)    │    │    (FTS5)     │                         │\n│ │     60%       │    │     40%       │                         │\n│ └───────┬───────┘    └───────┬───────┘                         │\n│         └────────┬───────────┘                                  │\n│                  ↓                                              │\n│         Top 50 candidates                                       │\n└─────────────────────────────────────────────────────────────────┘\n                   ↓\n┌─────────────────────────────────────────────────────────────────┐\n│ Stage 2: ColBERT Late Interaction (--colbert)                   │\n│ ┌───────────────────────────────────────────────────────────┐  │\n│ │  Token-level similarity: MaxSim(query_tokens, doc_tokens) │  │\n│ │  Scores all 50 candidates with fine-grained matching      │  │\n│ └───────────────────────────────────────────────────────────┘  │\n│                  ↓                                              │\n│         Re-scored candidates                                    │\n└─────────────────────────────────────────────────────────────────┘\n                   ↓\n┌─────────────────────────────────────────────────────────────────┐\n│ Stage 3: Cross-Encoder Reranking (--rerank)                     │\n│ ┌───────────────────────────────────────────────────────────┐  │\n│ │  Full attention: query ⊗ document → relevance score       │  │\n│ │  Reranks top 20 ColBERT results (~300-700ms)              │  │\n│ └───────────────────────────────────────────────────────────┘  │\n│                  ↓                                              │\n│         Final ranked results                                    │\n└─────────────────────────────────────────────────────────────────┘\n```\n\n### Retrieval Modes\n\n| Mode | Command | MRR | Latency | Best For |\n|------|---------|-----|---------|----------|\n| Semantic only | `sgrep \"query\"` | 0.61 | ~30ms | Quick searches |\n| **Hybrid + ColBERT** | `sgrep --hybrid --colbert \"query\"` | **0.70** | ~200ms | **Best accuracy for code** |\n| Hybrid | `sgrep --hybrid \"query\"` | 0.62 | ~50ms | Exact term matching |\n| Cascade (all 3 stages) | `sgrep --hybrid --colbert --rerank \"query\"` | 0.60 | ~500ms | General text (not code) |\n\n**Recommended for code**: Use `--hybrid --colbert`. ColBERT provides +13% MRR over plain hybrid.\n\n> **Note**: Cross-encoder reranking adds a third stage but currently hurts code search accuracy (MRR drops from 0.70 to 0.60). This is because available cross-encoder models (mxbai-rerank) are trained on general text, not code. Cross-encoder may help for non-code search tasks.\n\n```bash\n# Best accuracy (recommended)\nsgrep --hybrid --colbert \"authentication middleware\"\n\n# Quick search (semantic only)\nsgrep \"error handling\"\n\n# With custom weights\nsgrep --hybrid --colbert --semantic-weight 0.5 --bm25-weight 0.5 \"JWT token\"\n```\n\n### Setup\n\n```bash\n# Basic setup (embedding model only, ~130MB)\nsgrep setup\n\n# With cross-encoder reranking (~1.6GB additional)\nsgrep setup --with-rerank\n```\n\n**Note**: ColBERT scoring uses the same embedding model—no additional setup required. Cross-encoder reranking requires a separate model download.\n\n## Document-Level Search\n\nsgrep automatically handles meta-queries about your repository:\n\n```bash\n# These queries use document-level embeddings\nsgrep \"what does this repo do\"\nsgrep \"project overview\"\nsgrep \"purpose of this codebase\"\n```\n\nDocument-level embeddings (mean of chunk embeddings per file) are computed during indexing, enabling README.md and other overview files to rank highly for repository-level questions.\n\n## Agent-Optimized Output\n\nDefault output is minimal for token efficiency:\n\n```bash\n$ sgrep \"authentication middleware\"\nauth/middleware.go:45-67\nauth/jwt.go:12-38\nhandlers/login.go:89-112\n```\n\nUse `-c` for context (still concise):\n```bash\n$ sgrep -c \"authentication middleware\"\nauth/middleware.go:45-67\n  func AuthMiddleware(next http.Handler) http.Handler {\n      token := r.Header.Get(\"Authorization\")\n      ...\n\nauth/jwt.go:12-38\n  func ValidateJWT(token string) (*Claims, error) {\n      ...\n```\n\nJSON output for programmatic use:\n```bash\n$ sgrep --json \"authentication\"\n[{\"file\":\"auth/middleware.go\",\"start\":45,\"end\":67,\"score\":0.92}]\n```\n\n## Combining with ripgrep and ast-grep\n\n**The search hierarchy for agents:**\n\n1. **sgrep** - Find the right files/functions by intent\n2. **ast-grep** - Match structural patterns in those files  \n3. **ripgrep** - Exact text search for specific symbols\n\nExample workflow:\n```bash\n# Step 1: Semantic search to find relevant code\nsgrep \"rate limiting implementation\" \n# → api/ratelimit.go:20-80\n\n# Step 2: AST pattern to find all similar usages\nsg -p 'rateLimiter.Check($ctx, $key)' \n\n# Step 3: Exact search for specific constant\nrg \"RATE_LIMIT_MAX\"\n```\n\n## Storage\n\nAll data is stored in `~/.sgrep/`:\n```\n~/.sgrep/\n├── models/\n│   └── nomic-embed-text-v1.5.Q8_0.gguf   # Embedding model (~130MB)\n├── repos/\n│   ├── a1b2c3/              # Hash of /path/to/repo1\n│   │   ├── index.db         # libSQL database with DiskANN vectors\n│   │   └── metadata.json    # Repo path, index time\n│   └── d4e5f6/              # Hash of /path/to/repo2\n│       └── ...\n├── server.pid               # Embedding server PID\n└── server.log               # Embedding server logs\n```\n\nUse `sgrep list` to see all indexed repositories.\n\n## Storage Backends\n\nsgrep supports two vector storage backends:\n\n| Backend | Build Command | Storage Efficiency | Best For |\n|---------|--------------|-------------------|----------|\n| **libSQL** (default) | `go build ./cmd/sgrep` | ~5-10 KB/vector | Large repos, production |\n| sqlite-vec | `go build -tags=sqlite_vec ./cmd/sgrep` | ~780 KB/vector | Development, compatibility |\n\n**libSQL advantages:**\n- Uses DiskANN for approximate nearest neighbor search\n- 93-177x more space-efficient than sqlite-vec\n- Native F32_BLOB column type for vectors\n- Compress neighbors option for index compression\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `sgrep [query]` | Semantic search (default) |\n| `sgrep index [path]` | Index a directory |\n| `sgrep watch [path]` | Watch and auto-index |\n| `sgrep list` | List all indexed repos |\n| `sgrep status` | Show index status |\n| `sgrep clear` | Clear index |\n| `sgrep setup` | Download embedding model, verify llama-server |\n| `sgrep setup --with-rerank` | Also download reranker model (~636MB) |\n| `sgrep server start` | Manually start embedding server |\n| `sgrep server stop` | Stop embedding server |\n| `sgrep server status` | Show server status |\n| `sgrep install-claude-code` | Install Claude Code plugin |\n\n## Claude Code Integration\n\nInstall the sgrep plugin for Claude Code with one command:\n\n```bash\nsgrep install-claude-code\n```\n\nThis creates a plugin at `~/.claude/plugins/sgrep` that:\n- **Auto-indexes** your project when Claude Code starts\n- **Watch mode** keeps the index updated as you code\n- **Skill documentation** teaches Claude when to use sgrep vs ripgrep\n\nAfter installation, restart Claude Code to activate. The plugin works automatically—Claude will use sgrep for semantic searches like \"how does authentication work\" while using ripgrep for exact matches.\n\n## Flags\n\n| Flag | Description |\n|------|-------------|\n| `-n, --limit N` | Max results (default: 10) |\n| `-c, --context` | Show code context |\n| `--json` | JSON output for agents |\n| `-q, --quiet` | Minimal output (paths only) |\n| `--threshold F` | L2 distance threshold (default: 1.5, lower = stricter) |\n| `-t, --include-tests` | Include test files in results (excluded by default) |\n| `--all-chunks` | Show all matching chunks (disable deduplication) |\n| `--hybrid` | Enable hybrid search (semantic + BM25) |\n| `--colbert` | Enable ColBERT late interaction scoring (recommended with --hybrid) |\n| `--semantic-weight F` | Weight for semantic score in hybrid mode (default: 0.6) |\n| `--bm25-weight F` | Weight for BM25 score in hybrid mode (default: 0.4) |\n| `--rerank` | Enable cross-encoder reranking (requires `sgrep setup --with-rerank`) |\n| `-d, --debug` | Show debug timing information |\n\n## Configuration\n\nEnvironment variables:\n```bash\nSGREP_HOME=~/.sgrep                    # Data storage location\nSGREP_ENDPOINT=http://localhost:8080   # Override embedding server URL\nSGREP_PORT=8080                        # Embedding server port\nSGREP_DIMS=768                         # Vector dimensions\n```\n\n## How It Works\n\n1. **Setup**: `sgrep setup` downloads the embedding model and verifies llama-server\n2. **Indexing**: Files are chunked using AST-aware splitting (Go, TS, Python) or size-based fallback\n3. **Embedding**: Each chunk is embedded via llama.cpp (local, $0 cost, auto-started)\n4. **Storage**: Vectors stored in libSQL with DiskANN indexing\n5. **Search**: Query embedded → DiskANN approximate nearest neighbor → load matching documents\n\n**Smart skip for large repos**: When indexing repos with >1000 files, sgrep automatically filters out test files, generated code (*.pb.go, *.generated.go), and vendored directories to speed up indexing.\n\n## Architecture\n\n```\n┌──────────────────────────────────────────────────────────────┐\n│                         sgrep                                │\n├──────────────────────────────────────────────────────────────┤\n│  Query: \"error handling\"                                     │\n│         ↓                                                    │\n│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐      │\n│  │ llama.cpp   │───▶│  DiskANN    │───▶│   libSQL    │      │\n│  │ Embedding   │    │ + BM25/FTS5 │    │  Documents  │      │\n│  │   (~15ms)   │    │   (~10ms)   │    │   (~5ms)    │      │\n│  └─────────────┘    └─────────────┘    └─────────────┘      │\n│       ▲                    │                                 │\n│       │                    ▼ (with --colbert)                │\n│       │              ┌─────────────┐                         │\n│       │              │  ColBERT    │                         │\n│       │              │ Late-Interx │                         │\n│       │              │  (~150ms)   │                         │\n│       │              └──────┬──────┘                         │\n│       │                     │                                │\n│       │                     ▼ (with --rerank)                │\n│       │              ┌─────────────┐                         │\n│       │              │Cross-Encoder│                         │\n│       │              │  Reranker   │                         │\n│       │              │ (~300-700ms)│                         │\n│       │              └─────────────┘                         │\n│       │                                                      │\n│       │ Auto-started by sgrep (16 parallel slots)           │\n│       │ (daemon mode, continuous batching)                  │\n│                                                              │\n│  Recommended: --hybrid --colbert (~200ms, MRR 0.70)         │\n└──────────────────────────────────────────────────────────────┘\n```\n\n### Hybrid Search Architecture\n\nWhen `--hybrid` is enabled, sgrep combines semantic and lexical search:\n\n```\nQuery: \"authentication middleware\"\n         ↓\n  ┌──────────────────────────────────────────────────────┐\n  │                                                      │\n  │  ┌─────────────┐         ┌─────────────┐           │\n  │  │  Semantic   │         │    BM25     │           │\n  │  │  (Vectors)  │         │   (FTS5)    │           │\n  │  │    60%      │         │    40%      │           │\n  │  └──────┬──────┘         └──────┬──────┘           │\n  │         │                       │                   │\n  │         └───────┬───────────────┘                   │\n  │                 ↓                                   │\n  │         ┌─────────────┐                            │\n  │         │   Hybrid    │                            │\n  │         │   Ranking   │                            │\n  │         └─────────────┘                            │\n  │                                                      │\n  └──────────────────────────────────────────────────────┘\n```\n\n- **Semantic**: Understands intent (\"auth\" matches \"authentication\", \"login\", \"session\")\n- **BM25**: Exact term matching with TF-IDF weighting (boosts exact \"authentication\" matches)\n\n## Performance\n\nBenchmarked on maestro codebase (102 files, 1572 chunks, 768-dim vectors):\n\n| Metric | sgrep | ripgrep | \n|--------|-------|---------|\n| Latency (avg) | **31ms** | 10ms |\n| Token usage | **57% less** | baseline |\n| Attempts needed | 1 | 3-7 |\n\n**Embedding server optimization:**\n\nThe llama.cpp server is configured for maximum throughput:\n- 16 parallel slots with continuous batching (`-cb`)\n- Dynamic thread count based on CPU cores\n- GPU acceleration (Metal on Mac, CUDA on Linux)\n\n## Chunk Size Limits\n\nThe embedding model (nomic-embed-text) has a 2048 token context limit. sgrep handles this by:\n\n1. Default chunk size: 1000 tokens (with AST-aware splitting)\n2. Safety truncation at 1500 tokens in embedder\n3. Large functions/types split into parts automatically\n\n## Library Usage\n\nUse sgrep as an embedded library in your Go application:\n\n```go\npackage main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"log\"\n\n    \"github.com/XiaoConstantine/sgrep\"\n)\n\nfunc main() {\n    ctx := context.Background()\n    \n    // Create client for a codebase\n    client, err := sgrep.New(\"/path/to/codebase\")\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer client.Close()\n\n    // Index the codebase (required before searching)\n    if err := client.Index(ctx); err != nil {\n        log.Fatal(err)\n    }\n\n    // Search for code by semantic intent\n    results, err := client.Search(ctx, \"authentication logic\", 10)\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    for _, r := range results {\n        fmt.Printf(\"%s:%d-%d (score: %.2f)\\n\", r.FilePath, r.StartLine, r.EndLine, r.Score)\n    }\n}\n```\n\nFor more control, use the `pkg/` subpackages directly:\n- `pkg/index` - Indexing and file watching\n- `pkg/search` - Search with caching\n- `pkg/embed` - Embedding generation\n- `pkg/store` - Vector storage\n- `pkg/chunk` - Code chunking with AST awareness\n\n## License\n\nApache-2.0\n"
      },
      "plugins": [
        {
          "name": "sgrep",
          "source": "./plugins/sgrep",
          "description": "Smart semantic + hybrid code search",
          "version": "0.1.0",
          "author": {
            "name": "Xiao Cui"
          },
          "skills": [
            "./skills/sgrep"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add XiaoConstantine/sgrep",
            "/plugin install sgrep@sgrep"
          ]
        }
      ]
    }
  ]
}