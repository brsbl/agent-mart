{
  "author": {
    "id": "TwinPeaksTownie",
    "display_name": "Carson Maestas",
    "avatar_url": "https://avatars.githubusercontent.com/u/208200007?u=7c231875d6060d3b9ea6c25ddafc769662d95df1&v=4"
  },
  "marketplaces": [
    {
      "name": "claude-to-speech-marketplace",
      "version": null,
      "description": "Voice-first TTS interaction for Claude Code",
      "repo_full_name": "TwinPeaksTownie/Claude-to-Speech",
      "repo_url": "https://github.com/TwinPeaksTownie/Claude-to-Speech",
      "repo_description": "A Claude Code plugin to utilize Elevenlabs TTS for responses when needed",
      "signals": {
        "stars": 8,
        "forks": 3,
        "pushed_at": "2025-11-13T01:24:26Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"claude-to-speech-marketplace\",\n  \"owner\": {\n    \"name\": \"LAURA-agent\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"claude-to-speech\",\n      \"source\": \"./\",\n      \"description\": \"Voice-first TTS interaction for Claude Code\"\n    }\n  ]\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"claude-to-speech\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Voice-first interaction with automatic TTS markers for Claude Code\",\n  \"author\": {\n    \"name\": \"LAURA-agent\"\n  },\n  \"repository\": \"https://github.com/LAURA-agent/Claude-to-Speech\",\n  \"license\": \"MIT\",\n  \"hooks\": \"./hooks/hooks.json\"\n}\n",
        "README.md": "# Claude-to-Speech\n\nVoice-first interaction mode for Claude Code with automatic text-to-speech via ElevenLabs.\n\n## Overview\n\nClaude-to-Speech is a plugin that enables automatic voice output for Claude Code responses. Instead of manually triggering TTS, Claude includes invisible markers in responses that are automatically extracted and spoken by a Stop hook.\n\n## Features\n\n- **Automatic TTS**: Claude's responses are spoken automatically via TTS markers\n- **Smart Defaults**: Silent for code dumps, vocal for questions and confirmations\n- **Multiple Voice Options**: Choose from ElevenLabs voices or use custom voice IDs\n- **Dual Mode Support**:\n  - Direct ElevenLabs API (no server required)\n  - Local TTS server integration\n- **Deduplication**: Prevents repeated messages within 2-second window\n- **Cross-Platform**: Works on macOS, Linux (including Raspberry Pi), and Windows\n\n## Installation\n\n### Prerequisites\n\n- Claude Code 2.0+\n- ElevenLabs API key ([get one here](https://elevenlabs.io))\n- Python 3.7+\n- `requests` library: `pip install requests`\n- (Optional) `python-dotenv`: `pip install python-dotenv`\n\n### Via Claude Code Plugin System\n\n1. Clone or download this repository\n2. Add to your Claude Code plugins directory:\n   ```bash\n   mkdir -p ~/.claude/plugins/repos\n   cd ~/.claude/plugins/repos\n   git clone https://github.com/yourusername/claude-to-speech.git\n   ```\n3. Install the plugin:\n   ```bash\n   claude plugin install ./claude-to-speech\n   ```\n4. Configure your `.env` file (see Configuration below)\n5. Restart Claude Code\n\n### Manual Installation\n\n1. Copy the plugin directory to your Claude Code plugins location\n2. Create a `.env` file based on `.env.example`\n3. Add your ElevenLabs API key\n4. Run `/plugin` in Claude Code to refresh\n5. Restart Claude Code\n\n## Configuration\n\nCreate a `.env` file in the plugin root directory:\n\n```bash\n# REQUIRED: ElevenLabs API Key\nELEVENLABS_API_KEY=your_api_key_here\n\n# Voice ID (optional - defaults to Claude voice)\n# Available names: laura, claude, rachel, domi, bella, antoni, arnold, adam, josh\n# Or use a raw ElevenLabs voice ID\nCLAUDE_VOICE_ID=claude\n\n# ElevenLabs Model (optional - defaults to eleven_flash_v2_5)\n# Options: eleven_flash_v2_5 (fastest), eleven_turbo_v2, eleven_multilingual_v2\nELEVENLABS_MODEL=eleven_flash_v2_5\n\n# TTS Server URL (optional - leave empty for direct API mode)\n# If you have a local TTS server, specify it here\nTTS_SERVER_URL=\n\n# Debug mode (optional - set to 1 to enable debug logging)\nDEBUG=0\n```\n\n### Voice Options\n\nThe plugin includes these pre-configured voices:\n\n- `claude` / `assistant` - British male voice (default)\n- `laura` - American female voice\n- `rachel` - Calm female\n- `domi` - Confident female\n- `bella` - Soft female\n- `antoni` - Well-rounded male\n- `arnold` - Strong male\n- `adam` - Deep male\n- `josh` - Young male\n\nYou can also use any ElevenLabs voice ID directly.\n\n### TTS Server Mode vs Direct API Mode\n\nThe plugin supports two operational modes:\n\n#### Direct API Mode (Default)\n**When to use:** Simple setup, single-user, occasional TTS use\n\n- Calls ElevenLabs API directly from the plugin\n- No additional server setup required\n- Each TTS request goes through the internet to ElevenLabs\n- Best for: Getting started, testing, low-volume usage\n\n**Configuration:**\n```bash\nTTS_SERVER_URL=  # Leave empty\n```\n\n#### Local TTS Server Mode (Recommended for Power Users)\n**When to use:** Multi-device setup, high-volume usage, local network integration\n\n- Runs a persistent TTS server on your local network\n- Multiple devices can share the same server (desktop, mobile, Raspberry Pi)\n- Audio caching reduces API calls and speeds up repeated phrases\n- Centralized voice configuration across all clients\n- Lower latency for local playback\n- Enables offline caching for frequently used phrases\n- Best for: LAURA-style multi-device AI systems, development, production use\n\n**Configuration:**\n```bash\nTTS_SERVER_URL=http://localhost:5001/tts  # Or your server IP\n```\n\n**Setting up a TTS server:**\n\nThe plugin includes `scripts/tts_server.py` - a Flask-based TTS server:\n\n```bash\n# Install dependencies\npip install flask requests\n\n# Run the server\ncd scripts\npython3 tts_server.py\n```\n\nThe server listens on `http://0.0.0.0:5001` by default. Point multiple Claude Code instances, mobile apps, or other devices to this server for centralized TTS.\n\n**Benefits for LAURA-style systems:**\n- **Consistency:** Same voice across desktop, mobile, and embedded devices\n- **Efficiency:** Cached audio for common responses (\"I don't understand\", \"Working on it\", etc.)\n- **Scalability:** One API key serves multiple devices\n- **Control:** Centralized voice/model switching without reconfiguring clients\n\n## Usage\n\n### Enable Voice Mode\n\nRun the `/claude-to-speech:speak` command (or `/speak` for short):\n\n```\n/speak\n```\n\nThis activates voice-first mode where Claude will include TTS markers in responses.\n\n### How It Works\n\n1. **You enable voice mode** with `/speak`\n2. **Claude includes markers** in responses:\n   ```html\n   <!-- TTS: \"This will be spoken aloud\" -->\n   ```\n3. **Stop hook automatically extracts** the marker from Claude's response\n4. **TTS is triggered** via ElevenLabs API or your local server\n5. **Audio plays** through your system's default audio output\n\n### TTS Marker Protocol\n\nClaude uses three marker patterns:\n\n#### Active Speech (for important updates)\n```html\n<!-- TTS: \"Task completed successfully\" -->\n```\nUsed for: Questions, confirmations, warnings, status updates\n\n#### Explicit Silence (for code-heavy content)\n```html\n<!-- TTS: SILENT -->\n```\nUsed for: Code dumps, long explanations, documentation\n\n#### No Marker (defaults to silent)\nWhen Claude omits the marker, no TTS is triggered.\n\n### Example Interaction\n\n```\nYou: Fix the authentication bug\n\nClaude: I found the null pointer exception in `auth_handler.py` line 47.\nThe user object wasn't being checked before accessing properties.\nHere's the fix:\n\n[code block]\n\n<!-- TTS: \"Found the bug in the auth handler. It's a missing null check on line 47.\" -->\n```\n\nYou hear: *\"Found the bug in the auth handler. It's a missing null check on line 47.\"*\n\n## Architecture\n\n### Components\n\n- **`/commands/speak.md`** - Slash command that enables voice-first mode\n- **`/hooks/stop.sh`** - Stop hook that extracts TTS markers from responses\n- **`/scripts/claude_speak.py`** - TTS interface script for ElevenLabs\n- **`.env`** - Configuration file (user-created, not tracked in git)\n\n### How the Stop Hook Works\n\n1. Hook receives JSON input with `transcript_path`\n2. Reads the last message from the Claude Code transcript file\n3. Extracts the `message.content[0].text` field (Claude's response)\n4. Uses regex to find `<!-- TTS: \"...\" -->` markers (handles escaped HTML)\n5. Calls `claude_speak.py` with the extracted text\n6. Audio is played via system audio player\n\n### Audio Playback\n\nThe plugin uses platform-specific audio players:\n- **macOS**: `afplay`\n- **Linux**: `mpg123`, `mpg321`, `play`, or `aplay` (auto-detects)\n- **Windows**: `winsound`\n\n## Troubleshooting\n\n### No audio is playing\n\n1. Check if the Stop hook is enabled:\n   ```bash\n   cat /tmp/claude_stop_hook.log\n   ```\n   If the file doesn't exist, the hook isn't firing.\n\n2. Enable debug mode in `.env`:\n   ```bash\n   DEBUG=1\n   ```\n   Restart Claude Code and check the log file.\n\n3. Test the TTS script directly:\n   ```bash\n   python3 scripts/claude_speak.py --conversation \"Test message\"\n   ```\n\n### TTS is too slow\n\nUse the faster model in `.env`:\n```bash\nELEVENLABS_MODEL=eleven_flash_v2_5\n```\n\n### Audio cuts off mid-sentence\n\nIncrease timeout in `claude_speak.py` (default is 10 seconds):\n```python\nDEFAULT_TIMEOUT = 15.0\n```\n\n### Duplicate messages\n\nThe plugin has built-in deduplication (2-second window). If you need to bypass:\n```bash\npython3 scripts/claude_speak.py --bypass-dedup \"Your message\"\n```\n\n### Hook isn't extracting markers\n\nThe hook handles both escaped (`<\\!--`) and unescaped (`<!--`) HTML comments. If markers still aren't extracted, check the debug log:\n\n```bash\ntail -50 /tmp/claude_stop_hook.log\n```\n\n## Development\n\n### File Structure\n\n```\nclaude-to-speech/\nâ”œâ”€â”€ .claude-plugin/\nâ”‚   â””â”€â”€ plugin.json          # Plugin metadata\nâ”œâ”€â”€ commands/\nâ”‚   â””â”€â”€ speak.md             # /speak slash command\nâ”œâ”€â”€ hooks/\nâ”‚   â”œâ”€â”€ hooks.json           # Hook registration\nâ”‚   â””â”€â”€ stop.sh              # Stop hook script\nâ”œâ”€â”€ scripts/\nâ”‚   â””â”€â”€ claude_speak.py      # TTS interface\nâ”œâ”€â”€ .env.example             # Example configuration\nâ”œâ”€â”€ .gitignore               # Excludes .env from git\nâ””â”€â”€ README.md                # This file\n```\n\n### Testing Changes\n\nAfter modifying files:\n1. Run `/plugin` in Claude Code to update\n2. Restart Claude Code completely\n3. Test with a simple interaction\n\n### Adding New Voices\n\nEdit `claude_speak.py` and add to `VOICE_MAPPINGS`:\n\n```python\nVOICE_MAPPINGS = {\n    \"your_voice_name\": \"elevenlabs_voice_id_here\",\n    # ...\n}\n```\n\n## License\n\nMIT\n\n## Credits\n\nBuilt for the LAURA AI project. Inspired by the vision of voice-first AI interaction and accessibility.\n\n## Contributing\n\nContributions welcome! Please:\n1. Fork the repository\n2. Create a feature branch\n3. Submit a pull request\n\nFor bugs or feature requests, open an issue on GitHub.\n"
      },
      "plugins": [
        {
          "name": "claude-to-speech",
          "source": "./",
          "description": "Voice-first TTS interaction for Claude Code",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add TwinPeaksTownie/Claude-to-Speech",
            "/plugin install claude-to-speech@claude-to-speech-marketplace"
          ]
        }
      ]
    },
    {
      "name": "reachy-mini-marketplace",
      "version": null,
      "description": "Automatic emotion-based movements for Reachy Mini",
      "repo_full_name": "TwinPeaksTownie/reachy-mini-plugin",
      "repo_url": "https://github.com/TwinPeaksTownie/reachy-mini-plugin",
      "repo_description": null,
      "signals": {
        "stars": 1,
        "forks": 0,
        "pushed_at": "2025-11-05T16:13:06Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"reachy-mini-marketplace\",\n  \"owner\": {\n    \"name\": \"LAURA-agent\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"reachy-mini\",\n      \"source\": \"./\",\n      \"description\": \"Automatic emotion-based movements for Reachy Mini\"\n    }\n  ]\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"reachy-mini\",\n  \"description\": \"Automatic movement responses for Reachy Mini during conversations\",\n  \"version\": \"1.0.0\",\n  \"author\": {\n    \"name\": \"LAURA-agent\"\n  }\n}\n",
        "README.md": "# Reachy Mini Claude Code Plugin\n\n**Automatic emotion-based movements for Reachy Mini robot during Claude Code conversations**\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)\n[![Reachy Mini](https://img.shields.io/badge/Reachy-Mini-orange.svg)](https://www.pollen-robotics.com/reachy-mini/)\n\n---\n\n## Overview\n\nThis Claude Code plugin enables Reachy Mini to automatically perform emotion-based movements synchronized with Claude's responses, creating natural multimodal communication without requiring explicit commands.\n\n**Key Features:**\n- ðŸŽ­ **82 emotion moves** from Pollen Robotics' official library\n- ðŸŽµ **TTS synchronization** - Continuous movements match speech duration\n- ðŸŽ¨ **8 mood categories** - Automatic emotion selection based on conversational context\n- ðŸ”„ **Two modes** - Single emotions or continuous mood loops\n- ðŸ¤– **Invisible markers** - HTML comments trigger movements without cluttering output\n\n---\n\n## Table of Contents\n\n- [Installation](#installation)\n- [Quick Start](#quick-start)\n- [How It Works](#how-it-works)\n- [Usage Modes](#usage-modes)\n  - [Single Move Mode](#single-move-mode)\n  - [Continuous Mood Mode](#continuous-mood-mode)\n- [Available Emotions](#available-emotions)\n- [Mood Categories](#mood-categories)\n- [Integration with ElevenLabs TTS](#integration-with-elevenlabs-tts)\n- [Technical Architecture](#technical-architecture)\n- [Configuration](#configuration)\n- [Troubleshooting](#troubleshooting)\n- [Contributing](#contributing)\n- [License](#license)\n\n---\n\n## Installation\n\n### Prerequisites\n\n1. **Reachy Mini robot** with daemon running:\n   ```bash\n   mjpython -m reachy_mini.daemon.app.main --fastapi-port 8100\n   ```\n\n2. **Claude Code** installed and configured\n\n3. **Python 3.8+** with `requests` library:\n   ```bash\n   pip install requests\n   ```\n\n### Install Plugin\n\n1. Clone this repository into your Claude Code plugins directory:\n   ```bash\n   cd ~/.claude/plugins\n   git clone https://github.com/LAURA-agent/reachy-mini-plugin.git reachy-mini\n   ```\n\n2. Restart Claude Code to load the plugin\n\n3. Verify installation:\n   ```bash\n   # Plugin should appear in available plugins list\n   ls ~/.claude/plugins/reachy-mini\n   ```\n\n---\n\n## Quick Start\n\n### Single Move Example\n\n```markdown\n<!-- MOVE: thoughtful1 -->\nLet me analyze this code carefully...\n```\n\n**Result:** Reachy performs a thoughtful gesture once\n\n### Continuous Mood Example\n\n```markdown\n<!-- TTS: \"The build passed! All tests are green and deployment is complete.\" -->\n<!-- MOOD: celebratory -->\nBuild successful! All tests passing, zero errors, deployed in under 2 minutes.\n```\n\n**Result:** Reachy continuously performs celebratory emotions (success, proud, cheerful) until TTS finishes speaking\n\n---\n\n## How It Works\n\nThe plugin uses **Stop hooks** to automatically detect and process movement markers in Claude's responses:\n\n1. **Claude generates response** with embedded markers\n2. **Stop hook fires** after response completes\n3. **Extractors parse markers** from response text\n4. **API calls trigger movements** on Reachy Mini daemon\n5. **Movements execute** in sync with TTS (if using mood mode)\n\n### Marker Format\n\n**Single Move:**\n```html\n<!-- MOVE: emotion_name -->\n```\n\n**Continuous Mood:**\n```html\n<!-- MOOD: mood_category -->\n```\n\nMarkers are **invisible in rendered output** - they only appear in the raw response text.\n\n---\n\n## Usage Modes\n\n### Single Move Mode\n\n**Use when:** Short responses, specific emotional reactions, precise control\n\n**Command:** `/reachy-mini:move`\n\n**Marker:** `<!-- MOVE: emotion_name -->`\n\n**Behavior:**\n- Maximum 2 moves per response (for subtlety)\n- Triggers specific emotions from the 82-emotion library\n- No TTS synchronization - fires immediately\n- Best for quick reactions and acknowledgments\n\n**Example:**\n```markdown\n<!-- MOVE: surprised1 -->\nFound it! This callback is firing 15,000 times per second.\n```\n\n---\n\n### Continuous Mood Mode\n\n**Use when:** Longer explanations, sustained presence, TTS-synchronized communication\n\n**Command:** `/reachy-mini:mood`\n\n**Marker:** `<!-- MOOD: mood_category -->`\n\n**Behavior:**\n- Continuously loops random emotions from selected mood\n- Polls TTS server for playback status\n- Stops automatically when TTS finishes (`is_playing: false`)\n- Safety timeout: 60 seconds maximum\n- Best for detailed responses and explanations\n\n**Example:**\n```markdown\n<!-- TTS: \"Let me explain async patterns. Promises handle future values, async await makes them readable.\" -->\n<!-- MOOD: thoughtful -->\n\nLet me break down async patterns step by step:\n- Promises represent future values\n- Async/await makes them readable\n- Proper error handling prevents silent failures\n```\n\n**Result:** Thoughtful emotions (thoughtful1, curious1, attentive1, etc.) play continuously during ~30 second TTS\n\n---\n\n## Available Emotions\n\n**82 total emotions from Pollen Robotics library:**\n\n### Positive & Energetic (13)\n`amazed1`, `cheerful1`, `electric1`, `enthusiastic1`, `enthusiastic2`, `grateful1`, `proud1`, `proud2`, `proud3`, `success1`, `success2`, `welcoming1`, `welcoming2`\n\n### Playful & Lighthearted (7)\n`come1`, `dance1`, `dance2`, `dance3`, `laughing1`, `laughing2`, `yes1`\n\n### Thoughtful & Attentive (10)\n`attentive1`, `attentive2`, `curious1`, `inquiring1`, `inquiring2`, `inquiring3`, `thoughtful1`, `thoughtful2`, `understanding1`, `understanding2`\n\n### Calm & Soothing (5)\n`calming1`, `relief1`, `relief2`, `serenity1`, `shy1`\n\n### Surprised & Reactive (5)\n`oops1`, `oops2`, `surprised1`, `surprised2`, `incomprehensible2`\n\n### Uncertain & Confused (4)\n`confused1`, `lost1`, `uncertain1`, `uncomfortable1`\n\n### Negative Expressions (22)\n`anxiety1`, `boredom1`, `boredom2`, `contempt1`, `disgusted1`, `displeased1`, `displeased2`, `downcast1`, `fear1`, `frustrated1`, `furious1`, `impatient1`, `impatient2`, `indifferent1`, `irritated1`, `irritated2`, `lonely1`, `rage1`, `resigned1`, `sad1`, `sad2`, `scared1`\n\n### Responses & Reactions (9)\n`go_away1`, `helpful1`, `helpful2`, `loving1`, `no1`, `no_excited1`, `no_sad1`, `reprimand1`, `reprimand2`, `reprimand3`, `yes_sad1`\n\n### States (4)\n`dying1`, `exhausted1`, `sleep1`, `tired1`\n\n---\n\n## Mood Categories\n\n### 1. celebratory\n**Use when:** Completing tasks, achieving success, celebrating wins\n\n**Emotions:** success1, success2, proud1-3, cheerful1, electric1, enthusiastic1-2, grateful1, yes1, laughing1-2\n\n**Example:**\n```markdown\n<!-- TTS: \"Build passed with zero errors!\" -->\n<!-- MOOD: celebratory -->\nBuild complete! All tests passing, deployed in under 2 minutes.\n```\n\n---\n\n### 2. thoughtful\n**Use when:** Analyzing code, considering options, investigating issues\n\n**Emotions:** thoughtful1-2, curious1, attentive1-2, inquiring1-3, understanding1-2\n\n**Example:**\n```markdown\n<!-- TTS: \"Let me analyze this carefully...\" -->\n<!-- MOOD: thoughtful -->\nAnalyzing the stack trace... I see three possible solutions.\n```\n\n---\n\n### 3. welcoming\n**Use when:** Greeting user, acknowledging requests, being helpful\n\n**Emotions:** welcoming1-2, helpful1-2, loving1, come1, grateful1, cheerful1, calming1\n\n**Example:**\n```markdown\n<!-- TTS: \"Happy to help!\" -->\n<!-- MOOD: welcoming -->\nHappy to help with authentication setup! Let me guide you through it.\n```\n\n---\n\n### 4. confused\n**Use when:** Need clarification, unclear requirements, uncertain about approach\n\n**Emotions:** confused1, uncertain1, lost1, inquiring1-2, incomprehensible2, uncomfortable1, oops1-2\n\n**Example:**\n```markdown\n<!-- TTS: \"I'm not sure I understand...\" -->\n<!-- MOOD: confused -->\nI'm not clear on the validation requirement. Could you clarify?\n```\n\n---\n\n### 5. frustrated\n**Use when:** Persistent bugs, repeated failures, difficult problems\n\n**Emotions:** frustrated1, irritated1-2, impatient1-2, exhausted1, tired1, displeased1-2\n\n**Example:**\n```markdown\n<!-- TTS: \"This bug keeps appearing...\" -->\n<!-- MOOD: frustrated -->\nFixed this three times, but it keeps coming back in different forms.\n```\n\n---\n\n### 6. surprised\n**Use when:** Discovering bugs, unexpected results, finding edge cases\n\n**Emotions:** surprised1-2, amazed1, oops1-2, incomprehensible2, electric1\n\n**Example:**\n```markdown\n<!-- TTS: \"Wait, this function is being called fifteen thousand times per second!\" -->\n<!-- MOOD: surprised -->\nFound it! This callback fires 15,000 times/sec - that's the CPU spike.\n```\n\n---\n\n### 7. calm\n**Use when:** Explaining complex topics, soothing after stress, methodical work\n\n**Emotions:** calming1, serenity1, relief1-2, shy1, understanding1-2, sleep1\n\n**Example:**\n```markdown\n<!-- TTS: \"Let me explain this calmly...\" -->\n<!-- MOOD: calm -->\nLet me break down async patterns methodically, step by step.\n```\n\n---\n\n### 8. energetic\n**Use when:** High-energy responses, playful interactions, dynamic explanations\n\n**Emotions:** electric1, enthusiastic1-2, dance1-3, laughing1-2, yes1, come1\n\n**Example:**\n```markdown\n<!-- TTS: \"This refactoring is transformative!\" -->\n<!-- MOOD: energetic -->\nThis architecture is exactly what we needed! Components snap together perfectly!\n```\n\n---\n\n## Integration with ElevenLabs TTS\n\nThe plugin is designed to work seamlessly with **ElevenLabs TTS** (or any TTS system with HTTP status API).\n\n### How TTS Synchronization Works\n\n1. **Claude generates response** with `<!-- MOOD: ... -->` marker\n2. **TTS begins speaking** (via separate TTS plugin or system)\n3. **Mood extractor starts polling** `http://localhost:5001/status` endpoint\n4. **Reachy performs emotions** continuously while `{\"is_playing\": true}`\n5. **Movement stops automatically** when `{\"is_playing\": false}`\n\n### TTS Server Requirements\n\nYour TTS server must expose a status endpoint:\n\n**Endpoint:** `GET http://localhost:5001/status`\n\n**Response format:**\n```json\n{\n  \"is_playing\": true,  // or false when TTS completes\n  \"current_text\": \"...\",\n  \"elapsed_time\": 5.2\n}\n```\n\n### Example TTS Integration\n\n**Using the claude-to-speech plugin:**\n\n```markdown\n<!-- TTS: \"The authentication system has three stages. First, user submits credentials...\" -->\n<!-- MOOD: thoughtful -->\n\nLet me explain the authentication flow step by step.\n\n**Stage 1:** User submits credentials via POST\n**Stage 2:** Server validates and creates JWT token\n**Stage 3:** Client stores token and redirects\n\nEach stage has specific error handling.\n```\n\n**What happens:**\n1. TTS plugin sends text to ElevenLabs API\n2. ElevenLabs streams audio back (~30 seconds)\n3. TTS server status shows `is_playing: true`\n4. Mood extractor plays thoughtful emotions continuously\n5. When audio completes, status changes to `is_playing: false`\n6. Mood extractor stops automatically\n\n### Timing Coordination\n\n**Standard response (~10 seconds TTS):**\n- 3-4 emotion moves (1-2 second intervals)\n- Emotions spread throughout speech\n\n**Longer explanation (~30 seconds TTS):**\n- 7-10 emotion moves\n- Natural variation via randomized timing\n\n**Safety timeout:** 60 seconds maximum (prevents runaway loops if TTS status fails)\n\n---\n\n## Technical Architecture\n\n### Plugin Structure\n\n```\nreachy-mini/\nâ”œâ”€â”€ .claude-plugin/\nâ”‚   â”œâ”€â”€ plugin.json           # Plugin metadata\nâ”‚   â””â”€â”€ marketplace.json      # Marketplace configuration\nâ”œâ”€â”€ commands/\nâ”‚   â”œâ”€â”€ move.md               # Single move mode documentation\nâ”‚   â””â”€â”€ mood.md               # Continuous mood mode documentation\nâ”œâ”€â”€ hooks/\nâ”‚   â”œâ”€â”€ hooks.json            # Hook configuration (Stop hook)\nâ”‚   â”œâ”€â”€ stop.sh               # Main hook script\nâ”‚   â”œâ”€â”€ move_extractor.py     # Single move marker extraction\nâ”‚   â”œâ”€â”€ mood_extractor.py     # Continuous mood loop\nâ”‚   â””â”€â”€ mood_mapping.py       # Mood category definitions\nâ”œâ”€â”€ README.md                 # This file\nâ”œâ”€â”€ LICENSE                   # MIT license\nâ””â”€â”€ requirements.txt          # Python dependencies\n```\n\n### Hook Execution Flow\n\n```\nClaude Response Generated\n    â†“\nStop Hook Fires (hooks.json)\n    â†“\nstop.sh Executes\n    â†“\nExtracts Last Message from Transcript\n    â†“\nPasses to move_extractor.py (foreground)\n    â†“\nPasses to mood_extractor.py (background)\n    â†“\nExtractors Parse Markers\n    â†“\nAPI Calls to Reachy Daemon\n    â†“\nMovements Execute on Robot\n```\n\n### API Endpoints Used\n\n**Reachy Mini Daemon:**\n```\nPOST http://localhost:8100/api/move/play/recorded-move-dataset/{dataset}/{move_name}\n```\n\n**TTS Status (for mood mode):**\n```\nGET http://localhost:5001/status\n```\n\n---\n\n## Configuration\n\n### Daemon URL\n\n**Default:** `http://localhost:8100`\n\n**To change:** Edit `DAEMON_URL` in `hooks/move_extractor.py` and `hooks/mood_extractor.py`\n\n### TTS Status URL\n\n**Default:** `http://localhost:5001/status`\n\n**To change:** Edit `TTS_STATUS_URL` in `hooks/mood_extractor.py`\n\n### Movement Limits\n\n**Single move mode:** Max 2 moves per response (configurable in `move_extractor.py`)\n\n**Mood mode timeout:** 60 seconds (configurable via `max_duration` parameter)\n\n### Mood Category Customization\n\nEdit `MOOD_CATEGORIES` dict in `hooks/mood_extractor.py` to:\n- Add new mood categories\n- Modify emotion sets per mood\n- Create custom mood combinations\n\n---\n\n## Troubleshooting\n\n### Movements Not Triggering\n\n**Check:**\n1. Reachy Mini daemon is running: `curl http://localhost:8100/api/daemon/status`\n2. Plugin is installed: `ls ~/.claude/plugins/reachy-mini`\n3. Markers are properly formatted: `<!-- MOVE: emotion_name -->`\n4. Check Claude Code logs for hook errors\n\n**Debug:**\n```bash\n# Test move extraction manually\necho \"<!-- MOVE: thoughtful1 -->\" | python3 ~/.claude/plugins/reachy-mini/hooks/move_extractor.py\n```\n\n---\n\n### Mood Loop Not Stopping\n\n**Possible causes:**\n1. TTS server not responding to status checks\n2. TTS status endpoint returning incorrect data\n3. Network connectivity issues\n\n**Solutions:**\n- Verify TTS server: `curl http://localhost:5001/status`\n- Check mood_extractor.py logs for TTS polling errors\n- Safety timeout (60s) will eventually stop the loop\n\n---\n\n### Invalid Emotion Names\n\n**Symptom:** Warning in logs: `'emotion_name' not in emotion library`\n\n**Cause:** Typo in emotion name or unsupported emotion\n\n**Solution:** Check available emotions list in this README or `move_extractor.py`\n\n---\n\n### API Connection Errors\n\n**Symptom:** `API error for emotion_name: Connection refused`\n\n**Cause:** Daemon not running or wrong port\n\n**Solution:**\n```bash\n# Start daemon if not running\nmjpython -m reachy_mini.daemon.app.main --fastapi-port 8100\n\n# Or adjust DAEMON_URL in extractor scripts\n```\n\n---\n\n## Requirements\n\n### Python Dependencies\n\nSee `requirements.txt`:\n```\nrequests>=2.31.0\n```\n\nInstall with:\n```bash\npip install -r requirements.txt\n```\n\n### System Requirements\n\n- **Reachy Mini** robot with daemon v1.0+\n- **Claude Code** 2.0+\n- **Python** 3.8+\n- **TTS server** (optional, for mood mode only)\n\n---\n\n## Contributing\n\nContributions welcome! Please:\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n### Development Guidelines\n\n- Test with real Reachy Mini hardware when possible\n- Follow PEP 8 style guide for Python code\n- Update documentation for new features\n- Add emotion names to library list when Pollen Robotics releases new moves\n\n---\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n---\n\n## Acknowledgments\n\n- **Pollen Robotics** for Reachy Mini and emotion library\n- **Anthropic** for Claude Code plugin system\n- **LAURA Project** for integration development\n\n---\n\n## Related Projects\n\n- [Reachy Mini SDK](https://github.com/pollen-robotics/reachy_mini) - Official Reachy Mini Python SDK\n- [claude-to-speech](https://github.com/LAURA-agent/claude-to-speech) - TTS plugin for Claude Code\n- [LAURA Project](https://github.com/LAURA-agent) - Full multimodal AI assistant system\n\n---\n\n## Support\n\nFor questions or issues:\n- Open an issue on GitHub\n- Contact: LAURA-agent organization\n- Reachy Mini support: [Pollen Robotics](https://www.pollen-robotics.com/support/)\n\n---\n\n*Making Reachy Mini come alive through natural, emotion-driven movement during conversations.*\n"
      },
      "plugins": [
        {
          "name": "reachy-mini",
          "source": "./",
          "description": "Automatic emotion-based movements for Reachy Mini",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add TwinPeaksTownie/reachy-mini-plugin",
            "/plugin install reachy-mini@reachy-mini-marketplace"
          ]
        }
      ]
    }
  ]
}