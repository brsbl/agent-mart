{
  "author": {
    "id": "abatilo",
    "display_name": "Aaron Batilo",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/1634746?u=f13168335a7914b873617ea8e0f53b9c4306419a&v=4",
    "url": "https://github.com/abatilo",
    "bio": "If I don't have to do it, I won't. If I have to do it, I'll do it as quickly as possible.",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 4,
      "total_skills": 7,
      "total_stars": 1,
      "total_forks": 1
    }
  },
  "marketplaces": [
    {
      "name": "abatilo-plugins",
      "version": null,
      "description": "Core commands, skills, and hooks for abatilo's Claude Code setup",
      "owner_info": {
        "name": "abatilo"
      },
      "keywords": [],
      "repo_full_name": "abatilo/vimrc",
      "repo_url": "https://github.com/abatilo/vimrc",
      "repo_description": "My personal vim settings",
      "homepage": null,
      "signals": {
        "stars": 1,
        "forks": 1,
        "pushed_at": "2026-01-28T18:44:54Z",
        "created_at": "2015-09-28T13:46:32Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 264
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 136
        },
        {
          "path": "plugins/abatilo-core/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/commands/CLAUDE.md",
          "type": "blob",
          "size": 310
        },
        {
          "path": "plugins/abatilo-core/commands/bits-drain.md",
          "type": "blob",
          "size": 1006
        },
        {
          "path": "plugins/abatilo-core/commands/commit.md",
          "type": "blob",
          "size": 619
        },
        {
          "path": "plugins/abatilo-core/commands/interview.md",
          "type": "blob",
          "size": 727
        },
        {
          "path": "plugins/abatilo-core/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/hooks/CLAUDE.md",
          "type": "blob",
          "size": 1466
        },
        {
          "path": "plugins/abatilo-core/hooks/hooks.json",
          "type": "blob",
          "size": 599
        },
        {
          "path": "plugins/abatilo-core/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/skills/CLAUDE.md",
          "type": "blob",
          "size": 374
        },
        {
          "path": "plugins/abatilo-core/skills/bits-plan",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/skills/bits-plan/SKILL.md",
          "type": "blob",
          "size": 10759
        },
        {
          "path": "plugins/abatilo-core/skills/bits",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/skills/bits/SKILL.md",
          "type": "blob",
          "size": 2106
        },
        {
          "path": "plugins/abatilo-core/skills/diataxis-documentation",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/skills/diataxis-documentation/SKILL.md",
          "type": "blob",
          "size": 8142
        },
        {
          "path": "plugins/abatilo-core/skills/diataxis-documentation/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/skills/diataxis-documentation/references/explanation.md",
          "type": "blob",
          "size": 19004
        },
        {
          "path": "plugins/abatilo-core/skills/diataxis-documentation/references/framework-overview.md",
          "type": "blob",
          "size": 11058
        },
        {
          "path": "plugins/abatilo-core/skills/diataxis-documentation/references/how-to-guides.md",
          "type": "blob",
          "size": 13765
        },
        {
          "path": "plugins/abatilo-core/skills/diataxis-documentation/references/reference.md",
          "type": "blob",
          "size": 14675
        },
        {
          "path": "plugins/abatilo-core/skills/diataxis-documentation/references/tutorials.md",
          "type": "blob",
          "size": 11407
        },
        {
          "path": "plugins/abatilo-core/skills/git-commit",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/skills/git-commit/SKILL.md",
          "type": "blob",
          "size": 6663
        },
        {
          "path": "plugins/abatilo-core/skills/git-commit/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/skills/git-commit/references/conventional-commits.md",
          "type": "blob",
          "size": 4129
        },
        {
          "path": "plugins/abatilo-core/skills/git-spice",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/skills/git-spice/SKILL.md",
          "type": "blob",
          "size": 7959
        },
        {
          "path": "plugins/abatilo-core/skills/git-spice/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/skills/git-spice/references/commands.md",
          "type": "blob",
          "size": 9125
        },
        {
          "path": "plugins/abatilo-core/skills/git-spice/references/workflows.md",
          "type": "blob",
          "size": 8736
        },
        {
          "path": "plugins/abatilo-core/skills/kubernetes",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/skills/kubernetes/SKILL.md",
          "type": "blob",
          "size": 6754
        },
        {
          "path": "plugins/abatilo-core/skills/kubernetes/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/skills/kubernetes/references/best_practices.md",
          "type": "blob",
          "size": 16335
        },
        {
          "path": "plugins/abatilo-core/skills/kubernetes/references/helm_reference.md",
          "type": "blob",
          "size": 14692
        },
        {
          "path": "plugins/abatilo-core/skills/kubernetes/references/kubectl_reference.md",
          "type": "blob",
          "size": 14668
        },
        {
          "path": "plugins/abatilo-core/skills/kubernetes/references/workflows.md",
          "type": "blob",
          "size": 14734
        },
        {
          "path": "plugins/abatilo-core/skills/repo-explore",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/skills/repo-explore/SKILL.md",
          "type": "blob",
          "size": 4790
        },
        {
          "path": "plugins/abatilo-core/skills/repo-explore/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/abatilo-core/skills/repo-explore/references/update-reference.md",
          "type": "blob",
          "size": 5254
        },
        {
          "path": "plugins/abatilo-core/skills/repo-explore/references/version-detection.md",
          "type": "blob",
          "size": 5846
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"abatilo-plugins\",\n  \"owner\": {\n    \"name\": \"abatilo\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"abatilo-core\",\n      \"source\": \"./plugins/abatilo-core\",\n      \"description\": \"Core commands, skills, and hooks for abatilo's Claude Code setup\"\n    }\n  ]\n}\n",
        "plugins/abatilo-core/.claude-plugin/plugin.json": "{\n  \"name\": \"abatilo-core\",\n  \"version\": \"0.7.1\",\n  \"description\": \"Core commands, skills, and hooks for abatilo's Claude Code setup\"\n}\n",
        "plugins/abatilo-core/commands/CLAUDE.md": "# Commands Directory\n\nFiles here define slash commands (e.g., `/bd-plan`, `/git-commit`).\n\n## Before committing changes\n\n**Bump the plugin version.** See `../CLAUDE.md` for the checklist.\n\nQuick reminder:\n- Adding a command → bump MINOR\n- Modifying a command → bump PATCH\n- Update version in `plugin.json`\n",
        "plugins/abatilo-core/commands/bits-drain.md": "---\ndescription: Start working on the next ready task\n---\n\n# Bits-Drain\n\nStart working on the next ready task. Uses bits as the single source of truth.\n\n## Startup\n\nFirst, activate drain mode to block exit until all tasks are complete:\n```bash\nbits drain claim\n```\n\nThen check for an already active task:\n```bash\nbits list --active --json | jq -r '.[0].id // empty'\n```\n\n**If a task is already active:** Resume working on it.\n\n**If no task is active:** Find the next ready task:\n```bash\nbits ready --json | jq -r '.[0].id // empty'\n```\n\n## Logic\n\n**If no ready tasks and none active:** Inform user there are no tasks to work on.\n\n**If tasks ready:**\n\n1. Get the first ready task ID\n2. Mark it as active: `bits claim <task_id>`\n3. Output work prompt:\n\n```\nWork on task <task_id>. Run 'bits show <task_id>' for details. Implement, test, and close when done. Use 'bits close <task_id> \"reason\"' when complete. Use /commit for atomic commits.\n```\n\nThe Stop hook blocks exit while a task is active.\n\n$ARGUMENTS\n",
        "plugins/abatilo-core/commands/commit.md": "---\ndescription: Create logically grouped, atomic git commits with well-formatted commit messages\nargument-hint: [optional: additional context or specific files]\n---\n\n## Context\n\n- Current git status: !`git status`\n- Current git diff (staged and unstaged changes): !`git diff HEAD`\n- Current branch: !`git branch --show-current`\n- Recent commits: !`git log --oneline -10`\n\n## Task\n\nCreate logically grouped, atomic commits based on the above context.\nUse the git-commit skill for commit message formatting and best practices.\nUse partial adds (`git add -p`) when a file contains multiple unrelated changes.\n\n$ARGUMENTS\n",
        "plugins/abatilo-core/commands/interview.md": "---\ndescription: Interview users in-depth about their plans using probing, non-obvious questions.\n---\n\n# Plan Interview\n\nFirst, review the entire conversation to understand what plan is being discussed.\n\nInterview me about this plan in detail using the AskUserQuestion tool. Ask about literally anything: technical implementation, UI & UX, concerns, tradeoffs, edge cases, assumptions, risks, dependencies, etc.\n\nMake sure the questions are not obvious - probe deeper into things I might not have considered. Challenge assumptions. Ask about the hard parts.\n\nBe very in-depth and continue interviewing me continually until the plan is fully fleshed out, then re-iterate the complete plan incorporating everything we discussed.\n",
        "plugins/abatilo-core/hooks/CLAUDE.md": "# Hooks Directory\n\nFiles here define Claude Code hooks for session and drain mode management.\n\n## Architecture (v6.0 - Session-Based)\n\nThe hooks use bits session management to track primary Claude instance ownership.\nOnly the primary instance (first to start) can be blocked during drain mode.\n\n### Hook Events\n\n| Event | Command | Purpose |\n|-------|---------|---------|\n| SessionStart | `bits session claim` | Claim primary session ownership |\n| SessionEnd | `bits session release` | Release session ownership |\n| Stop | `bits session hook` | Check drain mode and block if needed |\n\n### Session Flow\n\n1. First Claude instance starts → claims session via `bits session claim`\n2. Secondary instances → see existing session, do nothing\n3. Primary runs `/bits-drain` → `bits drain claim` sets drain_active=true\n4. Primary tries to exit → blocked if drain_active AND tasks remain\n5. Secondary tries to exit → allowed (not session owner)\n6. Primary exits normally → `bits session release` deletes session file\n\n### Session File\n\nLocation: `~/.bits/<project>/session.json`\n\n```json\n{\n  \"session_id\": \"abc123\",\n  \"started_at\": \"2025-01-21T10:00:00Z\",\n  \"source\": \"claude-code\",\n  \"drain_active\": false,\n  \"drain_started_at\": null\n}\n```\n\n## Before committing changes\n\n**Bump the plugin version.** See `../CLAUDE.md` for the checklist.\n\nQuick reminder:\n- Modifying hook behavior → bump PATCH\n- Adding new hooks → bump MINOR\n- Update version in `plugin.json`\n",
        "plugins/abatilo-core/hooks/hooks.json": "{\n  \"hooks\": {\n    \"SessionStart\": [\n      {\n        \"matcher\": \"\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"bits session claim\"\n          }\n        ]\n      }\n    ],\n    \"SessionEnd\": [\n      {\n        \"matcher\": \"\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"bits session release\"\n          }\n        ]\n      }\n    ],\n    \"Stop\": [\n      {\n        \"matcher\": \"\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"bits session hook\"\n          }\n        ]\n      }\n    ]\n  }\n}\n",
        "plugins/abatilo-core/skills/CLAUDE.md": "# Skills Directory\n\nFiles here define skills that Claude can invoke (e.g., `beads`, `repo-explore`).\n\n## Before committing changes\n\n**Bump the plugin version.** See `../CLAUDE.md` for the checklist.\n\nQuick reminder:\n- Adding a skill → bump MINOR\n- Modifying a skill → bump PATCH\n- Removing a skill → bump PATCH (or MAJOR if breaking)\n- Update version in `plugin.json`\n",
        "plugins/abatilo-core/skills/bits-plan/SKILL.md": "---\nname: bits-plan\ndescription: Analyze conversation history and create bits tasks with dependencies. Use when extracting work from a discussion, turning decisions into tracked tasks, or breaking down what was discussed into actionable items. Triggers on \"create tasks from this\", \"turn this into bits\", \"extract tasks\", \"what should we track\", \"break this down into tasks\", \"plan from this conversation\". Uses collaborative Codex debate to refine scope, discovers verification commands, creates self-contained tasks with context and acceptance criteria.\nargument-hint: \"[optional focus area]\"\n---\n\n# Bits Planning Skill\n\nReview the conversation history above to identify work that needs planning. Extract requirements, decisions, and context discussed—these inform the bits tasks you create. If the user provided additional instructions below, incorporate those as well.\n\n## When to Use This Skill\n\n| Scenario | Approach |\n|----------|----------|\n| Complex multi-step implementation | Use this skill for structured planning |\n| Breaking down large features into tasks | Use this skill with debate refinement |\n| Simple single-task work | Use bits skill directly |\n| Quick research or exploration | Use Explore agent |\n\nThis is a two-phase process: discovery first, then planning with collaborative debate.\n\n## Phase 1: Discovery\n\nGather context from the conversation history and find verification commands.\n\n### Step 1: Verification Commands\nRun a focused Explore query to discover development commands. This may return nothing, especially for new projects—in which case, simply create tasks without verification sections.\n```\nFind the ACTUAL commands used in this project for verification. Search in order:\n1. mise.toml / .mise.toml (mise task runner - https://github.com/jdx/mise)\n2. package.json scripts / pyproject.toml / Makefile / Justfile\n3. .github/workflows (CI jobs are authoritative)\n4. docs/CONTRIBUTING.md or README.md\n\nFor each category, report the EXACT command string:\n- Linting/formatting (e.g., `mise run lint`, `go fmt ./...`)\n- Static analysis / type checking (e.g., `mise run check`, `staticcheck ./...`, `golangci-lint run`)\n- Unit tests (e.g., `mise run test`, `go test ./...`)\n- Scoped E2E tests - run specific tests (e.g., `mise run test:e2e -- -run TestAuth`, `go test ./e2e/... -run TestAuth`)\n- Full E2E tests - run entire suite (e.g., `mise run test:e2e`, `go test ./e2e/...`)\n\nOutput format: \"CATEGORY: [exact command]\"\nStop searching a category once you find an authoritative source.\n```\n\n### Step 2: Discovery Synthesis\nConsolidate findings from conversation history into planning input:\n- **Architecture overview**: Patterns, conventions, and constraints discussed\n- **Testing setup**: Where tests live, how to run them, what coverage exists\n- **Verification commands**: From Step 1\n- **Known risks**: Edge cases and caveats identified\n\nThis synthesis becomes the input for Phase 2.\n\n## Phase 2: Planning with Collaborative Debate\n\nUse multi-round refinement for thorough planning.\n\n### Guiding Principles: Speed-of-Light Implementation\n\n**Treat planning as a minimization problem.** The goal is not to design a comprehensive solution—it's to find the smallest, fastest path to the desired outcome.\n\n- **Minimize changes**: What is the absolute minimum number of lines, files, and touch points needed? Every additional change is a potential bug, a review burden, and merge conflict risk.\n- **Minimize complexity**: Prefer boring, obvious solutions over clever ones. If two approaches work, choose the one a junior developer could understand in 5 minutes.\n- **Minimize scope**: Ruthlessly cut anything that isn't strictly required. \"Nice to have\" belongs in a separate future task, not this plan.\n- **Minimize risk**: Favor incremental changes over big-bang rewrites. Ship something small that works over something ambitious that might not.\n\n**Ask at every decision point**: \"Is there a simpler way?\" If the answer is yes, take it.\n\n### Step 1: Initial Plan\nUse the Plan subagent with **model: \"opus\"** to design the minimum viable implementation based on discovery synthesis. The plan should answer: \"What is the smallest change that achieves the goal?\"\n\n### Step 2: Interview Codex\n\nUse threaded conversations to probe and refine the plan. Claude interviews Codex, asking probing questions to surface gaps, risks, and simplification opportunities.\n\n**Start the thread:**\nUse `mcp__codex__codex` to share the initial plan and begin the interview. Inform Codex of your capabilities so it can request specific research:\n```\nprompt: \"I'm planning this implementation: [plan].\n\nI can run multiple parallel sub-agents to gather information:\n- Explore agents to search the codebase and answer specific questions\n- Plan agents for deeper architectural analysis\n\nHelp me think through this critically. What concerns do you have? What might I be missing? Are there specific questions I should investigate with an Explore agent before proceeding?\"\n```\n\n**Probe deeper:**\nContinue with `mcp__codex__codex-reply` using the returned `threadId`. Ask about literally anything: technical implementation, concerns, tradeoffs, edge cases, assumptions, risks, dependencies.\n\nQuestions should not be obvious—probe deeper into things that might not have been considered:\n- \"What's the hardest part of this?\"\n- \"Where could this break in production?\"\n- \"What assumptions am I making that might be wrong?\"\n- \"Is there a simpler way to achieve this?\"\n- \"What would you cut if you had to ship this in half the time?\"\n\nChallenge assumptions. Ask about the hard parts. Push back when answers feel incomplete.\n\n**Continue until the plan is fully fleshed out:**\nThere's no fixed number of rounds. Keep interviewing until:\n- Major concerns have been addressed or explicitly deferred\n- The plan feels minimal and well-understood\n- You're confident it represents the smallest viable implementation\n\n**Synthesize insights:**\nAfter the interview, integrate Codex's feedback into the final plan. Document what was deferred and why.\n\n### Quality Gate\nBefore creating tasks, confirm:\n- All discovered edge cases addressed or explicitly deferred with rationale\n- Error paths defined (what happens when X fails?)\n- Testing strategy covers new code\n- Trade-offs documented with reasoning\n\n### Step 3: Create Tasks\n\nCreate bits tasks using the bits skill. **Tasks must be self-contained** with sufficient context for immediate implementation without repeating discovery work. Be verbose and repeat context; prioritize completeness over brevity.\n\n#### Task Description Structure\n\n```markdown\n# Context\nExplain why this task exists and what it solves:\n- The specific problem being addressed\n- Why this solution was chosen over alternatives\n- Relevant constraints or assumptions\n\n# References\nList all files and resources to consult during implementation:\n- `path/to/relevant/file.ts` - reason it's relevant\n- `path/to/example/pattern.ts:42-58` - specific pattern to follow\n- [Link or doc reference] - what to learn\n\n# Code Snippets\nInclude code from discovery only if it shows patterns or templates to replicate:\n\n\\`\\`\\`language\n// Existing code to modify or pattern to follow\n\\`\\`\\`\n\n# File Changes\nSpecify every file that will be touched:\n\nFiles to **edit**:\n- `path/to/file.ts` - specific changes required\n\nFiles to **create**:\n- `path/to/new/file.ts` - purpose and responsibility\n\nFiles to **delete**:\n- `path/to/obsolete/file.ts` - reason for removal\n\n# Acceptance Criteria\nCreate a verification bit for each criterion (bits are immutable—no checkboxes):\n- \"Verify: [criterion 1]\"\n- \"Verify: [criterion 2]\"\n\n# Verification\nCreate a verification bit for each command:\n- \"Verify: `[lint command]` passes\"\n- \"Verify: `[test command]` passes\"\n- \"Verify: `[e2e test command]` passes\"\n- \"Verify: `[integration test command]` passes\"\n```\n\n**Section inclusion rules:**\n- Always include: Context, References, File Changes, Acceptance Criteria\n- Include Code Snippets only if discovery surfaced code to replicate or templates to follow\n- Include Verification only if the project has test or lint commands\n- Include Files to delete only if the task involves deletion or refactoring\n- Replace all bracketed examples with concrete values\n\n#### Task Requirements\n1. Scope each task to complete in one focused session\n2. Use specific language; avoid vague descriptions or qualifiers\n3. When implementation reveals new tasks or scope changes, create separate bits tasks for each discovery instead of expanding this task. Add a note linking them: \"Discovered: [task IDs]\"\n\n### Step 4: Final Verification Task (if applicable)\n\nIf a full E2E/integration test command was discovered, create a final verification task:\n\n1. **Create the task**:\n   - Title: \"Run full E2E/integration test suite\"\n   - Description: Verify all changes work together by running the complete test suite\n   - Include the discovered **full E2E** command from Phase 1\n   - Acceptance criteria: All tests pass, no regressions introduced. If any tests fail, create new tasks for each failure before closing this verification task.\n\n2. **Set up dependencies**:\n   Create the verification task first, then add dependencies to each blocker:\n   ```bash\n   bits add \"Run full E2E test suite\"\n   # Note the returned task ID (e.g., bits-xxx)\n   bits dep bits-xxx <task-1-id>\n   bits dep bits-xxx <task-2-id>\n   bits dep bits-xxx <task-3-id>\n   ```\n   This ensures the final verification runs only after all implementation work is complete.\n\n### Step 5: CLAUDE.md Update Task\n\nAfter all implementation tasks, create a documentation maintenance task:\n\n1. **Create the task**:\n   - Title: \"Update CLAUDE.md documentation\"\n   - Description: Review git commits from the last 4 days. Update CLAUDE.md files:\n     (1) Add documentation for new patterns\n     (2) Fix stale references\n     (3) Create CLAUDE.md in directories lacking documentation\n     Delete redundant or low-signal sections. Use the Explore subagent for thorough discovery. Use /commit for atomic commits.\n\n2. **Set up dependencies**:\n   This task should depend on the final verification task (if created) or all implementation tasks:\n   ```bash\n   bits add \"Update CLAUDE.md documentation\"\n   # Note the returned task ID\n   bits dep <claude-md-task-id> <verification-task-id>\n   ```\n\n## Handling Failures\n\nWhen discovery or planning reveals blocking issues:\n1. Create a P0 meta task titled: \"Create plan for [blocker-topic]\"\n2. Description must include:\n   - What was blocking and why it matters\n   - Instruction to use Explore subagent for discovery\n   - Instruction to use Plan subagent to design fix\n   - Instruction to create implementation bits tasks via bits skill\n3. Any implementation tasks spawned from meta tasks are also P0\n\n$ARGUMENTS\n",
        "plugins/abatilo-core/skills/bits/SKILL.md": "---\nname: bits\ndescription: Track and manage work items, tasks, issues, and todos with dependencies using bits. Use when user needs to create tasks, track progress, manage blockers, find ready work, claim/release tasks, close completed work, or organize multi-step projects. Triggers on \"bits\", \"task\", \"issue\", \"backlog\", \"blockers\", \"dependencies\", \"what's ready\", \"track this\", \"add to my list\", \"what should I work on\".\nargument-hint: \"[command or task description]\"\nallowed-tools:\n  - Bash(bits:*)\n  - Bash(git:*)\n  - Read\n---\n\n# Bits Task Tracking\n\n## When to Use\n\n| Scenario | Tool |\n|----------|------|\n| Multi-step work with dependencies | bits |\n| Tasks that block other tasks | bits |\n| Tracking progress across sessions | bits |\n| Simple one-off checklist | TaskCreate |\n| Quick session-scoped todos | TaskCreate |\n\n## Commands\n\n| Task | Command |\n|------|---------|\n| Find ready work | `bits ready --json` |\n| Create task | `bits add \"Title\" -d \"Description\" --json` |\n| Start work | `bits claim <id>` |\n| Pause work | `bits release <id>` |\n| Complete work | `bits close <id> \"reason\"` |\n| View details | `bits show <id>` |\n| List tasks | `bits list` |\n\nRun `bits --help` for full reference.\n\n## Dependencies\n\n```bash\nbits add \"Feature B\" --json  # Returns: bits-abc123\nbits dep bits-abc123 bits-blocker  # B blocked by blocker\n```\n\nTasks with unresolved dependencies won't appear in `bits ready`.\n\n## Session Commands\n\n| Command | Purpose |\n|---------|---------|\n| `bits session claim` | Claim primary session (reads stdin) |\n| `bits session release` | Release session (reads stdin) |\n| `bits session prune` | Manual cleanup of stale sessions |\n| `bits session hook` | Stop hook with session ownership check |\n\n## Drain Commands\n\n| Command | Purpose |\n|---------|---------|\n| `bits drain claim` | Activate drain mode (reads stdin) |\n| `bits drain release` | Deactivate drain mode (reads stdin) |\n\n## Task Description Format\n\n```markdown\n# Description\nWhat and why.\n\n# Acceptance Criteria\n- [ ] Criterion 1\n- [ ] Criterion 2\n\n# Session Notes\n[Date] COMPLETED: X | IN PROGRESS: Y | NEXT: Z\n```\n",
        "plugins/abatilo-core/skills/diataxis-documentation/SKILL.md": "---\nname: diataxis-documentation\ndescription: Write comprehensive, user-focused documentation following the Diataxis framework. Use this skill when creating or improving tutorials, how-to guides, reference documentation, or explanatory content. Helps identify the right documentation type and apply best practices for each.\nallowed-tools:\n  - Read\n  - Write\n  - Edit\n---\n\n# Diataxis Documentation Skill\n\nThis skill helps you create high-quality, user-focused documentation following the Diataxis framework, which organizes documentation into four distinct types based on user needs.\n\n## When to Use This Skill\n\nUse this skill when:\n- Creating new documentation of any kind\n- Improving existing documentation\n- Organizing documentation for a project or codebase\n- Writing tutorials, how-to guides, reference material, or explanations\n- Unsure which type of documentation is needed\n- Documentation feels unclear or serves multiple purposes poorly\n\n## The Diataxis Framework Overview\n\nDiataxis organizes documentation along two dimensions:\n\n**User Context:**\n- **Study** (Skill Acquisition): User is learning\n- **Work** (Skill Application): User is doing\n\n**Content Nature:**\n- **Action** (Practical Steps): How to do things\n- **Cognition** (Theoretical Knowledge): Understanding concepts\n\nThis creates four distinct documentation types:\n\n```\n                Study          |          Work\n           (Learning)          |         (Doing)\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━\n                                |\n    TUTORIALS                   |    HOW-TO GUIDES\n    Learning-oriented           |    Goal-oriented\n    Guided lessons              |    Practical directions\n    \"Learn by doing\"            |    \"Achieve a goal\"\n                                |\nAction ━━━━━━━━━━━━━━━━━━━━━━━━┼━━━━━━━━━━━━━━━━━━━━━━━━━━ Action\n                                |\n    EXPLANATION                 |    REFERENCE\n    Understanding-oriented      |    Information-oriented\n    Background & context        |    Technical description\n    \"Why & how it works\"        |    \"Facts about machinery\"\n                                |\n    ━━━━━━━━━━━━━━━━━━━━━━━━━━━┿━━━━━━━━━━━━━━━━━━━━━━━━━━━\nCognition                       |                    Cognition\n```\n\n## How to Use This Skill\n\n### 1. Identify the Documentation Type Needed\n\n**Ask these two questions:**\n1. **Action or Cognition?** Does the user need to DO something or UNDERSTAND something?\n2. **Study or Work?** Is the user learning something new or applying existing knowledge?\n\n**Decision Tree:**\n- Action + Study = **Tutorial** (learning by doing)\n- Action + Work = **How-to Guide** (solving a problem)\n- Cognition + Work = **Reference** (looking up facts)\n- Cognition + Study = **Explanation** (understanding concepts)\n\n### 2. Load the Appropriate Reference File\n\nBased on the documentation type identified, load the relevant reference for detailed guidance:\n\n**For Tutorials:**\nLoad [Tutorials Reference](./references/tutorials.md) when you need to:\n- Guide a learner through a complete, practical lesson\n- Teach basic skills and concepts through hands-on experience\n- Create a learning-oriented \"first steps\" experience\n- Help someone gain confidence with a new tool or technology\n\n**For How-to Guides:**\nLoad [How-to Guides Reference](./references/how-to-guides.md) when you need to:\n- Provide step-by-step instructions to achieve a specific goal\n- Help solve a particular real-world problem\n- Write task-oriented documentation for competent users\n- Address a \"How do I...\" question\n\n**For Reference Documentation:**\nLoad [Reference Documentation Reference](./references/reference.md) when you need to:\n- Document APIs, functions, classes, or configuration options\n- Provide accurate technical descriptions\n- Create lookup material for factual information\n- Write information-oriented content structured like the product\n\n**For Explanations:**\nLoad [Explanations Reference](./references/explanation.md) when you need to:\n- Explain concepts, design decisions, or architectural choices\n- Provide background and context\n- Discuss alternatives and trade-offs\n- Answer \"why\" questions about how things work\n\n**For Framework Overview:**\nLoad [Framework Overview Reference](./references/framework-overview.md) when you need:\n- Detailed understanding of Diataxis principles\n- Guidance on maintaining distinctness between types\n- Common mistakes to avoid\n- The iterative improvement workflow\n\n### 3. Follow the Iterative Improvement Process\n\nDiataxis emphasizes continuous, incremental improvement:\n\n1. **Choose**: Select a small piece of documentation (page, paragraph, or sentence)\n2. **Assess**: Evaluate it against Diataxis standards:\n   - What user need does it serve?\n   - How well does it serve that need?\n   - Does it belong in the right documentation type?\n   - Is it using the right style and approach?\n3. **Decide**: Determine one specific improvement that aligns with Diataxis\n4. **Do**: Complete that single improvement and publish immediately\n\n**Important:** Focus on small, immediate improvements rather than large restructuring efforts.\n\n## Key Principles\n\n### Maintain Distinctness\n- Each documentation type has a specific purpose - don't blur them\n- Tutorials teach through doing, not explaining\n- How-to guides solve problems, not teach concepts\n- Reference describes facts, not guide users through tasks\n- Explanations provide context, not instructions\n\n### User-Centered Approach\n- Always consider: What does the user need right now?\n- Match the documentation type to the user's context (study vs. work)\n- Match the content to the user's need (action vs. cognition)\n\n### Organic Structure\n- Don't create empty documentation structures upfront\n- Let structure emerge from content improvements\n- Create documentation types only when content demands it\n\n### Link Between Types\n- Tutorials can link to explanations for deeper understanding\n- How-to guides can reference relevant reference material\n- Keep each type focused; use links for cross-cutting needs\n\n## Quick Documentation Type Selector\n\n**User says \"How do I...\"**\n- If they're learning → Tutorial\n- If they're working → How-to Guide\n\n**User needs facts about something**\n→ Reference\n\n**User asks \"Why...\" or \"What is...\"**\n→ Explanation\n\n**User is frustrated or stuck**\n- Check recent tasks → How-to Guide\n- Check understanding → Explanation\n- Check syntax/parameters → Reference\n\n**Creating first-time user content**\n→ Tutorial\n\n## Common Patterns\n\n### Tutorial Example Scenarios\n- \"Build your first web app\"\n- \"Getting started with X\"\n- \"Introduction to Y\"\n- \"Your first Z project\"\n\n### How-to Guide Example Scenarios\n- \"How to deploy to production\"\n- \"Implementing authentication\"\n- \"Optimizing database queries\"\n- \"Troubleshooting connection errors\"\n\n### Reference Example Scenarios\n- API documentation\n- Configuration file reference\n- Command-line options\n- Class/function documentation\n\n### Explanation Example Scenarios\n- \"Understanding the architecture\"\n- \"Why we chose X over Y\"\n- \"How the authentication system works\"\n- \"Database design decisions\"\n\n## Important Notes\n\n- Load specific reference files only when needed to keep context manageable\n- Each documentation type requires different writing styles and structures\n- Avoid mixing purposes - if documentation tries to do multiple things, split it\n- The framework is descriptive, not prescriptive - adapt to your project's needs\n- Iterate continuously rather than attempting complete restructuring\n- Quality comes from alignment with user needs, not from following rigid templates\n\n---\n\n**Remember:** The goal is to serve user needs effectively. Use the Diataxis compass to identify what users need, then load the appropriate reference file for detailed guidance on creating that documentation type.\n",
        "plugins/abatilo-core/skills/diataxis-documentation/references/explanation.md": "# Writing Explanations\n\n## What is an Explanation?\n\nExplanation is **understanding-oriented** documentation that provides context, background, and clarifies concepts to deepen the user's understanding of a subject.\n\n**Key characteristics:**\n- Understanding-oriented\n- Provides context and background\n- Explains \"why\" and \"how it works\"\n- Discusses alternatives and trade-offs\n- Can include opinions and perspectives\n\n**User context:**\n- Learning and building understanding\n- Study mode (not actively working)\n- Wants to understand concepts\n- Seeking deeper knowledge\n\n**User question:** \"Why...?\" or \"How does this work?\" or \"What is...?\"\n\n## Purpose and Goals\n\n### Primary Purpose\nHelp users understand concepts, design decisions, and how things work at a deeper level.\n\n### Success Criteria\n- User gains understanding of concepts\n- User understands \"why\" things are the way they are\n- User can make informed decisions\n- User sees the bigger picture\n- User understands trade-offs and alternatives\n\n### What Explanations Are NOT\n- Not step-by-step instructions (that's Tutorials or How-to Guides)\n- Not technical specifications (that's Reference)\n- Not problem-solving (that's How-to Guides)\n- Not meant for quick lookups (that's Reference)\n- Not teaching through doing (that's Tutorials)\n\n## Core Principles\n\n### 1. Provide Context and Background\n\nExplain the \"why\" behind decisions and the context around concepts.\n\n**Good:**\n```markdown\n# Why We Use Event-Driven Architecture\n\nWe chose event-driven architecture for this system because\nour domain involves multiple independent services that need\nto react to state changes without tight coupling.\n\nTraditional request-response patterns would create dependencies\nbetween services, making the system harder to scale and maintain.\nWith events, each service can evolve independently.\n\nHowever, this approach introduces eventual consistency, which\nmeans there's a brief window where different services may have\ndifferent views of the data. This trade-off is acceptable for\nour use case because...\n```\n\n**Bad:**\n```markdown\n# Event-Driven Architecture\n\nTo implement events, follow these steps...\n(This is a how-to, not an explanation)\n```\n\n### 2. Make Connections\n\nLink concepts together and show how they relate to each other and the bigger picture.\n\n**Good:**\n```markdown\n# Understanding Authentication and Authorization\n\nAuthentication and authorization are often confused, but they\nserve distinct purposes in security:\n\n**Authentication** answers \"who are you?\" It verifies identity.\n\n**Authorization** answers \"what can you do?\" It controls access.\n\nThey work together in a typical flow:\n1. User authenticates (proves identity)\n2. System looks up user's roles/permissions\n3. System authorizes (or denies) each requested action\n\nThis separation allows you to change authorization rules\nwithout re-authenticating users, and to authenticate users\nwithout knowing in advance what they'll try to access.\n```\n\n**Bad:**\n```markdown\n# Authentication\n\nCall the `authenticate()` function with credentials...\n(This is reference or how-to, not explanation)\n```\n\n### 3. Discuss Alternatives and Trade-offs\n\nExplore different approaches, explaining pros and cons.\n\n**Good:**\n```markdown\n# Database Choice: SQL vs. NoSQL\n\nFor this application, we considered both SQL and NoSQL databases.\n\n**SQL (PostgreSQL) Advantages:**\n- ACID transactions ensure data consistency\n- Mature ecosystem and tooling\n- Powerful query capabilities with JOINs\n- Well-understood by the team\n\n**SQL Disadvantages:**\n- Schema changes can be complex\n- Horizontal scaling is more difficult\n- Fixed schema doesn't fit all data\n\n**NoSQL (MongoDB) Advantages:**\n- Flexible schema fits varied data\n- Easier horizontal scaling\n- Better performance for certain access patterns\n\n**NoSQL Disadvantages:**\n- No transactions across documents (in older versions)\n- Less mature tooling\n- Eventual consistency can be complex\n\nWe chose PostgreSQL because our data is highly relational\nand consistency is critical for financial transactions.\n```\n\n**Bad:**\n```markdown\n# Database Setup\n\nInstall PostgreSQL:\n```bash\napt-get install postgresql\n```\n(This is a tutorial/how-to, not explanation)\n```\n\n### 4. Explain \"How It Works\"\n\nDescribe mechanisms, processes, and internal workings at a conceptual level.\n\n**Good:**\n```markdown\n# How Caching Improves Performance\n\nWhen you request data from the database, it's a slow operation:\n1. Network round-trip to database server\n2. Database query execution\n3. Data serialization and transfer\n\nA cache sits between your application and the database,\nstoring frequently-accessed data in memory. When you request\ndata:\n\n**First request (cache miss):**\n1. Check cache → not found\n2. Query database\n3. Store result in cache\n4. Return result\n**Time: ~50ms**\n\n**Subsequent requests (cache hit):**\n1. Check cache → found\n2. Return cached result\n**Time: ~1ms**\n\nThis 50x speedup comes with trade-offs:\n- **Staleness**: Cached data may be outdated\n- **Memory usage**: Cache consumes RAM\n- **Complexity**: Cache invalidation is notoriously difficult\n\nThe benefit is usually worth these costs for read-heavy\nworkloads where data doesn't change frequently.\n```\n\n**Bad:**\n```markdown\n# Caching\n\nCaching stores data in memory for fast access. It's important\nfor performance. Here's how to implement it...\n(Too brief and moves into how-to)\n```\n\n### 5. Accommodate Perspective and Opinion\n\nUnlike reference documentation, explanations can include opinions, perspectives, and subjective insights.\n\n**Good:**\n```markdown\n# Our Microservices Philosophy\n\nWe believe microservices should be organized around business\ncapabilities, not technical layers. This is somewhat controversial\nin the industry, where many teams organize services by data types\nor technical functions.\n\nWe've found that business-capability boundaries are more stable\nover time. Product features change, but core business capabilities\n(\"process orders,\" \"manage inventory\") remain consistent.\n\nThis approach has served us well, though it does mean some\ncode duplication across services. We consider this acceptable—\nit's a trade-off we've consciously chosen for better service\nindependence.\n```\n\n**Bad:**\n```markdown\n# Microservices\n\nMicroservices are an architectural style where applications\nare composed of small, independent services. Each service...\n(Too dry, sounds like reference material)\n```\n\n### 6. Go Deeper Than Necessary\n\nExplanations can explore topics beyond immediate practical needs, satisfying curiosity.\n\n**Good:**\n```markdown\n# The History of Our API Design\n\nOur API started as a traditional REST API in 2018. As we grew,\nwe hit limitations:\n- Mobile apps needed different data shapes than web\n- Multiple round-trips caused slow performance\n- Version management became complex\n\nWe evaluated several alternatives:\n- **REST with better batching**: Didn't solve different-data-shapes problem\n- **gRPC**: Better performance but poor browser support\n- **GraphQL**: Solved data shape and round-trip issues\n\nWe chose GraphQL in 2020. The migration took six months...\n\nToday, we're exploring edge computing with GraphQL resolvers\nat the CDN level, which would reduce latency further...\n```\n\nThis historical context and future thinking isn't immediately practical, but helps readers understand the evolution and direction.\n\n## Structure of an Explanation\n\n### 1. Title and Introduction\n\nState what you're explaining and why it matters.\n\n**Example:**\n```markdown\n# Understanding Eventual Consistency\n\nEventual consistency is a key concept in distributed systems that\noften confuses developers coming from traditional database backgrounds.\nUnderstanding it is crucial for working with distributed architectures.\n```\n\n### 2. Main Content (Flexible Structure)\n\nUnlike other documentation types, explanations don't follow a rigid structure. Common approaches:\n\n**Concept Introduction:**\n- Define the concept\n- Explain why it exists\n- Show how it relates to other concepts\n\n**Historical/Evolutionary:**\n- How did we get here?\n- What problems were we trying to solve?\n- How has thinking evolved?\n\n**Comparative:**\n- Compare different approaches\n- Explain trade-offs\n- When to use each\n\n**Mechanism Explanation:**\n- How does this work internally?\n- What are the components?\n- How do they interact?\n\n**Problem/Solution:**\n- What problem does this solve?\n- Why is it solved this way?\n- What are the implications?\n\n### 3. Conclusion (Optional)\n\nSummarize key points or provide perspective.\n\n**Example:**\n```markdown\n## Key Takeaways\n\nEventual consistency is a trade-off: you gain availability\nand partition tolerance at the cost of immediate consistency.\nFor many modern applications, this trade-off makes sense,\nbut it requires different thinking about data and operations.\n```\n\n## Writing Style\n\n### Use Conversational Tone\n\nExplanations can be more conversational than other documentation types.\n\n**Good:** \"Let's explore why we made this decision...\"\n**Acceptable:** \"You might wonder why...\"\n**Acceptable:** \"This is a common point of confusion...\"\n\n### Tell a Story\n\nNarrative structure helps understanding.\n\n**Good:**\n```markdown\nWhen we first built the notification system, we used a simple\npolling approach. Every 30 seconds, clients would ask: \"any\nnew notifications?\" This worked fine with 100 users.\n\nAt 10,000 users, we had a problem. The server was handling\n20,000 requests per minute just for polling, and most returned\n\"no new notifications.\" We were wasting resources.\n\nThis led us to WebSockets...\n```\n\n**Bad:**\n```markdown\nNotification systems can use polling or WebSockets. Each has\nadvantages and disadvantages. Polling is simpler. WebSockets\nare more efficient.\n```\n\n### Use Analogies and Metaphors\n\nHelp readers build mental models.\n\n**Good:**\n```markdown\nThink of a database transaction like a shopping cart at a store.\nYou can add items (changes) to your cart, but nothing is final\nuntil you check out (commit). If you change your mind, you can\nput everything back (rollback) and it's as if you never picked\nup those items.\n```\n\n### Explore \"What If\" Scenarios\n\nHelp readers understand implications.\n\n**Good:**\n```markdown\nWhat if we didn't use a load balancer?\n\nWith no load balancer, you'd need to:\n- Give clients the list of all server addresses\n- Implement client-side load distribution logic\n- Handle server failures in every client\n- Update all clients when servers change\n\nThis complexity in every client is why we centralize it\nin a load balancer.\n```\n\n### Include Diagrams and Visuals\n\nExplanations benefit greatly from diagrams.\n\n**Good:**\n```markdown\n# How Request Routing Works\n\n```\nClient → Load Balancer → Server 1\n                       → Server 2\n                       → Server 3\n```\n\nThe load balancer receives all client requests and distributes\nthem across available servers based on current load...\n```\n\n## Best Practices\n\n### ✓ DO\n\n- **Explain \"why\"**: The reasoning behind decisions\n- **Provide context**: Historical, technical, business\n- **Make connections**: Link concepts to the bigger picture\n- **Discuss alternatives**: What else could we have done?\n- **Share trade-offs**: What did we gain? What did we sacrifice?\n- **Use examples**: Concrete scenarios to illustrate abstract concepts\n- **Include opinions**: Perspectives and subjective insights\n- **Tell stories**: Narrative helps understanding\n- **Go deep**: Satisfy curiosity beyond immediate needs\n- **Admit uncertainty**: \"We're still learning...\" is OK\n- **Link to other docs**: Reference specs, tutorials, how-tos\n\n### ✗ DON'T\n\n- **Don't provide step-by-step instructions**: That's tutorials/how-tos\n- **Don't try to be comprehensive reference**: Link to reference instead\n- **Don't solve specific problems**: That's how-to guides\n- **Don't assume no prior knowledge**: Explanations build on basics\n- **Don't be dogmatic**: Acknowledge different valid perspectives\n- **Don't ignore complexity**: Simplify, but don't oversimplify\n- **Don't forget the \"why\"**: Explanation without \"why\" is just description\n\n## Common Patterns\n\n### Pattern 1: Concept Explanation\n```markdown\n# Understanding [Concept]\n\n## What is [Concept]?\nDefinition and basic understanding\n\n## Why [Concept] Exists\nProblems it solves, context for its existence\n\n## How [Concept] Works\nMechanisms and processes\n\n## When to Use [Concept]\nSituations where it's appropriate\n\n## Trade-offs and Alternatives\nWhat else exists and why choose this\n```\n\n### Pattern 2: Design Decision Explanation\n```markdown\n# Why We Chose [Technology/Approach]\n\n## The Problem We Faced\nContext and requirements\n\n## Alternatives We Considered\nOptions and their pros/cons\n\n## Why We Chose [This]\nReasoning for the decision\n\n## What We Learned\nResults and reflections\n```\n\n### Pattern 3: How It Works\n```markdown\n# How [System/Feature] Works\n\n## Overview\nHigh-level description\n\n## Components\nKey parts and their roles\n\n## Flow\nHow it all works together\n\n## Edge Cases\nInteresting scenarios and how they're handled\n```\n\n### Pattern 4: Comparative Explanation\n```markdown\n# [Approach A] vs [Approach B]\n\n## Overview of Each\nBrief description of both\n\n## Key Differences\nWhere they diverge\n\n## When to Use Each\nGuidance on choosing\n\n## Our Choice and Why\nIf applicable, what we chose\n```\n\n## Example: Good Explanation\n\n```markdown\n# Understanding Our Caching Strategy\n\n## The Performance Challenge\n\nOur application serves product data that changes infrequently\n(maybe once per day) but is accessed thousands of times per\nsecond. Without caching, every request hits the database:\n\n- Database queries: ~50ms per request\n- At 1000 requests/second: 50,000ms of DB time per second\n- Database becomes the bottleneck\n- Response time suffers\n\n## The Caching Approach\n\nWe cache product data in Redis, a fast in-memory store:\n\n**First request (cache miss):**\n```\nClient → API → Redis (miss) → Database → Redis (store) → API → Client\nTotal: ~50ms\n```\n\n**Subsequent requests (cache hit):**\n```\nClient → API → Redis (hit) → API → Client\nTotal: ~2ms\n```\n\nThis 25x speedup means we can handle 1000 requests/second\nusing only 2 seconds of total processing time.\n\n## The Staleness Trade-off\n\nCaching introduces a problem: **stale data**. When a product\nprice changes in the database, cached copies don't automatically\nupdate.\n\nWe considered several approaches:\n\n### Approach 1: Time-Based Expiration\nCache entries expire after a fixed time (e.g., 1 hour).\n\n**Pros:**\n- Simple to implement\n- Predictable memory usage\n\n**Cons:**\n- Data can be stale for up to 1 hour\n- Cache misses happen periodically even for popular items\n\n### Approach 2: Manual Invalidation\nExplicitly delete cache entries when data changes.\n\n**Pros:**\n- Cache is always current\n- No unnecessary invalidation\n\n**Cons:**\n- Must remember to invalidate on every data change\n- Easy to miss edge cases\n- Doesn't handle external data changes\n\n### Approach 3: Event-Based Invalidation\nDatabase triggers emit events when data changes; cache listens\nand invalidates automatically.\n\n**Pros:**\n- Automatic and reliable\n- Catches all changes\n\n**Cons:**\n- Complex to set up\n- Adds infrastructure (event bus)\n- Possible race conditions\n\n## Our Choice: Hybrid Approach\n\nWe use **time-based expiration (5 minutes) + manual invalidation**:\n\n- Default 5-minute TTL means data is never more than 5 minutes stale\n- Critical operations (price changes, inventory updates) manually invalidate cache\n- Balances simplicity with freshness\n\nThis isn't perfect. We still have brief staleness windows, but\nthey're acceptable for our use case. An e-commerce site might\nneed event-based invalidation for inventory; we sell less\ntime-sensitive content.\n\n## The Cache Warming Problem\n\nWith time-based expiration, popular items expire periodically.\nWhen they do, the next request is slow (cache miss).\n\nWe solve this with **background refresh**: 30 seconds before\nexpiration, we refresh the cache in the background. Users\nnever experience cache misses for popular items.\n\nThis adds complexity, but the user experience improvement is\nworth it.\n\n## What We Learned\n\nCaching isn't just about speed—it's about trade-offs:\n- **Staleness vs. freshness**: How up-to-date must data be?\n- **Complexity vs. simplicity**: Is advanced caching worth the maintenance?\n- **Memory vs. database load**: What's your bottleneck?\n\nFor us, a simple TTL-based approach with selective invalidation\nhits the sweet spot. Your needs might differ.\n\n## Further Reading\n\n- [How to implement caching →](link-to-how-to)\n- [Cache API reference →](link-to-reference)\n- [Getting started tutorial →](link-to-tutorial)\n```\n\n## Checklist for Explanation Quality\n\nBefore publishing, verify:\n\n- [ ] Explains \"why\" not just \"what\"\n- [ ] Provides context and background\n- [ ] Discusses alternatives or trade-offs\n- [ ] Makes connections to broader concepts\n- [ ] Includes examples or scenarios\n- [ ] Tells a coherent story\n- [ ] Avoids step-by-step instructions\n- [ ] Avoids comprehensive technical reference\n- [ ] Links to other documentation types\n- [ ] Appropriate level of depth\n- [ ] Clear and engaging writing\n- [ ] Diagrams or visuals where helpful\n\n## Common Mistakes\n\n### Mistake: Turning Into a Tutorial\n**Bad:**\n```markdown\n# Understanding Authentication\n\nFirst, install the auth package:\n```bash\nnpm install auth\n```\n\nThen create a config file...\n```\n\n**Good:**\n```markdown\n# Understanding Authentication\n\nAuthentication verifies user identity through credentials.\nThe process typically involves...\n```\n\n### Mistake: Duplicating Reference Material\n**Bad:**\n```markdown\nThe `authenticate()` function takes parameters: username (string),\npassword (string), options (object)...\n```\n\n**Good:**\n```markdown\nAuthentication typically requires credentials (username and password)\nand may include additional options. [See API reference](link)\n```\n\n### Mistake: Being Too Dry\n**Bad:** \"Caching stores data. It's faster than databases.\"\n**Good:** \"Imagine if every time you wanted to check your phone number,\nyou had to look it up in a phone book. You'd probably remember it\nafter the first lookup. That's caching.\"\n\n### Mistake: No \"Why\"\n**Bad:** \"We use microservices. Each service is independent.\"\n**Good:** \"We chose microservices because our teams were blocking\neach other with monolith deploys. Independent services let teams\ndeploy independently.\"\n\n### Mistake: Ignoring Trade-offs\n**Bad:** \"Use this approach because it's best\"\n**Good:** \"We chose this approach because it optimizes for X at the\ncost of Y, which aligns with our priorities.\"\n\n### Mistake: Too Much Detail\n**Bad:** Explaining every parameter, every edge case, every line of code\n**Good:** Explaining concepts, mechanisms, decisions at appropriate level\n\n---\n\n**Remember**: Explanations help people understand. They answer \"why\" and \"how it works\" at a conceptual level. They provide context, explore alternatives, and build mental models. They can be conversational, opinionated, and deeper than immediately practical. Use them to help your users really *get* what's going on.\n",
        "plugins/abatilo-core/skills/diataxis-documentation/references/framework-overview.md": "# Diataxis Framework Overview\n\nThis reference provides comprehensive details about the Diataxis documentation framework, its principles, and how to apply it effectively.\n\n## What is Diataxis?\n\nDiataxis is a systematic approach to technical documentation authoring that organizes content based on user needs. It identifies four distinct types of documentation, each serving a different purpose in the user's journey.\n\nThe name \"Diataxis\" comes from the ancient Greek διάταξις, meaning \"arrangement\" or \"disposition.\"\n\n## The Two-Dimensional Model\n\nDiataxis organizes documentation along two axes:\n\n### Axis 1: Action vs. Cognition\n- **Action**: Documentation that informs practical steps (what to DO)\n- **Cognition**: Documentation that informs understanding (what to KNOW)\n\n### Axis 2: Acquisition vs. Application\n- **Acquisition** (Study): User is learning and acquiring new skills\n- **Application** (Work): User is applying existing knowledge to accomplish tasks\n\n## The Four Documentation Types\n\n| Type | Orientation | Context | Content | User Question |\n|------|-------------|---------|---------|---------------|\n| **Tutorial** | Learning-oriented | Study + Action | Guided lesson | \"Can you teach me...?\" |\n| **How-to Guide** | Goal-oriented | Work + Action | Problem-solving steps | \"How do I...?\" |\n| **Reference** | Information-oriented | Work + Cognition | Technical description | \"What exactly is...?\" |\n| **Explanation** | Understanding-oriented | Study + Cognition | Background & context | \"Why...?\" |\n\n### Visual Representation\n\n```\n                        User is STUDYING (acquiring skills)\n                                    ↓\n\n            TUTORIALS                        EXPLANATION\n         Learning-oriented              Understanding-oriented\n         \"Teach me to...\"                   \"Help me understand...\"\n                ↓                                   ↓\n\nUser needs  → [Action]  ←━━━━━━━━━━━━━━━━━━━→ [Cognition] ← User needs\nto DO                                                         to KNOW\n                ↓                                   ↓\n\n         HOW-TO GUIDES                      REFERENCE\n         Goal-oriented                  Information-oriented\n         \"Help me achieve...\"              \"Tell me facts about...\"\n\n                                    ↑\n                        User is WORKING (applying skills)\n```\n\n## The Compass: Identifying Documentation Type\n\nThe Diataxis compass helps you classify content by asking two key questions:\n\n### Question 1: Does this content primarily inform ACTION or COGNITION?\n- **Action**: Contains steps, instructions, procedures, commands to execute\n- **Cognition**: Explains concepts, provides context, describes facts\n\n### Question 2: Is the user ACQUIRING skills or APPLYING skills?\n- **Acquiring** (Study): User is learning something new, building understanding\n- **Applying** (Work): User has knowledge and is using it to accomplish something\n\n### Decision Matrix\n\n| Action + Acquisition | Action + Application |\n|---------------------|---------------------|\n| **TUTORIAL** | **HOW-TO GUIDE** |\n| Learning by doing | Solving a problem |\n\n| Cognition + Acquisition | Cognition + Application |\n|------------------------|------------------------|\n| **EXPLANATION** | **REFERENCE** |\n| Understanding why | Looking up facts |\n\n## Core Principles\n\n### 1. Separation of Concerns\n\nEach documentation type should maintain its distinct purpose. Mixing purposes creates \"blur\" that confuses users and reduces effectiveness.\n\n**Examples of harmful blur:**\n- Tutorials that try to explain everything (overwhelming the learner)\n- Reference material that tries to teach (not useful for quick lookups)\n- How-to guides that explain concepts (distracting from the goal)\n- Explanations that include step-by-step instructions (loses conceptual focus)\n\n### 2. User-Centered Design\n\nDocumentation should be organized around user needs, not product features or author preferences.\n\n**Key considerations:**\n- What is the user trying to accomplish right now?\n- What stage of the journey is the user in?\n- What kind of information serves this user's current need?\n\n### 3. Iterative Improvement\n\nDiataxis emphasizes continuous, small improvements over large restructuring efforts.\n\n**The improvement cycle:**\n1. **Choose**: Pick a small piece of documentation\n2. **Assess**: Evaluate against Diataxis principles\n3. **Decide**: Identify one specific improvement\n4. **Do**: Make that single change and publish it\n\n**Anti-patterns to avoid:**\n- Planning entire documentation structure upfront\n- Creating empty sections for all four types\n- Working on large tranches of documentation at once\n- Waiting for \"complete\" documentation before publishing\n\n### 4. Organic Structure\n\nDocumentation structure should emerge naturally from content improvements, not be imposed externally.\n\n**Good practice:**\n- Create documentation types only when content demands it\n- Let similar content naturally group together\n- Move content to new sections when it makes sense\n- Don't create placeholder sections\n\n**Bad practice:**\n- Creating empty \"Tutorials,\" \"How-to,\" \"Reference,\" \"Explanation\" sections\n- Forcing all documentation into the four-type structure\n- Planning structure before creating content\n\n## Maintaining Distinctness\n\nEach documentation type has specific characteristics that keep it focused and effective:\n\n### Tutorials: Learning-Oriented\n- **DO**: Guide through complete practical lesson\n- **DO**: Focus on getting user to successful result\n- **DO**: Minimize explanation and choices\n- **DON'T**: Explain concepts in depth\n- **DON'T**: Offer alternatives or options\n- **DON'T**: Assume prior knowledge beyond basics\n\n### How-to Guides: Goal-Oriented\n- **DO**: Focus on achieving a specific goal\n- **DO**: Provide practical directions\n- **DO**: Assume user competence\n- **DON'T**: Teach concepts\n- **DON'T**: Explain why unless critical\n- **DON'T**: Cover unrelated topics\n\n### Reference: Information-Oriented\n- **DO**: Describe accurately and completely\n- **DO**: Maintain neutral, objective tone\n- **DO**: Structure according to product architecture\n- **DON'T**: Include instructions or tutorials\n- **DON'T**: Add opinions or recommendations\n- **DON'T**: Explain concepts\n\n### Explanation: Understanding-Oriented\n- **DO**: Provide context and background\n- **DO**: Explain \"why\" things are the way they are\n- **DO**: Discuss alternatives and trade-offs\n- **DON'T**: Include step-by-step instructions\n- **DON'T**: Try to be comprehensive reference\n- **DON'T**: Focus on one specific task\n\n## Common Mistakes\n\n### 1. Top-Down Planning\n**Mistake**: Creating a complete four-type structure before writing content.\n**Solution**: Start with existing content and improve it iteratively using Diataxis principles.\n\n### 2. Documentation Type Confusion\n**Mistake**: Tutorial that explains concepts extensively, or how-to guide that teaches basics.\n**Solution**: Use the compass to identify the primary user need and maintain focus.\n\n### 3. Trying to Do Everything\n**Mistake**: One piece of documentation trying to teach, guide, reference, and explain.\n**Solution**: Split into multiple pieces, each with a clear, single purpose.\n\n### 4. Empty Structure\n**Mistake**: Creating sections for all four types with \"Coming soon\" placeholders.\n**Solution**: Create documentation only when you have content. Structure emerges from content.\n\n### 5. Perfectionism\n**Mistake**: Waiting until documentation is \"complete\" before publishing.\n**Solution**: Publish small improvements continuously. Perfection comes through iteration.\n\n### 6. Ignoring Existing Style\n**Mistake**: Imposing Diataxis rigidly without considering project context.\n**Solution**: Adapt Diataxis to fit your project's needs and existing conventions.\n\n## Relationships Between Documentation Types\n\nWhile each type should remain distinct, they can and should reference each other:\n\n### From Tutorials\n- Link to **Explanations** for users who want deeper understanding\n- Link to **Reference** for detailed parameter information\n- Link to **How-to Guides** for related real-world tasks\n\n### From How-to Guides\n- Link to **Tutorials** if user might lack foundational knowledge\n- Link to **Reference** for technical details about commands/APIs used\n- Link to **Explanations** for context on why this approach works\n\n### From Reference\n- Provide minimal examples without teaching (can link to **Tutorials**)\n- Avoid explanations (link to **Explanations** instead)\n- Focus solely on accurate, factual description\n\n### From Explanations\n- Reference related **Tutorials** for hands-on learning\n- Link to **How-to Guides** for practical applications\n- Point to **Reference** for technical specifications\n\n## Quality Metrics\n\nDocumentation quality in Diataxis is measured by:\n\n1. **User Alignment**: Does it serve the right user need at the right time?\n2. **Focus**: Does it maintain clear purpose without blur?\n3. **Completeness**: Within its type, does it provide what's needed?\n4. **Accessibility**: Can users find and understand it?\n5. **Accuracy**: Is the information correct and current?\n\n## Applying Diataxis to Your Project\n\n### Starting Point\n\n**If you have existing documentation:**\n1. Pick any piece of documentation\n2. Identify its primary user need using the compass\n3. Assess how well it serves that need\n4. Make one small improvement aligned with its type\n5. Repeat\n\n**If you're starting from scratch:**\n1. Identify what users need most urgently (often: tutorial or how-to)\n2. Create that single piece of documentation\n3. Iteratively add more content based on user feedback\n4. Let structure emerge organically\n\n### Common Scenarios\n\n**Building a new tool:**\n1. Start with Tutorial (help users get started)\n2. Add Reference (document the API/commands)\n3. Add How-to Guides (solve common problems)\n4. Add Explanations (help users understand design decisions)\n\n**Improving existing documentation:**\n1. Identify pages that try to do too much\n2. Split them according to Diataxis types\n3. Ensure each piece has a clear, single purpose\n4. Add cross-references between related pieces\n\n## Integration with Other Systems\n\nDiataxis is compatible with:\n- **Docs-as-code**: Version control, CI/CD for documentation\n- **Static site generators**: Jekyll, Hugo, Sphinx, MkDocs\n- **Documentation platforms**: ReadTheDocs, GitBook, Docusaurus\n- **Agile workflows**: Iterative improvement fits naturally with sprints\n- **Content management systems**: Can structure content hierarchically\n\n## Further Learning\n\n- The Diataxis website: https://diataxis.fr/\n- Focus on understanding user needs first, framework second\n- Practice identifying documentation types in existing docs\n- Experiment with improving one piece of documentation at a time\n\n---\n\n**Remember**: Diataxis is a guide, not a rigid rulebook. The goal is better documentation that serves user needs effectively. Adapt the framework to your project's context while maintaining the core principle of separation based on user needs.\n",
        "plugins/abatilo-core/skills/diataxis-documentation/references/how-to-guides.md": "# Writing How-to Guides\n\n## What is a How-to Guide?\n\nA how-to guide is **goal-oriented** documentation that helps a competent user achieve a specific real-world task or solve a particular problem.\n\n**Key characteristics:**\n- Problem-solving focused\n- Task-oriented\n- Assumes user competence\n- Provides practical directions\n- Goal-driven\n\n**User context:**\n- Has working knowledge of the tool\n- Working mode (not learning)\n- Has a specific problem to solve\n- Needs efficient solution\n\n**User question:** \"How do I...?\"\n\n## Purpose and Goals\n\n### Primary Purpose\nHelp an already-competent user accomplish a specific real-world goal efficiently.\n\n### Success Criteria\n- User achieves their specific goal\n- Solution is practical and actionable\n- User can adapt approach to similar problems\n- Time to solution is minimized\n- Steps are clear and direct\n\n### What How-to Guides Are NOT\n- Not tutorials (those teach basics to beginners)\n- Not reference documentation (those describe all features)\n- Not explanatory (those explain concepts and \"why\")\n- Not comprehensive (focused on one specific goal)\n- Not for beginners (assumes working knowledge)\n\n## Core Principles\n\n### 1. Focus on the Goal\n\nStart with the user's goal, not the tool's features.\n\n**Good:**\n```markdown\n# How to Deploy Your Application to Production\n\nThis guide shows you how to deploy your application\nto a production server with zero downtime.\n```\n\n**Bad:**\n```markdown\n# The Deployment System\n\nOur deployment system has many features including\nblue-green deployments, canary releases, and rollback\ncapabilities. Let's explore each one...\n```\n\n### 2. Assume Competence\n\nThe user knows the basics. Don't teach fundamentals.\n\n**Good:**\n```markdown\n# How to Add Caching\n\nAdd a Redis cache layer to improve performance:\n\n1. Install Redis: `npm install redis`\n2. Configure the connection in `config/cache.js`\n3. Wrap your database queries with cache calls\n```\n\n**Bad:**\n```markdown\n# How to Add Caching\n\nFirst, let's understand what caching is. Caching is a\ntechnique where you store frequently accessed data\nin memory to avoid repeated expensive operations...\n```\n\n### 3. Be Practical and Direct\n\nProvide concrete steps for the specific goal, not general advice.\n\n**Good:**\n```markdown\nEdit your nginx config at `/etc/nginx/sites-available/default`:\n```nginx\nlocation / {\n    proxy_pass http://localhost:3000;\n}\n```\n```\n\n**Bad:**\n```markdown\nYou'll need to configure your reverse proxy. Depending on\nyour setup, you might be using nginx, Apache, or HAProxy.\nEach has different configuration approaches...\n```\n\n### 4. Acknowledge Real-World Constraints\n\nAddress actual conditions users face, including limitations and trade-offs.\n\n**Good:**\n```markdown\n# How to Migrate Data with Zero Downtime\n\n**Note**: This approach requires 2x database storage during\nmigration. If storage is limited, see [alternative migration\nstrategies](link).\n```\n\n**Bad:**\n```markdown\n# How to Migrate Data\n\nJust run the migration script.\n```\n\n### 5. Provide Context for Decisions\n\nWhen choices matter, briefly explain why you're recommending a particular approach.\n\n**Good:**\n```markdown\nUse environment variables for sensitive configuration:\n```bash\nexport API_KEY=your_key_here\n```\n\nThis keeps secrets out of version control and allows\ndifferent values per environment.\n```\n\n**Bad:**\n```markdown\nSet your API key however you prefer.\n```\n\n### 6. Link to Related Resources\n\nDon't explain concepts or provide comprehensive reference. Link instead.\n\n**Good:**\n```markdown\nConfigure CORS headers in your middleware:\n```javascript\napp.use(cors({ origin: 'https://example.com' }))\n```\n\nSee [CORS options reference](link) for all available settings.\n```\n\n**Bad:**\n```markdown\nCORS (Cross-Origin Resource Sharing) is a security feature\nthat restricts resources from being accessed by web pages\nfrom different domains. It works by using HTTP headers\nthat tell browsers whether a particular request...\n```\n\n## Structure of a How-to Guide\n\n### 1. Title: \"How to [Achieve Goal]\"\n\nMake the goal immediately clear.\n\n**Good:**\n- \"How to Set Up Continuous Deployment\"\n- \"How to Add OAuth Authentication\"\n- \"How to Optimize Database Queries\"\n\n**Bad:**\n- \"Continuous Deployment\" (not action-oriented)\n- \"OAuth Guide\" (too vague)\n- \"Database Performance\" (not specific)\n\n### 2. Introduction (Brief)\n\n**What to include:**\n- What problem this solves\n- What the user will achieve\n- Any prerequisites or requirements\n- (Optional) When this approach is appropriate\n\n**Keep it short:** 2-3 sentences max.\n\n**Example:**\n```markdown\n# How to Set Up Continuous Deployment\n\nThis guide shows you how to automatically deploy your application\nto production when you push to the main branch.\n\n**Prerequisites**: GitHub repository, production server with SSH access\n```\n\n### 3. Steps (The Main Content)\n\n**Structure each step as:**\n1. Action to take\n2. Specific commands/code\n3. Brief explanation if needed\n4. Verification (when helpful)\n\n**Example:**\n```markdown\n## Step 1: Configure GitHub Actions\n\nCreate `.github/workflows/deploy.yml`:\n```yaml\nname: Deploy\non:\n  push:\n    branches: [main]\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - run: npm install\n      - run: npm run build\n```\n\nThis workflow triggers on every push to main and\nbuilds your application.\n\n## Step 2: Add Deploy Script\n\nCreate `deploy.sh`:\n```bash\n#!/bin/bash\nscp -r build/* user@server:/var/www/app/\n```\n\nMake it executable: `chmod +x deploy.sh`\n```\n\n### 4. Verification (Optional)\n\nShow how to confirm the solution works.\n\n**Example:**\n```markdown\n## Verify the Deployment\n\nPush a change to the main branch:\n```bash\ngit push origin main\n```\n\nCheck the Actions tab in GitHub. You should see\na successful deployment run.\n\nVisit your production URL to see the changes live.\n```\n\n### 5. Troubleshooting (Optional)\n\nAddress common issues specific to this task.\n\n**Example:**\n```markdown\n## Troubleshooting\n\n**Problem**: \"Permission denied\" error during deployment\n**Solution**: Add your deployment key to the server's authorized_keys\n\n**Problem**: Changes not appearing on production\n**Solution**: Check that the build directory is being copied correctly\n```\n\n### 6. Next Steps / Related Guides (Optional)\n\nLink to related how-to guides or relevant explanations.\n\n**Example:**\n```markdown\n## Related Guides\n- [How to Set Up Staging Environments →](link)\n- [How to Roll Back a Deployment →](link)\n```\n\n## Writing Style\n\n### Focus on Action\n\nUse active voice and imperative mood.\n\n**Good:** \"Configure the database connection\"\n**Bad:** \"The database connection should be configured\"\n\n### Be Concise\n\nRespect the user's time. Get to the point.\n\n**Good:**\n```markdown\nInstall the package:\n```bash\nnpm install express\n```\n```\n\n**Bad:**\n```markdown\nThe next thing we need to do is install Express. Express is\na popular web framework for Node.js. You can install it using\nnpm, which is the package manager for Node.js. To do this,\nrun the following command...\n```\n\n### Use Numbered Steps for Sequential Actions\n\nMakes the flow clear and easy to follow.\n\n**Good:**\n```markdown\n1. Create the config file\n2. Add your credentials\n3. Restart the service\n```\n\n**Bad:**\n```markdown\nYou'll need to create a config file, and then add your credentials,\nand then restart the service.\n```\n\n### Provide Exact Commands\n\nDon't make users guess.\n\n**Good:** `sudo systemctl restart nginx`\n**Bad:** \"restart the web server\"\n\n### Be Specific About File Paths\n\nTell users exactly where things go.\n\n**Good:** \"Edit `/etc/postgresql/12/main/pg_hba.conf`\"\n**Bad:** \"Edit the PostgreSQL config file\"\n\n## Best Practices\n\n### ✓ DO\n\n- **Start with the goal**: Make it clear what this achieves\n- **Assume basic knowledge**: Don't explain fundamentals\n- **Provide complete examples**: Working code, not fragments\n- **Use realistic scenarios**: Real-world problems, not toy examples\n- **Test your instructions**: Verify every step works\n- **Address common issues**: Include troubleshooting\n- **Be prescriptive**: Recommend a specific approach\n- **Link to references**: For detailed options/parameters\n- **Show alternative approaches**: When significantly different\n- **Consider user constraints**: Time, resources, expertise\n\n### ✗ DON'T\n\n- **Don't teach basics**: Link to tutorials instead\n- **Don't explain concepts**: Link to explanations instead\n- **Don't cover everything**: Focus on the specific goal\n- **Don't be vague**: Provide exact commands and paths\n- **Don't assume environment**: Specify prerequisites clearly\n- **Don't ignore edge cases**: Address common variations\n- **Don't leave users hanging**: Provide verification steps\n- **Don't duplicate reference docs**: Link to API docs instead\n- **Don't wander off topic**: Stay focused on the goal\n\n## Common Patterns\n\n### Pattern 1: Installation and Configuration\n```markdown\n# How to Set Up X\n\n1. Install X\n2. Create configuration file\n3. Configure for your environment\n4. Start the service\n5. Verify it's working\n```\n\n### Pattern 2: Migration or Upgrade\n```markdown\n# How to Migrate from X to Y\n\n1. Backup your current data\n2. Install Y alongside X\n3. Run migration script\n4. Verify data integrity\n5. Switch to Y\n6. Clean up old X installation\n```\n\n### Pattern 3: Problem-Solving\n```markdown\n# How to Fix [Specific Problem]\n\n1. Identify the cause\n2. Apply the fix\n3. Verify the problem is resolved\n4. Prevent future occurrences\n```\n\n### Pattern 4: Integration\n```markdown\n# How to Integrate X with Y\n\n1. Install required packages\n2. Configure X to connect to Y\n3. Set up authentication\n4. Test the integration\n```\n\n### Pattern 5: Optimization\n```markdown\n# How to Improve [Performance Metric]\n\n1. Identify the bottleneck\n2. Apply optimization technique\n3. Measure the improvement\n4. Further optimizations (optional)\n```\n\n## Example: Good How-to Guide\n\n```markdown\n# How to Add Rate Limiting to Your API\n\nProtect your API from abuse by limiting request rates per user.\n\n**Prerequisites**: Express.js application, Redis server\n\n## Install Dependencies\n\n```bash\nnpm install express-rate-limit redis\n```\n\n## Configure Redis Connection\n\nCreate `config/redis.js`:\n```javascript\nconst redis = require('redis');\nconst client = redis.createClient({\n  host: process.env.REDIS_HOST || 'localhost',\n  port: process.env.REDIS_PORT || 6379\n});\n\nmodule.exports = client;\n```\n\n## Add Rate Limiting Middleware\n\nCreate `middleware/rateLimiter.js`:\n```javascript\nconst rateLimit = require('express-rate-limit');\nconst RedisStore = require('rate-limit-redis');\nconst redis = require('../config/redis');\n\nconst limiter = rateLimit({\n  store: new RedisStore({ client: redis }),\n  windowMs: 15 * 60 * 1000, // 15 minutes\n  max: 100 // limit each IP to 100 requests per windowMs\n});\n\nmodule.exports = limiter;\n```\n\n## Apply to Your Routes\n\nIn `app.js`:\n```javascript\nconst rateLimiter = require('./middleware/rateLimiter');\n\n// Apply to all routes\napp.use(rateLimiter);\n\n// Or apply to specific routes only\napp.use('/api/', rateLimiter);\n```\n\n## Test the Rate Limit\n\nUse curl to test:\n```bash\n# Make 101 requests rapidly\nfor i in {1..101}; do curl http://localhost:3000/api/test; done\n```\n\nAfter 100 requests, you should see:\n```json\n{\"error\": \"Too many requests, please try again later.\"}\n```\n\n## Customize for Different Endpoints\n\nApply stricter limits to sensitive endpoints:\n```javascript\nconst strictLimiter = rateLimit({\n  store: new RedisStore({ client: redis }),\n  windowMs: 15 * 60 * 1000,\n  max: 5 // only 5 requests per 15 minutes\n});\n\napp.use('/api/admin', strictLimiter);\n```\n\n## Troubleshooting\n\n**Problem**: Rate limiting not working\n**Solution**: Ensure Redis is running: `redis-cli ping` (should return \"PONG\")\n\n**Problem**: Different users sharing rate limits\n**Solution**: Check that your load balancer is forwarding the correct IP address\n\n## Related Guides\n- [How to Set Up Redis Cluster →](link)\n- [How to Monitor API Usage →](link)\n```\n\n## Checklist for How-to Guide Quality\n\nBefore publishing, verify:\n\n- [ ] Title clearly states the goal\n- [ ] Introduction identifies what problem this solves\n- [ ] Prerequisites are explicitly stated\n- [ ] Assumes appropriate level of user knowledge\n- [ ] Steps are concrete and actionable\n- [ ] All commands/code are complete and correct\n- [ ] File paths and locations are specific\n- [ ] Verification steps are provided\n- [ ] Common issues are addressed\n- [ ] Stays focused on the specific goal\n- [ ] Links to reference docs instead of duplicating them\n- [ ] Links to explanations instead of explaining concepts\n- [ ] Tested on a clean environment\n\n## Common Mistakes\n\n### Mistake: Teaching Instead of Guiding\n**Bad:** \"Before we begin, let's understand what rate limiting is...\"\n**Good:** \"Protect your API from abuse by limiting request rates.\"\n\n### Mistake: Being Too General\n**Bad:** \"Configure your settings appropriately\"\n**Good:** \"Set `max: 100` in the rate limiter config\"\n\n### Mistake: Explaining the Obvious\n**Bad:** \"Save the file. Saving the file writes it to disk so you can...\"\n**Good:** \"Save the file.\"\n\n### Mistake: Duplicating Reference Docs\n**Bad:** \"The rate limiter has these options: windowMs (number), max (number), message (string), statusCode (number)...\"\n**Good:** \"Set `windowMs: 900000` (15 minutes). [See all options →](link)\"\n\n### Mistake: Ignoring Context\n**Bad:** \"Just use this configuration\" (works locally but not in production)\n**Good:** \"For production, set these environment variables:\"\n\n### Mistake: No Verification\n**Bad:** \"Run the script. Done!\"\n**Good:** \"Run the script. You should see: `Migration completed: 1000 records processed`\"\n\n---\n\n**Remember**: A how-to guide helps someone accomplish a goal. Be practical, be specific, be direct. The user knows what they want to do—just show them how to do it efficiently.\n",
        "plugins/abatilo-core/skills/diataxis-documentation/references/reference.md": "# Writing Reference Documentation\n\n## What is Reference Documentation?\n\nReference documentation is **information-oriented** documentation that provides accurate, complete, and reliable technical descriptions of the machinery.\n\n**Key characteristics:**\n- Information-oriented\n- Comprehensive and accurate\n- Structured like the product\n- Neutral and objective\n- Factual descriptions\n\n**User context:**\n- Has working knowledge\n- Working mode (at work, not learning)\n- Needs to look up specific information\n- Needs facts quickly\n\n**User question:** \"What exactly is...?\" or \"What are the parameters for...?\"\n\n## Purpose and Goals\n\n### Primary Purpose\nProvide accurate, complete technical information that users can quickly look up while working.\n\n### Success Criteria\n- User finds needed information quickly\n- Information is accurate and complete\n- User can trust the documentation\n- Structure matches user's mental model\n- Information is easy to scan and search\n\n### What Reference Documentation Is NOT\n- Not tutorials (those teach through doing)\n- Not how-to guides (those solve specific problems)\n- Not explanatory (those provide understanding)\n- Not opinionated (reference is neutral)\n- Not selective (reference is comprehensive)\n\n## Core Principles\n\n### 1. Describe, Don't Instruct\n\nReference describes what something is or does, not how to use it.\n\n**Good:**\n```markdown\n## authenticate(credentials)\n\nValidates user credentials and returns an authentication token.\n\n**Parameters:**\n- `credentials` (Object): User login credentials\n  - `username` (string): User's username\n  - `password` (string): User's password\n\n**Returns:** (string) Authentication token\n\n**Throws:** `AuthenticationError` if credentials are invalid\n```\n\n**Bad:**\n```markdown\n## authenticate()\n\nTo authenticate a user, call this function with their username\nand password. This is useful when you need to verify who the\nuser is before giving them access to protected resources...\n```\n\n### 2. Be Comprehensive\n\nDocument everything, even if it seems obvious.\n\n**Good:**\n```markdown\n## Configuration Options\n\n- `port` (number): Server port. Default: 3000\n- `host` (string): Server hostname. Default: 'localhost'\n- `timeout` (number): Request timeout in ms. Default: 30000\n- `debug` (boolean): Enable debug mode. Default: false\n```\n\n**Bad:**\n```markdown\n## Configuration Options\n\n- `port`: The port number\n- Other options are available\n```\n\n### 3. Structure According to the Product\n\nOrganize reference material to match the product's architecture.\n\n**Good (API Reference):**\n```markdown\n# API Reference\n\n## Authentication\n- POST /auth/login\n- POST /auth/logout\n- POST /auth/refresh\n\n## Users\n- GET /users\n- GET /users/:id\n- POST /users\n- PUT /users/:id\n- DELETE /users/:id\n\n## Posts\n- GET /posts\n- GET /posts/:id\n- POST /posts\n```\n\n**Bad:**\n```markdown\n# API Reference\n\nEndpoints in alphabetical order:\n- DELETE /users/:id\n- GET /posts\n- GET /posts/:id\n- GET /users\n- POST /auth/login\n```\n\n### 4. Maintain Neutrality\n\nAvoid opinions, recommendations, or guidance. Just state facts.\n\n**Good:**\n```markdown\n## cache.invalidate(key)\n\nRemoves the entry with the specified key from the cache.\n\n**Parameters:**\n- `key` (string): Cache key to invalidate\n\n**Returns:** (boolean) `true` if entry was found and removed, `false` otherwise\n```\n\n**Bad:**\n```markdown\n## cache.invalidate(key)\n\nYou should use this function when you want to remove stale data\nfrom the cache. It's particularly useful in scenarios where...\n```\n\n### 5. Be Accurate and Precise\n\nEvery detail matters. Be exact.\n\n**Good:**\n```markdown\n**Returns:** (number | null) User ID if found, null if not found\n\n**Throws:**\n- `ValidationError` if input is invalid\n- `DatabaseError` if database connection fails\n```\n\n**Bad:**\n```markdown\n**Returns:** The user ID or nothing if not found\n\n**Throws:** Various errors depending on what goes wrong\n```\n\n### 6. Use Consistent Patterns\n\nApply the same structure to all similar items.\n\n**Good:**\n```markdown\n## add(a, b)\nReturns the sum of two numbers.\n\n## subtract(a, b)\nReturns the difference of two numbers.\n\n## multiply(a, b)\nReturns the product of two numbers.\n```\n\n**Bad:**\n```markdown\n## add(a, b)\nReturns the sum of two numbers.\n\nParameters: a and b are numbers\n\n## subtract\nSubtracts one number from another\n\n## multiply(a, b)\na - first number\nb - second number\nReturns: a * b\n```\n\n## Structure of Reference Documentation\n\n### 1. Overview (Brief)\n\nState what is being documented.\n\n**Example:**\n```markdown\n# Logger API Reference\n\nThe Logger module provides methods for structured application logging.\n```\n\n### 2. Organization\n\nGroup related items logically, following the product's structure.\n\n**For APIs:**\n- Group by resource or module\n- List methods/endpoints under each\n\n**For Configuration:**\n- Group by section or category\n- List all options systematically\n\n**For CLI:**\n- Group by command category\n- List all commands and flags\n\n### 3. Each Item (Consistent Structure)\n\nFor each documented item, provide:\n\n**Functions/Methods:**\n```markdown\n## functionName(params)\n\nBrief description of what it does.\n\n**Parameters:**\n- `param1` (type): Description\n- `param2` (type, optional): Description. Default: value\n\n**Returns:** (type) Description\n\n**Throws:**\n- `ErrorType1`: When condition\n- `ErrorType2`: When condition\n\n**Example:**\n```javascript\nconst result = functionName(value1, value2);\n```\n```\n\n**API Endpoints:**\n```markdown\n## POST /api/resource\n\nBrief description of what this endpoint does.\n\n**Headers:**\n- `Authorization`: Bearer token (required)\n- `Content-Type`: application/json\n\n**Request Body:**\n```json\n{\n  \"field1\": \"string\",\n  \"field2\": \"number\"\n}\n```\n\n**Response:** 200 OK\n```json\n{\n  \"id\": \"string\",\n  \"created\": \"timestamp\"\n}\n```\n\n**Errors:**\n- `400 Bad Request`: Invalid input\n- `401 Unauthorized`: Missing or invalid token\n- `409 Conflict`: Resource already exists\n```\n\n**Configuration Options:**\n```markdown\n## option_name\n\n**Type:** string | number | boolean\n**Default:** default_value\n**Required:** yes/no\n\nDescription of what this option controls and its effect.\n\n**Example:**\n```yaml\noption_name: example_value\n```\n```\n\n**CLI Commands:**\n```markdown\n## command [options] [arguments]\n\nBrief description of what the command does.\n\n**Arguments:**\n- `arg1`: Description\n\n**Options:**\n- `-f, --flag`: Description\n- `-o, --option <value>`: Description\n\n**Examples:**\n```bash\ncommand --flag arg1\ncommand --option value arg1\n```\n```\n\n## Writing Style\n\n### Use Technical Language\n\nBe precise and use correct terminology.\n\n**Good:** \"Returns a Promise that resolves to an Array of Objects\"\n**Bad:** \"Gives you a list of things\"\n\n### Be Concise But Complete\n\nDon't add fluff, but include all necessary information.\n\n**Good:**\n```markdown\n**timeout** (number): Maximum time in milliseconds to wait\nfor response. Default: 5000\n```\n\n**Bad:**\n```markdown\n**timeout**: This is a really important setting that controls\nhow long the system will wait before giving up. You might want\nto adjust this based on your network conditions...\n```\n\n### Use Present Tense\n\nDescribe what something does, not what it did or will do.\n\n**Good:** \"Returns the user object\"\n**Bad:** \"Will return the user object\"\n\n### Be Literal\n\nState exactly what happens.\n\n**Good:** \"Throws `ValidationError` if email format is invalid\"\n**Bad:** \"Throws an error if something's wrong with the email\"\n\n### Show Types Clearly\n\nMake data types explicit.\n\n**Good:**\n```markdown\n**Parameters:**\n- `id` (number | string): User identifier\n- `options` (Object, optional): Configuration options\n  - `includeDeleted` (boolean): Include deleted users. Default: false\n```\n\n**Bad:**\n```markdown\n**Parameters:**\n- `id`: The user ID\n- `options`: Some optional settings\n```\n\n## Best Practices\n\n### ✓ DO\n\n- **Document everything**: All functions, all parameters, all options\n- **Be consistent**: Use same format for all similar items\n- **Provide examples**: Show actual usage, but don't explain\n- **Include edge cases**: Document behavior for unusual inputs\n- **Specify defaults**: State default values clearly\n- **List all errors**: Document all possible exceptions/errors\n- **Use tables**: Great for parameter lists and option comparisons\n- **Show type information**: Be explicit about data types\n- **Update with code**: Keep reference in sync with implementation\n- **Make it searchable**: Use clear, predictable naming\n\n### ✗ DON'T\n\n- **Don't explain concepts**: Link to explanations instead\n- **Don't provide tutorials**: Link to tutorials instead\n- **Don't give advice**: Stay neutral and objective\n- **Don't be selective**: Document all features equally\n- **Don't add opinions**: No \"best practices\" or recommendations\n- **Don't skip \"obvious\" things**: Document comprehensively\n- **Don't use marketing language**: Technical description only\n- **Don't mix with how-to**: Keep pure reference separate\n\n## Common Patterns\n\n### Pattern 1: API Reference\n```markdown\n# API Reference\n\n## Resource Name\n\nBrief description of the resource.\n\n### GET /api/resource\n[detailed documentation]\n\n### POST /api/resource\n[detailed documentation]\n\n### GET /api/resource/:id\n[detailed documentation]\n```\n\n### Pattern 2: Function/Method Reference\n```markdown\n# Module Name\n\nBrief description of the module.\n\n## Methods\n\n### method1(params)\n[detailed documentation]\n\n### method2(params)\n[detailed documentation]\n```\n\n### Pattern 3: Configuration Reference\n```markdown\n# Configuration Reference\n\n## Section Name\n\n### option1\n[detailed documentation]\n\n### option2\n[detailed documentation]\n```\n\n### Pattern 4: CLI Reference\n```markdown\n# Command Line Reference\n\n## Commands\n\n### command1 [options]\n[detailed documentation]\n\n### command2 [options]\n[detailed documentation]\n```\n\n## Example: Good Reference Documentation\n\n```markdown\n# Cache API Reference\n\nThe Cache API provides methods for storing and retrieving data in memory.\n\n## Methods\n\n### set(key, value, options)\n\nStores a value in the cache with the specified key.\n\n**Parameters:**\n- `key` (string): Cache key. Must be non-empty.\n- `value` (any): Value to store. Must be serializable to JSON.\n- `options` (Object, optional): Storage options\n  - `ttl` (number, optional): Time-to-live in seconds. Default: 3600\n  - `tags` (Array<string>, optional): Tags for cache invalidation. Default: []\n\n**Returns:** (boolean) `true` if stored successfully, `false` if key already exists\n\n**Throws:**\n- `InvalidKeyError`: If key is empty or not a string\n- `SerializationError`: If value cannot be serialized to JSON\n\n**Example:**\n```javascript\ncache.set('user:123', { name: 'John' }, { ttl: 7200 });\n// Returns: true\n```\n\n---\n\n### get(key)\n\nRetrieves a value from the cache.\n\n**Parameters:**\n- `key` (string): Cache key\n\n**Returns:** (any | null) Cached value if found and not expired, `null` otherwise\n\n**Example:**\n```javascript\nconst user = cache.get('user:123');\n// Returns: { name: 'John' } or null\n```\n\n---\n\n### delete(key)\n\nRemoves an entry from the cache.\n\n**Parameters:**\n- `key` (string): Cache key\n\n**Returns:** (boolean) `true` if entry existed and was deleted, `false` otherwise\n\n**Example:**\n```javascript\ncache.delete('user:123');\n// Returns: true\n```\n\n---\n\n### clear(tags)\n\nRemoves all entries from the cache, or entries with specified tags.\n\n**Parameters:**\n- `tags` (Array<string>, optional): Only clear entries with these tags. If omitted, clears all entries.\n\n**Returns:** (number) Number of entries removed\n\n**Example:**\n```javascript\ncache.clear(['users']);\n// Returns: 42\n```\n\n---\n\n### has(key)\n\nChecks if a key exists in the cache and has not expired.\n\n**Parameters:**\n- `key` (string): Cache key\n\n**Returns:** (boolean) `true` if key exists and is not expired, `false` otherwise\n\n**Example:**\n```javascript\nif (cache.has('user:123')) {\n  // Use cached value\n}\n```\n\n---\n\n## Configuration\n\n### maxSize\n\n**Type:** number\n**Default:** 1000\n**Required:** no\n\nMaximum number of entries the cache can hold. When exceeded, oldest entries are evicted.\n\n**Example:**\n```javascript\nconst cache = new Cache({ maxSize: 5000 });\n```\n\n---\n\n### defaultTTL\n\n**Type:** number\n**Default:** 3600\n**Required:** no\n\nDefault time-to-live in seconds for cache entries when not specified in `set()`.\n\n**Example:**\n```javascript\nconst cache = new Cache({ defaultTTL: 7200 });\n```\n\n---\n\n### onEvict\n\n**Type:** function\n**Default:** undefined\n**Required:** no\n\nCallback function invoked when an entry is evicted.\n\n**Signature:** `(key: string, value: any) => void`\n\n**Example:**\n```javascript\nconst cache = new Cache({\n  onEvict: (key, value) => {\n    console.log(`Evicted ${key}`);\n  }\n});\n```\n```\n\n## Checklist for Reference Documentation Quality\n\nBefore publishing, verify:\n\n- [ ] Every public function/method/endpoint is documented\n- [ ] All parameters are listed with types\n- [ ] Return types are specified\n- [ ] All possible errors/exceptions are documented\n- [ ] Default values are stated\n- [ ] Optional vs. required is clear\n- [ ] Structure mirrors the product's architecture\n- [ ] Consistent format used throughout\n- [ ] Examples are provided (but not explained)\n- [ ] No opinions or recommendations (pure facts)\n- [ ] No instructional content (no \"how to\")\n- [ ] No explanatory content (no \"why\")\n- [ ] Terminology is accurate and precise\n- [ ] Content is comprehensive (nothing missing)\n- [ ] Easy to scan and search\n\n## Common Mistakes\n\n### Mistake: Mixing in Instructions\n**Bad:** \"To authenticate, call `auth()` with your credentials\"\n**Good:** \"`auth(credentials)` validates credentials and returns a token\"\n\n### Mistake: Adding Opinions\n**Bad:** \"The recommended timeout is 30 seconds\"\n**Good:** \"`timeout` (number): Request timeout in seconds. Default: 30\"\n\n### Mistake: Being Incomplete\n**Bad:**\n```markdown\n## process(data)\nProcesses the data\n```\n**Good:**\n```markdown\n## process(data)\nValidates and transforms input data according to configured rules.\n\n**Parameters:**\n- `data` (Object): Input data to process\n\n**Returns:** (Object) Transformed data\n\n**Throws:** `ValidationError` if data is invalid\n```\n\n### Mistake: Inconsistent Structure\n**Bad:** Different functions documented with different formats\n**Good:** Every function follows the exact same structure\n\n### Mistake: Explaining Instead of Describing\n**Bad:** \"This function is useful when you need to...\"\n**Good:** \"Returns the sum of two numbers\"\n\n### Mistake: Hiding Information in Prose\n**Bad:** \"The function takes a user ID (number) and returns their profile\"\n**Good:** Use proper parameter and return type documentation structure\n\n---\n\n**Remember**: Reference documentation is a technical description of the machinery. Be accurate, be complete, be neutral, be consistent. Your users need facts they can trust and find quickly.\n",
        "plugins/abatilo-core/skills/diataxis-documentation/references/tutorials.md": "# Writing Tutorials\n\n## What is a Tutorial?\n\nA tutorial is **learning-oriented** documentation that guides a beginner through a complete, practical activity to acquire basic skills and confidence.\n\n**Key characteristics:**\n- Learning by doing\n- Provides a guided lesson\n- Takes the user by the hand\n- Focuses on skill acquisition\n- Guarantees success\n\n**User context:**\n- New to the tool/technology\n- Learning mode (study, not work)\n- Needs to build confidence\n- Wants to see what's possible\n\n**User question:** \"Can you teach me to...?\"\n\n## Purpose and Goals\n\n### Primary Purpose\nEnable a beginner to acquire basic skills and confidence through a successful, hands-on experience.\n\n### Success Criteria\n- User completes the tutorial successfully\n- User gains confidence in using the tool\n- User understands what's possible\n- User is motivated to continue learning\n- User has working knowledge to build on\n\n### What Tutorials Are NOT\n- Not reference material (that's Reference documentation)\n- Not problem-solving guides (that's How-to Guides)\n- Not comprehensive teaching (focus on basics)\n- Not explanatory (that's Explanation documentation)\n- Not for experienced users (they need How-to Guides)\n\n## Core Principles\n\n### 1. Learning by Doing\n\nTutorials focus on **concrete actions** that produce **visible results**.\n\n**Good:**\n```markdown\nCreate a new file called `hello.py`:\n```python\nprint(\"Hello, world!\")\n```\n\nRun the file:\n```bash\npython hello.py\n```\n\nYou should see: `Hello, world!`\n```\n\n**Bad:**\n```markdown\nPython is a high-level programming language with dynamic typing.\nThe print function outputs text to stdout. Let's explore different\nways you might want to use print...\n```\n\n### 2. Provide Immediate Success\n\nStart with the simplest possible successful outcome, as quickly as possible.\n\n**Good:** \"In 5 minutes, you'll have a working web server\"\n**Bad:** \"First, let's understand HTTP protocols and server architecture...\"\n\n### 3. Ensure Reliability\n\nEvery step must work exactly as described. No surprises, no failures.\n\n**Requirements:**\n- Test the tutorial thoroughly\n- Specify exact versions if needed\n- Provide troubleshooting for common issues\n- Ensure prerequisites are clear\n- Make no assumptions about user knowledge\n\n### 4. Guide, Don't Explore\n\nMake all decisions for the learner. No options, no alternatives, no \"you could also...\"\n\n**Good:**\n```markdown\nSet the timeout to 30 seconds:\n```python\ntimeout = 30\n```\n```\n\n**Bad:**\n```markdown\nSet the timeout to whatever value works for your use case.\nCommon values are 30, 60, or 300 seconds depending on\nwhether you're dealing with fast local operations or\nslow external APIs...\n```\n\n### 5. Minimize Explanation\n\nFocus on **what** to do, not **why** it works. Link to explanations instead.\n\n**Good:**\n```markdown\nAdd this middleware to enable authentication:\n```python\napp.use(authenticate)\n```\n\n[Learn more about authentication →](link-to-explanation)\n```\n\n**Bad:**\n```markdown\nAdd this middleware to enable authentication. Middleware\nfunctions are executed sequentially in the order they're\nregistered. The authenticate middleware checks the session\ncookie, validates it against the database, and attaches\nthe user object to the request...\n```\n\n### 6. Repeat and Reinforce\n\nLet learners practice the same skills in slightly different contexts.\n\n**Example:**\n```markdown\n1. Create a user: `python manage.py createuser`\n2. Create a group: `python manage.py creategroup`\n3. Create a project: `python manage.py createproject`\n```\n\n(All three commands follow the same pattern)\n\n## Structure of a Tutorial\n\n### 1. Introduction\n\n**What to include:**\n- What the user will learn\n- What the user will build/achieve\n- How long it will take\n- Prerequisites (keep minimal)\n\n**Example:**\n```markdown\n# Your First Web API\n\nIn this tutorial, you'll build a simple REST API that manages\na todo list. You'll learn to:\n- Set up a new project\n- Create API endpoints\n- Handle data with a database\n- Test your API\n\n**Time**: 30 minutes\n**Prerequisites**: Python 3.8+ installed\n```\n\n### 2. Setup\n\n**What to include:**\n- Installation instructions\n- Initial project setup\n- Verification that setup worked\n\n**Example:**\n```markdown\n## Setup\n\nInstall the framework:\n```bash\npip install webframework\n```\n\nCreate a new project:\n```bash\nwebframework new myproject\ncd myproject\n```\n\nVerify it works:\n```bash\nwebframework run\n```\n\nYou should see: `Server running on http://localhost:8000`\n```\n\n### 3. Main Content (Step-by-Step)\n\n**Structure each step as:**\n1. Clear instruction\n2. Exact code or command\n3. Expected result\n4. Brief confirmation\n\n**Example:**\n```markdown\n## Step 1: Create Your First Endpoint\n\nOpen `app.py` and add this code:\n```python\n@app.route('/hello')\ndef hello():\n    return {'message': 'Hello, World!'}\n```\n\nStart the server:\n```bash\nwebframework run\n```\n\nVisit http://localhost:8000/hello in your browser.\nYou should see: `{\"message\": \"Hello, World!\"}`\n\n✓ You've created your first API endpoint!\n```\n\n### 4. Conclusion\n\n**What to include:**\n- Recap what was learned\n- What the user has achieved\n- What they can do next\n- Links to related how-to guides or explanations\n\n**Example:**\n```markdown\n## What You've Learned\n\nCongratulations! You've built a working REST API. You now know how to:\n- ✓ Set up a new project\n- ✓ Create API endpoints\n- ✓ Store data in a database\n- ✓ Test your API\n\n## Next Steps\n\nNow that you have the basics, you can:\n- [Add authentication to your API →](link-to-how-to)\n- [Deploy your API to production →](link-to-how-to)\n- [Understand how routing works →](link-to-explanation)\n```\n\n## Writing Style\n\n### Use Imperative Mood\nTell the user what to do directly.\n\n**Good:** \"Create a file,\" \"Run the command,\" \"Add this code\"\n**Bad:** \"You should create,\" \"We can run,\" \"Let's add\"\n\n### Be Concrete and Specific\nProvide exact commands, exact file names, exact content.\n\n**Good:** \"Create `config.yaml` with these exact contents:\"\n**Bad:** \"Create a configuration file\"\n\n### Use Short Sentences\nKeep instructions clear and scannable.\n\n**Good:** \"Save the file. Run the server. Open your browser.\"\n**Bad:** \"After saving the file, you'll want to run the server, then navigate to your browser.\"\n\n### Provide Feedback\nTell users what they should see after each step.\n\n**Good:**\n```markdown\nRun `npm start`\nYou should see: `Compiled successfully!`\n```\n\n**Bad:**\n```markdown\nRun `npm start`\n```\n\n### Use Encouraging Language\nBuild confidence without being condescending.\n\n**Good:** \"Great! Your server is running.\"\n**Bad:** \"Wow! You're amazing! You did it!\"\n\n## Best Practices\n\n### ✓ DO\n\n- **Focus on one clear goal**: \"Build a todo list app\"\n- **Start simple**: Most basic successful outcome first\n- **Build progressively**: Each step adds one new concept\n- **Show, don't tell**: Code examples, not prose\n- **Verify frequently**: User confirms success after each step\n- **Handle errors**: Provide troubleshooting for common issues\n- **Test thoroughly**: Every single step, multiple times\n- **Use realistic examples**: Meaningful, not abstract\n- **Provide working code**: No \"...\", no placeholders\n- **Make it meaningful**: Build something useful\n\n### ✗ DON'T\n\n- **Don't explain everything**: Link to explanations instead\n- **Don't offer choices**: Make decisions for the learner\n- **Don't assume knowledge**: Specify all prerequisites\n- **Don't skip steps**: Every action must be explicit\n- **Don't leave gaps**: No \"now configure the settings...\"\n- **Don't use placeholders**: No \"YOUR_API_KEY_HERE\"\n- **Don't be abstract**: Use real, concrete examples\n- **Don't optimize early**: Simple working code first\n- **Don't distract**: Stay focused on the learning path\n- **Don't rush**: Take time to build confidence\n\n## Common Patterns\n\n### Pattern 1: Installation Tutorial\n```markdown\n# Getting Started with X\n\nInstall X, create your first project, verify it works.\n\n1. Install\n2. Create new project\n3. Run \"hello world\"\n4. Verify output\n```\n\n### Pattern 2: Build a Simple Project\n```markdown\n# Build Your First Y\n\nCreate a complete, minimal working Y application.\n\n1. Set up project\n2. Add core functionality\n3. Add one feature at a time\n4. Test the complete application\n```\n\n### Pattern 3: Hands-On Introduction\n```markdown\n# Introduction to Z\n\nLearn Z concepts through practical exercises.\n\n1. Exercise 1: Basic concept\n2. Exercise 2: Build on concept\n3. Exercise 3: Combine concepts\n4. Review what you've learned\n```\n\n## Example: Good Tutorial\n\n```markdown\n# Build Your First Blog\n\nCreate a simple blog with posts and comments in 20 minutes.\n\n## Prerequisites\n- Python 3.8+\n- Basic command line knowledge\n\n## Setup\n\nInstall BlogFramework:\n```bash\npip install blogframework\n```\n\nCreate a new blog:\n```bash\nblog new myblog\ncd myblog\n```\n\nStart the development server:\n```bash\nblog serve\n```\n\nVisit http://localhost:8000. You should see the default homepage.\n\n## Create Your First Post\n\nCreate a new post:\n```bash\nblog post create\n```\n\nWhen prompted:\n- Title: `My First Post`\n- Author: `Your Name`\n\nEdit `posts/my-first-post.md` and add:\n```markdown\nThis is my first blog post!\n```\n\nRefresh http://localhost:8000. You should see your post on the homepage.\n\nClick the post title to see the full post.\n\n## Add a Comment\n\nOpen http://localhost:8000/posts/my-first-post\n\nScroll to the comments section and add:\n- Name: `Test User`\n- Comment: `Great post!`\n\nClick \"Submit\". Your comment should appear below the post.\n\n## Customize the Theme\n\nEdit `config.yaml`:\n```yaml\ntheme:\n  color: blue\n  title: My Awesome Blog\n```\n\nRefresh the page. The site should now have a blue theme with your custom title.\n\n## What You've Learned\n\nYou've built a working blog! You can now:\n- ✓ Create and publish posts\n- ✓ Allow comments\n- ✓ Customize the theme\n\n## Next Steps\n- [Add authentication →](link)\n- [Deploy your blog →](link)\n- [Understand the architecture →](link)\n```\n\n## Checklist for Tutorial Quality\n\nBefore publishing, verify:\n\n- [ ] Prerequisites are clearly stated and minimal\n- [ ] Every step works exactly as described\n- [ ] User gets successful result early (within 5 minutes)\n- [ ] Each step has expected output specified\n- [ ] No unexplained jargon or terms\n- [ ] No choices or alternatives presented\n- [ ] Explanations are minimal and link to separate docs\n- [ ] Progression is logical and builds skills gradually\n- [ ] The completed result is useful and meaningful\n- [ ] Next steps are provided at the end\n- [ ] Tested on a clean environment multiple times\n\n## Common Mistakes\n\n### Mistake: Over-Explaining\n**Bad:** \"We use JSON because it's a lightweight data format that...\"\n**Good:** \"Return the data as JSON:\" (link to explanation)\n\n### Mistake: Offering Options\n**Bad:** \"You can use SQLite, PostgreSQL, or MySQL depending on...\"\n**Good:** \"Use SQLite for this tutorial:\"\n\n### Mistake: Assuming Knowledge\n**Bad:** \"Configure your environment variables\"\n**Good:** \"Create a `.env` file with these contents:\"\n\n### Mistake: Skipping Verification\n**Bad:** \"Run the server.\"\n**Good:** \"Run the server. You should see `Server started on port 8000`\"\n\n### Mistake: Being Too Abstract\n**Bad:** \"Create a model for your domain objects\"\n**Good:** \"Create a Post model with title and content fields\"\n\n---\n\n**Remember**: A tutorial's job is to give someone their first successful experience with your tool. Everything else is secondary. Keep it simple, keep it reliable, and keep them succeeding.\n",
        "plugins/abatilo-core/skills/git-commit/SKILL.md": "---\nname: git-commit\ndescription: Create logically grouped, atomic git commits with well-formatted commit messages following best practices. Use when user says \"/commit\", \"commit changes\", \"create commits\", asks about conventional commits format, needs to split changes into multiple commits, or wants help with git add -p partial staging.\nallowed-tools:\n  - Bash(git:*)\n  - Read\n  - Edit\n---\n\n# Git Commit Skill\n\nThis skill helps you create well-structured, atomic git commits with properly formatted commit messages.\n\n## When to Use This Skill\n\nUse this skill when:\n- You need to commit changes to a git repository\n- You want to create atomic, logically grouped commits\n- You need to follow commit message best practices\n- You have multiple changes that should be split into separate commits\n- You need to use git partial adds (git add -p) for fine-grained control\n\n## Task Overview\n\nBased on the current git status and changes, create a set of logically grouped, atomic commits.\nBe specific with each grouping, and keep scope minimal. Leverage partial adds to\nmake sure that multiple changes within a single file aren't batched into\ncommits with unrelated changes.\n\n## Process\n\n1. **Analyze Current State**\n   - Check git status to see staged and unstaged changes\n   - Review git diff to understand what has changed\n   - Check recent commits (`git log --oneline -20`) to understand:\n     - Whether the project uses conventional commits (e.g., `feat:`, `fix:`, `docs:`)\n     - The project's commit message style and conventions\n     - Typical subject line length and formatting patterns\n\n2. **Group Changes Logically**\n   - Identify related changes that should be committed together\n   - Separate unrelated changes into different commits\n   - Use `git add -p` for partial adds when a file contains multiple logical changes\n\n3. **Create Commits**\n   - Stage the appropriate changes for each commit\n   - Write commit messages following the best practices below\n   - Verify each commit is atomic and complete\n\n## Commit Message Format Detection\n\n**IMPORTANT**: Before writing any commits, analyze the recent git history to determine the project's commit style:\n\n- **Check for Conventional Commits**: Look for patterns like `feat:`, `fix:`, `docs:`, `chore:`, `refactor:`, `test:`, `style:`, `perf:`, `ci:`, `build:`\n- **Match the existing style**: If 80% or more of recent commits follow conventional commits, use that format\n- **Be consistent**: Match the capitalization, punctuation, and structure of existing commits\n\n### Conventional Commits Format\n\nIf the project uses conventional commits, follow this structure:\n\n```\n<type>[(optional scope)]: <description>\n\n[optional body]\n\n[optional footer(s)]\n```\n\n**Common types:**\n- `feat`: A new feature\n- `fix`: A bug fix\n- `docs`: Documentation changes\n- `style`: Code style changes (formatting, missing semicolons, etc.)\n- `refactor`: Code changes that neither fix bugs nor add features\n- `perf`: Performance improvements\n- `test`: Adding or updating tests\n- `build`: Changes to build system or dependencies\n- `ci`: Changes to CI configuration\n- `chore`: Other changes that don't modify src or test files\n\n**Examples:**\n- `feat: add user authentication`\n- `fix: resolve null pointer in login handler`\n- `docs: update API documentation`\n- `refactor(auth): simplify token validation logic`\n\n## Git Commit Message Best Practices\n\nFollow these seven rules for excellent commit messages (adjust for conventional commits if used):\n\n1. **Separate subject from body with a blank line** - Critical for readability\n2. **Limit subject line to 50 characters** - Forces concise summaries\n3. **Capitalize the subject line** - Consistent formatting\n4. **Do not end subject line with a period** - It's a title, not a sentence\n5. **Use imperative mood in subject** - \"Add feature\" not \"Added feature\"\n   - Test: Subject should complete \"If applied, this commit will _____\"\n6. **Wrap body at 72 characters** - Ensures readability in terminals\n7. **Use body to explain what and why vs. how** - Code shows how, commit explains why\n\n### Message Structure\n\n```\n<subject: concise summary, imperative, capitalized, no period>\n\n<body: explain the motivation for the change and contrast with previous behavior>\n\n<footer: references to issues, breaking changes, etc.>\n```\n\n### Key Principles\n\n- **Atomic commits**: Each commit should represent one logical change\n- **Context is king**: Explain WHY the change was made, not just what\n- **Future-proof**: Write for someone (including future you) reading this months later\n- **Consistency**: Maintain uniform style across the project\n\n### Examples\n\n**Good Examples (Traditional Style):**\n- `Refactor subsystem X for readability`\n- `Remove deprecated methods from UserService`\n- `Fix null pointer exception in login handler`\n- `Add user authentication middleware`\n\n**Good Examples (Conventional Commits):**\n- `feat: add user authentication middleware`\n- `fix: resolve null pointer exception in login handler`\n- `refactor: improve subsystem X readability`\n- `chore: remove deprecated methods from UserService`\n\n**Bad Examples:**\n- `fixed stuff`\n- `Changes`\n- `wip`\n- `Update file.js`\n- `feat added new feature` (incorrect format - missing colon)\n\n## Implementation Steps\n\n1. Run `git status` to see current state\n2. Run `git diff HEAD` to see all changes\n3. Run `git log --oneline -20` to analyze recent commit style\n   - **Determine if conventional commits are used** (look for `type:` prefix patterns)\n   - Note the typical capitalization and formatting style\n   - Identify any project-specific conventions\n4. Identify logical groupings of changes\n5. For each logical group:\n   - Stage the relevant changes (use `git add -p` if needed)\n   - Create a commit with a well-formatted message **matching the project's style**\n   - Verify the commit with `git show`\n6. After all commits, run `git status` to verify nothing important was missed\n\n## Reference Documentation\n\nFor detailed information on conventional commits, see:\n- [Conventional Commits Reference](references/conventional-commits.md) - Complete specification and examples\n\n## Notes\n\n- **ALWAYS check recent git history first** to determine if conventional commits are used\n- **Match the project's existing style** - consistency is more important than personal preference\n- DO NOT push to remote unless explicitly asked\n- Always verify authorship and commit details before amending\n- Use `git add -p` for interactive staging when files contain multiple unrelated changes\n- Keep commits focused and atomic - one logical change per commit\n- If in doubt about whether to use conventional commits, look at the last 20-30 commits for patterns\n",
        "plugins/abatilo-core/skills/git-commit/references/conventional-commits.md": "# Conventional Commits Reference\n\nThis reference provides detailed guidance on the Conventional Commits specification.\n\n## Specification Overview\n\nConventional Commits is a specification for adding human and machine readable meaning to commit messages.\n\n### Structure\n\n```\n<type>[optional scope]: <description>\n\n[optional body]\n\n[optional footer(s)]\n```\n\n## Commit Types\n\n### Primary Types\n\n| Type | When to Use | Example |\n|------|-------------|---------|\n| `feat` | A new feature for the user | `feat: add user profile page` |\n| `fix` | A bug fix for the user | `fix: resolve login timeout issue` |\n\n### Secondary Types\n\n| Type | When to Use | Example |\n|------|-------------|---------|\n| `docs` | Documentation only changes | `docs: update API reference` |\n| `style` | Formatting, missing semicolons, etc. (no code change) | `style: fix indentation in utils.ts` |\n| `refactor` | Code change that neither fixes a bug nor adds a feature | `refactor: extract validation logic` |\n| `perf` | Performance improvement | `perf: optimize database queries` |\n| `test` | Adding or updating tests | `test: add unit tests for auth service` |\n| `build` | Changes to build system or dependencies | `build: upgrade webpack to v5` |\n| `ci` | Changes to CI configuration | `ci: add GitHub Actions workflow` |\n| `chore` | Other changes that don't modify src or test files | `chore: update .gitignore` |\n\n## Scopes\n\nScopes provide additional contextual information about what part of the codebase is affected.\n\n### Examples\n\n```\nfeat(auth): add OAuth2 support\nfix(api): handle null response from server\ndocs(readme): add installation instructions\nrefactor(utils): simplify date formatting functions\n```\n\n### Common Scope Patterns\n\n- **By module**: `feat(auth)`, `fix(payments)`, `refactor(users)`\n- **By layer**: `feat(api)`, `fix(ui)`, `refactor(db)`\n- **By file type**: `style(css)`, `test(unit)`, `build(docker)`\n\n## Breaking Changes\n\n### Using BREAKING CHANGE footer\n\n```\nfeat(api): change authentication endpoint\n\nBREAKING CHANGE: The /auth endpoint now requires a JSON body instead of form data.\n```\n\n### Using ! shorthand\n\n```\nfeat(api)!: change authentication endpoint\n\nThe /auth endpoint now requires a JSON body instead of form data.\n```\n\n## Body Guidelines\n\nThe body should:\n- Explain the **motivation** for the change\n- Contrast with **previous behavior**\n- Be wrapped at **72 characters**\n\n### Example\n\n```\nfix(auth): resolve session expiration race condition\n\nPreviously, sessions could expire while a request was in-flight, causing\nintermittent 401 errors. This change adds a 30-second grace period to\nsession validation, preventing premature expiration during active use.\n\nFixes #123\n```\n\n## Footer Conventions\n\n### Issue References\n\n```\nFixes #123\nCloses #456\nRelates to #789\n```\n\n### Co-authors\n\n```\nCo-authored-by: Name <email@example.com>\n```\n\n### Reviewed-by\n\n```\nReviewed-by: Name <email@example.com>\n```\n\n## Detection Heuristics\n\nWhen analyzing a project's git history to detect conventional commits usage:\n\n1. **Check the last 20-30 commits**\n2. **Look for type prefixes**: `feat:`, `fix:`, `docs:`, etc.\n3. **Check consistency**: If 80%+ use the format, follow it\n4. **Note variations**: Some projects use `feat():` with empty scope, others never use scope\n\n### Detection Regex\n\n```regex\n^(feat|fix|docs|style|refactor|perf|test|build|ci|chore)(\\(.+\\))?!?:\\s.+\n```\n\n## Common Mistakes\n\n### Incorrect\n\n```\nfeat added new feature          # Missing colon\nFeat: add new feature          # Type should be lowercase\nfeat: Add new feature.         # Subject shouldn't end with period\nfeat: added new feature        # Should use imperative mood\n```\n\n### Correct\n\n```\nfeat: add new feature\n```\n\n## Tools & Automation\n\nConventional Commits enable:\n\n- **Automatic changelog generation**\n- **Semantic versioning automation**\n- **Filtering commits by type**\n- **Triggering CI/CD pipelines based on commit type**\n\n### Semantic Versioning Mapping\n\n| Commit Type | Version Bump |\n|-------------|--------------|\n| `fix` | PATCH (0.0.X) |\n| `feat` | MINOR (0.X.0) |\n| `BREAKING CHANGE` | MAJOR (X.0.0) |\n| Other types | No version bump |\n",
        "plugins/abatilo-core/skills/git-spice/SKILL.md": "---\nname: git-spice\ndescription: Manage Git branches and pull requests using git-spice (gs). Use when user says \"/gs\", \"create branch\", \"new branch\", \"switch branch\", \"checkout branch\", \"rebase branch\", \"update branch from main\", \"create PR\", \"submit PR\", \"open pull request\", needs to manage multiple related branches, wants stacked PRs or PR chains, or asks about rebasing and branch dependencies. Handles branch creation, navigation, rebasing, and PR submission.\nargument-hint: \"[branch-name or command]\"\ncontext: fork\nallowed-tools:\n  - Bash(gs:*)\n  - Bash(git:*)\n  - Read\n  - Edit\n---\n\n# Git Spice Skill\n\nThis skill helps you manage stacked Git branches using git-spice (`gs`), a CLI tool for creating, navigating, and submitting branch stacks as pull requests.\n\n## When to Use This Skill\n\nUse this skill when the user wants to:\n- Create a new feature branch (\"create a branch\", \"new branch called X\")\n- Switch to another branch (\"switch branch\", \"checkout branch\")\n- Update a branch with latest main (\"rebase my branch\", \"update from main\")\n- Create a pull request (\"create PR\", \"submit PR\", \"open pull request\")\n- Manage multiple related changes (\"I have several related changes\")\n- Work with stacked branches for large features broken into reviewable chunks\n- Navigate up/down through branch stacks\n- Submit multiple related PRs as a stack\n- Manage branch dependencies and PR chains on GitHub/GitLab\n\n## Core Concepts\n\n**Stacked Branches**: A series of branches where each branch is based on the previous one, forming a dependency chain rooted at trunk (main/master).\n\n```\n    ┌── feat3 (#3)    <- top of stack\n  ┌─┴ feat2 (#2)\n┌─┴ feat1 (#1)        <- bottom of stack\nmain                  <- trunk\n```\n\n**Trunk**: The main development branch (main, master, or configured trunk).\n\n**Upstack/Downstack**: Branches above/below the current branch in the stack.\n\n## Quick Start\n\n### 1. Initialize Repository\n\n```bash\ngs repo init\n```\n\nThis sets up git-spice tracking in your repository. You'll be prompted to select the trunk branch and remote.\n\n### 2. Create a Branch Stack\n\n```bash\n# Start from trunk\ngit checkout main\n\n# Create first branch in stack\ngs branch create feat1 -m \"Add user model\"\n\n# Create second branch stacked on feat1\ngs branch create feat2 -m \"Add user API\"\n\n# Create third branch stacked on feat2\ngs branch create feat3 -m \"Add user tests\"\n```\n\n### 3. Navigate the Stack\n\n```bash\ngs up        # Move up one branch (u)\ngs down      # Move down one branch (d)\ngs top       # Jump to top of stack (U)\ngs bottom    # Jump to bottom of stack (D)\ngs trunk     # Return to trunk branch\n```\n\n### 4. View Your Stack\n\n```bash\ngs log short    # List all tracked branches (ls)\ngs log long     # Show branches with commits (ll)\n```\n\n### 5. Submit PRs\n\n```bash\ngs stack submit     # Submit entire stack as PRs (ss)\ngs branch submit    # Submit current branch only (bs)\ngs upstack submit   # Submit current and all above (uss)\ngs downstack submit # Submit current and all below (dss)\n```\n\n### 6. Sync and Restack\n\n```bash\ngs repo sync       # Pull latest, delete merged branches (rs)\ngs stack restack   # Rebase all branches onto latest (sr)\n```\n\n## Command Reference (Shorthands)\n\n| Command | Shorthand | Description |\n|---------|-----------|-------------|\n| `gs branch create` | `gs bc` | Create new branch |\n| `gs branch checkout` | `gs bco` | Switch to branch |\n| `gs branch submit` | `gs bs` | Submit branch as PR |\n| `gs branch restack` | `gs br` | Rebase branch on base |\n| `gs branch delete` | `gs bd` | Delete branch |\n| `gs branch onto` | `gs bon` | Move branch onto another |\n| `gs branch edit` | `gs be` | Interactive rebase |\n| `gs stack submit` | `gs ss` | Submit entire stack |\n| `gs stack restack` | `gs sr` | Restack entire stack |\n| `gs upstack submit` | `gs uss` | Submit upstack |\n| `gs upstack restack` | `gs usr` | Restack upstack |\n| `gs downstack submit` | `gs dss` | Submit downstack |\n| `gs repo sync` | `gs rs` | Sync with remote |\n| `gs repo init` | `gs ri` | Initialize repo |\n| `gs commit create` | `gs cc` | Create commit |\n| `gs commit amend` | `gs ca` | Amend commit |\n| `gs log short` | `gs ls` | List branches |\n| `gs log long` | `gs ll` | List with commits |\n\n## Common Workflows\n\n### Creating a Feature Stack\n\n```bash\n# Start from updated trunk\ngs trunk\ngit pull\n\n# Create logical branches for each reviewable piece\ngs bc api-models -m \"Add data models for new API\"\ngs bc api-handlers -m \"Implement API handlers\"\ngs bc api-tests -m \"Add API integration tests\"\n\n# View your stack\ngs ll\n```\n\n### Updating After Review Feedback\n\n```bash\n# Navigate to branch that needs changes\ngs bco api-handlers\n\n# Make changes, then amend or create new commit\ngs ca  # amend current commit\n# or\ngs cc -m \"Address review feedback\"\n\n# Restack all branches above to incorporate changes\ngs usr  # upstack restack\n```\n\n### Syncing with Upstream Changes\n\n```bash\n# Sync repo - pulls trunk, deletes merged branches\ngs rs\n\n# Restack all tracked branches onto new trunk\ngs repo restack\n# or for just current stack:\ngs sr\n```\n\n### Moving a Branch\n\n```bash\n# Move current branch onto a different base\ngs bon main           # Move onto main directly\ngs bon other-feature  # Move onto another branch\n\n# Insert a new branch in the middle of a stack\ngs bc new-branch --insert  # Restacks upstack onto new branch\n```\n\n### Handling Conflicts\n\nWhen restacking encounters conflicts:\n\n```bash\n# Resolve conflicts in your editor\ngit status  # See conflicted files\n# ... fix conflicts ...\ngit add <resolved-files>\n\n# Continue the restack operation\ngs rebase continue  # (gs rbc)\n\n# Or abort if needed\ngs rebase abort     # (gs rba)\n```\n\n### Submitting PRs\n\n```bash\n# Submit all branches in stack as linked PRs\ngs ss\n\n# Submit with draft PRs\ngs ss --draft\n\n# Submit only current branch\ngs bs\n\n# Update PR after changes\ngs bs  # Re-run submit updates existing PR\n```\n\n## Branch Operations\n\n### Track Existing Branches\n\n```bash\n# Track a single branch\ngs branch track feature-branch --base main\n\n# Track all branches in a downstack\ngs downstack track\n```\n\n### Split and Squash\n\n```bash\n# Split current branch into multiple commits\ngs branch split\n\n# Squash branch into single commit\ngs branch squash\n```\n\n### Delete Branches\n\n```bash\n# Delete a single branch\ngs bd feature-branch\n\n# Delete entire upstack\ngs upstack delete\n\n# Delete entire stack\ngs stack delete\n```\n\n## Authentication\n\n```bash\ngs auth login   # Authenticate with GitHub/GitLab\ngs auth status  # Check current auth status\ngs auth logout  # Clear credentials\n```\n\n## Configuration\n\nGit-spice uses git config for settings:\n\n```bash\n# Set branch name prefix\ngit config spice.branchCreate.prefix \"username/\"\n\n# Configure navigation comment style\ngit config spice.submit.navigationComment multiple\n\n# View all spice config\ngit config --get-regexp spice\n```\n\n## Troubleshooting\n\n### Branch Not Tracked\n\n```bash\n# Track an existing branch\ngs branch track my-branch --base main\n```\n\n### Rebase Conflicts\n\n```bash\n# After resolving conflicts\ngs rebase continue\n\n# To abort and try different approach\ngs rebase abort\n```\n\n### Out of Sync with Remote\n\n```bash\ngs repo sync    # Fetch and sync\ngs repo restack # Restack all branches\n```\n\n### Force Push After Restack\n\nAfter restacking, branches need force push:\n```bash\ngs bs --force  # Submit handles force push\n# or manually:\ngit push --force-with-lease\n```\n\n## Reference Documentation\n\nFor detailed information on specific topics, see:\n- [Command Reference](references/commands.md) - Complete command documentation\n- [Workflows](references/workflows.md) - Advanced workflow patterns\n\n## Key Principles\n\n1. **Atomic branches**: Each branch should be one logical, reviewable change\n2. **Stack from trunk**: Build stacks starting from main/master\n3. **Restack often**: Keep branches rebased on latest changes\n4. **Submit together**: Use `gs ss` to create linked PRs\n5. **Sync regularly**: Use `gs rs` to stay current with upstream\n",
        "plugins/abatilo-core/skills/git-spice/references/commands.md": "# Git Spice Command Reference\n\nComplete reference for all git-spice (gs) commands.\n\n## Global Flags\n\nAll commands support these flags:\n\n| Flag | Description |\n|------|-------------|\n| `-h, --help` | Show help for command |\n| `--version` | Print version and exit |\n| `-v, --verbose` | Enable verbose output |\n| `-C, --dir=DIR` | Change directory before running |\n| `--[no-]prompt` | Enable/disable interactive prompts |\n\n## Repository Commands\n\n### gs repo init (ri)\n\nInitialize git-spice in a repository.\n\n```bash\ngs repo init\ngs ri\n```\n\nPrompts for:\n- Trunk branch (main, master, etc.)\n- Remote name (origin, etc.)\n\n### gs repo sync (rs)\n\nSynchronize with remote repository.\n\n```bash\ngs repo sync\ngs rs\n```\n\nActions:\n- Fetches latest from remote\n- Fast-forwards trunk if possible\n- Deletes local branches whose PRs are merged\n- Updates branch tracking state\n\n### gs repo restack (rr)\n\nRestack all tracked branches onto their bases.\n\n```bash\ngs repo restack\ngs rr\n```\n\nRebases every tracked branch to ensure it's up-to-date with its base.\n\n## Branch Commands\n\n### gs branch create (bc)\n\nCreate a new branch stacked on current branch.\n\n```bash\ngs branch create <name> [flags]\ngs bc <name> [flags]\n```\n\n**Flags:**\n\n| Flag | Description |\n|------|-------------|\n| `-m, --message=MSG` | Commit message for initial commit |\n| `-a, --all` | Stage all modified/deleted files |\n| `-t, --target=BRANCH` | Base branch (default: current) |\n| `--insert` | Restack upstack onto new branch |\n| `--below` | Create below target branch |\n| `--no-commit` | Create branch without commit |\n| `--no-verify` | Skip pre-commit hooks |\n| `--signoff` | Add Signed-off-by trailer |\n\n**Examples:**\n\n```bash\n# Basic creation with commit message\ngs bc feature-auth -m \"Add authentication middleware\"\n\n# Create without committing staged changes\ngs bc feature-auth --no-commit\n\n# Insert branch in middle of stack\ngs bc new-middle --insert\n\n# Create below current branch\ngs bc earlier-feature --below\n```\n\n### gs branch checkout (bco)\n\nSwitch to a tracked branch.\n\n```bash\ngs branch checkout [branch]\ngs bco [branch]\n```\n\nIf no branch specified, shows interactive picker.\n\n### gs branch track (btr)\n\nTrack an existing branch.\n\n```bash\ngs branch track <branch> --base <base>\ngs btr <branch> --base <base>\n```\n\n**Examples:**\n\n```bash\ngs btr feature-x --base main\ngs btr feature-y --base feature-x\n```\n\n### gs branch untrack (buntr)\n\nStop tracking a branch (doesn't delete it).\n\n```bash\ngs branch untrack [branch]\ngs buntr [branch]\n```\n\n### gs branch submit (bs)\n\nSubmit branch as a pull request.\n\n```bash\ngs branch submit [flags]\ngs bs [flags]\n```\n\n**Flags:**\n\n| Flag | Description |\n|------|-------------|\n| `--draft` | Create as draft PR |\n| `--title=TITLE` | PR title |\n| `--body=BODY` | PR body |\n| `--fill` | Fill title/body from commits |\n| `--no-publish` | Don't open in browser |\n| `--force` | Force push |\n| `-R, --reviewer=USER` | Add reviewer |\n\n**Examples:**\n\n```bash\ngs bs                    # Submit current branch\ngs bs --draft            # Submit as draft\ngs bs --fill             # Auto-fill from commits\ngs bs -R alice -R bob    # Add reviewers\n```\n\n### gs branch restack (br)\n\nRebase branch onto its base.\n\n```bash\ngs branch restack [branch]\ngs br [branch]\n```\n\n### gs branch onto (bon)\n\nMove branch to a different base.\n\n```bash\ngs branch onto <new-base>\ngs bon <new-base>\n```\n\n**Examples:**\n\n```bash\ngs bon main           # Rebase onto main\ngs bon other-feature  # Rebase onto another branch\n```\n\n### gs branch edit (be)\n\nInteractive rebase to edit commits in branch.\n\n```bash\ngs branch edit [branch]\ngs be [branch]\n```\n\nOpens interactive rebase for commits between base and branch head.\n\n### gs branch rename (brn, bmv)\n\nRename a branch.\n\n```bash\ngs branch rename <old> <new>\ngs brn <old> <new>\ngs bmv <old> <new>\n```\n\n### gs branch delete (bd, brm)\n\nDelete one or more branches.\n\n```bash\ngs branch delete <branch>...\ngs bd <branch>...\n```\n\n**Flags:**\n\n| Flag | Description |\n|------|-------------|\n| `--force` | Force delete unmerged branches |\n\n### gs branch fold (bfo)\n\nMerge branch into its base.\n\n```bash\ngs branch fold [branch]\ngs bfo [branch]\n```\n\nSquash-merges branch commits into base branch.\n\n### gs branch split (bsp)\n\nSplit branch at specified commits.\n\n```bash\ngs branch split\ngs bsp\n```\n\nInteractive command to split branch into multiple branches.\n\n### gs branch squash (bsq)\n\nSquash all commits in branch into one.\n\n```bash\ngs branch squash [branch]\ngs bsq [branch]\n```\n\n## Stack Commands\n\n### gs stack submit (ss)\n\nSubmit entire stack as PRs.\n\n```bash\ngs stack submit [flags]\ngs ss [flags]\n```\n\nCreates/updates PRs for all branches in the stack. PRs are linked with navigation comments.\n\n**Flags:** Same as `gs branch submit`\n\n### gs stack restack (sr)\n\nRestack all branches in current stack.\n\n```bash\ngs stack restack\ngs sr\n```\n\n### gs stack edit (se)\n\nEdit order of branches in stack.\n\n```bash\ngs stack edit\ngs se\n```\n\nOpens editor to reorder or remove branches.\n\n### gs stack delete (sd)\n\nDelete all branches in current stack.\n\n```bash\ngs stack delete [flags]\ngs sd [flags]\n```\n\n## Upstack Commands\n\nCommands that operate on current branch and everything above it.\n\n### gs upstack submit (uss)\n\nSubmit current branch and all branches above.\n\n```bash\ngs upstack submit [flags]\ngs uss [flags]\n```\n\n### gs upstack restack (usr)\n\nRestack current branch and all above.\n\n```bash\ngs upstack restack\ngs usr\n```\n\n### gs upstack onto (uso)\n\nMove current branch and upstack onto new base.\n\n```bash\ngs upstack onto <new-base>\ngs uso <new-base>\n```\n\n### gs upstack delete (usd)\n\nDelete all branches above current branch.\n\n```bash\ngs upstack delete\ngs usd\n```\n\n## Downstack Commands\n\nCommands that operate on current branch and everything below it.\n\n### gs downstack submit (dss)\n\nSubmit current branch and all branches below.\n\n```bash\ngs downstack submit [flags]\ngs dss [flags]\n```\n\n### gs downstack track (dstr)\n\nTrack all untracked branches below current branch.\n\n```bash\ngs downstack track\ngs dstr\n```\n\n### gs downstack edit (dse)\n\nEdit order of branches below current.\n\n```bash\ngs downstack edit\ngs dse\n```\n\n## Commit Commands\n\n### gs commit create (cc)\n\nCreate a new commit.\n\n```bash\ngs commit create [flags]\ngs cc [flags]\n```\n\n**Flags:**\n\n| Flag | Description |\n|------|-------------|\n| `-m, --message=MSG` | Commit message |\n| `-a, --all` | Stage all changes |\n| `--no-verify` | Skip hooks |\n| `--signoff` | Add Signed-off-by |\n\n### gs commit amend (ca)\n\nAmend the current commit.\n\n```bash\ngs commit amend [flags]\ngs ca [flags]\n```\n\n**Flags:**\n\n| Flag | Description |\n|------|-------------|\n| `-m, --message=MSG` | New commit message |\n| `-a, --all` | Stage all changes |\n| `--no-edit` | Keep existing message |\n| `--no-verify` | Skip hooks |\n\n### gs commit split (csp)\n\nSplit current commit into multiple commits.\n\n```bash\ngs commit split\ngs csp\n```\n\n### gs commit fixup (cf)\n\nCreate fixup commit for a commit below.\n\n```bash\ngs commit fixup [commit]\ngs cf [commit]\n```\n\n### gs commit pick (cp)\n\nCherry-pick a commit into current branch.\n\n```bash\ngs commit pick <commit>\ngs cp <commit>\n```\n\n## Navigation Commands\n\n### gs up (u)\n\nMove up one branch in the stack.\n\n```bash\ngs up\ngs u\n```\n\n### gs down (d)\n\nMove down one branch in the stack.\n\n```bash\ngs down\ngs d\n```\n\n### gs top (U)\n\nMove to the top of the current stack.\n\n```bash\ngs top\ngs U\n```\n\n### gs bottom (D)\n\nMove to the bottom of the current stack.\n\n```bash\ngs bottom\ngs D\n```\n\n### gs trunk\n\nSwitch to the trunk branch.\n\n```bash\ngs trunk\n```\n\n## Log Commands\n\n### gs log short (ls)\n\nList all tracked branches.\n\n```bash\ngs log short\ngs ls\n```\n\nShows branch tree with PR status.\n\n### gs log long (ll)\n\nList branches with their commits.\n\n```bash\ngs log long\ngs ll\n```\n\nShows branch tree with commit details.\n\n## Rebase Commands\n\n### gs rebase continue (rbc)\n\nContinue an interrupted rebase operation.\n\n```bash\ngs rebase continue\ngs rbc\n```\n\nUse after resolving conflicts during restack.\n\n### gs rebase abort (rba)\n\nAbort an interrupted rebase operation.\n\n```bash\ngs rebase abort\ngs rba\n```\n\n## Authentication Commands\n\n### gs auth login\n\nAuthenticate with GitHub or GitLab.\n\n```bash\ngs auth login\n```\n\n### gs auth status\n\nShow current authentication status.\n\n```bash\ngs auth status\n```\n\n### gs auth logout\n\nClear stored credentials.\n\n```bash\ngs auth logout\n```\n\n## Shell Completion\n\n```bash\ngs shell completion bash   # Bash completion\ngs shell completion zsh    # Zsh completion\ngs shell completion fish   # Fish completion\n```\n\n## Configuration Options\n\nSet via `git config`:\n\n| Option | Description |\n|--------|-------------|\n| `spice.branchCreate.prefix` | Prefix for new branch names |\n| `spice.branchCreate.generatedBranchNameLimit` | Max auto-generated name length (default: 32) |\n| `spice.branchCreate.commit` | Auto-commit on branch create |\n| `spice.commit.signoff` | Add Signed-off-by by default |\n| `spice.submit.navigationComment` | PR navigation comment style |\n| `spice.forge.github.url` | GitHub base URL |\n| `spice.forge.github.apiUrl` | GitHub API URL |\n| `spice.forge.gitlab.url` | GitLab base URL |\n| `spice.forge.gitlab.apiURL` | GitLab API URL |\n",
        "plugins/abatilo-core/skills/git-spice/references/workflows.md": "# Git Spice Workflows\n\nAdvanced workflow patterns for managing stacked branches.\n\n## Workflow 1: Building a Feature Stack\n\n### Scenario\n\nYou're implementing a large feature that should be broken into reviewable pieces.\n\n### Steps\n\n```bash\n# 1. Start from updated trunk\ngs trunk\ngit pull origin main\n\n# 2. Create the first branch (foundation layer)\ngs bc api-models -m \"Add User and Profile models\"\n\n# Make your changes...\ngit add src/models/\ngs ca  # Amend to add more changes\n# Or create additional commits\ngs cc -m \"Add model validation\"\n\n# 3. Create second branch (builds on first)\ngs bc api-endpoints -m \"Add user API endpoints\"\n\n# Make changes...\ngit add src/api/\ngs cc -m \"Implement CRUD operations\"\n\n# 4. Create third branch (builds on second)\ngs bc api-tests -m \"Add API integration tests\"\n\n# Make changes...\ngit add tests/\ngs cc -m \"Add user endpoint tests\"\n\n# 5. View your stack\ngs ll\n```\n\n### Result\n\n```\n      ┌── api-tests\n    ┌─┴ api-endpoints\n  ┌─┴ api-models\n  main\n```\n\n## Workflow 2: Submitting a Stack for Review\n\n### Scenario\n\nYour stack is ready for review. You want to create linked PRs.\n\n### Steps\n\n```bash\n# 1. Ensure you're authenticated\ngs auth status\n\n# 2. View what will be submitted\ngs ls\n\n# 3. Submit entire stack\ngs ss\n\n# For draft PRs\ngs ss --draft\n\n# For auto-filled titles/bodies from commits\ngs ss --fill\n\n# 4. View PR links\ngs ls  # Shows PR numbers next to branches\n```\n\n### Navigation Comments\n\nGit-spice automatically adds navigation comments to PRs:\n\n```markdown\n## Stack\n- #101 (api-models) ← Base\n- #102 (api-endpoints) ← **This PR**\n- #103 (api-tests)\n```\n\n## Workflow 3: Updating After Review Feedback\n\n### Scenario\n\nReviewers requested changes to a branch in the middle of your stack.\n\n### Steps\n\n```bash\n# 1. Check out the branch that needs changes\ngs bco api-endpoints\n\n# 2. Make your changes\n# ... edit files ...\n\n# 3. Either amend existing commit\ngs ca\n\n# Or create a new commit\ngs cc -m \"Address review: improve error handling\"\n\n# 4. Restack everything above this branch\ngs usr  # upstack restack\n\n# 5. Re-submit updated branches\ngs uss  # upstack submit (force push happens automatically)\n```\n\n## Workflow 4: Syncing with Upstream\n\n### Scenario\n\nTrunk has new commits and your stack needs updating.\n\n### Steps\n\n```bash\n# 1. Sync repository\ngs rs  # repo sync\n# This:\n# - Fetches from remote\n# - Fast-forwards trunk\n# - Deletes branches whose PRs merged\n\n# 2. Restack your branches\n# Option A: Restack all tracked branches\ngs repo restack\n\n# Option B: Restack just current stack\ngs sr  # stack restack\n\n# 3. Re-submit to update PRs\ngs ss\n```\n\n## Workflow 5: Handling Merge Conflicts\n\n### Scenario\n\nA restack operation encounters conflicts.\n\n### Steps\n\n```bash\n# 1. Start restack\ngs sr\n\n# 2. If conflicts occur, gs pauses and shows conflicted files\n# Check status\ngit status\n\n# 3. Resolve conflicts in your editor\n# ... edit conflicted files ...\n\n# 4. Stage resolved files\ngit add <resolved-files>\n\n# 5. Continue the restack\ngs rbc  # rebase continue\n\n# If conflicts continue in other branches, repeat steps 3-5\n\n# 6. If you need to abort\ngs rba  # rebase abort\n```\n\n## Workflow 6: Reorganizing a Stack\n\n### Scenario\n\nYou need to reorder branches or insert a new branch in the middle.\n\n### Reorder Branches\n\n```bash\n# 1. Edit stack order\ngs se  # stack edit\n\n# Opens editor with branch list - reorder as needed\n# Save and close to apply changes\n```\n\n### Insert New Branch\n\n```bash\n# 1. Check out where you want to insert\ngs bco api-endpoints\n\n# 2. Create with --insert flag\ngs bc api-middleware --insert -m \"Add rate limiting middleware\"\n\n# This creates:\n#       ┌── api-tests      (moved up)\n#     ┌─┴ api-middleware   (new)\n#   ┌─┴ api-endpoints\n# ┌─┴ api-models\n# main\n```\n\n### Move Branch to Different Base\n\n```bash\n# Move current branch onto different base\ngs bon main  # Direct to trunk\n\n# Move entire upstack\ngs uso other-feature\n```\n\n## Workflow 7: Cleaning Up After Merge\n\n### Scenario\n\nPRs have been merged and you want to clean up.\n\n### Steps\n\n```bash\n# 1. Sync to detect merged PRs\ngs rs\n\n# Repo sync automatically:\n# - Detects merged PRs\n# - Deletes local branches\n# - Updates tracking state\n\n# 2. If manual cleanup needed\ngs bd merged-branch --force\n```\n\n## Workflow 8: Working with Draft PRs\n\n### Scenario\n\nYou want early feedback without formal review.\n\n### Steps\n\n```bash\n# 1. Submit as drafts\ngs ss --draft\n\n# 2. Continue working and updating\ngs bco some-branch\n# ... make changes ...\ngs ca\ngs usr\ngs uss  # Updates existing draft PRs\n\n# 3. When ready, mark as ready on GitHub/GitLab\n# (No gs command - use web UI)\n```\n\n## Workflow 9: Splitting a Large Branch\n\n### Scenario\n\nA branch has grown too large and should be split.\n\n### Steps\n\n```bash\n# 1. Check out the branch to split\ngs bco large-feature\n\n# 2. Use branch split\ngs bsp\n\n# Interactive mode lets you:\n# - Select commits for each new branch\n# - Name the new branches\n# - Automatically restacks\n```\n\n### Alternative: Manual Split\n\n```bash\n# 1. Create new branch at earlier point\ngs bco large-feature\ngs bc first-half --below\n\n# 2. Cherry-pick relevant commits\ngs cp <commit-hash>\n\n# 3. Use branch edit to remove from original\ngs bco large-feature\ngs be  # Remove commits that were moved\n```\n\n## Workflow 10: Squashing Before Merge\n\n### Scenario\n\nYou want to squash commits before the final merge.\n\n### Steps\n\n```bash\n# Squash all commits in branch to one\ngs bsq\n\n# Or use branch edit for selective squashing\ngs be\n# In editor, change \"pick\" to \"squash\" for commits to combine\n```\n\n## Workflow 11: Importing Existing Branches\n\n### Scenario\n\nYou have existing branches that aren't tracked by git-spice.\n\n### Steps\n\n```bash\n# Track a single branch\ngs btr existing-feature --base main\n\n# Track a chain of branches (bottom-up)\ngs btr feature-part1 --base main\ngs btr feature-part2 --base feature-part1\ngs btr feature-part3 --base feature-part2\n\n# Or use downstack track from the top\ngs bco feature-part3\ngs dstr  # Tracks all branches below\n```\n\n## Workflow 12: Multiple Stacks\n\n### Scenario\n\nYou're working on multiple independent features.\n\n### Steps\n\n```bash\n# Stack 1: Auth feature\ngs trunk\ngs bc auth-models -m \"Auth models\"\ngs bc auth-api -m \"Auth API\"\n\n# Stack 2: Separate feature\ngs trunk  # Return to trunk\ngs bc reporting-models -m \"Reporting models\"\ngs bc reporting-ui -m \"Reporting UI\"\n\n# View all stacks\ngs ls\n\n# Navigate between stacks\ngs bco auth-api      # Jump to auth stack\ngs bco reporting-ui  # Jump to reporting stack\n```\n\n## Workflow 13: Handling Force Push Failures\n\n### Scenario\n\nA force push fails due to new commits on remote.\n\n### Steps\n\n```bash\n# 1. Fetch latest\ngit fetch origin\n\n# 2. Check what's different\ngit log HEAD..origin/your-branch\n\n# 3. If remote has wanted changes, reset\ngit reset --hard origin/your-branch\n\n# 4. Restack if needed\ngs br\n\n# 5. Re-submit\ngs bs\n```\n\n## Best Practices\n\n### Stack Size\n\n- Keep stacks to 3-5 branches maximum\n- Each branch should be independently reviewable\n- Larger features: consider multiple smaller stacks\n\n### Commit Hygiene\n\n- Use meaningful commit messages\n- Squash fixup commits before final review\n- Keep commits atomic and focused\n\n### Naming Conventions\n\n```bash\n# Use prefixes for organization\ngit config spice.branchCreate.prefix \"username/\"\n\n# Result: username/feature-name\n```\n\n### Review Workflow\n\n1. Submit stack as draft (`gs ss --draft`)\n2. Get early feedback\n3. Address comments branch by branch\n4. Restack after changes (`gs sr`)\n5. Mark ready when complete\n\n### Merge Strategy\n\n- Merge from bottom to top\n- After each merge, sync (`gs rs`)\n- Continue merging remaining branches\n\n## Gotchas\n\n### GitHub Auto-Retarget Race Condition\n\nWhen merging a PR at the bottom of a stack with `gh pr merge --delete-branch`:\n\n**Expected:** GitHub auto-retargets dependent PRs to the new base branch.\n\n**Actual:** Sometimes the branch is deleted before GitHub can retarget, causing dependent PRs to close instead.\n\n**Timeline observed:**\n```\n21:52:17Z - PR merged\n21:52:19Z - base_ref_deleted (2 seconds later)\n21:52:20Z - Dependent PR closed (not retargeted)\n```\n\n**Workarounds:**\n1. Don't use `--delete-branch` flag - let GitHub delete branches automatically via repo settings (`delete_branch_on_merge: true`)\n2. Manually update base branches of dependent PRs before merging\n3. Use `gs repo sync` after merge - git-spice will detect closed PRs and create new ones with correct base\n\n**Recovery with git-spice:**\n```bash\n# After the race condition closes your PR\ngs rs                           # Sync - detects closed PR\ngs branch track <branch> --base main  # Re-track with correct base\ngs sr                           # Restack\ngs ss                           # Submit - creates new PR\n```\n",
        "plugins/abatilo-core/skills/kubernetes/SKILL.md": "---\nname: kubernetes\ndescription: Comprehensive Kubernetes (k8s) cluster management skill. Use when working with kubectl, Helm, kustomize, pods, deployments, services, configmaps, secrets, or any Kubernetes operations. Triggers on \"k8s\", \"kubectl get\", \"helm install\", \"debug pod\", \"scale deployment\", or cluster troubleshooting questions.\ncontext: fork\nallowed-tools:\n  - Bash(kubectl:*)\n  - Bash(helm:*)\n  - Bash(kustomize:*)\n  - Read\n---\n\n# Kubernetes Management Skill\n\nThis skill provides comprehensive capabilities for managing Kubernetes clusters, resources, and workloads using kubectl, Helm, and Kustomize.\n\n## When to Use This Skill\n\nUse this skill when working with:\n- Kubernetes resources (pods, deployments, services, configmaps, secrets, etc.)\n- Debugging containerized applications and troubleshooting cluster issues\n- Helm chart installation, upgrades, and management\n- kubectl operations (get, describe, apply, create, delete, logs, exec, scale, rollout)\n- Context and namespace management\n- Deployment strategies (rolling updates, blue-green, canary)\n- Configuration management and resource optimization\n\n## How to Use This Skill\n\n### 1. Verify Context and Namespace\n\n**Always start by verifying your current context and namespace:**\n```bash\nkubectl config current-context\nkubectl config view --minify\n```\n\nSet namespace if needed:\n```bash\nkubectl config set-context --current --namespace=<namespace>\n```\n\n### 2. Load Appropriate Reference Files\n\nBased on the task at hand, load the relevant reference documentation:\n\n**For kubectl Operations:**\nLoad [kubectl Reference](./references/kubectl_reference.md) when you need detailed information about:\n- Getting, describing, creating, updating, or deleting resources\n- Viewing logs or executing commands in containers\n- Port forwarding and debugging\n- Scaling deployments\n- Managing rollouts and rollbacks\n- Context and namespace operations\n- Output formats and filtering\n\n**For Helm Operations:**\nLoad [Helm Reference](./references/helm_reference.md) when you need detailed information about:\n- Installing or upgrading Helm charts\n- Managing releases (list, status, uninstall, rollback)\n- Repository management\n- Chart development and inspection\n- Values configuration and overrides\n- Troubleshooting Helm issues\n\n**For Common Workflows:**\nLoad [Workflows Reference](./references/workflows.md) when you need guidance on:\n- Debugging failing pods or services\n- Deploying applications\n- Updating deployments with different strategies\n- Blue-green and canary deployments\n- Configuration management (ConfigMaps and Secrets)\n- Maintenance operations (draining nodes, backup/restore)\n- Cluster inspection and cleanup\n\n**For Best Practices:**\nLoad [Best Practices Reference](./references/best_practices.md) when you need guidance on:\n- Safety and validation before operations\n- Efficiency and optimization\n- Debugging approaches\n- YAML and manifest management\n- High availability patterns\n- Error handling and troubleshooting\n- Integration with other tools\n- Environment-specific practices\n\n### 3. General Workflow\n\n**For Resource Management:**\n1. Verify context and namespace\n2. Use `kubectl get` to list resources\n3. Use `kubectl describe` for detailed information\n4. Apply changes with `kubectl apply` or `kubectl patch`\n5. Monitor with `kubectl rollout status` or `kubectl get events`\n\n**For Debugging:**\n1. Check pod status with `kubectl get pods`\n2. Describe the resource with `kubectl describe`\n3. View logs with `kubectl logs`\n4. Check events with `kubectl get events`\n5. Exec into container if needed with `kubectl exec -it`\n\n**For Deployments:**\n1. Validate manifests with `--dry-run`\n2. Apply manifests with `kubectl apply`\n3. Monitor rollout with `kubectl rollout status`\n4. Verify with `kubectl get` and `kubectl logs`\n5. Rollback if needed with `kubectl rollout undo`\n\n## Key Principles\n\n### Safety First\n- Always verify context and namespace before operations\n- Use `--dry-run=client` or `--dry-run=server` to validate changes\n- Use `kubectl diff` to preview changes before applying\n- Be cautious with destructive operations (delete, force, drain)\n\n### Declarative Over Imperative\n- Prefer `kubectl apply -f file.yaml` over imperative commands\n- Store manifests in version control\n- Use Kustomize for environment-specific overlays\n- Make infrastructure reproducible and auditable\n\n### Efficient Resource Usage\n- Use label selectors to operate on groups of resources\n- Use output formats (`-o json|yaml`) for automation and parsing\n- Filter with `--field-selector` and sort with `--sort-by`\n- Watch resources in real-time with `-w` flag\n\n### Systematic Debugging\n- Follow the debugging workflow: status → describe → logs → events → exec\n- Use timestamps in logs for correlation\n- Check recent events with `kubectl get events --sort-by='.lastTimestamp'`\n- Test connectivity with temporary debug pods\n\n## Quick Command Reference\n\n**Most Common Operations:**\n```bash\n# Get resources\nkubectl get pods\nkubectl get pods -o wide\nkubectl get pods -l app=myapp\n\n# Describe for details\nkubectl describe pod <pod-name>\n\n# View logs\nkubectl logs <pod-name>\nkubectl logs <pod-name> -f\nkubectl logs <pod-name> --previous\n\n# Exec into pod\nkubectl exec -it <pod-name> -- /bin/sh\n\n# Apply manifests\nkubectl apply -f deployment.yaml\nkubectl apply -f ./manifests/\n\n# Scale deployment\nkubectl scale deployment/<name> --replicas=3\n\n# Check rollout\nkubectl rollout status deployment/<name>\nkubectl rollout undo deployment/<name>\n\n# Port forward\nkubectl port-forward service/<name> 8080:80\n\n# Helm operations\nhelm install <release> <chart>\nhelm upgrade <release> <chart>\nhelm list\nhelm uninstall <release>\n```\n\n## Important Notes\n\n- Reference files contain comprehensive details - load them as needed to avoid context overhead\n- Always validate configurations before applying to production\n- Use namespaces for resource isolation\n- Set resource requests and limits for all containers\n- Implement health checks (liveness, readiness, startup probes)\n- Use PodDisruptionBudgets for high availability\n- Store sensitive data in Secrets, not ConfigMaps\n- Tag images with specific versions, avoid `:latest` in production\n\n## Integration Points\n\nThis skill works well with:\n- **Docker** for container image management\n- **Git** for manifest version control (GitOps)\n- **Terraform** for infrastructure provisioning\n- **CI/CD pipelines** for automated deployments\n- **Monitoring tools** (Prometheus, Grafana) for observability\n- **Logging systems** (EFK stack) for centralized logging\n\n---\n\n**Remember:** Load the specific reference files only when you need detailed information about kubectl commands, Helm operations, specific workflows, or best practices. This keeps the context manageable and efficient.\n",
        "plugins/abatilo-core/skills/kubernetes/references/best_practices.md": "# Kubernetes Best Practices\n\nThis reference provides best practices, tips, troubleshooting guidelines, and integration patterns for working with Kubernetes.\n\n## Safety Best Practices\n\n### Pre-Deployment Validation\n\n**Always Validate Before Applying:**\n```bash\n# Client-side validation (checks syntax)\nkubectl apply -f deployment.yaml --dry-run=client\n\n# Server-side validation (checks against cluster)\nkubectl apply -f deployment.yaml --dry-run=server\n\n# Preview changes before applying\nkubectl diff -f deployment.yaml\n```\n\n**Verify Context and Namespace:**\n```bash\n# Check current context\nkubectl config current-context\n\n# Check current namespace\nkubectl config view --minify --output 'jsonpath={..namespace}'\n\n# Explicitly set namespace\nkubectl apply -f deployment.yaml -n production\n```\n\n### Destructive Operations\n\n**Be Cautious With:**\n- `kubectl delete` - Removes resources permanently\n- `kubectl delete --all` - Deletes everything of a type\n- `kubectl delete namespace` - Removes namespace and all resources in it\n- `--force` flag - Bypasses graceful termination\n- `kubectl drain` - Evicts all pods from a node\n- `kubectl replace --force` - Deletes and recreates resources\n\n**Safe Patterns:**\n```bash\n# List before deleting\nkubectl get pods\nkubectl delete pod specific-pod-name\n\n# Use labels to target specific resources\nkubectl delete pods -l app=myapp,env=dev\n\n# Dry run first\nkubectl delete -f deployment.yaml --dry-run=client\n```\n\n### Resource Management Safety\n\n**Set Resource Limits:**\n```yaml\nresources:\n  requests:\n    memory: \"128Mi\"\n    cpu: \"100m\"\n  limits:\n    memory: \"256Mi\"\n    cpu: \"200m\"\n```\n\nThis prevents:\n- Resource exhaustion on nodes\n- OOM kills affecting other pods\n- Runaway processes consuming all CPU\n\n**Use PodDisruptionBudgets:**\n```yaml\napiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: myapp-pdb\nspec:\n  minAvailable: 2\n  selector:\n    matchLabels:\n      app: myapp\n```\n\nProtects against:\n- Too many pods being evicted during node maintenance\n- Service downtime during voluntary disruptions\n\n### Configuration Safety\n\n**Never Store Secrets in ConfigMaps:**\n```bash\n# Wrong\nkubectl create configmap app-config --from-literal=password=secret123\n\n# Right\nkubectl create secret generic app-secret --from-literal=password=secret123\n```\n\n**Use RBAC:**\n```bash\n# Check your permissions\nkubectl auth can-i create deployments\nkubectl auth can-i delete pods --all-namespaces\n\n# List all permissions\nkubectl auth can-i --list\n```\n\n## Efficiency Best Practices\n\n### Resource Organization\n\n**Use Labels Effectively:**\n```yaml\nmetadata:\n  labels:\n    app: myapp\n    tier: frontend\n    env: production\n    version: v1.0.0\n    team: platform\n```\n\nQuery by labels:\n```bash\n# Get all frontend pods\nkubectl get pods -l tier=frontend\n\n# Get production resources\nkubectl get all -l env=production\n\n# Complex selectors\nkubectl get pods -l 'app=myapp,env in (prod,staging)'\n```\n\n**Use Namespaces for Isolation:**\n```bash\n# Organize by environment\nkubectl create namespace development\nkubectl create namespace staging\nkubectl create namespace production\n\n# Organize by team\nkubectl create namespace team-platform\nkubectl create namespace team-data\n\n# Set default namespace\nkubectl config set-context --current --namespace=development\n```\n\n### Command Efficiency\n\n**Use Shortcuts:**\n```bash\n# Resource type shortcuts\nkubectl get po      # pods\nkubectl get svc     # services\nkubectl get deploy  # deployments\nkubectl get cm      # configmaps\nkubectl get ns      # namespaces\n\n# Multiple resources\nkubectl get po,svc,deploy\n\n# All resources\nkubectl get all\n```\n\n**Use Output Formats for Automation:**\n```bash\n# Get pod names only\nkubectl get pods -o name\n\n# Get specific fields with JSONPath\nkubectl get pods -o jsonpath='{.items[*].metadata.name}'\n\n# Format as table\nkubectl get pods -o custom-columns=NAME:.metadata.name,STATUS:.status.phase,IP:.status.podIP\n```\n\n**Combine Operations:**\n```bash\n# Wait for condition\nkubectl wait --for=condition=ready pod/myapp-pod --timeout=60s\n\n# Port forward and test\nkubectl port-forward svc/myapp 8080:80 &\nsleep 2\ncurl http://localhost:8080\nkill %1\n```\n\n### Filtering and Selection\n\n**Use Field Selectors:**\n```bash\n# Get running pods only\nkubectl get pods --field-selector status.phase=Running\n\n# Get pods on specific node\nkubectl get pods --field-selector spec.nodeName=node-1\n\n# Combine multiple fields\nkubectl get pods --field-selector status.phase=Running,spec.restartPolicy=Always\n```\n\n**Sort Results:**\n```bash\n# Sort by creation time\nkubectl get pods --sort-by=.metadata.creationTimestamp\n\n# Sort by name\nkubectl get pods --sort-by=.metadata.name\n\n# Sort events by time\nkubectl get events --sort-by='.lastTimestamp'\n```\n\n## Debugging Best Practices\n\n### Systematic Debugging Approach\n\n**Follow This Order:**\n1. **Check Status**: `kubectl get pods`\n2. **Describe Resource**: `kubectl describe pod <name>`\n3. **View Logs**: `kubectl logs <name>`\n4. **Check Events**: `kubectl get events`\n5. **Exec Into Pod**: `kubectl exec -it <name> -- /bin/sh`\n\n### Effective Log Analysis\n\n**Use Timestamps:**\n```bash\nkubectl logs <pod-name> --timestamps\n```\n\n**Filter Logs:**\n```bash\n# Since time\nkubectl logs <pod-name> --since=5m\nkubectl logs <pod-name> --since=1h\n\n# Tail logs\nkubectl logs <pod-name> --tail=100\n\n# Previous container\nkubectl logs <pod-name> --previous\n```\n\n**Aggregate Logs:**\n```bash\n# All pods with label\nkubectl logs -l app=myapp --tail=50\n\n# Stream from multiple pods\nkubectl logs -l app=myapp -f --max-log-requests=10\n```\n\n### Event Analysis\n\n**Monitor Events:**\n```bash\n# Watch events in real-time\nkubectl get events -w\n\n# Filter events by type\nkubectl get events --field-selector type=Warning\n\n# Events for specific resource\nkubectl get events --field-selector involvedObject.name=<pod-name>\n\n# Recent events\nkubectl get events --sort-by='.lastTimestamp' | tail -20\n```\n\n### Network Debugging\n\n**Use Debug Containers:**\n```bash\n# Run temporary debug pod\nkubectl run debug-pod --rm -it --image=nicolaka/netshoot -- /bin/bash\n\n# Test connectivity\nwget -O- http://service-name:80\nnslookup service-name\ntraceroute service-name\n```\n\n**Ephemeral Debug Containers (K8s 1.23+):**\n```bash\nkubectl debug <pod-name> -it --image=busybox --target=<container-name>\n```\n\n## YAML Management Best Practices\n\n### Manifest Organization\n\n**File Structure:**\n```\nk8s/\n├── base/\n│   ├── deployment.yaml\n│   ├── service.yaml\n│   └── kustomization.yaml\n└── overlays/\n    ├── dev/\n    │   ├── kustomization.yaml\n    │   └── patches/\n    ├── staging/\n    │   └── kustomization.yaml\n    └── prod/\n        └── kustomization.yaml\n```\n\n**Version Control:**\n- Store all manifests in Git\n- Use branches for environments\n- Tag releases\n- Use GitOps tools (ArgoCD, Flux)\n\n### Declarative Configuration\n\n**Prefer Declarative Over Imperative:**\n\n```bash\n# Imperative (avoid for production)\nkubectl create deployment nginx --image=nginx\nkubectl expose deployment nginx --port=80\n\n# Declarative (preferred)\nkubectl apply -f deployment.yaml\nkubectl apply -f service.yaml\n```\n\n**Use kubectl apply:**\n```bash\n# Initial creation\nkubectl apply -f deployment.yaml\n\n# Updates\nkubectl apply -f deployment.yaml  # Same command!\n\n# Entire directory\nkubectl apply -f ./manifests/\n\n# Recursive\nkubectl apply -R -f ./k8s/\n```\n\n### Kustomize Integration\n\n**Base Configuration:**\n```yaml\n# kustomization.yaml\nresources:\n- deployment.yaml\n- service.yaml\n\ncommonLabels:\n  app: myapp\n\nnamespace: default\n```\n\n**Environment Overlays:**\n```yaml\n# overlays/prod/kustomization.yaml\nbases:\n- ../../base\n\nnamePrefix: prod-\nnamespace: production\n\nreplicas:\n- name: myapp\n  count: 5\n\nimages:\n- name: myapp\n  newTag: v2.0.0\n```\n\n**Apply with Kustomize:**\n```bash\nkubectl apply -k base/\nkubectl apply -k overlays/prod/\n```\n\n## Performance Optimization\n\n### Resource Optimization\n\n**Right-Size Resources:**\n```bash\n# Check actual usage\nkubectl top pods\nkubectl top pods --containers\n\n# Set appropriate requests/limits\nrequests:\n  memory: \"128Mi\"  # What it typically uses\n  cpu: \"100m\"\nlimits:\n  memory: \"256Mi\"  # Maximum it can use\n  cpu: \"500m\"      # Can burst to this\n```\n\n**Use Horizontal Pod Autoscaling:**\n```bash\n# Create HPA\nkubectl autoscale deployment myapp --min=2 --max=10 --cpu-percent=80\n\n# Check HPA\nkubectl get hpa\n```\n\n**Use Vertical Pod Autoscaling (if available):**\n```yaml\napiVersion: autoscaling.k8s.io/v1\nkind: VerticalPodAutoscaler\nmetadata:\n  name: myapp-vpa\nspec:\n  targetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: myapp\n  updatePolicy:\n    updateMode: \"Auto\"\n```\n\n### Image Optimization\n\n**Use Specific Tags:**\n```yaml\n# Bad\nimage: nginx:latest\n\n# Good\nimage: nginx:1.21.6-alpine\n```\n\n**Use Image Pull Policies:**\n```yaml\nimagePullPolicy: IfNotPresent  # For tagged images\n# or\nimagePullPolicy: Always        # For :latest or no tag\n```\n\n**Use Small Base Images:**\n- Alpine Linux images (~5MB)\n- Distroless images (no shell, minimal CVEs)\n- Scratch images (static binaries)\n\n## High Availability Patterns\n\n### Multi-Replica Deployments\n\n**Minimum Replicas:**\n```yaml\nspec:\n  replicas: 3  # Minimum for HA\n```\n\n**Pod Disruption Budgets:**\n```yaml\napiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: myapp-pdb\nspec:\n  minAvailable: 2  # At least 2 must be available\n  selector:\n    matchLabels:\n      app: myapp\n```\n\n### Topology Spread\n\n**Spread Across Nodes:**\n```yaml\nspec:\n  topologySpreadConstraints:\n  - maxSkew: 1\n    topologyKey: kubernetes.io/hostname\n    whenUnsatisfiable: DoNotSchedule\n    labelSelector:\n      matchLabels:\n        app: myapp\n```\n\n**Spread Across Zones:**\n```yaml\nspec:\n  topologySpreadConstraints:\n  - maxSkew: 1\n    topologyKey: topology.kubernetes.io/zone\n    whenUnsatisfiable: ScheduleAnyway\n    labelSelector:\n      matchLabels:\n        app: myapp\n```\n\n### Health Checks\n\n**Liveness Probe** (restart if unhealthy):\n```yaml\nlivenessProbe:\n  httpGet:\n    path: /health\n    port: 8080\n  initialDelaySeconds: 30\n  periodSeconds: 10\n  timeoutSeconds: 5\n  failureThreshold: 3\n```\n\n**Readiness Probe** (remove from service if not ready):\n```yaml\nreadinessProbe:\n  httpGet:\n    path: /ready\n    port: 8080\n  initialDelaySeconds: 5\n  periodSeconds: 5\n  timeoutSeconds: 3\n  failureThreshold: 2\n```\n\n**Startup Probe** (for slow-starting containers):\n```yaml\nstartupProbe:\n  httpGet:\n    path: /health\n    port: 8080\n  initialDelaySeconds: 0\n  periodSeconds: 10\n  timeoutSeconds: 3\n  failureThreshold: 30  # Up to 5 minutes to start\n```\n\n## Error Handling\n\n### Common Errors and Solutions\n\n**ImagePullBackOff**\n```bash\n# Check image name and tag\nkubectl describe pod <pod-name> | grep Image\n\n# Verify image exists\ndocker pull <image-name>\n\n# Check image pull secret\nkubectl get secret <secret-name> -o yaml\n```\n\n**CrashLoopBackOff**\n```bash\n# Check logs\nkubectl logs <pod-name>\nkubectl logs <pod-name> --previous\n\n# Check exit code\nkubectl describe pod <pod-name> | grep \"Exit Code\"\n\n# Common causes:\n# - Application error\n# - Missing environment variables\n# - Failed health checks\n# - Resource limits\n```\n\n**Pending Pods**\n```bash\n# Check events\nkubectl describe pod <pod-name>\n\n# Common causes:\n# - Insufficient resources\n# - Node selector doesn't match\n# - Taints not tolerated\n# - PV not available\n\n# Check node resources\nkubectl top nodes\nkubectl describe nodes\n```\n\n**OOMKilled**\n```bash\n# Increase memory limits\nresources:\n  limits:\n    memory: \"512Mi\"  # Increase this\n\n# Check actual usage\nkubectl top pod <pod-name> --containers\n```\n\n**Permission Denied Errors**\n```bash\n# Check RBAC\nkubectl auth can-i create pods\nkubectl auth can-i get services --as=system:serviceaccount:default:myapp\n\n# Describe ServiceAccount\nkubectl describe serviceaccount <sa-name>\n\n# Check RoleBindings\nkubectl get rolebindings\nkubectl describe rolebinding <binding-name>\n```\n\n## Integration with Other Tools\n\n### Docker Integration\n\n**Build and Push:**\n```bash\n# Build image\ndocker build -t myapp:v1.0.0 .\n\n# Tag for registry\ndocker tag myapp:v1.0.0 registry.example.com/myapp:v1.0.0\n\n# Push to registry\ndocker push registry.example.com/myapp:v1.0.0\n\n# Update deployment\nkubectl set image deployment/myapp myapp=registry.example.com/myapp:v1.0.0\n```\n\n### Git Integration (GitOps)\n\n**ArgoCD Pattern:**\n```yaml\n# application.yaml\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: myapp\nspec:\n  source:\n    repoURL: https://github.com/org/repo\n    path: k8s/overlays/prod\n    targetRevision: main\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: production\n  syncPolicy:\n    automated:\n      prune: true\n      selfHeal: true\n```\n\n### Terraform Integration\n\n**Provision with Terraform, Configure with Kubectl:**\n```hcl\n# Terraform creates cluster\nresource \"aws_eks_cluster\" \"main\" {\n  name = \"my-cluster\"\n  # ...\n}\n\n# Then use kubectl for applications\n# kubectl apply -f manifests/\n```\n\n### CI/CD Integration\n\n**GitHub Actions Example:**\n```yaml\n- name: Deploy to Kubernetes\n  run: |\n    kubectl config use-context production\n    kubectl set image deployment/myapp myapp=${{ env.IMAGE_TAG }}\n    kubectl rollout status deployment/myapp\n```\n\n### Monitoring Integration\n\n**Prometheus:**\n```yaml\n# ServiceMonitor for Prometheus\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: myapp\nspec:\n  selector:\n    matchLabels:\n      app: myapp\n  endpoints:\n  - port: metrics\n    interval: 30s\n```\n\n**Logging (EFK Stack):**\n```yaml\n# Fluentd reads logs\n# Elasticsearch stores logs\n# Kibana visualizes logs\n\n# View logs\nkubectl logs <pod-name> -f\n```\n\n## Tips and Tricks\n\n### Useful Aliases\n\n```bash\nalias k=kubectl\nalias kg='kubectl get'\nalias kd='kubectl describe'\nalias kdel='kubectl delete'\nalias kl='kubectl logs'\nalias kex='kubectl exec -it'\nalias kgpo='kubectl get pods'\nalias kgsvc='kubectl get services'\n```\n\n### Quick Operations\n\n**Watch Resources:**\n```bash\n# Watch pods\nkubectl get pods -w\n\n# Watch events\nkubectl get events -w\n\n# Watch with specific output\nwatch kubectl get pods -o wide\n```\n\n**Temporary Debug Pod:**\n```bash\nkubectl run debug-pod --rm -it --image=busybox -- /bin/sh\n```\n\n**Quick Port Forward:**\n```bash\n# Background port forward\nkubectl port-forward service/myapp 8080:80 &\nPF_PID=$!\n# Do work...\nkill $PF_PID\n```\n\n**Export Resources:**\n```bash\n# Export pod definition\nkubectl get pod <pod-name> -o yaml --export > pod.yaml\n\n# Export all resources\nkubectl get all -o yaml > all-resources.yaml\n```\n\n### Power User Commands\n\n**List All Resources in Namespace:**\n```bash\nkubectl api-resources --verbs=list --namespaced -o name | \\\n  xargs -n 1 kubectl get --show-kind --ignore-not-found -n <namespace>\n```\n\n**Find Resource Hogs:**\n```bash\n# CPU hogs\nkubectl top pods --all-namespaces --sort-by=cpu\n\n# Memory hogs\nkubectl top pods --all-namespaces --sort-by=memory\n```\n\n**Bulk Delete:**\n```bash\n# Delete all failed pods\nkubectl delete pods --field-selector=status.phase=Failed --all-namespaces\n\n# Delete all completed jobs\nkubectl delete jobs --field-selector status.successful=1\n```\n\n**Context Switching:**\n```bash\n# Quick context switch (if kubectx installed)\nkubectx production\n\n# Quick namespace switch (if kubens installed)\nkubens staging\n\n# Without tools\nkubectl config use-context production\nkubectl config set-context --current --namespace=staging\n```\n\n### Advanced JSONPath\n\n**Complex Queries:**\n```bash\n# Get all container images\nkubectl get pods -o jsonpath='{.items[*].spec.containers[*].image}' | tr -s ' ' '\\n'\n\n# Get pod names and IPs\nkubectl get pods -o jsonpath='{range .items[*]}{.metadata.name}{\"\\t\"}{.status.podIP}{\"\\n\"}{end}'\n\n# Get node capacity\nkubectl get nodes -o jsonpath='{range .items[*]}{.metadata.name}{\"\\t\"}{.status.capacity.cpu}{\"\\t\"}{.status.capacity.memory}{\"\\n\"}{end}'\n```\n\n## Environment-Specific Practices\n\n### Development Environment\n\n- Use smaller resource requests/limits\n- Use NodePort or port-forwarding instead of LoadBalancers\n- Enable debug logging\n- Use :latest tags (with imagePullPolicy: Always)\n- Shorter grace periods for faster iteration\n\n### Production Environment\n\n- Use specific image tags\n- Set resource requests and limits\n- Use multiple replicas\n- Configure health checks\n- Use PodDisruptionBudgets\n- Enable monitoring and logging\n- Use NetworkPolicies\n- Implement proper RBAC\n- Regular backups\n- Use namespaces for isolation\n",
        "plugins/abatilo-core/skills/kubernetes/references/helm_reference.md": "# Helm Command Reference\n\nThis reference provides comprehensive details on Helm operations for managing Kubernetes applications through charts.\n\n## Overview\n\nHelm is the package manager for Kubernetes that helps you manage Kubernetes applications. Helm charts define, install, and upgrade even the most complex Kubernetes applications.\n\n**Key Concepts:**\n- **Chart** - A Helm package containing Kubernetes resource definitions\n- **Release** - An instance of a chart running in a Kubernetes cluster\n- **Repository** - A collection of charts that can be shared\n- **Values** - Configuration parameters for a chart\n\n## Installing Charts\n\n### Basic Installation\n\n**Syntax:**\n```bash\nhelm install <release-name> <chart> [flags]\n```\n\n**Common Options:**\n- `-f <values-file>` or `--values <values-file>` - Specify values file\n- `--set <key>=<value>` - Set values on command line\n- `-n <namespace>` or `--namespace <namespace>` - Target namespace\n- `--create-namespace` - Create namespace if it doesn't exist\n- `--wait` - Wait for resources to be ready\n- `--timeout <duration>` - Time to wait (default 5m)\n- `--dry-run` - Simulate installation\n- `--debug` - Enable verbose output\n- `--version <version>` - Specify chart version\n\n**Examples:**\n```bash\n# Install from repository\nhelm install my-release bitnami/nginx\n\n# Install with custom values file\nhelm install my-release bitnami/nginx -f values.yaml\n\n# Install with inline values\nhelm install my-release bitnami/nginx --set replicaCount=3\n\n# Install in specific namespace\nhelm install my-release bitnami/nginx -n production --create-namespace\n\n# Install and wait for readiness\nhelm install my-release bitnami/nginx --wait --timeout 10m\n\n# Dry run to preview\nhelm install my-release bitnami/nginx --dry-run --debug\n\n# Install specific version\nhelm install my-release bitnami/nginx --version 12.0.0\n\n# Install from local chart\nhelm install my-release ./my-chart\n\n# Install from URL\nhelm install my-release https://example.com/charts/mychart-1.0.0.tgz\n\n# Generate name automatically\nhelm install bitnami/nginx --generate-name\n```\n\n### Setting Values\n\n**Three Methods:**\n\n1. **Values File (`-f` or `--values`):**\n```bash\nhelm install my-release bitnami/nginx -f values.yaml -f values-prod.yaml\n```\nMultiple values files can be specified. Rightmost file takes precedence.\n\n2. **Command Line (`--set`):**\n```bash\nhelm install my-release bitnami/nginx --set replicaCount=3,service.type=LoadBalancer\n```\n\n3. **Set from File (`--set-file`):**\n```bash\nhelm install my-release bitnami/nginx --set-file config=config.json\n```\n\n**Priority Order (highest to lowest):**\n1. `--set` parameters\n2. `--set-file` parameters\n3. `-f` or `--values` files (rightmost wins)\n4. Chart's default `values.yaml`\n\n**Complex Value Examples:**\n```bash\n# Nested values\nhelm install my-release bitnami/nginx --set service.type=LoadBalancer\n\n# Array values\nhelm install my-release bitnami/nginx --set ingress.hosts[0]=example.com\n\n# Multiple values\nhelm install my-release bitnami/nginx \\\n  --set replicaCount=3 \\\n  --set image.tag=latest \\\n  --set service.type=ClusterIP\n```\n\n## Upgrading Releases\n\n### Basic Upgrade\n\n**Syntax:**\n```bash\nhelm upgrade <release-name> <chart> [flags]\n```\n\n**Common Options:**\n- `-f <values-file>` - Specify values file\n- `--set <key>=<value>` - Set values\n- `--reuse-values` - Reuse values from previous release\n- `--reset-values` - Reset values to chart defaults (when not using `--reuse-values`)\n- `--install` - Install if release doesn't exist (helm upgrade --install)\n- `--wait` - Wait for resources to be ready\n- `--atomic` - Rollback on failure\n- `--force` - Force resource updates\n- `--cleanup-on-fail` - Delete newly created resources on failure\n\n**Examples:**\n```bash\n# Upgrade to new chart version\nhelm upgrade my-release bitnami/nginx\n\n# Upgrade with new values\nhelm upgrade my-release bitnami/nginx -f values-v2.yaml\n\n# Upgrade or install if doesn't exist\nhelm upgrade my-release bitnami/nginx --install\n\n# Upgrade with inline values\nhelm upgrade my-release bitnami/nginx --set replicaCount=5\n\n# Reuse existing values\nhelm upgrade my-release bitnami/nginx --reuse-values\n\n# Atomic upgrade (rollback on failure)\nhelm upgrade my-release bitnami/nginx --atomic\n\n# Force upgrade (recreate resources)\nhelm upgrade my-release bitnami/nginx --force\n\n# Upgrade to specific version\nhelm upgrade my-release bitnami/nginx --version 13.0.0\n```\n\n### Upgrade Strategies\n\n**Standard Upgrade:**\n```bash\nhelm upgrade my-release bitnami/nginx -f new-values.yaml\n```\nNew values override all previous values unless `--reuse-values` is used.\n\n**Incremental Upgrade:**\n```bash\nhelm upgrade my-release bitnami/nginx --reuse-values --set newFeature.enabled=true\n```\nKeeps existing values and only updates specified ones.\n\n**Safe Upgrade:**\n```bash\nhelm upgrade my-release bitnami/nginx -f values.yaml --atomic --wait --timeout 5m\n```\nAutomatically rolls back if upgrade fails or times out.\n\n## Managing Releases\n\n### Listing Releases\n\n**Syntax:**\n```bash\nhelm list [flags]\n```\n\n**Common Options:**\n- `-n <namespace>` - List releases in specific namespace\n- `-A` or `--all-namespaces` - List releases across all namespaces\n- `-a` or `--all` - Show all releases (including failed/deleted)\n- `--deployed` - Show deployed releases only\n- `--failed` - Show failed releases only\n- `--pending` - Show pending releases\n- `-o json|yaml|table` - Output format\n\n**Examples:**\n```bash\n# List releases in current namespace\nhelm list\n\n# List releases in specific namespace\nhelm list -n production\n\n# List all releases in all namespaces\nhelm list --all-namespaces\n\n# List including failed/uninstalled\nhelm list --all\n\n# JSON output\nhelm list -o json\n\n# Filter by status\nhelm list --deployed\nhelm list --failed\n```\n\n### Viewing Release Status\n\n**Show Release Status:**\n```bash\nhelm status <release-name> [-n <namespace>]\n```\n\n**Show Release Values:**\n```bash\nhelm get values <release-name> [-n <namespace>]\n```\n\n**Show All Release Information:**\n```bash\nhelm get all <release-name> [-n <namespace>]\n```\n\n**Show Release Manifest:**\n```bash\nhelm get manifest <release-name> [-n <namespace>]\n```\n\n**Show Release Notes:**\n```bash\nhelm get notes <release-name> [-n <namespace>]\n```\n\n**Examples:**\n```bash\n# Check release status\nhelm status my-release\n\n# Get current values\nhelm get values my-release\n\n# Get values with defaults\nhelm get values my-release --all\n\n# Get manifests\nhelm get manifest my-release\n\n# Get everything\nhelm get all my-release\n\n# Output as YAML\nhelm get values my-release -o yaml\n```\n\n### Uninstalling Releases\n\n**Syntax:**\n```bash\nhelm uninstall <release-name> [flags]\n```\n\n**Common Options:**\n- `-n <namespace>` - Namespace of release\n- `--keep-history` - Keep release history\n- `--dry-run` - Simulate uninstall\n- `--wait` - Wait for deletion to complete\n\n**Examples:**\n```bash\n# Uninstall release\nhelm uninstall my-release\n\n# Uninstall from specific namespace\nhelm uninstall my-release -n production\n\n# Keep history for rollback\nhelm uninstall my-release --keep-history\n\n# Dry run\nhelm uninstall my-release --dry-run\n```\n\n## Rollback\n\n### Rolling Back Releases\n\n**Syntax:**\n```bash\nhelm rollback <release-name> [revision] [flags]\n```\n\n**Common Options:**\n- `--wait` - Wait for rollback to complete\n- `--cleanup-on-fail` - Clean up new resources on failure\n- `--force` - Force resource updates\n- `--recreate-pods` - Recreate pods for deployment rollback\n\n**Examples:**\n```bash\n# Rollback to previous version\nhelm rollback my-release\n\n# Rollback to specific revision\nhelm rollback my-release 3\n\n# Rollback with wait\nhelm rollback my-release --wait\n\n# Force rollback\nhelm rollback my-release --force\n```\n\n### Viewing Rollback History\n\n**Syntax:**\n```bash\nhelm history <release-name> [flags]\n```\n\n**Examples:**\n```bash\n# View release history\nhelm history my-release\n\n# View history with output\nhelm history my-release -o yaml\n\n# Limit history entries\nhelm history my-release --max 10\n```\n\n## Repository Management\n\n### Adding Repositories\n\n**Syntax:**\n```bash\nhelm repo add <name> <url> [flags]\n```\n\n**Examples:**\n```bash\n# Add Bitnami repository\nhelm repo add bitnami https://charts.bitnami.com/bitnami\n\n# Add with authentication\nhelm repo add private https://charts.example.com --username user --password pass\n\n# Add with TLS certificate\nhelm repo add secure https://charts.example.com --ca-file ca.crt --cert-file cert.crt --key-file key.key\n```\n\n### Managing Repositories\n\n**List Repositories:**\n```bash\nhelm repo list\n```\n\n**Update Repositories:**\n```bash\nhelm repo update\n```\n\n**Remove Repository:**\n```bash\nhelm repo remove <name>\n```\n\n**Examples:**\n```bash\n# List all repositories\nhelm repo list\n\n# Update all repositories\nhelm repo update\n\n# Update specific repository\nhelm repo update bitnami\n\n# Remove repository\nhelm repo remove bitnami\n```\n\n### Searching Charts\n\n**Search in Repositories:**\n```bash\nhelm search repo <keyword> [flags]\n```\n\n**Search Helm Hub:**\n```bash\nhelm search hub <keyword> [flags]\n```\n\n**Options:**\n- `--versions` - Show all versions\n- `--version <constraint>` - Show versions matching constraint\n- `-l` - Show long output\n\n**Examples:**\n```bash\n# Search in configured repositories\nhelm search repo nginx\n\n# Show all versions\nhelm search repo nginx --versions\n\n# Search Helm Hub\nhelm search hub nginx\n\n# Filter by version\nhelm search repo nginx --version \"^1.0.0\"\n```\n\n## Chart Development & Inspection\n\n### Inspecting Charts\n\n**Show Chart Details:**\n```bash\nhelm show chart <chart>\n```\n\n**Show Chart Values:**\n```bash\nhelm show values <chart>\n```\n\n**Show Chart README:**\n```bash\nhelm show readme <chart>\n```\n\n**Show Everything:**\n```bash\nhelm show all <chart>\n```\n\n**Examples:**\n```bash\n# Show chart metadata\nhelm show chart bitnami/nginx\n\n# Show default values\nhelm show values bitnami/nginx\n\n# Show README\nhelm show readme bitnami/nginx\n\n# Show all info\nhelm show all bitnami/nginx\n\n# Show specific version\nhelm show values bitnami/nginx --version 12.0.0\n```\n\n### Pulling Charts\n\n**Syntax:**\n```bash\nhelm pull <chart> [flags]\n```\n\n**Common Options:**\n- `--untar` - Untar the chart after download\n- `--version <version>` - Specify version\n- `-d <destination>` - Destination directory\n\n**Examples:**\n```bash\n# Pull chart\nhelm pull bitnami/nginx\n\n# Pull and untar\nhelm pull bitnami/nginx --untar\n\n# Pull specific version\nhelm pull bitnami/nginx --version 12.0.0\n\n# Pull to directory\nhelm pull bitnami/nginx -d ./charts\n```\n\n### Creating Charts\n\n**Create New Chart:**\n```bash\nhelm create <chart-name>\n```\n\n**Lint Chart:**\n```bash\nhelm lint <chart-path>\n```\n\n**Package Chart:**\n```bash\nhelm package <chart-path>\n```\n\n**Examples:**\n```bash\n# Create new chart scaffold\nhelm create mychart\n\n# Lint chart for issues\nhelm lint ./mychart\n\n# Package chart\nhelm package ./mychart\n\n# Package with version\nhelm package ./mychart --version 1.0.0\n```\n\n### Template Rendering\n\n**Render Templates Locally:**\n```bash\nhelm template <release-name> <chart> [flags]\n```\n\n**Common Options:**\n- `-f <values-file>` - Values file\n- `--set <key>=<value>` - Set values\n- `-s <template>` - Only show specific template\n- `--debug` - Enable debug output\n- `--validate` - Validate against Kubernetes\n\n**Examples:**\n```bash\n# Render templates\nhelm template my-release bitnami/nginx\n\n# Render with values\nhelm template my-release bitnami/nginx -f values.yaml\n\n# Render specific template\nhelm template my-release bitnami/nginx -s templates/deployment.yaml\n\n# Debug template rendering\nhelm template my-release bitnami/nginx --debug\n\n# Validate against cluster\nhelm template my-release bitnami/nginx --validate\n```\n\n## Advanced Operations\n\n### Testing Releases\n\n**Run Chart Tests:**\n```bash\nhelm test <release-name> [flags]\n```\n\nChart tests are pods with special annotations that run tests against the release.\n\n**Examples:**\n```bash\n# Run tests\nhelm test my-release\n\n# Show test logs\nhelm test my-release --logs\n```\n\n### Dependency Management\n\n**Update Chart Dependencies:**\n```bash\nhelm dependency update <chart-path>\n```\n\n**Build Dependency Lock:**\n```bash\nhelm dependency build <chart-path>\n```\n\n**List Dependencies:**\n```bash\nhelm dependency list <chart-path>\n```\n\n### Plugin Management\n\n**List Plugins:**\n```bash\nhelm plugin list\n```\n\n**Install Plugin:**\n```bash\nhelm plugin install <url>\n```\n\n**Uninstall Plugin:**\n```bash\nhelm plugin uninstall <plugin-name>\n```\n\n**Update Plugin:**\n```bash\nhelm plugin update <plugin-name>\n```\n\n## Helm with Kustomize\n\nWhile Helm and Kustomize serve different purposes, they can be used together:\n\n**Post-Rendering with Kustomize:**\n```bash\nhelm install my-release bitnami/nginx --post-renderer kustomize\n```\n\nThis allows Kustomize to modify Helm-generated manifests before applying them.\n\n## Common Patterns\n\n### Install or Upgrade Pattern\n\n```bash\nhelm upgrade my-release bitnami/nginx --install --wait --atomic\n```\n\nThis pattern:\n- Installs if release doesn't exist\n- Upgrades if it exists\n- Waits for resources to be ready\n- Rolls back automatically on failure\n\n### Blue-Green Deployment Pattern\n\n```bash\n# Install new version (green)\nhelm install my-release-green bitnami/nginx --set service.name=nginx-green\n\n# Test...\n\n# Switch traffic by updating service\nkubectl patch service nginx -p '{\"spec\":{\"selector\":{\"app\":\"nginx-green\"}}}'\n\n# Remove old version (blue)\nhelm uninstall my-release-blue\n```\n\n### Values Override Pattern\n\n```bash\n# Base values\nhelm upgrade my-release bitnami/nginx \\\n  -f values-base.yaml \\\n  -f values-environment.yaml \\\n  -f values-custom.yaml \\\n  --set image.tag=v2.0.0\n```\n\nPriority: `--set` > `values-custom.yaml` > `values-environment.yaml` > `values-base.yaml`\n\n## Troubleshooting\n\n### Debug Installation Issues\n\n```bash\n# Dry run with debug\nhelm install my-release bitnami/nginx --dry-run --debug\n\n# Template with debug\nhelm template my-release bitnami/nginx --debug\n\n# Check release status\nhelm status my-release\n\n# View release history\nhelm history my-release\n```\n\n### Common Issues\n\n**Issue: Release not found**\n```bash\n# List all releases including failed\nhelm list --all\n\n# Check in other namespaces\nhelm list --all-namespaces\n```\n\n**Issue: Values not applying**\n```bash\n# Check what values are set\nhelm get values my-release\n\n# Check with defaults\nhelm get values my-release --all\n\n# Re-render templates to debug\nhelm template my-release bitnami/nginx -f values.yaml --debug\n```\n\n**Issue: Upgrade stuck**\n```bash\n# Check release status\nhelm status my-release\n\n# Check pods\nkubectl get pods -l app.kubernetes.io/instance=my-release\n\n# Rollback if needed\nhelm rollback my-release\n```\n\n**Issue: Cannot delete release**\n```bash\n# Force delete\nhelm uninstall my-release --no-hooks\n\n# If still stuck, manually delete release secret\nkubectl delete secret -l owner=helm,name=my-release\n```\n",
        "plugins/abatilo-core/skills/kubernetes/references/kubectl_reference.md": "# kubectl Command Reference\n\nThis reference provides comprehensive details on kubectl operations for managing Kubernetes resources.\n\n## Resource Management\n\n### Getting Resources\n\nUse `kubectl get` to list and retrieve resources.\n\n**Syntax:**\n```bash\nkubectl get <resource-type> [name] [flags]\n```\n\n**Common Options:**\n- `-o json|yaml|wide|name|custom-columns` - Output format\n- `-l <label-selector>` - Filter by labels (e.g., `-l app=nginx,env=prod`)\n- `--field-selector` - Filter by fields (e.g., `--field-selector status.phase=Running`)\n- `-n <namespace>` - Specify namespace\n- `--all-namespaces` or `-A` - Query across all namespaces\n- `-w` or `--watch` - Watch for changes in real-time\n- `--sort-by=<jsonpath>` - Sort output (e.g., `--sort-by=.metadata.creationTimestamp`)\n\n**Common Resource Types:**\n- `pods` (po) - Running containers\n- `deployments` (deploy) - Deployment controllers\n- `services` (svc) - Service endpoints\n- `configmaps` (cm) - Configuration data\n- `secrets` - Sensitive data\n- `nodes` - Cluster nodes\n- `namespaces` (ns) - Namespace isolation\n- `ingresses` (ing) - Ingress rules\n- `persistentvolumes` (pv) - Storage volumes\n- `persistentvolumeclaims` (pvc) - Storage claims\n- `statefulsets` (sts) - Stateful applications\n- `daemonsets` (ds) - Node-level pods\n- `jobs` - Batch jobs\n- `cronjobs` (cj) - Scheduled jobs\n- `events` - Cluster events\n\n**Examples:**\n```bash\n# List all pods in current namespace\nkubectl get pods\n\n# List pods with additional details\nkubectl get pods -o wide\n\n# Get pod in JSON format\nkubectl get pod nginx-pod -o json\n\n# Get pods across all namespaces\nkubectl get pods --all-namespaces\n\n# Filter pods by label\nkubectl get pods -l app=nginx\n\n# Watch pods in real-time\nkubectl get pods -w\n\n# Get pods sorted by creation time\nkubectl get pods --sort-by=.metadata.creationTimestamp\n```\n\n### Describing Resources\n\nUse `kubectl describe` to get detailed information about resources, including events and conditions.\n\n**Syntax:**\n```bash\nkubectl describe <resource-type> <name> [-n <namespace>]\n```\n\n**What It Shows:**\n- Resource metadata (name, labels, annotations)\n- Spec configuration\n- Current status and conditions\n- Recent events related to the resource\n- Related resources (e.g., pods for a deployment)\n\n**Examples:**\n```bash\n# Describe a specific pod\nkubectl describe pod nginx-pod\n\n# Describe a deployment\nkubectl describe deployment web-app\n\n# Describe with namespace\nkubectl describe service api-service -n production\n\n# Describe all pods with label\nkubectl describe pods -l app=nginx\n```\n\n### Creating Resources\n\n**Declarative Approach (Recommended):**\n```bash\nkubectl apply -f <filename|directory|url>\n```\n\nThe `apply` command:\n- Creates resources if they don't exist\n- Updates resources if they already exist\n- Preserves fields managed by other processes\n- Tracks configuration for future updates\n\n**Examples:**\n```bash\n# Apply a single file\nkubectl apply -f deployment.yaml\n\n# Apply all files in a directory\nkubectl apply -f manifests/\n\n# Apply from URL\nkubectl apply -f https://example.com/manifest.yaml\n\n# Apply with validation\nkubectl apply -f deployment.yaml --dry-run=client\nkubectl apply -f deployment.yaml --dry-run=server\n```\n\n**Imperative Approach:**\n```bash\nkubectl create -f <filename>\n```\n\nThe `create` command:\n- Only creates new resources\n- Fails if resource already exists\n- Useful for one-time operations\n\n**Direct Resource Creation:**\n```bash\n# Create namespace\nkubectl create namespace development\n\n# Create configmap from literal values\nkubectl create configmap app-config --from-literal=key1=value1 --from-literal=key2=value2\n\n# Create configmap from file\nkubectl create configmap app-config --from-file=config.properties\n\n# Create secret from literal values\nkubectl create secret generic db-secret --from-literal=password=mypassword\n\n# Create deployment\nkubectl create deployment nginx --image=nginx:latest --replicas=3\n\n# Create service\nkubectl create service clusterip my-service --tcp=80:8080\n```\n\n### Updating Resources\n\n**Declarative Updates:**\n```bash\nkubectl apply -f <filename>\n```\nModify the YAML file and reapply. Kubernetes will compute and apply the diff.\n\n**Patch Updates:**\n```bash\nkubectl patch <resource-type> <name> -p '<patch-data>'\n```\n\n**Patch Types:**\n- Strategic merge patch (default) - Kubernetes-native merging\n- JSON merge patch (`--type=merge`) - RFC 7386 merge\n- JSON patch (`--type=json`) - RFC 6902 operations\n\n**Examples:**\n```bash\n# Strategic merge patch\nkubectl patch deployment nginx -p '{\"spec\":{\"replicas\":5}}'\n\n# JSON merge patch\nkubectl patch deployment nginx --type=merge -p '{\"spec\":{\"replicas\":5}}'\n\n# JSON patch\nkubectl patch deployment nginx --type=json -p '[{\"op\":\"replace\",\"path\":\"/spec/replicas\",\"value\":5}]'\n\n# Update image\nkubectl set image deployment/nginx nginx=nginx:1.21\n\n# Update environment variable\nkubectl set env deployment/nginx APP_ENV=production\n```\n\n**Interactive Editing (use sparingly):**\n```bash\nkubectl edit <resource-type> <name>\n```\nOpens resource in default editor. Save and close to apply changes.\n\n### Deleting Resources\n\n**Syntax:**\n```bash\nkubectl delete <resource-type> <name> [flags]\n```\n\n**Common Options:**\n- `--grace-period=<seconds>` - Time before force deletion\n- `--force` - Force deletion immediately\n- `--cascade=<background|foreground|orphan>` - Cascading deletion behavior\n- `-l <label-selector>` - Delete by label\n- `--all` - Delete all resources of a type\n\n**Examples:**\n```bash\n# Delete specific pod\nkubectl delete pod nginx-pod\n\n# Delete from file\nkubectl delete -f deployment.yaml\n\n# Delete by label\nkubectl delete pods -l app=nginx\n\n# Delete all pods in namespace\nkubectl delete pods --all\n\n# Force delete stuck pod\nkubectl delete pod nginx-pod --grace-period=0 --force\n\n# Delete namespace (deletes all resources in it)\nkubectl delete namespace development\n```\n\n## Application Debugging\n\n### Viewing Logs\n\n**Syntax:**\n```bash\nkubectl logs <pod-name> [flags]\n```\n\n**Common Options:**\n- `-f` or `--follow` - Stream logs in real-time\n- `-c <container-name>` - Specify container in multi-container pod\n- `--previous` - Show logs from previous container (for crashed containers)\n- `--since=<duration>` - Show logs since relative time (e.g., `5m`, `1h`)\n- `--since-time=<timestamp>` - Show logs since absolute time\n- `--tail=<lines>` - Show last N lines\n- `--timestamps` - Include timestamps\n- `-l <label-selector>` - Get logs from all pods matching label\n\n**Examples:**\n```bash\n# View pod logs\nkubectl logs nginx-pod\n\n# Follow logs in real-time\nkubectl logs nginx-pod -f\n\n# Get logs from specific container\nkubectl logs nginx-pod -c nginx-container\n\n# Get logs from previous container instance\nkubectl logs nginx-pod --previous\n\n# Get last 100 lines\nkubectl logs nginx-pod --tail=100\n\n# Get logs from last 5 minutes\nkubectl logs nginx-pod --since=5m\n\n# Get logs from all pods with label\nkubectl logs -l app=nginx\n\n# Get logs with timestamps\nkubectl logs nginx-pod --timestamps\n```\n\n### Executing Commands in Containers\n\n**Syntax:**\n```bash\nkubectl exec <pod-name> [flags] -- <command>\n```\n\n**Common Options:**\n- `-it` - Interactive terminal (for shells)\n- `-c <container-name>` - Specify container in multi-container pod\n\n**Examples:**\n```bash\n# Run single command\nkubectl exec nginx-pod -- ls /etc\n\n# Interactive shell\nkubectl exec -it nginx-pod -- /bin/bash\nkubectl exec -it nginx-pod -- /bin/sh\n\n# Specific container in multi-container pod\nkubectl exec -it nginx-pod -c sidecar -- /bin/sh\n\n# Run command with arguments\nkubectl exec nginx-pod -- cat /etc/nginx/nginx.conf\n\n# Check environment variables\nkubectl exec nginx-pod -- env\n```\n\n### Port Forwarding\n\n**Syntax:**\n```bash\nkubectl port-forward <resource>/<name> <local-port>:<remote-port>\n```\n\n**Resource Types:**\n- `pod/<name>`\n- `deployment/<name>`\n- `service/<name>`\n\n**Examples:**\n```bash\n# Forward to pod\nkubectl port-forward pod/nginx-pod 8080:80\n\n# Forward to deployment\nkubectl port-forward deployment/nginx 8080:80\n\n# Forward to service\nkubectl port-forward service/nginx-service 8080:80\n\n# Forward multiple ports\nkubectl port-forward pod/nginx-pod 8080:80 8443:443\n\n# Forward to random local port\nkubectl port-forward pod/nginx-pod :80\n```\n\n## Deployment Management\n\n### Scaling\n\n**Syntax:**\n```bash\nkubectl scale <resource-type>/<name> --replicas=<count>\n```\n\n**Supported Resources:**\n- deployments\n- replicasets\n- statefulsets\n- replicationcontrollers\n\n**Examples:**\n```bash\n# Scale deployment\nkubectl scale deployment/nginx --replicas=5\n\n# Scale statefulset\nkubectl scale statefulset/postgres --replicas=3\n\n# Conditional scaling (only if current replicas match)\nkubectl scale deployment/nginx --current-replicas=3 --replicas=5\n```\n\n### Rollout Management\n\n**Check Rollout Status:**\n```bash\nkubectl rollout status <resource-type>/<name>\n```\n\n**View Rollout History:**\n```bash\nkubectl rollout history <resource-type>/<name>\nkubectl rollout history <resource-type>/<name> --revision=<number>\n```\n\n**Undo Rollout (Rollback):**\n```bash\nkubectl rollout undo <resource-type>/<name>\nkubectl rollout undo <resource-type>/<name> --to-revision=<number>\n```\n\n**Restart Rollout:**\n```bash\nkubectl rollout restart <resource-type>/<name>\n```\n\n**Pause/Resume Rollout:**\n```bash\nkubectl rollout pause <resource-type>/<name>\nkubectl rollout resume <resource-type>/<name>\n```\n\n**Examples:**\n```bash\n# Check deployment rollout status\nkubectl rollout status deployment/nginx\n\n# View rollout history\nkubectl rollout history deployment/nginx\n\n# View specific revision\nkubectl rollout history deployment/nginx --revision=2\n\n# Rollback to previous version\nkubectl rollout undo deployment/nginx\n\n# Rollback to specific revision\nkubectl rollout undo deployment/nginx --to-revision=3\n\n# Restart deployment (recreate pods)\nkubectl rollout restart deployment/nginx\n\n# Pause rollout for canary deployment\nkubectl rollout pause deployment/nginx\n# ...make changes, test...\nkubectl rollout resume deployment/nginx\n```\n\n## Context and Namespace Management\n\n### Managing Contexts\n\n**List Contexts:**\n```bash\nkubectl config get-contexts\n```\n\n**Show Current Context:**\n```bash\nkubectl config current-context\n```\n\n**Switch Context:**\n```bash\nkubectl config use-context <context-name>\n```\n\n**Set Default Namespace for Context:**\n```bash\nkubectl config set-context --current --namespace=<namespace>\n```\n\n**Examples:**\n```bash\n# List all contexts\nkubectl config get-contexts\n\n# Show current context\nkubectl config current-context\n\n# Switch to different context\nkubectl config use-context production-cluster\n\n# Set default namespace for current context\nkubectl config set-context --current --namespace=development\n```\n\n### Managing Namespaces\n\n**Create Namespace:**\n```bash\nkubectl create namespace <name>\n```\n\n**Delete Namespace:**\n```bash\nkubectl delete namespace <name>\n```\n\n**Set Default Namespace:**\n```bash\nkubectl config set-context --current --namespace=<namespace>\n```\n\n## Resource Introspection\n\n### API Resources\n\n**List All Resource Types:**\n```bash\nkubectl api-resources\n```\n\n**Common Options:**\n- `--namespaced=true|false` - Filter by namespace scope\n- `--api-group=<group>` - Filter by API group\n- `--verbs=<verb1,verb2>` - Filter by supported verbs\n- `-o wide|name` - Output format\n\n**Examples:**\n```bash\n# List all resources\nkubectl api-resources\n\n# List only namespaced resources\nkubectl api-resources --namespaced=true\n\n# List resources that support 'list' verb\nkubectl api-resources --verbs=list\n\n# Short names\nkubectl api-resources -o wide\n```\n\n### Explain Resource Fields\n\n**Syntax:**\n```bash\nkubectl explain <resource>[.<field>[.<subfield>]]\n```\n\n**Options:**\n- `--recursive` - Show all fields recursively\n\n**Examples:**\n```bash\n# Explain pod resource\nkubectl explain pod\n\n# Explain pod spec\nkubectl explain pod.spec\n\n# Explain container specification\nkubectl explain pod.spec.containers\n\n# Recursive explanation\nkubectl explain pod.spec --recursive\n\n# Explain deployment\nkubectl explain deployment.spec.template.spec.containers\n```\n\n## Advanced Operations\n\n### Waiting for Conditions\n\n**Syntax:**\n```bash\nkubectl wait --for=<condition> <resource-type>/<name>\n```\n\n**Examples:**\n```bash\n# Wait for pod to be ready\nkubectl wait --for=condition=ready pod/nginx-pod\n\n# Wait for pod to be deleted\nkubectl wait --for=delete pod/nginx-pod\n\n# Wait with timeout\nkubectl wait --for=condition=ready pod/nginx-pod --timeout=60s\n```\n\n### Diff Before Apply\n\n**Preview Changes:**\n```bash\nkubectl diff -f <filename>\n```\n\nShows what would change if you applied the file.\n\n### Label and Annotation Management\n\n**Add/Update Label:**\n```bash\nkubectl label <resource-type> <name> <key>=<value>\n```\n\n**Remove Label:**\n```bash\nkubectl label <resource-type> <name> <key>-\n```\n\n**Add/Update Annotation:**\n```bash\nkubectl annotate <resource-type> <name> <key>=<value>\n```\n\n**Examples:**\n```bash\n# Add label\nkubectl label pod nginx-pod env=production\n\n# Update label (requires --overwrite)\nkubectl label pod nginx-pod env=staging --overwrite\n\n# Remove label\nkubectl label pod nginx-pod env-\n\n# Add annotation\nkubectl annotate pod nginx-pod description=\"Main web server\"\n```\n\n## Output Formats\n\nKubectl supports multiple output formats via the `-o` or `--output` flag:\n\n- **`json`** - Full JSON output\n- **`yaml`** - YAML format\n- **`wide`** - Additional columns (more info)\n- **`name`** - Resource name only (e.g., `pod/nginx`)\n- **`jsonpath=<template>`** - Custom output using JSONPath expressions\n- **`jsonpath-file=<file>`** - JSONPath template from file\n- **`go-template=<template>`** - Go template output\n- **`go-template-file=<file>`** - Go template from file\n- **`custom-columns=<spec>`** - Define custom columns\n- **`custom-columns-file=<file>`** - Custom columns from file\n\n**Examples:**\n```bash\n# JSON output\nkubectl get pod nginx-pod -o json\n\n# YAML output\nkubectl get pod nginx-pod -o yaml\n\n# Wide output\nkubectl get pods -o wide\n\n# Name only\nkubectl get pods -o name\n\n# JSONPath - get pod IPs\nkubectl get pods -o jsonpath='{.items[*].status.podIP}'\n\n# JSONPath - custom format\nkubectl get pods -o jsonpath='{range .items[*]}{.metadata.name}{\"\\t\"}{.status.phase}{\"\\n\"}{end}'\n\n# Custom columns\nkubectl get pods -o custom-columns=NAME:.metadata.name,STATUS:.status.phase\n\n# Go template\nkubectl get pods -o go-template='{{range .items}}{{.metadata.name}}{{\"\\n\"}}{{end}}'\n```\n\n## Permissions and Authorization\n\n**Check Permissions:**\n```bash\nkubectl auth can-i <verb> <resource>\n```\n\n**Examples:**\n```bash\n# Check if I can create pods\nkubectl auth can-i create pods\n\n# Check if I can delete deployments\nkubectl auth can-i delete deployments\n\n# Check for specific user\nkubectl auth can-i get pods --as=john@example.com\n\n# List all permissions\nkubectl auth can-i --list\n```\n",
        "plugins/abatilo-core/skills/kubernetes/references/workflows.md": "# Common Kubernetes Workflows\n\nThis reference provides step-by-step workflows for common Kubernetes operations and troubleshooting scenarios.\n\n## Debugging Workflows\n\n### Debugging a Failing Pod\n\nWhen a pod is not starting or crashing, follow this systematic approach:\n\n**1. Check Pod Status**\n```bash\nkubectl get pods\nkubectl get pods -o wide  # Show node, IP, and more details\n```\n\nLook for status indicators:\n- `Pending` - Not scheduled yet (resource constraints, node selector issues)\n- `ContainerCreating` - Being created (image pull, volume mount issues)\n- `CrashLoopBackOff` - Container keeps crashing\n- `Error` - Container exited with error\n- `ImagePullBackOff` - Cannot pull container image\n- `ErrImagePull` - Image pull failed\n\n**2. Describe the Pod**\n```bash\nkubectl describe pod <pod-name>\n```\n\nLook for:\n- Events at the bottom (most recent issues)\n- Container states and reasons\n- Resource requests/limits\n- Volume mount issues\n- Image pull errors\n\n**3. Check Container Logs**\n```bash\n# Current container logs\nkubectl logs <pod-name>\n\n# Previous container logs (if crashed)\nkubectl logs <pod-name> --previous\n\n# Specific container in multi-container pod\nkubectl logs <pod-name> -c <container-name>\n\n# Follow logs in real-time\nkubectl logs <pod-name> -f\n```\n\n**4. Check Events**\n```bash\nkubectl get events --sort-by='.lastTimestamp'\nkubectl get events --field-selector involvedObject.name=<pod-name>\n```\n\n**5. Exec into Pod (if running)**\n```bash\nkubectl exec -it <pod-name> -- /bin/sh\n# or\nkubectl exec -it <pod-name> -- /bin/bash\n\n# Check processes\nps aux\n\n# Check disk usage\ndf -h\n\n# Check environment variables\nenv\n\n# Check network connectivity\nping google.com\ncurl http://service-name\n```\n\n**6. Common Issues and Solutions**\n\n**Image Pull Issues:**\n```bash\n# Check image name and tag\nkubectl describe pod <pod-name> | grep Image\n\n# Verify image exists\ndocker pull <image-name>\n\n# Check image pull secrets\nkubectl get secrets\nkubectl describe pod <pod-name> | grep -A 5 \"Image Pull Secrets\"\n```\n\n**Resource Issues:**\n```bash\n# Check node resources\nkubectl top nodes\nkubectl describe node <node-name>\n\n# Check pod resource requests\nkubectl describe pod <pod-name> | grep -A 5 \"Requests\"\n```\n\n**Configuration Issues:**\n```bash\n# Check ConfigMap exists\nkubectl get configmap <name>\n\n# Check Secret exists\nkubectl get secret <name>\n\n# Verify volume mounts\nkubectl describe pod <pod-name> | grep -A 10 \"Mounts\"\n```\n\n### Debugging Service Connectivity\n\nWhen services are not accessible:\n\n**1. Verify Service Exists**\n```bash\nkubectl get services\nkubectl describe service <service-name>\n```\n\nCheck:\n- Service type (ClusterIP, NodePort, LoadBalancer)\n- Selector matches pod labels\n- Port and targetPort configuration\n- Endpoints are populated\n\n**2. Check Endpoints**\n```bash\nkubectl get endpoints <service-name>\n```\n\nIf endpoints are empty, selector doesn't match any pods.\n\n**3. Verify Pod Labels**\n```bash\nkubectl get pods --show-labels\nkubectl get pods -l app=<label-value>\n```\n\n**4. Test Connectivity**\n```bash\n# From another pod\nkubectl run test-pod --rm -it --image=busybox -- /bin/sh\nwget -O- http://<service-name>:<port>\nnslookup <service-name>\n\n# Port forward to test locally\nkubectl port-forward service/<service-name> 8080:80\ncurl http://localhost:8080\n```\n\n**5. Check Network Policies**\n```bash\nkubectl get networkpolicies\nkubectl describe networkpolicy <policy-name>\n```\n\n**6. Check DNS**\n```bash\n# Test DNS resolution\nkubectl run test-dns --rm -it --image=busybox -- nslookup <service-name>\n\n# Check CoreDNS pods\nkubectl get pods -n kube-system -l k8s-app=kube-dns\n\n# Check CoreDNS logs\nkubectl logs -n kube-system -l k8s-app=kube-dns\n```\n\n### Debugging Performance Issues\n\n**1. Check Resource Usage**\n```bash\n# Node metrics\nkubectl top nodes\n\n# Pod metrics\nkubectl top pods\nkubectl top pods --namespace=<namespace>\n\n# Specific pod containers\nkubectl top pod <pod-name> --containers\n```\n\n**2. Check Resource Limits**\n```bash\nkubectl describe pod <pod-name> | grep -A 5 \"Limits\"\nkubectl describe pod <pod-name> | grep -A 5 \"Requests\"\n```\n\n**3. Check for OOMKilled**\n```bash\nkubectl get pods | grep OOMKilled\nkubectl describe pod <pod-name> | grep -i \"OOM\"\n```\n\n**4. Check Node Conditions**\n```bash\nkubectl describe node <node-name> | grep -A 10 \"Conditions\"\n```\n\nLook for:\n- MemoryPressure\n- DiskPressure\n- PIDPressure\n\n**5. Analyze Application Metrics**\n```bash\n# Get logs with timestamps\nkubectl logs <pod-name> --timestamps\n\n# Check application-specific metrics\nkubectl port-forward <pod-name> 9090:9090\n# Access metrics endpoint locally\ncurl http://localhost:9090/metrics\n```\n\n## Deployment Workflows\n\n### Deploying an Application\n\n**1. Prepare Manifests**\n\nCreate deployment.yaml:\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp\n  labels:\n    app: myapp\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    metadata:\n      labels:\n        app: myapp\n    spec:\n      containers:\n      - name: myapp\n        image: myapp:v1.0.0\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            memory: \"128Mi\"\n            cpu: \"100m\"\n          limits:\n            memory: \"256Mi\"\n            cpu: \"200m\"\n```\n\nCreate service.yaml:\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-service\nspec:\n  selector:\n    app: myapp\n  ports:\n  - port: 80\n    targetPort: 8080\n  type: ClusterIP\n```\n\n**2. Validate Manifests**\n```bash\n# Client-side validation\nkubectl apply -f deployment.yaml --dry-run=client\n\n# Server-side validation\nkubectl apply -f deployment.yaml --dry-run=server\n```\n\n**3. Apply Manifests**\n```bash\n# Apply all files in directory\nkubectl apply -f manifests/\n\n# Apply specific files\nkubectl apply -f deployment.yaml\nkubectl apply -f service.yaml\n```\n\n**4. Monitor Deployment**\n```bash\n# Watch rollout status\nkubectl rollout status deployment/myapp\n\n# Watch pods\nkubectl get pods -l app=myapp -w\n\n# Check events\nkubectl get events --sort-by='.lastTimestamp'\n```\n\n**5. Verify Application**\n```bash\n# Check pods are running\nkubectl get pods -l app=myapp\n\n# Check service endpoints\nkubectl get endpoints myapp-service\n\n# Test connectivity\nkubectl port-forward service/myapp-service 8080:80\ncurl http://localhost:8080\n```\n\n**6. View Logs**\n```bash\n# All pods with label\nkubectl logs -l app=myapp\n\n# Follow logs\nkubectl logs -l app=myapp -f\n\n# Specific pod\nkubectl logs <pod-name>\n```\n\n### Updating a Deployment\n\n**1. Update Image**\n```bash\n# Using kubectl set\nkubectl set image deployment/myapp myapp=myapp:v2.0.0\n\n# Or update YAML and apply\nkubectl apply -f deployment.yaml\n```\n\n**2. Monitor Rollout**\n```bash\n# Watch rollout status\nkubectl rollout status deployment/myapp\n\n# Watch pods during rollout\nkubectl get pods -l app=myapp -w\n\n# Check rollout history\nkubectl rollout history deployment/myapp\n```\n\n**3. Verify New Version**\n```bash\n# Check image version\nkubectl get deployment myapp -o jsonpath='{.spec.template.spec.containers[0].image}'\n\n# Test application\nkubectl port-forward deployment/myapp 8080:8080\ncurl http://localhost:8080/version\n```\n\n**4. Rollback if Needed**\n```bash\n# Rollback to previous version\nkubectl rollout undo deployment/myapp\n\n# Rollback to specific revision\nkubectl rollout history deployment/myapp\nkubectl rollout undo deployment/myapp --to-revision=3\n```\n\n### Scaling Applications\n\n**Manual Scaling:**\n```bash\n# Scale deployment\nkubectl scale deployment/myapp --replicas=5\n\n# Verify scaling\nkubectl get deployment myapp\nkubectl get pods -l app=myapp\n```\n\n**Autoscaling (HPA):**\n```bash\n# Create horizontal pod autoscaler\nkubectl autoscale deployment myapp --min=2 --max=10 --cpu-percent=80\n\n# Check HPA status\nkubectl get hpa\nkubectl describe hpa myapp\n\n# View HPA events\nkubectl get events --field-selector involvedObject.name=myapp\n```\n\n### Blue-Green Deployment\n\n**1. Deploy Green (New Version)**\n```bash\n# Create new deployment\nkubectl apply -f deployment-green.yaml\n\n# Wait for ready\nkubectl rollout status deployment/myapp-green\n\n# Verify\nkubectl get pods -l version=green\n```\n\n**2. Test Green Deployment**\n```bash\n# Create temporary service\nkubectl expose deployment myapp-green --name=myapp-test --type=ClusterIP\n\n# Test\nkubectl port-forward service/myapp-test 8080:80\ncurl http://localhost:8080\n\n# Delete test service\nkubectl delete service myapp-test\n```\n\n**3. Switch Traffic**\n```bash\n# Update service selector to point to green\nkubectl patch service myapp -p '{\"spec\":{\"selector\":{\"version\":\"green\"}}}'\n\n# Verify endpoints\nkubectl get endpoints myapp\n```\n\n**4. Monitor and Cleanup**\n```bash\n# Monitor new version\nkubectl logs -l version=green -f\n\n# If successful, delete blue\nkubectl delete deployment myapp-blue\n\n# If issues, rollback\nkubectl patch service myapp -p '{\"spec\":{\"selector\":{\"version\":\"blue\"}}}'\n```\n\n### Canary Deployment\n\n**1. Deploy Canary**\n```bash\n# Keep production at 9 replicas\nkubectl scale deployment/myapp-prod --replicas=9\n\n# Deploy canary with 1 replica (10% traffic)\nkubectl apply -f deployment-canary.yaml\nkubectl scale deployment/myapp-canary --replicas=1\n```\n\n**2. Monitor Canary**\n```bash\n# Watch canary pods\nkubectl get pods -l version=canary -w\n\n# Monitor canary logs\nkubectl logs -l version=canary -f\n\n# Check metrics/errors\nkubectl top pods -l version=canary\n```\n\n**3. Gradually Increase Traffic**\n```bash\n# Increase canary to 30% (3/10 pods)\nkubectl scale deployment/myapp-prod --replicas=7\nkubectl scale deployment/myapp-canary --replicas=3\n\n# Monitor...\n\n# Increase to 50%\nkubectl scale deployment/myapp-prod --replicas=5\nkubectl scale deployment/myapp-canary --replicas=5\n```\n\n**4. Complete Rollout or Rollback**\n```bash\n# If successful, full rollout\nkubectl scale deployment/myapp-prod --replicas=0\nkubectl scale deployment/myapp-canary --replicas=10\n# Or update prod deployment to new version\nkubectl set image deployment/myapp-prod myapp=myapp:v2.0.0\nkubectl delete deployment myapp-canary\n\n# If issues, rollback\nkubectl scale deployment/myapp-canary --replicas=0\nkubectl scale deployment/myapp-prod --replicas=10\n```\n\n## Configuration Management\n\n### Managing ConfigMaps\n\n**Creating ConfigMaps:**\n```bash\n# From literals\nkubectl create configmap app-config \\\n  --from-literal=key1=value1 \\\n  --from-literal=key2=value2\n\n# From file\nkubectl create configmap app-config --from-file=config.properties\n\n# From directory\nkubectl create configmap app-config --from-file=configs/\n\n# From YAML\nkubectl apply -f configmap.yaml\n```\n\n**Using ConfigMaps:**\n```yaml\n# As environment variables\nenv:\n- name: KEY1\n  valueFrom:\n    configMapKeyRef:\n      name: app-config\n      key: key1\n\n# As volume mount\nvolumes:\n- name: config\n  configMap:\n    name: app-config\n```\n\n**Updating ConfigMaps:**\n```bash\n# Edit directly\nkubectl edit configmap app-config\n\n# Replace from file\nkubectl create configmap app-config --from-file=config.properties --dry-run=client -o yaml | kubectl apply -f -\n\n# Restart pods to pick up changes\nkubectl rollout restart deployment/myapp\n```\n\n### Managing Secrets\n\n**Creating Secrets:**\n```bash\n# Generic secret\nkubectl create secret generic db-secret \\\n  --from-literal=username=admin \\\n  --from-literal=password=secret123\n\n# TLS secret\nkubectl create secret tls tls-secret \\\n  --cert=path/to/cert.crt \\\n  --key=path/to/key.key\n\n# Docker registry secret\nkubectl create secret docker-registry regcred \\\n  --docker-server=registry.example.com \\\n  --docker-username=user \\\n  --docker-password=pass \\\n  --docker-email=user@example.com\n\n# From file\nkubectl create secret generic ssh-secret --from-file=ssh-privatekey=~/.ssh/id_rsa\n```\n\n**Using Secrets:**\n```yaml\n# As environment variables\nenv:\n- name: DB_PASSWORD\n  valueFrom:\n    secretKeyRef:\n      name: db-secret\n      key: password\n\n# As volume\nvolumes:\n- name: secret\n  secret:\n    secretName: db-secret\n```\n\n### Environment-Specific Deployments\n\n**Using Kustomize:**\n\n**Base (base/kustomization.yaml):**\n```yaml\nresources:\n- deployment.yaml\n- service.yaml\n```\n\n**Overlay for Dev (overlays/dev/kustomization.yaml):**\n```yaml\nbases:\n- ../../base\nnamePrefix: dev-\nreplicas:\n- name: myapp\n  count: 1\n```\n\n**Overlay for Prod (overlays/prod/kustomization.yaml):**\n```yaml\nbases:\n- ../../base\nnamePrefix: prod-\nreplicas:\n- name: myapp\n  count: 5\n```\n\n**Deploy:**\n```bash\n# Dev\nkubectl apply -k overlays/dev/\n\n# Prod\nkubectl apply -k overlays/prod/\n```\n\n## Maintenance Workflows\n\n### Draining and Cordoning Nodes\n\n**Drain Node for Maintenance:**\n```bash\n# Cordon node (prevent new pods)\nkubectl cordon <node-name>\n\n# Drain node (evict pods gracefully)\nkubectl drain <node-name> --ignore-daemonsets --delete-emptydir-data\n\n# Perform maintenance...\n\n# Uncordon node\nkubectl uncordon <node-name>\n```\n\n### Backup and Restore\n\n**Backup Resources:**\n```bash\n# Backup all resources in namespace\nkubectl get all -n production -o yaml > backup-production.yaml\n\n# Backup specific resources\nkubectl get deployment,service,configmap -n production -o yaml > backup.yaml\n\n# Backup with labels\nkubectl get all -l app=myapp -o yaml > backup-myapp.yaml\n```\n\n**Restore Resources:**\n```bash\n# Restore from backup\nkubectl apply -f backup-production.yaml\n\n# Restore to different namespace\nkubectl apply -f backup-production.yaml -n staging\n```\n\n### Cluster Inspection\n\n**Check Cluster Health:**\n```bash\n# Node status\nkubectl get nodes\nkubectl describe nodes | grep -A 5 \"Conditions\"\n\n# Component status\nkubectl get componentstatuses\nkubectl get pods -n kube-system\n\n# API server health\nkubectl get --raw /healthz\nkubectl get --raw /readyz\n\n# Check critical pods\nkubectl get pods -n kube-system\n```\n\n**Resource Usage Overview:**\n```bash\n# Cluster-wide resource usage\nkubectl top nodes\n\n# All pods resource usage\nkubectl top pods --all-namespaces\n\n# Resources by namespace\nkubectl top pods -n production\n\n# Sort by CPU\nkubectl top pods --sort-by=cpu\n\n# Sort by memory\nkubectl top pods --sort-by=memory\n```\n\n### Cleaning Up Resources\n\n**Delete Resources by Label:**\n```bash\n# Delete all resources with label\nkubectl delete all -l app=myapp\n\n# Delete specific types with label\nkubectl delete deployment,service -l app=myapp\n```\n\n**Delete Old Resources:**\n```bash\n# Find old completed jobs\nkubectl get jobs --field-selector status.successful=1\n\n# Delete completed jobs\nkubectl delete jobs --field-selector status.successful=1\n\n# Delete failed pods\nkubectl delete pods --field-selector status.phase=Failed\n\n# Delete evicted pods\nkubectl get pods --all-namespaces --field-selector=status.phase==Failed -o json | kubectl delete -f -\n```\n\n**Force Delete Stuck Resources:**\n```bash\n# Force delete pod\nkubectl delete pod <pod-name> --grace-period=0 --force\n\n# Remove finalizers (last resort)\nkubectl patch pod <pod-name> -p '{\"metadata\":{\"finalizers\":[]}}' --type=merge\nkubectl delete pod <pod-name>\n```\n",
        "plugins/abatilo-core/skills/repo-explore/SKILL.md": "---\nname: repo-explore\ndescription: Clone and explore external GitHub repositories to understand how libraries, frameworks, or dependencies work. Use when user provides a GitHub URL (github.com/owner/repo), asks \"how does X library work\", wants to look at source code for a dependency, asks about implementation details of an external package, or says \"explore\", \"look at\", or \"check out\" a repository. Automatically checks out the matching version tag when the repo is a dependency in the current project.\ncontext: fork\nallowed-tools:\n  - Bash(git:*)\n  - Bash(ls:*)\n  - Read\n  - Glob\n  - Grep\n  - Task\n---\n\n# Repo Explore Skill\n\nExplore external GitHub repositories by cloning them locally and using the Explore agent for comprehensive codebase analysis.\n\n## Cache Location\n\n```\n~/.cache/claude/repos/<owner>/<repo>/\n```\n\n## Workflow\n\n### 1. Parse Repository URL\n\nExtract owner and repo from various formats:\n- `https://github.com/owner/repo`\n- `git@github.com:owner/repo.git`\n- `owner/repo` (shorthand)\n- `github.com/owner/repo`\n\n### 2. Check Cache\n\n```bash\nls ~/.cache/claude/repos/<owner>/<repo>/\n```\n\n- **If exists**: Check if update needed (see `references/update-reference.md`)\n- **If not exists**: Proceed to clone\n\n### 3. Clone Repository\n\n```bash\nmkdir -p ~/.cache/claude/repos/<owner>\ngit clone https://github.com/<owner>/<repo>.git ~/.cache/claude/repos/<owner>/<repo>\n```\n\n### 4. Version Detection (CRITICAL)\n\n**Before exploring, check if this repo is a dependency in the current working directory.**\n\nConsult `references/version-detection.md` for:\n- Which dependency files to check\n- How to extract versions from each format\n- How to map versions to git tags\n\nIf a matching version is found:\n```bash\ncd ~/.cache/claude/repos/<owner>/<repo>\ngit fetch --all --tags\ngit checkout <tag>\n```\n\nCommon tag formats to try:\n- `v1.2.3`\n- `1.2.3`\n- `release-1.2.3`\n- `release/1.2.3`\n\n### 5. Explore with Explore Agent\n\n**ALWAYS use the Task tool with `subagent_type=Explore` for answering questions about the repository.**\n\nDo NOT manually browse files when the Explore agent can do it. The Explore agent is optimized for:\n- Finding files by patterns\n- Searching code for keywords\n- Understanding codebase architecture\n- Answering questions about how code works\n\nExample:\n```\nTask(\n  subagent_type=\"Explore\",\n  prompt=\"\"\"In ~/.cache/claude/repos/owner/repo/, find how authentication is implemented.\n\nRequirements for your response:\n- Include code snippets with file paths and line numbers\n- Show key type definitions and function signatures\n- End with a 'Key Files for Further Exploration' table with columns: File, Purpose, Start Here If...\n\"\"\"\n)\n```\n\n### 6. Response Format Requirements\n\n**When answering questions about the repository, responses MUST include:**\n\n#### Code Snippets\n- Include relevant code snippets that directly support the answer\n- Show actual type definitions, function signatures, and key logic\n- Use proper syntax highlighting with language identifier\n- Include file path and line numbers for each snippet:\n  ```go\n  // File: pkg/controller/foo.go:42-58\n  func (r *Reconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) {\n      // ... relevant code\n  }\n  ```\n\n#### File Recommendations for Further Reading\nAt the end of every response, include a **\"Key Files for Further Exploration\"** section:\n\n```markdown\n## Key Files for Further Exploration\n\n| File | Purpose | Start Here If... |\n|------|---------|------------------|\n| `pkg/apis/v1/types.go` | Core type definitions | You want to understand the data model |\n| `pkg/controller/main_controller.go` | Main reconciliation logic | You want to understand the control flow |\n| `docs/design.md` | Architecture decisions | You want high-level understanding |\n```\n\n**Guidelines for file recommendations:**\n- Prioritize files by relevance to the question asked\n- Include 3-7 files (not too few, not overwhelming)\n- Add context on WHY each file is useful\n- Include \"Start Here If...\" guidance to help with future exploration\n- Order from most fundamental to most specific\n\n#### Response Structure Template\n```\n1. Brief answer summary (2-3 sentences)\n2. Detailed explanation with inline code snippets\n3. Architecture/flow diagrams if helpful (ASCII or description)\n4. Key Files for Further Exploration table\n5. Optional: Related topics the user might want to explore next\n```\n\n### 7. Updates\n\nFor refreshing the repository or switching versions, consult `references/update-reference.md`.\n\n## Important Notes\n\n- Always verify the checkout succeeded before exploring\n- If the user asks about a specific version, checkout that version even if not a dependency\n- For private repos, the clone will work if the user has git credentials configured\n- Large repos may take time to clone; inform the user\n",
        "plugins/abatilo-core/skills/repo-explore/references/update-reference.md": "# Update Reference\n\nInstructions for updating, refreshing, and managing cached repositories.\n\n## Repository Location\n\nAll cached repos are stored at:\n```\n~/.cache/claude/repos/<owner>/<repo>/\n```\n\n## Common Update Operations\n\n### Fetch Latest Changes (Without Switching)\n\nFetch all updates from remote without changing your current checkout:\n\n```bash\ncd ~/.cache/claude/repos/<owner>/<repo>\ngit fetch --all --tags --prune\n```\n\n- `--all`: Fetch from all remotes\n- `--tags`: Fetch all tags\n- `--prune`: Remove deleted remote branches\n\n### Update to Latest Default Branch\n\n```bash\ncd ~/.cache/claude/repos/<owner>/<repo>\n\n# Determine default branch\ngit remote show origin | grep \"HEAD branch\" | cut -d: -f2 | xargs\n\n# Checkout and pull (typically main or master)\ngit checkout main && git pull origin main\n# OR\ngit checkout master && git pull origin master\n```\n\n### Switch to a Specific Version/Tag\n\n```bash\ncd ~/.cache/claude/repos/<owner>/<repo>\ngit fetch --all --tags\ngit checkout <tag-name>\n```\n\nExample:\n```bash\ngit checkout v2.1.0\n```\n\n### Switch to a Specific Branch\n\n```bash\ncd ~/.cache/claude/repos/<owner>/<repo>\ngit fetch --all\ngit checkout <branch-name>\ngit pull origin <branch-name>\n```\n\n### Switch to a Specific Commit\n\n```bash\ncd ~/.cache/claude/repos/<owner>/<repo>\ngit checkout <commit-sha>\n```\n\n## When to Update\n\n### Update Required\n\n1. **Dependency version changed**: The current project updated its dependency\n   - Re-run version detection from `version-detection.md`\n   - Checkout the new matching tag\n\n2. **User requests latest**: User explicitly asks for current/latest code\n   - Fetch and checkout default branch\n\n3. **Investigating upstream fix**: Looking for a bug fix or feature\n   - Fetch latest, may need specific branch or tag\n\n4. **Stale cache**: Repo hasn't been updated in a long time\n   - Run `git fetch --all --tags` to refresh\n\n### Update Not Required\n\n1. **Same version still in use**: Dependency hasn't changed\n2. **Historical investigation**: Looking at specific past version intentionally\n3. **Just cloned**: Repo was freshly cloned this session\n\n## Checking Current State\n\n### What version am I on?\n\n```bash\ncd ~/.cache/claude/repos/<owner>/<repo>\n\n# Show current commit\ngit rev-parse HEAD\n\n# Show current branch/tag\ngit describe --tags --always\n\n# Show if on a tag exactly\ngit describe --tags --exact-match 2>/dev/null || echo \"Not on a tag\"\n\n# Show current branch (if any)\ngit branch --show-current\n```\n\n### How old is my checkout?\n\n```bash\ncd ~/.cache/claude/repos/<owner>/<repo>\n\n# Last fetch time (approximate via FETCH_HEAD)\nstat -f \"%Sm\" .git/FETCH_HEAD 2>/dev/null || stat -c \"%y\" .git/FETCH_HEAD 2>/dev/null\n\n# Last commit date in current checkout\ngit log -1 --format=\"%ci\"\n```\n\n### What tags are available?\n\n```bash\ncd ~/.cache/claude/repos/<owner>/<repo>\n\n# List all tags\ngit tag -l\n\n# List recent tags (sorted by version)\ngit tag -l | sort -V | tail -20\n\n# List tags matching a pattern\ngit tag -l \"v1.*\"\n\n# Show tag with date\ngit for-each-ref --sort=-creatordate --format '%(refname:short) %(creatordate:short)' refs/tags | head -20\n```\n\n## Troubleshooting\n\n### Dirty Working Directory\n\nIf local changes exist (shouldn't happen, but possible):\n\n```bash\ncd ~/.cache/claude/repos/<owner>/<repo>\n\n# Check status\ngit status\n\n# Discard all local changes\ngit checkout -- .\ngit clean -fd\n```\n\n### Detached HEAD State\n\nThis is normal when checking out tags. Not an error.\n\n```bash\n# Verify you're on expected commit\ngit describe --tags --always\n```\n\n### Failed Checkout\n\nIf checkout fails due to conflicts:\n\n```bash\ncd ~/.cache/claude/repos/<owner>/<repo>\n\n# Force checkout (discards local changes)\ngit checkout -f <tag-or-branch>\n```\n\n### Corrupted Repository\n\nIf git commands fail or repo seems broken:\n\n```bash\n# Remove and re-clone\nrm -rf ~/.cache/claude/repos/<owner>/<repo>\n\n# Then re-run the clone workflow from SKILL.md\nmkdir -p ~/.cache/claude/repos/<owner>\ngit clone https://github.com/<owner>/<repo>.git ~/.cache/claude/repos/<owner>/<repo>\n```\n\n### Network Issues\n\nIf fetch/clone fails:\n\n```bash\n# Check if GitHub is accessible\ncurl -I https://github.com\n\n# Try with verbose output\nGIT_CURL_VERBOSE=1 git fetch\n\n# For private repos, verify credentials\nssh -T git@github.com  # For SSH\n# or\ngh auth status  # For GitHub CLI\n```\n\n## Cache Management\n\n### List All Cached Repos\n\n```bash\nfind ~/.cache/claude/repos -maxdepth 2 -mindepth 2 -type d 2>/dev/null\n```\n\n### Check Cache Size\n\n```bash\ndu -sh ~/.cache/claude/repos/\ndu -sh ~/.cache/claude/repos/*/* 2>/dev/null | sort -h\n```\n\n### Remove a Specific Repo\n\n```bash\nrm -rf ~/.cache/claude/repos/<owner>/<repo>\n```\n\n### Clear Entire Cache\n\n```bash\nrm -rf ~/.cache/claude/repos/\n```\n\n## Best Practices\n\n1. **Always fetch before checkout**: Ensures tags are up to date\n   ```bash\n   git fetch --all --tags && git checkout <tag>\n   ```\n\n2. **Verify checkout succeeded**: Confirm you're on expected version\n   ```bash\n   git describe --tags --always\n   ```\n\n3. **Inform user of version**: When exploring, mention which version/tag is checked out\n\n4. **Check for version mismatch**: If exploring for a dependency, re-verify the project's dependency hasn't changed since last check\n\n5. **Prefer tags over branches**: Tags are immutable; branches can change\n",
        "plugins/abatilo-core/skills/repo-explore/references/version-detection.md": "# Version Detection Reference\n\nWhen exploring a repository that is a dependency of the current project, check out the specific version being used. This ensures you're looking at the exact code the project depends on.\n\n## Detection Workflow\n\n1. Identify the package name from the repo (often matches repo name, but not always)\n2. Search dependency files in the current working directory\n3. Extract the pinned/resolved version\n4. Map to a git tag and checkout\n\n## Dependency Files by Ecosystem\n\n### Node.js / JavaScript / TypeScript\n\n#### package.json\n```json\n{\n  \"dependencies\": {\n    \"lodash\": \"^4.17.21\",\n    \"express\": \"~4.18.2\"\n  },\n  \"devDependencies\": {\n    \"typescript\": \"5.0.0\"\n  }\n}\n```\n- Version may have prefixes: `^`, `~`, `>=`, etc.\n- For exact version, check lockfiles\n\n#### package-lock.json\n```json\n{\n  \"packages\": {\n    \"node_modules/lodash\": {\n      \"version\": \"4.17.21\",\n      \"resolved\": \"https://registry.npmjs.org/lodash/-/lodash-4.17.21.tgz\"\n    }\n  }\n}\n```\n- `version` field has the exact resolved version\n\n#### yarn.lock\n```\nlodash@^4.17.21:\n  version \"4.17.21\"\n  resolved \"https://registry.yarnpkg.com/lodash/-/lodash-4.17.21.tgz\"\n```\n- Version on second line after `version \"`\n\n#### pnpm-lock.yaml\n```yaml\npackages:\n  /lodash@4.17.21:\n    resolution: {integrity: sha512-...}\n```\n- Version in the package path after `@`\n\n---\n\n### Go\n\n#### go.mod\n```\nrequire (\n    github.com/gin-gonic/gin v1.9.1\n    golang.org/x/text v0.14.0\n)\n```\n- Version after package path\n- May include `// indirect` suffix (ignore it)\n- Pseudo-versions like `v0.0.0-20231215164722-abcdef123456` indicate a specific commit\n\n#### go.sum\n```\ngithub.com/gin-gonic/gin v1.9.1 h1:4+...\ngithub.com/gin-gonic/gin v1.9.1/go.mod h1:...\n```\n- Confirms exact version from go.mod\n\n**Go version to tag mapping:**\n- `v1.9.1` → tag `v1.9.1`\n- `v0.0.0-20231215164722-abcdef123456` → commit `abcdef123456`\n\n---\n\n### Python\n\n#### requirements.txt\n```\nrequests==2.31.0\nflask>=2.0.0,<3.0.0\ndjango~=4.2.0\n```\n- `==` pins exact version\n- For ranges, may need to check installed version or use lower bound\n\n#### pyproject.toml (Poetry)\n```toml\n[tool.poetry.dependencies]\npython = \"^3.9\"\nrequests = \"^2.31.0\"\ndjango = {version = \"^4.2\", optional = true}\n```\n\n#### poetry.lock\n```toml\n[[package]]\nname = \"requests\"\nversion = \"2.31.0\"\n```\n- `version` field has exact resolved version\n\n#### Pipfile\n```toml\n[packages]\nrequests = \"==2.31.0\"\nflask = \"*\"\n```\n\n#### Pipfile.lock\n```json\n{\n  \"default\": {\n    \"requests\": {\n      \"version\": \"==2.31.0\"\n    }\n  }\n}\n```\n\n#### setup.py / setup.cfg\n```python\ninstall_requires=[\n    'requests>=2.20.0',\n    'click>=7.0',\n]\n```\n\n**Python version to tag mapping:**\n- `2.31.0` → try `v2.31.0`, then `2.31.0`\n- Some projects use `release-2.31.0`\n\n---\n\n### Rust\n\n#### Cargo.toml\n```toml\n[dependencies]\nserde = \"1.0\"\ntokio = { version = \"1.35\", features = [\"full\"] }\n```\n\n#### Cargo.lock\n```toml\n[[package]]\nname = \"serde\"\nversion = \"1.0.193\"\nsource = \"registry+https://github.com/rust-lang/crates.io-index\"\n```\n- `version` field has exact resolved version\n\n**Rust version to tag mapping:**\n- `1.0.193` → try `v1.0.193`, then `1.0.193`\n\n---\n\n### Ruby\n\n#### Gemfile\n```ruby\ngem 'rails', '~> 7.0.0'\ngem 'puma', '>= 5.0'\n```\n\n#### Gemfile.lock\n```\nGEM\n  specs:\n    rails (7.0.8)\n    puma (6.4.0)\n```\n- Version in parentheses after gem name\n\n**Ruby version to tag mapping:**\n- `7.0.8` → try `v7.0.8`, then `7.0.8`\n\n---\n\n### Java / Kotlin\n\n#### pom.xml (Maven)\n```xml\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-core</artifactId>\n    <version>6.1.2</version>\n</dependency>\n```\n- Check `<version>` element\n- May use properties: `${spring.version}`\n\n#### build.gradle / build.gradle.kts (Gradle)\n```groovy\ndependencies {\n    implementation 'org.springframework:spring-core:6.1.2'\n    implementation(\"com.google.guava:guava:33.0.0-jre\")\n}\n```\n- Version after second colon\n\n**Java version to tag mapping:**\n- `6.1.2` → try `v6.1.2`, then `6.1.2`\n- Spring uses tags like `v6.1.2`\n\n---\n\n### .NET / C#\n\n#### *.csproj\n```xml\n<ItemGroup>\n    <PackageReference Include=\"Newtonsoft.Json\" Version=\"13.0.3\" />\n</ItemGroup>\n```\n\n#### Directory.Packages.props (Central Package Management)\n```xml\n<ItemGroup>\n    <PackageVersion Include=\"Newtonsoft.Json\" Version=\"13.0.3\" />\n</ItemGroup>\n```\n\n#### packages.config (legacy)\n```xml\n<packages>\n    <package id=\"Newtonsoft.Json\" version=\"13.0.3\" />\n</packages>\n```\n\n---\n\n### PHP\n\n#### composer.json\n```json\n{\n    \"require\": {\n        \"laravel/framework\": \"^10.0\"\n    }\n}\n```\n\n#### composer.lock\n```json\n{\n    \"packages\": [\n        {\n            \"name\": \"laravel/framework\",\n            \"version\": \"v10.40.0\"\n        }\n    ]\n}\n```\n\n---\n\n### Elixir\n\n#### mix.exs\n```elixir\ndefp deps do\n  [\n    {:phoenix, \"~> 1.7.0\"},\n    {:ecto, \"~> 3.11\"}\n  ]\nend\n```\n\n#### mix.lock\n```elixir\n%{\n  \"phoenix\": {:hex, :phoenix, \"1.7.10\", ...},\n}\n```\n\n---\n\n## Tag Lookup Strategy\n\nAfter extracting version `X.Y.Z`, try these git tags in order:\n\n```bash\ncd ~/.cache/claude/repos/<owner>/<repo>\ngit fetch --all --tags\n\n# Try in order:\ngit checkout v<X.Y.Z>      # Most common: v1.2.3\ngit checkout <X.Y.Z>        # Without prefix: 1.2.3\ngit checkout release-<X.Y.Z>\ngit checkout release/<X.Y.Z>\ngit checkout <package>-<X.Y.Z>  # Monorepo style\n```\n\nList available tags to find the pattern:\n```bash\ngit tag -l | head -20\ngit tag -l \"*<version>*\"\n```\n\n## Handling Version Ranges\n\nIf only a range is specified (e.g., `^1.2.0`, `>=2.0`):\n1. Prefer lockfile versions (always exact)\n2. If no lockfile, checkout latest matching tag\n3. Inform user which version was selected\n\n## Monorepo Considerations\n\nSome repos contain multiple packages. Tags may be prefixed:\n- `@scope/package@1.2.3`\n- `package-v1.2.3`\n- `packages/foo/v1.2.3`\n\nCheck the repo's releases page pattern if standard tags don't match.\n"
      },
      "plugins": [
        {
          "name": "abatilo-core",
          "source": "./plugins/abatilo-core",
          "description": "Core commands, skills, and hooks for abatilo's Claude Code setup",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add abatilo/vimrc",
            "/plugin install abatilo-core@abatilo-plugins"
          ]
        }
      ]
    }
  ]
}