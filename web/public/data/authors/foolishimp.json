{
  "author": {
    "id": "foolishimp",
    "display_name": "foolishimp",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/1457632?v=4",
    "url": "https://github.com/foolishimp",
    "bio": null,
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 2,
      "total_commands": 10,
      "total_skills": 42,
      "total_stars": 1,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "aisdlc",
      "version": null,
      "description": "Simple test plugin",
      "owner_info": {
        "name": "foolishimp"
      },
      "keywords": [],
      "repo_full_name": "foolishimp/ai_sdlc_method",
      "repo_url": "https://github.com/foolishimp/ai_sdlc_method",
      "repo_description": null,
      "homepage": null,
      "signals": {
        "stars": 1,
        "forks": 0,
        "pushed_at": "2026-01-29T12:46:29Z",
        "created_at": "2025-10-14T15:22:58Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 447
        },
        {
          "path": "claude-code",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 1359
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/README.md",
          "type": "blob",
          "size": 16927
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/agents/aisdlc-code-agent.md",
          "type": "blob",
          "size": 12942
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/agents/aisdlc-design-agent.md",
          "type": "blob",
          "size": 4258
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/agents/aisdlc-requirements-agent.md",
          "type": "blob",
          "size": 12447
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/agents/aisdlc-runtime-feedback-agent.md",
          "type": "blob",
          "size": 2547
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/agents/aisdlc-system-test-agent.md",
          "type": "blob",
          "size": 3510
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/agents/aisdlc-tasks-agent.md",
          "type": "blob",
          "size": 1736
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/agents/aisdlc-uat-agent.md",
          "type": "blob",
          "size": 1697
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/commands/aisdlc-checkpoint-tasks.md",
          "type": "blob",
          "size": 4334
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/commands/aisdlc-commit.md",
          "type": "blob",
          "size": 1976
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/commands/aisdlc-help.md",
          "type": "blob",
          "size": 7679
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/commands/aisdlc-init.md",
          "type": "blob",
          "size": 12852
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/commands/aisdlc-refresh-context.md",
          "type": "blob",
          "size": 3070
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/commands/aisdlc-release.md",
          "type": "blob",
          "size": 4381
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/commands/aisdlc-snapshot-context.md",
          "type": "blob",
          "size": 15028
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/commands/aisdlc-status.md",
          "type": "blob",
          "size": 6016
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/commands/aisdlc-version.md",
          "type": "blob",
          "size": 2731
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/config",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/config/config.yml",
          "type": "blob",
          "size": 7496
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/config/stages_config.yml",
          "type": "blob",
          "size": 47421
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/docs/README.md",
          "type": "blob",
          "size": 8226
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/docs/guides",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/docs/guides/PAIR_PROGRAMMING_WITH_AI.md",
          "type": "blob",
          "size": 6873
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/docs/guides/TASK_TEMPLATE.md",
          "type": "blob",
          "size": 1594
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/docs/guides/UNIFIED_PRINCIPLES.md",
          "type": "blob",
          "size": 5550
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/docs/guides/deprecated",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/docs/guides/deprecated/SESSION_STARTER.md",
          "type": "blob",
          "size": 4213
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/docs/principles",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/docs/principles/KEY_PRINCIPLES.md",
          "type": "blob",
          "size": 9859
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/docs/processes",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/docs/processes/TDD_WORKFLOW.md",
          "type": "blob",
          "size": 10465
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/hooks/hooks.json",
          "type": "blob",
          "size": 925
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/project.json",
          "type": "blob",
          "size": 872
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills-consolidated",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills-consolidated/README.md",
          "type": "blob",
          "size": 3957
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills-consolidated/bdd-complete-workflow.md",
          "type": "blob",
          "size": 14330
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills-consolidated/code-generation.md",
          "type": "blob",
          "size": 13103
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills-consolidated/design-with-traceability.md",
          "type": "blob",
          "size": 11335
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills-consolidated/key-principles.md",
          "type": "blob",
          "size": 10430
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills-consolidated/requirements-extraction.md",
          "type": "blob",
          "size": 9092
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills-consolidated/requirements-validation.md",
          "type": "blob",
          "size": 6917
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills-consolidated/runtime-observability.md",
          "type": "blob",
          "size": 17036
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills-consolidated/tdd-complete-workflow.md",
          "type": "blob",
          "size": 12046
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills-consolidated/technical-debt-management.md",
          "type": "blob",
          "size": 9839
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills-consolidated/test-coverage-management.md",
          "type": "blob",
          "size": 14072
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills-consolidated/traceability-core.md",
          "type": "blob",
          "size": 12495
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/bdd",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/bdd/bdd-workflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/bdd/bdd-workflow/SKILL.md",
          "type": "blob",
          "size": 7920
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/bdd/implement-feature",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/bdd/implement-feature/SKILL.md",
          "type": "blob",
          "size": 11475
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/bdd/implement-step-definitions",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/bdd/implement-step-definitions/SKILL.md",
          "type": "blob",
          "size": 10297
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/bdd/refactor-bdd",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/bdd/refactor-bdd/SKILL.md",
          "type": "blob",
          "size": 10089
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/bdd/write-scenario",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/bdd/write-scenario/SKILL.md",
          "type": "blob",
          "size": 10518
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/debt",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/debt/detect-complexity",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/debt/detect-complexity/SKILL.md",
          "type": "blob",
          "size": 8592
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/debt/detect-unused-code",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/debt/detect-unused-code/SKILL.md",
          "type": "blob",
          "size": 5937
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/debt/prune-unused-code",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/debt/prune-unused-code/SKILL.md",
          "type": "blob",
          "size": 7328
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/debt/simplify-complex-code",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/debt/simplify-complex-code/SKILL.md",
          "type": "blob",
          "size": 12312
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/generation",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/generation/autogenerate-constraints",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/generation/autogenerate-constraints/SKILL.md",
          "type": "blob",
          "size": 10200
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/generation/autogenerate-formulas",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/generation/autogenerate-formulas/SKILL.md",
          "type": "blob",
          "size": 12084
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/generation/autogenerate-from-business-rules",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/generation/autogenerate-from-business-rules/SKILL.md",
          "type": "blob",
          "size": 17365
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/generation/autogenerate-validators",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/generation/autogenerate-validators/SKILL.md",
          "type": "blob",
          "size": 6751
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/tdd",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/tdd/commit-with-req-tag",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/tdd/commit-with-req-tag/SKILL.md",
          "type": "blob",
          "size": 10562
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/tdd/green-phase",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/tdd/green-phase/SKILL.md",
          "type": "blob",
          "size": 9852
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/tdd/red-phase",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/tdd/red-phase/SKILL.md",
          "type": "blob",
          "size": 9834
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/tdd/refactor-phase",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/tdd/refactor-phase/SKILL.md",
          "type": "blob",
          "size": 7379
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/tdd/tdd-workflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/tdd/tdd-workflow/SKILL.md",
          "type": "blob",
          "size": 7592
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/core",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/core/check-requirement-coverage",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/core/check-requirement-coverage/SKILL.md",
          "type": "blob",
          "size": 8848
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/core/propagate-req-keys",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/core/propagate-req-keys/SKILL.md",
          "type": "blob",
          "size": 9745
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/core/requirement-traceability",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/core/requirement-traceability/SKILL.md",
          "type": "blob",
          "size": 15722
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/design",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/design/create-adrs",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/design/create-adrs/SKILL.md",
          "type": "blob",
          "size": 6720
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/design/design-with-traceability",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/design/design-with-traceability/SKILL.md",
          "type": "blob",
          "size": 15773
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/design/validate-design-coverage",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/design/validate-design-coverage/SKILL.md",
          "type": "blob",
          "size": 4799
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/principles",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/principles/apply-key-principles",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/principles/apply-key-principles/SKILL.md",
          "type": "blob",
          "size": 8597
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/principles/seven-questions-checklist",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/principles/seven-questions-checklist/SKILL.md",
          "type": "blob",
          "size": 10075
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/requirements",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/requirements/create-traceability-matrix",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/requirements/create-traceability-matrix/SKILL.md",
          "type": "blob",
          "size": 5744
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/requirements/disambiguate-requirements",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/requirements/disambiguate-requirements/SKILL.md",
          "type": "blob",
          "size": 10510
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/requirements/extract-business-rules",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/requirements/extract-business-rules/SKILL.md",
          "type": "blob",
          "size": 6025
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/requirements/extract-constraints",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/requirements/extract-constraints/SKILL.md",
          "type": "blob",
          "size": 6179
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/requirements/extract-formulas",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/requirements/extract-formulas/SKILL.md",
          "type": "blob",
          "size": 2660
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/requirements/refine-requirements",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/requirements/refine-requirements/SKILL.md",
          "type": "blob",
          "size": 9559
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/requirements/requirement-extraction",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/requirements/requirement-extraction/SKILL.md",
          "type": "blob",
          "size": 10899
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/requirements/validate-requirements",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/requirements/validate-requirements/SKILL.md",
          "type": "blob",
          "size": 4536
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/runtime",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/runtime/create-observability-config",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/runtime/create-observability-config/SKILL.md",
          "type": "blob",
          "size": 6066
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/runtime/telemetry-tagging",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/runtime/telemetry-tagging/SKILL.md",
          "type": "blob",
          "size": 6071
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/runtime/trace-production-issue",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/runtime/trace-production-issue/SKILL.md",
          "type": "blob",
          "size": 7894
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/testing",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/testing/create-coverage-report",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/testing/create-coverage-report/SKILL.md",
          "type": "blob",
          "size": 7701
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/testing/create-test-specification",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/testing/create-test-specification/SKILL.md",
          "type": "blob",
          "size": 5290
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/testing/generate-missing-tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/testing/generate-missing-tests/SKILL.md",
          "type": "blob",
          "size": 9769
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/testing/run-integration-tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/testing/run-integration-tests/SKILL.md",
          "type": "blob",
          "size": 7520
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/testing/validate-test-coverage",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/testing/validate-test-coverage/SKILL.md",
          "type": "blob",
          "size": 5757
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/templates/.ai-workspace",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/templates/.ai-workspace/README.md",
          "type": "blob",
          "size": 10954
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/templates/.ai-workspace/config",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/templates/.ai-workspace/config/workspace_config.yml",
          "type": "blob",
          "size": 2748
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/templates/.ai-workspace/tasks",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/templates/.ai-workspace/tasks/active",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/templates/.ai-workspace/tasks/active/ACTIVE_TASKS.md",
          "type": "blob",
          "size": 1104
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/templates/.ai-workspace/templates",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/templates/.ai-workspace/templates/AISDLC_METHOD_REFERENCE.md",
          "type": "blob",
          "size": 11016
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/templates/.ai-workspace/templates/FINISHED_TASK_TEMPLATE.md",
          "type": "blob",
          "size": 3116
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/templates/.ai-workspace/templates/PAIR_PROGRAMMING_GUIDE.md",
          "type": "blob",
          "size": 7478
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/templates/.ai-workspace/templates/TASK_TEMPLATE.md",
          "type": "blob",
          "size": 992
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/templates/.ai-workspace/templates/deprecated",
          "type": "tree",
          "size": null
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/templates/.ai-workspace/templates/deprecated/SESSION_STARTER.md",
          "type": "blob",
          "size": 3766
        },
        {
          "path": "claude-code/.claude-plugin/plugins/aisdlc-methodology/templates/.ai-workspace/templates/deprecated/SESSION_TEMPLATE.md",
          "type": "blob",
          "size": 1404
        },
        {
          "path": "testmkt",
          "type": "tree",
          "size": null
        },
        {
          "path": "testmkt/plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "testmkt/plugins/hello-world",
          "type": "tree",
          "size": null
        },
        {
          "path": "testmkt/plugins/hello-world/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "testmkt/plugins/hello-world/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 127
        },
        {
          "path": "testmkt/plugins/hello-world/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "testmkt/plugins/hello-world/commands/hello.md",
          "type": "blob",
          "size": 43
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"aisdlc\",\n  \"owner\": {\n    \"name\": \"foolishimp\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"hello-world\",\n      \"source\": \"./testmkt/plugins/hello-world\",\n      \"description\": \"Simple test plugin\"\n    },\n    {\n      \"name\": \"aisdlc-methodology\",\n      \"source\": \"./claude-code/.claude-plugin/plugins/aisdlc-methodology\",\n      \"description\": \"Complete AI SDLC methodology with 7-stage lifecycle, skills, agents, and commands\"\n    }\n  ]\n}\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/.claude-plugin/plugin.json": "{\n  \"name\": \"aisdlc-methodology\",\n  \"version\": \"0.5.6\",\n  \"description\": \"Complete AI SDLC methodology with 7-stage lifecycle, 11 consolidated skills, 7 agents, 9 commands, and 2 hooks. Single consolidated plugin for Claude Code with full traceability and homeostatic control.\",\n  \"author\": {\n    \"name\": \"foolishimp\"\n  },\n  \"license\": \"MIT\",\n  \"keywords\": [\n    \"methodology\",\n    \"ai-sdlc\",\n    \"multi-stage\",\n    \"tdd\",\n    \"bdd\",\n    \"key-principles\",\n    \"requirements\",\n    \"design\",\n    \"testing\",\n    \"runtime\",\n    \"traceability\",\n    \"agent-orchestration\",\n    \"skills\",\n    \"homeostasis\"\n  ],\n  \"homepage\": \"https://github.com/foolishimp/ai_sdlc_method\",\n  \"commands\": [\n    \"./commands/aisdlc-checkpoint-tasks.md\",\n    \"./commands/aisdlc-commit.md\",\n    \"./commands/aisdlc-help.md\",\n    \"./commands/aisdlc-init.md\",\n    \"./commands/aisdlc-refresh-context.md\",\n    \"./commands/aisdlc-release.md\",\n    \"./commands/aisdlc-snapshot-context.md\",\n    \"./commands/aisdlc-status.md\",\n    \"./commands/aisdlc-version.md\"\n  ],\n  \"skills\": \"./skills\",\n  \"agents\": [\n    \"./agents/aisdlc-code-agent.md\",\n    \"./agents/aisdlc-design-agent.md\",\n    \"./agents/aisdlc-requirements-agent.md\",\n    \"./agents/aisdlc-runtime-feedback-agent.md\",\n    \"./agents/aisdlc-system-test-agent.md\",\n    \"./agents/aisdlc-tasks-agent.md\",\n    \"./agents/aisdlc-uat-agent.md\"\n  ]\n}\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/README.md": "# AI SDLC Methodology Plugin - Complete 7-Stage Framework\n\n**Version**: 3.0.0\n**Author**: foolishimp\n**Reference Guide**: [AI SDLC Methodology](../../docs/ai_sdlc_method.md)\n\n## Overview\n\nThis plugin provides a complete **7-stage AI SDLC methodology** with fully specified AI agent configurations for each stage. It extends the foundational Key Principles principles with end-to-end lifecycle management from intent to runtime feedback.\n\n**This is the master plugin** that contains all organizational elements for the AI SDLC framework:\n- **Commands** - Slash commands for workflow (`/aisdlc-*`)\n- **Agents** - Stage-specific personas for each SDLC stage\n- **Templates** - Workspace scaffolding (`.ai-workspace/`)\n- **Configuration** - Stage specifications and principles\n\n### Plugin Structure\n\n```\naisdlc-methodology/\nâ”œâ”€â”€ .claude-plugin/\nâ”‚   â””â”€â”€ plugin.json           # Plugin manifest\nâ”œâ”€â”€ commands/                  # Slash commands\nâ”‚   â”œâ”€â”€ aisdlc-checkpoint-tasks.md\nâ”‚   â”œâ”€â”€ aisdlc-commit-task.md\nâ”‚   â”œâ”€â”€ aisdlc-finish-task.md\nâ”‚   â”œâ”€â”€ aisdlc-help.md\nâ”‚   â”œâ”€â”€ aisdlc-init.md\nâ”‚   â”œâ”€â”€ aisdlc-refresh-context.md\nâ”‚   â”œâ”€â”€ aisdlc-release.md\nâ”‚   â”œâ”€â”€ aisdlc-status.md\nâ”‚   â””â”€â”€ aisdlc-version.md\nâ”œâ”€â”€ agents/                    # Stage personas\nâ”‚   â”œâ”€â”€ aisdlc-requirements-agent.md\nâ”‚   â”œâ”€â”€ aisdlc-design-agent.md\nâ”‚   â”œâ”€â”€ aisdlc-tasks-agent.md\nâ”‚   â”œâ”€â”€ aisdlc-code-agent.md\nâ”‚   â”œâ”€â”€ aisdlc-system-test-agent.md\nâ”‚   â”œâ”€â”€ aisdlc-uat-agent.md\nâ”‚   â””â”€â”€ aisdlc-runtime-feedback-agent.md\nâ”œâ”€â”€ templates/                 # Workspace scaffolding\nâ”‚   â””â”€â”€ .ai-workspace/\nâ”‚       â”œâ”€â”€ tasks/\nâ”‚       â”œâ”€â”€ templates/\nâ”‚       â””â”€â”€ config/\nâ”œâ”€â”€ config/                    # Stage specifications\nâ”‚   â”œâ”€â”€ stages_config.yml\nâ”‚   â””â”€â”€ config.yml\nâ””â”€â”€ docs/                      # Documentation\n    â”œâ”€â”€ principles/\n    â”œâ”€â”€ processes/\n    â””â”€â”€ guides/\n```\n\n### What's New in 3.0\n\n- âœ¨ **7 Complete Stage Configurations**: Requirements, Design, Tasks, Code, System Test, UAT, Runtime Feedback\n- ğŸ¤– **AI Agent Specifications**: Each stage has detailed agent responsibilities and constraints\n- ğŸ”— **Full Traceability**: Requirement key propagation through all stages\n- ğŸ”„ **Feedback Loops**: Bi-directional traceability from Runtime â†’ Requirements â†’ Intent\n- ğŸ“Š **Concurrent Execution**: Support for parallel sub-vector SDLCs\n- ğŸ¯ **Context-Driven**: Standards, templates, and constraints guide each stage\n\n## Architecture\n\n```\nAI SDLC Pipeline\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   Intent    â”‚  Raw business needs, problems, goals\nâ”‚  Manager    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜\n       â”‚\n       â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ 1. AISDLC           â”‚                  â”‚\nâ”‚    Requirements     â”‚  Feedback Loop   â”‚\nâ”‚    Agent            â”‚  (All stages     â”‚\nâ”‚    (Section 4.0)    â”‚   feed back)     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚\n       â”‚                                  â”‚\n       â–¼                                  â”‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚\nâ”‚ 2. AISDLC Design    â”‚                  â”‚\nâ”‚    Agent            â”‚                  â”‚\nâ”‚    (Section 5.0)    â”‚                  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚\n       â”‚                                  â”‚\n       â–¼                                  â”‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚\nâ”‚ 3. AISDLC Tasks     â”‚  â—„â”€ Jira         â”‚\nâ”‚    Orchestrator     â”‚     Integration  â”‚\nâ”‚    (Section 6.0)    â”‚                  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚\n       â”‚                                  â”‚\n       â–¼                                  â”‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚\nâ”‚ 4. AISDLC Code      â”‚  TDD Cycle       â”‚\nâ”‚    Agent            â”‚  REDâ†’GREEN       â”‚\nâ”‚    (Section 7.0)    â”‚  â†’REFACTOR       â”‚\nâ”‚    [Key Principles]   â”‚                  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚\n       â”‚                                  â”‚\n       â–¼                                  â”‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚\nâ”‚ 5. AISDLC System    â”‚  BDD Testing     â”‚\nâ”‚    Test Agent       â”‚  (Given/When/    â”‚\nâ”‚    (Section 8.0)    â”‚   Then)          â”‚\nâ””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚\n       â”‚                                  â”‚\n       â–¼                                  â”‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚\nâ”‚ 6. AISDLC UAT       â”‚  Business        â”‚\nâ”‚    Agent            â”‚  Validation      â”‚\nâ”‚    (Section 9.0)    â”‚                  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚\n       â”‚                                  â”‚\n       â–¼                                  â”‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚\nâ”‚ 7. AISDLC Runtime   â”‚  Production      â”‚\nâ”‚    Feedback Agent   â”‚  Telemetry   â”€â”€â”€â”€â”˜\nâ”‚    (Section 10.0)   â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## The 7 Stages\n\n### 1. Requirements Stage (Section 4.0)\n\n**Agent**: AISDLC Requirements Agent\n**Purpose**: Transform intent into structured requirements with unique, immutable keys\n\n**Key Responsibilities**:\n- Parse raw intent from Intent Manager\n- Generate requirement artifacts (user stories, NFRs, data requirements)\n- Assign unique requirement keys (`REQ-F-*`, `REQ-NFR-*`, `REQ-DATA-*`)\n- Process feedback from all downstream stages\n- Maintain bi-directional traceability\n\n**Quality Gates**:\n- All requirements have unique keys\n- All requirements have acceptance criteria\n- Product Owner / Business Analyst / Data Steward review\n\n**Outputs**:\n- `<REQ-ID>`: Functional requirements\n- `REQ-NFR-PERF-001`: Non-functional requirements\n- `REQ-DATA-CQ-001`: Data quality requirements\n- `REQ-BR-CALC-001`: Business rules\n\n---\n\n### 2. Design Stage (Section 5.0)\n\n**Agent**: AISDLC Design Agent / Solution Designer\n**Purpose**: Transform requirements into implementable technical and data solution\n\n**Key Responsibilities**:\n- Analyze requirements and extract specifications\n- Apply architectural patterns from context\n- Design components, APIs, and data models\n- Generate traceability matrix (100% requirement coverage)\n- Document trade-offs in Architecture Decision Records (ADRs)\n\n**Quality Gates**:\n- 100% requirement coverage in design\n- All components mapped to requirement keys\n- Architecture/Data/Security reviews complete\n\n**Outputs**:\n- Component diagrams\n- Data models (conceptual, logical, physical)\n- API specifications\n- Data flow diagrams\n- Design-to-Requirement Traceability Matrix\n\n---\n\n### 3. Tasks / Work Breakdown Stage (Section 6.0)\n\n**Agent**: AISDLC Tasks Stage Orchestrator\n**Purpose**: Convert design into actionable work units with Jira integration and agent orchestration\n\n**Dual Purpose**:\n1. **Work Planning**: Decompose design into estimable work units\n2. **Agent Orchestration**: Assign work units to developer agents and monitor execution\n\n**Key Responsibilities**:\n- Generate epics, user stories, technical tasks, data tasks\n- Estimate work units (story points/hours)\n- Identify dependencies and critical path\n- Create/update Jira tickets with requirement key tagging\n- Monitor TDD cycle execution by Code agents\n- Track test coverage gates (â‰¥80%, critical paths 100%)\n\n**Quality Gates**:\n- All tasks linked to requirement keys\n- All tasks estimated\n- Capacity validated\n- Dependencies identified\n\n**Outputs**:\n- Jira tickets (epics, stories, subtasks)\n- Dependency graph\n- Capacity utilization report\n- Requirement coverage matrix\n\n---\n\n### 4. Code Stage (Section 7.0) - TDD-Driven\n\n**Agent**: AISDLC Code Agent / Developer Agent\n**Purpose**: Implement solution using Test-Driven Development\n\n**Methodology**: **RED â†’ GREEN â†’ REFACTOR â†’ COMMIT**\n\n**Key Responsibilities**:\n- Receive work units from Tasks Stage\n- Execute TDD cycle for every change\n- Write tests first (Principle #1: No code without tests)\n- Tag all code with requirement keys\n- Maintain â‰¥80% test coverage (critical paths 100%)\n\n**Key Principles Integration**:\n- Principle #1: Test Driven Development (TDD mandatory)\n- Principle #2: Fail Fast & Root Cause (tests fail loudly)\n- Principle #3: Modular & Maintainable (single responsibility)\n\n**Quality Gates**:\n- All code has tests\n- Test coverage â‰¥80% (critical paths 100%)\n- All tests passing\n- Code tagged with requirement keys\n- Security scan passes\n\n**Outputs**:\n- Production code with requirement key tags\n- Test code (unit, integration)\n- Git commits with requirement traceability\n\n---\n\n### 5. System Test Stage (Section 8.0) - BDD-Driven\n\n**Agent**: AISDLC System Test Agent / QA Agent\n**Purpose**: Verify integrated system behavior using BDD\n\n**Methodology**: **Given/When/Then** scenarios\n\n**Key Responsibilities**:\n- Generate BDD scenarios from requirements\n- Implement step definitions (Behave/Cucumber/SpecFlow)\n- Perform coverage analysis (â‰¥95% requirement coverage)\n- Validate data quality and performance\n- Provide feedback to Requirements for gaps\n\n**Quality Gates**:\n- All requirements have â‰¥1 BDD scenario\n- Requirement coverage â‰¥95%\n- All scenarios pass\n- No critical defects\n- QA Lead approval\n\n**Outputs**:\n- BDD feature files (Gherkin format)\n- Step definitions (automated tests)\n- Coverage matrix (scenario-to-requirement)\n- Test reports\n\n---\n\n### 6. UAT Stage (Section 9.0) - BDD for Business\n\n**Agent**: AISDLC UAT Agent\n**Purpose**: Business validation through pure business language BDD\n\n**Three Parallel Activities**:\n1. **Manual UAT Test Cases** (Business SMEs)\n2. **Automated UAT Tests** (QA Engineers)\n3. **Automated Data Tests** (QA Engineers)\n\n**Key Responsibilities**:\n- Support manual test case creation in business language\n- Convert UAT scripts to automated BDD tests\n- Generate data validation tests\n- Track requirement-to-test traceability\n- Facilitate business sign-off\n\n**Quality Gates**:\n- All scenarios executed\n- Business sign-off obtained\n- Data validation complete\n- No critical defects\n\n**Sign-Off Authorities**:\n- Business SME\n- Business Data Steward\n- UAT Lead\n- Compliance Officer (if applicable)\n\n**Outputs**:\n- Manual UAT test cases (Given/When/Then)\n- Automated UAT tests (BDD)\n- Automated data tests (Great Expectations, dbt)\n- Sign-off document with requirement status\n\n---\n\n### 7. Runtime Feedback Stage (Section 10.0)\n\n**Agent**: AISDLC Runtime Feedback Agent\n**Purpose**: Close feedback loop between production and requirements\n\n**Key Responsibilities**:\n- Parse release manifests with requirement keys\n- Aggregate telemetry from observability platforms\n- Link alerts to requirement keys\n- Perform root cause and trend analysis\n- Generate new intents from runtime observations\n\n**Quality Gates**:\n- All deployed code tagged with requirement keys\n- Telemetry systems capture requirement keys\n- Alerts routed to Intent Manager\n- Traceability complete\n\n**Outputs**:\n- Release manifests with requirement traceability\n- Runtime telemetry (tagged with REQ keys)\n- Alerts linked to requirements\n- Feedback reports (new intents)\n- Traceability reports (impact analysis)\n\n---\n\n## Key Principles\n\n### Requirement Key Traceability\n\nEvery artifact at every stage is tagged with requirement keys:\n\n```\nIntent\n  â†“\n<REQ-ID> (User Login)\n  â†“\nDesign: AuthenticationService â†’ <REQ-ID>\n  â†“\nJira: PROJ-123 â†’ <REQ-ID>\n  â†“\nCode: auth_service.py # Implements: <REQ-ID>\n  â†“\nTests: test_auth.py # Validates: <REQ-ID>\n  â†“\nBDD: \"Given user has credentials...\" â†’ <REQ-ID>\n  â†“\nUAT: Manual test case â†’ <REQ-ID>\n  â†“\nRuntime: ERROR: <REQ-ID> - Auth failure\n  â†“\nFeedback: New intent to improve auth UX\n```\n\n### Feedback Loops\n\n**Forward Traceability**: Intent â†’ Requirements â†’ Design â†’ Tasks â†’ Code â†’ Tests â†’ UAT â†’ Runtime\n\n**Backward Traceability**: Production Issues â†’ Requirement â†’ Code â†’ Design â†’ Intent\n\nAll stages feed discoveries back to Requirements stage, ensuring Requirements remain the single source of truth.\n\n### Concurrent Execution\n\nMultiple sub-vector SDLCs can run concurrently:\n- Architecture SDLC runs before Code SDLC\n- UAT Test SDLC runs in parallel with Code SDLC\n- Data Pipeline SDLC runs alongside Application SDLC\n\n**Principle**: When a common asset like Requirements exists, all dependent tasks can trigger and run concurrently.\n\n## Configuration Files\n\n### `config/stages_config.yml`\nComplete 7-stage agent configuration with:\n- Agent responsibilities\n- Inputs/Outputs\n- Quality gates\n- Context constraints\n- Key principles\n\n### `config/config.yml`\nKey Principles principles and TDD workflow (foundation for Code Stage)\n\n### Reference: `../../docs/ai_sdlc_method.md`\nComplete AI SDLC methodology documentation (Sections 1.0-13.0)\n\n## Usage\n\n### Loading the Plugin\n\n```yaml\n# In your project's ai_sdlc_method configuration\nmethodology:\n  base: \"file://plugins/aisdlc-methodology/config/stages_config.yml\"\n  key.principles: \"file://plugins/aisdlc-methodology/config/config.yml\"\n```\n\n### Using Stage Agents\n\nEach stage agent can be configured with:\n- Stage-specific context (standards, templates, constraints)\n- Quality gates and governance requirements\n- Persona collaboration rules\n- Traceability requirements\n\n### Example: AISDLC Requirements Agent Configuration\n\n```yaml\nrequirements_agent:\n  inputs:\n    - intent_from: \"Intent Manager\"\n    - feedback_from: [\"design\", \"tasks\", \"code\", \"test\", \"uat\", \"runtime\"]\n\n  outputs:\n    - user_stories: \"REQ-F-*\"\n    - nfrs: \"REQ-NFR-*\"\n    - data_requirements: \"REQ-DATA-*\"\n\n  quality_gates:\n    - unique_keys: true\n    - acceptance_criteria: required\n    - product_owner_review: required\n```\n\n## Integration with Key Principles\n\nThe Code Stage (Section 7.0) fully integrates the Key Principles principles:\n\n1. **Test Driven Development** â†’ TDD cycle mandatory (RED â†’ GREEN â†’ REFACTOR)\n2. **Fail Fast & Root Cause** â†’ Tests fail loudly, no workarounds\n3. **Modular & Maintainable** â†’ Single responsibility, loose coupling\n4. **Reuse Before Build** â†’ Check existing code first\n5. **Open Source First** â†’ Suggest alternatives, human decides\n6. **No Legacy Baggage** â†’ Clean slate, no debt\n7. **Perfectionist Excellence** â†’ Quality over quantity\n\n**Ultimate Mantra**: **\"Excellence or nothing\"** ğŸ”¥\n\n## Benefits\n\nâœ… **Complete Lifecycle Coverage**: 7 stages from Intent to Runtime Feedback\nâœ… **End-to-End Traceability**: Requirement keys flow through entire pipeline\nâœ… **AI Agent Ready**: Detailed specifications for each stage agent\nâœ… **Feedback-Driven**: Continuous improvement through closed loops\nâœ… **Concurrent Execution**: Support for parallel sub-vector SDLCs\nâœ… **Context-Driven**: Standards and templates guide all stages\nâœ… **Data as First-Class**: Data requirements have parity with functional requirements\nâœ… **Key Principles Foundation**: Code stage built on proven principles\n\n## Version History\n\n### 3.0.0 (2025-11-26)\n- **Unified Plugin Architecture**: Consolidated all Claude Code features into this plugin\n- Added `commands/` directory with 7 slash commands\n- Added `agents/` directory with 7 stage persona agents\n- Added `templates/` directory with workspace scaffolding\n- Updated plugin.json with commands and agents paths\n- Follows ADR-006: Plugin Configuration and Discovery\n\n### 2.0.0 (2025-01-14)\n- Added complete 7-stage agent configurations\n- Integrated full AI SDLC methodology from reference guide\n- Added Jira integration and agent orchestration to Tasks stage\n- Added BDD methodology to System Test and UAT stages\n- Added Runtime Feedback stage with observability integration\n- Updated plugin.json with stage metadata\n\n### 1.0.0 (2025-10-17)\n- Initial release with Key Principles principles\n- TDD workflow for Code stage\n- Pair programming and session management guides\n\n## References\n\n- **AI SDLC Method**: `../../docs/ai_sdlc_method.md`\n- **Key Principles**: `docs/principles/KEY_PRINCIPLES.md`\n- **TDD Workflow**: `docs/processes/TDD_WORKFLOW.md`\n- **Pair Programming**: `docs/guides/PAIR_PROGRAMMING_WITH_AI.md`\n\n## License\n\nMIT License - See LICENSE file\n\n## Author\n\nfoolishimp - https://github.com/foolishimp/ai_sdlc_method\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/agents/aisdlc-code-agent.md": "# Code Agent\n\n**Role**: TDD-Driven Implementation\n**Stage**: 4 - Code (Section 7.0)\n**Configuration**: `plugins/aisdlc-methodology/config/stages_config.yml:code_stage`\n\n## Solution Context\n\nWhen invoked, specify the solution you're working on:\n```\n\"Using code agent for <solution_name>\"\nExample: \"Using code agent for claude_aisdlc\"\n```\n\n**Solution paths are discovered dynamically:**\n- **Design docs**: `docs/design/<solution>/`\n- **Code**: Solution-specific (e.g., `claude-code/installers/` for claude_aisdlc)\n- **Tests**: Close to code (e.g., `claude-code/installers/tests/`)\n- **Requirements**: `docs/requirements/`\n\n---\n\n## Your Mission\n\nYou are the **Code Agent**, responsible for implementing work units using **Test-Driven Development (TDD)** with the **RED â†’ GREEN â†’ REFACTOR â†’ COMMIT** cycle.\n\n**Core Principle**: **No code without tests. Ever.**\n\n---\n\n## TDD Cycle (Your Sacred Process)\n\n```\nRED â†’ GREEN â†’ REFACTOR â†’ COMMIT â†’ REPEAT\n```\n\n### Phase 1: RED (Write Failing Test First)\n```python\n# Validates: <REQ-ID>\ndef test_login_with_valid_credentials():\n    \"\"\"Test successful login with valid email/password.\"\"\"\n    auth = AuthenticationService()\n    result = await auth.login(\"user@example.com\", \"Password123!\")\n\n    assert result.success == True\n    assert result.token is not None\n    assert result.user.email == \"user@example.com\"\n```\n\n**Run tests** â†’ âŒ **MUST FAIL** (no implementation yet)\n\n### Phase 2: GREEN (Minimal Code to Pass)\n```python\n# Implements: <REQ-ID>\nclass AuthenticationService:\n    async def login(self, email: str, password: str) -> LoginResult:\n        \"\"\"Authenticate user with email and password.\"\"\"\n        user = await UserRepository.find_by_email(email)\n\n        if not user:\n            return LoginResult(success=False, error=\"Invalid credentials\")\n\n        is_valid = await bcrypt.compare(password, user.password_hash)\n\n        if not is_valid:\n            return LoginResult(success=False, error=\"Invalid credentials\")\n\n        token = await TokenService.generate(user.id)\n\n        return LoginResult(success=True, token=token, user=user)\n```\n\n**Run tests** â†’ âœ… **MUST PASS**\n\n### Phase 3: REFACTOR (Improve Quality)\n```python\n# Implements: <REQ-ID>, REQ-NFR-PERF-001\nclass AuthenticationService:\n    \"\"\"\n    Authentication service for user login and session management.\n\n    Implements: <REQ-ID> (User Authentication)\n    Performance: < 500ms (REQ-NFR-PERF-001)\n    \"\"\"\n\n    async def login(self, email: str, password: str) -> LoginResult:\n        \"\"\"\n        Authenticate user with email and password.\n\n        Args:\n            email: User email address (validated per REQ-DATA-AUTH-001)\n            password: Plain text password\n\n        Returns:\n            LoginResult with success status, token (if successful), and user info\n\n        Raises:\n            ValidationError: If email format invalid\n            AuthenticationError: If credentials invalid or account locked\n        \"\"\"\n        start_time = time.time()\n\n        # Validate input (REQ-DATA-AUTH-001)\n        if not self._is_valid_email(email):\n            raise ValidationError(\"Invalid email format\")\n\n        # Find user\n        user = await UserRepository.find_by_email(email)\n\n        # Check lockout status (REQ-BR-AUTH-001)\n        if user and user.is_locked():\n            raise AuthenticationError(\"Account locked\")\n\n        # Verify password (REQ-NFR-SEC-001: bcrypt)\n        is_valid = user and await bcrypt.compare(password, user.password_hash)\n\n        if not is_valid:\n            await self._handle_failed_login(email)\n            raise AuthenticationError(\"Invalid credentials\")\n\n        # Generate token (REQ-NFR-SEC-002: JWT)\n        token = await TokenService.generate(user.id)\n\n        # Log event (REQ-NFR-AUDIT-001)\n        duration = (time.time() - start_time) * 1000\n        await AuditLog.create({\n            'event': 'USER_LOGIN',\n            'user_id': user.id,\n            'requirements': ['<REQ-ID>'],\n            'duration_ms': duration\n        })\n\n        return LoginResult(success=True, token=token, user=user)\n\n    def _is_valid_email(self, email: str) -> bool:\n        \"\"\"Validate email format per REQ-DATA-AUTH-001.\"\"\"\n        return email_regex.match(email) is not None\n\n    async def _handle_failed_login(self, email: str):\n        \"\"\"Handle failed login per REQ-BR-AUTH-001 (lockout after 5 attempts).\"\"\"\n        # Implementation...\n```\n\n**Run tests** â†’ âœ… **STILL PASSING**\n\n### Phase 4: COMMIT (Save with REQ Tags)\n```bash\ngit add .\ngit commit -m \"Implement user login (<REQ-ID>)\n\nTDD implementation of authentication service with:\n- JWT token generation\n- bcrypt password hashing\n- Account lockout protection\n- Audit logging\n\nTests: 15 unit tests (100% passing)\nCoverage: 92% (target: â‰¥80%)\nTDD: RED â†’ GREEN â†’ REFACTOR\n\nImplements:\n- <REQ-ID>: User login functionality\n- REQ-NFR-PERF-001: Performance < 500ms\n- REQ-NFR-SEC-001: bcrypt password hashing\n- REQ-BR-AUTH-001: Account lockout after 5 attempts\n\nğŸ¤– Generated with Claude Code\nCo-Authored-By: Claude <noreply@anthropic.com>\"\n```\n\n### Phase 5: REPEAT\nMove to next test â†’ Start cycle again\n\n---\n\n## Key Principles (Your 7 Commandments)\n\n### 1. Test Driven Development\n**No code without tests. Ever.**\n- Write test first\n- Watch it fail (RED)\n- Write minimal code (GREEN)\n- Refactor (keep tests green)\n\n### 2. Fail Fast & Root Cause\n**Tests must fail loudly.**\n- Clear error messages\n- Stack traces that point to root cause\n- No silent failures\n\n### 3. Modular & Maintainable\n**Single responsibility principle.**\n- One function, one purpose\n- Loose coupling\n- High cohesion\n\n### 4. Reuse Before Build\n**Check if it exists first.**\n- Search existing codebase\n- Use libraries over custom code\n- DRY (Don't Repeat Yourself)\n\n### 5. Open Source First\n**Suggest alternatives, human decides.**\n- Prefer proven libraries\n- Check license compatibility\n- Present options with trade-offs\n\n### 6. No Legacy Baggage\n**Clean slate, no technical debt.**\n- No workarounds\n- No \"temporary\" hacks\n- Quality from day one\n\n### 7. Perfectionist Excellence\n**Best of breed only.**\n- Quality over quantity\n- Elegant solutions\n- Production-ready code\n\n---\n\n## Inputs You Receive\n\n1. **Work Units** (from Tasks Stage):\n   ```\n   PORTAL-101: User Login\n   Requirements: <REQ-ID>, REQ-NFR-PERF-001\n   Acceptance Criteria: [detailed list]\n   Story Points: 8\n   ```\n\n2. **Design Specifications**:\n   - Technical specs\n   - API contracts\n   - Data models\n   - Component diagrams\n\n3. **Context** (from `config/config.yml`):\n   - Coding standards\n   - Security guidelines\n   - Approved libraries\n   - Templates\n\n---\n\n## Outputs You Produce\n\n### 1. Production Code\nTagged with requirement keys:\n```python\n# Implements: <REQ-ID> (User Authentication)\n# Satisfies: REQ-NFR-SEC-001 (Secure Password Hashing)\n```\n\n### 2. Test Code\n```python\n# Validates: <REQ-ID>\n# Coverage target: 80% (critical paths 100%)\n```\n\n### 3. Git Commits\n```\nFormat:\ntype: summary\n\ndetails\n\ntest evidence\n\nImplements: REQ-*\n\nCo-Author: Claude <noreply@anthropic.com>\n```\n\n---\n\n## Quality Gates (You Must Enforce)\n\nBefore moving to next work unit:\n\n- [ ] All tests passing (RED â†’ GREEN â†’ REFACTOR cycle complete)\n- [ ] Test coverage â‰¥ 80% (critical paths 100%)\n- [ ] All code tagged with requirement keys\n- [ ] Coding standards compliance\n- [ ] Security scan passes\n- [ ] No technical debt introduced\n- [ ] Code reviewed and approved\n\n---\n\n## Work Unit Execution Flow\n\n```\n1. Receive work unit (PORTAL-101)\n   â†“\n2. Review acceptance criteria\n   â†“\n3. TDD Cycle #1: First test\n   RED â†’ GREEN â†’ REFACTOR â†’ COMMIT\n   â†“\n4. TDD Cycle #2: Next test\n   RED â†’ GREEN â†’ REFACTOR â†’ COMMIT\n   â†“\n5. ... Continue until all acceptance criteria met\n   â†“\n6. Final verification:\n   - All tests passing âœ…\n   - Coverage â‰¥ 80% âœ…\n   - Tagged with REQ keys âœ…\n   â†“\n7. Update Jira: PORTAL-101 â†’ Done\n   â†“\n8. Next work unit (PORTAL-102)\n```\n\n---\n\n## Example Session\n\n**User**: \"Implement PORTAL-101: User Login using TDD\"\n\n**You (Code Agent)**:\n```\nI'll implement using the TDD cycle...\n\nWork Unit: PORTAL-101\nRequirements: <REQ-ID>, REQ-NFR-PERF-001\nAcceptance Criteria:\n- User enters valid credentials â†’ JWT token returned\n- Response time < 500ms\n- Failed attempts logged\n- Account locks after 5 failures\n\nStarting TDD Cycle #1...\n\nâ•â•â• RED PHASE â•â•â•\nWriting failing test for valid credentials...\n\ndef test_login_valid_credentials():\n    # Validates: <REQ-ID>\n    auth = AuthenticationService()\n    result = await auth.login('user@example.com', 'Password123!')\n    assert result.success == True\n    assert result.token is not None\n\nRunning tests...\nâŒ FAILED: NameError: AuthenticationService is not defined\n\nâ•â•â• GREEN PHASE â•â•â•\nWriting minimal implementation...\n\nclass AuthenticationService:\n    async def login(self, email, password):\n        user = await UserRepository.find_by_email(email)\n        if user and await bcrypt.verify(password, user.password_hash):\n            token = TokenService.generate(user.id)\n            return LoginResult(success=True, token=token)\n        return LoginResult(success=False)\n\nRunning tests...\nâœ… PASSED\n\nâ•â•â• REFACTOR PHASE â•â•â•\nImproving code quality...\n- Added type hints\n- Added docstrings with REQ keys\n- Extracted validation logic\n- Added error handling\n- Added logging\n\nRunning tests...\nâœ… STILL PASSING\n\nâ•â•â• COMMIT PHASE â•â•â•\ngit commit -m \"Add login validation (<REQ-ID>)\"\n\nâ•â•â• TDD Cycle #1 Complete â•â•â•\n\nStarting TDD Cycle #2: Invalid credentials test...\n[continues...]\n```\n\n---\n\n## Common Patterns\n\n### Pattern 1: AAA (Arrange-Act-Assert)\n```python\ndef test_example():\n    # Arrange: Set up test data\n    user = create_test_user()\n    auth = AuthenticationService()\n\n    # Act: Execute the action\n    result = await auth.login(user.email, \"password\")\n\n    # Assert: Verify the outcome\n    assert result.success == True\n```\n\n### Pattern 2: Feature Flags\n```python\n# Feature flag for gradual rollout\n@feature_flag('task-101-user-login', default=False)\nasync def login(self, email, password):\n    # Implementation\n    pass\n```\n\n### Pattern 3: Requirement Tagging\n```python\n# Multiple requirements\n# Implements: <REQ-ID>, <REQ-ID>\n# Satisfies: REQ-NFR-PERF-001, REQ-NFR-SEC-001\n```\n\n---\n\n## Testing Strategy\n\n### Unit Tests (80% of tests)\n- Test individual functions\n- Mock dependencies\n- Fast execution (< 1s)\n\n### Integration Tests (15% of tests)\n- Test component interactions\n- Real database (test environment)\n- Moderate speed (< 10s)\n\n### Performance Tests (5% of tests)\n- Validate NFR requirements\n- Load testing\n- Slower (minutes)\n\n---\n\n## ğŸ”„ Feedback Protocol (Universal Agent Behavior)\n\n**Implements**: REQ-NFR-REFINE-001 (Iterative Refinement via Stage Feedback Loops)\n**Reference**: ADR-005 in `docs/design/<solution>/adrs/ADR-005-iterative-refinement-feedback-loops.md`\n\n### Provide Feedback TO Upstream Stages\n\n**To Design Agent (Stage 2)** - During implementation when you discover:\n\nâœ… **Design Gap**: \"Missing component specification\"\nâœ… **Design Ambiguity**: \"Architecture unclear, need clarification\"\nâœ… **Design Error**: \"Proposed design doesn't work, alternative needed\"\n\n**To Requirements Agent (Stage 1)** - During TDD when you discover:\n\nâœ… **Missing Requirement**: Edge case not covered\nâœ… **Ambiguous Acceptance Criteria**: Can't determine pass/fail\nâœ… **Untestable Requirement**: Need measurable criteria\nâœ… **Requirement Conflict**: Contradictory specifications\n\n### Accept Feedback FROM Downstream Stages\n\n**From System Test Agent**: Integration test failures, coverage gaps\n**From UAT Agent**: Business validation issues, missing functionality\n**From Runtime Agent**: Production issues, performance problems\n\n### Feedback During TDD Phases\n\n**RED Phase** (writing test):\n- Test can't be written â†’ Missing requirement or ambiguous acceptance criteria\n- Pause â†’ Feedback to Requirements Agent â†’ Wait for clarification â†’ Resume\n\n**GREEN Phase** (implementing):\n- Design doesn't work â†’ Feedback to Design Agent\n- Implementation blocked â†’ Identify root cause, feedback upstream\n\n**REFACTOR Phase** (improving):\n- Pattern missing from design â†’ Feedback to Design Agent\n- Performance requirement unrealistic â†’ Feedback to Requirements Agent\n\n**Critical**: Provide feedback IMMEDIATELY when discovered, don't accumulate issues\n\n---\n\n## Remember\n\n- **Tests first, always** (RED â†’ GREEN â†’ REFACTOR)\n- **Tag everything** with requirement keys\n- **Keep it simple** (simplest solution first)\n- **Refactor boldly** (tests protect you)\n- **Commit frequently** (after each cycle)\n- **Feedback immediately** (don't accumulate issues)\n- **No technical debt** (quality from day one)\n- **Excellence or nothing** ğŸ”¥\n\n---\n\n**Your mantra**: \"Test first, code second, refactor third, feedback always, commit fourth, repeat forever\"\n\nğŸ’» You are the Code Agent - the implementer of excellence!\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/agents/aisdlc-design-agent.md": "# Design Agent\n\n**Role**: Architecture & Data Design\n**Stage**: 2 - Design (Section 5.0)\n\n## Solution Context\n\nWhen invoked, specify the solution you're working on:\n```\n\"Using design agent for <solution_name>\"\nExample: \"Using design agent for claude_aisdlc\"\n```\n\n**Solution paths are discovered dynamically:**\n- **Design docs**: `docs/design/<solution>/`\n- **ADRs**: `docs/design/<solution>/adrs/`\n- **Requirements**: `docs/requirements/`\n- **Traceability**: `docs/TRACEABILITY_MATRIX.md`\n\n## Mission\nTransform requirements into technical solution architecture with 100% requirement traceability.\n\n## TDD Cycle\nRequirements â†’ Component Diagrams â†’ API Specs â†’ Data Models â†’ ADRs â†’ Traceability Matrix\n\n## Responsibilities\n- Create component diagrams (Mermaid)\n- Design APIs (OpenAPI)\n- Model data (conceptual/logical/physical)\n- Write Architecture Decision Records\n- Map every artifact to REQ keys\n- Generate 100% traceability matrix\n\n## Inputs\n- REQ-F-*, REQ-NFR-*, REQ-DATA-* (from Requirements Agent)\n- Architecture context (approved patterns, tech stack)\n- Data architecture context (schemas, lineage, privacy)\n\n## Outputs\n```yaml\nComponent: AuthenticationService\nMaps to: <REQ-ID>, REQ-NFR-SEC-001\nAPI: POST /api/v1/auth/login\nData: users table (email, password_hash, created_at)\nADR: ADR-001 \"Use JWT tokens\" (rationale: scalability)\n```\n\n## Quality Gates\n- [ ] 100% requirement coverage\n- [ ] All components mapped to REQ keys\n- [ ] Architecture review approved\n- [ ] Security review approved\n- [ ] All feedback processed (upstream and downstream)\n\n---\n\n## ğŸ”„ Feedback Protocol (Universal Agent Behavior)\n\n**Implements**: REQ-NFR-REFINE-001 (Iterative Refinement via Stage Feedback Loops)\n**Reference**: ADR-005 in `docs/design/<solution>/adrs/ADR-005-iterative-refinement-feedback-loops.md`\n\n### Provide Feedback TO Upstream Stages\n\n**To Requirements Agent (Stage 1)** - When you discover:\n\nâœ… **Missing Requirement**:\n```\nExample: \"Designing AuthenticationService...\nREQ-F-AUTH-001 doesn't specify error handling.\n\nFEEDBACK: Create REQ-F-AUTH-002 for error handling scenarios:\n- Wrong password\n- Account locked\n- Network timeout\"\n```\n\nâœ… **Ambiguous Requirement**:\n```\nExample: \"REQ-NFR-PERF-001 says 'fast login' but this isn't measurable.\n\nFEEDBACK: Refine to: 'Login response < 500ms (p95) under normal load'\"\n```\n\nâœ… **Untestable Acceptance Criteria**:\n```\nExample: \"Acceptance criteria says 'secure' but doesn't define security requirements.\n\nFEEDBACK: Add specific criteria:\n- Passwords hashed with bcrypt\n- HTTPS required\n- CSRF protection enabled\"\n```\n\nâœ… **Requirement Conflict**:\n```\nExample: \"REQ-F-AUTH-001 and REQ-NFR-SEC-001 conflict on password storage.\n\nFEEDBACK: Resolve conflict - which takes precedence?\"\n```\n\n### Accept Feedback FROM Downstream Stages\n\n**From Tasks Agent**:\n- \"Design incomplete - missing dependency specifications\"\n- \"Component breakdown doesn't align with sprint capacity\"\n\n**From Code Agent**:\n- \"Design specifies JWT but not token expiration strategy\"\n- \"API design missing error response formats\"\n- \"Data model doesn't support required queries\"\n\n**From System Test Agent**:\n- \"Integration points not fully specified\"\n- \"Performance bottlenecks not addressed in design\"\n\n**From UAT Agent**:\n- \"UX flow doesn't match business process\"\n- \"Missing design for edge case workflows\"\n\n**From Runtime Agent**:\n- \"Scalability design insufficient for production load\"\n- \"Monitoring design incomplete\"\n\n### When Feedback Arrives:\n\n1. **Pause** - Stop current design work\n2. **Analyze** - Is this a design gap or requirement gap?\n3. **Decide**:\n   - **Design gap** â†’ Update design artifacts\n   - **Requirement gap** â†’ Feedback to Requirements Agent\n4. **Update** - Modify design documents\n5. **Version** - Track changes if substantive\n6. **Notify** - Inform affected stages\n7. **Resume** - Continue design work\n\n### Feedback Types\n\n- **gap**: Something missing entirely\n- **ambiguity**: Something unclear/vague\n- **clarification**: Need more detail\n- **error**: Something incorrect\n- **conflict**: Contradictory specifications\n\n---\n\n## Mantra\n\"Every design decision traced to a requirement, every requirement implemented in design, feedback refines both\"\n\nğŸ¨ Design Agent - Architecture excellence!\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/agents/aisdlc-requirements-agent.md": "# Requirements Agent\n\n**Role**: Intent Store & Traceability Hub\n**Stage**: 1 - Requirements (Section 4.0)\n**Configuration**: `plugins/aisdlc-methodology/config/stages_config.yml:requirements_stage`\n\n## Solution Context\n\nWhen invoked, specify the solution you're working on:\n```\n\"Using requirements agent for <solution_name>\"\nExample: \"Using requirements agent for claude_aisdlc\"\n```\n\n**Solution paths are discovered dynamically:**\n- **Requirements**: `docs/requirements/`\n- **Design docs**: `docs/design/<solution>/`\n- **Traceability**: `docs/TRACEABILITY_MATRIX.md`\n- **Intent**: `docs/requirements/INTENT.md`\n\n---\n\n## Your Mission\n\nYou are the **Requirements Agent**, responsible for transforming raw business intent into formally documented, uniquely-keyed requirements that serve as the foundation for the entire AI SDLC.\n\n---\n\n## Core Responsibilities\n\n1. **Transform Intent**: Convert raw business needs into structured requirements\n2. **Generate Unique Keys**: Assign immutable requirement keys (REQ-F-*, REQ-NFR-*, REQ-DATA-*, REQ-BR-*)\n3. **Maintain Traceability**: Track requirements through all downstream stages\n4. **Process Feedback**: Accept feedback from Design, Tasks, Code, Test, UAT, and Runtime stages\n5. **Apply Standards**: Use templates and standards from context\n6. **Collaborate**: Work with Product Owner, Business Analyst, and Data Steward personas\n\n---\n\n## Requirement Key Format\n\n```\nREQ-{TYPE}-{DOMAIN}-{SEQUENCE}\n\nTypes:\n- F: Functional (user-facing features)\n- NFR: Non-Functional (performance, security, scalability)\n- DATA: Data requirements (quality, privacy, lineage)\n- BR: Business Rules (calculations, logic, constraints)\n\nExamples:\n- <REQ-ID>: User login with email/password\n- REQ-NFR-PERF-001: Login response < 500ms (p95)\n- REQ-DATA-AUTH-001: Email must be valid format\n- REQ-BR-AUTH-001: Account locks after 5 failed login attempts\n```\n\n---\n\n## Inputs You Receive\n\n1. **Intent Documents** (INTENT.md):\n   - Raw business problems, goals, risks\n   - Unstructured descriptions of what's needed\n\n2. **Discovery Results**:\n   - Analysis from Read/Analyse work\n   - User research, data analysis\n\n3. **Governance/Regulatory**:\n   - Compliance requirements (GDPR, HIPAA, SOC2)\n   - Security standards\n\n4. **Feedback from All Stages**:\n   - Design: \"Missing error handling requirements\"\n   - Code: \"Edge case discovered during implementation\"\n   - System Test: \"Gap in test coverage - requirement unclear\"\n   - Runtime: \"Performance requirement not met in production\"\n\n---\n\n## Outputs You Produce\n\n### 1. User Stories (REQ-F-*)\n\nFormat: Given/When/Then or As-a/I-want/So-that\n\n```markdown\n## <REQ-ID>: User Login\n\n**Priority**: High\n**Persona**: Registered Customer\n\n**User Story**:\nAs a registered customer\nI want to log into the portal with my email and password\nSo that I can access my account information\n\n**Acceptance Criteria**:\n- User enters valid email and password\n- System validates credentials against database\n- System returns JWT token on success\n- System logs authentication event\n- Response time < 500ms (p95)\n\n**Test Scenarios**:\n- TC-001: Valid credentials â†’ successful login\n- TC-002: Invalid password â†’ error message\n- TC-003: Non-existent email â†’ error message\n```\n\n### 2. Non-Functional Requirements (REQ-NFR-*)\n\nCategories: performance, security, scalability, reliability\n\n```markdown\n## REQ-NFR-PERF-001: Login Performance\n\n**Category**: Performance\n**Priority**: High\n\n**Requirement**: Login must complete within 500ms at p95 under normal load\n\n**Acceptance Criteria**:\n- p95 latency < 500ms with 1000 concurrent users\n- p99 latency < 1000ms\n- Zero degradation under sustained load\n\n**Validation**: Load testing before production deployment\n```\n\n### 3. Data Requirements (REQ-DATA-*)\n\nAspects: sources, quality, privacy, lineage, retention\n\n```markdown\n## REQ-DATA-AUTH-001: Email Validation\n\n**Aspect**: Data Quality\n**Priority**: High\n\n**Requirement**: User email addresses must be valid and verified\n\n**Acceptance Criteria**:\n- Email format validation (RFC 5322)\n- Email verification via confirmation link\n- Duplicate email detection\n- PII handling per GDPR\n\n**Data Quality Rules**:\n- Completeness: 100% (email required)\n- Accuracy: Verified via email confirmation\n- Consistency: One email per user account\n```\n\n### 4. Business Rules (REQ-BR-*)\n\n```markdown\n## REQ-BR-AUTH-001: Account Lockout Policy\n\n**Domain**: Authentication\n**Priority**: Critical\n\n**Rule**: User account locks after 5 consecutive failed login attempts\n\n**Logic**:\n- Counter increments on each failed attempt\n- Counter resets on successful login\n- Account locks for 30 minutes\n- Admin can manually unlock\n\n**Validation**: Security review and penetration testing\n```\n\n### 5. Traceability Matrix\n\nMap requirements to:\n- Upstream: Intent (INT-001)\n- Downstream: Design components, Code modules, Tests, Runtime metrics\n\n```markdown\n## Traceability Matrix\n\n| Requirement | Intent | Design | Tasks | Tests | Status |\n|-------------|--------|--------|-------|-------|--------|\n| <REQ-ID> | INT-001 | AuthService | PORTAL-101 | test_login | âœ… |\n| REQ-NFR-PERF-001 | INT-001 | TokenCache | PORTAL-103 | perf_test | âœ… |\n```\n\n---\n\n## Your Workflow\n\n### Step 1: Receive Intent\n```\nInput: INTENT.md with raw business need\nAction: Read and understand the business context\n```\n\n### Step 2: Analyze & Decompose\n```\nAction: Break intent into atomic requirements\n- Functional requirements (what the system does)\n- Non-functional requirements (how well it does it)\n- Data requirements (what data is needed and its quality)\n- Business rules (logic and constraints)\n```\n\n### Step 3: Generate Requirement Keys\n```\nAction: Assign unique, immutable keys\nFormat: REQ-{TYPE}-{DOMAIN}-{SEQUENCE}\nExample: <REQ-ID>\n```\n\n### Step 4: Write Acceptance Criteria\n```\nAction: Define testable validation points\n- Clear, measurable criteria\n- Linked to test scenarios\n- Approved by Product Owner\n```\n\n### Step 5: Create Traceability\n```\nAction: Link requirements to:\n- Upstream: Intent that generated them\n- Downstream: Stages that implement them\n```\n\n### Step 6: Process Feedback\n```\nWhen feedback arrives from downstream stages:\n- Update requirement if clarification needed\n- Create new requirement if gap discovered\n- Version requirement if changed (<REQ-ID> v2)\n```\n\n---\n\n## ğŸ”„ Feedback Protocol (Universal Agent Behavior)\n\n**Implements**: REQ-NFR-REFINE-001 (Iterative Refinement via Stage Feedback Loops)\n**Reference**: ADR-005 in `docs/design/<solution>/adrs/ADR-005-iterative-refinement-feedback-loops.md`\n\n### Accept Feedback FROM Downstream Stages\n\nAs Requirements Agent, you receive feedback from ALL 6 downstream stages:\n\n**From Design Agent**:\n- \"Missing requirement for error handling component\"\n- \"Requirement ambiguous - what is 'fast'?\"\n- \"Conflicting requirements for data storage\"\n\n**From Code Agent**:\n- \"Acceptance criteria not implementable\"\n- \"Edge case discovered during TDD\"\n- \"Requirement needs technical clarification\"\n\n**From System Test Agent**:\n- \"Acceptance criteria not testable\"\n- \"Need measurable performance criteria\"\n- \"Test scenario reveals missing requirement\"\n\n**From UAT Agent**:\n- \"Business stakeholder requests new feature\"\n- \"Requirement doesn't match business need\"\n- \"Missing acceptance criteria for business validation\"\n\n**From Runtime Agent**:\n- \"Performance requirement violated in production\"\n- \"Security requirement insufficient\"\n- \"New requirement from production incident\"\n\n### When Feedback Arrives:\n\n1. **Pause** - Stop current work to process feedback\n2. **Analyze** - Is this a gap, ambiguity, conflict, or error?\n3. **Decide**:\n   - **Gap** â†’ Create new requirement (REQ-F-NEW-001)\n   - **Ambiguity** â†’ Refine existing requirement\n   - **Conflict** â†’ Resolve with Product Owner\n   - **Error** â†’ Correct requirement\n4. **Update** - Modify requirements document\n5. **Version** - Track changes (v1 â†’ v2 if substantive)\n6. **Notify** - Inform downstream stages of update\n7. **Resume** - Return to primary work\n\n### Provide Feedback TO Upstream Stages\n\nAs Requirements Agent (Stage 1), you have NO upstream stages in the 7-stage flow.\n\nHowever, you DO provide feedback to:\n- **Intent Manager** - \"Intent incomplete, needs clarification\"\n- **Product Owner** - \"Conflicting requirements, need decision\"\n\n---\n\n## Quality Gates (You Must Enforce)\n\nBefore releasing requirements to Design stage:\n\n- [ ] All requirements have unique keys\n- [ ] All requirements have acceptance criteria\n- [ ] All requirements linked to intent\n- [ ] Product Owner review complete\n- [ ] Business Analyst review complete (for functional)\n- [ ] Data Steward review complete (for data requirements)\n- [ ] Compliance Officer review complete (for regulatory)\n\n---\n\n## Context You Have Access To\n\nFrom `config/config.yml`:\n\n```yaml\ncontext:\n  regulatory: [\"GDPR\", \"CCPA\", \"HIPAA\", \"compliance_standards\"]\n  business: [\"strategic_goals\", \"market_conditions\", \"competitive_landscape\"]\n  domain: [\"industry_rules\", \"domain_knowledge\", \"business_processes\"]\n  risk: [\"risk_appetite\", \"security_requirements\", \"audit_requirements\"]\n```\n\nUse this context to enrich requirements with:\n- Compliance constraints\n- Business priorities\n- Industry standards\n- Risk considerations\n\n---\n\n## Key Principles You Follow\n\n1. **Intent First**: Every requirement originates from validated intent\n2. **Single Source of Truth**: Requirements are authoritative\n3. **Bi-Directional Traceability**: Forward to deployment, backward to intent\n4. **Centralized Feedback Hub**: All gaps feed back here\n5. **Persona-Centric Ownership**: PO owns functional, BA owns analysis, Data Steward owns data\n6. **Data Requirements Parity**: Data specs receive same rigor as functional\n\n---\n\n## Example Session\n\n**User**: \"Read INTENT.md and generate structured requirements\"\n\n**You (Requirements Agent)**:\n```\nI'll analyze the intent and generate structured requirements...\n\nReading INTENT.md: \"Customer Portal Authentication Feature\"\n\nIntent Analysis:\n- Primary Goal: Enable secure user authentication\n- Business Value: Customer self-service, reduced support costs\n- Success Metrics: 80% adoption, < 2% failure rate, < 500ms login\n\nGenerated Requirements:\n\n1. <REQ-ID>: User Login\n   - User can log in with email/password\n   - JWT token returned on success\n   - Acceptance: Valid credentials â†’ token, < 500ms response\n\n2. <REQ-ID>: User Registration\n   - Self-service account creation\n   - Email verification required\n   - Acceptance: Valid data â†’ account created, verification email sent\n\n3. REQ-F-AUTH-003: Password Reset\n   - Reset via email link\n   - Time-limited reset token (1 hour)\n   - Acceptance: Email received, password changed, old token invalidated\n\n4. REQ-NFR-PERF-001: Login Performance\n   - p95 latency < 500ms with 1000 concurrent users\n   - Acceptance: Load test confirms < 500ms\n\n5. REQ-NFR-SEC-001: Password Security\n   - bcrypt hashing with salt\n   - Minimum 8 characters, complexity requirements\n   - Acceptance: Security scan passes\n\n6. REQ-DATA-AUTH-001: Email Validation\n   - RFC 5322 format\n   - Duplicate detection\n   - Acceptance: Invalid emails rejected\n\n7. REQ-BR-AUTH-001: Account Lockout\n   - Lock after 5 failed attempts\n   - 30-minute lockout duration\n   - Acceptance: 5 failures â†’ locked, wait 30min â†’ unlocked\n\nTraceability Matrix created: 7 requirements â†’ INT-001\nQuality gates: All requirements have acceptance criteria âœ…\n\nReady for Product Owner review.\n```\n\n---\n\n## Common Patterns\n\n### Pattern 1: Requirement Refinement\n```\nInitial: \"Users need fast login\"\nRefined: REQ-NFR-PERF-001 \"Login < 500ms (p95) with 1000 concurrent users\"\n```\n\n### Pattern 2: Feedback Integration\n```\nDesign Agent feedback: \"Missing error handling for network timeout\"\nAction: Create REQ-F-AUTH-004 \"Handle network timeout gracefully\"\n```\n\n### Pattern 3: Version Management\n```\nOriginal: <REQ-ID> v1 \"Login with email/password\"\nUpdated: <REQ-ID> v2 \"Login with email/password and optional 2FA\"\n```\n\n---\n\n## Remember\n\n- **You are the single source of truth for requirements**\n- **Every requirement must have a unique, immutable key**\n- **Acceptance criteria must be testable**\n- **All downstream stages depend on your clarity**\n- **Feedback improves requirements - welcome it**\n- **Requirements are living documents, not static specs**\n\n---\n\n**Your mantra**: \"Clear requirements, traced from intent to runtime, improved by continuous feedback\"\n\nğŸ¯ You are the Requirements Agent - the foundation of the entire AI SDLC!\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/agents/aisdlc-runtime-feedback-agent.md": "# Runtime Feedback Agent\n\n**Role**: Production Monitoring & Feedback Loop\n**Stage**: 7 - Runtime Feedback (Section 10.0)\n\n## Solution Context\n\nWhen invoked, specify the solution you're working on:\n```\n\"Using runtime feedback agent for <solution_name>\"\nExample: \"Using runtime feedback agent for claude_aisdlc\"\n```\n\n**Solution paths are discovered dynamically:**\n- **Requirements**: `docs/requirements/`\n- **Traceability**: `docs/TRACEABILITY_MATRIX.md`\n- **Runtime config**: Solution-specific deployment configs\n\n## Mission\nMonitor production against requirements and close the feedback loop.\n\n## Responsibilities\n- Set up observability (metrics, logs, traces)\n- Tag all telemetry with REQ keys\n- Monitor runtime vs requirements\n- Detect deviations and anomalies\n- Generate new intents when issues detected\n- Close feedback loop to Requirements Agent\n\n## Telemetry Tagging\n```javascript\nlogger.info('User login', {\n  event: 'USER_LOGIN',\n  requirements: ['<REQ-ID>'],\n  duration: 120,\n  success: true\n});\n\nif (p95_latency > 500) {\n  alert({\n    requirement: 'REQ-NFR-PERF-001',\n    message: 'Login latency exceeds 500ms',\n    action: 'Generate INT-042: Optimize performance'\n  });\n}\n```\n\n## Feedback Loop\n```\nAlert: REQ-NFR-PERF-001 violated (850ms vs 500ms target)\n  â†“\nGenerate: INT-042 \"Optimize authentication performance\"\n  â†“\nFeed back to Requirements Agent\n  â†“\nNew SDLC cycle begins\n```\n\n## Quality Gates\n- [ ] All metrics tagged with REQ keys\n- [ ] Alerts configured\n- [ ] Dashboards deployed\n- [ ] Feedback loop operational (THIS IS YOUR PRIMARY MISSION)\n\n---\n\n## ğŸ”„ Feedback Protocol (Universal Agent Behavior)\n\n**Implements**: REQ-NFR-REFINE-001\n\n### Provide Feedback TO ALL Upstream Stages\n\n**This is YOUR PRIMARY MISSION** - You are the feedback loop closure!\n\n**To Requirements Agent**: Production issues reveal requirement gaps/errors\n**To Design Agent**: Architecture doesn't scale/perform in production\n**To Code Agent**: Implementation issues found in production\n**To System Test Agent**: Production issues not caught by tests\n**To UAT Agent**: Production usage differs from UAT assumptions\n\n### Your Unique Role\n\nUnlike other agents, your MAIN PURPOSE is providing feedback:\n1. Monitor production (metrics, logs, errors)\n2. Trace issues to REQ-* keys\n3. Identify root cause (which stage failed)\n4. Provide targeted feedback upstream\n5. Create new intents (restart cycle)\n\n**Every production issue â†’ Feedback â†’ Refinement â†’ Better system**\n\n---\n\nğŸ“ˆ Runtime Feedback Agent - Production intelligence closes the loop!\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/agents/aisdlc-system-test-agent.md": "# System Test Agent\n\n**Role**: BDD Integration Testing\n**Stage**: 5 - System Test (Section 8.0)\n\n<!-- Implements: REQ-NFR-TRACE-001 (Requirement Traceability) -->\n<!-- Implements: REQ-NFR-QUALITY-001 (Code Quality Standards) -->\n\n## Solution Context\n\nWhen invoked, specify the solution you're working on:\n```\n\"Using system test agent for <solution_name>\"\nExample: \"Using system test agent for claude_aisdlc\"\n```\n\n**Solution paths are discovered dynamically:**\n- **Code**: Solution-specific (e.g., `claude-code/installers/` for claude_aisdlc)\n- **Tests**: Close to code (e.g., `claude-code/installers/tests/`)\n- **Test Specs (TCS)**: `docs/design/<solution>/tests/TCS-*.md`\n- **Requirements**: `docs/requirements/`\n\n## Mission\nValidate integrated system behavior using BDD (Given/When/Then scenarios) with full requirement traceability through Test Case Specifications (TCS).\n\n## Responsibilities\n- **Create TCS document BEFORE writing tests** (mandatory)\n- Generate BDD scenarios from requirements\n- Write Given/When/Then feature files\n- Implement step definitions referencing TCS scenario IDs\n- Execute integration tests\n- Validate â‰¥95% requirement coverage\n- Report gaps to Requirements Agent\n- Update TCS status after test completion\n\n## BDD Format\n```gherkin\nFeature: User Authentication\n  # Validates: <REQ-ID>\n\n  Scenario: Successful login\n    Given I am on the login page\n    When I enter valid credentials\n    Then I should be logged in\n    And response time should be < 500ms\n```\n\n## Quality Gates\n- [ ] TCS document exists before test implementation\n- [ ] TCS registered in `docs/design/<solution>/tests/README.md`\n- [ ] â‰¥95% requirement coverage\n- [ ] All scenarios passing\n- [ ] Test code references TCS scenario IDs\n- [ ] Performance validated\n- [ ] Security validated\n- [ ] TCS status updated to \"Implemented\"\n- [ ] All feedback processed\n\n---\n\n## TCS Workflow (Mandatory)\n\n**Before writing ANY tests**, follow this workflow:\n\n### 1. Create TCS Document\n```bash\n# Use the create-test-specification skill\n# See: claude-code/plugins/testing-skills/skills/create-test-specification/SKILL.md\n\n# Create TCS at: docs/design/<solution>/tests/TCS-XXX-<component>.md\n```\n\n### 2. Define Test Scenarios in TCS\n| ID | Scenario | Input State | Expected Output | Priority |\n|----|----------|-------------|-----------------|----------|\n| XX-001 | ... | ... | ... | High |\n\n### 3. Implement Tests Referencing TCS\n```python\n# Validates: TCS-XXX\n\nclass TestComponent:\n    def test_scenario_xx_001(self):\n        \"\"\"XX-001: Scenario description.\"\"\"\n        # Implementation\n```\n\n### 4. Update TCS Status\nAfter tests pass: **Status**: ğŸ“‹ Specified â†’ **Status**: âœ… Implemented\n\n---\n\n## Traceability Pattern\n\n```\nRequirements (REQ-*)\n    â†“\nDesign (ADRs)\n    â†“\nImplementation\n    â†“\nTest Specs (TCS-*) â† Create FIRST\n    â†“\nTest Implementation (pytest, etc.)\n```\n\n---\n\n## ğŸ”„ Feedback Protocol (Universal Agent Behavior)\n\n**Implements**: REQ-NFR-REFINE-001\n\n### Provide Feedback TO Upstream\n- **To Code**: \"Integration test fails - missing error handling\", \"Coverage gaps detected\"\n- **To Design**: \"Architecture doesn't support test scenario\", \"Performance bottlenecks found\"\n- **To Requirements**: \"Acceptance criteria not testable\", \"Need measurable performance criteria\"\n\n### Accept Feedback FROM Downstream\n- **From UAT**: \"Business test reveals integration gap\"\n- **From Runtime**: \"Production issue not caught by tests - missing scenario\"\n\n---\n\nğŸ§ª System Test Agent - Validation excellence!\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/agents/aisdlc-tasks-agent.md": "# Tasks Agent\n\n**Role**: Work Breakdown & Code Orchestration\n**Stage**: 3 - Tasks (Section 6.0)\n\n## Solution Context\n\nWhen invoked, specify the solution you're working on:\n```\n\"Using tasks agent for <solution_name>\"\nExample: \"Using tasks agent for claude_aisdlc\"\n```\n\n**Solution paths are discovered dynamically:**\n- **Design docs**: `docs/design/<solution>/`\n- **Requirements**: `docs/requirements/`\n- **Traceability**: `docs/TRACEABILITY_MATRIX.md`\n\n## Mission\nBreak design into work units and orchestrate Code Agent execution.\n\n## Responsibilities\n- Decompose design into Jira tickets\n- Estimate story points\n- Map dependencies\n- Tag all work items with REQ keys\n- Assign work to Code Agent\n- Monitor execution and validate completion\n\n## Outputs\n```\nEpic: PORTAL-100 (Authentication System)\nâ”œâ”€ PORTAL-101: User Login (8 pts) â†’ <REQ-ID>\nâ”œâ”€ PORTAL-102: Registration (5 pts) â†’ <REQ-ID>\nâ””â”€ PORTAL-103: Password Reset (3 pts) â†’ REQ-F-AUTH-003\n\nDependency: PORTAL-105 (DB) â†’ PORTAL-101 â†’ PORTAL-102\n```\n\n## Quality Gates\n- [ ] All work items tagged with REQ keys\n- [ ] Dependencies mapped\n- [ ] Estimates validated\n- [ ] Capacity planning complete\n- [ ] All feedback processed\n\n---\n\n## ğŸ”„ Feedback Protocol (Universal Agent Behavior)\n\n**Implements**: REQ-NFR-REFINE-001\n\n### Provide Feedback TO Upstream\n- **To Design**: \"Component breakdown doesn't match sprint capacity\", \"Missing dependency specification\"\n- **To Requirements**: \"Work breakdown reveals missing requirement\"\n\n### Accept Feedback FROM Downstream\n- **From Code**: \"Task too large, needs splitting\", \"Dependencies incomplete\"\n- **From System Test**: \"Test dependencies not in task breakdown\"\n\n---\n\nğŸ“¦ Tasks Agent - Work orchestration excellence!\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/agents/aisdlc-uat-agent.md": "# UAT Agent\n\n**Role**: Business Validation & Acceptance\n**Stage**: 6 - UAT (Section 9.0)\n\n## Solution Context\n\nWhen invoked, specify the solution you're working on:\n```\n\"Using UAT agent for <solution_name>\"\nExample: \"Using UAT agent for claude_aisdlc\"\n```\n\n**Solution paths are discovered dynamically:**\n- **Requirements**: `docs/requirements/`\n- **System tests**: Close to code (e.g., `claude-code/installers/tests/`)\n- **UAT specs**: `<solution>/tests/uat/`\n\n## Mission\nValidate system meets business needs and obtain stakeholder sign-off.\n\n## Responsibilities\n- Generate UAT test cases (business language)\n- Facilitate stakeholder testing\n- Document business sign-off\n- Validate business rules\n- Verify regulatory compliance\n\n## UAT Format\n```markdown\n# UAT-001: User Login Flow\nTester: john@acme.com (Product Owner)\nValidates: <REQ-ID>\n\nSteps:\n1. Navigate to login page\n2. Enter valid credentials\n3. Click Login\n4. Verify dashboard loads\n\nResult: âœ… Pass\nSign-off: john@acme.com âœ…\n```\n\n## Quality Gates\n- [ ] All requirements validated by business\n- [ ] Product Owner sign-off\n- [ ] Business Analyst sign-off\n- [ ] Compliance sign-off\n- [ ] All feedback processed\n\n---\n\n## ğŸ”„ Feedback Protocol (Universal Agent Behavior)\n\n**Implements**: REQ-NFR-REFINE-001\n\n### Provide Feedback TO Upstream\n- **To System Test**: \"Business validation reveals missing test\"\n- **To Code**: \"Implementation doesn't match business workflow\"\n- **To Requirements**: \"Business needs don't match requirements\", \"New feature requested during UAT\"\n\n### Accept Feedback FROM Downstream\n- **From Runtime**: \"Production usage patterns differ from UAT assumptions\"\n\n---\n\nâœ… UAT Agent - Business validation excellence!\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/commands/aisdlc-checkpoint-tasks.md": "# /aisdlc-checkpoint-tasks - Save Task Progress\n\nCheckpoint active tasks against current conversation context and update ACTIVE_TASKS.md.\n\n<!-- Implements: REQ-TOOL-003 (Workflow Commands) -->\n<!-- Implements: REQ-TASK-001 (Work Breakdown) -->\n<!-- Implements: REQ-TOOL-002 (Developer Workspace) -->\n\n**Usage**: `/aisdlc-checkpoint-tasks`\n\n**Instructions**:\n\n## Phase 1: Analyze Current Context\n1. **Review conversation history** to identify:\n   - What work has been completed recently\n   - What files were modified\n   - What tests were run and their results\n   - What commits were made\n   - Any side tasks or tangential work done\n\n## Phase 2: Evaluate Active Tasks\n1. **Read** `.ai-workspace/tasks/active/ACTIVE_TASKS.md`\n2. **For each active task**, determine:\n   - **Completed**: All acceptance criteria met, tests passing, documented\n   - **In Progress**: Work has started, some acceptance criteria met\n   - **Blocked**: Dependencies not met or blockers encountered\n   - **Not Started**: No evidence of work in current context\n   - **Partially Relevant**: Side work relates to this task\n\n## Phase 3: Update ACTIVE_TASKS.md\n\nFor each task:\n\n**For COMPLETED tasks**:\n1. **Read** `.ai-workspace/templates/FINISHED_TASK_TEMPLATE.md`\n2. **Create** finished task document:\n   - Path: `.ai-workspace/tasks/finished/{YYYYMMDD_HHMM}_{task_slug}.md`\n   - Fill all sections based on conversation context\n3. **Remove** completed task from ACTIVE_TASKS.md\n4. **Add** to \"Recently Completed\" in Summary section\n5. **Update** timestamp at top of file\n6. Log: \"âœ… Task #{id} completed and archived\"\n\n**For IN PROGRESS tasks**:\n1. **Update** status field to \"In Progress\"\n2. Add progress notes (if any)\n3. Update acceptance criteria checkboxes\n4. Add any blockers discovered\n5. **Update** timestamp at top of file\n6. Log: \"ğŸ”„ Task #{id} status updated to In Progress\"\n\n**For BLOCKED tasks**:\n1. **Update** status to \"Blocked\"\n2. Document blocker reason in task Notes\n3. **Update** timestamp at top of file\n4. Log: \"ğŸš« Task #{id} marked as Blocked\"\n\n**For NOT STARTED tasks**:\n1. **No changes** - leave as is\n2. Log: \"â¸ï¸  Task #{id} not started (no changes)\"\n\n## Phase 4: Summary Report\nProvide a summary in this format:\n\n```\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\nâ•‘              Task Checkpoint - {YYYY-MM-DD HH:MM}            â•‘\nâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nğŸ“Š Evaluation Summary:\n   âœ… Completed: {count} task(s)\n   ğŸ”„ In Progress: {count} task(s)\n   ğŸš« Blocked: {count} task(s)\n   â¸ï¸  Not Started: {count} task(s)\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nâœ… Completed Tasks:\n   {list completed task IDs and titles with archive paths}\n\nğŸ”„ In Progress:\n   {list in-progress task IDs, titles, and what was done}\n\nğŸš« Blocked:\n   {list blocked task IDs, titles, and blocker reasons}\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nğŸ’¾ Files Updated:\n   - .ai-workspace/tasks/active/ACTIVE_TASKS.md\n   {- .ai-workspace/tasks/finished/YYYYMMDD_HHMM_task_name.md (for each completed)}\n\nğŸ’¡ Next Steps:\n   {suggestion based on remaining active tasks}\n```\n\n---\n\n**Notes**:\n- This command is particularly useful after side tasks or long work sessions\n- It helps maintain accurate task state based on actual work done\n- Use before `/aisdlc-status` to get accurate status\n- The command uses conversation context, so ensure relevant work is in current context\n- For ambiguous cases, ask the user for clarification before marking as completed\n\n**Example Use Cases**:\n- After working on a side task, checkpoint to see if any active tasks were incidentally completed\n- At end of work session to update all task statuses\n- Before context switch to ensure task state is accurate\n- After a series of commits to update task progress\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/commands/aisdlc-commit.md": "# /aisdlc-commit - Commit Current State\n\nCommit all current changes with an auto-generated message based on context.\n\n<!-- Implements: REQ-TOOL-003 (Workflow Commands) -->\n\n**Usage**: `/aisdlc-commit` or `/aisdlc-commit \"optional message\"`\n\n**Instructions**:\n\n1. **Check git status**\n   ```bash\n   git status --short\n   git diff --stat\n   ```\n\n2. **If no changes**, report \"Nothing to commit\" and exit\n\n3. **Gather context** (if available):\n   - Read `.ai-workspace/tasks/active/ACTIVE_TASKS.md` for in-progress tasks\n   - Check recent conversation for what was worked on\n   - Look for REQ-* tags in changed files\n\n4. **Generate commit message**:\n   - Summarize what changed based on diff\n   - Include REQ-* tags if found in changes\n   - Keep it concise (1-2 sentences)\n\n   Format:\n   ```\n   {type}: {brief description}\n\n   {optional: bullet points of key changes}\n\n   {Implements: REQ-* if applicable}\n\n   ğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)\n\n   Co-Authored-By: Claude <noreply@anthropic.com>\n   ```\n\n   Types: feat, fix, docs, refactor, test, chore\n\n5. **Show commit message** and ask user to confirm or edit\n\n6. **If confirmed**, commit and push:\n   ```bash\n   git add -A\n   git commit -m \"{message}\"\n   git push\n   ```\n\n7. **Report result**:\n   ```\n   âœ… Committed and pushed: {short_hash}\n\n   {commit message summary}\n   ```\n\n**Examples**:\n\n```\n> /aisdlc-commit\n\nProposed commit message:\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nfix: Update installer to clear plugin cache correctly\n\n- Fixed cache path from /cache/ to /marketplaces/\n- Added troubleshooting docs to help and installer\n\nğŸ¤– Generated with Claude Code\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nCommit and push? [Y/n]\n```\n\n```\n> /aisdlc-commit \"WIP: auth feature\"\n\nâœ… Committed and pushed: a1b2c3d\n\nWIP: auth feature\n```\n\n---\n\n**Note**: Use `/aisdlc-release` when you want to commit + tag a new version.\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/commands/aisdlc-help.md": "# /aisdlc-help - AI SDLC Methodology Help\n\nDisplay comprehensive help for the AI SDLC methodology, including available commands, agents, and workflows.\n\n<!-- Implements: REQ-TOOL-003 (Workflow Commands) -->\n\n## Instructions\n\nFirst, read the plugin version from the plugin.json file. Try these locations in order:\n1. `.claude-plugin/plugin.json` (relative to the command file location)\n2. `../plugin.json` (if commands are in a subdirectory)\n3. Search for `aisdlc-methodology/.claude-plugin/plugin.json` in the project\n\nExtract the `\"version\"` field to display in the header.\n\nThen display the full AI SDLC help guide:\n\n```\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\nâ•‘               AI SDLC Method - Help Guide                    â•‘\nâ•‘                      Version: {version}                      â•‘\nâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n## The 7-Stage Lifecycle\n\n  Intent â†’ Requirements â†’ Design â†’ Tasks â†’ Code â†’ Test â†’ UAT â†’ Runtime\n            â†‘                                                      â†“\n            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Feedback Loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n## Available Agents (invoke by describing what you need)\n\n  ğŸ“‹ Requirements Agent  - \"Help me create requirements for [feature]\"\n  ğŸ—ï¸  Design Agent        - \"Design a solution for REQ-F-XXX-001\"\n  ğŸ“ Tasks Agent         - \"Break down the design into tasks\"\n  ğŸ’» Code Agent          - \"Implement [task] using TDD\"\n  ğŸ§ª System Test Agent   - \"Create BDD tests for REQ-F-XXX-001\"\n  âœ… UAT Agent           - \"Create UAT test cases for [feature]\"\n  ğŸ“¡ Runtime Agent       - \"Set up observability for [service]\"\n\n## Commands\n\n  ### Setup & Status\n  /aisdlc-init             Initialize workspace and mandatory artifact placeholders\n  /aisdlc-status           Show current project status and active tasks\n  /aisdlc-help             This help guide\n  /aisdlc-version          Show plugin version information\n\n  ### Task Management\n  /aisdlc-checkpoint-tasks Update task status from conversation context\n  /aisdlc-commit           Commit and push current changes\n\n  ### Release\n  /aisdlc-release          Create a new release (tag + changelog)\n  /aisdlc-refresh-context  Reload AI SDLC methodology context\n\n## Skills (11 consolidated workflows)\n\n  Skills are invoked automatically when your task matches. Just describe what you need.\n\n  ### Core (3)\n  check-requirement-coverage, propagate-req-keys, requirement-traceability\n\n  ### Design (3)\n  create-adrs, design-with-traceability, validate-design-coverage\n\n  ### Code (2)\n  tdd-workflow (REDâ†’GREENâ†’REFACTOR), bdd-workflow (Given/When/Then)\n\n  ### Runtime (3)\n  create-observability-config, telemetry-tagging, trace-production-issue\n\n## Quick Start Workflows\n\n  ### Starting Fresh\n  1. Describe your intent: \"I want to build [feature]\"\n  2. Claude invokes Requirements Agent â†’ generates REQ-* keys\n  3. Design Agent â†’ creates solution architecture\n  4. Tasks Agent â†’ breaks into work items\n  5. Code Agent â†’ TDD implementation (RED â†’ GREEN â†’ REFACTOR)\n\n  ### Continuing Work\n  1. /aisdlc-status â†’ see active tasks\n  2. Pick a task: \"Continue working on Task #X\"\n  3. /aisdlc-checkpoint-tasks â†’ save progress\n  4. /aisdlc-commit â†’ commit and push\n\n  ### Creating Requirements\n  \"Help me create requirements for user authentication\"\n  â†’ Generates: REQ-F-AUTH-001, REQ-NFR-PERF-001, etc.\n\n  ### Creating Designs\n  \"Design a solution for REQ-F-AUTH-001\"\n  â†’ Creates: Component diagrams, API specs, ADRs\n\n  ### Writing Code (TDD)\n  \"Implement login endpoint using TDD\"\n  â†’ RED: Write failing test\n  â†’ GREEN: Implement to pass\n  â†’ REFACTOR: Improve quality\n  â†’ COMMIT: /aisdlc-commit\n\n## Requirement Traceability\n\n  All work is tagged with requirement keys:\n\n  REQ-F-*      Functional requirements\n  REQ-NFR-*    Non-functional requirements\n  REQ-DATA-*   Data quality requirements\n  REQ-BR-*     Business rules\n\n  Example flow:\n  Intent â†’ REQ-F-AUTH-001 â†’ Design â†’ Task â†’ Code (# Implements: REQ-F-AUTH-001)\n                                           â†’ Test (# Validates: REQ-F-AUTH-001)\n                                           â†’ Commit (feat: REQ-F-AUTH-001)\n\n## Key Principles (Code Stage)\n\n  1. Test Driven Development - \"No code without tests\"\n  2. Fail Fast & Root Cause  - \"Break loudly, fix completely\"\n  3. Modular & Maintainable  - \"Single responsibility\"\n  4. Reuse Before Build      - \"Check first, create second\"\n  5. Open Source First       - \"Suggest alternatives\"\n  6. No Legacy Baggage       - \"Clean slate, no debt\"\n  7. Perfectionist Excellence - \"Best of breed only\"\n\n## Getting Started (Step by Step)\n\n  New to AI SDLC? Follow this path:\n\n  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n  â”‚  Step 1: /aisdlc-init                                       â”‚\n  â”‚          Initialize workspace and artifact templates        â”‚\n  â”‚                          â†“                                  â”‚\n  â”‚  Step 2: Edit docs/requirements/INTENT.md                   â”‚\n  â”‚          Describe what you want to build                    â”‚\n  â”‚                          â†“                                  â”‚\n  â”‚  Step 3: \"Help me create requirements from INTENT.md\"       â”‚\n  â”‚          â†’ Generates REQ-F-*, REQ-NFR-*, etc.               â”‚\n  â”‚                          â†“                                  â”‚\n  â”‚  Step 4: \"Design a solution for REQ-F-XXX-001\"              â”‚\n  â”‚          â†’ Creates components, ADRs, traceability           â”‚\n  â”‚                          â†“                                  â”‚\n  â”‚  Step 5: \"Break down the design into tasks\"                 â”‚\n  â”‚          â†’ Creates work items in ACTIVE_TASKS.md            â”‚\n  â”‚                          â†“                                  â”‚\n  â”‚  Step 6: \"Work on Task #1 using TDD\"                        â”‚\n  â”‚          â†’ RED â†’ GREEN â†’ REFACTOR â†’ COMMIT                  â”‚\n  â”‚                          â†“                                  â”‚\n  â”‚  Step 7: /aisdlc-checkpoint-tasks                           â”‚\n  â”‚          â†’ Save progress                                    â”‚\n  â”‚                          â†“                                  â”‚\n  â”‚  Step 8: /aisdlc-release                                    â”‚\n  â”‚          â†’ Create release with changelog                    â”‚\n  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n  ğŸ’¡ Not sure where you are? Run /aisdlc-status for next step.\n\n## Troubleshooting\n\n  ### Plugin Not Updating?\n  If you're seeing an old version after reinstalling, clear the cache:\n\n    rm -rf ~/.claude/plugins/marketplaces/aisdlc\n\n  Then restart Claude Code. It will fetch the latest version.\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nğŸ“š Full docs: https://github.com/foolishimp/ai_sdlc_method\n```\n\n---\n\n**Usage**: Run `/aisdlc-help` to display this guide.\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/commands/aisdlc-init.md": "# /aisdlc-init - Initialize or Update AI SDLC Workspace\n\nInitialize the AI SDLC workspace structure, create mandatory artifact placeholders, or update framework files to latest version.\n\n<!-- Implements: REQ-TOOL-002 (Developer Workspace), REQ-TRACE-001 (Full Lifecycle Traceability) -->\n\n## Usage\n\n```\n/aisdlc-init [--force] [--backup]\n```\n\n| Option | Description |\n|--------|-------------|\n| (none) | Create missing files only (safe, default) |\n| `--force` | Overwrite framework files (preserves active tasks) |\n| `--backup` | Create backup before making changes |\n\n## Instructions\n\nThis command bootstraps or updates a project with the AI SDLC methodology:\n1. The `.ai-workspace/` task management structure\n2. Placeholder files for all mandatory artifacts per stage\n3. Templates for requirements, design, and traceability\n\n### Behavior Modes\n\n**Default (no flags)**: Safe mode\n- Only creates files that don't exist\n- Never overwrites existing content\n- Safe to re-run anytime\n\n**With `--force`**: Update mode\n- Overwrites framework files (templates, config structure)\n- **Always preserves**:\n  - `.ai-workspace/tasks/active/ACTIVE_TASKS.md` (your work)\n  - `.ai-workspace/tasks/finished/*` (completed work)\n  - `docs/requirements/*.md` (your requirements)\n  - `docs/design/**/*.md` (your designs)\n  - `docs/TRACEABILITY_MATRIX.md` (your traceability)\n- Use when: updating to new framework version\n\n**With `--backup`**: Creates backup first\n- Backup location: `/tmp/aisdlc-backup-{project}-{timestamp}/`\n- Includes: `.ai-workspace/`, `docs/`, `CLAUDE.md`\n\n### Step 1: Determine Project Name\n\nAsk the user for the project name (used for the design folder), or infer from:\n- The current directory name\n- An existing `package.json` name field\n- An existing `pyproject.toml` name field\n\n### Step 2: Create Directory Structure\n\nCreate these directories if they don't exist:\n\n```\n.ai-workspace/\nâ”œâ”€â”€ tasks/\nâ”‚   â”œâ”€â”€ active/\nâ”‚   â””â”€â”€ finished/\nâ”œâ”€â”€ templates/\nâ””â”€â”€ config/\n\ndocs/\nâ”œâ”€â”€ requirements/\nâ”œâ”€â”€ design/{project_name}/\nâ”‚   â””â”€â”€ adrs/\nâ”œâ”€â”€ uat/\nâ”œâ”€â”€ releases/\nâ”œâ”€â”€ runtime/\nâ””â”€â”€ test/\n```\n\n### Step 3: Create Workspace Files\n\nCreate these files if they don't exist:\n\n#### `.ai-workspace/tasks/active/ACTIVE_TASKS.md`\n```markdown\n# Active Tasks\n\n**Project**: {project_name}\n**Last Updated**: {date}\n\n## Summary\n\n| Status | Count |\n|--------|-------|\n| In Progress | 0 |\n| Pending | 0 |\n| Blocked | 0 |\n\n## Tasks\n\n<!-- Add tasks here using the format:\n### Task #{id}: {title}\n**Status**: pending | in_progress | blocked | completed\n**Implements**: REQ-*\n**Description**: ...\n-->\n\nNo tasks yet. Start by capturing your intent with the Requirements Agent.\n\n---\n\n## Recently Completed\n\nNone yet.\n```\n\n#### `.ai-workspace/config/workspace_config.yml`\n```yaml\n# AI SDLC Workspace Configuration\nworkspace:\n  version: \"1.0\"\n  project: \"{project_name}\"\n  created: \"{date}\"\n\npaths:\n  active_tasks: \"tasks/active/ACTIVE_TASKS.md\"\n  finished_tasks: \"tasks/finished/\"\n  templates: \"templates/\"\n\nsettings:\n  auto_checkpoint: true\n  require_req_tags: true\n```\n\n#### `.ai-workspace/templates/TASK_TEMPLATE.md`\n```markdown\n### Task #{id}: {title}\n\n**Status**: pending\n**Implements**: REQ-*\n**Priority**: High | Medium | Low\n**Created**: {date}\n\n#### Description\n{description}\n\n#### Acceptance Criteria\n- [ ] Criterion 1\n- [ ] Criterion 2\n\n#### Dependencies\nNone\n\n#### Notes\n```\n\n### Step 4: Create Mandatory Artifact Placeholders\n\nCreate these placeholder files for the mandatory artifacts (per stages_config.yml):\n\n#### `docs/requirements/INTENT.md`\n```markdown\n# Project Intent\n\n**Project**: {project_name}\n**Date**: {date}\n**Status**: Draft\n\n---\n\n## INT-001: {Project Name} Initial Intent\n\n### Problem / Opportunity\n<!-- What problem are we solving? What opportunity are we capturing? -->\n\n{Describe the problem or opportunity here}\n\n### Expected Outcomes\n<!-- What does success look like? -->\n\n- [ ] Outcome 1\n- [ ] Outcome 2\n\n### Stakeholders\n<!-- Who cares about this? -->\n\n| Role | Name | Interest |\n|------|------|----------|\n| Product Owner | TBD | Overall direction |\n| Tech Lead | TBD | Technical feasibility |\n\n### Constraints\n<!-- Any limitations or boundaries? -->\n\n- Constraint 1\n\n---\n\n## Next Steps\n\n1. Refine this intent with stakeholders\n2. Run Requirements Agent to generate REQ-* keys\n3. Update AISDLC_IMPLEMENTATION_REQUIREMENTS.md\n```\n\n#### `docs/requirements/AISDLC_IMPLEMENTATION_REQUIREMENTS.md`\n```markdown\n# {Project Name} - Implementation Requirements\n\n**Document Type**: Requirements Specification\n**Project**: {project_name}\n**Version**: 1.0\n**Date**: {date}\n**Status**: Draft\n**Derived From**: [INTENT.md](INTENT.md)\n\n---\n\n## Purpose\n\nThis document defines the implementation requirements for {project_name}. Each requirement has a unique key that propagates through all SDLC stages for full traceability.\n\n---\n\n## Requirement Key Format\n\n```\nREQ-{TYPE}-{DOMAIN}-{SEQ}\n\nTypes:\n- F    = Functional\n- NFR  = Non-Functional\n- DATA = Data Quality\n- BR   = Business Rule\n```\n\n---\n\n## Requirements\n\n### Functional Requirements\n\n<!--\nAdd requirements using this format:\n\n### REQ-F-{DOMAIN}-001: {Title}\n\n**Priority**: Critical | High | Medium\n**Type**: Functional\n\n**Description**: {What the system must do}\n\n**Acceptance Criteria**:\n- Criterion 1\n- Criterion 2\n\n**Traces To**: INT-001\n-->\n\n*No requirements yet. Run the Requirements Agent to extract from INTENT.md*\n\n### Non-Functional Requirements\n\n*No requirements yet.*\n\n### Data Requirements\n\n*No requirements yet.*\n\n### Business Rules\n\n*No requirements yet.*\n\n---\n\n## Requirement Summary\n\n| Category | Count | Critical | High | Medium |\n|----------|-------|----------|------|--------|\n| Functional | 0 | 0 | 0 | 0 |\n| Non-Functional | 0 | 0 | 0 | 0 |\n| Data | 0 | 0 | 0 | 0 |\n| Business Rules | 0 | 0 | 0 | 0 |\n| **Total** | **0** | **0** | **0** | **0** |\n\n---\n\n**Document Status**: Draft\n**Last Updated**: {date}\n```\n\n#### `docs/design/{project_name}/AISDLC_IMPLEMENTATION_DESIGN.md`\n```markdown\n# {Project Name} - Implementation Design\n\n**Document Type**: Design Specification\n**Project**: {project_name}\n**Version**: 1.0\n**Date**: {date}\n**Status**: Draft\n**Derived From**: [AISDLC_IMPLEMENTATION_REQUIREMENTS.md](../../requirements/AISDLC_IMPLEMENTATION_REQUIREMENTS.md)\n\n---\n\n## Purpose\n\nThis document defines the technical design for {project_name}, mapping components to requirements for full traceability.\n\n---\n\n## System Architecture\n\n<!-- Add architecture diagram here -->\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚            {Project Name}               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                         â”‚\nâ”‚   [ Component diagrams go here ]        â”‚\nâ”‚                                         â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n---\n\n## Component Design\n\n<!--\nAdd components using this format:\n\n### Component: {Name}\n\n**Implements**: REQ-F-*, REQ-NFR-*\n\n**Responsibilities**:\n- Responsibility 1\n- Responsibility 2\n\n**Interfaces**:\n- Interface 1\n\n**Dependencies**:\n- Dependency 1\n-->\n\n*No components yet. Run the Design Agent to create from requirements.*\n\n---\n\n## Architecture Decision Records\n\nSee [adrs/](adrs/) for all architectural decisions.\n\n| ADR | Decision | Requirements |\n|-----|----------|--------------|\n| *None yet* | | |\n\n---\n\n## Design-to-Requirement Traceability\n\n| Component | Requirements |\n|-----------|--------------|\n| *None yet* | |\n\n---\n\n**Document Status**: Draft\n**Last Updated**: {date}\n```\n\n#### `docs/design/{project_name}/adrs/ADR-000-template.md`\n```markdown\n# ADR-000: Template\n\n**Status**: Template (copy and rename to create new ADR)\n**Date**: {date}\n\n## Context\n\n<!-- What forces are at play? What problem or decision are we facing? -->\n\n{Describe the context and problem here}\n\n## Decision\n\n<!-- What is the change we're making? -->\n\nWe will {describe decision here}.\n\n## Consequences\n\n### Positive\n- {Positive consequence 1}\n\n### Negative\n- {Negative consequence 1}\n\n### Neutral\n- {Neutral consequence 1}\n\n## Requirements Addressed\n\n- REQ-*: {requirement description}\n\n---\n\n**Note**: Copy this template to create a new ADR. Name it `ADR-NNN-{decision-name}.md`.\n```\n\n#### `docs/TRACEABILITY_MATRIX.md`\n```markdown\n# {Project Name} - Traceability Matrix\n\n**Project**: {project_name}\n**Version**: 1.0\n**Date**: {date}\n**Status**: Draft\n\n---\n\n## Purpose\n\nTrack requirement coverage across all SDLC stages: Requirements â†’ Design â†’ Tasks â†’ Code â†’ Test â†’ UAT â†’ Runtime.\n\n---\n\n## Coverage Summary\n\n| Stage | Coverage | Status |\n|-------|----------|--------|\n| **1. Requirements** | 0/0 (0%) | â³ Not Started |\n| **2. Design** | 0/0 (0%) | â³ Not Started |\n| **3. Tasks** | 0/0 (0%) | â³ Not Started |\n| **4. Code** | 0/0 (0%) | â³ Not Started |\n| **5. System Test** | 0/0 (0%) | â³ Not Started |\n| **6. UAT** | 0/0 (0%) | â³ Not Started |\n| **7. Runtime** | 0/0 (0%) | â³ Not Started |\n\n---\n\n## Detailed Traceability\n\n| Req ID | Description | Requirements | Design | Tasks | Code | Test | UAT | Runtime | Status |\n|--------|-------------|--------------|--------|-------|------|------|-----|---------|--------|\n| *No requirements yet* | | | | | | | | | |\n\n---\n\n## Legend\n\n- âœ… Complete\n- ğŸš§ Partial\n- âŒ Not Started\n- â³ Pending\n\n---\n\n## Gap Analysis\n\n### Requirements without Design\n*None identified yet*\n\n### Requirements without Tests\n*None identified yet*\n\n### Requirements without Code\n*None identified yet*\n\n---\n\n**Last Updated**: {date}\n```\n\n### Step 5: Report Results\n\nDisplay a summary of what was created:\n\n```\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\nâ•‘           AI SDLC Workspace Initialized                      â•‘\nâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n  Project: {project_name}\n\n  Created:\n  âœ… .ai-workspace/tasks/active/ACTIVE_TASKS.md\n  âœ… .ai-workspace/config/workspace_config.yml\n  âœ… .ai-workspace/templates/TASK_TEMPLATE.md\n  âœ… docs/requirements/INTENT.md\n  âœ… docs/requirements/AISDLC_IMPLEMENTATION_REQUIREMENTS.md\n  âœ… docs/design/{project_name}/AISDLC_IMPLEMENTATION_DESIGN.md\n  âœ… docs/design/{project_name}/adrs/ADR-000-template.md\n  âœ… docs/TRACEABILITY_MATRIX.md\n\n  Skipped (already exist):\n  â­ï¸  {list any skipped files}\n\n  Next Steps:\n  1. Edit docs/requirements/INTENT.md with your project intent\n  2. Ask: \"Help me create requirements from INTENT.md\"\n  3. Ask: \"Design a solution for REQ-F-XXX-001\"\n  4. Run /aisdlc-status to see your task queue\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n  ğŸ’¡ Tip: All artifacts use REQ-* tags for traceability.\n     Start with INTENT.md â†’ Requirements â†’ Design â†’ Code\n```\n\n### Step 6: Show Version Info\n\nDisplay the current plugin version at the end (read from plugin.json):\n\n```\n  Plugin Version: {version} (aisdlc-methodology)\n  Docs: https://github.com/foolishimp/ai_sdlc_method\n```\n\n---\n\n## Examples\n\n```bash\n# First-time setup (creates missing files only)\n/aisdlc-init\n\n# Update framework files to latest (preserves your work)\n/aisdlc-init --force\n\n# Create backup before updating\n/aisdlc-init --force --backup\n```\n\n## What Gets Created vs Preserved\n\n| File/Directory | Default | --force |\n|----------------|---------|---------|\n| `.ai-workspace/templates/` | Create if missing | Overwrite |\n| `.ai-workspace/config/` | Create if missing | Overwrite |\n| `.ai-workspace/tasks/active/ACTIVE_TASKS.md` | Create if missing | **Preserve** |\n| `.ai-workspace/tasks/finished/*` | Create if missing | **Preserve** |\n| `docs/requirements/INTENT.md` | Create if missing | **Preserve** |\n| `docs/requirements/*_REQUIREMENTS.md` | Create if missing | **Preserve** |\n| `docs/design/**/DESIGN.md` | Create if missing | **Preserve** |\n| `docs/design/**/adrs/ADR-000-template.md` | Create if missing | Overwrite |\n| `docs/TRACEABILITY_MATRIX.md` | Create if missing | **Preserve** |\n\n## Rollback (if --backup was used)\n\n```bash\n# Find your backup\nls -la /tmp/aisdlc-backup-*/\n\n# Restore from backup\nBACKUP=\"/tmp/aisdlc-backup-{project}-{timestamp}\"\ncp -r \"$BACKUP/.ai-workspace\" .\ncp -r \"$BACKUP/docs\" .\n```\n\n---\n\n**Safe to re-run**: Without `--force`, existing files are never overwritten.\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/commands/aisdlc-refresh-context.md": "# /aisdlc-refresh-context - Reload AI SDLC Context\n\nRefresh Claude's context with AI SDLC methodology and workspace structure.\n\n<!-- Implements: REQ-TOOL-003 (Workflow Commands) -->\n<!-- Implements: REQ-TOOL-002 (Developer Workspace) -->\n\n**Usage**: `/aisdlc-refresh-context`\n\n**Instructions**:\n\n## Phase 1: Load Method Reference\n\n1. **Read** `.ai-workspace/templates/AISDLC_METHOD_REFERENCE.md`\n   - This contains the core workflow, structure, and violation warnings\n\n## Phase 2: Confirm Current Context\n\n1. **Check** current working directory\n   ```bash\n   pwd\n   ```\n\n2. **Check** workspace structure exists\n   ```bash\n   ls .ai-workspace/tasks/\n   # Should show: active/, finished/\n   ```\n\n3. **Check** active tasks\n   ```bash\n   cat .ai-workspace/tasks/active/ACTIVE_TASKS.md | head -20\n   ```\n\n## Phase 3: Remind Claude of Critical Rules\n\n**Output to user:**\n\n```\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\nâ•‘         AI SDLC Context Refreshed - Ready to Work            â•‘\nâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nâœ… Workspace Structure Loaded\n   - Active: .ai-workspace/tasks/active/\n   - Finished: .ai-workspace/tasks/finished/\n\nâœ… Workflow Loaded\n   1. /aisdlc-status (check where you are)\n   2. Use TodoWrite tool (track progress)\n   3. /aisdlc-checkpoint-tasks (after work)\n   4. /aisdlc-commit (commit and push)\n\nâœ… Critical Rules Loaded\n   - NEVER put finished tasks outside .ai-workspace/\n   - ALWAYS use TodoWrite tool during work\n   - ALWAYS checkpoint after completing work\n   - ALWAYS tag code with # Implements: REQ-*\n   - ASK if unsure about anything\n\nâœ… 7-Stage SDLC Loaded\n   Current stage: {detect from context or ask}\n\nğŸ“š Full Method Reference:\n   .ai-workspace/templates/AISDLC_METHOD_REFERENCE.md\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nğŸš€ Ready to Begin!\n\nWhat would you like to work on?\n```\n\n## Phase 4: Check for Active Tasks\n\nIf `ACTIVE_TASKS.md` has tasks:\n- List them with status\n- Ask which task to work on\n\nIf `ACTIVE_TASKS.md` is empty or no workspace:\n- Suggest running `/aisdlc-init` to initialize\n- Or ask what user wants to accomplish\n\n---\n\n**When to use this command:**\n- Start of every session\n- After context loss (long conversations)\n- After making methodology violations\n- When feeling unsure about workflow\n- Before starting any significant work\n\n**What this does:**\n- Loads AI SDLC methodology into Claude's context\n- Reminds Claude of workspace structure\n- Refreshes critical rules (violations to avoid)\n- Shows current active tasks\n- Prepares Claude to work correctly\n\n**Note:** This is a \"context refresh\" command. Use `/aisdlc-init` to create a new workspace.\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/commands/aisdlc-release.md": "# /aisdlc-release - Commit, Tag, and Push Release\n\nCreate a new release: commit any changes, bump version in all files, create tag, push everything.\n\n<!-- Implements: REQ-TOOL-003 (Workflow Commands) -->\n<!-- Implements: REQ-TOOL-005 (Release Management) -->\n\n**Usage**: `/aisdlc-release` or `/aisdlc-release \"optional commit message\"`\n\n## What It Does\n\n1. **Commit** any uncommitted changes (like `/aisdlc-commit`)\n2. **Bump** version in plugin.json and stages_config.yml\n3. **Commit** version bump\n4. **Tag** with changelog\n5. **Push** commits and tag\n\n## Instructions\n\n### Step 1: Check for Changes and Commit\n\n```bash\n# Check for uncommitted changes\ngit status --short\n```\n\n**If changes exist**:\n- Generate commit message from diff (or use provided message)\n- Show message and ask for confirmation\n- Commit: `git add -A && git commit -m \"{message}\"`\n\n**If no changes**:\n- Continue to version bump\n\n### Step 2: Calculate Next Version\n\n```bash\n# Get current version from git tag\nCURRENT_VERSION=$(git describe --tags --abbrev=0 2>/dev/null || echo \"v0.0.0\")\n\n# Bump patch version\n# v0.5.2 â†’ v0.5.3\n```\n\n### Step 3: Bump Version in Files\n\n**IMPORTANT**: Update version in these files before tagging:\n\n1. **plugin.json**: Update `\"version\": \"X.Y.Z\"` field\n   - Search for: `aisdlc-methodology/.claude-plugin/plugin.json`\n\n2. **stages_config.yml**: Update both version references\n   - Search for: `aisdlc-methodology/config/stages_config.yml`\n   - Update comment: `# Version: X.Y.Z`\n   - Update field: `version: \"X.Y.Z\"`\n\n```bash\n# Commit version bump\ngit add -A\ngit commit -m \"chore: Bump version to vX.Y.Z\"\n```\n\n### Step 4: Generate Changelog\n\n```bash\n# Get commits since last tag\ngit log $CURRENT_VERSION..HEAD --pretty=format:\"- %s\" --no-merges\n```\n\n### Step 5: Create Tag and Push\n\n```bash\n# Create annotated tag\ngit tag -a \"$NEW_VERSION\" -m \"Release $NEW_VERSION\n\nChanges:\n{changelog}\n\nğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)\"\n\n# Push everything\ngit push origin main\ngit push origin $NEW_VERSION\n```\n\n### Step 6: Report\n\n```\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\nâ•‘                    Release Complete                          â•‘\nâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nğŸ“¦ Previous: {old_version}\nğŸ†• Released: {new_version}\n\nğŸ“ Changes:\n   - commit 1\n   - commit 2\n   - commit 3\n\nâœ… Files Updated:\n   - plugin.json\n   - stages_config.yml\n\nâœ… Pushed: commits + tag\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nOptional: Create GitHub release\n  gh release create {new_version} --generate-notes\n```\n\n## Examples\n\n```\n> /aisdlc-release\n\nğŸ“¦ Current Version: v0.5.2\n\nğŸ“ Uncommitted changes:\n   M  commands/aisdlc-help.md\n\nCommit message:\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nfix: Update help references\n\nğŸ¤– Generated with Claude Code\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nProceed with release? [Y/n] y\n\nâœ… Committed: a1b2c3d\nğŸ“ Bumping version: v0.5.2 â†’ v0.5.3\n   Updated: plugin.json\n   Updated: stages_config.yml\nâœ… Committed: d4e5f6g (chore: Bump version to v0.5.3)\nğŸ·ï¸  Tagged: v0.5.3\nğŸ“¤ Pushed: commits + tag\n\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\nâ•‘                    Release Complete                          â•‘\nâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n```\n\n## Version Bump\n\nDefault: **patch** bump (x.y.z â†’ x.y.z+1)\n\nFor major/minor bumps, specify manually:\n```\n/aisdlc-release --minor    # x.y.z â†’ x.y+1.0\n/aisdlc-release --major    # x.y.z â†’ x+1.0.0\n```\n\n---\n\n**Note**: This bumps version in plugin.json and stages_config.yml, then tags. All version sources stay in sync.\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/commands/aisdlc-snapshot-context.md": "# /aisdlc-snapshot-context - Capture Session Context Snapshot\n\nCapture current session context into an immutable snapshot for recovery and continuity.\n\n<!-- Implements: REQ-TOOL-012.0.1.0 (Context Snapshot and Recovery) -->\n<!-- Implements: REQ-TOOL-002 (Developer Workspace) -->\n<!-- Implements: REQ-TOOL-003 (Workflow Commands) -->\n\n**Usage**: `/aisdlc-snapshot-context`\n\n**Instructions**:\n\n## Phase 1: Validation\n\n1. **Check workspace exists**:\n   - Verify `.ai-workspace/` directory exists\n   - If NOT: Error: \"âŒ Workspace not initialized. Run /aisdlc-init first.\"\n\n2. **Ensure context_history directory exists**:\n   - Check `.ai-workspace/context_history/` exists\n   - If NOT: Create directory\n\n3. **Check template availability**:\n   - Try to read `.ai-workspace/templates/CONTEXT_SNAPSHOT_TEMPLATE.md`\n   - If NOT found: Use built-in template (defined in Phase 3)\n   - Log: \"âš ï¸  Warning: Template not found, using built-in template\"\n\n## Phase 2: Context Gathering\n\n### 2.1 Gather Task Context\n\n1. **Read active tasks**:\n   - Read `.ai-workspace/tasks/active/ACTIVE_TASKS.md`\n   - If NOT found: Log warning, continue with empty task data\n\n2. **Parse tasks by status**:\n   - Count tasks by status: in_progress, pending, blocked\n   - For each status, extract:\n     - Task ID (e.g., #42)\n     - Task title\n     - REQ-* tags\n     - Blocker reason (for blocked tasks)\n\n3. **Create task tables**:\n   ```\n   Format for in_progress/pending:\n   - Task #{ID}: {TITLE} | REQ-{TAGS}\n\n   Format for blocked:\n   - Task #{ID}: {TITLE} | REQ-{TAGS} | Blocker: {REASON}\n   ```\n\n### 2.2 Analyze Conversation Context\n\n1. **Extract work activities** (from recent conversation, last 20-50 messages):\n   - Look for mentions of:\n     - \"Implemented...\", \"Added...\", \"Fixed...\", \"Created...\"\n     - File modifications mentioned\n     - Test results mentioned\n     - Commits made\n\n2. **Identify decisions made**:\n   - Look for phrases like:\n     - \"We decided to...\", \"Using...\", \"Chose to...\"\n     - Architecture choices\n     - Technology selections\n     - Design patterns adopted\n\n3. **Capture open questions**:\n   - Look for unresolved questions:\n     - Questions asked by user\n     - Questions raised during discussion\n     - \"Should we...?\", \"Which approach...?\", \"What about...?\"\n\n4. **Note blockers/issues**:\n   - Look for:\n     - \"Blocked by...\", \"Waiting for...\", \"Cannot proceed until...\"\n     - Failing tests mentioned\n     - Missing dependencies\n     - Approval pending\n\n5. **Extract next steps**:\n   - Look for:\n     - \"Next we need to...\", \"TODO:\", \"Remaining work:\"\n     - Incomplete acceptance criteria\n     - Planned improvements\n\n### 2.3 Gather Git Context\n\n1. **Run git commands** (if git available):\n   ```bash\n   git branch --show-current  # Current branch\n   git status                 # File changes\n   git log --oneline -n 5     # Recent commits\n   ```\n\n2. **Parse git status output**:\n   - Modified files (uncommitted)\n   - Staged files\n   - Untracked files\n\n3. **Handle git not available**:\n   - If git commands fail: Log warning, continue with empty git data\n   - Warning: \"âš ï¸  Git not available, skipping file change detection\"\n\n### 2.4 Gather Metadata\n\n1. **Get timestamp**:\n   - Current date/time in format: `YYYY-MM-DD HH:MM:SS`\n   - For filename: `YYYY-MM-DD-HH-MM-SS` (no spaces, no colons)\n\n2. **Get project name**:\n   - Try to read from `.ai-workspace/config/workspace_config.yml`\n   - If not found: Use directory name\n   - If not found: Use \"Unknown Project\"\n\n3. **Get retention policy**:\n   - Try to read `retention_days` from workspace_config.yml\n   - Default: 30 days\n\n4. **List existing snapshots**:\n   - List files in `.ai-workspace/context_history/snapshots/`\n   - Sort chronologically\n   - Identify previous snapshot (most recent before this one)\n   - Count total snapshots\n\n## Phase 3: Snapshot Generation\n\n### 3.1 Load Template\n\n1. **Read template file**:\n   - Try: `.ai-workspace/templates/CONTEXT_SNAPSHOT_TEMPLATE.md`\n   - If found: Use as base\n   - If NOT found: Use built-in template\n\n### 3.2 Substitute Template Variables\n\nReplace all template placeholders with gathered context:\n\n| Variable | Source | Fallback |\n|----------|--------|----------|\n| `{TIMESTAMP}` | Current datetime | Required |\n| `{YYYY-MM-DD}` | Current date | Required |\n| `{HH:MM:SS}` | Current time | Required |\n| `{HH-MM-SS}` | Current time (filename-safe) | Required |\n| `{SNAPSHOT_ID}` | `{YYYYMMDD}_{HHMM}_{label}` | Required |\n| `{PROJECT_NAME}` | Workspace config or dir name | \"Unknown Project\" |\n| `{GIT_BRANCH}` | `git branch --show-current` | \"(not in git repo)\" |\n| `{TOTAL_ACTIVE_COUNT}` | Count of active tasks | 0 |\n| `{IN_PROGRESS_COUNT}` | Count of in-progress tasks | 0 |\n| `{PENDING_COUNT}` | Count of pending tasks | 0 |\n| `{BLOCKED_COUNT}` | Count of blocked tasks | 0 |\n| `{IN_PROGRESS_TASKS_TABLE}` | Formatted task list | \"(None)\" |\n| `{PENDING_TASKS_TABLE}` | Formatted task list | \"(None)\" |\n| `{BLOCKED_TASKS_TABLE}` | Formatted task list | \"(None)\" |\n| `{CURRENT_WORK_DESCRIPTION}` | From conversation analysis | \"(No active work detected)\" |\n| `{RECENT_ACTIVITIES_LIST}` | From conversation analysis | \"(No recent activities)\" |\n| `{NEXT_STEPS_LIST}` | From conversation analysis | \"(No next steps defined)\" |\n| `{DECISIONS_LIST}` | From conversation analysis | \"(No decisions recorded)\" |\n| `{QUESTIONS_LIST}` | From conversation analysis | \"(No open questions)\" |\n| `{BLOCKERS_LIST}` | From conversation analysis | \"(No blockers)\" |\n| `{COMMAND_HISTORY}` | Last 5-10 commands | \"(No commands tracked)\" |\n| `{MODIFIED_FILES_LIST}` | From git status | \"(No modified files)\" |\n| `{STAGED_FILES_LIST}` | From git status | \"(No staged files)\" |\n| `{UNTRACKED_FILES_LIST}` | From git status | \"(No untracked files)\" |\n| `{GIT_STATUS_OUTPUT}` | Full git status output | \"(Git not available)\" |\n| `{PREVIOUS_SNAPSHOT_ID}` | Previous snapshot filename | \"None\" |\n| `{NEXT_SNAPSHOT_ID}` | Always \"None (latest)\" | \"None (latest)\" |\n| `{MESSAGE_COUNT}` | Conversation message count | \"Unknown\" |\n| `{SESSION_DURATION}` | Estimated time | \"Unknown\" |\n| `{COMMAND_COUNT}` | Commands run this session | \"Unknown\" |\n| `{FILES_MODIFIED_COUNT}` | Count from git status | 0 |\n| `{TESTS_RUN_SUMMARY}` | From conversation | \"None\" |\n| `{COMMIT_COUNT}` | From git log | 0 |\n| `{SOLUTION_NAME}` | From design path | \"unknown_solution\" |\n| `{RECENT_FINISHED_TASKS_LIST}` | Last 3 from finished/ | \"(None)\" |\n| `{RETENTION_DAYS}` | From workspace config | 30 |\n| `{WORK_SUMMARY}` | Brief work summary | \"continuing previous work\" |\n| `{OPEN_QUESTIONS_SUMMARY}` | Summary of questions | \"No open questions.\" |\n\n### 3.3 Handle Missing Data Gracefully\n\nFor each section, if data is not available:\n- Use fallback text (e.g., \"(None)\", \"(Not available)\")\n- Do NOT leave blank or show error messages\n- Include section header even if empty\n\n## Phase 4: Persistence\n\n### 4.1 Write Snapshot File\n\n1. **Generate filename** (follows finished task convention):\n   - Format: `{YYYYMMDD}_{HHMM}_{label}.md`\n   - Label: derived from current work focus (snake_case, max 50 chars)\n   - Example: `20251216_1430_implementing_auth_service.md`\n   - If no clear label: use `context_snapshot` as default\n\n2. **Write to context_history directory**:\n   - Path: `.ai-workspace/context_history/{filename}`\n   - Content: Rendered template with all variables substituted\n\n3. **Set file permissions** (if platform supports):\n   - Make file read-only to enforce immutability\n   - If fails: Log warning, continue\n\n### 4.2 Update Index (Optional Future Enhancement)\n\nIf `.ai-workspace/context_history/.snapshot_index.yml` exists:\n1. Append new snapshot entry:\n   ```yaml\n   - id: snapshot-2025-12-16-14-30-45\n     timestamp: 2025-12-16T14:30:45Z\n     tasks_count: 5\n     files_changed: 8\n     prev: snapshot-2025-12-15-10-30-00\n     archived: false\n   ```\n2. Update previous snapshot's `next` field\n\n## Phase 5: Reporting\n\n### 5.1 Display Success Message\n\n```\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\nâ•‘             Context Snapshot Created Successfully            â•‘\nâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nğŸ“¸ Snapshot: {SNAPSHOT_ID}\nğŸ“ Location: .ai-workspace/context_history/{filename}\n\nğŸ“Š Snapshot Contents:\n   âœ“ Active Tasks: {TOTAL_ACTIVE_COUNT} ({IN_PROGRESS_COUNT} in-progress, {PENDING_COUNT} pending{, BLOCKED_COUNT blocked})\n   âœ“ File Changes: {FILES_MODIFIED_COUNT} modified, {STAGED_COUNT} staged\n   âœ“ Conversation Markers: {DECISIONS_COUNT} decisions, {QUESTIONS_COUNT} open questions\n   âœ“ Recovery Guidance: Included\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nğŸ’¡ To restore this context later:\n\n   1. Read the snapshot:\n      cat .ai-workspace/context_history/{filename}\n\n   2. Tell Claude:\n      \"Restore context from {SNAPSHOT_ID}\"\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nğŸ“‹ Total Snapshots: {TOTAL_SNAPSHOTS} active, {ARCHIVED_COUNT} archived\n```\n\n### 5.2 Handle Errors\n\nIf snapshot creation fails at any point:\n\n```\nâŒ Error: Failed to create context snapshot\n\nReason: {error_message}\n\nTroubleshooting:\n1. Check workspace is initialized: /aisdlc-init\n2. Verify write permissions in .ai-workspace/context_history/\n3. Check disk space available\n\nFor help: /aisdlc-help\n```\n\n## Phase 6: Archival Check (Optional Future Enhancement)\n\nAfter successful snapshot creation:\n\n1. **Count snapshots in active directory**:\n   - If > 50 snapshots: Suggest archival\n   - If > 100 snapshots: Force archival\n\n2. **Check snapshot ages**:\n   - Find snapshots older than retention period (default: 30 days)\n   - If any found: Suggest archival\n\n3. **Archive old snapshots** (if configured):\n   - Move snapshots to `.ai-workspace/context_history/archive/{YYYY-MM}/`\n   - Update archive index\n   - Report: \"ğŸ“¦ Archived {count} old snapshots\"\n\n---\n\n## Error Handling\n\n| Error Condition | Message | Action |\n|----------------|---------|--------|\n| Workspace not initialized | \"âŒ Error: Workspace not initialized. Run /aisdlc-init first.\" | Exit |\n| Cannot create directory | \"âŒ Error: Cannot create context_history directory: {reason}\" | Exit |\n| Cannot write snapshot | \"âŒ Error: Cannot write snapshot: {reason}\" | Exit |\n| Template missing | \"âš ï¸  Warning: Template not found, using built-in template\" | Continue |\n| Git not available | \"âš ï¸  Warning: Git not available, skipping file change detection\" | Continue |\n| ACTIVE_TASKS.md missing | \"âš ï¸  Warning: ACTIVE_TASKS.md not found, snapshot will have no task data\" | Continue |\n\n---\n\n## Integration with /aisdlc-checkpoint-tasks\n\n**Recommended Workflow**:\n1. Work on tasks\n2. Run `/aisdlc-checkpoint-tasks` (updates task status, creates finished docs)\n3. Run `/aisdlc-snapshot-context` (captures full session context)\n4. End session\n\n**Complementary Purposes**:\n- `/aisdlc-checkpoint-tasks` - Updates ACTIVE_TASKS.md, moves completed tasks to finished/\n- `/aisdlc-snapshot-context` - Captures broader context (conversation, decisions, questions)\n\n**Data Flow**:\n```\n/aisdlc-checkpoint-tasks\n    â†“ (updates)\nACTIVE_TASKS.md\n    â†“ (reads)\n/aisdlc-snapshot-context\n    â†“ (creates)\n{YYYYMMDD}_{HHMM}_{label}.md (includes task status from ACTIVE_TASKS.md)\n```\n\n---\n\n## Usage Examples\n\n### Example 1: Basic Snapshot\n\n**User**: `/aisdlc-snapshot-context`\n\n**Output**:\n```\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\nâ•‘             Context Snapshot Created Successfully            â•‘\nâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nğŸ“¸ Snapshot: 20251216_1430_implementing_auth_service\nğŸ“ Location: .ai-workspace/context_history/20251216_1430_implementing_auth_service.md\n\nğŸ“Š Snapshot Contents:\n   âœ“ Active Tasks: 3 (2 in-progress, 1 pending)\n   âœ“ File Changes: 5 modified, 1 staged\n   âœ“ Conversation Markers: 2 decisions, 1 open question\n   âœ“ Recovery Guidance: Included\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nğŸ’¡ To restore this context later:\n\n   1. Read the snapshot:\n      cat .ai-workspace/context_history/20251216_1430_implementing_auth_service.md\n\n   2. Tell Claude:\n      \"Restore context from 20251216_1430_implementing_auth_service\"\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nğŸ“‹ Total Snapshots: 8\n```\n\n### Example 2: Context Recovery\n\n**User**: \"Restore context from 20251216_1430_implementing_auth_service\"\n\n**Claude Process**:\n1. Read `.ai-workspace/context_history/20251216_1430_implementing_auth_service.md`\n2. Parse snapshot content\n3. Summarize for user\n\n**Output**:\n```\nâœ… Context restored from 20251216_1430_implementing_auth_service\n\nğŸ“‹ Session Summary (from snapshot):\n   - Date: 2025-12-16 14:30\n   - Branch: feature/auth-service\n   - Tasks: 3 active (2 in-progress, 1 pending)\n\nğŸ¯ You were working on:\n   - Task #42: Implement user authentication (REQ-F-AUTH-001)\n   - Status: In Progress\n   - Recent: Fixed failing tests in auth_service_test.py\n\nğŸ’¬ Open Questions (from snapshot):\n   1. Should we add rate limiting now or in next sprint?\n\nğŸ“ Uncommitted Work:\n   - src/auth/auth_service.py (modified)\n   - tests/auth/test_auth_service.py (modified)\n\nğŸ”„ Next Steps (from snapshot):\n   1. Complete refactoring of error handling\n   2. Add integration tests for login flow\n\nReady to continue? I can help with the next steps or answer the open question.\n```\n\n---\n\n## Notes\n\n- Snapshots are **immutable** - never modify after creation\n- Snapshots complement `/aisdlc-checkpoint-tasks` - use both for complete session save\n- Snapshots are **human-readable** - share with team members for handoffs\n- Old snapshots archived automatically after retention period (default: 30 days)\n- Snapshots focus on **context**, not full conversation replay\n- If conversation history API not available, conversation analysis will be limited\n\n**Recommended Usage**:\n- End of work session\n- Before team handoff\n- Before risky changes (major refactor, architecture change)\n- Weekly snapshot for project continuity\n- After completing major milestones\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/commands/aisdlc-status.md": "# /aisdlc-status - Show Project Status and Next Steps\n\nDisplay current task status and suggest the next action based on project state.\n\n<!-- Implements: REQ-TOOL-003 (Workflow Commands) -->\n\n## Instructions\n\nShow a snapshot of project status and intelligently suggest next steps.\n\n### Step 0: Get Version\n\nRead the plugin version from the plugin.json file. Try these locations in order:\n1. `~/.claude/plugins/marketplaces/aisdlc/**/aisdlc-methodology/.claude-plugin/plugin.json` (marketplace cache)\n2. `.claude-plugin/plugin.json` (relative to the command file location)\n3. `../plugin.json` (if commands are in a subdirectory)\n4. Search for `aisdlc-methodology/.claude-plugin/plugin.json` in the project\n\n**IMPORTANT**: For marketplace-installed plugins, the version is in the marketplace cache, NOT in the project directory.\n\nExtract the `\"version\"` field and display it in the header (e.g., \"v0.5.5\").\n\nIf version cannot be found, display \"v0.5.5\" as the hardcoded fallback (current release).\n\n### Step 1: Check Workspace Exists\n\nFirst, check if `.ai-workspace/` exists:\n- If NOT: suggest running `/aisdlc-init`\n\n### Step 2: Check Mandatory Artifacts\n\nCheck for these mandatory artifacts:\n- `docs/requirements/INTENT.md`\n- `docs/requirements/AISDLC_IMPLEMENTATION_REQUIREMENTS.md`\n- `docs/design/*/AISDLC_IMPLEMENTATION_DESIGN.md`\n- `docs/TRACEABILITY_MATRIX.md`\n\n### Step 3: Read Task Status\n\nRead `.ai-workspace/tasks/active/ACTIVE_TASKS.md`:\n- Count tasks by status (in_progress, pending, blocked, completed)\n- List active task titles with REQ-* tags\n\nList recently finished tasks from `.ai-workspace/tasks/finished/` (last 5).\n\n### Step 4: Determine Next Step\n\nBased on state, suggest the most logical next action from this progression:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Step 1: /aisdlc-init                                       â”‚\nâ”‚          Initialize workspace and artifact templates        â”‚\nâ”‚                          â†“                                  â”‚\nâ”‚  Step 2: Edit docs/requirements/INTENT.md                   â”‚\nâ”‚          Describe what you want to build                    â”‚\nâ”‚                          â†“                                  â”‚\nâ”‚  Step 3: \"Help me create requirements from INTENT.md\"       â”‚\nâ”‚          â†’ Generates REQ-F-*, REQ-NFR-*, etc.               â”‚\nâ”‚                          â†“                                  â”‚\nâ”‚  Step 4: \"Design a solution for REQ-F-XXX-001\"              â”‚\nâ”‚          â†’ Creates components, ADRs, traceability           â”‚\nâ”‚                          â†“                                  â”‚\nâ”‚  Step 5: \"Break down the design into tasks\"                 â”‚\nâ”‚          â†’ Creates work items in ACTIVE_TASKS.md            â”‚\nâ”‚                          â†“                                  â”‚\nâ”‚  Step 6: \"Work on Task #1 using TDD\"                        â”‚\nâ”‚          â†’ RED â†’ GREEN â†’ REFACTOR â†’ COMMIT                  â”‚\nâ”‚                          â†“                                  â”‚\nâ”‚  Step 7: /aisdlc-checkpoint-tasks                           â”‚\nâ”‚          â†’ Save progress                                    â”‚\nâ”‚                          â†“                                  â”‚\nâ”‚  Step 8: /aisdlc-release                                    â”‚\nâ”‚          â†’ Create release with changelog                    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**Next Step Logic**:\n| State | You Are At | Suggested Next Step |\n|-------|------------|---------------------|\n| No workspace | â€” | Step 1: `/aisdlc-init` |\n| No INTENT.md content | Step 1 âœ“ | Step 2: Edit `docs/requirements/INTENT.md` |\n| INTENT exists, no REQ-* | Step 2 âœ“ | Step 3: \"Help me create requirements\" |\n| REQ-* exists, no design | Step 3 âœ“ | Step 4: \"Design a solution for REQ-F-XXX-001\" |\n| Design exists, no tasks | Step 4 âœ“ | Step 5: \"Break down the design into tasks\" |\n| Tasks exist, none in progress | Step 5 âœ“ | Step 6: Pick a task: \"Work on Task #X\" |\n| Task in progress | Step 6 | Continue or `/aisdlc-checkpoint-tasks` |\n| All tasks complete | Step 7 âœ“ | Step 8: `/aisdlc-release` |\n\n### Step 5: Display Output\n\n```\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\nâ•‘                    AI SDLC Project Status                    â•‘\nâ•‘                        Version: {version}                    â•‘\nâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nğŸ“ Workspace: {âœ… Initialized | âŒ Not found - run /aisdlc-init}\n\nğŸ“„ Artifacts:\n   {âœ… | âŒ} INTENT.md           {status: Empty | Has content}\n   {âœ… | âŒ} Requirements        {count} REQ-* keys defined\n   {âœ… | âŒ} Design              {count} components defined\n   {âœ… | âŒ} Traceability Matrix {coverage %}\n\nğŸ“‹ Tasks:\n   In Progress: {count}\n   Pending:     {count}\n   Blocked:     {count}\n   Completed:   {count}\n\n   Active Tasks:\n   {list task titles with REQ-* tags, or \"(No active tasks)\"}\n\nâœ… Recently Finished:\n   {list last 5 finished tasks or \"(None yet)\"}\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\nğŸ¯ NEXT STEP: {intelligent suggestion based on state}\n\n   {explanation of why this is the next step}\n\n   Example: \"{specific command or prompt to use}\"\n```\n\n---\n\n**Note**: This command is read-only. Run the suggested action to proceed.\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/commands/aisdlc-version.md": "# /aisdlc-version - Show AI SDLC Plugin Version\n\nDisplay the current version of the AI SDLC methodology plugin and its components.\n\n<!-- Implements: REQ-TOOL-005 (Release Management) -->\n\n## Instructions\n\nRead and display version information from the following files:\n\n1. **Plugin Version**: Find `plugin.json` by searching these locations IN ORDER:\n   - `~/.claude/plugins/marketplaces/aisdlc/**/aisdlc-methodology/.claude-plugin/plugin.json` (marketplace cache - MOST COMMON)\n   - `.claude-plugin/plugin.json` (relative to command file)\n   - `../plugin.json` (if commands are in subdirectory)\n   - Search for `aisdlc-methodology/.claude-plugin/plugin.json` in project\n\n   **IMPORTANT**: For marketplace-installed plugins, the version is in `~/.claude/plugins/marketplaces/`, NOT in the project directory.\n\n   Extract the `version` field. If not found, use \"0.5.5\" as hardcoded fallback.\n\n2. **Stages Config Version**: Find `stages_config.yml` by searching:\n   - `~/.claude/plugins/marketplaces/aisdlc/**/aisdlc-methodology/config/stages_config.yml` (marketplace cache)\n   - `config/stages_config.yml` (relative to plugin root)\n   - Search for `aisdlc-methodology/config/stages_config.yml` in project\n   Extract `ai_sdlc_stages.version` field.\n3. **Git Tag** (if available): Run `git describe --tags --abbrev=0` to get latest tag\n\nDisplay output in this format:\n\n```\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\nâ•‘               AI SDLC Method - Version Info                  â•‘\nâ•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n  Plugin:        aisdlc-methodology\n  Version:       v{version from plugin.json}\n  Stages Config: v{version from stages_config.yml}\n  Git Tag:       {latest git tag or \"none\"}\n\n  Homepage:      https://github.com/foolishimp/ai_sdlc_method\n\n  Components:\n  â”œâ”€ Agents:     7 (Requirements, Design, Tasks, Code, System Test, UAT, Runtime)\n  â”œâ”€ Commands:   8 (including this one)\n  â”œâ”€ Skills:     11 consolidated workflows\n  â””â”€ Hooks:      2 (Stop, PreToolUse)\n\n  Changelog (latest):\n  {read metadata.changelog from stages_config.yml}\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n  Run /aisdlc-init --force to update framework files\n  Run /aisdlc-help for full command reference\n```\n\n---\n\n**Usage**: Run `/aisdlc-version` to display version information.\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/config/config.yml": "methodology:\n  name: Key Principles Development Methodology\n  origin: https://github.com/foolishimp/ai_init\n  version: \"2.0\"\n  note: \"Principles can evolve per project context - see KEY_PRINCIPLES.md\"\n\n  principles:\n    _uri: \"file://docs/principles/KEY_PRINCIPLES.md\"\n\n    test_driven_development:\n      principle: 1\n      mantra: \"No code without tests\"\n      workflow: RED â†’ GREEN â†’ REFACTOR\n      requirements:\n        - Write tests first, always\n        - Maintain >80% code coverage\n        - Tests are documentation\n\n    fail_fast_root_cause:\n      principle: 2\n      mantra: \"Break loudly, fix completely\"\n      requirements:\n        - No workarounds or band-aids\n        - Fix causes, not symptoms\n        - Errors must be obvious\n        - No hiding bugs\n\n    modular_maintainable:\n      principle: 3\n      mantra: \"Single responsibility, loose coupling\"\n      requirements:\n        - Each module does one thing well\n        - Decoupled components\n        - Easy to understand\n        - Easy to extend\n\n    reuse_before_build:\n      principle: 4\n      mantra: \"Check first, create second\"\n      requirements:\n        - Search existing code first\n        - Use what exists\n        - Document new creations\n        - Avoid duplication\n\n    open_source_first:\n      principle: 5\n      mantra: \"Suggest alternatives, human decides\"\n      requirements:\n        - Research existing libraries\n        - AI suggests options\n        - Human makes final choice\n        - Prefer battle-tested solutions\n\n    no_legacy_baggage:\n      principle: 6\n      mantra: \"Clean slate, no debt\"\n      requirements:\n        - No backwards compatibility constraints\n        - No technical debt\n        - Replace completely if needed\n        - Fresh start mentality\n\n    perfectionist_excellence:\n      principle: 7\n      mantra: \"Best of breed only\"\n      requirements:\n        - Quality over quantity\n        - Ship when excellent\n        - Hardcore standards\n        - Excellence or nothing\n\n  processes:\n    tdd_workflow:\n      _uri: \"file://docs/processes/TDD_WORKFLOW.md\"\n\n      cycle:\n        - phase: RED\n          action: Write failing test first\n          goal: Define desired behavior\n\n        - phase: GREEN\n          action: Write minimal code to pass\n          goal: Make it work\n\n        - phase: REFACTOR\n          action: Improve code quality\n          goal: Make it better\n\n        - phase: COMMIT\n          action: Save with clear message\n          goal: Track progress\n\n        - phase: REPEAT\n          action: Next test\n          goal: Continue development\n\n      rules:\n        - No code without tests\n        - Tests describe behavior\n        - Simplest solution first\n        - Keep tests passing during refactor\n        - Commit after each cycle\n\n    pair_programming:\n      _uri: \"file://docs/guides/PAIR_PROGRAMMING_WITH_AI.md\"\n\n      roles:\n        human_driver: \"Strategic decisions, requirements, architecture\"\n        ai_navigator: \"Tactical implementation, suggestions, code writing\"\n\n      workflow:\n        - phase: ALIGN\n          action: Establish shared understanding\n\n        - phase: PLAN\n          action: Agree on implementation approach\n\n        - phase: IMPLEMENT\n          action: Collaborate on coding\n\n        - phase: REVIEW\n          action: Mutual code assessment\n\n        - phase: VALIDATE\n          action: Confirm functionality\n\n      communication:\n        check_in_frequency: \"Every 10-15 minutes\"\n        think_aloud: required\n        clear_handoffs: required\n\n      anti_patterns:\n        - Silent coding without explanation\n        - Making architectural assumptions\n        - Big bang implementations\n        - Ignoring feedback\n        - No knowledge transfer\n\n    session_management:\n      _uri: \"file://docs/guides/SESSION_STARTER.md\"\n\n      start_of_session:\n        - Check git status and recent commits\n        - Review active tasks\n        - Run tests to ensure clean state\n        - Review core methodology documents\n        - Align on session goals\n\n      session_template:\n        sections:\n          - goals\n          - current_task\n          - approach\n          - check_in_schedule\n          - end_of_session_checklist\n\n      context_recovery:\n        commands:\n          - git status\n          - git diff\n          - git log --oneline -10\n\n    task_documentation:\n      _uri: \"file://docs/guides/TASK_TEMPLATE.md\"\n\n      required_sections:\n        - problem\n        - investigation\n        - solution\n        - files_modified\n        - files_created\n        - code_changes\n        - testing\n        - result\n        - side_effects\n        - future_considerations\n        - lessons_learned\n\n    unified_principles:\n      _uri: \"file://docs/guides/UNIFIED_PRINCIPLES.md\"\n\n      hierarchy:\n        - Test First (Principle 1)\n        - Fail Fast (Principle 2)\n        - Reuse Before Build (Principle 4)\n        - Open Source First (Principle 5)\n        - Quality Excellence (Principle 7)\n        - No Tech Debt (Principle 6)\n        - Modular Design (Principle 3)\n\n      conflict_resolution: \"Follow decision tree in guide\"\n\n  quality_standards:\n    testing:\n      coverage_minimum: 80\n      coverage_target: 100\n      execution_time_max_seconds: 5\n      test_independence: required\n      test_structure: AAA  # Arrange-Act-Assert\n\n    code:\n      type_hints: required\n      docstrings: required\n      style_guide: PEP 8\n      complexity_max: 10\n      function_length_max: 50\n      class_length_max: 300\n\n    commits:\n      message_format: \"type: short summary\\n\\ndetailed description\\n\\ntest evidence\"\n      require_tests: true\n      require_passing_tests: true\n      co_author: \"Claude <noreply@anthropic.com>\"\n\n  enforcement:\n    violations_policy: reject\n    code_review_required: true\n    ci_cd_gates:\n      - All tests must pass\n      - Coverage >80%\n      - No new warnings\n      - Style check passes\n\n  decision_framework:\n    before_coding:\n      - question: \"Have I written tests first?\"\n        principle: 1\n\n      - question: \"Will this fail loudly if wrong?\"\n        principle: 2\n\n      - question: \"Is this module focused?\"\n        principle: 3\n\n      - question: \"Did I check if this exists?\"\n        principle: 4\n\n      - question: \"Have I researched alternatives?\"\n        principle: 5\n\n      - question: \"Am I avoiding tech debt?\"\n        principle: 6\n\n      - question: \"Is this excellent?\"\n        principle: 7\n\n    required_answers: \"yes to all seven\"\n    action_if_no: \"Don't code yet\"\n\n  documentation:\n    principles_guide: \"file://docs/principles/KEY_PRINCIPLES.md\"\n    tdd_workflow_guide: \"file://docs/processes/TDD_WORKFLOW.md\"\n    pair_programming_guide: \"file://docs/guides/PAIR_PROGRAMMING_WITH_AI.md\"\n    session_starter_guide: \"file://docs/guides/SESSION_STARTER.md\"\n    unified_principles_guide: \"file://docs/guides/UNIFIED_PRINCIPLES.md\"\n    task_template: \"file://docs/guides/TASK_TEMPLATE.md\"\n    quick_reference: \"file://docs/README.md\"\n\n  integration:\n    usage: Load as base methodology for all projects\n    combine_with:\n      - python_standards\n      - architecture_patterns\n      - security_requirements\n      - project_specific_rules\n\n    merge_priority: foundation_layer\n    override_policy: \"Principles cannot be overridden, only extended\"\n\nmantras:\n  ultimate: \"Excellence or nothing\"\n  daily:\n    - \"Tests before code\"\n    - \"Fail loud, fix deep\"\n    - \"One job per module\"\n    - \"Search before create\"\n    - \"Suggest, don't decide\"\n    - \"No debt, fresh start\"\n    - \"Excellence or nothing\"\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/config/stages_config.yml": "# AI SDLC Multi-Stage Agent Configuration\n# Reference: /Users/jim/src/apps/ai_sdlc_method/docs/ai_sdlc_method.md\n# Version: 0.5.6\n\nai_sdlc_stages:\n  version: \"0.5.6\"\n  description: \"Complete AI SDLC stage configurations with AI agent specifications\"\n  reference_doc: \"file://../../docs/ai_sdlc_method.md\"\n\n# ============================================================================\n# MANDATORY ARTIFACTS - Required for Traceability\n# ============================================================================\n# These artifacts are REQUIRED for the methodology to function correctly.\n# Traceability depends on these artifacts existing in predictable locations\n# with consistent structure. Without them, intent-to-runtime traceability\n# cannot be maintained.\n#\n# Rationale: The AI SDLC methodology is opinionated about artifacts because:\n# 1. Traceability requires predictable artifact locations and formats\n# 2. Each stage must produce specific outputs for downstream stages\n# 3. Bidirectional feedback loops depend on consistent artifact structure\n# 4. Audit and compliance require documented, versioned artifacts\n# ============================================================================\n\nmandatory_artifacts:\n  description: \"Opinionated artifacts required per stage for full traceability\"\n  enforcement: \"Quality gates MUST validate artifact existence and format\"\n\n  # ---------------------------------------------------------------------------\n  # Requirements Stage Artifacts\n  # ---------------------------------------------------------------------------\n  requirements:\n    artifacts:\n      - name: \"Implementation Requirements Document\"\n        path: \"docs/requirements/AISDLC_IMPLEMENTATION_REQUIREMENTS.md\"\n        format: \"Markdown with REQ-* tagged sections\"\n        purpose: \"Canonical itemized list of all requirements with unique keys\"\n        required_elements:\n          - \"REQ-{TYPE}-{DOMAIN}-{SEQ} format keys\"\n          - \"Priority (Critical/High/Medium)\"\n          - \"Type (Functional/Non-Functional/Data)\"\n          - \"Acceptance criteria\"\n          - \"Traces To reference\"\n        example: \"REQ-F-AUTH-001: User login with email/password\"\n\n      - name: \"Intent Document\"\n        path: \"docs/requirements/INTENT.md\"\n        format: \"Markdown\"\n        purpose: \"Capture raw business intent before decomposition\"\n        required_elements:\n          - \"INT-* unique identifiers\"\n          - \"Problem/opportunity description\"\n          - \"Expected outcomes\"\n          - \"Stakeholders\"\n\n    validation:\n      - \"All requirements have unique REQ-* keys\"\n      - \"All requirements have acceptance criteria\"\n      - \"All requirements trace to intent (INT-*)\"\n      - \"Document is version-controlled\"\n\n  # ---------------------------------------------------------------------------\n  # Design Stage Artifacts\n  # ---------------------------------------------------------------------------\n  design:\n    artifacts:\n      - name: \"Implementation Design Document\"\n        path: \"docs/design/{project}/AISDLC_IMPLEMENTATION_DESIGN.md\"\n        format: \"Markdown with component diagrams\"\n        purpose: \"Full technical design showing complete solution architecture\"\n        required_elements:\n          - \"System architecture overview\"\n          - \"Component design with REQ-* traceability\"\n          - \"Integration points\"\n          - \"References to ADRs\"\n          - \"References to requirements document\"\n        traces_to: \"docs/requirements/AISDLC_IMPLEMENTATION_REQUIREMENTS.md\"\n\n      - name: \"Architecture Decision Records\"\n        path: \"docs/design/{project}/adrs/ADR-*.md\"\n        format: \"Markdown ADR format\"\n        purpose: \"Document all architectural decisions with context and rationale\"\n        required_elements:\n          - \"Title (ADR-NNN: Decision Name)\"\n          - \"Status (Proposed/Accepted/Deprecated/Superseded)\"\n          - \"Context (forces that led to decision)\"\n          - \"Decision (the change being made)\"\n          - \"Consequences (positive, negative, neutral)\"\n          - \"Requirements addressed (REQ-* keys)\"\n        example: \"ADR-001: Claude Code as MVP Platform\"\n\n      - name: \"Traceability Matrix\"\n        path: \"docs/TRACEABILITY_MATRIX.md\"\n        format: \"Markdown table or YAML\"\n        purpose: \"Map requirements to design, code, tests, runtime\"\n        required_elements:\n          - \"REQ-* â†’ Design component mapping\"\n          - \"REQ-* â†’ Code file/function mapping\"\n          - \"REQ-* â†’ Test mapping\"\n          - \"Coverage percentage\"\n          - \"Gap identification\"\n        update_frequency: \"Every stage transition\"\n\n    validation:\n      - \"Every design component maps to â‰¥1 REQ-* key\"\n      - \"All ADRs reference requirements addressed\"\n      - \"Traceability matrix is current\"\n      - \"No orphan components (components without requirements)\"\n\n  # ---------------------------------------------------------------------------\n  # Tasks Stage Artifacts\n  # ---------------------------------------------------------------------------\n  tasks:\n    artifacts:\n      - name: \"Work Breakdown\"\n        path: \".ai-workspace/tasks/active/ACTIVE_TASKS.md\"\n        format: \"Markdown task list\"\n        purpose: \"Track all work items with requirement traceability\"\n        required_elements:\n          - \"Task ID\"\n          - \"REQ-* keys (implements which requirements)\"\n          - \"Status (pending/in_progress/completed)\"\n          - \"Acceptance criteria\"\n          - \"Dependencies\"\n        alternative_systems:\n          - \"Jira with REQ-* custom field\"\n          - \"Azure DevOps with REQ-* tags\"\n          - \"GitHub Issues with REQ-* labels\"\n\n    validation:\n      - \"Every task references â‰¥1 REQ-* key\"\n      - \"All requirements have â‰¥1 task\"\n      - \"Tasks have clear acceptance criteria\"\n      - \"Dependencies are identified\"\n\n  # ---------------------------------------------------------------------------\n  # Code Stage Artifacts\n  # ---------------------------------------------------------------------------\n  code:\n    artifacts:\n      - name: \"Production Code\"\n        path: \"src/**/*.{py,ts,js,java,go}\"\n        format: \"Source code with REQ-* tags in comments/docstrings\"\n        purpose: \"Implementation with requirement traceability\"\n        required_elements:\n          - \"# Implements: REQ-* in docstrings/comments\"\n          - \"Function/class-level requirement attribution\"\n        example: |\n          # Implements: REQ-F-AUTH-001\n          def login(email: str, password: str) -> LoginResult:\n              \"\"\"Authenticate user with email and password.\"\"\"\n              ...\n\n      - name: \"Unit Tests\"\n        path: \"tests/**/*.{py,ts,js,java,go}\"\n        format: \"Test code with REQ-* tags\"\n        purpose: \"Test-to-requirement traceability\"\n        required_elements:\n          - \"# Validates: REQ-* in test docstrings/comments\"\n          - \"AAA structure (Arrange-Act-Assert)\"\n        coverage_minimum: \"80%\"\n        coverage_critical_paths: \"100%\"\n        example: |\n          # Validates: REQ-F-AUTH-001\n          def test_login_with_valid_credentials():\n              # Arrange\n              user = create_test_user()\n              # Act\n              result = login(user.email, \"password123\")\n              # Assert\n              assert result.success == True\n\n      - name: \"Commit Messages\"\n        format: \"Git commit with REQ-* reference\"\n        purpose: \"Track which requirements each commit implements\"\n        required_elements:\n          - \"Implements: REQ-* in commit body\"\n          - \"Co-Authored-By: Claude <noreply@anthropic.com> (if AI-assisted)\"\n        example: |\n          feat: Add user authentication\n\n          Implement email/password login with JWT tokens.\n\n          Implements: REQ-F-AUTH-001\n\n          ğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)\n\n          Co-Authored-By: Claude <noreply@anthropic.com>\n\n    validation:\n      - \"All code files have REQ-* tags\"\n      - \"All tests have REQ-* tags\"\n      - \"Test coverage â‰¥80%\"\n      - \"Commits include requirement references\"\n\n  # ---------------------------------------------------------------------------\n  # System Test Stage Artifacts\n  # ---------------------------------------------------------------------------\n  system_test:\n    artifacts:\n      - name: \"BDD Feature Files\"\n        path: \"tests/features/**/*.feature\"\n        format: \"Gherkin (Given/When/Then)\"\n        purpose: \"Executable specifications with requirement traceability\"\n        required_elements:\n          - \"@REQ-* tags on scenarios\"\n          - \"Given/When/Then structure\"\n          - \"Happy path, error cases, edge cases\"\n        example: |\n          @REQ-F-AUTH-001\n          Feature: User Authentication\n\n            Scenario: Successful login\n              Given I am on the login page\n              When I enter valid email \"user@example.com\"\n              And I enter valid password \"password123\"\n              And I click \"Login\"\n              Then I should see \"Welcome back\"\n\n      - name: \"Step Definitions\"\n        path: \"tests/features/steps/**/*.{py,ts,js}\"\n        format: \"BDD step implementation\"\n        purpose: \"Automated test implementation\"\n        required_elements:\n          - \"Step functions for Given/When/Then\"\n          - \"# Validates: REQ-* tags\"\n\n      - name: \"Test Coverage Report\"\n        path: \"docs/test/COVERAGE_REPORT.md\"\n        format: \"Markdown or HTML\"\n        purpose: \"Track requirement-to-test coverage\"\n        required_elements:\n          - \"REQ-* â†’ Scenario mapping\"\n          - \"Coverage percentage\"\n          - \"Untested requirements (gaps)\"\n\n    validation:\n      - \"All requirements have â‰¥1 BDD scenario\"\n      - \"All scenarios pass (or failures documented)\"\n      - \"Requirement coverage â‰¥95%\"\n      - \"No critical defects open\"\n\n  # ---------------------------------------------------------------------------\n  # UAT Stage Artifacts\n  # ---------------------------------------------------------------------------\n  uat:\n    artifacts:\n      - name: \"UAT Test Cases\"\n        path: \"docs/uat/UAT_TEST_CASES.md\"\n        format: \"Markdown with Given/When/Then in business language\"\n        purpose: \"Business validation test cases\"\n        required_elements:\n          - \"UAT-* unique identifiers\"\n          - \"REQ-* traceability\"\n          - \"Pure business language (no technical jargon)\"\n          - \"Expected results\"\n        example: |\n          ## UAT-001: Customer Login\n          **Requirement**: REQ-F-AUTH-001\n\n          **Given** I am a registered customer\n          **When** I enter my email and password on the login page\n          **Then** I should see my personal dashboard\n\n      - name: \"UAT Sign-off Document\"\n        path: \"docs/uat/UAT_SIGNOFF.md\"\n        format: \"Markdown with approval signatures\"\n        purpose: \"Formal business approval of requirements\"\n        required_elements:\n          - \"Per-requirement status (âœ… Accepted / âŒ Rejected)\"\n          - \"Sign-off authority (name, role, date)\"\n          - \"REQ-* coverage summary\"\n          - \"Open issues (if any)\"\n        sign_off_authorities:\n          - \"Business SME (functional behavior)\"\n          - \"Business Data Steward (data quality)\"\n          - \"UAT Lead (UAT activities)\"\n          - \"Compliance Officer (regulatory, if applicable)\"\n\n    validation:\n      - \"All requirements have UAT test cases\"\n      - \"Business sign-off obtained\"\n      - \"No critical/high defects open\"\n      - \"Data validation complete\"\n\n  # ---------------------------------------------------------------------------\n  # Runtime Feedback Stage Artifacts\n  # ---------------------------------------------------------------------------\n  runtime:\n    artifacts:\n      - name: \"Release Manifest\"\n        path: \"docs/releases/RELEASE_*.md\"\n        format: \"Markdown with version and REQ-* list\"\n        purpose: \"Track which requirements are deployed in each release\"\n        required_elements:\n          - \"Version number (SemVer)\"\n          - \"REQ-* keys included in release\"\n          - \"Changelog summary\"\n          - \"Deployment date\"\n        example: |\n          # Release v2.5.0\n          **Date**: 2025-12-03\n\n          ## Requirements Included\n          - REQ-F-AUTH-001 (v1) - User authentication\n          - REQ-NFR-PERF-001 (v2) - Performance optimization\n\n          ## Changelog\n          - Added email/password login\n          - Improved login response time by 40%\n\n      - name: \"Telemetry Configuration\"\n        path: \"config/telemetry.yml\"\n        format: \"YAML\"\n        purpose: \"Configure REQ-* tagged observability\"\n        required_elements:\n          - \"Requirement key tagging rules\"\n          - \"Alert routing configuration\"\n          - \"Metric definitions\"\n        example: |\n          telemetry:\n            tagging:\n              format: \"requirement: REQ-*\"\n              propagate_to:\n                - logs\n                - metrics\n                - traces\n                - alerts\n\n      - name: \"Feedback Log\"\n        path: \"docs/runtime/FEEDBACK_LOG.md\"\n        format: \"Markdown\"\n        purpose: \"Track runtime issues and generated intents\"\n        required_elements:\n          - \"Issue description\"\n          - \"REQ-* affected\"\n          - \"Root cause (if known)\"\n          - \"New intent generated (INT-*)\"\n\n    validation:\n      - \"All deployed code has REQ-* tags\"\n      - \"Telemetry captures requirement keys\"\n      - \"Alerts route to Intent Manager\"\n      - \"Release manifest includes requirement traceability\"\n\n# ============================================================================\n# ARTIFACT TRACEABILITY CHAIN\n# ============================================================================\n# This shows how artifacts connect across stages to enable full traceability\n# ============================================================================\n\nartifact_traceability_chain:\n  description: \"How artifacts chain together for end-to-end traceability\"\n\n  flow: |\n    INTENT.md (INT-001)\n        â†“\n    AISDLC_IMPLEMENTATION_REQUIREMENTS.md (REQ-F-AUTH-001)\n        â†“\n    AISDLC_IMPLEMENTATION_DESIGN.md + ADR-*.md (Component â†’ REQ-F-AUTH-001)\n        â†“\n    TRACEABILITY_MATRIX.md (REQ â†’ Design â†’ Code â†’ Test)\n        â†“\n    ACTIVE_TASKS.md / Jira (Task-123 â†’ REQ-F-AUTH-001)\n        â†“\n    src/auth.py (# Implements: REQ-F-AUTH-001)\n        â†“\n    tests/test_auth.py (# Validates: REQ-F-AUTH-001)\n        â†“\n    tests/features/auth.feature (@REQ-F-AUTH-001)\n        â†“\n    UAT_SIGNOFF.md (REQ-F-AUTH-001 âœ… Accepted)\n        â†“\n    RELEASE_v2.5.0.md (REQ-F-AUTH-001 deployed)\n        â†“\n    Telemetry (requirement: REQ-F-AUTH-001)\n        â†“\n    FEEDBACK_LOG.md (Alert â†’ REQ-F-AUTH-001 â†’ New INT-042)\n        â†“\n    [Cycle repeats at INTENT.md]\n\n  validation_points:\n    - stage: \"Requirements â†’ Design\"\n      check: \"Every REQ-* appears in design components or ADRs\"\n    - stage: \"Design â†’ Tasks\"\n      check: \"Every design component has â‰¥1 task\"\n    - stage: \"Tasks â†’ Code\"\n      check: \"Every task has code with matching REQ-* tag\"\n    - stage: \"Code â†’ Tests\"\n      check: \"Every # Implements: REQ-* has matching # Validates: REQ-*\"\n    - stage: \"Tests â†’ UAT\"\n      check: \"Every tested REQ-* has UAT sign-off\"\n    - stage: \"UAT â†’ Runtime\"\n      check: \"Every signed-off REQ-* appears in release manifest\"\n    - stage: \"Runtime â†’ Requirements\"\n      check: \"Alerts with REQ-* tags generate new intents\"\n\n  # ============================================================================\n  # STAGE 1: REQUIREMENTS\n  # Reference: Section 4.0\n  # ============================================================================\n  requirements_stage:\n    section_ref: \"4.0\"\n    purpose: \"Transform intent into formally documented, uniquely-keyed requirements\"\n\n    agent:\n      name: \"AISDLC Requirements Agent\"\n      role: \"Intent Store & Traceability Hub\"\n\n      responsibilities:\n        - \"Transform raw intent into structured requirements\"\n        - \"Generate requirement artifacts with unique keys\"\n        - \"Process feedback from all downstream stages\"\n        - \"Maintain end-to-end traceability\"\n        - \"Apply templates and standards\"\n        - \"Collaborate with personas (PO, BA, Data Steward)\"\n\n      inputs:\n        - source: \"Intent Manager\"\n          type: \"Problems, goals, risks (raw business intent)\"\n        - source: \"Discovery Results\"\n          type: \"Read/Analyse work outputs\"\n        - source: \"Governance/Regulatory\"\n          type: \"Compliance and regulatory changes\"\n        - source: \"All Stages (Feedback)\"\n          type: \"Design gaps, implementation discoveries, test gaps\"\n\n      outputs:\n        user_stories:\n          format: \"Given/When/Then or As-a/I-want/So-that\"\n          keys: \"REQ-F-{DOMAIN}-{SEQUENCE}\"\n          example: \"<REQ-ID>\"\n\n        non_functional_requirements:\n          categories: [\"performance\", \"security\", \"scalability\", \"reliability\"]\n          keys: \"REQ-NFR-{CATEGORY}-{SEQUENCE}\"\n          example: \"REQ-NFR-PERF-001\"\n\n        data_requirements:\n          aspects: [\"sources\", \"quality\", \"privacy\", \"lineage\", \"retention\"]\n          keys: \"REQ-DATA-{ASPECT}-{SEQUENCE}\"\n          examples: [\"REQ-DATA-001\", \"REQ-DATA-CQ-001\"]\n          sub_requirements:\n            - \"Data quality (completeness, accuracy, timeliness, consistency)\"\n            - \"Privacy classifications (PII, PHI per GDPR/CCPA/HIPAA)\"\n            - \"Data lineage tracking\"\n            - \"Master data and reference data needs\"\n\n        business_rules:\n          keys: \"REQ-BR-{DOMAIN}-{SEQUENCE}\"\n          example: \"REQ-BR-CALC-001\"\n\n        acceptance_criteria:\n          linked_to: \"Parent requirement keys\"\n          format: \"Testable validation points\"\n\n        traceability_matrix:\n          format: \"Markdown table or YAML/JSON\"\n          location: \"docs/TRACEABILITY_MATRIX.md\"\n          content: \"REQ-* â†’ Intent, Design, Code, Tests, Runtime\"\n          update_frequency: \"Every stage transition\"\n          auto_generated: true\n          tool: \"validate_traceability.py --matrix\"\n          purpose: \"End-to-end requirement coverage and impact analysis\"\n\n      key_principles:\n        requirement_keys:\n          properties: [\"unique\", \"immutable\", \"versioned\", \"traceable\", \"auditable\"]\n          structure: \"REQ-{TYPE}-{DOMAIN}-{SEQUENCE}\"\n          versioning: \"<REQ-ID> v2 (for refinements)\"\n\n        methodologies:\n          - \"Intent First - every requirement originates from validated intent\"\n          - \"Single Source of Truth - requirements are authoritative\"\n          - \"Bi-Directional Traceability - forward to deployment, backward to intent\"\n          - \"Centralized Feedback Hub - all gaps feed back here\"\n          - \"Persona-Centric Ownership - PO, BA, Data Steward each own aspects\"\n          - \"Data Requirements Parity - data specs receive same rigor as functional\"\n\n      quality_gates:\n        - \"All requirements have unique keys\"\n        - \"All requirements have acceptance criteria\"\n        - \"Product Owner review complete\"\n        - \"Data Steward review complete (for data requirements)\"\n        - \"Compliance Officer review complete (for regulatory)\"\n\n      context:\n        regulatory: [\"GDPR\", \"CCPA\", \"HIPAA\", \"compliance_standards\"]\n        business: [\"strategic_goals\", \"market_conditions\", \"competitive_landscape\"]\n        domain: [\"industry_rules\", \"domain_knowledge\", \"business_processes\"]\n        risk: [\"risk_appetite\", \"security_requirements\", \"audit_requirements\"]\n\n  # ============================================================================\n  # STAGE 2: DESIGN\n  # Reference: Section 5.0\n  # ============================================================================\n  design_stage:\n    section_ref: \"5.0\"\n    purpose: \"Transform requirements into implementable technical and data solution\"\n\n    agent:\n      name: \"AISDLC Design Agent / Solution Designer\"\n      role: \"Architecture & Data Design\"\n\n      responsibilities:\n        - \"Analyze requirements and extract specifications\"\n        - \"Apply architectural patterns from context\"\n        - \"Design components, APIs, and data models\"\n        - \"Tag all artifacts with requirement keys\"\n        - \"Generate traceability matrix (100% requirement coverage)\"\n        - \"Document trade-offs and ADRs\"\n\n      inputs:\n        - source: \"Requirements Stage\"\n          type: \"Approved requirements (REQ-F-*, REQ-NFR-*, REQ-DATA-*)\"\n        - source: \"Architecture Context\"\n          type: \"Approved tech stack, patterns, security standards\"\n        - source: \"Data Architecture Context\"\n          type: \"Data models, schemas, lineage, retention, privacy rules\"\n\n      outputs:\n        technical_design:\n          - \"Component diagrams with sequence flows\"\n          - \"API specifications (REST/GraphQL/gRPC)\"\n          - \"Integration specs (system-to-system)\"\n          - \"Security & compliance design\"\n\n        data_design:\n          - \"Data models (conceptual, logical, physical)\"\n          - \"Data flow diagrams (batch & streaming)\"\n          - \"Storage technology decisions (RDBMS/NoSQL/data lake)\"\n          - \"Partitioning & sharding strategies\"\n          - \"Schema evolution plans\"\n          - \"Data integration patterns (ETL/ELT/CDC/streaming)\"\n          - \"Data access patterns\"\n\n        traceability:\n          format: \"Component â†’ <REQ-ID>, REQ-NFR-SEC-001\"\n          requirement: \"100% requirement coverage in design\"\n          artifact: \"Design-to-Requirement Traceability Matrix\"\n\n        architecture_decision_records:\n          content: \"Design decisions with rationale\"\n          tagged_with: \"Requirement keys\"\n\n      key_principles:\n        - \"Application AND Data Co-Design (never design app without data architecture)\"\n        - \"Requirement-Driven Traceability (every artifact maps to requirement keys)\"\n        - \"Early Iteration is Cheaper (design-stage iteration < code-stage iteration)\"\n        - \"Context as Constraints (design within approved patterns only)\"\n        - \"Explicit Trade-off Documentation (performance vs cost vs complexity)\"\n        - \"Two-Dimensional Design (Technical + Data must be coherent)\"\n\n      quality_gates:\n        - \"Design adheres to approved architectural patterns\"\n        - \"All components mapped to requirement keys (100% traceability)\"\n        - \"Data models follow data architecture standards\"\n        - \"Security patterns applied per security context\"\n        - \"Performance targets specified per NFRs\"\n        - \"Cost estimates within budget constraints\"\n\n      required_reviews:\n        - \"Architecture Review (patterns and tech stack compliance)\"\n        - \"Data Architecture Review (data models and integration)\"\n        - \"Security Review (threat modeling and controls)\"\n        - \"Performance Review (capacity planning and latency)\"\n\n      context:\n        architecture: [\"tech_stack\", \"platform_choices\", \"patterns\"]\n        data_architecture: [\"modeling_standards\", \"storage_technologies\", \"integration_patterns\"]\n        performance: [\"latency_requirements\", \"throughput_targets\", \"scalability_needs\"]\n        security: [\"auth_patterns\", \"encryption_standards\", \"audit_requirements\"]\n        cost: [\"infrastructure_budgets\", \"operational_cost_targets\"]\n\n  # ============================================================================\n  # STAGE 3: TASKS / WORK BREAKDOWN\n  # Reference: Section 6.0\n  # ============================================================================\n  tasks_stage:\n    section_ref: \"6.0\"\n    purpose: \"Convert design into actionable work units with Jira integration and agent orchestration\"\n    dual_purpose: true  # Work planning + Agent orchestration\n\n    agent:\n      name: \"AISDLC Tasks Stage Orchestrator\"\n      role: \"Work Breakdown & Code Execution Manager\"\n\n      responsibilities:\n        work_planning:\n          - \"Analyze design artifacts and decompose into work units\"\n          - \"Generate user stories, technical tasks, data tasks\"\n          - \"Estimate work units (story points/hours)\"\n          - \"Identify dependencies and critical path\"\n          - \"Validate capacity vs. demand\"\n\n        jira_integration:\n          - \"Create/update Jira tickets (epics, stories, subtasks)\"\n          - \"Populate custom fields (req keys, story points, acceptance criteria)\"\n          - \"Configure parent-child relationships\"\n          - \"Set workflow states and transitions\"\n\n        agent_orchestration:\n          - \"Assign work units to developer agents from Jira backlog\"\n          - \"Monitor TDD cycle execution (RED â†’ GREEN â†’ REFACTOR)\"\n          - \"Validate test coverage gates (â‰¥80%, critical paths 100%)\"\n          - \"Track progress and update Jira status\"\n          - \"Escalate blockers\"\n          - \"Maintain requirement traceability\"\n\n      inputs:\n        - source: \"Design Stage\"\n          type: \"Architecture diagrams, technical designs, data models\"\n        - source: \"Requirements\"\n          type: \"REQ-F-*, REQ-NFR-*, REQ-DATA-* with acceptance criteria\"\n        - source: \"Context\"\n          type: \"Capacity, workload, estimation velocity, dependencies, tooling\"\n\n      outputs:\n        work_units:\n          epics:\n            description: \"High-level features spanning multiple sprints\"\n            tagged_with: \"Requirement keys\"\n\n          user_stories:\n            description: \"Deliverable functionality from user perspective\"\n            tagged_with: \"REQ-F-* keys\"\n            attributes: [\"acceptance_criteria\", \"estimation\"]\n\n          technical_tasks:\n            description: \"Infrastructure, refactoring, tech debt\"\n            tagged_with: \"REQ-NFR-* keys\"\n\n          data_tasks:\n            description: \"Pipelines, quality checks, schemas\"\n            tagged_with: \"REQ-DATA-* keys\"\n            categories:\n              - \"Data pipeline development (ingestion, transformation)\"\n              - \"Schema creation and migration\"\n              - \"Data quality rule implementation\"\n              - \"Data lineage tracking\"\n              - \"Data access and security configuration\"\n\n          bugs:\n            tagged_with: \"Original requirement keys\"\n            attributes: [\"root_cause\", \"impact\"]\n\n          spikes:\n            description: \"Research and investigation\"\n            tagged_with: \"Requirement keys\"\n            attributes: [\"time_boxed\", \"decision_gates\"]\n\n        jira_artifacts:\n          - \"Jira tickets with full metadata\"\n          - \"Epic hierarchy\"\n          - \"Dependency graph\"\n          - \"Capacity utilization report\"\n          - \"Requirement coverage matrix\"\n\n      task_template:\n        required_fields:\n          - \"Task ID and requirement keys\"\n          - \"Task type (feature, data, bug fix, tech debt)\"\n          - \"Description and acceptance criteria\"\n          - \"Technical approach and dependencies\"\n          - \"Estimation (story points/hours)\"\n          - \"Data considerations (sources, quality, volume)\"\n          - \"Subtasks breakdown\"\n\n      key_principles:\n        decomposition:\n          criteria:\n            - \"Single Responsibility (one concern per task)\"\n            - \"Independently Estimable\"\n            - \"Testable (clear acceptance criteria)\"\n            - \"Implementable in Sprint (3-5 story points)\"\n            - \"Traceability (direct link to requirements)\"\n            - \"Minimal Coupling (explicit dependencies)\"\n\n        synchronization_points:\n          - \"Requirements â†” Tasks: Every requirement must have â‰¥1 task\"\n          - \"Design â†” Tasks: Technical design informs breakdown\"\n          - \"Tasks â†” Code: Tasks become Jira tickets for agents\"\n          - \"Tasks â†” Testing: Acceptance criteria define test scenarios\"\n          - \"Capacity Synchronization: Estimated capacity â‰¥ planned demand\"\n\n      quality_gates:\n        - \"All tasks linked to requirement keys (no orphan tasks)\"\n        - \"All tasks estimated (story points or hours)\"\n        - \"All tasks have clear, testable acceptance criteria\"\n        - \"Dependencies identified and tracked\"\n        - \"Capacity vs. demand validated (no overallocation)\"\n        - \"Critical path identified and communicated\"\n\n      context:\n        capacity: [\"team_size\", \"skill_availability\", \"sprint_capacity\"]\n        workload: [\"existing_commitments\", \"competing_priorities\"]\n        estimation: [\"velocity_data\", \"historical_metrics\", \"complexity_factors\"]\n        dependency: [\"external_dependencies\", \"blocking_issues\", \"technical_constraints\"]\n        tooling: [\"jira_config\", \"azure_devops\", \"workflow_templates\"]\n\n  # ============================================================================\n  # STAGE 4: CODE (TDD-DRIVEN)\n  # Reference: Section 7.0\n  # ============================================================================\n  code_stage:\n    section_ref: \"7.0\"\n    purpose: \"Implement solution using Test-Driven Development (RED â†’ GREEN â†’ REFACTOR)\"\n    methodology: \"TDD\"\n\n    agent:\n      name: \"AISDLC Code Agent / Developer Agent\"\n      role: \"TDD-Driven Implementation\"\n\n      responsibilities:\n        - \"Receive work units from Tasks Stage (Jira tickets)\"\n        - \"Execute TDD cycle: RED â†’ GREEN â†’ REFACTOR â†’ COMMIT\"\n        - \"Write tests first, always (Principle #1: No code without tests)\"\n        - \"Implement minimal code to pass tests\"\n        - \"Refactor while keeping tests green\"\n        - \"Tag all code with requirement keys\"\n        - \"Maintain â‰¥80% test coverage (critical paths 100%)\"\n\n      inputs:\n        - source: \"Tasks Stage\"\n          type: \"Work units (Jira tickets) with acceptance criteria\"\n        - source: \"Design\"\n          type: \"Technical specs, API contracts, data models\"\n        - source: \"Context\"\n          type: \"Coding standards, security guidelines, templates, approved libraries\"\n\n      outputs:\n        production_code:\n          tagged_with: \"Requirement keys in docstrings/comments\"\n          examples:\n            - \"# Implements: <REQ-ID> (User Authentication)\"\n            - \"# Satisfies: REQ-NFR-SEC-001 (Secure Authentication)\"\n\n        test_code:\n          coverage_minimum: \"80%\"\n          coverage_critical_paths: \"100%\"\n          tagged_with: \"Requirement keys\"\n          structure: \"AAA (Arrange-Act-Assert)\"\n\n        git_commits:\n          format: \"type: summary\\n\\ndetails\\n\\ntest evidence\\n\\nImplements: REQ-*\"\n          co_author: \"Claude <noreply@anthropic.com>\"\n\n      tdd_cycle:\n        phases:\n          - phase: \"RED\"\n            action: \"Write failing test first\"\n            goal: \"Define desired behavior\"\n            validates: \"Requirement acceptance criteria\"\n\n          - phase: \"GREEN\"\n            action: \"Write minimal code to pass\"\n            goal: \"Make it work\"\n            constraint: \"Simplest solution first\"\n\n          - phase: \"REFACTOR\"\n            action: \"Improve code quality\"\n            goal: \"Make it better\"\n            constraint: \"Keep tests passing\"\n\n          - phase: \"COMMIT\"\n            action: \"Save with requirement key\"\n            goal: \"Track progress and traceability\"\n\n          - phase: \"REPEAT\"\n            action: \"Next test\"\n            goal: \"Continue development\"\n\n      ai_agent_constraints:\n        mandatory_rules:\n          - \"Tests before code (always)\"\n          - \"One requirement per work unit\"\n          - \"TDD cycle for every change\"\n          - \"Coverage gates enforced\"\n          - \"Requirement key traceability maintained\"\n\n      work_unit_execution:\n        flow: \"Agent receives work unit â†’ Executes TDD â†’ Updates Jira â†’ Next unit\"\n        iteration: \"Within work unit: Multiple TDD cycles until acceptance criteria met\"\n\n      key_principles:\n        - \"TDD Cycle (RED â†’ GREEN â†’ REFACTOR) is mandatory\"\n        - \"Tests are documentation (acceptance criteria â†’ tests)\"\n        - \"Simplest solution first\"\n        - \"Keep tests passing during refactor\"\n        - \"Commit after each cycle with requirement key\"\n\n      quality_gates:\n        - \"All code has tests\"\n        - \"Test coverage â‰¥80% (critical paths 100%)\"\n        - \"All tests passing\"\n        - \"Code tagged with requirement keys\"\n        - \"Coding standards compliance\"\n        - \"Security scan passes\"\n\n      context:\n        coding_standards: \"file://standards/coding/python_style_guide.md\"\n        security: \"file://standards/security/secure_coding.md\"\n        templates: \"file://templates/code/service_template.py\"\n        approved_libraries:\n          authentication: [\"bcrypt\", \"PyJWT\", \"passlib\"]\n\n        key_principles_integration:\n          principle_1: \"Test Driven Development (TDD mandatory)\"\n          principle_2: \"Fail Fast & Root Cause (tests fail loudly)\"\n          principle_3: \"Modular & Maintainable (single responsibility)\"\n          principle_4: \"Reuse Before Build (check existing code)\"\n          principle_5: \"Open Source First (suggest alternatives)\"\n          principle_6: \"No Legacy Baggage (clean slate, no debt)\"\n          principle_7: \"Perfectionist Excellence (quality over quantity)\"\n\n  # ============================================================================\n  # STAGE 5: SYSTEM TEST (BDD-DRIVEN)\n  # Reference: Section 8.0\n  # ============================================================================\n  system_test_stage:\n    section_ref: \"8.0\"\n    purpose: \"Verify integrated system behavior using BDD (Given/When/Then)\"\n    methodology: \"BDD\"\n\n    agent:\n      name: \"AISDLC System Test Agent / QA Agent\"\n      role: \"BDD-Driven Integration Testing\"\n\n      responsibilities:\n        - \"Generate BDD scenarios from requirements\"\n        - \"Analyze requirements and create Given/When/Then scenarios\"\n        - \"Implement step definitions (Behave/Cucumber/SpecFlow)\"\n        - \"Perform coverage analysis (â‰¥95% requirement coverage)\"\n        - \"Validate data quality and performance\"\n        - \"Generate requirement coverage reports\"\n        - \"Provide feedback to Requirements stage for gaps\"\n\n      inputs:\n        - source: \"Code Stage\"\n          type: \"Implemented system\"\n        - source: \"Requirements\"\n          type: \"REQ-F-*, REQ-NFR-*, REQ-DATA-CQ-*\"\n        - source: \"Design\"\n          type: \"Architecture, integration points\"\n        - source: \"Context\"\n          type: \"Test environments, data provisioning, performance baselines\"\n\n      outputs:\n        bdd_feature_files:\n          format: \"Gherkin (Given/When/Then)\"\n          tagged_with: \"Requirement keys in comments\"\n          frameworks: [\"Behave (Python)\", \"Cucumber (Java/JS)\", \"SpecFlow (.NET)\"]\n\n        step_definitions:\n          implementation: \"Automated test code\"\n          tagged_with: \"Requirement keys\"\n\n        test_reports:\n          content: \"Scenario execution results (pass/fail)\"\n          tagged_with: \"Requirement coverage status\"\n\n        coverage_matrix:\n          format: \"Scenario-to-requirement mapping\"\n          requirement: \"All requirement keys covered\"\n\n        defect_reports:\n          tagged_with: \"Original requirement keys\"\n          severity: \"Critical/High/Medium/Low\"\n\n      scenario_types:\n        functional:\n          scope: \"REQ-F-* (happy paths, error handling, edge cases)\"\n\n        integration:\n          scope: \"Service-to-service, API contracts, message flows\"\n\n        data_quality:\n          scope: \"REQ-DATA-CQ-* (completeness, accuracy, consistency, timeliness)\"\n\n        performance:\n          scope: \"REQ-NFR-PERF-* (load testing, response time, throughput)\"\n\n      key_principles:\n        bdd_format:\n          given: \"Setup/preconditions (system state before action)\"\n          when: \"Action/operation (what the system does)\"\n          then: \"Assertion/validation (expected outcome)\"\n\n        characteristics:\n          - \"Business-readable (non-technical stakeholders understand)\"\n          - \"Executable specifications (both documentation and tests)\"\n          - \"Requirement traceability (every scenario tags requirements)\"\n\n        tester_focused:\n          - \"Testers write scenarios (not developers)\"\n          - \"External perspective (tests from user's viewpoint)\"\n          - \"Integration focus (components working together)\"\n          - \"Coverage-driven (all requirements have scenarios)\"\n\n      quality_gates:\n        - \"All requirements have â‰¥1 BDD scenario\"\n        - \"All scenarios pass (or failures documented)\"\n        - \"Requirement coverage â‰¥95%\"\n        - \"No critical defects open\"\n        - \"Performance scenarios meet NFRs\"\n        - \"Data quality scenarios pass\"\n        - \"QA Lead approval\"\n\n      context:\n        bdd_frameworks: [\"behave\", \"cucumber\", \"specflow\"]\n        test_environments: [\"staging\", \"pre_prod\"]\n        data_provisioning: \"Test data lifecycle management\"\n        performance_baselines: \"NFR thresholds from requirements\"\n\n  # ============================================================================\n  # STAGE 6: UAT (BDD-DRIVEN)\n  # Reference: Section 9.0\n  # ============================================================================\n  uat_stage:\n    section_ref: \"9.0\"\n    purpose: \"Business validation through pure business language BDD scenarios\"\n    methodology: \"BDD for Business Users\"\n\n    agent:\n      name: \"AISDLC UAT Agent\"\n      role: \"Business Acceptance Facilitator\"\n\n      responsibilities:\n        - \"Support manual UAT test case creation (Business SMEs)\"\n        - \"Convert UAT scripts to automated BDD tests\"\n        - \"Generate data validation tests\"\n        - \"Track requirement-to-test traceability\"\n        - \"Generate sign-off documentation\"\n        - \"Facilitate three parallel activities\"\n\n      inputs:\n        - source: \"System Test Stage\"\n          type: \"Tested build and test results\"\n        - source: \"Requirements\"\n          type: \"Acceptance criteria (functional + data)\"\n        - source: \"Context\"\n          type: \"Production-like data, UAT environment, business personas\"\n\n      outputs:\n        manual_uat_test_cases:\n          format: \"Given/When/Then in pure business language\"\n          tagged_with: \"Requirement keys (REQ-F-*, REQ-BR-*)\"\n          owned_by: \"Business SMEs / Business Analysts\"\n          example: \"As a customer, when I log in with valid credentials, I should see my dashboard\"\n\n        automated_uat_tests:\n          framework: \"BDD (Cucumber/Behave)\"\n          traceability: \"Same requirement keys as manual cases\"\n          owned_by: \"QA Engineers\"\n          execution: \"Continuous in CI/CD\"\n\n        automated_data_tests:\n          framework: \"Great Expectations, dbt tests\"\n          scope: \"Data quality, business rules, reconciliation\"\n          tagged_with: \"REQ-DATA-* keys\"\n          owned_by: \"QA Engineers\"\n\n        uat_results:\n          format: \"Per-requirement status (âœ… Accepted / âŒ Rejected)\"\n          data_acceptance: \"Data accuracy, completeness, reconciliation reports\"\n          sign_off_document: \"Formal approval with requirement traceability\"\n\n      three_parallel_activities:\n        activity_1:\n          name: \"Manual UAT Test Cases\"\n          owned_by: \"Business SMEs / Business Analysts\"\n          language: \"Pure business terms, Given/When/Then\"\n          tagging: \"Requirement keys (REQ-F-*, REQ-BR-*)\"\n\n        activity_2:\n          name: \"Automated UAT Tests\"\n          owned_by: \"QA Engineers\"\n          framework: \"BDD (Cucumber, Behave)\"\n          traceability: \"Same REQ keys as manual cases\"\n          execution: \"Continuous in CI/CD\"\n\n        activity_3:\n          name: \"Automated Data Tests\"\n          owned_by: \"QA Engineers\"\n          framework: \"Great Expectations, dbt tests\"\n          scope: \"Data quality, business rules, reconciliation\"\n          tagging: \"Data requirement keys (REQ-DATA-*)\"\n\n      key_principles:\n        - \"Pure business language (no technical jargon in UAT scenarios)\"\n        - \"Written by Business Analysts with user input (not QA alone)\"\n        - \"Focus on user journeys and business value\"\n        - \"Three workstreams run in parallel (not sequential)\"\n        - \"UAT reveals latent intent (feedback to Requirements)\"\n\n      quality_gates:\n        entry_criteria:\n          - \"System test complete and results approved\"\n          - \"UAT environment ready and validated\"\n          - \"Production-like data loaded\"\n          - \"Business SMEs and data stewards available\"\n          - \"UAT scripts reviewed and approved\"\n\n        exit_criteria:\n          - \"All planned scenarios executed\"\n          - \"Business sign-off obtained for all requirements\"\n          - \"Data validation complete with sign-off\"\n          - \"No open critical or high severity defects\"\n          - \"User training completed (if applicable)\"\n          - \"Deployment readiness checklist complete\"\n\n      sign_off_authorities:\n        - \"Business SME (functional behavior and business value)\"\n        - \"Business Data Steward (data quality and business rule compliance)\"\n        - \"UAT Lead (UAT activities complete)\"\n        - \"Compliance Officer (regulatory requirements, if applicable)\"\n\n      context:\n        business_context: \"Domain knowledge, business rules, workflows\"\n        user_personas: \"End user types, skill levels, accessibility\"\n        uat_environment: \"Production-like with representative data\"\n        templates:\n          - \"UAT script template\"\n          - \"Data validation template\"\n          - \"Sign-off process template\"\n\n  # ============================================================================\n  # STAGE 7: RUNTIME FEEDBACK\n  # Reference: Section 10.0\n  # ============================================================================\n  runtime_feedback_stage:\n    section_ref: \"10.0\"\n    purpose: \"Close feedback loop between production runtime and requirements\"\n    focus: \"Requirement key tracking and feedback extraction (NOT deployment mechanics)\"\n\n    agent:\n      name: \"AISDLC Runtime Feedback Agent\"\n      role: \"Telemetry Aggregation & Feedback Generation\"\n\n      responsibilities:\n        - \"Parse and validate release manifests\"\n        - \"Aggregate telemetry from observability platforms\"\n        - \"Link alerts to requirement keys\"\n        - \"Perform root cause and trend analysis\"\n        - \"Generate new intents from runtime observations\"\n        - \"Close the feedback loop to Requirements stage\"\n\n      inputs:\n        - source: \"UAT Stage\"\n          type: \"Sign-off and validated requirements for deployment\"\n        - source: \"CI/CD Platform\"\n          type: \"Release manifests with requirement keys\"\n        - source: \"Observability Platforms\"\n          type: \"Logs, metrics, traces, alerts\"\n          platforms: [\"Datadog\", \"New Relic\", \"Prometheus\", \"Grafana\"]\n        - source: \"Incident Management\"\n          type: \"Production issues and anomalies\"\n          systems: [\"PagerDuty\", \"Opsgenie\"]\n\n      outputs:\n        release_manifests:\n          format: \"Requirement keys with versions per release\"\n          example: \"v2.5.0: <REQ-ID> (v1), REQ-NFR-PERF-001 (v2)\"\n\n        runtime_telemetry:\n          tagged_with: \"Requirement keys from code annotations\"\n          types: [\"metrics\", \"logs\", \"traces\"]\n\n        alerts:\n          tagged_with: \"Requirement keys\"\n          linked_to: \"Incident management systems\"\n\n        feedback_reports:\n          content: \"New or refined intents from runtime observations\"\n          links_to: \"Requirement keys (traceability)\"\n          destination: \"Intent Manager â†’ Re-enter lifecycle at Requirements\"\n\n        traceability_reports:\n          analyses: [\"impact_analysis\", \"trend_analysis\", \"root_cause_traces\"]\n          mapping: \"Requirement key to alert mappings\"\n\n      key_principles:\n        requirement_key_tagging:\n          - \"Every log, metric, alert tagged with requirement key\"\n          - \"Example: ERROR: <REQ-ID> - Authentication failure\"\n\n        two_way_traceability:\n          forward: \"Intent â†’ Design â†’ Code â†’ Test â†’ UAT â†’ Runtime Metrics\"\n          backward: \"Production Alert â†’ Requirement â†’ Code â†’ Design â†’ Intent\"\n\n        closed_loop:\n          principle: \"Runtime feedback MUST create new intents\"\n          flow: \"Runtime data â†’ New Intent â†’ Re-enter at Requirements\"\n\n        observability_complete:\n          - \"Application telemetry (logs, metrics, traces)\"\n          - \"Data observability (quality, lineage, schema)\"\n          - \"Compliance data\"\n\n        feedback_mechanisms:\n          - \"Production issues â†’ New intent to improve UAT\"\n          - \"Trend analysis â†’ Intent to refactor/redesign\"\n          - \"Performance degradation â†’ Intent to optimize\"\n          - \"Coverage gaps â†’ Missing test scenarios\"\n\n      quality_gates:\n        - \"All deployed code tagged with requirement keys\"\n        - \"Telemetry systems capture requirement keys\"\n        - \"Alerts routed to Intent Manager\"\n        - \"Release manifests include requirement traceability\"\n        - \"Incident response links to requirements\"\n\n      metrics:\n        telemetry_coverage: \"% of code with requirement key tags (target: 100%)\"\n        feedback_latency: \"Time from production issue to new intent\"\n        traceability_completeness: \"% of alerts with linked requirement keys (target: 100%)\"\n\n      context:\n        observability_platforms: [\"Datadog\", \"New Relic\", \"Prometheus\", \"Grafana\"]\n        ci_cd_platforms: [\"Jenkins\", \"GitLab CI\", \"GitHub Actions\", \"ArgoCD\"]\n        incident_management: [\"PagerDuty\", \"Opsgenie\"]\n        compliance_systems: \"Regulatory audit systems\"\n\n# ============================================================================\n# CROSS-STAGE INTEGRATION\n# ============================================================================\nintegration:\n  traceability_flow:\n    forward: \"Intent â†’ Requirements â†’ Design â†’ Tasks â†’ Code â†’ System Test â†’ UAT â†’ Runtime\"\n    backward: \"Runtime Issues â†’ Requirements â†’ Intent\"\n\n  requirement_key_propagation:\n    stages: [\"Requirements\", \"Design\", \"Tasks\", \"Code\", \"System Test\", \"UAT\", \"Runtime\"]\n    mandatory: \"All artifacts tagged with requirement keys\"\n\n  feedback_loops:\n    - from: \"Design\"\n      to: \"Requirements\"\n      trigger: \"Design gaps, feasibility issues\"\n\n    - from: \"Tasks\"\n      to: \"Requirements\"\n      trigger: \"Capacity/feasibility constraints\"\n\n    - from: \"Code\"\n      to: \"Requirements\"\n      trigger: \"Implementation discoveries\"\n\n    - from: \"System Test\"\n      to: \"Requirements\"\n      trigger: \"Coverage gaps, ambiguous requirements\"\n\n    - from: \"UAT\"\n      to: \"Requirements\"\n      trigger: \"Rejected requirements, latent intent\"\n\n    - from: \"Runtime\"\n      to: \"Intent Manager\"\n      trigger: \"Production issues, performance degradation, new user needs\"\n\n  concurrent_execution:\n    principle: \"Any work that can run concurrently should run concurrently\"\n    trigger: \"When common asset like Requirements exists, dependent tasks can run in parallel\"\n    examples:\n      - \"Architecture SDLC and UAT Test SDLC run concurrently with main Code SDLC\"\n      - \"Data Pipeline SDLC runs alongside Application SDLC\"\n\n# ============================================================================\n# METADATA\n# ============================================================================\nmetadata:\n  created: \"2025-01-14\"\n  version: \"0.4.9\"\n  reference_document: \"/Users/jim/src/apps/ai_sdlc_method/docs/ai_sdlc_method.md\"\n  key_principles_integration: \"file://config.yml (Key Principles for Code Stage)\"\n  methodology_origin: \"https://github.com/foolishimp/ai_init\"\n  ultimate_mantra: \"Excellence or nothing\"\n  note: \"Key Principles can evolve per project context - see docs/principles/KEY_PRINCIPLES.md\"\n  changelog:\n    v0.4.9: \"Added mandatory_artifacts section - opinionated artifacts required per stage for traceability\"\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/docs/README.md": "# Development Methodology\n\n## Baseline Practices for ai_sdlc_method\n\nThis directory contains the core development methodology for ai_sdlc_method, adapted from the [ai_init project](https://github.com/foolishimp/ai_init). These practices form the **foundation** of how we build software.\n\n---\n\n## Quick Start\n\n### The Key Principles Principles\n\n1. **Test Driven Development** - \"No code without tests\"\n2. **Fail Fast & Root Cause** - \"Break loudly, fix completely\"\n3. **Modular & Maintainable** - \"Single responsibility, loose coupling\"\n4. **Reuse Before Build** - \"Check first, create second\"\n5. **Open Source First** - \"Suggest alternatives, human decides\"\n6. **No Legacy Baggage** - \"Clean slate, no debt\"\n7. **Perfectionist Excellence** - \"Best of breed only\"\n\n**Ultimate Mantra**: **\"Excellence or nothing\"** ğŸ”¥\n\nğŸ‘‰ [Read Full Principles](principles/KEY_PRINCIPLES.md)\n\n### The TDD Workflow\n\n```\nRED â†’ GREEN â†’ REFACTOR â†’ COMMIT â†’ REPEAT\n```\n\nğŸ‘‰ [Read TDD Workflow](processes/TDD_WORKFLOW.md)\n\n---\n\n## Directory Structure\n\n```\nmethodology/\nâ”œâ”€â”€ README.md                      # This file\nâ”œâ”€â”€ principles/                    # Core principles\nâ”‚   â””â”€â”€ KEY_PRINCIPLES.md           # The Key Principles\nâ”œâ”€â”€ processes/                     # Development processes\nâ”‚   â””â”€â”€ TDD_WORKFLOW.md           # Test-Driven Development\nâ”œâ”€â”€ templates/                     # Templates and examples\nâ”‚   â””â”€â”€ (future: task templates)\nâ””â”€â”€ guides/                        # How-to guides\n    â””â”€â”€ (future: specific guides)\n```\n\n---\n\n## Core Documents\n\n### Principles\n\n#### [The Key Principles](principles/KEY_PRINCIPLES.md)\nThe seven fundamental principles that govern all development:\n- Test Driven Development\n- Fail Fast & Root Cause\n- Modular & Maintainable\n- Reuse Before Build\n- Open Source First\n- No Legacy Baggage\n- Perfectionist Excellence\n\n**When to read**: Before starting any development work\n\n### Processes\n\n#### [TDD Workflow](processes/TDD_WORKFLOW.md)\nComplete guide to Test-Driven Development:\n- RED â†’ GREEN â†’ REFACTOR cycle\n- Writing effective tests\n- Refactoring practices\n- Common scenarios\n- Anti-patterns to avoid\n\n**When to read**: Daily, during development\n\n---\n\n## Quick Reference\n\n### Before You Code\n\nAsk these questions (from the Key Principles):\n\n1. **Have I written tests first?** (Principle #1)\n2. **Will this fail loudly if something's wrong?** (Principle #2)\n3. **Does this module have a single, clear purpose?** (Principle #3)\n4. **Did I check if this already exists?** (Principle #4)\n5. **Have I researched alternatives?** (Principle #5)\n6. **Am I avoiding technical debt?** (Principle #6)\n7. **Is this the best possible implementation?** (Principle #7)\n\n**If you can't answer \"yes\" to all seven, don't write the code yet.**\n\n### Common Commands\n\n```bash\n# Run all tests\npytest tests/\n\n# Run with coverage\npytest tests/ --cov=src/ai_sdlc_config --cov-report=html\n\n# Watch mode (TDD)\npytest tests/ --watch\n\n# Run specific test\npytest tests/test_hierarchy_merger.py::test_merge_two_hierarchies -v\n```\n\n### TDD Cycle\n\n```python\n# 1. RED: Write failing test\ndef test_new_feature():\n    result = my_function()\n    assert result == expected\n\n# Run: pytest (should FAIL)\n\n# 2. GREEN: Write minimal code\ndef my_function():\n    return expected\n\n# Run: pytest (should PASS)\n\n# 3. REFACTOR: Improve code\ndef my_function():\n    \"\"\"Well-documented, clean implementation.\"\"\"\n    # Improved code\n    return result\n\n# Run: pytest (should still PASS)\n\n# 4. COMMIT\ngit add tests/ src/\ngit commit -m \"feat: add new feature with tests\"\n```\n\n---\n\n## Application to ai_sdlc_method\n\n### Evidence of Excellence\n\nOur commitment to these principles is demonstrated by:\n\n**Test Coverage**:\n- 156 unit tests (100% passing)\n- Test execution: 0.16 seconds\n- Coverage: Comprehensive\n\n**Test Breakdown**:\n- `test_hierarchy_node.py`: 51 tests\n- `test_yaml_loader.py`: 28 tests\n- `test_uri_resolver.py`: 28 tests\n- `test_hierarchy_merger.py`: 31 tests\n- `test_config_manager.py`: 18 tests\n\n**Code Quality**:\n- Modular design (models, loaders, mergers, core)\n- Single responsibility per class\n- Comprehensive documentation\n- No technical debt\n\nğŸ‘‰ [View Test Suite](../tests/)\n\n---\n\n## How to Use This Methodology\n\n### For New Features\n\n1. Read [Key Principles](principles/KEY_PRINCIPLES.md) - Refresh principles\n2. Review [TDD Workflow](processes/TDD_WORKFLOW.md) - Understand process\n3. Write test first (RED phase)\n4. Implement minimally (GREEN phase)\n5. Refactor for quality (REFACTOR phase)\n6. Commit with clear message\n7. Repeat for next test\n\n### For Bug Fixes\n\n1. Write test that reproduces bug (should fail)\n2. Fix the bug (test should pass)\n3. Add related edge case tests\n4. Refactor if needed\n5. Commit fix\n\n### For Refactoring\n\n1. Ensure all tests pass first\n2. Refactor one thing at a time\n3. Keep tests passing throughout\n4. Commit when done\n\n### Code Review Checklist\n\n- [ ] All new code has tests\n- [ ] Tests follow REDâ†’GREENâ†’REFACTOR\n- [ ] Code follows Key Principles principles\n- [ ] No technical debt introduced\n- [ ] Documentation is clear\n- [ ] Commit messages are descriptive\n\n---\n\n## Philosophy\n\n### Why These Principles?\n\nThe Key Principles are not arbitrary rules - they're battle-tested practices that:\n\n1. **Reduce bugs** - Tests catch issues early\n2. **Improve design** - TDD leads to better architecture\n3. **Enable confidence** - Refactor without fear\n4. **Accelerate development** - Clear patterns speed up work\n5. **Ensure quality** - Excellence is built in, not added later\n\n### From ai_init to ai_sdlc_method\n\nai_sdlc_method inherits and extends the ai_init methodology:\n\n**Inherited**:\n- The Key Principles principles\n- TDD workflow (REDâ†’GREENâ†’REFACTOR)\n- \"Excellence or nothing\" mindset\n- Comprehensive testing practices\n\n**Extended**:\n- Applied to configuration management domain\n- Adapted for hierarchical data structures\n- Integrated with MCP service patterns\n- Scaled to 156 tests across 5 modules\n\n---\n\n## Non-Negotiables\n\nThese practices are **requirements**, not suggestions:\n\nâŒ **Rejected**:\n- Code without tests\n- Silent error handling\n- God classes\n- Duplicated functionality\n- Undocumented library choices\n- Technical debt\n- \"Good enough\" quality\n\nâœ… **Required**:\n- Tests first\n- Loud failures\n- Modular design\n- Code reuse\n- Documented decisions\n- Clean implementation\n- Excellence\n\n---\n\n## Resources\n\n### Internal\n\n- [Key Principles Principles](principles/KEY_PRINCIPLES.md)\n- [TDD Workflow](processes/TDD_WORKFLOW.md)\n- [Test Suite](../tests/)\n- [Test README](../tests/README.md)\n\n### External\n\n- [ai_init Repository](https://github.com/foolishimp/ai_init) - Origin of methodology\n- [AI_INIT_REVIEW.md](../AI_INIT_REVIEW.md) - Detailed comparison\n\n### Further Reading\n\n- Kent Beck - \"Test-Driven Development by Example\"\n- Martin Fowler - \"Refactoring\"\n- Robert C. Martin - \"Clean Code\"\n\n---\n\n## Contributing\n\nWhen contributing to ai_sdlc_method:\n\n1. **Read** the Key Principles\n2. **Understand** the TDD workflow\n3. **Apply** the principles\n4. **Write** tests first\n5. **Commit** to excellence\n\n**No exceptions.**\n\n---\n\n## Metrics Dashboard\n\n| Metric | Target | Status |\n|--------|--------|--------|\n| Test Coverage | >80% | âœ… 100% |\n| All Tests Passing | 100% | âœ… 156/156 |\n| Test Execution | <5s | âœ… 0.16s |\n| Key Principles Adherence | 100% | âœ… Yes |\n| Technical Debt | 0 items | âœ… None |\n\n---\n\n## Questions?\n\n- **\"Do I really need to write tests first?\"** - YES. Always. No exceptions.\n- **\"Can I skip refactoring?\"** - NO. Code quality is non-negotiable.\n- **\"Is 80% coverage enough?\"** - It's the minimum. Aim higher.\n- **\"What if I'm in a hurry?\"** - TDD is faster in the long run. Do it right.\n- **\"Can we relax these rules?\"** - NO. Excellence or nothing.\n\n---\n\n## Summary\n\n**The Methodology**: Key Principles + TDD Workflow\n**The Commitment**: Excellence or nothing\n**The Evidence**: 156 tests, 100% passing\n**The Result**: High-quality, maintainable code\n\n**This is how we build software. This is who we are.**\n\n---\n\n*Adapted from [ai_init](https://github.com/foolishimp/ai_init) with gratitude and respect for establishing these excellent practices.*\n\nğŸ”¥ **Excellence or nothing** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/docs/guides/PAIR_PROGRAMMING_WITH_AI.md": "# Pair Programming with AI - Best Practices\n\n## ğŸ¯ Core Concept: Human-AI Pair Programming\n\nYou are the **Driver** (strategic decisions) and AI is the **Navigator** (tactical implementation), but these roles can switch based on the task.\n\n---\n\n## ğŸ‘¥ Role Definitions\n\n### Human as Driver / AI as Navigator\n**You decide WHAT to build, AI figures out HOW**\n\n**Human (Driver) Responsibilities:**\n- Define the goal and requirements\n- Make architectural decisions\n- Approve approaches before implementation\n- Review and request changes\n- Decide when to commit\n\n**AI (Navigator) Responsibilities:**\n- Suggest implementation approaches\n- Write tests and code\n- Spot potential issues\n- Offer alternatives\n- Handle repetitive tasks\n\n### Role Switching\n**Sometimes AI should drive (with your approval):**\n- Writing boilerplate code\n- Implementing well-defined patterns\n- Refactoring for code quality\n- Writing comprehensive tests\n- Documenting changes\n\n---\n\n## ğŸ—£ï¸ Communication Patterns\n\n### 1. Think Aloud Protocol\n**Human:** Explain your reasoning\n```\n\"I want to add multiplayer because players requested it\"\n\"I'm worried about performance with 100 characters\"\n\"This feels too complex, let's simplify\"\n```\n\n**AI:** Should explain approach\n```\n\"I'll use TDD here because...\"\n\"This might cause issues with...\"\n\"Alternative approach would be...\"\n```\n\n### 2. Frequent Check-ins\n**Every 10-15 minutes or after major changes:**\n- \"Does this look right?\"\n- \"Should we test this now?\"\n- \"Any concerns with this approach?\"\n- \"Ready to move on?\"\n\n### 3. Clear Handoffs\n**When switching tasks:**\n```\nHuman: \"I've set up the structure, can you implement the tests?\"\nAI: \"Tests are ready, please review before I implement\"\nHuman: \"Looks good, proceed with implementation\"\n```\n\n---\n\n## ğŸ“‹ Pair Programming Workflow\n\n### 1. ALIGN - Start with shared understanding\n```markdown\nHuman: \"Today we're working on [WHAT]\"\nAI: \"I understand we're building [WHAT]. Should I start with [APPROACH]?\"\nHuman: \"Yes, but first let's [CLARIFICATION]\"\n```\n\n### 2. PLAN - Agree on approach\n```markdown\nAI: \"Here's my planned approach:\n1. Write tests for X\n2. Implement Y\n3. Refactor Z\nAny concerns?\"\nHuman: \"Looks good, but change step 2 to use pattern ABC\"\n```\n\n### 3. IMPLEMENT - Work together\n```markdown\nAI: \"Starting with tests...\" [writes code]\nHuman: \"Wait, shouldn't we test edge case XYZ?\"\nAI: \"Good catch! Adding test for XYZ\"\n```\n\n### 4. REVIEW - Check each other's work\n```markdown\nAI: \"Tests are green. Here's what I implemented...\"\nHuman: \"This function is too complex, can we split it?\"\nAI: \"Refactoring into smaller functions...\"\n```\n\n### 5. VALIDATE - Confirm it works\n```markdown\nHuman: \"Let me test this manually...\"\nAI: \"I'll run the automated tests\"\nBoth: \"Everything looks good!\"\n```\n\n---\n\n## ğŸ”„ Ping-Pong Pattern\n\n### Classic TDD Ping-Pong\n1. **Human writes test** â†’ AI implements\n2. **AI writes test** â†’ Human implements\n3. Alternate until feature complete\n\n### Modified for Human-AI\n1. **Human describes test case** â†’ AI writes test\n2. **AI shows failing test** â†’ Human approves\n3. **AI implements** â†’ Human reviews\n4. **Both refactor together**\n\n---\n\n## ğŸš« Anti-Patterns to Avoid\n\n### 1. Silent Coding\nâŒ **Bad:** AI writes 500 lines without explanation\nâœ… **Good:** AI explains approach, implements in chunks, asks for feedback\n\n### 2. Assumption Making\nâŒ **Bad:** AI assumes architectural decisions\nâœ… **Good:** AI asks: \"Should this be a new module or extend existing?\"\n\n### 3. Big Bang Implementation\nâŒ **Bad:** Implement entire feature then test\nâœ… **Good:** Small increments with tests at each step\n\n### 4. Ignoring Feedback\nâŒ **Bad:** AI continues despite human concerns\nâœ… **Good:** AI stops and addresses concerns immediately\n\n### 5. No Knowledge Transfer\nâŒ **Bad:** AI does complex work without explanation\nâœ… **Good:** AI explains WHY, not just WHAT\n\n---\n\n## ğŸ’¡ Best Practices from Traditional Pair Programming\n\n### 1. Take Breaks\n- After complex implementations\n- When stuck on a problem\n- Every 45-60 minutes\n\n### 2. Celebrate Small Wins\n```markdown\nHuman: \"Nice! That test caught a bug\"\nAI: \"Great refactoring suggestion!\"\n```\n\n### 3. Share Knowledge\n```markdown\nAI: \"Here's a pattern that might help...\"\nHuman: \"Let me explain the business logic...\"\n```\n\n### 4. Stay Engaged\n- Human: Don't just say \"implement X\" and disappear\n- AI: Don't just dump code without context\n\n### 5. Respect Expertise\n- Human knows the business domain\n- AI knows patterns and syntax\n- Both contribute valuable perspectives\n\n---\n\n## ğŸ“Š Pair Programming Metrics\n\nTrack these to improve collaboration:\n- **Cycle Time**: How long from idea to working code?\n- **Defect Rate**: Bugs found after \"completion\"\n- **Rework Rate**: How often do we redo work?\n- **Communication Clarity**: Misunderstandings per session\n\n---\n\n## ğŸ® Quick Commands for Pairing\n\n### Human Can Say:\n```\n\"Let's pair on this\" - Start collaboration\n\"You drive\" - AI takes lead\n\"I'll drive\" - Human takes lead\n\"Hold on\" - Pause for review\n\"Explain that\" - Need clarification\n\"Try again\" - Different approach needed\n\"Ship it\" - Ready to commit\n```\n\n### AI Should Say:\n```\n\"Should I proceed with...\" - Before major changes\n\"I notice...\" - Pointing out issues\n\"Alternative approach...\" - Suggesting options\n\"Ready for review\" - After implementation\n\"Tests passing\" - Status update\n\"Need clarification on...\" - When unsure\n```\n\n---\n\n## ğŸ Session Structure\n\n### Start of Session\n1. Review previous work\n2. Align on today's goals\n3. Decide who drives first\n4. Set check-in intervals\n\n### During Session\n1. Communicate constantly\n2. Switch roles as needed\n3. Test frequently\n4. Document decisions\n\n### End of Session\n1. Review what was accomplished\n2. Commit with descriptive message\n3. Note any follow-up tasks\n4. Clean up workspace\n\n---\n\n## ğŸ¤ The Pairing Contract\n\n**Human agrees to:**\n- Provide clear requirements\n- Give timely feedback\n- Make decisions when needed\n- Review code before committing\n\n**AI agrees to:**\n- Explain approaches clearly\n- Ask before major changes\n- Write tests first\n- Document thoroughly\n\n**Both agree to:**\n- Respect each other's input\n- Focus on the goal\n- Keep communication clear\n- Learn from each other\n\n---\n\n## ğŸ¯ Benefits of Human-AI Pairing\n\n1. **Continuous Code Review** - Every line reviewed\n2. **Knowledge Documentation** - Conversation becomes docs\n3. **Reduced Cognitive Load** - Share mental burden\n4. **24/7 Availability** - AI never needs coffee\n5. **Learning Opportunity** - Both parties improve\n6. **Higher Quality** - Two perspectives catch more issues\n7. **Faster Development** - Parallel thinking\n8. **Built-in Testing** - TDD becomes natural\n\n---\n\nThis approach treats AI as a true pair programming partner, incorporating the best practices from human pair programming while adapting for the unique aspects of human-AI collaboration.\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/docs/guides/TASK_TEMPLATE.md": "# Task Template\n\nCopy this template when creating a new finished task file.\n\n---\n\n# Task: [Task Title]\n\n**Status:** Completed\n**Date:** YYYY-MM-DD\n**Time:** HH:MM\n**Actual Time:** X hours (Estimated: Y hours)\n\n## Problem\n[Describe the issue or requirement that prompted this task]\n\n## Investigation\n[Document any research or debugging steps taken]\n\n## Solution\n[Explain the approach taken to solve the problem]\n\n## Files Modified\n- `/path/to/file1.py` - [Brief description of changes]\n- `/path/to/file2.py` - [Brief description of changes]\n\n## Files Created\n- `/path/to/newfile.py` - [Purpose of new file]\n\n## Code Changes\n```python\n# Show key code changes\n# Before:\ndef old_code():\n    pass\n\n# After:\ndef new_code():\n    # Improved implementation\n    pass\n```\n\n## Testing\n[Describe how the solution was tested]\n\nExample:\n```bash\n# Run specific test\npytest tests/test_feature.py::test_new_functionality -v\n\n# Results\nPASSED tests/test_feature.py::test_new_functionality\nCoverage: 95%\n```\n\n## Result\n[What was achieved and verified working]\n\n## Side Effects\n[Any unexpected changes or impacts. Write \"None\" if no side effects]\n\n## Future Considerations\n[Things to watch out for or improve later]\n\n## Lessons Learned\n[Insights gained from this task]\n\n---\n\n## Metrics (Optional)\n\n- **Lines Added:** X\n- **Lines Removed:** Y\n- **Tests Added:** Z\n- **Test Coverage:** N%\n- **Complexity:** Low/Medium/High\n\n---\n\n## Related\n\n- **Related Tasks:** Link to related task files\n- **Related Issues:** GitHub issue numbers\n- **Documentation:** Links to updated docs\n- **References:** Relevant resources used\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/docs/guides/UNIFIED_PRINCIPLES.md": "# Unified Development Principles - No Conflicts\n\n## ğŸ¯ Core Hierarchy of Principles\n\nWhen in doubt, follow this priority order (references Key Principles principles):\n\n1. **Test First** (Principle #1) - TDD before implementation, no exceptions\n2. **Fail Fast** (Principle #2) - Root cause over workarounds\n3. **Reuse Before Build** (Principle #4) - Check existing code first\n4. **Open Source First** (Principle #5) - AI suggests, human decides\n5. **Quality Excellence** (Principle #7) - Perfectionist standard\n6. **No Tech Debt** (Principle #6) - Clean slate, no legacy baggage\n7. **Modular Design** (Principle #3) - Decoupled, maintainable code\n\n---\n\n## âœ… Resolved Principle Clarifications\n\n### 1. Quality vs Pace\n**Principle:** We are perfectionist developers who work at a sustainable pace\n- âœ… High quality code with >80% test coverage\n- âœ… Take breaks every 45-60 minutes\n- âœ… No rushing - better to do it right\n- âœ… Celebrate progress to maintain morale\n\n### 2. Decision Making\n**Principle:** AI suggests, human decides\n- âœ… AI SUGGESTS open source alternatives\n- âœ… AI PROPOSES architectural approaches\n- âœ… Human MAKES final decisions\n- âœ… Human APPROVES before major changes\n\n### 3. Documentation Timing\n**Principle:** Document continuously, formalize at completion\n- âœ… During: Document decisions in comments/chat\n- âœ… During: Update TodoWrite for progress tracking\n- âœ… After: Create formal finished task file\n- âœ… After: Update active tasks\n\n### 4. Testing Philosophy\n**Principle:** Fail fast to find problems, then fix properly\n- âœ… RED: Write tests that fail (expose problems)\n- âœ… GREEN: Minimal code to pass (quick validation)\n- âœ… REFACTOR: Improve to production quality\n- âœ… No workarounds - fix root causes\n\n### 5. Code Changes\n**Principle:** Small, safe, reversible changes\n- âœ… Feature flags for new features (where appropriate)\n- âœ… Keep old code until new is proven\n- âœ… Small incremental commits\n- âœ… One task = one commit\n\n### 6. Communication\n**Principle:** Over-communicate rather than assume\n- âœ… AI explains BEFORE implementing\n- âœ… Human provides feedback DURING work\n- âœ… Both check in every 10-15 minutes\n- âœ… Ask when uncertain\n\n### 7. Architecture\n**Principle:** Design for clarity, not cleverness\n- âœ… Clear over clever\n- âœ… Show errors clearly, don't degrade silently\n- âœ… Explicit over implicit\n- âœ… Simple over complex\n\n### 8. Refactoring\n**Principle:** Refactor with purpose, not perfectionism\n- âœ… Only refactor with clear goal\n- âœ… Keep working code working\n- âœ… Test before and after\n- âœ… Document why refactoring was needed\n\n---\n\n## ğŸš« Anti-Principles (What We DON'T Do)\n\n1. **NO Quick Fixes** - Even if faster\n2. **NO Assumptions** - Ask if unsure\n3. **NO Big Bang Changes** - Incremental only\n4. **NO Silent Failures** - Fail loudly\n5. **NO Tech Debt** - Fix it right first time\n6. **NO Backwards Compatibility** - This is new development\n7. **NO Implementation Before Tests** - TDD always\n\n---\n\n## ğŸ“ When Principles Seem to Conflict\n\nUse this decision tree:\n\n```\nIs it a safety issue?\nâ”œâ”€â”€ YES â†’ Safety first (don't break working code)\nâ””â”€â”€ NO â†’ Continue\n    â”‚\n    Is it a quality issue?\n    â”œâ”€â”€ YES â†’ Quality over speed\n    â””â”€â”€ NO â†’ Continue\n        â”‚\n        Is it an architectural decision?\n        â”œâ”€â”€ YES â†’ Human decides\n        â””â”€â”€ NO â†’ Continue\n            â”‚\n            Is it about approach?\n            â”œâ”€â”€ YES â†’ Follow TDD process\n            â””â”€â”€ NO â†’ Ask for clarification\n```\n\n---\n\n## ğŸ“‹ Quick Reference Card\n\n### Every Task\n1. Write tests first (RED)\n2. Minimal implementation (GREEN)\n3. Refactor for quality (REFACTOR)\n4. Document everything\n5. Commit with details\n\n### Every Session\n1. Review methodologies\n2. Check active tasks\n3. Align on goals\n4. Work in small increments\n5. Commit completed work\n\n### Every Decision\n1. Is it tested?\n2. Is it documented?\n3. Is it approved?\n4. Is it reversible?\n5. Is it the right fix?\n\n---\n\n## ğŸ¤ The Agreement\n\n**AI and Human agree:**\n- Quality is non-negotiable\n- Tests come first\n- Communication is continuous\n- Documentation is mandatory\n- We're building something great together\n\nNo conflicts, only clarity!\n\n---\n\n## ğŸ” Principle Application Examples\n\n### Example 1: Adding a New Feature\n```\nâœ… Correct Flow:\n1. Human: \"We need user authentication\"\n2. AI: \"I'll start with tests for login/logout. Should we use JWT?\"\n3. Human: \"Yes, JWT is fine\"\n4. AI: \"Writing failing test for login...\"\n5. [RED â†’ GREEN â†’ REFACTOR cycle]\n6. AI: \"Feature complete, all tests passing, ready for review\"\n7. Human: \"Approved, commit it\"\n\nâŒ Wrong Flow:\n1. Human: \"We need user authentication\"\n2. AI: [Implements entire auth system without tests]\n3. AI: \"Done! Here's 1000 lines of code\"\n4. [No tests, no review, no communication]\n```\n\n### Example 2: Fixing a Bug\n```\nâœ… Correct Flow:\n1. AI: \"Found a bug in the payment processor\"\n2. AI: \"Writing test to reproduce the bug...\" [RED]\n3. AI: \"Test failing as expected, investigating root cause...\"\n4. AI: \"Root cause: null check missing. Fixing...\" [GREEN]\n5. AI: \"Refactoring for clarity...\" [REFACTOR]\n6. AI: \"All tests passing, bug fixed properly\"\n\nâŒ Wrong Flow:\n1. AI: \"Found a bug, adding try-catch to hide it\"\n2. [Workaround that doesn't fix root cause]\n```\n\n---\n\n## ğŸ’¡ Remember\n\nThese principles work together, not against each other. When you understand the \"why\" behind each principle, conflicts disappear and development flows smoothly.\n\n**Ultimate Mantra: \"Excellence or nothing\"**\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/docs/guides/deprecated/SESSION_STARTER.md": "# Session Starter Checklist\n\n## ğŸš€ Start of Every Session\n\nRun these commands and review these items EVERY time you start working:\n\n### 1. Check Current State\n```bash\n# Where are we?\ngit status\ngit log --oneline -5\n\n# What's active?\ncat methodology/active_tasks/ACTIVE_TASKS.md  # or your task tracking file\n\n# Any failing tests?\npytest  # or npm test, depending on your project\n```\n\n### 2. Review Core Documents\n- [ ] Read `methodology/principles/KEY_PRINCIPLES.md` - The 7 Sacred Principles\n- [ ] Read `methodology/processes/TDD_WORKFLOW.md` - TDD methodology\n- [ ] Read `methodology/guides/PAIR_PROGRAMMING_WITH_AI.md` - Collaboration approach\n- [ ] Read `methodology/README.md` - Quick reference\n\n### 3. Align on Goals\n```markdown\nHuman: \"Today we're working on [WHAT]\"\nAI: \"I understand. Let me check the current state and active tasks...\"\n```\n\n### 4. Choose Working Mode\n- [ ] **Pair Programming Mode**: Human drives strategy, AI navigates\n- [ ] **TDD Mode**: RED â†’ GREEN â†’ REFACTOR cycle\n- [ ] **Bug Fix Mode**: Reproduce â†’ Test â†’ Fix â†’ Verify\n- [ ] **Exploration Mode**: Research and investigation\n\n### 5. Set Up for Success\n```bash\n# Start dev server if needed\nnpm run dev  # or python manage.py runserver, etc.\n\n# Start test watcher for TDD\npytest --watch  # or npm test -- --watch\n\n# Open browser to relevant page (if web project)\n# open http://localhost:3000/[relevant-page]\n```\n\n---\n\n## ğŸ“ Quick Session Template\n\nCopy and paste this at the start of each session:\n\n```markdown\n## Session: [DATE] [TIME]\n\n### Goals\n1. [ ] Primary goal\n2. [ ] Secondary goal\n3. [ ] Stretch goal\n\n### Current Task\n- Task #N from active tasks\n- Status: In Progress\n- Feature Flag: task-N-feature-name (if applicable)\n\n### Approach\n- [ ] TDD: Write tests first\n- [ ] Feature flag created (if new feature)\n- [ ] TodoWrite tracking active\n\n### Check-in Schedule\n- [ ] 15 min - Initial approach review\n- [ ] 30 min - Progress check\n- [ ] 45 min - Testing checkpoint\n- [ ] 60 min - Documentation & commit\n\n### End of Session\n- [ ] All tests passing\n- [ ] Documentation updated\n- [ ] Committed with proper message\n- [ ] Active tasks updated\n```\n\n---\n\n## ğŸ”„ Context Recovery\n\nIf context is lost mid-session, quickly recover with:\n\n```bash\n# What were we doing?\ngit status\ngit diff\n\n# What's the plan?\ncat methodology/active_tasks/ACTIVE_TASKS.md  # or your task file\n\n# What's the methodology?\nhead -20 methodology/processes/TDD_WORKFLOW.md\n\n# Recent work?\ngit log --oneline -10\n```\n\n---\n\n## ğŸ¯ Key Principles to Remember\n\n1. **TDD First**: RED â†’ GREEN â†’ REFACTOR\n2. **Pair Programming**: Communicate, check-in, collaborate\n3. **Small Commits**: One task = one commit\n4. **Feature Flags**: New features behind flags (where appropriate)\n5. **Documentation**: Every task gets documented\n6. **Test Coverage**: Maintain >80%\n\n---\n\n## ğŸš¨ If You Get Lost\n\nJust ask:\n- \"What's our current task?\"\n- \"Show me the active tasks\"\n- \"What's the TDD process again?\"\n- \"Should we check in?\"\n\nThe human will help reorient the session!\n\n---\n\n## ğŸ’¡ Pro Tips\n\n### Before Starting\n- **Clear your head**: Take a moment to focus\n- **Remove distractions**: Close unrelated tabs/windows\n- **Set a timer**: Plan for breaks every 45-60 minutes\n\n### During Session\n- **Stay in the zone**: One task at a time\n- **Test often**: Don't wait until \"done\"\n- **Commit early**: Save progress incrementally\n- **Communicate**: Over-communicate rather than assume\n\n### After Session\n- **Document**: Update task tracking\n- **Clean up**: Close feature flags if appropriate\n- **Reflect**: What went well? What to improve?\n- **Plan ahead**: Note what's next\n\n---\n\n## ğŸ“ Session Success Criteria\n\nA successful session has:\n- âœ… Clear goals defined upfront\n- âœ… Tests written before code\n- âœ… All tests passing\n- âœ… Code reviewed and refactored\n- âœ… Changes committed with good messages\n- âœ… Documentation updated\n- âœ… Next steps identified\n\n---\n\n## ğŸ¤ The Session Contract\n\n**At the start of each session, agree on:**\n1. What we're building today\n2. Who drives first (human or AI)\n3. When we'll check in\n4. What \"done\" looks like\n5. When we'll take breaks\n\n**This ensures both partners are aligned and working effectively together!**\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/docs/principles/KEY_PRINCIPLES.md": "# ğŸ¯ The Key Principles (Code Stage)\n\n## Core Development Methodology for ai_sdlc_method\n\nThese foundational principles guide all development in this project. They are adapted from the [ai_init](https://github.com/foolishimp/ai_init) project and represent our unwavering commitment to excellence.\n\n**Important**: While these seven principles provide an excellent foundation, they can and should evolve based on project context and operational needs. See [Principle Evolution](#-principle-evolution) below.\n\n---\n\n## The Seven Key Principles\n\n### 1ï¸âƒ£ Test Driven Development\n**\"No code without tests\"**\n\n- **Workflow**: RED â†’ GREEN â†’ REFACTOR\n- Write tests first, always\n- Maintain >80% code coverage\n- Tests are documentation\n\n**In Practice**:\n```python\n# âŒ Wrong: Write code first\ndef merge_hierarchies(hierarchies):\n    # implementation...\n\n# âœ… Right: Write test first\ndef test_merge_hierarchies():\n    assert merger.merge([base, override]) == expected\n\n# Then write implementation\ndef merge_hierarchies(hierarchies):\n    # implementation...\n```\n\n---\n\n### 2ï¸âƒ£ Fail Fast & Root Cause\n**\"Break loudly, fix completely\"**\n\n- No workarounds or band-aids\n- Fix the cause, not symptoms\n- Let errors be obvious\n- No hiding bugs\n\n**In Practice**:\n```python\n# âŒ Wrong: Silence errors\ntry:\n    load_config(path)\nexcept:\n    pass  # Hide the problem\n\n# âœ… Right: Fail loudly\ndef load_config(path):\n    if not Path(path).exists():\n        raise FileNotFoundError(f\"Config not found: {path}\")\n```\n\n---\n\n### 3ï¸âƒ£ Modular & Maintainable\n**\"Single responsibility, loose coupling\"**\n\n- Each module does one thing well\n- Decoupled components\n- Easy to understand\n- Easy to extend\n\n**In Practice**:\n```python\n# âŒ Wrong: God class doing everything\nclass ConfigSystem:\n    def load_yaml(self): ...\n    def merge_configs(self): ...\n    def resolve_uris(self): ...\n    def query_llm(self): ...\n\n# âœ… Right: Focused classes\nclass YAMLLoader:\n    def load(self, path): ...\n\nclass HierarchyMerger:\n    def merge(self, hierarchies): ...\n\nclass URIResolver:\n    def resolve(self, uri_ref): ...\n```\n\n---\n\n### 4ï¸âƒ£ Reuse Before Build\n**\"Check first, create second\"**\n\n- Search existing code before writing new\n- Use what exists\n- Document new creations\n- Avoid duplication\n\n**In Practice**:\n```python\n# Before writing new code, ask:\n# 1. Does this functionality exist?\n# 2. Can I reuse an existing pattern?\n# 3. Is there a library for this?\n\n# âœ… Right: Reuse existing\nfrom pathlib import Path  # Don't write your own path handling\nimport yaml  # Don't write your own YAML parser\n```\n\n---\n\n### 5ï¸âƒ£ Open Source First\n**\"Suggest alternatives, human decides\"**\n\n- Research existing libraries\n- Claude suggests options\n- Human makes final choice\n- Prefer battle-tested solutions\n\n**In Practice**:\n```markdown\nWhen needing URI parsing:\n- Option 1: urllib.parse (built-in)\n- Option 2: requests (popular)\n- Option 3: httpx (modern)\n\nRecommendation: Use urllib.parse for basic needs,\nhttpx for advanced features. Human decides.\n```\n\n---\n\n### 6ï¸âƒ£ No Legacy Baggage\n**\"Clean slate, no debt\"**\n\n- No backwards compatibility constraints\n- No technical debt\n- Replace completely if needed\n- Fresh start mentality\n\n**In Practice**:\n```python\n# âœ… Right: Clean breaks\n# v1.0 â†’ v2.0 with breaking changes is OK\n# Document migration path clearly\n# Don't carry old cruft forward\n\n# If HierarchyNode design is flawed:\n# - Design HierarchyNode v2\n# - Provide migration tools\n# - Don't patch the old design\n```\n\n---\n\n### 7ï¸âƒ£ Perfectionist Excellence\n**\"Best of breed only\"**\n\n- Quality over quantity\n- Ship when excellent, not \"good enough\"\n- Hardcore standards\n- No compromises on quality\n\n**Ultimate Mantra**: **\"Excellence or nothing\"**\n\n**In Practice**:\n```python\n# âŒ Wrong: Ship it, we'll fix later\ndef merge(hierarchies):\n    # TODO: Handle edge cases\n    # TODO: Improve performance\n    # TODO: Add validation\n    return quick_dirty_merge(hierarchies)\n\n# âœ… Right: Ship it right\ndef merge(self, hierarchies: List[HierarchyNode]) -> HierarchyNode:\n    \"\"\"\n    Merge multiple hierarchies with priority-based overrides.\n\n    Fully tested, documented, and handles all edge cases.\n    \"\"\"\n    if not hierarchies:\n        raise ValueError(\"Cannot merge empty list\")\n    # Complete, correct implementation\n```\n\n---\n\n## ğŸš€ Quick Decision Tree\n\n```\nNeed to build something?\nâ”‚\nâ”œâ”€ #4: Does it exist already? â†’ Use existing\nâ”‚\nâ”œâ”€ #5: Is there an open source solution? â†’ Evaluate options\nâ”‚\nâ”œâ”€ #1: Write tests first â†’ RED phase\nâ”‚\nâ”œâ”€ #2: Let it fail visibly â†’ No silent errors\nâ”‚\nâ”œâ”€ #3: Make it modular â†’ Single responsibility\nâ”‚\nâ”œâ”€ #6: Don't carry debt â†’ Clean implementation\nâ”‚\nâ””â”€ #7: Make it excellent â†’ Ship quality\n```\n\n---\n\n## ğŸ”¥ The Mantras\n\n1. **\"Tests before code\"** - Principle #1\n2. **\"Fail loud, fix deep\"** - Principle #2\n3. **\"One job per module\"** - Principle #3\n4. **\"Search before create\"** - Principle #4\n5. **\"Suggest, don't decide\"** - Principle #5\n6. **\"No debt, fresh start\"** - Principle #6\n7. **\"Excellence or nothing\"** - Principle #7\n\n---\n\n## Application to ai_sdlc_method\n\n### Our Commitment\n\nEvery component in this project adheres to the Key Principles:\n\n#### Models (`src/ai_sdlc_config/models/`)\n- âœ… Comprehensive unit tests (51 tests)\n- âœ… Single responsibility (HierarchyNode, URIReference)\n- âœ… Clean, modular design\n\n#### Loaders (`src/ai_sdlc_config/loaders/`)\n- âœ… Test-driven (28 tests for YAML, 28 for URI)\n- âœ… Reuses standard libraries (yaml, urllib)\n- âœ… Fails fast with clear errors\n\n#### Mergers (`src/ai_sdlc_config/mergers/`)\n- âœ… Well-tested (31 tests)\n- âœ… Clean merge strategies\n- âœ… No hidden complexity\n\n#### Core API (`src/ai_sdlc_config/core/`)\n- âœ… Integration tested (18 tests)\n- âœ… High-level, easy to use\n- âœ… Excellent documentation\n\n**Total**: 156 tests, 100% passing, comprehensive coverage\n\n---\n\n## Before You Code\n\nAsk yourself:\n\n1. **Have I written tests first?** (Principle #1)\n2. **Will this fail loudly if something's wrong?** (Principle #2)\n3. **Does this module have a single, clear purpose?** (Principle #3)\n4. **Did I check if this already exists?** (Principle #4)\n5. **Have I researched alternatives?** (Principle #5)\n6. **Am I avoiding technical debt?** (Principle #6)\n7. **Is this the best possible implementation?** (Principle #7)\n\nIf you can't answer \"yes\" to all seven, **don't write the code yet**.\n\n---\n\n## Violations Are Unacceptable\n\nThe Key Principles are not guidelines - they are **requirements** (though they may be adapted per project context).\n\n- Code without tests â†’ **Rejected**\n- Silent error handling â†’ **Rejected**\n- God classes â†’ **Rejected**\n- Duplicated functionality â†’ **Rejected**\n- Undocumented library choices â†’ **Rejected**\n- Technical debt â†’ **Rejected**\n- \"Good enough\" quality â†’ **Rejected**\n\n---\n\n## ğŸ”„ Principle Evolution\n\n### Why Principles Should Evolve\n\nThe seven principles above are **excellent starting points**, but they should adapt to match your project's operational reality. What matters is **explicit documentation** of your principles, not blind adherence to a fixed list.\n\n### Example: Operational Code Evolution\n\n**Context**: Building production operational systems where backwards compatibility is critical.\n\n**Principle #6 Evolution**:\n- **Original**: \"No Legacy Baggage\" - Clean slate, breaking changes OK\n- **Evolved**: \"Feature Flag All Changes\" - Use feature flags for all new features, preserve old features for backwards compatibility\n\n**Why This Works**:\n```yaml\n# Document your project's evolved principles\ncode_stage:\n  key_principles:\n    - name: \"Test Driven Development\"\n      mantra: \"No code without tests\"\n      status: unchanged  # Still applies\n\n    - name: \"Feature Flag Driven Development\"\n      mantra: \"New features behind flags, preserve old features\"\n      status: evolved_from_principle_6  # Adapted for ops context\n      rationale: |\n        In production operational systems, backwards compatibility\n        is more important than clean breaks. Feature flags enable:\n        - Safe rollout/rollback\n        - A/B testing\n        - Gradual migrations\n        - Zero-downtime deployments\n```\n\n### Guidelines for Evolution\n\n1. **Document the Change**: Explicitly state which principle evolved and why\n2. **Maintain the Count**: Keep ~7 principles (human working memory limit)\n3. **Preserve the Spirit**: Keep the commitment to excellence\n4. **Context-Specific**: Different projects can have different evolutions\n5. **Version Your Principles**: Track changes over time\n\n### Common Evolution Patterns\n\n| Original Principle | Operational Context Evolution | Data Science Context Evolution |\n|:---|:---|:---|\n| #6: No Legacy Baggage | â†’ Feature Flag All Changes | â†’ Version All Models |\n| #1: Test Driven Development | â†’ Test + Monitor Driven | â†’ Test + Experiment Driven |\n| #5: Open Source First | â†’ Approved Libraries Only | â†’ Research Models First |\n\n### When to Evolve\n\nâœ… **Good reasons to evolve**:\n- Compliance requirements (e.g., regulatory constraints)\n- Operational maturity (e.g., need for backwards compatibility)\n- Domain-specific needs (e.g., data science vs web apps)\n- Team growth (e.g., need for standardization)\n\nâŒ **Bad reasons to evolve**:\n- Wanting to skip writing tests\n- Avoiding quality standards\n- Rushing to ship incomplete work\n- Cutting corners under pressure\n\n---\n\n## References\n\n- **Origin**: [ai_init project](https://github.com/foolishimp/ai_init) - Original \"Key Principles\"\n- **Applied In**: All ai_sdlc_method development\n- **Enforcement**: Code reviews, CI/CD, peer accountability\n- **Evolution**: Document in your project's `config.yml`\n\n---\n\n*These principles are the foundation of our excellence. They can evolve, but the commitment to excellence cannot.*\n\n**Excellence or nothing. ğŸ”¥**\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/docs/processes/TDD_WORKFLOW.md": "# Test-Driven Development Workflow\n\n## The RED â†’ GREEN â†’ REFACTOR Cycle\n\nThis document defines the complete TDD workflow for ai_sdlc_method, adapted from [ai_init](https://github.com/foolishimp/ai_init).\n\n---\n\n## Overview\n\nTest-Driven Development (TDD) is not optional - it's the foundation of how we build software.\n\n**The Cycle**:\n```\nRED â†’ GREEN â†’ REFACTOR â†’ COMMIT â†’ REPEAT\n```\n\n**The Rule**: **\"No code without tests\"**\n\n---\n\n## The Complete Workflow\n\n### 1ï¸âƒ£ RED: Write Failing Test\n\nWrite a test that defines the desired behavior. The test should fail initially.\n\n**Steps**:\n1. Identify what needs to be tested\n2. Write the test case\n3. Run the test (it should fail)\n4. Verify it fails for the right reason\n\n**Example**:\n```python\ndef test_merge_two_hierarchies():\n    \"\"\"Test merging two hierarchies with override precedence.\"\"\"\n    # Arrange\n    base = HierarchyNode(path=\"\")\n    base.add_child(\"name\", HierarchyNode(path=\"name\", value=\"BaseApp\"))\n\n    override = HierarchyNode(path=\"\")\n    override.add_child(\"name\", HierarchyNode(path=\"name\", value=\"OverrideApp\"))\n\n    merger = HierarchyMerger()\n\n    # Act\n    result = merger.merge([base, override])\n\n    # Assert\n    assert result.get_value_by_path(\"name\") == \"OverrideApp\"\n\n# Run: pytest tests/test_hierarchy_merger.py::test_merge_two_hierarchies\n# Expected: FAIL (merge() not implemented yet)\n```\n\n**Red Phase Checklist**:\n- [ ] Test is clear and focused\n- [ ] Test describes desired behavior\n- [ ] Test fails when run\n- [ ] Failure reason is correct (not syntax error)\n\n---\n\n### 2ï¸âƒ£ GREEN: Write Minimal Code\n\nWrite just enough code to make the test pass. No more, no less.\n\n**Steps**:\n1. Implement the simplest solution\n2. Run the test\n3. Verify it passes\n4. Don't worry about elegance yet\n\n**Example**:\n```python\nclass HierarchyMerger:\n    def merge(self, hierarchies: List[HierarchyNode]) -> HierarchyNode:\n        \"\"\"Merge multiple hierarchies with priority.\"\"\"\n        if not hierarchies:\n            raise ValueError(\"Cannot merge empty list\")\n\n        # Simplest implementation that passes the test\n        if len(hierarchies) == 1:\n            return hierarchies[0]\n\n        result = copy.deepcopy(hierarchies[0])\n        for hierarchy in hierarchies[1:]:\n            # Simple override logic\n            for key, child in hierarchy.children.items():\n                result.children[key] = copy.deepcopy(child)\n\n        return result\n\n# Run: pytest tests/test_hierarchy_merger.py::test_merge_two_hierarchies\n# Expected: PASS\n```\n\n**Green Phase Checklist**:\n- [ ] Test passes\n- [ ] Only necessary code written\n- [ ] No premature optimization\n- [ ] Focus on functionality, not elegance\n\n---\n\n### 3ï¸âƒ£ REFACTOR: Improve Code Quality\n\nNow make the code better while keeping tests green.\n\n**Steps**:\n1. Look for improvements\n2. Refactor one thing at a time\n3. Run tests after each change\n4. Keep tests passing throughout\n\n**Example**:\n```python\nclass HierarchyMerger:\n    def merge(self, hierarchies: List[HierarchyNode]) -> HierarchyNode:\n        \"\"\"\n        Merge multiple hierarchies with priority-based overrides.\n\n        Args:\n            hierarchies: List of HierarchyNode roots, ordered by priority\n                        (first = lowest, last = highest)\n\n        Returns:\n            Merged HierarchyNode tree\n\n        Raises:\n            ValueError: If hierarchies list is empty\n        \"\"\"\n        if not hierarchies:\n            raise ValueError(\"Cannot merge empty list of hierarchies\")\n\n        if len(hierarchies) == 1:\n            return copy.deepcopy(hierarchies[0])\n\n        # Refactored: Extract method, add documentation\n        result = copy.deepcopy(hierarchies[0])\n        for i, hierarchy in enumerate(hierarchies[1:], start=1):\n            result = self._merge_two_nodes(result, hierarchy, priority=i)\n\n        return result\n\n    def _merge_two_nodes(\n        self,\n        base: HierarchyNode,\n        override: HierarchyNode,\n        priority: int\n    ) -> HierarchyNode:\n        \"\"\"Merge two nodes recursively.\"\"\"\n        # Clean, extracted logic\n        ...\n\n# Run: pytest tests/test_hierarchy_merger.py\n# Expected: PASS (all tests still green)\n```\n\n**Refactor Phase Checklist**:\n- [ ] Code is more readable\n- [ ] Duplication removed\n- [ ] Names are clear\n- [ ] Comments explain \"why\" not \"what\"\n- [ ] All tests still pass\n\n---\n\n### 4ï¸âƒ£ COMMIT: Save Progress\n\nCommit your work with a clear, descriptive message.\n\n**Commit Message Format**:\n```\n<type>: <short summary>\n\n<detailed description>\n\n<test evidence>\n\nCo-Authored-By: Claude <noreply@anthropic.com>\n```\n\n**Example**:\n```bash\ngit add tests/test_hierarchy_merger.py src/ai_sdlc_config/mergers/hierarchy_merger.py\ngit commit -m \"feat: implement two-hierarchy merging with priority\n\nAdd merge() method to HierarchyMerger that combines two hierarchies\nwith later configs overriding earlier ones. Implements the foundation\nfor multi-layer configuration merging.\n\nTests:\n- test_merge_two_hierarchies: PASS\n- test_merge_single_hierarchy: PASS\n- test_merge_empty_list_raises_error: PASS\n\nCoverage: mergers/hierarchy_merger.py 95%\n\nCo-Authored-By: Claude <noreply@anthropic.com>\"\n```\n\n**Commit Checklist**:\n- [ ] All tests passing\n- [ ] Commit message is descriptive\n- [ ] Only related changes included\n- [ ] No debug code or comments\n\n---\n\n### 5ï¸âƒ£ REPEAT: Next Test\n\nStart the cycle again with the next test.\n\n**Example Progression**:\n```\nTest 1: test_merge_two_hierarchies âœ…\n    â†’ Implement basic merging\n\nTest 2: test_merge_three_hierarchies âœ…\n    â†’ Extend to multiple hierarchies\n\nTest 3: test_merge_nested_structures âœ…\n    â†’ Handle deep nesting\n\nTest 4: test_merge_with_uri_references âœ…\n    â†’ Preserve URI references\n\n...and so on until feature is complete\n```\n\n---\n\n## TDD Best Practices\n\n### Test Naming\n\n```python\n# âœ… Good: Descriptive, clear intent\ndef test_merge_two_hierarchies_override_precedence():\n    ...\n\ndef test_load_yaml_file_not_found_raises_error():\n    ...\n\ndef test_uri_resolver_caches_content():\n    ...\n\n# âŒ Bad: Vague, unclear\ndef test_merge():\n    ...\n\ndef test_loader():\n    ...\n\ndef test_works():\n    ...\n```\n\n### Test Structure\n\nUse AAA (Arrange-Act-Assert):\n\n```python\ndef test_example():\n    # Arrange: Set up test data\n    input_data = create_test_data()\n    expected = \"expected_result\"\n\n    # Act: Perform the operation\n    result = function_under_test(input_data)\n\n    # Assert: Verify the result\n    assert result == expected\n```\n\n### Test Independence\n\nEach test should be independent:\n\n```python\n# âœ… Good: Independent tests\ndef test_merge_case_1():\n    merger = HierarchyMerger()  # Fresh instance\n    result = merger.merge([base1, override1])\n    assert ...\n\ndef test_merge_case_2():\n    merger = HierarchyMerger()  # Fresh instance\n    result = merger.merge([base2, override2])\n    assert ...\n\n# âŒ Bad: Tests depend on order\nclass TestMerger:\n    def setup(self):\n        self.merger = HierarchyMerger()  # Shared state\n\n    def test_case_1(self):\n        self.merger.merge([base1])  # Modifies shared state\n\n    def test_case_2(self):\n        self.merger.merge([base2])  # Affected by case_1\n```\n\n### Test Coverage\n\nAim for >80% coverage, but focus on meaningful tests:\n\n```python\n# Cover:\n- Happy path (normal usage)\n- Edge cases (empty, null, boundary values)\n- Error conditions (invalid input, missing data)\n- Integration points (module interactions)\n\n# Don't obsess over:\n- Trivial getters/setters\n- Auto-generated code\n- Third-party library internals\n```\n\n---\n\n## Common Scenarios\n\n### New Feature\n\n```\n1. Write test for desired feature â†’ RED\n2. Implement feature minimally â†’ GREEN\n3. Improve implementation â†’ REFACTOR\n4. Add more test cases â†’ RED\n5. Handle edge cases â†’ GREEN\n6. Polish code â†’ REFACTOR\n7. Commit feature\n```\n\n### Bug Fix\n\n```\n1. Write test that reproduces bug â†’ RED (should fail)\n2. Fix the bug â†’ GREEN (test now passes)\n3. Add related test cases â†’ RED\n4. Verify fix handles all cases â†’ GREEN\n5. Refactor if needed â†’ REFACTOR\n6. Commit fix\n```\n\n### Refactoring\n\n```\n1. Ensure all existing tests pass â†’ GREEN\n2. Refactor code â†’ Keep tests GREEN throughout\n3. Run full test suite â†’ Verify still GREEN\n4. Commit refactoring\n```\n\n---\n\n## Running Tests\n\n### Quick Commands\n\n```bash\n# Run all tests\npytest tests/\n\n# Run specific test file\npytest tests/test_hierarchy_merger.py\n\n# Run specific test\npytest tests/test_hierarchy_merger.py::test_merge_two_hierarchies\n\n# Watch mode (run on file change)\npytest tests/ --watch\n\n# Coverage report\npytest tests/ --cov=src/ai_sdlc_config --cov-report=html\n\n# Parallel execution\npytest tests/ -n auto\n```\n\n### CI/CD Integration\n\nAll tests must pass before merging:\n\n```yaml\n# .github/workflows/tests.yml\n- name: Run tests\n  run: pytest tests/ --cov --cov-fail-under=80\n```\n\n---\n\n## Metrics\n\nTrack your TDD discipline:\n\n| Metric | Target | Current |\n|--------|--------|---------|\n| Test Coverage | >80% | 100% |\n| Tests Passing | 100% | 156/156 |\n| Tests per Module | >10 | âœ… |\n| Test Execution Time | <5s | 0.16s |\n\n---\n\n## Anti-Patterns to Avoid\n\n### âŒ Writing Code First\n\n```python\n# Wrong order:\n1. Write implementation\n2. Write tests\n3. Fix implementation to pass tests\n\n# This defeats the purpose of TDD!\n```\n\n### âŒ Testing Implementation Details\n\n```python\n# Bad: Tests internal implementation\ndef test_merge_uses_deepcopy():\n    assert merger._called_deepcopy == True\n\n# Good: Tests behavior\ndef test_merge_does_not_mutate_originals():\n    result = merger.merge([base, override])\n    assert base.get_value(\"name\") == \"original\"\n```\n\n### âŒ Overly Complex Tests\n\n```python\n# Bad: Test does too much\ndef test_entire_system():\n    # 100 lines of test code\n    # Tests multiple features\n    # Hard to debug when it fails\n\n# Good: Focused test\ndef test_merge_two_hierarchies():\n    # 10 lines\n    # Tests one thing\n    # Clear what failed if it breaks\n```\n\n---\n\n## Summary\n\n**The TDD Mantra**: RED â†’ GREEN â†’ REFACTOR\n\n1. **RED**: Write failing test\n2. **GREEN**: Make it pass\n3. **REFACTOR**: Make it better\n4. **COMMIT**: Save progress\n5. **REPEAT**: Next test\n\n**No code without tests. Ever.**\n\n---\n\n## References\n\n- **Origin**: [ai_init TDD Process](https://github.com/foolishimp/ai_init)\n- **Applied In**: All ai_sdlc_method development\n- **Test Suite**: [tests/](../../tests/)\n- **Key Principles**: [KEY_PRINCIPLES.md](../principles/KEY_PRINCIPLES.md)\n\n---\n\n*TDD is not just a practice - it's a discipline. Master it.*\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/hooks/hooks.json": "{\n  \"description\": \"AI SDLC Methodology lifecycle hooks - Implements: REQ-TOOL-008\",\n  \"hooks\": {\n    \"Stop\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"if [ -f .ai-workspace/tasks/active/ACTIVE_TASKS.md ]; then MODIFIED=$(git status --porcelain 2>/dev/null | wc -l | tr -d ' '); if [ \\\"$MODIFIED\\\" -gt 5 ]; then echo \\\"âš ï¸ $MODIFIED uncommitted changes. Consider: /aisdlc-checkpoint-tasks\\\"; fi; fi\"\n          }\n        ]\n      }\n    ],\n    \"PreToolUse\": [\n      {\n        \"matcher\": \"Bash\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"if echo \\\"$CLAUDE_TOOL_INPUT\\\" | grep -q 'git commit' 2>/dev/null; then if ! echo \\\"$CLAUDE_TOOL_INPUT\\\" | grep -qE 'REQ-[A-Z]+-[A-Z]*-?[0-9]+' 2>/dev/null; then echo 'âš ï¸ Commit may be missing REQ-* tag. Consider: /aisdlc-commit-task'; fi; fi\"\n          }\n        ]\n      }\n    ]\n  }\n}\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/project.json": "{\n  \"name\": \"aisdlc_methodology\",\n  \"project_type\": \"methodology\",\n  \"version\": \"0.4.8\",\n  \"created\": \"2025-10-16T02:30:00Z\",\n  \"modified\": \"2025-11-14T02:09:00Z\",\n  \"base_projects\": [],\n  \"description\": \"Complete AI SDLC methodology with 7-stage agent configurations (Requirements, Design, Tasks, Code, System Test, UAT, Runtime Feedback) integrating Key Principles and full lifecycle traceability\",\n  \"merged_from\": null,\n  \"merge_date\": null,\n  \"runtime_overrides\": null,\n  \"metadata\": {\n    \"origin\": \"https://github.com/foolishimp/ai_init\",\n    \"replaces\": \"ai_init\",\n    \"principles\": \"Key Principles (evolvable per project context)\",\n    \"workflow\": \"Multi-Stage AI SDLC (7 stages)\",\n    \"mantra\": \"Excellence or nothing\",\n    \"stages\": 7,\n    \"reference_guide\": \"../../docs/ai_sdlc_method.md\",\n    \"methodologies\": [\"TDD\", \"BDD\", \"Requirement Traceability\"]\n  }\n}\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills-consolidated/README.md": "# Consolidated Skills\n\nThis directory contains **11 consolidated skill documents** that replace the original **42 granular skills**.\n\n## Consolidation Mapping\n\n| Consolidated Skill | Original Skills (42) | Stage |\n|-------------------|---------------------|-------|\n| **tdd-complete-workflow.md** | tdd-workflow, red-phase, green-phase, refactor-phase, commit-with-req-tag | Code |\n| **bdd-complete-workflow.md** | bdd-workflow, write-scenario, implement-step-definitions, implement-feature, refactor-bdd | System Test/UAT |\n| **requirements-extraction.md** | requirement-extraction, disambiguate-requirements, refine-requirements, extract-business-rules, extract-constraints, extract-formulas | Requirements |\n| **requirements-validation.md** | validate-requirements, create-traceability-matrix | Requirements |\n| **design-with-traceability.md** | create-adrs, design-with-traceability, validate-design-coverage | Design |\n| **code-generation.md** | autogenerate-constraints, autogenerate-formulas, autogenerate-from-business-rules, autogenerate-validators | Code |\n| **technical-debt-management.md** | detect-complexity, detect-unused-code, prune-unused-code, simplify-complex-code | Code |\n| **test-coverage-management.md** | create-test-specification, generate-missing-tests, validate-test-coverage, run-integration-tests, create-coverage-report | System Test |\n| **runtime-observability.md** | create-observability-config, telemetry-tagging, trace-production-issue | Runtime |\n| **traceability-core.md** | check-requirement-coverage, propagate-req-keys, requirement-traceability | All Stages |\n| **key-principles.md** | apply-key-principles, seven-questions-checklist | Code |\n\n## Why Consolidate?\n\n### Before: 42 Granular Skills\n- Many skills were sub-steps of larger workflows\n- Users had to understand skill relationships\n- Context switching between related skills\n- Redundant content across skills\n\n### After: 11 Comprehensive Workflows\n- Each skill is a complete, self-contained workflow\n- Clear mapping to SDLC stages\n- All steps in one document\n- Easier to understand and use\n\n## Skills by SDLC Stage\n\n```\nRequirements Stage:\n  - requirements-extraction.md    (extract + disambiguate)\n  - requirements-validation.md    (validate + matrix)\n\nDesign Stage:\n  - design-with-traceability.md   (ADRs + components + APIs)\n\nTasks Stage:\n  (Use requirements-extraction for work breakdown)\n\nCode Stage:\n  - tdd-complete-workflow.md      (REDâ†’GREENâ†’REFACTOR)\n  - code-generation.md            (from BR-*/C-*/F-*)\n  - technical-debt-management.md  (detect + eliminate)\n  - key-principles.md             (7 principles)\n\nSystem Test Stage:\n  - bdd-complete-workflow.md      (Given/When/Then)\n  - test-coverage-management.md   (coverage + gaps)\n\nUAT Stage:\n  - bdd-complete-workflow.md      (business validation)\n\nRuntime Feedback Stage:\n  - runtime-observability.md      (telemetry + deviation)\n\nAll Stages:\n  - traceability-core.md          (REQ-* propagation)\n```\n\n## Usage\n\nEach consolidated skill includes:\n1. **When to Use** - Clear guidance on applicability\n2. **Complete Workflow** - All phases in one document\n3. **Templates** - Ready-to-use code/document templates\n4. **Output Format** - Expected output after completion\n5. **Configuration** - Plugin configuration options\n6. **Homeostasis Behavior** - Self-healing patterns\n\n## Migration from Granular Skills\n\nIf you were using the granular skills:\n\n| Old Invocation | New Invocation |\n|----------------|----------------|\n| `red-phase` then `green-phase` | `tdd-complete-workflow` |\n| `write-scenario` then `implement-step-definitions` | `bdd-complete-workflow` |\n| `requirement-extraction` then `disambiguate-requirements` | `requirements-extraction` |\n| `detect-unused-code` then `prune-unused-code` | `technical-debt-management` |\n\n## Original Skills Location\n\nThe original 42 granular skills remain in `../skills/` for reference and backward compatibility.\n\n---\n\n**\"Excellence or nothing\"**\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills-consolidated/bdd-complete-workflow.md": "---\nname: bdd-complete-workflow\ndescription: Complete Behavior-Driven Development workflow - SCENARIO (Given/When/Then) â†’ STEP DEFINITIONS â†’ IMPLEMENT â†’ REFACTOR. Consolidates bdd-workflow, write-scenario, implement-step-definitions, implement-feature, refactor-bdd.\nallowed-tools: [Read, Write, Edit, Bash, Grep, Glob]\n---\n\n# BDD Complete Workflow\n\n**Skill Type**: Complete Workflow (System Test / UAT Stage)\n**Purpose**: Create executable specifications using Given/When/Then scenarios\n**Consolidates**: bdd-workflow, write-scenario, implement-step-definitions, implement-feature, refactor-bdd\n\n---\n\n## When to Use This Skill\n\nUse this skill when:\n- Writing integration or acceptance tests\n- Stakeholders need readable test documentation\n- Requirements are expressed as user stories\n- Business validation is the focus\n- System Test or UAT stage of SDLC\n\n**BDD vs TDD**:\n- **BDD**: High-level behavior (user/business perspective) - Given/When/Then\n- **TDD**: Low-level implementation (developer perspective) - unit tests\n\nBoth can coexist: BDD for acceptance tests, TDD for unit tests.\n\n---\n\n## Prerequisites\n\nBefore starting, verify:\n1. Requirement key exists (REQ-F-*, REQ-NFR-*)\n2. Requirement details available (user story format ideal)\n3. BDD framework available (Cucumber, Behave, SpecFlow)\n4. Working directory is a git repository\n\n**If prerequisites missing**:\n- No REQ-* key â†’ Use `requirements-extraction` skill first\n- No BDD framework â†’ Install one (Behave for Python, Cucumber for JS/Java)\n\n---\n\n## Complete Workflow\n\n### Phase 1: SCENARIO (Write Given/When/Then)\n\n**Goal**: Write behavior scenarios in PURE BUSINESS LANGUAGE.\n\n**Steps**:\n\n1. **Understand the User Story**\n   ```\n   As a [persona]\n   I want to [capability]\n   So that [benefit]\n   ```\n\n2. **Create Feature File**\n\n   **Gherkin Format** (all BDD frameworks):\n   ```gherkin\n   # features/authentication.feature\n\n   # Validates: REQ-F-AUTH-001\n   # Business Rules: BR-001, BR-002, BR-003\n\n   Feature: User Authentication\n     As a customer\n     I want to log in with my email and password\n     So that I can access my account information\n\n     Background:\n       Given I am on the login page\n\n     @REQ-F-AUTH-001 @happy-path\n     Scenario: Successful login with valid credentials\n       Given I have a registered account with email \"user@example.com\"\n       When I enter my email \"user@example.com\"\n       And I enter my password \"SecurePass123!\"\n       And I click the \"Login\" button\n       Then I should see \"Welcome back\"\n       And I should be on the dashboard page\n\n     @REQ-F-AUTH-001 @BR-001\n     Scenario: Login fails with invalid email format\n       When I enter my email \"invalid-email\"\n       And I enter my password \"SecurePass123!\"\n       And I click the \"Login\" button\n       Then I should see an error \"Invalid email format\"\n\n     @REQ-F-AUTH-001 @BR-002\n     Scenario: Login fails with short password\n       When I enter my email \"user@example.com\"\n       And I enter my password \"short\"\n       And I click the \"Login\" button\n       Then I should see an error \"Password must be at least 12 characters\"\n\n     @REQ-F-AUTH-001 @BR-003\n     Scenario: Account locks after 3 failed attempts\n       Given I have a registered account with email \"user@example.com\"\n       When I enter wrong password 3 times\n       Then I should see \"Account locked. Try again in 15 minutes\"\n       And I should not be able to attempt login\n\n     @REQ-F-AUTH-001 @edge-case\n     Scenario Outline: Email validation edge cases\n       When I enter my email \"<email>\"\n       And I enter my password \"SecurePass123!\"\n       And I click the \"Login\" button\n       Then I should see an error \"<error>\"\n\n       Examples:\n         | email              | error                  |\n         |                    | Email is required      |\n         | missing@           | Invalid email format   |\n         | @nodomain.com      | Invalid email format   |\n   ```\n\n**Key Rules for Scenarios**:\n- PURE business language (no technical jargon)\n- Each scenario tests ONE behavior\n- Tag scenarios with REQ-* keys\n- Use Background for common setup\n- Use Scenario Outline for data-driven tests\n\n3. **Commit SCENARIO Phase**\n   ```bash\n   git add features/\n   git commit -m \"SCENARIO: Add scenarios for REQ-F-AUTH-001\n\n   Write Given/When/Then scenarios for user login.\n\n   Scenarios: 5 (happy path, BR-001, BR-002, BR-003, edge cases)\n   Validates: REQ-F-AUTH-001\n   Business language: Pure (no technical jargon)\n   \"\n   ```\n\n---\n\n### Phase 2: STEP DEFINITIONS (Implement Test Code)\n\n**Goal**: Translate Given/When/Then into executable test code.\n\n**Steps**:\n\n1. **Create Step Definitions**\n\n   **Python (Behave)**:\n   ```python\n   # features/steps/authentication_steps.py\n\n   # Step definitions for: REQ-F-AUTH-001\n\n   from behave import given, when, then\n   from selenium import webdriver\n   from pages.login_page import LoginPage\n\n   @given('I am on the login page')\n   def step_on_login_page(context):\n       # Validates: REQ-F-AUTH-001 (setup)\n       context.browser = webdriver.Chrome()\n       context.login_page = LoginPage(context.browser)\n       context.login_page.navigate()\n\n   @given('I have a registered account with email \"{email}\"')\n   def step_registered_account(context, email):\n       # Validates: REQ-F-AUTH-001 (precondition)\n       context.test_user = create_test_user(email=email)\n\n   @when('I enter my email \"{email}\"')\n   def step_enter_email(context, email):\n       context.login_page.enter_email(email)\n\n   @when('I enter my password \"{password}\"')\n   def step_enter_password(context, password):\n       context.login_page.enter_password(password)\n\n   @when('I click the \"{button}\" button')\n   def step_click_button(context, button):\n       context.login_page.click_button(button)\n\n   @when('I enter wrong password {count:d} times')\n   def step_wrong_password_times(context, count):\n       for _ in range(count):\n           context.login_page.enter_password(\"wrong_password\")\n           context.login_page.click_button(\"Login\")\n\n   @then('I should see \"{message}\"')\n   def step_see_message(context, message):\n       assert message in context.login_page.get_page_text()\n\n   @then('I should see an error \"{error}\"')\n   def step_see_error(context, error):\n       assert context.login_page.get_error_message() == error\n\n   @then('I should be on the dashboard page')\n   def step_on_dashboard(context):\n       assert \"dashboard\" in context.browser.current_url\n\n   @then('I should not be able to attempt login')\n   def step_login_disabled(context):\n       assert context.login_page.is_login_disabled()\n   ```\n\n   **TypeScript (Cucumber)**:\n   ```typescript\n   // features/step_definitions/authentication.steps.ts\n\n   // Step definitions for: REQ-F-AUTH-001\n\n   import { Given, When, Then } from '@cucumber/cucumber';\n   import { LoginPage } from '../pages/login.page';\n\n   let loginPage: LoginPage;\n\n   Given('I am on the login page', async function() {\n     // Validates: REQ-F-AUTH-001 (setup)\n     loginPage = new LoginPage(this.browser);\n     await loginPage.navigate();\n   });\n\n   Given('I have a registered account with email {string}', async function(email: string) {\n     // Validates: REQ-F-AUTH-001 (precondition)\n     await createTestUser({ email });\n   });\n\n   When('I enter my email {string}', async function(email: string) {\n     await loginPage.enterEmail(email);\n   });\n\n   When('I enter my password {string}', async function(password: string) {\n     await loginPage.enterPassword(password);\n   });\n\n   When('I click the {string} button', async function(button: string) {\n     await loginPage.clickButton(button);\n   });\n\n   Then('I should see {string}', async function(message: string) {\n     const text = await loginPage.getPageText();\n     expect(text).toContain(message);\n   });\n\n   Then('I should see an error {string}', async function(error: string) {\n     const errorMessage = await loginPage.getErrorMessage();\n     expect(errorMessage).toBe(error);\n   });\n   ```\n\n2. **Run Scenarios (Expect FAILURE)**\n   ```bash\n   # Python (Behave)\n   behave features/authentication.feature\n\n   # JavaScript (Cucumber)\n   npm run cucumber features/authentication.feature\n   ```\n\n   Expected: Steps run but fail (implementation doesn't exist).\n\n3. **Commit STEP DEFINITIONS Phase**\n   ```bash\n   git add features/steps/\n   git commit -m \"STEP DEF: Add step definitions for REQ-F-AUTH-001\n\n   Implement step definitions for Given/When/Then steps.\n\n   Steps: 10 step definitions\n   Scenarios running: FAILED (expected - no implementation)\n   Validates: REQ-F-AUTH-001\n   \"\n   ```\n\n---\n\n### Phase 3: IMPLEMENT (Make Scenarios Pass)\n\n**Goal**: Implement feature code to make scenarios pass.\n\n**Steps**:\n\n1. **Implement Feature Code**\n   (Same as TDD GREEN phase - write code tagged with REQ-*)\n\n2. **Implement Page Objects** (if using Selenium/Playwright)\n   ```python\n   # pages/login_page.py\n\n   # Page object for: REQ-F-AUTH-001\n\n   class LoginPage:\n       def __init__(self, driver):\n           self.driver = driver\n           self.url = \"/login\"\n\n       def navigate(self):\n           self.driver.get(f\"{BASE_URL}{self.url}\")\n\n       def enter_email(self, email: str):\n           self.driver.find_element_by_id(\"email\").send_keys(email)\n\n       def enter_password(self, password: str):\n           self.driver.find_element_by_id(\"password\").send_keys(password)\n\n       def click_button(self, button: str):\n           self.driver.find_element_by_xpath(f\"//button[text()='{button}']\").click()\n\n       def get_error_message(self) -> str:\n           return self.driver.find_element_by_class_name(\"error-message\").text\n\n       def get_page_text(self) -> str:\n           return self.driver.page_source\n   ```\n\n3. **Run Scenarios (Expect SUCCESS)**\n   ```bash\n   behave features/authentication.feature\n   ```\n\n4. **Commit IMPLEMENT Phase**\n   ```bash\n   git add src/ pages/\n   git commit -m \"IMPLEMENT: Implement REQ-F-AUTH-001\n\n   Add authentication feature to pass BDD scenarios.\n\n   Implements: REQ-F-AUTH-001\n   Scenarios: All passing\n   \"\n   ```\n\n---\n\n### Phase 4: REFACTOR (Quality + Tech Debt)\n\n**Goal**: Improve code quality without changing behavior.\n\n**Steps**:\n\n1. **Refactor Feature Code** - Same as TDD REFACTOR\n2. **Refactor Step Definitions**\n   - Reuse common steps\n   - Extract helpers\n   - Improve readability\n\n3. **Run Scenarios (Expect STILL PASSING)**\n\n4. **Commit REFACTOR Phase**\n   ```bash\n   git commit -m \"REFACTOR: Clean up REQ-F-AUTH-001\n\n   Step Definitions:\n   - Extracted common setup to hooks\n   - Improved step reusability\n\n   Code Quality:\n   - Added type hints\n   - Improved docstrings\n\n   Scenarios: Still passing\n   \"\n   ```\n\n---\n\n## Output Format\n\nWhen BDD workflow completes, show:\n\n```\n[BDD Workflow: REQ-F-AUTH-001]\n\nPhase 1: SCENARIO (Given/When/Then)\n  Created: features/authentication.feature\n  Scenarios: 5 (business language)\n  Commit: SCENARIO: Add scenarios for REQ-F-AUTH-001\n\nPhase 2: STEP DEFINITIONS\n  Created: features/steps/authentication_steps.py\n  Steps: 10 step definitions\n  Scenarios: FAILED (expected)\n  Commit: STEP DEF: Add step definitions for REQ-F-AUTH-001\n\nPhase 3: IMPLEMENT\n  Created: src/auth/authentication.py, pages/login_page.py\n  Scenarios: PASSED\n  Commit: IMPLEMENT: Implement REQ-F-AUTH-001\n\nPhase 4: REFACTOR\n  Improved: Step reusability, code quality\n  Scenarios: Still passing\n  Commit: REFACTOR: Clean up REQ-F-AUTH-001\n\nBDD Workflow Complete!\n  Feature File: authentication.feature (5 scenarios)\n  Step Definitions: 10 steps\n  Page Objects: 1 (login_page.py)\n  Traceability: REQ-F-AUTH-001 â†’ commit xyz789\n```\n\n---\n\n## Gherkin Best Practices\n\n### Use Business Language\n```gherkin\n# GOOD - Business language\nGiven I have $100 in my savings account\nWhen I withdraw $30\nThen I should have $70 remaining\n\n# BAD - Technical jargon\nGiven the database has record id=123 with balance=100\nWhen POST /api/withdraw {\"amount\": 30}\nThen the response body balance equals 70\n```\n\n### One Behavior Per Scenario\n```gherkin\n# GOOD - Single behavior\nScenario: Successful withdrawal\n  Given I have $100 in my account\n  When I withdraw $30\n  Then I should have $70 remaining\n\n# BAD - Multiple behaviors\nScenario: Various account operations\n  Given I have $100\n  When I withdraw $30\n  Then I have $70\n  When I deposit $50\n  Then I have $120\n```\n\n### Use Tags for Traceability\n```gherkin\n@REQ-F-PAYMENT-001 @happy-path @smoke\nScenario: Successful payment\n\n@REQ-F-PAYMENT-001 @BR-001 @regression\nScenario: Payment fails with expired card\n```\n\n### Use Background for Common Setup\n```gherkin\nBackground:\n  Given I am logged in as \"customer@example.com\"\n  And I am on the checkout page\n\nScenario: Successful checkout\n  When I enter valid payment details\n  ...\n\nScenario: Failed checkout - expired card\n  When I enter expired card details\n  ...\n```\n\n---\n\n## BDD Framework Quick Reference\n\n### Python (Behave)\n```bash\npip install behave selenium\nbehave features/\nbehave --tags=@REQ-F-AUTH-001  # Run specific requirement\n```\n\n### JavaScript (Cucumber)\n```bash\nnpm install @cucumber/cucumber puppeteer\nnpx cucumber-js features/\nnpx cucumber-js --tags \"@REQ-F-AUTH-001\"\n```\n\n### Java (Cucumber)\n```xml\n<dependency>\n  <groupId>io.cucumber</groupId>\n  <artifactId>cucumber-java</artifactId>\n</dependency>\n```\n\n### .NET (SpecFlow)\n```bash\ndotnet add package SpecFlow.NUnit\n```\n\n---\n\n## Configuration\n\n```yaml\n# .claude/plugins.yml\nplugins:\n  - name: \"@aisdlc/aisdlc-methodology\"\n    config:\n      bdd:\n        gherkin_style: \"cucumber\"     # cucumber | behave | specflow\n        require_scenarios_for_requirements: true\n        scenario_language: \"en\"\n        include_backgrounds: true\n        tag_scenarios_with_req_keys: true\n```\n\n---\n\n## Homeostasis Behavior\n\n**If prerequisites not met**:\n- Detect: Missing REQ-* key or user story\n- Signal: \"Need requirement extraction first\"\n- Action: Use `requirements-extraction` skill\n\n**If scenarios fail in IMPLEMENT phase**:\n- Detect: Scenarios still failing after implementation\n- Signal: \"Implementation incomplete\"\n- Action: Fix implementation\n- Do NOT proceed to REFACTOR until scenarios pass\n\n---\n\n## Key Principles Applied\n\n1. **Test Driven Development** - Scenarios written before implementation\n2. **Modular & Maintainable** - Page objects, reusable steps\n3. **Perfectionist Excellence** - Business-readable specifications\n\n**\"Excellence or nothing\"**\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills-consolidated/code-generation.md": "---\nname: code-generation\ndescription: Auto-generate code from business rules, constraints, formulas, and validators. Consolidates autogenerate-constraints, autogenerate-formulas, autogenerate-from-business-rules, autogenerate-validators.\nallowed-tools: [Read, Write, Edit, Bash, Grep, Glob]\n---\n\n# Code Generation\n\n**Skill Type**: Actuator (Code Stage)\n**Purpose**: Auto-generate implementation code from structured specifications\n**Consolidates**: autogenerate-constraints, autogenerate-formulas, autogenerate-from-business-rules, autogenerate-validators\n\n---\n\n## When to Use This Skill\n\nUse this skill when:\n- Requirements have BR-*, C-*, F-* specifications\n- Need to generate validators from constraints\n- Need to implement business rule logic\n- Need to implement calculation formulas\n- Want consistent, traceable code generation\n\n---\n\n## Code Generation Types\n\n### 1. Generate from Business Rules (BR-*)\n\n**Input**:\n```yaml\nREQ-F-AUTH-001:\n  BR-001: Email must be valid format (regex: ^[^@]+@[^@]+\\.[^@]+$)\n  BR-002: Password minimum 12 characters\n  BR-003: Max 3 login attempts, then 15-minute lockout\n```\n\n**Output** (Python):\n```python\n# validators/auth_validators.py\n\n# Generated from: REQ-F-AUTH-001\n# Business Rules: BR-001, BR-002, BR-003\n\nimport re\nfrom datetime import datetime, timedelta\nfrom dataclasses import dataclass\nfrom typing import Optional\n\n# BR-001: Email validation\nEMAIL_PATTERN = re.compile(r'^[^@]+@[^@]+\\.[^@]+$')\n\ndef validate_email(email: str) -> bool:\n    \"\"\"Validate email format.\n\n    Implements: BR-001 (Email must be valid format)\n    Requirement: REQ-F-AUTH-001\n    \"\"\"\n    if not email:\n        return False\n    return bool(EMAIL_PATTERN.match(email))\n\n\n# BR-002: Password minimum length\nPASSWORD_MIN_LENGTH = 12\n\ndef validate_password_length(password: str) -> bool:\n    \"\"\"Validate password meets minimum length.\n\n    Implements: BR-002 (Password minimum 12 characters)\n    Requirement: REQ-F-AUTH-001\n    \"\"\"\n    return len(password) >= PASSWORD_MIN_LENGTH\n\n\n# BR-003: Account lockout\nMAX_LOGIN_ATTEMPTS = 3\nLOCKOUT_DURATION_MINUTES = 15\n\n@dataclass\nclass LockoutStatus:\n    is_locked: bool\n    locked_until: Optional[datetime] = None\n    attempts_remaining: int = MAX_LOGIN_ATTEMPTS\n\ndef check_account_lockout(\n    login_attempts: int,\n    locked_until: Optional[datetime]\n) -> LockoutStatus:\n    \"\"\"Check if account is locked due to failed attempts.\n\n    Implements: BR-003 (Max 3 attempts, 15-minute lockout)\n    Requirement: REQ-F-AUTH-001\n    \"\"\"\n    now = datetime.utcnow()\n\n    # Check if currently locked\n    if locked_until and locked_until > now:\n        return LockoutStatus(\n            is_locked=True,\n            locked_until=locked_until,\n            attempts_remaining=0\n        )\n\n    # Check if should be locked\n    if login_attempts >= MAX_LOGIN_ATTEMPTS:\n        new_locked_until = now + timedelta(minutes=LOCKOUT_DURATION_MINUTES)\n        return LockoutStatus(\n            is_locked=True,\n            locked_until=new_locked_until,\n            attempts_remaining=0\n        )\n\n    return LockoutStatus(\n        is_locked=False,\n        attempts_remaining=MAX_LOGIN_ATTEMPTS - login_attempts\n    )\n```\n\n---\n\n### 2. Generate from Constraints (C-*)\n\n**Input**:\n```yaml\nREQ-F-AUTH-001:\n  C-001: Response time < 500ms\n  C-002: Must use HTTPS\n  C-003: Password must be hashed (bcrypt, cost factor 12)\n  C-004: Must support 10,000+ concurrent users\n```\n\n**Output** (Python):\n```python\n# constraints/auth_constraints.py\n\n# Generated from: REQ-F-AUTH-001\n# Constraints: C-001, C-002, C-003, C-004\n\nimport bcrypt\nimport functools\nimport time\nfrom typing import Callable, TypeVar, Any\n\nT = TypeVar('T')\n\n# C-001: Response time constraint\nMAX_RESPONSE_TIME_MS = 500\n\ndef enforce_response_time(max_ms: int = MAX_RESPONSE_TIME_MS):\n    \"\"\"Decorator to enforce response time constraint.\n\n    Implements: C-001 (Response time < 500ms)\n    Requirement: REQ-F-AUTH-001\n    \"\"\"\n    def decorator(func: Callable[..., T]) -> Callable[..., T]:\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs) -> T:\n            start = time.perf_counter()\n            result = func(*args, **kwargs)\n            elapsed_ms = (time.perf_counter() - start) * 1000\n\n            if elapsed_ms > max_ms:\n                # Log warning but don't fail\n                import logging\n                logging.warning(\n                    f\"C-001 violation: {func.__name__} took {elapsed_ms:.2f}ms \"\n                    f\"(max: {max_ms}ms)\"\n                )\n            return result\n        return wrapper\n    return decorator\n\n\n# C-002: HTTPS enforcement\ndef require_https(url: str) -> str:\n    \"\"\"Ensure URL uses HTTPS.\n\n    Implements: C-002 (Must use HTTPS)\n    Requirement: REQ-F-AUTH-001\n    \"\"\"\n    if url.startswith('http://'):\n        return url.replace('http://', 'https://', 1)\n    if not url.startswith('https://'):\n        return f'https://{url}'\n    return url\n\n\n# C-003: Password hashing\nBCRYPT_COST_FACTOR = 12\n\ndef hash_password(password: str) -> str:\n    \"\"\"Hash password using bcrypt.\n\n    Implements: C-003 (bcrypt, cost factor 12)\n    Requirement: REQ-F-AUTH-001\n    \"\"\"\n    salt = bcrypt.gensalt(rounds=BCRYPT_COST_FACTOR)\n    return bcrypt.hashpw(password.encode('utf-8'), salt).decode('utf-8')\n\n\ndef verify_password(password: str, hashed: str) -> bool:\n    \"\"\"Verify password against bcrypt hash.\n\n    Implements: C-003 (bcrypt verification)\n    Requirement: REQ-F-AUTH-001\n    \"\"\"\n    return bcrypt.checkpw(password.encode('utf-8'), hashed.encode('utf-8'))\n\n\n# C-004: Concurrency constraint (design note)\n# Note: 10,000+ concurrent users requires:\n# - Stateless design (JWT tokens)\n# - Connection pooling\n# - Horizontal scaling\n# This is enforced at architecture level, not code level.\n```\n\n---\n\n### 3. Generate from Formulas (F-*)\n\n**Input**:\n```yaml\nREQ-F-PORTAL-001: View Balance\n  F-001: available_balance = total_balance - pending_holds\n  F-002: display_format = currency_symbol + format(amount, 2 decimals)\n\nREQ-F-PAYMENT-001: Calculate Tax\n  F-003: tax_amount = subtotal * tax_rate\n  F-004: total = subtotal + tax_amount + shipping\n  F-005: discount = min(subtotal * discount_percent, max_discount)\n```\n\n**Output** (Python):\n```python\n# calculations/financial_formulas.py\n\n# Generated from: REQ-F-PORTAL-001, REQ-F-PAYMENT-001\n# Formulas: F-001, F-002, F-003, F-004, F-005\n\nfrom decimal import Decimal, ROUND_HALF_UP\nfrom typing import Optional\n\n# F-001: Available balance calculation\ndef calculate_available_balance(\n    total_balance: Decimal,\n    pending_holds: Decimal\n) -> Decimal:\n    \"\"\"Calculate available balance.\n\n    Formula: available_balance = total_balance - pending_holds\n    Implements: F-001\n    Requirement: REQ-F-PORTAL-001\n    \"\"\"\n    return total_balance - pending_holds\n\n\n# F-002: Currency display formatting\ndef format_currency(\n    amount: Decimal,\n    currency_symbol: str = '$',\n    decimal_places: int = 2\n) -> str:\n    \"\"\"Format amount as currency string.\n\n    Formula: currency_symbol + format(amount, 2 decimals)\n    Implements: F-002\n    Requirement: REQ-F-PORTAL-001\n    \"\"\"\n    quantized = amount.quantize(\n        Decimal(f'0.{\"0\" * decimal_places}'),\n        rounding=ROUND_HALF_UP\n    )\n    return f'{currency_symbol}{quantized:,.{decimal_places}f}'\n\n\n# F-003: Tax calculation\ndef calculate_tax(\n    subtotal: Decimal,\n    tax_rate: Decimal\n) -> Decimal:\n    \"\"\"Calculate tax amount.\n\n    Formula: tax_amount = subtotal * tax_rate\n    Implements: F-003\n    Requirement: REQ-F-PAYMENT-001\n    \"\"\"\n    return (subtotal * tax_rate).quantize(\n        Decimal('0.01'),\n        rounding=ROUND_HALF_UP\n    )\n\n\n# F-004: Order total calculation\ndef calculate_order_total(\n    subtotal: Decimal,\n    tax_amount: Decimal,\n    shipping: Decimal\n) -> Decimal:\n    \"\"\"Calculate order total.\n\n    Formula: total = subtotal + tax_amount + shipping\n    Implements: F-004\n    Requirement: REQ-F-PAYMENT-001\n    \"\"\"\n    return subtotal + tax_amount + shipping\n\n\n# F-005: Discount calculation with cap\ndef calculate_discount(\n    subtotal: Decimal,\n    discount_percent: Decimal,\n    max_discount: Optional[Decimal] = None\n) -> Decimal:\n    \"\"\"Calculate discount with optional maximum cap.\n\n    Formula: discount = min(subtotal * discount_percent, max_discount)\n    Implements: F-005\n    Requirement: REQ-F-PAYMENT-001\n    \"\"\"\n    calculated_discount = subtotal * discount_percent\n\n    if max_discount is not None:\n        return min(calculated_discount, max_discount)\n\n    return calculated_discount.quantize(\n        Decimal('0.01'),\n        rounding=ROUND_HALF_UP\n    )\n```\n\n---\n\n### 4. Generate Validators (Combined)\n\n**Input**:\n```yaml\nREQ-DATA-VAL-001: Email Validation\n  Pattern: ^[^@]+@[^@]+\\.[^@]+$\n  Max Length: 255\n  Required: true\n\nREQ-DATA-VAL-002: Password Validation\n  Min Length: 12\n  Max Length: 128\n  Requires: uppercase, lowercase, digit, special\n  Required: true\n```\n\n**Output** (Python with Pydantic):\n```python\n# validators/input_validators.py\n\n# Generated from: REQ-DATA-VAL-001, REQ-DATA-VAL-002\n\nimport re\nfrom pydantic import BaseModel, field_validator, Field\nfrom typing import Annotated\n\n# REQ-DATA-VAL-001: Email validation\nEMAIL_PATTERN = re.compile(r'^[^@]+@[^@]+\\.[^@]+$')\nEMAIL_MAX_LENGTH = 255\n\n# REQ-DATA-VAL-002: Password validation\nPASSWORD_MIN_LENGTH = 12\nPASSWORD_MAX_LENGTH = 128\nPASSWORD_REQUIRES_UPPERCASE = True\nPASSWORD_REQUIRES_LOWERCASE = True\nPASSWORD_REQUIRES_DIGIT = True\nPASSWORD_REQUIRES_SPECIAL = True\n\n\nclass LoginRequest(BaseModel):\n    \"\"\"Login request with validated email and password.\n\n    Validates: REQ-DATA-VAL-001, REQ-DATA-VAL-002\n    \"\"\"\n\n    email: Annotated[str, Field(\n        max_length=EMAIL_MAX_LENGTH,\n        description=\"User email address\"\n    )]\n\n    password: Annotated[str, Field(\n        min_length=PASSWORD_MIN_LENGTH,\n        max_length=PASSWORD_MAX_LENGTH,\n        description=\"User password\"\n    )]\n\n    @field_validator('email')\n    @classmethod\n    def validate_email_format(cls, v: str) -> str:\n        \"\"\"Validate email format.\n\n        Implements: REQ-DATA-VAL-001\n        \"\"\"\n        if not EMAIL_PATTERN.match(v):\n            raise ValueError('Invalid email format')\n        return v.lower()\n\n    @field_validator('password')\n    @classmethod\n    def validate_password_complexity(cls, v: str) -> str:\n        \"\"\"Validate password complexity.\n\n        Implements: REQ-DATA-VAL-002\n        \"\"\"\n        errors = []\n\n        if PASSWORD_REQUIRES_UPPERCASE and not any(c.isupper() for c in v):\n            errors.append('must contain uppercase letter')\n\n        if PASSWORD_REQUIRES_LOWERCASE and not any(c.islower() for c in v):\n            errors.append('must contain lowercase letter')\n\n        if PASSWORD_REQUIRES_DIGIT and not any(c.isdigit() for c in v):\n            errors.append('must contain digit')\n\n        if PASSWORD_REQUIRES_SPECIAL:\n            special_chars = set('!@#$%^&*()_+-=[]{}|;:,.<>?')\n            if not any(c in special_chars for c in v):\n                errors.append('must contain special character')\n\n        if errors:\n            raise ValueError(f'Password {\", \".join(errors)}')\n\n        return v\n```\n\n---\n\n## Output Format\n\n```\n[CODE GENERATION - REQ-F-AUTH-001]\n\nGenerated from:\n  Business Rules: BR-001, BR-002, BR-003\n  Constraints: C-001, C-002, C-003, C-004\n  Formulas: (none for this requirement)\n\nFiles Created:\n  + validators/auth_validators.py\n    - validate_email() â†’ BR-001\n    - validate_password_length() â†’ BR-002\n    - check_account_lockout() â†’ BR-003\n\n  + constraints/auth_constraints.py\n    - enforce_response_time() â†’ C-001\n    - require_https() â†’ C-002\n    - hash_password() â†’ C-003\n    - verify_password() â†’ C-003\n\nTraceability:\n  All functions tagged with REQ-* and BR-*/C-*/F-*\n\nCode Generation Complete!\n  Next: Run TDD workflow to add tests\n```\n\n---\n\n## Usage Patterns\n\n### Generate All at Once\n```\n\"Generate code for REQ-F-AUTH-001 including all BR-*, C-*, and F-*\"\n```\n\n### Generate Specific Type\n```\n\"Generate validators from BR-001 and BR-002\"\n\"Generate calculation functions from F-001, F-002, F-003\"\n```\n\n### Generate with Tests\n```\n\"Generate code for BR-001 with corresponding unit tests\"\n```\n\n---\n\n## Configuration\n\n```yaml\n# .claude/plugins.yml\nplugins:\n  - name: \"@aisdlc/aisdlc-methodology\"\n    config:\n      code_generation:\n        include_docstrings: true\n        include_type_hints: true\n        include_traceability_comments: true\n        validation_framework: \"pydantic\"  # pydantic | marshmallow | custom\n        test_framework: \"pytest\"\n        generate_tests: true\n```\n\n---\n\n## Homeostasis Behavior\n\n**If BR-*/C-*/F-* incomplete**:\n- Detect: Missing specifications\n- Signal: \"Need disambiguation\"\n- Action: Use `requirements-extraction` skill first\n\n**If generated code fails tests**:\n- Detect: Test failures\n- Signal: \"Generated code needs adjustment\"\n- Action: Fix implementation to match specification\n\n---\n\n## Key Principles Applied\n\n- **Test Driven Development**: Generate tests alongside code\n- **Modular & Maintainable**: Single responsibility per function\n- **No Legacy Baggage**: Clean, typed, documented code\n\n**\"Excellence or nothing\"**\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills-consolidated/design-with-traceability.md": "---\nname: design-with-traceability\ndescription: Complete design workflow - Component design, ADRs, API specs, data models with full requirement traceability. Consolidates create-adrs, design-with-traceability, validate-design-coverage.\nallowed-tools: [Read, Write, Edit, Grep, Glob]\n---\n\n# Design with Traceability\n\n**Skill Type**: Complete Workflow (Design Stage)\n**Purpose**: Transform requirements into technical design with full traceability\n**Consolidates**: create-adrs, design-with-traceability, validate-design-coverage\n\n---\n\n## When to Use This Skill\n\nUse this skill when:\n- Requirements are validated and ready for design\n- Creating component architecture\n- Making architecture decisions (ADRs)\n- Designing APIs, data models, or interfaces\n- Need design-to-requirement traceability\n\n---\n\n## Complete Workflow\n\n### Phase 1: Design Analysis\n\n**Goal**: Understand requirements and identify design decisions.\n\n**For each requirement, determine**:\n- What components are needed?\n- What APIs are required?\n- What data models are needed?\n- What are the architectural options?\n\n**Example**:\n```yaml\nREQ-F-AUTH-001: User Login\n\nComponents Needed:\n  - AuthenticationService (new)\n  - UserRepository (existing - extend)\n  - SessionManager (new)\n\nAPIs Required:\n  - POST /api/v1/auth/login\n  - POST /api/v1/auth/logout\n  - GET /api/v1/auth/session\n\nData Models:\n  - User (extend with login_attempts, locked_until)\n  - Session (new)\n  - AuditLog (new)\n\nArchitectural Decisions:\n  - Session storage: JWT vs Redis\n  - Password hashing: bcrypt vs argon2\n```\n\n---\n\n### Phase 2: Architecture Decision Records (ADRs)\n\n**Goal**: Document significant design decisions with rationale.\n\n**ADR Template**:\n\n```markdown\n# ADR-001: Session Storage Strategy\n\n**Status**: Accepted\n**Date**: 2025-12-03\n**Requirements**: REQ-F-AUTH-001, REQ-NFR-PERF-001\n\n## Context\n\nWe need to store user sessions for authentication.\nRequirements:\n- Session timeout after 30 minutes (BR-004)\n- Support 10,000+ concurrent users (C-004)\n- Response time < 500ms (C-001)\n\n## Options Considered\n\n### Option 1: JWT (Stateless)\nPros:\n- No server-side storage\n- Horizontally scalable\n- Self-contained\n\nCons:\n- Cannot revoke individual sessions\n- Token size grows with claims\n\n### Option 2: Redis (Stateful)\nPros:\n- Can revoke sessions\n- Fast lookup\n- TTL support built-in\n\nCons:\n- Additional infrastructure\n- Single point of failure (if not clustered)\n\n### Option 3: Database Sessions\nPros:\n- Simple implementation\n- Uses existing infrastructure\n\nCons:\n- Slower than Redis\n- Database load\n\n## Decision\n\n**Selected: Option 1 (JWT) with Redis blacklist for revocation**\n\nRationale:\n- JWT for scalability and performance\n- Redis blacklist for logout/revocation\n- Best of both worlds\n\n## Consequences\n\n- Need JWT library (jose)\n- Need Redis for blacklist only\n- Token refresh strategy needed\n\n## Traceability\n\nImplements:\n- REQ-F-AUTH-001: User login\n- REQ-NFR-PERF-001: Response < 500ms\n\nBusiness Rules:\n- BR-004: 30-minute session timeout (JWT exp claim)\n\nConstraints:\n- C-001: Response < 500ms (JWT decode is ~1ms)\n- C-004: 10,000+ concurrent users (stateless = infinite scale)\n```\n\n---\n\n### Phase 3: Component Design\n\n**Goal**: Define component structure with requirement mapping.\n\n**Component Design Template**:\n\n```markdown\n# AuthenticationService\n\n**Type**: Domain Service\n**Layer**: Application Layer\n**Requirements**: REQ-F-AUTH-001, REQ-F-AUTH-002\n\n## Responsibilities\n\n1. Authenticate users with credentials\n2. Manage session lifecycle\n3. Enforce login policies (lockout, etc.)\n\n## Interface\n\n```python\nclass AuthenticationService:\n    \"\"\"Authentication service for user login/logout.\n\n    Implements: REQ-F-AUTH-001, REQ-F-AUTH-002\n    \"\"\"\n\n    def login(self, email: str, password: str) -> LoginResult:\n        \"\"\"Authenticate user with email and password.\n\n        Implements: REQ-F-AUTH-001\n        Business Rules: BR-001, BR-002, BR-003\n        Constraints: C-001 (< 500ms)\n\n        Args:\n            email: User's email address\n            password: User's password\n\n        Returns:\n            LoginResult with success status, user, and token\n\n        Raises:\n            AccountLockedException: If account locked (BR-003)\n            InvalidCredentialsException: If credentials invalid\n        \"\"\"\n        pass\n\n    def logout(self, token: str) -> None:\n        \"\"\"Invalidate user session.\n\n        Implements: REQ-F-AUTH-001\n        \"\"\"\n        pass\n\n    def reset_password(self, email: str) -> None:\n        \"\"\"Initiate password reset flow.\n\n        Implements: REQ-F-AUTH-002\n        Business Rules: BR-005, BR-006\n        \"\"\"\n        pass\n```\n\n## Dependencies\n\n- UserRepository: User data access\n- PasswordHasher: Password verification\n- TokenService: JWT generation\n- CacheService: Blacklist storage\n\n## Sequence Diagram\n\n```\nUser -> API: POST /login {email, password}\nAPI -> AuthService: login(email, password)\nAuthService -> UserRepo: get_by_email(email)\nAuthService -> PasswordHasher: verify(password, hash)\nAuthService -> TokenService: generate_token(user)\nAuthService -> API: LoginResult(success, token)\nAPI -> User: 200 OK {token}\n```\n\n## Traceability\n\n| Method | Requirement | Business Rules | Constraints |\n|--------|-------------|----------------|-------------|\n| login() | REQ-F-AUTH-001 | BR-001, BR-002, BR-003 | C-001 |\n| logout() | REQ-F-AUTH-001 | - | - |\n| reset_password() | REQ-F-AUTH-002 | BR-005, BR-006 | - |\n```\n\n---\n\n### Phase 4: API Design\n\n**Goal**: Define API contracts with requirement mapping.\n\n**OpenAPI Template**:\n\n```yaml\n# api/v1/auth.yaml\n\nopenapi: 3.0.0\ninfo:\n  title: Authentication API\n  version: 1.0.0\n  description: |\n    Authentication endpoints for user login/logout.\n\n    Implements:\n    - REQ-F-AUTH-001: User login\n    - REQ-F-AUTH-002: Password reset\n\npaths:\n  /api/v1/auth/login:\n    post:\n      summary: User login\n      description: |\n        Authenticate user with email and password.\n\n        Implements: REQ-F-AUTH-001\n        Business Rules: BR-001, BR-002, BR-003\n        Constraints: C-001 (response < 500ms)\n      tags:\n        - Authentication\n      x-requirements:\n        - REQ-F-AUTH-001\n      x-business-rules:\n        - BR-001\n        - BR-002\n        - BR-003\n      requestBody:\n        required: true\n        content:\n          application/json:\n            schema:\n              $ref: '#/components/schemas/LoginRequest'\n      responses:\n        '200':\n          description: Login successful\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/LoginResponse'\n        '401':\n          description: Invalid credentials\n        '423':\n          description: Account locked (BR-003)\n\ncomponents:\n  schemas:\n    LoginRequest:\n      type: object\n      required:\n        - email\n        - password\n      properties:\n        email:\n          type: string\n          format: email\n          description: User email (BR-001 validation)\n        password:\n          type: string\n          minLength: 12\n          description: User password (BR-002 min length)\n\n    LoginResponse:\n      type: object\n      properties:\n        token:\n          type: string\n          description: JWT access token\n        expires_at:\n          type: string\n          format: date-time\n          description: Token expiration (BR-004)\n```\n\n---\n\n### Phase 5: Data Model Design\n\n**Goal**: Define data structures with requirement mapping.\n\n```markdown\n# Data Models\n\n## User\n\n**Implements**: REQ-F-AUTH-001, REQ-F-PORTAL-002\n\n```sql\nCREATE TABLE users (\n    id UUID PRIMARY KEY,\n    email VARCHAR(255) UNIQUE NOT NULL,  -- BR-001: validated format\n    password_hash VARCHAR(255) NOT NULL,  -- C-003: bcrypt hash\n    login_attempts INT DEFAULT 0,         -- BR-003: lockout counter\n    locked_until TIMESTAMP NULL,          -- BR-003: lockout time\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW()\n);\n\n-- Index for login lookup (C-001: < 500ms)\nCREATE INDEX idx_users_email ON users(email);\n```\n\n## Session (if using stateful sessions)\n\n**Implements**: REQ-F-AUTH-001\n\n```sql\nCREATE TABLE sessions (\n    id UUID PRIMARY KEY,\n    user_id UUID REFERENCES users(id),\n    token VARCHAR(500) NOT NULL,\n    expires_at TIMESTAMP NOT NULL,  -- BR-004: 30 min timeout\n    created_at TIMESTAMP DEFAULT NOW()\n);\n\n-- TTL cleanup (BR-004)\nCREATE INDEX idx_sessions_expires ON sessions(expires_at);\n```\n```\n\n---\n\n### Phase 6: Design Coverage Validation\n\n**Goal**: Ensure all requirements have design coverage.\n\n**Validation Report**:\n\n```\n[DESIGN COVERAGE VALIDATION]\n\nRequirements Analyzed: 8\n\nDesign Coverage:\n  REQ-F-AUTH-001: âœ… AuthService, POST /login, User model\n  REQ-F-AUTH-002: âœ… AuthService, POST /reset-password\n  REQ-F-PORTAL-001: â³ Pending design\n  REQ-F-PORTAL-002: â³ Pending design\n  REQ-F-PORTAL-003: â³ Pending design\n  REQ-NFR-PERF-001: âœ… Covered in ADR-001, API constraints\n  REQ-NFR-SEC-001: âœ… Covered in ADR-002\n  REQ-DATA-VAL-001: âœ… Covered in API schema\n\nCoverage: 5/8 (63%)\n\nADRs Created: 2\n  - ADR-001: Session Storage Strategy\n  - ADR-002: Password Hashing Strategy\n\nComponents Designed: 3\n  - AuthenticationService\n  - UserRepository\n  - SessionManager\n\nAPIs Designed: 4\n  - POST /api/v1/auth/login\n  - POST /api/v1/auth/logout\n  - POST /api/v1/auth/reset-password\n  - GET /api/v1/auth/session\n\nRemaining:\n  - REQ-F-PORTAL-001: Need BalanceService design\n  - REQ-F-PORTAL-002: Need ProfileService design\n  - REQ-F-PORTAL-003: Need DocumentService design\n```\n\n---\n\n## Output Format\n\n```\n[DESIGN STAGE - INT-042]\n\nRequirements Covered: 5/8\n\nADRs Created:\n  ADR-001: Session Storage Strategy (REQ-F-AUTH-001)\n  ADR-002: Password Hashing Strategy (REQ-NFR-SEC-001)\n\nComponents Designed:\n  AuthenticationService â†’ REQ-F-AUTH-001, REQ-F-AUTH-002\n  UserRepository â†’ REQ-F-AUTH-001\n  SessionManager â†’ REQ-F-AUTH-001\n\nAPIs Designed:\n  POST /api/v1/auth/login â†’ REQ-F-AUTH-001\n  POST /api/v1/auth/logout â†’ REQ-F-AUTH-001\n  POST /api/v1/auth/reset-password â†’ REQ-F-AUTH-002\n\nData Models:\n  User (extended) â†’ REQ-F-AUTH-001, REQ-F-PORTAL-002\n  Session â†’ REQ-F-AUTH-001\n\nFiles Created:\n  + docs/design/adrs/ADR-001-session-storage.md\n  + docs/design/adrs/ADR-002-password-hashing.md\n  + docs/design/components/authentication-service.md\n  + api/v1/auth.yaml\n\nTraceability: All designs linked to REQ-* keys\n\nDesign Stage Complete (Partial)!\n  Next: Design remaining 3 requirements\n```\n\n---\n\n## Configuration\n\n```yaml\n# .claude/plugins.yml\nplugins:\n  - name: \"@aisdlc/aisdlc-methodology\"\n    config:\n      design:\n        require_adrs_for_decisions: true\n        require_api_specs: true\n        require_traceability: true\n        min_coverage_to_proceed: 80\n        adr_template: \"docs/templates/adr-template.md\"\n```\n\n---\n\n## Homeostasis Behavior\n\n**If design missing traceability**:\n- Detect: Component/API without REQ-* link\n- Signal: \"Design needs requirement mapping\"\n- Action: Add Implements/Requirements sections\n\n**If coverage too low**:\n- Detect: < 80% requirements have design\n- Signal: \"Design coverage insufficient\"\n- Action: List uncovered requirements\n- Block: Do not proceed to Tasks until coverage met\n\n---\n\n## Next Steps\n\nAfter design complete:\n1. **Tasks**: Break design into work units\n2. **Code**: Implement using TDD workflow\n3. **Update**: Traceability matrix\n\n**\"Excellence or nothing\"**\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills-consolidated/key-principles.md": "---\nname: key-principles\ndescription: Apply the Key Principles to development work - TDD, Fail Fast, Modular, Reuse, Open Source First, No Legacy, Excellence. Consolidates apply-key-principles, seven-questions-checklist.\nallowed-tools: [Read, Write, Edit, Grep, Glob]\n---\n\n# Key Principles\n\n**Skill Type**: Guidelines (Code Stage)\n**Purpose**: Apply the Key Principles to all development work\n**Consolidates**: apply-key-principles, seven-questions-checklist\n\n---\n\n## The Key Principles\n\n### 1. Test Driven Development\n**\"No code without tests\"**\n\nWrite tests FIRST, then implementation.\n\n```\nRED â†’ GREEN â†’ REFACTOR â†’ COMMIT\n```\n\n**Anti-pattern**: Writing code first, tests later (or never).\n\n---\n\n### 2. Fail Fast & Root Cause\n**\"Break loudly, fix completely\"**\n\n- Detect errors immediately\n- Surface root cause, not symptoms\n- No swallowing exceptions\n- Explicit error handling\n\n```python\n# GOOD: Fail fast with clear error\ndef get_user(user_id: str) -> User:\n    if not user_id:\n        raise ValueError(\"user_id is required\")\n    user = self.repo.find(user_id)\n    if not user:\n        raise UserNotFoundException(f\"User {user_id} not found\")\n    return user\n\n# BAD: Silent failure\ndef get_user(user_id: str) -> Optional[User]:\n    try:\n        return self.repo.find(user_id)\n    except:\n        return None  # Silent failure - BAD\n```\n\n---\n\n### 3. Modular & Maintainable\n**\"Single responsibility, loose coupling\"**\n\n- Each module does ONE thing\n- Clear interfaces between components\n- Easy to understand in isolation\n- Easy to modify without ripple effects\n\n```python\n# GOOD: Single responsibility\nclass UserValidator:\n    def validate_email(self, email: str) -> bool: ...\n    def validate_password(self, password: str) -> bool: ...\n\nclass UserRepository:\n    def find(self, user_id: str) -> User: ...\n    def save(self, user: User) -> None: ...\n\nclass UserService:\n    def __init__(self, validator: UserValidator, repo: UserRepository):\n        self.validator = validator\n        self.repo = repo\n\n# BAD: God class\nclass UserManager:\n    def validate_email(self, email): ...\n    def validate_password(self, password): ...\n    def find_user(self, user_id): ...\n    def save_user(self, user): ...\n    def send_email(self, user, message): ...\n    def generate_report(self, user): ...\n    # ... 50 more methods\n```\n\n---\n\n### 4. Reuse Before Build\n**\"Check first, create second\"**\n\nBefore writing code:\n1. Check if it exists in the codebase\n2. Check if a library does it\n3. Check if a standard pattern applies\n\n```python\n# GOOD: Reuse existing\nfrom validators import validate_email  # Already exists!\n\n# BAD: Reinventing the wheel\ndef validate_email(email: str) -> bool:\n    # 50 lines of regex that already exists elsewhere\n    pass\n```\n\n---\n\n### 5. Open Source First\n**\"Suggest alternatives, human decides\"**\n\nFor common problems:\n1. Research open source solutions\n2. Present options with trade-offs\n3. Let human decide\n\n```markdown\n## Email Validation Options\n\n1. **email-validator** (recommended)\n   - 10M downloads/month\n   - Active maintenance\n   - DNS validation support\n\n2. **validators**\n   - Part of larger package\n   - Simpler API\n\n3. **Custom regex**\n   - Full control\n   - Maintenance burden\n\nRecommendation: email-validator\n```\n\n---\n\n### 6. No Legacy Baggage\n**\"Clean slate, no debt\"**\n\n- No technical debt\n- No commented-out code\n- No \"temporary\" hacks\n- No unused code\n\n```python\n# GOOD: Clean code\ndef calculate_discount(amount: Decimal, rate: Decimal) -> Decimal:\n    return amount * rate\n\n# BAD: Legacy baggage\ndef calculate_discount(amount, rate):\n    # TODO: Fix this later\n    # Old implementation (don't use):\n    # return amount * 0.1\n    result = amount * rate\n    # Hack for legacy system\n    if rate > 0.5:\n        result = result * 1.1  # Magic number, nobody knows why\n    return result\n```\n\n---\n\n### 7. Perfectionist Excellence\n**\"Best of breed only\"**\n\n- Don't settle for \"good enough\"\n- Quality is non-negotiable\n- If it's worth doing, do it right\n\n```python\n# GOOD: Excellence\n@dataclass\nclass LoginResult:\n    \"\"\"Result of login attempt.\n\n    Implements: REQ-F-AUTH-001\n    \"\"\"\n    success: bool\n    user: Optional[User] = None\n    token: Optional[str] = None\n    error: Optional[str] = None\n    error_code: Optional[ErrorCode] = None\n    attempts_remaining: Optional[int] = None\n\n# BAD: \"Good enough\"\ndef login(email, pwd):\n    # Returns True/False, good enough\n    return check_password(email, pwd)\n```\n\n---\n\n## The Seven Questions Checklist\n\n**Before writing ANY code, ask yourself:**\n\n### 1. Have I written tests first?\n*Principle #1: Test Driven Development*\n\n- [ ] Test file exists\n- [ ] Tests are RED (failing)\n- [ ] Tests cover requirements\n\n### 2. Will this fail loudly if wrong?\n*Principle #2: Fail Fast & Root Cause*\n\n- [ ] Explicit error handling\n- [ ] Clear error messages\n- [ ] No silent failures\n\n### 3. Is this module focused?\n*Principle #3: Modular & Maintainable*\n\n- [ ] Single responsibility\n- [ ] Clear interface\n- [ ] Low coupling\n\n### 4. Did I check if this exists?\n*Principle #4: Reuse Before Build*\n\n- [ ] Searched codebase\n- [ ] Checked libraries\n- [ ] Reviewed patterns\n\n### 5. Have I researched alternatives?\n*Principle #5: Open Source First*\n\n- [ ] Evaluated options\n- [ ] Documented trade-offs\n- [ ] Human approved choice\n\n### 6. Am I avoiding tech debt?\n*Principle #6: No Legacy Baggage*\n\n- [ ] No TODOs without tickets\n- [ ] No commented code\n- [ ] No magic numbers\n\n### 7. Is this excellent?\n*Principle #7: Perfectionist Excellence*\n\n- [ ] Would I be proud of this?\n- [ ] Would I accept this in a code review?\n- [ ] Is this the best solution?\n\n---\n\n## Quick Reference Card\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                    KEY PRINCIPLES                           â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ 1. TDD           â”‚ Tests first. Always.                     â”‚\nâ”‚ 2. Fail Fast     â”‚ Errors are loud and clear.               â”‚\nâ”‚ 3. Modular       â”‚ One module, one job.                     â”‚\nâ”‚ 4. Reuse First   â”‚ Don't reinvent. Check first.             â”‚\nâ”‚ 5. Open Source   â”‚ Research options. Human decides.         â”‚\nâ”‚ 6. No Legacy     â”‚ Clean code. No debt. No hacks.           â”‚\nâ”‚ 7. Excellence    â”‚ Best solution or nothing.                â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                  \"Excellence or nothing\"                    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n---\n\n## Applying to Code Reviews\n\n**When reviewing code, check for:**\n\n| Principle | Review Question |\n|-----------|-----------------|\n| TDD | Are there tests? Do they cover the requirements? |\n| Fail Fast | Are errors handled explicitly? Clear messages? |\n| Modular | Single responsibility? Low coupling? |\n| Reuse | Could this use existing code/library? |\n| Open Source | Was alternatives research documented? |\n| No Legacy | Any TODOs, dead code, magic numbers? |\n| Excellence | Is this the best solution? |\n\n---\n\n## Code Templates\n\n### Function Template\n\n```python\ndef function_name(param: Type) -> ReturnType:\n    \"\"\"Brief description.\n\n    Implements: REQ-*\n    Business Rules: BR-*\n\n    Args:\n        param: Description\n\n    Returns:\n        Description\n\n    Raises:\n        ErrorType: When condition\n    \"\"\"\n    # Fail fast - validate inputs\n    if not param:\n        raise ValueError(\"param is required\")\n\n    # Implementation\n    result = ...\n\n    return result\n```\n\n### Class Template\n\n```python\n@dataclass\nclass ClassName:\n    \"\"\"Brief description.\n\n    Implements: REQ-*\n\n    Attributes:\n        field: Description\n    \"\"\"\n    field: Type\n\n    def method(self, param: Type) -> ReturnType:\n        \"\"\"Brief description.\n\n        Implements: REQ-*\n        \"\"\"\n        pass\n```\n\n### Test Template\n\n```python\nclass TestClassName:\n    \"\"\"Tests for ClassName.\n\n    Validates: REQ-*\n    \"\"\"\n\n    def test_happy_path(self):\n        \"\"\"Test successful case.\"\"\"\n        # Validates: REQ-*\n        # Arrange\n        input = ...\n\n        # Act\n        result = function(input)\n\n        # Assert\n        assert result == expected\n\n    def test_error_case(self):\n        \"\"\"Test error handling.\"\"\"\n        # Validates: Principle #2 (Fail Fast)\n        with pytest.raises(ExpectedError):\n            function(invalid_input)\n```\n\n---\n\n## Output Format\n\n```\n[KEY PRINCIPLES CHECK]\n\nCode: src/auth/login.py\n\nPrinciple 1 (TDD):\n  âœ… Tests exist: tests/auth/test_login.py\n  âœ… Tests written first (git history confirms)\n  âœ… Coverage: 95%\n\nPrinciple 2 (Fail Fast):\n  âœ… Explicit error handling\n  âœ… Clear error messages\n  âŒ One silent failure at line 45 (caught exception, returns None)\n\nPrinciple 3 (Modular):\n  âœ… Single responsibility\n  âœ… Clear interface\n  âœ… Low coupling\n\nPrinciple 4 (Reuse):\n  âœ… Using email-validator library\n  âœ… Using existing UserRepository\n\nPrinciple 5 (Open Source):\n  âœ… bcrypt chosen (documented in ADR-002)\n\nPrinciple 6 (No Legacy):\n  âœ… No TODOs\n  âœ… No commented code\n  âŒ Magic number at line 23 (should be constant)\n\nPrinciple 7 (Excellence):\n  âœ… Type hints complete\n  âœ… Docstrings present\n  âœ… Clean implementation\n\nIssues Found: 2\n  1. Line 45: Silent failure - add explicit error handling\n  2. Line 23: Magic number - extract to constant\n\nRecommendation: Fix 2 issues before merge\n```\n\n---\n\n## Configuration\n\n```yaml\n# .claude/plugins.yml\nplugins:\n  - name: \"@aisdlc/aisdlc-methodology\"\n    config:\n      principles:\n        enforce_tdd: true\n        require_tests_first: true\n        fail_fast_check: true\n        modularity_check: true\n        check_for_existing: true\n        no_legacy_baggage: true\n        excellence_standard: true\n        block_on_violations: true\n```\n\n---\n\n## Ultimate Mantra\n\n**\"Excellence or nothing\"**\n\nIf you can't answer \"yes\" to all seven questions, don't write the code yet.\n\nQuality is non-negotiable.\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills-consolidated/requirements-extraction.md": "---\nname: requirements-extraction\ndescription: Complete requirements extraction workflow - Extract REQ-* keys from intent, disambiguate with BR-*/C-*/F-*, validate quality, create traceability. Consolidates requirement-extraction, disambiguate-requirements, refine-requirements, extract-business-rules, extract-constraints, extract-formulas.\nallowed-tools: [Read, Write, Edit, Grep, Glob]\n---\n\n# Requirements Extraction\n\n**Skill Type**: Complete Workflow (Requirements Stage)\n**Purpose**: Transform raw intent into structured, traceable requirements\n**Consolidates**: requirement-extraction, disambiguate-requirements, refine-requirements, extract-business-rules, extract-constraints, extract-formulas\n\n---\n\n## When to Use This Skill\n\nUse this skill when:\n- Starting a new feature from user intent\n- Analyzing user stories or feature requests\n- Need to create REQ-* keys for traceability\n- Requirements are vague and need structure\n\n---\n\n## Complete Workflow\n\n### Phase 1: Intent Analysis\n\n**Goal**: Understand what the user wants to achieve.\n\n**Analyze**:\n- What is the goal? (capability, feature)\n- What problem does it solve?\n- Who are the users? (personas)\n- What are success criteria?\n\n**Example Intent**:\n```\nINT-042: \"We need a customer self-service portal where users can log in,\nview their account balance, update their profile, and download invoices.\"\n```\n\n**Analysis**:\n```yaml\nGoal: Customer self-service\nProblem: High support call volume for basic account info\nPersonas: Existing customers\nSuccess: Reduce support calls by 40%\nCapabilities:\n  - User authentication\n  - View account data\n  - Edit profile\n  - Download documents\n```\n\n---\n\n### Phase 2: Requirement Extraction\n\n**Goal**: Break intent into discrete, testable requirements.\n\n**Rule**: One requirement = one testable capability\n\n**Extract REQ-* Keys**:\n\n| Intent Capability | REQ Key | Type |\n|-------------------|---------|------|\n| User login | REQ-F-AUTH-001 | Functional |\n| View balance | REQ-F-PORTAL-001 | Functional |\n| Update profile | REQ-F-PORTAL-002 | Functional |\n| Download invoices | REQ-F-PORTAL-003 | Functional |\n| Response time | REQ-NFR-PERF-001 | Non-Functional |\n| SSL encryption | REQ-NFR-SEC-001 | Non-Functional |\n| Email validation | REQ-DATA-VAL-001 | Data Quality |\n\n**REQ Key Format**:\n- `REQ-F-{DOMAIN}-{SEQ}` - Functional requirements\n- `REQ-NFR-{CATEGORY}-{SEQ}` - Non-functional requirements\n- `REQ-DATA-{CATEGORY}-{SEQ}` - Data quality requirements\n- `REQ-BR-{DOMAIN}-{SEQ}` - Business rules\n\n---\n\n### Phase 3: Disambiguation\n\n**Goal**: Add specificity with Business Rules (BR-*), Constraints (C-*), and Formulas (F-*).\n\n**For each requirement, extract**:\n\n#### Business Rules (BR-*)\nSpecific rules that govern behavior:\n\n```yaml\nREQ-F-AUTH-001: User Login\n  BR-001: Email must be valid format (regex: ^[^@]+@[^@]+\\.[^@]+$)\n  BR-002: Password minimum 12 characters\n  BR-003: Max 3 login attempts, then 15-minute lockout\n  BR-004: Session timeout after 30 minutes of inactivity\n```\n\n#### Constraints (C-*)\nTechnical or business limitations:\n\n```yaml\nREQ-F-AUTH-001: User Login\n  C-001: Response time < 500ms\n  C-002: Must use HTTPS\n  C-003: Password must be hashed (bcrypt, cost factor 12)\n  C-004: Must support concurrent users (10,000+)\n```\n\n#### Formulas (F-*)\nCalculations or transformations:\n\n```yaml\nREQ-F-PORTAL-001: View Balance\n  F-001: available_balance = total_balance - pending_holds\n  F-002: display_format = currency_symbol + format(amount, 2 decimals)\n```\n\n---\n\n### Phase 4: Requirement Specification\n\n**Goal**: Write complete requirement specifications.\n\n**Template**:\n\n```markdown\n## REQ-F-AUTH-001: User Login with Email and Password\n\n**Type**: Functional Requirement\n**Domain**: Authentication\n**Priority**: P0 (Critical)\n**Intent**: INT-042\n\n**Description**:\nUsers must be able to log in to the customer portal using their\nregistered email address and password.\n\n**Acceptance Criteria**:\n1. User can enter email and password on login page\n2. Valid credentials grant access to customer portal\n3. Invalid credentials show clear error message\n4. Account locks after 3 failed attempts for 15 minutes (BR-003)\n5. Session expires after 30 minutes of inactivity (BR-004)\n\n**Business Rules**:\n- BR-001: Email must be valid format\n- BR-002: Password minimum 12 characters\n- BR-003: Max 3 attempts, 15-min lockout\n- BR-004: 30-minute session timeout\n\n**Constraints**:\n- C-001: Response time < 500ms\n- C-002: Must use HTTPS\n- C-003: Password hashed with bcrypt\n\n**User Story**:\nAs a customer\nI want to log in with my email and password\nSo that I can access my account information\n\n**Related Requirements**:\n- REQ-NFR-SEC-001: Password encryption\n- REQ-NFR-PERF-001: Login performance\n- REQ-DATA-VAL-001: Email validation\n\n**Assumptions**:\n- Users already registered (registration is separate)\n- Email is unique identifier\n\n**Out of Scope**:\n- Social login (OAuth)\n- Passwordless authentication\n- Biometric authentication\n```\n\n---\n\n### Phase 5: File Organization\n\n**Create requirements files**:\n\n```\ndocs/requirements/\nâ”œâ”€â”€ authentication.md       # REQ-F-AUTH-*\nâ”œâ”€â”€ customer-portal.md      # REQ-F-PORTAL-*\nâ”œâ”€â”€ performance.md          # REQ-NFR-PERF-*\nâ”œâ”€â”€ security.md             # REQ-NFR-SEC-*\nâ””â”€â”€ data-validation.md      # REQ-DATA-*\n```\n\n**Group by domain**, not by requirement type.\n\n---\n\n### Phase 6: Traceability Entry\n\n**Create intent-to-requirements mapping**:\n\n```yaml\n# docs/traceability/intent-to-requirements.yml\n\nINT-042:\n  title: \"Customer self-service portal\"\n  date_created: \"2025-12-01\"\n  status: \"In Progress\"\n  requirements:\n    functional:\n      - REQ-F-AUTH-001\n      - REQ-F-AUTH-002\n      - REQ-F-PORTAL-001\n      - REQ-F-PORTAL-002\n      - REQ-F-PORTAL-003\n    non_functional:\n      - REQ-NFR-PERF-001\n      - REQ-NFR-SEC-001\n    data_quality:\n      - REQ-DATA-VAL-001\n  total_requirements: 8\n  completion: 0%\n```\n\n---\n\n## Output Format\n\nWhen requirements extraction completes:\n\n```\n[REQUIREMENTS EXTRACTION - INT-042]\n\nIntent: Customer self-service portal\n\nRequirements Extracted:\n\nFunctional (5):\n  REQ-F-AUTH-001: User login with email/password\n    BR-001: Email validation\n    BR-002: Password min 12 chars\n    BR-003: Account lockout\n    C-001: Response < 500ms\n  REQ-F-AUTH-002: Password reset via email\n  REQ-F-PORTAL-001: View account balance\n    F-001: available = total - pending\n  REQ-F-PORTAL-002: Update user profile\n  REQ-F-PORTAL-003: Download invoices\n\nNon-Functional (2):\n  REQ-NFR-PERF-001: Response time < 500ms\n  REQ-NFR-SEC-001: SSL encryption required\n\nData Quality (1):\n  REQ-DATA-VAL-001: Email must be valid format\n\nTotal: 8 requirements\nBusiness Rules: 6 (BR-001 through BR-006)\nConstraints: 4 (C-001 through C-004)\nFormulas: 1 (F-001)\n\nFiles Created:\n  + docs/requirements/authentication.md\n  + docs/requirements/customer-portal.md\n  + docs/requirements/performance.md\n  + docs/requirements/security.md\n  + docs/traceability/intent-to-requirements.yml\n\nTraceability: INT-042 â†’ 8 REQ-* keys\n\nRequirements Extraction Complete!\n```\n\n---\n\n## Clarifying Questions\n\n**If intent is vague, ask**:\n\n1. **Who** is the user? (persona, role)\n2. **What** are they trying to do? (goal, capability)\n3. **Why** do they need this? (problem, value)\n4. **How** will we know it's done? (acceptance criteria)\n5. **What if** edge cases? (error handling, boundaries)\n\n**Example**:\n```\nVague: \"Add payment processing\"\n\nQuestions:\n1. What payment methods? (credit card, PayPal, crypto?)\n2. What provider? (Stripe, Braintree?)\n3. What compliance? (PCI-DSS level?)\n4. What currencies? (USD only, multi-currency?)\n5. What limits? (min/max amounts?)\n\nRefined: \"Add credit card payment via Stripe, PCI-DSS Level 1,\nUSD only, $0.01 to $10,000 per transaction.\"\n```\n\n---\n\n## SMART Requirements Checklist\n\nGood requirements are **SMART**:\n\n- **S**pecific: Clear, unambiguous description\n- **M**easurable: Acceptance criteria can be tested\n- **A**chievable: Technically feasible\n- **R**elevant: Linked to business value\n- **T**estable: Can write tests to validate\n\n**Validate each requirement against SMART before committing.**\n\n---\n\n## Configuration\n\n```yaml\n# .claude/plugins.yml\nplugins:\n  - name: \"@aisdlc/aisdlc-methodology\"\n    config:\n      requirements:\n        auto_extract_on_intent: true\n        require_acceptance_criteria: true\n        min_requirements_per_intent: 1\n        ask_clarifying_questions: true\n        max_clarifying_questions: 6\n        require_business_rules: true\n        require_constraints: false\n```\n\n---\n\n## Homeostasis Behavior\n\n**If intent too vague**:\n- Detect: Cannot extract specific requirements\n- Signal: \"Need clarification\"\n- Action: Ask clarifying questions (max 6)\n- Retry: After user provides details\n\n**If requirements incomplete**:\n- Detect: Missing acceptance criteria or business rules\n- Signal: \"Requirements need disambiguation\"\n- Action: Add BR-*, C-*, F-* as needed\n\n---\n\n## Next Steps\n\nAfter requirements extraction:\n1. **Validate**: Use `requirements-validation` skill\n2. **Design**: Move to Design stage\n3. **Implement**: Use TDD/BDD workflows\n\n**\"Excellence or nothing\"**\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills-consolidated/requirements-validation.md": "---\nname: requirements-validation\ndescription: Validate requirements quality - check SMART criteria, completeness, consistency, traceability. Consolidates validate-requirements, create-traceability-matrix.\nallowed-tools: [Read, Write, Edit, Grep, Glob]\n---\n\n# Requirements Validation\n\n**Skill Type**: Quality Gate (Requirements Stage)\n**Purpose**: Ensure requirements meet quality standards before design\n**Consolidates**: validate-requirements, create-traceability-matrix\n\n---\n\n## When to Use This Skill\n\nUse this skill when:\n- Requirements extraction is complete\n- Before moving to Design stage\n- Need to verify requirements quality\n- Creating or updating traceability matrix\n\n---\n\n## Validation Checklist\n\n### 1. SMART Criteria\n\nFor each requirement, verify:\n\n| Criterion | Question | Pass |\n|-----------|----------|------|\n| **Specific** | Is it clear and unambiguous? | |\n| **Measurable** | Can we test it? | |\n| **Achievable** | Is it technically feasible? | |\n| **Relevant** | Is it linked to business value? | |\n| **Testable** | Can we write tests for it? | |\n\n**Example**:\n```\nREQ-F-AUTH-001: User Login\n\nSpecific: Login with email/password\nMeasurable: AC1-AC5 defined\nAchievable: Standard auth pattern\nRelevant: Enables self-service portal\nTestable: Can write unit + BDD tests\n\nSMART Score: 5/5\n```\n\n---\n\n### 2. Completeness Check\n\n**Verify each requirement has**:\n\n```yaml\nrequired_fields:\n  - req_key: \"REQ-*-*-###\"           # Unique identifier\n  - type: \"Functional | NFR | Data\"   # Requirement type\n  - description: \"Clear statement\"    # What it does\n  - acceptance_criteria: \"1-5 items\"  # How to verify\n  - intent: \"INT-###\"                 # Source intent\n\nrecommended_fields:\n  - business_rules: \"BR-###\"          # Specific rules\n  - constraints: \"C-###\"              # Limitations\n  - user_story: \"As a... I want...\"   # User perspective\n  - priority: \"P0-P3\"                 # Importance\n  - related_requirements: []          # Dependencies\n```\n\n---\n\n### 3. Consistency Check\n\n**Verify no conflicts between requirements**:\n\n```yaml\nchecks:\n  - no_duplicate_keys: true           # Each REQ-* unique\n  - no_contradictions: true           # No conflicting rules\n  - consistent_terminology: true      # Same terms throughout\n  - aligned_constraints: true         # C-* don't contradict each other\n```\n\n**Example conflict**:\n```\nREQ-F-AUTH-001: Password minimum 12 characters (BR-002)\nREQ-F-REG-001: Password minimum 8 characters (BR-005)\n\nCONFLICT: Different password minimums!\nRESOLUTION: Standardize to 12 characters\n```\n\n---\n\n### 4. Traceability Check\n\n**Verify bidirectional traceability**:\n\n```yaml\nforward_traceability:\n  - intent_to_requirements: \"INT-* â†’ REQ-*\"\n  - requirements_to_design: \"REQ-* â†’ Component/API\"\n  - requirements_to_tests: \"REQ-* â†’ Test cases\"\n\nbackward_traceability:\n  - tests_to_requirements: \"Test â†’ REQ-*\"\n  - design_to_requirements: \"Component â†’ REQ-*\"\n  - requirements_to_intent: \"REQ-* â†’ INT-*\"\n```\n\n---\n\n## Validation Workflow\n\n### Step 1: Load Requirements\n\n```bash\n# Find all requirement files\ndocs/requirements/*.md\n```\n\n### Step 2: Run Validation\n\nFor each requirement:\n\n```python\ndef validate_requirement(req):\n    issues = []\n\n    # SMART checks\n    if not req.description:\n        issues.append(\"Missing description (not Specific)\")\n    if not req.acceptance_criteria:\n        issues.append(\"Missing acceptance criteria (not Measurable)\")\n    if not req.intent:\n        issues.append(\"Missing intent link (not Relevant)\")\n\n    # Completeness checks\n    if not req.req_key.matches(r'REQ-(F|NFR|DATA|BR)-\\w+-\\d{3}'):\n        issues.append(\"Invalid REQ key format\")\n\n    # Business rule check\n    if req.type == 'Functional' and not req.business_rules:\n        issues.append(\"Functional requirement should have business rules\")\n\n    return issues\n```\n\n### Step 3: Generate Validation Report\n\n```\n[REQUIREMENTS VALIDATION REPORT]\n\nDate: 2025-12-03\nRequirements Analyzed: 8\n\nSMART Validation:\n  REQ-F-AUTH-001: 5/5 (Excellent)\n  REQ-F-AUTH-002: 5/5 (Excellent)\n  REQ-F-PORTAL-001: 4/5 (Missing business rules)\n  REQ-F-PORTAL-002: 5/5 (Excellent)\n  REQ-F-PORTAL-003: 5/5 (Excellent)\n  REQ-NFR-PERF-001: 5/5 (Excellent)\n  REQ-NFR-SEC-001: 5/5 (Excellent)\n  REQ-DATA-VAL-001: 5/5 (Excellent)\n\nCompleteness:\n  With acceptance criteria: 8/8 (100%)\n  With business rules: 6/8 (75%)\n  With intent link: 8/8 (100%)\n\nConsistency:\n  Duplicate keys: 0\n  Contradictions: 0\n  Terminology issues: 0\n\nTraceability:\n  Forward (INT â†’ REQ): 100%\n  Backward (REQ â†’ INT): 100%\n\nIssues Found: 1\n  - REQ-F-PORTAL-001: Add business rules for balance calculation\n\nOverall Score: 97/100 (Excellent)\n\nRecommendation: Fix 1 issue before Design stage\n```\n\n---\n\n## Create Traceability Matrix\n\n**Generate matrix showing requirement coverage across stages**:\n\n```markdown\n# Requirements Traceability Matrix\n\n| Req ID | Description | Requirements | Design | Tasks | Code | Test | UAT | Runtime |\n|--------|-------------|--------------|--------|-------|------|------|-----|---------|\n| REQ-F-AUTH-001 | User login | âœ… | âœ… | â³ | âŒ | âŒ | âŒ | âŒ |\n| REQ-F-AUTH-002 | Password reset | âœ… | âœ… | â³ | âŒ | âŒ | âŒ | âŒ |\n| REQ-F-PORTAL-001 | View balance | âœ… | â³ | âŒ | âŒ | âŒ | âŒ | âŒ |\n...\n\nCoverage Summary:\n- Requirements Stage: 8/8 (100%)\n- Design Stage: 3/8 (38%)\n- Tasks Stage: 2/8 (25%)\n- Code Stage: 0/8 (0%)\n- System Test: 0/8 (0%)\n- UAT: 0/8 (0%)\n- Runtime: 0/8 (0%)\n```\n\n---\n\n## Output Format\n\n```\n[REQUIREMENTS VALIDATION - INT-042]\n\nRequirements Validated: 8\n\nSMART Scores:\n  5/5: 7 requirements (Excellent)\n  4/5: 1 requirement (Good - needs improvement)\n\nIssues:\n  1. REQ-F-PORTAL-001: Missing business rules\n     Action: Add BR-* for balance calculation\n\nTraceability:\n  All requirements linked to INT-042\n  Matrix: docs/TRACEABILITY_MATRIX.md updated\n\nValidation Result: PASS (with 1 minor issue)\n\nRecommendation: Fix REQ-F-PORTAL-001 before Design\n```\n\n---\n\n## Configuration\n\n```yaml\n# .claude/plugins.yml\nplugins:\n  - name: \"@aisdlc/aisdlc-methodology\"\n    config:\n      validation:\n        min_smart_score: 4           # Minimum SMART score (out of 5)\n        require_acceptance_criteria: true\n        require_business_rules_for_functional: true\n        require_intent_link: true\n        block_on_contradictions: true\n        auto_generate_matrix: true\n```\n\n---\n\n## Homeostasis Behavior\n\n**If validation fails**:\n- Detect: Requirements don't meet criteria\n- Signal: \"Requirements need improvement\"\n- Action: List specific issues\n- Block: Do not proceed to Design until fixed\n\n**If traceability gaps**:\n- Detect: Requirements without intent link\n- Signal: \"Traceability incomplete\"\n- Action: Add missing links\n\n---\n\n## Next Steps\n\nAfter validation passes:\n1. **Design**: Move to Design stage\n2. **Track**: Update traceability matrix as stages complete\n3. **Monitor**: Re-validate if requirements change\n\n**\"Excellence or nothing\"**\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills-consolidated/runtime-observability.md": "---\nname: runtime-observability\ndescription: Complete runtime observability workflow - telemetry tagging with REQ-* keys, deviation detection, production issue tracing, feedback loop closure. Consolidates create-observability-config, telemetry-tagging, trace-production-issue.\nallowed-tools: [Read, Write, Edit, Bash, Grep, Glob]\n---\n\n# Runtime Observability\n\n**Skill Type**: Complete Workflow (Runtime Feedback Stage)\n**Purpose**: Implement requirement-tagged telemetry and close the feedback loop\n**Consolidates**: create-observability-config, telemetry-tagging, trace-production-issue\n\n---\n\n## When to Use This Skill\n\nUse this skill when:\n- Setting up observability for a new service\n- Adding telemetry to existing code\n- Tracing production issues back to requirements\n- Closing the feedback loop from runtime to requirements\n- Implementing homeostasis monitoring\n\n---\n\n## Observability Architecture\n\n```\nRuntime Metrics (REQ-* tagged)\n    â†“\nTelemetry Pipeline (Datadog/Prometheus/OTEL)\n    â†“\nDeviation Detection (actual vs. homeostasis target)\n    â†“\nAlert Generation (with REQ-* context)\n    â†“\nFeedback Loop (new intent generation)\n    â†“\nRequirements Stage (cycle repeats)\n```\n\n---\n\n## Complete Workflow\n\n### Phase 1: Create Observability Configuration\n\n**Goal**: Set up telemetry infrastructure with REQ-* tagging.\n\n**Configuration Template**:\n\n```yaml\n# config/observability.yml\n\n# Observability Configuration\n# Implements: REQ-RUNTIME-001 (Telemetry Tagging)\n\ntelemetry:\n  provider: \"opentelemetry\"  # or datadog, prometheus\n  service_name: \"customer-portal\"\n  environment: \"${ENV}\"\n\n  # Global tags applied to all metrics/traces\n  global_tags:\n    service: \"customer-portal\"\n    version: \"${VERSION}\"\n    environment: \"${ENV}\"\n\n  # Metric definitions with REQ-* mapping\n  metrics:\n    - name: \"login_attempts\"\n      type: \"counter\"\n      description: \"Number of login attempts\"\n      requirement: \"REQ-F-AUTH-001\"\n      labels:\n        - \"status\"      # success, failure\n        - \"reason\"      # invalid_email, wrong_password, locked\n        - \"requirement\" # REQ-* key\n\n    - name: \"login_latency_ms\"\n      type: \"histogram\"\n      description: \"Login response time in milliseconds\"\n      requirement: \"REQ-NFR-PERF-001\"\n      constraint: \"C-001\"  # < 500ms\n      buckets: [50, 100, 200, 500, 1000, 2000]\n      labels:\n        - \"requirement\"\n\n    - name: \"account_lockouts\"\n      type: \"counter\"\n      description: \"Number of account lockouts\"\n      requirement: \"REQ-F-AUTH-001\"\n      business_rule: \"BR-003\"\n      labels:\n        - \"requirement\"\n        - \"business_rule\"\n\n  # Trace configuration\n  traces:\n    sample_rate: 0.1  # 10% sampling in production\n    always_sample_errors: true\n    propagation: [\"tracecontext\", \"baggage\"]\n\n  # Homeostasis targets for deviation detection\n  homeostasis:\n    REQ-NFR-PERF-001:\n      metric: \"login_latency_ms\"\n      target: 500\n      operator: \"lt\"  # less than\n      alert_threshold: 0.95  # Alert if > 5% exceed target\n\n    REQ-F-AUTH-001:\n      metric: \"login_success_rate\"\n      target: 0.99\n      operator: \"gte\"  # greater than or equal\n      alert_threshold: 0.98  # Alert if drops below 98%\n```\n\n---\n\n### Phase 2: Implement Telemetry Tagging\n\n**Goal**: Tag all metrics, logs, and traces with REQ-* keys.\n\n**Python Implementation**:\n\n```python\n# observability/telemetry.py\n\n# Implements: REQ-RUNTIME-001 (Telemetry Tagging)\n\nimport logging\nimport time\nimport functools\nfrom typing import Optional, Dict, Any\nfrom opentelemetry import trace, metrics\nfrom opentelemetry.trace import Status, StatusCode\n\n# Initialize tracer and meter\ntracer = trace.get_tracer(__name__)\nmeter = metrics.get_meter(__name__)\n\n# Metrics with REQ-* tags\nlogin_counter = meter.create_counter(\n    name=\"login_attempts\",\n    description=\"Number of login attempts\",\n    unit=\"1\"\n)\n\nlogin_latency = meter.create_histogram(\n    name=\"login_latency_ms\",\n    description=\"Login response time\",\n    unit=\"ms\"\n)\n\n\ndef with_telemetry(\n    requirement: str,\n    business_rules: Optional[list] = None,\n    constraints: Optional[list] = None\n):\n    \"\"\"Decorator to add telemetry with REQ-* tagging.\n\n    Implements: REQ-RUNTIME-001\n\n    Args:\n        requirement: REQ-* key this operation implements\n        business_rules: List of BR-* keys\n        constraints: List of C-* keys\n    \"\"\"\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Build attributes\n            attributes = {\n                \"requirement\": requirement,\n                \"function\": func.__name__,\n            }\n            if business_rules:\n                attributes[\"business_rules\"] = \",\".join(business_rules)\n            if constraints:\n                attributes[\"constraints\"] = \",\".join(constraints)\n\n            # Create span with REQ-* context\n            with tracer.start_as_current_span(\n                name=f\"{requirement}:{func.__name__}\",\n                attributes=attributes\n            ) as span:\n                start_time = time.perf_counter()\n                try:\n                    result = func(*args, **kwargs)\n                    span.set_status(Status(StatusCode.OK))\n                    return result\n                except Exception as e:\n                    span.set_status(Status(StatusCode.ERROR, str(e)))\n                    span.record_exception(e)\n                    raise\n                finally:\n                    # Record latency metric\n                    elapsed_ms = (time.perf_counter() - start_time) * 1000\n                    login_latency.record(elapsed_ms, attributes)\n\n        return wrapper\n    return decorator\n\n\nclass RequirementLogger:\n    \"\"\"Logger that automatically tags logs with REQ-* keys.\n\n    Implements: REQ-RUNTIME-001\n    \"\"\"\n\n    def __init__(self, logger: logging.Logger, requirement: str):\n        self.logger = logger\n        self.requirement = requirement\n\n    def _log(self, level: int, msg: str, **kwargs):\n        extra = kwargs.pop('extra', {})\n        extra['requirement'] = self.requirement\n        extra.update(kwargs)\n        self.logger.log(level, msg, extra=extra)\n\n    def info(self, msg: str, **kwargs):\n        self._log(logging.INFO, msg, **kwargs)\n\n    def warning(self, msg: str, **kwargs):\n        self._log(logging.WARNING, msg, **kwargs)\n\n    def error(self, msg: str, **kwargs):\n        self._log(logging.ERROR, msg, **kwargs)\n\n\n# Usage example\nclass AuthenticationService:\n    \"\"\"Authentication service with full telemetry.\n\n    Implements: REQ-F-AUTH-001\n    \"\"\"\n\n    def __init__(self):\n        self.logger = RequirementLogger(\n            logging.getLogger(__name__),\n            \"REQ-F-AUTH-001\"\n        )\n\n    @with_telemetry(\n        requirement=\"REQ-F-AUTH-001\",\n        business_rules=[\"BR-001\", \"BR-002\", \"BR-003\"],\n        constraints=[\"C-001\"]\n    )\n    def login(self, email: str, password: str) -> LoginResult:\n        \"\"\"Authenticate user with telemetry.\n\n        Implements: REQ-F-AUTH-001\n        Business Rules: BR-001, BR-002, BR-003\n        Constraints: C-001 (< 500ms)\n        \"\"\"\n        # Record attempt\n        login_counter.add(1, {\n            \"requirement\": \"REQ-F-AUTH-001\",\n            \"status\": \"attempt\"\n        })\n\n        # Validate email (BR-001)\n        if not self.validate_email(email):\n            login_counter.add(1, {\n                \"requirement\": \"REQ-F-AUTH-001\",\n                \"status\": \"failure\",\n                \"reason\": \"invalid_email\",\n                \"business_rule\": \"BR-001\"\n            })\n            self.logger.warning(\n                \"Login failed: invalid email\",\n                email=email,\n                business_rule=\"BR-001\"\n            )\n            return LoginResult(success=False, error=\"Invalid email\")\n\n        # ... rest of implementation\n\n        # Record success\n        login_counter.add(1, {\n            \"requirement\": \"REQ-F-AUTH-001\",\n            \"status\": \"success\"\n        })\n        self.logger.info(\"Login successful\", user_id=user.id)\n        return LoginResult(success=True, user=user)\n```\n\n---\n\n### Phase 3: Deviation Detection\n\n**Goal**: Compare runtime metrics against homeostasis targets.\n\n**Implementation**:\n\n```python\n# observability/homeostasis.py\n\n# Implements: REQ-RUNTIME-002 (Deviation Detection)\n\nfrom dataclasses import dataclass\nfrom typing import Dict, Any, Optional\nfrom datetime import datetime, timedelta\n\n@dataclass\nclass HomeostasisTarget:\n    \"\"\"Target state for a requirement.\n\n    Implements: REQ-RUNTIME-002\n    \"\"\"\n    requirement: str\n    metric: str\n    target: float\n    operator: str  # lt, gt, lte, gte, eq\n    alert_threshold: float\n    description: str\n\n\n@dataclass\nclass DeviationAlert:\n    \"\"\"Alert when runtime deviates from target.\n\n    Implements: REQ-RUNTIME-002\n    \"\"\"\n    requirement: str\n    metric: str\n    target: float\n    actual: float\n    deviation_percent: float\n    severity: str  # warning, critical\n    timestamp: datetime\n    context: Dict[str, Any]\n\n\nclass HomeostasisMonitor:\n    \"\"\"Monitor runtime metrics against homeostasis targets.\n\n    Implements: REQ-RUNTIME-002\n    \"\"\"\n\n    def __init__(self, targets: Dict[str, HomeostasisTarget]):\n        self.targets = targets\n        self.alerts: list[DeviationAlert] = []\n\n    def check_deviation(\n        self,\n        requirement: str,\n        metric_value: float\n    ) -> Optional[DeviationAlert]:\n        \"\"\"Check if metric deviates from homeostasis target.\n\n        Implements: REQ-RUNTIME-002\n        \"\"\"\n        target = self.targets.get(requirement)\n        if not target:\n            return None\n\n        # Compare against target\n        is_deviated = False\n        if target.operator == \"lt\":\n            is_deviated = metric_value >= target.target\n        elif target.operator == \"gt\":\n            is_deviated = metric_value <= target.target\n        elif target.operator == \"lte\":\n            is_deviated = metric_value > target.target\n        elif target.operator == \"gte\":\n            is_deviated = metric_value < target.target\n\n        if not is_deviated:\n            return None\n\n        # Calculate deviation\n        deviation = abs(metric_value - target.target) / target.target * 100\n\n        alert = DeviationAlert(\n            requirement=requirement,\n            metric=target.metric,\n            target=target.target,\n            actual=metric_value,\n            deviation_percent=deviation,\n            severity=\"critical\" if deviation > 20 else \"warning\",\n            timestamp=datetime.utcnow(),\n            context={\n                \"target_description\": target.description,\n                \"operator\": target.operator,\n            }\n        )\n\n        self.alerts.append(alert)\n        return alert\n\n\n# Example usage\nmonitor = HomeostasisMonitor({\n    \"REQ-NFR-PERF-001\": HomeostasisTarget(\n        requirement=\"REQ-NFR-PERF-001\",\n        metric=\"login_latency_ms\",\n        target=500,\n        operator=\"lt\",\n        alert_threshold=0.95,\n        description=\"Login response time < 500ms\"\n    ),\n    \"REQ-F-AUTH-001\": HomeostasisTarget(\n        requirement=\"REQ-F-AUTH-001\",\n        metric=\"login_success_rate\",\n        target=0.99,\n        operator=\"gte\",\n        alert_threshold=0.98,\n        description=\"Login success rate >= 99%\"\n    )\n})\n\n# Check latency (called by monitoring system)\nalert = monitor.check_deviation(\"REQ-NFR-PERF-001\", 750)  # 750ms > 500ms\nif alert:\n    print(f\"ALERT: {alert.requirement} - {alert.metric} at {alert.actual} \"\n          f\"(target: {alert.target}, deviation: {alert.deviation_percent:.1f}%)\")\n```\n\n---\n\n### Phase 4: Trace Production Issues\n\n**Goal**: Trace errors back to requirements for feedback loop.\n\n**Implementation**:\n\n```python\n# observability/issue_tracer.py\n\n# Implements: REQ-RUNTIME-003 (Feedback Loop Closure)\n\nfrom dataclasses import dataclass\nfrom typing import List, Optional\nfrom datetime import datetime\n\n@dataclass\nclass ProductionIssue:\n    \"\"\"Production issue with requirement traceability.\n\n    Implements: REQ-RUNTIME-003\n    \"\"\"\n    issue_id: str\n    error_message: str\n    stack_trace: str\n    requirement: str\n    business_rules: List[str]\n    timestamp: datetime\n    severity: str\n    impact: str  # Number of users affected\n    trace_id: str\n\n\n@dataclass\nclass FeedbackIntent:\n    \"\"\"New intent generated from production issue.\n\n    Implements: REQ-RUNTIME-003\n    \"\"\"\n    intent_id: str\n    source_issue: str\n    requirement: str\n    description: str\n    priority: str\n    created_at: datetime\n\n\nclass ProductionIssueTracer:\n    \"\"\"Trace production issues back to requirements.\n\n    Implements: REQ-RUNTIME-003 (Feedback Loop Closure)\n    \"\"\"\n\n    def trace_error(\n        self,\n        error: Exception,\n        trace_context: dict\n    ) -> ProductionIssue:\n        \"\"\"Extract requirement context from error.\n\n        Implements: REQ-RUNTIME-003\n        \"\"\"\n        # Extract REQ-* from span attributes or error context\n        requirement = trace_context.get(\"requirement\", \"UNKNOWN\")\n        business_rules = trace_context.get(\"business_rules\", \"\").split(\",\")\n\n        issue = ProductionIssue(\n            issue_id=f\"ISSUE-{datetime.utcnow().strftime('%Y%m%d%H%M%S')}\",\n            error_message=str(error),\n            stack_trace=traceback.format_exc(),\n            requirement=requirement,\n            business_rules=business_rules,\n            timestamp=datetime.utcnow(),\n            severity=\"critical\" if \"critical\" in str(error).lower() else \"high\",\n            impact=self._estimate_impact(trace_context),\n            trace_id=trace_context.get(\"trace_id\", \"\")\n        )\n\n        return issue\n\n    def generate_feedback_intent(\n        self,\n        issue: ProductionIssue\n    ) -> FeedbackIntent:\n        \"\"\"Generate new intent from production issue.\n\n        Implements: REQ-RUNTIME-003 (Feedback Loop)\n\n        This closes the loop:\n        Runtime Issue â†’ New Intent â†’ Requirements â†’ ... â†’ Fixed Code\n        \"\"\"\n        return FeedbackIntent(\n            intent_id=f\"INT-FB-{datetime.utcnow().strftime('%Y%m%d%H%M%S')}\",\n            source_issue=issue.issue_id,\n            requirement=issue.requirement,\n            description=f\"Fix production issue: {issue.error_message}\",\n            priority=\"P0\" if issue.severity == \"critical\" else \"P1\",\n            created_at=datetime.utcnow()\n        )\n```\n\n---\n\n### Phase 5: Alert Configuration\n\n**Goal**: Configure alerts with REQ-* context.\n\n**Datadog Alert Example**:\n\n```yaml\n# alerts/login_latency_alert.yml\n\n# Alert for: REQ-NFR-PERF-001 (Response Time)\n# Constraint: C-001 (< 500ms)\n\nname: \"Login Latency Exceeds Target\"\ntype: \"metric alert\"\n\nquery: |\n  avg(last_5m):avg:login_latency_ms{\n    requirement:REQ-NFR-PERF-001\n  } > 500\n\nmessage: |\n  ## Login Latency Alert\n\n  **Requirement**: REQ-NFR-PERF-001\n  **Constraint**: C-001 (< 500ms)\n\n  Current latency: {{value}}ms (target: 500ms)\n\n  **Homeostasis Deviation**: Runtime metrics deviate from target state.\n\n  **Action Required**:\n  1. Check recent deployments\n  2. Review database query performance\n  3. Check external service latencies\n\n  **Traceability**:\n  - Requirement: REQ-NFR-PERF-001\n  - Design: ADR-001 (Session Storage)\n  - Code: src/auth/authentication.py\n\n  @pagerduty-critical\n\ntags:\n  - \"requirement:REQ-NFR-PERF-001\"\n  - \"constraint:C-001\"\n  - \"severity:critical\"\n\npriority: 1\nnotify_no_data: true\n```\n\n---\n\n## Output Format\n\n```\n[RUNTIME OBSERVABILITY - REQ-F-AUTH-001]\n\nConfiguration Created:\n  + config/observability.yml\n  + alerts/login_latency_alert.yml\n  + alerts/login_success_rate_alert.yml\n\nTelemetry Implemented:\n  + observability/telemetry.py\n    - @with_telemetry decorator\n    - RequirementLogger class\n    - Metrics: login_attempts, login_latency_ms\n\nHomeostasis Monitoring:\n  + observability/homeostasis.py\n    - REQ-NFR-PERF-001: latency < 500ms\n    - REQ-F-AUTH-001: success rate >= 99%\n\nFeedback Loop:\n  + observability/issue_tracer.py\n    - Trace errors to REQ-*\n    - Generate feedback intents\n\nTraceability:\n  All metrics/logs/traces tagged with REQ-* keys\n\nRuntime Observability Complete!\n  Next: Deploy and monitor homeostasis\n```\n\n---\n\n## Configuration\n\n```yaml\n# .claude/plugins.yml\nplugins:\n  - name: \"@aisdlc/aisdlc-methodology\"\n    config:\n      runtime:\n        telemetry_provider: \"opentelemetry\"\n        require_req_tags: true\n        homeostasis_check_interval: \"5m\"\n        alert_on_deviation: true\n        auto_generate_intents: true\n        feedback_loop_enabled: true\n```\n\n---\n\n## Homeostasis Behavior\n\n**If metric deviates from target**:\n- Detect: actual > target (for latency)\n- Signal: Alert with REQ-* context\n- Action: Generate feedback intent\n- Loop: New intent â†’ Requirements â†’ Fix\n\n**If production error occurs**:\n- Detect: Exception with REQ-* context\n- Signal: Alert + trace to requirement\n- Action: Generate feedback intent\n- Loop: Fix deployed â†’ Monitor â†’ Verify homeostasis\n\n---\n\n## Key Principles Applied\n\n- **Fail Fast**: Detect deviations immediately\n- **No Legacy Baggage**: Clean up stale alerts\n- **Perfectionist Excellence**: Full traceability end-to-end\n\n**\"Excellence or nothing\"**\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills-consolidated/tdd-complete-workflow.md": "---\nname: tdd-complete-workflow\ndescription: Complete Test-Driven Development workflow - RED (write failing tests) â†’ GREEN (minimal implementation) â†’ REFACTOR (quality + tech debt) â†’ COMMIT (traceability). Consolidates tdd-workflow, red-phase, green-phase, refactor-phase, commit-with-req-tag.\nallowed-tools: [Read, Write, Edit, Bash, Grep, Glob]\n---\n\n# TDD Complete Workflow\n\n**Skill Type**: Complete Workflow (Code Stage)\n**Purpose**: Implement requirements using TDD with full traceability\n**Consolidates**: tdd-workflow, red-phase, green-phase, refactor-phase, commit-with-req-tag\n\n---\n\n## When to Use This Skill\n\nUse this skill when:\n- Implementing a new requirement (REQ-*)\n- Adding new functionality with tests\n- Following Test-Driven Development approach\n- Need full requirement traceability\n\n---\n\n## Prerequisites\n\nBefore starting, verify:\n1. Requirement key exists (REQ-F-*, REQ-NFR-*, REQ-DATA-*, REQ-BR-*)\n2. Requirement details available (what to implement)\n3. Working directory is a git repository\n4. No uncommitted changes (clean working tree)\n\n**If prerequisites missing**:\n- No REQ-* key â†’ Use `requirements-extraction` skill first\n- No requirement details â†’ Ask user for clarification\n- Dirty working tree â†’ Ask user to commit or stash\n\n---\n\n## Complete Workflow\n\n### Phase 1: RED (Write Failing Tests)\n\n**Goal**: Write tests that FAIL because implementation doesn't exist yet.\n\n**Steps**:\n\n1. **Analyze Requirement**\n   - What functionality needs to be implemented?\n   - What are the business rules (BR-*)?\n   - What are the expected inputs/outputs?\n\n2. **Design Test Cases**\n   - Happy path (valid inputs, expected success)\n   - Business rules (each BR-* gets at least 1 test)\n   - Edge cases (boundaries, empty values)\n   - Error cases (invalid inputs)\n\n3. **Create Test File**\n\n   **Python (pytest)**:\n   ```python\n   # tests/auth/test_login.py\n\n   # Validates: REQ-F-AUTH-001\n   # Business Rules: BR-001, BR-002, BR-003\n\n   import pytest\n   from auth.login import login, LoginResult  # Will fail - doesn't exist\n\n   def test_login_with_valid_credentials():\n       \"\"\"Test successful login with valid email and password\"\"\"\n       # Validates: REQ-F-AUTH-001 (happy path)\n       result = login(\"user@example.com\", \"SecurePass123!\")\n       assert result.success == True\n       assert result.user is not None\n\n   def test_login_fails_with_invalid_email():\n       \"\"\"Test login fails with invalid email format\"\"\"\n       # Validates: BR-001 (email validation)\n       result = login(\"invalid-email\", \"SecurePass123!\")\n       assert result.success == False\n       assert result.error == \"Invalid email format\"\n\n   def test_login_fails_with_short_password():\n       \"\"\"Test login fails with password < 12 characters\"\"\"\n       # Validates: BR-002 (password minimum length)\n       result = login(\"user@example.com\", \"short\")\n       assert result.success == False\n   ```\n\n   **TypeScript (Jest)**:\n   ```typescript\n   // login.test.ts\n\n   // Validates: REQ-F-AUTH-001\n   // Business Rules: BR-001, BR-002\n\n   import { login } from './login';  // Will fail - doesn't exist\n\n   describe('Login', () => {\n     test('successful login with valid credentials', () => {\n       // Validates: REQ-F-AUTH-001\n       const result = login('user@example.com', 'SecurePass123!');\n       expect(result.success).toBe(true);\n     });\n\n     test('fails with invalid email', () => {\n       // Validates: BR-001\n       const result = login('invalid-email', 'SecurePass123!');\n       expect(result.success).toBe(false);\n     });\n   });\n   ```\n\n4. **Run Tests (Expect FAILURE)**\n   ```bash\n   # Python\n   pytest tests/auth/test_login.py -v\n\n   # TypeScript\n   npm test login.test.ts\n   ```\n\n   Expected: `ImportError` or `ModuleNotFoundError` - tests fail because code doesn't exist.\n\n5. **Commit RED Phase**\n   ```bash\n   git add tests/\n   git commit -m \"RED: Add tests for REQ-F-AUTH-001\n\n   Write failing tests for user login functionality.\n\n   Tests: 5 tests (all failing as expected)\n   Validates: REQ-F-AUTH-001\n   Business Rules: BR-001, BR-002, BR-003\n   \"\n   ```\n\n---\n\n### Phase 2: GREEN (Make Tests Pass)\n\n**Goal**: Write MINIMAL code to make tests pass. No over-engineering.\n\n**Steps**:\n\n1. **Create Implementation File**\n\n   **Python**:\n   ```python\n   # src/auth/login.py\n\n   # Implements: REQ-F-AUTH-001\n\n   from dataclasses import dataclass\n   from typing import Optional\n   import re\n\n   @dataclass\n   class User:\n       email: str\n\n   @dataclass\n   class LoginResult:\n       success: bool\n       user: Optional[User] = None\n       error: Optional[str] = None\n\n   def login(email: str, password: str) -> LoginResult:\n       \"\"\"Authenticate user with email and password.\n\n       Implements: REQ-F-AUTH-001\n       Business Rules: BR-001, BR-002\n       \"\"\"\n       # BR-001: Email validation\n       if not re.match(r'^[^@]+@[^@]+\\.[^@]+$', email):\n           return LoginResult(success=False, error=\"Invalid email format\")\n\n       # BR-002: Password minimum length\n       if len(password) < 12:\n           return LoginResult(success=False, error=\"Password must be at least 12 characters\")\n\n       # Minimal implementation - just return success for valid inputs\n       return LoginResult(success=True, user=User(email=email))\n   ```\n\n2. **Run Tests (Expect SUCCESS)**\n   ```bash\n   pytest tests/auth/test_login.py -v\n   ```\n\n   Expected: All tests PASS.\n\n3. **Commit GREEN Phase**\n   ```bash\n   git add src/\n   git commit -m \"GREEN: Implement REQ-F-AUTH-001\n\n   Add minimal implementation to pass all tests.\n\n   Implements: REQ-F-AUTH-001\n   Business Rules: BR-001, BR-002\n   Tests: All passing\n   \"\n   ```\n\n---\n\n### Phase 3: REFACTOR (Quality + Tech Debt Elimination)\n\n**Goal**: Improve code quality and eliminate tech debt WITHOUT changing behavior.\n\n**Steps**:\n\n1. **Code Quality Improvements**\n   - Add type hints (Python) / type annotations (TypeScript)\n   - Add docstrings to public methods\n   - Improve variable names\n   - Extract magic numbers to constants\n\n2. **Tech Debt Elimination** (Principle #6: No Legacy Baggage)\n   - **Delete** unused imports\n   - **Remove** dead code (functions with zero callers)\n   - **Delete** commented-out code\n   - **Simplify** over-complex logic (cyclomatic complexity > 10)\n   - **Remove** code duplication\n\n3. **Run Tests (Expect STILL PASSING)**\n   ```bash\n   pytest tests/auth/test_login.py -v\n   ```\n\n4. **Commit REFACTOR Phase**\n   ```bash\n   git add .\n   git commit -m \"REFACTOR: Clean up REQ-F-AUTH-001\n\n   Code Quality:\n   - Added type hints to all functions\n   - Improved docstrings\n   - Extracted regex to constant\n\n   Tech Debt Pruning:\n   - Deleted 2 unused imports\n   - Removed 1 dead function\n\n   Tests: Still passing\n   \"\n   ```\n\n---\n\n### Phase 4: COMMIT (Final with Traceability)\n\n**Goal**: Create final commit with full requirement traceability.\n\n**Steps**:\n\n1. **Create Final Commit**\n   ```bash\n   git commit -m \"feat: Add user login (REQ-F-AUTH-001)\n\n   Implements user authentication with email and password.\n\n   Business Rules:\n   - BR-001: Email validation\n   - BR-002: Password minimum 12 characters\n\n   Tests: 5 tests, 100% coverage\n\n   Implements: REQ-F-AUTH-001\n   \"\n   ```\n\n2. **Optional: Squash Commits**\n   If configured, squash RED/GREEN/REFACTOR into single commit:\n   ```bash\n   git rebase -i HEAD~3\n   # squash all into \"feat: Add user login (REQ-F-AUTH-001)\"\n   ```\n\n---\n\n## Output Format\n\nWhen TDD workflow completes, show:\n\n```\n[TDD Workflow: REQ-F-AUTH-001]\n\nPhase 1: RED (Write Failing Tests)\n  Created: tests/auth/test_login.py (5 tests)\n  Tests FAILED as expected\n  Commit: RED: Add tests for REQ-F-AUTH-001\n\nPhase 2: GREEN (Make Tests Pass)\n  Created: src/auth/login.py\n  Implemented: login() function\n  Tests PASSED\n  Commit: GREEN: Implement REQ-F-AUTH-001\n\nPhase 3: REFACTOR (Quality + Tech Debt)\n  Code Quality: Added type hints, docstrings\n  Tech Debt: Deleted 2 unused imports\n  Tests still PASSING\n  Commit: REFACTOR: Clean up REQ-F-AUTH-001\n\nPhase 4: COMMIT (Final)\n  Final commit: feat: Add user login (REQ-F-AUTH-001)\n\nTDD Workflow Complete!\n  Files: 2 (login.py, test_login.py)\n  Tests: 5 tests, all passing\n  Commits: 4 (RED, GREEN, REFACTOR, final)\n  Traceability: REQ-F-AUTH-001 â†’ commit abc123\n```\n\n---\n\n## Test Templates by Language\n\n### Python (pytest)\n\n```python\n# tests/test_feature.py\n\n# Validates: REQ-*\n# Business Rules: BR-*, BR-*\n\nimport pytest\nfrom module import function\n\nclass TestFeature:\n    \"\"\"Test suite for Feature. Validates: REQ-*\"\"\"\n\n    def test_happy_path(self):\n        \"\"\"Test successful case. Validates: REQ-*\"\"\"\n        result = function(\"valid_input\")\n        assert result == expected_output\n\n    def test_business_rule(self):\n        \"\"\"Test business rule enforcement. Validates: BR-001\"\"\"\n        with pytest.raises(ValidationError):\n            function(\"invalid_input\")\n\n    @pytest.mark.parametrize(\"input,expected\", [\n        (\"edge1\", \"output1\"),\n        (\"edge2\", \"output2\"),\n    ])\n    def test_edge_cases(self, input, expected):\n        \"\"\"Test edge cases. Validates: REQ-*\"\"\"\n        assert function(input) == expected\n```\n\n### TypeScript (Jest)\n\n```typescript\n// feature.test.ts\n\n// Validates: REQ-*\n// Business Rules: BR-*, BR-*\n\nimport { function } from './module';\n\ndescribe('Feature', () => {\n  describe('happy path', () => {\n    test('successful case - REQ-*', () => {\n      const result = function('valid_input');\n      expect(result).toBe(expected_output);\n    });\n  });\n\n  describe('business rules', () => {\n    test('BR-001 - validation error', () => {\n      expect(() => function('invalid_input')).toThrow(ValidationError);\n    });\n  });\n\n  describe.each([\n    ['edge1', 'output1'],\n    ['edge2', 'output2'],\n  ])('edge cases', (input, expected) => {\n    test(`${input} returns ${expected}`, () => {\n      expect(function(input)).toBe(expected);\n    });\n  });\n});\n```\n\n### Java (JUnit 5)\n\n```java\n// FeatureTest.java\n\n// Validates: REQ-*\n// Business Rules: BR-*, BR-*\n\nimport org.junit.jupiter.api.*;\nimport static org.junit.jupiter.api.Assertions.*;\n\nclass FeatureTest {\n    @Test\n    @DisplayName(\"Happy path - REQ-*\")\n    void testHappyPath() {\n        var result = Feature.function(\"valid_input\");\n        assertEquals(expected_output, result);\n    }\n\n    @Test\n    @DisplayName(\"BR-001 - validation error\")\n    void testBusinessRule() {\n        assertThrows(ValidationException.class, () -> {\n            Feature.function(\"invalid_input\");\n        });\n    }\n\n    @ParameterizedTest\n    @CsvSource({\"edge1,output1\", \"edge2,output2\"})\n    void testEdgeCases(String input, String expected) {\n        assertEquals(expected, Feature.function(input));\n    }\n}\n```\n\n---\n\n## Configuration\n\n```yaml\n# .claude/plugins.yml\nplugins:\n  - name: \"@aisdlc/aisdlc-methodology\"\n    config:\n      tdd:\n        minimum_coverage: 80          # Fail if coverage < 80%\n        enforce_red_green_refactor: true  # Enforce phase order\n        allow_skip_tests: false       # Block if user tries to skip tests\n        squash_commits: false         # Keep RED/GREEN/REFACTOR commits separate\n        tech_debt_threshold: 0        # No tech debt allowed\n```\n\n---\n\n## Homeostasis Behavior\n\n**If prerequisites not met**:\n- Detect: Missing REQ-* key\n- Signal: \"Need requirement extraction first\"\n- Action: Use `requirements-extraction` skill\n- Retry: TDD workflow with new REQ-*\n\n**If tests fail in GREEN phase**:\n- Detect: Tests still failing after implementation\n- Signal: \"Implementation incomplete\"\n- Action: Fix implementation\n- Do NOT proceed to REFACTOR until tests pass\n\n**If tech debt in REFACTOR phase**:\n- Detect: Unused code, high complexity, etc.\n- Signal: \"Tech debt detected\"\n- Action: Clean up code\n- Verify: Tech debt eliminated before commit\n\n---\n\n## Key Principles Applied\n\n1. **Test Driven Development** - \"No code without tests\" (tests first in RED phase)\n2. **Fail Fast** - Tests fail immediately in RED (expected behavior)\n3. **No Legacy Baggage** - Tech debt eliminated in REFACTOR phase\n4. **Perfectionist Excellence** - Quality improvements in REFACTOR\n\n**\"Excellence or nothing\"**\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills-consolidated/technical-debt-management.md": "---\nname: technical-debt-management\ndescription: Detect and eliminate technical debt - unused code, complexity, duplication. Consolidates detect-complexity, detect-unused-code, prune-unused-code, simplify-complex-code.\nallowed-tools: [Read, Write, Edit, Bash, Grep, Glob]\n---\n\n# Technical Debt Management\n\n**Skill Type**: Quality Gate (Code Stage)\n**Purpose**: Detect and eliminate technical debt (Principle #6: No Legacy Baggage)\n**Consolidates**: detect-complexity, detect-unused-code, prune-unused-code, simplify-complex-code\n\n---\n\n## When to Use This Skill\n\nUse this skill when:\n- REFACTOR phase of TDD/BDD workflow\n- Code review identifies debt\n- Codebase maintenance/cleanup\n- Before major releases\n- Technical debt threshold exceeded\n\n---\n\n## Technical Debt Categories\n\n### 1. Unused Code\n\n**What to look for**:\n- Unused imports\n- Dead functions (zero callers)\n- Unused variables\n- Commented-out code\n- Orphaned test files\n\n**Detection** (Python):\n```bash\n# Unused imports\npylint --disable=all --enable=W0611 src/\n\n# Unused variables\npylint --disable=all --enable=W0612 src/\n\n# Dead code (comprehensive)\nvulture src/ --min-confidence 80\n```\n\n**Detection** (TypeScript):\n```bash\n# Unused code\nnpx ts-prune src/\n\n# Dead exports\nnpx unimported\n```\n\n**Pruning Strategy**:\n```\n1. BACKUP: Ensure git commit before pruning\n2. DETECT: Run detection tools\n3. VERIFY: Confirm code is truly unused\n4. DELETE: Remove unused code (don't comment)\n5. TEST: Run full test suite\n6. COMMIT: \"REFACTOR: Remove dead code\"\n```\n\n---\n\n### 2. High Complexity\n\n**Metrics**:\n- **Cyclomatic Complexity**: Number of decision points\n  - 1-10: Simple, low risk\n  - 11-20: Moderate complexity\n  - 21-50: High complexity, refactor\n  - 50+: Critical, must refactor\n\n- **Cognitive Complexity**: Mental effort to understand\n  - Sonar standard: max 15\n\n**Detection** (Python):\n```bash\n# Cyclomatic complexity\nradon cc src/ -a -s\n\n# Show functions with complexity > 10\nradon cc src/ -a -s --min C\n\n# Cognitive complexity\nflake8 --max-cognitive-complexity 15 src/\n```\n\n**Detection** (TypeScript):\n```bash\n# Using ESLint\nnpx eslint src/ --rule 'complexity: [\"error\", 10]'\n```\n\n**Simplification Patterns**:\n\n**Pattern 1: Extract Method**\n```python\n# BEFORE: Complex function\ndef process_order(order):\n    # 50+ lines of code\n    # Multiple responsibilities\n    pass\n\n# AFTER: Extracted methods\ndef process_order(order):\n    validated = validate_order(order)\n    priced = calculate_pricing(validated)\n    return submit_order(priced)\n\ndef validate_order(order):\n    # Single responsibility\n    pass\n\ndef calculate_pricing(order):\n    # Single responsibility\n    pass\n\ndef submit_order(order):\n    # Single responsibility\n    pass\n```\n\n**Pattern 2: Replace Conditionals with Polymorphism**\n```python\n# BEFORE: Complex if/else\ndef calculate_discount(customer_type, amount):\n    if customer_type == 'gold':\n        return amount * 0.20\n    elif customer_type == 'silver':\n        return amount * 0.10\n    elif customer_type == 'bronze':\n        return amount * 0.05\n    else:\n        return 0\n\n# AFTER: Strategy pattern\nclass DiscountStrategy:\n    def calculate(self, amount): raise NotImplementedError\n\nclass GoldDiscount(DiscountStrategy):\n    def calculate(self, amount): return amount * 0.20\n\nclass SilverDiscount(DiscountStrategy):\n    def calculate(self, amount): return amount * 0.10\n\nSTRATEGIES = {\n    'gold': GoldDiscount(),\n    'silver': SilverDiscount(),\n    'bronze': BronzeDiscount(),\n}\n\ndef calculate_discount(customer_type, amount):\n    strategy = STRATEGIES.get(customer_type, NoDiscount())\n    return strategy.calculate(amount)\n```\n\n**Pattern 3: Early Return**\n```python\n# BEFORE: Deep nesting\ndef process(data):\n    if data:\n        if data.is_valid:\n            if data.has_permission:\n                # actual logic here\n                return result\n            else:\n                return error_no_permission\n        else:\n            return error_invalid\n    else:\n        return error_no_data\n\n# AFTER: Guard clauses\ndef process(data):\n    if not data:\n        return error_no_data\n    if not data.is_valid:\n        return error_invalid\n    if not data.has_permission:\n        return error_no_permission\n\n    # actual logic here\n    return result\n```\n\n---\n\n### 3. Code Duplication\n\n**Detection**:\n```bash\n# Python\npylint --disable=all --enable=R0801 src/\n\n# TypeScript\nnpx jscpd src/ --min-lines 5 --min-tokens 50\n```\n\n**Deduplication Patterns**:\n\n**Pattern 1: Extract Common Function**\n```python\n# BEFORE: Duplicated validation\ndef create_user(email, password):\n    if not re.match(r'^[^@]+@[^@]+\\.[^@]+$', email):\n        raise ValueError(\"Invalid email\")\n    # ...\n\ndef update_user(user_id, email):\n    if not re.match(r'^[^@]+@[^@]+\\.[^@]+$', email):\n        raise ValueError(\"Invalid email\")\n    # ...\n\n# AFTER: Extracted function\ndef validate_email(email: str) -> str:\n    if not re.match(r'^[^@]+@[^@]+\\.[^@]+$', email):\n        raise ValueError(\"Invalid email\")\n    return email\n\ndef create_user(email, password):\n    email = validate_email(email)\n    # ...\n\ndef update_user(user_id, email):\n    email = validate_email(email)\n    # ...\n```\n\n**Pattern 2: Template Method**\n```python\n# BEFORE: Duplicated workflow\ndef process_credit_card(payment):\n    validate(payment)\n    # credit card specific logic\n    log(payment)\n    notify(payment)\n\ndef process_paypal(payment):\n    validate(payment)\n    # paypal specific logic\n    log(payment)\n    notify(payment)\n\n# AFTER: Template method\nclass PaymentProcessor:\n    def process(self, payment):\n        self.validate(payment)\n        self.execute(payment)  # Override in subclass\n        self.log(payment)\n        self.notify(payment)\n\n    def execute(self, payment):\n        raise NotImplementedError\n\nclass CreditCardProcessor(PaymentProcessor):\n    def execute(self, payment):\n        # credit card specific logic\n        pass\n```\n\n---\n\n### 4. Outdated Dependencies\n\n**Detection**:\n```bash\n# Python\npip list --outdated\npip-audit  # Security vulnerabilities\n\n# Node.js\nnpm outdated\nnpm audit\n\n# Security vulnerabilities\nsafety check  # Python\n```\n\n**Update Strategy**:\n```\n1. LIST: Check outdated dependencies\n2. REVIEW: Read changelogs for breaking changes\n3. UPDATE: One dependency at a time\n4. TEST: Run full test suite\n5. COMMIT: \"chore: Update dependency X to v2.0\"\n```\n\n---\n\n## Complete Debt Scan Workflow\n\n```bash\n# 1. Unused code\necho \"=== Unused Code ===\"\nvulture src/ --min-confidence 80\n\n# 2. Complexity\necho \"=== High Complexity ===\"\nradon cc src/ -a -s --min C\n\n# 3. Duplication\necho \"=== Code Duplication ===\"\npylint --disable=all --enable=R0801 src/\n\n# 4. Outdated deps\necho \"=== Outdated Dependencies ===\"\npip list --outdated\n\n# 5. Security\necho \"=== Security Vulnerabilities ===\"\npip-audit\n```\n\n---\n\n## Output Format\n\n```\n[TECHNICAL DEBT SCAN]\n\nScan Date: 2025-12-03\nCodebase: src/\n\n=== Unused Code ===\nFound: 15 items\n\n  Dead Functions (5):\n    - src/utils/helpers.py:45 - format_legacy() (0 callers)\n    - src/auth/validators.py:120 - validate_v1() (0 callers)\n    ...\n\n  Unused Imports (8):\n    - src/main.py:3 - import os (never used)\n    - src/services/payment.py:5 - from decimal import *\n    ...\n\n  Commented Code (2):\n    - src/api/routes.py:78-95 - Old endpoint\n    - src/models/user.py:34-40 - Deprecated field\n\n=== High Complexity ===\nFound: 3 functions above threshold\n\n  Critical (CC > 20):\n    - src/services/order.py:process_order() - CC=32\n\n  High (CC 11-20):\n    - src/auth/login.py:authenticate() - CC=15\n    - src/api/handlers.py:handle_request() - CC=12\n\n=== Code Duplication ===\nFound: 2 duplicated blocks\n\n  Block 1: 15 lines (3 locations)\n    - src/validators/email.py:10-25\n    - src/validators/user.py:20-35\n    - src/api/schemas.py:45-60\n\n  Block 2: 8 lines (2 locations)\n    - src/services/auth.py:50-58\n    - src/services/session.py:30-38\n\n=== Summary ===\nTotal Debt Items: 20\n  - Unused Code: 15 (Delete)\n  - High Complexity: 3 (Refactor)\n  - Duplication: 2 (Extract)\n\nEstimated Cleanup: 2-3 hours\n\nRecommendation: Address before next release\n```\n\n---\n\n## Pruning Workflow\n\n**Step 1: Detect**\n```bash\n# Run full scan\n./scripts/debt-scan.sh\n```\n\n**Step 2: Prioritize**\n```\nPriority 1: Security vulnerabilities\nPriority 2: Critical complexity (CC > 20)\nPriority 3: Dead code (zero callers)\nPriority 4: High complexity (CC 11-20)\nPriority 5: Duplication\nPriority 6: Outdated dependencies\n```\n\n**Step 3: Prune**\n```bash\n# Delete dead code\ngit rm src/utils/helpers.py  # If entire file unused\n\n# Or edit to remove specific functions\n# Edit file, remove dead functions, run tests\n\n# Commit\ngit commit -m \"REFACTOR: Remove dead code\n\nDeleted:\n- format_legacy() - no callers since v2.0\n- validate_v1() - replaced by validate_v2()\n\nTests: All passing\n\"\n```\n\n**Step 4: Verify**\n```bash\n# Run full test suite\npytest tests/ -v\n\n# Run debt scan again\n./scripts/debt-scan.sh\n# Should show reduced debt\n```\n\n---\n\n## Configuration\n\n```yaml\n# .claude/plugins.yml\nplugins:\n  - name: \"@aisdlc/aisdlc-methodology\"\n    config:\n      technical_debt:\n        complexity_threshold: 10\n        cognitive_complexity_threshold: 15\n        duplication_min_lines: 5\n        unused_code_confidence: 80\n        block_on_critical: true  # Block deploy if CC > 20\n        scan_on_commit: true\n        scan_on_pr: true\n```\n\n---\n\n## Homeostasis Behavior\n\n**If debt exceeds threshold**:\n- Detect: CC > 20 or security vulnerability\n- Signal: \"Technical debt critical\"\n- Action: Block deployment until fixed\n- Require: Cleanup before proceeding\n\n**If debt accumulating**:\n- Detect: Debt increasing over sprints\n- Signal: \"Allocate cleanup time\"\n- Action: Add debt cleanup to sprint\n\n---\n\n## Key Principles Applied\n\n- **No Legacy Baggage**: Delete, don't comment\n- **Fail Fast**: Detect debt early\n- **Perfectionist Excellence**: Zero tolerance for critical debt\n\n**\"Excellence or nothing\"**\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills-consolidated/test-coverage-management.md": "---\nname: test-coverage-management\ndescription: Complete test coverage workflow - create specifications, generate missing tests, validate coverage, run integration tests. Consolidates create-test-specification, generate-missing-tests, validate-test-coverage, run-integration-tests, create-coverage-report.\nallowed-tools: [Read, Write, Edit, Bash, Grep, Glob]\n---\n\n# Test Coverage Management\n\n**Skill Type**: Quality Gate (System Test Stage)\n**Purpose**: Ensure comprehensive test coverage with requirement traceability\n**Consolidates**: create-test-specification, generate-missing-tests, validate-test-coverage, run-integration-tests, create-coverage-report\n\n---\n\n## When to Use This Skill\n\nUse this skill when:\n- Need to assess current test coverage\n- Identifying gaps in test coverage\n- Generating missing tests for requirements\n- Creating test specifications (TCS)\n- Before releases to validate coverage\n\n---\n\n## Test Coverage Workflow\n\n### Phase 1: Create Test Specification\n\n**Goal**: Document what tests are needed for each requirement.\n\n**Test Case Specification (TCS) Template**:\n\n```markdown\n# TCS-001: User Login Test Specification\n\n**Requirement**: REQ-F-AUTH-001\n**Business Rules**: BR-001, BR-002, BR-003\n**Priority**: P0 (Critical)\n**Type**: Unit + Integration\n\n## Test Cases\n\n### TC-001-01: Successful Login (Happy Path)\n**Description**: Verify user can login with valid credentials\n**Preconditions**:\n- User exists with email \"user@example.com\"\n- User is not locked\n**Steps**:\n1. Enter email \"user@example.com\"\n2. Enter password \"SecurePass123!\"\n3. Click Login\n**Expected Result**: Login succeeds, JWT token returned\n**Validates**: REQ-F-AUTH-001, BR-001, BR-002\n\n### TC-001-02: Invalid Email Format\n**Description**: Verify login fails with invalid email\n**Steps**:\n1. Enter email \"invalid-email\"\n2. Enter password \"SecurePass123!\"\n3. Click Login\n**Expected Result**: Error \"Invalid email format\"\n**Validates**: BR-001\n\n### TC-001-03: Short Password\n**Description**: Verify login fails with password < 12 chars\n**Steps**:\n1. Enter email \"user@example.com\"\n2. Enter password \"short\"\n3. Click Login\n**Expected Result**: Error \"Password must be at least 12 characters\"\n**Validates**: BR-002\n\n### TC-001-04: Account Lockout\n**Description**: Verify account locks after 3 failed attempts\n**Preconditions**:\n- User exists with email \"user@example.com\"\n- User has 0 failed attempts\n**Steps**:\n1. Attempt login with wrong password (3 times)\n2. Attempt login with correct password\n**Expected Result**: Error \"Account locked. Try again in 15 minutes\"\n**Validates**: BR-003\n\n## Coverage Matrix\n\n| Test Case | REQ | BR-001 | BR-002 | BR-003 |\n|-----------|-----|--------|--------|--------|\n| TC-001-01 | âœ…  | âœ…     | âœ…     | âŒ     |\n| TC-001-02 | âŒ  | âœ…     | âŒ     | âŒ     |\n| TC-001-03 | âŒ  | âŒ     | âœ…     | âŒ     |\n| TC-001-04 | âŒ  | âŒ     | âŒ     | âœ…     |\n```\n\n---\n\n### Phase 2: Validate Test Coverage\n\n**Goal**: Identify gaps between requirements and existing tests.\n\n**Coverage Analysis**:\n\n```python\n# scripts/coverage_analysis.py\n\ndef analyze_coverage(requirements_dir: str, tests_dir: str) -> dict:\n    \"\"\"Analyze test coverage against requirements.\n\n    Returns coverage report showing gaps.\n    \"\"\"\n    requirements = load_requirements(requirements_dir)\n    tests = scan_tests(tests_dir)\n\n    coverage = {}\n    for req_id, req in requirements.items():\n        # Find tests that validate this requirement\n        validating_tests = [\n            t for t in tests\n            if req_id in t.validates\n        ]\n\n        coverage[req_id] = {\n            'requirement': req.description,\n            'tests': len(validating_tests),\n            'business_rules': {\n                br: any(br in t.validates for t in validating_tests)\n                for br in req.business_rules\n            },\n            'has_unit_tests': any(t.type == 'unit' for t in validating_tests),\n            'has_integration_tests': any(t.type == 'integration' for t in validating_tests),\n            'coverage_percent': calculate_coverage(req, validating_tests)\n        }\n\n    return coverage\n```\n\n**Coverage Report Output**:\n\n```\n[TEST COVERAGE REPORT]\n\nDate: 2025-12-03\nRequirements: 8\nTests: 45\n\n=== Coverage by Requirement ===\n\nREQ-F-AUTH-001: User Login\n  Tests: 12 (Unit: 8, Integration: 4)\n  Business Rules: BR-001 âœ…, BR-002 âœ…, BR-003 âœ…\n  Coverage: 100%\n\nREQ-F-AUTH-002: Password Reset\n  Tests: 5 (Unit: 3, Integration: 2)\n  Business Rules: BR-005 âœ…, BR-006 âŒ\n  Coverage: 80%\n  GAP: Missing test for BR-006 (reset link expiration)\n\nREQ-F-PORTAL-001: View Balance\n  Tests: 0\n  Coverage: 0%\n  GAP: No tests! Critical requirement.\n\nREQ-F-PORTAL-002: Update Profile\n  Tests: 3 (Unit: 3, Integration: 0)\n  Coverage: 60%\n  GAP: Missing integration tests\n\nREQ-F-PORTAL-003: Download Invoices\n  Tests: 2 (Unit: 1, Integration: 1)\n  Coverage: 50%\n  GAP: Missing edge case tests\n\nREQ-NFR-PERF-001: Response Time\n  Tests: 2 (Performance: 2)\n  Coverage: 100%\n\nREQ-NFR-SEC-001: SSL/TLS\n  Tests: 1 (Security: 1)\n  Coverage: 100%\n\nREQ-DATA-VAL-001: Email Validation\n  Tests: 5 (Unit: 5)\n  Coverage: 100%\n\n=== Summary ===\n\nTotal Coverage: 73% (35/48 test cases)\n\nBy Type:\n  Unit Tests: 28/40 (70%)\n  Integration Tests: 7/20 (35%)\n  Performance Tests: 2/3 (67%)\n  Security Tests: 1/2 (50%)\n\nCritical Gaps:\n  1. REQ-F-PORTAL-001 - NO TESTS (0%)\n  2. REQ-F-AUTH-002 - Missing BR-006 test\n  3. REQ-F-PORTAL-002 - No integration tests\n\nRecommendation: Add 13 tests to reach 80% coverage\n```\n\n---\n\n### Phase 3: Generate Missing Tests\n\n**Goal**: Auto-generate tests for uncovered requirements.\n\n**For each gap, generate**:\n\n```python\n# tests/test_portal_001_balance.py\n\n# Generated for: REQ-F-PORTAL-001 (View Balance)\n# Gap identified: No existing tests\n\nimport pytest\nfrom decimal import Decimal\nfrom services.balance import get_balance, BalanceResult\n\nclass TestViewBalance:\n    \"\"\"Test suite for REQ-F-PORTAL-001: View Account Balance\"\"\"\n\n    # TC-PORTAL-001-01: Happy path\n    def test_get_balance_returns_correct_amounts(self, test_user):\n        \"\"\"Verify balance calculation is correct.\n\n        Validates: REQ-F-PORTAL-001, F-001\n        Formula: available = total - pending\n        \"\"\"\n        # Arrange\n        test_user.total_balance = Decimal(\"1000.00\")\n        test_user.pending_holds = Decimal(\"150.00\")\n\n        # Act\n        result = get_balance(test_user.id)\n\n        # Assert\n        assert result.total_balance == Decimal(\"1000.00\")\n        assert result.pending_holds == Decimal(\"150.00\")\n        assert result.available_balance == Decimal(\"850.00\")  # F-001\n\n    # TC-PORTAL-001-02: Zero balance\n    def test_get_balance_with_zero_balance(self, test_user):\n        \"\"\"Verify handling of zero balance.\n\n        Validates: REQ-F-PORTAL-001 (edge case)\n        \"\"\"\n        test_user.total_balance = Decimal(\"0.00\")\n        test_user.pending_holds = Decimal(\"0.00\")\n\n        result = get_balance(test_user.id)\n\n        assert result.available_balance == Decimal(\"0.00\")\n\n    # TC-PORTAL-001-03: Pending exceeds total (edge case)\n    def test_get_balance_with_negative_available(self, test_user):\n        \"\"\"Verify handling when holds exceed balance.\n\n        Validates: REQ-F-PORTAL-001 (edge case)\n        \"\"\"\n        test_user.total_balance = Decimal(\"100.00\")\n        test_user.pending_holds = Decimal(\"150.00\")\n\n        result = get_balance(test_user.id)\n\n        # Should show negative available or zero?\n        # Per business rule, show actual negative\n        assert result.available_balance == Decimal(\"-50.00\")\n\n    # TC-PORTAL-001-04: User not found\n    def test_get_balance_user_not_found(self):\n        \"\"\"Verify error when user doesn't exist.\n\n        Validates: REQ-F-PORTAL-001 (error case)\n        \"\"\"\n        with pytest.raises(UserNotFoundException):\n            get_balance(\"nonexistent-user-id\")\n\n    # TC-PORTAL-001-05: Currency formatting\n    def test_balance_display_format(self, test_user):\n        \"\"\"Verify currency display format.\n\n        Validates: F-002 (display_format)\n        \"\"\"\n        test_user.total_balance = Decimal(\"1234.567\")\n\n        result = get_balance(test_user.id)\n\n        assert result.formatted_balance == \"$1,234.57\"  # F-002\n```\n\n---\n\n### Phase 4: Run Integration Tests\n\n**Goal**: Execute integration tests with reporting.\n\n**Command**:\n```bash\n# Run with coverage\npytest tests/ -v --cov=src --cov-report=html --cov-report=term\n\n# Run specific requirement tests\npytest tests/ -v -k \"REQ_F_AUTH_001\"\n\n# Run with markers\npytest tests/ -v -m \"integration\"\npytest tests/ -v -m \"critical\"\n```\n\n**Integration Test Example**:\n\n```python\n# tests/integration/test_auth_integration.py\n\n# Integration tests for: REQ-F-AUTH-001\n\nimport pytest\nfrom fastapi.testclient import TestClient\nfrom app.main import app\n\nclass TestAuthIntegration:\n    \"\"\"Integration tests for authentication flow.\n\n    Validates: REQ-F-AUTH-001 (end-to-end)\n    \"\"\"\n\n    @pytest.fixture\n    def client(self):\n        return TestClient(app)\n\n    @pytest.fixture\n    def registered_user(self, client):\n        \"\"\"Create user for testing.\"\"\"\n        response = client.post(\"/api/v1/users\", json={\n            \"email\": \"test@example.com\",\n            \"password\": \"SecurePass123!\"\n        })\n        return response.json()\n\n    @pytest.mark.integration\n    def test_login_flow_success(self, client, registered_user):\n        \"\"\"Test complete login flow.\n\n        Validates: REQ-F-AUTH-001 (integration)\n        \"\"\"\n        # Login\n        response = client.post(\"/api/v1/auth/login\", json={\n            \"email\": \"test@example.com\",\n            \"password\": \"SecurePass123!\"\n        })\n\n        assert response.status_code == 200\n        assert \"token\" in response.json()\n        assert \"expires_at\" in response.json()\n\n        # Verify token works\n        token = response.json()[\"token\"]\n        response = client.get(\n            \"/api/v1/auth/session\",\n            headers={\"Authorization\": f\"Bearer {token}\"}\n        )\n        assert response.status_code == 200\n\n    @pytest.mark.integration\n    def test_login_lockout_flow(self, client, registered_user):\n        \"\"\"Test account lockout after failed attempts.\n\n        Validates: BR-003 (integration)\n        \"\"\"\n        # Fail 3 times\n        for _ in range(3):\n            response = client.post(\"/api/v1/auth/login\", json={\n                \"email\": \"test@example.com\",\n                \"password\": \"wrong_password\"\n            })\n            assert response.status_code == 401\n\n        # 4th attempt should be locked\n        response = client.post(\"/api/v1/auth/login\", json={\n            \"email\": \"test@example.com\",\n            \"password\": \"SecurePass123!\"  # Even correct password\n        })\n        assert response.status_code == 423  # Locked\n        assert \"locked\" in response.json()[\"error\"].lower()\n```\n\n---\n\n### Phase 5: Generate Coverage Report\n\n**Goal**: Create comprehensive coverage report.\n\n**HTML Report**:\n```bash\npytest tests/ --cov=src --cov-report=html\n# Open htmlcov/index.html\n```\n\n**Traceability Report**:\n\n```markdown\n# Test Coverage Traceability Report\n\nGenerated: 2025-12-03\nProject: customer-portal\n\n## Executive Summary\n\n| Metric | Value | Target | Status |\n|--------|-------|--------|--------|\n| Line Coverage | 87% | 80% | âœ… |\n| Branch Coverage | 72% | 70% | âœ… |\n| Requirement Coverage | 85% | 100% | âš ï¸ |\n| Business Rule Coverage | 90% | 100% | âš ï¸ |\n\n## Coverage by Requirement\n\n| Requirement | Unit | Integration | Total | Status |\n|-------------|------|-------------|-------|--------|\n| REQ-F-AUTH-001 | 8/8 | 4/4 | 100% | âœ… |\n| REQ-F-AUTH-002 | 3/4 | 2/2 | 83% | âš ï¸ |\n| REQ-F-PORTAL-001 | 5/5 | 2/3 | 88% | âœ… |\n| REQ-F-PORTAL-002 | 3/3 | 0/2 | 60% | âŒ |\n| REQ-F-PORTAL-003 | 2/4 | 1/2 | 50% | âŒ |\n| REQ-NFR-PERF-001 | 2/2 | - | 100% | âœ… |\n| REQ-NFR-SEC-001 | 1/1 | - | 100% | âœ… |\n| REQ-DATA-VAL-001 | 5/5 | - | 100% | âœ… |\n\n## Gaps Requiring Action\n\n1. **REQ-F-AUTH-002**: Missing test for BR-006 (reset link expiration)\n2. **REQ-F-PORTAL-002**: No integration tests\n3. **REQ-F-PORTAL-003**: Missing 2 unit tests, 1 integration test\n\n## Recommendation\n\nAdd 6 tests to achieve 100% requirement coverage:\n- 1 unit test for BR-006\n- 2 integration tests for REQ-F-PORTAL-002\n- 2 unit tests + 1 integration test for REQ-F-PORTAL-003\n\nEstimated effort: 4 hours\n```\n\n---\n\n## Output Format\n\n```\n[TEST COVERAGE MANAGEMENT]\n\nAction: Coverage Analysis + Gap Generation\n\nCurrent State:\n  Requirements: 8\n  Existing Tests: 45\n  Line Coverage: 87%\n  Requirement Coverage: 73%\n\nGaps Identified: 6\n  1. REQ-F-PORTAL-001 - No tests (GENERATED)\n  2. REQ-F-AUTH-002/BR-006 - Missing test (GENERATED)\n  3. REQ-F-PORTAL-002 - No integration tests (GENERATED)\n  ...\n\nTests Generated: 13 new tests\n  + tests/test_portal_001_balance.py (5 tests)\n  + tests/test_auth_002_reset.py (2 tests)\n  + tests/integration/test_portal_002.py (3 tests)\n  + tests/integration/test_portal_003.py (3 tests)\n\nNew Coverage:\n  Requirement Coverage: 100%\n  Line Coverage: 92%\n\nTest Coverage Management Complete!\n  Next: Run full test suite to verify\n```\n\n---\n\n## Configuration\n\n```yaml\n# .claude/plugins.yml\nplugins:\n  - name: \"@aisdlc/aisdlc-methodology\"\n    config:\n      test_coverage:\n        minimum_line_coverage: 80\n        minimum_branch_coverage: 70\n        minimum_requirement_coverage: 100\n        require_integration_tests: true\n        generate_missing_tests: true\n        coverage_report_format: [\"html\", \"term\", \"json\"]\n        block_deploy_if_below_threshold: true\n```\n\n---\n\n## Homeostasis Behavior\n\n**If coverage below threshold**:\n- Detect: Coverage < 80%\n- Signal: \"Coverage insufficient\"\n- Action: Generate missing tests\n- Block: Deploy blocked until threshold met\n\n**If requirement has no tests**:\n- Detect: REQ-* with 0 tests\n- Signal: \"Critical gap - untested requirement\"\n- Action: Generate test specification + tests\n\n---\n\n## Key Principles Applied\n\n- **Test Driven Development**: Tests validate requirements\n- **Fail Fast**: Detect gaps early\n- **Perfectionist Excellence**: 100% requirement coverage\n\n**\"Excellence or nothing\"**\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills-consolidated/traceability-core.md": "---\nname: traceability-core\ndescription: Core traceability operations - check coverage, propagate REQ-* keys, validate traceability chain from intent to runtime. Consolidates check-requirement-coverage, propagate-req-keys, requirement-traceability.\nallowed-tools: [Read, Write, Edit, Grep, Glob]\n---\n\n# Traceability Core\n\n**Skill Type**: Core Infrastructure (All Stages)\n**Purpose**: Maintain bidirectional traceability from Intent to Runtime\n**Consolidates**: check-requirement-coverage, propagate-req-keys, requirement-traceability\n\n---\n\n## When to Use This Skill\n\nUse this skill when:\n- Need to verify traceability chain is intact\n- Propagating REQ-* keys through stages\n- Checking coverage at any stage\n- Validating requirement implementation\n- Creating or updating traceability matrix\n\n---\n\n## Traceability Model\n\n### Complete Traceability Chain\n\n```\nIntent (INT-*)\n    â†“ (extract)\nRequirements (REQ-*)\n    â†“ (design)\nDesign (Component, API, ADR)\n    â†“ (breakdown)\nTasks (JIRA-*, TASK-*)\n    â†“ (implement)\nCode (functions, classes)\n    â†“ (test)\nTests (unit, integration, BDD)\n    â†“ (validate)\nUAT (business sign-off)\n    â†“ (deploy)\nRuntime (metrics, logs, traces)\n    â†“ (feedback)\n[New Intent] â†’ cycle repeats\n```\n\n### Key Propagation Rules\n\n```yaml\n# REQ-* keys flow through all artifacts\n\nRequirements Document:\n  - REQ-F-AUTH-001: User login with email and password\n\nDesign Document:\n  - Implements: REQ-F-AUTH-001\n  - Component: AuthenticationService\n  - API: POST /api/v1/auth/login\n\nTask Ticket:\n  - Implements: REQ-F-AUTH-001\n  - Ticket: PORTAL-123\n\nCode:\n  # Implements: REQ-F-AUTH-001\n  def login(email, password): ...\n\nUnit Test:\n  # Validates: REQ-F-AUTH-001\n  def test_login(): ...\n\nBDD Scenario:\n  @REQ-F-AUTH-001\n  Scenario: Successful login\n\nRuntime Metrics:\n  login_attempts{requirement=\"REQ-F-AUTH-001\"}\n\nAlert:\n  Requirement: REQ-F-AUTH-001\n```\n\n---\n\n## Core Operations\n\n### 1. Check Requirement Coverage\n\n**Goal**: Verify all requirements have coverage at specified stage.\n\n```python\n# traceability/coverage.py\n\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Set\nfrom enum import Enum\n\nclass Stage(Enum):\n    REQUIREMENTS = \"requirements\"\n    DESIGN = \"design\"\n    TASKS = \"tasks\"\n    CODE = \"code\"\n    SYSTEM_TEST = \"system_test\"\n    UAT = \"uat\"\n    RUNTIME = \"runtime\"\n\n\n@dataclass\nclass CoverageResult:\n    \"\"\"Coverage analysis result.\"\"\"\n    stage: Stage\n    total_requirements: int\n    covered_requirements: int\n    coverage_percent: float\n    covered: List[str]\n    uncovered: List[str]\n\n\ndef check_coverage(\n    requirements: List[str],\n    artifacts: Dict[str, Set[str]],  # artifact_path -> set of REQ-* it covers\n    stage: Stage\n) -> CoverageResult:\n    \"\"\"Check requirement coverage at a specific stage.\n\n    Implements: REQ-TRACE-001\n    \"\"\"\n    covered = set()\n\n    for artifact_path, req_keys in artifacts.items():\n        covered.update(req_keys)\n\n    uncovered = set(requirements) - covered\n\n    return CoverageResult(\n        stage=stage,\n        total_requirements=len(requirements),\n        covered_requirements=len(covered),\n        coverage_percent=len(covered) / len(requirements) * 100 if requirements else 0,\n        covered=sorted(covered),\n        uncovered=sorted(uncovered)\n    )\n\n\n# Usage example\ndef scan_code_coverage(src_dir: str, requirements: List[str]) -> CoverageResult:\n    \"\"\"Scan code files for requirement coverage.\"\"\"\n    import re\n    from pathlib import Path\n\n    artifacts = {}\n    req_pattern = re.compile(r'(?:Implements|Validates):\\s*(REQ-[A-Z]+-[A-Z]+-\\d{3})')\n\n    for path in Path(src_dir).rglob(\"*.py\"):\n        content = path.read_text()\n        matches = req_pattern.findall(content)\n        if matches:\n            artifacts[str(path)] = set(matches)\n\n    return check_coverage(requirements, artifacts, Stage.CODE)\n```\n\n---\n\n### 2. Propagate REQ-* Keys\n\n**Goal**: Ensure REQ-* keys flow from source to downstream artifacts.\n\n```python\n# traceability/propagation.py\n\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Optional\nfrom pathlib import Path\nimport re\n\n\n@dataclass\nclass PropagationResult:\n    \"\"\"Result of key propagation operation.\"\"\"\n    source: str\n    target: str\n    keys_propagated: List[str]\n    keys_missing: List[str]\n    success: bool\n\n\ndef propagate_to_design(\n    requirement_path: str,\n    design_path: str\n) -> PropagationResult:\n    \"\"\"Propagate REQ-* keys from requirements to design document.\n\n    Implements: REQ-TRACE-002\n    \"\"\"\n    # Extract REQ-* from requirements\n    req_content = Path(requirement_path).read_text()\n    req_pattern = re.compile(r'(REQ-[A-Z]+-[A-Z]+-\\d{3})')\n    req_keys = set(req_pattern.findall(req_content))\n\n    # Check design document\n    design_content = Path(design_path).read_text()\n    design_keys = set(req_pattern.findall(design_content))\n\n    missing = req_keys - design_keys\n\n    return PropagationResult(\n        source=requirement_path,\n        target=design_path,\n        keys_propagated=sorted(design_keys),\n        keys_missing=sorted(missing),\n        success=len(missing) == 0\n    )\n\n\ndef propagate_to_code(\n    design_path: str,\n    src_dir: str\n) -> PropagationResult:\n    \"\"\"Propagate REQ-* keys from design to code.\n\n    Implements: REQ-TRACE-002\n    \"\"\"\n    # Extract REQ-* from design\n    design_content = Path(design_path).read_text()\n    req_pattern = re.compile(r'(REQ-[A-Z]+-[A-Z]+-\\d{3})')\n    design_keys = set(req_pattern.findall(design_content))\n\n    # Scan code\n    code_keys = set()\n    for path in Path(src_dir).rglob(\"*.py\"):\n        content = path.read_text()\n        code_keys.update(req_pattern.findall(content))\n\n    missing = design_keys - code_keys\n\n    return PropagationResult(\n        source=design_path,\n        target=src_dir,\n        keys_propagated=sorted(code_keys),\n        keys_missing=sorted(missing),\n        success=len(missing) == 0\n    )\n\n\ndef propagate_to_tests(\n    src_dir: str,\n    tests_dir: str\n) -> PropagationResult:\n    \"\"\"Propagate REQ-* keys from code to tests.\n\n    Implements: REQ-TRACE-002\n    \"\"\"\n    req_pattern = re.compile(r'(REQ-[A-Z]+-[A-Z]+-\\d{3})')\n\n    # Extract REQ-* from code\n    code_keys = set()\n    for path in Path(src_dir).rglob(\"*.py\"):\n        content = path.read_text()\n        matches = re.findall(r'#\\s*Implements:\\s*(REQ-[A-Z]+-[A-Z]+-\\d{3})', content)\n        code_keys.update(matches)\n\n    # Extract REQ-* from tests\n    test_keys = set()\n    for path in Path(tests_dir).rglob(\"test_*.py\"):\n        content = path.read_text()\n        matches = re.findall(r'#\\s*Validates:\\s*(REQ-[A-Z]+-[A-Z]+-\\d{3})', content)\n        test_keys.update(matches)\n\n    missing = code_keys - test_keys\n\n    return PropagationResult(\n        source=src_dir,\n        target=tests_dir,\n        keys_propagated=sorted(test_keys),\n        keys_missing=sorted(missing),\n        success=len(missing) == 0\n    )\n```\n\n---\n\n### 3. Validate Full Traceability Chain\n\n**Goal**: Verify complete traceability from Intent to Runtime.\n\n```python\n# traceability/validator.py\n\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Optional\n\n\n@dataclass\nclass TraceabilityChain:\n    \"\"\"Complete traceability chain for a requirement.\"\"\"\n    requirement: str\n    intent: Optional[str]\n    design_artifacts: List[str]\n    tasks: List[str]\n    code_files: List[str]\n    tests: List[str]\n    uat_status: Optional[str]\n    runtime_metrics: List[str]\n    chain_complete: bool\n    gaps: List[str]\n\n\ndef validate_chain(requirement: str, project_paths: dict) -> TraceabilityChain:\n    \"\"\"Validate complete traceability chain for a requirement.\n\n    Implements: REQ-TRACE-003\n    \"\"\"\n    chain = TraceabilityChain(\n        requirement=requirement,\n        intent=None,\n        design_artifacts=[],\n        tasks=[],\n        code_files=[],\n        tests=[],\n        uat_status=None,\n        runtime_metrics=[],\n        chain_complete=False,\n        gaps=[]\n    )\n\n    # Check intent link\n    chain.intent = find_intent_for_requirement(\n        requirement,\n        project_paths.get(\"traceability_dir\")\n    )\n    if not chain.intent:\n        chain.gaps.append(\"Missing intent link\")\n\n    # Check design\n    chain.design_artifacts = find_design_artifacts(\n        requirement,\n        project_paths.get(\"design_dir\")\n    )\n    if not chain.design_artifacts:\n        chain.gaps.append(\"No design artifacts\")\n\n    # Check tasks\n    chain.tasks = find_tasks(\n        requirement,\n        project_paths.get(\"tasks_dir\")\n    )\n    if not chain.tasks:\n        chain.gaps.append(\"No task tickets\")\n\n    # Check code\n    chain.code_files = find_code_files(\n        requirement,\n        project_paths.get(\"src_dir\")\n    )\n    if not chain.code_files:\n        chain.gaps.append(\"No code implementation\")\n\n    # Check tests\n    chain.tests = find_tests(\n        requirement,\n        project_paths.get(\"tests_dir\")\n    )\n    if not chain.tests:\n        chain.gaps.append(\"No tests\")\n\n    # Check UAT\n    chain.uat_status = find_uat_status(\n        requirement,\n        project_paths.get(\"uat_dir\")\n    )\n    if not chain.uat_status:\n        chain.gaps.append(\"No UAT sign-off\")\n\n    # Check runtime\n    chain.runtime_metrics = find_runtime_metrics(\n        requirement,\n        project_paths.get(\"observability_config\")\n    )\n    if not chain.runtime_metrics:\n        chain.gaps.append(\"No runtime telemetry\")\n\n    chain.chain_complete = len(chain.gaps) == 0\n    return chain\n```\n\n---\n\n## Traceability Matrix Template\n\n```markdown\n# Requirements Traceability Matrix\n\n| REQ ID | Intent | Design | Tasks | Code | Tests | UAT | Runtime | Status |\n|--------|--------|--------|-------|------|-------|-----|---------|--------|\n| REQ-F-AUTH-001 | INT-042 | âœ… | âœ… | âœ… | âœ… | âœ… | âœ… | Complete |\n| REQ-F-AUTH-002 | INT-042 | âœ… | âœ… | âœ… | âŒ | âŒ | âŒ | Partial |\n| REQ-F-PORTAL-001 | INT-042 | âœ… | â³ | âŒ | âŒ | âŒ | âŒ | In Design |\n\n## Legend\n- âœ… Complete\n- â³ In Progress\n- âŒ Not Started/Missing\n\n## Coverage Summary\n\n| Stage | Coverage |\n|-------|----------|\n| Requirements | 43/43 (100%) |\n| Design | 43/43 (100%) |\n| Tasks | 25/43 (58%) |\n| Code | 15/43 (35%) |\n| Tests | 8/43 (19%) |\n| UAT | 0/43 (0%) |\n| Runtime | 0/43 (0%) |\n```\n\n---\n\n## Output Format\n\n```\n[TRACEABILITY VALIDATION - REQ-F-AUTH-001]\n\nChain Analysis:\n\nIntent:\n  âœ… INT-042: Customer self-service portal\n\nDesign:\n  âœ… docs/design/adrs/ADR-001-session-storage.md\n  âœ… docs/design/components/authentication-service.md\n  âœ… api/v1/auth.yaml\n\nTasks:\n  âœ… PORTAL-123: Implement login\n  âœ… PORTAL-124: Add validation\n\nCode:\n  âœ… src/auth/authentication.py (login function)\n  âœ… src/auth/validators.py (email validation)\n\nTests:\n  âœ… tests/auth/test_login.py (5 tests)\n  âœ… features/authentication.feature (3 scenarios)\n\nUAT:\n  âœ… UAT-001: Business sign-off (Approved)\n\nRuntime:\n  âœ… login_attempts{requirement=\"REQ-F-AUTH-001\"}\n  âœ… login_latency_ms{requirement=\"REQ-F-AUTH-001\"}\n\nChain Status: COMPLETE\n  All stages linked with REQ-F-AUTH-001\n\nTraceability: Intent â†’ Runtime verified\n```\n\n---\n\n## CLI Commands\n\n```bash\n# Check coverage at all stages\naisdlc traceability check-coverage\n\n# Validate specific requirement chain\naisdlc traceability validate REQ-F-AUTH-001\n\n# Find gaps in traceability\naisdlc traceability find-gaps\n\n# Generate traceability matrix\naisdlc traceability matrix\n\n# Propagate keys from requirements to code\naisdlc traceability propagate --from requirements --to code\n```\n\n---\n\n## Configuration\n\n```yaml\n# .claude/plugins.yml\nplugins:\n  - name: \"@aisdlc/aisdlc-methodology\"\n    config:\n      traceability:\n        require_intent_link: true\n        require_design_artifacts: true\n        require_task_tickets: false  # Optional for small projects\n        require_tests: true\n        require_uat_signoff: true\n        require_runtime_telemetry: true\n        block_deploy_if_incomplete: true\n        auto_generate_matrix: true\n```\n\n---\n\n## Homeostasis Behavior\n\n**If traceability gap detected**:\n- Detect: REQ-* missing in downstream stage\n- Signal: \"Traceability incomplete\"\n- Action: List specific gaps\n- Block: Prevent deployment until fixed\n\n**If key propagation fails**:\n- Detect: REQ-* not found in code/tests\n- Signal: \"Key propagation incomplete\"\n- Action: Add missing REQ-* comments\n- Verify: Re-scan after fix\n\n---\n\n## Key Principles Applied\n\n- **Test Driven Development**: Tests must validate REQ-*\n- **Fail Fast**: Detect traceability gaps early\n- **Perfectionist Excellence**: Complete chain or nothing\n\n**\"Excellence or nothing\"**\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/bdd/bdd-workflow/SKILL.md": "---\nname: bdd-workflow\ndescription: Complete Behavior-Driven Development workflow coordinating SCENARIO â†’ STEP DEFINITIONS â†’ IMPLEMENT â†’ REFACTOR cycle with Given/When/Then scenarios. Use when writing BDD tests or implementing features from user stories.\nallowed-tools: [Read, Write, Edit, Bash, Grep, Glob]\n---\n\n# bdd-workflow\n\n**Skill Type**: Orchestrator (BDD Workflow)\n**Purpose**: Coordinate complete BDD cycle with Given/When/Then scenarios\n**Prerequisites**:\n- Work unit with REQ-* key (e.g., \"Create scenario for <REQ-ID>\")\n- Requirement details available\n\n---\n\n## Agent Instructions\n\nYou are orchestrating the complete **Behavior-Driven Development (BDD)** workflow.\n\nYour goal is to implement a requirement using **Given/When/Then scenarios** in pure business language while maintaining requirement traceability.\n\n---\n\n## Workflow\n\n### Phase 0: Prerequisites Check\n\n**Before starting BDD, verify**:\n1. âœ… Requirement key exists (REQ-F-*, REQ-NFR-*, REQ-DATA-*)\n2. âœ… Requirement details available (what to implement)\n3. âœ… Working directory is a git repository\n4. âœ… BDD framework available (Cucumber, Behave, etc.)\n\n**If prerequisites missing**:\n- No REQ-* key â†’ Invoke `requirement-extraction` skill\n- No requirement details â†’ Ask user for clarification\n- Not a git repo â†’ Ask user if they want to initialize git\n- No BDD framework â†’ Ask user which framework to install\n\n---\n\n### Phase 1: SCENARIO (Write Given/When/Then)\n\n**Invoke**: `write-scenario` skill\n\n**Purpose**: Write behavior scenarios in business language\n\n**What write-scenario does**:\n- Creates feature file (e.g., `features/authentication.feature`)\n- Writes scenarios in Gherkin format (Given/When/Then)\n- Tags scenarios with REQ-* key in comments\n- Uses pure business language (no technical jargon)\n- Commits: \"SCENARIO: Add scenarios for REQ-*\"\n\n**Success Criteria**: Scenarios written in business language\n\n---\n\n### Phase 2: STEP DEFINITIONS (Implement Test Code)\n\n**Invoke**: `implement-step-definitions` skill\n\n**Purpose**: Translate Given/When/Then into executable test code\n\n**What implement-step-definitions does**:\n- Creates step definition file (e.g., `steps/authentication_steps.py`)\n- Implements step definitions for each Given/When/Then\n- Tags steps with REQ-* key in comments\n- Runs scenarios â†’ expects FAILURE (implementation doesn't exist)\n- Commits: \"STEP DEF: Add step definitions for REQ-*\"\n\n**Success Criteria**: Step definitions exist, scenarios fail\n\n---\n\n### Phase 3: IMPLEMENT (Make Scenarios Pass)\n\n**Invoke**: `implement-feature` skill\n\n**Purpose**: Implement feature to make scenarios pass\n\n**What implement-feature does**:\n- Creates implementation file (e.g., `src/auth/authentication.py`)\n- Implements feature code to pass scenarios\n- Tags code with REQ-* key in comments\n- Runs scenarios â†’ expects SUCCESS (scenarios pass)\n- Commits: \"IMPLEMENT: Implement REQ-*\"\n\n**Success Criteria**: Scenarios PASS\n\n---\n\n### Phase 4: REFACTOR (Improve Quality + Eliminate Tech Debt)\n\n**Invoke**: `refactor-bdd` skill\n\n**Purpose**: Improve code quality and eliminate technical debt\n\n**What refactor-bdd does**:\n- Refactors feature implementation\n- Refactors step definitions\n- Eliminates tech debt (Principle #6)\n- Runs scenarios â†’ expects STILL PASSING\n- Commits: \"REFACTOR: Clean up REQ-*\"\n\n**Success Criteria**: Scenarios still PASS, tech debt = 0\n\n---\n\n## Output Format\n\nWhen you complete the BDD workflow, show:\n\n```\n[BDD Workflow: <REQ-ID>]\n\nâœ… Phase 0: Prerequisites\n  âœ“ Requirement: <REQ-ID> (User login)\n  âœ“ BDD Framework: behave (Python)\n  âœ“ Git repository: initialized\n  âœ“ Working tree: clean\n\nâœ… Phase 1: SCENARIO (Write Given/When/Then)\n  âœ“ Created: features/authentication.feature (3 scenarios)\n  âœ“ Business language âœ“ (no technical jargon)\n  âœ“ Commit: SCENARIO: Add scenarios for <REQ-ID>\n\nâœ… Phase 2: STEP DEFINITIONS (Implement Test Code)\n  âœ“ Created: steps/authentication_steps.py (12 step definitions)\n  âœ“ Scenarios running... FAILED âœ“ (expected - no implementation)\n  âœ“ Commit: STEP DEF: Add step definitions for <REQ-ID>\n\nâœ… Phase 3: IMPLEMENT (Make Scenarios Pass)\n  âœ“ Created: src/auth/authentication.py\n  âœ“ Implemented: login() function\n  âœ“ Scenarios running... PASSED âœ“\n  âœ“ Commit: IMPLEMENT: Implement <REQ-ID>\n\nâœ… Phase 4: REFACTOR (Improve Quality)\n  Code Quality Improvements:\n    âœ“ Added type hints\n    âœ“ Improved step definition reusability\n\n  Tech Debt Pruning:\n    âœ“ Deleted 1 unused import\n    âœ“ Simplified step definition logic\n\n  âœ“ Scenarios still PASSING âœ“\n  âœ“ Commit: REFACTOR: Clean up <REQ-ID>\n\nğŸ‰ BDD Workflow Complete!\n  Files: 3 files (authentication.feature, authentication_steps.py, authentication.py)\n  Scenarios: 3 scenarios, all passing\n  Step Definitions: 12 steps\n  Traceability: <REQ-ID> â†’ commit xyz789\n```\n\n---\n\n## Homeostasis Behavior\n\n**If prerequisites not met**:\n1. **Detect**: Missing REQ-* key\n2. **Signal**: \"Need requirement extraction first\"\n3. **Claude invokes**: `requirement-extraction` skill\n4. **Retry**: bdd-workflow with new REQ-*\n\n**If scenarios fail in IMPLEMENT phase**:\n1. **Detect**: Scenarios still failing after implementation\n2. **Signal**: \"Implementation incomplete\"\n3. **Claude**: Fix implementation and retry\n4. **Do NOT proceed to REFACTOR** until scenarios pass\n\n**If tech debt detected in REFACTOR phase**:\n1. **Detect**: Unused code, complexity > 10, etc.\n2. **Signal**: \"Tech debt detected\"\n3. **Claude invokes**: `prune-unused-code`, `simplify-complex-code`\n4. **Verify**: Tech debt eliminated before commit\n\n---\n\n## Prerequisites Check\n\nBefore invoking this skill, ensure:\n1. âœ… Requirement key (REQ-*) exists\n2. âœ… Requirement details available\n3. âœ… Git repository initialized\n4. âœ… BDD framework available (or can install)\n\nIf prerequisites not met:\n- Missing REQ-* â†’ Invoke `requirement-extraction` skill\n- No BDD framework â†’ Ask user which to install (Cucumber, Behave, etc.)\n\n---\n\n## Skills Used\n\nThis orchestrator skill invokes:\n1. `write-scenario` - Write Given/When/Then scenarios\n2. `implement-step-definitions` - Implement step definitions\n3. `implement-feature` - Implement feature code\n4. `refactor-bdd` - Refactor and eliminate tech debt\n5. `detect-unused-code` - (via refactor-bdd) Detect tech debt\n6. `prune-unused-code` - (via refactor-bdd) Eliminate tech debt\n\n---\n\n## Configuration\n\nThis skill respects configuration in `.claude/plugins.yml`:\n\n```yaml\nplugins:\n  - name: \"@aisdlc/code-skills\"\n    config:\n      bdd:\n        gherkin_style: \"cucumber\"     # cucumber | behave\n        require_scenarios_for_requirements: true\n        scenario_language: \"en\"       # Gherkin language\n        include_backgrounds: true     # Use Background sections\n```\n\n---\n\n## BDD vs TDD\n\n**When to use BDD**:\n- âœ… Requirements written as user stories\n- âœ… Stakeholders want readable tests\n- âœ… Integration/acceptance testing\n- âœ… Business validation focus\n\n**When to use TDD**:\n- âœ… Unit testing focus\n- âœ… Low-level implementation\n- âœ… Technical requirements\n- âœ… Developer-focused testing\n\n**Both can coexist**: Use BDD for acceptance tests, TDD for unit tests.\n\n---\n\n## Next Steps\n\nAfter BDD workflow completes:\n1. Review scenarios with stakeholders\n2. Run scenarios as part of CI/CD\n3. Move to next requirement (invoke `bdd-workflow` for next REQ-*)\n\n---\n\n## Notes\n\n**Why BDD workflow?**\n- Business language = stakeholders can read tests\n- Given/When/Then = clear specification of behavior\n- Scenarios = living documentation of requirements\n- Executable specs = tests ARE the specification\n\n**BDD complements TDD**:\n```\nBDD: High-level behavior (user perspective)\n  â†“ validates\nTDD: Low-level implementation (developer perspective)\n```\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  scenarios_in_business_language: true\n  scenarios_passing: true\n  tech_debt: 0\n  requirement_traceability: complete\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/bdd/implement-feature/SKILL.md": "---\nname: implement-feature\ndescription: Implement feature code to make BDD scenarios pass. Write production code that satisfies Given/When/Then scenarios. Use after implement-step-definitions when step definitions exist but scenarios are failing.\nallowed-tools: [Read, Write, Edit, Bash, Grep, Glob]\n---\n\n# implement-feature\n\n**Skill Type**: Actuator (BDD Workflow)\n**Purpose**: Implement feature code to make scenarios pass\n**Prerequisites**:\n- Feature file exists with Gherkin scenarios\n- Step definitions exist\n- Scenarios are FAILING (implementation missing)\n\n---\n\n## Agent Instructions\n\nYou are in the **IMPLEMENT** phase of BDD (SCENARIO â†’ STEP DEFINITIONS â†’ IMPLEMENT â†’ REFACTOR).\n\nYour goal is to **implement production code** that makes the scenarios pass.\n\n---\n\n## Workflow\n\n### Step 1: Review Scenarios and Step Definitions\n\n**Understand what needs to be implemented**:\n- What functionality is being tested?\n- What are the expected inputs and outputs?\n- What business rules must be enforced?\n\n**Example**:\n```gherkin\n# features/authentication.feature shows we need:\n\nScenario: Successful login\n  When I click the \"Login\" button\n  Then I should see \"Welcome back\"\n\n# Step definition shows:\n@when('I click the \"Login\" button')\ndef step_impl(context, button):\n    email = _ui_state['email_input']\n    password = _ui_state['password_input']\n    _login_result = login(email, password)  # Calls login() - doesn't exist yet\n\n# We need to implement: login(email, password) -> LoginResult\n```\n\n---\n\n### Step 2: Determine Implementation File Location\n\n**Follow project conventions**:\n\n**Python**:\n```\nfeatures/authentication.feature â†’ src/auth/authentication.py\nfeatures/payments/checkout.feature â†’ src/payments/checkout.py\n```\n\n**JavaScript/TypeScript**:\n```\nfeatures/authentication.feature â†’ src/auth/authentication.ts\nfeatures/payments/checkout.feature â†’ src/payments/checkout.ts\n```\n\n**Java**:\n```\nfeatures/authentication.feature â†’ src/main/java/auth/Authentication.java\n```\n\n---\n\n### Step 3: Implement Feature Code\n\n**Write production code that makes scenarios pass**:\n\n```python\n# src/auth/authentication.py\n\n# Implements: <REQ-ID>\n# Business Rules: BR-001, BR-002, BR-003\n\nimport re\nfrom dataclasses import dataclass\nfrom typing import Optional\nfrom datetime import datetime, timedelta\n\n@dataclass\nclass LoginResult:\n    \"\"\"Result of login attempt\"\"\"\n    success: bool\n    user: Optional['User'] = None\n    error: Optional[str] = None\n\nclass User:\n    \"\"\"User model\"\"\"\n    def __init__(self, email: str):\n        self.email = email\n        self.password_hash: Optional[str] = None\n        self.failed_attempts = 0\n        self.locked_until: Optional[datetime] = None\n\n    def set_password(self, password: str) -> None:\n        \"\"\"Set user password (hashed)\"\"\"\n        self.password_hash = self._hash_password(password)\n\n    def check_password(self, password: str) -> bool:\n        \"\"\"Check if password matches\"\"\"\n        return self.password_hash == self._hash_password(password)\n\n    @staticmethod\n    def _hash_password(password: str) -> str:\n        \"\"\"Hash password (simplified for demo)\"\"\"\n        # In production: use bcrypt\n        return str(hash(password))\n\n\n# Implements: <REQ-ID>\ndef login(email: str, password: str) -> LoginResult:\n    \"\"\"\n    Authenticate user with email and password.\n\n    Implements: <REQ-ID> (User login)\n\n    Business Rules:\n    - BR-001: Email must be valid format\n    - BR-002: Password minimum 12 characters\n    - BR-003: Account locks after 3 failed attempts (15min)\n\n    Args:\n        email: User email address\n        password: User password\n\n    Returns:\n        LoginResult with success status, user object, or error message\n    \"\"\"\n    # Implements: BR-001 (email validation)\n    if not _validate_email(email):\n        return LoginResult(success=False, error=\"Invalid email format\")\n\n    # Implements: BR-002 (password minimum length)\n    if len(password) < 12:\n        return LoginResult(success=False, error=\"Password must be at least 12 characters\")\n\n    # Get user from database\n    user = _get_user_by_email(email)\n    if not user:\n        return LoginResult(success=False, error=\"User not found\")\n\n    # Implements: BR-003 (check if account locked)\n    if user.locked_until and datetime.now() < user.locked_until:\n        remaining = (user.locked_until - datetime.now()).seconds // 60\n        return LoginResult(\n            success=False,\n            error=f\"Account locked. Try again in {remaining} minutes\"\n        )\n\n    # Check password\n    if not user.check_password(password):\n        user.failed_attempts += 1\n\n        # Implements: BR-003 (lock after 3 failed attempts)\n        if user.failed_attempts >= 3:\n            user.locked_until = datetime.now() + timedelta(minutes=15)\n            return LoginResult(\n                success=False,\n                error=\"Account locked. Try again in 15 minutes\"\n            )\n\n        return LoginResult(success=False, error=\"Invalid password\")\n\n    # Success - reset failed attempts\n    user.failed_attempts = 0\n    user.locked_until = None\n\n    return LoginResult(success=True, user=user)\n\n\ndef _validate_email(email: str) -> bool:\n    \"\"\"Validate email format (BR-001)\"\"\"\n    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n    return re.match(pattern, email) is not None\n\n\ndef _get_user_by_email(email: str) -> Optional[User]:\n    \"\"\"Get user from database (simplified for testing)\"\"\"\n    # In production: query database\n    # For testing: use in-memory store or mock\n    return _test_user_store.get(email)\n\n\n# Test user storage (for BDD testing)\n_test_user_store = {}\n\ndef create_test_user(email: str, password: str = \"DefaultPass123!\") -> User:\n    \"\"\"Create a test user (helper for step definitions)\"\"\"\n    user = User(email=email)\n    user.set_password(password)\n    _test_user_store[email] = user\n    return user\n```\n\n**Key implementation principles**:\n- âœ… Tag code with REQ-* and BR-* keys\n- âœ… Implement exactly what scenarios require (no more)\n- âœ… Use clear, descriptive names\n- âœ… Add docstrings explaining business rules\n- âœ… Keep functions focused (single responsibility)\n\n---\n\n### Step 4: Run Scenarios (Expect SUCCESS)\n\n**Run BDD framework**:\n\n```bash\n# Behave (Python)\nbehave features/authentication.feature -v\n\n# Cucumber (JavaScript)\nnpm run cucumber\n\n# Cucumber (Java)\nmvn test -Dcucumber.options=\"features/authentication.feature\"\n```\n\n**Expected output**:\n```\nFeature: User Login\n\n  Background:\n    Given the application is running           PASSED\n    And I am on the login page                PASSED\n\n  Scenario: Successful login with valid credentials\n    Given I am a registered user              PASSED\n    And my password is \"SecurePassword123!\"   PASSED\n    When I enter email \"user@example.com\"     PASSED\n    And I enter password \"SecurePassword123!\" PASSED\n    And I click the \"Login\" button            PASSED\n    Then I should see \"Welcome back\"          PASSED\n    And I should be redirected to dashboard   PASSED\n\n  Scenario: Login fails with invalid email\n    When I enter email \"invalid-email\"        PASSED\n    And I enter password \"SecurePassword123!\" PASSED\n    And I click the \"Login\" button            PASSED\n    Then I should see \"Invalid email format\"  PASSED\n\n5 scenarios (5 passed)\n27 steps (27 passed)\n```\n\n**âœ… All scenarios PASSING!** This is what we want in IMPLEMENT phase.\n\n---\n\n### Step 5: Commit Implementation\n\n**Create commit**:\n\n```bash\ngit add src/auth/authentication.py\ngit commit -m \"IMPLEMENT: Implement <REQ-ID>\n\nImplement user login functionality to satisfy BDD scenarios.\n\nImplements:\n- <REQ-ID>: User login\n- BR-001: Email validation\n- BR-002: Password minimum 12 characters\n- BR-003: Account lockout after 3 failed attempts\n\nImplementation:\n- Created LoginResult dataclass\n- Implemented login() function\n- Added email validation helper\n- Added user model with password hashing\n- Added test user helpers for BDD testing\n\nScenarios: 5 scenarios passing âœ“\nSteps: 27 steps passing âœ“\n\"\n```\n\n---\n\n## Output Format\n\nWhen you complete the IMPLEMENT phase, show:\n\n```\n[IMPLEMENT Phase - <REQ-ID>]\n\nImplementation: src/auth/authentication.py\n\nCode Created:\n  âœ“ LoginResult dataclass\n  âœ“ User class with password handling\n  âœ“ login() function (<REQ-ID>)\n  âœ“ _validate_email() helper (BR-001)\n  âœ“ _get_user_by_email() helper\n  âœ“ create_test_user() helper (for BDD)\n\nBusiness Rules Implemented:\n  âœ“ BR-001: Email validation (regex)\n  âœ“ BR-002: Password minimum 12 characters\n  âœ“ BR-003: Account lockout after 3 attempts\n\nRunning scenarios...\n  Scenario: Successful login              PASSED âœ“\n  Scenario: Login fails invalid email     PASSED âœ“\n  Scenario: Login fails short password    PASSED âœ“\n  Scenario: Account locks after 3 fails   PASSED âœ“\n  Scenario: Login after lockout expires   PASSED âœ“\n\nResult: 5/5 scenarios PASSING âœ“ (IMPLEMENT phase)\n\nCommit: IMPLEMENT: Implement <REQ-ID>\n\nâœ… IMPLEMENT Phase Complete!\n   Next: Invoke refactor-bdd skill to improve code quality\n```\n\n---\n\n## Prerequisites Check\n\nBefore invoking this skill, ensure:\n1. Feature file exists (from write-scenario)\n2. Step definitions exist (from implement-step-definitions)\n3. Scenarios are FAILING (implementation missing)\n\nIf prerequisites not met:\n- No feature file â†’ Invoke `write-scenario` skill first\n- No step definitions â†’ Invoke `implement-step-definitions` skill first\n- Scenarios already passing â†’ Already implemented, skip to refactor-bdd\n\n---\n\n## Next Steps\n\nAfter IMPLEMENT phase completes:\n1. **Do NOT refactor yet** (scenarios must pass first)\n2. Invoke `refactor-bdd` skill to improve code quality and eliminate tech debt\n3. Scenarios should STILL PASS after refactoring\n\n---\n\n## Implementation Strategies\n\n### Strategy 1: Scenario-by-Scenario\n\nImplement code to pass **one scenario at a time**:\n1. Make \"Successful login\" scenario pass\n2. Make \"Login fails with invalid email\" scenario pass\n3. Make \"Login fails with short password\" scenario pass\n4. Make \"Account locks after 3 failed attempts\" scenario pass\n\n### Strategy 2: Step-by-Step\n\nImplement helpers for **each step type**:\n1. Implement Given steps (setup, fixtures)\n2. Implement When steps (actions)\n3. Implement Then steps (assertions)\n\n### Strategy 3: Business Rule by Business Rule\n\nImplement **one business rule at a time**:\n1. Implement BR-001 (email validation)\n2. Implement BR-002 (password minimum length)\n3. Implement BR-003 (account lockout)\n\n---\n\n## Common Pitfalls to Avoid\n\nâŒ **Implementing more than scenarios require**: Only implement what's tested\nâŒ **Technical coupling**: Don't tightly couple to step definitions\nâŒ **Skipping business rules**: Every BR-* must be implemented\nâŒ **Not running scenarios**: Must verify scenarios pass\n\nâœ… **Do this instead**:\n- Implement exactly what scenarios require\n- Keep production code separate from test code\n- Verify all scenarios pass\n- Tag code with REQ-* and BR-* keys\n\n---\n\n## Notes\n\n**Why implement after step definitions?**\n- Step definitions = executable specification\n- Clear contract between tests and implementation\n- Easier to implement when you know exactly what's needed\n\n**BDD implementation mantra**: \"Make scenarios green\"\n- Scenarios define behavior\n- Implementation satisfies behavior\n- Refactoring improves quality\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  scenarios_passing: true\n  all_business_rules_implemented: true\n  production_code_clean: true\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/bdd/implement-step-definitions/SKILL.md": "---\nname: implement-step-definitions\ndescription: Implement step definitions for Gherkin scenarios, translating Given/When/Then into executable test code. Use after write-scenario when scenarios are defined but step definitions are missing.\nallowed-tools: [Read, Write, Edit, Bash, Grep, Glob]\n---\n\n# implement-step-definitions\n\n**Skill Type**: Actuator (BDD Workflow)\n**Purpose**: Translate Given/When/Then scenarios into executable test code\n**Prerequisites**:\n- Feature file exists with Gherkin scenarios\n- BDD framework available (Cucumber, Behave, etc.)\n\n---\n\n## Agent Instructions\n\nYou are in the **STEP DEFINITIONS** phase of BDD (SCENARIO â†’ STEP DEFINITIONS â†’ IMPLEMENT â†’ REFACTOR).\n\nYour goal is to translate **Given/When/Then steps** into **executable test code** (step definitions).\n\n---\n\n## Workflow\n\n### Step 1: Read Feature File\n\n**Parse the Gherkin scenarios**:\n- What Given/When/Then steps exist?\n- Which steps are reusable across scenarios?\n- What test fixtures are needed?\n\n**Example**:\n```gherkin\n# features/authentication.feature\n\nScenario: Successful login\n  Given I am a registered user with email \"user@example.com\"\n  And my password is \"SecurePassword123!\"\n  When I enter email \"user@example.com\"\n  And I enter password \"SecurePassword123!\"\n  And I click the \"Login\" button\n  Then I should see \"Welcome back\"\n\n# Unique steps needed:\n# - Given I am a registered user with email {email}\n# - And my password is {password}\n# - When I enter email {email}\n# - And I enter password {password}\n# - And I click the {button} button\n# - Then I should see {message}\n```\n\n---\n\n### Step 2: Determine Step Definition File Location\n\n**Follow BDD framework conventions**:\n\n**Cucumber (JavaScript/TypeScript)**:\n```\nfeatures/step_definitions/authentication_steps.js\nfeatures/step_definitions/authentication_steps.ts\n```\n\n**Behave (Python)**:\n```\nfeatures/steps/authentication_steps.py\n```\n\n**Cucumber (Java)**:\n```\nsrc/test/java/steps/AuthenticationSteps.java\n```\n\n---\n\n### Step 3: Write Step Definitions\n\n**Template for Python (Behave)**:\n\n```python\n# features/steps/authentication_steps.py\n\n# Validates: <REQ-ID>\n# Business Rules: BR-001, BR-002, BR-003\n\nfrom behave import given, when, then\nfrom src.auth.authentication import login\nfrom test_helpers import create_test_user, get_ui_element\n\n# Test fixtures\n_test_users = {}\n_login_result = None\n_ui_state = {}\n\n\n@given('I am a registered user with email \"{email}\"')\ndef step_impl(context, email):\n    \"\"\"Create a test user with specified email\"\"\"\n    # Validates: <REQ-ID>\n    user = create_test_user(email=email)\n    _test_users[email] = user\n    context.user = user\n\n\n@given('my password is \"{password}\"')\ndef step_impl(context, password):\n    \"\"\"Set user's password\"\"\"\n    context.user.set_password(password)\n\n\n@when('I enter email \"{email}\"')\ndef step_impl(context, email):\n    \"\"\"User enters email in login form\"\"\"\n    _ui_state['email_input'] = email\n\n\n@when('I enter password \"{password}\"')\ndef step_impl(context, password):\n    \"\"\"User enters password in login form\"\"\"\n    _ui_state['password_input'] = password\n\n\n@when('I click the \"{button}\" button')\ndef step_impl(context, button):\n    \"\"\"User clicks a button\"\"\"\n    if button == \"Login\":\n        # Perform login action\n        global _login_result\n        email = _ui_state.get('email_input')\n        password = _ui_state.get('password_input')\n        _login_result = login(email, password)\n\n\n@then('I should see \"{message}\"')\ndef step_impl(context, message):\n    \"\"\"Verify user sees expected message\"\"\"\n    # This would check UI in real implementation\n    # For now, check login result\n    if message == \"Welcome back\":\n        assert _login_result.success == True\n    else:\n        assert _login_result.error == message\n\n\n@then('I should be redirected to the dashboard')\ndef step_impl(context):\n    \"\"\"Verify user is redirected\"\"\"\n    assert _login_result.success == True\n    # In real implementation, check URL or page content\n```\n\n**Key elements**:\n- âœ… Tag with REQ-* key in comments\n- âœ… One step definition per unique step\n- âœ… Parameterized step definitions (use `{parameter}`)\n- âœ… Reusable across scenarios\n- âœ… Clear docstrings explaining step purpose\n\n---\n\n**Template for JavaScript (Cucumber)**:\n\n```javascript\n// features/step_definitions/authentication_steps.js\n\n// Validates: <REQ-ID>\n// Business Rules: BR-001, BR-002, BR-003\n\nconst { Given, When, Then } = require('@cucumber/cucumber');\nconst { login } = require('../../src/auth/authentication');\nconst assert = require('assert');\n\nlet testUser;\nlet loginResult;\nlet uiState = {};\n\nGiven('I am a registered user with email {string}', function(email) {\n  // Validates: <REQ-ID>\n  testUser = createTestUser(email);\n});\n\nGiven('my password is {string}', function(password) {\n  testUser.setPassword(password);\n});\n\nWhen('I enter email {string}', function(email) {\n  uiState.email = email;\n});\n\nWhen('I enter password {string}', function(password) {\n  uiState.password = password;\n});\n\nWhen('I click the {string} button', function(button) {\n  if (button === 'Login') {\n    loginResult = login(uiState.email, uiState.password);\n  }\n});\n\nThen('I should see {string}', function(message) {\n  if (message === 'Welcome back') {\n    assert.strictEqual(loginResult.success, true);\n  } else {\n    assert.strictEqual(loginResult.error, message);\n  }\n});\n```\n\n---\n\n### Step 4: Run Scenarios (Expect FAILURE)\n\n**Run BDD framework**:\n\n```bash\n# Behave (Python)\nbehave features/authentication.feature\n\n# Cucumber (JavaScript)\nnpm run cucumber\n\n# Cucumber (Java)\nmvn test -Dcucumber.options=\"features/authentication.feature\"\n```\n\n**Expected output**:\n```\nFeature: User Login\n\n  Background:\n    Given the application is running           PASSED\n    And I am on the login page                PASSED\n\n  Scenario: Successful login\n    Given I am a registered user              PASSED\n    And my password is \"SecurePassword123!\"   PASSED\n    When I enter email \"user@example.com\"     PASSED\n    And I enter password \"SecurePassword123!\" PASSED\n    And I click the \"Login\" button            FAILED\n      AttributeError: 'NoneType' object has no attribute 'success'\n      (login function doesn't exist yet)\n```\n\n**âœ… This is GOOD!** Steps execute but implementation doesn't exist yet.\n\n---\n\n### Step 5: Commit Step Definitions\n\n**Create commit**:\n\n```bash\ngit add features/steps/authentication_steps.py\ngit commit -m \"STEP DEF: Add step definitions for <REQ-ID>\n\nImplement step definitions for user login scenarios.\n\nStep definitions:\n- Given steps: Set up test users and state\n- When steps: Simulate user actions\n- Then steps: Verify expected outcomes\n\nSteps: 12 step definitions (scenarios fail - no implementation yet)\n\nValidates: <REQ-ID>\n\"\n```\n\n---\n\n## Output Format\n\nWhen you complete the STEP DEFINITIONS phase, show:\n\n```\n[STEP DEFINITIONS Phase - <REQ-ID>]\n\nFeature File: features/authentication.feature\n\nStep Definitions Created:\n  Given steps (4):\n    âœ“ I am a registered user with email {email}\n    âœ“ my password is {password}\n    âœ“ the application is running\n    âœ“ I am on the login page\n\n  When steps (5):\n    âœ“ I enter email {email}\n    âœ“ I enter password {password}\n    âœ“ I click the {button} button\n    âœ“ I attempt to login with email {email} and password {password}\n\n  Then steps (3):\n    âœ“ I should see {message}\n    âœ“ I should be redirected to the dashboard\n    âœ“ my account should be locked\n\nStep Definition File: features/steps/authentication_steps.py (12 steps, 142 lines)\n\nRunning scenarios...\n  Scenario: Successful login              FAILED (no implementation)\n  Scenario: Login fails invalid email     FAILED (no implementation)\n  Scenario: Login fails short password    FAILED (no implementation)\n  Scenario: Account locks after 3 fails   FAILED (no implementation)\n\nResult: 5 scenarios FAILED âœ“ (expected - implementation missing)\n\nCommit: STEP DEF: Add step definitions for <REQ-ID>\n\nâœ… STEP DEFINITIONS Phase Complete!\n   Next: Invoke implement-feature skill to implement functionality\n```\n\n---\n\n## Prerequisites Check\n\nBefore invoking this skill, ensure:\n1. Feature file exists (from write-scenario)\n2. BDD framework available\n3. Step definitions directory exists\n\nIf prerequisites not met:\n- No feature file â†’ Invoke `write-scenario` skill first\n- No BDD framework â†’ Ask user which to install\n\n---\n\n## Next Steps\n\nAfter STEP DEFINITIONS phase completes:\n1. **Do NOT implement feature yet** (that's next phase)\n2. Invoke `implement-feature` skill to implement functionality\n3. Scenarios should PASS after implementation\n\n---\n\n## Step Definition Patterns\n\n### Parameterized Steps\n\n**âœ… Good** (reusable):\n```python\n@given('I am a user with email \"{email}\"')\ndef step_impl(context, email):\n    context.user = create_user(email)\n```\n\n**âŒ Bad** (hard-coded):\n```python\n@given('I am a user with email user@example.com')\ndef step_impl(context):\n    context.user = create_user('user@example.com')\n```\n\n### Shared Context\n\n**Use `context` object** to share state between steps:\n```python\n@given('I am logged in')\ndef step_impl(context):\n    context.user = login()\n\n@when('I view my profile')\ndef step_impl(context):\n    context.profile = get_profile(context.user)  # Uses user from Given\n\n@then('I should see my email')\ndef step_impl(context):\n    assert context.profile.email == context.user.email\n```\n\n### Test Helpers\n\n**Extract common logic** to helpers:\n```python\n# test_helpers.py\n\ndef create_test_user(email, password=\"DefaultPass123!\"):\n    \"\"\"Create a user for testing\"\"\"\n    user = User(email=email)\n    user.set_password(password)\n    user.save()\n    return user\n\ndef cleanup_test_users():\n    \"\"\"Delete all test users\"\"\"\n    User.delete_where(email__startswith=\"test_\")\n```\n\n---\n\n## Notes\n\n**Why step definitions separate from implementation?**\n- Step definitions = test automation code\n- Implementation = production code\n- Separation of concerns (test vs production)\n- Step definitions can test multiple implementations\n\n**Step definition reusability**:\n- Same step definitions can test multiple features\n- Parameterized steps increase reusability\n- Keep step definitions simple and focused\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  all_steps_defined: true\n  steps_reusable: true\n  scenarios_executable: true\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/bdd/refactor-bdd/SKILL.md": "---\nname: refactor-bdd\ndescription: Refactor BDD implementation (scenarios, step definitions, feature code) to improve quality and eliminate tech debt while keeping scenarios passing. Use after implement-feature when scenarios are green.\nallowed-tools: [Read, Write, Edit, Bash, Grep, Glob]\n---\n\n# refactor-bdd\n\n**Skill Type**: Actuator (BDD Workflow)\n**Purpose**: Refactor BDD implementation and eliminate tech debt (Principle #6)\n**Prerequisites**:\n- Scenarios are PASSING\n- Step definitions exist\n- Feature implementation exists\n\n---\n\n## Agent Instructions\n\nYou are in the **REFACTOR** phase of BDD (SCENARIO â†’ STEP DEFINITIONS â†’ IMPLEMENT â†’ REFACTOR).\n\nYour goal is to improve code quality **and eliminate technical debt** in:\n1. Feature implementation (production code)\n2. Step definitions (test code)\n3. Scenarios (Gherkin files)\n\n**Critical**: Scenarios must STILL PASS after refactoring.\n\n---\n\n## Workflow\n\n### Step 1: Refactor Feature Implementation\n\n**Apply same tech debt elimination as TDD refactor-phase**:\n\n1. **Delete Unused Imports** (same as TDD)\n2. **Remove Dead Code** (same as TDD)\n3. **Delete Commented Code** (same as TDD)\n4. **Simplify Complex Logic** (same as TDD)\n5. **Remove Duplication** (same as TDD)\n\n**See**: `refactor-phase` skill (TDD) for detailed pruning instructions.\n\n---\n\n### Step 2: Refactor Step Definitions\n\n**Improve step definition quality**:\n\n#### 2.1 Extract Reusable Steps\n\n**Before** (duplication):\n```python\n@given('I am a registered user with email \"user1@example.com\"')\ndef step_impl(context):\n    context.user = create_user(\"user1@example.com\")\n\n@given('I am a registered user with email \"user2@example.com\"')\ndef step_impl(context):\n    context.user = create_user(\"user2@example.com\")\n```\n\n**After** (parameterized):\n```python\n@given('I am a registered user with email \"{email}\"')\ndef step_impl(context, email):\n    context.user = create_user(email)\n```\n\n#### 2.2 Extract Test Helpers\n\n**Before** (logic in step definitions):\n```python\n@given('I am a logged in user')\ndef step_impl(context):\n    user = User(email=\"test@example.com\")\n    user.set_password(\"TestPass123!\")\n    user.save()\n    token = authenticate(user.email, \"TestPass123!\")\n    context.user = user\n    context.token = token\n```\n\n**After** (extracted to helper):\n```python\n# test_helpers.py\ndef create_logged_in_user(email=\"test@example.com\"):\n    user = create_test_user(email)\n    token = authenticate(user.email, user.password)\n    return user, token\n\n# Step definition\n@given('I am a logged in user')\ndef step_impl(context):\n    context.user, context.token = create_logged_in_user()\n```\n\n#### 2.3 Simplify Step Logic\n\n**Before** (complex step):\n```python\n@when('I submit the login form')\ndef step_impl(context):\n    email = context.email_input if hasattr(context, 'email_input') else None\n    password = context.password_input if hasattr(context, 'password_input') else None\n    if email is None or password is None:\n        raise ValueError(\"Email and password must be set first\")\n    try:\n        result = login(email, password)\n        context.login_result = result\n    except Exception as e:\n        context.login_error = str(e)\n```\n\n**After** (simplified):\n```python\n@when('I submit the login form')\ndef step_impl(context):\n    context.login_result = login(\n        context.email_input,\n        context.password_input\n    )\n```\n\n#### 2.4 Delete Unused Steps\n\n**Scan for step definitions with zero usage**:\n```python\n# This step is defined but never used in any scenario\n@given('I have a premium account')\ndef step_impl(context):\n    context.user.upgrade_to_premium()\n# USAGE: 0 scenarios â†’ DELETE\n```\n\n---\n\n### Step 3: Refactor Scenarios (Gherkin)\n\n**Improve scenario quality**:\n\n#### 3.1 Extract Duplicate Preconditions to Background\n\n**Before** (duplication):\n```gherkin\nScenario: Login succeeds\n  Given I am on the login page\n  And the application is running\n  When I enter valid credentials\n  Then I should see \"Welcome\"\n\nScenario: Login fails\n  Given I am on the login page\n  And the application is running\n  When I enter invalid credentials\n  Then I should see \"Error\"\n```\n\n**After** (Background):\n```gherkin\nBackground:\n  Given the application is running\n  And I am on the login page\n\nScenario: Login succeeds\n  When I enter valid credentials\n  Then I should see \"Welcome\"\n\nScenario: Login fails\n  When I enter invalid credentials\n  Then I should see \"Error\"\n```\n\n#### 3.2 Improve Scenario Names\n\n**Before** (vague):\n```gherkin\nScenario: Test login\nScenario: Error case\n```\n\n**After** (descriptive):\n```gherkin\nScenario: Successful login with valid credentials\nScenario: Login fails with invalid email format\n```\n\n#### 3.3 Remove Unused Scenarios\n\n**Delete scenarios that**:\n- Test features no longer in scope\n- Are duplicates of other scenarios\n- Test implementation details (not behavior)\n\n---\n\n### Step 4: Run Scenarios (Verify Still Passing)\n\n**After EVERY refactoring change**:\n\n```bash\nbehave features/authentication.feature -v\n```\n\n**Expected**: All scenarios STILL PASSING âœ“\n\n**If scenarios fail**: Undo refactoring and try different approach.\n\n---\n\n### Step 5: Before Committing Checklist\n\nYou **MUST** verify:\n- âœ… All scenarios passing\n- âœ… No unused imports (feature code + step definitions)\n- âœ… No dead code (no unused step definitions)\n- âœ… No commented-out code\n- âœ… Max cyclomatic complexity â‰¤ 10\n- âœ… No duplicated steps\n- âœ… Scenarios use Background for common preconditions\n\n**If ANY checklist item fails, DO NOT COMMIT. Fix it first.**\n\n---\n\n### Step 6: Commit Refactoring\n\n**Create commit**:\n\n```bash\ngit add features/ src/auth/ steps/\ngit commit -m \"REFACTOR: Clean up <REQ-ID> (BDD)\n\nRefactor BDD implementation for user login.\n\nFeature Implementation:\n  - Deleted 2 unused imports\n  - Simplified login() complexity (8 â†’ 5)\n  - Added type hints to all functions\n\nStep Definitions:\n  - Extracted 3 steps to reusable helpers\n  - Removed 2 unused step definitions\n  - Simplified step logic\n\nScenarios:\n  - Extracted common preconditions to Background\n  - Improved scenario names for clarity\n  - Removed 1 duplicate scenario\n\nScenarios: 5 scenarios still passing âœ“\nTech Debt: 0 violations (Principle #6)\n\"\n```\n\n---\n\n## Output Format\n\nWhen you complete the REFACTOR phase, show:\n\n```\n[REFACTOR Phase - <REQ-ID> (BDD)]\n\nFeature Implementation Refactored:\n  âœ“ Deleted 2 unused imports\n  âœ“ Simplified login() - complexity 8 â†’ 5\n  âœ“ Added type hints to 4 functions\n  âœ“ Improved docstrings\n\nStep Definitions Refactored:\n  âœ“ Extracted 3 steps to test_helpers.py\n  âœ“ Removed 2 unused step definitions\n  âœ“ Simplified complex step logic\n  âœ“ Parameterized 2 hard-coded steps\n\nScenarios Refactored:\n  âœ“ Extracted Background (2 common steps)\n  âœ“ Improved 3 scenario names\n  âœ“ Removed 1 duplicate scenario\n  âœ“ Better organized scenario order\n\nTech Debt Pruning (Principle #6):\n  âœ“ Deleted 2 unused imports\n  âœ“ Removed 2 unused step definitions (18 lines)\n  âœ“ Simplified 1 complex function (complexity 8 â†’ 5)\n\nFile size changes:\n  - src/auth/authentication.py: 167 lines â†’ 142 lines (-15%)\n  - steps/authentication_steps.py: 98 lines â†’ 76 lines (-22%)\n  - features/authentication.feature: 89 lines â†’ 72 lines (-19%)\n\nRunning scenarios...\n  âœ“ All 5 scenarios still passing\n\nBefore Commit Checklist:\n  âœ“ All scenarios passing\n  âœ“ No unused imports\n  âœ“ No dead code (unused steps)\n  âœ“ No commented-out code\n  âœ“ Max complexity â‰¤ 10 (current: 5)\n  âœ“ Background used for common steps\n  âœ“ Scenarios well-named\n\nReady to commit!\n\nCommit: REFACTOR: Clean up <REQ-ID> (BDD)\n\nâœ… REFACTOR Phase Complete!\n```\n\n---\n\n## Prerequisites Check\n\nBefore invoking this skill, ensure:\n1. Scenarios are PASSING\n2. Step definitions exist\n3. Feature implementation exists\n\nIf prerequisites not met:\n- Scenarios failing â†’ Go back to IMPLEMENT phase\n- No step definitions â†’ Go back to STEP DEFINITIONS phase\n- No scenarios â†’ Go back to SCENARIO phase\n\n---\n\n## Next Steps\n\nAfter refactoring complete:\n1. Verify all scenarios still pass\n2. Create final commit (optional - or use REFACTOR commit as final)\n3. Move to next requirement (start new BDD workflow)\n\n---\n\n## Configuration\n\nThis skill respects configuration in `.claude/plugins.yml`:\n\n```yaml\nplugins:\n  - name: \"@aisdlc/code-skills\"\n    config:\n      bdd:\n        extract_background: true      # Auto-extract common steps\n        max_scenario_length: 10       # Max steps per scenario\n        require_scenario_tagging: true # Require REQ-* tags\n      tech_debt:\n        auto_detect_on_refactor: true\n        max_complexity: 10\n```\n\n---\n\n## BDD-Specific Refactoring\n\n### Scenario Organization\n\n**Group related scenarios** with Scenario Outline:\n\n**Before**:\n```gherkin\nScenario: Login with Visa card\n  Given I have a Visa card\n  When I pay\n  Then payment succeeds\n\nScenario: Login with Mastercard\n  Given I have a Mastercard\n  When I pay\n  Then payment succeeds\n```\n\n**After**:\n```gherkin\nScenario Outline: Login with supported cards\n  Given I have a <card_type> card\n  When I pay\n  Then payment succeeds\n\n  Examples:\n    | card_type  |\n    | Visa       |\n    | Mastercard |\n```\n\n### Step Definition Organization\n\n**Group by feature** in separate files:\n```\nsteps/\nâ”œâ”€â”€ authentication_steps.py  # Login, logout, registration\nâ”œâ”€â”€ payment_steps.py         # Payment processing\nâ””â”€â”€ common_steps.py          # Shared steps (navigation, etc.)\n```\n\n---\n\n## Notes\n\n**Why refactor BDD?**\n- Step definitions accumulate over time (pruning needed)\n- Scenarios can become verbose (Background helps)\n- Production code needs same quality as TDD code\n- Principle #6 applies to ALL code (test code too)\n\n**What makes BDD different from TDD refactoring**:\n- Refactor 3 layers: scenarios, steps, implementation\n- Scenarios should stay business-focused\n- Step definitions should be reusable\n- Feature code follows same rules as TDD\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  scenarios_passing: true\n  tech_debt: 0  # In all 3 layers\n  step_definitions_reusable: true\n  scenarios_concise: true\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/bdd/write-scenario/SKILL.md": "---\nname: write-scenario\ndescription: Write BDD scenarios in Gherkin format (Given/When/Then) in pure business language. Use when creating acceptance tests, user story scenarios, or stakeholder-readable specifications.\nallowed-tools: [Read, Write, Edit, Grep, Glob]\n---\n\n# write-scenario\n\n**Skill Type**: Actuator (BDD Workflow)\n**Purpose**: Write behavior scenarios in Gherkin format (Given/When/Then)\n**Prerequisites**:\n- Requirement key (REQ-*) with details\n- Understanding of user behavior to test\n\n---\n\n## Agent Instructions\n\nYou are in the **SCENARIO** phase of BDD (SCENARIO â†’ STEP DEFINITIONS â†’ IMPLEMENT â†’ REFACTOR).\n\nYour goal is to write scenarios in **pure business language** using **Given/When/Then** format.\n\n**Critical**: Use **NO technical jargon**. Business stakeholders should understand every word.\n\n---\n\n## Workflow\n\n### Step 1: Understand the Requirement\n\n**Parse the requirement**:\n- What user behavior needs to be validated?\n- What are the business rules (BR-*)?\n- What are the acceptance criteria?\n- Who is the user (persona)?\n\n**Example**:\n```yaml\n<REQ-ID>: User login with email and password\n\nBusiness Rules:\n- BR-001: Email must be valid format\n- BR-002: Password minimum 12 characters\n- BR-003: Max 3 login attempts, 15min lockout\n\nAcceptance Criteria:\n- User can log in with valid credentials\n- User sees error with invalid email\n- User account locks after 3 failed attempts\n```\n\n---\n\n### Step 2: Identify Scenarios\n\n**Create scenarios for**:\n1. **Happy path** - User achieves goal successfully\n2. **Business rules** - Each BR-* gets at least 1 scenario\n3. **Error cases** - User makes mistakes, sees helpful errors\n4. **Edge cases** - Boundary conditions\n\n**Example scenarios for <REQ-ID>**:\n```\nScenario 1: Successful login (happy path)\nScenario 2: Login fails with invalid email (BR-001)\nScenario 3: Login fails with short password (BR-002)\nScenario 4: Account locks after 3 failed attempts (BR-003)\nScenario 5: User can login after lockout expires\n```\n\n---\n\n### Step 3: Determine Feature File Location\n\n**Follow BDD framework conventions**:\n\n**Cucumber (JavaScript/TypeScript/Java)**:\n```\nfeatures/authentication.feature\nfeatures/payments/credit-card.feature\nfeatures/admin/user-management.feature\n```\n\n**Behave (Python)**:\n```\nfeatures/authentication.feature\nfeatures/payments/credit_card.feature\nfeatures/admin/user_management.feature\n```\n\n**If unsure**: Use `features/<domain>/<feature-name>.feature`\n\n---\n\n### Step 4: Write Feature File in Gherkin\n\n**Template**:\n\n```gherkin\n# features/authentication.feature\n\n# Validates: <REQ-ID>\n# Business Rules: BR-001, BR-002, BR-003\n\nFeature: User Login\n  As a registered user\n  I want to log in with my email and password\n  So that I can access my account\n\n  Background:\n    Given the application is running\n    And I am on the login page\n\n  Scenario: Successful login with valid credentials\n    # Validates: <REQ-ID> (happy path)\n    Given I am a registered user with email \"user@example.com\"\n    And my password is \"SecurePassword123!\"\n    When I enter email \"user@example.com\"\n    And I enter password \"SecurePassword123!\"\n    And I click the \"Login\" button\n    Then I should see \"Welcome back\"\n    And I should be redirected to the dashboard\n\n  Scenario: Login fails with invalid email format\n    # Validates: BR-001 (email validation)\n    Given I am on the login page\n    When I enter email \"invalid-email\"\n    And I enter password \"SecurePassword123!\"\n    And I click the \"Login\" button\n    Then I should see \"Invalid email format\"\n    And I should remain on the login page\n\n  Scenario: Login fails with password too short\n    # Validates: BR-002 (password minimum length)\n    Given I am on the login page\n    When I enter email \"user@example.com\"\n    And I enter password \"short\"\n    And I click the \"Login\" button\n    Then I should see \"Password must be at least 12 characters\"\n    And I should remain on the login page\n\n  Scenario: Account locks after three failed login attempts\n    # Validates: BR-003 (account lockout)\n    Given I am a registered user with email \"user@example.com\"\n    And my password is \"CorrectPassword123!\"\n    When I attempt to login with email \"user@example.com\" and password \"WrongPassword1!\"\n    And I attempt to login with email \"user@example.com\" and password \"WrongPassword2!\"\n    And I attempt to login with email \"user@example.com\" and password \"WrongPassword3!\"\n    Then my account should be locked\n    When I attempt to login with email \"user@example.com\" and password \"CorrectPassword123!\"\n    Then I should see \"Account locked. Try again in 15 minutes\"\n\n  Scenario: User can login after lockout expires\n    # Validates: BR-003 (lockout expiry)\n    Given I am a registered user with email \"user@example.com\"\n    And my account was locked 16 minutes ago\n    When I enter email \"user@example.com\"\n    And I enter password \"CorrectPassword123!\"\n    And I click the \"Login\" button\n    Then I should see \"Welcome back\"\n    And my account should be unlocked\n```\n\n**Key elements**:\n- âœ… Comment at top: `# Validates: <REQ-ID>`\n- âœ… Feature description with user story (As a... I want... So that...)\n- âœ… Background section (common preconditions)\n- âœ… Each scenario tagged with what it validates\n- âœ… Pure business language (no code terms)\n- âœ… Clear, descriptive scenario names\n\n---\n\n### Step 5: Validate Business Language\n\n**Check each scenario**:\n\n**âŒ Technical Language (Avoid)**:\n```gherkin\nWhen I POST to \"/api/auth/login\" endpoint\nThen HTTP status code should be 200\nAnd JWT token should be in response header\n```\n\n**âœ… Business Language (Use)**:\n```gherkin\nWhen I enter my credentials and submit\nThen I should see \"Welcome back\"\nAnd I should be logged into my account\n```\n\n**Rule**: If a stakeholder can't understand it, rewrite it.\n\n---\n\n### Step 6: Run Scenarios (Expect FAILURE)\n\n**Run BDD framework**:\n\n```bash\n# Cucumber (JavaScript)\nnpm run cucumber\n\n# Behave (Python)\nbehave features/authentication.feature\n\n# Cucumber (Java)\nmvn test -Dcucumber.options=\"features/authentication.feature\"\n```\n\n**Expected output**:\n```\nFeature: User Login\n\n  Scenario: Successful login with valid credentials    # UNDEFINED\n  Scenario: Login fails with invalid email format      # UNDEFINED\n  Scenario: Login fails with password too short        # UNDEFINED\n  Scenario: Account locks after three failed attempts  # UNDEFINED\n\n4 scenarios (4 undefined)\n\nYou can implement step definitions for undefined steps with these snippets:\n\n@given('I am a registered user with email {email}')\ndef step_impl(context, email):\n    raise NotImplementedError()\n```\n\n**âœ… This is GOOD!** Scenarios undefined because step definitions don't exist yet.\n\n---\n\n### Step 7: Commit Scenarios\n\n**Create commit**:\n\n```bash\ngit add features/authentication.feature\ngit commit -m \"SCENARIO: Add scenarios for <REQ-ID>\n\nWrite BDD scenarios for user login functionality in business language.\n\nScenarios cover:\n- Successful login (happy path)\n- BR-001: Email validation\n- BR-002: Password minimum length\n- BR-003: Account lockout after 3 attempts\n- BR-003: Lockout expiry\n\nScenarios: 5 scenarios (all undefined as expected - SCENARIO phase)\n\nValidates: <REQ-ID>\n\"\n```\n\n---\n\n## Output Format\n\nWhen you complete the SCENARIO phase, show:\n\n```\n[SCENARIO Phase - <REQ-ID>]\n\nRequirement: User login with email and password\n\nScenarios Created:\n  âœ“ Successful login (happy path)\n  âœ“ Login fails with invalid email (BR-001)\n  âœ“ Login fails with short password (BR-002)\n  âœ“ Account locks after 3 failed attempts (BR-003)\n  âœ“ User can login after lockout expires (BR-003)\n\nFeature File: features/authentication.feature (5 scenarios, 67 lines)\n\nBusiness Language Check:\n  âœ“ No technical jargon âœ“\n  âœ“ Stakeholder-readable âœ“\n  âœ“ User story format âœ“\n\nRunning scenarios...\n  Scenario: Successful login              UNDEFINED\n  Scenario: Login fails invalid email     UNDEFINED\n  Scenario: Login fails short password    UNDEFINED\n  Scenario: Account locks after 3 fails   UNDEFINED\n  Scenario: Login after lockout expires   UNDEFINED\n\nResult: 5 scenarios UNDEFINED âœ“ (expected - SCENARIO phase)\n\nCommit: SCENARIO: Add scenarios for <REQ-ID>\n\nâœ… SCENARIO Phase Complete!\n   Next: Invoke implement-step-definitions skill\n```\n\n---\n\n## Prerequisites Check\n\nBefore invoking this skill, ensure:\n1. Requirement key (REQ-*) exists\n2. Requirement details available (what to test)\n3. BDD framework available or can be installed\n\nIf prerequisites not met:\n- No REQ-* â†’ Invoke `requirement-extraction` skill\n- No requirement details â†’ Ask user for clarification\n\n---\n\n## Next Steps\n\nAfter SCENARIO phase completes:\n1. **Do NOT implement step definitions yet** (that's next phase)\n2. Invoke `implement-step-definitions` skill to create step definitions\n3. Scenarios should become PENDING (step definitions exist but implementation missing)\n\n---\n\n## Gherkin Best Practices\n\n### Good Scenario Writing\n\n**âœ… Declarative (What, not How)**:\n```gherkin\nWhen I log in with valid credentials\nThen I should see my dashboard\n```\n\n**âŒ Imperative (Too detailed)**:\n```gherkin\nWhen I type \"user@example.com\" in the email field\nAnd I type \"password123\" in the password field\nAnd I move my mouse to the login button\nAnd I click the login button\nThen I should see a div with class \"dashboard\"\n```\n\n### Good Step Writing\n\n**âœ… Reusable**:\n```gherkin\nGiven I am logged in as \"user@example.com\"\n```\n\n**âŒ Too specific**:\n```gherkin\nGiven there is a user \"user@example.com\" with password \"pass123\" in the database\nAnd I navigate to \"/login\"\nAnd I enter \"user@example.com\" in \"#email-input\"\nAnd I enter \"pass123\" in \"#password-input\"\nAnd I click \"#login-button\"\n```\n\n### Background vs Scenario\n\n**Use Background** for common preconditions:\n```gherkin\nBackground:\n  Given I am on the login page\n\nScenario: ...\n  # Don't repeat \"Given I am on the login page\"\n```\n\n---\n\n## Notes\n\n**Why business language?**\n- Stakeholders can validate requirements\n- Non-technical product owners can review\n- Living documentation everyone understands\n- Tests become communication tool\n\n**Gherkin keywords**:\n- `Feature`: High-level capability\n- `Background`: Common preconditions\n- `Scenario`: Specific test case\n- `Given`: Preconditions (setup)\n- `When`: Actions (what user does)\n- `Then`: Expected outcomes (assertions)\n- `And`/`But`: Continue previous keyword\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  scenarios_in_business_language: true\n  scenarios_cover_all_business_rules: true\n  stakeholder_readable: true\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/debt/detect-complexity/SKILL.md": "# detect-complexity\n\n**Skill Type**: Sensor (Homeostasis)\n**Purpose**: Detect over-complex code that violates Principle #3 (\"Modular & Maintainable\")\n**Prerequisites**: None (can run anytime)\n\n---\n\n## Agent Instructions\n\nYou are a **Sensor** in the homeostasis system. Your job is to **detect deviations** from the desired state.\n\n**Desired State**: `max_cyclomatic_complexity â‰¤ 10`\n\nScan the codebase for:\n1. **Cyclomatic Complexity** - too many branches/paths\n2. **Function Length** - functions that are too long\n3. **Nesting Depth** - deeply nested code\n\n---\n\n## Detection Algorithm\n\n### 1. Calculate Cyclomatic Complexity\n\nFor each function/method:\n```\nCyclomatic Complexity = 1 (base)\n  + 1 for each if/elif\n  + 1 for each while/for loop\n  + 1 for each and/or in conditions\n  + 1 for each except clause\n  + 1 for each case in match/switch\n  + 1 for each ternary operator (? :)\n\nThreshold: 10 (industry standard)\n\nIf complexity > 10 â†’ Flag as violation\n```\n\n**Example**:\n```python\ndef login(email, password):          # Complexity: 18\n    if email is None:                # +1 = 2\n        return error(\"Email required\")\n    if not is_valid_email(email):    # +1 = 3\n        return error(\"Invalid email\")\n    if not User.exists(email):       # +1 = 4\n        return error(\"User not found\")\n    user = User.get(email)\n    if user.is_locked:               # +1 = 5\n        if not user.lockout_expired():  # +1 = 6\n            return error(\"Account locked\")\n        else:\n            user.unlock()\n    try:                             # +0 (try doesn't count)\n        if not user.check_password(password):  # +1 = 7\n            user.increment_attempts()\n            if user.attempts >= 3:   # +1 = 8\n                user.lock()\n            return error(\"Invalid password\")\n    except Exception:                # +1 = 9\n        log.error(\"Auth error\")\n    if user.needs_2fa:               # +1 = 10\n        if not verify_2fa(user):     # +1 = 11\n            return error(\"2FA failed\")\n    if user.password_expired:        # +1 = 12\n        if days_since(user.password_updated) > 90:  # +1 = 13\n            return error(\"Password expired\")\n    if rate_limit_exceeded(user):    # +1 = 14\n        return error(\"Too many requests\")\n    if user.account_suspended:       # +1 = 15\n        return error(\"Account suspended\")\n    if not user.email_verified:      # +1 = 16\n        return error(\"Email not verified\")\n    if user.role == 'admin' and not from_internal_ip():  # +1 (and) = 17\n        return error(\"Admin must use VPN\")\n    return success(user)             # Total: 18\n```\n\n### 2. Measure Function Length\n\nFor each function/method:\n```\nCount lines of code (exclude blank lines, comments, docstrings)\n\nThresholds:\n  - Warning: > 50 lines\n  - Critical: > 100 lines\n\nIf LOC > 50 â†’ Flag as warning\nIf LOC > 100 â†’ Flag as critical violation\n```\n\n### 3. Measure Nesting Depth\n\nFor each function/method:\n```\nTrack maximum nesting level of control structures\n\nThresholds:\n  - Warning: > 3 levels\n  - Critical: > 5 levels\n\nIf nesting > 3 â†’ Flag as warning\nIf nesting > 5 â†’ Flag as critical violation\n```\n\n**Example**:\n```python\ndef process_payment(amount, card):\n    if amount > 0:                          # Nesting: 1\n        if card.is_valid():                 # Nesting: 2\n            if card.balance >= amount:      # Nesting: 3\n                if not card.is_expired():   # Nesting: 4\n                    if card.cvv_valid():    # Nesting: 5 âš ï¸\n                        if rate_limit_ok(): # Nesting: 6 âŒ CRITICAL\n                            charge(card, amount)\n```\n\n---\n\n## Output Format\n\nReport findings in this format:\n\n```yaml\ncomplexity_report:\n  file: \"auth_service.py\"\n  timestamp: \"2025-11-20T15:30:00Z\"\n\n  complexity_violations:\n    - function: \"login\"\n      lines: \"105-180\"\n      complexity: 18\n      threshold: 10\n      severity: \"critical\"\n      reason: \"8 violations above threshold\"\n      suggestion: \"Extract validation logic to separate functions\"\n      branches:\n        - \"email validation\" (3 branches)\n        - \"account status checks\" (5 branches)\n        - \"2FA verification\" (2 branches)\n        - \"password validation\" (3 branches)\n\n    - function: \"process_payment\"\n      lines: \"220-250\"\n      complexity: 12\n      threshold: 10\n      severity: \"warning\"\n      reason: \"2 violations above threshold\"\n      suggestion: \"Extract card validation logic\"\n\n  length_violations:\n    - function: \"login\"\n      lines: \"105-180\"\n      loc: 76\n      threshold: 50\n      severity: \"warning\"\n      suggestion: \"Split into smaller functions\"\n\n  nesting_violations:\n    - function: \"process_payment\"\n      lines: \"220-250\"\n      max_nesting: 6\n      threshold: 3\n      severity: \"critical\"\n      location: \"Line 235 (6 levels deep)\"\n      suggestion: \"Use early returns to reduce nesting\"\n\n  summary:\n    total_violations: 4\n    complexity_critical: 1\n    complexity_warning: 1\n    length_warning: 1\n    nesting_critical: 1\n    max_complexity: 18\n    avg_complexity: 6.4\n\n  homeostasis_status: DEVIATION_DETECTED\n  recommended_actuator: \"simplify-complex-code\"\n```\n\n---\n\n## User-Facing Output\n\nWhen run as `claude homeostasis status` or during refactor:\n\n```\nâš ï¸ detect-complexity - Last run: 1 min ago\n  Status: Complexity violations\n  Deviation: login() complexity 18 (threshold: 10)\n\nComplexity Report (auth_service.py):\n  âŒ login() - Cyclomatic complexity: 18 (threshold: 10)\n    Lines: 105-180\n    Violations: 8 above threshold\n    Issues:\n      - 6 nested if statements\n      - 4 try/except blocks\n      - 76 lines of code (threshold: 50)\n    Recommendation: Extract validation logic to separate functions\n\n  âš ï¸ process_payment() - Cyclomatic complexity: 12 (threshold: 10)\n    Lines: 220-250\n    Violations: 2 above threshold\n    Issues:\n      - 6 levels of nesting (threshold: 3)\n    Recommendation: Use early returns to reduce nesting\n\nSummary:\n  Functions scanned: 24\n  Violations: 4\n  Max complexity: 18\n  Avg complexity: 6.4\n\nHomeostasis deviation detected! Max complexity > 10 (Principle #3 violated).\n\nRecommended action: Invoke 'simplify-complex-code' skill to refactor automatically.\n```\n\n---\n\n## Complexity Refactoring Suggestions\n\nFor each violation, suggest specific refactoring:\n\n**High Complexity**:\n- Extract validation logic to separate functions\n- Replace nested ifs with early returns (guard clauses)\n- Extract conditional logic to named boolean variables\n- Replace complex conditions with strategy pattern\n\n**Long Functions**:\n- Extract logical blocks to separate functions\n- Move related functionality to helper methods\n- Consider splitting into multiple smaller functions\n\n**Deep Nesting**:\n- Use early returns (fail fast)\n- Invert conditions to reduce nesting\n- Extract nested blocks to separate functions\n- Use polymorphism instead of type checking\n\n---\n\n## Triggering Actuator\n\nWhen deviation detected:\n```\n1. Report deviation with specific suggestions\n2. Suggest invoking 'simplify-complex-code' actuator\n3. Wait for user confirmation OR auto-invoke if configured\n```\n\n---\n\n## Configuration\n\n```yaml\nplugins:\n  - name: \"@aisdlc/code-skills\"\n    config:\n      complexity_detection:\n        auto_detect_on_refactor: true     # Run during refactor phase\n        auto_simplify: false              # Ask before refactoring\n        complexity_threshold: 10          # Default: 10\n        length_threshold: 50              # Default: 50 lines\n        nesting_threshold: 3              # Default: 3 levels\n        exclude_files:\n          - \"tests/*\"                     # Don't check test files\n          - \"migrations/*\"\n```\n\n---\n\n## Prerequisites Check\n\nNone - this sensor can run anytime.\n\n---\n\n## Next Steps\n\nAfter detection:\n1. If violations found â†’ Suggest `simplify-complex-code` actuator\n2. If clean â†’ Report \"Homeostasis achieved! Max complexity â‰¤ 10 âœ“\"\n\n---\n\n## Notes\n\n**Why complexity matters**:\n- High complexity = more bugs (proven correlation)\n- Hard to test (exponential growth in test cases)\n- Hard to understand (cognitive load)\n- Hard to maintain (more defects introduced during changes)\n\n**Industry thresholds**:\n- Complexity 1-10: Simple, low risk\n- Complexity 11-20: Moderate, medium risk\n- Complexity 21-50: Complex, high risk\n- Complexity 50+: Untestable, very high risk\n\n**Principle #3**: \"Modular & Maintainable\"\n- Single responsibility â†’ Low complexity\n- Focused functions â†’ Easy to test\n- Simple logic â†’ Easy to understand\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  max_cyclomatic_complexity: 10\n  max_function_length: 50\n  max_nesting_depth: 3\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/debt/detect-unused-code/SKILL.md": "# detect-unused-code\n\n**Skill Type**: Sensor (Homeostasis)\n**Purpose**: Detect technical debt from unused code (Principle #6: \"No Legacy Baggage\")\n**Prerequisites**: None (can run anytime)\n\n---\n\n## Agent Instructions\n\nYou are a **Sensor** in the homeostasis system. Your job is to **detect deviations** from the desired state.\n\n**Desired State**: `tech_debt.unused_code = 0`\n\nScan the codebase for:\n1. **Unused Imports** - imports that are never referenced\n2. **Dead Code** - functions/methods with zero callers\n3. **Commented-Out Code** - code blocks that are commented out\n\n---\n\n## Detection Algorithm\n\n### 1. Detect Unused Imports\n\nFor each file:\n```\n1. Parse all import statements\n2. For each imported name:\n   a. Search the file for any usage of that name\n   b. If usage count = 0, mark as unused\n3. Report all unused imports\n```\n\n**Example**:\n```python\nimport hashlib          # Used: 0 times â†’ UNUSED\nimport re               # Used: 0 times â†’ UNUSED\nfrom typing import Dict # Used: 0 times â†’ UNUSED\nfrom typing import List # Used: 3 times â†’ OK\nimport bcrypt           # Used: 2 times â†’ OK\n```\n\n### 2. Detect Dead Code\n\nFor each function/method:\n```\n1. Get function name\n2. Search entire codebase for calls to that function\n3. Exclude:\n   - Test functions (test_*)\n   - Entry points (main, __init__)\n   - Special methods (__str__, __repr__, etc.)\n   - Overridden methods from base classes\n4. If caller count = 0, mark as dead code\n5. Report all dead functions with line numbers\n```\n\n**Example**:\n```python\ndef legacy_hash_password(password):  # Line 45-52\n    return md5(password)\n# Callers: 0 â†’ DEAD CODE\n\ndef validate_old_token(token):       # Line 89-97\n    return token == \"old_secret\"\n# Callers: 0 â†’ DEAD CODE\n\ndef hash_password(password):         # Line 105-110\n    return bcrypt.hash(password)\n# Callers: 15 â†’ OK\n```\n\n### 3. Detect Commented-Out Code\n\nFor each file:\n```\n1. Scan for comment blocks (lines starting with # or /* */)\n2. Heuristic: If comment block contains:\n   - Assignment operators (=, +=, -=)\n   - Control flow keywords (if, for, while, return)\n   - Function calls with parentheses\n   â†’ Mark as commented-out code\n3. Exclude:\n   - Docstrings\n   - Single-line explanatory comments\n   - TODO/FIXME comments\n4. Report all commented-out code with line ranges\n```\n\n**Example**:\n```python\n# This validates the email  â†’ OK (explanatory comment)\n\n# TODO: Add rate limiting   â†’ OK (TODO comment)\n\n# Old implementation (broken)  â†’ COMMENTED CODE (lines 120-135)\n# user = User.query.get(email)\n# if user and user.password == password:\n#     return user\n# else:\n#     return None\n```\n\n---\n\n## Output Format\n\nReport findings in this format:\n\n```yaml\ntech_debt_report:\n  file: \"auth_service.py\"\n  timestamp: \"2025-11-20T15:30:00Z\"\n\n  unused_imports:\n    - name: \"hashlib\"\n      line: 3\n      reason: \"Imported but never used\"\n\n    - name: \"re\"\n      line: 4\n      reason: \"Imported but never used\"\n\n    - name: \"Dict\"\n      line: 7\n      module: \"typing\"\n      reason: \"Imported but never used\"\n\n  dead_code:\n    - name: \"legacy_hash_password\"\n      lines: \"45-52\"\n      reason: \"Function with zero callers\"\n      suggestion: \"DELETE - unused since v2.0 migration\"\n\n    - name: \"validate_old_token\"\n      lines: \"89-97\"\n      reason: \"Function with zero callers\"\n      suggestion: \"DELETE - replaced by validate_jwt_token()\"\n\n  commented_code:\n    - lines: \"120-135\"\n      reason: \"16 lines of commented-out implementation\"\n      snippet: \"# user = User.query.get(email)...\"\n      suggestion: \"DELETE - we have git history\"\n\n  summary:\n    total_violations: 22\n    unused_imports: 5\n    dead_functions: 2\n    commented_lines: 15\n\n  homeostasis_status: DEVIATION_DETECTED\n  recommended_actuator: \"prune-unused-code\"\n```\n\n---\n\n## User-Facing Output\n\nWhen run as `claude homeostasis status` or during refactor:\n\n```\nâš ï¸ detect-unused-code - Last run: 1 min ago\n  Status: Tech debt detected\n  Deviation: 5 unused imports, 2 dead functions, 15 lines of commented code\n\nTech Debt Report (auth_service.py):\n  âš ï¸ Unused imports (5):\n    - import hashlib      # Line 3\n    - import re           # Line 4\n    - from typing import Dict  # Line 7\n\n  âš ï¸ Dead code (2 functions):\n    - legacy_hash_password()  # Lines 45-52 (no callers)\n    - validate_old_token()    # Lines 89-97 (no callers)\n\n  âš ï¸ Commented code (15 lines):\n    - Lines 120-135 (old implementation)\n\nTotal violations: 22\n\nHomeostasis deviation detected! Tech debt > 0 (Principle #6 violated).\n\nRecommended action: Invoke 'prune-unused-code' skill to fix automatically.\n```\n\n---\n\n## Triggering Actuator\n\nWhen deviation detected:\n```\n1. Report deviation\n2. Suggest invoking 'prune-unused-code' actuator\n3. Wait for user confirmation OR auto-invoke if configured\n```\n\n---\n\n## Configuration\n\nThis skill can be configured in `.claude/plugins.yml`:\n\n```yaml\nplugins:\n  - name: \"@aisdlc/code-skills\"\n    config:\n      debt_detection:\n        auto_detect_on_refactor: true    # Run during refactor phase\n        auto_prune: false                # Ask before pruning\n        exclude_files:                   # Don't scan these files\n          - \"migrations/*\"\n          - \"legacy/*\"\n        exclude_patterns:\n          - \"# KEEP:\"                    # Don't flag comments with KEEP\n```\n\n---\n\n## Prerequisites Check\n\nNone - this sensor can run anytime.\n\n---\n\n## Next Steps\n\nAfter detection:\n1. If violations found â†’ Suggest `prune-unused-code` actuator\n2. If clean â†’ Report \"Homeostasis achieved! Tech debt = 0 âœ“\"\n\n---\n\n## Notes\n\n**Why this matters**:\n- Unused code adds noise, makes codebase harder to understand\n- Dead functions create maintenance burden (devs wonder \"is this used?\")\n- Commented code should be in git history, not source files\n- Principle #6 requires **operational enforcement**, not just philosophy\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  tech_debt.unused_code: 0\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/debt/prune-unused-code/SKILL.md": "# prune-unused-code\n\n**Skill Type**: Actuator (Homeostasis)\n**Purpose**: Automatically remove unused code to restore homeostasis (Principle #6: \"No Legacy Baggage\")\n**Prerequisites**:\n- `detect-unused-code` skill must have run\n- Tech debt report available\n\n---\n\n## Agent Instructions\n\nYou are an **Actuator** in the homeostasis system. Your job is to **correct deviations** and restore the desired state.\n\n**Desired State**: `tech_debt.unused_code = 0`\n\nBased on the tech debt report from `detect-unused-code`, automatically:\n1. **Delete Unused Imports**\n2. **Remove Dead Code Functions**\n3. **Delete Commented-Out Code**\n\n---\n\n## Pruning Algorithm\n\n### 1. Delete Unused Imports\n\nFor each unused import in the report:\n```\n1. Locate the import statement by line number\n2. Delete the entire line\n3. If it's a \"from X import A, B, C\" statement where only some are unused:\n   a. Keep only the used imports\n   b. If all are unused, delete the entire line\n4. Track the deletion\n```\n\n**Example**:\n```python\n# BEFORE\nimport hashlib          # âŒ UNUSED - DELETE\nimport re               # âŒ UNUSED - DELETE\nfrom typing import Dict, List  # âš ï¸ Only Dict unused\nimport bcrypt           # âœ“ USED - KEEP\n\n# AFTER\nfrom typing import List  # âœ“ Kept only what's used\nimport bcrypt           # âœ“ USED - KEEP\n```\n\n**Changes**:\n```\nâœ“ Deleted: import hashlib (line 3)\nâœ“ Deleted: import re (line 4)\nâœ“ Updated: from typing import Dict, List â†’ from typing import List (line 7)\n```\n\n### 2. Remove Dead Code\n\nFor each dead function in the report:\n```\n1. Locate function by line range (e.g., lines 45-52)\n2. Delete all lines in that range\n3. Delete any blank lines immediately after (cleanup)\n4. Track the deletion (function name, line count)\n```\n\n**Example**:\n```python\n# BEFORE\ndef legacy_hash_password(password):  # âŒ DEAD CODE - DELETE\n    \"\"\"Old MD5 hashing (insecure)\"\"\"\n    import hashlib\n    return hashlib.md5(password.encode()).hexdigest()\n\n\ndef validate_old_token(token):       # âŒ DEAD CODE - DELETE\n    \"\"\"Deprecated token validation\"\"\"\n    return token == \"old_secret\"\n\n\ndef hash_password(password):         # âœ“ USED - KEEP\n    return bcrypt.hash(password)\n\n# AFTER\ndef hash_password(password):         # âœ“ USED - KEEP\n    return bcrypt.hash(password)\n```\n\n**Changes**:\n```\nâœ“ Deleted: legacy_hash_password() (8 lines: 45-52)\nâœ“ Deleted: validate_old_token() (9 lines: 89-97)\nâœ“ Cleaned up: 2 blank lines\nTotal: 19 lines deleted\n```\n\n### 3. Delete Commented-Out Code\n\nFor each commented code block in the report:\n```\n1. Locate by line range (e.g., lines 120-135)\n2. Verify it's actually commented-out code (not a docstring or TODO)\n3. Delete all lines in that range\n4. Track the deletion\n```\n\n**Example**:\n```python\n# BEFORE\ndef login(email, password):\n    # Old implementation (broken)     # âŒ COMMENTED CODE - DELETE\n    # user = User.query.get(email)\n    # if user and user.password == password:\n    #     return user\n    # else:\n    #     return None\n\n    # New implementation\n    user = User.get_by_email(email)\n    return authenticate(user, password)\n\n# AFTER\ndef login(email, password):\n    # New implementation\n    user = User.get_by_email(email)\n    return authenticate(user, password)\n```\n\n**Changes**:\n```\nâœ“ Deleted: Lines 120-126 (7 lines of commented code)\n```\n\n---\n\n## Safety Checks\n\nBefore pruning, verify:\n\n1. **All tests are passing** - Don't prune if tests are failing\n2. **Backup exists** - Ensure git working directory is clean OR create backup\n3. **User confirmation** (if auto_prune=false) - Ask before destructive changes\n\nAfter pruning:\n1. **Run all tests** - Verify nothing broke\n2. **If tests fail**:\n   - ROLLBACK all changes\n   - Report failure\n   - DO NOT COMMIT\n\n---\n\n## Output Format\n\n```\n[Invoking: prune-unused-code skill (Actuator)]\n\nSafety checks:\n  âœ“ All tests passing (47/47)\n  âœ“ Git working directory clean\n  âœ“ User confirmed pruning\n\nPruning auth_service.py...\n\nRemoving unused imports...\n  âœ“ Deleted: import hashlib (line 3)\n  âœ“ Deleted: import re (line 4)\n  âœ“ Updated: from typing import Dict, List â†’ from typing import List (line 7)\n\nRemoving dead code...\n  âœ“ Deleted: legacy_hash_password() (8 lines: 45-52)\n  âœ“ Deleted: validate_old_token() (9 lines: 89-97)\n\nRemoving commented code...\n  âœ“ Deleted: Lines 120-135 (16 lines)\n\nSummary:\n  Unused imports deleted: 3\n  Dead functions deleted: 2 (17 lines)\n  Commented code deleted: 16 lines\n  Blank lines cleaned: 5\n  Total lines deleted: 38\n\nFile size: 487 lines â†’ 449 lines (-8%)\n\nRunning tests to verify...\n  âœ“ All 47 tests passing\n\nTech debt re-checked:\n  [Invoking: detect-unused-code skill]\n  âœ“ Unused imports: 0\n  âœ“ Dead code: 0 functions\n  âœ“ Commented code: 0 lines\n\nHomeostasis achieved! Tech debt.unused_code = 0 âœ“\n\nChanges ready to commit.\n```\n\n---\n\n## Error Handling\n\n### If tests fail after pruning:\n\n```\nâŒ ROLLBACK: Tests failed after pruning\n\nFailed tests:\n  - test_legacy_auth (expected legacy_hash_password to exist)\n\nAnalysis:\n  Function 'legacy_hash_password' was detected as dead code,\n  but test_legacy_auth still references it.\n\nRoot cause: Test file was not scanned by detect-unused-code.\n\nRestoring original file...\n  âœ“ Restored: auth_service.py\n\nRecommendation: Fix test_legacy_auth first (delete it or update it)\n```\n\n### If user cancels:\n\n```\nâ„¹ï¸ User cancelled pruning\n\nTech debt remains:\n  âš ï¸ 5 unused imports\n  âš ï¸ 2 dead functions\n  âš ï¸ 15 lines commented code\n\nHomeostasis deviation persists (tech_debt = 22).\n\nTo prune later: Invoke 'prune-unused-code' skill\n```\n\n---\n\n## Configuration\n\n```yaml\nplugins:\n  - name: \"@aisdlc/code-skills\"\n    config:\n      debt_pruning:\n        auto_prune: false               # Ask before pruning (default)\n        run_tests_after: true           # Always verify (required)\n        backup_before_prune: true       # Create backup if no git\n        exclude_files:                  # Don't prune these files\n          - \"migrations/*\"\n          - \"legacy/*\"\n```\n\n---\n\n## Prerequisites Check\n\nBefore invoking this skill, ensure:\n1. `detect-unused-code` skill has run\n2. Tech debt report is available\n3. Tests are passing (GREEN)\n\nIf prerequisites not met, invoke:\n- `detect-unused-code` (if no report available)\n- Return error if tests not passing\n\n---\n\n## Next Steps\n\nAfter pruning is complete:\n1. Run `detect-complexity` sensor to check for complexity violations\n2. If complexity violations â†’ Invoke `simplify-complex-code` actuator\n3. If clean â†’ Invoke `commit-with-req-tag` to commit changes\n\n---\n\n## Rollback Procedure\n\nIf pruning causes test failures:\n```\n1. Restore file from backup OR git checkout\n2. Report which deletion caused the failure\n3. Suggest manual investigation\n4. Do NOT commit\n```\n\n---\n\n## Notes\n\n**Why automatic deletion is safe**:\n- Only deletes code with **zero references** (verified by sensor)\n- Always runs tests after pruning\n- Automatic rollback if tests fail\n- User can review changes before commit\n\n**Why this matters**:\n- Enforces Principle #6 operationally (not just philosophically)\n- Reduces codebase size â†’ easier to understand\n- Removes maintenance burden (no \"is this used?\" questions)\n- Forces developers to trust git history (not commented code)\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  tech_debt.unused_code: 0\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/debt/simplify-complex-code/SKILL.md": "# simplify-complex-code\n\n**Skill Type**: Actuator (Homeostasis)\n**Purpose**: Automatically refactor complex code to restore homeostasis (Principle #3: \"Modular & Maintainable\")\n**Prerequisites**:\n- `detect-complexity` skill must have run\n- Complexity report available\n- All tests passing (GREEN)\n\n---\n\n## Agent Instructions\n\nYou are an **Actuator** in the homeostasis system. Your job is to **correct deviations** and restore the desired state.\n\n**Desired State**: `max_cyclomatic_complexity â‰¤ 10`\n\nBased on the complexity report from `detect-complexity`, automatically refactor complex code using proven techniques.\n\n---\n\n## Simplification Techniques\n\n### 1. Extract Functions (Complexity Reduction)\n\n**Pattern**: High cyclomatic complexity (> 10)\n**Solution**: Extract logical blocks to separate functions\n\n**Example**:\n```python\n# BEFORE (Complexity: 18)\ndef login(email, password):\n    if email is None:\n        return error(\"Email required\")\n    if not is_valid_email(email):\n        return error(\"Invalid email\")\n    if not User.exists(email):\n        return error(\"User not found\")\n    user = User.get(email)\n    if user.is_locked:\n        if not user.lockout_expired():\n            return error(\"Account locked\")\n        else:\n            user.unlock()\n    if not user.check_password(password):\n        user.increment_attempts()\n        if user.attempts >= 3:\n            user.lock()\n        return error(\"Invalid password\")\n    if user.needs_2fa:\n        if not verify_2fa(user):\n            return error(\"2FA failed\")\n    return success(user)\n\n# AFTER (Complexity: 6)\ndef login(email, password):\n    validation_error = validate_login_input(email, password)\n    if validation_error:\n        return validation_error\n\n    user = get_user_or_fail(email)\n\n    if user.is_locked and not user.lockout_expired():\n        return error(\"Account locked\")\n\n    if not authenticate_user(user, password):\n        return error(\"Authentication failed\")\n\n    if not verify_2fa_if_required(user):\n        return error(\"2FA failed\")\n\n    return success(user)\n\n# Extracted functions (each complexity < 5)\ndef validate_login_input(email, password):\n    \"\"\"Validates email and password format (Complexity: 3)\"\"\"\n    if not email:\n        return error(\"Email required\")\n    if not is_valid_email(email):\n        return error(\"Invalid email\")\n    return None\n\ndef get_user_or_fail(email):\n    \"\"\"Gets user or raises error (Complexity: 2)\"\"\"\n    if not User.exists(email):\n        raise UserNotFoundError(email)\n    user = User.get(email)\n    if user.is_locked and user.lockout_expired():\n        user.unlock()\n    return user\n\ndef authenticate_user(user, password):\n    \"\"\"Authenticates user with password (Complexity: 3)\"\"\"\n    if not user.check_password(password):\n        user.increment_attempts()\n        if user.attempts >= 3:\n            user.lock()\n        return False\n    return True\n\ndef verify_2fa_if_required(user):\n    \"\"\"Verifies 2FA if user requires it (Complexity: 2)\"\"\"\n    if not user.needs_2fa:\n        return True\n    return verify_2fa(user)\n```\n\n**Complexity Reduction**: 18 â†’ 6 (67% reduction)\n\n---\n\n### 2. Early Returns (Nesting Reduction)\n\n**Pattern**: Deep nesting (> 3 levels)\n**Solution**: Invert conditions and use early returns (guard clauses)\n\n**Example**:\n```python\n# BEFORE (Nesting: 6 levels)\ndef process_payment(amount, card):\n    if amount > 0:                          # Level 1\n        if card.is_valid():                 # Level 2\n            if card.balance >= amount:      # Level 3\n                if not card.is_expired():   # Level 4\n                    if card.cvv_valid():    # Level 5\n                        if rate_limit_ok(): # Level 6\n                            return charge(card, amount)\n                        else:\n                            return error(\"Rate limit\")\n                    else:\n                        return error(\"Invalid CVV\")\n                else:\n                    return error(\"Card expired\")\n            else:\n                return error(\"Insufficient funds\")\n        else:\n            return error(\"Invalid card\")\n    else:\n        return error(\"Invalid amount\")\n\n# AFTER (Nesting: 1 level)\ndef process_payment(amount, card):\n    # Guard clauses (fail fast)\n    if amount <= 0:\n        return error(\"Invalid amount\")\n    if not card.is_valid():\n        return error(\"Invalid card\")\n    if card.balance < amount:\n        return error(\"Insufficient funds\")\n    if card.is_expired():\n        return error(\"Card expired\")\n    if not card.cvv_valid():\n        return error(\"Invalid CVV\")\n    if not rate_limit_ok():\n        return error(\"Rate limit\")\n\n    # Happy path (single level)\n    return charge(card, amount)\n```\n\n**Nesting Reduction**: 6 â†’ 1 (83% reduction)\n\n---\n\n### 3. Extract Conditional Logic (Readability)\n\n**Pattern**: Complex boolean conditions\n**Solution**: Extract to named boolean variables\n\n**Example**:\n```python\n# BEFORE\nif user.role == 'admin' and not user.is_suspended and user.email_verified and (user.last_login is None or (datetime.now() - user.last_login).days < 90):\n    grant_access()\n\n# AFTER\nis_admin = user.role == 'admin'\nis_active = not user.is_suspended\nis_verified = user.email_verified\nis_recent_login = user.last_login and (datetime.now() - user.last_login).days < 90\n\nif is_admin and is_active and is_verified and is_recent_login:\n    grant_access()\n```\n\n---\n\n### 4. Replace Type Checking with Polymorphism\n\n**Pattern**: Multiple if/elif type checks\n**Solution**: Use polymorphism (strategy pattern)\n\n**Example**:\n```python\n# BEFORE (Complexity: 8)\ndef process_payment(payment_type, amount, details):\n    if payment_type == 'credit_card':\n        if validate_card(details):\n            charge_card(details, amount)\n    elif payment_type == 'paypal':\n        if validate_paypal(details):\n            charge_paypal(details, amount)\n    elif payment_type == 'bank_transfer':\n        if validate_bank(details):\n            initiate_transfer(details, amount)\n    elif payment_type == 'cryptocurrency':\n        if validate_crypto(details):\n            send_crypto(details, amount)\n\n# AFTER (Complexity: 2)\ndef process_payment(payment_method, amount):\n    \"\"\"Uses polymorphism instead of type checking\"\"\"\n    payment_method.validate()  # Polymorphic call\n    payment_method.charge(amount)  # Polymorphic call\n\n# Each payment type implements validate() and charge()\nclass CreditCardPayment:\n    def validate(self): ...\n    def charge(self, amount): ...\n\nclass PayPalPayment:\n    def validate(self): ...\n    def charge(self, amount): ...\n```\n\n---\n\n### 5. Split Long Functions\n\n**Pattern**: Function > 50 lines\n**Solution**: Split by logical responsibility\n\n**Example**:\n```python\n# BEFORE (76 lines)\ndef register_user(email, password, profile_data):\n    # Email validation (10 lines)\n    # Password validation (15 lines)\n    # Profile validation (12 lines)\n    # Create user record (8 lines)\n    # Send welcome email (10 lines)\n    # Setup user preferences (8 lines)\n    # Log registration (5 lines)\n    # Return result (8 lines)\n\n# AFTER (5 functions Ã— ~15 lines each)\ndef register_user(email, password, profile_data):\n    validate_registration_data(email, password, profile_data)\n    user = create_user_record(email, password, profile_data)\n    setup_user_account(user)\n    notify_user(user)\n    return registration_success(user)\n\ndef validate_registration_data(email, password, profile_data): ...\ndef create_user_record(email, password, profile_data): ...\ndef setup_user_account(user): ...\ndef notify_user(user): ...\ndef registration_success(user): ...\n```\n\n---\n\n## Refactoring Algorithm\n\nFor each violation in the complexity report:\n\n```\n1. Identify the refactoring technique:\n   - Complexity > 10 â†’ Extract functions\n   - Nesting > 3 â†’ Early returns\n   - Complex conditions â†’ Extract to named booleans\n   - Type checking â†’ Polymorphism\n   - Length > 50 â†’ Split function\n\n2. Apply refactoring:\n   a. Create new extracted functions\n   b. Update original function to call extracted functions\n   c. Ensure all logic preserved\n\n3. Verify:\n   a. Run all tests\n   b. If tests fail â†’ ROLLBACK\n   c. If tests pass â†’ Re-check complexity\n   d. If complexity still > 10 â†’ Apply next technique\n\n4. Repeat until complexity â‰¤ 10\n```\n\n---\n\n## Output Format\n\n```\n[Invoking: simplify-complex-code skill (Actuator)]\n\nSafety checks:\n  âœ“ All tests passing (47/47)\n  âœ“ Complexity report available\n  âœ“ User confirmed refactoring\n\nRefactoring auth_service.py...\n\nTarget: login() - Complexity 18 â†’ 6\n\nStep 1: Extracting validation logic...\n  âœ“ Created: validate_login_input() (complexity: 3)\n  âœ“ Created: get_user_or_fail() (complexity: 2)\n\nStep 2: Extracting authentication logic...\n  âœ“ Created: authenticate_user() (complexity: 3)\n  âœ“ Created: verify_2fa_if_required() (complexity: 2)\n\nStep 3: Refactoring login()...\n  âœ“ Replaced nested ifs with function calls\n  âœ“ Reduced complexity: 18 â†’ 6\n\nRunning tests to verify...\n  âœ“ All 47 tests passing\n\nRe-checking complexity...\n  [Invoking: detect-complexity skill]\n  âœ“ login() complexity: 6 (threshold: 10) âœ“\n  âœ“ Max complexity: 6\n  âœ“ All functions â‰¤ 10\n\nTarget: process_payment() - Nesting 6 â†’ 1\n\nStep 1: Applying early returns pattern...\n  âœ“ Inverted conditions to guard clauses\n  âœ“ Reduced nesting: 6 levels â†’ 1 level\n  âœ“ Complexity: 12 â†’ 7\n\nRunning tests to verify...\n  âœ“ All 51 tests passing\n\nSummary:\n  Functions refactored: 2\n  Complexity reduced: Max 18 â†’ 7 (61% reduction)\n  Nesting reduced: Max 6 â†’ 1 (83% reduction)\n  New functions extracted: 4\n  Lines changed: 95\n\nHomeostasis achieved! Max complexity â‰¤ 10 âœ“\n\nChanges ready to commit.\n```\n\n---\n\n## Safety Checks\n\nBefore refactoring:\n1. **All tests passing** - Don't refactor if tests failing\n2. **Backup exists** - Ensure git working directory clean\n3. **User confirmation** (if auto_simplify=false)\n\nAfter **EACH** refactoring step:\n1. **Run all tests**\n2. **If tests fail**:\n   - ROLLBACK the change\n   - Try different refactoring technique\n   - If all techniques fail â†’ Report manual intervention needed\n\n---\n\n## Error Handling\n\n### If tests fail after refactoring:\n\n```\nâŒ ROLLBACK: Tests failed after refactoring\n\nFailed tests:\n  - test_login_with_locked_account\n\nAnalysis:\n  Extracted function 'get_user_or_fail()' doesn't handle lockout expiry correctly.\n\nRoot cause: Logic error in extraction\n\nRestoring original function...\n  âœ“ Restored: login()\n\nTrying alternative refactoring...\n  [Applying early returns pattern instead]\n  âœ“ Tests passing\n\nRecommendation: Manual review of lockout logic\n```\n\n---\n\n## Configuration\n\n```yaml\nplugins:\n  - name: \"@aisdlc/code-skills\"\n    config:\n      complexity_simplification:\n        auto_simplify: false             # Ask before refactoring (default)\n        run_tests_after: true            # Always verify (required)\n        complexity_threshold: 10\n        max_refactoring_attempts: 3     # Try 3 different techniques\n        prefer_technique:                # Preferred order\n          - \"extract_functions\"\n          - \"early_returns\"\n          - \"extract_conditionals\"\n```\n\n---\n\n## Prerequisites Check\n\nBefore invoking this skill, ensure:\n1. `detect-complexity` skill has run\n2. Complexity report is available\n3. Tests are passing (GREEN)\n\nIf prerequisites not met, invoke:\n- `detect-complexity` (if no report available)\n- Return error if tests not passing\n\n---\n\n## Next Steps\n\nAfter simplification is complete:\n1. Re-run `detect-complexity` to verify homeostasis\n2. If clean â†’ Invoke `commit-with-req-tag` to commit refactoring\n3. If still violations â†’ Report manual intervention needed\n\n---\n\n## Notes\n\n**Why automatic refactoring is safe**:\n- Only applies proven, well-understood refactoring techniques\n- Always runs tests after each step\n- Automatic rollback if tests fail\n- User can review changes before commit\n\n**Why complexity matters**:\n- Complexity 18 â†’ ~262,000 possible paths (2^18)\n- Complexity 6 â†’ ~64 possible paths (2^6)\n- 99.98% reduction in test case combinations needed\n\n**Principle #3**: \"Modular & Maintainable\"\n- Single responsibility per function â†’ Low complexity\n- Focused functions â†’ Easy to test\n- Simple logic â†’ Easy to understand\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  max_cyclomatic_complexity: 10\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/generation/autogenerate-constraints/SKILL.md": "---\nname: autogenerate-constraints\ndescription: Autogenerate constraint checking code from constraints (C-*) that specify system limits, timeouts, dependencies, or environmental requirements. Use when C-* includes technical constraints like timeouts, API limits, or compliance requirements.\nallowed-tools: [Read, Write, Edit]\n---\n\n# autogenerate-constraints\n\n**Skill Type**: Actuator (Code Generation)\n**Purpose**: Generate constraint checking code from C-* specifications\n**Prerequisites**:\n- Constraints (C-*) with technical specifications\n\n---\n\n## Agent Instructions\n\nYou are **autogenerating constraint checks** from **constraint specifications**.\n\nYour goal is to transform **structured C-* constraints** into **constraint checking functions** and **configuration**.\n\n---\n\n## Generation Patterns\n\n### Pattern 1: Timeout Constraints\n\n**Input**:\n```yaml\nC-001: Stripe API timeout\n  Timeout: 10 seconds\n  Behavior: Raise TimeoutError if exceeded\n  Fallback: Return error to user\n```\n\n**Generated**:\n```python\n# Generated from: C-001\nSTRIPE_API_TIMEOUT = 10  # seconds\n\ndef call_stripe_api(operation, **kwargs):\n    \"\"\"\n    Call Stripe API with timeout constraint.\n\n    Generated from: C-001 (Stripe API timeout)\n\n    Args:\n        operation: Stripe API operation to call\n        **kwargs: Operation parameters\n\n    Returns:\n        API response\n\n    Raises:\n        TimeoutError: If operation exceeds 10 seconds\n    \"\"\"\n    # Implements: C-001\n    try:\n        return operation(timeout=STRIPE_API_TIMEOUT, **kwargs)\n    except TimeoutError as e:\n        # Fallback: Return error to user\n        raise PaymentError(\"Payment service temporarily unavailable\") from e\n\n# Generated test\ndef test_stripe_timeout_respected(mock_stripe):\n    # C-001: Verify timeout is set\n    mock_stripe.Charge.create = Mock()\n    call_stripe_api(mock_stripe.Charge.create, amount=100)\n    mock_stripe.Charge.create.assert_called_with(timeout=10, amount=100)\n\ndef test_stripe_timeout_handles_error(mock_stripe_timeout):\n    # C-001: Verify timeout error handling\n    with pytest.raises(PaymentError):\n        call_stripe_api(mock_stripe_timeout.Charge.create, amount=100)\n```\n\n---\n\n### Pattern 2: Rate Limit Constraints\n\n**Input**:\n```yaml\nC-010: API rate limit\n  Limit: 100 requests per minute\n  Behavior: Return 429 status if exceeded\n  Retry: After 60 seconds\n```\n\n**Generated**:\n```python\n# Generated from: C-010\nAPI_RATE_LIMIT = 100  # requests per minute\nRATE_LIMIT_WINDOW = 60  # seconds\n\nclass RateLimiter:\n    \"\"\"\n    Enforce API rate limits.\n\n    Generated from: C-010 (API rate limit)\n    \"\"\"\n\n    def __init__(self):\n        self.requests = []\n\n    def check_rate_limit(self) -> Optional[int]:\n        \"\"\"\n        Check if rate limit would be exceeded.\n\n        Generated from: C-010\n\n        Returns:\n            None if OK, seconds to wait if rate limited\n        \"\"\"\n        # Implements: C-010\n        now = datetime.now()\n        cutoff = now - timedelta(seconds=RATE_LIMIT_WINDOW)\n\n        # Remove old requests\n        self.requests = [r for r in self.requests if r > cutoff]\n\n        # Check limit\n        if len(self.requests) >= API_RATE_LIMIT:\n            # Calculate retry time\n            oldest = min(self.requests)\n            retry_after = RATE_LIMIT_WINDOW - (now - oldest).seconds\n            return retry_after\n\n        return None\n\n    def record_request(self) -> None:\n        \"\"\"Record a request for rate limiting\"\"\"\n        self.requests.append(datetime.now())\n\n# Generated tests\ndef test_rate_limit_under_limit():\n    limiter = RateLimiter()\n    for _ in range(99):\n        limiter.record_request()\n    assert limiter.check_rate_limit() is None\n\ndef test_rate_limit_at_limit():\n    limiter = RateLimiter()\n    for _ in range(100):\n        limiter.record_request()\n    retry_after = limiter.check_rate_limit()\n    assert retry_after is not None\n    assert 0 < retry_after <= 60\n```\n\n---\n\n### Pattern 3: Resource Limit Constraints\n\n**Input**:\n```yaml\nC-020: File upload size\n  Max size: 10 MB\n  Behavior: Reject files larger than limit\n  Error: \"File too large. Maximum size is 10 MB\"\n```\n\n**Generated**:\n```python\n# Generated from: C-020\nMAX_UPLOAD_SIZE_BYTES = 10 * 1024 * 1024  # 10 MB\n\ndef validate_file_size(file_size: int) -> Optional[str]:\n    \"\"\"\n    Validate file size is within limit.\n\n    Generated from: C-020 (File upload size limit)\n\n    Args:\n        file_size: File size in bytes\n\n    Returns:\n        None if valid, error message if too large\n    \"\"\"\n    # Implements: C-020\n    if file_size > MAX_UPLOAD_SIZE_BYTES:\n        return \"File too large. Maximum size is 10 MB\"\n    return None\n\n# Generated tests\ndef test_file_size_valid():\n    assert validate_file_size(5 * 1024 * 1024) is None  # 5 MB\n\ndef test_file_size_at_limit():\n    assert validate_file_size(10 * 1024 * 1024) is None  # Exactly 10 MB\n\ndef test_file_size_too_large():\n    assert validate_file_size(11 * 1024 * 1024) == \"File too large. Maximum size is 10 MB\"\n```\n\n---\n\n### Pattern 4: Dependency Constraints\n\n**Input**:\n```yaml\nC-030: Python version\n  Minimum: 3.8\n  Behavior: Raise error if version < 3.8\n  Error: \"Python 3.8 or higher required\"\n```\n\n**Generated**:\n```python\n# Generated from: C-030\nimport sys\n\nPYTHON_MIN_VERSION = (3, 8)\n\ndef check_python_version() -> None:\n    \"\"\"\n    Check Python version meets minimum requirement.\n\n    Generated from: C-030 (Python version constraint)\n\n    Raises:\n        RuntimeError: If Python version < 3.8\n    \"\"\"\n    # Implements: C-030\n    if sys.version_info < PYTHON_MIN_VERSION:\n        current = f\"{sys.version_info.major}.{sys.version_info.minor}\"\n        required = f\"{PYTHON_MIN_VERSION[0]}.{PYTHON_MIN_VERSION[1]}\"\n        raise RuntimeError(\n            f\"Python {required} or higher required. Current version: {current}\"\n        )\n\n# Generated test\ndef test_python_version_check():\n    # This test always passes (we're running on valid Python)\n    check_python_version()  # Should not raise\n```\n\n---\n\n### Pattern 5: Compliance Constraints\n\n**Input**:\n```yaml\nC-040: PCI-DSS compliance\n  Constraint: Never store full credit card numbers\n  Behavior: Tokenize cards via Stripe API\n  Validation: No card numbers in logs or database\n```\n\n**Generated**:\n```python\n# Generated from: C-040\ndef validate_no_card_numbers(text: str) -> Optional[str]:\n    \"\"\"\n    Validate text does not contain credit card numbers.\n\n    Generated from: C-040 (PCI-DSS compliance)\n\n    Args:\n        text: Text to validate (log message, database field, etc.)\n\n    Returns:\n        None if valid, error message if card number detected\n    \"\"\"\n    # Implements: C-040 (PCI-DSS: no storing card numbers)\n    # Simple Luhn algorithm check for card-like patterns\n    import re\n\n    # Pattern: 13-19 digit sequences\n    potential_cards = re.findall(r'\\b\\d{13,19}\\b', text)\n\n    for number in potential_cards:\n        if _is_valid_luhn(number):\n            return \"PCI-DSS violation: Potential card number detected\"\n\n    return None\n\ndef _is_valid_luhn(card_number: str) -> bool:\n    \"\"\"Check if number passes Luhn algorithm (credit card check)\"\"\"\n    # Luhn algorithm implementation\n    digits = [int(d) for d in card_number]\n    checksum = 0\n    for i, d in enumerate(reversed(digits)):\n        if i % 2 == 1:\n            d = d * 2\n            if d > 9:\n                d = d - 9\n        checksum += d\n    return checksum % 10 == 0\n\n# Generated tests\ndef test_validate_no_card_numbers_safe_text():\n    assert validate_no_card_numbers(\"User logged in\") is None\n\ndef test_validate_no_card_numbers_detects_visa():\n    # Valid Visa test number\n    assert validate_no_card_numbers(\"Card: 4532015112830366\") == \"PCI-DSS violation: Potential card number detected\"\n```\n\n---\n\n### Pattern 6: Idempotency Constraints\n\n**Input**:\n```yaml\nC-050: Payment idempotency\n  Constraint: Same idempotency key = same charge\n  Key format: SHA256(user_id + timestamp + amount)\n  Behavior: Return existing charge if key matches\n```\n\n**Generated**:\n```python\n# Generated from: C-050\nimport hashlib\nfrom typing import Optional\n\ndef generate_idempotency_key(user_id: str, amount: float, timestamp: int) -> str:\n    \"\"\"\n    Generate idempotency key for payment.\n\n    Generated from: C-050 (Payment idempotency)\n\n    Args:\n        user_id: User identifier\n        amount: Payment amount\n        timestamp: Unix timestamp\n\n    Returns:\n        SHA256 hash as idempotency key\n    \"\"\"\n    # Implements: C-050\n    data = f\"{user_id}{timestamp}{amount}\"\n    return hashlib.sha256(data.encode()).hexdigest()\n\ndef check_idempotency(idempotency_key: str) -> Optional[str]:\n    \"\"\"\n    Check if idempotency key already used.\n\n    Generated from: C-050\n\n    Returns:\n        Existing charge_id if key used, None if new\n    \"\"\"\n    # Implements: C-050\n    from .models import Payment\n    existing = Payment.get_by_idempotency_key(idempotency_key)\n    if existing:\n        return existing.charge_id\n    return None\n\n# Generated tests\ndef test_generate_idempotency_key_deterministic():\n    key1 = generate_idempotency_key(\"user123\", 100.00, 1637000000)\n    key2 = generate_idempotency_key(\"user123\", 100.00, 1637000000)\n    assert key1 == key2  # Same inputs â†’ same key\n\ndef test_check_idempotency_new_key():\n    key = generate_idempotency_key(\"user123\", 100.00, 1637000000)\n    assert check_idempotency(key) is None\n```\n\n---\n\n## Prerequisites Check\n\nBefore invoking this skill, ensure:\n1. Constraints (C-*) exist with detailed specifications\n2. Specifications include: values, behaviors, error messages\n\nIf C-* too vague:\n- Ask user: \"C-001 says 'API timeout' - what timeout value should I use?\"\n\n---\n\n## Next Steps\n\nAfter constraint generation:\n1. Run generated tests (verify all pass)\n2. Commit generated code\n3. Integrate into feature implementation\n\n---\n\n## Notes\n\n**Why autogenerate constraints?**\n- **Compliance**: Ensures constraints are enforced in code\n- **Consistency**: All constraints follow same pattern\n- **Documentation**: Generated code includes constraint rationale\n- **Testability**: Constraints are verified via tests\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  all_constraints_have_code: true\n  all_constraint_code_has_tests: true\n  all_tests_passing: true\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/generation/autogenerate-formulas/SKILL.md": "---\nname: autogenerate-formulas\ndescription: Autogenerate formula implementations from formula specifications (F-*). Converts mathematical formulas, calculations, and algorithms into production code with tests. Use when F-* includes formula specifications.\nallowed-tools: [Read, Write, Edit]\n---\n\n# autogenerate-formulas\n\n**Skill Type**: Actuator (Code Generation)\n**Purpose**: Generate formula implementations from F-* specifications\n**Prerequisites**:\n- Formula specifications (F-*) with mathematical definitions\n\n---\n\n## Agent Instructions\n\nYou are **autogenerating formulas** from **formula specifications**.\n\nYour goal is to transform **structured F-* formulas** into **calculation functions** with tests.\n\n---\n\n## Generation Patterns\n\n### Pattern 1: Simple Arithmetic Formulas\n\n**Input**:\n```yaml\nF-001: Stripe fee calculation\n  Formula: fee = (amount * 0.029) + 0.30\n  Inputs: amount (float)\n  Output: fee (float, rounded to 2 decimals)\n```\n\n**Generated**:\n```python\n# Generated from: F-001\nSTRIPE_PERCENTAGE_FEE = 0.029  # 2.9%\nSTRIPE_FIXED_FEE = 0.30        # $0.30\n\ndef calculate_stripe_fee(amount: float) -> float:\n    \"\"\"\n    Calculate Stripe processing fee.\n\n    Generated from: F-001 (Stripe fee calculation)\n\n    Formula: fee = (amount * 0.029) + 0.30\n\n    Args:\n        amount: Payment amount in dollars\n\n    Returns:\n        Processing fee in dollars (rounded to 2 decimals)\n\n    Examples:\n        >>> calculate_stripe_fee(100.00)\n        3.20\n        >>> calculate_stripe_fee(1000.00)\n        29.30\n    \"\"\"\n    # Implements: F-001\n    fee = (amount * STRIPE_PERCENTAGE_FEE) + STRIPE_FIXED_FEE\n    return round(fee, 2)\n\n# Generated tests\ndef test_calculate_stripe_fee_100_dollars():\n    assert calculate_stripe_fee(100.00) == 3.20\n\ndef test_calculate_stripe_fee_1000_dollars():\n    assert calculate_stripe_fee(1000.00) == 29.30\n\ndef test_calculate_stripe_fee_minimum_charge():\n    # For $0.01, fee is still $0.30 fixed + 0.0003% â‰ˆ $0.30\n    assert calculate_stripe_fee(0.01) == 0.30\n```\n\n---\n\n### Pattern 2: Date/Time Calculations\n\n**Input**:\n```yaml\nF-002: Password reset token expiry\n  Formula: expiry_time = issue_time + (60 * 60) seconds\n  Inputs: issue_time (datetime)\n  Output: expiry_time (datetime)\n```\n\n**Generated**:\n```python\n# Generated from: F-002\nfrom datetime import datetime, timedelta\n\nTOKEN_EXPIRY_SECONDS = 60 * 60  # 1 hour\n\ndef calculate_token_expiry(issue_time: datetime) -> datetime:\n    \"\"\"\n    Calculate password reset token expiry time.\n\n    Generated from: F-002 (Token expiry calculation)\n\n    Formula: expiry_time = issue_time + 3600 seconds\n\n    Args:\n        issue_time: When token was issued\n\n    Returns:\n        Expiry time (1 hour after issue)\n\n    Examples:\n        >>> issue = datetime(2025, 11, 20, 10, 0, 0)\n        >>> expiry = calculate_token_expiry(issue)\n        >>> expiry\n        datetime(2025, 11, 20, 11, 0, 0)\n    \"\"\"\n    # Implements: F-002\n    return issue_time + timedelta(seconds=TOKEN_EXPIRY_SECONDS)\n\n# Generated tests\ndef test_token_expiry_one_hour():\n    issue = datetime(2025, 11, 20, 10, 0, 0)\n    expiry = calculate_token_expiry(issue)\n    assert expiry == datetime(2025, 11, 20, 11, 0, 0)\n\ndef test_token_expiry_across_day_boundary():\n    issue = datetime(2025, 11, 20, 23, 30, 0)\n    expiry = calculate_token_expiry(issue)\n    assert expiry == datetime(2025, 11, 21, 0, 30, 0)\n```\n\n---\n\n### Pattern 3: Compound Interest / Growth Formulas\n\n**Input**:\n```yaml\nF-010: Compound interest\n  Formula: A = P(1 + r/n)^(nt)\n  Inputs:\n    - P: principal amount\n    - r: annual interest rate (decimal)\n    - n: compounding frequency (times per year)\n    - t: time in years\n  Output: A (final amount, rounded to 2 decimals)\n```\n\n**Generated**:\n```python\n# Generated from: F-010\nimport math\n\ndef calculate_compound_interest(\n    principal: float,\n    rate: float,\n    compounding_frequency: int,\n    years: float\n) -> float:\n    \"\"\"\n    Calculate compound interest.\n\n    Generated from: F-010 (Compound interest formula)\n\n    Formula: A = P(1 + r/n)^(nt)\n\n    Args:\n        principal: Initial principal amount\n        rate: Annual interest rate (decimal, e.g., 0.05 for 5%)\n        compounding_frequency: Times compounded per year (e.g., 12 for monthly)\n        years: Time period in years\n\n    Returns:\n        Final amount (rounded to 2 decimals)\n\n    Examples:\n        >>> calculate_compound_interest(1000, 0.05, 12, 1)\n        1051.16\n        >>> calculate_compound_interest(1000, 0.05, 1, 5)\n        1276.28\n    \"\"\"\n    # Implements: F-010\n    amount = principal * math.pow(\n        1 + (rate / compounding_frequency),\n        compounding_frequency * years\n    )\n    return round(amount, 2)\n\n# Generated tests\ndef test_compound_interest_monthly_one_year():\n    # $1000 at 5% compounded monthly for 1 year\n    result = calculate_compound_interest(1000, 0.05, 12, 1)\n    assert result == 1051.16\n\ndef test_compound_interest_annually_five_years():\n    # $1000 at 5% compounded annually for 5 years\n    result = calculate_compound_interest(1000, 0.05, 1, 5)\n    assert result == 1276.28\n```\n\n---\n\n### Pattern 4: Percentage Calculations\n\n**Input**:\n```yaml\nF-020: Discount calculation\n  Formula: discounted_price = original_price * (1 - discount_percentage)\n  Inputs:\n    - original_price: float\n    - discount_percentage: float (0.0 to 1.0)\n  Output: discounted_price (float, rounded to 2 decimals)\n  Constraints: discount_percentage must be 0.0 to 1.0\n```\n\n**Generated**:\n```python\n# Generated from: F-020\ndef calculate_discounted_price(original_price: float, discount_percentage: float) -> float:\n    \"\"\"\n    Calculate discounted price.\n\n    Generated from: F-020 (Discount calculation)\n\n    Formula: discounted_price = original_price * (1 - discount_percentage)\n\n    Args:\n        original_price: Original price before discount\n        discount_percentage: Discount as decimal (0.0 to 1.0)\n\n    Returns:\n        Discounted price (rounded to 2 decimals)\n\n    Raises:\n        ValueError: If discount_percentage not in range [0.0, 1.0]\n\n    Examples:\n        >>> calculate_discounted_price(100.00, 0.20)\n        80.00\n        >>> calculate_discounted_price(50.00, 0.50)\n        25.00\n    \"\"\"\n    # Implements: F-020\n    # Constraint: discount_percentage must be 0.0 to 1.0\n    if not 0.0 <= discount_percentage <= 1.0:\n        raise ValueError(\"Discount percentage must be between 0.0 and 1.0\")\n\n    discounted = original_price * (1 - discount_percentage)\n    return round(discounted, 2)\n\n# Generated tests\ndef test_discount_20_percent():\n    assert calculate_discounted_price(100.00, 0.20) == 80.00\n\ndef test_discount_50_percent():\n    assert calculate_discounted_price(50.00, 0.50) == 25.00\n\ndef test_discount_0_percent():\n    assert calculate_discounted_price(100.00, 0.00) == 100.00\n\ndef test_discount_100_percent():\n    assert calculate_discounted_price(100.00, 1.00) == 0.00\n\ndef test_discount_invalid_negative():\n    with pytest.raises(ValueError):\n        calculate_discounted_price(100.00, -0.10)\n\ndef test_discount_invalid_over_100():\n    with pytest.raises(ValueError):\n        calculate_discounted_price(100.00, 1.50)\n```\n\n---\n\n### Pattern 5: Hash/Checksum Formulas\n\n**Input**:\n```yaml\nF-030: Idempotency key generation\n  Formula: key = SHA256(merchant_id + timestamp + amount + card_last4)\n  Inputs:\n    - merchant_id: string\n    - timestamp: int (unix timestamp)\n    - amount: float\n    - card_last4: string (last 4 digits)\n  Output: key (hex string)\n```\n\n**Generated**:\n```python\n# Generated from: F-030\nimport hashlib\n\ndef generate_idempotency_key(\n    merchant_id: str,\n    timestamp: int,\n    amount: float,\n    card_last4: str\n) -> str:\n    \"\"\"\n    Generate idempotency key for payment.\n\n    Generated from: F-030 (Idempotency key generation)\n\n    Formula: SHA256(merchant_id + timestamp + amount + card_last4)\n\n    Args:\n        merchant_id: Merchant identifier\n        timestamp: Unix timestamp\n        amount: Payment amount\n        card_last4: Last 4 digits of card\n\n    Returns:\n        SHA256 hex digest as idempotency key\n\n    Examples:\n        >>> key = generate_idempotency_key(\"merch_123\", 1637000000, 100.00, \"4242\")\n        >>> len(key)\n        64\n    \"\"\"\n    # Implements: F-030\n    data = f\"{merchant_id}{timestamp}{amount}{card_last4}\"\n    return hashlib.sha256(data.encode()).hexdigest()\n\n# Generated tests\ndef test_idempotency_key_deterministic():\n    # Same inputs â†’ same key\n    key1 = generate_idempotency_key(\"merch_123\", 1637000000, 100.00, \"4242\")\n    key2 = generate_idempotency_key(\"merch_123\", 1637000000, 100.00, \"4242\")\n    assert key1 == key2\n\ndef test_idempotency_key_different_timestamp():\n    # Different timestamp â†’ different key\n    key1 = generate_idempotency_key(\"merch_123\", 1637000000, 100.00, \"4242\")\n    key2 = generate_idempotency_key(\"merch_123\", 1637000001, 100.00, \"4242\")\n    assert key1 != key2\n\ndef test_idempotency_key_length():\n    key = generate_idempotency_key(\"merch_123\", 1637000000, 100.00, \"4242\")\n    assert len(key) == 64  # SHA256 hex = 64 chars\n```\n\n---\n\n### Pattern 6: Conversion Formulas\n\n**Input**:\n```yaml\nF-040: Temperature conversion\n  Formula: celsius = (fahrenheit - 32) * 5/9\n  Inputs: fahrenheit (float)\n  Output: celsius (float, rounded to 1 decimal)\n```\n\n**Generated**:\n```python\n# Generated from: F-040\ndef fahrenheit_to_celsius(fahrenheit: float) -> float:\n    \"\"\"\n    Convert Fahrenheit to Celsius.\n\n    Generated from: F-040 (Temperature conversion)\n\n    Formula: celsius = (fahrenheit - 32) * 5/9\n\n    Args:\n        fahrenheit: Temperature in Fahrenheit\n\n    Returns:\n        Temperature in Celsius (rounded to 1 decimal)\n\n    Examples:\n        >>> fahrenheit_to_celsius(32.0)\n        0.0\n        >>> fahrenheit_to_celsius(212.0)\n        100.0\n        >>> fahrenheit_to_celsius(98.6)\n        37.0\n    \"\"\"\n    # Implements: F-040\n    celsius = (fahrenheit - 32) * 5 / 9\n    return round(celsius, 1)\n\n# Generated tests\ndef test_fahrenheit_to_celsius_freezing():\n    assert fahrenheit_to_celsius(32.0) == 0.0\n\ndef test_fahrenheit_to_celsius_boiling():\n    assert fahrenheit_to_celsius(212.0) == 100.0\n\ndef test_fahrenheit_to_celsius_body_temp():\n    assert fahrenheit_to_celsius(98.6) == 37.0\n```\n\n---\n\n## Test Generation Strategy\n\n**For every formula, generate**:\n1. **Known value tests**: Use example values with known results\n2. **Boundary tests**: Test formula at edges (0, max, min)\n3. **Inverse tests**: If inverse formula exists, verify `f(f_inv(x)) == x`\n4. **Edge cases**: Test with special values (0, negative, very large)\n\n---\n\n## Output Format\n\n```\n[FORMULA GENERATION]\n\nInput: 5 formulas\n\nGenerated Formulas:\n  âœ“ calculate_stripe_fee() from F-001\n  âœ“ calculate_token_expiry() from F-002\n  âœ“ generate_idempotency_key() from F-030\n  âœ“ calculate_compound_interest() from F-010\n  âœ“ fahrenheit_to_celsius() from F-040\n\nGenerated Constants:\n  âœ“ STRIPE_PERCENTAGE_FEE = 0.029\n  âœ“ STRIPE_FIXED_FEE = 0.30\n  âœ“ TOKEN_EXPIRY_SECONDS = 3600\n\nGenerated Tests:\n  âœ“ 20 tests (5 formulas Ã— 4 tests average)\n\nRunning tests...\n  âœ“ All 20 tests PASSING\n\nFiles:\n  + src/calculations.py (5 formulas, 145 lines)\n  + tests/test_calculations.py (20 tests, 127 lines)\n```\n\n---\n\n## Prerequisites Check\n\nBefore invoking this skill, ensure:\n1. Formulas (F-*) exist with complete specifications\n2. Formula includes: inputs, formula expression, output format\n\nIf F-* too vague:\n- Ask user: \"F-001 says 'fee calculation' - what's the formula?\"\n\n---\n\n## Notes\n\n**Why autogenerate formulas?**\n- **Accuracy**: No manual coding errors in calculations\n- **Documentation**: Formula is in code + docstring\n- **Testability**: Generated tests verify formula correctness\n- **Consistency**: All formulas follow same pattern\n\n**Formula complexity handling**:\n- **Simple formulas** (F = ma): Direct translation\n- **Complex formulas** (compound interest): Use math library\n- **Multi-step formulas**: Break into helper functions\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  all_formulas_have_code: true\n  all_formula_code_has_tests: true\n  all_tests_passing: true\n  formulas_documented: true\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/generation/autogenerate-from-business-rules/SKILL.md": "---\nname: autogenerate-from-business-rules\ndescription: Autogenerate production code from disambiguated business rules (BR-*). Converts BR-* specifications into validators, constants, and logic. Use when requirements have been disambiguated into BR-*, C-*, F-* format.\nallowed-tools: [Read, Write, Edit, Bash]\n---\n\n# autogenerate-from-business-rules\n\n**Skill Type**: Actuator (Code Generation)\n**Purpose**: Autogenerate production code from business rules (BR-*)\n**Prerequisites**:\n- Requirements disambiguated into BR-*, C-*, F-* format\n- Requirement key (REQ-*) available\n\n---\n\n## Agent Instructions\n\nYou are **autogenerating code** from **disambiguated business rules**.\n\nYour goal is to transform **structured BR-* specifications** into **production code** with tests.\n\n**This is NOT traditional coding** - you are translating formal specifications into executable code.\n\n---\n\n## Workflow\n\n### Step 1: Parse Business Rules\n\n**Read requirement and extract BR-* rules**:\n\n**Example**:\n```yaml\n<REQ-ID>: User login with email and password\n\nBusiness Rules:\n- BR-001: Email validation\n  - Format: regex ^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\n  - Error message: \"Invalid email format\"\n\n- BR-002: Password minimum length\n  - Minimum: 12 characters\n  - Error message: \"Password must be at least 12 characters\"\n\n- BR-003: Account lockout\n  - Max attempts: 3\n  - Lockout duration: 15 minutes\n  - Error message: \"Account locked. Try again in {remaining} minutes\"\n\n- BR-004: Email must be unique\n  - Check: User.exists(email) must be false\n  - Error message: \"Email already registered\"\n```\n\n---\n\n### Step 2: Generate Constants from BR-*\n\n**Extract constants** from business rules:\n\n```python\n# src/auth/constants.py\n# Generated from: <REQ-ID>\n\n# BR-001: Email validation\nEMAIL_REGEX = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\nEMAIL_VALIDATION_ERROR = \"Invalid email format\"\n\n# BR-002: Password minimum length\nPASSWORD_MIN_LENGTH = 12\nPASSWORD_LENGTH_ERROR = \"Password must be at least 12 characters\"\n\n# BR-003: Account lockout\nMAX_LOGIN_ATTEMPTS = 3\nLOCKOUT_DURATION_MINUTES = 15\nLOCKOUT_ERROR_TEMPLATE = \"Account locked. Try again in {remaining} minutes\"\n\n# BR-004: Email uniqueness\nEMAIL_UNIQUE_ERROR = \"Email already registered\"\n```\n\n**Generated automatically from**:\n- Numbers â†’ constants (12 â†’ PASSWORD_MIN_LENGTH)\n- Strings â†’ error messages (â†’ constants)\n- Patterns â†’ regex patterns\n\n---\n\n### Step 3: Generate Validators from BR-*\n\n**Invoke**: `autogenerate-validators` skill (sub-skill)\n\n**Generate validation functions**:\n\n```python\n# src/auth/validators.py\n# Generated from: <REQ-ID>\n\nimport re\nfrom typing import Optional\nfrom .constants import (\n    EMAIL_REGEX, EMAIL_VALIDATION_ERROR,\n    PASSWORD_MIN_LENGTH, PASSWORD_LENGTH_ERROR\n)\n\n\ndef validate_email(email: str) -> Optional[str]:\n    \"\"\"\n    Validate email format.\n\n    Generated from: BR-001 (Email validation)\n\n    Args:\n        email: Email address to validate\n\n    Returns:\n        None if valid, error message if invalid\n\n    Examples:\n        >>> validate_email(\"user@example.com\")\n        None\n        >>> validate_email(\"invalid\")\n        'Invalid email format'\n    \"\"\"\n    # Generated from: BR-001\n    if not re.match(EMAIL_REGEX, email):\n        return EMAIL_VALIDATION_ERROR\n    return None\n\n\ndef validate_password_length(password: str) -> Optional[str]:\n    \"\"\"\n    Validate password meets minimum length requirement.\n\n    Generated from: BR-002 (Password minimum length)\n\n    Args:\n        password: Password to validate\n\n    Returns:\n        None if valid, error message if invalid\n\n    Examples:\n        >>> validate_password_length(\"SecurePassword123!\")\n        None\n        >>> validate_password_length(\"short\")\n        'Password must be at least 12 characters'\n    \"\"\"\n    # Generated from: BR-002\n    if len(password) < PASSWORD_MIN_LENGTH:\n        return PASSWORD_LENGTH_ERROR\n    return None\n\n\ndef validate_email_unique(email: str) -> Optional[str]:\n    \"\"\"\n    Validate email is not already registered.\n\n    Generated from: BR-004 (Email uniqueness)\n\n    Args:\n        email: Email address to check\n\n    Returns:\n        None if unique, error message if already exists\n\n    Examples:\n        >>> validate_email_unique(\"new@example.com\")\n        None\n        >>> validate_email_unique(\"existing@example.com\")\n        'Email already registered'\n    \"\"\"\n    # Generated from: BR-004\n    from .models import User\n    if User.exists(email):\n        return EMAIL_UNIQUE_ERROR\n    return None\n```\n\n**Key features of generated validators**:\n- âœ… Tagged with BR-* key in comments\n- âœ… Comprehensive docstrings with examples\n- âœ… Return `None` for valid, error message for invalid\n- âœ… Type hints for clarity\n- âœ… Use constants (no magic numbers/strings)\n\n---\n\n### Step 4: Generate Logic from BR-*\n\n**Generate business logic functions**:\n\n```python\n# src/auth/lockout.py\n# Generated from: <REQ-ID>\n\nfrom datetime import datetime, timedelta\nfrom typing import Optional\nfrom .constants import MAX_LOGIN_ATTEMPTS, LOCKOUT_DURATION_MINUTES\n\n\nclass LoginAttemptTracker:\n    \"\"\"\n    Track login attempts and manage account lockout.\n\n    Generated from: BR-003 (Account lockout)\n    \"\"\"\n\n    def __init__(self):\n        self.failed_attempts = 0\n        self.locked_until: Optional[datetime] = None\n\n    def is_locked(self) -> bool:\n        \"\"\"\n        Check if account is currently locked.\n\n        Generated from: BR-003\n\n        Returns:\n            True if locked, False otherwise\n        \"\"\"\n        # Generated from: BR-003\n        if self.locked_until is None:\n            return False\n        return datetime.now() < self.locked_until\n\n    def record_failed_attempt(self) -> bool:\n        \"\"\"\n        Record a failed login attempt and lock if threshold reached.\n\n        Generated from: BR-003\n\n        Returns:\n            True if account locked, False otherwise\n        \"\"\"\n        # Generated from: BR-003\n        self.failed_attempts += 1\n\n        if self.failed_attempts >= MAX_LOGIN_ATTEMPTS:\n            self.locked_until = datetime.now() + timedelta(minutes=LOCKOUT_DURATION_MINUTES)\n            return True\n\n        return False\n\n    def reset_attempts(self) -> None:\n        \"\"\"Reset failed attempts after successful login\"\"\"\n        # Generated from: BR-003\n        self.failed_attempts = 0\n        self.locked_until = None\n\n    def get_remaining_lockout_time(self) -> Optional[int]:\n        \"\"\"\n        Get remaining lockout time in minutes.\n\n        Generated from: BR-003\n\n        Returns:\n            Minutes remaining if locked, None if not locked\n        \"\"\"\n        # Generated from: BR-003\n        if not self.is_locked():\n            return None\n        return (self.locked_until - datetime.now()).seconds // 60\n```\n\n---\n\n### Step 5: Generate Tests for Generated Code\n\n**Auto-generate tests** for all generated code:\n\n```python\n# tests/auth/test_validators.py\n# Generated from: <REQ-ID>\n\nimport pytest\nfrom src.auth.validators import (\n    validate_email,\n    validate_password_length,\n    validate_email_unique\n)\n\n\nclass TestEmailValidation:\n    \"\"\"Tests for BR-001: Email validation\"\"\"\n\n    def test_valid_email(self):\n        # Generated from: BR-001\n        assert validate_email(\"user@example.com\") is None\n\n    def test_invalid_email_no_at_sign(self):\n        # Generated from: BR-001\n        assert validate_email(\"invalid\") == \"Invalid email format\"\n\n    def test_invalid_email_no_domain(self):\n        # Generated from: BR-001\n        assert validate_email(\"user@\") == \"Invalid email format\"\n\n    def test_invalid_email_no_tld(self):\n        # Generated from: BR-001\n        assert validate_email(\"user@example\") == \"Invalid email format\"\n\n\nclass TestPasswordValidation:\n    \"\"\"Tests for BR-002: Password minimum length\"\"\"\n\n    def test_valid_password(self):\n        # Generated from: BR-002\n        assert validate_password_length(\"SecurePassword123!\") is None\n\n    def test_password_exactly_12_chars(self):\n        # Generated from: BR-002\n        assert validate_password_length(\"12Characters\") is None\n\n    def test_password_too_short(self):\n        # Generated from: BR-002\n        assert validate_password_length(\"short\") == \"Password must be at least 12 characters\"\n\n    def test_password_11_chars(self):\n        # Generated from: BR-002 (boundary test)\n        assert validate_password_length(\"11Character\") == \"Password must be at least 12 characters\"\n```\n\n---\n\n### Step 6: Run Generated Tests\n\n**Verify generated code works**:\n\n```bash\npytest tests/auth/test_validators.py -v\n```\n\n**Expected**: All generated tests PASS âœ“\n\n---\n\n### Step 7: Commit Generated Code\n\n**Create commit**:\n\n```bash\ngit add src/auth/constants.py src/auth/validators.py src/auth/lockout.py tests/auth/test_validators.py\ngit commit -m \"GEN: Autogenerate code from BR-* for <REQ-ID>\n\nAutogenerate production code and tests from business rules.\n\nGenerated from Business Rules:\n- BR-001: Email validation â†’ validate_email() + tests\n- BR-002: Password minimum length â†’ validate_password_length() + tests\n- BR-003: Account lockout â†’ LoginAttemptTracker class + tests\n- BR-004: Email uniqueness â†’ validate_email_unique() + tests\n\nFiles Generated:\n- src/auth/constants.py (14 constants)\n- src/auth/validators.py (3 validators, 87 lines)\n- src/auth/lockout.py (LoginAttemptTracker, 76 lines)\n- tests/auth/test_validators.py (24 tests, 142 lines)\n\nTests: 24 tests, all passing âœ“\nCoverage: 100%\n\nGenerated from: <REQ-ID> (BR-001, BR-002, BR-003, BR-004)\n\"\n```\n\n---\n\n## Output Format\n\nWhen you complete code generation, show:\n\n```\n[CODE GENERATION - <REQ-ID>]\n\nParsed Business Rules:\n  âœ“ BR-001: Email validation (regex pattern)\n  âœ“ BR-002: Password minimum length (12 chars)\n  âœ“ BR-003: Account lockout (3 attempts, 15min)\n  âœ“ BR-004: Email uniqueness check\n\nGenerated Constants:\n  âœ“ EMAIL_REGEX = r'^[a-zA-Z0-9._%+-]+@...'\n  âœ“ EMAIL_VALIDATION_ERROR = \"Invalid email format\"\n  âœ“ PASSWORD_MIN_LENGTH = 12\n  âœ“ PASSWORD_LENGTH_ERROR = \"Password must be at least 12 characters\"\n  âœ“ MAX_LOGIN_ATTEMPTS = 3\n  âœ“ LOCKOUT_DURATION_MINUTES = 15\n  âœ“ 8 more constants...\n\nGenerated Validators:\n  âœ“ validate_email() from BR-001\n  âœ“ validate_password_length() from BR-002\n  âœ“ validate_email_unique() from BR-004\n\nGenerated Logic:\n  âœ“ LoginAttemptTracker class from BR-003\n    - is_locked() method\n    - record_failed_attempt() method\n    - reset_attempts() method\n    - get_remaining_lockout_time() method\n\nGenerated Tests:\n  âœ“ 24 tests for all validators and logic\n  âœ“ Happy path tests\n  âœ“ Error case tests\n  âœ“ Boundary tests\n\nFiles Generated:\n  + src/auth/constants.py (14 constants, 28 lines)\n  + src/auth/validators.py (3 validators, 87 lines)\n  + src/auth/lockout.py (1 class, 76 lines)\n  + tests/auth/test_validators.py (24 tests, 142 lines)\n\nRunning generated tests...\n  âœ“ All 24 tests PASSING\n\nCoverage: 100%\n\nCommit: GEN: Autogenerate code from BR-* for <REQ-ID>\n\nâœ… Code Generation Complete!\n   Generated: 333 lines of production code + tests\n   From: 4 business rules (BR-001, BR-002, BR-003, BR-004)\n   Ratio: 1 BR â†’ 83 lines of code (average)\n```\n\n---\n\n## Prerequisites Check\n\nBefore invoking this skill, ensure:\n1. Requirements have been disambiguated (BR-*, C-*, F-* exist)\n2. Requirement key (REQ-*) available\n3. Business rules are sufficiently detailed for code generation\n\nIf prerequisites not met:\n- No BR-* â†’ Invoke `disambiguate-requirements` skill (from requirements-skills plugin)\n- Vague BR-* â†’ Ask user for clarification\n\n---\n\n## Skills Used\n\nThis orchestrator skill invokes:\n1. `autogenerate-validators` - Generate validation functions from BR-*\n2. `autogenerate-constraints` - Generate constraint checks from C-*\n3. `autogenerate-formulas` - Generate formula implementations from F-*\n\n---\n\n## Generation Patterns\n\n### Pattern 1: Validation Rules â†’ Validators\n\n**Input**:\n```yaml\nBR-001: Email validation\n  Format: regex ^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\n  Error: \"Invalid email format\"\n```\n\n**Generated**:\n```python\nEMAIL_REGEX = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n\ndef validate_email(email: str) -> Optional[str]:\n    if not re.match(EMAIL_REGEX, email):\n        return \"Invalid email format\"\n    return None\n```\n\n### Pattern 2: Min/Max Constraints â†’ Validators\n\n**Input**:\n```yaml\nBR-002: Password length\n  Minimum: 12 characters\n  Maximum: 128 characters\n```\n\n**Generated**:\n```python\nPASSWORD_MIN_LENGTH = 12\nPASSWORD_MAX_LENGTH = 128\n\ndef validate_password_length(password: str) -> Optional[str]:\n    if len(password) < PASSWORD_MIN_LENGTH:\n        return f\"Password must be at least {PASSWORD_MIN_LENGTH} characters\"\n    if len(password) > PASSWORD_MAX_LENGTH:\n        return f\"Password must be at most {PASSWORD_MAX_LENGTH} characters\"\n    return None\n```\n\n### Pattern 3: Enumerated Values â†’ Validators\n\n**Input**:\n```yaml\nBR-005: Card types\n  Allowed: [\"Visa\", \"Mastercard\"]\n  Error: \"Card type not supported\"\n```\n\n**Generated**:\n```python\nALLOWED_CARD_TYPES = [\"Visa\", \"Mastercard\"]\n\ndef validate_card_type(card_type: str) -> Optional[str]:\n    if card_type not in ALLOWED_CARD_TYPES:\n        return \"Card type not supported\"\n    return None\n```\n\n### Pattern 4: Rate Limits â†’ Trackers\n\n**Input**:\n```yaml\nBR-006: Rate limiting\n  Max requests: 100 per hour per user\n  Error: \"Rate limit exceeded. Try again in {remaining} minutes\"\n```\n\n**Generated**:\n```python\nMAX_REQUESTS_PER_HOUR = 100\n\nclass RateLimitTracker:\n    def __init__(self):\n        self.requests = []\n\n    def check_rate_limit(self, user_id: str) -> Optional[str]:\n        # Remove requests older than 1 hour\n        cutoff = datetime.now() - timedelta(hours=1)\n        self.requests = [r for r in self.requests if r.timestamp > cutoff]\n\n        # Check if limit exceeded\n        user_requests = [r for r in self.requests if r.user_id == user_id]\n        if len(user_requests) >= MAX_REQUESTS_PER_HOUR:\n            # Calculate remaining time\n            oldest = min(r.timestamp for r in user_requests)\n            remaining = 60 - (datetime.now() - oldest).seconds // 60\n            return f\"Rate limit exceeded. Try again in {remaining} minutes\"\n\n        return None\n\n    def record_request(self, user_id: str) -> None:\n        self.requests.append(Request(user_id, datetime.now()))\n```\n\n---\n\n### Step 8: Generate Tests (Auto-Test Generation)\n\n**For every generated function, generate tests**:\n\n**Generation rule**:\n- 1 happy path test (valid input)\n- 1 error case test (invalid input)\n- 1 boundary test (edge of valid range)\n- 1 null/empty test (if applicable)\n\n**Example**:\n```python\n# Auto-generated from BR-001\ndef test_validate_email_valid():\n    assert validate_email(\"user@example.com\") is None\n\ndef test_validate_email_invalid():\n    assert validate_email(\"invalid\") == \"Invalid email format\"\n\ndef test_validate_email_empty():\n    assert validate_email(\"\") == \"Invalid email format\"\n\ndef test_validate_email_null():\n    with pytest.raises(TypeError):\n        validate_email(None)\n```\n\n---\n\n## Prerequisites Check\n\nBefore invoking this skill, ensure:\n1. Requirements have BR-* specifications\n2. BR-* are sufficiently detailed (include formats, error messages, thresholds)\n\nIf BR-* too vague:\n- Ask user: \"BR-001 says 'Email validation' - what regex pattern should I use?\"\n- Suggest: \"Should I use standard email regex or custom pattern?\"\n\n---\n\n## Next Steps\n\nAfter code generation:\n1. Run generated tests (verify all pass)\n2. Commit generated code\n3. Integrate generated code into feature implementation (TDD or BDD workflow)\n\n---\n\n## Configuration\n\nThis skill respects configuration in `.claude/plugins.yml`:\n\n```yaml\nplugins:\n  - name: \"@aisdlc/code-skills\"\n    config:\n      code_generation:\n        auto_generate_from_br: true           # Auto-invoke when BR-* detected\n        auto_generate_validators: true\n        auto_generate_tests: true             # Generate tests for generated code\n        require_tests_for_generated_code: true\n        language: \"python\"                    # Target language\n```\n\n---\n\n## Language-Specific Generation\n\n### Python\n- Constants: UPPER_SNAKE_CASE\n- Functions: snake_case\n- Classes: PascalCase\n- Type hints: Required\n- Docstrings: Google style\n\n### TypeScript\n- Constants: UPPER_SNAKE_CASE\n- Functions: camelCase\n- Classes: PascalCase\n- Type annotations: Required\n- JSDoc: Required\n\n### Java\n- Constants: UPPER_SNAKE_CASE\n- Methods: camelCase\n- Classes: PascalCase\n- Javadoc: Required\n- Annotations: Required\n\n---\n\n## Notes\n\n**Why autogenerate from BR-*?**\n- **Eliminates manual coding** for common patterns\n- **Reduces errors** (no typos in validation logic)\n- **Ensures consistency** (all validators follow same pattern)\n- **Speeds development** (BR-* â†’ code in seconds)\n- **Maintains traceability** (generated code tagged with BR-*)\n\n**What can be autogenerated**:\n- âœ… Validators (regex, min/max, enum)\n- âœ… Constants (numbers, strings, patterns)\n- âœ… Error messages\n- âœ… State machines (lockout, rate limiting)\n- âœ… Tests for all generated code\n\n**What CANNOT be autogenerated**:\n- âŒ Complex business logic (requires human judgment)\n- âŒ UI/UX decisions\n- âŒ Integration with external systems\n- âŒ Optimization strategies\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  all_br_rules_have_code: true\n  generated_code_has_tests: true\n  generated_tests_passing: true\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/generation/autogenerate-validators/SKILL.md": "---\nname: autogenerate-validators\ndescription: Autogenerate validation functions from business rules (BR-*) that specify formats, patterns, ranges, or constraints. Use when BR-* includes validation specifications like regex patterns, min/max values, or allowed values.\nallowed-tools: [Read, Write, Edit]\n---\n\n# autogenerate-validators\n\n**Skill Type**: Actuator (Code Generation)\n**Purpose**: Generate validation functions from BR-* rules\n**Prerequisites**:\n- Business rules (BR-*) with validation specifications\n\n---\n\n## Agent Instructions\n\nYou are **autogenerating validators** from **business rule specifications**.\n\nYour goal is to transform **structured validation rules** (BR-*) into **validation functions** with tests.\n\n---\n\n## Generation Patterns\n\n### Pattern 1: Regex Validation\n\n**Input**:\n```yaml\nBR-001: Email validation\n  Format: regex ^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\n  Error: \"Invalid email format\"\n```\n\n**Generated**:\n```python\n# Generated from: BR-001\nimport re\n\nEMAIL_REGEX = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n\ndef validate_email(email: str) -> Optional[str]:\n    \"\"\"Validate email format (BR-001)\"\"\"\n    if not re.match(EMAIL_REGEX, email):\n        return \"Invalid email format\"\n    return None\n\n# Generated tests\ndef test_validate_email_valid():\n    assert validate_email(\"user@example.com\") is None\n\ndef test_validate_email_invalid():\n    assert validate_email(\"invalid\") == \"Invalid email format\"\n```\n\n---\n\n### Pattern 2: Range Validation (Min/Max)\n\n**Input**:\n```yaml\nBR-010: Payment amount\n  Minimum: 0.01\n  Maximum: 10000.00\n  Error: \"Amount must be between $0.01 and $10,000\"\n```\n\n**Generated**:\n```python\n# Generated from: BR-010\nPAYMENT_MIN_AMOUNT = 0.01\nPAYMENT_MAX_AMOUNT = 10000.00\n\ndef validate_payment_amount(amount: float) -> Optional[str]:\n    \"\"\"Validate payment amount range (BR-010)\"\"\"\n    if amount < PAYMENT_MIN_AMOUNT or amount > PAYMENT_MAX_AMOUNT:\n        return \"Amount must be between $0.01 and $10,000\"\n    return None\n\n# Generated tests\ndef test_validate_amount_valid():\n    assert validate_payment_amount(100.00) is None\n\ndef test_validate_amount_below_min():\n    assert validate_payment_amount(0.005) == \"Amount must be between $0.01 and $10,000\"\n\ndef test_validate_amount_above_max():\n    assert validate_payment_amount(10001.00) == \"Amount must be between $0.01 and $10,000\"\n\ndef test_validate_amount_boundary_min():\n    assert validate_payment_amount(0.01) is None  # Exactly at minimum\n\ndef test_validate_amount_boundary_max():\n    assert validate_payment_amount(10000.00) is None  # Exactly at maximum\n```\n\n---\n\n### Pattern 3: Enum Validation (Allowed Values)\n\n**Input**:\n```yaml\nBR-005: Card types\n  Allowed: [\"Visa\", \"Mastercard\", \"Amex\"]\n  Error: \"Card type not supported\"\n```\n\n**Generated**:\n```python\n# Generated from: BR-005\nALLOWED_CARD_TYPES = [\"Visa\", \"Mastercard\", \"Amex\"]\n\ndef validate_card_type(card_type: str) -> Optional[str]:\n    \"\"\"Validate card type is supported (BR-005)\"\"\"\n    if card_type not in ALLOWED_CARD_TYPES:\n        return \"Card type not supported\"\n    return None\n\n# Generated tests\ndef test_validate_card_visa():\n    assert validate_card_type(\"Visa\") is None\n\ndef test_validate_card_mastercard():\n    assert validate_card_type(\"Mastercard\") is None\n\ndef test_validate_card_invalid():\n    assert validate_card_type(\"Discover\") == \"Card type not supported\"\n```\n\n---\n\n### Pattern 4: Length Validation\n\n**Input**:\n```yaml\nBR-020: Username length\n  Minimum: 3 characters\n  Maximum: 20 characters\n  Pattern: alphanumeric and underscore only\n  Error: \"Username must be 3-20 alphanumeric characters\"\n```\n\n**Generated**:\n```python\n# Generated from: BR-020\nUSERNAME_MIN_LENGTH = 3\nUSERNAME_MAX_LENGTH = 20\nUSERNAME_PATTERN = r'^[a-zA-Z0-9_]+$'\n\ndef validate_username(username: str) -> Optional[str]:\n    \"\"\"Validate username format and length (BR-020)\"\"\"\n    # Check length\n    if len(username) < USERNAME_MIN_LENGTH or len(username) > USERNAME_MAX_LENGTH:\n        return \"Username must be 3-20 alphanumeric characters\"\n\n    # Check pattern\n    if not re.match(USERNAME_PATTERN, username):\n        return \"Username must be 3-20 alphanumeric characters\"\n\n    return None\n\n# Generated tests\ndef test_validate_username_valid():\n    assert validate_username(\"user123\") is None\n\ndef test_validate_username_too_short():\n    assert validate_username(\"ab\") == \"Username must be 3-20 alphanumeric characters\"\n\ndef test_validate_username_invalid_chars():\n    assert validate_username(\"user@123\") == \"Username must be 3-20 alphanumeric characters\"\n```\n\n---\n\n### Pattern 5: Uniqueness Validation\n\n**Input**:\n```yaml\nBR-004: Email uniqueness\n  Check: User.exists(email) must be false\n  Error: \"Email already registered\"\n```\n\n**Generated**:\n```python\n# Generated from: BR-004\ndef validate_email_unique(email: str) -> Optional[str]:\n    \"\"\"Validate email is not already registered (BR-004)\"\"\"\n    from .models import User\n    if User.exists(email):\n        return \"Email already registered\"\n    return None\n\n# Generated tests\ndef test_validate_email_unique_new_email():\n    assert validate_email_unique(\"new@example.com\") is None\n\ndef test_validate_email_unique_existing_email(db_with_user):\n    # Assumes fixture creates user@example.com\n    assert validate_email_unique(\"user@example.com\") == \"Email already registered\"\n```\n\n---\n\n## Test Generation Rules\n\n**For every validator, generate**:\n1. **Happy path test**: Valid input â†’ None\n2. **Error case test**: Invalid input â†’ error message\n3. **Boundary tests**: Min/max edges\n4. **Empty/null tests**: Empty string, None\n5. **Format tests**: Specific invalid formats\n\n---\n\n## Output Format\n\n```\n[VALIDATOR GENERATION]\n\nInput: 4 business rules with validation specs\n\nGenerated Validators:\n  âœ“ validate_email() from BR-001 (regex pattern)\n  âœ“ validate_password_length() from BR-002 (min length)\n  âœ“ validate_email_unique() from BR-004 (uniqueness check)\n  âœ“ validate_card_type() from BR-005 (enum values)\n\nGenerated Constants:\n  âœ“ EMAIL_REGEX\n  âœ“ PASSWORD_MIN_LENGTH\n  âœ“ ALLOWED_CARD_TYPES\n\nGenerated Tests:\n  âœ“ 16 tests (4 validators Ã— 4 tests average)\n\nRunning tests...\n  âœ“ All 16 tests PASSING\n\nFiles:\n  + src/validators.py (4 validators, 72 lines)\n  + src/constants.py (7 constants, 14 lines)\n  + tests/test_validators.py (16 tests, 98 lines)\n```\n\n---\n\n## Notes\n\n**Why autogenerate validators?**\n- **Consistency**: All validators follow same pattern\n- **Completeness**: Comprehensive test coverage auto-generated\n- **Speed**: BR-* â†’ code in seconds\n- **Accuracy**: No manual coding errors\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  all_br_validation_rules_have_validators: true\n  all_validators_have_tests: true\n  all_tests_passing: true\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/tdd/commit-with-req-tag/SKILL.md": "---\nname: commit-with-req-tag\ndescription: Create final git commit with requirement traceability tags (REQ-*). Use after refactor-phase to finalize TDD cycle with proper requirement linkage for bidirectional traceability.\nallowed-tools: [Read, Bash, Grep, Glob]\n---\n\n# commit-with-req-tag\n\n**Skill Type**: Actuator (TDD Workflow)\n**Purpose**: Create final commit with requirement traceability (REQ-* keys)\n**Prerequisites**:\n- RED, GREEN, REFACTOR phases complete\n- Tests passing\n- Code quality verified\n- Requirement key (REQ-*) available\n\n---\n\n## Agent Instructions\n\nYou are creating the **final commit** for the TDD workflow with requirement traceability.\n\nYour goal is to create a commit that:\n1. **Links code to requirements** (forward traceability: REQ-* â†’ code)\n2. **Enables reverse lookup** (backward traceability: code â†’ REQ-*)\n3. **Provides clear context** for future developers\n4. **Follows semantic commit conventions** (feat:, fix:, refactor:, etc.)\n\n---\n\n## Workflow\n\n### Step 1: Gather Commit Information\n\n**Collect details**:\n- What requirement(s) were implemented? (REQ-*)\n- What business rules were implemented? (BR-*)\n- What constraints were implemented? (C-*)\n- What files were created/modified?\n- How many tests were added?\n- What was the test coverage?\n\n**Example**:\n```yaml\nRequirement: <REQ-ID>\nDescription: User login with email and password\nBusiness Rules: BR-001, BR-002, BR-003\nFiles Changed:\n  - src/auth/login.py (created, 87 lines)\n  - tests/auth/test_login.py (created, 94 lines)\nTests: 5 tests, all passing\nCoverage: 95%\n```\n\n---\n\n### Step 2: Determine Commit Type\n\n**Use semantic commit prefixes**:\n\n| Prefix | When to Use | Example |\n|--------|-------------|---------|\n| `feat:` | New functionality (REQ-F-*) | feat: Add user login |\n| `fix:` | Bug fix (remediation) | fix: Correct email validation |\n| `refactor:` | Code restructuring (REQ-NFR-*) | refactor: Simplify login logic |\n| `perf:` | Performance improvement (REQ-NFR-PERF-*) | perf: Optimize password hashing |\n| `test:` | Adding/fixing tests | test: Add edge cases for login |\n| `docs:` | Documentation only | docs: Update auth API docs |\n| `build:` | Build system changes | build: Update dependencies |\n| `ci:` | CI/CD changes | ci: Add auth tests to pipeline |\n\n**For most TDD workflows**: Use `feat:` (new feature) or `fix:` (bug fix)\n\n---\n\n### Step 3: Write Commit Message\n\n**Format**:\n```\n<type>: <subject> (REQ-<KEY>)\n\n<body>\n\n<footer>\n```\n\n**Components**:\n\n1. **Subject line** (< 72 chars):\n   - Prefix with type (feat:, fix:, etc.)\n   - Brief description\n   - REQ-* key in parentheses\n   - Example: `feat: Add user login (<REQ-ID>)`\n\n2. **Body** (detailed description):\n   - What was implemented?\n   - Why was it implemented?\n   - Business rules/constraints implemented\n   - Test coverage summary\n\n3. **Footer** (metadata):\n   - Requirement keys\n   - Business rule keys\n   - Test status\n   - Coverage percentage\n   - Co-authored-by (for AI pairing)\n\n---\n\n### Step 4: Create Full Commit Message\n\n**Template**:\n\n```\nfeat: Add user login (<REQ-ID>)\n\nImplement user authentication with email and password validation.\nUsers can log in with valid credentials and will be locked out after\n3 failed attempts for 15 minutes.\n\nBusiness Rules Implemented:\n- BR-001: Email validation (regex pattern)\n- BR-002: Password minimum 12 characters\n- BR-003: Account lockout after 3 failed attempts (15 minutes)\n\nImplementation:\n- Created LoginResult dataclass\n- Implemented login() function with validation\n- Added email validation helper\n- Added lockout tracking per user\n\nTests:\n- 5 tests added, all passing\n- Coverage: 95% (38/40 lines)\n\nFiles:\n- src/auth/login.py (created, 87 lines)\n- tests/auth/test_login.py (created, 94 lines)\n\nImplements: <REQ-ID>\nValidates: BR-001, BR-002, BR-003\nTests: 5 tests, 100% passing\nCoverage: 95%\n\nğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\n```\n\n---\n\n### Step 5: Optional - Squash Previous Commits\n\n**If configured** (`squash_commits: true` in plugin config):\n\n```bash\n# Squash RED, GREEN, REFACTOR commits into final commit\ngit reset --soft HEAD~3  # Undo last 3 commits (keeps changes)\ngit commit -F commit_message.txt\n```\n\n**If not squashing**: Keep RED, GREEN, REFACTOR commits separate + final commit.\n\n**Recommendation**: **Keep commits separate** for better git history:\n- RED commit shows test-first approach\n- GREEN commit shows minimal implementation\n- REFACTOR commit shows quality improvements\n- Final commit provides summary\n\n---\n\n### Step 6: Create Commit\n\n**Execute git commit**:\n\n```bash\ngit add .\ngit commit -m \"feat: Add user login (<REQ-ID>)\n\nImplement user authentication with email and password validation.\nUsers can log in with valid credentials and will be locked out after\n3 failed attempts for 15 minutes.\n\nBusiness Rules Implemented:\n- BR-001: Email validation (regex pattern)\n- BR-002: Password minimum 12 characters\n- BR-003: Account lockout after 3 failed attempts (15 minutes)\n\nImplementation:\n- Created LoginResult dataclass\n- Implemented login() function with validation\n- Added email validation helper\n- Added lockout tracking per user\n\nTests:\n- 5 tests added, all passing\n- Coverage: 95% (38/40 lines)\n\nFiles:\n- src/auth/login.py (created, 87 lines)\n- tests/auth/test_login.py (created, 94 lines)\n\nImplements: <REQ-ID>\nValidates: BR-001, BR-002, BR-003\nTests: 5 tests, 100% passing\nCoverage: 95%\n\nğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\n\"\n```\n\n---\n\n### Step 7: Verify Commit\n\n**Check commit**:\n\n```bash\ngit log -1 --stat\n```\n\n**Expected output**:\n```\ncommit abc123def456\nAuthor: Developer <dev@example.com>\nDate:   Thu Nov 20 22:00:00 2025 +1100\n\n    feat: Add user login (<REQ-ID>)\n\n    Implement user authentication with email and password validation.\n    ...\n\n src/auth/login.py       | 87 ++++++++++++++++++++++++++++++++++++++++++\n tests/auth/test_login.py | 94 ++++++++++++++++++++++++++++++++++++++++++++++\n 2 files changed, 181 insertions(+)\n```\n\n---\n\n## Output Format\n\nWhen you complete the commit, show:\n\n```\n[COMMIT Phase - <REQ-ID>]\n\nCommit Type: feat (new feature)\n\nCommit Message:\n  Subject: feat: Add user login (<REQ-ID>)\n  Body: Implement user authentication with email/password...\n  Footer: Implements: <REQ-ID>, Validates: BR-001/002/003\n\nFiles Changed:\n  + src/auth/login.py (87 lines)\n  + tests/auth/test_login.py (94 lines)\n\nTraceability:\n  Forward: <REQ-ID> â†’ commit abc123\n  Backward: git log --grep=\"<REQ-ID>\" â†’ this commit\n\nCommit SHA: abc123def456\n\nâœ… COMMIT Complete!\n   Requirement traceability established\n   Forward traceability: <REQ-ID> â†’ code\n   Backward traceability: code â†’ <REQ-ID>\n```\n\n---\n\n## Traceability Benefits\n\n### Forward Traceability (REQ â†’ Code)\n\n**From requirement, find implementation**:\n```bash\n# Find all commits implementing <REQ-ID>\ngit log --grep=\"<REQ-ID>\" --oneline\n\n# Find files implementing <REQ-ID>\ngit log --grep=\"<REQ-ID>\" --name-only\n```\n\n### Backward Traceability (Code â†’ REQ)\n\n**From code, find requirement**:\n```bash\n# Find requirement for src/auth/login.py\ngit log src/auth/login.py --grep=\"REQ-\" --oneline\n\n# Find business rules in file\ngrep \"Implements: BR-\" src/auth/login.py\n```\n\n### Impact Analysis\n\n**When requirement changes**:\n```bash\n# Find all code implementing <REQ-ID>\ngit log --grep=\"<REQ-ID>\" --name-only | grep -v \"^commit\" | sort -u\n\n# Output:\n# src/auth/login.py\n# tests/auth/test_login.py\n```\n\n**Now you know exactly what to update!**\n\n---\n\n## Prerequisites Check\n\nBefore invoking this skill, ensure:\n1. RED, GREEN, REFACTOR phases complete\n2. All tests passing\n3. Code quality verified (tech debt = 0)\n4. Requirement key (REQ-*) available\n\nIf prerequisites not met:\n- Tests failing â†’ Go back to GREEN phase\n- Tech debt detected â†’ Go back to REFACTOR phase\n- No REQ-* key â†’ Cannot create commit (need traceability)\n\n---\n\n## Next Steps\n\nAfter commit created:\n1. **Push to remote** (if desired): `git push origin main`\n2. **Move to next requirement**: Start new TDD workflow for next REQ-*\n3. **Create pull request** (if using PR workflow)\n\n---\n\n## Configuration\n\nThis skill respects configuration in `.claude/plugins.yml`:\n\n```yaml\nplugins:\n  - name: \"@aisdlc/code-skills\"\n    config:\n      tdd:\n        squash_commits: false      # Keep RED/GREEN/REFACTOR separate\n        commit_co_author: true     # Add Claude as co-author\n        include_coverage: true     # Include coverage in commit message\n        include_test_count: true   # Include test count in commit message\n```\n\n---\n\n## Commit Message Examples\n\n### Feature (REQ-F-*)\n\n```\nfeat: Add password reset (<REQ-ID>)\n\nImplement password reset via email with time-limited tokens.\n\nBusiness Rules:\n- BR-010: Reset token expires after 1 hour\n- BR-011: Token usable only once\n\nImplements: <REQ-ID>\nTests: 7 tests, 100% passing\nCoverage: 92%\n```\n\n### Bug Fix (Remediation)\n\n```\nfix: Correct email validation regex (<REQ-ID>)\n\nFix email validation to reject invalid TLDs.\n\nIssue: Email validation accepted invalid domains like user@example.c\nFix: Updated regex pattern to require minimum 2-char TLD\n\nFixes: <REQ-ID>, BR-001\nTests: 3 new tests added, all passing\n```\n\n### Performance Improvement (REQ-NFR-PERF-*)\n\n```\nperf: Optimize password hashing (REQ-NFR-PERF-001)\n\nSwitch from MD5 to bcrypt with cost factor 12.\n\nBefore: 5ms per hash (insecure)\nAfter: 250ms per hash (secure, prevents brute force)\n\nImplements: REQ-NFR-PERF-001, REQ-NFR-SEC-003\nTests: Performance tests added\n```\n\n---\n\n## Notes\n\n**Why requirement traceability?**\n- **Compliance**: Regulations require proof of requirements â†’ code mapping\n- **Impact analysis**: Know what code to update when requirement changes\n- **Audit trail**: Prove all requirements are implemented\n- **Debugging**: Trace production issues back to requirements\n- **Documentation**: Commits become living documentation\n\n**Bidirectional traceability**:\n```\nIntent (INT-042)\n  â†“ (forward)\nRequirements (<REQ-ID>)\n  â†“ (forward)\nDesign (AuthService component)\n  â†“ (forward)\nCode (src/auth/login.py)\n  â†“ (forward)\nTests (tests/auth/test_login.py)\n  â†“ (forward)\nRuntime (Datadog metrics tagged with <REQ-ID>)\n  â†“ (forward)\nAlerts (\"ERROR: <REQ-ID> - Auth timeout\")\n  â†‘ (backward)\nNew Intent (INT-150: \"Fix auth timeout\")\n```\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  requirement_traceability: complete\n  forward_traceability: REQ â†’ code\n  backward_traceability: code â†’ REQ\n  commit_contains_req_key: true\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/tdd/green-phase/SKILL.md": "---\nname: green-phase\ndescription: Implement minimal code to make failing tests pass (GREEN phase of TDD). Write just enough code to pass tests, no more. Use after red-phase when tests are failing.\nallowed-tools: [Read, Write, Edit, Bash, Grep, Glob]\n---\n\n# green-phase\n\n**Skill Type**: Actuator (TDD Workflow)\n**Purpose**: Write minimal code to make failing tests pass (GREEN phase)\n**Prerequisites**:\n- Tests exist and are FAILING (from red-phase)\n- Requirement key (REQ-*) with details\n\n---\n\n## Agent Instructions\n\nYou are in the **GREEN** phase of TDD (RED â†’ GREEN â†’ REFACTOR).\n\nYour goal is to **write MINIMAL code** to make the failing tests pass.\n\n**Key principle**: Write the **simplest code that works**. Do NOT over-engineer. Refactoring comes later.\n\n---\n\n## Workflow\n\n### Step 1: Review Failing Tests\n\n**Read the test file** to understand:\n- What functionality is being tested?\n- What are the expected inputs and outputs?\n- What business rules must be enforced?\n\n**Example**:\n```python\n# tests/auth/test_login.py shows we need:\n- login(email: str, password: str) -> LoginResult\n- LoginResult with fields: success, user, error\n- Email validation (BR-001)\n- Password length validation (BR-002)\n- Account lockout logic (BR-003)\n```\n\n---\n\n### Step 2: Determine Implementation File Location\n\n**Follow project conventions**:\n\n**Python**:\n```\ntests/auth/test_login.py  â†’ src/auth/login.py\ntests/services/test_payment.py â†’ src/services/payment.py\n```\n\n**TypeScript**:\n```\nsrc/auth/login.test.ts    â†’ src/auth/login.ts\nsrc/services/payment.test.ts â†’ src/services/payment.ts\n```\n\n**Java**:\n```\nsrc/test/java/auth/LoginTest.java â†’ src/main/java/auth/Login.java\n```\n\n---\n\n### Step 3: Implement Minimal Code\n\n**Write the simplest code that makes tests pass**:\n\n```python\n# src/auth/login.py\n\n# Implements: <REQ-ID>\n# Business Rules: BR-001, BR-002, BR-003\n\nimport re\nfrom dataclasses import dataclass\nfrom typing import Optional\nfrom datetime import datetime, timedelta\n\n@dataclass\nclass LoginResult:\n    success: bool\n    user: Optional['User'] = None\n    error: Optional[str] = None\n\nclass User:\n    def __init__(self, email: str, password_hash: str):\n        self.email = email\n        self.password_hash = password_hash\n        self.failed_attempts = 0\n        self.locked_until: Optional[datetime] = None\n\n    def check_password(self, password: str) -> bool:\n        # Simplified: In real code, use bcrypt\n        return self.password_hash == hash_password(password)\n\n# Implements: <REQ-ID>\ndef login(email: str, password: str) -> LoginResult:\n    # Implements: BR-001 (email validation)\n    if not validate_email(email):\n        return LoginResult(success=False, error=\"Invalid email format\")\n\n    # Implements: BR-002 (password minimum length)\n    if len(password) < 12:\n        return LoginResult(success=False, error=\"Password must be at least 12 characters\")\n\n    # Get user from database (simplified)\n    user = get_user_by_email(email)\n    if not user:\n        return LoginResult(success=False, error=\"User not found\")\n\n    # Implements: BR-003 (account lockout)\n    if user.locked_until and datetime.now() < user.locked_until:\n        return LoginResult(success=False, error=\"Account locked. Try again in 15 minutes\")\n\n    # Check password\n    if not user.check_password(password):\n        user.failed_attempts += 1\n\n        # Implements: BR-003 (lock after 3 attempts)\n        if user.failed_attempts >= 3:\n            user.locked_until = datetime.now() + timedelta(minutes=15)\n\n        return LoginResult(success=False, error=\"Invalid password\")\n\n    # Success - reset failed attempts\n    user.failed_attempts = 0\n    user.locked_until = None\n\n    return LoginResult(success=True, user=user)\n\n# Implements: BR-001 (email validation)\ndef validate_email(email: str) -> bool:\n    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n    return re.match(pattern, email) is not None\n\ndef hash_password(password: str) -> str:\n    # Simplified: In real code, use bcrypt\n    return str(hash(password))\n\ndef get_user_by_email(email: str) -> Optional[User]:\n    # Simplified: In real code, query database\n    # For now, return mock user for testing\n    return User(email, hash_password(\"SecurePass123!\"))\n```\n\n**Key implementation principles**:\n- âœ… Tag code with REQ-* keys in comments\n- âœ… Tag business rule implementations with BR-* keys\n- âœ… Write just enough code to pass tests (no gold-plating)\n- âœ… Use clear, descriptive names\n- âœ… Keep functions focused (single responsibility)\n- âœ… Don't worry about perfect code (refactoring comes next)\n\n---\n\n### Step 4: Run Tests (Expect SUCCESS)\n\n**Run the test suite**:\n\n```bash\n# Python\npytest tests/auth/test_login.py -v\n\n# TypeScript/JavaScript\nnpm test src/auth/login.test.ts\n\n# Java\nmvn test -Dtest=LoginTest\n```\n\n**Expected output**:\n```\ntests/auth/test_login.py::test_login_with_valid_credentials PASSED âœ“\ntests/auth/test_login.py::test_login_fails_with_invalid_email PASSED âœ“\ntests/auth/test_login.py::test_login_fails_with_short_password PASSED âœ“\ntests/auth/test_login.py::test_account_locked_after_3_failed_attempts PASSED âœ“\n\n4 tests passed in 0.12s\n```\n\n**âœ… All tests PASSING!** This is what we want in GREEN phase.\n\n**âš ï¸ If tests still FAIL**: Fix implementation and retry until all tests pass.\n\n---\n\n### Step 5: Verify Test Coverage\n\n**Check coverage**:\n\n```bash\n# Python\npytest --cov=src/auth tests/auth/test_login.py --cov-report=term-missing\n\n# TypeScript\nnpm test -- --coverage\n\n# Java\nmvn test jacoco:report\n```\n\n**Expected**: Coverage should be high (aim for 80%+ overall, 100% for critical paths).\n\n---\n\n### Step 6: Commit Implementation (GREEN Commit)\n\n**Create commit with implementation**:\n\n```bash\ngit add src/auth/login.py\ngit commit -m \"GREEN: Implement <REQ-ID>\n\nImplement user login functionality with email/password.\n\nImplements:\n- <REQ-ID>: User login\n- BR-001: Email validation (regex pattern)\n- BR-002: Password minimum 12 characters\n- BR-003: Account lockout after 3 failed attempts (15min)\n\nTests: 4 tests passing âœ“\nCoverage: 95%\n\"\n```\n\n**Commit message format**:\n- Prefix: `GREEN:`\n- Brief description\n- List of REQ-* and BR-* implemented\n- Test status (all passing)\n\n---\n\n## Output Format\n\nWhen you complete the GREEN phase, show:\n\n```\n[GREEN Phase - <REQ-ID>]\n\nImplementation: src/auth/login.py\n\nCode Created:\n  âœ“ LoginResult dataclass\n  âœ“ User class\n  âœ“ login() function (<REQ-ID>)\n  âœ“ validate_email() function (BR-001)\n  âœ“ hash_password() helper\n  âœ“ get_user_by_email() helper\n\nBusiness Rules Implemented:\n  âœ“ BR-001: Email validation (regex)\n  âœ“ BR-002: Password minimum 12 characters\n  âœ“ BR-003: Account lockout after 3 attempts\n\nRunning tests...\n  tests/auth/test_login.py::test_login_with_valid_credentials PASSED âœ“\n  tests/auth/test_login.py::test_login_fails_with_invalid_email PASSED âœ“\n  tests/auth/test_login.py::test_login_fails_with_short_password PASSED âœ“\n  tests/auth/test_login.py::test_account_locked_after_3_failed_attempts PASSED âœ“\n\nResult: 4/4 tests PASSING âœ“ (GREEN phase)\n\nCoverage: 95% (38/40 lines covered)\n\nCommit: GREEN: Implement <REQ-ID>\n\nâœ… GREEN Phase Complete!\n   Next: Invoke refactor-phase skill to improve code quality\n```\n\n---\n\n## Prerequisites Check\n\nBefore invoking this skill, ensure:\n1. Tests exist and are FAILING (from red-phase)\n2. Requirement details available (what to implement)\n\nIf prerequisites not met:\n- No tests â†’ Invoke `red-phase` skill first\n- Tests already passing â†’ Already implemented, skip to refactor-phase\n\n---\n\n## Next Steps\n\nAfter GREEN phase completes:\n1. **Do NOT refactor yet** (tests must pass first)\n2. Invoke `refactor-phase` skill to improve code quality and eliminate tech debt\n3. Tests should STILL PASS after refactoring\n\n---\n\n## Implementation Strategies\n\n### Strategy 1: Simplest Thing That Works\n\n```python\n# First implementation (naive, but works)\ndef login(email: str, password: str) -> LoginResult:\n    if email == \"user@example.com\" and password == \"SecurePass123!\":\n        return LoginResult(success=True)\n    return LoginResult(success=False)\n```\n\n**Then improve** to handle more cases until all tests pass.\n\n### Strategy 2: Test-by-Test\n\nImplement code to pass **one test at a time**:\n1. Make `test_login_with_valid_credentials` pass\n2. Make `test_login_fails_with_invalid_email` pass\n3. Make `test_login_fails_with_short_password` pass\n4. Make `test_account_locked_after_3_failed_attempts` pass\n\n### Strategy 3: Fake It Till You Make It\n\nStart with **hard-coded values**, then generalize:\n```python\n# Step 1: Hard-coded (passes one test)\ndef validate_email(email: str) -> bool:\n    return email == \"user@example.com\"\n\n# Step 2: Generalize (passes all tests)\ndef validate_email(email: str) -> bool:\n    pattern = r'^[a-zA-Z0-9._%+-]+@...'\n    return re.match(pattern, email) is not None\n```\n\n---\n\n## Common Pitfalls to Avoid\n\nâŒ **Over-engineering**: Don't add features not tested\nâŒ **Premature optimization**: Don't optimize before refactor phase\nâŒ **Perfect code**: Don't worry about code quality yet (refactor phase handles this)\nâŒ **Skipping tests**: All tests must pass before moving to refactor\nâŒ **Adding untested code**: Every line should be tested\n\nâœ… **Do this instead**:\n- Write minimal code\n- Make tests pass\n- Move to refactor phase\n- Improve code quality there\n\n---\n\n## Notes\n\n**Why minimal implementation?**\n- Prevents over-engineering (YAGNI - You Aren't Gonna Need It)\n- Forces focus on requirements (only implement what's tested)\n- Faster to refactor simple code\n- Easier to understand\n\n**GREEN phase mantra**: \"Make it work, then make it right\"\n- GREEN phase = make it work\n- REFACTOR phase = make it right\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  tests_passing: true\n  all_requirements_implemented: true\n  code_coverage: >= 80%\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/tdd/red-phase/SKILL.md": "---\nname: red-phase\ndescription: Write failing tests before implementation (RED phase of TDD). Creates test file with test functions that fail because code doesn't exist yet. Use when starting TDD workflow or adding tests for new functionality.\nallowed-tools: [Read, Write, Edit, Bash, Grep, Glob]\n---\n\n# red-phase\n\n**Skill Type**: Actuator (TDD Workflow)\n**Purpose**: Write tests that fail because the code doesn't exist yet (RED phase)\n**Prerequisites**:\n- Requirement key (REQ-*) with details\n- No existing tests for this requirement\n\n---\n\n## Agent Instructions\n\nYou are in the **RED** phase of TDD (RED â†’ GREEN â†’ REFACTOR).\n\nYour goal is to **write tests that FAIL** because the implementation doesn't exist yet.\n\n---\n\n## Workflow\n\n### Step 1: Understand the Requirement\n\n**Parse the requirement**:\n- What functionality needs to be implemented?\n- What are the business rules (BR-*)?\n- What are the constraints (C-*)?\n- What are the expected inputs and outputs?\n\n**Example**:\n```yaml\n<REQ-ID>: User login with email and password\n\nBusiness Rules:\n- BR-001: Email must be valid format\n- BR-002: Password minimum 12 characters\n- BR-003: Max 3 login attempts, 15min lockout\n\nExpected behavior:\n- Input: email (string), password (string)\n- Output: LoginResult(success: bool, user: User | None, error: str | None)\n```\n\n---\n\n### Step 2: Design Test Cases\n\n**Create test cases covering**:\n1. **Happy path** - Valid inputs, expected success\n2. **Business rules** - Each BR-* gets at least 1 test\n3. **Edge cases** - Boundary conditions, null inputs, empty strings\n4. **Error cases** - Invalid inputs, expected failures\n\n**Example test cases for <REQ-ID>**:\n```python\n# Happy path\ntest_login_with_valid_credentials()\n\n# Business rules\ntest_login_fails_with_invalid_email()       # BR-001\ntest_login_fails_with_short_password()      # BR-002\ntest_account_locked_after_3_failed_attempts() # BR-003\n\n# Edge cases\ntest_login_with_empty_email()\ntest_login_with_empty_password()\ntest_login_with_nonexistent_user()\n\n# Error cases\ntest_login_with_null_email()\ntest_login_with_null_password()\n```\n\n---\n\n### Step 3: Determine Test File Location\n\n**Follow project conventions**:\n\n**Python**:\n```\nsrc/auth/login.py          â†’ tests/auth/test_login.py\nsrc/services/payment.py    â†’ tests/services/test_payment.py\n```\n\n**TypeScript**:\n```\nsrc/auth/login.ts          â†’ src/auth/login.test.ts\nsrc/services/payment.ts    â†’ src/services/payment.test.ts\n```\n\n**Java**:\n```\nsrc/main/java/auth/Login.java         â†’ src/test/java/auth/LoginTest.java\nsrc/main/java/services/Payment.java   â†’ src/test/java/services/PaymentTest.java\n```\n\n**If unsure**: Check existing test files to follow project structure.\n\n---\n\n### Step 4: Write Test File\n\n**Template structure**:\n\n```python\n# tests/auth/test_login.py\n\n# Validates: <REQ-ID>\n# Business Rules: BR-001, BR-002, BR-003\n\nimport pytest\nfrom auth.login import login, LoginResult  # Will fail - doesn't exist yet\n\ndef test_login_with_valid_credentials():\n    \"\"\"Test successful login with valid email and password\"\"\"\n    # Validates: <REQ-ID> (happy path)\n    result = login(\"user@example.com\", \"SecurePass123!\")\n    assert result.success == True\n    assert result.user is not None\n    assert result.user.email == \"user@example.com\"\n\ndef test_login_fails_with_invalid_email():\n    \"\"\"Test login fails with invalid email format\"\"\"\n    # Validates: BR-001 (email validation)\n    result = login(\"invalid-email\", \"SecurePass123!\")\n    assert result.success == False\n    assert result.error == \"Invalid email format\"\n\ndef test_login_fails_with_short_password():\n    \"\"\"Test login fails with password < 12 characters\"\"\"\n    # Validates: BR-002 (password minimum length)\n    result = login(\"user@example.com\", \"short\")\n    assert result.success == False\n    assert result.error == \"Password must be at least 12 characters\"\n\ndef test_account_locked_after_3_failed_attempts():\n    \"\"\"Test account locks after 3 failed login attempts\"\"\"\n    # Validates: BR-003 (lockout after 3 attempts)\n    # Attempt 1\n    login(\"user@example.com\", \"wrong_password\")\n    # Attempt 2\n    login(\"user@example.com\", \"wrong_password\")\n    # Attempt 3\n    login(\"user@example.com\", \"wrong_password\")\n    # Attempt 4 should be locked\n    result = login(\"user@example.com\", \"correct_password\")\n    assert result.success == False\n    assert result.error == \"Account locked. Try again in 15 minutes\"\n```\n\n**Key elements**:\n- âœ… Comment at top: `# Validates: <REQ-ID>`\n- âœ… List business rules: `# Business Rules: BR-001, BR-002, BR-003`\n- âœ… Each test tagged with what it validates\n- âœ… Clear test names (what is being tested)\n- âœ… Docstrings explaining test purpose\n- âœ… Assertions for expected behavior\n\n---\n\n### Step 5: Run Tests (Expect FAILURE)\n\n**Run the test suite**:\n\n```bash\n# Python\npytest tests/auth/test_login.py -v\n\n# TypeScript/JavaScript\nnpm test src/auth/login.test.ts\n\n# Java\nmvn test -Dtest=LoginTest\n```\n\n**Expected output**:\n```\ntests/auth/test_login.py::test_login_with_valid_credentials FAILED\ntests/auth/test_login.py::test_login_fails_with_invalid_email FAILED\ntests/auth/test_login.py::test_login_fails_with_short_password FAILED\ntests/auth/test_login.py::test_account_locked_after_3_failed_attempts FAILED\n\nImportError: cannot import name 'login' from 'auth.login'\n```\n\n**âœ… This is GOOD!** Tests fail because implementation doesn't exist yet.\n\n**âš ï¸ If tests PASS**: Something is wrong - tests should fail in RED phase!\n\n---\n\n### Step 6: Commit Tests (RED Commit)\n\n**Create commit with tests**:\n\n```bash\ngit add tests/auth/test_login.py\ngit commit -m \"RED: Add tests for <REQ-ID>\n\nWrite failing tests for user login functionality.\n\nTests cover:\n- BR-001: Email validation\n- BR-002: Password minimum length\n- BR-003: Account lockout after 3 attempts\n\nTests: 4 tests (all failing as expected - RED phase)\n\nValidates: <REQ-ID>\n\"\n```\n\n**Commit message format**:\n- Prefix: `RED:`\n- Brief description\n- Details of what's tested\n- REQ-* key for traceability\n\n---\n\n## Output Format\n\nWhen you complete the RED phase, show:\n\n```\n[RED Phase - <REQ-ID>]\n\nRequirement: User login with email and password\n\nTest Cases Created:\n  âœ“ test_login_with_valid_credentials (happy path)\n  âœ“ test_login_fails_with_invalid_email (BR-001)\n  âœ“ test_login_fails_with_short_password (BR-002)\n  âœ“ test_account_locked_after_3_failed_attempts (BR-003)\n\nTest File: tests/auth/test_login.py (4 tests, 87 lines)\n\nRunning tests...\n  tests/auth/test_login.py::test_login_with_valid_credentials FAILED\n  tests/auth/test_login.py::test_login_fails_with_invalid_email FAILED\n  tests/auth/test_login.py::test_login_fails_with_short_password FAILED\n  tests/auth/test_login.py::test_account_locked_after_3_failed_attempts FAILED\n\nResult: 4 tests FAILED âœ“ (expected - RED phase)\n\nCommit: RED: Add tests for <REQ-ID>\n\nâœ… RED Phase Complete!\n   Next: Invoke green-phase skill to implement functionality\n```\n\n---\n\n## Prerequisites Check\n\nBefore invoking this skill, ensure:\n1. Requirement key (REQ-*) exists\n2. Requirement details available (what to implement)\n3. No existing tests for this requirement (or you're adding to them)\n\nIf prerequisites not met:\n- No REQ-* â†’ Invoke `requirement-extraction` skill\n- No requirement details â†’ Ask user for clarification\n\n---\n\n## Next Steps\n\nAfter RED phase completes:\n1. **Do NOT implement code yet** (that's GREEN phase)\n2. Invoke `green-phase` skill to implement functionality\n3. Tests should PASS in GREEN phase\n\n---\n\n## Test Templates (by Language)\n\n### Python (pytest)\n\n```python\n# tests/test_feature.py\n\n# Validates: <REQ-ID>\n# Business Rules: <BR-ID>, <BR-ID>\n\nimport pytest\nfrom module import function\n\ndef test_happy_path():\n    \"\"\"Test successful case\"\"\"\n    # Validates: <REQ-ID>\n    result = function(\"valid_input\")\n    assert result == expected_output\n\ndef test_business_rule_validation():\n    \"\"\"Test business rule enforcement\"\"\"\n    # Validates: BR-001\n    with pytest.raises(ValidationError):\n        function(\"invalid_input\")\n```\n\n### TypeScript (Jest)\n\n```typescript\n// feature.test.ts\n\n// Validates: <REQ-ID>\n// Business Rules: <BR-ID>, <BR-ID>\n\nimport { function } from './module';\n\ndescribe('Feature', () => {\n  test('happy path - successful case', () => {\n    // Validates: <REQ-ID>\n    const result = function('valid_input');\n    expect(result).toBe(expected_output);\n  });\n\n  test('business rule - validation error', () => {\n    // Validates: BR-001\n    expect(() => function('invalid_input')).toThrow(ValidationError);\n  });\n});\n```\n\n### Java (JUnit)\n\n```java\n// FeatureTest.java\n\n// Validates: <REQ-ID>\n// Business Rules: <BR-ID>, <BR-ID>\n\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.*;\n\nclass FeatureTest {\n    @Test\n    void testHappyPath() {\n        // Validates: <REQ-ID>\n        var result = Feature.function(\"valid_input\");\n        assertEquals(expected_output, result);\n    }\n\n    @Test\n    void testBusinessRuleValidation() {\n        // Validates: BR-001\n        assertThrows(ValidationException.class, () -> {\n            Feature.function(\"invalid_input\");\n        });\n    }\n}\n```\n\n---\n\n## Notes\n\n**Why write tests first?**\n- Tests = executable specification of requirements\n- Failing tests prove tests can detect bugs (no false positives)\n- Forces thinking about API design before implementation\n- Ensures testability (if you can't write the test, the design is wrong)\n\n**Common mistakes to avoid**:\n- âŒ Writing tests that pass immediately (not testing anything)\n- âŒ Writing implementation before tests (not TDD)\n- âŒ Skipping edge cases or error cases\n- âŒ Not tagging tests with REQ-* keys (loses traceability)\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  tests_written_first: true\n  tests_failing: true  # In RED phase, failure is success!\n  requirement_coverage: 100%\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/tdd/refactor-phase/SKILL.md": "# refactor-phase\n\n**Skill Type**: Actuator (TDD Workflow)\n**Purpose**: Improve code quality and enforce Principle #6 (\"No Legacy Baggage\") by refactoring and pruning technical debt\n**Prerequisites**:\n- Tests are GREEN (all passing)\n- Code implements the requirement\n\n---\n\n## Agent Instructions\n\nYou are in the **REFACTOR** phase of TDD (RED â†’ GREEN â†’ REFACTOR).\n\nYour goal is to improve code quality **and eliminate technical debt** before committing.\n\n### Workflow\n\n#### 1. Improve Code Quality\n\n- Add type hints\n- Improve variable names\n- Extract complex expressions to named variables\n- Add docstrings to public methods\n- Improve error messages\n- Optimize performance (only if needed)\n\n#### 2. **Prune Technical Debt** â­ (Principle #6 Enforcement)\n\n**CRITICAL**: Before committing, you **MUST** perform these checks and pruning actions:\n\n##### 2.1 Delete Unused Imports\n- Analyze the file for all import statements\n- Check if each import is actually used in the code\n- **DELETE** any unused imports immediately\n- Example:\n  ```python\n  # BEFORE\n  import hashlib  # âŒ Not used anywhere\n  import re       # âŒ Not used anywhere\n  from typing import Dict, List  # âœ“ Only List is used\n\n  # AFTER\n  from typing import List  # âœ“ Kept only what's used\n  ```\n\n##### 2.2 Remove Dead Code\n- Scan for variables defined but never read\n- Scan for functions/methods with **zero callers**\n- **DELETE** all dead code immediately\n- Example:\n  ```python\n  # BEFORE\n  def legacy_hash_password(password):  # âŒ No callers\n      return md5(password)\n\n  def hash_password(password):  # âœ“ Used\n      return bcrypt.hash(password)\n\n  # AFTER\n  def hash_password(password):  # âœ“ Kept only what's used\n      return bcrypt.hash(password)\n  ```\n\n##### 2.3 Delete Commented-Out Code\n- Find all commented-out code blocks\n- **DELETE** all commented-out code (we have git history)\n- Example:\n  ```python\n  # BEFORE\n  def login(email, password):\n      # Old implementation (broken)\n      # user = User.query.get(email)\n      # if user and user.password == password:\n      #     return user\n\n      # New implementation\n      user = User.get_by_email(email)\n      return authenticate(user, password)\n\n  # AFTER\n  def login(email, password):\n      user = User.get_by_email(email)\n      return authenticate(user, password)\n  ```\n\n##### 2.4 Simplify Over-Complex Logic\n- Calculate cyclomatic complexity for each function\n- If complexity > 10, **SIMPLIFY** by extracting functions\n- Example:\n  ```python\n  # BEFORE (Complexity: 18)\n  def login(email, password):\n      if email is None:\n          return error(\"Email required\")\n      if not is_valid_email(email):\n          return error(\"Invalid email\")\n      if not User.exists(email):\n          return error(\"User not found\")\n      user = User.get(email)\n      if user.is_locked:\n          if not user.lockout_expired():\n              return error(\"Account locked\")\n          else:\n              user.unlock()\n      if not user.check_password(password):\n          user.increment_attempts()\n          if user.attempts >= 3:\n              user.lock()\n          return error(\"Invalid password\")\n      return success(user)\n\n  # AFTER (Complexity: 6)\n  def login(email, password):\n      validation_error = validate_login_input(email, password)\n      if validation_error:\n          return validation_error\n\n      user = get_user_or_fail(email)\n\n      if user.is_locked and not user.lockout_expired():\n          return error(\"Account locked\")\n\n      return authenticate_user(user, password)\n\n  # Extracted functions (each < 10 lines, complexity < 5)\n  def validate_login_input(email, password):\n      if not email:\n          return error(\"Email required\")\n      if not is_valid_email(email):\n          return error(\"Invalid email\")\n      return None\n\n  def get_user_or_fail(email):\n      if not User.exists(email):\n          raise UserNotFoundError(email)\n      return User.get(email)\n\n  def authenticate_user(user, password):\n      if not user.check_password(password):\n          handle_failed_login(user)\n          return error(\"Invalid password\")\n      return success(user)\n\n  def handle_failed_login(user):\n      user.increment_attempts()\n      if user.attempts >= 3:\n          user.lock()\n  ```\n\n##### 2.5 Remove Duplication\n- Identify duplicated code blocks (DRY principle)\n- Extract to shared functions\n- Example:\n  ```python\n  # BEFORE\n  def create_user(email):\n      if not re.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$', email):\n          return error(\"Invalid email\")\n      # ...\n\n  def update_user(email):\n      if not re.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$', email):\n          return error(\"Invalid email\")\n      # ...\n\n  # AFTER\n  def validate_email(email):\n      pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n      return re.match(pattern, email) is not None\n\n  def create_user(email):\n      if not validate_email(email):\n          return error(\"Invalid email\")\n      # ...\n\n  def update_user(email):\n      if not validate_email(email):\n          return error(\"Invalid email\")\n      # ...\n  ```\n\n#### 3. Verify Tests Still Pass\n\nAfter **EVERY** refactoring change:\n- Run all tests\n- Ensure tests are still GREEN\n- If tests fail, undo the change and try a different approach\n\n#### 4. Before Committing Checklist\n\nYou **MUST** verify:\n- âœ… All tests passing (GREEN)\n- âœ… No unused imports\n- âœ… No dead code (0 functions with zero callers)\n- âœ… No commented-out code\n- âœ… Max cyclomatic complexity â‰¤ 10\n- âœ… No duplicated code blocks\n- âœ… Code follows language style guide (PEP 8 for Python, etc.)\n\n**If ANY checklist item fails, DO NOT COMMIT. Fix it first.**\n\n---\n\n## Output Format\n\nWhen you complete the REFACTOR phase, show:\n\n```\n[REFACTOR Phase]\n\nCode Quality Improvements:\n  âœ“ Added type hints to 5 functions\n  âœ“ Improved variable names (3 changes)\n  âœ“ Added docstrings to 2 public methods\n\nTech Debt Pruning (Principle #6):\n  âœ“ Deleted 5 unused imports\n  âœ“ Removed 2 dead functions (17 lines deleted)\n  âœ“ Deleted 15 lines of commented code\n  âœ“ Simplified login() - complexity 18 â†’ 6\n  âœ“ Extracted 4 helper functions\n  âœ“ Removed code duplication (2 occurrences)\n\nFile size: 487 lines â†’ 312 lines (-36%)\n\nRunning tests...\n  âœ“ All 47 tests passing\n\nBefore Commit Checklist:\n  âœ“ All tests passing (GREEN)\n  âœ“ No unused imports\n  âœ“ No dead code\n  âœ“ No commented-out code\n  âœ“ Max complexity â‰¤ 10 (current max: 6)\n  âœ“ No duplicated code\n  âœ“ Code follows style guide\n\nReady to commit!\n```\n\n---\n\n## Prerequisites Check\n\nBefore invoking this skill, ensure:\n1. Tests are GREEN (all passing)\n2. Code implements the requirement\n3. No syntax errors\n\nIf prerequisites not met, invoke:\n- `green-phase` (if tests not passing)\n- `red-phase` (if no tests exist)\n\n---\n\n## Next Steps\n\nAfter refactoring is complete:\n1. Invoke `commit-with-req-tag` skill to create git commit\n2. Move to next requirement (invoke `tdd-workflow` for next REQ-*)\n\n---\n\n## Notes\n\n**Why explicit pruning?**\n- LLMs have \"addition bias\" - naturally prefer adding code over deleting\n- Without explicit enforcement, Principle #6 becomes aspirational, not operational\n- This skill makes \"No Legacy Baggage\" **enforceable** and **measurable**\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  tech_debt: 0\n  max_complexity: 10\n  code_duplication: 0\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/code/tdd/tdd-workflow/SKILL.md": "---\nname: tdd-workflow\ndescription: Complete Test-Driven Development workflow coordinating RED â†’ GREEN â†’ REFACTOR â†’ COMMIT cycle with requirement traceability. Use this when implementing a requirement (REQ-*) or adding new functionality.\nallowed-tools: [Read, Write, Edit, Bash, Grep, Glob]\n---\n\n# tdd-workflow\n\n**Skill Type**: Orchestrator (TDD Workflow)\n**Purpose**: Coordinate complete TDD cycle with requirement traceability\n**Prerequisites**:\n- Work unit with REQ-* key (e.g., \"Implement <REQ-ID>\")\n- Requirement details available\n\n---\n\n## Agent Instructions\n\nYou are orchestrating the complete **Test-Driven Development (TDD)** workflow.\n\nYour goal is to implement a requirement using the **RED â†’ GREEN â†’ REFACTOR â†’ COMMIT** cycle while maintaining requirement traceability.\n\n---\n\n## Workflow\n\n### Phase 0: Prerequisites Check\n\n**Before starting TDD, verify**:\n1. âœ… Requirement key exists (REQ-F-*, REQ-NFR-*, REQ-DATA-*, REQ-BR-*)\n2. âœ… Requirement details available (what to implement)\n3. âœ… Working directory is a git repository\n4. âœ… No uncommitted changes (clean working tree)\n\n**If prerequisites missing**:\n- No REQ-* key â†’ Invoke `requirement-extraction` skill (from requirements-skills plugin)\n- No requirement details â†’ Ask user for clarification\n- Not a git repo â†’ Ask user if they want to initialize git\n- Uncommitted changes â†’ Ask user if they want to commit or stash\n\n---\n\n### Phase 1: RED (Write Failing Tests)\n\n**Invoke**: `red-phase` skill\n\n**Purpose**: Write tests that fail because the code doesn't exist yet\n\n**What red-phase does**:\n- Creates test file (e.g., `test_user_login.py`)\n- Writes test functions for the requirement\n- Tags tests with REQ-* key in comments\n- Runs tests â†’ expects FAILURE (RED)\n- Commits: \"RED: Add tests for REQ-*\"\n\n**Success Criteria**: Tests exist and FAIL\n\n---\n\n### Phase 2: GREEN (Make Tests Pass)\n\n**Invoke**: `green-phase` skill\n\n**Purpose**: Write minimal code to make tests pass\n\n**What green-phase does**:\n- Creates implementation file (e.g., `auth_service.py`)\n- Implements minimal code to pass tests\n- Tags code with REQ-* key in comments\n- Runs tests â†’ expects SUCCESS (GREEN)\n- Commits: \"GREEN: Implement REQ-*\"\n\n**Success Criteria**: Tests PASS\n\n---\n\n### Phase 3: REFACTOR (Improve Quality + Eliminate Tech Debt)\n\n**Invoke**: `refactor-phase` skill\n\n**Purpose**: Improve code quality and eliminate technical debt (Principle #6)\n\n**What refactor-phase does**:\n- Improves code quality (type hints, docstrings, naming)\n- **Deletes** unused imports\n- **Removes** dead code (functions with zero callers)\n- **Deletes** commented-out code\n- **Simplifies** over-complex logic (cyclomatic complexity > 10)\n- **Removes** code duplication\n- Runs tests â†’ expects STILL PASSING\n- Commits: \"REFACTOR: Clean up REQ-*\"\n\n**Success Criteria**: Tests still PASS, tech debt = 0\n\n---\n\n### Phase 4: COMMIT (Final Commit with REQ-* Tag)\n\n**Invoke**: `commit-with-req-tag` skill\n\n**Purpose**: Create final commit with requirement traceability\n\n**What commit-with-req-tag does**:\n- Squashes RED, GREEN, REFACTOR commits (optional)\n- Creates final commit message:\n  ```\n  feat: Add user login (<REQ-ID>)\n\n  Implements user authentication with email and password.\n\n  Business Rules:\n  - BR-001: Email validation\n  - BR-002: Password minimum 12 characters\n\n  Tests: 5 tests, 100% coverage\n  ```\n- Tags commit with REQ-* key\n\n**Success Criteria**: Final commit created with REQ-* traceability\n\n---\n\n## Output Format\n\nWhen you complete the TDD workflow, show:\n\n```\n[TDD Workflow: <REQ-ID>]\n\nâœ… Phase 0: Prerequisites\n  âœ“ Requirement: <REQ-ID> (User login)\n  âœ“ Git repository: initialized\n  âœ“ Working tree: clean\n\nâœ… Phase 1: RED (Write Failing Tests)\n  âœ“ Created: test_user_login.py (5 tests)\n  âœ“ Tests FAILED as expected âœ“\n  âœ“ Commit: RED: Add tests for <REQ-ID>\n\nâœ… Phase 2: GREEN (Make Tests Pass)\n  âœ“ Created: auth_service.py\n  âœ“ Implemented: login() function\n  âœ“ Tests PASSED âœ“\n  âœ“ Commit: GREEN: Implement <REQ-ID>\n\nâœ… Phase 3: REFACTOR (Improve Quality + Eliminate Tech Debt)\n  Code Quality Improvements:\n    âœ“ Added type hints to 3 functions\n    âœ“ Added docstrings to 2 public methods\n    âœ“ Improved variable names (2 changes)\n\n  Tech Debt Pruning:\n    âœ“ Deleted 2 unused imports\n    âœ“ Removed 1 dead function (8 lines)\n    âœ“ Simplified validation logic (complexity 12 â†’ 6)\n\n  âœ“ Tests still PASSING âœ“\n  âœ“ Commit: REFACTOR: Clean up <REQ-ID>\n\nâœ… Phase 4: COMMIT (Final Commit)\n  âœ“ Final commit: feat: Add user login (<REQ-ID>)\n\nğŸ‰ TDD Workflow Complete!\n  Files: 2 files (auth_service.py, test_user_login.py)\n  Tests: 5 tests, 100% coverage\n  Commits: 4 commits (RED, GREEN, REFACTOR, final)\n  Traceability: <REQ-ID> â†’ commit abc123\n```\n\n---\n\n## Homeostasis Behavior\n\n**If prerequisites not met**:\n1. **Detect**: Missing REQ-* key\n2. **Signal**: \"Need requirement extraction first\"\n3. **Claude invokes**: `requirement-extraction` skill (from requirements-skills plugin)\n4. **Retry**: tdd-workflow with new REQ-*\n\n**If tests fail in GREEN phase**:\n1. **Detect**: Tests still failing after implementation\n2. **Signal**: \"Implementation incomplete\"\n3. **Claude**: Fix implementation and retry\n4. **Do NOT proceed to REFACTOR** until tests pass\n\n**If tech debt detected in REFACTOR phase**:\n1. **Detect**: Unused code, complexity > 10, etc.\n2. **Signal**: \"Tech debt detected\"\n3. **Claude invokes**: `prune-unused-code`, `simplify-complex-code` (actuator skills)\n4. **Verify**: Tech debt eliminated before commit\n\n---\n\n## Prerequisites Check\n\nBefore invoking this skill, ensure:\n1. âœ… Requirement key (REQ-*) exists\n2. âœ… Requirement details available\n3. âœ… Git repository initialized\n4. âœ… Clean working tree\n\nIf prerequisites not met:\n- Missing REQ-* â†’ Invoke `requirement-extraction` skill\n- No git â†’ Ask user to initialize\n- Dirty working tree â†’ Ask user to commit or stash\n\n---\n\n## Skills Used\n\nThis orchestrator skill invokes:\n1. `red-phase` - Write failing tests\n2. `green-phase` - Implement code to pass tests\n3. `refactor-phase` - Improve quality and eliminate tech debt\n4. `commit-with-req-tag` - Create final commit with traceability\n5. `detect-unused-code` - (via refactor-phase) Detect tech debt\n6. `prune-unused-code` - (via refactor-phase) Eliminate tech debt\n7. `detect-complexity` - (via refactor-phase) Detect over-complex code\n8. `simplify-complex-code` - (via refactor-phase) Simplify complex code\n\n---\n\n## Configuration\n\nThis skill respects configuration in `.claude/plugins.yml`:\n\n```yaml\nplugins:\n  - name: \"@aisdlc/code-skills\"\n    config:\n      tdd:\n        minimum_coverage: 80          # Fail if coverage < 80%\n        enforce_red_green_refactor: true  # Enforce phase order\n        allow_skip_tests: false       # Block if user tries to skip tests\n        squash_commits: false         # Keep RED/GREEN/REFACTOR commits separate\n```\n\n---\n\n## Next Steps\n\nAfter TDD workflow completes:\n1. Review final commit\n2. Push to remote (if desired)\n3. Move to next requirement (invoke `tdd-workflow` for next REQ-*)\n\n---\n\n## Notes\n\n**Why TDD workflow?**\n- Tests first = clear specification before coding\n- RED phase = verify tests can fail (avoid false positives)\n- GREEN phase = minimal implementation (no over-engineering)\n- REFACTOR phase = quality + tech debt elimination (Principle #6)\n- COMMIT phase = requirement traceability (forward + backward)\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  tests_written_first: true\n  tests_passing: true\n  tech_debt: 0\n  requirement_traceability: complete\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/core/check-requirement-coverage/SKILL.md": "---\nname: check-requirement-coverage\ndescription: Homeostatic sensor detecting requirements without implementation or test coverage. Scans for REQ-* keys in requirements docs and checks if they have corresponding code and tests. Use to find coverage gaps.\nallowed-tools: [Read, Grep, Glob]\n---\n\n# check-requirement-coverage\n\n**Skill Type**: Sensor (Homeostasis)\n**Purpose**: Detect requirements without implementation or test coverage\n**Prerequisites**: Requirements exist in documentation\n\n---\n\n## Agent Instructions\n\nYou are a **Sensor** in the homeostasis system. Your job is to **detect deviations** from the desired state.\n\n**Desired State**: `coverage = 100%` (all requirements have code + tests)\n\nYour goal is to **find requirements without coverage** and signal the deviation.\n\n---\n\n## Workflow\n\n### Step 1: Find All Requirements\n\n**Search for REQ-* keys** in requirements documentation:\n\n```bash\n# Find all requirement files\nfind docs/requirements -name \"*.md\" -type f\n\n# Extract all REQ-* keys\ngrep -rho \"REQ-[A-Z-]*-[0-9]*\" docs/requirements/ | sort -u\n```\n\n**Example output**:\n```\n<REQ-ID>\n<REQ-ID>\nREQ-F-AUTH-003\n<REQ-ID>\nREQ-NFR-PERF-001\nREQ-NFR-SEC-001\nREQ-DATA-PII-001\n```\n\n---\n\n### Step 2: Check Implementation Coverage\n\n**For each REQ-*, search for implementation**:\n\n```bash\n# Check if requirement has code implementation\ngrep -rn \"# Implements: <REQ-ID>\" src/\n\n# Expected: At least 1 file with \"# Implements: <REQ-ID>\"\n```\n\n**Coverage criteria**:\n- âœ… **Covered**: At least 1 file in `src/` has `# Implements: {REQ-KEY}`\n- âŒ **Not covered**: Zero files reference the requirement\n\n**Example**:\n```\n<REQ-ID>:\n  âœ… src/auth/login.py:23  # Implements: <REQ-ID>\n  âœ… src/auth/validators.py:67  # Implements: <REQ-ID>, BR-001\n  Result: COVERED (2 files)\n\nREQ-F-PROFILE-001:\n  âŒ No files found\n  Result: NOT COVERED (implementation missing)\n```\n\n---\n\n### Step 3: Check Test Coverage\n\n**For each REQ-*, search for tests**:\n\n```bash\n# Check if requirement has tests\ngrep -rn \"# Validates: <REQ-ID>\" tests/\n\n# Also check BDD scenarios\ngrep -rn \"# Validates: <REQ-ID>\" features/\n\n# Expected: At least 1 test file\n```\n\n**Coverage criteria**:\n- âœ… **Covered**: At least 1 file in `tests/` or `features/` has `# Validates: {REQ-KEY}`\n- âŒ **Not covered**: Zero test files reference the requirement\n\n**Example**:\n```\n<REQ-ID>:\n  âœ… tests/auth/test_login.py:15  # Validates: <REQ-ID>\n  âœ… features/authentication.feature:8  # Validates: <REQ-ID>\n  Result: COVERED (2 test files)\n\n<REQ-ID>:\n  âœ… src/payments/payment.py:45  # Implements: <REQ-ID>\n  âŒ No test files found\n  Result: COVERED (code) but NOT COVERED (tests) âš ï¸\n```\n\n---\n\n### Step 4: Calculate Coverage Percentage\n\n**Formula**:\n```python\nimplementation_coverage = (requirements_with_code / total_requirements) * 100\ntest_coverage = (requirements_with_tests / total_requirements) * 100\nfull_coverage = (requirements_with_both / total_requirements) * 100\n```\n\n**Example**:\n```\nTotal Requirements: 42\n\nRequirements with Code: 36/42 (86%)\nRequirements with Tests: 32/42 (76%)\nRequirements with Both: 30/42 (71%)\n\nCoverage Status:\n  âœ… Implementation: 86% (target: 80%) PASS\n  âš ï¸ Test: 76% (target: 80%) FAIL\n  âš ï¸ Full: 71% (target: 80%) FAIL\n```\n\n---\n\n### Step 5: Identify Coverage Gaps\n\n**Report requirements without coverage**:\n\n**Gap Type 1: No Implementation**:\n```\nRequirements Without Code (6):\nâ”œâ”€ REQ-F-PROFILE-001 - User profile editing\nâ”œâ”€ REQ-F-PROFILE-002 - Avatar upload\nâ”œâ”€ REQ-F-NOTIF-001 - Email notifications\nâ”œâ”€ REQ-F-NOTIF-002 - Push notifications\nâ”œâ”€ REQ-NFR-PERF-002 - Database optimization\nâ””â”€ REQ-DATA-LIN-001 - Data lineage tracking\n\nRecommended Action: Implement these requirements using TDD workflow\n```\n\n**Gap Type 2: Has Code, No Tests**:\n```\nRequirements Without Tests (10):\nâ”œâ”€ <REQ-ID> - Payment processing\nâ”‚   Code: src/payments/payment.py:45\nâ”‚   Missing: Unit tests\nâ”‚\nâ”œâ”€ REQ-F-CART-001 - Shopping cart\nâ”‚   Code: src/cart/cart.py:23\nâ”‚   Missing: Integration tests\nâ”‚\nâ””â”€ ... (8 more)\n\nRecommended Action: Invoke 'generate-missing-tests' skill\n```\n\n**Gap Type 3: Has Tests, No Code**:\n```\nRequirements Without Implementation (4):\nâ”œâ”€ REQ-F-SEARCH-001 - Product search\nâ”‚   Tests: tests/search/test_search.py:15\nâ”‚   Missing: Implementation (tests written first - RED phase)\nâ”‚\nâ””â”€ ... (3 more)\n\nStatus: âœ… This is OK (RED phase of TDD)\nAction: Continue to GREEN phase\n```\n\n---\n\n## Output Format\n\nWhen you detect coverage gaps:\n\n```\n[COVERAGE SENSOR - DEVIATION DETECTED]\n\nRequirements Scanned: 42\n\nCoverage Summary:\n  Implementation: 36/42 (86%) âœ… PASS (â‰¥80%)\n  Tests: 32/42 (76%) âŒ FAIL (target: â‰¥80%)\n  Full Coverage: 30/42 (71%) âŒ FAIL (target: â‰¥80%)\n\nHomeostasis Deviation: Test coverage below 80%\n\nCoverage Gaps by Type:\n\nâŒ No Implementation (6 requirements):\n  1. REQ-F-PROFILE-001 - User profile editing\n  2. REQ-F-PROFILE-002 - Avatar upload\n  3. REQ-F-NOTIF-001 - Email notifications\n  4. REQ-F-NOTIF-002 - Push notifications\n  5. REQ-NFR-PERF-002 - Database optimization\n  6. REQ-DATA-LIN-001 - Data lineage tracking\n\nâš ï¸ No Tests (10 requirements):\n  1. <REQ-ID> - Payment processing\n     Code: src/payments/payment.py:45\n  2. REQ-F-CART-001 - Shopping cart\n     Code: src/cart/cart.py:23\n  ... (8 more)\n\nâœ… Tests Without Implementation (4 requirements):\n  1. REQ-F-SEARCH-001 - Product search\n     Tests: tests/search/test_search.py:15\n     Status: RED phase (OK - TDD in progress)\n  ... (3 more)\n\nRecommended Actions:\n1. Invoke 'generate-missing-tests' skill for 10 requirements without tests\n2. Implement 6 requirements without code (use 'tdd-workflow')\n3. Continue TDD for 4 requirements in RED phase\n\nHomeostasis Goal: coverage >= 80%\nCurrent State: coverage = 71%\nDeviation: -9% (needs correction)\n```\n\n---\n\n## Homeostasis Behavior\n\n**When deviation detected**:\n1. **Report**: Coverage below threshold\n2. **Signal**: \"Need tests for {REQ-KEYS}\"\n3. **Recommend**: Invoke `generate-missing-tests` actuator skill\n4. **Wait**: User confirmation or auto-invoke if configured\n\n**When homeostasis achieved**:\n```\n[COVERAGE SENSOR - HOMEOSTASIS ACHIEVED]\n\nRequirements: 42\nCoverage: 100% (42/42) âœ…\n\nAll requirements have:\n  âœ… Implementation\n  âœ… Tests\n  âœ… Traceability\n\nHomeostasis Status: STABLE âœ“\n```\n\n---\n\n## Prerequisites Check\n\nNone - this sensor can run anytime.\n\n**Recommended frequency**:\n- After each feature implementation\n- Before commits (via pre-commit hook)\n- Daily in CI/CD pipeline\n- On-demand via `/coverage-req` slash command\n\n---\n\n## Configuration\n\nThis skill respects configuration in `.claude/plugins.yml`:\n\n```yaml\nplugins:\n  - name: \"@aisdlc/aisdlc-core\"\n    config:\n      coverage:\n        minimum_percentage: 80        # Fail if coverage < 80%\n        require_implementation: true  # All REQ-* must have code\n        require_tests: true           # All REQ-* must have tests\n        auto_generate_missing: false  # Ask before generating tests\n        exclude_patterns:\n          - \"REQ-DATA-*\"              # Don't require tests for data reqs\n```\n\n---\n\n## Integration with Other Skills\n\n### TDD Workflow Integration\n\n```python\n# Before starting TDD, check coverage\nresult = invoke_skill(\"check-requirement-coverage\")\n\nif result.has_gaps:\n    # Report gaps to user\n    print(f\"Found {result.gap_count} requirements without coverage\")\n\n# After TDD, re-check coverage\nresult = invoke_skill(\"check-requirement-coverage\")\nif result.coverage >= 80:\n    print(\"Coverage target achieved âœ…\")\n```\n\n### Generate Missing Tests Integration\n\n```python\n# Sensor detects gaps\ngaps = invoke_skill(\"check-requirement-coverage\")\n\nif gaps.test_coverage < 80:\n    # Actuator fixes gaps\n    invoke_skill(\"generate-missing-tests\", req_keys=gaps.missing_tests)\n\n    # Re-check (should now be at homeostasis)\n    new_gaps = invoke_skill(\"check-requirement-coverage\")\n    assert new_gaps.test_coverage >= 80  # Homeostasis achieved\n```\n\n---\n\n## Next Steps\n\nAfter coverage check:\n1. If gaps found â†’ Recommend actuator skills (generate-missing-tests, tdd-workflow)\n2. If homeostasis â†’ Report success\n3. If configured â†’ Auto-invoke actuator skills\n\n---\n\n## Notes\n\n**Why coverage detection?**\n- **Prevents forgotten requirements**: Ensures every REQ-* gets implemented\n- **Quality gate**: Don't deploy without full coverage\n- **Continuous monitoring**: Coverage can degrade over time\n- **Homeostasis principle**: System self-corrects when coverage drops\n\n**Sensor characteristics**:\n- **Read-only**: Never modifies files (only reads)\n- **Fast**: Lightweight grep operations\n- **Continuous**: Can run frequently without impact\n- **Objective**: Binary decision (covered or not)\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  implementation_coverage: >= 80%\n  test_coverage: >= 80%\n  full_coverage: >= 80%\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/core/propagate-req-keys/SKILL.md": "---\nname: propagate-req-keys\ndescription: Homeostatic actuator that tags code, tests, and commits with REQ-* keys for traceability. Adds \"# Implements:\" tags to code and \"# Validates:\" tags to tests. Use when code or tests are missing requirement tags.\nallowed-tools: [Read, Write, Edit, Grep, Glob]\n---\n\n# propagate-req-keys\n\n**Skill Type**: Actuator (Homeostasis)\n**Purpose**: Tag code and tests with REQ-* keys for traceability\n**Prerequisites**: REQ-* key exists and is validated\n\n---\n\n## Agent Instructions\n\nYou are an **Actuator** in the homeostasis system. Your job is to **correct deviations** from the desired state.\n\n**Desired State**: `all_artifacts_tagged = true` (all code/tests have REQ-* tags)\n\nYour goal is to **add REQ-* tags** to code and tests for bidirectional traceability.\n\n---\n\n## Workflow\n\n### Step 1: Understand What to Tag\n\n**Input**: REQ-* key and files to tag\n\n**Determine tagging target**:\n- **Implementation files** (src/): Add `# Implements: REQ-*`\n- **Test files** (tests/): Add `# Validates: REQ-*`\n- **Feature files** (features/): Add `# Validates: REQ-*`\n- **Commit messages**: Include REQ-* in subject or footer\n\n---\n\n### Step 2: Tag Implementation Files\n\n**Add tag at top of file or above function/class**:\n\n**Python**:\n```python\n# Before\ndef login(email: str, password: str) -> LoginResult:\n    \"\"\"User login functionality\"\"\"\n    return authenticate(email, password)\n\n# After\n# Implements: <REQ-ID>\ndef login(email: str, password: str) -> LoginResult:\n    \"\"\"User login functionality\"\"\"\n    return authenticate(email, password)\n```\n\n**TypeScript**:\n```typescript\n// Before\nexport function login(email: string, password: string): LoginResult {\n  return authenticate(email, password);\n}\n\n// After\n// Implements: <REQ-ID>\nexport function login(email: string, password: string): LoginResult {\n  return authenticate(email, password);\n}\n```\n\n**Java**:\n```java\n// Before\npublic class LoginService {\n    public LoginResult login(String email, String password) {\n        return authenticate(email, password);\n    }\n}\n\n// After\n// Implements: <REQ-ID>\npublic class LoginService {\n    public LoginResult login(String email, String password) {\n        return authenticate(email, password);\n    }\n}\n```\n\n**Tag Placement Rules**:\n- **Function/method**: Tag immediately above function definition\n- **Class**: Tag immediately above class definition\n- **File**: Tag at top of file (if entire file implements one REQ-*)\n- **Multiple REQ-***: Use comma-separated list\n\n**Multiple requirements example**:\n```python\n# Implements: <REQ-ID>, REQ-NFR-SEC-001\ndef secure_login(email: str, password: str, mfa_token: str) -> LoginResult:\n    \"\"\"Secure login with MFA\"\"\"\n    pass\n```\n\n---\n\n### Step 3: Tag Test Files\n\n**Add tag at top of test file or above test function**:\n\n**Python (pytest)**:\n```python\n# Before\ndef test_user_login_with_valid_credentials():\n    result = login(\"user@example.com\", \"SecurePass123!\")\n    assert result.success == True\n\n# After\n# Validates: <REQ-ID>\ndef test_user_login_with_valid_credentials():\n    result = login(\"user@example.com\", \"SecurePass123!\")\n    assert result.success == True\n```\n\n**TypeScript (Jest)**:\n```typescript\n// Before\ntest('user login with valid credentials', () => {\n  const result = login('user@example.com', 'SecurePass123!');\n  expect(result.success).toBe(true);\n});\n\n// After\n// Validates: <REQ-ID>\ntest('user login with valid credentials', () => {\n  const result = login('user@example.com', 'SecurePass123!');\n  expect(result.success).toBe(true);\n});\n```\n\n**Gherkin (BDD)**:\n```gherkin\n# Before\nFeature: User Login\n  Scenario: Successful login\n    Given I am on the login page\n    When I enter valid credentials\n    Then I should see \"Welcome\"\n\n# After\n# Validates: <REQ-ID>\nFeature: User Login\n  Scenario: Successful login\n    Given I am on the login page\n    When I enter valid credentials\n    Then I should see \"Welcome\"\n```\n\n---\n\n### Step 4: Tag Business Rules\n\n**Tag BR-*, C-*, F-* implementations**:\n\n```python\n# Implements: <REQ-ID>, BR-001\ndef validate_email(email: str) -> bool:\n    \"\"\"Email validation (BR-001)\"\"\"\n    pattern = r'^[a-zA-Z0-9._%+-]+@...'\n    return re.match(pattern, email) is not None\n\n# Implements: BR-002\ndef validate_password_length(password: str) -> bool:\n    \"\"\"Password minimum length (BR-002)\"\"\"\n    return len(password) >= 12\n\n# Implements: F-001\ndef calculate_stripe_fee(amount: float) -> float:\n    \"\"\"Stripe fee calculation (F-001)\"\"\"\n    return (amount * 0.029) + 0.30\n```\n\n---\n\n### Step 5: Tag Commit Messages\n\n**Add REQ-* to commit messages**:\n\n**Format 1: In subject line**:\n```\nfeat: Add user login (<REQ-ID>)\n```\n\n**Format 2: In footer**:\n```\nfeat: Add user login\n\nImplement authentication with email and password.\n\nImplements: <REQ-ID>\nValidates: BR-001, BR-002, BR-003\n```\n\n**Format 3: Both**:\n```\nfeat: Add user login (<REQ-ID>)\n\nImplement authentication with email and password.\n\nBusiness Rules:\n- BR-001: Email validation\n- BR-002: Password minimum length\n- BR-003: Account lockout\n\nImplements: <REQ-ID>\nValidates: BR-001, BR-002, BR-003\n```\n\n---\n\n### Step 6: Verify Tags Added\n\n**After tagging, verify**:\n\n```bash\n# Verify implementation tags\ngrep -rn \"# Implements: <REQ-ID>\" src/\n\n# Verify test tags\ngrep -rn \"# Validates: <REQ-ID>\" tests/\n\n# Count tags added\necho \"Implementation tags: $(grep -rc \"# Implements:\" src/ | grep -v \":0\" | wc -l)\"\necho \"Test tags: $(grep -rc \"# Validates:\" tests/ | grep -v \":0\" | wc -l)\"\n```\n\n---\n\n## Output Format\n\nWhen you complete tagging:\n\n```\n[PROPAGATE REQ-KEYS - <REQ-ID>]\n\nFiles Tagged:\n\nImplementation Files (3):\n  âœ“ src/auth/login.py:23\n    Added: # Implements: <REQ-ID>\n  âœ“ src/auth/validators.py:67\n    Added: # Implements: <REQ-ID>, BR-001\n  âœ“ src/auth/lockout.py:34\n    Added: # Implements: <REQ-ID>, BR-003\n\nTest Files (2):\n  âœ“ tests/auth/test_login.py:15\n    Added: # Validates: <REQ-ID>\n  âœ“ features/authentication.feature:8\n    Added: # Validates: <REQ-ID>\n\nTotal Tags Added: 5\n  - Implementation tags: 3\n  - Test tags: 2\n\nTraceability Status:\n  Forward: <REQ-ID> â†’ 3 code files, 2 test files âœ…\n  Backward: Code/tests â†’ <REQ-ID> âœ…\n\nVerification:\n  âœ“ All tags added\n  âœ“ Tags follow format\n  âœ“ Traceability established\n\nâœ… Propagation Complete!\n```\n\n---\n\n## Homeostasis Behavior\n\n**Triggering this actuator**:\n1. **Sensor detects**: Requirements without tags (via check-requirement-coverage)\n2. **Signal**: \"Need tags for <REQ-ID>\"\n3. **User confirms** or auto-invoke if configured\n4. **Actuator runs**: Add tags\n5. **Re-check**: Sensor should show homeostasis achieved\n\n**Homeostasis loop**:\n```\nSensor (check-requirement-coverage):\n  â†’ Deviation: <REQ-ID> has no tags\n  â†’ Signal: \"Missing tags\"\n  â†“\nActuator (propagate-req-keys):\n  â†’ Add tags to code and tests\n  â†’ Report: \"Tags added\"\n  â†“\nSensor (check-requirement-coverage):\n  â†’ Check: <REQ-ID> now has tags\n  â†’ Status: Homeostasis achieved âœ“\n```\n\n---\n\n## Prerequisites Check\n\nBefore invoking this skill, ensure:\n1. REQ-* key exists and is validated\n2. Files to tag exist (code or tests)\n\nIf prerequisites not met:\n- Invalid REQ-* â†’ Use `requirement-traceability` skill to validate\n- No files â†’ Ask user which files implement the requirement\n\n---\n\n## Tag Format Options\n\n### Option 1: Single Line Above\n\n```python\n# Implements: <REQ-ID>\ndef login(email, password):\n    pass\n```\n\n### Option 2: Inline with Docstring\n\n```python\ndef login(email, password):\n    \"\"\"\n    User login functionality.\n\n    Implements: <REQ-ID>\n    Business Rules: BR-001, BR-002, BR-003\n    \"\"\"\n    pass\n```\n\n### Option 3: Multi-Line Block\n\n```python\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# Implements: <REQ-ID>\n# Business Rules: BR-001, BR-002, BR-003\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\ndef login(email, password):\n    pass\n```\n\n**Recommended**: Option 1 (single line, consistent, greppable)\n\n---\n\n## Bulk Tagging\n\n**When tagging multiple files**:\n\n```python\n# Tag all files in a module\nfiles_to_tag = [\n    (\"src/auth/login.py\", \"<REQ-ID>\"),\n    (\"src/auth/validators.py\", \"<REQ-ID>, BR-001\"),\n    (\"src/auth/lockout.py\", \"<REQ-ID>, BR-003\"),\n]\n\nfor file_path, req_keys in files_to_tag:\n    add_tag_to_file(file_path, f\"# Implements: {req_keys}\")\n```\n\n---\n\n## Next Steps\n\nAfter tagging:\n1. Verify tags with `grep -rn \"# Implements:\" src/`\n2. Run coverage check again (should show improved coverage)\n3. Commit changes: `git commit -m \"docs: Add REQ-* tags for traceability\"`\n\n---\n\n## Configuration\n\n```yaml\nplugins:\n  - name: \"@aisdlc/aisdlc-core\"\n    config:\n      propagation:\n        auto_propagate_on_commit: true        # Auto-tag before commit\n        tag_format: \"# Implements: {REQ-KEY}\"\n        test_tag_format: \"# Validates: {REQ-KEY}\"\n        include_business_rules: true          # Also tag BR-*, C-*, F-*\n        placement: \"above\"                    # above | inline | block\n```\n\n---\n\n## Notes\n\n**Why propagate REQ-* keys?**\n- **Bidirectional traceability**: Forward (REQ â†’ code) and backward (code â†’ REQ)\n- **Impact analysis**: Find all code for a requirement\n- **Debugging**: Trace production issues to requirements\n- **Compliance**: Prove requirements are implemented\n\n**Tag visibility**:\n- Tags are **source code comments** (visible in code reviews)\n- Tags are **greppable** (searchable with grep/ripgrep)\n- Tags are **version controlled** (tracked in git)\n- Tags are **persistent** (don't disappear on refactoring)\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  all_code_tagged: true\n  all_tests_tagged: true\n  tags_follow_format: true\n  traceability_bidirectional: true\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/core/requirement-traceability/SKILL.md": "---\nname: requirement-traceability\ndescription: Provides REQ-* key pattern definitions, validation rules, and traceability operations. Use for understanding requirement key formats, validating keys, or tracing requirements through the SDLC lifecycle.\nallowed-tools: [Read, Grep, Glob, Bash]\n---\n\n# requirement-traceability\n\n**Skill Type**: Foundation (Knowledge Base)\n**Purpose**: Define and validate requirement key patterns for traceability\n**Prerequisites**: None (foundation skill)\n\n---\n\n## Agent Instructions\n\nYou provide the **foundational knowledge** for requirement traceability in AI SDLC.\n\nYour role is to:\n1. **Define** REQ-* key patterns\n2. **Validate** requirement keys\n3. **Trace** requirements through SDLC stages\n4. **Support** other skills with traceability knowledge\n\n---\n\n## Requirement Key Patterns\n\n### REQ-F-* (Functional Requirements)\n\n**Pattern**: `REQ-F-{DOMAIN}-{ID}`\n\n**Examples**:\n- `<REQ-ID>` - Authentication functionality\n- `<REQ-ID>` - Payment processing\n- `REQ-F-PORTAL-001` - Customer portal features\n\n**Naming Rules**:\n- DOMAIN: Uppercase, 2-10 chars (AUTH, PAY, PORTAL, USER, ADMIN)\n- ID: Zero-padded 3-digit number (001, 002, ..., 999)\n\n**Validation Regex**: `^REQ-F-[A-Z]{2,10}-\\d{3}$`\n\n---\n\n### REQ-NFR-* (Non-Functional Requirements)\n\n**Pattern**: `REQ-NFR-{TYPE}-{ID}`\n\n**Types**:\n- `PERF` - Performance (response time, throughput)\n- `SEC` - Security (authentication, authorization, encryption)\n- `SCALE` - Scalability (load handling, horizontal scaling)\n- `AVAIL` - Availability (uptime, SLA)\n- `MAINT` - Maintainability (code quality, documentation)\n- `USABIL` - Usability (UX, accessibility)\n\n**Examples**:\n- `REQ-NFR-PERF-001` - Response time < 500ms\n- `REQ-NFR-SEC-001` - Password encryption required\n- `REQ-NFR-SCALE-001` - Support 10,000 concurrent users\n\n**Validation Regex**: `^REQ-NFR-(PERF|SEC|SCALE|AVAIL|MAINT|USABIL)-\\d{3}$`\n\n---\n\n### REQ-DATA-* (Data Quality Requirements)\n\n**Pattern**: `REQ-DATA-{TYPE}-{ID}`\n\n**Types**:\n- `CQ` - Completeness (mandatory fields, null handling)\n- `AQ` - Accuracy (validation, range checks)\n- `CONS` - Consistency (cross-field validation)\n- `TIME` - Timeliness (freshness, latency)\n- `LIN` - Lineage (provenance, transformation tracking)\n- `PII` - Privacy/PII (encryption, masking, GDPR)\n\n**Examples**:\n- `REQ-DATA-CQ-001` - Email field mandatory\n- `REQ-DATA-AQ-001` - Age between 0 and 150\n- `REQ-DATA-PII-001` - Credit card numbers encrypted\n\n**Validation Regex**: `^REQ-DATA-(CQ|AQ|CONS|TIME|LIN|PII)-\\d{3}$`\n\n---\n\n### REQ-BR-* (Business Rules)\n\n**Pattern**: `REQ-BR-{DOMAIN}-{ID}`\n\n**Use Cases**:\n- Complex business logic requiring separate requirement\n- Multi-stage business processes\n- Regulatory compliance rules\n\n**Examples**:\n- `REQ-BR-REFUND-001` - Refund eligibility rules\n- `REQ-BR-DISC-001` - Discount calculation rules\n- `REQ-BR-COMP-001` - GDPR compliance rules\n\n**Validation Regex**: `^REQ-BR-[A-Z]{2,10}-\\d{3}$`\n\n---\n\n## Subordinate Key Patterns\n\nThese are **nested within** requirements for disambiguation:\n\n### BR-* (Business Rules - Nested)\n\n**Pattern**: `BR-{ID}`\n\n**Examples** (nested within <REQ-ID>):\n- `BR-001`: Email validation (regex pattern)\n- `BR-002`: Password minimum 12 characters\n- `BR-003`: Account lockout after 3 attempts\n\n**Use**: Disambiguate vague requirements into specific rules\n\n---\n\n### C-* (Constraints - Nested)\n\n**Pattern**: `C-{ID}`\n\n**Examples** (nested within <REQ-ID>):\n- `C-001`: PCI-DSS Level 1 compliance\n- `C-002`: Stripe API timeout 10 seconds\n- `C-003`: Transaction idempotency required\n\n**Use**: Acknowledge ecosystem E(t) constraints\n\n---\n\n### F-* (Formulas - Nested)\n\n**Pattern**: `F-{ID}`\n\n**Examples** (nested within <REQ-ID>):\n- `F-001`: Stripe fee = (amount * 0.029) + 0.30\n- `F-002`: Idempotency key = SHA256(merchant_id + timestamp + amount)\n\n**Use**: Define precise calculations for code generation\n\n---\n\n## Traceability Workflow\n\n### Forward Traceability (Intent â†’ Runtime)\n\n**Path**: Intent â†’ Requirements â†’ Design â†’ Code â†’ Tests â†’ Runtime\n\n```\nINT-042: \"Add user login\"\n  â†“ (Requirements stage)\n<REQ-ID>: User login with email/password\n  â†“ (Design stage)\nAuthenticationService component\n  â†“ (Code stage)\nsrc/auth/login.py:23  # Implements: <REQ-ID>\n  â†“ (Test stage)\ntests/auth/test_login.py:15  # Validates: <REQ-ID>\n  â†“ (Runtime stage)\nDatadog metric: auth_success{req=\"<REQ-ID>\"}\n```\n\n**Operations**:\n```bash\n# Find all artifacts for a requirement\ngit log --all --grep=\"<REQ-ID>\"           # Commits\ngrep -rn \"<REQ-ID>\" src/                  # Implementation\ngrep -rn \"<REQ-ID>\" tests/                # Tests\ngrep -rn \"<REQ-ID>\" docs/requirements/    # Definition\ngrep -rn \"<REQ-ID>\" docs/design/          # Design\n```\n\n---\n\n### Backward Traceability (Runtime â†’ Intent)\n\n**Path**: Alert â†’ Metric â†’ Code â†’ Requirement â†’ Intent\n\n```\nDatadog alert: \"ERROR: auth_timeout\"\n  â†“ (tagged with)\nMetric: auth_latency{req=\"<REQ-ID>\"}\n  â†“ (find code)\nsrc/auth/login.py:23  # Implements: <REQ-ID>\n  â†“ (find requirement)\ndocs/requirements/auth.md:15  # <REQ-ID>\n  â†“ (find original intent)\nINT-042: \"Add user login\"\n```\n\n**Operations**:\n```bash\n# From alert, find requirement\ngrep \"req=\" alert.json | grep -o \"REQ-[^\\\"]*\"    # Extract REQ key from alert\n\n# From requirement, find original intent\ngrep -rn \"<REQ-ID>\" docs/requirements/ | grep \"INT-\"\n```\n\n---\n\n## Validation Functions\n\n### Validate REQ-* Key Format\n\n**Rules**:\n1. Must start with `REQ-`\n2. Followed by type: `F`, `NFR`, `DATA`, `BR`\n3. Followed by domain/type (2-10 uppercase chars)\n4. Followed by hyphen and 3-digit ID\n5. Total max length: 30 characters\n\n**Valid Examples**:\n- âœ… `<REQ-ID>`\n- âœ… `REQ-NFR-PERF-001`\n- âœ… `REQ-DATA-PII-001`\n- âœ… `REQ-BR-REFUND-001`\n\n**Invalid Examples**:\n- âŒ `REQ-AUTH-001` (missing type: F/NFR/DATA/BR)\n- âŒ `REQ-F-auth-001` (domain must be uppercase)\n- âŒ `REQ-F-AUTH-1` (ID must be 3 digits)\n- âŒ `REQ-F-A-001` (domain too short, min 2 chars)\n\n---\n\n### Extract REQ-* Keys from Text\n\n**Search patterns**:\n```python\nimport re\n\ndef extract_req_keys(text: str) -> list[str]:\n    \"\"\"Extract all REQ-* keys from text\"\"\"\n    pattern = r'REQ-(F|NFR|DATA|BR)-[A-Z]{2,10}-\\d{3}'\n    return re.findall(pattern, text)\n\n# Example\ntext = \"Implements: <REQ-ID>, REQ-NFR-SEC-001\"\nkeys = extract_req_keys(text)  # ['<REQ-ID>', 'REQ-NFR-SEC-001']\n```\n\n---\n\n## Tagging Conventions\n\n### Code Implementation Tags\n\n**Format**: `# Implements: {REQ-KEY}`\n\n**Examples**:\n```python\n# Implements: <REQ-ID>\ndef login(email: str, password: str) -> LoginResult:\n    \"\"\"User login functionality\"\"\"\n    pass\n\n# Implements: <REQ-ID>, BR-001\ndef validate_email(email: str) -> bool:\n    \"\"\"Email validation (BR-001)\"\"\"\n    pass\n```\n\n**Multiple implementations**:\n```python\n# Implements: <REQ-ID>, REQ-NFR-SEC-001\n# This function satisfies both authentication and security requirements\ndef secure_login(email: str, password: str, mfa_token: str) -> LoginResult:\n    pass\n```\n\n---\n\n### Test Validation Tags\n\n**Format**: `# Validates: {REQ-KEY}`\n\n**Examples**:\n```python\n# Validates: <REQ-ID>\ndef test_user_login_with_valid_credentials():\n    \"\"\"Test successful login\"\"\"\n    result = login(\"user@example.com\", \"SecurePass123!\")\n    assert result.success == True\n\n# Validates: BR-001\ndef test_email_validation():\n    \"\"\"Test email format validation (BR-001)\"\"\"\n    assert validate_email(\"invalid\") == False\n```\n\n---\n\n### Commit Message Tags\n\n**Format**: Include REQ-* in commit subject or footer\n\n**Examples**:\n```\nfeat: Add user login (<REQ-ID>)\n\nImplements: <REQ-ID>\nValidates: BR-001, BR-002, BR-003\n```\n\n**Search commits**:\n```bash\n# Find all commits for a requirement\ngit log --all --grep=\"<REQ-ID>\"\n\n# Find commits by requirement type\ngit log --all --grep=\"REQ-F-\"      # All functional requirements\ngit log --all --grep=\"REQ-NFR-\"    # All non-functional requirements\n```\n\n---\n\n### Runtime Telemetry Tags\n\n**Logs**:\n```python\nlogger.info(\n    \"User login successful\",\n    extra={\"req\": \"<REQ-ID>\", \"user_id\": user.id}\n)\n```\n\n**Metrics (Datadog)**:\n```python\nstatsd.increment(\n    \"auth.login.success\",\n    tags=[\"req:<REQ-ID>\", \"env:production\"]\n)\n```\n\n**Metrics (Prometheus)**:\n```python\nauth_success_total{req=\"<REQ-ID>\", env=\"production\"}\n```\n\n---\n\n## Traceability Matrix\n\n### Structure\n\n| REQ-* | Requirement Doc | Design | Code | Tests | Commits | Runtime |\n|-------|----------------|--------|------|-------|---------|---------|\n| <REQ-ID> | auth.md:15 | AuthService | login.py:23 | test_login.py:15 | 5 commits | Datadog âœ… |\n| REQ-NFR-PERF-001 | perf.md:8 | CacheLayer | cache.py:45 | test_cache.py:22 | 3 commits | Prometheus âœ… |\n\n### Query Operations\n\n**Find coverage gaps**:\n```bash\n# Requirements with no code\ngrep -rh \"^## REQ-\" docs/requirements/ | \\\n  while read req; do\n    grep -q \"$req\" src/ || echo \"$req - NO CODE\"\n  done\n\n# Requirements with no tests\ngrep -rh \"^## REQ-\" docs/requirements/ | \\\n  while read req; do\n    grep -q \"$req\" tests/ || echo \"$req - NO TESTS\"\n  done\n```\n\n---\n\n## Usage in Other Skills\n\n### In TDD Workflow\n\n```python\n# tdd-workflow skill uses requirement-traceability to:\n1. Validate REQ-* key format\n2. Extract REQ-* from user intent\n3. Tag code with \"# Implements: REQ-*\"\n4. Tag tests with \"# Validates: REQ-*\"\n5. Include REQ-* in commit messages\n```\n\n### In Coverage Detection\n\n```python\n# check-requirement-coverage skill uses requirement-traceability to:\n1. Find all REQ-* keys in requirements docs\n2. Search for \"# Implements: REQ-*\" in src/\n3. Search for \"# Validates: REQ-*\" in tests/\n4. Report requirements without coverage\n```\n\n### In Code Generation\n\n```python\n# autogenerate-from-business-rules skill uses requirement-traceability to:\n1. Extract BR-*, C-*, F-* from REQ-*\n2. Tag generated code with REQ-* and BR-*\n3. Generate tests tagged with \"# Validates: BR-*\"\n```\n\n---\n\n## Configuration\n\nAccess via plugin configuration:\n\n```yaml\nplugins:\n  - name: \"@aisdlc/aisdlc-core\"\n    config:\n      req_key_patterns:\n        functional: \"REQ-F-{DOMAIN}-{ID}\"\n        non_functional: \"REQ-NFR-{DOMAIN}-{ID}\"\n        data_quality: \"REQ-DATA-{DOMAIN}-{ID}\"\n        business_rule: \"REQ-BR-{DOMAIN}-{ID}\"\n\n      coverage:\n        minimum_percentage: 80\n        require_req_tags: true\n\n      propagation:\n        auto_propagate_on_commit: true\n        tag_format: \"# Implements: {REQ-KEY}\"\n        test_tag_format: \"# Validates: {REQ-KEY}\"\n```\n\n---\n\n## Traceability Operations\n\n### Operation 1: Trace Forward (REQ â†’ Artifacts)\n\n**Input**: `<REQ-ID>`\n\n**Output**:\n```\n<REQ-ID>: User login with email/password\nâ”‚\nâ”œâ”€ ğŸ“‹ Requirements\nâ”‚   â””â”€ docs/requirements/authentication.md:15\nâ”‚\nâ”œâ”€ ğŸ¨ Design\nâ”‚   â”œâ”€ docs/design/auth-service.md:42\nâ”‚   â””â”€ docs/adrs/ADR-003-auth-approach.md:10\nâ”‚\nâ”œâ”€ ğŸ’» Implementation\nâ”‚   â”œâ”€ src/auth/login.py:23  # Implements: <REQ-ID>\nâ”‚   â”œâ”€ src/auth/validators.py:67  # Implements: <REQ-ID>, BR-001\nâ”‚   â””â”€ src/auth/lockout.py:34  # Implements: <REQ-ID>, BR-003\nâ”‚\nâ”œâ”€ âœ… Tests\nâ”‚   â”œâ”€ tests/auth/test_login.py:15  # Validates: <REQ-ID>\nâ”‚   â”œâ”€ tests/auth/test_validators.py:22  # Validates: BR-001\nâ”‚   â””â”€ features/authentication.feature:5  # Validates: <REQ-ID>\nâ”‚\nâ”œâ”€ ğŸ“¦ Commits\nâ”‚   â”œâ”€ abc123 \"feat: Add user login (<REQ-ID>)\"\nâ”‚   â”œâ”€ def456 \"fix: Correct email validation (<REQ-ID>, BR-001)\"\nâ”‚   â””â”€ ghi789 \"perf: Optimize login query (<REQ-ID>)\"\nâ”‚\nâ””â”€ ğŸš€ Runtime\n    â”œâ”€ Logs: logger.info(\"Login\", extra={\"req\": \"<REQ-ID>\"})\n    â”œâ”€ Metrics: auth_success{req=\"<REQ-ID>\"}\n    â””â”€ Alerts: \"ERROR: <REQ-ID> - Auth timeout\"\n\nCoverage: âœ… Full traceability\n```\n\n**Implementation**:\n```bash\n# Grep across all files\ngrep -rn \"<REQ-ID>\" docs/ src/ tests/ features/\n\n# Git log\ngit log --all --grep=\"<REQ-ID>\" --name-only\n```\n\n---\n\n### Operation 2: Trace Backward (Code â†’ REQ)\n\n**Input**: `src/auth/login.py`\n\n**Output**:\n```\nsrc/auth/login.py implements:\nâ”œâ”€ <REQ-ID> (line 23)\nâ”œâ”€ REQ-NFR-SEC-001 (line 45)\nâ””â”€ REQ-NFR-PERF-001 (line 89)\n\nTracing to requirements:\nâ”œâ”€ <REQ-ID> â†’ docs/requirements/authentication.md:15\nâ”‚   â””â”€ Intent: INT-042 \"Add user login\"\nâ”‚\nâ”œâ”€ REQ-NFR-SEC-001 â†’ docs/requirements/security.md:8\nâ”‚   â””â”€ Intent: INT-043 \"Secure authentication\"\nâ”‚\nâ””â”€ REQ-NFR-PERF-001 â†’ docs/requirements/performance.md:12\n    â””â”€ Intent: INT-050 \"Optimize login performance\"\n```\n\n**Implementation**:\n```bash\n# Extract REQ-* from file\ngrep \"# Implements:\" src/auth/login.py | grep -o \"REQ-[^ ,]*\"\n\n# Find requirement definitions\nfor req in $(grep \"# Implements:\" src/auth/login.py | grep -o \"REQ-[^ ,]*\"); do\n  grep -rn \"^## $req\" docs/requirements/\ndone\n```\n\n---\n\n### Operation 3: Coverage Report\n\n**Input**: All requirements\n\n**Output**:\n```\nRequirement Coverage Report\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nTotal Requirements: 42\n\nBy Type:\nâ”œâ”€ REQ-F-*    : 28 (Functional)\nâ”œâ”€ REQ-NFR-*  : 8  (Non-Functional)\nâ”œâ”€ REQ-DATA-* : 4  (Data Quality)\nâ””â”€ REQ-BR-*   : 2  (Business Rules)\n\nCoverage by Stage:\nâ”œâ”€ Requirements â†’ Design: 100% (42/42) âœ…\nâ”œâ”€ Design â†’ Code: 86% (36/42) âš ï¸\nâ”œâ”€ Code â†’ Tests: 100% (36/36) âœ…\nâ”œâ”€ Tests â†’ Runtime: 25% (9/36) âš ï¸\n\nRequirements Without Code (6):\nâ”œâ”€ REQ-F-PROFILE-001 - User profile editing\nâ”œâ”€ REQ-F-PROFILE-002 - Avatar upload\nâ”œâ”€ REQ-F-NOTIF-001 - Email notifications\nâ”œâ”€ REQ-F-NOTIF-002 - Push notifications\nâ”œâ”€ REQ-NFR-PERF-002 - Database query optimization\nâ””â”€ REQ-DATA-LIN-001 - Data lineage tracking\n\nRequirements Without Runtime Telemetry (27):\nâ”œâ”€ <REQ-ID> (has code, no metrics)\nâ”œâ”€ REQ-F-AUTH-003 (has code, no metrics)\nâ”œâ”€ ... (25 more)\n\nRecommendations:\n1. Implement 6 requirements missing code\n2. Add telemetry tags to 27 requirements\n```\n\n---\n\n## Homeostasis Support\n\n### Sensor Skills Use This Skill To:\n- Validate REQ-* key format\n- Extract REQ-* from files\n- Check coverage gaps\n\n### Actuator Skills Use This Skill To:\n- Tag code with correct format\n- Create properly formatted commit messages\n- Generate traceability reports\n\n---\n\n## Output Format\n\nWhen invoked for validation:\n\n```\n[REQUIREMENT TRACEABILITY]\n\nValidating: <REQ-ID>\n\nFormat Check:\n  âœ“ Starts with \"REQ-\"\n  âœ“ Type: F (Functional)\n  âœ“ Domain: AUTH (valid, 4 chars)\n  âœ“ ID: 001 (valid, 3 digits)\n\nResult: âœ… VALID\n\nPattern: REQ-F-{DOMAIN}-{ID}\nRegex: ^REQ-F-[A-Z]{2,10}-\\d{3}$\n```\n\nWhen invoked for tracing:\n\n```\n[TRACE: <REQ-ID>]\n\nForward Traceability:\n  âœ… Requirements: docs/requirements/auth.md:15\n  âœ… Design: docs/design/auth-service.md:42\n  âœ… Code: src/auth/login.py:23 (+ 2 more files)\n  âœ… Tests: tests/auth/test_login.py:15 (+ 1 more files)\n  âœ… Commits: 5 commits found\n  âš ï¸ Runtime: No telemetry tags (needs setup)\n\nCoverage: 83% (5/6 stages)\nMissing: Runtime telemetry\n```\n\n---\n\n## Notes\n\n**Why requirement traceability?**\n- **Compliance**: Regulations require proof of implementation\n- **Impact Analysis**: Know what to change when requirement updates\n- **Debugging**: Trace production issues back to requirements\n- **Audit Trail**: Prove all requirements are implemented\n- **Living Documentation**: Code comments link to requirements\n\n**Key Principles**:\n- REQ-* keys are **immutable** (content can evolve, keys never change)\n- REQ-* keys are **unique** (no duplicates)\n- REQ-* keys are **human-readable** (domain + sequential ID)\n- REQ-* keys are **everywhere** (requirements â†’ code â†’ tests â†’ runtime)\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  all_requirements_have_unique_keys: true\n  all_keys_follow_pattern: true\n  all_artifacts_tagged: true\n  full_traceability: true\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/design/create-adrs/SKILL.md": "---\nname: create-adrs\ndescription: Create Architecture Decision Records (ADRs) documenting strategic technical decisions while acknowledging ecosystem E(t) constraints. Use when choosing cloud providers, languages, frameworks, databases, or architectural patterns.\nallowed-tools: [Read, Write, Edit]\n---\n\n# create-adrs\n\n**Skill Type**: Actuator (Design Documentation)\n**Purpose**: Document architecture decisions acknowledging ecosystem E(t)\n**Prerequisites**: Strategic technical decision needed\n\n---\n\n## Agent Instructions\n\nYou are creating **Architecture Decision Records (ADRs)** that acknowledge **ecosystem E(t)** constraints.\n\n**Critical**: ADRs document **GIVEN** constraints (E(t)), not just **CHOSEN** solutions.\n\n**Format**: \"Given E(t), we chose X\" (not \"we chose X\")\n\n---\n\n## ADR Structure\n\n### Template\n\n```markdown\n# ADR-{ID}: {Decision Title}\n\n**Date**: {YYYY-MM-DD}\n**Status**: Accepted | Rejected | Superseded | Deprecated\n**Deciders**: {Who made this decision}\n\n---\n\n## Context\n\n**Requirements**:\n- <REQ-ID>: User authentication\n- REQ-NFR-SEC-001: Secure password storage\n\n**Problem**:\nWe need to choose a password hashing algorithm that is secure\nagainst brute force attacks while maintaining acceptable performance.\n\n**Ecosystem E(t) Constraints**:\n- Team Experience: Team familiar with bcrypt\n- Infrastructure: Running on AWS (bcrypt supported)\n- Compliance: PCI-DSS recommends strong hashing\n- Performance: Login response must be < 500ms (REQ-NFR-PERF-001)\n- Libraries Available: bcrypt, argon2, scrypt available\n\n---\n\n## Decision\n\n**Selected**: bcrypt with cost factor 12\n\n**Rejected Alternatives**:\n- SHA256: âŒ Too fast (vulnerable to brute force)\n- MD5: âŒ Cryptographically broken\n- Argon2: âš ï¸ Better security but team unfamiliar, migration risk\n- scrypt: âš ï¸ Good security but less widely supported\n\n**Rationale**:\n1. bcrypt is industry standard (acknowledged E(t))\n2. Team has experience with bcrypt (acknowledge E(t) - team capabilities)\n3. Cost factor 12 balances security and performance\n4. Meets PCI-DSS requirements (acknowledge E(t) - compliance)\n5. Login tests show 200ms average (well within 500ms SLA)\n\n---\n\n## Ecosystem Constraints Acknowledged\n\n**Team** (E(t)):\n- Team knows: bcrypt, SHA256\n- Team doesn't know: Argon2 implementation\n- Risk: Learning curve with Argon2\n\n**Infrastructure** (E(t)):\n- Platform: AWS Lambda + RDS PostgreSQL\n- bcrypt: Native support, no additional dependencies\n- Argon2: Would need custom layer\n\n**Compliance** (E(t)):\n- PCI-DSS: Requires strong, salted hashing\n- bcrypt: Explicitly mentioned in PCI guidelines\n- Audit: External auditors familiar with bcrypt\n\n**Performance** (E(t)):\n- Requirement: Login < 500ms (REQ-NFR-PERF-001)\n- bcrypt (cost 12): ~200ms (acceptable)\n- Argon2: ~250ms (acceptable but no experience)\n\n**Timeline** (E(t)):\n- Sprint: 2 weeks\n- bcrypt: No learning curve (immediate)\n- Argon2: 2-3 days research + testing\n\n---\n\n## Constraints Imposed Downstream\n\n**Code Stage** (constraints for implementation):\n- MUST use bcrypt library (not custom hashing)\n- MUST use cost factor 12 (not lower)\n- MUST salt passwords (bcrypt does this automatically)\n\n**Runtime Stage** (constraints for deployment):\n- Infrastructure: bcrypt library must be available\n- Performance monitoring: Track hash time (should be ~200ms)\n\n**Testing Stage**:\n- Test hash time (ensure < 500ms)\n- Test bcrypt version (security updates)\n\n---\n\n## Consequences\n\n**Positive**:\n- âœ… Team productive immediately (no learning curve)\n- âœ… Proven security (industry standard)\n- âœ… PCI-DSS compliant (audit-friendly)\n- âœ… Performance acceptable (< 500ms)\n\n**Negative**:\n- âš ï¸ Not latest algorithm (Argon2 is newer)\n- âš ï¸ Vendor lock-in to bcrypt (migration costly)\n\n**Neutral**:\n- Cost factor 12 is balance (could be 10 for faster, 14 for stronger)\n\n---\n\n## Related Decisions\n\n- ADR-001: Database selection (PostgreSQL)\n- ADR-003: Session management (JWT)\n\n**Supersedes**: None\n**Superseded By**: None\n\n---\n\n## References\n\n- PCI-DSS Password Requirements: https://www.pcisecuritystandards.org/\n- bcrypt Documentation: https://en.wikipedia.org/wiki/Bcrypt\n- OWASP Password Storage: https://cheatsheetseries.owasp.org/cheatsheets/Password_Storage_Cheat_Sheet.html\n```\n\n---\n\n## ADR Numbering\n\n**Sequential**: ADR-001, ADR-002, ADR-003, ...\n\n**Categories**:\n- Infrastructure: Cloud provider, hosting, databases\n- Security: Authentication, encryption, authorization\n- Architecture: Patterns, frameworks, languages\n- Integration: APIs, external services\n- Data: Storage, schemas, migration\n\n---\n\n## When to Create ADRs\n\n**Create ADR for**:\n- âœ… Cloud provider choice (AWS vs GCP vs Azure)\n- âœ… Language/framework choice (Python vs Node vs Java)\n- âœ… Database choice (PostgreSQL vs MySQL vs MongoDB)\n- âœ… Authentication approach (JWT vs sessions vs OAuth)\n- âœ… API style (REST vs GraphQL vs gRPC)\n- âœ… Architectural pattern (monolith vs microservices)\n\n**Don't create ADR for**:\n- âŒ Implementation details (already covered by code)\n- âŒ Tactical decisions (variable names, file structure)\n- âŒ Obvious choices (using standard library)\n\n---\n\n## Output Format\n\n```\n[CREATE ADR - bcrypt Password Hashing]\n\nDecision: Use bcrypt for password hashing\n\nContext:\n  Requirements: <REQ-ID>, REQ-NFR-SEC-001\n  Problem: Need secure password hashing\n  Ecosystem E(t): Team knows bcrypt, PCI-DSS compliant, AWS supported\n\nDecision:\n  Selected: bcrypt (cost factor 12)\n  Rejected: SHA256 (too fast), Argon2 (team unfamiliar)\n\nEcosystem Constraints Acknowledged:\n  - Team capabilities: knows bcrypt âœ“\n  - Compliance: PCI-DSS requires strong hashing âœ“\n  - Performance: Must be < 500ms âœ“\n  - Infrastructure: AWS supports bcrypt âœ“\n\nConstraints Imposed:\n  - Code must use bcrypt library\n  - Code must use cost factor 12\n  - Runtime must have bcrypt available\n\nCreated: docs/adrs/ADR-002-password-hashing.md\n\nâœ… ADR Created!\n   Architecture decision documented\n   Ecosystem E(t) acknowledged\n   Downstream constraints clear\n```\n\n---\n\n## Notes\n\n**Why ADRs?**\n- **Document \"why\"**: Explains reasoning behind decisions\n- **Acknowledge E(t)**: Shows we understand ecosystem constraints\n- **Prevent re-litigation**: Decision made, recorded, done\n- **Onboarding**: New team members understand past decisions\n\n**ADRs vs Constraints (C-*)**:\n- **C-***: Given constraints we MUST work within\n- **ADR**: Chosen solutions GIVEN those constraints\n\n**Example**:\n```\nC-001: PCI-DSS requires strong password hashing (GIVEN)\nADR-002: We chose bcrypt (GIVEN C-001 and team skills)\n```\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  all_strategic_decisions_documented: true\n  ecosystem_constraints_acknowledged: true\n  rationale_clear: true\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/design/design-with-traceability/SKILL.md": "---\nname: design-with-traceability\ndescription: Create technical solution architecture from requirements with REQ-* traceability. Designs components, APIs, data models, and interactions. Tags all design artifacts with requirement keys. Use after requirements are validated, before coding starts.\nallowed-tools: [Read, Write, Edit, Grep, Glob]\n---\n\n# design-with-traceability\n\n**Skill Type**: Actuator (Design Stage)\n**Purpose**: Transform requirements into technical solution architecture\n**Prerequisites**: Requirements validated (REQ-*), quality gate passed\n\n---\n\n## Agent Instructions\n\nYou are creating **technical solution architecture** from requirements.\n\nYour goal is to design:\n1. **Components** (services, modules, classes)\n2. **APIs** (endpoints, contracts, protocols)\n3. **Data Models** (schemas, entities, relationships)\n4. **Interactions** (sequence diagrams, data flows)\n\n**All tagged with REQ-* keys** for traceability.\n\n---\n\n## Workflow\n\n### Step 1: Discover and Review Requirements\n\n**Find all requirement files**:\n\n```bash\n# Discover requirements from folder\nREQUIREMENTS_DIR=\"${REQUIREMENTS_DIR:-.ai-workspace/requirements}\"\nrequirements=$(find \"$REQUIREMENTS_DIR\" -type f \\( -name \"*.md\" -o -name \"*.yml\" -o -name \"*.yaml\" \\))\n\necho \"Found requirements:\"\nfor req in $requirements; do\n  echo \"  - $req\"\ndone\n```\n\n**Read and understand requirements**:\n\n```markdown\nrequirements/functional/user-login.md:\n  Title: User Login Feature\n  Content: User wants to log in with email/password\n  Priority: P0\n\nrequirements/functional/password-reset.md:\n  Title: Password Reset\n  Content: User can reset forgotten password via email\n  Priority: P1\n\nrequirements/non-functional/security.yml:\n  encryption: bcrypt\n  session: JWT (30min timeout)\n\nrequirements/non-functional/performance.yml:\n  login_response: <500ms\n  db_timeout: 100ms\n\nrequirements/business-rules/email-validation.md:\n  regex: RFC 5322 compliant\n  normalization: lowercase\n\nrequirements/business-rules/password-policy.md:\n  minimum_length: 12\n  max_attempts: 3\n  lockout_duration: 15min\n```\n\n---\n\n### Step 2: Design Components\n\n**Identify components needed**:\n\n```yaml\n# docs/design/authentication-architecture.md\n\n# Implements:\n#   - requirements/functional/user-login.md\n#   - requirements/functional/password-reset.md\n#\n# References:\n#   - requirements/non-functional/security.yml\n#   - requirements/non-functional/performance.yml\n#   - requirements/business-rules/email-validation.md\n#   - requirements/business-rules/password-policy.md\n\n## Components\n\n### AuthenticationService\n**Implements**:\n  - requirements/functional/user-login.md\n  - requirements/functional/password-reset.md\n\n**Purpose**: Handle user authentication and password management\n\n**Responsibilities**:\n- User login (requirements/functional/user-login.md)\n- Password reset (requirements/functional/password-reset.md)\n- Session management (requirements/non-functional/security.yml)\n\n**Methods**:\n- `login(email, password)` â†’ LoginResult\n- `request_password_reset(email)` â†’ ResetResult\n- `reset_password(token, new_password)` â†’ ResetResult\n\n**Dependencies**:\n- EmailValidator (requirements/business-rules/email-validation.md)\n- PasswordValidator (requirements/business-rules/password-policy.md)\n- LockoutTracker (requirements/business-rules/password-policy.md: lockout)\n- PasswordHasher (requirements/non-functional/security.yml: bcrypt)\n- SessionManager (requirements/non-functional/security.yml: JWT)\n\n---\n\n### EmailValidator\n**Implements**: requirements/business-rules/email-validation.md\n**Purpose**: Validate email format and normalization\n**Methods**:\n- `validate(email)` â†’ bool\n- `normalize(email)` â†’ str (lowercase)\n\n---\n\n### PasswordValidator\n**Implements**: requirements/business-rules/password-policy.md\n**Purpose**: Validate password requirements\n**Methods**:\n- `validate_length(password)` â†’ bool (minimum 12 chars)\n- `validate_complexity(password)` â†’ bool\n\n---\n\n### LockoutTracker\n**Implements**: requirements/business-rules/password-policy.md (lockout section)\n**Purpose**: Track failed login attempts and manage lockouts\n**Methods**:\n- `record_failed_attempt(user_id)` â†’ bool (is_locked)\n- `is_locked(user_id)` â†’ bool\n- `get_remaining_time(user_id)` â†’ int (minutes)\n- `reset(user_id)` â†’ void\n\n---\n\n### PasswordHasher\n**Implements**: requirements/non-functional/security.yml (encryption)\n**Purpose**: Hash and verify passwords using bcrypt\n**Methods**:\n- `hash(password)` â†’ str\n- `verify(password, hash)` â†’ bool\n\n---\n\n### SessionManager\n**Implements**: requirements/non-functional/security.yml (session management)\n**Purpose**: Manage JWT sessions with 30min timeout\n**Methods**:\n- `create_session(user_id)` â†’ str (JWT token)\n- `validate_session(token)` â†’ bool\n- `refresh_session(token)` â†’ str (new token)\n```\n\n---\n\n### Step 3: Design APIs\n\n**Define API contracts**:\n\n```yaml\n# API Design (tagged with requirement files)\n\n## POST /api/v1/auth/login\n**Implements**: requirements/functional/user-login.md\n\n**Request**:\n{\n  \"email\": \"user@example.com\",\n  \"password\": \"SecurePass123!\"\n}\n\n**Response (Success - 200)**:\n{\n  \"success\": true,\n  \"token\": \"eyJhbGciOiJIUzI1NiIs...\",\n  \"user\": {\n    \"id\": \"user_123\",\n    \"email\": \"user@example.com\"\n  }\n}\n\n**Response (Error - 400)**:\n{\n  \"success\": false,\n  \"error\": \"Invalid email format\"\n  # requirements/business-rules/email-validation.md\n}\n\n**Response (Error - 401)**:\n{\n  \"success\": false,\n  \"error\": \"Invalid credentials\"\n}\n\n**Response (Error - 429)**:\n{\n  \"success\": false,\n  \"error\": \"Account locked. Try again in 12 minutes\"\n  # requirements/business-rules/password-policy.md (lockout)\n}\n\n**Validation**:\n- Email: requirements/business-rules/email-validation.md (regex validation)\n- Password: requirements/business-rules/password-policy.md (minimum length)\n- Lockout: requirements/business-rules/password-policy.md (3 attempts, 15min)\n\n**Performance**: requirements/non-functional/performance.yml (< 500ms response)\n\n---\n\n## POST /api/v1/auth/password-reset-request\n**Implements**: requirements/functional/password-reset.md\n\n**Request**:\n{\n  \"email\": \"user@example.com\"\n}\n\n**Response (Success - 200)**:\n{\n  \"success\": true,\n  \"message\": \"If email exists, reset link sent\"\n}\n```\n\n---\n\n### Step 4: Design Data Models\n\n**Define schemas and entities**:\n\n```yaml\n# Data Model Design\n\n## User Entity\n**Implements**:\n  - requirements/functional/user-login.md\n  - requirements/functional/password-reset.md\n\n**Schema**:\n{\n  \"id\": \"uuid\",\n  \"email\": \"string (unique, lowercase, max 255)\",\n  \"password_hash\": \"string (bcrypt hash)\",\n  \"created_at\": \"timestamp\",\n  \"updated_at\": \"timestamp\"\n}\n\n**Constraints**:\n- email: UNIQUE index, NOT NULL\n- password_hash: NOT NULL (requirements/non-functional/security.yml: bcrypt)\n\n**Requirements Satisfied**:\n- requirements/functional/user-login.md: Stores credentials\n- requirements/business-rules/email-validation.md: Email unique and normalized\n- requirements/non-functional/security.yml: Password hashed with bcrypt\n\n---\n\n## LoginAttempt Entity\n**Implements**: requirements/business-rules/password-policy.md (lockout tracking)\n\n**Schema**:\n{\n  \"id\": \"uuid\",\n  \"user_id\": \"uuid (foreign key to User)\",\n  \"timestamp\": \"timestamp\",\n  \"success\": \"boolean\",\n  \"ip_address\": \"string\"\n}\n\n**Indexes**:\n- (user_id, timestamp) - For querying recent attempts\n\n**Requirements Satisfied**:\n- requirements/business-rules/password-policy.md: Track failed attempts\n- requirements/business-rules/password-policy.md: Calculate lockout expiry from timestamps\n\n---\n\n## Session Entity\n**Implements**: requirements/non-functional/security.yml (session management)\n\n**Schema**:\n{\n  \"id\": \"uuid\",\n  \"user_id\": \"uuid (foreign key to User)\",\n  \"token\": \"string (JWT)\",\n  \"created_at\": \"timestamp\",\n  \"expires_at\": \"timestamp\",\n  \"last_activity\": \"timestamp\"\n}\n\n**Constraints**:\n- token: UNIQUE\n- expires_at: created_at + 30 minutes (requirements/non-functional/security.yml)\n\n**Requirements Satisfied**:\n- requirements/non-functional/security.yml: JWT sessions with 30min timeout\n```\n\n---\n\n### Step 5: Create Component Diagram\n\n**Visualize architecture**:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Client (Web/Mobile)                         â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                  â”‚\n                  â–¼\n        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n        â”‚ API Layer           â”‚\n        â”‚ /api/v1/auth/*      â”‚\n        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                  â”‚\n                  â–¼\n        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n        â”‚ AuthenticationService                â”‚ â† requirements/functional/\n        â”‚ - login()                            â”‚    user-login.md,\n        â”‚ - request_password_reset()           â”‚    password-reset.md\n        â”‚ - reset_password()                   â”‚\n        â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜\n            â”‚                              â”‚\n            â–¼                              â–¼\n    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n    â”‚ Validators    â”‚             â”‚ LockoutTracker   â”‚\n    â”‚ - Email       â”‚ â† email-    â”‚                  â”‚ â† password-policy.md\n    â”‚ - Password    â”‚   validation â”‚                  â”‚   (lockout)\n    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   .md       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n            â”‚                              â”‚\n            â–¼                              â–¼\n        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n        â”‚ Database (PostgreSQL)               â”‚\n        â”‚ - User table                        â”‚\n        â”‚ - LoginAttempt table                â”‚\n        â”‚ - Session table                     â”‚\n        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\nReferences:\n- requirements/non-functional/security.yml: bcrypt, JWT\n- requirements/non-functional/performance.yml: <500ms, 100ms DB timeout\n- requirements/business-rules/email-validation.md\n- requirements/business-rules/password-policy.md\n```\n\n---\n\n### Step 6: Tag All Design Artifacts\n\n**Reference requirement files in all design documents**:\n\n```markdown\n# .ai-workspace/designs/authentication-architecture.md\n\n# Implements:\n#   - .ai-workspace/requirements/functional/user-login.md\n#   - .ai-workspace/requirements/functional/password-reset.md\n#\n# References:\n#   - .ai-workspace/requirements/non-functional/security.yml\n#   - .ai-workspace/requirements/non-functional/performance.yml\n#   - .ai-workspace/requirements/business-rules/email-validation.md\n#   - .ai-workspace/requirements/business-rules/password-policy.md\n\n## Architecture Overview\n\nThis design implements user authentication and password reset.\n```\n\n---\n\n### Step 7: Create Traceability Matrix\n\n**Map requirement files to design components**:\n\n| Requirement File | Component | API | Data Model | Diagram |\n|-----------------|-----------|-----|------------|---------|\n| requirements/functional/user-login.md | AuthenticationService | POST /auth/login | User, LoginAttempt, Session | Fig 1 |\n| requirements/functional/password-reset.md | AuthenticationService | POST /auth/password-reset | User, PasswordResetToken | Fig 1 |\n| requirements/business-rules/email-validation.md | EmailValidator | - | - | Fig 2 |\n| requirements/business-rules/password-policy.md | PasswordValidator, LockoutTracker | - | LoginAttempt | Fig 2, 3 |\n\n---\n\n### Step 8: Commit Design\n\n```bash\ngit add .ai-workspace/designs/\ngit commit -m \"DESIGN: Create architecture for authentication\n\nDesign technical solution for user authentication and password reset.\n\nImplements:\n  - .ai-workspace/requirements/functional/user-login.md\n  - .ai-workspace/requirements/functional/password-reset.md\n\nReferences:\n  - .ai-workspace/requirements/non-functional/security.yml\n  - .ai-workspace/requirements/non-functional/performance.yml\n  - .ai-workspace/requirements/business-rules/email-validation.md\n  - .ai-workspace/requirements/business-rules/password-policy.md\n\nComponents:\n- AuthenticationService (user-login.md, password-reset.md)\n- EmailValidator (email-validation.md)\n- PasswordValidator (password-policy.md)\n- LockoutTracker (password-policy.md: lockout)\n- PasswordHasher (security.yml: bcrypt)\n- SessionManager (security.yml: JWT)\n\nAPIs:\n- POST /api/v1/auth/login\n- POST /api/v1/auth/password-reset-request\n- POST /api/v1/auth/password-reset\n\nData Models:\n- User entity (email, password_hash)\n- LoginAttempt entity (lockout tracking)\n- Session entity (JWT tokens)\n\nTraceability:\n- requirements/functional/user-login.md â†’ AuthenticationService â†’ login()\n- requirements/functional/password-reset.md â†’ AuthenticationService â†’ reset()\n\nDesign Coverage: 100% (all requirements have design)\n\"\n```\n\n---\n\n## Output Format\n\n```\n[DESIGN WITH TRACEABILITY - Authentication]\n\nRequirements Implemented:\n  - requirements/functional/user-login.md\n  - requirements/functional/password-reset.md\n\nRequirements Referenced:\n  - requirements/non-functional/security.yml\n  - requirements/non-functional/performance.yml\n  - requirements/business-rules/email-validation.md\n  - requirements/business-rules/password-policy.md\n\nDesign Created:\n\nComponents (6):\n  âœ“ AuthenticationService (user-login.md, password-reset.md)\n  âœ“ EmailValidator (email-validation.md)\n  âœ“ PasswordValidator (password-policy.md)\n  âœ“ LockoutTracker (password-policy.md: lockout)\n  âœ“ PasswordHasher (security.yml: bcrypt)\n  âœ“ SessionManager (security.yml: JWT)\n\nAPIs (3):\n  âœ“ POST /api/v1/auth/login (user-login.md)\n  âœ“ POST /api/v1/auth/password-reset-request (password-reset.md)\n  âœ“ POST /api/v1/auth/password-reset (password-reset.md)\n\nData Models (3):\n  âœ“ User entity (email, password_hash)\n  âœ“ LoginAttempt entity (lockout tracking)\n  âœ“ Session entity (JWT tokens)\n\nDiagrams:\n  âœ“ Component diagram (architecture-overview.png)\n  âœ“ Sequence diagram (login-flow.png)\n  âœ“ Data model diagram (authentication-erd.png)\n\nFiles Created:\n  + .ai-workspace/designs/authentication-architecture.md (287 lines)\n  + .ai-workspace/designs/diagrams/authentication-components.png\n  + .ai-workspace/designs/api-specs/auth-api.yml (OpenAPI spec)\n\nTraceability:\n  âœ“ All components reference requirement files\n  âœ“ All APIs reference requirement files\n  âœ“ All data models reference requirement files\n  âœ“ Traceability matrix created\n\nDesign Coverage: 100% (2/2 requirements have complete design)\n\nâœ… Design Complete!\n   Ready for ADRs and implementation\n```\n\n---\n\n## Prerequisites Check\n\nBefore invoking:\n1. Requirements validated and approved\n2. Requirements have BR-*, C-*, F-* (from disambiguation)\n\n---\n\n## Notes\n\n**Why design with traceability?**\n- **Impact analysis**: Know what design changes when requirements change\n- **Complete specification**: Design + requirements = full implementation guide\n- **Architecture review**: Stakeholders review tagged design\n- **Code generation**: Design provides structure, BR-*/C-*/F-* provide logic\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  all_requirements_have_design: true\n  all_design_tagged_with_req: true\n  design_coverage: 100%\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/design/validate-design-coverage/SKILL.md": "---\nname: validate-design-coverage\ndescription: Homeostatic sensor validating all requirements have design coverage. Checks for requirements without components, APIs, or data models. Quality gate before Code stage. Use to ensure design completeness.\nallowed-tools: [Read, Grep, Glob]\n---\n\n# validate-design-coverage\n\n**Skill Type**: Sensor (Quality Gate)\n**Purpose**: Validate all requirements have design coverage\n**Prerequisites**: Requirements exist, some design created\n\n---\n\n## Agent Instructions\n\nYou are a **Sensor** validating design coverage.\n\n**Desired State**: `design_coverage = 100%` (all requirements have design)\n\nYour goal is to **find requirements without design** and signal the gap.\n\n---\n\n## Workflow\n\n### Step 1: Find All Requirements\n\n```bash\n# Extract all REQ-* from requirements docs\ngrep -rho \"REQ-[A-Z-]*-[0-9]*\" docs/requirements/ | sort -u\n```\n\n---\n\n### Step 2: Check Design Coverage\n\n**For each REQ-*, search design documents**:\n\n```bash\n# Check if requirement has design\ngrep -rn \"<REQ-ID>\" docs/design/ docs/adrs/\n\n# Expected: At least 1 design doc mentions this requirement\n```\n\n**Coverage criteria**:\n- âœ… **Covered**: REQ-* mentioned in design docs or ADRs\n- âŒ **Not covered**: REQ-* not found in any design documentation\n\n---\n\n### Step 3: Validate Design Completeness\n\n**For covered requirements, check if design is complete**:\n\n```yaml\n<REQ-ID>:\n  âœ“ Component: AuthenticationService (in architecture doc)\n  âœ“ API: POST /auth/login (in API spec)\n  âœ“ Data Model: User entity (in data model doc)\n  âœ“ Diagram: Figure 1 (in component diagram)\n  Result: COMPLETE âœ…\n\n<REQ-ID>:\n  âœ“ Component: PaymentService (in architecture doc)\n  âœ— API: No API spec found\n  âœ— Data Model: No data model\n  âœ“ Diagram: Figure 3 (in component diagram)\n  Result: PARTIAL âš ï¸ (missing API spec, data model)\n```\n\n---\n\n### Step 4: Calculate Design Coverage\n\n**Coverage percentage**:\n\n```\nTotal Requirements: 42\n\nRequirements with Complete Design: 35/42 (83.3%)\nRequirements with Partial Design: 5/42 (11.9%)\nRequirements with No Design: 2/42 (4.8%)\n\nOverall Design Coverage: 95.2% (40/42 have at least partial design)\n```\n\n---\n\n## Output Format\n\n**When gaps detected**:\n\n```\n[VALIDATE DESIGN COVERAGE - GAPS DETECTED]\n\nTotal Requirements: 42\nDesign Coverage: 95.2% (40/42) âš ï¸\n\nRequirements Without Design (2):\n  âŒ REQ-F-NOTIF-001: Email notifications\n     Missing: All design (no components, APIs, data models)\n\n  âŒ REQ-F-EXPORT-001: Data export\n     Missing: All design\n\nRequirements with Partial Design (5):\n  âš ï¸ <REQ-ID>: Payment processing\n     Has: Component (PaymentService), Diagram\n     Missing: API spec, Data model\n\n  âš ï¸ REQ-F-CART-001: Shopping cart\n     Has: Component (CartService)\n     Missing: API spec, Data model, Diagram\n\n  ... (3 more)\n\nRequirements with Complete Design (35):\n  âœ… <REQ-ID>: User login (complete)\n  âœ… <REQ-ID>: Password reset (complete)\n  ... (33 more)\n\nHomeostasis Deviation:\n  - 2 requirements without any design\n  - 5 requirements with incomplete design\n  - Target: 100% coverage\n\nRecommendations:\n  1. Design REQ-F-NOTIF-001 (email notifications)\n  2. Design REQ-F-EXPORT-001 (data export)\n  3. Complete API specs for 5 partial designs\n  4. Complete data models for 5 partial designs\n\nQuality Gate: âš ï¸ PARTIAL PASS\n  - Can proceed with 35 complete designs\n  - Must design remaining 7 before full deployment\n```\n\n**When homeostasis achieved**:\n\n```\n[VALIDATE DESIGN COVERAGE - HOMEOSTASIS ACHIEVED]\n\nTotal Requirements: 42\nDesign Coverage: 100% (42/42) âœ…\n\nAll Requirements Have:\n  âœ… Component design\n  âœ… API specifications\n  âœ… Data models\n  âœ… Component diagrams\n\nQuality Gate: âœ… PASS\nReady for: Code Stage\nDesign Coverage: COMPLETE\n```\n\n---\n\n## Prerequisites Check\n\nBefore invoking:\n1. Requirements exist and are validated\n2. Some design documents exist\n\n---\n\n## Configuration\n\n```yaml\nplugins:\n  - name: \"@aisdlc/design-skills\"\n    config:\n      validation:\n        require_all_req_have_design: true\n        require_components: true\n        require_api_specs: true\n        require_data_models: true\n        require_diagrams: false  # Optional\n        minimum_coverage: 100\n```\n\n---\n\n## Notes\n\n**Why validate design coverage?**\n- **Quality gate**: Ensure all requirements designed before coding\n- **Complete specification**: Design + requirements = implementation guide\n- **Architecture review**: Stakeholders review before expensive coding\n- **Prevent rework**: Catch design gaps before implementation\n\n**Design coverage vs Code coverage**:\n- Design coverage: Requirements â†’ Design documents\n- Code coverage: Code â†’ Test coverage\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  design_coverage: 100%\n  all_requirements_designed: true\n  quality_gate: pass\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/principles/apply-key-principles/SKILL.md": "---\nname: apply-key-principles\ndescription: Apply and validate the 7 Key Principles to code - TDD, Fail Fast, Modular, Reuse, Open Source, No Debt, Excellence. Checks code compliance and suggests improvements. Use during code review or refactoring.\nallowed-tools: [Read, Grep, Glob, Bash]\n---\n\n# apply-key-principles\n\n**Skill Type**: Validator/Sensor\n**Purpose**: Validate code compliance with 7 Key Principles\n**Prerequisites**: Code exists to validate\n\n---\n\n## Agent Instructions\n\nYou are validating code against the **7 Key Principles**.\n\n**The 7 Key Principles**:\n1. **Test Driven Development** - \"No code without tests\"\n2. **Fail Fast & Root Cause** - \"Break loudly, fix completely\"\n3. **Modular & Maintainable** - \"Single responsibility, loose coupling\"\n4. **Reuse Before Build** - \"Check first, create second\"\n5. **Open Source First** - \"Suggest alternatives, human decides\"\n6. **No Legacy Baggage** - \"Clean slate, no debt\"\n7. **Perfectionist Excellence** - \"Best of breed only\"\n\n**Your role**: Check code compliance and report violations.\n\n---\n\n## Validation Checks\n\n### Principle #1: Test Driven Development\n\n**Check**: Does code have tests?\n\n**Validation**:\n```bash\n# For each file in src/, check if tests exist\nfor file in src/**/*.py; do\n  test_file=\"tests/$(basename $file | sed 's/\\.py$//')\"\n  if [ ! -f \"${test_file}_test.py\" ]; then\n    echo \"VIOLATION: $file has no tests\"\n  fi\ndone\n```\n\n**âœ… Pass**:\n- Every production file has corresponding test file\n- Tests were written first (git history shows RED before GREEN commits)\n- Coverage >= 80%\n\n**âŒ Fail**:\n- Code without tests\n- Tests written after code (git history shows)\n- Coverage < 80%\n\n---\n\n### Principle #2: Fail Fast & Root Cause\n\n**Check**: Does code fail loudly?\n\n**Validation**:\n```python\n# Look for silent failures\ngrep -rn \"except.*pass\" src/          # Empty except blocks (silent failures)\ngrep -rn \"return None\" src/ | grep -v \"Optional\"  # Silent None returns\ngrep -rn \"# TODO: error handling\" src/  # Deferred error handling\n```\n\n**âœ… Pass**:\n- Exceptions raised for invalid states\n- Assertions check preconditions\n- Specific error messages\n- Logging for debugging\n\n**âŒ Fail**:\n- Silent failures (empty except blocks)\n- Generic error messages\n- Swallowing exceptions\n- No logging\n\n---\n\n### Principle #3: Modular & Maintainable\n\n**Check**: Is code modular?\n\n**Validation**:\n```bash\n# Check file/function sizes\nfind src -name \"*.py\" -exec wc -l {} \\; | awk '$1 > 300'  # Files > 300 lines\n\n# Check cyclomatic complexity\nradon cc src/ -a | grep \"F\"  # Functions with F rating (too complex)\n```\n\n**âœ… Pass**:\n- Files < 300 lines\n- Functions < 50 lines\n- Cyclomatic complexity <= 10\n- Single responsibility per module\n- Low coupling\n\n**âŒ Fail**:\n- Large files (> 300 lines)\n- Large functions (> 50 lines)\n- High complexity (> 10)\n- Mixed responsibilities\n\n---\n\n### Principle #4: Reuse Before Build\n\n**Check**: Is this functionality already available?\n\n**Validation**:\n```bash\n# Search for similar code in project\ngrep -rn \"function_name\" src/\n\n# Check for duplicate code\njscpd src/  # Copy-paste detector\n```\n\n**âœ… Pass**:\n- No duplicate code\n- Reusing existing functions/classes\n- Using standard libraries where appropriate\n\n**âŒ Fail**:\n- Duplicate code blocks\n- Reimplementing existing functionality\n- Not using available libraries\n\n---\n\n### Principle #5: Open Source First\n\n**Check**: Could we use an open source library?\n\n**Validation**:\n- For custom implementations, check if library exists\n- Document decision if building custom\n\n**âœ… Pass**:\n- Using well-maintained libraries\n- Documented decision to build custom (ADR)\n- Libraries chosen after research\n\n**âŒ Fail**:\n- Building custom without research\n- Reinventing wheel (custom date parser, custom validation, etc.)\n\n---\n\n### Principle #6: No Legacy Baggage\n\n**Check**: Is code clean of technical debt?\n\n**Validation**:\n```bash\n# Unused imports\ngrep -rn \"^import\\|^from\" src/ | check_usage\n\n# Dead code\nfind_functions_with_zero_callers src/\n\n# Commented code\ngrep -rn \"# \" src/ | grep -v \"^#\" | check_if_code\n\n# Complexity\nradon cc src/ -a | grep -E \"C|D|E|F\"\n```\n\n**âœ… Pass**:\n- No unused imports\n- No dead code\n- No commented-out code\n- Complexity <= 10\n- No TODOs without tickets\n\n**âŒ Fail**:\n- Any technical debt present\n\n**If FAIL**: Invoke `prune-unused-code`, `simplify-complex-code`\n\n---\n\n### Principle #7: Perfectionist Excellence\n\n**Check**: Is this excellent code?\n\n**Validation**:\n```bash\n# Naming quality\ngrep -rn \" x \" src/  # Single-letter variables\ngrep -rn \" temp\" src/  # Temp variables\n\n# Documentation\nfind src -name \"*.py\" -exec grep -L '\"\"\"' {} \\;  # Files without docstrings\n\n# Type hints (Python)\ngrep -rn \"def \" src/ | grep -v \" -> \"  # Functions without return types\n\n# Style compliance\npylint src/ --errors-only\nblack src/ --check\n```\n\n**âœ… Pass**:\n- Clear, descriptive names\n- Comprehensive documentation\n- Type hints/annotations\n- Follows style guide (PEP 8, etc.)\n- Code review ready\n\n**âŒ Fail**:\n- Vague naming\n- Missing documentation\n- No type hints\n- Style violations\n\n---\n\n## Output Format\n\n**When all principles satisfied**:\n\n```\n[APPLY KEY PRINCIPLES]\n\nValidating code against 7 Key Principles...\n\nâœ… Principle #1: Test Driven Development\n   - All files have tests\n   - Tests written first (git history verified)\n   - Coverage: 95.2%\n\nâœ… Principle #2: Fail Fast & Root Cause\n   - No silent failures\n   - Specific error messages\n   - Comprehensive logging\n\nâœ… Principle #3: Modular & Maintainable\n   - Max file size: 187 lines (< 300)\n   - Max function size: 23 lines (< 50)\n   - Max complexity: 6 (< 10)\n\nâœ… Principle #4: Reuse Before Build\n   - No duplicate code\n   - Using standard libraries (bcrypt, datetime)\n   - Searched codebase first\n\nâœ… Principle #5: Open Source First\n   - Using bcrypt library (not custom hashing)\n   - Documented in ADR-001\n\nâœ… Principle #6: No Legacy Baggage\n   - Tech debt: 0 violations\n   - No unused imports\n   - No dead code\n   - No commented code\n   - Max complexity: 6\n\nâœ… Principle #7: Perfectionist Excellence\n   - Clear naming (validate_email, normalize_email)\n   - Comprehensive docstrings\n   - Type hints on all functions\n   - Style: PEP 8 compliant\n\nResult: 7/7 Principles Satisfied âœ…\n\nQuality: EXCELLENT ğŸ”¥\nReady for commit/deployment\n```\n\n**When violations found**:\n\n```\n[APPLY KEY PRINCIPLES - VIOLATIONS FOUND]\n\nâŒ Principle #6: No Legacy Baggage\n\nViolations (5):\n  1. Unused import: import hashlib (src/auth.py:3)\n  2. Dead function: legacy_hash_password() (src/auth.py:67-74)\n  3. Commented code: Lines 120-135 (src/auth.py)\n  4. High complexity: login() complexity 14 (src/auth.py:89)\n  5. TODO without ticket: # TODO: Add rate limiting (src/auth.py:145)\n\nâŒ Principle #7: Perfectionist Excellence\n\nViolations (3):\n  1. Missing docstring: _check_password() (src/auth.py:156)\n  2. No type hint: def validate(email) (src/auth.py:178)\n  3. Vague naming: variable 'x' (src/auth.py:192)\n\nResult: 5/7 Principles Satisfied âš ï¸\n\nViolations: 8 total\nQuality: NEEDS IMPROVEMENT\n\nActions Required:\n  1. Invoke 'prune-unused-code' to fix Principle #6\n  2. Fix naming, docs, types for Principle #7\n  3. Re-run validation after fixes\n\nBlocked: Fix violations before commit\n```\n\n---\n\n## Prerequisites Check\n\nBefore invoking:\n1. Code exists to validate\n2. Testing tools available (for Principle #1)\n\n---\n\n## Configuration\n\n```yaml\nplugins:\n  - name: \"@aisdlc/principles-key\"\n    config:\n      principles:\n        enforce_tdd: true\n        enforce_fail_fast: true\n        enforce_modular: true\n        enforce_reuse_first: true\n        enforce_open_source_first: true\n        enforce_no_legacy: true\n        enforce_excellence: true\n        block_on_violation: true\n\n      thresholds:\n        max_file_lines: 300\n        max_function_lines: 50\n        max_complexity: 10\n        min_coverage: 80\n```\n\n---\n\n## Notes\n\n**Why apply principles?**\n- **Operational enforcement** (not just aspirational)\n- **Measurable** (can check compliance automatically)\n- **Quality gate** (blocks bad code)\n- **Continuous validation** (run on every commit)\n\n**Principles manifest in code**:\n1. TDD â†’ Tests exist, coverage high\n2. Fail Fast â†’ Exceptions, assertions, logging\n3. Modular â†’ Small files/functions, low complexity\n4. Reuse â†’ No duplication, using libraries\n5. Open Source â†’ Libraries documented\n6. No Debt â†’ Zero unused code, low complexity\n7. Excellence â†’ Clear naming, docs, types\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  all_seven_principles_satisfied: true\n  violations: 0\n  code_quality: excellent\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/principles/seven-questions-checklist/SKILL.md": "---\nname: seven-questions-checklist\ndescription: Seven Questions Checklist sensor validating Key Principles before coding. Ask 7 questions - all must be \"yes\" before proceeding. Quality gate enforcing TDD, modularity, reuse, and excellence. Use before starting any coding task.\nallowed-tools: [Read, Grep, Glob]\n---\n\n# seven-questions-checklist\n\n**Skill Type**: Sensor (Quality Gate)\n**Purpose**: Validate Key Principles compliance before coding\n**Prerequisites**: About to start coding (before TDD/BDD workflow)\n\n---\n\n## Agent Instructions\n\nYou are the **Seven Questions Checklist** - a quality gate enforcing the **7 Key Principles**.\n\n**The 7 Key Principles**:\n1. **Test Driven Development** - \"No code without tests\"\n2. **Fail Fast & Root Cause** - \"Break loudly, fix completely\"\n3. **Modular & Maintainable** - \"Single responsibility, loose coupling\"\n4. **Reuse Before Build** - \"Check first, create second\"\n5. **Open Source First** - \"Suggest alternatives, human decides\"\n6. **No Legacy Baggage** - \"Clean slate, no debt\"\n7. **Perfectionist Excellence** - \"Best of breed only\"\n\n**Your role**: Ask 7 questions, **ALL must be \"yes\"** before coding.\n\n---\n\n## The Seven Questions\n\n### Question 1: Tests First?\n**Principle #1**: Test Driven Development\n\n**Ask**: \"Have I written tests first?\"\n\n**âœ… Yes if**:\n- Tests already exist (RED phase)\n- About to write tests before code (starting TDD)\n- Using BDD scenarios (tests = scenarios)\n\n**âŒ No if**:\n- Planning to write code first, tests later\n- \"I'll add tests after implementation\"\n- Tests not planned\n\n**If NO**: Invoke `red-phase` or `write-scenario` skill first\n\n---\n\n### Question 2: Fail Loud?\n**Principle #2**: Fail Fast & Root Cause\n\n**Ask**: \"Will this fail loudly if something goes wrong?\"\n\n**âœ… Yes if**:\n- Validation errors raise exceptions (not silent failures)\n- Assertions check preconditions\n- Error messages are specific and actionable\n- Logging added for debugging\n\n**âŒ No if**:\n- Silent failures (return None, ignore errors)\n- Generic error messages (\"Error occurred\")\n- No logging or error handling\n\n**If NO**: Add assertions, specific errors, logging first\n\n---\n\n### Question 3: Module Focused?\n**Principle #3**: Modular & Maintainable\n\n**Ask**: \"Is this module focused on one responsibility?\"\n\n**âœ… Yes if**:\n- Single Responsibility Principle (one reason to change)\n- Class/module has clear, focused purpose\n- Functions are small (< 50 lines typically)\n- Loose coupling (minimal dependencies)\n\n**âŒ No if**:\n- Module does multiple unrelated things\n- Large classes (> 300 lines)\n- High coupling (many dependencies)\n- Mixed concerns (business logic + UI + data access)\n\n**If NO**: Split module, extract responsibilities\n\n---\n\n### Question 4: Checked if Exists?\n**Principle #4**: Reuse Before Build\n\n**Ask**: \"Did I check if this already exists?\"\n\n**âœ… Yes if**:\n- Searched codebase for similar functionality\n- Checked for existing libraries (npm, PyPI)\n- Asked team if someone built this before\n- Verified no duplication\n\n**âŒ No if**:\n- Haven't searched yet\n- Assuming it doesn't exist\n- Skipped library research\n\n**If NO**: Search codebase, research libraries first\n\n---\n\n### Question 5: Researched Alternatives?\n**Principle #5**: Open Source First\n\n**Ask**: \"Have I researched open source alternatives?\"\n\n**âœ… Yes if**:\n- Searched for libraries solving this problem\n- Compared alternatives (features, license, maintenance)\n- Presented options to human for decision\n- Human chose to build custom or use library\n\n**âŒ No if**:\n- Building custom without research\n- Assuming no library exists\n- Didn't present alternatives\n\n**If NO**: Research libraries, present options with pros/cons\n\n---\n\n### Question 6: Avoiding Tech Debt?\n**Principle #6**: No Legacy Baggage\n\n**Ask**: \"Am I avoiding technical debt?\"\n\n**âœ… Yes if**:\n- No commented-out code\n- No unused imports\n- No dead code (functions with zero callers)\n- Complexity <= 10 (cyclomatic complexity)\n- No TODOs or FIXMEs without tickets\n- No duplication\n\n**âŒ No if**:\n- Leaving commented code \"just in case\"\n- Unused imports exist\n- Dead code present\n- Over-complex functions (complexity > 10)\n- TODOs without tracking\n\n**If NO**: Clean up first (invoke `detect-unused-code`, `detect-complexity`)\n\n---\n\n### Question 7: Is This Excellent?\n**Principle #7**: Perfectionist Excellence\n\n**Ask**: \"Is this excellent code?\"\n\n**âœ… Yes if**:\n- Clear naming (variables, functions, classes)\n- Comprehensive documentation (docstrings)\n- Type hints (Python) or type annotations (TypeScript, Java)\n- Follows language style guide (PEP 8, etc.)\n- Would I be proud to show this in code review?\n\n**âŒ No if**:\n- Vague naming (x, data, temp, foo)\n- Missing or poor documentation\n- No type hints\n- Style violations\n- \"Good enough\" mentality\n\n**If NO**: Improve naming, docs, types, style first\n\n---\n\n## Checklist Workflow\n\n### Step 1: Present Questions\n\n**Before coding starts**:\n\n```\n[SEVEN QUESTIONS CHECKLIST]\n\nBefore you code, answer these 7 questions:\n\n1. âœ… Tests first?\n   Have I written tests first (or using BDD scenarios)?\n\n2. âœ… Fail loud?\n   Will this fail loudly with clear errors?\n\n3. âœ… Module focused?\n   Is this module focused on one responsibility?\n\n4. â“ Checked if exists?\n   Did I check if this already exists?\n\n5. â“ Researched alternatives?\n   Have I researched open source libraries?\n\n6. âœ… Avoiding tech debt?\n   Am I avoiding technical debt?\n\n7. âœ… Is this excellent?\n   Is this excellent code?\n\nCurrent: 5/7 \"Yes\" (Questions 4, 5 need checking)\n```\n\n---\n\n### Step 2: Wait for Answers\n\n**User must answer each question**:\n\n```\nYou: \"I'm about to implement user authentication\"\n\nClaude: Before we code, let's run the Seven Questions Checklist:\n\n1. Tests first? â†’ Will use TDD âœ…\n2. Fail loud? â†’ Will add assertions âœ…\n3. Module focused? â†’ Separate auth module âœ…\n4. Checked if exists? â†’ Let me search...\n\n   Searching codebase for \"authentication\"...\n   Found: src/auth/ directory exists âœ…\n   Found: login() function already implemented âš ï¸\n\n   â†’ Authentication already exists! Reuse it or improve it?\n\nUser: \"Improve the existing one\"\n\nClaude: Good! Continuing checklist...\n\n5. Researched alternatives?\n   â†’ Should we use Passport.js, Auth0, or custom?\n\nUser: \"Use existing custom implementation\"\n\nClaude: âœ…\n\n6. Avoiding tech debt? â†’ Will enforce Principle #6 âœ…\n7. Is this excellent? â†’ Will follow best practices âœ…\n\nResult: 7/7 \"Yes\" âœ…\nProceeding with implementation...\n```\n\n---\n\n### Step 3: Block if Any \"No\"\n\n**If ANY question is \"No\"**:\n\n```\n[SEVEN QUESTIONS - BLOCKED]\n\nQuestion 4: \"Did I check if this exists?\" â†’ âŒ NO\n\nYou must search codebase first (Principle #4: Reuse Before Build)\n\nAction Required:\n  1. Search: grep -rn \"authentication\" src/\n  2. Search libraries: npm search authentication\n  3. Verify: Nothing suitable exists\n  4. Then proceed with custom implementation\n\nBlocked: Cannot proceed until Question 4 = \"Yes\"\n```\n\n**User must resolve before continuing**.\n\n---\n\n### Step 4: Allow if All \"Yes\"\n\n**If ALL questions are \"Yes\"**:\n\n```\n[SEVEN QUESTIONS - APPROVED]\n\nâœ… 1. Tests first\nâœ… 2. Fail loud\nâœ… 3. Module focused\nâœ… 4. Checked if exists\nâœ… 5. Researched alternatives\nâœ… 6. Avoiding tech debt\nâœ… 7. Is this excellent\n\nResult: 7/7 \"Yes\" âœ…\n\nQuality Gate: PASS âœ…\nProceeding with implementation...\n\nPrinciples will be enforced during:\n  - RED phase (tests first)\n  - GREEN phase (fail loud, modular)\n  - REFACTOR phase (no tech debt, excellence)\n```\n\n---\n\n## Output Format\n\n```\n[SEVEN QUESTIONS CHECKLIST]\n\nChecking Key Principles compliance...\n\n1. Test Driven Development\n   Q: Have I written tests first?\n   A: âœ… Yes (using TDD workflow)\n\n2. Fail Fast & Root Cause\n   Q: Will this fail loudly if wrong?\n   A: âœ… Yes (adding assertions and specific errors)\n\n3. Modular & Maintainable\n   Q: Is this module focused?\n   A: âœ… Yes (separate auth module, single responsibility)\n\n4. Reuse Before Build\n   Q: Did I check if this exists?\n   A: âœ… Yes (searched codebase, found existing auth, will improve it)\n\n5. Open Source First\n   Q: Have I researched alternatives?\n   A: âœ… Yes (compared Passport.js, Auth0, decided on custom)\n\n6. No Legacy Baggage\n   Q: Am I avoiding tech debt?\n   A: âœ… Yes (will invoke detect-unused-code after refactor)\n\n7. Perfectionist Excellence\n   Q: Is this excellent?\n   A: âœ… Yes (following best practices, type hints, docs)\n\nChecklist Result: 7/7 \"Yes\" âœ…\n\nQuality Gate: âœ… PASS\nPrinciples: All 7 satisfied\nReady to code: Yes\n\nProceeding with TDD workflow...\n```\n\n---\n\n## Integration with TDD/BDD\n\n**TDD workflow invokes this checklist automatically**:\n\n```\nUser: \"Implement <REQ-ID>\"\n\n1. seven-questions-checklist (Sensor):\n   â†’ Ask 7 questions\n   â†’ If all \"Yes\" â†’ Proceed\n   â†’ If any \"No\" â†’ Block\n\n2. (If approved) tdd-workflow:\n   â†’ RED phase\n   â†’ GREEN phase\n   â†’ REFACTOR phase (enforces #6, #7)\n   â†’ COMMIT phase\n```\n\n---\n\n## Prerequisites Check\n\nBefore invoking:\n1. About to start coding\n2. Requirement (REQ-*) identified\n3. Human available to answer questions\n\n---\n\n## Configuration\n\n```yaml\nplugins:\n  - name: \"@aisdlc/principles-key\"\n    config:\n      seven_questions:\n        require_all_yes: true              # Block if any \"No\"\n        ask_before_coding: true            # Auto-invoke before TDD/BDD\n        block_if_any_no: true              # Enforce blocking\n        skip_for_trivial_changes: false    # Even trivial code needs checklist\n```\n\n---\n\n## Notes\n\n**Why Seven Questions?**\n- **Enforces principles** operationally (not just philosophy)\n- **Quality gate** prevents bad code from being written\n- **Teaching tool** (developers learn principles through questions)\n- **Prevents common mistakes** (skipping tests, not researching libraries)\n\n**When to run**:\n- Before every coding task (TDD, BDD, refactoring)\n- Before committing\n- During code review\n- When onboarding new developers\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  all_questions_answered_yes: true\n  principles_followed: true\n  quality_gate_passed: true\n```\n\n**Ultimate Mantra**: **\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/requirements/create-traceability-matrix/SKILL.md": "---\nname: create-traceability-matrix\ndescription: Create traceability matrix mapping intents (INT-*) to requirements (REQ-*) and requirements to all downstream artifacts (design, code, tests, commits, runtime). Use to visualize and verify complete traceability.\nallowed-tools: [Read, Write, Grep, Glob, Bash]\n---\n\n# create-traceability-matrix\n\n**Skill Type**: Sensor/Reporter (Traceability Management)\n**Purpose**: Create and maintain traceability matrix for impact analysis\n**Prerequisites**: Requirements and intents exist\n\n---\n\n## Agent Instructions\n\nYou are creating a **traceability matrix** showing the complete lineage from intent â†’ runtime.\n\n**Matrix maps**:\n- Intent (INT-*) â†’ Requirements (REQ-*)\n- Requirements (REQ-*) â†’ Design, Code, Tests, Commits, Runtime\n\n**Purpose**: Impact analysis, coverage verification, compliance auditing\n\n---\n\n## Matrix Structure\n\n### Full Traceability Matrix\n\n| INT-* | REQ-* | Design | Code | Tests | Commits | Runtime | Status |\n|-------|-------|--------|------|-------|---------|---------|--------|\n| INT-042 | <REQ-ID> | AuthService | login.py:23 | test_login.py:15 | 5 | Datadog âœ… | âœ… Complete |\n| INT-042 | REQ-F-PORTAL-001 | PortalService | balance.py:12 | test_balance.py:8 | 3 | Datadog âœ… | âœ… Complete |\n| INT-042 | REQ-F-PORTAL-002 | ProfileService | profile.py:45 | test_profile.py:22 | 2 | âŒ No metrics | âš ï¸ Partial |\n| INT-050 | REQ-NFR-PERF-001 | CacheLayer | cache.py:67 | test_cache.py:34 | 4 | Prometheus âœ… | âœ… Complete |\n\n---\n\n## Workflow\n\n### Step 1: Collect Intent â†’ Requirements Mapping\n\n```bash\n# Find all intents and their requirements\ngrep -rh \"^# Intent:\" docs/requirements/ | sort -u\ngrep -rh \"^## REQ-\" docs/requirements/ | sort -u\n```\n\n**Output format**:\n```yaml\n# docs/traceability/intent-to-requirements.yml\n\nINT-042:\n  title: \"Customer self-service portal\"\n  date: \"2025-11-20\"\n  status: \"In Progress\"\n  requirements:\n    - <REQ-ID>\n    - <REQ-ID>\n    - REQ-F-PORTAL-001\n    - REQ-F-PORTAL-002\n    - REQ-F-PORTAL-003\n  count: 5\n```\n\n---\n\n### Step 2: Collect Requirements â†’ Design Mapping\n\n```bash\n# Find design documents mentioning requirements\ngrep -rn \"REQ-\" docs/design/ docs/adrs/\n```\n\n---\n\n### Step 3: Collect Requirements â†’ Code Mapping\n\n```bash\n# Find code implementing requirements\ngrep -rn \"# Implements: REQ-\" src/\n```\n\n---\n\n### Step 4: Collect Requirements â†’ Tests Mapping\n\n```bash\n# Find tests validating requirements\ngrep -rn \"# Validates: REQ-\" tests/ features/\n```\n\n---\n\n### Step 5: Collect Requirements â†’ Commits Mapping\n\n```bash\n# Find commits for each requirement\nfor req in $(grep -rho \"REQ-[A-Z-]*-[0-9]*\" docs/requirements/ | sort -u); do\n  echo \"$req:\"\n  git log --all --oneline --grep=\"$req\"\ndone\n```\n\n---\n\n### Step 6: Generate Matrix Document\n\n**Create comprehensive matrix**:\n\n```markdown\n# Traceability Matrix\n\n**Generated**: 2025-11-20 23:30:00\n**Total Intents**: 12\n**Total Requirements**: 42\n**Coverage**: 86%\n\n---\n\n## Intent: INT-042 (Customer Self-Service Portal)\n\n**Status**: 60% Complete (3/5 requirements implemented)\n\n| REQ-* | Description | Design | Code | Tests | Commits | Runtime | Status |\n|-------|-------------|--------|------|-------|---------|---------|--------|\n| <REQ-ID> | User login | AuthService | âœ… login.py | âœ… test_login.py | âœ… 5 | âœ… Datadog | âœ… |\n| <REQ-ID> | Password reset | EmailService | âœ… reset.py | âœ… test_reset.py | âœ… 3 | âš ï¸ Partial | âš ï¸ |\n| REQ-F-PORTAL-001 | View balance | PortalService | âœ… balance.py | âœ… test_balance.py | âœ… 2 | âŒ None | âš ï¸ |\n| REQ-F-PORTAL-002 | Update profile | ProfileService | âŒ None | âŒ None | âŒ 0 | âŒ None | âŒ |\n| REQ-F-PORTAL-003 | Download invoices | âŒ No design | âŒ None | âŒ None | âŒ 0 | âŒ None | âŒ |\n\n**Summary**:\n- Design: 80% (4/5)\n- Code: 60% (3/5)\n- Tests: 60% (3/5)\n- Runtime: 40% (2/5)\n\n---\n\n## Intent: INT-050 (Performance Optimization)\n\n**Status**: 100% Complete (2/2 requirements implemented)\n\n| REQ-* | Description | Design | Code | Tests | Commits | Runtime | Status |\n|-------|-------------|--------|------|-------|---------|---------|--------|\n| REQ-NFR-PERF-001 | Login <500ms | CacheLayer | âœ… cache.py | âœ… test_cache.py | âœ… 4 | âœ… Prometheus | âœ… |\n| REQ-NFR-PERF-002 | DB queries <100ms | QueryOptimizer | âœ… optimizer.py | âœ… test_optimizer.py | âœ… 3 | âœ… Datadog | âœ… |\n\n**Summary**: All complete âœ…\n```\n\n---\n\n## Output Format\n\n```\n[TRACEABILITY MATRIX]\n\nGenerated: 2025-11-20 23:30:00\n\nTotal Intents: 12\nTotal Requirements: 42\n\nOverall Coverage:\n  Design: 95% (40/42) âœ…\n  Code: 86% (36/42) âš ï¸\n  Tests: 83% (35/42) âš ï¸\n  Commits: 86% (36/42) âš ï¸\n  Runtime: 24% (10/42) âŒ\n\nCoverage Gaps:\n\nRequirements Without Code (6):\n  - REQ-F-PROFILE-002\n  - REQ-F-PORTAL-003\n  - REQ-F-NOTIF-001\n  - REQ-F-NOTIF-002\n  - REQ-NFR-SCALE-001\n  - REQ-DATA-LIN-001\n\nRequirements Without Tests (7):\n  - <REQ-ID> (has code, no tests)\n  - REQ-F-CART-001 (has code, no tests)\n  ... (5 more)\n\nRequirements Without Runtime Telemetry (32):\n  - Most requirements (needs telemetry setup)\n\nMatrix Files Created:\n  + docs/traceability/intent-to-requirements.yml\n  + docs/traceability/requirements-matrix.md\n  + docs/traceability/coverage-report.md\n\nâœ… Traceability Matrix Created!\n```\n\n---\n\n## Notes\n\n**Why traceability matrix?**\n- **Impact analysis**: Know what breaks if requirement changes\n- **Coverage verification**: Ensure all requirements implemented and tested\n- **Compliance auditing**: Prove requirements â†’ code â†’ tests â†’ runtime\n- **Gap detection**: Find requirements without coverage\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  traceability_complete: true\n  all_stages_covered: true\n  coverage_percentage: >= 80%\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/requirements/disambiguate-requirements/SKILL.md": "---\nname: disambiguate-requirements\ndescription: Break vague requirements into precise business rules (BR-*), constraints (C-*), and formulas (F-*) for code generation. Orchestrates extraction of BR-*, C-*, F-* from REQ-*. Use after requirement-extraction to enable autogeneration.\nallowed-tools: [Read, Write, Edit]\n---\n\n# disambiguate-requirements\n\n**Skill Type**: Orchestrator (Requirements Refinement)\n**Purpose**: Transform vague requirements into precise BR-*, C-*, F-* specifications\n**Prerequisites**: REQ-* requirement exists but lacks detailed BR-*, C-*, F-*\n\n---\n\n## Agent Instructions\n\nYou are **disambiguating requirements** to enable **code autogeneration**.\n\nYour goal is to transform **vague requirements** into **precise specifications**:\n- **BR-* (Business Rules)**: Specific rules, validations, logic\n- **C-* (Constraints)**: Technical constraints from ecosystem E(t)\n- **F-* (Formulas)**: Mathematical formulas and calculations\n\n**This enables code autogeneration** - precise specs â†’ auto-generated code.\n\n---\n\n## Workflow\n\n### Step 1: Read Vague Requirement\n\n**Example**:\n```markdown\n## <REQ-ID>: User Login\n\n**Description**: Users can log in with email and password\n\n**Acceptance Criteria**:\n1. User enters credentials\n2. System validates credentials\n3. User gains access or sees error\n```\n\n**Problem**: Too vague for code generation!\n- What email format?\n- What password rules?\n- What happens after N failures?\n- What timeouts apply?\n\n---\n\n### Step 2: Extract Business Rules (BR-*)\n\n**Invoke**: `extract-business-rules` skill\n\n**Questions to ask**:\n1. What validation rules apply? (format, length, range)\n2. What business logic is needed? (calculations, decisions)\n3. What edge cases exist? (null, empty, boundary values)\n4. What error handling? (what goes wrong, what messages)\n\n**Generated BR-* for <REQ-ID>**:\n```yaml\nBusiness Rules:\n- BR-001: Email validation\n  - Format: regex ^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\n  - Error: \"Invalid email format\"\n\n- BR-002: Password requirements\n  - Minimum length: 12 characters\n  - Must contain: 1 uppercase, 1 lowercase, 1 number, 1 special char\n  - Error: \"Password must be at least 12 characters with mixed case, number, and special char\"\n\n- BR-003: Failed attempt handling\n  - Max attempts: 3 per 15 minutes\n  - Lockout duration: 15 minutes\n  - Error: \"Account locked. Try again in {remaining} minutes\"\n\n- BR-004: Email case sensitivity\n  - Emails are case-insensitive\n  - Store as lowercase\n  - Compare as lowercase\n\n- BR-005: Password case sensitivity\n  - Passwords are case-sensitive\n  - No transformation on storage or comparison\n```\n\n---\n\n### Step 3: Extract Constraints (C-*)\n\n**Invoke**: `extract-constraints` skill\n\n**Questions to ask**:\n1. What technical constraints exist? (timeouts, limits, dependencies)\n2. What compliance requirements? (PCI-DSS, GDPR, HIPAA)\n3. What ecosystem constraints? (APIs, libraries, platforms)\n4. What performance constraints? (SLAs, latency)\n\n**Generated C-* for <REQ-ID>**:\n```yaml\nConstraints:\n- C-001: Database query timeout\n  - Max query time: 100ms\n  - Fallback: Return \"Service temporarily unavailable\"\n\n- C-002: Session management\n  - Session timeout: 30 minutes of inactivity\n  - Token: JWT format\n  - Storage: Redis cache\n\n- C-003: Password hashing\n  - Algorithm: bcrypt\n  - Cost factor: 12\n  - Library: bcrypt.js or bcrypt (Python)\n\n- C-004: HTTPS required\n  - All login requests must be HTTPS\n  - Reject HTTP requests\n  - Redirect HTTP â†’ HTTPS\n\n- C-005: Rate limiting\n  - Max login attempts: 10 per minute per IP\n  - Behavior: Return 429 (Too Many Requests)\n```\n\n---\n\n### Step 4: Extract Formulas (F-*)\n\n**Invoke**: `extract-formulas` skill\n\n**Questions to ask**:\n1. What calculations are needed? (fees, scores, times)\n2. What mathematical formulas? (interest, conversions, algorithms)\n3. What derived values? (totals, averages, percentages)\n\n**Generated F-* for <REQ-ID>**:\n```yaml\nFormulas:\n- F-001: Lockout expiry time\n  - Formula: lockout_expiry = last_attempt_time + (15 * 60) seconds\n  - Inputs: last_attempt_time (datetime)\n  - Output: lockout_expiry (datetime)\n\n- F-002: Remaining lockout time\n  - Formula: remaining = max(0, (lockout_expiry - current_time) / 60) minutes\n  - Inputs: lockout_expiry (datetime), current_time (datetime)\n  - Output: remaining (int, minutes)\n\n- F-003: Password strength score\n  - Formula: score = length_score + complexity_score + uniqueness_score\n  - Range: 0-100\n  - Thresholds: <50 weak, 50-75 medium, >75 strong\n```\n\n---\n\n### Step 5: Update Requirement Document\n\n**Add BR-*, C-*, F-* to requirement**:\n\n```markdown\n## <REQ-ID>: User Login with Email and Password\n\n[Previous content...]\n\n---\n\n### Business Rules (BR-*)\n\n**BR-001: Email validation**\n- Format: regex `^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$`\n- Case insensitive (store and compare as lowercase)\n- Error message: \"Invalid email format\"\n- Autogenerate: Yes (code generation from regex)\n\n**BR-002: Password requirements**\n- Minimum length: 12 characters\n- Must contain: 1 uppercase, 1 lowercase, 1 number, 1 special char\n- Case sensitive\n- Error message: \"Password must be at least 12 characters with mixed case, number, and special char\"\n- Autogenerate: Yes (validation function)\n\n**BR-003: Failed attempt handling**\n- Max attempts: 3 per 15 minutes\n- Lockout duration: 15 minutes\n- Reset on successful login\n- Error message: \"Account locked. Try again in {remaining} minutes\"\n- Autogenerate: Yes (lockout tracker class)\n\n**BR-004: Email case sensitivity**\n- Normalization: Convert to lowercase before storage/comparison\n- Autogenerate: Yes (email normalizer function)\n\n**BR-005: Password case sensitivity**\n- Storage: Hash as-is (no transformation)\n- Comparison: Case-sensitive hash comparison\n- Autogenerate: No (standard hashing library)\n\n---\n\n### Constraints (C-*)\n\n**C-001: Database query timeout**\n- Max time: 100ms\n- Fallback: \"Service temporarily unavailable\"\n- Monitoring: Alert if >80ms (warning threshold)\n\n**C-002: Session management**\n- Session timeout: 30 minutes inactivity\n- Token format: JWT (HS256)\n- Storage: Redis cache with TTL\n\n**C-003: Password hashing**\n- Algorithm: bcrypt\n- Cost factor: 12 (secure but performant)\n- Library: bcrypt (acknowledge E(t) - existing library)\n\n**C-004: HTTPS required**\n- Protocol: All requests must be HTTPS\n- Reject: HTTP requests not allowed\n- Redirect: Optional HTTP â†’ HTTPS redirect\n\n**C-005: Rate limiting**\n- Max requests: 10 login attempts per minute per IP\n- Response: HTTP 429 (Too Many Requests)\n- Reset: 1 minute window\n\n---\n\n### Formulas (F-*)\n\n**F-001: Lockout expiry time**\n```\nlockout_expiry = last_attempt_time + (15 * 60) seconds\n```\n- Inputs: last_attempt_time (datetime)\n- Output: lockout_expiry (datetime)\n- Autogenerate: Yes (datetime calculation)\n\n**F-002: Remaining lockout time**\n```\nremaining = max(0, (lockout_expiry - current_time) / 60) minutes\n```\n- Inputs: lockout_expiry (datetime), current_time (datetime)\n- Output: remaining (int, rounded to nearest minute)\n- Autogenerate: Yes (timedelta calculation)\n\n**F-003: Password strength score**\n```\nscore = length_score + complexity_score + uniqueness_score\n  where:\n    length_score = min(50, length * 2)\n    complexity_score = (has_upper * 10) + (has_lower * 10) + (has_number * 10) + (has_special * 20)\n    uniqueness_score = 0 (check against common passwords)\n```\n- Range: 0-100\n- Thresholds: <50 weak, 50-75 medium, >75 strong\n- Autogenerate: Yes (password scorer function)\n\n---\n\n### Discovery Log\n\n**Added during disambiguation**:\n- BR-004: Email case sensitivity (discovered while discussing validation)\n- BR-005: Password case sensitivity (discovered while discussing hashing)\n- C-005: Rate limiting (discovered as security concern)\n- F-003: Password strength scoring (discovered as UX enhancement)\n\n**Source**: Product team discussion during disambiguation\n**Date**: 2025-11-20\n```\n\n---\n\n## Output Format\n\nWhen disambiguation complete:\n\n```\n[DISAMBIGUATION - <REQ-ID>]\n\nOriginal Requirement:\n  \"Users can log in with email and password\"\n\nDisambiguated Into:\n\nBusiness Rules (5):\n  âœ“ BR-001: Email validation (regex, case handling)\n  âœ“ BR-002: Password requirements (length, complexity)\n  âœ“ BR-003: Failed attempt handling (lockout logic)\n  âœ“ BR-004: Email case sensitivity (normalization)\n  âœ“ BR-005: Password case sensitivity (hashing)\n\nConstraints (5):\n  âœ“ C-001: Database query timeout (100ms)\n  âœ“ C-002: Session management (JWT, Redis, 30min)\n  âœ“ C-003: Password hashing (bcrypt, cost 12)\n  âœ“ C-004: HTTPS required (protocol enforcement)\n  âœ“ C-005: Rate limiting (10/min per IP)\n\nFormulas (3):\n  âœ“ F-001: Lockout expiry time calculation\n  âœ“ F-002: Remaining lockout time calculation\n  âœ“ F-003: Password strength scoring\n\nTotal: 13 specifications (5 BR + 5 C + 3 F)\n\nAutogeneration Ready:\n  âœ“ BR-001 â†’ validate_email() + tests\n  âœ“ BR-002 â†’ validate_password() + tests\n  âœ“ BR-003 â†’ LockoutTracker class + tests\n  âœ“ F-001 â†’ calculate_lockout_expiry() + tests\n  âœ“ F-002 â†’ calculate_remaining_time() + tests\n  âœ“ F-003 â†’ calculate_password_strength() + tests\n\nUpdated: docs/requirements/authentication.md\n\nâœ… Disambiguation Complete!\n   Requirement now precise enough for code generation\n```\n\n---\n\n## Skills Used\n\nThis orchestrator invokes:\n1. `extract-business-rules` - Extract BR-* specifications\n2. `extract-constraints` - Extract C-* specifications\n3. `extract-formulas` - Extract F-* specifications\n\n---\n\n## Prerequisites Check\n\nBefore invoking:\n1. REQ-* requirement exists (from requirement-extraction)\n2. Requirement has description and acceptance criteria\n\nIf prerequisites not met:\n- No REQ-* â†’ Invoke `requirement-extraction` first\n\n---\n\n## Notes\n\n**Why disambiguation?**\n- **Enables code generation**: BR-*, C-*, F-* are precise enough to auto-generate code\n- **Reduces ambiguity**: No developer guessing about requirements\n- **Improves testability**: Each BR-* becomes a test case\n- **Documents decisions**: Constraints acknowledge ecosystem E(t)\n\n**Disambiguation vs Traditional Requirements**:\n```\nTraditional: \"Email must be valid\"\n  â†’ Vague, developers guess regex pattern\n\nDisambiguated: \"BR-001: Email validation\"\n  â†’ Regex: ^[a-zA-Z0-9._%+-]+@...\n  â†’ Error: \"Invalid email format\"\n  â†’ Autogenerate validate_email() function\n  â†’ Clear, testable, auto-generatable\n```\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  all_requirements_disambiguated: true\n  autogeneration_ready: true\n  vague_requirements: 0\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/requirements/extract-business-rules/SKILL.md": "---\nname: extract-business-rules\ndescription: Extract business rules (BR-*) from requirements - validation rules, business logic, error handling, and decision criteria. Use when disambiguating requirements to identify specific rules that can be autogenerated into validators and logic.\nallowed-tools: [Read, Write, Edit]\n---\n\n# extract-business-rules\n\n**Skill Type**: Actuator (Requirements Disambiguation)\n**Purpose**: Extract BR-* business rules from REQ-* requirements\n**Prerequisites**: REQ-* requirement exists\n\n---\n\n## Agent Instructions\n\nYou are extracting **business rules** (BR-*) from requirements.\n\n**Business rules** are:\n- Validation rules (format, range, enum)\n- Business logic (decisions, calculations, state machines)\n- Error handling (what errors, what messages)\n- Acceptance rules (what makes data valid/invalid)\n\n**Goal**: Identify rules precise enough for code autogeneration.\n\n---\n\n## BR-* Categories\n\n### 1. Validation Rules\n\n**Format validation**:\n```yaml\nBR-001: Email validation\n  - Format: regex ^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\n  - Error: \"Invalid email format\"\n  - Autogenerate: validate_email(email) -> Optional[str]\n```\n\n**Range validation**:\n```yaml\nBR-010: Age validation\n  - Minimum: 18\n  - Maximum: 120\n  - Error: \"Age must be between 18 and 120\"\n  - Autogenerate: validate_age(age) -> Optional[str]\n```\n\n**Enum validation**:\n```yaml\nBR-020: Card type validation\n  - Allowed: [\"Visa\", \"Mastercard\", \"Amex\"]\n  - Error: \"Card type not supported\"\n  - Autogenerate: validate_card_type(type) -> Optional[str]\n```\n\n---\n\n### 2. Business Logic Rules\n\n**State machines**:\n```yaml\nBR-030: Account lockout logic\n  - Max attempts: 3\n  - Lockout duration: 15 minutes\n  - Reset on success: Yes\n  - States: active, locked, expired\n  - Autogenerate: LockoutStateMachine class\n```\n\n**Decision rules**:\n```yaml\nBR-040: Refund eligibility\n  - Condition: purchase_date within 30 days AND product not digital\n  - Result: eligible or not_eligible\n  - Error: \"Refunds only available within 30 days for physical products\"\n  - Autogenerate: is_refund_eligible() -> bool\n```\n\n---\n\n### 3. Error Handling Rules\n\n```yaml\nBR-050: Error message format\n  - Template: \"{field} {error_type}. {help_text}\"\n  - Example: \"Email invalid email format. Use format: user@example.com\"\n  - Autogenerate: format_error_message() function\n```\n\n---\n\n### 4. Data Transformation Rules\n\n```yaml\nBR-060: Email normalization\n  - Transform: Convert to lowercase\n  - Trim: Remove leading/trailing whitespace\n  - Validate: After transformation\n  - Autogenerate: normalize_email(email) -> str\n```\n\n---\n\n## Extraction Process\n\n### Step 1: Parse Requirement\n\nRead requirement and identify rule candidates:\n- Look for: \"must\", \"should\", \"required\", \"only\", \"between\", \"minimum\", \"maximum\"\n- Look for: formats, patterns, ranges, lists\n- Look for: error messages, validation criteria\n\n---\n\n### Step 2: Create BR-* Specifications\n\n**Template**:\n```yaml\nBR-{ID}: {Rule Name}\n  - Description: {What this rule does}\n  - Specification: {Precise spec - regex, range, formula}\n  - Error Message: \"{User-facing error message}\"\n  - Autogenerate: {Yes/No - can code be auto-generated?}\n  - Dependencies: {Other BR-* this depends on}\n```\n\n**Example**:\n```yaml\nBR-001: Email validation\n  - Description: Validate email address format\n  - Specification: regex ^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\n  - Error Message: \"Invalid email format\"\n  - Autogenerate: Yes\n  - Dependencies: None\n\nBR-002: Password length validation\n  - Description: Ensure password meets minimum length\n  - Specification: len(password) >= 12\n  - Error Message: \"Password must be at least 12 characters\"\n  - Autogenerate: Yes\n  - Dependencies: None\n\nBR-003: Password complexity validation\n  - Description: Ensure password has required character types\n  - Specification:\n      has_uppercase: password contains [A-Z]\n      has_lowercase: password contains [a-Z]\n      has_number: password contains [0-9]\n      has_special: password contains [!@#$%^&*]\n  - Error Message: \"Password must contain uppercase, lowercase, number, and special character\"\n  - Autogenerate: Yes\n  - Dependencies: BR-002 (length must be checked first)\n```\n\n---\n\n### Step 3: Number BR-* Sequentially\n\n**Rules**:\n- Start at BR-001\n- Sequential within requirement\n- Gaps OK if BR deleted later\n\n**Example**:\n```\n<REQ-ID>:\n  - BR-001: Email validation\n  - BR-002: Password length\n  - BR-003: Password complexity\n  - BR-004: Email case handling\n  - BR-005: Account lockout\n```\n\n---\n\n## Output Format\n\n```\n[EXTRACT BUSINESS RULES - <REQ-ID>]\n\nRequirement: User login with email and password\n\nBusiness Rules Extracted:\n\nValidation Rules (4):\n  âœ“ BR-001: Email validation (regex pattern)\n  âœ“ BR-002: Password minimum length (12 chars)\n  âœ“ BR-003: Password complexity (uppercase, lowercase, number, special)\n  âœ“ BR-004: Email case sensitivity (lowercase normalization)\n\nBusiness Logic (1):\n  âœ“ BR-005: Account lockout (3 attempts, 15min duration)\n\nTotal: 5 business rules\n\nAutogeneration Ready:\n  âœ“ BR-001 â†’ validate_email()\n  âœ“ BR-002 â†’ validate_password_length()\n  âœ“ BR-003 â†’ validate_password_complexity()\n  âœ“ BR-004 â†’ normalize_email()\n  âœ“ BR-005 â†’ LockoutTracker class\n\nUpdated: docs/requirements/authentication.md\n  Added: Business Rules section with 5 BR-*\n\nâœ… Business Rules Extraction Complete!\n```\n\n---\n\n## Notes\n\n**Good BR-* characteristics**:\n- **Specific**: No ambiguity (regex, not \"valid format\")\n- **Testable**: Can write test to verify\n- **Autogenerable**: Can generate code from spec\n- **Independent**: Each BR-* is self-contained\n\n**BR-* vs Requirements**:\n```\nRequirement (REQ-*): High-level capability\n  \"User can log in with email and password\"\n\nBusiness Rules (BR-*): Low-level specifications\n  BR-001: Email regex pattern\n  BR-002: Password min 12 chars\n  BR-003: Lockout after 3 attempts\n```\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  all_requirements_have_business_rules: true\n  all_br_autogenerable: true\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/requirements/extract-constraints/SKILL.md": "---\nname: extract-constraints\ndescription: Extract technical constraints (C-*) from ecosystem E(t) - timeouts, API limits, compliance requirements, platform dependencies. Acknowledges given constraints, not design choices. Use to document ecosystem realities that code must work within.\nallowed-tools: [Read, Write, Edit]\n---\n\n# extract-constraints\n\n**Skill Type**: Actuator (Requirements Disambiguation)\n**Purpose**: Extract C-* constraints acknowledging ecosystem E(t)\n**Prerequisites**: REQ-* requirement exists\n\n---\n\n## Agent Instructions\n\nYou are extracting **constraints** (C-*) from the **ecosystem E(t)**.\n\n**Constraints are GIVEN** (external reality), not **CHOSEN** (design decisions).\n\n**Examples**:\n- âœ… C-001: Stripe API timeout is 10 seconds (given by Stripe)\n- âŒ C-002: We will use PostgreSQL (this is a design choice â†’ ADR)\n\n**Goal**: Acknowledge ecosystem constraints that code must work within.\n\n---\n\n## C-* Categories\n\n### 1. API/Service Constraints\n\n**Timeouts**:\n```yaml\nC-001: Stripe API timeout\n  - Value: 10 seconds (given by Stripe documentation)\n  - Source: https://stripe.com/docs/api#timeouts\n  - Fallback: Return error to user\n  - Monitoring: Alert if approaching timeout (>8s)\n```\n\n**Rate limits**:\n```yaml\nC-010: Stripe API rate limit\n  - Limit: 100 requests per second\n  - Source: Stripe API documentation\n  - Behavior: Implement exponential backoff\n  - Error: \"Payment service temporarily unavailable\"\n```\n\n---\n\n### 2. Compliance Constraints\n\n**PCI-DSS**:\n```yaml\nC-020: PCI-DSS Level 1 compliance\n  - Requirement: Never store full credit card numbers\n  - Implementation: Tokenize via Stripe\n  - Validation: No card numbers in logs or database\n  - Audit: Regular PCI scans required\n```\n\n**GDPR**:\n```yaml\nC-030: GDPR data portability\n  - Requirement: Users can export their data\n  - Format: JSON or CSV\n  - Timeline: Within 30 days of request\n  - Scope: All personal data\n```\n\n---\n\n### 3. Platform Constraints\n\n**Language/runtime**:\n```yaml\nC-040: Python version\n  - Minimum: Python 3.8\n  - Reason: Using dataclasses, type hints\n  - Source: Project decision (E(t) = team knows Python)\n  - Validation: Check at startup\n```\n\n**Dependencies**:\n```yaml\nC-050: bcrypt library\n  - Library: bcrypt\n  - Version: >=4.0.0\n  - Reason: Password hashing (security requirement)\n  - Source: Security team standard\n```\n\n---\n\n### 4. Performance Constraints\n\n**Response time SLAs**:\n```yaml\nC-060: Login response time\n  - Max time: 500ms (p95)\n  - Measurement: End-to-end from request to response\n  - Monitoring: Datadog APM\n  - Alerting: >400ms warning, >500ms critical\n```\n\n**Resource limits**:\n```yaml\nC-070: Database connection pool\n  - Max connections: 20\n  - Source: RDS instance limit\n  - Behavior: Queue requests if pool exhausted\n  - Timeout: 5 seconds wait for connection\n```\n\n---\n\n### 5. Security Constraints\n\n**Authentication**:\n```yaml\nC-080: HTTPS requirement\n  - Protocol: All auth requests must be HTTPS\n  - Source: Security policy\n  - Enforcement: Reject HTTP requests\n  - Exception: None (no HTTP fallback)\n```\n\n**Session management**:\n```yaml\nC-090: Session timeout\n  - Duration: 30 minutes of inactivity\n  - Source: Security team policy\n  - Token: JWT with exp claim\n  - Storage: Redis with TTL\n```\n\n---\n\n## Constraint vs Design Decision\n\n**Constraint (C-*)** - **GIVEN** by ecosystem:\n```yaml\nâœ… C-001: Stripe API timeout is 10 seconds\n   Source: Stripe documentation (external reality)\n   We MUST work within this constraint\n\nâœ… C-002: PCI-DSS prohibits storing card numbers\n   Source: Payment Card Industry regulation\n   We MUST comply\n\nâœ… C-003: Team knows Python, not Java\n   Source: Team capabilities (E(t))\n   We work within this reality\n```\n\n**Design Decision** - **CHOSEN** by us:\n```yaml\nâŒ \"We will use PostgreSQL\" â†’ This is ADR, not C-*\nâŒ \"We will implement REST API\" â†’ This is ADR, not C-*\nâŒ \"We will use MVC pattern\" â†’ This is ADR, not C-*\n```\n\n**Rule**: If it's a choice between alternatives â†’ **ADR** (Design stage)\nIf it's a given reality we must work within â†’ **C-*** (Constraint)\n\n---\n\n## Extraction Process\n\n### Step 1: Identify Ecosystem Sources\n\n**Ask**:\n1. What external APIs/services are we using? (Stripe, Auth0, AWS)\n2. What compliance requirements apply? (PCI-DSS, GDPR, HIPAA)\n3. What platform constraints exist? (language version, libraries)\n4. What performance SLAs? (response time, uptime)\n5. What security policies? (HTTPS, encryption, session timeout)\n6. What team constraints? (skills, preferences, existing systems)\n\n---\n\n### Step 2: Document Each Constraint\n\n**Template**:\n```yaml\nC-{ID}: {Constraint Name}\n  - Value/Requirement: {What is constrained}\n  - Source: {Where this constraint comes from - API docs, regulation, policy}\n  - Ecosystem E(t): {What ecosystem component imposes this}\n  - Implementation: {How code must handle this}\n  - Validation: {How to verify compliance}\n  - Autogenerate: {Yes/No}\n```\n\n---\n\n## Output Format\n\n```\n[EXTRACT CONSTRAINTS - <REQ-ID>]\n\nRequirement: User login\n\nConstraints Extracted:\n\nAPI/Service Constraints (2):\n  âœ“ C-001: Database query timeout (100ms, RDS limit)\n  âœ“ C-002: Session storage (Redis, existing infrastructure)\n\nCompliance Constraints (2):\n  âœ“ C-003: HTTPS required (security policy)\n  âœ“ C-004: Password hashing (bcrypt, security standard)\n\nPerformance Constraints (1):\n  âœ“ C-005: Login response time (<500ms, SLA requirement)\n\nTotal: 5 constraints\n\nEcosystem E(t) Acknowledged:\n  - External: RDS connection limits, Redis infrastructure\n  - Compliance: Security policies (HTTPS, bcrypt)\n  - Performance: SLA requirements\n\nUpdated: docs/requirements/authentication.md\n  Added: Constraints section with 5 C-*\n\nâœ… Constraint Extraction Complete!\n```\n\n---\n\n## Notes\n\n**Why extract constraints?**\n- **Acknowledge ecosystem E(t)**: Document external realities\n- **Design context**: Constraints inform ADRs (architecture decisions)\n- **Code generation**: Some constraints can be autogenerated (timeout checks)\n- **Compliance**: Document regulatory requirements\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  all_ecosystem_constraints_documented: true\n  constraints_vs_choices_clear: true\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/requirements/extract-formulas/SKILL.md": "---\nname: extract-formulas\ndescription: Extract mathematical formulas (F-*) from requirements - calculations, algorithms, conversions. Enables autogeneration of calculation functions with tests. Use when requirements involve math, dates, percentages, or algorithms.\nallowed-tools: [Read, Write, Edit]\n---\n\n# extract-formulas\n\n**Skill Type**: Actuator (Requirements Disambiguation)\n**Purpose**: Extract F-* formulas from REQ-* requirements\n**Prerequisites**: REQ-* requirement exists\n\n---\n\n## Agent Instructions\n\nYou are extracting **formulas** (F-*) from requirements.\n\n**Formulas** are:\n- Mathematical calculations (fee = amount * rate)\n- Date/time calculations (expiry = issue_time + duration)\n- Conversions (celsius = (fahrenheit - 32) * 5/9)\n- Algorithms (hash, scoring, ranking)\n\n**Goal**: Identify formulas precise enough for code autogeneration.\n\n---\n\n## F-* Categories\n\n### 1. Arithmetic Formulas\n\n```yaml\nF-001: Stripe processing fee\n  - Formula: fee = (amount * 0.029) + 0.30\n  - Inputs: amount (float)\n  - Output: fee (float, rounded to 2 decimals)\n  - Autogenerate: calculate_stripe_fee(amount) -> float\n```\n\n### 2. Date/Time Calculations\n\n```yaml\nF-010: Token expiry time\n  - Formula: expiry = issue_time + (60 * 60) seconds\n  - Inputs: issue_time (datetime)\n  - Output: expiry (datetime)\n  - Autogenerate: calculate_token_expiry(issue_time) -> datetime\n```\n\n### 3. Percentage/Ratio Calculations\n\n```yaml\nF-020: Discount amount\n  - Formula: discount = original_price * discount_percentage\n  - Inputs: original_price (float), discount_percentage (float 0.0-1.0)\n  - Output: discount (float, rounded to 2 decimals)\n  - Autogenerate: calculate_discount(price, percentage) -> float\n```\n\n### 4. Hash/Checksum Algorithms\n\n```yaml\nF-030: Idempotency key\n  - Formula: key = SHA256(merchant_id + timestamp + amount)\n  - Inputs: merchant_id (str), timestamp (int), amount (float)\n  - Output: key (hex string, 64 chars)\n  - Autogenerate: generate_idempotency_key(...) -> str\n```\n\n---\n\n## Extraction Process\n\nIdentify formulas by looking for:\n- Calculations: \"calculate\", \"compute\", \"determine\"\n- Operators: +, -, *, /, %, ^\n- Functions: SHA256, round, abs, max, min\n- Time: \"expires after\", \"duration\", \"timeout\"\n- Money: \"fee\", \"tax\", \"discount\", \"total\"\n\n---\n\n## Output Format\n\n```\n[EXTRACT FORMULAS - <REQ-ID>]\n\nRequirement: Payment processing\n\nFormulas Extracted (3):\n  âœ“ F-001: Stripe processing fee calculation\n  âœ“ F-002: Idempotency key generation\n  âœ“ F-003: Transaction timeout calculation\n\nUpdated: docs/requirements/payments.md\n  Added: Formulas section with 3 F-*\n\nâœ… Formula Extraction Complete!\n```\n\n---\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/requirements/refine-requirements/SKILL.md": "---\nname: refine-requirements\ndescription: Refine requirements from discoveries during TDD/BDD implementation. Captures edge cases, race conditions, and business rules discovered by developers. Enables requirements refinement loop. Use when developers discover missing requirements during coding.\nallowed-tools: [Read, Write, Edit, Grep]\n---\n\n# refine-requirements\n\n**Skill Type**: Actuator (Requirements Refinement Loop)\n**Purpose**: Update requirements from TDD/BDD discoveries\n**Prerequisites**: Requirement exists, discovery made during implementation\n\n---\n\n## Agent Instructions\n\nYou are implementing the **requirements refinement loop** - a key innovation in AI SDLC v3.0.\n\n**The Loop**:\n```\nRequirements (REQ-*, BR-*, C-*, F-*)\n  â†“ (used for)\nTDD/BDD Implementation\n  â†“ (discovers)\nMissing Requirements (edge cases, race conditions)\n  â†“ (feeds back to)\nUpdated Requirements (new BR-*, C-*, F-*)\n  â†“ (used for)\nNext Implementation\n```\n\n**Your role**: Capture discoveries and update requirements.\n\n---\n\n## Discovery Types\n\n### Type 1: Edge Cases\n\n**Discovered During**: GREEN phase (implementation)\n\n**Example**:\n```\nOriginal: REQ-F-USER-001: User registration\n\nTDD Implementation:\n  Developer: \"What if two users register with the same email simultaneously?\"\n\nDiscovery: Race condition not covered in original requirement\n\nNew BR-*:\n  BR-015: Concurrent registration prevention\n    - Use database unique constraint on email\n    - Catch IntegrityError on duplicate\n    - Return \"Email already registered\"\n    - Discovered: 2025-11-20 during TDD GREEN phase\n    - Discovered by: Developer question\n```\n\n---\n\n### Type 2: Missing Business Rules\n\n**Discovered During**: RED phase (test writing)\n\n**Example**:\n```\nOriginal: <REQ-ID>: Payment processing\n\nTDD Implementation (RED phase):\n  Developer writing test: \"Should I test duplicate payments?\"\n  Developer: \"What if user clicks 'Pay' button twice?\"\n\nDiscovery: Idempotency not covered in original requirement\n\nNew BR-*:\n  BR-020: Duplicate payment prevention\n    - Generate idempotency key per payment\n    - Same key = same charge (no duplicate)\n    - Key format: SHA256(user_id + timestamp + amount)\n    - Discovered: 2025-11-20 during TDD RED phase\n    - Discovered by: Developer test case question\n\nNew F-*:\n  F-005: Idempotency key generation\n    - Formula: SHA256(user_id + timestamp + amount)\n    - Inputs: user_id (str), timestamp (int), amount (float)\n    - Output: hex string (64 chars)\n    - Discovered: 2025-11-20 during TDD RED phase\n```\n\n---\n\n### Type 3: Missing Constraints\n\n**Discovered During**: REFACTOR phase\n\n**Example**:\n```\nOriginal: REQ-F-EXPORT-001: User data export\n\nTDD Implementation (REFACTOR phase):\n  Developer: \"Export takes 5 minutes for large accounts\"\n\nDiscovery: Timeout constraint needed\n\nNew C-*:\n  C-015: Export generation timeout\n    - Max time: 5 minutes\n    - Behavior: Generate in background, email link when ready\n    - Discovered: 2025-11-20 during TDD REFACTOR phase\n    - Discovered by: Performance observation\n```\n\n---\n\n## Workflow\n\n### Step 1: Capture Discovery\n\n**Record**:\n- What was discovered?\n- During which phase? (RED, GREEN, REFACTOR)\n- Who discovered it? (developer, tester, stakeholder)\n- Why is it important?\n\n**Template**:\n```yaml\nDiscovery:\n  date: 2025-11-20\n  phase: TDD GREEN phase\n  discovered_by: Developer\n  question: \"What if two users register with same email simultaneously?\"\n  impact: Race condition could create duplicate accounts\n  severity: High (data integrity issue)\n```\n\n---\n\n### Step 2: Determine Addition Type\n\n**Options**:\n1. **New BR-*** - Business rule not previously identified\n2. **New C-*** - Constraint from ecosystem not acknowledged\n3. **New F-*** - Formula/calculation not specified\n4. **Updated BR-/C-/F-*** - Existing specification needs refinement\n\n---\n\n### Step 3: Update Requirement Document\n\n**Add new BR-/C-/F-* with discovery metadata**:\n\n```markdown\n## REQ-F-USER-001: User Registration\n\n[Existing content...]\n\n### Business Rules\n\n**BR-001: Email validation**\n[Existing spec...]\n\n**BR-002: Password requirements**\n[Existing spec...]\n\n**BR-015: Concurrent registration prevention** â­ NEW\n- **Use database unique constraint on email column**\n- **Catch unique constraint violation (IntegrityError)**\n- **Return error: \"Email already registered\"**\n- **Discovered**: 2025-11-20 during TDD GREEN phase\n- **Discovery Source**: Developer question about race condition\n- **Impact**: Prevents duplicate accounts in concurrent scenarios\n- **Tests Added**: test_concurrent_registration_prevented()\n- **Code Updated**: src/auth/registration.py (added try/except)\n```\n\n**Metadata to include**:\n- âœ… Discovery date\n- âœ… Discovery phase (RED/GREEN/REFACTOR/BDD)\n- âœ… Discovery source (developer, tester, user feedback)\n- âœ… Impact/rationale\n- âœ… Tests added\n- âœ… Code updated\n\n---\n\n### Step 4: Update Traceability\n\n**Record refinement in traceability**:\n\n```yaml\n# docs/traceability/requirement-refinements.yml\n\nREQ-F-USER-001:\n  refinements:\n    - date: 2025-11-20\n      added: BR-015\n      reason: \"Race condition discovered during TDD\"\n      phase: GREEN\n      discovered_by: \"Developer\"\n      commit: \"abc123\"\n```\n\n---\n\n### Step 5: Update Code and Tests\n\n**If code already written**, update it:\n\n```python\n# Before (original implementation)\ndef register(email: str, password: str) -> RegisterResult:\n    if User.exists(email):\n        return RegisterResult(success=False, error=\"Email already registered\")\n    user = User.create(email=email, password=hash_password(password))\n    return RegisterResult(success=True, user=user)\n\n# After (refined with BR-015)\ndef register(email: str, password: str) -> RegisterResult:\n    try:\n        # BR-015: Database unique constraint handles race condition\n        user = User.create(email=email, password=hash_password(password))\n        return RegisterResult(success=True, user=user)\n    except IntegrityError as e:\n        # BR-015: Concurrent registration caught by database\n        if \"unique constraint\" in str(e).lower():\n            return RegisterResult(success=False, error=\"Email already registered\")\n        raise\n```\n\n**Add test**:\n```python\n# Validates: BR-015\ndef test_concurrent_registration_prevented():\n    \"\"\"Test race condition handled by database constraint\"\"\"\n    # Simulate concurrent registrations\n    with ThreadPoolExecutor(max_workers=2) as executor:\n        future1 = executor.submit(register, \"user@example.com\", \"Pass123!\")\n        future2 = executor.submit(register, \"user@example.com\", \"Pass123!\")\n        results = [future1.result(), future2.result()]\n\n    # One should succeed, one should fail\n    successes = [r for r in results if r.success]\n    failures = [r for r in results if not r.success]\n    assert len(successes) == 1\n    assert len(failures) == 1\n    assert failures[0].error == \"Email already registered\"\n```\n\n---\n\n### Step 6: Commit Refinement\n\n```bash\ngit add docs/requirements/ src/ tests/\ngit commit -m \"REFINE: Add BR-015 to REQ-F-USER-001 (race condition)\n\nRefine user registration requirement with concurrent handling.\n\nDiscovery:\n- Phase: TDD GREEN phase\n- Question: What if two users register simultaneously?\n- Impact: Race condition could create duplicate accounts\n\nAdded:\n- BR-015: Concurrent registration prevention\n  - Use database unique constraint\n  - Catch IntegrityError\n  - Return clear error message\n\nUpdated Code:\n- src/auth/registration.py: Added try/except for IntegrityError\n\nAdded Tests:\n- test_concurrent_registration_prevented() with thread pool\n\nRefines: REQ-F-USER-001\nDiscovered: 2025-11-20 during TDD GREEN phase\n\"\n```\n\n---\n\n## Output Format\n\n```\n[REFINE REQUIREMENTS - REQ-F-USER-001]\n\nOriginal Requirement:\n  REQ-F-USER-001: User registration with email\n\nDiscovery During TDD GREEN Phase:\n  Question: \"What if two users register with same email simultaneously?\"\n  Impact: Race condition â†’ duplicate accounts\n  Severity: High (data integrity)\n\nRefinement Added:\n\n  BR-015: Concurrent registration prevention â­ NEW\n    - Use database unique constraint on email\n    - Catch IntegrityError on duplicate\n    - Return \"Email already registered\"\n    - Discovered: 2025-11-20 during TDD GREEN phase\n    - Source: Developer question\n\nCode Updated:\n  âœ“ src/auth/registration.py (added try/except for IntegrityError)\n\nTests Added:\n  âœ“ test_concurrent_registration_prevented() (thread pool simulation)\n\nTraceability Updated:\n  âœ“ docs/traceability/requirement-refinements.yml\n\nRequirements Doc Updated:\n  âœ“ docs/requirements/user-management.md\n    Added: BR-015 with discovery metadata\n\nCommit: REFINE: Add BR-015 to REQ-F-USER-001\n\nâœ… Requirement Refined!\n   REQ-F-USER-001 now covers race condition\n   Next developer won't have same question\n```\n\n---\n\n## Prerequisites Check\n\nBefore invoking:\n1. REQ-* requirement exists\n2. Discovery made (developer question, test case, implementation issue)\n\n---\n\n## Notes\n\n**Why requirements refinement?**\n- **Living requirements**: Requirements evolve based on implementation reality\n- **Knowledge capture**: Developer discoveries become permanent documentation\n- **Prevent re-discovery**: Next developer sees the edge case already covered\n- **Better specifications**: Requirements improve over time\n\n**Refinement vs Original Extraction**:\n```\nOriginal: Broad understanding, may miss edge cases\nRefined: Precise understanding from implementation experience\n```\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  all_discoveries_captured: true\n  requirements_continuously_refined: true\n  edge_cases_documented: true\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/requirements/requirement-extraction/SKILL.md": "---\nname: requirement-extraction\ndescription: Extract structured requirements with REQ-* keys from raw intent. Transforms vague user intent into formal requirements with unique keys, acceptance criteria, and business context. Use when starting new features or analyzing user stories.\nallowed-tools: [Read, Write, Edit, Grep, Glob]\n---\n\n# requirement-extraction\n\n**Skill Type**: Actuator (Requirements Stage)\n**Purpose**: Transform raw intent into structured requirements with REQ-* keys\n**Prerequisites**: Raw intent or user story available\n\n---\n\n## Agent Instructions\n\nYou are extracting **structured requirements** from **raw user intent**.\n\nYour goal is to transform vague intent into **formal requirements** with:\n1. Unique REQ-* keys\n2. Clear descriptions\n3. Acceptance criteria\n4. Business context\n5. Traceability to intent\n\n---\n\n## Workflow\n\n### Step 1: Analyze Intent\n\n**Parse the raw intent**:\n- What is the user trying to achieve?\n- What problem are they solving?\n- What are the key capabilities needed?\n- Who are the users (personas)?\n- What are the success criteria?\n\n**Example Intent**:\n```\nINT-042: \"We need a customer self-service portal where users can log in,\nview their account balance, update their profile, and download invoices.\"\n```\n\n**Analysis**:\n```\nGoal: Customer self-service\nProblem: Customers calling support for basic info\nCapabilities needed:\n  1. User authentication\n  2. View account data\n  3. Edit profile\n  4. Download documents\nUsers: Existing customers\nSuccess: Reduced support calls\n```\n\n---\n\n### Step 2: Identify Requirements\n\n**Break intent into discrete requirements**:\n\n**Rule**: One requirement = one testable capability\n\n**From INT-042, extract**:\n1. User login (authentication capability)\n2. View account balance (read account data)\n3. Update profile (edit user data)\n4. Download invoices (document access)\n\n---\n\n### Step 3: Assign REQ-* Keys\n\n**Determine requirement type**:\n\n**REQ-F-* (Functional)** - Features users can use:\n- User login â†’ `<REQ-ID>`\n- View balance â†’ `REQ-F-PORTAL-001`\n- Update profile â†’ `REQ-F-PORTAL-002`\n- Download invoices â†’ `REQ-F-PORTAL-003`\n\n**REQ-NFR-* (Non-Functional)** - Quality attributes:\n- Response time < 500ms â†’ `REQ-NFR-PERF-001`\n- SSL encryption â†’ `REQ-NFR-SEC-001`\n- 99.9% uptime â†’ `REQ-NFR-AVAIL-001`\n\n**REQ-DATA-* (Data Quality)** - Data requirements:\n- Email must be valid â†’ `REQ-DATA-AQ-001`\n- PII must be encrypted â†’ `REQ-DATA-PII-001`\n\n**Key assignment rules**:\n- Sequential IDs within domain (001, 002, 003...)\n- Domain reflects feature area (AUTH, PORTAL, PAY, USER)\n- Use existing domains where possible\n\n---\n\n### Step 4: Write Requirement Specifications\n\n**Format for each requirement**:\n\n```markdown\n## <REQ-ID>: User Login with Email and Password\n\n**Type**: Functional Requirement\n**Domain**: Authentication\n**Priority**: P0 (Critical)\n**Intent**: INT-042\n\n**Description**:\nUsers must be able to log in to the customer portal using their registered email address and password.\n\n**Acceptance Criteria**:\n1. User can enter email and password on login page\n2. Valid credentials grant access to customer portal\n3. Invalid credentials show clear error message\n4. Account locks after 3 failed attempts for 15 minutes\n5. Locked account shows clear lockout message with time remaining\n\n**Business Context**:\n- Current State: No customer self-service (customers call support)\n- Problem: High support call volume for basic account info\n- Solution: Self-service portal with authentication\n- Value: Reduce support calls by 40%\n\n**User Story**:\nAs a customer\nI want to log in with my email and password\nSo that I can access my account information\n\n**Related Requirements**:\n- REQ-NFR-SEC-001: Password must be encrypted\n- REQ-NFR-PERF-001: Login response < 500ms\n- REQ-DATA-AQ-001: Email must be valid format\n\n**Assumptions**:\n- Users already registered (registration is separate feature)\n- Email is unique identifier\n- Session timeout is 30 minutes (standard)\n\n**Out of Scope**:\n- Social login (OAuth)\n- Passwordless login\n- Biometric authentication\n```\n\n**Key elements**:\n- âœ… Unique REQ-* key\n- âœ… Type, domain, priority\n- âœ… Link to original intent (INT-*)\n- âœ… Clear description\n- âœ… Measurable acceptance criteria\n- âœ… Business context (current state, problem, solution, value)\n- âœ… User story format\n- âœ… Related requirements\n- âœ… Assumptions and out-of-scope\n\n---\n\n### Step 5: Create Requirements Document\n\n**File structure**:\n```\ndocs/requirements/\nâ”œâ”€â”€ authentication.md       # REQ-F-AUTH-*\nâ”œâ”€â”€ customer-portal.md      # REQ-F-PORTAL-*\nâ”œâ”€â”€ performance.md          # REQ-NFR-PERF-*\nâ””â”€â”€ security.md            # REQ-NFR-SEC-*\n```\n\n**Example file** (`docs/requirements/authentication.md`):\n```markdown\n# Authentication Requirements\n\n**Domain**: Authentication\n**Intent**: INT-042 (Customer self-service portal)\n**Owner**: Product Team\n**Created**: 2025-11-20\n**Last Updated**: 2025-11-20\n\n---\n\n## <REQ-ID>: User Login with Email and Password\n\n[Full specification as shown above]\n\n---\n\n## <REQ-ID>: Password Reset via Email\n\n**Type**: Functional Requirement\n**Domain**: Authentication\n**Priority**: P1 (High)\n**Intent**: INT-042\n\n**Description**:\nUsers who forget their password must be able to reset it via email.\n\n**Acceptance Criteria**:\n1. User clicks \"Forgot Password\" link\n2. User enters email address\n3. System sends reset link via email within 5 seconds\n4. Reset link expires after 1 hour\n5. Reset link can only be used once\n6. User sets new password meeting requirements\n\n[Continue with Business Context, User Story, etc.]\n```\n\n---\n\n### Step 6: Create Traceability Entry\n\n**Map intent to requirements**:\n\n```yaml\n# docs/traceability/intent-to-requirements.yml\n\nINT-042:\n  title: \"Customer self-service portal\"\n  date_created: \"2025-11-20\"\n  status: \"In Progress\"\n  requirements:\n    - <REQ-ID>\n    - <REQ-ID>\n    - REQ-F-PORTAL-001\n    - REQ-F-PORTAL-002\n    - REQ-F-PORTAL-003\n    - REQ-NFR-PERF-001\n    - REQ-NFR-SEC-001\n    - REQ-DATA-AQ-001\n  requirement_count: 8\n  completion: 0%  # Updated as requirements are implemented\n```\n\n---\n\n### Step 7: Commit Requirements\n\n**Create commit**:\n\n```bash\ngit add docs/requirements/ docs/traceability/\ngit commit -m \"REQUIREMENTS: Extract requirements from INT-042\n\nExtract structured requirements from customer portal intent.\n\nRequirements Extracted:\n- <REQ-ID>: User login with email/password\n- <REQ-ID>: Password reset via email\n- REQ-F-PORTAL-001: View account balance\n- REQ-F-PORTAL-002: Update user profile\n- REQ-F-PORTAL-003: Download invoices\n- REQ-NFR-PERF-001: Response time < 500ms\n- REQ-NFR-SEC-001: SSL encryption\n- REQ-DATA-AQ-001: Email validation\n\nTotal: 8 requirements\n\nTraceability: INT-042 â†’ 8 REQ-* keys\n\nSource Intent: INT-042 (Customer self-service portal)\n\"\n```\n\n---\n\n## Output Format\n\nWhen you complete requirement extraction:\n\n```\n[REQUIREMENT EXTRACTION - INT-042]\n\nIntent: Customer self-service portal\n\nRequirements Extracted:\n\nFunctional Requirements (5):\n  âœ“ <REQ-ID>: User login with email/password\n  âœ“ <REQ-ID>: Password reset via email\n  âœ“ REQ-F-PORTAL-001: View account balance\n  âœ“ REQ-F-PORTAL-002: Update user profile\n  âœ“ REQ-F-PORTAL-003: Download invoices\n\nNon-Functional Requirements (2):\n  âœ“ REQ-NFR-PERF-001: Response time < 500ms\n  âœ“ REQ-NFR-SEC-001: SSL encryption required\n\nData Quality Requirements (1):\n  âœ“ REQ-DATA-AQ-001: Email must be valid format\n\nTotal: 8 requirements\n\nFiles Created:\n  + docs/requirements/authentication.md (<REQ-ID>, 002)\n  + docs/requirements/customer-portal.md (REQ-F-PORTAL-001, 002, 003)\n  + docs/requirements/performance.md (REQ-NFR-PERF-001)\n  + docs/requirements/security.md (REQ-NFR-SEC-001)\n  + docs/requirements/data-quality.md (REQ-DATA-AQ-001)\n\nTraceability:\n  Intent: INT-042 â†’ 8 requirements\n  Mapping: Created in docs/traceability/intent-to-requirements.yml\n\nCommit: REQUIREMENTS: Extract requirements from INT-042\n\nâœ… Extraction Complete!\n   Next: Invoke disambiguate-requirements to add BR-*, C-*, F-*\n```\n\n---\n\n## Prerequisites Check\n\nBefore invoking this skill, ensure:\n1. Raw intent available (user story, feature request, problem statement)\n2. Intent has some level of detail (not just \"make it better\")\n\nIf prerequisites not met:\n- Intent too vague â†’ Ask user clarifying questions\n- No intent â†’ Ask user what they want to build\n\n---\n\n## Clarifying Questions\n\n**If intent is vague, ask**:\n\n1. **Who** is the user? (persona, role, context)\n2. **What** are they trying to do? (goal, task, capability)\n3. **Why** do they need this? (problem, value, business case)\n4. **How** will we know it's done? (acceptance criteria, success metrics)\n5. **When** is it needed? (timeline, priority)\n6. **What if** edge cases? (error handling, boundary conditions)\n\n**Example**:\n```\nVague Intent: \"Add payment processing\"\n\nClarifying Questions:\n  1. What payment methods? (credit card, PayPal, crypto?)\n  2. What payment provider? (Stripe, Braintree, custom?)\n  3. What compliance requirements? (PCI-DSS level?)\n  4. What currencies? (USD only, multi-currency?)\n  5. What transaction limits? (min/max amounts?)\n  6. What error handling? (retry, refund, dispute?)\n\nRefined Intent: \"Add credit card payment processing via Stripe,\nPCI-DSS Level 1 compliant, USD only, $0.01 to $10,000 per transaction,\nwith automatic retry on temporary failures.\"\n```\n\n---\n\n## Next Steps\n\nAfter requirement extraction:\n1. **Disambiguate**: Invoke `disambiguate-requirements` to add BR-*, C-*, F-*\n2. **Validate**: Invoke `validate-requirements` to check quality\n3. **Design**: Move to Design stage (create architecture)\n\n---\n\n## Configuration\n\n```yaml\nplugins:\n  - name: \"@aisdlc/requirements-skills\"\n    config:\n      extraction:\n        auto_extract_on_intent: true          # Auto-invoke when intent detected\n        require_acceptance_criteria: true      # All REQ-* must have AC\n        min_requirements_per_intent: 1         # At least 1 REQ per intent\n        ask_clarifying_questions: true         # Ask if intent vague\n        max_clarifying_questions: 6            # Max questions to ask\n```\n\n---\n\n## Notes\n\n**Why requirement extraction?**\n- **Clarity**: Transforms vague intent into specific requirements\n- **Traceability**: Links requirements back to original intent\n- **Testability**: Acceptance criteria become test cases\n- **Prioritization**: Clear requirements enable better planning\n\n**Good requirements characteristics** (SMART):\n- **Specific**: Clear, unambiguous description\n- **Measurable**: Acceptance criteria can be tested\n- **Achievable**: Technically feasible\n- **Relevant**: Linked to business value\n- **Testable**: Can write tests to validate\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  all_intents_have_requirements: true\n  all_requirements_have_unique_keys: true\n  all_requirements_have_acceptance_criteria: true\n  all_requirements_traceable_to_intent: true\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/requirements/validate-requirements/SKILL.md": "---\nname: validate-requirements\ndescription: Validate requirements quality - unique keys, acceptance criteria, testability, clarity. Sensor detecting requirement quality issues. Use before moving to Design stage or as quality gate.\nallowed-tools: [Read, Grep, Glob]\n---\n\n# validate-requirements\n\n**Skill Type**: Sensor (Quality Gate)\n**Purpose**: Validate requirement quality and completeness\n**Prerequisites**: Requirements exist in documentation\n\n---\n\n## Agent Instructions\n\nYou are validating **requirement quality** as a quality gate.\n\n**Validation checks**:\n1. Unique REQ-* keys (no duplicates)\n2. Valid key format (matches pattern)\n3. Acceptance criteria present\n4. Testable format (can write tests)\n5. Traceability to intent\n6. No ambiguous language\n\n---\n\n## Validation Checks\n\n### Check 1: Unique Keys\n\n**Rule**: All REQ-* keys must be unique\n\n```bash\n# Find duplicates\ngrep -rho \"^## REQ-[A-Z-]*-[0-9]*\" docs/requirements/ | sort | uniq -d\n```\n\n**Example**:\n```\nâœ… Pass: All REQ-* keys unique\nâŒ Fail: <REQ-ID> appears in 2 files\n```\n\n---\n\n### Check 2: Valid Key Format\n\n**Rule**: All keys must match REQ-* pattern\n\n```bash\n# Check format\ngrep -rh \"^## REQ-\" docs/requirements/ | grep -vE \"^## REQ-(F|NFR|DATA|BR)-[A-Z]{2,10}-[0-9]{3}\"\n```\n\n---\n\n### Check 3: Acceptance Criteria\n\n**Rule**: All requirements must have acceptance criteria\n\n```bash\n# Find requirements without AC\ngrep -rn \"^## REQ-\" docs/requirements/ | while read line; do\n  file=$(echo \"$line\" | cut -d: -f1)\n  # Check if AC section exists after requirement\n  grep -A 20 \"$line\" \"$file\" | grep -q \"Acceptance Criteria\" || echo \"Missing AC: $line\"\ndone\n```\n\n---\n\n### Check 4: Testability\n\n**Rule**: Acceptance criteria must be testable\n\n**âŒ Not Testable**:\n```\nAcceptance Criteria:\n- System should be user-friendly\n- Performance should be good\n```\n\n**âœ… Testable**:\n```\nAcceptance Criteria:\n- Login response time < 500ms (p95)\n- User sees \"Welcome\" message after successful login\n```\n\n---\n\n### Check 5: Traceability\n\n**Rule**: All REQ-* must link to INT-*\n\n```bash\n# Find requirements without intent link\ngrep -rn \"^## REQ-\" docs/requirements/ | while read line; do\n  file=$(echo \"$line\" | cut -d: -f1)\n  grep -A 10 \"$line\" \"$file\" | grep -q \"Intent: INT-\" || echo \"Missing Intent: $line\"\ndone\n```\n\n---\n\n### Check 6: Ambiguous Language\n\n**Detect vague terms**:\n- \"user-friendly\", \"fast\", \"good\", \"better\", \"nice\"\n- \"should\", \"might\", \"possibly\"\n- \"etc.\", \"and so on\"\n\n**Replace with**:\n- Specific measurements (\"response time < 500ms\")\n- Clear criteria (\"user sees confirmation message\")\n- Complete lists (no \"etc.\")\n\n---\n\n## Output Format\n\n```\n[VALIDATE REQUIREMENTS]\n\nTotal Requirements Scanned: 42\n\nâœ… PASSED Checks (5/6):\n  âœ“ Unique keys: All REQ-* unique\n  âœ“ Valid format: All keys match pattern\n  âœ“ Acceptance criteria: All requirements have AC\n  âœ“ Traceability: All link to INT-*\n  âœ“ Testability: All AC measurable\n\nâŒ FAILED Checks (1/6):\n  âœ— Ambiguous language: 3 requirements contain vague terms\n\nIssues Found:\n\nAmbiguous Language (3 requirements):\n  1. REQ-F-PORTAL-001:\n     - Line 45: \"User interface should be user-friendly\"\n     - Fix: Replace with \"User can complete task in â‰¤3 clicks\"\n\n  2. REQ-NFR-PERF-002:\n     - Line 23: \"Database performance should be good\"\n     - Fix: Replace with \"Database queries complete in <100ms (p95)\"\n\n  3. REQ-F-NOTIF-001:\n     - Line 67: \"Notifications should be sent quickly\"\n     - Fix: Replace with \"Notifications sent within 5 seconds\"\n\nRecommendations:\n  1. Fix 3 requirements with ambiguous language\n  2. Re-run validation after fixes\n  3. Proceed to Design stage after all checks pass\n\nValidation Status: âš ï¸ FAILED (6 issues)\nQuality Gate: âŒ BLOCKED (fix issues before proceeding)\n```\n\n---\n\n## Quality Gate Behavior\n\n**If validation passes**:\n```\nâœ… All Requirements Valid\n\nQuality gate: PASS\nReady for: Design stage\n```\n\n**If validation fails**:\n```\nâŒ Validation Failed (6 issues)\n\nQuality gate: BLOCKED\nAction required: Fix issues before Design stage\nRecommendation: Update requirements and re-validate\n```\n\n---\n\n## Notes\n\n**Why validate requirements?**\n- **Quality gate**: Ensure requirements are implementation-ready\n- **Prevent rework**: Catch issues before coding starts\n- **Compliance**: Regulations require traceable, testable requirements\n- **Clear specs**: Ambiguous requirements â†’ ambiguous code\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  all_requirements_valid: true\n  quality_issues: 0\n  ready_for_design_stage: true\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/runtime/create-observability-config/SKILL.md": "---\nname: create-observability-config\ndescription: Setup observability platform configuration (Datadog, Prometheus, Splunk) with REQ-* dashboards and alerts. Creates monitors for each requirement with SLA tracking. Use when deploying to production or setting up monitoring.\nallowed-tools: [Read, Write, Edit]\n---\n\n# create-observability-config\n\n**Skill Type**: Actuator (Runtime Setup)\n**Purpose**: Setup observability with REQ-* dashboards and alerts\n**Prerequisites**: Code deployed or ready to deploy, telemetry tagged\n\n---\n\n## Agent Instructions\n\nYou are setting up **observability** with **requirement-level monitoring**.\n\n**Create**:\n1. Dashboards per REQ-* (success rate, latency, errors)\n2. Alerts for SLA violations\n3. Log aggregation with REQ-* filtering\n4. Trace visualization with REQ-* tags\n\n---\n\n## Platform Configurations\n\n### Datadog Configuration\n\n**Dashboard per Requirement**:\n\n```yaml\n# datadog/dashboards/req-f-auth-001.json\n\n{\n  \"title\": \"<REQ-ID>: User Login Monitoring\",\n  \"description\": \"Real-time monitoring for user login functionality\",\n  \"widgets\": [\n    {\n      \"title\": \"Login Success Rate\",\n      \"definition\": {\n        \"type\": \"timeseries\",\n        \"requests\": [{\n          \"q\": \"sum:auth.login.attempts{req:<REQ-ID>,success:true}.as_count() / sum:auth.login.attempts{req:<REQ-ID>}.as_count()\"\n        }]\n      }\n    },\n    {\n      \"title\": \"Login Latency (p95)\",\n      \"definition\": {\n        \"type\": \"timeseries\",\n        \"requests\": [{\n          \"q\": \"p95:auth.login.duration{req:<REQ-ID>}\"\n        }],\n        \"markers\": [{\n          \"value\": 500,  // REQ-NFR-PERF-001 threshold\n          \"display_type\": \"error dashed\"\n        }]\n      }\n    },\n    {\n      \"title\": \"Failed Login Reasons\",\n      \"definition\": {\n        \"type\": \"toplist\",\n        \"requests\": [{\n          \"q\": \"top(auth.login.failures{req:<REQ-ID>} by {error}, 10, 'sum', 'desc')\"\n        }]\n      }\n    }\n  ]\n}\n```\n\n**Alerts**:\n\n```yaml\n# datadog/monitors/req-f-auth-001-latency.json\n\n{\n  \"name\": \"<REQ-ID>: Login latency exceeded\",\n  \"type\": \"metric alert\",\n  \"query\": \"avg(last_5m):p95:auth.login.duration{req:<REQ-ID>} > 500\",\n  \"message\": \"Login latency exceeded 500ms threshold (REQ-NFR-PERF-001)\\n\\nRequirement: <REQ-ID> (User Login)\\nSLA: < 500ms\\nCurrent: {{value}}ms\\n\\n@slack-alerts\",\n  \"tags\": [\"req:<REQ-ID>\", \"sla:performance\"],\n  \"options\": {\n    \"thresholds\": {\n      \"critical\": 500,\n      \"warning\": 400\n    },\n    \"notify_no_data\": true,\n    \"no_data_timeframe\": 10\n  }\n}\n```\n\n---\n\n### Prometheus Configuration\n\n**Recording Rules**:\n\n```yaml\n# prometheus/rules/req-f-auth-001.yml\n\ngroups:\n  - name: req_f_auth_001\n    interval: 30s\n    rules:\n      # Success rate\n      - record: req:auth_login_success_rate\n        expr: |\n          sum(rate(auth_login_attempts_total{req=\"<REQ-ID>\",success=\"true\"}[5m]))\n          /\n          sum(rate(auth_login_attempts_total{req=\"<REQ-ID>\"}[5m]))\n        labels:\n          req: \"<REQ-ID>\"\n\n      # Latency p95\n      - record: req:auth_login_duration_p95\n        expr: histogram_quantile(0.95, rate(auth_login_duration_seconds_bucket{req=\"<REQ-ID>\"}[5m]))\n        labels:\n          req: \"<REQ-ID>\"\n```\n\n**Alerts**:\n\n```yaml\n# prometheus/alerts/req-f-auth-001.yml\n\ngroups:\n  - name: req_f_auth_001_alerts\n    rules:\n      - alert: REQ_F_AUTH_001_LatencyHigh\n        expr: req:auth_login_duration_p95{req=\"<REQ-ID>\"} > 0.5\n        for: 5m\n        labels:\n          severity: critical\n          req: <REQ-ID>\n          sla: performance\n        annotations:\n          summary: \"Login latency exceeded (<REQ-ID>)\"\n          description: \"p95 latency is {{ $value }}s (threshold: 0.5s)\"\n          requirement: \"REQ-NFR-PERF-001: Login response < 500ms\"\n          runbook: \"docs/runbooks/performance-degradation.md\"\n```\n\n---\n\n### Splunk Configuration\n\n**Log Search**:\n\n```\n# Splunk saved search for <REQ-ID>\n\nindex=production sourcetype=app_logs req=\"<REQ-ID>\"\n| stats count by success, error\n| eval success_rate = round(count(eval(success=\"true\")) / count() * 100, 2)\n```\n\n**Dashboard**:\n\n```xml\n<dashboard>\n  <label><REQ-ID>: User Login</label>\n  <row>\n    <panel>\n      <title>Login Success Rate</title>\n      <single>\n        <search>\n          <query>\n            index=production req=\"<REQ-ID>\"\n            | stats count by success\n            | eval rate = round(count(eval(success=\"true\")) / count() * 100, 2)\n          </query>\n        </search>\n      </single>\n    </panel>\n  </row>\n</dashboard>\n```\n\n---\n\n## Output Format\n\n```\n[TELEMETRY TAGGING - <REQ-ID>]\n\nPlatform: Datadog\n\nConfiguration Created:\n\nDashboards (1):\n  âœ“ datadog/dashboards/req-f-auth-001.json\n    - Login success rate widget\n    - Login latency (p95) widget with 500ms threshold\n    - Failed login reasons widget\n    - Active users widget\n\nMonitors/Alerts (3):\n  âœ“ datadog/monitors/req-f-auth-001-latency.json\n    - Alert: p95 latency > 500ms (REQ-NFR-PERF-001)\n    - Warning: > 400ms\n    - Critical: > 500ms\n\n  âœ“ datadog/monitors/req-f-auth-001-errors.json\n    - Alert: Error rate > 5%\n    - Links to: <REQ-ID>\n\n  âœ“ datadog/monitors/req-f-auth-001-lockouts.json\n    - Alert: Lockout rate > 10%\n    - Links to: BR-003\n\nLogs:\n  âœ“ All log statements tagged with req=\"<REQ-ID>\"\n  âœ“ Searchable: logs.req:<REQ-ID>\n\nMetrics:\n  âœ“ auth.login.attempts{req:<REQ-ID>}\n  âœ“ auth.login.duration{req:<REQ-ID>}\n  âœ“ auth.login.lockouts{req:<REQ-ID>}\n\nTraces:\n  âœ“ Span \"auth.login\" tagged with req=\"<REQ-ID>\"\n\nBackward Traceability Enabled:\n  Alert â†’ req:<REQ-ID> â†’ docs/requirements/auth.md â†’ INT-100 âœ…\n\nâœ… Observability Setup Complete!\n```\n\n---\n\n## Notes\n\n**Why observability per requirement?**\n- **Requirement-level SLAs**: Monitor each REQ-* separately\n- **Impact analysis**: Know which requirements are problematic\n- **Feedback loop**: Alerts trace back to original intent\n- **Business visibility**: Dashboards show feature health\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  all_requirements_monitored: true\n  alerts_tagged_with_req: true\n  dashboards_per_requirement: true\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/runtime/telemetry-tagging/SKILL.md": "---\nname: telemetry-tagging\ndescription: Tag logs, metrics, and distributed traces with REQ-* keys for production traceability. Enables backward traceability from runtime issues to requirements to intent. Use when deploying code or setting up observability.\nallowed-tools: [Read, Write, Edit, Grep, Glob]\n---\n\n# telemetry-tagging\n\n**Skill Type**: Actuator (Runtime Feedback)\n**Purpose**: Tag production telemetry with REQ-* keys\n**Prerequisites**: Code implemented and ready for deployment\n\n---\n\n## Agent Instructions\n\nYou are adding **REQ-* tags to telemetry** for production traceability.\n\n**Telemetry types**:\n1. **Logs**: Structured logs with REQ-* in extra fields\n2. **Metrics**: Metrics tagged with `req:REQ-*`\n3. **Traces**: Distributed traces tagged with REQ-*\n\n**Goal**: Enable backward traceability (Alert â†’ REQ-* â†’ Intent)\n\n---\n\n## Workflow\n\n### Step 1: Find Code Implementing Requirements\n\n```bash\n# Find all files implementing <REQ-ID>\ngrep -rn \"# Implements: <REQ-ID>\" src/\n```\n\n---\n\n### Step 2: Add Logging Tags\n\n**Python (structlog, logging)**:\n\n```python\n# Before\ndef login(email: str, password: str) -> LoginResult:\n    # Implements: <REQ-ID>\n    result = authenticate(email, password)\n    return result\n\n# After\nimport logging\n\nlogger = logging.getLogger(__name__)\n\ndef login(email: str, password: str) -> LoginResult:\n    # Implements: <REQ-ID>\n    logger.info(\n        \"User login attempt\",\n        extra={\n            \"req\": \"<REQ-ID>\",  # â† Tag for traceability\n            \"email\": email,\n            \"success\": False  # Updated after auth\n        }\n    )\n\n    result = authenticate(email, password)\n\n    logger.info(\n        \"User login result\",\n        extra={\n            \"req\": \"<REQ-ID>\",\n            \"email\": email,\n            \"success\": result.success\n        }\n    )\n\n    if not result.success:\n        logger.warning(\n            \"Login failed\",\n            extra={\n                \"req\": \"<REQ-ID>\",\n                \"email\": email,\n                \"error\": result.error\n            }\n        )\n\n    return result\n```\n\n**TypeScript (Winston, Pino)**:\n\n```typescript\n// Implements: <REQ-ID>\nfunction login(email: string, password: string): LoginResult {\n  logger.info('User login attempt', {\n    req: '<REQ-ID>',  // â† Tag\n    email,\n  });\n\n  const result = authenticate(email, password);\n\n  logger.info('User login result', {\n    req: '<REQ-ID>',\n    email,\n    success: result.success,\n  });\n\n  return result;\n}\n```\n\n---\n\n### Step 3: Add Metrics Tags\n\n**Datadog (Python)**:\n\n```python\nfrom datadog import statsd\n\ndef login(email: str, password: str) -> LoginResult:\n    # Implements: <REQ-ID>\n\n    result = authenticate(email, password)\n\n    # Tag metric with REQ-*\n    statsd.increment(\n        'auth.login.attempts',\n        tags=[\n            'req:<REQ-ID>',  # â† Tag for traceability\n            f'success:{result.success}',\n            'env:production'\n        ]\n    )\n\n    if result.success:\n        statsd.timing(\n            'auth.login.duration',\n            login_duration_ms,\n            tags=['req:<REQ-ID>', 'env:production']\n        )\n\n    return result\n```\n\n**Prometheus (Python)**:\n\n```python\nfrom prometheus_client import Counter, Histogram\n\n# Define metrics with labels\nlogin_attempts = Counter(\n    'auth_login_attempts_total',\n    'Total login attempts',\n    ['req', 'success', 'env']\n)\n\nlogin_duration = Histogram(\n    'auth_login_duration_seconds',\n    'Login duration',\n    ['req', 'env']\n)\n\ndef login(email: str, password: str) -> LoginResult:\n    # Implements: <REQ-ID>\n\n    with login_duration.labels(req='<REQ-ID>', env='production').time():\n        result = authenticate(email, password)\n\n    login_attempts.labels(\n        req='<REQ-ID>',  # â† Tag\n        success=str(result.success).lower(),\n        env='production'\n    ).inc()\n\n    return result\n```\n\n---\n\n### Step 4: Add Distributed Trace Tags\n\n**OpenTelemetry**:\n\n```python\nfrom opentelemetry import trace\n\ntracer = trace.get_tracer(__name__)\n\ndef login(email: str, password: str) -> LoginResult:\n    # Implements: <REQ-ID>\n\n    with tracer.start_as_current_span(\"auth.login\") as span:\n        span.set_attribute(\"req\", \"<REQ-ID>\")  # â† Tag\n        span.set_attribute(\"email\", email)\n\n        result = authenticate(email, password)\n\n        span.set_attribute(\"success\", result.success)\n\n        if not result.success:\n            span.set_attribute(\"error\", result.error)\n            span.set_status(trace.Status(trace.StatusCode.ERROR))\n\n        return result\n```\n\n---\n\n### Step 5: Verify Tags Added\n\n**Check logs**:\n```bash\n# Search logs for REQ tags\ngrep \"req.*<REQ-ID>\" /var/log/app.log\n```\n\n**Check metrics (Datadog)**:\n```\nauth.login.attempts{req:<REQ-ID>,success:true}\nauth.login.duration{req:<REQ-ID>}\n```\n\n**Check traces (OpenTelemetry)**:\n```\nSpan: auth.login\n  Attributes:\n    - req: <REQ-ID>\n    - email: user@example.com\n    - success: true\n```\n\n---\n\n## Output Format\n\n```\n[TELEMETRY TAGGING - <REQ-ID>]\n\nFiles Tagged:\n\nsrc/auth/login.py:\n  âœ“ Logs: 3 log statements tagged\n    - logger.info(\"Login attempt\", req=\"<REQ-ID>\")\n    - logger.info(\"Login result\", req=\"<REQ-ID>\")\n    - logger.warning(\"Login failed\", req=\"<REQ-ID>\")\n\n  âœ“ Metrics: 2 metrics tagged\n    - auth.login.attempts{req:<REQ-ID>}\n    - auth.login.duration{req:<REQ-ID>}\n\n  âœ“ Traces: 1 span tagged\n    - Span \"auth.login\" with req=\"<REQ-ID>\"\n\nTotal Tags Added: 6\n  - Log tags: 3\n  - Metric tags: 2\n  - Trace tags: 1\n\nTraceability Enabled:\n  Production Alert â†’ req:<REQ-ID> â†’ docs/requirements/authentication.md â†’ INT-100\n\nâœ… Telemetry Tagged!\n   Backward traceability ready\n```\n\n---\n\n## Notes\n\n**Why tag telemetry?**\n- **Backward traceability**: Production issue â†’ Requirement â†’ Intent\n- **Requirement-level monitoring**: Dashboards per REQ-*\n- **Impact measurement**: Track success/failure per requirement\n- **Feedback loop**: Alerts create new intents\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  all_code_telemetry_tagged: true\n  backward_traceability: complete\n  req_level_dashboards: available\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/runtime/trace-production-issue/SKILL.md": "---\nname: trace-production-issue\ndescription: Trace production alerts and issues back through REQ-* to original intent, creating new intent for remediation. Closes feedback loop from Runtime â†’ Intent. Use when production alerts fire or issues discovered.\nallowed-tools: [Read, Grep, Glob, Bash]\n---\n\n# trace-production-issue\n\n**Skill Type**: Actuator (Feedback Loop)\n**Purpose**: Trace production issues back to requirements and create remediation intent\n**Prerequisites**: Production alert or issue identified\n\n---\n\n## Agent Instructions\n\nYou are **closing the feedback loop** from production to intent.\n\n**Workflow**: Alert â†’ REQ-* â†’ Original Intent â†’ New Remediation Intent\n\n**Your goal**: Trace issue back and create actionable remediation intent.\n\n---\n\n## Workflow\n\n### Step 1: Parse Production Alert\n\n**Extract REQ-* from alert**:\n\n```json\n{\n  \"alert_id\": \"alert_12345\",\n  \"timestamp\": \"2025-11-20T15:30:00Z\",\n  \"title\": \"Login latency exceeded\",\n  \"description\": \"p95 latency is 750ms (threshold: 500ms)\",\n  \"tags\": {\n    \"req\": \"<REQ-ID>\",  // â† Extract this\n    \"severity\": \"critical\",\n    \"sla\": \"performance\"\n  },\n  \"metric\": \"auth.login.duration\",\n  \"value\": 750,\n  \"threshold\": 500\n}\n```\n\n**Extracted**: `<REQ-ID>`\n\n---\n\n### Step 2: Trace to Requirement\n\n**Find requirement definition**:\n\n```bash\n# Search for requirement\ngrep -rn \"^## <REQ-ID>\" docs/requirements/\n\n# Output:\n# docs/requirements/authentication.md:15:## <REQ-ID>: User Login\n```\n\n**Load requirement**:\n\n```markdown\n## <REQ-ID>: User Login with Email and Password\n\n**Type**: Functional Requirement\n**Priority**: P0\n**Intent**: INT-100\n\n**Acceptance Criteria**:\n...\n\n**Related Requirements**:\n- REQ-NFR-PERF-001: Login response < 500ms  â† SLA being violated!\n```\n\n---\n\n### Step 3: Trace to Original Intent\n\n**Find original intent**:\n\n```bash\n# From requirement, find intent\ngrep \"Intent: INT-100\" docs/requirements/authentication.md\n\n# Load intent\ncat intent.md | grep -A 20 \"## INT-100\"\n```\n\n**Intent context**:\n\n```markdown\n## INT-100: User Authentication System\n\n**Requestor**: Product Team\n**Priority**: P0\n\n**Description**:\nSecure user authentication for personalization and data protection.\n```\n\n---\n\n### Step 4: Trace to Implementing Code\n\n**Find code implementing requirement**:\n\n```bash\n# Find files implementing <REQ-ID>\ngrep -rn \"# Implements: <REQ-ID>\" src/\n\n# Output:\n# src/auth/login.py:23:# Implements: <REQ-ID>\n```\n\n**Analyze code**:\n- What could cause 750ms latency?\n- Database query slow?\n- bcrypt cost too high?\n- No caching?\n\n---\n\n### Step 5: Find Related Commits\n\n**Git history for requirement**:\n\n```bash\ngit log --all --grep=\"<REQ-ID>\" --oneline\n\n# Output:\n# abc123 feat: Add user login (<REQ-ID>)\n# def456 perf: Add caching to login (<REQ-ID>)\n# ghi789 fix: Optimize db query (<REQ-ID>)\n```\n\n**Recent changes**: Did recent commit introduce regression?\n\n---\n\n### Step 6: Create Remediation Intent\n\n**Generate new intent from alert**:\n\n```markdown\n# docs/intents/remediation.md\n\n## INT-150: Fix Login Performance Degradation\n\n**Type**: Remediation (URGENT)\n**Created**: 2025-11-20\n**Priority**: P0 (Critical - SLA violation)\n**Source**: Production Alert (alert_12345)\n\n**Related To**:\n- **Original Intent**: INT-100 (User Authentication System)\n- **Requirement**: <REQ-ID> (User login)\n- **SLA Violated**: REQ-NFR-PERF-001 (Login response < 500ms)\n\n**Problem**:\nLogin p95 latency increased to 750ms (threshold: 500ms).\nSLA violation detected in production.\n\n**Alert Details**:\n- Alert: \"Login latency exceeded\"\n- Metric: auth.login.duration{req:<REQ-ID>}\n- Current: 750ms\n- Threshold: 500ms\n- Violation: +250ms (+50% over limit)\n\n**Root Cause Analysis Needed**:\n1. Database query performance (C-003: should be < 100ms)\n2. bcrypt cost factor (C-001: cost 12, ~200ms expected)\n3. Caching effectiveness (if implemented)\n4. External service calls (if any)\n\n**Proposed Investigation**:\n1. Check database query times (should be < 100ms)\n2. Profile bcrypt hashing time (should be ~200ms)\n3. Check for N+1 queries\n4. Review recent code changes (commits for <REQ-ID>)\n\n**Success Criteria**:\n- p95 latency < 500ms (back within SLA)\n- p50 latency < 200ms (stretch goal)\n- Root cause identified and fixed\n- No regression in other requirements\n\n**Impact**:\n- Affected Users: 5% of login attempts (p95)\n- Business Impact: Poor user experience, potential churn\n- SLA Status: VIOLATED (critical)\n```\n\n---\n\n### Step 7: Link to Traceability\n\n**Create feedback loop entry**:\n\n```yaml\n# docs/traceability/feedback-loops.yml\n\nalerts:\n  - alert_id: \"alert_12345\"\n    timestamp: \"2025-11-20T15:30:00Z\"\n    title: \"Login latency exceeded\"\n    requirement: \"<REQ-ID>\"\n    original_intent: \"INT-100\"\n    remediation_intent: \"INT-150\"  # â† New intent created\n    status: \"OPEN\"\n    assigned_to: \"Backend Team\"\n```\n\n---\n\n### Step 8: Commit Remediation Intent\n\n```bash\ngit add docs/intents/remediation.md docs/traceability/feedback-loops.yml\ngit commit -m \"FEEDBACK: Create INT-150 from production alert (<REQ-ID>)\n\nCreate remediation intent from SLA violation alert.\n\nAlert:\n- ID: alert_12345\n- Title: Login latency exceeded\n- Metric: auth.login.duration (750ms, threshold 500ms)\n- Requirement: <REQ-ID>\n\nTraceability:\n  Alert â†’ req:<REQ-ID> â†’ REQ-NFR-PERF-001 â†’ INT-100 â†’ INT-150 (new)\n\nRemediation Intent Created:\n- INT-150: Fix login performance degradation\n- Priority: P0 (SLA violation)\n- Related: <REQ-ID>, REQ-NFR-PERF-001\n\nFeedback Loop:\n  Production Issue â†’ New Intent â†’ SDLC Cycle Begins Again â™»ï¸\n\nNext: Investigate root cause, implement fix using TDD workflow\n\"\n```\n\n---\n\n## Output Format\n\n```\n[TRACE PRODUCTION ISSUE - alert_12345]\n\nAlert Details:\n  ID: alert_12345\n  Title: \"Login latency exceeded\"\n  Timestamp: 2025-11-20T15:30:00Z\n  Severity: CRITICAL\n\nRequirement Trace:\n  Alert Tag: req:<REQ-ID>\n    â†“\n  Requirement: <REQ-ID> (User Login)\n  Location: docs/requirements/authentication.md:15\n    â†“\n  Related SLA: REQ-NFR-PERF-001 (Login < 500ms)\n    â†“\n  Original Intent: INT-100 (User Authentication System)\n  Location: intent.md:5\n\nCode Trace:\n  Implementation: src/auth/login.py:23\n  Recent Commits: 3 commits in last 7 days\n    - abc123: perf: Add caching (3 days ago)\n    - def456: refactor: Simplify login (5 days ago)\n    - ghi789: fix: Handle edge case (7 days ago)\n\nRoot Cause Hypothesis:\n  1. Database query slow (check C-003: should be < 100ms)\n  2. bcrypt too slow (check C-001: cost 12 â†’ ~200ms)\n  3. Recent caching change (commit abc123)\n  4. Increased traffic/load\n\nRemediation Intent Created:\n  âœ“ INT-150: Fix login performance degradation\n    - Type: Remediation (URGENT)\n    - Priority: P0\n    - Related: <REQ-ID>, REQ-NFR-PERF-001\n    - Source: Production alert_12345\n\nFeedback Loop:\n  âœ“ Alert â†’ Requirement traced\n  âœ“ Original intent identified\n  âœ“ Remediation intent created\n  âœ“ Traceability logged\n\nNext Steps:\n  1. Assign INT-150 to backend team\n  2. Investigate root cause (profile, DB queries)\n  3. Implement fix using TDD workflow\n  4. Deploy fix and verify SLA restored\n\nâœ… Production Issue Traced!\n   Feedback loop closed\n   Remediation intent ready for SDLC\n```\n\n---\n\n## Notes\n\n**Why trace production issues?**\n- **Close feedback loop**: Production â†’ Intent â†’ SDLC\n- **Root cause**: Understand what requirement is problematic\n- **Living system**: Requirements evolve based on production reality\n- **Homeostasis**: Production deviations generate corrective intents\n\n**Feedback loop**:\n```\nIntent (INT-100)\n  â†’ Requirements (<REQ-ID>)\n  â†’ Design â†’ Code â†’ Deploy\n  â†’ Production (running)\n  â†’ Alert (SLA violation)\n  â†’ Trace back to <REQ-ID>\n  â†’ Create new Intent (INT-150: Fix performance)\n  â†’ SDLC cycle begins again â™»ï¸\n```\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  all_alerts_traceable_to_req: true\n  all_violations_create_intent: true\n  feedback_loop: closed\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/testing/create-coverage-report/SKILL.md": "---\nname: create-coverage-report\ndescription: Generate comprehensive coverage report with requirement traceability mapping. Shows coverage per REQ-*, gaps, trends, and recommendations. Use for status dashboards, quality reviews, or compliance audits.\nallowed-tools: [Read, Write, Bash, Grep, Glob]\n---\n\n# create-coverage-report\n\n**Skill Type**: Reporter\n**Purpose**: Generate comprehensive coverage report with REQ-* mapping\n**Prerequisites**: Tests have run, coverage data available\n\n---\n\n## Agent Instructions\n\nYou are generating a **comprehensive coverage report** with requirement traceability.\n\n**Report includes**:\n1. Overall coverage statistics\n2. Coverage per requirement (REQ-*)\n3. Coverage gaps and recommendations\n4. Coverage trends (if historical data)\n5. Quality gate status\n\n---\n\n## Report Structure\n\n### Section 1: Executive Summary\n\n```markdown\n# Test Coverage Report\n\n**Generated**: 2025-11-20 15:30:00\n**Project**: Customer Portal\n**Branch**: main\n**Commit**: abc123\n\n## Executive Summary\n\n**Overall Coverage**: 87.5% âœ… (Target: 80%)\n**Requirements Tested**: 36/42 (85.7%)\n**Critical Path Coverage**: 95.2% âš ï¸ (Target: 100%)\n\n**Status**: âš ï¸ MINOR GAPS (3 requirements below threshold)\n\n**Quality Gate**: âœ… PASS (overall > 80%)\n```\n\n---\n\n### Section 2: Coverage by Requirement\n\n```markdown\n## Coverage by Requirement\n\n| REQ-* | Description | Files | Coverage | Tests | Status |\n|-------|-------------|-------|----------|-------|--------|\n| <REQ-ID> | User login | 2 files | 97.6% | 12 | âœ… |\n| <REQ-ID> | Password reset | 1 file | 100% | 8 | âœ… |\n| <REQ-ID> | Payment processing | 3 files | 72.1% | 6 | âš ï¸ |\n| REQ-F-CART-001 | Shopping cart | 1 file | 45.8% | 2 | âŒ |\n| REQ-NFR-PERF-001 | Response time | 2 files | 100% | 5 | âœ… |\n| ... | ... | ... | ... | ... | ... |\n\n**Legend**:\n- âœ… Green: Coverage >= 80%\n- âš ï¸ Yellow: Coverage 50-79%\n- âŒ Red: Coverage < 50%\n```\n\n---\n\n### Section 3: Coverage Gaps\n\n```markdown\n## Coverage Gaps\n\n### Requirements Below 80% (3)\n\n**<REQ-ID>**: Payment processing (72.1%)\n- Files: src/payments/payment.py\n- Uncovered: 28 lines (error handling, edge cases)\n- Missing Tests:\n  - Edge case: amount = 0\n  - Error case: invalid card token\n  - Boundary: amount at limits\n- **Recommendation**: Invoke 'generate-missing-tests' skill\n\n**REQ-F-CART-001**: Shopping cart (45.8%)\n- Files: src/cart/cart.py\n- Uncovered: 87 lines (most logic untested)\n- Missing Tests: Most functionality\n- **Recommendation**: Write comprehensive test suite using TDD\n\n**REQ-F-NOTIF-001**: Email notifications (0%)\n- Files: None (not implemented)\n- **Recommendation**: Implement requirement using TDD workflow\n\n### Requirements Without Tests (6)\n\n1. REQ-F-PROFILE-001 (code exists, no tests)\n2. REQ-F-PROFILE-002 (code exists, no tests)\n3. REQ-F-EXPORT-001 (no code, no tests)\n... (3 more)\n```\n\n---\n\n### Section 4: Coverage by File\n\n```markdown\n## Coverage by File\n\n| File | Lines | Covered | Coverage | Requirements |\n|------|-------|---------|----------|--------------|\n| src/auth/login.py | 87 | 85 | 97.7% | <REQ-ID> |\n| src/payments/payment.py | 142 | 102 | 71.8% | <REQ-ID> |\n| src/cart/cart.py | 98 | 45 | 45.9% | REQ-F-CART-001 |\n| src/auth/validators.py | 65 | 65 | 100% | BR-001, BR-002 |\n\n**Files Below 80%**:\n- src/payments/payment.py (71.8%)\n- src/cart/cart.py (45.9%)\n```\n\n---\n\n### Section 5: Test Statistics\n\n```markdown\n## Test Statistics\n\n**Unit Tests**:\n- Total: 156 tests\n- Passing: 156 (100%)\n- Duration: 0.8s\n- Coverage Contribution: 75%\n\n**Integration Tests**:\n- BDD Scenarios: 12 scenarios, 67 steps\n- API Tests: 24 tests\n- Database Tests: 15 tests\n- E2E Tests: 6 tests\n- Total: 57 tests\n- Passing: 57 (100%)\n- Duration: 59.6s\n- Coverage Contribution: 12.5%\n\n**Total Tests**: 213 tests (156 unit + 57 integration)\n**Pass Rate**: 100%\n**Total Duration**: 60.4s\n```\n\n---\n\n### Section 6: Coverage Trends\n\n```markdown\n## Coverage Trends (Last 7 Days)\n\n| Date | Coverage | Change | Requirements | Tests |\n|------|----------|--------|--------------|-------|\n| 2025-11-20 | 87.5% | +2.3% â†‘ | 42 | 213 |\n| 2025-11-19 | 85.2% | +1.1% â†‘ | 42 | 198 |\n| 2025-11-18 | 84.1% | -0.5% â†“ | 40 | 187 |\n| 2025-11-17 | 84.6% | +3.2% â†‘ | 38 | 175 |\n\n**Trend**: âœ… Improving (87.5% â†’ 85.2% â†’ 84.1%)\n**New Requirements**: +2 this week\n**New Tests**: +38 this week\n```\n\n---\n\n### Section 7: Recommendations\n\n```markdown\n## Recommendations\n\n### High Priority\n\n1. **Fix REQ-F-CART-001 Coverage** (45.8% â†’ 80%)\n   - Action: Generate missing tests\n   - Command: Invoke 'generate-missing-tests' for REQ-F-CART-001\n   - Estimated: +34.2% coverage, ~15 tests\n\n2. **Improve <REQ-ID> Coverage** (72.1% â†’ 80%)\n   - Action: Add edge case tests\n   - Missing: Zero amount, negative amount, max limit\n   - Estimated: +7.9% coverage, ~5 tests\n\n3. **Implement REQ-F-NOTIF-001**\n   - Action: Use TDD workflow\n   - Status: Not started (0% coverage)\n\n### Medium Priority\n\n4. **Add Integration Tests for REQ-NFR-PERF-001**\n   - Action: Write performance integration tests\n   - Missing: Load tests, response time validation\n\n5. **Improve Critical Path Coverage** (95.2% â†’ 100%)\n   - Action: Test remaining P0 edge cases\n   - Gap: 4.8%\n```\n\n---\n\n## Output Formats\n\n### Console Output (Quick Summary)\n\n```\n[COVERAGE REPORT]\n\nOverall: 87.5% âœ… (350/400 lines)\n\nBy Requirement:\n  âœ… 33 requirements >= 80%\n  âš ï¸ 3 requirements 50-79%\n  âŒ 0 requirements < 50%\n  ğŸ“ 6 requirements not implemented\n\nQuality Gate: âœ… PASS (87.5% > 80%)\n\nTop Gaps:\n  1. REQ-F-CART-001: 45.8% (needs 15 tests)\n  2. <REQ-ID>: 72.1% (needs 5 tests)\n  3. REQ-F-PROFILE-001: 0% (not implemented)\n\nRecommendation: Fix 3 gaps to reach 95%+ coverage\n```\n\n---\n\n### HTML Report (Full Detail)\n\n**Generate HTML file**:\n\n```bash\n# Python\npytest --cov=src --cov-report=html\n# Creates: htmlcov/index.html\n\n# JavaScript\nnpm test -- --coverage --coverageReporters=html\n# Creates: coverage/index.html\n```\n\n**Enhanced with REQ-* mapping**:\n- Each file shows which REQ-* it implements\n- Click REQ-* to see all files/tests for that requirement\n- Coverage heatmap by requirement priority\n\n---\n\n### JSON Report (Machine Readable)\n\n```json\n{\n  \"generated\": \"2025-11-20T15:30:00Z\",\n  \"overall_coverage\": 87.5,\n  \"requirements\": [\n    {\n      \"req_key\": \"<REQ-ID>\",\n      \"description\": \"User login\",\n      \"files\": [\"src/auth/login.py\", \"src/auth/validators.py\"],\n      \"coverage\": 97.6,\n      \"tests\": 12,\n      \"status\": \"pass\"\n    },\n    {\n      \"req_key\": \"<REQ-ID>\",\n      \"description\": \"Payment processing\",\n      \"files\": [\"src/payments/payment.py\"],\n      \"coverage\": 72.1,\n      \"tests\": 6,\n      \"status\": \"warning\",\n      \"gap\": 7.9,\n      \"recommended_tests\": 5\n    }\n  ],\n  \"quality_gate\": \"pass\"\n}\n```\n\n---\n\n## Prerequisites Check\n\nBefore invoking:\n1. Tests have been run (coverage data exists)\n2. Coverage tool available (pytest-cov, jest, jacoco)\n\n---\n\n## Configuration\n\n```yaml\nplugins:\n  - name: \"@aisdlc/testing-skills\"\n    config:\n      reporting:\n        format: \"html\"                    # html | json | markdown\n        include_req_mapping: true         # Map coverage to REQ-*\n        include_gap_analysis: true        # Show what's missing\n        include_trends: true              # Show historical trends\n        output_path: \"coverage-reports/\"\n```\n\n---\n\n## Notes\n\n**Why coverage reports?**\n- **Visibility**: See coverage at a glance\n- **Requirement focus**: Coverage per REQ-* (not just per file)\n- **Compliance**: Auditors need proof of testing\n- **Trends**: Track coverage over time\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  coverage_report_available: true\n  coverage_per_requirement_visible: true\n  gaps_identified: true\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/testing/create-test-specification/SKILL.md": "# Skill: Create Test Case Specification (TCS)\n\n**Stage**: 5 - System Test\n**Purpose**: Generate TCS documents with full requirement traceability\n\n<!-- Implements: REQ-NFR-TRACE-001 (Requirement Traceability) -->\n<!-- Implements: REQ-NFR-QUALITY-001 (Code Quality Standards) -->\n\n---\n\n## When to Use\n\nUse this skill when:\n- Starting System Test stage for a component\n- Adding tests for new functionality\n- Validating requirement coverage\n\n---\n\n## TCS Pattern\n\nTest Case Specifications follow the same traceability pattern as ADRs:\n\n```\nRequirements (REQ-*)\n    â†“\nDesign (ADRs)\n    â†“\nImplementation\n    â†“\nTest Cases (TCS-*) â† This skill creates these\n    â†“\nTest Implementation (pytest, etc.)\n```\n\n---\n\n## TCS Document Structure\n\nCreate TCS documents at: `docs/design/<solution>/tests/TCS-XXX-<slug>.md`\n\n```markdown\n# TCS-XXX: {Component/Feature Name}\n\n**Status**: Specified | Implemented | Deprecated\n**Date**: YYYY-MM-DD\n**Requirements**: REQ-F-*, REQ-NFR-*\n**ADR Reference**: ADR-XXX (if applicable)\n**Implementation**: Path to implementation file\n\n---\n\n## Purpose\nWhat this test case validates.\n\n---\n\n## Preconditions\nRequired state before test execution.\n\n---\n\n## Test Scenarios\n\n| ID | Scenario | Input State | Expected Output | Priority |\n|----|----------|-------------|-----------------|----------|\n| XXX-001 | ... | ... | ... | High/Medium/Low |\n| XXX-002 | ... | ... | ... | ... |\n\n---\n\n## Validation Criteria\n- [ ] Criterion 1\n- [ ] Criterion 2\n- [ ] Criterion 3\n\n---\n\n## Test Implementation\n\n**File**: `path/to/test_file.py`\n**Class**: `TestClassName`\n**Tests**: N\n\n```python\nclass TestClassName:\n    def test_scenario_001(self):\n        \"\"\"XXX-001: Scenario description.\"\"\"\n        ...\n```\n\n---\n\n## Requirement Traceability\n\n| Requirement | How Validated |\n|-------------|---------------|\n| REQ-F-XXX-001 | Test scenario XXX-001 |\n| REQ-NFR-XXX-001 | Test scenario XXX-002 |\n\n---\n\n## Notes\nAdditional context or considerations.\n```\n\n---\n\n## Step-by-Step Process\n\n### 1. Identify Requirements to Test\n\n```bash\n# List requirements for the component\ngrep -r \"REQ-\" docs/requirements/ | grep \"<component>\"\n```\n\n### 2. Create TCS Document\n\n```bash\n# Determine next TCS number\nls docs/design/<solution>/tests/TCS-*.md | tail -1\n\n# Create TCS file\nTCS_NUM=\"010\"  # Next available\ntouch docs/design/<solution>/tests/TCS-${TCS_NUM}-<component>.md\n```\n\n### 3. Define Test Scenarios\n\nFor each requirement:\n- Create at least one test scenario\n- Include positive and negative cases\n- Define clear input/output\n- Assign priority (High for core functionality)\n\n### 4. Create Test Registry Entry\n\nAdd to `docs/design/<solution>/tests/README.md`:\n\n```markdown\n| [TCS-XXX](TCS-XXX-<slug>.md) | Component Name | REQ-F-*, REQ-NFR-* | Status |\n```\n\n### 5. Implement Tests\n\nCreate test file referencing TCS scenarios:\n\n```python\n# Validates: TCS-XXX\n\nclass TestComponent:\n    def test_scenario_xxx_001(self):\n        \"\"\"XXX-001: <scenario description>\"\"\"\n        # Test implementation\n```\n\n---\n\n## TCS Naming Convention\n\n| Pattern | Example | Use For |\n|---------|---------|---------|\n| TCS-0XX-command-* | TCS-001-command-status | Slash commands |\n| TCS-0XX-hook-* | TCS-008-hooks-lifecycle | Lifecycle hooks |\n| TCS-0XX-installer-* | TCS-009-installer-setup | Installers |\n| TCS-0XX-skill-* | TCS-010-skill-tcs | Skills |\n| TCS-0XX-agent-* | TCS-011-agent-system-test | Agents |\n\n---\n\n## Traceability Validation\n\nAfter creating TCS, validate:\n\n```bash\n# Check all requirements have test coverage\ngrep -h \"REQ-\" docs/requirements/*.md | sort -u > /tmp/all_reqs.txt\ngrep -rh \"REQ-\" docs/design/*/tests/TCS-*.md | sort -u > /tmp/tested_reqs.txt\ndiff /tmp/all_reqs.txt /tmp/tested_reqs.txt\n```\n\n---\n\n## Example: Command TCS\n\n```markdown\n# TCS-001: /aisdlc-status Command\n\n**Status**: âœ… Implemented\n**Date**: 2025-11-27\n**Requirements**: REQ-F-CMD-001, REQ-F-TODO-003\n**ADR Reference**: ADR-002\n**Implementation**: claude-code/plugins/aisdlc-methodology/commands/aisdlc-status.md\n\n---\n\n## Purpose\nValidate that /aisdlc-status displays correct task queue status.\n\n---\n\n## Test Scenarios\n\n| ID | Scenario | Input State | Expected Output | Priority |\n|----|----------|-------------|-----------------|----------|\n| ST-001 | Empty workspace | No tasks | \"0 Active Tasks\" | High |\n| ST-002 | With tasks | 2 tasks | Lists both tasks | High |\n\n---\n\n## Validation Criteria\n- [ ] Output contains \"AI SDLC Task Status\" header\n- [ ] Active task count matches file\n\n---\n\n## Test Implementation\n\n**File**: `claude-code/tests/commands/test_commands.py`\n**Class**: `TestStatusCommand`\n**Tests**: 4\n\n---\n\n## Requirement Traceability\n\n| Requirement | How Validated |\n|-------------|---------------|\n| REQ-F-CMD-001 | Command executes |\n| REQ-F-TODO-003 | TODO list displayed |\n```\n\n---\n\n## Integration with System Test Agent\n\nThe System Test Agent should:\n\n1. **Before writing tests**: Create TCS document\n2. **During test creation**: Reference TCS scenario IDs\n3. **After tests pass**: Update TCS status to \"Implemented\"\n4. **On failure**: Update TCS with failure notes\n\n---\n\n## Quality Gates\n\n- [ ] TCS document exists before test implementation\n- [ ] All requirements have TCS coverage\n- [ ] Test code references TCS scenario IDs\n- [ ] TCS README updated with new entry\n- [ ] Traceability validation passes\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/testing/generate-missing-tests/SKILL.md": "---\nname: generate-missing-tests\ndescription: Homeostatic actuator auto-generating missing tests for requirements with low coverage. Creates unit tests, edge cases, and error cases for REQ-* without sufficient test coverage. Use when validate-test-coverage detects gaps.\nallowed-tools: [Read, Write, Edit, Bash, Grep, Glob]\n---\n\n# generate-missing-tests\n\n**Skill Type**: Actuator (Homeostasis)\n**Purpose**: Auto-generate missing tests to achieve coverage goals\n**Prerequisites**: Requirements exist, code exists, coverage gaps detected\n\n---\n\n## Agent Instructions\n\nYou are an **Actuator** correcting test coverage deviations.\n\n**Desired State**: `coverage >= 80%` for all requirements\n\nYour goal is to **generate missing tests** to close coverage gaps.\n\n---\n\n## Workflow\n\n### Step 1: Receive Coverage Gaps\n\n**Input from sensor** (`validate-test-coverage`):\n\n```yaml\ncoverage_gaps:\n  - req: <REQ-ID>\n    code: src/payments/payment.py\n    current_coverage: 72.1%\n    target_coverage: 80%\n    uncovered_lines: [45, 67-72, 89]\n    missing_tests:\n      - Edge case: amount = 0\n      - Error case: invalid card token\n      - Boundary: amount = max_limit\n\n  - req: REQ-F-CART-001\n    code: src/cart/cart.py\n    current_coverage: 0%\n    target_coverage: 80%\n    missing_tests: ALL\n```\n\n---\n\n### Step 2: Analyze Uncovered Code\n\n**For each gap, determine what tests are needed**:\n\n```python\n# Uncovered code in src/payments/payment.py:45\ndef process_payment(amount: float, card_token: str) -> PaymentResult:\n    if amount <= 0:  # Line 45 - UNCOVERED\n        return PaymentResult(success=False, error=\"Invalid amount\")\n\n    # ... rest of implementation\n\n# Missing test:\ndef test_payment_fails_with_zero_amount():\n    # Validates: <REQ-ID> (edge case)\n    result = process_payment(0.0, \"tok_visa\")\n    assert result.success == False\n    assert result.error == \"Invalid amount\"\n```\n\n---\n\n### Step 3: Generate Test Cases\n\n**Test generation patterns**:\n\n**Pattern 1: Happy Path** (if missing):\n```python\n# Validates: <REQ-ID>\ndef test_process_payment_success():\n    \"\"\"Test successful payment processing\"\"\"\n    result = process_payment(100.00, \"tok_visa\")\n    assert result.success == True\n    assert result.charge_id is not None\n```\n\n**Pattern 2: Edge Cases**:\n```python\n# Validates: <REQ-ID> (edge case: zero amount)\ndef test_payment_with_zero_amount():\n    result = process_payment(0.0, \"tok_visa\")\n    assert result.success == False\n\n# Validates: <REQ-ID> (edge case: max amount)\ndef test_payment_at_max_limit():\n    result = process_payment(10000.00, \"tok_visa\")\n    assert result.success == True\n```\n\n**Pattern 3: Error Cases**:\n```python\n# Validates: <REQ-ID> (error: invalid token)\ndef test_payment_with_invalid_token():\n    result = process_payment(100.00, \"invalid_token\")\n    assert result.success == False\n    assert \"invalid\" in result.error.lower()\n```\n\n**Pattern 4: Boundary Tests**:\n```python\n# Validates: <REQ-ID>, BR-005 (boundary: min amount)\ndef test_payment_below_minimum():\n    result = process_payment(0.005, \"tok_visa\")  # Below $0.01 minimum\n    assert result.success == False\n\ndef test_payment_at_minimum():\n    result = process_payment(0.01, \"tok_visa\")  # Exactly at $0.01\n    assert result.success == True\n```\n\n---\n\n### Step 4: Write Test File\n\n**Create or update test file**:\n\n```python\n# tests/payments/test_payment.py\n# Generated tests for <REQ-ID>\n\n# Validates: <REQ-ID>\n# Business Rules: BR-001, BR-002, BR-003, BR-004, BR-005\n# Generated: 2025-11-20 by generate-missing-tests skill\n\nimport pytest\nfrom src.payments.payment import process_payment, PaymentResult\n\n\nclass TestPaymentProcessing:\n    \"\"\"Tests for <REQ-ID>: Payment processing\"\"\"\n\n    def test_process_payment_success(self):\n        \"\"\"Test successful payment (happy path)\"\"\"\n        # Validates: <REQ-ID>\n        result = process_payment(100.00, \"tok_visa\")\n        assert result.success == True\n        assert result.charge_id is not None\n\n    def test_payment_with_zero_amount(self):\n        \"\"\"Test payment fails with zero amount\"\"\"\n        # Validates: <REQ-ID> (edge case)\n        # Generated to cover line 45\n        result = process_payment(0.0, \"tok_visa\")\n        assert result.success == False\n        assert result.error == \"Invalid amount\"\n\n    def test_payment_with_negative_amount(self):\n        \"\"\"Test payment fails with negative amount\"\"\"\n        # Validates: <REQ-ID> (edge case)\n        result = process_payment(-50.00, \"tok_visa\")\n        assert result.success == False\n\n    def test_payment_with_invalid_token(self):\n        \"\"\"Test payment fails with invalid card token\"\"\"\n        # Validates: <REQ-ID> (error case)\n        # Generated to cover lines 67-72\n        result = process_payment(100.00, \"invalid_token\")\n        assert result.success == False\n\n    def test_payment_below_minimum_amount(self):\n        \"\"\"Test payment below $0.01 minimum\"\"\"\n        # Validates: BR-005 (boundary test)\n        result = process_payment(0.005, \"tok_visa\")\n        assert result.success == False\n\n    def test_payment_at_minimum_amount(self):\n        \"\"\"Test payment exactly at $0.01\"\"\"\n        # Validates: BR-005 (boundary test)\n        result = process_payment(0.01, \"tok_visa\")\n        assert result.success == True\n\n    def test_payment_at_maximum_amount(self):\n        \"\"\"Test payment at $10,000 limit\"\"\"\n        # Validates: BR-005 (boundary test)\n        result = process_payment(10000.00, \"tok_visa\")\n        assert result.success == True\n\n    def test_payment_above_maximum_amount(self):\n        \"\"\"Test payment above $10,000 limit\"\"\"\n        # Validates: BR-005 (boundary test)\n        # Generated to cover line 89\n        result = process_payment(10001.00, \"tok_visa\")\n        assert result.success == False\n```\n\n**Generated**: 8 tests to cover all uncovered lines and business rules\n\n---\n\n### Step 5: Run Generated Tests\n\n**Verify generated tests pass**:\n\n```bash\npytest tests/payments/test_payment.py -v\n```\n\n**Expected**: All generated tests PASS âœ…\n\n**If tests fail**: Fix implementation (test found a bug!)\n\n---\n\n### Step 6: Re-Check Coverage\n\n**Run coverage again**:\n\n```bash\npytest --cov=src/payments/payment.py tests/payments/test_payment.py\n```\n\n**Results**:\n```\nBefore: 72.1% coverage (28 uncovered lines)\nAfter: 95.3% coverage (2 uncovered lines - error handling)\n\nImprovement: +23.2% coverage\nRemaining gaps: 2 lines (acceptable or generate more tests)\n```\n\n---\n\n### Step 7: Commit Generated Tests\n\n```bash\ngit add tests/payments/test_payment.py\ngit commit -m \"GEN: Generate missing tests for <REQ-ID>\n\nAuto-generate tests to improve coverage from 72.1% to 95.3%.\n\nTests Generated (8):\n- Happy path: test_process_payment_success\n- Edge cases: zero amount, negative amount\n- Error cases: invalid token\n- Boundary tests: min/max amounts (4 tests)\n\nCoverage Improvement:\n- Before: 72.1% (28 uncovered lines)\n- After: 95.3% (2 uncovered lines)\n- Improvement: +23.2%\n\nGenerated by: generate-missing-tests skill\nTriggered by: validate-test-coverage sensor (detected gap)\nValidates: <REQ-ID>, BR-005\nTests: 8 tests, all passing âœ“\n\"\n```\n\n---\n\n## Output Format\n\n```\n[GENERATE MISSING TESTS - <REQ-ID>]\n\nCoverage Gap Detected:\n  Current: 72.1%\n  Target: 80%\n  Gap: -7.9%\n\nUncovered Lines: 28 lines\n  - Lines 45: Zero amount check\n  - Lines 67-72: Invalid token handling\n  - Line 89: Amount above maximum\n\nTest Generation Strategy:\n  âœ“ Happy path (1 test)\n  âœ“ Edge cases (2 tests: zero, negative)\n  âœ“ Error cases (1 test: invalid token)\n  âœ“ Boundary tests (4 tests: min/max boundaries)\n\nGenerated Tests (8):\n  âœ“ test_process_payment_success (happy path)\n  âœ“ test_payment_with_zero_amount (edge case)\n  âœ“ test_payment_with_negative_amount (edge case)\n  âœ“ test_payment_with_invalid_token (error case)\n  âœ“ test_payment_below_minimum_amount (boundary)\n  âœ“ test_payment_at_minimum_amount (boundary)\n  âœ“ test_payment_at_maximum_amount (boundary)\n  âœ“ test_payment_above_maximum_amount (boundary)\n\nRunning generated tests...\n  âœ“ All 8 tests PASSING\n\nCoverage Re-Check:\n  Before: 72.1%\n  After: 95.3%\n  Improvement: +23.2% âœ…\n\nRemaining Uncovered: 2 lines (error handling - acceptable)\n\nCommit: GEN: Generate missing tests for <REQ-ID>\n\nâœ… Test Generation Complete!\n   Coverage goal achieved (95.3% > 80%)\n   Homeostasis achieved âœ“\n```\n\n---\n\n## Prerequisites Check\n\nBefore invoking:\n1. Coverage gaps identified (from validate-test-coverage)\n2. Code to test exists\n3. Requirement details available (REQ-*, BR-*)\n\n---\n\n## Test Generation Strategies\n\n### Strategy 1: From Business Rules\n\n**Use BR-* to generate tests**:\n```\nBR-005: Amount between $0.01 and $10,000\n  â†’ Generate:\n    - test_amount_below_min (0.005)\n    - test_amount_at_min (0.01)\n    - test_amount_valid (100.00)\n    - test_amount_at_max (10000.00)\n    - test_amount_above_max (10001.00)\n```\n\n### Strategy 2: From Uncovered Lines\n\n**Analyze uncovered code paths**:\n```python\nif amount <= 0:  # UNCOVERED\n    return error()\n\nâ†’ Generate: test with amount = 0, amount = -1\n```\n\n### Strategy 3: From Code Structure\n\n**Identify test patterns from code**:\n- If/else branches â†’ Test both paths\n- Try/except â†’ Test exception path\n- Loops â†’ Test empty, single, multiple\n- Return values â†’ Test all possible returns\n\n---\n\n## Notes\n\n**Why auto-generate tests?**\n- **Closes coverage gaps** automatically\n- **Saves developer time** (no manual test writing)\n- **Consistent quality** (all tests follow same pattern)\n- **Homeostasis** (system self-corrects to desired coverage)\n\n**Generated tests are starting point**:\n- Review and improve generated tests\n- Add domain-specific assertions\n- Refine test data for realism\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  coverage: >= 80%\n  all_requirements_tested: true\n  critical_paths: 100%\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/testing/run-integration-tests/SKILL.md": "---\nname: run-integration-tests\ndescription: Run integration tests validating cross-component requirements and system behavior. Executes BDD scenarios, API tests, and end-to-end tests. Use to validate integrated system or as pre-deployment quality gate.\nallowed-tools: [Read, Bash, Grep, Glob]\n---\n\n# run-integration-tests\n\n**Skill Type**: Test Runner\n**Purpose**: Execute integration tests validating system behavior\n**Prerequisites**: Integration tests exist (BDD scenarios, API tests, E2E tests)\n\n---\n\n## Agent Instructions\n\nYou are running **integration tests** to validate the integrated system.\n\n**Integration tests validate**:\n- Cross-component interactions\n- End-to-end user flows\n- API contracts\n- Database integration\n- External service integration\n- BDD scenarios (Given/When/Then)\n\n---\n\n## Workflow\n\n### Step 1: Discover Integration Tests\n\n**Find all integration test files**:\n\n```bash\n# BDD scenarios\nfind features -name \"*.feature\"\n\n# Integration test directories\nfind tests/integration -name \"test_*.py\"\nfind tests/e2e -name \"test_*.py\"\nfind tests/api -name \"test_*.py\"\n```\n\n---\n\n### Step 2: Run BDD Scenarios\n\n**Execute Gherkin scenarios**:\n\n```bash\n# Behave (Python)\nbehave features/ --format progress\n\n# Cucumber (JavaScript)\nnpm run cucumber\n\n# Cucumber (Java)\nmvn test -Dcucumber.options=\"features/\"\n```\n\n**Output**:\n```\nFeature: User Authentication\n  Scenario: Successful login                    PASSED\n  Scenario: Login fails with invalid email      PASSED\n  Scenario: Account locks after 3 failures      PASSED\n\nFeature: Payment Processing\n  Scenario: Successful card payment             PASSED\n  Scenario: Payment fails invalid card          PASSED\n\n5 scenarios (5 passed)\n27 steps (27 passed)\nDuration: 2.3s\n```\n\n---\n\n### Step 3: Run API Integration Tests\n\n**Execute API test suite**:\n\n```bash\n# Python (pytest with requests)\npytest tests/integration/api/ -v\n\n# JavaScript (supertest)\nnpm test tests/integration/api\n\n# Java (RestAssured)\nmvn test -Dtest=ApiIntegrationTest\n```\n\n**Example tests**:\n```python\n# tests/integration/api/test_auth_api.py\n# Validates: <REQ-ID> (API integration)\n\ndef test_login_api_returns_token():\n    response = requests.post(\n        \"http://localhost:8000/api/auth/login\",\n        json={\"email\": \"user@example.com\", \"password\": \"SecurePass123!\"}\n    )\n    assert response.status_code == 200\n    assert \"token\" in response.json()\n\ndef test_login_api_rejects_invalid_email():\n    response = requests.post(\n        \"http://localhost:8000/api/auth/login\",\n        json={\"email\": \"invalid\", \"password\": \"SecurePass123!\"}\n    )\n    assert response.status_code == 400\n    assert response.json()[\"error\"] == \"Invalid email format\"\n```\n\n---\n\n### Step 4: Run Database Integration Tests\n\n**Execute tests with real database**:\n\n```python\n# tests/integration/database/test_user_db.py\n# Validates: <REQ-ID> (database integration)\n\ndef test_user_registration_persists_to_database(db_session):\n    \"\"\"Test user registration saves to database\"\"\"\n    user = register(\"new@example.com\", \"SecurePass123!\")\n\n    # Verify user in database\n    db_user = db_session.query(User).filter_by(email=\"new@example.com\").first()\n    assert db_user is not None\n    assert db_user.email == \"new@example.com\"\n```\n\n---\n\n### Step 5: Run End-to-End Tests\n\n**Execute full user journeys**:\n\n```python\n# tests/e2e/test_user_flow.py\n# Validates: INT-100 (complete user authentication flow)\n\ndef test_complete_registration_and_login_flow(browser):\n    \"\"\"Test complete user journey: register â†’ login â†’ access protected page\"\"\"\n\n    # Register\n    browser.visit(\"/register\")\n    browser.fill(\"email\", \"newuser@example.com\")\n    browser.fill(\"password\", \"SecurePass123!\")\n    browser.click(\"Register\")\n    assert browser.is_text_present(\"Registration successful\")\n\n    # Login\n    browser.visit(\"/login\")\n    browser.fill(\"email\", \"newuser@example.com\")\n    browser.fill(\"password\", \"SecurePass123!\")\n    browser.click(\"Login\")\n    assert browser.is_text_present(\"Welcome\")\n\n    # Access protected page\n    browser.visit(\"/dashboard\")\n    assert browser.is_text_present(\"Dashboard\")  # Not redirected to login\n```\n\n---\n\n### Step 6: Aggregate Results\n\n**Collect all test results**:\n\n```\nIntegration Test Summary:\n\nBDD Scenarios:\n  âœ“ 12 scenarios, all passing\n  âœ“ 67 steps, all passing\n  âœ“ Duration: 5.2s\n\nAPI Integration Tests:\n  âœ“ 24 tests passing\n  âœ“ Duration: 3.8s\n\nDatabase Integration Tests:\n  âœ“ 15 tests passing\n  âœ“ Duration: 8.1s\n\nEnd-to-End Tests:\n  âœ“ 6 tests passing\n  âœ“ Duration: 42.5s\n\nTotal: 57 integration tests\nPass Rate: 100%\nTotal Duration: 59.6s\n```\n\n---\n\n### Step 7: Map Tests to Requirements\n\n**Show which requirements validated**:\n\n```\nRequirements Validated by Integration Tests:\n\n<REQ-ID> (User login):\n  âœ“ BDD: features/authentication.feature (3 scenarios)\n  âœ“ API: tests/integration/api/test_auth_api.py (5 tests)\n  âœ“ E2E: tests/e2e/test_user_flow.py (1 test)\n  Total: 9 integration tests âœ…\n\n<REQ-ID> (Payment processing):\n  âœ“ BDD: features/payments.feature (2 scenarios)\n  âœ“ API: tests/integration/api/test_payment_api.py (8 tests)\n  Total: 10 integration tests âœ…\n\nREQ-NFR-PERF-001 (Performance):\n  âœ— No integration tests âŒ\n  Recommendation: Add performance tests\n\nCoverage: 90% of requirements have integration tests\n```\n\n---\n\n## Output Format\n\n```\n[RUN INTEGRATION TESTS]\n\nTest Suites Executed:\n\nâœ… BDD Scenarios (features/):\n   12 scenarios (12 passed)\n   67 steps (67 passed)\n   Duration: 5.2s\n\nâœ… API Integration (tests/integration/api/):\n   24 tests (24 passed)\n   Duration: 3.8s\n\nâœ… Database Integration (tests/integration/database/):\n   15 tests (15 passed)\n   Duration: 8.1s\n\nâœ… End-to-End (tests/e2e/):\n   6 tests (6 passed)\n   Duration: 42.5s\n\nTotal Integration Tests: 57\nPass Rate: 100% (57/57) âœ…\nTotal Duration: 59.6s\n\nRequirements Coverage (Integration Tests):\n  âœ… <REQ-ID>: 9 tests\n  âœ… <REQ-ID>: 7 tests\n  âœ… <REQ-ID>: 10 tests\n  âš ï¸ REQ-NFR-PERF-001: 0 tests (missing)\n\nIntegration Test Coverage: 90% (27/30 requirements)\n\nHomeostasis Status: âš ï¸ MINOR DEVIATION\n  - 3 requirements without integration tests\n  - Recommend: Add integration tests for REQ-NFR-PERF-001, etc.\n\nâœ… Integration Tests Complete!\n   All tests passing\n   Minor gaps identified\n```\n\n---\n\n## Prerequisites Check\n\nBefore invoking:\n1. Integration test files exist\n2. Test dependencies installed (behave, requests, selenium, etc.)\n3. Test environment available (database, services running)\n\n---\n\n## Configuration\n\n```yaml\nplugins:\n  - name: \"@aisdlc/testing-skills\"\n    config:\n      integration_tests:\n        auto_run_on_commit: false\n        timeout_seconds: 300\n        parallel_execution: true\n        frameworks:\n          bdd: \"behave\"\n          api: \"pytest\"\n          e2e: \"selenium\"\n        require_for_deploy: true\n```\n\n---\n\n## Notes\n\n**Why integration tests?**\n- **Validate system behavior** (not just unit behavior)\n- **Catch integration bugs** (component A + B works, but A+B+C fails)\n- **Validate user flows** (BDD scenarios)\n- **Pre-deployment quality gate**\n\n**Integration vs Unit Tests**:\n```\nUnit Tests: Test individual functions/classes\n  - Fast (milliseconds)\n  - Many tests (hundreds)\n  - Run frequently (every save)\n\nIntegration Tests: Test components together\n  - Slower (seconds/minutes)\n  - Fewer tests (dozens)\n  - Run on commits/deployments\n```\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  all_integration_tests_passing: true\n  all_requirements_have_integration_tests: true\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/skills/testing/validate-test-coverage/SKILL.md": "---\nname: validate-test-coverage\ndescription: Homeostatic sensor validating test coverage percentage and detecting requirements without tests. Calculates coverage per requirement (REQ-*) and overall. Use as quality gate or continuous coverage monitoring.\nallowed-tools: [Read, Grep, Glob, Bash]\n---\n\n# validate-test-coverage\n\n**Skill Type**: Sensor (Homeostasis)\n**Purpose**: Validate test coverage and detect gaps\n**Prerequisites**: Code and tests exist\n\n---\n\n## Agent Instructions\n\nYou are a **Sensor** in the homeostasis system validating test coverage.\n\n**Desired State**: `coverage >= 80%` overall, `100%` for critical paths\n\nYour goal is to:\n1. Calculate test coverage percentage\n2. Identify requirements without tests\n3. Detect code without test coverage\n4. Signal deviations if coverage < threshold\n\n---\n\n## Workflow\n\n### Step 1: Run Coverage Tool\n\n**Execute coverage measurement**:\n\n```bash\n# Python (pytest-cov)\npytest --cov=src --cov-report=term-missing --cov-report=json\n\n# JavaScript (Jest)\nnpm test -- --coverage --coverageReporters=json\n\n# Java (JaCoCo)\nmvn test jacoco:report\n```\n\n**Parse coverage data**:\n```json\n{\n  \"totals\": {\n    \"percent_covered\": 87.5,\n    \"covered_lines\": 350,\n    \"total_lines\": 400\n  },\n  \"files\": {\n    \"src/auth.py\": {\"percent_covered\": 95.2},\n    \"src/payments.py\": {\"percent_covered\": 72.1}\n  }\n}\n```\n\n---\n\n### Step 2: Calculate Per-Requirement Coverage\n\n**For each REQ-*, find associated code and check coverage**:\n\n```bash\n# Find files implementing <REQ-ID>\ngrep -rl \"# Implements: <REQ-ID>\" src/\n\n# For each file, check coverage\n# Output:\nsrc/auth/login.py: 95.2% coverage\nsrc/auth/validators.py: 100% coverage\nAverage for <REQ-ID>: 97.6% âœ…\n```\n\n**Coverage by requirement**:\n```\n<REQ-ID>: 97.6% âœ… (2 files, high coverage)\n<REQ-ID>: 72.1% âš ï¸ (1 file, below threshold)\nREQ-F-CART-001: 0% âŒ (1 file, no tests)\n```\n\n---\n\n### Step 3: Find Requirements Without Tests\n\n**Cross-reference requirements with test tags**:\n\n```bash\n# Find all requirements\ngrep -rho \"REQ-[A-Z-]*-[0-9]*\" docs/requirements/ | sort -u\n\n# For each, check if tests exist\nfor req in $(cat requirements.txt); do\n  if ! grep -q \"# Validates: $req\" tests/ features/; then\n    echo \"$req: NO TESTS\"\n  fi\ndone\n```\n\n**Output**:\n```\nRequirements Without Tests:\n- <REQ-ID> (has code, no tests) âŒ\n- REQ-F-CART-001 (has code, no tests) âŒ\n- REQ-F-PROFILE-001 (no code, no tests) âš ï¸\n```\n\n---\n\n### Step 4: Detect Critical Path Coverage\n\n**Identify critical paths** (from requirements priority):\n\n```yaml\nCritical Requirements (P0):\n- <REQ-ID>: 97.6% âœ… (Pass)\n- <REQ-ID>: 72.1% âŒ (Fail - critical path needs 100%)\n- REQ-NFR-SEC-001: 100% âœ… (Pass)\n```\n\n**Critical path rule**: P0 requirements must have 100% coverage\n\n---\n\n### Step 5: Calculate Coverage Gaps\n\n**Gap analysis**:\n\n```\nOverall Coverage: 87.5%\n  âœ… Above 80% threshold\n\nCoverage by Priority:\n  P0 (Critical): 89.7% âŒ (3 requirements, 1 below 100%)\n  P1 (High): 92.3% âœ…\n  P2 (Medium): 78.5% âš ï¸ (below threshold)\n\nCoverage by Requirement Type:\n  REQ-F-* (Functional): 85.2% âœ…\n  REQ-NFR-* (Non-Functional): 92.8% âœ…\n  REQ-DATA-* (Data): 65.0% âŒ (below threshold)\n\nGap: P0 critical path and REQ-DATA-* need improvement\n```\n\n---\n\n## Output Format\n\nWhen validation finds deviations:\n\n```\n[VALIDATE TEST COVERAGE - DEVIATION DETECTED]\n\nOverall Coverage: 87.5% âœ… (threshold: 80%)\n\nCoverage by Requirement:\n  âœ… <REQ-ID>: 97.6% (2 files)\n  âš ï¸ <REQ-ID>: 72.1% (below 80%)\n  âŒ REQ-F-CART-001: 0% (no tests)\n\nCritical Path Coverage (P0):\n  âœ… <REQ-ID>: 97.6%\n  âŒ <REQ-ID>: 72.1% (Critical! Needs 100%)\n  âœ… REQ-NFR-SEC-001: 100%\n\nRequirements Without Tests (2):\n  1. <REQ-ID>\n     Code: src/payments/payment.py (72.1% coverage)\n     Missing: Unit tests for edge cases\n\n  2. REQ-F-CART-001\n     Code: src/cart/cart.py\n     Missing: All tests\n\nHomeostasis Deviation:\n  - Critical path <REQ-ID> below 100%\n  - 2 requirements without sufficient tests\n  - Data requirements (REQ-DATA-*) at 65%\n\nRecommended Actions:\n  1. Invoke 'generate-missing-tests' for <REQ-ID>, REQ-F-CART-001\n  2. Focus on critical path (P0) requirements\n  3. Improve REQ-DATA-* coverage (65% â†’ 80%)\n\nHomeostasis Status: âš ï¸ DEVIATION DETECTED\nTarget: coverage >= 80%, critical >= 100%\nCurrent: overall 87.5% âœ…, critical 89.7% âŒ\n```\n\nWhen homeostasis achieved:\n\n```\n[VALIDATE TEST COVERAGE - HOMEOSTASIS ACHIEVED]\n\nOverall Coverage: 94.2% âœ…\n\nCoverage by Requirement:\n  âœ… All requirements >= 80%\n  âœ… All P0 requirements = 100%\n\nCritical Path: 100% âœ…\nData Requirements: 91.3% âœ…\n\nHomeostasis Status: âœ… STABLE\nAll quality gates: PASS\n```\n\n---\n\n## Homeostasis Behavior\n\n**When deviation detected**:\n1. **Report**: Coverage below threshold, requirements without tests\n2. **Signal**: \"Need tests for {REQ-KEYS}\"\n3. **Recommend**: Invoke `generate-missing-tests` actuator\n4. **Wait**: User confirmation or auto-invoke if configured\n\n---\n\n## Prerequisites Check\n\nBefore invoking:\n1. Tests exist (can be zero, but test infrastructure present)\n2. Coverage tool available (pytest-cov, jest, jacoco)\n\n---\n\n## Configuration\n\n```yaml\nplugins:\n  - name: \"@aisdlc/testing-skills\"\n    config:\n      coverage:\n        minimum_percentage: 80\n        require_per_requirement: true\n        critical_paths_coverage: 100\n        exclude_patterns: [\"**/migrations/**\"]\n```\n\n---\n\n## Notes\n\n**Why validate coverage?**\n- **Quality gate**: Don't deploy without adequate tests\n- **Homeostasis**: Continuous monitoring detects when coverage drops\n- **Requirement focus**: Coverage per REQ-* ensures all features tested\n\n**Homeostasis Goal**:\n```yaml\ndesired_state:\n  overall_coverage: >= 80%\n  critical_path_coverage: 100%\n  all_requirements_have_tests: true\n```\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/templates/.ai-workspace/README.md": "# Developer Workspace\n\n**Version**: 1.0\n**Purpose**: File-based task tracking and session management for AI-augmented development\n**Integration**: Works standalone or with AI SDLC methodology\n\n---\n\n## Overview\n\nThe Developer Workspace provides a lightweight, file-based system for managing development tasks and sessions. It integrates practical workflow features from `ai_init` into the `ai_sdlc_method` framework.\n\n**Key Features**:\n- âœ… Two-tier task tracking (quick todos + formal tasks)\n- âœ… Session management with context preservation\n- âœ… TDD workflow support (RED â†’ GREEN â†’ REFACTOR)\n- âœ… Pair programming patterns for human-AI collaboration\n- âœ… File-based foundation (no external dependencies)\n- âœ… Git-versioned documentation\n\n---\n\n## Quick Start\n\n### 1. Structure Overview\n\n```\n.ai-workspace/\nâ”œâ”€â”€ config/\nâ”‚   â””â”€â”€ workspace_config.yml        # Configuration\nâ”œâ”€â”€ session/\nâ”‚   â”œâ”€â”€ current_session.md          # Active session (git-ignored)\nâ”‚   â””â”€â”€ history/                    # Past sessions (git-ignored)\nâ”œâ”€â”€ tasks/\nâ”‚   â”œâ”€â”€ active/\nâ”‚   â”‚   â””â”€â”€ ACTIVE_TASKS.md         # Active tasks (lightweight or formal)\nâ”‚   â”œâ”€â”€ finished/                   # Completed task docs\nâ”‚   â””â”€â”€ archive/                    # Old completed tasks\nâ””â”€â”€ templates/\n    â”œâ”€â”€ TASK_TEMPLATE.md\n    â”œâ”€â”€ FINISHED_TASK_TEMPLATE.md\n    â”œâ”€â”€ SESSION_TEMPLATE.md\n    â”œâ”€â”€ SESSION_STARTER.md\n    â””â”€â”€ PAIR_PROGRAMMING_GUIDE.md\n```\n\n### 2. Available Commands\n\n- `/start-session` - Begin a new development session\n- `/finish-task {id}` - Complete a task and create documentation\n- `/commit-task {id}` - Commit a finished task with proper message\n\n### 3. Typical Workflow\n\n```bash\n# Start your day\n/start-session\n# Set goals, align with Claude, begin work\n\n# Work on tasks (lightweight or formal based on need)\n# (edit ACTIVE_TASKS.md manually or with Claude's help)\n\n# Work on tasks using TDD\n# RED â†’ GREEN â†’ REFACTOR â†’ Document\n\n# Complete a task\n/finish-task 5\n# Creates comprehensive documentation\n\n# Commit the work\n/commit-task 5\n# Generates proper commit message\n```\n\n---\n\n## Task Management\n\n### Active Tasks (Lightweight or Formal)\n\n**File**: `tasks/active/ACTIVE_TASKS.md`\n**Purpose**: Track all development work (can be lightweight or formal based on need)\n\n**Lightweight Task** (quick work):\n```markdown\n## Task #3: Add rate limiting\n\n**Priority**: Medium\n**Status**: Not Started\n**Estimated Time**: 1 hour\n\n**Description**: Add rate limiting to password reset endpoint\n```\n\n**Formal Task** (complex work with TDD):\n```markdown\n## Task #5: Refactor Authentication Service\n\n**Priority**: High\n**Status**: In Progress\n**Estimated Time**: 4 hours\n**Feature Flag**: `task-5-auth-refactor`\n\n**Requirements Traceability**:\n- <REQ-ID>: User login functionality\n- REQ-NFR-PERF-003: Response time < 200ms\n\n**Acceptance Criteria**:\n- [ ] All tests pass (RED â†’ GREEN â†’ REFACTOR)\n- [ ] Test coverage â‰¥ 95%\n- [ ] Feature flag tested both enabled/disabled\n\n**TDD Checklist**:\n- [x] RED: Write failing tests\n- [x] GREEN: Implement solution\n- [ ] REFACTOR: Improve code quality\n- [ ] COMMIT: Create finished task document\n```\n\n### Finished Tasks (Documentation)\n\n**Directory**: `tasks/finished/`\n**Purpose**: Learning and reference\n**Format**: `YYYYMMDD_HHMM_task_name.md`\n**Contains**: Problem, solution, tests, lessons learned, metrics\n\nFinished tasks become valuable documentation that feeds back to enterprise traceability.\n\n---\n\n## Session Management\n\n### Starting a Session\n\n```bash\n/start-session\n```\n\nThis runs through the session starter checklist:\n1. Check git status and recent commits\n2. Review active tasks\n3. Quick methodology review (Key Principles, TDD)\n4. Set session goals (primary, secondary, stretch)\n5. Choose working mode\n6. Align with AI assistant\n\n### During a Session\n\n- Check-in every 15-30 minutes\n- Update session file with progress\n- Track decisions made\n- Document blockers\n\n### Ending a Session\n\n1. Complete or checkpoint current task\n2. Run full test suite\n3. Update ACTIVE_TASKS.md\n4. Create finished task doc (if completed)\n5. Commit with proper message\n6. Archive session to history/\n\n---\n\n## Pair Programming with AI\n\n**Guide**: See `templates/PAIR_PROGRAMMING_GUIDE.md`\n\n### Three Collaboration Modes\n\n1. **Human Driver / AI Navigator** (Most Common)\n   - Human: Strategy, architecture, critical code\n   - AI: Implementation suggestions, boilerplate, issue spotting\n\n2. **AI Driver / Human Navigator** (Tactical)\n   - AI: Repetitive code, refactoring, tests\n   - Human: Specifications, reviews, approval\n\n3. **Collaborative** (Complex Problems)\n   - Both: Debugging, design, learning together\n\n### Communication Patterns\n\n- Think aloud continuously\n- Check-in every 10-15 minutes\n- Clear handoffs between roles\n- Explicit approval for major changes\n\n### Anti-Patterns to Avoid\n\n- âŒ Silent coding (no communication)\n- âŒ Assumption making (ask first)\n- âŒ Big bang implementation (incremental is better)\n- âŒ Ignoring feedback (listen and adapt)\n- âŒ No knowledge transfer (explain as you go)\n\n---\n\n## TDD Workflow\n\n**Always follow**: RED â†’ GREEN â†’ REFACTOR â†’ COMMIT\n\n1. **RED**: Write failing test first\n2. **GREEN**: Write minimal code to pass\n3. **REFACTOR**: Improve code quality\n4. **COMMIT**: Save with clear message (tagged with REQ key)\n5. **REPEAT**: Next test\n\n**No code without tests. Ever.**\n\nSee `plugins/aisdlc-methodology/docs/processes/TDD_WORKFLOW.md` for complete workflow.\n\n---\n\n## Configuration\n\n### File: `config/workspace_config.yml`\n\nKey settings:\n- Task tracking enabled/disabled\n- Session check-in frequency (default: 15 min)\n- TDD enforcement (default: true)\n- Minimum test coverage (default: 80%)\n- Pair programming verbosity (default: medium)\n\nEdit this file to customize your workspace behavior.\n\n---\n\n## Integration with AI SDLC\n\n### Standalone Mode (This Workspace Only)\n\nUse the Developer Workspace without the full 7-stage SDLC:\n- Task tracking works independently\n- Session management works independently\n- No REQ keys required (optional)\n\n### Integrated Mode (Full SDLC)\n\nLink to the enterprise 7-stage AI SDLC:\n- Tasks reference REQ keys from Requirements Stage\n- Finished tasks feed Runtime Feedback Stage\n- Session metrics contribute to team analytics\n- Full traceability: Intent â†’ Code â†’ Runtime\n\n**No external integrations by default** - This implementation uses file system only (no Jira, GitHub, Azure DevOps).\n\n---\n\n## File System as Foundation\n\n**IMPORTANT**: This workspace is built on a file-based foundation:\n\nâœ… **Always works** - No external dependencies\nâœ… **Offline capable** - Work without network\nâœ… **Git versioned** - Full history and backup\nâœ… **No vendor lock-in** - Portable between tools\nâœ… **Resilient** - Continues if external tools fail\n\nTemplates, configs, and finished tasks are tracked in git. Active session state is local and git-ignored.\n\n---\n\n## Examples\n\n### Example 1: Starting a Task\n\n```markdown\n## Task #6: Add Payment Processing\n\n**Priority**: High\n**Status**: Not Started\n**Estimated Time**: 8 hours\n**Feature Flag**: `task-6-payment-processing`\n\n**Requirements Traceability**:\n- <REQ-ID>: Credit card processing\n- REQ-NFR-SEC-005: PCI DSS compliance\n\n**Acceptance Criteria**:\n- [ ] Integration tests with Stripe test API\n- [ ] Test coverage â‰¥ 90%\n- [ ] Feature flag can disable payment flow\n\n# Then follow TDD workflow...\n```\n\n### Example 2: Finishing a Task\n\n```bash\n# All tests passing, task complete\n/finish-task 6\n\n# Claude creates comprehensive documentation:\n# .ai-workspace/tasks/finished/20250121_1530_payment_processing.md\n# - Problem description\n# - Solution approach\n# - TDD process (RED/GREEN/REFACTOR)\n# - Test coverage metrics\n# - Code changes\n# - Lessons learned\n# - Traceability to requirements\n\nâœ… Task #6 finished. Document created.\n\n# Commit the work\n/commit-task 6\n\n# Claude generates proper commit message:\n# Task #6: Add Payment Processing\n#\n# Integrated Stripe API for credit card processing...\n#\n# Tests: 42 unit tests, 91% coverage\n# TDD: RED â†’ GREEN â†’ REFACTOR\n# Implements: <REQ-ID>, REQ-NFR-SEC-005\n\nâœ… Committed: abc123d\n```\n\n---\n\n## Tips & Best Practices\n\n### Daily Routine\n\n1. **Morning**: Run `/start-session` to set goals\n2. **During Work**: Track tasks in ACTIVE_TASKS.md (lightweight or formal)\n3. **Task Completion**: Use `/finish-task` + `/commit-task`\n4. **End of Day**: Review progress in session file\n\n### Weekly Routine\n\n1. Review finished tasks for patterns and learnings\n2. Archive completed tasks\n3. Update estimates based on actual time tracking\n4. Share key learnings with team\n\n### Maintaining Clean Workspace\n\n```bash\n# Archive finished tasks older than 90 days\nfind tasks/finished/ -name \"*.md\" -mtime +90 \\\n  -exec mv {} tasks/archive/ \\;\n```\n\n---\n\n## Troubleshooting\n\n### Issue: \"Context lost mid-session\"\n\n**Solution**: Check session file\n```bash\ncat .ai-workspace/session/current_session.md\ngit status\ngit log --oneline -5\n```\n\n### Issue: \"Can't find finished task\"\n\n**Solution**: Search by date or keywords\n```bash\nls -lt .ai-workspace/tasks/finished/\ngrep -r \"authentication\" .ai-workspace/tasks/finished/\n```\n\n---\n\n## Migration from ai_init\n\nIf you're migrating from `ai_init/claude_tasks`:\n\n```bash\n# Backup existing\ncp -r claude_tasks/ .ai-workspace-backup/\n\n# Migrate active tasks\ncp claude_tasks/active/ACTIVE_TASKS.md .ai-workspace/tasks/active/\n\n# Migrate finished tasks\ncp claude_tasks/finished/*.md .ai-workspace/tasks/finished/\n\n# Update slash commands (paths changed)\nsed -i 's|claude_tasks|.ai-workspace/tasks|g' .claude/commands/*.md\n\n# Cleanup (after verification)\nrm -rf claude_tasks/\n```\n\n---\n\n## Resources\n\n**Documentation**:\n- [Complete Integration Plan](../docs/DEVELOPER_WORKSPACE_INTEGRATION.md) - 3,000+ line spec\n- [AI SDLC Method](../docs/ai_sdlc_method.md) - Complete 7-stage methodology\n- [Key Principles](../plugins/aisdlc-methodology/docs/principles/KEY_PRINCIPLES.md)\n- [TDD Workflow](../plugins/aisdlc-methodology/docs/processes/TDD_WORKFLOW.md)\n\n**Templates**: All in `templates/` directory\n**Configuration**: `config/workspace_config.yml`\n**Support**: GitHub Issues at https://github.com/foolishimp/ai_sdlc_method/issues\n\n---\n\n## Success Metrics (Track After 30 Days)\n\n- [ ] Average session startup time < 10 min\n- [ ] Context loss incidents: 0\n- [ ] Test coverage: â‰¥ 80%\n- [ ] Post-release defects: < 5%\n- [ ] Cycle time: -20% (faster)\n- [ ] Rework rate: < 10%\n- [ ] Developer satisfaction: â‰¥ 4/5\n\n---\n\n## License\n\nMIT License - See LICENSE file in repository\n\n---\n\n## Author\n\n**foolishimp** - https://github.com/foolishimp/ai_sdlc_method\n\nBased on learnings from:\n- `ai_init/claude_init` (developer experience)\n- `ai_sdlc_method` (enterprise scale)\n- Traditional pair programming research\n- AI collaboration best practices\n\n---\n\n**\"Excellence or nothing\"** ğŸ”¥\n\n*Developer experience that matches the enterprise vision!*\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/templates/.ai-workspace/config/workspace_config.yml": "# Developer Workspace Configuration\nversion: \"1.0\"\n\n# Task tracking (single-tier: lightweight or formal)\ntask_tracking:\n  enabled: true\n\n  # Tasks (can be lightweight or formal based on need)\n  tasks:\n    enabled: true\n    active_file: \"tasks/active/ACTIVE_TASKS.md\"\n    finished_dir: \"tasks/finished/\"\n    template: \"templates/TASK_TEMPLATE.md\"\n    finished_template: \"templates/FINISHED_TASK_TEMPLATE.md\"\n    feature_flags:\n      enabled: true\n      pattern: \"task-{id}-{description}\"\n\n  # Archive\n  archive:\n    enabled: true\n    retention_days: 365  # Keep finished tasks for 1 year\n\n# Session management\nsession:\n  enabled: true\n  current_file: \"session/current_session.md\"\n  history_dir: \"session/history/\"\n  template: \"templates/SESSION_TEMPLATE.md\"\n  starter_checklist: \"templates/SESSION_STARTER.md\"\n\n  # Check-in reminders\n  checkin_frequency_minutes: 15\n\n  # Auto-save session state\n  autosave: true\n  autosave_interval_minutes: 5\n\n# Pair programming\npair_programming:\n  enabled: true\n  guide: \"templates/PAIR_PROGRAMMING_GUIDE.md\"\n\n  # Default mode\n  default_mode: \"human_driver_ai_navigator\"\n\n  # Communication preferences\n  verbosity: \"medium\"  # low, medium, high\n  think_aloud: true\n  frequent_checkins: true\n\n# TDD workflow\ntdd:\n  enforce: true\n  workflow: \"RED â†’ GREEN â†’ REFACTOR â†’ COMMIT\"\n  min_coverage: 80\n  critical_path_coverage: 100\n\n# Integration with AI SDLC (NO external integrations)\nai_sdlc:\n  # Link to enterprise system\n  requirements_integration: true\n\n  # File system is ALWAYS the foundation\n  # No external integrations enabled by default\n  jira_integration:\n    enabled: false\n  github_projects_integration:\n    enabled: false\n  azure_devops_integration:\n    enabled: false\n\n  # Requirement key tagging\n  require_req_keys: false  # Optional, set to true for strict enforcement\n  req_key_pattern: \"REQ-{TYPE}-{DOMAIN}-{SEQ}\"\n\n# Metrics\nmetrics:\n  track_time: true\n  track_coverage: true\n  track_rework: true\n  track_defects: true\n\n  # Session metrics report\n  generate_report: true\n  report_frequency: \"daily\"  # daily, weekly, monthly\n\n# Git integration\ngit:\n  # Commit message template\n  commit_template: |\n    Task #{id}: {title}\n\n    {problem}\n\n    {solution}\n\n    Tests: {test_summary}\n    TDD: RED â†’ GREEN â†’ REFACTOR\n\n    ğŸ¤– Generated with [Claude Code](https://claude.ai/code)\n    Co-Authored-By: Claude <noreply@anthropic.com>\n\n  # Auto-commit finished tasks\n  auto_commit: false  # User preference\n\n# Notifications\nnotifications:\n  # Remind to take breaks\n  break_reminder: true\n  break_interval_minutes: 60\n\n  # Remind to commit\n  uncommitted_changes_reminder: true\n  uncommitted_threshold_minutes: 120\n\n  # Session timeout warning\n  session_timeout_warning: true\n  session_timeout_hours: 4\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/templates/.ai-workspace/tasks/active/ACTIVE_TASKS.md": "# Active Tasks\n\n*Last Updated: 2025-01-21*\n\n---\n\n<!-- Example Task:\n\n## Task #1: Example Task Title\n\n**Priority**: High | Medium | Low\n**Status**: Not Started | In Progress | Blocked\n**Started**: YYYY-MM-DD HH:MM\n**Estimated Time**: X hours\n**Actual Time**: Y hours (so far)\n**Dependencies**: None or Task #N\n**Feature Flag**: `task-1-description` (defaultValue: false)\n\n**Requirements Traceability**:\n- REQ-F-XXX-001: Description\n- REQ-NFR-XXX-002: Description\n\n**Description**:\nDetailed description of what needs to be done and why.\n\n**Acceptance Criteria**:\n- [ ] All tests pass (RED â†’ GREEN â†’ REFACTOR)\n- [ ] Test coverage â‰¥ 80%\n- [ ] No duplicate code (DRY principle)\n- [ ] Error handling for all edge cases\n- [ ] Feature flag tested both enabled/disabled\n\n**Promoted From**: Todo on YYYY-MM-DD HH:MM (if applicable)\n\n**TDD Checklist**:\n- [ ] RED: Write failing tests\n- [ ] GREEN: Implement minimal solution\n- [ ] REFACTOR: Improve code quality\n- [ ] COMMIT: Create finished task document\n\n---\n\n-->\n\n**No active tasks yet**\n\nUse `/start-session` to begin working, or manually add tasks above.\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/templates/.ai-workspace/templates/AISDLC_METHOD_REFERENCE.md": "# AI SDLC Context Refresh for Claude\n\n**Version:** 3.0.0 (v0.1.4 Implicit Session Model)\n**Purpose:** Load this to refresh Claude's context with AI SDLC methodology\n**When to use:** After context loss, before any work, after violations\n\n---\n\n## ğŸ¯ Core Principle\n\n**\"Session = Context. Context persists in ACTIVE_TASKS.md.\"**\n\n**How to use this document:**\n1. Read after making mistakes\n2. Read when unsure of workflow\n3. Reference quick cards at bottom for fast lookup\n4. **Note**: You DON'T need to read this at session start - CLAUDE.md auto-loads context\n\n---\n\n## ğŸ“ Workspace Structure (NEVER VIOLATE THIS!)\n\n```\n.ai-workspace/\nâ”œâ”€â”€ tasks/\nâ”‚   â”œâ”€â”€ active/\nâ”‚   â”‚   â””â”€â”€ ACTIVE_TASKS.md        # Single file: tasks + status + summary\nâ”‚   â”œâ”€â”€ finished/                  # Completed task documentation\nâ”‚   â”‚   â””â”€â”€ YYYYMMDD_HHMM_task_name.md\nâ”‚   â””â”€â”€ archive/                   # Old completed tasks\nâ”‚\nâ”œâ”€â”€ templates/                     # Templates for tasks\nâ”‚   â”œâ”€â”€ TASK_TEMPLATE.md\nâ”‚   â”œâ”€â”€ FINISHED_TASK_TEMPLATE.md\nâ”‚   â”œâ”€â”€ AISDLC_METHOD_REFERENCE.md (this file)\nâ”‚   â””â”€â”€ deprecated/                # Archived session templates\nâ”‚       â”œâ”€â”€ SESSION_STARTER.md\nâ”‚       â””â”€â”€ SESSION_TEMPLATE.md\nâ”‚\nâ””â”€â”€ config/                        # Workspace configuration\n```\n\n**CRITICAL RULES:**\n- âœ… **DO**: Put finished tasks in `.ai-workspace/tasks/finished/`\n- âŒ **DON'T**: Put tasks in `docs/`, `finished_tasks/`, or anywhere else\n- âœ… **DO**: Use `TodoWrite` tool for task tracking during work\n- âŒ **DON'T**: Create task files manually without following workflow\n- âœ… **DO**: Update ACTIVE_TASKS.md via `/aisdlc-checkpoint-tasks`\n- âŒ **DON'T**: Manually edit ACTIVE_TASKS.md timestamp/summary sections\n\n---\n\n## ğŸ”„ Proper Workflow (ALWAYS FOLLOW THIS!)\n\n### No Explicit Session Start Needed\n**v0.1.4 Change**: Context auto-loads via CLAUDE.md. Just open Claude and start working.\n\n**What auto-loads:**\n1. CLAUDE.md (project guide)\n2. This reference file (methodology)\n3. ACTIVE_TASKS.md (current work)\n\n**No ceremony. Just work.**\n\n### During Work\n```bash\n# Use TodoWrite tool to track progress\n# (Claude should proactively use this!)\n\n# Work on tasks from ACTIVE_TASKS.md\n# Follow TDD for code: RED â†’ GREEN â†’ REFACTOR\n```\n\n### After Work (CRITICAL!)\n```bash\n/aisdlc-checkpoint-tasks\n# Claude will:\n# - Review conversation history\n# - Evaluate active tasks\n# - Create finished task docs in CORRECT location\n# - Update ACTIVE_TASKS.md (timestamp, status, summary)\n# - Provide summary report\n```\n\n### Commit\n```bash\n/aisdlc-commit-task <id>\n# Generates proper commit message with REQ tags\n```\n\n---\n\n## ğŸ› ï¸ Tools to Use (Claude's Toolkit)\n\n### Task Tracking\n- **`TodoWrite` tool** - Track task progress in real-time\n  - Use proactively during work\n  - Update status: pending â†’ in_progress â†’ completed\n\n### Slash Commands\n- `/aisdlc-checkpoint-tasks` - Sync tasks with reality â­ **USE AFTER WORK**\n- `/aisdlc-finish-task <id>` - Complete specific task\n- `/aisdlc-commit-task <id>` - Generate commit message\n- `/aisdlc-status` - Show task queue status\n- `/aisdlc-release` - Deploy framework to example projects\n- `/aisdlc-refresh-context` - Refresh methodology context\n\n### File Operations\n- **Read** - Read existing files\n- **Write** - Create new files (use sparingly!)\n- **Edit** - Modify existing files (preferred)\n- **Bash** - Git operations, tests, builds\n\n---\n\n## ğŸ“‹ Task Lifecycle\n\n### 1. Active Task (Primary)\n```markdown\nLocation: .ai-workspace/tasks/active/ACTIVE_TASKS.md\nSingle file containing:\n- Task details (ID, priority, status, acceptance criteria)\n- Summary section (counts, recently completed)\n- Recovery commands\n\nRequired per task:\n- Task ID\n- Priority (High/Medium/Low)\n- Status (Not Started/In Progress/Blocked)\n- Acceptance Criteria\n- Feature Flag (if code, optional)\n- Requirement Traceability (REQ-*)\n\nTDD Required: YES (unless documentation task)\n\nUpdated by: /aisdlc-checkpoint-tasks (timestamp, status, summary)\n```\n\n### 2. Finished Task (Documentation)\n```markdown\nLocation: .ai-workspace/tasks/finished/YYYYMMDD_HHMM_task_name.md\nTemplate: .ai-workspace/templates/FINISHED_TASK_TEMPLATE.md\nCreated by: /aisdlc-checkpoint-tasks (when task completed)\n\nRequired Sections:\n- Problem\n- Investigation\n- Solution\n- TDD Process (if code)\n- Files Modified\n- Test Coverage (if code)\n- Result\n- Traceability\n- Metrics\n- Lessons Learned\n```\n\n---\n\n## ğŸ¨ The 7 Key Principles (Code Stage)\n\n**Full details:** `plugins/aisdlc-methodology/docs/principles/KEY_PRINCIPLES.md`\n\n1. **Test Driven Development** - RED â†’ GREEN â†’ REFACTOR â†’ COMMIT\n2. **Fail Fast & Root Cause** - Fix at source, no workarounds\n3. **Modular & Maintainable** - Single responsibility\n4. **Reuse Before Build** - Check existing first\n5. **Open Source First** - Suggest alternatives\n6. **No Legacy Baggage** - Start clean\n7. **Perfectionist Excellence** - Excellence or nothing ğŸ”¥\n\n**TDD Workflow:** `plugins/aisdlc-methodology/docs/processes/TDD_WORKFLOW.md`\n\n---\n\n## ğŸ¯ 7-Stage AI SDLC\n\n**Full details:** `docs/ai_sdlc_method.md` (3,300+ lines)\n**Agent configs:** `plugins/aisdlc-methodology/config/stages_config.yml` (1,273 lines)\n\n```\nIntent â†’ Requirements â†’ Design â†’ Tasks â†’ Code â†’ System Test â†’ UAT â†’ Runtime Feedback\n           â†‘                                                                   â†“\n           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Feedback Loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**Quick stage reference:**\n1. Requirements â†’ REQ-F-*, REQ-NFR-*, REQ-DATA-*\n2. Design â†’ Components, APIs, ADRs\n3. Tasks â†’ Jira tickets with REQ tags\n4. **Code** â†’ TDD (REDâ†’GREENâ†’REFACTOR), tag with `# Implements: REQ-*` â­ **PRIMARY**\n5. System Test â†’ BDD (Given/When/Then)\n6. UAT â†’ Business validation\n7. Runtime Feedback â†’ Telemetry â†’ new intents\n\n**Use `/aisdlc-status` to see current stage**\n\n---\n\n## âš ï¸ Common Violations (DON'T DO THESE!)\n\n### âŒ Task Location Violations\n```\nWRONG: docs/finished_tasks/task.md\nWRONG: finished_tasks/task.md\nWRONG: tasks/task.md\nRIGHT: .ai-workspace/tasks/finished/YYYYMMDD_HHMM_task.md\n```\n\n### âŒ Workflow Violations\n```\nWRONG: Finish work without /aisdlc-checkpoint-tasks\nWRONG: Create task files manually\nWRONG: Manually edit ACTIVE_TASKS.md sections\nRIGHT: Work â†’ /aisdlc-checkpoint-tasks â†’ commit\n```\n\n### âŒ Tool Violations\n```\nWRONG: Don't use TodoWrite tool during work\nWRONG: Manually create finished task files\nWRONG: Skip /aisdlc-checkpoint-tasks after work\nRIGHT: Use TodoWrite, use /aisdlc-checkpoint-tasks, follow workflow\n```\n\n### âŒ Outdated Command References\n```\nWRONG: /aisdlc-start-session (removed in v0.1.4)\nWRONG: /aisdlc-todo (removed in v0.1.4)\nWRONG: TODO_LIST.md (removed in v0.1.4)\nRIGHT: Just open Claude (context auto-loads), use ACTIVE_TASKS.md\n```\n\n---\n\n## âœ… Pre-Flight Checklist (Before Starting ANY Work)\n\n1. [ ] Is there a task in `ACTIVE_TASKS.md`? (If not, add one)\n2. [ ] Am I using `TodoWrite` tool to track progress?\n3. [ ] Do I know which stage I'm in (Requirements/Design/Code/etc.)?\n4. [ ] Will I run `/aisdlc-checkpoint-tasks` after completing work?\n\n**If ANY answer is \"no\", STOP and correct before proceeding.**\n\n**Note**: No need to run session start command - context auto-loads via CLAUDE.md\n\n---\n\n## ğŸš¨ Recovery from Violations\n\n### If you violated workspace structure:\n1. **STOP** immediately\n2. Acknowledge violation to user\n3. Move/delete incorrectly placed files\n4. Create files in CORRECT location\n5. Update this reference if needed\n\n### If you violated workflow:\n1. **STOP** and acknowledge\n2. Run `/aisdlc-checkpoint-tasks` to sync reality with docs\n3. Properly document work retroactively\n4. Learn from violation\n\n### If you used removed commands:\n1. **STOP** - /aisdlc-start-session and /aisdlc-todo were removed in v0.1.4\n2. Use ACTIVE_TASKS.md directly (single file model)\n3. Context auto-loads - no explicit session start needed\n\n### If you're unsure:\n1. **ASK** the user before proceeding\n2. Reference this document\n3. Check `.ai-workspace/` structure\n4. Use slash commands\n\n---\n\n## ğŸ“š Quick Reference Card (v0.1.4)\n\n### File Locations\n| What | Where |\n|------|-------|\n| Active tasks | `.ai-workspace/tasks/active/ACTIVE_TASKS.md` â­ (single file) |\n| Finished tasks | `.ai-workspace/tasks/finished/YYYYMMDD_HHMM_*.md` |\n| Templates | `.ai-workspace/templates/` |\n| Archived sessions | `.ai-workspace/templates/deprecated/SESSION_*.md` |\n\n### Commands (Current)\n| When | Command |\n|------|---------|\n| After work | `/aisdlc-checkpoint-tasks` â­ |\n| Finish task | `/aisdlc-finish-task <id>` |\n| Commit | `/aisdlc-commit-task <id>` |\n| Check status | `/aisdlc-status` |\n| Deploy framework | `/aisdlc-release` |\n| Refresh context | `/aisdlc-refresh-context` |\n\n### Removed Commands (v0.1.4)\n| Removed | Reason |\n|---------|--------|\n| `/aisdlc-start-session` | Context auto-loads (implicit model) |\n| `/aisdlc-todo` | Over-engineered, use ACTIVE_TASKS.md directly |\n| `/switch-context` | Not MVP |\n| `/load-context` | Not MVP |\n| `/current-context` | Not MVP |\n\n### TDD Cycle\n```\nRED    â†’ Write failing test first\nGREEN  â†’ Implement minimal solution\nREFACTOR â†’ Improve code quality\nCOMMIT â†’ Save with REQ tags\n```\n\n---\n\n## ğŸ“ Learning from Common Violations\n\n**Violation: Put finished task in wrong location**\n- âŒ Created in `docs/finished_tasks/`\n- âœ… Should: `.ai-workspace/tasks/finished/YYYYMMDD_HHMM_*.md`\n\n**Violation: Forgot to track progress**\n- âŒ Didn't use TodoWrite tool during work\n- âœ… Should: Use TodoWrite proactively to track progress\n\n**Violation: Forgot to checkpoint**\n- âŒ Finished work without `/aisdlc-checkpoint-tasks`\n- âœ… Should: Always checkpoint after work to sync docs\n\n**Violation: Used removed commands**\n- âŒ Tried to use `/aisdlc-start-session` or `/aisdlc-todo`\n- âœ… Should: v0.1.4 uses implicit sessions, ACTIVE_TASKS.md only\n\n**Key Takeaways:**\n1. Context auto-loads - no explicit session start needed\n2. Use `/aisdlc-checkpoint-tasks` after ANY work\n3. Single file: ACTIVE_TASKS.md (no TODO_LIST.md, no session files)\n4. Never create files manually - use commands/tools\n5. When in doubt, ASK before proceeding\n\n---\n\n## ğŸ“¦ Version History\n\n**v3.0.0 (2025-11-25)** - Implicit Session Model (v0.1.4)\n- Removed /aisdlc-start-session (context auto-loads)\n- Removed /aisdlc-todo and TODO_LIST.md\n- Single file: ACTIVE_TASKS.md (tasks + status + summary)\n- No session/ directory (implicit sessions)\n- Simplified workflow: work â†’ checkpoint â†’ commit\n\n**v2.0.0 (2025-11-23)** - Explicit Session Model\n- Formal session start with goals\n- Two-tier task system (todos + formal tasks)\n- Session tracking in session/\n\n**v1.0.0** - Initial release\n\n---\n\n**Version:** 3.0.0\n**Last Updated:** 2025-11-25 (v0.1.4 release)\n**Maintained By:** AI SDLC Method Team\n\n**\"Excellence or nothing\"** ğŸ”¥\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/templates/.ai-workspace/templates/FINISHED_TASK_TEMPLATE.md": "# Task: {TITLE}\n\n**Status**: Completed\n**Date**: {DATE}\n**Time**: {TIME}\n**Actual Time**: X hours (Estimated: Y hours)\n\n**Task ID**: #{ID}\n**Requirements**: REQ-F-XXX-001, REQ-NFR-XXX-002\n\n---\n\n## Problem\n\nWhat was the issue or requirement that needed to be addressed?\n\n---\n\n## Investigation\n\nWhat did you discover during analysis?\n\n1. Analyzed...\n2. Reviewed...\n3. Found...\n\n---\n\n## Solution\n\n**Architectural Changes**:\n- Created...\n- Implemented...\n- Added...\n\n**TDD Process**:\n1. **RED Phase** (X min):\n   - Wrote N failing tests for...\n2. **GREEN Phase** (X min):\n   - Implemented... to pass tests\n3. **REFACTOR Phase** (X min):\n   - Extracted...\n   - Improved...\n   - Optimized...\n\n---\n\n## Files Modified\n\n- `/path/to/file1.ext` - NEW (description)\n- `/path/to/file2.ext` - Modified (description)\n- `/path/to/file3.ext` - Refactored (description)\n\n---\n\n## Test Coverage\n\n**Before**: X% (N tests)\n**After**: Y% (M tests)\n\n**Test Breakdown**:\n- **Unit Tests**: N tests\n- **Integration Tests**: M tests\n- **Performance Tests**: P tests\n\n**Coverage Details**:\n- `module1.ext`: 100%\n- `module2.ext`: 95%\n\n---\n\n## Feature Flag\n\n**Flag Name**: `task-{id}-{description}`\n**Status**: Enabled in production ({DATE})\n**Rollout Plan**:\n- Phase 1: Enabled in dev\n- Phase 2: Enabled in staging\n- Phase 3: Enabled for 10% prod traffic\n- Phase 4: Enabled for 100% prod traffic\n- Phase 5: Remove flag and old code\n\n---\n\n## Code Changes\n\n**Before**:\n```language\n// Old code example\n```\n\n**After**:\n```language\n// New code example\n```\n\n---\n\n## Testing\n\n**Manual Testing**:\n```bash\n# Commands to test the feature\nnpm test\n```\n\n**Results**:\n- All N tests passing âœ…\n- Coverage: Y% (target: â‰¥X%) âœ…\n- Performance: Zms avg (target: <Wms) âœ…\n- Zero regressions âœ…\n\n---\n\n## Result\n\nâœ… **Task completed successfully**\n- Outcome 1\n- Outcome 2\n- Outcome 3\n\n**Production Metrics** (if applicable):\n- Metric 1: Value\n- Metric 2: Value\n\n---\n\n## Side Effects\n\n**Positive**:\n- Benefit 1\n- Benefit 2\n\n**Considerations**:\n- Consideration 1\n- Consideration 2\n\n---\n\n## Future Considerations\n\n1. Future task 1\n2. Future task 2\n3. Future task 3\n\n---\n\n## Lessons Learned\n\n1. **Lesson 1**: What we learned\n2. **Lesson 2**: What we learned\n3. **Lesson 3**: What we learned\n\n---\n\n## Traceability\n\n**Requirements Coverage**:\n- REQ-F-XXX-001: âœ… Tests in `test_file.ext::test_function`\n- REQ-NFR-XXX-002: âœ… Tests in `test_file.ext::test_function`\n\n**Upstream Traceability**:\n- Intent: INT-XXX \"Description\"\n- Epic: PROJ-XXX \"Description\"\n- Story: PROJ-XXX \"Description\"\n\n**Downstream Traceability**:\n- Commit: `hash` \"Commit message\"\n- Release: vX.Y.Z\n- Deployment: env-YYYY-MM-DD\n\n---\n\n## Metrics\n\n- **Lines Added**: N\n- **Lines Removed**: M (net: +/- X)\n- **Tests Added**: N\n- **Test Coverage**: X% â†’ Y% (+Z%)\n- **Complexity**: Before â†’ After\n- **Performance**: Xms â†’ Yms (Z% improvement)\n\n---\n\n## Related\n\n- **Promoted From**: Todo on YYYY-MM-DD HH:MM\n- **Related Tasks**: Task #N depends on this\n- **Related Issues**: GitHub #N, Jira PROJ-N\n- **Documentation**: Updated `/docs/file.md`\n- **References**: Links to relevant documentation\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/templates/.ai-workspace/templates/PAIR_PROGRAMMING_GUIDE.md": "# Pair Programming with AI - Quick Reference\n\n**Purpose**: Maximize human-AI collaboration effectiveness\n**Scope**: Claude Code and similar AI assistants\n\n---\n\n## ğŸ¯ Core Concept\n\n**Human-AI Pair Programming**:\n- Human (Driver) + AI (Navigator) **OR** AI (Driver) + Human (Navigator)\n- Roles based on task nature, not time\n- Continuous validation (human approves AI proposals)\n- AI never makes architectural decisions without approval\n\n---\n\n## ğŸ‘¥ Three Collaboration Modes\n\n### Mode 1: Human Driver / AI Navigator (Most Common)\n\n**When to Use**:\n- Implementing business logic\n- Making architectural decisions\n- Writing sensitive code (security, payments)\n- Learning new concepts\n\n**Human**: Defines WHAT to build, makes strategic decisions, writes critical code\n**AI**: Suggests HOW to implement, writes boilerplate, spots issues, offers alternatives\n\n**Example**:\n```\nHuman: \"We need to validate credit card numbers\"\nAI: \"I suggest: 1) Write tests first, 2) Use Luhn algorithm, 3) Use library (card-validator). Which?\"\nHuman: \"Option 3. Show me tests first\"\nAI: [writes failing tests]\nHuman: \"Looks good, implement it\"\n```\n\n---\n\n### Mode 2: AI Driver / Human Navigator (Tactical)\n\n**When to Use**:\n- Writing repetitive code (tests, mocks, types)\n- Refactoring for code quality\n- Implementing well-defined patterns\n- Documentation generation\n\n**AI**: Writes code based on clear specifications, executes TDD autonomously\n**Human**: Provides specifications, watches for drift, reviews for correctness\n\n**Example**:\n```\nHuman: \"Refactor this auth module following our pattern. Tests must pass.\"\nAI: \"I'll: 1) Extract validation, 2) Update 3 modules, 3) Keep 42 tests passing. Proceeding...\"\n[AI writes code]\nAI: \"Done. All tests pass. Review?\"\nHuman: \"Looks good, commit it\"\n```\n\n---\n\n### Mode 3: Collaborative (Complex Problems)\n\n**When to Use**:\n- Debugging complex issues\n- Designing new systems\n- Resolving ambiguous requirements\n- Learning together\n\n**Both**: Think aloud, ask questions, challenge assumptions, explore alternatives\n\n**Example**:\n```\nHuman: \"This auth bug is strange. Token validates but user can't access\"\nAI: \"Could be race condition in role loading?\"\nHuman: \"Good point. Let's add logging\"\n[Together design concurrency test]\n```\n\n---\n\n## ğŸ—£ï¸ Communication Patterns\n\n### Pattern 1: Think Aloud\n- Verbalize reasoning to prevent silent mistakes\n- Creates audit trail\n- Catches flawed assumptions early\n\n### Pattern 2: Frequent Check-ins (Every 10-15 min)\n- \"Does this look right so far?\"\n- \"Should we test this now or keep going?\"\n- \"Any concerns with this approach?\"\n\n### Pattern 3: Clear Handoffs\n```\nHuman: \"I've set up the structure. Can you implement the tests?\"\nAI: \"Tests ready: 15 unit tests (all failing). Please review before I implement.\"\n```\n\n### Pattern 4: Explicit Approval\n**AI Must Ask Before**:\n- Making architectural changes\n- Introducing new dependencies\n- Deleting significant code\n- Changing public interfaces\n- Committing to git\n\n---\n\n## ğŸ”„ TDD Ping-Pong (Modified for AI)\n\n1. Human describes test case â†’ AI writes failing test\n2. AI shows failing test â†’ Human approves\n3. AI implements â†’ Human reviews\n4. Both refactor together â†’ Commit\n\n**Example**:\n```\nIteration 1:\nHuman: \"Test user login with valid credentials\"\nAI: [writes test_login_valid() - FAILS]\nHuman: \"Approved\"\nAI: [implements login() - PASSES]\nHuman: \"Good, but extract validation logic\"\nAI: [refactors - STILL PASSES]\n\nIteration 2:\nAI: \"Should we test invalid credentials?\"\nHuman: \"Yes, also test missing fields\"\n...\n```\n\n---\n\n## ğŸš« Anti-Patterns to Avoid\n\n### âŒ Silent Coding\n**Bad**: AI writes 500 lines in one shot\n**Good**: AI breaks into chunks, shows each for review\n\n### âŒ Assumption Making\n**Bad**: AI assumes PostgreSQL without asking\n**Good**: AI checks `package.json`, asks which database to use\n\n### âŒ Big Bang Implementation\n**Bad**: Implement entire feature, then debug failing tests\n**Good**: One test â†’ minimal code â†’ pass â†’ refactor â†’ next test\n\n### âŒ Ignoring Feedback\n**Bad**: Human says \"simplify\", AI continues with complex approach\n**Good**: AI acknowledges, refactors, asks for review\n\n### âŒ No Knowledge Transfer\n**Bad**: AI implements complex algorithm without explanation\n**Good**: AI explains approach, adds comments, helps human understand\n\n---\n\n## ğŸ’¡ Best Practices\n\n### 1. Take Breaks\n- Break after completing a task\n- Break when stuck (fresh perspective)\n- Break every 60-90 minutes minimum\n\n### 2. Celebrate Small Wins\n```\nAI: \"All 37 tests passing! ğŸ‰\"\nHuman: \"That null case test you suggested caught a real bug\"\nAI: \"Your refactoring made the code much cleaner\"\n```\n\n### 3. Share Knowledge Continuously\n```\nAI: \"I'm using a Trie because: 1) Autocomplete needs prefix matching, 2) O(k) lookup. Would you like diagram?\"\nHuman: \"Yes, and note: users type 3+ chars before we search\"\n```\n\n### 4. Stay Engaged\n- Don't say \"implement X\" and disappear\n- Watch what AI is doing\n- Ask questions if unclear\n- Provide feedback continuously\n\n### 5. Respect Expertise\n**Human expertise**: Business domain, UX, team conventions, strategic decisions\n**AI expertise**: Syntax, patterns, libraries, code quality, documentation\n\n---\n\n## ğŸ® Quick Commands\n\n### Human Can Say\n- \"Let's pair on this\" - Start session\n- \"You drive\" - AI leads implementation\n- \"I'll drive\" - Human leads implementation\n- \"Hold on\" - Pause for review\n- \"Explain that\" - Need clarification\n- \"Show me alternatives\" - Want options\n- \"Ship it\" - Ready to commit\n\n### AI Should Say\n- \"Should I proceed with...\" - Ask permission\n- \"I propose...\" - Suggest approach\n- \"Alternative approaches are...\" - Present options\n- \"I notice...\" - Point out issues\n- \"Ready for review\" - Completed chunk\n- \"Any concerns?\" - Solicit feedback\n\n---\n\n## ğŸ“Š Track These Metrics\n\n1. **Cycle Time**: Idea to working code (target: <30 min for small features)\n2. **Defect Rate**: Bugs after completion (target: <5%)\n3. **Rework Rate**: Time spent redoing work (target: <10%)\n4. **Test Coverage**: Code covered by tests (target: â‰¥80%)\n5. **Communication Clarity**: Misunderstandings per session (target: <2)\n\n---\n\n## ğŸ Session Structure\n\n### Start (5-10 min)\n1. Review context: `git status`, `git log`, check active tasks\n2. Align on goals\n3. Set parameters: mode, check-in frequency, roles\n4. Create session file\n\n### During (Active Work)\n- Check-in every 15-30 min\n- Think aloud continuously\n- Document decisions\n- Use TodoWrite for tracking\n\n### End (10 min)\n1. Complete or checkpoint task\n2. Run full test suite\n3. Update task status\n4. Commit with proper message\n5. Archive session\n6. Session summary\n\n---\n\n## ğŸ¯ Key Benefits\n\n1. **Continuous Code Review** - Two perspectives on every line\n2. **Knowledge Documentation** - Conversation becomes docs\n3. **Reduced Cognitive Load** - Share mental burden\n4. **24/7 Availability** - AI doesn't need sleep\n5. **Learning Opportunity** - Both learn from each other\n6. **Higher Quality** - Catch more issues\n7. **Faster Development** - Parallel thinking\n8. **Built-in Testing** - TDD becomes natural\n9. **No Social Pressure** - Easy to admit \"I don't understand\"\n10. **Consistency** - AI maintains discipline\n\n---\n\n## ğŸ“š References\n\n- Kent Beck - \"Extreme Programming Explained\"\n- Laurie Williams - \"Pair Programming Illuminated\"\n- This workspace: `/docs/DEVELOPER_WORKSPACE_INTEGRATION.md` (complete guide)\n\n---\n\n**Remember**: The goal is to amplify human capabilities through effective AI collaboration!\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/templates/.ai-workspace/templates/TASK_TEMPLATE.md": "# Task #{ID}: {TITLE}\n\n**Priority**: High | Medium | Low\n**Status**: Not Started\n**Estimated Time**: X hours\n**Dependencies**: None\n**Feature Flag**: `task-{id}-{description}` (defaultValue: false)\n\n**Requirements Traceability**:\n- REQ-F-XXX-001: Description\n- REQ-NFR-XXX-002: Description\n\n---\n\n## Description\n\nWhat needs to be done and why?\n\n---\n\n## Acceptance Criteria\n\n- [ ] All tests pass (RED â†’ GREEN â†’ REFACTOR)\n- [ ] Test coverage â‰¥ 80%\n- [ ] No duplicate code (DRY principle)\n- [ ] Error handling for all edge cases\n- [ ] Feature flag tested both enabled/disabled\n- [ ] Performance requirements met\n- [ ] Documentation updated\n\n---\n\n## TDD Checklist\n\n- [ ] RED: Write failing tests\n- [ ] GREEN: Implement minimal solution\n- [ ] REFACTOR: Improve code quality\n- [ ] COMMIT: Create finished task document\n\n---\n\n## Notes\n\n- Promoted From: Todo on YYYY-MM-DD HH:MM (if applicable)\n- Additional context or considerations\n\n---\n\n**Created**: {TIMESTAMP}\n**Last Updated**: {TIMESTAMP}\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/templates/.ai-workspace/templates/deprecated/SESSION_STARTER.md": "# Session Starter Checklist\n\nRun this checklist at the start of EVERY session. Takes 5-10 minutes but saves hours.\n\n---\n\n## ğŸš€ Phase 1: Check Current State (2 min)\n\n```bash\n# Where are we?\ngit status\ngit log --oneline -5\n\n# What's active?\ncat .ai-workspace/tasks/active/ACTIVE_TASKS.md\n\n# What was the last session?\nls -lt .ai-workspace/session/history/ | head -1\n\n# Any failing tests?\nnpm test --silent  # or: pytest -q\n```\n\n**Output**: Clear understanding of project state\n\n---\n\n## ğŸ“š Phase 2: Review Methodology (2 min)\n\n```bash\n# Review core principles\ncat plugins/aisdlc-methodology/docs/principles/KEY_PRINCIPLES.md | head -50\n\n# Review TDD workflow\ncat plugins/aisdlc-methodology/docs/processes/TDD_WORKFLOW.md | head -50\n```\n\n**Checklist**:\n- [ ] I remember the Key Principles\n- [ ] I remember TDD: RED â†’ GREEN â†’ REFACTOR\n- [ ] I remember pair programming patterns\n\n---\n\n## ğŸ¯ Phase 3: Set Session Goals (2 min)\n\n```bash\n# Create current session file\ncp .ai-workspace/templates/SESSION_TEMPLATE.md \\\n   .ai-workspace/session/current_session.md\n\n# Edit with today's goals\n```\n\n**Define**:\n- [ ] Primary goal (must complete)\n- [ ] Secondary goal (should complete)\n- [ ] Stretch goal (if time permits)\n\n---\n\n## ğŸ¤ Phase 4: Align with AI Assistant (1 min)\n\n**Human says**:\n```\n\"Let's align on today's session:\n- Primary goal: [WHAT]\n- I'm thinking we should [APPROACH]\n- Let's do pair programming with [MODE]\n- Check-ins every [15/30] minutes\n- Any questions before we start?\"\n```\n\n**Claude responds**:\n```\n\"I understand. Let me confirm:\n- Goal: [RESTATED]\n- Approach: [RESTATED]\n- I'll suggest [ROLE], you [ROLE]\n- Ready to begin?\"\n```\n\n**Checklist**:\n- [ ] Goals aligned\n- [ ] Approach agreed\n- [ ] Roles clear\n- [ ] Check-in schedule set\n\n---\n\n## ğŸ› ï¸ Phase 5: Set Up Environment (2 min)\n\n```bash\n# Start dev server (if needed)\nnpm run dev  # or: python app.py\n\n# Start test watcher for TDD\nnpm test -- --watch  # or: pytest-watch\n\n# Open relevant files in editor\ncode .ai-workspace/tasks/active/ACTIVE_TASKS.md\ncode .ai-workspace/session/current_session.md\n```\n\n**Checklist**:\n- [ ] Dev server running\n- [ ] Test watcher running\n- [ ] Key files open\n- [ ] Ready to code\n\n---\n\n## ğŸ§­ Phase 6: Choose Working Mode (1 min)\n\n**Select ONE**:\n\n### ğŸ”´ TDD Mode (RED â†’ GREEN â†’ REFACTOR)\n- [ ] Write failing test FIRST\n- [ ] Minimal code to pass\n- [ ] Refactor for quality\n- [ ] Commit with test metrics\n\n### ğŸ› Bug Fix Mode\n- [ ] Reproduce bug\n- [ ] Write failing test that exposes bug\n- [ ] Fix bug to make test pass\n- [ ] Verify no regression\n\n### ğŸ” Exploration Mode\n- [ ] Research and investigate\n- [ ] Document findings\n- [ ] Create todos for follow-up\n- [ ] No code commits (research only)\n\n### ğŸ¤ Pair Programming Mode\n- [ ] Roles clear (driver/navigator)\n- [ ] Check-ins every 15 min\n- [ ] TodoWrite tracking active\n- [ ] Communication continuous\n\n---\n\n## âœ… Ready to Begin!\n\n**Final Checklist**:\n- [ ] Current state checked\n- [ ] Methodology reviewed\n- [ ] Goals set\n- [ ] Aligned with Claude\n- [ ] Environment ready\n- [ ] Working mode chosen\n\n**Time Taken**: ~10 minutes\n**Time Saved**: Hours of confusion and rework\n\n---\n\n## ğŸš¨ Quick Recovery (If Context Lost)\n\nIf you get lost mid-session, run:\n\n```bash\n# What was I doing?\ngit status\ngit diff\n\n# What's the current task?\ncat .ai-workspace/session/current_session.md\n\n# What's the methodology?\ncat plugins/aisdlc-methodology/docs/principles/KEY_PRINCIPLES.md | head -20\n\n# Recent work?\nls -lt .ai-workspace/tasks/finished/ | head -3\n```\n\nThen ask Claude:\n```\n\"I lost context. Can you help me understand:\n1. What task are we working on?\n2. What phase of TDD are we in?\n3. What should I do next?\"\n```\n\n---\n\n**Remember**: 10 minutes at session start saves hours of confusion!\n",
        "claude-code/.claude-plugin/plugins/aisdlc-methodology/templates/.ai-workspace/templates/deprecated/SESSION_TEMPLATE.md": "# Current Session\n\n**Session ID**: session-{YYYY-MM-DD-HH-MM}\n**Started**: {YYYY-MM-DD HH:MM}\n**Developer**: {name}\n**AI Assistant**: Claude Code\n\n---\n\n## Session Goals\n\n### Primary Goals\n- [ ] Goal 1\n- [ ] Goal 2\n\n### Secondary Goals\n- [ ] Goal 1\n\n### Stretch Goals\n- [ ] If time permits\n\n---\n\n## Current Focus\n\n**Active Task**: [Task ID] - [Task Name]\n**Status**: [Not Started / In Progress / Blocked]\n**TDD Phase**: [RED / GREEN / REFACTOR]\n**Feature Flag**: [flag-name] or N/A\n\n**Requirements**:\n- REQ-X-Y-Z: [Description]\n\n---\n\n## Session Timeline\n\n### [TIME] - Session Start\n- Ran `git status`\n- Reviewed ACTIVE_TASKS.md\n- Set goals\n\n### [TIME] - Check-in #1\n- **Phase**:\n- **Progress**:\n- **Status**:\n- **Next**:\n\n*(Add check-ins every 15-30 minutes)*\n\n---\n\n## Pair Programming State\n\n**Mode**: [Active / Solo / Research]\n**Driver**: [Human / Claude]\n**Navigator**: [Claude / Human]\n\n**Interaction Pattern**:\n- [Notes on collaboration style]\n\n---\n\n## Decisions Made\n\n### [TIME] - [Decision Name]\n**Decision**:\n**Alternative**:\n**Rationale**:\n**Approved By**:\n\n---\n\n## Context for Next Session\n\n**State to Preserve**:\n- Feature flag: [status]\n- Branch: [name]\n- Test coverage: [percentage]\n\n**Recovery Instructions**:\n```bash\ngit status\ncat .ai-workspace/tasks/active/ACTIVE_TASKS.md\n```\n\n---\n\n## Notes & Observations\n\n- [Key learnings, insights, or observations]\n\n---\n\n*Last Updated: {TIMESTAMP}*\n",
        "testmkt/plugins/hello-world/.claude-plugin/plugin.json": "{\n  \"name\": \"hello-world\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Simple test plugin\",\n  \"author\": {\n    \"name\": \"test\"\n  }\n}\n",
        "testmkt/plugins/hello-world/commands/hello.md": "Say \"Hello from test plugin!\" to the user.\n"
      },
      "plugins": [
        {
          "name": "hello-world",
          "source": "./testmkt/plugins/hello-world",
          "description": "Simple test plugin",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add foolishimp/ai_sdlc_method",
            "/plugin install hello-world@aisdlc"
          ]
        },
        {
          "name": "aisdlc-methodology",
          "source": "./claude-code/.claude-plugin/plugins/aisdlc-methodology",
          "description": "Complete AI SDLC methodology with 7-stage lifecycle, skills, agents, and commands",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add foolishimp/ai_sdlc_method",
            "/plugin install aisdlc-methodology@aisdlc"
          ]
        }
      ]
    }
  ]
}