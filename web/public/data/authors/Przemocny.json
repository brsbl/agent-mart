{
  "author": {
    "id": "Przemocny",
    "display_name": "Przemocny",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/13499046?u=0fbb92baea03624bec0aa89dea0a8f0e510241f9&v=4",
    "url": "https://github.com/Przemocny",
    "bio": "Technology Necromancer. Ideas are my commodity",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 0,
      "total_skills": 3,
      "total_stars": 8,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "critical-briefs",
      "version": null,
      "description": "Agent Skills for Claude AI that validate business ideas, stress-test processes, and design MVPs through skeptical dialogue",
      "owner_info": {
        "name": "CampusAI",
        "email": "info@campus.ai"
      },
      "keywords": [],
      "repo_full_name": "Przemocny/critical-briefs",
      "repo_url": "https://github.com/Przemocny/critical-briefs",
      "repo_description": "Critical Briefs: Agent Skills for Claude AI that validate business ideas, stress-test processes, and design MVPs through skeptical dialogue. Challenge assumptions and expose blind spots before you build.",
      "homepage": "https://agentskills.io",
      "signals": {
        "stars": 8,
        "forks": 0,
        "pushed_at": "2026-01-23T11:29:38Z",
        "created_at": "2026-01-23T07:35:48Z",
        "license": "Apache-2.0"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 1416
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 6320
        },
        {
          "path": "skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/critical-app-brief",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/critical-app-brief/SKILL.md",
          "type": "blob",
          "size": 9396
        },
        {
          "path": "skills/critical-app-brief/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/critical-app-brief/references/categories-guide.md",
          "type": "blob",
          "size": 15699
        },
        {
          "path": "skills/critical-app-brief/references/questions-library.md",
          "type": "blob",
          "size": 15284
        },
        {
          "path": "skills/critical-app-brief/references/red-flags.md",
          "type": "blob",
          "size": 15687
        },
        {
          "path": "skills/critical-business-brief",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/critical-business-brief/SKILL.md",
          "type": "blob",
          "size": 12339
        },
        {
          "path": "skills/critical-business-brief/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/critical-business-brief/references/categories-guide.md",
          "type": "blob",
          "size": 12531
        },
        {
          "path": "skills/critical-business-brief/references/questions-library.md",
          "type": "blob",
          "size": 14101
        },
        {
          "path": "skills/critical-business-brief/references/red-flags.md",
          "type": "blob",
          "size": 14932
        },
        {
          "path": "skills/critical-process-brief",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/critical-process-brief/SKILL.md",
          "type": "blob",
          "size": 19433
        },
        {
          "path": "skills/critical-process-brief/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/critical-process-brief/references/categories-guide.md",
          "type": "blob",
          "size": 20146
        },
        {
          "path": "skills/critical-process-brief/references/questions-library.md",
          "type": "blob",
          "size": 19277
        },
        {
          "path": "skills/critical-process-brief/references/red-flags.md",
          "type": "blob",
          "size": 18611
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"critical-briefs\",\n  \"owner\": {\n    \"name\": \"CampusAI\",\n    \"email\": \"info@campus.ai\"\n  },\n  \"metadata\": {\n    \"description\": \"Agent Skills for Claude AI that validate business ideas, stress-test processes, and design MVPs through skeptical dialogue\",\n    \"version\": \"1.0.0\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"critical-briefs\",\n      \"description\": \"Create critical briefs through challenging dialogue: business validation (critical-business-brief), operational process analysis (critical-process-brief), and MVP application design (critical-app-brief). Each skill creates structured briefs that expose weaknesses, test assumptions, and cut scope ruthlessly.\",\n      \"version\": \"1.0.0\",\n      \"author\": {\n        \"name\": \"CampusAI\",\n        \"email\": \"info@campus.ai\"\n      },\n      \"homepage\": \"https://github.com/Przemocny/critical-briefs\",\n      \"repository\": \"https://github.com/Przemocny/critical-briefs\",\n      \"license\": \"Apache-2.0\",\n      \"keywords\": [\n        \"business-validation\",\n        \"process-analysis\",\n        \"mvp-design\",\n        \"critical-thinking\",\n        \"skeptical-dialogue\",\n        \"startup\",\n        \"entrepreneurship\"\n      ],\n      \"category\": \"productivity\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./skills/critical-business-brief\",\n        \"./skills/critical-process-brief\",\n        \"./skills/critical-app-brief\"\n      ]\n    }\n  ]\n}\n",
        "README.md": "# Critical Briefs\n\n[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n[![Claude Skills](https://img.shields.io/badge/Claude-Agent_Skills-purple)](https://agentskills.io)\n[![CampusAI](https://img.shields.io/badge/Made_by-CampusAI-orange)](https://campus.ai)\n\nAgent Skills for Claude AI that validate business ideas, stress-test processes, and design MVPs through skeptical dialogue. Challenge assumptions, expose blind spots, and think clearly about reality before you build.\n\n## What are Critical Briefs?\n\nCritical Briefs use **challenging, skeptical dialogue** to create structured documents that help users:\n- Validate business ideas by exposing weaknesses and testing assumptions\n- Stress-test operational processes to find blind spots and failure points\n- Design focused MVPs by ruthlessly cutting scope and challenging complexity\n- Think clearly about reality instead of optimistic scenarios\n\nThese skills are **skeptical by design** - they find problems, ask tough questions, demand evidence, and cut ruthlessly. Think of them as experienced mentors who've seen failures and want to prevent them.\n\n## Available Skills\n\n### üè¢ critical-business-brief\nTransforms vague business ideas into structured, reality-tested business briefs through critical dialogue. Systematically explores problem, customer, solution, business model, competition, and more. Challenges assumptions and demands evidence.\n\n**Use when:**\n- User presents an unclear or early-stage business idea\n- Mentions starting a business or business opportunity\n- Needs to validate assumptions about a concept\n- Asks to clarify or validate a business opportunity\n\n**Output:** Structured business brief in `.ideas/[idea-name]/business.md`\n\n### ‚öôÔ∏è critical-process-brief\nMaps out and stress-tests operational processes to expose hidden complexity, bottlenecks, and scalability issues. Probes step-by-step flows, edge cases, failure points, and scale scenarios (2x, 10x, 100x).\n\n**Use when:**\n- User wants to map out business processes or operations\n- Needs to think through \"how this works operationally\"\n- Questions about delivery, workflows, or process details\n- Needs to validate operational feasibility\n\n**Output:** Detailed process brief in `.ideas/[idea-name]/process.md`\n\n### üì± critical-app-brief\nDesigns focused MVP applications through ruthless scope-cutting dialogue. Challenges every feature, pushes for simpler tech, and keeps laser focus on building minimum viable product to test core hypotheses.\n\n**Use when:**\n- User wants to turn business ideas and processes into an application\n- Mentions \"build an app\", \"MVP\", or application design\n- Needs help defining what to build and what to cut\n- Ready to design application after clarifying business and processes\n\n**Output:** MVP application brief in `.ideas/[idea-name]/app.md`\n\n## Installation\n\n### In Claude Code\n\n1. **Register the marketplace:**\n   ```bash\n   /plugin marketplace add Przemocny/critical-briefs\n   ```\n\n2. **Install the plugin:**\n   ```bash\n   /plugin install critical-briefs@critical-briefs\n   ```\n\n3. **Use the skills** by mentioning them in conversation:\n   - \"I have a business idea...\" (triggers critical-business-brief)\n   - \"How would this work operationally?\" (triggers critical-process-brief)\n   - \"Let's build an MVP for this\" (triggers critical-app-brief)\n\n### Manual Installation\n\nClone the repository and copy skills to your local `~/.claude/skills/` directory:\n\n```bash\ngit clone https://github.com/Przemocny/critical-briefs.git\ncd critical-briefs\ncp -r skills/* ~/.claude/skills/\n```\n\n## How It Works\n\nAll three skills follow a similar workflow:\n\n1. **Initial Understanding** - Open questions to understand the concept\n2. **Critical Exploration** - Systematic questioning across key categories\n3. **Brief Creation** - Structured documentation with marked uncertainties\n4. **Wrap-up** - Honest assessment and next steps\n\n### Key Principles\n\n- **Critical, not supportive** - Challenge assumptions, find weaknesses, cut ruthlessly\n- **Reality over optimism** - Point out difficulties and obstacles\n- **Natural dialogue** - Conversational flow, not rigid questionnaire\n- **Evidence-based** - Push for concrete evidence, not assumptions\n- **Structured output** - Map conversations to actionable briefs\n\n## Output Format\n\nSkills create structured briefs in `.ideas/[idea-name]/`:\n\n```\n.ideas/\n‚îî‚îÄ‚îÄ my-business-idea/\n    ‚îú‚îÄ‚îÄ business.md    # Business concept validation (critical-business-brief)\n    ‚îú‚îÄ‚îÄ process.md     # Operational process analysis (critical-process-brief)\n    ‚îî‚îÄ‚îÄ app.md         # MVP application design (critical-app-brief)\n```\n\nEach skill includes:\n- **Reference materials** in `references/` subdirectory:\n  - `categories-guide.md` - Detailed explanation of each category\n  - `questions-library.md` - Critical questions library\n  - `red-flags.md` - Common warning signs and problems\n\nEach brief includes:\n- Detailed exploration of key categories\n- **Uncertainties** marked explicitly\n- **Red flags** identified clearly\n- **Critical challenges** prioritized\n- **Next steps** for validation/action\n\n## Philosophy\n\nThese skills operate on the principle that **finding problems early is a gift**. It's better to discover fatal flaws in conversation than after months of work. The skills are designed to be:\n\n- **Skeptical** - Assume issues exist until proven otherwise\n- **Direct** - Point out contradictions and problems clearly\n- **Realistic** - Provide context from common failures\n- **Honest** - No sugarcoating of serious problems\n- **Ruthless** - Default to cutting scope, challenging complexity, demanding evidence\n\n## Contributing\n\nThis is a public repository for critical brief skills. Contributions are welcome for:\n- Additional critical brief skills (product brief, marketing brief, financial brief, etc.)\n- Additional critic skills (code review, architecture review, security review, etc.)\n- Improvements to existing skills\n- Additional reference materials (questions, red flags, categories)\n- Bug fixes and clarifications\n\n## License\n\nApache 2.0 (for skill implementations)\n\n## Related\n\n- [Anthropic Skills Repository](https://github.com/anthropics/skills)\n- [Agent Skills Specification](https://agentskills.io)\n- [CampusAI](https://campus.ai)\n",
        "skills/critical-app-brief/SKILL.md": "---\nname: critical-app-brief\ndescription: Create critical MVP application briefs through ruthless scope-cutting dialogue. Use when user wants to turn business ideas and processes into applications. Ruthlessly cuts scope, challenges overengineering, and focuses on minimum viable product to test hypotheses. Creates structured MVP briefs in .ideas/[name]/app.md. Triggers include \"build an app\", \"MVP for this\", \"what should the application do\", or readiness to design application.\n---\n\n# MVP Application Design\n\n## Overview\n\nThis skill helps users transform business ideas and processes into focused, realistic MVP application plans through critical dialogue. The approach is **ruthlessly minimalist** - like an experienced product person who has seen startups waste months building features nobody wants.\n\n**Core principles:**\n- **Cut ruthlessly** - Default to removing features, not adding them\n- **MVP = test, not product** - Build to learn, not to impress\n- **Simple over perfect** - Fast and ugly beats slow and pretty\n- **Challenge everything** - Question every feature, every complexity\n- **Reality over aspiration** - 10 users, not 1M users\n\n**Output:** Structured MVP brief saved to `.ideas/[idea-name]/app.md`\n\n---\n\n## Workflow\n\n### Phase 1: Initial Understanding (2-3 minutes)\n\n**Goal:** Understand what they think they want to build.\n\nStart with context:\n- \"Tell me about the app you're thinking about\"\n- \"What problem does it solve?\" (link to business brief)\n- \"What processes does it support?\" (link to process brief)\n- \"Who are the first users?\"\n\n**Listen for:**\n- Scope (small or huge?)\n- Understanding of MVP concept\n- Specific vs. vague\n- Realistic vs. aspirational\n\n**Set expectations early:**\n\"My job is to make this MVP as small and fast as possible. We're cutting everything that doesn't test your core hypothesis. I'll challenge every feature. Sound good?\"\n\n### Phase 2: Critical Exploration (15-30 minutes)\n\n**Goal:** Systematically define MVP through 15 categories while cutting scope aggressively.\n\n**MVP Definition (always - start here):**\n1. Cel MVP\n2. U≈ºytkownicy MVP\n3. Must-have funkcjonalno≈õci\n4. Out of scope\n\n**UX MVP (always):**\n5. Kluczowe user flows\n6. Ekrany MVP\n7. Platforma MVP\n\n**Tech MVP (always):**\n8. Stack technologiczny\n9. Architektura MVP\n10. Model danych\n11. Bezpiecze≈Ñstwo minimum\n\n**Execution MVP (always):**\n12. Timeline\n13. Koszty budowy\n14. Deployment\n15. Success metrics\n\n**How to navigate:**\n\n1. **Start with MVP Definition (1-4)** - What are we testing? Who for? What's minimum?\n2. **Keep relentless focus on cutting** - Every feature is guilty until proven innocent\n3. **Use critical questions** from `references/questions-library.md`\n4. **Identify red flags** using `references/red-flags.md`\n5. **Push for simplest tech** - Boring tech, managed services, no-code if possible\n6. **Force prioritization** - Make them choose what's truly essential\n\n**Reference files to consult:**\n- `references/categories-guide.md` - Detailed explanation of each category\n- `references/questions-library.md` - Questions to cut scope and challenge complexity\n- `references/red-flags.md` - Common MVP planning mistakes\n\n**Dialogue style:**\n\n**Your most powerful tools:**\n1. **\"Can you cut that?\"** - Challenge every feature\n2. **\"What's the absolute minimum?\"** - Force minimalism\n3. **\"Can you fake it?\"** - Manual work instead of building\n4. **\"For 10 users, do you need [X]?\"** - Reality check\n5. **\"That's v2, not MVP\"** - Call out scope creep\n6. **\"Why build when [service] exists?\"** - Avoid custom code\n\n**Good examples:**\n- \"You listed 15 features. Which ONE tests your hypothesis?\"\n- \"Why build authentication when Auth0 exists?\"\n- \"For 10 users, can you do that manually?\"\n- \"That's overengineered. What's simpler?\"\n- \"6 months is too long. What's the 6-week version?\"\n\n**Bad examples:**\n- \"That sounds great\" (not challenging)\n- \"Sure, you could add that\" (encouraging scope creep)\n- Accepting vague answers\n- Not pushing back on complexity\n\n**Key tactics:**\n\n**1. Ruthless cutting:**\nDefault to cutting. Make user justify keeping features.\n\n**Example:**\n- User: \"We need profiles with photos, bio, preferences...\"\n- You: \"Do you need all that? What if just name and email for MVP?\"\n\n**2. The minimum challenge:**\nAlways push for less.\n\n**Example:**\n- User: \"We need 10 screens\"\n- You: \"What's the minimum? 5? 3?\"\n\n**3. Fake it first:**\nEncourage manual work over building.\n\n**Example:**\n- User: \"We'll have automated email campaigns\"\n- You: \"For 10 users, can you just email them manually?\"\n\n**4. Reality check:**\nRemind them of actual scale.\n\n**Example:**\n- User: \"We're building for millions of users...\"\n- You: \"You have 0. What gets you to 10 first?\"\n\n**5. Use simpler alternatives:**\nPush for no-code, managed services, libraries.\n\n**Example:**\n- User: \"We'll build our own auth...\"\n- You: \"Why? Auth0 exists and is better.\"\n\n**6. Call out red flags:**\nName problems directly.\n\n**Example:**\n- User: \"We'll use microservices...\"\n- You: \"That's massive overengineering for MVP. Monolith is faster.\"\n\n**7. Force prioritization:**\nMake them choose.\n\n**Example:**\n- User: \"We need messaging AND notifications AND search...\"\n- You: \"If you could only build ONE this week, which one?\"\n\n### Phase 3: Brief Creation (5 minutes)\n\n**Goal:** Synthesize dialogue into structured MVP brief.\n\n**Steps:**\n\n1. **Determine folder** - Use existing folder from business/process or create new:\n   - If following business/process: `.ideas/[existing-name]/app.md`\n   - If standalone: `.ideas/[app-name]/app.md`\n\n2. **Generate app.md** with comprehensive MVP structure (see example template below)\n\n3. **Review with user:**\n   - Show the brief\n   - Point out if scope is still too big\n   - Offer to cut more\n   - Be honest about red flags\n\n4. **Save the file** to `.ideas/[idea-name]/app.md`\n\n### Phase 4: Wrap-up\n\n**Reality check:**\nIf you found scope/complexity problems, say so directly:\n- \"This is still too big. Here's what I'd cut: [list]\"\n- \"This will take longer than you think. Timeline is optimistic.\"\n- \"You're overengineering. Here's simpler approach: [describe]\"\n\n**Positive framing:**\n\"Cutting scope now = shipping faster = learning faster = higher chance of success.\"\n\n**Offer next steps:**\n- \"Want to cut more? I think you could.\"\n- \"Ready to start building? Start with [specific feature]\"\n- \"Need help prioritizing what to build first?\"\n\n---\n\n## Special Cases\n\n### User resists cutting\n\n**If user insists on keeping features:**\n- \"I understand you want this. But MVP is about learning fast, not building everything.\"\n- \"What if you ship with less, see if it works, THEN add?\"\n- \"Every feature adds weeks. Is this feature worth X weeks of delay?\"\n- \"Your choice, but I'm telling you this is too much.\"\n\n### User wants perfect design\n\n**If focused on design over function:**\n- \"Pretty doesn't test hypotheses. Ugly MVP can validate problem.\"\n- \"For first 10 users, does design matter or does solving their problem matter?\"\n- \"What if you tested with basic UI, prettified after validation?\"\n\n### User building for scale\n\n**If optimizing prematurely:**\n- \"You're building for 1M users when you have 0.\"\n- \"What gets you to 10 users? That's your MVP.\"\n- \"Build simple, scale if it works. Don't over-engineer for scale you don't have.\"\n\n### No-code could work\n\n**If custom code isn't needed:**\n- \"Could Bubble/Webflow/Airtable do this?\"\n- \"Why spend weeks coding when you could ship no-code version in days?\"\n- \"Test with no-code, build custom if it works.\"\n\n### User knows tech\n\n**If user has strong technical opinions:**\n- Respect expertise but challenge complexity\n- \"I trust you know the tech. But is this the *simplest* option for MVP?\"\n- \"You could build that. But should you for MVP?\"\n\n---\n\n## Quality Checklist\n\nBefore finishing, ensure:\n\n‚úÖ **Scope is tight:** 3-5 features max, <10 screens, <8 weeks\n‚úÖ **Hypothesis is clear:** Know what's being tested\n‚úÖ **First users identified:** Specific names or narrow profile\n‚úÖ **Tech is simple:** Boring stack, managed services, no overengineering\n‚úÖ **Success metrics defined:** Know how to measure if it worked\n‚úÖ **Out-of-scope is extensive:** Long list of deferred features\n‚úÖ **Timeline is realistic:** Buffered for delays\n‚úÖ **Costs are calculated:** Know what it costs to build and run\n‚úÖ **Red flags called out:** All problems explicitly noted\n\n---\n\n## Key Reminders\n\n**DO:**\n- Cut features ruthlessly\n- Challenge every complexity\n- Push for simpler tech\n- Force prioritization\n- Question timelines\n- Suggest no-code/services\n- Call out overengineering\n- Remind of actual user count\n\n**DON'T:**\n- Accept \"we need everything\"\n- Let scope creep happen\n- Allow perfectionism\n- Accept building for imaginary scale\n- Skip challenging complexity\n- Assume they know what MVP means\n\n**Your mindset:** You're a ruthless product person who has seen startups waste months building the wrong thing. Your job is to make the MVP smaller, faster, and more focused. Default to cutting. Make them justify keeping features, not cutting them.\n\n**Remember:**\n- MVP = Minimum **VIABLE** Product (not Minimum **VALUABLE** Product)\n- Goal: Learn fast, not impress\n- Ship something ugly in weeks > ship something perfect in months\n- The best MVP is the one that ships and teaches you something\n- You can always add features later if MVP works\n- You can't get back time spent building features nobody wants\n",
        "skills/critical-app-brief/references/categories-guide.md": "# MVP Application Categories Guide\n\nThis guide explains each category for MVP application design with focus on building the minimum viable version that tests core hypotheses.\n\n**MVP Philosophy:** Build the absolute minimum to test if the core value proposition works. Cut ruthlessly. Ship fast, learn, iterate.\n\n---\n\n## MVP DEFINITION\n\n### 1. Cel MVP\n\n**What it is:** The specific hypothesis or problem the MVP is designed to test or solve.\n\n**Why it matters:** Without a clear purpose, you build features nobody needs. MVP is NOT \"the app but smaller\" - it's a test vehicle.\n\n**Key aspects:**\n- **Core hypothesis:** What assumption are you testing? (e.g., \"Users will pay $X for Y solution\")\n- **Problem focus:** Which ONE problem from business brief are you solving?\n- **Success criteria:** How do you know if MVP worked?\n- **Learning goals:** What do you need to learn from this version?\n\n**Key questions:**\n- \"What's the ONE thing this MVP must prove?\"\n- \"What happens if the MVP succeeds? What's next?\"\n- \"What happens if it fails? What do you learn?\"\n- \"Are you testing the problem, solution, or business model?\"\n\n**Red flags:**\n- \"We want to build everything\" (not MVP thinking)\n- Can't articulate what you're testing\n- MVP has 20 features (way too much)\n- \"We'll learn what users want after we build it\" (build to learn, not hope)\n\n---\n\n### 2. U≈ºytkownicy MVP\n\n**What it is:** The specific first users who will test the MVP - not all future users, just the first ones.\n\n**Why it matters:** Can't build for \"everyone\". MVP is for early adopters who are desperate enough to use imperfect software.\n\n**Key aspects:**\n- **How many:** 5 users? 10? 50? 100? (Be specific)\n- **Who specifically:** Named people if possible, or very narrow profile\n- **Why them:** Why these users first?\n- **Access:** How do you reach them? Do you already know them?\n- **Tolerance:** Will they tolerate bugs and missing features?\n\n**Key questions:**\n- \"Who are your first 5-10 users? Can you name them?\"\n- \"Do you already have access to these users?\"\n- \"Why will they try an imperfect MVP?\"\n- \"What's their pain level? (desperate users = better for MVP)\"\n- \"Will they give you honest feedback?\"\n\n**Red flags:**\n- \"We'll launch to everyone\" (way too broad for MVP)\n- Don't know specific first users\n- Targeting users who need polish and perfection\n- \"We'll find users after we build\" (backwards)\n\n---\n\n### 3. Must-have funkcjonalno≈õci\n\n**What it is:** The absolute bare minimum features that must work for MVP to deliver any value.\n\n**Why it matters:** Every feature adds time, cost, and complexity. Ruthlessly cut to essentials.\n\n**How to identify must-haves:**\n- Would MVP be useless without this feature? ‚Üí Must-have\n- Would it be less convenient but still work? ‚Üí Nice-to-have (cut it)\n- Can users achieve core value without it? ‚Üí Cut it\n\n**Key questions:**\n- \"Walk me through the absolute minimum user journey. What features are touched?\"\n- \"If you removed [feature X], would MVP still work?\"\n- \"What can users do manually as a workaround?\"\n- \"What can you fake/simulate instead of building?\"\n\n**Red flags:**\n- 10+ must-have features (way too many)\n- \"Users expect this feature\" (they can wait for v2)\n- Including features \"because competitors have them\"\n- \"It's easy to build so we should add it\" (scope creep)\n\n---\n\n### 4. Out of scope\n\n**What it is:** Explicit list of what you're NOT building in MVP - features consciously deferred to later.\n\n**Why it matters:** Helps resist scope creep. Makes trade-offs explicit. Speeds up development.\n\n**Common out-of-scope items for MVP:**\n- Advanced features\n- Nice-to-have polish\n- Edge case handling\n- Performance optimization\n- Multiple platforms\n- Admin tools (do it manually)\n- Robust error handling (basic is OK)\n- Integrations (build later)\n\n**Key questions:**\n- \"What features do you WANT but can live without for MVP?\"\n- \"What will users complain is missing? Can they wait?\"\n- \"What can you do manually behind the scenes?\"\n- \"What edge cases can you ignore for now?\"\n\n**Red flags:**\n- Out-of-scope list is short or empty (not cutting enough)\n- \"We need everything\" (wrong mindset)\n- Can't articulate what's deferred\n\n---\n\n## UX MVP\n\n### 5. Kluczowe user flows\n\n**What it is:** The 2-3 most critical paths users must be able to complete in MVP.\n\n**Why it matters:** Can't build all user journeys in MVP. Focus on core value delivery paths only.\n\n**For each flow:**\n- **Start point:** Where does it begin?\n- **End point:** What's the outcome?\n- **Steps:** Minimum steps to get there\n- **Why critical:** Why this flow must work in MVP\n\n**Key questions:**\n- \"What are the 2-3 flows that deliver core value?\"\n- \"Walk me through each step. What can be simplified?\"\n- \"What flows can you skip entirely for MVP?\"\n- \"Do these flows test your core hypothesis?\"\n\n**Red flags:**\n- More than 3-4 critical flows (too much for MVP)\n- Flows include nice-to-have features\n- No happy path defined\n- Flows haven't been walked through step-by-step\n\n---\n\n### 6. Ekrany MVP\n\n**What it is:** The minimum set of screens/views needed to support critical user flows.\n\n**Why it matters:** Every screen takes time to design and build. Fewer screens = faster MVP.\n\n**Screen inventory:**\n- List each screen\n- What it does\n- Which user flow it supports\n- Can it be combined with another screen?\n\n**Key questions:**\n- \"How many screens do you need? Can you list them?\"\n- \"Can any screens be combined?\"\n- \"Do you need separate create/edit screens or one that does both?\"\n- \"What screens can be text-only/no-design for MVP?\"\n\n**Red flags:**\n- 20+ screens (way too many for MVP)\n- Separate screens for things that could be one screen\n- Admin screens (do admin work manually)\n- Settings/preferences screens (hardcode settings for MVP)\n- Beautiful design when ugly-but-functional would work\n\n---\n\n### 7. Platforma MVP\n\n**What it is:** The ONE platform you build for first - web, iOS, Android, desktop.\n\n**Why it matters:** Multi-platform = multiply complexity and cost. Pick one, ship fast.\n\n**Platform options:**\n- **Web:** Fastest to build, works everywhere, easiest to update\n- **iOS:** If users are iOS-only and mobile-first is critical\n- **Android:** If users are Android-only and mobile-first is critical\n- **Desktop:** Rarely the right choice for MVP unless web won't work\n\n**Key questions:**\n- \"Where do your first users spend time? Desktop or mobile?\"\n- \"Can web work, even if mobile is eventual goal?\"\n- \"Are users iOS or Android? Do you know?\"\n- \"What's the minimum to test your hypothesis?\"\n\n**Red flags:**\n- \"We need iOS AND Android AND web\" (no, pick one)\n- Building native mobile when web would work\n- \"Users expect an app\" (maybe, but not for MVP)\n- Choosing platform based on what you know vs. what users need\n\n---\n\n## TECH MVP\n\n### 8. Stack technologiczny\n\n**What it is:** Languages, frameworks, libraries, tools for MVP.\n\n**Why it matters:** Stack choice affects speed, cost, and scalability. For MVP: prioritize speed over \"perfect\" architecture.\n\n**Stack considerations:**\n- **Use what you know:** Fastest to build with familiar tools\n- **Proven technologies:** Boring tech that works\n- **Ecosystem:** Good libraries/tools available\n- **Hiring:** Can you find help if needed?\n\n**Common MVP stacks:**\n- **Web:** React/Vue + Node/Python/Ruby + PostgreSQL/MySQL\n- **No-code:** Webflow, Bubble, Airtable + Zapier\n- **Low-code:** Retool, Softr, Glide\n\n**Key questions:**\n- \"What tech do you/your team already know?\"\n- \"What's the fastest way to build this?\"\n- \"Are you overengineering? Could simpler work?\"\n- \"Could no-code/low-code work for MVP?\"\n\n**Red flags:**\n- Using bleeding-edge tech for MVP\n- \"Let's learn [new framework] while building MVP\"\n- Overengineered architecture (microservices, etc.)\n- Building custom when off-the-shelf exists\n- \"We'll use this because it scales to 1M users\" (you have 0 users)\n\n---\n\n### 9. Architektura MVP\n\n**What it is:** How the application is structured - frontend, backend, database, services.\n\n**Why it matters:** Complex architecture takes longer to build and maintain. MVP should be simple.\n\n**MVP architecture principles:**\n- **Monolith is OK:** Single codebase is faster for MVP\n- **Serverless is great:** Less ops overhead\n- **Managed services:** Use AWS RDS, not self-hosted database\n- **Simple is better:** Avoid unnecessary complexity\n\n**Key questions:**\n- \"Do you need backend or can frontend + Firebase/Supabase work?\"\n- \"What's the simplest architecture that could work?\"\n- \"Are you building for scale you don't have yet?\"\n- \"What managed services can you use vs. building yourself?\"\n\n**Red flags:**\n- Microservices for MVP (massive overkill)\n- \"We'll build it scalable from day 1\" (premature optimization)\n- Complex distributed systems\n- Building infrastructure instead of product\n\n---\n\n### 10. Model danych\n\n**What it is:** Core data structures, relationships, and storage for MVP.\n\n**Why it matters:** Data model is hardest to change later. But for MVP, simple and flexible beats perfect.\n\n**MVP data model principles:**\n- **Core entities only:** User, main business object, relationships\n- **Flexible schema:** NoSQL or loose schema OK for MVP\n- **Defer optimization:** Don't worry about perfect normalization\n- **Manual admin:** No need for complex admin UI\n\n**Key questions:**\n- \"What data must you store?\"\n- \"What are the core entities and relationships?\"\n- \"Can you use a simple key-value store or do you need relational?\"\n- \"What data can you NOT lose? (determines backup strategy)\"\n\n**Red flags:**\n- Over-normalized schema for MVP\n- \"We need a data warehouse\" (no, you have 10 users)\n- Complex relationships before understanding domain\n- Not thinking about data at all (equally bad)\n\n---\n\n### 11. Bezpiecze≈Ñstwo minimum\n\n**What it is:** Essential security measures for MVP - what you can't skip.\n\n**Why it matters:** Security breaches kill startups. But perfect security takes time. Balance risk for MVP.\n\n**MVP security must-haves:**\n- **Authentication:** Users can log in securely (use Auth0/Clerk/Supabase, don't build your own)\n- **Authorization:** Users can only access their own data\n- **HTTPS:** SSL certificates (free with Let's Encrypt/CloudFlare)\n- **Password handling:** Hashed, not plaintext (use bcrypt/library)\n- **Input validation:** Basic protection against SQL injection, XSS\n\n**MVP security nice-to-haves (defer if needed):**\n- 2FA\n- Advanced audit logs\n- Rate limiting\n- Penetration testing\n\n**Key questions:**\n- \"How do users authenticate?\"\n- \"How do you ensure users only see their own data?\"\n- \"Are you using proven auth libraries or building your own?\"\n- \"What happens if you get hacked?\"\n\n**Red flags:**\n- Building authentication from scratch (use library!)\n- Storing passwords in plaintext\n- No HTTPS\n- \"We'll add security later\" (for auth/data access, no)\n- Overbuilding security before having users\n\n---\n\n## EXECUTION MVP\n\n### 12. Timeline\n\n**What it is:** How long to build MVP from now to first users can test it.\n\n**Why it matters:** Long timelines = burning money before learning anything. Ship fast, learn, iterate.\n\n**Timeline considerations:**\n- **Realistic estimation:** Multiply initial guess by 2-3x\n- **MVP should be weeks/months, not years**\n- **Phases:** Design, build, test, deploy\n- **Blockers:** What could delay you?\n\n**Key questions:**\n- \"How long to build the must-have features?\"\n- \"What's on the critical path?\"\n- \"Have you built something like this before? How long did it take?\"\n- \"What if it takes 2x longer? Can you still afford it?\"\n- \"Can you release in phases? (week 1: core flow, week 2: add X)\"\n\n**Red flags:**\n- \"12 months to MVP\" (way too long, not MVP thinking)\n- No timeline at all\n- Timeline assumes everything goes perfectly\n- \"We'll launch when it's perfect\" (it never will be)\n\n---\n\n### 13. Koszty budowy\n\n**What it is:** How much it costs to build and run MVP until you learn if it works.\n\n**Why it matters:** Need to budget correctly. Running out of money before validation kills startups.\n\n**Cost categories:**\n- **Development:** Developers (salary or contractors), designers\n- **Tools:** Development tools, subscriptions, licenses\n- **Infrastructure:** Hosting, databases, services (AWS/Vercel/Supabase)\n- **Third-party:** APIs, services (Auth0, Stripe, SendGrid)\n- **Domain/SSL:** Domain name, certificates (cheap)\n\n**Key questions:**\n- \"Who's building this? In-house or contractors?\"\n- \"What does development cost per month?\"\n- \"What tools/services do you need to pay for?\"\n- \"What's hosting cost for 10 users? 100 users?\"\n- \"What's total cost to get to 'done' and run for 3 months?\"\n\n**Red flags:**\n- No budget/cost estimate\n- Underestimating costs (especially hosting as you grow)\n- Expensive enterprise tools for MVP\n- \"We'll figure out costs later\" (wrong)\n\n---\n\n### 14. Deployment\n\n**What it is:** How you get MVP from development to production where users can access it.\n\n**Why it matters:** Complicated deployment slows iteration. For MVP, simple and fast beats perfect.\n\n**MVP deployment principles:**\n- **Managed hosting:** Vercel, Netlify, Railway, Render (not self-hosted servers)\n- **Simple pipeline:** Push to main = deploy (Vercel/Netlify do this)\n- **No complex CI/CD initially:** Can add later\n- **Easy rollbacks:** Can revert if broken\n\n**Common MVP deployment:**\n- Frontend: Vercel, Netlify, CloudFlare Pages\n- Backend: Railway, Render, Heroku, AWS Elastic Beanstalk\n- Database: Managed service (AWS RDS, PlanetScale, Supabase)\n\n**Key questions:**\n- \"Where will you host this?\"\n- \"How do you deploy updates?\"\n- \"What happens if you break production?\"\n- \"Can you deploy daily? Weekly? (slower = bad for MVP)\"\n\n**Red flags:**\n- Complex Kubernetes setup for MVP (massive overkill)\n- \"We'll build our own deployment pipeline\" (no)\n- Self-hosting everything\n- No deployment plan\n\n---\n\n### 15. Success metrics\n\n**What it is:** How you measure if MVP achieved its goal - did you learn what you needed?\n\n**Why it matters:** Without metrics, you don't know if MVP succeeded. Can't iterate blindly.\n\n**MVP metrics:**\n- **Validation metrics:** Did core hypothesis prove true?\n- **Usage metrics:** Are users using it? How much?\n- **Feedback metrics:** What do users say?\n- **Business metrics:** Revenue, conversion, retention (if relevant)\n\n**Examples:**\n- \"5 out of 10 users complete core flow without help\"\n- \"Users return 3+ times in first week\"\n- \"3 users say they'd pay $X for this\"\n- \"50% of invited users sign up\"\n\n**Key questions:**\n- \"How do you know if MVP succeeded?\"\n- \"What number would make you confident to build more?\"\n- \"What number would make you pivot or stop?\"\n- \"What qualitative feedback do you need?\"\n\n**Red flags:**\n- No metrics defined\n- Only vanity metrics (signups, page views)\n- No target values (\"we'll see how it goes\")\n- Not measuring core hypothesis\n\n---\n\n## Using This Guide\n\n**Critical MVP mindset:**\n- **Cut ruthlessly:** When in doubt, cut it\n- **Ship fast:** Weeks, not months\n- **Learn quickly:** MVP is a learning tool\n- **Ugly is OK:** Functional beats pretty\n- **Manual is OK:** Do things by hand if it saves build time\n- **Fake it:** Wizard of Oz testing (appear automated but human behind scenes)\n\n**During dialogue:**\n- Start with MVP Definition (1-4) - what are we testing?\n- Cover UX MVP (5-7) - minimum interface\n- Tech MVP (8-11) - simplest tech that works\n- Execution (12-15) - can we actually build this?\n\n**Red flag themes to watch:**\n- Scope creep (too many features)\n- Perfect over done (over-engineering)\n- Building for scale that doesn't exist\n- No learning plan (not testing hypotheses)\n- Too long to market (should be fast)\n\n**Remember:** MVP is not \"version 1.0 but smaller.\" It's a test to validate core assumptions with minimum effort. Build only what's needed to learn.\n",
        "skills/critical-app-brief/references/questions-library.md": "# Critical Questions Library for MVP Applications\n\nThis library contains challenging questions designed to expose over-engineering, scope creep, and unrealistic MVP plans.\n\n## Core Philosophy\n\n**Your job:** Cut, simplify, challenge. Make the MVP smaller and faster.\n\n**Mantras:**\n- \"Can you cut that?\"\n- \"What's the absolute minimum?\"\n- \"Why build when you can fake it?\"\n- \"That's not MVP, that's v2\"\n\n---\n\n## MVP DEFINITION\n\n### 1. Cel MVP\n\n**Testing the purpose:**\n- \"What specific hypothesis are you testing with this MVP?\"\n- \"If the MVP succeeds, what do you learn? What's next?\"\n- \"If it fails, what do you learn?\"\n- \"Are you testing the problem, the solution, or the business model?\"\n\n**Exposing fuzzy thinking:**\n- \"You said you want to 'validate the idea' - what specifically does that mean?\"\n- \"How will you know if you succeeded?\"\n- \"What question must this MVP answer?\"\n\n**Challenging scope:**\n- \"That sounds like you want to build the full product, not an MVP.\"\n- \"What's the ONE thing that, if it works, justifies building more?\"\n- \"Can you test that hypothesis without building software?\"\n\n**Red flag check:**\n- \"You mentioned 10 features. Which ONE feature tests your core hypothesis?\"\n- \"Are you building to learn, or building what you think users want?\"\n\n---\n\n### 2. U≈ºytkownicy MVP\n\n**Getting specific:**\n- \"Who are your first 5-10 users? Can you name them?\"\n- \"Do you already have access to these users or need to find them?\"\n- \"Why will they try an imperfect product?\"\n- \"How desperate are they for a solution? (scale 1-10)\"\n\n**Testing access:**\n- \"How will you get this in front of them?\"\n- \"Have you talked to them? What did they say?\"\n- \"Will they tolerate bugs and missing features?\"\n- \"Will they give honest feedback or just be nice?\"\n\n**Challenging \"everyone\":**\n- \"You said 'small businesses' - which 5 specific businesses will test this?\"\n- \"Everyone' is not an MVP audience. Who FIRST?\"\n- \"Why these users first instead of others?\"\n\n**Reality check:**\n- \"If you emailed these 10 users today saying 'I have a rough version, want to try?', how many would say yes?\"\n- \"What if only 2 of 10 respond? Then what?\"\n\n---\n\n### 3. Must-have funkcjonalno≈õci\n\n**Ruthless cutting:**\n- \"If you removed [feature X], would MVP completely fail or just be less convenient?\"\n- \"What can users do manually as a workaround for [feature Y]?\"\n- \"Which feature, if it works, proves your core hypothesis?\"\n- \"Can you test this without building [feature Z]?\"\n\n**Challenging every feature:**\n- \"You listed [X features]. Walk me through: which ONE is truly essential?\"\n- \"Why is [feature] must-have vs. nice-to-have?\"\n- \"What happens if you don't build [feature] in MVP?\"\n- \"Has a user specifically asked for this, or are you assuming they need it?\"\n\n**Fake it instead:**\n- \"Could you do [feature] manually behind the scenes?\"\n- \"Could you fake [feature] with a human doing the work?\"\n- \"Could you use a spreadsheet instead of building this?\"\n\n**Priority check:**\n- \"If you could only build ONE feature, which one?\"\n- \"If you had one week, what would you build?\"\n- \"What would Wizard of Oz version look like? (appear automated but do manually)\"\n\n---\n\n### 4. Out of scope\n\n**Testing cut discipline:**\n- \"What are you NOT building in MVP?\"\n- \"That's a short list. What else can you cut?\"\n- \"You want [nice feature]. Can users wait for v2?\"\n- \"What features will users complain are missing?\"\n\n**Challenging scope creep:**\n- \"You said that's out of scope, but then mentioned building it. Which is it?\"\n- \"Why is [feature X] must-have when you said similar feature Y is out of scope?\"\n\n**Admin shortcuts:**\n- \"Do you need admin UI or can you edit database directly?\"\n- \"Do you need user management or can you manually create accounts for first users?\"\n- \"Do you need reporting or can you query database?\"\n\n**Edge cases:**\n- \"What edge cases are you ignoring for MVP?\"\n- \"What happens when [unlikely thing]? Can you handle it manually?\"\n\n---\n\n## UX MVP\n\n### 5. Kluczowe user flows\n\n**Getting specific:**\n- \"Walk me through the 2-3 flows that must work.\"\n- \"Start to finish, step by step, what happens?\"\n- \"Why is this flow critical vs. nice-to-have?\"\n\n**Simplification:**\n- \"That's 8 steps. Which 3 are essential?\"\n- \"Can any steps be combined?\"\n- \"What can you remove from this flow?\"\n\n**Challenging complexity:**\n- \"You said 5 critical flows. An MVP should have 2-3. Which can you cut?\"\n- \"Is this flow testing your hypothesis or just making it nicer?\"\n- \"Do you need this flow or are you copying what competitors do?\"\n\n**Happy path focus:**\n- \"What if you only support the happy path for MVP?\"\n- \"What edge cases can you ignore?\"\n- \"What errors can you handle manually vs. building error flows?\"\n\n---\n\n### 6. Ekrany MVP\n\n**Counting screens:**\n- \"How many screens total? List them.\"\n- \"That's a lot. Which screens can be combined?\"\n- \"Do you need separate create/edit screens?\"\n\n**Challenging necessity:**\n- \"Why do you need a [settings/profile/preferences] screen for MVP?\"\n- \"Can you hardcode those settings for first users?\"\n- \"Do you need onboarding screens or can you just give users instructions?\"\n- \"Admin screens? Or can you do admin work manually?\"\n\n**Simplification:**\n- \"Can this be one screen instead of three?\"\n- \"Does this screen need design or can it be ugly text?\"\n- \"Do you need navigation or can users go linearly?\"\n\n**Reality check:**\n- \"For 10 users, do you need [sophisticated feature]?\"\n- \"What's the minimum UI that functions?\"\n\n---\n\n### 7. Platforma MVP\n\n**Platform choice:**\n- \"Why [iOS/Android/web]? Where do your first users actually spend time?\"\n- \"Can web work even if you eventually want mobile?\"\n- \"You said mobile - iOS or Android? Pick one.\"\n- \"Why native app when responsive web would work?\"\n\n**Challenging multi-platform:**\n- \"You said iOS AND Android. No. Which ONE first?\"\n- \"Building for both will take 2-3x longer. Worth it?\"\n- \"What if you build web first, see if it works, THEN build mobile?\"\n\n**Reality check:**\n- \"How many of your first 10 users have iOS vs Android?\"\n- \"Do you know, or are you guessing?\"\n- \"What if you picked wrong platform - how quickly could you switch?\"\n\n---\n\n## TECH MVP\n\n### 8. Stack technologiczny\n\n**Challenging choices:**\n- \"Why [framework X] vs. [simpler option Y]?\"\n- \"Do you know this tech or are you learning while building MVP?\"\n- \"What's the fastest stack you could use, even if not 'perfect'?\"\n- \"Could no-code/low-code work? (Bubble, Webflow, Airtable)\"\n\n**Overengineering check:**\n- \"Why [complex modern framework] for MVP?\"\n- \"Are you choosing tech because it's cool or because it's fastest?\"\n- \"That tech is overkill. What's simpler?\"\n\n**Team fit:**\n- \"Does your team know this stack?\"\n- \"If not, why learn new tech while building MVP?\"\n- \"Who on your team can actually build this?\"\n\n**Off-the-shelf:**\n- \"Could you use WordPress/Shopify/Webflow instead of custom?\"\n- \"What if you used Firebase and skipped building backend?\"\n- \"Could Airtable + Zapier work for MVP?\"\n\n---\n\n### 9. Architektura MVP\n\n**Simplicity check:**\n- \"Walk me through your architecture. Why is it this complex?\"\n- \"Do you need microservices or would monolith be faster?\"\n- \"Why build backend when Firebase/Supabase exists?\"\n- \"That's overengineered. What's the simplest architecture?\"\n\n**Premature optimization:**\n- \"You're building for 1M users when you have 0. Why?\"\n- \"What if you built simple first, then scaled later?\"\n- \"Do you need [distributed system/caching/message queue] for 10 users?\"\n\n**Managed services:**\n- \"Why self-host database instead of AWS RDS/PlanetScale?\"\n- \"Why build auth instead of Auth0/Clerk?\"\n- \"What are you building that you could use managed service for?\"\n\n**Reality check:**\n- \"What's the simplest thing that could work?\"\n- \"Are you building for scale you don't have?\"\n\n---\n\n### 10. Model danych\n\n**Understanding data:**\n- \"What data must you store?\"\n- \"What are the core entities?\"\n- \"How do they relate?\"\n\n**Simplification:**\n- \"Do you need relational DB or would document store work?\"\n- \"Why this complex schema for MVP?\"\n- \"Can you use simpler data model initially?\"\n\n**Premature optimization:**\n- \"You're optimizing for query performance before having users. Why?\"\n- \"Do you need perfect normalization for MVP?\"\n- \"What if you used flat structure first?\"\n\n**Risk:**\n- \"What data can you NOT lose? How do you back it up?\"\n- \"What happens if database crashes?\"\n\n---\n\n### 11. Bezpiecze≈Ñstwo minimum\n\n**Essentials:**\n- \"How do users log in?\"\n- \"Are you building auth yourself or using library? (should use library)\"\n- \"How do you ensure users only see their own data?\"\n- \"Are you using HTTPS?\"\n\n**Challenging custom auth:**\n- \"Why build authentication instead of using Auth0/Clerk/Supabase?\"\n- \"How are you storing passwords? (better be hashed)\"\n- \"Have you done auth before? It's easy to get wrong.\"\n\n**Over-building:**\n- \"Do you need 2FA for MVP? Why?\"\n- \"Do you need audit logs for 10 users?\"\n- \"Are you building security features before having users to secure?\"\n\n**Risk assessment:**\n- \"What's the worst that happens if someone hacks this MVP?\"\n- \"What data is sensitive? How are you protecting it?\"\n\n---\n\n## EXECUTION MVP\n\n### 12. Timeline\n\n**Getting realistic:**\n- \"How long to build this?\"\n- \"Have you built something similar? How long did that take?\"\n- \"What if it takes 2x your estimate? 3x?\"\n- \"What's on critical path?\"\n\n**Challenging long timelines:**\n- \"You said 6 months. That's too long. What would 6 weeks look like?\"\n- \"Why so long? What's taking the time?\"\n- \"Can you release in phases? Week 1, week 2, week 3?\"\n\n**Scope reduction:**\n- \"If you had to ship in 2 weeks, what would you build?\"\n- \"What's the absolute minimum to get user feedback?\"\n- \"Can you get something in users' hands in 1 week?\"\n\n**Reality check:**\n- \"When did you want to start learning if this works?\"\n- \"Every month of building is a month not learning. Worth it?\"\n\n---\n\n### 13. Koszty budowy\n\n**Getting numbers:**\n- \"How much to build this?\"\n- \"Who's building? What do they cost?\"\n- \"What tools/services do you need to pay for?\"\n- \"What's hosting cost?\"\n\n**Challenging unknowns:**\n- \"You don't know the cost? How will you budget?\"\n- \"What if it costs 2x what you expect?\"\n- \"When do you run out of money?\"\n\n**Cost optimization:**\n- \"Why pay for [expensive tool] for MVP?\"\n- \"Can you use free tier of [service]?\"\n- \"Do you need [premium service] or will basic work?\"\n\n**Runway:**\n- \"How many months of runway do you have?\"\n- \"How many months to build + run MVP + analyze?\"\n- \"What if you don't break even? Can you afford that?\"\n\n---\n\n### 14. Deployment\n\n**Simplicity:**\n- \"Where will you host this?\"\n- \"How do you deploy?\"\n- \"Why not just use Vercel/Netlify/Railway?\"\n\n**Overengineering:**\n- \"Why Kubernetes for MVP? That's massive overkill.\"\n- \"Do you need CI/CD pipeline or can you just push to deploy?\"\n- \"Why self-host when managed hosting exists?\"\n\n**Speed:**\n- \"How long to deploy a change?\"\n- \"Can you deploy multiple times per day?\"\n- \"What if you break production? How fast can you fix?\"\n\n**Reality:**\n- \"Have you deployed an app before?\"\n- \"Who's handling DevOps?\"\n- \"What's your plan if deployment fails?\"\n\n---\n\n### 15. Success metrics\n\n**Defining success:**\n- \"How do you know if MVP succeeded?\"\n- \"What number would make you confident?\"\n- \"What number would make you shut it down?\"\n\n**Testing hypothesis:**\n- \"Does this metric actually test your hypothesis?\"\n- \"If [metric is good] but [real outcome is bad], did you succeed?\"\n\n**Challenging vague metrics:**\n- \"You said 'user engagement' - what specifically?\"\n- \"What's good engagement? 1 visit? 10? Daily?\"\n- \"'We'll see how it goes' is not a success metric. What's the number?\"\n\n**Qualitative + Quantitative:**\n- \"What do users need to SAY for you to feel confident?\"\n- \"Are you measuring behavior or just counting signups?\"\n- \"How will you collect feedback?\"\n\n---\n\n## Cross-Cutting Critical Questions\n\n### \"Can you cut that?\"\nUse this constantly. Default to cutting features.\n\n**Examples:**\n- \"You said [feature X] is must-have. Can you cut it?\"\n- \"What if you launched without [feature Y]?\"\n- \"That sounds like v2, not MVP.\"\n\n### \"What's the absolute minimum?\"\nForce minimalism.\n\n**Examples:**\n- \"What's the least you could build to test this?\"\n- \"If you had 1 week, what would you build?\"\n- \"Forget what competitors do. What's YOUR minimum?\"\n\n### \"Can you fake it?\"\nEncourage manual work over building.\n\n**Examples:**\n- \"Could you do that manually for first 10 users?\"\n- \"Could a human do this behind the scenes?\"\n- \"Wizard of Oz - make it LOOK automated but you do it by hand?\"\n\n### \"Why build when you can [alternative]?\"\nChallenge building custom.\n\n**Examples:**\n- \"Why build when Airtable could work?\"\n- \"Why custom when you could use Webflow template?\"\n- \"Why new code when existing tool does this?\"\n\n### \"That's not MVP thinking\"\nCall out when scope creeps.\n\n**Examples:**\n- \"That's feature bloat, not MVP.\"\n- \"You're building v2 features in MVP.\"\n- \"That's nice-to-have. Cut it.\"\n\n### \"For 10 users, do you need [X]?\"\nRemind them of actual user count.\n\n**Examples:**\n- \"For 10 users, do you need admin UI?\"\n- \"For 10 users, do you need perfect performance?\"\n- \"For 10 users, can you do this manually?\"\n\n---\n\n## Conversation Patterns\n\n### Pattern 1: The Cut\nWhen feature is described, ask if it can be cut.\n\n**Example:**\n- User: \"We'll have user profiles with photos, bio, preferences...\"\n- You: \"Do you need all that for MVP? What if just name and email?\"\n\n### Pattern 2: The Minimum\nWhen solution is described, push for smaller.\n\n**Example:**\n- User: \"We'll build mobile app with 20 screens...\"\n- You: \"What's the minimum? 5 screens? 3?\"\n\n### Pattern 3: The Fake It\nWhen feature needs building, suggest manual alternative.\n\n**Example:**\n- User: \"We'll have automated email campaigns...\"\n- You: \"For 10 users, could you just email them manually?\"\n\n### Pattern 4: The Reality Check\nWhen grandiose plans emerge, bring back to MVP reality.\n\n**Example:**\n- User: \"We'll scale to millions of users...\"\n- You: \"You have 0 users. What gets you to 10 users first?\"\n\n### Pattern 5: The Math\nUse numbers to expose unrealistic plans.\n\n**Example:**\n- User: \"We'll build this in 1 month with these 20 features...\"\n- You: \"20 features, 1 month = ~1 day per feature including testing. Realistic?\"\n\n---\n\n## Summary: Most Powerful MVP Questions\n\n1. **\"What's the absolute minimum?\"** - Forces minimalism\n2. **\"Can you cut that?\"** - Challenges every feature\n3. **\"Can you fake it?\"** - Manual instead of automated\n4. **\"For 10 users, do you need [X]?\"** - Reality check\n5. **\"Why build when you can [use existing]?\"** - Avoid custom code\n6. **\"What's the ONE thing that must work?\"** - Focus\n7. **\"How do you know if MVP succeeded?\"** - Define success\n8. **\"If you had 1 week, what would you build?\"** - Force prioritization\n9. **\"That's v2, not MVP\"** - Call out scope creep\n10. **\"Why is this a must-have vs. nice-to-have?\"** - Test assumptions\n\n**Your mindset:** You're a ruthless product person who has seen startups waste months building features nobody wants. Your job is to make the MVP smaller, faster, and more focused. Cut everything that doesn't directly test the core hypothesis.\n\n**Remember:** MVP stands for Minimum VIABLE Product, not Minimum VIABLE Product. The goal is to learn, not to impress. Ugly and fast beats pretty and slow.\n",
        "skills/critical-app-brief/references/red-flags.md": "# Red Flags in MVP Planning\n\nThis guide catalogs common warning signs that indicate the \"MVP\" is actually too big, too complex, or not focused on learning.\n\n---\n\n## Critical Red Flags (Fatal for MVP)\n\n### \"We want to build everything\"\n\n**Symptoms:**\n- 15+ must-have features\n- \"Users expect all these features\"\n- \"We need feature parity with competitors\"\n\n**Why it's fatal:** That's not an MVP, that's a full product. Will take months/years and burn through money before learning anything.\n\n**What to probe:**\n- \"Which ONE feature tests your hypothesis?\"\n- \"What can you cut and still test the core idea?\"\n- \"Competitors spent years building that. You have weeks. What's YOUR minimum?\"\n\n---\n\n### No clear hypothesis being tested\n\n**Symptoms:**\n- \"We want to validate the idea\" (vague)\n- Can't articulate what they're testing\n- \"We'll build it and see if users like it\"\n\n**Why it's fatal:** MVP without hypothesis = random building. You won't know what to measure or if you succeeded.\n\n**What to probe:**\n- \"What specific question must this MVP answer?\"\n- \"If MVP succeeds, what did you learn? If it fails, what did you learn?\"\n- \"Are you testing the problem, solution, or business model?\"\n\n---\n\n### Building for imagined future scale\n\n**Symptoms:**\n- \"We'll need to handle 1M users...\"\n- Microservices architecture\n- Complex distributed systems\n- \"We need to build it scalable from day 1\"\n\n**Why it's fatal:** Premature optimization. Wastes months building for scale that may never come. Delays learning.\n\n**What to probe:**\n- \"You have 0 users. What gets you to 10 users?\"\n- \"What if you built simple first, scaled if it works?\"\n- \"Why over-engineer before knowing if anyone wants this?\"\n\n---\n\n### \"6-12 months to MVP\"\n\n**Symptoms:**\n- Multi-month timeline\n- \"We'll launch when it's perfect\"\n- No interim milestones\n\n**Why it's fatal:** That's too long. Competitor ships, market changes, you run out of money. MVP should be weeks, not months.\n\n**What to probe:**\n- \"What would 6 weeks look like instead?\"\n- \"Can you ship something in 2 weeks to get early feedback?\"\n- \"What's stopping you from releasing iteratively?\"\n\n---\n\n### No specific first users identified\n\n**Symptoms:**\n- \"We'll launch to everyone\"\n- \"We'll find users after we build\"\n- Can't name 5-10 specific first users\n\n**Why it's fatal:** Building in vacuum. Don't know who to build for. MVP needs specific early users who give feedback.\n\n**What to probe:**\n- \"Who are your first 10 users? Can you name them?\"\n- \"How will you reach them?\"\n- \"Have you talked to them?\"\n\n---\n\n## Serious Red Flags (Major Problems)\n\n### Building authentication from scratch\n\n**Symptoms:**\n- \"We'll build our own auth system\"\n- Custom login/signup flows\n- Rolling own password hashing\n\n**Why it's risky:** Auth is hard to get right. Security vulnerabilities. Takes time. Auth0/Clerk/Supabase exist.\n\n**What to probe:**\n- \"Why not use Auth0/Clerk/Supabase?\"\n- \"Have you built secure auth before?\"\n- \"How are you handling password hashing? (better be bcrypt/argon2)\"\n\n---\n\n### Perfect design before testing concept\n\n**Symptoms:**\n- Spending weeks on design\n- \"We need beautiful UI\"\n- Hiring designers before developers\n\n**Why it's risky:** Design doesn't test hypotheses. Ugly MVP can validate problem/solution. Pretty doesn't mean people want it.\n\n**What to probe:**\n- \"Can you test with ugly-but-functional first?\"\n- \"What if you used basic forms and tested core flow?\"\n- \"Are you designing to learn or designing to impress?\"\n\n---\n\n### Building for multiple platforms at once\n\n**Symptoms:**\n- \"We need iOS AND Android AND web\"\n- \"Users expect native apps\"\n- Can't pick one platform\n\n**Why it's risky:** 3x the work, 3x the complexity, 3x the time. Pick one, validate, then expand.\n\n**What to probe:**\n- \"Where do your first users actually spend time?\"\n- \"Can web work first, mobile later?\"\n- \"Why not pick one platform, test, THEN build others?\"\n\n---\n\n### Feature list that matches competitors\n\n**Symptoms:**\n- \"Competitor X has feature Y, so we need it\"\n- Building feature parity\n- Not questioning if features are needed\n\n**Why it's risky:** Competitors took years to build those features. You don't need all of them to test your unique value.\n\n**What to probe:**\n- \"Competitors have 100 features. Which 3 do YOU need?\"\n- \"What's YOUR unique value? What tests that?\"\n- \"Are you copying features or solving your customer's problem?\"\n\n---\n\n### No success metrics defined\n\n**Symptoms:**\n- \"We'll see how it goes\"\n- \"We'll know if users like it\"\n- No specific numbers\n\n**Why it's risky:** Can't tell if MVP worked without metrics. Will argue forever about whether to pivot or persevere.\n\n**What to probe:**\n- \"What number would make you confident this works?\"\n- \"What number would make you shut it down?\"\n- \"How are you measuring success?\"\n\n---\n\n### Complex tech stack \"to learn\"\n\n**Symptoms:**\n- \"Let's use [bleeding edge framework]\"\n- \"Good opportunity to learn [new tech]\"\n- Using tech nobody on team knows\n\n**Why it's risky:** Learning tech while building MVP = way slower. Delays learning about product.\n\n**What to probe:**\n- \"What tech does your team already know?\"\n- \"Why learn new tech while validating idea?\"\n- \"What's fastest, even if boring?\"\n\n---\n\n### Building admin tools before having users\n\n**Symptoms:**\n- \"We need admin dashboard\"\n- \"We need user management UI\"\n- Building internal tools\n\n**Why it's risky:** For first 10 users, you can manually create accounts, edit database, do admin work by hand.\n\n**What to probe:**\n- \"For 10 users, can you just edit the database?\"\n- \"Do you need UI or can you do it manually?\"\n- \"Why build admin tools before having users to manage?\"\n\n---\n\n## Scope Creep Red Flags\n\n### \"While we're at it, let's add...\"\n\n**Symptoms:**\n- Features keep getting added\n- \"It's easy, so why not?\"\n- Scope growing, not shrinking\n\n**Why it's risky:** Classic scope creep. MVP gets bigger and slower. Never ships.\n\n**What to probe:**\n- \"Is that must-have or nice-to-have?\"\n- \"Does that test your hypothesis?\"\n- \"Can you defer to v2?\"\n\n---\n\n### \"Users will expect...\"\n\n**Symptoms:**\n- Adding features based on assumptions\n- \"Modern apps have [X]\"\n- \"Users won't use it without [Y]\"\n\n**Why it's risky:** Assumptions, not validated needs. MVP is for desperate early adopters who tolerate imperfection.\n\n**What to probe:**\n- \"Have users told you they need this?\"\n- \"What if they use it without this feature?\"\n- \"Can you test that assumption before building?\"\n\n---\n\n### Edge case handling\n\n**Symptoms:**\n- \"What if user does [unlikely thing]?\"\n- Building flows for rare scenarios\n- \"We need to handle all cases\"\n\n**Why it's risky:** Edge cases take time. For MVP, happy path + manual handling of exceptions is fine.\n\n**What to probe:**\n- \"How often will that happen?\"\n- \"Can you handle that manually for MVP?\"\n- \"Does that test your core hypothesis?\"\n\n---\n\n## Technical Red Flags\n\n### Overengineered architecture\n\n**Symptoms:**\n- Microservices\n- Event-driven architecture\n- Message queues, caching layers, load balancers\n- \"Building for scale\"\n\n**Why it's risky:** Massive overkill for MVP. Takes much longer to build and maintain.\n\n**What to probe:**\n- \"Do you need that complexity for 10 users?\"\n- \"What's the simplest architecture that works?\"\n- \"Why not monolith for MVP, split later if needed?\"\n\n---\n\n### Building what exists as service\n\n**Symptoms:**\n- Building auth (Auth0 exists)\n- Building payments (Stripe exists)\n- Building notifications (SendGrid exists)\n\n**Why it's risky:** Reinventing wheel. Takes time. Managed services are better.\n\n**What to probe:**\n- \"Why build when [service] exists?\"\n- \"What's the cost of using managed service?\"\n- \"Is building this core to your value prop?\"\n\n---\n\n### No-code could work but building custom\n\n**Symptoms:**\n- Building CRUD app from scratch\n- Simple app that Bubble/Webflow could handle\n- Not considering no-code\n\n**Why it's risky:** Could ship in days with no-code instead of weeks/months with custom code.\n\n**What to probe:**\n- \"Could Bubble/Webflow/Airtable work?\"\n- \"Why custom code vs. no-code for MVP?\"\n- \"What if you tested with no-code first?\"\n\n---\n\n### Perfect database design\n\n**Symptoms:**\n- Weeks designing schema\n- \"Need perfect normalization\"\n- Complex relationships before understanding domain\n\n**Why it's risky:** Premature optimization. Don't know domain well enough yet. Flexible beats perfect for MVP.\n\n**What to probe:**\n- \"What's minimum data model that works?\"\n- \"Can you use simple schema now, optimize later?\"\n- \"Why spend time optimizing for scale you don't have?\"\n\n---\n\n## UX Red Flags\n\n### 20+ screens\n\n**Symptoms:**\n- Large screen count\n- Separate screens for everything\n- Complex navigation\n\n**Why it's risky:** Takes too long to build. Too complex for MVP. Users get lost.\n\n**What to probe:**\n- \"Can screens be combined?\"\n- \"Do you need [settings/preferences/profile] for MVP?\"\n- \"What's minimum screen count?\"\n\n---\n\n### Onboarding flows\n\n**Symptoms:**\n- Multi-step onboarding\n- Tutorial screens\n- \"We need to educate users\"\n\n**Why it's risky:** Takes time to build. For 10 users, you can onboard manually (call, email, Loom video).\n\n**What to probe:**\n- \"For first 10 users, can you onboard them personally?\"\n- \"Do you need UI or can you send instructions?\"\n- \"Why build onboarding before knowing if core product works?\"\n\n---\n\n### Beautiful design required\n\n**Symptoms:**\n- \"It needs to look professional\"\n- \"Users won't use ugly apps\"\n- Weeks on visual design\n\n**Why it's risky:** Pretty doesn't validate hypotheses. Ugly can work for desperate early users.\n\n**What to probe:**\n- \"Are you testing problem/solution or testing design?\"\n- \"Can you use basic UI library? (Material/Tailwind/Bootstrap)\"\n- \"What if you tested ugly first, prettified later?\"\n\n---\n\n## Timeline Red Flags\n\n### No buffer in timeline\n\n**Symptoms:**\n- \"2 months if everything goes perfectly\"\n- No contingency\n- Assumes no problems\n\n**Why it's risky:** Things ALWAYS take longer. Always.\n\n**What to probe:**\n- \"What if it takes 2x longer?\"\n- \"What's on critical path?\"\n- \"What could delay you?\"\n\n---\n\n### \"We'll launch when it's done\"\n\n**Symptoms:**\n- No hard deadline\n- \"When it's ready\"\n- Feature-complete mindset\n\n**Why it's risky:** \"Done\" never happens. Perfection is enemy of learning.\n\n**What to probe:**\n- \"What if you released in 2 weeks with less?\"\n- \"What's good enough to test hypothesis?\"\n- \"Can you set hard deadline?\"\n\n---\n\n## Cost Red Flags\n\n### No budget\n\n**Symptoms:**\n- \"We haven't calculated costs\"\n- \"It won't cost much\"\n- No breakdown\n\n**Why it's risky:** Will run out of money. Surprised by costs.\n\n**What to probe:**\n- \"What does hosting cost at 10 users? 100? 1000?\"\n- \"What tools/services cost money?\"\n- \"What's total to build + run for 3 months?\"\n\n---\n\n### Expensive tools for MVP\n\n**Symptoms:**\n- Enterprise tools\n- Expensive subscriptions\n- Premium services\n\n**Why it's risky:** Burning money before validation. Free/cheap alternatives exist.\n\n**What to probe:**\n- \"Do you need enterprise tier for 10 users?\"\n- \"What's the free/cheap alternative?\"\n- \"Can you use free tier?\"\n\n---\n\n## How to Use These Red Flags\n\n### Severity levels\n\n**üî¥ Critical (likely fatal):**\n- No hypothesis\n- Building everything\n- 6-12 month timeline\n- Building for imaginary scale\n\n**üü° Serious (major problems):**\n- Multiple platforms\n- Perfect design first\n- Building auth from scratch\n- No success metrics\n\n**üü¢ Caution (watch these):**\n- Scope creep starting\n- Some overengineering\n- Admin tools for MVP\n\n### Intervention strategies\n\n**For critical red flags:**\nBe very direct. These kill MVPs.\n\n\"That's not an MVP. That's a full product. You'll spend a year building features nobody wants. What's the absolute minimum to test if anyone cares?\"\n\n**For serious red flags:**\nChallenge strongly but offer alternatives.\n\n\"Building for iOS AND Android AND web will take 3x longer. Pick one. Which platform are your first 10 users on?\"\n\n**For caution flags:**\nPoint out, suggest simpler, move on if they insist.\n\n\"You're adding admin UI before having users. For 10 users you can edit database directly. But if you want to build it, OK.\"\n\n### Conversation tactics\n\n**1. The Minimum Challenge:**\nConstantly push for less.\n- \"That's 15 features. What's the minimum? 5? 3? 1?\"\n\n**2. The Reality Check:**\nRemind them of actual user count.\n- \"For 10 users, do you really need [complex feature]?\"\n\n**3. The Alternative:**\nSuggest simpler options.\n- \"Why build when [service/no-code] exists?\"\n\n**4. The Math:**\nUse numbers to expose problems.\n- \"20 features √ó 1 week each = 5 months. Too long for MVP.\"\n\n**5. The Hypothesis Test:**\nLink back to core purpose.\n- \"Does [feature] test your hypothesis? No? Cut it.\"\n\n---\n\n## Example Red Flag Conversations\n\n### Example 1: Too Many Features\n\n**User:** \"MVP needs profiles, search, filters, messaging, notifications, payments, admin dashboard...\"\n\n**You:** \"That's 7+ major features. Not an MVP. Which ONE feature, if it works, proves your core idea?\"\n\n**User:** \"Well, they all work together...\"\n\n**You:** \"No. If you could build ONE thing this week, what tests your hypothesis?\"\n\n**User:** \"I guess... messaging?\"\n\n**You:** \"OK. MVP is basic messaging. Everything else is v2. Can you test your idea with just messaging?\"\n\n---\n\n### Example 2: Building for Scale\n\n**User:** \"We're using microservices so it scales to millions of users.\"\n\n**You:** \"How many users do you have?\"\n\n**User:** \"We're pre-launch, but we expect rapid growth...\"\n\n**You:** \"You have 0 users. Microservices for 0 users? That's massive overengineering.\"\n\n**User:** \"But we want to build it right from the start...\"\n\n**You:** \"Right' for MVP is fast and simple. Ship monolith, get users, scale IF needed. Why waste months on architecture for users that don't exist?\"\n\n---\n\n### Example 3: Perfect Design\n\n**User:** \"We're spending 4 weeks on design before coding.\"\n\n**You:** \"Why?\"\n\n**User:** \"We want it to look professional. Users won't use ugly apps.\"\n\n**You:** \"Are you testing if users want the solution, or testing if they like pretty design?\"\n\n**User:** \"Both?\"\n\n**You:** \"Test solution first with ugly-but-functional. If they use ugly version, THEN make it pretty. If they don't, pretty doesn't matter.\"\n\n---\n\n### Example 4: Long Timeline\n\n**User:** \"We'll have MVP ready in 6 months.\"\n\n**You:** \"That's not an MVP timeline. What would 6 WEEKS look like?\"\n\n**User:** \"We couldn't build everything in 6 weeks...\"\n\n**You:** \"Exactly. What's the minimum you COULD build in 6 weeks?\"\n\n**User:** \"I guess just the core flow...\"\n\n**You:** \"That's your MVP. Not 'everything', just core flow. 6 weeks, not 6 months.\"\n\n---\n\n## Summary: Top 20 MVP Red Flags\n\n1. **No clear hypothesis** - Don't know what testing\n2. **15+ features** - Way too much\n3. **6-12 month timeline** - Too long\n4. **Building for scale** - Premature optimization\n5. **No first users identified** - Building in vacuum\n6. **Building auth from scratch** - Use library/service\n7. **iOS AND Android AND web** - Pick one\n8. **Perfect design first** - Test solution before prettifying\n9. **Microservices** - Overkill for MVP\n10. **No success metrics** - Can't tell if it worked\n11. **Admin tools before users** - Do manually\n12. **Learning new tech** - Use what you know\n13. **Feature parity with competitors** - You're not them\n14. **\"Users will expect...\"** - Assumptions, not facts\n15. **20+ screens** - Too many\n16. **No budget** - Will run out of money\n17. **Onboarding flows** - Onboard manually\n18. **Building what exists as service** - Use Auth0/Stripe/etc\n19. **\"We'll launch when done\"** - Done never comes\n20. **Scope creep** - Features keep getting added\n\nWhen you see these, intervene strongly. Your job is to make the MVP smaller, faster, and more focused on learning.\n",
        "skills/critical-business-brief/SKILL.md": "---\nname: critical-business-brief\ndescription: Create critical business briefs through challenging dialogue that validates ideas and stress-tests assumptions. Use when user presents business ideas, wants to explore concepts, mentions starting a business, or needs business validation. Conducts realistic, skeptical conversations to expose weaknesses and creates structured business briefs in .ideas/ folder. Triggers include \"I have a business idea\", \"business opportunity\", \"startup idea\", or \"validate this concept\".\n---\n\n# Business Idea Clarification\n\n## Overview\n\nThis skill helps users transform vague business ideas into structured, reality-tested business briefs through critical dialogue. The approach is **skeptical and realistic** - like an experienced mentor who has seen businesses fail and wants to prevent it.\n\n**Core principles:**\n- **Critical, not supportive** - Challenge assumptions, find weaknesses, stress-test ideas\n- **Reality over optimism** - Point out difficulties, competition, and obstacles\n- **Natural dialogue** - Conversational flow, not rigid questionnaire\n- **Evidence-based** - Push for concrete evidence, not assumptions\n- **Structured output** - Map conversation to business brief framework\n\n**Output:** Structured business brief saved to `.ideas/[idea-name]/business.md`\n\n---\n\n## Workflow\n\n### Phase 1: Initial Understanding (2-3 minutes)\n\n**Goal:** Understand what the user is thinking about, even if vague.\n\nStart with open questions:\n- \"Tell me about the idea you're thinking about\"\n- \"What got you interested in this?\"\n- \"What problem are you trying to solve?\"\n\n**Listen for:**\n- Core concept\n- User's background/expertise\n- How developed the thinking is\n- Energy level / commitment\n\n**Set expectations early:**\n\"I'm going to ask some tough questions to help stress-test this idea. My job is to find weak spots, not to validate. Sound good?\"\n\n### Phase 2: Critical Exploration (15-30 minutes)\n\n**Goal:** Systematically explore the business through 14 key categories while maintaining natural dialogue flow.\n\n**Core Categories (always cover):**\n1. Problem / Pain Point\n2. Target Customer\n3. Proposed Solution\n4. Unique Value Proposition\n5. Business Model / Revenue\n6. Competition / Alternatives\n\n**Secondary Categories (cover as relevant):**\n7. Go-to-Market Strategy\n8. Key Metrics (KPIs)\n9. Market Size (TAM/SAM/SOM)\n10. Key Resources\n11. Partners / Ecosystem\n12. Risks and Assumptions\n13. Timeline / Milestones\n14. Budget / Funding Needs\n\n**How to navigate:**\n\n1. **Start with Problem ‚Üí Customer ‚Üí Solution ‚Üí Business Model** (the core)\n2. **Follow natural conversation flow** - if user brings up competition, explore it deeply\n3. **Use critical questions** from `references/questions-library.md`\n4. **Identify red flags** using `references/red-flags.md`\n5. **Don't force all 14 categories** - some won't apply to early ideas\n6. **Mark uncertainties** - if user doesn't know something, note it explicitly\n\n**Reference files to consult:**\n- `references/categories-guide.md` - Detailed explanation of each category, use when you need to understand what to explore in a category\n- `references/questions-library.md` - Critical questions for each category, use throughout dialogue to challenge assumptions\n- `references/red-flags.md` - Common warning signs, use to identify fundamental problems\n\n**Dialogue style:**\n\n**Good examples:**\n- \"How do you know this is actually a problem?\" (push for evidence)\n- \"That's going to be really hard because X. How do you plan to overcome that?\" (direct but constructive)\n- \"Many startups have tried that distribution strategy. Most fail because...\" (provide context)\n- \"You said 'small businesses' - which specific businesses? What size? What industry?\" (demand specificity)\n\n**Bad examples:**\n- \"That's a great idea!\" (premature validation)\n- \"Sounds interesting\" (non-committal)\n- Accepting vague answers without pushing back\n- Moving on when something doesn't make sense\n\n**Key tactics:**\n\n**1. Demand specificity:**\n- \"Can you be more specific?\"\n- \"Give me an example\"\n- \"Describe one specific person/company where this applies\"\n\n**2. Push for evidence:**\n- \"How do you know?\"\n- \"Have you talked to anyone about this?\"\n- \"What evidence supports that?\"\n\n**3. Use math to expose problems:**\n- \"At $50/month and $500 CAC, you need 10 months to break even. What's your churn rate?\"\n- \"How many customers do you need to make $1M revenue?\"\n\n**4. Follow the weak spots:**\nWhen you sense uncertainty, dig deeper before moving on.\n\nExample:\n- User: \"Small businesses need this\"\n- You: \"Which specific types of businesses?\"\n- User: \"Um, like retail shops...\"\n- You: \"What size? 1 employee or 50?\"\n- User: \"Maybe 5-20 employees\"\n- You: \"Have you talked to any shops that size? What did they say?\"\n\n**5. Name the contradictions:**\nIf something doesn't add up, say it directly.\n\nExample:\n\"You said the market is huge but nobody is solving this. That usually means it's not actually a valuable problem. Why do you think this is different?\"\n\n**6. Offer alternative perspectives:**\nShare why something is difficult based on common startup failures.\n\nExample:\n\"Distribution is usually harder than building the product. Most startups fail from lack of customers, not lack of product. Where specifically will you find your first 100 customers?\"\n\n### Phase 3: Brief Creation (5 minutes)\n\n**Goal:** Synthesize dialogue into structured brief.\n\n**Steps:**\n\n1. **Propose folder name** based on the idea\n   - Use kebab-case (lowercase with hyphens)\n   - Keep it short and descriptive\n   - Example: `ai-dla-malych-firm`, `edukacja-online-b2b`\n\n2. **Create directory structure:**\n   ```\n   .ideas/[idea-name]/\n   ‚îî‚îÄ‚îÄ business.md\n   ```\n\n3. **Generate business.md** with this structure:\n\n```markdown\n# [Idea Name]\n\n**Created:** [Date]\n**Status:** Concept / Early exploration\n\n---\n\n## 1. Problem / Pain Point\n\n[Capture user's description of the problem. Include:\n- What is the specific problem?\n- How painful is it?\n- How often does it occur?\n- Evidence of problem existence]\n\n**Uncertainties:**\n[Mark what's still unclear or needs validation]\n\n---\n\n## 2. Target Customer\n\n[Describe the specific customer. Include:\n- Who specifically? (job title, role, company size, industry)\n- Demographics if relevant\n- Psychographics (goals, fears, behaviors)\n- Buying power]\n\n**Uncertainties:**\n[Mark what's still unclear]\n\n---\n\n## 3. Proposed Solution\n\n[Describe how the problem is solved. Include:\n- Core mechanism\n- Key features\n- Why this approach]\n\n**Uncertainties:**\n[Mark what's still unclear]\n\n---\n\n## 4. Unique Value Proposition\n\n[Why customers choose this over alternatives. Include:\n- Key differentiation\n- Why it matters to customers\n- Defensibility]\n\n**Uncertainties:**\n[Mark what's still unclear]\n\n---\n\n## 5. Business Model / Revenue\n\n[How money is made. Include:\n- Revenue model (subscription, transaction, licensing, etc.)\n- Price point\n- Who pays\n- Unit economics if discussed]\n\n**Uncertainties:**\n[Mark what's still unclear]\n\n---\n\n## 6. Competition / Alternatives\n\n[What exists today. Include:\n- Direct competitors\n- Indirect competitors\n- What customers do today without a solution\n- Competitive advantages/disadvantages]\n\n**Uncertainties:**\n[Mark what's still unclear]\n\n---\n\n## 7. Go-to-Market Strategy\n\n[If discussed - How to acquire customers. Include:\n- Distribution channels\n- Customer acquisition approach\n- Sales process]\n\n**Uncertainties:**\n[Mark what's still unclear]\n\n---\n\n## 8. Key Metrics (KPIs)\n\n[If discussed - How to measure success. Include:\n- Key metrics to track\n- Target values if discussed]\n\n**Uncertainties:**\n[Mark what's still unclear]\n\n---\n\n## 9. Market Size\n\n[If discussed - Size of opportunity. Include:\n- TAM/SAM/SOM if discussed\n- Market growth trends]\n\n**Uncertainties:**\n[Mark what's still unclear]\n\n---\n\n## 10. Key Resources\n\n[If discussed - Critical resources needed. Include:\n- People/skills needed\n- Technology requirements\n- Capital needs\n- Critical partnerships]\n\n**Uncertainties:**\n[Mark what's still unclear]\n\n---\n\n## 11. Partners / Ecosystem\n\n[If discussed - Key partnerships. Include:\n- Who\n- Why\n- What's in it for them]\n\n**Uncertainties:**\n[Mark what's still unclear]\n\n---\n\n## 12. Risks and Assumptions\n\n[Key risks and assumptions. Include:\n- Riskiest assumptions\n- What could kill the business\n- Dependencies on external factors]\n\n**RED FLAGS IDENTIFIED:**\n[List any red flags from references/red-flags.md that apply]\n\n**Uncertainties:**\n[Mark what's still unclear]\n\n---\n\n## 13. Timeline / Milestones\n\n[If discussed - Key milestones. Include:\n- Major checkpoints\n- Time estimates if discussed]\n\n**Uncertainties:**\n[Mark what's still unclear]\n\n---\n\n## 14. Budget / Funding Needs\n\n[If discussed - Financial requirements. Include:\n- Funding needed\n- Major expense categories\n- Runway]\n\n**Uncertainties:**\n[Mark what's still unclear]\n\n---\n\n## Summary Assessment\n\n**Strengths:**\n[What's strong about this idea]\n\n**Critical Challenges:**\n[Top 3-5 most difficult challenges to overcome]\n\n**Next Steps for Validation:**\n[Concrete actions to de-risk key assumptions, prioritized by importance]\n\n1. [Most critical thing to validate]\n2. [Second most critical]\n3. [Third most critical]\n\n---\n\n## Conversation Notes\n\n[Any additional context, observations, or quotes from the dialogue that are important]\n```\n\n4. **Review with user:**\n   - Show the brief\n   - Ask if anything is missing or misrepresented\n   - Offer to refine sections\n\n5. **Save the file** to `.ideas/[idea-name]/business.md`\n\n### Phase 4: Wrap-up\n\n**Offer next steps:**\n- \"Would you like to explore how this works operationally?\" (triggers critical-process-brief)\n- \"These are the critical assumptions to test. Want to discuss how to validate them?\"\n- \"Happy to dive deeper into any section\"\n\n**Be honest about viability:**\nIf you identified fatal red flags, say so directly:\n- \"Based on our conversation, I see [X, Y, Z] as serious problems that might make this not viable. Here's why...\"\n\n---\n\n## Special Cases\n\n### User skips categories\n\n**If user doesn't know / isn't ready:**\n- \"That's fine, we can come back to this\"\n- Mark as \"TBD\" or \"Not yet defined\" in brief\n- Note it in Uncertainties section\n\n**If category doesn't apply:**\n- Skip it or mark as \"N/A\"\n- Example: Early idea might not have funding discussion\n\n### User asks for your suggestions\n\n**Acceptable:**\n- Offer 2-3 options with trade-offs\n- \"Here are some common approaches: A (pros/cons), B (pros/cons), C (pros/cons)\"\n- Push back to user for decision\n\n**Not acceptable:**\n- Filling in blanks with your assumptions\n- Making decisions for them\n- \"This is what you should do\"\n\n### User seems defensive\n\n**If user pushes back on critical questions:**\n- \"I know these are tough questions. They're the same questions investors, customers, and reality will ask. Better to think through them now.\"\n- Stay direct but not aggressive\n- Explain WHY you're asking (context from similar failures)\n\n### Multiple ideas in one session\n\n**If user wants to explore multiple ideas:**\n- Complete one brief fully first\n- Each idea gets its own folder\n- Can compare ideas at the end\n\n---\n\n## Quality Checklist\n\nBefore finishing, ensure:\n\n‚úÖ **Core categories addressed:** Problem, Customer, Solution, UVP, Business Model, Competition\n‚úÖ **Specific, not vague:** Avoid \"small businesses\", \"everyone\", \"people who need X\"\n‚úÖ **Evidence noted:** What's validated vs. assumed\n‚úÖ **Uncertainties marked:** Clear what's still unknown\n‚úÖ **Red flags identified:** Called out explicitly\n‚úÖ **Critical challenges listed:** Top 3-5 hardest things\n‚úÖ **Next steps concrete:** Actionable validation steps\n\n---\n\n## Key Reminders\n\n**DO:**\n- Challenge assumptions relentlessly\n- Demand specificity and evidence\n- Point out contradictions and red flags\n- Use math to expose problems\n- Explain WHY something is difficult\n- Mark uncertainties explicitly\n- Maintain conversational flow\n\n**DON'T:**\n- Validate prematurely (\"great idea!\")\n- Accept vague answers\n- Fill in blanks with your assumptions\n- Skip categories just because user seems uncertain\n- Move on when something doesn't make sense\n- Sugarcoat fatal problems\n\n**Remember:** Your job is to help the user think clearly about reality, not to make them feel good about their idea. The best gift you can give is honest, critical analysis early‚Äîbefore they waste time and money.\n",
        "skills/critical-business-brief/references/categories-guide.md": "# Business Brief Categories Guide\n\nThis guide explains each category in the business brief with clarity and practical context.\n\n## 1. Problem / Pain Point\n\n**What it is:** The specific problem or frustration that customers experience today.\n\n**Why it matters:** Without a real problem, there's no real business. Problems create willingness to pay.\n\n**Key questions:**\n- What frustrates people today?\n- How painful is this problem? (annoying vs. critical)\n- How often does this problem occur?\n- What triggers this problem?\n\n**Not a valid problem:**\n- \"People don't have X\" (unless X solves a real pain)\n- \"Market is growing\" (that's opportunity, not pain)\n- \"Nobody does Y\" (maybe because Y isn't needed)\n\n---\n\n## 2. Target Customer\n\n**What it is:** The specific person or organization who experiences the problem and will pay for the solution.\n\n**Why it matters:** Can't sell to \"everyone\". Different customers have different needs, budgets, and buying processes.\n\n**Key aspects:**\n- **Who specifically:** Job title, role, industry, company size\n- **Demographics:** Age, income, location (if relevant)\n- **Psychographics:** Goals, fears, values, behaviors\n- **Buying power:** Can they actually buy? Who approves budget?\n\n**Red flags:**\n- \"Everyone who...\" (too broad)\n- \"Companies that need...\" (which companies specifically?)\n- Customer has no budget or authority\n\n---\n\n## 3. Proposed Solution\n\n**What it is:** How you solve the problem. The product or service you're building.\n\n**Why it matters:** Must be feasible, different enough, and actually solve the problem better than alternatives.\n\n**Key aspects:**\n- **Core mechanism:** How does it work?\n- **Key features:** What does it do?\n- **Why this approach:** Why is this solution better than alternatives?\n\n**Red flags:**\n- Solution doesn't directly address the stated problem\n- Requires massive behavior change\n- Technically impossible or extremely difficult\n- \"It's like Uber but for X\" without explaining why Uber model works here\n\n---\n\n## 4. Unique Value Proposition (UVP)\n\n**What it is:** Why customers should choose you instead of competitors or alternatives.\n\n**Why it matters:** If you're not better in a meaningful way, price becomes the only differentiator.\n\n**Key aspects:**\n- **Differentiation:** What makes you different?\n- **Better, not just different:** Why does that difference matter to customers?\n- **Defensibility:** Can competitors easily copy this?\n\n**Common mistakes:**\n- \"Better quality\" (everyone says this)\n- \"Better customer service\" (hard to prove, easy to copy)\n- \"First mover\" (rarely a sustainable advantage)\n- Features that don't matter to customers\n\n---\n\n## 5. Business Model / Revenue Model\n\n**What it is:** How you make money. The mechanism for converting value into revenue.\n\n**Why it matters:** Great products fail without viable business models. Must be realistic about what customers will actually pay.\n\n**Common models:**\n- **Subscription:** Recurring monthly/annual payment\n- **Transaction fee:** Percentage or fixed fee per transaction\n- **Licensing:** One-time or annual license fee\n- **Advertising:** Free to users, monetize attention\n- **Marketplace:** Commission on transactions between parties\n- **Freemium:** Free basic, paid premium\n\n**Key questions:**\n- Who pays? (user, buyer might be different)\n- How much? (realistic willingness to pay)\n- When? (upfront, monthly, per-use)\n- Unit economics: Does it work at scale?\n\n**Red flags:**\n- \"We'll figure out monetization later\"\n- Requires massive scale to work\n- Depends on ads without proven engagement\n- Price point doesn't match customer budget\n\n---\n\n## 6. Competition / Alternatives\n\n**What it is:** What customers do today instead of using your solution.\n\n**Why it matters:** \"No competition\" usually means \"no market\". Understanding alternatives shows you understand the market.\n\n**Types of alternatives:**\n- **Direct competitors:** Similar solution to same problem\n- **Indirect competitors:** Different solution to same problem\n- **Substitute behaviors:** How people cope without a solution\n- **Status quo:** Doing nothing, living with the problem\n\n**Key analysis:**\n- What do they do well?\n- What do they do poorly?\n- Why will customers switch to you?\n- What's their market position and funding?\n\n**Red flags:**\n- \"We have no competition\" (wrong or no market)\n- \"We're better in every way\" (unrealistic)\n- Ignoring massive incumbents with deep pockets\n\n---\n\n## 7. Go-to-Market Strategy\n\n**What it is:** How you'll acquire customers and get your product into their hands.\n\n**Why it matters:** Great products die because nobody knows they exist. Customer acquisition is often the hardest part.\n\n**Common approaches:**\n- **Direct sales:** Sales team reaches out to prospects\n- **Inbound marketing:** Content, SEO, ads drive customers to you\n- **Partnerships:** Other companies distribute/recommend you\n- **Product-led growth:** Free tier or viral mechanics drive adoption\n- **Community/word-of-mouth:** Users recruit other users\n\n**Key questions:**\n- Where do target customers spend time?\n- What's the customer acquisition cost (CAC)?\n- What's the sales cycle length?\n- Do you need to educate the market?\n\n**Red flags:**\n- \"It will go viral\" (rarely happens organically)\n- Depends on expensive sales team before product-market fit\n- Requires customers to change ingrained habits\n- No clear path from awareness to purchase\n\n---\n\n## 8. Key Metrics (KPIs)\n\n**What it is:** Measurable numbers that indicate whether the business is working.\n\n**Why it matters:** Can't improve what you don't measure. Metrics show truth beyond opinions.\n\n**Essential metrics by stage:**\n\n**Early stage (validation):**\n- Customer interviews completed\n- Wait list sign-ups\n- Conversion rate from landing page\n- Time to onboard/first value\n\n**Growth stage:**\n- Monthly Recurring Revenue (MRR) / Annual Recurring Revenue (ARR)\n- Customer Acquisition Cost (CAC)\n- Lifetime Value (LTV)\n- Churn rate\n- Active users (DAU/MAU)\n- Net Revenue Retention\n\n**Key principle:** LTV must be significantly greater than CAC (ideally 3x+)\n\n**Red flags:**\n- Vanity metrics (sign-ups without activation)\n- No unit economics defined\n- Metrics that don't tie to revenue\n\n---\n\n## 9. Market Size (TAM/SAM/SOM)\n\n**What it is:** How big is the opportunity?\n\n**Why it matters:** Investors need big markets. But beware: \"billion dollar market\" doesn't mean your business will be big.\n\n**Three levels:**\n- **TAM (Total Addressable Market):** Everyone who could theoretically use this\n- **SAM (Serviceable Addressable Market):** Realistic segment you can reach\n- **SOM (Serviceable Obtainable Market):** What you can realistically capture in 3-5 years\n\n**Calculation approaches:**\n- **Top-down:** Industry reports, market research\n- **Bottom-up:** Number of customers √ó price √ó adoption rate\n- **Value theory:** How much value you create √ó capture rate\n\n**Red flags:**\n- Only stating TAM without SAM/SOM\n- Market size based on \"everyone who uses smartphones\"\n- No realistic path to capture meaningful share\n- Market too small to support a venture-backed business\n\n---\n\n## 10. Key Resources\n\n**What it is:** Critical assets needed to build and run the business.\n\n**Why it matters:** Helps identify gaps and investment needs early.\n\n**Categories:**\n- **People:** Founders, engineers, designers, sales, domain experts\n- **Technology:** Infrastructure, licenses, IP, data\n- **Capital:** How much cash needed to reach key milestones\n- **Partnerships:** Distribution, suppliers, strategic relationships\n- **Physical assets:** Equipment, inventory, real estate (if applicable)\n\n**Key questions:**\n- What resources do we have vs. need?\n- What's the critical path resource?\n- What's hardest to acquire?\n- What resources are must-have vs. nice-to-have?\n\n**Red flags:**\n- Requires resources you can't realistically get\n- Critical dependency on scarce talent (e.g., \"need 10 senior ML engineers\")\n- Needs massive upfront capital before validation\n\n---\n\n## 11. Partners / Ecosystem\n\n**What it is:** Other companies or organizations you'll work with to deliver value.\n\n**Why it matters:** Partnerships can accelerate growth but also create dependencies and complexity.\n\n**Types of partners:**\n- **Distribution partners:** Help you reach customers\n- **Technology partners:** Provide critical infrastructure or integrations\n- **Supply partners:** Provide inputs for your product/service\n- **Strategic partners:** Alignment on vision, mutual benefits\n\n**Key questions:**\n- Why would they partner with you?\n- What's in it for them?\n- How dependent are you on them?\n- What if they become a competitor?\n\n**Red flags:**\n- Business model requires partnership with major player unlikely to care about small startup\n- Single point of failure (one critical partner)\n- \"We'll partner with Google/Apple/Microsoft\" without specific pathway\n\n---\n\n## 12. Risks and Assumptions\n\n**What it is:** What must be true for this to work, and what could go wrong.\n\n**Why it matters:** Helps prioritize what to test first and prepares for challenges.\n\n**Types of risks:**\n- **Market risk:** Will customers actually want this?\n- **Technical risk:** Can we build it?\n- **Execution risk:** Can we execute the plan?\n- **Competitive risk:** What if competitors respond?\n- **Regulatory risk:** Legal/compliance issues?\n- **Timing risk:** Are we too early or too late?\n\n**Critical assumptions to test:**\n- Customers will pay $X for this solution\n- We can acquire customers at $Y cost\n- Technical approach is feasible\n- Market is ready for this solution\n- Key partnerships are achievable\n\n**Key questions:**\n- What's the riskiest assumption?\n- How can we test it cheaply and quickly?\n- What kills the business if we're wrong?\n\n**Red flags:**\n- Assuming everything will go according to plan\n- No plan to de-risk key assumptions\n- Fatal dependency on things outside your control\n\n---\n\n## 13. Timeline / Milestones\n\n**What it is:** Key achievements and when you expect to reach them.\n\n**Why it matters:** Shows you think realistically about execution. Helps track progress and identify when you're off track.\n\n**Common milestones:**\n- **Product:** MVP, beta, v1, major features\n- **Customer:** First customer, 10 customers, 100 customers, first enterprise customer\n- **Revenue:** First dollar, $10K MRR, $100K MRR, $1M ARR\n- **Funding:** Bootstrapped runway, seed raise, Series A\n- **Team:** First hire, key leadership roles filled\n\n**Key principle:** Milestones should be specific, measurable, and tied to value creation (not just \"launch the product\")\n\n**Red flags:**\n- Timelines that assume everything goes perfectly\n- No intermediate milestones (just \"launch in 6 months\")\n- Milestones focused on outputs not outcomes (\"build feature X\" vs \"achieve X adoption\")\n\n---\n\n## 14. Budget / Funding Needs\n\n**What it is:** How much money is needed and where it will be spent.\n\n**Why it matters:** Running out of money is the #1 reason startups fail. Must be realistic about costs and runway.\n\n**Key components:**\n- **Runway:** How many months of operations can you fund?\n- **Burn rate:** How much cash spent per month?\n- **Major expenses:** People, infrastructure, marketing, legal, operations\n- **Funding source:** Bootstrapped, friends/family, angels, VCs\n\n**Budget categories:**\n- Personnel (usually largest expense)\n- Technology/infrastructure\n- Marketing/customer acquisition\n- Legal/compliance\n- Operations/overhead\n\n**Key questions:**\n- How much to reach next major milestone?\n- What's the minimum viable budget?\n- When do you need to raise next round?\n- Can you achieve profitability before running out of money?\n\n**Red flags:**\n- Underestimating costs (especially customer acquisition)\n- No clear plan for what funding enables\n- Runway less than 12 months after raise\n- Burn rate that requires massive revenue growth to justify\n\n---\n\n## Using This Guide\n\n**During dialog:**\n- Don't overwhelm user by going through all 14 categories linearly\n- Start with Problem ‚Üí Customer ‚Üí Solution ‚Üí Business Model (core elements)\n- Add other categories as they become relevant in conversation\n- Some categories might not apply to early-stage ideas\n\n**Critical attitude:**\n- Use this guide to challenge assumptions\n- Ask \"How do you know?\" frequently\n- Push for specifics, not generalities\n- Point out when answers contradict each other\n- Identify gaps and weak reasoning\n\n**Recording answers:**\n- Capture actual user words, not polished marketing speak\n- Note uncertainties and assumptions explicitly\n- Mark areas needing more validation\n- Don't fill in blanks with your assumptions\n",
        "skills/critical-business-brief/references/questions-library.md": "# Critical Questions Library\n\nThis library contains challenging questions designed to stress-test business ideas and surface weak assumptions. Use these to push users toward realistic thinking.\n\n## General Approach\n\n**Tone:** Direct, skeptical, but not dismissive. Like a mentor who's seen businesses fail and wants to prevent it.\n\n**Pattern:**\n1. Listen to the claim\n2. Ask \"How do you know?\"\n3. Push for specifics\n4. Point out contradictions\n5. Challenge assumptions\n\n**Avoid:**\n- \"That's a great idea!\" (premature validation)\n- Filling in gaps with your assumptions\n- Accepting vague answers\n- Moving on when something doesn't make sense\n\n---\n\n## Problem / Pain Point\n\n### Surface-level answers\n- \"How do you know this is actually a problem?\"\n- \"How painful is this? Does it cause people to lose money, time, or something else measurable?\"\n- \"How often do people experience this problem? Daily? Weekly? Once a year?\"\n- \"What do people do today when they encounter this problem?\"\n- \"If this problem disappeared tomorrow, what would actually change for them?\"\n\n### Validating severity\n- \"Would people pay to solve this, or is it just mildly annoying?\"\n- \"Is this a 'vitamin' (nice to have) or 'painkiller' (must have)?\"\n- \"What's the cost of NOT solving this problem? Can people live with it?\"\n- \"Who feels this pain most acutely? Who doesn't care?\"\n\n### Testing reality\n- \"Have you talked to people who have this problem? What did they say?\"\n- \"How many people have you interviewed about this?\"\n- \"Is this a problem YOU have, or a problem you think OTHER people have?\"\n- \"What evidence do you have that this problem exists beyond your intuition?\"\n\n---\n\n## Target Customer\n\n### Avoiding \"everyone\"\n- \"You said 'small businesses' ‚Äì which specific businesses? What size? Which industries?\"\n- \"You said 'professionals' ‚Äì which professions? What level? What age range?\"\n- \"If you had to pick ONE specific person who represents your ideal customer, who would it be? Name them if possible.\"\n- \"Can you describe a real person you know who fits this customer profile?\"\n\n### Testing access\n- \"How will you reach these customers? Where do they spend time?\"\n- \"Do these customers have budget for this? Who controls that budget?\"\n- \"What's their buying process? Can they decide themselves or need approval?\"\n- \"Why would they trust you enough to buy from you?\"\n\n### Testing willingness\n- \"Have any of these people told you they'd pay for this?\"\n- \"What are they paying for today that's similar?\"\n- \"What would make them switch from their current solution to yours?\"\n- \"If they're not solving this problem today, why not? Too expensive? Not important enough?\"\n\n---\n\n## Proposed Solution\n\n### Technical reality\n- \"Can this actually be built? What's the hardest technical challenge?\"\n- \"What technology exists today that makes this possible?\"\n- \"What's the minimum version that actually solves the problem?\"\n- \"How long would it take to build a working prototype?\"\n\n### Behavior change\n- \"Does this require people to change their behavior? How hard is that change?\"\n- \"What needs to be different about the world for people to use this?\"\n- \"Are you asking people to do something new, or do something they already do but differently?\"\n- \"How many steps does someone need to take to get value from this?\"\n\n### Testing completeness\n- \"Does this actually solve the problem you described, or just part of it?\"\n- \"What's missing from this solution that customers will still need elsewhere?\"\n- \"Why this approach instead of other possible solutions?\"\n\n---\n\n## Unique Value Proposition\n\n### Avoiding generic claims\n- \"You said 'better quality' ‚Äì better than what, specifically? How will customers know it's better?\"\n- \"You said 'better service' ‚Äì what does that mean in practice? Can competitors copy it?\"\n- \"You said 'cheaper' ‚Äì how much cheaper? Why can you be cheaper? Is that sustainable?\"\n\n### Testing differentiation\n- \"What can you do that competitors CAN'T do?\"\n- \"If a competitor wanted to copy your key differentiator, how long would it take them?\"\n- \"Why hasn't someone already done this if it's better?\"\n- \"What stops bigger companies with more resources from crushing you?\"\n\n### Testing value\n- \"Does this difference actually matter to customers?\"\n- \"Would customers pay more for this differentiator?\"\n- \"Is this difference obvious to customers immediately, or do you need to educate them?\"\n\n---\n\n## Business Model / Revenue\n\n### Testing willingness to pay\n- \"How much do you think customers will pay? Why that number?\"\n- \"What are they paying today for alternatives? Is your price higher or lower?\"\n- \"Have you asked anyone if they'd pay this amount?\"\n- \"At this price point, how many customers do you need to break even?\"\n\n### Testing unit economics\n- \"What does it cost you to acquire one customer?\"\n- \"What does it cost you to serve one customer?\"\n- \"How long before a customer generates enough revenue to cover acquisition cost?\"\n- \"What happens if customer acquisition costs are 2x or 3x what you expect?\"\n\n### Monetization reality\n- \"Who actually pays ‚Äì the user or someone else?\"\n- \"When do they pay ‚Äì upfront, monthly, per use?\"\n- \"What if customers want to use it but not pay for it?\"\n- \"How do you prevent people from getting the value without paying?\"\n\n### Scale requirements\n- \"How many customers do you need to make $1M in revenue?\"\n- \"Is that realistic in the first year? Second year?\"\n- \"What if it takes 2x or 3x longer to hit those numbers?\"\n\n---\n\n## Competition / Alternatives\n\n### \"No competition\" response\n- \"If nobody is solving this problem, why not? Maybe it's not a big problem?\"\n- \"What do people do TODAY instead of using a solution like yours?\"\n- \"Even if there's no direct competitor, what would people do if you didn't exist?\"\n\n### Understanding competitive position\n- \"What do the big competitors do better than you?\"\n- \"Why haven't they already solved this problem?\"\n- \"If they decide to enter your space, what stops them from winning?\"\n- \"Do you need to compete on price? If so, how will you survive?\"\n\n### Switching costs\n- \"Why would someone switch from their current solution to you?\"\n- \"What's the pain of switching? Is it worth it for the customer?\"\n- \"How locked in are customers to existing solutions?\"\n\n---\n\n## Go-to-Market Strategy\n\n### Testing distribution\n- \"Where exactly will you find these customers?\"\n- \"How will they hear about you?\"\n- \"What marketing channels will you use? Have you tested them?\"\n- \"Do you need to educate the market, or do they already know they want this?\"\n\n### Testing acquisition\n- \"How much will it cost to acquire one customer?\"\n- \"Have you run any tests on customer acquisition channels?\"\n- \"What if customer acquisition costs are 5x what you expect?\"\n- \"How long is the sales cycle? Can you afford to wait that long?\"\n\n### Testing scale\n- \"Can this acquisition strategy scale, or does it only work for first 100 customers?\"\n- \"Do you need a sales team? Can you afford one before product-market fit?\"\n- \"What's your plan if 'organic growth' doesn't happen?\"\n\n### Viral / word-of-mouth\n- \"Why would someone tell their friends about this?\"\n- \"What companies have successfully used viral growth in your space?\"\n- \"What if it doesn't go viral? What's plan B?\"\n\n---\n\n## Key Metrics (KPIs)\n\n### Testing understanding\n- \"What's the ONE metric that shows this business is working?\"\n- \"How will you know if customers are getting value?\"\n- \"What's an acceptable customer acquisition cost for your model?\"\n- \"How do you calculate customer lifetime value?\"\n\n### Testing math\n- \"If LTV is $X and CAC is $Y, does that work?\"\n- \"What's your target churn rate? Is that realistic?\"\n- \"How many customers do you need to break even?\"\n- \"What if conversion rates are half what you expect?\"\n\n### Testing tracking\n- \"How will you measure this?\"\n- \"What tools will you use to track these metrics?\"\n- \"How often will you review these numbers?\"\n\n---\n\n## Market Size\n\n### Testing TAM claims\n- \"You said $50B market ‚Äì how did you calculate that?\"\n- \"What percentage of that market can you realistically reach?\"\n- \"What percentage can you realistically capture in 3 years?\"\n- \"A big market doesn't mean an easy business. Why will you win any share?\"\n\n### Testing reachability\n- \"Of the total market, how many can you actually reach with your distribution?\"\n- \"What geography will you start in? Why there?\"\n- \"Are you going after the whole market or a specific segment first?\"\n\n### Testing adoption\n- \"What percentage of the market will realistically adopt a solution like yours?\"\n- \"How long does it typically take for this market to adopt new solutions?\"\n- \"Is the market growing, shrinking, or stable? Why?\"\n\n---\n\n## Key Resources\n\n### Testing availability\n- \"Do you have the technical talent needed to build this?\"\n- \"Where will you find engineers/designers/salespeople with this specific expertise?\"\n- \"How much will it cost to hire the team you need?\"\n- \"What if key people leave?\"\n\n### Testing capital\n- \"How much money do you need to reach the next major milestone?\"\n- \"Where will that money come from?\"\n- \"What if it takes 2x the capital you expect?\"\n- \"Can you bootstrap this, or do you need venture funding?\"\n\n### Testing dependencies\n- \"What's the one resource that, if you don't get it, the business fails?\"\n- \"What resources do competitors have that you don't?\"\n- \"What resources can you get that competitors can't?\"\n\n---\n\n## Partners / Ecosystem\n\n### Testing partnership viability\n- \"Why would this partner work with you?\"\n- \"What's in it for them?\"\n- \"Have you talked to them? What did they say?\"\n- \"What happens if they say no?\"\n\n### Testing dependency\n- \"Can the business work without this partnership?\"\n- \"What if they decide to compete with you instead?\"\n- \"What if they get acquired by a competitor?\"\n- \"Are you building on someone else's platform? What if they change the rules?\"\n\n### Testing alternatives\n- \"If this partner doesn't work out, who else could you work with?\"\n- \"Can you reach customers without this partner, even if slower?\"\n\n---\n\n## Risks and Assumptions\n\n### Surfacing assumptions\n- \"What needs to be true for this to work?\"\n- \"What's the riskiest assumption you're making?\"\n- \"How can you test that assumption cheaply?\"\n- \"What if you're wrong about that assumption?\"\n\n### Testing failure modes\n- \"What would kill this business?\"\n- \"What keeps you up at night about this idea?\"\n- \"If this fails, what would be the most likely reason?\"\n- \"What could competitors do to destroy your advantage?\"\n\n### Regulatory and legal\n- \"Are there regulatory hurdles? Licenses needed?\"\n- \"Could this get shut down by regulators?\"\n- \"What legal risks exist?\"\n- \"Have you talked to a lawyer about this?\"\n\n---\n\n## Timeline / Milestones\n\n### Testing realism\n- \"You said '6 months to launch' ‚Äì what needs to happen in those 6 months?\"\n- \"What if it takes 2x or 3x longer than you expect?\"\n- \"What's the longest step? What could go wrong there?\"\n- \"Have you built something like this before? How long did that take?\"\n\n### Testing sequence\n- \"What needs to happen first? What depends on what?\"\n- \"Can you test core assumptions before building the full product?\"\n- \"What's the minimum you could build to test whether this works?\"\n\n### Testing contingencies\n- \"What's your plan if you miss key milestones?\"\n- \"How will you know if you're off track?\"\n- \"When would you pivot or shut down?\"\n\n---\n\n## Budget / Funding\n\n### Testing cost realism\n- \"What are your monthly expenses?\"\n- \"How long will your current funding last?\"\n- \"What if costs are 2x what you expect?\"\n- \"What's the biggest expense? Can you reduce it?\"\n\n### Testing funding strategy\n- \"Do you need to raise money? How much?\"\n- \"Why would investors fund this?\"\n- \"What will you accomplish with this funding?\"\n- \"What if you can't raise? Can you bootstrap?\"\n\n### Testing runway\n- \"How many months of runway do you have?\"\n- \"When do you need to raise the next round?\"\n- \"What milestones do you need to hit to raise?\"\n- \"What if revenue takes longer to materialize than expected?\"\n\n---\n\n## Cross-Cutting Stress Tests\n\nThese questions cut across multiple categories and are useful throughout the conversation:\n\n### Evidence and validation\n- \"How do you know this?\"\n- \"Have you tested this assumption?\"\n- \"How many people have you talked to about this?\"\n- \"What evidence do you have beyond intuition?\"\n- \"What if you're wrong about this?\"\n\n### Specificity\n- \"Can you be more specific?\"\n- \"Can you give me an example?\"\n- \"What exactly do you mean by that?\"\n- \"Describe a specific person/company/situation where this applies\"\n\n### Alternatives and failure\n- \"What else have you considered?\"\n- \"Why this approach instead of X?\"\n- \"What's plan B?\"\n- \"What would make you give up on this idea?\"\n\n### Scale and sustainability\n- \"Does this work at 10 customers? 100? 10,000?\"\n- \"What breaks as you scale?\"\n- \"Can you afford to keep doing this?\"\n- \"What happens when competitors copy you?\"\n\n---\n\n## Conversation Flow Tips\n\n**Start gentle, build pressure:**\nBegin with open questions, then get more pointed as you identify weak spots.\n\n**Good:** \"Tell me about the problem\" ‚Üí \"How do you know this is a problem?\" ‚Üí \"How many people have confirmed this?\" ‚Üí \"What did they say when you asked if they'd pay?\"\n\n**Follow the thread:**\nWhen you sense uncertainty, dig deeper on that specific point before moving on.\n\n**Good:** If user says \"small businesses\" ask \"which specific types?\" then \"what size?\" then \"have you talked to any?\"\n\n**Name the elephant:**\nIf something doesn't add up, say it directly.\n\n**Good:** \"You said the market is huge but nobody is solving this. That usually means it's not actually a valuable problem. Why do you think this is different?\"\n\n**Demand evidence:**\nWhenever possible, push for concrete evidence over assumptions.\n\n**Good:** \"Have you talked to potential customers?\" not \"Do you think customers would want this?\"\n\n**Use math to expose problems:**\nNumbers don't lie. Calculate unit economics, required scale, etc.\n\n**Good:** \"At $50/month and $500 CAC, you need customers to stay for 10 months just to break even. What's your expected churn rate?\"\n",
        "skills/critical-business-brief/references/red-flags.md": "# Red Flags in Business Ideas\n\nThis guide catalogs common warning signs that indicate a business idea needs more work, pivoting, or abandonment. Use these to quickly identify fundamental problems.\n\n## Critical Red Flags (Likely Fatal)\n\nThese are serious problems that often can't be overcome:\n\n### \"No competition because nobody has thought of it\"\n\n**Why it's fatal:** If it's a good idea in a real market, someone has tried it. \"No competition\" usually means:\n- No real market demand\n- Technical barriers you haven't discovered yet\n- Economics don't work\n- Regulatory issues\n\n**What to probe:**\n- \"Have you searched extensively? Are you sure?\"\n- \"Why hasn't anyone solved this if it's valuable?\"\n- \"What do people do TODAY instead?\"\n\n---\n\n### \"We'll figure out monetization later\"\n\n**Why it's fatal:** If you can't articulate how money changes hands, you don't understand your business.\n\n**What to probe:**\n- \"Why would someone pay for this?\"\n- \"What are they paying for today that's similar?\"\n- \"At what point does this stop working without revenue?\"\n\n**Only acceptable if:**\n- Clear path to monetization exists after user base (like social networks)\n- Team has track record of successful \"growth first\" models\n- User engagement metrics that prove value\n\n---\n\n### \"It will go viral\"\n\n**Why it's risky:** Virality is extremely rare and unpredictable. Can't be the only growth strategy.\n\n**What to probe:**\n- \"Why would someone share this with friends?\"\n- \"What existing products have gone viral in this category?\"\n- \"What's your backup plan if it doesn't go viral?\"\n\n**Red flags within red flags:**\n- No inherent sharing mechanism\n- Value doesn't increase with network size\n- No successful viral products in this category\n\n---\n\n### Solution looking for a problem\n\n**Symptoms:**\n- \"We can use AI/blockchain/VR for...\"\n- Technology-first, not problem-first\n- Can't articulate clear customer pain\n\n**Why it's fatal:** Cool technology ‚â† viable business. Customers buy solutions to problems, not technology.\n\n**What to probe:**\n- \"What problem does this solve?\"\n- \"Do customers know they have this problem?\"\n- \"Why does this need [specific technology]?\"\n\n---\n\n### Requires massive behavior change\n\n**Examples:**\n- \"People will start doing X instead of Y\"\n- \"This will replace [entrenched behavior]\"\n- \"Once people understand, they'll switch\"\n\n**Why it's risky:** Behavior change is slow and expensive. Even good products fail if they require too much change.\n\n**What to probe:**\n- \"How ingrained is the current behavior?\"\n- \"How much better does this need to be to justify switching?\"\n- \"Who has successfully changed this behavior before?\"\n\n---\n\n### Fatal dependency on major player\n\n**Examples:**\n- \"We need Google/Apple/Amazon to partner with us\"\n- \"Once we integrate with Salesforce/SAP/Oracle...\"\n- \"This only works if Meta/Microsoft/etc. gives us access\"\n\n**Why it's fatal:** Big companies don't care about small startups. They'll ignore you, copy you, or crush you.\n\n**What to probe:**\n- \"Why would they work with you?\"\n- \"Can the business work without them?\"\n- \"What if they build this themselves?\"\n\n---\n\n## Serious Red Flags (Difficult but Possibly Surmountable)\n\n### Underestimating competition\n\n**Symptoms:**\n- \"Our competitors are outdated/bad/stupid\"\n- \"We'll just do it better\"\n- Not acknowledging incumbents' advantages\n\n**Why it's risky:** Incumbents have resources, relationships, and market knowledge. They're not stupid, just optimized for different things.\n\n**What to probe:**\n- \"What do they do well? Why are customers still with them?\"\n- \"What prevents them from doing what you're doing?\"\n- \"What advantages do they have over you?\"\n\n---\n\n### Targeting \"everyone\"\n\n**Symptoms:**\n- \"Anyone who...\"\n- \"All businesses need...\"\n- \"Everyone with a smartphone...\"\n\n**Why it's risky:** Can't build, market, or sell to \"everyone.\" Different segments need different things.\n\n**What to probe:**\n- \"Who needs this MOST?\"\n- \"Who will be the first 10 customers?\"\n- \"Describe ONE specific person who represents your customer\"\n\n---\n\n### Assuming \"build it and they will come\"\n\n**Symptoms:**\n- No clear distribution strategy\n- \"We'll use social media/SEO/content marketing\"\n- \"It's so good people will naturally find it\"\n\n**Why it's risky:** Distribution is usually harder than building the product. Most startups fail from lack of customers, not lack of product.\n\n**What to probe:**\n- \"Where will you find first 100 customers?\"\n- \"How much will it cost to acquire a customer?\"\n- \"Have you tested any acquisition channels?\"\n\n---\n\n### Unrealistic timelines\n\n**Symptoms:**\n- \"We'll launch in 3 months\"\n- \"We'll have 10,000 users by end of year\"\n- No buffer for problems\n\n**Why it's risky:** Everything takes longer than expected. Unrealistic timelines lead to rushed/bad product and burnout.\n\n**What to probe:**\n- \"What needs to happen in those 3 months?\"\n- \"Have you built something like this before?\"\n- \"What if it takes 2x or 3x longer?\"\n\n---\n\n### Insufficient runway\n\n**Symptoms:**\n- Less than 12 months of funding\n- No plan for next funding round\n- Assuming quick revenue\n\n**Why it's risky:** Fundraising takes 3-6 months. Product and traction take longer than expected. Running out of money kills businesses.\n\n**What to probe:**\n- \"How long until you run out of money?\"\n- \"When do you need to raise next round?\"\n- \"What if revenue takes 6 months longer than expected?\"\n\n---\n\n### Weak unit economics\n\n**Symptoms:**\n- CAC > LTV\n- Long payback period\n- Low margins\n\n**Why it's risky:** Can't scale a business that loses money on each customer.\n\n**What to probe:**\n- \"What does it cost to acquire a customer?\"\n- \"How much revenue does a customer generate?\"\n- \"How long until you break even on a customer?\"\n\n**Minimum viable:** LTV should be at least 3x CAC\n\n---\n\n## Market Red Flags\n\n### Market too small\n\n**Symptoms:**\n- \"It's a $50M market\"\n- Niche within a niche\n- Only viable in one geography\n\n**Why it's risky:** Can't build a venture-scale business in a small market. Also limits exit opportunities.\n\n**What to probe:**\n- \"How many potential customers exist?\"\n- \"What's realistic market capture in 5 years?\"\n- \"Is this big enough to build a meaningful business?\"\n\n**Note:** Small markets are fine for lifestyle businesses, not venture-backed startups.\n\n---\n\n### Market too early\n\n**Symptoms:**\n- \"In 5 years, everyone will...\"\n- Requires technology that doesn't exist yet\n- Requires social change\n\n**Why it's risky:** Being too early = being wrong. Burn capital waiting for market to materialize.\n\n**What to probe:**\n- \"What needs to change for this market to exist?\"\n- \"Is that change happening now or someday?\"\n- \"Who else has tried this? What happened?\"\n\n---\n\n### Fragmented market\n\n**Symptoms:**\n- No dominant player\n- Every customer needs customization\n- Difficult to scale sales\n\n**Why it's risky:** Hard to build repeatable sales process. Every deal is custom.\n\n**What to probe:**\n- \"Why is the market fragmented?\"\n- \"Can you serve multiple segments with one product?\"\n- \"What's the path to repeatability?\"\n\n---\n\n## Product Red Flags\n\n### Too many features\n\n**Symptoms:**\n- \"It will do X, Y, Z, and also W\"\n- Trying to be \"all-in-one\" from day one\n- Feature list keeps growing\n\n**Why it's risky:** Dilutes focus, slows development, confuses customers. Usually means don't know what's actually valuable.\n\n**What to probe:**\n- \"If you could only build ONE feature, which one?\"\n- \"What's the minimum version that provides value?\"\n- \"Which features are must-have vs. nice-to-have?\"\n\n---\n\n### Solving your problem, not their problem\n\n**Symptoms:**\n- \"I wanted this so I built it\"\n- Haven't validated with other potential customers\n- Assumes others have same problem\n\n**Why it's risky:** Market of one. Your specific needs might not generalize.\n\n**What to probe:**\n- \"How many other people have confirmed they have this problem?\"\n- \"Have you talked to potential customers?\"\n- \"What do they do today to solve this?\"\n\n---\n\n### Complex product for unproven market\n\n**Symptoms:**\n- Requires months/years to build MVP\n- Can't test core hypothesis without full build\n- High technical risk\n\n**Why it's risky:** Burning time and money before learning if anyone wants it.\n\n**What to probe:**\n- \"Can you test the core hypothesis with a simpler version?\"\n- \"What's the fastest way to learn if this is valuable?\"\n- \"Could you fake this with manual processes first?\"\n\n---\n\n## Team Red Flags\n\n### Missing critical skills\n\n**Symptoms:**\n- Technical idea with no technical co-founder\n- No one with sales/marketing experience\n- No domain expertise\n\n**Why it's risky:** Have to hire critical skills you can't evaluate. Slows everything down.\n\n**What to probe:**\n- \"Who on the team can build this?\"\n- \"Who can sell this?\"\n- \"Who understands this market/customer?\"\n\n---\n\n### Solo founder (in complex space)\n\n**Why it's risky:** Complex businesses need multiple perspectives and skills. Solo founders burn out, have blind spots, and investors are more skeptical.\n\n**When it's okay:**\n- Simple product/market\n- Founder has deep expertise\n- Path to profitability without funding\n\n**What to probe:**\n- \"Why go solo vs. finding co-founder?\"\n- \"What skills are you missing?\"\n- \"Who can you lean on for blind spots?\"\n\n---\n\n### Part-time founders\n\n**Why it's risky:** Can't compete with full-time teams. Signals lack of commitment.\n\n**What to probe:**\n- \"When will you go full-time?\"\n- \"What needs to happen to make that leap?\"\n- \"Can you realistically compete part-time?\"\n\n---\n\n## Financial Red Flags\n\n### Burning cash with no traction\n\n**Symptoms:**\n- High burn rate\n- No revenue\n- No user growth\n- No clear path to either\n\n**Why it's fatal:** Running out of runway with nothing to show.\n\n**What to probe:**\n- \"How many months of runway left?\"\n- \"What metrics are improving?\"\n- \"What would you do differently if you had 6 months left?\"\n\n---\n\n### Complicated revenue model\n\n**Symptoms:**\n- \"We have multiple revenue streams\"\n- \"It depends on...\"\n- Takes 5 minutes to explain how you make money\n\n**Why it's risky:** Complicated = unproven. Usually means haven't figured out what works.\n\n**What to probe:**\n- \"What's the PRIMARY way you make money?\"\n- \"Which revenue stream will be biggest?\"\n- \"Why not focus on just one?\"\n\n---\n\n### Requires massive scale to work\n\n**Symptoms:**\n- \"At 1M users, this will work\"\n- Low margins requiring volume\n- Network effects only kick in late\n\n**Why it's risky:** Might run out of money before reaching scale. Can't survive as small business.\n\n**What to probe:**\n- \"Does this work at 1,000 users? 10,000?\"\n- \"How will you survive until reaching scale?\"\n- \"What if you never reach that scale?\"\n\n---\n\n## How to Use These Red Flags\n\n### 1. Listen for patterns\nDon't interrupt immediately when you hear a red flag. Let the user explain fully, then probe the weak point.\n\n### 2. Combine red flags\nOne red flag = caution. Multiple red flags = serious problems.\n\nExample: \"No competition\" + \"Will go viral\" + \"No specific customer\" = likely doomed\n\n### 3. Differentiate fatal vs. fixable\n- **Fatal:** Core premise is flawed (no market, impossible economics)\n- **Fixable:** Execution issues (wrong initial customer, need to pivot GTM)\n\n### 4. Be direct but constructive\n**Bad:** \"This will never work\"\n**Good:** \"This is going to be really hard because X. How do you plan to overcome that?\"\n\n### 5. Offer perspective\nShare why this is a red flag by referencing similar failures or challenges.\n\n**Good:** \"Many startups have tried 'build it and they will come' distribution. Most fail because...\"\n\n### 6. Push for evidence\nRed flags often reveal assumptions. Ask for evidence.\n\n**Good:** \"You said no competition. Have you searched [specific places]? What did you find?\"\n\n### 7. Suggest tests\nWhen you identify red flags, suggest cheap ways to de-risk.\n\n**Good:** \"Before building this, could you manually do it for 10 customers to validate demand?\"\n\n---\n\n## Red Flag Severity Assessment\n\n### üî¥ Fatal - Requires major pivot or abandonment\n- No real market/problem\n- Impossible unit economics\n- Fatal platform dependency\n- \"We'll figure out monetization later\" with no plan\n\n### üü° Serious - Needs addressing before proceeding\n- Weak competition understanding\n- No distribution strategy\n- Insufficient runway\n- Missing critical team skills\n- Unrealistic timelines\n\n### üü¢ Caution - Worth discussing but not blockers\n- Part-time founders (in early stage)\n- Limited domain expertise (can learn)\n- Small initial market (if expanding)\n- Feature complexity (if prioritizing)\n\n---\n\n## Example Red Flag Conversations\n\n### Example 1: \"No Competition\"\n\n**User:** \"Nobody is doing this, which is why it's a great opportunity.\"\n\n**You:** \"That's interesting. If it's valuable and nobody's doing it, there's usually a reason. Let me ask‚Äîhave you searched [specific places where competitors would be]?\"\n\n**User:** \"I've done some googling...\"\n\n**You:** \"What did you find? Sometimes competitors don't show up in Google searches. Have you checked Product Hunt, Crunchbase, industry conferences? What do people do TODAY instead of this?\"\n\n**User:** \"They just deal with the problem...\"\n\n**You:** \"If they're willing to live with the problem, how painful is it really? Would they pay to solve it?\"\n\n### Example 2: \"It Will Go Viral\"\n\n**User:** \"Once people see this, they'll share it with everyone.\"\n\n**You:** \"Why would someone share this? What's their incentive?\"\n\n**User:** \"Because it's useful...\"\n\n**You:** \"Useful products don't automatically go viral. What successful viral products exist in your space? What made them viral?\"\n\n**User:** \"Well, Dropbox had that referral program...\"\n\n**You:** \"Right‚Äîthey DESIGNED viral mechanics with incentives. What's your viral mechanism? And what if it doesn't go viral‚Äîwhat's plan B for customer acquisition?\"\n\n### Example 3: Targeting \"Everyone\"\n\n**User:** \"Anyone with a smartphone could use this.\"\n\n**You:** \"That's billions of people. But they all have different needs. Who needs this MOST? Who has the biggest pain?\"\n\n**User:** \"Young professionals in cities.\"\n\n**You:** \"Still pretty broad. Can you describe ONE specific person? Their job, age, what they do on weekends, what apps they use?\"\n\n**User:** \"Um, like a 28-year-old marketing manager in New York...\"\n\n**You:** \"Good‚Äîlet's use that person as our reference. What's their specific pain? How do they try to solve it today?\"\n\n---\n\n## Summary: Top 10 Red Flags\n\n1. **\"No competition\"** - Usually means no market\n2. **\"We'll monetize later\"** - No business model\n3. **\"It will go viral\"** - Magical thinking\n4. **Targeting \"everyone\"** - Unfocused\n5. **Massive behavior change required** - Too hard\n6. **Depends on big company partnership** - No control\n7. **CAC > LTV** - Broken economics\n8. **\"Build it and they will come\"** - No distribution\n9. **Less than 12 months runway** - Will run out of money\n10. **Solution looking for problem** - Technology-first\n\nWhen you see these, dig deep and push for realistic thinking.\n",
        "skills/critical-process-brief/SKILL.md": "---\nname: critical-process-brief\ndescription: Create critical process briefs through challenging dialogue that exposes operational blind spots and stress-tests workflows. Use when user wants to map out business processes, operations, or workflows. Proactively finds gaps, exposes hidden complexity, identifies fragile points, and tests scalability. Creates structured process briefs in .ideas/[name]/process.md. Triggers include \"how would this work operationally\", \"what's the process\", \"how do we deliver\", or operational details questions.\n---\n\n# Process Clarification & Stress-Testing\n\n## Overview\n\nThis skill helps users transform vague operational thinking into detailed, stress-tested process briefs through critical dialogue. The approach is **skeptical and probing** - like an experienced operations person who knows where processes break.\n\n**Core principles:**\n- **Critical, not supportive** - Find blind spots, expose hidden complexity, identify failure points\n- **Reality over assumptions** - Push for specifics, probe edge cases, test at scale\n- **Natural dialogue** - Conversational flow, not rigid questionnaire\n- **Evidence-based** - Demand concrete details, not hand-waving\n- **Structured output** - Map conversation to process brief framework\n\n**Output:** Structured process brief saved to `.ideas/[idea-name]/process.md`\n\n---\n\n## Workflow\n\n### Phase 1: Initial Understanding (2-3 minutes)\n\n**Goal:** Understand what the user thinks they know about their processes.\n\nStart with open questions:\n- \"Walk me through how this works operationally\"\n- \"What happens from start to finish?\"\n- \"Who does what?\"\n\n**Listen for:**\n- What they've thought through\n- What they're glossing over (\"we just handle it\")\n- Where they say \"it's straightforward\" (red flag)\n- What they haven't considered\n\n**Set expectations early:**\n\"I'm going to ask detailed questions to find where this breaks and what you haven't thought about. My job is to expose problems before they happen. Sound good?\"\n\n### Phase 2: Critical Exploration (20-40 minutes)\n\n**Goal:** Systematically explore processes through 20 key categories while finding blind spots and weak points.\n\n**Core Categories (always cover):**\n1. Kluczowe procesy biznesowe\n2. Aktorzy / Role\n3. Flow proces√≥w\n4. Zale≈ºno≈õci miƒôdzy procesami\n5. Pain points / Bottlenecki\n6. Edge cases / WyjƒÖtki\n\n**Data & Decisions (cover as relevant):**\n7. Inputs / Outputs\n8. Decision points\n9. Dane / Informacje\n10. Handoffy\n\n**Requirements (cover as relevant):**\n11. Czas trwania / SLA\n12. Compliance / Regulacje\n13. Wymagania jako≈õciowe\n\n**Tech & Tools (cover if relevant):**\n14. Narzƒôdzia / Systemy\n15. Integracje\n16. Automatyzacja\n\n**Economics & Scale (always cover):**\n17. Koszty operacyjne\n18. Skalowanie\n19. Ryzyka operacyjne\n20. Metryki procesu\n\n**How to navigate:**\n\n1. **Start with Core (1-6)** - Understand basic process flow and major problems\n2. **Follow natural conversation** - If user mentions data, explore Data & Decisions deeply\n3. **Use critical questions** from `references/questions-library.md` to expose gaps\n4. **Identify red flags** using `references/red-flags.md` to spot problems\n5. **Don't force all 20 categories** - Focus on what's relevant and revealing\n6. **Mark uncertainties** - Note what user doesn't know or hasn't thought about\n\n**Reference files to consult:**\n- `references/categories-guide.md` - Detailed explanation of each category\n- `references/questions-library.md` - Critical questions to expose blind spots\n- `references/red-flags.md` - Common problems and warning signs\n\n**Dialogue style:**\n\n**Your most powerful tools:**\n1. **\"Walk me through exactly what happens when...\"** - Forces detailed thinking\n2. **\"What am I missing?\"** - Finds gaps in their thinking\n3. **\"What if [specific failure]?\"** - Tests resilience\n4. **\"Who specifically?\"** - Avoids vague answers\n5. **\"How do you know?\"** - Demands evidence not assumptions\n6. **\"That seems straightforward - what am I missing?\"** - Challenges glossing over\n\n**Good examples:**\n- \"You said 'we handle orders' - walk me through every single step from order placed to delivered\"\n- \"Where does this break when volume doubles?\"\n- \"What happens if John is sick for a week?\"\n- \"You're saying 'it's simple' - that's usually not true. What am I missing?\"\n\n**Bad examples:**\n- \"That sounds good\" (non-committal)\n- \"Makes sense\" (accepting vague answers)\n- Moving on when user glosses over complexity\n- Not probing \"obvious\" steps\n\n**Key tactics:**\n\n**1. Force step-by-step detail:**\nWhen user says \"we process the order,\" drill down:\n- \"What's the literally first action?\"\n- \"Then what?\"\n- \"And after that?\"\n- \"What triggers each step?\"\n\n**2. Probe edge cases:**\nOnce you understand happy path, immediately probe exceptions:\n- \"What if data is missing?\"\n- \"What if system is down?\"\n- \"What if the person who does this is unavailable?\"\n\n**3. Use math to expose problems:**\nNumbers don't lie:\n- \"If each order takes 15 minutes and you get 100 per day, that's 25 hours. How does that work?\"\n- \"At $500 cost per order and $400 revenue, you lose money on each one?\"\n\n**4. Find single points of failure:**\nRelentlessly identify dependencies:\n- \"What happens if [person/system/partner] fails?\"\n- \"Do you have a backup?\"\n- \"What's your manual fallback?\"\n\n**5. Test at scale:**\nAlways probe 2x, 10x, 100x:\n- \"What happens when volume doubles?\"\n- \"What breaks first at 10x growth?\"\n- \"Do costs scale linearly or worse?\"\n\n**6. Name contradictions:**\nPoint out when things don't add up:\n- \"You said you need speed but also three manual approval steps. How do you balance that?\"\n- \"You said 'straightforward' but described 15 steps with 4 handoffs. Which is it?\"\n\n**7. Expose \"someone will handle it\":**\nPush for specifics:\n- \"Who specifically?\"\n- \"How many hours per week does that take?\"\n- \"Can they keep up when volume increases?\"\n\n### Phase 3: Brief Creation (5-10 minutes)\n\n**Goal:** Synthesize dialogue into structured process brief.\n\n**Steps:**\n\n1. **Determine folder** - Use existing folder from business brief or create new:\n   - If following business brief: `.ideas/[existing-name]/process.md`\n   - If standalone: `.ideas/[process-name]/process.md`\n\n2. **Generate process.md** with this structure:\n\n```markdown\n# [Process Name] - Operational Brief\n\n**Created:** [Date]\n**Status:** [Conceptual / Partially defined / Needs validation]\n**Related:** [Link to business.md if exists]\n\n---\n\n## Executive Summary\n\n**What:** [One sentence: what this process does]\n**Why:** [One sentence: why it's critical]\n**Current State:** [Conceptual / Partially implemented / Running at small scale]\n\n**Key Risks Identified:**\n1. [Biggest risk]\n2. [Second biggest risk]\n3. [Third biggest risk]\n\n---\n\n## 1. Kluczowe procesy biznesowe\n\n**Main processes:**\n[List major processes that must work, e.g., Lead gen ‚Üí Sales ‚Üí Onboarding ‚Üí Delivery ‚Üí Support]\n\n**Process details:**\n[For each major process:\n- Purpose: What it does\n- Criticality: Must-have vs. nice-to-have\n- Current state: Exists / planned / not yet considered]\n\n**Uncertainties:**\n- [What's not clear]\n\n---\n\n## 2. Aktorzy / Role\n\n**Roles involved:**\n[For each role:\n- Role name\n- Responsibilities\n- Who fills it (specific person, TBD, external)\n- Time commitment\n- Critical? (yes/no)]\n\n**Accountabilities:**\n[Who's accountable for what]\n\n**Gaps:**\n[Missing roles, unclear responsibilities]\n\n**Uncertainties:**\n- [What's not clear]\n\n---\n\n## 3. Flow proces√≥w\n\n[For each major process, document step-by-step flow]\n\n### Process: [Name]\n\n**Trigger:** [What starts this process]\n\n**Steps:**\n1. [Step 1: Actor does X]\n2. [Step 2: Decision point - if Y then A, else B]\n3. [Step 3: ...]\n...\nN. [End state]\n\n**Decision points:**\n- [Where: What's decided, by whom, based on what]\n\n**Handoffs:**\n- [Where work passes between people/systems]\n\n**Uncertainties:**\n- [What's not clear]\n\n---\n\n## 4. Zale≈ºno≈õci miƒôdzy procesami\n\n**Dependencies:**\n[What must happen before what]\n- Process A ‚Üí Process B (A must complete before B starts)\n- Process C ‚ü∑ Process D (bidirectional dependency)\n\n**Critical path:**\n[Longest chain of dependencies]\n\n**Parallel processes:**\n[What can run simultaneously]\n\n**Uncertainties:**\n- [What's not clear]\n\n---\n\n## 5. Inputs / Outputs\n\n[For key process steps]\n\n**Step:** [Name]\n- **Inputs needed:** [What's required to start]\n- **Source:** [Where inputs come from]\n- **Outputs produced:** [What's created]\n- **Consumers:** [Who uses outputs]\n- **Format:** [Data format, structure]\n\n**Mismatches identified:**\n- [Where outputs don't match needed inputs]\n\n**Uncertainties:**\n- [What's not clear]\n\n---\n\n## 6. Decision Points\n\n[Key decisions in processes]\n\n**Decision:** [What's being decided]\n- **Who decides:** [Person or role]\n- **Criteria:** [How to decide - objective or subjective]\n- **Options:** [Possible outcomes]\n- **Time:** [How long it takes]\n- **Bottleneck risk:** [High/Medium/Low]\n\n**Uncertainties:**\n- [What's not clear]\n\n---\n\n## 7. Dane / Informacje\n\n**Critical data:**\n[What data is essential]\n\n**Data source:** [Where it lives]\n**Access method:** [How to get it]\n**Quality:** [Current accuracy, completeness]\n**Owner:** [Who maintains it]\n\n**Data flows:**\n[How data moves through process]\n\n**Data risks:**\n- [Missing data, wrong data, inaccessible data]\n\n**Uncertainties:**\n- [What's not clear]\n\n---\n\n## 8. Handoffy\n\n[Where work passes between people/teams/systems]\n\n**Handoff:** [A ‚Üí B]\n- **What's handed off:** [Work, data, responsibility]\n- **How:** [Email, ticket, verbal, automated]\n- **Notification:** [How B knows there's work]\n- **Risk:** [What can go wrong]\n\n**Uncertainties:**\n- [What's not clear]\n\n---\n\n## 9. Pain Points / Bottlenecki\n\n**Current pain points:**\n[What's slow, frustrating, error-prone today]\n\n**Bottlenecks:**\n[Where capacity is limited]\n- **Location:** [Which step]\n- **Impact:** [How it slows things]\n- **Workaround:** [Current solution if any]\n\n**Uncertainties:**\n- [What's not clear]\n\n---\n\n## 10. Edge Cases / WyjƒÖtki\n\n**Exception scenarios:**\n[What unusual things could happen]\n\n**For each edge case:**\n- **Scenario:** [What happens]\n- **Frequency:** [How often / likely]\n- **Current handling:** [What you do today / plan to do]\n- **Impact:** [What happens if not handled]\n\n**Gaps:**\n[Edge cases not yet considered]\n\n**Uncertainties:**\n- [What's not clear]\n\n---\n\n## 11. Ryzyka operacyjne\n\n**Critical risks:**\n\n**Risk:** [What could go wrong]\n- **Type:** [Single point of failure / Dependency / Capacity / Quality / Compliance / Security]\n- **Impact:** [What happens if it occurs]\n- **Likelihood:** [High / Medium / Low]\n- **Mitigation:** [Plan to address / None yet]\n\n**Single points of failure:**\n- [Person: X is only one who can do Y]\n- [System: If Z goes down, everything stops]\n- [Partner: Dependent on A with no backup]\n\n**Uncertainties:**\n- [What's not clear]\n\n---\n\n## 12. Czas trwania / SLA\n\n**Process durations:**\n\n**Process:** [Name]\n- **Average time:** [How long typically]\n- **Best case:** [Fastest possible]\n- **Worst case:** [Longest observed/expected]\n- **SLA committed:** [What you've promised customers]\n- **% meeting SLA:** [Current performance]\n\n**Delays:**\n[What causes slowdowns]\n\n**Uncertainties:**\n- [What's not clear]\n\n---\n\n## 13. Compliance / Regulacje\n\n**Regulatory requirements:**\n[What regulations apply]\n\n**For each requirement:**\n- **Regulation:** [Name - GDPR, PCI, HIPAA, etc.]\n- **Applies to:** [Which processes]\n- **Requirements:** [What you must do]\n- **Current state:** [Compliant / Working on it / Not yet addressed]\n- **Evidence needed:** [Audit trail, documentation, etc.]\n\n**Risks:**\n[What happens if non-compliant]\n\n**Uncertainties:**\n- [What's not clear]\n\n---\n\n## 14. Wymagania jako≈õciowe\n\n**Quality standards:**\n[What quality means for this process]\n\n**Metrics:**\n- **Accuracy:** [Target error rate]\n- **Consistency:** [Standard variance]\n- **Completeness:** [All steps done]\n\n**Quality checks:**\n[When and how quality is verified]\n\n**Current quality:**\n- **Error rate:** [Current %]\n- **Rework rate:** [How often redo work]\n\n**Uncertainties:**\n- [What's not clear]\n\n---\n\n## 15. Narzƒôdzia / Systemy\n\n**Tools used:**\n\n**Tool:** [Name]\n- **Purpose:** [What it's for]\n- **Used by:** [Who]\n- **When:** [Which process steps]\n- **Cost:** [Amount]\n- **Limitations:** [What it can't do]\n- **Scale limit:** [Max capacity]\n\n**Tool gaps:**\n[Where manual work happens because no tool]\n\n**Uncertainties:**\n- [What's not clear]\n\n---\n\n## 16. Integracje\n\n**System integrations:**\n\n**Integration:** [System A ‚Üí System B]\n- **Data shared:** [What's transferred]\n- **Method:** [API, file, manual, ETL]\n- **Frequency:** [Real-time, batch, on-demand]\n- **Reliability:** [How often it breaks]\n- **Error handling:** [What happens on failure]\n\n**Integration gaps:**\n[Where manual work bridges systems]\n\n**Uncertainties:**\n- [What's not clear]\n\n---\n\n## 17. Automatyzacja\n\n**Automation state:**\n\n**Fully automated:**\n[What runs without human involvement]\n\n**Semi-automated:**\n[What requires human trigger or approval]\n\n**Manual:**\n[What's done by hand]\n\n**Automation roadmap:**\n[What to automate next, in priority order]\n\n**Why not automated:**\n[Reasons things are still manual - complexity, volume, ROI]\n\n**Uncertainties:**\n- [What's not clear]\n\n---\n\n## 18. Koszty operacyjne\n\n**Cost breakdown:**\n\n**Cost category:** [Labor / Tools / Infrastructure / Transaction costs / Overhead]\n- **Amount:** [$ or % of total]\n- **Fixed vs. variable:** [Does it scale with volume?]\n\n**Unit economics:**\n- **Cost per [unit]:** [$X]\n- **Revenue per [unit]:** [$Y]\n- **Margin:** [Profit or loss per unit]\n\n**Biggest costs:**\n[Top 3 cost drivers]\n\n**Uncertainties:**\n- [What's not clear]\n\n---\n\n## 19. Skalowanie\n\n**Current capacity:**\n- **Volume:** [Current # of transactions/customers/orders per day/month]\n- **Utilization:** [What % of max capacity]\n\n**Scale testing:**\n\n**At 2x volume:**\n- **What breaks:** [First bottleneck]\n- **Cost impact:** [How costs change]\n- **Changes needed:** [What to fix]\n\n**At 10x volume:**\n- **What breaks:** [Major problems]\n- **Cost impact:** [Unit economics at scale]\n- **Changes needed:** [Major rebuilds required]\n\n**At 100x volume:**\n- **Feasibility:** [Possible with current approach?]\n- **Complete redesign needed:** [Yes/No and why]\n\n**Uncertainties:**\n- [What's not clear]\n\n---\n\n## 20. Metryki procesu\n\n**Key metrics tracked:**\n\n**Metric:** [Name]\n- **What it measures:** [Description]\n- **Current value:** [Number]\n- **Target value:** [Goal]\n- **Frequency:** [How often reviewed]\n- **Action trigger:** [What value triggers action]\n\n**Visibility:**\n[Real-time dashboard / Periodic reports / Manual calculation]\n\n**Gaps:**\n[What should be measured but isn't]\n\n**Uncertainties:**\n- [What's not clear]\n\n---\n\n## Summary Assessment\n\n### Strengths\n[What's well thought through]\n\n### Critical Weaknesses\n**Top 5 problems that will prevent success or scale:**\n1. [Most critical issue]\n2. [Second most critical]\n3. [Third most critical]\n4. [Fourth]\n5. [Fifth]\n\n### Red Flags Identified\n[List red flags from references/red-flags.md]\n- üî¥ Critical: [Fatal problems]\n- üü° Serious: [Major problems]\n- üü¢ Caution: [Watch these]\n\n### Next Steps\n\n**Must address before launching:**\n1. [Critical item]\n2. [Critical item]\n3. [Critical item]\n\n**Should address for scale:**\n1. [Important for growth]\n2. [Important for growth]\n3. [Important for growth]\n\n**Consider for optimization:**\n1. [Nice to have]\n2. [Nice to have]\n\n---\n\n## Conversation Notes\n\n[Additional context, observations, or specific quotes that are important]\n\n---\n\n## Appendix: Detailed Process Flows\n\n[If processes are complex, include detailed flowcharts or step-by-step breakdowns here]\n```\n\n3. **Review with user:**\n   - Show the brief\n   - Ask if anything misrepresented or missing\n   - Offer to refine sections\n   - Be honest about severity of problems found\n\n4. **Save the file** to `.ideas/[idea-name]/process.md`\n\n### Phase 4: Wrap-up\n\n**Be brutally honest:**\nIf you found critical problems, say so directly:\n- \"Based on our conversation, I found [X critical problems] that will prevent this from working at scale. Here's why...\"\n- \"These [3 issues] are show-stoppers that must be addressed before you can operate.\"\n\n**Offer next steps:**\n- \"Want to dive deeper into [specific problem area]?\"\n- \"Should we talk about how to address the top 3 risks?\"\n- \"Ready to think about the application that would support these processes?\" (triggers critical-app-brief)\n\n**Positive framing:**\n\"Finding these problems now is much better than discovering them after you've built everything. Let's prioritize what to fix first.\"\n\n---\n\n## Special Cases\n\n### User doesn't know\n\n**If user doesn't know:**\n- \"That's fine - mark it as uncertain and something to figure out\"\n- \"What would you need to know to answer this?\"\n- \"Who could answer this question?\"\n\n**Don't:**\n- Fill in with your assumptions\n- Skip the question\n- Let them move on without marking uncertainty\n\n### \"It's straightforward\"\n\n**When user says this:**\nALWAYS probe deeper. Nothing is straightforward.\n\n**Response:**\n- \"That seems straightforward - walk me through every step so I understand.\"\n- \"When things seem simple, there's usually hidden complexity. What am I missing?\"\n- \"I've seen 'simple' processes have 20 steps. Help me understand yours.\"\n\n### User is defensive\n\n**If user pushes back:**\n- \"I know this feels like I'm poking holes. That's the point - better to find holes now than after you build it.\"\n- \"These are the same questions reality will ask. Customers won't care that you didn't think of it.\"\n- \"Would you rather discover these problems in this conversation or after you've wasted 6 months building?\"\n\n### Theoretical vs. Actual\n\n**If process doesn't exist yet:**\n- Mark everything as \"Planned\" or \"Conceptual\"\n- Note assumptions clearly\n- Identify what needs validation\n\n**If process exists:**\n- Ask about actual performance, not ideal\n- Get real numbers\n- Probe actual failures that have occurred\n\n---\n\n## Quality Checklist\n\nBefore finishing, ensure:\n\n‚úÖ **Core categories covered:** All 6 core categories addressed\n‚úÖ **Step-by-step flows:** Detailed process flows, not hand-waving\n‚úÖ **Edge cases probed:** Not just happy path\n‚úÖ **Single points of failure identified:** All dependencies mapped\n‚úÖ **Scale tested:** Explored 2x, 10x, 100x scenarios\n‚úÖ **Numbers documented:** Costs, times, volumes, error rates\n‚úÖ **Red flags called out:** All problems explicitly listed\n‚úÖ **Uncertainties marked:** Clear what's unknown\n‚úÖ **Actionable next steps:** Specific things to address\n\n---\n\n## Key Reminders\n\n**DO:**\n- Assume user hasn't thought through details\n- Force step-by-step thinking\n- Probe edge cases relentlessly\n- Use math to expose problems\n- Find single points of failure\n- Test at scale (2x, 10x, 100x)\n- Mark uncertainties explicitly\n- Point out contradictions\n- Challenge \"it's straightforward\"\n\n**DON'T:**\n- Accept vague answers (\"we handle it\")\n- Let user gloss over complexity\n- Skip edge cases\n- Assume they know what they're talking about\n- Fill in blanks with your assumptions\n- Move on when something doesn't make sense\n- Sugarcoat serious problems\n\n**Your mindset:** You're an experienced operations person who has seen processes break in production. Your job is to find problems BEFORE they happen, not to make the user feel good about their half-baked thinking.\n\n**Remember:** \"It's straightforward\" is the most dangerous phrase in operations. Nothing is straightforward. Dig deeper.\n",
        "skills/critical-process-brief/references/categories-guide.md": "# Process Brief Categories Guide\n\nThis guide explains each category in the process brief with practical context for stress-testing operational thinking.\n\n---\n\n## CORE - Podstawy procesu\n\n### 1. Kluczowe procesy biznesowe\n\n**What it is:** The major operational processes that must function for the business to work.\n\n**Why it matters:** Missing a critical process = business doesn't work. Understanding all processes helps identify dependencies and complexity.\n\n**Common processes by business type:**\n- **SaaS:** Lead generation ‚Üí Sales ‚Üí Onboarding ‚Üí Usage ‚Üí Support ‚Üí Renewal\n- **E-commerce:** Marketing ‚Üí Purchase ‚Üí Fulfillment ‚Üí Delivery ‚Üí Returns ‚Üí Support\n- **Marketplace:** Supplier onboarding ‚Üí Buyer acquisition ‚Üí Matching ‚Üí Transaction ‚Üí Fulfillment\n- **Service business:** Lead gen ‚Üí Sales ‚Üí Delivery ‚Üí Invoicing ‚Üí Support\n\n**Key questions:**\n- What are ALL the processes needed from customer awareness to value delivery?\n- Which processes are customer-facing vs. internal?\n- Which processes are revenue-generating vs. support?\n- Are there processes you haven't thought about? (billing, compliance, hiring, etc.)\n\n**Red flags:**\n- Only thinking about the \"happy path\" main process\n- Missing support/exception processes\n- Forgetting back-office processes (finance, legal, HR)\n- Underestimating complexity of \"simple\" processes\n\n---\n\n### 2. Aktorzy / Role\n\n**What it is:** Every person or entity that participates in processes, and what they're responsible for.\n\n**Why it matters:** Unclear roles = confusion, delays, things falling through cracks. Each actor needs clear ownership.\n\n**Types of actors:**\n- **External:** Customer, supplier, partner, regulator, auditor\n- **Internal:** Sales, operations, support, engineering, finance, legal\n- **System/Automated:** Bots, APIs, automated workflows\n\n**Key questions:**\n- Who does what in each process?\n- Who makes decisions at each decision point?\n- Who is accountable if something goes wrong?\n- Are roles clearly defined or will people step on each other's toes?\n- Do you have people to fill these roles?\n\n**Red flags:**\n- \"We'll figure out who does what later\"\n- Assuming one person can do multiple complex roles\n- No clear decision-maker for critical choices\n- Relying on external actors you don't control\n\n---\n\n### 3. Flow proces√≥w\n\n**What it is:** Step-by-step sequence of what happens in each process.\n\n**Why it matters:** Understanding detailed flow reveals hidden complexity, dependencies, and potential failure points.\n\n**How to document:**\n- Start ‚Üí Step 1 ‚Üí Decision point ‚Üí Step 2 ‚Üí ... ‚Üí End\n- Include all branches (success, failure, exceptions)\n- Note where process hands off between actors\n\n**Key questions:**\n- What's the first step? What triggers it?\n- What happens next? And then?\n- Where are the decision points? What are the options at each?\n- Where does the process hand off between people/systems?\n- What's the end state? How do you know it's complete?\n- What happens if a step fails?\n\n**Red flags:**\n- \"It's straightforward\" (nothing is straightforward)\n- Missing exception paths\n- Vague steps like \"handle the order\" (what specifically?)\n- No clear end state\n\n---\n\n### 4. Zale≈ºno≈õci miƒôdzy procesami\n\n**What it is:** How processes depend on each other - what must happen before what.\n\n**Why it matters:** Dependencies create bottlenecks, delays, and complexity. Understanding them helps optimize and identify risks.\n\n**Types of dependencies:**\n- **Sequential:** Process B can't start until Process A completes\n- **Parallel:** Processes run simultaneously\n- **Conditional:** Process C only runs if Process A had outcome X\n- **Circular:** Process A feeds Process B which feeds back to Process A\n\n**Key questions:**\n- Which processes must happen in sequence?\n- Which can happen in parallel?\n- What happens if a dependency fails or delays?\n- Are there circular dependencies? (usually bad)\n- Which dependencies are hard constraints vs. preferences?\n\n**Red flags:**\n- Long chains of dependencies (slow, fragile)\n- Circular dependencies (complexity, potential deadlock)\n- Dependencies on external actors you don't control\n- Not understanding critical path\n\n---\n\n## DATA & DECISIONS - Informacje i decyzje\n\n### 5. Inputs / Outputs\n\n**What it is:** What goes into each process step and what comes out.\n\n**Why it matters:** Mismatched inputs/outputs = process breaks. Understanding data flow reveals integration needs and potential errors.\n\n**For each process step, identify:**\n- **Inputs:** What information, materials, approvals, or resources are needed?\n- **Outputs:** What is produced? (data, product, decision, notification)\n- **Format:** What form? (structured data, document, physical item)\n\n**Key questions:**\n- What inputs are required for each step to start?\n- Where do those inputs come from?\n- What if an input is missing or wrong?\n- What outputs are produced at each step?\n- Who consumes those outputs?\n- Are outputs in the format consumers need?\n\n**Red flags:**\n- Outputs from one step don't match inputs needed by next step\n- Missing data that's needed downstream\n- Manual data entry/transformation between steps (error-prone)\n- No validation of input quality\n\n---\n\n### 6. Decision points\n\n**What it is:** Where choices must be made in the process, who makes them, and based on what criteria.\n\n**Why it matters:** Decisions slow things down and introduce variability. Unclear decision criteria = inconsistency and delays.\n\n**For each decision point:**\n- **What's being decided?** (approve/reject, which path, how much, etc.)\n- **Who decides?** (person, role, automated rule)\n- **Based on what?** (criteria, data, judgment)\n- **How long does it take?**\n- **What happens for each outcome?**\n\n**Key questions:**\n- What decisions must be made in this process?\n- Are decision criteria clear and objective, or subjective?\n- Can decisions be automated?\n- What happens if decision-maker is unavailable?\n- What if decision is wrong? Can it be reversed?\n\n**Red flags:**\n- Too many decision points (slow process)\n- Subjective/unclear decision criteria\n- Single person as bottleneck for all decisions\n- No escalation path when decision is unclear\n\n---\n\n### 7. Dane / Informacje\n\n**What it is:** What data is needed, where it's stored, how it flows, and who has access.\n\n**Why it matters:** Data is the lifeblood of processes. Missing, wrong, or inaccessible data breaks everything.\n\n**Key aspects:**\n- **What data:** Customer info, product data, transaction records, etc.\n- **Where stored:** Database, CRM, spreadsheet, paper, someone's head\n- **How accessed:** API, manual lookup, automated sync\n- **Data quality:** How accurate? How current?\n- **Data ownership:** Who maintains it?\n\n**Key questions:**\n- What data is needed for each process?\n- Where does that data live today?\n- How do you get access to it?\n- How do you know it's accurate and current?\n- What happens if data is wrong?\n- Who updates the data?\n\n**Red flags:**\n- Data in multiple places that can get out of sync\n- Critical data only in someone's head\n- No single source of truth\n- Manual data entry in multiple systems\n- No data validation\n\n---\n\n### 8. Handoffy\n\n**What it is:** Points where work passes from one person/team/system to another.\n\n**Why it matters:** Handoffs are where things get dropped, delayed, or miscommunicated. Each handoff is a risk point.\n\n**For each handoff:**\n- **From who/what ‚Üí To who/what**\n- **What's being handed off?** (work, data, decision, responsibility)\n- **How?** (email, ticket, verbal, automated)\n- **When?** (immediately, batched, scheduled)\n- **What can go wrong?**\n\n**Key questions:**\n- Where do handoffs happen in the process?\n- How is the receiving party notified?\n- How do they know what to do?\n- What if handoff fails? (person on vacation, system down)\n- Is there a record of the handoff?\n- How long does handoff take?\n\n**Red flags:**\n- Many handoffs (each is a delay and risk)\n- Informal handoffs (verbal, email) for critical work\n- No notification mechanism\n- No tracking of handoff status\n- Handoff requires manual coordination\n\n---\n\n## PROBLEMS & EDGE CASES - Problemy\n\n### 9. Pain points / Bottlenecki\n\n**What it is:** Where the process is slow, frustrating, error-prone, or breaks down.\n\n**Why it matters:** Pain points cost time and money. Bottlenecks limit capacity and growth.\n\n**Types of problems:**\n- **Speed:** Takes too long\n- **Quality:** High error rate\n- **Capacity:** Can't handle volume\n- **Cost:** Too expensive to run\n- **Experience:** Frustrating for users\n- **Reliability:** Breaks frequently\n\n**Key questions:**\n- What's the slowest part of the process?\n- Where do errors happen most?\n- What do people complain about?\n- What breaks when volume increases?\n- Where do you need manual intervention most?\n- What would you fix first if you could?\n\n**Red flags:**\n- \"It works fine\" (nothing works fine, push harder)\n- Not knowing where bottlenecks are\n- Accepting pain points as inevitable\n- No metrics to identify problems\n\n---\n\n### 10. Edge cases / WyjƒÖtki\n\n**What it is:** Unusual situations, exceptions, and what-if scenarios that don't follow the happy path.\n\n**Why it matters:** Edge cases reveal process fragility. \"It usually works\" isn't good enough - what happens when it doesn't?\n\n**Common edge cases:**\n- **Input errors:** Wrong data, missing fields, invalid format\n- **System failures:** API down, database offline, network issue\n- **Human errors:** Wrong button clicked, forgot a step\n- **Timing issues:** Late delivery, expired token, timeout\n- **Volume spikes:** 10x normal traffic\n- **External issues:** Payment fails, partner unavailable\n\n**Key questions:**\n- What unusual situations could occur?\n- What happens when systems fail?\n- What if someone makes a mistake?\n- What if data is invalid?\n- What if external dependency is down?\n- Is there a manual fallback?\n\n**Red flags:**\n- \"That will never happen\" (it will)\n- No error handling\n- Process completely breaks on edge case\n- No way to recover from failures\n- Manual intervention required for every exception\n\n---\n\n### 11. Ryzyka operacyjne\n\n**What it is:** Things that could go wrong that would significantly impact operations.\n\n**Why it matters:** Understanding risks helps prioritize what to build robustly vs. what can be fragile early on.\n\n**Types of risks:**\n- **Single point of failure:** One person, one system, one supplier\n- **Dependency risk:** Reliance on external party\n- **Capacity risk:** Can't handle growth\n- **Quality risk:** High error rate leads to customer churn\n- **Compliance risk:** Violate regulation, get shut down\n- **Security risk:** Data breach, fraud\n\n**Key questions:**\n- What's your single point of failure?\n- What happens if key person leaves?\n- What if a critical system goes down?\n- What if a partner stops working with you?\n- What could get you sued or shut down?\n- What would happen in a worst-case scenario?\n\n**Red flags:**\n- No redundancy for critical components\n- One person knows how everything works\n- Complete dependency on one vendor/partner\n- No disaster recovery plan\n- Not thinking about risks until they happen\n\n---\n\n## REQUIREMENTS - Wymagania\n\n### 12. Czas trwania / SLA\n\n**What it is:** How long each process step takes and what time commitments you've made to customers.\n\n**Why it matters:** Time is money and customer expectation. Slow processes cost more and create bad experience.\n\n**For each process:**\n- **Average duration:** How long does it typically take?\n- **Best case:** Fastest possible\n- **Worst case:** Longest observed\n- **SLA:** What have you promised customers?\n- **Dependencies:** What affects duration?\n\n**Key questions:**\n- How long does the full process take end-to-end?\n- What's the longest step?\n- What slows things down?\n- Have you promised customers specific timeframes?\n- Can you consistently meet those commitments?\n- What happens if you miss SLA?\n\n**Red flags:**\n- Don't know how long processes take\n- Promising SLAs you can't meet consistently\n- Long delays with no visibility to customer\n- No way to track if you're meeting commitments\n\n---\n\n### 13. Compliance / Regulacje\n\n**What it is:** Legal, regulatory, and contractual requirements the process must satisfy.\n\n**Why it matters:** Non-compliance = fines, lawsuits, shutdown. Can't ignore regulations.\n\n**Common requirements:**\n- **Data protection:** GDPR, CCPA, HIPAA\n- **Financial:** PCI DSS, SOX, anti-money laundering\n- **Industry-specific:** FDA, FCC, SEC, etc.\n- **Contractual:** SLAs, terms of service, partner agreements\n- **Internal:** Company policies, audit requirements\n\n**Key questions:**\n- What regulations apply to your business?\n- What are the specific requirements?\n- Which processes need to be compliant?\n- How do you prove compliance? (audit trail, documentation)\n- What happens if you're not compliant?\n- Do you need certifications?\n\n**Red flags:**\n- \"We'll worry about compliance later\" (dangerous)\n- Not understanding what regulations apply\n- No documentation/audit trail\n- Assuming you're too small to matter to regulators\n- Storing sensitive data without proper controls\n\n---\n\n### 14. Wymagania jako≈õciowe\n\n**What it is:** Quality standards the process must meet - accuracy, consistency, reliability.\n\n**Why it matters:** Poor quality = rework, refunds, churn. Quality problems compound over time.\n\n**Quality dimensions:**\n- **Accuracy:** Correctness of outputs\n- **Consistency:** Same result every time\n- **Completeness:** All required steps done\n- **Timeliness:** Done on time\n- **Reliability:** Works every time\n\n**Key questions:**\n- What quality standards apply?\n- How do you measure quality?\n- What's acceptable error rate?\n- How do you ensure consistency?\n- What happens when quality fails?\n- Who checks quality?\n\n**Red flags:**\n- No quality standards defined\n- Not measuring quality\n- High error rates considered normal\n- No quality checks until customer complains\n- Manual quality control that doesn't scale\n\n---\n\n## TECH & TOOLS - Technologia\n\n### 15. Narzƒôdzia / Systemy\n\n**What it is:** Software, hardware, and tools used in each process step.\n\n**Why it matters:** Tools enable or constrain processes. Wrong tools slow you down or prevent scaling.\n\n**For each tool:**\n- **Purpose:** What's it used for?\n- **Users:** Who uses it?\n- **When:** At which process steps?\n- **Cost:** How much does it cost?\n- **Limitations:** What can't it do?\n\n**Key questions:**\n- What tools do you use in each step?\n- Are they the right tools or just what you happen to use?\n- Do tools integrate with each other?\n- What manual work happens between tools?\n- Can tools handle your growth?\n- What happens if a tool goes down?\n\n**Red flags:**\n- Too many tools that don't integrate\n- Manual work copying data between tools\n- Tools that don't scale\n- Expensive tools for simple needs\n- Critical process depends on single tool with no backup\n\n---\n\n### 16. Integracje\n\n**What it is:** How systems connect to each other - APIs, data sync, file transfers.\n\n**Why it matters:** Bad integrations = manual work, errors, delays. Good integrations enable automation and scale.\n\n**For each integration:**\n- **What systems:** A ‚Üí B\n- **What data:** What's being shared?\n- **How:** API, file transfer, manual, ETL\n- **When:** Real-time, batch, on-demand\n- **Error handling:** What if integration fails?\n\n**Key questions:**\n- What systems need to talk to each other?\n- How do they integrate today?\n- Is integration real-time or batch?\n- What happens if integration breaks?\n- Do you have to build custom integrations?\n- What's the cost/complexity of integrations?\n\n**Red flags:**\n- No integrations (everything manual)\n- Fragile integrations that break often\n- Building all integrations yourself\n- No error handling or retry logic\n- Data sync issues between systems\n\n---\n\n### 17. Automatyzacja\n\n**What it is:** What's automated, what's manual, and what could be automated.\n\n**Why it matters:** Manual work doesn't scale and is error-prone. Automation enables growth and consistency.\n\n**Categories:**\n- **Fully automated:** No human involvement\n- **Semi-automated:** Human triggers or approves\n- **Manual with tools:** Human does it with software help\n- **Fully manual:** Human does everything\n\n**Key questions:**\n- What's automated today?\n- What's still manual?\n- Why is it manual? (complexity, volume too low, technical limitation)\n- What should be automated next?\n- What should stay manual? (judgment, customer touch, exceptions)\n- What's the ROI of automation?\n\n**Red flags:**\n- Everything is manual (won't scale)\n- Automating before understanding process (premature optimization)\n- No plan for what to automate as you grow\n- Assuming you can automate everything\n\n---\n\n## ECONOMICS & SCALE - Ekonomia\n\n### 18. Koszty operacyjne\n\n**What it is:** How much it costs to run each process.\n\n**Why it matters:** High operational costs eat into margins. Understanding costs helps prioritize optimization.\n\n**Cost categories:**\n- **Labor:** People time (salary √ó hours)\n- **Tools:** Software subscriptions, licenses\n- **Infrastructure:** Servers, hosting, services\n- **Transaction costs:** Payment processing, per-unit fees\n- **Overhead:** Support, management, facilities\n\n**Key questions:**\n- What does each process cost to run?\n- What's the biggest cost component?\n- What's the cost per unit? (per customer, per order, per transaction)\n- How do costs change with volume?\n- Where can you reduce costs?\n- Are costs fixed or variable?\n\n**Red flags:**\n- Don't know what processes cost\n- Cost per unit higher than revenue per unit\n- Fixed costs that don't scale\n- Expensive manual processes that could be automated\n- Not tracking costs at all\n\n---\n\n### 19. Skalowanie\n\n**What it is:** What happens when volume increases 2x, 10x, 100x.\n\n**Why it matters:** Processes that work at 10 customers often break at 100 or 1000. Understanding scale limitations helps plan growth.\n\n**Scale dimensions:**\n- **Volume:** More transactions/customers/orders\n- **Speed:** Faster processing required\n- **Complexity:** More edge cases, more integration\n- **Geography:** More locations, more languages\n- **Team:** More people doing the work\n\n**Key questions:**\n- What happens when volume doubles?\n- Where does the process break?\n- What's the current capacity limit?\n- What needs to change to handle 10x volume?\n- Do costs scale linearly or better?\n- What becomes a bottleneck first?\n\n**Red flags:**\n- Process works only at current tiny scale\n- Costs scale faster than revenue\n- Bottlenecks obvious at 2x volume\n- Manual steps that can't scale\n- \"We'll hire more people\" as only scale strategy\n\n---\n\n### 20. Metryki procesu\n\n**What it is:** How you measure process performance and health.\n\n**Why it matters:** Can't improve what you don't measure. Metrics show when process is degrading.\n\n**Key metrics categories:**\n- **Speed:** Cycle time, lead time, throughput\n- **Quality:** Error rate, defect rate, customer satisfaction\n- **Cost:** Cost per unit, cost per transaction\n- **Capacity:** Utilization, queue length, backlog\n- **Reliability:** Uptime, success rate, failure rate\n\n**Key questions:**\n- What metrics do you track for each process?\n- How often do you review them?\n- What are target values?\n- What do you do when metrics degrade?\n- Do you have real-time visibility or only periodic reports?\n\n**Red flags:**\n- Not measuring anything\n- Measuring vanity metrics that don't matter\n- No alerts when metrics degrade\n- Metrics exist but no one looks at them\n- No action taken when metrics show problems\n\n---\n\n## Using This Guide\n\n**During dialogue:**\n- Start with Core categories (1-4) to understand basic process\n- Explore Data & Decisions (5-8) to understand information flow\n- Probe Problems (9-11) to find weaknesses\n- Cover Requirements (12-14) if relevant to business\n- Discuss Tech (15-17) if technology is involved\n- Analyze Economics (18-20) to understand viability\n\n**Critical attitude:**\n- Assume user hasn't thought through details\n- Ask about specific scenarios\n- Push for numbers (time, cost, volume)\n- Identify what they don't know\n- Point out where process will break\n\n**Recording:**\n- Capture what user knows\n- Mark what's uncertain\n- Note assumptions that need testing\n- Identify biggest risks\n",
        "skills/critical-process-brief/references/questions-library.md": "# Critical Questions Library for Processes\n\nThis library contains challenging questions designed to expose blind spots, find weaknesses, and stress-test operational thinking.\n\n## Approach\n\n**Goal:** Find what the user DOESN'T know, not just what they do know.\n\n**Tactics:**\n- Ask about specific scenarios\n- Push for numbers and details\n- Probe edge cases\n- Identify single points of failure\n- Challenge \"it's straightforward\" statements\n- Ask \"what if\" repeatedly\n\n---\n\n## CORE - Podstawy procesu\n\n### 1. Kluczowe procesy biznesowe\n\n**Identifying blind spots:**\n- \"Walk me through every step from when a customer first hears about you to when they get value. What am I missing?\"\n- \"What happens between [Step A] and [Step B]? That seems like a big jump.\"\n- \"You mentioned the main process. What about support? Returns? Billing? Compliance?\"\n- \"What processes run in the background that customers don't see?\"\n\n**Testing completeness:**\n- \"If I'm your first customer tomorrow, what needs to happen?\"\n- \"What happens after the customer pays? Walk me through delivery.\"\n- \"How do you handle [support tickets, refunds, changes, cancellations]?\"\n- \"What about internal processes - hiring, finance, legal?\"\n\n**Exposing assumptions:**\n- \"You said 'then we fulfill the order' - what specifically does that involve?\"\n- \"How many steps are in your 'simple' onboarding process?\"\n- \"When you say 'customer support,' what exactly does that mean operationally?\"\n\n---\n\n### 2. Aktorzy / Role\n\n**Finding gaps:**\n- \"Who specifically does each step? Name a person or role.\"\n- \"Who makes decisions when [X situation] occurs?\"\n- \"What happens if [key person] is on vacation or leaves?\"\n- \"Do you actually have people to fill these roles?\"\n\n**Testing clarity:**\n- \"Who's responsible if [specific thing] goes wrong?\"\n- \"If two people think they're both responsible for X, how do you resolve that?\"\n- \"What happens when responsibilities overlap? Who has final say?\"\n\n**Exposing dependencies:**\n- \"You said 'the team will handle it' - which specific person?\"\n- \"How many people need to touch this before it's complete?\"\n- \"Are you depending on external people you don't control?\"\n\n**Testing capacity:**\n- \"How many hours per week will [role] spend on this?\"\n- \"Can one person really do [all these things]?\"\n- \"When volume doubles, who's overwhelmed first?\"\n\n---\n\n### 3. Flow proces√≥w\n\n**Getting specific:**\n- \"Walk me through step by step. What's literally the first action?\"\n- \"Then what? And after that?\"\n- \"You said 'we process it' - what are the actual steps in 'processing'?\"\n- \"What triggers this process to start?\"\n\n**Finding decision points:**\n- \"At what points do you need to make a choice?\"\n- \"What are the options at each decision point?\"\n- \"Who makes that decision and how long does it take?\"\n\n**Testing exception paths:**\n- \"What happens if [Step 3] fails?\"\n- \"What if the customer provides incomplete information?\"\n- \"What if [System X] is down when you need it?\"\n- \"How do you recover from errors?\"\n\n**Exposing handoffs:**\n- \"Where does this hand off from one person to another?\"\n- \"How does the next person know they need to do their part?\"\n- \"What happens if the handoff is missed?\"\n\n---\n\n### 4. Zale≈ºno≈õci miƒôdzy procesami\n\n**Mapping dependencies:**\n- \"What has to happen before this process can start?\"\n- \"What's blocked waiting for this to finish?\"\n- \"Can these run in parallel or must they be sequential?\"\n\n**Testing critical path:**\n- \"What's the longest chain of dependent steps?\"\n- \"If we could speed up one thing, what would have biggest impact?\"\n- \"What's the bottleneck in the dependency chain?\"\n\n**Finding circular dependencies:**\n- \"Does Process A depend on Process B which depends on Process A?\"\n- \"How do you break circular dependencies?\"\n\n**Testing fragility:**\n- \"What happens if Process A takes 2x longer than expected?\"\n- \"What if Process B fails completely?\"\n- \"What's your single point of failure in the dependency chain?\"\n\n---\n\n## DATA & DECISIONS - Informacje i decyzje\n\n### 5. Inputs / Outputs\n\n**Identifying inputs:**\n- \"What information do you need before you can start this step?\"\n- \"Where does that information come from?\"\n- \"What if that information is missing or wrong?\"\n- \"Who provides those inputs?\"\n\n**Testing outputs:**\n- \"What gets produced at the end of this step?\"\n- \"Who needs that output? What do they do with it?\"\n- \"What format is it in? Is that the format they need?\"\n- \"How do they know the output is ready?\"\n\n**Finding mismatches:**\n- \"The previous step outputs X, but this step needs Y. How do you transform it?\"\n- \"Is any manual work needed to convert outputs to inputs?\"\n- \"What happens if output quality is poor?\"\n\n---\n\n### 6. Decision points\n\n**Identifying decisions:**\n- \"At what points in the process does someone need to make a choice?\"\n- \"What are they deciding between?\"\n- \"Can this decision be made by a rule or does it need human judgment?\"\n\n**Testing criteria:**\n- \"How do you decide [yes/no, A/B, how much]?\"\n- \"Are the criteria clear and objective?\"\n- \"Could two people make different decisions with the same inputs?\"\n- \"What if the decision criteria aren't met?\"\n\n**Testing decision-makers:**\n- \"Who makes this decision?\"\n- \"How long does it take them to decide?\"\n- \"What if they're unavailable?\"\n- \"Do they have all the information they need to decide?\"\n\n**Exposing bottlenecks:**\n- \"How many decisions does [one person] need to make per day?\"\n- \"Can they keep up when volume increases?\"\n- \"What happens if they're slow to decide?\"\n\n---\n\n### 7. Dane / Informacje\n\n**Finding data needs:**\n- \"What data is critical for this process?\"\n- \"Where is that data stored today?\"\n- \"How do you access it? API? Database query? Asking someone?\"\n- \"How current is the data?\"\n\n**Testing data quality:**\n- \"How do you know the data is accurate?\"\n- \"What if it's out of date?\"\n- \"What happens if data is wrong?\"\n- \"Who's responsible for keeping data accurate?\"\n\n**Identifying data gaps:**\n- \"What data do you need that you don't have?\"\n- \"What data exists in multiple places?\"\n- \"How do you keep data in sync across systems?\"\n\n**Testing access:**\n- \"Who can access this data?\"\n- \"What if the person who knows where data is leaves?\"\n- \"Is critical data only in someone's head?\"\n\n---\n\n### 8. Handoffy\n\n**Identifying handoffs:**\n- \"Where does work pass from one person to another?\"\n- \"How does the receiving person know they have work to do?\"\n- \"What information gets passed along?\"\n\n**Testing handoff mechanism:**\n- \"How does the handoff happen? Email? Ticket? Verbal?\"\n- \"What if the email gets lost or ignored?\"\n- \"Is there a record of the handoff?\"\n- \"How do you track if the handoff was successful?\"\n\n**Exposing risks:**\n- \"What happens if Person B is on vacation when A hands off?\"\n- \"What if they misunderstand what needs to be done?\"\n- \"How long does it typically take between handoff and next action?\"\n- \"What's the longest a handoff has taken?\"\n\n**Testing at scale:**\n- \"When you have 10x more handoffs per day, how does this work?\"\n- \"Do handoffs require manual coordination?\"\n\n---\n\n## PROBLEMS & EDGE CASES - Problemy\n\n### 9. Pain points / Bottlenecki\n\n**Finding pain:**\n- \"What's the most frustrating part of this process?\"\n- \"Where does it typically get stuck?\"\n- \"What do people complain about most?\"\n- \"If you could fix one thing, what would it be?\"\n\n**Identifying bottlenecks:**\n- \"What's the slowest step?\"\n- \"Where is capacity limited?\"\n- \"What would break first if volume doubled?\"\n- \"Who's constantly overwhelmed?\"\n\n**Testing current state:**\n- \"How often does this process fail or need to be redone?\"\n- \"What's the error rate?\"\n- \"How much manual intervention is needed?\"\n- \"What workarounds have you built?\"\n\n**Exposing hidden costs:**\n- \"How much time is wasted on [pain point]?\"\n- \"How much does it cost when this fails?\"\n- \"What's the opportunity cost of bottlenecks?\"\n\n---\n\n### 10. Edge cases / WyjƒÖtki\n\n**Probing exceptions:**\n- \"What's the weirdest thing that's happened?\"\n- \"What happens when [specific unusual situation]?\"\n- \"What if the customer provides invalid data?\"\n- \"What if your system is down during a critical moment?\"\n\n**Testing error handling:**\n- \"What happens if [Step 5] fails? Can you retry? Roll back?\"\n- \"What if an external API doesn't respond?\"\n- \"What if payment fails?\"\n- \"How do you handle duplicate submissions?\"\n\n**Finding brittle points:**\n- \"What scenarios have you NOT thought about?\"\n- \"What would completely break your process?\"\n- \"Do you have a manual fallback?\"\n- \"What happens at 3am on Sunday when something breaks?\"\n\n**Volume and timing:**\n- \"What if you get 100 requests at once instead of 10 per day?\"\n- \"What if something takes 10x longer than expected?\"\n- \"What if two processes try to update the same data simultaneously?\"\n\n---\n\n### 11. Ryzyka operacyjne\n\n**Identifying single points of failure:**\n- \"If [person/system/supplier] disappeared tomorrow, what would break?\"\n- \"What's your single point of failure?\"\n- \"What happens if [critical dependency] fails?\"\n\n**Testing redundancy:**\n- \"Do you have a backup for [critical component]?\"\n- \"What if your main supplier can't deliver?\"\n- \"What if your database corrupts?\"\n\n**Exposing dependencies:**\n- \"What are you completely dependent on that you don't control?\"\n- \"What if [partner] changes their terms or pricing?\"\n- \"What if [vendor] goes out of business?\"\n\n**Compliance and legal:**\n- \"What could get you shut down?\"\n- \"What could you get sued for?\"\n- \"Are you compliant with [relevant regulations]?\"\n- \"What happens in an audit?\"\n\n**Security and fraud:**\n- \"How do you prevent fraud?\"\n- \"What if there's a data breach?\"\n- \"What if someone abuses your system?\"\n\n---\n\n## REQUIREMENTS - Wymagania\n\n### 12. Czas trwania / SLA\n\n**Getting numbers:**\n- \"How long does this process take end-to-end?\"\n- \"What's the fastest it's ever completed? Slowest?\"\n- \"What's the average time for each step?\"\n\n**Testing commitments:**\n- \"Have you promised customers a specific timeframe?\"\n- \"Can you consistently meet that commitment?\"\n- \"What percentage of the time do you miss SLA?\"\n- \"What happens when you miss it?\"\n\n**Finding delays:**\n- \"What causes delays?\"\n- \"Where does work sit waiting?\"\n- \"What's the longest someone has waited?\"\n\n**Testing at scale:**\n- \"When volume doubles, how does this affect speed?\"\n- \"Can you maintain SLA at 10x volume?\"\n\n---\n\n### 13. Compliance / Regulacje\n\n**Identifying requirements:**\n- \"What regulations apply to your business?\"\n- \"Do you know all compliance requirements?\"\n- \"Have you talked to a lawyer about this?\"\n\n**Testing understanding:**\n- \"What specifically do you need to do to comply with [regulation]?\"\n- \"How do you prove compliance?\"\n- \"What documentation is required?\"\n- \"Who's responsible for compliance?\"\n\n**Exposing gaps:**\n- \"Are you collecting data that requires compliance?\"\n- \"Do you have proper consents and disclosures?\"\n- \"Are you handling payments? (PCI DSS)\"\n- \"Are you processing EU data? (GDPR)\"\n\n**Testing consequences:**\n- \"What's the penalty for non-compliance?\"\n- \"Have you been audited?\"\n- \"What would an auditor find?\"\n\n---\n\n### 14. Wymagania jako≈õciowe\n\n**Setting standards:**\n- \"What quality standards apply?\"\n- \"What's acceptable error rate?\"\n- \"How do you define 'good quality' for this process?\"\n\n**Testing measurement:**\n- \"How do you measure quality?\"\n- \"Who checks quality and when?\"\n- \"What happens when quality fails?\"\n\n**Finding quality gaps:**\n- \"What's your current error rate?\"\n- \"How often do you need to redo work?\"\n- \"What quality issues do customers complain about?\"\n\n**Testing scale:**\n- \"Can you maintain quality at 10x volume?\"\n- \"Does quality degrade when you're busy?\"\n\n---\n\n## TECH & TOOLS - Technologia\n\n### 15. Narzƒôdzia / Systemy\n\n**Identifying tools:**\n- \"What tools do you use for each step?\"\n- \"Why those specific tools?\"\n- \"Do they do what you need or are you working around limitations?\"\n\n**Testing integration:**\n- \"Do your tools talk to each other?\"\n- \"How much manual work happens between tools?\"\n- \"Are you copying data between systems?\"\n\n**Exposing limitations:**\n- \"What can't your tools do that you need?\"\n- \"What happens when a tool goes down?\"\n- \"Can your tools handle 10x growth?\"\n\n**Testing cost:**\n- \"How much do all these tools cost?\"\n- \"Does cost scale with usage?\"\n- \"Are you paying for features you don't use?\"\n\n---\n\n### 16. Integracje\n\n**Mapping integrations:**\n- \"What systems need to connect?\"\n- \"How are they integrated today?\"\n- \"Is it real-time or batch?\"\n\n**Testing reliability:**\n- \"How often do integrations break?\"\n- \"What happens when an integration fails?\"\n- \"Do you have retry logic?\"\n- \"How long before you notice an integration is down?\"\n\n**Exposing gaps:**\n- \"What integrations are missing?\"\n- \"Where do you manually transfer data?\"\n- \"What's the impact of integration lag?\"\n\n**Testing maintainability:**\n- \"Who built the integrations?\"\n- \"If they leave, can someone else maintain them?\"\n- \"How much work is it to add a new integration?\"\n\n---\n\n### 17. Automatyzacja\n\n**Finding manual work:**\n- \"What's still done manually?\"\n- \"Why haven't you automated it?\"\n- \"How much time is spent on manual work?\"\n\n**Testing automation:**\n- \"What have you automated?\"\n- \"Does the automation work reliably?\"\n- \"What happens when automation fails?\"\n- \"Is there a manual fallback?\"\n\n**Prioritizing automation:**\n- \"What should you automate next?\"\n- \"What's the ROI of automating [specific thing]?\"\n- \"What's too complex or low-volume to automate?\"\n\n**Exposing premature automation:**\n- \"Why automate before you've proven the process works?\"\n- \"Is the manual process understood well enough to automate?\"\n\n---\n\n## ECONOMICS & SCALE - Ekonomia\n\n### 18. Koszty operacyjne\n\n**Getting numbers:**\n- \"How much does this process cost to run?\"\n- \"What's the cost per [customer/order/transaction]?\"\n- \"What's the biggest cost component?\"\n\n**Breaking down costs:**\n- \"How much is labor? Tools? Infrastructure?\"\n- \"What costs are fixed vs. variable?\"\n- \"What would happen to costs if volume doubled?\"\n\n**Testing viability:**\n- \"Is cost per unit higher than revenue per unit?\"\n- \"At what volume do you break even?\"\n- \"Can you afford these costs long-term?\"\n\n**Finding savings:**\n- \"Where could you reduce costs?\"\n- \"What's worth investing in to lower costs?\"\n- \"What expensive thing could be automated?\"\n\n---\n\n### 19. Skalowanie\n\n**Testing current limits:**\n- \"What's your current capacity?\"\n- \"How many [customers/orders/transactions] can you handle?\"\n- \"What breaks first when volume increases?\"\n\n**Probing 2x growth:**\n- \"What happens when volume doubles?\"\n- \"What would you need to change?\"\n- \"Do costs double or less?\"\n\n**Probing 10x growth:**\n- \"What about 10x volume?\"\n- \"Would your process completely break?\"\n- \"What would need to be completely rebuilt?\"\n\n**Finding bottlenecks:**\n- \"What's your constraint on growth?\"\n- \"What can't scale?\"\n- \"Where would you need to hire?\"\n\n**Testing assumptions:**\n- \"You said you'd 'just hire more people' - how many?\"\n- \"Can you really find and train that many people?\"\n- \"Do your tools scale or do you need new ones?\"\n\n---\n\n### 20. Metryki procesu\n\n**Identifying metrics:**\n- \"How do you measure if this process is working?\"\n- \"What metrics do you track?\"\n- \"How often do you review metrics?\"\n\n**Testing measurement:**\n- \"How do you actually measure [metric]?\"\n- \"Is it manual or automated?\"\n- \"How current is the data?\"\n\n**Finding blind spots:**\n- \"What important things are you NOT measuring?\"\n- \"Do you know your error rate? Cycle time? Cost per unit?\"\n- \"What metrics would tell you the process is degrading?\"\n\n**Testing action:**\n- \"When metrics show a problem, what do you do?\"\n- \"Do you have alerts when metrics cross thresholds?\"\n- \"What's an example of using metrics to improve?\"\n\n**Exposing vanity:**\n- \"Are you measuring things that don't actually matter?\"\n- \"Do those metrics tie to business outcomes?\"\n\n---\n\n## Cross-Cutting Critical Questions\n\n### \"How do you know?\"\nUse this constantly to push for evidence over assumptions.\n\n**Examples:**\n- \"How do you know this step takes 2 hours?\"\n- \"How do you know customers are satisfied?\"\n- \"How do you know your error rate is low?\"\n\n### \"What if?\"\nUse this to explore edge cases and risks.\n\n**Examples:**\n- \"What if volume is 10x higher?\"\n- \"What if [key person] quits?\"\n- \"What if [critical system] is down for a day?\"\n- \"What if [assumption] is wrong?\"\n\n### \"Walk me through...\"\nUse this to force detailed explanation and expose gaps.\n\n**Examples:**\n- \"Walk me through exactly what happens when [specific scenario]\"\n- \"Walk me through the last time this failed\"\n- \"Walk me through a specific example end-to-end\"\n\n### \"Who specifically?\"\nUse this to avoid vague roles and identify gaps.\n\n**Examples:**\n- \"Who specifically does this step?\"\n- \"Who specifically decides this?\"\n- \"Who specifically is accountable when it fails?\"\n\n### \"That seems straightforward - what am I missing?\"\nUse this when user glosses over complexity.\n\n**Examples:**\n- User: \"Then we just deliver it\"\n- You: \"That seems straightforward - what am I missing?\"\n\n### \"Have you actually done this?\"\nUse this to distinguish between theoretical and proven.\n\n**Examples:**\n- \"Have you actually run this process?\"\n- \"How many times have you done this?\"\n- \"What went wrong the last time?\"\n\n---\n\n## Conversation Patterns\n\n### Pattern 1: The Dig\nWhen user gives surface answer, dig deeper.\n\n**Example:**\n- User: \"We handle customer support\"\n- You: \"What does 'handle' mean specifically?\"\n- User: \"We answer questions\"\n- You: \"How? Email? Phone? Chat?\"\n- User: \"Email\"\n- You: \"How fast? Who answers? What if volume is high?\"\n\n### Pattern 2: The Specific Scenario\nForce user to think through concrete example.\n\n**Example:**\n- You: \"Let's say I'm a customer who just signed up. Walk me through exactly what happens next.\"\n- [User describes]\n- You: \"You said 'we set up your account' - what are the actual steps in setting up?\"\n\n### Pattern 3: The Edge Case\nOnce you understand happy path, probe exceptions.\n\n**Example:**\n- You: \"OK, that's the normal flow. What if [system is down / data is wrong / person is unavailable]?\"\n\n### Pattern 4: The Math\nUse numbers to expose problems.\n\n**Example:**\n- User: \"We manually review each order\"\n- You: \"How long does one review take?\"\n- User: \"About 10 minutes\"\n- You: \"So at 100 orders per day, that's 1000 minutes = 16 hours. Who does that?\"\n\n### Pattern 5: The Contradiction\nPoint out when things don't add up.\n\n**Example:**\n- User: \"We need to be very fast\" ... \"and each order is manually reviewed by 3 people\"\n- You: \"Those seem contradictory. How do you maintain speed with 3 manual reviews?\"\n\n---\n\n## Summary: Most Powerful Questions\n\n1. **\"Walk me through exactly what happens when [specific scenario]\"** - Forces detail\n2. **\"What am I missing?\"** - Finds gaps in your understanding and their thinking\n3. **\"What if [specific failure]?\"** - Tests resilience\n4. **\"Who specifically?\"** - Avoids vague answers\n5. **\"How do you know?\"** - Demands evidence\n6. **\"What happens at 10x volume?\"** - Tests scalability\n7. **\"Where does this break?\"** - Finds weaknesses\n8. **\"How long does this take?\"** - Gets concrete numbers\n9. **\"What's the worst case?\"** - Explores risks\n10. **\"Have you actually done this?\"** - Distinguishes theory from practice\n\nUse these relentlessly to find blind spots and expose weak thinking.\n",
        "skills/critical-process-brief/references/red-flags.md": "# Red Flags in Process Design\n\nThis guide catalogs common warning signs in operational processes that indicate problems, fragility, or inability to scale.\n\n---\n\n## Critical Red Flags (High Risk)\n\n### \"It's straightforward\" / \"It's simple\"\n\n**Why it's a red flag:** Nothing is straightforward. This usually means user hasn't thought through details or edge cases.\n\n**What to probe:**\n- \"Walk me through every step\"\n- \"What happens when [edge case]?\"\n- \"What am I missing?\"\n\n**Example:**\n- User: \"We just fulfill the order, it's straightforward\"\n- Reality: Pick item, check inventory, pack, print label, schedule pickup, track, handle exceptions, process returns...\n\n---\n\n### Single point of failure - One person\n\n**Symptoms:**\n- \"John handles all the orders\"\n- \"Only Sarah knows how to do this\"\n- \"The founder approves everything\"\n\n**Why it's critical:** Business stops when that person is unavailable. Creates bottleneck and key-person risk.\n\n**What to probe:**\n- \"What happens if they're sick/on vacation/quit?\"\n- \"How many decisions/actions does this person make per day?\"\n- \"Can they keep up when volume increases?\"\n\n---\n\n### Single point of failure - One system\n\n**Symptoms:**\n- \"Everything goes through [one system]\"\n- \"If [vendor] is down, we can't operate\"\n- \"We built our own custom system\"\n\n**Why it's critical:** No redundancy = complete failure when system goes down.\n\n**What to probe:**\n- \"What happens when this system is down?\"\n- \"Do you have a backup or manual fallback?\"\n- \"What's the longest outage you've had?\"\n\n---\n\n### Single point of failure - One supplier/partner\n\n**Symptoms:**\n- \"We only work with [one supplier]\"\n- \"This only works if [big company] gives us access\"\n- \"We're dependent on [partner] for all distribution\"\n\n**Why it's critical:** Partner has leverage. No alternative if relationship fails.\n\n**What to probe:**\n- \"What if they change pricing? Terms? Stop working with you?\"\n- \"Do you have alternative partners?\"\n- \"How long to switch to backup supplier?\"\n\n---\n\n### No idea of operational costs\n\n**Symptoms:**\n- \"We haven't calculated it\"\n- \"It won't cost much\"\n- \"We'll figure that out later\"\n\n**Why it's critical:** Can't manage what you don't measure. Might lose money on every transaction.\n\n**What to probe:**\n- \"What's your cost per [unit/order/customer]?\"\n- \"Is that higher or lower than your revenue per unit?\"\n- \"What's the biggest cost component?\"\n\n---\n\n### Process only works at current tiny scale\n\n**Symptoms:**\n- \"We do everything manually\"\n- \"The founder is involved in every decision\"\n- \"We handle each one custom\"\n\n**Why it's critical:** Won't scale. Need complete rebuild for growth.\n\n**What to probe:**\n- \"What happens when volume doubles? 10x?\"\n- \"Where does this break first?\"\n- \"What needs to change to scale?\"\n\n---\n\n### No error handling or edge case planning\n\n**Symptoms:**\n- \"That won't happen\"\n- \"We'll deal with exceptions manually\"\n- \"We haven't thought about that\"\n\n**Why it's critical:** Edge cases WILL happen. Process breaks on exceptions.\n\n**What to probe:**\n- \"What's the weirdest thing that's happened?\"\n- \"What happens if [specific failure]?\"\n- \"Do you have a fallback?\"\n\n---\n\n### Long chains of dependencies\n\n**Symptoms:**\n- \"A must complete before B before C before D...\"\n- Many sequential steps\n- Everything tightly coupled\n\n**Why it's critical:** Slow, fragile, any delay compounds through the chain.\n\n**What to probe:**\n- \"What's the critical path?\"\n- \"What if Step 3 takes 2x longer?\"\n- \"Can any steps run in parallel?\"\n\n---\n\n## Serious Red Flags (Difficult Problems)\n\n### Too many manual handoffs\n\n**Symptoms:**\n- \"Then Person A emails Person B who tells Person C...\"\n- Work passes through many people\n- Coordination needed for each handoff\n\n**Why it's risky:** Each handoff = delay, potential drop, communication error.\n\n**What to probe:**\n- \"How many people touch this before it's complete?\"\n- \"What happens if a handoff is missed?\"\n- \"How long do handoffs take?\"\n\n---\n\n### Critical process only exists in someone's head\n\n**Symptoms:**\n- \"Only [person] knows how to do this\"\n- No documentation\n- Tribal knowledge\n\n**Why it's risky:** Can't train others, can't automate, at risk if person leaves.\n\n**What to probe:**\n- \"Is this documented anywhere?\"\n- \"Could someone else do this if needed?\"\n- \"What happens if this person quits?\"\n\n---\n\n### Many tools that don't integrate\n\n**Symptoms:**\n- Using 5+ separate tools\n- Manual data entry between tools\n- Copy-pasting between systems\n\n**Why it's risky:** Slow, error-prone, doesn't scale, data inconsistencies.\n\n**What to probe:**\n- \"Do these tools talk to each other?\"\n- \"How much time copying data between tools?\"\n- \"Where do errors happen?\"\n\n---\n\n### Unclear responsibilities / Overlapping ownership\n\n**Symptoms:**\n- \"The team handles it\"\n- \"Someone will take care of it\"\n- \"We all chip in\"\n\n**Why it's risky:** Things fall through cracks. No accountability.\n\n**What to probe:**\n- \"Who specifically is responsible?\"\n- \"Who's accountable if it fails?\"\n- \"What if two people think it's the other's job?\"\n\n---\n\n### No quality checks until customer complains\n\n**Symptoms:**\n- \"Customers will let us know if there's a problem\"\n- No quality checkpoints in process\n- Quality measured by complaints\n\n**Why it's risky:** Bad quality reaches customers. Expensive to fix after delivery.\n\n**What to probe:**\n- \"When do you check quality?\"\n- \"Who checks it?\"\n- \"What's your error rate?\"\n\n---\n\n### Promising SLAs you can't consistently meet\n\n**Symptoms:**\n- \"We promise 24-hour turnaround\"\n- \"But sometimes it takes 3 days\"\n- Often missing commitments\n\n**Why it's risky:** Erodes trust, customer churn, potential legal issues.\n\n**What to probe:**\n- \"What percentage of time do you meet SLA?\"\n- \"What causes you to miss it?\"\n- \"What happens when you miss?\"\n\n---\n\n### High error rates considered normal\n\n**Symptoms:**\n- \"We usually need to redo about 20%\"\n- \"Errors happen, no big deal\"\n- \"We have a lot of rework\"\n\n**Why it's risky:** Waste, cost, slow, frustrating for customers and team.\n\n**What to probe:**\n- \"What's your error rate?\"\n- \"How much time spent fixing errors?\"\n- \"Why are errors happening?\"\n\n---\n\n### Process heavily dependent on email for coordination\n\n**Symptoms:**\n- \"We email to coordinate\"\n- \"We forward emails around\"\n- Critical information in email threads\n\n**Why it's risky:** Things get missed, no visibility, hard to track, doesn't scale.\n\n**What to probe:**\n- \"What happens if email gets missed?\"\n- \"How do you track status?\"\n- \"Can you see what's pending?\"\n\n---\n\n### \"We'll just hire more people\" as only scale strategy\n\n**Symptoms:**\n- Linear relationship between volume and headcount\n- No plan to automate\n- Assuming people solve all problems\n\n**Why it's risky:** Expensive, slow to hire/train, quality inconsistent, management overhead.\n\n**What to probe:**\n- \"How many people needed at 10x volume?\"\n- \"Can you hire and train that many?\"\n- \"What's the cost of all those people?\"\n\n---\n\n## Data & Information Red Flags\n\n### Critical data only in spreadsheets\n\n**Symptoms:**\n- \"We track everything in Excel/Sheets\"\n- Shared spreadsheets as database\n- Manual updates to spreadsheet\n\n**Why it's risky:** No data integrity, version conflicts, doesn't scale, no audit trail.\n\n**What to probe:**\n- \"What happens when two people edit at once?\"\n- \"How do you prevent errors?\"\n- \"Can this handle 100x more rows?\"\n\n---\n\n### Data in multiple places that can get out of sync\n\n**Symptoms:**\n- \"We update it in System A and System B\"\n- No single source of truth\n- Frequent sync issues\n\n**Why it's risky:** Inconsistent data, errors, confusion about which is correct.\n\n**What to probe:**\n- \"How do you keep them in sync?\"\n- \"What happens when they differ?\"\n- \"Which system is the source of truth?\"\n\n---\n\n### No audit trail / No way to see what happened\n\n**Symptoms:**\n- \"We just overwrite the data\"\n- Can't see history\n- No record of changes\n\n**Why it's risky:** Can't debug, can't meet compliance, can't understand problems.\n\n**What to probe:**\n- \"Can you see what changed and when?\"\n- \"Who made this change?\"\n- \"Do you need audit trail for compliance?\"\n\n---\n\n### Manual data entry in multiple systems\n\n**Symptoms:**\n- \"We enter it in System A, then re-enter in System B\"\n- Typing the same data multiple times\n- High error rate from typos\n\n**Why it's risky:** Slow, error-prone, frustrating, doesn't scale.\n\n**What to probe:**\n- \"How much time spent on data entry?\"\n- \"What's the error rate?\"\n- \"Why can't systems integrate?\"\n\n---\n\n## Decision & Approval Red Flags\n\n### Too many approval steps\n\n**Symptoms:**\n- \"Needs approval from A, B, C, and D\"\n- Four+ approval layers\n- Everything needs executive approval\n\n**Why it's risky:** Extremely slow, bottlenecks, delays compound.\n\n**What to probe:**\n- \"How long for all approvals?\"\n- \"What if one approver is unavailable?\"\n- \"Why so many approvals?\"\n\n---\n\n### Subjective decision criteria\n\n**Symptoms:**\n- \"We'll know it when we see it\"\n- \"Depends on the situation\"\n- No clear rules\n\n**Why it's risky:** Inconsistent decisions, can't automate, quality varies by who decides.\n\n**What to probe:**\n- \"What exactly are you deciding based on?\"\n- \"Would two people make the same decision?\"\n- \"Can you write down the criteria?\"\n\n---\n\n### No escalation path for exceptions\n\n**Symptoms:**\n- \"We don't know what to do in that case\"\n- Process stops when exception occurs\n- No way to handle edge cases\n\n**Why it's risky:** Process breaks on exceptions, requires manual intervention each time.\n\n**What to probe:**\n- \"What do you do when [edge case]?\"\n- \"Who handles exceptions?\"\n- \"How often do exceptions happen?\"\n\n---\n\n## Technical & Integration Red Flags\n\n### Building all integrations yourself\n\n**Symptoms:**\n- \"We're building custom connectors for everything\"\n- Reinventing integration infrastructure\n- Each integration is a project\n\n**Why it's risky:** Time-consuming, maintenance burden, fragile, diverts from core product.\n\n**What to probe:**\n- \"Can you use existing integration platforms?\"\n- \"Who maintains these integrations?\"\n- \"How long to add a new integration?\"\n\n---\n\n### Fragile integrations that break often\n\n**Symptoms:**\n- \"The integration goes down a lot\"\n- \"We have to restart it manually\"\n- \"Sometimes data doesn't sync\"\n\n**Why it's risky:** Unreliable, requires constant attention, data loss risk.\n\n**What to probe:**\n- \"How often does it break?\"\n- \"What breaks it?\"\n- \"Do you have error handling and retries?\"\n\n---\n\n### No automated testing of process\n\n**Symptoms:**\n- \"We manually test everything\"\n- \"We test in production\"\n- \"We find bugs when customers report them\"\n\n**Why it's risky:** Changes break things, slow to release, quality issues reach customers.\n\n**What to probe:**\n- \"How do you test changes?\"\n- \"How do you know you didn't break something?\"\n- \"Can you test automatically?\"\n\n---\n\n### Custom-built system that only one person understands\n\n**Symptoms:**\n- \"John built our custom system\"\n- No documentation\n- Hard to modify\n\n**Why it's risky:** Key-person dependency, hard to maintain, technical debt.\n\n**What to probe:**\n- \"Is it documented?\"\n- \"Can others modify it?\"\n- \"What happens if John leaves?\"\n\n---\n\n## Compliance & Risk Red Flags\n\n### \"We'll worry about compliance later\"\n\n**Symptoms:**\n- Not thinking about regulations\n- Assuming too small to matter\n- No legal review\n\n**Why it's critical:** Can get shut down, fined, sued. Expensive to retrofit compliance.\n\n**What to probe:**\n- \"What regulations apply?\"\n- \"Have you talked to a lawyer?\"\n- \"What happens if you're audited?\"\n\n---\n\n### Handling sensitive data without proper controls\n\n**Symptoms:**\n- \"We store credit cards in our database\"\n- \"Everyone has access to customer data\"\n- \"We haven't thought about security\"\n\n**Why it's critical:** Data breach = lawsuit, fines, reputation damage, potential shutdown.\n\n**What to probe:**\n- \"How do you protect sensitive data?\"\n- \"Who has access?\"\n- \"Are you PCI/GDPR/HIPAA compliant?\"\n\n---\n\n### No disaster recovery plan\n\n**Symptoms:**\n- \"We haven't thought about that\"\n- No backups or untested backups\n- \"That won't happen\"\n\n**Why it's risky:** When (not if) disaster strikes, business stops.\n\n**What to probe:**\n- \"What if your database corrupts?\"\n- \"What if your office burns down?\"\n- \"When did you last test backup recovery?\"\n\n---\n\n## Scaling Red Flags\n\n### Everything breaks at 2x current volume\n\n**Symptoms:**\n- \"We're at capacity now\"\n- \"Can't handle much more\"\n- Current process already stressed\n\n**Why it's critical:** Can't grow. Need to rebuild process before scaling.\n\n**What to probe:**\n- \"What's your current capacity?\"\n- \"What breaks first when volume increases?\"\n- \"What needs to change to handle 2x?\"\n\n---\n\n### Costs scale faster than revenue\n\n**Symptoms:**\n- \"We need to double headcount to double revenue\"\n- \"Each customer costs more as we grow\"\n- Negative economies of scale\n\n**Why it's critical:** Unit economics get worse with growth. Can't be profitable at scale.\n\n**What to probe:**\n- \"What's cost per unit at current scale vs. 10x scale?\"\n- \"Why do costs scale faster?\"\n- \"Can you get economies of scale?\"\n\n---\n\n### Process requires geographic proximity\n\n**Symptoms:**\n- \"Everyone needs to be in the office\"\n- \"We need face-to-face coordination\"\n- Can't work remotely or in multiple locations\n\n**Why it's risky:** Limits hiring, limits scale, limits geographic expansion.\n\n**What to probe:**\n- \"Why does it need to be in-person?\"\n- \"Can you redesign for remote work?\"\n- \"What if you want to expand to other cities?\"\n\n---\n\n## Measurement & Visibility Red Flags\n\n### No metrics / No visibility\n\n**Symptoms:**\n- \"We don't track that\"\n- \"Not sure, let me check\"\n- Flying blind\n\n**Why it's risky:** Can't identify problems, can't improve, don't know when things break.\n\n**What to probe:**\n- \"How do you know if the process is working well?\"\n- \"What metrics do you track?\"\n- \"How do you know when something's wrong?\"\n\n---\n\n### Metrics exist but no one acts on them\n\n**Symptoms:**\n- \"We have dashboards but rarely look\"\n- \"Metrics show problems but we haven't fixed them\"\n- Measurement theater\n\n**Why it's risky:** Waste of effort measuring. Problems persist.\n\n**What to probe:**\n- \"When's the last time you reviewed metrics?\"\n- \"What did you change based on metrics?\"\n- \"Why measure if you don't act?\"\n\n---\n\n### Only measuring outputs, not outcomes\n\n**Symptoms:**\n- \"We processed 100 orders\" (but how many had errors?)\n- \"We sent 1000 emails\" (but how many responded?)\n- Activity metrics, not result metrics\n\n**Why it's risky:** Can look busy while failing. Don't measure what matters.\n\n**What to probe:**\n- \"What's the outcome you're trying to achieve?\"\n- \"How do you measure success, not just activity?\"\n\n---\n\n## How to Use These Red Flags\n\n### Pattern recognition\nListen for symptoms that indicate red flags. User might not explicitly say \"single point of failure\" but will describe it.\n\n### Severity assessment\n- **üî¥ Critical:** Business likely fails or can't scale (single points of failure, broken unit economics)\n- **üü° Serious:** Major problems that need addressing (many handoffs, no error handling)\n- **üü¢ Caution:** Worth discussing but may be acceptable early on (manual processes, minimal documentation)\n\n### Combinations amplify risk\nMultiple red flags together = very high risk.\n\n**Example:** \"Only John knows how to do it\" + \"No documentation\" + \"If system is down, process stops\" = disaster waiting to happen\n\n### Context matters\nSome red flags acceptable in early stages but must be addressed for scale.\n\n**Early stage OK:**\n- Manual processes (when volume is low)\n- Founder does everything (when there's no team)\n- Minimal documentation (when testing product-market fit)\n\n**Not OK at any stage:**\n- Broken unit economics\n- Non-compliance with regulations\n- No single point of failure plan\n\n### Use red flags to prioritize\nWhen multiple red flags exist, help user prioritize which to address first:\n1. Critical risks (compliance, single points of failure)\n2. Scale blockers (what prevents growth)\n3. Operational pain (what's most frustrating)\n4. Future optimization (nice-to-have improvements)\n\n---\n\n## Example Red Flag Conversations\n\n### Example 1: Single Point of Failure\n\n**User:** \"John handles all our order fulfillment.\"\n\n**You:** \"What happens when John is sick or on vacation?\"\n\n**User:** \"Um, orders pile up until he gets back.\"\n\n**You:** \"That's a single point of failure. How many orders per day?\"\n\n**User:** \"About 50.\"\n\n**You:** \"So if John is out for a week, 350 orders pile up? What's the customer experience?\"\n\n**User:** \"Not great...\"\n\n**You:** \"This will get worse as you grow. What's your plan to eliminate this dependency?\"\n\n---\n\n### Example 2: Process Only Works at Tiny Scale\n\n**User:** \"We manually review each order.\"\n\n**You:** \"How long does that take?\"\n\n**User:** \"About 15 minutes per order.\"\n\n**You:** \"And how many orders per day?\"\n\n**User:** \"Right now, 20.\"\n\n**You:** \"So that's 5 hours per day. What happens when you have 100 orders per day?\"\n\n**User:** \"Um... that would be 25 hours...\"\n\n**You:** \"Right. So this process breaks at 5x growth. You're hiring 3 more reviewers? Or automating? What's the plan?\"\n\n---\n\n### Example 3: No Error Handling\n\n**User:** \"The process is pretty straightforward - we import the data, process it, and export.\"\n\n**You:** \"What happens if the import file is malformed?\"\n\n**User:** \"Uh... I guess it would fail?\"\n\n**You:** \"Then what? Does someone get notified? Can you retry? Does it leave partial data?\"\n\n**User:** \"We haven't really thought about that...\"\n\n**You:** \"What about if the external API you export to is down?\"\n\n**User:** \"I guess we'd need to try again manually...\"\n\n**You:** \"So every exception requires manual intervention? That's going to be a lot of your time. What's your error rate?\"\n\n---\n\n## Summary: Top 15 Process Red Flags\n\n1. **\"It's straightforward\"** - Never is, probe deeper\n2. **Single point of failure (person)** - Key-person risk\n3. **Single point of failure (system)** - No redundancy\n4. **Single point of failure (partner)** - No control\n5. **No idea of costs** - Can't manage finances\n6. **Only works at tiny scale** - Can't grow\n7. **No error handling** - Breaks on exceptions\n8. **Long dependency chains** - Slow and fragile\n9. **Many manual handoffs** - Delays and drops\n10. **Knowledge only in someone's head** - Can't scale or train\n11. **Too many approvals** - Bottleneck\n12. **No compliance thinking** - Legal risk\n13. **Everything breaks at 2x volume** - Can't grow\n14. **No metrics** - Flying blind\n15. **Data in multiple places** - Inconsistency and errors\n\nWhen you see these, probe deeply and help user understand the risk and cost of not addressing them.\n"
      },
      "plugins": [
        {
          "name": "critical-briefs",
          "description": "Create critical briefs through challenging dialogue: business validation (critical-business-brief), operational process analysis (critical-process-brief), and MVP application design (critical-app-brief). Each skill creates structured briefs that expose weaknesses, test assumptions, and cut scope ruthlessly.",
          "version": "1.0.0",
          "author": {
            "name": "CampusAI",
            "email": "info@campus.ai"
          },
          "homepage": "https://github.com/Przemocny/critical-briefs",
          "repository": "https://github.com/Przemocny/critical-briefs",
          "license": "Apache-2.0",
          "keywords": [
            "business-validation",
            "process-analysis",
            "mvp-design",
            "critical-thinking",
            "skeptical-dialogue",
            "startup",
            "entrepreneurship"
          ],
          "category": "productivity",
          "source": "./",
          "strict": false,
          "skills": [
            "./skills/critical-business-brief",
            "./skills/critical-process-brief",
            "./skills/critical-app-brief"
          ],
          "categories": [
            "business-validation",
            "critical-thinking",
            "entrepreneurship",
            "mvp-design",
            "process-analysis",
            "productivity",
            "skeptical-dialogue",
            "startup"
          ],
          "install_commands": [
            "/plugin marketplace add Przemocny/critical-briefs",
            "/plugin install critical-briefs@critical-briefs"
          ]
        }
      ]
    }
  ]
}