{
  "author": {
    "id": "gaurangrshah",
    "display_name": "gshah2020",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/1086269?u=ad12da0c6cc72b90196e8416f08eb0bd23fea769&v=4",
    "url": "https://github.com/gaurangrshah",
    "bio": "/* ... */",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 5,
      "total_commands": 21,
      "total_skills": 0,
      "total_stars": 0,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "gsc-plugins",
      "version": null,
      "description": "Claude Code plugins for web/app generation, knowledge persistence, task management, and documentation",
      "owner_info": {
        "name": "gs",
        "email": "gaurang.r.shah@gmail.com"
      },
      "keywords": [],
      "repo_full_name": "gaurangrshah/gsc-plugins",
      "repo_url": "https://github.com/gaurangrshah/gsc-plugins",
      "repo_description": "Claude Code plugins: webgen, worklog, taskflow",
      "homepage": null,
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-01-18T02:43:01Z",
        "created_at": "2025-12-13T22:09:06Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 1858
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/appgen",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/appgen/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/appgen/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 667
        },
        {
          "path": "plugins/appgen/README.md",
          "type": "blob",
          "size": 17376
        },
        {
          "path": "plugins/appgen/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/appgen/agents/appgen-code-reviewer.md",
          "type": "blob",
          "size": 3996
        },
        {
          "path": "plugins/appgen/agents/appgen-orchestrator.md",
          "type": "blob",
          "size": 9684
        },
        {
          "path": "plugins/appgen/agents/appgen.md",
          "type": "blob",
          "size": 7743
        },
        {
          "path": "plugins/appgen/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/appgen/commands/appgen.md",
          "type": "blob",
          "size": 4706
        },
        {
          "path": "plugins/appgen/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/appgen/skills/api-design",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/appgen/skills/api-design/skill.md",
          "type": "blob",
          "size": 10730
        },
        {
          "path": "plugins/appgen/skills/asset-management",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/appgen/skills/asset-management/skill.md",
          "type": "blob",
          "size": 12989
        },
        {
          "path": "plugins/appgen/skills/auth-integration",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/appgen/skills/auth-integration/skill.md",
          "type": "blob",
          "size": 11478
        },
        {
          "path": "plugins/appgen/skills/database-design",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/appgen/skills/database-design/skill.md",
          "type": "blob",
          "size": 10336
        },
        {
          "path": "plugins/appgen/skills/project-scaffold",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/appgen/skills/project-scaffold/skill.md",
          "type": "blob",
          "size": 7648
        },
        {
          "path": "plugins/appgen/skills/taskflow-integration",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/appgen/skills/taskflow-integration/skill.md",
          "type": "blob",
          "size": 12622
        },
        {
          "path": "plugins/appgen/skills/worktree-workflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/appgen/skills/worktree-workflow/skill.md",
          "type": "blob",
          "size": 6875
        },
        {
          "path": "plugins/docs",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/docs/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/docs/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 649
        },
        {
          "path": "plugins/docs/README.md",
          "type": "blob",
          "size": 4916
        },
        {
          "path": "plugins/docs/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/docs/commands/docs-init.md",
          "type": "blob",
          "size": 9529
        },
        {
          "path": "plugins/docs/commands/docs-reconcile.md",
          "type": "blob",
          "size": 3290
        },
        {
          "path": "plugins/docs/commands/docs-validate.md",
          "type": "blob",
          "size": 2757
        },
        {
          "path": "plugins/docs/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/docs/skills/docs-manager",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/docs/skills/docs-manager/skill.md",
          "type": "blob",
          "size": 22434
        },
        {
          "path": "plugins/docs/skills/docs-validator",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/docs/skills/docs-validator/skill.md",
          "type": "blob",
          "size": 11646
        },
        {
          "path": "plugins/taskflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/taskflow/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/taskflow/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 694
        },
        {
          "path": "plugins/taskflow/README.md",
          "type": "blob",
          "size": 10108
        },
        {
          "path": "plugins/taskflow/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/taskflow/commands/task-add.md",
          "type": "blob",
          "size": 6465
        },
        {
          "path": "plugins/taskflow/commands/task-expand.md",
          "type": "blob",
          "size": 6983
        },
        {
          "path": "plugins/taskflow/commands/task-init.md",
          "type": "blob",
          "size": 7802
        },
        {
          "path": "plugins/taskflow/commands/task-list.md",
          "type": "blob",
          "size": 2513
        },
        {
          "path": "plugins/taskflow/commands/task-migrate-config.md",
          "type": "blob",
          "size": 11752
        },
        {
          "path": "plugins/taskflow/commands/task-next.md",
          "type": "blob",
          "size": 19274
        },
        {
          "path": "plugins/taskflow/commands/task-parse.md",
          "type": "blob",
          "size": 16707
        },
        {
          "path": "plugins/taskflow/commands/task-show.md",
          "type": "blob",
          "size": 9068
        },
        {
          "path": "plugins/taskflow/commands/task-status.md",
          "type": "blob",
          "size": 6138
        },
        {
          "path": "plugins/taskflow/commands/task-tag.md",
          "type": "blob",
          "size": 8764
        },
        {
          "path": "plugins/taskflow/commands/task.md",
          "type": "blob",
          "size": 8546
        },
        {
          "path": "plugins/taskflow/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/taskflow/skills/task-setup",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/taskflow/skills/task-setup/skill.md",
          "type": "blob",
          "size": 13769
        },
        {
          "path": "plugins/webgen",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/webgen/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/webgen/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 676
        },
        {
          "path": "plugins/webgen/README.md",
          "type": "blob",
          "size": 25874
        },
        {
          "path": "plugins/webgen/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/webgen/agents/webgen-code-reviewer.md",
          "type": "blob",
          "size": 3627
        },
        {
          "path": "plugins/webgen/agents/webgen-orchestrator.md",
          "type": "blob",
          "size": 9089
        },
        {
          "path": "plugins/webgen/agents/webgen.md",
          "type": "blob",
          "size": 6958
        },
        {
          "path": "plugins/webgen/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/webgen/commands/webgen.md",
          "type": "blob",
          "size": 4519
        },
        {
          "path": "plugins/webgen/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/webgen/skills/asset-management",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/webgen/skills/asset-management/skill.md",
          "type": "blob",
          "size": 12989
        },
        {
          "path": "plugins/webgen/skills/design-system",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/webgen/skills/design-system/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/webgen/skills/design-system/references/shadcn.md",
          "type": "blob",
          "size": 13528
        },
        {
          "path": "plugins/webgen/skills/design-system/skill.md",
          "type": "blob",
          "size": 7437
        },
        {
          "path": "plugins/webgen/skills/project-scaffold",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/webgen/skills/project-scaffold/skill.md",
          "type": "blob",
          "size": 4765
        },
        {
          "path": "plugins/webgen/skills/taskflow-integration",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/webgen/skills/taskflow-integration/skill.md",
          "type": "blob",
          "size": 12622
        },
        {
          "path": "plugins/webgen/skills/worktree-workflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/webgen/skills/worktree-workflow/skill.md",
          "type": "blob",
          "size": 6875
        },
        {
          "path": "plugins/worklog",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/worklog/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/worklog/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 793
        },
        {
          "path": "plugins/worklog/README.md",
          "type": "blob",
          "size": 30771
        },
        {
          "path": "plugins/worklog/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/worklog/agents/kb-curator.md",
          "type": "blob",
          "size": 9394
        },
        {
          "path": "plugins/worklog/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/worklog/commands/worklog-configure.md",
          "type": "blob",
          "size": 4301
        },
        {
          "path": "plugins/worklog/commands/worklog-connect.md",
          "type": "blob",
          "size": 5100
        },
        {
          "path": "plugins/worklog/commands/worklog-init.md",
          "type": "blob",
          "size": 12601
        },
        {
          "path": "plugins/worklog/commands/worklog-setup-mcp.md",
          "type": "blob",
          "size": 4829
        },
        {
          "path": "plugins/worklog/commands/worklog-status.md",
          "type": "blob",
          "size": 3912
        },
        {
          "path": "plugins/worklog/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/worklog/hooks/post-tool-use.md",
          "type": "blob",
          "size": 12651
        },
        {
          "path": "plugins/worklog/hooks/session-start.md",
          "type": "blob",
          "size": 9722
        },
        {
          "path": "plugins/worklog/hooks/session-stop.md",
          "type": "blob",
          "size": 12066
        },
        {
          "path": "plugins/worklog/mcp",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/worklog/mcp/README.md",
          "type": "blob",
          "size": 2625
        },
        {
          "path": "plugins/worklog/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/worklog/skills/curate",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/worklog/skills/curate/skill.md",
          "type": "blob",
          "size": 12573
        },
        {
          "path": "plugins/worklog/skills/memory-recall",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/worklog/skills/memory-recall/skill.md",
          "type": "blob",
          "size": 6884
        },
        {
          "path": "plugins/worklog/skills/memory-store",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/worklog/skills/memory-store/skill.md",
          "type": "blob",
          "size": 7306
        },
        {
          "path": "plugins/worklog/skills/memory-sync",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/worklog/skills/memory-sync/skill.md",
          "type": "blob",
          "size": 12301
        },
        {
          "path": "plugins/worklog/worklog-viewer",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/worklog/worklog-viewer/README.md",
          "type": "blob",
          "size": 4894
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"gsc-plugins\",\n  \"owner\": {\n    \"name\": \"gs\",\n    \"email\": \"gaurang.r.shah@gmail.com\"\n  },\n  \"metadata\": {\n    \"description\": \"Claude Code plugins for web/app generation, knowledge persistence, task management, and documentation\",\n    \"version\": \"1.2.0\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"webgen\",\n      \"source\": \"./plugins/webgen\",\n      \"version\": \"2.0.0\",\n      \"description\": \"Transform natural language descriptions into complete, production-ready web projects\",\n      \"keywords\": [\"web\", \"generator\", \"react\", \"nextjs\", \"astro\", \"frontend\", \"landing-pages\"]\n    },\n    {\n      \"name\": \"appgen\",\n      \"source\": \"./plugins/appgen\",\n      \"version\": \"2.0.0\",\n      \"description\": \"Generate full-stack applications and APIs from natural language descriptions\",\n      \"keywords\": [\"app\", \"generator\", \"fullstack\", \"api\", \"backend\", \"database\", \"auth\"]\n    },\n    {\n      \"name\": \"worklog\",\n      \"source\": \"./plugins/worklog\",\n      \"version\": \"1.7.1\",\n      \"description\": \"Cross-session knowledge persistence with SQLite/PostgreSQL for maintaining context across sessions\",\n      \"keywords\": [\"memory\", \"persistence\", \"sqlite\", \"postgresql\", \"knowledge-base\", \"cross-session\", \"hooks\", \"automation\", \"mcp\", \"seed-data\"]\n    },\n    {\n      \"name\": \"taskflow\",\n      \"source\": \"./plugins/taskflow\",\n      \"version\": \"2.0.0\",\n      \"description\": \"AI-powered task management - transform PRDs into structured, dependency-aware tasks\",\n      \"keywords\": [\"tasks\", \"project-management\", \"prd\", \"workflow\", \"productivity\"]\n    },\n    {\n      \"name\": \"docs\",\n      \"source\": \"./plugins/docs\",\n      \"version\": \"1.1.0\",\n      \"description\": \"Documentation management and validation with single source of truth philosophy\",\n      \"keywords\": [\"documentation\", \"markdown\", \"frontmatter\", \"validation\", \"quality-assurance\", \"journal\"]\n    }\n  ]\n}\n",
        "plugins/appgen/.claude-plugin/plugin.json": "{\n  \"name\": \"appgen\",\n  \"version\": \"2.0.0\",\n  \"description\": \"Generate full-stack applications and APIs from natural language. Part of the unified GSC plugins ecosystem with query-first knowledge, progressive discovery, and cross-plugin integration.\",\n  \"author\": {\n    \"name\": \"gs\"\n  },\n  \"license\": \"MIT\",\n  \"repository\": \"https://github.com/gaurangrshah/gsc-plugins\",\n  \"homepage\": \"https://github.com/gaurangrshah/gsc-plugins/tree/main/plugins/appgen\",\n  \"keywords\": [\n    \"fullstack\",\n    \"application\",\n    \"api\",\n    \"rest\",\n    \"graphql\",\n    \"database\",\n    \"auth\",\n    \"scaffold\",\n    \"orchestrated\",\n    \"code-review\",\n    \"testing\",\n    \"ecosystem\"\n  ]\n}\n",
        "plugins/appgen/README.md": "# AppGen - Claude Code Plugin\n\nGenerate full-stack applications and APIs from natural language descriptions using Claude's capabilities directly through your Max subscription.\n\n**Version:** 2.0.0\n\n## Overview\n\nAppGen is a **self-contained** Claude Code plugin that transforms natural language descriptions into complete, production-ready full-stack applications and APIs. All agents are bundledâ€”no external dependencies required. It leverages Claude's understanding and code generation capabilities without requiring API costsâ€”just your existing Max subscription.\n\n## Installation\n\n### Option 1: Marketplace (Recommended)\n\n```bash\n# Add the marketplace (if not already added)\nclaude plugin marketplace add https://github.com/gaurangrshah/gsc-plugins.git\n\n# Install the plugin\nclaude plugin install appgen@gsc-plugins\n```\n\n### Option 2: Manual Installation\n\n```bash\n# Clone the repo\ngit clone https://github.com/gaurangrshah/gsc-plugins.git\n\n# Copy to local-plugins\ncp -r gsc-plugins/plugins/appgen ~/.claude/plugins/local-plugins/\n\n# Restart Claude Code to activate\n```\n\n## Usage\n\n```bash\n# With description\n/appgen inventory management system for a warehouse\n\n# Interactive mode (asks clarifying questions)\n/appgen\n\n# Various project types\n/appgen SaaS dashboard for subscription management\n/appgen REST API for a blog with auth and comments\n/appgen task tracking app with teams and notifications\n/appgen e-commerce backend with Stripe integration\n```\n\n## Configuration\n\n### Environment Variables\n\n| Variable | Default | Description |\n|----------|---------|-------------|\n| `APPGEN_OUTPUT_DIR` | `./appgen-projects` | Base directory for generated applications |\n| `APPGEN_DB_PATH` | *(empty)* | SQLite database for cross-session learning (empty = disabled) |\n\nSet these in your environment or shell profile:\n\n```bash\nexport APPGEN_OUTPUT_DIR=\"$HOME/my-projects\"\nexport APPGEN_DB_PATH=\"\"  # Leave empty for stateless mode\n```\n\n## Standalone & Integration\n\n### Works 100% Standalone\n\nAppGen is fully self-contained. **No other plugins required.**\n\n```bash\n# This works perfectly with ONLY appgen installed:\n/appgen inventory management system\n```\n\nAll 8 phases complete. All features work. No errors or warnings about missing plugins.\n\n### Optional Integrations\n\nAppGen detects other GSC plugins and offers enhancements:\n\n#### TaskFlow Integration (Opt-in)\n\nIf [TaskFlow](../taskflow/) is installed, AppGen offers task tracking:\n\n```\nTaskFlow detected. Track this project with tasks? (y/n)\n```\n\n**What happens if you say \"yes\":**\n\n| Phase | Task Created |\n|-------|--------------|\n| Requirements | \"Define app requirements\" |\n| Research | \"Research tech stack\" |\n| Database | \"Design database schema\" |\n| API | \"Design API endpoints\" |\n| Architecture | \"Define project structure\" |\n| Implementation | \"Implement application\" |\n| Testing | \"Write and run tests\" |\n| Deployment | \"Configure deployment\" |\n\n**Benefits:**\n- Visual progress tracking through 8 phases\n- Clear dependency chains (Database â†’ API â†’ Implementation)\n- Resume capability if session interrupted\n- Task history for future reference\n\n**What happens if you say \"no\" or TaskFlow isn't installed:**\n- AppGen proceeds with standard workflow\n- No errors, no warnings, no prompts\n- Identical functionality\n\n#### Git Worktree Integration (Opt-in)\n\nIf AppGen detects you have work in progress in the output directory (uncommitted changes in a git repo), it offers isolated development via git worktrees:\n\n```\n**Git Worktree (Recommended):**\nI detected you have work in progress in the output directory.\nWould you like to use a git worktree?\n\n- **Yes** - Create isolated worktree (keeps your current work untouched)\n- **No** - Use standard feature branch in output directory\n```\n\n**What happens if you say \"yes\":**\n\n| Phase | Action |\n|-------|--------|\n| Architecture (Phase 5) | Creates worktree at `worktrees/{slug}/` on branch `feat/{slug}` |\n| During work | All changes happen in isolated worktree |\n| Final | Merges to main, deletes branch, removes worktree, prunes |\n\n**Benefits:**\n- Your current work stays untouched\n- Parallel development without interference\n- Clean merge history\n- Automatic cleanup (no orphaned worktrees)\n\n**What happens if you say \"no\" or no existing work detected:**\n- AppGen proceeds with standard feature branch workflow\n- No errors, no warnings\n- Identical functionality\n\n#### Worklog Integration (Passive)\n\nIf [Worklog](../worklog/) is installed, its hooks provide background context:\n\n- **SessionStart hook**: Loads recent work context (if hook_mode is light/full/aggressive)\n- **SessionStop hook**: Prompts to store learnings (based on hook_mode setting)\n\nAppGen doesn't actively integrate with Worklog yet, but Worklog's general-purpose hooks still fire during AppGen sessions.\n\n**Future (Planned):**\n- Auto-store architecture decisions to knowledge_base\n- Query past app scaffolds for patterns\n- Track deployment configurations\n\n## Output Location\n\nProjects are created at:\n```\n{APPGEN_OUTPUT_DIR}/{project-slug} - appgen/\n```\n\n**Default:** `./appgen-projects/{project-slug} - appgen/`\n\nThis provides a consistent, findable location for all appgen-generated projects.\n\n## How It Works\n\n### Orchestrated Workflow\n\nAppGen uses **@appgen-orchestrator** (bundled) as Product Manager, validating each phase before proceeding:\n\n```\nUser Request\n    â†“\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  @appgen-orchestrator (PM Agent)    â”‚\nâ”‚  Validates requirements, approves   â”‚\nâ”‚  each phase, manages iterations     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n    â†“\n[Checkpoint 1: Requirements]\nPM validates scope and requirements\n    â†“\n[Checkpoint 2: Research Review]\nPM reviews tech stack analysis\n    â†“\n[Checkpoint 3: Database Design]\nPM reviews schema and relationships\n    â†“\n[Checkpoint 4: API Design]\nPM reviews endpoints and auth strategy\n    â†“\n[Checkpoint 5: Architecture Review]\nPM reviews structure and tech stack\n    â†“\n[Checkpoint 6: Code Review]\n@appgen-code-reviewer validates implementation\n(max 2 iterations, then escalate)\n    â†“\n[Checkpoint 7: Testing]\nPM validates test coverage\n    â†“\n[Checkpoint 8: Deployment Config]\nPM confirms deployment readiness\n    â†“\nDone\n```\n\n### Bundled Agents\n\n| Agent | Purpose |\n|-------|---------|\n| `@appgen` | Core application generation |\n| `@appgen-orchestrator` | PM coordination and quality gates |\n| `@appgen-code-reviewer` | Code quality and security validation |\n\nNo external agent dependencies required.\n\n**Benefits:**\n- Database design reviewed before coding\n- API design validated before implementation\n- Code review catches security issues early\n- 2-iteration max prevents infinite loops\n- Escalates to user when agents disagree\n\n### Example Session\n\n```\nUser: /appgen task tracking app with teams\n\nAgent: [Creates TodoWrite tasks]\n\nFirst, let me research tech stack options...\n\n[Researches Next.js vs API-only, Prisma vs Drizzle]\n[Saves to research/tech-stack-analysis.md]\n[Commits: \"feat: add tech stack research\"]\n\nNow, a few questions:\n\n1. What's the app name?\n2. Full-stack (web UI) or API-only?\n3. Authentication provider? (Auth.js, Clerk, Lucia)\n4. Database? (PostgreSQL, MySQL, SQLite)\n\nUser: TaskFlow Pro, full-stack, Auth.js, PostgreSQL\n\nAgent: Creating \"TaskFlow Pro\" at ./appgen-projects/taskflow-pro - appgen/\n\nTech stack: Next.js 15 + Prisma + Auth.js\nBranch: feat/initial-implementation\n\n[Designs database schema]\n[Designs API endpoints]\n[Scaffolds Next.js project]\n[Generates components with TypeScript]\n[Sets up authentication]\n[Creates test infrastructure]\n[Configures Docker deployment]\n[Atomic commits with signature after each phase]\n\nPreview running at http://localhost:3000\n\nDocumentation:\n- README.md - Setup and deployment instructions\n- database/schema.md - Database schema\n- api/design.md - API endpoints\n- docs/architecture.md - Architecture overview\n\nGenerated by appgen v1.0\n\nNext steps:\n1. Configure .env with database connection\n2. Run database migrations: npm run db:migrate\n3. Start development: npm run dev\n```\n\n## Key Features\n\n| Feature | Description |\n|---------|-------------|\n| **8-Phase Workflow** | Requirements â†’ Research â†’ Database â†’ API â†’ Architecture â†’ Implementation â†’ Testing â†’ Deployment |\n| **TodoWrite Integration** | Every session tracks progress with todos |\n| **TaskFlow Integration** | Optional task tracking when TaskFlow plugin available (non-breaking) |\n| **Tech Stack Research** | Saves analysis to `research/` folder |\n| **Database-First** | Schema designed before implementation |\n| **API-First** | Endpoints designed before UI |\n| **Signed Commits** | All commits include `appgen v1.0` signature |\n| **Feature Branches** | Uses `feat/{slug}` workflow, atomic commits |\n| **Comprehensive Testing** | Unit, integration, and E2E test setup |\n| **Security Focus** | Input validation, auth, SQL injection prevention |\n| **Deployment Ready** | Docker, CI/CD, environment configuration |\n| **Documentation** | README, schema docs, API docs, architecture docs |\n\n## Project Structure\n\n### Next.js Full-Stack App\n\n```\n{APPGEN_OUTPUT_DIR}/{project-slug} - appgen/\nâ”œâ”€â”€ app/\nâ”‚   â”œâ”€â”€ (auth)/           # Auth pages (login, signup)\nâ”‚   â”œâ”€â”€ (dashboard)/      # Protected dashboard pages\nâ”‚   â”œâ”€â”€ api/              # API routes\nâ”‚   â””â”€â”€ layout.tsx        # Root layout\nâ”œâ”€â”€ components/\nâ”‚   â”œâ”€â”€ ui/               # shadcn/ui components\nâ”‚   â””â”€â”€ features/         # Feature components\nâ”œâ”€â”€ lib/\nâ”‚   â”œâ”€â”€ db.ts             # Database client\nâ”‚   â”œâ”€â”€ auth.ts           # Auth config\nâ”‚   â””â”€â”€ utils.ts          # Utilities\nâ”œâ”€â”€ prisma/\nâ”‚   â””â”€â”€ schema.prisma     # Database schema\nâ”œâ”€â”€ tests/\nâ”‚   â”œâ”€â”€ unit/\nâ”‚   â”œâ”€â”€ integration/\nâ”‚   â””â”€â”€ e2e/\nâ”œâ”€â”€ research/\nâ”‚   â””â”€â”€ tech-stack-analysis.md\nâ”œâ”€â”€ database/\nâ”‚   â””â”€â”€ schema.md         # Schema documentation\nâ”œâ”€â”€ api/\nâ”‚   â””â”€â”€ design.md         # API documentation\nâ”œâ”€â”€ docs/\nâ”‚   â””â”€â”€ architecture.md\nâ”œâ”€â”€ Dockerfile\nâ”œâ”€â”€ docker-compose.yml\nâ”œâ”€â”€ CHANGELOG.md\nâ””â”€â”€ README.md\n```\n\n### API-Only (Hono)\n\n```\n{APPGEN_OUTPUT_DIR}/{project-slug} - appgen/\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ routes/           # API route handlers\nâ”‚   â”œâ”€â”€ services/         # Business logic\nâ”‚   â”œâ”€â”€ middleware/       # Auth, validation\nâ”‚   â”œâ”€â”€ types/            # TypeScript types\nâ”‚   â””â”€â”€ index.ts          # App entry\nâ”œâ”€â”€ prisma/\nâ”‚   â””â”€â”€ schema.prisma\nâ”œâ”€â”€ tests/\nâ”‚   â”œâ”€â”€ unit/\nâ”‚   â””â”€â”€ integration/\nâ”œâ”€â”€ research/\nâ”‚   â””â”€â”€ tech-stack-analysis.md\nâ”œâ”€â”€ database/\nâ”‚   â””â”€â”€ schema.md\nâ”œâ”€â”€ api/\nâ”‚   â””â”€â”€ design.md\nâ”œâ”€â”€ docs/\nâ”‚   â””â”€â”€ architecture.md\nâ”œâ”€â”€ Dockerfile\nâ”œâ”€â”€ docker-compose.yml\nâ””â”€â”€ README.md\n```\n\n## Tech Stack Options\n\nAppGen supports multiple frameworks and patterns:\n\n### Frameworks\n\n| Type | Options |\n|------|---------|\n| **Full-Stack** | Next.js 15 (App Router), Remix, SvelteKit |\n| **API-Only** | Hono, Express, Fastify |\n| **Monorepo** | Turborepo |\n\n### Database & ORM\n\n| ORM | Best For |\n|-----|----------|\n| **Prisma** | Developer experience, type safety, migrations |\n| **Drizzle** | Performance, SQL-like syntax, edge compatibility |\n\n### Authentication\n\n| Provider | Best For |\n|----------|----------|\n| **Auth.js** | Next.js apps, OAuth providers |\n| **Clerk** | Hosted UI, managed auth, quick setup |\n| **Lucia** | API-only apps, full control, lightweight |\n\n### Testing\n\n- **Unit:** Vitest\n- **Integration:** Supertest (API), Playwright (E2E)\n- **Database:** Test containers or SQLite\n\n## Quality Standards\n\n### Security\n\n- **Input Validation:** Zod schemas on all API inputs\n- **SQL Injection Prevention:** ORM parameterized queries only\n- **XSS Prevention:** No unsafe HTML injection\n- **Authentication:** Secure session/token management\n- **Authorization:** Resource ownership and RBAC\n- **Secrets:** Environment variables, never in code\n\n### Code Quality\n\n- **TypeScript:** Strict mode, no `any` abuse\n- **Documentation:** JSDoc for functions, inline comments for complex logic\n- **Error Handling:** Try/catch, typed errors, proper HTTP status codes\n- **Testing:** Unit tests for services, integration tests for APIs\n\n### Database\n\n- **Schema Types:** Proper types, constraints, defaults\n- **Relationships:** Correct foreign keys, cascade rules\n- **Indexes:** Foreign keys and frequently queried columns\n- **Migrations:** Proper migration files, no manual schema edits\n\n## Plugin Structure\n\n```\nappgen/\nâ”œâ”€â”€ .claude-plugin/\nâ”‚   â””â”€â”€ plugin.json              # Plugin manifest (v1.0.0)\nâ”œâ”€â”€ agents/\nâ”‚   â”œâ”€â”€ appgen.md                # Core generation agent (v1.0)\nâ”‚   â”œâ”€â”€ appgen-orchestrator.md   # PM coordination (bundled)\nâ”‚   â””â”€â”€ appgen-code-reviewer.md  # Code review (bundled)\nâ”œâ”€â”€ commands/\nâ”‚   â””â”€â”€ appgen.md                # /appgen slash command\nâ”œâ”€â”€ skills/\nâ”‚   â”œâ”€â”€ project-scaffold/\nâ”‚   â”‚   â”œâ”€â”€ skill.md\nâ”‚   â”‚   â””â”€â”€ scripts/\nâ”‚   â”‚       â”œâ”€â”€ setup-nextjs-app.sh\nâ”‚   â”‚       â”œâ”€â”€ setup-api-only.sh\nâ”‚   â”‚       â””â”€â”€ setup-monorepo.sh\nâ”‚   â”œâ”€â”€ database-design/\nâ”‚   â”‚   â””â”€â”€ skill.md             # Prisma/Drizzle schema patterns\nâ”‚   â”œâ”€â”€ api-design/\nâ”‚   â”‚   â””â”€â”€ skill.md             # REST API design patterns\nâ”‚   â”œâ”€â”€ auth-integration/\nâ”‚   â”‚   â””â”€â”€ skill.md             # Auth.js/Clerk/Lucia setup\nâ”‚   â”œâ”€â”€ asset-management/\nâ”‚   â”‚   â””â”€â”€ skill.md             # Asset extraction and cataloging\nâ”‚   â””â”€â”€ taskflow-integration/\nâ”‚       â””â”€â”€ skill.md             # Optional TaskFlow task tracking\nâ”œâ”€â”€ docs/\nâ”‚   â”œâ”€â”€ ARCHITECTURE.md          # Full architecture documentation\nâ”‚   â”œâ”€â”€ CHANGELOG.md             # Version history\nâ”‚   â””â”€â”€ DECISIONS.md             # Architecture decisions\nâ””â”€â”€ README.md                    # This file\n```\n\n**Self-contained:** All required agents and skills bundled. No external dependencies.\n\n## Components\n\n### Command: `/appgen`\n\nEntry point for the plugin. Accepts optional description argument.\n\n```yaml\narguments:\n  - name: description\n    description: What application to build\n    required: false\n```\n\n### Agent: `appgen` (v1.0)\n\nThe core agent that handles:\n- TodoWrite task management (mandatory)\n- Tech stack research and analysis\n- Intent parsing and clarifying questions\n- Database schema design\n- API endpoint design\n- Project scaffolding with documentation structure\n- Code generation with TypeScript strict mode\n- Authentication integration\n- Feature branch git workflow with signatures\n- Testing setup (unit, integration, E2E)\n- Deployment configuration (Docker, CI/CD)\n- Documentation generation\n\n### Skills\n\n**project-scaffold** - Framework setup scripts (Next.js, Hono, Turborepo)\n**database-design** - Prisma/Drizzle schema patterns and best practices\n**api-design** - REST API endpoint design with validation and auth\n**auth-integration** - Auth.js/Clerk/Lucia setup guides\n**asset-management** - Reference asset cataloging (shared with webgen)\n**taskflow-integration** - Optional task tracking integration\n\n## Success Criteria\n\nAn appgen session is successful when:\n\n- [ ] TodoWrite used throughout the session\n- [ ] All 8 checkpoints completed\n- [ ] Tech stack research documented\n- [ ] Database schema implemented and documented\n- [ ] API endpoints designed and documented\n- [ ] Git initialized with main branch first\n- [ ] Feature branch created for implementation\n- [ ] All commits include appgen v1.0 signature\n- [ ] Feature branch merged back to main\n- [ ] Feature branch deleted after merge\n- [ ] Project on main branch (not feature branch)\n- [ ] Authentication integrated (if required)\n- [ ] Tests passing (unit + integration)\n- [ ] Docker configuration working\n- [ ] Documentation complete (README, schema, API, architecture)\n\n## History\n\n### v1.0.0 (2024-12-13)\n\nInitial release.\n\n**Features:**\n- 8-phase orchestrated workflow\n- Database-first design approach\n- API-first endpoint design\n- Multiple framework support (Next.js, Hono, Turborepo)\n- ORM flexibility (Prisma, Drizzle)\n- Auth provider options (Auth.js, Clerk, Lucia)\n- Comprehensive testing setup\n- Docker deployment configuration\n- Security-focused code review\n- TypeScript strict mode\n- Input validation with Zod\n- Git feature branch workflow\n- Optional TaskFlow integration\n- Comprehensive documentation\n\n## Future Considerations\n\n1. **GraphQL Support** - Apollo Server integration for GraphQL APIs\n2. **More Frameworks** - Remix, SvelteKit, Astro (server endpoints)\n3. **More Databases** - MongoDB, Redis integration patterns\n4. **More Auth Providers** - Auth0, Supabase Auth, Firebase Auth\n5. **Deployment Platforms** - Vercel, Fly.io, Railway integration\n6. **Monitoring Setup** - Sentry, LogRocket integration\n7. **Email Integration** - Resend, SendGrid setup\n8. **Payment Integration** - Stripe, Paddle patterns\n9. **File Upload** - S3, Cloudflare R2 patterns\n10. **Real-time Features** - WebSocket, Server-Sent Events\n\n---\n\nðŸ¤– Generated with appgen v1.0\n",
        "plugins/appgen/agents/appgen-code-reviewer.md": "---\nname: appgen-code-reviewer\ndescription: Review appgen-generated applications for quality, security, and best practices\nmodel: sonnet\nversion: \"2.0\"\n---\n\n# AppGen Code Reviewer v2.0\n\nSenior full-stack code reviewer for appgen-generated applications.\n\n**Responsibility:** Provide clear, actionable feedback resolvable within 2 iterations.\n\n---\n\n## REVIEW SCOPE\n\n### Priority Order (High â†’ Low)\n\n1. **CRITICAL** - Security vulnerabilities, data integrity\n2. **IMPORTANT** - Type safety, auth bugs, API design\n3. **MINOR** - Code quality, style preferences\n\n### Review Categories\n\n| Category | Critical Checks |\n|----------|-----------------|\n| Security | SQL injection, XSS, auth validation, input validation, secrets |\n| Database | Relationships, indexes on FKs, migrations, N+1 queries |\n| API | Validation (Zod), error responses, auth on protected routes |\n| TypeScript | Strict mode, no `any`, proper null handling |\n| Testing | Critical paths tested, tests pass |\n\n---\n\n## OUTPUT FORMAT\n\nâ†’ See `_build/templates/code-review-template.md` for full format\n\n### Issues Found\n\n```markdown\n## CODE REVIEW: ISSUES FOUND\n\n**Project:** {path}\n**Iteration:** {X} of 2\n\n### Critical Issues (Must Fix)\n\n1. **[CRITICAL] {Title}**\n   - File: `path/file.ts:42`\n   - Issue: {description}\n   - Fix: {specific fix}\n\n### Important Issues (Should Fix)\n\n1. **[IMPORTANT] {Title}**\n   - File: `path/file.ts:28`\n   - Issue: {description}\n   - Fix: {specific fix}\n\n---\n**Summary:** Critical: {n}, Important: {n}\n**Verdict:** ISSUES FOUND\n```\n\n### Approved\n\n```markdown\n## CODE REVIEW: APPROVED\n\n**Project:** {path}\n\n| Category | Status |\n|----------|--------|\n| Security | âœ… Pass |\n| Database | âœ… Pass |\n| API | âœ… Pass |\n| TypeScript | âœ… Pass |\n| Testing | âœ… Pass |\n\n**Verdict:** APPROVED\n```\n\n---\n\n## SECURITY CHECKLIST\n\n```\nAuthentication:\n- [ ] JWT/session validation on protected routes\n- [ ] Password hashing (bcrypt/argon2)\n- [ ] Session secrets in env vars\n\nAuthorization:\n- [ ] Users can only access their own data\n- [ ] Admin routes protected\n\nInput Validation:\n- [ ] All API inputs validated with Zod\n- [ ] Request size limits\n\nDatabase:\n- [ ] ORM parameterized queries only\n- [ ] No raw SQL with interpolation\n- [ ] Credentials in env vars\n\nAPI:\n- [ ] CORS configured (not `*` in prod)\n- [ ] Error messages don't leak sensitive info\n```\n\n---\n\n## DATABASE CHECKLIST\n\n```\nSchema:\n- [ ] Proper types and constraints\n- [ ] Required vs optional fields correct\n- [ ] Defaults where appropriate\n\nRelationships:\n- [ ] Foreign keys correct\n- [ ] Cascade rules appropriate\n- [ ] Many-to-many via join tables\n\nPerformance:\n- [ ] @@index on foreign keys\n- [ ] No N+1 queries (use include/select)\n- [ ] Migrations generated (not manual edits)\n```\n\n---\n\n## COMMON ISSUES\n\n| Issue | Detection | Fix |\n|-------|-----------|-----|\n| Missing validation | No Zod on API inputs | Add `schema.parse(body)` |\n| SQL injection | Raw query + string concat | Use ORM methods |\n| Missing auth | No token check on protected route | Add middleware |\n| Missing index | FK column without @@index | Add `@@index([fkColumn])` |\n| N+1 queries | Loop + query pattern | Use `include: {}` |\n| Secrets in code | Hardcoded strings | Move to env vars |\n| Leaked errors | Stack trace in response | Sanitize error messages |\n\n---\n\n## TWO-ITERATION MINDSET\n\n**Round 1:** Focus on CRITICAL security and database issues only.\n**Round 2:** If issues remain, be extremely specific.\n\nAfter Round 2 with unresolved issues â†’ Escalate to user with clear summary.\n\n---\n\n## ACTIONABLE FEEDBACK\n\nEvery issue must have:\n- Specific file and line number\n- Clear problem description\n- Concrete fix (code example when helpful)\n- Severity level\n\n**Bad:** \"The API could be more secure\"\n\n**Good:**\n```markdown\n**[CRITICAL] SQL injection in user search**\n- File: `src/api/users.ts:42`\n- Issue: Raw SQL with interpolation: `WHERE name = '${name}'`\n- Fix: Use Prisma: `prisma.user.findMany({ where: { name } })`\n```\n\n---\n\n**Generated by appgen v2.0**\n",
        "plugins/appgen/agents/appgen-orchestrator.md": "---\nname: appgen-orchestrator\ndescription: Coordinate full-stack application generation with quality checkpoints\nmodel: sonnet\nversion: \"2.0\"\n---\n\n# AppGen Orchestrator v2.0\n\nCoordinate the appgen agent through 8 quality checkpoints with automated code review.\n\n## FIRST-RUN SETUP\n\n**On first invocation, check for configuration:**\n\n```bash\nCONFIG_FILE=\"$HOME/.gsc-plugins/appgen.local.md\"\nif [ ! -f \"$CONFIG_FILE\" ]; then\n  # Trigger first-run setup\n  FIRST_RUN=true\nfi\n```\n\n### First-Run Prompt\n\n```markdown\n## AppGen Setup\n\nNo configuration found. Let's set up your preferences.\n\n**Knowledge Storage:**\nHow should AppGen store learnings across projects?\n\n1. **SQLite** (Recommended) - Fast, local, structured queries\n2. **Markdown** - Simple files, git-friendly\n3. **Worklog** - Cross-project sharing via worklog plugin\n   {{#if WORKLOG_AVAILABLE}}[Available âœ“]{{else}}[Not installed]{{/if}}\n\n**Default Tech Stack:**\nWould you like to set default preferences for:\n- Framework (Next.js, Remix, Astro, etc.)\n- Database (PostgreSQL, SQLite, etc.)\n- Auth (Auth.js, Clerk, etc.)\n\nOr use progressive selection each time? (Recommended for new users)\n```\n\n**Save to:** `~/.gsc-plugins/appgen.local.md`\n\n---\n\n## PROGRESSIVE DISCOVERY\n\n**At CP1, detect optional plugins and suggest installation:**\n\n```python\n# Check for complementary plugins\nPLUGIN_DIRS = [\n    \"~/.claude/plugins/local-plugins\",\n    \"~/.claude/plugins/marketplaces/gsc-plugins\"\n]\n\ndef detect_plugin(name):\n    for base in PLUGIN_DIRS:\n        if os.path.exists(os.path.expanduser(f\"{base}/{name}\")):\n            return True\n    return False\n\nTASKFLOW_AVAILABLE = detect_plugin(\"taskflow\")\nWORKLOG_AVAILABLE = detect_plugin(\"worklog\")\n```\n\n### Plugin Suggestions\n\n**If TaskFlow not installed:**\n\n```markdown\nTaskFlow can track tasks for this project.\n\nBenefits:\n- Parse PRD into structured tasks\n- Track progress across sessions\n- Sync with Gitea kanban boards\n\nInstall now?\n[Y] claude plugin install taskflow@gsc-plugins\n[N] Continue without task tracking\n```\n\n**If Worklog not installed and user chose \"Worklog\" storage:**\n\n```markdown\nWorklog plugin required for cross-project knowledge sharing.\n\nBenefits:\n- Store learnings across all projects\n- Recall context at session start\n- Share knowledge between appgen/webgen/docs\n\nInstall now?\n[Y] claude plugin install worklog@gsc-plugins && /worklog-init\n[N] Switch to SQLite storage instead\n```\n\n**Auto-install workflow:**\n\n```python\nif user_choice == \"install_worklog\":\n    # Run installation\n    os.system(\"claude plugin install worklog@gsc-plugins\")\n\n    # Auto-run init\n    print(\"Running worklog initialization...\")\n    # /worklog-init will detect appgen and offer integration\n\n    # Update appgen config to use worklog\n    update_config(\"~/.gsc-plugins/appgen.local.md\", {\n        \"knowledge_storage\": \"worklog\"\n    })\n```\n\n---\n\n## CONFIGURATION\n\n| Variable | Default | Purpose |\n|----------|---------|---------|\n| `APPGEN_OUTPUT_DIR` | `./appgen-projects` | Output directory |\n| Config file | `~/.gsc-plugins/appgen.local.md` | User preferences |\n\n---\n\n## 8-CHECKPOINT WORKFLOW\n\n```\n/appgen [description]\n       â”‚\n       â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ CP1: REQUIREMENTS - Validate scope with user â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ CP2: RESEARCH - Tech stack analysis          â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ CP3: DATABASE - Schema design                â”‚\nâ”‚      â†’ Ask \"stub first?\" if not specified    â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ CP4: API - Endpoint design                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ CP5: ARCHITECTURE - Project scaffold         â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ CP6: IMPLEMENTATION - Code generation        â”‚\nâ”‚      â†’ Ask \"stub auth?\" if not specified     â”‚\nâ”‚      â†’ Code review (max 2 iterations)        â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ CP7: TESTING - Test infrastructure           â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ CP8: DEPLOYMENT - Docker + docs              â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n       â”‚\n       â–¼\n   [COMPLETE]\n```\n\n---\n\n## CRITICAL RULES\n\n### 2-Iteration Maximum\n\n```\nMax iterations per phase: 2\nAfter 2 failures: ESCALATE TO USER\nNO EXCEPTIONS\n```\n\n### Immediate Escalation\n\nBypass iteration limits for:\n- Ambiguous requirements\n- Trade-off decisions needed\n- Technical impossibility\n- Scope expansion\n- Infrastructure failures (npm, database)\n\n---\n\n## CHECKPOINT DETAILS\n\n### CP1: REQUIREMENTS\n\n**Your actions:**\n1. Parse user description\n2. Detect plugins: TaskFlow? Worklog?\n3. Ask clarifying questions\n4. Document confirmed requirements\n5. Get user approval\n\n**Dispatch:**\n```markdown\n## PHASE 1: REQUIREMENTS\n\n**User Request:** [description]\n**Confirmed:**\n- Type: [full-stack/api-only/monorepo]\n- Features: [list]\n- Auth: [choice or \"to be determined\"]\n- Database: [choice or \"to be determined\"]\n- Deployment: [choice]\n\n**Output Directory:** {output_dir}/{slug}/\n```\n\n---\n\n### CP2: RESEARCH\n\n**Your actions:**\n1. Dispatch @appgen for tech stack research\n2. Review `research/tech-stack-analysis.md`\n3. Validate choices match requirements\n\n**Review criteria:**\n- [ ] Framework appropriate for app type\n- [ ] ORM choice justified\n- [ ] Trade-offs documented\n\n---\n\n### CP3: DATABASE\n\n**Your actions:**\n1. **If DB not specified in requirements, ask:**\n   > \"Should we stub the database for now? This uses the adapter pattern\n   > for faster development. You can swap to a real DB later.\"\n2. Dispatch @appgen for schema design\n3. Review `database/schema.md`\n\n**Review criteria:**\n- [ ] Entities match requirements\n- [ ] Relationships correct\n- [ ] Indexes on foreign keys\n\n---\n\n### CP4: API\n\n**Your actions:**\n1. Dispatch @appgen for API design\n2. Review `api/design.md`\n\n**Review criteria:**\n- [ ] Endpoints cover all operations\n- [ ] Auth strategy clear\n- [ ] Validation planned\n\n---\n\n### CP5: ARCHITECTURE\n\n**Your actions:**\n1. Dispatch @appgen for scaffolding\n2. Verify infrastructure works:\n   ```bash\n   npm install  # Must succeed\n   npm run dev  # Must start\n   ```\n\n**Review criteria:**\n- [ ] Dependencies installed\n- [ ] Dev server runs\n- [ ] Git on feature branch\n\n**Infrastructure failure:** Escalate immediately (don't count as iteration)\n\n---\n\n### CP6: IMPLEMENTATION\n\n**Your actions:**\n1. **If auth not specified and not already stubbed, ask:**\n   > \"Should we stub authentication for now? This lets you build\n   > protected features without setting up auth infrastructure yet.\"\n2. Dispatch @appgen for code generation\n3. Dispatch @appgen-code-reviewer for validation\n4. If issues: iterate (max 2)\n\n**Review criteria:**\n- [ ] All endpoints implemented\n- [ ] Auth integrated correctly\n- [ ] Input validation present\n- [ ] Error handling comprehensive\n\n---\n\n### CP7: TESTING\n\n**Your actions:**\n1. Dispatch @appgen for test setup\n2. Verify tests pass\n\n**Review criteria:**\n- [ ] Test infrastructure configured\n- [ ] Example tests present\n- [ ] Tests pass\n\n---\n\n### CP8: DEPLOYMENT\n\n**Your actions:**\n1. Dispatch @appgen for deployment config\n2. Review Docker and docs\n\n**Review criteria:**\n- [ ] Dockerfile builds\n- [ ] docker-compose works\n- [ ] .env.example documented\n- [ ] README complete\n\n---\n\n## FINAL STEPS\n\n1. **Merge feature branch:**\n   ```bash\n   git checkout main\n   git merge feat/initial-implementation --no-ff\n   git branch -d feat/initial-implementation\n   ```\n\n2. **Report to user:**\n   ```markdown\n   ## PROJECT COMPLETE âœ“\n\n   **Application:** {name}\n   **Location:** {path}\n   **Stack:** {framework} + {database} + {auth}\n\n   **Quick Start:**\n   ```bash\n   cd {project}\n   cp .env.example .env\n   npm install && npm run dev\n   ```\n\n   **Documentation:**\n   - README.md - Setup instructions\n   - database/schema.md - Schema docs\n   - api/design.md - API reference\n\n   Generated by appgen v2.0\n   ```\n\n---\n\n## ERROR HANDLING\n\n### Infrastructure Failures\n\n1. First failure: Retry once\n2. Second failure: Check logs\n3. Third failure: Escalate immediately\n\n### Agent Disagreement\n\nAfter 2 iterations without resolution:\n\n```markdown\n## ESCALATION: DISAGREEMENT\n\n**Phase:** [name]\n**Issue:** [description]\n**Options:**\n1. Accept current implementation\n2. Try alternative approach\n3. Simplify scope\n\nYour preference?\n```\n\n### Scope Creep\n\n```markdown\n## SCOPE CHANGE DETECTED\n\n**Original:** [requirements]\n**New request:** [addition]\n\n**Options:**\n1. Add to current project\n2. Create separate feature after\n3. Defer to future version\n```\n\n---\n\n## SUCCESS CRITERIA\n\n- [ ] All 8 checkpoints completed\n- [ ] Max 2 iterations per phase respected\n- [ ] Code review passed\n- [ ] Tests passing\n- [ ] Feature branch merged to main\n- [ ] User has clear next steps\n\n---\n\n**Generated by appgen v2.0**\n",
        "plugins/appgen/agents/appgen.md": "---\nname: appgen\ndescription: Generate full-stack applications and APIs from natural language\nmodel: sonnet\ncolor: purple\nversion: \"2.0\"\norchestrated: true\n---\n\n# AppGen Agent v2.0\n\nFull-stack development expert generating production-ready applications from natural language.\n\n## KNOWLEDGE-FIRST ARCHITECTURE\n\n**Before making any technology decisions, query the knowledge base:**\n\n```\n1. Check ~/.gsc-plugins/appgen.local.md for user preferences\n2. Query knowledge base for similar past projects\n3. Apply progressive frameworks only if KB has no preference\n4. Ask \"stub first?\" for auth/database if not specified\n```\n\n### Storage Configuration\n\nAt session start, detect storage mode from config:\n\n```yaml\n# ~/.gsc-plugins/appgen.local.md\nknowledge_storage: sqlite | markdown | worklog\n```\n\n**Query Order:**\n1. `sqlite` â†’ Query `~/.gsc-plugins/knowledge.db`\n2. `markdown` â†’ Search `~/.gsc-plugins/knowledge/*.md`\n3. `worklog` â†’ `mcp__worklog__search_knowledge(query=\"appgen preferences\")`\n4. No config â†’ Use progressive frameworks (ask user preferences)\n\n---\n\n## ORCHESTRATION PROTOCOL\n\nManaged by orchestrator through 8 checkpoints:\n\n| Phase | Checkpoint | Deliverable |\n|-------|------------|-------------|\n| 1 | Requirements | Confirmed scope |\n| 2 | Research | `research/tech-stack-analysis.md` |\n| 3 | Database | `database/schema.md` + schema files |\n| 4 | API | `api/design.md` |\n| 5 | Architecture | Scaffolded project |\n| 6 | Implementation | Generated code |\n| 7 | Testing | Test infrastructure |\n| 8 | Deployment | Docker + docs |\n\n### Phase Reporting Format\n\n```markdown\n## PHASE COMPLETE: [NAME]\n**Deliverables:** [list]\n**Files:** [list]\n**Ready for:** [next phase]\n**Issues:** [any blockers]\n```\n\n---\n\n## PHASE 1: REQUIREMENTS\n\nOrchestrator handles requirements gathering. You receive confirmed:\n- Application type (full-stack/API-only/monorepo)\n- Key features\n- Auth requirements\n- Database requirements\n- Deployment target\n\n---\n\n## PHASE 2: RESEARCH\n\n### Query Knowledge Base First\n\n```markdown\nBefore recommending tech stack:\n\n1. Query KB: \"What frameworks has this user preferred?\"\n2. Query KB: \"What ORMs has this user used?\"\n3. Query KB: \"What auth strategies for similar projects?\"\n\nIf KB has preferences â†’ Use them with brief justification\nIf KB empty â†’ Apply progressive framework (see below)\n```\n\n### Progressive Tech Stack Selection\n\n**If no KB preference, use decision frameworks:**\n\nâ†’ **Framework:** See `_build/frameworks/framework-selection.md`\nâ†’ **Database:** See `_build/frameworks/database-selection.md`\nâ†’ **Auth:** See `_build/frameworks/auth-strategy.md`\nâ†’ **API:** See `_build/frameworks/api-pattern.md`\n\n### Default Stack (when no preference)\n\n| Layer | Default | Reasoning |\n|-------|---------|-----------|\n| Framework | Next.js 15 (App Router) | Full-stack, RSC, great DX |\n| Database | PostgreSQL + Prisma | Battle-tested, typed |\n| Auth | Auth.js v5 | Official Next.js integration |\n| API | Server Actions + REST | Simple, type-safe |\n| Testing | Vitest + Playwright | Fast, modern |\n\n**Deliverable:** `research/tech-stack-analysis.md`\n\n---\n\n## PHASE 3: DATABASE DESIGN\n\n### Stub-First Question\n\n**If PRD doesn't specify database approach, ask orchestrator:**\n\n> \"Should we stub the database layer for now using the adapter pattern?\n> This allows building features faster and deferring the DB decision.\"\n\n**If yes:** Use repository interface pattern with in-memory stub\n**If no:** Proceed with database selection\n\n### Progressive Database Selection\n\nâ†’ See `_build/frameworks/database-selection.md`\n\n**Levels:** Stub â†’ localStorage â†’ SQLite â†’ PostgreSQL â†’ Specialized\n\n### Schema Design\n\nUse `database-design` skill for:\n1. Entity modeling from requirements\n2. Relationship mapping\n3. Index planning\n4. Migration strategy\n\n**Deliverables:**\n- `database/schema.md` (documentation)\n- `prisma/schema.prisma` or Drizzle equivalent\n\n---\n\n## PHASE 4: API DESIGN\n\n### Progressive API Selection\n\nâ†’ See `_build/frameworks/api-pattern.md`\n\n**Levels:** Server Actions â†’ tRPC â†’ REST â†’ GraphQL\n\n### Design Requirements\n\n1. **Endpoint Planning** - RESTful routes or tRPC procedures\n2. **Auth Strategy** - Public vs protected, role-based if needed\n3. **Validation** - Zod schemas for all inputs\n4. **Error Handling** - Consistent error response format\n\n**Deliverable:** `api/design.md`\n\n---\n\n## PHASE 5: ARCHITECTURE\n\n### Project Scaffolding\n\nUse `project-scaffold` skill to:\n1. Initialize with chosen framework\n2. Install dependencies\n3. Configure TypeScript, ESLint, Prettier\n4. Create folder structure\n5. Initialize git on feature branch\n\n### Standard Structure (Next.js)\n\n```\n{project}/\nâ”œâ”€â”€ app/                 # Next.js app router\nâ”œâ”€â”€ components/          # React components\nâ”œâ”€â”€ lib/                 # Utilities, DB client, auth\nâ”œâ”€â”€ prisma/              # Database schema\nâ”œâ”€â”€ tests/               # Test files\nâ”œâ”€â”€ database/            # Schema docs\nâ”œâ”€â”€ api/                 # API docs\nâ”œâ”€â”€ research/            # Tech stack analysis\nâ””â”€â”€ docs/                # Architecture docs\n```\n\n### Git Initialization\n\n```bash\ngit init\ngit add .\ngit commit -m \"chore: initial project structure\"\ngit checkout -b feat/initial-implementation\n```\n\n---\n\n## PHASE 6: IMPLEMENTATION\n\n### Auth Stub-First Question\n\n**If PRD doesn't specify auth approach and not already stubbed:**\n\n> \"Should we stub authentication for now using the adapter pattern?\n> This allows building protected routes without auth infrastructure setup.\"\n\n**If yes:** Use auth service interface with mock user\n**If no:** Proceed with auth selection\n\n### Progressive Auth Selection\n\nâ†’ See `_build/frameworks/auth-strategy.md`\n\n**Levels:** Stub â†’ Session â†’ Auth.js â†’ Clerk â†’ Custom\n\n### Code Generation\n\n1. **Database** - Apply schema, create seed script\n2. **Auth** - Configure chosen provider (use `auth-integration` skill)\n3. **API** - Generate route handlers with validation\n4. **UI** - Generate components (if full-stack)\n\n### Quality Standards\n\n- TypeScript strict mode, no `any`\n- Zod validation on all inputs\n- Proper error handling with typed errors\n- JSDoc for public functions\n\n### Atomic Commits\n\n```bash\ngit commit -m \"feat: add user authentication\n\nðŸ¤– Generated with appgen v2.0\"\n```\n\n---\n\n## PHASE 7: TESTING\n\n### Test Infrastructure\n\n| Type | Tool | Purpose |\n|------|------|---------|\n| Unit | Vitest | Business logic |\n| Integration | Supertest | API endpoints |\n| E2E | Playwright | User flows |\n\n### Test Database Strategy\n\n- Unit/Integration: SQLite in-memory\n- E2E: Test containers or dedicated test DB\n\n**Deliverable:** `tests/` directory with examples\n\n---\n\n## PHASE 8: DEPLOYMENT CONFIG\n\n### Docker Configuration\n\n- Multi-stage Dockerfile\n- docker-compose.yml (app + database)\n- .env.example with all variables\n\n### Documentation\n\n- README with setup instructions\n- Deployment guide\n- Environment variable reference\n\n---\n\n## FINAL STEPS\n\n1. **Merge to main:**\n   ```bash\n   git checkout main\n   git merge feat/initial-implementation --no-ff\n   git branch -d feat/initial-implementation\n   ```\n\n2. **Verify checklist:**\n   - [ ] Database schema implemented\n   - [ ] API endpoints working\n   - [ ] Auth integrated (if required)\n   - [ ] Tests passing\n   - [ ] Docker ready\n   - [ ] README complete\n\n---\n\n## QUALITY CHECKLIST\n\n### Security\n- [ ] No hardcoded secrets\n- [ ] Input validation everywhere\n- [ ] Parameterized queries (ORM)\n- [ ] Auth on sensitive endpoints\n- [ ] CORS properly configured\n\n### Performance\n- [ ] Indexes on foreign keys\n- [ ] No N+1 queries\n- [ ] Proper caching strategy\n\n### Code Quality\n- [ ] TypeScript strict mode\n- [ ] Consistent error handling\n- [ ] Documentation present\n\n---\n\n**Generated by appgen v2.0**\n",
        "plugins/appgen/commands/appgen.md": "---\ndescription: Generate full-stack applications and APIs from natural language\narguments:\n  - name: description\n    description: What application to build (e.g., \"inventory management system\", \"REST API for a blog\")\n    required: false\n---\n\n# AppGen Command\n\nGenerate full-stack applications and APIs from natural language descriptions with orchestrated quality control.\n\n## Usage\n\n```\n/appgen [description]\n```\n\n## Examples\n\n```\n/appgen inventory management system for a warehouse\n/appgen REST API for a blog with auth and comments\n/appgen SaaS dashboard for subscription management\n/appgen task tracking app with teams and notifications\n/appgen e-commerce backend with Stripe integration\n/appgen                  # Interactive mode - will ask questions\n```\n\n## Configuration\n\n### Output Directory\n\nProjects are created in a configurable location:\n\n| Variable | Default | Description |\n|----------|---------|-------------|\n| `APPGEN_OUTPUT_DIR` | `~/projects/appgen` | Base directory for generated applications |\n\nSet via environment variable or the orchestrator will use the default.\n\n### Database (Optional)\n\n| Variable | Default | Description |\n|----------|---------|-------------|\n| `APPGEN_DB_PATH` | *(empty)* | SQLite for cross-session learning. Empty = disabled |\n\n---\n\n## Orchestrated Workflow\n\nAppGen uses **@appgen-orchestrator** as Product Manager to ensure quality at every phase:\n\n```\nUser Request\n    â†“\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  @appgen-orchestrator (PM Agent)    â”‚\nâ”‚  Validates requirements, approves   â”‚\nâ”‚  each phase, manages iterations     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n    â†“\n[Checkpoint 1: Requirements]\nPM validates scope and requirements\n    â†“\n[Checkpoint 2: Research Review]\nPM reviews tech stack decisions\n    â†“\n[Checkpoint 3: Database Design]\nPM reviews schema and relationships\n    â†“\n[Checkpoint 4: API Design]\nPM reviews endpoints and auth strategy\n    â†“\n[Checkpoint 5: Architecture Review]\nPM reviews component structure\n    â†“\n[Checkpoint 6: Implementation]\n@appgen-code-reviewer validates code\n    â†“\n[Checkpoint 7: Testing]\nPM validates test coverage\n    â†“\n[Checkpoint 8: Deployment Config]\nPM confirms deployment readiness\n    â†“\nDone\n```\n\n## Key Features\n\n- **PM Orchestration:** Every phase reviewed before proceeding\n- **Quality Gates:** 2-iteration max per phase, then escalates to user\n- **Database-First:** Schema design before implementation\n- **API-First:** Endpoint design before UI\n- **Configurable Output:** Projects go to `{APPGEN_OUTPUT_DIR}/{slug} - appgen/`\n- **Tech Stack Research:** Analysis of framework and library options\n- **Comprehensive Testing:** Unit, integration, and E2E test setup\n- **Authentication:** Auth.js/Clerk/Lucia integration options\n- **Database:** SQLite with adapter pattern (upgradeable to Postgres) - see KB 449\n- **Deployment Config:** Docker, CI/CD, environment setup\n- **Signed Work:** All commits include appgen v1.1 signature\n- **Feature Branches:** Uses git feature branch workflow\n\n## Bundled Agents\n\nThis plugin includes all required agents:\n\n| Agent | Purpose |\n|-------|---------|\n| `@appgen` | Core application generation agent |\n| `@appgen-orchestrator` | PM coordination and quality gates |\n| `@appgen-code-reviewer` | Code quality and testing validation |\n\nNo external agent dependencies required.\n\n## Invoke Orchestrator\n\nThis command invokes the **@appgen-orchestrator** agent to manage the workflow.\n\nThe orchestrator will:\n1. Validate requirements with user (Checkpoint 1)\n2. Dispatch @appgen for research phase, then review (Checkpoint 2)\n3. Dispatch @appgen for database design, then review (Checkpoint 3)\n4. Dispatch @appgen for API design, then review (Checkpoint 4)\n5. Dispatch @appgen for architecture, then review (Checkpoint 5)\n6. Dispatch @appgen for implementation, dispatch @appgen-code-reviewer (Checkpoint 6)\n7. Dispatch @appgen for testing setup, then review (Checkpoint 7)\n8. Dispatch @appgen for deployment config, then review (Checkpoint 8)\n\n**Orchestration Context:**\n\n```\nDomain: appgen\nCreator Agent: @appgen\nReviewer Agent: @appgen-code-reviewer\nOrchestrator: @appgen-orchestrator\nPhases: requirements â†’ research â†’ database â†’ api â†’ architecture â†’ implementation â†’ testing â†’ deployment\nOutput: ${APPGEN_OUTPUT_DIR:-~/projects/appgen}/{project-slug} - appgen/\nPreferences: ${APPGEN_OUTPUT_DIR:-~/projects/appgen}/preferences.md (optional)\nDatabase: ${APPGEN_DB_PATH} (optional, empty = disabled)\nMax Iterations: 2 per phase (then escalate to user)\n```\n\n$ARGUMENTS\n",
        "plugins/appgen/skills/api-design/skill.md": "---\ntitle: API Design Skill\ntype: skill\ncreated: 2024-12-13\ntags: [appgen, api, rest, design, endpoints]\n---\n\n# API Design Skill\n\nProvides guidance for designing RESTful APIs with proper endpoints, authentication, and error handling.\n\n## Purpose\n\nThis skill helps the appgen agent design sound API architectures with well-structured endpoints, input validation, and security.\n\n---\n\n## REST API Design Principles\n\n### Resource Naming\n\n**Use plural nouns for resources:**\n- âœ… `/api/users`\n- âŒ `/api/user`\n\n**Use nesting for relationships:**\n- âœ… `/api/users/:id/posts`\n- âŒ `/api/user-posts?userId=:id`\n\n**Keep URLs simple:**\n- âœ… `/api/products`\n- âŒ `/api/get-all-products`\n\n### HTTP Methods\n\n| Method | Purpose | Example |\n|--------|---------|---------|\n| GET | Retrieve resources | `GET /api/users` |\n| POST | Create resource | `POST /api/users` |\n| PUT | Replace resource | `PUT /api/users/:id` |\n| PATCH | Update fields | `PATCH /api/users/:id` |\n| DELETE | Delete resource | `DELETE /api/users/:id` |\n\n---\n\n## Standard Endpoints\n\n### List Resources\n\n```\nGET /api/users?page=1&limit=10&sort=name&order=asc\n```\n\n**Query Parameters:**\n- `page` (number) - Page number (default: 1)\n- `limit` (number) - Items per page (default: 10, max: 100)\n- `sort` (string) - Field to sort by\n- `order` (asc|desc) - Sort direction\n\n**Response:**\n```json\n{\n  \"data\": [\n    { \"id\": \"1\", \"name\": \"Alice\", \"email\": \"alice@example.com\" },\n    { \"id\": \"2\", \"name\": \"Bob\", \"email\": \"bob@example.com\" }\n  ],\n  \"pagination\": {\n    \"page\": 1,\n    \"limit\": 10,\n    \"total\": 42,\n    \"totalPages\": 5\n  }\n}\n```\n\n### Get Single Resource\n\n```\nGET /api/users/:id\n```\n\n**Response:**\n```json\n{\n  \"data\": {\n    \"id\": \"1\",\n    \"name\": \"Alice\",\n    \"email\": \"alice@example.com\",\n    \"createdAt\": \"2024-01-15T10:00:00Z\"\n  }\n}\n```\n\n### Create Resource\n\n```\nPOST /api/users\nContent-Type: application/json\n\n{\n  \"name\": \"Alice\",\n  \"email\": \"alice@example.com\"\n}\n```\n\n**Response (201 Created):**\n```json\n{\n  \"data\": {\n    \"id\": \"1\",\n    \"name\": \"Alice\",\n    \"email\": \"alice@example.com\",\n    \"createdAt\": \"2024-01-15T10:00:00Z\"\n  }\n}\n```\n\n### Update Resource\n\n```\nPATCH /api/users/:id\nContent-Type: application/json\n\n{\n  \"name\": \"Alice Smith\"\n}\n```\n\n**Response:**\n```json\n{\n  \"data\": {\n    \"id\": \"1\",\n    \"name\": \"Alice Smith\",\n    \"email\": \"alice@example.com\",\n    \"updatedAt\": \"2024-01-15T11:00:00Z\"\n  }\n}\n```\n\n### Delete Resource\n\n```\nDELETE /api/users/:id\n```\n\n**Response (204 No Content):**\nEmpty body\n\n---\n\n## Error Responses\n\n### Standard Error Format\n\n```json\n{\n  \"error\": {\n    \"code\": \"VALIDATION_ERROR\",\n    \"message\": \"Invalid request body\",\n    \"details\": [\n      {\n        \"field\": \"email\",\n        \"message\": \"Invalid email format\"\n      }\n    ]\n  }\n}\n```\n\n### HTTP Status Codes\n\n| Code | Meaning | Use Case |\n|------|---------|----------|\n| 200 | OK | Successful GET, PATCH, PUT |\n| 201 | Created | Successful POST |\n| 204 | No Content | Successful DELETE |\n| 400 | Bad Request | Validation error |\n| 401 | Unauthorized | Missing or invalid auth token |\n| 403 | Forbidden | Valid token but insufficient permissions |\n| 404 | Not Found | Resource doesn't exist |\n| 409 | Conflict | Duplicate resource (e.g., email already exists) |\n| 422 | Unprocessable Entity | Business logic error |\n| 429 | Too Many Requests | Rate limit exceeded |\n| 500 | Internal Server Error | Unexpected server error |\n\n### Error Code Examples\n\n```typescript\n// Validation error (400)\n{\n  \"error\": {\n    \"code\": \"VALIDATION_ERROR\",\n    \"message\": \"Invalid request body\",\n    \"details\": [\n      { \"field\": \"email\", \"message\": \"Invalid email format\" }\n    ]\n  }\n}\n\n// Unauthorized (401)\n{\n  \"error\": {\n    \"code\": \"UNAUTHORIZED\",\n    \"message\": \"Authentication required\"\n  }\n}\n\n// Forbidden (403)\n{\n  \"error\": {\n    \"code\": \"FORBIDDEN\",\n    \"message\": \"Insufficient permissions\"\n  }\n}\n\n// Not found (404)\n{\n  \"error\": {\n    \"code\": \"NOT_FOUND\",\n    \"message\": \"User not found\"\n  }\n}\n\n// Conflict (409)\n{\n  \"error\": {\n    \"code\": \"DUPLICATE_EMAIL\",\n    \"message\": \"Email already in use\"\n  }\n}\n\n// Server error (500)\n{\n  \"error\": {\n    \"code\": \"INTERNAL_ERROR\",\n    \"message\": \"An unexpected error occurred\"\n  }\n}\n```\n\n---\n\n## Input Validation with Zod\n\n### Define Schemas\n\n```typescript\nimport { z } from 'zod';\n\n// Create user schema\nexport const createUserSchema = z.object({\n  name: z.string().min(1).max(100),\n  email: z.string().email(),\n  role: z.enum(['USER', 'ADMIN']).default('USER'),\n});\n\n// Update user schema (all fields optional)\nexport const updateUserSchema = createUserSchema.partial();\n\n// Query parameters schema\nexport const listUsersQuerySchema = z.object({\n  page: z.coerce.number().int().positive().default(1),\n  limit: z.coerce.number().int().positive().max(100).default(10),\n  sort: z.enum(['name', 'createdAt']).default('createdAt'),\n  order: z.enum(['asc', 'desc']).default('desc'),\n});\n```\n\n### Validate in Route Handlers\n\n```typescript\n// Hono example\napp.post('/api/users', async (c) => {\n  try {\n    // Parse and validate request body\n    const body = await c.req.json();\n    const data = createUserSchema.parse(body);\n\n    // Create user\n    const user = await prisma.user.create({ data });\n\n    return c.json({ data: user }, 201);\n  } catch (error) {\n    if (error instanceof z.ZodError) {\n      return c.json({\n        error: {\n          code: 'VALIDATION_ERROR',\n          message: 'Invalid request body',\n          details: error.errors.map(e => ({\n            field: e.path.join('.'),\n            message: e.message,\n          })),\n        },\n      }, 400);\n    }\n    throw error;\n  }\n});\n```\n\n---\n\n## Authentication Strategy\n\n### JWT Authentication\n\n**Endpoints:**\n\n```\nPOST /api/auth/register     # Create account\nPOST /api/auth/login        # Get JWT token\nPOST /api/auth/refresh      # Refresh token\nGET  /api/auth/me           # Get current user (protected)\n```\n\n**Login Flow:**\n\n```typescript\n// POST /api/auth/login\n{\n  \"email\": \"alice@example.com\",\n  \"password\": \"secure123\"\n}\n\n// Response (200)\n{\n  \"data\": {\n    \"accessToken\": \"eyJhbGciOiJIUzI1NiIs...\",\n    \"refreshToken\": \"eyJhbGciOiJIUzI1NiIs...\",\n    \"expiresIn\": 3600,  // seconds\n    \"user\": {\n      \"id\": \"1\",\n      \"name\": \"Alice\",\n      \"email\": \"alice@example.com\"\n    }\n  }\n}\n```\n\n**Protected Endpoint:**\n\n```typescript\n// Middleware to verify JWT\nexport async function authMiddleware(c: Context, next: Next) {\n  const authHeader = c.req.header('Authorization');\n\n  if (!authHeader?.startsWith('Bearer ')) {\n    return c.json({\n      error: {\n        code: 'UNAUTHORIZED',\n        message: 'Authentication required',\n      },\n    }, 401);\n  }\n\n  const token = authHeader.substring(7);\n\n  try {\n    const payload = await verifyJWT(token);\n    c.set('userId', payload.userId);\n    await next();\n  } catch (error) {\n    return c.json({\n      error: {\n        code: 'INVALID_TOKEN',\n        message: 'Invalid or expired token',\n      },\n    }, 401);\n  }\n}\n\n// Use middleware\napp.get('/api/users/:id', authMiddleware, async (c) => {\n  const userId = c.get('userId');  // From middleware\n  const targetId = c.req.param('id');\n\n  // Check authorization\n  if (userId !== targetId) {\n    return c.json({\n      error: {\n        code: 'FORBIDDEN',\n        message: 'Cannot access other users',\n      },\n    }, 403);\n  }\n\n  // Fetch user...\n});\n```\n\n---\n\n## Authorization Patterns\n\n### Role-Based Access Control (RBAC)\n\n```typescript\n// Middleware for admin-only routes\nexport async function adminOnly(c: Context, next: Next) {\n  const userId = c.get('userId');\n\n  const user = await prisma.user.findUnique({\n    where: { id: userId },\n  });\n\n  if (user?.role !== 'ADMIN') {\n    return c.json({\n      error: {\n        code: 'FORBIDDEN',\n        message: 'Admin access required',\n      },\n    }, 403);\n  }\n\n  await next();\n}\n\n// Admin-only endpoint\napp.delete('/api/users/:id', authMiddleware, adminOnly, async (c) => {\n  // Delete user...\n});\n```\n\n### Resource Ownership\n\n```typescript\n// Ensure user owns the resource\napp.patch('/api/posts/:id', authMiddleware, async (c) => {\n  const userId = c.get('userId');\n  const postId = c.req.param('id');\n\n  const post = await prisma.post.findUnique({\n    where: { id: postId },\n  });\n\n  if (!post) {\n    return c.json({\n      error: { code: 'NOT_FOUND', message: 'Post not found' },\n    }, 404);\n  }\n\n  if (post.authorId !== userId) {\n    return c.json({\n      error: { code: 'FORBIDDEN', message: 'Not your post' },\n    }, 403);\n  }\n\n  // Update post...\n});\n```\n\n---\n\n## API Design Checklist\n\nBefore finalizing API design:\n\n### Endpoints\n- [ ] All CRUD operations defined for each resource\n- [ ] URLs use plural nouns\n- [ ] Nested resources use proper nesting\n- [ ] HTTP methods correct (GET, POST, PATCH, DELETE)\n\n### Request Validation\n- [ ] All inputs validated with Zod schemas\n- [ ] Query parameters validated\n- [ ] Path parameters validated\n- [ ] Request body validated\n\n### Response Format\n- [ ] Consistent response structure (`{ data: ... }`)\n- [ ] List endpoints include pagination\n- [ ] Error responses follow standard format\n- [ ] Proper HTTP status codes\n\n### Authentication\n- [ ] Auth strategy defined (JWT, session, OAuth)\n- [ ] Protected endpoints identified\n- [ ] Public endpoints identified\n- [ ] Token refresh strategy (if JWT)\n\n### Authorization\n- [ ] User can only access their own data\n- [ ] Admin-only endpoints protected\n- [ ] Resource ownership checked\n\n### Error Handling\n- [ ] Validation errors return 400\n- [ ] Auth errors return 401 or 403\n- [ ] Not found errors return 404\n- [ ] Server errors return 500\n- [ ] Error messages don't leak sensitive info\n\n---\n\n## Documentation Template\n\nSave API documentation to `api/design.md`:\n\n```markdown\n# API Design\n\n## Base URL\n\n\\`\\`\\`\nhttp://localhost:3000/api/v1\n\\`\\`\\`\n\n## Authentication\n\nAll protected endpoints require a JWT token in the Authorization header:\n\n\\`\\`\\`\nAuthorization: Bearer <token>\n\\`\\`\\`\n\n## Endpoints\n\n### Authentication\n\n#### Register\n\\`\\`\\`\nPOST /auth/register\n\\`\\`\\`\n\n**Request Body:**\n\\`\\`\\`json\n{\n  \"name\": \"Alice\",\n  \"email\": \"alice@example.com\",\n  \"password\": \"secure123\"\n}\n\\`\\`\\`\n\n**Response (201):**\n[Example response...]\n\n#### Login\n\\`\\`\\`\nPOST /auth/login\n\\`\\`\\`\n\n[Continue for each endpoint...]\n\n### Users\n\n#### List Users\n\\`\\`\\`\nGET /users?page=1&limit=10\n\\`\\`\\`\n\n**Auth:** Required\n**Query Params:**\n- \\`page\\` (number, default: 1)\n- \\`limit\\` (number, default: 10, max: 100)\n\n**Response (200):**\n[Example response...]\n\n[Continue for each resource...]\n\n## Error Responses\n\n[Document error format and codes...]\n```\n\n---\n\n## Version History\n\n**v1.0** (2024-12-13)\n- Initial skill for appgen plugin\n- REST API design principles\n- Input validation with Zod\n- Authentication strategies\n- Authorization patterns\n- Error handling standards\n",
        "plugins/appgen/skills/asset-management/skill.md": "---\nname: asset-management\ndescription: Extract, catalog, and propagate reference assets (screenshots, designs) throughout the webgen workflow\nversion: \"1.0\"\n---\n\n# Asset Management Skill\n\n**Purpose:** Detect, extract, catalog, and propagate reference assets (screenshots, UI mockups, design files) provided by users throughout the entire webgen workflow, ensuring all implementation agents have access to visual references.\n\n## Problem Solved\n\n**Before:** Users provide screenshots or design references in the initial prompt, but these assets:\n- Are not cataloged or tracked\n- Don't reach architecture/implementation agents\n- Get lost in the workflow\n- Result in implementations that don't match the reference\n\n**After:** Assets are extracted, cataloged, and made available to every phase of the workflow.\n\n---\n\n## Asset Catalog Structure\n\n### Directory Layout\n\n```\n.webgen/\nâ”œâ”€â”€ assets/\nâ”‚   â”œâ”€â”€ catalog.json           # Asset manifest with metadata\nâ”‚   â”œâ”€â”€ screenshots/           # UI reference screenshots\nâ”‚   â”œâ”€â”€ designs/              # Design files (Figma, Sketch exports)\nâ”‚   â”œâ”€â”€ references/           # Other reference materials\nâ”‚   â””â”€â”€ README.md             # Asset usage instructions\n```\n\n### Catalog Schema (catalog.json)\n\n```json\n{\n  \"version\": \"1.0\",\n  \"created\": \"2024-12-13T10:00:00Z\",\n  \"updated\": \"2024-12-13T10:00:00Z\",\n  \"projectSlug\": \"example-project\",\n  \"assets\": [\n    {\n      \"id\": \"asset-1\",\n      \"type\": \"screenshot\",\n      \"originalName\": \"hero-reference.png\",\n      \"path\": \".webgen/assets/screenshots/hero-reference.png\",\n      \"description\": \"Hero section layout with gradient background\",\n      \"source\": \"user-prompt\",\n      \"usedIn\": [\"architecture\", \"implementation\"],\n      \"tags\": [\"hero\", \"layout\", \"gradient\"],\n      \"metadata\": {\n        \"width\": 1920,\n        \"height\": 1080,\n        \"format\": \"png\"\n      }\n    }\n  ]\n}\n```\n\n**Field Definitions:**\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `id` | string | Unique identifier (asset-1, asset-2, etc.) |\n| `type` | string | Asset type: screenshot, design, reference, mockup |\n| `originalName` | string | Original filename from user |\n| `path` | string | Relative path within project |\n| `description` | string | What the asset shows/represents |\n| `source` | string | Where it came from: user-prompt, research, generated |\n| `usedIn` | array | Which phases need this: requirements, architecture, implementation, etc. |\n| `tags` | array | Searchable tags: hero, navigation, footer, layout, color-scheme |\n| `metadata` | object | Additional info: dimensions, format, color palette |\n\n---\n\n## Workflow Integration\n\n### Phase 1: Requirements (Asset Extraction)\n\n**When:** User provides `/webgen` command with description\n\n**Action:** Detect and extract assets from the prompt context\n\n**Detection Logic:**\n```javascript\n// Pseudo-code for asset detection\nfunction detectAssets(prompt, attachments) {\n  const assets = [];\n\n  // Check for explicit asset references\n  if (prompt.includes(\"screenshot\") || prompt.includes(\"reference image\")) {\n    // Asset mentioned\n  }\n\n  // Check for file attachments (Claude Code provides these)\n  if (attachments && attachments.length > 0) {\n    attachments.forEach(file => {\n      if (isImageFile(file)) {\n        assets.push(createAssetEntry(file));\n      }\n    });\n  }\n\n  // Check shared screenshots location\n  const screenshotsDir = \"~/workspace/screenshots/\";\n  // Look for recently added files if user mentioned them\n\n  return assets;\n}\n```\n\n**Extraction Process:**\n1. Scan prompt for asset references\n2. Check for file attachments in Claude Code context\n3. Check `~/workspace/screenshots/` if user mentioned screenshots\n4. Copy assets to `.webgen/assets/{type}/`\n5. Generate catalog.json entries\n6. Add to orchestrator context for handoff\n\n### Phase 2: Research (Asset Awareness)\n\n**When:** Orchestrator dispatches @webgen for competitive research\n\n**Action:** Make researcher aware of provided assets\n\n**Handoff Context:**\n```markdown\n## Reference Assets Provided\n\nThe following assets were provided for this project:\n- **asset-1**: Hero section reference (path: .webgen/assets/screenshots/hero-reference.png)\n  - Use to understand desired layout and visual style\n  - Tags: hero, layout, gradient\n\nAnalyze these assets to inform your competitive research and recommendations.\n```\n\n### Phase 3: Architecture (Asset-Driven Decisions)\n\n**When:** Orchestrator dispatches @webgen for project scaffolding\n\n**Action:** Include asset context in architecture decisions\n\n**Handoff Context:**\n```markdown\n## Architecture Context - Reference Assets\n\nThe following reference assets are available:\n{{#each assets}}\n- **{{id}}**: {{description}}\n  - Path: {{path}}\n  - Type: {{type}}\n  - Relevant for: {{usedIn}}\n{{/each}}\n\n**Architecture Guidance:**\n- Review reference assets to inform component structure\n- Identify components needed based on visual references\n- Consider layout patterns shown in screenshots\n```\n\n### Phase 4: Implementation (Direct Asset Access)\n\n**When:** Orchestrator dispatches @webgen for code generation\n\n**Action:** Provide direct asset references to implementation agents\n\n**Handoff Context:**\n```markdown\n## Implementation Assets - CRITICAL\n\nYou have access to the following reference assets. **Read and analyze these BEFORE implementing:**\n\n{{#each assets where usedIn includes \"implementation\"}}\n### {{id}}: {{description}}\n- **Path:** {{path}}\n- **Use for:** {{usedIn}}\n- **Tags:** {{tags}}\n\n**MANDATORY:** Use the Read tool to view this asset before implementing related components.\n```\n\n**Read Command Example:**\n```bash\n# Agent should execute:\nRead(.webgen/assets/screenshots/hero-reference.png)\n# This provides visual context for pixel-perfect implementation\n```\n\n### Phase 5: Final (Asset Documentation)\n\n**When:** Final documentation generation\n\n**Action:** Document assets used in the project\n\n**Generated Section (docs/assets.md):**\n```markdown\n# Reference Assets\n\nThis project was generated using the following reference assets:\n\n## Screenshots\n- **hero-reference.png**: Hero section layout reference\n  - Source: User-provided\n  - Used for: Hero component design and layout\n\n## Usage\nAll reference assets are stored in `.webgen/assets/` for future reference.\n```\n\n---\n\n## API: Asset Functions\n\n### extractAssets(prompt, attachments)\n\n**Purpose:** Extract assets from user input and attachments\n\n**Returns:** Array of asset objects\n\n```javascript\n{\n  id: \"asset-1\",\n  type: \"screenshot\",\n  originalName: \"ui-reference.png\",\n  tempPath: \"/tmp/asset-1.png\",  // Before copying to project\n  description: \"Auto-detected from user prompt\",\n  tags: []\n}\n```\n\n### createCatalog(projectPath, assets)\n\n**Purpose:** Initialize asset catalog in project\n\n**Actions:**\n1. Create `.webgen/assets/` directory structure\n2. Copy assets from temp location to project\n3. Generate `catalog.json` with metadata\n4. Create `README.md` with usage instructions\n\n**Returns:** Path to catalog.json\n\n### loadCatalog(projectPath)\n\n**Purpose:** Load existing catalog for a project\n\n**Returns:** Catalog object with assets array\n\n### addAsset(catalogPath, assetData)\n\n**Purpose:** Add new asset to existing catalog (e.g., from research phase)\n\n**Updates:** catalog.json with new entry and updated timestamp\n\n### getAssetsForPhase(catalogPath, phaseName)\n\n**Purpose:** Filter assets relevant for specific phase\n\n**Returns:** Subset of assets where `usedIn` includes phaseName\n\n---\n\n## Asset Type Detection\n\n### Image Assets\n\n**Extensions:** .png, .jpg, .jpeg, .gif, .webp, .svg\n\n**Analysis:**\n- Extract dimensions\n- Detect primary colors (for color palette inference)\n- Identify UI sections (hero, navigation, footer)\n\n### Design Files\n\n**Extensions:** .fig (Figma export), .sketch (Sketch export), .xd (Adobe XD)\n\n**Note:** These are typically exported as images or PDFs for webgen processing\n\n### Reference Documents\n\n**Extensions:** .pdf (brand guidelines, wireframes)\n\n**Processing:** Extract relevant pages as images if needed\n\n---\n\n## Asset Propagation Protocol\n\n### Orchestrator Responsibility\n\nThe **@webgen-orchestrator** must:\n\n1. **Phase 1 (Requirements):** Invoke asset extraction\n   ```markdown\n   @webgen: Extract any reference assets from the user prompt.\n   Use the asset-management skill to create catalog.\n   ```\n\n2. **Phase 2+ (All subsequent phases):** Include asset context in dispatch\n   ```markdown\n   @webgen: Proceeding to [PHASE].\n\n   **Reference Assets Available:**\n   - Review catalog at .webgen/assets/catalog.json\n   - Read assets before implementing related components\n\n   Load catalog using asset-management skill for full context.\n   ```\n\n3. **Handoff verification:** Ensure catalog.json exists before proceeding to implementation\n\n### Agent Responsibility\n\nEach **@webgen** agent invocation must:\n\n1. **Load catalog** at phase start\n2. **Read relevant assets** for the current phase\n3. **Reference assets** in implementation decisions\n4. **Update catalog** if new assets discovered (e.g., from research)\n\n---\n\n## Example Workflow\n\n### User Provides Screenshot\n\n```\nUser: /webgen restaurant landing page. I want it to look like this:\n[Attaches: hero-reference.png]\n\nDescription: Modern hero section with large food image and reservation button\n```\n\n### Phase 1: Asset Extraction\n\n```\n@webgen (Requirements phase):\n1. Detect attachment: hero-reference.png\n2. Create .webgen/assets/screenshots/hero-reference.png\n3. Generate catalog.json:\n   {\n     \"assets\": [{\n       \"id\": \"asset-1\",\n       \"type\": \"screenshot\",\n       \"path\": \".webgen/assets/screenshots/hero-reference.png\",\n       \"description\": \"Hero section reference - large food image with reservation button\",\n       \"usedIn\": [\"architecture\", \"implementation\"],\n       \"tags\": [\"hero\", \"food-image\", \"cta-button\"]\n     }]\n   }\n4. Report to orchestrator: \"Asset catalog created with 1 screenshot\"\n```\n\n### Phase 3: Architecture\n\n```\n@webgen (Architecture phase):\n1. Load catalog.json\n2. Read asset-1 to understand layout requirements\n3. Identify components needed: Hero (with image background), CTAButton\n4. Include in architecture report: \"Hero component based on asset-1 reference\"\n```\n\n### Phase 4: Implementation\n\n```\n@webgen (Implementation phase):\n1. Load catalog.json\n2. Read .webgen/assets/screenshots/hero-reference.png\n3. Analyze:\n   - Image fills full viewport height\n   - Text overlays image with dark gradient\n   - CTA button prominent, centered\n   - Color scheme: warm tones (extracted from image)\n4. Implement Hero component matching reference\n5. Document: \"Hero section implements layout from asset-1\"\n```\n\n---\n\n## Fallbacks and Edge Cases\n\n### No Assets Provided\n\n**Behavior:** Skip asset extraction, proceed normally\n**Catalog:** Create empty catalog.json for consistency\n\n```json\n{\n  \"version\": \"1.0\",\n  \"assets\": []\n}\n```\n\n### Assets Mentioned But Not Attached\n\n**Behavior:** Prompt user to provide the asset\n\n```markdown\nYou mentioned a screenshot/reference but I don't see an attachment.\nPlease provide the file, or I can proceed without it using competitive research for design inspiration.\n```\n\n### Asset Not Readable\n\n**Behavior:** Log error, continue without asset\n\n```markdown\nâš ï¸ Warning: Could not read asset-1 (hero-reference.png).\nProceeding with competitive research for design guidance instead.\n```\n\n### Large Asset Files\n\n**Threshold:** > 10MB\n\n**Behavior:** Store reference in catalog but don't inline in prompts\n\n```markdown\nAsset-2 (design-mockup.pdf) is large (15MB).\nStored in catalog for manual reference, but not loaded automatically.\n```\n\n---\n\n## Success Criteria\n\nAsset management is successful when:\n\n- [ ] Assets detected from user prompt/attachments\n- [ ] Catalog created at `.webgen/assets/catalog.json`\n- [ ] Assets copied to appropriate subdirectories\n- [ ] Orchestrator includes assets in phase handoffs\n- [ ] Architecture agent reviews assets before scaffolding\n- [ ] Implementation agents read assets before coding\n- [ ] Final documentation includes asset references\n- [ ] Asset-driven decisions documented\n\n---\n\n## Integration Checklist\n\nTo integrate asset management into webgen:\n\n### Skill Files\n- [x] `skills/asset-management/skill.md` (this file)\n\n### Agent Updates\n- [ ] `agents/webgen.md` - Add Phase 1 asset extraction\n- [ ] `agents/webgen-orchestrator.md` - Add asset propagation\n\n### Command Updates\n- [ ] `commands/webgen.md` - Mention asset support in docs\n\n### Documentation\n- [ ] `README.md` - Add asset management to features\n- [ ] `docs/ARCHITECTURE.md` - Document asset flow\n\n---\n\n## Future Enhancements\n\n1. **Automatic Color Extraction:** Analyze screenshots to extract color palette\n2. **Component Detection:** Use AI to identify components in screenshots (hero, nav, footer)\n3. **Figma Integration:** Direct import from Figma URLs\n4. **Asset Versioning:** Track asset changes across iterations\n5. **Multi-Asset Comparison:** Compare multiple reference screenshots\n\n---\n\n**Version:** 1.0\n**Created:** 2024-12-13\n**Requires:** webgen v1.4+\n",
        "plugins/appgen/skills/auth-integration/skill.md": "---\ntitle: Auth Integration Skill\ntype: skill\ncreated: 2024-12-13\ntags: [appgen, auth, authentication, jwt, nextauth]\n---\n\n# Auth Integration Skill\n\nProvides guidance for integrating authentication into full-stack applications.\n\n## Purpose\n\nThis skill helps the appgen agent integrate authentication providers (Auth.js, Clerk, Lucia) into applications.\n\n---\n\n## Authentication Options\n\n### 1. Auth.js (NextAuth) - Next.js Apps\n\n**Best for:** Next.js applications with email/password or OAuth\n\n**Features:**\n- Built-in OAuth providers (Google, GitHub, etc.)\n- Email/password authentication\n- Session management\n- Database adapters (Prisma, Drizzle)\n\n**Installation:**\n```bash\nnpm install next-auth @auth/prisma-adapter\n```\n\n### 2. Clerk - Hosted Auth\n\n**Best for:** Quick setup, modern UI, managed auth\n\n**Features:**\n- Hosted UI components\n- OAuth providers\n- User management dashboard\n- Email verification\n- Multi-factor authentication\n\n**Installation:**\n```bash\nnpm install @clerk/nextjs\n```\n\n### 3. Lucia - Lightweight Custom\n\n**Best for:** API-only apps, full control, minimal dependencies\n\n**Features:**\n- Framework-agnostic\n- Session-based or token-based\n- Full control over auth flow\n- Works with any database\n\n**Installation:**\n```bash\nnpm install lucia @lucia-auth/adapter-prisma\n```\n\n---\n\n## Auth.js (NextAuth) Setup\n\n### Step 1: Install Dependencies\n\n```bash\nnpm install next-auth @auth/prisma-adapter\nnpm install bcryptjs\nnpm install -D @types/bcryptjs\n```\n\n### Step 2: Prisma Schema\n\n```prisma\nmodel User {\n  id            String    @id @default(cuid())\n  name          String?\n  email         String    @unique\n  emailVerified DateTime?\n  image         String?\n  passwordHash  String?\n  createdAt     DateTime  @default(now())\n  updatedAt     DateTime  @updatedAt\n\n  accounts Account[]\n  sessions Session[]\n\n  @@index([email])\n}\n\nmodel Account {\n  id                String  @id @default(cuid())\n  userId            String\n  type              String\n  provider          String\n  providerAccountId String\n  refresh_token     String?\n  access_token      String?\n  expires_at        Int?\n  token_type        String?\n  scope             String?\n  id_token          String?\n  session_state     String?\n\n  user User @relation(fields: [userId], references: [id], onDelete: Cascade)\n\n  @@unique([provider, providerAccountId])\n  @@index([userId])\n}\n\nmodel Session {\n  id           String   @id @default(cuid())\n  sessionToken String   @unique\n  userId       String\n  expires      DateTime\n  user         User     @relation(fields: [userId], references: [id], onDelete: Cascade)\n\n  @@index([userId])\n}\n\nmodel VerificationToken {\n  identifier String\n  token      String   @unique\n  expires    DateTime\n\n  @@unique([identifier, token])\n}\n```\n\n### Step 3: Auth Configuration\n\nCreate `lib/auth.ts`:\n\n```typescript\nimport { NextAuthOptions } from 'next-auth';\nimport { PrismaAdapter } from '@auth/prisma-adapter';\nimport CredentialsProvider from 'next-auth/providers/credentials';\nimport GoogleProvider from 'next-auth/providers/google';\nimport { prisma } from '@/lib/db';\nimport bcrypt from 'bcryptjs';\nimport { z } from 'zod';\n\nconst credentialsSchema = z.object({\n  email: z.string().email(),\n  password: z.string().min(8),\n});\n\nexport const authOptions: NextAuthOptions = {\n  adapter: PrismaAdapter(prisma),\n  providers: [\n    GoogleProvider({\n      clientId: process.env.GOOGLE_CLIENT_ID!,\n      clientSecret: process.env.GOOGLE_CLIENT_SECRET!,\n    }),\n    CredentialsProvider({\n      name: 'credentials',\n      credentials: {\n        email: { label: 'Email', type: 'email' },\n        password: { label: 'Password', type: 'password' },\n      },\n      async authorize(credentials) {\n        if (!credentials?.email || !credentials?.password) {\n          throw new Error('Invalid credentials');\n        }\n\n        const { email, password } = credentialsSchema.parse(credentials);\n\n        const user = await prisma.user.findUnique({\n          where: { email },\n        });\n\n        if (!user || !user.passwordHash) {\n          throw new Error('Invalid credentials');\n        }\n\n        const isValidPassword = await bcrypt.compare(\n          password,\n          user.passwordHash\n        );\n\n        if (!isValidPassword) {\n          throw new Error('Invalid credentials');\n        }\n\n        return {\n          id: user.id,\n          email: user.email,\n          name: user.name,\n        };\n      },\n    }),\n  ],\n  session: {\n    strategy: 'jwt',\n  },\n  pages: {\n    signIn: '/login',\n    signOut: '/logout',\n    error: '/error',\n  },\n  callbacks: {\n    async jwt({ token, user }) {\n      if (user) {\n        token.id = user.id;\n      }\n      return token;\n    },\n    async session({ session, token }) {\n      if (session.user) {\n        session.user.id = token.id as string;\n      }\n      return session;\n    },\n  },\n};\n```\n\n### Step 4: API Route\n\nCreate `app/api/auth/[...nextauth]/route.ts`:\n\n```typescript\nimport NextAuth from 'next-auth';\nimport { authOptions } from '@/lib/auth';\n\nconst handler = NextAuth(authOptions);\n\nexport { handler as GET, handler as POST };\n```\n\n### Step 5: Auth Provider\n\nCreate `components/providers/auth-provider.tsx`:\n\n```typescript\n'use client';\n\nimport { SessionProvider } from 'next-auth/react';\n\nexport function AuthProvider({ children }: { children: React.ReactNode }) {\n  return <SessionProvider>{children}</SessionProvider>;\n}\n```\n\nWrap app in `app/layout.tsx`:\n\n```typescript\nimport { AuthProvider } from '@/components/providers/auth-provider';\n\nexport default function RootLayout({ children }) {\n  return (\n    <html>\n      <body>\n        <AuthProvider>{children}</AuthProvider>\n      </body>\n    </html>\n  );\n}\n```\n\n### Step 6: Protected Routes\n\nCreate middleware (`middleware.ts`):\n\n```typescript\nimport { withAuth } from 'next-auth/middleware';\n\nexport default withAuth({\n  pages: {\n    signIn: '/login',\n  },\n});\n\nexport const config = {\n  matcher: ['/dashboard/:path*', '/api/users/:path*'],\n};\n```\n\n### Step 7: Use in Components\n\n```typescript\n'use client';\n\nimport { useSession, signIn, signOut } from 'next-auth/react';\n\nexport function UserButton() {\n  const { data: session, status } = useSession();\n\n  if (status === 'loading') {\n    return <div>Loading...</div>;\n  }\n\n  if (!session) {\n    return <button onClick={() => signIn()}>Sign In</button>;\n  }\n\n  return (\n    <div>\n      <p>Signed in as {session.user.email}</p>\n      <button onClick={() => signOut()}>Sign Out</button>\n    </div>\n  );\n}\n```\n\n### Step 8: Server-Side Auth\n\n```typescript\nimport { getServerSession } from 'next-auth';\nimport { authOptions } from '@/lib/auth';\n\nexport async function GET() {\n  const session = await getServerSession(authOptions);\n\n  if (!session) {\n    return new Response('Unauthorized', { status: 401 });\n  }\n\n  // Use session.user.id...\n}\n```\n\n---\n\n## Lucia Setup (API-Only)\n\n### Step 1: Install Dependencies\n\n```bash\nnpm install lucia @lucia-auth/adapter-prisma\nnpm install bcryptjs\nnpm install -D @types/bcryptjs\n```\n\n### Step 2: Prisma Schema\n\n```prisma\nmodel User {\n  id           String    @id @default(cuid())\n  email        String    @unique\n  passwordHash String\n  createdAt    DateTime  @default(now())\n  updatedAt    DateTime  @updatedAt\n\n  sessions Session[]\n\n  @@index([email])\n}\n\nmodel Session {\n  id        String   @id @default(cuid())\n  userId    String\n  expiresAt DateTime\n  user      User     @relation(fields: [userId], references: [id], onDelete: Cascade)\n\n  @@index([userId])\n}\n```\n\n### Step 3: Lucia Configuration\n\nCreate `lib/auth.ts`:\n\n```typescript\nimport { Lucia } from 'lucia';\nimport { PrismaAdapter } from '@lucia-auth/adapter-prisma';\nimport { prisma } from './db';\n\nconst adapter = new PrismaAdapter(prisma.session, prisma.user);\n\nexport const lucia = new Lucia(adapter, {\n  sessionCookie: {\n    attributes: {\n      secure: process.env.NODE_ENV === 'production',\n    },\n  },\n  getUserAttributes: (attributes) => {\n    return {\n      email: attributes.email,\n    };\n  },\n});\n\ndeclare module 'lucia' {\n  interface Register {\n    Lucia: typeof lucia;\n    DatabaseUserAttributes: {\n      email: string;\n    };\n  }\n}\n```\n\n### Step 4: Register Endpoint\n\n```typescript\nimport { lucia } from '@/lib/auth';\nimport { prisma } from '@/lib/db';\nimport bcrypt from 'bcryptjs';\nimport { z } from 'zod';\n\nconst registerSchema = z.object({\n  email: z.string().email(),\n  password: z.string().min(8),\n});\n\napp.post('/api/auth/register', async (c) => {\n  try {\n    const body = await c.req.json();\n    const { email, password } = registerSchema.parse(body);\n\n    const passwordHash = await bcrypt.hash(password, 10);\n\n    const user = await prisma.user.create({\n      data: { email, passwordHash },\n    });\n\n    const session = await lucia.createSession(user.id, {});\n    const sessionCookie = lucia.createSessionCookie(session.id);\n\n    c.header('Set-Cookie', sessionCookie.serialize());\n\n    return c.json({ data: { userId: user.id } }, 201);\n  } catch (error) {\n    // Handle errors...\n  }\n});\n```\n\n### Step 5: Login Endpoint\n\n```typescript\napp.post('/api/auth/login', async (c) => {\n  try {\n    const body = await c.req.json();\n    const { email, password } = registerSchema.parse(body);\n\n    const user = await prisma.user.findUnique({ where: { email } });\n\n    if (!user) {\n      return c.json({\n        error: { code: 'INVALID_CREDENTIALS', message: 'Invalid email or password' },\n      }, 401);\n    }\n\n    const validPassword = await bcrypt.compare(password, user.passwordHash);\n\n    if (!validPassword) {\n      return c.json({\n        error: { code: 'INVALID_CREDENTIALS', message: 'Invalid email or password' },\n      }, 401);\n    }\n\n    const session = await lucia.createSession(user.id, {});\n    const sessionCookie = lucia.createSessionCookie(session.id);\n\n    c.header('Set-Cookie', sessionCookie.serialize());\n\n    return c.json({ data: { userId: user.id } });\n  } catch (error) {\n    // Handle errors...\n  }\n});\n```\n\n### Step 6: Auth Middleware\n\n```typescript\nimport { lucia } from '@/lib/auth';\n\nexport async function authMiddleware(c: Context, next: Next) {\n  const sessionId = getCookie(c, lucia.sessionCookieName);\n\n  if (!sessionId) {\n    return c.json({\n      error: { code: 'UNAUTHORIZED', message: 'Authentication required' },\n    }, 401);\n  }\n\n  const { session, user } = await lucia.validateSession(sessionId);\n\n  if (!session) {\n    return c.json({\n      error: { code: 'INVALID_SESSION', message: 'Invalid or expired session' },\n    }, 401);\n  }\n\n  c.set('user', user);\n  c.set('session', session);\n\n  await next();\n}\n```\n\n---\n\n## Environment Variables\n\nAdd to `.env.example`:\n\n**Auth.js:**\n```env\nNEXTAUTH_URL=\"http://localhost:3000\"\nNEXTAUTH_SECRET=\"your-secret-here\"  # Generate with: openssl rand -base64 32\n\n# OAuth (if using)\nGOOGLE_CLIENT_ID=\"your-google-client-id\"\nGOOGLE_CLIENT_SECRET=\"your-google-client-secret\"\n```\n\n**Lucia:**\n```env\n# Session secret\nSESSION_SECRET=\"your-secret-here\"\n```\n\n---\n\n## Security Checklist\n\n- [ ] Passwords hashed with bcrypt (cost factor 10+)\n- [ ] Session secrets in environment variables\n- [ ] HTTPS enforced in production\n- [ ] JWT secrets strong and random\n- [ ] Password minimum length 8 characters\n- [ ] Rate limiting on auth endpoints\n- [ ] Email verification implemented (if needed)\n- [ ] Session expiration configured\n- [ ] Secure cookie flags set (httpOnly, secure, sameSite)\n\n---\n\n## Version History\n\n**v1.0** (2024-12-13)\n- Initial skill for appgen plugin\n- Auth.js (NextAuth) setup guide\n- Lucia setup guide\n- Security best practices\n",
        "plugins/appgen/skills/database-design/skill.md": "---\ntitle: Database Design Skill\ntype: skill\ncreated: 2024-12-13\ntags: [appgen, database, prisma, drizzle, schema]\n---\n\n# Database Design Skill\n\nProvides guidance for designing database schemas for full-stack applications.\n\n## Purpose\n\nThis skill helps the appgen agent design sound database schemas with proper relationships, types, constraints, and indexes.\n\n---\n\n## Schema Design Process\n\n### 1. Entity Identification\n\nExtract entities from requirements:\n\n**Example Requirement:** \"Inventory management system for a warehouse\"\n\n**Entities:**\n- User (warehouse staff)\n- Product (items in inventory)\n- Category (product categories)\n- Location (warehouse locations)\n- InventoryTransaction (stock movements)\n\n### 2. Attribute Definition\n\nFor each entity, define:\n- **ID:** Primary key (usually String cuid() or Int autoincrement())\n- **Required fields:** Cannot be null\n- **Optional fields:** Can be null (marked with `?`)\n- **Timestamps:** createdAt, updatedAt\n- **Constraints:** Unique, default values\n\n**Example:**\n```prisma\nmodel Product {\n  id          String   @id @default(cuid())\n  name        String\n  sku         String   @unique\n  description String?\n  quantity    Int      @default(0)\n  categoryId  String\n  createdAt   DateTime @default(now())\n  updatedAt   DateTime @updatedAt\n}\n```\n\n### 3. Relationship Mapping\n\nIdentify relationships:\n\n**One-to-Many:**\n- One Category has many Products\n- One User has many InventoryTransactions\n\n**Many-to-Many:**\n- Products can be in multiple Locations\n- Locations can have multiple Products\n\n**Prisma Syntax:**\n\n**One-to-Many:**\n```prisma\nmodel Category {\n  id       String    @id @default(cuid())\n  name     String\n  products Product[]  // Array on \"many\" side\n}\n\nmodel Product {\n  id         String   @id @default(cuid())\n  categoryId String\n  category   Category @relation(fields: [categoryId], references: [id])\n}\n```\n\n**Many-to-Many (Explicit Join Table):**\n```prisma\nmodel Product {\n  id        String            @id @default(cuid())\n  locations ProductLocation[]\n}\n\nmodel Location {\n  id       String            @id @default(cuid())\n  products ProductLocation[]\n}\n\nmodel ProductLocation {\n  productId  String\n  locationId String\n  quantity   Int\n  product    Product  @relation(fields: [productId], references: [id])\n  location   Location @relation(fields: [locationId], references: [id])\n\n  @@id([productId, locationId])\n  @@index([productId])\n  @@index([locationId])\n}\n```\n\n### 4. Index Planning\n\nAdd indexes for:\n- Foreign keys (always)\n- Frequently queried columns\n- Unique constraints\n\n**Example:**\n```prisma\nmodel Product {\n  id         String   @id @default(cuid())\n  sku        String   @unique\n  categoryId String\n  category   Category @relation(fields: [categoryId], references: [id])\n\n  @@index([categoryId])  // Index on foreign key\n  @@index([sku])         // Index on frequently searched field\n}\n```\n\n---\n\n## Prisma Schema Reference\n\n### Data Types\n\n| Prisma Type | Database Type | Use Case |\n|-------------|---------------|----------|\n| `String` | VARCHAR | Text fields, IDs |\n| `Int` | INTEGER | Numbers, counts |\n| `BigInt` | BIGINT | Large numbers |\n| `Float` | DOUBLE | Decimals |\n| `Decimal` | DECIMAL | Money (precise) |\n| `Boolean` | BOOLEAN | True/false |\n| `DateTime` | TIMESTAMP | Dates and times |\n| `Json` | JSON | Unstructured data |\n\n### Attributes\n\n| Attribute | Purpose | Example |\n|-----------|---------|---------|\n| `@id` | Primary key | `id String @id` |\n| `@default()` | Default value | `@default(cuid())` |\n| `@unique` | Unique constraint | `email String @unique` |\n| `@updatedAt` | Auto-update timestamp | `updatedAt DateTime @updatedAt` |\n| `@relation()` | Foreign key | `@relation(fields: [userId], references: [id])` |\n| `@@index()` | Index | `@@index([email])` |\n| `@@unique()` | Composite unique | `@@unique([email, tenantId])` |\n\n### Default Functions\n\n| Function | Purpose | Example |\n|----------|---------|---------|\n| `cuid()` | Random ID (short) | `@default(cuid())` |\n| `uuid()` | Random ID (standard) | `@default(uuid())` |\n| `autoincrement()` | Auto-increment number | `@default(autoincrement())` |\n| `now()` | Current timestamp | `@default(now())` |\n\n---\n\n## Common Patterns\n\n### User Authentication\n\n```prisma\nmodel User {\n  id            String    @id @default(cuid())\n  email         String    @unique\n  passwordHash  String    // Use bcrypt or argon2\n  name          String?\n  emailVerified DateTime?\n  image         String?\n  createdAt     DateTime  @default(now())\n  updatedAt     DateTime  @updatedAt\n\n  sessions Session[]\n  accounts Account[]\n\n  @@index([email])\n}\n\nmodel Session {\n  id           String   @id @default(cuid())\n  sessionToken String   @unique\n  userId       String\n  expires      DateTime\n  user         User     @relation(fields: [userId], references: [id], onDelete: Cascade)\n\n  @@index([userId])\n}\n```\n\n### Multi-Tenancy\n\n```prisma\nmodel Tenant {\n  id    String @id @default(cuid())\n  name  String\n  users User[]\n}\n\nmodel User {\n  id       String @id @default(cuid())\n  email    String\n  tenantId String\n  tenant   Tenant @relation(fields: [tenantId], references: [id])\n\n  @@unique([email, tenantId])  // Email unique per tenant\n  @@index([tenantId])\n}\n```\n\n### Soft Deletes\n\n```prisma\nmodel Product {\n  id        String    @id @default(cuid())\n  name      String\n  deletedAt DateTime?  // Null = not deleted\n  createdAt DateTime  @default(now())\n  updatedAt DateTime  @updatedAt\n\n  @@index([deletedAt])\n}\n```\n\n### Audit Trail\n\n```prisma\nmodel Product {\n  id        String   @id @default(cuid())\n  name      String\n  createdBy String\n  updatedBy String?\n  createdAt DateTime @default(now())\n  updatedAt DateTime @updatedAt\n\n  creator User @relation(\"ProductCreator\", fields: [createdBy], references: [id])\n  updater User? @relation(\"ProductUpdater\", fields: [updatedBy], references: [id])\n\n  @@index([createdBy])\n  @@index([updatedBy])\n}\n```\n\n---\n\n## Schema Design Checklist\n\nBefore finalizing a schema:\n\n### Structure\n- [ ] All entities identified from requirements\n- [ ] All required fields present\n- [ ] Optional fields marked with `?`\n- [ ] Primary keys defined (`@id`)\n- [ ] Timestamps included (createdAt, updatedAt)\n\n### Relationships\n- [ ] All relationships identified\n- [ ] One-to-many use scalar field + relation field\n- [ ] Many-to-many use explicit join tables\n- [ ] Foreign key fields match referenced type\n- [ ] Cascade delete rules appropriate (`onDelete: Cascade`)\n\n### Constraints\n- [ ] Unique constraints on unique fields\n- [ ] Default values where appropriate\n- [ ] Enums for fixed sets of values\n\n### Indexes\n- [ ] Indexes on all foreign keys\n- [ ] Indexes on frequently queried fields\n- [ ] Composite indexes for multi-column queries\n\n### Security\n- [ ] No sensitive data in plain text\n- [ ] Password fields named `passwordHash` (not `password`)\n- [ ] Email verification fields if needed\n\n---\n\n## Migration Strategy\n\n### Initial Migration\n\n```bash\n# Generate Prisma client\nnpx prisma generate\n\n# Create initial migration\nnpx prisma migrate dev --name init\n\n# Apply migration\nnpx prisma migrate deploy\n```\n\n### Schema Changes\n\n1. Modify schema.prisma\n2. Run `npx prisma migrate dev --name description_of_change`\n3. Review generated migration file\n4. Test migration on development database\n\n### Seed Data\n\nCreate `prisma/seed.ts`:\n\n```typescript\nimport { PrismaClient } from '@prisma/client';\n\nconst prisma = new PrismaClient();\n\nasync function main() {\n  // Create seed data\n  const category = await prisma.category.create({\n    data: {\n      name: 'Electronics',\n    },\n  });\n\n  console.log({ category });\n}\n\nmain()\n  .catch((e) => {\n    console.error(e);\n    process.exit(1);\n  })\n  .finally(async () => {\n    await prisma.$disconnect();\n  });\n```\n\nAdd to package.json:\n```json\n{\n  \"prisma\": {\n    \"seed\": \"tsx prisma/seed.ts\"\n  }\n}\n```\n\n---\n\n## Drizzle Alternative\n\nIf using Drizzle instead of Prisma:\n\n```typescript\n// schema.ts\nimport { pgTable, text, timestamp, integer, index } from 'drizzle-orm/pg-core';\n\nexport const users = pgTable('users', {\n  id: text('id').primaryKey(),\n  email: text('email').notNull().unique(),\n  name: text('name'),\n  createdAt: timestamp('created_at').defaultNow(),\n  updatedAt: timestamp('updated_at').defaultNow(),\n}, (table) => ({\n  emailIdx: index('email_idx').on(table.email),\n}));\n\nexport const posts = pgTable('posts', {\n  id: text('id').primaryKey(),\n  title: text('title').notNull(),\n  content: text('content').notNull(),\n  authorId: text('author_id').notNull().references(() => users.id),\n  createdAt: timestamp('created_at').defaultNow(),\n}, (table) => ({\n  authorIdx: index('author_idx').on(table.authorId),\n}));\n```\n\n---\n\n## Documentation Template\n\nSave schema documentation to `database/schema.md`:\n\n```markdown\n# Database Schema\n\n## Overview\n\n[Brief description of the database purpose]\n\n## Entities\n\n### User\n\nRepresents warehouse staff members.\n\n**Fields:**\n- \\`id\\` (String) - Primary key\n- \\`email\\` (String) - Unique email address\n- \\`name\\` (String) - Full name\n- \\`role\\` (Enum) - USER | ADMIN\n- \\`createdAt\\` (DateTime) - Account creation date\n- \\`updatedAt\\` (DateTime) - Last update date\n\n**Relationships:**\n- Has many InventoryTransactions\n\n**Indexes:**\n- email\n\n### Product\n\nRepresents items in the warehouse inventory.\n\n[Continue for each entity...]\n\n## Relationships\n\n- User â†’ InventoryTransaction (one-to-many)\n- Category â†’ Product (one-to-many)\n- Product â†” Location (many-to-many via ProductLocation)\n\n## Migrations\n\n### Initial Schema (YYYY-MM-DD)\n\nCreated base schema with User, Product, Category, Location, InventoryTransaction entities.\n\n[Document each migration...]\n```\n\n---\n\n## Common Mistakes to Avoid\n\n1. **Missing indexes on foreign keys** - Always add `@@index([foreignKeyId])`\n2. **Array index as keys** - Use stable IDs for keys, not array positions\n3. **No cascade delete** - Decide if related records should be deleted\n4. **Missing timestamps** - Always include createdAt and updatedAt\n5. **Ambiguous relationship names** - Use clear names for self-relations\n6. **No unique constraints** - Add @unique on emails, SKUs, etc.\n7. **Wrong relationship type** - Many-to-many needs join table, not one-to-many\n\n---\n\n## Version History\n\n**v1.0** (2024-12-13)\n- Initial skill for appgen plugin\n- Prisma schema patterns\n- Drizzle alternative syntax\n- Migration strategies\n- Common patterns and checklist\n",
        "plugins/appgen/skills/project-scaffold/skill.md": "---\ntitle: Project Scaffold Skill\ntype: skill\ncreated: 2024-12-13\ntags: [appgen, scaffold, nextjs, api, setup]\n---\n\n# Project Scaffold Skill\n\nProvides setup scripts and guidance for scaffolding full-stack applications and APIs.\n\n## Purpose\n\nThis skill helps the appgen agent scaffold projects using the appropriate framework and structure based on the application type.\n\n## Application Types\n\n### 1. Full-Stack App (Next.js)\n\n**Use when:** Building complete web applications with frontend and backend.\n\n**Framework:** Next.js 15 (App Router)\n\n**Features:**\n- Server and Client Components\n- Built-in API routes\n- TypeScript\n- Tailwind CSS\n- Automatic code splitting\n\n**Script:** `./scripts/setup-nextjs-app.sh`\n\n**Usage:**\n```bash\n./setup-nextjs-app.sh \"project-name\" \"/output/path\"\n```\n\n### 2. API-Only\n\n**Use when:** Building backend services, REST APIs, GraphQL servers.\n\n**Framework Options:**\n- **Hono** - Ultrafast, edge-ready (recommended)\n- **Express** - Traditional, mature ecosystem\n- **Fastify** - High performance, schema validation\n\n**Features:**\n- TypeScript\n- Minimal dependencies\n- Fast startup\n- Easy to containerize\n\n**Script:** `./scripts/setup-api-only.sh`\n\n**Usage:**\n```bash\n./setup-api-only.sh \"project-name\" \"/output/path\" \"hono|express|fastify\"\n```\n\n### 3. Monorepo (Turborepo)\n\n**Use when:** Multiple apps/packages need to share code.\n\n**Framework:** Turborepo\n\n**Structure:**\n```\nmonorepo/\nâ”œâ”€â”€ apps/\nâ”‚   â”œâ”€â”€ web/          # Next.js app\nâ”‚   â””â”€â”€ api/          # Hono API\nâ”œâ”€â”€ packages/\nâ”‚   â”œâ”€â”€ database/     # Prisma schema + client\nâ”‚   â”œâ”€â”€ ui/           # Shared UI components\nâ”‚   â””â”€â”€ typescript-config/  # Shared tsconfig\nâ””â”€â”€ turbo.json\n```\n\n**Script:** `./scripts/setup-monorepo.sh`\n\n**Usage:**\n```bash\n./setup-monorepo.sh \"project-name\" \"/output/path\"\n```\n\n---\n\n## Decision Matrix\n\n| Requirement | Recommended Type |\n|-------------|------------------|\n| SaaS dashboard with UI | Full-Stack (Next.js) |\n| Admin panel | Full-Stack (Next.js) |\n| REST API for mobile app | API-Only (Hono) |\n| GraphQL server | API-Only (Express + Apollo) |\n| Microservices | API-Only (Hono or Fastify) |\n| Multiple frontends sharing API | Monorepo |\n| Mobile + Web sharing backend | Monorepo |\n\n---\n\n## Common Dependencies\n\n### Database & ORM\n\n**Prisma:**\n```bash\nnpm install prisma @prisma/client\nnpm install -D prisma\n```\n\n**Drizzle:**\n```bash\nnpm install drizzle-orm\nnpm install -D drizzle-kit\n```\n\n### Validation\n\n**Zod:**\n```bash\nnpm install zod\n```\n\n### Authentication\n\n**Auth.js (Next.js):**\n```bash\nnpm install next-auth\n```\n\n**Lucia (Universal):**\n```bash\nnpm install lucia @lucia-auth/adapter-prisma\n```\n\n### Testing\n\n**Vitest:**\n```bash\nnpm install -D vitest @vitest/ui\n```\n\n**Supertest (API testing):**\n```bash\nnpm install -D supertest @types/supertest\n```\n\n**Playwright (E2E):**\n```bash\nnpm install -D @playwright/test\n```\n\n---\n\n## Project Structure Conventions\n\n### Next.js App Router\n\n```\nproject-name/\nâ”œâ”€â”€ app/\nâ”‚   â”œâ”€â”€ (auth)/           # Auth pages (login, signup)\nâ”‚   â”œâ”€â”€ (dashboard)/      # Protected dashboard pages\nâ”‚   â”œâ”€â”€ api/              # API routes\nâ”‚   â””â”€â”€ layout.tsx        # Root layout\nâ”œâ”€â”€ components/\nâ”‚   â”œâ”€â”€ ui/               # shadcn/ui components\nâ”‚   â””â”€â”€ features/         # Feature components\nâ”œâ”€â”€ lib/\nâ”‚   â”œâ”€â”€ db.ts             # Database client\nâ”‚   â”œâ”€â”€ auth.ts           # Auth config\nâ”‚   â””â”€â”€ utils.ts          # Utilities\nâ”œâ”€â”€ prisma/\nâ”‚   â””â”€â”€ schema.prisma\nâ”œâ”€â”€ tests/\nâ”‚   â”œâ”€â”€ unit/\nâ”‚   â”œâ”€â”€ integration/\nâ”‚   â””â”€â”€ e2e/\nâ””â”€â”€ docs/\n```\n\n### API-Only (Hono)\n\n```\nproject-name/\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ routes/           # API route handlers\nâ”‚   â”‚   â”œâ”€â”€ users.ts\nâ”‚   â”‚   â””â”€â”€ posts.ts\nâ”‚   â”œâ”€â”€ services/         # Business logic\nâ”‚   â”œâ”€â”€ middleware/       # Auth, validation\nâ”‚   â”œâ”€â”€ types/            # TypeScript types\nâ”‚   â””â”€â”€ index.ts          # App entry\nâ”œâ”€â”€ prisma/\nâ”‚   â””â”€â”€ schema.prisma\nâ”œâ”€â”€ tests/\nâ”‚   â”œâ”€â”€ unit/\nâ”‚   â””â”€â”€ integration/\nâ””â”€â”€ docs/\n```\n\n### Monorepo\n\n```\nmonorepo/\nâ”œâ”€â”€ apps/\nâ”‚   â”œâ”€â”€ web/              # Next.js frontend\nâ”‚   â””â”€â”€ api/              # Hono backend\nâ”œâ”€â”€ packages/\nâ”‚   â”œâ”€â”€ database/         # Shared Prisma\nâ”‚   â”œâ”€â”€ ui/               # Shared components\nâ”‚   â”œâ”€â”€ typescript-config/\nâ”‚   â””â”€â”€ eslint-config/\nâ”œâ”€â”€ turbo.json\nâ””â”€â”€ package.json\n```\n\n---\n\n## Configuration Files\n\n### TypeScript (tsconfig.json)\n\n**Strict mode:**\n```json\n{\n  \"compilerOptions\": {\n    \"strict\": true,\n    \"noImplicitAny\": true,\n    \"strictNullChecks\": true,\n    \"noUnusedLocals\": true,\n    \"noUnusedParameters\": true\n  }\n}\n```\n\n### ESLint (.eslintrc.json)\n\n```json\n{\n  \"extends\": [\"next/core-web-vitals\", \"prettier\"],\n  \"rules\": {\n    \"@typescript-eslint/no-unused-vars\": \"error\",\n    \"@typescript-eslint/no-explicit-any\": \"warn\"\n  }\n}\n```\n\n### Prettier (.prettierrc)\n\n```json\n{\n  \"semi\": true,\n  \"singleQuote\": true,\n  \"tabWidth\": 2,\n  \"trailingComma\": \"es5\"\n}\n```\n\n---\n\n## Setup Script Requirements\n\nAll setup scripts must:\n1. Create project directory\n2. Initialize package.json\n3. Install dependencies\n4. Configure TypeScript (strict mode)\n5. Configure ESLint\n6. Configure Prettier\n7. Create .gitignore\n8. Create folder structure\n9. Create README.md with setup instructions\n\n---\n\n## Usage Examples\n\n### Example 1: Next.js SaaS App\n\n```bash\n# Scaffold Next.js app\ncd /path/to/appgen-projects\n./setup-nextjs-app.sh \"task-manager\" \".\"\n\n# Result:\n# - task-manager - appgen/\n# - Next.js 15 with App Router\n# - TypeScript configured\n# - Tailwind CSS\n# - Ready for database integration\n```\n\n### Example 2: Hono API\n\n```bash\n# Scaffold Hono API\ncd /path/to/appgen-projects\n./setup-api-only.sh \"blog-api\" \".\" \"hono\"\n\n# Result:\n# - blog-api - appgen/\n# - Hono framework\n# - TypeScript configured\n# - Basic route structure\n# - Ready for Prisma integration\n```\n\n### Example 3: Turborepo Monorepo\n\n```bash\n# Scaffold monorepo\ncd /path/to/appgen-projects\n./setup-monorepo.sh \"acme\" \".\"\n\n# Result:\n# - acme - appgen/\n# - Turborepo structure\n# - web app (Next.js)\n# - api app (Hono)\n# - Shared packages\n```\n\n---\n\n## Post-Scaffold Steps\n\nAfter running a scaffold script, the appgen agent should:\n\n1. **Verify infrastructure:**\n   ```bash\n   cd project-dir\n   npm install  # Should succeed\n   npm run dev  # Should start (if applicable)\n   ```\n\n2. **Add database:**\n   - Initialize Prisma or Drizzle\n   - Create schema.prisma\n   - Configure database connection\n\n3. **Add authentication:**\n   - Use auth-integration skill\n   - Install auth provider\n   - Configure middleware\n\n4. **Document architecture:**\n   - Create docs/architecture.md\n   - Document tech stack choices\n   - Document folder structure\n\n---\n\n## Troubleshooting\n\n### npm install fails\n\n**Symptoms:**\n- Network errors\n- Permission errors\n- Conflicting dependencies\n\n**Solutions:**\n1. Check internet connection\n2. Clear npm cache: `npm cache clean --force`\n3. Try with --legacy-peer-deps flag\n4. Check Node.js version (>=18.0.0)\n\n### Dev server won't start\n\n**Symptoms:**\n- Port already in use\n- Missing dependencies\n- Configuration errors\n\n**Solutions:**\n1. Kill process on port: `lsof -ti:3000 | xargs kill`\n2. Reinstall dependencies: `rm -rf node_modules && npm install`\n3. Check for syntax errors in config files\n\n---\n\n## Version History\n\n**v1.0** (2024-12-13)\n- Initial skill for appgen plugin\n- Setup scripts for Next.js, API-only, Monorepo\n- Project structure conventions\n- Configuration examples\n",
        "plugins/appgen/skills/taskflow-integration/skill.md": "---\nname: taskflow-integration\ndescription: Optional TaskFlow integration for AppGen projects\nversion: 1.0.0\n---\n\n# TaskFlow Integration Skill\n\n**Purpose:** Enable optional task management for AppGen projects when TaskFlow plugin is available.\n\n**Integration Type:** Non-breaking, opt-in\n\n---\n\n## Core Principle: Optional Enhancement\n\n**This skill provides TaskFlow integration WITHOUT breaking AppGen when TaskFlow is unavailable.**\n\n**Rules:**\n- âœ… Detect TaskFlow availability before offering integration\n- âœ… Gracefully degrade if TaskFlow not found\n- âœ… User can decline even if TaskFlow is available\n- âœ… NEVER error if TaskFlow missing\n- âœ… AppGen works identically with or without TaskFlow\n\n---\n\n## Detection Protocol\n\n### 1. Check TaskFlow Availability\n\n**At appgen session start**, check for TaskFlow:\n\n```bash\n# Method 1: Check for taskflow plugin directory\nif [ -d \"$HOME/.claude/plugins/local-plugins/taskflow\" ]; then\n  TASKFLOW_AVAILABLE=true\nelse\n  TASKFLOW_AVAILABLE=false\nfi\n\n# Method 2: Try to locate task command\nif command -v task-init &> /dev/null; then\n  TASKFLOW_AVAILABLE=true\nfi\n```\n\n**Store result** in session context:\n- `taskflow_available: true|false`\n- `taskflow_enabled: true|false` (user's choice)\n\n### 2. Offer Integration (If Available)\n\n**After requirements confirmed (Checkpoint 1):**\n\n```markdown\n## CHECKPOINT 1 COMPLETE\n\n**Project:** {project-name}\n**Type:** {project-type}\n**Output:** {output-dir}\n\n**TaskFlow Detected:**\nI detected TaskFlow is available. Would you like to track this project with tasks?\n\n- **Yes** - Initialize task tracking, break requirements into tasks\n- **No** - Continue with standard AppGen workflow\n\nWhat would you like to do?\n```\n\n**If user declines:**\n```markdown\nUnderstood. Proceeding with standard AppGen workflow...\n```\n\n**If user accepts:**\n```markdown\nâœ… TaskFlow enabled for this project.\nInitializing task tracking...\n```\n\n---\n\n## Integration Points\n\n### Phase 1: Requirements â†’ Task Initialization\n\n**Trigger:** User accepts TaskFlow integration\n\n**Actions:**\n1. Initialize TaskFlow in project directory\n2. Create initial task structure from requirements\n3. Optionally parse requirements as PRD\n\n**Implementation:**\n\n```bash\ncd {output-dir}\n\n# Initialize TaskFlow\n/task-init\n\n# Option A: Parse requirements.md as PRD (if structured)\nif [ -f \"docs/requirements.md\" ]; then\n  /task-parse docs/requirements.md\nfi\n\n# Option B: Create tasks manually from requirements\n# (Use if requirements not in PRD format)\n```\n\n**Task Structure from Requirements:**\n\n```json\n{\n  \"tasks\": [\n    {\n      \"id\": 1,\n      \"title\": \"Conduct competitive research\",\n      \"description\": \"Research {industry} competitors and extract design patterns\",\n      \"status\": \"pending\",\n      \"priority\": \"high\",\n      \"phase\": \"research\",\n      \"acceptanceCriteria\": [\n        \"3+ competitors analyzed\",\n        \"Research saved to research/competitive-analysis.md\"\n      ]\n    },\n    {\n      \"id\": 2,\n      \"title\": \"Scaffold project architecture\",\n      \"description\": \"Initialize {tech-stack} project with proper structure\",\n      \"status\": \"pending\",\n      \"priority\": \"high\",\n      \"phase\": \"architecture\",\n      \"dependencies\": [1],\n      \"acceptanceCriteria\": [\n        \"Project structure created\",\n        \"Dev server running\",\n        \"Infrastructure verified\"\n      ]\n    },\n    {\n      \"id\": 3,\n      \"title\": \"Implement {component-name}\",\n      \"description\": \"Generate {component-name} component\",\n      \"status\": \"pending\",\n      \"priority\": \"medium\",\n      \"phase\": \"implementation\",\n      \"dependencies\": [2]\n    }\n  ]\n}\n```\n\n### Phase 2-4: Task Tracking During Implementation\n\n**At each checkpoint:**\n\n**Before starting phase:**\n```bash\n/task-status {task-id} in_progress\n```\n\n**During implementation:**\n- Update subtasks as components completed\n- Track blockers if encountered\n- Use `/task-next` for prioritization\n\n**After phase complete:**\n```bash\n/task-status {task-id} done\n```\n\n**Example for Checkpoint 4 (Implementation):**\n\n```markdown\nStarting Implementation phase...\n\n# Update TaskFlow\n/task-status 3 in_progress\n\n# Generate components\n[Component generation...]\n\n# Mark subtasks complete\n/task-status 3.1 done  # Hero component\n/task-status 3.2 done  # Features section\n/task-status 3.3 done  # CTA component\n\n# Mark main task complete\n/task-status 3 done\n\nâœ… Implementation complete\n```\n\n### Phase 5: Final Task Completion\n\n**At project completion:**\n\n1. Mark all remaining tasks as complete\n2. Generate task summary\n3. Include in final report\n\n**Implementation:**\n\n```bash\n# List any incomplete tasks\n/task-list --status pending,in_progress\n\n# Mark project complete\n/task-status {final-task-id} done\n\n# Generate summary\n/task-list --summary\n```\n\n**Include in final report:**\n\n```markdown\n## CHECKPOINT 5 COMPLETE: Project finished\n\n**Project Summary:**\n- Location: {output-dir}\n- Stack: {tech-stack}\n- Preview: {url}\n\n**Task Summary:**\n- Total tasks: {count}\n- Completed: {completed}\n- Time tracked: {duration}\n- Phases: Research â†’ Architecture â†’ Implementation â†’ Legal â†’ Final\n\n**Deliverables:**\n[Standard appgen deliverables...]\n```\n\n---\n\n## TaskFlow Commands Reference\n\n### Commands Used in Integration\n\n| Command | When | Purpose |\n|---------|------|---------|\n| `/task-init` | Checkpoint 1 | Initialize task tracking |\n| `/task-parse <prd>` | Checkpoint 1 (optional) | Parse structured requirements |\n| `/task-status <id> <status>` | Each checkpoint | Update task status |\n| `/task-list` | Any phase | View current tasks |\n| `/task-next` | Implementation | Get recommended next task |\n| `/task-show <id>` | Any phase | View task details |\n| `/task-expand <id>` | Complex tasks | Break into subtasks |\n\n### Status Mapping\n\n| AppGen Phase | TaskFlow Status |\n|--------------|-----------------|\n| Not started | `pending` |\n| In progress | `in_progress` |\n| Complete | `done` |\n| Blocked (code review issues) | `blocked` |\n| Skipped (legal pages) | `deferred` |\n\n---\n\n## Phase-Specific Task Examples\n\n### Checkpoint 2: Research\n\n```json\n{\n  \"id\": 1,\n  \"title\": \"Conduct competitive research\",\n  \"description\": \"Research fintech competitors and extract patterns\",\n  \"status\": \"in_progress\",\n  \"priority\": \"high\",\n  \"subtasks\": [\n    {\n      \"id\": \"1.1\",\n      \"title\": \"Research Betterment\",\n      \"status\": \"done\"\n    },\n    {\n      \"id\": \"1.2\",\n      \"title\": \"Research Wealthfront\",\n      \"status\": \"in_progress\"\n    },\n    {\n      \"id\": \"1.3\",\n      \"title\": \"Extract design patterns\",\n      \"status\": \"pending\"\n    }\n  ],\n  \"acceptanceCriteria\": [\n    \"3+ competitors analyzed\",\n    \"Research saved to research/competitive-analysis.md\",\n    \"Design patterns documented\"\n  ]\n}\n```\n\n### Checkpoint 3: Architecture\n\n```json\n{\n  \"id\": 2,\n  \"title\": \"Scaffold project architecture\",\n  \"description\": \"Initialize React + Vite + Tailwind project\",\n  \"status\": \"pending\",\n  \"priority\": \"high\",\n  \"dependencies\": [1],\n  \"subtasks\": [\n    {\n      \"id\": \"2.1\",\n      \"title\": \"Create project structure\",\n      \"status\": \"pending\"\n    },\n    {\n      \"id\": \"2.2\",\n      \"title\": \"Run pnpm install\",\n      \"status\": \"pending\"\n    },\n    {\n      \"id\": \"2.3\",\n      \"title\": \"Verify dev server\",\n      \"status\": \"pending\"\n    }\n  ],\n  \"acceptanceCriteria\": [\n    \"Project structure created\",\n    \"Dependencies installed\",\n    \"Dev server running on port 5173\"\n  ]\n}\n```\n\n### Checkpoint 4: Implementation\n\n```json\n{\n  \"id\": 3,\n  \"title\": \"Implement landing page components\",\n  \"description\": \"Generate all landing page sections\",\n  \"status\": \"pending\",\n  \"priority\": \"high\",\n  \"dependencies\": [2],\n  \"subtasks\": [\n    {\n      \"id\": \"3.1\",\n      \"title\": \"Hero component\",\n      \"status\": \"pending\"\n    },\n    {\n      \"id\": \"3.2\",\n      \"title\": \"Features section\",\n      \"status\": \"pending\"\n    },\n    {\n      \"id\": \"3.3\",\n      \"title\": \"Trust indicators\",\n      \"status\": \"pending\"\n    },\n    {\n      \"id\": \"3.4\",\n      \"title\": \"Pricing section\",\n      \"status\": \"pending\"\n    },\n    {\n      \"id\": \"3.5\",\n      \"title\": \"CTA section\",\n      \"status\": \"pending\"\n    }\n  ],\n  \"acceptanceCriteria\": [\n    \"All components generated with docstrings\",\n    \"Code review passed\",\n    \"Accessibility compliant\",\n    \"Preview screenshot captured\"\n  ]\n}\n```\n\n---\n\n## Error Handling\n\n### TaskFlow Not Available\n\n```markdown\n# User requests TaskFlow integration\nUser: \"Use TaskFlow for this project\"\n\n# Detection fails\nAgent: \"I don't see TaskFlow installed on this system.\nWould you like to:\n1. Continue with standard AppGen workflow\n2. Install TaskFlow first (provide instructions)\n\nWhat would you like to do?\"\n```\n\n### TaskFlow Command Fails\n\n```bash\n# Graceful degradation\nif ! /task-init 2>/dev/null; then\n  echo \"TaskFlow command failed. Continuing with standard workflow...\"\n  TASKFLOW_ENABLED=false\nfi\n```\n\n**Never crash AppGen due to TaskFlow issues.**\n\n---\n\n## Session Context Tracking\n\n### Store Integration State\n\n**In appgen session metadata:**\n\n```json\n{\n  \"project\": \"investwise - appgen\",\n  \"taskflow\": {\n    \"available\": true,\n    \"enabled\": true,\n    \"initialized\": true,\n    \"task_count\": 12,\n    \"current_task\": 3,\n    \"current_phase\": \"implementation\"\n  }\n}\n```\n\n### Use for Context Awareness\n\n```markdown\n# When resuming session\nAgent: \"Resuming InvestWise project...\"\n\n# Check TaskFlow state\nif taskflow.enabled:\n  current_task = /task-show {current_task}\n\n  \"TaskFlow Status:\n   - Current task: #{current_task.id} - {current_task.title}\n   - Status: {current_task.status}\n   - Progress: {completed}/{total} tasks complete\n\n   Should I continue with task #{current_task.id}?\"\n```\n\n---\n\n## Benefits of Integration\n\n**For Users:**\n- âœ… Visual task progress during long generations\n- âœ… Clear dependency tracking\n- âœ… Resume capability if session interrupted\n- âœ… Structured completion checklist\n- âœ… Historical record of work done\n\n**For Agents:**\n- âœ… Clear next-action recommendations (`/task-next`)\n- âœ… Dependency awareness (don't start blocked tasks)\n- âœ… Progress context across checkpoints\n- âœ… Shared task list with other agents\n\n---\n\n## Usage Example\n\n### Full Session with TaskFlow\n\n```\nUser: /appgen fintech landing page for InvestWise\n\nAgent: [Detects TaskFlow]\nTaskFlow detected. Track this project with tasks? (y/n)\n\nUser: y\n\nAgent: âœ… TaskFlow enabled\nInitializing task tracking...\n\n/task-init\nCreated .tasks/ directory\nInitialized master tag\n\nCreating tasks from requirements...\n\nTasks created:\n1. [pending] Conduct competitive research (high priority)\n2. [pending] Scaffold project architecture (high priority, depends on #1)\n3. [pending] Implement landing page components (medium, depends on #2)\n4. [pending] Generate legal pages (low, depends on #3)\n5. [pending] Final documentation (low, depends on #4)\n\nStarting with task #1...\n\n/task-status 1 in_progress\n\n[Conducts research...]\n\n/task-status 1 done\n\nâœ… Research complete\nMoving to task #2...\n\n/task-status 2 in_progress\n\n[Scaffolds project...]\n\n/task-status 2 done\n\nâœ… Architecture complete\nMoving to task #3...\n\n/task-status 3 in_progress\n\nImplementing components...\n- /task-status 3.1 done  # Hero\n- /task-status 3.2 done  # Features\n- /task-status 3.3 done  # CTA\n\n/task-status 3 done\n\nâœ… Implementation complete\n\n[Continues through remaining tasks...]\n\n## FINAL REPORT\n\n**Task Summary:**\n- Total: 5 tasks, 12 subtasks\n- All tasks complete âœ…\n- No blockers encountered\n- Phases: Research â†’ Architecture â†’ Implementation â†’ Legal â†’ Final\n\nProject complete!\n```\n\n---\n\n## Future Enhancements (Optional)\n\n**Potential improvements for future versions:**\n\n1. **Effort Estimation:**\n   - Track actual time vs estimated time\n   - Improve estimates over time\n\n2. **Tag-Based Organization:**\n   - Use TaskFlow tags for multi-page projects\n   - Separate tag per major section\n\n3. **Template Integration:**\n   - Save task templates for common project types\n   - Auto-populate tasks based on project type\n\n4. **Cross-Session Resume:**\n   - Detect incomplete projects\n   - Offer to resume from last checkpoint\n\n5. **Parallel Component Generation:**\n   - Use tags to track parallel component work\n   - Enable distributed generation\n\n---\n\n## Success Criteria\n\n**Integration is successful when:**\n\nâœ… TaskFlow detected reliably (no false negatives)\nâœ… User can decline without breaking workflow\nâœ… AppGen works identically with/without TaskFlow\nâœ… Tasks accurately reflect appgen phases\nâœ… Task statuses stay synchronized with actual progress\nâœ… Final report includes meaningful task summary\nâœ… No errors when TaskFlow unavailable\nâœ… Commands fail gracefully with clear messaging\n\n---\n\n**Version:** 1.0.0\n**Created:** 2025-12-13\n**Status:** Active\n",
        "plugins/appgen/skills/worktree-workflow/skill.md": "---\nname: worktree-workflow\ndescription: Git worktree setup, management, and cleanup for isolated parallel development\n---\n\n# Worktree Workflow Skill\n\nEnables isolated development using git worktrees. Each project runs in its own directory with full git history but no interference with other work.\n\n---\n\n## When to Recommend Worktrees\n\n**Offer worktrees when:**\n- User has multiple projects/tasks in progress\n- Working in a shared/team repository\n- Project generation might conflict with ongoing work\n- User wants to preserve current branch state\n- Long-running generation that shouldn't block other work\n\n**Skip worktrees when:**\n- Fresh/empty output directory with no existing work\n- User explicitly wants to work in main directory\n- Simple single-file or component generation\n- User declines worktree option\n\n---\n\n## Worktree Setup Protocol\n\n### 1. Pre-Flight Check\n\nBefore creating worktree, verify:\n\n```bash\n# Check if we're in a git repo\ngit rev-parse --git-dir 2>/dev/null || echo \"NOT_GIT_REPO\"\n\n# Check current branch\ngit branch --show-current\n\n# Check for uncommitted changes\ngit status --porcelain\n```\n\n**If not a git repo:** Initialize one or use standard workflow (no worktree needed for new projects).\n\n**If uncommitted changes:** Warn user - worktrees work best with clean state.\n\n### 2. Create Worktree\n\n```bash\n# Standard pattern: worktrees live in sibling directory\nPROJECT_DIR=\"${OUTPUT_DIR}/${slug} - ${generator}\"\nWORKTREE_DIR=\"${OUTPUT_DIR}/worktrees/${slug}\"\nBRANCH_NAME=\"feat/${slug}\"\n\n# Ensure worktrees directory exists\nmkdir -p \"${OUTPUT_DIR}/worktrees\"\n\n# Create worktree with new branch\ngit worktree add -b \"${BRANCH_NAME}\" \"${WORKTREE_DIR}\" main\n\n# Navigate to worktree\ncd \"${WORKTREE_DIR}\"\n```\n\n### 3. Verify Worktree Creation\n\n```bash\n# List all worktrees (should show new one)\ngit worktree list\n\n# Verify we're on the correct branch\ngit branch --show-current  # Should be: feat/${slug}\n\n# Verify isolation\npwd  # Should be in worktrees directory\n```\n\n---\n\n## Working in Worktree\n\n### Directory Structure\n\n```\n${OUTPUT_DIR}/\nâ”œâ”€â”€ worktrees/\nâ”‚   â””â”€â”€ ${slug}/          # Isolated worktree\nâ”‚       â”œâ”€â”€ .git          # Worktree git link (NOT full .git)\nâ”‚       â””â”€â”€ [project files]\nâ”œâ”€â”€ main-project/         # Main checkout (if exists)\nâ””â”€â”€ .git/                 # Shared git directory\n```\n\n### Committing in Worktree\n\nSame as normal git workflow - worktrees share history:\n\n```bash\ncd \"${WORKTREE_DIR}\"\ngit add .\ngit commit -m \"feat(${slug}): description\"\ngit push -u origin \"feat/${slug}\"\n```\n\n---\n\n## Worktree Cleanup Protocol (MANDATORY)\n\n**CRITICAL:** Agents MUST clean up worktrees and merged branches. Orphaned worktrees waste disk space and create confusion.\n\n### After Successful Completion\n\n```bash\n# 1. Ensure all changes committed and pushed\ngit status --porcelain  # Must be empty\n\n# 2. Switch to main in the MAIN worktree (not this worktree)\ncd \"${OUTPUT_DIR}\"  # Back to main project area\ngit checkout main\ngit pull origin main\n\n# 3. Merge the feature branch\ngit merge \"feat/${slug}\" --no-ff -m \"Merge feat/${slug}: ${description}\"\n\n# 4. Push merged main\ngit push origin main\n\n# 5. Delete the remote branch\ngit push origin --delete \"feat/${slug}\"\n\n# 6. Remove the worktree\ngit worktree remove \"${WORKTREE_DIR}\"\n\n# 7. Delete the local branch\ngit branch -d \"feat/${slug}\"\n\n# 8. Prune stale worktree references\ngit worktree prune\n```\n\n### Cleanup Verification\n\n```bash\n# Verify worktree removed\ngit worktree list  # Should NOT include the removed worktree\n\n# Verify branch deleted\ngit branch -a | grep \"feat/${slug}\"  # Should return nothing\n\n# Verify merge happened\ngit log --oneline -3  # Should show merge commit\n```\n\n### Failed/Abandoned Worktree Cleanup\n\nIf user abandons or generation fails:\n\n```bash\n# Force remove worktree (if changes not worth keeping)\ngit worktree remove --force \"${WORKTREE_DIR}\"\n\n# Delete the branch\ngit branch -D \"feat/${slug}\"  # -D for force delete\n\n# Prune references\ngit worktree prune\n```\n\n---\n\n## Orchestrator Integration\n\n### Checkpoint 1: Requirements (Add to existing)\n\nAfter requirements confirmed, add this prompt:\n\n```markdown\n**Worktree Option:**\n\nI can generate this project in an isolated git worktree, which:\n- Keeps your current work untouched\n- Creates a separate directory for this project\n- Allows parallel development\n- Merges back to main when complete\n\nWould you like to use a git worktree? (Recommended if you have work in progress)\n- **Yes** - Create isolated worktree\n- **No** - Use standard feature branch in output directory\n```\n\n### Store Worktree Context\n\nIf user chooses worktree, store in session:\n\n```json\n{\n  \"use_worktree\": true,\n  \"worktree_path\": \"${OUTPUT_DIR}/worktrees/${slug}\",\n  \"branch_name\": \"feat/${slug}\",\n  \"main_path\": \"${OUTPUT_DIR}\"\n}\n```\n\n### Final Phase: Add Cleanup Step\n\nBefore marking project complete:\n\n```markdown\n## WORKTREE CLEANUP\n\n**Worktree:** ${worktree_path}\n**Branch:** ${branch_name}\n\nCleanup steps:\n1. Verify all changes committed\n2. Merge to main\n3. Push main\n4. Delete remote branch\n5. Remove worktree\n6. Delete local branch\n7. Prune references\n\nExecuting cleanup...\n```\n\n---\n\n## Error Handling\n\n### Worktree Already Exists\n\n```bash\n# Check if worktree exists\ngit worktree list | grep \"${slug}\" && echo \"EXISTS\"\n\n# If exists, offer options:\n# 1. Use existing worktree (continue previous work)\n# 2. Remove and recreate (fresh start)\n# 3. Use different name\n```\n\n### Branch Already Exists\n\n```bash\n# Check if branch exists\ngit branch -a | grep \"feat/${slug}\" && echo \"BRANCH_EXISTS\"\n\n# If exists locally only: can checkout\n# If exists on remote: need to fetch and merge or use different name\n```\n\n### Merge Conflicts\n\n```markdown\n## MERGE CONFLICT DETECTED\n\nThe worktree branch has conflicts with main.\n\n**Conflicting files:**\n- [list files]\n\n**Options:**\n1. Resolve conflicts (I'll help)\n2. Force merge (may lose main changes)\n3. Keep worktree, skip merge (manual resolution later)\n4. Abandon worktree changes\n\nYour choice?\n```\n\n---\n\n## Quick Reference\n\n| Action | Command |\n|--------|---------|\n| List worktrees | `git worktree list` |\n| Create worktree | `git worktree add -b BRANCH PATH BASE` |\n| Remove worktree | `git worktree remove PATH` |\n| Force remove | `git worktree remove --force PATH` |\n| Prune stale | `git worktree prune` |\n| Check branch | `git branch --show-current` |\n\n---\n\n## Hygiene Checklist (For Agents)\n\nBefore ending ANY session with worktrees:\n\n- [ ] All worktree changes committed?\n- [ ] Worktree branch pushed to remote?\n- [ ] If complete: Merged to main?\n- [ ] If complete: Remote branch deleted?\n- [ ] If complete: Worktree removed?\n- [ ] If complete: Local branch deleted?\n- [ ] `git worktree prune` run?\n- [ ] `git worktree list` shows expected state?\n\n**Rule:** Never leave orphaned worktrees. Either merge+cleanup OR explicitly document for user to handle later.\n",
        "plugins/docs/.claude-plugin/plugin.json": "{\n  \"name\": \"docs\",\n  \"version\": \"1.1.0\",\n  \"description\": \"Documentation management and validation with .local.md config support. Single source of truth philosophy with inline updates, journal reconciliation, and worklog integration.\",\n  \"author\": {\n    \"name\": \"gs\"\n  },\n  \"license\": \"MIT\",\n  \"repository\": \"https://github.com/gaurangrshah/gsc-plugins\",\n  \"homepage\": \"https://github.com/gaurangrshah/gsc-plugins/tree/main/plugins/docs\",\n  \"keywords\": [\n    \"documentation\",\n    \"docs\",\n    \"markdown\",\n    \"frontmatter\",\n    \"validation\",\n    \"quality-assurance\",\n    \"single-source-of-truth\",\n    \"changelog\",\n    \"journal\",\n    \"worklog\"\n  ]\n}\n",
        "plugins/docs/README.md": "# Docs Plugin\n\n**Docs** is a Claude Code plugin for documentation management and quality assurance. It enforces a single source of truth philosophy with inline updates, journal reconciliation, and proactive validation.\n\n**Version:** 1.1.0\n\n## Installation\n\n### Option 1: Marketplace (Recommended)\n\n```bash\n# Add the marketplace (if not already added)\nclaude plugin marketplace add https://github.com/gaurangrshah/gsc-plugins.git\n\n# Install the plugin\nclaude plugin install docs@gsc-plugins\n```\n\n### Option 2: Manual Installation\n\n```bash\n# Clone the repo\ngit clone https://github.com/gaurangrshah/gsc-plugins.git\n\n# Copy to local-plugins\ncp -r gsc-plugins/plugins/docs ~/.claude/plugins/local-plugins/\n\n# Restart Claude Code to activate\n```\n\n## Core Capabilities\n\nThe plugin provides two complementary skills: **docs-manager** for creating and maintaining documentation, and **docs-validator** for quality assurance. Together they ensure documentation stays current, consistent, and queryable.\n\n## Key Features\n\n**Single Source of Truth**: All system documentation flows through one main guide file. Updates happen inlineâ€”no separate incident files, no documentation sprawl.\n\n**Journal Reconciliation**: After completing tasks, reconcile journal notes into permanent documentation. Decisions, learnings, and config changes are extracted and routed to appropriate locations.\n\n**Proactive Validation**: Check frontmatter compliance, internal links, README completeness, and changelog entries. Catch issues before they become problems.\n\n**Worklog Integration**: When the worklog plugin is installed, docs automatically stores reusable learnings and logs documentation work to the shared database.\n\n**Platform Agnostic**: Configure paths via environment variables. Works with any project structure on any system.\n\n## Configuration\n\nConfiguration uses `.local.md` files with YAML frontmatter:\n\n**Project-level:** `./.docs.local.md`\n**Global:** `~/.gsc-plugins/docs.local.md`\n\n```yaml\n---\ndocs_root: ~/docs\nmain_guide: ~/docs/guide.md\nknowledge_base: ~/.gsc-plugins/knowledge\n\nworklog:\n  enabled: true\n  use_mcp: true\n---\n```\n\nRun `/docs-init` to create configuration interactively.\n\n## Commands\n\n| Command | Purpose |\n|---------|---------|\n| `/docs-init` | Initialize documentation structure |\n| `/docs-validate` | Run validation checks |\n| `/docs-reconcile` | Reconcile journal into docs |\n\n## Skills\n\n| Skill | Purpose |\n|-------|---------|\n| `docs-manager` | Create, update, and reconcile documentation |\n| `docs-validator` | Validate quality and compliance |\n\n## Quick Start\n\n1. Initialize documentation structure:\n   ```\n   /docs-init\n   ```\n\n2. Configure environment (auto-created by init):\n   ```\n   ~/.gsc-plugins/docs.local.md\n   ```\n\n3. Start documenting with inline updates to main guide\n\n4. After tasks, reconcile journals:\n   ```\n   /docs-reconcile /tmp/journal-task-2025-01-15.md\n   ```\n\n5. Run validation monthly:\n   ```\n   /docs-validate\n   ```\n\n## Documentation Philosophy\n\n**DO:**\n- Update main guide inline for system changes\n- Use /tmp for working notes during tasks\n- Add frontmatter to all markdown files\n- Keep documentation concise and current\n\n**DON'T:**\n- Create separate files for each incident/change\n- Leave documentation for \"later\"\n- Add hypothetical configurations\n- Over-document obvious things\n\n## Standalone & Integration\n\nDocs operates independently without dependencies. When the **worklog** plugin is installed:\n- Reusable learnings are stored to `knowledge_base` table\n- Documentation work is logged to `entries` table\n- Working memory uses `memories` table during tasks\n\n## Frontmatter Standard\n\nAll documentation requires YAML frontmatter:\n\n```yaml\n---\ntitle: \"Brief descriptive title\"\ntype: decision|learning|guide|reference|changelog|environment\ncreated: YYYY-MM-DD\n---\n```\n\n## Validation Checks\n\n`/docs-validate` performs:\n- Frontmatter compliance (required fields, valid values)\n- Internal link validation (no broken references)\n- README completeness (all files referenced)\n- CHANGELOG compliance (proper format)\n- Structure compliance (files in correct directories)\n\n## File Structure\n\n```\n$DOCS_ROOT/\nâ”œâ”€â”€ README.md           # Navigation hub\nâ”œâ”€â”€ guide.md            # THE GUIDE (single source of truth)\nâ”œâ”€â”€ FRONTMATTER-SCHEMA.md\nâ”œâ”€â”€ security/\nâ”œâ”€â”€ guides/\nâ”œâ”€â”€ services/\nâ””â”€â”€ baselines/\n```\n\n## Journal Reconciliation Flow\n\n```\nJournal Entry â†’ Decision Tree â†’ Documentation Action\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nSystem config     â†’ Main guide inline\nArchitecture      â†’ $KNOWLEDGE_BASE/decisions/\nLesson learned    â†’ Main guide \"Key Lessons\"\nCross-project     â†’ $KNOWLEDGE_BASE/guides/\nCode change       â†’ Project CHANGELOG\nTrivial           â†’ No action needed\n```\n\n---\n\n**License:** MIT\n",
        "plugins/docs/commands/docs-init.md": "---\nname: docs-init\ndescription: Initialize documentation structure for a project with frontmatter standards\nargs: [--path <dir>] [--guide <name>] [--global] [--with-worklog]\nversion: \"2.0\"\n---\n\n# /docs-init\n\nInitialize documentation structure and configuration.\n\n## Usage\n\n```bash\n/docs-init                              # Interactive setup\n/docs-init --path ~/docs                # Specify docs root\n/docs-init --global                     # Save as global default\n/docs-init --with-worklog               # Enable worklog integration\n```\n\n## Options\n\n| Flag | Description |\n|------|-------------|\n| `--path <dir>` | Documentation root directory |\n| `--guide <name>` | Main guide filename (default: `guide.md`) |\n| `--global` | Save config globally (`~/.gsc-plugins/docs.local.md`) |\n| `--project` | Save config for project only (`./.docs.local.md`) |\n| `--with-worklog` | Enable worklog integration |\n\n---\n\n## Workflow\n\n### Step 1: Check Existing Config\n\n```python\n# Check for existing configs\nproject_config = \"./.docs.local.md\"\nglobal_config = os.path.expanduser(\"~/.gsc-plugins/docs.local.md\")\n\nif os.path.exists(project_config):\n    print(\"Docs already configured for this project.\")\n    print(f\"Config: {project_config}\")\n    response = AskUserQuestion({\n        \"question\": \"What would you like to do?\",\n        \"header\": \"Config exists\",\n        \"options\": [\n            {\"label\": \"Keep existing\", \"description\": \"Exit without changes\"},\n            {\"label\": \"Reconfigure\", \"description\": \"Update configuration\"},\n            {\"label\": \"View config\", \"description\": \"Show current settings\"}\n        ]\n    })\n    if response == \"Keep existing\":\n        return\n    elif response == \"View config\":\n        showConfig(project_config)\n        return\n```\n\n### Step 2: Prompt for Settings\n\n```python\n# Use arg or prompt for docs_root\nif args.path:\n    docs_root = args.path\nelse:\n    response = AskUserQuestion({\n        \"question\": \"Where should documentation be stored?\",\n        \"header\": \"Docs Root\",\n        \"options\": [\n            {\"label\": \"~/docs (Recommended)\", \"description\": \"Standard location in home directory\"},\n            {\"label\": \"./docs\", \"description\": \"In current project directory\"},\n            {\"label\": \"Custom path\", \"description\": \"Specify a different location\"}\n        ]\n    })\n\n    if \"~/docs\" in response:\n        docs_root = \"~/docs\"\n    elif \"./docs\" in response:\n        docs_root = \"./docs\"\n    else:\n        docs_root = input(\"Enter documentation path: \")\n\n# Expand path\ndocs_root = os.path.expanduser(docs_root)\n```\n\n### Step 3: Detect Worklog\n\n```python\n# Check for worklog MCP tools\nworklog_mcp = tool_exists('mcp__worklog__store_knowledge')\n\n# Check for worklog.db in common locations\nworklog_db = None\nfor path in ['~/.claude/worklog/worklog.db', '~/.gsc-plugins/worklog.db']:\n    if os.path.exists(os.path.expanduser(path)):\n        worklog_db = path\n        break\n\n# Prompt for worklog integration\nif worklog_mcp or worklog_db or args.with_worklog:\n    if worklog_mcp:\n        print(\"Worklog MCP detected - can store learnings cross-project\")\n    elif worklog_db:\n        print(f\"Worklog database found: {worklog_db}\")\n\n    if not args.with_worklog:\n        response = AskUserQuestion({\n            \"question\": \"Enable worklog integration?\",\n            \"header\": \"Worklog\",\n            \"options\": [\n                {\"label\": \"Yes (Recommended)\", \"description\": \"Store learnings to shared knowledge base\"},\n                {\"label\": \"No\", \"description\": \"Keep documentation isolated\"}\n            ]\n        })\n        enable_worklog = \"Yes\" in response\n    else:\n        enable_worklog = True\nelse:\n    enable_worklog = False\n```\n\n### Step 4: Select Scope\n\n```python\nif not args.global and not args.project:\n    response = AskUserQuestion({\n        \"question\": \"Save configuration for?\",\n        \"header\": \"Scope\",\n        \"options\": [\n            {\"label\": \"This project\", \"description\": \"Save to ./.docs.local.md\"},\n            {\"label\": \"All projects (global)\", \"description\": \"Save to ~/.gsc-plugins/docs.local.md\"}\n        ]\n    })\n    scope = \"global\" if \"global\" in response.lower() else \"project\"\nelse:\n    scope = \"global\" if args.global else \"project\"\n```\n\n### Step 5: Create Directory Structure\n\n```python\n# Create docs directories\ndirs_to_create = [\n    docs_root,\n    f\"{docs_root}/security\",\n    f\"{docs_root}/guides\",\n    f\"{docs_root}/services\",\n    f\"{docs_root}/baselines\"\n]\n\nfor dir_path in dirs_to_create:\n    os.makedirs(dir_path, exist_ok=True)\n\n# Create subdirectory READMEs\nsubdirs = ['security', 'guides', 'services']\nfor subdir in subdirs:\n    readme_path = f\"{docs_root}/{subdir}/README.md\"\n    if not os.path.exists(readme_path):\n        writeSubdirReadme(readme_path, subdir)\n```\n\n### Step 6: Create Main Guide (if needed)\n\n```python\nguide_name = args.guide or \"guide.md\"\nmain_guide = f\"{docs_root}/{guide_name}\"\n\nif not os.path.exists(main_guide):\n    writeMainGuideTemplate(main_guide)\n    print(f\"Created main guide: {main_guide}\")\nelse:\n    print(f\"Main guide exists: {main_guide}\")\n```\n\n### Step 7: Create Frontmatter Schema\n\n```python\nschema_path = f\"{docs_root}/FRONTMATTER-SCHEMA.md\"\nif not os.path.exists(schema_path):\n    writeFrontmatterSchema(schema_path)\n```\n\n### Step 8: Write Config File\n\n```python\nknowledge_base = '~/.gsc-plugins/knowledge'\n\nconfig_content = f\"\"\"---\ndocs_root: {docs_root}\nmain_guide: {main_guide}\nknowledge_base: {knowledge_base}\n\nworklog:\n  enabled: {str(enable_worklog).lower()}\n  use_mcp: {str(worklog_mcp).lower()}\n{\"  db_path: \" + worklog_db if worklog_db and not worklog_mcp else \"\"}\n\ndefaults:\n  frontmatter_required: true\n  validate_on_save: false\n  journal_dir: /tmp\n---\n\n# Docs Configuration\n\n{\"Global\" if scope == \"global\" else \"Project\"} documentation settings.\nInitialized: {datetime.now().isoformat()}\n\n## Paths\n\n- **docs_root**: {docs_root}\n- **main_guide**: {main_guide}\n- **knowledge_base**: {knowledge_base}\n\n## Integration\n\n- **Worklog**: {\"Enabled\" if enable_worklog else \"Disabled\"}\n\"\"\"\n\n# Determine config path\nif scope == \"global\":\n    config_path = os.path.expanduser(\"~/.gsc-plugins/docs.local.md\")\n    os.makedirs(os.path.dirname(config_path), exist_ok=True)\nelse:\n    config_path = \"./.docs.local.md\"\n\nwith open(config_path, 'w') as f:\n    f.write(config_content)\n\nprint(f\"Config saved: {config_path}\")\n```\n\n### Step 9: Confirm Success\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Docs initialized!                                          â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                             â”‚\nâ”‚  Structure created:                                         â”‚\nâ”‚    ~/docs/                                                  â”‚\nâ”‚    â”œâ”€â”€ guide.md          (main guide)                       â”‚\nâ”‚    â”œâ”€â”€ FRONTMATTER-SCHEMA.md                                â”‚\nâ”‚    â”œâ”€â”€ security/                                            â”‚\nâ”‚    â”œâ”€â”€ guides/                                              â”‚\nâ”‚    â”œâ”€â”€ services/                                            â”‚\nâ”‚    â””â”€â”€ baselines/                                           â”‚\nâ”‚                                                             â”‚\nâ”‚  Config: ~/.gsc-plugins/docs.local.md (global)              â”‚\nâ”‚  Worklog: Enabled (MCP)                                     â”‚\nâ”‚                                                             â”‚\nâ”‚  Next steps:                                                â”‚\nâ”‚    1. Edit ~/docs/guide.md with your system info            â”‚\nâ”‚    2. Run /docs-validate to check structure                 â”‚\nâ”‚    3. Use inline updates for all changes                    â”‚\nâ”‚                                                             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n---\n\n## Templates\n\n### Main Guide Template\n\n```python\ndef writeMainGuideTemplate(path):\n    content = \"\"\"---\ntitle: \"System Guide\"\ntype: reference\ncreated: {date}\nupdated: {date}\n---\n\n# System Guide\n\n> Single source of truth for system configuration and operations.\n\n## Current State\n\n| Component | Status | Notes |\n|-----------|--------|-------|\n| Example   | âœ… OK  | -     |\n\n## Quick Reference\n\n### Access Points\n\n- **Service A**: https://...\n- **Service B**: https://...\n\n## Configuration\n\n### Section 1\n\nConfiguration details here.\n\n**Key Lessons:**\n- Lesson 1\n- Lesson 2\n\n### Section 2\n\nMore configuration.\n\n## Troubleshooting\n\n### Common Issues\n\n**Issue:** Description\n**Solution:** How to fix\n\n## Change History\n\n### {date}\n- Initial documentation created\n\"\"\".format(date=datetime.now().strftime('%Y-%m-%d'))\n\n    with open(path, 'w') as f:\n        f.write(content)\n```\n\n---\n\n## Examples\n\n```bash\n# Basic initialization (interactive)\n/docs-init\n\n# Initialize with specific path\n/docs-init --path ~/projects/myapp/docs\n\n# Initialize as global default\n/docs-init --global\n\n# Initialize with worklog integration\n/docs-init --with-worklog\n```\n\n---\n\n**Command Version:** 2.0\n**Creates:** Directory structure, config file, main guide template\n",
        "plugins/docs/commands/docs-reconcile.md": "---\nname: docs-reconcile\ndescription: Reconcile a journal file into permanent documentation following decision tree routing\n---\n\n# /docs-reconcile\n\nReconcile a journal file into permanent documentation.\n\n## Usage\n\n```\n/docs-reconcile <journal-path>\n```\n\n## What It Does\n\n1. **Reads and analyzes the journal**\n   - Parses entry types (Discovery, Decision, Blocker, Checkpoint, Completed)\n   - Identifies what changed (code, config, architecture, services)\n   - Extracts key decisions and rationale\n   - Notes lessons learned or gotchas\n\n2. **Determines documentation actions** using decision tree:\n   ```\n   System config change     â†’ Update $MAIN_GUIDE inline\n   Service deployment       â†’ Update services/ or $MAIN_GUIDE\n   Security change          â†’ Update security/ AND $MAIN_GUIDE\n   Architecture decision    â†’ $KNOWLEDGE_BASE/decisions/\n   Lesson learned           â†’ Main guide \"Key Lessons\"\n   Cross-project pattern    â†’ $KNOWLEDGE_BASE/guides/\n   Bug fix (non-trivial)    â†’ Troubleshooting section\n   Code change only         â†’ Project CHANGELOG\n   Trivial change           â†’ No documentation needed\n   ```\n\n3. **Executes documentation updates**\n   - Makes inline updates (never separate incident files)\n   - Updates \"Current State\" tables if applicable\n   - Adds to \"Change History\" sections\n   - Validates frontmatter on new files\n\n4. **Stores to worklog.db** (if configured)\n   - Reusable learnings â†’ `knowledge_base` table\n   - Work completion â†’ `entries` table\n\n5. **Reports reconciliation results**\n   - What was updated\n   - What was skipped (and why)\n   - Confirms journal can be deleted\n\n## Journal Format Expected\n\n```markdown\n# Journal: Task Name\n\n## Task Started - HH:MM\n**Context:** What you're working on\n\n## Discovery - HH:MM\n**Context:** What you found\n**Content:** Details\n\n## Decision - HH:MM\n**Context:** What decision was needed\n**Content:** What was decided and why\n**Next:** What to do next\n\n## Blocker - HH:MM\n**Context:** What's blocking\n**Content:** Details\n**Resolution:** How resolved (if resolved)\n\n## Checkpoint - HH:MM\n**Context:** Progress update\n**Content:** What's done so far\n\n## Completed - HH:MM\n**Context:** Task completion\n**Content:** Summary of what was accomplished\n```\n\n## Examples\n\n**Basic reconciliation:**\n```\n/docs-reconcile /tmp/journal-fix-auth-2025-01-15.md\n```\n\n## Output\n\n```\nðŸ“ Journal Reconciliation Report\n\nJournal: /tmp/journal-fix-auth-2025-01-15.md\nEntries found: 6 (2 decisions, 1 discovery, 1 completed)\n\nâœ… Documentation Updated:\n- $MAIN_GUIDE: Added firewall rule to Current State\n- $MAIN_GUIDE: Added entry to Change History\n- $KNOWLEDGE_BASE/decisions/jwt-auth-strategy.md: Created\n\nâ­ï¸  Skipped:\n- 2 checkpoint entries (context only)\n- 1 trivial discovery (no lasting value)\n\nðŸ“¦ Stored to worklog.db:\n- knowledge_base: 1 new entry (JWT auth decision)\n- entries: 1 work log entry\n\nâœ… Journal can be safely deleted\n```\n\n## Post-Reconciliation\n\nAfter successful reconciliation:\n1. Review the documentation updates\n2. Commit changes to git\n3. Delete the journal file\n4. Run `/docs-validate --quick` to verify\n\n## Integration\n\n- Works with docs-manager skill for documentation updates\n- Logs to worklog.db if configured\n- Respects frontmatter standards\n- Never creates separate incident files\n",
        "plugins/docs/commands/docs-validate.md": "---\nname: docs-validate\ndescription: Run documentation validation checks for frontmatter, links, and structure compliance\n---\n\n# /docs-validate\n\nRun documentation validation checks.\n\n## Usage\n\n```\n/docs-validate [options]\n```\n\n## Options\n\n- `--quick` - Fast validation (frontmatter + obvious issues only)\n- `--path <dir>` - Validate specific directory (default: `$DOCS_ROOT`)\n- `--fix` - Attempt to auto-fix simple issues\n- `--report` - Generate detailed report to `/tmp/docs-validation-YYYY-MM-DD.md`\n\n## What It Checks\n\n### Quick Mode (`--quick`)\n- Frontmatter exists on all .md files\n- Required fields present (title, type, created)\n- No obvious broken links\n- ~1-2 minutes\n\n### Full Mode (default)\n- All quick mode checks\n- Internal link validation\n- README completeness\n- CHANGELOG compliance\n- Structure compliance\n- ~5-10 minutes\n\n## Validation Categories\n\n| Category | Severity | Example |\n|----------|----------|---------|\n| Missing frontmatter | Critical | File has no `---` block |\n| Broken link | Critical | Link to non-existent file |\n| Missing required field | Warning | No `created` date |\n| Orphaned file | Warning | Not referenced in README |\n| Missing README | Warning | Subdirectory without README.md |\n| Stale content | Info | Not updated in 90+ days |\n\n## Examples\n\n**Quick validation before commit:**\n```\n/docs-validate --quick\n```\n\n**Full validation with report:**\n```\n/docs-validate --report\n```\n\n**Validate specific directory:**\n```\n/docs-validate --path ~/docs/security\n```\n\n**Auto-fix simple issues:**\n```\n/docs-validate --fix\n```\n\n## Output\n\n**Console output:**\n```\nðŸ“‹ Documentation Validation Report\n\nChecked: 42 files\nIssues: 3 critical, 5 warnings, 2 info\n\nâŒ Critical Issues:\n- security/new-policy.md: Missing frontmatter\n- guides/README.md: Broken link to old-guide.md\n\nâš ï¸  Warnings:\n- 5 files not referenced in READMEs\n\nâ„¹ï¸  Info:\n- Consider adding tags to 2 files\n\nFull report: /tmp/docs-validation-2025-01-15.md\n```\n\n## Auto-Fix Capabilities\n\nWhen `--fix` is used:\n\n| Issue | Auto-Fix Action |\n|-------|-----------------|\n| Missing frontmatter | Add minimal frontmatter template |\n| Missing created date | Add today's date |\n| Malformed date | Convert to YYYY-MM-DD |\n\n**Note:** Auto-fix creates backups before modifying files.\n\n## Integration with Worklog\n\nIf worklog plugin is configured, validation results are logged:\n\n```sql\nINSERT INTO entries (agent, task_type, title, details, outcome, tags)\nVALUES ('hostname', 'validation', 'Docs validation', 'details', 'outcome', 'docs,validation');\n```\n\n## Recommended Schedule\n\n| Frequency | Mode | When |\n|-----------|------|------|\n| Per commit | `--quick` | Before git commit |\n| Weekly | Full | During review |\n| Monthly | Full + `--report` | First of month |\n",
        "plugins/docs/skills/docs-manager/skill.md": "---\nname: docs-manager\ndescription: Maintain living documentation with single source of truth approach, journal reconciliation, and worklog.db integration\n---\n\n# Documentation Manager Skill\n\nMaintain documentation using the single source of truth philosophy. All system documentation flows through one main guide file with inline updates.\n\n## Prerequisites\n\n- Run `/docs-init` to create configuration\n- Optional: Worklog plugin for cross-session persistence\n\n## Configuration\n\n> **See:** `_core/config-loader.md` for full config loading logic\n\nConfiguration is loaded from `.local.md` files with YAML frontmatter:\n\n```\n1. ./.docs.local.md           (project-specific)\n2. ~/.gsc-plugins/docs.local.md   (global)\n```\n\n### Config File Format\n\n```yaml\n---\ndocs_root: ~/docs\nmain_guide: ~/docs/guide.md\nknowledge_base: ~/.gsc-plugins/knowledge\n\nworklog:\n  enabled: true\n  use_mcp: true  # Use MCP tools if available\n\ndefaults:\n  frontmatter_required: true\n  journal_dir: /tmp\n---\n\n# Docs Configuration\n```\n\n### Quick Setup\n\n```bash\n# Interactive setup (recommended)\n/docs-init\n\n# Or with specific options\n/docs-init --path ~/docs --global --with-worklog\n```\n\n---\n\n## Core Principle\n\n> **ALL system documentation goes into your main guide (`$MAIN_GUIDE`)**\n>\n> Update it inline. NO separate files. NO exceptions.\n\n---\n\n## Working Documentation\n\n### Use /tmp for Agent Process Work\n\n**While working on tasks:**\n- Use `/tmp/` for your own process notes, logs, investigation results\n- Track your steps as you go\n- Keep working files ephemeral (vanish on reboot)\n\n**When task complete:**\n- Review `/tmp/` working files\n- Promote ONLY what's valuable to persistent locations\n- Let everything else vanish\n\n### When to Create Permanent Process Documentation\n\n**âœ… Create ONLY when:**\n- Human needs to understand something they don't know\n- Human needs to be communicated complex results/findings\n- Human has expressed lack of knowledge requiring explanation\n- It's actually necessary (not just \"nice to have\")\n\n**âŒ Don't create for:**\n- Everything you do\n- Your own reference\n- \"Documentation for documentation's sake\"\n- Things easily explained in a message\n\n### Workflow\n\n```bash\n# 1. Use /tmp for your working notes\necho \"Investigating issue X...\" > /tmp/work-notes.md\n# ... continue adding as you work ...\n\n# 2. When done, review\ncat /tmp/work-notes.md\n\n# 3. Promote selectively:\n# - System config changes â†’ $MAIN_GUIDE (inline update)\n# - Script automation â†’ project scripts directory\n# - Everything else â†’ let it vanish\n\n# 4. Default: Don't persist\n```\n\n**Rule:** Default to /tmp. Only persist when human actually needs it.\n\n---\n\n## When to Document\n\n### âœ… ALWAYS Document (in $MAIN_GUIDE)\n\n| Type | Where | When |\n|------|-------|------|\n| System config changes | $MAIN_GUIDE inline | Firewall, SSH, network changes |\n| Service deployments | $MAIN_GUIDE inline | New services, modifications |\n| Security changes | $MAIN_GUIDE + security/ | Any security-related change |\n| Architectural decisions | `$KNOWLEDGE_BASE/decisions/` | Major design choices |\n| Lessons learned | $MAIN_GUIDE \"Key Lessons\" | Gotchas, patterns discovered |\n\n### âŒ NEVER Document\n\n| Type | Why Not | Alternative |\n|------|---------|-------------|\n| Routine operations | No lasting value | None needed |\n| Typo corrections | Trivial | Git commit message |\n| Temporary investigations | Ephemeral | /tmp/ notes |\n| Hypothetical configs | Not real | Wait until implemented |\n\n**Rule:** If it changes system behavior or you'll need to reference it later â†’ Document.\n\n---\n\n## Documentation Structure & Decision Tree\n\n**CRITICAL: Before creating ANY .md file, follow this decision tree:**\n\n```\n1. Is this temporary work/planning?\n   YES â†’ /tmp/{task}-{date}.md (ephemeral)\n   STOP\n\n2. Is this system configuration?\n   YES â†’ $MAIN_GUIDE (inline update)\n   STOP\n\n3. Is this a cross-project pattern/decision/learning?\n   YES â†’ $KNOWLEDGE_BASE/\n   â”œâ”€ decisions/ - Architecture decisions (ADRs)\n   â”œâ”€ guides/ - Cross-project how-tos\n   â””â”€ learnings/ - Incident learnings\n   STOP\n\n4. Is this project-specific documentation?\n   YES â†’ $DOCS_ROOT/{category}/\n   â”œâ”€ security/ - Security configs\n   â”œâ”€ guides/ - How-to guides\n   â”œâ”€ services/ - Service docs\n   â””â”€ audits/ - System audits\n   STOP\n```\n\n### Forbidden Actions\n\n**NEVER:**\n- âŒ Create `$DOCS_ROOT/decisions/` directory (use `$KNOWLEDGE_BASE/decisions/`)\n- âŒ Skip frontmatter on new documentation\n- âŒ Create separate files for system config changes (use $MAIN_GUIDE)\n- âŒ Leave /tmp files after task completion\n- âŒ Create root-level .md files in $DOCS_ROOT (use subdirectories)\n\n### Required Frontmatter\n\n**ALL new documentation MUST include:**\n\n```yaml\n---\ntitle: \"Descriptive title\"\ntype: decision|learning|guide|reference|audit|changelog|environment\ncreated: YYYY-MM-DD\n---\n```\n\n---\n\n## How to Document\n\n### Step 1: Open the Guide\n\n```bash\n# Edit the one true guide\n$EDITOR $MAIN_GUIDE\n```\n\n### Step 2: Update Inline\n\n**Find the relevant section:**\n- Firewall change? â†’ Update \"Firewall\" section\n- SSH change? â†’ Update \"SSH\" section\n- New service? â†’ Update \"Services\" section\n- New lesson? â†’ Add to relevant \"Key Lessons\" subsection\n\n**Update these 3 places:**\n1. **Relevant section** (add/modify configuration details)\n2. **\"Current State\" table** (top of file)\n3. **\"Change History\"** (bottom of file)\n\n**Update header:**\n- Change \"Last Updated\" date\n\n### Step 3: Be Concise\n\n**DO write:**\n- Current configuration (what's active)\n- How to access/use it\n- Key lessons (1-2 sentences)\n- Emergency procedures\n\n**DON'T write:**\n- Verbose explanations\n- Hypothetical configurations\n- Theoretical frameworks\n- Template boilerplate\n\n**Example - Good:**\n```markdown\n### Firewall\n**Rules:** 2 (LAN + Tailscale)\n**Lesson:** Firewall is inbound-only. No loopback/Docker rules needed.\n```\n\n**Example - Bad:**\n```markdown\n### Firewall Configuration Documentation\n\nThis section comprehensively documents the complete firewall\nconfiguration strategy implemented across the system...\n\n[10 paragraphs explaining obvious things]\n```\n\n---\n\n## Anti-Patterns\n\n### âŒ Creating Permanent Process Documentation Unnecessarily\n\n**WRONG:**\n```bash\n# DON'T create permanent docs for agent work:\ntouch $DOCS_ROOT/how-i-fixed-docker-2025-11-08.md\ntouch ~/investigation-summary.md\ntouch ~/complete-fixes-summary.md\n```\n\n**RIGHT:**\n```bash\n# DO use /tmp for process work:\nvi /tmp/docker-fix-notes.md\n# Only persist if human actually needs it\n```\n\n### âŒ Creating Separate System Documentation Files\n\n**WRONG:**\n```bash\n# DON'T do this:\ntouch $DOCS_ROOT/firewall-update-2025-11-08.md\ntouch $DOCS_ROOT/ssh-key-implementation.md\ntouch $DOCS_ROOT/docker-networking-fix.md\n```\n\n**RIGHT:**\n```bash\n# DO this:\n$EDITOR $MAIN_GUIDE\n# Update relevant section inline\n```\n\n### âŒ Over-Documenting\n\n**WRONG:**\n```markdown\n## Firewall Rule Addition Procedure\n\n### Prerequisites\n- [ ] Understand network topology\n- [ ] Review security policies\n- [ ] Obtain change approval\n...\n\n### Step 1: Access Web Interface\nNavigate to the control panel by opening your web browser\nand entering the IP address... [500 more words]\n```\n\n**RIGHT:**\n```markdown\n### Firewall\nAdd rules: Web UI â†’ Control Panel â†’ Security â†’ Firewall\n```\n\n### âŒ Keeping Stale Content\n\n**WRONG:** Keeping old configuration details after they've changed\n\n**RIGHT:** Update inline, note in Change History what changed\n\n---\n\n## Documentation Workflow\n\n### For Material Changes\n\n1. **Make the change** (firewall, SSH, service, etc.)\n2. **Test it works**\n3. **Open $MAIN_GUIDE**\n4. **Update relevant section** (configuration details)\n5. **Update \"Current State\" table** (if status changed)\n6. **Add to \"Change History\"** (date, what, why)\n7. **Update \"Last Updated\" date**\n8. **Save and close**\n\n**Time:** 2-5 minutes max\n\n### For Lessons Learned\n\n**If you discover a pattern or learn something important:**\n\n1. **Find relevant section** (Firewall, SSH, Docker, etc.)\n2. **Add to \"Key Lessons\" subsection** (1-2 sentences)\n3. **Example:** \"Firewall is inbound-only. No loopback rules needed.\"\n\n### For New Systems\n\n**If adding entirely new domain (rare):**\n\n1. **Add new section** to $MAIN_GUIDE\n2. **Follow existing format:** Current config â†’ How to use â†’ Lessons â†’ Troubleshooting\n3. **Keep it lean** (resist urge to add 50 pages)\n\n---\n\n## Quality Standards\n\n### Good Documentation Has\n\n- âœ… Current state clearly stated\n- âœ… How to access/use it\n- âœ… Key lessons (concise)\n- âœ… Emergency procedures\n- âœ… Change history entry\n\n### Bad Documentation Has\n\n- âŒ Hypothetical configurations\n- âŒ Verbose explanations of obvious things\n- âŒ Multiple files for same topic\n- âŒ Outdated information\n- âŒ Template boilerplate\n\n---\n\n## Examples\n\n### Example 1: Firewall Rule Added\n\n**Scenario:** \"I added Tailscale to the firewall whitelist.\"\n\n**Action:**\n```markdown\n# Open $MAIN_GUIDE\n\n# 1. Update Firewall section:\n### Current Configuration\nRules:\n1. Allow local network (e.g., 192.168.x.0/24)\n2. Allow VPN network (e.g., 100.64.0.0/10 for Tailscale)\n\n# 2. Update Current State table:\n| Firewall | âœ… ENABLED | 2 rules (LAN + VPN) |\n\n# 3. Add to Change History:\n### 2025-01-15\n- Added VPN firewall rule\n\n# 4. Update header:\nLast Updated: 2025-01-15\n```\n\n**Time:** 2 minutes\n\n### Example 2: Typo Fixed\n\n**Scenario:** \"Fixed typo in .zshrc comment.\"\n\n**Action:** None. No documentation needed (non-material change).\n\n### Example 3: Learning Discovered\n\n**Scenario:** \"TIL: Firewall is inbound-only.\"\n\n**Action:**\n```markdown\n# Open $MAIN_GUIDE\n\n# Add to Firewall â†’ Key Lessons:\n**Key insight:** Firewall is inbound-only.\nNo loopback or Docker rules needed.\n```\n\n**Time:** 30 seconds\n\n---\n\n## Integration Points\n\n### With Git\n\nCommit documentation changes with your project's git workflow:\n```bash\ngit add $MAIN_GUIDE\ngit commit -m \"docs: Update firewall configuration\"\n```\n\n### With Knowledge Base\n\n**$MAIN_GUIDE is for:**\n- System configuration (what's active)\n- How to use/access things\n- Key lessons\n- Troubleshooting\n\n**$KNOWLEDGE_BASE is for:**\n- Patterns across projects (not system-specific)\n- Technical discoveries (language/tool quirks)\n- Decision rationale (architecture choices)\n\n**If in doubt:** Put it in $MAIN_GUIDE (safer)\n\n---\n\n## File Structure\n\n```\n$DOCS_ROOT/\nâ”œâ”€â”€ README.md                    # Navigation hub and quick reference\nâ”œâ”€â”€ {system}-guide.md            # THE GUIDE (single source of truth)\nâ”œâ”€â”€ FRONTMATTER-SCHEMA.md        # Documentation standards\nâ”œâ”€â”€ security/                    # ALL security documentation\nâ”‚   â”œâ”€â”€ README.md\nâ”‚   â””â”€â”€ *.md\nâ”œâ”€â”€ guides/                      # How-to guides and procedures\nâ”‚   â”œâ”€â”€ README.md\nâ”‚   â””â”€â”€ *.md\nâ”œâ”€â”€ services/                    # Service deployment documentation\nâ”‚   â”œâ”€â”€ README.md\nâ”‚   â””â”€â”€ *.md\nâ”œâ”€â”€ audits/                      # System audits and assessments\nâ”‚   â””â”€â”€ YYYY-MM-DD-*.md\nâ”œâ”€â”€ archive/                     # Historical documentation (reference only)\nâ”‚   â””â”€â”€ *.md\nâ””â”€â”€ baselines/                   # System state baselines\n    â””â”€â”€ current.json\n```\n\n**Documentation Guidelines:**\n\n- **System configuration changes** â†’ Update `$MAIN_GUIDE` inline\n- **Security documentation** â†’ Add to appropriate file in `security/`\n- **How-to guides** â†’ Add to `guides/` with frontmatter\n- **Service deployments** â†’ Document in `services/`\n- **System audits** â†’ Add to `audits/` with frontmatter\n- **All documentation** â†’ Use YAML frontmatter\n- **Each subdirectory** â†’ Has comprehensive README for navigation\n\n**Never:**\n- Create root-level .md files for incidents/changes (use $MAIN_GUIDE inline)\n- Skip frontmatter on new documentation\n- Bypass subdirectory READMEs (they provide important context)\n\n---\n\n## Maintenance\n\n### Weekly\n\n- Review $MAIN_GUIDE for accuracy\n- Remove any bloat that crept in\n- Verify \"Current State\" table is current\n\n### After Every Change\n\n- Update relevant section\n- Update \"Current State\" if needed\n- Add to \"Change History\"\n- Update \"Last Updated\" date\n\n### Never\n\n- âŒ Create new documentation files for system changes\n- âŒ Keep outdated information\n- âŒ Add hypothetical configurations\n- âŒ Write verbose explanations\n\n---\n\n## Success Criteria\n\n**Good documentation system:**\n- âœ… One file has everything\n- âœ… Can find anything in <1 minute\n- âœ… Current state always accurate\n- âœ… No stale content\n- âœ… No separate files\n\n**Bad documentation system:**\n- âŒ Multiple files per topic\n- âŒ Can't find what you need\n- âŒ Outdated information\n- âŒ Documentation bloat\n- âŒ Temporary files everywhere\n\n---\n\n## Frontmatter Standards\n\n**All documentation uses YAML frontmatter for queryability**\n\n### Required Fields\n\n```yaml\n---\ntitle: \"Brief descriptive title\"\ntype: decision|learning|guide|reference|changelog|environment\ncreated: YYYY-MM-DD\n---\n```\n\n### Optional Fields\n\n```yaml\nupdated: YYYY-MM-DD\ntags: [tag1, tag2, tag3]\nstatus: active|deprecated|superseded\ncategory: \"Primary category\"\nrelated: [path/to/doc.md]\ncommit: abc1234\nenvironment: system-name\n```\n\n### Valid Type Values\n\n| Type | Use Case |\n|------|----------|\n| `decision` | Architectural or operational decisions |\n| `learning` | Lessons learned from incidents |\n| `guide` | How-to documentation |\n| `reference` | Reference docs and indexes |\n| `changelog` | Change history |\n| `environment` | Environment-specific docs |\n\n### Document Templates\n\n#### Decision Template (in $KNOWLEDGE_BASE/decisions/)\n\n```markdown\n---\ntitle: \"Decision title\"\ntype: decision\ncategory: infrastructure|security|tooling\ntags: [relevant, tags]\nstatus: active\ncreated: YYYY-MM-DD\n---\n\n## Context\nWhy this decision was needed\n\n## Decision\nWhat was decided\n\n## Rationale\n- Reason 1\n- Reason 2\n\n## Consequences\n**Positive:** What this enables\n**Negative:** Trade-offs\n\n## Alternatives Considered\n- Option A: Why not\n```\n\n#### Learning Template (in $KNOWLEDGE_BASE/learnings/)\n\n```markdown\n---\ntitle: \"What we learned\"\ntype: learning\ncategory: incident|optimization|troubleshooting\ntags: [relevant, tags]\ncreated: YYYY-MM-DD\n---\n\n## What Happened\nSituation description\n\n## Root Cause\nWhat caused it\n\n## Solution\nHow resolved\n\n## Prevention\nHow to avoid\n```\n\n#### Guide Template (in $KNOWLEDGE_BASE/guides/)\n\n```markdown\n---\ntitle: \"How to [do thing]\"\ntype: guide\ncategory: operations|security|maintenance\ntags: [relevant, tags]\nstatus: active\ncreated: YYYY-MM-DD\n---\n\n## Purpose\nWhat this accomplishes\n\n## Prerequisites\nWhat you need\n\n## Steps\n1. Step one\n2. Step two\n\n## Verification\nHow to verify\n\n## Troubleshooting\nCommon issues\n```\n\n### Querying Documentation\n\nIf `$DOCS_QUERY_SCRIPT` is configured:\n\n```bash\n# Find security decisions\n$DOCS_QUERY_SCRIPT --type decision --tag security\n\n# Find recent learnings\n$DOCS_QUERY_SCRIPT --type learning --updated-last 30d\n\n# Find all guides\n$DOCS_QUERY_SCRIPT --type guide --status active\n\n# See all options\n$DOCS_QUERY_SCRIPT --help\n```\n\n---\n\n## Journal Reconciliation Workflow\n\n**Purpose:** Convert agent journal notes into permanent documentation after task completion.\n\n### When Invoked for Journal Reconciliation\n\nWhen called with a journal file path (e.g., `/tmp/journal-fix-auth-2025-01-15.md`):\n\n1. **Read and analyze the journal**\n   - Parse all entry types (Discovery, Decision, Blocker, Checkpoint, Completed)\n   - Identify what changed (code, config, architecture, services)\n   - Extract key decisions and their rationale\n   - Note any lessons learned or gotchas\n\n2. **Determine documentation actions**\n   Use this decision tree for each finding:\n\n   ```\n   Finding Type â†’ Documentation Action\n   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   System config change     â†’ Update $MAIN_GUIDE inline\n   Service deployment       â†’ Update services/ doc or $MAIN_GUIDE\n   Security change          â†’ Update security/ doc AND $MAIN_GUIDE\n   Architecture decision    â†’ Create/update $KNOWLEDGE_BASE/decisions/\n   Lesson learned           â†’ Add to relevant section's \"Key Lessons\"\n   New pattern/approach     â†’ Create $KNOWLEDGE_BASE/guides/ if cross-project\n   Bug fix (non-trivial)    â†’ Add to relevant troubleshooting section\n   Code change only         â†’ Update CHANGELOG only (if significant)\n   Trivial change           â†’ No documentation needed\n   ```\n\n3. **Execute documentation updates**\n   For each required update:\n   - Read the target file first\n   - Make inline updates (never create separate incident files)\n   - Update \"Current State\" tables if applicable\n   - Add to \"Change History\" sections with date\n   - Ensure frontmatter is valid on any new files\n\n4. **Update CHANGELOGs**\n   - Project CHANGELOG: If code/feature changes occurred\n   - $MAIN_GUIDE Change History: If system config changed\n   - Use format: `Date - Title, Changed, Why, Impact`\n\n5. **Confirm reconciliation**\n   Report back:\n   - What documentation was updated\n   - What was intentionally skipped (and why)\n   - Any new files created\n   - Confirmation that journal can be deleted\n\n### Journal Entry Types â†’ Doc Actions\n\n| Entry Type | Typical Action |\n|------------|----------------|\n| `## Task Started` | Context only, rarely needs docs |\n| `## Discovery` | May need docs if significant finding |\n| `## Decision` | Often needs $KNOWLEDGE_BASE/decisions/ or inline update |\n| `## Blocker` | May need troubleshooting section update |\n| `## Checkpoint` | Context only, rarely needs docs |\n| `## Recovery` | May warrant learning doc if significant |\n| `## Completed` | Summary guides what needs documentation |\n\n### Example Reconciliation\n\n**Journal excerpt:**\n```markdown\n### Decision - 14:32\n**Context:** Choosing auth strategy for new API\n**Content:** Going with JWT over sessions - API is stateless, mobile clients\n**Next:** Implement in auth.service.ts\n\n### Completed - 16:45\n**Context:** JWT auth implementation done\n**Content:** Added JWT middleware, refresh token rotation, 15min access tokens\n```\n\n**Reconciliation actions:**\n1. âœ… Create `$KNOWLEDGE_BASE/decisions/jwt-auth-strategy.md` (architecture decision)\n2. âœ… Update project CHANGELOG (new feature)\n3. â­ï¸ Skip $MAIN_GUIDE (not system config)\n4. âœ… Confirm journal can be deleted\n\n### Invocation\n\n```bash\n# After task completion, invoke skill with journal path:\n# \"Reconcile journal at /tmp/journal-fix-auth-2025-01-15.md\"\n\n# Or programmatically in workflow:\n# 1. Complete task\n# 2. Invoke docs-manager skill\n# 3. Provide journal path\n# 4. Skill performs reconciliation\n# 5. Delete journal after confirmation\n```\n\n---\n\n## Worklog Database Integration\n\n**Purpose:** Use shared worklog.db for cross-system knowledge persistence and work tracking.\n\n### Database Location\n\nWhen `$WORKLOG_DB` is set, the skill integrates with the worklog database.\n\n**Example paths by setup:**\n| Setup | Path |\n|-------|------|\n| Local (default) | `~/.claude/worklog/worklog.db` |\n| Shared (network) | `/mnt/share/path/to/worklog.db` |\n\n### When to Store to worklog.db\n\n| Scenario | Store? | Table |\n|----------|--------|-------|\n| System config change | After documenting | `entries` |\n| Reusable knowledge/pattern | Yes | `knowledge_base` |\n| Architectural decision | Yes (+ decisions/ doc) | `knowledge_base` |\n| Task completion with learnings | Yes | `entries` + `knowledge_base` |\n| Incident/issue resolution | Yes | `incidents` |\n| Research findings | Yes | `research` |\n| Trivial changes | No | - |\n\n### Storing Knowledge\n\n```bash\nsqlite3 \"$WORKLOG_DB\" \"INSERT INTO knowledge_base\n(category, title, content, tags, source_agent, system) VALUES (\n'category-here',\n'Title of the Knowledge',\n'**Problem:** What was the issue\n\n**Solution:** How to solve it\n\n**Notes:** Gotchas, warnings',\n'comma,separated,tags',\n'$(hostname)',\n'$(hostname)'\n);\"\n```\n\n**Categories:** `learnings`, `guides`, `patterns`, `protocols`, `decisions`\n\n### Logging Work\n\n```bash\nsqlite3 \"$WORKLOG_DB\" \"INSERT INTO entries\n(agent, task_type, title, details, decision_rationale, outcome, tags, related_files) VALUES (\n'$(hostname)',\n'documentation',\n'Task Title',\n'What was done',\n'Why this approach',\n'Result/outcome',\n'docs,tags',\n'/path/to/files'\n);\"\n```\n\n### In Journal Reconciliation\n\n**When reconciling journals:**\n\n1. Query worklog.db for related prior context\n2. Document outcomes as usual ($MAIN_GUIDE, decisions/, etc.)\n3. Store reusable learnings to `knowledge_base` table\n4. Log significant work sessions to `entries` table\n\n### Querying Prior Knowledge\n\n```bash\n# Search for relevant patterns\nsqlite3 \"$WORKLOG_DB\" \\\n  \"SELECT title, content FROM knowledge_base WHERE tags LIKE '%pattern%';\"\n\n# Check recent related work\nsqlite3 \"$WORKLOG_DB\" \\\n  \"SELECT title, outcome FROM entries WHERE tags LIKE '%topic%' ORDER BY timestamp DESC LIMIT 5;\"\n```\n\n### Working Memory (memories table)\n\nFor session-to-session context during tasks:\n\n```bash\n# Store working memory\nsqlite3 \"$WORKLOG_DB\" \"INSERT INTO memories\n(key, content, memory_type, importance, source_agent, system, tags) VALUES (\n'mem_' || lower(hex(randomblob(8))),\n'[DECISION] Brief title | Details of the decision',\n'fact',\n7,\n'$(hostname)',\n'$(hostname)',\n'system:shared,type:decision'\n);\"\n\n# Recall memories\nsqlite3 \"$WORKLOG_DB\" \"SELECT key, content FROM memories\nWHERE status != 'archived' ORDER BY importance DESC LIMIT 10;\"\n```\n\n---\n\n## For Future Claude Instances\n\n**Starting a new session?**\n\n1. Read `$DOCS_ROOT/README.md` (navigation)\n2. Read relevant section in `$MAIN_GUIDE`\n3. Make your changes\n4. **UPDATE $MAIN_GUIDE inline** (this is critical!)\n5. Use frontmatter on all new docs\n6. ALWAYS update CHANGELOG\n7. Store reusable learnings to worklog.db (if configured)\n\n**After completing tasks:**\n1. Review your journal file\n2. Invoke docs-manager for reconciliation\n3. Delete journal after confirmation\n\n**Never:**\n- Create separate files for incidents/changes\n- Leave documentation for \"later\"\n- Add hypothetical content\n- Skip frontmatter on new docs\n- Delete journal before reconciliation confirms\n\n**Remember:** This system works because it's simple. Keep it simple.\n\n---\n\n**Skill Version:** 2.1.0\n**Philosophy:** Single source of truth. Inline updates. Structured knowledge. Queryable metadata. Journal-driven reconciliation. Cross-system worklog.db persistence.\n**Config:** Uses `.local.md` files with YAML frontmatter. See `_core/config-loader.md`.\n",
        "plugins/docs/skills/docs-validator/skill.md": "---\nname: docs-validator\ndescription: Proactive documentation quality assurance - validate frontmatter, links, READMEs, and changelogs\n---\n\n# Documentation Validator Skill\n\n**Purpose:** Proactive documentation quality assurance and compliance checking\n\n**Philosophy:** Catch documentation issues early, maintain quality standards, ensure queryability.\n\n---\n\n## Prerequisites\n\n- Environment variables configured (see Configuration below)\n- Optional: Worklog plugin for logging validation results\n- Optional: Query script for queryable documentation\n\n## Configuration\n\n```bash\n# Required\nDOCS_ROOT=\"${DOCS_ROOT:-~/docs}\"\nKNOWLEDGE_BASE=\"${KNOWLEDGE_BASE:-~/.claude/knowledge}\"\n\n# Optional\nWORKLOG_DB=\"${WORKLOG_DB:-}\"              # Log validation results to worklog\nDOCS_QUERY_SCRIPT=\"${DOCS_QUERY_SCRIPT:-}\" # Path to query-docs.sh or equivalent\n```\n\n---\n\n## When to Use\n\n**Monthly Hygiene:**\n- First of each month: validate all documentation\n- Check for compliance drift\n- Identify stale or outdated content\n\n**Before Major Commits:**\n- After documentation reorganization\n- Before releasing documentation to other environments\n- After bulk documentation updates\n\n**After Major Doc Changes:**\n- New documentation added\n- READMEs updated\n- Structure changes\n\n**Proactive Quality Checks:**\n- When you notice potential issues\n- After agent updates\n- Periodic spot-checks\n\n---\n\n## What This Skill Validates\n\n### 1. Frontmatter Compliance\n\n**Checks:**\n- âœ… All .md files have YAML frontmatter\n- âœ… Required fields present: `title`, `type`, `created`\n- âœ… Valid `type` values: decision, learning, guide, reference, changelog, environment\n- âœ… Dates in YYYY-MM-DD format\n- âœ… `status` values if present: active, deprecated, superseded\n- âœ… Tags are arrays, not strings\n\n**Reports:**\n- Files missing frontmatter\n- Files with incomplete required fields\n- Invalid field values\n- Malformed dates\n\n### 2. Internal Link Validation\n\n**Checks:**\n- âœ… All `[text](path)` links point to existing files\n- âœ… Relative paths resolve correctly\n- âœ… No broken cross-references\n- âœ… README links to all files in directory\n\n**Reports:**\n- Broken links (file doesn't exist)\n- Incorrect relative paths\n- Orphaned files (not linked from any README)\n\n### 3. CHANGELOG Compliance\n\n**Checks:**\n- âœ… READMEs have Changelog sections\n- âœ… Changelog entries have proper format\n- âœ… Recent changes are documented\n- âœ… Commit hashes present where applicable\n\n**Reports:**\n- READMEs missing Changelog section\n- Malformed changelog entries\n- Undocumented recent changes (from git log)\n\n### 4. README Completeness\n\n**Checks:**\n- âœ… Every subdirectory has README.md\n- âœ… READMEs reference all files in directory\n- âœ… READMEs have frontmatter\n- âœ… Navigation links work\n\n**Reports:**\n- Directories missing READMEs\n- Files not referenced in README\n- README frontmatter issues\n\n### 5. Structure Compliance\n\n**Checks:**\n- âœ… Files in correct directories (security docs in security/, guides in guides/)\n- âœ… No orphaned files in root\n- âœ… Archive properly organized\n- âœ… Naming conventions followed\n\n**Reports:**\n- Misplaced files\n- Files that should be archived\n- Naming convention violations\n\n---\n\n## Validation Workflow\n\n### Step 1: Scan Documentation\n\n```bash\n# Scan primary documentation\ncd $DOCS_ROOT\nfind . -type f -name \"*.md\" | grep -v archive/\n```\n\n### Step 2: Check Frontmatter\n\nFor each markdown file:\n1. Extract YAML frontmatter (between `---` delimiters)\n2. Parse required fields: title, type, created\n3. Validate optional fields if present\n4. Check data formats and allowed values\n5. Report issues\n\n### Step 3: Validate Links\n\nFor each markdown file:\n1. Extract all `[text](path)` patterns\n2. Resolve relative paths\n3. Check if target exists\n4. Report broken links\n\n### Step 4: Check READMEs\n\nFor each subdirectory:\n1. Verify README.md exists\n2. Extract all file references\n3. Compare with actual files in directory\n4. Report orphaned or unreferenced files\n\n### Step 5: Verify CHANGELOGs\n\nFor each README:\n1. Check for Changelog section\n2. Parse entries (Date - Title format)\n3. Compare with recent git commits (if in git repo)\n4. Report missing or malformed entries\n\n### Step 6: Generate Report\n\nCreate validation report in `/tmp/docs-validation-YYYY-MM-DD.md`:\n- Summary (files checked, issues found)\n- Issues by category (Frontmatter, Links, READMEs, CHANGELOGs)\n- Severity levels (Critical, Warning, Info)\n- Recommended actions\n\n---\n\n## Validation Report Format\n\n```markdown\n# Documentation Validation Report\n**Date:** YYYY-MM-DD HH:MM\n**Scope:** $DOCS_ROOT\n**Files Checked:** N\n**Issues Found:** N\n\n## Summary\n\n- âŒ Critical: N (must fix)\n- âš ï¸  Warning: N (should fix)\n- â„¹ï¸  Info: N (consider fixing)\n\n## Critical Issues\n\n### Missing Frontmatter\n- `path/to/file.md` - No frontmatter block found\n\n### Broken Links\n- `path/to/file.md:42` - Link to `missing.md` (file doesn't exist)\n\n## Warnings\n\n### Incomplete Frontmatter\n- `path/to/file.md` - Missing required field: `created`\n\n### Orphaned Files\n- `security/old-config.md` - Not referenced in security/README.md\n\n## Info\n\n### Potential Improvements\n- Consider adding `tags` field to improve queryability\n- README could reference additional files\n\n## Recommended Actions\n\n1. Fix critical issues first (broken links, missing frontmatter)\n2. Address warnings (incomplete frontmatter, orphaned files)\n3. Consider info items for next documentation pass\n\n## Files Validated\n\n- $DOCS_ROOT/*.md (N files)\n- $DOCS_ROOT/security/*.md (N files)\n- $DOCS_ROOT/guides/*.md (N files)\n- ...\n```\n\n---\n\n## Validation Rules Reference\n\n### Required Frontmatter Fields\n\n```yaml\n---\ntitle: \"Brief descriptive title\"\ntype: decision|learning|guide|reference|changelog|environment\ncreated: YYYY-MM-DD\n---\n```\n\n### Optional Frontmatter Fields\n\n```yaml\nupdated: YYYY-MM-DD\ntags: [tag1, tag2, tag3]\nstatus: active|deprecated|superseded\ncategory: \"Primary category\"\nrelated: [path/to/doc.md]\ncommit: abc1234\nenvironment: system-name\n```\n\n### Valid Type Values\n\n| Type | Use Case |\n|------|----------|\n| `decision` | Architectural or operational decisions |\n| `learning` | Lessons learned from incidents or tasks |\n| `guide` | How-to documentation and procedures |\n| `reference` | Reference documentation and indexes |\n| `changelog` | Change history and logs |\n| `environment` | Environment-specific documentation |\n\n### Date Format\n\n- **YYYY-MM-DD** (e.g., 2025-01-15)\n- ISO 8601 compliant\n- Sortable chronologically\n\n### Status Values\n\n| Status | Meaning |\n|--------|---------|\n| `active` | Currently in use |\n| `deprecated` | No longer recommended, but still referenced |\n| `superseded` | Replaced by newer documentation |\n\n---\n\n## Quick Validation Mode\n\nFor fast checks before commits:\n\n**Quick Mode Checks:**\n- âœ… Frontmatter exists\n- âœ… Required fields present\n- âœ… No obvious broken links\n- â© Skip detailed analysis\n\n**Usage:**\n```bash\n# Quick validation (1-2 minutes)\n/skill docs-validator --quick\n\n# Full validation (5-10 minutes)\n/skill docs-validator\n\n# Specific directory\n/skill docs-validator --path $DOCS_ROOT/security\n```\n\n---\n\n## Integration with Other Tools\n\n### With Query Script\n\nWhen `$DOCS_QUERY_SCRIPT` is set, validation ensures all documents are queryable:\n\n```bash\n# After validation, these queries should work\n$DOCS_QUERY_SCRIPT --type guide\n$DOCS_QUERY_SCRIPT --tag security\n$DOCS_QUERY_SCRIPT --status active\n```\n\n### With docs-manager\n\nValidation complements docs-manager:\n- **docs-manager**: Creates and updates documentation\n- **docs-validator**: Ensures quality and compliance\n\n**Workflow:**\n1. Use docs-manager for all documentation updates\n2. Run docs-validator monthly or before major commits\n3. Fix issues identified by validator\n4. Log results to worklog if enabled\n\n### With System Analyzer\n\nValidation can be part of baseline checks:\n- Run validator after baseline capture\n- Include validation report in system audit\n- Track documentation health over time\n\n---\n\n## Common Issues and Fixes\n\n### Missing Frontmatter\n\n**Issue:** File has no YAML frontmatter\n\n**Fix:**\n```bash\n# Add frontmatter to file\ncat > /tmp/frontmatter.txt <<'EOF'\n---\ntitle: \"File Title\"\ntype: guide\ncreated: 2025-01-15\n---\n\nEOF\n\n# Prepend to file\ncat /tmp/frontmatter.txt original.md > new.md\nmv new.md original.md\n```\n\n### Broken Link\n\n**Issue:** `[text](missing.md)` points to non-existent file\n\n**Fix:**\n- Update link to correct path\n- Create missing file if needed\n- Remove link if no longer relevant\n\n### Orphaned File\n\n**Issue:** File exists but not referenced in README\n\n**Fix:**\n```markdown\n# In README.md, add reference:\n\n**[File Title](filename.md)** - Brief description\n\n**Contents:**\n- Key point 1\n- Key point 2\n```\n\n### Malformed Changelog Entry\n\n**Issue:** Changelog entry doesn't follow format\n\n**Fix:**\n```markdown\n# Correct format:\n\n### YYYY-MM-DD - Title\n**Changed:** What changed\n**Why:** Reason for change\n**Impact:** Effect of change\n\n**See also:** Related documentation\n```\n\n---\n\n## Worklog Integration\n\nWhen `$WORKLOG_DB` is set, log validation results:\n\n```bash\nsqlite3 \"$WORKLOG_DB\" \"INSERT INTO entries\n(agent, task_type, title, details, outcome, tags) VALUES (\n'$(hostname)',\n'validation',\n'Documentation validation - $DOCS_ROOT',\n'Checked N files, found N issues (N critical, N warning)',\n'Validation complete - see /tmp/docs-validation-YYYY-MM-DD.md',\n'docs,validation,quality'\n);\"\n```\n\n---\n\n## Automation Opportunities\n\n### Pre-Commit Hook\n\nCould validate before git commits:\n```bash\n#!/bin/bash\n# .git/hooks/pre-commit\n/skill docs-validator --quick\n```\n\n### Monthly Validation Cron\n\nCould be automated to run monthly:\n```bash\n# Add to crontab (if desired)\n0 9 1 * * /skill docs-validator > /tmp/monthly-validation.log\n```\n\n### Integration with CI/CD\n\nIf documentation repo has CI:\n- Run validator on pull requests\n- Block merges with critical issues\n- Generate reports as artifacts\n\n---\n\n## Example Validation Session\n\n**User:** \"Run docs validation\"\n\n**Skill Actions:**\n1. Scan $DOCS_ROOT for all .md files\n2. Check frontmatter compliance (required fields, valid values)\n3. Validate internal links\n4. Check README completeness\n5. Verify CHANGELOG entries\n6. Generate report in /tmp/docs-validation-YYYY-MM-DD.md\n7. Present summary to user\n8. Offer to fix critical issues\n\n**Output:**\n```\nðŸ“‹ Documentation Validation Report\n\nChecked: 42 files\nIssues: 3 critical, 5 warnings, 2 info\n\nâŒ Critical Issues:\n- security/new-policy.md: Missing frontmatter\n- guides/README.md: Broken link to old-guide.md\n- services/deploy.md: Missing required field 'created'\n\nâš ï¸  Warnings:\n- 5 files not referenced in READMEs\n\nâ„¹ï¸  Info:\n- Consider adding tags to 2 files for better queryability\n\nFull report: /tmp/docs-validation-YYYY-MM-DD.md\n\nFix critical issues? (y/n)\n```\n\n---\n\n## Success Criteria\n\n**Good documentation system:**\n- âœ… All files have frontmatter\n- âœ… All links work\n- âœ… Every directory has README\n- âœ… All files referenced\n- âœ… CHANGELOGs current\n- âœ… Structure compliant\n\n**After validation:**\n- Critical issues: 0\n- Warnings: Minimal\n- Info items: Tracked for next pass\n\n---\n\n## For Future Claude Instances\n\n**When to run docs-validator:**\n- Monthly (first of month)\n- After major documentation changes\n- Before important commits\n- When documentation issues suspected\n\n**How to use:**\n```bash\n# Full validation\n/skill docs-validator\n\n# Quick check\n/skill docs-validator --quick\n\n# Specific directory\n/skill docs-validator --path $DOCS_ROOT/security\n```\n\n**Remember:** Validation is proactive. Catch issues before they become problems.\n\n---\n\n**Skill Version:** 2.0.0\n**Philosophy:** Proactive quality assurance. Early detection. Maintainable documentation.\n",
        "plugins/taskflow/.claude-plugin/plugin.json": "{\n  \"name\": \"taskflow\",\n  \"version\": \"2.0.0\",\n  \"description\": \"AI-powered task management with backend abstraction. Supports Local, Plane, GitHub, and Linear backends. Transform PRDs into structured tasks or add ad-hoc tasks with hygiene tracking.\",\n  \"author\": {\n    \"name\": \"gs\"\n  },\n  \"license\": \"MIT\",\n  \"repository\": \"https://github.com/gaurangrshah/gsc-plugins\",\n  \"homepage\": \"https://github.com/gaurangrshah/gsc-plugins/tree/main/plugins/taskflow\",\n  \"keywords\": [\n    \"tasks\",\n    \"project-management\",\n    \"prd\",\n    \"workflow\",\n    \"productivity\",\n    \"checkpoints\",\n    \"dependencies\",\n    \"plane\",\n    \"github\",\n    \"linear\",\n    \"issue-tracking\",\n    \"backend-abstraction\"\n  ]\n}\n",
        "plugins/taskflow/README.md": "# TaskFlow - AI-Powered Task Management\n\nA Claude Code plugin for transforming Product Requirements Documents (PRDs) into structured, dependency-aware tasks with human-in-the-loop checkpoints.\n\n**Version:** 2.0.0\n\n## Overview\n\nTaskFlow bridges the gap between planning and execution. It parses PRDs, generates actionable tasks, tracks dependencies, and provides intelligent task recommendationsâ€”all integrated with Claude Code's native tools.\n\nInspired by [claude-task-master](https://github.com/eyaltoledano/claude-task-master), adapted for multi-environment Claude Code workflows.\n\n## Standalone & Integration\n\n### Works 100% Standalone\n\nTaskFlow is fully self-contained. **No other plugins required.**\n\n```bash\n# This works perfectly with ONLY taskflow installed:\n/task-init\n/task-parse docs/PRD/my-feature.md\n/task next\n```\n\nAll commands work. PRD parsing works. Task tracking works. No errors or warnings about missing plugins.\n\n### Optional Integrations\n\nTaskFlow can be detected and used by other GSC plugins:\n\n#### Used by WebGen/AppGen (Passive)\n\nWhen WebGen or AppGen are installed alongside TaskFlow, they detect TaskFlow and offer to track their workflows as tasks:\n\n```\n# User runs /webgen with TaskFlow installed:\nTaskFlow detected. Track this project with tasks? (y/n)\n```\n\n**TaskFlow doesn't need to do anything**â€”WebGen/AppGen handle the integration. TaskFlow just provides its normal task management capabilities.\n\n**Benefits when used together:**\n- WebGen/AppGen phases become trackable tasks\n- Visual progress during generation\n- Resume capability if interrupted\n- Task history persists after generation\n\n#### Worklog Integration (Passive)\n\nIf [Worklog](../worklog/) is installed, its hooks provide background context:\n\n- **SessionStart hook**: Loads recent work context during task sessions\n- **SessionStop hook**: Prompts to store learnings after task completion\n\nTaskFlow doesn't actively integrate with Worklog yet, but Worklog's general-purpose hooks still fire during TaskFlow sessions.\n\n**Future (Planned):**\n- Auto-log completed tasks to worklog entries table\n- Store task templates to knowledge_base\n- Cross-session task context from memories table\n\n## Quick Start\n\n### 1. Install Plugin\n\n**Option A: Marketplace (Recommended)**\n```bash\n# Add the marketplace (if not already added)\nclaude plugin marketplace add https://github.com/gaurangrshah/gsc-plugins.git\n\n# Install the plugin\nclaude plugin install taskflow@gsc-plugins\n```\n\n**Option B: Manual Installation**\n```bash\n# Clone the repo\ngit clone https://github.com/gaurangrshah/gsc-plugins.git\n\n# Copy to local-plugins\ncp -r gsc-plugins/plugins/taskflow ~/.claude/plugins/local-plugins/\n\n# Restart Claude Code to activate\n```\n\n### 2. Configure (Optional)\n\nCreate `~/.claude/task-config.json`:\n```json\n{\n  \"version\": \"1.1\",\n  \"environments\": {\n    \"my-machine\": {\n      \"hostname\": \"my-machine\",\n      \"workspacePath\": \"/home/user/projects\",\n      \"indexPath\": \"/home/user/projects/.task-index.json\"\n    }\n  },\n  \"defaults\": {\n    \"syncTodoWrite\": true,\n    \"defaultTag\": \"master\"\n  }\n}\n```\n\n### 3. Initialize a Project\n\n```\n/task-init\n```\n\n### 4. Parse a PRD\n\n```\n/task-parse docs/PRD/my-feature.md\n```\n\n### 5. Start Working\n\n```\n/task next\n```\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `/task` | Conversational interface - status overview and natural language routing |\n| `/task-init` | Initialize TaskFlow in current project (with backend selection) |\n| `/task-add` | Add an ad-hoc task (no PRD required) |\n| `/task-parse <prd>` | Generate tasks from a PRD document |\n| `/task-list` | List all tasks with filtering options |\n| `/task-next` | Get AI-recommended next task |\n| `/task-show <id>` | View detailed task information |\n| `/task-status <id> <status>` | Update task status (with hygiene prompts) |\n| `/task-tag` | Manage parallel work contexts (tags) |\n| `/task-expand <id>` | Break task into subtasks |\n| `/task-migrate-config` | Migrate v1.x JSON config to v2.0 format |\n\n## Features\n\n### PRD Parsing\nTransforms markdown PRD documents into structured tasks with:\n- Automatic dependency detection\n- Priority assignment\n- Effort estimation\n- Acceptance criteria extraction\n\n### Intelligent Task Selection\n`/task-next` considers:\n- Dependency satisfaction\n- Priority levels\n- Your recent work context\n- Blocked task avoidance\n\n### Tags for Parallel Work\nWork on multiple features without conflicts:\n```\n/task-tag create feat-auth\n/task-tag switch feat-auth\n# Work in isolated context\n/task-tag switch master\n```\n\n### Human-in-the-Loop Checkpoints\nThree checkpoint stages ensure quality:\n1. **Parse** - Review generated tasks before starting\n2. **Execute** - Confirm approach before implementation\n3. **Complete** - Verify acceptance criteria before closing\n\n### TodoWrite Integration\nActive tasks sync to Claude Code's TodoWrite for real-time visibility.\n\n## Storage Structure\n\n```\nproject/\nâ””â”€â”€ .tasks/\n    â”œâ”€â”€ state.json           # Current tag tracking\n    â””â”€â”€ tags/\n        â”œâ”€â”€ master/\n        â”‚   â””â”€â”€ tasks.json   # Default task list\n        â””â”€â”€ feat-auth/\n            â””â”€â”€ tasks.json   # Feature-specific tasks\n```\n\n## Task Schema\n\n```json\n{\n  \"id\": 1,\n  \"title\": \"Implement user authentication\",\n  \"description\": \"Add JWT-based auth with refresh tokens\",\n  \"status\": \"pending\",\n  \"priority\": \"high\",\n  \"dependencies\": [],\n  \"subtasks\": [],\n  \"acceptanceCriteria\": [\n    \"Users can register with email\",\n    \"Users can login and receive tokens\",\n    \"Tokens refresh automatically\"\n  ],\n  \"prdSection\": \"## Authentication\",\n  \"estimatedEffort\": \"medium\",\n  \"created\": \"2025-12-01T10:00:00Z\",\n  \"updated\": \"2025-12-01T10:00:00Z\"\n}\n```\n\n## Status Values\n\n| Status | Description |\n|--------|-------------|\n| `pending` | Not yet started |\n| `in_progress` | Currently being worked on |\n| `done` | Completed successfully |\n| `blocked` | Waiting on external dependency |\n| `deferred` | Postponed for later |\n\n## Configuration\n\n### Config File Format (v2.0)\n\nTaskFlow v2.0 uses `.local.md` files with YAML frontmatter:\n\n**Project-level:** `./.taskflow.local.md`\n**Global:** `~/.gsc-plugins/taskflow.local.md`\n\n```yaml\n---\nbackend: local  # local | plane | github\n\nlocal:\n  path: .tasks/\n\n# For Plane backend:\n# plane:\n#   workspace: gsdev\n#   project: work\n\n# For GitHub backend:\n# github:\n#   owner: myuser\n#   repo: my-project\n\ndefaults:\n  defaultPriority: medium\n  defaultTag: master\n  syncTodoWrite: true\n\nhygiene:\n  requireCompletionNotes: true\n  requireBlockerReason: true\n  promptForNotes: true\n  autoSyncToWorklog: false\n---\n\n# TaskFlow Configuration\n```\n\n### Backend Options\n\n| Backend | Description | Requirements |\n|---------|-------------|--------------|\n| `local` | Store tasks in `.tasks/` folder | None (default) |\n| `plane` | Sync with Plane issues | Plane MCP configured |\n| `github` | Sync with GitHub Issues | `gh` CLI authenticated |\n\n### Upgrading from v1.x\n\nIf you have an existing `~/.claude/task-config.json`:\n\n```bash\n# Preview migration\n/task-migrate-config --dry-run\n\n# Run migration\n/task-migrate-config\n```\n\nTaskFlow v2.0 is backwards compatible - old configs still work, but you'll see a migration notice.\n\n### Legacy Config (v1.x - deprecated)\n\n```json\n{\n  \"version\": \"1.1\",\n  \"environments\": { ... },\n  \"defaults\": { ... }\n}\n```\n\nThe `environments` section is no longer used. Use project-level `.taskflow.local.md` files instead.\n\n## Natural Language Examples\n\n```\n/task what should I work on next?\n/task I finished the authentication task\n/task show me task 5\n/task break down task 3\n/task I'm blocked on task 2\n```\n\n## Multi-Environment Support\n\nTaskFlow detects your hostname and applies environment-specific configuration automatically. This enables:\n- Different workspace paths per machine\n- Separate task indexes per environment\n- Consistent behavior across systems\n\n## Plugin Structure\n\n```\ntaskflow/\nâ”œâ”€â”€ .claude-plugin/\nâ”‚   â””â”€â”€ plugin.json\nâ”œâ”€â”€ commands/\nâ”‚   â”œâ”€â”€ task.md\nâ”‚   â”œâ”€â”€ task-init.md\nâ”‚   â”œâ”€â”€ task-list.md\nâ”‚   â”œâ”€â”€ task-next.md\nâ”‚   â”œâ”€â”€ task-parse.md\nâ”‚   â”œâ”€â”€ task-show.md\nâ”‚   â”œâ”€â”€ task-status.md\nâ”‚   â”œâ”€â”€ task-tag.md\nâ”‚   â””â”€â”€ task-expand.md\nâ”œâ”€â”€ config/\nâ”‚   â””â”€â”€ default-config.json\nâ”œâ”€â”€ docs/\nâ”‚   â””â”€â”€ design.md\nâ””â”€â”€ README.md\n```\n\n## Design Decisions\n\n| Decision | Choice | Rationale |\n|----------|--------|-----------|\n| Storage | Per-project JSON | Portable, git-friendly |\n| Tags | Isolated contexts | Parallel feature work |\n| TodoWrite | One-way sync | Task system is source of truth |\n| Checkpoints | Human-in-the-loop | Quality over speed |\n\n## Version History\n\n### 2.0.0\n- **Backend abstraction**: Unified interface for Local, Plane, GitHub, Linear backends\n- **New config format**: `.local.md` with YAML frontmatter (project + global scope)\n- **Auto-detection**: Automatically detects available backends (Plane MCP, GitHub CLI)\n- **Task hygiene**: Prompts for completion notes, blocker reasons, decisions, gotchas\n- **Epic support**: Complex tasks become epics with subtasks\n- **Ad-hoc tasks**: New `/task-add` command for tasks without PRDs\n- **Migration command**: `/task-migrate-config` upgrades v1.x configs\n- **Backwards compatible**: Old JSON configs still work with migration notice\n\n### 1.1.0\n- **Issue tracker auto-detection**: Auto-detects Gitea and GitHub during `/task-init`\n- **Dual Gitea detection**: Checks both config files AND git remotes for Gitea availability\n- **GitHub fallback**: Falls back to GitHub Issues via `gh` CLI if Gitea unavailable\n- **Mandatory TodoWrite**: TodoWrite is now required for all TaskFlow projects (dual-write for redundancy)\n- **Enhanced config**: New `issueTracker` and `todoWrite` config sections\n- **Graceful fallbacks**: Works 100% locally if no issue trackers available\n\n### 1.0.0\n- Initial plugin release\n- 9 commands for complete task lifecycle\n- Tag-based parallel work contexts\n- PRD parsing with dependency detection\n- Intelligent task recommendation\n- TodoWrite integration\n- Multi-environment support\n\n## License\n\nMIT\n",
        "plugins/taskflow/commands/task-add.md": "---\nname: task-add\ndescription: Add a new task to TaskFlow (ad-hoc, no PRD required)\nargs: <title> [--priority=high|medium|low] [--type=task|epic] [--description=\"...\"]\nversion: \"2.0\"\n---\n\n# /task-add\n\nAdd a task directly to TaskFlow without needing a PRD.\n\n## Usage\n\n```bash\n# Simple task\n/task-add \"Fix login button styling\"\n\n# With priority\n/task-add \"Implement user auth\" --priority=high\n\n# Create an epic\n/task-add \"User Management System\" --type=epic\n\n# With description\n/task-add \"Add dark mode toggle\" --description=\"Should respect system preference\"\n```\n\n---\n\n## Workflow\n\n### Step 1: Load Backend\n\n```python\n# Load configured backend (or trigger first-run setup)\nbackend = loadBackend()\n\nif not backend:\n    # First run - trigger setup flow\n    # See: _core/backend-loader.md\n    return runFirstTimeSetup()\n```\n\n### Step 2: Parse Arguments\n\n```python\ndef parseArgs(args):\n    # Extract title (required)\n    title = args[0] if args else None\n    if not title:\n        error(\"Task title required. Usage: /task-add \\\"Your task title\\\"\")\n        return\n\n    # Parse flags\n    priority = extractFlag(args, \"--priority\") or \"medium\"\n    task_type = extractFlag(args, \"--type\") or \"task\"\n    description = extractFlag(args, \"--description\") or \"\"\n\n    return {\n        \"title\": title,\n        \"priority\": priority,\n        \"type\": task_type,\n        \"description\": description\n    }\n```\n\n### Step 3: Create Task\n\n```python\ndef createTask(parsed):\n    backend = loadBackend()\n\n    task = backend.createTask({\n        \"title\": parsed[\"title\"],\n        \"description\": parsed[\"description\"],\n        \"priority\": parsed[\"priority\"],\n        \"type\": parsed[\"type\"],\n        \"createdBy\": \"claude\"\n    })\n\n    return task\n```\n\n### Step 4: Confirm & Offer Next Steps\n\n```markdown\n## Task Created\n\n**ID:** {task.id}\n**Title:** {task.title}\n**Priority:** {task.priority}\n**Status:** pending\n\n{if backend.type != \"local\"}\n**Synced to:** {backend.externalUrl}\n{/if}\n\n---\n\n**Next steps:**\n- Start working: `/task-status {task.id} in_progress`\n- Add subtasks: `/task-add \"Subtask\" --parent={task.id}`\n- View all tasks: `/task-list`\n```\n\n---\n\n## Examples\n\n### Basic Task\n\n```bash\n/task-add \"Update README with installation instructions\"\n```\n\nOutput:\n```\nTask Created\n\nID: task-001\nTitle: Update README with installation instructions\nPriority: medium\nStatus: pending\n\nNext steps:\n- Start working: /task-status task-001 in_progress\n- View all tasks: /task-list\n```\n\n### High Priority Task\n\n```bash\n/task-add \"Fix production database connection timeout\" --priority=high\n```\n\nOutput:\n```\nTask Created\n\nID: task-002\nTitle: Fix production database connection timeout\nPriority: high\nStatus: pending\n\nThis is marked HIGH PRIORITY.\n\nNext steps:\n- Start immediately: /task-status task-002 in_progress\n```\n\n### Create Epic\n\n```bash\n/task-add \"Authentication System\" --type=epic --description=\"Complete auth flow with JWT, refresh tokens, and OAuth\"\n```\n\nOutput:\n```\nEpic Created\n\nID: task-003\nTitle: Authentication System\nType: epic\nPriority: medium\nStatus: pending\n\nDescription:\nComplete auth flow with JWT, refresh tokens, and OAuth\n\nEpics can have subtasks. Add them with:\n  /task-add \"Subtask title\" --parent=task-003\n\nOr expand from a description:\n  /task-expand task-003\n```\n\n### With Plane Backend\n\n```bash\n/task-add \"Implement search feature\" --priority=high\n```\n\nOutput:\n```\nTask Created\n\nID: abc123-def456\nTitle: Implement search feature\nPriority: high (urgent in Plane)\nStatus: pending\n\nSynced to: https://plane.example.com/your-workspace/your-project\nIssue: WORK-42\n\nNext steps:\n- Start working: /task-status abc123-def456 in_progress\n- View in Plane: https://plane.example.com/issue/WORK-42\n```\n\n---\n\n## Interactive Mode\n\nIf called without arguments, enter interactive mode:\n\n```bash\n/task-add\n```\n\nPrompts:\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Add New Task                                               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                             â”‚\nâ”‚  Title: _                                                   â”‚\nâ”‚                                                             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\nThen use AskUserQuestion for priority:\n\n```json\n{\n  \"question\": \"What priority level?\",\n  \"header\": \"Priority\",\n  \"options\": [\n    {\"label\": \"Medium (default)\", \"description\": \"Standard priority\"},\n    {\"label\": \"High\", \"description\": \"Urgent or blocking other work\"},\n    {\"label\": \"Low\", \"description\": \"Nice to have, not urgent\"}\n  ],\n  \"multiSelect\": false\n}\n```\n\n---\n\n## Flags Reference\n\n| Flag | Values | Default | Description |\n|------|--------|---------|-------------|\n| `--priority` | high, medium, low | medium | Task priority |\n| `--type` | task, epic | task | Task type |\n| `--description` | string | \"\" | Detailed description |\n| `--parent` | task-id | null | Parent epic ID (creates subtask) |\n| `--no-sync` | flag | false | Skip syncing to external backend |\n\n---\n\n## Error Handling\n\n### No Title Provided\n\n```\nError: Task title required.\n\nUsage: /task-add \"Your task title\"\n\nExamples:\n  /task-add \"Fix login bug\"\n  /task-add \"New feature\" --priority=high\n```\n\n### Backend Not Configured\n\n```\nTaskFlow not configured.\n\nRunning first-time setup...\n\n[Triggers backend-loader first-run flow]\n```\n\n### Backend Connection Failed\n\n```\nWarning: Could not connect to Plane backend.\n\nTask saved locally to .tasks/tasks.json\nSync will retry when backend is available.\n\nTo switch to local-only mode:\n  /task config --backend=local\n```\n\n---\n\n## Integration with TodoWrite\n\nWhen a task is created, optionally add to Claude's TodoWrite:\n\n```python\nif config.defaults.get(\"syncTodoWrite\", True):\n    TodoWrite([\n        {\n            \"content\": task.title,\n            \"status\": \"pending\",\n            \"activeForm\": f\"Working on {task.title[:30]}...\"\n        }\n    ])\n```\n\nThis keeps Claude's visible todo list in sync with TaskFlow.\n\n---\n\n**Command Version:** 2.0\n**Requires:** Backend configured or first-run setup\n",
        "plugins/taskflow/commands/task-expand.md": "---\ndescription: Break a task into smaller subtasks\n---\n\n# /task-expand\n\nBreak down a complex task into smaller, manageable subtasks using AI analysis.\n\n## What This Command Does\n\n1. Load task by ID from `.tasks/tasks.json`\n2. Analyze task complexity and generate subtasks\n3. **CHECKPOINT**: Present subtasks for human review\n4. On approval, save subtasks to task\n5. Update task status if needed\n\n## Arguments\n\n- `<task-id>` - **Required.** Task ID to expand (e.g., `3`)\n- `--num=N` - Optional. Target number of subtasks (default: 3-5)\n- `--force` - Expand even if subtasks already exist (replaces them)\n\n## Prerequisites\n\n- Project must have tasks (`.tasks/tasks.json` exists)\n- Task must exist and not already have subtasks (unless `--force`)\n\n## Workflow\n\n### Step 1: Load Task\n\nRead `.tasks/tasks.json` and find the specified task.\n\nIf task already has subtasks:\n```\nTask 3 already has 4 subtasks:\n  3.1 Create registration endpoint (done)\n  3.2 Create login endpoint (in_progress)\n  3.3 Create token refresh endpoint (pending)\n  3.4 Create logout endpoint (pending)\n\nUse --force to replace existing subtasks, or work with current ones.\n```\n\n### Step 2: Generate Subtasks with AI\n\nUse the following prompt:\n\n---\n\n**SYSTEM PROMPT FOR SUBTASK GENERATION:**\n\n```\nBreak down this task into smaller, actionable subtasks.\n\n## Parent Task\nID: <TASK_ID>\nTitle: <TASK_TITLE>\nDescription: <TASK_DESCRIPTION>\nPriority: <TASK_PRIORITY>\n\nAcceptance Criteria:\n<ACCEPTANCE_CRITERIA>\n\n## Instructions\n1. Create <NUM_SUBTASKS> subtasks that together complete the parent task\n2. Each subtask should be completable in 30-90 minutes\n3. Subtasks should be sequential where there are natural dependencies\n4. First subtask should be the logical starting point\n5. Final subtask should complete/verify the parent task\n\n## Output Format\nReturn ONLY valid JSON (no markdown, no explanation):\n\n{\n  \"subtasks\": [\n    {\n      \"id\": \"<TASK_ID>.1\",\n      \"title\": \"<action-oriented title>\",\n      \"status\": \"pending\"\n    },\n    {\n      \"id\": \"<TASK_ID>.2\",\n      \"title\": \"<action-oriented title>\",\n      \"status\": \"pending\"\n    }\n  ]\n}\n\n## Rules\n- Subtask IDs must be <parent_id>.<sequential_number> (e.g., 3.1, 3.2, 3.3)\n- All subtasks start with status \"pending\"\n- Titles should start with action verbs\n- Together, subtasks should fully address all acceptance criteria\n```\n\n---\n\n### Step 3: Validate Subtasks\n\nBefore presenting to user:\n\n1. **JSON Valid**: Parse without errors\n2. **IDs Correct**: Format is `<parent_id>.<number>`, sequential\n3. **Status Valid**: All are \"pending\"\n4. **Coverage**: Subtasks should address acceptance criteria\n\n### Step 4: CHECKPOINT - Human Review\n\nPresent generated subtasks:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Expanding Task 3: Implement user authentication                 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                 â”‚\nâ”‚ Generated 4 subtasks:                                           â”‚\nâ”‚                                                                 â”‚\nâ”‚   3.1 Set up authentication middleware and JWT utilities        â”‚\nâ”‚   3.2 Create user registration endpoint with validation         â”‚\nâ”‚   3.3 Create login endpoint with token generation               â”‚\nâ”‚   3.4 Implement token refresh and logout endpoints              â”‚\nâ”‚                                                                 â”‚\nâ”‚ Criteria coverage:                                              â”‚\nâ”‚   âœ“ Users can register with email/password â†’ 3.2                â”‚\nâ”‚   âœ“ Users can log in and receive JWT token â†’ 3.3                â”‚\nâ”‚   âœ“ Tokens expire after 24 hours â†’ 3.1, 3.3                     â”‚\nâ”‚   âœ“ Refresh token flow extends session â†’ 3.4                    â”‚\nâ”‚                                                                 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Approve these subtasks?                                         â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\nUse AskUserQuestion:\n\n```json\n{\n  \"question\": \"Approve these subtasks?\",\n  \"header\": \"Subtask Review\",\n  \"options\": [\n    {\"label\": \"Approve\", \"description\": \"Save subtasks to task\"},\n    {\"label\": \"Edit\", \"description\": \"Modify before saving\"},\n    {\"label\": \"Regenerate\", \"description\": \"Try again with different breakdown\"},\n    {\"label\": \"Cancel\", \"description\": \"Keep task without subtasks\"}\n  ],\n  \"multiSelect\": false\n}\n```\n\n### Step 5: Handle Response\n\n**If Approve:**\n- Proceed to save\n\n**If Edit:**\n- Ask which subtask(s) to modify\n- Allow adding/removing/renaming\n- Re-display and confirm\n\n**If Regenerate:**\n- Ask for guidance (more/fewer subtasks, different focus)\n- Re-run Step 2 with adjusted prompt\n- Return to Step 4\n\n**If Cancel:**\n- Exit without changes\n\n### Step 6: Save Subtasks\n\nUpdate the task in `tasks.json`:\n\n```python\ntask.subtasks = generated_subtasks\ntask.updated = now_iso8601()\n\n# If task was pending, could mark as ready for subtask work\n# Status remains unchanged - user starts work via /task-next\n```\n\n### Step 7: Confirm Success\n\n```\nTask expanded successfully!\n\nTask 3: Implement user authentication\n  â””â”€â”€ 4 subtasks created:\n      â—‹ 3.1 Set up authentication middleware and JWT utilities\n      â—‹ 3.2 Create user registration endpoint with validation\n      â—‹ 3.3 Create login endpoint with token generation\n      â—‹ 3.4 Implement token refresh and logout endpoints\n\nNext steps:\n  - Run /task-next to start with subtask 3.1\n  - Run /task-show 3 to see full task details\n  - Run /task-status 3.1 in_progress to start manually\n```\n\n## Error Handling\n\n| Error | Resolution |\n|-------|------------|\n| Task not found | Show available task IDs |\n| Task already has subtasks | Suggest --force or work with existing |\n| Cannot expand subtask | Subtasks cannot have sub-subtasks |\n| Task is done | Cannot expand completed tasks |\n| Generation failed | Retry once, then show error |\n\n## Examples\n\n```bash\n# Expand task 3 into subtasks\n/task-expand 3\n\n# Expand with specific subtask count\n/task-expand 3 --num=6\n\n# Replace existing subtasks\n/task-expand 3 --force\n```\n\n## Related\n\n- Command: /task-show (view task and subtasks)\n- Command: /task-next (start working on subtask)\n- Command: /task-status (update subtask status)\n- Command: /task-parse (initial task generation)\n",
        "plugins/taskflow/commands/task-init.md": "---\nname: task-init\ndescription: Initialize TaskFlow in current project\nargs: [--backend=local|plane|github] [--global]\nversion: \"2.0\"\n---\n\n# /task-init\n\nInitialize TaskFlow task tracking with backend selection.\n\n## Usage\n\n```bash\n/task-init                           # Interactive setup\n/task-init --backend=local           # Quick local setup\n/task-init --backend=plane --global  # Plane as global default\n```\n\n## Arguments\n\n| Flag | Description |\n|------|-------------|\n| `--backend` | Skip detection, use specified backend |\n| `--global` | Save config globally (all projects) |\n| `--project` | Save config for this project only |\n\n---\n\n## Workflow\n\n### Step 1: Check Existing Config\n\n```python\n# Check for existing config\nif exists(\"./.taskflow.local.md\"):\n    print(\"TaskFlow already configured for this project.\")\n    print(\"Use /task config to view or change settings.\")\n    return\n\nif exists(\"~/.gsc-plugins/taskflow.local.md\") and not args.project:\n    print(\"Global TaskFlow config exists.\")\n    response = AskUserQuestion({\n        \"question\": \"Use global config or create project-specific?\",\n        \"header\": \"Config\",\n        \"options\": [\n            {\"label\": \"Use global\", \"description\": \"Apply existing global settings\"},\n            {\"label\": \"Project config\", \"description\": \"Create settings for this project only\"}\n        ]\n    })\n    if response == \"Use global\":\n        print(\"Using global TaskFlow config.\")\n        return\n```\n\n### Step 2: Detect Available Backends\n\nâ†’ See `_core/backend-loader.md` for detection logic\n\n```python\nbackends = detectBackends()\n# Returns: [\n#   {\"name\": \"local\", \"available\": True, ...},\n#   {\"name\": \"plane\", \"available\": True, \"workspace\": \"gsdev\", ...},\n#   {\"name\": \"github\", \"available\": True, \"owner\": \"user\", ...}\n# ]\n```\n\n### Step 3: Display Detection Results\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  TaskFlow Setup                                             â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                             â”‚\nâ”‚  Detected integrations:                                     â”‚\nâ”‚    âœ“ Plane   - workspace: gsdev                             â”‚\nâ”‚    âœ“ GitHub  - authenticated as myuser                      â”‚\nâ”‚    âœ— Linear  - not detected                                 â”‚\nâ”‚                                                             â”‚\nâ”‚  Default: Local .tasks/ (no setup required)                 â”‚\nâ”‚                                                             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Step 4: Select Backend\n\n```python\nif args.backend:\n    selected = args.backend\nelse:\n    # Build options - local always first\n    options = [\n        {\"label\": \"Local only (Recommended)\", \"description\": \"Use .tasks/ - works offline\"}\n    ]\n    for b in backends:\n        if b[\"name\"] != \"local\" and b[\"available\"]:\n            options.append({\"label\": b[\"label\"], \"description\": b[\"description\"]})\n\n    selected = AskUserQuestion({\n        \"question\": \"Where should TaskFlow store tasks?\",\n        \"header\": \"Backend\",\n        \"options\": options\n    })\n```\n\n### Step 5: Backend-Specific Config\n\n#### Local (default)\n\nNo additional config needed.\n\n#### Plane\n\n```python\nif selected == \"Plane\":\n    # Get projects\n    projects = mcp__plane__list_projects(workspace_slug=detected_workspace)\n\n    project = AskUserQuestion({\n        \"question\": \"Which Plane project?\",\n        \"header\": \"Project\",\n        \"options\": [{\"label\": p[\"name\"], \"description\": \"\"} for p in projects[\"results\"]]\n    })\n\n    backend_config = {\n        \"workspace\": detected_workspace,\n        \"project\": project\n    }\n```\n\n#### GitHub\n\n```python\nif selected == \"GitHub\":\n    if detected_repo:\n        confirm = AskUserQuestion({\n            \"question\": f\"Use {detected_owner}/{detected_repo}?\",\n            \"header\": \"Repo\",\n            \"options\": [\n                {\"label\": \"Yes\", \"description\": f\"Use current repo\"},\n                {\"label\": \"Different\", \"description\": \"Specify another\"}\n            ]\n        })\n        if confirm == \"Yes\":\n            backend_config = {\"owner\": detected_owner, \"repo\": detected_repo}\n        else:\n            # Manual input needed\n            pass\n```\n\n### Step 6: Select Scope\n\n```python\nif not args.global and not args.project:\n    scope = AskUserQuestion({\n        \"question\": \"Save configuration for?\",\n        \"header\": \"Scope\",\n        \"options\": [\n            {\"label\": \"This project\", \"description\": \"Save to ./.taskflow.local.md\"},\n            {\"label\": \"All projects\", \"description\": \"Save to ~/.gsc-plugins/taskflow.local.md\"}\n        ]\n    })\nelse:\n    scope = \"All projects\" if args.global else \"This project\"\n```\n\n### Step 7: Write Config\n\n```python\nconfig_content = f\"\"\"---\nbackend: {selected.lower()}\n\n{selected.lower()}:\n{yaml_dump(backend_config)}\n\nhygiene:\n  requireCompletionNotes: true\n  requireBlockerReason: true\n  promptForNotes: true\n  autoSyncToWorklog: false\n---\n\n# TaskFlow Configuration\n\nInitialized: {datetime.now().isoformat()}\n\"\"\"\n\nif scope == \"This project\":\n    path = \"./.taskflow.local.md\"\nelse:\n    path = os.path.expanduser(\"~/.gsc-plugins/taskflow.local.md\")\n    os.makedirs(os.path.dirname(path), exist_ok=True)\n\nwrite_file(path, config_content)\n```\n\n### Step 8: Initialize Local Storage (if local backend)\n\n```python\nif selected.lower() == \"local\":\n    os.makedirs(\".tasks\", exist_ok=True)\n    write_json(\".tasks/tasks.json\", {\n        \"version\": \"2.0\",\n        \"project\": os.path.basename(os.getcwd()),\n        \"created\": datetime.now().isoformat(),\n        \"tasks\": []\n    })\n```\n\n### Step 9: Confirm\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  TaskFlow initialized!                                      â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                             â”‚\nâ”‚  Backend: Local (.tasks/)                                   â”‚\nâ”‚  Config:  ./.taskflow.local.md                              â”‚\nâ”‚                                                             â”‚\nâ”‚  Get started:                                               â”‚\nâ”‚    /task-add \"Your first task\"                              â”‚\nâ”‚    /task-parse docs/PRD/feature.md                          â”‚\nâ”‚    /task-list                                               â”‚\nâ”‚                                                             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n---\n\n## Quick Setup (No Prompts)\n\n```bash\n# Local backend, project scope\n/task-init --backend=local\n\n# Plane backend, global scope\n/task-init --backend=plane --global\n\n# GitHub backend with current repo\n/task-init --backend=github\n```\n\n---\n\n## Reconfigure\n\n```bash\n# View current config\n/task config\n\n# Change backend\n/task config --backend=plane\n\n# Reset and re-init\n/task config --reset\n```\n\n---\n\n**Command Version:** 2.0\n**Triggers:** First-run setup flow\n",
        "plugins/taskflow/commands/task-list.md": "---\nname: task-list\ndescription: List all tasks with status and filtering\nargs: [--status=...] [--priority=...] [--type=...] [--search=\"...\"]\nversion: \"2.0\"\n---\n\n# /task-list\n\nList tasks from the configured backend with optional filtering.\n\n## Usage\n\n```bash\n/task-list [--status=pending,in_progress] [--priority=high] [--type=epic] [--search=\"auth\"]\n```\n\n## Filters\n\n| Flag | Values | Description |\n|------|--------|-------------|\n| `--status` | pending, in_progress, done, blocked, deferred, cancelled | Filter by status |\n| `--priority` | high, medium, low | Filter by priority |\n| `--type` | epic, task, subtask | Filter by type |\n| `--search` | string | Full-text search |\n| `--limit` | number | Max results (default: 20) |\n\n---\n\n## Workflow\n\n### Step 1: Load Backend\n\n```python\nbackend = loadBackend()\nif not backend:\n    triggerSetup()\n    return\n```\n\n### Step 2: Build Filters & Fetch\n\n```python\nfilters = {}\nif args.status:\n    filters[\"status\"] = args.status.split(\",\")\nif args.priority:\n    filters[\"priority\"] = args.priority.split(\",\")\nif args.type:\n    filters[\"type\"] = args.type.split(\",\")\nif args.search:\n    filters[\"search\"] = args.search\nfilters[\"limit\"] = args.limit or 20\n\ntasks = backend.listTasks(filters)\n```\n\n### Step 3: Display\n\n```python\ninfo = backend.getBackendInfo()\n\n# Header\nprint(f\"TaskFlow Tasks ({info['type']})\")\nif info.get(\"externalUrl\"):\n    print(f\"â†’ {info['externalUrl']}\")\nprint()\n\n# Group by status\nfor status in [\"in_progress\", \"pending\", \"blocked\", \"done\"]:\n    group = [t for t in tasks if t[\"status\"] == status]\n    if group:\n        print(f\"{STATUS_LABELS[status]} ({len(group)})\")\n        for task in group:\n            print(formatTask(task))\n        print()\n\n# Summary\nprint(f\"Total: {len(tasks)} tasks\")\n```\n\n---\n\n## Output Format\n\n```\nTaskFlow Tasks (plane)\nâ†’ https://plane.example.com/your-workspace/your-project\n\nIn Progress (2)\nâ— [HIGH] task-001: Implement user authentication\nâ— [MED]  task-002: Add input validation\n\nPending (3)\nâ—‹ [HIGH] task-003: Create API endpoints\nâ—‹ [MED]  task-004: Write unit tests\nâ—‹ [LOW]  task-005: Update documentation\n\nDone (1)\nâœ“ task-006: Set up project structure\n\nTotal: 6 tasks\n```\n\n---\n\n## Examples\n\n```bash\n/task-list                              # All tasks\n/task-list --status=pending             # Pending only\n/task-list --priority=high              # High priority\n/task-list --search=\"auth\"              # Search\n/task-list --type=epic                  # Epics only\n```\n\n---\n\n**Command Version:** 2.0\n",
        "plugins/taskflow/commands/task-migrate-config.md": "---\nname: task-migrate-config\ndescription: Migrate from old JSON config to new .local.md format\nargs: [--dry-run] [--force] [--global]\nversion: \"2.0\"\n---\n\n# /task-migrate-config\n\nMigrate TaskFlow configuration from old JSON format to new `.local.md` format.\n\n## Usage\n\n```bash\n/task-migrate-config                    # Interactive migration\n/task-migrate-config --dry-run          # Preview changes without writing\n/task-migrate-config --force            # Overwrite existing .local.md\n/task-migrate-config --global           # Migrate to global config only\n```\n\n---\n\n## Old Config Format (v1.x)\n\n**Location:** `~/.claude/task-config.json`\n\n```json\n{\n  \"version\": \"1.1\",\n  \"environments\": {\n    \"my-machine\": {\n      \"hostname\": \"my-machine\",\n      \"workspacePath\": \"/home/user/projects\",\n      \"indexPath\": \"/home/user/projects/.task-index.json\"\n    }\n  },\n  \"defaults\": {\n    \"checkpoints\": [\"parse\", \"execute\", \"complete\"],\n    \"syncTodoWrite\": true,\n    \"defaultPriority\": \"medium\",\n    \"defaultNumTasks\": 10,\n    \"defaultTag\": \"master\"\n  }\n}\n```\n\n---\n\n## New Config Format (v2.x)\n\n**Location:** `~/.gsc-plugins/taskflow.local.md` (global) or `./.taskflow.local.md` (project)\n\n```yaml\n---\nbackend: local\n\nlocal:\n  path: .tasks/\n\n# Legacy settings preserved\nlegacy:\n  environments:\n    my-machine:\n      workspacePath: /home/user/projects\n      indexPath: /home/user/projects/.task-index.json\n\ndefaults:\n  defaultPriority: medium\n  defaultTag: master\n  checkpoints:\n    - parse\n    - execute\n    - complete\n  syncTodoWrite: true\n\nhygiene:\n  requireCompletionNotes: true\n  requireBlockerReason: true\n  promptForNotes: true\n  autoSyncToWorklog: false\n---\n\n# TaskFlow Configuration\n\nMigrated from ~/.claude/task-config.json on <timestamp>\n```\n\n---\n\n## Workflow\n\n### Step 1: Check for Existing Config\n\n```python\nold_config_path = os.path.expanduser(\"~/.claude/task-config.json\")\nnew_global_path = os.path.expanduser(\"~/.gsc-plugins/taskflow.local.md\")\nnew_project_path = \"./.taskflow.local.md\"\n\n# Check if old config exists\nif not os.path.exists(old_config_path):\n    print(\"No old config found at ~/.claude/task-config.json\")\n    print(\"Nothing to migrate. Use /task-init to create new config.\")\n    return\n\n# Check if new config already exists\nif os.path.exists(new_global_path) and not args.force:\n    print(f\"New config already exists: {new_global_path}\")\n    print(\"Use --force to overwrite, or delete it first.\")\n    return\n```\n\n### Step 2: Read Old Config\n\n```python\nwith open(old_config_path, 'r') as f:\n    old_config = json.load(f)\n\nversion = old_config.get(\"version\", \"1.0\")\nenvironments = old_config.get(\"environments\", {})\ndefaults = old_config.get(\"defaults\", {})\n\nprint(f\"Found TaskFlow config v{version}\")\nprint(f\"  Environments: {len(environments)}\")\nprint(f\"  Defaults: {len(defaults)} settings\")\n```\n\n### Step 3: Detect Available Backends\n\n```python\n# Detect what backends are available\nbackends = detectBackends()\n\n# Default to local (preserving v1.x behavior)\nsuggested_backend = \"local\"\n\n# If Plane or GitHub available, suggest but don't require\nif any(b[\"name\"] == \"plane\" and b[\"available\"] for b in backends):\n    print(\"\\n  Plane integration detected - you can switch after migration\")\nif any(b[\"name\"] == \"github\" and b[\"available\"] for b in backends):\n    print(\"  GitHub integration detected - you can switch after migration\")\n```\n\n### Step 4: Build New Config\n\n```python\ndef buildNewConfig(old_config, backend=\"local\"):\n    \"\"\"Convert old JSON config to new YAML format.\"\"\"\n\n    new_config = {\n        \"backend\": backend,\n        backend: {\"path\": \".tasks/\"} if backend == \"local\" else {},\n        \"defaults\": {},\n        \"hygiene\": {\n            \"requireCompletionNotes\": True,\n            \"requireBlockerReason\": True,\n            \"promptForNotes\": True,\n            \"autoSyncToWorklog\": False\n        }\n    }\n\n    # Map old defaults to new\n    old_defaults = old_config.get(\"defaults\", {})\n\n    if \"defaultPriority\" in old_defaults:\n        new_config[\"defaults\"][\"defaultPriority\"] = old_defaults[\"defaultPriority\"]\n\n    if \"defaultTag\" in old_defaults:\n        new_config[\"defaults\"][\"defaultTag\"] = old_defaults[\"defaultTag\"]\n\n    if \"checkpoints\" in old_defaults:\n        new_config[\"defaults\"][\"checkpoints\"] = old_defaults[\"checkpoints\"]\n\n    if \"syncTodoWrite\" in old_defaults:\n        new_config[\"defaults\"][\"syncTodoWrite\"] = old_defaults[\"syncTodoWrite\"]\n\n    # Preserve environment configs in legacy section (for reference)\n    if old_config.get(\"environments\"):\n        new_config[\"legacy\"] = {\n            \"environments\": old_config[\"environments\"],\n            \"note\": \"Preserved from v1.x config. Environments are no longer used in v2.x.\"\n        }\n\n    return new_config\n```\n\n### Step 5: Preview Changes (--dry-run)\n\n```python\nif args.dry_run:\n    print(\"\\n--- DRY RUN - No changes will be made ---\\n\")\n    print(\"Old config: ~/.claude/task-config.json\")\n    print(f\"New config: {new_global_path if args.global else 'auto-selected'}\")\n    print(\"\\nNew configuration would be:\")\n    print(\"---\")\n    print(yaml.dump(new_config, default_flow_style=False))\n    print(\"---\")\n    return\n```\n\n### Step 6: Choose Scope\n\n```python\nif not args.global:\n    scope = AskUserQuestion({\n        \"question\": \"Where should the migrated config be saved?\",\n        \"header\": \"Scope\",\n        \"options\": [\n            {\n                \"label\": \"Global (Recommended)\",\n                \"description\": f\"Save to {new_global_path}\"\n            },\n            {\n                \"label\": \"This project only\",\n                \"description\": f\"Save to {new_project_path}\"\n            }\n        ],\n        \"multiSelect\": False\n    })\n\n    target_path = new_global_path if \"Global\" in scope else new_project_path\nelse:\n    target_path = new_global_path\n```\n\n### Step 7: Backup Old Config\n\n```python\n# Create backup directory\nbackup_dir = os.path.expanduser(\"~/.claude/.backups\")\nos.makedirs(backup_dir, exist_ok=True)\n\n# Backup with timestamp\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nbackup_path = f\"{backup_dir}/task-config.json.{timestamp}.bak\"\n\nshutil.copy2(old_config_path, backup_path)\nprint(f\"\\nBackup created: {backup_path}\")\n```\n\n### Step 8: Write New Config\n\n```python\n# Ensure target directory exists\nos.makedirs(os.path.dirname(target_path), exist_ok=True)\n\n# Convert to YAML frontmatter format\nyaml_content = f\"\"\"---\nbackend: {new_config[\"backend\"]}\n\n{new_config[\"backend\"]}:\n{indent(yaml.dump(new_config[new_config[\"backend\"]], default_flow_style=False), \"  \")}\n\ndefaults:\n{indent(yaml.dump(new_config[\"defaults\"], default_flow_style=False), \"  \")}\n\nhygiene:\n{indent(yaml.dump(new_config[\"hygiene\"], default_flow_style=False), \"  \")}\n\n{f\"legacy:\" + chr(10) + indent(yaml.dump(new_config.get(\"legacy\", {}), default_flow_style=False), \"  \") if new_config.get(\"legacy\") else \"\"}\n---\n\n# TaskFlow Configuration\n\nMigrated from ~/.claude/task-config.json\nDate: {datetime.now().isoformat()}\nOriginal version: {old_config.get(\"version\", \"unknown\")}\n\n## Changes in v2.0\n\n- Backend abstraction: Local, Plane, GitHub, Linear support\n- Task hygiene: Notes for decisions, gotchas, workarounds\n- Epic support: Complex tasks become epics with subtasks\n- Project/global scope: Per-project or global settings\n\n## Switch Backend\n\nTo use a different backend:\n\n```bash\n/task config --backend=plane\n/task config --backend=github\n```\n\"\"\"\n\nwith open(target_path, 'w') as f:\n    f.write(yaml_content)\n\nprint(f\"New config written: {target_path}\")\n```\n\n### Step 9: Offer to Remove Old Config\n\n```python\nresponse = AskUserQuestion({\n    \"question\": \"Remove old config file?\",\n    \"header\": \"Cleanup\",\n    \"options\": [\n        {\n            \"label\": \"Yes, remove it\",\n            \"description\": \"Delete ~/.claude/task-config.json (backup preserved)\"\n        },\n        {\n            \"label\": \"No, keep both\",\n            \"description\": \"Keep old config for reference\"\n        }\n    ],\n    \"multiSelect\": False\n})\n\nif \"Yes\" in response:\n    os.remove(old_config_path)\n    print(\"Old config removed.\")\nelse:\n    print(\"Old config preserved at ~/.claude/task-config.json\")\n```\n\n### Step 10: Confirm Success\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Migration Complete!                                        â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                             â”‚\nâ”‚  Old config: ~/.claude/task-config.json                     â”‚\nâ”‚  New config: ~/.gsc-plugins/taskflow.local.md               â”‚\nâ”‚  Backup: ~/.claude/.backups/task-config.json.20260112.bak   â”‚\nâ”‚                                                             â”‚\nâ”‚  Backend: local (default - preserves v1.x behavior)         â”‚\nâ”‚  Environments: Preserved in 'legacy' section                â”‚\nâ”‚                                                             â”‚\nâ”‚  To switch backends:                                        â”‚\nâ”‚    /task config --backend=plane                             â”‚\nâ”‚    /task config --backend=github                            â”‚\nâ”‚                                                             â”‚\nâ”‚  Test your setup:                                           â”‚\nâ”‚    /task-list                                               â”‚\nâ”‚                                                             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n---\n\n## Field Mapping\n\n| Old Field (v1.x) | New Field (v2.x) | Notes |\n|------------------|------------------|-------|\n| `version` | *(removed)* | Version in plugin.json |\n| `environments.*.workspacePath` | `legacy.environments.*.workspacePath` | Preserved for reference |\n| `environments.*.indexPath` | `legacy.environments.*.indexPath` | No longer used |\n| `defaults.checkpoints` | `defaults.checkpoints` | Direct mapping |\n| `defaults.syncTodoWrite` | `defaults.syncTodoWrite` | Direct mapping |\n| `defaults.defaultPriority` | `defaults.defaultPriority` | Direct mapping |\n| `defaults.defaultNumTasks` | *(removed)* | No longer configurable |\n| `defaults.defaultTag` | `defaults.defaultTag` | Direct mapping |\n| *(new)* | `backend` | Backend type |\n| *(new)* | `hygiene.*` | Task hygiene settings |\n\n---\n\n## Error Handling\n\n### Old Config Not Found\n\n```\nNo old config found at ~/.claude/task-config.json\n\nNothing to migrate. TaskFlow v2.0 will auto-configure on first use.\nRun /task-init or any /task-* command to get started.\n```\n\n### New Config Already Exists\n\n```\nTaskFlow v2.0 config already exists:\n  ~/.gsc-plugins/taskflow.local.md\n\nOptions:\n  1. Use --force to overwrite\n  2. Delete existing file and run migration again\n  3. Keep existing config (no migration needed)\n```\n\n### Invalid JSON in Old Config\n\n```\nError reading old config: ~/.claude/task-config.json\n\n  JSON parse error at line 5: unexpected token\n\nFix the JSON syntax error and try again, or use:\n  /task-init --force\nto create fresh config (old settings will be lost).\n```\n\n---\n\n## Examples\n\n```bash\n# Preview what migration would do\n/task-migrate-config --dry-run\n\n# Migrate to global config\n/task-migrate-config --global\n\n# Force overwrite existing config\n/task-migrate-config --force\n\n# Full migration with cleanup\n/task-migrate-config\n# Follow prompts to choose scope and cleanup\n```\n\n---\n\n**Command Version:** 2.0\n**One-time operation:** Only needed when upgrading from v1.x to v2.x\n",
        "plugins/taskflow/commands/task-next.md": "---\ndescription: Get the recommended next task to work on\n---\n\n# /task-next\n\nDetermine and display the optimal next task based on dependencies, priority, and status.\n\n## What This Command Does\n\n1. Load tasks from current tag's `tasks.json`\n2. Apply selection algorithm (dependencies satisfied, priority, blocking factor)\n3. **CHECKPOINT**: Present task for approval before starting\n4. On approval, mark as `in_progress` and sync to TodoWrite\n\n## Arguments\n\n- `--skip` - Skip the recommended task and show the next alternative\n- `--no-checkpoint` - Start immediately without confirmation\n- `--tag=<name>` - Get next task from specific tag (default: current tag)\n\n## Prerequisites\n\n- Project must be initialized (`.tasks/state.json` exists)\n- Current tag must have tasks\n- At least one task must be actionable (pending with satisfied dependencies)\n\n## Workflow\n\n### Step 1: Load Tasks\n\n**Load current tag and tasks:**\n\n```python\nif not exists(\".tasks/state.json\"):\n    error(\"TaskFlow not initialized.\")\n    suggest(\"Run /task-init first\")\n    exit()\n\nstate = read_json(\".tasks/state.json\")\ncurrent_tag = args.tag or state[\"currentTag\"]\ntasks_file = f\".tasks/tags/{current_tag}/tasks.json\"\n\nif not exists(tasks_file):\n    error(f\"Tag '{current_tag}' has no tasks file.\")\n    suggest(\"Run /task-parse to generate tasks\")\n    exit()\n\ndata = read_json(tasks_file)\ntasks = data[\"tasks\"]\n\nif not tasks:\n    error(\"No tasks in current tag.\")\n    suggest(\"Run /task-parse docs/PRD/your-feature.md\")\n    exit()\n```\n\n**Show tag context in output:**\n```\n[Tag: feat-auth]  # Only show if not 'master'\n```\n\n### Step 2: Check for In-Progress Tasks\n\nFirst, check if there's already a task in progress:\n\n```python\n# Check both top-level tasks and subtasks\nin_progress = []\nfor task in tasks:\n    if task[\"status\"] == \"in_progress\":\n        in_progress.append(task)\n    for subtask in task.get(\"subtasks\", []):\n        if subtask[\"status\"] == \"in_progress\":\n            in_progress.append({\"parent\": task, \"subtask\": subtask})\n\nif in_progress:\n    display_current_task(in_progress[0])\n    ask_continue_or_switch()\n```\n\n**If task already in progress:**\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ You have a task in progress                                     â”‚\nâ”‚ [Tag: master]                                                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                 â”‚\nâ”‚ â— Task 3: Implement user authentication                         â”‚\nâ”‚   Priority: HIGH                                                â”‚\nâ”‚   Started: 2025-11-29 14:30 (2 hours ago)                       â”‚\nâ”‚                                                                 â”‚\nâ”‚   Subtasks:                                                     â”‚\nâ”‚   âœ“ 3.1 Create registration endpoint                            â”‚\nâ”‚   â— 3.2 Create login endpoint (in progress)                     â”‚\nâ”‚   â—‹ 3.3 Create token refresh endpoint                           â”‚\nâ”‚                                                                 â”‚\nâ”‚   Acceptance Criteria remaining:                                â”‚\nâ”‚   â˜ Users can log in and receive JWT token                      â”‚\nâ”‚   â˜ Refresh token flow extends session                          â”‚\nâ”‚                                                                 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Continue with this task?                                        â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\nUse AskUserQuestion:\n\n```json\n{\n  \"question\": \"Continue with current task?\",\n  \"header\": \"In Progress\",\n  \"options\": [\n    {\"label\": \"Continue\", \"description\": \"Keep working on this task\"},\n    {\"label\": \"Complete\", \"description\": \"Mark as done and get next\"},\n    {\"label\": \"Switch\", \"description\": \"Work on different task\"},\n    {\"label\": \"Block\", \"description\": \"Mark as blocked, get next\"}\n  ],\n  \"multiSelect\": false\n}\n```\n\n### Step 3: Select Next Task\n\nApply selection algorithm:\n\n```python\ndef get_next_task(tasks, skip_ids=None):\n    skip_ids = skip_ids or set()\n\n    # Build task lookup for dependency checking\n    task_map = {t[\"id\"]: t for t in tasks}\n\n    # Filter to actionable tasks\n    candidates = [t for t in tasks\n                  if t[\"status\"] in (\"pending\", \"blocked\")\n                  and t[\"id\"] not in skip_ids]\n\n    # Check dependency satisfaction\n    actionable = []\n    for task in candidates:\n        deps_satisfied = all(\n            task_map.get(dep_id, {}).get(\"status\") == \"done\"\n            for dep_id in task.get(\"dependencies\", [])\n        )\n        if deps_satisfied:\n            # If task was blocked but deps now satisfied, it's actionable\n            actionable.append(task)\n\n    if not actionable:\n        return None\n\n    # Calculate blocking factor (how many tasks depend on this one)\n    def count_dependents(task_id):\n        return sum(1 for t in tasks if task_id in t.get(\"dependencies\", []))\n\n    # Priority weights\n    priority_weight = {\"high\": 3, \"medium\": 2, \"low\": 1}\n\n    # Sort by: priority DESC, blocking_count DESC, id ASC\n    actionable.sort(key=lambda t: (\n        -priority_weight.get(t.get(\"priority\", \"medium\"), 2),\n        -count_dependents(t[\"id\"]),\n        t[\"id\"]\n    ))\n\n    return actionable[0]\n```\n\n**Handle subtask selection:**\n\nIf selected task has subtasks, return the first pending subtask instead:\n\n```python\ntask = get_next_task(tasks)\nif task and task.get(\"subtasks\"):\n    pending_subtasks = [s for s in task[\"subtasks\"] if s[\"status\"] == \"pending\"]\n    if pending_subtasks:\n        return {\"parent\": task, \"subtask\": pending_subtasks[0]}\nreturn task\n```\n\n### Step 4: Handle No Available Tasks\n\n**If all tasks blocked:**\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ No actionable tasks available                                   â”‚\nâ”‚ [Tag: master]                                                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                 â”‚\nâ”‚ Current status:                                                 â”‚\nâ”‚   âœ“ Done: 3 tasks                                               â”‚\nâ”‚   â— In Progress: 1 task (Task 4)                                â”‚\nâ”‚   â—Œ Blocked: 2 tasks (waiting on Task 4)                        â”‚\nâ”‚   â—‹ Pending: 0 tasks                                            â”‚\nâ”‚                                                                 â”‚\nâ”‚ Blocked tasks and their blockers:                               â”‚\nâ”‚   Task 5 â† waiting on: Task 4 (in_progress)                     â”‚\nâ”‚   Task 6 â† waiting on: Task 4 (in_progress), Task 5 (blocked)   â”‚\nâ”‚                                                                 â”‚\nâ”‚ Action needed:                                                  â”‚\nâ”‚   Complete Task 4 to unblock Tasks 5, 6                         â”‚\nâ”‚                                                                 â”‚\nâ”‚ Run /task-show 4 to see details.                                â”‚\nâ”‚                                                                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**If all tasks done:**\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ All tasks complete!                                             â”‚\nâ”‚ [Tag: master]                                                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                 â”‚\nâ”‚ Project: my-project                                             â”‚\nâ”‚ Tasks completed: 8/8                                            â”‚\nâ”‚ Duration: Started 2025-11-28, completed 2025-11-29              â”‚\nâ”‚                                                                 â”‚\nâ”‚ What's next?                                                    â”‚\nâ”‚   â€¢ Parse another PRD: /task-parse docs/PRD/next-feature.md     â”‚\nâ”‚   â€¢ Create new tag: /task-tag create phase-2                    â”‚\nâ”‚   â€¢ Switch tags: /task-tag use feat-auth                        â”‚\nâ”‚                                                                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**If no tasks at all:**\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ No tasks in tag 'master'                                        â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                 â”‚\nâ”‚ Get started:                                                    â”‚\nâ”‚   1. Create a PRD in docs/PRD/your-feature.md                   â”‚\nâ”‚   2. Run: /task-parse docs/PRD/your-feature.md                  â”‚\nâ”‚                                                                 â”‚\nâ”‚ Or switch to a tag with tasks:                                  â”‚\nâ”‚   /task-tag list                                                â”‚\nâ”‚                                                                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Step 5: CHECKPOINT - Confirm Task Start\n\nPresent the selected task for approval:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Recommended Next Task                                           â”‚\nâ”‚ [Tag: master]                                                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                 â”‚\nâ”‚ Task 3: Implement user authentication                           â”‚\nâ”‚                                                                 â”‚\nâ”‚ Priority:     HIGH                                              â”‚\nâ”‚ Dependencies: âœ“ All satisfied                                   â”‚\nâ”‚   âœ“ Task 1: Set up project structure (done)                     â”‚\nâ”‚   âœ“ Task 2: Implement database schema (done)                    â”‚\nâ”‚                                                                 â”‚\nâ”‚ Description:                                                    â”‚\nâ”‚ Set up JWT-based authentication flow with login, logout, and    â”‚\nâ”‚ token refresh capabilities.                                     â”‚\nâ”‚                                                                 â”‚\nâ”‚ Acceptance Criteria:                                            â”‚\nâ”‚ â˜ Users can register with email/password                        â”‚\nâ”‚ â˜ Users can log in and receive JWT token                        â”‚\nâ”‚ â˜ Tokens expire after 24 hours                                  â”‚\nâ”‚ â˜ Refresh token flow extends session                            â”‚\nâ”‚                                                                 â”‚\nâ”‚ Impact:                                                         â”‚\nâ”‚ This task blocks 2 other tasks (4, 5)                           â”‚\nâ”‚                                                                 â”‚\nâ”‚ Alternatives available: 1 other actionable task                 â”‚\nâ”‚                                                                 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Ready to start this task?                                       â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\nUse AskUserQuestion:\n\n```json\n{\n  \"question\": \"Ready to start this task?\",\n  \"header\": \"Start Task\",\n  \"options\": [\n    {\"label\": \"Yes\", \"description\": \"Mark as in_progress and begin\"},\n    {\"label\": \"Skip\", \"description\": \"Show next available task\"},\n    {\"label\": \"Expand\", \"description\": \"Break into subtasks first\"},\n    {\"label\": \"Details\", \"description\": \"Show full task details\"}\n  ],\n  \"multiSelect\": false\n}\n```\n\n### Step 6: Handle Response\n\n**If Yes:**\n- Update task status to `in_progress`\n- Update `updated` timestamp\n- Save to tasks.json\n- Sync to TodoWrite\n- Display \"Task started\" confirmation\n\n**If Skip:**\n- Add task ID to session skip list\n- Re-run selection excluding skipped tasks\n- If no more tasks available after skipping, inform user\n- Return to Step 5 with next candidate\n\n```\nSkipped Task 3. Checking for alternatives...\n\n[Shows next task or \"No other actionable tasks available\"]\n```\n\n**If Expand:**\n- Trigger `/task-expand <id>` flow\n- After expansion, return and show first subtask\n\n**If Details:**\n- Trigger `/task-show <id>` flow\n- After viewing, return to checkpoint\n\n### Step 7: Sync to TodoWrite\n\nOn task start, sync current state to TodoWrite:\n\n```python\ntodos = []\n\n# Current task (with subtasks if any)\nif task.get(\"subtasks\"):\n    for subtask in task[\"subtasks\"]:\n        todos.append({\n            \"content\": subtask[\"title\"],\n            \"status\": map_status(subtask[\"status\"]),\n            \"activeForm\": to_active_form(subtask[\"title\"])\n        })\nelse:\n    todos.append({\n        \"content\": task[\"title\"],\n        \"status\": \"in_progress\",\n        \"activeForm\": to_active_form(task[\"title\"])\n    })\n\n# Upcoming tasks for context (max 3)\nupcoming = get_next_tasks(tasks, exclude=task[\"id\"], limit=3)\nfor t in upcoming:\n    todos.append({\n        \"content\": t[\"title\"],\n        \"status\": \"pending\",\n        \"activeForm\": to_active_form(t[\"title\"])\n    })\n\nTodoWrite(todos=todos)\n\ndef map_status(task_status):\n    return {\n        \"done\": \"completed\",\n        \"in_progress\": \"in_progress\",\n        \"pending\": \"pending\",\n        \"blocked\": \"pending\",\n        \"deferred\": \"pending\"\n    }.get(task_status, \"pending\")\n\ndef to_active_form(title):\n    \"\"\"Convert 'Create login endpoint' to 'Creating login endpoint'\"\"\"\n    verb_mappings = {\n        \"Create\": \"Creating\",\n        \"Implement\": \"Implementing\",\n        \"Add\": \"Adding\",\n        \"Configure\": \"Configuring\",\n        \"Set up\": \"Setting up\",\n        \"Build\": \"Building\",\n        \"Write\": \"Writing\",\n        \"Fix\": \"Fixing\",\n        \"Update\": \"Updating\",\n        \"Remove\": \"Removing\",\n        \"Refactor\": \"Refactoring\",\n        \"Test\": \"Testing\",\n        \"Deploy\": \"Deploying\",\n    }\n    for verb, active in verb_mappings.items():\n        if title.startswith(verb + \" \"):\n            return title.replace(verb + \" \", active + \" \", 1)\n        if title.startswith(verb.lower() + \" \"):\n            return title.replace(verb.lower() + \" \", active.lower() + \" \", 1)\n    # Fallback: prepend \"Working on\"\n    return f\"Working on {title}\"\n```\n\n### Step 8: Confirm Start\n\n```\nTask started: Implement user authentication\n\n  Status: in_progress â—\n  Tag: master\n  Started: 2025-11-29 14:30\n\nAcceptance Criteria to complete:\n  â˜ Users can register with email/password\n  â˜ Users can log in and receive JWT token\n  â˜ Tokens expire after 24 hours\n  â˜ Refresh token flow extends session\n\nWhen done, run: /task-status 3 done\n\nTodoWrite synced âœ“\n```\n\n## Edge Cases\n\n### Multiple Tasks In Progress\n\nIf somehow multiple tasks are in progress (shouldn't happen normally):\n\n```\nWarning: Multiple tasks are in progress:\n  â— Task 3: Implement authentication\n  â— Task 5: Add caching\n\nThis may indicate interrupted work. Please choose one to continue:\n```\n\n### All Skipped\n\nIf user skips all actionable tasks:\n\n```\nAll actionable tasks have been skipped.\n\nSkipped: Task 3, Task 5, Task 7\n\nOptions:\n  â€¢ Clear skips and start over: /task-next\n  â€¢ View all tasks: /task-list\n  â€¢ Work on a specific task: /task-status <id> in_progress\n```\n\n### Task Has Already-Started Subtasks\n\nIf task has subtasks and some are already in progress:\n\n```\nTask 3 has a subtask in progress:\n  â— 3.2 Create login endpoint\n\nContinue with subtask 3.2?\n```\n\n### Circular Skip Detection\n\nIf skip would create circular situation:\n\n```\nCannot skip Task 3 - it's the only actionable task.\n\nOptions:\n  â€¢ Start Task 3\n  â€¢ Mark a blocking task as done: /task-status <id> done\n  â€¢ Defer Task 3: /task-status 3 deferred\n```\n\n## Error Handling\n\n| Error | Resolution |\n|-------|------------|\n| No `.tasks/state.json` | Prompt to run `/task-init` |\n| Tag doesn't exist | Suggest valid tags or create new |\n| No tasks in tag | Prompt to run `/task-parse` |\n| No tasks file | Tag exists but no tasks.json - suggest parse |\n| All tasks blocked | Show blocking chain and how to unblock |\n| All tasks done | Celebrate and suggest next steps |\n| All tasks skipped | Offer to clear skips |\n\n## Examples\n\n```bash\n# Get next recommended task\n/task-next\n\n# Skip current recommendation\n/task-next --skip\n\n# Start without confirmation\n/task-next --no-checkpoint\n\n# Get next from specific tag\n/task-next --tag=feat-auth\n```\n\n## Related\n\n- Command: /task-list (see all tasks)\n- Command: /task-show (detailed task view)\n- Command: /task-status (mark task done)\n- Command: /task-expand (break into subtasks)\n- Command: /task-tag (manage tags)\n",
        "plugins/taskflow/commands/task-parse.md": "---\ndescription: Parse PRD document into structured tasks\n---\n\n# /task-parse\n\nParse a Product Requirements Document (PRD) and generate structured, dependency-aware tasks.\n\n## What This Command Does\n\n1. Read the specified PRD file\n2. Analyze content using AI to extract tasks\n3. Generate structured tasks with dependencies and acceptance criteria\n4. **CHECKPOINT**: Present tasks for human review\n5. On approval, save to current tag's `tasks.json`\n6. Update central index stats\n\n## Arguments\n\n- `<prd-path>` - **Required.** Path to PRD file (relative to project root, typically `docs/PRD/*.md`)\n- `--num-tasks=N` - Optional. Hint for target number of tasks (default: 10)\n- `--append` - Append to existing tasks instead of replacing\n- `--tag=<name>` - Parse into specific tag (default: current tag)\n\n## Prerequisites\n\n- Project must be initialized (`/task-init` run first)\n- `.tasks/` directory must exist\n- PRD file should exist (typically in `docs/PRD/` directory)\n\n## PRD Location Convention\n\nPRD files should be stored in:\n```\n<project-root>/docs/PRD/<feature-name>.md\n```\n\nExamples:\n- `docs/PRD/user-authentication.md`\n- `docs/PRD/api-v2.md`\n- `docs/PRD/dashboard-redesign.md`\n\n## Workflow\n\n### Step 1: Validate Setup\n\n**Check TaskFlow initialized:**\n```python\nif not exists(\".tasks/state.json\"):\n    error(\"TaskFlow not initialized in this project.\")\n    suggest(\"Run /task-init first\")\n    exit()\n```\n\n**Load current tag:**\n```python\nstate = read_json(\".tasks/state.json\")\ncurrent_tag = args.tag or state[\"currentTag\"]\ntasks_file = f\".tasks/tags/{current_tag}/tasks.json\"\n\nif not exists(tasks_file):\n    error(f\"Tag '{current_tag}' does not exist.\")\n    suggest(f\"Run /task-tag create {current_tag}\")\n    exit()\n```\n\n### Step 2: Read PRD\n\n**Try to find and read PRD file:**\n\n```python\nprd_path = args.prd_path\n\n# Handle relative paths\nif not prd_path.startswith('/'):\n    prd_path = os.path.join(project_root, prd_path)\n\nif not exists(prd_path):\n    # Try common variations\n    alternatives = [\n        f\"docs/PRD/{prd_path}\",\n        f\"docs/PRD/{prd_path}.md\",\n        f\"docs/{prd_path}\",\n    ]\n    # Check each alternative...\n```\n\n**If file doesn't exist:**\n```\nPRD file not found: docs/PRD/feature.md\n\nSearched locations:\n  âœ— docs/PRD/feature.md\n  âœ— docs/PRD/feature\n  âœ— docs/feature.md\n\nAvailable PRDs in docs/PRD/:\n  â€¢ user-authentication.md (3.2 KB)\n  â€¢ api-redesign.md (5.1 KB)\n  â€¢ dashboard-v2.md (2.8 KB)\n\nUsage: /task-parse docs/PRD/<filename>.md\n```\n\n**If file is empty or too short:**\n```\nPRD file appears to be empty or incomplete: docs/PRD/feature.md\n\nSize: 45 bytes (expected: 500+ bytes for meaningful task generation)\n\nA good PRD typically includes:\n  â€¢ Feature description and goals\n  â€¢ User stories or use cases\n  â€¢ Technical requirements\n  â€¢ Success criteria\n  â€¢ Dependencies\n\nSee: ~/.claude/knowledge/guides/taskflow-design.md for PRD tips\n```\n\n**If file is very large (>50KB):**\n```\nPRD file is large: docs/PRD/full-spec.md (127 KB)\n\nLarge PRDs may generate many tasks. Options:\n  1. Parse anyway (may generate 20+ tasks)\n  2. Specify --num-tasks=N to limit scope\n  3. Split PRD into smaller feature documents\n\nProceed with full PRD? [Y/n]\n```\n\n### Step 3: Check Existing Tasks\n\n**If tag already has tasks and not using --append:**\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Tag 'master' already has tasks                                  â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                 â”‚\nâ”‚ Current tasks: 8 (3 done, 1 in progress, 4 pending)             â”‚\nâ”‚ PRD source: docs/PRD/original-feature.md                        â”‚\nâ”‚                                                                 â”‚\nâ”‚ Parsing new PRD will REPLACE existing tasks.                    â”‚\nâ”‚                                                                 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Options:                                                        â”‚\nâ”‚   â€¢ Replace all tasks (existing progress lost)                  â”‚\nâ”‚   â€¢ Append new tasks (use --append)                             â”‚\nâ”‚   â€¢ Create new tag (use --tag=<name>)                           â”‚\nâ”‚   â€¢ Cancel                                                      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Step 4: Parse with AI\n\nUse the following prompt to generate tasks:\n\n---\n\n**SYSTEM PROMPT FOR TASK GENERATION:**\n\n```\nAnalyze this Product Requirements Document and generate a structured task breakdown.\n\n## Instructions\n1. Identify discrete, implementable units of work\n2. Establish dependencies (what must complete before what)\n3. Order by logical implementation sequence\n4. Each task should be completable in a focused work session (1-4 hours)\n5. Include clear, measurable acceptance criteria for each task\n6. Assign priority based on:\n   - high: Foundational work, blocks other tasks\n   - medium: Important features, some dependencies\n   - low: Nice-to-have, no blockers\n\n## Output Format\nReturn ONLY valid JSON matching this exact schema (no markdown, no explanation, no code fences):\n\n{\n  \"tasks\": [\n    {\n      \"id\": 1,\n      \"title\": \"<concise action-oriented title - start with verb>\",\n      \"description\": \"<what needs to be done and why - 1-3 sentences>\",\n      \"status\": \"pending\",\n      \"priority\": \"high|medium|low\",\n      \"dependencies\": [],\n      \"subtasks\": [],\n      \"acceptanceCriteria\": [\n        \"<specific, measurable criterion>\",\n        \"<another criterion>\"\n      ]\n    }\n  ]\n}\n\n## Rules\n- IDs must be sequential integers starting at 1\n- No circular dependencies allowed\n- Task 1 MUST have empty dependencies array (entry point)\n- Dependencies reference task IDs that must complete first\n- Each task needs 2-5 acceptance criteria\n- Titles should start with action verbs (Create, Implement, Add, Configure, etc.)\n- Keep descriptions focused on WHAT and WHY, not HOW\n- Do NOT include markdown code fences or any text outside the JSON\n\n## Target Task Count\nAim for approximately <NUM_TASKS> top-level tasks. Break down further only if a task would take more than 4 hours.\n\n## PRD Content\n<PRD_CONTENT>\n```\n\n---\n\n### Step 5: Validate Generated Tasks\n\n**Validation checks (in order):**\n\n1. **JSON Valid**: Parse without errors\n   - Strip markdown code fences if present\n   - Handle common JSON errors (trailing commas, single quotes)\n\n2. **Schema Complete**: All required fields present\n   ```python\n   required_fields = [\"id\", \"title\", \"description\", \"status\", \"priority\", \"dependencies\", \"acceptanceCriteria\"]\n   for task in tasks:\n       missing = [f for f in required_fields if f not in task]\n       if missing:\n           error(f\"Task {task.get('id', '?')} missing fields: {missing}\")\n   ```\n\n3. **No Circular Dependencies**: Build and validate graph\n   ```python\n   def has_cycle(tasks):\n       # Build adjacency list\n       # Run DFS cycle detection\n       # Return cycle path if found\n   ```\n\n4. **Dependencies Exist**: All referenced IDs valid\n   ```python\n   task_ids = {t[\"id\"] for t in tasks}\n   for task in tasks:\n       for dep in task[\"dependencies\"]:\n           if dep not in task_ids:\n               error(f\"Task {task['id']} depends on non-existent task {dep}\")\n   ```\n\n5. **Has Entry Point**: At least one task with no dependencies\n   ```python\n   entry_points = [t for t in tasks if not t[\"dependencies\"]]\n   if not entry_points:\n       error(\"No entry point task (all tasks have dependencies)\")\n   ```\n\n6. **IDs Sequential**: No gaps or duplicates\n   ```python\n   ids = sorted([t[\"id\"] for t in tasks])\n   expected = list(range(1, len(tasks) + 1))\n   if ids != expected:\n       error(f\"IDs should be {expected}, got {ids}\")\n   ```\n\n**If validation fails:**\n```\nValidation errors in generated tasks:\n\n  âœ— Task 3 depends on non-existent task 7\n  âœ— Circular dependency: 4 â†’ 5 â†’ 6 â†’ 4\n  âœ— Task 2 missing 'acceptanceCriteria' field\n\nAttempting to fix automatically...\n[If fixable, show fixed version]\n[If not, offer to regenerate]\n```\n\n### Step 6: CHECKPOINT - Human Review\n\nPresent generated tasks for approval:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ PRD Parsed: <N> tasks generated                                 â”‚\nâ”‚ Source: <prd-path>                                              â”‚\nâ”‚ Tag: <current-tag>                                              â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                 â”‚\nâ”‚  1. [HIGH] <Task 1 title>                                       â”‚\nâ”‚     â””â”€â”€ No dependencies                                         â”‚\nâ”‚     â””â”€â”€ Criteria: <count> acceptance criteria                   â”‚\nâ”‚                                                                 â”‚\nâ”‚  2. [HIGH] <Task 2 title>                          (needs: 1)   â”‚\nâ”‚     â””â”€â”€ Depends on: Task 1                                      â”‚\nâ”‚     â””â”€â”€ Criteria: <count> acceptance criteria                   â”‚\nâ”‚                                                                 â”‚\nâ”‚  3. [MED]  <Task 3 title>                          (needs: 1,2) â”‚\nâ”‚     â””â”€â”€ Depends on: Task 1, Task 2                              â”‚\nâ”‚     â””â”€â”€ Criteria: <count> acceptance criteria                   â”‚\nâ”‚                                                                 â”‚\nâ”‚  ... (show all tasks)                                           â”‚\nâ”‚                                                                 â”‚\nâ”‚ Summary:                                                        â”‚\nâ”‚   HIGH: <count> | MEDIUM: <count> | LOW: <count>                â”‚\nâ”‚   Estimated entry points: <count>                               â”‚\nâ”‚   Max dependency depth: <count>                                 â”‚\nâ”‚                                                                 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Review the task breakdown above.                                â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\nUse AskUserQuestion:\n\n```json\n{\n  \"question\": \"Approve this task breakdown?\",\n  \"header\": \"Task Review\",\n  \"options\": [\n    {\"label\": \"Approve\", \"description\": \"Save tasks and continue\"},\n    {\"label\": \"Edit\", \"description\": \"Modify specific tasks before saving\"},\n    {\"label\": \"Regenerate\", \"description\": \"Parse PRD again with different approach\"},\n    {\"label\": \"Cancel\", \"description\": \"Discard and exit\"}\n  ],\n  \"multiSelect\": false\n}\n```\n\n### Step 7: Handle Response\n\n**If Approve:**\n- Proceed to save\n\n**If Edit:**\n- Ask: \"Which task(s) to modify? (e.g., 1,3,5 or 'all')\"\n- For each task, ask what to change:\n  - Title\n  - Description\n  - Priority\n  - Dependencies\n  - Acceptance criteria\n- Re-display modified tasks and confirm\n\n**If Regenerate:**\n- Ask for guidance with AskUserQuestion:\n  ```json\n  {\n    \"question\": \"How should I adjust the task generation?\",\n    \"header\": \"Regenerate\",\n    \"options\": [\n      {\"label\": \"More tasks\", \"description\": \"Break down into smaller pieces\"},\n      {\"label\": \"Fewer tasks\", \"description\": \"Higher-level groupings\"},\n      {\"label\": \"Different focus\", \"description\": \"I'll provide specific guidance\"},\n      {\"label\": \"Try again\", \"description\": \"Same settings, fresh attempt\"}\n    ],\n    \"multiSelect\": false\n  }\n  ```\n- Adjust prompt based on response\n- Re-run Step 4\n\n**If Cancel:**\n- Exit without saving\n- Display: \"No changes made. PRD not parsed.\"\n\n### Step 8: Save Tasks\n\n**For --append mode:**\n```python\nexisting = read_json(tasks_file)\nmax_id = max([t[\"id\"] for t in existing[\"tasks\"]], default=0)\n\n# Renumber new tasks\nfor i, task in enumerate(new_tasks):\n    old_id = task[\"id\"]\n    task[\"id\"] = max_id + i + 1\n    # Update any internal dependencies\n    for t in new_tasks:\n        t[\"dependencies\"] = [\n            (max_id + d) if d == old_id else d\n            for d in t[\"dependencies\"]\n        ]\n\nexisting[\"tasks\"].extend(new_tasks)\nexisting[\"updated\"] = now_iso8601()\n```\n\n**Write to tag's tasks.json:**\n\n```json\n{\n  \"version\": \"1.0\",\n  \"project\": \"<project-name>\",\n  \"tag\": \"<current-tag>\",\n  \"prdSource\": \"<prd-path>\",\n  \"created\": \"<original-or-now>\",\n  \"updated\": \"<ISO-8601-now>\",\n  \"tasks\": [<generated-tasks>]\n}\n```\n\n### Step 9: Update Central Index\n\nUpdate project stats in central index:\n\n```python\nstats = {\n    \"total\": len(tasks),\n    \"pending\": len([t for t in tasks if t[\"status\"] == \"pending\"]),\n    \"in_progress\": len([t for t in tasks if t[\"status\"] == \"in_progress\"]),\n    \"done\": len([t for t in tasks if t[\"status\"] == \"done\"])\n}\nupdate_index(project_slug, stats, current_tag)\n```\n\n### Step 10: Confirm Success\n\n```\nTasks saved successfully!\n\n  Project: <project-name>\n  Tag: <current-tag>\n  PRD Source: <prd-path>\n  Tasks Created: <N>\n\n  Breakdown:\n    HIGH priority: <count>\n    MEDIUM priority: <count>\n    LOW priority: <count>\n\n  Entry points (no dependencies):\n    Task 1: <title>\n\nNext steps:\n  - Run /task-list to see all tasks\n  - Run /task-next to get started\n  - Run /task-show <id> for task details\n```\n\n## Edge Cases\n\n### PRD Contains Code Blocks\n\nThe parser should handle PRDs with embedded code examples without treating them as task content.\n\n### PRD Is Not English\n\n```\nNote: PRD appears to be in a non-English language.\nTask generation will proceed, but titles/descriptions will match PRD language.\n```\n\n### Very Few Requirements in PRD\n\n```\nWarning: PRD seems minimal. Only <N> tasks generated.\n\nThis might indicate:\n  â€¢ PRD needs more detail\n  â€¢ Feature is genuinely small\n  â€¢ Consider combining with other PRDs\n\nProceed anyway? [Y/n]\n```\n\n### Conflicting Dependencies Detected\n\nIf AI generates conflicting or illogical dependencies:\n\n```\nWarning: Dependency structure may have issues:\n\n  Task 5 depends on Task 6, but Task 6 depends on Task 5\n  This creates a circular dependency.\n\nAuto-fixing by removing dependency from Task 6 â†’ Task 5.\nPlease review after approval.\n```\n\n## Error Handling\n\n| Error | Resolution |\n|-------|------------|\n| No `.tasks/` directory | Prompt to run `/task-init` first |\n| Tag doesn't exist | Suggest creating tag or using existing |\n| PRD file not found | List available PRDs in `docs/PRD/`, suggest path |\n| PRD file empty | Error with guidance on PRD content |\n| PRD file too large | Warn and offer options |\n| JSON parse failure | Strip fences, retry once, show raw on failure |\n| Circular dependency | Show cycle, auto-fix or regenerate |\n| Existing tasks | Offer replace/append/new-tag options |\n| User cancels | Confirm no changes made |\n\n## Examples\n\n```bash\n# Parse PRD for authentication feature\n/task-parse docs/PRD/user-authentication.md\n\n# Parse with target task count hint\n/task-parse docs/PRD/api-redesign.md --num-tasks=15\n\n# Add tasks from additional PRD (phase 2)\n/task-parse docs/PRD/phase2-features.md --append\n\n# Parse into specific tag\n/task-parse docs/PRD/experiment.md --tag=experimental\n```\n\n## Tips for Good PRDs\n\nThe quality of generated tasks depends on PRD quality. Good PRDs include:\n\n- Clear feature descriptions\n- User stories or use cases\n- Technical requirements or constraints\n- Success criteria\n- Non-functional requirements (performance, security)\n- Dependencies on external systems\n\n## Related\n\n- Command: /task-init (prerequisite)\n- Command: /task-list (view generated tasks)\n- Command: /task-next (start working)\n- Command: /task-tag (manage tags)\n- Design: ~/.claude/knowledge/guides/taskflow-design.md\n",
        "plugins/taskflow/commands/task-show.md": "---\ndescription: Display detailed information for a specific task\n---\n\n# /task-show\n\nDisplay comprehensive details for a specific task or subtask.\n\n## What This Command Does\n\n1. Load task by ID from `.tasks/tasks.json`\n2. Display all task details including acceptance criteria\n3. Show dependency status and blocking information\n4. Optionally sync to TodoWrite for visibility\n\n## Arguments\n\n- `<task-id>` - **Required.** Task ID (e.g., `3` or `3.2` for subtask)\n\n## Prerequisites\n\n- Project must have tasks (`.tasks/tasks.json` exists with tasks)\n\n## Workflow\n\n### Step 1: Parse Task ID\n\nHandle both task and subtask IDs:\n\n- `3` â†’ Top-level task with id=3\n- `3.2` â†’ Subtask 2 of task 3\n\n### Step 2: Load Task\n\nRead `.tasks/tasks.json` and find the specified task.\n\nIf not found:\n```\nTask <id> not found.\n\nAvailable tasks: 1, 2, 3, 4, 5\nRun /task-list to see all tasks.\n```\n\n### Step 3: Resolve Dependencies\n\nFor each dependency, check its current status:\n\n```python\nfor dep_id in task.dependencies:\n    dep_task = find_task(dep_id)\n    dep_status = dep_task.status\n    # Determine if satisfied (done) or blocking\n```\n\n### Step 4: Display Task Details\n\n**For top-level task:**\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Task 3: Implement user authentication                           â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                 â”‚\nâ”‚ Status:      â—‹ pending                                          â”‚\nâ”‚ Priority:    HIGH                                               â”‚\nâ”‚ Created:     2025-11-29 10:00                                   â”‚\nâ”‚ Updated:     2025-11-29 12:30                                   â”‚\nâ”‚                                                                 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Description                                                     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Set up JWT-based authentication flow with login, logout, and    â”‚\nâ”‚ token refresh capabilities. Should integrate with existing      â”‚\nâ”‚ user model from task 2.                                         â”‚\nâ”‚                                                                 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Dependencies                                                    â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ âœ“ Task 1: Set up project structure (done)                       â”‚\nâ”‚ â— Task 2: Implement database schema (in_progress)               â”‚\nâ”‚                                                                 â”‚\nâ”‚ âš  BLOCKED: Waiting on task 2 to complete                        â”‚\nâ”‚                                                                 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Acceptance Criteria                                             â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ â˜ Users can register with email/password                        â”‚\nâ”‚ â˜ Users can log in and receive JWT token                        â”‚\nâ”‚ â˜ Tokens expire after 24 hours                                  â”‚\nâ”‚ â˜ Refresh token flow extends session                            â”‚\nâ”‚ â˜ Invalid credentials return 401                                â”‚\nâ”‚                                                                 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Subtasks                                                        â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ (none - run /task-expand 3 to break down)                       â”‚\nâ”‚                                                                 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Blocking                                                        â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ This task blocks:                                               â”‚\nâ”‚   â†’ Task 4: Create API endpoints                                â”‚\nâ”‚   â†’ Task 5: Add rate limiting                                   â”‚\nâ”‚                                                                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**For subtask:**\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Subtask 3.2: Create login endpoint                              â”‚\nâ”‚ Parent: Task 3 - Implement user authentication                  â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                 â”‚\nâ”‚ Status:      â—‹ pending                                          â”‚\nâ”‚                                                                 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Sibling Subtasks                                                â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ âœ“ 3.1 Create user registration endpoint                         â”‚\nâ”‚ â—‹ 3.2 Create login endpoint (this task)                         â”‚\nâ”‚ â—‹ 3.3 Create token refresh endpoint                             â”‚\nâ”‚ â—‹ 3.4 Create logout endpoint                                    â”‚\nâ”‚                                                                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Acceptance Criteria Display\n\n| Status | Display | Meaning |\n|--------|---------|---------|\n| Unchecked | â˜ | Not verified |\n| Checked | â˜‘ | Verified (when task done) |\n\nWhen task status is `done`, all criteria show as checked.\n\n### Dependency Status Icons\n\n| Icon | Meaning |\n|------|---------|\n| âœ“ | Dependency satisfied (done) |\n| â— | Dependency in progress |\n| â—‹ | Dependency pending |\n| â—Œ | Dependency blocked |\n\n## Error Handling\n\n| Error | Resolution |\n|-------|------------|\n| No `.tasks/tasks.json` | Prompt to run `/task-init` |\n| Task ID not found | Show available task IDs |\n| Invalid ID format | Show expected format (number or number.number) |\n\n## Examples\n\n```bash\n# Show task 3 details\n/task-show 3\n\n# Show subtask 3.2 details\n/task-show 3.2\n\n# Show first task\n/task-show 1\n```\n\n## Related\n\n- Command: /task-list (overview of all tasks)\n- Command: /task-next (get recommended next task)\n- Command: /task-status (update this task's status)\n- Command: /task-expand (break into subtasks)\n",
        "plugins/taskflow/commands/task-status.md": "---\nname: task-status\ndescription: Update the status of a task\nargs: <task-id> <status> [--note=\"...\"] [--force]\nversion: \"2.0\"\n---\n\n# /task-status\n\nUpdate task status with hygiene prompts and backend sync.\n\n## Usage\n\n```bash\n/task-status <task-id> <status> [--note=\"...\"] [--force]\n```\n\n## Status Values\n\n| Status | Meaning |\n|--------|---------|\n| `pending` | Not started |\n| `in_progress` | Currently working |\n| `done` | Completed |\n| `blocked` | Cannot proceed |\n| `deferred` | Postponed |\n| `cancelled` | Will not do |\n\n---\n\n## Workflow\n\n### Step 1: Load Backend\n\nâ†’ See `_core/command-preamble.md`\n\n```python\nbackend = loadBackend()\nif not backend:\n    triggerSetup()\n    return\n```\n\n### Step 2: Get Task\n\n```python\ntask = backend.getTask(task_id)\nif not task:\n    print(f\"Task not found: {task_id}\")\n    print(\"\\nUse /task-list to see available tasks.\")\n    return\n```\n\n### Step 3: Validate Transition\n\n```python\nVALID_TRANSITIONS = {\n    \"pending\": [\"in_progress\", \"deferred\", \"cancelled\"],\n    \"in_progress\": [\"done\", \"blocked\", \"deferred\", \"pending\", \"cancelled\"],\n    \"blocked\": [\"pending\", \"in_progress\", \"cancelled\"],\n    \"deferred\": [\"pending\", \"cancelled\"],\n    \"done\": [],  # Final - requires --force\n    \"cancelled\": [],  # Final - requires --force\n    \"pending_review\": [\"pending\", \"in_progress\", \"done\", \"cancelled\"]\n}\n\ncurrent = task[\"status\"]\n\nif new_status not in VALID_TRANSITIONS.get(current, []):\n    if not args.force:\n        print(f\"Invalid transition: {current} â†’ {new_status}\")\n        print(f\"Valid: {', '.join(VALID_TRANSITIONS[current])}\")\n        if current in [\"done\", \"cancelled\"]:\n            print(\"\\nUse --force to reopen completed/cancelled tasks.\")\n        return\n```\n\n### Step 4: Hygiene - Prompt for Notes\n\nâ†’ See `_core/task-hygiene.md`\n\n```python\nif isAutonomous():\n    # Auto-generate note based on transition\n    if new_status == \"done\" and not args.note:\n        note = \"Task completed\"\n    elif new_status == \"blocked\" and not args.note:\n        note = \"Task blocked (no reason provided)\"\n    else:\n        note = args.note\nelse:\n    # Interactive - prompt based on config\n    note = promptForNote(current, new_status, task, args.note)\n```\n\n#### Completion Prompt (â†’ done)\n\n```python\nif new_status == \"done\" and config.hygiene.requireCompletionNotes:\n    if task[\"priority\"] == \"high\" or not args.note:\n        # Show acceptance criteria if present\n        if task.get(\"acceptanceCriteria\"):\n            print(\"Verify acceptance criteria:\")\n            for criterion in task[\"acceptanceCriteria\"]:\n                print(f\"  â˜ {criterion}\")\n            print()\n\n        response = AskUserQuestion({\n            \"question\": \"Add completion notes?\",\n            \"header\": \"Done\",\n            \"options\": [\n                {\"label\": \"Add notes\", \"description\": \"Capture outcome, gotchas, follow-ups\"},\n                {\"label\": \"Skip\", \"description\": \"Mark done without notes\"}\n            ]\n        })\n\n        if response == \"Add notes\":\n            note = input(\"Completion notes: \")\n```\n\n#### Blocker Prompt (â†’ blocked)\n\n```python\nif new_status == \"blocked\":\n    if config.hygiene.requireBlockerReason and not args.note:\n        print(\"What's blocking this task?\")\n        note = input(\"Reason: \")\n        if not note:\n            print(\"Blocker reason required. Use --note or provide reason.\")\n            return\n```\n\n### Step 5: Update Status\n\n```python\n# Update via backend (handles sync to external system)\ntask = backend.setStatus(task_id, new_status, note)\n```\n\n### Step 6: Check Epic Completion\n\n```python\n# If subtask completed, check if epic should complete\nif task.get(\"parentId\") and new_status == \"done\":\n    parent = backend.getTask(task[\"parentId\"])\n    siblings = backend.listTasks({\"parentId\": task[\"parentId\"]})\n\n    all_done = all(s[\"status\"] == \"done\" for s in siblings)\n    if all_done:\n        response = AskUserQuestion({\n            \"question\": f\"All subtasks done. Complete epic '{parent['title']}'?\",\n            \"header\": \"Epic\",\n            \"options\": [\n                {\"label\": \"Yes\", \"description\": \"Mark epic as done\"},\n                {\"label\": \"No\", \"description\": \"Keep epic in progress\"}\n            ]\n        })\n        if response == \"Yes\":\n            backend.setStatus(parent[\"id\"], \"done\", \"All subtasks completed\")\n```\n\n### Step 7: Worklog Sync\n\n```python\nif config.hygiene.autoSyncToWorklog and note:\n    # Promote valuable notes to worklog\n    if any(keyword in note.lower() for keyword in [\"gotcha\", \"workaround\", \"decision\", \"learned\"]):\n        mcp__worklog__store_memory(\n            key=f\"taskflow_{task_id}_{datetime.now().strftime('%Y%m%d')}\",\n            content=note,\n            memory_type=\"fact\",\n            importance=7,\n            tags=\"taskflow,auto-captured\"\n        )\n```\n\n### Step 8: Confirm & Suggest Next\n\n```python\n# Show confirmation\nprint(f\"\\nTask updated: {task['title']}\")\nprint(f\"  Status: {current} â†’ {new_status}\")\n\nif backend.getBackendInfo()[\"type\"] != \"local\":\n    print(f\"  Synced: {task.get('externalUrl', 'external system')}\")\n\n# Suggest next task if completed\nif new_status == \"done\":\n    next_tasks = backend.listTasks({\"status\": [\"pending\"], \"limit\": 1})\n    if next_tasks:\n        print(f\"\\nNext task: {next_tasks[0]['title']}\")\n        print(f\"  /task-status {next_tasks[0]['id']} in_progress\")\n```\n\n---\n\n## Examples\n\n```bash\n# Start working on a task\n/task-status task-001 in_progress\n\n# Complete with notes\n/task-status task-001 done --note=\"Implemented with retry logic. Gotcha: needed exponential backoff\"\n\n# Block with reason\n/task-status task-002 blocked --note=\"Waiting on API credentials from client\"\n\n# Defer task\n/task-status task-003 deferred --note=\"Moving to phase 2\"\n\n# Reopen completed task\n/task-status task-001 in_progress --force\n```\n\n---\n\n## Backend Behavior\n\n| Backend | Status Update | Note |\n|---------|---------------|------|\n| Local | Update tasks.json | Append to notes array |\n| Plane | `update_issue(state_id)` | `add_comment()` |\n| GitHub | Label change + open/close | `gh issue comment` |\n\n---\n\n**Command Version:** 2.0\n**Uses:** Backend abstraction, Task hygiene\n",
        "plugins/taskflow/commands/task-tag.md": "---\ndescription: Manage TaskFlow tags for parallel work contexts\n---\n\n# /task-tag\n\nManage tagged task lists for parallel work streams (feature branches, phases, experiments).\n\n## What This Command Does\n\nTags provide isolated task contexts. Each tag has its own `tasks.json`, allowing:\n- Parallel feature development without conflicts\n- Phase-based project organization\n- Experimental branches without affecting main tasks\n\n## Subcommands\n\n### `/task-tag` (no args)\nShow current tag and list all available tags.\n\n### `/task-tag list`\nList all tags with stats.\n\n### `/task-tag use <name>`\nSwitch to a different tag context.\n\n### `/task-tag create <name>`\nCreate a new tag (optionally from current git branch).\n\n### `/task-tag delete <name>`\nDelete a tag (with confirmation).\n\n### `/task-tag copy <from> <to>`\nCopy tasks from one tag to another.\n\n## Directory Structure\n\n```\n.tasks/\nâ”œâ”€â”€ config.json           # Project config\nâ”œâ”€â”€ state.json            # Current tag, timestamps\nâ””â”€â”€ tags/\n    â”œâ”€â”€ master/\n    â”‚   â””â”€â”€ tasks.json    # Default tag\n    â”œâ”€â”€ feat-auth/\n    â”‚   â””â”€â”€ tasks.json\n    â””â”€â”€ phase-2/\n        â””â”€â”€ tasks.json\n```\n\n## State File (`.tasks/state.json`)\n\n```json\n{\n  \"currentTag\": \"master\",\n  \"lastSwitched\": \"2025-11-29T14:30:00Z\",\n  \"tags\": {\n    \"master\": {\n      \"created\": \"2025-11-29T10:00:00Z\",\n      \"description\": \"Main task list\"\n    },\n    \"feat-auth\": {\n      \"created\": \"2025-11-29T12:00:00Z\",\n      \"description\": \"Authentication feature\",\n      \"branch\": \"feat/user-authentication\"\n    }\n  }\n}\n```\n\n## Workflow\n\n### Show Current Tag (`/task-tag`)\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ TaskFlow Tags: my-project                                       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                 â”‚\nâ”‚ Current: master                                                 â”‚\nâ”‚                                                                 â”‚\nâ”‚ Available tags:                                                 â”‚\nâ”‚   â€¢ master (active)     8 tasks (3 done, 1 in progress)         â”‚\nâ”‚   â€¢ feat-auth           5 tasks (0 done)                        â”‚\nâ”‚   â€¢ phase-2             0 tasks                                 â”‚\nâ”‚                                                                 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Commands:                                                       â”‚\nâ”‚   /task-tag use <name>     Switch to tag                        â”‚\nâ”‚   /task-tag create <name>  Create new tag                       â”‚\nâ”‚   /task-tag delete <name>  Remove tag                           â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Create Tag (`/task-tag create <name>`)\n\n**Arguments:**\n- `<name>` - Tag name (lowercase, hyphens allowed, no spaces)\n- `--from-branch` - Auto-name from current git branch\n- `--copy-from=<tag>` - Copy tasks from another tag\n- `--description=\"...\"` - Optional description\n\n**Workflow:**\n\n1. Validate tag name (alphanumeric + hyphens, no spaces)\n2. Check tag doesn't already exist\n3. Create directory `.tasks/tags/<name>/`\n4. Create empty `tasks.json` (or copy if `--copy-from`)\n5. Update `state.json` with new tag\n6. Optionally switch to new tag\n\n```\n/task-tag create feat-auth --description=\"User authentication feature\"\n\nCreated tag: feat-auth\nLocation: .tasks/tags/feat-auth/tasks.json\nTasks: 0\n\nSwitch to this tag now? [Y/n]\n```\n\n**With --from-branch:**\n\n```bash\n# On branch feat/user-authentication\n/task-tag create --from-branch\n\nDetected branch: feat/user-authentication\nCreating tag: feat-user-authentication\n\nCreated tag: feat-user-authentication\nBranch linked: feat/user-authentication\n\nSwitch to this tag now? [Y/n]\n```\n\n### Switch Tag (`/task-tag use <name>`)\n\n**Workflow:**\n\n1. Validate tag exists\n2. Check for unsaved work in current tag (in_progress tasks)\n3. Update `state.json` with new current tag\n4. Display new context summary\n\n```\n/task-tag use feat-auth\n\nâš  Warning: You have 1 task in progress on 'master':\n   Task 3: Implement caching\n\nSwitch anyway? This won't lose progress - you can switch back.\n[Y]es / [N]o / [C]omplete first\n\n> Y\n\nSwitched to tag: feat-auth\nTasks: 5 (0 done, 0 in progress, 5 pending)\n\nRun /task-next to start working.\n```\n\n### Delete Tag (`/task-tag delete <name>`)\n\n**Safeguards:**\n- Cannot delete currently active tag\n- Cannot delete `master` tag (protected)\n- Requires confirmation\n- Shows task count before deletion\n\n```\n/task-tag delete feat-auth\n\nâš  Delete tag 'feat-auth'?\n   Contains: 5 tasks (2 done, 3 pending)\n   This cannot be undone.\n\nType 'delete feat-auth' to confirm:\n```\n\n### Copy Tasks (`/task-tag copy <from> <to>`)\n\n**Options:**\n- `--status=<status>` - Only copy tasks with specific status\n- `--renumber` - Renumber task IDs in destination (default: true)\n\n```\n/task-tag copy master phase-2 --status=pending\n\nCopying from 'master' to 'phase-2':\n  - 5 pending tasks selected\n  - IDs will be renumbered starting at 1\n\nProceed? [Y/n]\n\nCopied 5 tasks to 'phase-2'.\n```\n\n## Integration with Other Commands\n\nAll task commands operate on the **current tag**:\n\n- `/task-init` creates `master` tag by default\n- `/task-parse` saves to current tag\n- `/task-list` shows current tag's tasks\n- `/task-next` selects from current tag\n- `/task-status` updates in current tag\n\n**Tag-aware output:**\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Tasks: my-project [feat-auth]                                   â”‚\nâ”‚        ^^^^^^^^^^^^^^^^^^^^^ shows current tag if not master    â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n```\n\n## Edge Cases\n\n### Tag Name Validation\n\nValid: `master`, `feat-auth`, `phase-2`, `v1-release`\nInvalid: `Feat Auth`, `feat/auth`, `master!`, `my tag`\n\n```\n/task-tag create \"my feature\"\n\nError: Invalid tag name 'my feature'\nTag names must be lowercase alphanumeric with hyphens only.\nExamples: feat-auth, phase-2, bugfix-login\n```\n\n### Non-existent Tag\n\n```\n/task-tag use nonexistent\n\nError: Tag 'nonexistent' does not exist.\n\nAvailable tags:\n  â€¢ master\n  â€¢ feat-auth\n\nCreate it with: /task-tag create nonexistent\n```\n\n### Protected Master Tag\n\n```\n/task-tag delete master\n\nError: Cannot delete 'master' tag.\nThe master tag is protected as the default context.\n\nTo remove all tasks from master, use /task-parse with a new PRD\nor manually clear .tasks/tags/master/tasks.json\n```\n\n### Git Branch Integration\n\nWhen `autoTagFromBranch: true` in config:\n\n```\n# Automatically detect and offer to create/switch tags based on git branch\n\n$ git checkout -b feat/new-feature\n\n# Next task command detects branch change\n/task-next\n\nDetected git branch: feat/new-feature\nNo matching tag found.\n\nCreate tag 'feat-new-feature' for this branch? [Y/n]\n```\n\n## Error Handling\n\n| Error | Resolution |\n|-------|------------|\n| Invalid tag name | Show naming rules and examples |\n| Tag already exists | Suggest `use` or `--force` to overwrite |\n| Tag not found | List available tags, suggest create |\n| Delete active tag | Must switch first |\n| Delete master | Blocked (protected) |\n| No `.tasks/` directory | Run `/task-init` first |\n\n## Examples\n\n```bash\n# Show current tag and list all\n/task-tag\n\n# Create tag for feature work\n/task-tag create feat-user-auth --description=\"User authentication\"\n\n# Create from current git branch\n/task-tag create --from-branch\n\n# Switch to different tag\n/task-tag use feat-user-auth\n\n# Copy pending tasks to new phase\n/task-tag create phase-2\n/task-tag copy master phase-2 --status=pending\n\n# Clean up completed feature branch\n/task-tag use master\n/task-tag delete feat-user-auth\n```\n\n## Related\n\n- Command: /task-init (creates master tag)\n- Command: /task-list (shows current tag's tasks)\n- Design: ~/.claude/knowledge/guides/taskflow-design.md\n",
        "plugins/taskflow/commands/task.md": "---\ndescription: TaskFlow orchestrator - conversational task management\n---\n\n# /task\n\nConversational interface for TaskFlow task management. Interprets natural language requests and routes to appropriate task commands.\n\n## What This Skill Does\n\n1. Parse natural language task management requests\n2. Route to appropriate `/task-*` command\n3. Provide contextual help and suggestions\n4. Handle multi-step workflows conversationally\n\n## Usage\n\nInvoke with natural language:\n\n```\n/task <natural language request>\n```\n\nOr just `/task` for status overview.\n\n## Request Routing\n\n| User Says | Routes To |\n|-----------|-----------|\n| \"initialize\", \"init\", \"set up tasks\" | `/task-init` |\n| \"parse\", \"generate tasks from\", \"read PRD\" | `/task-parse` |\n| \"list\", \"show all\", \"what tasks\" | `/task-list` |\n| \"next\", \"what should I work on\", \"what's next\" | `/task-next` |\n| \"show task N\", \"details for N\", \"what's task N\" | `/task-show N` |\n| \"done\", \"complete\", \"finished task N\" | `/task-status N done` |\n| \"start task N\", \"working on N\" | `/task-status N in_progress` |\n| \"expand\", \"break down task N\" | `/task-expand N` |\n| \"block\", \"blocked on N\" | `/task-status N blocked` |\n| \"defer\", \"postpone task N\" | `/task-status N deferred` |\n| \"help\", \"how do I\", \"what can you do\" | Show help |\n\n## Workflow\n\n### Step 1: Parse Intent\n\nAnalyze the user's request to determine intent:\n\n```python\nintents = {\n    \"init\": [\"initialize\", \"init\", \"set up\", \"create tasks\"],\n    \"parse\": [\"parse\", \"generate\", \"from prd\", \"read prd\", \"create from\"],\n    \"list\": [\"list\", \"show all\", \"all tasks\", \"what tasks\", \"overview\"],\n    \"next\": [\"next\", \"what should\", \"recommend\", \"what's next\", \"start\"],\n    \"show\": [\"show\", \"details\", \"tell me about\", \"what's task\", \"describe\"],\n    \"done\": [\"done\", \"complete\", \"finished\", \"mark done\", \"completed\"],\n    \"start\": [\"start\", \"begin\", \"working on\", \"in progress\"],\n    \"expand\": [\"expand\", \"break down\", \"split\", \"subtasks\"],\n    \"block\": [\"block\", \"blocked\", \"stuck\", \"waiting\"],\n    \"defer\": [\"defer\", \"postpone\", \"later\", \"skip\"],\n    \"help\": [\"help\", \"how\", \"what can\", \"commands\"]\n}\n\n# Extract task ID if present\ntask_id = extract_task_id(request)  # e.g., \"task 3\" â†’ 3\n```\n\n### Step 2: Context Check\n\nBefore routing, check project context:\n\n```python\n# Check if in a project with tasks\nhas_tasks = exists(\".tasks/tasks.json\")\n\nif not has_tasks and intent not in [\"init\", \"help\"]:\n    suggest_init()\n    return\n```\n\n### Step 3: Route to Command\n\nExecute the appropriate command:\n\n```python\nif intent == \"init\":\n    execute(\"/task-init\")\nelif intent == \"parse\":\n    prd_path = extract_path(request) or prompt_for_prd()\n    execute(f\"/task-parse {prd_path}\")\nelif intent == \"list\":\n    filters = extract_filters(request)  # --status, --priority\n    execute(f\"/task-list {filters}\")\nelif intent == \"next\":\n    execute(\"/task-next\")\nelif intent == \"show\":\n    execute(f\"/task-show {task_id}\")\nelif intent == \"done\":\n    execute(f\"/task-status {task_id} done\")\nelif intent == \"start\":\n    execute(f\"/task-status {task_id} in_progress\")\nelif intent == \"expand\":\n    execute(f\"/task-expand {task_id}\")\nelif intent == \"block\":\n    execute(f\"/task-status {task_id} blocked\")\nelif intent == \"defer\":\n    execute(f\"/task-status {task_id} deferred\")\nelif intent == \"help\":\n    show_help()\n```\n\n### Step 4: Handle Ambiguity\n\nIf intent unclear, ask for clarification:\n\n```\nI'm not sure what you want to do. Did you mean:\n\n  â€¢ /task-list - See all tasks\n  â€¢ /task-next - Get next recommended task\n  â€¢ /task-show <id> - View specific task details\n\nOr tell me more about what you need.\n```\n\n## Context-Aware Responses\n\n### No Project Initialized\n```\nNo TaskFlow project found in current directory.\n\nTo get started:\n  1. Run /task-init to initialize\n  2. Create a PRD in docs/PRD/your-feature.md\n  3. Run /task-parse docs/PRD/your-feature.md\n\nOr run /task help for more information.\n```\n\n### Project Has No Tasks\n```\nTaskFlow is initialized, but no tasks yet.\n\nTo generate tasks:\n  1. Create a PRD document in docs/PRD/\n  2. Run: /task parse docs/PRD/your-prd.md\n\nAvailable PRDs found:\n  â€¢ docs/PRD/feature-spec.md\n  â€¢ docs/PRD/api-design.md\n```\n\n### Status Overview (just `/task`)\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ TaskFlow: my-project                                            â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                 â”‚\nâ”‚ Progress: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 50% (4/8 tasks)                      â”‚\nâ”‚                                                                 â”‚\nâ”‚ Current: Task 5 - Implement caching (in_progress)               â”‚\nâ”‚ Next up: Task 6 - Add logging                                   â”‚\nâ”‚                                                                 â”‚\nâ”‚ Status breakdown:                                               â”‚\nâ”‚   âœ“ Done: 4                                                     â”‚\nâ”‚   â— In Progress: 1                                              â”‚\nâ”‚   â—‹ Pending: 2                                                  â”‚\nâ”‚   â—Œ Blocked: 1                                                  â”‚\nâ”‚                                                                 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ Quick actions:                                                  â”‚\nâ”‚   /task done 5     - Complete current task                      â”‚\nâ”‚   /task next       - See next recommendation                    â”‚\nâ”‚   /task list       - View all tasks                             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Example Conversations\n\n### Starting Fresh\n```\nUser: /task initialize\nâ†’ Executes /task-init\n\nUser: /task parse the PRD at docs/PRD/auth-feature.md\nâ†’ Executes /task-parse docs/PRD/auth-feature.md\n\nUser: /task what should I work on first?\nâ†’ Executes /task-next\n```\n\n### During Development\n```\nUser: /task\nâ†’ Shows status overview with current task\n\nUser: /task I finished the authentication task\nâ†’ Executes /task-status 3 done (infers current task)\n\nUser: /task show me task 5\nâ†’ Executes /task-show 5\n\nUser: /task break down task 6 into smaller pieces\nâ†’ Executes /task-expand 6\n```\n\n### Handling Issues\n```\nUser: /task I'm blocked on task 4, waiting for API access\nâ†’ Executes /task-status 4 blocked\nâ†’ Optionally records note about API access\n\nUser: /task let's defer the caching task for now\nâ†’ Executes /task-status 7 deferred\n\nUser: /task what's still pending?\nâ†’ Executes /task-list --status=pending\n```\n\n## Help Output\n\nWhen user asks for help:\n\n```\nTaskFlow - AI-Powered Task Management\n\nCommands:\n  /task                    Status overview\n  /task init               Initialize in current project\n  /task parse <prd>        Generate tasks from PRD\n  /task list               List all tasks\n  /task next               Get next recommended task\n  /task show <id>          View task details\n  /task done <id>          Mark task complete\n  /task start <id>         Start working on task\n  /task expand <id>        Break into subtasks\n  /task block <id>         Mark task as blocked\n  /task defer <id>         Postpone task\n\nNatural language examples:\n  \"What should I work on next?\"\n  \"I finished task 3\"\n  \"Show me the details for task 5\"\n  \"Break down task 4 into smaller pieces\"\n  \"Parse the PRD at docs/PRD/feature.md\"\n\nDocumentation: ~/.claude/knowledge/guides/taskflow-design.md\n```\n\n## Error Handling\n\n| Situation | Response |\n|-----------|----------|\n| No task ID when required | Ask for task ID or show list |\n| Invalid task ID | Show available task IDs |\n| Ambiguous request | Ask for clarification with options |\n| Command fails | Show error and suggest fix |\n\n## Related\n\n- Design: ~/.claude/knowledge/guides/taskflow-design.md\n- Commands: /task-init, /task-parse, /task-list, /task-show, /task-next, /task-status, /task-expand\n",
        "plugins/taskflow/skills/task-setup/skill.md": "---\nname: task-setup\ndescription: First-run setup for TaskFlow - configure backend and preferences\ntrigger: auto  # Triggered when no config exists\nversion: \"2.0\"\n---\n\n# TaskFlow First-Run Setup\n\nTriggered automatically when TaskFlow commands are used without existing configuration.\n\n---\n\n## Trigger Conditions\n\nThis setup runs when:\n1. No `./.taskflow.local.md` in current directory\n2. No `~/.gsc-plugins/taskflow.local.md` globally\n3. User runs any `/task-*` command\n\n---\n\n## Setup Flow\n\n### Step 1: Detect Available Backends\n\n```python\ndef detectBackends():\n    backends = []\n\n    # Local is always available (default)\n    backends.append({\n        \"name\": \"local\",\n        \"available\": True,\n        \"label\": \"Local (.tasks/)\",\n        \"description\": \"Store tasks locally - works offline, no setup\"\n    })\n\n    # Check Plane MCP\n    if tool_exists(\"mcp__plane__list_issues\"):\n        try:\n            workspaces = mcp__plane__list_workspaces()\n            if workspaces.get(\"results\"):\n                ws = workspaces[\"results\"][0]\n                backends.append({\n                    \"name\": \"plane\",\n                    \"available\": True,\n                    \"label\": \"Plane\",\n                    \"description\": f\"Sync with Plane - workspace: {ws['slug']}\",\n                    \"workspace\": ws[\"slug\"]\n                })\n        except:\n            pass\n\n    # Check GitHub CLI\n    try:\n        result = bash(\"gh auth status 2>&1\")\n        if \"Logged in\" in result:\n            # Try to get current repo\n            repo_info = bash(\"gh repo view --json owner,name 2>/dev/null || echo '{}'\")\n            repo = json.loads(repo_info)\n            if repo.get(\"owner\"):\n                desc = f\"Sync with GitHub Issues - {repo['owner']['login']}/{repo['name']}\"\n            else:\n                desc = \"Sync with GitHub Issues - authenticated\"\n            backends.append({\n                \"name\": \"github\",\n                \"available\": True,\n                \"label\": \"GitHub\",\n                \"description\": desc,\n                \"owner\": repo.get(\"owner\", {}).get(\"login\"),\n                \"repo\": repo.get(\"name\")\n            })\n    except:\n        pass\n\n    # Check Linear MCP (if exists)\n    if tool_exists(\"mcp__linear__list_issues\"):\n        backends.append({\n            \"name\": \"linear\",\n            \"available\": True,\n            \"label\": \"Linear\",\n            \"description\": \"Sync with Linear issues\"\n        })\n\n    return backends\n```\n\n### Step 2: Display Detection Results\n\n```markdown\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  TaskFlow Setup                                             â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                             â”‚\nâ”‚  Detected integrations:                                     â”‚\nâ”‚                                                             â”‚\nâ”‚    âœ“ Plane     - workspace: gsdev                           â”‚\nâ”‚    âœ“ GitHub    - authenticated as myuser                    â”‚\nâ”‚    âœ— Linear    - not detected                               â”‚\nâ”‚                                                             â”‚\nâ”‚  Default: Local .tasks/ (no setup required)                 â”‚\nâ”‚                                                             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n### Step 3: Ask Backend Preference\n\nUse AskUserQuestion with local as default:\n\n```python\ndef askBackendPreference(backends):\n    options = []\n\n    # Local always first (default)\n    options.append({\n        \"label\": \"Local only (Recommended)\",\n        \"description\": \"Use .tasks/ folder - works offline, no external sync\"\n    })\n\n    # Add detected integrations\n    for backend in backends:\n        if backend[\"name\"] != \"local\" and backend[\"available\"]:\n            options.append({\n                \"label\": backend[\"label\"],\n                \"description\": backend[\"description\"]\n            })\n\n    return AskUserQuestion({\n        \"question\": \"Where should TaskFlow store tasks?\",\n        \"header\": \"Backend\",\n        \"options\": options,\n        \"multiSelect\": False\n    })\n```\n\n### Step 4: Backend-Specific Configuration\n\n#### If Local Selected\n\nNo additional config needed. Proceed to scope.\n\n#### If Plane Selected\n\n```python\ndef configurePlane(detected_workspace):\n    # Get projects in workspace\n    projects = mcp__plane__list_projects(workspace_slug=detected_workspace)\n\n    options = []\n    for project in projects.get(\"results\", []):\n        options.append({\n            \"label\": project[\"name\"],\n            \"description\": project.get(\"description\", \"\")[:50]\n        })\n\n    selected = AskUserQuestion({\n        \"question\": \"Which Plane project should tasks go to?\",\n        \"header\": \"Project\",\n        \"options\": options,\n        \"multiSelect\": False\n    })\n\n    return {\n        \"workspace\": detected_workspace,\n        \"project\": selected\n    }\n```\n\n#### If GitHub Selected\n\n```python\ndef configureGitHub(detected_owner, detected_repo):\n    if detected_owner and detected_repo:\n        # Confirm detected repo\n        confirm = AskUserQuestion({\n            \"question\": f\"Use {detected_owner}/{detected_repo} for task tracking?\",\n            \"header\": \"Repository\",\n            \"options\": [\n                {\"label\": \"Yes\", \"description\": f\"Use {detected_owner}/{detected_repo}\"},\n                {\"label\": \"Different repo\", \"description\": \"Specify another repository\"}\n            ],\n            \"multiSelect\": False\n        })\n\n        if confirm == \"Yes\":\n            return {\"owner\": detected_owner, \"repo\": detected_repo}\n\n    # Manual entry needed\n    print(\"Enter repository as owner/repo (e.g., myuser/tasks):\")\n    # Would need text input here\n    return {\"owner\": \"...\", \"repo\": \"...\"}\n```\n\n### Step 5: Ask Scope\n\n```python\ndef askScope():\n    return AskUserQuestion({\n        \"question\": \"Save this configuration for?\",\n        \"header\": \"Scope\",\n        \"options\": [\n            {\n                \"label\": \"This project only\",\n                \"description\": \"Save to ./.taskflow.local.md\"\n            },\n            {\n                \"label\": \"All projects (global default)\",\n                \"description\": \"Save to ~/.gsc-plugins/taskflow.local.md\"\n            },\n            {\n                \"label\": \"This session only\",\n                \"description\": \"Don't save - will ask again next time\"\n            }\n        ],\n        \"multiSelect\": False\n    })\n```\n\n### Step 6: Write Configuration\n\n```python\ndef writeConfig(backend, backend_config, scope):\n    config = {\n        \"backend\": backend,\n        backend: backend_config,\n        \"hygiene\": {\n            \"requireCompletionNotes\": True,\n            \"requireBlockerReason\": True,\n            \"promptForNotes\": True,\n            \"autoSyncToWorklog\": False\n        }\n    }\n\n    # Convert to YAML frontmatter\n    yaml_content = f\"\"\"---\nbackend: {backend}\n\n{backend}:\n{indent(yaml.dump(backend_config), \"  \")}\n\nhygiene:\n  requireCompletionNotes: true\n  requireBlockerReason: true\n  promptForNotes: true\n  autoSyncToWorklog: false\n---\n\n# TaskFlow Configuration\n\nConfigured on {datetime.now().isoformat()}\n\"\"\"\n\n    if scope == \"This project only\":\n        path = \"./.taskflow.local.md\"\n    elif scope == \"All projects (global default)\":\n        path = os.path.expanduser(\"~/.gsc-plugins/taskflow.local.md\")\n        os.makedirs(os.path.dirname(path), exist_ok=True)\n    else:\n        # Session only - store in memory, don't write\n        SESSION_CONFIG = config\n        return\n\n    with open(path, \"w\") as f:\n        f.write(yaml_content)\n```\n\n### Step 7: Confirm & Initialize\n\n```python\ndef confirmSetup(backend, backend_config, scope, path):\n    if backend == \"local\":\n        # Create .tasks/ directory\n        os.makedirs(\".tasks\", exist_ok=True)\n\n        print(f\"\"\"\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  TaskFlow configured!                                       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                             â”‚\nâ”‚  Backend: Local (.tasks/)                                   â”‚\nâ”‚  Storage: ./.tasks/tasks.json                               â”‚\nâ”‚  Config:  {path}\nâ”‚                                                             â”‚\nâ”‚  Tasks stored locally - no external sync.                   â”‚\nâ”‚  Change anytime: /task config --backend=plane               â”‚\nâ”‚                                                             â”‚\nâ”‚  Get started:                                               â”‚\nâ”‚    /task-add \"Your first task\"                              â”‚\nâ”‚    /task-list                                               â”‚\nâ”‚                                                             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\"\"\")\n\n    elif backend == \"plane\":\n        print(f\"\"\"\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  TaskFlow configured!                                       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                             â”‚\nâ”‚  Backend: Plane                                             â”‚\nâ”‚  Workspace: {backend_config['workspace']}\nâ”‚  Project: {backend_config['project']}\nâ”‚  Config: {path}\nâ”‚                                                             â”‚\nâ”‚  Tasks sync to:                                             â”‚\nâ”‚  https://${{PLANE_URL}}/{backend_config['workspace']}/{backend_config['project']}\nâ”‚                                                             â”‚\nâ”‚  Get started:                                               â”‚\nâ”‚    /task-add \"Your first task\"                              â”‚\nâ”‚    /task-list                                               â”‚\nâ”‚                                                             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\"\"\")\n\n    elif backend == \"github\":\n        print(f\"\"\"\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  TaskFlow configured!                                       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                             â”‚\nâ”‚  Backend: GitHub Issues                                     â”‚\nâ”‚  Repository: {backend_config['owner']}/{backend_config['repo']}\nâ”‚  Config: {path}\nâ”‚                                                             â”‚\nâ”‚  Tasks sync to:                                             â”‚\nâ”‚  https://github.com/{backend_config['owner']}/{backend_config['repo']}/issues\nâ”‚                                                             â”‚\nâ”‚  Get started:                                               â”‚\nâ”‚    /task-add \"Your first task\"                              â”‚\nâ”‚    /task-list                                               â”‚\nâ”‚                                                             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\"\"\")\n```\n\n---\n\n## Quick Setup (No Prompts)\n\nFor autonomous mode or quick setup:\n\n```bash\n# Use local backend (default)\n/task-init --backend=local\n\n# Use Plane with auto-detection\n/task-init --backend=plane --auto\n\n# Use GitHub with current repo\n/task-init --backend=github --auto\n\n# Specify explicitly\n/task-init --backend=plane --workspace=gsdev --project=work\n```\n\n---\n\n## Re-Configuration\n\nTo change configuration later:\n\n```bash\n# View current config\n/task config\n\n# Change backend\n/task config --backend=github\n\n# Reset and re-run setup\n/task config --reset\n```\n\n---\n\n## Error Handling\n\n### No Integrations Available\n\n```\nNo external integrations detected.\n\nTaskFlow will use local storage (.tasks/).\n\nTo set up integrations later:\n  â€¢ Plane: Configure MCP server in settings\n  â€¢ GitHub: Run `gh auth login`\n  â€¢ Linear: Configure MCP server in settings\n\nContinuing with local backend...\n```\n\n### Integration Connection Failed\n\n```\nWarning: Could not connect to Plane.\n\nOptions:\n  1. Use local backend instead\n  2. Retry connection\n  3. Configure manually\n\n[1/2/3]: _\n```\n\n---\n\n**Skill Version:** 2.0\n**Triggered By:** Any /task-* command when no config exists\n",
        "plugins/webgen/.claude-plugin/plugin.json": "{\n  \"name\": \"webgen\",\n  \"version\": \"2.0.0\",\n  \"description\": \"Generate production-ready websites from natural language. Part of the unified GSC plugins ecosystem with query-first knowledge, progressive discovery, and cross-plugin integration.\",\n  \"author\": {\n    \"name\": \"gs\"\n  },\n  \"license\": \"MIT\",\n  \"repository\": \"https://github.com/gaurangrshah/gsc-plugins\",\n  \"homepage\": \"https://github.com/gaurangrshah/gsc-plugins/tree/main/plugins/webgen\",\n  \"keywords\": [\n    \"website\",\n    \"generator\",\n    \"react\",\n    \"nextjs\",\n    \"astro\",\n    \"vite\",\n    \"tailwind\",\n    \"scaffold\",\n    \"orchestrated\",\n    \"code-review\",\n    \"accessibility\",\n    \"wcag\",\n    \"ecosystem\"\n  ]\n}\n",
        "plugins/webgen/README.md": "# WebGen - Claude Code Plugin\n\nGenerate websites, components, and features from natural language descriptions using Claude's capabilities directly through your Max subscription.\n\n**Version:** 2.0.0\n\n## Overview\n\nWebGen is a **self-contained** Claude Code plugin that transforms natural language descriptions into complete, production-ready web projects. All agents are bundledâ€”no external dependencies required. It leverages Claude's understanding and code generation capabilities without requiring API costsâ€”just your existing Max subscription.\n\n## Installation\n\n### Option 1: Marketplace (Recommended)\n\n```bash\n# Add the marketplace (if not already added)\nclaude plugin marketplace add https://github.com/gaurangrshah/gsc-plugins.git\n\n# Install the plugin\nclaude plugin install webgen@gsc-plugins\n```\n\n### Option 2: Manual Installation\n\n```bash\n# Clone the repo\ngit clone https://github.com/gaurangrshah/gsc-plugins.git\n\n# Copy to local-plugins\ncp -r gsc-plugins/plugins/webgen ~/.claude/plugins/local-plugins/\n\n# Restart Claude Code to activate\n```\n\n## Usage\n\n```bash\n# With description\n/webgen restaurant landing page for Bistro Bliss\n\n# Interactive mode (asks clarifying questions)\n/webgen\n\n# Various project types\n/webgen portfolio site for a freelance photographer\n/webgen pricing component with 3 tiers\n/webgen SaaS dashboard with analytics widgets\n/webgen multi-page healthcare site for Clarity Health\n```\n\n## Configuration\n\n### Environment Variables\n\n| Variable | Default | Description |\n|----------|---------|-------------|\n| `WEBGEN_OUTPUT_DIR` | `./webgen-projects` | Base directory for generated projects |\n| `WEBGEN_DB_PATH` | *(empty)* | SQLite database for cross-session learning (empty = disabled) |\n\nSet these in your environment or shell profile:\n\n```bash\nexport WEBGEN_OUTPUT_DIR=\"$HOME/my-projects\"\nexport WEBGEN_DB_PATH=\"\"  # Leave empty for stateless mode\n```\n\n## Standalone & Integration\n\n### Works 100% Standalone\n\nWebGen is fully self-contained. **No other plugins required.**\n\n```bash\n# This works perfectly with ONLY webgen installed:\n/webgen restaurant landing page\n```\n\nAll 5 checkpoints complete. All features work. No errors or warnings about missing plugins.\n\n### Optional Integrations\n\nWebGen detects other GSC plugins and offers enhancements:\n\n#### TaskFlow Integration (Opt-in)\n\nIf [TaskFlow](../taskflow/) is installed, WebGen offers task tracking:\n\n```\nTaskFlow detected. Track this project with tasks? (y/n)\n```\n\n**What happens if you say \"yes\":**\n\n| Checkpoint | Task Created |\n|------------|--------------|\n| Requirements | \"Define project requirements\" |\n| Research | \"Conduct competitive research\" |\n| Architecture | \"Design project architecture\" |\n| Implementation | \"Implement components\" |\n| Final Sign-off | \"Complete documentation\" |\n\n**Benefits:**\n- Visual progress tracking during generation\n- Clear dependency chains (Research â†’ Architecture â†’ Implementation)\n- Resume capability if session interrupted\n- Task history for future reference\n\n**What happens if you say \"no\" or TaskFlow isn't installed:**\n- WebGen proceeds with standard workflow\n- No errors, no warnings, no prompts\n- Identical functionality\n\n#### Git Worktree Integration (Opt-in)\n\nIf WebGen detects you have work in progress in the output directory (uncommitted changes in a git repo), it offers isolated development via git worktrees:\n\n```\n**Git Worktree (Recommended):**\nI detected you have work in progress in the output directory.\nWould you like to use a git worktree?\n\n- **Yes** - Create isolated worktree (keeps your current work untouched)\n- **No** - Use standard feature branch in output directory\n```\n\n**What happens if you say \"yes\":**\n\n| Phase | Action |\n|-------|--------|\n| Architecture | Creates worktree at `worktrees/{slug}/` on branch `feat/{slug}` |\n| During work | All changes happen in isolated worktree |\n| Final | Merges to main, deletes branch, removes worktree, prunes |\n\n**Benefits:**\n- Your current work stays untouched\n- Parallel development without interference\n- Clean merge history\n- Automatic cleanup (no orphaned worktrees)\n\n**Real-world example:** Successfully used for beacon-advisory-support project - full Astro site conversion in isolated worktree, cleanly merged to main.\n\n**What happens if you say \"no\" or no existing work detected:**\n- WebGen proceeds with standard feature branch workflow\n- No errors, no warnings\n- Identical functionality\n\n#### Worklog Integration (Passive)\n\nIf [Worklog](../worklog/) is installed, its hooks provide background context:\n\n- **SessionStart hook**: Loads recent work context (if hook_mode is light/full/aggressive)\n- **SessionStop hook**: Prompts to store learnings (based on hook_mode setting)\n\nWebGen doesn't actively integrate with Worklog yet, but Worklog's general-purpose hooks still fire during WebGen sessions.\n\n**Future (Planned):**\n- Auto-store design patterns to knowledge_base\n- Query similar past projects for consistency\n- Track generation metrics\n\n## Output Location\n\nProjects are created at:\n```\n{WEBGEN_OUTPUT_DIR}/{project-slug} - webgen/\n```\n\n**Default:** `./webgen-projects/{project-slug} - webgen/`\n\nThis provides a consistent, findable location for all webgen-generated projects.\n\n## How It Works\n\n### Orchestrated Workflow (v1.4)\n\nWebGen uses **@webgen-orchestrator** (bundled) as Product Manager, validating each phase before proceeding:\n\n```\nUser Request\n    â†“\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   @webgen-orchestrator (PM Agent)   â”‚\nâ”‚  Validates requirements, approves   â”‚\nâ”‚  each phase, manages iterations     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n    â†“\n[Checkpoint 1: Requirements]\nPM validates scope and requirements\n    â†“\n[Checkpoint 2: Research Review]\nPM reviews competitive analysis\n    â†“\n[Checkpoint 3: Architecture Review]\nPM reviews structure and tech stack\n    â†“\n[Checkpoint 4: Code Review]\n@webgen-code-reviewer validates implementation\n(max 2 iterations, then escalate)\n    â†“\n[Checkpoint 4.5: Legal Pages]\n(Conditional - if applicable)\n    â†“\n[Checkpoint 5: Final Sign-off]\nPM confirms all requirements met\n    â†“\nDone\n```\n\n### Bundled Agents\n\n| Agent | Purpose |\n|-------|---------|\n| `@webgen` | Core website generation |\n| `@webgen-orchestrator` | PM coordination and quality gates |\n| `@webgen-code-reviewer` | Code quality and accessibility validation |\n\nNo external agent dependencies required.\n\n**Benefits:**\n- Research reviewed before wasting time on wrong direction\n- Architecture approved before coding begins\n- Code review catches issues early\n- 2-iteration max prevents infinite loops\n- Escalates to user when agents disagree\n\n### Example Session\n\n```\nUser: /webgen fintech landing page\n\nAgent: [Creates TodoWrite tasks]\n\nFirst, let me research competitors...\n\n[Researches Betterment, Wealthfront, Oscar Health]\n[Saves to research/competitive-analysis.md]\n[Commits: \"feat: add competitive research\"]\n\nNow, a few questions:\n\n1. What's the company/product name?\n2. Key sections needed? (Based on research: Hero, Features, Trust indicators, Pricing, CTA)\n3. Design preference? (Competitors use clean, trustworthy designs)\n\nUser: InvestWise, modern minimal, all those sections\n\nAgent: Creating \"InvestWise\" at ./webgen-projects/investwise - webgen/\n\nTech stack: React + Vite + Tailwind\nBranch: feat/initial-scaffold\n\n[Scaffolds project with research/, docs/ folders]\n[Generates components with docstrings]\n[Atomic commits with signature after each feature]\n[Captures screenshot]\n[Generates README, design-decisions.md, assets.md]\n\nPreview running at http://localhost:5173\n\nResearch saved in research/competitive-analysis.md\nDesign decisions documented in docs/design-decisions.md\n\nGenerated by webgen v1.4\n\nShould this become a reusable template?\n```\n\n## Key Features (v1.5)\n\n| Feature | Description |\n|---------|-------------|\n| **Asset Management** | Detects, catalogs, and propagates reference assets (screenshots, designs) throughout workflow |\n| **TodoWrite Integration** | Every session tracks progress with todos |\n| **TaskFlow Integration** | Optional task tracking when TaskFlow plugin available (non-breaking) |\n| **Competitive Research** | Saves competitor analysis to `research/` folder |\n| **Signed Commits** | All commits include `webgen v1.4` signature |\n| **Feature Branches** | Uses `feat/{slug}` workflow, atomic commits |\n| **Documentation** | Generates README, design-decisions, assets docs |\n| **Screenshot Capture** | Saves preview to `docs/screenshots/preview.png` |\n| **Legal Pages** | Industry-specific privacy, terms, disclosures |\n| **Template Promotion** | Successful projects can become reusable templates |\n| **Testing** | Mandatory test suite for API/server projects |\n| **Accessibility** | WCAG 2.1 AA compliance baseline |\n| **Performance Targets** | Lighthouse 90+, <200KB bundle documented |\n\n## Project Structure\n\n### Code Projects\n\n```\n{WEBGEN_OUTPUT_DIR}/{project-slug} - webgen/\nâ”œâ”€â”€ .webgen/                      # WebGen metadata\nâ”‚   â””â”€â”€ assets/                   # Reference assets catalog\nâ”‚       â”œâ”€â”€ catalog.json          # Asset metadata and manifest\nâ”‚       â”œâ”€â”€ screenshots/          # UI reference screenshots\nâ”‚       â”œâ”€â”€ designs/              # Design files\nâ”‚       â””â”€â”€ references/           # Other reference materials\nâ”œâ”€â”€ research/\nâ”‚   â””â”€â”€ competitive-analysis.md   # Competitor insights\nâ”œâ”€â”€ docs/\nâ”‚   â”œâ”€â”€ design-decisions.md       # Colors, fonts, spacing, breakpoints\nâ”‚   â”œâ”€â”€ assets.md                 # Asset sources and attribution\nâ”‚   â””â”€â”€ screenshots/\nâ”‚       â””â”€â”€ preview.png           # Final preview screenshot\nâ”œâ”€â”€ src/\nâ”‚   â””â”€â”€ components/               # Generated components with docstrings\nâ”œâ”€â”€ tests/                        # For API/server projects (MANDATORY)\nâ”œâ”€â”€ CHANGELOG.md\nâ”œâ”€â”€ README.md                     # Includes \"Generated by webgen v1.4\"\nâ””â”€â”€ package.json\n```\n\n### Content Projects (emails, brochures, campaigns)\n\n```\n{project-slug} - webgen/\nâ”œâ”€â”€ research/                     # If git approved\nâ”‚   â””â”€â”€ competitive-analysis.md\nâ”œâ”€â”€ content/\nâ””â”€â”€ README.md\n```\n\n### Templates Location\n\n```\n{WEBGEN_OUTPUT_DIR}/templates/{category}/\n```\n\n## Asset Management (v1.5)\n\n**NEW:** WebGen now detects and catalogs reference assets (screenshots, designs) provided in the initial prompt, making them available throughout the entire workflow.\n\n### How It Works\n\n1. **Provide Assets:** Attach screenshots, design files, or reference images when invoking `/webgen`\n2. **Automatic Detection:** Orchestrator detects files and dispatches @webgen for extraction\n3. **Cataloging:** Assets are cataloged in `.webgen/assets/catalog.json` with metadata\n4. **Propagation:** Every phase receives asset context in dispatch prompts\n5. **Implementation:** Implementation agents read assets before coding for pixel-perfect results\n\n### Example Workflow\n\n```\nUser: /webgen restaurant landing page\n[Attaches: hero-reference.png, features-grid.png]\n\nOrchestrator:\n- Detects 2 assets\n- Dispatches @webgen for extraction\n- Creates .webgen/assets/catalog.json\n- Includes asset context in all phase dispatches\n\nResearch Phase:\n- @webgen reads assets to understand visual style\n- Finds competitors with similar layouts\n\nArchitecture Phase:\n- @webgen analyzes screenshots to identify needed components\n- Plans Hero, Features Grid components\n\nImplementation Phase:\n- @webgen reads hero-reference.png\n- Extracts colors, spacing, layout\n- Implements pixel-perfect Hero component matching reference\n- Documents asset usage in component docstrings\n```\n\n### Asset Types Supported\n\n| Type | Examples | Detection |\n|------|----------|-----------|\n| **Screenshots** | UI mockups, reference pages | .png, .jpg, .jpeg attachments |\n| **Designs** | Figma/Sketch exports | .fig, .sketch, .pdf exports |\n| **References** | Brand guidelines, wireframes | .pdf, image files |\n\n### Asset Catalog Schema\n\n```json\n{\n  \"version\": \"1.0\",\n  \"assets\": [\n    {\n      \"id\": \"asset-1\",\n      \"type\": \"screenshot\",\n      \"path\": \".webgen/assets/screenshots/hero-reference.png\",\n      \"description\": \"Hero section with gradient background\",\n      \"usedIn\": [\"architecture\", \"implementation\"],\n      \"tags\": [\"hero\", \"layout\", \"gradient\"]\n    }\n  ]\n}\n```\n\n### Benefits\n\n- **Pixel-perfect implementation** - Components match provided references\n- **Faster iteration** - No guessing about desired design\n- **Better communication** - Visual references clearer than text descriptions\n- **Documented decisions** - Asset usage documented in component docstrings\n\n## Design Decisions\n\n### Why a Claude Code Plugin?\n\n**Background:** This started as a standalone Next.js app using local LLMs (Ollama with Llama 3.1 and CodeLlama). After extensive experimentation, we pivoted to a claude code plugin (we were already paying for the subscription).\n\n### Privacy-First Approach\n\n**Problem:** Generating websites often requires contact information, but had industry specific considerations:\nDon't want to: \n- Ask users for personal information\n- Store PII in prompts or outputs\n- Risk exposing real contact details\n\n**Solution:** The agent NEVER asks for PII. For contact sections, it generates believable placeholders:\n- **Address:** \"123 Main Street, Anytown, ST 12345\"\n- **Phone:** \"555-XXX-XXXX\" (reserved for fiction by telecom standards)\n- **Email:** \"contact@{business-slug}.example.com\"\n- **Social:** Uses \"#\" as placeholder URLs\n\nThe user adds real data locally after generation. Possible future consideration for a --pii-safe flag and allow the normal Q&A to get company details if they exist.\n\n### Tech Stack Selection\n\n| Scenario | Stack | Reason |\n|----------|-------|--------|\n| Simple landing page | React + Vite | Fast, simple, no SSR complexity |\n| Portfolio, marketing | React + Vite | Static content, quick dev |\n| Blog, documentation | Astro | Content-focused, partial hydration |\n| App with API routes | Next.js | Server-side features needed |\n| E-commerce, auth | Next.js | Dynamic content, SSR/SSG |\n\nDefault: **React + Vite + Tailwind** for most landing pages.\n\n### Git Workflow (v1.4)\n\n**Feature Branch Workflow:**\n1. **Initialize with main branch FIRST** (Phase 3):\n   ```bash\n   git init\n   git add .gitignore README.md package.json  # Minimum viable files\n   git commit -m \"chore: initial project structure\"\n   git branch -M main  # Ensure on main branch\n   ```\n2. **Create feature branch for implementation:**\n   ```bash\n   git checkout -b feat/initial-implementation\n   ```\n3. **Atomic commits** after each logical unit with signature:\n   ```\n   feat: add hero section\n\n   ðŸ¤– Generated with webgen v1.4\n   Agent: webgen v1.4\n   ```\n4. **Push regularly:** `git push -u origin HEAD`\n5. **Merge back to main before completion** (Phase 5):\n   ```bash\n   git checkout main\n   git merge feat/initial-implementation --no-ff -m \"feat: complete {project-name}\"\n   git branch -d feat/initial-implementation  # Clean up\n   ```\n6. **Final state:** Project on `main` branch with feature branch deleted\n\n**CRITICAL:** Project MUST end on `main` branch with all changes merged.\n\n**Content Projects:** Git is optional - agent asks before initializing.\n\n### Asset Sourcing\n\nDefault placeholder sources:\n- **Photos:** Unsplash (free, high-quality)\n- **Dimensions:** placeholder.com\n- **Icons:** Heroicons, Lucide\n- **Illustrations:** unDraw\n\nAll sources documented in `docs/assets.md` with attribution requirements.\n\n## Quality Standards\n\n### Accessibility (WCAG 2.1 AA)\n\nAll generated code must include:\n- Semantic HTML (`nav`, `main`, `section`, `article`)\n- Proper heading hierarchy (h1 â†’ h2 â†’ h3)\n- Alt text for all images\n- Focus states for interactive elements\n- Color contrast 4.5:1 minimum\n\n### Performance Targets\n\n| Metric | Target | Notes |\n|--------|--------|-------|\n| Lighthouse Performance | 90+ | For production builds |\n| Lighthouse Accessibility | 100 | WCAG 2.1 AA compliance |\n| Lighthouse Best Practices | 90+ | Modern web standards |\n| Bundle Size | < 200KB | Initial load, simple sites |\n| First Contentful Paint | < 1.5s | User perception |\n| Time to Interactive | < 3.5s | Usability threshold |\n\nTargets are documented in generated README.\n\n### Code Documentation\n\nAll generated code includes:\n- Module-level docstrings (purpose, design decisions)\n- Function-level docstrings (what, parameters, returns)\n- Inline comments for complex logic (WHY, not WHAT)\n- Placeholder: `// TODO: Integrate with marketing reference library when available`\n\n## Plugin Structure\n\n```\nwebgen/\nâ”œâ”€â”€ .claude-plugin/\nâ”‚   â””â”€â”€ plugin.json              # Plugin manifest (v1.5.0)\nâ”œâ”€â”€ agents/\nâ”‚   â”œâ”€â”€ webgen.md                # Core generation agent (v1.5)\nâ”‚   â”œâ”€â”€ webgen-orchestrator.md   # PM coordination (bundled)\nâ”‚   â””â”€â”€ webgen-code-reviewer.md  # Code review (bundled)\nâ”œâ”€â”€ commands/\nâ”‚   â””â”€â”€ webgen.md                # /webgen slash command\nâ”œâ”€â”€ skills/\nâ”‚   â”œâ”€â”€ asset-management/\nâ”‚   â”‚   â””â”€â”€ skill.md             # Asset extraction, catalog, propagation\nâ”‚   â”œâ”€â”€ design-system/\nâ”‚   â”‚   â”œâ”€â”€ skill.md             # Color tokens, component classes\nâ”‚   â”‚   â””â”€â”€ references/\nâ”‚   â”‚       â””â”€â”€ shadcn.md        # Full component examples\nâ”‚   â”œâ”€â”€ project-scaffold/\nâ”‚   â”‚   â”œâ”€â”€ skill.md             # Stack selection guide\nâ”‚   â”‚   â””â”€â”€ scripts/\nâ”‚   â”‚       â”œâ”€â”€ setup-vite.sh    # React + Vite + Tailwind\nâ”‚   â”‚       â”œâ”€â”€ setup-next.sh    # Next.js + Tailwind\nâ”‚   â”‚       â””â”€â”€ setup-astro.sh   # Astro + React + Tailwind\nâ”‚   â””â”€â”€ taskflow-integration/\nâ”‚       â””â”€â”€ skill.md             # Optional TaskFlow task tracking\nâ”œâ”€â”€ docs/\nâ”‚   â”œâ”€â”€ ARCHITECTURE.md          # Full architecture documentation\nâ”‚   â”œâ”€â”€ CHANGELOG.md             # Version history\nâ”‚   â”œâ”€â”€ DECISIONS.md             # Architecture decisions\nâ”‚   â””â”€â”€ LEARNINGS.md             # Test session insights\nâ””â”€â”€ README.md                    # This file\n```\n\n**Self-contained:** All required agents and skills bundled. No external dependencies.\n\n## Components\n\n### Command: `/webgen`\n\nEntry point for the plugin. Accepts optional description argument.\n\n```yaml\narguments:\n  - name: description\n    description: What to generate\n    required: false\n```\n\n### Agent: `webgen` (v1.4)\n\nThe core agent that handles:\n- TodoWrite task management (mandatory)\n- Competitive research and capture\n- Intent parsing and clarifying questions\n- Stack selection\n- Project scaffolding with documentation structure\n- Code generation with docstrings\n- Feature branch git workflow with signatures\n- Testing setup for APIs/servers\n- Screenshot capture\n- Documentation generation\n- Template promotion\n\n### Skill: `design-system`\n\nProvides:\n- **Color tokens** - Primary (indigo), secondary (gray), accent (amber)\n- **Component classes** - btn, card, nav, hero, section, cta, footer\n- **Responsive patterns** - Container, grids, typography scale\n- **Dark mode** - Automatic via `.dark` class\n\n### Skill: `project-scaffold`\n\nProvides:\n- **Stack templates** - React+Vite, Astro, Next.js\n- **Common files** - globals.css, tailwind.config.js\n- **Folder structures** - Recommended organization per stack\n- **Quick start** - CLI commands for each stack\n\n## Success Criteria\n\nA webgen session is successful when:\n\n- [ ] TodoWrite used throughout the session\n- [ ] **Assets extracted and cataloged** (if provided)\n- [ ] **Asset catalog created** at `.webgen/assets/catalog.json` (if assets provided)\n- [ ] **Assets read in implementation phase** (if provided)\n- [ ] Competitive research saved (when applicable)\n- [ ] Project created at `{WEBGEN_OUTPUT_DIR}/{slug} - webgen/`\n- [ ] Git initialized with main branch first\n- [ ] Feature branch created for implementation\n- [ ] All commits include webgen v1.4 signature\n- [ ] Feature branch merged back to main\n- [ ] Feature branch deleted after merge\n- [ ] Project on main branch (not feature branch)\n- [ ] Code includes proper documentation\n- [ ] **Asset usage documented in component docstrings** (if applicable)\n- [ ] Tests included for API/server projects\n- [ ] Accessibility baseline met (WCAG 2.1 AA)\n- [ ] Performance targets documented\n- [ ] README.md complete with version footer\n- [ ] Design decisions documented\n- [ ] Asset sources documented\n- [ ] Preview screenshot captured\n- [ ] Template promotion asked\n- [ ] Research persisted, not ephemeral\n\n## History\n\n### v1.5.0 (2024-12-13)\n\n**Asset Management System.**\n\n**Added:**\n- **Asset extraction and cataloging** in Phase 1 (Requirements)\n- **Asset-management skill** for extraction, catalog, and propagation\n- **Asset context propagation** through all workflow phases\n- Asset awareness in Research phase (inform research direction)\n- Asset awareness in Architecture phase (identify components)\n- **Mandatory asset reading** in Implementation phase (pixel-perfect matching)\n- Asset catalog schema with metadata (id, type, path, description, usedIn, tags)\n- `.webgen/assets/` directory structure (screenshots, designs, references)\n- Updated orchestrator to include asset context in all phase dispatches\n- Documentation of asset workflow in README\n\n**Changed:**\n- Phase 1 renamed: \"Requirements\" â†’ \"Requirements + Asset Extraction\"\n- Implementation phase now requires reading reference assets before coding\n- Component docstrings must document asset usage when applicable\n\n**Benefits:**\n- Pixel-perfect implementations matching user-provided references\n- Faster iterations with visual references\n- Better communication via screenshots vs text descriptions\n\n### v1.4.0 (2024-12-13)\n\n**Self-Contained Packaging + Legal Pages.**\n\n**Added:**\n- Phase 4.5: Legal Pages (conditional phase)\n- Industry-specific templates (Privacy, Terms, Cookies, Disclosures)\n- Mandatory legal disclaimer on all generated legal pages\n- **Bundled orchestrator agent** (`webgen-orchestrator.md`)\n- **Bundled code reviewer agent** (`webgen-code-reviewer.md`)\n- **Configurable output directory** (`WEBGEN_OUTPUT_DIR`)\n- **Optional SQLite database** (`WEBGEN_DB_PATH`, empty = disabled)\n- Comprehensive architecture documentation\n\n**Changed:**\n- Workflow includes legal checkpoint between Implementation and Final\n- **Plugin is now fully self-contained** - no external agent dependencies\n- Output path configurable (default: `./webgen-projects/`)\n- Database is now optional (stateless mode when empty)\n- Removed all hardcoded paths\n\n### v1.3 (2024-12-13)\n\n**Fail-fast infrastructure + Quality assurance.**\n\n**Added:**\n- Fail-fast infrastructure verification (install + dev server before coding)\n- Anti-degradation protocol (equal effort per section)\n- Section-by-section atomic commits\n- Expanded accessibility checklist (WCAG 2.1 AA per component)\n- Network filesystem warning\n- Install timeout with escalation\n\n**Fixed:**\n- Install loop bug (no more infinite retries)\n- Duplicate project creation (existence check)\n- Quality degradation (hero strong, footer weak)\n- Monolithic commits (now atomic per section)\n\n### v1.2 (2024-12-13)\n\n**Orchestrated workflow - PM oversight at every phase.**\n\n**Added:**\n- Orchestrator integration as Product Manager\n- 5-checkpoint workflow (Requirements â†’ Research â†’ Architecture â†’ Implementation â†’ Final)\n- Phase reporting protocol for orchestrator communication\n- Code review integration at Implementation phase\n- 2-iteration maximum per phase with escalation\n- Orchestrated: true flag in agent frontmatter\n\n**Changed:**\n- Version bumped to 1.2\n- Workflow restructured into discrete phases\n- Each phase reports status to orchestrator\n- Code review now mandatory (via orchestrator)\n\n### v1.1 (2024-12-13)\n\nMajor update adding comprehensive documentation, research capture, and quality standards.\n\n**Added:**\n- Mandatory TodoWrite integration for progress tracking\n- Competitive research capture to `research/competitive-analysis.md`\n- Default output location: `/workspace/projects/webgen/`\n- Feature branch git workflow with version signatures\n- Mandatory testing for API/server projects\n- Smart git init (auto for code, ask for content projects)\n- README generation with setup instructions and version footer\n- Design decisions documentation (`docs/design-decisions.md`)\n- Asset sourcing documentation (`docs/assets.md`)\n- Screenshot capture (`docs/screenshots/preview.png`)\n- Template promotion workflow\n- Agent version tracking (v1.1)\n- Accessibility baseline (WCAG 2.1 AA)\n- Performance targets (Lighthouse 90+, <200KB bundle)\n- 15-point success criteria checklist\n\n**Changed:**\n- Project folder naming includes \" - webgen\" suffix\n- Commits include webgen version in signature\n\n### v1.0.1 (2024-12-12)\n\n**Fixed:**\n- Plugin now properly registered with Claude Code marketplace system\n- Created local-plugins marketplace infrastructure\n\n### v1.0.0 (2024-12-12)\n\nInitial release after pivoting from local LLM experiment.\n\n**What we learned from the Ollama experiment:**\n- Local LLMs aren't reliable enough for structured output\n- Code completion models (CodeLlama) copy examples verbatim\n- Orchestration (LangChain) doesn't fix model capability issues\n- Claude's instruction-following is the real differentiator\n\n**Archived:** The original Next.js + Ollama experiment is preserved in the `archive/local-llm-experiment` branch.\n\n## Future Considerations\n\n1. **Marketing reference library** - Centralized patterns for marketing projects\n2. **Template expansion** - More starter templates (blog, e-commerce, dashboard)\n3. **Design presets** - Industry-specific color schemes\n4. **Component library** - Pre-built complex components\n5. **Integration hooks** - Post-generation hooks for deployment setup\n",
        "plugins/webgen/agents/webgen-code-reviewer.md": "---\nname: webgen-code-reviewer\ndescription: Review webgen-generated websites for quality, accessibility, and best practices\nmodel: sonnet\nversion: \"2.0\"\n---\n\n# WebGen Code Reviewer v2.0\n\nSenior code reviewer for webgen-generated websites.\n\n**Responsibility:** Provide clear, actionable feedback resolvable within 2 iterations.\n\n---\n\n## REVIEW SCOPE\n\n### Priority Order (High â†’ Low)\n\n1. **CRITICAL** - Security vulnerabilities, accessibility failures\n2. **IMPORTANT** - TypeScript issues, React best practices\n3. **MINOR** - Code quality, style preferences\n\n### Review Categories\n\n| Category | Critical Checks |\n|----------|-----------------|\n| Accessibility | Semantic HTML, heading hierarchy, alt text, focus states, ARIA |\n| Security | XSS prevention, external link attrs, no hardcoded secrets |\n| TypeScript | Proper types, no `any` abuse |\n| React/Next.js | Hooks rules, key props, Link component |\n| Structure | File naming, import organization, colocation |\n\n---\n\n## OUTPUT FORMAT\n\nâ†’ See `_build/templates/code-review-template.md` for full format\n\n### Issues Found\n\n```markdown\n## CODE REVIEW: ISSUES FOUND\n\n**Project:** {path}\n**Iteration:** {X} of 2\n\n### Critical Issues (Must Fix)\n\n1. **[CRITICAL] {Title}**\n   - File: `src/components/Example.tsx:42`\n   - Issue: {description}\n   - Fix: {specific fix}\n\n### Important Issues (Should Fix)\n\n1. **[IMPORTANT] {Title}**\n   - File: `src/components/Nav.tsx:28`\n   - Issue: {description}\n   - Fix: {specific fix}\n\n---\n**Summary:** Critical: {n}, Important: {n}\n**Verdict:** ISSUES FOUND\n```\n\n### Approved\n\n```markdown\n## CODE REVIEW: APPROVED\n\n**Project:** {path}\n\n| Category | Status |\n|----------|--------|\n| Accessibility | âœ… Pass |\n| Security | âœ… Pass |\n| TypeScript | âœ… Pass |\n| React | âœ… Pass |\n| Structure | âœ… Pass |\n\n**Verdict:** APPROVED\n```\n\n---\n\n## ACCESSIBILITY CHECKLIST (WCAG 2.1 AA)\n\n```\nStructure:\n- [ ] Semantic HTML (nav, main, section, article)\n- [ ] Single <main> per page\n- [ ] Heading hierarchy (h1 â†’ h2 â†’ h3, no skips)\n- [ ] Skip link present\n\nImages & Media:\n- [ ] All <img> have alt attribute\n- [ ] Decorative images have alt=\"\"\n\nInteractive Elements:\n- [ ] All buttons have accessible names\n- [ ] Icon-only buttons have aria-label\n- [ ] Focus visible on all interactive elements\n\nColor & Contrast:\n- [ ] Text contrast â‰¥ 4.5:1 (normal) / 3:1 (large)\n- [ ] Information not conveyed by color alone\n\nMotion:\n- [ ] prefers-reduced-motion respected\n```\n\n---\n\n## COMMON ISSUES\n\n| Issue | Detection | Fix |\n|-------|-----------|-----|\n| Missing aria-label | Icon-only button | Add `aria-label=\"Menu\"` |\n| Heading skip | h1 â†’ h3 | Add missing h2 |\n| Missing focus styles | No focus-visible | Add `focus-visible:ring-2` |\n| External link risk | target=\"_blank\" | Add `rel=\"noopener noreferrer\"` |\n| Key on index | `key={index}` | Use unique ID |\n| Any type abuse | `any` in TypeScript | Add proper types |\n\n---\n\n## TWO-ITERATION MINDSET\n\n**Round 1:** Focus on CRITICAL security and accessibility issues only.\n**Round 2:** If issues remain, be extremely specific.\n\nAfter Round 2 with unresolved issues â†’ Escalate to user with clear summary.\n\n---\n\n## ACTIONABLE FEEDBACK\n\nEvery issue must have:\n- Specific file and line number\n- Clear problem description\n- Concrete fix (code example when helpful)\n- Severity level\n\n**Bad:** \"The accessibility could be improved\"\n\n**Good:**\n```markdown\n**[CRITICAL] Missing aria-label on mobile menu toggle**\n- File: `src/components/Nav.tsx:42`\n- Issue: Icon-only button without accessible name\n- Fix: Add `aria-label=\"Toggle menu\"` and `aria-hidden=\"true\"` on icon\n```\n\n---\n\n**Generated by webgen v2.0**\n",
        "plugins/webgen/agents/webgen-orchestrator.md": "---\nname: webgen-orchestrator\ndescription: Coordinate website generation with quality checkpoints\nmodel: sonnet\nversion: \"2.0\"\n---\n\n# WebGen Orchestrator v2.0\n\nCoordinate the webgen agent through 5 quality checkpoints with automated code review.\n\n## FIRST-RUN SETUP\n\n**On first invocation, check for configuration:**\n\n```bash\nCONFIG_FILE=\"$HOME/.gsc-plugins/webgen.local.md\"\nif [ ! -f \"$CONFIG_FILE\" ]; then\n  # Trigger first-run setup\n  FIRST_RUN=true\nfi\n```\n\n### First-Run Prompt\n\n```markdown\n## WebGen Setup\n\nNo configuration found. Let's set up your preferences.\n\n**Knowledge Storage:**\nHow should WebGen store learnings across projects?\n\n1. **SQLite** (Recommended) - Fast, local, structured queries\n2. **Markdown** - Simple files, git-friendly\n3. **Worklog** - Cross-project sharing via worklog plugin\n   {{#if WORKLOG_AVAILABLE}}[Available âœ“]{{else}}[Not installed]{{/if}}\n\n**Default Preferences:**\nWould you like to set default preferences for:\n- Framework (React+Vite, Next.js, Astro)\n- Styling approach (Tailwind, CSS-in-JS)\n\nOr use progressive selection each time? (Recommended for new users)\n```\n\n**Save to:** `~/.gsc-plugins/webgen.local.md`\n\n---\n\n## PROGRESSIVE DISCOVERY\n\n**At CP1, detect optional plugins and suggest installation:**\n\n```python\n# Check for complementary plugins\nPLUGIN_DIRS = [\n    \"~/.claude/plugins/local-plugins\",\n    \"~/.claude/plugins/marketplaces/gsc-plugins\"\n]\n\ndef detect_plugin(name):\n    for base in PLUGIN_DIRS:\n        if os.path.exists(os.path.expanduser(f\"{base}/{name}\")):\n            return True\n    return False\n\nTASKFLOW_AVAILABLE = detect_plugin(\"taskflow\")\nWORKLOG_AVAILABLE = detect_plugin(\"worklog\")\n```\n\n### Plugin Suggestions\n\n**If TaskFlow not installed:**\n\n```markdown\nTaskFlow can track tasks for this project.\n\nBenefits:\n- Parse design requirements into tasks\n- Track progress across sessions\n- Sync with Gitea kanban boards\n\nInstall now?\n[Y] claude plugin install taskflow@gsc-plugins\n[N] Continue without task tracking\n```\n\n**If Worklog not installed and user chose \"Worklog\" storage:**\n\n```markdown\nWorklog plugin required for cross-project knowledge sharing.\n\nBenefits:\n- Store design patterns across projects\n- Recall context at session start\n- Share knowledge between webgen/appgen/docs\n\nInstall now?\n[Y] claude plugin install worklog@gsc-plugins && /worklog-init\n[N] Switch to SQLite storage instead\n```\n\n**Auto-install workflow:**\n\n```python\nif user_choice == \"install_worklog\":\n    # Run installation\n    os.system(\"claude plugin install worklog@gsc-plugins\")\n\n    # Auto-run init\n    print(\"Running worklog initialization...\")\n    # /worklog-init will detect webgen and offer integration\n\n    # Update webgen config to use worklog\n    update_config(\"~/.gsc-plugins/webgen.local.md\", {\n        \"knowledge_storage\": \"worklog\"\n    })\n```\n\n---\n\n## CONFIGURATION\n\n| Variable | Default | Purpose |\n|----------|---------|---------|\n| `WEBGEN_OUTPUT_DIR` | `./webgen-projects` | Output directory |\n| Config file | `~/.gsc-plugins/webgen.local.md` | User preferences |\n\n---\n\n## 5-CHECKPOINT WORKFLOW\n\n```\n/webgen [description]\n       â”‚\n       â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ CP1: REQUIREMENTS - Validate scope with user     â”‚\nâ”‚      â†’ Detect reference assets                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ CP2: RESEARCH - Competitive analysis             â”‚\nâ”‚      â†’ Asset-informed research                   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ CP3: ARCHITECTURE - Project scaffold             â”‚\nâ”‚      â†’ Ask \"stub API?\" if backend needed         â”‚\nâ”‚      â†’ Verify infrastructure                     â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ CP4: IMPLEMENTATION - Code generation            â”‚\nâ”‚      â†’ Code review (max 2 iterations)            â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ CP4.5: LEGAL PAGES (Conditional)                 â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ CP5: FINAL - Documentation, merge to main        â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n       â”‚\n       â–¼\n   [COMPLETE]\n```\n\n---\n\n## CRITICAL RULES\n\n### 2-Iteration Maximum\n\n```\nMax iterations per phase: 2\nAfter 2 failures: ESCALATE TO USER\nNO EXCEPTIONS\n```\n\n### Immediate Escalation\n\nBypass iteration limits for:\n- Ambiguous requirements\n- Trade-off decisions needed\n- Technical impossibility\n- Scope expansion\n- Infrastructure failures\n\n---\n\n## CHECKPOINT DETAILS\n\n### CP1: REQUIREMENTS\n\n**Your actions:**\n1. Parse user description\n2. Detect reference assets (screenshots, designs)\n3. Detect plugins: TaskFlow? Worklog?\n4. Ask clarifying questions\n5. Get user approval\n\n**Dispatch @webgen for asset extraction if assets detected:**\n```markdown\n@webgen:\n**Phase:** Requirements + Asset Extraction\n**Detected Assets:** [list]\nExtract assets to .webgen/assets/ directory.\nCreate catalog.json with metadata.\n```\n\n**Output:**\n```markdown\n## CHECKPOINT 1: REQUIREMENTS\n\n**Project:** [Name/description]\n**Type:** [Landing page / Multi-page / Component]\n**Industry:** [e.g., Fintech, Healthcare, SaaS]\n**Design:** [Modern, minimal, bold]\n\n**Reference Assets:** [X] assets detected\n**Output Directory:** {output_dir}/{slug}/\n\nPlease confirm to proceed.\n```\n\n---\n\n### CP2: RESEARCH\n\n**Your actions:**\n1. Dispatch @webgen for research **with asset context**\n2. Review `research/competitive-analysis.md`\n3. Validate insights are actionable\n\n**Review criteria:**\n- [ ] Competitors appropriate for industry\n- [ ] Insights actionable\n- [ ] Assets reviewed (if provided)\n\n---\n\n### CP3: ARCHITECTURE\n\n**Your actions:**\n1. **If backend/API features needed and not specified, ask:**\n   > \"Should we stub the API layer using the adapter pattern?\n   > This allows building UI first without backend setup.\"\n2. Dispatch @webgen for scaffolding\n3. Verify infrastructure works:\n   ```bash\n   pnpm install  # Must succeed\n   pnpm dev      # Must start\n   ```\n\n**Review criteria:**\n- [ ] Tech stack appropriate\n- [ ] Dependencies installed\n- [ ] Dev server runs\n- [ ] Git on feature branch\n\n**Infrastructure failure:** Escalate immediately (don't count as iteration)\n\n---\n\n### CP4: IMPLEMENTATION\n\n**Your actions:**\n1. Dispatch @webgen for code generation **with asset context**\n2. Dispatch @webgen-code-reviewer for validation\n3. If issues: iterate (max 2)\n\n**Code Review Dispatch:**\n```markdown\n@webgen-code-reviewer:\n**Project:** {project-path}\n**Iteration:** [1/2]\n\nReview: code quality, accessibility, security, TypeScript.\nReport: APPROVED or ISSUES FOUND.\n```\n\n**Review criteria:**\n- [ ] All components generated\n- [ ] Code review passed\n- [ ] Accessibility baseline met\n- [ ] Preview working\n\n---\n\n### CP4.5: LEGAL PAGES (Conditional)\n\n**Condition:** Generate if data collection, auth, payments, or regulated industry.\n\n**Skip if:** Simple portfolio, docs, internal tools.\n\n---\n\n### CP5: FINAL\n\n**Your actions:**\n1. Dispatch @webgen for documentation\n2. Verify git merge to main\n3. Offer template promotion\n\n**Review criteria:**\n- [ ] README complete\n- [ ] Screenshot captured\n- [ ] Feature branch merged to main\n- [ ] On main branch\n\n---\n\n## FINAL STEPS\n\n1. **Merge feature branch:**\n   ```bash\n   git checkout main\n   git merge feat/initial-implementation --no-ff\n   git branch -d feat/initial-implementation\n   ```\n\n2. **Report to user:**\n   ```markdown\n   ## PROJECT COMPLETE âœ“\n\n   **Website:** {name}\n   **Location:** {path}\n   **Stack:** {framework} + {styling}\n\n   **Quick Start:**\n   ```bash\n   cd {project}\n   pnpm install && pnpm dev\n   ```\n\n   **Documentation:**\n   - README.md - Setup instructions\n   - docs/design-decisions.md - Design system\n\n   Generated by webgen v2.0\n   ```\n\n---\n\n## ERROR HANDLING\n\n### Infrastructure Failures\n\n1. First failure: Retry once\n2. Second failure: Check logs\n3. Third failure: Escalate immediately\n\n### Agent Disagreement\n\nAfter 2 iterations without resolution:\n\n```markdown\n## ESCALATION: DISAGREEMENT\n\n**Phase:** [name]\n**Issue:** [description]\n**Options:**\n1. Accept current implementation\n2. Try alternative approach\n3. Simplify scope\n\nYour preference?\n```\n\n---\n\n## SUCCESS CRITERIA\n\n- [ ] All 5 checkpoints completed\n- [ ] Max 2 iterations per phase respected\n- [ ] Code review passed\n- [ ] Feature branch merged to main\n- [ ] User has clear next steps\n\n---\n\n**Generated by webgen v2.0**\n",
        "plugins/webgen/agents/webgen.md": "---\nname: webgen\ndescription: Generate websites, components, and features from natural language\nmodel: sonnet\ncolor: blue\nversion: \"2.0\"\norchestrated: true\n---\n\n# WebGen Agent v2.0\n\nWeb development expert generating production-ready websites from natural language.\n\n## KNOWLEDGE-FIRST ARCHITECTURE\n\n**Before making any technology decisions, query the knowledge base:**\n\n```\n1. Check ~/.gsc-plugins/webgen.local.md for user preferences\n2. Query knowledge base for similar past projects\n3. Apply progressive frameworks only if KB has no preference\n4. Ask \"stub first?\" for database/API if backend features needed\n```\n\n### Storage Configuration\n\nAt session start, detect storage mode from config:\n\n```yaml\n# ~/.gsc-plugins/webgen.local.md\nknowledge_storage: sqlite | markdown | worklog\n```\n\n**Query Order:**\n1. `sqlite` â†’ Query `~/.gsc-plugins/knowledge.db`\n2. `markdown` â†’ Search `~/.gsc-plugins/knowledge/*.md`\n3. `worklog` â†’ `mcp__worklog__search_knowledge(query=\"webgen preferences\")`\n4. No config â†’ Use progressive frameworks (ask user preferences)\n\n---\n\n## ORCHESTRATION PROTOCOL\n\nManaged by orchestrator through 5 checkpoints:\n\n| Phase | Checkpoint | Deliverable |\n|-------|------------|-------------|\n| 1 | Requirements | Confirmed scope + assets |\n| 2 | Research | `research/competitive-analysis.md` |\n| 3 | Architecture | Scaffolded project, dev server running |\n| 4 | Implementation | Generated components, code review passed |\n| 5 | Final | Documentation, merged to main |\n\n### Phase Reporting Format\n\n```markdown\n## PHASE COMPLETE: [NAME]\n**Deliverables:** [list]\n**Files:** [list]\n**Ready for:** [next phase]\n**Issues:** [any blockers]\n```\n\n---\n\n## PHASE 1: REQUIREMENTS + ASSETS\n\nOrchestrator handles requirements gathering. You receive confirmed:\n- Project type (landing page, multi-page, component)\n- Industry/domain\n- Design preferences\n- Target audience\n- Reference assets (if provided)\n\n### Asset Extraction\n\nIf reference assets detected (screenshots, designs):\n\n1. Create `.webgen/assets/` directory structure\n2. Catalog each asset with metadata\n3. Map assets to phases (architecture, implementation)\n\n**Catalog Schema:**\n```json\n{\n  \"assets\": [{\n    \"id\": \"asset-1\",\n    \"type\": \"screenshot\",\n    \"path\": \".webgen/assets/screenshots/hero-reference.png\",\n    \"description\": \"Hero section with gradient background\",\n    \"usedIn\": [\"architecture\", \"implementation\"]\n  }]\n}\n```\n\n---\n\n## PHASE 2: RESEARCH\n\n### Query Knowledge Base First\n\n```markdown\nBefore recommending approach:\n1. Query KB: \"What frameworks has this user preferred?\"\n2. Query KB: \"What styling approaches for similar projects?\"\n3. If KB has preferences â†’ Use them\n4. If KB empty â†’ Apply progressive framework\n```\n\n### Progressive Tech Stack Selection\n\nâ†’ **Framework:** See `_build/frameworks/framework-selection.md`\n\n**Default Stack (when no preference):**\n\n| Layer | Default | Reasoning |\n|-------|---------|-----------|\n| Framework | React + Vite | Fast, no SSR complexity |\n| Styling | Tailwind CSS | Utility-first, rapid |\n| Content-heavy | Astro | Partial hydration |\n| Server features | Next.js | API routes, SSR |\n\n**Deliverable:** `research/competitive-analysis.md`\n\n---\n\n## PHASE 3: ARCHITECTURE + INFRASTRUCTURE\n\n### Stub-First Question (If API Features Needed)\n\n**If project requires backend/API and not specified, ask orchestrator:**\n\n> \"This project needs backend features. Should we stub the API layer using the adapter pattern? This allows building UI first without backend setup.\"\n\nâ†’ See `_build/frameworks/database-selection.md` (Level 0: Stub)\n\n### Project Scaffolding\n\n1. Initialize with chosen framework\n2. Install dependencies (`pnpm install`)\n3. Start dev server - **MUST verify it runs**\n4. Initialize git on feature branch\n\n### Standard Structure\n\n```\n{project}/\nâ”œâ”€â”€ research/            # Competitive analysis\nâ”œâ”€â”€ docs/                # Documentation, screenshots\nâ”œâ”€â”€ src/                 # Source code\nâ”œâ”€â”€ tests/               # Test files (if applicable)\nâ””â”€â”€ .webgen/             # WebGen metadata, assets\n    â””â”€â”€ assets/\n```\n\n### Git Initialization\n\n```bash\ngit init\ngit add .\ngit commit -m \"chore: initial project structure\"\ngit checkout -b feat/initial-implementation\n```\n\n**Infrastructure Verification (MANDATORY):**\n- [ ] `pnpm install` completed successfully\n- [ ] Dev server starts without errors\n- [ ] Base route (/) responds\n\n---\n\n## PHASE 4: IMPLEMENTATION\n\n### Reference Assets - CRITICAL\n\n**If reference assets exist, MUST read them before implementing:**\n\n```bash\n# Load asset catalog\ncat .webgen/assets/catalog.json\n\n# Read each asset to understand visual requirements\nRead(.webgen/assets/screenshots/hero-reference.png)\n```\n\n**Asset-Driven Implementation:**\n- Extract colors, typography, spacing from references\n- Match layouts closely\n- Document asset usage in component docstrings\n\n### Coding Standards\n\n- TypeScript strict mode, no `any`\n- Semantic HTML (`nav`, `main`, `section`, `article`)\n- WCAG 2.1 AA accessibility baseline\n- Atomic commits per component\n\n### Anti-Degradation Protocol\n\n**Equal effort per section** - Footer deserves same attention as Hero.\n\n**Per-section checklist:**\n1. GENERATE section code\n2. VERIFY hot reload - no errors\n3. CHECK quality against Hero baseline\n4. VERIFY accessibility\n5. COMMIT immediately\n6. MOVE to next section\n\n### Accessibility Baseline (MANDATORY)\n\n- Proper heading hierarchy (h1 â†’ h2 â†’ h3)\n- Alt text for ALL images\n- Focus states for interactive elements\n- Color contrast 4.5:1 minimum\n- ARIA labels for icon-only buttons\n- Skip link for keyboard navigation\n- `prefers-reduced-motion` support\n\n---\n\n## PHASE 4.5: LEGAL PAGES (Conditional)\n\n**Generate legal pages if project includes:**\n- Contact forms or data collection\n- User accounts or authentication\n- Payment processing\n- Regulated industries\n\n**Skip if:** Simple portfolio, documentation, internal tools\n\n**MANDATORY disclaimer on all legal pages:**\n```html\n<!-- This document was auto-generated as a starting template. -->\n<!-- Consult with a qualified attorney before publishing. -->\n```\n\n---\n\n## PHASE 5: FINAL\n\n### Documentation Requirements\n\n**README.md:**\n- Project overview, tech stack\n- Setup instructions\n- Design decisions summary\n- Footer: \"Generated by webgen v2.0\"\n\n**docs/design-decisions.md:**\n- Colors, fonts, spacing\n- Breakpoints, reference to research\n\n### Git Finalization\n\n```bash\ngit checkout main\ngit merge feat/initial-implementation --no-ff\ngit branch -d feat/initial-implementation\n```\n\n**Verification:**\n- [ ] Feature branch merged to main\n- [ ] On main branch\n- [ ] All documentation complete\n\n---\n\n## QUALITY CHECKLIST\n\n### Per Project\n\n- [ ] Lighthouse Performance 90+\n- [ ] Lighthouse Accessibility 100\n- [ ] Bundle size < 200KB\n- [ ] FCP < 1.5s\n- [ ] TTI < 3.5s\n\n### Security\n\n- [ ] No hardcoded secrets\n- [ ] External links have `rel=\"noopener noreferrer\"`\n- [ ] HTTPS for all external resources\n\n---\n\n**Generated by webgen v2.0**\n",
        "plugins/webgen/commands/webgen.md": "---\ndescription: Generate websites, components, or features from natural language\narguments:\n  - name: description\n    description: What to generate (e.g., \"restaurant landing page\", \"pricing component\")\n    required: false\n---\n\n# WebGen Command\n\nGenerate web projects from natural language descriptions with orchestrated quality control.\n\n## Usage\n\n```\n/webgen [description]\n```\n\n## Examples\n\n```\n/webgen restaurant landing page for Bistro Bliss\n/webgen portfolio site for a freelance designer\n/webgen pricing component with 3 tiers\n/webgen multi-page healthcare site for Clarity Health\n/webgen                  # Interactive mode - will ask questions\n```\n\n## Configuration\n\n### Output Directory\n\nProjects are created in a configurable location:\n\n| Variable | Default | Description |\n|----------|---------|-------------|\n| `WEBGEN_OUTPUT_DIR` | `./webgen-projects` | Base directory for generated projects |\n\nSet via environment variable or the orchestrator will use the default.\n\n### Database (Optional)\n\n| Variable | Default | Description |\n|----------|---------|-------------|\n| `WEBGEN_DB_PATH` | *(empty)* | SQLite for cross-session learning. Empty = disabled |\n\n---\n\n## Orchestrated Workflow\n\nWebGen uses **@webgen-orchestrator** as Product Manager to ensure quality at every phase:\n\n```\nUser Request\n    â†“\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   @webgen-orchestrator (PM Agent)   â”‚\nâ”‚  Validates requirements, approves   â”‚\nâ”‚  each phase, manages iterations     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n    â†“\n[Checkpoint 1: Requirements]\nPM validates scope and requirements\n    â†“\n[Checkpoint 2: Research Review]\nPM reviews competitive analysis\n    â†“\n[Checkpoint 3: Architecture Review]\nPM reviews structure and tech stack\n    â†“\n[Checkpoint 4: Code Review]\n@webgen-code-reviewer validates implementation\n    â†“\n[Checkpoint 4.5: Legal Pages]\n(Conditional - if applicable)\n    â†“\n[Checkpoint 5: Final Sign-off]\nPM confirms all requirements met\n    â†“\nDone\n```\n\n## Key Features\n\n- **PM Orchestration:** Every phase reviewed before proceeding\n- **Quality Gates:** 2-iteration max per phase, then escalates to user\n- **Configurable Output:** Projects go to `{WEBGEN_OUTPUT_DIR}/{slug} - webgen/`\n- **Competitive Research:** Saves competitor analysis to `research/` folder\n- **Comprehensive Documentation:** README, design decisions, asset sources\n- **Screenshot Capture:** Saves preview to docs/screenshots/preview.png\n- **Default Design System:** GSDEV Baseline 2026 with OKLch colors - see KB 451\n- **Accessibility Baseline:** WCAG 2.1 AA compliance\n- **Performance Targets:** Documents Lighthouse and bundle size goals\n- **Legal Pages:** Industry-specific privacy, terms, disclosures with disclaimers\n- **Signed Work:** All commits include webgen v1.5 signature\n- **Feature Branches:** Uses git feature branch workflow\n- **Testing:** Automatic test setup for API/server projects\n- **Template Promotion:** Offers to save successful projects as reusable templates\n\n## Bundled Agents\n\nThis plugin includes all required agents:\n\n| Agent | Purpose |\n|-------|---------|\n| `@webgen` | Core website generation agent |\n| `@webgen-orchestrator` | PM coordination and quality gates |\n| `@webgen-code-reviewer` | Code quality and accessibility validation |\n\nNo external agent dependencies required.\n\n## Invoke Orchestrator\n\nThis command invokes the **@webgen-orchestrator** agent to manage the workflow.\n\nThe orchestrator will:\n1. Validate requirements with user (Checkpoint 1)\n2. Dispatch @webgen for research phase, then review (Checkpoint 2)\n3. Dispatch @webgen for scaffold phase, then review (Checkpoint 3)\n4. Dispatch @webgen for code generation, dispatch @webgen-code-reviewer (Checkpoint 4)\n5. Dispatch @webgen for legal pages if applicable (Checkpoint 4.5)\n6. Final sign-off confirming all requirements met (Checkpoint 5)\n\n**Orchestration Context:**\n\n```\nDomain: webgen\nCreator Agent: @webgen\nReviewer Agent: @webgen-code-reviewer\nOrchestrator: @webgen-orchestrator\nPhases: requirements â†’ research â†’ architecture â†’ implementation â†’ legal â†’ final\nOutput: ${WEBGEN_OUTPUT_DIR:-./webgen-projects}/{project-slug} - webgen/\nPreferences: ${WEBGEN_OUTPUT_DIR:-./webgen-projects}/preferences.md (optional)\nDatabase: ${WEBGEN_DB_PATH} (optional, empty = disabled)\nMax Iterations: 2 per phase (then escalate to user)\n```\n\n$ARGUMENTS\n",
        "plugins/webgen/skills/asset-management/skill.md": "---\nname: asset-management\ndescription: Extract, catalog, and propagate reference assets (screenshots, designs) throughout the webgen workflow\nversion: \"1.0\"\n---\n\n# Asset Management Skill\n\n**Purpose:** Detect, extract, catalog, and propagate reference assets (screenshots, UI mockups, design files) provided by users throughout the entire webgen workflow, ensuring all implementation agents have access to visual references.\n\n## Problem Solved\n\n**Before:** Users provide screenshots or design references in the initial prompt, but these assets:\n- Are not cataloged or tracked\n- Don't reach architecture/implementation agents\n- Get lost in the workflow\n- Result in implementations that don't match the reference\n\n**After:** Assets are extracted, cataloged, and made available to every phase of the workflow.\n\n---\n\n## Asset Catalog Structure\n\n### Directory Layout\n\n```\n.webgen/\nâ”œâ”€â”€ assets/\nâ”‚   â”œâ”€â”€ catalog.json           # Asset manifest with metadata\nâ”‚   â”œâ”€â”€ screenshots/           # UI reference screenshots\nâ”‚   â”œâ”€â”€ designs/              # Design files (Figma, Sketch exports)\nâ”‚   â”œâ”€â”€ references/           # Other reference materials\nâ”‚   â””â”€â”€ README.md             # Asset usage instructions\n```\n\n### Catalog Schema (catalog.json)\n\n```json\n{\n  \"version\": \"1.0\",\n  \"created\": \"2024-12-13T10:00:00Z\",\n  \"updated\": \"2024-12-13T10:00:00Z\",\n  \"projectSlug\": \"example-project\",\n  \"assets\": [\n    {\n      \"id\": \"asset-1\",\n      \"type\": \"screenshot\",\n      \"originalName\": \"hero-reference.png\",\n      \"path\": \".webgen/assets/screenshots/hero-reference.png\",\n      \"description\": \"Hero section layout with gradient background\",\n      \"source\": \"user-prompt\",\n      \"usedIn\": [\"architecture\", \"implementation\"],\n      \"tags\": [\"hero\", \"layout\", \"gradient\"],\n      \"metadata\": {\n        \"width\": 1920,\n        \"height\": 1080,\n        \"format\": \"png\"\n      }\n    }\n  ]\n}\n```\n\n**Field Definitions:**\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `id` | string | Unique identifier (asset-1, asset-2, etc.) |\n| `type` | string | Asset type: screenshot, design, reference, mockup |\n| `originalName` | string | Original filename from user |\n| `path` | string | Relative path within project |\n| `description` | string | What the asset shows/represents |\n| `source` | string | Where it came from: user-prompt, research, generated |\n| `usedIn` | array | Which phases need this: requirements, architecture, implementation, etc. |\n| `tags` | array | Searchable tags: hero, navigation, footer, layout, color-scheme |\n| `metadata` | object | Additional info: dimensions, format, color palette |\n\n---\n\n## Workflow Integration\n\n### Phase 1: Requirements (Asset Extraction)\n\n**When:** User provides `/webgen` command with description\n\n**Action:** Detect and extract assets from the prompt context\n\n**Detection Logic:**\n```javascript\n// Pseudo-code for asset detection\nfunction detectAssets(prompt, attachments) {\n  const assets = [];\n\n  // Check for explicit asset references\n  if (prompt.includes(\"screenshot\") || prompt.includes(\"reference image\")) {\n    // Asset mentioned\n  }\n\n  // Check for file attachments (Claude Code provides these)\n  if (attachments && attachments.length > 0) {\n    attachments.forEach(file => {\n      if (isImageFile(file)) {\n        assets.push(createAssetEntry(file));\n      }\n    });\n  }\n\n  // Check shared screenshots location\n  const screenshotsDir = \"~/workspace/screenshots/\";\n  // Look for recently added files if user mentioned them\n\n  return assets;\n}\n```\n\n**Extraction Process:**\n1. Scan prompt for asset references\n2. Check for file attachments in Claude Code context\n3. Check `~/workspace/screenshots/` if user mentioned screenshots\n4. Copy assets to `.webgen/assets/{type}/`\n5. Generate catalog.json entries\n6. Add to orchestrator context for handoff\n\n### Phase 2: Research (Asset Awareness)\n\n**When:** Orchestrator dispatches @webgen for competitive research\n\n**Action:** Make researcher aware of provided assets\n\n**Handoff Context:**\n```markdown\n## Reference Assets Provided\n\nThe following assets were provided for this project:\n- **asset-1**: Hero section reference (path: .webgen/assets/screenshots/hero-reference.png)\n  - Use to understand desired layout and visual style\n  - Tags: hero, layout, gradient\n\nAnalyze these assets to inform your competitive research and recommendations.\n```\n\n### Phase 3: Architecture (Asset-Driven Decisions)\n\n**When:** Orchestrator dispatches @webgen for project scaffolding\n\n**Action:** Include asset context in architecture decisions\n\n**Handoff Context:**\n```markdown\n## Architecture Context - Reference Assets\n\nThe following reference assets are available:\n{{#each assets}}\n- **{{id}}**: {{description}}\n  - Path: {{path}}\n  - Type: {{type}}\n  - Relevant for: {{usedIn}}\n{{/each}}\n\n**Architecture Guidance:**\n- Review reference assets to inform component structure\n- Identify components needed based on visual references\n- Consider layout patterns shown in screenshots\n```\n\n### Phase 4: Implementation (Direct Asset Access)\n\n**When:** Orchestrator dispatches @webgen for code generation\n\n**Action:** Provide direct asset references to implementation agents\n\n**Handoff Context:**\n```markdown\n## Implementation Assets - CRITICAL\n\nYou have access to the following reference assets. **Read and analyze these BEFORE implementing:**\n\n{{#each assets where usedIn includes \"implementation\"}}\n### {{id}}: {{description}}\n- **Path:** {{path}}\n- **Use for:** {{usedIn}}\n- **Tags:** {{tags}}\n\n**MANDATORY:** Use the Read tool to view this asset before implementing related components.\n```\n\n**Read Command Example:**\n```bash\n# Agent should execute:\nRead(.webgen/assets/screenshots/hero-reference.png)\n# This provides visual context for pixel-perfect implementation\n```\n\n### Phase 5: Final (Asset Documentation)\n\n**When:** Final documentation generation\n\n**Action:** Document assets used in the project\n\n**Generated Section (docs/assets.md):**\n```markdown\n# Reference Assets\n\nThis project was generated using the following reference assets:\n\n## Screenshots\n- **hero-reference.png**: Hero section layout reference\n  - Source: User-provided\n  - Used for: Hero component design and layout\n\n## Usage\nAll reference assets are stored in `.webgen/assets/` for future reference.\n```\n\n---\n\n## API: Asset Functions\n\n### extractAssets(prompt, attachments)\n\n**Purpose:** Extract assets from user input and attachments\n\n**Returns:** Array of asset objects\n\n```javascript\n{\n  id: \"asset-1\",\n  type: \"screenshot\",\n  originalName: \"ui-reference.png\",\n  tempPath: \"/tmp/asset-1.png\",  // Before copying to project\n  description: \"Auto-detected from user prompt\",\n  tags: []\n}\n```\n\n### createCatalog(projectPath, assets)\n\n**Purpose:** Initialize asset catalog in project\n\n**Actions:**\n1. Create `.webgen/assets/` directory structure\n2. Copy assets from temp location to project\n3. Generate `catalog.json` with metadata\n4. Create `README.md` with usage instructions\n\n**Returns:** Path to catalog.json\n\n### loadCatalog(projectPath)\n\n**Purpose:** Load existing catalog for a project\n\n**Returns:** Catalog object with assets array\n\n### addAsset(catalogPath, assetData)\n\n**Purpose:** Add new asset to existing catalog (e.g., from research phase)\n\n**Updates:** catalog.json with new entry and updated timestamp\n\n### getAssetsForPhase(catalogPath, phaseName)\n\n**Purpose:** Filter assets relevant for specific phase\n\n**Returns:** Subset of assets where `usedIn` includes phaseName\n\n---\n\n## Asset Type Detection\n\n### Image Assets\n\n**Extensions:** .png, .jpg, .jpeg, .gif, .webp, .svg\n\n**Analysis:**\n- Extract dimensions\n- Detect primary colors (for color palette inference)\n- Identify UI sections (hero, navigation, footer)\n\n### Design Files\n\n**Extensions:** .fig (Figma export), .sketch (Sketch export), .xd (Adobe XD)\n\n**Note:** These are typically exported as images or PDFs for webgen processing\n\n### Reference Documents\n\n**Extensions:** .pdf (brand guidelines, wireframes)\n\n**Processing:** Extract relevant pages as images if needed\n\n---\n\n## Asset Propagation Protocol\n\n### Orchestrator Responsibility\n\nThe **@webgen-orchestrator** must:\n\n1. **Phase 1 (Requirements):** Invoke asset extraction\n   ```markdown\n   @webgen: Extract any reference assets from the user prompt.\n   Use the asset-management skill to create catalog.\n   ```\n\n2. **Phase 2+ (All subsequent phases):** Include asset context in dispatch\n   ```markdown\n   @webgen: Proceeding to [PHASE].\n\n   **Reference Assets Available:**\n   - Review catalog at .webgen/assets/catalog.json\n   - Read assets before implementing related components\n\n   Load catalog using asset-management skill for full context.\n   ```\n\n3. **Handoff verification:** Ensure catalog.json exists before proceeding to implementation\n\n### Agent Responsibility\n\nEach **@webgen** agent invocation must:\n\n1. **Load catalog** at phase start\n2. **Read relevant assets** for the current phase\n3. **Reference assets** in implementation decisions\n4. **Update catalog** if new assets discovered (e.g., from research)\n\n---\n\n## Example Workflow\n\n### User Provides Screenshot\n\n```\nUser: /webgen restaurant landing page. I want it to look like this:\n[Attaches: hero-reference.png]\n\nDescription: Modern hero section with large food image and reservation button\n```\n\n### Phase 1: Asset Extraction\n\n```\n@webgen (Requirements phase):\n1. Detect attachment: hero-reference.png\n2. Create .webgen/assets/screenshots/hero-reference.png\n3. Generate catalog.json:\n   {\n     \"assets\": [{\n       \"id\": \"asset-1\",\n       \"type\": \"screenshot\",\n       \"path\": \".webgen/assets/screenshots/hero-reference.png\",\n       \"description\": \"Hero section reference - large food image with reservation button\",\n       \"usedIn\": [\"architecture\", \"implementation\"],\n       \"tags\": [\"hero\", \"food-image\", \"cta-button\"]\n     }]\n   }\n4. Report to orchestrator: \"Asset catalog created with 1 screenshot\"\n```\n\n### Phase 3: Architecture\n\n```\n@webgen (Architecture phase):\n1. Load catalog.json\n2. Read asset-1 to understand layout requirements\n3. Identify components needed: Hero (with image background), CTAButton\n4. Include in architecture report: \"Hero component based on asset-1 reference\"\n```\n\n### Phase 4: Implementation\n\n```\n@webgen (Implementation phase):\n1. Load catalog.json\n2. Read .webgen/assets/screenshots/hero-reference.png\n3. Analyze:\n   - Image fills full viewport height\n   - Text overlays image with dark gradient\n   - CTA button prominent, centered\n   - Color scheme: warm tones (extracted from image)\n4. Implement Hero component matching reference\n5. Document: \"Hero section implements layout from asset-1\"\n```\n\n---\n\n## Fallbacks and Edge Cases\n\n### No Assets Provided\n\n**Behavior:** Skip asset extraction, proceed normally\n**Catalog:** Create empty catalog.json for consistency\n\n```json\n{\n  \"version\": \"1.0\",\n  \"assets\": []\n}\n```\n\n### Assets Mentioned But Not Attached\n\n**Behavior:** Prompt user to provide the asset\n\n```markdown\nYou mentioned a screenshot/reference but I don't see an attachment.\nPlease provide the file, or I can proceed without it using competitive research for design inspiration.\n```\n\n### Asset Not Readable\n\n**Behavior:** Log error, continue without asset\n\n```markdown\nâš ï¸ Warning: Could not read asset-1 (hero-reference.png).\nProceeding with competitive research for design guidance instead.\n```\n\n### Large Asset Files\n\n**Threshold:** > 10MB\n\n**Behavior:** Store reference in catalog but don't inline in prompts\n\n```markdown\nAsset-2 (design-mockup.pdf) is large (15MB).\nStored in catalog for manual reference, but not loaded automatically.\n```\n\n---\n\n## Success Criteria\n\nAsset management is successful when:\n\n- [ ] Assets detected from user prompt/attachments\n- [ ] Catalog created at `.webgen/assets/catalog.json`\n- [ ] Assets copied to appropriate subdirectories\n- [ ] Orchestrator includes assets in phase handoffs\n- [ ] Architecture agent reviews assets before scaffolding\n- [ ] Implementation agents read assets before coding\n- [ ] Final documentation includes asset references\n- [ ] Asset-driven decisions documented\n\n---\n\n## Integration Checklist\n\nTo integrate asset management into webgen:\n\n### Skill Files\n- [x] `skills/asset-management/skill.md` (this file)\n\n### Agent Updates\n- [ ] `agents/webgen.md` - Add Phase 1 asset extraction\n- [ ] `agents/webgen-orchestrator.md` - Add asset propagation\n\n### Command Updates\n- [ ] `commands/webgen.md` - Mention asset support in docs\n\n### Documentation\n- [ ] `README.md` - Add asset management to features\n- [ ] `docs/ARCHITECTURE.md` - Document asset flow\n\n---\n\n## Future Enhancements\n\n1. **Automatic Color Extraction:** Analyze screenshots to extract color palette\n2. **Component Detection:** Use AI to identify components in screenshots (hero, nav, footer)\n3. **Figma Integration:** Direct import from Figma URLs\n4. **Asset Versioning:** Track asset changes across iterations\n5. **Multi-Asset Comparison:** Compare multiple reference screenshots\n\n---\n\n**Version:** 1.0\n**Created:** 2024-12-13\n**Requires:** webgen v1.4+\n",
        "plugins/webgen/skills/design-system/references/shadcn.md": "# shadcn/ui Inspired Patterns\n\nReference patterns based on shadcn/ui design principles.\n\n## Philosophy\n\n1. **Composable** - Small, focused components that combine well\n2. **Customizable** - CSS variables for easy theming\n3. **Accessible** - Built with a11y in mind\n4. **Consistent** - Unified visual language\n\n## Complete Component Examples\n\n### Navigation with Mobile Menu\n\n```tsx\nimport { useState } from 'react';\nimport { Menu, X } from 'lucide-react';\n\nexport function Navigation() {\n  const [isOpen, setIsOpen] = useState(false);\n\n  return (\n    <nav className=\"nav\">\n      <div className=\"nav-container\">\n        <a href=\"/\" className=\"nav-logo\">Brand</a>\n\n        {/* Desktop Nav */}\n        <div className=\"nav-links\">\n          <a href=\"#features\" className=\"nav-link\">Features</a>\n          <a href=\"#pricing\" className=\"nav-link\">Pricing</a>\n          <a href=\"#about\" className=\"nav-link\">About</a>\n          <button className=\"btn btn-primary btn-sm\">Get Started</button>\n        </div>\n\n        {/* Mobile Toggle */}\n        <button\n          className=\"md:hidden\"\n          onClick={() => setIsOpen(!isOpen)}\n          aria-label=\"Toggle menu\"\n        >\n          {isOpen ? <X size={24} /> : <Menu size={24} />}\n        </button>\n      </div>\n\n      {/* Mobile Menu */}\n      {isOpen && (\n        <div className=\"md:hidden border-t\">\n          <div className=\"container py-4 space-y-4\">\n            <a href=\"#features\" className=\"block nav-link\">Features</a>\n            <a href=\"#pricing\" className=\"block nav-link\">Pricing</a>\n            <a href=\"#about\" className=\"block nav-link\">About</a>\n            <button className=\"btn btn-primary w-full\">Get Started</button>\n          </div>\n        </div>\n      )}\n    </nav>\n  );\n}\n```\n\n### Hero with Background Pattern\n\n```tsx\nexport function Hero() {\n  return (\n    <section className=\"hero relative\">\n      {/* Optional background pattern */}\n      <div className=\"absolute inset-0 -z-10 bg-[radial-gradient(#e5e7eb_1px,transparent_1px)] [background-size:16px_16px] opacity-50\" />\n\n      <div className=\"hero-container\">\n        <span className=\"inline-block px-4 py-1.5 mb-6 text-sm font-medium bg-primary/10 text-primary rounded-full\">\n          Now in Beta\n        </span>\n\n        <h1 className=\"hero-title\">\n          Build faster with\n          <span className=\"text-primary\"> modern tools</span>\n        </h1>\n\n        <p className=\"hero-subtitle\">\n          Create beautiful, responsive websites in minutes.\n          No design skills required.\n        </p>\n\n        <div className=\"hero-actions\">\n          <button className=\"btn btn-primary btn-lg\">\n            Start Building\n            <ArrowRight className=\"ml-2 h-4 w-4\" />\n          </button>\n          <button className=\"btn btn-outline btn-lg\">\n            View Demo\n          </button>\n        </div>\n      </div>\n    </section>\n  );\n}\n```\n\n### Feature Grid\n\n```tsx\nimport { Zap, Shield, Sparkles } from 'lucide-react';\n\nconst features = [\n  {\n    icon: Zap,\n    title: \"Lightning Fast\",\n    description: \"Optimized for speed with automatic code splitting and lazy loading.\"\n  },\n  {\n    icon: Shield,\n    title: \"Secure by Default\",\n    description: \"Built-in security features protect your site and users.\"\n  },\n  {\n    icon: Sparkles,\n    title: \"Beautiful Design\",\n    description: \"Pre-built components that look great out of the box.\"\n  }\n];\n\nexport function Features() {\n  return (\n    <section className=\"section\">\n      <div className=\"container\">\n        <div className=\"section-header\">\n          <h2 className=\"section-title\">Everything you need</h2>\n          <p className=\"section-subtitle\">\n            Powerful features to help you build amazing websites.\n          </p>\n        </div>\n\n        <div className=\"grid-features\">\n          {features.map((feature) => (\n            <div key={feature.title} className=\"feature-card\">\n              <div className=\"h-12 w-12 rounded-lg bg-primary/10 flex items-center justify-center mb-4\">\n                <feature.icon className=\"h-6 w-6 text-primary\" />\n              </div>\n              <h3 className=\"text-lg font-semibold mb-2\">{feature.title}</h3>\n              <p className=\"text-muted-foreground\">{feature.description}</p>\n            </div>\n          ))}\n        </div>\n      </div>\n    </section>\n  );\n}\n```\n\n### Pricing Cards\n\n```tsx\nimport { Check } from 'lucide-react';\n\nconst plans = [\n  {\n    name: \"Starter\",\n    price: \"$9\",\n    description: \"Perfect for side projects\",\n    features: [\"5 projects\", \"Basic analytics\", \"Email support\"],\n  },\n  {\n    name: \"Pro\",\n    price: \"$29\",\n    description: \"For growing businesses\",\n    features: [\"Unlimited projects\", \"Advanced analytics\", \"Priority support\", \"Custom domains\"],\n    popular: true,\n  },\n  {\n    name: \"Enterprise\",\n    price: \"$99\",\n    description: \"For large teams\",\n    features: [\"Everything in Pro\", \"SSO\", \"Dedicated support\", \"SLA\"],\n  },\n];\n\nexport function Pricing() {\n  return (\n    <section className=\"section bg-muted/50\">\n      <div className=\"container\">\n        <div className=\"section-header\">\n          <h2 className=\"section-title\">Simple Pricing</h2>\n          <p className=\"section-subtitle\">\n            Choose the plan that works for you.\n          </p>\n        </div>\n\n        <div className=\"grid gap-8 md:grid-cols-3 max-w-5xl mx-auto\">\n          {plans.map((plan) => (\n            <div\n              key={plan.name}\n              className={`pricing-card ${\n                plan.popular ? 'border-primary ring-2 ring-primary' : ''\n              }`}\n            >\n              {plan.popular && (\n                <span className=\"inline-block px-3 py-1 text-xs font-medium bg-primary text-primary-foreground rounded-full mb-4\">\n                  Most Popular\n                </span>\n              )}\n\n              <h3 className=\"text-xl font-bold\">{plan.name}</h3>\n              <p className=\"text-muted-foreground text-sm mt-1\">{plan.description}</p>\n\n              <div className=\"my-6\">\n                <span className=\"text-4xl font-bold\">{plan.price}</span>\n                <span className=\"text-muted-foreground\">/month</span>\n              </div>\n\n              <ul className=\"space-y-3 text-left mb-8\">\n                {plan.features.map((feature) => (\n                  <li key={feature} className=\"flex items-center gap-2\">\n                    <Check className=\"h-4 w-4 text-primary\" />\n                    <span className=\"text-sm\">{feature}</span>\n                  </li>\n                ))}\n              </ul>\n\n              <button\n                className={`btn w-full ${\n                  plan.popular ? 'btn-primary' : 'btn-outline'\n                }`}\n              >\n                Get Started\n              </button>\n            </div>\n          ))}\n        </div>\n      </div>\n    </section>\n  );\n}\n```\n\n### Testimonial Section\n\n```tsx\nconst testimonials = [\n  {\n    quote: \"This tool has completely transformed how we build websites. Highly recommended!\",\n    author: \"Sarah Johnson\",\n    role: \"Lead Developer\",\n    company: \"TechCorp\",\n  },\n  {\n    quote: \"The design system is beautiful and the components are so easy to customize.\",\n    author: \"Mike Chen\",\n    role: \"Designer\",\n    company: \"Creative Studio\",\n  },\n  {\n    quote: \"We shipped our new site in half the time. The quality is incredible.\",\n    author: \"Emily Davis\",\n    role: \"Product Manager\",\n    company: \"StartupXYZ\",\n  },\n];\n\nexport function Testimonials() {\n  return (\n    <section className=\"section\">\n      <div className=\"container\">\n        <div className=\"section-header\">\n          <h2 className=\"section-title\">Loved by developers</h2>\n          <p className=\"section-subtitle\">\n            See what others are saying about us.\n          </p>\n        </div>\n\n        <div className=\"grid-features\">\n          {testimonials.map((t) => (\n            <div key={t.author} className=\"testimonial-card\">\n              <p className=\"text-lg mb-6\">\"{t.quote}\"</p>\n              <div className=\"not-italic\">\n                <p className=\"font-semibold\">{t.author}</p>\n                <p className=\"text-sm text-muted-foreground\">\n                  {t.role}, {t.company}\n                </p>\n              </div>\n            </div>\n          ))}\n        </div>\n      </div>\n    </section>\n  );\n}\n```\n\n### CTA Section\n\n```tsx\nexport function CTA() {\n  return (\n    <section className=\"cta\">\n      <div className=\"cta-container\">\n        <h2 className=\"cta-title\">Ready to get started?</h2>\n        <p className=\"cta-subtitle\">\n          Join thousands of developers building amazing websites.\n        </p>\n        <div className=\"cta-actions\">\n          <button className=\"btn btn-lg bg-white text-primary hover:bg-white/90\">\n            Start Free Trial\n          </button>\n          <button className=\"btn btn-lg border-white/30 text-white hover:bg-white/10\">\n            Contact Sales\n          </button>\n        </div>\n      </div>\n    </section>\n  );\n}\n```\n\n### Footer\n\n```tsx\nexport function Footer() {\n  return (\n    <footer className=\"footer\">\n      <div className=\"footer-container\">\n        <div className=\"footer-section\">\n          <h3 className=\"footer-title\">Brand</h3>\n          <p className=\"text-sm text-muted-foreground\">\n            Building the future of web development.\n          </p>\n        </div>\n\n        <div className=\"footer-section\">\n          <h4 className=\"footer-title\">Product</h4>\n          <div className=\"footer-links\">\n            <a href=\"#\" className=\"footer-link block\">Features</a>\n            <a href=\"#\" className=\"footer-link block\">Pricing</a>\n            <a href=\"#\" className=\"footer-link block\">Changelog</a>\n          </div>\n        </div>\n\n        <div className=\"footer-section\">\n          <h4 className=\"footer-title\">Company</h4>\n          <div className=\"footer-links\">\n            <a href=\"#\" className=\"footer-link block\">About</a>\n            <a href=\"#\" className=\"footer-link block\">Blog</a>\n            <a href=\"#\" className=\"footer-link block\">Careers</a>\n          </div>\n        </div>\n\n        <div className=\"footer-section\">\n          <h4 className=\"footer-title\">Legal</h4>\n          <div className=\"footer-links\">\n            <a href=\"#\" className=\"footer-link block\">Privacy</a>\n            <a href=\"#\" className=\"footer-link block\">Terms</a>\n          </div>\n        </div>\n      </div>\n\n      <div className=\"footer-bottom\">\n        <p>&copy; 2024 Brand. All rights reserved.</p>\n      </div>\n    </footer>\n  );\n}\n```\n\n## Industry-Specific Patterns\n\n### Restaurant\n\n```tsx\n// Menu Item Card\n<div className=\"card p-4 flex gap-4\">\n  <img src={item.image} alt={item.name} className=\"w-24 h-24 rounded-lg object-cover\" />\n  <div className=\"flex-1\">\n    <div className=\"flex justify-between items-start\">\n      <h3 className=\"font-semibold\">{item.name}</h3>\n      <span className=\"text-primary font-bold\">${item.price}</span>\n    </div>\n    <p className=\"text-sm text-muted-foreground mt-1\">{item.description}</p>\n  </div>\n</div>\n\n// Reservation CTA\n<section className=\"cta bg-amber-700\">\n  <div className=\"cta-container\">\n    <h2 className=\"cta-title\">Reserve Your Table</h2>\n    <p className=\"cta-subtitle\">Experience exceptional dining</p>\n    <button className=\"btn btn-lg bg-white text-amber-700\">\n      Make Reservation\n    </button>\n  </div>\n</section>\n```\n\n### Portfolio\n\n```tsx\n// Project Card with Hover\n<div className=\"group relative overflow-hidden rounded-lg\">\n  <img\n    src={project.image}\n    alt={project.title}\n    className=\"w-full aspect-video object-cover transition-transform group-hover:scale-105\"\n  />\n  <div className=\"absolute inset-0 bg-black/60 opacity-0 group-hover:opacity-100 transition-opacity flex items-center justify-center\">\n    <div className=\"text-center text-white p-4\">\n      <h3 className=\"text-xl font-bold\">{project.title}</h3>\n      <p className=\"text-sm mt-2\">{project.category}</p>\n      <button className=\"btn btn-outline border-white text-white mt-4\">\n        View Project\n      </button>\n    </div>\n  </div>\n</div>\n```\n\n### SaaS Dashboard\n\n```tsx\n// Stats Card\n<div className=\"card p-6\">\n  <div className=\"flex items-center justify-between\">\n    <div>\n      <p className=\"text-sm text-muted-foreground\">Total Revenue</p>\n      <p className=\"text-2xl font-bold mt-1\">$45,231.89</p>\n      <p className=\"text-xs text-green-600 mt-1\">+20.1% from last month</p>\n    </div>\n    <div className=\"h-12 w-12 rounded-full bg-primary/10 flex items-center justify-center\">\n      <DollarSign className=\"h-6 w-6 text-primary\" />\n    </div>\n  </div>\n</div>\n```\n\n## Animation Patterns\n\n```css\n/* Subtle entrance */\n@keyframes fadeIn {\n  from { opacity: 0; transform: translateY(10px); }\n  to { opacity: 1; transform: translateY(0); }\n}\n\n.animate-fade-in {\n  animation: fadeIn 0.5s ease-out;\n}\n\n/* Staggered children */\n.stagger-children > * {\n  animation: fadeIn 0.5s ease-out backwards;\n}\n.stagger-children > *:nth-child(1) { animation-delay: 0ms; }\n.stagger-children > *:nth-child(2) { animation-delay: 100ms; }\n.stagger-children > *:nth-child(3) { animation-delay: 200ms; }\n```\n\n## Icon Usage\n\nUse [Lucide React](https://lucide.dev/) for icons:\n\n```tsx\nimport { ArrowRight, Check, Menu, X, Zap, Shield, Sparkles } from 'lucide-react';\n\n// Usage\n<ArrowRight className=\"h-4 w-4\" />\n```\n\nCommon icons by purpose:\n- Navigation: `Menu`, `X`, `ChevronDown`\n- Actions: `ArrowRight`, `Plus`, `Edit`, `Trash`\n- Status: `Check`, `AlertCircle`, `Info`\n- Features: `Zap`, `Shield`, `Sparkles`, `Globe`\n- Social: `Github`, `Twitter`, `Linkedin`\n",
        "plugins/webgen/skills/design-system/skill.md": "---\nname: design-system\ndescription: Shadcn-inspired design system with CSS variables, component classes, and responsive patterns for generated websites\n---\n\n# Design System Skill\n\n**Type:** Reference Skill\n**Purpose:** Provide consistent, modern styling patterns for generated websites\n\n## Overview\n\nThis skill provides a shadcn-inspired design system with CSS variables, component classes, and responsive patterns. Use this as the foundation for all generated components.\n\n## Usage\n\nWhen generating components, reference:\n1. Color tokens via CSS variables\n2. Component classes for consistent styling\n3. Responsive patterns for mobile-first design\n4. Dark mode support via `.dark` class\n\n## Core Design Tokens\n\n### Colors (HSL Format)\n\n```css\n:root {\n  /* Primary - Deep indigo */\n  --primary: 243 75% 59%;\n  --primary-foreground: 0 0% 100%;\n\n  /* Secondary - Soft gray */\n  --secondary: 240 5% 96%;\n  --secondary-foreground: 240 6% 10%;\n\n  /* Accent - Warm amber */\n  --accent: 35 92% 60%;\n  --accent-foreground: 35 92% 10%;\n\n  /* Background & Foreground */\n  --background: 0 0% 100%;\n  --foreground: 240 10% 4%;\n\n  /* Muted */\n  --muted: 240 5% 96%;\n  --muted-foreground: 240 4% 46%;\n\n  /* Card */\n  --card: 0 0% 100%;\n  --card-foreground: 240 10% 4%;\n\n  /* Border & Input */\n  --border: 240 6% 90%;\n  --input: 240 6% 90%;\n  --ring: 243 75% 59%;\n\n  /* Radius */\n  --radius: 0.5rem;\n}\n\n.dark {\n  --primary: 243 75% 70%;\n  --primary-foreground: 0 0% 100%;\n  --secondary: 240 4% 16%;\n  --secondary-foreground: 0 0% 98%;\n  --accent: 35 92% 50%;\n  --background: 240 10% 4%;\n  --foreground: 0 0% 98%;\n  --muted: 240 4% 16%;\n  --muted-foreground: 240 5% 65%;\n  --card: 240 6% 10%;\n  --card-foreground: 0 0% 98%;\n  --border: 240 4% 16%;\n  --input: 240 4% 16%;\n}\n```\n\n## Component Classes\n\n### Buttons\n\n```css\n.btn {\n  @apply inline-flex items-center justify-center rounded-md text-sm font-medium\n         transition-colors focus-visible:outline-none focus-visible:ring-2\n         focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50;\n}\n\n.btn-primary {\n  @apply bg-primary text-primary-foreground hover:bg-primary/90;\n}\n\n.btn-secondary {\n  @apply bg-secondary text-secondary-foreground hover:bg-secondary/80;\n}\n\n.btn-outline {\n  @apply border border-input bg-background hover:bg-accent hover:text-accent-foreground;\n}\n\n.btn-ghost {\n  @apply hover:bg-accent hover:text-accent-foreground;\n}\n\n/* Sizes */\n.btn-sm { @apply h-9 px-3; }\n.btn-md { @apply h-10 px-4 py-2; }\n.btn-lg { @apply h-11 px-8; }\n```\n\n### Cards\n\n```css\n.card {\n  @apply rounded-lg border bg-card text-card-foreground shadow-sm;\n}\n\n.card-header {\n  @apply flex flex-col space-y-1.5 p-6;\n}\n\n.card-content {\n  @apply p-6 pt-0;\n}\n\n.card-footer {\n  @apply flex items-center p-6 pt-0;\n}\n\n/* Variants */\n.feature-card {\n  @apply card p-6 hover:shadow-md transition-shadow;\n}\n\n.pricing-card {\n  @apply card p-8 text-center;\n}\n\n.testimonial-card {\n  @apply card p-6 italic;\n}\n```\n\n### Navigation\n\n```css\n.nav {\n  @apply sticky top-0 z-50 w-full border-b bg-background/95 backdrop-blur;\n}\n\n.nav-container {\n  @apply container flex h-16 items-center justify-between;\n}\n\n.nav-logo {\n  @apply text-xl font-bold;\n}\n\n.nav-links {\n  @apply hidden md:flex items-center space-x-6;\n}\n\n.nav-link {\n  @apply text-sm font-medium text-muted-foreground hover:text-foreground transition-colors;\n}\n\n.nav-link-active {\n  @apply text-foreground;\n}\n```\n\n### Hero Sections\n\n```css\n.hero {\n  @apply relative py-20 md:py-32 overflow-hidden;\n}\n\n.hero-container {\n  @apply container flex flex-col items-center text-center;\n}\n\n.hero-title {\n  @apply text-4xl md:text-6xl font-bold tracking-tight;\n}\n\n.hero-subtitle {\n  @apply mt-6 text-xl text-muted-foreground max-w-2xl;\n}\n\n.hero-actions {\n  @apply mt-10 flex flex-col sm:flex-row gap-4;\n}\n```\n\n### Sections\n\n```css\n.section {\n  @apply py-16 md:py-24;\n}\n\n.section-header {\n  @apply text-center mb-12;\n}\n\n.section-title {\n  @apply text-3xl md:text-4xl font-bold;\n}\n\n.section-subtitle {\n  @apply mt-4 text-lg text-muted-foreground max-w-2xl mx-auto;\n}\n```\n\n### Footer\n\n```css\n.footer {\n  @apply border-t bg-muted/50 py-12;\n}\n\n.footer-container {\n  @apply container grid gap-8 md:grid-cols-4;\n}\n\n.footer-section {\n  @apply space-y-4;\n}\n\n.footer-title {\n  @apply font-semibold;\n}\n\n.footer-links {\n  @apply space-y-2 text-sm text-muted-foreground;\n}\n\n.footer-link {\n  @apply hover:text-foreground transition-colors;\n}\n\n.footer-bottom {\n  @apply container mt-8 pt-8 border-t text-center text-sm text-muted-foreground;\n}\n```\n\n### CTA (Call to Action)\n\n```css\n.cta {\n  @apply py-16 md:py-24 bg-primary text-primary-foreground;\n}\n\n.cta-container {\n  @apply container text-center;\n}\n\n.cta-title {\n  @apply text-3xl md:text-4xl font-bold;\n}\n\n.cta-subtitle {\n  @apply mt-4 text-lg opacity-90 max-w-2xl mx-auto;\n}\n\n.cta-actions {\n  @apply mt-8 flex flex-col sm:flex-row gap-4 justify-center;\n}\n```\n\n## Responsive Patterns\n\n### Container\n```css\n.container {\n  @apply mx-auto max-w-7xl px-4 sm:px-6 lg:px-8;\n}\n```\n\n### Grid Layouts\n```css\n/* 2 columns on md, 3 on lg */\n.grid-features {\n  @apply grid gap-8 md:grid-cols-2 lg:grid-cols-3;\n}\n\n/* 2 columns on sm, 3 on md, 4 on lg */\n.grid-cards {\n  @apply grid gap-6 sm:grid-cols-2 md:grid-cols-3 lg:grid-cols-4;\n}\n```\n\n### Typography Scale\n```css\n.text-display { @apply text-5xl md:text-7xl font-bold; }\n.text-h1 { @apply text-4xl md:text-5xl font-bold; }\n.text-h2 { @apply text-3xl md:text-4xl font-bold; }\n.text-h3 { @apply text-2xl md:text-3xl font-semibold; }\n.text-h4 { @apply text-xl md:text-2xl font-semibold; }\n.text-body { @apply text-base; }\n.text-small { @apply text-sm; }\n```\n\n## Usage Example\n\n```tsx\nexport function Hero() {\n  return (\n    <section className=\"hero\">\n      <div className=\"hero-container\">\n        <h1 className=\"hero-title\">\n          Welcome to Our Site\n        </h1>\n        <p className=\"hero-subtitle\">\n          A compelling description of what we offer.\n        </p>\n        <div className=\"hero-actions\">\n          <button className=\"btn btn-primary btn-lg\">\n            Get Started\n          </button>\n          <button className=\"btn btn-outline btn-lg\">\n            Learn More\n          </button>\n        </div>\n      </div>\n    </section>\n  );\n}\n```\n\n## Tailwind Config Integration\n\nAdd to `tailwind.config.js`:\n\n```js\nmodule.exports = {\n  theme: {\n    extend: {\n      colors: {\n        border: \"hsl(var(--border))\",\n        input: \"hsl(var(--input))\",\n        ring: \"hsl(var(--ring))\",\n        background: \"hsl(var(--background))\",\n        foreground: \"hsl(var(--foreground))\",\n        primary: {\n          DEFAULT: \"hsl(var(--primary))\",\n          foreground: \"hsl(var(--primary-foreground))\",\n        },\n        secondary: {\n          DEFAULT: \"hsl(var(--secondary))\",\n          foreground: \"hsl(var(--secondary-foreground))\",\n        },\n        muted: {\n          DEFAULT: \"hsl(var(--muted))\",\n          foreground: \"hsl(var(--muted-foreground))\",\n        },\n        accent: {\n          DEFAULT: \"hsl(var(--accent))\",\n          foreground: \"hsl(var(--accent-foreground))\",\n        },\n        card: {\n          DEFAULT: \"hsl(var(--card))\",\n          foreground: \"hsl(var(--card-foreground))\",\n        },\n      },\n      borderRadius: {\n        lg: \"var(--radius)\",\n        md: \"calc(var(--radius) - 2px)\",\n        sm: \"calc(var(--radius) - 4px)\",\n      },\n    },\n  },\n}\n```\n\n## References\n\nSee `references/shadcn.md` for detailed component patterns and examples.\n",
        "plugins/webgen/skills/project-scaffold/skill.md": "---\nname: project-scaffold\ndescription: Setup scripts for React+Vite, Astro, and Next.js projects with design system integration\n---\n\n# Project Scaffold Skill\n\n**Type:** Reference Skill\n**Purpose:** Provide setup scripts for React+Vite, Astro, and Next.js projects\n\n## Overview\n\nThis skill provides executable setup scripts for the three supported tech stacks. Each script:\n- Creates the project with the official CLI\n- Configures Tailwind with our design system\n- Adds the component utility classes\n- Initializes git with an initial commit\n\n## Setup Scripts\n\nLocated in `scripts/`:\n\n| Script | Stack | Usage |\n|--------|-------|-------|\n| `setup-vite.sh` | React + Vite + Tailwind | `./setup-vite.sh my-project` |\n| `setup-next.sh` | Next.js + Tailwind | `./setup-next.sh my-project` |\n| `setup-astro.sh` | Astro + React + Tailwind | `./setup-astro.sh my-project` |\n\n### Usage\n\n```bash\n# From the plugin scripts directory\n~/.claude/plugins/local-plugins/webgen/skills/project-scaffold/scripts/setup-vite.sh my-landing-page\n\n# Or reference the full path\n${CLAUDE_PLUGIN_ROOT}/skills/project-scaffold/scripts/setup-vite.sh my-landing-page\n```\n\n## Stack Selection Guide\n\n| Need | Recommendation | Script |\n|------|---------------|--------|\n| Simple landing page | React + Vite | `setup-vite.sh` |\n| Portfolio, marketing | React + Vite | `setup-vite.sh` |\n| Blog, documentation | Astro | `setup-astro.sh` |\n| Content-heavy site | Astro | `setup-astro.sh` |\n| App with API routes | Next.js | `setup-next.sh` |\n| Dynamic content/auth | Next.js | `setup-next.sh` |\n| E-commerce | Next.js | `setup-next.sh` |\n\n## What Each Script Does\n\n### setup-vite.sh\n\n1. `pnpm create vite@latest` with react-ts template\n2. Adds tailwindcss, postcss, autoprefixer, lucide-react\n3. Creates tailwind.config.js with design system colors\n4. Creates index.css with CSS variables and component classes\n5. Creates src/components directory\n6. Creates CHANGELOG.md\n7. `git init` + initial commit\n\n### setup-next.sh\n\n1. `pnpm create next-app@latest` with TypeScript, Tailwind, App Router\n2. Adds lucide-react\n3. Updates tailwind.config.ts with design system colors\n4. Updates globals.css with CSS variables and component classes\n5. Creates src/components directory\n6. Creates CHANGELOG.md\n7. Amends initial commit\n\n### setup-astro.sh\n\n1. `pnpm create astro@latest` with minimal template\n2. Adds @astrojs/tailwind, @astrojs/react, lucide-react\n3. Creates tailwind.config.mjs with design system colors\n4. Creates src/styles/globals.css with CSS variables and classes\n5. Creates src/layouts/Layout.astro base layout\n6. Creates CHANGELOG.md\n7. `git init` + initial commit\n\n## Folder Structures Created\n\n### React + Vite\n```\nproject-name/\nâ”œâ”€â”€ public/\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ components/\nâ”‚   â”œâ”€â”€ App.tsx\nâ”‚   â”œâ”€â”€ main.tsx\nâ”‚   â””â”€â”€ index.css\nâ”œâ”€â”€ index.html\nâ”œâ”€â”€ package.json\nâ”œâ”€â”€ tailwind.config.js\nâ”œâ”€â”€ postcss.config.js\nâ”œâ”€â”€ tsconfig.json\nâ”œâ”€â”€ vite.config.ts\nâ”œâ”€â”€ CHANGELOG.md\nâ””â”€â”€ .gitignore\n```\n\n### Next.js (App Router)\n```\nproject-name/\nâ”œâ”€â”€ public/\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ app/\nâ”‚   â”‚   â”œâ”€â”€ layout.tsx\nâ”‚   â”‚   â”œâ”€â”€ page.tsx\nâ”‚   â”‚   â””â”€â”€ globals.css\nâ”‚   â””â”€â”€ components/\nâ”œâ”€â”€ package.json\nâ”œâ”€â”€ tailwind.config.ts\nâ”œâ”€â”€ tsconfig.json\nâ”œâ”€â”€ next.config.js\nâ”œâ”€â”€ CHANGELOG.md\nâ””â”€â”€ .gitignore\n```\n\n### Astro\n```\nproject-name/\nâ”œâ”€â”€ public/\nâ”œâ”€â”€ src/\nâ”‚   â”œâ”€â”€ components/\nâ”‚   â”œâ”€â”€ layouts/\nâ”‚   â”‚   â””â”€â”€ Layout.astro\nâ”‚   â”œâ”€â”€ pages/\nâ”‚   â”‚   â””â”€â”€ index.astro\nâ”‚   â””â”€â”€ styles/\nâ”‚       â””â”€â”€ globals.css\nâ”œâ”€â”€ package.json\nâ”œâ”€â”€ tailwind.config.mjs\nâ”œâ”€â”€ astro.config.mjs\nâ”œâ”€â”€ tsconfig.json\nâ”œâ”€â”€ CHANGELOG.md\nâ””â”€â”€ .gitignore\n```\n\n## Dev Server Ports\n\nAfter running setup:\n\n```bash\ncd project-name\npnpm dev\n```\n\n| Stack | Port |\n|-------|------|\n| Vite | http://localhost:5173 |\n| Next.js | http://localhost:3000 |\n| Astro | http://localhost:4321 |\n\n## Design System Included\n\nAll scripts inject the same design system:\n\n### CSS Variables\n- `--primary`: Deep indigo (243 75% 59%)\n- `--secondary`: Soft gray (240 5% 96%)\n- `--accent`: Warm amber (35 92% 60%)\n- Full dark mode variants\n\n### Component Classes\n- Buttons: `.btn`, `.btn-primary`, `.btn-secondary`, `.btn-outline`\n- Cards: `.card`, `.feature-card`, `.pricing-card`, `.testimonial-card`\n- Layout: `.nav`, `.hero`, `.section`, `.cta`, `.footer`\n- Grid: `.grid-features`, `.grid-cards`\n\n## Customizing Scripts\n\nEdit the scripts to:\n- Change default dependencies\n- Add additional setup steps\n- Modify the design system\n- Add project-specific configuration\n\nScripts are version-controlled, so changes are tracked.\n",
        "plugins/webgen/skills/taskflow-integration/skill.md": "---\nname: taskflow-integration\ndescription: Optional TaskFlow integration for WebGen projects\nversion: 1.0.0\n---\n\n# TaskFlow Integration Skill\n\n**Purpose:** Enable optional task management for WebGen projects when TaskFlow plugin is available.\n\n**Integration Type:** Non-breaking, opt-in\n\n---\n\n## Core Principle: Optional Enhancement\n\n**This skill provides TaskFlow integration WITHOUT breaking WebGen when TaskFlow is unavailable.**\n\n**Rules:**\n- âœ… Detect TaskFlow availability before offering integration\n- âœ… Gracefully degrade if TaskFlow not found\n- âœ… User can decline even if TaskFlow is available\n- âœ… NEVER error if TaskFlow missing\n- âœ… WebGen works identically with or without TaskFlow\n\n---\n\n## Detection Protocol\n\n### 1. Check TaskFlow Availability\n\n**At webgen session start**, check for TaskFlow:\n\n```bash\n# Method 1: Check for taskflow plugin directory\nif [ -d \"$HOME/.claude/plugins/local-plugins/taskflow\" ]; then\n  TASKFLOW_AVAILABLE=true\nelse\n  TASKFLOW_AVAILABLE=false\nfi\n\n# Method 2: Try to locate task command\nif command -v task-init &> /dev/null; then\n  TASKFLOW_AVAILABLE=true\nfi\n```\n\n**Store result** in session context:\n- `taskflow_available: true|false`\n- `taskflow_enabled: true|false` (user's choice)\n\n### 2. Offer Integration (If Available)\n\n**After requirements confirmed (Checkpoint 1):**\n\n```markdown\n## CHECKPOINT 1 COMPLETE\n\n**Project:** {project-name}\n**Type:** {project-type}\n**Output:** {output-dir}\n\n**TaskFlow Detected:**\nI detected TaskFlow is available. Would you like to track this project with tasks?\n\n- **Yes** - Initialize task tracking, break requirements into tasks\n- **No** - Continue with standard WebGen workflow\n\nWhat would you like to do?\n```\n\n**If user declines:**\n```markdown\nUnderstood. Proceeding with standard WebGen workflow...\n```\n\n**If user accepts:**\n```markdown\nâœ… TaskFlow enabled for this project.\nInitializing task tracking...\n```\n\n---\n\n## Integration Points\n\n### Phase 1: Requirements â†’ Task Initialization\n\n**Trigger:** User accepts TaskFlow integration\n\n**Actions:**\n1. Initialize TaskFlow in project directory\n2. Create initial task structure from requirements\n3. Optionally parse requirements as PRD\n\n**Implementation:**\n\n```bash\ncd {output-dir}\n\n# Initialize TaskFlow\n/task-init\n\n# Option A: Parse requirements.md as PRD (if structured)\nif [ -f \"docs/requirements.md\" ]; then\n  /task-parse docs/requirements.md\nfi\n\n# Option B: Create tasks manually from requirements\n# (Use if requirements not in PRD format)\n```\n\n**Task Structure from Requirements:**\n\n```json\n{\n  \"tasks\": [\n    {\n      \"id\": 1,\n      \"title\": \"Conduct competitive research\",\n      \"description\": \"Research {industry} competitors and extract design patterns\",\n      \"status\": \"pending\",\n      \"priority\": \"high\",\n      \"phase\": \"research\",\n      \"acceptanceCriteria\": [\n        \"3+ competitors analyzed\",\n        \"Research saved to research/competitive-analysis.md\"\n      ]\n    },\n    {\n      \"id\": 2,\n      \"title\": \"Scaffold project architecture\",\n      \"description\": \"Initialize {tech-stack} project with proper structure\",\n      \"status\": \"pending\",\n      \"priority\": \"high\",\n      \"phase\": \"architecture\",\n      \"dependencies\": [1],\n      \"acceptanceCriteria\": [\n        \"Project structure created\",\n        \"Dev server running\",\n        \"Infrastructure verified\"\n      ]\n    },\n    {\n      \"id\": 3,\n      \"title\": \"Implement {component-name}\",\n      \"description\": \"Generate {component-name} component\",\n      \"status\": \"pending\",\n      \"priority\": \"medium\",\n      \"phase\": \"implementation\",\n      \"dependencies\": [2]\n    }\n  ]\n}\n```\n\n### Phase 2-4: Task Tracking During Implementation\n\n**At each checkpoint:**\n\n**Before starting phase:**\n```bash\n/task-status {task-id} in_progress\n```\n\n**During implementation:**\n- Update subtasks as components completed\n- Track blockers if encountered\n- Use `/task-next` for prioritization\n\n**After phase complete:**\n```bash\n/task-status {task-id} done\n```\n\n**Example for Checkpoint 4 (Implementation):**\n\n```markdown\nStarting Implementation phase...\n\n# Update TaskFlow\n/task-status 3 in_progress\n\n# Generate components\n[Component generation...]\n\n# Mark subtasks complete\n/task-status 3.1 done  # Hero component\n/task-status 3.2 done  # Features section\n/task-status 3.3 done  # CTA component\n\n# Mark main task complete\n/task-status 3 done\n\nâœ… Implementation complete\n```\n\n### Phase 5: Final Task Completion\n\n**At project completion:**\n\n1. Mark all remaining tasks as complete\n2. Generate task summary\n3. Include in final report\n\n**Implementation:**\n\n```bash\n# List any incomplete tasks\n/task-list --status pending,in_progress\n\n# Mark project complete\n/task-status {final-task-id} done\n\n# Generate summary\n/task-list --summary\n```\n\n**Include in final report:**\n\n```markdown\n## CHECKPOINT 5 COMPLETE: Project finished\n\n**Project Summary:**\n- Location: {output-dir}\n- Stack: {tech-stack}\n- Preview: {url}\n\n**Task Summary:**\n- Total tasks: {count}\n- Completed: {completed}\n- Time tracked: {duration}\n- Phases: Research â†’ Architecture â†’ Implementation â†’ Legal â†’ Final\n\n**Deliverables:**\n[Standard webgen deliverables...]\n```\n\n---\n\n## TaskFlow Commands Reference\n\n### Commands Used in Integration\n\n| Command | When | Purpose |\n|---------|------|---------|\n| `/task-init` | Checkpoint 1 | Initialize task tracking |\n| `/task-parse <prd>` | Checkpoint 1 (optional) | Parse structured requirements |\n| `/task-status <id> <status>` | Each checkpoint | Update task status |\n| `/task-list` | Any phase | View current tasks |\n| `/task-next` | Implementation | Get recommended next task |\n| `/task-show <id>` | Any phase | View task details |\n| `/task-expand <id>` | Complex tasks | Break into subtasks |\n\n### Status Mapping\n\n| WebGen Phase | TaskFlow Status |\n|--------------|-----------------|\n| Not started | `pending` |\n| In progress | `in_progress` |\n| Complete | `done` |\n| Blocked (code review issues) | `blocked` |\n| Skipped (legal pages) | `deferred` |\n\n---\n\n## Phase-Specific Task Examples\n\n### Checkpoint 2: Research\n\n```json\n{\n  \"id\": 1,\n  \"title\": \"Conduct competitive research\",\n  \"description\": \"Research fintech competitors and extract patterns\",\n  \"status\": \"in_progress\",\n  \"priority\": \"high\",\n  \"subtasks\": [\n    {\n      \"id\": \"1.1\",\n      \"title\": \"Research Betterment\",\n      \"status\": \"done\"\n    },\n    {\n      \"id\": \"1.2\",\n      \"title\": \"Research Wealthfront\",\n      \"status\": \"in_progress\"\n    },\n    {\n      \"id\": \"1.3\",\n      \"title\": \"Extract design patterns\",\n      \"status\": \"pending\"\n    }\n  ],\n  \"acceptanceCriteria\": [\n    \"3+ competitors analyzed\",\n    \"Research saved to research/competitive-analysis.md\",\n    \"Design patterns documented\"\n  ]\n}\n```\n\n### Checkpoint 3: Architecture\n\n```json\n{\n  \"id\": 2,\n  \"title\": \"Scaffold project architecture\",\n  \"description\": \"Initialize React + Vite + Tailwind project\",\n  \"status\": \"pending\",\n  \"priority\": \"high\",\n  \"dependencies\": [1],\n  \"subtasks\": [\n    {\n      \"id\": \"2.1\",\n      \"title\": \"Create project structure\",\n      \"status\": \"pending\"\n    },\n    {\n      \"id\": \"2.2\",\n      \"title\": \"Run pnpm install\",\n      \"status\": \"pending\"\n    },\n    {\n      \"id\": \"2.3\",\n      \"title\": \"Verify dev server\",\n      \"status\": \"pending\"\n    }\n  ],\n  \"acceptanceCriteria\": [\n    \"Project structure created\",\n    \"Dependencies installed\",\n    \"Dev server running on port 5173\"\n  ]\n}\n```\n\n### Checkpoint 4: Implementation\n\n```json\n{\n  \"id\": 3,\n  \"title\": \"Implement landing page components\",\n  \"description\": \"Generate all landing page sections\",\n  \"status\": \"pending\",\n  \"priority\": \"high\",\n  \"dependencies\": [2],\n  \"subtasks\": [\n    {\n      \"id\": \"3.1\",\n      \"title\": \"Hero component\",\n      \"status\": \"pending\"\n    },\n    {\n      \"id\": \"3.2\",\n      \"title\": \"Features section\",\n      \"status\": \"pending\"\n    },\n    {\n      \"id\": \"3.3\",\n      \"title\": \"Trust indicators\",\n      \"status\": \"pending\"\n    },\n    {\n      \"id\": \"3.4\",\n      \"title\": \"Pricing section\",\n      \"status\": \"pending\"\n    },\n    {\n      \"id\": \"3.5\",\n      \"title\": \"CTA section\",\n      \"status\": \"pending\"\n    }\n  ],\n  \"acceptanceCriteria\": [\n    \"All components generated with docstrings\",\n    \"Code review passed\",\n    \"Accessibility compliant\",\n    \"Preview screenshot captured\"\n  ]\n}\n```\n\n---\n\n## Error Handling\n\n### TaskFlow Not Available\n\n```markdown\n# User requests TaskFlow integration\nUser: \"Use TaskFlow for this project\"\n\n# Detection fails\nAgent: \"I don't see TaskFlow installed on this system.\nWould you like to:\n1. Continue with standard WebGen workflow\n2. Install TaskFlow first (provide instructions)\n\nWhat would you like to do?\"\n```\n\n### TaskFlow Command Fails\n\n```bash\n# Graceful degradation\nif ! /task-init 2>/dev/null; then\n  echo \"TaskFlow command failed. Continuing with standard workflow...\"\n  TASKFLOW_ENABLED=false\nfi\n```\n\n**Never crash WebGen due to TaskFlow issues.**\n\n---\n\n## Session Context Tracking\n\n### Store Integration State\n\n**In webgen session metadata:**\n\n```json\n{\n  \"project\": \"investwise - webgen\",\n  \"taskflow\": {\n    \"available\": true,\n    \"enabled\": true,\n    \"initialized\": true,\n    \"task_count\": 12,\n    \"current_task\": 3,\n    \"current_phase\": \"implementation\"\n  }\n}\n```\n\n### Use for Context Awareness\n\n```markdown\n# When resuming session\nAgent: \"Resuming InvestWise project...\"\n\n# Check TaskFlow state\nif taskflow.enabled:\n  current_task = /task-show {current_task}\n\n  \"TaskFlow Status:\n   - Current task: #{current_task.id} - {current_task.title}\n   - Status: {current_task.status}\n   - Progress: {completed}/{total} tasks complete\n\n   Should I continue with task #{current_task.id}?\"\n```\n\n---\n\n## Benefits of Integration\n\n**For Users:**\n- âœ… Visual task progress during long generations\n- âœ… Clear dependency tracking\n- âœ… Resume capability if session interrupted\n- âœ… Structured completion checklist\n- âœ… Historical record of work done\n\n**For Agents:**\n- âœ… Clear next-action recommendations (`/task-next`)\n- âœ… Dependency awareness (don't start blocked tasks)\n- âœ… Progress context across checkpoints\n- âœ… Shared task list with other agents\n\n---\n\n## Usage Example\n\n### Full Session with TaskFlow\n\n```\nUser: /webgen fintech landing page for InvestWise\n\nAgent: [Detects TaskFlow]\nTaskFlow detected. Track this project with tasks? (y/n)\n\nUser: y\n\nAgent: âœ… TaskFlow enabled\nInitializing task tracking...\n\n/task-init\nCreated .tasks/ directory\nInitialized master tag\n\nCreating tasks from requirements...\n\nTasks created:\n1. [pending] Conduct competitive research (high priority)\n2. [pending] Scaffold project architecture (high priority, depends on #1)\n3. [pending] Implement landing page components (medium, depends on #2)\n4. [pending] Generate legal pages (low, depends on #3)\n5. [pending] Final documentation (low, depends on #4)\n\nStarting with task #1...\n\n/task-status 1 in_progress\n\n[Conducts research...]\n\n/task-status 1 done\n\nâœ… Research complete\nMoving to task #2...\n\n/task-status 2 in_progress\n\n[Scaffolds project...]\n\n/task-status 2 done\n\nâœ… Architecture complete\nMoving to task #3...\n\n/task-status 3 in_progress\n\nImplementing components...\n- /task-status 3.1 done  # Hero\n- /task-status 3.2 done  # Features\n- /task-status 3.3 done  # CTA\n\n/task-status 3 done\n\nâœ… Implementation complete\n\n[Continues through remaining tasks...]\n\n## FINAL REPORT\n\n**Task Summary:**\n- Total: 5 tasks, 12 subtasks\n- All tasks complete âœ…\n- No blockers encountered\n- Phases: Research â†’ Architecture â†’ Implementation â†’ Legal â†’ Final\n\nProject complete!\n```\n\n---\n\n## Future Enhancements (Optional)\n\n**Potential improvements for future versions:**\n\n1. **Effort Estimation:**\n   - Track actual time vs estimated time\n   - Improve estimates over time\n\n2. **Tag-Based Organization:**\n   - Use TaskFlow tags for multi-page projects\n   - Separate tag per major section\n\n3. **Template Integration:**\n   - Save task templates for common project types\n   - Auto-populate tasks based on project type\n\n4. **Cross-Session Resume:**\n   - Detect incomplete projects\n   - Offer to resume from last checkpoint\n\n5. **Parallel Component Generation:**\n   - Use tags to track parallel component work\n   - Enable distributed generation\n\n---\n\n## Success Criteria\n\n**Integration is successful when:**\n\nâœ… TaskFlow detected reliably (no false negatives)\nâœ… User can decline without breaking workflow\nâœ… WebGen works identically with/without TaskFlow\nâœ… Tasks accurately reflect webgen phases\nâœ… Task statuses stay synchronized with actual progress\nâœ… Final report includes meaningful task summary\nâœ… No errors when TaskFlow unavailable\nâœ… Commands fail gracefully with clear messaging\n\n---\n\n**Version:** 1.0.0\n**Created:** 2025-12-13\n**Status:** Active\n",
        "plugins/webgen/skills/worktree-workflow/skill.md": "---\nname: worktree-workflow\ndescription: Git worktree setup, management, and cleanup for isolated parallel development\n---\n\n# Worktree Workflow Skill\n\nEnables isolated development using git worktrees. Each project runs in its own directory with full git history but no interference with other work.\n\n---\n\n## When to Recommend Worktrees\n\n**Offer worktrees when:**\n- User has multiple projects/tasks in progress\n- Working in a shared/team repository\n- Project generation might conflict with ongoing work\n- User wants to preserve current branch state\n- Long-running generation that shouldn't block other work\n\n**Skip worktrees when:**\n- Fresh/empty output directory with no existing work\n- User explicitly wants to work in main directory\n- Simple single-file or component generation\n- User declines worktree option\n\n---\n\n## Worktree Setup Protocol\n\n### 1. Pre-Flight Check\n\nBefore creating worktree, verify:\n\n```bash\n# Check if we're in a git repo\ngit rev-parse --git-dir 2>/dev/null || echo \"NOT_GIT_REPO\"\n\n# Check current branch\ngit branch --show-current\n\n# Check for uncommitted changes\ngit status --porcelain\n```\n\n**If not a git repo:** Initialize one or use standard workflow (no worktree needed for new projects).\n\n**If uncommitted changes:** Warn user - worktrees work best with clean state.\n\n### 2. Create Worktree\n\n```bash\n# Standard pattern: worktrees live in sibling directory\nPROJECT_DIR=\"${OUTPUT_DIR}/${slug} - ${generator}\"\nWORKTREE_DIR=\"${OUTPUT_DIR}/worktrees/${slug}\"\nBRANCH_NAME=\"feat/${slug}\"\n\n# Ensure worktrees directory exists\nmkdir -p \"${OUTPUT_DIR}/worktrees\"\n\n# Create worktree with new branch\ngit worktree add -b \"${BRANCH_NAME}\" \"${WORKTREE_DIR}\" main\n\n# Navigate to worktree\ncd \"${WORKTREE_DIR}\"\n```\n\n### 3. Verify Worktree Creation\n\n```bash\n# List all worktrees (should show new one)\ngit worktree list\n\n# Verify we're on the correct branch\ngit branch --show-current  # Should be: feat/${slug}\n\n# Verify isolation\npwd  # Should be in worktrees directory\n```\n\n---\n\n## Working in Worktree\n\n### Directory Structure\n\n```\n${OUTPUT_DIR}/\nâ”œâ”€â”€ worktrees/\nâ”‚   â””â”€â”€ ${slug}/          # Isolated worktree\nâ”‚       â”œâ”€â”€ .git          # Worktree git link (NOT full .git)\nâ”‚       â””â”€â”€ [project files]\nâ”œâ”€â”€ main-project/         # Main checkout (if exists)\nâ””â”€â”€ .git/                 # Shared git directory\n```\n\n### Committing in Worktree\n\nSame as normal git workflow - worktrees share history:\n\n```bash\ncd \"${WORKTREE_DIR}\"\ngit add .\ngit commit -m \"feat(${slug}): description\"\ngit push -u origin \"feat/${slug}\"\n```\n\n---\n\n## Worktree Cleanup Protocol (MANDATORY)\n\n**CRITICAL:** Agents MUST clean up worktrees and merged branches. Orphaned worktrees waste disk space and create confusion.\n\n### After Successful Completion\n\n```bash\n# 1. Ensure all changes committed and pushed\ngit status --porcelain  # Must be empty\n\n# 2. Switch to main in the MAIN worktree (not this worktree)\ncd \"${OUTPUT_DIR}\"  # Back to main project area\ngit checkout main\ngit pull origin main\n\n# 3. Merge the feature branch\ngit merge \"feat/${slug}\" --no-ff -m \"Merge feat/${slug}: ${description}\"\n\n# 4. Push merged main\ngit push origin main\n\n# 5. Delete the remote branch\ngit push origin --delete \"feat/${slug}\"\n\n# 6. Remove the worktree\ngit worktree remove \"${WORKTREE_DIR}\"\n\n# 7. Delete the local branch\ngit branch -d \"feat/${slug}\"\n\n# 8. Prune stale worktree references\ngit worktree prune\n```\n\n### Cleanup Verification\n\n```bash\n# Verify worktree removed\ngit worktree list  # Should NOT include the removed worktree\n\n# Verify branch deleted\ngit branch -a | grep \"feat/${slug}\"  # Should return nothing\n\n# Verify merge happened\ngit log --oneline -3  # Should show merge commit\n```\n\n### Failed/Abandoned Worktree Cleanup\n\nIf user abandons or generation fails:\n\n```bash\n# Force remove worktree (if changes not worth keeping)\ngit worktree remove --force \"${WORKTREE_DIR}\"\n\n# Delete the branch\ngit branch -D \"feat/${slug}\"  # -D for force delete\n\n# Prune references\ngit worktree prune\n```\n\n---\n\n## Orchestrator Integration\n\n### Checkpoint 1: Requirements (Add to existing)\n\nAfter requirements confirmed, add this prompt:\n\n```markdown\n**Worktree Option:**\n\nI can generate this project in an isolated git worktree, which:\n- Keeps your current work untouched\n- Creates a separate directory for this project\n- Allows parallel development\n- Merges back to main when complete\n\nWould you like to use a git worktree? (Recommended if you have work in progress)\n- **Yes** - Create isolated worktree\n- **No** - Use standard feature branch in output directory\n```\n\n### Store Worktree Context\n\nIf user chooses worktree, store in session:\n\n```json\n{\n  \"use_worktree\": true,\n  \"worktree_path\": \"${OUTPUT_DIR}/worktrees/${slug}\",\n  \"branch_name\": \"feat/${slug}\",\n  \"main_path\": \"${OUTPUT_DIR}\"\n}\n```\n\n### Final Phase: Add Cleanup Step\n\nBefore marking project complete:\n\n```markdown\n## WORKTREE CLEANUP\n\n**Worktree:** ${worktree_path}\n**Branch:** ${branch_name}\n\nCleanup steps:\n1. Verify all changes committed\n2. Merge to main\n3. Push main\n4. Delete remote branch\n5. Remove worktree\n6. Delete local branch\n7. Prune references\n\nExecuting cleanup...\n```\n\n---\n\n## Error Handling\n\n### Worktree Already Exists\n\n```bash\n# Check if worktree exists\ngit worktree list | grep \"${slug}\" && echo \"EXISTS\"\n\n# If exists, offer options:\n# 1. Use existing worktree (continue previous work)\n# 2. Remove and recreate (fresh start)\n# 3. Use different name\n```\n\n### Branch Already Exists\n\n```bash\n# Check if branch exists\ngit branch -a | grep \"feat/${slug}\" && echo \"BRANCH_EXISTS\"\n\n# If exists locally only: can checkout\n# If exists on remote: need to fetch and merge or use different name\n```\n\n### Merge Conflicts\n\n```markdown\n## MERGE CONFLICT DETECTED\n\nThe worktree branch has conflicts with main.\n\n**Conflicting files:**\n- [list files]\n\n**Options:**\n1. Resolve conflicts (I'll help)\n2. Force merge (may lose main changes)\n3. Keep worktree, skip merge (manual resolution later)\n4. Abandon worktree changes\n\nYour choice?\n```\n\n---\n\n## Quick Reference\n\n| Action | Command |\n|--------|---------|\n| List worktrees | `git worktree list` |\n| Create worktree | `git worktree add -b BRANCH PATH BASE` |\n| Remove worktree | `git worktree remove PATH` |\n| Force remove | `git worktree remove --force PATH` |\n| Prune stale | `git worktree prune` |\n| Check branch | `git branch --show-current` |\n\n---\n\n## Hygiene Checklist (For Agents)\n\nBefore ending ANY session with worktrees:\n\n- [ ] All worktree changes committed?\n- [ ] Worktree branch pushed to remote?\n- [ ] If complete: Merged to main?\n- [ ] If complete: Remote branch deleted?\n- [ ] If complete: Worktree removed?\n- [ ] If complete: Local branch deleted?\n- [ ] `git worktree prune` run?\n- [ ] `git worktree list` shows expected state?\n\n**Rule:** Never leave orphaned worktrees. Either merge+cleanup OR explicitly document for user to handle later.\n",
        "plugins/worklog/.claude-plugin/plugin.json": "{\n  \"name\": \"worklog\",\n  \"version\": \"1.7.1\",\n  \"description\": \"Cross-session knowledge persistence with SQLite (default) or PostgreSQL. Store learnings, recall context, and maintain continuity across Claude Code sessions. Part of the unified GSC plugins ecosystem with plugin discovery and knowledge import.\",\n  \"author\": {\n    \"name\": \"gs\"\n  },\n  \"license\": \"MIT\",\n  \"repository\": \"https://github.com/gaurangrshah/gsc-plugins\",\n  \"homepage\": \"https://github.com/gaurangrshah/gsc-plugins/tree/main/plugins/worklog\",\n  \"keywords\": [\n    \"memory\",\n    \"persistence\",\n    \"sqlite\",\n    \"postgresql\",\n    \"knowledge-base\",\n    \"cross-session\",\n    \"context\",\n    \"learning\",\n    \"hooks\",\n    \"automation\",\n    \"mcp\",\n    \"mcp-server\",\n    \"security\",\n    \"ecosystem\",\n    \"plugin-discovery\"\n  ]\n}\n",
        "plugins/worklog/README.md": "# Worklog - Cross-Session Knowledge Persistence\n\nA Claude Code plugin for maintaining knowledge, context, and learnings across sessions.\n\n**Version:** 1.7.1\n\n## Overview\n\nWorklog provides persistent memory for Claude Code sessions. Store learnings, recall context, track work history, and maintain continuity across sessions and systems.\n\n### Database Backends\n\n| Backend | Best For | Dependencies |\n|---------|----------|--------------|\n| **SQLite** (default) | Single user, local development | None (built-in) |\n| **PostgreSQL** (optional) | Multi-system teams, shared context | PostgreSQL server |\n\nChoose your backend during `/worklog-init`. SQLite is recommended for most users.\n\n## Standalone & Integration\n\n### Works 100% Standalone\n\nWorklog is fully self-contained. **No other plugins required.**\n\n```bash\n# This works perfectly with ONLY worklog installed:\n/worklog-init\n# Use memory-store skill to save learnings\n# Use memory-recall skill to query context\n```\n\nAll skills work. All hooks work. All commands work. No errors or warnings about missing plugins.\n\n### How Worklog Interacts with Other Plugins\n\nWorklog provides **background context** for all sessions via hooksâ€”it doesn't need to know about other plugins specifically.\n\n#### Hooks Fire for All Sessions\n\nWhen you use WebGen, AppGen, TaskFlow, or any Claude Code session:\n\n| Hook | When | What Happens |\n|------|------|--------------|\n| SessionStart | Conversation begins | Loads recent context from worklog DB |\n| SessionStop | Conversation ends | Captures learnings, logs work |\n\n**The hooks don't care which plugin is active**â€”they provide general-purpose context and learning capture.\n\n#### Example: WebGen + Worklog\n\n```\nUser: /webgen fintech landing page\n\n[SessionStart hook fires]\nâ†’ Loads recent work context from worklog DB\nâ†’ Agent sees: \"Recent work: Implemented auth system yesterday\"\n\n[WebGen runs its workflow]\nâ†’ Generates landing page across 5 checkpoints\n\n[SessionStop hook fires]\nâ†’ Prompts: \"Session had significant activity. Store learnings?\"\nâ†’ If aggressive mode: Auto-extracts design patterns to knowledge_base\n```\n\n#### Docs Plugin Integration (Bidirectional)\n\nWhen both worklog and docs plugins are installed, they form a **bidirectional knowledge flow**:\n\n```\ndocs-manager                    memory-sync\n     â†“                              â†‘\nStores learnings TO worklog    Promotes FROM worklog to docs\n     â†“                              â†‘\n     â””â”€â”€â”€â”€â”€â”€â”€â”€ worklog.db â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n| Direction | What Happens |\n|-----------|--------------|\n| **Docs â†’ Worklog** | docs-manager stores learnings, decisions, and work entries to worklog.db |\n| **Worklog â†’ Docs** | memory-sync promotes valuable entries back to docs with proper frontmatter |\n\n**Configuration for docs integration:**\n\n```bash\n# Set in both plugins for full integration\nexport WORKLOG_DB=\"/path/to/worklog.db\"\nexport DOCS_ROOT=\"~/docs\"\nexport KNOWLEDGE_BASE=\"~/.claude/knowledge\"\n```\n\nWhen `$DOCS_ROOT` is set, memory-sync:\n- Detects docs plugin and enables enhanced mode\n- Creates files with proper YAML frontmatter\n- Validates promoted files against docs standards\n- Uses consistent type mapping (decisions â†’ `type: decision`, etc.)\n\n#### Other Plugin Integrations\n\n| Integration | Status | Behavior |\n|-------------|--------|----------|\n| WebGen â†’ Worklog | Passive (hooks only) | SessionStart/Stop hooks fire during generation |\n| AppGen â†’ Worklog | Passive (hooks only) | SessionStart/Stop hooks fire during generation |\n| TaskFlow â†’ Worklog | Passive (hooks only) | SessionStart/Stop hooks fire during task work |\n| **Docs â†’ Worklog** | **Active** | docs-manager stores to worklog.db |\n| **Worklog â†’ Docs** | **Active** | memory-sync promotes with frontmatter |\n\n**The hooks provide value regardless**â€”any session benefits from context loading and learning capture.\n\n## Quick Start (5 minutes)\n\n### 1. Install Plugin\n\n**Option A: Marketplace (Recommended)**\n```bash\n# Add the marketplace (if not already added)\nclaude plugin marketplace add https://github.com/gaurangrshah/gsc-plugins.git\n\n# Install the plugin\nclaude plugin install worklog@gsc-plugins\n```\n\n**Option B: Manual Installation**\n```bash\n# Clone the repo\ngit clone https://github.com/gaurangrshah/gsc-plugins.git\n\n# Copy to local-plugins\ncp -r gsc-plugins/plugins/worklog ~/.claude/plugins/local-plugins/\n\n# Restart Claude Code to activate\n```\n\n### 2. Initialize\n\nRun in any Claude Code session:\n```\n/worklog-init\n```\n\nYou'll be prompted to choose:\n- **Backend:** SQLite (default) or PostgreSQL\n- **Profile:** Standard (recommended) - balanced integration\n- **Location:** Local (default) - `~/.claude/worklog/worklog.db`\n\nThe command will:\n1. Create a backup of your CLAUDE.md\n2. Initialize the database (SQLite) or connect (PostgreSQL)\n3. Load seed data (tag taxonomy, topics, quick start guide)\n4. Add worklog section to CLAUDE.md\n5. Show verification results\n6. Ask for confirmation (rollback if declined)\n\n### 3. Start Using\n\nAfter init, you have access to:\n- `memory-store` skill - Save learnings after tasks\n- `memory-recall` skill - Query context at task start\n- `/worklog-status` - Check connectivity\n\n### Multi-System Setup (Optional)\n\n#### Option A: Shared SQLite (Network Mount)\n\n**Primary system:**\n```\n/worklog-init\n# Choose: SQLite\n# Choose: shared location\n# Provide network path (e.g., /mnt/nas/worklog.db)\n```\n\n**Secondary systems:**\n```\n/worklog-connect /path/to/shared/worklog.db\n```\n\n| Platform | Example Shared DB Path |\n|----------|------------------------|\n| macOS | `/Volumes/share-name/path/to/worklog.db` |\n| Linux | `/mnt/share-name/path/to/worklog.db` |\n| Windows | `\\\\server\\share\\path\\to\\worklog.db` |\n\n> **Note:** Network mount paths vary by system. Ensure each system can access the shared location before configuring.\n\n#### Option B: PostgreSQL (Recommended for Teams)\n\n**All systems:**\n```\n/worklog-init\n# Choose: PostgreSQL\n# Configure DATABASE_URL or PG* environment variables\n```\n\nOr quick connect:\n```bash\nexport DATABASE_URL=\"postgresql://user:pass@host:5432/worklog\"\n/worklog-connect\n```\n\nPostgreSQL advantages:\n- No network mount required\n- Better concurrent access\n- Centralized backup\n- Cross-agent collaboration\n\n## Profiles\n\n| Profile | Tables | Default Hook Mode | Best For |\n|---------|--------|-------------------|----------|\n| **Minimal** | 6 core | remind | Occasional use |\n| **Standard** (default) | 6 core | light | Daily use |\n| **Full** | 10 (core + extended) | full | Multi-system teams |\n\n## Hook Modes (Automation Levels)\n\nHooks automatically load context at session start and capture learnings at session end.\n\n| Mode | Session Start | Session End | Best For |\n|------|---------------|-------------|----------|\n| **off** | Nothing | Nothing | Full manual control |\n| **remind** | Reminder only | Suggest storing | Minimal overhead |\n| **light** | Summary index (~150-300 tokens) | Prompt to log | Balanced automation |\n| **full** | Detailed index (~300-500 tokens) | Auto-log compressed summary | Comprehensive tracking |\n| **aggressive** | Index + critical auto-fetch | Auto-extract all learnings | Power users, shared DBs |\n\n**Hook mode is independent of profile** - you can mix any profile with any hook mode.\n\n### Hook Benefits\n\n- **No more forgetting to log**: Hooks capture work automatically\n- **Context always available**: Start each session with relevant history\n- **Learning compounds**: Knowledge extracted and stored without manual effort\n- **Background operation**: Hooks run without blocking your work\n- **Token efficient**: Progressive disclosure reduces context bloat by 60-70%\n\n### Progressive Disclosure (SessionStart)\n\nInstead of dumping all context at once, hooks now inject a **summary index** first:\n\n| Layer | What | When | Token Cost |\n|-------|------|------|------------|\n| **1. Index** | Summary of available context | Always (SessionStart) | ~100-300 tokens |\n| **2. Details** | Full content for selected items | On-demand (memory-recall) | ~500-2000 tokens |\n| **3. Source** | Original entries/queries | Explicit request | Variable |\n\n**Example output (light mode):**\n```\n<worklog-context mode=\"light\" disclosure=\"index\">\n## Available Context\n\n| Category | Count | Est. Tokens | Top Items |\n|----------|-------|-------------|-----------|\n| Recent Work (24h) | 3 | ~450 | Auth system, API refactor |\n| Active Memories | 5 | ~1000 | ctx_ubuntu_session, ... |\n\n**To fetch full details:** Use `memory-recall` skill with category filter.\n</worklog-context>\n```\n\n### AI Compression (SessionStop)\n\nSessions are compressed into semantic learnings, not raw transcripts:\n\n| Raw Data | Compressed Output | Storage |\n|----------|-------------------|---------|\n| Full conversation (10,000+ tokens) | 1-2 sentence summary (~100 tokens) | entries.outcome |\n| Debugging steps | Root cause + resolution | error_patterns |\n| Decisions discussed | Decision + rationale | knowledge_base |\n| Patterns observed | Pattern + when to apply | knowledge_base |\n\n**Aggressive mode extracts:**\n- Decisions (choice, rationale, alternatives)\n- Patterns (description, when to use, examples)\n- Errors (signature, root cause, resolution, prevention)\n- Gotchas (wrong approach, right approach, context)\n\n### PostToolUse Hook (Optional)\n\nAutomatically capture significant file changes during sessions. **OFF by default.**\n\nEnable in `~/.gsc-plugins/worklog.local.md`:\n```yaml\n---\ncapture_observations: true          # Enable PostToolUse hook\ncapture_filter: significant         # all | significant | decisions-only\ncapture_files: [\"*.md\", \"*.ts\", \"*.py\", \"*.json\"]\ncapture_exclude: [\"node_modules/*\", \"*.lock\"]\n---\n```\n\n| Capture Mode | What Gets Captured | Recommended For |\n|--------------|-------------------|-----------------|\n| `off` (default) | Nothing | Most users |\n| `significant` | Config files, schemas, docs, major code changes | Power users |\n| `decisions-only` | Only explicit decision markers in changes | Minimal overhead |\n| `all` | Every Write/Edit to matching files | Debug/audit only |\n\nObservations are stored to `memories` table with `status='staging'` for review at session end.\n\n### Minimal\n- Core tables only (6 tables)\n- ~20 lines added to CLAUDE.md\n- Default hook mode: `remind`\n\n### Standard (Recommended)\n- Core tables (6 tables)\n- ~50 lines added to CLAUDE.md\n- Default hook mode: `light`\n\n### Full\n- All 10 tables (core + extended: projects, components, reference_library)\n- Network failure handling with retry + handoffs\n- ~100 lines added to CLAUDE.md\n- Default hook mode: `full`\n- Optional: Add domain-agency.sql for clients/competitors tables\n\n## Commands\n\n| Command | Purpose |\n|---------|---------|\n| `/worklog-init` | Initialize database (primary system) |\n| `/worklog-connect <path>` | Connect to shared database (secondary) |\n| `/worklog-configure` | Change profile or settings |\n| `/worklog-setup-mcp` | Set up Python environment for MCP server |\n| `/worklog-status` | Check connectivity and stats |\n\n## Skills\n\n| Skill | Purpose |\n|-------|---------|\n| `memory-store` | Store knowledge, entries, errors |\n| `memory-recall` | Query context and history |\n| `memory-sync` | Reconcile with local docs |\n\n## MCP Server (Programmatic Access)\n\n**New in v1.4.0:** The worklog plugin includes an MCP server for direct tool access.\n\n**v1.6.0:** MCP server now supports both SQLite and PostgreSQL backends automatically.\n\n### MCP Server Setup\n\nThe MCP server requires Python 3.10+ and includes cross-platform setup scripts.\n\n**Option A: Use the Setup Command (Recommended)**\n\nRun in Claude Code:\n```\n/worklog-setup-mcp\n```\n\nThis command:\n1. Detects Python using intelligent priority (pyenv â†’ mise â†’ Homebrew â†’ system)\n2. Creates an isolated virtual environment\n3. Installs MCP dependencies\n4. Configures `.mcp.json` automatically\n\n**Option B: Run Setup Script Directly**\n\n```bash\n# Navigate to plugin directory\ncd /path/to/gsc-plugins/plugins/worklog\n\n# Run the setup script\n./scripts/setup-mcp-venv.sh\n\n# For custom venv location:\n./scripts/setup-mcp-venv.sh --venv-path ~/.local/share/worklog-mcp-venv\n```\n\n**Option C: Manual Installation**\n\n```bash\n# Navigate to the MCP server directory\ncd ~/.claude/plugins/marketplaces/gsc-plugins/worklog/mcp\n\n# Create venv with your preferred Python 3.10+\npython3 -m venv .venv\nsource .venv/bin/activate\n\n# Install the package (SQLite support included by default)\npip install -e .\n\n# For PostgreSQL support, install with optional dependency:\npip install -e \".[postgresql]\"\n\n# Verify installation\npython -m worklog_mcp --help\n```\n\n### Python Detection Priority\n\nThe setup scripts check for Python in this order:\n\n| Priority | Source | Why |\n|----------|--------|-----|\n| 1 | pyenv | Respects explicit user choice |\n| 2 | Homebrew (macOS) | Platform standard, very common |\n| 3 | mise | Polyglot version manager |\n| 4 | System Python | Last resort if â‰¥3.10 |\n\nIf no suitable Python is found, you'll get platform-specific recommendations:\n- **macOS:** `brew install python@3.12`\n- **Linux (apt):** `sudo apt-get install python3.12 python3.12-venv`\n- **Linux (other):** `mise use python@3.12`\n\n### Verify MCP Server\n\nAfter setup, restart Claude Code and verify:\n```bash\nclaude mcp list\n# Should show: worklog (11 tools)\n```\n\nOnce installed, Claude Code automatically detects the MCP server via the plugin's `.mcp.json` configuration.\n\n### When to Use Each Approach\n\n| Approach | Best For |\n|----------|----------|\n| **Skills** | Human-guided workflows with context and validation |\n| **Commands** | Configuration and status checks |\n| **MCP Tools** | Programmatic access, automation, agent-to-agent |\n\n### Available MCP Tools\n\nWhen the MCP server is installed and the plugin is enabled, these tools are available as `mcp__worklog__<tool>`:\n\n| Tool | Description |\n|------|-------------|\n| `query_table` | Query any table with filtering, pagination |\n| `search_knowledge` | Full-text search across tables |\n| `recall_context` | Smart context retrieval for agent sessions |\n| `get_knowledge_entry` | Get KB entry by ID |\n| `get_memory` | Get memory by key |\n| `store_memory` | Store new memories |\n| `update_memory` | Update existing memories |\n| `log_entry` | Log work entries |\n| `store_knowledge` | Add to knowledge base |\n| `list_tables` | List tables with counts |\n| `get_recent_entries` | Recent work by agent |\n\n### MCP Usage Examples\n\n```python\n# Load context at task start\nmcp__worklog__recall_context(topic=\"deployment\", min_importance=5)\n\n# Store a learning\nmcp__worklog__store_memory(\n    key=\"fact_agent_20251217_learning\",\n    content=\"Important discovery...\",\n    memory_type=\"fact\",\n    importance=7\n)\n\n# Search across all knowledge\nmcp__worklog__search_knowledge(query=\"SSH\", limit=10)\n\n# Log completed work\nmcp__worklog__log_entry(\n    title=\"Deployed API\",\n    task_type=\"deployment\",\n    outcome=\"Success\"\n)\n```\n\n### MCP Server Development\n\nThe MCP server source is in `mcp/`:\n\n```bash\ncd plugins/worklog/mcp\npip install -e \".[dev]\"     # Install\npython -m worklog_mcp       # Run directly\npytest -v                   # Run tests\n```\n\n## Database Schema\n\n### Core Tables (5)\n\n| Table | Purpose |\n|-------|---------|\n| `entries` | Work history and activity logs |\n| `knowledge_base` | Reusable learnings and protocols |\n| `memories` | Working context and session state |\n| `error_patterns` | Error signatures and resolutions |\n| `research` | External research items |\n\n### Extended Tables (4) - Full Profile Only\n\n| Table | Purpose |\n|-------|---------|\n| `projects` | Project registry |\n| `component_registry` | Agents, skills, commands |\n| `component_deployments` | Per-system deployments |\n| `reference_library` | Research assets |\n\n### Domain Extension: Agency (2) - Optional Add-on\n\n| Table | Purpose |\n|-------|---------|\n| `clients` | Client entities (PII-safe) |\n| `competitors` | Competitor profiles |\n\nInstall with: `sqlite3 $WORKLOG_DB_PATH < schema/domain-agency.sql`\n\n## Configuration\n\nSettings stored in `~/.gsc-plugins/worklog.local.md`:\n\n**SQLite Configuration:**\n```yaml\n---\nprofile: standard\nbackend: sqlite\ndb_path: ~/.claude/worklog/worklog.db\nhook_mode: light\nsystem_name: my-system\n---\n```\n\n**PostgreSQL Configuration:**\n```yaml\n---\nprofile: standard\nbackend: postgresql\n# Connection via DATABASE_URL or PG* environment variables\nhook_mode: light\nsystem_name: my-system\n---\n```\n\n### Environment Variables\n\n| Variable | Default | Description |\n|----------|---------|-------------|\n| `WORKLOG_BACKEND` | `sqlite` | `sqlite` or `postgresql` |\n| `WORKLOG_DB_PATH` | `~/.claude/worklog/worklog.db` | SQLite database location |\n| `DATABASE_URL` | - | PostgreSQL connection string |\n| `PGHOST`, `PGPORT`, etc. | - | Individual PostgreSQL settings |\n| `WORKLOG_PROFILE` | `standard` | Integration level |\n| `WORKLOG_MODE` | `local` | `local` or `shared` |\n| `WORKLOG_ALLOW_FALLBACK` | `false` | Allow SQLite fallback if PostgreSQL fails |\n\n### Backend Auto-Detection\n\nThe plugin automatically detects the backend:\n1. If `DATABASE_URL` is set â†’ PostgreSQL\n2. If `WORKLOG_BACKEND=postgresql` â†’ PostgreSQL\n3. If `PGHOST` is set â†’ PostgreSQL\n4. Otherwise â†’ SQLite (default)\n\n## Network Usage\n\nFor shared databases over network mounts:\n\n### Journal Mode\n\nSQLite requires DELETE journal mode (not WAL) for network shares:\n\n```sql\nPRAGMA journal_mode=DELETE;\n```\n\nThis is set automatically during init.\n\n### Retry Logic\n\nNetwork writes may fail with \"database is locked\". Use retry:\n\n```bash\nfor i in 1 2 3; do\n  sqlite3 $DB_PATH \"YOUR SQL\" && break\n  sleep $((5 + RANDOM % 6))\ndone\n```\n\n### Mount Commands\n\n**macOS:**\n```bash\nmount -t smbfs //server/share /Volumes/mount\n```\n\n**Linux:**\n```bash\nsudo mount -t cifs //server/share /mnt/mount -o username=user,uid=1000\n```\n\n## Usage Examples\n\n### SQLite Examples\n\n```bash\nDB=\"${WORKLOG_DB_PATH:-$HOME/.claude/worklog/worklog.db}\"\n\n# Store a Learning\nsqlite3 \"$DB\" \"INSERT INTO knowledge_base\n(category, title, content, tags, source_agent) VALUES\n('development', 'React memo pattern',\n'Use React.memo for expensive pure components...',\n'react,performance,patterns', 'claude');\"\n\n# Query Knowledge\nsqlite3 \"$DB\" \"SELECT title, content FROM knowledge_base WHERE tags LIKE '%react%';\"\n\n# Log Work\nsqlite3 \"$DB\" \"INSERT INTO entries\n(agent, task_type, title, outcome, tags) VALUES\n('claude', 'development', 'Implemented auth flow',\n'JWT auth with refresh tokens', 'auth,security');\"\n\n# Check Error Patterns\nsqlite3 \"$DB\" \"SELECT resolution FROM error_patterns WHERE error_message LIKE '%ECONNREFUSED%';\"\n```\n\n### PostgreSQL Examples\n\n```bash\n# Store a Learning\npsql -c \"INSERT INTO knowledge_base\n(category, title, content, tags, source_agent) VALUES\n('development', 'React memo pattern',\n'Use React.memo for expensive pure components...',\n'react,performance,patterns', 'claude');\"\n\n# Query Knowledge (ILIKE for case-insensitive)\npsql -t -c \"SELECT title, content FROM knowledge_base WHERE tags ILIKE '%react%';\"\n\n# Log Work\npsql -c \"INSERT INTO entries\n(agent, task_type, title, outcome, tags) VALUES\n('claude', 'development', 'Implemented auth flow',\n'JWT auth with refresh tokens', 'auth,security');\"\n\n# Check Error Patterns\npsql -t -c \"SELECT resolution FROM error_patterns WHERE error_message ILIKE '%ECONNREFUSED%';\"\n```\n\n### SQL Syntax Differences\n\n| Feature | SQLite | PostgreSQL |\n|---------|--------|------------|\n| Case-insensitive | `LIKE` (default) | `ILIKE` |\n| Days ago | `datetime('now', '-7 days')` | `NOW() - INTERVAL '7 days'` |\n| Boolean | `1` / `0` | `true` / `false` |\n| Auto ID return | `last_insert_rowid()` | `RETURNING id` |\n\n## Worklog Viewer (Web UI)\n\nThe plugin includes a browser-based SQLite viewer for exploring your worklog data.\n\n### Location (varies by installation method)\n\n| Installation Method | Viewer Location |\n|---------------------|-----------------|\n| **Marketplace** | `~/.claude/plugins/marketplaces/gsc-plugins/worklog/worklog-viewer/index.html` |\n| **Local Plugin** | `~/.claude/plugins/local-plugins/worklog/worklog-viewer/index.html` |\n| **From Source** | `<repo>/plugins/worklog/worklog-viewer/index.html` |\n\n**Tip:** On macOS, the `~/.claude` folder is hidden. Use Finder â†’ Go â†’ Go to Folder (â‡§âŒ˜G) and enter the path above.\n\n### Features\n\n- Natural language search (multi-term filtering)\n- Tag filtering (click tags to filter)\n- Dark/Light theme with persistence\n- Database caching via IndexedDB\n- Custom SQL queries (Ctrl+Enter)\n- CSV export\n- Auto table discovery\n\n### Usage\n\n1. Navigate to the viewer location based on your installation method (see table above)\n2. Open `index.html` in a browser (drag-and-drop or right-click â†’ Open With)\n3. Click \"Load Database\" and select your `worklog.db` file\n4. Use search, tag filters, and sort controls to explore\n5. Double-click any row for full details\n\n### Keyboard Shortcuts\n\n| Key | Action |\n|-----|--------|\n| `Ctrl+Enter` | Run SQL query |\n| `Escape` | Close modal |\n\n## Plugin Structure\n\n```\nworklog/\nâ”œâ”€â”€ .claude-plugin/\nâ”‚   â””â”€â”€ plugin.json\nâ”œâ”€â”€ commands/\nâ”‚   â”œâ”€â”€ worklog-init.md\nâ”‚   â”œâ”€â”€ worklog-connect.md\nâ”‚   â”œâ”€â”€ worklog-configure.md\nâ”‚   â”œâ”€â”€ worklog-setup-mcp.md  # Cross-platform MCP setup (v1.5.0+)\nâ”‚   â””â”€â”€ worklog-status.md\nâ”œâ”€â”€ hooks/\nâ”‚   â”œâ”€â”€ session-start.md      # Auto-load context (progressive disclosure)\nâ”‚   â”œâ”€â”€ session-stop.md       # Auto-capture learnings (AI compression)\nâ”‚   â””â”€â”€ post-tool-use.md      # Optional: capture significant file changes\nâ”œâ”€â”€ skills/\nâ”‚   â”œâ”€â”€ memory-store/skill.md\nâ”‚   â”œâ”€â”€ memory-recall/skill.md\nâ”‚   â””â”€â”€ memory-sync/skill.md\nâ”œâ”€â”€ scripts/                  # Setup utilities (v1.5.0+)\nâ”‚   â”œâ”€â”€ detect-python-env.sh  # Cross-platform Python detection\nâ”‚   â””â”€â”€ setup-mcp-venv.sh     # Automated venv creation\nâ”œâ”€â”€ schema/\nâ”‚   â”œâ”€â”€ core.sql\nâ”‚   â””â”€â”€ extended.sql\nâ”œâ”€â”€ seed/                    # Bootstrap data (v1.7.1+)\nâ”‚   â”œâ”€â”€ tag_taxonomy.sql     # Tag normalization rules\nâ”‚   â”œâ”€â”€ topics.sql           # Core topic index\nâ”‚   â”œâ”€â”€ knowledge.sql        # Quick start documentation\nâ”‚   â””â”€â”€ run-seeds.sh         # Loader script (SQLite/PostgreSQL)\nâ”œâ”€â”€ templates/\nâ”‚   â”œâ”€â”€ minimal.md\nâ”‚   â”œâ”€â”€ standard.md\nâ”‚   â””â”€â”€ full.md\nâ”œâ”€â”€ docs/\nâ”‚   â””â”€â”€ network-protocol.md\nâ”œâ”€â”€ worklog-viewer/\nâ”‚   â”œâ”€â”€ index.html\nâ”‚   â””â”€â”€ README.md\nâ”œâ”€â”€ mcp/                      # MCP server (v1.4.0+)\nâ”‚   â”œâ”€â”€ src/worklog_mcp/\nâ”‚   â”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”‚   â”œâ”€â”€ __main__.py\nâ”‚   â”‚   â”œâ”€â”€ config.py\nâ”‚   â”‚   â””â”€â”€ server.py\nâ”‚   â”œâ”€â”€ tests/\nâ”‚   â”œâ”€â”€ pyproject.toml\nâ”‚   â””â”€â”€ README.md\nâ”œâ”€â”€ .mcp.json                 # MCP server config\nâ””â”€â”€ README.md\n```\n\n## Security Considerations\n\nThe MCP server implements several security measures to protect against common vulnerabilities.\n\n### SQL Injection Protection\n\nAll user inputs are validated and parameterized:\n\n| Input | Protection |\n|-------|------------|\n| `table` | Validated against allowed table list |\n| `columns` | Validated against per-table column whitelist |\n| `order_by` | Validated column + direction (ASC/DESC only) |\n| `filter_value` | Parameterized queries (never interpolated) |\n| `filter_op` | Restricted to: `=`, `!=`, `>`, `<`, `>=`, `<=`, `LIKE`, `ILIKE` |\n\n**Example - Safe filtering:**\n```python\n# Instead of raw SQL: WHERE status='promoted'\n# Use structured parameters:\nquery_table(table=\"memories\", filter_column=\"status\", filter_op=\"=\", filter_value=\"promoted\")\n```\n\n### Connection Security\n\n| Feature | Implementation |\n|---------|----------------|\n| Connection timeout | 30 seconds (prevents hanging) |\n| Query timeout | 60 seconds (prevents long-running queries) |\n| Pool cleanup | Lifespan context manager ensures proper shutdown |\n| Race condition prevention | asyncio.Lock with double-checked locking |\n\n### PostgreSQL Configuration\n\n| Environment Variable | Security Note |\n|---------------------|---------------|\n| `DATABASE_URL` | Contains password - never log this value |\n| `PGPASSWORD` | Required for PostgreSQL - use secrets management |\n| `PGPORT` | Validated range: 1-65535 |\n| `WORKLOG_ALLOW_FALLBACK` | Must be explicitly set to allow SQLite fallback |\n\n**Important:** Silent fallback to SQLite is disabled by default. If PostgreSQL is configured but fails to connect, the server will error rather than silently use SQLite. Set `WORKLOG_ALLOW_FALLBACK=1` to allow fallback behavior.\n\n### Best Practices\n\n1. **Credentials**: Use environment variables or secrets management, never hardcode\n2. **Network**: Use TLS for PostgreSQL connections in production\n3. **Access**: Apply principle of least privilege to database users\n4. **Logging**: The `_get_dsn()` function is internal - never log its output\n\n## Troubleshooting\n\n### \"unable to open database file\"\n\n1. Check path exists: `ls -la $DB_PATH`\n2. If network, verify mount: `mount | grep mount_point`\n3. Check directory permissions\n\n### \"database is locked\"\n\nNormal for network databases. Retry handles this automatically.\n\n### \"readonly database\"\n\nDirectory needs write permission (for journal file):\n```bash\nchmod 775 /path/to/db/directory\n```\n\n## Plugin Discovery\n\nDuring `/worklog-init`, worklog automatically detects other GSC plugins and offers integration:\n\n### Detected Plugins\n\n| Plugin | Integration |\n|--------|-------------|\n| **appgen** | SessionStart/Stop hooks provide context during app generation |\n| **webgen** | SessionStart/Stop hooks provide context during web generation |\n| **taskflow** | SessionStart/Stop hooks track task work sessions |\n| **docs** | Bidirectional: docs stores TO worklog, memory-sync promotes FROM worklog |\n\n### Knowledge Import\n\nIf existing knowledge files are found from other plugins, worklog offers to import them:\n\n```\nFound 23 knowledge files from other plugins:\n  - appgen/webgen: 15 files at ~/.gsc-plugins/knowledge\n  - docs: 8 files at ~/.gsc-plugins/knowledge\n\nImport existing knowledge into worklog? (y/n)\n```\n\nImport is **non-destructive** - original files are preserved.\n\n### Ecosystem Integration\n\nAll GSC plugins use `~/.gsc-plugins/` for configuration:\n\n| Plugin | Config Location |\n|--------|-----------------|\n| worklog | `~/.gsc-plugins/worklog.local.md` |\n| appgen | `~/.gsc-plugins/appgen.local.md` |\n| webgen | `~/.gsc-plugins/webgen.local.md` |\n| taskflow | `~/.gsc-plugins/taskflow.local.md` |\n| docs | `~/.gsc-plugins/docs.local.md` |\n\nProject-specific configs override globals via `./.{plugin}.local.md`.\n\n## Version History\n\n### 1.7.1\n- **Seed Data**: Bootstrap data loaded during init for better onboarding\n  - Tag taxonomy for consistent tagging (k8sâ†’kubernetes, pgâ†’postgresql, etc.)\n  - Core topics for knowledge organization (infrastructure, development, security, etc.)\n  - Quick start guide in knowledge base\n- **Run Seeds Script**: `seed/run-seeds.sh` for both SQLite and PostgreSQL backends\n\n### 1.7.0\n- **Unified Configuration**: Config moved to `~/.gsc-plugins/worklog.local.md`\n- **Plugin Discovery**: Auto-detect other GSC plugins during init\n- **Knowledge Import**: Import existing knowledge from other plugins\n- **Ecosystem Integration**: Part of unified GSC plugins ecosystem\n\n### 1.6.1\n- **Security Hardening**: Comprehensive security review and fixes\n  - SQL injection prevention via column whitelists and parameterized queries\n  - Connection pool lifecycle management with lifespan context manager\n  - Race condition fix in database initialization (asyncio.Lock)\n  - Connection and query timeouts for PostgreSQL (30s/60s)\n  - Explicit fallback control via `WORKLOG_ALLOW_FALLBACK`\n  - Port validation for PostgreSQL configuration\n  - DSN function marked internal to prevent credential logging\n\n### 1.6.0\n- **Dual Database Backend**: Support for both SQLite (default) and PostgreSQL\n- **SQLite Default**: No external dependencies required for standard use\n- **PostgreSQL Optional**: For multi-system teams and cross-agent collaboration\n- **Backend Auto-Detection**: Automatically uses PostgreSQL if `DATABASE_URL` or `PGHOST` is set\n- **Database Abstraction Layer**: MCP server handles SQL dialect differences automatically\n- **Updated Commands**: All commands (`/worklog-init`, `/worklog-connect`, `/worklog-configure`, `/worklog-status`) support both backends\n- **Updated Skills**: `memory-store` and `memory-recall` skills show examples for both backends\n\n### 1.5.0\n- **Cross-Platform Python Detection**: New `detect-python-env.sh` script with intelligent priority (pyenv â†’ mise â†’ Homebrew â†’ system)\n- **Automated MCP Setup**: New `/worklog-setup-mcp` command and `setup-mcp-venv.sh` script\n- **Platform-Aware Recommendations**: Suggests appropriate Python installation method per platform\n- **Lower Python Requirement**: Now requires Python 3.10+ (was 3.11+)\n- **Scripts Directory**: New `scripts/` folder for setup utilities\n\n### 1.4.0\n- **MCP Server**: Added FastMCP-based MCP server for programmatic database access\n- **11 MCP Tools**: query_table, search_knowledge, recall_context, store_memory, update_memory, log_entry, store_knowledge, get_knowledge_entry, get_memory, list_tables, get_recent_entries\n- **Dual Access**: Skills for guided workflows, MCP for automation\n- **Auto-Detection**: Database path auto-detected by hostname\n\n### 1.3.0\n- **Progressive Disclosure (SessionStart)**: Index-first injection reduces context bloat by 60-70%\n- **AI Compression (SessionStop)**: Semantic extraction of learnings vs raw transcript logging\n- **PostToolUse Hook**: Optional auto-capture of significant file changes (off by default)\n- **Deep Extraction (Aggressive)**: Automatically extracts decisions, patterns, errors, gotchas\n- **Token Efficiency**: Typical injection reduced from ~1500-3000 tokens to ~300-500 tokens\n\n### 1.2.0\n- **Hooks for Automation**: SessionStart and Stop hooks for automatic context loading and learning capture\n- **Hook Modes**: off, remind, light, full, aggressive - independent of profile selection\n- **Enhanced Init Flow**: Now prompts for hook mode during `/worklog-init`\n- **Updated Templates**: Templates now reflect hook behavior and settings\n- **Viewer Documentation**: Clarified installation-specific paths for worklog-viewer\n\n### 1.1.0\n- **Safety Protocol**: Backup-verify-restore flow for init/connect commands\n- Automated verification checks before finalizing\n- User confirmation step with rollback capability\n- Timestamped backups retained for 7 days\n\n### 1.0.1\n- Schema split: extended.sql reduced to 4 tables\n- New domain-agency.sql for clients/competitors (optional)\n\n### 1.0.0\n- Initial release\n- 3 profile levels (minimal, standard, full)\n- Core and extended schemas\n- Network retry logic\n- Multi-system support\n\n## License\n\nMIT\n",
        "plugins/worklog/agents/kb-curator.md": "---\nname: kb-curator\ndescription: Knowledge Base curator agent for periodic deep curation - normalizes tags, discovers relationships, manages topics, detects duplicates, and handles memory lifecycle\nmodel: haiku\ntools:\n  - mcp__plugin_worklog_worklog__*\n  - Bash\n  - Read\n  - Write\n---\n\n# Knowledge Base Curator Agent\n\nYou are an autonomous curator agent responsible for maintaining the quality and organization of the worklog knowledge base. You perform deep analysis and curation tasks that would be too time-consuming for interactive sessions.\n\n## Core Responsibilities\n\n1. **Tag Normalization** - Ensure consistent tag usage across all entries\n2. **Relationship Discovery** - Find and create semantic relationships between entries\n3. **Topic Index Management** - Generate and maintain topic summaries\n4. **Duplicate Detection** - Identify and flag potential duplicate content\n5. **Memory Lifecycle** - Evaluate memories for promotion or archival\n6. **Quality Reporting** - Generate curation metrics and recommendations\n\n## Safety Guardrails\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                    SAFETY CONSTRAINTS                        â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ âœ“ READ operations: Always allowed                           â”‚\nâ”‚ âœ“ CREATE operations: Relationships, topics, taxonomy        â”‚\nâ”‚ âœ“ UPDATE operations: Summaries, metadata, status            â”‚\nâ”‚ âš  FLAG operations: Mark for human review, don't delete     â”‚\nâ”‚ âœ— DELETE operations: NEVER - flag for review instead       â”‚\nâ”‚ âœ— MERGE operations: NEVER - flag duplicates for review     â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n**When uncertain:** Flag for human review rather than taking action.\n\n---\n\n## Curation Workflow\n\n### Phase 1: Assessment\n\nStart by gathering current state:\n\n```\n1. Use MCP: list_tables() - Get table counts\n2. Use MCP: query_table(table=\"curation_history\", order_by=\"run_at DESC\", limit=5)\n3. Calculate time since last curation run\n```\n\nReport initial assessment:\n```markdown\n## Curation Assessment\n\n**Last curation:** [timestamp] ([operation])\n**Tables:** [counts]\n**Estimated work:** [scope description]\n```\n\n### Phase 2: Tag Normalization\n\n1. **Scan for non-canonical tags**\n   ```sql\n   -- Find tags not in taxonomy (PostgreSQL)\n   SELECT DISTINCT unnest(string_to_array(tags, ',')) as tag\n   FROM memories WHERE tags IS NOT NULL AND tags != ''\n   EXCEPT SELECT canonical_tag FROM tag_taxonomy\n   EXCEPT SELECT unnest(aliases) FROM tag_taxonomy;\n   ```\n\n2. **For each unknown tag:**\n   - Check if it's a typo/variant of existing tag\n   - If similar to existing: Add as alias (flag for review)\n   - If new concept: Create new taxonomy entry\n   ```\n   Use MCP: add_tag_taxonomy(canonical_tag=\"[tag]\", category=\"[inferred]\")\n   ```\n\n3. **Normalize existing entries**\n   ```\n   Use MCP: normalize_tags(tags=\"[entry_tags]\")\n   ```\n   Update entries with normalized tags.\n\n4. **Log results**\n   ```\n   Use MCP: log_curation_run(operation=\"tag_normalization\", agent=\"kb-curator\",\n     stats='{\"scanned\":N,\"normalized\":M,\"new_tags\":K}')\n   ```\n\n### Phase 3: Relationship Discovery\n\n1. **Find unlinked high-value entries**\n   ```sql\n   SELECT m.id, m.key, m.content, m.tags\n   FROM memories m\n   WHERE m.importance >= 6\n     AND NOT EXISTS (\n       SELECT 1 FROM relationships r\n       WHERE (r.source_table = 'memories' AND r.source_id = m.id)\n          OR (r.target_table = 'memories' AND r.target_id = m.id)\n     )\n   LIMIT 20;\n   ```\n\n2. **Analyze content for relationships**\n   For each unlinked entry:\n   - Extract key concepts and entities\n   - Search for related entries by content similarity\n   - Identify relationship type (relates_to, implements, documents, etc.)\n\n3. **Create discovered relationships**\n   ```\n   Use MCP: add_relationship(\n     source_table=\"memories\", source_id=[id1],\n     target_table=\"knowledge_base\", target_id=[id2],\n     relationship_type=\"relates_to\",\n     confidence=0.8,\n     created_by=\"kb-curator\"\n   )\n   ```\n\n4. **Log results**\n   ```\n   Use MCP: log_curation_run(operation=\"relationship_discovery\", agent=\"kb-curator\",\n     stats='{\"analyzed\":N,\"relationships_created\":M}')\n   ```\n\n### Phase 4: Topic Index Management\n\n1. **Identify topic gaps**\n   Find clusters of related entries without a topic:\n   - Group by common tags\n   - Group by semantic similarity\n   - Identify recurring themes in content\n\n2. **Create or update topics**\n   ```\n   Use MCP: create_topic(topic_name=\"[name]\", summary=\"[TLDR]\", key_terms=\"[terms]\")\n   ```\n\n3. **Link entries to topics**\n   ```\n   Use MCP: add_topic_entry(topic_name=\"[name]\", entry_table=\"[table]\",\n     entry_id=[id], relevance_score=[0.0-1.0])\n   ```\n\n4. **Generate topic summaries**\n   For each topic with new entries:\n   - Read all linked entries\n   - Generate comprehensive summary\n   - Update topic index\n   ```\n   Use MCP: update_topic_summary(topic_name=\"[name]\",\n     summary=\"[TLDR]\", full_summary=\"[detailed]\", key_terms=\"[updated terms]\")\n   ```\n\n5. **Log results**\n   ```\n   Use MCP: log_curation_run(operation=\"topic_indexing\", agent=\"kb-curator\",\n     stats='{\"topics_created\":N,\"topics_updated\":M,\"entries_linked\":K}')\n   ```\n\n### Phase 5: Duplicate Detection\n\n1. **Scan for potential duplicates**\n   - Title/key similarity\n   - Content overlap (shared phrases > 50%)\n   - Same tags + similar content\n\n2. **Score duplicate candidates**\n   ```\n   similarity_score = weighted_average(\n     title_similarity * 0.3,\n     content_similarity * 0.5,\n     tag_similarity * 0.2\n   )\n   ```\n\n3. **Flag high-confidence duplicates**\n   For pairs with similarity > 0.7:\n   ```sql\n   INSERT INTO duplicate_candidates\n     (entry1_table, entry1_id, entry2_table, entry2_id,\n      similarity_score, detection_method, status)\n   VALUES ('[table1]', [id1], '[table2]', [id2],\n           [score], 'kb-curator-semantic', 'pending');\n   ```\n\n4. **Log results**\n   ```\n   Use MCP: log_curation_run(operation=\"duplicate_detection\", agent=\"kb-curator\",\n     stats='{\"scanned\":N,\"candidates_flagged\":M}')\n   ```\n\n### Phase 6: Memory Lifecycle\n\n1. **Identify promotion candidates**\n   ```sql\n   SELECT * FROM memories\n   WHERE status = 'staging'\n     AND importance >= 6\n     AND created_at < NOW() - INTERVAL '2 days'\n   ORDER BY importance DESC;\n   ```\n\n2. **Evaluate each candidate**\n   Criteria for auto-promotion:\n   - importance >= 7\n   - Has relationships or topic associations\n   - Content is substantial (> 100 chars)\n   - Not flagged as duplicate\n\n3. **Auto-promote qualifying memories**\n   ```\n   Use MCP: update_memory(key=\"[key]\", status=\"promoted\")\n   ```\n\n   Log to promotion_history:\n   ```sql\n   INSERT INTO promotion_history\n     (memory_id, from_status, to_status, reason, promoted_by)\n   VALUES ([id], 'staging', 'promoted', 'auto-promotion: meets criteria', 'kb-curator');\n   ```\n\n4. **Flag low-value for archival review**\n   Memories with:\n   - importance < 4\n   - age > 30 days\n   - No relationships\n   - status = 'staging'\n\n   Flag but don't archive automatically.\n\n5. **Log results**\n   ```\n   Use MCP: log_curation_run(operation=\"memory_lifecycle\", agent=\"kb-curator\",\n     stats='{\"promoted\":N,\"flagged_archive\":M}')\n   ```\n\n---\n\n## Output Format\n\n### Progress Updates\n\nDuring execution, provide periodic updates:\n```markdown\n## Curation Progress\n\n**Phase:** [current phase]\n**Status:** [in progress / complete]\n**Items processed:** N / M\n**Actions taken:** [summary]\n```\n\n### Final Report\n\nAfter all phases complete:\n```markdown\n## Curation Complete\n\n### Summary\n| Phase | Items Processed | Actions Taken |\n|-------|-----------------|---------------|\n| Tag Normalization | N | M normalized, K new |\n| Relationship Discovery | N | M relationships |\n| Topic Management | N | M topics updated |\n| Duplicate Detection | N | M flagged |\n| Memory Lifecycle | N | M promoted |\n\n### Total Duration\n[X minutes]\n\n### Recommendations\n- [Items requiring human review]\n- [Suggested follow-up actions]\n\n### Next Scheduled Run\n[Based on configuration]\n\n---\n*All operations logged to curation_history*\n```\n\n---\n\n## Invocation\n\nThis agent can be invoked via:\n\n```\nTask tool with subagent_type=\"kb-curator\"\n```\n\n**Example prompts:**\n- \"Run full curation cycle on the knowledge base\"\n- \"Focus on tag normalization only\"\n- \"Scan for duplicates in the last 7 days of entries\"\n- \"Generate topic summaries for all topics\"\n\n---\n\n## Configuration\n\n| Setting | Default | Description |\n|---------|---------|-------------|\n| max_items_per_phase | 50 | Limit items processed per phase |\n| auto_promote_threshold | 7 | Minimum importance for auto-promotion |\n| duplicate_threshold | 0.7 | Minimum similarity for duplicate flagging |\n| archive_age_days | 30 | Days before considering archival |\n\n---\n\n## Related\n\n- **INFA-290**: Schema migrations (curation tables)\n- **INFA-291**: MCP tools (curation operations)\n- **INFA-292**: /curate skill (interactive curation)\n- **INFA-295**: Curation automation (scheduling)\n",
        "plugins/worklog/commands/worklog-configure.md": "---\ndescription: \"Setting to change: profile, backend, or show\"\narguments:\n  - name: setting\n    description: \"Setting to change: profile, backend, or show\"\n    required: false\n---\n\n# Worklog Configure\n\nModify worklog settings after initial setup.\n\n## Usage\n\n```\n/worklog-configure              # Interactive menu\n/worklog-configure show         # Show current settings\n/worklog-configure backend      # Change database backend\n/worklog-configure profile      # Change profile level\n```\n\n## Workflow\n\n### Step 1: Read Current Configuration\n\nLoad settings from `~/.gsc-plugins/worklog.local.md`:\n- `backend`: sqlite or postgresql\n- `profile`: minimal/standard/full\n- `db_path`: SQLite database path\n- `database_url`: PostgreSQL connection (if applicable)\n\nIf config not found:\n```\nWorklog not configured.\nRun /worklog-init to set up.\n```\n\n### Step 2: Show Current Settings\n\n**For SQLite:**\n```bash\nDB=\"${WORKLOG_DB_PATH:-$HOME/.claude/worklog/worklog.db}\"\n[ -f \"$DB\" ] && echo \"Database: âœ… Found\" || echo \"Database: âŒ Not found\"\nsqlite3 \"$DB\" \"SELECT COUNT(*) as count FROM entries;\" 2>/dev/null\n```\n\n**For PostgreSQL:**\n```bash\npsql -c \"SELECT 1;\" > /dev/null 2>&1 && echo \"Connection: âœ… OK\" || echo \"Connection: âŒ Failed\"\npsql -t -c \"SELECT COUNT(*) FROM entries;\"\n```\n\n```\nCurrent Worklog Configuration:\n==============================\n\nBackend:        {sqlite|postgresql}\nProfile:        {profile}\nHook Mode:      {hook_mode}\n\n{For SQLite:}\nDatabase Path:  {db_path}\nDatabase Size:  {size}\n\n{For PostgreSQL:}\nHost:           {host}\nPort:           {port}\nDatabase:       {database}\n\nContent Stats:\n- Entries:      {count}\n- Knowledge:    {count}\n- Memories:     {count}\n\nWhat would you like to change?\n[1] Backend (switch between SQLite/PostgreSQL)\n[2] Profile (minimal/standard/full)\n[3] Test connection\n[4] Exit\n```\n\n### Step 3: Change Backend\n\nIf switching from SQLite to PostgreSQL:\n```\nSwitching to PostgreSQL requires:\n1. A running PostgreSQL server\n2. Connection credentials\n\nConfigure connection:\n[A] DATABASE_URL\n[B] Individual PG* variables\n\nNote: Your SQLite data will NOT be migrated automatically.\n```\n\nIf switching from PostgreSQL to SQLite:\n```\nSwitching to SQLite will create a local database at:\n~/.claude/worklog/worklog.db\n\nNote: Your PostgreSQL data will NOT be migrated automatically.\nContinue? (y/n)\n```\n\n### Step 4: Change Profile\n\n```\nSelect new profile:\n\n[1] MINIMAL - Manual store/recall only\n[2] STANDARD - Light boot queries (Recommended)\n[3] FULL - Aggressive context loading\n```\n\nUpdate `~/.gsc-plugins/worklog.local.md` and replace CLAUDE.md section with new template.\n\n### Step 5: Test Connection\n\n**SQLite:**\n```bash\nDB=\"${WORKLOG_DB_PATH:-$HOME/.claude/worklog/worklog.db}\"\nsqlite3 \"$DB\" \"SELECT 'Connection OK' as status, COUNT(*) as entries FROM entries;\"\n```\n\n**PostgreSQL:**\n```bash\npsql -c \"SELECT 'Connection OK' as status, COUNT(*) as entries FROM entries;\"\n```\n\n### Step 6: Update Configuration File\n\nRewrite `~/.gsc-plugins/worklog.local.md`:\n\n```markdown\n---\nprofile: {new_profile}\nhook_mode: {new_hook_mode}\nbackend: {backend}\ndb_path: {path}                    # for SQLite\ndatabase_url: {url}                # for PostgreSQL\nsystem_name: {hostname}\ninitialized: {original_timestamp}\nlast_modified: {now}\n---\n\n# Worklog Configuration\n\n## Change History\n- {timestamp}: {what changed}\n```\n\n### Step 7: Confirm Changes\n\n```\nConfiguration updated!\n\nBackend:  {backend}\nProfile:  {profile}\nStatus:   âœ… Connected\n\nRun `/worklog-status` to verify.\n```\n\n## Troubleshooting\n\n### SQLite Issues\n\n**Database not found:**\n```\nThe database file doesn't exist at the expected path.\nRun /worklog-init to create it.\n```\n\n**Permission denied:**\n```\nCannot write to database. Check permissions:\nls -la ~/.claude/worklog/\n```\n\n### PostgreSQL Issues\n\n**Connection refused:**\n```\n1. Check if PostgreSQL server is running\n2. Verify host and port are correct\n3. Check network connectivity\n```\n\n**Authentication failed:**\n```\n1. Verify credentials\n2. Check username and password\n3. Verify database name\n```\n\n### Environment Not Set\n\n**For PostgreSQL:**\n```bash\n# Check environment\necho \"DATABASE_URL: ${DATABASE_URL:-not set}\"\necho \"PGHOST: ${PGHOST:-not set}\"\n\n# Set if needed\nexport DATABASE_URL=\"postgresql://user:pass@host:port/db\"\nsource ~/.zshrc\n```\n\n$ARGUMENTS\n",
        "plugins/worklog/commands/worklog-connect.md": "---\ndescription: Path to the shared worklog database\narguments:\n  - name: db_path\n    description: Path to SQLite database or PostgreSQL connection string\n    required: false\n---\n\n# Worklog Connect\n\nConnect to an existing worklog database. Supports both SQLite (default) and PostgreSQL backends.\n\n**Note:** This is a quick-connect alias for `/worklog-init`. For full configuration including profile selection, run `/worklog-init` instead.\n\n## Workflow\n\n### Step 1: Detect Backend\n\nIf `db_path` argument provided:\n- If ends with `.db` â†’ SQLite\n- If starts with `postgresql://` â†’ PostgreSQL\n- If empty â†’ Interactive selection\n\n```\nChoose database backend:\n\n[A] SQLite (Recommended for most users)\n    Connect to local or shared SQLite database file\n    - No external dependencies\n    - Works offline\n\n[B] PostgreSQL (For multi-system setups)\n    Connect to PostgreSQL server\n    - Shared database across systems\n    - Requires network connectivity\n```\n\n---\n\n### If SQLite Selected:\n\n#### Step 2a: Get Database Path\n\n```\nEnter path to SQLite database:\n- Local: ~/.claude/worklog/worklog.db (default)\n- Shared: /mnt/nas/worklog.db\n\nPath: _\n```\n\n#### Step 3a: Test Connection\n\n```bash\nDB=\"$PROVIDED_PATH\"\n[ -f \"$DB\" ] && echo \"Database: âœ… Found\" || echo \"Database: âŒ Not found\"\nsqlite3 \"$DB\" \"SELECT COUNT(*) as count FROM entries;\"\n```\n\nIf database exists and is readable:\n```\nSQLite Connection Test:\n=======================\nDatabase:  âœ… Found\nEntries:   127\nTables:    6 core tables detected\n\nConnection successful!\n```\n\nIf not found:\n```\nDatabase not found at: /path/to/db\n\nOptions:\n[1] Run /worklog-init to create new database\n[2] Provide different path\n[3] Cancel\n```\n\n---\n\n### If PostgreSQL Selected:\n\n#### Step 2b: Configure Connection\n\n```\nHow would you like to configure the PostgreSQL connection?\n\n[A] DATABASE_URL (Recommended)\n    Single environment variable with full connection string\n\n[B] Individual PG* variables\n    Separate PGHOST, PGPORT, PGDATABASE, PGUSER, PGPASSWORD\n```\n\n**Option A - DATABASE_URL:**\n\n```bash\n# Add to ~/.zshrc or ~/.bashrc:\nexport DATABASE_URL=\"postgresql://user:password@host:port/database\"\n\n# Reload:\nsource ~/.zshrc\n```\n\n**Option B - Individual Variables:**\n\n```bash\n# Add to ~/.zshrc or ~/.bashrc:\nexport PGHOST=your-host\nexport PGPORT=5432\nexport PGDATABASE=worklog\nexport PGUSER=worklog\nexport PGPASSWORD=\"your-password\"\n\n# Reload:\nsource ~/.zshrc\n```\n\n#### Step 3b: Test Connection\n\n```bash\npsql -c \"SELECT 'Connected!' as status, COUNT(*) as entries FROM entries;\"\n```\n\nIf successful:\n```\nPostgreSQL Connection Test:\n===========================\nHost:      your-host:5432\nDatabase:  worklog\nStatus:    âœ… Connected\nEntries:   127\n\nConnection successful!\n```\n\nIf fails:\n```\nPostgreSQL Connection Test:\n===========================\nStatus:    âŒ Failed\nError:     {error_message}\n\nTroubleshooting:\n----------------\n{If \"connection refused\":}\n1. Check server is running\n2. Verify host and port\n\n{If \"authentication failed\":}\n1. Verify credentials\n2. Check DATABASE_URL or PG* variables\n\n{If \"could not translate host name\":}\n1. Check PGHOST is set correctly\n2. Verify DNS/network connectivity\n```\n\n---\n\n### Step 4: Create Configuration\n\nCreate `~/.gsc-plugins/worklog.local.md`:\n\n```markdown\n---\nprofile: standard\nbackend: {sqlite|postgresql}\ndb_path: {path}                    # for SQLite\n# database_url: {url}             # for PostgreSQL (if using DATABASE_URL)\nsystem_name: {hostname}\ninitialized: {timestamp}\n---\n\n# Worklog Configuration\n\nConnected to existing database via /worklog-connect.\nRun /worklog-configure to change settings.\n```\n\n### Step 5: Confirmation\n\n```\nWorklog connected!\n\nBackend:  {sqlite|postgresql}\nStatus:   âœ… Connected\nEntries:  {count}\n\nFor full configuration (profile, hooks), run:\n/worklog-init\n\nCommands available:\n- /worklog-status - Check connectivity\n- /worklog-configure - Change settings\n```\n\n## Quick Connect Examples\n\n**SQLite (local):**\n```\n/worklog-connect ~/.claude/worklog/worklog.db\n```\n\n**SQLite (network share):**\n```\n/worklog-connect /Volumes/nas/shared/worklog.db\n```\n\n**PostgreSQL (via DATABASE_URL):**\n```\n/worklog-connect postgresql://user:pass@host:5432/worklog\n```\n\n## Troubleshooting\n\n### SQLite Issues\n\n**Database not found:**\n```\n1. Verify the file exists: ls -la /path/to/db\n2. Check you have read permissions\n3. If new setup, run /worklog-init instead\n```\n\n**Permission denied:**\n```\n1. Check file permissions: ls -la /path/to/db\n2. For network shares, verify mount is writable\n3. Check directory permissions for journal file\n```\n\n### PostgreSQL Issues\n\n**Connection refused:**\n```\n1. Check if PostgreSQL server is running\n2. Verify host and port are correct\n3. Check network/firewall settings\n```\n\n**Authentication failed:**\n```\n1. Verify credentials in DATABASE_URL or PG* vars\n2. Check username and password\n3. Verify database name exists\n```\n\n**Environment not set:**\n```bash\n# Check environment\necho \"DATABASE_URL: ${DATABASE_URL:-not set}\"\necho \"PGHOST: ${PGHOST:-not set}\"\n\n# Set if needed\nexport DATABASE_URL=\"postgresql://user:pass@host:port/db\"\nsource ~/.zshrc\n```\n\n$ARGUMENTS\n",
        "plugins/worklog/commands/worklog-init.md": "---\ndescription: Initialize worklog database for cross-session persistence (primary system setup)\narguments: []\n---\n\n# Worklog Init\n\nInitialize the worklog plugin for cross-session knowledge persistence.\n\n## Overview\n\nThis command sets up the worklog database on your system. Choose between:\n\n- **SQLite (Default)**: Local database, no external dependencies\n- **PostgreSQL (Optional)**: Shared database for multi-system setups\n\n## Workflow\n\n### Step 1: Check Existing Configuration\n\n```python\n# Check for existing config\nconfig_path = os.path.expanduser(\"~/.gsc-plugins/worklog.local.md\")\n\nif os.path.exists(config_path):\n    print(\"Worklog already configured.\")\n    print(f\"Config: {config_path}\")\n\n    response = AskUserQuestion({\n        \"question\": \"What would you like to do?\",\n        \"header\": \"Config exists\",\n        \"options\": [\n            {\"label\": \"Keep existing\", \"description\": \"Exit without changes\"},\n            {\"label\": \"Reconfigure\", \"description\": \"Update configuration\"},\n            {\"label\": \"View config\", \"description\": \"Show current settings\"}\n        ]\n    })\n\n    if response == \"Keep existing\":\n        return\n    elif response == \"View config\":\n        showConfig(config_path)\n        return\n```\n\n### Step 2: Choose Database Backend\n\n```\nWhich database backend would you like to use?\n\n[A] SQLite (Recommended for most users)\n    - Local database at ~/.claude/worklog/worklog.db\n    - No external dependencies\n    - Works offline\n    - Single system use\n\n[B] PostgreSQL (For multi-system setups)\n    - Shared database across systems\n    - Requires PostgreSQL server\n    - Enables cross-agent collaboration\n    - Requires network connectivity\n```\n\n---\n\n### If SQLite Selected:\n\n#### Step 3a: Choose Integration Profile\n\n**[1] MINIMAL** - Lightweight persistence\n- Manual store/recall via skills\n- No automatic boot queries\n- CLAUDE.md addition: ~20 lines\n- Best for: Occasional use, minimal overhead\n\n**[2] STANDARD** - Balanced integration (Recommended)\n- Light boot queries for recent context\n- Prompts to store learnings at task end\n- CLAUDE.md addition: ~50 lines\n- Best for: Daily use, cross-session continuity\n\n**[3] FULL** - Maximum context awareness\n- Aggressive boot queries (protocols, recent work, errors)\n- Auto-store task outcomes\n- CLAUDE.md addition: ~100 lines\n- Best for: Power users wanting full automation\n\n#### Step 4a: Create Database\n\n```bash\n# Create directory\nmkdir -p ~/.claude/worklog\n\n# Database will be auto-created by the MCP server on first use\n# Or create manually with schema:\nsqlite3 ~/.claude/worklog/worklog.db < {plugin_root}/schema/core.sql\n\n# Load seed data (tag taxonomy, topics, bootstrap knowledge)\n{plugin_root}/seed/run-seeds.sh sqlite ~/.claude/worklog/worklog.db\n```\n\n---\n\n### If PostgreSQL Selected:\n\n#### Step 3b: Choose Integration Profile\n\nSame options as SQLite (MINIMAL, STANDARD, FULL)\n\n#### Step 4b: Configure Connection\n\n```\nHow would you like to configure the PostgreSQL connection?\n\n[A] DATABASE_URL (Recommended)\n    Single environment variable with full connection string\n\n[B] Individual PG* variables\n    Separate PGHOST, PGPORT, PGDATABASE, PGUSER, PGPASSWORD\n```\n\n**Option A - DATABASE_URL:**\n\n```bash\n# Add to ~/.zshrc or ~/.bashrc:\nexport DATABASE_URL=\"postgresql://user:password@host:port/database\"\n\n# Then run: source ~/.zshrc\n```\n\n**Option B - Individual Variables:**\n\n```bash\n# Add to ~/.zshrc or ~/.bashrc:\nexport PGHOST=your-host\nexport PGPORT=5432\nexport PGDATABASE=worklog\nexport PGUSER=worklog\nexport PGPASSWORD=\"your-password\"\n\n# Then run: source ~/.zshrc\n```\n\n#### Step 5b: Test Connection & Load Schema\n\n```bash\n# Test connection\npsql -c \"SELECT 1;\"\n\n# Load schema (if not already created)\npsql -f {plugin_root}/schema/core.sql\n\n# Load seed data (tag taxonomy, topics, bootstrap knowledge)\n{plugin_root}/seed/run-seeds.sh postgresql\n```\n\n---\n\n### Step 5: Create Backups (Safety Protocol)\n\n**Before making ANY changes**, backup existing files:\n\n```bash\nBACKUP_TS=$(date +%Y%m%d%H%M%S)\nBACKUP_DIR=~/.claude/.worklog-backup-$BACKUP_TS\n\nmkdir -p $BACKUP_DIR\n\n# Backup CLAUDE.md if exists\nif [ -f ~/.claude/CLAUDE.md ]; then\n  cp ~/.claude/CLAUDE.md $BACKUP_DIR/CLAUDE.md\n  echo \"Backed up: CLAUDE.md\"\nfi\n\necho $BACKUP_DIR > ~/.claude/.worklog-backup-path\n```\n\n### Step 6: Create Plugin Configuration\n\nCreate `~/.gsc-plugins/worklog.local.md`:\n\n```markdown\n---\nprofile: {selected_profile}\nhook_mode: {selected_hook_mode}\nbackend: {sqlite|postgresql}\ndb_path: ~/.claude/worklog/worklog.db  # for SQLite\n# database_url: postgresql://...       # for PostgreSQL\nsystem_name: {hostname}\ninitialized: {timestamp}\n---\n\n# Worklog Configuration\n\n## Backend\n- **Type:** {backend}\n- **Path/URL:** {path_or_url}\n\n## Settings\n- **Profile:** {profile}\n- **Hook Mode:** {hook_mode}\n\nTo reconfigure, run `/worklog-configure`.\n```\n\n### Step 7: Inject CLAUDE.md Section\n\nRead appropriate template from `{plugin_root}/templates/` based on profile:\n- `minimal.md` for MINIMAL profile\n- `standard.md` for STANDARD profile\n- `full.md` for FULL profile\n\nReplace `{DB_PATH}` or `{DATABASE_URL}` placeholders with actual values.\n\nFor SQLite, boot queries use `sqlite3`:\n```bash\nsqlite3 ~/.claude/worklog/worklog.db \"SELECT ...\"\n```\n\nFor PostgreSQL, boot queries use `psql`:\n```bash\npsql -c \"SELECT ...\"\n```\n\n### Step 8: Plugin Discovery\n\n**Detect other GSC plugins and offer integration:**\n\n```python\n# Scan for other GSC plugin configs\ngsc_plugins_dir = os.path.expanduser(\"~/.gsc-plugins\")\nplugin_configs = glob.glob(f\"{gsc_plugins_dir}/*.local.md\")\n\n# Check for known plugins\ndetected_plugins = []\nfor config in plugin_configs:\n    name = os.path.basename(config).replace(\".local.md\", \"\")\n    if name != \"worklog\":\n        detected_plugins.append(name)\n\n# Check for plugin directories\nplugin_dirs = [\n    \"~/.claude/plugins/local-plugins\",\n    \"~/.claude/plugins/marketplaces/gsc-plugins\"\n]\n\nfor base_dir in plugin_dirs:\n    expanded = os.path.expanduser(base_dir)\n    if os.path.exists(expanded):\n        for item in os.listdir(expanded):\n            if item in [\"appgen\", \"webgen\", \"taskflow\", \"docs\"]:\n                if item not in detected_plugins:\n                    detected_plugins.append(item)\n\n# Report discovered plugins\nif detected_plugins:\n    print(f\"\\nDiscovered GSC plugins: {', '.join(detected_plugins)}\")\n    print(\"\\nWorklog can provide cross-session context for these plugins:\")\n    print(\"- SessionStart hooks inject recent context\")\n    print(\"- SessionStop hooks capture learnings\")\n    print(\"- Knowledge base shared across all plugins\")\n```\n\n**Scan for existing knowledge to import:**\n\n```python\n# Check for markdown knowledge directories\nknowledge_sources = []\n\n# AppGen knowledge\nappgen_kb = os.path.expanduser(\"~/.gsc-plugins/knowledge\")\nif os.path.exists(appgen_kb):\n    md_files = glob.glob(f\"{appgen_kb}/**/*.md\", recursive=True)\n    if md_files:\n        knowledge_sources.append({\n            \"source\": \"appgen/webgen\",\n            \"type\": \"markdown\",\n            \"path\": appgen_kb,\n            \"count\": len(md_files)\n        })\n\n# Docs knowledge base\ndocs_config = loadLocalMdConfig(\"~/.gsc-plugins/docs.local.md\")\nif docs_config and docs_config.get(\"knowledge_base\"):\n    kb_path = os.path.expanduser(docs_config[\"knowledge_base\"])\n    if os.path.exists(kb_path):\n        md_files = glob.glob(f\"{kb_path}/**/*.md\", recursive=True)\n        if md_files:\n            knowledge_sources.append({\n                \"source\": \"docs\",\n                \"type\": \"markdown\",\n                \"path\": kb_path,\n                \"count\": len(md_files)\n            })\n\n# Offer import if knowledge found\nif knowledge_sources:\n    total_files = sum(k[\"count\"] for k in knowledge_sources)\n    print(f\"\\nFound {total_files} knowledge files from other plugins:\")\n    for ks in knowledge_sources:\n        print(f\"  - {ks['source']}: {ks['count']} files at {ks['path']}\")\n\n    response = AskUserQuestion({\n        \"question\": \"Import existing knowledge into worklog?\",\n        \"header\": \"Knowledge Import\",\n        \"options\": [\n            {\"label\": \"Yes (Recommended)\", \"description\": \"Import and centralize all knowledge\"},\n            {\"label\": \"No\", \"description\": \"Start fresh, keep separate\"}\n        ]\n    })\n\n    if \"Yes\" in response:\n        importKnowledge(knowledge_sources)\n```\n\n### Step 9: Import Knowledge (if requested)\n\n```python\ndef importKnowledge(sources):\n    \"\"\"Import markdown knowledge files into worklog database.\"\"\"\n    imported = 0\n\n    for source in sources:\n        if source[\"type\"] == \"markdown\":\n            for md_file in glob.glob(f\"{source['path']}/**/*.md\", recursive=True):\n                # Parse frontmatter\n                with open(md_file, 'r') as f:\n                    content = f.read()\n\n                frontmatter, body = parseFrontmatter(content)\n\n                # Map to knowledge_base entry\n                title = frontmatter.get(\"title\", os.path.basename(md_file))\n                category = frontmatter.get(\"type\", \"general\")\n                tags = frontmatter.get(\"tags\", source[\"source\"])\n\n                # Insert into worklog\n                mcp__worklog__store_knowledge(\n                    category=category,\n                    title=title,\n                    content=body,\n                    tags=tags,\n                    source_agent=f\"import:{source['source']}\"\n                )\n                imported += 1\n\n    print(f\"\\nImported {imported} knowledge entries to worklog.\")\n    print(\"Original files preserved (non-destructive import).\")\n```\n\n### Step 10: Run Verification\n\n**SQLite Verification:**\n```bash\nDB=~/.claude/worklog/worklog.db\n[ -f \"$DB\" ] && echo \"Database: OK\" || echo \"Database: MISSING\"\nsqlite3 \"$DB\" \"SELECT COUNT(*) FROM sqlite_master WHERE type='table';\" && echo \"Schema: OK\"\nsqlite3 \"$DB\" \"SELECT COUNT(*) FROM tag_taxonomy;\" && echo \"Seed data: OK\" || echo \"Seed data: MISSING\"\ngrep -q \"WORKLOG_START\" ~/.claude/CLAUDE.md && echo \"CLAUDE.md: OK\" || echo \"CLAUDE.md: MISSING\"\n[ -f ~/.gsc-plugins/worklog.local.md ] && echo \"Config: OK\" || echo \"Config: MISSING\"\n```\n\n**PostgreSQL Verification:**\n```bash\npsql -c \"SELECT 1;\" && echo \"Connection: OK\" || echo \"Connection: FAILED\"\npsql -c \"SELECT COUNT(*) FROM information_schema.tables WHERE table_schema='public';\" && echo \"Schema: OK\"\npsql -t -c \"SELECT COUNT(*) FROM tag_taxonomy;\" && echo \"Seed data: OK\" || echo \"Seed data: MISSING\"\ngrep -q \"WORKLOG_START\" ~/.claude/CLAUDE.md && echo \"CLAUDE.md: OK\" || echo \"CLAUDE.md: MISSING\"\n[ -f ~/.gsc-plugins/worklog.local.md ] && echo \"Config: OK\" || echo \"Config: MISSING\"\n```\n\n### Step 11: User Confirmation\n\n```\nInstallation complete!\n\nBackend:  {sqlite|postgresql}\nProfile:  {profile}\nHook:     {hook_mode}\n\nChanges made:\n- Created: ~/.gsc-plugins/worklog.local.md\n- Updated: ~/.claude/CLAUDE.md\n{If SQLite: - Created: ~/.claude/worklog/worklog.db}\n- Loaded seed data (tag taxonomy, topics, bootstrap knowledge)\n{If imported: - Imported {n} knowledge entries}\n\nKeep these changes? (y/n)\n```\n\n**If YES:** Finalize installation\n**If NO:** Rollback from backup\n\n### Step 12: Provide Next Steps\n\n```\nWorklog initialized successfully!\n\nBackend: {backend}\nProfile: {profile}\n{If plugins discovered:}\nIntegrates with: {detected_plugins}\n\nSeed data loaded:\n- Tag taxonomy for consistent tagging (k8sâ†’kubernetes, pgâ†’postgresql, etc.)\n- Core topics for knowledge organization\n- Quick start guide in knowledge base\n\nNext steps:\n- Run `search_knowledge(\"Quick Start\")` to see the getting started guide\n- Use `store_memory` to save learnings (tags auto-normalized)\n- Use `recall_context` to query relevant context\n- Run `/worklog-status` to check connectivity\n\nMCP tools available:\n- store_memory, recall_context, search_knowledge\n- log_entry, store_knowledge, query_table\n```\n\n## Error Handling\n\n**SQLite creation fails:**\n- Check write permissions to ~/.claude/\n- Verify disk space available\n\n**PostgreSQL connection fails:**\n- Verify environment variables are set\n- Check network connectivity\n- Verify credentials\n\n**CLAUDE.md not found:**\n- Create minimal CLAUDE.md with worklog section\n\n**Import fails:**\n- Original files are preserved\n- Check file permissions\n- Verify frontmatter format\n\n**Seed data fails:**\n- Schema must be created first\n- Run `{plugin_root}/seed/run-seeds.sh` manually\n- Check for unique constraint violations (safe to ignore - ON CONFLICT DO NOTHING)\n\n## Rollback Command\n\n```bash\nBACKUP=$(ls -td ~/.claude/.worklog-backup-* 2>/dev/null | head -1)\nif [ -n \"$BACKUP\" ]; then\n  cp $BACKUP/CLAUDE.md ~/.claude/CLAUDE.md 2>/dev/null\n  rm -f ~/.gsc-plugins/worklog.local.md\n  echo \"Restored from $BACKUP\"\nfi\n```\n",
        "plugins/worklog/commands/worklog-setup-mcp.md": "---\ndescription: Set up Python environment for worklog MCP server (cross-platform)\narguments: []\n---\n\n# Worklog Setup MCP\n\nSet up the Python virtual environment for the worklog MCP server with intelligent cross-platform detection.\n\n## What This Command Does\n\n1. **Detects Python Environment** - Checks for existing version managers in order:\n   - pyenv (if installed, respects user's explicit choice)\n   - mise (if installed)\n   - Homebrew Python (macOS only)\n   - System Python\n\n2. **Creates Virtual Environment** - Isolated venv for MCP dependencies\n\n3. **Installs Dependencies** - fastmcp, aiosqlite, and plugin code\n\n4. **Outputs Configuration** - Shows .mcp.json settings to use\n\n## Workflow\n\n### Step 1: Run Detection\n\nExecute the detection script to find suitable Python:\n\n```bash\nPLUGIN_DIR=$(dirname $(dirname $(realpath ~/.claude/plugins.json 2>/dev/null || echo ~/.claude)))/gsc-plugins/plugins/worklog\n\n# Or use known paths\nif [[ -d /volume2/dev-env/workspace/gsc-plugins ]]; then\n    PLUGIN_DIR=\"/volume2/dev-env/workspace/gsc-plugins/plugins/worklog\"\nelif [[ -d /Volumes/dev-env/workspace/gsc-plugins ]]; then\n    PLUGIN_DIR=\"/Volumes/dev-env/workspace/gsc-plugins/plugins/worklog\"\nelif [[ -d /mnt/nasdevenv/workspace/gsc-plugins ]]; then\n    PLUGIN_DIR=\"/mnt/nasdevenv/workspace/gsc-plugins/plugins/worklog\"\nelif [[ -d ~/workspace/gsc-plugins ]]; then\n    PLUGIN_DIR=\"$HOME/workspace/gsc-plugins/plugins/worklog\"\nfi\n\n# Run detection\nsource \"$PLUGIN_DIR/scripts/detect-python-env.sh\"\n```\n\nShow the user the detection results:\n\n```\nPython Environment Detection\n==============================\nOS: {macos|linux}\n\n{If PYTHON_OK == \"yes\":}\nâœ“ Found suitable Python\n  Command: {PYTHON_CMD}\n  Version: {PYTHON_VERSION}\n  Source:  {PYTHON_SOURCE}\n\n{If PYTHON_OK == \"no\":}\nâœ— No suitable Python found\n  Required: Python >= 3.10\n\nRecommendation:\n  {PYTHON_RECOMMENDATION}\n```\n\n### Step 2: Handle Missing Python\n\nIf `PYTHON_OK` is \"no\", present the recommendation and ask:\n\n> \"Python 3.10+ is required for the MCP server. Would you like me to help install it?\"\n>\n> **Recommendation:** `{PYTHON_RECOMMENDATION}`\n>\n> Options:\n> - [A] Run the recommended command\n> - [B] I'll install Python myself, then re-run this command\n> - [C] Cancel setup\n\n**If user chooses A:**\n\nExecute the recommendation command. For example:\n- macOS with brew: `brew install python@3.12`\n- Linux with apt: `sudo apt-get install python3.12 python3.12-venv`\n- mise: `mise use python@3.12`\n- pyenv: `pyenv install 3.12 && pyenv global 3.12`\n\nAfter installation, re-run detection to verify.\n\n### Step 3: Create Virtual Environment\n\nOnce Python is available:\n\n```bash\n\"$PLUGIN_DIR/scripts/setup-mcp-venv.sh\"\n```\n\nThis creates the venv at `$PLUGIN_DIR/mcp/.venv` and installs dependencies.\n\n### Step 4: Configure MCP\n\nRead the Python path from the setup output and help configure `.mcp.json`:\n\n```bash\nVENV_PYTHON=$(cat \"$PLUGIN_DIR/mcp/.python-path\")\n```\n\nDetermine the correct database path based on your setup:\n\n| Setup | Database Path |\n|-------|---------------|\n| Local (default) | ~/.claude/worklog/worklog.db |\n| Shared (network mount) | /path/to/shared/worklog.db |\n| PostgreSQL | Set via DATABASE_URL environment variable |\n\nCreate or update `~/.claude/.mcp.json`:\n\n```json\n{\n  \"mcpServers\": {\n    \"worklog\": {\n      \"type\": \"stdio\",\n      \"command\": \"{VENV_PYTHON}\",\n      \"args\": [\"-m\", \"worklog_mcp\"],\n      \"env\": {\n        \"WORKLOG_DB\": \"{DB_PATH}\"\n      }\n    }\n  }\n}\n```\n\n### Step 5: Verify Setup\n\nTest the MCP server:\n\n```bash\n$VENV_PYTHON -m worklog_mcp --help\n```\n\nOr run a quick tool test:\n\n```bash\n$VENV_PYTHON -c \"from worklog_mcp import server; print('MCP server loads OK')\"\n```\n\n### Step 6: Restart Claude Code\n\nInform the user:\n\n> \"Setup complete! Restart Claude Code to load the MCP server.\"\n>\n> After restart, verify with: `claude mcp list`\n>\n> You should see `worklog` with tools like:\n> - query_table\n> - search_knowledge\n> - store_memory\n> - log_entry\n\n## Error Handling\n\n**Python version too old:**\n- Show current version and required version\n- Provide upgrade instructions for the detected source\n\n**venv creation fails:**\n- Check disk space\n- Check write permissions\n- Try alternative venv location: `~/.local/share/gsc-plugins-venv`\n\n**pip install fails:**\n- Check network connectivity\n- Try: `pip install --upgrade pip` first\n- Check if behind proxy (offer to set PIP_PROXY)\n\n**Database not found:**\n- Verify NAS mount (network drive paths)\n- Check if database was initialized with /worklog-init\n- Offer to create new database or set custom WORKLOG_DB path\n\n## Notes\n\n- This command is idempotent - safe to run multiple times\n- Existing venv will prompt before recreation\n- The detection prioritizes user-managed tools (pyenv) over system Python\n- On macOS, prefers Homebrew Python over the ancient system Python (3.9.6)\n",
        "plugins/worklog/commands/worklog-status.md": "---\ndescription: Check worklog database connectivity and display statistics\narguments: []\n---\n\n# Worklog Status\n\nCheck worklog database connectivity and display usage statistics.\n\n## Workflow\n\n### Step 1: Load Configuration\n\nRead `~/.gsc-plugins/worklog.local.md` for settings:\n- `backend`: sqlite or postgresql\n- `profile`\n- `db_path` or `database_url`\n\nIf config not found:\n```\nWorklog not configured.\nRun /worklog-init to set up.\n```\n\n### Step 2: Detect Backend\n\n```bash\n# Auto-detect backend from environment\nif [ -n \"$DATABASE_URL\" ] || [ -n \"$PGHOST\" ]; then\n    BACKEND=\"postgresql\"\nelse\n    BACKEND=\"sqlite\"\nfi\necho \"Backend: $BACKEND\"\n```\n\n### Step 3: Test Connectivity\n\n**SQLite:**\n```bash\nDB=\"${WORKLOG_DB_PATH:-$HOME/.claude/worklog/worklog.db}\"\nsqlite3 \"$DB\" \"SELECT 1;\" 2>&1\n```\n\n**PostgreSQL:**\n```bash\npsql -c \"SELECT 1;\" 2>&1\n```\n\n### Step 4: Gather Statistics\n\n**SQLite:**\n```bash\nDB=\"${WORKLOG_DB_PATH:-$HOME/.claude/worklog/worklog.db}\"\n\n# Table counts\nsqlite3 \"$DB\" \"\nSELECT\n  (SELECT COUNT(*) FROM entries) as entries,\n  (SELECT COUNT(*) FROM knowledge_base) as knowledge,\n  (SELECT COUNT(*) FROM memories) as memories;\n\"\n\n# Recent activity\nsqlite3 \"$DB\" \"\nSELECT agent, COUNT(*) as count\nFROM entries\nWHERE timestamp > datetime('now', '-7 days')\nGROUP BY agent;\n\"\n\n# Database size\nls -lh \"$DB\" | awk '{print $5}'\n```\n\n**PostgreSQL:**\n```bash\n# Table counts\npsql -t -c \"\nSELECT\n  (SELECT COUNT(*) FROM entries) as entries,\n  (SELECT COUNT(*) FROM knowledge_base) as knowledge,\n  (SELECT COUNT(*) FROM memories) as memories;\n\"\n\n# Recent activity\npsql -t -c \"\nSELECT agent, COUNT(*) as count\nFROM entries\nWHERE timestamp > NOW() - INTERVAL '7 days'\nGROUP BY agent;\n\"\n\n# Database size\npsql -t -c \"SELECT pg_size_pretty(pg_database_size(current_database()));\"\n```\n\n### Step 5: Display Status\n\n```\nWorklog Status\n==============\n\nBackend:     {sqlite|postgresql}\nConnection:  âœ… Connected\nProfile:     {profile}\n\n{For SQLite:}\nDatabase:    {db_path}\nSize:        {size}\n\n{For PostgreSQL:}\nHost:        {host}:{port}\nDatabase:    {database}\nSize:        {size}\n\nContent:\n--------\nEntries:         {count}\nKnowledge Base:  {count}\nMemories:        {count}\nOpen Issues:     {count}\nError Patterns:  {count}\n\nRecent Activity (7 days):\n-------------------------\n{agent}: {count} entries\n{agent}: {count} entries\n\nLast Entry:\n-----------\n{timestamp} | {agent} | {title}\n```\n\n### Step 6: Test Write Access\n\n**SQLite:**\n```bash\nsqlite3 \"$DB\" \"INSERT INTO entries (agent, task_type, title) VALUES ('_test', '_test', '_test'); DELETE FROM entries WHERE agent='_test';\"\necho \"Write: âœ…\"\n```\n\n**PostgreSQL:**\n```bash\npsql -c \"INSERT INTO entries (agent, task_type, title) VALUES ('_test', '_test', '_test'); DELETE FROM entries WHERE agent='_test';\"\necho \"Write: âœ…\"\n```\n\n### Troubleshooting Output\n\nIf connectivity fails:\n\n**SQLite:**\n```\nWorklog Status\n==============\n\nBackend:     SQLite\nConnection:  âŒ Failed\nDatabase:    {db_path}\nError:       {error_message}\n\nTroubleshooting:\n----------------\n1. Check if file exists: ls -la {db_path}\n2. Check permissions: test -w {db_path} && echo \"Writable\"\n3. Check directory exists: ls -la ~/.claude/worklog/\n\nRun /worklog-init to create database.\n```\n\n**PostgreSQL:**\n```\nWorklog Status\n==============\n\nBackend:     PostgreSQL\nConnection:  âŒ Failed\nError:       {error_message}\n\nTroubleshooting:\n----------------\n{If \"connection refused\":}\n1. Check server is running\n2. Verify host and port\n3. Check network connectivity\n\n{If \"authentication failed\":}\n1. Verify credentials\n2. Check DATABASE_URL or PG* variables\n\n{If \"could not translate host name\":}\n1. Check PGHOST is set\n2. Verify environment variables\n\nRun /worklog-configure to update settings.\n```\n\n## Quick Check Commands\n\n**SQLite:**\n```bash\nsqlite3 ~/.claude/worklog/worklog.db \"SELECT 'OK', COUNT(*) FROM entries;\"\n```\n\n**PostgreSQL:**\n```bash\npsql -c \"SELECT 'OK', COUNT(*) FROM entries;\"\n```\n",
        "plugins/worklog/hooks/post-tool-use.md": "---\nevent: PostToolUse\npriority: 50\nmatch_tools: [\"Write\", \"Edit\", \"MultiEdit\"]\n---\n\n# Post Tool Use Hook - Selective Observation Capture\n\nAutomatically capture significant tool outcomes during a session. Inspired by claude-mem's observation system but with selective filtering to avoid noise.\n\n## Design Philosophy\n\n**Claude-mem captures everything.** We capture selectively.\n\n| Approach | Pros | Cons |\n|----------|------|------|\n| Capture all | Complete history | Token bloat, noise |\n| Capture none | No overhead | Lost learnings |\n| **Capture significant** | Signal preserved | Requires filtering |\n\nThis hook captures **significant Write/Edit outcomes** - the moments that matter.\n\n## Configuration\n\nThis hook is **OFF by default**. Enable via `~/.gsc-plugins/worklog.local.md`:\n\n```yaml\n---\nprofile: full\nhook_mode: aggressive\ndb_path: ~/.claude/worklog/worklog.db\nsystem_name: my-system\n# PostToolUse capture settings\ncapture_observations: true          # Enable this hook (default: false)\ncapture_filter: significant         # all | significant | decisions-only\ncapture_files: [\"*.md\", \"*.ts\", \"*.py\", \"*.json\"]  # File patterns to capture\ncapture_exclude: [\"node_modules/*\", \"*.lock\", \".git/*\"]  # Exclude patterns\n---\n```\n\n### Capture Modes\n\n| Mode | What Gets Captured | Recommended For |\n|------|-------------------|-----------------|\n| `off` (default) | Nothing | Most users |\n| `significant` | Major file changes, configs, decisions | Power users |\n| `decisions-only` | Only explicit decision markers | Minimal overhead |\n| `all` | Every Write/Edit | Debug/audit only |\n\n## What Makes an Observation \"Significant\"\n\n### Capture If:\n\n| Signal | Example | Why Significant |\n|--------|---------|-----------------|\n| Config file modified | `.env`, `config.json`, `docker-compose.yml` | Deployment-affecting |\n| Schema/migration | `schema.sql`, `*.migration.ts` | Data structure change |\n| Core logic file | `auth.ts`, `api/*.ts` | Business logic |\n| Documentation | `README.md`, `CLAUDE.md` | Knowledge capture |\n| Test file with fix | `*.test.ts` after bug discussion | Bug resolution |\n| Multiple related edits | 3+ files in same directory | Feature implementation |\n\n### Skip If:\n\n| Signal | Example | Why Skip |\n|--------|---------|----------|\n| Generated file | `package-lock.json`, `*.min.js` | No learning value |\n| Trivial change | Typo fix, whitespace | Noise |\n| Temporary file | `/tmp/*`, `*.log` | Ephemeral |\n| Build artifact | `dist/*`, `build/*` | Derived |\n| Single small edit | One-line comment | Too granular |\n\n## Hook Execution\n\n### Step 1: Check if enabled\n\n```bash\nCAPTURE=$(grep -A1 \"^capture_observations:\" ~/.gsc-plugins/worklog.local.md 2>/dev/null | tail -1 | tr -d ' ')\n\nif [ \"$CAPTURE\" != \"true\" ]; then\n  # Hook disabled, exit silently\n  exit 0\nfi\n```\n\n### Step 2: Check tool and file\n\n```bash\nTOOL_NAME=\"{from hook context}\"\nFILE_PATH=\"{from hook context}\"\nCHANGE_SUMMARY=\"{from hook context}\"\n\n# Only process Write, Edit, MultiEdit\nif [[ ! \"$TOOL_NAME\" =~ ^(Write|Edit|MultiEdit)$ ]]; then\n  exit 0\nfi\n\n# Check exclude patterns\nfor pattern in \"${EXCLUDE_PATTERNS[@]}\"; do\n  if [[ \"$FILE_PATH\" == $pattern ]]; then\n    exit 0\n  fi\ndone\n\n# Check include patterns (if specified)\nif [ -n \"$CAPTURE_FILES\" ]; then\n  MATCH=false\n  for pattern in \"${CAPTURE_FILES[@]}\"; do\n    if [[ \"$FILE_PATH\" == $pattern ]]; then\n      MATCH=true\n      break\n    fi\n  done\n  if [ \"$MATCH\" = false ]; then\n    exit 0\n  fi\nfi\n```\n\n### Step 3: Assess significance\n\n```bash\nFILTER=$(grep -A1 \"^capture_filter:\" ~/.gsc-plugins/worklog.local.md 2>/dev/null | tail -1 | tr -d ' ')\nFILTER=\"${FILTER:-significant}\"\n\ncase \"$FILTER\" in\n  all)\n    # Capture everything that passed file filters\n    CAPTURE=true\n    ;;\n  significant)\n    # Apply significance heuristics\n    CAPTURE=false\n\n    # Config files are always significant\n    if [[ \"$FILE_PATH\" =~ \\.(env|json|yaml|yml|toml|ini)$ ]]; then\n      CAPTURE=true\n    fi\n\n    # Schema/migration files\n    if [[ \"$FILE_PATH\" =~ (schema|migration|seed) ]]; then\n      CAPTURE=true\n    fi\n\n    # Core code directories\n    if [[ \"$FILE_PATH\" =~ (src/|lib/|app/) ]]; then\n      # Only if change is substantial (>10 lines or >3 hunks)\n      if [ \"$LINES_CHANGED\" -gt 10 ] || [ \"$HUNKS\" -gt 3 ]; then\n        CAPTURE=true\n      fi\n    fi\n\n    # Documentation always captured\n    if [[ \"$FILE_PATH\" =~ \\.(md|rst|txt)$ ]]; then\n      CAPTURE=true\n    fi\n    ;;\n  decisions-only)\n    # Only capture if change contains decision markers\n    if [[ \"$CHANGE_SUMMARY\" =~ (DECISION|DECIDED|CHOSE|RATIONALE) ]]; then\n      CAPTURE=true\n    fi\n    ;;\nesac\n\nif [ \"$CAPTURE\" = false ]; then\n  exit 0\nfi\n```\n\n### Step 4: Generate observation\n\n```yaml\nobservation:\n  timestamp: \"{ISO-8601}\"\n  tool: \"{Write|Edit|MultiEdit}\"\n  file: \"{file_path}\"\n  type: \"{config|schema|code|docs|test}\"\n  summary: \"One-line description of change\"\n  context: \"Why this change was made (from conversation)\"\n  significance: \"low|medium|high\"\n  tags: [\"auto-generated\", \"tags\"]\n```\n\n### Step 5: Store to memories table\n\n```bash\n# Generate unique key\nOBS_KEY=\"obs_${SYSTEM_NAME}_$(date +%Y%m%d%H%M%S)_$(basename $FILE_PATH | tr '.' '_')\"\n\n# Determine importance based on file type\ncase \"$TYPE\" in\n  config|schema) IMPORTANCE=7 ;;\n  code) IMPORTANCE=6 ;;\n  docs) IMPORTANCE=5 ;;\n  test) IMPORTANCE=5 ;;\n  *) IMPORTANCE=4 ;;\nesac\n\nsqlite3 \"$DB_PATH\" \"INSERT INTO memories\n(key, content, summary, memory_type, importance, source_agent, tags, status) VALUES\n('$OBS_KEY',\n'{\\\"tool\\\": \\\"$TOOL_NAME\\\", \\\"file\\\": \\\"$FILE_PATH\\\", \\\"type\\\": \\\"$TYPE\\\", \\\"context\\\": \\\"$CONTEXT\\\"}',\n'$SUMMARY',\n'observation', $IMPORTANCE, '$SYSTEM_NAME',\n'observation,auto:post-tool,file:$(basename $FILE_PATH),type:$TYPE', 'staging');\" 2>/dev/null\n```\n\n### Step 6: Silent confirmation (no output to user)\n\nThis hook runs silently. Observations are stored but don't interrupt the workflow.\n\nTo review captured observations:\n```sql\nSELECT key, summary, created_at FROM memories\nWHERE memory_type = 'observation'\nORDER BY created_at DESC LIMIT 10;\n```\n\n## Observation Lifecycle\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                    OBSERVATION LIFECYCLE                         â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                                                  â”‚\nâ”‚  PostToolUse Hook                                                â”‚\nâ”‚       â”‚                                                          â”‚\nâ”‚       â–¼                                                          â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚\nâ”‚  â”‚ Filter: Enabled? â”‚â”€â”€Noâ”€â”€â–º Exit silently                      â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚\nâ”‚           â”‚ Yes                                                  â”‚\nâ”‚           â–¼                                                      â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚\nâ”‚  â”‚ Filter: File OK? â”‚â”€â”€Noâ”€â”€â–º Exit silently                      â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚\nâ”‚           â”‚ Yes                                                  â”‚\nâ”‚           â–¼                                                      â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚\nâ”‚  â”‚ Significant?     â”‚â”€â”€Noâ”€â”€â–º Exit silently                      â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚\nâ”‚           â”‚ Yes                                                  â”‚\nâ”‚           â–¼                                                      â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚\nâ”‚  â”‚ Store to         â”‚                                           â”‚\nâ”‚  â”‚ memories table   â”‚                                           â”‚\nâ”‚  â”‚ (status=staging) â”‚                                           â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚\nâ”‚           â”‚                                                      â”‚\nâ”‚           â–¼                                                      â”‚\nâ”‚  SessionEnd Hook                                                 â”‚\nâ”‚       â”‚                                                          â”‚\nâ”‚       â–¼                                                          â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚\nâ”‚  â”‚ Review staged    â”‚                                           â”‚\nâ”‚  â”‚ observations     â”‚                                           â”‚\nâ”‚  â”‚ Promote or       â”‚                                           â”‚\nâ”‚  â”‚ archive          â”‚                                           â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚\nâ”‚                                                                  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Integration with Other Hooks\n\n### SessionStart\n\n```bash\n# Show count of recent observations\nOBS_COUNT=$(sqlite3 \"$DB_PATH\" \"SELECT COUNT(*) FROM memories\nWHERE memory_type = 'observation'\nAND created_at > datetime('now', '-1 day');\" 2>/dev/null)\n\n# Include in index if >0\n```\n\n### SessionEnd\n\n```bash\n# Review staged observations\nSTAGED=$(sqlite3 \"$DB_PATH\" \"SELECT key, summary FROM memories\nWHERE memory_type = 'observation' AND status = 'staging';\" 2>/dev/null)\n\n# Option to promote significant ones to knowledge_base\n# Option to archive trivial ones\n```\n\n## Performance Considerations\n\n| Concern | Mitigation |\n|---------|------------|\n| Hook overhead | Only triggers on Write/Edit/MultiEdit |\n| Database writes | Single INSERT, <10ms |\n| Filter complexity | Exit early if disabled |\n| Storage bloat | Staging â†’ promote/archive cycle |\n\n**Target:** <50ms per hook execution, invisible to user.\n\n## Example Observations\n\n### Config Change\n```json\n{\n  \"key\": \"obs_myhost_20241216143022_docker_compose_yml\",\n  \"summary\": \"Added Redis service to docker-compose.yml\",\n  \"memory_type\": \"observation\",\n  \"importance\": 7,\n  \"tags\": \"observation,auto:post-tool,file:docker-compose.yml,type:config\"\n}\n```\n\n### Code Change\n```json\n{\n  \"key\": \"obs_myhost_20241216143156_auth_ts\",\n  \"summary\": \"Implemented JWT refresh token rotation\",\n  \"memory_type\": \"observation\",\n  \"importance\": 6,\n  \"tags\": \"observation,auto:post-tool,file:auth.ts,type:code\"\n}\n```\n\n### Documentation\n```json\n{\n  \"key\": \"obs_myhost_20241216143312_README_md\",\n  \"summary\": \"Added deployment instructions\",\n  \"memory_type\": \"observation\",\n  \"importance\": 5,\n  \"tags\": \"observation,auto:post-tool,file:README.md,type:docs\"\n}\n```\n\n## Troubleshooting\n\n### Hook not capturing\n\n1. Check `capture_observations: true` in config\n2. Verify file matches include patterns\n3. Check file doesn't match exclude patterns\n4. Verify database is writable\n\n### Too many observations\n\n1. Switch to `capture_filter: significant` or `decisions-only`\n2. Narrow `capture_files` patterns\n3. Expand `capture_exclude` patterns\n\n### Review captured observations\n\n```sql\n-- Recent observations\nSELECT key, summary, importance, created_at\nFROM memories\nWHERE memory_type = 'observation'\nORDER BY created_at DESC LIMIT 20;\n\n-- Observations by file\nSELECT key, summary FROM memories\nWHERE memory_type = 'observation'\nAND tags LIKE '%file:auth.ts%';\n\n-- High importance only\nSELECT key, summary FROM memories\nWHERE memory_type = 'observation'\nAND importance >= 7;\n```\n\n## Version History\n\n### 1.0.0 (Current)\n- Initial PostToolUse hook\n- Selective capture with significance filtering\n- Three capture modes: all, significant, decisions-only\n- File pattern include/exclude\n- Silent operation with staging status\n- Integration with SessionStart/SessionEnd hooks\n",
        "plugins/worklog/hooks/session-start.md": "---\nevent: SessionStart\npriority: 100\nmatch_files: [\"*\"]\n---\n\n# Session Start Hook - Worklog Context Loading\n\nAutomatically load relevant context from the worklog database at session start using **progressive disclosure** - inject summaries first, fetch full details on-demand.\n\n## Progressive Disclosure Pattern\n\nInspired by claude-mem's token-efficient approach:\n\n| Layer | What | When | Token Cost |\n|-------|------|------|------------|\n| **1. Index** | Summary of available context | Always (SessionStart) | ~100-300 tokens |\n| **2. Details** | Full content for selected items | On-demand (memory-recall) | ~500-2000 tokens |\n| **3. Source** | Original entries/queries | Explicit request | Variable |\n\n**Why:** Dumping all context wastes tokens. Index-first lets the agent decide what's relevant.\n\n## Behavior by Hook Mode\n\nRead configuration from `~/.gsc-plugins/worklog.local.md` frontmatter.\n\n### Configuration Check\n\n```bash\n# Read settings from config\nHOOK_MODE=$(grep -A1 \"^hook_mode:\" ~/.gsc-plugins/worklog.local.md 2>/dev/null | tail -1 | tr -d ' ')\nPROFILE=$(grep -A1 \"^profile:\" ~/.gsc-plugins/worklog.local.md 2>/dev/null | tail -1 | tr -d ' ')\nDB_PATH=$(grep -A1 \"^db_path:\" ~/.gsc-plugins/worklog.local.md 2>/dev/null | tail -1 | tr -d ' ')\nSYSTEM_NAME=$(grep -A1 \"^system_name:\" ~/.gsc-plugins/worklog.local.md 2>/dev/null | tail -1 | tr -d ' ')\n\n# Expand ~ in path\nDB_PATH=\"${DB_PATH/#\\~/$HOME}\"\n\n# Default system name to hostname\nSYSTEM_NAME=\"${SYSTEM_NAME:-$(hostname)}\"\n```\n\n### Hook Modes\n\n| Mode | Index Injection | Full Content | Default For |\n|------|-----------------|--------------|-------------|\n| `off` | None | None | - |\n| `remind` | Reminder only | None | minimal |\n| `light` | Summary index | On-demand | standard |\n| `full` | Detailed index | On-demand | full |\n| `aggressive` | Detailed index + auto-fetch critical | Auto for high-priority | full (shared) |\n\n## Execution\n\n### Mode: off\n\nDo nothing.\n\n### Mode: remind\n\nOutput (as system context):\n```\n<worklog-reminder>\nWorklog database available at {db_path}.\nUse `memory-recall` skill to query context. Use `memory-store` skill to save learnings.\n</worklog-reminder>\n```\n\n### Mode: light\n\n**Step 1: Query counts and summaries (fast queries only)**\n\n```bash\n# Count recent work (24h)\nWORK_COUNT=$(sqlite3 \"$DB_PATH\" \"SELECT COUNT(*) FROM entries WHERE timestamp > datetime('now', '-1 day');\" 2>/dev/null)\n\n# Count active memories\nMEMORY_COUNT=$(sqlite3 \"$DB_PATH\" \"SELECT COUNT(*) FROM memories WHERE status != 'archived' AND importance >= 5;\" 2>/dev/null)\n\n# Get top 3 memory keys (index only, not full content)\nMEMORY_INDEX=$(sqlite3 \"$DB_PATH\" \"SELECT key || ' [' || importance || ']' FROM memories WHERE status != 'archived' AND importance >= 5 ORDER BY importance DESC, last_accessed DESC LIMIT 3;\" 2>/dev/null)\n\n# Get most recent work titles (index only)\nWORK_INDEX=$(sqlite3 \"$DB_PATH\" \"SELECT title FROM entries WHERE timestamp > datetime('now', '-1 day') ORDER BY timestamp DESC LIMIT 3;\" 2>/dev/null)\n```\n\n**Step 2: Output summary index**\n\n```\n<worklog-context mode=\"light\" disclosure=\"index\">\n## Available Context\n\n| Category | Count | Est. Tokens | Top Items |\n|----------|-------|-------------|-----------|\n| Recent Work (24h) | {WORK_COUNT} | ~{WORK_COUNT * 150} | {WORK_INDEX or \"None\"} |\n| Active Memories | {MEMORY_COUNT} | ~{MEMORY_COUNT * 200} | {MEMORY_INDEX or \"None\"} |\n\n**To fetch full details:** Use `memory-recall` skill with category filter.\n**To store learnings:** Use `memory-store` skill after significant work.\n</worklog-context>\n```\n\n### Mode: full\n\n**Step 1: Query counts across all categories**\n\n```bash\n# Protocols\nPROTOCOL_COUNT=$(sqlite3 \"$DB_PATH\" \"SELECT COUNT(*) FROM knowledge_base WHERE category = 'protocols' OR tags LIKE '%protocol%';\" 2>/dev/null)\nPROTOCOL_INDEX=$(sqlite3 \"$DB_PATH\" \"SELECT title FROM knowledge_base WHERE category = 'protocols' OR tags LIKE '%protocol%' ORDER BY updated_at DESC LIMIT 3;\" 2>/dev/null)\n\n# Recent work\nWORK_COUNT=$(sqlite3 \"$DB_PATH\" \"SELECT COUNT(*) FROM entries WHERE timestamp > datetime('now', '-1 day');\" 2>/dev/null)\nWORK_INDEX=$(sqlite3 \"$DB_PATH\" \"SELECT title FROM entries WHERE timestamp > datetime('now', '-1 day') ORDER BY timestamp DESC LIMIT 3;\" 2>/dev/null)\n\n# Recent errors (7d)\nERROR_COUNT=$(sqlite3 \"$DB_PATH\" \"SELECT COUNT(*) FROM error_patterns WHERE last_seen > datetime('now', '-7 days');\" 2>/dev/null)\nERROR_INDEX=$(sqlite3 \"$DB_PATH\" \"SELECT error_signature FROM error_patterns WHERE last_seen > datetime('now', '-7 days') ORDER BY occurrence_count DESC LIMIT 3;\" 2>/dev/null)\n\n# Important memories\nMEMORY_COUNT=$(sqlite3 \"$DB_PATH\" \"SELECT COUNT(*) FROM memories WHERE status = 'promoted' OR importance >= 7;\" 2>/dev/null)\nMEMORY_INDEX=$(sqlite3 \"$DB_PATH\" \"SELECT key || ' [' || importance || ']' FROM memories WHERE status = 'promoted' OR importance >= 7 ORDER BY importance DESC LIMIT 3;\" 2>/dev/null)\n\n# Knowledge base (recent/relevant)\nKB_COUNT=$(sqlite3 \"$DB_PATH\" \"SELECT COUNT(*) FROM knowledge_base WHERE updated_at > datetime('now', '-7 days');\" 2>/dev/null)\nKB_INDEX=$(sqlite3 \"$DB_PATH\" \"SELECT title FROM knowledge_base WHERE updated_at > datetime('now', '-7 days') ORDER BY updated_at DESC LIMIT 3;\" 2>/dev/null)\n```\n\n**Step 2: Output detailed index**\n\n```\n<worklog-context mode=\"full\" disclosure=\"index\">\n## Available Context Index\n\n| Category | Count | Est. Tokens | Recent/Top Items |\n|----------|-------|-------------|------------------|\n| Protocols | {PROTOCOL_COUNT} | ~{PROTOCOL_COUNT * 300} | {PROTOCOL_INDEX or \"None\"} |\n| Recent Work (24h) | {WORK_COUNT} | ~{WORK_COUNT * 150} | {WORK_INDEX or \"None\"} |\n| Error Patterns (7d) | {ERROR_COUNT} | ~{ERROR_COUNT * 250} | {ERROR_INDEX or \"None\"} |\n| Important Memories | {MEMORY_COUNT} | ~{MEMORY_COUNT * 200} | {MEMORY_INDEX or \"None\"} |\n| Knowledge Base (7d) | {KB_COUNT} | ~{KB_COUNT * 400} | {KB_INDEX or \"None\"} |\n\n### Quick Actions\n\n- **Fetch category:** `memory-recall` with `category: <name>`\n- **Search all:** `memory-recall` with `query: <search term>`\n- **Store learning:** `memory-store` after significant work\n\n**Tip:** Only fetch what's relevant to the current task.\n</worklog-context>\n```\n\n### Mode: aggressive\n\nSame index as `full`, PLUS:\n\n1. **Auto-fetch critical items** (importance >= 9 or status = 'critical')\n2. **Update last_accessed** on displayed memories\n3. **Log session start** to entries table\n4. **Check for flagged items** for this system\n\n**Step 1: Additional queries**\n\n```bash\n# Critical memories (auto-fetch full content)\nCRITICAL=$(sqlite3 \"$DB_PATH\" \"SELECT key, content FROM memories WHERE importance >= 9 OR status = 'critical' LIMIT 3;\" 2>/dev/null)\n\n# Flagged for this system\nFLAGGED=$(sqlite3 \"$DB_PATH\" \"SELECT title, details FROM entries WHERE tags LIKE '%for:$SYSTEM_NAME%' AND timestamp > datetime('now', '-7 days');\" 2>/dev/null)\n\n# Log session start\nsqlite3 \"$DB_PATH\" \"INSERT INTO entries (agent, task_type, title, outcome, tags) VALUES ('$SYSTEM_NAME', 'session', 'Session started', 'Auto-logged by hook', 'system:$SYSTEM_NAME,type:session-start');\" 2>/dev/null\n\n# Update last_accessed on critical memories\nsqlite3 \"$DB_PATH\" \"UPDATE memories SET last_accessed = datetime('now') WHERE importance >= 9 OR status = 'critical';\" 2>/dev/null\n```\n\n**Step 2: Output with auto-fetched critical items**\n\n```\n<worklog-context mode=\"aggressive\" disclosure=\"index+critical\">\n## Available Context Index\n\n{...same table as full mode...}\n\n## Critical Items (Auto-Fetched)\n\n{CRITICAL or \"No critical items\"}\n\n## Flagged for {SYSTEM_NAME}\n\n{FLAGGED or \"Nothing flagged for this system\"}\n\n---\n**Worklog Active (Aggressive):** Session logged. Critical items pre-loaded.\nUse `memory-recall` for additional context. Use `memory-store` to capture learnings.\n</worklog-context>\n```\n\n## Error Handling\n\n**Database unreachable:**\n```\n<worklog-warning>\nWorklog database not accessible at {db_path}.\nRun `/worklog-status` to diagnose. Continuing without context.\n</worklog-warning>\n```\n\n**Config missing:**\n```\n<worklog-warning>\nWorklog not configured. Run `/worklog-init` to set up.\n</worklog-warning>\n```\n\n**Network timeout (>500ms):**\nGracefully degrade to `remind` mode:\n```\n<worklog-warning>\nWorklog query timed out (network database). Degrading to remind mode.\nUse `memory-recall` to manually fetch context when needed.\n</worklog-warning>\n```\n\n## Token Efficiency\n\n| Mode | Typical Injection | vs. Old Full Dump |\n|------|-------------------|-------------------|\n| remind | ~50 tokens | N/A |\n| light | ~150-300 tokens | 60% reduction |\n| full | ~300-500 tokens | 70% reduction |\n| aggressive | ~500-1000 tokens | 50% reduction |\n\n**Key insight:** Old approach dumped ~1500-3000 tokens. New approach injects ~300-500 token index, agent fetches only what's needed.\n\n## Backwards Compatibility\n\n- All existing hook_mode values work unchanged\n- Output format is enhanced but structurally similar\n- `memory-recall` skill works as before for fetching details\n- No changes required to user configuration\n\n## Notes\n\n- Hook runs in background, injects context before first user message\n- Keep index queries fast (<100ms each, <500ms total)\n- Network databases may timeout - graceful degradation built in\n- Token estimates are approximate (~150-400 tokens per full entry)\n- Progressive disclosure reduces context bloat significantly\n\n## Version History\n\n### 1.3.0 (Current)\n- **Progressive disclosure:** Index-first injection, on-demand details\n- **Token estimates:** Show approximate cost per category\n- **Graceful degradation:** Timeout handling for network databases\n- **Critical auto-fetch:** Aggressive mode pre-loads importance >= 9 items\n\n### 1.2.0\n- Initial hook modes (off, remind, light, full, aggressive)\n- Basic context injection\n",
        "plugins/worklog/hooks/session-stop.md": "---\nevent: Stop\npriority: 100\nmatch_files: [\"*\"]\n---\n\n# Session Stop Hook - Worklog Learning Capture\n\nAutomatically capture learnings and log work completion when a session ends using **AI compression** - extract semantic learnings from raw session activity.\n\n## AI Compression Pattern\n\nInspired by claude-mem's approach to knowledge extraction:\n\n| Raw Data | Compressed Output | Storage |\n|----------|-------------------|---------|\n| Full conversation transcript | 1-2 sentence summary | entries.outcome |\n| Debugging steps taken | Root cause + resolution | error_patterns |\n| Decisions discussed | Decision + rationale | knowledge_base |\n| Patterns observed | Pattern + when to apply | knowledge_base |\n| Current work state | Context for resumption | memories |\n\n**Why:** Raw transcripts waste tokens and storage. Semantic extraction preserves value, discards noise.\n\n## Behavior by Hook Mode\n\nRead configuration from `~/.gsc-plugins/worklog.local.md` frontmatter.\n\n### Configuration Check\n\n```bash\nHOOK_MODE=$(grep -A1 \"^hook_mode:\" ~/.gsc-plugins/worklog.local.md 2>/dev/null | tail -1 | tr -d ' ')\nPROFILE=$(grep -A1 \"^profile:\" ~/.gsc-plugins/worklog.local.md 2>/dev/null | tail -1 | tr -d ' ')\nDB_PATH=$(grep -A1 \"^db_path:\" ~/.gsc-plugins/worklog.local.md 2>/dev/null | tail -1 | tr -d ' ')\nSYSTEM_NAME=$(grep -A1 \"^system_name:\" ~/.gsc-plugins/worklog.local.md 2>/dev/null | tail -1 | tr -d ' ')\n\nDB_PATH=\"${DB_PATH/#\\~/$HOME}\"\nSYSTEM_NAME=\"${SYSTEM_NAME:-$(hostname)}\"\n```\n\n### Stop Behavior Modes\n\n| Mode | On Stop Behavior | Compression | Default For |\n|------|------------------|-------------|-------------|\n| `off` | Nothing | None | - |\n| `remind` | Remind if significant work | None | minimal |\n| `light` | Prompt with compressed summary | Basic | standard |\n| `full` | Auto-log compressed summary | Full | full |\n| `aggressive` | Auto-log + extract all learnings | Deep | full (shared) |\n\n## Determining \"Significant Work\"\n\nBefore any mode executes, assess session significance:\n\n**Indicators of significant work:**\n1. **TodoWrite activity**: Tasks created/completed during session\n2. **File modifications**: Write/Edit tool used on project files\n3. **Decisions made**: Architecture, implementation, or tool choices\n4. **Problems solved**: Debugging, troubleshooting, fixes applied\n5. **Session length**: Multiple exchanges (>5 user messages)\n\n**Quick heuristic:**\n```\nSIGNIFICANT = (todos_completed > 0) OR\n              (files_modified > 2) OR\n              (session_messages > 10) OR\n              (errors_resolved > 0)\n```\n\nIf not significant, modes `remind` and `light` output nothing.\n\n## Execution\n\n### Mode: off\n\nDo nothing.\n\n### Mode: remind\n\nIf significant work detected, output reminder:\n```\n<worklog-reminder>\nSession had significant activity. Consider capturing learnings:\n- Use `memory-store` skill to save reusable knowledge\n- Decisions and patterns persist across sessions\n</worklog-reminder>\n```\n\nIf trivial session, output nothing.\n\n### Mode: light\n\n**Step 1: Generate compressed summary**\n\nAnalyze session to produce:\n```yaml\nsummary:\n  title: \"One-line description of work done\"\n  type: \"development|debugging|research|configuration|documentation\"\n  outcome: \"Completed|Partial|Blocked\"\n  key_result: \"The main thing accomplished\"\n```\n\n**Step 2: Present for confirmation**\n\n```\n<worklog-prompt mode=\"light\">\n## Session Summary (Compressed)\n\n**Title:** {title}\n**Type:** {type}\n**Outcome:** {outcome}\n**Key Result:** {key_result}\n\nStore this to worklog? Reply:\n- \"yes\" to store as-is\n- \"yes, also learned: <insight>\" to add learning\n- \"no\" to skip\n</worklog-prompt>\n```\n\n**Step 3: If confirmed, store**\n\n```bash\nsqlite3 \"$DB_PATH\" \"INSERT INTO entries\n(agent, task_type, title, outcome, tags) VALUES\n('$SYSTEM_NAME', '{type}', '{title}', '{key_result}',\n'system:$SYSTEM_NAME,auto:light,session:$(date +%Y%m%d)');\" 2>/dev/null\n```\n\n### Mode: full\n\n**Step 1: Deep compression - extract structured data**\n\nAnalyze entire session to extract:\n\n```yaml\nsession:\n  # Entry for entries table\n  entry:\n    title: \"Concise title of work performed\"\n    type: \"development|debugging|research|configuration|documentation\"\n    details: \"2-3 sentence description of what was done\"\n    outcome: \"What was accomplished or current state\"\n    tags: [\"auto-generated\", \"relevant\", \"tags\"]\n\n  # Context for memories table (for session resumption)\n  context:\n    current_state: \"Where work stands now\"\n    next_steps: \"What should happen next\"\n    blockers: \"Any blockers identified\"\n    importance: 5-8  # Based on work significance\n```\n\n**Step 2: Auto-store (no confirmation needed)**\n\n```bash\n# Store entry\nsqlite3 \"$DB_PATH\" \"INSERT INTO entries\n(agent, task_type, title, details, outcome, tags) VALUES\n('$SYSTEM_NAME', '{type}', '{title}', '{details}', '{outcome}',\n'system:$SYSTEM_NAME,auto:full,session:$(date +%Y%m%d),{additional_tags}');\" 2>/dev/null\n\n# Store/update session context memory\nsqlite3 \"$DB_PATH\" \"INSERT OR REPLACE INTO memories\n(key, content, summary, memory_type, importance, source_agent, tags, status) VALUES\n('ctx_${SYSTEM_NAME}_$(date +%Y%m%d)_session',\n'{current_state}. Next: {next_steps}. {blockers}',\n'{title}',\n'context', {importance}, '$SYSTEM_NAME',\n'session,auto:full,{tags}', 'staging');\" 2>/dev/null\n```\n\n**Step 3: Output confirmation**\n\n```\n<worklog-logged mode=\"full\">\nSession logged:\n- Entry: {title}\n- Outcome: {outcome}\n- Context saved for resumption\n\nUse `memory-recall` to review stored context.\n</worklog-logged>\n```\n\n### Mode: aggressive\n\nEverything in `full` mode, PLUS deep extraction of all learning types.\n\n**Step 1: Extract ALL learnable content**\n\n```yaml\nextraction:\n  # Decisions made during session\n  decisions:\n    - title: \"Decision title\"\n      choice: \"What was decided\"\n      rationale: \"Why this choice\"\n      alternatives: \"What was considered\"\n      category: \"architecture|implementation|tooling|process\"\n\n  # Patterns discovered or applied\n  patterns:\n    - title: \"Pattern name\"\n      description: \"What the pattern is\"\n      when_to_use: \"Applicable situations\"\n      example: \"Brief example from session\"\n      category: \"design|code|workflow|debugging\"\n\n  # Errors debugged and resolved\n  errors:\n    - signature: \"Error type/message pattern\"\n      message: \"Actual error encountered\"\n      root_cause: \"What caused it\"\n      resolution: \"How it was fixed\"\n      prevention: \"How to avoid in future\"\n\n  # Gotchas and anti-patterns\n  gotchas:\n    - title: \"Gotcha description\"\n      wrong_approach: \"What doesn't work\"\n      right_approach: \"What to do instead\"\n      context: \"When this applies\"\n\n  # Commands/configurations that worked\n  commands:\n    - command: \"The command or config\"\n      purpose: \"What it does\"\n      context: \"When to use\"\n```\n\n**Step 2: Store each extraction type**\n\n```bash\n# Store decisions to knowledge_base\nfor decision in decisions:\n  sqlite3 \"$DB_PATH\" \"INSERT INTO knowledge_base\n  (category, title, content, tags, source_agent, system) VALUES\n  ('decisions', '{decision.title}',\n  'Decision: {decision.choice}\\n\\nRationale: {decision.rationale}\\n\\nAlternatives considered: {decision.alternatives}',\n  '{decision.category},auto:aggressive,decision', '$SYSTEM_NAME', '$SYSTEM_NAME');\" 2>/dev/null\n\n# Store patterns to knowledge_base\nfor pattern in patterns:\n  sqlite3 \"$DB_PATH\" \"INSERT INTO knowledge_base\n  (category, title, content, tags, source_agent, system) VALUES\n  ('patterns', '{pattern.title}',\n  '{pattern.description}\\n\\nWhen to use: {pattern.when_to_use}\\n\\nExample: {pattern.example}',\n  '{pattern.category},auto:aggressive,pattern', '$SYSTEM_NAME', '$SYSTEM_NAME');\" 2>/dev/null\n\n# Store errors to error_patterns\nfor error in errors:\n  sqlite3 \"$DB_PATH\" \"INSERT INTO error_patterns\n  (error_signature, error_message, root_cause, resolution, prevention, tags) VALUES\n  ('{error.signature}', '{error.message}', '{error.root_cause}',\n  '{error.resolution}', '{error.prevention}', 'auto:aggressive');\" 2>/dev/null\n\n# Store gotchas to knowledge_base\nfor gotcha in gotchas:\n  sqlite3 \"$DB_PATH\" \"INSERT INTO knowledge_base\n  (category, title, content, tags, source_agent, system) VALUES\n  ('gotchas', '{gotcha.title}',\n  'Wrong: {gotcha.wrong_approach}\\n\\nRight: {gotcha.right_approach}\\n\\nContext: {gotcha.context}',\n  'gotcha,anti-pattern,auto:aggressive', '$SYSTEM_NAME', '$SYSTEM_NAME');\" 2>/dev/null\n```\n\n**Step 3: Output detailed confirmation**\n\n```\n<worklog-logged mode=\"aggressive\">\nSession fully processed:\n\n**Entry:** {title}\n**Outcome:** {outcome}\n\n**Extracted & Stored:**\n| Type | Count | Examples |\n|------|-------|----------|\n| Decisions | {decisions.length} | {decisions[0].title if any} |\n| Patterns | {patterns.length} | {patterns[0].title if any} |\n| Errors | {errors.length} | {errors[0].signature if any} |\n| Gotchas | {gotchas.length} | {gotchas[0].title if any} |\n\n**Context:** Saved for session resumption\n\nKnowledge compounds across sessions. Query with `memory-recall`.\n</worklog-logged>\n```\n\n## Compression Quality Guidelines\n\n### What to Extract\n\n| Type | Extract If... | Skip If... |\n|------|---------------|------------|\n| **Decisions** | Explicit choice made with rationale | Obvious/trivial choice |\n| **Patterns** | Reusable across projects/sessions | One-time solution |\n| **Errors** | Debugging took >5 minutes | Typo/obvious fix |\n| **Gotchas** | Non-obvious, easy to forget | Well-documented elsewhere |\n| **Commands** | Complex or rarely used | Common/well-known |\n\n### Compression Ratios\n\nTarget compression:\n- **Session transcript**: 10,000+ tokens â†’ **Entry**: ~100 tokens\n- **Debugging session**: 5,000 tokens â†’ **Error pattern**: ~150 tokens\n- **Decision discussion**: 2,000 tokens â†’ **Decision record**: ~100 tokens\n\n### Avoiding Duplicates\n\nBefore storing to knowledge_base, check for existing similar entries:\n\n```bash\n# Check for similar title\nEXISTING=$(sqlite3 \"$DB_PATH\" \"SELECT id FROM knowledge_base\nWHERE title LIKE '%{similar_keywords}%' LIMIT 1;\" 2>/dev/null)\n\nif [ -n \"$EXISTING\" ]; then\n  # Update existing instead of creating duplicate\n  sqlite3 \"$DB_PATH\" \"UPDATE knowledge_base\n  SET content = content || '\\n\\n---\\nAdditional context: {new_content}',\n  updated_at = datetime('now')\n  WHERE id = $EXISTING;\" 2>/dev/null\nfi\n```\n\n## Error Handling\n\n**Database write fails:**\n```\n<worklog-warning>\nCould not log to worklog database.\n\n**Session summary (save manually):**\n- Title: {title}\n- Outcome: {outcome}\n- Key learnings: {learnings_summary}\n\nRun `/worklog-status` to check connectivity.\n</worklog-warning>\n```\n\n**Network timeout:**\nGracefully degrade to `remind` mode and output summary for manual saving.\n\n## Tagging Convention\n\nAll auto-logged entries include standard tags:\n\n| Tag | Meaning |\n|-----|---------|\n| `auto:light` | Logged by light mode |\n| `auto:full` | Logged by full mode |\n| `auto:aggressive` | Logged by aggressive mode |\n| `system:{hostname}` | Source system |\n| `session:{YYYYMMDD}` | Session date |\n| `type:{category}` | Content type |\n\nThis enables filtering: `SELECT * FROM entries WHERE tags LIKE '%auto:aggressive%'`\n\n## Backwards Compatibility\n\n- All existing hook_mode values work unchanged\n- Output format enhanced but structurally similar\n- Existing entries/knowledge_base queries unaffected\n- No changes required to user configuration\n\n## Notes\n\n- Hook analyzes conversation context to determine extractions\n- Compression uses LLM reasoning, not simple truncation\n- All auto-logged entries tagged for easy identification/filtering\n- Manual `memory-store` always available for more detail\n- Network failures gracefully degrade to remind mode\n- Duplicate detection prevents knowledge_base bloat\n\n## Version History\n\n### 1.3.0 (Current)\n- **AI compression:** Semantic extraction vs raw logging\n- **Deep extraction (aggressive):** Decisions, patterns, errors, gotchas\n- **Duplicate detection:** Check before inserting to knowledge_base\n- **Compression guidelines:** Clear rules for what to extract\n- **Tagging convention:** Standard tags for filtering\n\n### 1.2.0\n- Initial hook modes (off, remind, light, full, aggressive)\n- Basic session logging\n",
        "plugins/worklog/mcp/README.md": "# worklog-mcp\n\nMCP server providing programmatic access to the worklog database.\n\n## Overview\n\nThis MCP server complements the worklog plugin's skills and commands by providing direct tool access for automated workflows and agent-to-agent communication.\n\n## When to Use\n\n| Approach | Use Case |\n|----------|----------|\n| **Skills** (`memory-store`, `memory-recall`) | Human-guided workflows with context and validation |\n| **Commands** (`/worklog-*`) | Configuration and status |\n| **MCP Tools** | Programmatic access, automation, agent tasks |\n\n## Installation\n\n### Prerequisites\n\n- Python 3.11 or higher\n- The worklog plugin installed\n\n### Step 1: Install Python Dependencies\n\n```bash\n# Navigate to the MCP server directory\ncd ~/.claude/plugins/local-plugins/worklog/mcp  # or marketplace path\n\n# Install the package\npip install -e .\n\n# For development (includes test dependencies)\npip install -e \".[dev]\"\n```\n\n### Step 2: Verify Installation\n\n```bash\n# Test the server starts correctly\npython -m worklog_mcp --help\n```\n\n### Automatic Activation\n\nOnce the worklog plugin is installed, the MCP server is automatically configured via the plugin's `.mcp.json` file. Claude Code reads this configuration and makes the tools available as `mcp__worklog__<tool_name>`.\n\n## Tools\n\n### Query Tools\n| Tool | Description |\n|------|-------------|\n| `query_table` | Query any table with filtering, pagination |\n| `search_knowledge` | Full-text search across tables |\n| `recall_context` | Smart context retrieval for agent sessions |\n| `get_knowledge_entry` | Get KB entry by ID |\n| `get_memory` | Get memory by key |\n\n### Storage Tools\n| Tool | Description |\n|------|-------------|\n| `store_memory` | Store new memories |\n| `update_memory` | Update existing memories |\n| `log_entry` | Log work entries |\n| `store_knowledge` | Add to knowledge base |\n\n### Utility Tools\n| Tool | Description |\n|------|-------------|\n| `list_tables` | List tables with counts |\n| `get_recent_entries` | Recent work by agent |\n\n## Configuration\n\nDatabase path auto-detected by hostname, or set via environment:\n\n```bash\nexport WORKLOG_DB=/path/to/worklog.db\n```\n\n## Development\n\n```bash\n# Run server directly\npython -m worklog_mcp\n\n# Test with MCP Inspector\nmcp-inspector python -m worklog_mcp\n\n# Run tests\npytest -v\n```\n\n## Integration with Skills\n\nSkills can optionally use MCP tools instead of raw SQL:\n\n```markdown\n# Instead of direct SQL in skills:\nsqlite3 $WORKLOG_DB \"INSERT INTO memories...\"\n\n# Skills could call:\nmcp__worklog__store_memory(key=\"...\", content=\"...\")\n```\n\nThis provides validation and consistent behavior across all access methods.\n",
        "plugins/worklog/skills/curate/skill.md": "---\nname: curate\ndescription: On-demand knowledge base curation - normalize tags, find duplicates, manage topics, promote memories\n---\n\n# Knowledge Base Curation Skill\n\nOn-demand curation of the worklog knowledge base. Use this skill to maintain knowledge quality and organization.\n\n## Prerequisites\n\n- Worklog plugin configured with PostgreSQL backend\n- Curation tables created (INFA-290 migration applied)\n- Curation MCP tools available (INFA-291)\n\n## Subcommands\n\n| Command | Purpose |\n|---------|---------|\n| `/curate topic [name]` | Focus curation on specific topic |\n| `/curate duplicates` | Scan and flag potential duplicates |\n| `/curate orphans` | Find unlinked entries |\n| `/curate taxonomy` | Review and normalize tags |\n| `/curate promote` | Evaluate staging memories for promotion |\n| `/curate status` | Show curation system status |\n\n---\n\n## /curate topic [name]\n\nCreate or update a topic in the topic index, linking relevant entries.\n\n### Workflow\n\n1. **Check if topic exists**\n   ```\n   Use MCP: query_table(table=\"topic_index\", filter_column=\"topic_name\", filter_value=\"[name]\")\n   ```\n\n2. **If new topic - create it**\n   ```\n   Use MCP: create_topic(topic_name=\"[name]\", summary=\"[brief description]\", key_terms=\"term1,term2,term3\")\n   ```\n\n3. **Find relevant entries**\n   Search across memories and knowledge_base for entries related to this topic:\n   ```\n   Use MCP: search_knowledge(query=\"[name]\", tables=\"memories,knowledge_base,entries\", limit=50)\n   ```\n\n4. **Present candidates to user**\n   ```markdown\n   ## Topic: [name]\n\n   ### Candidates for inclusion:\n\n   | # | Source | Title | Relevance |\n   |---|--------|-------|-----------|\n   | 1 | memories | [key] | HIGH/MEDIUM/LOW |\n   | 2 | knowledge_base | [title] | HIGH/MEDIUM/LOW |\n   ...\n\n   **Select entries to add (comma-separated numbers, or 'all'):**\n   ```\n\n5. **Add selected entries**\n   For each selected entry:\n   ```\n   Use MCP: add_topic_entry(topic_name=\"[name]\", entry_table=\"[table]\", entry_id=[id], relevance_score=[0.0-1.0])\n   ```\n\n6. **Update topic summary**\n   Generate summary based on linked entries:\n   ```\n   Use MCP: update_topic_summary(topic_name=\"[name]\", summary=\"[TLDR]\", full_summary=\"[detailed]\", key_terms=\"[terms]\")\n   ```\n\n7. **Log curation run**\n   ```\n   Use MCP: log_curation_run(operation=\"topic_indexing\", agent=\"claude\", stats='{\"topic\":\"[name]\",\"entries_added\":N}')\n   ```\n\n---\n\n## /curate duplicates\n\nScan for potential duplicate entries across the knowledge base.\n\n### Workflow\n\n1. **Check pending duplicates**\n   ```\n   Use MCP: query_table(table=\"duplicate_candidates\", filter_column=\"status\", filter_value=\"pending\", limit=20)\n   ```\n\n2. **If pending duplicates exist, present for review**\n   ```markdown\n   ## Pending Duplicate Candidates\n\n   ### Pair #1 (similarity: 0.85)\n   **Entry 1:** [table].[id] - [title/key]\n   > [preview of content]\n\n   **Entry 2:** [table].[id] - [title/key]\n   > [preview of content]\n\n   **Action:** [merge / dismiss / skip]\n   ```\n\n3. **For new scan - detect duplicates**\n   Search for entries with similar titles or content:\n   ```\n   Use MCP: search_knowledge(query=\"[common terms]\", tables=\"memories,knowledge_base\", limit=100)\n   ```\n\n   Compare entries using:\n   - Title similarity (exact matches, fuzzy matches)\n   - Content overlap (shared phrases, concepts)\n   - Tag similarity\n\n4. **Record new candidates**\n   For each potential duplicate pair found:\n   - Check if pair already exists in duplicate_candidates\n   - If new, would need direct SQL to insert (future: add_duplicate_candidate MCP tool)\n\n5. **Process user decisions**\n   - **merge**: Combine entries, archive duplicate\n   - **dismiss**: Mark as not-duplicate, won't show again\n   - **skip**: Leave for later review\n\n6. **Log curation run**\n   ```\n   Use MCP: log_curation_run(operation=\"duplicate_detection\", agent=\"claude\", stats='{\"scanned\":N,\"found\":M,\"resolved\":K}')\n   ```\n\n---\n\n## /curate orphans\n\nFind entries with no relationships or topic associations.\n\n### Workflow\n\n1. **Find orphan memories**\n   ```sql\n   -- Memories not in any topic and with no relationships\n   SELECT m.id, m.key, m.summary\n   FROM memories m\n   WHERE NOT EXISTS (\n     SELECT 1 FROM topic_entries te\n     WHERE te.entry_table = 'memories' AND te.entry_id = m.id\n   )\n   AND NOT EXISTS (\n     SELECT 1 FROM relationships r\n     WHERE (r.source_table = 'memories' AND r.source_id = m.id)\n        OR (r.target_table = 'memories' AND r.target_id = m.id)\n   )\n   AND m.importance >= 5\n   ORDER BY m.importance DESC\n   LIMIT 20;\n   ```\n\n2. **Find orphan knowledge entries**\n   ```sql\n   SELECT kb.id, kb.title, kb.category\n   FROM knowledge_base kb\n   WHERE NOT EXISTS (\n     SELECT 1 FROM topic_entries te\n     WHERE te.entry_table = 'knowledge_base' AND te.entry_id = kb.id\n   )\n   AND NOT EXISTS (\n     SELECT 1 FROM relationships r\n     WHERE (r.source_table = 'knowledge_base' AND r.source_id = kb.id)\n        OR (r.target_table = 'knowledge_base' AND r.target_id = kb.id)\n   )\n   ORDER BY kb.updated_at DESC\n   LIMIT 20;\n   ```\n\n3. **Present orphans for action**\n   ```markdown\n   ## Orphan Entries\n\n   These entries have no topic associations or relationships.\n\n   ### High-Value Memories (importance >= 7)\n   | ID | Key | Summary | Action |\n   |----|-----|---------|--------|\n   | 42 | ctx_... | [summary] | [link / archive / skip] |\n\n   ### Knowledge Base Entries\n   | ID | Title | Category | Action |\n   |----|-------|----------|--------|\n   | 15 | [title] | development | [link / archive / skip] |\n\n   **Actions:**\n   - **link**: Suggest topics/relationships to add\n   - **archive**: Mark as archived (low value)\n   - **skip**: Leave for later\n   ```\n\n4. **Process user decisions**\n   - **link**: Prompt for topic name or related entry, then create relationship\n   - **archive**: Update memory status to 'archived'\n   - **skip**: Continue to next\n\n5. **Log curation run**\n   ```\n   Use MCP: log_curation_run(operation=\"orphan_detection\", agent=\"claude\", stats='{\"orphans_found\":N,\"linked\":M,\"archived\":K}')\n   ```\n\n---\n\n## /curate taxonomy\n\nReview and normalize tag usage across the knowledge base.\n\n### Workflow\n\n1. **Get current tag taxonomy**\n   ```\n   Use MCP: query_table(table=\"tag_taxonomy\", columns=\"canonical_tag,aliases,category,usage_count\", order_by=\"usage_count DESC\", limit=50)\n   ```\n\n2. **Find tags not in taxonomy**\n   Scan memories and knowledge_base for tags not in tag_taxonomy:\n   ```sql\n   -- Get all unique tags from memories\n   SELECT DISTINCT unnest(string_to_array(tags, ',')) as tag\n   FROM memories WHERE tags IS NOT NULL AND tags != ''\n   EXCEPT\n   SELECT canonical_tag FROM tag_taxonomy\n   EXCEPT\n   SELECT unnest(aliases) FROM tag_taxonomy;\n   ```\n\n3. **Present unknown tags**\n   ```markdown\n   ## Tag Taxonomy Review\n\n   ### Current Taxonomy (top 10 by usage)\n   | Tag | Category | Aliases | Usage |\n   |-----|----------|---------|-------|\n   | infrastructure | system | infra, ops | 45 |\n\n   ### Unknown Tags Found\n   | Tag | Occurrences | Action |\n   |-----|-------------|--------|\n   | k8s | 12 | [add / alias / ignore] |\n   | kubernetes | 8 | [add / alias / ignore] |\n\n   **Suggestion:** 'k8s' appears to be an alias for 'kubernetes'\n\n   **Actions:**\n   - **add**: Add as new canonical tag\n   - **alias [tag]**: Add as alias to existing tag\n   - **ignore**: Skip this tag\n   ```\n\n4. **Process user decisions**\n   - **add**:\n     ```\n     Use MCP: add_tag_taxonomy(canonical_tag=\"[tag]\", category=\"[category]\")\n     ```\n   - **alias [canonical]**:\n     ```\n     Update tag_taxonomy to add alias (future: update_tag_taxonomy MCP tool)\n     ```\n   - **ignore**: Skip\n\n5. **Normalize existing entries**\n   For each entry using non-canonical tags:\n   ```\n   Use MCP: normalize_tags(tags=\"[current_tags]\")\n   ```\n   Then update the entry with normalized tags.\n\n6. **Log curation run**\n   ```\n   Use MCP: log_curation_run(operation=\"tag_normalization\", agent=\"claude\", stats='{\"tags_reviewed\":N,\"added\":M,\"aliased\":K}')\n   ```\n\n---\n\n## /curate promote\n\nEvaluate staging memories for promotion to permanent status.\n\n### Workflow\n\n1. **Find promotion candidates**\n   Memories with:\n   - status = 'staging' (not yet promoted)\n   - importance >= 6\n   - age > 1 day (not too recent)\n\n   ```sql\n   SELECT id, key, summary, content, importance, memory_type, tags, created_at\n   FROM memories\n   WHERE status = 'staging'\n     AND importance >= 6\n     AND created_at < NOW() - INTERVAL '1 day'\n   ORDER BY importance DESC, created_at ASC\n   LIMIT 10;\n   ```\n\n2. **Present candidates for review**\n   ```markdown\n   ## Promotion Candidates\n\n   ### Memory #1: [key]\n   - **Type:** fact\n   - **Importance:** 7\n   - **Created:** 2025-12-28\n   - **Tags:** infrastructure, deployment\n\n   > [content preview]\n\n   **Decision:** [promote / archive / boost / skip]\n   - **promote**: Move to 'promoted' status\n   - **archive**: Mark as archived (not valuable)\n   - **boost**: Increase importance and promote\n   - **skip**: Leave for later\n   ```\n\n3. **Process user decisions**\n   For each decision:\n   - Record in promotion_history\n   - Update memory status\n\n   ```\n   Use MCP: update_memory(key=\"[key]\", status=\"promoted\", importance=[new_importance])\n   ```\n\n   Log to promotion_history (direct SQL):\n   ```sql\n   INSERT INTO promotion_history (memory_id, from_status, to_status, reason, promoted_by)\n   VALUES ([id], 'staging', 'promoted', '[reason]', 'claude');\n   ```\n\n4. **Log curation run**\n   ```\n   Use MCP: log_curation_run(operation=\"memory_promotion\", agent=\"claude\", stats='{\"reviewed\":N,\"promoted\":M,\"archived\":K}')\n   ```\n\n---\n\n## /curate status\n\nShow current state of the curation system.\n\n### Workflow\n\n1. **Gather statistics**\n   ```\n   Use MCP: list_tables()\n   ```\n\n   Plus specific counts:\n   - Topics: `query_table(table=\"topic_index\", columns=\"count(*)\")`\n   - Relationships: `query_table(table=\"relationships\", columns=\"count(*)\")`\n   - Pending duplicates: `query_table(table=\"duplicate_candidates\", filter_column=\"status\", filter_value=\"pending\")`\n   - Tag taxonomy size: `query_table(table=\"tag_taxonomy\", columns=\"count(*)\")`\n\n2. **Get recent curation history**\n   ```\n   Use MCP: query_table(table=\"curation_history\", order_by=\"run_at DESC\", limit=5)\n   ```\n\n3. **Present status report**\n   ```markdown\n   ## Curation System Status\n\n   ### Tables\n   | Table | Count |\n   |-------|-------|\n   | topic_index | 12 |\n   | topic_entries | 87 |\n   | relationships | 45 |\n   | duplicate_candidates | 3 pending |\n   | tag_taxonomy | 28 |\n   | promotion_history | 15 |\n   | curation_history | 42 |\n\n   ### Recent Curation Runs\n   | When | Operation | Agent | Stats |\n   |------|-----------|-------|-------|\n   | 2h ago | topic_indexing | claude | 5 entries added |\n   | 1d ago | tag_normalization | claude | 3 tags added |\n\n   ### Recommendations\n   - 3 pending duplicates need review (`/curate duplicates`)\n   - 15 orphan entries found (`/curate orphans`)\n   - 8 unknown tags detected (`/curate taxonomy`)\n   ```\n\n---\n\n## Summary Report Format\n\nAfter any curation operation, provide a summary:\n\n```markdown\n## Curation Complete\n\n### Operation: [operation_type]\n- **Duration:** [X seconds]\n- **Items processed:** N\n- **Changes made:** M\n\n### Actions Taken\n- [List of specific changes]\n\n### Recommendations\n- [Follow-up suggestions]\n\n---\n*Logged to curation_history*\n```\n\n---\n\n## MCP Tools Reference\n\n| Tool | Purpose |\n|------|---------|\n| `normalize_tag(tag)` | Normalize single tag to canonical form |\n| `normalize_tags(tags)` | Normalize comma-separated tags |\n| `add_tag_taxonomy(canonical_tag, aliases, category, description)` | Add new canonical tag |\n| `add_relationship(source_table, source_id, target_table, target_id, relationship_type, confidence)` | Create entry relationship |\n| `get_relationships(entry_table, entry_id, relationship_type, direction)` | Query relationships |\n| `create_topic(topic_name, summary, key_terms)` | Create new topic |\n| `add_topic_entry(topic_name, entry_table, entry_id, relevance_score)` | Link entry to topic |\n| `get_topic_entries(topic_name, entry_table, min_relevance, limit)` | Get entries for topic |\n| `update_topic_summary(topic_name, summary, full_summary, key_terms)` | Update topic metadata |\n| `log_curation_run(operation, agent, stats, duration_seconds, success, error_message)` | Log curation operation |\n\n---\n\n## Related\n\n- **INFA-290**: Schema migrations (tables created)\n- **INFA-291**: MCP tools (tool implementations)\n- **INFA-293**: Curator agent (automated curation)\n- **Skill**: `/memory-recall` - Query knowledge base\n- **Skill**: `/memory-store` - Store new memories\n",
        "plugins/worklog/skills/memory-recall/skill.md": "---\nname: memory-recall\ndescription: Query the worklog database for context, knowledge, errors, and history\n---\n\n# Memory Recall Skill\n\nQuery the worklog database to retrieve context, knowledge, and history.\n\n## Prerequisites\n\n- Worklog plugin configured (run `/worklog-init` first)\n- Database backend configured:\n  - **SQLite (default)**: No additional setup needed\n  - **PostgreSQL (optional)**: Set `DATABASE_URL` or `PGHOST` environment variables\n\n## When to Recall\n\n| Scenario | Query Type |\n|----------|------------|\n| Starting a task | Boot queries for relevant context |\n| Debugging an error | Search error_patterns |\n| Making a decision | Check knowledge_base for precedents |\n| Continuing previous work | Query entries and memories |\n| Learning about a topic | Search across all tables |\n\n## Detect Your Backend\n\n```bash\n# Check which backend is configured\nif [ -n \"$DATABASE_URL\" ] || [ -n \"$PGHOST\" ]; then\n    echo \"Backend: PostgreSQL\"\nelse\n    echo \"Backend: SQLite\"\nfi\n```\n\n---\n\n## SQLite Queries (Default)\n\nDefault database path: `~/.claude/worklog/worklog.db`\n\n### Boot Sequence\n\n```bash\nDB=\"${WORKLOG_DB_PATH:-$HOME/.claude/worklog/worklog.db}\"\n\n# Protocols\nsqlite3 \"$DB\" \"SELECT title FROM knowledge_base WHERE is_protocol=1 ORDER BY updated_at DESC LIMIT 5;\"\n\n# Recent work (24h)\nsqlite3 \"$DB\" \"SELECT agent, title FROM entries WHERE timestamp > datetime('now', '-1 day') ORDER BY timestamp DESC LIMIT 5;\"\n\n# Items flagged for me\nsqlite3 \"$DB\" \"SELECT title FROM entries WHERE tags LIKE '%for:claude%' AND timestamp > datetime('now', '-7 days');\"\n```\n\n### Search Knowledge Base\n\n```bash\n# By topic\nsqlite3 \"$DB\" \"SELECT id, title FROM knowledge_base WHERE title LIKE '%topic%' OR content LIKE '%topic%' ORDER BY updated_at DESC LIMIT 10;\"\n\n# By category\nsqlite3 \"$DB\" \"SELECT title, content FROM knowledge_base WHERE category = 'development' ORDER BY updated_at DESC LIMIT 10;\"\n\n# Protocols only\nsqlite3 \"$DB\" \"SELECT title, content FROM knowledge_base WHERE is_protocol = 1 ORDER BY updated_at DESC;\"\n```\n\n### Search Work History\n\n```bash\n# By agent\nsqlite3 \"$DB\" \"SELECT timestamp, title, outcome FROM entries WHERE agent = 'claude' ORDER BY timestamp DESC LIMIT 20;\"\n\n# By task type\nsqlite3 \"$DB\" \"SELECT timestamp, agent, title FROM entries WHERE task_type = 'debugging' ORDER BY timestamp DESC LIMIT 10;\"\n\n# Recent across all agents\nsqlite3 \"$DB\" \"SELECT timestamp, agent, title FROM entries ORDER BY timestamp DESC LIMIT 20;\"\n```\n\n### Search Error Patterns\n\n```bash\n# By error text\nsqlite3 \"$DB\" \"SELECT error_signature, resolution FROM error_patterns WHERE error_message LIKE '%error text%' LIMIT 5;\"\n\n# By platform\nsqlite3 \"$DB\" \"SELECT error_signature, resolution FROM error_patterns WHERE platform = 'macos' ORDER BY id DESC LIMIT 10;\"\n```\n\n### Query Memories\n\n```bash\n# By key\nsqlite3 \"$DB\" \"SELECT content FROM memories WHERE key = 'ctx_agent_date_slug';\"\n\n# High importance\nsqlite3 \"$DB\" \"SELECT key, summary FROM memories WHERE importance >= 7 ORDER BY importance DESC LIMIT 10;\"\n\n# Active memories\nsqlite3 \"$DB\" \"SELECT key, summary FROM memories WHERE status != 'archived' ORDER BY importance DESC LIMIT 10;\"\n```\n\n---\n\n## PostgreSQL Queries (Optional)\n\nFor multi-system setups with shared database.\n\n### Boot Sequence\n\n```bash\n# Protocols\npsql -t -c \"SELECT title FROM knowledge_base WHERE is_protocol=true ORDER BY updated_at DESC LIMIT 5;\"\n\n# Recent work (24h)\npsql -t -c \"SELECT agent, title FROM entries WHERE timestamp > NOW() - INTERVAL '1 day' ORDER BY timestamp DESC LIMIT 5;\"\n\n# Items flagged for me\npsql -t -c \"SELECT title FROM entries WHERE tags LIKE '%for:claude%' AND timestamp > NOW() - INTERVAL '7 days';\"\n```\n\n### Search Knowledge Base\n\n```bash\n# By topic (ILIKE for case-insensitive)\npsql -t -c \"SELECT id, title FROM knowledge_base WHERE title ILIKE '%topic%' OR content ILIKE '%topic%' ORDER BY updated_at DESC LIMIT 10;\"\n\n# By category\npsql -t -c \"SELECT title, content FROM knowledge_base WHERE category = 'development' ORDER BY updated_at DESC LIMIT 10;\"\n\n# Protocols only\npsql -t -c \"SELECT title, content FROM knowledge_base WHERE is_protocol = true ORDER BY updated_at DESC;\"\n```\n\n### Search Work History\n\n```bash\n# By agent\npsql -t -c \"SELECT timestamp, title, outcome FROM entries WHERE agent = 'claude' ORDER BY timestamp DESC LIMIT 20;\"\n\n# By task type\npsql -t -c \"SELECT timestamp, agent, title FROM entries WHERE task_type = 'debugging' ORDER BY timestamp DESC LIMIT 10;\"\n\n# Recent across all agents\npsql -t -c \"SELECT timestamp, agent, title FROM entries ORDER BY timestamp DESC LIMIT 20;\"\n```\n\n### Search Error Patterns\n\n```bash\n# By error text\npsql -t -c \"SELECT error_signature, resolution FROM error_patterns WHERE error_message ILIKE '%error text%' LIMIT 5;\"\n\n# By platform\npsql -t -c \"SELECT error_signature, resolution FROM error_patterns WHERE platform = 'macos' ORDER BY id DESC LIMIT 10;\"\n```\n\n### Query Memories\n\n```bash\n# By key\npsql -t -c \"SELECT content FROM memories WHERE key = 'ctx_agent_date_slug';\"\n\n# High importance\npsql -t -c \"SELECT key, summary FROM memories WHERE importance >= 7 ORDER BY importance DESC LIMIT 10;\"\n\n# Active memories\npsql -t -c \"SELECT key, summary FROM memories WHERE status != 'archived' ORDER BY importance DESC LIMIT 10;\"\n```\n\n---\n\n## MCP Tools (Backend-Agnostic)\n\nThe MCP server automatically uses the correct backend:\n\n```python\n# Search across tables\nsearch_knowledge(query=\"topic\", tables=\"knowledge_base,entries\")\n\n# Get context for a task\nrecall_context(topic=\"docker deployment\", min_importance=5)\n\n# Query specific table\nquery_table(table=\"entries\", where=\"agent='claude'\", limit=10)\n\n# Get recent entries\nget_recent_entries(days=7, limit=20)\n```\n\n---\n\n## SQL Syntax Reference\n\n| Feature | SQLite | PostgreSQL |\n|---------|--------|------------|\n| Case-insensitive | `LIKE` (default) | `ILIKE` |\n| Days ago | `datetime('now', '-7 days')` | `NOW() - INTERVAL '7 days'` |\n| Boolean | `1` / `0` | `true` / `false` |\n| Last insert ID | `last_insert_rowid()` | `RETURNING id` |\n\n## Cross-Table Search\n\n### SQLite\n```bash\nsqlite3 \"$DB\" \"\nSELECT 'knowledge' as source, title, substr(content, 1, 100) as preview\nFROM knowledge_base WHERE content LIKE '%term%'\nUNION ALL\nSELECT 'entry' as source, title, outcome as preview\nFROM entries WHERE details LIKE '%term%'\nLIMIT 20;\"\n```\n\n### PostgreSQL\n```bash\npsql -t -c \"\nSELECT 'knowledge' as source, title, substring(content, 1, 100) as preview\nFROM knowledge_base WHERE content ILIKE '%term%'\nUNION ALL\nSELECT 'entry' as source, title, outcome as preview\nFROM entries WHERE details ILIKE '%term%'\nLIMIT 20;\"\n```\n\n## Output Formatting\n\nWhen presenting recalled information:\n\n```\n## Prior Knowledge Found\n\n### From Knowledge Base\n**{title}** (Category: {category})\n{content_excerpt}\n\n### From Work History\n- {timestamp}: {title} â†’ {outcome}\n\n### Relevant Error Patterns\n**{error_signature}**\nResolution: {resolution}\n```\n",
        "plugins/worklog/skills/memory-store/skill.md": "---\nname: memory-store\ndescription: Store knowledge, entries, errors, and context in the worklog database\n---\n\n# Memory Store Skill\n\nStore information in the worklog database for cross-session persistence.\n\n## Prerequisites\n\n- Worklog plugin configured (run `/worklog-init` first)\n- Database backend configured:\n  - **SQLite (default)**: No additional setup needed\n  - **PostgreSQL (optional)**: Set `DATABASE_URL` or `PGHOST` environment variables\n\n## What to Store\n\n### DO Store\n\n| Type | Table | When |\n|------|-------|------|\n| Reusable learnings | `knowledge_base` | Patterns, gotchas, anti-patterns |\n| Work completion | `entries` | After significant tasks |\n| Error resolutions | `error_patterns` | When you solve a tricky error |\n| Working context | `memories` | Session state, decisions in progress |\n\n### DO NOT Store\n\n| Type | Why Not | Alternative |\n|------|---------|-------------|\n| In-progress tasks | Transient | Use TodoWrite |\n| Obvious code behavior | Documented in code | None needed |\n| Already in files | Redundant | Reference the file |\n| Trivial changes | No reuse value | None needed |\n\n## Detect Your Backend\n\n```bash\nif [ -n \"$DATABASE_URL\" ] || [ -n \"$PGHOST\" ]; then\n    echo \"Backend: PostgreSQL (use psql)\"\nelse\n    echo \"Backend: SQLite (use sqlite3)\"\nfi\n```\n\n---\n\n## SQLite Store Patterns (Default)\n\nDefault database path: `~/.claude/worklog/worklog.db`\n\n### Knowledge Base Entry\n\n```bash\nDB=\"${WORKLOG_DB_PATH:-$HOME/.claude/worklog/worklog.db}\"\n\nsqlite3 \"$DB\" \"INSERT INTO knowledge_base\n(category, title, content, tags, source_agent, system) VALUES (\n'development',\n'Title of the knowledge',\n'Content with problem, solution, examples',\n'system:shared,agent:claude,topic:example',\n'claude',\n'$(hostname)'\n);\"\n```\n\n### Work Entry\n\n```bash\nsqlite3 \"$DB\" \"INSERT INTO entries\n(agent, task_type, title, details, decision_rationale, outcome, tags) VALUES (\n'claude',\n'debugging',\n'Fixed authentication bug',\n'User sessions were expiring prematurely',\n'Root cause was timezone mismatch',\n'Sessions now persist correctly',\n'system:$(hostname),agent:claude,topic:auth'\n);\"\n```\n\n### Memory\n\n```bash\nsqlite3 \"$DB\" \"INSERT INTO memories\n(key, content, summary, memory_type, importance, source_agent, tags) VALUES (\n'ctx_claude_20251222_project_context',\n'Detailed content here',\n'Brief summary',\n'context',\n7,\n'claude',\n'system:$(hostname),agent:claude'\n);\"\n```\n\n### Error Pattern\n\n```bash\nsqlite3 \"$DB\" \"INSERT INTO error_patterns\n(error_signature, error_message, platform, language, root_cause, resolution, tags) VALUES (\n'ECONNREFUSED',\n'connect ECONNREFUSED 127.0.0.1:5432',\n'all',\n'all',\n'PostgreSQL not running',\n'Start PostgreSQL: brew services start postgresql',\n'topic:postgresql,topic:connection'\n);\"\n```\n\n---\n\n## PostgreSQL Store Patterns (Optional)\n\nFor multi-system setups with shared database.\n\n### Knowledge Base Entry\n\n```bash\npsql -c \"INSERT INTO knowledge_base\n(category, title, content, tags, source_agent, system) VALUES (\n'development',\n'Title of the knowledge',\n'Content with problem, solution, examples',\n'system:shared,agent:claude,topic:example',\n'claude',\n'$(hostname)'\n);\"\n```\n\n### Work Entry\n\n```bash\npsql -c \"INSERT INTO entries\n(agent, task_type, title, details, decision_rationale, outcome, tags) VALUES (\n'claude',\n'debugging',\n'Fixed authentication bug',\n'User sessions were expiring prematurely',\n'Root cause was timezone mismatch',\n'Sessions now persist correctly',\n'system:$(hostname),agent:claude,topic:auth'\n);\"\n```\n\n### Memory\n\n```bash\npsql -c \"INSERT INTO memories\n(key, content, summary, memory_type, importance, source_agent, tags) VALUES (\n'ctx_claude_20251222_project_context',\n'Detailed content here',\n'Brief summary',\n'context',\n7,\n'claude',\n'system:$(hostname),agent:claude'\n);\"\n```\n\n### Error Pattern\n\n```bash\npsql -c \"INSERT INTO error_patterns\n(error_signature, error_message, platform, language, root_cause, resolution, tags) VALUES (\n'ECONNREFUSED',\n'connect ECONNREFUSED 127.0.0.1:5432',\n'all',\n'all',\n'PostgreSQL not running',\n'Start PostgreSQL: brew services start postgresql',\n'topic:postgresql,topic:connection'\n);\"\n```\n\n---\n\n## MCP Tools (Backend-Agnostic)\n\nThe MCP server automatically uses the correct backend:\n\n```python\n# Store a memory\nstore_memory(\n    key=\"ctx_claude_20251222_project\",\n    content=\"Detailed content\",\n    summary=\"Brief summary\",\n    memory_type=\"context\",\n    importance=7,\n    tags=\"system:shared,agent:claude\"\n)\n\n# Log work entry\nlog_entry(\n    title=\"Fixed authentication bug\",\n    task_type=\"debugging\",\n    details=\"User sessions were expiring prematurely\",\n    outcome=\"Sessions now persist correctly\",\n    tags=\"system:shared,agent:claude,topic:auth\"\n)\n\n# Store knowledge\nstore_knowledge(\n    category=\"development\",\n    title=\"React useEffect cleanup\",\n    content=\"Always return cleanup function...\",\n    tags=\"topic:react,topic:hooks\"\n)\n```\n\n---\n\n## Categories & Types\n\n**Knowledge Base Categories:**\n`system-administration`, `development`, `infrastructure`, `decisions`, `projects`, `protocols`\n\n**Task Types:**\n`configuration`, `deployment`, `debugging`, `documentation`, `research`, `maintenance`, `handoff`\n\n**Memory Types:**\n`fact`, `entity`, `preference`, `context`\n\n**Platforms:**\n`linux`, `macos`, `docker`, `nas`, `all`\n\n**Languages:**\n`python`, `typescript`, `bash`, `go`, `rust`, `all`\n\n---\n\n## Tagging Convention\n\nAlways include structured tags:\n\n```\nsystem:{system_name},agent:{agent_name},topic:{topic1},topic:{topic2}\n```\n\nExamples:\n- `system:my-laptop,agent:claude,topic:docker,topic:networking`\n- `system:shared,agent:claude,type:protocol,topic:sqlite`\n\n---\n\n## Content Format for Knowledge\n\n```markdown\n**Problem:** What was the issue\n\n**Solution:** How to solve it\n\n**Commands:**\n```bash\nexample commands\n```\n\n**Notes:** Gotchas, warnings\n```\n\n---\n\n## SQL Syntax Reference\n\n| Feature | SQLite | PostgreSQL |\n|---------|--------|------------|\n| Boolean | `1` / `0` | `true` / `false` |\n| Auto-increment | `INTEGER PRIMARY KEY` | `SERIAL` |\n| Current time | `CURRENT_TIMESTAMP` | `CURRENT_TIMESTAMP` |\n\n---\n\n## Complete Example\n\n### SQLite\n```bash\nDB=\"${WORKLOG_DB_PATH:-$HOME/.claude/worklog/worklog.db}\"\n\nsqlite3 \"$DB\" \"INSERT INTO knowledge_base\n(category, title, content, tags, source_agent, system, is_protocol) VALUES (\n'development',\n'React useEffect cleanup pattern',\n'**Problem:** Memory leaks from uncleared intervals\n\n**Solution:** Return cleanup function from useEffect\n\n**Code:**\n\\`\\`\\`typescript\nuseEffect(() => {\n  const id = setInterval(tick, 1000);\n  return () => clearInterval(id);\n}, []);\n\\`\\`\\`\n\n**Notes:** Also applies to event listeners, subscriptions',\n'system:shared,agent:claude,topic:react,topic:hooks,type:pattern',\n'claude',\n'$(hostname)',\n0\n);\"\n```\n\n### PostgreSQL\n```bash\npsql -c \"INSERT INTO knowledge_base\n(category, title, content, tags, source_agent, system, is_protocol) VALUES (\n'development',\n'React useEffect cleanup pattern',\n'**Problem:** Memory leaks from uncleared intervals\n\n**Solution:** Return cleanup function from useEffect\n\n**Code:**\n\\`\\`\\`typescript\nuseEffect(() => {\n  const id = setInterval(tick, 1000);\n  return () => clearInterval(id);\n}, []);\n\\`\\`\\`\n\n**Notes:** Also applies to event listeners, subscriptions',\n'system:shared,agent:claude,topic:react,topic:hooks,type:pattern',\n'claude',\n'$(hostname)',\nfalse\n);\"\n```\n",
        "plugins/worklog/skills/memory-sync/skill.md": "---\nname: memory-sync\ndescription: Reconcile worklog database with documentation - promotes learnings to docs with proper frontmatter and validates after sync\n---\n\n# Memory Sync Skill\n\nSynchronize worklog database entries with local documentation. Promotes important learnings to permanent docs with proper frontmatter, and validates the results.\n\n## Prerequisites\n\n- Worklog plugin configured (`$WORKLOG_DB` set)\n- Optional: Docs plugin for enhanced integration\n\n## Configuration\n\n```bash\n# Required\nWORKLOG_DB=\"${WORKLOG_DB:-}\"\n\n# Docs integration (auto-detected if docs plugin installed)\nKNOWLEDGE_BASE=\"${KNOWLEDGE_BASE:-~/.claude/knowledge}\"\nDOCS_ROOT=\"${DOCS_ROOT:-}\"  # If set, enables full docs integration\n\n# Optional\nDOCS_VALIDATOR=\"${DOCS_VALIDATOR:-}\"  # Path to docs-validator if available\n```\n\n### Integration Modes\n\n| Mode | When | Behavior |\n|------|------|----------|\n| **Standalone** | No docs plugin | Promotes to `$KNOWLEDGE_BASE` with basic formatting |\n| **Docs-aware** | `$DOCS_ROOT` set | Full frontmatter, validates after sync, respects docs structure |\n\n---\n\n## When to Use\n\n| Trigger | Action |\n|---------|--------|\n| Weekly maintenance | Full sync review |\n| After major project | Sync project learnings |\n| Before context loss | Ensure learnings captured |\n| Monthly cleanup | Archive old entries |\n\n---\n\n## Workflow\n\n### Step 1: Detect Docs Integration\n\n```bash\n# Check if docs plugin is available\nif [ -n \"$DOCS_ROOT\" ] && [ -d \"$DOCS_ROOT\" ]; then\n  DOCS_INTEGRATION=true\n  echo \"Docs integration enabled: $DOCS_ROOT\"\nelse\n  DOCS_INTEGRATION=false\n  echo \"Standalone mode: promoting to $KNOWLEDGE_BASE\"\nfi\n```\n\n### Step 2: Query Recent Entries\n\n**SQLite:**\n```sql\n-- Knowledge added in last 7 days\nSELECT id, category, title, content, tags, created_at\nFROM knowledge_base\nWHERE created_at > datetime('now', '-7 days')\nORDER BY created_at DESC;\n\n-- Recent work entries\nSELECT id, title, outcome, tags, timestamp\nFROM entries\nWHERE timestamp > datetime('now', '-7 days')\nORDER BY timestamp DESC;\n\n-- Active memories\nSELECT id, key, content, importance, status\nFROM memories\nWHERE status = 'staging'\nORDER BY importance DESC;\n```\n\n**PostgreSQL:**\n```sql\n-- Knowledge added in last 7 days (includes source_url if available)\nSELECT id, category, title, content, tags, created_at, source_url\nFROM knowledge_base\nWHERE created_at > NOW() - INTERVAL '7 days'\nORDER BY created_at DESC;\n\n-- Recent work entries\nSELECT id, title, outcome, tags, timestamp\nFROM entries\nWHERE timestamp > NOW() - INTERVAL '7 days'\nORDER BY timestamp DESC;\n\n-- Active memories\nSELECT id, key, content, importance, status\nFROM memories\nWHERE status = 'staging'\nORDER BY importance DESC;\n```\n\n### Step 3: Identify Promotion Candidates\n\nReview entries for local documentation promotion:\n\n**Promote to insights.md:**\n- Patterns seen multiple times\n- Gotchas and anti-patterns\n- Cross-system learnings\n\n**Promote to decisions/:**\n- Architectural decisions\n- Technology choices\n- Process decisions\n\n**Promote to guides/:**\n- Step-by-step procedures\n- Configuration guides\n- Troubleshooting flows\n\n### Step 4: Check for Duplicates\n\nBefore adding to local knowledge base:\n\n```bash\n# Search local insights\ngrep -i \"{keyword}\" \"$KNOWLEDGE_BASE/insights.md\"\n\n# Check decisions folder\nls \"$KNOWLEDGE_BASE/decisions/\" | grep -i \"{topic}\"\n\n# If docs integration, also check DOCS_ROOT\nif [ \"$DOCS_INTEGRATION\" = true ]; then\n  grep -r -i \"{keyword}\" \"$DOCS_ROOT/\" --include=\"*.md\"\nfi\n```\n\nIf duplicate found:\n- Bump score in insights.md instead of adding new entry\n- Update existing decision doc if new information\n\n### Step 5: Promote to Local Docs\n\n#### For insights.md (No Frontmatter Needed)\n\n```markdown\n**[Score: 1] | YYYY-MM-DD | {agent} | {topic}**\n{insight_text}. Source: worklog knowledge_base #{id}\n```\n\n#### For decisions/ (With Frontmatter)\n\nCreate `YYYY-MM-DD-{slug}.md`:\n\n```markdown\n---\ntitle: \"{Decision Title}\"\ntype: decision\ncreated: YYYY-MM-DD\nstatus: active\ntags: [worklog-sync, {category}]\nsource: worklog-kb-{id}\n---\n\n# {Decision Title}\n\n## Context\n\n{from knowledge_base.content - the problem or situation}\n\n## Decision\n\n{extracted decision - what was decided}\n\n## Consequences\n\n{extracted consequences - impact of the decision}\n\n## References\n\n- Source: worklog knowledge_base #{id}\n- Synced: YYYY-MM-DD\n```\n\n#### For guides/ (With Frontmatter)\n\nCreate `{slug}.md`:\n\n```markdown\n---\ntitle: \"{Guide Title}\"\ntype: guide\ncreated: YYYY-MM-DD\nstatus: active\ntags: [worklog-sync, {category}]\nsource: worklog-kb-{id}\n---\n\n# {Guide Title}\n\n{from knowledge_base.content - formatted as step-by-step guide}\n\n## Prerequisites\n\n{extracted prerequisites if any}\n\n## Steps\n\n{extracted steps}\n\n## Troubleshooting\n\n{extracted gotchas or common issues}\n\n## References\n\n- Source: worklog knowledge_base #{id}\n- Synced: YYYY-MM-DD\n```\n\n### Step 6: Update Memory Status\n\nPromote valuable memories:\n\n```sql\nUPDATE memories\nSET status = 'promoted',\n    promoted_at = CURRENT_TIMESTAMP\nWHERE id = {id};\n```\n\nArchive stale memories:\n\n**SQLite:**\n```sql\nUPDATE memories\nSET status = 'archived'\nWHERE status = 'staging'\n  AND last_accessed < datetime('now', '-30 days')\n  AND importance < 5;\n```\n\n**PostgreSQL:**\n```sql\nUPDATE memories\nSET status = 'archived'\nWHERE status = 'staging'\n  AND last_accessed < NOW() - INTERVAL '30 days'\n  AND importance < 5;\n```\n\n### Step 7: Mark Entries as Synced\n\nAdd sync tag to processed entries:\n\n```sql\nUPDATE knowledge_base\nSET tags = tags || ',synced:{system_name}'\nWHERE id = {id};\n```\n\n### Step 8: Validate Promoted Files (Docs Integration)\n\n**If docs plugin available**, run validation on new files:\n\n```bash\nif [ \"$DOCS_INTEGRATION\" = true ]; then\n  echo \"Running docs validation on promoted files...\"\n\n  # Quick validation on new files\n  for file in $PROMOTED_FILES; do\n    # Check frontmatter exists\n    if ! head -1 \"$file\" | grep -q \"^---$\"; then\n      echo \"WARNING: $file missing frontmatter\"\n    fi\n\n    # Check required fields\n    if ! grep -q \"^title:\" \"$file\"; then\n      echo \"WARNING: $file missing title field\"\n    fi\n    if ! grep -q \"^type:\" \"$file\"; then\n      echo \"WARNING: $file missing type field\"\n    fi\n    if ! grep -q \"^created:\" \"$file\"; then\n      echo \"WARNING: $file missing created field\"\n    fi\n  done\n\n  echo \"Validation complete\"\nfi\n```\n\n### Step 9: Cleanup Old Data\n\n**Archive old entries (optional):**\n\n**SQLite:**\n```sql\n-- Delete test/junk entries\nDELETE FROM entries\nWHERE agent LIKE '_test%'\n   OR title LIKE '%_test%';\n\n-- Clean up orphaned memories\nDELETE FROM memories\nWHERE status = 'archived'\n  AND last_accessed < datetime('now', '-90 days');\n```\n\n**PostgreSQL:**\n```sql\n-- Delete test/junk entries\nDELETE FROM entries\nWHERE agent LIKE '_test%'\n   OR title LIKE '%_test%';\n\n-- Clean up orphaned memories\nDELETE FROM memories\nWHERE status = 'archived'\n  AND last_accessed < NOW() - INTERVAL '90 days';\n```\n\n---\n\n## Frontmatter Reference\n\nAll promoted files use docs-compatible frontmatter:\n\n### Required Fields\n\n| Field | Format | Description |\n|-------|--------|-------------|\n| `title` | String | Brief descriptive title |\n| `type` | Enum | `decision`, `learning`, `guide`, `reference` |\n| `created` | YYYY-MM-DD | Date created/synced |\n\n### Optional Fields\n\n| Field | Format | Description |\n|-------|--------|-------------|\n| `status` | Enum | `active`, `deprecated`, `superseded` |\n| `tags` | Array | `[tag1, tag2]` |\n| `source` | String | `worklog-kb-{id}` for traceability |\n| `updated` | YYYY-MM-DD | Last update date |\n\n### Type Mapping\n\n| Worklog Category | Docs Type |\n|------------------|-----------|\n| `decisions`, `architecture` | `decision` |\n| `learnings`, `patterns` | `learning` |\n| `guides`, `procedures` | `guide` |\n| `protocols`, `references` | `reference` |\n\n---\n\n## Sync Report Template\n\nAfter sync, generate report:\n\n```markdown\n## Worklog Sync Report - {date}\n\n### Configuration\n- Mode: {Standalone | Docs-integrated}\n- KNOWLEDGE_BASE: {path}\n- DOCS_ROOT: {path or \"not set\"}\n\n### Reviewed\n- Knowledge entries: {count}\n- Work entries: {count}\n- Memories: {count}\n\n### Promoted to Local Docs\n- insights.md: {count} new entries\n- decisions/: {count} new ADRs (with frontmatter)\n- guides/: {count} new guides (with frontmatter)\n\n### Validation Results\n- Files validated: {count}\n- Frontmatter issues: {count}\n- All files compliant: {yes/no}\n\n### Memory Status Updates\n- Promoted: {count}\n- Archived: {count}\n\n### Cleanup\n- Deleted test entries: {count}\n- Archived stale memories: {count}\n\n### Pending Review\n{list entries that need human decision}\n```\n\n---\n\n## Promotion Decision Matrix\n\n| Criteria | Action | Frontmatter |\n|----------|--------|-------------|\n| Seen 3+ times | Promote to insights.md | No (inline format) |\n| Architectural decision | Promote to decisions/ | Yes (type: decision) |\n| Step-by-step procedure | Promote to guides/ | Yes (type: guide) |\n| Single occurrence, high value | Promote to insights.md | No (inline format) |\n| Single occurrence, low value | Leave in worklog | N/A |\n| Stale (>30 days, low importance) | Archive | N/A |\n\n---\n\n## Cross-System Sync\n\nFor shared databases, check for entries from other systems:\n\n**SQLite:**\n```sql\nSELECT DISTINCT source_agent, system\nFROM knowledge_base\nWHERE created_at > datetime('now', '-7 days')\n  AND system != '{this_system}';\n```\n\n**PostgreSQL:**\n```sql\nSELECT DISTINCT source_agent, system\nFROM knowledge_base\nWHERE created_at > NOW() - INTERVAL '7 days'\n  AND system != '{this_system}';\n```\n\nReview entries from other systems for local relevance.\n\n---\n\n## Example Sync Session\n\n```bash\n# 1. Check docs integration\nif [ -n \"$DOCS_ROOT\" ]; then\n  echo \"Docs integration: enabled\"\n  KNOWLEDGE_BASE=\"${KNOWLEDGE_BASE:-$DOCS_ROOT/../.claude/knowledge}\"\nfi\n\n# 2. Query recent knowledge (detect backend)\nif [ -n \"$DATABASE_URL\" ] || [ -n \"$PGHOST\" ]; then\n  # PostgreSQL\n  psql -t -c \"SELECT id, title, category, tags FROM knowledge_base\n    WHERE created_at > NOW() - INTERVAL '7 days';\"\nelse\n  # SQLite\n  sqlite3 \"$WORKLOG_DB\" \"SELECT id, title, category, tags FROM knowledge_base\n    WHERE created_at > datetime('now', '-7 days');\"\nfi\n\n# Found: ID 47 - \"Docker compose override pattern\" (category: patterns)\n# Action: New pattern, add to insights.md with score 1\n\n# Found: ID 48 - \"JWT auth architecture decision\" (category: decisions)\n# Action: Create decisions/2025-12-14-jwt-auth-strategy.md with frontmatter\n\n# 3. Update insights.md\necho \"**[Score: 1] | 2025-12-14 | claude | Docker Compose**\nUse override files for environment-specific config. Source: worklog #47\" >> \"$KNOWLEDGE_BASE/insights.md\"\n\n# 4. Create decision doc with frontmatter\ncat > \"$KNOWLEDGE_BASE/decisions/2025-12-14-jwt-auth-strategy.md\" << 'EOF'\n---\ntitle: \"JWT Authentication Strategy\"\ntype: decision\ncreated: 2025-12-14\nstatus: active\ntags: [worklog-sync, auth, security]\nsource: worklog-kb-48\n---\n\n# JWT Authentication Strategy\n\n## Context\n\nNeed to implement authentication for the API...\n\n## Decision\n\nUse JWT with refresh tokens...\n\n## Consequences\n\n- Stateless authentication\n- Need secure token storage on client\n- Refresh token rotation required\n\n## References\n\n- Source: worklog knowledge_base #48\n- Synced: 2025-12-14\nEOF\n\n# 5. Validate new file\nhead -1 \"$KNOWLEDGE_BASE/decisions/2025-12-14-jwt-auth-strategy.md\" | grep -q \"^---$\" && echo \"âœ“ Frontmatter valid\"\n\n# 6. Mark as synced (use your system name)\nsqlite3 \"$WORKLOG_DB\" \"UPDATE knowledge_base\nSET tags = tags || ',synced:$(hostname)' WHERE id IN (47, 48);\"\n\n# 7. Generate report\necho \"Sync complete: 1 insight, 1 decision promoted\"\n```\n\n---\n\n## Integration with Docs Plugin\n\nWhen docs plugin is installed:\n\n1. **Auto-detection**: memory-sync detects `$DOCS_ROOT` and enables full integration\n2. **Frontmatter compliance**: All promoted files follow docs frontmatter schema\n3. **Post-sync validation**: Validates promoted files match docs standards\n4. **Consistent paths**: Uses `$KNOWLEDGE_BASE` which docs plugin also uses\n\n**Complementary workflow:**\n- **docs-manager**: Creates docs, stores learnings TO worklog\n- **memory-sync**: Promotes worklog entries BACK to docs\n\nThis creates a bidirectional flow where knowledge moves between worklog and documentation.\n\n---\n\n**Skill Version:** 2.0.0\n**Philosophy:** Promote valuable learnings. Maintain frontmatter compliance. Validate after sync.\n",
        "plugins/worklog/worklog-viewer/README.md": "# Worklog Database Viewer\n\nBrowser-based SQLite viewer for the worklog knowledge persistence system with optional GitHub document integration.\n\n## Features\n\n### Database Viewer\n- **Natural Language Search** - Type multiple terms to filter (e.g., \"debugging react\") - all terms must match\n- **Tag Filtering** - Click tags to filter by system/agent identifiers\n- **Markdown Rendering** - Content fields render as formatted markdown with syntax highlighting\n- **View Toggle** - Switch between rendered and raw views for markdown content\n- **Dark/Light Theme** - Toggle with persistence\n- **Database Caching** - Loaded database persists in IndexedDB across page refreshes\n- **Custom SQL Queries** - Run arbitrary SQL with Ctrl+Enter\n- **CSV Export** - Export filtered results\n- **Auto Table Discovery** - Works with any SQLite database structure\n\n### GitHub Document Browser (Optional)\n- **Multi-System Support** - Browse docs from different system branches\n- **Private Repo Access** - Use Personal Access Token for private repos\n- **Markdown Rendering** - View rendered documentation with syntax highlighting\n- **File Browser** - Navigate directory structure from GitHub\n\n## Usage\n\n### Basic (Local Database)\n1. Open `index.html` in a browser\n2. Click \"Load Database\" and select your `worklog.db` file\n3. Use search, tag filters, and sort controls to explore data\n4. Double-click any row to view full details\n\n### GitHub Document Browser\n1. Click the **Settings** (gear icon) to configure:\n   - **GitHub Repository** - Format: `owner/repo` (e.g., `username/my-docs`)\n   - **Branches** - Comma-separated list of branches to show in dropdown\n2. Click **Token** to add your GitHub PAT (with `repo` scope for private repos)\n3. Select a branch from the dropdown\n4. Enter a document path or click **Browse** to navigate the repository\n\n## Database Location\n\n| Setup | Default Path |\n|-------|--------------|\n| Local (default) | `~/.claude/worklog/worklog.db` |\n| Shared (network) | Your configured shared path |\n\n## Configuration\n\nAll settings are configured via the **Settings** modal (gear icon) and stored in browser localStorage:\n\n| Setting | Storage Key | Description |\n|---------|-------------|-------------|\n| GitHub Repository | `worklog-github-repo` | Repository in `owner/repo` format |\n| Branches | `worklog-branches` | JSON array of branch names |\n| GitHub Token | `github-token` | Personal Access Token for private repos |\n| Theme | `worklog-theme` | `dark` or `light` |\n| Last Table | `worklog-last-table` | Last viewed database table |\n\n### First-Time Setup\n\n1. Open the viewer in your browser\n2. Click the **Settings** gear icon\n3. Enter your GitHub repository (e.g., `username/my-docs`)\n4. Add branches you want to access (comma-separated)\n5. Click **Save Settings**\n6. (Optional) Click **Token** to add a PAT for private repository access\n\nSettings persist across browser sessions.\n\n## Keyboard Shortcuts\n\n| Key | Action |\n|-----|--------|\n| `Ctrl+Enter` | Run SQL query |\n| `Escape` | Close modal |\n\n## Technical Details\n\n- **SQL.js** - SQLite compiled to WebAssembly for browser execution\n- **Marked.js** - Markdown parser for rendering content fields\n- **Highlight.js** - Syntax highlighting for code blocks\n- **DOMPurify** - HTML sanitization for XSS protection\n- **IndexedDB** - Caches loaded database for persistence\n- **localStorage** - Stores theme preference, last selected table, and GitHub token\n- **Single HTML file** - All libraries loaded from CDN\n\n## Contributing\n\n### Source Location\n\nThe source file is maintained separately from the distributed plugin:\n\n```\nSource:  /mnt/nasdevenv/workspace/logs/worklog-viewer/index.html\nOutput:  plugins/worklog/worklog-viewer/index.html (minified)\n```\n\n**Important:** Always edit the source file, never the minified output.\n\n### Build Process\n\nAfter making changes to `index.html`:\n\n```bash\ncd /mnt/nasdevenv/workspace/logs/worklog-viewer\n./build.sh\n```\n\n**What the build does:**\n1. Minifies HTML, CSS, and JS using `html-minifier-terser`\n2. Prepends MIT license attribution comment\n3. Copies minified `index.html` and `README.md` to plugin directories\n\n### Build Output\n\nThe build script copies to these locations:\n- `~/projects/gsc-plugins/plugins/worklog/worklog-viewer/` (for commits)\n- `~/.claude/plugins/local-plugins/worklog/worklog-viewer/` (for local testing)\n\n### Commit Workflow\n\n```bash\n# 1. Edit source\nvim /mnt/nasdevenv/workspace/logs/worklog-viewer/index.html\n\n# 2. Build\ncd /mnt/nasdevenv/workspace/logs/worklog-viewer && ./build.sh\n\n# 3. Commit\ncd ~/projects/gsc-plugins\ngit add -A && git commit -m \"feat(worklog-viewer): description\" && git push\n```\n\n### License\n\nDesign system by [@gaurangrshah](https://github.com/gaurangrshah) - MIT License.\n\nThe build process preserves the license comment in the minified output.\n\n## Related\n\n- [Worklog Plugin Documentation](../README.md)\n- [Schema Reference](../schema/)\n"
      },
      "plugins": [
        {
          "name": "webgen",
          "source": "./plugins/webgen",
          "version": "2.0.0",
          "description": "Transform natural language descriptions into complete, production-ready web projects",
          "keywords": [
            "web",
            "generator",
            "react",
            "nextjs",
            "astro",
            "frontend",
            "landing-pages"
          ],
          "categories": [
            "astro",
            "frontend",
            "generator",
            "landing-pages",
            "nextjs",
            "react",
            "web"
          ],
          "install_commands": [
            "/plugin marketplace add gaurangrshah/gsc-plugins",
            "/plugin install webgen@gsc-plugins"
          ]
        },
        {
          "name": "appgen",
          "source": "./plugins/appgen",
          "version": "2.0.0",
          "description": "Generate full-stack applications and APIs from natural language descriptions",
          "keywords": [
            "app",
            "generator",
            "fullstack",
            "api",
            "backend",
            "database",
            "auth"
          ],
          "categories": [
            "api",
            "app",
            "auth",
            "backend",
            "database",
            "fullstack",
            "generator"
          ],
          "install_commands": [
            "/plugin marketplace add gaurangrshah/gsc-plugins",
            "/plugin install appgen@gsc-plugins"
          ]
        },
        {
          "name": "worklog",
          "source": "./plugins/worklog",
          "version": "1.7.1",
          "description": "Cross-session knowledge persistence with SQLite/PostgreSQL for maintaining context across sessions",
          "keywords": [
            "memory",
            "persistence",
            "sqlite",
            "postgresql",
            "knowledge-base",
            "cross-session",
            "hooks",
            "automation",
            "mcp",
            "seed-data"
          ],
          "categories": [
            "automation",
            "cross-session",
            "hooks",
            "knowledge-base",
            "mcp",
            "memory",
            "persistence",
            "postgresql",
            "seed-data",
            "sqlite"
          ],
          "install_commands": [
            "/plugin marketplace add gaurangrshah/gsc-plugins",
            "/plugin install worklog@gsc-plugins"
          ]
        },
        {
          "name": "taskflow",
          "source": "./plugins/taskflow",
          "version": "2.0.0",
          "description": "AI-powered task management - transform PRDs into structured, dependency-aware tasks",
          "keywords": [
            "tasks",
            "project-management",
            "prd",
            "workflow",
            "productivity"
          ],
          "categories": [
            "prd",
            "productivity",
            "project-management",
            "tasks",
            "workflow"
          ],
          "install_commands": [
            "/plugin marketplace add gaurangrshah/gsc-plugins",
            "/plugin install taskflow@gsc-plugins"
          ]
        },
        {
          "name": "docs",
          "source": "./plugins/docs",
          "version": "1.1.0",
          "description": "Documentation management and validation with single source of truth philosophy",
          "keywords": [
            "documentation",
            "markdown",
            "frontmatter",
            "validation",
            "quality-assurance",
            "journal"
          ],
          "categories": [
            "documentation",
            "frontmatter",
            "journal",
            "markdown",
            "quality-assurance",
            "validation"
          ],
          "install_commands": [
            "/plugin marketplace add gaurangrshah/gsc-plugins",
            "/plugin install docs@gsc-plugins"
          ]
        }
      ]
    }
  ]
}