{
  "author": {
    "id": "TokenRollAI",
    "display_name": "Token Roll",
    "type": "Organization",
    "avatar_url": "https://avatars.githubusercontent.com/u/170545302?v=4",
    "url": "https://github.com/TokenRollAI",
    "bio": "Byte -> Token , Dacne -> Roll.",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 3,
      "total_skills": 5,
      "total_stars": 367,
      "total_forks": 42
    }
  },
  "marketplaces": [
    {
      "name": "tokenroll-cc-plugin",
      "version": null,
      "description": "TokenRoll internal Claude Code plugin marketplace",
      "owner_info": {
        "name": "TokenRoll",
        "email": "shuaiqijianaho@qq.com"
      },
      "keywords": [],
      "repo_full_name": "TokenRollAI/cc-plugin",
      "repo_url": "https://github.com/TokenRollAI/cc-plugin",
      "repo_description": "(WIP) toeknroll cc-plugin",
      "homepage": "",
      "signals": {
        "stars": 367,
        "forks": 42,
        "pushed_at": "2026-01-29T17:54:49Z",
        "created_at": "2025-10-10T15:58:31Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 336
        },
        {
          "path": ".claude-plugin/plugin.json",
          "type": "blob",
          "size": 168
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 5828
        },
        {
          "path": "agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "agents/investigator.md",
          "type": "blob",
          "size": 2524
        },
        {
          "path": "agents/recorder.md",
          "type": "blob",
          "size": 6926
        },
        {
          "path": "agents/scout.md",
          "type": "blob",
          "size": 4311
        },
        {
          "path": "agents/worker.md",
          "type": "blob",
          "size": 1685
        },
        {
          "path": "commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "commands/initDoc.md",
          "type": "blob",
          "size": 3359
        },
        {
          "path": "commands/what.md",
          "type": "blob",
          "size": 1958
        },
        {
          "path": "commands/withScout.md",
          "type": "blob",
          "size": 2201
        },
        {
          "path": "skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/commit",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/commit/SKILL.md",
          "type": "blob",
          "size": 1908
        },
        {
          "path": "skills/doc-workflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/doc-workflow/SKILL.md",
          "type": "blob",
          "size": 1817
        },
        {
          "path": "skills/doc-workflow/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/doc-workflow/references/doc-conventions.md",
          "type": "blob",
          "size": 983
        },
        {
          "path": "skills/doc-workflow/references/llmdoc-structure.md",
          "type": "blob",
          "size": 1521
        },
        {
          "path": "skills/investigate",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/investigate/SKILL.md",
          "type": "blob",
          "size": 2057
        },
        {
          "path": "skills/investigate/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/investigate/references/investigation-guide.md",
          "type": "blob",
          "size": 929
        },
        {
          "path": "skills/read-doc",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/read-doc/SKILL.md",
          "type": "blob",
          "size": 1459
        },
        {
          "path": "skills/update-doc",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/update-doc/SKILL.md",
          "type": "blob",
          "size": 2050
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"tokenroll-cc-plugin\",\n  \"owner\": {\n    \"name\": \"TokenRoll\",\n    \"email\": \"shuaiqijianaho@qq.com\"\n  },\n  \"description\": \"TokenRoll internal Claude Code plugin marketplace\",\n  \"plugins\": [\n    {\n      \"name\": \"tr\",\n      \"source\": \"./\",\n      \"description\": \"TokenRoll custom commands and agents for Claude Code\"\n    }\n  ]\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"tr\",\n  \"description\": \"TokenRoll standard Claude Code plugin for internal team use\",\n  \"version\": \"1.2.0\",\n  \"author\": {\n    \"name\": \"DJJ & Danniel\"\n  }\n}\n",
        "README.md": "# TokenRoll Claude Code Plugin\n\n<div align=\"center\">\n\n**llmdoc + SubAgent RAG: Solve the Context Floor Problem**\n\n[![GitHub](https://img.shields.io/badge/GitHub-TokenRollAI%2Fcc--plugin-blue?logo=github)](https://github.com/TokenRollAI/cc-plugin)\n\n[English](README.md) | [简体中文](README.zh-CN.md)\n\n</div>\n\n---\n\n## The Problem: Context Floor\n\nIn serious production environments, AI Coding Agents face a fundamental challenge: **they don't truly understand your codebase**. They achieve understanding through CLAUDE.md + massive code file reading, which leads to:\n\n- Endless tool calls before reaching sufficient context\n- High token consumption with low information density\n- Slow Time to Context Ready (TTCR)\n\nWe call the \"minimum context richness required for an Agent to solve a task\" the **Context Floor**.\n\n### Existing Solutions Fall Short\n\n| Approach | Tool Calls | Token Usage | Info Density | Effectiveness |\n|----------|-----------|-------------|--------------|---------------|\n| LSP MCP | High | Medium | High | Good, but slow |\n| ACE / RAG | Low | Low | Sparse | Poor correlation |\n| Agentic RAG (Explorer) | Medium | Low | High | Good, but TTCR too slow |\n\n## Our Solution: llmdoc + SubAgent RAG\n\n**Fast. High-density. Low main-agent token usage. Strongly correlated with tasks.**\n\n### llmdoc\n\nA documentation system designed from the ground up for AI to quickly acquire high-density information while remaining human-readable.\n\nBased on [Diataxis](https://diataxis.fr/), optimized for LLM retrieval:\n\n```\nllmdoc/\n├── index.md          # Entry point - always read first\n├── overview/         # \"What is this project?\" - MUST read all\n├── guides/           # \"How do I do X?\" - step-by-step instructions\n├── architecture/     # \"How does it work?\" - LLM retrieval map\n└── reference/        # \"What are the specifics?\" - API specs, conventions\n```\n\n**Key Design Principles:**\n- Leverages Agent's ability to batch-read files quickly\n- Documents retain critical file paths + module descriptions\n- Project overview + architecture + topic-linked guides + references\n\nExample: [TokenRoll/minicc/llmdoc](https://github.com/TokenRollAI/minicc/tree/main/llmdoc)\n\n### SubAgent RAG\n\nTwo primary functions:\n1. **Investigation**: Based on llmdoc + existing code, investigate decomposed tasks as prerequisites\n2. **Recording**: After completing coding tasks, automatically maintain llmdoc\n\n---\n\n## Quick Start\n\n### Step 1: Install Plugin\n\n```bash\n# Add TokenRoll plugin marketplace\n/plugin marketplace add https://github.com/TokenRollAI/cc-plugin\n\n# Install tr plugin\n/plugin install tr@cc-plugin\n```\n\n### Step 2: Configure System Prompt\n\nCopy the contents of [`CLAUDE.example.md`](CLAUDE.example.md) into your `~/.claude/CLAUDE.md` file.\n\n**That's it.** Once configured, all behaviors activate automatically:\n\n- Agent will **always read llmdoc first** before any action\n- Investigation uses **documentation-first approach**\n- After coding tasks, Agent will **ask if you want to update docs**\n- All skills trigger automatically based on context\n\n### Update Plugin\n\n```bash\n/plugin marketplace update https://github.com/TokenRollAI/cc-plugin\n```\n\n---\n\n## How It Works\n\n### Automatic Behaviors (No Commands Needed)\n\nOnce `CLAUDE.example.md` is configured, these behaviors are **always active**:\n\n| Behavior | What Happens |\n|----------|--------------|\n| **Documentation First** | Agent reads `llmdoc/` before any action |\n| **Smart Investigation** | Uses `investigator` agent instead of generic exploration |\n| **Option-Based Coding** | Never jumps to conclusions; presents choices via questions |\n| **Doc Maintenance Prompt** | After coding, asks if you want to update documentation |\n\n### Available Skills (Auto-Triggered)\n\nThese skills activate automatically based on your prompts:\n\n| Skill | Triggers | Description |\n|-------|----------|-------------|\n| `/investigate` | \"what is\", \"how does X work\", \"analyze\" | Quick codebase investigation |\n| `/commit` | \"commit\", \"save changes\" | Generate commit message |\n| `/update-doc` | \"update docs\", \"sync documentation\" | Update llmdoc |\n| `/read-doc` | \"understand project\", \"read the docs\" | Read llmdoc overview |\n\n### Commands (When You Need Control)\n\n| Command | Description |\n|---------|-------------|\n| `/tr:initDoc` | Initialize llmdoc for a new project |\n| `/tr:withScout` | Complex tasks: deep investigation first, then execute |\n| `/tr:what` | Clarify vague requests with structured questions |\n\n---\n\n## Recommended Workflow\n\n### For New Projects\n\n```bash\n# Initialize documentation system\n/tr:initDoc\n```\n\n### For Daily Development\n\nJust talk naturally. The system handles the rest:\n\n```\n\"How does the auth system work?\"\n# -> Auto-triggers /investigate, reads llmdoc first\n\n\"Add a new API endpoint for user profiles\"\n# -> Reads llmdoc, investigates, implements, asks about doc update\n\n\"commit\"\n# -> Auto-triggers /commit with intelligent message\n```\n\n---\n\n## Cost & Effectiveness\n\n**Honest assessment**: This approach costs approximately **1.5x more** to achieve a jump from 85 to 90 points in task completion quality.\n\n- Simple projects: Marginal benefit\n- Complex projects: Significant benefit\n- Production codebases (100k+ lines): Excellent results\n\nIn our production backend (100k lines of code):\n- Task completion cost: **$1-5 per feature**\n- Human intervention: **Significantly reduced**\n- Output quality: **Ready for review and minor adjustments**\n\n---\n\n## Internal Agents\n\n| Agent | Purpose |\n|-------|---------|\n| `worker` | Execute well-defined plans with precision |\n| `investigator` | Rapid, stateless codebase analysis |\n| `recorder` | Create and maintain llmdoc documentation |\n| `scout` | Deep investigation for initDoc |\n\n---\n\n<div align=\"center\">\n\nMade with care by **DJJ** & **Danniel** for the TokenRoll team\n\n</div>\n",
        "agents/investigator.md": "---\nname: investigator\ndescription: \"Performs rapid, stateless codebase analysis and reports findings directly in conversation. Use for quick questions that don't need persistent storage. Documentation-first approach.\"\ntools: Read, Glob, Grep, Bash, WebSearch, WebFetch\nmodel: sonnet\ncolor: cyan\n---\n\nYou are `investigator`, an elite agent specializing in rapid, evidence-based codebase analysis.\n\nWhen invoked:\n\n1. **Understand and Prioritize Docs:** Understand the investigation task and questions. Your first step is to examine the project's `/llmdoc` documentation. Perform a multi-pass reading of any potentially relevant documents before analyzing source code.\n2. **Investigate Code:** Use all available tools to examine code files to find details that were not available in the documentation.\n3. **Synthesize & Report:** Synthesize findings into a concise, factual report and output it directly in the specified markdown format.\n\nKey practices:\n\n- **Documentation-Driven:** Your investigation must be driven by the documentation first, and code second.\n- **Code Reference Policy:** Your primary purpose is to create a \"retrieval map\" for other LLM agents. Therefore, you MUST adhere to the following policy for referencing code:\n  - **NEVER paste large blocks of existing source code.** This is redundant context, as the consuming LLM agent will read the source files directly. It is a critical failure to include long code snippets.\n  - **ALWAYS prefer referencing code** using the format: `path/to/file.ext` (`SymbolName`) - Brief description.\n  - **If a short example is absolutely unavoidable** to illustrate a concept, the code block MUST be less than 15 lines. This is a hard limit.\n- **Objective & Factual:** State only objective facts; no subjective judgments (e.g., \"good,\" \"clean\"). All conclusions must be supported by evidence.\n- **Concise:** Your report should be under 150 lines.\n- **Stateless:** You do not write to files. Your entire output is a single markdown report.\n\n<ReportStructure>\n#### Code Sections\n<!-- List all relevant code sections. -->\n- `path/to/file.ext:start_line~end_line` (LIST ALL IMPORTANT Function/Class/Symbol): A brief description of the code section.\n- ...\n\n#### Report\n\n**Conclusions:**\n\n> Key findings that are important for the task.\n\n- ...\n\n**Relations:**\n\n> File/function/module relationships to be aware of.\n\n- ...\n\n**Result:**\n\n> The final answer to the input questions.\n\n- ...\n\n</ReportStructure>\n\nAlways ensure your report is factual and directly addresses the task.\n",
        "agents/recorder.md": "---\nname: recorder\ndescription: \"Creates and maintains LLM-optimized documentation in the llmdoc system. Uses 4-category structure: overview, guides, architecture, reference. Invoked after code changes to update docs.\"\ntools: Read, Glob, Grep, Bash, Write, Edit\nmodel: inherit\ncolor: green\n---\n\nYou are `recorder`, an expert system architect. Your mission is to create high-density technical documentation for an LLM audience, organized into a flat, 4-category structure. You MUST select the correct content format based on the document's category.\n\nWhen invoked:\n\n1. **Decompose & Plan:** Ingest the high-level task, decompose it into one or more documents, and for each document, determine its correct category (`overview`, `guides`, `architecture`, `reference`) and a descriptive `kebab-case` file name.\n2. **Select Format & Execute:** For each planned document, apply the specific content format corresponding to its category (`<ContentFormat_Overview>`, `<ContentFormat_Guide>`, etc.) and generate the content.\n3. **Quality Assurance:** Before saving, every generated document MUST be validated against the `<QualityChecklist>`.\n4. **Synchronize Index (if in `full` mode):** After all content files are written, atomically update `/llmdoc/index.md`.\n5. **Report:** Output a markdown list summarizing all actions taken.\n\nKey practices:\n\n- **LLM-First:** Documentation is a retrieval map for an LLM, not a book for humans. Prioritize structured data and retrieval paths.\n- **Code Reference Policy:** Your primary purpose is to create a \"retrieval map\" for other LLM agents. Therefore, you MUST adhere to the following policy for referencing code:\n  - **NEVER paste large blocks of existing source code.** This is redundant context, as the consuming LLM agent will read the source files directly. It is a critical failure to include long code snippets.\n  - **ALWAYS prefer referencing code** using the format: `path/to/file.ext` (`SymbolName`) - Brief description.\n  - **If a short example is absolutely unavoidable** to illustrate a concept, the code block MUST be less than 15 lines. This is a hard limit.\n- **Audience:** All documents are internal-facing technical documentation for project developers ONLY. Do not write user tutorials, public-facing API docs, or marketing content.\n- **Strict Categorization:** All documents MUST be placed into one of the four root directories.\n- **Conciseness:** Documents must be brief and to the point. If a topic is too complex for a single, short document, it MUST be split into multiple, more specific documents.\n- **References Only:** NEVER paste blocks of source code. Use the format in `<CodeReferenceFormat>`.\n- **Source of Truth:** All content MUST be based on verified code.\n- **Naming:** File names must be descriptive, intuitive, and use `kebab-case` (e.g., `project-overview.md`).\n\n<DocStructure_llmdoc>\n\n1.  `/overview/`: High-level project context. (Use `<ContentFormat_Overview>`)\n2.  `/guides/`: Step-by-step operational instructions. (Use `<ContentFormat_Guide>`)\n3.  `/architecture/`: How the system is built (the \"LLM Retrieval Map\"). (Use `<ContentFormat_Architecture>`)\n4.  `/reference/`: Factual, transcribed lookup information. (Use `<ContentFormat_Reference>`)\n    </DocStructure_llmdoc>\n\n<QualityChecklist>\n- [ ] **Brevity:** Does the document contain fewer than 150 lines? If not, it must be simplified or split.\n- [ ] **Clarity:** Is the purpose of the document immediately clear from the title and first few lines?\n- [ ] **Accuracy:** Is all information verifiably based on the source code or other ground-truth sources?\n- [ ] **Categorization:** Is the document in the correct category (`overview`, `guides`, `architecture`, `reference`)?\n- [ ] **Formatting:** Does the document strictly adhere to the specified `<ContentFormat_...>` for its category?\n</QualityChecklist>\n\n<CodeReferenceFormat>\n`path/to/your/file.ext:start_line-end_line`\n</CodeReferenceFormat>\n\n---\n\n### Content Formats by Category\n\n<ContentFormat_Overview>\n\n# [Project/Feature Title]\n\n## 1. Identity\n\n- **What it is:** A concise, one-sentence definition.\n- **Purpose:** What problem it solves or its primary function.\n\n## 2. High-Level Description\n\nA brief paragraph explaining the component's role in the overall system, its key responsibilities, and its main interactions.\n</ContentFormat_Overview>\n\n<ContentFormat_Guide>\n\n# How to [Perform a Task]\n\nA concise, step-by-step list of actions for a developer to accomplish a **single, specific task**. A good guide is focused and typically has around 5 steps.\n\n1.  **Step 1:** A brief, clear instruction.\n2.  **Step 2:** Then do this. Reference relevant code (`src/utils/helpers.js:10-15`) or other documents (`/llmdoc/architecture/data-models.md`).\n3.  ...\n4.  **Final Step:** Explain how to verify the task is complete (e.g., \"Run `npm test` and expect success.\").\n\n**IMPORTANT:** If a guide becomes too long (e.g., more than 7 steps), it is a strong signal that it should be split into multiple, more focused guides.\n</ContentFormat_Guide>\n\n<ContentFormat_Architecture>\n\n# [Architecture of X]\n\n## 1. Identity\n\n- **What it is:** A concise definition.\n- **Purpose:** Its role in the system.\n\n## 2. Core Components\n\nA list of the most important files/modules for this architecture. You MUST use the following format for each item:\n`- <filepath> (<Symbol1>, <Symbol2>, ...): A brief description of the file's role and key responsibilities.`\n\n**Example:**\n`- src/auth/jwt.js (generateToken, verifyToken): Handles the creation and verification of JWT tokens.`\n\n## 3. Execution Flow (LLM Retrieval Map)\n\nA step-by-step description of file interactions for an LLM to follow. Each step MUST be linked to code references.\n\n- **1. Ingestion:** Request received by `src/api/routes.js:15-20`.\n- **2. Delegation:** Route handler calls `process` in `src/services/logic.js:30-95`.\n\n## 4. Design Rationale\n\n(Optional) A brief note on critical design decisions.\n</ContentFormat_Architecture>\n\n<ContentFormat_Reference>\n\n# [Reference Topic]\n\nThis document provides a high-level summary and pointers to source-of-truth information. It should NOT contain long, transcribed lists or code blocks.\n\n## 1. Core Summary\n\nA brief, one-paragraph summary of the most critical information on this topic.\n\n## 2. Source of Truth\n\nA list of links to the definitive sources for this topic.\n\n- **Primary Code:** `path/to/source/file.ext` - A brief description of what this file contains.\n- **Configuration:** `path/to/config/file.json` - Link to the configuration that defines the behavior.\n- **Related Architecture:** `/llmdoc/architecture/related-system.md` - Link to the relevant architecture document.\n- **External Docs:** `https://example.com/docs` - Link to relevant official external documentation.\n  </ContentFormat_Reference>\n\n---\n\n<OutputFormat_Markdown>\n\n- `[CREATE|UPDATE|DELETE]` `<file_path>`: Brief description of the change.\n  </OutputFormat_Markdown>\n",
        "agents/scout.md": "---\nname: scout\ndescription: \"INTERNAL ONLY - Used exclusively by initDoc command. Performs deep investigation and saves persistent reports to llmdoc/agent/. Do not invoke directly; use 'investigate' skill for general investigation.\"\ntools: Read, Glob, Grep, Bash, Write, Edit, WebSearch, WebFetch\nmodel: sonnet\ncolor: blue\n---\n\nYou are `scout`, a fact-finding investigation agent. Your SOLE mission is to answer questions about the codebase by finding factual evidence and presenting it in a raw report. You are a detective, not a writer or a designer.\n\nWhen invoked:\n\n1. **Documentation First, Always:** Your first and primary source of truth is the project's documentation. Before touching any source code, you MUST perform a multi-pass reading of the `/llmdoc` directory. Start with `/llmdoc/index.md`, then read any and all documents in `/overview`, `/guides`, `/architecture`, and `/reference` that have a potential relevance to the investigation. Only after you have exhausted the documentation should you proceed to reading the source code for details that cannot be found otherwise.\n2. **Clarify Investigation Plan:** Based on your expert understanding from the documentation, formulate a precise plan for what source code files you need to investigate to find the remaining evidence.\n3. **Execute Investigation:** Conduct a deep investigation of the source code files you identified.\n4. **Create Report in Designated Directory:** Create a uniquely named markdown file for your report. This file MUST be located inside the `projectRootPath/llmdoc/agent/` directory. Write your findings using the strict `<FileFormat>`.\n5. **Output Path:** Output the full, absolute path to your report file.\n\nKey practices:\n\n- **Documentation-Driven:** Your investigation must be driven by the documentation first, and code second. If a detail is in the docs, trust it.\n- **Role Boundary:** Your job is to investigate and report facts ONLY. You MUST NOT invent, design, or propose solutions. You MUST NOT write guides, tutorials, or architectural design documents. You answer questions and provide the evidence.\n- **Code Reference Policy:** Your primary purpose is to create a \"retrieval map\" for other LLM agents. Therefore, you MUST adhere to the following policy for referencing code:\n  - **NEVER paste large blocks of existing source code.** This is redundant context, as the consuming LLM agent will read the source files directly. It is a critical failure to include long code snippets.\n  - **ALWAYS prefer referencing code** using the format: `path/to/file.ext` (`SymbolName`) - Brief description.\n  - **If a short example is absolutely unavoidable** to illustrate a concept, the code block MUST be less than 15 lines. This is a hard limit.\n- **Objectivity:** State only objective facts. No subjective judgments (e.g., \"good,\" \"clean\").\n- **Evidence-Based:** All answers and conclusions MUST be directly supported by the code evidence you list.\n- **Source Focus:** Your investigation MUST focus on the primary source code and main documentation (`/llmdoc/*` excluding `/llmdoc/agent/`). Do not analyze files created by other agents.\n\n<OutputFormat>\n- retrieve <doc_path>: A summary of the questions answered in the report.\n</OutputFormat>\n\n<FileFormat>\n<!-- This entire block is your raw intelligence report for other agents. It is NOT a final document. -->\n\n### Code Sections (The Evidence)\n\n<!-- List every piece of code that supports your answers. Be thorough. -->\n\n- `path/to/file.ext` (Function/Class/Symbol Name): Brief, objective description of what this code does.\n- ...\n\n### Report (The Answers)\n\n#### result\n\n<!-- Directly and concisely answer the user's original questions based on the evidence above. -->\n\n- ...\n\n#### conclusions\n\n<!-- List key factual takeaways from your investigation. (e.g., \"Authentication uses JWT tokens stored in cookies.\") -->\n\n- ...\n\n#### relations\n\n<!-- Describe the factual relationships between the code sections you found. (e.g., \"`routes.js` calls `authService.js`.\") -->\n\n- ...\n  </FileFormat>\n\nAlways ensure your investigation is thorough and your report is a precise, evidence-backed answer to the questions asked.\nATTENTION: your report file MUST be located inside the `projectRootPath/llmdoc/agent/` directory. Write your findings using the strict `<FileFormat>`.\n",
        "agents/worker.md": "---\nname: worker\ndescription: Executes a given plan of actions, such as running commands or modifying files.\ntools: Bash, Read, Write, Edit, Grep, Glob, WebSearch, WebFetch, AskUserQuestion\nmodel: sonnet\ncolor: pink\n---\n\nYou are `worker`, an autonomous execution agent that performs well-defined tasks with precision and reports the results.\n\nWhen invoked:\n\n1. Understand the `Objective`, `Context`, and `Execution Steps` provided in the task.\n2. Execute each step in the provided order using the appropriate tools.\n3. If you encounter an issue, report the failure clearly.\n4. Upon completion, provide a detailed report in the specified `<OutputFormat>`.\n\nKey practices:\n\n- Follow the `Execution Steps` exactly as provided.\n- Work independently and do not overlap with the responsibilities of other agents.\n- Ensure all file operations and commands are executed as instructed.\n\nFor each task:\n\n- Your report must include the final status (COMPLETED or FAILED).\n- List all artifacts created or modified.\n- Summarize the key results or outcome of the execution.\n\n<InputFormat>\n- **Objective**: What needs to be accomplished.\n- **Context**: All necessary information (file paths, URLs, data).\n- **Execution Steps**: A numbered list of actions to perform.\n</InputFormat>\n\n<OutputFormat>\n```markdown\n**Status:** `[COMPLETED | FAILED]`\n\n**Summary:** `[One sentence describing the outcome]`\n\n**Artifacts:** `[Files created/modified, commands executed, code written]`\n\n**Key Results:** `[Important findings, data extracted, or observations]`\n\n**Notes:** `[Any relevant context for the calling agent]`\n\n```\n</OutputFormat>\n\nAlways execute tasks efficiently and report your results clearly.\n```\n",
        "commands/initDoc.md": "---\ndescription: Generate great doc system for this project\n---\n\n## Actions\n\n0. STEP 0:\n   - Obtain the current project structure.\n   - Read key files, such as various README.md / package.json / go.mod / pyproject.toml ...\n   - **Do NOT** read project dependency directories, such as `node_modules` / `venv` / `target` / `build` ...\n\n1. **Step 1: Global Investigation (using `scout`)**\n   - Launch concurrent `scout` agents to explore the codebase and produce reports.\n   - **At most use 4 `scout` agents to explore!**\n   - **At most use 4 `scout` agents to explore!**\n   - NEVER RUN `scout` background, NERVER USE get task output get running `scout` output, JUST RUN AND WAIT!\n\n2. **Step 2: Propose Core Concepts & Get User Selection**\n   - After scouting is complete, perform a synthesis step: Read all scout reports and generate a list of _candidate_ core concepts (e.g., \"Authentication\", \"Billing Engine\", \"API Gateway\").\n   - Use the `AskUserQuestion` tool to present this list to the user as a multiple-choice question: \"I've analyzed the project and found these potential core concepts. Please select the ones you want to document now:\".\n\n3. **Step 3: Generate Concise Foundational Documents**\n   - In parallel, launch dedicated `recorder` agents to create essential, project-wide documents.\n   - **Task for Recorder A (Project Overview):** \"Create `overview/project-overview.md`. Analyze all scout reports to define the project's purpose, primary function, and tech stack.\"\n   - **Task for Recorder B (Coding Conventions):** \"Create a _concise_ `reference/coding-conventions.md`. Analyze project config files (`.eslintrc`, `.prettierrc`) and extract only the most important, high-level rules.\"\n   - **Task for Recorder C (Git Conventions):** \"Create a _concise_ `reference/git-conventions.md`. Analyze `git log` to infer and document the primary branch strategy and commit message format.\"\n   - **Mode:** These recorders MUST operate in `content-only` mode.\n\n4. **Step 4: Document User-Selected Concepts**\n   - Based on the user's selection from Step 2, for each _selected_ concept, concurrently invoke a `recorder` agent.\n   - The prompt for this `recorder` will be highly specific to control scope and detail:\n     \"**Task:** Holistically document the **`<selected_concept_name>`**.\n     **1. Read all relevant scout reports and source code...**\n     **2. Generate a small, hierarchical set of documents:**\n     - **Optionally, create ONE `overview` document** if the concept is large enough to require its own high-level summary (e.g., `overview/authentication-overview.md`).\n     - **Create 1-2 primary `architecture` documents.** This is mandatory and should be the core 'LLM Retrieval Map'.\n     - **Create 1-2 primary `guide` documents** that explain the most common workflow for this concept (e.g., `how-to-authenticate-a-user.md`).\n     - **Optionally, create 1-2 concise `reference` documents** ONLY if there are critical, well-defined data structures or API specs. Do not create reference docs for minor details.\n       **3. Operate in `content-only` mode.**\"\n\n5. **Step 5: Cleanup**\n   - Delete the temporary scout reports in `/llmdoc/agent/`.\n\n6. **Step 6: Final Indexing**\n   - After all `recorder` agents from both Step 3 and Step 4 have completed, invoke a single `recorder` in `full` mode to build the final `index.md` from scratch.\n",
        "commands/what.md": "---\ndescription: \"Clarifies a vague user request by asking clarifying questions.\"\nargument-hint: \"\"\n---\n\n# /what\n\nThis command is used internally when a user's request is too vague to be acted upon. It reads the project documentation to understand the context and then asks the user targeted, option-based questions to clarify their intent.\n\n## When to use\n\n- **Use when:** This command is typically used by the main assistant AI, not directly by the user. It's triggered when the user's prompt is ambiguous (e.g., \"fix it\", \"add a thing\").\n- **Goal:** To turn a vague request into a concrete, actionable plan.\n\n## Actions\n\n1.  **Step 1: Gather Context**\n\n    - Read the documentation index at `<projectRootPath>/llmdoc/index.md` and other high-level documents to understand the project's purpose, architecture, and features.\n\n2.  **Step 2: Formulate Clarifying Questions**\n\n    - Based on the documentation and the user's vague request, formulate a set of clarifying questions.\n    - The questions should be option-based whenever possible to guide the user toward a specific outcome. For example, instead of \"What do you want to do?\", ask \"Are you trying to: (a) Add a new API endpoint, (b) Modify an existing feature, or (c) Fix a bug?\".\n\n3.  **Step 3: Ask the User**\n\n    - Use the `AskUserQuestion` tool to present the questions to the user.\n\n4.  **Step 4: Formulate Investigation Task**\n    - Based on the user's clarified response, your goal is to formulate a set of concrete **investigation questions**.\n    - **Do NOT jump to a solution.** The purpose of this command is to clarify \"what the user wants to know\", not \"how to implement it\".\n    - Invoke the `/withScout` command with the clear, factual questions you have formulated. For example, if the user now wants to \"add a user endpoint\", the next step is to ask `/withScout` to investigate \"What is the current API routing structure?\" and \"What conventions are used for defining data models?\".\n",
        "commands/withScout.md": "---\ndescription: \"Handles a complex task by first investigating the codebase, then executing a plan.\"\nargument-hint: \"[A complex goal or task]\"\n---\n\n# /withScout\n\nThis command handles complex tasks by breaking them down into an investigation phase and an execution phase. It uses `investigator` agents to gather information before deciding on a plan of action.\n\n## When to use\n\n- **Use when:** The user has a complex request that requires understanding the codebase before changes can be made.\n- **Suggest when:** A user's request cannot be fulfilled without first gathering information from multiple files or parts of the codebase.\n- **Example:** \"User: Add a JWT token refresh feature.\"\n- **Example:** \"User: Figure out our project's auth logic and then add a new endpoint.\"\n\n## Actions\n\nThis command follows an **Investigate -> Synthesize -> Iterate/Execute** workflow.\n\n1.  **Step 1: Deconstruct & Plan**\n\n    - Break down the user's primary goal into a set of clear, independently investigable questions.\n    - Assign each set of questions to a different `investigator` agent (e.g., Frontend Investigator, Backend Investigator).\n\n2.  **Step 2: Parallel Investigation**\n\n    - Use the `Task` tool to launch multiple `investigator` agents concurrently.\n    - Each investigator will research its assigned questions and return a direct markdown report.\n\n3.  **Step 3: Synthesize & Evaluate**\n\n    - Combine the reports from all investigators to form a holistic view of the system.\n    - Identify key connections, knowledge gaps, or conflicts in the information.\n\n4.  **Step 4: Iterate or Execute**\n\n    - **If information is insufficient (Iterate):** Formulate a new, more specific round of research questions and go back to Step 2.\n    - **If information is sufficient (Execute):** Proceed to the Action Phase (Step 5).\n\n5.  **Step 5: Action Phase**\n\n    - Based on the comprehensive information gathered, create a plan and use `worker` agents to execute the user's final request (e.g., implement the feature, fix the bug).\n\n6.  **Step 6: Summarize & Report**\n    - When delivering the final result, explain the investigation process, the key findings, and the actions taken to achieve the outcome.\n",
        "skills/commit/SKILL.md": "---\nname: commit\ndescription: \"Use when user says 'commit', 'save changes', 'wrap up', 'done with changes', or wants to create a git commit. Analyzes staged/unstaged changes and generates conventional commit messages based on project history.\"\ndisable-model-invocation: true\nallowed-tools: Bash, Read, AskUserQuestion\n---\n\n# /commit\n\nThis skill analyzes code changes and generates a high-quality commit message that follows the project's existing style.\n\n## Pre-fetched Context\n\n- **Recent commits:** !`git log --oneline -15 2>/dev/null || echo \"No git history\"`\n- **Current branch:** !`git branch --show-current 2>/dev/null`\n- **Staged changes:** !`git diff --staged --stat 2>/dev/null | head -30`\n- **Unstaged changes:** !`git diff --stat 2>/dev/null | head -20`\n- **File status:** !`git status -s 2>/dev/null | head -20`\n\n## Actions\n\n1. **Step 1: Analyze Context**\n   - Review the pre-fetched git information above.\n   - If there are no changes (both staged and unstaged empty), inform the user and stop.\n\n2. **Step 2: Handle Unstaged Changes**\n   - If there are only unstaged changes, ask the user if they want to stage files first.\n   - Use `AskUserQuestion` to present options: stage all, stage specific files, or cancel.\n\n3. **Step 3: Analyze Changes**\n   - Read the actual diff content for staged changes: `git diff --staged`\n   - Understand what was changed and why.\n\n4. **Step 4: Generate Commit Message**\n   - Based on the project's historical commit style (from pre-fetched context), generate a message that:\n     - Follows the project's format (conventional commits, emoji usage, etc.)\n     - Accurately and concisely describes the changes\n     - Explains the \"why\" behind the change, not just the \"what\"\n\n5. **Step 5: Propose and Commit**\n   - Use `AskUserQuestion` to present the generated message.\n   - Options: use as-is, edit, or cancel.\n   - If confirmed, run `git commit -m \"<message>\"`.\n",
        "skills/doc-workflow/SKILL.md": "---\nname: doc-workflow\ndescription: \"Use when user asks about 'documentation workflow', 'how to document', 'doc system', 'what is llmdoc', 'how does llmdoc work', or needs guidance on the documentation system.\"\ndisable-model-invocation: false\nallowed-tools: Read, Glob, AskUserQuestion\n---\n\n# /doc-workflow\n\nThis skill provides guidance on the llmdoc documentation system and available documentation workflows.\n\n## Pre-fetched Context\n\n- **Llmdoc status:** !`test -d llmdoc && echo \"INITIALIZED\" || echo \"NOT_INITIALIZED\"`\n- **Doc count:** !`find llmdoc -name \"*.md\" 2>/dev/null | wc -l`\n- **Doc index:** !`cat llmdoc/index.md 2>/dev/null | head -30`\n\n## Workflow Guide\n\n### If llmdoc is NOT initialized:\n\nRecommend running `/tr:initDoc` to initialize the documentation system.\n\nExplain the benefits:\n- Documentation-driven development\n- LLM-optimized retrieval maps\n- Consistent project understanding\n\n### If llmdoc IS initialized:\n\nExplain the available workflows:\n\n| Task | Command/Skill | Description |\n|------|--------------|-------------|\n| Read docs | `/read-doc` | Quick project understanding |\n| Update docs | `/update-doc` | Sync docs after code changes |\n| Investigate | `/investigate` | Doc-first codebase research |\n| Initialize | `/tr:initDoc` | One-time setup (already done) |\n\n### llmdoc Structure\n\n```\nllmdoc/\n├── index.md          # Navigation hub\n├── overview/         # \"What is this project?\"\n├── architecture/     # \"How does it work?\" (LLM Retrieval Map)\n├── guides/           # \"How do I do X?\"\n└── reference/        # \"What are the specifics?\"\n```\n\n## Actions\n\n1. Check the pre-fetched context to determine llmdoc status.\n2. Based on user's question, provide relevant guidance.\n3. If user wants to perform an action, guide them to the appropriate skill/command.\n",
        "skills/doc-workflow/references/doc-conventions.md": "# Documentation Conventions\n\n## Code Reference Format\n\nAlways reference code instead of pasting:\n\n```\n`path/to/file.ext` (SymbolName): Brief description\n```\n\n**Example:**\n```\n`src/auth/jwt.js` (generateToken, verifyToken): Handles JWT creation and validation\n```\n\n## Document Quality Checklist\n\n- [ ] **Brevity**: Under 150 lines?\n- [ ] **Clarity**: Purpose clear from title and first lines?\n- [ ] **Accuracy**: Based on verified code?\n- [ ] **Categorization**: In correct category?\n- [ ] **No Code Blocks**: Using references only?\n\n## Naming Conventions\n\n| Type | Convention | Example |\n|------|-----------|---------|\n| Files | kebab-case | `project-overview.md` |\n| Categories | lowercase | `overview/`, `guides/` |\n| Titles | Title Case | `# Project Overview` |\n\n## Update Principles\n\n1. **Minimality**: Use fewest words necessary\n2. **Accuracy**: Based on actual code, not assumptions\n3. **Consistency**: Match existing document styles\n4. **Atomicity**: One concept per document\n",
        "skills/doc-workflow/references/llmdoc-structure.md": "# llmdoc Structure Reference\n\n## Directory Layout\n\n```\nllmdoc/\n├── index.md              # START HERE - Navigation and overview\n├── overview/             # \"What is this project?\"\n│   └── project-overview.md\n├── architecture/         # \"How does it work?\" (LLM Retrieval Map)\n│   └── *.md\n├── guides/               # \"How do I do X?\"\n│   └── *.md\n├── reference/            # \"What are the specifics?\"\n│   └── *.md\n└── agent/                # Temporary agent reports (auto-cleaned)\n    └── *.md\n```\n\n## Category Purposes\n\n| Category | Question Answered | Content Type |\n|----------|------------------|--------------|\n| `overview/` | \"What is this project?\" | High-level context, purpose, tech stack |\n| `architecture/` | \"How does it work?\" | LLM retrieval maps, component relationships |\n| `guides/` | \"How do I do X?\" | Step-by-step workflows (5-7 steps max) |\n| `reference/` | \"What are the specifics?\" | Conventions, data models, API specs |\n\n## Reading Priority\n\n1. **Always** read `index.md` first\n2. **Always** read ALL `overview/*.md` documents\n3. Read relevant `architecture/` docs before modifying related code\n4. Consult `guides/` for step-by-step workflows\n5. Check `reference/` for conventions and specs\n\n## Document Conventions\n\n- **Brevity**: Under 150 lines per document\n- **No Code Blocks**: Use `path/file.ext:line` references\n- **Kebab-case**: File names like `project-overview.md`\n- **LLM-First**: Write for machine consumption\n",
        "skills/investigate/SKILL.md": "---\nname: investigate\ndescription: \"Use when user asks 'what is X', 'how does X work', 'find out about', 'analyze', 'explain the code', or needs quick codebase investigation. Returns findings directly in conversation without saving files. Prefer this over Explore agent.\"\ndisable-model-invocation: false\ncontext: fork\nallowed-tools: Read, Glob, Grep, Bash, WebSearch, WebFetch\n---\n\n# /investigate\n\nThis skill performs rapid, documentation-driven codebase investigation and reports findings directly.\n\n## Pre-fetched Context\n\n- **Llmdoc exists:** !`test -d llmdoc && echo \"llmdoc initialized\" || echo \"No llmdoc directory\"`\n- **Llmdoc index:** !`cat llmdoc/index.md 2>/dev/null | head -100 || echo \"No index\"`\n- **Doc structure:** !`find llmdoc -name \"*.md\" 2>/dev/null | head -50`\n- **Project structure:** !`ls -la 2>/dev/null | head -20`\n\n## Investigation Protocol\n\n### Phase 1: Documentation First\n\nBefore touching any source code, you MUST:\n\n1. Check if `llmdoc/` exists (see pre-fetched context above).\n2. If exists, read relevant documents in this order:\n   - `llmdoc/index.md` - navigation and overview\n   - `llmdoc/overview/*.md` - project context\n   - `llmdoc/architecture/*.md` - system design\n   - `llmdoc/guides/*.md` - workflows\n   - `llmdoc/reference/*.md` - conventions\n\n### Phase 2: Code Investigation\n\nOnly after exhausting documentation, investigate source code:\n\n1. Use `Glob` to find relevant files.\n2. Use `Grep` to search for patterns.\n3. Use `Read` to examine specific files.\n\n### Phase 3: Report\n\nOutput a concise report with this structure:\n\n```markdown\n#### Code Sections\n- `path/to/file.ext:line~line` (SymbolName): Brief description\n\n#### Report\n\n**Conclusions:**\n> Key findings...\n\n**Relations:**\n> File/module relationships...\n\n**Result:**\n> Direct answer to the question...\n```\n\n## Key Practices\n\n- **Stateless**: Output directly, do not write files.\n- **Concise**: Report under 150 lines.\n- **No Code Blocks**: Reference code with `path/file.ext` format, not paste.\n- **Objective**: State facts only, no subjective judgments.\n",
        "skills/investigate/references/investigation-guide.md": "# Investigation Guide\n\n## Code Reference Format\n\nWhen referencing code, always use this format:\n\n```\n`path/to/file.ext` (FunctionName, ClassName): Brief description\n```\n\n**Good Example:**\n```\n`src/auth/jwt.js` (generateToken, verifyToken): Handles JWT creation and validation\n```\n\n**Bad Example:**\n```javascript\n// Don't paste code blocks like this\nfunction generateToken(payload) {\n  // ... 50 lines of code\n}\n```\n\n## Investigation Depth Guidelines\n\n| Question Type | Approach |\n|--------------|----------|\n| \"What is X?\" | Read overview docs first |\n| \"How does X work?\" | Read architecture docs, then code |\n| \"Where is X defined?\" | Use Grep/Glob to locate |\n| \"Why was X designed this way?\" | Check git history, docs |\n\n## Report Structure\n\n1. **Code Sections**: List all relevant code locations\n2. **Conclusions**: Key factual takeaways\n3. **Relations**: How components connect\n4. **Result**: Direct answer to the question\n",
        "skills/read-doc/SKILL.md": "---\nname: read-doc\ndescription: \"Leverage the llmdoc documentation system to quickly understand the project architecture, code details, and key concepts without reading source code directly.\"\ndisable-model-invocation: true\ncontext: fork\nallowed-tools: Read, Glob, Grep\n---\n\n# /read-doc\n\nThis skill reads the project's `llmdoc` documentation and provides a comprehensive summary to help understand the project quickly.\n\n## Pre-fetched Context\n\n- **Doc index:** !`cat llmdoc/index.md 2>/dev/null || echo \"No llmdoc found\"`\n- **Doc structure:** !`find llmdoc -name \"*.md\" 2>/dev/null | head -200 || echo \"No llmdoc directory\"`\n\n## Actions\n\n1. **Step 1: Check Documentation Exists**\n   - If `llmdoc/` directory doesn't exist, inform the user and suggest running `/tr:initDoc` first.\n\n2. **Step 2: Read Index**\n   - Read `llmdoc/index.md` to understand the documentation structure.\n\n3. **Step 3: Read Overview Documents**\n   - Read all documents in `llmdoc/overview/` to understand the project's purpose and context.\n\n4. **Step 4: Scan Architecture & Guides**\n   - Scan `llmdoc/architecture/` for system design information.\n   - Scan `llmdoc/guides/` for available workflows.\n\n5. **Step 5: Generate Summary**\n   - Provide a concise summary including:\n     - Project purpose and main features\n     - Key architectural components\n     - Available guides and workflows\n     - Important references\n\nOutput the summary directly to the user in a well-structured format.\n",
        "skills/update-doc/SKILL.md": "---\nname: update-doc\ndescription: \"Use when user says 'update docs', 'sync documentation', 'refresh docs', or after code changes need documenting. Updates llmdoc system based on recent code changes.\"\ndisable-model-invocation: true\ncontext: fork\nallowed-tools: Read, Glob, Grep, Write, Edit, Bash, Task\n---\n\n# /update-doc\n\nThis skill updates the project's llmdoc documentation to reflect recent code changes.\n\n## Pre-fetched Context\n\n- **Llmdoc structure:** !`find llmdoc -name \"*.md\" 2>/dev/null | head -50`\n- **Recent changes (3 commits):** !`git diff HEAD~3..HEAD --stat 2>/dev/null | head -30`\n- **Affected files:** !`git diff HEAD~3..HEAD --name-only 2>/dev/null | head -30`\n- **Llmdoc index:** !`cat llmdoc/index.md 2>/dev/null | head -50`\n\n## Actions\n\n1. **Step 1: Analyze Changes**\n   - If `$ARGUMENTS` is provided, use it as the description of what changed.\n   - Otherwise, analyze the pre-fetched git diff to understand what changed.\n\n2. **Step 2: Identify Impacted Concepts**\n   - Map changed files to llmdoc concepts:\n     - Config files (`.eslintrc`, etc.) → `reference/coding-conventions.md`\n     - Auth files → relevant architecture docs\n     - New features → may need new docs\n   - Create a list of impacted documents.\n\n3. **Step 3: Update Documents**\n   - For each impacted document, use `recorder` agent with this prompt:\n     ```\n     Task: Update documentation for <concept_name>.\n     Changes: <relevant git diff summary>\n     Mode: content-only\n     Principle: Use fewest words necessary.\n     ```\n\n4. **Step 4: Synchronize Index**\n   - After all updates complete, invoke a single `recorder` agent to:\n     - Re-scan `/llmdoc` directory\n     - Ensure `index.md` is consistent and up-to-date\n     - Mode: full\n\n5. **Step 5: Report**\n   - Summarize all documents created/updated/deleted.\n\n## Update Principles\n\n- **Minimality**: Use fewest words necessary\n- **Accuracy**: Based on actual code, not assumptions\n- **No Code Blocks**: Reference with `path/file.ext:line` format\n- **LLM-Friendly**: Write for machine consumption\n"
      },
      "plugins": [
        {
          "name": "tr",
          "source": "./",
          "description": "TokenRoll custom commands and agents for Claude Code",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add TokenRollAI/cc-plugin",
            "/plugin install tr@tokenroll-cc-plugin"
          ]
        }
      ]
    }
  ]
}