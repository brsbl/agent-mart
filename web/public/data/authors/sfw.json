{
  "author": {
    "id": "sfw",
    "display_name": "Scott Francis Winder",
    "avatar_url": "https://avatars.githubusercontent.com/u/63518?u=457fb4c42251ac02ffdf4061dcb844a095a4bb82&v=4"
  },
  "marketplaces": [
    {
      "name": "sfw-ALM",
      "version": null,
      "description": "Adaptive Learning Memory — Claude learns from corrections to get better at your recurring tasks",
      "repo_full_name": "sfw/ALM",
      "repo_url": "https://github.com/sfw/ALM",
      "repo_description": "Claude Code Learning Memory System",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-02-07T21:28:40Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"sfw-ALM\",\n  \"owner\": {\n    \"name\": \"Scott Francis Winder\",\n    \"email\": \"scott@hackedpodcast.com\",\n    \"url\": \"https://github.com/sfw\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"alm\",\n      \"source\": \"./\",\n      \"description\": \"Adaptive Learning Memory — Claude learns from corrections to get better at your recurring tasks\"\n    }\n  ]\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"alm\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Adaptive Learning Memory — Claude learns from corrections to get better at your recurring tasks\",\n  \"author\": {\n    \"name\": \"Scott Francis Winder\",\n    \"email\": \"scott@hackedpodcast.com\",\n    \"url\": \"https://github.com/sfw\"\n  },\n  \"repository\": \"https://github.com/sfw/ALM\",\n  \"license\": \"MIT\",\n  \"keywords\": [\"memory\", \"learning\", \"playbooks\", \"adaptive\", \"skill-acquisition\"]\n}\n",
        "README.md": "# ALM — Adaptive Learning Memory for Claude Code\n\nALM is a Claude Code plugin that helps Claude get better at your recurring tasks over time. It silently tracks session outcomes, detects when you correct Claude, and synthesizes what it learns into actionable playbooks that get injected into future sessions.\n\nNo API calls. No external services. All data stays local in `~/.claude/alm/`.\n\n## Why ALM?\n\nClaude starts every session from zero. If you correct the same mistake across sessions — say, Claude keeps writing verbose commit messages when you want terse ones — it has no way to remember that. ALM closes that loop:\n\n1. **Observe** — Each session, ALM classifies the task type and detects corrections (explicit requests to redo something, file re-edits, undo patterns).\n2. **Accumulate** — Outcomes and correction patterns are persisted as structured evaluation records.\n3. **Reflect** — When enough data exists, you trigger `/alm:reflect`. A dedicated subagent analyzes your correction history and writes concise playbooks capturing what Claude should do differently.\n4. **Inject** — On future sessions, the right playbook is injected into Claude's context before it starts working. Claude benefits from past lessons without you repeating yourself.\n\n## Quick Start\n\n```bash\n# Load ALM for one session (development mode)\nclaude --plugin-dir /path/to/alm\n\n# ALM activates automatically — you'll see a welcome message\n# Check it's working:\n/alm:status\n```\n\nSee [INSTALL.md](INSTALL.md) for persistent installation.\n\n## The Learning Timeline\n\n| Phase | Sessions | What Happens |\n|-------|----------|--------------|\n| Seed | 1 | ALM ships with curated best-practice playbooks for 8 common task types. Claude gets guidance immediately. |\n| Learning | 2-14 | ALM silently evaluates each session — classifying tasks, detecting corrections, recording outcomes. You see progress messages. |\n| Personalization | 15+ | Run `/alm:reflect` to generate playbooks derived from your actual correction patterns. Seed advice is replaced with learned strategies. |\n| Precision | 30+ | The TF-IDF classifier activates, matching each prompt to the most relevant playbook. Confidence scores calibrate injection — high-confidence types are skipped (Claude already knows). |\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `/alm:status` | Dashboard showing sessions tracked, confidence scores, classifier status, and stale playbook warnings |\n| `/alm:reflect` | Analyze correction patterns and generate/update personalized playbooks |\n| `/alm:review` | View recent evaluations and override misclassifications |\n| `/alm:pause` | Temporarily disable ALM evaluation and injection |\n| `/alm:resume` | Re-enable ALM after pausing |\n| `/alm:forget <type>` | Hard reset a specific task type — deletes its playbook, evaluations, and confidence data |\n| `/alm:export` | Export playbooks as standalone markdown for sharing or version control |\n| `/alm:reset` | Delete all ALM data and start fresh (requires confirmation) |\n\n## Configuration\n\nALM works with zero configuration. To customize, create `~/.claude/alm/config.json`:\n\n```json\n{\n  \"maxPlaybooksInjected\": 3,\n  \"confidenceThresholdForSkip\": 0.90,\n  \"dataRetentionDays\": 180,\n  \"showProgressMessages\": true,\n  \"enableProjectOverrides\": true\n}\n```\n\nAll keys are optional — missing keys use defaults. See [INSTALL.md](INSTALL.md) for the full list.\n\n## Project-Level Playbook Overrides\n\nTeams can share playbooks that override user-level playbooks for a specific project:\n\n```\nyour-project/.claude/alm/playbooks/api-design.md\n```\n\nWhen ALM detects a project-level playbook matching the classified task type, it injects that instead of the user-level one. The session output notes `[project override]`. Disable with `\"enableProjectOverrides\": false` in config.\n\n---\n\n## Architecture\n\nThis section covers ALM's internals for contributors and technical reviewers.\n\n### Plugin Structure\n\n```\nalm/\n├── .claude-plugin/\n│   └── plugin.json              # Plugin manifest (name, version, metadata)\n├── hooks/\n│   └── hooks.json               # 4 lifecycle hook registrations\n├── skills/                      # 8 user-invocable slash commands\n│   ├── status/SKILL.md\n│   ├── reflect/SKILL.md         # Spawns alm-reflector subagent (context: fork)\n│   ├── review/SKILL.md\n│   ├── pause/SKILL.md\n│   ├── resume/SKILL.md\n│   ├── forget/SKILL.md\n│   ├── export/SKILL.md\n│   └── reset/SKILL.md\n├── agents/\n│   └── alm-reflector.md         # Sonnet subagent for playbook synthesis\n├── scripts/                     # Hook implementations\n│   ├── inject-playbooks.sh      # SessionStart: inject playbooks into context\n│   ├── classify-and-inject.py   # UserPromptSubmit: TF-IDF classification + injection\n│   ├── evaluate-and-persist.py  # Stop: evaluate session, persist record\n│   ├── pre-compact.sh           # PreCompact: safeguard evaluation before compaction\n│   └── lib/                     # Shared Python modules\n│       ├── taxonomy.py          # Decision-tree task classifier (8 types)\n│       ├── corrections.py       # Correction detection (keywords, re-edits, undo patterns)\n│       ├── confidence.py        # Confidence scoring with time decay\n│       ├── tfidf.py             # Zero-dependency TF-IDF classifier\n│       ├── state.py             # State file management\n│       └── config.py            # Config with defaults\n└── seed-playbooks/              # 8 curated best-practice playbooks\n    ├── bug-fixing.md\n    ├── code-refactoring.md\n    ├── feature-implementation.md\n    ├── test-writing.md\n    ├── code-review.md\n    ├── api-design.md\n    ├── documentation.md\n    └── devops.md\n```\n\n### Hook Lifecycle\n\nALM registers 4 hooks that fire at different points in Claude's lifecycle:\n\n```\nSession start\n  │\n  ▼\nSessionStart hook (inject-playbooks.sh)\n  │  Injects seed or learned playbooks into additionalContext.\n  │  Shows welcome/progress messages. Checks pause state.\n  │\n  ▼\nUser submits prompt\n  │\n  ▼\nUserPromptSubmit hook (classify-and-inject.py)\n  │  If TF-IDF model exists: classify prompt → inject matching playbook.\n  │  Skips if confidence ≥ 0.90 (Claude already knows this type).\n  │  Falls through silently if no model yet.\n  │\n  ▼\n... Claude works ...\n  │\n  ▼\nContext compaction triggered\n  │\n  ▼\nPreCompact hook (pre-compact.sh)\n  │  Safeguard: runs a lightweight evaluation if none exists yet\n  │  for this session, so data isn't lost to compaction.\n  │\n  ▼\nSession ends\n  │\n  ▼\nStop hook (evaluate-and-persist.py)\n  │  Parses transcript. Classifies task type (decision tree).\n  │  Detects corrections. Calculates tool success rate.\n  │  Writes evaluation record to ~/.claude/alm/evaluations/{date}.jsonl.\n  │  Updates confidence scores. Checks auto-reflect queue.\n  │  Runs data retention archiving (once/day).\n```\n\nAll hooks exit 0 on any error — they never block Claude.\n\n### Evaluation Record\n\nEach session produces one JSONL record:\n\n```json\n{\n  \"id\": \"eval_1738900000_a1b2c3\",\n  \"timestamp\": \"2026-02-07T12:00:00Z\",\n  \"sessionId\": \"sess_abc123\",\n  \"taskType\": \"bug-fixing\",\n  \"outcome\": \"partial\",\n  \"correctionDetected\": true,\n  \"correctionType\": \"explicit\",\n  \"correctionSummary\": \"User asked to check error handling, not just the happy path\",\n  \"correctionContext\": { \"before\": \"...\", \"after\": \"...\" },\n  \"learning\": \"Always check error paths when fixing bugs\",\n  \"severity\": \"moderate\",\n  \"toolsUsed\": [\"Read\", \"Edit\", \"Bash\"],\n  \"toolSuccessRate\": 0.92,\n  \"transcriptLines\": 47,\n  \"promptText\": \"Fix the login bug where...\",\n  \"promptFingerprint\": \"Fix the login bug where... Read:auth.py Edit:auth.py\"\n}\n```\n\n### Task Classification\n\nThe decision-tree classifier (`taxonomy.py`) categorizes sessions into 8 types based on file extensions, tool usage patterns, and keyword analysis:\n\n- `bug-fixing` — debugging, error resolution, fixing broken behavior\n- `feature-implementation` — new functionality, adding capabilities\n- `code-refactoring` — restructuring without behavior change\n- `test-writing` — creating or updating tests\n- `code-review` — reviewing existing code, suggesting improvements\n- `api-design` — API endpoints, schemas, contracts\n- `documentation` — docs, READMEs, comments\n- `devops` — CI/CD, Docker, deployment, infrastructure\n\nSessions with fewer than 2 user messages and 0 tool calls are classified as `trivial` and skipped.\n\n### Confidence Scoring\n\nEach task type has a confidence score (0.0-1.0) that determines injection behavior:\n\n```\nscore = (1 - recentCorrectionRate) * familiarityFactor * recencyFactor * decayFactor\n```\n\n- **recentCorrectionRate** — corrections / outcomes in recent evaluations\n- **familiarityFactor** — `min(1.0, totalOutcomes / 20)` — ramps up with experience\n- **recencyFactor** — 1.0 within 14 days, decays 0.05/week after\n- **decayFactor** — `max(0.5, 1 - daysIdle/180)` — prevents stale high scores\n\nAutonomy levels: `novice` (<0.30) | `low` (0.30-0.59) | `medium` (0.60-0.84) | `high` (0.85+)\n\nWhen confidence reaches 0.90, playbook injection is skipped for that type — Claude has demonstrated mastery.\n\n### TF-IDF Classifier\n\nAfter `/alm:reflect` runs with 10+ training examples, a zero-dependency TF-IDF classifier (`tfidf.py`) is trained on prompt fingerprints (prompt text + first tool calls). On subsequent sessions, the `UserPromptSubmit` hook classifies the user's prompt and injects only the matching playbook, rather than the broad top-N approach used at session start.\n\n### Reflection\n\n`/alm:reflect` spawns the `alm-reflector` subagent (Sonnet) which:\n\n1. Loads all evaluations for eligible task types (5+ evals since last reflection)\n2. Identifies recurring correction patterns (3+ occurrences required for promotion)\n3. Extracts concrete anti-patterns from before/after correction context\n4. Synthesizes a playbook (max 800 tokens) with approach, preferences, anti-patterns, and quality criteria\n5. Detects cross-type patterns shared by 3+ types and extracts them to `_global.md`\n6. Retrains the TF-IDF classifier\n7. Updates confidence scores with `lastReflection` timestamps\n\n### Data Storage\n\nAll runtime data lives in `~/.claude/alm/`:\n\n```\n~/.claude/alm/\n├── evaluations/           # JSONL files, one per day (2026-02-07.jsonl)\n│   └── archive/           # Files older than dataRetentionDays (default 180)\n├── playbooks/             # Learned playbooks (created by /alm:reflect)\n│   ├── bug-fixing.md      # Per-type playbook\n│   └── _global.md         # Cross-type patterns (if any)\n├── classifier/\n│   └── model.json         # Serialized TF-IDF model\n├── confidence.json        # Per-type confidence scores\n├── state.json             # Pause state, install date, eval count\n├── config.json            # User configuration (optional)\n└── reflect-queue.json     # Task types queued for auto-reflection\n```\n\n### Privacy\n\n- **No network calls.** ALM makes zero HTTP requests. All classification and evaluation uses local heuristics.\n- **No LLM calls for evaluation.** The Stop hook uses a decision tree and keyword matching — no model inference at session end.\n- **Reflection uses Sonnet.** The `/alm:reflect` command spawns a Sonnet subagent that reads local data and writes local files. This is the only ALM operation that uses model inference.\n- **Data is local-only.** Everything is stored in `~/.claude/alm/` under the user's home directory.\n- **What ALM stores:** task type classifications, outcome assessments, correction signals, and the first prompt of each session (capped at 500 characters, used for TF-IDF training).\n- **What ALM does NOT store:** full transcripts, file contents, tool outputs, or any project source code.\n\n## Contributors\n\n- [Scott Francis Winder](https://github.com/sfw)\n- [Claude Code](https://claude.com/claude-code) (Anthropic)\n\n## License\n\nMIT\n"
      },
      "plugins": [
        {
          "name": "alm",
          "source": "./",
          "description": "Adaptive Learning Memory — Claude learns from corrections to get better at your recurring tasks",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add sfw/ALM",
            "/plugin install alm@sfw-ALM"
          ]
        }
      ]
    }
  ]
}