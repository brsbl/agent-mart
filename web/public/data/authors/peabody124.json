{
  "author": {
    "id": "peabody124",
    "display_name": "peabody124",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/618346?v=4",
    "url": "https://github.com/peabody124",
    "bio": null,
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 1,
      "total_skills": 8,
      "total_stars": 2,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "rae-marketplace",
      "version": null,
      "description": "Reproducible Agent Environment plugins for consistent AI-assisted development",
      "owner_info": {
        "name": "James Cotton"
      },
      "keywords": [],
      "repo_full_name": "peabody124/reproducible_agent_environment",
      "repo_url": "https://github.com/peabody124/reproducible_agent_environment",
      "repo_description": null,
      "homepage": null,
      "signals": {
        "stars": 2,
        "forks": 0,
        "pushed_at": "2026-01-29T07:21:46Z",
        "created_at": "2025-12-25T17:09:51Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".agent_setup_instructions",
          "type": "tree",
          "size": null
        },
        {
          "path": ".agent_setup_instructions/README.md",
          "type": "blob",
          "size": 546
        },
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 441
        },
        {
          "path": ".claude-plugin/plugin.json",
          "type": "blob",
          "size": 636
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 6379
        },
        {
          "path": "commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "commands/bead-driven-development.md",
          "type": "blob",
          "size": 826
        },
        {
          "path": "conductor",
          "type": "tree",
          "size": null
        },
        {
          "path": "conductor/README.md",
          "type": "blob",
          "size": 1646
        },
        {
          "path": "skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/bead-driven-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/bead-driven-development/SKILL.md",
          "type": "blob",
          "size": 6776
        },
        {
          "path": "skills/bead-driven-development/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/bead-driven-development/references/prompt-templates.md",
          "type": "blob",
          "size": 5681
        },
        {
          "path": "skills/config-improvement",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/config-improvement/SKILL.md",
          "type": "blob",
          "size": 2134
        },
        {
          "path": "skills/consult-guidelines",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/consult-guidelines/SKILL.md",
          "type": "blob",
          "size": 1905
        },
        {
          "path": "skills/datajoint-biomechanics-schema",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/datajoint-biomechanics-schema/SKILL.md",
          "type": "blob",
          "size": 10547
        },
        {
          "path": "skills/deslop",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/deslop/SKILL.md",
          "type": "blob",
          "size": 695
        },
        {
          "path": "skills/enforce-guidelines",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/enforce-guidelines/SKILL.md",
          "type": "blob",
          "size": 5217
        },
        {
          "path": "skills/pose-datajoint",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/pose-datajoint/SKILL.md",
          "type": "blob",
          "size": 11211
        },
        {
          "path": "skills/scaffold-repo",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/scaffold-repo/SKILL.md",
          "type": "blob",
          "size": 5320
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"rae-marketplace\",\n  \"description\": \"Reproducible Agent Environment plugins for consistent AI-assisted development\",\n  \"owner\": {\n    \"name\": \"James Cotton\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"rae\",\n      \"source\": \"./\",\n      \"description\": \"Core RAE skills: deslop, consult-guidelines, config-improvement, bead-driven-development, datajoint-biomechanics-schema, and coding standards\",\n      \"version\": \"1.0.4\"\n    }\n  ]\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"rae\",\n  \"description\": \"Reproducible Agent Environment: coding standards, deslop, quality enforcement, and datajoint-biomechanics-schema skills for consistent AI-assisted development\",\n  \"version\": \"1.0.4\",\n  \"author\": {\n    \"name\": \"James Cotton\"\n  },\n  \"homepage\": \"https://github.com/peabody124/reproducible_agent_environment\",\n  \"repository\": \"https://github.com/peabody124/reproducible_agent_environment\",\n  \"license\": \"MIT\",\n  \"keywords\": [\n    \"standards\",\n    \"tdd\",\n    \"deslop\",\n    \"guidelines\",\n    \"quality\",\n    \"python\",\n    \"best-practices\",\n    \"datajoint\",\n    \"biomechanics\",\n    \"pose-estimation\"\n  ]\n}\n",
        ".agent_setup_instructions/README.md": "# Agent Setup Instructions\n\nThis directory contains instructions for AI agents to properly configure themselves for RAE (Reproducible Agent Environment) development.\n\n**For agents:** Read and follow `setup-checklist.md` to ensure you're properly configured.\n\n**For humans:** This directory helps agents self-configure. You shouldn't need to do anything here.\n\n## Files\n\n- `setup-checklist.md` — Steps for agents to verify/install RAE\n- `verify-installation.md` — How to check RAE is working\n- `troubleshooting.md` — Common issues and fixes\n",
        "README.md": "# Reproducible Agent Environment (RAE)\n\nStandardized AI agent configurations for consistent development across projects. Supports both **Claude Code** and **Gemini CLI** with shared skills, SOPs, and coding standards.\n\n## Why RAE?\n\nJust as Docker standardizes runtime environments, RAE standardizes the context and tooling for AI agents working on your code. This means:\n\n- **Consistent behavior** across projects and agents\n- **Shared improvements** flow to all projects via sync\n- **Cross-agent compatibility** using skillz format\n- **Version-controlled workflows** that evolve with your practices\n- **Enforced guidelines** — not suggestions, requirements\n\n## Installation\n\n### Option 1: Claude Code Plugin (Recommended)\n\nInstall RAE as a native Claude Code plugin — no repo pollution:\n\n```bash\n# In Claude Code, add the marketplace\n/plugin marketplace add peabody124/reproducible_agent_environment\n\n# Install the RAE plugin\n/plugin install rae@rae-marketplace\n```\n\n### Option 2: User-Level Install (Dev Containers)\n\nInstalls RAE to your home directory only — nothing added to repos:\n\n```bash\ncurl -fsSL https://raw.githubusercontent.com/peabody124/reproducible_agent_environment/main/scripts/install-user.sh | bash\n```\n\nThis installs to:\n- `~/.claude/rae/` — Guidelines cache\n- `~/.skillz/` — Skills for Gemini/MCP\n- Claude Code plugin system\n\n**Use this for dev containers** — add to `postCreateCommand`.\n\n### Option 3: Full Bootstrap (Your Own Repos)\n\nSets up a repo with vendored guidelines and full RAE structure:\n\n```bash\ncurl -fsSL https://raw.githubusercontent.com/peabody124/reproducible_agent_environment/main/scripts/bootstrap.sh | bash\n```\n\nThis adds files to the repo:\n- `guidelines/` directory\n- `.claude/GLOBAL_INSTRUCTIONS.md`\n- `conductor/` directory\n\n**Use this only for repos you own** where you want versioned guidelines.\n\n### Option 4: With Devcontainers\n\nCopy `.devcontainer/devcontainer.json` to your project:\n\n```json\n{\n  \"postCreateCommand\": \"curl -fsSL .../install-user.sh | bash\"\n}\n```\n\nThe dev container auto-installs RAE at user level without modifying the project.\n\n## What's Included\n\n### Guidelines (`guidelines/`)\n\n| File | Purpose |\n|------|---------|\n| `coding-standards.md` | TDD mandate, DRY, fail-fast, configuration |\n| `python-standards.md` | ruff (120 chars), typing, coverage ≥80% |\n| `repo-structure.md` | Repository layout, pyproject.toml requirements |\n| `git-workflow.md` | Staging discipline, commit standards |\n| `anti-patterns.md` | \"Slop\" patterns to avoid |\n\n### Skills (`skills/`)\n\n| Skill | Purpose | Activation |\n|-------|---------|------------|\n| `enforce-guidelines` | Ensures all work follows RAE guidelines | **Auto** — before any code task |\n| `scaffold-repo` | Initialize new repo with correct structure | Manual |\n| `deslop` | Clean AI-generated slop from code changes | Manual |\n| `consult-guidelines` | Review relevant guidelines for task | Manual |\n| `config-improvement` | Propose improvements upstream | Manual |\n| `bead-driven-development` | Orchestrate planning + execution with beads tracking | Manual |\n\n### Bead-Driven Development Prerequisites\n\nThe `bead-driven-development` skill requires additional plugins:\n\n```bash\n# Install beads CLI and plugin\ncurl -fsSL https://raw.githubusercontent.com/steveyegge/beads/main/scripts/install.sh | bash\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n/plugin marketplace add steveyegge/beads\n/plugin install beads\n\n# Install superpowers (for writing-plans, executing-plans, investigation)\n/plugin marketplace add obra/superpowers-marketplace\n/plugin install superpowers@superpowers-marketplace\n\n# Initialize beads in your repo\nbd init\n```\n\n### Agent Self-Setup (`.agent_setup_instructions/`)\n\nInstructions for agents to self-configure:\n- `setup-checklist.md` — Step-by-step plugin installation\n- `verify-installation.md` — How to confirm RAE works\n- `troubleshooting.md` — Common issues and fixes\n\n## Key Standards\n\n### Python Projects\n\n- **Line length:** 120 characters (not 80, not 100)\n- **Coverage:** ≥80% required (enforced by pytest-cov)\n- **Layout:** `src/` directory with `tests/` mirroring structure\n- **Dependencies:** pytest, ruff in `[project.optional-dependencies] dev`\n\n```toml\n[project.optional-dependencies]\ndev = [\"pytest>=8.0\", \"pytest-cov>=4.0\", \"ruff>=0.8\"]\n\n[tool.coverage.report]\nfail_under = 80\n```\n\n### Workflow Enforcement\n\nRAE skills are inspired by [obra/superpowers](https://github.com/obra/superpowers) and [Gemini Conductor](https://github.com/gemini-cli-extensions/conductor):\n\n- **Guidelines are mandatory** — `enforce-guidelines` activates before any code task\n- **TDD is the default** — tests before implementation\n- **Verification required** — `ruff format && ruff check && pytest` before completion\n\n## Scripts\n\n| Script | Purpose | Modifies Repo? |\n|--------|---------|----------------|\n| `install-user.sh` | User-level only installation | No |\n| `bootstrap.sh` | Full repo setup with vendored guidelines | Yes |\n| `sync.sh` | Update RAE to latest version | Depends |\n\n## Upgrading\n\n```bash\n# User-level: re-run install\ncurl -fsSL .../install-user.sh | bash\n\n# Repo-level: sync script\n./scripts/sync.sh\n```\n\nOr update the Claude Code plugin:\n\n```bash\n# In Claude Code\n/plugin update rae@rae-marketplace\n```\n\n## Cross-Agent Compatibility\n\n| Method | Target | Location |\n|--------|--------|----------|\n| Claude Code Plugin | Claude Code native | Managed by plugin |\n| `~/.skillz/` | Gemini CLI, MCP | `~/.skillz/*/SKILL.md` |\n| `~/.claude/rae/` | Guidelines cache | `~/.claude/rae/guidelines/` |\n\nSkills use the [skillz](https://github.com/intellectronica/skillz) format, compatible with:\n\n- **Claude Code** — Native plugin support\n- **Gemini CLI** — Via [gemini-cli-skillz](https://github.com/intellectronica/gemini-cli-skillz)\n\n## Contributing\n\nDiscovered a better pattern? Use the `/config-improvement` skill or:\n\n1. Fork this repository\n2. Create a branch: `improve/<area>-<change>`\n3. Make your improvement with rationale\n4. Open a PR with before/after examples\n\n## Research References\n\n- [obra/superpowers](https://github.com/obra/superpowers) — Skill-driven TDD enforcement\n- [Gemini Conductor](https://github.com/gemini-cli-extensions/conductor) — Context-driven development\n- [Skillz](https://github.com/intellectronica/skillz) — MCP server for cross-agent skills\n\n## License\n\nMIT\n",
        "commands/bead-driven-development.md": "---\ndescription: Execute plan with beads tracking\nallowed-tools:\n  - Read\n  - Write\n  - Edit\n  - Grep\n  - Glob\n  - Bash(bd *)\n  - Bash(git add *)\n  - Bash(git commit *)\n  - Bash(git status)\n  - Bash(git diff *)\n  - Bash(git push *)\n  - Bash(git log *)\n  - Bash(mkdir *)\n  - Task\n  - TodoWrite\n  - Skill\n---\n\nUse the `rae:bead-driven-development` skill to orchestrate planning and execution with persistent beads tracking.\n\nThis command is for multi-task development workflows where you want:\n- Persistent task tracking across sessions (via beads)\n- Automatic skill orchestration (writing-plans, executing-plans, investigation)\n- Two-stage code review integration\n- Unified workspace organization in `scratch/{date}-plan-{topic}/`\n\n**Prerequisites:** beads CLI installed (`bd`), beads plugin active, superpowers plugin active.\n",
        "conductor/README.md": "# Conductor Context Directory\n\nThis directory contains context files for [Gemini Conductor](https://github.com/gemini-cli-extensions/conductor) and cross-agent workflow support.\n\n## Purpose\n\nThese files provide persistent project context that agents can reference:\n\n- **product.md** — Product vision, goals, and non-goals\n- **workflow.md** — Development workflow preferences and checklists\n- **tech-stack.md** — Technology choices and constraints\n\n## Cross-Agent Compatibility\n\nWhile Conductor is a Gemini CLI extension, the context files in this directory are plain markdown and can be referenced by any agent:\n\n- **Claude Code** — Reference these files in CLAUDE.md or read them directly\n- **Gemini CLI** — Use `conductor setup` to initialize, then `conductor new track` for features\n- **Other agents** — Read the markdown files for context\n\n## Integration with RAE\n\nThe bootstrap script creates starter templates for these files. Customize them for your project:\n\n```markdown\n# product.md\n## Vision\nA biomechanics analysis tool that...\n\n## Goals\n1. Accurate motion capture processing\n2. Real-time feedback\n3. Accessible to clinicians\n\n## Non-Goals\n- Gaming or entertainment applications\n- Consumer mobile apps\n```\n\n## Workflow with OpenCode-Conductor-Bridge\n\nFor projects using OpenCode, the [opencode-conductor-bridge](https://github.com/bardusco/opencode-conductor-bridge) enables the same Conductor workflows:\n\n1. Context stored in `conductor/` works across tools\n2. Commands translate between platforms\n3. Styleguides and templates are portable\n\nThis means your project context is portable across Claude, Gemini, and OpenCode.\n",
        "skills/bead-driven-development/SKILL.md": "---\nname: bead-driven-development\ndescription: >\n  This skill should be used when the user asks to \"execute plan with beads\",\n  \"implement with persistent tracking\", \"bead-driven execution\", \"run plan with subagents\",\n  \"track tasks across sessions\", \"use beads for planning\", or wants planning + subagents +\n  beads + code review unified. Orchestrates writing-plans, executing-plans, and investigation\n  skills with beads integration for persistent cross-session tracking.\n---\n\n# Bead-Driven Development\n\n## Overview\n\nThis skill orchestrates existing skills with beads integration. It provides prompt refinements rather than reimplementing functionality:\n- **writing-plans** → create plan + beads for major tasks\n- **executing-plans** → use subagents + track via beads\n- **investigation** → create blocking beads on failure, update plan\n\n**Announce at start:** \"I'm using the bead-driven-development skill to orchestrate planning and execution with persistent tracking.\"\n\n## Prerequisites\n\nThis skill requires beads and superpowers plugins. Install them first:\n\n### Install beads\n```bash\n# Install beads CLI\ncurl -fsSL https://raw.githubusercontent.com/steveyegge/beads/main/scripts/install.sh | bash\n\n# Install uv (Python package manager)\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Add beads marketplace and install plugin\n/plugin marketplace add steveyegge/beads\n/plugin install beads\n```\n\n### Install superpowers\n```bash\n/plugin marketplace add obra/superpowers-marketplace\n/plugin install superpowers@superpowers-marketplace\n```\n\n### Initialize beads in your repo\n```bash\nbd init\n```\n\n**Required skills from superpowers:**\n- writing-plans\n- executing-plans\n- investigation (or from ~/.claude/skills/)\n\n## Unified Workspace Convention\n\n**All phases share one workspace:** `scratch/{YYYY-MM-DD}-plan-{topic}/`\n\n```\nscratch/2026-01-18-plan-auth-system/\n├── README.md          ← Plan (Phase 1)\n├── scripts/           ← Temp scripts (Phase 2)\n└── debug/             ← Investigations (Phase 3)\n    └── bd-xxx/\n```\n\nBeads provide the commit history. Plan doesn't need to be committed separately.\n\n## Phase 1: Planning with Beads\n\nInvoke **writing-plans** skill with these additions:\n\n> \"Create plan in unified workspace following investigation pattern:\n> `scratch/{YYYY-MM-DD}-plan-{topic}/README.md`\n> Example: `scratch/2026-01-18-plan-auth-system/README.md`\n>\n> After finalizing the plan, create a bead for each major task:\n> ```bash\n> bd create 'Task 1: Component name' -t task\n> bd create 'Task 2: Next component' -t task\n> bd dep add <task-2-id> <task-1-id> --type blocks\n> ```\n>\n> Include bead IDs in the plan file for tracking.\n>\n> **Important**: Add a section in the plan noting:\n> - Temp scripts go in: `scratch/{date}-plan-{topic}/scripts/`\n> - Debug investigations go in: `scratch/{date}-plan-{topic}/debug/`\n> - Beads provide commit history (plan doesn't need to be committed)\n>\n> Note: TodoWrite will still be used for fine-grained in-session tracking.\"\n\n## Phase 2: Execution with Beads\n\nInvoke **executing-plans** skill with these additions:\n\n> \"Before starting each task:\n> 1. Run `bd ready` to find next unblocked task\n> 2. Mark bead in_progress: `bd update <id> --status in_progress`\n>\n> Use TodoWrite as normal for fine-grained step tracking within the task.\n>\n> **Workspace**: Put any temporary scripts, test outputs, or debugging artifacts\n> in the plan's scratch directory: `scratch/{date}-plan-{topic}/scripts/`\n>\n> After each successful task:\n> 1. Commit with bead ID: `git commit -m 'feat: description (bd-xxx)'`\n> 2. Add commit SHA to bead: `bd comment <id> 'Commit: <sha>'`\n> 3. Dispatch code-reviewer subagent (per subagent-driven-development two-stage review)\n> 4. If review passes: `bd close <id> --reason 'Implemented and reviewed'`\n> 5. Sync TodoWrite → bead status when marking task complete\n>\n> Run `bd sync` every 2-3 completed tasks to persist to git.\n>\n> **On failure** → transition to Phase 3 (Failure Recovery).\"\n\n## Phase 3: Failure Recovery with Beads\n\nWhen any task fails, invoke **investigation** skill with these additions:\n\n> **Step 1: Create blocking debug bead**\n> ```bash\n> bd create 'Debug: <issue description>' -t bug\n> bd dep add <failed-task-id> <debug-bead-id> --type blocks\n> ```\n>\n> **Step 2: Investigation in plan's scratch directory**\n> Create investigation subfolder:\n> `scratch/{date}-plan-{topic}/debug/{bead-id}/README.md`\n>\n> Or if separate investigation needed:\n> `scratch/{date}-debug-{bead-id}/README.md`\n>\n> Document findings, hypotheses, and tests in the investigation folder.\n>\n> **Step 3: Resolution**\n> Copy key findings summary to debug bead:\n> ```bash\n> bd comment <debug-id> 'Resolution: <summary of fix>'\n> ```\n>\n> If plan needs updates: edit `scratch/{date}-plan-{topic}/README.md` and note changes.\n>\n> If new tasks discovered:\n> ```bash\n> bd create 'New task from investigation' -t task --discovered-from <debug-id>\n> ```\n>\n> **Step 4: Resume**\n> Close debug bead:\n> ```bash\n> bd close <debug-id> --reason 'Resolved: <summary>'\n> ```\n>\n> Original task becomes unblocked.\n> Signal: \"Plan updated, resume from Task N with `bd ready`\"\n\n## Hybrid Tracking Model\n\n| Tool | Purpose | Scope |\n|------|---------|-------|\n| Beads | Major milestones/tasks | Cross-session persistence |\n| TodoWrite | Fine-grained steps | In-session tracking |\n\n**Sync rule**: When TodoWrite marks task complete → close corresponding bead.\n\n## Quick Reference\n\n| Command | Purpose |\n|---------|---------|\n| `bd ready` | Find next unblocked task |\n| `bd update <id> --status in_progress` | Mark task started |\n| `bd close <id> --reason '...'` | Mark task complete |\n| `bd comment <id> 'message'` | Add context to bead |\n| `bd dep add <id> <blocker> --type blocks` | Add dependency |\n| `bd sync` | Persist to git (every 2-3 tasks) |\n| `bd show <id>` | Get task context |\n\n## Workflow Summary\n\n```\nUser: \"execute this plan with beads\"\n           ↓\n[bead-driven-development loads]\n           ↓\nPhase 1: Invoke writing-plans + beads prompt\n  → Creates unified workspace\n  → Plan in README.md\n  → Creates beads for major tasks\n  → Adds blocks dependencies\n           ↓\nPhase 2: Invoke executing-plans + beads prompt\n  → Uses bd ready to pick next task\n  → Updates bead status + TodoWrite\n  → Commits with bead ID: (bd-xxx)\n  → Two-stage code review\n  → Close bead after review\n  → bd sync every 2-3 tasks\n           ↓\n(On failure) Phase 3: Invoke investigation + beads prompt\n  → Creates blocking debug bead\n  → Investigates in workspace: debug/{bead-id}/\n  → Copies findings to bead notes\n  → Updates README.md when resolved\n  → Resumes with bd ready\n```\n\n## See Also\n\n- `references/prompt-templates.md` - Exact copy-paste prompts for each skill\n",
        "skills/bead-driven-development/references/prompt-templates.md": "# Prompt Templates for Bead-Driven Development\n\nExact prompts to add when invoking each skill. All skills share the unified workspace.\n\n## Workspace Convention\n\n**Format:** `scratch/{YYYY-MM-DD}-plan-{topic}/`\n\n**Example:** `scratch/2026-01-18-plan-auth-system/`\n\n```\nscratch/2026-01-18-plan-auth-system/\n├── README.md          ← Plan document\n├── scripts/           ← Temporary scripts during execution\n└── debug/             ← Investigation folders\n    └── bd-xxx/        ← Per-bead debug investigation\n```\n\n---\n\n## 1. For writing-plans Skill\n\nAdd this prompt when invoking writing-plans:\n\n```\nBEAD-DRIVEN ADDITIONS:\n\n1. WORKSPACE: Create plan in unified workspace:\n   `scratch/{YYYY-MM-DD}-plan-{topic}/README.md`\n\n   Example: `scratch/2026-01-18-plan-auth-system/README.md`\n\n   Use today's date. Topic should be kebab-case, 2-4 words.\n\n2. BEADS: After finalizing the plan, create a bead for each major task:\n\n   bd create 'Task 1: [Component name]' -t task\n   bd create 'Task 2: [Next component]' -t task\n   bd create 'Task 3: [Another component]' -t task\n\n   Add dependencies where tasks must be sequential:\n   bd dep add <task-2-id> <task-1-id> --type blocks\n   bd dep add <task-3-id> <task-2-id> --type blocks\n\n3. PLAN HEADER: Add this section to the plan document:\n\n   ## Tracking\n\n   **Beads:**\n   - bd-xxx: Task 1 - [Component name]\n   - bd-yyy: Task 2 - [Next component]\n   - bd-zzz: Task 3 - [Another component]\n\n   **Workspace Layout:**\n   - Plan: `scratch/{date}-plan-{topic}/README.md`\n   - Scripts: `scratch/{date}-plan-{topic}/scripts/`\n   - Debug: `scratch/{date}-plan-{topic}/debug/`\n\n   **Note:** Beads provide commit history. Plan doesn't need to be committed.\n\n4. HYBRID TRACKING: TodoWrite will still be used for fine-grained in-session\n   step tracking. Beads track major milestones across sessions.\n```\n\n---\n\n## 2. For executing-plans Skill\n\nAdd this prompt when invoking executing-plans:\n\n```\nBEAD-DRIVEN ADDITIONS:\n\n1. BEFORE EACH TASK:\n   - Run `bd ready` to find next unblocked task\n   - Mark bead in_progress: `bd update <bead-id> --status in_progress`\n   - Use TodoWrite as normal for fine-grained steps\n\n2. WORKSPACE:\n   Put temporary scripts, test outputs, debugging artifacts in:\n   `scratch/{date}-plan-{topic}/scripts/`\n\n   Example: `scratch/2026-01-18-plan-auth-system/scripts/test_auth.py`\n\n3. AFTER EACH SUCCESSFUL TASK:\n\n   a. Commit with bead ID in message:\n      git commit -m 'feat: add authentication middleware (bd-xxx)'\n\n   b. Record commit SHA in bead:\n      bd comment <bead-id> 'Commit: abc1234'\n\n   c. Dispatch code-reviewer subagent (two-stage review):\n      - Stage 1: Verify implementation matches spec\n      - Stage 2: Check code quality and conventions\n\n   d. If review passes, close bead:\n      bd close <bead-id> --reason 'Implemented and reviewed'\n\n   e. Sync TodoWrite status with bead status\n\n4. SYNC CADENCE:\n   Run `bd sync` every 2-3 completed tasks to persist to git.\n\n5. ON FAILURE:\n   Stop execution and transition to Phase 3 (Failure Recovery):\n   - Create blocking debug bead\n   - Invoke investigation skill with bead additions\n   - Resume after resolution with `bd ready`\n```\n\n---\n\n## 3. For investigation Skill\n\nAdd this prompt when invoking investigation for failure recovery:\n\n```\nBEAD-DRIVEN ADDITIONS:\n\n1. CREATE BLOCKING DEBUG BEAD:\n\n   bd create 'Debug: [issue description]' -t bug\n\n   Add as blocker to the failed task:\n   bd dep add <failed-task-id> <debug-bead-id> --type blocks\n\n2. INVESTIGATION LOCATION:\n\n   Use the plan's scratch directory:\n   `scratch/{date}-plan-{topic}/debug/{bead-id}/README.md`\n\n   Example: `scratch/2026-01-18-plan-auth-system/debug/bd-abc/README.md`\n\n   If investigation is large/separate:\n   `scratch/{date}-debug-{bead-id}/README.md`\n\n3. INVESTIGATION README TEMPLATE:\n\n   # Debug: [Issue Description]\n\n   **Bead:** bd-xxx\n   **Blocking:** bd-yyy (Task N: [name])\n   **Date:** YYYY-MM-DD\n\n   ## Problem Statement\n   [What failed and how]\n\n   ## Hypotheses\n   1. [ ] Hypothesis A\n   2. [ ] Hypothesis B\n\n   ## Investigation Log\n   - [timestamp] Finding 1\n   - [timestamp] Finding 2\n\n   ## Resolution\n   [What fixed it]\n\n   ## Plan Updates\n   [Any changes needed to the main plan]\n\n4. RESOLUTION STEPS:\n\n   a. Copy key findings to bead:\n      bd comment <debug-id> 'Resolution: [summary of what fixed it]'\n\n   b. If plan needs updates:\n      Edit `scratch/{date}-plan-{topic}/README.md`\n      Note what changed and why\n\n   c. If new tasks discovered:\n      bd create 'New task: [description]' -t task --discovered-from <debug-id>\n\n5. RESUME:\n\n   Close debug bead:\n   bd close <debug-id> --reason 'Resolved: [one-line summary]'\n\n   Original task becomes unblocked.\n\n   Signal to continue: \"Plan updated, resume from Task N with `bd ready`\"\n```\n\n---\n\n## Quick Reference Card\n\n### Bead Commands\n\n| Action | Command |\n|--------|---------|\n| Find next task | `bd ready` |\n| Start task | `bd update <id> --status in_progress` |\n| Add note | `bd comment <id> 'message'` |\n| Complete task | `bd close <id> --reason 'description'` |\n| Add blocker | `bd dep add <blocked> <blocker> --type blocks` |\n| Persist | `bd sync` |\n| View task | `bd show <id>` |\n\n### Commit Message Format\n\n```\n<type>: <description> (bd-xxx)\n\nTypes: feat, fix, refactor, test, docs\nBead ID always in parentheses at end\n```\n\n### Workspace Paths\n\n| Purpose | Path |\n|---------|------|\n| Plan | `scratch/{date}-plan-{topic}/README.md` |\n| Scripts | `scratch/{date}-plan-{topic}/scripts/` |\n| Debug | `scratch/{date}-plan-{topic}/debug/{bead-id}/` |\n\n### Sync Cadence\n\n- `bd sync` every 2-3 completed tasks\n- Always sync before ending session\n- Sync after resolving any debug bead\n",
        "skills/config-improvement/SKILL.md": "---\nname: config-improvement\ndescription: Propose improvements to upstream RAE repository\n---\n\n## Overview\n\nWhen you discover a better pattern, configuration, or guideline during work, this skill guides you through proposing it upstream to the Reproducible Agent Environment repository.\n\n## Parameters\n\n- **improvement_type** (optional): \"guideline\", \"skill\", \"sop\", \"config\", or \"template\"\n- **description** (required): Brief description of the improvement\n\n## Steps\n\n### 1. Evaluate Scope\n\nDetermine if the improvement is universal or project-specific.\n\n**Constraints:**\n- You MUST verify the improvement works in the current project\n- You MUST check if a similar pattern already exists upstream\n- You SHOULD consider if the improvement applies broadly or only to specific domains\n\n**Decision:**\n- IF universal → Proceed to step 2\n- IF project-specific → Add to local overrides with comment explaining why, then STOP\n\n### 2. Document the Improvement\n\nPrepare a clear description of the change.\n\n**Constraints:**\n- You MUST include before/after examples\n- You MUST explain the rationale (why is this better?)\n- You SHOULD reference any research or sources that informed the improvement\n- You MUST specify which file(s) would be modified\n\n### 3. Create Upstream PR\n\n**Constraints:**\n- You MUST create a branch with descriptive name (e.g., `improve/ruff-config`, `guideline/async-patterns`)\n- You MUST write a clear commit message explaining the improvement\n- You SHOULD include test cases or examples if applicable\n- You MUST open PR with the documented rationale\n\n### 4. Update Local\n\nAfter PR is merged:\n- Run `scripts/sync.sh` to pull the improvement\n- Verify it works correctly in your project\n\n## Examples\n\n**User:** \"I found a better ruff configuration for catching common issues\"\n**Agent:** Evaluates if it's universal (yes), documents the change with before/after examples, creates PR to update templates/pyproject.toml.\n\n**User:** \"/config-improvement guideline 'Add guidance on async/await patterns'\"\n**Agent:** Checks if async guidance exists (no), drafts new section for python-standards.md, creates PR with examples.\n",
        "skills/consult-guidelines/SKILL.md": "---\nname: consult-guidelines\ndescription: Review relevant guidelines before starting a task\n---\n\n## Overview\n\nRead and internalize the coding guidelines relevant to the current task. This ensures consistent application of standards across all work.\n\n## Parameters\n\n- **task_type** (optional): \"python\", \"git\", \"refactor\", \"debug\", \"review\", or \"all\"\n\n## Steps\n\n### 1. Determine Relevant Guidelines\n\nBased on task type, identify which guidelines to review.\n\n**Mapping:**\n- `python` → coding-standards.md, python-standards.md\n- `git` → git-workflow.md\n- `refactor` → coding-standards.md, anti-patterns.md\n- `debug` → coding-standards.md (TDD section)\n- `review` → anti-patterns.md, coding-standards.md\n- `all` → all guidelines\n\n**Constraints:**\n- You MUST read `guidelines/coding-standards.md` for any code changes\n- You MUST read `guidelines/python-standards.md` for Python work\n- You MUST read `guidelines/git-workflow.md` before any commits\n- You SHOULD read `guidelines/anti-patterns.md` before code review or refactoring\n\n### 2. Summarize Key Points\n\nExtract the 3-5 most relevant rules for the current task.\n\n**Constraints:**\n- You MUST highlight any MUST/MUST NOT constraints\n- You SHOULD note any task-specific gotchas\n\n### 3. Apply During Work\n\nKeep these guidelines in mind while executing the task. Reference them when making decisions.\n\n**Constraints:**\n- You MUST cite the relevant guideline when it influences a decision\n- You SHOULD flag if you discover a case not covered by guidelines\n\n## Examples\n\n**User:** \"I'm about to refactor the auth module\"\n**Agent:** Reads coding-standards.md and anti-patterns.md, summarizes DRY principles and slop patterns to avoid, proceeds with refactor while citing guidelines.\n\n**User:** \"/consult-guidelines python\"\n**Agent:** Reviews coding-standards.md and python-standards.md, extracts key rules about ruff, type hints, and path management.\n",
        "skills/datajoint-biomechanics-schema/SKILL.md": "---\nname: datajoint-biomechanics-schema\ndescription: Use when working with biomechanics DataJoint pipeline - querying KinematicReconstruction, understanding Video-Session relationships, using bridging algorithms, debugging schema issues across PosePipeline/MultiCameraTracking/BodyModels, or working with method 137 results\n---\n\n# DataJoint Biomechanics Schema Reference\n\n## Overview\n\nThe biomechanics pipeline uses DataJoint across four repositories with **two complementary data collection approaches**:\n\n1. **Multi-Camera (MMC)** - Lab-based with calibrated camera rigs → `MultiCameraTracking` + `BodyModels/kinematic_dj.py`\n2. **Portable/Monocular (PBL)** - Smartphone videos with optional IMU → `PortableBiomechanicsSessions` + `BodyModels/monocular_dj.py`\n\nBoth produce the same output format: **qpos, qvel, joints, sites** from MuJoCo body models.\n\n---\n\n## DataJoint Query Basics\n\n### Operators\n| Operator | Meaning | Example |\n|----------|---------|---------|\n| `&` | Restrict (filter) | `(Table & {'field': value})` |\n| `*` | Join tables | `(Table1 * Table2)` |\n| `-` | Set difference | `(Table1 - Table2)` finds rows NOT in Table2 |\n| `.proj()` | Select attributes | `Table.proj('field1', 'field2')` |\n\n### Fetch Patterns\n```python\n# fetch1() - Exactly one row, returns tuple or dict\ntimestamps, qpos = (KinematicReconstruction.Trial & key).fetch1('timestamps', 'qpos')\n\n# fetch() - Multiple rows, returns arrays\nall_keys = (Session & filter).fetch('KEY')\nkeypoints = (TopDownPerson & key).fetch('keypoints')\n\n# With ordering (critical for multi-camera consistency)\nkp, names = (Table & key).fetch('keypoints', 'camera_name', order_by='camera_name')\n```\n\n---\n\n## Filtering by Project and Participant\n\n### video_project Field\n\n`video_project` is a categorical field (varchar(50)) that identifies the study/cohort. It lives in `MultiCameraRecording` and `Video` tables.\n\n**Common projects:**\n| Project | Description |\n|---------|-------------|\n| `GAIT_CONTROLS` | Healthy control gait data |\n| `PROSTHETIC_GAIT` | Prosthetic gait subjects |\n| `CM_GAIT` | Cervical myelopathy gait |\n| `CLINIC_GAIT` | Clinical gait assessment |\n| `PEDIATRIC_GAIT` | Pediatric subjects |\n| `ASB2024` | ASB conference dataset |\n\n### Query Patterns by Project\n\n```python\n# List all unique projects\nprojects = np.unique((MultiCameraRecording).fetch(\"video_project\"))\n\n# Find all participants in a project\nparticipants = (Session & (Recording & (MultiCameraRecording & 'video_project=\"GAIT_CONTROLS\"'))).fetch(\"participant_id\")\n\n# Filter trials by project\ntrials = KinematicReconstruction.Trial & (Recording & (MultiCameraRecording & f\"video_project='{project}'\"))\n\n# Multiple projects with IN clause\nfilt = 'video_project in (\"CLINIC_GAIT\", \"GAIT_CONTROLS\", \"PROSTHETIC_GAIT\")'\nsessions = Session & (Recording * MultiCameraRecording & filt)\n```\n\n### Participant Naming Conventions\n\n| Project Type | Format | Examples |\n|--------------|--------|----------|\n| ASB studies | `ASB_###` | ASB_001, ASB_022 |\n| Numeric IDs | integers | 72, 504, 127 |\n| Special codes | mapped | TF01, TF02, TF47 |\n\n### Session → Video Path (via video_project)\n```\nSession (participant_id, session_date)\n    → Recording → MultiCameraRecording (video_project)\n        → SingleCameraVideo → Video (video_project, filename)\n```\n\n---\n\n## Key Output Fields Reference\n\n| Field | Table | Shape | Description |\n|-------|-------|-------|-------------|\n| **qpos** | KinematicReconstruction.Trial | (T, 41) | Joint angles in generalized coordinates (radians) |\n| **qvel** | KinematicReconstruction.Trial | (T, 41) | Joint velocities (rad/s) |\n| **joints** | KinematicReconstruction.Trial | (T, N_joints, 3) | 3D joint positions (mm) |\n| **sites** | KinematicReconstruction.Trial | (T, N_sites, 3) | 3D anatomical markers (mm) |\n| **keypoints** | TopDownPerson | (T, N_kpts, 3) | 2D keypoints [x, y, conf] |\n| **keypoints3d** | PersonKeypointReconstruction | (T, N_kpts, 4) | 3D keypoints [x, y, z, conf] (mm) |\n| **keypoints_3d** | LiftingPerson | (T, N_kpts, 4) | Lifted 3D from monocular [x, y, z, conf] |\n| **timestamps** | VideoInfo | list[datetime] | Absolute frame times |\n| **delta_time** | VideoInfo | (T,) | Seconds from first frame |\n| **fps** | VideoInfo | float | Frames per second |\n\n### Common Access Patterns\n```python\n# Get 2D keypoints with video info\ntimestamps, keypoints = (TopDownPerson * VideoInfo & key).fetch1('timestamps', 'keypoints')\n\n# Get kinematic reconstruction (ALWAYS specify method!)\nqpos, sites = (KinematicReconstruction.Trial & key &\n               {'kinematic_reconstruction_settings_num': 137}).fetch1('qpos', 'sites')\n\n# Get 3D triangulated keypoints\nkp3d = (PersonKeypointReconstruction & key).fetch1('keypoints3d')\n```\n\n---\n\n## Two Data Collection Approaches\n\n### 1. Multi-Camera (MMC) → KinematicReconstruction\n\n**Key space:** `(participant_id, session_date)` bridged to `(recording_timestamps, camera_config_hash)`\n\n```\nSession → Recording → MultiCameraRecording → SingleCameraVideo → Video\n                   ↘ SessionCalibration.Grouping → Calibration\n                                     ↓\nVideo → TopDownPerson → PersonKeypointReconstruction (3D triangulation)\n                                     ↓\n                   KinematicReconstruction.Trial (qpos, qvel, joints, sites)\n```\n\n**Bridge Tables:**\n- `Recording` - Links Session → MultiCameraRecording\n- `SingleCameraVideo` - Links MultiCameraRecording → Video\n- `SessionCalibration.Grouping` - Links Session → Calibration (required for KinematicReconstruction)\n\n**Use when:** Lab-based data, multiple synchronized cameras, highest accuracy needed.\n\n### 2. Portable/Monocular (PBL) → MonocularReconstruction\n\n**Key space:** `(subject_id, session_start_time)` via Firebase\n\n```\nSubject → Session → Session.FirebaseSessionInfo\n                              ↓\n                    FirebaseSession (Computed)\n                              ↓\n            ┌─────────────────┼─────────────────┐\n       AppVideo           Attitude/Gyro      PhoneAttitude\n     (→ Video)            (IMU sensors)      (phone quaternion)\n            ↓\n    TopDownPerson → LiftingPerson (3D lifting)\n                              ↓\n            MonocularReconstruction.Trial (qpos, qvel, joints, sites, rnc)\n```\n\n**Additional output:** `rnc` (T, 3) - camera rotation vector from phone attitude\n\n**Use when:** Smartphone videos, remote/home monitoring, wearable IMU/EMG data.\n\n### Comparison\n\n| Aspect | Multi-Camera | Monocular |\n|--------|--------------|-----------|\n| Input | Multiple synced cameras | Single smartphone camera |\n| 3D Method | Triangulation | 2D→3D lifting |\n| Accuracy | ~10-15mm, ~2-5° | ~15-20mm, ~5-10° |\n| qpos DOF | 41 | 40 |\n| Extra data | updated_calibration | rnc (phone rotation), IMU/EMG |\n| Schema | `kinematic_dj.py` | `monocular_dj.py` |\n\n---\n\n## Method Numbers by Pipeline\n\n**CRITICAL:** Always specify the method number in queries to avoid duplicates.\n\n| Pipeline | Table | Method Field | Default Method |\n|----------|-------|--------------|----------------|\n| Multi-Camera | KinematicReconstruction | `kinematic_reconstruction_settings_num` | **137** |\n| Monocular | MonocularReconstruction | `monocular_reconstruction_settings_num` | **1** |\n\n### Multi-Camera: Method 137\n```python\n# CORRECT - Always specify method for KinematicReconstruction\nkey = {'participant_id': '102', 'session_date': date(2023, 7, 21),\n       'kinematic_reconstruction_settings_num': 137}  # CRITICAL!\n\n# WRONG - Returns BOTH 130 and 137 for dual-processed participants\nkey = {'participant_id': '102', 'session_date': date(2023, 7, 21)}\n```\n\n**Dual-processed participants (have both 130 and 137):**\nASB_022, ASB_007, ASB_008, ASB_020, ASB_041, ASB_071, ASB_081, ASB_083, ASB_085, ASB_095, ASB_125, ASB_130\n\n**Method 137 config:** humanoid_torque_rl.xml, floor leveling enabled, 40k iterations\n\n### Monocular: Method 1\n```python\n# For MonocularReconstruction queries\nkey = {'subject_id': 123, 'session_start_time': ...,\n       'monocular_reconstruction_settings_num': 1}\n```\n\n---\n\n## Bridging Algorithm\n\nBottom-up MeTRAbs detection inserted into top-down tables:\n\n```\nMeTRAbs (580 keypoints) → BottomUpBridging → BottomUpBridgingPerson\n    ↓ filter_skeleton(\"bml_movi_87\") → indices 264-350\nTopDownPerson (method=\"Bridging_bml_movi_87\")\n    ↓ re-fetch from BottomUpBridging (not TopDownPerson!)\nLiftingPerson (method=\"Bridging_bml_movi_87\")\n```\n\n**Why \"weird\":** LiftingPerson normally uses TopDownPerson, but for bridging it re-fetches directly from BottomUpBridging.\n\n---\n\n## Quick Reference: Key Files\n\n| Task | File |\n|------|------|\n| Video/VideoInfo/TopDownPerson | `PosePipeline/pose_pipeline/pipeline.py` |\n| Bridging algorithm | `PosePipeline/pose_pipeline/wrappers/bridging.py` |\n| MultiCameraRecording/SingleCameraVideo | `MultiCameraTracking/multi_camera/datajoint/multi_camera_dj.py` |\n| Session/Recording (MMC) | `MultiCameraTracking/multi_camera/datajoint/sessions.py` |\n| SessionCalibration | `MultiCameraTracking/multi_camera/datajoint/session_calibrations.py` |\n| PersonKeypointReconstruction | `MultiCameraTracking/multi_camera/datajoint/multi_camera_dj.py` |\n| KinematicReconstruction | `BodyModels/body_models/datajoint/kinematic_dj.py` |\n| MonocularReconstruction | `BodyModels/body_models/datajoint/monocular_dj.py` |\n| FirebaseSession/AppVideo (PBL) | `PortableBiomechanicsSessions/portable_biomechanics_sessions/emgimu_session.py` |\n| PBL↔MMC linkage | `PortableBiomechanicsSessions/portable_biomechanics_sessions/mmc_linkage.py` |\n| DataJoint principles | `PipelineOrchestrator/docs/datajoint_principles.md` |\n\n---\n\n## Common Mistakes\n\n1. **Missing method number** - Queries without `kinematic_reconstruction_settings_num=137` return duplicates\n2. **Wrong key space** - Using `(video_project, filename)` when you need `(participant_id, session_date)`\n3. **Assuming LiftingPerson uses TopDownPerson** - For bridging methods, it re-fetches from BottomUpBridging\n4. **Missing SessionCalibration.Grouping** - KinematicReconstruction requires this bridge\n5. **Forgetting order_by** - Multi-camera queries need `order_by='camera_name'` for consistent ordering\n6. **Confusing MonocularReconstruction vs KinematicReconstruction** - Monocular uses FirebaseSession.AppVideo, Kinematic uses SessionCalibration.Recordings\n7. **Not filtering by video_project** - Queries across all projects mix different populations; always filter to your target cohort\n",
        "skills/deslop/SKILL.md": "---\nname: deslop\ndescription: Use a subagent to review the code change and remove AI generated slop\n---\n\nCheck the diff against main, and remove all AI generated slop introduced in the\noutstanding code changes, most recent commit, or branch based on the user instructions.\n\nThis includes:\n- Extra comments that a human wouldn't add or is inconsistent with the rest of the file\n- Extra defensive checks or try/catch blocks that are abnormal for that area of the codebase (especially if called by trusted / validated codepaths)\n- Casts to `Any` to get around type issues\n- Any other style that is inconsistent with the file\n\nReport at the end with only a 1-3 sentence summary of what you changed.\n",
        "skills/enforce-guidelines/SKILL.md": "---\nname: enforce-guidelines\ndescription: Mandatory skill that ensures all work follows RAE guidelines. Activates automatically before any code task.\n---\n\n## The Iron Law\n\n**IF A GUIDELINE APPLIES TO YOUR TASK, YOU DO NOT HAVE A CHOICE. YOU MUST FOLLOW IT.**\n\nThis is not a suggestion. Guidelines are requirements. Violations require correction before work is considered complete.\n\n## When This Skill Activates\n\nThis skill activates automatically when:\n\n- Writing Python code → `python-standards.md`, `coding-standards.md`\n- Creating a new repository → `repo-structure.md`\n- Making commits → `git-workflow.md`\n- Reviewing or refactoring code → `anti-patterns.md`\n- Any code changes → `coding-standards.md`\n\n**You MUST check for applicable guidelines before starting any task.** Even a 1% chance a guideline applies means you consult it.\n\n## Decision Flow\n\nBefore responding to ANY code-related request:\n\n```\n1. What type of task is this?\n   └─→ Identify: python, git, new-repo, refactor, debug, review\n\n2. Which guidelines apply?\n   └─→ Map task type to required guidelines (see mapping below)\n\n3. Read the applicable guidelines\n   └─→ Actually read them, don't assume you know the content\n\n4. Extract MUST/MUST NOT constraints\n   └─→ These are non-negotiable requirements\n\n5. Proceed with task, citing guidelines when they influence decisions\n```\n\n## Where to Find Guidelines\n\nGuidelines are bundled with the RAE plugin. Look for them in order of precedence:\n\n1. **Project-local:** `./guidelines/*.md` (if vendored)\n2. **Plugin bundle:** Bundled with RAE plugin installation\n3. **RAE repository:** https://github.com/peabody124/reproducible_agent_environment/tree/main/guidelines\n\nIf you cannot find guidelines, check `.agent_setup_instructions/` for setup help.\n\n## Guideline Mapping\n\n| Task Type | Required Guidelines |\n|-----------|-------------------|\n| Any Python code | `python-standards.md`, `coding-standards.md` |\n| New repository | `repo-structure.md`, `python-standards.md` |\n| Git operations | `git-workflow.md` |\n| Refactoring | `anti-patterns.md`, `coding-standards.md` |\n| Code review | `anti-patterns.md`, `python-standards.md` |\n| Bug fixes | `coding-standards.md` (TDD section) |\n| New features | `coding-standards.md`, `python-standards.md` |\n\n## Red Flags (Rationalization Detection)\n\nThese thoughts indicate you're trying to skip guidelines:\n\n| Thought | Reality |\n|---------|---------|\n| \"This is just a quick fix\" | Quick fixes still follow guidelines |\n| \"I already know the standards\" | Read them anyway, they may have changed |\n| \"This is too simple to need guidelines\" | Simple code still needs type hints and formatting |\n| \"I'll fix it later\" | Fix it now, there is no later |\n| \"The user didn't ask for TDD\" | TDD is the default, not optional |\n| \"100 chars is close enough to 120\" | Line length is 120, configure ruff correctly |\n\n## Enforcement Mechanism\n\n### Before Starting Work\n\n1. **Identify task type** from the mapping above\n2. **Read applicable guidelines** - actually open and read them\n3. **Extract key constraints** - list the MUST/MUST NOT rules\n4. **Acknowledge constraints** - state which rules apply to this task\n\n### During Work\n\n1. **Cite guidelines** when they influence a decision\n2. **Check compliance** before completing each step\n3. **Run verification commands** (ruff, pytest) as guidelines require\n\n### Before Completing Work\n\n1. **Run all required checks**: `ruff format . && ruff check . && pytest`\n2. **Verify coverage**: pytest runs with `--cov` by default, coverage must be ≥80%\n3. **Verify against checklist** from applicable guidelines\n4. **Confirm no violations** remain\n\n## Constraints\n\n- You MUST read guidelines before starting code tasks\n- You MUST cite the specific guideline when it influences a decision\n- You MUST NOT skip guidelines because the task seems simple\n- You MUST NOT proceed if guideline compliance is unclear\n- You MUST run `ruff format` and `ruff check` before completing Python work\n- You MUST run `pytest` if tests exist\n- You SHOULD flag if you discover a case not covered by guidelines\n\n## Verification Checklist\n\nBefore marking any code task complete:\n\n- [ ] Identified applicable guidelines\n- [ ] Read the guidelines (not just remembered them)\n- [ ] Listed MUST constraints that apply\n- [ ] Followed all MUST constraints\n- [ ] Avoided all MUST NOT patterns\n- [ ] Ran `ruff format` on changed files\n- [ ] Ran `ruff check` with no errors\n- [ ] Ran `pytest` with coverage ≥80%\n- [ ] No anti-patterns from `anti-patterns.md`\n\n**Cannot check all boxes? Work is not complete.**\n\n## Examples\n\n**User:** \"Add a helper function to parse dates\"\n\n**Agent (correct):**\n> This is Python code, so I need to consult `python-standards.md` and `coding-standards.md`.\n>\n> Key constraints:\n> - MUST use type hints for function signatures\n> - MUST run ruff format/check\n> - SHOULD write test first (TDD)\n>\n> Let me write a failing test first, then implement...\n\n**Agent (incorrect):**\n> Sure, here's a quick function:\n> ```python\n> def parse_date(s):\n>     return datetime.strptime(s, \"%Y-%m-%d\")\n> ```\n\nThe incorrect response skips guidelines consultation, misses type hints, and doesn't run verification.\n",
        "skills/pose-datajoint/SKILL.md": "---\nname: pose-datajoint\ndescription: Use when writing Python code to query biomechanics DataJoint tables - counting videos/sessions, filtering by video_project or participant_id/subject_id, fetching keypoints or kinematic reconstructions, understanding Session-Video relationships for both multi-camera and monocular pipelines\n---\n\n# Pose DataJoint Query Reference\n\n## Overview\n\nThe biomechanics pipeline has **two parallel systems**:\n1. **Multi-Camera (MMC)** - Lab-based, multiple synchronized cameras, uses `participant_id` (string)\n2. **Monocular (PBL)** - Phone-based portable recordings, uses `subject_id` (integer)\n\nBoth produce kinematic outputs (qpos, joints, sites) but have different table hierarchies.\n\n## Quick Reference: Package Imports\n\n```python\n# Shared: Video and 2D/3D pose estimation\nfrom pose_pipeline.pipeline import Video, VideoInfo, TopDownPerson, LiftingPerson\n\n# === MULTI-CAMERA (MMC) ===\nfrom multi_camera.datajoint.sessions import Session, Recording, Subject\nfrom multi_camera.datajoint.multi_camera_dj import (\n    MultiCameraRecording, SingleCameraVideo, PersonKeypointReconstruction\n)\nfrom body_models.datajoint.kinematic_dj import KinematicReconstruction\n\n# === MONOCULAR (PBL) ===\nfrom portable_biomechanics_sessions.emgimu_session import (\n    Subject as PBLSubject,      # Note: different from MMC Subject!\n    Session as PBLSession,      # Note: different from MMC Session!\n    FirebaseSession\n)\nfrom body_models.datajoint.monocular_dj import MonocularReconstruction\n```\n\n## Key Spaces (CRITICAL - Different Per Pipeline!)\n\n### Multi-Camera Key Space\n```python\n# Session: participant_id is STRING\nsession_key = {'participant_id': '104', 'session_date': date(2023, 7, 21)}\n\n# Video: video_project + filename\nvideo_key = {'video_project': 'CLINIC_GAIT', 'filename': 'trial_001.27.mp4'}\n```\n\n### Monocular Key Space\n```python\n# Subject/Session: subject_id is INTEGER, project is part of key\nsubject_key = {'subject_id': 301, 'project': 'HLL'}\n\n# Session adds timestamp\nsession_key = {'subject_id': 301, 'project': 'HLL',\n               'session_start_time': datetime(2024, 1, 15, 10, 30, 0)}\n\n# AppVideo links to Video table\napp_video_key = {**session_key, 'app_start_time': ...,\n                 'video_project': 'HLL', 'filename': '0301_gait.mp4'}\n```\n\n## DataJoint Operators\n\n| Operator | Meaning | Example |\n|----------|---------|---------|\n| `&` | Restrict (filter) | `Video & 'video_project=\"HLL\"'` |\n| `*` | Join tables | `Session * Recording * MultiCameraRecording` |\n| `-` | Set difference | `Video - TopDownPerson` (videos without poses) |\n| `.proj()` | Select attributes | `Table.proj('field1', 'field2')` |\n\n## Fetching Data\n\n```python\n# fetch1() - Exactly ONE row (raises error if 0 or >1)\ntimestamps, qpos = (Table & key).fetch1('timestamps', 'qpos')\n\n# fetch() - Multiple rows as arrays\nall_keys = (Table & restriction).fetch('KEY')  # List of dicts\nvalues = (Table & key).fetch('field_name')     # Numpy array\n\n# fetch(as_dict=True) - Multiple rows as list of dicts\nrecords = (Table & key).fetch(as_dict=True)\n```\n\n---\n\n## Multi-Camera (MMC) Queries\n\n### Count Videos in MMC Project\n```python\nfrom pose_pipeline.pipeline import Video\nfrom multi_camera.datajoint.multi_camera_dj import MultiCameraRecording, SingleCameraVideo\n\n# Videos linked to multi-camera recordings\ncount = len(Video & SingleCameraVideo & (MultiCameraRecording & 'video_project=\"CLINIC_GAIT\"'))\n```\n\n### Count Sessions/Participants in MMC\n```python\nfrom multi_camera.datajoint.sessions import Session, Recording\nfrom multi_camera.datajoint.multi_camera_dj import MultiCameraRecording\nimport numpy as np\n\n# Sessions for a participant (participant_id is STRING!)\ncount = len(Session & {'participant_id': '104'})\n\n# Unique participants in a project\nparticipants = np.unique(\n    (Session & (Recording & (MultiCameraRecording & 'video_project=\"CLINIC_GAIT\"'))).fetch('participant_id')\n)\nprint(f\"Participants: {len(participants)}\")\n```\n\n### Get MMC Kinematic Reconstruction\n```python\nfrom body_models.datajoint.kinematic_dj import KinematicReconstruction\nfrom datetime import date\n\n# CRITICAL: Always specify kinematic_reconstruction_settings_num!\nkey = {\n    'participant_id': '102',\n    'session_date': date(2023, 7, 21),\n    'kinematic_reconstruction_settings_num': 137  # REQUIRED!\n}\n\ntimestamps, qpos, joints, sites = (KinematicReconstruction.Trial & key).fetch1(\n    'timestamps', 'qpos', 'joints', 'sites'\n)\n# qpos: (T, 41) joint angles in radians\n# joints: (T, N_bodies, 3) body positions in meters\n# sites: (T, N_sites, 3) marker positions in meters\n```\n\n### Get 3D Triangulated Keypoints (MMC)\n```python\nfrom multi_camera.datajoint.multi_camera_dj import PersonKeypointReconstruction\n\nkey = {\n    'video_project': 'CLINIC_GAIT',\n    'video_base_filename': 'trial_20231215_143022',\n    'reconstruction_method': 0  # 0=Robust Triangulation\n}\nkeypoints3d = (PersonKeypointReconstruction & key).fetch1('keypoints3d')\n# Shape: (T, N_joints, 4) - [x, y, z, confidence], units: mm\n```\n\n---\n\n## Monocular (PBL) Queries\n\n### Count Videos in Monocular Project\n```python\nfrom portable_biomechanics_sessions.emgimu_session import FirebaseSession\n\n# AppVideo is a Part table of FirebaseSession\ncount = len(FirebaseSession.AppVideo & {'video_project': 'HLL'})\nprint(f\"HLL monocular videos: {count}\")\n```\n\n### Count Subjects in Monocular Project\n```python\nfrom portable_biomechanics_sessions.emgimu_session import FirebaseSession\nimport numpy as np\n\n# Get unique subject_ids for a project\nsubject_ids = np.unique(\n    (FirebaseSession.AppVideo & {'video_project': 'HLL'}).fetch('subject_id')\n)\nprint(f\"Subjects with HLL videos: {len(subject_ids)}\")\n```\n\n### Count Monocular Videos Processed with Kinematic Reconstruction\n```python\nfrom portable_biomechanics_sessions.emgimu_session import FirebaseSession\nfrom body_models.datajoint.monocular_dj import MonocularReconstruction\n\n# Videos that have monocular reconstruction\nprocessed = len(\n    FirebaseSession.AppVideo\n    & (MonocularReconstruction.Trial & {'video_project': 'HLL'})\n)\nprint(f\"HLL videos with monocular reconstruction: {processed}\")\n\n# Videos NOT yet processed\nall_videos = FirebaseSession.AppVideo & {'video_project': 'HLL'}\nunprocessed = len(all_videos - MonocularReconstruction.Trial)\nprint(f\"HLL videos needing processing: {unprocessed}\")\n```\n\n### Get Monocular Kinematic Reconstruction\n```python\nfrom body_models.datajoint.monocular_dj import MonocularReconstruction\nfrom datetime import datetime\n\n# Monocular uses subject_id (INTEGER) and project\nkey = {\n    'subject_id': 301,\n    'project': 'HLL',\n    'session_start_time': datetime(2024, 1, 15, 10, 30, 0),\n    'monocular_reconstruction_settings_num': 1  # Specify method\n}\n\n# Get all trials for this session\ntrial_keys = (MonocularReconstruction.Trial & key).fetch('KEY')\n\nfor trial_key in trial_keys:\n    timestamps, qpos, joints, sites, rnc = (MonocularReconstruction.Trial & trial_key).fetch1(\n        'timestamps', 'qpos', 'joints', 'sites', 'rnc'\n    )\n    # qpos: (T, 40) joint angles - monocular has 40 DOF (vs 41 for MMC)\n    # rnc: (T, 3) camera rotation vector from phone attitude\n    print(f\"Video: {trial_key['filename']}, frames: {len(timestamps)}\")\n```\n\n### List Monocular Projects\n```python\nfrom portable_biomechanics_sessions.emgimu_session import FirebaseSession\nimport numpy as np\n\nprojects = np.unique(FirebaseSession.AppVideo.fetch('video_project'))\nprint(f\"Monocular projects: {projects}\")\n```\n\n---\n\n## Shared Queries (Work for Both Pipelines)\n\n### Get 2D Keypoints\n```python\nfrom pose_pipeline.pipeline import TopDownPerson\n\nkey = {\n    'video_project': 'HLL',  # Works for any project\n    'filename': 'trial_001.mp4',\n    'video_subject_id': 0,\n    'top_down_method': 0  # 0=MMPose\n}\nkeypoints = (TopDownPerson & key).fetch1('keypoints')  # Shape: (T, N_joints, 3)\n```\n\n### Get 3D Lifted Keypoints\n```python\nfrom pose_pipeline.pipeline import LiftingPerson\n\nkey = {**video_key, 'video_subject_id': 0, 'top_down_method': 0, 'lifting_method': 1}\nkeypoints_3d = (LiftingPerson & key).fetch1('keypoints_3d')  # Shape: (T, N_joints, 4)\n```\n\n### Count All Videos by Project\n```python\nfrom pose_pipeline.pipeline import Video\nfrom collections import Counter\n\nprojects = Video.fetch('video_project')\nfor project, count in Counter(projects).items():\n    print(f\"{project}: {count} videos\")\n```\n\n---\n\n## Table Relationships\n\n### Multi-Camera Hierarchy\n```\nSubject (participant_id)  ← STRING\n    -> Session (participant_id, session_date)\n        -> Recording -> MultiCameraRecording (video_project)\n                            -> SingleCameraVideo -> Video\n                            -> PersonKeypointReconstruction (3D triangulated)\n        -> SessionCalibration.Grouping\n            -> KinematicReconstruction (method 137)\n                -> KinematicReconstruction.Trial (qpos, joints, sites)\n```\n\n### Monocular Hierarchy\n```\nSubject (subject_id, project)  ← INTEGER + project\n    -> Session (subject_id, project, session_start_time)\n        -> FirebaseSession\n            -> FirebaseSession.AppVideo -> Video\n            -> FirebaseSession.PhoneAttitude (phone orientation)\n            -> FirebaseSession.Gyro/Accel/Mag (IMU data)\n\nMonocularReconstruction (subject_id, project, session_start_time, method)\n    -> MonocularReconstruction.Trial (qpos, joints, sites, rnc)\n        -> FirebaseSession.AppVideo (links video)\n```\n\n---\n\n## Common Mistakes\n\n| Mistake | Fix |\n|---------|-----|\n| MMC: `{'subject_id': 104}` | Use `{'participant_id': '104'}` (string!) |\n| PBL: `{'participant_id': '301'}` | Use `{'subject_id': 301}` (integer!) |\n| `Keypoints2D` table | Use `TopDownPerson` for 2D keypoints |\n| Missing method for KinematicReconstruction | Add `'kinematic_reconstruction_settings_num': 137` |\n| Missing method for MonocularReconstruction | Add `'monocular_reconstruction_settings_num': 1` |\n| `fetch(unique=True)` | Use `np.unique(table.fetch('field'))` |\n| `create_virtual_module()` | Direct import from modules |\n| Mixing MMC Session with PBL Session | Import with alias: `Session as PBLSession` |\n\n---\n\n## Method Numbers Reference\n\n| Pipeline | Table | Method Field | Default |\n|----------|-------|--------------|---------|\n| 2D Pose | TopDownPerson | `top_down_method` | 0 (MMPose) |\n| 3D Lifting | LiftingPerson | `lifting_method` | 1 (VideoPose3D) |\n| 3D Triangulation (MMC) | PersonKeypointReconstruction | `reconstruction_method` | 0 |\n| Multi-Camera Kinematic | KinematicReconstruction | `kinematic_reconstruction_settings_num` | **137** |\n| Monocular Kinematic | MonocularReconstruction | `monocular_reconstruction_settings_num` | **1** |\n\n---\n\n## Files to Explore\n\n| Task | File |\n|------|------|\n| Video/TopDownPerson | `PosePipeline/pose_pipeline/pipeline.py` |\n| MMC Session/Recording | `MultiCameraTracking/multi_camera/datajoint/sessions.py` |\n| MMC MultiCameraRecording | `MultiCameraTracking/multi_camera/datajoint/multi_camera_dj.py` |\n| MMC KinematicReconstruction | `BodyModels/body_models/datajoint/kinematic_dj.py` |\n| PBL Subject/Session/FirebaseSession | `PortableBiomechanicsSessions/portable_biomechanics_sessions/emgimu_session.py` |\n| PBL MonocularReconstruction | `BodyModels/body_models/datajoint/monocular_dj.py` |\n",
        "skills/scaffold-repo/SKILL.md": "---\nname: scaffold-repo\ndescription: Initialize a new Python repository with correct structure following RAE guidelines\n---\n\n## Overview\n\nThis skill creates a properly structured Python repository from scratch. It enforces `guidelines/repo-structure.md` requirements automatically.\n\n**Use when:**\n- Creating a new Python project\n- Converting an unstructured project to proper layout\n- User says \"new repo\", \"new project\", \"initialize\", \"scaffold\"\n\n## Parameters\n\n- **name** (required): Project name (lowercase, hyphens allowed)\n- **description** (required): One-line project description\n- **package_name** (optional): Python package name (defaults to name with underscores)\n- **author** (optional): Author name (defaults to \"James Cotton\")\n- **extras** (optional): Additional optional-dependencies groups to include\n\n## Steps\n\n### 1. Validate Inputs\n\n**Constraints:**\n- You MUST verify project name is lowercase with hyphens only\n- You MUST derive package_name from project name (replace hyphens with underscores)\n- You MUST NOT proceed without a description\n\n### 2. Create Directory Structure\n\nCreate the required structure:\n\n```bash\nmkdir -p src/{package_name}\nmkdir -p tests\ntouch src/{package_name}/__init__.py\ntouch src/{package_name}/py.typed\ntouch tests/__init__.py\n```\n\n**Constraints:**\n- You MUST use src/ layout\n- You MUST create both src/ and tests/ directories\n- You MUST include py.typed marker for type hint support\n\n### 3. Create pyproject.toml\n\nGenerate pyproject.toml following `guidelines/repo-structure.md`:\n\n```toml\n[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n\n[project]\nname = \"{name}\"\nversion = \"0.1.0\"\ndescription = \"{description}\"\nreadme = \"README.md\"\nrequires-python = \">=3.11\"\nlicense = \"MIT\"\nauthors = [\n    { name = \"{author}\", email = \"your@email.com\" }\n]\ndependencies = []\n\n[project.optional-dependencies]\ndev = [\n    \"pytest>=8.0\",\n    \"pytest-cov>=4.0\",\n    \"ruff>=0.8\",\n]\n\n[tool.hatch.build.targets.wheel]\npackages = [\"src/{package_name}\"]\n\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\npythonpath = [\"src\"]\naddopts = [\"-ra\", \"-q\", \"--strict-markers\", \"--cov=src\", \"--cov-report=term-missing\", \"--cov-branch\"]\n\n[tool.coverage.run]\nomit = [\"*/__init__.py\", \"*/tests/*\", \"*/config.py\"]\n\n[tool.coverage.report]\nfail_under = 80\nshow_missing = true\n\n[tool.ruff]\nline-length = 120\ntarget-version = \"py311\"\nsrc = [\"src\", \"tests\"]\n\n[tool.ruff.lint]\nselect = [\"E\", \"W\", \"F\", \"I\", \"B\", \"C4\", \"UP\", \"ARG\", \"SIM\"]\nignore = [\"E501\"]\n\n[tool.ruff.lint.isort]\nknown-first-party = [\"{package_name}\"]\n\n[tool.ruff.format]\nquote-style = \"double\"\nindent-style = \"space\"\n```\n\n**Constraints:**\n- You MUST set line-length = 120\n- You MUST put pytest and ruff in dev optional-dependencies\n- You MUST NOT put dev tools in main dependencies\n\n### 4. Create .gitignore\n\n```gitignore\n# Python\n__pycache__/\n*.py[cod]\n*.egg-info/\ndist/\nbuild/\n.eggs/\n\n# Virtual environments\n.venv/\nvenv/\nENV/\n\n# IDE\n.idea/\n.vscode/\n*.swp\n\n# Testing\n.pytest_cache/\n.coverage\nhtmlcov/\n\n# RAE\nscraps/\n.rae-version\n\n# OS\n.DS_Store\nThumbs.db\n```\n\n### 5. Create README.md\n\n```markdown\n# {name}\n\n{description}\n\n## Installation\n\n```bash\nuv pip install -e \".[dev]\"\n```\n\n## Development\n\n```bash\n# Run tests\npytest\n\n# Format code\nruff format .\n\n# Lint code\nruff check .\n```\n\n## License\n\nMIT\n```\n\n### 6. Create Initial Test\n\nCreate `tests/test_placeholder.py`:\n\n```python\n\"\"\"Placeholder test to verify pytest works.\"\"\"\n\n\ndef test_placeholder() -> None:\n    \"\"\"Remove this test once real tests exist.\"\"\"\n    assert True\n```\n\n**Constraints:**\n- You MUST include type hints (-> None)\n- You MUST include a docstring\n- This ensures pytest runs successfully from the start\n\n### 7. Initialize Git (if not already)\n\n```bash\ngit init\ngit add .\ngit commit -m \"feat: Initialize {name} with RAE structure\"\n```\n\n**Constraints:**\n- You MUST NOT commit if already in a git repo with uncommitted changes\n- You SHOULD offer to commit but confirm with user first\n\n### 8. Verify Structure\n\nRun verification:\n\n```bash\nruff format .\nruff check .\npytest\n```\n\n**Constraints:**\n- You MUST run ruff format before completing\n- You MUST run ruff check with no errors\n- You MUST run pytest with all tests passing\n\n## Adding Optional Dependencies\n\nIf user requests specific libraries, add appropriate optional-dependencies:\n\n**OpenCV:**\n```toml\n[project.optional-dependencies]\nopencv = [\"opencv-python>=4.0.0\"]\nopencv-headless = [\"opencv-python-headless>=4.0.0\"]\nopencv-contrib = [\"opencv-contrib-python>=4.0.0\"]\n```\n\n**PyTorch:**\n```toml\n[project.optional-dependencies]\ntorch-cpu = [\"torch>=2.0\"]\ntorch-cuda = [\"torch>=2.0\"]  # User installs with CUDA separately\n```\n\n**Jupyter:**\n```toml\n[project.optional-dependencies]\nnotebooks = [\"jupyter>=1.0\", \"ipykernel>=6.0\"]\n```\n\n## Examples\n\n**User:** \"/scaffold-repo my-analysis-tool A tool for analyzing motion capture data\"\n\n**Agent:**\n1. Creates directory structure\n2. Generates pyproject.toml with name=\"my-analysis-tool\", package=\"my_analysis_tool\"\n3. Creates .gitignore, README.md\n4. Creates placeholder test\n5. Runs ruff format, ruff check, pytest\n6. Reports success with next steps\n\n**User:** \"/scaffold-repo cv-processor Image processing pipeline --extras opencv-headless\"\n\n**Agent:**\n1. Creates standard structure\n2. Adds opencv-headless to optional-dependencies\n3. Completes verification\n"
      },
      "plugins": [
        {
          "name": "rae",
          "source": "./",
          "description": "Core RAE skills: deslop, consult-guidelines, config-improvement, bead-driven-development, datajoint-biomechanics-schema, and coding standards",
          "version": "1.0.4",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add peabody124/reproducible_agent_environment",
            "/plugin install rae@rae-marketplace"
          ]
        }
      ]
    }
  ]
}