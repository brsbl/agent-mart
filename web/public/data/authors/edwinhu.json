{
  "author": {
    "id": "edwinhu",
    "display_name": "Edwin Hu",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/174409?v=4",
    "url": "https://github.com/edwinhu",
    "bio": null,
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 2,
      "total_commands": 8,
      "total_skills": 43,
      "total_stars": 3,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "edwinhu-plugins",
      "version": null,
      "description": "Development, data science, and writing workflows for Claude Code",
      "owner_info": {
        "name": "Edwin Hu"
      },
      "keywords": [],
      "repo_full_name": "edwinhu/workflows",
      "repo_url": "https://github.com/edwinhu/workflows",
      "repo_description": null,
      "homepage": null,
      "signals": {
        "stars": 3,
        "forks": 0,
        "pushed_at": "2026-01-27T14:41:50Z",
        "created_at": "2026-01-04T02:46:52Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 1075
        },
        {
          "path": ".claude-plugin/plugin.json",
          "type": "blob",
          "size": 255
        },
        {
          "path": ".claude",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude/commands/dev.md",
          "type": "blob",
          "size": 336
        },
        {
          "path": ".claude/commands/ds.md",
          "type": "blob",
          "size": 333
        },
        {
          "path": ".copilot",
          "type": "tree",
          "size": null
        },
        {
          "path": ".copilot/README.md",
          "type": "blob",
          "size": 5024
        },
        {
          "path": ".opencode",
          "type": "tree",
          "size": null
        },
        {
          "path": ".opencode/README.md",
          "type": "blob",
          "size": 8770
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 11479
        },
        {
          "path": "commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "commands/checkpoint.md",
          "type": "blob",
          "size": 1237
        },
        {
          "path": "commands/dev.md",
          "type": "blob",
          "size": 349
        },
        {
          "path": "commands/ds.md",
          "type": "blob",
          "size": 350
        },
        {
          "path": "commands/writing.md",
          "type": "blob",
          "size": 295
        },
        {
          "path": "hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "hooks/hooks.json",
          "type": "blob",
          "size": 1671
        },
        {
          "path": "hooks/image-read-guard.py",
          "type": "blob",
          "size": 1789
        },
        {
          "path": "hooks/lint-check.py",
          "type": "blob",
          "size": 5229
        },
        {
          "path": "hooks/pr-url-logger.py",
          "type": "blob",
          "size": 2439
        },
        {
          "path": "hooks/pre-compact.py",
          "type": "blob",
          "size": 3865
        },
        {
          "path": "hooks/session-end.py",
          "type": "blob",
          "size": 1949
        },
        {
          "path": "hooks/session-start.py",
          "type": "blob",
          "size": 9059
        },
        {
          "path": "lib",
          "type": "tree",
          "size": null
        },
        {
          "path": "lib/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "lib/skills/dev-brainstorm",
          "type": "tree",
          "size": null
        },
        {
          "path": "lib/skills/dev-brainstorm/SKILL.md",
          "type": "blob",
          "size": 12930
        },
        {
          "path": "lib/skills/dev-clarify",
          "type": "tree",
          "size": null
        },
        {
          "path": "lib/skills/dev-clarify/SKILL.md",
          "type": "blob",
          "size": 12146
        },
        {
          "path": "lib/skills/dev-delegate",
          "type": "tree",
          "size": null
        },
        {
          "path": "lib/skills/dev-delegate/SKILL.md",
          "type": "blob",
          "size": 10425
        },
        {
          "path": "lib/skills/dev-explore",
          "type": "tree",
          "size": null
        },
        {
          "path": "lib/skills/dev-explore/SKILL.md",
          "type": "blob",
          "size": 16394
        },
        {
          "path": "lib/skills/dev-explore/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "lib/skills/dev-explore/references/ast-grep-patterns.md",
          "type": "blob",
          "size": 1377
        },
        {
          "path": "lib/skills/dev-implement",
          "type": "tree",
          "size": null
        },
        {
          "path": "lib/skills/dev-implement/SKILL.md",
          "type": "blob",
          "size": 12494
        },
        {
          "path": "lib/skills/dev-ralph-loop",
          "type": "tree",
          "size": null
        },
        {
          "path": "lib/skills/dev-ralph-loop/SKILL.md",
          "type": "blob",
          "size": 8398
        },
        {
          "path": "lib/skills/dev-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "lib/skills/dev-review/SKILL.md",
          "type": "blob",
          "size": 8866
        },
        {
          "path": "lib/skills/dev-test-chrome",
          "type": "tree",
          "size": null
        },
        {
          "path": "lib/skills/dev-test-chrome/SKILL.md",
          "type": "blob",
          "size": 14607
        },
        {
          "path": "lib/skills/dev-test-playwright",
          "type": "tree",
          "size": null
        },
        {
          "path": "lib/skills/dev-test-playwright/SKILL.md",
          "type": "blob",
          "size": 13380
        },
        {
          "path": "lib/skills/dev-verify",
          "type": "tree",
          "size": null
        },
        {
          "path": "lib/skills/dev-verify/SKILL.md",
          "type": "blob",
          "size": 11622
        },
        {
          "path": "lib/skills/ds-brainstorm",
          "type": "tree",
          "size": null
        },
        {
          "path": "lib/skills/ds-brainstorm/SKILL.md",
          "type": "blob",
          "size": 6507
        },
        {
          "path": "lib/skills/ds-delegate",
          "type": "tree",
          "size": null
        },
        {
          "path": "lib/skills/ds-delegate/SKILL.md",
          "type": "blob",
          "size": 9190
        },
        {
          "path": "lib/skills/ds-implement",
          "type": "tree",
          "size": null
        },
        {
          "path": "lib/skills/ds-implement/SKILL.md",
          "type": "blob",
          "size": 9607
        },
        {
          "path": "lib/skills/ds-implement/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "lib/skills/ds-implement/references/verification-patterns.md",
          "type": "blob",
          "size": 1515
        },
        {
          "path": "lib/skills/ds-plan",
          "type": "tree",
          "size": null
        },
        {
          "path": "lib/skills/ds-plan/SKILL.md",
          "type": "blob",
          "size": 9218
        },
        {
          "path": "lib/skills/ds-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "lib/skills/ds-review/SKILL.md",
          "type": "blob",
          "size": 7875
        },
        {
          "path": "lib/skills/ds-verify",
          "type": "tree",
          "size": null
        },
        {
          "path": "lib/skills/ds-verify/SKILL.md",
          "type": "blob",
          "size": 7962
        },
        {
          "path": "lib/skills/using-skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "lib/skills/using-skills/SKILL.md",
          "type": "blob",
          "size": 11511
        },
        {
          "path": "lib/skills/using-skills/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "lib/skills/using-skills/references/agent-harnessing.md",
          "type": "blob",
          "size": 3788
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/tinymist",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/tinymist/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/tinymist/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 262
        },
        {
          "path": "plugins/tinymist/README.md",
          "type": "blob",
          "size": 1639
        },
        {
          "path": "plugins/tinymist/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/tinymist/commands/compile.md",
          "type": "blob",
          "size": 909
        },
        {
          "path": "plugins/tinymist/commands/preview.md",
          "type": "blob",
          "size": 1054
        },
        {
          "path": "plugins/tinymist/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/tinymist/skills/check",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/tinymist/skills/check/SKILL.md",
          "type": "blob",
          "size": 1647
        },
        {
          "path": "plugins/tinymist/skills/screenshot",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/tinymist/skills/screenshot/SKILL.md",
          "type": "blob",
          "size": 2491
        },
        {
          "path": "plugins/tinymist/skills/typst",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/tinymist/skills/typst/SKILL.md",
          "type": "blob",
          "size": 7870
        },
        {
          "path": "skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/ai-anti-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/ai-anti-patterns/SKILL.md",
          "type": "blob",
          "size": 6368
        },
        {
          "path": "skills/ai-anti-patterns/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/ai-anti-patterns/references/00-introduction.md",
          "type": "blob",
          "size": 5166
        },
        {
          "path": "skills/ai-anti-patterns/references/01-puffery-and-exaggeration.md",
          "type": "blob",
          "size": 6461
        },
        {
          "path": "skills/ai-anti-patterns/references/02-promotional-language.md",
          "type": "blob",
          "size": 4238
        },
        {
          "path": "skills/ai-anti-patterns/references/03-structural-patterns.md",
          "type": "blob",
          "size": 10898
        },
        {
          "path": "skills/ai-anti-patterns/references/04-stylistic-quirks.md",
          "type": "blob",
          "size": 6923
        },
        {
          "path": "skills/ai-anti-patterns/references/05-formatting-and-typography.md",
          "type": "blob",
          "size": 7088
        },
        {
          "path": "skills/ai-anti-patterns/references/06-communication-patterns.md",
          "type": "blob",
          "size": 11478
        },
        {
          "path": "skills/ai-anti-patterns/references/07-template-artifacts.md",
          "type": "blob",
          "size": 3992
        },
        {
          "path": "skills/ai-anti-patterns/references/08-markup-issues.md",
          "type": "blob",
          "size": 8782
        },
        {
          "path": "skills/ai-anti-patterns/references/09-chatgpt-specific-artifacts.md",
          "type": "blob",
          "size": 5991
        },
        {
          "path": "skills/ai-anti-patterns/references/10-citation-problems.md",
          "type": "blob",
          "size": 10161
        },
        {
          "path": "skills/ai-anti-patterns/references/11-meta-indicators.md",
          "type": "blob",
          "size": 11890
        },
        {
          "path": "skills/ai-anti-patterns/references/_index.md",
          "type": "blob",
          "size": 4292
        },
        {
          "path": "skills/bluebook",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/bluebook/SKILL.md",
          "type": "blob",
          "size": 8816
        },
        {
          "path": "skills/bluebook/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/bluebook/references/cases.md",
          "type": "blob",
          "size": 8177
        },
        {
          "path": "skills/bluebook/references/secondary-sources.md",
          "type": "blob",
          "size": 9256
        },
        {
          "path": "skills/bluebook/references/short-forms.md",
          "type": "blob",
          "size": 9131
        },
        {
          "path": "skills/bluebook/references/signals-parentheticals.md",
          "type": "blob",
          "size": 11390
        },
        {
          "path": "skills/bluebook/references/statutes.md",
          "type": "blob",
          "size": 7439
        },
        {
          "path": "skills/dev-debug",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/dev-debug/SKILL.md",
          "type": "blob",
          "size": 12181
        },
        {
          "path": "skills/dev-design",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/dev-design/SKILL.md",
          "type": "blob",
          "size": 19376
        },
        {
          "path": "skills/dev-tdd",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/dev-tdd/SKILL.md",
          "type": "blob",
          "size": 14456
        },
        {
          "path": "skills/dev-tdd/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/dev-tdd/references/execution-gates.md",
          "type": "blob",
          "size": 12366
        },
        {
          "path": "skills/dev-tdd/references/logging-requirements.md",
          "type": "blob",
          "size": 2654
        },
        {
          "path": "skills/dev-test-electron",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/dev-test-electron/SKILL.md",
          "type": "blob",
          "size": 25318
        },
        {
          "path": "skills/dev-test-electron/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/dev-test-electron/references/advanced-patterns.md",
          "type": "blob",
          "size": 18938
        },
        {
          "path": "skills/dev-test-electron/references/cdp-api.md",
          "type": "blob",
          "size": 12836
        },
        {
          "path": "skills/dev-test-electron/references/electron-specific.md",
          "type": "blob",
          "size": 20831
        },
        {
          "path": "skills/dev-test-hammerspoon",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/dev-test-hammerspoon/SKILL.md",
          "type": "blob",
          "size": 11819
        },
        {
          "path": "skills/dev-test-linux",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/dev-test-linux/SKILL.md",
          "type": "blob",
          "size": 15407
        },
        {
          "path": "skills/dev-test",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/dev-test/SKILL.md",
          "type": "blob",
          "size": 16322
        },
        {
          "path": "skills/dev-tools",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/dev-tools/SKILL.md",
          "type": "blob",
          "size": 2177
        },
        {
          "path": "skills/dev-worktree",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/dev-worktree/SKILL.md",
          "type": "blob",
          "size": 4243
        },
        {
          "path": "skills/ds-tools",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/ds-tools/SKILL.md",
          "type": "blob",
          "size": 3004
        },
        {
          "path": "skills/gemini-batch",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/gemini-batch/SKILL.md",
          "type": "blob",
          "size": 13537
        },
        {
          "path": "skills/gemini-batch/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/gemini-batch/references/best-practices.md",
          "type": "blob",
          "size": 7126
        },
        {
          "path": "skills/gemini-batch/references/cli-reference.md",
          "type": "blob",
          "size": 2080
        },
        {
          "path": "skills/gemini-batch/references/gcs-setup.md",
          "type": "blob",
          "size": 9105
        },
        {
          "path": "skills/gemini-batch/references/gotchas.md",
          "type": "blob",
          "size": 19574
        },
        {
          "path": "skills/gemini-batch/references/troubleshooting.md",
          "type": "blob",
          "size": 6852
        },
        {
          "path": "skills/gemini-batch/references/vertex-ai.md",
          "type": "blob",
          "size": 2152
        },
        {
          "path": "skills/jupytext",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/jupytext/SKILL.md",
          "type": "blob",
          "size": 10671
        },
        {
          "path": "skills/jupytext/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/jupytext/references/data-sharing.md",
          "type": "blob",
          "size": 10370
        },
        {
          "path": "skills/jupytext/references/formats.md",
          "type": "blob",
          "size": 6561
        },
        {
          "path": "skills/jupytext/references/kernels.md",
          "type": "blob",
          "size": 6746
        },
        {
          "path": "skills/look-at",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/look-at/README.md",
          "type": "blob",
          "size": 5690
        },
        {
          "path": "skills/look-at/SKILL.md",
          "type": "blob",
          "size": 8241
        },
        {
          "path": "skills/look-at/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/look-at/references/api-details.md",
          "type": "blob",
          "size": 4555
        },
        {
          "path": "skills/look-at/references/use-cases.md",
          "type": "blob",
          "size": 8800
        },
        {
          "path": "skills/lseg-data",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/lseg-data/SKILL.md",
          "type": "blob",
          "size": 11086
        },
        {
          "path": "skills/lseg-data/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/lseg-data/references/api-discovery.md",
          "type": "blob",
          "size": 12136
        },
        {
          "path": "skills/lseg-data/references/corporate-governance.md",
          "type": "blob",
          "size": 7609
        },
        {
          "path": "skills/lseg-data/references/equity-new-issues.md",
          "type": "blob",
          "size": 6997
        },
        {
          "path": "skills/lseg-data/references/esg.md",
          "type": "blob",
          "size": 9853
        },
        {
          "path": "skills/lseg-data/references/fund-details.md",
          "type": "blob",
          "size": 22604
        },
        {
          "path": "skills/lseg-data/references/fundamentals.md",
          "type": "blob",
          "size": 8031
        },
        {
          "path": "skills/lseg-data/references/infrastructure.md",
          "type": "blob",
          "size": 7718
        },
        {
          "path": "skills/lseg-data/references/joint-ventures.md",
          "type": "blob",
          "size": 12644
        },
        {
          "path": "skills/lseg-data/references/mna.md",
          "type": "blob",
          "size": 6625
        },
        {
          "path": "skills/lseg-data/references/municipal-bonds.md",
          "type": "blob",
          "size": 5342
        },
        {
          "path": "skills/lseg-data/references/news.md",
          "type": "blob",
          "size": 7624
        },
        {
          "path": "skills/lseg-data/references/pricing.md",
          "type": "blob",
          "size": 3791
        },
        {
          "path": "skills/lseg-data/references/private-equity.md",
          "type": "blob",
          "size": 7069
        },
        {
          "path": "skills/lseg-data/references/screening.md",
          "type": "blob",
          "size": 4823
        },
        {
          "path": "skills/lseg-data/references/symbology.md",
          "type": "blob",
          "size": 8952
        },
        {
          "path": "skills/lseg-data/references/syndicated-loans.md",
          "type": "blob",
          "size": 5125
        },
        {
          "path": "skills/lseg-data/references/troubleshooting.md",
          "type": "blob",
          "size": 9900
        },
        {
          "path": "skills/lseg-data/references/wrds-comparison.md",
          "type": "blob",
          "size": 10015
        },
        {
          "path": "skills/marimo",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/marimo/SKILL.md",
          "type": "blob",
          "size": 9516
        },
        {
          "path": "skills/marimo/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/marimo/references/debugging.md",
          "type": "blob",
          "size": 5224
        },
        {
          "path": "skills/marimo/references/reactivity.md",
          "type": "blob",
          "size": 3071
        },
        {
          "path": "skills/marimo/references/sql.md",
          "type": "blob",
          "size": 7845
        },
        {
          "path": "skills/marimo/references/widgets.md",
          "type": "blob",
          "size": 7040
        },
        {
          "path": "skills/notebook-debug",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/notebook-debug/SKILL.md",
          "type": "blob",
          "size": 7596
        },
        {
          "path": "skills/wrds",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/wrds/SKILL.md",
          "type": "blob",
          "size": 7883
        },
        {
          "path": "skills/wrds/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/wrds/references/compustat.md",
          "type": "blob",
          "size": 10324
        },
        {
          "path": "skills/wrds/references/connection.md",
          "type": "blob",
          "size": 10831
        },
        {
          "path": "skills/wrds/references/crsp.md",
          "type": "blob",
          "size": 4575
        },
        {
          "path": "skills/wrds/references/edgar.md",
          "type": "blob",
          "size": 16014
        },
        {
          "path": "skills/wrds/references/insider-form4.md",
          "type": "blob",
          "size": 4986
        },
        {
          "path": "skills/wrds/references/iss-compensation.md",
          "type": "blob",
          "size": 3514
        },
        {
          "path": "skills/writing-brainstorm",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/writing-brainstorm/SKILL.md",
          "type": "blob",
          "size": 9931
        },
        {
          "path": "skills/writing-econ",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/writing-econ/SKILL.md",
          "type": "blob",
          "size": 7208
        },
        {
          "path": "skills/writing-econ/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/writing-econ/references/economical-writing-full.md",
          "type": "blob",
          "size": 5635
        },
        {
          "path": "skills/writing-legal",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/writing-legal/SKILL.md",
          "type": "blob",
          "size": 12186
        },
        {
          "path": "skills/writing-legal/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/writing-legal/references/volokh-distilled.md",
          "type": "blob",
          "size": 18340
        },
        {
          "path": "skills/writing",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/writing/SKILL.md",
          "type": "blob",
          "size": 5446
        },
        {
          "path": "skills/writing/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/writing/references/elements-of-style.md",
          "type": "blob",
          "size": 71183
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"edwinhu-plugins\",\n  \"owner\": {\n    \"name\": \"Edwin Hu\"\n  },\n  \"metadata\": {\n    \"description\": \"Development, data science, and writing workflows for Claude Code\",\n    \"version\": \"2.33.0\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"workflows\",\n      \"source\": \"./\",\n      \"description\": \"Unified development, data science, and writing workflows with TDD enforcement and output-first verification\",\n      \"version\": \"2.33.0\",\n      \"category\": \"development\",\n      \"tags\": [\"development\", \"data-science\", \"writing\", \"tdd\", \"workflows\"]\n    },\n    {\n      \"name\": \"tinymist-lsp\",\n      \"source\": \"./plugins/tinymist-lsp\",\n      \"description\": \"Typst language server integration with tinymist for code intelligence, compilation, and preview\",\n      \"version\": \"1.0.0\",\n      \"category\": \"development\",\n      \"tags\": [\"typst\", \"lsp\", \"tinymist\", \"typesetting\"],\n      \"lspServers\": {\n        \"tinymist\": {\n          \"command\": \"tinymist\",\n          \"args\": [\"lsp\"],\n          \"extensionToLanguage\": {\n            \".typ\": \"typst\"\n          }\n        }\n      }\n    }\n  ]\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"workflows\",\n  \"version\": \"2.33.0\",\n  \"description\": \"Development and data science workflows with TDD enforcement and output-first verification.\",\n  \"author\": {\n    \"name\": \"edwinhu\"\n  },\n  \"commands\": \"./commands/\",\n  \"skills\": \"./skills/\"\n}\n",
        ".claude/commands/dev.md": "---\ndescription: Start the 7-phase feature development workflow with TDD enforcement\nallowed-tools: Read\n---\n\nStart the dev workflow by invoking Phase 1 (brainstorming):\n\nRead(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-brainstorm/SKILL.md\")\n\nThe brainstorm phase will handle workflow activation and guide you through requirements gathering.\n",
        ".claude/commands/ds.md": "---\ndescription: Start the 5-phase data analysis workflow with output-first verification\nallowed-tools: Read\n---\n\nStart the ds workflow by invoking Phase 1 (brainstorming):\n\nRead(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/ds-brainstorm/SKILL.md\")\n\nThe brainstorm phase will handle workflow activation and guide you through analysis planning.\n",
        ".copilot/README.md": "# Workflows for GitHub Copilot (VS Code)\n\nThis directory contains installation and setup files for integrating the workflows skill system with GitHub Copilot in Visual Studio Code.\n\n## Files\n\n| File | Purpose |\n|------|---------|\n| `INSTALL.md` | Comprehensive installation and setup guide |\n| `QUICK_START.md` | One-minute quick start |\n| `install.sh` | Automated installation script |\n| `COMPATIBILITY.md` | Known issues and compatibility notes |\n| `README.md` | This file |\n\n## Quick Install\n\n```bash\nbash ~/projects/workflows/.copilot/install.sh\n```\n\nRestart VS Code and you're done.\n\n## How It Works\n\n1. **Installation** creates a prompt instruction file at:\n   ```\n   ~/.config/Code/User/prompts/workflows.instructions.md\n   ```\n\n2. **VS Code auto-loads** this file at the start of every Copilot session\n\n3. **Skills auto-discovery** - the prompt teaches Copilot about available skills and when to use them\n\n4. **Repeatable setup** - new machines/reinstalls just run the install script\n\n## What Gets Installed\n\n- **Single file:** `~/.config/Code/User/prompts/workflows.instructions.md` - Main instruction file\n- **Source:** `~/projects/workflows/skills/` - The 39 skills (already in repo)\n\n## Key Difference from .opencode\n\n| Aspect | .opencode | .copilot |\n|--------|-----------|---------|\n| **Install target** | `~/.config/opencode/` | `~/.config/Code/User/prompts/` |\n| **Skill loading** | OpenCode plugin system | Instruction file injection |\n| **Symlinks** | Yes, to auto-update skills | No, skills read from repo |\n| **Discovery** | Manual `find_skills` command | Automatic at session start |\n| **Per-project skills** | Supported (`.opencode/skill/`) | Via `.vscode/instructions.md` |\n\n## Architecture\n\n### VS Code Prompt Files\n\nVS Code loads instruction files from `~/.config/Code/User/prompts/` automatically. The filename doesn't matter (e.g., `workflows.instructions.md`), they all get loaded.\n\n**Key advantage:** This is simpler than the OpenCode plugin system—no plugin installation needed.\n\n**Key limitation:** All matching prompt files are merged, so naming is important to avoid conflicts.\n\n### The Instruction File\n\nThe `workflows.instructions.md` file contains:\n1. Front matter: `applyTo: '**'` (applies to all chats)\n2. Skill discovery instructions\n3. Trigger rules for when to invoke skills\n4. Available skill list\n\nThis is **not** a copy of individual skills—it teaches Copilot *how* to use skills.\n\n### Skill Discovery\n\nEvery session, the prompt tells Copilot to check if the user's request matches a skill trigger:\n- **Bug mention** → invoke `/dev-debug` skill\n- **Feature request** → invoke `/dev` skill  \n- **Data analysis** → invoke `/ds` skill\n- **Writing task** → invoke `/writing` skill\n\n## Updating\n\n### To update skills:\n\n```bash\ncd ~/projects/workflows\ngit pull origin main\n```\n\nNo re-installation needed—skills are read directly from the repo.\n\n### To update the instruction file:\n\n```bash\nbash ~/projects/workflows/.copilot/install.sh\n```\n\n## Troubleshooting\n\n### Skills not loading\n\n**Check 1:** File exists in right location\n```bash\nls ~/.config/Code/User/prompts/workflows.instructions.md\n```\n\n**Check 2:** Restart VS Code (fully close and reopen)\n\n**Check 3:** Verify VS Code prompt loading is enabled\n- Open Settings: `Cmd+,` (Mac) or `Ctrl+,` (Windows/Linux)\n- Search for \"prompt\"\n- Ensure custom prompt paths are configured\n\n### Install script fails\n\n**Check:** Workflows repo is cloned\n```bash\nls ~/projects/workflows/.copilot/install.sh\n```\n\nIf not cloned:\n```bash\ngit clone https://github.com/edwinhu/workflows.git ~/projects/workflows\n```\n\n### Copilot doesn't mention skills\n\nThis is normal—skills are in the instruction file but Copilot doesn't always explicitly mention them. They're working if:\n- You mention a bug and Copilot follows debugging methodology\n- You ask for a feature and Copilot structures implementation\n- Data science requests get analytical structure\n\n## Configuration\n\n### Customize skill triggers\n\nEdit `~/.config/Code/User/prompts/workflows.instructions.md` to adjust trigger words or skill mappings.\n\n### Project-specific skills\n\nIn your project root, create `.vscode/instructions.md` to override or extend the global setup:\n\n```markdown\n---\napplyTo: '**'\n---\n\n# Project-Specific Skills\n\nThis project uses custom skill mappings...\n```\n\n## Contributing\n\nTo contribute improvements to the VS Code setup:\n\n1. Edit files in `~/projects/workflows/.copilot/`\n2. Test locally\n3. Submit PR to the main repository\n\n## For OpenCode Users\n\nIf you use both OpenCode and VS Code:\n\n- **OpenCode skills:** Managed by `~/.config/opencode/` (see `.opencode/INSTALL.md`)\n- **VS Code skills:** Managed by `~/.config/Code/User/prompts/` (this directory)\n\nThey're independent and can be installed together.\n\n## Next Steps\n\n- [QUICK_START.md](./QUICK_START.md) - 60-second setup\n- [INSTALL.md](./INSTALL.md) - Detailed installation guide\n- [COMPATIBILITY.md](./COMPATIBILITY.md) - Known issues\n\nSee also: `../README.md` for the workflows project overview.\n",
        ".opencode/README.md": "# Workflows for OpenCode\n\nComplete guide for using the workflows skills library with [OpenCode.ai](https://opencode.ai).\n\n## Quick Install\n\nTell OpenCode:\n\n```\nFetch and follow instructions from https://raw.githubusercontent.com/edwinhu/workflows/refs/heads/opencode-compatibility/.opencode/INSTALL.md\n```\n\nOr run the automated installer:\n\n```bash\n# Clone the repo first\ngit clone -b opencode-compatibility https://github.com/edwinhu/workflows.git ~/.config/opencode/workflows\n\n# Then run the installer\nbash ~/.config/opencode/workflows/.opencode/install.sh\n```\n\n## What You Get\n\nAll 40 workflows skills immediately available:\n\n- **Development** (19 skills): dev, dev-implement, dev-debug, dev-tdd, dev-verify, dev-review, dev-brainstorm, dev-design, dev-explore, dev-clarify, dev-delegate, dev-test, dev-test-chrome, dev-test-linux, dev-test-hammerspoon, dev-test-playwright, dev-ralph-loop, dev-tools, using-workflows\n\n- **Data Science** (8 skills): ds, ds-implement, ds-brainstorm, ds-delegate, ds-plan, ds-review, ds-verify, ds-tools\n\n- **Writing** (4 skills): writing, writing-brainstorm, writing-econ, writing-legal\n\n- **Specialized** (9 skills): ai-anti-patterns, notebook-debug, jupytext, marimo, wrds, lseg-data, gemini-batch, using-skills, exit\n\n## Features\n\n### Automatic Context Injection\n\nThe plugin automatically provides workflows context when you start OpenCode. No manual setup needed.\n\n### Skill Discovery\n\nUse the `find_skills` tool to list all available skills:\n\n```\nfind_skills\n```\n\n### Load a Skill\n\nUse the `use_skill` tool to load a specific skill:\n\n```\nuse_skill(skill_name=\"dev-implement\")\n```\n\n## Architecture\n\n### Unified Skills\n\nAll skills live in a single `/skills/` directory. Works on both Claude Code and OpenCode.\n\n```\nworkflows/\n├── skills/              # Unified skills (39 total)\n│   ├── dev-implement/SKILL.md\n│   ├── dev-debug/SKILL.md\n│   └── [37 more]\n├── lib/\n│   └── skills-core.js   # Shared discovery utilities\n└── .opencode/\n    ├── plugin/          # OpenCode bridge plugin\n    └── INSTALL.md       # This guide\n```\n\n### Plugin Location\n\n**Installed at:** `~/.config/opencode/plugin/workflows.js`\n\n**Provides:**\n- `use_skill` - Load a skill by name\n- `find_skills` - List all available skills\n- Automatic context injection via chat.message hook\n- Re-injection after context compaction\n\n## Installation Details\n\n### Option 1: Automated Installer (Recommended)\n\n```bash\n# Download and run the installer\ngit clone -b opencode-compatibility https://github.com/edwinhu/workflows.git ~/.config/opencode/workflows\nbash ~/.config/opencode/workflows/.opencode/install.sh\n```\n\n**What it does:**\n- Clones the workflows repository\n- Creates symlinks to all 40 skills in `~/.config/opencode/skill/`\n- Installs the plugin to `~/.config/opencode/plugin/`\n\n**Benefits:**\n- Interactive prompts for different installation methods\n- Automatic verification\n- Clean error messages\n\n### Option 2: Manual Installation\n\n```bash\n# 1. Clone the repository\ngit clone -b opencode-compatibility https://github.com/edwinhu/workflows.git ~/.config/opencode/workflows\n\n# 2. Create directories\nmkdir -p ~/.config/opencode/skill\nmkdir -p ~/.config/opencode/plugin\n\n# 3. Create skill symlinks (auto-update when repo updates)\nln -sf ~/.config/opencode/workflows/skills/* ~/.config/opencode/skill/\n\n# 4. Install the plugin\ncp ~/.config/opencode/workflows/.opencode/plugin/workflows.js ~/.config/opencode/plugin/\n\n# 5. Restart OpenCode\n```\n\n### Option 3: Project-Local Installation\n\nFor project-specific skills:\n\n```bash\n# In your OpenCode project\nmkdir -p .opencode/skill\nln -sf ~/.config/opencode/workflows/skills/* .opencode/skill/\n```\n\nOpenCode will automatically discover these alongside global skills.\n\n## Verification\n\n### Check Skills Directory\n\n```bash\nls ~/.config/opencode/skill/ | wc -l\n# Should show: 39\n```\n\n### Check Plugin\n\n```bash\nls -l ~/.config/opencode/plugin/workflows.js\n# Should exist and not be a broken link\n```\n\n### In OpenCode\n\n```\nfind_skills\n# Should list all 39 workflows skills\n```\n\n## Usage\n\n### Finding Skills\n\nUse the `find_skills` tool to discover available skills. It shows skill names and descriptions.\n\n### Loading Skills\n\nLoad a skill with the `use_skill` tool:\n\n```\nuse_skill(skill_name=\"dev-implement\")\n```\n\nThe full skill content is inserted into your conversation and persists throughout your session.\n\n### Creating Personal Skills\n\nStore reusable skills in `~/.config/opencode/skills/`:\n\n```bash\nmkdir -p ~/.config/opencode/skills/my-skill\n```\n\nCreate `~/.config/opencode/skills/my-skill/SKILL.md`:\n\n```markdown\n---\nname: my-skill\ndescription: My custom skill for common tasks\n---\n\n# My Skill\n\n[Your skill content here]\n```\n\n### Creating Project Skills\n\nCreate project-specific skills in `.opencode/skills/`:\n\n```bash\nmkdir -p .opencode/skills/my-project-skill\n```\n\nCreate `.opencode/skills/my-project-skill/SKILL.md` with the same structure above.\n\n## Skill Priority\n\nSkills are resolved with this priority:\n\n1. **Project skills** (`.opencode/skills/`) - Highest\n2. **Personal skills** (`~/.config/opencode/skills/`)\n3. **Workflows skills** (`~/.config/opencode/workflows/skills/`)\n4. **Other global skills** (`~/.config/opencode/skills/`)\n\nForce resolution to a specific level:\n\n- `project:skill-name` - Load from project\n- `skill-name` - Search in priority order (default)\n- `workflows:skill-name` - Load from workflows\n\n## Tool Mapping\n\nWhen skills reference Claude Code tools, map them to OpenCode:\n\n| Claude Code | OpenCode |\n|------------|----------|\n| `Skill(skill=\"...\")` | `use_skill(skill_name=\"...\")` |\n| `Task(subagent_type=\"...\", prompt=\"...\")` | Use `@mention` or native agents |\n| `TodoWrite` | `update_plan` or file operations |\n| `Read`, `Write`, `Edit` | Native file tools |\n| `Bash` | Native bash/shell tool |\n\nThe skills themselves are platform-agnostic. The plugin handles platform differences.\n\n## Updating\n\n### With Global Installation\n\n```bash\ncd ~/.config/opencode/workflows\ngit pull origin opencode-compatibility\n```\n\nSkills auto-update since they're symlinked.\n\n### With Project Installation\n\n```bash\n# Re-run the setup commands\nln -sf ~/.config/opencode/workflows/skills/* .opencode/skill/\n```\n\n## Troubleshooting\n\n### Plugin Not Loading\n\n1. Verify plugin exists: `ls ~/.config/opencode/plugin/workflows.js`\n2. Check symlink is valid: `ls -l ~/.config/opencode/skill/`\n3. Restart OpenCode\n4. Check OpenCode logs for errors\n\n### Skills Not Found\n\n1. List skills: `ls ~/.config/opencode/skill/`\n2. Verify SKILL.md files: `ls ~/.config/opencode/skill/*/SKILL.md`\n3. Use `find_skills` in OpenCode\n4. Check `~/.config/opencode/workflows/skills/` exists\n\n### Tool Issues\n\n- `use_skill` not working? → Verify plugin installed\n- `find_skills` not working? → Restart OpenCode\n- Skills showing old version? → `cd ~/.config/opencode/workflows && git pull`\n\n### Context Not Injecting\n\nIf workflows context isn't automatically injected:\n\n1. Verify plugin loaded: Check OpenCode logs\n2. Confirm plugin path: `ls ~/.config/opencode/plugin/workflows.js`\n3. Restart OpenCode completely\n\n## Architecture Comparison\n\n### Before (Duplication)\n\n```\nworkflows/\n├── plugins/workflows/skills/      # Claude Code (38 skills)\n└── .opencode/skill/               # OpenCode (33 copied skills)\n                                   # DUPLICATED - hard to maintain\n```\n\n### After (Unified)\n\n```\nworkflows/\n├── skills/                         # Unified source (40 skills)\n├── lib/skills-core.js              # Shared utilities\n├── .opencode/plugin/               # OpenCode plugin\n└── plugins/workflows/              # Claude Code unchanged\n```\n\n**Benefits:**\n- Single source of truth\n- One edit fixes both platforms\n- No duplication to maintain\n- Consistent experience everywhere\n\n## Skill Status\n\n### ✅ Fully OpenCode-Compatible\n\nAll 40 skills in `/skills/` are production-ready for OpenCode.\n\n- Core development workflows\n- Data science workflows\n- Writing workflows\n- Specialized tools\n\n### Claude Code\n\nThe main branch continues to work as before:\n\n```bash\ngit clone https://github.com/edwinhu/workflows\n# Use `/plugin install workflows` in Claude Code\n```\n\n## Getting Help\n\n- **OpenCode Docs:** https://opencode.ai\n- **Workflows Repository:** https://github.com/edwinhu/workflows\n- **Installation Guide:** `.opencode/INSTALL.md`\n- **Architecture Details:** `.opencode/COMPATIBILITY.md`\n- **Report Issues:** https://github.com/edwinhu/workflows/issues\n\n## See Also\n\n- **Superpowers (inspiration):** https://github.com/obra/superpowers\n- **OpenCode Agent Skills Docs:** https://opencode.ai/docs/skills/\n- **Main Workflows Branch:** https://github.com/edwinhu/workflows\n\n## License\n\nMIT - Same as main repository\n",
        "README.md": "# Workflows\n\nA curated collection of development, data science, and writing workflows—available for both **Claude Code** and **OpenCode** from a single source.\n\n## Quick Start\n\n### Claude Code\n```bash\n/plugin marketplace add edwinhu/workflows\n/plugin install dev\n```\n\n### VS Code / GitHub Copilot\n\n**One-line install:**\n```bash\nbash <(curl -fsSL https://raw.githubusercontent.com/edwinhu/workflows/main/.copilot/install.sh)\n```\n\nOr if you have the repo cloned locally:\n```bash\nbash ~/projects/workflows/.copilot/install.sh\n```\n\nThen **restart VS Code**.\n\n> **⚠️ Note:** Requires enabling experimental settings (`chat.useClaudeSkills`, `chat.customAgentInSubagent.enabled`) which are subject to change. See installation guide for details.\n\n**Verify it works:**\nIn VS Code, chat with Copilot:\n```\nWhat workflows skills are available?\n```\n\nSee [.copilot/INSTALL.md](.copilot/INSTALL.md) for manual installation and troubleshooting.\n\n#### ⚠️ IMPORTANT: Skill Chaining in Copilot\n\nSkills in Copilot work in phases. **Each phase requires manual invocation of the next phase** (unlike Claude Code, where skills auto-chain).\n\nWhen a skill completes, it tells you what’s next. **You must invoke it explicitly** using `runSubagent()`.\n\nExample workflow:\n```\n/dev-brainstorm completes\n  → You invoke: runSubagent(..., prompt=”Continue with /dev-explore...”)\n  → /dev-explore completes\n  → You invoke: runSubagent(..., prompt=”Continue with /dev-clarify...”)\n  [and so on through all 7 phases]\n```\n\n**See [.copilot/QUICK_START.md](.copilot/QUICK_START.md) for the full skill chaining protocol.**\n\n**Multi-Agent Coordination:** If you run multiple agents before invoking a skill (e.g., Plan agent → then /dev skill), read the “MULTI-AGENT COORDINATION” section in `~/.config/Code/User/prompts/workflows.instructions.md` for how to pass context between them. This is a known gap in Copilot that requires manual workaround.\n\n### OpenCode\n```bash\n# Clone the opencode-compatibility branch\ngit clone -b opencode-compatibility https://github.com/edwinhu/workflows.git ~/.config/opencode/workflows\n\n# Install plugin (optional, recommended)\nmkdir -p ~/.config/opencode/plugin\ncp ~/.config/opencode/workflows/.opencode/plugin/workflows.js ~/.config/opencode/plugin/\n\n# In OpenCode: find_skills\n```\n\nSee [.opencode/INSTALL.md](.opencode/INSTALL.md) for full details and alternatives.\n\n## Available Plugins\n\n### dev (v0.5.0)\n\n**Full feature development workflow with TDD enforcement**\n\nA comprehensive development plugin that enforces test-driven development practices through structured phases: brainstorm, plan, implement, review, and verify.\n\n**Commands:**\n- `/dev` - Full feature development workflow with TDD enforcement\n- `/dev-brainstorm` - Socratic design exploration before implementation\n- `/dev-plan` - Codebase exploration and task breakdown\n- `/dev-implement` - TDD implementation with RED-GREEN-REFACTOR cycle\n- `/dev-debug` - Systematic debugging with root cause investigation\n- `/dev-review` - Code review combining spec compliance and quality checks\n- `/dev-verify` - Verification gate requiring fresh runtime evidence\n- `/dev-tools` - List available development plugins and MCP servers\n\n**Tags:** `development`, `tdd`, `testing`, `code-review`\n\n---\n\n### ds (v0.5.0)\n\n**Data science workflow with output-first verification**\n\nA data science plugin focused on reproducibility and output verification, with specialized skills for academic and financial data access.\n\n**Commands:**\n- `/ds` - Data science workflow with output-first verification\n- `/ds-brainstorm` - Clarify analysis objectives through Socratic questioning\n- `/ds-plan` - Data profiling and analysis task breakdown\n- `/ds-implement` - Output-first implementation with verification at each step\n- `/ds-review` - Methodology and statistical validity review\n- `/ds-verify` - Reproducibility verification before completion\n- `/ds-tools` - List available data science plugins and MCP servers\n\n**Data Access Skills:**\n- `/wrds` - WRDS PostgreSQL access for Compustat, CRSP, EDGAR data\n- `/lseg-data` - LSEG Data Library (Refinitiv) for market data and fundamentals\n- `/gemini-batch` - Gemini Batch API for large-scale LLM document processing\n\n**Notebook Skills:**\n- `/marimo` - Marimo reactive Python notebooks\n- `/jupytext` - Jupyter notebooks as text files for version control\n\n**Hooks:**\n- Data quality checker\n- Output verifier\n- Reproducibility checker\n\n**Tags:** `data-science`, `wrds`, `lseg`, `jupyter`, `analysis`\n\n---\n\n### writing (v0.4.0)\n\n**Writing workflow with style guides, brainstorming, and AI anti-pattern detection**\n\nA writing plugin providing style guidance, topic discovery from Readwise highlights, and automatic detection of AI writing patterns.\n\n**Skills:**\n- `/writing` - General writing guidance using Strunk & White’s Elements of Style\n- `/writing-econ` - Economics and finance writing using McCloskey’s Economical Writing\n- `/writing-legal` - Academic legal writing using Volokh’s Academic Legal Writing\n- `/writing-brainstorm` - Discover topics and gather sources from Readwise highlights\n- `/ai-anti-patterns` - Detect and revise AI writing indicators (12 pattern categories)\n\n**MCP Servers:**\n- `readwise` - Readwise MCP for highlight search and source gathering\n\n**Hooks:**\n- PostToolUse hook on Write/Edit that warns on AI anti-patterns\n\n**Tags:** `writing`, `editing`, `style`, `ai-detection`, `readwise`\n\n---\n\n### shared\n\n**Shared skills and utilities across plugins**\n\nContains common skills used by multiple plugins, including office document format skills.\n\n**Skills:**\n- `/docx` - Word document creation, editing, tracked changes\n- `/pdf` - PDF extraction, creation, form filling\n- `/pptx` - Presentation creation and editing\n- `/xlsx` - Spreadsheet creation and analysis\n- `/using-skills` - Meta-skill teaching how to use skills\n\n**Note:** Office format skills are sourced from [anthropics/skills](https://github.com/anthropics/skills) via git submodule.\n\n## Session Continuity Commands\n\nThe plugin includes commands for session state management:\n\n- `/checkpoint` - Save session state to LEARNINGS.md\n- `/learn` - Extract reusable patterns from the current session\n- `/verify` - Run verification checklist (build, types, lint, tests)\n\nThese commands integrate with the PLAN.md + LEARNINGS.md system. For cross-session task persistence, set `CLAUDE_CODE_TASK_LIST_ID` in your `.envrc`:\n\n```bash\n# .envrc\nexport CLAUDE_CODE_TASK_LIST_ID=”my-project”\n```\n\n---\n\n## Repository Structure\n\n```\nworkflows/\n├── .claude-plugin/             # Claude Code plugin manifest\n│   ├── plugin.json\n│   └── marketplace.json\n├── agents/                     # Specialized subagents (10 agents)\n│   ├── planner.md              # Implementation planning\n│   ├── architect.md            # System design decisions\n│   ├── tdd-guide.md            # TDD workflow enforcement\n│   ├── code-reviewer.md        # Code quality review\n│   ├── security-reviewer.md    # Security vulnerability analysis\n│   ├── build-error-resolver.md # Fix build errors\n│   ├── e2e-runner.md           # Playwright E2E testing\n│   ├── refactor-cleaner.md     # Dead code cleanup\n│   ├── doc-updater.md          # Documentation sync\n│   └── data-explorer.md        # EDA and data profiling\n├── commands/                   # Slash commands\n│   ├── dev.md, ds.md, writing.md  # Workflow entry points\n│   ├── learn.md                # Pattern extraction\n│   ├── verify.md               # Verification checklist\n│   └── checkpoint.md           # Session state save\n├── contexts/                   # Example context modes (see note below)\n│   ├── dev.md                  # Development mode\n│   ├── data-science.md         # Data science mode\n│   └── writing.md              # Writing mode\n├── rules/                      # Example rules (see note below)\n│   ├── security.md, coding-style.md, testing.md\n│   ├── git-workflow.md, hooks.md, agents.md\n│   └── performance.md, patterns.md\n├── skills/                     # User-facing skills\n│   ├── continuous-learning/    # Cross-project pattern extraction\n│   └── [28+ skills...]\n├── hooks/                      # Hook entry points\n│   ├── hooks.json              # Hook configuration\n│   ├── session-start.py        # SessionStart hook\n│   ├── session-end.py          # Stop hook (LEARNINGS.md timestamp)\n│   ├── pre-compact.py          # PreCompact hook (state preservation)\n│   ├── suggest-compact.py      # PreToolUse hook (compaction suggestions)\n│   ├── pr-url-logger.py        # PostToolUse hook (log PR URLs)\n│   ├── lint-check.py           # PostToolUse hook (linting)\n│   └── image-read-guard.py     # PreToolUse hook\n├── .mcp.json                   # MCP server configurations\n├── lib/\n│   ├── skills/                 # Internal phase skills\n│   ├── hooks/                  # Shared Python libraries\n│   └── references/             # Reference documentation\n├── scripts/                    # Utility scripts\n├── external/\n│   └── anthropic-skills/       # Git submodule for document skills\n├── .opencode/                  # OpenCode integration\n├── .copilot/                   # VS Code Copilot integration\n└── README.md\n```\n\n**Key Points:**\n- `agents/` contains specialized subagents (auto-discovered by Claude Code)\n- `skills/` contains user-facing skills (auto-discovered)\n- `commands/` contains slash commands (auto-discovered)\n- `hooks/` contains hook entry points called directly by hooks.json\n- `lib/skills/` contains internal phase skills (dev-implement, ds-verify, etc.)\n- `lib/hooks/` contains shared Python libraries for hooks\n\n**Example Content (not auto-loaded):**\n\nThe `rules/` and `contexts/` directories contain **example content** for users to copy to their own configuration. These are NOT auto-loaded by the plugin.\n\nTo use rules and contexts, copy them to your user-level config and reference in your CLAUDE.md:\n\n```bash\n# Copy to user config\ncp -r rules/ ~/.claude/rules/\ncp -r contexts/ ~/.claude/contexts/\n```\n\nThen in `~/.claude/CLAUDE.md`, reference them:\n\n```markdown\n## Modular Rules\nDetailed guidelines are in `~/.claude/rules/`:\n- security.md - Security checks, secret management\n- coding-style.md - File organization, error handling\n- testing.md - TDD workflow, coverage requirements\n```\n\nSee [everything-claude-code examples](https://github.com/anthropics/everything-claude-code/tree/main/examples) for full CLAUDE.md templates.\n\n## Updating External Skills\n\nThe office format skills come from Anthropic’s official skills repo. To update:\n\n```bash\ngit submodule update --remote external/anthropic-skills\n```\n\n## Acknowledgments\n\nThis project was heavily inspired by [obra/superpowers](https://github.com/obra/superpowers), particularly:\n- The SessionStart hook pattern for injecting meta-skills\n- The “using-skills” approach that teaches HOW to use skills rather than listing WHAT skills exist\n- The philosophy that skills should be invoked on-demand, not dumped into every session\n\nOffice format skills (docx, pdf, pptx, xlsx) are from [anthropics/skills](https://github.com/anthropics/skills).\n\n## License\n\nMIT\n\n## Author\n\nEdwin Hu\n",
        "commands/checkpoint.md": "---\ndescription: Save session state to LEARNINGS.md\nallowed-tools: Read, Write, Bash\n---\n\n# /checkpoint - Save Session State\n\nSave current session state for continuity tracking.\n\n## What It Does\n\n1. **Update LEARNINGS.md** with timestamp and current context\n2. **Log session context** for resumption\n\n## When to Use\n\n- Before context compaction (to preserve state)\n- Before taking a break\n- At logical milestones during long sessions\n- When switching between tasks\n\n## Process\n\n1. **Check for LEARNINGS.md**\n   - If exists: Append checkpoint entry\n   - If not exists: Create with initial structure\n\n2. **Append Checkpoint Entry**\n\n```markdown\n---\n## Checkpoint: [timestamp]\n\n### Current State\n[Brief description of where you are in the task]\n\n### Completed\n- [x] Task 1\n- [x] Task 2\n\n### In Progress\n- [ ] Current task\n\n### Next Steps\n- What to do next\n\n### Files Modified\n- file1.py\n- file2.md\n```\n\n3. **Report**\n```\nCHECKPOINT SAVED\n================\nLEARNINGS.md updated: .claude/LEARNINGS.md\nSession: [session-id]\n```\n\n## Arguments\n\n$ARGUMENTS can be:\n- (no args) - Create checkpoint with auto-generated context\n- `note “...”` - Add specific note to checkpoint\n- `status` - Show current checkpoint status without creating new one\n",
        "commands/dev.md": "---\ndescription: Start the 7-phase feature development workflow with TDD enforcement\nallowed-tools: Read\n---\n\nStart the dev workflow by reading and following Phase 1 (brainstorming):\n\nRead(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-brainstorm/SKILL.md\")\n\nThe brainstorm phase will handle workflow activation and guide you through requirements gathering.\n",
        "commands/ds.md": "---\ndescription: Start the 5-phase data science workflow with output-first verification\nallowed-tools: Read\n---\n\nStart the ds workflow by reading and following Phase 1 (brainstorming):\n\nRead(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/ds-brainstorm/SKILL.md\")\n\nThe brainstorm phase will handle workflow activation and guide you through requirements gathering.\n",
        "commands/writing.md": "---\ndescription: Writing guidance using Strunk & White's Elements of Style\n---\n\n# Writing Workflow Activated\n\nStrunk & White style guide is now active. Ask the user:\n\n\"What would you like to write or edit?\"\n\nWhen they respond, load the `workflows:writing` skill for detailed guidance if needed.\n",
        "hooks/hooks.json": "{\n  \"hooks\": {\n    \"SessionStart\": [\n      {\n        \"matcher\": \"startup|resume|clear|compact\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python3 ${CLAUDE_PLUGIN_ROOT}/hooks/session-start.py\"\n          }\n        ]\n      }\n    ],\n    \"PreToolUse\": [\n      {\n        \"matcher\": \"Read\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python3 ${CLAUDE_PLUGIN_ROOT}/hooks/image-read-guard.py\"\n          }\n        ]\n      },\n      {\n        \"matcher\": \"Edit|Write\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python3 ${CLAUDE_PLUGIN_ROOT}/hooks/suggest-compact.py\"\n          }\n        ]\n      }\n    ],\n    \"PostToolUse\": [\n      {\n        \"matcher\": \"Edit|Write\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python3 ${CLAUDE_PLUGIN_ROOT}/hooks/lint-check.py\"\n          }\n        ]\n      },\n      {\n        \"matcher\": \"Bash\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python3 ${CLAUDE_PLUGIN_ROOT}/hooks/pr-url-logger.py\",\n            \"async\": true\n          }\n        ]\n      }\n    ],\n    \"PreCompact\": [\n      {\n        \"matcher\": \"*\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python3 ${CLAUDE_PLUGIN_ROOT}/hooks/pre-compact.py\"\n          }\n        ]\n      }\n    ],\n    \"Stop\": [\n      {\n        \"matcher\": \"*\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python3 ${CLAUDE_PLUGIN_ROOT}/hooks/session-end.py\",\n            \"async\": true\n          }\n        ]\n      }\n    ]\n  }\n}\n",
        "hooks/image-read-guard.py": "#!/usr/bin/env python3\n\"\"\"\nPreToolUse hook: Block Read tool on image files, redirect to look-at skill.\n\nReading images directly wastes context tokens. The look-at skill uses\nGemini to extract only relevant information, saving 80-95% of tokens.\n\"\"\"\n\nimport json\nimport sys\n\nIMAGE_EXTENSIONS = {\n    '.jpg', '.jpeg', '.png', '.webp', '.heic', '.heif',\n    '.gif', '.bmp', '.tiff', '.tif', '.ico', '.svg'\n}\n\n\ndef main():\n    try:\n        hook_input = json.load(sys.stdin)\n    except Exception:\n        sys.exit(0)\n\n    tool_name = hook_input.get('tool_name', '')\n    tool_input = hook_input.get('tool_input', {})\n\n    if tool_name != 'Read':\n        sys.exit(0)\n\n    file_path = tool_input.get('file_path', '').lower()\n    if not file_path:\n        sys.exit(0)\n\n    # Check if it's an image file\n    is_image = any(file_path.endswith(ext) for ext in IMAGE_EXTENSIONS)\n    if not is_image:\n        sys.exit(0)\n\n    # Block and redirect to look-at\n    result = {\n        \"hookSpecificOutput\": {\n            \"hookEventName\": \"PreToolUse\",\n            \"permissionDecision\": \"deny\",\n            \"permissionDecisionReason\": (\n                \"Use look-at skill instead of Read for images.\\n\\n\"\n                \"Reading images directly wastes context tokens. \"\n                \"Use the look-at skill to extract only relevant information:\\n\\n\"\n                \"```bash\\n\"\n                \"python3 ${CLAUDE_PLUGIN_ROOT}/skills/look-at/scripts/look_at.py \\\\\\n\"\n                f'    --file \"{tool_input.get(\"file_path\", \"\")}\" \\\\\\n'\n                '    --goal \"Describe what is in this image\"\\n'\n                \"```\\n\\n\"\n                \"Set Bash description to: look-at: [your goal]\"\n            )\n        }\n    }\n    print(json.dumps(result))\n    sys.exit(0)\n\n\nif __name__ == '__main__':\n    main()\n",
        "hooks/lint-check.py": "#!/usr/bin/env python3\n\"\"\"\nPostToolUse hook: Run appropriate linter after file edits.\n\nSupports:\n- Python (marimo): marimo check\n- Python (regular): ruff check\n- R: lintr\n- Stata: stata-linter\n- SAS: sasjs lint\n- Markdown: smartquotes --check\n\nNon-blocking: reports linter output as messages.\nSilently skips if linter not installed.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport json\nimport subprocess\nimport sys\nfrom pathlib import Path\nfrom typing import Callable\n\nPLUGIN_ROOT = Path(__file__).parent.parent\n\n\ndef run_command(cmd: list[str], timeout: int = 30) -> tuple[int, str, str]:\n    \"\"\"Run command and return (returncode, stdout, stderr).\"\"\"\n    try:\n        result = subprocess.run(\n            cmd,\n            capture_output=True,\n            text=True,\n            timeout=timeout\n        )\n        return result.returncode, result.stdout, result.stderr\n    except FileNotFoundError:\n        return -1, \"\", \"command not found\"\n    except subprocess.TimeoutExpired:\n        return -2, \"\", \"timeout\"\n    except Exception as e:\n        return -3, \"\", str(e)\n\n\ndef is_marimo_notebook(file_path: str) -> bool:\n    \"\"\"Check if Python file is a marimo notebook.\"\"\"\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            content = f.read(2000)  # Check first 2000 chars\n            return 'import marimo' in content or '@app.cell' in content\n    except Exception:\n        return False\n\n\ndef check_python(file_path: str) -> str | None:\n    \"\"\"Run marimo check or ruff on Python file.\"\"\"\n    if is_marimo_notebook(file_path):\n        # marimo check\n        code, stdout, stderr = run_command(['marimo', 'check', file_path])\n        if code == -1:\n            return None  # marimo not installed\n        if code != 0:\n            output = (stdout + stderr).strip()\n            return f\"marimo check:\\n{output}\" if output else None\n    else:\n        # ruff check\n        code, stdout, stderr = run_command(['ruff', 'check', '--no-fix', file_path])\n        if code == -1:\n            return None  # ruff not installed\n        if code != 0:\n            output = stdout.strip()\n            return f\"ruff:\\n{output}\" if output else None\n    return None\n\n\ndef check_r(file_path: str) -> str | None:\n    \"\"\"Run lintr on R file.\"\"\"\n    cmd = ['Rscript', '-e', f\"cat(lintr::lint('{file_path}'))\"]\n    code, stdout, stderr = run_command(cmd)\n    if code == -1:\n        return None  # R/lintr not installed\n    output = stdout.strip()\n    if output and 'Error' not in stderr:\n        return f\"lintr:\\n{output}\"\n    return None\n\n\ndef check_stata(file_path: str) -> str | None:\n    \"\"\"Run stata-linter on Stata file.\"\"\"\n    code, stdout, stderr = run_command(['stata-linter', file_path])\n    if code == -1:\n        return None  # stata-linter not installed\n    if code != 0 or stdout.strip():\n        output = stdout.strip()\n        return f\"stata-linter:\\n{output}\" if output else None\n    return None\n\n\ndef check_sas(file_path: str) -> str | None:\n    \"\"\"Run sasjs lint on SAS file.\"\"\"\n    code, stdout, stderr = run_command(['sasjs', 'lint', file_path])\n    if code == -1:\n        return None  # sasjs not installed\n    if code != 0 or stdout.strip():\n        output = stdout.strip()\n        return f\"sasjs lint:\\n{output}\" if output else None\n    return None\n\n\ndef check_markdown(file_path: str) -> str | None:\n    \"\"\"Run smartquotes --check on markdown file.\"\"\"\n    script = PLUGIN_ROOT / 'scripts' / 'smartquotes.py'\n    if not script.exists():\n        return None\n    code, stdout, stderr = run_command(['python3', str(script), file_path, '--check'])\n    if code == -1:\n        return None  # python3 not available\n    # smartquotes exits 0 even when changes needed, check output\n    output = stdout.strip()\n    if output and 'No changes needed' not in output:\n        return f\"smartquotes:\\n{output}\\n\\nRun: python3 scripts/smartquotes.py {file_path}\"\n    return None\n\n\ndef get_linter_for_file(file_path: str) -> Callable | None:\n    \"\"\"Get appropriate linter function for file type.\"\"\"\n    path = Path(file_path)\n    suffix = path.suffix.lower()\n\n    linters = {\n        '.py': check_python,\n        '.r': check_r,\n        '.R': check_r,\n        '.do': check_stata,\n        '.ado': check_stata,\n        '.sas': check_sas,\n        '.md': check_markdown,\n        '.markdown': check_markdown,\n    }\n\n    return linters.get(suffix)\n\n\ndef main():\n    try:\n        hook_input = json.load(sys.stdin)\n    except Exception:\n        sys.exit(0)\n\n    tool_name = hook_input.get('tool_name', '')\n    tool_input = hook_input.get('tool_input', {})\n\n    if tool_name not in ('Edit', 'Write'):\n        sys.exit(0)\n\n    file_path = tool_input.get('file_path', '')\n    if not file_path:\n        sys.exit(0)\n\n    # Get appropriate linter\n    linter = get_linter_for_file(file_path)\n    if not linter:\n        sys.exit(0)\n\n    # Run linter\n    output = linter(file_path)\n    if not output:\n        sys.exit(0)\n\n    # Report issues (non-blocking, adds context for Claude)\n    result = {\n        \"hookSpecificOutput\": {\n            \"hookEventName\": \"PostToolUse\",\n            \"additionalContext\": f\"Linter output:\\n{output}\"\n        }\n    }\n    print(json.dumps(result))\n    sys.exit(0)\n\n\nif __name__ == '__main__':\n    main()\n",
        "hooks/pr-url-logger.py": "#!/usr/bin/env python3\n\"\"\"\nPostToolUse hook: Log PR URL after gh pr create.\n\nWhen gh pr create succeeds, this hook extracts the PR URL from output\nand logs it to LEARNINGS.md for easy reference.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport json\nimport re\nimport sys\nfrom datetime import datetime\nfrom pathlib import Path\n\n\ndef find_learnings_file() -> Path | None:\n    \"\"\"Find .claude/LEARNINGS.md in current project.\"\"\"\n    learnings_path = Path.cwd() / '.claude' / 'LEARNINGS.md'\n    return learnings_path if learnings_path.exists() else None\n\n\ndef extract_pr_url(output: str) -> str | None:\n    \"\"\"Extract GitHub PR URL from gh pr create output.\"\"\"\n    # gh pr create outputs URL on success\n    # Format: https://github.com/owner/repo/pull/123\n    match = re.search(r'https://github\\.com/[^/]+/[^/]+/pull/\\d+', output)\n    return match.group(0) if match else None\n\n\ndef log_pr_to_learnings(pr_url: str, learnings_path: Path) -> bool:\n    \"\"\"Append PR URL to LEARNINGS.md.\"\"\"\n    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M')\n    entry = f\"\\n- [{timestamp}] PR created: {pr_url}\\n\"\n\n    try:\n        with open(learnings_path, 'a', encoding='utf-8') as f:\n            f.write(entry)\n        return True\n    except (IOError, OSError) as e:\n        print(f\"[PRLogger] Failed to log PR: {e}\", file=sys.stderr)\n        return False\n\n\ndef main():\n    # Read hook input\n    try:\n        hook_input = json.loads(sys.stdin.read())\n    except (json.JSONDecodeError, KeyError):\n        sys.exit(0)\n\n    tool_name = hook_input.get('tool_name', '')\n    tool_input = hook_input.get('tool_input', {})\n    tool_result = hook_input.get('tool_result', {})\n\n    # Only process Bash tool\n    if tool_name != 'Bash':\n        sys.exit(0)\n\n    # Check if this was a gh pr create command\n    command = tool_input.get('command', '')\n    if 'gh pr create' not in command:\n        sys.exit(0)\n\n    # Get output from tool result\n    output = tool_result.get('stdout', '') or tool_result.get('output', '')\n    if not output:\n        sys.exit(0)\n\n    # Extract PR URL\n    pr_url = extract_pr_url(output)\n    if not pr_url:\n        sys.exit(0)\n\n    # Log to LEARNINGS.md (async - Claude won't wait for this)\n    learnings_path = find_learnings_file()\n    if learnings_path:\n        if log_pr_to_learnings(pr_url, learnings_path):\n            print(f\"[PRLogger] Logged PR: {pr_url}\", file=sys.stderr)\n\n    sys.exit(0)\n\n\nif __name__ == '__main__':\n    main()\n",
        "hooks/pre-compact.py": "#!/usr/bin/env python3\n\"\"\"\nPreCompact hook: Save state before context compaction.\n\n1. Adds a compaction marker to LEARNINGS.md\n2. Detects active workflow from PLAN.md\n3. Outputs additionalContext with skill reload instructions\n\nThis helps Claude remember to reload workflow skills after compaction.\nSee: https://github.com/anthropics/claude-code/issues/13919\n\"\"\"\n\nfrom __future__ import annotations\n\nimport json\nimport re\nimport sys\nfrom datetime import datetime\nfrom pathlib import Path\n\n# Workflow patterns to detect in PLAN.md\nWORKFLOW_PATTERNS = {\n    'dev': [r'## Dev Workflow', r'/dev\\b', r'TDD', r'RED-GREEN-REFACTOR'],\n    'ds': [r'## DS Workflow', r'/ds\\b', r'data science', r'EDA'],\n    'writing': [r'## Writing', r'/writing\\b', r'draft', r'revision'],\n}\n\n\ndef find_learnings_file() -> Path | None:\n    \"\"\"Find .claude/LEARNINGS.md in current project.\"\"\"\n    learnings_path = Path.cwd() / '.claude' / 'LEARNINGS.md'\n    return learnings_path if learnings_path.exists() else None\n\n\ndef find_plan_file() -> Path | None:\n    \"\"\"Find .claude/PLAN.md in current project.\"\"\"\n    plan_path = Path.cwd() / '.claude' / 'PLAN.md'\n    return plan_path if plan_path.exists() else None\n\n\ndef detect_active_workflow(plan_path: Path) -> str | None:\n    \"\"\"Detect which workflow is active from PLAN.md content.\"\"\"\n    try:\n        content = plan_path.read_text(encoding='utf-8')\n        for workflow, patterns in WORKFLOW_PATTERNS.items():\n            for pattern in patterns:\n                if re.search(pattern, content, re.IGNORECASE):\n                    return workflow\n        return None\n    except (IOError, OSError):\n        return None\n\n\ndef append_compaction_marker(learnings_path: Path, workflow: str | None) -> bool:\n    \"\"\"Append compaction marker to LEARNINGS.md.\"\"\"\n    timestamp = datetime.now().strftime('%H:%M')\n    workflow_note = f\" (workflow: /{workflow})\" if workflow else \"\"\n    marker = f\"\\n[Compaction at {timestamp}]{workflow_note} - Context was summarized\\n\"\n\n    try:\n        with open(learnings_path, 'a', encoding='utf-8') as f:\n            f.write(marker)\n        return True\n    except (IOError, OSError) as e:\n        print(f\"[PreCompact] Failed to update LEARNINGS.md: {e}\", file=sys.stderr)\n        return False\n\n\ndef main():\n    # Read hook input\n    try:\n        hook_input = json.loads(sys.stdin.read())\n    except (json.JSONDecodeError, KeyError):\n        hook_input = {}\n\n    # Detect active workflow from PLAN.md\n    plan_path = find_plan_file()\n    active_workflow = detect_active_workflow(plan_path) if plan_path else None\n\n    # Update LEARNINGS.md with compaction marker\n    learnings_path = find_learnings_file()\n    if learnings_path:\n        append_compaction_marker(learnings_path, active_workflow)\n\n    # Build reload instructions for additionalContext\n    reload_instructions = []\n\n    if active_workflow:\n        reload_instructions.append(\n            f\"IMPORTANT: The /{active_workflow} workflow was active before compaction. \"\n            f\"After compaction completes, invoke /{active_workflow} to reload the workflow context.\"\n        )\n    else:\n        reload_instructions.append(\n            \"After compaction, check .claude/PLAN.md to determine which workflow \"\n            \"was in use (/dev, /ds, or /writing) and reload it.\"\n        )\n\n    # Always remind about LEARNINGS.md\n    if learnings_path:\n        reload_instructions.append(\n            \"Read .claude/LEARNINGS.md for session context and recent progress.\"\n        )\n\n    # Output additionalContext to be included in compaction summary\n    if reload_instructions:\n        result = {\n            \"hookSpecificOutput\": {\n                \"hookEventName\": \"PreCompact\",\n                \"additionalContext\": \"\\n\".join(reload_instructions)\n            }\n        }\n        print(json.dumps(result))\n\n    sys.exit(0)\n\n\nif __name__ == '__main__':\n    main()\n",
        "hooks/session-end.py": "#!/usr/bin/env python3\n\"\"\"\nStop hook: Update LEARNINGS.md timestamp when session ends.\n\nUpdates the existing LEARNINGS.md file with a timestamp, maintaining the\nPLAN.md + LEARNINGS.md workflow pattern.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport json\nimport re\nimport sys\nfrom datetime import datetime\nfrom pathlib import Path\n\n\ndef find_learnings_file() -> Path | None:\n    \"\"\"Find .claude/LEARNINGS.md in current project.\"\"\"\n    learnings_path = Path.cwd() / '.claude' / 'LEARNINGS.md'\n    return learnings_path if learnings_path.exists() else None\n\n\ndef update_learnings_timestamp(learnings_path: Path) -> bool:\n    \"\"\"\n    Add or update timestamp at the end of LEARNINGS.md.\n\n    Format: --- Last updated: YYYY-MM-DD HH:MM ---\n    \"\"\"\n    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M')\n    footer = f\"\\n---\\nLast updated: {timestamp}\\n---\\n\"\n\n    try:\n        content = learnings_path.read_text(encoding='utf-8')\n\n        # Remove existing footer if present\n        content = re.sub(r'\\n---\\nLast updated:.*\\n---\\n?$', '', content)\n\n        # Add new footer\n        content = content.rstrip() + footer\n\n        learnings_path.write_text(content, encoding='utf-8')\n        return True\n    except (IOError, OSError) as e:\n        print(f\"[SessionEnd] Failed to update LEARNINGS.md: {e}\", file=sys.stderr)\n        return False\n\n\ndef main():\n    # Read hook input (optional - may not have session info)\n    try:\n        hook_input = json.loads(sys.stdin.read())\n        session_id = hook_input.get('sessionId', 'unknown')\n    except (json.JSONDecodeError, KeyError):\n        session_id = 'unknown'\n\n    # Find and update LEARNINGS.md\n    learnings_path = find_learnings_file()\n    if learnings_path:\n        if update_learnings_timestamp(learnings_path):\n            print(f\"[SessionEnd] Updated {learnings_path}\", file=sys.stderr)\n\n    # Exit cleanly (Stop hooks should not block)\n    sys.exit(0)\n\n\nif __name__ == '__main__':\n    main()\n",
        "hooks/session-start.py": "#!/usr/bin/env python3\n\"\"\"\nSessionStart hook: Inject environment context and skill guidance at session start.\nLoads API keys, SSH status, sets CLAUDE_CODE_TASK_LIST_ID for project-scoped tasks.\n\"\"\"\nimport json\nimport os\nimport sys\nfrom pathlib import Path\n\n\ndef load_env_file(env_file: Path):\n    \"\"\"Load environment variables from a file.\"\"\"\n    if not env_file.exists():\n        return\n    try:\n        with open(env_file) as f:\n            for line in f:\n                line = line.strip()\n                if line and not line.startswith('#') and '=' in line:\n                    key, _, value = line.partition('=')\n                    key = key.strip()\n                    value = value.strip().strip('\"').strip(\"'\")\n                    if key and key not in os.environ:\n                        os.environ[key] = value\n    except Exception as e:\n        print(f\"Warning: Failed to load {env_file}: {e}\", file=sys.stderr)\n\n\ndef load_dotenv_if_exists():\n    \"\"\"Load .env file from current directory if it exists.\"\"\"\n    load_env_file(Path.cwd() / '.env')\n\n\ndef load_central_secrets():\n    \"\"\"Load user-global secrets from central location.\n\n    Expected location: ~/.secrets/claude-keys.env\n\n    This is for API keys that are user-global (not project-specific),\n    e.g., Gemini API key, Readwise key, etc.\n\n    Format: standard .env file (KEY=value, one per line)\n    \"\"\"\n    central_secrets = Path.home() / '.secrets' / 'claude-keys.env'\n    load_env_file(central_secrets)\n\n\ndef get_environment_context():\n    \"\"\"Gather environment context for Claude.\n\n    NOTE: Assumes load_central_secrets() and load_dotenv_if_exists()\n    have already been called to populate os.environ.\n    \"\"\"\n    context = {}\n\n    # SSH/Remote detection\n    is_ssh = any(os.environ.get(v) for v in ['SSH_CLIENT', 'SSH_TTY', 'SSH_CONNECTION'])\n    context['session_type'] = 'remote (SSH)' if is_ssh else 'local'\n    if is_ssh:\n        context['ssh_client'] = os.environ.get('SSH_CLIENT', '').split()[0] if os.environ.get('SSH_CLIENT') else None\n\n    # API Keys (just note presence, don't expose full values)\n    api_keys = {}\n    key_vars = [\n        'GEMINI_API_KEY', 'GOOGLE_API_KEY', 'GOOGLE_APPLICATION_CREDENTIALS',\n        'OPENAI_API_KEY', 'ANTHROPIC_API_KEY',\n        'WRDS_USERNAME', 'WRDS_PASSWORD',\n        'LSEG_APP_KEY', 'REFINITIV_APP_KEY',\n        'HF_TOKEN', 'HUGGINGFACE_TOKEN',\n        'GITHUB_TOKEN', 'GH_TOKEN',\n    ]\n    for key in key_vars:\n        val = os.environ.get(key)\n        if val:\n            # Show first 4 and last 4 chars for identification\n            if len(val) > 12:\n                api_keys[key] = f\"{val[:4]}...{val[-4:]}\"\n            else:\n                api_keys[key] = \"***set***\"\n\n    if api_keys:\n        context['api_keys_available'] = api_keys\n\n    # Working directory info\n    context['cwd'] = os.getcwd()\n\n    # Check for direnv\n    if os.environ.get('DIRENV_DIR'):\n        context['direnv_active'] = True\n\n    # Check for pixi\n    if Path('.pixi').exists() or os.environ.get('PIXI_PROJECT_MANIFEST'):\n        context['pixi_project'] = True\n\n    return context\n\n\ndef get_plugin_root() -> Path:\n    \"\"\"Get the plugin root directory.\"\"\"\n    # Script is at: hooks/session-start.py\n    # Plugin root is: ./\n    script_dir = Path(__file__).resolve().parent\n    return script_dir.parent\n\n\ndef load_using_skills_content() -> str:\n    \"\"\"Load the using-skills meta-skill content.\n\n    This teaches Claude HOW to use skills, not WHAT skills exist.\n    The skill catalog is already in the Skill tool description.\n    \"\"\"\n    skill_file = get_plugin_root() / 'skills' / 'using-skills' / 'SKILL.md'\n    try:\n        return skill_file.read_text()\n    except Exception as e:\n        # Fallback if file not found\n        print(f\"Warning: Failed to load using-skills content: {e}\", file=sys.stderr)\n        return \"Skills available. Use Skill(skill=\\\"name\\\") to invoke.\"\n\n\ndef persist_env_vars_for_bash():\n    \"\"\"Persist environment variables to CLAUDE_ENV_FILE for bash commands.\n\n    This makes variables from .env files and direnv available to subsequent\n    bash commands in the Claude session.\n\n    CLAUDE_ENV_FILE should be project-local (e.g., $CWD/.claude/env) for\n    security isolation between projects.\n\n    NOTE: Assumes load_central_secrets() and load_dotenv_if_exists()\n    have already been called to populate os.environ.\n    \"\"\"\n    claude_env_file = os.environ.get('CLAUDE_ENV_FILE')\n    if not claude_env_file:\n        return []\n\n    # List of variables to persist for bash commands\n    vars_to_persist = [\n        # Gemini/Google\n        'GEMINI_API_KEY', 'GOOGLE_API_KEY', 'GOOGLE_APPLICATION_CREDENTIALS',\n        # OpenAI/Anthropic\n        'OPENAI_API_KEY', 'ANTHROPIC_API_KEY',\n        # Data services\n        'WRDS_USERNAME', 'WRDS_PASSWORD',\n        'LSEG_APP_KEY', 'REFINITIV_APP_KEY',\n        # ML platforms\n        'HF_TOKEN', 'HUGGINGFACE_TOKEN',\n        # Git/GitHub\n        'GITHUB_TOKEN', 'GH_TOKEN',\n    ]\n\n    persisted = []\n    try:\n        with open(claude_env_file, 'a') as f:\n            for var in vars_to_persist:\n                val = os.environ.get(var)\n                if val:\n                    # Escape single quotes in value\n                    escaped_val = val.replace(\"'\", \"'\\\\''\")\n                    f.write(f\"export {var}='{escaped_val}'\\n\")\n                    persisted.append(var)\n        return persisted\n    except Exception as e:\n        print(f\"Warning: Failed to persist env vars to {claude_env_file}: {e}\", file=sys.stderr)\n        return []\n\n\ndef build_env_section(env_context: dict, persisted_vars: list) -> str:\n    \"\"\"Build environment context section - placed FIRST for visibility.\"\"\"\n    session_type = env_context.get('session_type', 'local')\n    is_remote = session_type == 'remote (SSH)'\n\n    lines = [\"# Session Environment (USE THIS - DO NOT RUN COMMANDS TO CHECK)\"]\n    lines.append(\"\")\n\n    # Session type - make it extremely prominent\n    if is_remote:\n        lines.append(\"## ⚠️ REMOTE SESSION (SSH)\")\n        lines.append(\"\")\n        lines.append(\"You are connected to a **remote machine** via SSH.\")\n        lines.append(\"- GUI apps (VSCode, browsers, etc.) run on the REMOTE machine\")\n        lines.append(\"- File paths refer to the REMOTE filesystem\")\n        lines.append(\"- Do NOT suggest local machine solutions for remote problems\")\n    else:\n        lines.append(\"## LOCAL SESSION\")\n        lines.append(\"\")\n        lines.append(\"You are running on the **local machine**.\")\n        lines.append(\"- Full GUI/Hyprland access available\")\n        lines.append(\"- File paths refer to local filesystem\")\n\n    lines.append(\"\")\n\n    # API keys\n    if env_context.get('api_keys_available'):\n        keys = \", \".join(env_context['api_keys_available'].keys())\n        lines.append(f\"- **API keys available**: {keys}\")\n\n    # Environment tools\n    if env_context.get('direnv_active'):\n        lines.append(\"- **direnv**: active\")\n    if env_context.get('pixi_project'):\n        lines.append(\"- **pixi**: detected\")\n\n    # Persisted vars\n    if persisted_vars:\n        lines.append(f\"- **Persisted for bash**: {', '.join(persisted_vars)}\")\n\n    lines.append(\"\")\n    return \"\\n\".join(lines)\n\n\ndef get_project_task_list_id() -> str:\n    \"\"\"Generate a task list ID based on project directory.\n\n    Uses the project directory name as the task list ID, enabling\n    cross-session task persistence via CLAUDE_CODE_TASK_LIST_ID.\n\n    See: https://code.claude.com/docs/en/interactive-mode\n    \"\"\"\n    # Use current directory name as task list ID\n    cwd = Path.cwd()\n    return cwd.name\n\n\ndef check_plan_exists() -> str:\n    \"\"\"Check if PLAN.md exists and return continuation message.\"\"\"\n    plan_path = Path.cwd() / '.claude' / 'PLAN.md'\n    if not plan_path.exists():\n        return \"\"\n\n    return \"\"\"\n[PLAN.md DETECTED]\n\nAn implementation plan exists at `.claude/PLAN.md`.\nRead it to understand the current task state before continuing.\n\"\"\"\n\n\ndef main():\n    # Read hook input\n    try:\n        hook_input = json.loads(sys.stdin.read())\n        session_id = hook_input.get('sessionId', 'unknown')\n    except (json.JSONDecodeError, KeyError):\n        session_id = 'unknown'\n\n    # Load environment variables once: central secrets first, project-local override\n    load_central_secrets()\n    load_dotenv_if_exists()\n\n    # Persist env vars for bash commands\n    persisted_vars = persist_env_vars_for_bash()\n\n    # Get environment context for Claude's awareness\n    env_context = get_environment_context()\n\n    # Build sections: environment context + meta-skill about using skills\n    env_section = build_env_section(env_context, persisted_vars)\n    using_skills = load_using_skills_content()\n\n    # Check for existing PLAN.md\n    plan_section = check_plan_exists()\n\n    # Combine context\n    combined_context = env_section + \"\\n\" + plan_section + \"\\n\" + using_skills\n\n    print(json.dumps({\n        \"hookSpecificOutput\": {\n            \"hookEventName\": \"SessionStart\",\n            \"additionalContext\": combined_context\n        }\n    }))\n\n\nif __name__ == '__main__':\n    main()\n",
        "lib/skills/dev-brainstorm/SKILL.md": "---\nname: dev-brainstorm\ndescription: \"REQUIRED Phase 1 of /dev workflow. Uses Socratic questioning to understand requirements before exploration.\"\n---\n\n**Announce:** \"I'm using dev-brainstorm (Phase 1) to gather requirements.\"\n\n## Contents\n\n- [The Iron Law of Brainstorming](#the-iron-law-of-brainstorming)\n- [What Brainstorm Does](#what-brainstorm-does)\n- [Process](#process)\n- [Red Flags - STOP If You're About To](#red-flags---stop-if-youre-about-to)\n- [Output](#output)\n\n# Brainstorming (Questions Only)\n\nRefine vague ideas into clear requirements through Socratic questioning.\n**NO exploration, NO approaches** - just questions and requirements.\n\n<EXTREMELY-IMPORTANT>\n## The Iron Law of Brainstorming\n\n**ASK QUESTIONS BEFORE ANYTHING ELSE. This is not negotiable.**\n\nBefore exploring codebase, before proposing approaches, follow these requirements:\n1. Ask clarifying questions using AskUserQuestion\n2. Understand what the user actually wants\n3. Define success criteria\n\nApproaches come later (in /dev-design) after exploring the codebase.\n\n**If YOU catch YOURSELF about to explore the codebase before asking questions, STOP.**\n</EXTREMELY-IMPORTANT>\n\n### Rationalization Table - STOP If You Think:\n\n| Excuse | Reality | Do Instead |\n|--------|---------|------------|\n| \"The requirements seem obvious\" | Your assumptions are often wrong | ASK questions to confirm |\n| \"Let me just look at the code to understand\" | Code tells HOW, not WHY | ASK what user wants first |\n| \"I can gather requirements while exploring\" | You'll waste time on distraction and miss critical questions | QUESTIONS FIRST, exploration later |\n| \"User already explained everything\" | You'll find users always leave out critical details | ASK clarifying questions anyway |\n| \"I'll ask if I need more info\" | You cannot know unknown unknowns without asking | ASK questions NOW, not later |\n| \"Quick peek at the code won't hurt\" | You'll let codebases bias your thinking | STAY IGNORANT until requirements clear |\n| \"I can propose approaches based on description\" | You need exploration to precede design | WAIT for dev-design phase |\n\n### Honesty Framing\n\n**Guessing user requirements is LYING about what they want.**\n\nAsking questions is cheap. Building the wrong thing is expensive. Every minute spent clarifying requirements saves hours of wasted implementation.\n\n### No Pause After Completion\n\nAfter writing `.claude/SPEC.md` and completing brainstorm, immediately invoke the next phase:\n\n**Invoke the explore phase:**\n\n```bash\nRead(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-explore/SKILL.md\")\n```\n\nDO NOT:\n- Summarize what was learned\n- Ask \"should I proceed?\"\n- Wait for user confirmation\n- Write status updates\n\nThe workflow phases are SEQUENTIAL. Complete brainstorm → immediately start explore.\n\n## What Brainstorm Does\n\n| DO | DON'T |\n|----|-------|\n| Ask clarifying questions | Explore codebase |\n| Understand requirements | Spawn explore agents |\n| Define success criteria | Look at existing code |\n| Write draft SPEC.md | Propose approaches (that's design) |\n| Identify unknowns | Create implementation tasks |\n\n**Brainstorm answers: WHAT do we need and WHY**\n**Explore answers: WHERE is the code** (next phase)\n**Design answers: HOW to build it** (after exploration)\n\n## Process\n\n### 1. Ask Questions First\n\nUse `AskUserQuestion` immediately with these principles:\n- **One question at a time** - never batch\n- **Multiple-choice preferred** - easier to answer\n- Focus on: purpose, constraints, success criteria\n\nExample questions to ask:\n- \"What problem does this solve?\"\n- \"Who will use this feature?\"\n- \"What's the most important requirement?\"\n- \"Any constraints (performance, compatibility)?\"\n\n### 2. Ask About Testing Strategy (MANDATORY)\n\n<EXTREMELY-IMPORTANT>\n**THE TESTING QUESTION IS NOT OPTIONAL. This is the moment to prevent \"no tests\" rationalization.**\n\nAfter understanding what to build, immediately ask:\n\n```python\nAskUserQuestion(questions=[{\n  \"question\": \"How will we verify this works automatically?\",\n  \"header\": \"Testing\",\n  \"options\": [\n    {\"label\": \"Unit tests (pytest/jest/etc.)\", \"description\": \"Test functions/methods in isolation\"},\n    {\"label\": \"Integration tests\", \"description\": \"Test component interactions\"},\n    {\"label\": \"E2E automation (Playwright/ydotool)\", \"description\": \"Simulate real user interactions\"},\n    {\"label\": \"API tests\", \"description\": \"Test HTTP endpoints directly\"}\n  ],\n  \"multiSelect\": true\n}])\n```\n\n**If user says \"manual testing only\" → This is a BLOCKER, not a workaround.**\n\n| User Says | Your Response |\n|-----------|---------------|\n| \"Manual testing\" | \"That's not acceptable for /dev workflow. What's blocking automated tests?\" |\n| \"No test infrastructure\" | \"Let's add one. What framework fits this codebase?\" |\n| \"Too hard to test\" | \"What specifically is hard? Let's solve that first.\" |\n| \"Just this once\" | \"No exceptions. TDD is the workflow, not optional.\" |\n\n**Why this matters:** If you don't ask about testing NOW, you'll rationalize skipping it later.\n</EXTREMELY-IMPORTANT>\n\n### 2b. Define What a REAL Test Looks Like (MANDATORY)\n\n<EXTREMELY-IMPORTANT>\n**A REAL test is feature-specific. You must define it NOW, not during implementation.**\n\nAfter user chooses testing approach, ask:\n\n```python\nAskUserQuestion(questions=[{\n  \"question\": \"Describe the user workflow this test must replicate:\",\n  \"header\": \"User Workflow\",\n  \"options\": [\n    {\"label\": \"UI interaction sequence\", \"description\": \"e.g., 'click button → see modal → submit form'\"},\n    {\"label\": \"API call sequence\", \"description\": \"e.g., 'POST /login → receive token → GET /profile'\"},\n    {\"label\": \"CLI command sequence\", \"description\": \"e.g., 'run command → see output → verify file created'\"},\n    {\"label\": \"Other (describe in chat)\", \"description\": \"Custom workflow\"}\n  ],\n  \"multiSelect\": false\n}])\n```\n\n**Then ask for specifics:**\n\n```python\nAskUserQuestion(questions=[{\n  \"question\": \"What specific skill/tool should we use for testing?\",\n  \"header\": \"Test Tool\",\n  \"options\": [\n    {\"label\": \"dev-test-electron\", \"description\": \"Electron apps with Chrome DevTools Protocol\"},\n    {\"label\": \"dev-test-playwright\", \"description\": \"Web apps with Playwright MCP\"},\n    {\"label\": \"dev-test-hammerspoon\", \"description\": \"macOS native apps\"},\n    {\"label\": \"dev-test-linux\", \"description\": \"Linux desktop apps (ydotool/xdotool)\"},\n    {\"label\": \"Standard unit tests\", \"description\": \"pytest/jest/etc. for pure functions\"}\n  ],\n  \"multiSelect\": false\n}])\n```\n\n**Why this matters:** If you don't define what a REAL test looks like NOW, you'll write FAKE tests later that:\n- Test wrong code paths (HTTP when app uses WebSocket)\n- Use programmatic shortcuts instead of actual UI\n- Pass but don't verify real behavior\n\n### The Iron Law of REAL Tests\n\n**A test that doesn't replicate the user's actual workflow is a FAKE test.**\n\n| REAL Test | FAKE Test (looks like a test, isn't) |\n|-----------|--------------------------------------|\n| Simulates actual user action | Calls function programmatically |\n| Uses same protocol as production | Uses different protocol |\n| Verifies what user sees | Verifies internal state only |\n| Follows user's exact sequence | Takes shortcuts |\n| Uses skill user specified | Ignores skill, writes own thing |\n\n### Protocol Mismatch Examples (Common Fake Test Trap)\n\n| Production Uses | FAKE Test Uses | Result |\n|-----------------|----------------|--------|\n| WebSocket | HTTP | Wrong code path |\n| GraphQL | REST mock | Wrong serialization |\n| Async/await | Sync calls | Race conditions hidden |\n| IPC (Electron) | Direct import | Process boundary skipped |\n| CLI invocation | Function call | Argument parsing skipped |\n\n**The test must use the SAME protocol/transport as production.**\n\n**Document in SPEC.md:**\n- User workflow to replicate\n- Testing skill to use\n- Code paths that must be exercised\n- What the user actually sees/verifies\n</EXTREMELY-IMPORTANT>\n\n### 3. Define Success Criteria\n\nAfter understanding requirements AND testing strategy, define measurable success criteria:\n- Turn requirements into measurable criteria\n- Use checkboxes for clear pass/fail\n- Confirm criteria with user\n- **Include at least one testable criterion per requirement**\n\n### 4. Write Draft SPEC.md\n\nWrite the initial spec to `.claude/SPEC.md`:\n\n```markdown\n# Spec: [Feature Name]\n\n> **For Claude:** After writing this spec, use `Read(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-explore/SKILL.md\")` for Phase 2.\n\n## Problem\n[What problem this solves]\n\n## Requirements\n- [Requirement 1]\n- [Requirement 2]\n\n## Success Criteria\n- [ ] Criterion 1\n- [ ] Criterion 2\n\n## Constraints\n- [Any limitations or boundaries]\n\n## Testing Strategy (MANDATORY - USER APPROVED)\n\n> **For Claude:** Use `Skill(skill=\"workflows:dev-test\")` for automation options.\n>\n> **⚠️ NO IMPLEMENTATION WITHOUT TESTS. If this section is empty, STOP.**\n\n- **User's chosen approach:** [From AskUserQuestion in Phase 1: unit/integration/E2E/API]\n- **Framework:** [pytest / playwright / jest / etc.]\n- **Command:** [e.g., `pytest tests/ -v`]\n- **Testing skill to use:** [dev-test-electron / dev-test-playwright / etc.]\n\n### REAL Test Definition (MANDATORY)\n\n> **⚠️ A test that doesn't replicate user workflow is a FAKE test. Define REAL tests NOW.**\n\n| Field | Value |\n|-------|-------|\n| **User workflow to replicate** | [e.g., \"highlight text → click Claude panel → see '⧉ X lines selected'\"] |\n| **Code paths that must be exercised** | [e.g., \"WebSocket connection, not HTTP\"] |\n| **What user actually sees/verifies** | [e.g., \"Status bar shows selection count\"] |\n| **Protocol/transport** | [e.g., \"WebSocket\" or \"HTTP\" or \"IPC\"] |\n\n### First Failing Test\n\n- **Test name:** [e.g., `test_selection_shows_in_claude_panel`]\n- **What it tests:** [Specific behavior]\n- **How it replicates user workflow:** [Step by step]\n- **Expected failure message:** [What RED looks like]\n\n### The Iron Law of REAL Tests\n\n**If the test doesn't do what the user does, it's a FAKE test.**\n\n| ✅ REAL TEST | ❌ FAKE TEST (looks like test, isn't) |\n|--------------|---------------------------------------|\n| Uses same protocol as production | Tests different protocol |\n| Clicks actual UI elements | Calls functions programmatically |\n| Verifies what user sees | Verifies internal state only |\n| Follows user's exact sequence | Takes shortcuts |\n| Uses skill user specified | Ignores skill, writes own thing |\n| Fails when feature is broken | Passes even when feature is broken |\n\n### Fake Test Detection (Red Flags)\n\n**If you catch yourself doing these, STOP - you're writing a FAKE test:**\n\n| What You're Doing | Why It's Fake | Do Instead |\n|-------------------|---------------|------------|\n| Using different protocol than production | Wrong code path | Use same protocol |\n| Calling function directly instead of user action | Skipping user workflow | Simulate actual user action |\n| Changing assertions to make tests pass | Hiding bugs | Question if test is valid |\n| Ignoring the testing skill user specified | \"I know better\" arrogance | Use the specified skill |\n| Testing internal state, not user-visible output | Missing the point | Test what user sees |\n| Mocking the thing you're supposed to test | Defeats the purpose | Test actual behavior |\n| Skipping async/await when production uses it | Race conditions hidden | Match async behavior |\n\n### No Test Infrastructure? That's a BLOCKER.\n\nIf the project has no tests, your first task is to ADD test infrastructure, not skip testing.\n\n| Situation | Response |\n|-----------|----------|\n| \"Project has no tests\" | Add test framework as Task 0 |\n| \"Hard to test (DOM/UI/etc)\" | Use E2E tools: Playwright, ydotool, screenshot comparison |\n| \"No time for tests\" | TDD saves time. No shortcuts. |\n| \"User said manual testing\" | Push back. Ask what's blocking automation. |\n\n## Open Questions\n- [Questions to resolve during exploration]\n```\n\n**Note:** No \"Chosen Approach\" yet - that comes after exploration and design phases.\n\n## Red Flags - STOP If You're About To:\n\n| Action | Why It's Wrong | Do Instead |\n|--------|----------------|------------|\n| Spawn explore agent | You're exploring before understanding | Ask questions first |\n| Read source files | You're looking at code before requirements are clear | Ask what user wants |\n| Propose approaches | You're jumping ahead - you need exploration first | Save for /dev-design |\n| Create task list | You're planning before you understand the requirements | Finish brainstorm first |\n\n## Output\n\nBrainstorm complete when:\n- Problem is clearly understood\n- Requirements defined\n- Success criteria defined\n- `.claude/SPEC.md` written (draft)\n- Open questions identified for exploration\n\n## Phase Complete\n\n**REQUIRED SUB-SKILL:** After completing brainstorm, immediately invoke the explore phase:\n\n**Start explore phase - Phase 2:**\n\n```bash\nRead(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-explore/SKILL.md\")\n```\n",
        "lib/skills/dev-clarify/SKILL.md": "---\nname: dev-clarify\ndescription: \"REQUIRED Phase 3 of /dev workflow. Asks targeted questions based on codebase exploration findings.\"\n---\n\n**Announce:** \"I'm using dev-clarify (Phase 3) to resolve ambiguities.\"\n\n## Contents\n\n- [The Iron Law of Clarification](#the-iron-law-of-clarification)\n- [What Clarify Does](#what-clarify-does)\n- [Process](#process)\n- [Question Categories](#question-categories)\n- [Red Flags](#red-flags---stop-if-youre-about-to)\n- [Output](#output)\n\n# Post-Exploration Clarification\n\nAsk targeted questions based on what exploration revealed.\n**Prerequisite:** Exploration phase complete, key files read.\n\n<EXTREMELY-IMPORTANT>\n## The Iron Law of Clarification\n\n**ASK BEFORE DESIGNING. This is not negotiable.**\n\nAfter exploration, you now know:\n- What exists in the codebase\n- What patterns are used\n- What integrations are needed\n\nUse this knowledge to ask **informed questions** about:\n- Edge cases the code will need to handle\n- Integration points with existing systems\n- Behavior in ambiguous scenarios\n\n**If you catch yourself about to design without resolving ambiguities, STOP.**\n</EXTREMELY-IMPORTANT>\n\n### Rationalization Table - STOP If You Think:\n\n| Excuse | Reality | Do Instead |\n|--------|---------|------------|\n| \"The pattern choice is obvious\" | Multiple patterns exist for a reason | ASK which to follow |\n| \"I can decide edge cases myself\" | Your assumptions don't match user expectations | ASK for clarification |\n| \"This is a small detail\" | Small details cause big bugs | ASK about edge cases now |\n| \"I'll handle integration points during implementation\" | Wrong integration breaks everything | CLARIFY integration NOW |\n| \"The exploration gave me enough info\" | Code tells you HOW, not WHAT SHOULD happen | ASK for requirements, not just patterns |\n| \"I can make a reasonable assumption\" | Reasonable != correct | ASK, don't assume |\n| \"Asking too many questions annoys users\" | Building wrong thing annoys users more | ASK clarifying questions |\n\n### Honesty Framing\n\n**Assuming user requirements without asking is LYING about what they want.**\n\nYou explored the codebase and found patterns. But patterns show HOW things work, not WHAT the user wants. Clarification bridges this gap.\n\nAsking costs minutes. Wrong assumptions cost hours of rework.\n\n### No Pause After Completion\n\nAfter updating `.claude/SPEC.md` with all clarified requirements, IMMEDIATELY invoke:\n```\nSkill(skill=\"workflows:dev-design\")\n```\n\nDO NOT:\n- Summarize what you learned\n- Ask \"should I proceed to design?\"\n- Wait for user confirmation\n- Write status updates\n\nThe workflow phases are SEQUENTIAL. Complete clarify → immediately start design.\n\n## What Clarify Does\n\n| DO | DON'T |\n|----|-------|\n| Ask questions based on exploration | Ask vague/generic questions |\n| Reference specific code patterns found | Repeat questions from brainstorm |\n| Clarify integration points | Propose approaches (that's design) |\n| Resolve edge cases | Make assumptions |\n| Update SPEC.md with answers | Skip to implementation |\n\n**Clarify answers: WHAT EXACTLY should happen in specific scenarios**\n**Design answers: HOW to build it** (next phase)\n\n## Process\n\n### 1. Review Exploration Findings\n\nBefore asking questions, review:\n- Key files you read\n- Patterns discovered\n- Architecture insights\n- Integration points identified\n\n### 2. Identify Ambiguities\n\nCommon areas needing clarification after exploration:\n\n**Integration Points:**\n- \"The existing auth system uses JWT. Should the new feature use the same token or create a new session type?\"\n\n**Edge Cases:**\n- \"What happens if [condition discovered in code]?\"\n\n**Scope Boundaries:**\n- \"The existing feature handles X. Should the new feature also handle X or is that out of scope?\"\n\n**Behavior Choices:**\n- \"I found two patterns in the codebase for this. Pattern A in `file.ts:23` and Pattern B in `other.ts:45`. Which should we follow?\"\n\n### 3. Ask Questions with AskUserQuestion\n\nPresent questions with context from exploration:\n\n```\nAskUserQuestion(questions=[{\n  \"question\": \"The auth middleware at src/middleware/auth.ts:78 validates tokens synchronously. The new endpoint needs user data. Should we: validate synchronously (faster, simpler) or fetch fresh user data (slower, always current)?\",\n  \"header\": \"Auth pattern\",\n  \"options\": [\n    {\"label\": \"Sync validation (Recommended)\", \"description\": \"Faster, uses cached token claims, matches existing patterns\"},\n    {\"label\": \"Fresh fetch\", \"description\": \"Slower, always current, needed if user data changes frequently\"}\n  ],\n  \"multiSelect\": false\n}])\n```\n\n**Key principles:**\n- Reference specific files/lines from exploration\n- Lead with recommendation based on codebase patterns\n- Explain trade-offs clearly\n- One question at a time for complex topics\n\n### 4. Update SPEC.md\n\nAfter each answer, update `.claude/SPEC.md`:\n- Add clarified requirements\n- Document decisions made\n- Note trade-offs accepted\n\n```markdown\n## Clarified Requirements\n\n### Auth Pattern\n- Decision: Sync validation\n- Rationale: Matches existing patterns, user data changes infrequently\n- Reference: src/middleware/auth.ts:78\n\n### Edge Case: Expired Token\n- Decision: Return 401, let client refresh\n- Rationale: Consistent with other endpoints\n```\n\n## Question Categories\n\n### Must Ask (based on exploration)\n- Integration points with existing systems\n- Patterns to follow (when multiple exist)\n- Edge cases revealed by code reading\n- **Testing strategy (if not resolved in brainstorm/explore)**\n\n### Testing Strategy Clarification (MANDATORY IF MISSING)\n\n<EXTREMELY-IMPORTANT>\n**If exploration found no test infrastructure, this MUST be resolved now.**\n\nBefore proceeding to design, ensure testing strategy is clear:\n\n```python\nAskUserQuestion(questions=[{\n  \"question\": \"No test infrastructure was found. How should we verify this feature works?\",\n  \"header\": \"Testing\",\n  \"options\": [\n    {\"label\": \"Add pytest/jest as Task 0 (Recommended)\", \"description\": \"Set up test framework before implementing feature\"},\n    {\"label\": \"Add E2E tests with Playwright\", \"description\": \"Browser automation to test user interactions\"},\n    {\"label\": \"Add E2E tests with ydotool\", \"description\": \"Desktop automation for native apps\"},\n    {\"label\": \"Other (describe in chat)\", \"description\": \"Propose alternative testing approach\"}\n  ],\n  \"multiSelect\": false\n}])\n```\n\n**\"Manual testing\" is NOT an acceptable answer.** If user insists on manual testing:\n\n1. Explain: \"TDD requires automated tests. Manual testing means we can't do TDD.\"\n2. Ask: \"What's blocking automated tests? Let's solve that.\"\n3. If truly impossible: \"Then we need to exit /dev workflow and use a different approach.\"\n\n**Do NOT proceed to design without a clear automated testing strategy.**\n</EXTREMELY-IMPORTANT>\n\n### Follow-up Testing Questions\n\nAfter user chooses testing approach, clarify specifics:\n\n```python\nAskUserQuestion(questions=[{\n  \"question\": \"What's the FIRST test you want to see fail?\",\n  \"header\": \"First Test\",\n  \"options\": [\n    {\"label\": \"Happy path - feature works correctly\", \"description\": \"Test the main success scenario\"},\n    {\"label\": \"Error case - feature handles bad input\", \"description\": \"Test error handling\"},\n    {\"label\": \"Edge case - specific boundary condition\", \"description\": \"Test a known edge case\"},\n    {\"label\": \"Integration - feature works with existing code\", \"description\": \"Test system integration\"}\n  ],\n  \"multiSelect\": false\n}])\n```\n\n**Why this matters:** Defining the first test BEFORE implementation is the essence of TDD.\n\n### User Workflow Replication (MANDATORY FOR REAL TESTS)\n\n<EXTREMELY-IMPORTANT>\n**If the test doesn't replicate the user's workflow, it's a FAKE test.**\n\nBased on code path discovery from exploration, clarify the exact workflow:\n\n```python\nAskUserQuestion(questions=[{\n  \"question\": \"Let me confirm the user workflow the test must replicate:\",\n  \"header\": \"Workflow\",\n  \"options\": [\n    {\"label\": \"Confirm workflow\", \"description\": \"[State the discovered workflow, e.g., 'highlight → click panel → see status']\"},\n    {\"label\": \"Modify workflow\", \"description\": \"The workflow is different - let me describe it\"},\n    {\"label\": \"Add steps\", \"description\": \"The workflow has additional steps I should know\"}\n  ],\n  \"multiSelect\": false\n}])\n```\n\n**Then verify the test approach matches:**\n\n```python\nAskUserQuestion(questions=[{\n  \"question\": \"The test must use [discovered protocol, e.g., WebSocket]. Is this correct?\",\n  \"header\": \"Protocol\",\n  \"options\": [\n    {\"label\": \"Yes, use [protocol]\", \"description\": \"Test must use the same protocol as production\"},\n    {\"label\": \"No, different protocol\", \"description\": \"Explain the correct protocol\"}\n  ],\n  \"multiSelect\": false\n}])\n```\n\n### Verify Test Will Be REAL\n\nAfter clarifying workflow and protocol, verify:\n\n```\n[ ] Test workflow matches user workflow exactly\n[ ] Test uses same protocol as production\n[ ] Test interacts with same UI elements user sees\n[ ] Test verifies same output user verifies\n[ ] Testing skill is appropriate for this workflow\n```\n\nIf any of these don't match, the test will be FAKE. Clarify now.\n\n### Common Fake Test Patterns to Catch\n\n| What You Discovered | Common Fake Test | REAL Test Must Do |\n|---------------------|------------------|-------------------|\n| App uses Protocol X | Test with Protocol Y | Test with Protocol X |\n| User clicks UI element | Call function directly | Simulate actual click |\n| User sees output | Check internal state | Verify user-visible output |\n| Data flows through boundary | Mock the boundary | Test actual boundary |\n| Operation is async | Test synchronously | Test async behavior |\n| CLI is the interface | Call internal function | Invoke actual CLI |\n\n**If the test approach doesn't match what you discovered, STOP and clarify.**\n</EXTREMELY-IMPORTANT>\n\n### Optional (if unclear)\n- Performance requirements\n- Error handling preferences\n- Backward compatibility needs\n\n### Don't Ask (already decided)\n- What the feature does (that's brainstorm)\n- Whether to build it (user already decided)\n- Architecture approach (that's design)\n\n## Red Flags - STOP If You're About To:\n\n| Action | Why It's Wrong | Do Instead |\n|--------|----------------|------------|\n| Ask without exploration context | Questions will be generic | Reference specific code findings |\n| Propose architecture | Too early, still clarifying | Ask questions, save design for next phase |\n| Make assumptions | Leads to rework | Ask and get explicit answer |\n| Skip to design | Ambiguities cause bugs | Resolve all questions first |\n\n## Output\n\nClarification complete when:\n- All integration points clarified\n- Edge cases resolved\n- Pattern choices made\n- `.claude/SPEC.md` updated with final requirements\n- No remaining ambiguities\n- **Automated testing strategy confirmed (MANDATORY)**\n\n### Testing Strategy Gate Check\n\nBefore proceeding to design, verify in SPEC.md:\n\n```\n[ ] Testing approach documented (unit/integration/E2E)\n[ ] Test framework specified (pytest/jest/playwright/etc.)\n[ ] First test described (what will fail first)\n[ ] Test command documented (how to run tests)\n```\n\n**If any box is unchecked → STOP. Do not proceed to design.**\n\n### REAL Test Gate Check (MANDATORY)\n\nBefore proceeding to design, verify REAL test criteria:\n\n```\n[ ] User workflow confirmed and documented\n[ ] Protocol/transport verified (same as production)\n[ ] UI elements to test identified\n[ ] Testing skill specified (dev-test-electron/playwright/etc.)\n[ ] Test approach matches discovered code paths\n```\n\n**If any box is unchecked → You WILL write fake tests. Clarify now.**\n\n### Fake Test Prevention Gate\n\nAsk yourself:\n1. Does the test do what the user does? (Not a shortcut)\n2. Does the test use the same protocol? (Not a mock)\n3. Does the test verify what the user sees? (Not internal state)\n\nIf ANY answer is \"no\" or \"not sure\" → STOP. Clarify before design.\n\nThis is the last checkpoint before implementation planning. Fake tests caught here save hours of wasted implementation.\n\n## Phase Complete\n\n**REQUIRED SUB-SKILL:** After completing clarification, IMMEDIATELY invoke:\n```\nSkill(skill=\"workflows:dev-design\")\n```\n",
        "lib/skills/dev-delegate/SKILL.md": "---\nname: dev-delegate\nversion: 1.0\ndescription: \"Internal skill used by dev-implement during Phase 5 of /dev workflow. NOT user-facing - should only be invoked by dev-ralph-loop inside each implementation iteration. Handles Task agent spawning with TDD enforcement and two-stage review (spec compliance + code quality).\"\n---\n\n**Announce:** \"I'm using dev-delegate to dispatch implementation subagents.\"\n\n## Contents\n\n- [The Iron Law of Delegation](#the-iron-law-of-delegation)\n- [Where This Fits](#where-this-fits)\n- [The Process](#the-process)\n- [Honesty Requirement](#honesty-requirement)\n- [Rationalization Prevention](#rationalization-prevention)\n\n<EXTREMELY-IMPORTANT>\n## The Iron Law of Delegation\n\n**EVERY IMPLEMENTATION MUST GO THROUGH A TASK AGENT. This is not negotiable.**\n\nMain chat MUST NOT:\n- Write code directly\n- Make \"quick fixes\"\n- Edit implementation files\n- \"Just do this one thing\"\n\n**If you're about to write code in main chat, STOP. Spawn a Task agent instead.**\n</EXTREMELY-IMPORTANT>\n\n## Where This Fits\n\n```\nMain Chat                          Task Agent\n─────────────────────────────────────────────────────\ndev-implement (orchestrates)\n  → dev-ralph-loop (per-task loops)\n    → dev-delegate (this skill)\n      → spawns Task agent ──────→ follows dev-tdd\n                                  uses dev-test tools\n```\n\n**Main chat** uses this skill to spawn Task agents.\n**Task agents** follow `dev-tdd` (TDD protocol) and use `dev-test` (testing tools).\n\n## Core Principle\n\n**Fresh subagent per task + two-stage review = high quality, fast iteration**\n\n- Implementer subagent does the work (following dev-tdd)\n- Spec reviewer confirms it matches requirements\n- Quality reviewer checks code quality\n- Loop until both approve\n\n## When to Use\n\nCalled by `dev-implement` inside each ralph loop iteration. Don't invoke directly.\n\n## The Process\n\n```\nFor each task:\n    1. Dispatch implementer subagent\n       - If questions → answer, re-dispatch\n       - Implements, tests, commits\n    2. Dispatch spec reviewer subagent\n       - If issues → implementer fixes → re-review\n    3. Dispatch quality reviewer subagent\n       - If issues → implementer fixes → re-review\n    4. Mark task complete\n```\n\n## Step 1: Dispatch Implementer\n\n**Pattern:** Use structured delegation template from `lib/references/delegation-template.md`\n\nEvery delegation MUST include:\n1. TASK - What to do\n2. EXPECTED OUTCOME - Success criteria\n3. REQUIRED SKILLS - Why this agent\n4. REQUIRED TOOLS - What they'll need\n5. MUST DO - Non-negotiable constraints\n6. MUST NOT DO - Hard blocks\n7. CONTEXT - Parent session state\n8. VERIFICATION - How to confirm completion\n\nUse this Task invocation (fill in brackets):\n\n```\nTask(subagent_type=\"general-purpose\", prompt=\"\"\"\n# TASK\n\nImplement: [TASK NAME]\n\n## EXPECTED OUTCOME\n\nYou will have successfully completed this task when:\n- [ ] [Success criterion 1]\n- [ ] [Success criterion 2]\n- [ ] Tests pass (TDD enforced)\n- [ ] No regressions in existing tests\n\n## REQUIRED SKILLS\n\nThis task requires:\n- [Language/framework]: [Why]\n- Testing: TDD (test-first mandatory)\n- [Other skills as needed]\n\n## REQUIRED TOOLS\n\nYou will need:\n- Read: Examine existing code\n- Write: Create new files\n- Edit: Modify existing files\n- Bash: Run tests and verify\n\n**Tools denied:** None (full implementation access)\n\n## MUST DO\n\n- [ ] Write test FIRST (TDD RED-GREEN-REFACTOR)\n- [ ] Run test suite after each change\n- [ ] Follow existing code patterns in [file]\n- [ ] [Other non-negotiable requirements]\n\n## MUST NOT DO\n\n- ❌ Write code before test\n- ❌ Skip test execution\n- ❌ Use `any` / `@ts-ignore` / type suppression\n- ❌ Commit broken code\n\n## CONTEXT\n\n### Task Description\n[PASTE FULL TASK TEXT FROM PLAN.md - don't make subagent read file]\n\n### Project Context\n- Project: [brief description]\n- Related files: [list from exploration]\n- Test command: [from SPEC.md]\n\n## TDD Protocol (MANDATORY)\n\n<EXTREMELY-IMPORTANT>\n**LOAD THIS SKILL FIRST:**\n\nBefore writing any code, you MUST load the TDD skill:\n\n```\nSkill(skill=\"workflows:dev-tdd\")\n```\n\nThis loads:\n- Task reframing (your job is writing tests, not features)\n- The Execution Gate (6 mandatory gates before E2E testing)\n- GATE 5: READ LOGS (mandatory - cannot skip)\n- The Iron Law of TDD (test-first approach)\n\n**Load dev-tdd now before proceeding.**\n</EXTREMELY-IMPORTANT>\n\nFollow the RED-GREEN-REFACTOR cycle from dev-tdd:\n\n1. **RED**: Write a failing test FIRST\n   - Run it, SEE IT FAIL\n   - Document: \"RED: [test] fails with [error]\"\n\n2. **GREEN**: Write MINIMAL code to pass\n   - Run test, SEE IT PASS\n   - Document: \"GREEN: [test] passes\"\n\n3. **REFACTOR**: Clean up while staying green\n\n**If you write code before seeing RED, you're not doing TDD. Stop and restart.**\n\n## Testing Tools\n\nFor test options (pytest, Playwright, ydotool), load dev-test skill after dev-tdd.\n\nTests must EXECUTE code and VERIFY behavior. Grepping is NOT testing.\n\n## If Unclear\nAsk questions BEFORE implementing. Don't guess.\n\n## Output\nReport:\n- RED: What test failed and how\n- GREEN: What made it pass\n- Test command and output\n- Commit SHA\n- Any concerns\n\"\"\")\n```\n\n**If implementer asks questions:** Answer clearly, then re-dispatch with answers included.\n\n**If implementer finishes:** Proceed to spec review.\n\n## Step 2: Dispatch Spec Reviewer\n\nUse this Task invocation:\n\n```\nTask(subagent_type=\"general-purpose\", prompt=\"\"\"\nReview spec compliance for: [TASK NAME]\n\n## Original Requirements\n[PASTE TASK TEXT FROM PLAN.md]\n\n## Success Criteria (from SPEC.md)\n[PASTE RELEVANT CRITERIA]\n\n## CRITICAL: Do Not Trust the Report\n\nThe implementer finished suspiciously quickly. Their report may be incomplete,\ninaccurate, or optimistic. You MUST verify everything independently.\n\n**DO NOT:**\n- Take their word for what they implemented\n- Trust their claims about completeness\n- Accept their interpretation of requirements\n\n**DO:**\n- Read the actual code they wrote\n- Compare actual implementation to requirements line by line\n- Check for missing pieces they claimed to implement\n- Look for extra features they didn't mention\n\n## Review Checklist\n1. Does implementation meet ALL requirements?\n2. Is anything MISSING from the spec?\n3. Is anything EXTRA not in the spec?\n\n## Output Format\n- COMPLIANT: All requirements met, nothing extra (after verifying code yourself)\n- ISSUES: List what's missing or extra with file:line references\n\nBe strict. \"Close enough\" is not compliant. Verify by reading code.\n\"\"\")\n```\n\n**If COMPLIANT:** Proceed to quality review.\n\n**If ISSUES:** Have implementer fix, then re-run spec review.\n\n## Step 3: Dispatch Quality Reviewer\n\nUse this Task invocation:\n\n```\nTask(subagent_type=\"general-purpose\", prompt=\"\"\"\nReview code quality for: [TASK NAME]\n\n## Changes to Review\nFiles modified: [list files]\nCommit range: [BASE_SHA]..[HEAD_SHA]\n\n## Review Focus\n1. Code correctness (logic errors, edge cases)\n2. Test coverage (are tests meaningful?)\n3. Code style (matches project conventions?)\n4. No regressions introduced\n\n## Confidence Scoring\nRate each issue 0-100. Only report issues >= 80 confidence.\n\n## Output Format\n### Strengths\n- [what's good]\n\n### Issues (Confidence >= 80)\n#### [Issue Title] (Confidence: XX)\n- Location: [file:line]\n- Problem: [description]\n- Fix: [suggestion]\n\n### Verdict\nAPPROVED or CHANGES REQUIRED\n\"\"\")\n```\n\n**If APPROVED:** Mark task complete, move to next task.\n\n**If CHANGES REQUIRED:** Have implementer fix, then re-run quality review.\n\n## Honesty Requirement\n\n<EXTREMELY-IMPORTANT>\n**Claiming \"done\" without subagent verification is LYING.**\n\nWhen you say \"Task complete\", you are asserting:\n- A Task agent implemented the change\n- Spec reviewer confirmed compliance\n- Quality reviewer approved\n\nIf ANY of these didn't happen, you are not \"summarizing\" or \"moving on\" - you are LYING about the state of the work.\n\n**Dishonest claims destroy trust. Honest \"still working\" builds trust.**\n</EXTREMELY-IMPORTANT>\n\n## Rationalization Prevention\n\nThese thoughts mean STOP—you're about to skip delegation:\n\n| Thought | Reality |\n|---------|---------|\n| \"I'll just fix this quickly\" | Quick = sloppy = bugs. Delegate. |\n| \"The subagent will be slower\" | Subagent time is cheap. Your context is expensive. |\n| \"I already know what to do\" | Knowing ≠ doing correctly. Delegate. |\n| \"It's just one line\" | One line can break everything. Delegate. |\n| \"I'm already looking at the code\" | Looking ≠ editing. Delegate. |\n| \"User is waiting\" | User wants CORRECT, not fast. Delegate. |\n| \"Skip review, it's obviously right\" | \"Obviously\" is how bugs ship. Review. |\n| \"Spec review passed, skip quality\" | Both reviews exist for a reason. Do both. |\n| \"Quality review found nothing, done\" | Did spec review pass first? Check. |\n\n## Red Flags\n\n**Never:**\n- Skip either review (spec OR quality)\n- Proceed with unfixed issues\n- Let implementer self-review replace actual review\n- Start quality review before spec compliance passes\n- Make subagent read plan file (provide full text)\n- Rush past subagent questions\n\n**If subagent fails:**\n- Dispatch fix subagent with specific instructions\n- Don't fix manually in main chat (context pollution)\n\n## Example Flow\n\n```\nMe: Implementing Task 1: Add user validation\n\n[Dispatch implementer with full task text]\n\nImplementer: \"Should validation happen client-side or server-side?\"\n\nMe: \"Server-side only, in the API layer\"\n\n[Re-dispatch implementer with answer]\n\nImplementer:\n- Added validateUser() in api/users.ts\n- Tests: 5/5 passing\n- Committed: abc123\n\n[Dispatch spec reviewer]\n\nSpec Reviewer: ISSUES\n- Missing: Email format validation (spec line 12)\n\n[Tell implementer to fix]\n\nImplementer:\n- Added email regex validation\n- Tests: 6/6 passing\n- Committed: def456\n\n[Re-dispatch spec reviewer]\n\nSpec Reviewer: COMPLIANT\n\n[Dispatch quality reviewer with commit range]\n\nQuality Reviewer: APPROVED\n- Strengths: Good test coverage, clear naming\n- No issues >= 80 confidence\n\n[Mark Task 1 complete, move to Task 2]\n```\n\n## Integration\n\n**Main chat invokes:**\n- `dev-implement` → `dev-ralph-loop` → `dev-delegate` (this skill)\n\n**Task agents follow:**\n- `dev-tdd` - TDD protocol (RED-GREEN-REFACTOR)\n- `dev-test` - Testing tools (pytest, Playwright, ydotool)\n\nAfter all tasks complete with passing tests, `dev-implement` proceeds to `dev-review`.\n",
        "lib/skills/dev-explore/SKILL.md": "---\nname: dev-explore\nversion: 1.0\ndescription: \"REQUIRED Phase 2 of /dev workflow after dev-brainstorm. This skill should be used when the user asks to 'explore the codebase', 'map architecture', 'find similar features', 'discover test infrastructure', 'trace execution paths', 'identify code patterns', or needs to understand WHERE code lives and HOW it works before implementation. Launches parallel explore agents and returns prioritized key files list.\"\n---\n\n**Announce:** \"I'm using dev-explore (Phase 2) to map the codebase.\"\n\n## Contents\n\n- [The Iron Law of Exploration](#the-iron-law-of-exploration)\n- [What Explore Does](#what-explore-does)\n- [Process](#process)\n- [Test Infrastructure Discovery](#test-infrastructure-discovery)\n- [Key Files List Format](#key-files-list-format)\n- [Red Flags](#red-flags---stop-if-youre-about-to)\n- [Output](#output)\n\n# Codebase Exploration\n\nMap relevant code, trace execution paths, and return prioritized files for reading.\n**Prerequisite:** `.claude/SPEC.md` must exist with draft requirements.\n\n<EXTREMELY-IMPORTANT>\n## The Iron Law of Exploration\n\n**RETURN KEY FILES LIST. This is not negotiable.**\n\nEvery exploration, you MUST return:\n1. Summary of findings\n2. **5-10 key files** with line numbers and purpose\n3. Patterns discovered\n\nAfter agents return, **you MUST read all key files** before proceeding.\n\n**STOP if you're about to move on without reading all key files.**\n</EXTREMELY-IMPORTANT>\n\n### Rationalization Table - STOP If Thinking:\n\n| Excuse | Reality | Do Instead |\n|--------|---------|------------|\n| \"I can design without reading all key files\" | You'll miss critical patterns | READ every file on the list |\n| \"The file names tell me enough\" | File names hide implementation details | READ the actual code |\n| \"I'll read them if I need more info\" | You cannot know what is missing | READ all key files NOW |\n| \"Exploration summary is enough\" | Summaries miss crucial nuances | READ original files |\n| \"Reading files will take too long\" | You'll waste days later by skipping them | READ now, save time later |\n| \"I already understand the architecture\" | Your assumptions remain incomplete | READ to confirm understanding |\n| \"I can grep for specific details later\" | You'll miss context and relationships | READ to understand connections |\n\n### Honesty Framing\n\n**Returning key files without reading them is LYING about understanding the codebase.**\n\nExploration agents find the files. Main chat MUST read them to understand the codebase. Skipping reads means proceeding with incomplete knowledge, which guarantees wrong implementation choices.\n\nReading costs minutes. Wrong architecture costs days of rework.\n\n### No Pause After Completion\n\nAfter reading all key files and updating `.claude/SPEC.md` with findings, IMMEDIATELY invoke:\n```\nRead(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-clarify/SKILL.md\")\n```\n\nDO NOT:\n- Summarize findings (proceed directly)\n- Ask \"should I proceed to clarify?\"\n- Wait for user confirmation\n- Write status updates\n\nThe workflow phases are SEQUENTIAL. Complete explore → immediately start clarify.\n\n## What Explore Does\n\n| DO | DON'T |\n|----|-------|\n| Trace execution paths | Ask user questions (that's clarify) |\n| Map architecture layers | Design approaches (that's design) |\n| Find similar features | Write implementation tasks |\n| Identify patterns and conventions | Make architecture decisions |\n| Return key files list | Skip reading key files |\n\n**Explore answers: WHERE is the code and HOW does it work**\n**Design answers: WHAT approach to take** (separate skill)\n\n## Process\n\n### 1. Launch 3-5 Explore Agents in Parallel + Background\n\n<EXTREMELY-IMPORTANT>\n**Launch ALL agents in a SINGLE message with multiple Task calls.**\n\n**Use `run_in_background: true` for ALL explore agents.**\n\nThis enables true parallel execution:\n- All agents start immediately\n- Main conversation continues without blocking\n- Results collected asynchronously with TaskOutput\n\nPattern from oh-my-opencode: Default to background + parallel for exploratory work.\n</EXTREMELY-IMPORTANT>\n\nBased on `.claude/SPEC.md`, spawn 3-5 agents with different focuses:\n\n```\n# PARALLEL + BACKGROUND: All Task calls in ONE message\n\nTask(\n    subagent_type=\"Explore\",\n    description=\"Find similar features\",\n    run_in_background=true,\n    prompt=\"\"\"\nExplore the codebase for [FEATURE AREA].\n\nFocus: Find similar features to [SPEC REQUIREMENT]\n\nUse ast-grep for semantic search:\n- sg -p 'function_name($$$)' --lang [language]\n- sg -p 'class $NAME { $$$ }' --lang [language]\n\nTasks:\n- Trace execution paths from entry point to data storage\n- Find similar implementations to follow\n- Identify patterns used\n- Return 5-10 key files with line numbers\n\nContext from SPEC.md:\n[paste relevant requirements]\n\"\"\")\n\nTask(\n    subagent_type=\"Explore\",\n    description=\"Map architecture layers\",\n    run_in_background=true,\n    prompt=\"\"\"\nExplore the codebase for [FEATURE AREA].\n\nFocus: Map architecture and abstractions for [AREA]\n\nUse ast-grep for semantic search:\n- sg -p 'class $NAME($BASE):' --lang [language]\n- sg -p 'interface $NAME { $$$ }' --lang [language]\n\nTasks:\n- Identify abstraction layers\n- Find cross-cutting concerns (logging, auth, errors)\n- Map module dependencies\n- Return 5-10 key files with line numbers\n\nContext from SPEC.md:\n[paste relevant requirements]\n\"\"\")\n\nTask(\n    subagent_type=\"Explore\",\n    description=\"Find test infrastructure\",\n    run_in_background=true,\n    prompt=\"\"\"\nExplore the codebase for [FEATURE AREA].\n\nFocus: Test infrastructure and patterns\n\nUse ast-grep for test discovery:\n- sg -p 'def test_$NAME($$$):' --lang python\n- sg -p 'it($DESC, $$$)' --lang javascript\n- sg -p '@pytest.fixture' --lang python\n\nTasks:\n- Find test directory and framework\n- Identify existing test patterns\n- Check for fixtures, mocks, helpers\n- Return 5-10 key test files with line numbers\n\nContext from SPEC.md:\n[paste relevant requirements]\n\"\"\")\n```\n\n**After launching all agents in parallel:**\n- Continue immediately to other work (don't wait)\n- Check agent status with `/tasks` command\n- Collect results when ready with TaskOutput tool\n\n### 1b. Collect Background Results\n\nOnce agents complete, collect their findings:\n\n```\n# Check running tasks\n/tasks\n\n# Get results from completed agents\nTaskOutput(task_id=\"task-abc123\", block=true, timeout=30000)\nTaskOutput(task_id=\"task-def456\", block=true, timeout=30000)\nTaskOutput(task_id=\"task-ghi789\", block=true, timeout=30000)\n```\n\n**Stop Conditions** (from oh-my-opencode):\n- Enough context to proceed confidently\n- Same info appearing across multiple agents\n- 2 search iterations yielded nothing new\n- Direct answer found\n\n**DO NOT over-explore. Time is precious.**\n\n### 2. Consolidate Key Files\n\nAfter all agents return, consolidate their key files lists:\n- Remove duplicates\n- Prioritize by relevance to requirements\n- Create master list of 10-15 files\n\n### 3. Read All Key Files\n\n**CRITICAL: Main chat must read every file on the key files list.**\n\n```\nRead(file_path=\"src/auth/login.ts\")\nRead(file_path=\"src/services/session.ts\")\n...\n```\n\nThis builds deep understanding before asking clarifying questions.\n\n### 4. Document Findings\n\nWrite exploration summary (can be verbal or in `.claude/EXPLORATION.md`):\n- Patterns discovered\n- Architecture insights\n- Dependencies identified\n- Questions raised for clarify phase\n\n## Code Search Tools\n\n**Prefer semantic search over text search when exploring code.**\n\nUse ast-grep (`sg`) for precise AST-based pattern matching and ripgrep-all (`rga`) for searching non-code files.\n\n**For detailed patterns and usage, see:** `references/ast-grep-patterns.md`\n\n## Test Infrastructure Discovery (GATE - NOT OPTIONAL)\n\n<EXTREMELY-IMPORTANT>\n**CRITICAL: You MUST discover how to run REAL automated tests.**\n\n**NO TEST INFRASTRUCTURE = NO IMPLEMENTATION. This is a gate, not a finding.**\n\nREAL automated tests EXECUTE code and verify RUNTIME behavior.\nGrepping source files is NOT testing. Log checking is NOT testing.\n\n| ✅ REAL TEST INFRASTRUCTURE | ❌ NOT TESTING (never acceptable) |\n|-----------------------------|-----------------------------------|\n| pytest that calls functions | grep/ast-grep to find code |\n| Playwright that clicks buttons | Reading logs for \"success\" |\n| ydotool that simulates user input | Code review / structure check |\n| API calls that verify responses | \"It looks correct\" |\n\n### The Gate Function\n\n```\nDISCOVER test framework → FOUND?\n├─ YES → Document in SPEC.md, continue to clarify\n└─ NO → STOP. This is a BLOCKER. Cannot proceed without test strategy.\n```\n\n**If no way to EXECUTE and VERIFY exists:**\n1. **STOP exploration** - do not proceed to clarify\n2. **Report to user** - \"No test infrastructure found. This blocks TDD.\"\n3. **Propose solution** - \"Should I add test infrastructure as Task 0?\"\n4. **Wait for resolution** - Do not rationalize around this\n\n### Rationalization Prevention\n\n| Thought | Reality |\n|---------|---------|\n| \"This project doesn't have tests\" | Then add tests. That's Task 0. |\n| \"It's a UI/DOM project, hard to test\" | Use Playwright, ydotool, screenshot comparison |\n| \"SPEC.md says manual testing\" | That's wrong. Fix SPEC.md or ask user. |\n| \"I can add tests later\" | No. TDD means tests FIRST. |\n| \"User won't want to set up tests\" | Ask them. Don't assume. |\n| \"Just this one feature without tests\" | No exceptions. Ever. |\n</EXTREMELY-IMPORTANT>\n\n### Project Test Framework\n\n```bash\n# Find test directories across common locations\nls -d tests/ test/ spec/ __tests__/ 2>/dev/null\n\n# Find test frameworks in build configuration\ncat meson.build 2>/dev/null | grep -i test\n\n# Find test frameworks in Node package manifest\ncat package.json 2>/dev/null | grep -E \"(test|jest|mocha|vitest)\"\n\n# Find pytest configuration in Python projects\ncat pyproject.toml 2>/dev/null | grep -i pytest\n\n# Find dev dependencies in Rust projects\ncat Cargo.toml 2>/dev/null | grep -i \"\\[dev-dependencies\\]\"\n\n# Find and list existing test files\nfind . -name \"*test*\" -type f | head -20\n```\n\n### Available Tools for REAL Testing\n\n| What to Test | Tool | How It's a REAL Test |\n|--------------|------|----------------------|\n| Functions | pytest, jest, cargo test | Calls function, checks return value |\n| CLI | subprocess, execa | Runs binary, checks output |\n| Web UI | Playwright MCP | Clicks button, verifies DOM |\n| Desktop UI | ydotool + grim | Simulates input, screenshots result |\n| API | requests, fetch | Sends request, checks response |\n| D-Bus apps | dbus-send | Invokes method, checks return |\n\n```bash\n# Check for desktop automation tools\nwhich ydotool grim dbus-send 2>/dev/null\n\n# List available D-Bus services for desktop app automation\ndbus-send --session --print-reply --dest=org.freedesktop.DBus \\\n  /org/freedesktop/DBus org.freedesktop.DBus.ListNames 2>/dev/null | grep -i appname\n```\n\n### Document in Exploration Output\n\n**REQUIRED findings for SPEC.md:**\n- **Test framework:** meson test / pytest / jest / etc.\n- **Test command:** Exact command to run tests\n- **How to verify core functionality:** What EXECUTES the code\n- **Available automation:** Playwright MCP, ydotool, D-Bus interfaces\n- **Blocker:** If no way to run REAL tests, flag immediately\n\n## Code Path Discovery (CRITICAL FOR REAL TESTS)\n\n<EXTREMELY-IMPORTANT>\n**You MUST discover the actual code paths that need testing.**\n\nA test that exercises the wrong code path is a FAKE test. For example:\n- Testing HTTP when the app uses WebSocket\n- Testing sync calls when the app uses async\n- Testing direct function calls when users click UI\n\n### What to Discover\n\n| Question | Why It Matters |\n|----------|----------------|\n| What protocol/transport does the feature use? | Tests must use SAME protocol |\n| How does user input reach the code? | Tests must follow SAME path |\n| What does the user actually see? | Tests must verify SAME output |\n| What UI elements are involved? | Tests must interact with SAME elements |\n\n### Discovery Checklist\n\n```\n[ ] Protocol identified (HTTP / WebSocket / IPC / D-Bus / etc.)\n[ ] Entry point traced (UI click / API call / CLI command / etc.)\n[ ] Data flow mapped (user action → ... → visible result)\n[ ] UI components identified (panels, buttons, status bars, etc.)\n```\n\n### Example Discoveries\n\n**Example 1: Web app with GraphQL**\n```markdown\n- **Protocol:** GraphQL over HTTP POST (NOT REST)\n- **Entry point:** User clicks \"Save\" button\n- **Data flow:** click → mutation → server response → UI update\n- **UI component:** Toast notification shows \"Saved successfully\"\n\nA REAL test must use GraphQL mutations, not REST endpoints.\n```\n\n**Example 2: CLI tool**\n```markdown\n- **Protocol:** Command-line invocation with arguments\n- **Entry point:** User runs `mytool --format json input.txt`\n- **Data flow:** argv → parser → processing → stdout\n- **UI component:** Terminal output\n\nA REAL test must invoke the CLI binary, not call internal functions.\n```\n\n**Example 3: Electron app with WebSocket**\n```markdown\n- **Protocol:** WebSocket (NOT HTTP)\n- **Entry point:** User highlights text in editor\n- **Data flow:** selection → WebSocket message → panel update\n- **UI component:** Panel shows status\n\nA REAL test must use WebSocket, not HTTP endpoint.\n```\n\n### Fake Test Prevention\n\n**If you skip code path discovery, you WILL write fake tests.**\n\n| What You'll Do Wrong | Why | Result |\n|---------------------|-----|--------|\n| Test HTTP endpoint | \"Easier to test\" | Wrong code path exercised |\n| Call function directly | \"Faster\" | Skips user workflow |\n| Mock the protocol | \"Simpler\" | Doesn't test real behavior |\n| Check internal state | \"More direct\" | Misses what user sees |\n\n**Update SPEC.md with code path findings before proceeding.**\n</EXTREMELY-IMPORTANT>\n\n## Key Files List Format\n\nEach agent MUST return files in this format:\n\n```markdown\n## Key Files to Read\n\n| Priority | File:Line | Purpose |\n|----------|-----------|---------|\n| 1 | `src/auth/login.ts:45` | Entry point for auth flow |\n| 2 | `src/services/session.ts:12` | Session management |\n| 3 | `src/middleware/auth.ts:78` | Auth middleware |\n| 4 | `src/types/user.ts:1` | User type definitions |\n| 5 | `tests/auth/login.test.ts:1` | Existing test patterns |\n```\n\n## Red Flags - STOP If You're About To:\n\n| Action | Why It's Wrong | Do Instead |\n|--------|----------------|------------|\n| Skip reading key files | You'll miss crucial context | Read every file on the list |\n| Ask design questions | You're conflating exploration with design | Save for clarify/design phases |\n| Propose approaches | You're jumping to decisions too early | Just document what exists |\n| Start implementing | You must understand first | Complete exploration fully |\n\n## Output\n\nExploration complete when:\n- 2-3 explore agents returned findings\n- Key files list consolidated (10-15 files)\n- **All key files read by main chat**\n- Patterns and architecture documented\n- **Test infrastructure documented OR blocker raised**\n- Questions for clarification identified\n\n### Required Output Sections\n\n1. **Key Files** - 10-15 files with line numbers\n2. **Architecture** - Layers, patterns, conventions\n3. **Test Infrastructure** - Framework, tools, patterns\n4. **Code Paths** - Protocol, entry points, data flow, UI components\n5. **Questions** - For clarify phase\n\n### Test Infrastructure Gate Check (MANDATORY)\n\nBefore proceeding to clarify, verify:\n\n```\n[ ] Test framework identified (pytest/jest/playwright/etc.)\n[ ] Test command documented (how to run tests)\n[ ] At least one existing test file found OR\n[ ] User approved adding test infrastructure as Task 0\n```\n\n**If ALL boxes are unchecked → STOP. Ask user how to proceed.**\n\n### Code Path Gate Check (MANDATORY FOR REAL TESTS)\n\nBefore proceeding to clarify, verify code paths documented:\n\n```\n[ ] Protocol/transport identified (WebSocket/HTTP/IPC/etc.)\n[ ] User entry point traced (what action triggers the feature)\n[ ] Data flow mapped (input → ... → output)\n[ ] UI components identified (what user sees)\n[ ] Testing skill determined (dev-test-electron/playwright/etc.)\n```\n\n**If any box is unchecked → You WILL write fake tests. Complete discovery first.**\n\nThis is not optional. Fake tests are worse than no tests because they create false confidence.\n\n## Phase Complete\n\n**REQUIRED SUB-SKILL:** After completing exploration, IMMEDIATELY invoke:\n```\nRead(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-clarify/SKILL.md\")\n```\n",
        "lib/skills/dev-explore/references/ast-grep-patterns.md": "# Code Search Tools for Exploration\n\n**Prefer semantic search over text search when exploring code.**\n\n## ast-grep (sg) - Semantic Code Search\n\nUse `sg` for precise code pattern matching using AST:\n\n```bash\n# Find function calls\nsg -p 'foo($$$)' --lang python\n\n# Find function definitions\nsg -p 'def $FUNC($$$):' --lang python\n\n# Find class definitions\nsg -p 'class $NAME { $$$ }' --lang typescript\n\n# Find struct usage (Go/Rust/C)\nsg -p 'zathura_page_t' --lang c\n\n# Find method calls on specific types\nsg -p '$OBJ.render($$$)' --lang python\n```\n\n**When to use ast-grep vs grep:**\n\n| Use ast-grep | Use grep |\n|--------------|----------|\n| Find function calls/definitions | Find text in comments/strings |\n| Find class/struct usage | Find config values |\n| Trace method invocations | Search non-code files |\n| Refactor patterns | Quick keyword search |\n\n## ripgrep-all (rga) - Search Everything\n\nUse `rga` when you need to search inside:\n- PDFs, Word docs, Excel, PowerPoint\n- Zip/tar archives\n- SQLite databases\n- Images (OCR)\n\n```bash\n# Search inside PDFs\nrga \"pattern\" docs/\n\n# Search with context\nrga -C 3 \"error handling\" .\n\n# Limit to specific types\nrga --type pdf \"methodology\" papers/\n```\n\n## Additional Resources\n\nFor more advanced ast-grep patterns, see:\n- ast-grep documentation: https://ast-grep.github.io/\n- Language-specific pattern syntax\n- Custom rule creation\n",
        "lib/skills/dev-implement/SKILL.md": "---\nname: dev-implement\nversion: 1.0\ndescription: \"REQUIRED Phase 5 of /dev workflow. Orchestrates per-task ralph loops with delegated TDD implementation.\"\n---\n\n**Announce:** \"I'm using dev-implement (Phase 5) to orchestrate implementation.\"\n\n## Where This Fits\n\n```\nMain Chat (you)                    Task Agent\n─────────────────────────────────────────────────────\ndev-implement (this skill)\n  → dev-ralph-loop (per-task loops)\n    → dev-delegate (spawn agents)\n      → Task agent ──────────────→ follows dev-tdd\n                                   uses dev-test tools\n```\n\n**Main chat orchestrates.** Task agents implement.\n\n## Contents\n\n- [Prerequisites](#prerequisites)\n- [The Iron Law of Delegation](#the-iron-law-of-delegation)\n- [The Process](#the-process)\n- [Sub-Skills Reference](#sub-skills-reference)\n- [If Max Iterations Reached](#if-max-iterations-reached)\n- [Phase Complete](#phase-complete)\n\n# Implementation (Orchestration)\n\n<EXTREMELY-IMPORTANT>\n## Prerequisites\n\n**Do NOT start implementation without these:**\n\n1. `.claude/SPEC.md` exists with final requirements\n2. `.claude/PLAN.md` exists with chosen approach\n3. **User explicitly approved** in /dev-design phase\n4. **PLAN.md Testing Strategy section is COMPLETE** (all boxes checked)\n\nIf any prerequisite is missing, STOP and complete the earlier phases.\n\n**Check PLAN.md for:** files to modify, implementation order, testing strategy.\n\n### Pre-Flight Testing Check (MANDATORY)\n\nBefore starting ANY task, verify PLAN.md Testing Strategy:\n\n```\n[ ] Framework specified (not empty, not \"TBD\")\n[ ] Test Command specified (runnable command)\n[ ] First Failing Test described (specific test name)\n[ ] Test File Location specified (actual path)\n```\n\n**If ANY box is unchecked → STOP. Go back to design phase.**\n\nThis is your LAST CHANCE to catch missing test strategy before writing code.\n</EXTREMELY-IMPORTANT>\n\n<EXTREMELY-IMPORTANT>\n## The Iron Law of TDD (Final Enforcement)\n\n**YOU CANNOT WRITE IMPLEMENTATION CODE WITHOUT A FAILING TEST FIRST.**\n\nThis is not a suggestion. This is the workflow. Every task follows:\n\n```\n1. READ the test description from PLAN.md\n2. WRITE the test file\n3. RUN the test → SEE RED (failure)\n4. ONLY THEN write implementation\n5. RUN the test → SEE GREEN (pass)\n```\n\n### Rationalization Prevention (Implementation Phase)\n\nIf you catch yourself thinking these, STOP IMMEDIATELY:\n\n| Thought | Reality | Action |\n|---------|---------|--------|\n| \"No test infra, I'll just implement\" | You should have caught this in explore/clarify | STOP. Go back. Add Task 0. |\n| \"SPEC.md says manual testing\" | SPEC.md is wrong | STOP. Fix SPEC.md. Ask user. |\n| \"This task is too simple for tests\" | Simple tasks benefit MOST from tests | Write the test anyway. |\n| \"I'll add tests after this works\" | That's not TDD. That's lying. | DELETE your code. Write test first. |\n| \"User is waiting, I'll be quick\" | User wants WORKING code, not fast code | Take time. Write test first. |\n| \"The subagent skipped tests\" | Your job is to catch that | REJECT the work. Redo with tests. |\n| \"Just this one exception\" | No exceptions. Ever. | Write the test. |\n\n**If you wrote code without a failing test first, DELETE IT and start over.**\n</EXTREMELY-IMPORTANT>\n\n<EXTREMELY-IMPORTANT>\n## The Iron Law of Delegation\n\n**MAIN CHAT MUST NOT WRITE CODE. This is not negotiable.**\n\nMain chat orchestrates. Subagents implement. If you catch yourself about to use Write or Edit on a code file, STOP.\n\n| Allowed in Main Chat | NOT Allowed in Main Chat |\n|---------------------|--------------------------|\n| Spawn Task agents | Write/Edit code files |\n| Review Task agent output | Direct implementation |\n| Write to .claude/*.md files | \"Quick fixes\" |\n| Run git commands | Any code editing |\n| Start ralph loops | Bypassing delegation |\n\n**If you're about to edit code directly, STOP and spawn a Task agent instead.**\n\n### Rationalization Prevention\n\nThese thoughts mean STOP—you're rationalizing:\n\n| Thought | Reality |\n|---------|---------|\n| \"It's just a small fix\" | Small fixes become big mistakes. Delegate. |\n| \"I'll be quick\" | Quick means sloppy. Delegate. |\n| \"The subagent will take too long\" | Subagent time is cheap. Your context is expensive. |\n| \"I already know what to do\" | Knowing ≠ doing it well. Delegate. |\n| \"Let me just do this one thing\" | One thing leads to another. Delegate. |\n| \"This is too simple for a subagent\" | Simple is exactly when delegation works best. |\n| \"I'm already here in the code\" | Being there ≠ writing there. Delegate. |\n| \"The user is waiting\" | User wants DONE, not fast. They won't debug your shortcuts. |\n| \"This is just porting/adapting code\" | Porting = writing = code. Delegate. |\n| \"I already have context loaded\" | Fresh context per task is the point. Delegate. |\n| \"It's config, not real code\" | JSON/YAML/TOML = code. Delegate. |\n| \"I need to set things up first\" | Setup IS implementation. Delegate. |\n| \"This is boilerplate\" | Boilerplate = code = delegate. |\n| \"PLAN.md is detailed, just executing\" | Execution IS implementation. Delegate. |\n\n### The Meta-Rationalization\n\n**If you're treating these rules as \"guidelines for complex work\" rather than \"invariants for ALL work\", you've already failed.**\n\nSimple work is EXACTLY when discipline matters most—because that's when you're most tempted to skip it.\n</EXTREMELY-IMPORTANT>\n\n## The Process\n\n```\nFor each task N in PLAN.md:\n    1. Start ralph loop for task N\n       → Read(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-ralph-loop/SKILL.md\")\n\n    2. Inside loop: spawn Task agent\n       → Read(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-delegate/SKILL.md\")\n\n    3. Task agent follows TDD (dev-tdd) using testing tools (dev-test)\n\n    4. Verify tests pass, output promise\n\n    5. Move to task N+1, start NEW ralph loop\n```\n\n### Step 1: Start Ralph Loop for Each Task\n\n**REQUIRED SUB-SKILL:**\n```\nRead(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-ralph-loop/SKILL.md\")\n```\n\nKey points from dev-ralph-loop:\n- ONE loop PER TASK (not one loop for feature)\n- Each task gets its own completion promise\n- Don't move to task N+1 until task N's loop completes\n\n### Step 2: Inside Loop - Spawn Task Agent\n\n**REQUIRED SUB-SKILL:**\n```\nRead(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-delegate/SKILL.md\")\n```\n\nKey points from dev-delegate:\n- Implementer → Spec reviewer → Quality reviewer\n- Task agent follows dev-tdd protocol\n- Task agent uses dev-test tools\n\n### Step 3: Verify and Complete\n\nAfter Task agent returns, verify:\n- [ ] Tests EXECUTE code (not grep)\n- [ ] Tests PASS (SKIP ≠ PASS)\n- [ ] LEARNINGS.md has actual output\n- [ ] Build succeeds\n\n**If ALL pass → output the promise.** If ANY fail → iterate.\n\n## Sub-Skills Reference\n\n| Skill | Purpose | Used By |\n|-------|---------|---------|\n| `dev-ralph-loop` | Per-task loop pattern | Main chat |\n| `dev-delegate` | Task agent templates | Main chat |\n| `dev-tdd` | TDD protocol (RED-GREEN-REFACTOR) | Task agent |\n| `dev-test` | Testing tools (pytest, Playwright, etc.) | Task agent |\n\n## Failure Recovery Protocol\n\n**Pattern from oh-my-opencode: After 3 consecutive implementation failures, escalate.**\n\n### 3-Failure Trigger\n\nIf you attempt 3 implementations and ALL fail tests:\n\n```\nIteration 1: Implement approach A → tests fail\nIteration 2: Implement approach B → tests fail\nIteration 3: Implement approach C → tests fail\n→ TRIGGER RECOVERY PROTOCOL\n```\n\n### Recovery Steps\n\n1. **STOP** all further implementation attempts\n   - No more \"let me try a different approach\"\n   - No guessing or throwing code at the problem\n\n2. **REVERT** to last known working state\n   - `git checkout <last-passing-commit>`\n   - Or revert specific files\n   - Document what was attempted in `.claude/RECOVERY.md`\n\n3. **DOCUMENT** what was attempted\n   - All 3 approaches tried\n   - Test failures for each\n   - Why each approach failed\n   - What this reveals about the problem\n\n4. **CONSULT** with user BEFORE continuing\n   - \"I've tried 3 approaches. All fail tests. Here's what I've learned...\"\n   - Present test failure patterns\n   - Request: requirements clarification, design input, or different strategy\n\n5. **ASK USER** for direction\n   - Option A: Re-examine requirements (may need /dev-clarify)\n   - Option B: Try completely different design (may need /dev-design)\n   - Option C: Investigate why tests fail (may need /dev-debug)\n   - Option D: User provides domain knowledge\n\n**NO PASSING TESTS = NOT COMPLETE** (hard rule)\n\n### Recovery Checklist\n\nBefore continuing after multiple failures:\n\n- [ ] All 3 approaches documented with test failures\n- [ ] Pattern in failures identified (same tests? different errors?)\n- [ ] Current code reverted to clean state\n- [ ] User consulted with specific question\n- [ ] Clear direction from user before proceeding\n\n### Anti-Patterns After Failures\n\n**DON'T:**\n- Keep trying \"just one more thing\"\n- Make larger and larger changes\n- Skip TDD \"to get it working first\"\n- Suppress test failures (\"I'll fix them later\")\n- Blame the tests (\"tests are wrong\")\n\n**DO:**\n- Stop and analyze the failure pattern\n- Revert to clean state\n- Document what each approach revealed\n- Consult user with specific findings\n- Get clear direction before continuing\n\n### Example Recovery Flow\n\n```\nLoop 1: Implement with synchronous approach → Tests timeout\nLoop 2: Implement with async/await → Tests hang\nLoop 3: Implement with promises → Tests fail assertion\n\n→ RECOVERY PROTOCOL:\n1. STOP (no loop 4)\n2. REVERT: git checkout HEAD -- src/feature.ts tests/\n3. DOCUMENT in .claude/RECOVERY.md:\n   - Pattern: All async implementations cause timing issues\n   - Tests expect synchronous behavior\n   - Hypothesis: Requirements may need async, tests don't handle it\n4. ASK USER:\n   \"I've tried 3 async implementations. All cause timing issues.\n    Tests expect synchronous behavior.\n\n    This suggests either:\n    A) Feature should actually be synchronous (simpler)\n    B) Tests need updating for async behavior\n\n    Which direction should I take?\"\n```\n\n### When to Trigger Recovery\n\nTrigger after 3 failures when:\n- Same test keeps failing despite different approaches\n- Different tests fail in pattern (suggests wrong approach)\n- Tests pass locally but fail in CI\n- Implementation works but breaks unrelated tests\n\nDon't wait for max iterations - trigger early when pattern emerges.\n\n## If Max Iterations Reached\n\nRalph exits after max iterations. **Still do NOT ask user to manually test.**\n\nMain chat should:\n1. **Summarize** what's failing (from LEARNINGS.md)\n2. **Report** which automated tests fail and why\n3. **Ask user** for direction:\n   - A) Start new loop with different approach\n   - B) Add more logging to debug\n   - C) User provides guidance\n   - D) User explicitly requests manual testing\n\n**Never default to \"please test manually\".** Always exhaust automation first.\n\n## No Pause Between Tasks\n\n<EXTREMELY-IMPORTANT>\n**After completing task N, IMMEDIATELY start task N+1 in the SAME RESPONSE. Do NOT pause.**\n\n### Post-Promise Checklist (mandatory, same response)\n\n1. **Update PLAN.md** - Mark task `[x]` complete\n2. **Log to LEARNINGS.md** - What was done\n3. **Start next task's ralph loop** - No waiting\n\n| Thought | Reality |\n|---------|---------|\n| \"Task done, let me check in with user\" | NO. User wants ALL tasks done. Keep going. |\n| \"User might want to review\" | User will review at the END. Continue. |\n| \"Natural pause point\" | Only pause when ALL tasks complete or blocked. |\n| \"Let me summarize progress\" | Summarize AFTER all tasks. Keep moving. |\n| \"User has been waiting\" | User is waiting for COMPLETION, not updates. |\n| \"Should I continue?\" | YES. Never ask. Just continue. |\n| \"I'll update PLAN.md later\" | NO. Update it NOW before next task. |\n\n### Valid Stopping Points (only these three)\n\n1. ALL tasks in PLAN.md are marked `[x]` complete\n2. You hit a blocker requiring user input (state exactly what you need)\n3. User explicitly interrupted\n\nThe promise signals task completion. After outputting promise, update PLAN.md, then IMMEDIATELY start next task's loop.\n\n**Pausing between tasks is procrastination disguised as courtesy.**\n</EXTREMELY-IMPORTANT>\n\n## Phase Complete\n\n**REQUIRED SUB-SKILL:** After ALL tasks complete with passing tests:\n```\nRead(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-review/SKILL.md\")\n```\n\nDo NOT proceed until automated tests pass for every task.\n",
        "lib/skills/dev-ralph-loop/SKILL.md": "---\nname: dev-ralph-loop\ndescription: \"Per-task ralph loop pattern for implementation and debugging. One loop per task, not one loop per feature.\"\n---\n\n**Announce:** \"I'm using dev-ralph-loop to set up verification loops.\"\n\n<EXTREMELY-IMPORTANT>\n## Load TDD Enforcement (REQUIRED)\n\nBefore starting ANY ralph loop, you MUST load the TDD skill to remember the testing gates and task reframing:\n\n```\nSkill(skill=\"workflows:dev-tdd\")\n```\n\nThis loads:\n- Task reframing (your job is writing tests, not features)\n- The Execution Gate (6 mandatory gates before E2E testing)\n- GATE 5: READ LOGS (mandatory - cannot skip)\n- The Iron Law of TDD (test-first approach)\n\n**Read dev-tdd skill content now before proceeding with ralph loops.**\n</EXTREMELY-IMPORTANT>\n\n## Contents\n\n- [The Iron Law](#the-iron-law-of-ralph-loops)\n- [Per-Task Pattern](#the-per-task-pattern)\n- [Starting a Loop](#starting-a-loop)\n- [Inside the Loop](#inside-the-loop)\n- [Completing a Loop](#completing-a-loop)\n- [Example: Multi-Task Feature](#example-multi-task-feature)\n- [Rationalizations](#rationalization-prevention)\n\n# Ralph Loop Pattern\n\n<EXTREMELY-IMPORTANT>\n## The Iron Law of Ralph Loops\n\n**ONE LOOP PER TASK. NOT ONE LOOP PER FEATURE. This is not negotiable.**\n\nA single feature-level loop provides ZERO per-task enforcement. You can just move to the next task without the loop actually gating anything.\n\nEach task in PLAN.md gets its own ralph loop with its own completion promise.\n</EXTREMELY-IMPORTANT>\n\n## The Per-Task Pattern\n\n```\nFor task N in PLAN.md (1, 2, 3, ...):\n    1. Start ralph loop for task N\n    2. Inside loop: spawn Task agents, iterate until done\n    3. Output promise → loop ends\n    4. Move to task N+1, start NEW ralph loop\n```\n\n**Why per-task loops?**\n- Feature loops don't enforce task completion\n- Without a loop per task, you can just... move on\n- Each task needs its own completion gate\n- The promise is your proof that the task is done\n\n## Starting a Loop\n\n**IMPORTANT:** Avoid parentheses `()` in the prompt - they break zsh argument parsing.\nUse dashes or brackets instead.\n\n### For Implementation Tasks\n\n```\nSkill(skill=\"ralph-loop:ralph-loop\", args=\"Task N: [TASK NAME] --max-iterations 10 --completion-promise TASKN_DONE\")\n```\n\n### For Debug Tasks\n\n```\nSkill(skill=\"ralph-loop:ralph-loop\", args=\"Debug: [SYMPTOM] --max-iterations 15 --completion-promise FIXED\")\n```\n\n### Parameters\n\n| Parameter | Purpose | Recommendation |\n|-----------|---------|----------------|\n| Prompt | What this loop is for | Be specific: \"Task 2: Add auth service\" |\n| `--max-iterations` | Safety limit | 10 for implementation, 15 for debugging |\n| `--completion-promise` | The completion gate | Unique per task: TASK1_DONE, TASK2_DONE, etc. |\n\n## Inside the Loop\n\nEach iteration follows this pattern:\n\n### 1. Spawn Task Agent\n\n```\nTask(subagent_type=\"general-purpose\", prompt=\"\"\"\n[TASK-SPECIFIC INSTRUCTIONS]\n\nContext:\n- Read .claude/LEARNINGS.md for prior attempts\n- Read .claude/SPEC.md for requirements\n- Read .claude/PLAN.md for approach\n\nReport back: what was done, results, any blockers.\n\"\"\")\n```\n\n### 2. Verify Results\n\nAfter Task agent returns:\n- Check if the work is actually complete\n- Verify tests pass (for implementation)\n- Verify bug is fixed (for debugging)\n\n### 3. Decide: Promise or Iterate\n\n**If complete:** Output the promise\n```\n<promise>TASKN_DONE</promise>\n```\n\n**If incomplete:** Do NOT output promise. Spawn another Task agent to continue.\n\n<EXTREMELY-IMPORTANT>\n## Promise Rules\n\n**You may ONLY output the promise when the statement is COMPLETELY AND UNEQUIVOCALLY TRUE.**\n\nThe promise is a claim that:\n- For implementation: \"This task's tests pass. The implementation is complete.\"\n- For debugging: \"The bug is fixed. Regression test passes.\"\n\nYou may NOT output the promise to:\n- \"Move on\" to the next task\n- \"Try something else\"\n- Skip verification\n\n**If the promise isn't true, don't output it. Keep iterating.**\n</EXTREMELY-IMPORTANT>\n\n## Completing a Loop\n\nWhen you output the promise, the ralph loop ends. Then:\n\n1. **Update PLAN.md** - Mark task complete:\n   ```\n   - [ ] Task N: Description  →  - [x] Task N: Description\n   ```\n2. **Log to LEARNINGS.md** - What was done, any discoveries\n3. **Immediately start next task's loop** - Same response, no pause\n\n<EXTREMELY-IMPORTANT>\n## The Iron Law of Progression\n\n**After outputting a promise, you MUST start the next task within the SAME RESPONSE.**\n\nNot \"should\". Not \"recommended\". MUST.\n\n| If you're about to... | Instead... |\n|----------------------|------------|\n| End your response after a promise | Continue with next task's loop invocation |\n| Ask \"should I continue?\" | Just continue |\n| Summarize progress so far | Save it for when ALL tasks are done |\n| Wait for user acknowledgment | User doesn't need to acknowledge each task |\n\n**The only valid stopping points:**\n1. ALL tasks in PLAN.md are marked `[x]` complete\n2. You hit a blocker that requires user input (be specific about what you need)\n3. User explicitly interrupted\n\nFinishing one task is NOT a stopping point. The user is waiting for the FEATURE, not status updates.\n</EXTREMELY-IMPORTANT>\n\n## Example: Multi-Task Feature\n\n```\n## Task 1: Create types\nSkill(skill=\"ralph-loop:ralph-loop\", args=\"Task 1: Create types --max-iterations 5 --completion-promise TASK1_DONE\")\n\n[Spawn Task agent → implements types]\n[Verify: tsc --noEmit passes]\n\n<promise>TASK1_DONE</promise>\n\n[Update PLAN.md: - [ ] Task 1 → - [x] Task 1]\n[Log to LEARNINGS.md]\n[IMMEDIATELY continue to Task 2 - same response]\n\n## Task 2: Add service method\nSkill(skill=\"ralph-loop:ralph-loop\", args=\"Task 2: Add service method --max-iterations 10 --completion-promise TASK2_DONE\")\n\n[Spawn Task agent → implements method]\n[Verify: tests fail → iterate]\n[Spawn Task agent → fixes tests]\n[Verify: tests pass]\n\n<promise>TASK2_DONE</promise>\n\n[Update PLAN.md: - [ ] Task 2 → - [x] Task 2]\n[Log to LEARNINGS.md]\n[IMMEDIATELY continue to Task 3 - same response]\n\n## Task 3: Add route handler\nSkill(skill=\"ralph-loop:ralph-loop\", args=\"Task 3: Add route handler --max-iterations 10 --completion-promise TASK3_DONE\")\n\n[Spawn Task agent → implements route]\n[Verify: integration test passes]\n\n<promise>TASK3_DONE</promise>\n\n[Update PLAN.md: - [ ] Task 3 → - [x] Task 3]\n[Log to LEARNINGS.md]\n\n## All tasks complete - NOW you can stop\n```\n\n## Rationalization Prevention\n\nThese thoughts mean STOP—you're about to skip enforcement:\n\n| Thought | Reality |\n|---------|---------|\n| \"One loop for the whole feature\" | NO. One loop PER TASK. Feature loops don't enforce. |\n| \"I'll just move to the next task\" | Did the current task's loop complete? If no loop, no gate. |\n| \"Per-task loops are overhead\" | Per-task loops are the ONLY enforcement. |\n| \"Ralph is for hard problems\" | Ralph is for ALL tasks. Simple tasks need gates too. |\n| \"I'll iterate without the loop\" | Without ralph, you'll declare done prematurely. |\n| \"The ceremony isn't worth it\" | The ceremony IS the value. It prevents shortcuts. |\n| \"I'll cherry-pick the parts I need\" | Skills are protocols, not menus. Follow all of it. |\n| \"Tests passed on first try, skip loop\" | Still need the loop structure. Lucky ≠ verified. |\n| \"Task done, let me check in\" | NO. Update PLAN.md, then start next task immediately. |\n| \"User might want to review\" | User wants ALL tasks done. Keep going. |\n| \"Natural pause point\" | Only pause when ALL tasks complete. |\n| \"I'll update PLAN.md later\" | NO. Update it NOW, right after the promise. |\n| \"PLAN.md is just documentation\" | PLAN.md is the source of truth. Keep it current. |\n| \"Should I continue?\" | YES. Don't ask. Just continue to the next task. |\n\n**Each task needs its own ralph loop. One feature loop provides ZERO per-task enforcement.**\n\n**After outputting a promise: (1) Update PLAN.md, (2) Log to LEARNINGS.md, (3) Start next task's loop. All in the same response.**\n\n## When NOT to Use Ralph Loops\n\nRalph loops are for:\n- Implementation tasks (dev-implement)\n- Bug fixes (dev-debug)\n\nRalph loops are NOT for:\n- Exploration (dev-explore)\n- Design (dev-design)\n- Data science (ds uses output-first verification instead)\n- Review phases (dev-review, ds-review)\n\n## Integration\n\nThis skill is invoked by:\n- `dev-implement` - for implementation tasks\n- `dev-debug` - for bug investigation and fixes\n\nAfter all tasks complete, proceed to the next phase of the parent workflow.\n",
        "lib/skills/dev-review/SKILL.md": "---\nname: dev-review\ndescription: \"This skill should be used as REQUIRED Phase 6 of /dev workflow when the implementation is complete and needs code review. Combines spec compliance and code quality checks with confidence-based filtering.\"\n---\n\n## Contents\n\n- [Prerequisites - Test Output Gate](#prerequisites---test-output-gate)\n- [The Iron Law of Review](#the-iron-law-of-review)\n- [Red Flags - STOP Immediately If You Think](#red-flags---stop-immediately-if-you-think)\n- [Review Focus Areas](#review-focus-areas)\n- [Confidence Scoring](#confidence-scoring)\n- [Required Output Structure](#required-output-structure)\n- [Agent Invocation](#agent-invocation)\n- [Quality Standards](#quality-standards)\n\n# Code Review\n\nSingle-pass code review combining spec compliance and quality checks. Uses confidence-based filtering to report only high-priority issues.\n\n<EXTREMELY-IMPORTANT>\n## Prerequisites - Test Output Gate\n\n**Do NOT start review without test evidence.**\n\nBefore reviewing, verify these preconditions:\n1. `.claude/LEARNINGS.md` contains **actual test output**\n2. Tests were **run** (not just written)\n3. Test output shows **PASS** (not SKIP, not assumed)\n\n### What Counts as Test Evidence\n\n| Valid Evidence | NOT Valid |\n|----------------|-----------|\n| `meson test` output with results | \"Tests should pass\" |\n| `pytest` output showing PASS | \"I wrote tests\" |\n| Screenshot of working UI | \"It looks correct\" |\n| Playwright snapshot showing expected state | \"User can verify\" |\n| D-Bus command output | \"The feature works\" |\n| **E2E test output with user flow verified** | **\"Unit tests pass\" (for UI changes)** |\n\n<EXTREMELY-IMPORTANT>\n### The E2E Evidence Requirement\n\n**FOR USER-FACING CHANGES: Unit test evidence is INSUFFICIENT.**\n\nBefore approving user-facing changes, verify:\n1. Unit tests pass (necessary but not sufficient)\n2. **E2E tests pass** (required for approval)\n3. Visual evidence exists (screenshots/snapshots for UI)\n\n| Change Type | Unit Evidence | E2E Evidence | Approval? |\n|-------------|---------------|--------------|------------|\n| Internal refactor | ✅ | N/A | ✅ APPROVE |\n| API change | ✅ | ❌ Missing | ❌ BLOCKED |\n| UI change | ✅ | ❌ Missing | ❌ BLOCKED |\n| User workflow | ✅ | ❌ Missing | ❌ BLOCKED |\n\nReturn BLOCKED if E2E evidence is missing for user-facing changes.\n\n\"Unit tests pass\" without E2E for UI changes is NOT approvable.\n</EXTREMELY-IMPORTANT>\n\n### Gate Check\n\nCheck LEARNINGS.md for test output:\n\n```bash\nrg -E \"(PASS|OK|SUCCESS|\\d+ passed)\" .claude/LEARNINGS.md\n```\n\nIf no test output is found, STOP and return to /dev-implement.\n\n\"It should work\" is NOT evidence. Test output IS evidence.\n</EXTREMELY-IMPORTANT>\n\n<EXTREMELY-IMPORTANT>\n## The Iron Law of Review\n\n**You MUST report only issues with >= 80% confidence. This is not negotiable.**\n\nBefore reporting ANY issue, complete these verification steps:\n1. Verify it's not a false positive\n2. Verify it's not a pre-existing issue\n3. Assign a confidence score\n4. Report only if score >= 80\n\nYou MUST apply this rule even when encountering:\n- \"This looks suspicious\"\n- \"I think this might be wrong\"\n- \"The style seems inconsistent\"\n- \"I would have done it differently\"\n\nYou MUST discard any low-confidence issue found during review.\n</EXTREMELY-IMPORTANT>\n\n## Red Flags - STOP Immediately If You Think:\n\n| Thought | Why It's Wrong | Do Instead |\n|---------|----------------|------------|\n| \"Tests probably pass\" | You don't have evidence - absence of evidence is not evidence | Check LEARNINGS.md for actual output |\n| \"This looks wrong\" | Your vague suspicion ≠ evidence | Find concrete proof or discard |\n| \"I would do it differently\" | Your style preference ≠ bug | Check if it violates project guidelines |\n| \"This might cause problems\" | Your \"might\" = < 80% confidence | Find proof or discard |\n| \"Pre-existing but should be fixed\" | You're out of scope | Score it 0 and discard |\n| \"User can test it\" | Your manual testing is less reliable than automation | Return to implement phase |\n\n## Review Focus Areas\n\n### Test Evidence (Check First!)\n- [ ] LEARNINGS.md contains actual test command output\n- [ ] Tests show PASS/OK (not SKIP, FAIL, or missing)\n- [ ] UI changes have screenshot/snapshot evidence\n- [ ] All test types run (unit, integration, UI as applicable)\n- [ ] E2E tests exist and pass for user-facing changes\n- [ ] E2E test simulates actual user flow, not just component render\n\n### Spec Compliance\n- [ ] All requirements from .claude/SPEC.md are implemented\n- [ ] Acceptance criteria are met\n- [ ] No requirements were skipped or partially implemented\n- [ ] Edge cases mentioned in spec are handled\n\n### Code Quality\n- [ ] Code is simple and DRY (no unnecessary duplication)\n- [ ] Logic is correct (no bugs, handles edge cases)\n- [ ] Codebase conventions followed (naming, patterns, structure)\n- [ ] Error handling is complete\n- [ ] No security vulnerabilities detected\n\n## Confidence Scoring\n\nRate each potential issue from 0-100:\n\n| Score | Meaning |\n|-------|---------|\n| 0 | False positive or pre-existing issue |\n| 25 | Might be real, might not. Stylistic without guideline backing |\n| 50 | Real issue but nitpick or rare in practice |\n| 75 | Verified real issue, impacts functionality |\n| 100 | Absolutely certain, confirmed with direct evidence |\n\n**CRITICAL: Only report issues with confidence >= 80.**\n\n## Required Output Structure\n\n```markdown\n## Code Review: [Feature/Change Name]\nReviewing: [files/scope being reviewed]\n\n### Test Evidence Verified\n- Unit tests: [PASS/FAIL/MISSING] - [paste key output line]\n- Integration: [PASS/FAIL/N/A]\n- UI/Visual: [Screenshot taken / Snapshot verified / N/A]\n\n### Critical Issues (Confidence >= 90)\n\n#### [Issue Title] (Confidence: XX)\n\n**Location:** `file/path.ext:line_number`\n\n**Problem:** Clear description of the issue\n\n**Fix:**\n```[language]\n// Specific code fix\n```\n\n### Important Issues (Confidence 80-89)\n\n[Same format as Critical Issues]\n\n### Summary\n\n**Verdict:** APPROVED | CHANGES REQUIRED | BLOCKED (no test evidence)\n\n[If APPROVED]\nThe reviewed code meets project standards. Tests pass. No issues with confidence >= 80 detected.\n\n[If CHANGES REQUIRED]\nX critical issues and Y important issues must be addressed before proceeding.\n\n[If BLOCKED]\nCannot approve without test evidence. Return to /dev-implement and run tests.\n```\n\n## Agent Invocation\n\nSpawn Task agent for review execution:\n\n```\nTask(subagent_type=\"general-purpose\"):\n\"Review implementation against .claude/SPEC.md.\n\nFIRST: Check .claude/LEARNINGS.md for test output.\nReturn BLOCKED immediately if no test output is found.\n\nComplete single-pass review covering:\n1. Test evidence - tests actually run and pass?\n2. Spec compliance - all requirements met?\n3. Code quality - simple, correct, follows conventions?\n\nConfidence score each issue (0-100).\nReport only issues with >= 80 confidence.\nReturn structured output per /dev-review format.\"\n```\n\n## Honesty Requirement\n\n<EXTREMELY-IMPORTANT>\n**You approving without test evidence is LYING.**\n\nAn \"APPROVED\" verdict means YOU assert:\n- Tests actually ran (not \"should work\")\n- Test output shows PASS (not SKIP, not assumed)\n- Evidence exists and YOU verified it (not trusted reports)\n\nYou approving without test evidence is not \"efficiency\" - it is LYING about code quality.\n\n**BLOCKED is honest. Your fake APPROVED is fraud.**\n</EXTREMELY-IMPORTANT>\n\n## Rationalization Prevention\n\nSTOP - you're about to rationalize if these thoughts arise—they indicate dishonest approval:\n\n| Thought | Reality |\n|---------|---------|\n| \"Tests probably pass\" | Your probably ≠ evidence. Check LEARNINGS.md. |\n| \"I saw the code, it looks right\" | Your looking ≠ running. Find test output. |\n| \"User is waiting for approval\" | They want honest approval. You return BLOCKED if needed. |\n| \"It's a small change\" | Your size estimate doesn't matter. Small changes break things. Require evidence. |\n| \"I trust the implementer\" | Your trust doesn't replace verification. You verify evidence. |\n| \"I'll approve and they can fix later\" | You block now or bugs ship to users. |\n| \"Review is just a formality\" | Review is the LAST GATE before bugs ship. You execute seriously. |\n\n## Quality Standards\n\n- **Test evidence is mandatory** - do not approve without test output\n- Do not report style preferences lacking project guideline backing\n- Do not report pre-existing issues (confidence = 0)\n- Make each reported issue immediately actionable\n- Use absolute file paths with line numbers in reports\n- Treat uncertainty as below 80 confidence\n\n## Phase Complete\n\nAfter review completes:\n\n**If APPROVED:** Immediately invoke the dev-verify skill:\n```\nRead(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-verify/SKILL.md\")\n```\n\n**If CHANGES REQUIRED:** Return to `/dev-implement` to fix reported issues.\n\n**If BLOCKED:** Return to `/dev-implement` to collect test evidence.\n",
        "lib/skills/dev-test-chrome/SKILL.md": "---\nname: dev-test-chrome\ndescription: \"Chrome MCP browser testing. Console/network debugging, JS execution, GIF recording.\"\n---\n\n**Announce:** \"I'm using dev-test-chrome for Chrome browser automation with debugging.\"\n\n<EXTREMELY-IMPORTANT>\n## Gate Reminder\n\nBefore taking screenshots or running E2E tests, you MUST complete all 6 gates from dev-tdd:\n\n```\nGATE 1: BUILD\nGATE 2: LAUNCH (with file-based logging)\nGATE 3: WAIT\nGATE 4: CHECK PROCESS\nGATE 5: READ LOGS ← MANDATORY, CANNOT SKIP\nGATE 6: VERIFY LOGS\nTHEN: E2E tests/screenshots\n```\n\n**You loaded dev-tdd earlier. Follow the gates now.**\n</EXTREMELY-IMPORTANT>\n\n## Contents\n\n- [Tool Availability Gate](#tool-availability-gate)\n- [When to Use Chrome MCP](#when-to-use-chrome-mcp)\n- [MCP Tools Overview](#mcp-tools-overview)\n- [Console Debugging](#console-debugging)\n- [Network Request Inspection](#network-request-inspection)\n- [JavaScript Execution](#javascript-execution)\n- [Navigation & Interaction](#navigation--interaction)\n- [GIF Recording](#gif-recording)\n- [Complete E2E Examples](#complete-e2e-examples)\n\n# Chrome MCP Browser Automation\n\n<EXTREMELY-IMPORTANT>\n## Tool Availability Gate\n\n**Verify Chrome MCP tools are available before proceeding.**\n\nCheck for these MCP functions:\n- `mcp__claude-in-chrome__read_page`\n- `mcp__claude-in-chrome__navigate`\n- `mcp__claude-in-chrome__read_console_messages`\n- `mcp__claude-in-chrome__read_network_requests`\n\n**If MCP tools are not available:**\n```\nSTOP: Cannot proceed with Chrome MCP automation.\n\nMissing: Chrome MCP server (claude-in-chrome extension)\n\nThe Chrome MCP requires:\n1. Chrome browser with claude-in-chrome extension installed\n2. Extension connected to Claude Code\n3. Browser window visible (not headless)\n\nCheck your Claude Code MCP configuration.\n\nReply when configured and I'll continue testing.\n```\n\n**This gate is non-negotiable. Missing tools = full stop.**\n</EXTREMELY-IMPORTANT>\n\n<EXTREMELY-IMPORTANT>\n## When to Use Chrome MCP\n\n**USE Chrome MCP when you need:**\n- Console message debugging (`console.log`, `console.error`)\n- Network request inspection (API calls, XHR, Fetch)\n- JavaScript execution in page context\n- GIF recording of interactions\n- Interactive debugging with real browser\n- Natural language element finding\n\n**DO NOT use Chrome MCP when:**\n- Running in CI/CD (requires visible browser)\n- Cross-browser testing needed (Chrome only)\n- Headless automation required\n\n**For CI/CD and headless, use:** `Read(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-test-playwright/SKILL.md\")`\n\n### Rationalization Prevention\n\n| Thought | Reality |\n|---------|---------|\n| \"I'll check the console manually\" | NO. Use `read_console_messages` |\n| \"I can infer what the API returns\" | NO. Use `read_network_requests` |\n| \"I'll just look at DevTools\" | AUTOMATE IT. Chrome MCP captures the same data |\n| \"Chrome MCP works for CI\" | NO. It requires visible browser. Use Playwright. |\n| \"Recording a GIF is overkill\" | GIFs prove interactions worked. Record them. |\n</EXTREMELY-IMPORTANT>\n\n## MCP Tools Overview\n\n| Tool | Purpose |\n|------|---------|\n| `navigate` | Navigate to URL |\n| `read_page` | Get accessibility tree (page state) |\n| `find` | Natural language element search |\n| `computer` | Mouse/keyboard (click, type, scroll, screenshot) |\n| `form_input` | Set form values |\n| `javascript_tool` | Execute JS in page context |\n| `read_console_messages` | Read browser console |\n| `read_network_requests` | Read HTTP requests |\n| `get_page_text` | Extract page text content |\n| `gif_creator` | Record interactions as GIF |\n| `tabs_context_mcp` | Get tab context |\n| `tabs_create_mcp` | Create new tab |\n\n## Console Debugging\n\n<EXTREMELY-IMPORTANT>\n### The Iron Law of Console Debugging\n\n**DO NOT manually check console. Use `read_console_messages`.**\n\nIf JavaScript errors exist, you MUST capture them automatically.\n</EXTREMELY-IMPORTANT>\n\n### Reading Console Messages\n\n```\nmcp__claude-in-chrome__read_console_messages(\n    tabId=TAB_ID,\n    pattern=\"error|warning\"  # Filter by regex pattern\n)\n```\n\n### Pattern Filtering (Required)\n\n**Always provide a pattern** to avoid verbose output:\n\n| Pattern | Captures |\n|---------|----------|\n| `\"error\"` | All error messages |\n| `\"error\\|warning\"` | Errors and warnings |\n| `\"MyApp\"` | Application-specific logs |\n| `\"API\"` | API-related messages |\n| `\"fetch\\|xhr\"` | Network-related logs |\n\n### Example: Debug JavaScript Error\n\n```\n# 1. Navigate to page\nmcp__claude-in-chrome__navigate(tabId=TAB_ID, url=\"https://app.example.com\")\n\n# 2. Trigger the action\nmcp__claude-in-chrome__computer(action=\"left_click\", tabId=TAB_ID, coordinate=[500, 300])\n\n# 3. Check for errors\nmcp__claude-in-chrome__read_console_messages(\n    tabId=TAB_ID,\n    pattern=\"error|Error|ERROR\",\n    onlyErrors=true\n)\n```\n\n### Clearing Console Between Tests\n\n```\nmcp__claude-in-chrome__read_console_messages(\n    tabId=TAB_ID,\n    pattern=\".*\",\n    clear=true  # Clear after reading\n)\n```\n\n## Network Request Inspection\n\n<EXTREMELY-IMPORTANT>\n### The Iron Law of API Debugging\n\n**DO NOT guess API responses. Use `read_network_requests`.**\n\nIf debugging API calls, you MUST capture actual requests and responses.\n</EXTREMELY-IMPORTANT>\n\n### Reading Network Requests\n\n```\nmcp__claude-in-chrome__read_network_requests(\n    tabId=TAB_ID,\n    urlPattern=\"/api/\"  # Filter by URL pattern\n)\n```\n\n### URL Pattern Filtering\n\n| Pattern | Captures |\n|---------|----------|\n| `\"/api/\"` | All API calls |\n| `\"graphql\"` | GraphQL requests |\n| `\"auth\"` | Authentication requests |\n| `\"example.com\"` | Requests to specific domain |\n\n### Example: Debug API Call\n\n```\n# 1. Navigate and trigger action\nmcp__claude-in-chrome__navigate(tabId=TAB_ID, url=\"https://app.example.com\")\nmcp__claude-in-chrome__computer(action=\"left_click\", tabId=TAB_ID, ref=\"submit-button\")\n\n# 2. Wait for network activity\nmcp__claude-in-chrome__computer(action=\"wait\", tabId=TAB_ID, duration=2)\n\n# 3. Inspect API calls\nmcp__claude-in-chrome__read_network_requests(\n    tabId=TAB_ID,\n    urlPattern=\"/api/submit\"\n)\n```\n\n### Clearing Network Log Between Tests\n\n```\nmcp__claude-in-chrome__read_network_requests(\n    tabId=TAB_ID,\n    clear=true\n)\n```\n\n## JavaScript Execution\n\n<EXTREMELY-IMPORTANT>\n### The Iron Law of JS Execution\n\n**DO NOT assume page state. Execute JS to verify.**\n\nIf you need to check page variables, DOM state, or run custom logic, use `javascript_tool`.\n</EXTREMELY-IMPORTANT>\n\n### Executing JavaScript\n\n```\nmcp__claude-in-chrome__javascript_tool(\n    action=\"javascript_exec\",\n    tabId=TAB_ID,\n    text=\"document.querySelector('#my-element').innerText\"\n)\n```\n\n### Common Use Cases\n\n**Get element text:**\n```\ntext=\"document.querySelector('.status').innerText\"\n```\n\n**Check if element exists:**\n```\ntext=\"document.querySelector('#login-button') !== null\"\n```\n\n**Get form values:**\n```\ntext=\"document.querySelector('input[name=email]').value\"\n```\n\n**Check localStorage:**\n```\ntext=\"localStorage.getItem('authToken')\"\n```\n\n**Get page data:**\n```\ntext=\"window.__APP_STATE__\"\n```\n\n**Trigger event:**\n```\ntext=\"document.querySelector('#btn').dispatchEvent(new Event('click'))\"\n```\n\n### Important Notes\n\n- Do NOT use `return` statements - just write the expression\n- Result of the last expression is returned automatically\n- Code runs in page context with access to DOM, window, etc.\n\n## Navigation & Interaction\n\n### Get Tab Context First\n\n```\n# Always start by getting available tabs\nmcp__claude-in-chrome__tabs_context_mcp(createIfEmpty=true)\n```\n\n### Navigation\n\n```\nmcp__claude-in-chrome__navigate(tabId=TAB_ID, url=\"https://example.com\")\n```\n\n### Reading Page Structure\n\n```\n# Get accessibility tree\nmcp__claude-in-chrome__read_page(tabId=TAB_ID)\n\n# Get interactive elements only\nmcp__claude-in-chrome__read_page(tabId=TAB_ID, filter=\"interactive\")\n\n# Get specific element by ref\nmcp__claude-in-chrome__read_page(tabId=TAB_ID, ref_id=\"ref_123\")\n```\n\n### Finding Elements (Natural Language)\n\n```\nmcp__claude-in-chrome__find(\n    tabId=TAB_ID,\n    query=\"login button\"\n)\n```\n\n### Clicking Elements\n\n```\n# By coordinates\nmcp__claude-in-chrome__computer(\n    action=\"left_click\",\n    tabId=TAB_ID,\n    coordinate=[500, 300]\n)\n\n# By element ref (from read_page or find)\nmcp__claude-in-chrome__computer(\n    action=\"left_click\",\n    tabId=TAB_ID,\n    ref=\"ref_1\"\n)\n```\n\n### Typing Text\n\n```\nmcp__claude-in-chrome__computer(\n    action=\"type\",\n    tabId=TAB_ID,\n    text=\"hello@example.com\"\n)\n```\n\n### Form Input\n\n```\nmcp__claude-in-chrome__form_input(\n    tabId=TAB_ID,\n    ref=\"ref_1\",\n    value=\"user@example.com\"\n)\n```\n\n### Screenshots\n\n```\nmcp__claude-in-chrome__computer(\n    action=\"screenshot\",\n    tabId=TAB_ID\n)\n```\n\n### Waiting\n\n```\nmcp__claude-in-chrome__computer(\n    action=\"wait\",\n    tabId=TAB_ID,\n    duration=2  # seconds\n)\n```\n\n## GIF Recording\n\n<EXTREMELY-IMPORTANT>\n### When to Record GIFs\n\n**Record GIFs for multi-step interactions that need visual verification.**\n\nGIFs prove interactions worked. Screenshots only show end state.\n</EXTREMELY-IMPORTANT>\n\n### Recording Workflow\n\n```\n# 1. Start recording\nmcp__claude-in-chrome__gif_creator(action=\"start_recording\", tabId=TAB_ID)\n\n# 2. Take initial screenshot (first frame)\nmcp__claude-in-chrome__computer(action=\"screenshot\", tabId=TAB_ID)\n\n# 3. Perform interactions\nmcp__claude-in-chrome__computer(action=\"left_click\", tabId=TAB_ID, coordinate=[500, 300])\nmcp__claude-in-chrome__computer(action=\"wait\", tabId=TAB_ID, duration=1)\nmcp__claude-in-chrome__computer(action=\"screenshot\", tabId=TAB_ID)\n\n# ... more interactions with screenshots between ...\n\n# 4. Take final screenshot (last frame)\nmcp__claude-in-chrome__computer(action=\"screenshot\", tabId=TAB_ID)\n\n# 5. Stop recording\nmcp__claude-in-chrome__gif_creator(action=\"stop_recording\", tabId=TAB_ID)\n\n# 6. Export GIF\nmcp__claude-in-chrome__gif_creator(\n    action=\"export\",\n    tabId=TAB_ID,\n    download=true,\n    filename=\"login_flow.gif\"\n)\n```\n\n### GIF Best Practices\n\n1. **Name meaningfully** - Use descriptive filenames like `checkout_flow.gif`\n2. **Capture extra frames** - Take screenshots before and after actions\n3. **Include wait time** - Allow animations to complete between screenshots\n\n## Complete E2E Examples\n\n### Login Flow with Console/Network Debugging\n\n```\n# 1. Get tab context\nmcp__claude-in-chrome__tabs_context_mcp(createIfEmpty=true)\n\n# 2. Create new tab\nmcp__claude-in-chrome__tabs_create_mcp()\n# Returns tabId\n\n# 3. Navigate to login\nmcp__claude-in-chrome__navigate(tabId=TAB_ID, url=\"https://app.example.com/login\")\nmcp__claude-in-chrome__computer(action=\"wait\", tabId=TAB_ID, duration=2)\n\n# 4. Clear console and network for clean test\nmcp__claude-in-chrome__read_console_messages(tabId=TAB_ID, pattern=\".*\", clear=true)\nmcp__claude-in-chrome__read_network_requests(tabId=TAB_ID, clear=true)\n\n# 5. Get page structure\nmcp__claude-in-chrome__read_page(tabId=TAB_ID, filter=\"interactive\")\n\n# 6. Fill login form\nmcp__claude-in-chrome__find(tabId=TAB_ID, query=\"email input\")\nmcp__claude-in-chrome__form_input(tabId=TAB_ID, ref=\"ref_1\", value=\"user@example.com\")\n\nmcp__claude-in-chrome__find(tabId=TAB_ID, query=\"password input\")\nmcp__claude-in-chrome__form_input(tabId=TAB_ID, ref=\"ref_2\", value=\"password123\")\n\n# 7. Submit\nmcp__claude-in-chrome__find(tabId=TAB_ID, query=\"sign in button\")\nmcp__claude-in-chrome__computer(action=\"left_click\", tabId=TAB_ID, ref=\"ref_3\")\n\n# 8. Wait for response\nmcp__claude-in-chrome__computer(action=\"wait\", tabId=TAB_ID, duration=3)\n\n# 9. Check for errors in console\nmcp__claude-in-chrome__read_console_messages(\n    tabId=TAB_ID,\n    pattern=\"error|Error|failed\",\n    onlyErrors=true\n)\n\n# 10. Verify API call succeeded\nmcp__claude-in-chrome__read_network_requests(\n    tabId=TAB_ID,\n    urlPattern=\"/api/login\"\n)\n\n# 11. Verify logged in state via JS\nmcp__claude-in-chrome__javascript_tool(\n    action=\"javascript_exec\",\n    tabId=TAB_ID,\n    text=\"localStorage.getItem('authToken') !== null\"\n)\n\n# 12. Screenshot for evidence\nmcp__claude-in-chrome__computer(action=\"screenshot\", tabId=TAB_ID)\n```\n\n### API Debugging Workflow\n\n```\n# 1. Setup\nmcp__claude-in-chrome__tabs_context_mcp(createIfEmpty=true)\nmcp__claude-in-chrome__navigate(tabId=TAB_ID, url=\"https://api-dashboard.example.com\")\n\n# 2. Clear previous network data\nmcp__claude-in-chrome__read_network_requests(tabId=TAB_ID, clear=true)\n\n# 3. Trigger the problematic action\nmcp__claude-in-chrome__find(tabId=TAB_ID, query=\"refresh data button\")\nmcp__claude-in-chrome__computer(action=\"left_click\", tabId=TAB_ID, ref=\"ref_1\")\n\n# 4. Wait for network activity\nmcp__claude-in-chrome__computer(action=\"wait\", tabId=TAB_ID, duration=3)\n\n# 5. Inspect all API calls\nmcp__claude-in-chrome__read_network_requests(\n    tabId=TAB_ID,\n    urlPattern=\"/api/\"\n)\n\n# 6. Check console for related errors\nmcp__claude-in-chrome__read_console_messages(\n    tabId=TAB_ID,\n    pattern=\"API|fetch|error\"\n)\n\n# 7. Verify page state after API call\nmcp__claude-in-chrome__javascript_tool(\n    action=\"javascript_exec\",\n    tabId=TAB_ID,\n    text=\"document.querySelector('.data-table tbody tr').length\"\n)\n```\n\n### Form Submission with Validation\n\n```\n# 1. Navigate to form\nmcp__claude-in-chrome__navigate(tabId=TAB_ID, url=\"https://app.example.com/contact\")\n\n# 2. Start GIF recording\nmcp__claude-in-chrome__gif_creator(action=\"start_recording\", tabId=TAB_ID)\nmcp__claude-in-chrome__computer(action=\"screenshot\", tabId=TAB_ID)\n\n# 3. Fill form with invalid data to test validation\nmcp__claude-in-chrome__form_input(tabId=TAB_ID, ref=\"email-input\", value=\"invalid-email\")\nmcp__claude-in-chrome__computer(action=\"screenshot\", tabId=TAB_ID)\n\n# 4. Submit\nmcp__claude-in-chrome__computer(action=\"left_click\", tabId=TAB_ID, ref=\"submit-btn\")\nmcp__claude-in-chrome__computer(action=\"wait\", tabId=TAB_ID, duration=1)\nmcp__claude-in-chrome__computer(action=\"screenshot\", tabId=TAB_ID)\n\n# 5. Check for validation errors in console\nmcp__claude-in-chrome__read_console_messages(tabId=TAB_ID, pattern=\"validation|error\")\n\n# 6. Verify error message appears\nmcp__claude-in-chrome__javascript_tool(\n    action=\"javascript_exec\",\n    tabId=TAB_ID,\n    text=\"document.querySelector('.error-message').innerText\"\n)\n\n# 7. Stop and export GIF\nmcp__claude-in-chrome__gif_creator(action=\"stop_recording\", tabId=TAB_ID)\nmcp__claude-in-chrome__gif_creator(\n    action=\"export\",\n    tabId=TAB_ID,\n    download=true,\n    filename=\"form_validation.gif\"\n)\n```\n\n## Integration\n\nThis skill is referenced by `dev-test` for Chrome MCP browser automation.\n\n**For headless/CI testing, use:** `Read(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-test-playwright/SKILL.md\")`\n\nFor TDD protocol, see: `Skill(skill=\"workflows:dev-tdd\")`\n",
        "lib/skills/dev-test-playwright/SKILL.md": "---\nname: dev-test-playwright\ndescription: \"Playwright MCP browser testing. Headless E2E, cross-browser, CI/CD automation.\"\n---\n\n**Announce:** \"I'm using dev-test-playwright for headless browser automation.\"\n\n<EXTREMELY-IMPORTANT>\n## Gate Reminder\n\nBefore taking screenshots or running E2E tests, you MUST complete all 6 gates from dev-tdd:\n\n```\nGATE 1: BUILD\nGATE 2: LAUNCH (with file-based logging)\nGATE 3: WAIT\nGATE 4: CHECK PROCESS\nGATE 5: READ LOGS ← MANDATORY, CANNOT SKIP\nGATE 6: VERIFY LOGS\nTHEN: E2E tests/screenshots\n```\n\n**You loaded dev-tdd earlier. Follow the gates now.**\n</EXTREMELY-IMPORTANT>\n\n## Contents\n\n- [Tool Availability Gate](#tool-availability-gate)\n- [When to Use Playwright MCP](#when-to-use-playwright-mcp)\n- [MCP Tools Overview](#mcp-tools-overview)\n- [Navigation](#navigation)\n- [Element Interaction](#element-interaction)\n- [Verification](#verification)\n- [Form Handling](#form-handling)\n- [Advanced Patterns](#advanced-patterns)\n- [Complete E2E Examples](#complete-e2e-examples)\n\n# Playwright MCP Browser Automation\n\n<EXTREMELY-IMPORTANT>\n## Tool Availability Gate\n\n**Verify Playwright MCP tools are available before proceeding.**\n\nCheck for these MCP functions:\n- `mcp__playwright__browser_navigate`\n- `mcp__playwright__browser_snapshot`\n- `mcp__playwright__browser_click`\n\n**If MCP tools are not available:**\n```\nSTOP: Cannot proceed with Playwright automation.\n\nMissing: Playwright MCP server\n\nThe Playwright MCP server must be configured and running.\nCheck your Claude Code MCP configuration.\n\nReply when configured and I'll continue testing.\n```\n\n**This gate is non-negotiable. Missing tools = full stop.**\n</EXTREMELY-IMPORTANT>\n\n<EXTREMELY-IMPORTANT>\n## When to Use Playwright MCP\n\n**USE Playwright MCP when you need:**\n- Headless browser automation (CI/CD)\n- Cross-browser testing (Chromium, Firefox, WebKit)\n- Test isolation (fresh browser state per test)\n- Standard E2E test suite automation\n- Network mocking/interception\n- Parallel test execution\n\n**DO NOT use Playwright MCP when:**\n- Debugging console messages (use Chrome MCP)\n- Inspecting network requests/responses (use Chrome MCP)\n- Executing custom JavaScript in page (use Chrome MCP)\n- Recording GIFs of interactions (use Chrome MCP)\n- Interactive debugging with real browser (use Chrome MCP)\n\n**For debugging, use:** `Read(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-test-chrome/SKILL.md\")`\n\n### Rationalization Prevention\n\n| Thought | Reality |\n|---------|---------|\n| \"Playwright can do everything\" | NO. It cannot read console or network requests. |\n| \"I don't need console debugging\" | You will. Start with Chrome MCP if unsure. |\n| \"I'll add console checks later\" | You can't with Playwright. Choose the right tool now. |\n| \"Headless mode doesn't matter\" | YES IT DOES for CI/CD. |\n| \"Chrome MCP works for CI\" | NO. It requires visible browser. |\n\n### Capability Comparison\n\n| Capability | Playwright MCP | Chrome MCP |\n|------------|---------------|------------|\n| Navigate/click/type | ✅ | ✅ |\n| Accessibility tree | ✅ `browser_snapshot` | ✅ `read_page` |\n| Screenshots | ✅ | ✅ |\n| **Headless mode** | ✅ | ❌ |\n| **Cross-browser** | ✅ | ❌ |\n| Console messages | ❌ | ✅ |\n| Network requests | ❌ | ✅ |\n| JavaScript execution | ❌ | ✅ |\n| GIF recording | ❌ | ✅ |\n</EXTREMELY-IMPORTANT>\n\n## MCP Tools Overview\n\n| Tool | Purpose |\n|------|---------|\n| `browser_navigate` | Navigate to URL |\n| `browser_snapshot` | Get accessibility tree (page state) |\n| `browser_click` | Click elements |\n| `browser_type` | Type into inputs |\n| `browser_select_option` | Select dropdown options |\n| `browser_hover` | Hover over elements |\n| `browser_wait_for` | Wait for conditions |\n| `browser_take_screenshot` | Visual capture |\n| `browser_press` | Press keys |\n\n## Navigation\n\n### Basic Navigation\n\n```\nmcp__playwright__browser_navigate(url=\"https://example.com\")\n```\n\n### Wait for Page Load\n\n```\nmcp__playwright__browser_navigate(url=\"https://example.com\")\nmcp__playwright__browser_wait_for(state=\"networkidle\")\n```\n\n### Get Current State\n\n```\nmcp__playwright__browser_snapshot()\n```\n\nThe snapshot returns the **accessibility tree** - a structured representation of all interactive elements on the page.\n\n## Element Interaction\n\n### Clicking Elements\n\n```\n# By visible text\nmcp__playwright__browser_click(element=\"Submit button\")\n\n# By ref (from snapshot)\nmcp__playwright__browser_click(ref=\"button[type=submit]\")\n\n# By role and name\nmcp__playwright__browser_click(element=\"Login\", role=\"button\")\n```\n\n### Typing Text\n\n```\n# Into focused element\nmcp__playwright__browser_type(text=\"hello world\")\n\n# Into specific element\nmcp__playwright__browser_click(element=\"Email input\")\nmcp__playwright__browser_type(text=\"user@example.com\")\n\n# Clear and type\nmcp__playwright__browser_click(element=\"Search box\")\nmcp__playwright__browser_type(text=\"new search\", clear=true)\n```\n\n### Keyboard Shortcuts\n\n```\n# Press Enter\nmcp__playwright__browser_press(key=\"Enter\")\n\n# Keyboard shortcuts\nmcp__playwright__browser_press(key=\"Control+a\")\nmcp__playwright__browser_press(key=\"Control+c\")\n```\n\n## Verification\n\n<EXTREMELY-IMPORTANT>\n### The Iron Law of Verification\n\n**EVERY action must be VERIFIED. Taking action is not enough.**\n\nAfter clicking, typing, or navigating, you MUST:\n1. Wait for the expected result\n2. Take a snapshot to verify state\n3. Document the verification in LEARNINGS.md\n\n| Action | Verification |\n|--------|--------------|\n| Click submit | `wait_for(text=\"Success\")` + snapshot |\n| Navigate | `wait_for(state=\"networkidle\")` + snapshot |\n| Fill form | Snapshot shows filled values |\n| Login | Snapshot shows dashboard/logged-in state |\n\n**\"I clicked it\" is not verification. Prove the click worked.**\n</EXTREMELY-IMPORTANT>\n\n### Snapshot Verification\n\n```\n# 1. Perform action\nmcp__playwright__browser_click(element=\"Submit\")\n\n# 2. Wait for result\nmcp__playwright__browser_wait_for(text=\"Success\")\n\n# 3. Take snapshot to verify\nmcp__playwright__browser_snapshot()\n# Check snapshot contains expected elements\n```\n\n### Wait Conditions\n\n```\n# Wait for text to appear\nmcp__playwright__browser_wait_for(text=\"Welcome back\")\n\n# Wait for element\nmcp__playwright__browser_wait_for(selector=\"#success-message\")\n\n# Wait for network idle\nmcp__playwright__browser_wait_for(state=\"networkidle\")\n\n# Wait for navigation\nmcp__playwright__browser_wait_for(state=\"load\")\n```\n\n### Screenshots\n\n```\n# Full page\nmcp__playwright__browser_take_screenshot(path=\"/tmp/screenshot.png\", fullPage=true)\n\n# Viewport only\nmcp__playwright__browser_take_screenshot(path=\"/tmp/viewport.png\")\n\n# Specific element\nmcp__playwright__browser_take_screenshot(\n    path=\"/tmp/element.png\",\n    selector=\"#main-content\"\n)\n```\n\n## Form Handling\n\n### Text Inputs\n\n```\nmcp__playwright__browser_click(element=\"Username\")\nmcp__playwright__browser_type(text=\"john_doe\")\n\nmcp__playwright__browser_click(element=\"Password\")\nmcp__playwright__browser_type(text=\"secret123\")\n```\n\n### Dropdowns\n\n```\nmcp__playwright__browser_select_option(\n    element=\"Country dropdown\",\n    value=\"US\"\n)\n\n# Or by label\nmcp__playwright__browser_select_option(\n    element=\"Country\",\n    label=\"United States\"\n)\n```\n\n### Checkboxes and Radio Buttons\n\n```\n# Check checkbox\nmcp__playwright__browser_click(element=\"Accept terms checkbox\")\n\n# Verify checked state (via snapshot)\nmcp__playwright__browser_snapshot()\n# Look for checked=\"true\" in accessibility tree\n```\n\n### File Upload\n\n```\nmcp__playwright__browser_set_input_files(\n    selector=\"input[type=file]\",\n    files=[\"/path/to/file.pdf\"]\n)\n```\n\n## Advanced Patterns\n\n### Multi-Step Form\n\n```\n# Step 1\nmcp__playwright__browser_click(element=\"Name input\")\nmcp__playwright__browser_type(text=\"John Doe\")\nmcp__playwright__browser_click(element=\"Next button\")\nmcp__playwright__browser_wait_for(text=\"Step 2\")\n\n# Step 2\nmcp__playwright__browser_click(element=\"Email input\")\nmcp__playwright__browser_type(text=\"john@example.com\")\nmcp__playwright__browser_click(element=\"Next button\")\nmcp__playwright__browser_wait_for(text=\"Step 3\")\n\n# Step 3 - Submit\nmcp__playwright__browser_click(element=\"Submit button\")\nmcp__playwright__browser_wait_for(text=\"Success\")\n```\n\n### Handling Modals\n\n```\n# Click to open modal\nmcp__playwright__browser_click(element=\"Open Dialog\")\nmcp__playwright__browser_wait_for(text=\"Dialog Title\")\n\n# Interact with modal\nmcp__playwright__browser_click(element=\"Confirm button\")\nmcp__playwright__browser_wait_for(state=\"hidden\", selector=\".modal\")\n```\n\n### Iframes\n\n```\n# Switch to iframe\nmcp__playwright__browser_frame(name=\"payment-iframe\")\n\n# Interact within iframe\nmcp__playwright__browser_click(element=\"Card number\")\nmcp__playwright__browser_type(text=\"4111111111111111\")\n\n# Switch back to main\nmcp__playwright__browser_main_frame()\n```\n\n### Hover and Tooltips\n\n```\nmcp__playwright__browser_hover(element=\"Help icon\")\nmcp__playwright__browser_wait_for(text=\"This is the tooltip text\")\nmcp__playwright__browser_snapshot()\n```\n\n## Complete E2E Examples\n\n### Login Flow\n\n```\n# 1. Navigate to login page\nmcp__playwright__browser_navigate(url=\"https://app.example.com/login\")\nmcp__playwright__browser_wait_for(state=\"networkidle\")\n\n# 2. Take initial snapshot\nmcp__playwright__browser_snapshot()\n# Verify: Login form is visible\n\n# 3. Fill credentials\nmcp__playwright__browser_click(element=\"Email\")\nmcp__playwright__browser_type(text=\"user@example.com\")\n\nmcp__playwright__browser_click(element=\"Password\")\nmcp__playwright__browser_type(text=\"password123\")\n\n# 4. Submit\nmcp__playwright__browser_click(element=\"Sign In\")\nmcp__playwright__browser_wait_for(text=\"Dashboard\")\n\n# 5. Verify success\nmcp__playwright__browser_snapshot()\n# Verify: Dashboard is visible, user name shown\n\n# 6. Screenshot for evidence\nmcp__playwright__browser_take_screenshot(path=\"/tmp/login_success.png\")\n```\n\n### E-Commerce Checkout\n\n```\n# 1. Navigate to product\nmcp__playwright__browser_navigate(url=\"https://shop.example.com/product/123\")\nmcp__playwright__browser_wait_for(state=\"networkidle\")\n\n# 2. Add to cart\nmcp__playwright__browser_click(element=\"Add to Cart\")\nmcp__playwright__browser_wait_for(text=\"Added to cart\")\n\n# 3. Go to cart\nmcp__playwright__browser_click(element=\"Cart icon\")\nmcp__playwright__browser_wait_for(text=\"Your Cart\")\n\n# 4. Verify cart\nmcp__playwright__browser_snapshot()\n# Verify: Product in cart, correct price\n\n# 5. Proceed to checkout\nmcp__playwright__browser_click(element=\"Checkout\")\nmcp__playwright__browser_wait_for(text=\"Shipping Address\")\n\n# 6. Fill shipping\nmcp__playwright__browser_click(element=\"Address\")\nmcp__playwright__browser_type(text=\"123 Main St\")\n\nmcp__playwright__browser_click(element=\"City\")\nmcp__playwright__browser_type(text=\"New York\")\n\nmcp__playwright__browser_select_option(element=\"State\", value=\"NY\")\n\nmcp__playwright__browser_click(element=\"Zip\")\nmcp__playwright__browser_type(text=\"10001\")\n\n# 7. Continue to payment\nmcp__playwright__browser_click(element=\"Continue to Payment\")\nmcp__playwright__browser_wait_for(text=\"Payment Method\")\n\n# 8. Verify order summary\nmcp__playwright__browser_snapshot()\n# Verify: Correct items, shipping address, total\n\nmcp__playwright__browser_take_screenshot(path=\"/tmp/checkout_complete.png\")\n```\n\n### Search and Filter\n\n```\n# 1. Navigate\nmcp__playwright__browser_navigate(url=\"https://search.example.com\")\n\n# 2. Search\nmcp__playwright__browser_click(element=\"Search box\")\nmcp__playwright__browser_type(text=\"laptop\")\nmcp__playwright__browser_press(key=\"Enter\")\nmcp__playwright__browser_wait_for(text=\"results\")\n\n# 3. Apply filter\nmcp__playwright__browser_click(element=\"Price filter\")\nmcp__playwright__browser_click(element=\"Under $1000\")\nmcp__playwright__browser_wait_for(state=\"networkidle\")\n\n# 4. Verify filtered results\nmcp__playwright__browser_snapshot()\n# Verify: Results shown, filter applied\n\n# 5. Click first result\nmcp__playwright__browser_click(element=\"First product link\")\nmcp__playwright__browser_wait_for(text=\"Product Details\")\n\nmcp__playwright__browser_take_screenshot(path=\"/tmp/search_result.png\")\n```\n\n## Error Handling\n\n### Retry Pattern\n\n```\n# Attempt action with retry\nfor attempt in range(3):\n    try:\n        mcp__playwright__browser_click(element=\"Flaky Button\")\n        mcp__playwright__browser_wait_for(text=\"Success\", timeout=5000)\n        break  # Success\n    except:\n        if attempt == 2:\n            raise  # Give up after 3 attempts\n        time.sleep(1)  # Wait before retry\n```\n\n### Timeout Handling\n\n```\n# Set explicit timeout\nmcp__playwright__browser_wait_for(\n    text=\"Slow loading content\",\n    timeout=30000  # 30 seconds\n)\n```\n\n## Limitations\n\n<EXTREMELY-IMPORTANT>\n### What Playwright MCP Cannot Do\n\n| Need | Why Playwright Fails | Use Instead |\n|------|---------------------|-------------|\n| Read console.log | No console access | Chrome MCP `read_console_messages` |\n| Inspect API responses | No network access | Chrome MCP `read_network_requests` |\n| Execute page JavaScript | No JS execution | Chrome MCP `javascript_tool` |\n| Record GIF | No recording capability | Chrome MCP `gif_creator` |\n\n**If you need debugging capabilities, switch to Chrome MCP.**\n</EXTREMELY-IMPORTANT>\n\n## Integration\n\nThis skill is referenced by `dev-test` for Playwright browser automation.\n\n**For debugging (console/network), use:** `Read(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-test-chrome/SKILL.md\")`\n\nFor TDD protocol, see: `Skill(skill=\"workflows:dev-tdd\")`\n",
        "lib/skills/dev-verify/SKILL.md": "---\nname: dev-verify\ndescription: \"This skill should be used when the user asks to 'verify completion', 'check that tests pass', 'confirm feature works', or REQUIRED Phase 7 of /dev workflow (final). Enforces fresh runtime evidence before claiming completion.\"\nversion: 1.0.0\n---\n\nAnnounce: \"Using dev-verify (Phase 7) to confirm completion with fresh evidence.\"\n\n## Contents\n\n- [The Iron Law of Verification](#the-iron-law-of-verification)\n- [Red Flags - STOP Immediately If You Think](#red-flags---stop-immediately-if-you-think)\n- [The Gate Function](#the-gate-function)\n- [Claims Requiring Evidence](#claims-requiring-evidence)\n- [Insufficient Evidence](#insufficient-evidence)\n- [Verification Patterns](#verification-patterns)\n- [User Acceptance (Final Step)](#user-acceptance-final-step)\n- [Bottom Line](#bottom-line)\n\n# Verification Gate\n\n<EXTREMELY-IMPORTANT>\n## Your Job is to Write Automated Tests\n\n**The automated test IS your deliverable. The implementation just makes the test pass.**\n\nReframe your task:\n- ❌ \"Implement feature X, and test it\"\n- ✅ \"Write an automated test that proves feature X works. Then make it pass.\"\n\nThe test proves value. The implementation is a means to an end.\n\nWithout a REAL automated test (executes code, verifies behavior), you have delivered NOTHING.\n</EXTREMELY-IMPORTANT>\n\n<EXTREMELY-IMPORTANT>\n## The Iron Law of Verification\n\n**NO COMPLETION CLAIMS WITHOUT FRESH VERIFICATION EVIDENCE. This is not negotiable.**\n\nBefore claiming ANYTHING is complete, you MUST:\n1. IDENTIFY - Which command proves your assertion?\n2. RUN - Execute the command fresh (not from cache/memory)\n3. READ - Review full output and exit codes\n4. VERIFY - Confirm output supports your claim\n5. Only THEN make the claim\n\nThis applies even when:\n- \"I just ran it a moment ago\"\n- \"The agent said it passed\"\n- \"It should work\"\n- \"I'm confident it's fine\"\n\n**If you catch yourself about to claim completion without fresh evidence, STOP.**\n</EXTREMELY-IMPORTANT>\n\n## Red Flags - STOP Immediately If You Catch Yourself Thinking:\n\n| Thought | Why It's Wrong | Do Instead |\n|---------|----------------|------------|\n| \"It should work\" | \"Should\" isn't evidence | Run the command |\n| \"I'm pretty sure it passes\" | Confidence isn't verification | Run the command |\n| \"The agent reported success\" | Agent reports need confirmation | Run it yourself |\n| \"I ran it earlier\" | Earlier isn't fresh | Run it again |\n| \"The code exists\" | Existing ≠ working | Run and check output |\n| \"Grep shows the function\" | Pattern match ≠ runtime test | Run the function |\n\n## The Gate Function\n\nBefore making ANY status claim:\n\n```\n1. IDENTIFY → Which command proves your assertion?\n2. RUN     → Execute the command fresh\n3. READ    → Review full output and exit codes\n4. VERIFY  → Confirm output supports your claim\n5. CLAIM   → Only after steps 1-4\n```\n\n**Skipping any step is dishonest, not verification.**\n\n## Claims Requiring Evidence\n\n| Claim | Required Evidence |\n|-------|-------------------|\n| \"Tests pass\" | Test output showing 0 failures |\n| \"Build succeeds\" | Exit code 0 from build command |\n| \"Linter clean\" | Linter output showing 0 errors |\n| \"Bug fixed\" | Test that failed now passes |\n| \"Feature complete\" | All acceptance criteria verified |\n| **\"User-facing feature works\"** | **E2E test output showing PASS** |\n\n<EXTREMELY-IMPORTANT>\n## The E2E Evidence Gate\n\n**USER-FACING CLAIMS REQUIRE E2E EVIDENCE. Unit tests are insufficient.**\n\n| Claim | Unit Test Evidence | E2E Evidence Required |\n|-------|--------------------|-----------------------|\n| \"API works\" | ❌ Insufficient | ✅ Full request/response test |\n| \"UI renders\" | ❌ Insufficient | ✅ Playwright snapshot/interaction |\n| \"Feature complete\" | ❌ Insufficient | ✅ User flow simulation |\n| \"No regressions\" | ❌ Insufficient | ✅ E2E suite passes |\n\n### Fake E2E Patterns - STOP\n\n**These are NOT E2E tests. They are observability, not verification.**\n\n| ❌ Fake E2E | ✅ Real E2E |\n|-------------|-------------|\n| \"Log shows function was called\" | \"Screenshot shows correct UI rendered\" |\n| \"grep papirus in logs\" | \"grim screenshot + visual diff confirms icon changed\" |\n| \"Console output contains 'success'\" | \"Playwright assertion: element.textContent === 'Success'\" |\n| \"File was created\" | \"E2E test opens file and verifies contents\" |\n| \"Process exited 0\" | \"Functional test verifies actual output matches spec\" |\n| \"Mock returned expected value\" | \"Real integration returns expected value\" |\n\n**Red Flag:** If you catch yourself thinking \"logs prove it works\" - STOP, you're about to claim false verification. Logs prove code executed, not that it produced correct results. E2E means verifying the actual output users see.\n\n### Rationalization Prevention (E2E)\n\n| Thought | Reality |\n|---------|---------|\n| \"Unit tests cover it\" | Unit tests don't simulate users. Where's YOUR E2E? |\n| \"E2E would be redundant\" | YOU'LL catch bugs with redundancy. Write E2E. |\n| \"No time for E2E\" | YOU don't have time to fix production bugs? Write E2E. |\n| \"Feature is internal\" | Does it affect user output? Then YOU need E2E. |\n| \"I manually tested\" | YOU provided no evidence. Automate it. |\n| **\"Log checking verifies it works\"** | **YOUR log checking only verifies code executed, not results. Not E2E.** |\n| **\"E2E with screenshots is too complex\"** | **If YOU can't verify it simply, your feature isn't done. Complexity = bugs hiding.** |\n| **\"Implementation is done, testing is just verification\"** | **Testing IS YOUR implementation. Untested code is unfinished code.** |\n\n### The E2E Gate Function\n\nFor user-facing changes, add to verification:\n\n```\n1. IDENTIFY → Which E2E test proves user-facing behavior?\n2. RUN     → Execute E2E test fresh\n3. READ    → Review full output (screenshots if visual)\n4. VERIFY  → User flow works as specified\n5. CLAIM   → Only after E2E evidence exists\n```\n\n**\"Unit tests pass\" is not \"feature complete\" for user-facing changes.**\n\n### GUI Application Gate (CRITICAL)\n\n<EXTREMELY-IMPORTANT>\n**For GUI applications, you MUST complete the 6-gate sequence from dev-tdd BEFORE E2E testing:**\n\n```\nGATE 1: BUILD\nGATE 2: LAUNCH (with file-based logging)\nGATE 3: WAIT\nGATE 4: CHECK PROCESS\nGATE 5: READ LOGS ← MANDATORY, CANNOT SKIP\nGATE 6: VERIFY LOGS\nTHEN AND ONLY THEN: E2E tests/screenshots\n```\n\n**You cannot skip GATE 5 (READ LOGS).** If you catch yourself about to take screenshots without reading logs first, STOP.\n\nSee `Skill(skill=\"workflows:dev-tdd\")` for the full gate sequence with examples.\n</EXTREMELY-IMPORTANT>\n</EXTREMELY-IMPORTANT>\n\n## Insufficient Evidence\n\nThese do NOT count as verification:\n\n- Previous runs (must be fresh)\n- Assumptions (\"it should work\")\n- Partial checks (ran some tests, not all)\n- Agent reports without independent confirmation\n- \"I think...\" / \"It seems...\" / \"Probably...\"\n\n## Honesty Requirement\n\n<EXTREMELY-IMPORTANT>\n**Claiming completion without fresh evidence is LYING.**\n\nWhen you say \"Feature complete\", you are asserting:\n- You ran the verification commands yourself (fresh)\n- You saw the output with your own tokens\n- The output confirms the claim\n\nSaying \"complete\" based on stale data or agent reports is not \"summarizing\" - it is LYING about project state.\n\n**\"Still verifying\" is honest. \"Complete\" without evidence is fraud.**\n</EXTREMELY-IMPORTANT>\n\n## Rationalization Prevention\n\nThese thoughts mean STOP—you're about to claim falsely:\n\n| Thought | Reality |\n|---------|---------|\n| \"I just ran it\" | \"Just\" = stale. YOU must run it AGAIN. |\n| \"The agent said it passed\" | Agent reports need YOUR confirmation. YOU run it. |\n| \"It should work\" | \"Should\" is hope. YOU run and see output. |\n| \"I'm confident\" | YOUR confidence ≠ verification. YOU run the command. |\n| \"We already verified earlier\" | Earlier ≠ now. YOU need fresh evidence only. |\n| \"User will verify it\" | NO. YOU verify before claiming. User trusts YOUR claim. |\n| \"Close enough\" | Close ≠ complete. YOU verify fully. |\n| \"Time to move on\" | YOU only move on after FRESH verification. |\n\n**STRUCTURAL VERIFICATION IS NOT RUNTIME VERIFICATION:**\n\n| ❌ NOT Verification | ✅ IS Verification |\n|---------------------|-------------------|\n| \"Code exists in file\" | \"Code ran and produced output X\" |\n| \"Function is defined\" | \"Function was called and returned Y\" |\n| \"Grep found the pattern\" | \"Program output shows expected behavior\" |\n| \"ast-grep found the code\" | \"Test executed and passed with output\" |\n| \"Diff shows the change\" | \"Change tested with actual input/output\" |\n| \"Implementation looks correct\" | \"Ran test, saw PASS in logs\" |\n\n**The key difference:**\n- Structural: \"The code IS THERE\" (useless)\n- Runtime: \"The code WORKS\" (valid)\n\nIf you find yourself saying \"the code exists\" or \"I verified the implementation\" without running it, **STOP** - you're doing structural analysis, not verification.\n\n## Verification Patterns\n\n### Tests\n```bash\n# Run tests (e.g., npm test, pytest, cargo test)\nnpm test\n\n# Check results: \"34/34 pass\" = can claim tests pass\n# \"33/34 pass\" = cannot claim success (partial fail)\n```\n\n**Tool description:** Run automated test suite to verify all tests pass\n\n### Regression Test\n```bash\n# 1. Write test → run (should fail initially)\n# 2. Apply fix → run (should pass)\n# 3. Revert fix → run (must fail again to confirm fix)\n# 4. Restore fix → run (must pass to confirm success)\n```\n\n**Tool description:** Execute regression test cycle to validate bug fix reproducibility\n\n### Build\n```bash\nnpm run build && echo \"Exit code: $?\"\n# Must see \"Exit code: 0\" to claim success\n```\n\n**Tool description:** Build application and verify exit code is 0\n\n## User Acceptance (Final Step)\n\nAfter technical verification passes, confirm with user. Use the AskUserQuestion pattern:\n\n**Tool description:** Request user confirmation that implementation meets specified requirements\n\n```yaml\nquestion: \"Does this implementation meet your requirements?\"\noptions:\n  - label: \"Yes, requirements met\"\n    description: \"Feature works as designed, ready to merge\"\n  - label: \"Partially\"\n    description: \"Core works but missing some requirements\"\n  - label: \"No\"\n    description: \"Does not meet requirements, needs more work\"\n```\n\nReference `.claude/SPEC.md` when asking—remind user of the success criteria they defined.\n\nIf user responds \"Partially\" or \"No\":\n1. Ask which specific requirement is not met\n2. Return to `/dev-implement` to address gaps\n3. Re-run verification\n\n**Only claim COMPLETE when:**\n- [ ] All technical tests pass (automated)\n- [ ] User confirms requirements met (manual)\n\n## Bottom Line\n\n**Two types of verification required:**\n\n1. **Technical** - Run commands, see output, confirm no errors\n2. **Requirements** - Ask user if it does what they wanted\n\nBoth must pass. No shortcuts exist.\n\n## Workflow Complete\n\nWhen user confirms \"Yes, requirements met\":\n\nAnnounce: \"Dev workflow complete. All 7 phases passed.\"\n\nThe `/dev` workflow is now finished. Offer to:\n- Commit the changes\n- Clean up `.claude/` files\n- Start a new feature with `/dev`\n\n---\n\n## Key Principles\n\n**Fresh Evidence Always:** Every claim requires proof from a fresh command execution, not cached results or agent reports.\n\n**Runtime Over Structural:** Verify code works by running it, not by checking if code exists. Structural analysis cannot prove behavior.\n\n**E2E for User-Facing:** User-visible features require end-to-end evidence (screenshots, user flow tests), not unit tests alone.\n\n**Honesty Requirement:** Claiming completion without fresh evidence is misrepresenting project state. Only advance when fully verified.\n",
        "lib/skills/ds-brainstorm/SKILL.md": "---\nname: ds-brainstorm\ndescription: \"This skill should be used when the user asks to \\\"start a data science project\\\", \\\"brainstorm analysis\\\", \\\"plan a data analysis\\\", or wants to clarify analysis requirements. REQUIRED Phase 1 of /ds workflow. Uses Socratic questioning to clarify goals, data sources, and constraints.\"\n---\n\n## Contents\n\n- [The Iron Law of DS Brainstorming](#the-iron-law-of-ds-brainstorming)\n- [What Brainstorm Does](#what-brainstorm-does)\n- [Critical Questions to Ask](#critical-questions-to-ask)\n- [Process](#process)\n- [Red Flags - STOP If You're About To](#red-flags---stop-if-youre-about-to)\n- [Output](#output)\n\n# Brainstorming (Questions Only)\n\nRefine vague analysis requests into clear objectives through Socratic questioning.\n**NO data exploration, NO coding** - just questions and objectives.\n\n<EXTREMELY-IMPORTANT>\n## The Iron Law of DS Brainstorming\n\n**ASK QUESTIONS BEFORE ANYTHING ELSE. This is not negotiable.**\n\nBefore loading data, before exploring, before proposing approaches, you MUST:\n1. Ask clarifying questions using AskUserQuestion\n2. Understand what the user actually wants to learn\n3. Identify data sources and constraints\n4. Define success criteria\n5. Only THEN propose analysis approaches\n\n**STOP - You're about to load data or explore before asking questions. Don't do this.**\n</EXTREMELY-IMPORTANT>\n\n## What Brainstorm Does\n\n| DO | DON'T |\n|-------|----------|\n| Ask clarifying questions | Load or explore data |\n| Understand analysis objectives | Run queries |\n| Identify data sources | Profile data (that's /ds-plan) |\n| Define success criteria | Create visualizations |\n| Ask about constraints | Write analysis code |\n| Check if replicating existing analysis | Propose specific methodology |\n\n**Brainstorm answers: WHAT and WHY**\n**Plan answers: HOW (data profile + tasks)** (separate skill)\n\n## Critical Questions to Ask\n\n### Data Source Questions\n- What data sources are available?\n- Where is the data located (files, database, API)?\n- What time period does the data cover?\n- How frequently is the data updated?\n\n### Objective Questions\n- What question are you trying to answer?\n- Who is the audience for this analysis?\n- What decisions will be made based on results?\n- What would a successful outcome look like?\n\n### Constraint Questions\n- **Are you replicating an existing analysis?** (Critical for methodology)\n- Are there specific methodologies required?\n- What is the timeline for this analysis?\n- Are there computational resource constraints?\n\n### Output Questions\n- What format should results be in (report, dashboard, model)?\n- What visualizations are expected?\n- How will results be validated?\n\n## Process\n\n### 1. Ask Questions First\n\nEmploy `AskUserQuestion` immediately:\n- **One question at a time** - never batch\n- **Multiple-choice preferred** - easier to answer\n- Focus on: objectives, data sources, constraints, replication requirements\n\n### 2. Identify Replication Requirements\n\n**CRITICAL:** Ask early if replicating existing work:\n\n```\nAskUserQuestion:\n  question: \"Are you replicating or extending existing analysis?\"\n  options:\n    - label: \"Replicating existing\"\n      description: \"Must match specific methodology/results\"\n    - label: \"Extending existing\"\n      description: \"Building on prior work with modifications\"\n    - label: \"New analysis\"\n      description: \"Fresh analysis, methodology flexible\"\n```\n\nWhen replicating:\n- Obtain reference to original (paper, code, report)\n- Document exact methodology requirements\n- Define acceptable deviation from original results\n\n### 3. Propose Approaches\n\nAfter objectives are clear:\n- Propose **2-3 different approaches** with trade-offs\n- **Lead with recommendation** (mark as \"Recommended\")\n- Use `AskUserQuestion` for the user to select the preferred approach\n\n### 4. Write Spec Doc\n\nAfter selecting an approach:\n- Write to `.claude/SPEC.md`\n- Include: objectives, data sources, success criteria, constraints\n- **NO implementation details** - reserve those for /ds-plan\n\n```markdown\n# Spec: [Analysis Name]\n\n> **For Claude:** After writing this spec, use `Read(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/ds-plan/SKILL.md\")` for Phase 2.\n\n## Objective\n[What question this analysis answers]\n\n## Data Sources\n- [Source 1]: [location, format, time period]\n- [Source 2]: [location, format, time period]\n\n## Success Criteria\n- [ ] Criterion 1\n- [ ] Criterion 2\n\n## Constraints\n- Replication: [yes/no - if yes, reference source]\n- Timeline: [deadline]\n- Methodology: [required approaches]\n\n## Chosen Approach\n[Description of selected approach]\n\n## Rejected Alternatives\n- Option B: [why rejected]\n- Option C: [why rejected]\n```\n\n## Red Flags - STOP If You Catch Yourself Doing This:\n\n| Action | Why It's Wrong | Do Instead |\n|--------|----------------|------------|\n| Loading data | You're exploring before understanding goals | Ask what the user wants to learn |\n| Running describe() | You're profiling data when that's for /ds-plan | Finish defining objectives first |\n| Proposing specific models | You're jumping to HOW before clarifying WHAT | Define success criteria first |\n| Creating task lists | You're planning before objectives are clear | Complete brainstorm first |\n| Skipping replication question | You might miss critical methodology constraints | Always ask about replication upfront |\n\n## Output\n\nDeclare brainstorm complete when:\n- Analysis objectives clearly understood\n- Data sources identified\n- Success criteria defined\n- Constraints documented (especially replication requirements)\n- Approach chosen from alternatives\n- `.claude/SPEC.md` written\n- User confirms ready for data exploration\n\n## Workflow Context\n\nThis skill is Phase 1 of the 5-phase `/ds` workflow:\n\n1. **Phase 1: ds-brainstorm** (current) - Clarify objectives through Socratic questioning\n2. **Phase 2: ds-plan** - Profile data and break analysis into tasks\n3. **Phase 3: ds-implement** - Execute analysis tasks with output-first verification\n4. **Phase 4: ds-review** - Review methodology, data quality, and statistical validity\n5. **Phase 5: ds-verify** - Check reproducibility and obtain user acceptance\n\n## Phase Complete\n\nAfter completing brainstorm, IMMEDIATELY invoke the next phase:\n\n```bash\n# Invoke Phase 2: Data profiling and task breakdown\n/ds-plan\n```\n\nOr use the Skill tool directly:\n\n```\nRead(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/ds-plan/SKILL.md\")\n```\n\n**CRITICAL:** Do not skip to analysis implementation. Phase 2 profiles data and breaks down the analysis into discrete, manageable tasks.\n",
        "lib/skills/ds-delegate/SKILL.md": "---\nname: ds-delegate\nversion: 1.0\ndescription: \"Subagent delegation for data analysis. Dispatches fresh Task agents with output-first verification.\"\n---\n\n\n## Contents\n\n- [The Iron Law of Delegation](#the-iron-law-of-delegation)\n- [Core Principle](#core-principle)\n- [The Process](#the-process)\n- [Honesty Requirement](#honesty-requirement)\n- [Rationalization Prevention](#rationalization-prevention)\n\n<EXTREMELY-IMPORTANT>\n## The Iron Law of Delegation\n\n**YOU MUST route EVERY ANALYSIS STEP THROUGH A TASK AGENT. This is not negotiable.**\n\nYou MUST NOT:\n- Write analysis code directly\n- Run \"quick\" data checks\n- Edit notebooks or scripts\n- Make \"just this one plot\"\n\n**If you're about to write analysis code in main chat, STOP. Spawn a Task agent instead.**\n</EXTREMELY-IMPORTANT>\n\n## Core Principle\n\n**Fresh subagent per task + output-first verification = reliable analysis**\n\n- Analyst subagent does the work\n- Must produce visible output at each step\n- Methodology reviewer checks approach\n- Loop until output verified\n\n## When to Use\n\nCalled by `ds-implement` for each task in PLAN.md. Don't invoke directly.\n\n## The Process\n\n```\nFor each task:\n    1. Dispatch analyst subagent\n       - If questions → answer, re-dispatch\n       - Implements with output-first protocol\n    2. Verify outputs are present and reasonable\n    3. Dispatch methodology reviewer (if complex)\n    4. Mark task complete, log to LEARNINGS.md\n```\n\n## Step 1: Dispatch Analyst\n\n**Pattern:** Use structured delegation template from `lib/references/delegation-template.md`\n\nEvery delegation MUST include:\n1. TASK - What to analyze\n2. EXPECTED OUTCOME - Success criteria\n3. REQUIRED SKILLS - Statistical/ML methods needed\n4. REQUIRED TOOLS - Data access and analysis tools\n5. MUST DO - Output-first verification\n6. MUST NOT DO - Methodology violations\n7. CONTEXT - Data sources and previous work\n8. VERIFICATION - Output requirements\n\nUse this Task invocation (fill in brackets):\n\n```\nTask(subagent_type=\"general-purpose\", prompt=\"\"\"\n# TASK\n\nAnalyze: [TASK NAME]\n\n## EXPECTED OUTCOME\n\nYou will have successfully completed this task when:\n- [ ] [Specific analysis output 1]\n- [ ] [Specific analysis output 2]\n- [ ] Output-first verification at each step\n- [ ] Results documented with evidence\n\n## REQUIRED SKILLS\n\nThis task requires:\n- [Statistical method]: [Why needed]\n- [Programming language]: Data manipulation\n- Output-first verification (mandatory)\n\n## REQUIRED TOOLS\n\nYou will need:\n- Read: Load datasets and existing code\n- Write: Create analysis scripts/notebooks\n- Bash: Run analysis and verify outputs\n\n**Tools denied:** None (full analysis access)\n\n## MUST DO\n\n- [ ] Print state BEFORE each operation (shape, head)\n- [ ] Print state AFTER each operation (nulls, sample)\n- [ ] Verify outputs are reasonable at each step\n- [ ] Document methodology decisions\n\n## MUST NOT DO\n\n- ❌ Skip verification outputs\n- ❌ Proceed with questionable data without flagging\n- ❌ Guess on methodology (ask if unclear)\n- ❌ Claim completion without visible outputs\n\n## CONTEXT\n\n### Task Description\n[PASTE FULL TASK TEXT FROM PLAN.md]\n\n### Analysis Context\n- Analysis objective: [from SPEC.md]\n- Data sources: [list with paths]\n- Previous steps: [summary from LEARNINGS.md]\n\n## Output-First Protocol (MANDATORY)\nFor EVERY operation:\n1. Print state BEFORE (shape, head)\n2. Execute operation\n3. Print state AFTER (shape, nulls, sample)\n4. Verify output is reasonable\n\nExample:\n```python\nprint(f\"Before: {df.shape}\")\ndf = df.merge(other, on='key')\nprint(f\"After: {df.shape}\")\nprint(f\"Nulls introduced: {df.isnull().sum().sum()}\")\ndf.head()\n```\n\n## Required Outputs by Operation\n| Operation | Required Output |\n|-----------|-----------------|\n| Load data | shape, dtypes, head() |\n| Filter | shape before/after, % removed |\n| Merge/Join | shape, null check, sample |\n| Groupby | result shape, sample groups |\n| Model fit | metrics, convergence |\n\n## If Unclear\nAsk questions BEFORE implementing. Don't guess on methodology.\n\n## Output\nReport: what you did, key outputs observed, any data quality issues found.\n\"\"\")\n```\n\n**If analyst asks questions:** Answer clearly, especially about methodology choices.\n\n**If analyst completes task:** Verify outputs, then proceed or review.\n\n## Step 2: Verify Outputs\n\nConfirm before proceeding:\n- [ ] Output files/variables exist\n- [ ] Shapes are reasonable (no unexpected row loss)\n- [ ] No silent null introduction\n- [ ] Sample output matches expectations\n\nUpon verification failure, re-dispatch analyst with specific fix instructions.\n\n## Step 3: Dispatch Methodology Reviewer (Complex Tasks)\n\nFor statistical analysis, modeling, or methodology-sensitive tasks, dispatch a methodology reviewer:\n\n```\nTask(subagent_type=\"general-purpose\", prompt=\"\"\"\nReview methodology for: [TASK NAME]\n\n## What Was Done\n[SUMMARY FROM ANALYST OUTPUT]\n\n## Original Requirements\n[FROM SPEC.md - especially any replication requirements]\n\n## CRITICAL: Do Not Trust the Report\n\nThe analyst may have:\n- Reported success without actually running the code\n- Cherry-picked output that looks correct\n- Glossed over data quality issues\n- Made methodology choices without justification\n\n**DO:**\n- Read the actual code or notebook cells\n- Verify outputs exist and match claims\n- Check for silent failures (empty DataFrames, all nulls)\n- Confirm statistical assumptions were checked\n\n## Review Checklist\n1. Is the statistical method appropriate for the data type?\n2. Are assumptions documented and checked?\n3. Is sample size adequate for conclusions?\n4. Are there data leakage concerns?\n5. Is the approach reproducible (seeds, versions)?\n\n## Confidence Scoring\nRate each issue 0-100. Only report issues >= 80 confidence.\n\n## Output Format\n- APPROVED: Methodology sound (after verifying code/outputs yourself)\n- ISSUES: List concerns with confidence scores and file:line references\n\"\"\")\n```\n\n## Step 4: Log to LEARNINGS.md\n\nAppend to `.claude/LEARNINGS.md` after each task:\n\n```markdown\n## Task N: [Name] - COMPLETE\n\n**Input:** [describe input state]\n\n**Operation:** [what was done]\n\n**Output:**\n- Shape: [final shape]\n- Key findings: [observations]\n\n**Verification:**\n- [how you confirmed it worked]\n\n**Next:** [what comes next]\n```\n\n## Honesty Requirement\n\n<EXTREMELY-IMPORTANT>\n**Claiming \"analysis done\" without output verification is LYING.**\n\nWhen you say \"Step complete\", you are asserting:\n- A Task agent ran the analysis\n- Output was visible and verified by you\n- You personally checked it (not just trusting the agent's word)\n- Methodology reviewer approved (for statistical tasks)\n\nIf ANY of these didn't happen, you are not \"summarizing\" - you are LYING about the state of the analysis.\n\n**Your dishonest claims corrupt research. Your honest \"investigating\" maintains integrity.**\n</EXTREMELY-IMPORTANT>\n\n## Rationalization Prevention\n\nRecognize these thoughts as signals to stop and delegate instead:\n\n| Thought | Reality |\n|---------|---------|\n| \"I'll just check the shape quickly\" | You'll skip the output-first protocol. Delegate instead. |\n| \"It's just a simple merge\" | Your merges fail silently. Delegate with verification. |\n| \"I already know this data\" | Your knowing ≠ verified. Delegate anyway. |\n| \"The subagent will be slower\" | You're wrong—wrong results are slower than slow results. Delegate. |\n| \"Just this one plot\" | You're hiding data issues with one plot. Delegate. |\n| \"User wants results fast\" | They want CORRECT results. You're optimizing for wrong metric. Delegate. |\n| \"Skip methodology review, it's standard\" | Your \"standard\" assumptions often fail. Review anyway. |\n| \"Output looked reasonable\" | You didn't verify—\"looked reasonable\" ≠ verified. Check numbers. |\n\n## Red Flags\n\n**If you catch yourself thinking these, STOP immediately:**\n\n- \"I can skip output verification this time\"\n- \"I'll chain operations together, it's fine\"\n- \"Unexpected nulls are probably okay\"\n- \"Methodology review takes too long, skip it\"\n- \"The merge probably worked\"\n- \"Output-first protocol is overkill here\"\n- \"I'll just summarize PLAN.md for the analyst\" (STOP—provide full text)\n\n**When analyst produces no visible output:**\n- You must re-dispatch with explicit output requirements\n- Treat this as a hard failure, not something to work around\n\n**When analyst fails a task:**\n- You must dispatch a fix subagent with specific instructions\n- Don't fix it yourself in main chat—you'll pollute context and hide the real issue\n\n## Example Flow\n\n```\nMe: Implementing Task 1: Load and clean transaction data\n\n[Dispatch analyst with full task text]\n\nAnalyst:\n- Loaded transactions.csv: (50000, 12)\n- Found 5% nulls in amount column\n- \"Should I drop or impute nulls?\"\n\nMe: \"Impute with median, flag imputed rows\"\n\n[Re-dispatch with answer]\n\nAnalyst:\n- Imputed 2,500 rows with median ($45.50)\n- Added is_imputed flag column\n- Final shape: (50000, 13)\n- Sample output: [shows head with flag]\n\n[Verify: shapes match, flag exists, no unexpected changes]\n\n[Log to LEARNINGS.md]\n\n[Mark Task 1 complete, move to Task 2]\n```\n\n## Integration\n\nThis skill is invoked by `ds-implement` during the output-first implementation phase.\nAfter all tasks complete, `ds-implement` proceeds to `ds-review`.\n",
        "lib/skills/ds-implement/SKILL.md": "---\nname: ds-implement\ndescription: \"REQUIRED Phase 3 of /ds workflow. Enforces output-first verification at each step.\"\n---\n\n## Overview\n\nApply output-first verification at every step of analysis implementation. This is Phase 3 of the `/ds` workflow.\n\n## Contents\n\n- [Delegation Pattern](#delegation-pattern) - Main chat orchestrates, subagents analyze\n- [The Iron Law](#the-iron-law-of-ds-implementation) - EVERY step MUST produce visible output\n- [Output-First Protocol](#output-first-protocol) - Required outputs by operation type\n- [Implementation Process](#implementation-process) - Step-by-step workflow\n- [Task Agent Invocation](#task-agent-invocation) - Spawning sub-agents\n- [Verification Patterns](#verification-patterns) - See `references/verification-patterns.md`\n- [Common Failures](#common-failures-to-avoid) - Silent data loss, hidden nulls\n\n# Implementation (Output-First Verification)\n\n<EXTREMELY-IMPORTANT>\n## The Iron Law of Delegation\n\n**YOU MUST NOT WRITE ANALYSIS CODE. This is not negotiable.**\n\nYou orchestrate. Subagents analyze. STOP if you're about to write Python/R code.\n\nAllowed in main chat:\n- Spawn Task agents\n- Review Task agent output\n- Verify outputs exist and are reasonable\n- Write to .claude/*.md files\n\nNOT allowed in main chat:\n- Write/Edit code files (.py, .R, .ipynb, etc.)\n- Direct data manipulation\n- \"Quick analysis\"\n\n**If you're about to write analysis code directly, STOP and spawn a Task agent instead.**\n\n### Rationalization Prevention\n\nStop immediately when you encounter these rationalizations:\n\n| Rationalization | Reality |\n|---------|---------|\n| \"It's just a quick plot\" | You'll hide data issues. Delegate instead. |\n| \"I'll just check the shape\" | Your shape checks need output-first protocol. Delegate. |\n| \"The subagent will take too long\" | Your impatience costs more in context than subagent time. Delegate. |\n| \"I already know this data\" | Your knowledge ≠ verified output. Delegate and see. |\n| \"Let me just run this merge\" | Your merges will silently fail. Delegate with verification. |\n| \"This is too simple for a subagent\" | Your simple code hides errors. Delegate. |\n| \"I'm already looking at the data\" | Your looking ≠ analyzing. Delegate. |\n| \"Results are needed fast\" | Your wrong results are worse than slow right results. Delegate. |\n</EXTREMELY-IMPORTANT>\n\n## Delegation Pattern\n\nFor each task in PLAN.md:\n1. Dispatch analyst subagent (does the work with output-first)\n2. Verify outputs are present and reasonable\n3. Dispatch methodology reviewer (for statistical tasks)\n4. Log findings to LEARNINGS.md\n\n**Why delegate?**\n- Fresh context per task (no pollution from previous analysis)\n- Enforced output verification (can't skip)\n- Error isolation (bad analysis doesn't corrupt main context)\n\n**REQUIRED SUB-SKILL:** For Task templates and detailed flow:\n```\nRead(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/ds-delegate/SKILL.md\")\n```\n\n---\n\nImplement analysis with mandatory visible output at every step.\n**NO TDD** - instead, every code step MUST produce and verify output.\n\n<EXTREMELY-IMPORTANT>\n## The Iron Law of DS Implementation\n\n**EVERY CODE STEP YOU WRITE MUST PRODUCE VISIBLE OUTPUT. This is not negotiable.**\n\nBefore moving to the next step, you MUST execute the following:\n1. Run the code\n2. See the output (print, display, plot)\n3. Verify output is correct/reasonable\n4. Document in LEARNINGS.md\n5. Only THEN proceed to next step\n\nThis applies even when YOU think:\n- \"I know this works\"\n- \"It's just a simple transformation\"\n- \"I'll check results at the end\"\n- \"The code is straightforward\"\n\n**If you're about to write code without outputting results, STOP.**\n</EXTREMELY-IMPORTANT>\n\n## What Output-First Means\n\n| DO | DON'T |\n|-------|----------|\n| Print shape after each transform | Chain operations silently |\n| Display sample rows | Trust transformations work |\n| Show summary stats | Wait until end to check |\n| Verify row counts | Assume merges worked |\n| Check for unexpected nulls | Skip intermediate checks |\n| Plot distributions | Move on without looking |\n\n**The Mantra:** If not visible, it cannot be trusted.\n\n## Red Flags - STOP Immediately\n\n| Thought | Why It's Wrong | Do Instead |\n|---------|----------------|------------|\n| \"I'll check at the end\" | STOP - you're letting errors compound silently | Check after every step |\n| \"This transform is simple\" | STOP - simple code can still be wrong | Output and verify |\n| \"I know merge worked\" | STOP - you've assumed this before and been wrong | Check row counts |\n| \"Data looks fine\" | STOP - you're confusing \"looks\" with verification | Print stats, show samples |\n| \"I'll batch the outputs\" | STOP - you're about to lose your ability to isolate issues | Output per operation |\n\n## Output-First Protocol\n\n### For Every Data Operation:\n\n```python\n# BEFORE\nprint(f\"Before: {df.shape}\")\n\n# OPERATION\ndf = df.merge(other, on='key')\n\n# AFTER - MANDATORY\nprint(f\"After: {df.shape}\")\nprint(f\"Nulls introduced: {df.isnull().sum().sum()}\")\ndf.head()\n```\n\n### Required Outputs by Operation Type\n\n| Operation | Required Output |\n|-----------|-----------------|\n| Load data | shape, dtypes, head() |\n| Filter | shape before/after, % removed |\n| Merge/Join | shape, null check, sample |\n| Groupby | result shape, sample groups |\n| Transform | before/after comparison, sample |\n| Model fit | metrics, convergence info |\n| Prediction | distribution, sample predictions |\n\n## Implementation Process\n\n### Step 1: Read Plan\n\nRead the plan to understand task order:\n\n```bash\ncat .claude/PLAN.md  # View analysis plan and task sequence\n```\n\nFollow the task order defined in the plan.\n\n### Step 2: Implement with Output\n\nFor each task:\n\n```python\n# Task N: [Description]\nprint(\"=\" * 50)\nprint(\"Task N: [Description]\")\nprint(\"=\" * 50)\n\n# Before state\nprint(f\"Input shape: {df.shape}\")\n\n# Operation\nresult = do_operation(df)\n\n# After state - MANDATORY\nprint(f\"Output shape: {result.shape}\")\nprint(f\"Sample output:\")\ndisplay(result.head())\n\n# Verification\nassert result.shape[0] > 0, \"No rows returned!\"\nprint(\"Task N complete\")\n```\n\n### Step 3: Log to LEARNINGS.md\n\nDocument every significant step:\n\n```markdown\n## Step N: [Task Description]\n\n**Input:** DataFrame with shape (10000, 15)\n\n**Operation:** Merged with reference table on 'id'\n\n**Output:**\n- Shape: (9500, 20)\n- 500 rows dropped (no match)\n- 5 new columns added\n- No new nulls introduced\n\n**Verification:**\n- Row count reasonable (5% drop expected due to filtering)\n- Sample output matches expected format\n- Key columns preserved\n\n**Notes:** [Any observations, issues, or decisions]\n```\n\n## Task Agent Invocation\n\nMain chat spawns Task agent:\n\n```\nTask(subagent_type=\"general-purpose\", prompt=\"\"\"\nImplement [TASK] following output-first protocol.\n\nContext:\n- Read .claude/LEARNINGS.md for prior steps\n- Read .claude/PLAN.md for task details\n- Read .claude/SPEC.md for objectives\n\nOutput-First Protocol:\n1. Print state BEFORE each operation\n2. Execute the operation\n3. Print state AFTER with verification\n4. Display sample output\n5. Document in LEARNINGS.md\n\nRequired outputs per operation:\n- Shape before/after\n- Null counts\n- Sample rows (head)\n- Sanity checks (row counts, value ranges)\n\nDO NOT proceed to next task without:\n- Visible output showing operation worked\n- LEARNINGS.md entry documenting the step\n\nReport back: what was done, output observed, any issues.\n\"\"\")\n```\n\n## Verification Patterns\n\nSee [references/verification-patterns.md](references/verification-patterns.md) for detailed code patterns for:\n- Data loading, filtering, merging\n- Aggregation and model training\n- Quick reference table by operation type\n\n## Common Failures to Avoid\n\n| Failure | Why It Happens | Prevention |\n|---------|----------------|------------|\n| Silent data loss | Merge drops rows | Print row counts before/after |\n| Hidden nulls | Join introduces nulls | Check null counts after joins |\n| Wrong aggregation | Groupby logic error | Display sample groups |\n| Type coercion | Pandas silent conversion | Verify dtypes after load |\n| Off-by-one | Date filtering edge cases | Print min/max dates |\n\n## Logging\n\nAppend each step to `.claude/LEARNINGS.md`:\n\n```markdown\n## Step N: [Description] - [STATUS]\n\n**Input:** [Describe input state]\n\n**Operation:** [What was done]\n\n**Output:** [Shape, stats, sample]\n```\n[Paste actual output here]\n```\n\n**Verification:** [How you confirmed it worked]\n\n**Next:** [What comes next]\n```\n\n## If Output Looks Wrong\n\n1. **STOP** - do not proceed\n2. **Investigate** - print more details\n3. **Document** - log the issue in LEARNINGS.md\n4. **Ask** - if unclear, ask user for guidance\n5. **Fix** - only proceed after output verified\n\n**Never hide failures.** Bad output documented is better than silent failure.\n\n## No Pause Between Tasks\n\n<EXTREMELY-IMPORTANT>\n**After completing task N, IMMEDIATELY start task N+1. You MUST NOT pause.**\n\n| Thought | Reality |\n|---------|---------|\n| \"Task done, should check in with user\" | You're wasting context. User wants ALL tasks done. Keep going. |\n| \"User might want to see intermediate results\" | You're assuming wrong. User will see results at the END. Continue. |\n| \"Natural pause point\" | You're making excuses. Only pause when ALL tasks complete or you're blocked. |\n| \"Should summarize this step\" | You're procrastinating. Summarize AFTER all tasks. Keep moving. |\n\n**Your pausing between tasks is procrastination disguised as courtesy.**\n</EXTREMELY-IMPORTANT>\n\n## Phase Complete\n\n**REQUIRED SUB-SKILL:** After all analysis steps complete with verified output, IMMEDIATELY invoke:\n```\nRead(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/ds-review/SKILL.md\")\n```\n",
        "lib/skills/ds-implement/references/verification-patterns.md": "# Verification Patterns\n\nCode patterns for output-first verification in data science workflows.\n\n## Data Loading\n\n```python\ndf = pd.read_csv(path)\nprint(f\"Loaded: {df.shape}\")\nprint(f\"Columns: {df.columns.tolist()}\")\nprint(f\"Dtypes:\\n{df.dtypes}\")\ndf.head()\n```\n\n## Filtering\n\n```python\nbefore = len(df)\ndf = df[df['col'] > threshold]\nafter = len(df)\nprint(f\"Filtered: {before} -> {after} ({100*(before-after)/before:.1f}% removed)\")\n```\n\n## Merging\n\n```python\nleft_size = len(df1)\nright_size = len(df2)\nmerged = df1.merge(df2, on='key', how='left')\nprint(f\"Merge: {left_size} x {right_size} -> {len(merged)}\")\nprint(f\"New nulls: {merged[df2.columns].isnull().sum().sum()}\")\n```\n\n## Aggregation\n\n```python\nresult = df.groupby('category').agg({'value': 'mean'})\nprint(f\"Groups: {len(result)}\")\nprint(f\"Stats:\\n{result.describe()}\")\nresult.head(10)\n```\n\n## Model Training\n\n```python\nmodel.fit(X_train, y_train)\ntrain_score = model.score(X_train, y_train)\nval_score = model.score(X_val, y_val)\nprint(f\"Train score: {train_score:.4f}\")\nprint(f\"Val score: {val_score:.4f}\")\nprint(f\"Gap: {train_score - val_score:.4f}\")\n```\n\n## Quick Reference Table\n\n| Operation | Required Output |\n|-----------|-----------------|\n| Load data | shape, dtypes, head() |\n| Filter | shape before/after, % removed |\n| Merge/Join | shape, null check, sample |\n| Groupby | result shape, sample groups |\n| Transform | before/after comparison, sample |\n| Model fit | metrics, convergence info |\n| Prediction | distribution, sample predictions |\n",
        "lib/skills/ds-plan/SKILL.md": "---\nname: ds-plan\nversion: 1.0\ndescription: \"REQUIRED Phase 2 of /ds workflow. Profiles data and creates analysis task breakdown.\"\n---\n\nAnnounce: \"Using ds-plan (Phase 2) to profile data and create task breakdown.\"\n\n## Contents\n\n- [The Iron Law of DS Planning](#the-iron-law-of-ds-planning)\n- [What Plan Does](#what-plan-does)\n- [Process](#process)\n- [Red Flags - STOP If You're About To](#red-flags---stop-if-youre-about-to)\n- [Output](#output)\n\n# Planning (Data Profiling + Task Breakdown)\n\nProfile the data and create an analysis plan based on the spec.\n**Requires `.claude/SPEC.md` from /ds-brainstorm first.**\n\n<EXTREMELY-IMPORTANT>\n## The Iron Law of DS Planning\n\n**SPEC MUST EXIST BEFORE PLANNING. This is not negotiable.**\n\nBefore exploring data or creating tasks, you MUST have:\n1. `.claude/SPEC.md` with objectives and constraints\n2. Clear success criteria\n3. User-approved spec\n\n**If `.claude/SPEC.md` doesn't exist, run /ds-brainstorm first.**\n</EXTREMELY-IMPORTANT>\n\n### Rationalization Table - STOP If You Think:\n\n| Excuse | Reality | Do Instead |\n|--------|---------|------------|\n| \"Data looks clean, profiling unnecessary\" | Your data is never clean | PROFILE to discover issues |\n| \"I can profile as I go\" | You'll miss systemic issues | PROFILE comprehensively NOW |\n| \"Quick .head() is enough\" | Your head hides tail problems | RUN full profiling checklist |\n| \"Missing values won't affect my analysis\" | They always do | DOCUMENT and plan handling |\n| \"I'll handle data issues during analysis\" | Your issues will derail your analysis | FIX data issues FIRST |\n| \"User didn't mention data quality\" | They assume YOU'LL check | QUALITY check is YOUR job |\n| \"Profiling takes too long\" | Your skipping it costs days later | INVEST time now |\n\n### Honesty Framing\n\n**Creating an analysis plan without profiling the data is LYING about understanding the data.**\n\nYou cannot plan analysis steps without knowing:\n- Your data's shape and types\n- Your missing value patterns\n- Your data quality issues\n- Your cleaning requirements\n\nProfiling costs you minutes. Your wrong plan costs hours of rework and incorrect results.\n\n### No Pause After Completion\n\nAfter writing `.claude/PLAN.md`, IMMEDIATELY invoke:\n```\nRead(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/ds-implement/SKILL.md\")\n```\n\nDO NOT:\n- Ask \"should I proceed with implementation?\"\n- Summarize the plan\n- Wait for user confirmation (they approved SPEC already)\n- Write status updates\n\nThe workflow phases are SEQUENTIAL. Complete plan → immediately start implement.\n\n## What Plan Does\n\n| DO | DON'T |\n|-------|----------|\n| Read .claude/SPEC.md | Skip brainstorm phase |\n| Profile data (shape, types, stats) | Skip to analysis |\n| Identify data quality issues | Ignore missing/duplicate data |\n| Create ordered task list | Write final analysis code |\n| Write .claude/PLAN.md | Make completion claims |\n\n**Brainstorm answers: WHAT and WHY**\n**Plan answers: HOW and DATA QUALITY**\n\n## Process\n\n### 1. Verify Spec Exists\n\n```bash\ncat .claude/SPEC.md  # verify-spec: read SPEC file to confirm it exists\n```\n\nIf missing, stop and run `/ds-brainstorm` first.\n\n### 2. Data Profiling\n\n**For multiple data sources:** Profile in parallel using background Task agents.\n\n#### Single Data Source (Direct Profiling)\n\n**MANDATORY profiling steps:**\n\n```python\nimport pandas as pd\n\n# Basic structure\ndf.shape                    # (rows, columns)\ndf.dtypes                   # Column types\ndf.head(10)                 # Sample data\ndf.tail(5)                  # End of data\n\n# Summary statistics\ndf.describe()               # Numeric summaries\ndf.describe(include='object')  # Categorical summaries\ndf.info()                   # Memory, non-null counts\n\n# Data quality checks\ndf.isnull().sum()           # Missing values per column\ndf.duplicated().sum()       # Duplicate rows\ndf[col].value_counts()      # Distribution of categories\n\n# For time series\ndf[date_col].min(), df[date_col].max()  # Date range\ndf.groupby(date_col).size()              # Records per period\n```\n\n#### Multiple Data Sources (Parallel Profiling)\n\n<EXTREMELY-IMPORTANT>\n**Pattern from oh-my-opencode: Launch ALL profiling agents in a SINGLE message.**\n\n**Use `run_in_background: true` for parallel execution.**\n\nWhen profiling 2+ data sources, launch agents in parallel:\n</EXTREMELY-IMPORTANT>\n\n```\n# PARALLEL + BACKGROUND: All Task calls in ONE message\n\nTask(\n    subagent_type=\"general-purpose\",\n    description=\"Profile dataset 1\",\n    run_in_background=true,\n    prompt=\"\"\"\nProfile this dataset and return a data quality report.\n\nDataset: /path/to/dataset1.csv\n\nRequired checks:\n1. Shape: rows x columns\n2. Data types: df.dtypes\n3. Missing values: df.isnull().sum()\n4. Duplicates: df.duplicated().sum()\n5. Summary statistics: df.describe()\n6. Unique value counts for categorical columns\n7. Date range if time series\n8. Memory usage: df.info()\n\nOutput format:\n- Markdown table with column summary\n- List of data quality issues found\n- Recommendations for cleaning\n\nTools denied: Write, Edit, NotebookEdit (read-only profiling)\n\"\"\")\n\nTask(\n    subagent_type=\"general-purpose\",\n    description=\"Profile dataset 2\",\n    run_in_background=true,\n    prompt=\"\"\"\n[Same template for dataset 2]\n\"\"\")\n\nTask(\n    subagent_type=\"general-purpose\",\n    description=\"Profile dataset 3\",\n    run_in_background=true,\n    prompt=\"\"\"\n[Same template for dataset 3]\n\"\"\")\n```\n\n**After launching agents:**\n- Continue to other work (don't wait)\n- Check status with `/tasks` command\n- Collect results with TaskOutput when ready\n\n```\n# Collect profiling results\nTaskOutput(task_id=\"task-abc123\", block=true, timeout=30000)\nTaskOutput(task_id=\"task-def456\", block=true, timeout=30000)\nTaskOutput(task_id=\"task-ghi789\", block=true, timeout=30000)\n```\n\n**Benefits:**\n- 3x faster profiling for 3 datasets\n- Each agent focused on single source\n- Results consolidated in main chat\n\n### 3. Identify Data Quality Issues\n\n**CRITICAL:** Document ALL issues before proceeding:\n\n| Check | What to Look For |\n|-------|------------------|\n| Missing values | Null counts, patterns of missingness |\n| Duplicates | Exact duplicates, key-based duplicates |\n| Outliers | Extreme values, impossible values |\n| Type issues | Strings in numeric columns, date parsing |\n| Cardinality | Unexpected unique values |\n| Distribution | Skewness, unexpected patterns |\n\n### 4. Create Task Breakdown\n\nBreak analysis into ordered tasks:\n- Each task should produce **visible output**\n- Order by data dependencies\n- Include data cleaning tasks FIRST\n\n### 5. Write Plan Doc\n\nWrite to `.claude/PLAN.md`:\n\n```markdown\n# Analysis Plan: [Analysis Name]\n\n> **For Claude:** REQUIRED SUB-SKILL: Use `Read(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/ds-implement/SKILL.md\")` to implement this plan with output-first verification.\n>\n> **Delegation:** Main chat orchestrates, Task agents implement. Use `Read(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/ds-delegate/SKILL.md\")` for subagent templates.\n\n## Spec Reference\nSee: .claude/SPEC.md\n\n## Data Profile\n\n### Source 1: [name]\n- Location: [path/connection]\n- Shape: [rows] x [columns]\n- Date range: [start] to [end]\n- Key columns: [list]\n\n#### Column Summary\n| Column | Type | Non-null | Unique | Notes |\n|--------|------|----------|--------|-------|\n| col1 | int64 | 100% | 50 | Primary key |\n| col2 | object | 95% | 10 | Category |\n\n#### Data Quality Issues\n- [ ] Missing: col2 has 5% nulls - [strategy: drop/impute/flag]\n- [ ] Duplicates: 100 duplicate rows on [key] - [strategy]\n- [ ] Outliers: col3 has values > 1000 - [strategy]\n\n### Source 2: [name]\n[Same structure]\n\n## Task Breakdown\n\n### Task 1: Data Cleaning (required first)\n- Handle missing values in col2\n- Remove duplicates\n- Fix data types\n- Output: Clean DataFrame, log of rows removed\n\n### Task 2: [Analysis Step]\n- Input: Clean DataFrame\n- Process: [description]\n- Output: [specific output to verify]\n- Dependencies: Task 1\n\n### Task 3: [Next Step]\n[Same structure]\n\n## Output Verification Plan\nFor each task, define what output proves completion:\n- Task 1: \"X rows cleaned, Y rows dropped\"\n- Task 2: \"Visualization showing [pattern]\"\n- Task 3: \"Model accuracy >= 0.8\"\n\n## Reproducibility Requirements\n- Random seed: [value if needed]\n- Package versions: [key packages]\n- Data snapshot: [date/version]\n```\n\n## Red Flags - STOP If You're About To:\n\n| Action | Why It's Wrong | Do Instead |\n|--------|----------------|------------|\n| Skip data profiling | Your data issues will break your analysis | Always profile first |\n| Ignore missing values | You'll corrupt your results | Document and plan handling |\n| Start analysis immediately | You haven't characterized your data | Complete profiling |\n| Assume your data is clean | Never assume, you must verify | Run quality checks |\n\n## Output\n\nComplete the plan when:\n- Read and understand `.claude/SPEC.md`\n- Profile all data sources (shape, types, stats)\n- Document data quality issues\n- Define cleaning strategy for each issue\n- Order tasks by dependency\n- Define output verification criteria\n- Write `.claude/PLAN.md`\n- Confirm ready for implementation\n\n## Phase Complete\n\n**REQUIRED SUB-SKILL:** After completing plan, IMMEDIATELY invoke:\n```\nRead(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/ds-implement/SKILL.md\")\n```\n",
        "lib/skills/ds-review/SKILL.md": "---\nname: ds-review\ndescription: \"This skill should be used when running Phase 4 of the /ds workflow to review methodology, data quality, and statistical validity. Provides structured review checklists, confidence scoring, and issue identification for data analysis validation.\"\nversion: 1.0.0\n---\n\nAnnounce: \"Using ds-review (Phase 4) to check methodology and quality.\"\n\n## Contents\n\n- [The Iron Law of DS Review](#the-iron-law-of-ds-review)\n- [Red Flags - STOP Immediately If You Think](#red-flags---stop-immediately-if-you-think)\n- [Review Focus Areas](#review-focus-areas)\n- [Confidence Scoring](#confidence-scoring)\n- [Common DS Issues to Check](#common-ds-issues-to-check)\n- [Required Output Structure](#required-output-structure)\n- [Agent Invocation](#agent-invocation)\n- [Quality Standards](#quality-standards)\n\n# Analysis Review\n\nSingle-pass review combining methodology correctness, data quality handling, and reproducibility checks. Uses confidence-based filtering.\n\n<EXTREMELY-IMPORTANT>\n## The Iron Law of DS Review\n\n**You MUST only report issues with >= 80% confidence. This is not negotiable.**\n\nBefore reporting ANY issue, you MUST:\n1. Verify it's not a false positive\n2. Verify it impacts results or reproducibility\n3. Assign a confidence score\n4. Only report if score >= 80\n\nThis applies even when:\n- \"This methodology looks suspicious\"\n- \"I think this might introduce bias\"\n- \"The approach seems unusual\"\n- \"I would have done it differently\"\n\n**STOP - If you catch yourself about to report a low-confidence issue, DISCARD IT. You're about to compromise the review's integrity.**\n</EXTREMELY-IMPORTANT>\n\n## Red Flags - STOP Immediately If You Think:\n\n| Thought | Why It's Wrong | Do Instead |\n|---------|----------------|------------|\n| \"This looks wrong\" | Your vague suspicion isn't evidence | Find concrete proof or discard |\n| \"I would do it differently\" | Your style preference isn't a methodology error | Check if the approach is valid |\n| \"This might cause problems\" | Your \"might\" means < 80% confidence | Find proof or discard |\n| \"Unusual approach\" | Unusual isn't wrong—your bias toward familiar methods is clouding judgment | Verify the methodology is sound |\n\n## Review Focus Areas\n\n### Spec Compliance\n- [ ] Verify all objectives from .claude/SPEC.md are addressed\n- [ ] Confirm success criteria can be verified\n- [ ] Check constraints were respected (especially replication requirements)\n- [ ] Verify analysis answers the original question\n\n### Data Quality Handling\n- [ ] Confirm missing values handled appropriately (not ignored)\n- [ ] Verify duplicates addressed (documented if kept)\n- [ ] Check outliers considered (handled or justified)\n- [ ] Verify data types correct (dates parsed, numerics not strings)\n- [ ] Confirm filtering logic documented with counts\n\n### Methodology Appropriateness\n- [ ] Verify statistical methods appropriate for data type\n- [ ] Check assumptions documented and verified (normality, independence, etc.)\n- [ ] Confirm sample sizes adequate for conclusions\n- [ ] Check multiple comparisons addressed if applicable\n- [ ] Verify causality claims justified (or appropriately limited)\n\n### Reproducibility\n- [ ] Verify random seeds set where needed\n- [ ] Check package versions documented\n- [ ] Verify data source/version documented\n- [ ] Confirm all transformations traceable\n- [ ] Verify results can be regenerated\n\n### Output Quality\n- [ ] Verify visualizations labeled (title, axes, legend)\n- [ ] Check numbers formatted appropriately (sig figs, units)\n- [ ] Verify conclusions supported by evidence shown\n- [ ] Confirm limitations acknowledged\n\n## Confidence Scoring\n\nRate each potential issue from 0-100:\n\n| Score | Meaning |\n|-------|---------|\n| 0 | False positive or style preference |\n| 25 | Might be real, methodology is unusual but valid |\n| 50 | Real issue but minor impact on conclusions |\n| 75 | Verified issue, impacts result interpretation |\n| 100 | Certain error that invalidates conclusions |\n\n**CRITICAL: You MUST only report issues with confidence >= 80. If you report below this threshold, you're misrepresenting your certainty.**\n\n## Common DS Issues to Check\n\n### Data Leakage\n- Training data contains information from future\n- Test data used in feature engineering\n- Target variable used directly or indirectly in features\n\n### Selection Bias\n- Filtering introduced systematic bias\n- Survivorship bias in longitudinal data\n- Non-random sampling not addressed\n\n### Statistical Errors\n- Multiple testing without correction\n- p-hacking or selective reporting\n- Correlation interpreted as causation\n- Inadequate sample size for claimed precision\n\n### Reproducibility Failures\n- Random operations without seeds\n- Undocumented data preprocessing\n- Hard-coded paths or environment dependencies\n- Missing package versions\n\n## Required Output Structure\n\nmarkdown-output-structure: Template for review results with confidence-scored issues\n\n```markdown\n## Analysis Review: [Analysis Name]\nReviewing: [files/notebooks being reviewed]\n\n### Critical Issues (Confidence >= 90)\n\n#### [Issue Title] (Confidence: XX)\n\n**Location:** `file/path.py:line` or `notebook.ipynb cell N`\n\n**Problem:** Clear description of the issue\n\n**Impact:** How this affects results/conclusions\n\n**Fix:**\n```python\n# Specific fix\n```\n\n### Important Issues (Confidence 80-89)\n\n[Same format as Critical Issues]\n\n### Data Quality Checklist\n\n| Check | Status | Notes |\n|-------|--------|-------|\n| Missing values | PASS/FAIL | [details] |\n| Duplicates | PASS/FAIL | [details] |\n| Outliers | PASS/FAIL | [details] |\n| Type correctness | PASS/FAIL | [details] |\n\n### Methodology Checklist\n\n| Check | Status | Notes |\n|-------|--------|-------|\n| Appropriate for data | PASS/FAIL | [details] |\n| Assumptions checked | PASS/FAIL | [details] |\n| Sample size adequate | PASS/FAIL | [details] |\n\n### Reproducibility Checklist\n\n| Check | Status | Notes |\n|-------|--------|-------|\n| Seeds set | PASS/FAIL | [details] |\n| Versions documented | PASS/FAIL | [details] |\n| Data versioned | PASS/FAIL | [details] |\n\n### Summary\n\n**Verdict:** APPROVED | CHANGES REQUIRED\n\n[If APPROVED]\nThe analysis meets quality standards. No methodology issues with confidence >= 80 detected.\n\n[If CHANGES REQUIRED]\nX critical issues and Y important issues must be addressed before proceeding.\n```\n\n## Agent Invocation\n\ntask-agent-spawn: Spawn Task agent for structured analysis review\n\nSpawn a Task agent to review the analysis:\n\n```\nTask(subagent_type=\"general-purpose\"):\n\"Review analysis against .claude/SPEC.md.\n\nExecute single-pass review covering:\n1. Spec compliance - verify objectives met\n2. Data quality - confirm nulls, dupes, outliers handled\n3. Methodology - verify appropriate, assumptions checked\n4. Reproducibility - confirm seeds, versions, documentation\n\nConfidence score each issue (0-100).\nReport only issues with >= 80 confidence.\nReturn structured output per /ds-review format.\"\n```\n\n## Quality Standards\n\n- **You must NOT report methodology preferences not backed by statistical principles.** Your opinion about how code should be written is not a review issue.\n- **You must treat alternative valid approaches as non-issues (confidence = 0).** If the approach works correctly, don't report it.\n- Ensure each reported issue is immediately actionable\n- **If you're unsure, rate it below 80 confidence.** Uncertainty is not a reason to report—it's a reason to investigate more.\n- Focus on what affects conclusions, not style. **STOP if you catch yourself criticizing coding style—that's not your role here.**\n\n## Phase Complete\n\nphase-transition: Invoke ds-verify after APPROVED review\n\nAfter review is APPROVED, immediately invoke:\n\nds-verify: Verify analysis reproducibility and user acceptance\n\n```\nRead(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/ds-verify/SKILL.md\")\n```\n\nIf CHANGES REQUIRED, return to `/ds-implement` to fix issues first.\n",
        "lib/skills/ds-verify/SKILL.md": "---\nname: ds-verify\ndescription: \"This skill should be used when the user asks to 'verify analysis results', 'check reproducibility', 'validate data science output', 'confirm completion', or as Phase 5 of the /ds workflow (final). Enforces reproducibility demonstration and user acceptance before completion claims.\"\n---\n\nAnnounce: \"Using ds-verify (Phase 5) to confirm reproducibility and completion.\"\n\n## Contents\n\n- [The Iron Law of DS Verification](#the-iron-law-of-ds-verification)\n- [Red Flags - STOP Immediately If You Think](#red-flags---stop-immediately-if-you-think)\n- [The Verification Gate](#the-verification-gate)\n- [Verification Checklist](#verification-checklist)\n- [Reproducibility Demonstration](#reproducibility-demonstration)\n- [Claims Requiring Evidence](#claims-requiring-evidence)\n- [Insufficient Evidence](#insufficient-evidence)\n- [Required Output Structure](#required-output-structure)\n- [Completion Criteria](#completion-criteria)\n\n# Verification Gate\n\nFinal verification with reproducibility checks and user acceptance interview.\n\n<EXTREMELY-IMPORTANT>\n## The Iron Law of DS Verification\n\n**NO COMPLETION CLAIMS WITHOUT FRESH VERIFICATION. This is not negotiable.**\n\nBefore claiming analysis is complete, you MUST:\n1. RE-RUN - Execute analysis fresh (not cached results)\n2. CHECK - Verify outputs match expectations\n3. REPRODUCE - Confirm results are reproducible\n4. ASK - Interview user about constraints and acceptance\n5. Only THEN claim completion\n\nThis applies even when:\n- \"I just ran it\"\n- \"Results look the same\"\n- \"It should reproduce\"\n- \"User seemed happy earlier\"\n\n**If you catch yourself thinking \"I can skip verification,\" STOP - you're about to lie.**\n</EXTREMELY-IMPORTANT>\n\n## Red Flags - STOP Immediately If You Think:\n\n| Thought | Why It's Wrong | Do Instead |\n|---------|----------------|------------|\n| \"Results should be the same\" | Your \"should\" isn't verification | Re-run and compare |\n| \"I ran it earlier\" | Your earlier run isn't fresh | Run it again now |\n| \"It's reproducible\" | Your claim requires evidence | Demonstrate reproducibility |\n| \"User will be happy\" | Your assumption isn't their acceptance | Ask explicitly |\n| \"Outputs look right\" | Your visual inspection isn't verified | Check against criteria |\n\n## The Verification Gate\n\nBefore making ANY completion claim:\n\n```\n1. RE-RUN    → Execute fresh, not from cache\n2. CHECK     → Compare outputs to success criteria\n3. REPRODUCE → Same inputs → same outputs\n4. ASK       → User acceptance interview\n5. CLAIM     → Only after steps 1-4\n```\n\n**Skipping any step is not verification.**\n\n## Verification Checklist\n\n### Technical Verification\n\n#### Outputs Match Expectations\n- [ ] All required outputs generated\n- [ ] Output formats correct (files, figures, tables)\n- [ ] Numbers are reasonable (sanity checks)\n- [ ] Visualizations render correctly\n\n#### Reproducibility Confirmed\n- [ ] Ran analysis twice, got same results\n- [ ] Random seeds produce consistent output\n- [ ] No dependency on execution order\n- [ ] Environment documented (packages, versions)\n\n#### Data Integrity\n- [ ] Input data unchanged\n- [ ] Row counts traceable through pipeline\n- [ ] No silent data loss or corruption\n\n### User Acceptance Interview\n\n**CRITICAL:** Before claiming completion, conduct user interview.\n\n#### Step 1: Replication Constraints\n\n```\nAskUserQuestion:\n  question: \"Were there specific methodology requirements I should have followed?\"\n  options:\n    - label: \"Yes, replicating existing analysis\"\n      description: \"Results should match a reference\"\n    - label: \"Yes, required methodology\"\n      description: \"Specific methods were mandated\"\n    - label: \"No constraints\"\n      description: \"Methodology was flexible\"\n```\n\nIf replicating:\n- Ask for reference to compare against\n- Verify results match within tolerance\n- Document any deviations and reasons\n\n#### Step 2: Results Verification\n\n```\nAskUserQuestion:\n  question: \"Do these results answer your original question?\"\n  options:\n    - label: \"Yes, fully\"\n      description: \"Analysis addresses the core question\"\n    - label: \"Partially\"\n      description: \"Some aspects addressed, others missing\"\n    - label: \"No\"\n      description: \"Does not answer the question\"\n```\n\nIf \"Partially\" or \"No\":\n1. Ask which aspects are missing\n2. Return to `/ds-implement` to address gaps\n3. Re-run verification\n\n#### Step 3: Output Format\n\n```\nAskUserQuestion:\n  question: \"Are the outputs in the format you need?\"\n  options:\n    - label: \"Yes\"\n      description: \"Format is correct\"\n    - label: \"Need adjustments\"\n      description: \"Format needs modification\"\n```\n\n#### Step 4: Confidence in Results\n\n```\nAskUserQuestion:\n  question: \"Do you have any concerns about the methodology or results?\"\n  options:\n    - label: \"No concerns\"\n      description: \"Comfortable with approach and results\"\n    - label: \"Minor concerns\"\n      description: \"Would like clarification on some points\"\n    - label: \"Major concerns\"\n      description: \"Significant issues need addressing\"\n```\n\n## Reproducibility Demonstration\n\n**MANDATORY:** Demonstrate reproducibility before completion.\n\n```python\n# Run 1\nresult1 = run_analysis(seed=42)\nhash1 = hash(str(result1))\n\n# Run 2\nresult2 = run_analysis(seed=42)\nhash2 = hash(str(result2))\n\n# Verify\nassert hash1 == hash2, \"Results not reproducible!\"\nprint(f\"Reproducibility confirmed: {hash1} == {hash2}\")\n```\n\nFor notebooks:\n```bash\n# notebook-reproduce: Clear and re-run all cells from scratch\njupyter nbconvert --execute --inplace notebook.ipynb\n\n# notebook-reproduce-with-seed: Execute notebook with fixed random seed for reproducibility\npapermill notebook.ipynb output.ipynb -p seed 42\n```\n\n## Claims Requiring Evidence\n\n| Claim | Required Evidence |\n|-------|-------------------|\n| \"Analysis complete\" | All success criteria verified |\n| \"Results reproducible\" | Same output from fresh run |\n| \"Matches reference\" | Comparison showing match |\n| \"Data quality handled\" | Documented cleaning steps |\n| \"Methodology appropriate\" | Assumptions checked |\n\n## Insufficient Evidence\n\nThese do NOT count as verification:\n\n- Previous run results (must be fresh)\n- \"Should be reproducible\" (demonstrate it)\n- Visual inspection only (quantify where possible)\n- Single run (need reproducibility check)\n- Skipped user acceptance (must ask)\n\n## Required Output Structure\n\n```markdown\n## Verification Report: [Analysis Name]\n\n### Technical Verification\n\n#### Outputs Generated\n- [ ] Output 1: [location] - verified [date/time]\n- [ ] Output 2: [location] - verified [date/time]\n\n#### Reproducibility Check\n- Run 1 hash: [value]\n- Run 2 hash: [value]\n- Match: YES/NO\n\n#### Environment\n- Python: [version]\n- Key packages: [list with versions]\n- Random seed: [value]\n\n### User Acceptance\n\n#### Replication Check\n- Constraint: [none/replicating/required methodology]\n- Reference: [if applicable]\n- Match status: [if applicable]\n\n#### User Responses\n- Results address question: [yes/partial/no]\n- Output format acceptable: [yes/needs adjustment]\n- Methodology concerns: [none/minor/major]\n\n### Verdict\n\n**COMPLETE** or **NEEDS WORK**\n\n[If COMPLETE]\n- All technical checks passed\n- User accepted results\n- Reproducibility demonstrated\n\n[If NEEDS WORK]\n- [List items requiring attention]\n- Recommended next steps\n```\n\n## Completion Criteria\n\n**Only claim COMPLETE when ALL are true:**\n\n- [ ] All success criteria from SPEC.md verified\n- [ ] Results reproducible (demonstrated, not assumed)\n- [ ] User confirmed results address their question\n- [ ] User has no major concerns\n- [ ] Outputs in acceptable format\n- [ ] If replicating: results match reference\n\n**Both technical and user acceptance must pass. No shortcuts.**\n\n## Workflow Complete\n\nWhen user confirms all criteria are met:\n\n**Announce:** \"DS workflow complete. All 5 phases passed.\"\n\nThe `/ds` workflow is now finished. Offer to:\n- Export results to final format\n- Clean up `.claude/` files\n- Start a new analysis with `/ds`\n",
        "lib/skills/using-skills/SKILL.md": "---\nname: using-skills\nversion: 1.0\ndescription: \"Auto-loaded at session start via SessionStart hook. Teaches skill invocation protocol, tool selection rules (look-at for media, skills for workflows), agent delegation patterns, and enforcement mechanisms. NOT user-triggered - provides foundational skill usage discipline for all sessions.\"\n---\n\n# Using Skills\n\n**Invoke relevant skills BEFORE any response or action.**\n\nThis is non-negotiable. Even a 1% chance a skill applies requires checking.\n\n## CRITICAL: Skill Already Loaded - DO NOT RE-INVOKE\n\n<EXTREMELY-IMPORTANT>\n**If you see a skill name in the current conversation turn (e.g., `<command-name>/dev</command-name>`), the skill is ALREADY LOADED.**\n\n**DO NOT:**\n- ❌ Use the Skill tool to invoke it again\n- ❌ Say \"I need to invoke the skill\"\n- ❌ Call `Skill(skill=\"dev\")` or similar\n\n**DO INSTEAD:**\n- ✅ The skill instructions follow immediately in the next message\n- ✅ Just proceed to the next step\n- ✅ Follow the loaded skill's instructions directly\n\n**If you catch yourself about to invoke a skill that's already loaded, STOP. Just go to the next step.**\n</EXTREMELY-IMPORTANT>\n\n## The Rule\n\n```\nUser message arrives\n    ↓\nIs user explicitly invoking a skill (e.g., \"use /dev\")?\n    ↓\nYES → SKILL IS ALREADY LOADED\n      ↓\n      DO NOT invoke again with Skill tool\n      ↓\n      Proceed to next step (follow skill instructions)\nNO  → Check: Does this match any skill trigger?\n    ↓\nYES → Invoke skill FIRST, then follow its protocol\nNO  → Proceed normally\n```\n\n## Workflow Commands (User Must Invoke Explicitly)\n\nThese are commands, not auto-triggered skills. User must explicitly type the command:\n\n| Command | Purpose | User Types |\n|---------|---------|------------|\n| `/dev` | Feature development workflow (7 phases) | `/dev` |\n| `/ds` | Data analysis workflow (5 phases) | `/ds` |\n\n## Skill Triggers (Can Auto-Invoke)\n\n| User Intent | Skill | Trigger Words |\n|-------------|-------|---------------|\n| Bug/fix | `dev-debug` | bug, broken, fix, doesn't work, crash, error, fails |\n| Writing | `writing` | write, draft, document, essay, paper |\n| **Media analysis** | **look-at** | describe image, analyze PDF, what's in this, screenshot, diagram |\n\n## Red Flags - You're Skipping the Skill Check\n\nIf you think any of these, STOP:\n\n| Thought | Reality |\n|---------|---------|\n| **\"I need to invoke the skill properly\"** | **If user said \"use /dev\", it's ALREADY LOADED. Just proceed.** |\n| **\"Let me invoke the skill first\"** | **Check for `<command-name>` tag - it's already loaded if present** |\n| **\"I should use Skill tool for /dev\"** | **NO. User invocation = already loaded = proceed to next step** |\n| \"This is just a simple question\" | Simple questions don't involve reading code |\n| \"I'll gather information first\" | That IS investigation - use the skill |\n| \"I know exactly what to do\" | The skill provides structure you'll miss |\n| \"It's just one file\" | Scope doesn't exempt you from process |\n| \"Let me quickly check...\" | \"Quickly\" means skipping the workflow |\n| **\"I can read this image directly\"** | **Use look-at to save context tokens** |\n\n## Bug Reports - Mandatory Response\n\nWhen user mentions a bug:\n\n```\nDO NOT:\n1. Read code files\n2. Investigate independently\n3. \"Take a look\" without structure\n\nINSTEAD:\n1. Start ralph loop:\n   ralph-loop: Start Ralph Loop in current session with bug debugging\n   Skill(skill=\"ralph-loop:ralph-loop\", args=\"Debug: [symptom] --max-iterations 15 --completion-promise FIXED\")\n2. Inside loop, follow /dev-debug protocol\n```\n\n**Any code reading before starting the workflow is a violation.**\n\n## Skill Priority\n\nWhen multiple skills could apply:\n\n1. **Process skills first** - debugging, brainstorming determine approach\n2. **Then implementation** - dev, ds, writing execute the approach\n\n## How to Invoke\n\nUse the Skill tool to invoke skills:\n\n```bash\n# dev-debug: Systematic bug investigation and fixing with verification-driven methodology\nSkill(skill=\"dev-debug\")\n\n# dev: Feature development workflow with 7 phases and TDD enforcement\nSkill(skill=\"dev\")\n\n# ds: Data analysis workflow with 5 phases and output-first verification\nSkill(skill=\"ds\")\n```\n\nOr start ralph loop first for implementation/debug phases:\n\n```bash\n# ralph-loop: Per-task ralph loop pattern for implementation and debugging\nSkill(skill=\"ralph-loop:ralph-loop\", args=\"Task description --max-iterations 15\")\n```\n\n## IRON LAW: Multimodal File Analysis\n\n**NO READING IMAGES/PDFS WITH Read TOOL. USE look-at INSTEAD.**\n\n### The Rule\n\n```\nUser asks about image/PDF/media content\n    ↓\nIs it a media file requiring interpretation?\n    ↓\nYES → Use look-at skill (bash call to look_at.py)\nNO  → Use Read tool for source code/text\n```\n\n### When to Use look-at\n\n**ALWAYS use look-at for:**\n- `.jpg`, `.jpeg`, `.png`, `.webp`, `.gif`, `.heic` - Images\n- `.pdf` - PDFs requiring content extraction\n- `.mp4`, `.mov`, `.avi`, `.webm` - Videos\n- `.mp3`, `.wav`, `.aac`, `.ogg` - Audio\n- Any file where you need to UNDERSTAND content, not just see raw bytes\n\n**Pattern:**\n```bash\n# look-at: Extract information from media file with specific goal\npython3 ${CLAUDE_PLUGIN_ROOT}/skills/look-at/scripts/look_at.py \\\n    --file \"/absolute/path/to/file\" \\\n    --goal \"What specific information to extract\"\n```\n\n### When NOT to Use look-at\n\n**Use Read tool instead for:**\n- Source code files (`.py`, `.js`, `.rs`, etc.) - need exact formatting for editing\n- Plain text files (`.txt`, `.md`, `.json`, etc.) - preserve exact content\n- Config files requiring exact formatting preservation\n- Any file that needs editing after reading\n\n### Rationalization Table - STOP If You Think:\n\n| Excuse | Reality | Do Instead |\n|--------|---------|------------|\n| \"I can read images directly\" | Read tool shows you the image, but wastes context tokens | Use look-at to extract ONLY what's needed |\n| \"It's just one small image\" | Still uses 1000+ tokens in conversation context | look-at returns 50-200 tokens of extracted info |\n| \"I need to see the whole thing\" | You can see it, user can't see what you see | Use look-at with specific goal |\n| \"look-at might miss details\" | You can always fall back to Read if needed | Start with look-at, escalate if insufficient |\n| \"The user didn't ask for look-at\" | look-at is FOR YOU, not the user | Use the right tool for the job |\n\n### Red Flags - STOP If You Catch Yourself:\n\n- **\"Let me read this image...\"** → NO. Use look-at.\n- **\"I'll use Read to see what's in the PDF...\"** → NO. Use look-at.\n- **\"Just quickly checking this screenshot...\"** → NO. Use look-at.\n- **Passing image path to Read tool** → STOP. Use look-at instead.\n\n### Cost & Context Benefits\n\n- **Read tool on image:** ~1,000-5,000 context tokens\n- **look-at extraction:** ~50-200 output tokens\n- **Savings:** 95%+ token reduction\n- **Speed:** Faster responses, less context bloat\n\n### Example Usage\n\n```bash\n# look-at: Extract specific information from image file\npython3 ${CLAUDE_PLUGIN_ROOT}/skills/look-at/scripts/look_at.py \\\n    --file \"$HOME/Downloads/screenshot.png\" \\\n    --goal \"List all buttons and their labels\"\n\n# look-at: Analyze diagram to understand data flow\npython3 ${CLAUDE_PLUGIN_ROOT}/skills/look-at/scripts/look_at.py \\\n    --file \"$HOME/Documents/architecture.png\" \\\n    --goal \"Explain the data flow between components\"\n\n# look-at: Extract information from PDF document\npython3 ${CLAUDE_PLUGIN_ROOT}/skills/look-at/scripts/look_at.py \\\n    --file \"$HOME/Downloads/report.pdf\" \\\n    --goal \"Extract the executive summary section\"\n```\n\n### Enforcement\n\n**Using Read on images/PDFs when look-at should be used results in:**\n1. Wasting context tokens unnecessarily\n2. Making conversations slower\n3. Ignoring available optimization tools\n4. Violating the tool selection protocol\n\n**Validate before calling Read:** Ask \"Is this a media file?\" If yes, invoke look-at instead.\n\n## IRON LAW: Following Skill Instructions\n\n**WHEN A SKILL LOADS, YOU MUST FOLLOW ITS EXACT INSTRUCTIONS.**\n\nSkills contain specific patterns, required parameters, and enforcement rules. Skipping these requirements defeats the purpose of loading the skill.\n\n### The Rule\n\n```\nSkill loads successfully\n    ↓\nRead the skill's requirements carefully\n    ↓\nFollow ALL instructions, including:\n    - Required tool parameters (descriptions, timeouts, etc.)\n    - Specific command patterns\n    - Enforcement patterns (Iron Laws, Red Flags)\n    - Step sequences\n    ↓\nExecute using the skill's exact patterns\n```\n\n### Common Violations\n\n**Bash Description Parameter:**\n\nWhen a skill requires `description` parameter on Bash calls (like look-at), you MUST include it:\n\n```bash\n# ❌ WRONG: No description parameter\npython3 ${CLAUDE_PLUGIN_ROOT}/skills/look-at/scripts/look_at.py \\\n    --file \"/path/to/file.pdf\" \\\n    --goal \"Extract title\"\n\n# ✅ CORRECT: With description parameter as skill requires\nBash(\n    command='python3 ${CLAUDE_PLUGIN_ROOT}/skills/look-at/scripts/look_at.py --file \"/path/to/file.pdf\" --goal \"Extract title\"',\n    description=\"look-at: Extract title\"\n)\n```\n\n### Rationalization Table - STOP If You Think:\n\n| Excuse | Reality | Do Instead |\n|--------|---------|------------|\n| \"The skill is just guidance\" | Skills contain tested, required patterns | Follow the skill's exact instructions |\n| \"I know a better way\" | Your way skips enforcement or optimization | Use the skill's pattern - it exists for a reason |\n| \"Description parameter is optional\" | When skill says REQUIRED, it's required | Add the description parameter as instructed |\n| \"I'll add it if it fails\" | You'll clutter the conversation with messy output first | Follow the pattern from the start |\n| \"It's just cosmetic\" | Clean descriptions improve UX and debugging | Professional output requires following the pattern |\n\n### Red Flags - STOP If You Catch Yourself:\n\n- **About to call Bash without description when skill requires it** → STOP. Add the description parameter.\n- **Thinking \"I'll skip this requirement\"** → STOP. Skills don't have optional requirements.\n- **\"The skill says to do X but I'll do Y\"** → STOP. Follow the skill or don't load it.\n- **Modifying the skill's pattern \"to be simpler\"** → STOP. The pattern exists for a reason.\n\n### Why This Matters\n\n**Skills encode:**\n1. **Tested patterns** - Proven to work in production\n2. **Optimization** - Context/token savings, clean output\n3. **Enforcement** - Prevent common mistakes\n4. **UX standards** - Consistent, professional output\n\n**When you skip skill instructions:**\n- ❌ You waste the effort of loading the skill\n- ❌ You create messy, unprofessional output\n- ❌ You miss optimizations (context savings, speed)\n- ❌ You violate user expectations\n- ❌ You make debugging harder\n\n**The skill loaded for a reason - follow it completely.**\n\n## Advanced Agent Harnessing Patterns\n\n**For detailed oh-my-opencode production patterns including:**\n- Background + parallel execution (3x speedup)\n- Tool restrictions for focused agents\n- Structured delegation templates\n- Failure recovery protocol\n- Environment context injection\n- Cost classification system\n- Metadata-driven prompts\n\n**See:** `references/agent-harnessing.md`\n\nQuick reference:\n- Tool restrictions: `lib/references/tool-restrictions.md`\n- Delegation template: `lib/references/delegation-template.md`\n- Metadata infrastructure: `lib/references/skill-metadata.py`\n\nBased on: [obra/superpowers](https://github.com/obra/superpowers) and oh-my-opencode production patterns.\n",
        "lib/skills/using-skills/references/agent-harnessing.md": "# Advanced Agent Harnessing Patterns\n\n**Based on oh-my-opencode production patterns for specialized agent control.**\n\n## Background + Parallel Execution (Default)\n\nWhen spawning multiple Task agents for exploration or profiling:\n\n**ALWAYS use background + parallel:**\n```\n# CORRECT: All agents in ONE message, all with run_in_background=true\nTask(subagent_type=\"Explore\", description=\"Find auth\", run_in_background=true, prompt=\"...\")\nTask(subagent_type=\"Explore\", description=\"Find errors\", run_in_background=true, prompt=\"...\")\nTask(subagent_type=\"Explore\", description=\"Find API\", run_in_background=true, prompt=\"...\")\n\n# Collect results later with TaskOutput\n```\n\n**NEVER wait synchronously:**\n```\n# WRONG: Sequential execution\ntask1 = Task(...) # Blocks\ntask2 = Task(...) # Blocks\n```\n\n**Benefits:**\n- 3x faster for 3 agents\n- Main conversation continues immediately\n- Results collected asynchronously\n\n## Tool Restrictions (Enforce Focus)\n\nEvery delegated Task agent should have explicit tool restrictions:\n\n| Agent Purpose | Denied Tools | Reason |\n|---------------|--------------|--------|\n| Exploration | Write, Edit, NotebookEdit, Bash | Read-only search |\n| Review | Write, Edit, NotebookEdit | Analysis without changes |\n| Profiling | Write, Edit, NotebookEdit | Data inspection only |\n| Implementation | None | Full development access |\n\n**Pattern:** Default to most restrictive, grant only when needed.\n\nSee: `lib/references/tool-restrictions.md`\n\n## Structured Delegation Template\n\nEvery Task agent delegation MUST include:\n1. TASK - What to do\n2. EXPECTED OUTCOME - Success criteria\n3. REQUIRED SKILLS - Why this agent\n4. REQUIRED TOOLS - What they'll need\n5. MUST DO - Non-negotiable constraints\n6. MUST NOT DO - Hard blocks\n7. CONTEXT - Parent session state\n8. VERIFICATION - How to confirm\n\nSee: `lib/references/delegation-template.md`\n\nUsed by: `/dev-delegate`, `/ds-delegate`\n\n## Failure Recovery Protocol\n\n**After 3 consecutive failures, STOP and escalate:**\n\n1. STOP all further attempts\n2. REVERT to last known working state\n3. DOCUMENT what was attempted and why it failed\n4. CONSULT with user before continuing\n5. ASK USER for direction\n\n**NO EVIDENCE = NOT COMPLETE**\n\nImplemented in: `/dev-debug`, `/dev-implement`\n\n## Environment Context Injection\n\nResearch-heavy skills use current date/time context for:\n- Date range validation\n- Fiscal year calculations\n- API version checking\n- Documentation freshness\n\nSee: `lib/references/skill-metadata.py` - `get_env_context()`\n\nApplied to: `/wrds`, `/lseg-data`, `/gemini-batch`\n\n## Cost Classification System\n\nSkills are classified by cost:\n- **FREE**: Simple operations, no model calls (explore, grep)\n- **CHEAP**: Fast models, simple tasks (profiling, review)\n- **EXPENSIVE**: Complex reasoning, architecture decisions (design, debug after 3 failures)\n\nSee: `lib/references/skill-metadata.py` - `CostLevel`\n\n## Metadata-Driven Prompts\n\nSkills declare metadata in YAML frontmatter:\n```yaml\n---\nname: skill-name\ndescription: \"...\"\ncategory: workflow | domain | phase | utility\ncost: FREE | CHEAP | EXPENSIVE\ntriggers:\n  - domain: \"Feature implementation\"\n    trigger: \"add, implement, create, build\"\nuse_when:\n  - \"Complex multi-file changes\"\navoid_when:\n  - \"Simple single-line fixes\"\n---\n```\n\nParent skills consume metadata to build decision tables dynamically.\n\nSee: `lib/references/skill-metadata.py`\n\n## Pattern References\n\nAll patterns documented in:\n- `lib/references/` - Metadata infrastructure, delegation templates, tool restrictions\n\n## Additional Resources\n\nFor implementation details of oh-my-opencode patterns, see:\n- Plugin-dev skills (hook-development, agent-development, skill-development) - Best practices\n- [obra/superpowers](https://github.com/obra/superpowers) - Behavioral enforcement patterns\n",
        "plugins/tinymist/.claude-plugin/plugin.json": "{\n  \"name\": \"tinymist\",\n  \"version\": \"2.0.0\",\n  \"description\": \"Typst language support with tinymist for compilation, preview, and error checking\",\n  \"author\": {\n    \"name\": \"edwinhu\"\n  },\n  \"license\": \"MIT\",\n  \"keywords\": [\"typst\", \"tinymist\", \"typesetting\"]\n}\n",
        "plugins/tinymist/README.md": "# tinymist\n\nTypst language support for Claude Code using [tinymist](https://github.com/Myriad-Dreamin/tinymist).\n\n## Features\n\n- **Typst Skill**: Comprehensive syntax guidance and best practices\n- **Error Checking**: Auto-diagnose errors via VS Code or tinymist CLI\n- **Visual Inspection**: Export pages as PNG to see rendered output\n- **Compilation**: Build PDFs and start live preview servers\n\n## Prerequisites\n\nInstall tinymist:\n\n```bash\n# Via Homebrew (macOS)\nbrew install tinymist\n\n# Or via cargo\ncargo install tinymist\n```\n\nVerify installation:\n\n```bash\ntinymist --version\n```\n\n## Skills (Claude uses automatically)\n\n| Skill | Description |\n|-------|-------------|\n| `typst` | Typst syntax, templates, and best practices |\n| `check` | Get errors/warnings from VS Code diagnostics or tinymist CLI |\n| `screenshot` | Export page as PNG and view for visual inspection |\n\n## Commands (invoke explicitly)\n\n| Command | Description |\n|---------|-------------|\n| `/tinymist:compile` | Compile Typst file to PDF |\n| `/tinymist:preview` | Start live preview server |\n\n## Usage\n\n### Autonomous Debugging\n\nWhen you ask Claude to fix Typst issues, it will automatically:\n1. Use `check` to get errors from VS Code or tinymist\n2. Use `screenshot` to see the visual output\n3. Apply fixes based on `typst` skill knowledge\n4. Repeat until resolved\n\n### Explicit Commands\n\n```bash\n# Build PDF\n/tinymist:compile doc.typ\n\n# Start live preview\n/tinymist:preview doc.typ\n```\n\n## More Information\n\n- [Typst Documentation](https://typst.app/docs)\n- [tinymist GitHub](https://github.com/Myriad-Dreamin/tinymist)\n- [Typst Packages](https://typst.app/universe)\n",
        "plugins/tinymist/commands/compile.md": "---\ndescription: Compile Typst file to PDF\nargument-hint: [file.typ] [output.pdf]\nallowed-tools: Bash(tinymist:*), Glob, Read\n---\n\nCompile a Typst document to PDF.\n\nAuto-detect the Typst file to compile:\n1. If `$1` is provided and ends with `.typ`, use it as the input file\n2. Otherwise, search for `.typ` files in the current directory using Glob\n3. If multiple files found, list them and ask user to specify\n4. If exactly one file found, use it automatically\n\nDetermine output filename:\n1. If `$2` is provided, use it as the output path\n2. Otherwise, use the input filename with `.pdf` extension\n\nExecute compilation:\n```bash\ntinymist compile <input.typ> <output.pdf>\n```\n\nAfter compilation:\n- Report success with the output file path\n- If errors occur, display the error messages and suggest fixes based on tinymist diagnostics\n- Mention that `/tinymist:preview` can be used for live preview while editing\n",
        "plugins/tinymist/commands/preview.md": "---\ndescription: Start live preview server for Typst document\nargument-hint: [file.typ]\nallowed-tools: Bash(tinymist:*), Glob, Read\n---\n\nStart a live preview server for a Typst document.\n\nAuto-detect the Typst file:\n1. If `$1` is provided and ends with `.typ`, use it as the input file\n2. Otherwise, search for `.typ` files in the current directory using Glob\n3. If multiple files found, list them and ask user to specify\n4. If exactly one file found, use it automatically\n\nStart the preview server:\n```bash\ntinymist preview <input.typ> --open\n```\n\nInform the user:\n- The preview will open in their default browser\n- Changes to the document will automatically refresh the preview\n- The server will continue running until stopped (Ctrl+C)\n- Preview supports both document and slide modes (`--preview-mode slide` for presentations)\n\nIf the user wants to customize the preview:\n- `--partial-rendering true` for better performance on large documents\n- `--invert-colors auto` for dark mode compatibility\n- `--ppi <number>` to adjust resolution (default: 144)\n",
        "plugins/tinymist/skills/check/SKILL.md": "---\nname: check\ndescription: Check Typst files for errors. Use when debugging Typst compilation errors, investigating why a document fails to compile, or when the user mentions errors in their .typ files.\nversion: 1.0.0\n---\n\n# Check Typst Files for Errors\n\nUse this skill to get diagnostics (errors, warnings) from Typst files.\n\n## Error Sources (try in order)\n\n### 1. VS Code Diagnostics (preferred when in VS Code)\n\nIf `mcp__ide__getDiagnostics` is available, use it first:\n- Returns real-time LSP diagnostics from tinymist running in VS Code\n- Includes errors, warnings, and hints with line/column locations\n- No need to save the file first\n\n### 2. Tinymist CLI (fallback)\n\nIf VS Code diagnostics unavailable, run tinymist directly:\n\n```bash\ntinymist compile --check <file.typ> 2>&1\n```\n\nNote: `--check` validates without producing output PDF.\n\n## Auto-detect file\n\n1. If a specific `.typ` file is mentioned, use it\n2. Otherwise, search for `.typ` files in current directory using Glob\n3. If multiple files found, check the most recently modified or ask user\n4. If exactly one file found, use it automatically\n\n## Output format\n\nReport diagnostics clearly:\n- Group by severity (errors first, then warnings)\n- Include file path, line number, column\n- Quote the problematic code if possible\n- Suggest fixes based on the `/typst` skill knowledge\n\n## Common errors and fixes\n\n- “Unknown variable” → Check spelling, ensure `#let` before use\n- “Expected content” → Wrap value in brackets: `[#value]`\n- “Cannot apply” → Check function signature and argument types\n- “Unexpected end” → Check for unclosed brackets `{`, `[`, `(`\n",
        "plugins/tinymist/skills/screenshot/SKILL.md": "---\nname: screenshot\ndescription: Export Typst page as PNG and view it. Use when debugging layout issues, checking visual output, verifying formatting, or when the user wants to see what the document looks like.\nversion: 1.0.0\n---\n\n# Screenshot Typst Document\n\nUse this skill to export a Typst document page as PNG and view it for visual inspection.\n\n## When to use\n\n- Debugging layout or formatting issues\n- Verifying visual output after changes\n- When user asks to “show”, “preview”, or “see” the document\n- After fixing errors, to confirm the fix looks correct\n\n## Auto-detect file\n\n1. If a specific `.typ` file is mentioned, use it\n2. Otherwise, search for `.typ` files in current directory using Glob\n3. If multiple files found, use the most recently modified or ask user\n4. If exactly one file found, use it automatically\n\n## Export screenshot\n\nDefault: page 1 at 144 PPI\n\n```bash\ntinymist compile <input.typ> /tmp/typst-screenshot.png --pages 1 --ppi 144\n```\n\nOptions:\n- `--pages N` - Specific page number (default: 1)\n- `--ppi N` - Resolution (default: 144, use 288 for 2x/retina)\n\n## View the image\n\nAfter successful export, use the Read tool to display the PNG:\n\n```\nRead /tmp/typst-screenshot.png\n```\n\nThis allows visual inspection of the rendered output.\n\n## Testing individual slides from presentations\n\nWhen debugging a specific slide in a presentation that uses a theme (e.g., touying/university-theme), create a temporary test file to isolate the slide:\n\n1. **Create test file in project directory** (required for theme imports):\n   ```bash\n   # Write to output/ or similar directory within the project\n   cat > output/test-slide.typ << 'EOF'\n   #import \"../templates/theme.typ\": *\n\n   #show: university-theme.with(\n     aspect-ratio: \"16-9\",\n     config-info(title: [Test], author: [Test]),\n   )\n\n   #slide[\n   // Paste slide content here\n   ]\n   EOF\n   ```\n\n2. **Compile with project root**:\n   ```bash\n   typst compile --root . output/test-slide.typ /tmp/test-slide.png --ppi 144\n   ```\n\n3. **View the result**:\n   ```\n   Read /tmp/test-slide.png\n   ```\n\n**Important**: The test file must be inside the project directory because Typst cannot access files outside its project root. Writing to `/tmp/` directly won't work if the file imports templates from the project.\n\n## Error handling\n\nIf compilation fails:\n- Report the error messages from tinymist\n- Suggest using the check skill for detailed diagnostics\n- Do NOT attempt to read a non-existent screenshot\n",
        "plugins/tinymist/skills/typst/SKILL.md": "---\nname: typst\ndescription: This skill should be used when the user asks about “typst syntax”, “typst formatting”, “typst templates”, “typst functions”, “typst packages”, “typst tables”, “typst math”, “typst bibliography”, or mentions writing documents in Typst. Provides syntax guidance and best practices for the Typst typesetting language.\nversion: 1.0.0\n---\n\n# Typst Language Guide\n\nTypst is a modern typesetting language designed as an alternative to LaTeX. It combines markup syntax for common formatting with a powerful scripting language for advanced layouts.\n\n## Core Syntax\n\n### Text Formatting\n\n```typst\n*bold text*\n_italic text_\n`inline code`\n```\n\n### Headings\n\n```typst\n= Level 1 Heading\n== Level 2 Heading\n=== Level 3 Heading\n```\n\n### Lists\n\n```typst\n- Unordered item\n- Another item\n  - Nested item\n\n+ Ordered item\n+ Second item\n  + Nested ordered\n```\n\n### Links and References\n\n```typst\n#link(“https://typst.app”)[Typst Website]\n@label-name          // Reference a labeled element\n#ref(<label-name>)   // Alternative reference syntax\n```\n\n## Function Calls\n\nTypst uses `#` to call functions:\n\n```typst\n#image(“photo.png”, width: 50%)\n#table(\n  columns: 3,\n  [Header 1], [Header 2], [Header 3],\n  [Cell 1], [Cell 2], [Cell 3],\n)\n#figure(\n  image(“diagram.svg”),\n  caption: [A diagram showing the architecture],\n)\n```\n\n## Math Mode\n\nInline math uses `$...$`, display math uses `$ ... $` with spaces:\n\n```typst\nThe equation $E = m c^2$ is famous.\n\nDisplay equation:\n$ integral_0^infinity e^(-x^2) dif x = sqrt(pi) / 2 $\n```\n\nCommon math notation:\n- Subscripts: `x_1`, `a_(n+1)`\n- Superscripts: `x^2`, `e^(i pi)`\n- Fractions: `a/b` or `frac(a, b)`\n- Square roots: `sqrt(x)`, `root(3, x)` for cube root\n- Summations: `sum_(i=0)^n`\n- Greek letters: `alpha`, `beta`, `gamma`, `theta`\n\n## Document Structure\n\n### Page Setup\n\n```typst\n#set page(\n  paper: “a4”,\n  margin: (x: 2cm, y: 2.5cm),\n  header: [Document Header],\n  footer: context [Page #counter(page).display()],\n)\n```\n\n### Text Configuration\n\n```typst\n#set text(\n  font: “New Computer Modern”,\n  size: 11pt,\n  lang: “en”,\n)\n\n#set par(\n  justify: true,\n  leading: 0.65em,\n  first-line-indent: 1em,\n)\n```\n\n### Heading Styling\n\n```typst\n#set heading(numbering: “1.1”)\n\n#show heading.where(level: 1): it => {\n  pagebreak(weak: true)\n  text(size: 16pt, weight: “bold”, it)\n}\n```\n\n## Show Rules\n\nTransform elements using show rules:\n\n```typst\n// Style all links\n#show link: set text(fill: blue)\n\n// Custom heading appearance\n#show heading: it => block(\n  fill: luma(230),\n  inset: 8pt,\n  radius: 4pt,\n  it\n)\n\n// Replace text patterns\n#show “TODO”: text(fill: red, weight: “bold”)[TODO]\n```\n\n## Tables\n\n```typst\n#table(\n  columns: (auto, 1fr, 1fr),\n  align: (left, center, right),\n  stroke: 0.5pt,\n  inset: 8pt,\n  fill: (_, row) => if row == 0 { luma(230) },\n\n  [*Name*], [*Value*], [*Unit*],\n  [Length], [42], [cm],\n  [Width], [10], [cm],\n)\n```\n\n## Figures and Captions\n\n```typst\n#figure(\n  image(“chart.png”, width: 80%),\n  caption: [Sales data for Q1 2024],\n) <fig:sales>\n\nAs shown in @fig:sales, sales increased.\n```\n\n## Bibliography\n\n```typst\n// In document\n#bibliography(“refs.bib”, style: “ieee”)\n\n// Citation\n@smith2024 shows that...\n#cite(<smith2024>, form: “prose”)\n```\n\n## Variables and Functions\n\n```typst\n// Variables\n#let title = “My Document”\n#let primary-color = rgb(“#1a73e8”)\n\n// Functions\n#let highlight(body) = box(\n  fill: yellow.lighten(60%),\n  inset: 4pt,\n  radius: 2pt,\n  body\n)\n\nUse like: #highlight[important text]\n```\n\n## Imports and Packages\n\n```typst\n// Import from local file\n#import “template.typ”: conf, author\n\n// Import from Typst Universe package\n#import “@preview/cetz:0.3.4”: canvas, draw\n\n#canvas({\n  draw.circle((0, 0), radius: 1)\n})\n```\n\nPackages are available at [Typst Universe](https://typst.app/universe).\n\n## Common Templates\n\n### Academic Paper\n\n```typst\n#set document(\n  title: “Paper Title”,\n  author: “Author Name”,\n)\n\n#set page(paper: “us-letter”, margin: 1in)\n#set text(font: “Times New Roman”, size: 12pt)\n#set par(justify: true, first-line-indent: 0.5in)\n#set heading(numbering: “1.1”)\n\n#align(center)[\n  #text(size: 14pt, weight: “bold”)[Paper Title]\n\n  Author Name \\\n  Institution \\\n  #link(“mailto:email@example.com”)\n]\n\n#outline()\n\n= Introduction\n...\n```\n\n### Letter\n\n```typst\n#set page(paper: “us-letter”, margin: 1in)\n#set text(size: 11pt)\n\n#align(right)[\n  Your Name \\\n  Your Address \\\n  #datetime.today().display()\n]\n\n#v(1cm)\n\nDear Recipient,\n\n#lorem(50)\n\nSincerely,\n\n#v(1cm)\n\nYour Name\n```\n\n## Control Flow and Scripting\n\n### Conditionals\n\n```typst\n#if condition [\n  Content when true\n] else [\n  Content when false\n]\n\n// Inline conditional\n#text(fill: if important { red } else { black })[Text]\n```\n\n### Loops\n\n```typst\n// For loop over array\n#for item in (1, 2, 3) [\n  Item: #item \\\n]\n\n// For loop with index\n#for (i, item) in items.enumerate() [\n  #(i + 1). #item \\\n]\n\n// While loop (rare, usually use for)\n#let i = 0\n#while i < 3 {\n  [Item #i]\n  i += 1\n}\n```\n\n### Context and State\n\n```typst\n// Access page/document context\n#context {\n  let current-page = counter(page).get().first()\n  [Page #current-page of #counter(page).final().first()]\n}\n\n// State management\n#let note-counter = counter(\"notes\")\n\n#let note(body) = {\n  note-counter.step()\n  super(context note-counter.display())\n  // Store note for later\n}\n```\n\n## Common Patterns\n\n### Two-Column Layout\n\n```typst\n#set page(columns: 2, margin: (x: 1.5cm, y: 2cm))\n\n// Or manual columns\n#columns(2, gutter: 1em)[\n  Left column content.\n  #colbreak()\n  Right column content.\n]\n```\n\n### Boxed Content\n\n```typst\n#box(\n  fill: luma(240),\n  inset: 1em,\n  radius: 4pt,\n  width: 100%,\n)[\n  Important note or callout.\n]\n\n// Reusable callout\n#let callout(title, body) = block(\n  fill: rgb(\"#e8f4f8\"),\n  inset: 1em,\n  radius: 4pt,\n  width: 100%,\n)[\n  #text(weight: \"bold\")[#title] \\\n  #body\n]\n```\n\n### Custom Numbering\n\n```typst\n// Roman numerals for front matter\n#set page(numbering: \"i\")\n\n// Switch to arabic for main content\n#counter(page).update(1)\n#set page(numbering: \"1\")\n\n// Custom format\n#set heading(numbering: (..nums) => {\n  nums.pos().map(str).join(“.”) + ” ”\n})\n```\n\n### Include External Files\n\n```typst\n// Include another Typst file (content)\n#include “chapter1.typ”\n\n// Import functions/variables from file\n#import “utils.typ”: format-date, highlight\n```\n\n## Debugging Tips\n\n### Getting Diagnostics\n\nClaude will automatically use the `check` skill when debugging errors. It will:\n1. Try VS Code diagnostics first (if running in VS Code with tinymist extension)\n2. Fall back to running `tinymist compile --check` directly\n\n### Visual Inspection\n\nClaude will automatically use the `screenshot` skill to view rendered output when debugging layout issues.\n\n### Inspecting Values\n\nUse `#repr(value)` to inspect values during debugging:\n```typst\n#repr(some-variable)  // Shows type and value\n#type(value)          // Shows just the type\n```\n\n### Common Errors and Fixes\n\n- “Unknown variable” → Check spelling, ensure `#let` before use\n- “Expected content” → Wrap value in brackets: `[#value]`\n- “Cannot apply” → Check function signature and argument types\n- “Unexpected end” → Check for unclosed brackets `{`, `[`, `(`\n\n## Skills and Commands\n\n**Skills** (Claude uses automatically):\n- `check` - Get errors and warnings from Typst files\n- `screenshot` - Export page as PNG and view it\n\n**Commands** (invoke explicitly):\n- `/tinymist:compile` - Compile Typst file to PDF\n- `/tinymist:preview` - Start live preview server\n\n## Additional Resources\n\n- [Typst Documentation](https://typst.app/docs)\n- [Typst Universe (Packages)](https://typst.app/universe)\n- [tinymist GitHub](https://github.com/Myriad-Dreamin/tinymist)\n",
        "skills/ai-anti-patterns/SKILL.md": "---\nname: ai-anti-patterns\ndescription: This skill should be used when reviewing AI-generated text, checking for AI writing patterns, detecting undisclosed AI content, or before finalizing any written content. Covers 12 categories of AI writing indicators from Wikipedia's comprehensive guide.\n---\n\n# AI Writing Anti-Patterns\n\nField guide for detecting and revising AI-generated content indicators based on Wikipedia's \"Signs of AI writing\" guide.\n\n## When to Use\n\nInvoke this skill:\n- Before finalizing ANY AI-assisted writing\n- When reviewing text for AI writing indicators\n- When editing content to sound more natural\n- After completing writing tasks (automatic via hooks)\n\n## The Iron Law\n\n**Check every piece of AI-assisted writing against these patterns before submission.**\n\nThis is not optional. AI writing patterns are detectable and undermine credibility.\n\n## Quick Screening Order\n\nStart with the most objective indicators:\n\n| Priority | Section | What to Check |\n|----------|---------|---------------|\n| 1 | ChatGPT Artifacts | `turn0search0`, `oaicite`, `contentReference` |\n| 2 | Citation Problems | Hallucinated DOIs, dead links, non-existent sources |\n| 3 | Prompt Refusals | \"As an AI language model...\", \"I hope this helps\" |\n| 4 | Puffery | \"stands as\", \"plays a vital role\", \"rich tapestry\" |\n| 5 | Structure | Section summaries, \"Despite challenges\", rule of three |\n\n## Critical Patterns to Avoid\n\n### CRITICAL Severity (Immediate Revision Required)\n\nThese patterns are unambiguous AI artifacts:\n\n**ChatGPT-Specific Artifacts:**\n- `turn0search0`, `turn1search2` (internal search references)\n- `oaicite:X` (citation placeholders)\n- `contentReference[oaicite:X]` (unresolved references)\n- JSON attribution blocks in output\n\n**Prompt Refusals:**\n- \"As an AI language model...\"\n- \"I cannot provide...\"\n- \"I hope this helps!\"\n- \"I hope this email finds you well\"\n\n### HIGH Severity (Strong Revision Recommended)\n\n**Puffery and Exaggeration:**\n- \"stands as\" (a testament/example/beacon)\n- \"plays a vital/crucial/pivotal role\"\n- \"rich tapestry of\"\n- \"nestled in/among\"\n- \"it's important to note that\"\n- \"delves into\"\n- \"the landscape of\"\n\n**Promotional Language:**\n- \"groundbreaking\", \"transformative\", \"revolutionary\"\n- \"unparalleled\", \"unprecedented\"\n- \"cutting-edge\", \"state-of-the-art\"\n\n### MEDIUM Severity (Review and Consider)\n\n**Structural Patterns:**\n- Section summaries that repeat the heading\n- \"Despite [challenge], [positive outcome]\" formula\n- Negative parallelisms: \"However... Nevertheless...\"\n- Rule of three: exactly three examples every time\n- Weasel wording: \"some experts say\", \"it is believed\"\n\n**Stylistic Quirks:**\n- Elegant variation (synonym cycling to avoid repetition)\n- False ranges (\"from X to Y\" without real data)\n- Title Case In All Headings\n- Em dash overuse (—)\n- Excessive boldface for emphasis\n\n## How to Revise\n\n### For Puffery\n\n| AI Pattern | Human Alternative |\n|------------|-------------------|\n| \"stands as a testament to\" | \"shows\" or \"demonstrates\" |\n| \"plays a vital role in\" | \"affects\" or just state the effect |\n| \"rich tapestry of\" | describe specifically what it contains |\n| \"nestled in the heart of\" | \"in\" or \"located in\" |\n| \"delves into\" | \"examines\" or \"covers\" |\n\n### For Structure\n\n| AI Pattern | Human Alternative |\n|------------|-------------------|\n| Section summary of heading | Start with substance, not meta-commentary |\n| \"Despite challenges...\" | State the reality directly without formula |\n| Exactly three examples | Use the number that fits: 2, 4, 5, or just 1 |\n| \"It's important to note\" | Just state the important thing |\n\n### For Promotional Language\n\n| AI Pattern | Human Alternative |\n|------------|-------------------|\n| \"groundbreaking\" | describe what it actually does |\n| \"revolutionary\" | compare to what came before |\n| \"cutting-edge\" | specify the technology |\n| \"transformative\" | show the transformation with evidence |\n\n## Reference Files\n\nFor detailed patterns and extensive examples, consult:\n\n| File | Contents |\n|------|----------|\n| `references/_index.md` | Overview and quick screening guide |\n| `references/01-puffery-and-exaggeration.md` | \"Stands as\", superficial analyses |\n| `references/02-promotional-language.md` | \"Rich tapestry\", disclaimers |\n| `references/03-structural-patterns.md` | Section summaries, negative parallelisms |\n| `references/04-stylistic-quirks.md` | Elegant variation, false ranges |\n| `references/05-formatting-and-typography.md` | Boldface, em dashes, emojis |\n| `references/06-communication-patterns.md` | Subject lines, \"I hope this helps\" |\n| `references/07-template-artifacts.md` | Mad Libs patterns, placeholders |\n| `references/08-markup-issues.md` | Markdown vs wikitext confusion |\n| `references/09-chatgpt-specific-artifacts.md` | turn0search, oaicite |\n| `references/10-citation-problems.md` | Hallucinated DOIs, dead links |\n| `references/11-meta-indicators.md` | Abrupt cutoffs, style discrepancies |\n\n## Automatic Detection\n\nThis plugin includes PostToolUse hooks that automatically scan Write/Edit output for anti-patterns. When patterns are detected:\n\n1. Hook emits a warning with specific patterns found\n2. Claude immediately revises the content\n3. Revision removes or replaces flagged patterns\n\nThe hook checks for all CRITICAL and HIGH severity patterns automatically.\n\n## Red Flags - Stop If You Think\n\n| Thought | Why It's Wrong | Do Instead |\n|---------|----------------|------------|\n| \"This sounds professional\" | AI puffery sounds generic, not professional | Use concrete, specific language |\n| \"I'll add emphasis\" | \"Very important\" and bold are AI tells | Let content speak for itself |\n| \"Let me summarize the section\" | Section summaries are formulaic | Start with substance |\n| \"Three examples is a good number\" | Rule of three is an AI pattern | Use the right number for the content |\n\n## Key Principles\n\nFrom Wikipedia's guide:\n\n1. **These are signs, not proof** - Multiple indicators strengthen the case\n2. **Context matters** - Some patterns appear in human writing too\n3. **Focus on deeper issues** - Surface defects point to synthesis and quality problems\n4. **Don't rely on detection tools** - Human judgment required\n\n## Related Skills\n\n- `/writing` - Core writing principles from Elements of Style\n- `/writing-legal` - Legal writing (Phase 2)\n- `/writing-econ` - Economics writing (Phase 2)\n",
        "skills/ai-anti-patterns/references/00-introduction.md": "# Wikipedia: Signs of AI Writing - Introduction\n\n> **Source:** [Wikipedia:Signs of AI writing](https://en.wikipedia.org/wiki/Wikipedia:Signs_of_AI_writing)\n>\n> **This is an advice page from WikiProject AI Cleanup.** This page is not an encyclopedic article, nor one of Wikipedia's policies or guidelines, as it has not been thoroughly vetted by the community.\n\n![A screenshot of ChatGPT reading: \"[header] Legacy & Interpretation [body] The \"Black Hole Edition\" is not just a meme — it's a celebration of grassroots car culture, where ideas are limitless and fun is more important than spec sheets. Whether powered by a rotary engine, a V8 swap, or an imagined fighter jet turbine, the Miata remains the canvas for car enthusiasts worldwide.\"](https://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Mazda_miata_black_hole_edition.jpg/500px-Mazda_miata_black_hole_edition.jpg)\n\nLLMs tend to have an identifiable writing style.\n\n## Purpose and Scope\n\nThis is a list of writing and formatting conventions typical of AI chatbots such as ChatGPT, with real examples taken from Wikipedia articles and drafts. It is meant to act as a field guide to help detect undisclosed AI-generated content on Wikipedia. This list is *descriptive*, not *prescriptive*; it consists of observations, not rules. Advice about formatting or language to avoid in Wikipedia articles can be found in the policies and guidelines and the Manual of Style, but does not belong on this page.\n\n## Important Disclaimers\n\nThis list is *not* a ban on certain words, phrases, or punctuation. No one is taking your em-dashes away or claiming that only AI uses them. Not all text featuring the following indicators is AI-generated, as the large language models that power AI chatbots are trained on human writing, including the writing of Wikipedia editors. This is simply a catalog of very common patterns observed over many thousands of instances of AI-generated text, *specific to Wikipedia.* While some of its advice may be broadly applicable, some signs—particularly those involving punctuation and formatting—may not apply in a non-Wikipedia context.\n\nThe patterns here are also only potential *signs* of a problem, not *the problem itself*. While many of these issues are immediately obvious and easy to fix—e.g., excessive boldface, poor wordsmithing, broken markup, citation style quirks—they can point to less outwardly visible problems that carry much more serious policy risks. If LLM-generated text is polished enough (initially or subsequently tidied up), those surface defects might not be present, but the deeper problems likely will. Please do not merely treat these signs as the problems to be fixed; that could just make detection harder. The actual problems are those deeper concerns, so make sure to address them, either yourself or by flagging them, per the advice at Wikipedia:Large language models § Handling suspected LLM-generated content and Wikipedia:WikiProject AI Cleanup/Guide.\n\n## Speedy Deletion Criteria\n\nThe speedy deletion policy criterion G15 (LLM-generated pages without human review) is limited to the most objective and least contestable indications that the page's content was generated by an LLM. There are three such indicators, the first of which can be found in § Communication intended for the user and the other two in § Citations. The other signs, though they may indeed indicate AI use, are not sufficient for speedy deletion.\n\n## AI Detection Tools\n\nDo not solely rely on artificial intelligence content detection tools (such as GPTZero) to evaluate whether text is LLM-generated. While they perform better than random chance, these tools have nontrivial error rates and cannot replace human judgment.\n\n## Statistical Regression to the Mean\n\nLLMs (and artificial neural networks in general) use statistical algorithms to guess (infer) what should come next based on a large corpus of training material. It thus tends to regress to the mean; that is, the result tends toward the most statistically likely result that applies to the widest variety of cases. It can simultaneously be a strength and a \"tell\" for detecting AI-generated content.\n\nFor example, LLMs are usually trained on data from the internet in which famous people are generally described with positive, important-sounding language. It will thus sand down specific, unusual, nuanced facts (which are statistically rare) and replace them with more generic, positive descriptions (which are statistically common). Thus the specific detail \"invented a train-coupling device\" might become \"a revolutionary titan of industry.\" LLMs tend to smooth out unusual details and drift toward the most common, statistically probable way of describing a topic. It is like shouting louder and louder that a portrait shows a uniquely important person, while the portrait itself is fading from a sharp photograph into a blurry, generic sketch. The subject becomes simultaneously less specific and more exaggerated.\n\nThis statistical regression to the mean, a smoothing over of specific facts into generic statements that could apply to many topics, makes AI-generated content easier to detect.\n",
        "skills/ai-anti-patterns/references/01-puffery-and-exaggeration.md": "# Puffery and Exaggeration\n\n## \"Stands as\" / \"serves as\"\n\n|  | Words to watch: ***stands/serves as / is a testament/reminder*, *plays a vital/significant/crucial role*, *underscores/highlights its importance/significance*, *reflects broader*, *symbolizing its ongoing*, *enduring/lasting impact*, *key turning point*, *indelible mark*, *deeply rooted*, *profound heritage*, *steadfast dedication*...** |\n| --- | --- |\n\nLLM writing often puffs up the importance of the subject matter by adding statements about how arbitrary aspects of the topic represent or contribute to a broader topic.[^8] There is a distinct and easily identifiable repertoire of ways that it writes these statements.[^9] LLMs may include these for even the most mundane of things, sometimes with hedging comments like \"While \\[minor/not well known/etc\\], it \\[symbolizes/stands as/contributes\\]...\"\n\nWhen talking about biology (e.g. when asked to discuss a given animal or plant species), LLMs tend to put too much emphasis on the species' conservation status and the efforts to protect it, even if the status is unknown and no serious efforts exist, and may strain to derive symbolism from things like taxonomy.\n\n**Examples**\n\n> Douera enjoys close proximity to the capital city, Algiers, further ==enhancing its significance== as a dynamic hub of activity and culture. With its coastal charm and convenient location, Douera ==captivates both residents and visitors alike== \\[...\\]\n\n— From [this revision](https://en.wikipedia.org/w/index.php?title=&diff=1161677884&oldid=) to [Douéra](https://en.wikipedia.org/wiki/Dou%C3%A9ra \"Douéra\")\n\n> Berry Hill today ==stands as a symbol== of community resilience, ecological renewal, and historical continuity. Its transformation from a coal-mining hub to a thriving green space ==reflects the evolving identity== of Stoke-on-Trent.\n\n— From [Draft:Berry Hill, Stoke-on-Trent](https://en.wikipedia.org/wiki/Draft:Berry_Hill,_Stoke-on-Trent \"Draft:Berry Hill, Stoke-on-Trent\")\n\n> By preying on these pests, Zagloba species ==play a significant role== in natural pest control, ==contributing to ecological balance== and agricultural health.\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:Diff/1267500649 \"Special:Diff/1267500649\") to [Zagloba (beetle)](https://en.wikipedia.org/wiki/Zagloba_\\(beetle\\) \"Zagloba (beetle)\")\n\n> These citations, spanning more than six decades and appearing in recognized academic publications, ==illustrate Blois' lasting influence in computational linguistics, grammar, and neology.==\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:PermanentLink/1308008350 \"Special:PermanentLink/1308008350\") to [Draft:Jacques Blois (linguist)](https://en.wikipedia.org/wiki/Draft:Jacques_Blois_\\(linguist\\) \"Draft:Jacques Blois (linguist)\")\n\n## Superficial analyses\n\n|  | Words to watch: ***ensuring...*, *highlighting...*, *emphasizing...*, *reflecting...*, *underscoring...*, *showcasing...*, *aligns with...*, *contributing to...*** |\n| --- | --- |\n\nAI chatbots tend to insert superficial analysis of information, often in relation to its significance, recognition, or impact. This is often done by attaching a [present participle](https://en.wikipedia.org/wiki/Participle#Forms \"Participle\") (\"-ing\") phrase at the end of sentences, sometimes with vague attributions to third parties (see below).[^8]\n\nWhile many of these words are strong AI tells on their own,[^9] an even stronger tell is when the subjects of these verbs are facts, events, or other abstract concepts. A person, for example, can highlight or emphasize something, but a fact or event cannot. The \"highlighting\" or \"underscoring\" is not something that is actually happening; it is a claim by a disembodied narrator about what something means.[^8]\n\nSuch comments are usually [synthesis](https://en.wikipedia.org/wiki/Wikipedia:SYNTH \"Wikipedia:SYNTH\") and/or unattributed opinions in wikivoice. Newer chatbots with [retrieval-augmented generation](https://en.wikipedia.org/wiki/Retrieval-augmented_generation \"Retrieval-augmented generation\") may instead attach this language to attributed statements, e.g., \"Critic Roger Ebert praised the film, underscoring the story's impact...\", but since it is still AI-generated text it may be an inaccurate or [subjective representation](https://en.wikipedia.org/wiki/Wikipedia:OR \"Wikipedia:OR\") of what the source actually said.\n\n**Examples**\n\n> In 2025, the Federation was internationally recognized and invited to participate in the Asia Pickleball Summit, ==highlighting Pakistan's entry into the global pickleball community.==\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:Diff/1299294247 \"Special:Diff/1299294247\") to [Draft:Pakistan Pickleball Federation](https://en.wikipedia.org/wiki/Draft:Pakistan_Pickleball_Federation \"Draft:Pakistan Pickleball Federation\")\n\n> The [civil rights movement](https://en.wikipedia.org/wiki/Civil_rights_movement \"Civil rights movement\") emerged as a powerful continuation of this struggle, ==emphasizing the importance of solidarity and collective action in the fight for justice==.\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:PermanentLink/1299132059 \"Special:PermanentLink/1299132059\") to [African-American culture](https://en.wikipedia.org/wiki/African-American_culture \"African-American culture\")\n\n> These partnerships ==reflect the company's role== in serving both corporate and community organizations in Uganda.\n\n— From [Draft:GEOWISE MEDIA](https://en.wikipedia.org/wiki/Draft:GEOWISE_MEDIA \"Draft:GEOWISE MEDIA\")\n\n[^8]: [\"10 Ways AI Is Ruining Your Students' Writing\"](https://www.chronicle.com/article/10-ways-ai-is-ruining-your-students-writing). *Chronicle of Higher Education*. September 16, 2025.\n\n[^9]: Juzek, Tom S.; Ward, Zina B. (2025). [*Why Does ChatGPT \"Delve\" So Much? Exploring the Sources of Lexical Overrepresentation in Large Language Models*](https://aclanthology.org/2025.coling-main.426.pdf) (PDF). Findings of the Association for Computational Linguistics: ACL 2025. [Association for Computational Linguistics](https://en.wikipedia.org/wiki/Association_for_Computational_Linguistics \"Association for Computational Linguistics\"). [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv (identifier)\"):[2412.11385](https://arxiv.org/abs/2412.11385). Retrieved October 13, 2025 – via [ACL Anthology](https://en.wikipedia.org/wiki/ACL_Anthology \"ACL Anthology\").\n",
        "skills/ai-anti-patterns/references/02-promotional-language.md": "# Promotional Language\n\n## Promotional language\n\n|  | Words to watch: ***rich/vibrant tapestry*, *artistic/cultural/literary/media/etc. landscape*, *boasts a*, *continues to captivate*, *groundbreaking*, *intricate*, *stunning natural beauty*, *enduring/lasting legacy*, *nestled*, *in the heart of*...** |\n| --- | --- |\n\nLLMs have serious problems keeping a neutral tone, especially when writing about something that could be considered \"cultural heritage\"—in which case they will constantly remind the reader that it is cultural heritage.\n\n**Examples**\n\n> Nestled within the ==breathtaking== region of Gonder in Ethiopia, Alamata Raya Kobo ==stands as a vibrant town== with a ==rich cultural heritage and a significant place== within the Amhara region. From its ==scenic landscapes== to its ==historical landmarks==, Alamata Raya Kobo offers visitors a ==fascinating glimpse== into the ==diverse tapestry== of Ethiopia. In this article, we will explore the ==unique characteristics== that make Alamata Raya Kobo ==a town worth visiting== and shed light on ==its significance== within the Amhara region.\n\n— From [this revision](https://en.wikipedia.org/w/index.php?title=&diff=1162718043&oldid=) to [Alamata (woreda)](https://en.wikipedia.org/wiki/Alamata_\\(woreda\\) \"Alamata (woreda)\")\n\n> TTDC ==acts as the gateway== to Tamil Nadu's ==diverse attractions==, seamlessly connecting the beginning and end of ==every traveller's journey==. It offers ==dependable, value-driven experiences== that showcase the state's ==rich history, spiritual heritage, and natural beauty==.\n\n— From [this revision](https://en.wikipedia.org/w/index.php?title=&diff=1299567515&oldid=) to [Tamil Nadu Tourism Development Corporation](https://en.wikipedia.org/wiki/Tamil_Nadu_Tourism_Development_Corporation \"Tamil Nadu Tourism Development Corporation\")\n\n|  | Words to watch: ***it's important to note/remember/consider*, *may vary*...** |\n| --- | --- |\n\nLLMs often tell the reader about things \"it's important to remember.\" This frequently happens in the context of \"disclaimers\" to an imagined reader, often regarding safety or topics that vary in different locales/jurisdictions. It seems to be more common in text by older (pre-2025) chatbots.\n\n**Examples**\n\n> The emergence of these informal groups reflects a growing recognition of the interconnected nature of urban issues and the potential for ANCs to play a role in shaping citywide policies. ==However, it's important to note ==that these caucuses operate outside the formal ANC structure and their influence on policy decisions ==may vary==.====\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:Diff/1265416814 \"Special:Diff/1265416814\") to [Advisory Neighborhood Commission](https://en.wikipedia.org/wiki/Advisory_Neighborhood_Commission \"Advisory Neighborhood Commission\")\n\n> Although the [National Medical Commission](https://en.wikipedia.org/wiki/National_Medical_Commission \"National Medical Commission\") had deemed conversion therapy as 'professional misconduct' in response to a directive from the [Madras High Court](https://en.wikipedia.org/wiki/Madras_High_Court \"Madras High Court\") in the case of [S Sushma v. Commissioner of Police](https://en.wikipedia.org/wiki/S_Sushma_v._Commissioner_of_Police \"S Sushma v. Commissioner of Police\"), ==it's important to note== that [AYUSH](https://en.wikipedia.org/wiki/AYUSH \"AYUSH\") practitioners, who practice alternative medicine systems like Ayurveda, Yoga, Unani, Siddha, and Homeopathy, remain unregulated by the National Medical Commission.\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:Diff/1170828331 \"Special:Diff/1170828331\") to [Adhila Nasarin v. State Commissioner of Police](https://en.wikipedia.org/wiki/Adhila_Nasarin_v._State_Commissioner_of_Police \"Adhila Nasarin v. State Commissioner of Police\")\n\n> ==It's important to remember== that what's free in one country might not be free in another, so always check before you use something.\n\n— From [Wikimedia's LLM-generated Simple Summary](https://gitlab.wikimedia.org/repos/web/web-experiments-extension/-/commit/55fdbbb3decdc9b95ae0ef00e98b1108ddc3a498.diff) of [Public domain](https://en.wikipedia.org/wiki/Public_domain \"Public domain\")\n",
        "skills/ai-anti-patterns/references/03-structural-patterns.md": "# Structural Patterns\n\n## Section summaries\n\n|  | Words to watch: ***In summary*, *In conclusion*, *Overall*...** |\n| --- | --- |\n\nWhen generating longer outputs (such as when told to \"write an article\"), LLMs often add a section titled \"Conclusion\" or similar, and will often end a paragraph or section by summarizing and restating its core idea.[^10]\n\n**Examples**\n\n> ==In summary==, the educational and training trajectory for nurse scientists typically involves a progression from a master's degree in nursing to a Doctor of Philosophy in Nursing, followed by postdoctoral training in nursing research. This structured pathway ensures that nurse scientists acquire the necessary knowledge and skills to engage in rigorous research and contribute meaningfully to the advancement of nursing science.\n\n— From [this revision](https://en.wikipedia.org/w/index.php?title=&diff=1188230584&oldid=) in [Nurse scientist](https://en.wikipedia.org/wiki/Nurse_scientist \"Nurse scientist\")\n\n|  | Words to watch: ***Despite its... faces several challenges...*, *Despite these challenges*, *Challenges and Legacy*, *Future Outlook*...** |\n| --- | --- |\n\nMany LLM-generated Wikipedia articles include a \"Challenges\" section, which typically begins with a sentence like \"Despite its \\[positive/promotional words\\], \\[article subject\\] faces challenges...\" and ends with either a vaguely positive assessment of the article subject [^6], or speculation about how ongoing or potential initiatives could benefit the subject. Such paragraphs usually appear at the end of articles with a rigid outline structure, which may also include a separate section for \"Future Prospects.\"\n\nNote: This sign is about the rigid formula, not simply the mention of challenges.\n\n**Examples**\n\n> ==Despite its industrial and residential prosperity, Korattur faces challenges== typical of urban areas, including\\[...\\] With its ==strategic location and ongoing initiatives==, Korattur ==continues to thrive== as an integral part of the Ambattur industrial zone, embodying the synergy between industry and residential living.\n\n— From [this revision](https://en.wikipedia.org/w/index.php?title=&diff=1218690551&oldid=) to [Korattur](https://en.wikipedia.org/wiki/Korattur \"Korattur\")\n\n> ==Despite its success, the Panama Canal faces challenges==, including\\[...\\] ==Future investments in technology, such as automated navigation systems, and potential further expansions could enhance the canal's efficiency== and maintain its relevance in global trade.\n\n— From [this revision](https://en.wikipedia.org/w/index.php?title=&diff=1279428086&oldid=) to [Panama Canal](https://en.wikipedia.org/wiki/Panama_Canal \"Panama Canal\")\n\n> ==Despite their promising applications, pyroelectric materials face several challenges== that must be addressed for broader adoption. One key limitation is\\[...\\] ==Despite these challenges==, the versatility of pyroelectric materials ==positions them as critical components== for sustainable energy solutions and next-generation sensor technologies.\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:Diff/1277706730 \"Special:Diff/1277706730\") to [Pyroelectricity](https://en.wikipedia.org/wiki/Pyroelectricity \"Pyroelectricity\")\n\n> The future of hydrocarbon economies ==faces several challenges,== including\\[...\\] This section would speculate on ==potential developments== and the changing landscape of global energy.\n\n— From [this revision](https://en.wikipedia.org/w/index.php?title=&diff=1201557771&oldid=) to [Hydrocarbon economy](https://en.wikipedia.org/wiki/Hydrocarbon_economy \"Hydrocarbon economy\")\n\n> Operating in the current Afghan media environment ==presents numerous challenges,== including\\[...\\] ==Despite these challenges,== Amu TV has managed to ==continue to provide a vital service== to the Afghan population.\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:Diff/1241301672 \"Special:Diff/1241301672\") to [Amu Television](https://en.wikipedia.org/wiki/Amu_Television \"Amu Television\")\n\n> For example, while the methodology supports transdisciplinary collaboration in principle, applying it effectively in large, heterogeneous teams ==can be challenging.== \\[...\\] SCE continues to evolve ==in response to these challenges.==\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:Diff/1297629115 \"Special:Diff/1297629115\") to [Draft:Socio-cognitive engineering](https://en.wikipedia.org/wiki/Draft:Socio-cognitive_engineering \"Draft:Socio-cognitive engineering\")\n\n## Negative parallelisms\n\nParallel constructions involving \"not\", \"but\", or \"however\" such as \" Not only... but...\" or \" It is not just about..., it's...\" are common in LLM writing but are often unsuitable for writing in a neutral tone.[^6]\n\n**Examples**\n\n> **Self-Portrait** by Yayoi Kusama, executed in 2010 and currently preserved in the famous Uffizi Gallery in Florence, constitutes ==not only== a work of self-representation, ==but== a visual document of her obsessions, visual strategies and psychobiographical narratives.\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:Diff/1288184349 \"Special:Diff/1288184349\") to [Self-portrait (Yayoi Kusama)](https://en.wikipedia.org/wiki/Self-portrait_\\(Yayoi_Kusama\\) \"Self-portrait (Yayoi Kusama)\")\n\n> It's ==not just about== the beat riding under the vocals; ==it's== part of the aggression and atmosphere.\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:Diff/1291259591 \"Special:Diff/1291259591\") to [Draft:Critikal! The Rapper](https://en.wikipedia.org/wiki/Draft:Critikal!_The_Rapper \"Draft:Critikal! The Rapper\")\n\nHere is an example of a negative parallelism across multiple sentences:\n\n> He hailed from the esteemed Duse family, renowned for their theatrical legacy. Eugenio's life, however, took a path that intertwined both personal ambition and familial complexities.\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:Diff/1284729136 \"Special:Diff/1284729136\") to [Eugenio Duse](https://en.wikipedia.org/wiki/Eugenio_Duse \"Eugenio Duse\")\n\nOn rare occasions, user messages that appear AI-generated may also include phrases that read along the lines of \" no..., no..., just...\".\n\n**Examples**\n\n> There are ==no== long-form profiles. ==No== editorial insights. ==No== coverage of her game dev career. ==No== notable accolades. ==Just== TikTok recaps and callouts.\n>\n> ---\n>\n> This page should be gone, fully, cleanly, and without delay. ==No== redirect. ==No== merge. ==Just== delete.\n\n— From [Wikipedia:Articles for deletion/Lilly Contino](https://en.wikipedia.org/wiki/Wikipedia:Articles_for_deletion/Lilly_Contino \"Wikipedia:Articles for deletion/Lilly Contino\")\n\n> I'm hitting the reset button — ==no== hard feelings, ==no== drama — ==just== clean, policy-based engagement from here on out.\n\n— From [this user talk page message](https://en.wikipedia.org/wiki/User_talk:Fram/Archive_43#Reset \"User talk:Fram/Archive 43\")\n\nLLMs overuse the ' [rule of three](https://en.wikipedia.org/wiki/Rule_of_three_\\(writing\\) \"Rule of three (writing)\") '—\"the good, the bad, and the ugly\". This can take different forms from \"adjective, adjective, adjective\" to \"short phrase, short phrase, and short phrase\".[^6] LLMs often use this structure to make [superficial analyses](https://en.wikipedia.org/wiki/#Superficial_analyses) appear more comprehensive.\n\n**Examples**\n\n> The Amaze Conference brings together ==global SEO professionals, marketing experts, and growth hackers== to discuss the latest trends in digital marketing. The event features ==keynote sessions, panel discussions, and networking opportunities==.\n\n— From [Draft:Amaze Conference](https://en.wikipedia.org/wiki/Draft:Amaze_Conference \"Draft:Amaze Conference\")\n\n|  | Words to watch: ***Industry reports*, *Observers have cited*, *Some critics argue*...** |\n| --- | --- |\n\nAI chatbots tend to attribute opinions or claims to some vague authority—a practice called [weasel wording](https://en.wikipedia.org/wiki/Weasel_wording \"Weasel wording\") —while citing only one or two sources that may or may not actually express such view. They also tend to overgeneralize a perspective of one or few sources into that of a wider group.\n\n**Examples**\n\nHere, the weasel wording implies the opinion comes from an independent source, but it actually cites Nick Ford's own website.\n\n> His \\[Nick Ford's\\] compositions ==have been described== as exploring conceptual themes and bridging the gaps between artistic media.[^1]\n\n—  [Draft:Nick Ford (musician)](https://en.wikipedia.org/wiki/Draft:Nick_Ford_\\(musician\\) \"Draft:Nick Ford (musician)\")\n\n> Due to its unique characteristics, the Haolai River is of interest to ==researchers and conservationists==. Efforts are ongoing to monitor its ecological health and preserve the surrounding grassland environment, which is part of a larger initiative to protect China's semi-arid ecosystems from degradation.\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:PermanentLink/1295362066 \"Special:PermanentLink/1295362066\") to [Haolai River](https://en.wikipedia.org/wiki/Haolai_River \"Haolai River\")\n\n[^1]: [\"About\"](https://www.nickfordmusic.com/About). *Nick Ford*. Retrieved 2025-06-25.\n\n[^6]: Russell, Jenna; Karpinska, Marzena; Iyyer, Mohit (2025). [*People who frequently use ChatGPT for writing tasks are accurate and robust detectors of AI-generated text*](https://aclanthology.org/2025.acl-long.267/). Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Vienna, Austria: Association for Computational Linguistics. pp. 5342– 5373. [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv (identifier)\"):[2501.15654](https://arxiv.org/abs/2501.15654). [doi](https://en.wikipedia.org/wiki/Doi_\\(identifier\\) \"Doi (identifier)\"):[10.18653/v1/2025.acl-long.267](https://doi.org/10.18653%2Fv1%2F2025.acl-long.267). Retrieved 2025-09-05 – via [ACL Anthology](https://en.wikipedia.org/wiki/ACL_Anthology \"ACL Anthology\").\n\n[^10]: Ju, Da; Blix, Hagen; Williams, Adina (2025). [*Domain Regeneration: How well do LLMs match syntactic properties of text domains?*](https://aclanthology.org/2025.findings-acl.120). Findings of the Association for Computational Linguistics: ACL 2025. Vienna, Austria: [Association for Computational Linguistics](https://en.wikipedia.org/wiki/Association_for_Computational_Linguistics \"Association for Computational Linguistics\"). pp. 2367– 2388. [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv (identifier)\"):[2505.07784](https://arxiv.org/abs/2505.07784). [doi](https://en.wikipedia.org/wiki/Doi_\\(identifier\\) \"Doi (identifier)\"):[10.18653/v1/2025.findings-acl.120](https://doi.org/10.18653%2Fv1%2F2025.findings-acl.120). Retrieved October 4, 2025 – via [ACL Anthology](https://en.wikipedia.org/wiki/ACL_Anthology \"ACL Anthology\").\n",
        "skills/ai-anti-patterns/references/04-stylistic-quirks.md": "# Stylistic Quirks\n\n## Elegant variation\n\nGenerative AI has a repetition-penalty code, meant to discourage it from reusing words too often.[^8] For instance, the output might give a main character's name and then repeatedly use a different synonym or related term (e.g., protagonist, key player, eponymous character) when mentioning it again.\n\nNote: If a user adds multiple pieces of AI-generated content in separate edits, this tell may not apply, as each piece of text may have been generated in isolation.\n\n**Examples**\n\n> Vierny, after a visit in Moscow in the early 1970's, committed to supporting artists resisting ==the constraints of socialist realism== and discovered Yankilevskly, among others such as Ilya Kabakov and Erik Bulatov. In ==the challenging climate of Soviet artistic constraints==, Yankilevsky, alongside other ==non-conformist artists==, faced obstacles in expressing ==their creativity== freely. Dina Vierny, recognizing ==the immense talent== and the struggle ==these artists== endured, played a pivotal role in aiding ==their artistic aspirations==. \\[...\\]\n>\n> In this new chapter of his life, Yankilevsky found himself amidst a community of ==like-minded artists== who, despite diverse styles, shared a common goal—to break free from ==the confines of state-imposed artistic norms==, particularly socialist realism. \\[...\\]\n>\n> The move to Paris facilitated an environment where Yankilevsky could further explore and exhibit ==his distinctive artistic vision== without ==the constraints imposed by the Soviet regime==. Dina Vierny's unwavering support and commitment to the ==Russian avant-garde artists== played a crucial role in fostering a space where ==their creativity== could flourish, contributing to the rich tapestry of artistic expression in the vibrant cultural landscape of Paris. Vierny's commitment culminated in the groundbreaking exhibition \"Russian Avant-Garde - Moscow 1973\" at her Saint-Germain-des-Prés gallery, showcasing the ==diverse yet united front of non-conformist artists== challenging ==the artistic norms== of their time.\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:Diff/1205035512 \"Special:Diff/1205035512\") to [Vladimir Yankilevsky](https://en.wikipedia.org/wiki/Vladimir_Yankilevsky \"Vladimir Yankilevsky\")\n\n## False ranges\n\nWhen from... to... constructions are not used figuratively, they are used to indicate the lower and upper bounds of a scale. The scale is either quantitative, involving an explicit or implicit numerical range (e.g. from 1990 to 2000, from 15 to 20 ounces, from winter to autumn), or qualitative, involving categorical bounds (e.g. \" from seed to tree \", \" from mild to severe \", \" from white belt to black belt \"). The same constructions may be used to form a [merism](https://en.wikipedia.org/wiki/Merism \"Merism\") —a figure of speech that combines the two extremes as two contrasting parts of the whole to refer to the whole. This is a figurative meaning, but it has the same structure as the non-figurative usage, because it still requires an identifiable scale: from head to toe (the length of a body denoting the whole body), [from soup to nuts](https://en.wiktionary.org/wiki/from_soup_to_nuts \"wikt:from soup to nuts\") (clearly based on time), etc. This is *not* a false range.\n\nLLMs really like mixing it up, such as when giving examples of items within a set (instead of simply mentioning them one after another). An important consideration is whether some middle ground can be identified without changing the endpoints. If the middle requires switching from one scale to another scale, or there is no scale to begin with or a coherent whole that could be conceived, the construction is a **false range**. LLMs often employ \"figurative\" (often simply: meaningless) \" from... to...\" constructions that purport to signify a scale, while the endpoints are loosely related or essentially unrelated things and no meaningful scale can be inferred. LLMs do this because such meaningless language is used in persuasive writing to impress and woo, and LLMs are heavily influenced by materials consisting of persuasive writing during their training.\n\n**Examples**\n\n> Our journey through the universe has taken us ==from== the singularity of the Big Bang ==to== the grand cosmic web, ==from== the birth and death of stars that forge the elements of life, ==to== the enigmatic dance of dark matter and dark energy that shape its destiny.\n>\n> \\[...\\]\n>\n> Intelligence and Creativity: ==From== problem-solving and tool-making ==to== scientific discovery, artistic expression, and technological innovation, human intelligence is characterized by its adaptability and capacity for novel solutions.\n>\n> \\[...\\]\n>\n> Continued Scientific Discovery: The quest to understand the universe, life, and ourselves will continue to drive scientific breakthroughs, ==from== fundamental physics ==to== medicine and neuroscience.\n\n— From [Draft:The Cosmos Unveiled: A Grand Tapestry of Existence](https://en.wikipedia.org/wiki/Draft:The_Cosmos_Unveiled:_A_Grand_Tapestry_of_Existence \"Draft:The Cosmos Unveiled: A Grand Tapestry of Existence\")\n\n## Title case\n\nIn section headings, AI chatbots strongly tend to consistently capitalize all main words ([title case](https://en.wikipedia.org/wiki/Title_case \"Title case\")).[^6]\n\n**Examples**\n\n> Thomas was born in Cochranville, Pennsylvania. \\[...\\]\n>\n> Thomas's behavioral profiling has been used to evaluate Kentucky Derby \\[...\\]\n>\n> Global Consulting\n>\n> Thomas's behavioral profiling has been used to evaluate Kentucky Derby and Breeders' Cup contenders. \\[...\\]\n>\n> In July 2025, Thomas was invited as a featured presenter to the Second Horse Economic Forum \\[...\\]\n>\n> Educational Programs\n>\n> Thomas is the founder of the Institute for Advanced Equine Studies \\[...\\]\n\n— From [Draft:Kerry M. Thomas](https://en.wikipedia.org/wiki/Draft:Kerry_M._Thomas \"Draft:Kerry M. Thomas\")\n\n[^6]: Russell, Jenna; Karpinska, Marzena; Iyyer, Mohit (2025). [*People who frequently use ChatGPT for writing tasks are accurate and robust detectors of AI-generated text*](https://aclanthology.org/2025.acl-long.267/). Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Vienna, Austria: Association for Computational Linguistics. pp. 5342– 5373. [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv (identifier)\"):[2501.15654](https://arxiv.org/abs/2501.15654). [doi](https://en.wikipedia.org/wiki/Doi_\\(identifier\\) \"Doi (identifier)\"):[10.18653/v1/2025.acl-long.267](https://doi.org/10.18653%2Fv1%2F2025.acl-long.267). Retrieved 2025-09-05 – via [ACL Anthology](https://en.wikipedia.org/wiki/ACL_Anthology \"ACL Anthology\").\n\n[^8]: [\"10 Ways AI Is Ruining Your Students' Writing\"](https://www.chronicle.com/article/10-ways-ai-is-ruining-your-students-writing). *Chronicle of Higher Education*. September 16, 2025.\n",
        "skills/ai-anti-patterns/references/05-formatting-and-typography.md": "# Formatting and Typography\n\n## Excessive use of boldface\n\nAI chatbots may display various phrases in [boldface](https://en.wikipedia.org/wiki/Boldface \"Boldface\") for emphasis in an excessive, mechanical manner. One of their tendencies, inherited from readmes, fan wikis, how-tos, sales pitches, slide decks, listicles and other materials that heavily use boldface, is to emphasize every instance of a chosen word or phrase, often in a \"key takeaways\" fashion. Some newer large language models or apps have instructions to avoid overuse of boldface.\n\n**Examples**\n\n> It blends **OKRs (Objectives and Key Results)**, **KPIs (Key Performance Indicators)**, and visual strategy tools such as the **Business Model Canvas (BMC)** and **Balanced Scorecard (BSC)**. OPC is designed to bridge the gap between strategy and execution by fostering a unified mindset and shared direction within organizations.\n\n— From [Draft:One Page 4 Change (OPC)](https://en.wikipedia.org/wiki/Draft:One_Page_4_Change_\\(OPC\\) \"Draft:One Page 4 Change (OPC)\")\n\n## Inline-header vertical lists\n\nAI chatbots' content often includes vertical lists. A particular list formatting is employed: It comprises an ordered or unordered list where the list marker (number, bullet, dash, etc.) is followed by an inline boldfaced header of sorts; a colon then separates it from the remaining descriptive text. (Separately from this sign, this is one of the things which cause overabundant boldfacing; see [§ Excessive use of boldface](https://en.wikipedia.org/wiki/#Excessive_use_of_boldface))\n\nInstead of [proper wikitext](https://en.wikipedia.org/wiki/H:LIST \"H:LIST\"), a bullet point in an unordered list may appear as a bullet character (•), hyphen (-), en dash (–), or similar character. Ordered lists (i.e. numbered lists) may use explicit numbers (such as `1.`) instead of standard wikitext. When [copied as bare text appearing on the screen](https://en.wikipedia.org/wiki/Wikipedia:SCOPY \"Wikipedia:SCOPY\"), some of the formatting information is lost, and line breaks may be lost as well.\n\n**Examples**\n\n> 1\\. Historical Context Post-WWII Era: The world was rapidly changing after WWII, \\[...\\] 2. Nuclear Arms Race: Following the U.S. atomic bombings, the Soviet Union detonated its first bomb in 1949, \\[...\\] 3. Key Figures Edward Teller: A Hungarian physicist who advocated for the development of more powerful nuclear weapons, \\[...\\] 4. Technical Details of Sundial Hydrogen Bomb: The design of Sundial involved a hydrogen bomb \\[...\\] 5. Destructive Potential: If detonated, Sundial would create a fireball up to 50 kilometers in diameter, \\[...\\] 6. Consequences and Reactions Global Impact: The explosion would lead to an apocalyptic nuclear winter, \\[...\\] 7. Political Reactions: The U.S. military and scientists expressed horror at the implications of such a weapon, \\[...\\] 8. Modern Implications Current Nuclear Arsenal: Today, there are approximately 12,000 nuclear weapons worldwide, \\[...\\] 9. Key Takeaways Understanding the Madness: The concept of Project Sundial highlights the extremes of human ingenuity \\[...\\] 10. Questions to Consider What were the motivations behind the development of Project Sundial? \\[...\\]\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:PermanentLink/1255717748 \"Special:PermanentLink/1255717748\") to [Sundial (weapon)](https://en.wikipedia.org/wiki/Sundial_\\(weapon\\) \"Sundial (weapon)\")\n\n## Emojis\n\nSometimes, AI chatbots decorate section headings or bullet points by placing [emojis](https://en.wikipedia.org/wiki/Emoji \"Emoji\") in front of them.\n\n**Examples**\n\n> Let's decode exactly what's happening here:\n> 🧠 Cognitive Dissonance Pattern:\n> You've proven authorship, demonstrated originality, and introduced new frameworks, yet they're defending a system that explicitly disallows recognition of originators unless a third party writes about them first.\n> \\[...\\]\n> 🧱 Structural Gatekeeping:\n> Wikipedia policy favors:\n> \\[...\\]\n> 🚨 Underlying Motivation:\n> Why would a human fight you on this?\n> \\[...\\]\n> 🧭 What You're Actually Dealing With:\n> This is not a debate about rules.\n> \\[...\\]\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:Diff/1292160296 \"Special:Diff/1292160296\") to [Wikipedia:Village pump (policy)](https://en.wikipedia.org/wiki/Wikipedia:Village_pump_\\(policy\\) \"Wikipedia:Village pump (policy)\")\n\n> 🪷 Traditional Sanskrit Name: Trikoṇamiti\n> Tri = Three\n> Koṇa = Angle\n> Miti = Measurement 🧭 \"Measurement of three angles\" — the ancient Indian art of triangle and angle mathematics.\n> 🕰️ 1. Vedic Era (c. 1200 BCE – 500 BCE)\n> \\[...\\]\n> 🔭 2. Sine of the Bow: Sanskrit Terminology\n> \\[...\\]\n> 🌕 3. Āryabhaṭa (476 CE)\n> \\[...\\]\n> 🌀 4. Varāhamihira (6th Century CE)\n> \\[...\\]\n> 🌠 5. Bhāskarācārya II (12th Century CE)\n> \\[...\\]\n> 📤 Indian Legacy Spreads\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:Diff/1302443439/1303522049 \"Special:Diff/1302443439/1303522049\") to [History of trigonometry](https://en.wikipedia.org/wiki/History_of_trigonometry \"History of trigonometry\")\n\n## Em dashes\n\nWhile human editors and writers often do use [em dashes](https://en.wikipedia.org/wiki/Em_dash \"Em dash\") (—), LLM output tends to use them more often than nonprofessional human-written text of the same genre, and uses them in places where humans are more likely to use commas, parentheses, colons, or (misused) hyphens (-). LLMs especially tend to use em dashes in a formulaic, pat way, often mimicking \"punched up\" sales-like writing by over-emphasizing clauses or parallelisms. LLMs overuse em dashes because they were trained (sometimes illegally) on novels, and novelists have always used em dashes more often than is typical of a layperson.\n\nThis sign is most useful when taken in combination with other indicators, not by itself.\n\n**Examples**\n\n> Elwandore is a virtual micronation for people with passion and skill — a place to build, to create, and to help each other grow while chasing wealth. But not wealth for greed — wealth to give, to help others, to donate.\n\n— From [this version](https://en.wikipedia.org/w/index.php?title=1293560598&oldid=) of [Draft:United Digital Republic Of Elwandore](https://en.wikipedia.org/wiki/Draft:United_Digital_Republic_Of_Elwandore \"Draft:United Digital Republic Of Elwandore\")\n\n> The term \"Dutch Caribbean\" is **not used in the statute** and is primarily promoted by **Dutch institutions**, not by the **people of the autonomous countries** themselves. In practice, many Dutch organizations and businesses use it for **their own convenience**, even placing it in addresses — e.g., \"Curaçao, Dutch Caribbean\" — but this only **adds confusion** internationally and **erases national identity**. You don't say **\"Netherlands, Europe\"** as an address — yet this kind of mislabeling continues.\n\n— From [this revision](https://en.wikipedia.org/w/index.php?title=&diff=1286082047&oldid=) to [Talk:Dutch Caribbean](https://en.wikipedia.org/wiki/Talk:Dutch_Caribbean \"Talk:Dutch Caribbean\")\n\n",
        "skills/ai-anti-patterns/references/06-communication-patterns.md": "# Communication Patterns\n\n## Subject lines\n\nUser messages and [unblock requests](https://en.wikipedia.org/wiki/Wikipedia:Identifying_LLM_unblock_requests \"Wikipedia:Identifying LLM unblock requests\") generated by AI chatbots sometimes begin with text that is intended to be pasted into the *Subject* field on an email form.\n\n**Examples**\n\n> Subject: Request for Permission to Edit Wikipedia Article - \"Dog\"\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:Diff/1210351576 \"Special:Diff/1210351576\") to [Talk:Dog](https://en.wikipedia.org/wiki/Talk:Dog \"Talk:Dog\")\n\n> Subject: Request for Review and Clarification Regarding Draft Article\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:Diff/1256545561 \"Special:Diff/1256545561\") to [Wikipedia:WikiProject Articles for creation/Help desk](https://en.wikipedia.org/wiki/Wikipedia:WikiProject_Articles_for_creation/Help_desk \"Wikipedia:WikiProject Articles for creation/Help desk\")\n\n## Collaborative communication\n\n|  | Words to watch: ***I hope this helps*, *Of course!*, *Certainly!*, *You're absolutely right!*, *Would you like...*, *is there anything else*, *let me know*, *more detailed breakdown*, *here is a*...** |\n| --- | --- |\n\nIn some cases, editors will paste text from an AI chatbot that was meant as correspondence, prewriting or advice by the chatbot, rather than article content. AI chatbots may also explicitly indicate that the text is for a Wikipedia article if prompted to produce one, and may mention various [policies and guidelines](https://en.wikipedia.org/wiki/Wikipedia:PG \"Wikipedia:PG\") in their outputs—often explicitly specifying that they're *Wikipedia* 's conventions.\n\n**Examples**\n\n> This fictional article combines the tone of a Wikipedia article and the creative elements you requested, including the announcement date, release date, new cast, and crew for the sequel. Let me know if you'd like it expanded or tailored further!\n\n— From [Draft:A Knight's Tale: The Legend Continues](https://en.wikipedia.org/wiki/Draft:A_Knight%27s_Tale:_The_Legend_Continues \"Draft:A Knight's Tale: The Legend Continues\")\n\n> Certainly. Here's a draft Wikipedia-style article for Mark Biram, written in a neutral, encyclopedic tone and formatted according to Wikipedia conventions. This assumes notability is supported by independent sources (which would need to be cited for a real Wikipedia page):\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:PermanentLink/1299612408 \"Special:PermanentLink/1299612408\") to [Draft:Mark Biram](https://en.wikipedia.org/wiki/Draft:Mark_Biram \"Draft:Mark Biram\")\n\n> Final important tip: The ~~~~ at the very end is Wikipedia markup that automatically\n\n— Adapted from [this revision](https://en.wikipedia.org/w/index.php?title=&diff=1297191187&oldid=) to [Talk:Test automation management tools](https://en.wikipedia.org/wiki/Talk:Test_automation_management_tools \"Talk:Test automation management tools\"); the message also [ends unexpectedly](https://en.wikipedia.org/wiki/#Abrupt_cut_offs)\n\n> In this section, we will discuss the background information related to the topic of the report. This will include a discussion of relevant literature, previous research, and any theoretical frameworks or concepts that underpin the study. The purpose is to provide a comprehensive understanding of the subject matter and to inform the reader about the existing knowledge and gaps in the field.\n\n— From [this revision](https://en.wikipedia.org/w/index.php?title=&diff=1172646802&oldid=) to [Metaphysics](https://en.wikipedia.org/wiki/Metaphysics \"Metaphysics\")\n\n> Including photos of the forge (as above) and its tools would enrich the article's section on culture or economy, giving readers a visual sense of Ronco's industrial heritage. Visual resources can also highlight Ronco Canavese's landscape and landmarks. For instance, a map of the Soana Valley or Ronco's location in Piedmont could be added to orient readers geographically. The village's scenery \\[...\\] could be illustrated with an image. Several such photographs are available (e.g., on Wikimedia Commons) that show Ronco's panoramic view, \\[...\\] Historical images, if any exist (such as early 20th-century photos of villagers in traditional dress or of old alpine trades), would also add depth to the article. Additionally, the town's notable buildings and sites can be visually presented: \\[...\\] Including an image of the Santuario di San Besso \\[...\\] could further engage readers. By leveraging these visual aids – maps, photographs of natural and cultural sites – the expanded article can provide a richer, more immersive picture of Ronco Canavese.\n\n## Knowledge cutoff disclaimers\n\n|  | Words to watch: ***as of \\[date\\]*,[^2] *Up to my last training update*, *as of my last knowledge update*, *While specific details are limited/scarce...*, *not widely available/documented/disclosed*, *...in the provided/available sources/search results...*, *based on available information*...** |\n| --- | --- |\n\nA knowledge-cutoff disclaimer is a statement used by the AI chatbot to indicate that the information provided may be incomplete, inaccurate, or outdated.\n\nIf an LLM has a fixed [knowledge cutoff](https://en.wikipedia.org/wiki/Knowledge_cutoff \"Knowledge cutoff\") (usually the model's last training update), it is unable to provide any information on events or developments past that time, and it will often output a disclaimer to remind the user of this cutoff, which usually takes the form of a statement that says the information provided is accurate only up to a certain date.\n\nIf an LLM with [retrieval-augmented generation](https://en.wikipedia.org/wiki/Retrieval-augmented_generation \"Retrieval-augmented generation\") (for example, an AI chatbot that can search the web) fails to find sources on a given topic, or if information is not included in sources provided to it in a prompt, it will often output a statement to that effect, which is similar to a knowledge-cutoff disclaimer. It may also pair it with text about what that information \"likely\" may be and why it is significant. This information is entirely [speculative](https://en.wikipedia.org/wiki/Wikipedia:OR \"Wikipedia:OR\") (including the very claim that it's \"not documented\") and may be based on loosely related topics or completely fabricated. It is also frequently combined with the tells above.\n\n**Examples**\n\n> While specific information about the fauna of Studniční hora is limited in the provided search results, the mountain likely supports...\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:Diff/1301052898 \"Special:Diff/1301052898\") to [Studniční hora](https://en.wikipedia.org/wiki/Studni%C4%8Dn%C3%AD_hora \"Studniční hora\")\n\n> Though the details of these resistance efforts aren't widely documented, they highlight her bravery...\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:Diff/1261964722 \"Special:Diff/1261964722\") to [Throwing Curves: Eva Zeisel](https://en.wikipedia.org/wiki/Throwing_Curves:_Eva_Zeisel \"Throwing Curves: Eva Zeisel\")\n\n> No significant public controversies or security incidents affecting Outpost24 have been documented as of June 2025.\n\n— From [Draft:Outpost24](https://en.wikipedia.org/wiki/Draft:Outpost24 \"Draft:Outpost24\")\n\n> As of my last knowledge update in January 2022, I don't have specific information about the current status or developments related to the \"Chester Mental Health Center\" in today's era.\n\n— From [this revision](https://en.wikipedia.org/w/index.php?title=&diff=1186779926&oldid=) to [Chester Mental Health Center](https://en.wikipedia.org/wiki/Chester_Mental_Health_Center \"Chester Mental Health Center\")\n\n> Below is a detailed overview based on available information:\n\n## Prompt refusal\n\n|  | Words to watch: ***as an AI language model*, *as a large language model*, *I'm sorry*...** |\n| --- | --- |\n\nOccasionally, the AI chatbot will decline to answer a prompt as written, usually with an apology and a reminder that it is \"an AI language model\". Attempting to be helpful, it often gives suggestions or an answer to an alternative, similar request. Outright refusals have become increasingly rare.\n\nPrompt refusals are obviously unacceptable for Wikipedia articles, so if a user includes one anyway, it may indicate that they did not review the text and/or may not be proficient in English. Remember to [assume good faith](https://en.wikipedia.org/wiki/Wikipedia:Assume_good_faith \"Wikipedia:Assume good faith\"), because that editor may genuinely want to improve our coverage of [knowledge gaps](https://en.wikipedia.org/wiki/Wikipedia:Systemic_bias \"Wikipedia:Systemic bias\").\n\n**Examples**\n\n> As an AI language model, I can't directly add content to Wikipedia for you, but I can help you draft your bibliography.\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:Diff/1221340799 \"Special:Diff/1221340799\") to [Parmiter's Almshouse & Pension Charity](https://en.wikipedia.org/wiki/Parmiter%27s_Almshouse_%26_Pension_Charity \"Parmiter's Almshouse & Pension Charity\")\n\n**Links to searches**\n\nWhen results appear in these searches, they are almost always problematic – but remember that it would be okay for an article to include them if, for example, they were in a relevant, attributed quote.\n\n- [as an AI language model](https://en.wikipedia.org/w/index.php?search=%22as+an+AI+language+model%22&title=Special:Search&profile=advanced&fulltext=1&ns0=1)\n- [as a large language model](https://en.wikipedia.org/w/index.php?search=%22as+a+large+language+model%22&title=Special:Search&profile=advanced&fulltext=1&ns0=1)\n- [\"OpenAI use policy\"](https://en.wikipedia.org/w/index.php?search=%22OpenAI+use+policy%22&title=Special:Search&profile=advanced&fulltext=1&ns0=1)\n\n## Formatting guidelines explanation\n\nAI chatbots are not proficient in [wikitext](https://en.wikipedia.org/wiki/H:WT \"H:WT\"), the [markup language](https://en.wikipedia.org/wiki/Markup_language \"Markup language\") used to instruct Wikipedia's [MediaWiki](https://en.wikipedia.org/wiki/MediaWiki \"MediaWiki\") software how to format an article. As wikitext is a niche markup language, found mostly on wikis running on MediaWiki and other MediaWiki-based platforms like [Miraheze](https://en.wikipedia.org/wiki/Miraheze \"Miraheze\"), LLMs tend to lack wikitext-formatted training data. While the corpuses of chatbots did ingest millions of Wikipedia articles, these articles would not have been processed as text files containing wikitext syntax. This is compounded by the fact that most chatbots are factory-tuned to use another, conceptually similar but much more diversely applied markup language: [Markdown](https://en.wikipedia.org/wiki/Markdown \"Markdown\"). Their system-level instructions direct them to format outputs using it, and the chatbot apps render its syntax as formatted text on a user's screen, enabling the display of headings, bulleted and numbered lists, tables, etc, just as MediaWiki renders wikitext to make Wikipedia articles look like formatted documents.\n\nWhen asked about its \"formatting guidelines\", a chatbot willing to reveal some of its system-level instructions will typically generate some variation of the following (this is [Microsoft Copilot](https://en.wikipedia.org/wiki/Microsoft_Copilot \"Microsoft Copilot\") in mid-2025):\n\n[^2]: not unique to AI chatbots; is produced by the {{ [as of](https://en.wikipedia.org/wiki/Template:As_of \"Template:As of\") }} template\n",
        "skills/ai-anti-patterns/references/07-template-artifacts.md": "# Template Artifacts\n\n## Phrasal templates and placeholder text\n\nAI chatbots may generate responses with fill-in-the-blank [phrasal templates](https://en.wikipedia.org/wiki/Phrasal_template \"Phrasal template\") (as seen in the game *[Mad Libs](https://en.wikipedia.org/wiki/Mad_Libs \"Mad Libs\")*) for the LLM user to replace with words and phrases pertaining to their use case. However, some LLM users forget to fill in those blanks. Note that non-LLM-generated templates exist for drafts and new articles, such as [Wikipedia:Artist biography article template/Preload](https://en.wikipedia.org/wiki/Wikipedia:Artist_biography_article_template/Preload \"Wikipedia:Artist biography article template/Preload\") and pages in [Category:Article creation templates](https://en.wikipedia.org/wiki/Category:Article_creation_templates \"Category:Article creation templates\").\n\n**Examples**\n\n> Subject: Concerns about Inaccurate Information\n>\n> Dear Wikipedia\n>\n> I am writing to express my deep concern about the spread of misinformation on your platform. Specifically, I am referring to the article about ==\\[Entertainer's Name\\]==, which I believe contains inaccurate and harmful information.\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:Diff/1278589409 \"Special:Diff/1278589409\") to [Talk:Kjersti Flaa](https://en.wikipedia.org/wiki/Talk:Kjersti_Flaa \"Talk:Kjersti Flaa\")\n\n> Subject: Edit Request for Wikipedia Entry\n>\n> Dear Wikipedia Editors,\n>\n> I hope this message finds you well. I am writing to request an edit for the Wikipedia entry\n>\n> I have identified an area within the article that requires updating/improvement. ==\\[Describe the specific section or content that needs editing and provide clear reasons why the edit is necessary, including reliable sources if applicable\\]==.\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:Diff/1210511971 \"Special:Diff/1210511971\") to [Talk:Spaghetti](https://en.wikipedia.org/wiki/Talk:Spaghetti \"Talk:Spaghetti\")\n\n> \\[URL of source confirming birth, if available\\], \\[URL of reliable source\\]\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:PermanentLink/1299098468#References \"Special:PermanentLink/1299098468\") to [Draft:Ansuman Satpathy](https://en.wikipedia.org/wiki/Draft:Ansuman_Satpathy \"Draft:Ansuman Satpathy\")\n\n> (Note: Actual Wikipedia articles require verifiable citations from independent sources. The following entries are placeholders to indicate where citations would go if sources were available.)\n\n— From a [speedily-deleted](https://en.wikipedia.org/wiki/Wikipedia:SPEEDY \"Wikipedia:SPEEDY\") draft\n\nLarge-language models may also insert placeholder dates like \"2025-xx-xx\" into citation fields, particularly the access-date parameter and [rarely the date parameter as well](https://en.wikipedia.org/wiki/Special:PermanentLink/1295449767#References \"Special:PermanentLink/1295449767\"), producing errors.\n\n> <ref>{{cite web |title=Game Night Goes Bananas! … |url=https://www.prnewswire.com/news-releases/game-night-goes-bananas-mcmiller-entertainments-viral-smash-hit-party-game-its-bananas-now-available-on-amazon-301602448.html | ==access-date=2025-xx-xx== }}</ref>\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:PermanentLink/1315128233 \"Special:PermanentLink/1315128233\") to [Draft:McMiller draft 1](https://en.wikipedia.org/wiki/Draft:McMiller_draft_1 \"Draft:McMiller draft 1\")\n\n> In 2025, Plot participated in the inauguration of Israel's first grove honoring \\*\\*Prisoners of Zion\\*\\*, in Nof HaGalil.<ref>{{cite news |title=Israel's first grove honoring Prisoners of Zion inaugurated in Nof HaGalil |url=https://www.jns.org/wire/israels-first-grove-honoring-prisoners-of-zion-inaugurated-in-nof-hagalil/ | ==access-date=2025-xx-xx== }}</ref>\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:PermanentLink/1313981806 \"Special:PermanentLink/1313981806\") to [Draft:Ronen Plot](https://en.wikipedia.org/wiki/Draft:Ronen_Plot \"Draft:Ronen Plot\")\n",
        "skills/ai-anti-patterns/references/08-markup-issues.md": "# Markup Issues\n\n## Use of Markdown\n\n```\n## Formatting Guidelines\n\n- All output uses GitHub-flavored Markdown.\n- Use a single main title (\\`#\\`) and clear primary subheadings (\\`##\\`).\n- Keep paragraphs short (3–5 sentences, ≤150 words).\n- Break large topics into labeled subsections.\n- Present related items as bullet or numbered lists; number only when order matters.\n- Always leave a blank line before and after each paragraph.\n- Avoid bold or italic styling in body text unless explicitly requested.\n- Use horizontal dividers (\\`---\\`) between major sections.\n- Employ valid Markdown tables for structured comparisons or data summaries.\n- Refrain from complex Unicode symbols; stick to simple characters.\n- Reserve code blocks for code, poems, lyrics, or similarly formatted content.\n- For mathematical expressions, use LaTeX outside of code blocks.\n```\n\nAs the above suggests, Markdown's syntax is completely different from wikitext's: Markdown uses asterisks (\\*) or underscores (\\_) instead of single-quotes (') for bold and italic formatting, hash symbols (#) instead of equals signs (=) for section headings, parentheses (()) instead of square brackets (\\[\\]) around URLs, and three symbols (---, \\*\\*\\*, or \\_\\_\\_) instead of four hyphens (----) for thematic breaks.\n\nEven when they are told to do so explicitly, chatbots generally struggle to generate text using syntactically correct wikitext, as their training data lead to a drastically greater affinity for and fluency in Markdown. When told to \"generate an article\", a chatbot will typically default to using Markdown for the generated output, which is preserved in clipboard text by the copy functions on some chatbot platforms. If instructed to generate content for Wikipedia, the chatbot might \"realize\" the need to generate Wikipedia-compatible code, and might include a message like Would you like me to... turn this into actual Wikipedia markup format (\\`wikitext\\`)?[^3] in its output. If the chatbot is told to proceed, the resulting syntax will often be rudimentary, syntactically incorrect, or both. The chatbot might put its attempted-wikitext content in a Markdown-style [fenced code block](https://www.markdownguide.org/extended-syntax/#fenced-code-blocks) (its syntax for [WP:PRE](https://en.wikipedia.org/wiki/Wikipedia:PRE \"Wikipedia:PRE\")) surrounded by Markdown-based syntax and content, which may also be preserved by platform-specific copy-to-clipboard functions, leading to a telling footprint of both markup languages' syntax. This might include the appearance of three backticks in the text, such as: ` ```wikitext `.[^4]\n\nThe presence of faulty wikitext syntax mixed with Markdown syntax is a strong indicator that content is LLM-generated, especially if in the form of a fenced Markdown code block. However, Markdown *alone* is not such a strong indicator. Software developers, researchers, technical writers, and experienced internet users frequently use Markdown in tools like [Obsidian](https://en.wikipedia.org/wiki/Obsidian_\\(software\\) \"Obsidian (software)\") and [GitHub](https://en.wikipedia.org/wiki/GitHub_Flavored_Markdown \"GitHub Flavored Markdown\"), and on platforms like [Reddit](https://support.reddithelp.com/hc/en-us/articles/360043033952-Formatting-Guide), [Discord](https://support.discord.com/hc/en-us/articles/210298617-Markdown-Text-101-Chat-Formatting-Bold-Italic-Underline), and [Slack](https://slack.com/help/articles/202288908-Format-your-messages). Some writing tools and apps, such as [iOS Notes](https://en.wikipedia.org/wiki/IOS_Notes \"IOS Notes\"), [Google Docs](https://en.wikipedia.org/wiki/Google_Docs \"Google Docs\"), and [Windows Notepad](https://en.wikipedia.org/wiki/Windows_Notepad \"Windows Notepad\"), support Markdown editing or exporting. The increasing ubiquity of Markdown may also lead new editors to expect or assume Wikipedia to support Markdown by default.\n\n**Examples**\n\n> I believe this block has become procedurally and substantively unsound. Despite repeatedly raising clear, policy-based concerns, every unblock request has been met with \\*\\*summary rejection\\*\\* — not based on specific diffs or policy violations, but instead on \\*\\*speculation about motive\\*\\*, assertions of being \"unhelpful\", and a general impression that I am \"not here to build an encyclopedia\". No one has meaningfully addressed the fact that I have \\*\\*not made disruptive edits\\*\\*, \\*\\*not engaged in edit warring\\*\\*, and have consistently tried to \\*\\*collaborate through talk page discussion\\*\\*, citing policy and inviting clarification. Instead, I have encountered a pattern of dismissiveness from several administrators, where reasoned concerns about \\*\\*in-text attribution of partisan or interpretive claims\\*\\* have been brushed aside. Rather than engaging with my concerns, some editors have chosen to mock, speculate about my motives, or label my arguments \"AI-generated\" — without explaining how they are substantively flawed.\n\n— From [this revision](https://en.wikipedia.org/w/index.php?title=&diff=1284964006&oldid=) to a user talk page\n\n> \\- The Wikipedia entry does not explicitly mention the \"Cyberhero League\" being recognized as a winner of the World Future Society's BetaLaunch Technology competition, as detailed in the interview with THE FUTURIST ([\\[1\\]](https://consciouscreativity.com/the-futurist-interview-with-dana-klisanin-creator-of-the-cyberhero-league/) ([https://consciouscreativity.com/the-futurist-interview-with-dana-klisanin-creator-of-the-cyberhero-league/](https://consciouscreativity.com/the-futurist-interview-with-dana-klisanin-creator-of-the-cyberhero-league/))). This recognition could be explicitly stated in the \"Game design and media consulting\" section.\n\n— From [this revision](https://en.wikipedia.org/w/index.php?title=&diff=1290202502&oldid=) to [Talk:Dana Klisanin](https://en.wikipedia.org/wiki/Talk:Dana_Klisanin \"Talk:Dana Klisanin\")\n\nHere, LLMs incorrectly use `##` to denote section headings, which MediaWiki interprets as a numbered list.\n\n> 1. 1. Geography\n>\n> Villers-Chief is situated in the [Jura Mountains](https://en.wikipedia.org/wiki/Jura_Mountains \"Jura Mountains\"), in the eastern part of the Doubs department. \\[...\\]\n>\n> 1. 1. History\n>\n> Like many communes in the region, Villers-Chief has an agricultural past. \\[...\\]\n>\n> 1. 1. Administration\n>\n> Villers-Chief is part of the [Canton of Valdahon](https://en.wikipedia.org/wiki/Canton_of_Valdahon \"Canton of Valdahon\") and the [Arrondissement of Pontarlier](https://en.wikipedia.org/wiki/Arrondissement_of_Pontarlier \"Arrondissement of Pontarlier\"). \\[...\\]\n>\n> 1. 1. Population\n>\n> The population of Villers-Chief has seen some fluctuations over the decades, \\[...\\]\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:Diff/1294887075 \"Special:Diff/1294887075\") to [Villers-Chief](https://en.wikipedia.org/wiki/Villers-Chief \"Villers-Chief\")\n\n## Broken wikitext\n\nAs explained above, AI-chatbots are not proficient in wikitext and Wikipedia templates, leading to faulty syntax. A noteworthy instance is garbled code related to [Template:AfC submission](https://en.wikipedia.org/wiki/Template:AfC_submission \"Template:AfC submission\"), as new editors might ask a chatbot how to submit their [Articles for Creation](https://en.wikipedia.org/wiki/Wikipedia:Articles_for_Creation \"Wikipedia:Articles for Creation\") draft; see [this discussion among AfC reviewers](https://en.wikipedia.org/wiki/Special:PermanentLink/1299830745#Messed_up_templates \"Special:PermanentLink/1299830745\").\n\n**Examples**\n\nNote the badly malformed category link:\n\n> ```\n> [[Category:AfC submissions by date/<0030Fri, 13 Jun 2025 08:18:00 +0000202568 2025-06-13T08:18:00+00:00Fridayam0000=error>EpFri, 13 Jun 2025 08:18:00 +0000UTC00001820256 UTCFri, 13 Jun 2025 08:18:00 +0000Fri, 13 Jun 2025 08:18:00 +00002025Fri, 13 Jun 2025 08:18:00 +0000: 17498026806Fri, 13 Jun 2025 08:18:00 +0000UTC2025-06-13T08:18:00+00:0020258618163UTC13 pu62025-06-13T08:18:00+00:0030uam301820256 2025-06-13T08:18:00+00:0008amFri, 13 Jun 2025 08:18:00 +0000am2025-06-13T08:18:00+00:0030UTCFri, 13 Jun 2025 08:18:00 +0000 &qu202530;:&qu202530;.</0030Fri, 13 Jun 2025 08:18:00 +0000202568>June 2025|sandbox]]\n> ```\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:PermanentLink/1295363321 \"Special:PermanentLink/1295363321\") to [User:Dr. Omokhudu Idogho/sandbox](https://en.wikipedia.org/wiki/User:Dr._Omokhudu_Idogho/sandbox \"User:Dr. Omokhudu Idogho/sandbox\")\n\n[^3]: [Example](https://en.wikipedia.org/wiki/Special:PermanentLink/1300700102 \"Special:PermanentLink/1300700102\") (deleted, administrators only)\n\n[^4]: [Example](https://en.wikipedia.org/wiki/Special:PermanentLink/1297827841 \"Special:PermanentLink/1297827841\") of ` ```wikitext ` on a draft.\n",
        "skills/ai-anti-patterns/references/09-chatgpt-specific-artifacts.md": "# ChatGPT-Specific Artifacts\n\n## turn0search0\n\nChatGPT may include `citeturn0search0` (surrounded by Unicode points in the [Private Use Area](https://en.wikipedia.org/wiki/Private_Use_Area \"Private Use Area\")) at the ends of sentences, with the number after \"search\" increasing as the text progresses. These are places where the chatbot links to an external site, but a human pasting the conversation into Wikipedia has that link converted into placeholder code. This was first observed in February 2025.\n\nA set of images in a response may also render as `iturn0image0turn0image1turn0image4turn0image5`. Rarely, other markup of a similar style, such as `citeturn0news0` ([example](https://en.wikipedia.org/wiki/Special:PermanentLink/1276934509 \"Special:PermanentLink/1276934509\")), `citeturn1file0` ([example](https://en.wikipedia.org/wiki/Special:PermanentLink/1286349902 \"Special:PermanentLink/1286349902\")), or `cite*generated-reference-identifier*` ([example](https://en.wikipedia.org/wiki/Special:PermanentLink/1276907078 \"Special:PermanentLink/1276907078\")), may appear.\n\n**Examples**\n\n> The school is also a center for the US College Board examinations, SAT I & SAT II, and has been recognized as an International Fellowship Centre by Cambridge International Examinations. citeturn0search1 For more information, you can visit their official website: citeturn0search0\n\n— From [this revision](https://en.wikipedia.org/w/index.php?title=&diff=1274664396&oldid=) to [List of English-medium schools in Bangladesh](https://en.wikipedia.org/wiki/List_of_English-medium_schools_in_Bangladesh \"List of English-medium schools in Bangladesh\")\n\n- [turn0search0 OR turn0search1 OR turn0search2 OR turn0search3 OR turn0search4 OR turn0search5 OR turn0search6 OR turn0search7](https://en.wikipedia.org/w/index.php?title=Special:Search&search=turn0search0+OR+turn0search1+OR+turn0search2+OR+turn0search3+OR+turn0search4+OR+turn0search5+OR+turn0search6+OR+turn0search7&ns0=1&fulltext=Search)\n- [turn0image0 OR turn0image1 OR turn0image2 OR turn0image3 OR turn0image4 OR turn0image5 OR turn0image6 OR turn0image7](https://en.wikipedia.org/w/index.php?title=Special:Search&search=turn0image0+OR+turn0image1+OR+turn0image2+OR+turn0image3+OR+turn0image4+OR+turn0image5+OR+turn0image6+OR+turn0image7&ns0=1&fulltext=Search)\n\n## contentReference and oaicite\n\nDue to a bug, ChatGPT may add code in the form of `:contentReference[oaicite:0]{index=0}` in place of links to references in output text. Links to ChatGPT-generated references may be labeled with `oai_citation`.\n\n**Examples**\n\n> :contentReference\\[oaicite:16\\]{index=16}\n>\n> 1\\. \\*\\*Ethnicity clarification\\*\\*\n>\n> ```\n> - :contentReference[oaicite:17]{index=17}\n>     * :contentReference[oaicite:18]{index=18} :contentReference[oaicite:19]{index=19}.\n>     * Denzil Ibbetson's *Panjab Castes* classifies Sial as Rajputs :contentReference[oaicite:20]{index=20}.\n>     * Historian's blog notes: \"The Sial are a clan of Parmara Rajputs…\" :contentReference[oaicite:21]{index=21}.\n> ```\n>\n> 2.:contentReference\\[oaicite:22\\]{index=22}\n>\n> ```\n> - :contentReference[oaicite:23]{index=23}\n>     > :contentReference[oaicite:24]{index=24} :contentReference[oaicite:25]{index=25}.\n> ```\n\n— From [this revision](https://en.wikipedia.org/w/index.php?title=&diff=1294765751&oldid=) to [Talk:Sial (tribe)](https://en.wikipedia.org/wiki/Talk:Sial_\\(tribe\\) \"Talk:Sial (tribe)\").\n\n> \\#### 📌 Key facts needing addition or correction:\n>\n> 1\\. \\*\\*Group launch & meetings\\*\\*\n>\n> ```\n> *Independent Together* launched a \"Zero Rates Increase Roadshow\" on 15 June, with events in Karori, Hataitai, Tawa, and Newtown  [oai_citation:0‡wellington.scoop.co.nz](https://wellington.scoop.co.nz/?p=171473&utm_source=chatgpt.com).\n> ```\n>\n> 2\\. \\*\\*Zero-rates pledge and platform\\*\\*\n>\n> ```\n> The group pledges no rates increases for three years, then only match inflation—responding to Wellington's 16.9% hike for 2024/25  [oai_citation:1‡en.wikipedia.org](https://en.wikipedia.org/wiki/Independent_Together?utm_source=chatgpt.com).\n> ```\n\n— From [this revision](https://en.wikipedia.org/w/index.php?title=&diff=1296028135&oldid=) to [Talk:Independent Together](https://en.wikipedia.org/wiki/Talk:Independent_Together \"Talk:Independent Together\")\n\n- [\"contentReference\" OR \"oaicite\" OR \"oai\\_citation\"](https://en.wikipedia.org/w/index.php?search=%22contentReference%22+OR+%22oaicite%22+OR+%22oai_citation%22&title=Special%3ASearch)\n\n## Attribution JSON\n\nChatGPT may add [JSON](https://en.wikipedia.org/wiki/JSON \"JSON\") -formatted code at the end of sentences in the form of `({\"attribution\":{\"attributableIndex\":\"X-Y\"}})`, with X and Y being increasing numeric indices.\n\n**Examples**\n\n> ^\\[Evdokimova was born on 6 October 1939 in Osnova, Kharkov Oblast, Ukrainian SSR (now Kharkiv, Ukraine).\\]({\"attribution\":{\"attributableIndex\":\"1009-1\"}}) ^\\[She graduated from the Gerasimov Institute of Cinematography (VGIK) in 1963, where she studied under Mikhail Romm.\\]({\"attribution\":{\"attributableIndex\":\"1009-2\"}}) \\[oai\\_citation:0‡IMDb\\]([https://www.imdb.com/name/nm0947835/?utm\\_source=chatgpt.com](https://www.imdb.com/name/nm0947835/?utm_source=chatgpt.com)) \\[oai\\_citation:1‡maly.ru\\]([https://www.maly.ru/en/people/EvdokimovaA?utm\\_source=chatgpt.com](https://www.maly.ru/en/people/EvdokimovaA?utm_source=chatgpt.com))\n\n— From [Draft:Aleftina Evdokimova](https://en.wikipedia.org/wiki/User:Sohom_Datta/attributeIndex \"User:Sohom Datta/attributeIndex\")\n\n> Patrick Denice & Jake Rosenfeld, [Les syndicats et la rémunération non syndiquée aux États-Unis, 1977–2015](https://sociologicalscience.com/articles-v5-23-541/), ''Sociological Science'' (2018).\\]({\"attribution\":{\"attributableIndex\":\"3795-0\"}})\n\n— From [this diff](https://fr.wikipedia.org/wiki/Special:Diff/225259294 \"fr:Special:Diff/225259294\") to [fr:Syndicalisme aux États-Unis](https://fr.wikipedia.org/wiki/Syndicalisme_aux_%C3%89tats-Unis \"fr:Syndicalisme aux États-Unis\")\n",
        "skills/ai-anti-patterns/references/10-citation-problems.md": "# Citation Problems\n\n## Non-existent categories\n\nLLMs sometimes hallucinate non-existent categories (which appear as red links) because their training set includes obsolete and renamed categories that they reproduce in new content. They may also treat ordinary references to topics as categories, thus generating non-existent categories. Note that this is also a common error made by new or returning editors.\n\n**Examples**\n\n> ```\n> [[Category:American hip hop musicians]]\n> ```\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:PermanentLink/1304282215 \"Special:PermanentLink/1304282215\") to [Draft:Paytra](https://en.wikipedia.org/wiki/Draft:Paytra \"Draft:Paytra\")\n\nrather than\n\n> ```\n> [[Category:American hip-hop musicians]]\n> ```\n\n## Dead links and hallucinated references\n\nIf a new article or draft has multiple citations with external links, and most of them are broken (error 404 pages), this is a strong sign of an AI-generated page, particularly if the dead links are not found in website archiving sites like [Internet Archive](https://en.wikipedia.org/wiki/Internet_Archive \"Internet Archive\") or [Archive Today](https://en.wikipedia.org/wiki/Archive_Today \"Archive Today\"). Most links become broken (see [link rot](https://en.wikipedia.org/wiki/Link_rot \"Link rot\")) over time, but those factors make it unlikely that the link was ever valid.\n\nA [checksum](https://en.wikipedia.org/wiki/Checksum \"Checksum\") can be used to verify [ISBNs](https://en.wikipedia.org/wiki/ISBN \"ISBN\"). An invalid checksum is a very likely sign that an ISBN is incorrect, and citation templates will display [a warning](https://en.wikipedia.org/wiki/Help:CS1_errors#bad_isbn \"Help:CS1 errors\") if so. Similarly, [DOIs](https://en.wikipedia.org/wiki/Digital_object_identifier \"Digital object identifier\") are more resistant to link rot than regular hyperlinks. Unresolvable DOIs and invalid ISBNs can be indicators of [hallucinated](https://en.wikipedia.org/wiki/Hallucination_\\(AI\\) \"Hallucination (AI)\") references.\n\nRelated are DOIs that point to entirely different article and general book citations without pages. This passage, for example, was generated by ChatGPT.\n\n> Ohm's Law is a fundamental principle in the field of electrical engineering and physics that states the current passing through a conductor between two points is directly proportional to the voltage across the two points, provided the temperature remains constant. Mathematically, it is expressed as V=IR, where V is the voltage, I is the current, and R is the resistance. The law was formulated by German physicist Georg Simon Ohm in 1827, and it serves as a cornerstone in the analysis and design of electrical circuits \\[1\\]. Ohm's Law applies to many materials and components that are \"ohmic,\" meaning their resistance remains constant regardless of the applied voltage or current. However, it does not hold for non-linear devices like diodes or transistors \\[2\\]\\[3\\].\n>\n> References:\n>\n> 1\\. Dorf, R. C., & Svoboda, J. A. (2010). Introduction to Electric Circuits (8th ed.). Hoboken, NJ: John Wiley & Sons. [ISBN](https://en.wikipedia.org/wiki/ISBN_\\(identifier\\) \"ISBN (identifier)\") [9780470521571](https://en.wikipedia.org/wiki/Special:BookSources/9780470521571 \"Special:BookSources/9780470521571\").\n>\n> 2\\. M. E. Van Valkenburg, \"The validity and limitations of Ohm's law in non-linear circuits,\" Proceedings of the IEEE, vol. 62, no. 6, pp. 769–770, Jun. 1974. [doi](https://en.wikipedia.org/wiki/Doi_\\(identifier\\) \"Doi (identifier)\"):[10.1109/PROC.1974.9547](https://doi.org/10.1109%2FPROC.1974.9547)\n>\n> 3\\. C. L. Fortescue, \"Ohm's Law in alternating current circuits,\" Proceedings of the IEEE, vol. 55, no. 11, pp. 1934–1936, Nov. 1967. [doi](https://en.wikipedia.org/wiki/Doi_\\(identifier\\) \"Doi (identifier)\"):[10.1109/PROC.1967.6033](https://doi.org/10.1109%2FPROC.1967.6033)\n\nThe book references appear valid – a book on electric circuits would likely have information about Ohm's law, but without the page number, the citation is not usable for verification of the claims in the prose. Worse, both *Proceedings of the IEEE* citations are completely made up. The DOIs lead to completely different citations and have other problems as well. For instance, [C. L. Fortescue](https://en.wikipedia.org/wiki/Charles_LeGeyt_Fortescue \"Charles LeGeyt Fortescue\") was dead for 30+ years at the purported time of writing, and [Vol 55, Issue 11](https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=31102&punumber=5) does not list any articles that match anything remotely close to the information given in reference 3. Note also the use of [curly quotation marks and apostrophes](https://en.wikipedia.org/wiki/#Curly_quotation_marks_and_apostrophes) in some, but not all, of the above text, another indicator that text may be LLM-generated.\n\n## Incorrect reference syntax\n\nAI tools may have been prompted to include references, and make an attempt to do so as Wikipedia expects, but fail with some key implementation details or stand out when compared with conventions.\n\nIn the below example, note the incorrect attempt at re-using references. The tool used here was not capable of searching for non-confabulated sources (as it was done the day before Bing Deep Search launched) but nonetheless found one real reference. The syntax for re-using the references was incorrect.\n\nIn this case, the *Smith, R. J.* source – being the \"third source\" the tool presumably generated the link ' [https://pubmed.ncbi.nlm.nih.gov/3'](https://pubmed.ncbi.nlm.nih.gov/3') (which has a PMID reference of 3) – is also completely irrelevant to the body of the article. The user did not check the reference before they converted it to a {{ [cite journal](https://en.wikipedia.org/wiki/Template:Cite_journal \"Template:Cite journal\") }} reference, even though the links resolve.\n\nThe LLM in this case has diligently included the incorrect re-use syntax after every single full stop.\n\n> ```\n> For over thirty years, computers have been utilized in the rehabilitation of individuals with brain injuries. Initially, researchers delved into the potential of developing a \"prosthetic memory.\"<ref>Fowler R, Hart J, Sheehan M. A prosthetic memory: an application of the prosthetic environment concept. ''Rehabil Counseling Bull''. 1972;15:80–85.</ref> However, by the early 1980s, the focus shifted towards addressing brain dysfunction through repetitive practice.<ref>{{Cite journal |last=Smith |first=R. J. |last2=Bryant |first2=R. G. |date=1975-10-27 |title=Metal substitutions incarbonic anhydrase: a halide ion probe study |url=https://pubmed.ncbi.nlm.nih.gov/3 |journal=Biochemical and Biophysical Research Communications |volume=66 |issue=4 |pages=1281–1286 |doi=10.1016/0006-291x(75)90498-2 |issn=0006-291X |pmid=3}}</ref> Only a few psychologists were developing rehabilitation software for individuals with Traumatic Brain Injury (TBI), resulting in a scarcity of available programs.<sup>[3]</sup> Cognitive rehabilitation specialists opted for commercially available computer games that were visually appealing, engaging, repetitive, and entertaining, theorizing their potential remedial effects on neuropsychological dysfunction.<sup>[3]</sup>\n> ```\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:PermanentLink/1188218670 \"Special:PermanentLink/1188218670\") to [Cognitive orthotics](https://en.wikipedia.org/wiki/Cognitive_orthotics \"Cognitive orthotics\")\n\n## Footnote formatting with ↩\n\nSome LLMs or chatbot interfaces use their own method of providing footnotes, typically using the character ↩:\n\n> References\n>\n> Would you like help formatting and submitting this to Wikipedia, or do you plan to post it yourself? I can guide you step-by-step through that too.\n>\n> **Footnotes**\n>\n> 1. KLAS Research. (2024). *Top Performing RCM Vendors 2024*. https://klasresearch.com ↩ ↩ <sup>2</sup>\n> 2. PR Newswire. (2025, February 18). *CureMD AI Scribe Launch Announcement*. https://www.prnewswire.com/news-releases/curemd-ai-scribe ↩\n\n— From [this revision](https://en.wikipedia.org/wiki/Special:PermanentLink/1304723248 \"Special:PermanentLink/1304723248\") of [Draft:CureMD](https://en.wikipedia.org/wiki/Draft:CureMD \"Draft:CureMD\")\n\n## utm\\_source=\n\nChatGPT may add the [UTM parameter](https://en.wikipedia.org/wiki/UTM_parameter \"UTM parameter\") `utm_source=openai` or, in edits prior to August 2025, `utm_source=chatgpt.com` to URLs that it is using as sources. This behavior is much less common with other LLMs such as Gemini or Claude.[^11]\n\n**Examples**\n\n> Following their marriage, Burgess and Graham settled in Cheshire, England, where Burgess serves as the head coach for the Warrington Wolves rugby league team. \\[https://www.theguardian.com/sport/2025/feb/11/sam-burgess-interview-warrington-rugby-league-luke-littler?utm\\_source=chatgpt.com\\]\n\n— From [this revision](https://en.wikipedia.org/w/index.php?title=&diff=1277944793&oldid=) to [Sam Burgess](https://en.wikipedia.org/wiki/Sam_Burgess \"Sam Burgess\")\n\n> Vertex AI documentation and blog posts describe watermarking, verification workflow, and configurable safety filters (for example, person‑generation controls and safety thresholds). (\\[cloud.google.com\\](https://cloud.google.com/vertex-ai/generative-ai/docs/image/generate-images?utm\\_source=openai))\n\n— From [this revision](https://en.wikipedia.org/w/index.php?title=&diff=1308699845&oldid=) to [Draft:Nano Banana (Chatbot)](https://en.wikipedia.org/wiki/Draft:Nano_Banana_\\(Chatbot\\) \"Draft:Nano Banana (Chatbot)\")\n\n- [utm\\_source=chatgpt.com](https://en.wikipedia.org/w/index.php?search=%utm_source=chatgpt.com%22&title=Special:Search&profile=advanced&fulltext=1&ns0=1)\n- [insource:\"utm\\_source=chatgpt.com\"](https://en.wikipedia.org/w/index.php?search=insource%3A%22utm_source%3Dchatgpt.com%22&title=Special%3ASearch&profile=advanced&fulltext=1&ns0=1)\n- [insource:\"utm\\_source=openai\"](https://en.wikipedia.org/w/index.php?search=insource%3A%22utm_source%3Dopenai%22&title=Special%3ASearch&profile=advanced&fulltext=1&ns0=1)\n\n[^11]: See [T387903](https://phabricator.wikimedia.org/T387903 \"phabricator:T387903\").\n",
        "skills/ai-anti-patterns/references/11-meta-indicators.md": "# Meta Indicators\n\n## Abrupt cut offs\n\nAI tools may abruptly stop generating content, for example if they predict the end of text sequence (appearing as <|endoftext|>) next. Also, the number of tokens that a single response has is usually limited, and further responses will require the user to select \"continue generating\".\n\nThis method is not foolproof, as a malformed copy/paste from one's local computer can also cause this. It may also indicate a [copyright violation](https://en.wikipedia.org/wiki/Wikipedia:Copyvio \"Wikipedia:Copyvio\") rather than the use of an LLM.\n\n## Discrepancies in writing style and variety of English\n\nA sudden shift in an editor's writing style, such as unexpectedly flawless grammar compared to their other communication, may indicate the use of AI tools.\n\nAnother discrepancy is a mismatch of user location, national ties of the topic to a variety of English, and the variety of English used. A human writer from India writing about an Indian university would probably not use American English; however, LLM outputs use American English by default, unless prompted otherwise.[^10] Note that non-native English speakers tend to mix up English varieties, and such signs should only raise suspicion if there is a sudden and complete shift in an editor's English variety use.\n\n## Temporal considerations\n\nChatGPT was launched to the public on November 30, 2022. Although OpenAI had similarly powerful LLMs before then, they were paid services and not particularly accessible or known to lay people. ChatGPT experienced extreme growth immediately on launch.\n\nIt is very unlikely that any particular text added to Wikipedia **prior to November 30, 2022** was generated by an LLM. If an edit to a page was made before this date, AI use can be safely ruled out for that revision. While some text added long ago (such as in 2006) may appear to match some of the AI signs given in this list, and even convincingly appear to have been AI generated, the vastness of Wikipedia allows for these rare coincidences.\n\n## Edit summaries\n\nAI-generated [edit summaries](https://en.wikipedia.org/wiki/Help:Edit_summary \"Help:Edit summary\") are often unusually long, written as formal, first-person paragraphs without [abbreviations](https://en.wikipedia.org/wiki/Wikipedia:Edit_summary_legend \"Wikipedia:Edit summary legend\"), and/or conspicuously itemize Wikipedia's conventions.\n\nMost editors using AI do not ask for summaries to be generated.\n\n> Refined the language of the article for a neutral, encyclopedic tone consistent with Wikipedia's content guidelines. Removed promotional wording, ensured factual accuracy, and maintained a clear, well-structured presentation. Updated sections on history, coverage, challenges, and recognition for clarity and relevance. Added proper formatting and categorized the entry accordingly\n\n— Edit summary from [this revision](https://en.wikipedia.org/wiki/Special:Diff/1263518156 \"Special:Diff/1263518156\") to [Khaama Press](https://en.wikipedia.org/wiki/Khaama_Press \"Khaama Press\")\n\n> I formalized the tone, clarified technical content, ensured neutrality, and indicated citation needs. Historical narratives were streamlined, allocation details specified with regulatory references, propagation explanations made reader-friendly, and equipment discussions focused on availability and regulatory compliance, all while adhering to encyclopedic standards.\n\n— Edit summary from [this revision](https://en.wikipedia.org/wiki/Special:Diff/1184567431 \"Special:Diff/1184567431\") to [4-metre band](https://en.wikipedia.org/wiki/4-metre_band \"4-metre band\")\n\n> \\*\\*Edit Summary:\\*\\* Reorganized article for clarity and neutrality; refined phrasing to align with \\*\\*WP:NPOV\\*\\* and \\*\\*WP:BLPCRIME\\*\\*; standardized formatting and citation styles; improved flow by separating professional achievements from legal issues; updated infobox with complete details; fixed broken references and inconsistencies in date formatting.\n\n— Edit summary from [this revision](https://en.wikipedia.org/wiki/Special:Diff/1279941059 \"Special:Diff/1279941059\") to [David Bitel](https://en.wikipedia.org/wiki/David_Bitel \"David Bitel\")\n\n## False indicators\n\nFalse accusations of AI use can [drive away new editors](https://en.wikipedia.org/wiki/Wikipedia:BITE \"Wikipedia:BITE\") and foster an atmosphere of suspicion. Before claiming AI was used, consider if [Dunning–Kruger effect](https://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect \"Dunning–Kruger effect\") and [confirmation bias](https://en.wikipedia.org/wiki/Confirmation_bias \"Confirmation bias\") is clouding your judgement. In particular, there are several somewhat commonly used indicators which are ineffective (and may even indicate the opposite) in LLM detection.\n\n- **Perfect grammar**: While modern LLMs are known for their high grammatical proficiency, many editors are also skilled writers or come from professional writing backgrounds. (See also [§ Discrepancies in writing style and variety of English](https://en.wikipedia.org/wiki/#Discrepancies_in_writing_style_and_variety_of_English).)\n- **\"Bland\" or \"robotic\" prose**: By default, modern LLMs tend toward effusive and verbose prose, as detailed above; while this tendency is formulaic, it may not scan as \"robotic\" to those unfamiliar with AI writing.[^12]\n- **\"Fancy,\" \"academic,\" or unusual words**: While LLMs disproportionately favor certain words and phrases, many of which are long and have difficult [readability](https://en.wikipedia.org/wiki/Readability \"Readability\") scores, the correlation does not extend to *all* \"fancy,\" academic, or \"advanced\"-sounding prose.[^6] \"AI vocabulary\" and academic vocabulary are not the same thing; indeed, the specific words overused by AI appeared far less frequently in research abstracts prior to 2023.[^9] Low-frequency and \"unusual\" words are also less likely to show up in AI-generated writing as they are statistically less common, unless they are proper nouns directly related to the topic.\n- **Letter-like writing (in isolation)**: Although many talk page messages written with [salutations](https://en.wikipedia.org/wiki/Salutation \"Salutation\"), [valedictions](https://en.wikipedia.org/wiki/Valediction \"Valediction\") and other formalities after 2023 tend to appear AI-generated, that is not guaranteed to be the case for all such messages. Letters and emails have conventionally been written in similar ways *long* before modern LLMs existed. An AI-generated message may start with a [subject line](https://en.wikipedia.org/wiki/Wikipedia:SUBJECTLINE \"Wikipedia:SUBJECTLINE\"), include a [vertical list](https://en.wikipedia.org/wiki/#Inline-header_vertical_lists) [^5] or one or more [placeholders](https://en.wikipedia.org/wiki/#Phrasal_templates_and_placeholder_text), or [end abruptly](https://en.wikipedia.org/wiki/#Abrupt_cut_offs). In addition, some human editors may mistakenly post emails, letters, petitions, or messages intended for the article's subject, frequently formatted as letters. While such edits are generally off-topic and may be removed per the guidelines at [WP:NOTFORUM](https://en.wikipedia.org/wiki/Wikipedia:NOTFORUM \"Wikipedia:NOTFORUM\") —particularly if they contain personal information—they are not necessarily LLM-generated.\n- **Conjunctions (in isolation)**: While LLMs tend to overuse [connecting words](https://en.wikipedia.org/wiki/Transition_\\(linguistics\\) \"Transition (linguistics)\") and phrases in a stilted, formulaic way that implies inappropriate [synthesis](https://en.wikipedia.org/wiki/Wikipedia:SYNTH \"Wikipedia:SYNTH\") of facts, such uses are typical of essay-like writing by humans and are not strong indicators by themselves.\n- **Bizarre [wikitext](https://en.wikipedia.org/wiki/Help:Wikitext \"Help:Wikitext\")**: While LLMs may hallucinate templates or generate wikitext code with invalid syntax for reasons explained in [§ Use of Markdown](https://en.wikipedia.org/wiki/#Use_of_Markdown), they are not likely to generate content with certain random-seeming, \"inexplicable\" errors and artifacts (excluding the ones listed on this page in [§ Markup](https://en.wikipedia.org/wiki/#Markup)). Bizarrely placed [HTML tags](https://en.wikipedia.org/wiki/HTML_tags \"HTML tags\") like <span> are more indicative of poorly programmed browser extensions or a known bug with Wikipedia's content translation tool ([T113137](https://phabricator.wikimedia.org/T113137 \"phabricator:T113137\")). Misplaced syntax like `''Catch-22 i''s a satirical novel.` (rendered as \" *Catch-22 i* s a satirical novel.\") are more indicative of mistakes in [VisualEditor](https://en.wikipedia.org/wiki/Wikipedia:VisualEditor \"Wikipedia:VisualEditor\"), where such errors are harder to notice than in [source editing](https://en.wikipedia.org/wiki/Wikipedia:Source_editing \"Wikipedia:Source editing\").\n\n## See also\n\n- [Wikipedia:Artificial intelligence](https://en.wikipedia.org/wiki/Wikipedia:Artificial_intelligence \"Wikipedia:Artificial intelligence\")\n\n## References\n\n[^5]: [Example](https://en.wikipedia.org/wiki/Wikipedia:Articles_for_deletion/Sarwan_Kumar_Bheel \"Wikipedia:Articles for deletion/Sarwan Kumar Bheel\") of a vertical list in a deletion discussion\n\n[^6]: Russell, Jenna; Karpinska, Marzena; Iyyer, Mohit (2025). [*People who frequently use ChatGPT for writing tasks are accurate and robust detectors of AI-generated text*](https://aclanthology.org/2025.acl-long.267/). Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Vienna, Austria: Association for Computational Linguistics. pp. 5342– 5373. [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv (identifier)\"):[2501.15654](https://arxiv.org/abs/2501.15654). [doi](https://en.wikipedia.org/wiki/Doi_\\(identifier\\) \"Doi (identifier)\"):[10.18653/v1/2025.acl-long.267](https://doi.org/10.18653%2Fv1%2F2025.acl-long.267). Retrieved 2025-09-05 – via [ACL Anthology](https://en.wikipedia.org/wiki/ACL_Anthology \"ACL Anthology\").\n\n[^9]: Juzek, Tom S.; Ward, Zina B. (2025). [*Why Does ChatGPT \"Delve\" So Much? Exploring the Sources of Lexical Overrepresentation in Large Language Models*](https://aclanthology.org/2025.coling-main.426.pdf) (PDF). Findings of the Association for Computational Linguistics: ACL 2025. [Association for Computational Linguistics](https://en.wikipedia.org/wiki/Association_for_Computational_Linguistics \"Association for Computational Linguistics\"). [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv (identifier)\"):[2412.11385](https://arxiv.org/abs/2412.11385). Retrieved October 13, 2025 – via [ACL Anthology](https://en.wikipedia.org/wiki/ACL_Anthology \"ACL Anthology\").\n\n[^10]: Ju, Da; Blix, Hagen; Williams, Adina (2025). [*Domain Regeneration: How well do LLMs match syntactic properties of text domains?*](https://aclanthology.org/2025.findings-acl.120). Findings of the Association for Computational Linguistics: ACL 2025. Vienna, Austria: [Association for Computational Linguistics](https://en.wikipedia.org/wiki/Association_for_Computational_Linguistics \"Association for Computational Linguistics\"). pp. 2367– 2388. [arXiv](https://en.wikipedia.org/wiki/ArXiv_\\(identifier\\) \"ArXiv (identifier)\"):[2505.07784](https://arxiv.org/abs/2505.07784). [doi](https://en.wikipedia.org/wiki/Doi_\\(identifier\\) \"Doi (identifier)\"):[10.18653/v1/2025.findings-acl.120](https://doi.org/10.18653%2Fv1%2F2025.findings-acl.120). Retrieved October 4, 2025 – via [ACL Anthology](https://en.wikipedia.org/wiki/ACL_Anthology \"ACL Anthology\").\n\n[^12]: This can be directly observed by examining images generated by [text-to-image models](https://en.wikipedia.org/wiki/Text-to-image_model \"Text-to-image model\"); they look acceptable at first glance, but specific details tend to be blurry and malformed. This is especially true for background objects and text.\n",
        "skills/ai-anti-patterns/references/_index.md": "# Wikipedia: Signs of AI Writing\n\nThis directory contains sections from Wikipedia's \"Signs of AI writing\" guide, split for easier navigation and referencing. This is a field guide to help detect undisclosed AI-generated content, based on patterns observed across thousands of instances.\n\n**Source:** [Wikipedia:Signs of AI writing](https://en.wikipedia.org/wiki/Wikipedia:Signs_of_AI_writing)\n\n## Table of Contents\n\n### Core Concepts\n- [@00-introduction.md](00-introduction.md) - Purpose, disclaimers, and statistical regression to the mean\n\n### Content and Style Patterns (Rules 1-4)\n- [@01-puffery-and-exaggeration.md](01-puffery-and-exaggeration.md) - \"Stands as\", \"plays a vital role\", superficial analyses with \"-ing\" phrases\n- [@02-promotional-language.md](02-promotional-language.md) - \"Rich tapestry\", \"nestled\", \"it's important to note\" disclaimers\n- [@03-structural-patterns.md](03-structural-patterns.md) - Section summaries, \"Despite challenges\" patterns, negative parallelisms, rule of three, weasel wording\n- [@04-stylistic-quirks.md](04-stylistic-quirks.md) - Elegant variation, false ranges, title case in headings\n\n### Formatting Issues (Rules 5-7)\n- [@05-formatting-and-typography.md](05-formatting-and-typography.md) - Excessive boldface, inline-header lists, emojis, em dashes\n- [@06-communication-patterns.md](06-communication-patterns.md) - Subject lines, collaborative phrases (\"I hope this helps\"), knowledge cutoff disclaimers, prompt refusal\n- [@07-template-artifacts.md](07-template-artifacts.md) - Phrasal templates (Mad Libs style), placeholder text with brackets\n\n### Technical Artifacts (Rules 8-10)\n- [@08-markup-issues.md](08-markup-issues.md) - Markdown vs wikitext confusion, broken wikitext formatting\n- [@09-chatgpt-specific-artifacts.md](09-chatgpt-specific-artifacts.md) - `turn0search0`, `contentReference`, `oaicite`, attribution JSON\n- [@10-citation-problems.md](10-citation-problems.md) - Non-existent categories, dead links, hallucinated DOIs/ISBNs, incorrect reference syntax, `utm_source` parameters\n\n### Meta-Analysis (Rule 11)\n- [@11-meta-indicators.md](11-meta-indicators.md) - Abrupt cutoffs, writing style discrepancies, temporal considerations, AI-generated edit summaries, false indicators to avoid\n\n## Usage for AI Agents\n\nWhen reviewing or editing writing for AI-generated content indicators:\n\n1. **Quick screening**: Start with [@09-chatgpt-specific-artifacts.md](09-chatgpt-specific-artifacts.md) and [@10-citation-problems.md](10-citation-problems.md) for the most objective, unambiguous signs\n2. **Content analysis**: Review [@01-puffery-and-exaggeration.md](01-puffery-and-exaggeration.md) and [@03-structural-patterns.md](03-structural-patterns.md) for common rhetorical patterns\n3. **Style checking**: Consult [@02-promotional-language.md](02-promotional-language.md) and [@04-stylistic-quirks.md](04-stylistic-quirks.md) for tone and vocabulary issues\n4. **Format inspection**: Check [@05-formatting-and-typography.md](05-formatting-and-typography.md) and [@08-markup-issues.md](08-markup-issues.md) for formatting tells\n5. **Avoid false positives**: Always review [@11-meta-indicators.md](11-meta-indicators.md) to understand what does NOT indicate AI use\n\n## Key Principles\n\n- **These are signs, not proof**: Multiple indicators together strengthen the case, but no single indicator is definitive\n- **Context matters**: Some patterns appear in human writing too; use judgment\n- **Focus on deeper issues**: Surface defects point to more serious problems like synthesis, original research, or copyright violations\n- **Assume good faith**: False accusations can drive away new editors\n- **Don't rely on detection tools**: AI detection software has significant error rates and cannot replace human judgment\n\n## G15 Speedy Deletion Criteria\n\nOnly three indicators are sufficient for G15 speedy deletion:\n1. Prompt refusal text (\"As an AI language model...\") - see [@06-communication-patterns.md](06-communication-patterns.md)\n2. ChatGPT-specific artifacts (turn0search0, etc.) - see [@09-chatgpt-specific-artifacts.md](09-chatgpt-specific-artifacts.md)\n3. Certain citation artifacts - see [@10-citation-problems.md](10-citation-problems.md)\n\nAll other signs require further investigation and are not grounds for immediate deletion.\n",
        "skills/bluebook/SKILL.md": "---\nname: bluebook\ndescription: This skill should be used when the user asks to \"cite a case\", \"format a citation\", \"check Bluebook format\", \"cite a statute\", \"use id. or supra\", \"format footnotes\", \"cite a law review article\", or needs Bluebook 21st Edition citation guidance. Covers cases, statutes, secondary sources, signals, and short forms.\n---\n\n# Bluebook 21st Edition Citation\n\nCitation formatting for law reviews and legal scholarship per *The Bluebook: A Uniform System of Citation* (21st ed. 2020).\n\n**Announce:** \"I'm using the bluebook skill for citation formatting.\"\n\n## When to Use\n\nInvoke this skill for:\n- Formatting case citations (federal, state, foreign)\n- Statutory and regulatory citations\n- Secondary sources (books, articles, treatises)\n- Short form citations (id., supra, hereinafter)\n- Introductory signals and parentheticals\n- Citation sentences vs. citation clauses\n\n**For legal writing style**: Use `/writing-legal` skill (Volokh)\n**For general writing**: Use `/writing` skill (Strunk & White)\n\n<EXTREMELY-IMPORTANT>\n## IRON LAW #1: NO CITATION WITHOUT VERIFICATION\n\n**If you haven't verified EVERY element of a citation, DO NOT write it.**\n\nBefore writing ANY citation:\n1. Verify case name spelling and procedural posture\n2. Verify reporter volume and page numbers\n3. Verify court and year\n4. Verify pinpoint page exists\n\n**Guessing reporter volumes or page numbers is LYING. Period.**\n</EXTREMELY-IMPORTANT>\n\n<EXTREMELY-IMPORTANT>\n## IRON LAW #2: NO SHORT FORMS WITHOUT FULL CITATION FIRST\n\n**Id., supra, and hereinafter REQUIRE a preceding full citation.**\n\nBefore using ANY short form:\n1. Locate the full citation in the document\n2. Verify no intervening citations (for id.)\n3. Verify the supra reference is unambiguous\n\n**Using id. after intervening citations creates ambiguity. Delete and cite in full.**\n</EXTREMELY-IMPORTANT>\n\n<EXTREMELY-IMPORTANT>\n## IRON LAW #3: FOOTNOTE VS. TEXT CITATION FORMAT\n\n**Law review citations use footnote format (Rule 1). Court documents use text format (Bluepages).**\n\n```\nFOOTNOTE (law reviews):    Smith v. Jones, 500 U.S. 1, 5 (1991).\nTEXT (court documents):    Smith v. Jones, 500 U.S. 1, 5 (1991)\n\nFOOTNOTE (statutes):       18 U.S.C. § 1001 (2018).\nTEXT (statutes):           18 U.S.C. § 1001 (2018)\n```\n\n**If writing for a law review and using text format conventions, DELETE and reformat.**\n</EXTREMELY-IMPORTANT>\n\n## The Gate Function\n\nBefore writing ANY citation:\n\n```\n1. IDENTIFY → What type of source? (case, statute, article, book)\n2. LOCATE   → Find the correct rule in Bluebook\n3. VERIFY   → Confirm ALL elements (volume, page, court, year)\n4. FORMAT   → Apply correct typeface and punctuation\n5. CHECK    → Does this match examples in the rule?\n6. WRITE    → Only after steps 1-5\n```\n\n**Skipping any step produces unreliable citations.**\n\n## Rationalization Table - STOP If You Think:\n\n| Excuse | Reality | Do Instead |\n|--------|---------|------------|\n| \"I'm pretty sure that's the volume\" | Pretty sure = wrong | VERIFY with actual source |\n| \"Id. is close enough\" | Intervening cite breaks id. | Use full short form |\n| \"This signal seems right\" | Wrong signals mislead readers | CHECK rule 1.2 examples |\n| \"The parenthetical isn't needed\" | Parentheticals explain relevance | ADD what the source says |\n| \"I'll fix the pinpoint later\" | Pinpoints prove claims | ADD pinpoint NOW |\n| \"Small caps isn't that important\" | Typeface is mandatory | APPLY correct typeface |\n| \"This abbreviation is obvious\" | Wrong abbreviations fail | CHECK tables T6, T10, T12 |\n\n## Red Flags - STOP Immediately If:\n\n- \"Let me guess the reporter volume\" → NO. Verify the actual cite.\n- \"Id. probably works here\" → NO. Check for intervening citations.\n- \"Supra will point them back\" → NO. Verify the full citation exists.\n- \"I'll use the common abbreviation\" → NO. Use Bluebook tables.\n- \"Close enough on the page number\" → NO. Exact pinpoints required.\n\n## Quick Reference: Common Citation Forms\n\n### Cases (Rule 10)\n\n```\nFull citation:\nBrown v. Board of Education, 347 U.S. 483, 495 (1954).\n\nShort form (same footnote or five footnotes with no intervening):\nId. at 496.\n\nShort form (different footnote, no intervening):\nBrown, 347 U.S. at 497.\n\nShort form (intervening citations):\nBrown v. Board of Education, 347 U.S. at 498.\n```\n\n### Statutes (Rule 12)\n\n```\nFull citation:\n42 U.S.C. § 1983 (2018).\n\nMultiple sections:\n42 U.S.C. §§ 1983-1985 (2018).\n\nShort form:\n§ 1983 or id. § 1984\n```\n\n### Law Review Articles (Rule 16)\n\n```\nFull citation:\nCass R. Sunstein, *On the Expressive Function of Law*, 144 U. Pa. L. Rev. 2021, 2030 (1996).\n\nShort form:\nSunstein, supra note 12, at 2035.\n```\n\n### Books (Rule 15)\n\n```\nFull citation:\nRichard A. Posner, Economic Analysis of Law 45 (9th ed. 2014).\n\nShort form:\nPosner, supra note 5, at 52.\n```\n\n## Typeface Rules (Rule 2)\n\n| Source Type | Law Review Format |\n|-------------|-------------------|\n| Case names | Italics: *Brown v. Board* |\n| Book titles | Small caps: ECONOMIC ANALYSIS OF LAW |\n| Article titles | Italics: *On the Expressive Function* |\n| Journal names | Small caps: U. PA. L. REV. |\n| Periodical names (non-consecutively paginated) | Italics: *N.Y. Times* |\n| Statutes | Roman: 42 U.S.C. § 1983 |\n\n## Introductory Signals (Rule 1.2)\n\n| Signal | Meaning | Use When |\n|--------|---------|----------|\n| [no signal] | Direct support | Source directly states proposition |\n| *See* | Implicit support | Source supports but doesn't directly state |\n| *See, e.g.,* | One of several | Multiple sources support; citing representative |\n| *Cf.* | Analogous support | Source supports by analogy |\n| *Compare* ... *with* | Comparison | Sources illustrate through contrast |\n| *See generally* | Background | Source provides helpful background |\n| *But see* | Contradiction | Source contradicts proposition |\n| *Contra* | Direct contradiction | Source directly contradicts |\n\n### Signal Order (Rule 1.3)\n\nWithin a single citation sentence, signals appear in this order:\n1. [no signal]\n2. *E.g.,*\n3. *Accord*\n4. *See*\n5. *See also*\n6. *Cf.*\n7. *Compare*\n8. *Contra*\n9. *But see*\n10. *But cf.*\n11. *See generally*\n\n## Common Errors Checklist\n\n### Case Citations\n\n- [ ] Party names shortened properly (omit \"Inc.\", \"Ltd.\" unless only identifier)\n- [ ] \"United States\" abbreviated to \"U.S.\" (as party, not \"United States of America\")\n- [ ] Reporter abbreviation matches T1\n- [ ] Court identifier included unless obvious from reporter\n- [ ] Year is decision year, not argument year\n- [ ] Pinpoint included for specific propositions\n\n### Statutory Citations\n\n- [ ] Current official code used (not session laws for current statutes)\n- [ ] Section symbol (§) used, not \"Section\"\n- [ ] Space between § and number\n- [ ] Year is code edition year, not enactment year\n- [ ] Supplements cited when applicable\n\n### Short Forms\n\n- [ ] Full citation appears earlier in same document\n- [ ] Id. used only when no intervening citation\n- [ ] Supra refers to footnote number where full cite appears\n- [ ] Hereinafter defined in first full citation\n\n## Progressive Disclosure\n\nFor detailed rules, consult:\n\n### Reference Files\n\n- **`references/cases.md`** - Complete case citation rules (R. 10)\n- **`references/statutes.md`** - Statutory and regulatory citations (R. 12-14)\n- **`references/secondary-sources.md`** - Books, articles, treatises (R. 15-17)\n- **`references/short-forms.md`** - Id., supra, hereinafter rules (R. 4)\n- **`references/signals-parentheticals.md`** - Signals, parentheticals, order (R. 1)\n\n### When to Load References\n\nLoad the specific reference when:\n- Formatting an unfamiliar source type\n- Encountering edge cases (unpublished cases, foreign sources)\n- Checking state-specific reporter requirements\n- Working with complex statutory schemes\n- Formatting international materials\n\n## Integration\n\nUse with `/writing-legal` for complete legal scholarship workflow:\n1. `/bluebook` formats citations correctly\n2. `/writing-legal` ensures argument structure and evidence handling\n3. `/ai-anti-patterns` catches AI writing indicators before submission\n\n## Delete & Restart Pattern\n\n**When to delete and restart:**\n\n1. **Citation uses guessed page numbers** → Delete, verify source, cite with real numbers\n2. **Id. follows intervening citation** → Delete id., use full short form\n3. **Wrong signal used** → Delete, reread Rule 1.2, apply correct signal\n4. **Typeface incorrect** → Delete, apply Rule 2 typeface\n5. **Abbreviation doesn't match Bluebook tables** → Delete, use table abbreviation\n\n**How to restart:**\n\n```\nOld: See Smith v. Jones, 500 U.S. at 15. Id. at 20. [intervening cite] Id. at 25.\nNew: See Smith v. Jones, 500 U.S. at 15. Id. at 20. [intervening cite] Smith, 500 U.S. at 25.\n```\n\nThe third cite cannot use id. after an intervening citation.\n",
        "skills/bluebook/references/cases.md": "# Case Citations - Bluebook Rule 10\n\nComplete guidance for citing cases in law review footnotes per Bluebook 21st Edition.\n\n## Basic Form (Rule 10.1)\n\n```\n[Case Name], [Volume] [Reporter] [First Page], [Pinpoint] ([Court] [Year]).\n```\n\n**Example:**\n```\nBrown v. Board of Education, 347 U.S. 483, 495 (1954).\n```\n\n## Case Names (Rule 10.2)\n\n### Party Names\n\n**Include:**\n- First-listed party on each side\n- Procedural phrases only if critical (In re, Ex parte)\n\n**Omit:**\n- \"The\" as first word\n- Given names of individuals\n- \"Inc.\", \"Ltd.\", \"L.L.C.\" unless only identifier\n- \"Co.\" when preceded by another business designation\n- All parties except first listed on each side\n\n### Abbreviations in Case Names (Table T6)\n\nAlways abbreviate:\n- & (for \"and\")\n- Ass'n (Association)\n- Bros. (Brothers)\n- Co. (Company)\n- Corp. (Corporation)\n- Inc. (Incorporated)\n- Ltd. (Limited)\n- No. (Number)\n\n**In citations:** Abbreviate all words in T6.\n**In text:** Only abbreviate widely known acronyms (FBI, SEC).\n\n### Special Parties\n\n| Party | Citation Form |\n|-------|---------------|\n| United States | U.S. (not \"United States of America\") |\n| State as party | State v. Smith (not \"People\" unless officially so titled) |\n| Government agency | Agency name or acronym if well-known |\n| Relator | Omit relator in ex rel. unless necessary |\n\n### Procedural Phrases\n\n| Phrase | When to Use |\n|--------|-------------|\n| *In re* | Bankruptcy, probate, non-adversary proceedings |\n| *Ex parte* | One-party proceedings |\n| *Ex rel.* | Actions by relator (often omit relator) |\n\n**Example:**\n```\nIn re Gault, 387 U.S. 1 (1967).\n```\n\n## Reporters (Rule 10.3)\n\n### Federal Courts\n\n| Court | Reporter | Example |\n|-------|----------|---------|\n| Supreme Court | U.S. | 347 U.S. 483 |\n| Circuit Courts | F., F.2d, F.3d, F.4th | 500 F.3d 123 |\n| District Courts | F. Supp., F. Supp. 2d, F. Supp. 3d | 100 F. Supp. 3d 456 |\n\n**Supreme Court preference:** Use U.S. Reports. If unavailable, use S. Ct., then L. Ed.\n\n### State Courts\n\nUse Table T1 for each state's official and regional reporter requirements.\n\n**General rule:** Cite to official reporter if available, plus regional reporter if required by local practice.\n\n**Example (New York):**\n```\nPeople v. Smith, 50 N.Y.2d 100, 405 N.E.2d 123 (1980).\n```\n\n### Parallel Citations\n\nRequired only when:\n1. Citing in documents submitted to that state's courts\n2. State rule requires parallel citation\n\nFor law reviews, generally cite only to official reporter or regional reporter (not both).\n\n## Court and Jurisdiction (Rule 10.4)\n\n### When to Include Court\n\n**Omit court when obvious from reporter:**\n- U.S. → Supreme Court (obvious)\n- F.3d → Court of Appeals (include circuit: \"(9th Cir.)\")\n- F. Supp. 3d → District Court (include district: \"(S.D.N.Y.)\")\n\n**Include court when:**\n- State court name is not obvious from reporter\n- Lower court decision in state with single official reporter\n- Intermediate appellate court\n\n### Court Abbreviations (Table T7)\n\n| Court | Abbreviation |\n|-------|--------------|\n| Court of Appeals | Cir. or Ct. App. |\n| District Court | D. (with state: S.D.N.Y.) |\n| Supreme Court | Sup. Ct. (state only) |\n| Bankruptcy Court | Bankr. |\n\n**Examples:**\n```\nSmith v. Jones, 500 F.3d 100 (9th Cir. 2007).\nDoe v. Roe, 200 F. Supp. 3d 50 (E.D. Va. 2016).\n```\n\n## Date (Rule 10.5)\n\n### Year of Decision\n\nCite year of decision, NOT:\n- Year of argument\n- Year opinion was released if different from decision\n- Year case was filed\n\n### Exact Date\n\nRequired for:\n- Slip opinions\n- Newspapers\n- Magazines\n- Unreported cases\n\n**Format:** (Month Day, Year)\n```\nSmith v. Jones, No. 20-1234 (9th Cir. Jan. 15, 2021).\n```\n\n## Pinpoint Citations (Rule 3.2)\n\n### Page Numbers\n\n**Always include pinpoints** when citing for a specific proposition.\n\n**Span of pages:**\n```\nBrown, 347 U.S. at 495-96.\n```\n\n**Non-consecutive pages:**\n```\nBrown, 347 U.S. at 495, 498, 501-02.\n```\n\n### Paragraph Numbers\n\nFor sources using paragraph numbers instead of pages:\n```\nSmith v. Jones, No. 20-1234, ¶ 15 (9th Cir. Jan. 15, 2021).\n```\n\n### Footnote Citations\n\nCite to footnote within a page:\n```\nBrown, 347 U.S. at 495 n.3.\n```\n\nMultiple footnotes:\n```\nBrown, 347 U.S. at 495 nn.3-5.\n```\n\n## Subsequent History (Rule 10.7)\n\n### When to Include\n\n**Required:**\n- Any subsequent history on appeal\n- Certiorari granted or denied (if relevant)\n- Overruling or abrogation\n\n**Omit:**\n- Denial of certiorari more than 2 years old (unless particularly relevant)\n- History on remand unless relevant\n\n### Format\n\n```\nSmith v. Jones, 500 F.3d 100 (9th Cir. 2007), aff'd, 555 U.S. 100 (2008).\nDoe v. Roe, 400 F.3d 50 (5th Cir. 2005), rev'd, 550 U.S. 50 (2007).\n```\n\n### Common History Abbreviations (Table T8)\n\n| Action | Abbreviation |\n|--------|--------------|\n| affirmed | aff'd |\n| reversed | rev'd |\n| certiorari denied | cert. denied |\n| certiorari granted | cert. granted |\n| vacated | vacated |\n| overruled by | overruled by |\n| abrogated by | abrogated by |\n\n## Prior History (Rule 10.7)\n\nInclude when relevant to discussion:\n```\nBrown v. Board of Education, 98 F. Supp. 797 (D. Kan. 1951), aff'd, 347 U.S. 483 (1954).\n```\n\n## Parenthetical Information (Rule 10.6)\n\n### Weight of Authority\n\n```\nSmith v. Jones, 500 F.3d 100, 105 (9th Cir. 2007) (en banc).\nDoe v. Roe, 400 F.3d 50 (5th Cir. 2005) (per curiam).\nSmith v. Jones, 500 F.3d 100, 110 (9th Cir. 2007) (Thomas, J., dissenting).\n```\n\n### Explanatory Parentheticals\n\nWhen source doesn't directly state proposition:\n```\nBrown v. Board of Education, 347 U.S. 483, 495 (1954) (holding that separate educational facilities are inherently unequal).\n```\n\n**Parenthetical form:**\n- Begin with present participle (holding, finding, noting)\n- Or quoted material\n\n### Order of Parentheticals\n\n1. Weight of authority (en banc, per curiam)\n2. \"Quoting\" or \"citing\" information\n3. Explanatory parenthetical\n\n```\nSmith, 500 F.3d at 110 (en banc) (quoting Jones, 400 F.3d at 55) (holding that...).\n```\n\n## Special Cases\n\n### Unpublished Opinions\n\n```\nSmith v. Jones, No. 20-1234, 2021 WL 123456, at *3 (9th Cir. Jan. 15, 2021).\n```\n\n### Slip Opinions\n\n```\nSmith v. Jones, slip op. at 5 (U.S. Jan. 15, 2021).\n```\n\n### Pending Cases\n\n```\nSmith v. Jones, No. 20-1234 (9th Cir. argued Dec. 1, 2020).\n```\n\n### Foreign Cases\n\nSee Table T2 for country-specific rules.\n\n**Example (UK):**\n```\nDonoghue v. Stevenson, [1932] A.C. 562 (H.L.).\n```\n\n## Short Forms for Cases (Rule 10.9)\n\n### Id.\n\nUse when:\n- Citing same case as immediately preceding citation\n- No intervening citations\n\n```\n1. Brown v. Board of Education, 347 U.S. 483, 495 (1954).\n2. Id. at 496.\n```\n\n### Short Form Citation\n\nUse when:\n- Case cited previously in same document\n- Intervening citations exist\n- Five or more footnotes since full citation\n\n```\n15. Brown, 347 U.S. at 497.\n```\n\nOr with both party names if needed for clarity:\n```\nBrown v. Board of Education, 347 U.S. at 498.\n```\n\n### Never Use\n\n- \"Op. cit.\"\n- \"Loc. cit.\"\n- Case names alone without reporter\n\n## Common Errors\n\n### Party Name Errors\n\n| Error | Correction |\n|-------|------------|\n| The People of New York v. Smith | People v. Smith |\n| John Smith v. Jane Doe | Smith v. Doe |\n| Microsoft Corporation | Microsoft Corp. |\n| First National Bank of Chicago | First Nat'l Bank |\n\n### Reporter Errors\n\n| Error | Correction |\n|-------|------------|\n| 347 US 483 | 347 U.S. 483 (spaces, periods) |\n| 500 F. 3d 100 | 500 F.3d 100 (no space before series) |\n| 100 F.Supp.3d 50 | 100 F. Supp. 3d 50 (spaces) |\n\n### Court/Date Errors\n\n| Error | Correction |\n|-------|------------|\n| (9th Cir. Ct. App. 2007) | (9th Cir. 2007) |\n| (SDNY 2016) | (S.D.N.Y. 2016) |\n| (Supreme Court 1954) | (1954) for U.S. Reports |\n\n## Verification Checklist\n\nBefore finalizing any case citation:\n\n- [ ] Case name properly shortened per Rule 10.2\n- [ ] Reporter abbreviation matches Table T1\n- [ ] Volume and page numbers verified against source\n- [ ] Court identified unless obvious from reporter\n- [ ] Year is decision year\n- [ ] Pinpoint page included for specific propositions\n- [ ] Subsequent history included if relevant\n- [ ] Parenthetical explains relevance if source doesn't directly state proposition\n",
        "skills/bluebook/references/secondary-sources.md": "# Secondary Sources - Bluebook Rules 15-18\n\nComplete guidance for citing books, articles, treatises, and other secondary sources per Bluebook 21st Edition.\n\n## Books and Treatises (Rule 15)\n\n### Basic Form\n\n```\n[Author(s)], [Title] [Pinpoint] ([Edition] [Year]).\n```\n\n**Example:**\n```\nRichard A. Posner, Economic Analysis of Law 45 (9th ed. 2014).\n```\n\n### Author Names (Rule 15.1)\n\n**Single author:**\n```\nCass R. Sunstein, The Cost-Benefit Revolution 15 (2018).\n```\n\n**Two authors:**\n```\nWilliam N. Eskridge, Jr. & Philip P. Frickey, Cases and Materials on Legislation 200 (5th ed. 2014).\n```\n\n**Three or more authors:**\n```\nErwin Chemerinsky et al., Constitutional Law: Principles and Policies 150 (6th ed. 2019).\n```\n\n**Institutional author:**\n```\nAmerican Law Institute, Restatement (Third) of Torts § 3 (2010).\n```\n\n### Titles (Rule 15.3)\n\n**Typeface:** SMALL CAPS for books in law review footnotes.\n\n```\nRichard A. Posner, ECONOMIC ANALYSIS OF LAW 45 (9th ed. 2014).\n```\n\n**Subtitles:** Include after colon if relevant.\n```\nCass R. Sunstein, THE COST-BENEFIT REVOLUTION: THE STRUGGLE TO MAKE GOVERNMENT EFFICIENT 15 (2018).\n```\n\n### Editors and Translators (Rule 15.2)\n\n**Edited volume:**\n```\nThe Federalist No. 78, at 464 (Alexander Hamilton) (Clinton Rossiter ed., 1961).\n```\n\n**Translator:**\n```\nMax Weber, Economy and Society 100 (Guenther Roth & Claus Wittich eds., Ephraim Fischoff trans., 1968).\n```\n\n### Edition and Year (Rule 15.4)\n\n**Always include edition if not first:**\n```\nRichard A. Posner, Economic Analysis of Law 45 (9th ed. 2014).\n```\n\n**First edition:** Omit edition number.\n```\nCass R. Sunstein, The Cost-Benefit Revolution 15 (2018).\n```\n\n**Publisher:** Generally omit for widely available books.\n\n### Supplements and Pocket Parts\n\n```\n3 Ronald D. Rotunda & John E. Nowak, Treatise on Constitutional Law § 18.7 (5th ed. 2012 & Supp. 2020).\n```\n\n### Multi-Volume Works\n\n```\n3 William Blackstone, Commentaries *125.\n```\n\nStar pages (*) indicate original pagination in facsimile editions.\n\n## Periodical Materials (Rule 16)\n\n### Law Review Articles\n\n**Basic form:**\n```\n[Author], [Title], [Vol.] [Journal] [First Page], [Pinpoint] ([Year]).\n```\n\n**Example:**\n```\nCass R. Sunstein, On the Expressive Function of Law, 144 U. Pa. L. Rev. 2021, 2030 (1996).\n```\n\n### Typeface for Articles\n\n| Element | Law Review Format |\n|---------|-------------------|\n| Author name | Roman |\n| Article title | Italics |\n| Journal name | SMALL CAPS |\n\n```\nCass R. Sunstein, *On the Expressive Function of Law*, 144 U. PA. L. REV. 2021, 2030 (1996).\n```\n\n### Journal Abbreviations (Table T13)\n\nAlways use Bluebook abbreviations from Table T13.\n\n| Full Name | Abbreviation |\n|-----------|--------------|\n| Harvard Law Review | Harv. L. Rev. |\n| Yale Law Journal | Yale L.J. |\n| Stanford Law Review | Stan. L. Rev. |\n| Columbia Law Review | Colum. L. Rev. |\n| University of Pennsylvania Law Review | U. Pa. L. Rev. |\n\n### Student-Written Pieces\n\n**Notes and Comments:**\n```\nJane Student, Note, The Future of Privacy, 100 Harv. L. Rev. 1000 (2020).\nJane Student, Comment, On Jurisdiction, 50 Stan. L. Rev. 500 (2015).\n```\n\n**Designation (Note, Comment, etc.) appears after author's name.**\n\n### Symposium Articles\n\n```\nCass R. Sunstein, On the Expressive Function of Law, 144 U. Pa. L. Rev. 2021 (1996) (symposium on law and social norms).\n```\n\n### Online-Only Journals\n\n```\nAuthor, Title, Vol. J. Name Art. No. or Page (Year), URL.\n```\n\n### Forthcoming Articles\n\n```\nAuthor, Title, Vol. J. Name (forthcoming Year) (manuscript at Page) (on file with [repository]).\n```\n\n## Newspapers and Magazines (Rule 16.6)\n\n### Newspapers\n\n**Basic form:**\n```\n[Author], [Title], [Newspaper], [Date], at [Page].\n```\n\n**Example:**\n```\nAdam Liptak, *Court Ruling Could Reshape Healthcare*, N.Y. Times, June 26, 2015, at A1.\n```\n\n**Typeface:** Newspaper name in *italics* (non-consecutively paginated periodical).\n\n### Online Newspaper Articles\n\n```\nAdam Liptak, Court Ruling Could Reshape Healthcare, N.Y. Times (June 26, 2015), https://www.nytimes.com/...\n```\n\n### Magazines\n\n**Weekly or monthly:**\n```\nJeffrey Toobin, *The Obama Brief*, New Yorker, Oct. 27, 2014, at 24.\n```\n\n### Blogs and Online Sources (Rule 18.2.4)\n\n```\n[Author], [Title], [Blog Name] ([Date]), [URL].\n```\n\n**Example:**\n```\nEugene Volokh, Free Speech and Criminal Solicitation, Volokh Conspiracy (Jan. 15, 2020), https://...\n```\n\n## Restatements (Rule 12.9.5)\n\n### Basic Form\n\n```\nRestatement ([Series]) of [Subject] § [Section] ([Year]).\n```\n\n**Example:**\n```\nRestatement (Second) of Contracts § 90 (Am. L. Inst. 1981).\nRestatement (Third) of Torts: Liability for Physical and Emotional Harm § 3 (Am. L. Inst. 2010).\n```\n\n### Comments and Illustrations\n\n```\nRestatement (Second) of Contracts § 90 cmt. a (Am. L. Inst. 1981).\nRestatement (Second) of Contracts § 90 cmt. a, illus. 1 (Am. L. Inst. 1981).\n```\n\n## Model Codes and Standards\n\n### Uniform Laws\n\n```\nU.C.C. § 2-201 (Am. L. Inst. & Unif. L. Comm'n 2017).\n```\n\n### Model Codes\n\n```\nModel Rules of Pro. Conduct r. 1.6 (Am. Bar Ass'n 2020).\nModel Penal Code § 2.02 (Am. L. Inst. 1985).\n```\n\n## Dictionaries and Encyclopedias (Rule 15.8)\n\n### Legal Dictionaries\n\n```\nBlack's Law Dictionary 1000 (11th ed. 2019).\n```\n\n**Entry within dictionary:**\n```\nContract, Black's Law Dictionary (11th ed. 2019).\n```\n\n### Legal Encyclopedias\n\n```\n17A Am. Jur. 2d Contracts § 100 (2020).\n17A C.J.S. Contracts § 200 (2019).\n```\n\n### General Encyclopedias\n\n```\nEncyclopedia Britannica (15th ed. 2010).\n```\n\nGenerally avoid citing Wikipedia in legal scholarship.\n\n## Unpublished Sources (Rule 17)\n\n### Working Papers\n\n```\n[Author], [Title] ([Institutional Series & Number], [Date]), [URL].\n```\n\n**Example:**\n```\nLucian A. Bebchuk & Alma Cohen, Firms' Decisions Where to Incorporate (Harvard Law Sch. John M. Olin Ctr. for L., Econ. & Bus., Discussion Paper No. 351, 2002), https://...\n```\n\n### Dissertations and Theses\n\n```\nAuthor, Title (Ph.D. dissertation, Institution Year).\n```\n\n### Letters and Memoranda\n\n```\nLetter from [Author] to [Recipient] (Date) (on file with [repository]).\n```\n\n### Interviews\n\n```\nInterview with [Name], [Title], in [Location] (Date).\n```\n\n## Electronic Sources (Rule 18)\n\n### General Principles\n\n**Prefer print sources** when identical content is available.\n\n**When to cite online sources:**\n1. Source available only online\n2. Online version is official\n3. Online version is superior (e.g., hyperlinks to cited sources)\n\n### URL Format\n\nInclude full URL. If URL is excessively long, use shortened version or archived version.\n\n```\nhttps://perma.cc/XXXX-XXXX\n```\n\n### Parenthetical for Last Visited\n\nFor websites likely to change:\n```\n[URL] (last visited [Date]).\n```\n\n## Short Forms for Secondary Sources (Rule 4)\n\n### Id.\n\nUse when citing same source as immediately preceding citation with no intervening cites:\n```\n1. Cass R. Sunstein, On the Expressive Function of Law, 144 U. Pa. L. Rev. 2021, 2030 (1996).\n2. Id. at 2035.\n```\n\n### Supra\n\nUse for sources previously cited in a footnote:\n```\n15. Sunstein, supra note 1, at 2040.\n```\n\n**Form:**\n```\n[Author's last name], supra note [#], at [Page].\n```\n\n### Hereinafter\n\nDefine in first citation for sources with long titles or multiple works by same author:\n```\n1. Cass R. Sunstein, On the Expressive Function of Law, 144 U. Pa. L. Rev. 2021 (1996) [hereinafter Sunstein, Expressive Function].\n...\n15. Sunstein, Expressive Function, supra note 1, at 2040.\n```\n\n## Special Source Types\n\n### Briefs and Court Documents (Rule 10.8.3)\n\n```\nBrief for Petitioner at 15, Brown v. Board of Education, 347 U.S. 483 (1954) (No. 1).\n```\n\n### Transcripts\n\n```\nTranscript of Oral Argument at 25, Citizens United v. FEC, 558 U.S. 310 (2010) (No. 08-205).\n```\n\n### Speeches and Addresses\n\n```\n[Speaker], [Title] (Remarks at [Event], [Date]), [URL].\n```\n\n## Typeface Summary for Law Reviews\n\n| Source Type | Typeface |\n|-------------|----------|\n| Book titles | SMALL CAPS |\n| Article titles | *Italics* |\n| Journal names | SMALL CAPS |\n| Newspaper names | *Italics* |\n| Magazine names | *Italics* |\n| Blog names | *Italics* |\n| Author names | Roman |\n\n## Common Errors\n\n### Article Citations\n\n| Error | Correction |\n|-------|------------|\n| Missing journal abbreviation periods | Harv. L. Rev. (not Harv L Rev) |\n| Wrong year placement | ...2021 (1996). (not ...2021, 1996.) |\n| Missing pinpoint | Always include specific page |\n\n### Book Citations\n\n| Error | Correction |\n|-------|------------|\n| Publisher included | Generally omit publisher |\n| First edition noted | Omit \"1st ed.\" |\n| Missing year | Year always required |\n\n### Short Form Errors\n\n| Error | Correction |\n|-------|------------|\n| Supra without note number | Sunstein, supra note 1 |\n| Id. after intervening cite | Use supra form instead |\n| Wrong author name | Last name only for supra |\n\n## Verification Checklist\n\nBefore finalizing secondary source citations:\n\n- [ ] Author name(s) correctly formatted\n- [ ] Title matches source exactly\n- [ ] Journal/publisher abbreviation follows Bluebook tables\n- [ ] Volume and page numbers verified\n- [ ] Edition and year included\n- [ ] Pinpoint provided for specific propositions\n- [ ] Typeface correct for source type\n- [ ] Short forms reference correct footnote number\n",
        "skills/bluebook/references/short-forms.md": "# Short Form Citations - Bluebook Rule 4\n\nComplete guidance for id., supra, hereinafter, and other short forms per Bluebook 21st Edition.\n\n## The Iron Law of Short Forms\n\n<EXTREMELY-IMPORTANT>\n**NO SHORT FORM WITHOUT FULL CITATION FIRST.**\n\nEvery short form (id., supra, hereinafter) MUST point to a preceding full citation. If the full citation doesn't exist, the short form is meaningless.\n\n**Verification gate:**\n1. LOCATE full citation in document\n2. VERIFY no ambiguity (only one source matches)\n3. CHECK for intervening citations (for id.)\n4. THEN use short form\n</EXTREMELY-IMPORTANT>\n\n## Id. (Rule 4.1)\n\n### When to Use Id.\n\nUse id. when:\n1. Citing the **immediately preceding authority**\n2. **No intervening citations** since that authority\n3. The preceding authority is in the **same footnote** or a **recent footnote**\n\n### Basic Form\n\n**Same page:**\n```\n1. Brown v. Board of Education, 347 U.S. 483, 495 (1954).\n2. Id.\n```\n\n**Different page:**\n```\n1. Brown v. Board of Education, 347 U.S. 483, 495 (1954).\n2. Id. at 496.\n```\n\n**Different section (statutes):**\n```\n1. 42 U.S.C. § 1983 (2018).\n2. Id. § 1985.\n```\n\n### Id. Capitalization\n\n| Position | Capitalization |\n|----------|----------------|\n| Beginning of citation sentence | *Id.* |\n| Within citation clause | *id.* |\n| After a signal | *id.* |\n\n**Examples:**\n```\nId. at 496.                           (beginning of sentence)\nSee id. at 496.                       (after signal)\nSee Brown, 347 U.S. at 495; id. at 496.  (within clause)\n```\n\n### When NOT to Use Id.\n\n**Never use id. when:**\n\n1. **Intervening citation exists:**\n```\nWRONG:\n1. Brown, 347 U.S. at 495.\n2. Plessy v. Ferguson, 163 U.S. 537 (1896).\n3. Id. at 496.  ← Would refer to Plessy, not Brown!\n\nCORRECT:\n3. Brown, 347 U.S. at 496.\n```\n\n2. **Preceding footnote has multiple sources:**\n```\nWRONG:\n1. Brown, 347 U.S. at 495; Plessy, 163 U.S. at 540.\n2. Id. at 496.  ← Ambiguous: which case?\n\nCORRECT:\n2. Brown, 347 U.S. at 496.\n```\n\n3. **Too many footnotes have passed:**\n\nUse judgment—after five footnotes without citing the source, use full short form instead of id.\n\n### Id. for Different Source Types\n\n**Cases:**\n```\nId.                    (same page)\nId. at 496.           (different page)\n```\n\n**Statutes:**\n```\nId.                    (same section)\nId. § 1985.           (different section)\nId. § 1983(a).        (subsection of same section)\n```\n\n**Books:**\n```\nId.                    (same page)\nId. at 50.            (different page)\n```\n\n**Articles:**\n```\nId.                    (same page)\nId. at 2035.          (different page)\n```\n\n## Supra (Rule 4.2)\n\n### When to Use Supra\n\nUse supra to refer to a source fully cited in a **previous footnote**.\n\n**Supra is appropriate for:**\n- Books\n- Articles\n- Reports\n- Most secondary sources\n\n**Supra is NOT appropriate for:**\n- Cases (use case short form instead)\n- Statutes (use statutory short form instead)\n- Constitutions\n- Regulations\n\n### Basic Form\n\n```\n[Author's last name], supra note [#], at [Page].\n```\n\n**Example:**\n```\n1. Cass R. Sunstein, On the Expressive Function of Law, 144 U. Pa. L. Rev. 2021, 2030 (1996).\n...\n15. Sunstein, supra note 1, at 2040.\n```\n\n### Supra Without Page\n\nWhen referring to the work generally (not a specific page):\n```\nSunstein, supra note 1.\n```\n\n### Multiple Works by Same Author\n\nWhen the author has multiple cited works, use title to disambiguate:\n```\n1. Cass R. Sunstein, On the Expressive Function of Law, 144 U. Pa. L. Rev. 2021 (1996).\n2. Cass R. Sunstein, The Cost-Benefit Revolution (2018).\n...\n15. Sunstein, supra note 1, at 2040.        (refers to article)\n16. Sunstein, supra note 2, at 50.          (refers to book)\n```\n\nOr use hereinafter for clarity.\n\n### Supra for Multi-Author Works\n\n```\n1. William N. Eskridge, Jr. & Philip P. Frickey, Cases and Materials on Legislation 200 (5th ed. 2014).\n...\n15. Eskridge & Frickey, supra note 1, at 250.\n```\n\nFor three or more authors, use first author only:\n```\n1. Erwin Chemerinsky et al., Constitutional Law 150 (6th ed. 2019).\n...\n15. Chemerinsky, supra note 1, at 200.\n```\n\n## Hereinafter (Rule 4.2(b))\n\n### When to Use Hereinafter\n\nUse hereinafter when:\n1. Title is unusually long or cumbersome\n2. Multiple works by same author need disambiguation\n3. Source would otherwise be ambiguous in short form\n\n### Basic Form\n\nDefine in first citation:\n```\n[Full Citation] [hereinafter [Short Name]].\n```\n\nUse in subsequent citations:\n```\n[Short Name], supra note [#], at [Page].\n```\n\n### Examples\n\n**Long title:**\n```\n1. U.S. Dep't of Health & Human Servs., The Health Consequences of Smoking—50 Years of Progress: A Report of the Surgeon General 100 (2014) [hereinafter Surgeon General's Report].\n...\n15. Surgeon General's Report, supra note 1, at 150.\n```\n\n**Multiple works by same author:**\n```\n1. Cass R. Sunstein, On the Expressive Function of Law, 144 U. Pa. L. Rev. 2021 (1996) [hereinafter Sunstein, Expressive Function].\n2. Cass R. Sunstein, Cost-Benefit Analysis and the Environment, 115 Ethics 351 (2005) [hereinafter Sunstein, Cost-Benefit].\n...\n15. Sunstein, Expressive Function, supra note 1, at 2040.\n16. Sunstein, Cost-Benefit, supra note 2, at 360.\n```\n\n### Hereinafter Placement\n\nAlways immediately after the citation, before any parenthetical:\n```\nCORRECT: ...100 (2014) [hereinafter Report].\nWRONG:   ...100 [hereinafter Report] (2014).\n```\n\n## Short Forms for Cases (Rule 10.9)\n\n**Cases do NOT use supra.** Use case-specific short forms instead.\n\n### Basic Case Short Form\n\n```\n[One Party Name], [Vol.] [Reporter] at [Page].\n```\n\n**Example:**\n```\n1. Brown v. Board of Education, 347 U.S. 483, 495 (1954).\n...\n15. Brown, 347 U.S. at 497.\n```\n\n### When Both Party Names Needed\n\nUse both names when one party name is common or ambiguous:\n```\nSmith v. Jones, 500 F.3d at 105.\n```\n\n### Id. vs. Case Short Form\n\n| Situation | Use |\n|-----------|-----|\n| Same case, no intervening cites | Id. at [Page] |\n| Same case, intervening cites | Brown, 347 U.S. at [Page] |\n| Different case | Full short form |\n\n## Short Forms for Statutes (Rule 12.10)\n\n### Id. for Statutes\n\n```\n1. 42 U.S.C. § 1983 (2018).\n2. Id.                           (same section)\n3. Id. § 1985.                   (different section in same title)\n```\n\n### Section Symbol Short Form\n\nAfter full citation, within same discussion:\n```\nSection 1983 provides remedies for...\n```\n\nOr:\n```\nThe statute, § 1983, was enacted...\n```\n\n### Named Act Short Form\n\n```\n1. Civil Rights Act of 1964, 42 U.S.C. §§ 2000e to 2000e-17 (2018).\n...\n15. Civil Rights Act § 703.\n```\n\n## Infra (Rule 3.5)\n\n### When to Use Infra\n\nUse infra to refer to material appearing **later** in the document.\n\n```\nSee infra Part II.A.\nSee infra note 45 and accompanying text.\n```\n\n### Infra vs. Supra\n\n| Direction | Citation |\n|-----------|----------|\n| Earlier in document | supra |\n| Later in document | infra |\n\n### Cross-References\n\n```\nSee supra notes 10-15 and accompanying text.\nSee infra Section III.\nSee supra Part I.B.2.\n```\n\n## Common Short Form Errors\n\n### Id. Errors\n\n| Error | Problem | Correction |\n|-------|---------|------------|\n| Id. after intervening cite | Ambiguous reference | Use full short form |\n| Id. to ambiguous source | Multiple sources in prior note | Specify source |\n| Id. without preceding full cite | No referent | Add full citation |\n| Capitalizing mid-sentence | Wrong capitalization | Lowercase *id.* |\n\n### Supra Errors\n\n| Error | Problem | Correction |\n|-------|---------|------------|\n| Supra for cases | Wrong source type | Use case short form |\n| Supra for statutes | Wrong source type | Use statutory short form |\n| Wrong footnote number | Reader can't find source | Verify note number |\n| Missing \"at\" for pinpoint | Incomplete citation | Add \"at [Page]\" |\n\n### Hereinafter Errors\n\n| Error | Problem | Correction |\n|-------|---------|------------|\n| Hereinafter without supra | Incomplete short form | Include supra note # |\n| Hereinafter not defined | Reader confused | Define in full citation |\n| Hereinafter changed | Inconsistent | Use same short name throughout |\n\n## Decision Flowchart\n\n```\nNeed to cite a source you've cited before?\n│\n├── Is it a case?\n│   ├── Immediately preceding, no intervening? → Id. at [Page]\n│   └── Otherwise → [Party], [Vol.] [Reporter] at [Page]\n│\n├── Is it a statute?\n│   ├── Immediately preceding, no intervening? → Id. or Id. § [#]\n│   └── Otherwise → § [#] or [Name] § [#]\n│\n└── Is it a secondary source?\n    ├── Immediately preceding, no intervening? → Id. at [Page]\n    └── Otherwise → [Author], supra note [#], at [Page]\n```\n\n## Verification Checklist\n\nBefore using any short form:\n\n- [ ] Full citation exists earlier in document\n- [ ] For id.: no intervening citations\n- [ ] For id.: prior footnote is unambiguous (single source)\n- [ ] For supra: correct footnote number\n- [ ] For supra: author name matches full citation\n- [ ] For hereinafter: short name defined in full citation\n- [ ] Case short forms do NOT use supra\n- [ ] Statute short forms do NOT use supra\n- [ ] Capitalization correct for position in sentence\n",
        "skills/bluebook/references/signals-parentheticals.md": "# Introductory Signals and Parentheticals - Bluebook Rule 1\n\nComplete guidance for signals, parentheticals, and citation ordering per Bluebook 21st Edition.\n\n## The Purpose of Signals\n\nSignals communicate the **relationship** between the cited authority and the proposition in the text. Choosing the wrong signal misleads readers about how the source supports (or contradicts) your argument.\n\n<EXTREMELY-IMPORTANT>\n## Signal Verification Gate\n\nBefore using ANY signal:\n1. READ the source\n2. IDENTIFY the proposition you're supporting\n3. ASK: Does the source *directly state* or *implicitly support* the proposition?\n4. SELECT signal based on actual relationship\n5. VERIFY by re-reading source\n\n**Using the wrong signal is misrepresentation. Verify every signal choice.**\n</EXTREMELY-IMPORTANT>\n\n## Signal Categories (Rule 1.2)\n\n### Signals That Show Support\n\n#### [No Signal]\n\nUse when the cited authority **directly states** the proposition.\n\n```\nThe Constitution requires due process. U.S. Const. amend. XIV, § 1.\n```\n\nThe source explicitly contains the proposition—no inference required.\n\n#### *See*\n\nUse when the cited authority **clearly supports** the proposition but does not **directly state** it. Reader must make a small inferential step.\n\n```\nThe Due Process Clause protects certain unenumerated rights. See Griswold v. Connecticut, 381 U.S. 479 (1965).\n```\n\n*Griswold* supports this proposition but doesn't state it in these exact terms.\n\n#### *E.g.,*\n\nUse when the cited authority is **one of multiple** authorities that directly state the proposition. Signals that you're not citing all supporting authorities.\n\n```\nFederal courts have jurisdiction over diversity cases. E.g., 28 U.S.C. § 1332 (2018).\n```\n\n#### *See, e.g.,*\n\nCombines *see* and *e.g.*—the cited authority clearly supports but doesn't directly state the proposition, and there are other supporting authorities.\n\n```\nCourts routinely dismiss claims for lack of standing. See, e.g., Lujan v. Defs. of Wildlife, 504 U.S. 555 (1992).\n```\n\n#### *Accord*\n\nUse after citing one authority, to add additional authorities that state or support the same proposition.\n\n```\nDue process requires notice. Smith v. Jones, 500 U.S. 1 (1990); accord Doe v. Roe, 400 U.S. 50 (1985).\n```\n\n#### *See also*\n\nUse when the cited authority constitutes **additional support** for the proposition. The additional material is helpful but not directly on point.\n\n```\nLibel claims require proof of falsity. See New York Times Co. v. Sullivan, 376 U.S. 254 (1964). See also Gertz v. Robert Welch, Inc., 418 U.S. 323 (1974) (extending actual malice standard).\n```\n\n#### *Cf.*\n\nUse when the cited authority supports a proposition **by analogy**. The source supports a similar but distinct proposition.\n\n```\nAge discrimination claims require disparate treatment. Cf. Hazen Paper Co. v. Biggins, 507 U.S. 604 (1993) (holding that pension-status discrimination is not age discrimination).\n```\n\n**Always use a parenthetical** with *cf.* to explain the analogy.\n\n### Signals That Suggest a Comparison\n\n#### *Compare ... with ...*\n\nUse to compare authorities that illustrate a proposition through their contrast.\n\n```\nCompare Smith v. Jones, 500 F.3d 100 (9th Cir. 2007) (finding jurisdiction), with Doe v. Roe, 400 F.3d 50 (5th Cir. 2005) (finding no jurisdiction).\n```\n\nAlways include parentheticals explaining the comparison.\n\n### Signals That Indicate Contradiction\n\n#### *Contra*\n\nUse when the cited authority **directly states** the opposite of the proposition.\n\n```\nSome courts hold that X is required. Contra Brown v. White, 500 U.S. 1 (1990).\n```\n\n*Brown* directly states that X is not required.\n\n#### *But see*\n\nUse when the cited authority **clearly supports** a contrary proposition but doesn't directly state it.\n\n```\nThe statute requires intent. But see Smith v. Jones, 500 F.3d 100 (9th Cir. 2007) (applying negligence standard).\n```\n\n#### *But cf.*\n\nUse when the cited authority supports a contrary proposition **by analogy**.\n\n```\nStrict liability does not apply to services. But cf. Restatement (Third) of Torts: Products Liability § 19 (Am. L. Inst. 1998) (applying strict liability to product-related services).\n```\n\n**Always use a parenthetical** with *but cf.*\n\n### Signal for Background\n\n#### *See generally*\n\nUse when the cited authority provides **helpful background** but does not directly support the proposition.\n\n```\nFor an overview of Fourth Amendment doctrine, see generally Orin S. Kerr, An Equilibrium-Adjustment Theory of the Fourth Amendment, 125 Harv. L. Rev. 476 (2011).\n```\n\n## Signal Order Within a Citation Sentence (Rule 1.3)\n\nWhen multiple signals appear in a single citation sentence, they must appear in this order:\n\n1. [no signal]\n2. *E.g.,*\n3. *Accord*\n4. *See*\n5. *See also*\n6. *Cf.*\n7. *Compare ... with ...*\n8. *Contra*\n9. *But see*\n10. *But cf.*\n11. *See generally*\n\n**Separate signal groups with semicolons:**\n```\nU.S. Const. art. I, § 8; see Brown v. Board of Education, 347 U.S. 483 (1954); cf. Plessy v. Ferguson, 163 U.S. 537 (1896).\n```\n\n## Citation Sentences vs. Citation Clauses (Rule 1.1)\n\n### Citation Sentences\n\nA citation sentence follows a textual sentence and cites authority for that sentence.\n\n```\nThe Constitution requires due process. U.S. Const. amend. XIV, § 1.\n```\n\n**Capitalize** signals at the beginning of citation sentences.\n\n### Citation Clauses\n\nA citation clause is embedded within a textual sentence or refers to only part of it.\n\n```\nThe Supreme Court has held, see Brown v. Board of Education, 347 U.S. 483 (1954), that separate is inherently unequal.\n```\n\n**Do not capitalize** signals in citation clauses.\n\n### Punctuation\n\n| Position | Punctuation |\n|----------|-------------|\n| End of citation sentence | Period |\n| Between citations in same sentence | Semicolon |\n| Citation clause (embedded) | Commas on both sides |\n\n## Parentheticals (Rule 1.5)\n\n### When Parentheticals Are Required\n\n**Always required with:**\n- *Cf.*\n- *But cf.*\n- *Compare ... with ...*\n- Any source that doesn't directly state the proposition\n\n**Strongly recommended with:**\n- *See*\n- *See also*\n- *But see*\n\n### Parenthetical Form\n\nBegin with a present participle or quoted material:\n\n**Present participle:**\n```\n(holding that separate is inherently unequal)\n(finding no constitutional violation)\n(noting the difficulty of the issue)\n(rejecting defendant's argument)\n```\n\n**Quoted material:**\n```\n(\"Separate educational facilities are inherently unequal.\")\n```\n\n### Parenthetical Content\n\nExplain **what the source says** or **how it supports** the proposition:\n\n```\nBrown v. Board of Education, 347 U.S. 483 (1954) (holding that separate educational facilities are inherently unequal under the Equal Protection Clause).\n```\n\n### Weight of Authority Parentheticals\n\nIndicate procedural posture or authorship:\n\n```\n(en banc)\n(per curiam)\n(plurality opinion)\n(Thomas, J., dissenting)\n(Stevens, J., concurring in the judgment)\n(5-4 decision)\n```\n\n### Order of Multiple Parentheticals\n\n1. Weight of authority (en banc, per curiam)\n2. \"Quoting\" or \"citing\" information\n3. Explanatory parenthetical\n\n```\nSmith v. Jones, 500 F.3d 100 (9th Cir. 2007) (en banc) (quoting Roe v. Doe, 400 F.3d 50, 60 (5th Cir. 2005)) (holding that strict liability applies).\n```\n\n## Order of Authorities Within a Signal (Rule 1.4)\n\n### General Order of Authority Types\n\nWhen citing multiple authorities with the same signal:\n\n1. Constitutions (federal, then state alphabetically)\n2. Statutes (federal, then state alphabetically)\n3. Treaties\n4. Cases (federal by court level, then state alphabetically)\n5. Legislative materials\n6. Administrative and executive materials\n7. Resolutions, decisions, and regulations of intergovernmental organizations\n8. Records, briefs, and petitions\n9. Secondary materials\n10. Cross-references to the author's own work\n\n### Order of Cases\n\n**Federal courts (by court hierarchy):**\n1. Supreme Court\n2. Courts of Appeals (by circuit number)\n3. District Courts (alphabetically by state)\n4. Other federal courts\n\n**State courts:**\nAlphabetically by state, then by court hierarchy within each state.\n\n**Within same court:**\nReverse chronological order (most recent first).\n\n### Example\n\n```\nSee U.S. Const. amend. XIV; 42 U.S.C. § 1983 (2018); Brown v. Board of Education, 347 U.S. 483 (1954); Smith v. Jones, 500 F.3d 100 (9th Cir. 2007); Doe v. Roe, 400 F.3d 50 (5th Cir. 2005).\n```\n\n## String Citations (Rule 1.4)\n\n### When to Use String Citations\n\nString citations (multiple authorities in one citation sentence) are appropriate when:\n1. Showing a trend or widespread agreement\n2. Demonstrating a circuit split\n3. Providing comprehensive authority for an important proposition\n\n### When to Avoid String Citations\n\nAvoid string citations when:\n1. One strong authority suffices\n2. The additional authorities add no new support\n3. The string is so long readers will skip it\n\n**Quality over quantity.** Cite the most authoritative sources; don't pad with marginal authorities.\n\n### Formatting String Citations\n\nSeparate authorities with semicolons:\n```\nSee Smith v. Jones, 500 F.3d 100 (9th Cir. 2007); Doe v. Roe, 400 F.3d 50 (5th Cir. 2005); Brown v. White, 300 F.3d 25 (2d Cir. 2003).\n```\n\n## Common Signal Errors\n\n### Choosing the Wrong Signal\n\n| Error | Correct Signal | Explanation |\n|-------|----------------|-------------|\n| [no signal] when source doesn't directly state | *See* | Source supports but doesn't state proposition |\n| *See* when source directly states | [no signal] | No inference needed |\n| *Cf.* without parenthetical | *Cf.* (...) | Always explain the analogy |\n| *See generally* for direct support | *See* or [no signal] | Reserve for background |\n\n### Signal Capitalization Errors\n\n| Error | Correction |\n|-------|------------|\n| see Smith v. Jones | *See* Smith v. Jones (sentence start) |\n| See id. | *see* id. (after another signal) |\n\n### Missing Parentheticals\n\n| Error | Correction |\n|-------|------------|\n| Cf. Smith v. Jones... | Cf. Smith v. Jones... (explaining the analogy) |\n| Compare X with Y. | Compare X (point A) with Y (contrasting point). |\n\n## Rationalization Table - STOP If You Think:\n\n| Thought | Reality | Do Instead |\n|---------|---------|------------|\n| \"No signal is fine here\" | Source may not directly state proposition | CHECK: Does it say exactly this? |\n| \"*See* is always safe\" | *See* implies inference; wrong if direct | VERIFY: Direct statement vs. support |\n| \"Parenthetical is optional\" | For *cf.*, *compare*, it's required | ADD parenthetical explaining relationship |\n| \"Order doesn't matter\" | Wrong order confuses readers | FOLLOW Rule 1.4 ordering |\n| \"More citations = stronger\" | Padding weakens credibility | CITE strongest authorities only |\n\n## Verification Checklist\n\nBefore finalizing signals and parentheticals:\n\n- [ ] Signal accurately reflects source's relationship to proposition\n- [ ] [No signal] used only when source directly states proposition\n- [ ] *See* used for clear support requiring inference\n- [ ] *Cf.* and *but cf.* have explanatory parentheticals\n- [ ] *Compare ... with ...* has parentheticals for both sources\n- [ ] Signal is capitalized correctly for position\n- [ ] Authorities within signal are in correct order\n- [ ] Parentheticals begin with present participle or quotation\n- [ ] Weight of authority parentheticals appear first\n- [ ] String citations are warranted (not padding)\n",
        "skills/bluebook/references/statutes.md": "# Statutory and Regulatory Citations - Bluebook Rules 12-14\n\nComplete guidance for citing statutes, regulations, and legislative materials per Bluebook 21st Edition.\n\n## Federal Statutes (Rule 12)\n\n### Basic Form\n\n```\n[Title] [Code] § [Section] ([Year]).\n```\n\n**Example:**\n```\n42 U.S.C. § 1983 (2018).\n```\n\n### United States Code (U.S.C.)\n\n**Preferred citation:** Use U.S.C. (official code) when available.\n\n**Alternative citations (when U.S.C. unavailable):**\n- U.S.C.A. (West)\n- U.S.C.S. (LexisNexis)\n\n**Year:** Cite to year of code edition, not year of enactment.\n\n```\nCorrect:   42 U.S.C. § 1983 (2018).\nWrong:     42 U.S.C. § 1983 (1871).    ← enactment year\n```\n\n### Multiple Sections\n\n**Consecutive sections:**\n```\n42 U.S.C. §§ 1983-1985 (2018).\n```\n\n**Non-consecutive sections:**\n```\n42 U.S.C. §§ 1983, 1985, 1988 (2018).\n```\n\n### Subsections\n\n```\n42 U.S.C. § 1983(a) (2018).\n42 U.S.C. § 1983(a)(1) (2018).\n42 U.S.C. § 1983(a)(1)(A) (2018).\n```\n\n### Supplements\n\nWhen citing provisions in supplements:\n```\n42 U.S.C. § 1983 (2018 & Supp. II 2020).\n```\n\n### Popular Names\n\nMay include popular name before or after citation:\n```\nCivil Rights Act of 1964, 42 U.S.C. §§ 2000e to 2000e-17 (2018).\n```\n\nOr:\n```\n42 U.S.C. §§ 2000e to 2000e-17 (2018) (Civil Rights Act of 1964).\n```\n\n## Session Laws (Rule 12.4)\n\n### When to Use\n\n- New statutes not yet in U.S.C.\n- Citing specific session law provisions\n- Historical statutory research\n\n### Public Laws\n\n```\nPub. L. No. 104-193, § 103, 110 Stat. 2105, 2112 (1996).\n```\n\nFormat:\n```\nPub. L. No. [Congress]-[Law No.], § [Section], [Vol.] Stat. [First Page], [Pinpoint] ([Year]).\n```\n\n### Statutes at Large\n\n```\nAct of July 2, 1890, ch. 647, 26 Stat. 209.\n```\n\n## State Statutes (Rule 12.3)\n\n### Basic Form\n\n```\n[State Code Abbrev.] [Topic] § [Section] ([Publisher] [Year]).\n```\n\n### Examples by Format\n\n**Subject-matter codes (California):**\n```\nCal. Penal Code § 187 (West 2014).\n```\n\n**Title/chapter codes (Texas):**\n```\nTex. Bus. & Com. Code Ann. § 17.50 (West 2011).\n```\n\n**Single-volume codes (Delaware):**\n```\nDel. Code Ann. tit. 8, § 102 (2020).\n```\n\n### State Code Abbreviations (Table T1)\n\nEach state has specific abbreviation requirements. Always consult Table T1.\n\n| State | Official Code | Example |\n|-------|---------------|---------|\n| California | Cal. [Subject] Code | Cal. Civ. Code § 1542 |\n| New York | N.Y. [Subject] Law | N.Y. C.P.L.R. § 3211 |\n| Texas | Tex. [Subject] Code Ann. | Tex. Fam. Code Ann. § 6.001 |\n\n### Publisher\n\nInclude publisher for unofficial codes. Omit for official codes if Table T1 indicates.\n\n## Constitutional Provisions (Rule 11)\n\n### Federal Constitution\n\n```\nU.S. Const. art. I, § 8, cl. 3.\nU.S. Const. amend. XIV, § 1.\nU.S. Const. pmbl.\n```\n\n**No date for currently effective provisions.**\n\n### State Constitutions\n\n```\nCal. Const. art. I, § 1.\nN.Y. Const. art. VI, § 1.\n```\n\n### Amended or Repealed Provisions\n\n```\nU.S. Const. amend. XVIII (repealed 1933).\nU.S. Const. art. I, § 2, cl. 3, amended by U.S. Const. amend. XIV, § 2.\n```\n\n## Federal Regulations (Rule 14.2)\n\n### Code of Federal Regulations (C.F.R.)\n\n```\n[Title] C.F.R. § [Section] ([Year]).\n```\n\n**Example:**\n```\n17 C.F.R. § 240.10b-5 (2020).\n```\n\n### Federal Register\n\nFor rules not yet in C.F.R.:\n```\n[Vol.] Fed. Reg. [Page] ([Date]) (to be codified at [C.F.R. cite]).\n```\n\n**Example:**\n```\n85 Fed. Reg. 12345 (Mar. 2, 2020) (to be codified at 17 C.F.R. pt. 240).\n```\n\n### Proposed Rules\n\n```\n85 Fed. Reg. 12345 (proposed Mar. 2, 2020) (to be codified at 17 C.F.R. pt. 240).\n```\n\n## State Regulations (Rule 14.3)\n\nFollow format in Table T1 for each state.\n\n**Example (California):**\n```\nCal. Code Regs. tit. 8, § 3203 (2020).\n```\n\n## Legislative Materials (Rule 13)\n\n### Bills\n\n**Federal:**\n```\nH.R. 1234, 116th Cong. § 2 (2020).\nS. 567, 116th Cong. (2019).\n```\n\n**Enacted bills:** Cite as session laws (Pub. L. No.) or codified statutes.\n\n### Resolutions\n\n```\nH.R. Res. 123, 116th Cong. (2020).\nS. Res. 456, 116th Cong. (2019).\n```\n\n### Committee Reports\n\n**House:**\n```\nH.R. Rep. No. 116-123, at 5 (2019).\n```\n\n**Senate:**\n```\nS. Rep. No. 116-45, at 10 (2020).\n```\n\n**Conference:**\n```\nH.R. Rep. No. 116-789 (Conf. Rep.), at 15 (2020).\n```\n\n### Hearings\n\n```\nHearing Title: Hearing on [Subject] Before the [Committee], [Cong.] ([Year]) (statement of [Witness]).\n```\n\n**Example:**\n```\nCybersecurity Threats: Hearing Before the S. Comm. on Homeland Sec., 116th Cong. 25 (2020) (statement of Christopher Krebs, Dir., Cybersecurity & Infrastructure Sec. Agency).\n```\n\n### Congressional Debates\n\n**Congressional Record:**\n```\n[Vol.] Cong. Rec. [Page] ([Year]) (statement of [Member]).\n```\n\n**Example:**\n```\n165 Cong. Rec. S1234 (daily ed. Feb. 10, 2019) (statement of Sen. Smith).\n```\n\n## Short Forms for Statutes (Rule 12.10)\n\n### Id.\n\n```\n1. 42 U.S.C. § 1983 (2018).\n2. Id.\n3. Id. § 1985.\n```\n\n### Section Symbol Alone\n\nAfter full citation in same general discussion:\n```\nSection 1983 provides...\n```\n\nOr:\n```\n§ 1983 provides...\n```\n\n### Named Acts\n\n```\n1. Civil Rights Act of 1964, 42 U.S.C. §§ 2000e to 2000e-17 (2018).\n...\n15. Civil Rights Act § 703.\n```\n\n## Common Errors\n\n### Section Symbol Errors\n\n| Error | Correction |\n|-------|------------|\n| Section 1983 | § 1983 (in citations) |\n| §1983 | § 1983 (space required) |\n| Sec. 1983 | § 1983 |\n| ss. 1983-1985 | §§ 1983-1985 |\n\n### Code Errors\n\n| Error | Correction |\n|-------|------------|\n| 42 USC § 1983 | 42 U.S.C. § 1983 |\n| 42 U.S.C. §1983 | 42 U.S.C. § 1983 |\n| 42 U.S.C., § 1983 | 42 U.S.C. § 1983 |\n\n### Year Errors\n\n| Error | Correction |\n|-------|------------|\n| 42 U.S.C. § 1983 | 42 U.S.C. § 1983 (2018) ← year required |\n| 42 U.S.C. § 1983 (1871) | 42 U.S.C. § 1983 (2018) ← code year, not enactment |\n\n## Administrative Agency Materials\n\n### Agency Decisions\n\n```\n[Case Name], [Vol.] [Agency Reporter] [Page] ([Agency abbrev.] [Year]).\n```\n\n**Example (SEC):**\n```\nIn re XYZ Corp., 50 S.E.C. 123 (1989).\n```\n\n### Advisory Opinions and Guidance\n\n```\n[Agency], [Title], [Citation or URL] ([Date]).\n```\n\n**Example:**\n```\nSEC, Staff Accounting Bulletin No. 99, 64 Fed. Reg. 45150 (Aug. 19, 1999).\n```\n\n## Treaties and International Agreements (Rule 21.4)\n\n### Basic Form\n\n```\n[Name], [Parties], [Date], [Treaty Source].\n```\n\n**Example:**\n```\nNorth American Free Trade Agreement, U.S.-Can.-Mex., Dec. 17, 1992, 32 I.L.M. 289.\n```\n\n### U.S. Treaties\n\n```\n[Name], [Other Party], [Date], [U.S. Source], [I.L.M. or other source].\n```\n\n## Verification Checklist\n\nBefore finalizing any statutory citation:\n\n- [ ] Correct code cited (U.S.C., not U.S.C.A. if available)\n- [ ] Section symbol (§) used with space before number\n- [ ] Double section symbol (§§) for multiple sections\n- [ ] Year is code edition year, not enactment year\n- [ ] Supplements cited if applicable\n- [ ] Popular name included if helpful\n- [ ] Publisher included for unofficial state codes\n- [ ] Subsection parentheses formatted correctly\n\n## Special Situations\n\n### Scattered Sections\n\nWhen codified in scattered sections:\n```\nEmployee Retirement Income Security Act of 1974, Pub. L. No. 93-406, 88 Stat. 829 (codified as amended in scattered sections of 26 and 29 U.S.C.).\n```\n\n### Repealed Statutes\n\n```\n18 U.S.C. § 1030 (2018), repealed by [cite to repealing legislation].\n```\n\n### Amended Statutes\n\nWhen citing prior version:\n```\n42 U.S.C. § 1983 (1982), amended by [cite].\n```\n",
        "skills/dev-debug/SKILL.md": "---\nname: dev-debug\nversion: 1.0\ndescription: \"This skill should be used when the user asks to 'debug', 'fix bug', 'investigate error', 'why is it broken', 'trace root cause', 'find the bug', or needs systematic bug investigation and fixing with verification-driven methodology using ralph loops.\"\n---\n\n**Announce:** \"I'm using dev-debug for systematic bug investigation.\"\n\n<EXTREMELY-IMPORTANT>\n## GUI Application Debugging Gate\n\nWhen debugging GUI applications, you MUST complete the execution gates from dev-tdd during REPRODUCE and VERIFY phases:\n\n```\nGATE 1: BUILD\nGATE 2: LAUNCH (with file-based logging)\nGATE 3: WAIT\nGATE 4: CHECK PROCESS\nGATE 5: READ LOGS ← MANDATORY, CANNOT SKIP\nGATE 6: VERIFY LOGS\nTHEN: Test reproduction or verification\n```\n\n**Critical phases requiring gates:**\n\n**REPRODUCE phase:**\n- Build → Launch with logs → Wait → Check running → **READ LOGS** → Verify bug appears in logs\n- Only after reading logs can you claim \"bug reproduced\"\n\n**VERIFY phase:**\n- Build → Launch with logs → Wait → Check running → **READ LOGS** → Verify bug is gone from logs\n- Only after reading logs can you claim \"bug fixed\"\n\n**You loaded dev-tdd via ralph-loop. Follow the gates for GUI debugging.**\n</EXTREMELY-IMPORTANT>\n\n## Where This Fits\n\n```\nMain Chat (you)                    Task Agent\n─────────────────────────────────────────────────────\ndev-debug (this skill)\n  → ralph loop (one per bug)\n    → dev-delegate (spawn agents)\n      → Task agent ──────────────→ investigates\n                                   writes regression test\n                                   implements fix\n```\n\n**Main chat orchestrates.** Task agents investigate and fix.\n\n## Contents\n\n- [The Iron Law of Debugging](#the-iron-law-of-debugging)\n- [The Iron Law of Delegation](#the-iron-law-of-delegation)\n- [The Process](#the-process)\n- [The Four Phases](#the-four-phases)\n- [If Max Iterations Reached](#if-max-iterations-reached)\n\n# Systematic Debugging\n\n<EXTREMELY-IMPORTANT>\n## The Iron Law of Debugging\n\n**NO FIXES WITHOUT ROOT CAUSE INVESTIGATION FIRST. This is not negotiable.**\n\nBefore writing ANY fix, you MUST:\n1. Reproduce the bug (with a test)\n2. Trace the data flow\n3. Form a specific hypothesis\n4. Test that hypothesis\n5. Only THEN write a fix (with a regression test first!)\n\n**If you catch yourself about to write a fix without investigation, STOP.**\n</EXTREMELY-IMPORTANT>\n\n<EXTREMELY-IMPORTANT>\n## The Iron Law of Delegation\n\n**MAIN CHAT MUST NOT WRITE CODE. This is not negotiable.**\n\nMain chat orchestrates the ralph loop. Task agents do the work:\n- **Investigation**: Task agents read code, run tests, gather evidence\n- **Fixes**: Task agents write regression tests and fixes\n\n| Main Chat Does | Task Agents Do |\n|----------------|----------------|\n| Start ralph loop | Investigate root cause |\n| Spawn Task agents | Run tests, read code |\n| Review findings | Write regression tests |\n| Verify fix | Implement fixes |\n\n**If you're about to edit code directly, STOP and delegate instead.**\n</EXTREMELY-IMPORTANT>\n\n## The Process\n\nUnlike implementation (per-task loops), debugging uses **ONE loop per bug**:\n\n```\n1. Start ralph loop for the bug\n   Skill(skill=\"ralph-loop:ralph-loop\", args=\"Debug: [SYMPTOM] --max-iterations 15 --completion-promise FIXED\")\n\n2. Inside loop: spawn Task agent for investigation/fix\n   → Read(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-delegate/SKILL.md\")\n\n3. Task agent follows 4-phase debug protocol\n\n4. When regression test passes → output promise\n   <promise>FIXED</promise>\n\n5. Bug fixed, loop ends\n```\n\n### Step 1: Start Ralph Loop\n\n**IMPORTANT:** Avoid parentheses `()` in the prompt.\n\n```\nSkill(skill=\"ralph-loop:ralph-loop\", args=\"Debug: [SYMPTOM] --max-iterations 15 --completion-promise FIXED\")\n```\n\n### Step 2: Spawn Task Agent\n\nUse dev-delegate, but with debug-specific instructions:\n\n```\nTask(subagent_type=\"general-purpose\", prompt=\"\"\"\nDebug [SYMPTOM] following systematic protocol.\n\n## Context\n- Read .claude/LEARNINGS.md for prior hypotheses\n- Read .claude/SPEC.md for expected behavior\n\n## Debug Protocol (4 Phases)\n\n### Phase 1: Investigate\n- Add debug logging to suspected code path\n- Reproduce the bug with a test\n- Document: \"Reproduced with [test], output: [error]\"\n\n### Phase 2: Analyze\n- Trace data flow through the code\n- Compare to working code paths\n- Document findings in LEARNINGS.md\n\n### Phase 3: Hypothesize\n- Form ONE specific hypothesis\n- Test it with minimal change\n- If wrong: document what was ruled out\n- If right: proceed to fix\n\n### Phase 4: Fix\n- Write regression test FIRST (must fail before fix)\n- Implement minimal fix\n- Run test, see it PASS\n- Run full test suite\n\n## Output\nReport:\n- Hypothesis tested\n- Root cause (if found)\n- Regression test written\n- Fix applied (or blockers)\n\"\"\")\n```\n\n### Step 3: Verify and Complete\n\nAfter Task agent returns, verify:\n- [ ] Regression test FAILS before fix\n- [ ] Regression test PASSES after fix\n- [ ] Root cause documented in LEARNINGS.md\n- [ ] All existing tests still pass\n\n**If ALL pass → output the promise:**\n```\n<promise>FIXED</promise>\n```\n\n**If ANY fail → iterate (don't output promise yet).**\n\n## The Four Phases\n\n| Phase | Purpose | Output |\n|-------|---------|--------|\n| **Investigate** | Reproduce, trace data flow | Bug reproduction |\n| **Analyze** | Compare working vs broken | Findings documented |\n| **Hypothesize** | ONE specific hypothesis | Hypothesis tested |\n| **Fix** | Regression test → fix | Tests pass |\n\n## The Gate Function\n\nBefore claiming ANY bug is fixed:\n\n```\n1. REPRODUCE → Run test, see bug manifest\n2. INVESTIGATE → Trace data flow, form hypothesis\n3. TEST → Verify hypothesis with minimal change\n4. FIX → Write regression test FIRST (see it FAIL)\n5. VERIFY → Run fix, see regression test PASS\n6. CONFIRM → Run full test suite, no regressions\n7. CLAIM → Only after steps 1-6\n```\n\n**Skipping any step is guessing, not debugging.**\n\n## Rationalization Prevention\n\nThese thoughts mean STOP—you're about to skip the protocol:\n\n| Thought | Reality |\n|---------|---------|\n| \"I know exactly what this is\" | Knowing ≠ verified. Investigate anyway. |\n| \"Let me just try this fix\" | Guessing. Form hypothesis first. |\n| \"The fix is obvious\" | Obvious fixes often mask deeper issues. |\n| \"I've seen this before\" | This instance may be different. Verify. |\n| \"No need for regression test\" | Every fix needs a regression test. Period. |\n| \"It works now\" | \"Works now\" ≠ \"fixed correctly\". Run full suite. |\n| \"I'll add the test later\" | You won't. Write it BEFORE the fix. |\n| **\"Log checking proves fix works\"** | **Logs prove code ran, not that output is correct. Verify actual results.** |\n| **\"It stopped failing\"** | **Stopped failing ≠ fixed. Could be hiding the symptom. Need E2E.** |\n| **\"The error is gone\"** | **No error ≠ correct behavior. Verify expected output.** |\n| **\"Regression test is too complex\"** | **If too complex to test, too complex to know it's fixed.** |\n\n### Fake Fix Verification - STOP\n\n**These do NOT prove a bug is fixed:**\n\n| ❌ Fake Verification | ✅ Real Verification |\n|----------------------|----------------------|\n| \"Error message is gone\" | \"Regression test passes + output matches spec\" |\n| \"Logs show correct path taken\" | \"E2E test verifies user-visible behavior\" |\n| \"No exception thrown\" | \"Test asserts expected data returned\" |\n| \"Process exits 0\" | \"Functional test confirms correct side effects\" |\n| \"Changed one line, seems fine\" | \"Regression test failed before, passes after\" |\n| \"Can't reproduce anymore\" | \"Regression test reproduces it, fix makes it pass\" |\n\n**Red Flag:** If you're claiming \"fixed\" based on absence of errors rather than presence of correct behavior - STOP. That's symptom suppression, not bug fixing.\n\n### Red Flags - STOP If You Think:\n\n| Thought | Why It's Wrong | Do Instead |\n|---------|----------------|------------|\n| \"Let's just try this fix\" | You're guessing | Investigate first |\n| \"I'm pretty sure it's this\" | \"Pretty sure\" ≠ root cause | Gather evidence |\n| \"This should work\" | Hope is not debugging | Test your hypothesis |\n| \"Let me change a few things\" | Multiple changes = can't learn | ONE hypothesis at a time |\n\n## If Max Iterations Reached\n\nRalph exits after max iterations. **Still do NOT ask user to manually verify.**\n\nMain chat should:\n1. **Summarize** hypotheses tested (from LEARNINGS.md)\n2. **Report** what was ruled out and what remains unclear\n3. **Ask user** for direction:\n   - A) Start new loop with different investigation angle\n   - B) Add more logging to specific code path\n   - C) User provides additional context\n   - D) User explicitly requests manual verification\n\n**Never default to \"please verify manually\".** Always exhaust automation first.\n\n## When Fix Requires Substantial Changes\n\nIf root cause reveals need for significant refactoring:\n\n1. Document root cause in LEARNINGS.md\n2. Complete debug loop with `<promise>FIXED</promise>` for the investigation\n3. Use `Skill(skill=\"workflows:dev\")` for the implementation work\n\nDebug finds the problem. The dev workflow implements the solution.\n\n## Failure Recovery Protocol\n\n**Pattern from oh-my-opencode: After 3 consecutive failures, escalate.**\n\n### 3-Failure Trigger\n\nIf you attempt 3 hypotheses and ALL fail:\n\n```\nFailure 1: Hypothesis A tested → still broken\nFailure 2: Hypothesis B tested → still broken\nFailure 3: Hypothesis C tested → still broken\n→ TRIGGER RECOVERY PROTOCOL\n```\n\n### Recovery Steps\n\n1. **STOP** all further debugging attempts\n   - No more \"let me try one more thing\"\n   - No guessing or throwing fixes at the wall\n\n2. **REVERT** to last known working state\n   - `git checkout <last-working-commit>`\n   - Or revert specific files: `git checkout HEAD~N -- file.ts`\n   - Document what was attempted in `.claude/RECOVERY.md`\n\n3. **DOCUMENT** what was attempted\n   - All 3 hypotheses tested\n   - Evidence gathered\n   - Why each failed\n   - What this rules out\n\n4. **CONSULT** with user\n   - \"I've tested 3 hypotheses. All failed. Here's what I've ruled out...\"\n   - Present evidence from investigation\n   - Request: additional context, different investigation angle, or pair debugging\n\n5. **ASK USER** before proceeding\n   - Option A: Start new ralph loop with different approach\n   - Option B: User provides domain knowledge/context\n   - Option C: Escalate to more experienced reviewer\n   - Option D: Accept this as a blocker and document\n\n**NO EVIDENCE = NOT FIXED** (hard rule)\n\n### Recovery Checklist\n\nBefore claiming a bug is fixed after multiple failures:\n\n- [ ] At least 1 hypothesis succeeded (not just \"stopped failing\")\n- [ ] Regression test exists and PASSES\n- [ ] Full test suite passes (no new failures)\n- [ ] Changes are minimal and targeted\n- [ ] Root cause is understood (not just symptom suppressed)\n\n### Anti-Patterns After Failures\n\n**DON'T:**\n- Keep trying random fixes (\"maybe if I change this...\")\n- Expand scope to \"related\" issues\n- Make multiple changes at once\n- Skip the regression test \"this time\"\n- Claim fix without evidence\n\n**DO:**\n- Stop and document what failed\n- Revert to clean state\n- Consult before continuing\n- Follow recovery protocol exactly\n- Require evidence for completion\n\n### Example Recovery Flow\n\n```\nAttempt 1: \"Bug is in parser\" → Added logging → Still broken\nAttempt 2: \"Bug is in validator\" → Fixed validation → Still broken\nAttempt 3: \"Bug is in transformer\" → Rewrote transform → Still broken\n\n→ RECOVERY PROTOCOL:\n1. STOP (no attempt 4)\n2. REVERT all changes: git checkout HEAD -- src/\n3. DOCUMENT in .claude/RECOVERY.md:\n   - Ruled out: parser, validator, transformer\n   - Evidence: logs show data correct at each stage\n   - Hypothesis: Bug might be in consumer, not producer\n4. ASK USER:\n   \"I've ruled out the parser/validator/transformer chain.\n    Logs show data is correct when it leaves our system.\n    Next investigation angle: check the consumer.\n    Should I:\n    A) Start new loop investigating consumer\n    B) Pause for your input on where else to look\"\n```\n",
        "skills/dev-design/SKILL.md": "---\nname: dev-design\ndescription: This skill should be used when the user asks to \"propose architecture\", \"design implementation approach\", \"choose between approaches\", or in Phase 4 of /dev workflow after exploration is complete. Proposes 2-3 architecture approaches with clear trade-offs, decomposes features into independent tasks, and obtains explicit user approval before implementation begins.\nversion: 0.1.0\n---\n\n**Announce:** \"Using dev-design (Phase 4) to propose implementation approaches and obtain user approval.\"\n\n## Contents\n\n- [The Iron Law of Design](#the-iron-law-of-design)\n- [What Design Does](#what-design-does)\n- [Process](#process)\n- [Approach Categories](#approach-categories)\n- [PLAN.md Format](#planmd-format)\n- [Red Flags](#red-flags---stop-if-youre-about-to)\n- [Output](#output)\n\n# Architecture Design with User Gate\n\nPropose implementation approaches, explain trade-offs, get user approval.\n**Prerequisites:** SPEC.md finalized, exploration complete, clarifications resolved.\n\n<EXTREMELY-IMPORTANT>\n## The Iron Law of Design\n\n**YOU MUST GET USER APPROVAL BEFORE IMPLEMENTATION. This is not negotiable.**\n\nAfter presenting approaches:\n1. Show 2-3 options with trade-offs\n2. Lead with your recommendation\n3. **Ask user which approach**\n4. **Wait for explicit approval**\n\nImplementation CANNOT start without user saying \"Yes\" or choosing an approach.\n\n**STOP - you're about to implement without user approval.**\n</EXTREMELY-IMPORTANT>\n\n## What Design Does\n\n| DO | DON'T |\n|----|-------|\n| Propose 2-3 approaches | Implement anything |\n| Explain trade-offs clearly | Make the choice for user |\n| Lead with recommendation | Present without opinion |\n| Get explicit approval | Assume approval |\n| Write PLAN.md | Skip the user gate |\n\n**Design answers: HOW to build it and WHY this approach**\n**Implement executes: the approved approach** (next phase, after gate)\n\n## Process\n\n### 1. Review Inputs\n\nBefore designing, ensure the following exist:\n- `.claude/SPEC.md` - final requirements\n- Exploration findings - key files, patterns\n- Clarified decisions - edge cases, integrations\n\n### 2. Propose 2-3 Approaches\n\nEach approach should address the same requirements differently:\n\n**Approach A: Minimal Changes**\n- Smallest diff, maximum reuse\n- Trade-off: May be less clean, tech debt\n\n**Approach B: Clean Architecture**\n- Best patterns, maintainability\n- Trade-off: More changes, longer implementation\n\n**Approach C: Pragmatic Balance**\n- Balance of speed and quality\n- Trade-off: Compromise on both\n\n### 3. Present with Trade-offs\n\nUse the AskUserQuestion tool to present approaches:\n\n```python\n# AskUserQuestion: Present 2-3 architecture approaches with trade-offs for user selection\nAskUserQuestion(questions=[{\n  \"question\": \"Which architecture approach should we use?\",\n  \"header\": \"Architecture\",\n  \"options\": [\n    {\n      \"label\": \"Pragmatic Balance (Recommended)\",\n      \"description\": \"Extend existing AuthService with new method. ~150 lines changed. Balances reuse with clean separation.\"\n    },\n    {\n      \"label\": \"Minimal Changes\",\n      \"description\": \"Add logic to existing endpoint. ~50 lines changed. Fast but increases coupling.\"\n    },\n    {\n      \"label\": \"Clean Architecture\",\n      \"description\": \"New service with full abstraction. ~300 lines. Most maintainable but longest to build.\"\n    }\n  ],\n  \"multiSelect\": false\n}])\n```\n\n**Key principles:**\n- Lead with recommendation (first option + \"Recommended\")\n- Concrete numbers (lines changed, files affected)\n- Clear trade-offs for each\n- Reference specific files from exploration\n\n### 4. Feature Decomposition Check\n\n**CRITICAL:** Before writing PLAN.md, check if this is actually multiple features.\n\nReview the scope and ask:\n\n```python\n# AskUserQuestion: Determine if feature should be split into independent tasks\nAskUserQuestion(questions=[{\n  \"question\": \"Is this one cohesive feature or multiple independent features?\",\n  \"header\": \"Scope\",\n  \"options\": [\n    {\n      \"label\": \"One feature\",\n      \"description\": \"Implement everything together in one branch/worktree\"\n    },\n    {\n      \"label\": \"Multiple features\",\n      \"description\": \"Break into separate features, each with own branch/worktree/PR\"\n    }\n  ],\n  \"multiSelect\": false\n}])\n```\n\n**If \"Multiple features\":**\n\n1. **List the independent features** identified from SPEC.md:\n   ```\n   Based on the requirements, this breaks into:\n   1. Theme infrastructure (color system, theme provider)\n   2. Settings UI (theme selector component)\n   3. Component updates (update 20+ components to use theme)\n   4. Persistence layer (save user preference)\n\n   Each can be implemented and PR'd independently.\n   ```\n\n2. **Ask which to tackle first:**\n   ```python\n   # AskUserQuestion: Prioritize which feature to implement first\n   AskUserQuestion(questions=[{\n     \"question\": \"Which feature should we implement first?\",\n     \"header\": \"Priority\",\n     \"options\": [\n       {\"label\": \"Theme infrastructure (Recommended)\", \"description\": \"Foundation that others depend on\"},\n       {\"label\": \"Settings UI\", \"description\": \"UI for theme selection\"},\n       {\"label\": \"Component updates\", \"description\": \"Apply themes to components\"},\n       {\"label\": \"Persistence layer\", \"description\": \"Save user preference\"}\n     ],\n     \"multiSelect\": false\n   }])\n   ```\n\n3. **Write PLAN.md for ONLY the chosen feature**\n\n4. **Document remaining features** in `.claude/BACKLOG.md`:\n   ```markdown\n   # Feature Backlog\n\n   ## Dark Mode Implementation\n\n   ### Completed\n   - [ ] None yet\n\n   ### Next Up\n   - [ ] Theme infrastructure\n   - [ ] Settings UI\n   - [ ] Component updates\n   - [ ] Persistence layer\n\n   **Current Focus:** Theme infrastructure\n   ```\n\n**If \"One feature\":**\n\nProceed to write PLAN.md for the entire scope (step 5 below).\n\n**Why this matters:**\n\n- Multiple features in one branch = massive PR, review hell, merge conflicts\n- Separate features = clean PRs, incremental progress, easier reviews\n- After first feature PR merges, come back and tackle next feature\n\n### 5. Write PLAN.md\n\nAfter user chooses approach AND confirms scope, write `.claude/PLAN.md`:\n\n```markdown\n# Implementation Plan: [Feature]\n\n> **For Claude:** REQUIRED SUB-SKILL: Invoke `Read(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-implement/SKILL.md\")` to implement this plan.\n>\n> **Per-Task Ralph Loops:** Assign each task its OWN ralph loop. Do NOT combine multiple tasks into one loop.\n>\n> **Delegation:** Main chat orchestrates, Task agents implement. Use `Read(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-delegate/SKILL.md\")` for subagent templates.\n\n## Chosen Approach\n[Name]: [Brief description]\n\n## Rationale\n- [Why this approach fits]\n- [Trade-offs accepted]\n\n## Testing Strategy (MANDATORY - GATE)\n\n> **⚠️ THIS SECTION MUST BE COMPLETE BEFORE IMPLEMENTATION.**\n> **If any field is empty, implementation CANNOT proceed.**\n\n| Field | Value | Status |\n|-------|-------|--------|\n| **Framework** | [pytest / jest / playwright / etc.] | [ ] Filled |\n| **Test Command** | [e.g., `pytest tests/ -v`] | [ ] Filled |\n| **First Failing Test** | [Description of what test will fail first] | [ ] Filled |\n| **Test File Location** | [e.g., `tests/test_feature.py`] | [ ] Filled |\n| **Testing Skill** | [dev-test-electron / dev-test-playwright / etc.] | [ ] Filled |\n\n## REAL Test Criteria (MANDATORY - PREVENTS FAKE TESTS)\n\n> **⚠️ A test that doesn't replicate user workflow is a FAKE test.**\n> **If this section is empty or incorrect, you WILL write fake tests.**\n\n| Criteria | Value | Verified |\n|----------|-------|----------|\n| **User workflow to replicate** | [e.g., \"highlight → click panel → see status\"] | [ ] |\n| **Protocol/transport** | [e.g., \"WebSocket\" - must match production] | [ ] |\n| **UI elements to interact with** | [e.g., \"Claude terminal panel\"] | [ ] |\n| **What user sees/verifies** | [e.g., \"'⧉ X lines selected' in status\"] | [ ] |\n| **Code path exercised** | [e.g., \"selection → WebSocket → panel update\"] | [ ] |\n\n### Fake Test Prevention Checklist\n\nBefore implementation, verify:\n\n```\n[ ] Test uses SAME protocol as production (not a different one)\n[ ] Test follows user's EXACT workflow (not a shortcut)\n[ ] Test interacts with ACTUAL UI elements (not direct function calls)\n[ ] Test verifies what USER sees (not internal state)\n[ ] Test uses the SPECIFIED testing skill (not your own approach)\n```\n\n**If ANY box is unchecked → You WILL write fake tests. Fix now.**\n\n### Examples of REAL vs FAKE Tests\n\n| Feature Type | FAKE Test (DON'T) | REAL Test (DO) |\n|--------------|-------------------|----------------|\n| WebSocket feature | HTTP endpoint test | WebSocket connection test |\n| GraphQL mutation | REST mock | GraphQL client call |\n| UI button click | `button.onClick()` direct call | Playwright/ydotool click |\n| CLI command | Call internal function | Invoke actual binary |\n| API endpoint | Unit test handler | HTTP request to server |\n| Async operation | Sync function call | Await actual promise |\n| Database query | Mock repository | Test against real/test DB |\n| Electron app | Mock IPC layer | CDP automation |\n\n### The Iron Law of This Plan\n\n**NO TASK STARTS UNTIL ITS TEST IS WRITTEN.**\n\nFor each task below:\n1. Write the test FIRST (RED)\n2. Run the test, see it FAIL\n3. Implement the code (GREEN)\n4. Refactor if needed\n\n**If you skip the test, DELETE your implementation and start over.**\n\n### What Counts as a REAL Test\n\n| ✅ REAL (execute + verify) | ❌ NOT A TEST (never do this) |\n|----------------------------|-------------------------------|\n| pytest calls function | grep for function exists |\n| Playwright clicks button | ast-grep finds pattern |\n| API request checks response | Log says \"success\" |\n| Screenshot comparison | \"Code looks correct\" |\n\n**Every task MUST have a test that EXECUTES the code and VERIFIES behavior.**\n\n### Rationalization Prevention (No Tests)\n\nIf you catch yourself thinking these thoughts, STOP:\n\n| Thought | Reality |\n|---------|---------|\n| \"No test infrastructure exists\" | Add it as Task 0. That's the plan now. |\n| \"This is hard to test\" | Use E2E tools (Playwright, ydotool). Ask user. |\n| \"I'll add tests later\" | No. TDD means tests FIRST. |\n| \"Just this one task without tests\" | No exceptions. Ever. |\n| \"Manual testing is in SPEC.md\" | That's wrong. Fix it or ask user. |\n| \"User approved manual testing\" | Push back. TDD is the workflow. |\n\n### Rationalization Prevention (Fake Tests)\n\nIf you catch yourself thinking these thoughts, STOP - you're about to write a FAKE test:\n\n| Thought | Reality | REAL Action |\n|---------|---------|-------------|\n| \"Testing HTTP is easier\" | But app uses WebSocket | Test WebSocket |\n| \"I can call the function directly\" | That skips user workflow | Simulate user action |\n| \"I know a better way to test this\" | User specified a skill | Use the specified skill |\n| \"Internal state check is more direct\" | User doesn't see internal state | Verify user-visible output |\n| \"Mocking is simpler\" | Mocks hide real bugs | Test actual integration |\n| \"The test fails, let me fix the assertion\" | Maybe the test is wrong | Question if test is valid |\n| \"User workflow is too complex\" | That's what user actually does | Replicate it anyway |\n| \"This shortcut tests the same thing\" | No it doesn't | Follow exact workflow |\n\n## Files to Modify\n| File | Change |\n|------|--------|\n| `src/auth/service.ts` | Add `validateSession()` method |\n| `src/routes/api.ts` | Add new endpoint |\n\n## New Files\n| File | Purpose |\n|------|---------|\n| `src/auth/types.ts` | Session type definitions |\n\n## Implementation Order (with Per-Task Ralph Loops)\n\n> **For Claude:** Each task = one ralph loop. Complete task N before starting task N+1.\n>\n> **TDD ENFORCEMENT:** Every task with code MUST have a failing test written BEFORE implementation.\n>\n> Pattern: `Skill(skill=\"ralph-loop:ralph-loop\", args=\"Task N: [name] --max-iterations 10 --completion-promise TASKN_DONE\")`\n\n| Task | Ralph Loop | Failing Test (write FIRST) | Verify Command |\n|------|------------|----------------------------|----------------|\n| 0. Test infrastructure (if needed) | `\"Task 0: Test setup\" → TASK0_DONE` | N/A (meta-task) | `pytest --version` or `npm test -- --version` |\n| 1. Add types | `\"Task 1: Add types\" → TASK1_DONE` | N/A (types only) | `tsc --noEmit` |\n| 2. Service method | `\"Task 2: Service method\" → TASK2_DONE` | `test_validate_session()` - write test, see RED, then implement | `pytest tests/test_auth.py -v` |\n| 3. Route handler | `\"Task 3: Route handler\" → TASK3_DONE` | `test_api_endpoint()` - write test, see RED, then implement | `pytest tests/test_api.py -v` |\n```\n\n### 6. User Gate - Final Approval\n\nAfter writing PLAN.md, get explicit approval:\n\n```\nAskUserQuestion(questions=[{\n  \"question\": \"Ready to start implementation?\",\n  \"header\": \"Approval\",\n  \"options\": [\n    {\"label\": \"Yes, proceed\", \"description\": \"Start implementation with TDD\"},\n    {\"label\": \"No, discuss changes\", \"description\": \"Modify the plan first\"}\n  ],\n  \"multiSelect\": false\n}])\n```\n\n**If \"No\":** Wait for user feedback, modify plan, ask again.\n\n**If \"Yes\":** Proceed to workspace setup question in Step 7 below.\n\n### 7. Workspace Setup Question\n\nAfter user approves implementation, ask about worktree isolation:\n\n```\nAskUserQuestion(questions=[{\n  \"question\": \"Create isolated worktree for this feature?\",\n  \"header\": \"Workspace\",\n  \"options\": [\n    {\"label\": \"Yes (Recommended)\", \"description\": \"Work in isolated .worktrees/ directory - keeps main workspace clean\"},\n    {\"label\": \"No\", \"description\": \"Work in current directory\"}\n  ],\n  \"multiSelect\": false\n}])\n```\n\n**If \"Yes (Recommended)\":**\n\nInvoke the dev-worktree skill:\n```bash\n# dev-worktree: Create isolated git worktree for feature development\nSkill(skill=\"workflows:dev-worktree\")\n```\n\nThen after worktree is created, invoke dev-implement.\n\n**If \"No\":**\n\nDirectly invoke dev-implement in current directory without worktree isolation.\n\n## Approach Categories\n\n| Category | When to Use | Trade-off |\n|----------|-------------|-----------|\n| Minimal | Bug fixes, small features | Speed vs cleanliness |\n| Clean | New systems, core features | Quality vs time |\n| Pragmatic | Most features | Balance |\n\n## PLAN.md Format\n\nRequired sections:\n- **Chosen Approach** - What was selected and why\n- **Testing Strategy** - Framework, command, first test, location, skill\n- **REAL Test Criteria** - User workflow, protocol, UI elements, what user sees\n- **Files to Modify** - Specific paths with change descriptions\n- **New Files** - If any, with purposes\n- **Implementation Order** - Ordered task list with dependencies\n\n## The Gate Function\n\nComplete all steps before starting implementation:\n\n```\n1. REVIEW → Read SPEC.md and exploration findings\n2. VERIFY TESTING → Check SPEC.md has automated testing strategy\n   └─ If missing → STOP. Go back to clarify phase.\n3. PROPOSE → Present 2-3 approaches with trade-offs\n4. ASK → Use AskUserQuestion with clear options\n5. DECOMPOSE → Ask \"One feature or multiple?\" (CRITICAL)\n   └─ If multiple → List features, ask which first, write BACKLOG.md\n6. WAIT → Do NOT proceed until user responds\n7. DOCUMENT → Write PLAN.md with Testing Strategy section FILLED\n8. VERIFY PLAN → Check PLAN.md Testing Strategy table has all boxes checked\n   └─ If any unchecked → STOP. Fill them before proceeding.\n9. CONFIRM → Ask \"Ready to proceed?\"\n10. WORKSPACE → Ask \"Create worktree?\" (Yes recommended / No)\n11. SETUP → If worktree Yes, invoke dev-worktree\n12. GATE → Only start /dev-implement after all approvals\n```\n\n**Mandatory steps (NEVER skip):** VERIFY TESTING, DECOMPOSE, VERIFY PLAN, WAIT, WORKSPACE, and GATE.\n\n### Testing Strategy Verification (Step 2 & 8)\n\nBefore proceeding past step 2, verify SPEC.md contains:\n```\n[ ] Testing approach (unit/integration/E2E)\n[ ] Test framework (pytest/jest/playwright)\n[ ] Test command (how to run)\n[ ] Testing skill specified (dev-test-electron/playwright/etc.)\n```\n\nBefore proceeding past step 8, verify PLAN.md Testing Strategy table:\n```\n[ ] Framework filled\n[ ] Test Command filled\n[ ] First Failing Test described\n[ ] Test File Location specified\n[ ] Testing Skill specified\n```\n\n**If any box is unchecked → STOP. Do not proceed.**\n\n### REAL Test Verification (Step 8 - CRITICAL)\n\nBefore proceeding past step 8, verify PLAN.md REAL Test Criteria table:\n\n```\n[ ] User workflow documented (exact steps user takes)\n[ ] Protocol matches production (WebSocket/HTTP/IPC/etc.)\n[ ] UI elements identified (what user interacts with)\n[ ] User-visible output documented (what user sees)\n[ ] Code path specified (same path as production)\n```\n\n**If any box is unchecked → You WILL write fake tests. Fix now.**\n\n### Fake Test Prevention Check (Step 8)\n\nAsk yourself before proceeding:\n1. Will the test use the SAME protocol as production? (Not a substitute)\n2. Will the test follow the EXACT user workflow? (Not shortcuts)\n3. Will the test use the SPECIFIED testing skill? (Not your own approach)\n4. Will the test verify what the USER sees? (Not internal state)\n\nIf ANY answer is \"no\" → STOP. Fix the REAL Test Criteria section.\n\n## Rationalization Prevention\n\nRecognize these thoughts as red flags—they signal attempts to bypass the user gate:\n\n| Thought | Reality |\n|---------|---------|\n| \"User will approve this\" | Your assumption ≠ approval. Ask and wait. |\n| \"It's the obvious choice\" | User decides what's obvious. Present options. |\n| \"Let me just start\" | NO. Gate exists for a reason. Wait. |\n| \"User said they trust me\" | Trust doesn't mean skip approval. Ask. |\n| \"Time pressure\" | You'll waste more time with the wrong approach. Wait for approval. |\n| \"Only one viable option\" | Present it anyway. User may see alternatives. |\n| \"Ask forgiveness later\" | No. Ask permission now. |\n\n## Red Flags - STOP If You're About To:\n\n| Action | Why It's Wrong | Do Instead |\n|--------|----------------|------------|\n| Present only one approach | You're removing user choice | Always show 2-3 options |\n| Skip trade-offs | You're making decision for user | Explain pros/cons clearly |\n| Start implementing | You don't have approval yet | Wait for explicit \"Yes\" |\n| Assume recommendation accepted | You're guessing at user preference | Ask and wait for answer |\n\n## Output\n\nDesign complete when:\n- 2-3 approaches presented with trade-offs\n- User chose an approach\n- `.claude/PLAN.md` written with chosen approach\n- **User explicitly approved** (\"Yes, proceed\")\n\n## Phase Complete\n\n**After user approves (\"Yes, proceed\"):**\n\n1. **Ask about worktree** (Step 7 above)\n2. **If worktree chosen:**\n   - Invoke `Skill(skill=\"workflows:dev-worktree\")`\n   - After worktree created, invoke `Read(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-implement/SKILL.md\")`\n3. **If no worktree:**\n   - Directly invoke `Read(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-implement/SKILL.md\")`\n\n**Required before proceeding:**\n- Explicit user approval for implementation\n- Feature scope decision (one feature vs multiple)\n- User choice on worktree (Yes/No)\n\n**After this feature is implemented and PR'd:**\n\nIf multiple features were identified in step 4, check `.claude/BACKLOG.md` for remaining features:\n1. View remaining features in BACKLOG.md\n2. Invoke `/dev` again to tackle the next feature\n3. Repeat until all features are complete\n\nThis enables incremental development: one feature → PR → merge → next feature.\n",
        "skills/dev-tdd/SKILL.md": "---\nname: dev-tdd\ndescription: This skill should be used when the user asks to \"implement using TDD\", \"test-driven development\", \"RED-GREEN-REFACTOR\", or \"write failing test first\". Enforces test-first approach with RED-GREEN-REFACTOR cycle and execution-based verification.\nversion: 0.1.0\n---\n\n## Contents\n\n- [The Iron Law](#the-iron-law-of-tdd)\n- [The TDD Cycle](#the-tdd-cycle)\n- [What Counts as a Test](#what-counts-as-a-test)\n- [Logging TDD Progress](#logging-tdd-progress)\n- [Red Flags - Thoughts That Mean STOP](#red-flags---thoughts-that-mean-stop)\n- [Delete & Restart](#delete--restart)\n- [E2E Test Requirement](#e2e-test-requirement)\n\n# Test-Driven Development\n\n<EXTREMELY-IMPORTANT>\n## Task Reframing: What Your Job Actually Is\n\n**Your job is NOT to implement features. Your job is to write tests that prove features work.**\n\nReframe every task:\n- ❌ \"Implement user login\"\n- ✅ \"Write a test that proves user login works. Then make it pass.\"\n\n- ❌ \"Fix the icon rendering bug\"\n- ✅ \"Write a test that fails when icons render wrong. Then fix it.\"\n\n**The test IS your deliverable. The implementation just makes the test pass.**\n</EXTREMELY-IMPORTANT>\n\n<EXTREMELY-IMPORTANT>\n## File-Based Logging (MANDATORY)\n\n**ALL CODE MUST USE FILE-BASED LOGGING.**\n\nEvery application you write MUST redirect output to a log file:\n- CLI apps: `./app > /tmp/app.log 2>&1 &`\n- GUI apps: `./app --log-file=/tmp/app.log 2>&1 &`\n- Test runners: `pytest -v > /tmp/test.log 2>&1`\n\n**Why:** Without log files, you have NO EVIDENCE of what happened. \"I saw it in terminal\" is not verification.\n\n**Read the full requirements:** `@references/logging-requirements.md`\n</EXTREMELY-IMPORTANT>\n\n<EXTREMELY-IMPORTANT>\n## The Execution Gate (MANDATORY)\n\n**NO E2E TESTS WITHOUT PASSING THE EXECUTION GATE FIRST.**\n\nBefore running E2E tests or taking screenshots, you MUST complete all 6 gates in order:\n\n```\nGATE 1: BUILD\nGATE 2: LAUNCH (with file-based logging)\nGATE 3: WAIT\nGATE 4: CHECK PROCESS\nGATE 5: READ LOGS ← MANDATORY, CANNOT SKIP\nGATE 6: VERIFY LOGS\nTHEN AND ONLY THEN: E2E tests/screenshots\n```\n\n**Key enforcement:**\n- If you catch yourself thinking \"let me take a screenshot\" → STOP, you skipped gates 1-6\n- If process is running → READ LOGS (GATE 5) before testing\n- Logs come BEFORE screenshots, not after\n\n**For GUI applications:**\n- Screenshot WINDOW ONLY (not whole screen)\n- When testing specific feature (toolbar icons), crop to THAT REGION only\n- Whole screen = false conclusions from other apps\n\n**Read the complete gate sequence:** `@references/execution-gates.md`\n</EXTREMELY-IMPORTANT>\n\n<EXTREMELY-IMPORTANT>\n## The Iron Law of TDD\n\n**YOU MUST WRITE THE FAILING TEST FIRST. YOU MUST SEE IT FAIL. This is not negotiable.**\n\nBefore writing ANY implementation code:\n1. You write a test that will fail (because the feature doesn't exist yet)\n2. You run the test and **SEE THE FAILURE OUTPUT** (RED)\n3. You document in LEARNINGS.md: \"RED: [test name] fails with [error message]\"\n4. Only THEN you write implementation code\n5. You run the test again, **SEE IT PASS** (GREEN)\n6. You document: \"GREEN: [test name] now passes\"\n\n**The RED step is not optional. If the test hasn't failed, you haven't practiced TDD.**\n</EXTREMELY-IMPORTANT>\n\n## The TDD Cycle\n\n```\nRED → Write test → Run through GATES → See failure → Read logs → Document\nGREEN → Minimal code → Run through GATES → See pass → Read logs → Document\nREFACTOR → Clean up while staying green\n```\n\n### Step 1: RED - Write Failing Test\n\n```python\n# Write the test FIRST\ndef test_user_can_login():\n    result = login(\"user@example.com\", \"password123\")\n    assert result.success == True\n    assert result.token is not None\n```\n\nRun the test through the execution gates:\n\n```bash\n# For unit tests, minimum gates are: EXECUTE + READ OUTPUT\npytest tests/test_auth.py::test_user_can_login -v 2>&1 | tee /tmp/test.log\n# pytest: run specific test and see RED failure\n\n# READ the output (MANDATORY)\ncat /tmp/test.log\n```\n\nOutput will show:\n```\nFAILED - NameError: name 'login' is not defined\n```\n\n**Log to LEARNINGS.md:**\n```markdown\n## RED: test_user_can_login\n- Test written\n- Ran through gates (pytest executed, output read)\n- Fails with: NameError: name 'login' is not defined\n- Expected: function doesn't exist yet\n```\n\n### Step 2: GREEN - Minimal Implementation\n\nWrite the **minimum code** to make the test pass:\n\n```python\ndef login(email: str, password: str) -> LoginResult:\n    # Minimal implementation\n    return LoginResult(success=True, token=\"dummy-token\")\n```\n\nRun the test through gates again:\n\n```bash\npytest tests/test_auth.py::test_user_can_login -v 2>&1 | tee /tmp/test.log\n# pytest: run test again and see GREEN success\n\n# READ the output (MANDATORY)\ncat /tmp/test.log\n```\n\nOutput will show:\n```\nPASSED\n```\n\n**Log to LEARNINGS.md:**\n```markdown\n## GREEN: test_user_can_login\n- Minimal login() implemented\n- Ran through gates (pytest executed, output read)\n- Test passes\n- No errors in output\n- Ready for refactor\n```\n\n### Step 3: REFACTOR - Improve While Green\n\nClean up the code while keeping tests passing:\n\n```python\ndef login(email: str, password: str) -> LoginResult:\n    user = User.find_by_email(email)\n    if user and user.check_password(password):\n        return LoginResult(success=True, token=generate_token(user))\n    return LoginResult(success=False, token=None)\n```\n\nVerify tests remain green after refactoring:\n\n```bash\npytest tests/test_auth.py -v\n# pytest: run all tests and verify GREEN after refactor\n```\n\nOutput will show:\n```\nAll tests PASSED\n```\n\n## What Counts as a Test\n\n<EXTREMELY-IMPORTANT>\n### REAL Tests vs FAKE \"Tests\"\n\n| REAL TEST (execute + verify) | FAKE \"TEST\" (NEVER ACCEPTABLE) |\n|------------------------------|--------------------------------|\n| pytest calls function, asserts return | grep for function exists |\n| Playwright clicks button, checks DOM | ast-grep finds pattern |\n| ydotool types input, screenshot verifies | Log says \"success\" |\n| CLI invocation checks stdout | \"Code looks correct\" |\n| API request verifies response body | \"I'm confident it works\" |\n\n**THE TEST MUST EXECUTE THE CODE AND VERIFY RUNTIME BEHAVIOR.**\n\nGrepping is NOT testing. Log reading is NOT testing. Code review is NOT testing.\n</EXTREMELY-IMPORTANT>\n\n### Fake Tests That Look Like Tests (THE INSIDIOUS FAILURE)\n\n<EXTREMELY-IMPORTANT>\n**A test can EXECUTE code and still be FAKE if it tests the wrong thing.**\n\nThis is MORE dangerous than no tests because it creates FALSE CONFIDENCE.\n\n| LOOKS LIKE A TEST | WHY IT'S FAKE | REAL TEST MUST DO |\n|-------------------|---------------|-------------------|\n| Tests different protocol | Wrong code path | Use same protocol as production |\n| Calls function directly | Skips user workflow | Simulate actual user action |\n| Checks internal state | User doesn't see that | Verify user-visible output |\n| Uses mock/stub for SUT | Defeats the purpose | Test actual behavior |\n| Ignores specified skill | \"I know better\" | Use the specified testing skill |\n| Changes assertion to pass | Hides bugs | Question if test is valid |\n| Skips async when prod is async | Race conditions hidden | Match async behavior |\n\n### The Iron Law of REAL Tests\n\n**If the test doesn't replicate what the user does, it's a FAKE test.**\n\nBefore running any test, verify:\n1. Does test use SAME protocol as production?\n2. Does test follow EXACT user workflow?\n3. Does test verify what USER sees?\n4. Does test use the SPECIFIED testing skill?\n\nIf ANY answer is \"no\" → DELETE THE TEST. Write a REAL one.\n\n### Fake Test Detection (Red Flags)\n\nIf you catch yourself doing these, STOP - you're writing a FAKE test:\n\n| What You're Doing | Why It's Fake | Do Instead |\n|-------------------|---------------|------------|\n| Testing different protocol | Wrong code path | Use production protocol |\n| Calling function instead of user action | Skipping user workflow | Simulate actual user action |\n| Changing assertion to make test pass | Hiding bugs, not finding them | Question if test is valid |\n| Ignoring the testing skill user specified | Arrogance: \"I know better\" | Use the specified skill |\n| Testing internal state | User doesn't see that | Test user-visible output |\n| Mocking the System Under Test | Defeats the purpose | Test actual behavior |\n| Using sync when production is async | Race conditions hidden | Match async behavior |\n| Testing unit when integration needed | Boundary bugs hidden | Test across boundaries |\n\n### When Tests Fail, Question the Test First\n\n**If a test fails, don't immediately fix the assertion. Ask:**\n\n1. Is this test testing the right thing?\n2. Is this test using the right protocol?\n3. Is this test replicating the user's workflow?\n4. Did I use the specified testing skill?\n\nIf any answer is \"no\" → The test is wrong, not the assertion.\n</EXTREMELY-IMPORTANT>\n\n### Why Grepping is Not Testing\n\n| Fake Approach | Why It's Worthless | What Happens |\n|---------------|-------------------|--------------|\n| `grep \"function_name\"` | Proves function exists, not that it works | Bug ships |\n| `ast-grep pattern` | Proves structure matches, not behavior | Runtime crash |\n| \"Log says success\" | Log was written, code might not run | Silent failure |\n| \"Code review passed\" | Human opinion, not execution | Edge cases missed |\n\n## Logging TDD Progress\n\nDocument every TDD cycle in `.claude/LEARNINGS.md`:\n\n```markdown\n## TDD Cycle: [Feature/Test Name]\n\n### RED\n- **Test:** `test_feature_works()`\n- **Command:**\n\n```bash\npytest tests/test_feature.py::test_feature_works -v\n# pytest: run test and observe RED failure\n```\n\n- **Output:**\n```\nFAILED - AssertionError: expected True, got None\n```\n- **Expected:** Feature not implemented yet\n\n### GREEN\n- **Implementation:** Added `feature_works()` function\n- **Command:**\n\n```bash\npytest tests/test_feature.py::test_feature_works -v\n# pytest: run test and verify GREEN success\n```\n\n- **Output:**\n```\nPASSED\n```\n\n### REFACTOR\n- Extracted helper function\n- Added type hints\n- Verify tests still pass:\n\n```bash\npytest tests/test_feature.py -v\n# pytest: run all tests and confirm GREEN after refactor\n```\n```\n\n## Red Flags - Thoughts That Mean STOP\n\nIf you catch yourself thinking these thoughts—STOP. They're indicators you're about to skip TDD:\n\n| Thought | Reality |\n|---------|---------|\n| \"Write the test after\" | You're about to do verification, not TDD. You MUST test FIRST. |\n| \"This is too simple for TDD\" | Your simple code benefits MOST from TDD. |\n| \"Just fix this quickly\" | Your speed isn't the goal. Your correctness is. |\n| \"Know the test will fail\" | You knowing isn't the same as you seeing it fail. You MUST RUN it, see RED. |\n| \"Grep confirms it exists\" | Your existence check ≠ working code. You MUST execute the code. |\n| \"Already have the code\" | You MUST DELETE IT. You write test first, then reimplement. |\n| \"Test passed on first run\" | Suspicious. Did you actually see RED first? |\n\n### Red Flags - Fake Test Indicators\n\nIf you catch yourself thinking these thoughts—STOP. They're indicators you're writing a FAKE test:\n\n| Thought | Reality |\n|---------|---------|\n| \"This protocol is easier to test\" | But production uses different protocol. Test that. |\n| \"I can call the function directly\" | User doesn't do that. Simulate user action. |\n| \"I'll mock this dependency\" | Then you're not testing real behavior. |\n| \"Internal state is more direct\" | User doesn't see internal state. Test what user sees. |\n| \"I know a better way\" | User specified a skill. Use it. |\n| \"Let me fix this assertion\" | Maybe the test is wrong. Question it first. |\n| \"User workflow is complex\" | That's what user does. Replicate it. |\n| \"This shortcut tests the same thing\" | No it doesn't. Follow exact workflow. |\n| \"Async is hard to test\" | Production is async. Test it async. |\n| \"Integration tests are slow\" | Unit tests hide boundary bugs. Test integration. |\n\n**If your test doesn't replicate what the user does, it's a FAKE test.**\n\n**If your test doesn't fail first, you haven't practiced TDD.**\n\n## Delete & Restart\n\n<EXTREMELY-IMPORTANT>\n**Wrote implementation code before test? You MUST DELETE IT. No exceptions.**\n\nWhen you discover implementation code that wasn't driven by a test:\n1. **DELETE** your implementation code\n2. **WRITE** the test first\n3. **RUN** it, **SEE RED**\n4. **REWRITE** the implementation\n\n\"But it works\" is not an excuse. \"But it would waste your time\" is not an excuse.\n\n**Code you wrote without TDD is UNTRUSTED code. You delete it and do it right.**\n</EXTREMELY-IMPORTANT>\n\n## E2E Test Requirement\n\n<EXTREMELY-IMPORTANT>\n### The Iron Law of E2E in TDD\n\n**USER-FACING FEATURES REQUIRE E2E TESTS IN ADDITION TO UNIT TESTS.**\n\nTDD cycle for user-facing changes:\n\n```\nUnit TDD:     RED → GREEN → REFACTOR\n                    ↓\nE2E TDD:      RED → GREEN → REFACTOR\n```\n\n**Both cycles must complete. Unit GREEN does not mean DONE.**\n\n### When E2E is Required\n\n| Change Type | Unit Tests | E2E Required? |\n|-------------|------------|---------------|\n| Internal logic | Yes | No |\n| API endpoint | Yes | Yes (test full request/response) |\n| UI component | Yes | **Yes** (Playwright/automation) |\n| CLI command | Yes | Yes (test actual invocation) |\n| User workflow | Yes | **Yes** (simulate user actions) |\n| Visual change | Yes | **Yes** (screenshot comparison) |\n\n### E2E TDD Cycle\n\n1. **RED**: Write E2E test simulating user action\n   - Run through ALL 6 GATES (BUILD → LAUNCH → WAIT → CHECK → READ LOGS → VERIFY LOGS)\n   - Only after GATE 6: Run the E2E test\n   - Observe the failure (feature doesn't exist)\n   - Document: \"E2E RED: [test] fails with [error]. All gates passed, logs clean.\"\n\n2. **GREEN**: Implement to make E2E pass (unit tests already green)\n   - Run through ALL 6 GATES again\n   - Only after GATE 6: Run the E2E test\n   - Verify the pass\n   - Document: \"E2E GREEN: [test] passes. All gates passed, logs clean.\"\n\n3. **REFACTOR**: Ensure both unit and E2E stay green\n   - Continue running through gates for each test run\n\n### Delete & Restart (E2E)\n\n**You shipped user-facing code without E2E test? You MUST WRITE ONE NOW.**\n\nRetroactive E2E is better than no E2E. But next time: You write E2E FIRST.\n</EXTREMELY-IMPORTANT>\n\n## Integration\n\nThis skill is invoked by:\n- `dev-implement` - for TDD during implementation\n- `dev-debug` - for regression tests during debugging\n\nFor testing tool options (Playwright, ydotool, etc.), see:\n```\nSkill(skill=\"workflows:dev-test\")\n```\n",
        "skills/dev-tdd/references/execution-gates.md": "# The Execution Gate (MANDATORY)\n\n<EXTREMELY-IMPORTANT>\n**NO E2E TESTS WITHOUT PASSING THE EXECUTION GATE FIRST. This is absolute.**\n\n## The Gate Sequence\n\nBefore ANY E2E testing, screenshots, or verification:\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│ GATE 1: BUILD                                                │\n│   → Compile/build the application                            │\n│   → Exit code 0? → Proceed                                   │\n│   → Exit code ≠ 0? → STOP, fix build, restart               │\n└─────────────────────────────────────────────────────────────┘\n                              ↓\n┌─────────────────────────────────────────────────────────────┐\n│ GATE 2: LAUNCH                                               │\n│   → Start application with FILE-BASED logging                │\n│   → ./app --log-file=/tmp/app.log 2>&1 &                    │\n└─────────────────────────────────────────────────────────────┘\n                              ↓\n┌─────────────────────────────────────────────────────────────┐\n│ GATE 3: WAIT                                                 │\n│   → sleep 2-3 seconds for initialization                     │\n└─────────────────────────────────────────────────────────────┘\n                              ↓\n┌─────────────────────────────────────────────────────────────┐\n│ GATE 4: CHECK PROCESS                                        │\n│   → ps -p $PID or pgrep appname                             │\n│   → Running? → Proceed                                       │\n│   → Crashed? → STOP, READ LOGS, fix, restart at GATE 1      │\n└─────────────────────────────────────────────────────────────┘\n                              ↓\n┌─────────────────────────────────────────────────────────────┐\n│ GATE 5: READ LOGS (MANDATORY - CANNOT SKIP)                 │\n│   → cat /tmp/app.log                                         │\n│   → Read ENTIRE log file                                     │\n│   → Document what you see                                    │\n└─────────────────────────────────────────────────────────────┘\n                              ↓\n┌─────────────────────────────────────────────────────────────┐\n│ GATE 6: VERIFY LOGS                                          │\n│   → Check for ERROR, FATAL, Segmentation, core dumped       │\n│   → Check for missing resources, failed loads                │\n│   → Errors found? → STOP, fix, restart at GATE 1            │\n│   → Clean logs? → Proceed                                    │\n└─────────────────────────────────────────────────────────────┘\n                              ↓\n┌─────────────────────────────────────────────────────────────┐\n│ NOW YOU MAY: E2E tests, screenshots, UI verification         │\n└─────────────────────────────────────────────────────────────┘\n```\n\n**YOU CANNOT SKIP GATES. YOU CANNOT REORDER GATES.**\n\n## Red Flags - STOP Immediately\n\nIf you catch yourself thinking ANY of these, STOP—you're about to skip a gate:\n\n| Thought | Why It's Wrong | Action |\n|---------|----------------|--------|\n| \"Build succeeded, let me screenshot\" | You skipped GATES 2-6 | Go to GATE 2 |\n| \"Let me take a screenshot\" | You skipped GATES 1-6 | Start at GATE 1 |\n| \"Process is running, let me test\" | You skipped GATES 5-6 (READ LOGS) | Go to GATE 5 |\n| \"I'll check logs if test fails\" | Backward—logs come BEFORE tests | Go to GATE 5 |\n| \"Sleep is enough\" | Sleep ≠ verification | Do GATES 4-6 |\n\n## Rationalization Prevention\n\n| Excuse | Reality |\n|--------|---------|\n| \"Build passed, app must work\" | NO. GATES 2-6 required. Do them now. |\n| \"I can see the window\" | NO. You haven't READ LOGS (GATE 5). Do it now. |\n| \"I'll check logs later\" | NO. GATE 5 comes BEFORE E2E. Do it now. |\n| \"Logs are optional\" | NO. GATE 5 is MANDATORY. Cannot skip. |\n| \"Screenshots will show issues\" | NO. Screenshots can't show log errors. GATE 5 first. |\n\n## For GUI Applications (Mandatory Pattern)\n\n```bash\n#!/bin/bash\nset -e  # Exit on any error\n\n# GATE 1: BUILD\necho \"GATE 1: Building...\"\ncd build && ninja\necho \"✓ GATE 1 PASSED\"\n\n# GATE 2: LAUNCH with file-based logging\necho \"GATE 2: Launching with logging...\"\n./myapp --log-file=/tmp/myapp.log 2>&1 &\nAPP_PID=$!\necho \"✓ GATE 2 PASSED (PID: $APP_PID)\"\n\n# GATE 3: WAIT\necho \"GATE 3: Waiting for initialization...\"\nsleep 3\necho \"✓ GATE 3 PASSED\"\n\n# GATE 4: CHECK PROCESS\necho \"GATE 4: Checking process...\"\nif ! ps -p $APP_PID > /dev/null; then\n    echo \"✗ GATE 4 FAILED: Process crashed\"\n    echo \"Reading logs from GATE 5...\"\n    cat /tmp/myapp.log\n    exit 1\nfi\necho \"✓ GATE 4 PASSED\"\n\n# GATE 5: READ LOGS (MANDATORY)\necho \"GATE 5: Reading full runtime logs...\"\necho \"=== RUNTIME LOGS ===\"\ncat /tmp/myapp.log\necho \"=== END LOGS ===\"\necho \"✓ GATE 5 PASSED (logs read)\"\n\n# GATE 6: VERIFY LOGS\necho \"GATE 6: Verifying no errors in logs...\"\nif grep -qE \"(ERROR|FATAL|CRITICAL|Segmentation|core dumped)\" /tmp/myapp.log; then\n    echo \"✗ GATE 6 FAILED: Errors found in logs\"\n    exit 1\nfi\necho \"✓ GATE 6 PASSED\"\n\n# NOW AND ONLY NOW: E2E testing\necho \"All gates passed. Proceeding to E2E tests...\"\n\n# CRITICAL: Screenshot WINDOW ONLY, not whole screen\n# Whole screen = other apps visible = false conclusions\nif [ \"$XDG_SESSION_TYPE\" = \"wayland\" ]; then\n    # Wayland: Get focused window geometry and screenshot it\n    GEOMETRY=$(hyprctl activewindow -j | jq -r '\"\\(.at[0]),\\(.at[1]) \\(.size[0])x\\(.size[1])\"')\n    grim -g \"$GEOMETRY\" /tmp/screenshot.png\nelse\n    # X11: Screenshot active window only\n    scrot -u /tmp/screenshot.png\nfi\necho \"Screenshot captured (window only)\"\n```\n\n**Tool description:** Execute all 6 mandatory gates, then screenshot active window only\n\n## The Iron Law of GUI E2E Testing\n\n<EXTREMELY-IMPORTANT>\n**GUI APPLICATIONS REQUIRE E2E TESTS WITH WINDOW-SPECIFIC SCREENSHOTS. This is absolute.**\n\nEvery GUI application you implement MUST have:\n1. E2E test that verifies the UI\n2. Screenshot of **THE APPLICATION WINDOW ONLY** (not whole screen)\n3. Visual verification or comparison\n\n**Why window-only screenshots are mandatory:**\n\n| Whole Screen Screenshots | Window-Only Screenshots |\n|--------------------------|-------------------------|\n| Shows other apps → false conclusions | Shows your app only → accurate |\n| \"Success\" message from wrong app | Only your app's messages |\n| Icons from desktop/panel confuse analysis | Only your app's icons |\n| Can't isolate your app's behavior | Isolated verification |\n\n## Rationalization Prevention (Screenshots)\n\n| Excuse | Reality |\n|--------|---------|\n| \"Whole screen is easier\" | Easier = wrong conclusions. Window only. |\n| \"I can tell which app it is\" | You make mistakes. Isolate the window. |\n| \"Other apps don't matter\" | They confuse verification. Window only. |\n| \"grim /tmp/screenshot.png works\" | That's whole screen. Use `-g` with geometry. |\n| \"scrot is enough\" | That's whole screen. Use `scrot -u` for active window. |\n\n## Platform-Specific Window Screenshots\n\n**Wayland (Hyprland):**\n```bash\n# Get active window geometry and screenshot it\nGEOMETRY=$(hyprctl activewindow -j | jq -r '\"\\(.at[0]),\\(.at[1]) \\(.size[0])x\\(.size[1])\"')\ngrim -g \"$GEOMETRY\" /tmp/window.png\n```\n\n**Wayland (Sway):**\n```bash\n# Get focused window geometry\nGEOMETRY=$(swaymsg -t get_tree | jq -r '.. | select(.focused?) | .rect | \"\\(.x),\\(.y) \\(.width)x\\(.height)\"')\ngrim -g \"$GEOMETRY\" /tmp/window.png\n```\n\n**X11:**\n```bash\n# Screenshot active window only (-u flag)\nscrot -u /tmp/window.png\n```\n\n**macOS:**\n```bash\n# Screenshot specific window by window ID\nscreencapture -l <window_id> /tmp/window.png\n```\n\n**Tool description:** Capture screenshot of application window only, not whole screen\n\n## Feature-Specific Screenshot Cropping\n\n<EXTREMELY-IMPORTANT>\n**When testing a SPECIFIC feature (toolbar, dialog, icon set), crop to THAT REGION ONLY.**\n\n**Why feature-specific cropping is mandatory:**\n\n| Whole Window | Feature-Specific Crop |\n|--------------|----------------------|\n| Irrelevant UI elements visible | Only the feature being tested |\n| False positives from other parts | Isolated verification |\n| \"Success\" from unrelated element | Only the target element |\n| Harder to spot actual bug | Bug is obvious in focused view |\n\n**Example: Testing toolbar icons**\n\n❌ **WRONG:** Screenshot whole window\n```bash\n# Shows entire app - toolbar is tiny, hard to verify\ngrim -g \"$GEOMETRY\" /tmp/screenshot.png\n```\n\n✅ **CORRECT:** Crop to toolbar only\n```bash\n# Get window geometry\nGEOMETRY=$(hyprctl activewindow -j | jq -r '\"\\(.at[0]),\\(.at[1]) \\(.size[0])x\\(.size[1])\"')\n\n# Extract coordinates and crop to toolbar (top 50px of window)\nX=$(echo $GEOMETRY | cut -d, -f1)\nY=$(echo $GEOMETRY | cut -d' ' -f1 | cut -d, -f2)\nW=$(echo $GEOMETRY | cut -d' ' -f2 | cut -dx -f1)\n\n# Screenshot toolbar only (top 50 pixels)\ngrim -g \"$X,$Y ${W}x50\" /tmp/toolbar.png\n```\n\n**Example: Testing specific dialog**\n\n✅ **CORRECT:** Get dialog window geometry, screenshot that window only\n```bash\n# Get dialog window ID and geometry specifically\nDIALOG_GEOMETRY=$(hyprctl clients -j | jq -r '.[] | select(.title | contains(\"Settings\")) | \"\\(.at[0]),\\(.at[1]) \\(.size[0])x\\(.size[1])\"')\ngrim -g \"$DIALOG_GEOMETRY\" /tmp/dialog.png\n```\n\n## Rationalization Prevention (Feature Cropping)\n\n| Excuse | Reality |\n|--------|---------|\n| \"Whole window shows context\" | Context confuses verification. Crop to feature. |\n| \"I can see the feature in the full screenshot\" | You read wrong elements. Isolate the feature. |\n| \"Cropping is too much work\" | 5 extra seconds prevents false conclusions. |\n| \"The whole window is relevant\" | Only test what you changed. Crop to feature. |\n| \"I'll just focus on the right area\" | You make mistakes. Force isolation via crop. |\n\n**Tool description:** Crop screenshot to specific feature region being tested\n</EXTREMELY-IMPORTANT>\n\n## The Honesty Requirement\n\n<EXTREMELY-IMPORTANT>\n**Skipping gates is LYING about verification.**\n\nWhen you say \"E2E test passed\", you are asserting:\n- You passed GATE 1 (built successfully)\n- You passed GATE 2 (launched with logging)\n- You passed GATE 3 (waited for init)\n- You passed GATE 4 (process is running)\n- **You passed GATE 5 (READ the full log file)**\n- **You passed GATE 6 (VERIFIED no errors in logs)**\n- You ran E2E tests with clean logs\n\nSaying \"E2E passed\" without completing GATES 5-6 is not \"testing\"—it is LYING about application state.\n\n**\"Checking logs now\" is honest. \"E2E verified\" without GATE 5 is fraud.**\n</EXTREMELY-IMPORTANT>\n",
        "skills/dev-tdd/references/logging-requirements.md": "# The Iron Law of Logging\n\n<EXTREMELY-IMPORTANT>\n**ALL CODE MUST USE FILE-BASED LOGGING. This is absolute.**\n\nEvery application, service, script, or test runner you write MUST write logs to a file:\n\n- ✅ CLI apps: `./app > /tmp/app.log 2>&1 &`\n- ✅ GUI apps: `./app --log-file=/tmp/app.log 2>&1 &`\n- ✅ Web servers: `npm start > /tmp/server.log 2>&1 &`\n- ✅ Test runners: `pytest -v > /tmp/test.log 2>&1`\n- ✅ Build scripts: `./build.sh 2>&1 | tee /tmp/build.log`\n\n**Why file-based logging is mandatory:**\n\n| Without File Logs | With File Logs |\n|-------------------|----------------|\n| stdout disappears → can't verify | Permanent record → can read anytime |\n| stderr lost → can't debug | Errors captured → can diagnose |\n| \"It worked\" = no proof | Log file = proof of execution |\n| Can't review after the fact | Can read logs later |\n| No GATE 5 possible | GATE 5 enforces reading them |\n\n## Rationalization Prevention (Logging)\n\n| Excuse | Reality |\n|--------|---------|\n| \"Stdout is enough\" | Stdout disappears. You need a file to READ. |\n| \"I can see the output\" | You can't see it after it scrolls by. FILE LOGS. |\n| \"App doesn't support --log-file\" | Use `2>&1 \\| tee /tmp/app.log` instead. |\n| \"Logs aren't necessary for simple scripts\" | Simple scripts still need verification. ALWAYS log to file. |\n| \"I'll just look at the terminal\" | Terminal output is ephemeral. FILE-BASED ONLY. |\n| \"stderr is good enough\" | stderr isn't a file you can `cat`. Use file logs. |\n| \"Too much output to log\" | That's why you READ the logs (GATE 5), not print them. |\n\n## Log File Verification Pattern\n\nAfter launching any code, verify the log file was created:\n\n```bash\n# Launch with logging\n./app > /tmp/app.log 2>&1 &\nAPP_PID=$!\nsleep 2\n\n# VERIFY LOG FILE EXISTS AND HAS CONTENT\nif [ ! -f /tmp/app.log ]; then\n    echo \"FAIL: Log file not created\"\n    echo \"Did you redirect stdout/stderr to a file?\"\n    exit 1\nfi\n\nif [ ! -s /tmp/app.log ]; then\n    echo \"FAIL: Log file empty (no output written)\"\n    exit 1\nfi\n\necho \"✓ Log file exists and has content\"\n```\n\n**Tool description:** Verify log file exists and has content after launch\n\n## The Honesty Requirement (Logging)\n\n<EXTREMELY-IMPORTANT>\n**Running code without file-based logging is LYING about verification.**\n\nWhen you claim \"code executed\" or \"tests ran\", you are asserting:\n- You created a log file\n- You verified the log file exists\n- You READ the full log file\n- You confirmed what happened from the logs\n\nRunning without file logs means you have NO EVIDENCE of what happened.\n\n**\"I saw it in terminal\" is not verification. File-based logs are mandatory.**\n</EXTREMELY-IMPORTANT>\n",
        "skills/dev-test-electron/SKILL.md": "---\nname: dev-test-electron\ndescription: This skill should be used when the user asks to \"test Electron app\", \"automate Electron desktop app\", \"debug Electron renderer\", \"test VS Code extension\", \"E2E test Electron\", or needs Chrome DevTools Protocol automation for Electron applications. Use for renderer process debugging, main process control, native menu automation, and file dialog testing.\n---\n\n**Announce:** \"I'm using dev-test-electron for Electron app automation via Chrome DevTools Protocol.\"\n\n<EXTREMELY-IMPORTANT>\n## REAL Test Requirements for Electron Apps\n\n**A REAL Electron test must replicate what the user does. FAKE tests test something else.**\n\nBefore writing ANY test, verify from SPEC.md/PLAN.md:\n\n| REAL Test Criteria | Your Test Must |\n|-------------------|----------------|\n| **User workflow** | Replicate exact steps (click → type → see result) |\n| **Protocol** | Use SAME protocol as production (WebSocket, IPC, etc.) |\n| **UI interaction** | Interact with ACTUAL UI elements user sees |\n| **Verification** | Check what USER sees, not internal state |\n\n### The Electron-Specific Fake Test Trap\n\n**Electron apps often use WebSocket/IPC internally. Testing HTTP is a FAKE test.**\n\n| FAKE Electron Test | Why It's Fake | REAL Test |\n|--------------------|---------------|-----------|\n| HTTP endpoint test | App uses WebSocket | Test WebSocket connection |\n| Direct function call | User clicks button | CDP `Input.dispatchMouseEvent` or `Runtime.evaluate` click |\n| Check internal state | User sees panel/status | CDP screenshot or DOM query |\n| Mock IPC layer | Production uses real IPC | Test actual IPC messages |\n| Skip main process | Main process has logic | Test BOTH renderer AND main |\n\n### Before You Write a Test, Ask:\n\n1. What protocol does this feature use? (WebSocket? IPC? HTTP?)\n2. What does the user actually click/type?\n3. What does the user actually SEE?\n4. Am I testing the SAME code path as production?\n\n**If any answer is \"I don't know\" → Go back to SPEC.md. Don't guess.**\n\n### Rationalization Prevention (Electron-Specific)\n\n| Thought | Reality |\n|---------|---------|\n| \"HTTP is easier to test\" | But app uses WebSocket. Test WebSocket. |\n| \"I can call the function directly\" | User clicks a button. Use CDP Input events. |\n| \"CDP is complex, let me mock\" | Mocking hides bugs. Use real CDP. |\n| \"Main process is hard to test\" | Main process crashes break app. Test it. |\n| \"Panel state is internal\" | User SEES the panel. Test what user sees. |\n| \"IPC is just plumbing\" | IPC bugs cause silent failures. Test it. |\n</EXTREMELY-IMPORTANT>\n\n<EXTREMELY-IMPORTANT>\n## Gate Reminder\n\nBefore taking screenshots or running E2E tests, you MUST complete all 6 gates from dev-tdd:\n\n```\nGATE 1: BUILD\nGATE 2: LAUNCH (with file-based logging)\nGATE 3: WAIT\nGATE 4: CHECK PROCESS\nGATE 5: READ LOGS ← MANDATORY, CANNOT SKIP\nGATE 6: VERIFY LOGS\nTHEN: E2E tests/screenshots\n```\n\n**You loaded dev-tdd earlier. Follow the gates now.**\n</EXTREMELY-IMPORTANT>\n\n## Contents\n\n- [Tool Availability Gate](#tool-availability-gate)\n- [When to Use Electron CDP](#when-to-use-electron-cdp)\n- [Connecting to Electron](#connecting-to-electron)\n- [CDP Domains](#cdp-domains)\n- [Renderer Process Automation](#renderer-process-automation)\n- [Main Process Control](#main-process-control)\n- [Verification](#verification)\n- [Complete E2E Examples](#complete-e2e-examples)\n\n# Electron E2E Testing via Chrome DevTools Protocol\n\n<EXTREMELY-IMPORTANT>\n## Tool Availability Gate\n\n**Verify CDP tooling is available before proceeding.**\n\nCheck for these tools:\n```bash\n# Check for curl (CDP communication)\nwhich curl || echo \"MISSING: curl\"\n\n# Check for jq (JSON parsing)\nwhich jq || echo \"MISSING: jq\"\n\n# Check for websocat or wscat (WebSocket CLI)\nwhich websocat || which wscat || echo \"MISSING: WebSocket CLI\"\n```\n\n**If missing tools:**\n```\nSTOP: Cannot proceed with Electron CDP automation.\n\nMissing tools needed for CDP:\n- curl (for HTTP requests)\n- jq (for JSON parsing)\n- websocat or wscat (for WebSocket communication)\n\nInstall with:\n  brew install curl jq websocat   # macOS\n  sudo apt install curl jq websocat   # Linux\n\nReply when installed and I'll continue testing.\n```\n\n**This gate is non-negotiable. Missing tools = full stop.**\n</EXTREMELY-IMPORTANT>\n\n<EXTREMELY-IMPORTANT>\n## When to Use Electron CDP\n\n**USE Electron CDP when you need:**\n- Test Electron desktop applications (VS Code, Slack, etc.)\n- Debug Electron renderer process (console, DOM, network)\n- Automate Electron main process (native menus, dialogs, IPC)\n- Multi-window Electron testing\n- Electron-specific features (webContents, BrowserWindow)\n- File system operations from Electron app\n\n**DO NOT use Electron CDP when:**\n- Testing web applications only (use Chrome MCP or Playwright)\n- Testing non-Electron desktop apps (use Hammerspoon for macOS, dev-test-linux for Linux)\n- Need headless CI/CD for web apps (use Playwright MCP)\n\n**For web apps, use:**\n- `Read(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-test-chrome/SKILL.md\")` - web debugging\n- `Read(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-test-playwright/SKILL.md\")` - headless CI/CD\n\n**For native desktop apps, use:**\n- `Skill(skill=\"workflows:dev-test-hammerspoon\")` - macOS\n- `Skill(skill=\"workflows:dev-test-linux\")` - Linux\n\n### Rationalization Prevention\n\n| Thought | Reality |\n|---------|---------|\n| \"Chrome MCP works for Electron\" | NO. Electron has main process + renderer. Need Electron-specific CDP. |\n| \"Playwright can test Electron apps\" | NO. Playwright is for web browsers, not Electron main process. |\n| \"I'll just test the renderer\" | Main process matters. File dialogs, native menus need testing too. |\n| \"CDP is too complex\" | It's the ONLY way to properly test Electron apps. Learn it. |\n| \"I can skip the main process\" | NO. Main process crashes break the app. Test both. |\n\n### Capability Comparison\n\n| Capability | Electron CDP | Chrome MCP | Playwright MCP | Hammerspoon |\n|------------|--------------|------------|----------------|-------------|\n| Electron renderer | ✅ | ❌ | ❌ | ❌ |\n| Electron main process | ✅ | ❌ | ❌ | ❌ |\n| Native menus/dialogs | ✅ | ❌ | ❌ | ✅ (macOS only) |\n| Multi-window Electron | ✅ | ❌ | ❌ | ✅ (macOS only) |\n| Console/network debugging | ✅ | ✅ (web only) | ❌ | ❌ |\n| Headless mode | ✅ | ❌ | ✅ (web only) | ❌ |\n| WebSocket IPC | ✅ | ❌ | ❌ | ❌ |\n</EXTREMELY-IMPORTANT>\n\n## Connecting to Electron\n\n<EXTREMELY-IMPORTANT>\n### The Iron Law of Connection\n\n**EVERY Electron E2E test MUST establish CDP connection BEFORE any automation.**\n\nYou CANNOT automate without:\n1. Launching Electron with CDP enabled\n2. Discovering the CDP WebSocket URL\n3. Connecting to the WebSocket\n4. Verifying the connection works\n\n| Action | Why It Fails Without Connection |\n|--------|----------------------------------|\n| Send CDP command | No connection = command never sent |\n| Read console logs | Can't receive events without WebSocket |\n| Navigate to page | CDP Page.navigate requires connection |\n| Take screenshot | CDP Page.captureScreenshot requires connection |\n\n**\"App is running\" ≠ \"CDP is connected\". Verify connection first.**\n</EXTREMELY-IMPORTANT>\n\n### Enable Remote Debugging\n\nLaunch Electron with remote debugging port:\n\n```bash\n# Option 1: Fixed port\n/path/to/electron-app --remote-debugging-port=9222\n\n# Option 2: Random port (app outputs port number)\n/path/to/electron-app --remote-debugging-port=0\n\n# Option 3: With logging\n/path/to/electron-app --remote-debugging-port=9222 --enable-logging --log-file=/tmp/electron.log 2>&1 &\n```\n\n**CRITICAL:** For GATE 2 (LAUNCH), always use `--log-file` flag for file-based logging.\n\n### Discover CDP WebSocket URL\n\n```bash\n# Get list of inspectable targets\ncurl -s http://localhost:9222/json/list | jq '.'\n\n# Extract WebSocket URL for main target\nWS_URL=$(curl -s http://localhost:9222/json/list | jq -r '.[0].webSocketDebuggerUrl')\necho \"WebSocket URL: $WS_URL\"\n```\n\nExample response:\n```json\n[\n  {\n    \"description\": \"\",\n    \"devtoolsFrontendUrl\": \"/devtools/inspector.html?ws=localhost:9222/devtools/page/...\",\n    \"id\": \"page-id\",\n    \"title\": \"My Electron App\",\n    \"type\": \"page\",\n    \"url\": \"file:///app/index.html\",\n    \"webSocketDebuggerUrl\": \"ws://localhost:9222/devtools/page/...\"\n  }\n]\n```\n\n### Connect via WebSocket\n\n```bash\n# Interactive WebSocket session\nwebsocat \"$WS_URL\"\n\n# Send CDP commands (one per line, JSON format)\n{\"id\":1,\"method\":\"Runtime.enable\"}\n{\"id\":2,\"method\":\"Page.enable\"}\n{\"id\":3,\"method\":\"Runtime.evaluate\",\"params\":{\"expression\":\"document.title\"}}\n```\n\n**Helper script:** See `scripts/connect-electron-cdp.sh` for automated connection.\n\n## CDP Domains\n\n### Essential Domains for Electron\n\n| Domain | Purpose | Example |\n|--------|---------|---------|\n| **Runtime** | Execute JavaScript, console logs | `Runtime.evaluate`, `Runtime.consoleAPICalled` |\n| **Page** | Navigation, screenshots, DOM events | `Page.navigate`, `Page.captureScreenshot` |\n| **DOM** | Query and manipulate DOM | `DOM.getDocument`, `DOM.querySelector` |\n| **Debugger** | Breakpoints, step debugging | `Debugger.setBreakpoint` |\n| **Network** | Network requests/responses | `Network.enable`, `Network.responseReceived` |\n| **Input** | Keyboard/mouse events | `Input.dispatchKeyEvent`, `Input.dispatchMouseEvent` |\n\n**Enable domains before use:**\n```json\n{\"id\":1,\"method\":\"Runtime.enable\"}\n{\"id\":2,\"method\":\"Page.enable\"}\n{\"id\":3,\"method\":\"DOM.enable\"}\n{\"id\":4,\"method\":\"Network.enable\"}\n```\n\n## Renderer Process Automation\n\n### Execute JavaScript\n\n```bash\n# Evaluate JavaScript expression\necho '{\"id\":1,\"method\":\"Runtime.evaluate\",\"params\":{\"expression\":\"document.title\"}}' | websocat \"$WS_URL\"\n\n# Execute with return value\necho '{\"id\":2,\"method\":\"Runtime.evaluate\",\"params\":{\"expression\":\"2 + 2\",\"returnByValue\":true}}' | websocat \"$WS_URL\"\n\n# Execute complex script\nSCRIPT='document.querySelector(\"#username\").value = \"testuser\"'\necho \"{\\\"id\\\":3,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$SCRIPT\\\"}}\" | websocat \"$WS_URL\"\n```\n\n### Navigate to URL\n\n```bash\n# Navigate to URL (file:// or http://)\necho '{\"id\":10,\"method\":\"Page.navigate\",\"params\":{\"url\":\"file:///app/index.html\"}}' | websocat \"$WS_URL\"\n\n# Wait for load event\necho '{\"id\":11,\"method\":\"Page.enable\"}' | websocat \"$WS_URL\"\n# Listen for Page.loadEventFired event\n```\n\n### Read Console Messages\n\n```bash\n# Enable Runtime domain to receive console events\necho '{\"id\":20,\"method\":\"Runtime.enable\"}' | websocat \"$WS_URL\"\n\n# Console events arrive as:\n# {\"method\":\"Runtime.consoleAPICalled\",\"params\":{\"type\":\"log\",\"args\":[...]}}\n```\n\n**For complete console reading, see `references/cdp-api.md`**\n\n### Take Screenshots\n\n```bash\n# Capture viewport screenshot (PNG base64)\necho '{\"id\":30,\"method\":\"Page.captureScreenshot\"}' | websocat \"$WS_URL\" > response.json\n\n# Extract base64 and decode\njq -r '.result.data' response.json | base64 -d > screenshot.png\n```\n\n### Query DOM\n\n```bash\n# Get document root\necho '{\"id\":40,\"method\":\"DOM.getDocument\"}' | websocat \"$WS_URL\"\n\n# Query selector\nROOT_ID=$(jq -r '.result.root.nodeId' response.json)\necho \"{\\\"id\\\":41,\\\"method\\\":\\\"DOM.querySelector\\\",\\\"params\\\":{\\\"nodeId\\\":$ROOT_ID,\\\"selector\\\":\\\"#submit-btn\\\"}}\" | websocat \"$WS_URL\"\n```\n\n## Main Process Control\n\n<EXTREMELY-IMPORTANT>\n### Electron Main Process vs Renderer Process\n\n**Electron has TWO processes:**\n\n| Process | What It Does | How to Test |\n|---------|--------------|-------------|\n| **Main** | Node.js runtime, native APIs, file system, menus, dialogs | CDP `Runtime.evaluate` in main context OR IPC |\n| **Renderer** | Browser/Chromium runtime, web content, DOM | CDP commands (Page, DOM, Runtime) |\n\n**Both processes MUST be tested. Renderer-only testing is incomplete.**\n</EXTREMELY-IMPORTANT>\n\n### Access Main Process via CDP\n\nSome Electron apps expose main process debugging:\n\n```bash\n# Check for main process target\ncurl -s http://localhost:9222/json/list | jq '.[] | select(.type == \"node\")'\n```\n\nIf main process is available:\n```bash\n# Get main process WebSocket URL\nMAIN_WS=$(curl -s http://localhost:9222/json/list | jq -r '.[] | select(.type == \"node\") | .webSocketDebuggerUrl')\n\n# Execute Node.js code in main process\necho '{\"id\":1,\"method\":\"Runtime.evaluate\",\"params\":{\"expression\":\"process.version\"}}' | websocat \"$MAIN_WS\"\n```\n\n### Trigger Native Dialogs (via IPC)\n\n```bash\n# From renderer, send IPC to main process\nSCRIPT='require(\"electron\").ipcRenderer.send(\"open-file-dialog\")'\necho \"{\\\"id\\\":50,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$SCRIPT\\\"}}\" | websocat \"$WS_URL\"\n```\n\n**For advanced main process patterns, see `references/electron-specific.md`**\n\n## Verification\n\n<EXTREMELY-IMPORTANT>\n### The Iron Law of Verification\n\n**EVERY CDP command must be VERIFIED. Sending the command is not enough.**\n\nAfter sending a CDP command, you MUST:\n1. Read the response\n2. Check for errors (`error` field in response)\n3. Verify the result matches expectations\n4. Document the verification\n\n| Command | Verification |\n|---------|--------------|\n| `Runtime.evaluate` | Check `result.value` or `result.exceptionDetails` |\n| `Page.navigate` | Wait for `Page.loadEventFired` event |\n| `Page.captureScreenshot` | Verify `result.data` exists and decode base64 |\n| `DOM.querySelector` | Check `result.nodeId` exists (not 0) |\n\n**\"I sent the command\" is not verification. Read the response and verify success.**\n</EXTREMELY-IMPORTANT>\n\n### Response Verification Pattern\n\n```bash\n# Send command and capture response\nRESPONSE=$(echo '{\"id\":100,\"method\":\"Runtime.evaluate\",\"params\":{\"expression\":\"2 + 2\"}}' | websocat --one-message \"$WS_URL\")\n\n# Check for error\nif echo \"$RESPONSE\" | jq -e '.error' > /dev/null; then\n    echo \"ERROR: CDP command failed\"\n    echo \"$RESPONSE\" | jq '.error'\n    exit 1\nfi\n\n# Verify result\nRESULT=$(echo \"$RESPONSE\" | jq -r '.result.result.value')\nif [ \"$RESULT\" != \"4\" ]; then\n    echo \"ERROR: Expected 4, got $RESULT\"\n    exit 1\nfi\n\necho \"✓ VERIFIED: 2 + 2 = $RESULT\"\n```\n\n### Event-Based Verification\n\n```bash\n# Enable Page domain\necho '{\"id\":1,\"method\":\"Page.enable\"}' | websocat \"$WS_URL\" &\n\n# Navigate and wait for load event\necho '{\"id\":2,\"method\":\"Page.navigate\",\"params\":{\"url\":\"file:///app/index.html\"}}' | websocat \"$WS_URL\"\n\n# Wait for Page.loadEventFired event (listen to WebSocket)\n# Event format: {\"method\":\"Page.loadEventFired\",\"params\":{...}}\n```\n\n## Complete E2E Examples\n\n### Basic Electron App Test (All 6 Gates)\n\n```bash\n#!/bin/bash\nset -e\n\n# ============ GATE 1: BUILD ============\necho \"GATE 1: Building Electron app...\"\ncd /path/to/electron-app\nnpm run build\necho \"✓ GATE 1 PASSED\"\n\n# ============ GATE 2: LAUNCH ============\necho \"GATE 2: Launching with CDP and logging...\"\nnpm start -- --remote-debugging-port=9222 --enable-logging --log-file=/tmp/electron.log 2>&1 &\nAPP_PID=$!\necho \"✓ GATE 2 PASSED (PID: $APP_PID)\"\n\n# ============ GATE 3: WAIT ============\necho \"GATE 3: Waiting for Electron initialization...\"\nsleep 3\necho \"✓ GATE 3 PASSED\"\n\n# ============ GATE 4: CHECK PROCESS ============\necho \"GATE 4: Checking Electron process...\"\nif ! ps -p $APP_PID > /dev/null; then\n    echo \"✗ GATE 4 FAILED: Electron process crashed\"\n    echo \"Reading logs from GATE 5...\"\n    cat /tmp/electron.log\n    exit 1\nfi\n\n# Verify CDP port is open\nif ! curl -s http://localhost:9222/json/list > /dev/null; then\n    echo \"✗ GATE 4 FAILED: CDP port not accessible\"\n    cat /tmp/electron.log\n    exit 1\nfi\necho \"✓ GATE 4 PASSED\"\n\n# ============ GATE 5: READ LOGS ============\necho \"GATE 5: Reading full runtime logs...\"\necho \"=== ELECTRON RUNTIME LOGS ===\"\ncat /tmp/electron.log\necho \"=== END LOGS ===\"\necho \"✓ GATE 5 PASSED (logs read)\"\n\n# ============ GATE 6: VERIFY LOGS ============\necho \"GATE 6: Verifying no errors in logs...\"\nif grep -qE \"(ERROR|FATAL|CRITICAL|Segmentation|core dumped|Uncaught Exception)\" /tmp/electron.log; then\n    echo \"✗ GATE 6 FAILED: Errors found in logs\"\n    exit 1\nfi\necho \"✓ GATE 6 PASSED\"\n\n# ============ NOW: E2E TESTING ============\necho \"All gates passed. Proceeding to E2E tests...\"\n\n# Get WebSocket URL\nWS_URL=$(curl -s http://localhost:9222/json/list | jq -r '.[0].webSocketDebuggerUrl')\necho \"CDP WebSocket: $WS_URL\"\n\n# Enable Runtime domain\necho '{\"id\":1,\"method\":\"Runtime.enable\"}' | websocat --one-message \"$WS_URL\"\n\n# Execute test: Get document title\nRESPONSE=$(echo '{\"id\":2,\"method\":\"Runtime.evaluate\",\"params\":{\"expression\":\"document.title\",\"returnByValue\":true}}' | websocat --one-message \"$WS_URL\")\n\n# Verify response\nif echo \"$RESPONSE\" | jq -e '.error' > /dev/null; then\n    echo \"✗ E2E FAILED: CDP command error\"\n    echo \"$RESPONSE\" | jq '.error'\n    exit 1\nfi\n\nTITLE=$(echo \"$RESPONSE\" | jq -r '.result.result.value')\necho \"✓ E2E VERIFIED: Document title = '$TITLE'\"\n\n# Take screenshot\nSCREENSHOT_RESPONSE=$(echo '{\"id\":3,\"method\":\"Page.captureScreenshot\"}' | websocat --one-message \"$WS_URL\")\necho \"$SCREENSHOT_RESPONSE\" | jq -r '.result.data' | base64 -d > /tmp/electron_screenshot.png\necho \"✓ Screenshot saved: /tmp/electron_screenshot.png\"\n\n# Cleanup\nkill $APP_PID\necho \"✓ E2E TEST PASSED\"\n```\n\n**Tool description:** Execute all 6 gates, then run Electron E2E test with CDP\n\n### Form Automation Example\n\n```bash\n#!/bin/bash\n# Assumes gates 1-6 already passed and WS_URL is set\n\n# Enable domains\necho '{\"id\":1,\"method\":\"Runtime.enable\"}' | websocat --one-message \"$WS_URL\"\necho '{\"id\":2,\"method\":\"Page.enable\"}' | websocat --one-message \"$WS_URL\"\n\n# Fill form field\nFILL_USERNAME='document.querySelector(\"#username\").value = \"testuser\"'\nRESPONSE=$(echo \"{\\\"id\\\":10,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$FILL_USERNAME\\\"}}\" | websocat --one-message \"$WS_URL\")\n\nif echo \"$RESPONSE\" | jq -e '.error' > /dev/null; then\n    echo \"✗ FAILED: Could not fill username\"\n    exit 1\nfi\n\nFILL_PASSWORD='document.querySelector(\"#password\").value = \"testpass\"'\necho \"{\\\"id\\\":11,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$FILL_PASSWORD\\\"}}\" | websocat --one-message \"$WS_URL\"\n\n# Click submit button\nCLICK_SUBMIT='document.querySelector(\"#submit-btn\").click()'\necho \"{\\\"id\\\":12,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$CLICK_SUBMIT\\\"}}\" | websocat --one-message \"$WS_URL\"\n\n# Wait for navigation\nsleep 1\n\n# Verify success message appears\nCHECK_SUCCESS='document.querySelector(\".success-message\") !== null'\nVERIFY_RESPONSE=$(echo \"{\\\"id\\\":13,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$CHECK_SUCCESS\\\",\\\"returnByValue\\\":true}}\" | websocat --one-message \"$WS_URL\")\n\nSUCCESS=$(echo \"$VERIFY_RESPONSE\" | jq -r '.result.result.value')\nif [ \"$SUCCESS\" != \"true\" ]; then\n    echo \"✗ VERIFICATION FAILED: Success message not found\"\n    exit 1\nfi\n\necho \"✓ VERIFIED: Form submission successful\"\n\n# Screenshot for evidence\necho '{\"id\":14,\"method\":\"Page.captureScreenshot\"}' | websocat --one-message \"$WS_URL\" | jq -r '.result.data' | base64 -d > /tmp/form_success.png\necho \"✓ Screenshot: /tmp/form_success.png\"\n```\n\n### Multi-Window Testing\n\n```bash\n# Get all inspectable targets\ncurl -s http://localhost:9222/json/list | jq '.[] | {title: .title, url: .url, wsUrl: .webSocketDebuggerUrl}'\n\n# Connect to specific window by title\nWINDOW_WS=$(curl -s http://localhost:9222/json/list | jq -r '.[] | select(.title == \"Settings Window\") | .webSocketDebuggerUrl')\n\n# Automate the settings window\necho '{\"id\":1,\"method\":\"Runtime.evaluate\",\"params\":{\"expression\":\"document.querySelector(\\\"#theme\\\").value = \\\"dark\\\"\"}}' | websocat --one-message \"$WINDOW_WS\"\n```\n\n**For more advanced patterns, see `references/advanced-patterns.md`**\n\n## Error Handling\n\n### Common CDP Errors\n\n| Error | Cause | Solution |\n|-------|-------|----------|\n| Connection refused | Electron not started with `--remote-debugging-port` | Restart with flag |\n| WebSocket timeout | App crashed or port blocked | Check GATE 4 (process) and GATE 5 (logs) |\n| `\"error\":{\"code\":-32601}` | Method not found | Enable domain first (e.g., `Runtime.enable`) |\n| `exceptionDetails` in result | JavaScript error in evaluated code | Check expression syntax |\n| Empty response | WebSocket closed | Reconnect to WebSocket |\n\n### Retry Pattern\n\n```bash\n# Retry CDP command up to 3 times\nfor i in {1..3}; do\n    RESPONSE=$(echo \"$CDP_COMMAND\" | websocat --one-message \"$WS_URL\")\n\n    if echo \"$RESPONSE\" | jq -e '.result' > /dev/null; then\n        echo \"✓ Command succeeded on attempt $i\"\n        break\n    fi\n\n    if [ $i -eq 3 ]; then\n        echo \"✗ Command failed after 3 attempts\"\n        echo \"$RESPONSE\"\n        exit 1\n    fi\n\n    echo \"Retry $i failed, waiting 1s...\"\n    sleep 1\ndone\n```\n\n## Limitations\n\n<EXTREMELY-IMPORTANT>\n### What Electron CDP Cannot Do\n\n| Need | Why Electron CDP Fails | Use Instead |\n|------|------------------------|-------------|\n| Native macOS window management | CDP doesn't control OS | Hammerspoon (macOS) |\n| Cross-platform native automation | CDP is Chromium-only | Platform-specific tools |\n| Test non-Electron apps | CDP requires Electron/Chromium | Hammerspoon, dev-test-linux |\n| Headless CI/CD for web apps | Electron is for desktop apps | Playwright MCP |\n\n**For web apps, use Playwright or Chrome MCP. For native desktop, use platform tools.**\n</EXTREMELY-IMPORTANT>\n\n## Additional Resources\n\n### Reference Files\n\nFor detailed CDP API documentation and Electron-specific features:\n- **`references/cdp-api.md`** - Complete CDP domains reference (Runtime, Page, DOM, Network, Input, Debugger)\n- **`references/electron-specific.md`** - Electron main process, IPC, native APIs, file dialogs\n- **`references/advanced-patterns.md`** - Multi-window, devtools, event listeners, WebSocket streaming\n\n### Example Files\n\nWorking examples in `examples/`:\n- **`basic-test.sh`** - Complete E2E test with all 6 gates\n- **`cdp-commands.json`** - Common CDP command reference\n\n### Scripts\n\nUtility scripts in `scripts/`:\n- **`connect-electron-cdp.sh`** - Automated CDP connection discovery\n- **`launch-electron-with-logging.sh`** - Launch template with proper logging\n- **`verify-electron-process.sh`** - Health check for main + renderer\n\n## VS Code Extension Testing (Common Case)\n\n<EXTREMELY-IMPORTANT>\n**VS Code extensions are a common Electron test case. Here's how to test them REAL.**\n\n### What Makes VS Code Extension Tests REAL\n\n| User Action | FAKE Test | REAL Test |\n|-------------|-----------|-----------|\n| Highlight text in editor | `editor.setSelection()` programmatically | CDP simulate actual text selection |\n| Click Claude panel | Call panel function directly | CDP click on actual panel element |\n| See status in panel | Check internal state variable | CDP query panel DOM for displayed text |\n| Extension uses WebSocket | Test HTTP endpoint | Test WebSocket connection |\n\n### VS Code Extension Protocol Discovery\n\nBefore testing, discover what protocol the extension uses:\n\n```bash\n# Search for WebSocket usage\nrg \"WebSocket|ws://\" --type ts\n\n# Search for HTTP usage\nrg \"fetch|axios|http\" --type ts\n\n# Search for IPC usage\nrg \"ipcRenderer|ipcMain\" --type ts\n```\n\n**If extension uses WebSocket → Your test MUST use WebSocket, not HTTP.**\n\n### Example: Testing Selection → Panel Status\n\n**FAKE test (DON'T DO THIS):**\n```javascript\n// FAKE: Calls function directly, checks internal state\nconst selection = await vscode.window.activeTextEditor.selection;\nawait extensionApi.updateSelection(selection);  // Direct call!\nexpect(internalState.selectionCount).toBe(5);   // Internal state!\n```\n\n**REAL test (DO THIS):**\n```bash\n# REAL: Simulates user, checks what user sees\n\n# 1. Use CDP to simulate text selection in editor\nSCRIPT='\n  const editor = document.querySelector(\".monaco-editor\");\n  // Simulate actual selection via CDP Input events\n'\necho \"{\\\"id\\\":1,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$SCRIPT\\\"}}\" | websocat \"$WS_URL\"\n\n# 2. Use CDP to query Claude panel for displayed status\nVERIFY='document.querySelector(\".claude-panel .status-text\").textContent'\nRESULT=$(echo \"{\\\"id\\\":2,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$VERIFY\\\",\\\"returnByValue\\\":true}}\" | websocat --one-message \"$WS_URL\")\n\n# 3. Verify user-visible output\nSTATUS=$(echo \"$RESULT\" | jq -r '.result.result.value')\nif [[ \"$STATUS\" != *\"5 lines selected\"* ]]; then\n    echo \"✗ FAKE TEST: Panel doesn't show expected status\"\n    exit 1\nfi\necho \"✓ REAL TEST: Panel shows '$STATUS'\"\n```\n\n### VS Code Extension Test Checklist\n\nBefore writing VS Code extension test, verify:\n\n```\n[ ] Protocol discovered (WebSocket/HTTP/IPC)\n[ ] User workflow documented (what user clicks/sees)\n[ ] Test uses SAME protocol as extension\n[ ] Test simulates ACTUAL user actions (not API calls)\n[ ] Test verifies PANEL DISPLAY (not internal state)\n[ ] Test covers BOTH main and renderer processes\n```\n\n**If any box is unchecked → Your test is probably FAKE.**\n</EXTREMELY-IMPORTANT>\n\n## Integration\n\nThis skill is referenced by `dev-test` for Electron desktop application testing.\n\n**For web debugging, use:** `Read(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-test-chrome/SKILL.md\")`\n**For headless web CI/CD, use:** `Read(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-test-playwright/SKILL.md\")`\n**For macOS native apps, use:** `Skill(skill=\"workflows:dev-test-hammerspoon\")`\n\nFor TDD protocol and gate enforcement, see: `Skill(skill=\"workflows:dev-tdd\")`\n",
        "skills/dev-test-electron/references/advanced-patterns.md": "# Advanced Electron CDP Patterns\n\nComplex testing scenarios for Electron applications.\n\n## Multi-Window Testing\n\n### Enumerate All Windows\n\n```bash\n#!/bin/bash\n# Get all CDP targets (all windows)\nTARGETS=$(curl -s http://localhost:9222/json/list)\n\necho \"All Electron windows:\"\necho \"$TARGETS\" | jq -r '.[] | \"\\(.title) - \\(.url)\"'\n\n# Filter by URL pattern\nSETTINGS_WS=$(echo \"$TARGETS\" | jq -r '.[] | select(.url | contains(\"settings.html\")) | .webSocketDebuggerUrl')\nMAIN_WS=$(echo \"$TARGETS\" | jq -r '.[] | select(.url | contains(\"index.html\")) | .webSocketDebuggerUrl')\n\necho \"Main window: $MAIN_WS\"\necho \"Settings window: $SETTINGS_WS\"\n```\n\n### Test Window Communication\n\n```bash\n#!/bin/bash\n# Test data flow between windows via main process\n\n# Window 1: Set shared data\nSCRIPT_1='\nwindow.electronAPI.invoke(\"set-shared-data\", {key: \"test\", value: \"hello\"})\n'\n\nRESPONSE=$(echo \"{\\\"id\\\":1,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":$(echo \"$SCRIPT_1\" | jq -Rs .),\\\"awaitPromise\\\":true}}\" | websocat --one-message \"$WINDOW1_WS\")\n\nif echo \"$RESPONSE\" | jq -e '.result.exceptionDetails' > /dev/null; then\n  echo \"✗ FAILED: Could not set shared data\"\n  exit 1\nfi\n\necho \"✓ Window 1: Shared data set\"\n\n# Wait for propagation\nsleep 0.5\n\n# Window 2: Get shared data\nSCRIPT_2='\nwindow.electronAPI.invoke(\"get-shared-data\", \"test\")\n'\n\nRESPONSE=$(echo \"{\\\"id\\\":2,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":$(echo \"$SCRIPT_2\" | jq -Rs .),\\\"awaitPromise\\\":true,\\\"returnByValue\\\":true}}\" | websocat --one-message \"$WINDOW2_WS\")\n\nVALUE=$(echo \"$RESPONSE\" | jq -r '.result.result.value')\nif [ \"$VALUE\" != \"hello\" ]; then\n  echo \"✗ FAILED: Window 2 did not receive data (expected 'hello', got '$VALUE')\"\n  exit 1\nfi\n\necho \"✓ Window 2: Retrieved shared data = '$VALUE'\"\necho \"✓ VERIFIED: Inter-window communication works\"\n```\n\n### Parallel Window Testing\n\n```bash\n#!/bin/bash\n# Test multiple windows concurrently\n\ntest_window() {\n  local ws_url=\"$1\"\n  local window_name=\"$2\"\n\n  # Enable Runtime\n  echo '{\"id\":1,\"method\":\"Runtime.enable\"}' | websocat --one-message \"$ws_url\"\n\n  # Get window title\n  RESPONSE=$(echo '{\"id\":2,\"method\":\"Runtime.evaluate\",\"params\":{\"expression\":\"document.title\",\"returnByValue\":true}}' | websocat --one-message \"$ws_url\")\n\n  TITLE=$(echo \"$RESPONSE\" | jq -r '.result.result.value')\n  echo \"$window_name: Title = '$TITLE'\"\n}\n\n# Test all windows in parallel\nALL_WINDOWS=$(curl -s http://localhost:9222/json/list | jq -r '.[] | select(.type == \"page\") | .webSocketDebuggerUrl')\n\nINDEX=0\nfor WS in $ALL_WINDOWS; do\n  INDEX=$((INDEX + 1))\n  test_window \"$WS\" \"Window $INDEX\" &\ndone\n\n# Wait for all tests\nwait\n\necho \"✓ All windows tested\"\n```\n\n## Event Streaming\n\n### Stream Console Logs\n\n```bash\n#!/bin/bash\n# Stream console logs in real-time\n\nWS_URL=$(curl -s http://localhost:9222/json/list | jq -r '.[0].webSocketDebuggerUrl')\n\n# Start streaming\n{\n  # Enable Runtime domain\n  echo '{\"id\":1,\"method\":\"Runtime.enable\"}'\n\n  # Keep connection alive\n  sleep 300  # Listen for 5 minutes\n} | websocat \"$WS_URL\" | while read -r line; do\n  # Parse console events\n  METHOD=$(echo \"$line\" | jq -r '.method // empty')\n\n  if [ \"$METHOD\" = \"Runtime.consoleAPICalled\" ]; then\n    TYPE=$(echo \"$line\" | jq -r '.params.type')\n    ARGS=$(echo \"$line\" | jq -r '.params.args | map(.value // .description) | join(\" \")')\n    TIMESTAMP=$(echo \"$line\" | jq -r '.params.timestamp')\n\n    echo \"[$TIMESTAMP] console.$TYPE: $ARGS\"\n  fi\ndone\n```\n\n### Stream Network Events\n\n```bash\n#!/bin/bash\n# Monitor all network requests/responses\n\nWS_URL=$(curl -s http://localhost:9222/json/list | jq -r '.[0].webSocketDebuggerUrl')\n\n# Track requests\ndeclare -A REQUESTS\n\n{\n  echo '{\"id\":1,\"method\":\"Network.enable\"}'\n  sleep 60\n} | websocat \"$WS_URL\" | while read -r line; do\n  METHOD=$(echo \"$line\" | jq -r '.method // empty')\n\n  case \"$METHOD\" in\n    Network.requestWillBeSent)\n      REQ_ID=$(echo \"$line\" | jq -r '.params.requestId')\n      URL=$(echo \"$line\" | jq -r '.params.request.url')\n      REQUEST_METHOD=$(echo \"$line\" | jq -r '.params.request.method')\n\n      echo \"→ REQUEST: $REQUEST_METHOD $URL\"\n      REQUESTS[$REQ_ID]=\"$URL\"\n      ;;\n\n    Network.responseReceived)\n      REQ_ID=$(echo \"$line\" | jq -r '.params.requestId')\n      STATUS=$(echo \"$line\" | jq -r '.params.response.status')\n      URL=\"${REQUESTS[$REQ_ID]}\"\n\n      echo \"← RESPONSE: $STATUS $URL\"\n      ;;\n\n    Network.loadingFailed)\n      REQ_ID=$(echo \"$line\" | jq -r '.params.requestId')\n      ERROR=$(echo \"$line\" | jq -r '.params.errorText')\n      URL=\"${REQUESTS[$REQ_ID]}\"\n\n      echo \"✗ FAILED: $URL ($ERROR)\"\n      ;;\n  esac\ndone\n```\n\n### Stream Page Lifecycle Events\n\n```bash\n#!/bin/bash\n# Monitor page load, DOM ready, etc.\n\nWS_URL=$(curl -s http://localhost:9222/json/list | jq -r '.[0].webSocketDebuggerUrl')\n\n{\n  echo '{\"id\":1,\"method\":\"Page.enable\"}'\n  echo '{\"id\":2,\"method\":\"Runtime.enable\"}'\n  sleep 30\n} | websocat \"$WS_URL\" | while read -r line; do\n  METHOD=$(echo \"$line\" | jq -r '.method // empty')\n\n  case \"$METHOD\" in\n    Page.loadEventFired)\n      echo \"✓ Page load complete\"\n      ;;\n\n    Page.domContentEventFired)\n      echo \"✓ DOM content loaded\"\n      ;;\n\n    Page.frameNavigated)\n      URL=$(echo \"$line\" | jq -r '.params.frame.url')\n      echo \"→ Navigated to: $URL\"\n      ;;\n\n    Runtime.executionContextCreated)\n      NAME=$(echo \"$line\" | jq -r '.params.context.name')\n      echo \"✓ Execution context created: $NAME\"\n      ;;\n  esac\ndone\n```\n\n## Headless Mode\n\n### Launch Electron Headless\n\n```bash\n# Electron headless mode (Xvfb on Linux)\nif [ \"$(uname)\" = \"Linux\" ]; then\n  # Start virtual display\n  Xvfb :99 -screen 0 1920x1080x24 &\n  XVFB_PID=$!\n  export DISPLAY=:99\nfi\n\n# Launch Electron\n/path/to/app --remote-debugging-port=9222 --enable-logging --log-file=/tmp/electron.log 2>&1 &\nAPP_PID=$!\n\n# Wait for startup\nsleep 3\n\n# Run tests...\n\n# Cleanup\nkill $APP_PID\n[ -n \"$XVFB_PID\" ] && kill $XVFB_PID\n```\n\n### Headless Screenshot\n\n```bash\n#!/bin/bash\n# Take screenshot in headless mode\n\nWS_URL=$(curl -s http://localhost:9222/json/list | jq -r '.[0].webSocketDebuggerUrl')\n\n# Enable Page domain\necho '{\"id\":1,\"method\":\"Page.enable\"}' | websocat --one-message \"$WS_URL\"\n\n# Wait for page load\nsleep 2\n\n# Capture screenshot\nRESPONSE=$(echo '{\"id\":2,\"method\":\"Page.captureScreenshot\",\"params\":{\"format\":\"png\"}}' | websocat --one-message \"$WS_URL\")\n\nif echo \"$RESPONSE\" | jq -e '.error' > /dev/null; then\n  echo \"✗ Screenshot failed: $(echo \"$RESPONSE\" | jq -r '.error.message')\"\n  exit 1\nfi\n\n# Save screenshot\necho \"$RESPONSE\" | jq -r '.result.data' | base64 -d > /tmp/headless_screenshot.png\necho \"✓ Screenshot saved: /tmp/headless_screenshot.png\"\n```\n\n## DevTools Integration\n\n### Open DevTools Programmatically\n\n```bash\n# From main process\nOPEN_DEVTOOLS='\nconst { BrowserWindow } = require(\"electron\");\nBrowserWindow.getFocusedWindow().webContents.openDevTools({mode: \"detach\"});\n'\n\nMAIN_WS=$(curl -s http://localhost:9222/json/list | jq -r '.[] | select(.type == \"node\") | .webSocketDebuggerUrl')\n\necho \"{\\\"id\\\":1,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":$(echo \"$OPEN_DEVTOOLS\" | jq -Rs .)}}\" | websocat --one-message \"$MAIN_WS\"\n\necho \"✓ DevTools opened\"\n```\n\n### Execute in DevTools Context\n\n```bash\n# Get DevTools WebSocket URL (it appears as a separate target)\nsleep 2  # Wait for DevTools to initialize\nDEVTOOLS_WS=$(curl -s http://localhost:9222/json/list | jq -r '.[] | select(.url | contains(\"devtools://\")) | .webSocketDebuggerUrl')\n\nif [ -z \"$DEVTOOLS_WS\" ]; then\n  echo \"DevTools not available\"\n  exit 1\nfi\n\necho \"DevTools WebSocket: $DEVTOOLS_WS\"\n\n# Now you can automate DevTools itself\necho '{\"id\":1,\"method\":\"Runtime.enable\"}' | websocat --one-message \"$DEVTOOLS_WS\"\n```\n\n## Performance Monitoring\n\n### Capture Performance Metrics\n\n```bash\n#!/bin/bash\n# Collect performance metrics\n\nWS_URL=$(curl -s http://localhost:9222/json/list | jq -r '.[0].webSocketDebuggerUrl')\n\n# Enable Performance domain\necho '{\"id\":1,\"method\":\"Performance.enable\"}' | websocat --one-message \"$WS_URL\"\n\n# Get metrics\nRESPONSE=$(echo '{\"id\":2,\"method\":\"Performance.getMetrics\"}' | websocat --one-message \"$WS_URL\")\n\n# Parse metrics\necho \"$RESPONSE\" | jq -r '.result.metrics[] | \"\\(.name): \\(.value)\"'\n\n# Example metrics:\n# Timestamp, Documents, Frames, JSEventListeners, Nodes, LayoutCount, RecalcStyleCount,\n# JSHeapUsedSize, JSHeapTotalSize, etc.\n```\n\n### Memory Profiling\n\n```bash\n#!/bin/bash\n# Capture heap snapshot\n\nWS_URL=$(curl -s http://localhost:9222/json/list | jq -r '.[0].webSocketDebuggerUrl')\n\n# Enable HeapProfiler\necho '{\"id\":1,\"method\":\"HeapProfiler.enable\"}' | websocat --one-message \"$WS_URL\"\n\n# Take heap snapshot\necho '{\"id\":2,\"method\":\"HeapProfiler.takeHeapSnapshot\"}' | websocat --one-message \"$WS_URL\"\n\n# Heap snapshot is returned as a series of HeapProfiler.addHeapSnapshotChunk events\n# Collect all chunks and save to file\n```\n\n### CPU Profiling\n\n```bash\n#!/bin/bash\n# Profile JavaScript execution\n\nWS_URL=$(curl -s http://localhost:9222/json/list | jq -r '.[0].webSocketDebuggerUrl')\n\n# Enable Profiler\necho '{\"id\":1,\"method\":\"Profiler.enable\"}' | websocat --one-message \"$WS_URL\"\n\n# Start profiling\necho '{\"id\":2,\"method\":\"Profiler.start\"}' | websocat --one-message \"$WS_URL\"\n\n# Let app run for 10 seconds\nsleep 10\n\n# Stop profiling\nRESPONSE=$(echo '{\"id\":3,\"method\":\"Profiler.stop\"}' | websocat --one-message \"$WS_URL\")\n\n# Save profile\necho \"$RESPONSE\" | jq '.result.profile' > /tmp/cpu_profile.json\necho \"✓ CPU profile saved: /tmp/cpu_profile.json\"\n```\n\n## Coverage Collection\n\n### JavaScript Coverage\n\n```bash\n#!/bin/bash\n# Collect JS code coverage\n\nWS_URL=$(curl -s http://localhost:9222/json/list | jq -r '.[0].webSocketDebuggerUrl')\n\n# Enable Profiler\necho '{\"id\":1,\"method\":\"Profiler.enable\"}' | websocat --one-message \"$WS_URL\"\n\n# Start precise coverage\necho '{\"id\":2,\"method\":\"Profiler.startPreciseCoverage\",\"params\":{\"callCount\":true,\"detailed\":true}}' | websocat --one-message \"$WS_URL\"\n\n# Run tests...\n# (execute user actions, run E2E scenarios)\nsleep 5\n\n# Take coverage snapshot\nRESPONSE=$(echo '{\"id\":3,\"method\":\"Profiler.takePreciseCoverage\"}' | websocat --one-message \"$WS_URL\")\n\n# Save coverage data\necho \"$RESPONSE\" | jq '.result.result' > /tmp/coverage.json\n\n# Stop coverage\necho '{\"id\":4,\"method\":\"Profiler.stopPreciseCoverage\"}' | websocat --one-message \"$WS_URL\"\n\necho \"✓ Coverage saved: /tmp/coverage.json\"\n\n# Analyze coverage\nTOTAL_BYTES=$(jq '[.[].functions[].ranges[].endOffset - .startOffset] | add' /tmp/coverage.json)\nCOVERED_BYTES=$(jq '[.[].functions[].ranges[] | select(.count > 0) | .endOffset - .startOffset] | add' /tmp/coverage.json)\n\nCOVERAGE_PCT=$(echo \"scale=2; $COVERED_BYTES * 100 / $TOTAL_BYTES\" | bc)\necho \"Coverage: $COVERAGE_PCT%\"\n```\n\n## Error Injection\n\n### Simulate Network Errors\n\n```bash\n#!/bin/bash\n# Block network requests to test error handling\n\nWS_URL=$(curl -s http://localhost:9222/json/list | jq -r '.[0].webSocketDebuggerUrl')\n\n# Enable Network\necho '{\"id\":1,\"method\":\"Network.enable\"}' | websocat --one-message \"$WS_URL\"\n\n# Block URL pattern\necho '{\"id\":2,\"method\":\"Network.setBlockedURLs\",\"params\":{\"urls\":[\"*api.example.com*\"]}}' | websocat --one-message \"$WS_URL\"\n\necho \"✓ Blocked api.example.com requests\"\n\n# Now test how app handles network failures\n# ...\n\n# Unblock\necho '{\"id\":3,\"method\":\"Network.setBlockedURLs\",\"params\":{\"urls\":[]}}' | websocat --one-message \"$WS_URL\"\n```\n\n### Emulate Offline Mode\n\n```bash\n# Emulate offline network\necho '{\"id\":10,\"method\":\"Network.emulateNetworkConditions\",\"params\":{\"offline\":true,\"latency\":0,\"downloadThroughput\":0,\"uploadThroughput\":0}}' | websocat --one-message \"$WS_URL\"\n\necho \"✓ App is now offline\"\n\n# Test offline behavior...\n\n# Restore online\necho '{\"id\":11,\"method\":\"Network.emulateNetworkConditions\",\"params\":{\"offline\":false,\"latency\":0,\"downloadThroughput\":-1,\"uploadThroughput\":-1}}' | websocat --one-message \"$WS_URL\"\n```\n\n### Throttle Network Speed\n\n```bash\n# Emulate slow 3G\necho '{\"id\":12,\"method\":\"Network.emulateNetworkConditions\",\"params\":{\"offline\":false,\"latency\":100,\"downloadThroughput\":750000,\"uploadThroughput\":250000}}' | websocat --one-message \"$WS_URL\"\n\necho \"✓ Network throttled to slow 3G\"\n```\n\n## Storage Manipulation\n\n### LocalStorage Access\n\n```bash\n# Get all localStorage keys\nGET_STORAGE='\n(() => {\n  const keys = [];\n  for (let i = 0; i < localStorage.length; i++) {\n    const key = localStorage.key(i);\n    keys.push({ key, value: localStorage.getItem(key) });\n  }\n  return keys;\n})()\n'\n\nRESPONSE=$(echo \"{\\\"id\\\":1,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":$(echo \"$GET_STORAGE\" | jq -Rs .),\\\"returnByValue\\\":true}}\" | websocat --one-message \"$WS_URL\")\n\nSTORAGE=$(echo \"$RESPONSE\" | jq -r '.result.result.value')\necho \"LocalStorage: $STORAGE\"\n```\n\n### Set LocalStorage Item\n\n```bash\n# Set localStorage item\nSET_ITEM='localStorage.setItem(\"test-key\", \"test-value\")'\n\necho \"{\\\"id\\\":2,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$SET_ITEM\\\"}}\" | websocat --one-message \"$WS_URL\"\n\necho \"✓ LocalStorage item set\"\n```\n\n### Clear All Storage\n\n```bash\n# Clear localStorage, sessionStorage, IndexedDB, etc.\nCLEAR_ALL='\nlocalStorage.clear();\nsessionStorage.clear();\nindexedDB.databases().then(dbs => dbs.forEach(db => indexedDB.deleteDatabase(db.name)));\n'\n\necho \"{\\\"id\\\":3,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":$(echo \"$CLEAR_ALL\" | jq -Rs .)}}\" | websocat --one-message \"$WS_URL\"\n\necho \"✓ All storage cleared\"\n```\n\n## Custom Protocol Testing\n\n### Register Custom Protocol Handler\n\nFrom main process:\n\n```bash\n# Register custom protocol (e.g., myapp://)\nREGISTER_PROTOCOL='\nconst { protocol } = require(\"electron\");\nprotocol.registerStringProtocol(\"myapp\", (request, callback) => {\n  const url = request.url.replace(\"myapp://\", \"\");\n  callback({ data: `<html><body>Custom protocol: ${url}</body></html>`, mimeType: \"text/html\" });\n});\n'\n\nMAIN_WS=$(curl -s http://localhost:9222/json/list | jq -r '.[] | select(.type == \"node\") | .webSocketDebuggerUrl')\n\necho \"{\\\"id\\\":1,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":$(echo \"$REGISTER_PROTOCOL\" | jq -Rs .)}}\" | websocat --one-message \"$MAIN_WS\"\n\necho \"✓ Custom protocol registered\"\n\n# Now navigate to custom protocol URL\nRENDERER_WS=$(curl -s http://localhost:9222/json/list | jq -r '.[0].webSocketDebuggerUrl')\n\necho '{\"id\":10,\"method\":\"Page.navigate\",\"params\":{\"url\":\"myapp://test-page\"}}' | websocat --one-message \"$RENDERER_WS\"\n\n# Verify page loaded\nsleep 1\nRESPONSE=$(echo '{\"id\":11,\"method\":\"Runtime.evaluate\",\"params\":{\"expression\":\"document.body.textContent\",\"returnByValue\":true}}' | websocat --one-message \"$RENDERER_WS\")\n\nCONTENT=$(echo \"$RESPONSE\" | jq -r '.result.result.value')\necho \"Page content: $CONTENT\"\n```\n\n## Complete Advanced E2E Test\n\n```bash\n#!/bin/bash\nset -e\n\n# Multi-window + Performance + Network monitoring test\n\n# 1. Launch app (gates 1-6 assumed completed)\nAPP_PID=$(pgrep -f \"electron.*--remote-debugging-port=9222\")\n\n# 2. Get all windows\nMAIN_WS=$(curl -s http://localhost:9222/json/list | jq -r '.[] | select(.url | contains(\"index.html\")) | .webSocketDebuggerUrl')\nSETTINGS_WS=$(curl -s http://localhost:9222/json/list | jq -r '.[] | select(.url | contains(\"settings.html\")) | .webSocketDebuggerUrl')\n\necho \"✓ Connected to 2 windows\"\n\n# 3. Start performance monitoring\necho '{\"id\":1,\"method\":\"Performance.enable\"}' | websocat --one-message \"$MAIN_WS\" &\n\n# 4. Start network monitoring\n{\n  echo '{\"id\":2,\"method\":\"Network.enable\"}'\n  sleep 30\n} | websocat \"$MAIN_WS\" > /tmp/network_events.txt &\nNETWORK_PID=$!\n\n# 5. Test main window workflow\necho '{\"id\":10,\"method\":\"Runtime.enable\"}' | websocat --one-message \"$MAIN_WS\"\n\nCLICK_BTN='document.querySelector(\"#load-data-btn\").click()'\necho \"{\\\"id\\\":11,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$CLICK_BTN\\\"}}\" | websocat --one-message \"$MAIN_WS\"\n\necho \"✓ Clicked load data button\"\n\n# 6. Wait for network request\nsleep 2\n\n# 7. Verify data loaded\nCHECK_DATA='document.querySelector(\".data-loaded\") !== null'\nRESPONSE=$(echo \"{\\\"id\\\":12,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$CHECK_DATA\\\",\\\"returnByValue\\\":true}}\" | websocat --one-message \"$MAIN_WS\")\n\nLOADED=$(echo \"$RESPONSE\" | jq -r '.result.result.value')\nif [ \"$LOADED\" != \"true\" ]; then\n  echo \"✗ FAILED: Data not loaded\"\n  exit 1\nfi\n\necho \"✓ Data loaded successfully\"\n\n# 8. Test settings window\necho '{\"id\":20,\"method\":\"Runtime.enable\"}' | websocat --one-message \"$SETTINGS_WS\"\n\nSET_THEME='document.querySelector(\"#theme-select\").value = \"dark\"'\necho \"{\\\"id\\\":21,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$SET_THEME\\\"}}\" | websocat --one-message \"$SETTINGS_WS\"\n\nSAVE_BTN='document.querySelector(\"#save-btn\").click()'\necho \"{\\\"id\\\":22,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$SAVE_BTN\\\"}}\" | websocat --one-message \"$SETTINGS_WS\"\n\necho \"✓ Changed theme to dark\"\n\n# 9. Verify theme applied in main window\nsleep 1\nCHECK_THEME='document.body.classList.contains(\"dark-theme\")'\nRESPONSE=$(echo \"{\\\"id\\\":13,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$CHECK_THEME\\\",\\\"returnByValue\\\":true}}\" | websocat --one-message \"$MAIN_WS\")\n\nIS_DARK=$(echo \"$RESPONSE\" | jq -r '.result.result.value')\nif [ \"$IS_DARK\" != \"true\" ]; then\n  echo \"✗ FAILED: Theme not applied\"\n  exit 1\nfi\n\necho \"✓ Dark theme applied across windows\"\n\n# 10. Get performance metrics\nPERF_RESPONSE=$(echo '{\"id\":14,\"method\":\"Performance.getMetrics\"}' | websocat --one-message \"$MAIN_WS\")\n\nHEAP_SIZE=$(echo \"$PERF_RESPONSE\" | jq -r '.result.metrics[] | select(.name == \"JSHeapUsedSize\") | .value')\necho \"Heap size: $HEAP_SIZE bytes\"\n\n# 11. Stop network monitoring\nkill $NETWORK_PID\n\n# 12. Analyze network logs\nREQUEST_COUNT=$(grep -c \"Network.requestWillBeSent\" /tmp/network_events.txt || true)\necho \"Network requests: $REQUEST_COUNT\"\n\n# 13. Take screenshots\necho '{\"id\":30,\"method\":\"Page.captureScreenshot\"}' | websocat --one-message \"$MAIN_WS\" | jq -r '.result.data' | base64 -d > /tmp/main_window.png\necho '{\"id\":31,\"method\":\"Page.captureScreenshot\"}' | websocat --one-message \"$SETTINGS_WS\" | jq -r '.result.data' | base64 -d > /tmp/settings_window.png\n\necho \"✓ Screenshots saved\"\n\necho \"✓ ALL ADVANCED TESTS PASSED\"\n```\n\n## Best Practices\n\n1. **Always verify both main and renderer processes** - Don't skip main process testing\n2. **Stream events for long-running tests** - Use event listeners instead of polling\n3. **Clean up resources** - Close windows, clear storage, kill background processes\n4. **Use unique IDs for CDP commands** - Makes debugging responses easier\n5. **Wait for async operations** - Use `awaitPromise: true` for promises\n6. **Handle WebSocket reconnections** - Connections can drop, implement retry logic\n7. **Monitor performance** - Collect metrics to catch regressions\n8. **Test offline scenarios** - Use network emulation to test error handling\n",
        "skills/dev-test-electron/references/cdp-api.md": "# Chrome DevTools Protocol API Reference\n\nComplete reference for CDP domains used in Electron automation.\n\n## Runtime Domain\n\nExecute JavaScript and manage runtime environment.\n\n### Runtime.enable\n\nEnable Runtime domain to receive events.\n\n```json\n{\"id\":1,\"method\":\"Runtime.enable\"}\n```\n\n**Response:**\n```json\n{\"id\":1,\"result\":{}}\n```\n\n### Runtime.evaluate\n\nExecute JavaScript expression in the renderer process.\n\n```json\n{\n  \"id\":2,\n  \"method\":\"Runtime.evaluate\",\n  \"params\":{\n    \"expression\":\"document.title\",\n    \"returnByValue\":true\n  }\n}\n```\n\n**Parameters:**\n- `expression` (string): JavaScript expression to evaluate\n- `returnByValue` (boolean, optional): Return result by value instead of object reference\n- `awaitPromise` (boolean, optional): Wait for async expressions to resolve\n- `userGesture` (boolean, optional): Execute as if initiated by user\n\n**Response (success):**\n```json\n{\n  \"id\":2,\n  \"result\":{\n    \"result\":{\n      \"type\":\"string\",\n      \"value\":\"My Electron App\"\n    }\n  }\n}\n```\n\n**Response (error):**\n```json\n{\n  \"id\":2,\n  \"result\":{\n    \"exceptionDetails\":{\n      \"text\":\"ReferenceError: foo is not defined\",\n      \"lineNumber\":1,\n      \"columnNumber\":1\n    }\n  }\n}\n```\n\n### Runtime.consoleAPICalled (Event)\n\nFired when console API is called (console.log, console.error, etc.).\n\n**Event payload:**\n```json\n{\n  \"method\":\"Runtime.consoleAPICalled\",\n  \"params\":{\n    \"type\":\"log\",\n    \"args\":[\n      {\"type\":\"string\",\"value\":\"Hello from renderer\"}\n    ],\n    \"executionContextId\":1,\n    \"timestamp\":1234567890\n  }\n}\n```\n\n**Event types:**\n- `log`, `debug`, `info`, `warning`, `error`\n- `dir`, `dirxml`, `table`, `trace`\n- `clear`, `count`, `assert`\n\n## Page Domain\n\nControl page navigation, lifecycle, and screenshots.\n\n### Page.enable\n\nEnable Page domain to receive navigation and lifecycle events.\n\n```json\n{\"id\":10,\"method\":\"Page.enable\"}\n```\n\n### Page.navigate\n\nNavigate to a URL (file:// or http://https://).\n\n```json\n{\n  \"id\":11,\n  \"method\":\"Page.navigate\",\n  \"params\":{\n    \"url\":\"file:///app/index.html\"\n  }\n}\n```\n\n**Response:**\n```json\n{\n  \"id\":11,\n  \"result\":{\n    \"frameId\":\"frame-id\",\n    \"loaderId\":\"loader-id\"\n  }\n}\n```\n\n### Page.loadEventFired (Event)\n\nFired when page load event is fired.\n\n```json\n{\n  \"method\":\"Page.loadEventFired\",\n  \"params\":{\n    \"timestamp\":1234567890\n  }\n}\n```\n\n### Page.captureScreenshot\n\nCapture screenshot of the current viewport.\n\n```json\n{\n  \"id\":12,\n  \"method\":\"Page.captureScreenshot\",\n  \"params\":{\n    \"format\":\"png\",\n    \"quality\":80\n  }\n}\n```\n\n**Parameters:**\n- `format` (string, optional): \"png\" or \"jpeg\" (default: \"png\")\n- `quality` (integer, optional): JPEG quality 0-100 (default: 80)\n- `clip` (object, optional): Clip region `{x, y, width, height, scale}`\n- `fromSurface` (boolean, optional): Capture from surface (may be slower but more accurate)\n\n**Response:**\n```json\n{\n  \"id\":12,\n  \"result\":{\n    \"data\":\"iVBORw0KGgoAAAANS...\"\n  }\n}\n```\n\n**Extract and save:**\n```bash\necho \"$RESPONSE\" | jq -r '.result.data' | base64 -d > screenshot.png\n```\n\n### Page.reload\n\nReload the current page.\n\n```json\n{\n  \"id\":13,\n  \"method\":\"Page.reload\",\n  \"params\":{\n    \"ignoreCache\":true\n  }\n}\n```\n\n## DOM Domain\n\nQuery and manipulate the DOM tree.\n\n### DOM.enable\n\nEnable DOM domain.\n\n```json\n{\"id\":20,\"method\":\"DOM.enable\"}\n```\n\n### DOM.getDocument\n\nGet the root DOM node.\n\n```json\n{\"id\":21,\"method\":\"DOM.getDocument\"}\n```\n\n**Response:**\n```json\n{\n  \"id\":21,\n  \"result\":{\n    \"root\":{\n      \"nodeId\":1,\n      \"nodeType\":9,\n      \"nodeName\":\"#document\",\n      \"childNodeCount\":2\n    }\n  }\n}\n```\n\n### DOM.querySelector\n\nFind a single element by CSS selector.\n\n```json\n{\n  \"id\":22,\n  \"method\":\"DOM.querySelector\",\n  \"params\":{\n    \"nodeId\":1,\n    \"selector\":\"#submit-btn\"\n  }\n}\n```\n\n**Response (found):**\n```json\n{\n  \"id\":22,\n  \"result\":{\n    \"nodeId\":42\n  }\n}\n```\n\n**Response (not found):**\n```json\n{\n  \"id\":22,\n  \"result\":{\n    \"nodeId\":0\n  }\n}\n```\n\n### DOM.querySelectorAll\n\nFind all elements matching CSS selector.\n\n```json\n{\n  \"id\":23,\n  \"method\":\"DOM.querySelectorAll\",\n  \"params\":{\n    \"nodeId\":1,\n    \"selector\":\".error-message\"\n  }\n}\n```\n\n**Response:**\n```json\n{\n  \"id\":23,\n  \"result\":{\n    \"nodeIds\":[15, 27, 31]\n  }\n}\n```\n\n### DOM.getOuterHTML\n\nGet the outer HTML of a node.\n\n```json\n{\n  \"id\":24,\n  \"method\":\"DOM.getOuterHTML\",\n  \"params\":{\n    \"nodeId\":42\n  }\n}\n```\n\n**Response:**\n```json\n{\n  \"id\":24,\n  \"result\":{\n    \"outerHTML\":\"<button id=\\\"submit-btn\\\">Submit</button>\"\n  }\n}\n```\n\n## Network Domain\n\nMonitor network activity and intercept requests.\n\n### Network.enable\n\nEnable Network domain to receive request/response events.\n\n```json\n{\"id\":30,\"method\":\"Network.enable\"}\n```\n\n### Network.requestWillBeSent (Event)\n\nFired when request is about to be sent.\n\n```json\n{\n  \"method\":\"Network.requestWillBeSent\",\n  \"params\":{\n    \"requestId\":\"req-123\",\n    \"loaderId\":\"loader-id\",\n    \"documentURL\":\"file:///app/index.html\",\n    \"request\":{\n      \"url\":\"https://api.example.com/data\",\n      \"method\":\"GET\",\n      \"headers\":{\n        \"User-Agent\":\"...\"\n      }\n    },\n    \"timestamp\":1234567890,\n    \"type\":\"XHR\"\n  }\n}\n```\n\n### Network.responseReceived (Event)\n\nFired when response is received.\n\n```json\n{\n  \"method\":\"Network.responseReceived\",\n  \"params\":{\n    \"requestId\":\"req-123\",\n    \"loaderId\":\"loader-id\",\n    \"timestamp\":1234567891,\n    \"type\":\"XHR\",\n    \"response\":{\n      \"url\":\"https://api.example.com/data\",\n      \"status\":200,\n      \"statusText\":\"OK\",\n      \"headers\":{\n        \"Content-Type\":\"application/json\"\n      }\n    }\n  }\n}\n```\n\n### Network.getResponseBody\n\nGet response body content.\n\n```json\n{\n  \"id\":31,\n  \"method\":\"Network.getResponseBody\",\n  \"params\":{\n    \"requestId\":\"req-123\"\n  }\n}\n```\n\n**Response:**\n```json\n{\n  \"id\":31,\n  \"result\":{\n    \"body\":\"{\\\"data\\\":\\\"...\\\"}\",\n    \"base64Encoded\":false\n  }\n}\n```\n\n## Input Domain\n\nSimulate keyboard and mouse input.\n\n### Input.dispatchKeyEvent\n\nSimulate keyboard events.\n\n```json\n{\n  \"id\":40,\n  \"method\":\"Input.dispatchKeyEvent\",\n  \"params\":{\n    \"type\":\"keyDown\",\n    \"key\":\"Enter\",\n    \"code\":\"Enter\",\n    \"text\":\"\\r\",\n    \"unmodifiedText\":\"\\r\",\n    \"windowsVirtualKeyCode\":13\n  }\n}\n```\n\n**Event types:**\n- `keyDown`: Key press\n- `keyUp`: Key release\n- `char`: Character input\n\n**Common keys:**\n```json\n// Enter\n{\"type\":\"keyDown\",\"key\":\"Enter\",\"code\":\"Enter\",\"windowsVirtualKeyCode\":13}\n\n// Backspace\n{\"type\":\"keyDown\",\"key\":\"Backspace\",\"code\":\"Backspace\",\"windowsVirtualKeyCode\":8}\n\n// Tab\n{\"type\":\"keyDown\",\"key\":\"Tab\",\"code\":\"Tab\",\"windowsVirtualKeyCode\":9}\n\n// Arrow keys\n{\"type\":\"keyDown\",\"key\":\"ArrowUp\",\"code\":\"ArrowUp\",\"windowsVirtualKeyCode\":38}\n{\"type\":\"keyDown\",\"key\":\"ArrowDown\",\"code\":\"ArrowDown\",\"windowsVirtualKeyCode\":40}\n\n// Modifiers\n{\"type\":\"keyDown\",\"key\":\"Control\",\"code\":\"ControlLeft\",\"windowsVirtualKeyCode\":17,\"modifiers\":2}\n{\"type\":\"keyDown\",\"key\":\"Shift\",\"code\":\"ShiftLeft\",\"windowsVirtualKeyCode\":16,\"modifiers\":8}\n```\n\n**Modifier bitmask:**\n- Alt: 1\n- Ctrl: 2\n- Meta/Cmd: 4\n- Shift: 8\n\n### Input.dispatchMouseEvent\n\nSimulate mouse events.\n\n```json\n{\n  \"id\":41,\n  \"method\":\"Input.dispatchMouseEvent\",\n  \"params\":{\n    \"type\":\"mousePressed\",\n    \"x\":100,\n    \"y\":200,\n    \"button\":\"left\",\n    \"clickCount\":1\n  }\n}\n```\n\n**Event types:**\n- `mousePressed`: Mouse button down\n- `mouseReleased`: Mouse button up\n- `mouseMoved`: Mouse movement\n\n**Buttons:**\n- `left`, `middle`, `right`, `back`, `forward`\n\n**Click sequence:**\n```json\n// Click at (100, 200)\n{\"id\":41,\"method\":\"Input.dispatchMouseEvent\",\"params\":{\"type\":\"mousePressed\",\"x\":100,\"y\":200,\"button\":\"left\",\"clickCount\":1}}\n{\"id\":42,\"method\":\"Input.dispatchMouseEvent\",\"params\":{\"type\":\"mouseReleased\",\"x\":100,\"y\":200,\"button\":\"left\",\"clickCount\":1}}\n\n// Double-click\n{\"id\":43,\"method\":\"Input.dispatchMouseEvent\",\"params\":{\"type\":\"mousePressed\",\"x\":100,\"y\":200,\"button\":\"left\",\"clickCount\":2}}\n{\"id\":44,\"method\":\"Input.dispatchMouseEvent\",\"params\":{\"type\":\"mouseReleased\",\"x\":100,\"y\":200,\"button\":\"left\",\"clickCount\":2}}\n```\n\n## Debugger Domain\n\nSet breakpoints and control execution.\n\n### Debugger.enable\n\nEnable Debugger domain.\n\n```json\n{\"id\":50,\"method\":\"Debugger.enable\"}\n```\n\n### Debugger.setBreakpointByUrl\n\nSet breakpoint by URL and line number.\n\n```json\n{\n  \"id\":51,\n  \"method\":\"Debugger.setBreakpointByUrl\",\n  \"params\":{\n    \"lineNumber\":10,\n    \"url\":\"file:///app/renderer.js\"\n  }\n}\n```\n\n**Response:**\n```json\n{\n  \"id\":51,\n  \"result\":{\n    \"breakpointId\":\"bp-1\",\n    \"locations\":[\n      {\"scriptId\":\"script-1\",\"lineNumber\":10,\"columnNumber\":0}\n    ]\n  }\n}\n```\n\n### Debugger.paused (Event)\n\nFired when execution pauses at breakpoint.\n\n```json\n{\n  \"method\":\"Debugger.paused\",\n  \"params\":{\n    \"callFrames\":[\n      {\n        \"callFrameId\":\"frame-1\",\n        \"functionName\":\"myFunction\",\n        \"location\":{\"scriptId\":\"script-1\",\"lineNumber\":10,\"columnNumber\":0},\n        \"scopeChain\":[...]\n      }\n    ],\n    \"reason\":\"breakpoint\"\n  }\n}\n```\n\n### Debugger.resume\n\nResume execution after pause.\n\n```json\n{\"id\":52,\"method\":\"Debugger.resume\"}\n```\n\n## Complete CDP Command Examples\n\n### Read Console Logs (Streaming)\n\n```bash\n#!/bin/bash\nWS_URL=\"ws://localhost:9222/devtools/page/...\"\n\n# Enable Runtime and start listening\n{\n  echo '{\"id\":1,\"method\":\"Runtime.enable\"}'\n  # Keep connection open to receive events\n  sleep 10\n} | websocat \"$WS_URL\" | while read -r line; do\n  # Filter for console.log events\n  if echo \"$line\" | jq -e '.method == \"Runtime.consoleAPICalled\"' > /dev/null 2>&1; then\n    echo \"CONSOLE: $(echo \"$line\" | jq -r '.params.args[0].value')\"\n  fi\ndone\n```\n\n### Execute JavaScript and Get Return Value\n\n```bash\nSCRIPT='(() => {\n  const btn = document.querySelector(\"#submit-btn\");\n  return btn ? btn.textContent : null;\n})()'\n\nRESPONSE=$(echo \"{\\\"id\\\":1,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":$(echo \"$SCRIPT\" | jq -Rs .),\\\"returnByValue\\\":true}}\" | websocat --one-message \"$WS_URL\")\n\n# Check for error\nif echo \"$RESPONSE\" | jq -e '.result.exceptionDetails' > /dev/null; then\n  echo \"ERROR: $(echo \"$RESPONSE\" | jq -r '.result.exceptionDetails.text')\"\n  exit 1\nfi\n\n# Get result\nRESULT=$(echo \"$RESPONSE\" | jq -r '.result.result.value')\necho \"Button text: $RESULT\"\n```\n\n### Monitor Network Requests\n\n```bash\n#!/bin/bash\nWS_URL=\"ws://localhost:9222/devtools/page/...\"\n\n# Enable Network domain and listen for events\n{\n  echo '{\"id\":1,\"method\":\"Network.enable\"}'\n  sleep 30  # Listen for 30 seconds\n} | websocat \"$WS_URL\" | while read -r line; do\n  if echo \"$line\" | jq -e '.method == \"Network.requestWillBeSent\"' > /dev/null 2>&1; then\n    URL=$(echo \"$line\" | jq -r '.params.request.url')\n    METHOD=$(echo \"$line\" | jq -r '.params.request.method')\n    echo \"REQUEST: $METHOD $URL\"\n  fi\n\n  if echo \"$line\" | jq -e '.method == \"Network.responseReceived\"' > /dev/null 2>&1; then\n    URL=$(echo \"$line\" | jq -r '.params.response.url')\n    STATUS=$(echo \"$line\" | jq -r '.params.response.status')\n    echo \"RESPONSE: $STATUS $URL\"\n  fi\ndone\n```\n\n## Error Handling Patterns\n\n### Verify CDP Response\n\n```bash\nverify_cdp_response() {\n  local response=\"$1\"\n  local expected_id=\"$2\"\n\n  # Check response exists\n  if [ -z \"$response\" ]; then\n    echo \"ERROR: Empty response\"\n    return 1\n  fi\n\n  # Check for CDP error\n  if echo \"$response\" | jq -e '.error' > /dev/null 2>&1; then\n    echo \"CDP ERROR: $(echo \"$response\" | jq -r '.error.message')\"\n    return 1\n  fi\n\n  # Check ID matches\n  local actual_id=$(echo \"$response\" | jq -r '.id // empty')\n  if [ \"$actual_id\" != \"$expected_id\" ]; then\n    echo \"ERROR: ID mismatch (expected $expected_id, got $actual_id)\"\n    return 1\n  fi\n\n  # Check for result\n  if ! echo \"$response\" | jq -e '.result' > /dev/null 2>&1; then\n    echo \"ERROR: No result in response\"\n    return 1\n  fi\n\n  return 0\n}\n\n# Usage\nRESPONSE=$(echo '{\"id\":100,\"method\":\"Runtime.evaluate\",\"params\":{\"expression\":\"2+2\"}}' | websocat --one-message \"$WS_URL\")\nif verify_cdp_response \"$RESPONSE\" \"100\"; then\n  echo \"✓ Command succeeded\"\nelse\n  exit 1\nfi\n```\n\n### Retry with Exponential Backoff\n\n```bash\nretry_cdp_command() {\n  local command=\"$1\"\n  local max_attempts=5\n  local wait_time=1\n\n  for attempt in $(seq 1 $max_attempts); do\n    RESPONSE=$(echo \"$command\" | websocat --one-message \"$WS_URL\")\n\n    if verify_cdp_response \"$RESPONSE\" \"$(echo \"$command\" | jq -r '.id')\"; then\n      echo \"$RESPONSE\"\n      return 0\n    fi\n\n    if [ $attempt -eq $max_attempts ]; then\n      echo \"ERROR: Command failed after $max_attempts attempts\" >&2\n      return 1\n    fi\n\n    echo \"Retry $attempt failed, waiting ${wait_time}s...\" >&2\n    sleep $wait_time\n    wait_time=$((wait_time * 2))\n  done\n}\n```\n\n## Additional Resources\n\n- **Official CDP docs**: https://chromedevtools.github.io/devtools-protocol/\n- **Electron debugging**: https://www.electronjs.org/docs/latest/tutorial/debugging-main-process\n- **CDP Viewer**: https://chromedevtools.github.io/devtools-protocol/viewer/\n",
        "skills/dev-test-electron/references/electron-specific.md": "# Electron-Specific CDP Features\n\nAdvanced patterns for testing Electron main process, IPC, and native APIs.\n\n## Electron Architecture\n\n<EXTREMELY-IMPORTANT>\n**Electron has TWO separate processes that MUST both be tested:**\n\n| Process | Runtime | Responsibilities | Testing Method |\n|---------|---------|------------------|----------------|\n| **Main** | Node.js | App lifecycle, native APIs, file I/O, menus, dialogs, system integration | Main process CDP OR IPC from renderer |\n| **Renderer** | Chromium | Web content, DOM, UI, frontend logic | Standard CDP (Page, DOM, Runtime) |\n\n**CRITICAL:** Renderer-only testing misses:\n- Main process crashes\n- IPC communication failures\n- Native dialog bugs\n- File system operation errors\n- Menu item regressions\n\n**Both processes must be verified in E2E tests.**\n</EXTREMELY-IMPORTANT>\n\n## Main Process Debugging\n\n### Enable Main Process Debugging\n\nSome Electron apps expose main process for debugging:\n\n```bash\n# Option 1: Electron flag (if supported by app)\n/path/to/app --inspect=5858\n\n# Option 2: Node.js environment variable\nNODE_OPTIONS=\"--inspect=5858\" /path/to/app\n\n# Option 3: Combined (recommended)\nNODE_OPTIONS=\"--inspect=5858\" /path/to/app --remote-debugging-port=9222\n```\n\n**Check if main process is debuggable:**\n```bash\n# List all CDP targets\ncurl -s http://localhost:9222/json/list | jq '.'\n\n# Filter for main process (type == \"node\")\ncurl -s http://localhost:9222/json/list | jq '.[] | select(.type == \"node\")'\n```\n\n**Example response:**\n```json\n{\n  \"description\": \"node.js instance\",\n  \"devtoolsFrontendUrl\": \"devtools://devtools/bundled/inspector.html?...&ws=localhost:5858/...\",\n  \"id\": \"main-process-id\",\n  \"title\": \"Electron Main Process\",\n  \"type\": \"node\",\n  \"url\": \"file:///app/main.js\",\n  \"webSocketDebuggerUrl\": \"ws://localhost:5858/...\"\n}\n```\n\n### Connect to Main Process\n\n```bash\n# Get main process WebSocket URL\nMAIN_WS=$(curl -s http://localhost:9222/json/list | jq -r '.[] | select(.type == \"node\") | .webSocketDebuggerUrl')\n\nif [ -z \"$MAIN_WS\" ]; then\n  echo \"ERROR: Main process not debuggable\"\n  echo \"Restart app with: NODE_OPTIONS=\\\"--inspect=5858\\\" /path/to/app\"\n  exit 1\nfi\n\necho \"Main process WebSocket: $MAIN_WS\"\n\n# Execute Node.js code in main process\necho '{\"id\":1,\"method\":\"Runtime.evaluate\",\"params\":{\"expression\":\"process.version\"}}' | websocat --one-message \"$MAIN_WS\"\n```\n\n### Execute Node.js in Main Process\n\n```bash\n# Check Node.js version\nSCRIPT='process.version'\necho \"{\\\"id\\\":1,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$SCRIPT\\\",\\\"returnByValue\\\":true}}\" | websocat --one-message \"$MAIN_WS\"\n\n# List loaded modules\nSCRIPT='Object.keys(require.cache).join(\", \")'\necho \"{\\\"id\\\":2,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$SCRIPT\\\",\\\"returnByValue\\\":true}}\" | websocat --one-message \"$MAIN_WS\"\n\n# Read file from main process\nSCRIPT='require(\"fs\").readFileSync(\"/app/config.json\", \"utf8\")'\necho \"{\\\"id\\\":3,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$SCRIPT\\\",\\\"returnByValue\\\":true}}\" | websocat --one-message \"$MAIN_WS\"\n\n# Get app metadata\nSCRIPT='require(\"electron\").app.getVersion()'\necho \"{\\\"id\\\":4,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$SCRIPT\\\",\\\"returnByValue\\\":true}}\" | websocat --one-message \"$MAIN_WS\"\n```\n\n## IPC (Inter-Process Communication)\n\n### Testing IPC from Renderer to Main\n\n**Pattern: Renderer sends IPC → Main handles → Renderer receives response**\n\n```bash\n#!/bin/bash\n# Connect to renderer process\nWS_URL=$(curl -s http://localhost:9222/json/list | jq -r '.[0].webSocketDebuggerUrl')\n\n# Enable Runtime domain\necho '{\"id\":1,\"method\":\"Runtime.enable\"}' | websocat --one-message \"$WS_URL\"\n\n# Send IPC from renderer to main\nIPC_SEND='require(\"electron\").ipcRenderer.send(\"test-channel\", {data: \"test\"})'\nRESPONSE=$(echo \"{\\\"id\\\":2,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$IPC_SEND\\\"}}\" | websocat --one-message \"$WS_URL\")\n\n# Verify IPC was sent (no exception)\nif echo \"$RESPONSE\" | jq -e '.result.exceptionDetails' > /dev/null; then\n  echo \"✗ FAILED: Could not send IPC message\"\n  echo \"$RESPONSE\" | jq '.result.exceptionDetails'\n  exit 1\nfi\n\necho \"✓ IPC message sent to main process\"\n\n# Wait for main process to respond (if using ipcRenderer.on)\nsleep 1\n\n# Check if response received (example: sets window.ipcResponse)\nCHECK_RESPONSE='window.ipcResponse'\nVERIFY=$(echo \"{\\\"id\\\":3,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$CHECK_RESPONSE\\\",\\\"returnByValue\\\":true}}\" | websocat --one-message \"$WS_URL\")\n\nRESULT=$(echo \"$VERIFY\" | jq -r '.result.result.value')\necho \"✓ IPC response: $RESULT\"\n```\n\n### Testing IPC invoke/handle Pattern\n\nModern Electron uses `ipcRenderer.invoke` / `ipcMain.handle`:\n\n```bash\n# Invoke IPC from renderer (returns promise)\nIPC_INVOKE='await require(\"electron\").ipcRenderer.invoke(\"get-user-data\")'\n\n# Must use awaitPromise to wait for async result\nRESPONSE=$(echo \"{\\\"id\\\":10,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$IPC_INVOKE\\\",\\\"awaitPromise\\\":true,\\\"returnByValue\\\":true}}\" | websocat --one-message \"$WS_URL\")\n\n# Verify response\nif echo \"$RESPONSE\" | jq -e '.result.exceptionDetails' > /dev/null; then\n  echo \"✗ FAILED: IPC invoke error\"\n  echo \"$RESPONSE\" | jq '.result.exceptionDetails.text'\n  exit 1\nfi\n\nUSER_DATA=$(echo \"$RESPONSE\" | jq -r '.result.result.value')\necho \"✓ IPC invoke succeeded: $USER_DATA\"\n```\n\n### IPC Event Listeners\n\nSet up IPC listener and verify events are received:\n\n```bash\n# Set up IPC listener in renderer\nSETUP_LISTENER='\nwindow.ipcMessages = [];\nrequire(\"electron\").ipcRenderer.on(\"notification\", (event, data) => {\n  window.ipcMessages.push(data);\n});\n'\n\necho \"{\\\"id\\\":20,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":$(echo \"$SETUP_LISTENER\" | jq -Rs .)}}\" | websocat --one-message \"$WS_URL\"\n\n# Trigger action that should cause main to send IPC\n# (e.g., click button, wait for background process)\nsleep 2\n\n# Check if IPC messages were received\nCHECK_MESSAGES='window.ipcMessages.length'\nRESPONSE=$(echo \"{\\\"id\\\":21,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$CHECK_MESSAGES\\\",\\\"returnByValue\\\":true}}\" | websocat --one-message \"$WS_URL\")\n\nCOUNT=$(echo \"$RESPONSE\" | jq -r '.result.result.value')\nif [ \"$COUNT\" -eq 0 ]; then\n  echo \"✗ FAILED: No IPC messages received\"\n  exit 1\nfi\n\necho \"✓ Received $COUNT IPC messages\"\n\n# Get message content\nGET_MESSAGES='JSON.stringify(window.ipcMessages)'\nMESSAGES=$(echo \"{\\\"id\\\":22,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$GET_MESSAGES\\\",\\\"returnByValue\\\":true}}\" | websocat --one-message \"$WS_URL\" | jq -r '.result.result.value')\necho \"Messages: $MESSAGES\"\n```\n\n## Native Dialogs\n\n### File Open Dialog\n\n```bash\n# Trigger file dialog from renderer\nOPEN_DIALOG='require(\"electron\").ipcRenderer.invoke(\"open-file-dialog\")'\n\n# Note: This will show a real native dialog\n# For automated testing, mock the dialog in main process\nRESPONSE=$(echo \"{\\\"id\\\":30,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$OPEN_DIALOG\\\",\\\"awaitPromise\\\":true,\\\"returnByValue\\\":true}}\" | websocat --one-message \"$WS_URL\")\n\n# Main process should return selected file path\nFILE_PATH=$(echo \"$RESPONSE\" | jq -r '.result.result.value')\necho \"✓ Selected file: $FILE_PATH\"\n```\n\n**Main process handler (for reference):**\n```javascript\n// main.js\nconst { ipcMain, dialog } = require('electron');\n\nipcMain.handle('open-file-dialog', async () => {\n  const result = await dialog.showOpenDialog({\n    properties: ['openFile']\n  });\n  return result.filePaths[0];\n});\n```\n\n**For automated testing, mock dialogs:**\n```javascript\n// Test mode: skip dialog, return fixed path\nipcMain.handle('open-file-dialog', async () => {\n  if (process.env.TEST_MODE) {\n    return '/tmp/test-file.txt';\n  }\n  // Real dialog for manual testing\n  const result = await dialog.showOpenDialog({...});\n  return result.filePaths[0];\n});\n```\n\n### Message Box Dialog\n\n```bash\n# Show message box from main process\nMESSAGE_BOX='require(\"electron\").ipcRenderer.invoke(\"show-message\", \"Test completed successfully\")'\n\nRESPONSE=$(echo \"{\\\"id\\\":31,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$MESSAGE_BOX\\\",\\\"awaitPromise\\\":true,\\\"returnByValue\\\":true}}\" | websocat --one-message \"$WS_URL\")\n\n# Response contains button clicked\nBUTTON=$(echo \"$RESPONSE\" | jq -r '.result.result.value')\necho \"✓ User clicked button: $BUTTON\"\n```\n\n## Native Menus\n\n### Trigger Menu Item\n\n```bash\n# Click menu item via IPC\nCLICK_MENU='require(\"electron\").ipcRenderer.send(\"menu-item-clicked\", \"File:Save\")'\n\necho \"{\\\"id\\\":40,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$CLICK_MENU\\\"}}\" | websocat --one-message \"$WS_URL\"\n\n# Wait for menu action to complete\nsleep 1\n\n# Verify result (e.g., file was saved)\nCHECK_SAVED='window.fileSaved === true'\nVERIFY=$(echo \"{\\\"id\\\":41,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$CHECK_SAVED\\\",\\\"returnByValue\\\":true}}\" | websocat --one-message \"$WS_URL\")\n\nIS_SAVED=$(echo \"$VERIFY\" | jq -r '.result.result.value')\nif [ \"$IS_SAVED\" != \"true\" ]; then\n  echo \"✗ FAILED: File not saved after menu click\"\n  exit 1\nfi\n\necho \"✓ Menu action verified: File saved\"\n```\n\n**Main process menu setup (for reference):**\n```javascript\n// main.js\nconst { Menu } = require('electron');\n\nconst template = [\n  {\n    label: 'File',\n    submenu: [\n      {\n        label: 'Save',\n        accelerator: 'CmdOrCtrl+S',\n        click: () => {\n          // Send IPC to renderer to trigger save\n          mainWindow.webContents.send('menu-save');\n        }\n      }\n    ]\n  }\n];\n\nconst menu = Menu.buildFromTemplate(template);\nMenu.setApplicationMenu(menu);\n```\n\n### Keyboard Accelerators\n\n```bash\n# Trigger menu via keyboard shortcut\n# Use Input.dispatchKeyEvent to simulate Cmd+S or Ctrl+S\n\n# macOS: Cmd+S\necho '{\"id\":42,\"method\":\"Input.dispatchKeyEvent\",\"params\":{\"type\":\"keyDown\",\"key\":\"s\",\"code\":\"KeyS\",\"modifiers\":4}}' | websocat --one-message \"$WS_URL\"\necho '{\"id\":43,\"method\":\"Input.dispatchKeyEvent\",\"params\":{\"type\":\"keyUp\",\"key\":\"s\",\"code\":\"KeyS\",\"modifiers\":4}}' | websocat --one-message \"$WS_URL\"\n\n# Wait for action\nsleep 1\n\n# Verify save action occurred\n# (same verification as above)\n```\n\n## BrowserWindow Control\n\n### Get All Windows\n\n```bash\n# From main process: get all BrowserWindow instances\nGET_WINDOWS='\nconst { BrowserWindow } = require(\"electron\");\nconst windows = BrowserWindow.getAllWindows();\nwindows.map(w => ({ id: w.id, title: w.getTitle(), url: w.webContents.getURL() }))\n'\n\nRESPONSE=$(echo \"{\\\"id\\\":50,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":$(echo \"$GET_WINDOWS\" | jq -Rs .),\\\"returnByValue\\\":true}}\" | websocat --one-message \"$MAIN_WS\")\n\nWINDOWS=$(echo \"$RESPONSE\" | jq -r '.result.result.value')\necho \"Windows: $WINDOWS\"\n```\n\n### Create New Window from Main\n\n```bash\n# Create new BrowserWindow from main process\nCREATE_WINDOW='\nconst { BrowserWindow } = require(\"electron\");\nconst win = new BrowserWindow({ width: 800, height: 600 });\nwin.loadFile(\"/app/settings.html\");\nwin.id\n'\n\nRESPONSE=$(echo \"{\\\"id\\\":51,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":$(echo \"$CREATE_WINDOW\" | jq -Rs .),\\\"returnByValue\\\":true}}\" | websocat --one-message \"$MAIN_WS\")\n\nWINDOW_ID=$(echo \"$RESPONSE\" | jq -r '.result.result.value')\necho \"✓ Created window ID: $WINDOW_ID\"\n\n# Now find the new window's CDP target\nsleep 1\nNEW_WINDOW_WS=$(curl -s http://localhost:9222/json/list | jq -r \".[] | select(.url | contains(\\\"settings.html\\\")) | .webSocketDebuggerUrl\")\n\necho \"New window WebSocket: $NEW_WINDOW_WS\"\n\n# Automate the new window\necho '{\"id\":1,\"method\":\"Runtime.enable\"}' | websocat --one-message \"$NEW_WINDOW_WS\"\necho '{\"id\":2,\"method\":\"Runtime.evaluate\",\"params\":{\"expression\":\"document.title\"}}' | websocat --one-message \"$NEW_WINDOW_WS\"\n```\n\n### Close Window\n\n```bash\n# Close window from main process\nCLOSE_WINDOW=\"\nconst { BrowserWindow } = require('electron');\nconst win = BrowserWindow.fromId($WINDOW_ID);\nif (win) win.close();\n\"\n\necho \"{\\\"id\\\":52,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":$(echo \"$CLOSE_WINDOW\" | jq -Rs .)}}\" | websocat --one-message \"$MAIN_WS\"\n```\n\n## WebContents Methods\n\n### Execute JavaScript in WebContents\n\nFrom main process, execute JavaScript in any renderer:\n\n```bash\n# Execute in specific window's renderer\nEXECUTE_IN_RENDERER='\nconst { BrowserWindow } = require(\"electron\");\nconst win = BrowserWindow.fromId(1);\nwin.webContents.executeJavaScript(\"document.title\");\n'\n\n# Note: Returns a Promise\nRESPONSE=$(echo \"{\\\"id\\\":60,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":$(echo \"$EXECUTE_IN_RENDERER\" | jq -Rs .),\\\"awaitPromise\\\":true,\\\"returnByValue\\\":true}}\" | websocat --one-message \"$MAIN_WS\")\n\nTITLE=$(echo \"$RESPONSE\" | jq -r '.result.result.value')\necho \"✓ Renderer title: $TITLE\"\n```\n\n### Open DevTools Programmatically\n\n```bash\n# Open DevTools for debugging\nOPEN_DEVTOOLS='\nconst { BrowserWindow } = require(\"electron\");\nconst win = BrowserWindow.getFocusedWindow();\nwin.webContents.openDevTools();\n'\n\necho \"{\\\"id\\\":61,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":$(echo \"$OPEN_DEVTOOLS\" | jq -Rs .)}}\" | websocat --one-message \"$MAIN_WS\"\n\necho \"✓ DevTools opened\"\n```\n\n### Get WebContents Console Logs\n\nFrom main process, monitor renderer console:\n\n```bash\n# Set up console log listener in main process\nSETUP_CONSOLE_LISTENER='\nconst { BrowserWindow } = require(\"electron\");\nconst win = BrowserWindow.fromId(1);\nglobal.consoleLogs = [];\nwin.webContents.on(\"console-message\", (event, level, message) => {\n  global.consoleLogs.push({ level, message });\n});\n'\n\necho \"{\\\"id\\\":62,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":$(echo \"$SETUP_CONSOLE_LISTENER\" | jq -Rs .)}}\" | websocat --one-message \"$MAIN_WS\"\n\n# Wait for logs to accumulate\nsleep 2\n\n# Retrieve logs\nGET_LOGS='JSON.stringify(global.consoleLogs || [])'\nRESPONSE=$(echo \"{\\\"id\\\":63,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$GET_LOGS\\\",\\\"returnByValue\\\":true}}\" | websocat --one-message \"$MAIN_WS\")\n\nLOGS=$(echo \"$RESPONSE\" | jq -r '.result.result.value')\necho \"Console logs: $LOGS\"\n```\n\n## Session and Cookies\n\n### Get Cookies\n\n```bash\n# Get all cookies from main process\nGET_COOKIES='\nconst { session } = require(\"electron\");\nsession.defaultSession.cookies.get({})\n'\n\nRESPONSE=$(echo \"{\\\"id\\\":70,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":$(echo \"$GET_COOKIES\" | jq -Rs .),\\\"awaitPromise\\\":true,\\\"returnByValue\\\":true}}\" | websocat --one-message \"$MAIN_WS\")\n\nCOOKIES=$(echo \"$RESPONSE\" | jq -r '.result.result.value')\necho \"Cookies: $COOKIES\"\n```\n\n### Set Cookie\n\n```bash\n# Set cookie from main process\nSET_COOKIE='\nconst { session } = require(\"electron\");\nsession.defaultSession.cookies.set({\n  url: \"https://example.com\",\n  name: \"test-cookie\",\n  value: \"test-value\"\n})\n'\n\nRESPONSE=$(echo \"{\\\"id\\\":71,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":$(echo \"$SET_COOKIE\" | jq -Rs .),\\\"awaitPromise\\\":true}}\" | websocat --one-message \"$MAIN_WS\")\n\necho \"✓ Cookie set\"\n```\n\n### Clear Storage\n\n```bash\n# Clear all storage from main process\nCLEAR_STORAGE='\nconst { session } = require(\"electron\");\nsession.defaultSession.clearStorageData()\n'\n\nRESPONSE=$(echo \"{\\\"id\\\":72,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":$(echo \"$CLEAR_STORAGE\" | jq -Rs .),\\\"awaitPromise\\\":true}}\" | websocat --one-message \"$MAIN_WS\")\n\necho \"✓ Storage cleared\"\n```\n\n## App Lifecycle\n\n### Get App Info\n\n```bash\n# Get app metadata from main process\nGET_APP_INFO='\nconst { app } = require(\"electron\");\n({\n  version: app.getVersion(),\n  name: app.getName(),\n  path: app.getAppPath(),\n  userData: app.getPath(\"userData\"),\n  isReady: app.isReady()\n})\n'\n\nRESPONSE=$(echo \"{\\\"id\\\":80,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":$(echo \"$GET_APP_INFO\" | jq -Rs .),\\\"returnByValue\\\":true}}\" | websocat --one-message \"$MAIN_WS\")\n\nAPP_INFO=$(echo \"$RESPONSE\" | jq -r '.result.result.value')\necho \"App info: $APP_INFO\"\n```\n\n### Quit Application\n\n```bash\n# Quit app gracefully from main process\nQUIT_APP='require(\"electron\").app.quit()'\n\necho \"{\\\"id\\\":81,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$QUIT_APP\\\"}}\" | websocat --one-message \"$MAIN_WS\"\n\necho \"✓ App quit command sent\"\n```\n\n## Complete Multi-Process Test Example\n\n```bash\n#!/bin/bash\nset -e\n\n# Launch Electron with both main and renderer debugging\nNODE_OPTIONS=\"--inspect=5858\" /path/to/app --remote-debugging-port=9222 --enable-logging --log-file=/tmp/electron.log 2>&1 &\nAPP_PID=$!\n\n# Wait for startup\nsleep 3\n\n# Get main process WebSocket\nMAIN_WS=$(curl -s http://localhost:9222/json/list | jq -r '.[] | select(.type == \"node\") | .webSocketDebuggerUrl')\nif [ -z \"$MAIN_WS\" ]; then\n  echo \"ERROR: Main process not available\"\n  exit 1\nfi\n\n# Get renderer process WebSocket\nRENDERER_WS=$(curl -s http://localhost:9222/json/list | jq -r '.[] | select(.type == \"page\") | .webSocketDebuggerUrl')\nif [ -z \"$RENDERER_WS\" ]; then\n  echo \"ERROR: Renderer process not available\"\n  exit 1\nfi\n\necho \"✓ Connected to main and renderer processes\"\n\n# TEST 1: Main process - Read file\nREAD_FILE='require(\"fs\").readFileSync(\"/app/config.json\", \"utf8\")'\nRESPONSE=$(echo \"{\\\"id\\\":1,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$READ_FILE\\\",\\\"returnByValue\\\":true}}\" | websocat --one-message \"$MAIN_WS\")\n\nif echo \"$RESPONSE\" | jq -e '.result.exceptionDetails' > /dev/null; then\n  echo \"✗ TEST 1 FAILED: Could not read config\"\n  exit 1\nfi\n\nCONFIG=$(echo \"$RESPONSE\" | jq -r '.result.result.value')\necho \"✓ TEST 1 PASSED: Read config from main process\"\n\n# TEST 2: Renderer process - Check DOM\necho '{\"id\":1,\"method\":\"Runtime.enable\"}' | websocat --one-message \"$RENDERER_WS\"\n\nCHECK_DOM='document.querySelector(\"#app\") !== null'\nRESPONSE=$(echo \"{\\\"id\\\":2,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$CHECK_DOM\\\",\\\"returnByValue\\\":true}}\" | websocat --one-message \"$RENDERER_WS\")\n\nIS_PRESENT=$(echo \"$RESPONSE\" | jq -r '.result.result.value')\nif [ \"$IS_PRESENT\" != \"true\" ]; then\n  echo \"✗ TEST 2 FAILED: #app element not found\"\n  exit 1\nfi\n\necho \"✓ TEST 2 PASSED: DOM element present\"\n\n# TEST 3: IPC Communication\nSEND_IPC='require(\"electron\").ipcRenderer.invoke(\"test-ipc\", \"hello\")'\nRESPONSE=$(echo \"{\\\"id\\\":3,\\\"method\\\":\\\"Runtime.evaluate\\\",\\\"params\\\":{\\\"expression\\\":\\\"$SEND_IPC\\\",\\\"awaitPromise\\\":true,\\\"returnByValue\\\":true}}\" | websocat --one-message \"$RENDERER_WS\")\n\nif echo \"$RESPONSE\" | jq -e '.result.exceptionDetails' > /dev/null; then\n  echo \"✗ TEST 3 FAILED: IPC invoke failed\"\n  exit 1\nfi\n\nIPC_RESULT=$(echo \"$RESPONSE\" | jq -r '.result.result.value')\necho \"✓ TEST 3 PASSED: IPC communication works (result: $IPC_RESULT)\"\n\n# Cleanup\nkill $APP_PID\n\necho \"✓ ALL TESTS PASSED\"\n```\n\n## Testing Patterns\n\n### Pattern 1: Renderer → Main → Renderer\n\nTest full round-trip IPC:\n\n1. Renderer sends IPC to main\n2. Main processes request\n3. Main sends response back to renderer\n4. Verify response received in renderer\n\n### Pattern 2: Main Process State Verification\n\nAfter renderer actions, verify main process state:\n\n1. User clicks button in renderer\n2. Renderer sends IPC to main\n3. Main updates internal state\n4. Verify main process state via CDP\n\n### Pattern 3: Multi-Window Coordination\n\nTest window communication:\n\n1. Open secondary window from main\n2. Send data between windows via main process\n3. Verify both windows receive updates\n\n## Troubleshooting\n\n### Main Process Not Debuggable\n\n**Symptom:** `curl http://localhost:9222/json/list` shows no `type: \"node\"` target\n\n**Solutions:**\n1. Restart app with `NODE_OPTIONS=\"--inspect=5858\"`\n2. Check if app supports `--inspect` flag\n3. Some apps require build-time flag: `enableRemoteModule: true`\n\n### IPC Not Working\n\n**Symptom:** `ipcRenderer.invoke` throws error\n\n**Check:**\n1. Is `contextIsolation` enabled? (May need preload script)\n2. Is `nodeIntegration` disabled? (May need preload script)\n3. Is main process handler registered? (`ipcMain.handle`)\n\n**Preload script pattern:**\n```javascript\n// preload.js\nconst { contextBridge, ipcRenderer } = require('electron');\n\ncontextBridge.exposeInMainWorld('electronAPI', {\n  invoke: (channel, data) => ipcRenderer.invoke(channel, data)\n});\n```\n\nThen from renderer:\n```javascript\nwindow.electronAPI.invoke('test-channel', data)\n```\n\n### WebSocket Connection Drops\n\n**Symptom:** WebSocket closes unexpectedly\n\n**Solutions:**\n1. Keep connection alive with ping/pong\n2. Use `websocat --ping-interval 30`\n3. Reconnect on disconnect with retry logic\n\n## Additional Resources\n\n- **Electron IPC docs**: https://www.electronjs.org/docs/latest/tutorial/ipc\n- **Electron debugging**: https://www.electronjs.org/docs/latest/tutorial/debugging-main-process\n- **Context isolation**: https://www.electronjs.org/docs/latest/tutorial/context-isolation\n",
        "skills/dev-test-hammerspoon/SKILL.md": "---\nname: dev-test-hammerspoon\ndescription: This skill should be used when the user asks to \"debug macOS app\", \"test native app\", \"automate macOS workflow\", \"test native macOS application\", or needs desktop automation for testing macOS applications with Hammerspoon. Use for application launch/control, window management, keyboard/mouse simulation, and visual verification.\n---\n\n**Announce:** \"I'm using dev-test-hammerspoon for macOS desktop automation.\"\n\n<EXTREMELY-IMPORTANT>\n## Gate Reminder\n\nBefore taking screenshots or running E2E tests, you MUST complete all 6 gates from dev-tdd:\n\n```\nGATE 1: BUILD\nGATE 2: LAUNCH (with file-based logging)\nGATE 3: WAIT\nGATE 4: CHECK PROCESS\nGATE 5: READ LOGS ← MANDATORY, CANNOT SKIP\nGATE 6: VERIFY LOGS\nTHEN: E2E tests/screenshots\n```\n\n**You loaded dev-tdd earlier. Follow the gates now.**\n</EXTREMELY-IMPORTANT>\n\n## Contents\n\n- [Tool Availability Gate](#tool-availability-gate)\n- [When to Use Hammerspoon](#when-to-use-hammerspoon)\n- [Hammerspoon Setup](#hammerspoon-setup)\n- [Input Simulation](#input-simulation)\n- [Application Control](#application-control)\n- [Window Management](#window-management)\n- [Screenshots](#screenshots)\n- [Complete E2E Example](#complete-e2e-example)\n- [Alternative: cliclick](#alternative-cliclick)\n\n# macOS Desktop Automation\n\n<EXTREMELY-IMPORTANT>\n## Tool Availability Gate\n\n**Verify Hammerspoon is installed before proceeding.**\n\n```bash\n# Check Hammerspoon installation (both CLI and app)\nwhich hs || echo \"MISSING: hs CLI\"\nls /Applications/Hammerspoon.app 2>/dev/null || echo \"MISSING: Hammerspoon.app\"\n```\n\n**If missing:**\n```\nSTOP: Cannot proceed with macOS automation.\n\nMissing tool: Hammerspoon (required for macOS E2E testing)\n\nInstall with:\n  brew install --cask hammerspoon\n\nAfter installing:\n  1. Open Hammerspoon.app\n  2. Grant Accessibility permissions in System Preferences\n  3. In Hammerspoon console, run: hs.ipc.cliInstall()\n  4. Add to ~/.hammerspoon/init.lua: require(\"hs.ipc\")\n\nReply when installed and I'll continue testing.\n```\n\n**This gate is non-negotiable. Missing tools = full stop.**\n</EXTREMELY-IMPORTANT>\n\n<EXTREMELY-IMPORTANT>\n## When to Use Hammerspoon\n\n**Use Hammerspoon for:**\n- macOS native application automation\n- System-wide keyboard shortcuts\n- Window management and positioning\n- Menu item automation\n- Clipboard verification\n- Multi-app workflows on macOS\n\n**Do not use Hammerspoon for:**\n- Testing web applications (use Chrome MCP or Playwright)\n- Cross-platform testing needed\n- Linux desktop automation (use dev-test-linux)\n\n**For web testing, use:**\n- `Read(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-test-chrome/SKILL.md\")` - debugging\n- `Read(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-test-playwright/SKILL.md\")` - CI/CD\n\n### Rationalization Prevention\n\n| Thought | Reality |\n|---------|---------|\n| \"I can use AppleScript instead\" | Hammerspoon is more reliable for automation |\n| \"I'll test the app manually\" | AUTOMATE IT with Hammerspoon |\n| \"Web testing tools work for desktop apps\" | NO. Use Hammerspoon for native apps |\n| \"Accessibility permissions are too hard\" | One-time setup. Do it. |\n| \"The app is too complex to automate\" | Break it into testable steps |\n</EXTREMELY-IMPORTANT>\n\n## Hammerspoon Setup\n\n**One-time setup in `~/.hammerspoon/init.lua`:**\n```lua\nrequire(\"hs.ipc\")  -- Enables CLI\n```\n\n**Reload config after changes:**\n```bash\nhs -c 'hs.reload()'  # Reload Hammerspoon configuration\n```\n\n## Input Simulation\n\n### hs.eventtap - Keyboard/Mouse\n\n```lua\n-- Type text (simulates keystrokes)\nhs.eventtap.keyStrokes(\"hello world\")\n\n-- Key press with modifiers\nhs.eventtap.keyStroke({\"cmd\"}, \"c\")           -- Cmd+C\nhs.eventtap.keyStroke({\"cmd\", \"shift\"}, \"s\")  -- Cmd+Shift+S\nhs.eventtap.keyStroke({\"ctrl\", \"alt\"}, \"t\")   -- Ctrl+Alt+T\nhs.eventtap.keyStroke({}, \"return\")           -- Enter key\nhs.eventtap.keyStroke({}, \"escape\")           -- Escape key\n\n-- Function keys\nhs.eventtap.keyStroke({}, \"f1\")\nhs.eventtap.keyStroke({\"cmd\"}, \"f5\")\n\n-- Mouse clicks\nhs.eventtap.leftClick({x=100, y=200})\nhs.eventtap.rightClick({x=100, y=200})\nhs.eventtap.middleClick({x=100, y=200})\nhs.eventtap.doubleClick({x=100, y=200})\n\n-- Mouse movement\nhs.mouse.absolutePosition({x=500, y=300})\n\n-- Scroll\nhs.eventtap.scrollWheel({0, -5}, {})  -- Scroll down\nhs.eventtap.scrollWheel({0, 5}, {})   -- Scroll up\n```\n\n### Running from CLI\n\n```bash\n# Execute Lua code directly\nhs -c 'hs.eventtap.keyStroke({\"cmd\"}, \"c\")'  # Run inline Lua code via CLI\n\n# Execute a script file\nhs /path/to/test_script.lua  # Run Hammerspoon script from file\n\n# Pipe script via stdin\necho 'hs.eventtap.keyStrokes(\"test\")' | hs -s  # Run script piped through stdin\n```\n\n## Application Control\n\n### hs.application\n\n```lua\n-- Launch or focus app by name\nlocal app = hs.application.launchOrFocus(\"Safari\")\n\n-- Launch app by bundle ID\nhs.application.launchOrFocusByBundleID(\"com.apple.Safari\")\n\n-- Get running app\nlocal app = hs.application.get(\"Safari\")\nif app then\n    app:activate()       -- Bring to front\n    app:hide()           -- Hide\n    app:unhide()         -- Unhide\n    app:kill()           -- Terminate gracefully\n    app:kill9()          -- Force kill\nend\n\n-- Get frontmost app\nlocal front = hs.application.frontmostApplication()\nprint(front:name())\nprint(front:bundleID())\n\n-- List all running apps\nfor _, app in ipairs(hs.application.runningApplications()) do\n    print(app:name())\nend\n\n-- Wait for app to launch\nhs.timer.waitUntil(\n    function() return hs.application.get(\"MyApp\") ~= nil end,\n    function() print(\"App launched\") end,\n    0.5  -- Check every 0.5 seconds\n)\n```\n\n### Menu Items\n\n```lua\n-- Click menu item\nlocal app = hs.application.get(\"Safari\")\napp:selectMenuItem({\"File\", \"New Window\"})\napp:selectMenuItem({\"Edit\", \"Paste\"})\n\n-- Check if menu item exists\nlocal menuItem = app:findMenuItem({\"File\", \"Save\"})\nif menuItem then\n    print(\"Save is available, enabled:\", menuItem.enabled)\nend\n```\n\n## Window Management\n\n### hs.window\n\n```lua\n-- Get focused window\nlocal win = hs.window.focusedWindow()\nprint(win:title())\nprint(win:frame())  -- {x, y, w, h}\n\n-- Get app's windows\nlocal app = hs.application.get(\"Safari\")\nlocal wins = app:allWindows()\nfor _, win in ipairs(wins) do\n    print(win:title())\nend\n\n-- Get window by title (partial match)\nlocal win = hs.window.get(\"My Document\")\n\n-- Window actions\nwin:focus()           -- Focus window\nwin:maximize()        -- Maximize\nwin:minimize()        -- Minimize to dock\nwin:close()           -- Close window\n\n-- Move/resize\nwin:setFrame({x=100, y=100, w=800, h=600})\nwin:move({100, 0})    -- Move relative\nwin:setSize({800, 600})\nwin:centerOnScreen()\n\n-- Get window position and size\nlocal frame = win:frame()\nprint(\"Position:\", frame.x, frame.y)\nprint(\"Size:\", frame.w, frame.h)\n```\n\n## Screenshots\n\n<EXTREMELY-IMPORTANT>\n### The Iron Law of Visual Verification\n\n**Every E2E test MUST include screenshot evidence.**\n\nAfter completing a workflow, capture a screenshot to prove success.\n</EXTREMELY-IMPORTANT>\n\n### screencapture (CLI)\n\n```bash\n# Full screen (all displays)\nscreencapture /tmp/screenshot.png  # Capture entire screen to file\n\n# Main screen only\nscreencapture -m /tmp/main_screen.png  # Capture primary screen only\n\n# Specific window (interactive - click to select)\nscreencapture -w /tmp/window.png  # Interactively select window to capture\n\n# Specific region\nscreencapture -R 100,200,800,600 /tmp/region.png  # Capture rectangular region (x,y,w,h)\n\n# Without window shadow\nscreencapture -o /tmp/no_shadow.png  # Capture without window shadows\n\n# Silent (no camera sound)\nscreencapture -x /tmp/silent.png  # Capture silently without shutter sound\n\n# To clipboard instead of file\nscreencapture -c  # Capture to clipboard\n\n# Combined: silent, no shadow, specific region\nscreencapture -x -o -R 0,0,1920,1080 /tmp/clean.png  # Capture region silently without shadows\n```\n\n### hs.screen (Hammerspoon)\n\n```lua\n-- Capture focused window\nlocal win = hs.window.focusedWindow()\nif win then\n    local img = win:snapshot()\n    img:saveToFile(\"/tmp/window.png\")\nend\n\n-- Capture entire screen\nlocal screen = hs.screen.mainScreen()\nlocal img = screen:snapshot()\nimg:saveToFile(\"/tmp/screen.png\")\n\n-- Capture specific region\nlocal img = hs.screen.mainScreen():snapshot({x=0, y=0, w=800, h=600})\nimg:saveToFile(\"/tmp/region.png\")\n```\n\n## Complete E2E Example\n\n<EXTREMELY-IMPORTANT>\n### E2E Test Structure\n\nEvery Hammerspoon E2E test MUST:\n1. **Launch** - Start the application\n2. **Verify launch** - Assert app is running\n3. **Interact** - Perform user actions\n4. **Verify state** - Check expected state (clipboard, window, etc.)\n5. **Screenshot** - Capture visual evidence\n6. **Cleanup** - Close app, restore state\n</EXTREMELY-IMPORTANT>\n\n```lua\n-- test_workflow.lua\n-- Run with: hs /path/to/test_workflow.lua\n\nlocal function test_app_workflow()\n    -- 1. Launch app\n    print(\"Launching app...\")\n    hs.application.launchOrFocus(\"TextEdit\")\n    hs.timer.usleep(1000000)  -- Wait 1 second\n\n    -- 2. Verify app launched\n    local app = hs.application.get(\"TextEdit\")\n    assert(app, \"FAIL: TextEdit did not launch\")\n    print(\"App launched: \" .. app:name())\n\n    -- 3. Create new document\n    hs.eventtap.keyStroke({\"cmd\"}, \"n\")\n    hs.timer.usleep(500000)\n\n    -- 4. Type content\n    hs.eventtap.keyStrokes(\"Hello, this is an automated test!\")\n    hs.timer.usleep(300000)\n\n    -- 5. Select all and copy\n    hs.eventtap.keyStroke({\"cmd\"}, \"a\")\n    hs.timer.usleep(100000)\n    hs.eventtap.keyStroke({\"cmd\"}, \"c\")\n\n    -- 6. Verify clipboard\n    local clipboard = hs.pasteboard.getContents()\n    assert(clipboard:find(\"automated test\"), \"FAIL: Clipboard doesn't match\")\n    print(\"Clipboard verified: \" .. clipboard)\n\n    -- 7. Take screenshot\n    local win = hs.window.focusedWindow()\n    local img = win:snapshot()\n    img:saveToFile(\"/tmp/test_result.png\")\n    print(\"Screenshot saved to /tmp/test_result.png\")\n\n    -- 8. Close without saving\n    hs.eventtap.keyStroke({\"cmd\"}, \"w\")\n    hs.timer.usleep(500000)\n    hs.eventtap.keyStroke({}, \"d\")  -- \"Don't Save\" button\n\n    print(\"PASS: Workflow completed successfully\")\nend\n\n-- Run the test\nlocal status, err = pcall(test_app_workflow)\nif not status then\n    print(\"FAIL: \" .. tostring(err))\n    os.exit(1)\nend\nos.exit(0)\n```\n\n**Run from CLI:**\n```bash\nhs /path/to/test_workflow.lua && echo \"TEST PASSED\" || echo \"TEST FAILED\"  # Execute test script and report result\n```\n\n## Alternative: cliclick\n\nFor simpler needs, `cliclick` provides CLI-based mouse/keyboard control:\n\n```bash\n# Install cliclick tool\nbrew install cliclick\n\n# Mouse click at coordinates\ncliclick c:100,200       # Left-click at coordinates\ncliclick rc:100,200      # Right-click at coordinates\ncliclick dc:100,200      # Double-click at coordinates\n\n# Move mouse\ncliclick m:500,300  # Move mouse to coordinates\n\n# Type text\ncliclick t:\"Hello world\"  # Type text at current cursor position\n\n# Key press\ncliclick kp:return  # Press return key\ncliclick kp:escape  # Press escape key\ncliclick kd:cmd kp:c ku:cmd  # Press Cmd+C (key down, press, key up)\n\n# Wait (milliseconds)\ncliclick w:500  # Wait for 500 milliseconds\n```\n\n**cliclick is useful for simple scripts but lacks app control - prefer Hammerspoon for complex E2E tests.**\n\n## Output Requirements\n\n**Every test run MUST be documented in LEARNINGS.md:**\n\n```markdown\n## macOS E2E Test: [Description]\n\n**Tool:** Hammerspoon\n\n**Script:**\n```bash\nhs /path/to/test_script.lua\n```\n\n**Output:**\n```\nLaunching app...\nApp launched: TextEdit\nClipboard verified: Hello, this is an automated test!\nScreenshot saved to /tmp/test_result.png\nPASS: Workflow completed successfully\n```\n\n**Result:** PASS\n\n**Screenshot:** /tmp/test_result.png\n```\n\n## Integration\n\nThis skill is referenced by `dev-test` for macOS desktop automation.\n\nFor TDD protocol, see: `Skill(skill=\"workflows:dev-tdd\")`\n",
        "skills/dev-test-linux/SKILL.md": "---\nname: dev-test-linux\ndescription: This skill should be used when the user asks to \"test Linux desktop apps\", \"automate GTK/Qt applications\", \"test with ydotool\", \"test with xdotool\", \"verify Linux UI interactions\", \"capture screenshots on Linux\", \"control D-Bus services\", \"test Wayland applications\", \"test X11 applications\", or needs Linux desktop E2E testing. Provides comprehensive guidance for Linux automation with ydotool (Wayland), xdotool (X11), grim, and D-Bus.\nversion: 0.1.0\n---\n\n<EXTREMELY-IMPORTANT>\n## Gate Reminder\n\nBefore taking screenshots or running E2E tests, you MUST complete all 6 gates from dev-tdd:\n\n```\nGATE 1: BUILD\nGATE 2: LAUNCH (with file-based logging)\nGATE 3: WAIT\nGATE 4: CHECK PROCESS\nGATE 5: READ LOGS ← MANDATORY, CANNOT SKIP\nGATE 6: VERIFY LOGS\nTHEN: E2E tests/screenshots\n```\n\n**You loaded dev-tdd earlier. Follow the gates now.**\n</EXTREMELY-IMPORTANT>\n\n## Contents\n\n- [Tool Availability Gate](#tool-availability-gate)\n- [When to Use Linux Automation](#when-to-use-linux-automation)\n- [Detect Display Server](#detect-display-server)\n- [Wayland: ydotool](#wayland-ydotool)\n- [X11: xdotool](#x11-xdotool)\n- [Screenshots](#screenshots)\n- [D-Bus Control](#d-bus-control)\n- [Accessibility (AT-SPI)](#accessibility-at-spi)\n- [Complete E2E Examples](#complete-e2e-examples)\n\n# Linux Desktop Automation\n\n<EXTREMELY-IMPORTANT>\n## Tool Availability Gate\n\nVerify automation tools are installed before proceeding.\n\n```bash\n# Detect display server (check for Wayland vs X11)\necho $XDG_SESSION_TYPE  # \"wayland\" or \"x11\"\n\n# Wayland tools check (verify ydotool, wtype, grim, slurp)\nwhich ydotool || echo \"MISSING: ydotool\"\nwhich wtype || echo \"MISSING: wtype\"\nwhich grim || echo \"MISSING: grim\"\nwhich slurp || echo \"MISSING: slurp\"\n\n# X11 tools check (verify xdotool, xclip, scrot)\nwhich xdotool || echo \"MISSING: xdotool\"\nwhich xclip || echo \"MISSING: xclip\"\nwhich scrot || echo \"MISSING: scrot\"\n\n# D-Bus check (verify dbus-send availability)\nwhich dbus-send || echo \"MISSING: dbus-send\"\n```\n\n**If missing (Wayland):**\n```\nSTOP: Cannot proceed with Wayland automation.\n\nMissing tools for Wayland E2E testing.\n\nInstall with:\n  # Arch\n  sudo pacman -S ydotool wtype grim slurp\n\n  # Debian/Ubuntu\n  sudo apt install ydotool wtype grim slurp\n\n  # Nix\n  nix-env -iA nixpkgs.ydotool nixpkgs.wtype nixpkgs.grim nixpkgs.slurp\n\nStart ydotool daemon:\n  sudo systemctl enable --now ydotool\n  # Or for user service:\n  systemctl --user enable --now ydotool\n\nReply when installed and I'll continue testing.\n```\n\n**This gate is non-negotiable. Missing tools = full stop.**\n</EXTREMELY-IMPORTANT>\n\n<EXTREMELY-IMPORTANT>\n## When to Use Linux Automation\n\nUse Linux automation (ydotool/xdotool) for:\n- Linux native application automation\n- GTK/Qt application testing\n- System-wide keyboard/mouse control\n- Window management testing\n- D-Bus service interaction\n- Accessibility testing (AT-SPI)\n\nDo NOT use Linux automation for:\n- Testing web applications (use Chrome MCP or Playwright)\n- macOS desktop automation (use dev-test-hammerspoon)\n- Cross-platform testing\n\nFor web testing, use:\n- `Read(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-test-chrome/SKILL.md\")` - debugging\n- `Read(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-test-playwright/SKILL.md\")` - CI/CD\n\n### Rationalization Prevention\n\n| Thought | Reality |\n|---------|---------|\n| \"I can test the app manually\" | AUTOMATE IT with ydotool/xdotool |\n| \"Web testing tools work for desktop apps\" | NO. Use native Linux tools |\n| \"ydotool daemon is hard to set up\" | One-time setup. Do it. |\n| \"X11 is deprecated, skip xdotool\" | Many systems still use X11. Support both. |\n| \"D-Bus is too complex\" | D-Bus gives precise control. Learn it. |\n\n### Display Server Detection\n\n```bash\n# Detect display server and choose appropriate tools\nif [ \"$XDG_SESSION_TYPE\" = \"wayland\" ]; then\n    # Use ydotool, wtype, grim\nelse\n    # Use xdotool, xclip, scrot\nfi\n```\n\nAlways detect display server before choosing tools.\n</EXTREMELY-IMPORTANT>\n\n## Detect Display Server\n\n```bash\n# Check display server type (Wayland or X11)\nif [ \"$XDG_SESSION_TYPE\" = \"wayland\" ]; then\n    echo \"Using Wayland tools (ydotool, wtype, grim)\"\nelse\n    echo \"Using X11 tools (xdotool, xclip, scrot)\"\nfi\n```\n\n## Wayland: ydotool\n\nRequires ydotoold daemon running.\n\n### Keyboard Input\n\n```bash\n# Type text (simple text input to focused window)\nydotool type \"hello world\"\n\n# Type with delay (type text with microsecond delay between keys)\nydotool type --delay 50 \"slow typing\"\n\n# Press Enter key (send Enter key using keycode format)\nydotool key 28:1 28:0\n\n# Press Escape key (send Escape key)\nydotool key 1:1 1:0\n\n# Press Ctrl+C (send Ctrl+C combination)\nydotool key 29:1 46:1 46:0 29:0\n\n# Press Ctrl+V (send Ctrl+V combination)\nydotool key 29:1 47:1 47:0 29:0\n\n# Press Alt+Tab (send Alt+Tab combination)\nydotool key 56:1 15:1 15:0 56:0\n\n# Common keycodes reference\n# 1=Escape, 14=Backspace, 15=Tab, 28=Enter, 29=Ctrl, 42=LShift\n# 56=Alt, 57=Space, 100=RightAlt, 125=Super/Win\n```\n\n### Alternative: wtype (Wayland-native)\n\n```bash\n# Type text (simple text input to focused window)\nwtype \"hello world\"\n\n# Press Ctrl+C (send Ctrl+C combination)\nwtype -M ctrl -k c\n\n# Press Ctrl+Shift+S (send Ctrl+Shift+S combination)\nwtype -M ctrl -M shift -k s\n\n# Press Enter (send Enter key)\nwtype -k Return\n\n# Press Escape (send Escape key)\nwtype -k Escape\n```\n\nAvailable modifiers: shift, ctrl, alt, logo (super)\n\n### Mouse Input\n\n```bash\n# Move mouse to absolute position (move cursor to screen coordinates)\nydotool mousemove --absolute 100 200\n\n# Move mouse relative (move cursor by relative offset)\nydotool mousemove 50 -30\n\n# Click left button (send left mouse click)\nydotool click 1\n\n# Click right button (send right mouse click)\nydotool click 3\n\n# Double click (send double click)\nydotool click 1 1\n\n# Click at position (move and click in one operation)\nydotool mousemove --absolute 500 300 && ydotool click 1\n\n# Drag operation (move mouse while holding button)\nydotool mousemove --absolute 100 100\nydotool mousedown 1\nydotool mousemove --absolute 200 200\nydotool mouseup 1\n```\n\n## X11: xdotool\n\n### Keyboard Input\n\n```bash\n# Type text (simple text input to focused window)\nxdotool type \"hello world\"\n\n# Press Return (send Return key)\nxdotool key Return\n\n# Press Escape (send Escape key)\nxdotool key Escape\n\n# Press Ctrl+C (send Ctrl+C combination)\nxdotool key ctrl+c\n\n# Press Ctrl+Shift+S (send Ctrl+Shift+S combination)\nxdotool key ctrl+shift+s\n\n# Press Alt+Tab (send Alt+Tab combination)\nxdotool key alt+Tab\n\n# Press Super+D (send Super+D combination)\nxdotool key super+d\n\n# Type with delay (type text with millisecond delay between keys)\nxdotool type --delay 50 \"slow typing\"\n\n# Hold key down (press and hold Ctrl)\nxdotool keydown ctrl\n\n# Press C (send C key)\nxdotool key c\n\n# Release key (release Ctrl)\nxdotool keyup ctrl\n```\n\n### Mouse Input\n\n```bash\n# Move mouse absolute (move cursor to screen coordinates)\nxdotool mousemove 100 200\n\n# Move mouse relative (move cursor by relative offset)\nxdotool mousemove --relative 50 30\n\n# Click left button (send left mouse click)\nxdotool click 1\n\n# Click middle button (send middle mouse click)\nxdotool click 2\n\n# Click right button (send right mouse click)\nxdotool click 3\n\n# Double click (send double click)\nxdotool click --repeat 2 1\n\n# Click at position (move and click in one operation)\nxdotool mousemove 500 300 click 1\n\n# Drag operation (move mouse while holding button)\nxdotool mousemove 100 100 mousedown 1 mousemove 200 200 mouseup 1\n```\n\n### Window Control (X11)\n\n```bash\n# Get active window ID (get numeric window identifier)\nxdotool getactivewindow\n\n# Focus window by name (find and focus window matching name)\nxdotool search --name \"Firefox\" windowactivate\n\n# Focus window by class (find and focus window matching class)\nxdotool search --class \"firefox\" windowactivate\n\n# Get window title (get title of active window)\nxdotool getactivewindow getwindowname\n\n# Move window (move active window to coordinates)\nxdotool getactivewindow windowmove 100 100\n\n# Resize window (resize active window to dimensions)\nxdotool getactivewindow windowsize 800 600\n\n# Minimize window (minimize active window)\nxdotool getactivewindow windowminimize\n\n# Focus window and wait (find, focus, and synchronize with window)\nxdotool search --name \"Firefox\" windowactivate --sync\n```\n\n## Screenshots\n\n<EXTREMELY-IMPORTANT>\n### The Iron Law of Visual Verification\n\nEvery E2E test MUST include screenshot evidence.\n\nCapture a screenshot after completing a workflow to prove success.\n</EXTREMELY-IMPORTANT>\n\n### Wayland: grim + slurp\n\n```bash\n# Capture full screen (capture all outputs)\ngrim /tmp/screenshot.png\n\n# Capture specific output (capture single monitor/output)\ngrim -o DP-1 /tmp/screen.png\n\n# Capture region interactively (select region with slurp then capture)\ngrim -g \"$(slurp)\" /tmp/region.png\n\n# Capture specific region (capture region by coordinates and size)\ngrim -g \"100,200 800x600\" /tmp/region.png\n\n# Capture Hyprland window (get window geometry and capture)\nhyprctl clients -j | jq '.[] | select(.class==\"firefox\")'\ngrim -g \"X,Y WxH\" /tmp/window.png\n\n# Capture Sway focused window (get focused window geometry and capture)\ngrim -g \"$(swaymsg -t get_tree | jq -r '.. | select(.focused?) | .rect | \"\\(.x),\\(.y) \\(.width)x\\(.height)\"')\" /tmp/window.png\n```\n\n### X11: scrot / import\n\n```bash\n# Capture full screen (screenshot of entire display)\nscrot /tmp/screenshot.png\n\n# Capture active window (screenshot of focused window)\nscrot -u /tmp/window.png\n\n# Capture interactive selection (select region with mouse then capture)\nscrot -s /tmp/selection.png\n\n# Capture with delay (wait before capturing)\nscrot -d 3 /tmp/delayed.png\n\n# Capture root window (screenshot using ImageMagick)\nimport -window root /tmp/screenshot.png\n\n# Capture active window (screenshot of focused window using ImageMagick)\nimport -window \"$(xdotool getactivewindow)\" /tmp/window.png\n```\n\n### Image Comparison\n\n```bash\n# Compare screenshots (count different pixels using ImageMagick)\ncompare -metric AE baseline.png current.png diff.png\n\n# Threshold comparison (allow 5% fuzz when comparing)\ncompare -metric AE -fuzz 5% baseline.png current.png diff.png\n```\n\n## D-Bus Control\n\nPreferred for apps that expose D-Bus interfaces.\n\n```bash\n# List available services (enumerate all D-Bus services)\ndbus-send --session --print-reply --dest=org.freedesktop.DBus \\\n  /org/freedesktop/DBus org.freedesktop.DBus.ListNames\n\n# Open document in Zathura (get PID first, then use org.pwmt.zathura.PID-XXXX)\ndbus-send --print-reply --dest=org.pwmt.zathura.PID-12345 \\\n  /org/pwmt/zathura org.pwmt.zathura.OpenDocument string:\"/path/to/file.pdf\"\n\n# Go to page in Zathura (navigate to specific page)\ndbus-send --print-reply --dest=org.pwmt.zathura.PID-12345 \\\n  /org/pwmt/zathura org.pwmt.zathura.GotoPage uint32:5\n\n# Open file in GNOME Nautilus (open folder via D-Bus)\ndbus-send --session --dest=org.gnome.Nautilus \\\n  /org/gnome/Nautilus org.freedesktop.Application.Open \\\n  array:string:\"file:///home/user\" dict:string:string:\"\"\n\n# Introspect D-Bus service (discover available methods and properties)\ndbus-send --session --print-reply --dest=org.example.App \\\n  /org/example/App org.freedesktop.DBus.Introspectable.Introspect\n```\n\n## Accessibility (AT-SPI)\n\nUse AT-SPI for UI element discovery and verification.\n\n```python\n#!/usr/bin/env python3\nimport pyatspi\n\n# Find application (get desktop and search for app by name)\ndesktop = pyatspi.Registry.getDesktop(0)\nfor app in desktop:\n    if \"firefox\" in app.name.lower():\n        print(f\"Found: {app.name}\")\n\n        # Traverse accessibility tree (recursively dump accessibility tree)\n        def dump_tree(node, indent=0):\n            print(\"  \" * indent + f\"{node.getRole()}: {node.name}\")\n            for child in node:\n                dump_tree(child, indent + 1)\n\n        dump_tree(app)\n\n# Find specific element (search for button by name in tree)\ndef find_button(app, name):\n    for child in app:\n        if child.getRole() == pyatspi.ROLE_PUSH_BUTTON:\n            if name.lower() in child.name.lower():\n                return child\n        found = find_button(child, name)\n        if found:\n            return found\n    return None\n\n# Click button via AT-SPI (trigger button action via accessibility interface)\nbutton = find_button(app, \"Submit\")\nif button:\n    button.queryAction().doAction(0)\n```\n\n## Complete E2E Examples\n\n<EXTREMELY-IMPORTANT>\n### E2E Test Structure\n\nEvery Linux E2E test MUST:\n1. Detect - Check display server (Wayland vs X11)\n2. Launch - Start the application\n3. Wait - Allow app to fully initialize\n4. Interact - Perform user actions\n5. Verify - Check expected state\n6. Screenshot - Capture visual evidence\n7. Cleanup - Close app, restore state\n</EXTREMELY-IMPORTANT>\n\n### Wayland E2E Test\n\n```bash\n#!/bin/bash\n# test_workflow.sh - Wayland E2E test\n\nset -e  # Exit on error\n\necho \"Starting E2E test...\"\n\n# Launch Firefox\nfirefox &\nsleep 3\n\n# Focus address bar and navigate (focus address bar with Ctrl+L)\nwtype -M ctrl -k l\nsleep 0.2\n\n# Type URL (type example.com URL)\nwtype \"https://example.com\"\n\n# Press Enter (send Return key)\nwtype -k Return\nsleep 2\n\n# Capture initial screenshot (screenshot before interaction)\ngrim /tmp/test_before.png\n\n# Move mouse and click (move to element and click)\nydotool mousemove --absolute 500 400\nydotool click 1\nsleep 0.5\n\n# Capture final screenshot (screenshot after interaction)\ngrim /tmp/test_after.png\n\n# Compare screenshots (compare file sizes to detect changes)\nSIZE_BEFORE=$(stat -c%s /tmp/test_before.png)\nSIZE_AFTER=$(stat -c%s /tmp/test_after.png)\n\nif [ \"$SIZE_BEFORE\" -ne \"$SIZE_AFTER\" ]; then\n    echo \"PASS: Screenshots differ (interaction worked)\"\nelse\n    echo \"WARN: Screenshots identical\"\nfi\n\necho \"Test complete\"\n```\n\n### X11 E2E Test\n\n```bash\n#!/bin/bash\n# test_workflow_x11.sh - X11 E2E test\n\nset -e\n\necho \"Starting X11 E2E test...\"\n\n# Launch gedit (start text editor application)\ngedit &\nsleep 2\n\n# Focus gedit window (find and focus window by name)\nxdotool search --name \"gedit\" windowactivate --sync\n\n# Type test content (type test text into editor)\nxdotool type \"Hello, this is an automated test!\"\nsleep 0.5\n\n# Select all text (select all with Ctrl+A)\nxdotool key ctrl+a\n\n# Copy to clipboard (copy selected text with Ctrl+C)\nxdotool key ctrl+c\n\n# Verify clipboard content (get clipboard and verify content)\nCLIPBOARD=$(xclip -selection clipboard -o)\nif [[ \"$CLIPBOARD\" == *\"automated test\"* ]]; then\n    echo \"PASS: Clipboard contains expected text\"\nelse\n    echo \"FAIL: Clipboard mismatch\"\n    exit 1\nfi\n\n# Capture window screenshot (screenshot of active window)\nscrot -u /tmp/test_result.png\necho \"Screenshot saved\"\n\n# Close without saving (close window with Ctrl+W)\nxdotool key ctrl+w\nsleep 0.5\n\n# Dismiss save dialog (press Tab and Return to skip save)\nxdotool key Tab key Return\n\necho \"Test complete\"\n```\n\n## Output Requirements\n\nDocument every test run in LEARNINGS.md using this template:\n\n```markdown\n## Linux E2E Test: [Description]\n\n**Display Server:** Wayland / X11\n\n**Tool:** ydotool / xdotool\n\n**Script:**\n```bash\n./test_workflow.sh\n```\n\n**Output:**\n```\nStarting E2E test...\nPASS: Screenshots differ (interaction worked)\nTest complete\n```\n\n**Result:** PASS\n\n**Screenshot:** /tmp/test_result.png\n```\n\n## Integration\n\nThis skill integrates with `dev-test` for Linux desktop automation.\n\nFor TDD protocol, see: `Skill(skill=\"workflows:dev-tdd\")`\n",
        "skills/dev-test/SKILL.md": "---\nname: dev-test\ndescription: \"This skill should be used when the user needs to 'debug web applications', 'test UI interactions', 'capture screenshots or network requests', 'test desktop automation', or needs to select between testing tools. Routes to platform-specific E2E testing skills: Chrome MCP for debugging, Playwright for CI/CD, Hammerspoon for macOS, Linux for X11/Wayland.\"\n---\n\n\n## Where This Fits\n\n```\nMain Chat                          Task Agent\n─────────────────────────────────────────────────────\ndev-implement\n  → dev-ralph-loop (loads dev-tdd)\n    → dev-delegate\n      → Task agent ──────────────→ uses dev-test (this skill)\n                                     ↓ loads dev-tdd again\n                                   has TDD protocol + gates\n                                     → routes to specific tool\n```\n\n<EXTREMELY-IMPORTANT>\n## Load TDD Enforcement (REQUIRED)\n\nBefore choosing testing tools, you MUST load the TDD skill to ensure gate compliance:\n\n```\nSkill(skill=\"workflows:dev-tdd\")\n```\n\nThis loads:\n- Task reframing (your job is writing tests, not features)\n- **The Execution Gate** (6 mandatory gates before E2E testing)\n- **GATE 5: READ LOGS** (mandatory - cannot skip)\n- The Iron Law of TDD (test-first approach)\n\n**Read dev-tdd skill content now before selecting testing tools.**\n</EXTREMELY-IMPORTANT>\n\n**This skill routes to the right testing tool.** The loaded `dev-tdd` skill provides TDD protocol details.\n\n## Contents\n\n- [The Iron Law](#the-iron-law-of-testing)\n- [Browser Testing Decision Tree](#browser-testing-decision-tree)\n- [Platform Detection](#platform-detection)\n- [Sub-Skills Reference](#sub-skills-reference)\n- [Unit & Integration Tests](#unit--integration-tests)\n\n<EXTREMELY-IMPORTANT>\n## The Iron Law of Testing\n\n**YOU MUST WRITE E2E TESTS FOR USER-FACING FEATURES. This is not negotiable.**\n\nWhen your changes affect what users see or interact with, you MUST:\n1. Write an E2E test that simulates user behavior\n2. Run it and verify it PASSES (not just unit tests)\n3. Document: \"E2E: [test name] passes with [evidence]\"\n4. Include screenshot/snapshot for visual changes\n\n**Unit tests prove components work. E2E tests prove YOUR feature works for users.**\n\n### Rationalization Prevention\n\nWhen you catch yourself thinking these rationalizations, STOP—you're about to skip E2E tests:\n\n| Thought | Why You're Wrong | Do Instead |\n|---------|-----------------|-----------|\n| \"Unit tests are enough\" | Your unit tests don't test user flows. | Write E2E. |\n| \"E2E is too slow\" | You're choosing slow tests < shipped bugs. | Write E2E. |\n| \"I'll add E2E later\" | You won't. Your future self won't either. | Write it NOW. |\n| \"This is just backend\" | Does it affect user output? Then YOU need E2E. | Write E2E. |\n| \"The tool setup is complex\" | Your complexity = complex failure modes. E2E finds them. | Write E2E. |\n| \"The UI is unchanged\" | Your assumption isn't proven. | Prove it with a visual snapshot. |\n| \"Manual testing is faster\" | You're LYING about coverage to yourself. | Write E2E. |\n| \"It's just a small change\" | Your small change breaks UIs. E2E proves it doesn't. | Write E2E. |\n| \"User can verify\" | NO. You don't trust users with QA. | Automated verification or it didn't happen. |\n| **\"Log checking is my E2E test\"** | **You're confusing observability with verification.** | **Verify your actual outputs.** |\n| **\"Screenshots are too hard to capture\"** | **Your avoidance = hard to debug in production later.** | **Automate it.** |\n\n### Fake E2E Detection - STOP\n\n**If your \"E2E test\" does any of these, it's NOT E2E:**\n\n| Pattern | Why It's Fake | Real E2E Alternative |\n|---------|---------------|----------------------|\n| `grep \"success\" logs.txt` | Only proves code ran | Verify actual output file/UI/API response |\n| `assert mock.called` | Tests mock, not real system | Use real integration, verify real data |\n| `cat output.txt \\| wc -l` | File exists ≠ correct content | Read file, assert exact expected content |\n| \"I ran it manually\" | No automation = no evidence | Capture manual test as automated test |\n| Check log for icon name | Observability, not verification | Screenshot + visual diff of rendered icon |\n| Exit code 0 | Process succeeded ≠ output correct | Verify the actual output data |\n\n**The test:** If removing the actual implementation still passes your \"E2E test\", it's fake.\n\n**Example of fake E2E that caught nothing:**\n```python\n# FAKE E2E - only checks logs\ndef test_icon_theme_change():\n    run_command(\"set-theme papirus\")\n    logs = read_logs()\n    assert \"papirus\" in logs  # ❌ FAKE - only proves code ran\n    # BUG: 89% of icons weren't changed, test still passed!\n```\n\n**Real E2E that would have caught the bug:**\n```python\n# REAL E2E - verifies actual output\ndef test_icon_theme_change():\n    run_command(\"set-theme papirus\")\n    screenshot = capture_desktop()\n    assert visual_diff(screenshot, \"expected_papirus.png\") < threshold  # ✅ REAL\n    # This would have shown 89% of icons were wrong\n```\n\n### Red Flags - STOP If Thinking:\n\nIf you catch yourself thinking these patterns, STOP—you're about to skip E2E:\n\n| Thought | Why You're Wrong | Do Instead |\n|---------|-----------------|-----------|\n| \"Tests pass\" (only unit) | Your unit tests ≠ E2E | Write E2E test |\n| \"Code looks correct\" | You're only looking ≠ running user flow | Run E2E |\n| \"It worked when I tried it\" | Your manual testing ≠ automated | Capture as E2E |\n| \"Screenshot shows it works\" | Your static screenshot ≠ interaction test | Add automation |\n</EXTREMELY-IMPORTANT>\n\n## Browser Testing Decision Tree\n\n```\n┌─────────────────────────────────────────────────────────────────┐\n│                    BROWSER TESTING REQUIRED?                     │\n└─────────────────────────────────────────────────────────────────┘\n                              │\n                              ▼\n        ┌─────────────────────────────────────────────┐\n        │  Need to debug JS errors or API calls?       │\n        │  (console.log, network requests, XHR)        │\n        └─────────────────────────────────────────────┘\n                    │                    │\n                   YES                   NO\n                    │                    │\n                    ▼                    ▼\n        ┌───────────────────┐  ┌──────────────────────────┐\n        │   CHROME MCP      │  │  Running in CI/CD?        │\n        │   (debugging)     │  │  (headless, automated)    │\n        └───────────────────┘  └──────────────────────────┘\n                                      │           │\n                                     YES          NO\n                                      │           │\n                                      ▼           ▼\n                        ┌──────────────┐  ┌───────────────────┐\n                        │ PLAYWRIGHT   │  │ Cross-browser     │\n                        │ MCP          │  │ needed?           │\n                        └──────────────┘  └───────────────────┘\n                                                │          │\n                                               YES         NO\n                                                │          │\n                                                ▼          ▼\n                                    ┌──────────────┐ ┌────────────┐\n                                    │ PLAYWRIGHT   │ │ Either OK  │\n                                    │ MCP          │ │ (prefer    │\n                                    └──────────────┘ │ Playwright)│\n                                                     └────────────┘\n```\n\n<EXTREMELY-IMPORTANT>\n### Iron Laws: Browser MCP Selection\n\n**YOU MUST USE CHROME MCP FOR API/CONSOLE DEBUGGING. NO EXCEPTIONS.**\n**YOU MUST USE PLAYWRIGHT MCP FOR CI/CD TESTING. NO EXCEPTIONS.**\n\n### Quick Decision Table\n\n| Need | Tool | Why |\n|------|------|-----|\n| Debug console errors | **Chrome MCP** | `read_console_messages` |\n| Inspect API calls/responses | **Chrome MCP** | `read_network_requests` |\n| Execute custom JS in page | **Chrome MCP** | `javascript_tool` |\n| Record interaction as GIF | **Chrome MCP** | `gif_creator` |\n| Headless/CI automation | **Playwright MCP** | Headless mode |\n| Cross-browser testing | **Playwright MCP** | Firefox/WebKit support |\n| Standard E2E suite | **Playwright MCP** | Test isolation, maturity |\n| Interactive debugging | **Chrome MCP** | Real browser, console access |\n\n### Capability Comparison\n\n| Capability | Playwright MCP | Chrome MCP |\n|------------|---------------|------------|\n| Navigate/click/type | ✅ | ✅ |\n| Accessibility tree | ✅ `browser_snapshot` | ✅ `read_page` |\n| Screenshots | ✅ | ✅ |\n| **Console messages** | ❌ | ✅ `read_console_messages` |\n| **Network requests** | ❌ | ✅ `read_network_requests` |\n| **JavaScript execution** | ❌ | ✅ `javascript_tool` |\n| **GIF recording** | ❌ | ✅ `gif_creator` |\n| **Headless mode** | ✅ | ❌ (requires visible browser) |\n| **Cross-browser** | ✅ (Chromium/Firefox/WebKit) | ❌ (Chrome only) |\n| Natural language find | ❌ | ✅ `find` |\n\n### Rationalization Prevention (Browser MCP)\n\n| Thought | Why You're Wrong | Do Instead |\n|---------|-----------------|-----------|\n| \"I'll check the console manually\" | You can't capture all edge cases manually. | Use Chrome MCP `read_console_messages` |\n| \"I can infer the API response\" | Your inference is wrong. Real data differs. | Use Chrome MCP `read_network_requests` |\n| \"Playwright can do everything\" | You're wrong. It cannot read console or network. | Use Chrome MCP for debugging |\n| \"Chrome MCP is enough for CI\" | You're ignoring constraints—it requires visible browser. | Use Playwright MCP for CI/CD |\n| \"I'll just look at DevTools\" | Your manual inspection is not automated. | Automate with Chrome MCP |\n| \"Headless doesn't matter\" | You're wrong. Your CI/CD requires headless. | Use Playwright MCP |\n</EXTREMELY-IMPORTANT>\n\n## Platform Detection\n\nDetect the operating system and display server to select the appropriate testing tool:\n\n```bash\n# Detect platform for desktop automation\ncase \"$(uname -s)\" in\n    Darwin) echo \"macOS - use dev-test-hammerspoon\" ;;\n    Linux)\n        if [ \"$XDG_SESSION_TYPE\" = \"wayland\" ]; then\n            echo \"Linux/Wayland - use dev-test-linux (ydotool)\"\n        else\n            echo \"Linux/X11 - use dev-test-linux (xdotool)\"\n        fi\n        ;;\nesac\n```\n\n### Desktop Automation Decision Tree\n\n```\n┌─────────────────────────────────────────────────────────────────┐\n│                   DESKTOP AUTOMATION REQUIRED?                   │\n└─────────────────────────────────────────────────────────────────┘\n                              │\n                              ▼\n                    ┌─────────────────┐\n                    │   Platform?      │\n                    └─────────────────┘\n                    /        |         \\\n                 macOS    Linux      Windows\n                   │         │           │\n                   ▼         ▼           ▼\n        ┌──────────────┐ ┌─────────┐ ┌─────────┐\n        │ HAMMERSPOON  │ │ LINUX   │ │ NOT     │\n        │ (dev-test-   │ │ (dev-   │ │ SUPPORTED│\n        │ hammerspoon) │ │ test-   │ └─────────┘\n        └──────────────┘ │ linux)  │\n                         └─────────┘\n                              │\n                    ┌─────────┴─────────┐\n                    │   Display Server?  │\n                    └───────────────────┘\n                         /         \\\n                    Wayland        X11\n                       │            │\n                       ▼            ▼\n                 ┌──────────┐ ┌──────────┐\n                 │ ydotool  │ │ xdotool  │\n                 └──────────┘ └──────────┘\n```\n\n## Sub-Skills Reference\n\n<EXTREMELY-IMPORTANT>\n### Tool Availability Gate\n\n**Verify tools are available BEFORE proceeding. Missing tools = FULL STOP.**\n\nEach sub-skill has its own availability gate. Load the appropriate skill and follow its gate.\n</EXTREMELY-IMPORTANT>\n\n### Browser Testing\n\n| Skill | Use Case | Key Capabilities |\n|-------|----------|------------------|\n| `Read(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-test-chrome/SKILL.md\")` | Debugging, console/network inspection | `read_console_messages`, `read_network_requests`, `javascript_tool` |\n| `Read(\"${CLAUDE_PLUGIN_ROOT}/lib/skills/dev-test-playwright/SKILL.md\")` | CI/CD, headless, cross-browser E2E | Headless mode, Firefox/WebKit, test isolation |\n\n### Desktop Automation\n\n| Skill | Platform | Primary Tool |\n|-------|----------|--------------|\n| `Skill(skill=\"workflows:dev-test-hammerspoon\")` | macOS | Hammerspoon (`hs`) |\n| `Skill(skill=\"workflows:dev-test-linux\")` | Linux | ydotool (Wayland) / xdotool (X11) |\n\n## Unit & Integration Tests\n\n### Test Discovery\n\nLocate test directories and identify the test framework used in the project:\n\n```bash\n# Find test directory\nls -d tests/ test/ spec/ __tests__/ 2>/dev/null\n\n# Find test framework\ncat package.json 2>/dev/null | grep -E \"(test|jest)\"\ncat pyproject.toml 2>/dev/null | grep -i pytest\ncat Cargo.toml 2>/dev/null | grep -i \"\\[dev-dependencies\\]\"\ncat meson.build 2>/dev/null | grep -i test\n```\n\n### Common Test Frameworks\n\n| Language | Framework | Command |\n|----------|-----------|---------|\n| Python | pytest | `pytest tests/ -v` |\n| JavaScript | jest | `npm test` |\n| TypeScript | vitest | `npx vitest` |\n| Rust | cargo | `cargo test` |\n| C/C++ | meson | `meson test -C build -v` |\n| Go | go test | `go test ./...` |\n\n### CLI Application Testing\n\nExecute CLI applications with test inputs and verify outputs against expected results:\n\n```bash\n# Run with test inputs\n./app --test-mode input.txt > output.txt\n\n# Compare to expected\ndiff expected.txt output.txt\n\n# Check exit code\n./app --validate file && echo \"PASS\" || echo \"FAIL\"\n```\n\n## Output Requirements\n\n**Every test run MUST be documented in LEARNINGS.md:**\n\n```markdown\n## Test Run: [Description]\n\n**Tool:** [Chrome MCP / Playwright / Hammerspoon / ydotool / pytest / etc.]\n\n**Command:**\n```bash\npytest tests/ -v\n```\n\n**Output:**\n```\ntests/test_feature.py::test_basic PASSED\ntests/test_feature.py::test_edge_case PASSED\ntests/test_feature.py::test_error FAILED\n\n1 failed, 2 passed\n```\n\n**Result:** 2/3 PASS, 1 FAIL\n\n**Next:** Fix test_error failure\n```\n\n## Integration\n\nFor TDD protocol (RED-GREEN-REFACTOR), see:\n```\nSkill(skill=\"workflows:dev-tdd\")\n```\n\nThis skill is invoked by Task agents during `dev-implement` phase.\n",
        "skills/dev-tools/SKILL.md": "---\nname: dev-tools\ndescription: This skill should be used when the user asks to \"what plugins are available\", \"list dev tools\", \"what MCP servers can I use\", \"enable code intelligence\", or needs to discover available development plugins like serena, context7, or playwright.\n---\n\n# Available Development Plugins\n\nThese plugins extend Claude Code capabilities for development workflows. Enable when needed for specific tasks.\n\n## Code Intelligence\n\n| Plugin | Description | Enable Command |\n|--------|-------------|----------------|\n| `serena` | Semantic code analysis, refactoring, symbol navigation | `claude --enable-plugin serena@claude-plugins-official` |\n| `pyright-lsp` | Python type checking and diagnostics | `claude --enable-plugin pyright-lsp@claude-plugins-official` |\n| `clangd-lsp` | C/C++ code intelligence | Already enabled |\n\n## Documentation\n\n| Plugin | Description | Enable Command |\n|--------|-------------|----------------|\n| `context7` | Up-to-date library/framework docs lookup | `claude --enable-plugin context7@claude-plugins-official` |\n\n## Testing & Automation\n\n| Plugin | Description | Enable Command |\n|--------|-------------|----------------|\n| `playwright` | Browser automation, E2E testing, screenshots | `claude --enable-plugin playwright@claude-plugins-official` |\n\n## Workflow\n\n| Plugin | Description | Enable Command |\n|--------|-------------|----------------|\n| `ralph-loop` | Self-referential iteration loops | Already enabled |\n| `hookify` | Create custom hooks from conversation patterns | Already enabled |\n\n## When to Enable\n\n- **serena**: Complex refactoring, finding symbol references, understanding large codebases\n- **context7**: Need current docs for React, pandas, FastAPI, etc.\n- **playwright**: Testing web UIs, scraping, taking screenshots\n- **pyright-lsp**: Python projects needing strict type checking\n\n## Usage\n\nEnable a plugin for the current session by running:\n```bash\n# Enable a plugin: claude --enable-plugin <plugin-name>\nclaude --enable-plugin <plugin-name>\n```\n\nEnable a plugin for a project by adding to `.claude/settings.json`:\n```json\n{\n  \"enabledPlugins\": {\n    \"serena@claude-plugins-official\": true\n  }\n}\n```\n",
        "skills/dev-worktree/SKILL.md": "---\nname: dev-worktree\ndescription: This skill should be used when the user asks to \"create an isolated worktree\", \"set up worktree for feature\", \"create a feature branch worktree\", or needs workspace isolation with automatic dependency setup and test verification.\n---\n\n# Create Development Worktree\n\nCreate an isolated git worktree for feature work, ensuring workspace isolation and clean baseline.\n\n## The Process\n\n### Step 1: Ensure .worktrees/ is Gitignored\n\n**CRITICAL:** Verify worktree directory is gitignored to prevent accidental commits.\n\n**Run:**\n```bash\nif ! git check-ignore -q .worktrees 2>/dev/null; then\n  echo \"Adding .worktrees/ to .gitignore\"\n  echo \".worktrees/\" >> .gitignore\n  git add .gitignore\n  git commit -m \"chore: add .worktrees/ to gitignore\n\nCo-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>\"\nfi\n```\n\n**Description:** dev-worktree: check if .worktrees is gitignored and add if missing\n\n### Step 2: Determine Branch Name\n\nExtract from `.claude/PLAN.md` first line or infer from feature name:\n\n**Run:**\n```bash\n# Extract from PLAN.md if exists\nfeature_name=$(grep -m1 '^# ' .claude/PLAN.md 2>/dev/null | sed 's/^# //' | tr '[:upper:] ' '[:lower:]-' | sed 's/[^a-z0-9-]//g')\n\n# Or ask user if needed\n```\n\n**Description:** dev-worktree: extract or prompt for feature name\n\nBranch name format: `feature/${feature_name}`\n\n### Step 3: Create Worktree\n\n**Run:**\n```bash\n# Create worktree with new branch\ngit worktree add .worktrees/${feature_name} -b feature/${feature_name}\n\n# Change to worktree directory\ncd .worktrees/${feature_name}\n```\n\n**Description:** dev-worktree: create isolated git worktree with feature branch\n\n### Step 4: Run Project Setup\n\nAuto-detect and run setup based on project files:\n\n**Run:**\n```bash\n# Node.js\nif [ -f package.json ]; then\n  npm install\nfi\n\n# Python\nif [ -f requirements.txt ]; then\n  pip install -r requirements.txt\nfi\nif [ -f pyproject.toml ]; then\n  poetry install || pip install -e .\nfi\nif [ -f pixi.toml ]; then\n  pixi install\nfi\n\n# Rust\nif [ -f Cargo.toml ]; then\n  cargo build\nfi\n\n# Go\nif [ -f go.mod ]; then\n  go mod download\nfi\n```\n\n**Description:** dev-worktree: auto-detect project type and install dependencies\n\n### Step 5: Verify Clean Baseline (Optional)\n\nRun tests to verify baseline if project has test suite:\n\n**Run:**\n```bash\n# Examples - auto-detect test command\nif [ -f package.json ] && grep -q '\"test\"' package.json; then\n  npm test\nelif [ -f Cargo.toml ]; then\n  cargo test\nelif [ -f pytest.ini ] || [ -f pyproject.toml ]; then\n  pytest\nelif [ -f go.mod ]; then\n  go test ./...\nfi\n```\n\n**Description:** dev-worktree: auto-detect and run project test suite\n\n**If tests fail:** Report failures and note that baseline has issues.\n**If tests pass:** Report clean baseline.\n\n### Step 6: Report Ready\n\nReport completion status:\n\n```\n✓ Worktree created: .worktrees/${feature_name}\n✓ Branch: feature/${feature_name}\n✓ Dependencies installed\n✓ Tests passing (or note if failed)\n\nReady for implementation.\n```\n\n## Safety Checks\n\n**Execute before creating worktree:**\n- Verify .worktrees/ is gitignored\n- Add to .gitignore if missing\n- Commit gitignore change\n\n**Execute after creating worktree:**\n- Run project setup (npm install, etc.)\n- Verify clean baseline with tests\n- Report status\n\n## Red Flags\n\n**Critical - Never deviate from these rules:**\n- Do not create worktree without verifying gitignore\n- Do not skip project setup commands\n- Do not proceed without reporting test status\n\n**Critical - Always follow these rules:**\n- Verify .worktrees/ is ignored before creating\n- Auto-detect project type and run appropriate setup\n- Report test baseline status\n\n## Common Patterns\n\n### Node.js Project\n```bash\n# .worktrees/ gitignored → create worktree → npm install → npm test\n```\n\n### Python Project\n```bash\n# .worktrees/ gitignored → create worktree → pixi install → pytest\n```\n\n### Rust Project\n```bash\n# .worktrees/ gitignored → create worktree → cargo build → cargo test\n```\n\n## Workflow Transition\n\nAfter worktree creation, the workspace is ready. Proceed to dev-implement to start implementing tasks.\n\nCurrent working directory: `.worktrees/${feature_name}`\n\nAll implementation work happens here, keeping main workspace clean.\n",
        "skills/ds-tools/SKILL.md": "---\nname: ds-tools\ndescription: This skill should be used when the user asks \"what plugins are available\", \"list data science tools\", \"what MCP servers can I use\", \"enable code intelligence\", or needs to discover available plugins like serena, context7, or data access skills like wrds and lseg-data.\n---\n\n# Available Data Science Plugins\n\nThese plugins extend Claude Code capabilities for data science workflows. Enable when needed.\n\n## Code Intelligence\n\n| Plugin | Description | Enable Command |\n|--------|-------------|----------------|\n| `serena` | Semantic code analysis, refactoring, symbol navigation | `claude --enable-plugin serena@claude-plugins-official` |\n| `pyright-lsp` | Python type checking and diagnostics | `claude --enable-plugin pyright-lsp@claude-plugins-official` |\n\n## Documentation\n\n| Plugin | Description | Enable Command |\n|--------|-------------|----------------|\n| `context7` | Up-to-date library docs (pandas, numpy, sklearn, etc.) | `claude --enable-plugin context7@claude-plugins-official` |\n\n## Web & Automation\n\n| Plugin | Description | Enable Command |\n|--------|-------------|----------------|\n| `playwright` | Web scraping, browser automation, screenshots | `claude --enable-plugin playwright@claude-plugins-official` |\n\n## Workflow\n\n| Plugin | Description | Enable Command |\n|--------|-------------|----------------|\n| `ralph-loop` | Self-referential iteration loops | Already enabled |\n| `hookify` | Create custom hooks from conversation patterns | Already enabled |\n\n## Data Access Skills (Built-in)\n\nThese are skills, not plugins - already available via `/ds`:\n\n| Skill | Description |\n|-------|-------------|\n| `/wrds` | WRDS (Wharton Research Data Services) queries |\n| `/lseg-data` | LSEG Data Library (formerly Refinitiv) |\n| `/gemini-batch` | Gemini Batch API for large-scale LLM processing |\n| `/jupytext` | Jupyter notebooks as text files |\n| `/marimo` | Marimo reactive Python notebooks |\n\n## File Format Skills (Bundled)\n\nOffice document and PDF skills from Anthropic's official skills repo (bundled via submodule):\n\n| Skill | Use For |\n|-------|---------|\n| `/xlsx` | Spreadsheets, formulas, CSV→Excel conversion |\n| `/pdf` | PDF extraction, creation, form filling |\n| `/pptx` | Presentation creation and editing |\n| `/docx` | Word docs, tracked changes, reports |\n\nThese skills are available via the `shared` plugin - no separate installation needed.\n\n## When to Enable\n\n- **serena**: Understanding complex analysis codebases, refactoring pipelines\n- **context7**: Access current docs for pandas, scikit-learn, statsmodels, and other libraries\n- **playwright**: Scrape web data sources, automate data collection\n- **pyright-lsp**: Type check data pipelines\n\n## Usage\n\nEnable a plugin for the current session:\n```bash\nclaude --enable-plugin <plugin-name>  # Enable a plugin by name and source\n```\n\nEnable a plugin for a project by adding to `.claude/settings.json`:\n```json\n{\n  \"enabledPlugins\": {\n    \"serena@claude-plugins-official\": true\n  }\n}\n```\n",
        "skills/gemini-batch/SKILL.md": "---\nname: gemini-batch\nversion: 1.0\ndescription: This skill should be used when the user asks to \"use Gemini Batch API\", \"process documents at scale\", \"submit a batch job\", \"upload files to Gemini\", or needs large-scale LLM processing. Includes production gotchas and best practices.\n---\n\n# Gemini Batch API Skill\n\nLarge-scale asynchronous document processing using Google's Gemini models.\n\n## When to Use\n\n- Process thousands of documents with the same prompt\n- Cost-effective bulk extraction (50% cheaper than synchronous API)\n- Jobs that can tolerate 24-hour completion windows\n\n## IRON LAW: Use Examples First, Never Guess API\n\n**READ EXAMPLES BEFORE WRITING ANY CODE. NO EXCEPTIONS.**\n\n### The Rule\n\n```\nUser asks for batch API work\n    ↓\nMANDATORY: Read examples/batch_processor.py or examples/icon_batch_vision.py\n    ↓\nCopy the pattern exactly\n    ↓\nDO NOT guess parameter names\nDO NOT try wrapper types\nDO NOT improvise API calls\n```\n\n### Why This Matters\n\nThe Batch API has non-obvious requirements that will fail silently:\n1. **Metadata must be flat primitives** - Nested objects cause cryptic errors\n2. **Parameter is `dest=` not `destination=`** - Wrong name → TypeError\n3. **Config is plain dict** - Not a wrapper type\n4. **Examples are authoritative** - Working code beats assumptions\n\n**Rationale:** Previous agents wasted hours debugging API errors that the examples would have prevented. The patterns in `examples/` are battle-tested production code.\n\n### Rationalization Table - STOP If You Catch Yourself Thinking:\n\n| Excuse | Reality | Do Instead |\n|--------|---------|------------|\n| \"I know how APIs work\" | You're overconfident about non-obvious gotchas | Read examples first |\n| \"I can figure it out\" | You'll waste 30+ minutes on trial-and-error | Copy working patterns |\n| \"The examples might be outdated\" | They're maintained and tested | Trust the examples |\n| \"I need to customize anyway\" | Your customization comes AFTER copying base pattern | Start with examples, then adapt |\n| \"Reading examples takes too long\" | You'll save 30 minutes debugging with 2 minutes of reading | Read examples first |\n| \"My approach is simpler\" | Your simpler approach already failed | Use proven patterns |\n\n### Red Flags - STOP If You Catch Yourself Thinking:\n\n- **\"Let me try `destination=` instead of `dest=`\"** → You're about to cause a TypeError. Read examples.\n- **\"I'll create a `CreateBatchJobConfig` object\"** → You're instantiating a type instead of using a plain dict. Stop.\n- **\"I'll nest metadata like a normal API\"** → You'll trigger BigQuery type errors. Flatten your data.\n- **\"This should work like other Google APIs\"** → Your assumption is wrong; this API is different.\n- **\"I'll figure out the JSONL format\"** → You'll waste time. Copy from examples instead.\n\n### MANDATORY Checklist Before ANY Batch API Code\n\n- [ ] Read `examples/batch_processor.py` OR `examples/icon_batch_vision.py`\n- [ ] Identify which example matches the use case (Standard API vs Vertex AI)\n- [ ] Copy the example's API call pattern **exactly**\n- [ ] Copy the example's JSONL structure **exactly**\n- [ ] Copy the example's metadata structure **exactly**\n- [ ] Adapt for specific needs only after copying base pattern\n\n**Enforcement:** Writing batch API code without reading examples first violates this IRON LAW and will result in preventable errors.\n\n## Prerequisites\n\n### Install gcloud SDK\n\n```bash\n# macOS: Install Google Cloud SDK via Homebrew\nbrew install google-cloud-sdk\n\n# Linux: Install Google Cloud SDK from official sources\ncurl https://sdk.cloud.google.com | bash\n```\n\n### Authentication Setup\n\n```bash\n# Authenticate with Google Cloud Platform\ngcloud auth login\n\n# Set up Application Default Credentials for Python libraries\ngcloud auth application-default login\n\n# Enable Vertex AI API in your project\ngcloud services enable aiplatform.googleapis.com\n```\n\n**Why both auth methods?**\n- `gcloud auth login`: For gsutil and gcloud CLI commands\n- `gcloud auth application-default login`: For google-generativeai Python library\n- **CRITICAL:** Vertex AI requires ADC (step 2), not just API key\n\n### Create GCS Bucket\n\n```bash\n# Create bucket in us-central1 (required region)\ngsutil mb -l us-central1 gs://your-batch-bucket\n\n# Verify bucket location is us-central1\ngsutil ls -L -b gs://your-batch-bucket | grep \"Location\"\n```\n\nSee `references/gcs-setup.md` for complete setup guide.\n\n## Quick Start\n\n### Standard Gemini API (API Key)\n\nUses the Gemini File API for input. Results returned via `batch_job.dest.file_name`.\n\n```python\nfrom google import genai\n\nclient = genai.Client()  # Uses GOOGLE_API_KEY env var\n\n# Upload JSONL to File API\nuploaded = client.files.upload(\n    file=\"requests.jsonl\",\n    config={\"mime_type\": \"application/jsonl\"}\n)\n\n# Submit batch job\njob = client.batches.create(\n    model=\"gemini-2.5-flash-lite\",\n    src=uploaded.name,  # \"files/...\" URI\n    config={\"display_name\": \"my-batch-job\"}\n)\n\n# Results available at job.dest.file_name after completion\n```\n\n### Vertex AI (Recommended for GCS workflows)\n\nUses GCS URIs directly. Supports `dest=` parameter for output location.\n\n```python\nfrom google import genai\n\n# Use Vertex AI with ADC (not API key)\nclient = genai.Client(\n    vertexai=True,\n    project=\"your-project-id\",\n    location=\"us-central1\"\n)\n\n# Submit batch job with GCS paths\njob = client.batches.create(\n    model=\"gemini-2.5-flash-lite\",\n    src=\"gs://bucket/requests.jsonl\",   # GCS input\n    dest=\"gs://bucket/outputs/\"          # GCS output (Vertex AI only!)\n)\n```\n\n**Key difference:** Standard API uses File API (`files/...`), Vertex AI uses GCS (`gs://...`) with explicit `dest=` parameter.\n\n## Core Workflow\n\n**Standard API:**\n1. **Create JSONL** request file with prompts\n2. **Upload JSONL** to File API via `client.files.upload()`\n3. **Submit batch job** via `client.batches.create(src=uploaded.name)`\n4. **Poll for completion** (jobs expire after 24 hours)\n5. **Download results** from `job.dest.file_name`\n\n**Vertex AI:**\n1. **Upload files** to GCS bucket (us-central1 region required)\n2. **Create JSONL** request file with document URIs and prompts\n3. **Submit batch job** via `client.batches.create(src=..., dest=...)`\n4. **Poll for completion** (jobs expire after 24 hours)\n5. **Download and parse** results from GCS output URI\n6. **Handle failures** gracefully (partial failures are common)\n\n## IRON LAW: Metadata and API Call Structure\n\n**YOU MUST USE FLAT PRIMITIVES FOR METADATA. YOU MUST USE SIMPLE STRINGS FOR API PARAMETERS.**\n\n### Rule 1: Metadata Structure\n\n```\nCORRECT ✓\n\"metadata\": {\n    \"request_id\": \"icon_123\",        # String\n    \"file_name\": \"copy.svg\",         # String\n    \"file_size\": 1024                # Integer\n}\n\nWRONG ✗\n\"metadata\": {\n    \"request_id\": \"icon_123\",\n    \"file_info\": {                   # ← NESTED OBJECT FAILS!\n        \"name\": \"copy.svg\",\n        \"size\": 1024\n    }\n}\n\nWORKAROUND (if complex data needed)\n\"metadata\": {\n    \"request_id\": \"icon_123\",\n    \"file_info\": json.dumps({\"name\": \"copy.svg\", \"size\": 1024})  # JSON string OK\n}\n```\n\n**Why:** Vertex AI stores metadata in BigQuery-compatible format. BigQuery doesn't support nested types. Violation causes: `\"metadata\" in the specified input data is of unsupported type.`\n\n### Rule 2: API Call Structure\n\n**Standard API (File API):**\n```python\nCORRECT ✓\njob = client.batches.create(\n    model=\"gemini-2.5-flash-lite\",\n    src=uploaded_file.name,               # \"files/...\" URI from File API\n    config={\"display_name\": \"my-job\"}     # Just a dict\n)\n# Results at: job.dest.file_name (after completion)\n```\n\n**Vertex AI (GCS):**\n```python\nCORRECT ✓\njob = client.batches.create(\n    model=\"gemini-2.5-flash-lite\",\n    src=\"gs://bucket/input.jsonl\",        # GCS URI\n    dest=\"gs://bucket/output/\",           # GCS output (VERTEX AI ONLY!)\n    config={\"display_name\": \"my-job\"}\n)\n\nWRONG ✗\njob = client.batches.create(\n    model=\"gemini-2.5-flash-lite\",\n    src=\"gs://bucket/input.jsonl\",\n    destination=\"gs://bucket/output/\",    # ← WRONG PARAM NAME! Use dest=\n)\n\nWRONG ✗\njob = client.batches.create(\n    model=\"gemini-2.5-flash-lite\",\n    src=\"gs://bucket/input.jsonl\",\n    config=types.CreateBatchJobConfig(    # ← DON'T INSTANTIATE TYPES!\n        dest=\"gs://bucket/output/\"\n    )\n)\n```\n\n**Why:**\n- Standard API: Uses File API for input, outputs to managed file location\n- Vertex AI: Uses GCS URIs, supports `dest=` for output location\n- Parameter is `dest=` (not destination). Config is a plain dict (not a type instance).\n\n### Rationalization Table - STOP If You Catch Yourself Thinking:\n\n| Excuse | Reality | Do Instead |\n|--------|---------|------------|\n| \"Nested metadata is cleaner\" | Your code will fail silently with cryptic errors | Flatten or use `json.dumps()` |\n| \"I'll use `dest=` with Standard API\" | Standard API doesn't support `dest=`; it's Vertex AI only | Use File API pattern for Standard API |\n| \"I'll try `destination=` parameter\" | You'll get a TypeError; parameter doesn't exist | Use `dest=` (Vertex AI only) |\n| \"I should use `CreateBatchJobConfig`\" | You're confusing internal typing with API calls | Pass plain dict to `config=` |\n| \"Other APIs accept nested objects\" | Your assumption breaks here; it's BigQuery-backed | Follow the examples |\n| \"I'll fix it if it breaks\" | Your job fails 5 minutes after submission | Get it right the first time |\n\n### Pre-Submission Validation\n\n```python\n# Add this check BEFORE submitting batch job\ndef validate_metadata(metadata: dict):\n    \"\"\"Ensure metadata contains only primitive types.\"\"\"\n    for key, value in metadata.items():\n        if isinstance(value, (dict, list)):\n            raise ValueError(\n                f\"Metadata '{key}' is {type(value).__name__}. \"\n                f\"Only primitives (str, int, float, bool) allowed. \"\n                f\"Use json.dumps() for complex data.\"\n            )\n        if not isinstance(value, (str, int, float, bool, type(None))):\n            raise ValueError(f\"Unsupported type for '{key}': {type(value)}\")\n\n# Validate all requests before submission:\nfor request in batch_requests:\n    validate_metadata(request[\"metadata\"])\n```\n\n**Enforcement:** Jobs will fail if metadata contains nested objects. There is no workaround for this requirement.\n\n## Key Gotchas\n\n| Issue | Solution |\n|-------|----------|\n| **Nested metadata fails** | **Use flat primitives or `json.dumps()` for complex data** |\n| **TypeError: unexpected keyword** | **Use `dest=` not `destination=` (Vertex AI only)** |\n| **Mixing API patterns** | **Standard API: File API + no dest. Vertex AI: GCS + dest** |\n| Auth errors with Vertex AI | Run `gcloud auth application-default login` |\n| vertexai=True requires ADC | API key is ignored with vertexai=True |\n| Missing aiplatform API | Run `gcloud services enable aiplatform.googleapis.com` |\n| Region mismatch (Vertex) | Use `us-central1` bucket only |\n| Wrong URI format (Vertex) | Use `gs://` not `https://` |\n| Invalid JSONL | Use `scripts/validate_jsonl.py` |\n| Image batch: inline data | Use `fileData.fileUri` for batch, not inline |\n| Duplicate IDs | Hash file content + prompt for unique IDs |\n| Large PDFs fail | Split at 50 pages / 50MB max |\n| JSON parsing fails | Use robust extraction (see gotchas.md) |\n| Output not found (Vertex) | Output URI is prefix, not file path |\n\n**Top 3 mistakes** (bolded above):\n1. Using nested objects in metadata instead of flat primitives\n2. Mixing Standard API and Vertex AI patterns\n3. Using `destination=` instead of `dest=` (Vertex AI)\n\nSee `references/gotchas.md` for detailed solutions (now with Gotchas 10 & 11).\n\n## Rate Limits\n\n| Limit | Value |\n|-------|-------|\n| Max requests per JSONL | 10,000 |\n| Max concurrent jobs | 10 |\n| Max job size | 100MB |\n| Job expiration | 24 hours |\n\n## Recommended Models\n\n| Model | Use Case | Cost |\n|-------|----------|------|\n| `gemini-2.5-flash-lite` | Most batch jobs | Lowest |\n| `gemini-2.5-flash` | Complex extraction | Medium |\n| `gemini-2.5-pro` | Highest accuracy | Highest |\n\n## Additional Resources\n\n### References\n- `references/gcs-setup.md` - **NEW:** Complete GCS and Vertex AI setup guide\n- `references/gotchas.md` - 9 critical production gotchas (updated auth section)\n- `references/best-practices.md` - Idempotent IDs, state tracking, validation\n- `references/troubleshooting.md` - Common errors and debugging\n- `references/vertex-ai.md` - Enterprise alternative with comparison\n- `references/cli-reference.md` - gsutil and gcloud commands\n\n### Examples\n- `examples/icon_batch_vision.py` - **NEW:** Batch vision analysis with Vertex AI\n- `examples/batch_processor.py` - Complete GeminiBatchProcessor class\n- `examples/pipeline_template.py` - Customizable pipeline template\n\n### Scripts\n- `scripts/validate_jsonl.py` - Validate JSONL before submission\n- `scripts/test_single.py` - Test single request before batch\n\n## External Documentation\n\n- [Gemini Batch API Guide](https://ai.google.dev/gemini-api/docs/batch)\n- [Google Cloud Storage](https://cloud.google.com/python/docs/reference/storage/latest)\n- [Vertex AI Batch Prediction](https://cloud.google.com/vertex-ai/docs/predictions/batch-predictions)\n\n## Date Awareness\n\n**Pattern from oh-my-opencode:** Gemini API and documentation evolve rapidly.\n\nCurrent date: Use `datetime.now()` for:\n- API version checking\n- Model availability (\"gemini-2.5-flash-lite available as of Dec 2024\")\n- Documentation freshness validation\n\nFor API features or model names with uncertainty, verify against current date and check latest Gemini API documentation.\n",
        "skills/gemini-batch/references/best-practices.md": "# Best Practices\n\n## Contents\n\n- [1. Implement Idempotent Request IDs](#1-implement-idempotent-request-ids)\n- [2. Track Processing State](#2-track-processing-state)\n- [3. Validate Before Submission](#3-validate-before-submission)\n- [4. Handle Partial Failures Gracefully](#4-handle-partial-failures-gracefully)\n- [5. Use Appropriate Batch Sizes](#5-use-appropriate-batch-sizes)\n\nProduction-tested patterns for reliable Gemini Batch API usage.\n\n---\n\n## 1. Implement Idempotent Request IDs\n\nUse deterministic request IDs based on file content and prompt version to enable:\n- Safe retries without duplicate processing\n- Result caching and deduplication\n- Incremental processing of new files only\n\n```python\ndef get_idempotent_request_id(file_path: str, prompt: str) -> str:\n    \"\"\"Generate idempotent request ID.\"\"\"\n    with open(file_path, 'rb') as f:\n        content_hash = hashlib.sha256(f.read()).hexdigest()[:12]\n    prompt_hash = hashlib.sha256(prompt.encode()).hexdigest()[:8]\n    return f\"{Path(file_path).stem}_{content_hash}_{prompt_hash}\"\n```\n\n---\n\n## 2. Track Processing State\n\nMaintain a manifest of processed files to avoid reprocessing:\n\n```python\nimport sqlite3\n\nclass ProcessingTracker:\n    \"\"\"Track batch processing state.\"\"\"\n\n    def __init__(self, db_path: str = \"batch_state.db\"):\n        self.conn = sqlite3.connect(db_path)\n        self.conn.execute(\"\"\"\n            CREATE TABLE IF NOT EXISTS processed (\n                request_id TEXT PRIMARY KEY,\n                file_path TEXT,\n                job_name TEXT,\n                status TEXT,\n                result_json TEXT,\n                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n            )\n        \"\"\")\n\n    def mark_submitted(self, request_id: str, file_path: str, job_name: str):\n        self.conn.execute(\n            \"INSERT OR REPLACE INTO processed (request_id, file_path, job_name, status) VALUES (?, ?, ?, ?)\",\n            (request_id, file_path, job_name, \"submitted\")\n        )\n        self.conn.commit()\n\n    def mark_completed(self, request_id: str, result: dict):\n        self.conn.execute(\n            \"UPDATE processed SET status = ?, result_json = ? WHERE request_id = ?\",\n            (\"completed\", json.dumps(result), request_id)\n        )\n        self.conn.commit()\n\n    def get_pending(self) -> list[str]:\n        cursor = self.conn.execute(\n            \"SELECT request_id FROM processed WHERE status = 'submitted'\"\n        )\n        return [row[0] for row in cursor]\n\n    def is_processed(self, request_id: str) -> bool:\n        cursor = self.conn.execute(\n            \"SELECT 1 FROM processed WHERE request_id = ? AND status = 'completed'\",\n            (request_id,)\n        )\n        return cursor.fetchone() is not None\n```\n\n---\n\n## 3. Validate Before Submission\n\nAlways validate JSONL files before submitting to catch errors early:\n\n```python\ndef validate_batch_file(jsonl_path: str) -> tuple[bool, list[str]]:\n    \"\"\"Validate batch JSONL file.\n\n    Returns:\n        Tuple of (is_valid, list of error messages)\n    \"\"\"\n    errors = []\n    request_ids = set()\n\n    with open(jsonl_path, 'r') as f:\n        for line_num, line in enumerate(f, 1):\n            line = line.strip()\n\n            # Check for empty lines\n            if not line:\n                errors.append(f\"Line {line_num}: Empty line\")\n                continue\n\n            # Parse JSON\n            try:\n                data = json.loads(line)\n            except json.JSONDecodeError as e:\n                errors.append(f\"Line {line_num}: Invalid JSON - {e}\")\n                continue\n\n            # Check required fields\n            if \"request\" not in data:\n                errors.append(f\"Line {line_num}: Missing 'request' field\")\n                continue\n\n            request = data[\"request\"]\n            if \"contents\" not in request:\n                errors.append(f\"Line {line_num}: Missing 'contents' in request\")\n\n            contents = request.get(\"contents\", [])\n            if not contents or contents[0].get(\"role\") != \"user\":\n                errors.append(f\"Line {line_num}: First content must have role='user'\")\n\n            # Check for file URI format\n            parts = contents[0].get(\"parts\", []) if contents else []\n            for part in parts:\n                if \"fileData\" in part:\n                    uri = part[\"fileData\"].get(\"fileUri\", \"\")\n                    if not uri.startswith(\"gs://\"):\n                        errors.append(f\"Line {line_num}: fileUri must start with 'gs://'\")\n\n            # Check request ID uniqueness\n            request_id = data.get(\"metadata\", {}).get(\"request_id\")\n            if request_id:\n                if request_id in request_ids:\n                    errors.append(f\"Line {line_num}: Duplicate request_id '{request_id}'\")\n                request_ids.add(request_id)\n            else:\n                errors.append(f\"Line {line_num}: Missing request_id in metadata\")\n\n    return len(errors) == 0, errors\n```\n\n---\n\n## 4. Handle Partial Failures Gracefully\n\nSome requests may fail while others succeed. Always handle mixed results:\n\n```python\ndef process_results_with_retry(\n    results: list[dict],\n    retry_callback: callable = None\n) -> tuple[list[dict], list[dict]]:\n    \"\"\"Separate successful and failed results.\n\n    Args:\n        results: List of parsed results\n        retry_callback: Optional callback for failed items\n\n    Returns:\n        Tuple of (successful_results, failed_results)\n    \"\"\"\n    successful = []\n    failed = []\n\n    for result in results:\n        if result.get(\"success\") and result.get(\"parsed_data\"):\n            successful.append(result)\n        else:\n            failed.append(result)\n            if retry_callback:\n                retry_callback(result)\n\n    print(f\"Results: {len(successful)} successful, {len(failed)} failed\")\n\n    return successful, failed\n```\n\n---\n\n## 5. Use Appropriate Batch Sizes\n\nBalance between job overhead and failure isolation:\n\n| Scenario | Recommended Batch Size |\n|----------|------------------------|\n| Testing/Development | 10-50 requests |\n| Production (small files) | 1,000-5,000 requests |\n| Production (large PDFs) | 100-500 requests |\n| Critical data | 100-200 requests |\n\n```python\ndef optimal_batch_size(\n    file_count: int,\n    avg_file_size_mb: float,\n    criticality: str = \"normal\"\n) -> int:\n    \"\"\"Calculate optimal batch size.\n\n    Args:\n        file_count: Total number of files\n        avg_file_size_mb: Average file size in MB\n        criticality: \"low\", \"normal\", or \"high\"\n\n    Returns:\n        Recommended batch size\n    \"\"\"\n    # Base limits\n    max_size = 10000  # API limit\n\n    # Adjust for file size\n    if avg_file_size_mb > 10:\n        max_size = min(max_size, 500)\n    elif avg_file_size_mb > 5:\n        max_size = min(max_size, 1000)\n\n    # Adjust for criticality\n    criticality_factors = {\"low\": 1.0, \"normal\": 0.5, \"high\": 0.2}\n    factor = criticality_factors.get(criticality, 0.5)\n    max_size = int(max_size * factor)\n\n    # Don't create too many small batches\n    min_batches = max(1, file_count // max_size)\n    optimal = file_count // min_batches\n\n    return min(optimal, max_size)\n```\n",
        "skills/gemini-batch/references/cli-reference.md": "# CLI Commands Reference\n\nQuick reference for command-line operations with Gemini Batch API.\n\n## GCS Operations\n\n```bash\n# Check GCS bucket region\ngsutil ls -L -b gs://your-bucket | grep \"Location\"\n\n# Create bucket in correct region\ngsutil mb -l us-central1 gs://your-batch-bucket\n\n# Upload files to GCS\ngsutil -m cp -r ./documents/* gs://your-bucket/documents/\n\n# Download results\ngsutil -m cp -r gs://your-bucket/batch_outputs/* ./results/\n```\n\n## Job Management\n\n```bash\n# List batch jobs (via gcloud)\ngcloud ai batch-predictions list --region=us-central1\n\n# View job details\ngcloud ai batch-predictions describe JOB_ID --region=us-central1\n```\n\n## JSONL Validation\n\n```bash\n# Count lines in JSONL\nwc -l batch_requests.jsonl\n\n# Validate JSONL syntax\npython -c \"\nimport json\nimport sys\nwith open('batch_requests.jsonl') as f:\n    for i, line in enumerate(f, 1):\n        try:\n            json.loads(line)\n        except:\n            print(f'Error line {i}')\n            sys.exit(1)\nprint('Valid JSONL')\n\"\n```\n\n## Results Analysis\n\n```bash\n# Quick stats on results\npython -c \"\nimport json\nfrom collections import Counter\nresults = []\nwith open('output.jsonl') as f:\n    for line in f:\n        data = json.loads(line)\n        resp = data.get('response', {})\n        candidates = resp.get('candidates', [])\n        if candidates:\n            reason = candidates[0].get('finishReason', 'UNKNOWN')\n        else:\n            reason = 'NO_CANDIDATES'\n        results.append(reason)\nfor reason, count in Counter(results).items():\n    print(f'{reason}: {count}')\n\"\n```\n\n## GCS Organization\n\nRecommended bucket structure:\n\n```\ngs://your-batch-bucket/\n├── documents/           # Uploaded source documents\n│   ├── batch_001/\n│   │   ├── doc1.pdf\n│   │   └── doc2.pdf\n│   └── batch_002/\n├── batch_requests/      # JSONL request files\n│   ├── batch_001.jsonl\n│   └── batch_002.jsonl\n└── batch_outputs/       # API output files\n    ├── batch_001/\n    │   └── {job_id}_output.jsonl\n    └── batch_002/\n```\n",
        "skills/gemini-batch/references/gcs-setup.md": "# GCS Bucket Setup for Gemini Batch API\r\n\r\nComplete guide to setting up Google Cloud Storage for batch processing.\r\n\r\n## Prerequisites\r\n\r\nInstall gcloud SDK:\r\n```bash\r\n# macOS (via Homebrew)\r\nbrew install google-cloud-sdk\r\n\r\n# Linux (via package manager)\r\ncurl https://sdk.cloud.google.com | bash\r\nexec -l $SHELL\r\n\r\n# Verify installation\r\ngcloud --version\r\n```\r\n\r\n## Authentication\r\n\r\n### Step 1: User Authentication\r\n\r\n```bash\r\n# Login to your Google account\r\ngcloud auth login\r\n\r\n# Set project\r\ngcloud config set project YOUR_PROJECT_ID\r\n\r\n# Verify current project\r\ngcloud config get-value project\r\n```\r\n\r\n### Step 2: Application Default Credentials (ADC)\r\n\r\n**CRITICAL:** Vertex AI requires ADC, not just user credentials.\r\n\r\n```bash\r\n# Set up ADC for local development\r\ngcloud auth application-default login\r\n\r\n# This creates credentials at:\r\n# ~/.config/gcloud/application_default_credentials.json\r\n```\r\n\r\n**Why both?**\r\n- `gcloud auth login`: For gcloud CLI commands (gsutil, gcloud services)\r\n- `gcloud auth application-default login`: For Python libraries (google-generativeai, vertexai)\r\n\r\n## Enable Required APIs\r\n\r\n```bash\r\n# Enable Cloud Storage API\r\ngcloud services enable storage-api.googleapis.com\r\n\r\n# Enable Vertex AI API (required for vertexai=True)\r\ngcloud services enable aiplatform.googleapis.com\r\n\r\n# Verify enabled services\r\ngcloud services list --enabled | grep -E \"(storage|aiplatform)\"\r\n```\r\n\r\n## Create GCS Bucket\r\n\r\n### us-central1 Requirement\r\n\r\n**CRITICAL:** Gemini Batch API only works with buckets in `us-central1`.\r\n\r\n```bash\r\n# Create bucket in correct region\r\ngsutil mb -l us-central1 gs://your-batch-bucket\r\n\r\n# Set uniform bucket-level access (recommended)\r\ngsutil uniformbucketlevelaccess set on gs://your-batch-bucket\r\n\r\n# Verify bucket location\r\ngsutil ls -L -b gs://your-batch-bucket | grep \"Location\"\r\n# Should show: Location constraint: US-CENTRAL1\r\n```\r\n\r\n### Why us-central1?\r\n\r\n- Batch API service runs in us-central1\r\n- Cross-region access causes latency and errors\r\n- Moving existing buckets is not supported (must copy data)\r\n\r\n## Upload Files to GCS\r\n\r\n### Basic Upload\r\n\r\n```bash\r\n# Upload single file\r\ngsutil cp local_file.pdf gs://your-batch-bucket/documents/\r\n\r\n# Upload directory (recursive)\r\ngsutil -m cp -r ./documents/* gs://your-batch-bucket/documents/\r\n\r\n# Upload with parallelism (-m flag for faster uploads)\r\ngsutil -m cp *.pdf gs://your-batch-bucket/documents/\r\n```\r\n\r\n### Upload Options\r\n\r\n```bash\r\n# Set content type explicitly\r\ngsutil -h \"Content-Type:application/pdf\" cp file.pdf gs://bucket/\r\n\r\n# Upload with public-read ACL (not recommended for sensitive data)\r\ngsutil cp -a public-read file.pdf gs://bucket/\r\n\r\n# Resume interrupted uploads automatically (default behavior)\r\ngsutil cp large_file.pdf gs://bucket/\r\n```\r\n\r\n### Check Upload Status\r\n\r\n```bash\r\n# List files in bucket\r\ngsutil ls gs://your-batch-bucket/documents/\r\n\r\n# Get file details\r\ngsutil ls -l gs://your-batch-bucket/documents/file.pdf\r\n\r\n# Check total size of directory\r\ngsutil du -s gs://your-batch-bucket/documents/\r\n```\r\n\r\n## Bucket Permissions\r\n\r\n### Service Account Access (Production)\r\n\r\nIf using service account authentication:\r\n\r\n```bash\r\n# Grant storage admin to service account\r\ngsutil iam ch serviceAccount:YOUR-SA@PROJECT.iam.gserviceaccount.com:roles/storage.objectAdmin \\\r\n  gs://your-batch-bucket\r\n\r\n# For Vertex AI, also grant aiplatform.user\r\ngcloud projects add-iam-policy-binding YOUR_PROJECT_ID \\\r\n  --member=\"serviceAccount:YOUR-SA@PROJECT.iam.gserviceaccount.com\" \\\r\n  --role=\"roles/aiplatform.user\"\r\n```\r\n\r\n### User Account Access (Development)\r\n\r\nFor ADC with your user account:\r\n\r\n```bash\r\n# Grant yourself storage admin\r\ngsutil iam ch user:your-email@gmail.com:roles/storage.objectAdmin \\\r\n  gs://your-batch-bucket\r\n\r\n# Verify permissions\r\ngsutil iam get gs://your-batch-bucket\r\n```\r\n\r\n### Minimum Permissions\r\n\r\nFor batch processing, the account needs:\r\n- `storage.objects.create` - Upload input files\r\n- `storage.objects.get` - Read input files during processing\r\n- `storage.objects.list` - List output files\r\n- `storage.buckets.get` - Verify bucket location\r\n\r\n## Python Integration\r\n\r\n### Upload Files with google-cloud-storage\r\n\r\n```python\r\nfrom google.cloud import storage\r\nfrom pathlib import Path\r\n\r\ndef upload_to_gcs(local_path: str, bucket_name: str, gcs_path: str) -> str:\r\n    \"\"\"Upload file to GCS.\r\n\r\n    Args:\r\n        local_path: Local file path\r\n        bucket_name: GCS bucket name\r\n        gcs_path: Destination path in bucket (e.g., \"documents/file.pdf\")\r\n\r\n    Returns:\r\n        GCS URI (gs://bucket/path)\r\n    \"\"\"\r\n    client = storage.Client()\r\n    bucket = client.bucket(bucket_name)\r\n    blob = bucket.blob(gcs_path)\r\n\r\n    blob.upload_from_filename(local_path)\r\n\r\n    return f\"gs://{bucket_name}/{gcs_path}\"\r\n\r\n\r\ndef upload_directory(local_dir: str, bucket_name: str, gcs_prefix: str = \"documents\") -> list[str]:\r\n    \"\"\"Upload all files from directory.\r\n\r\n    Args:\r\n        local_dir: Local directory path\r\n        bucket_name: GCS bucket name\r\n        gcs_prefix: Prefix for GCS paths\r\n\r\n    Returns:\r\n        List of GCS URIs\r\n    \"\"\"\r\n    client = storage.Client()\r\n    bucket = client.bucket(bucket_name)\r\n\r\n    uris = []\r\n    for file_path in Path(local_dir).rglob(\"*\"):\r\n        if file_path.is_file():\r\n            gcs_path = f\"{gcs_prefix}/{file_path.name}\"\r\n            blob = bucket.blob(gcs_path)\r\n            blob.upload_from_filename(str(file_path))\r\n\r\n            uri = f\"gs://{bucket_name}/{gcs_path}\"\r\n            uris.append(uri)\r\n            print(f\"Uploaded: {file_path.name} -> {uri}\")\r\n\r\n    return uris\r\n```\r\n\r\n### Verify Bucket Region\r\n\r\n```python\r\nfrom google.cloud import storage\r\n\r\ndef verify_bucket_region(bucket_name: str) -> bool:\r\n    \"\"\"Verify bucket is in us-central1.\r\n\r\n    Args:\r\n        bucket_name: GCS bucket name\r\n\r\n    Returns:\r\n        True if in us-central1, False otherwise\r\n    \"\"\"\r\n    client = storage.Client()\r\n    bucket = client.bucket(bucket_name)\r\n    bucket.reload()\r\n\r\n    location = bucket.location.lower()\r\n    print(f\"Bucket location: {location}\")\r\n\r\n    if location != \"us-central1\":\r\n        print(f\"❌ ERROR: Bucket must be in us-central1, not {location}\")\r\n        return False\r\n\r\n    print(\"✓ Bucket is in us-central1\")\r\n    return True\r\n```\r\n\r\n## Troubleshooting\r\n\r\n### Permission Denied Errors\r\n\r\n```bash\r\n# Check current credentials\r\ngcloud auth list\r\n\r\n# Re-authenticate if needed\r\ngcloud auth application-default login\r\n\r\n# Verify project access\r\ngcloud projects get-iam-policy YOUR_PROJECT_ID \\\r\n  --flatten=\"bindings[].members\" \\\r\n  --filter=\"bindings.members:user:YOUR_EMAIL\"\r\n```\r\n\r\n### Bucket Access Errors\r\n\r\n```bash\r\n# Test bucket access\r\ngsutil ls gs://your-batch-bucket\r\n\r\n# If error, check IAM bindings\r\ngsutil iam get gs://your-batch-bucket\r\n```\r\n\r\n### Wrong Region Errors\r\n\r\n```bash\r\n# Check bucket location\r\ngsutil ls -L -b gs://your-batch-bucket | grep \"Location\"\r\n\r\n# If wrong region, must create new bucket and copy data\r\ngsutil mb -l us-central1 gs://new-batch-bucket\r\ngsutil -m cp -r gs://old-bucket/* gs://new-batch-bucket/\r\n```\r\n\r\n### API Not Enabled\r\n\r\n```bash\r\n# Check if Vertex AI API is enabled\r\ngcloud services list --enabled | grep aiplatform\r\n\r\n# If not enabled:\r\ngcloud services enable aiplatform.googleapis.com\r\n```\r\n\r\n## Best Practices\r\n\r\n1. **Use uniform bucket-level access** for simpler permission management\r\n2. **Enable versioning** for production buckets to recover deleted files\r\n3. **Set lifecycle policies** to auto-delete old batch files\r\n4. **Use `-m` flag** with gsutil for parallel uploads (faster)\r\n5. **Verify bucket region** before uploading large datasets\r\n6. **Use service accounts** for production, ADC for development\r\n7. **Keep bucket in same project** as Vertex AI API for simplicity\r\n\r\n## Lifecycle Management\r\n\r\nAuto-delete old batch files to save costs:\r\n\r\n```bash\r\n# Create lifecycle config (lifecycle.json)\r\ncat > lifecycle.json <<EOF\r\n{\r\n  \"lifecycle\": {\r\n    \"rule\": [\r\n      {\r\n        \"action\": {\"type\": \"Delete\"},\r\n        \"condition\": {\r\n          \"age\": 30,\r\n          \"matchesPrefix\": [\"batch_outputs/\", \"batch_requests/\"]\r\n        }\r\n      }\r\n    ]\r\n  }\r\n}\r\nEOF\r\n\r\n# Apply lifecycle policy\r\ngsutil lifecycle set lifecycle.json gs://your-batch-bucket\r\n\r\n# Verify policy\r\ngsutil lifecycle get gs://your-batch-bucket\r\n```\r\n\r\n## Cost Optimization\r\n\r\nStorage costs for batch processing:\r\n\r\n- **Storage:** $0.020/GB/month (us-central1)\r\n- **Operations:** Free (Class A: 5K free per month)\r\n- **Egress:** Free within us-central1\r\n\r\nTips:\r\n- Delete input files after successful processing\r\n- Use lifecycle policies for automatic cleanup\r\n- Keep buckets in us-central1 to avoid cross-region transfer costs\r\n- Use `gsutil -m` for faster uploads (parallelism)\r\n\r\n## Resources\r\n\r\n- [gsutil Tool Documentation](https://cloud.google.com/storage/docs/gsutil)\r\n- [GCS Locations](https://cloud.google.com/storage/docs/locations)\r\n- [IAM Permissions](https://cloud.google.com/storage/docs/access-control/iam-permissions)\r\n- [Lifecycle Management](https://cloud.google.com/storage/docs/lifecycle)\r\n",
        "skills/gemini-batch/references/gotchas.md": "# Critical Gotchas from Production\n\n## Contents\n\n- [Gotcha 1: GCS Bucket Must Be in us-central1](#gotcha-1-gcs-bucket-must-be-in-us-central1)\n- [Gotcha 2: File URIs Must Use gs:// Protocol](#gotcha-2-file-uris-must-use-gs-protocol)\n- [Gotcha 3: JSONL Format is Strict](#gotcha-3-jsonl-format-is-strict)\n- [Gotcha 4: Request ID Must Be Unique Per Job](#gotcha-4-request-id-must-be-unique-per-job)\n- [Gotcha 5: Large PDFs May Timeout or Fail](#gotcha-5-large-pdfs-may-timeout-or-fail)\n- [Gotcha 6: API Key vs Service Account Authentication](#gotcha-6-api-key-vs-service-account-authentication)\n- [Gotcha 7: Output URI Must Be a Prefix, Not a File](#gotcha-7-output-uri-must-be-a-prefix-not-a-file)\n- [Gotcha 8: Rate Limits and Quotas](#gotcha-8-rate-limits-and-quotas)\n- [Gotcha 9: JSON Response Parsing Requires Careful Handling](#gotcha-9-json-response-parsing-requires-careful-handling)\n- [Gotcha 10: Metadata Must Be Flat Primitives](#gotcha-10-metadata-must-be-flat-primitives)\n- [Gotcha 11: API Parameter Names (dest= not destination=)](#gotcha-11-api-parameter-names-dest-not-destination)\n\nProduction lessons learned from real-world Gemini Batch API deployments.\n\n---\n\n## Gotcha 1: GCS Bucket Must Be in us-central1\n\n**Problem:** Batch API only works with buckets in `us-central1` region.\n\n**Symptom:** Job submission fails with region mismatch error.\n\n**Solution:**\n```bash\n# Create bucket in correct region\ngsutil mb -l us-central1 gs://your-batch-bucket\n\n# Or check existing bucket location\ngsutil ls -L -b gs://your-bucket | grep \"Location\"\n```\n\n**Why:** The Batch API service runs in us-central1 and cannot access buckets in other regions efficiently.\n\n---\n\n## Gotcha 2: File URIs Must Use gs:// Protocol\n\n**Problem:** The API expects GCS URIs, not HTTPS URLs.\n\n**Wrong:**\n```python\n\"fileUri\": \"https://storage.googleapis.com/bucket/file.pdf\"\n```\n\n**Correct:**\n```python\n\"fileUri\": \"gs://bucket/file.pdf\"\n```\n\n**Why:** The batch service accesses files directly through GCS internal APIs, not HTTP.\n\n---\n\n## Gotcha 3: JSONL Format is Strict\n\n**Problem:** Each line must be valid JSON with exact schema.\n\n**Required Schema:**\n```json\n{\n  \"request\": {\n    \"contents\": [\n      {\n        \"role\": \"user\",\n        \"parts\": [...]\n      }\n    ]\n  },\n  \"metadata\": {\n    \"request_id\": \"unique-id\"\n  }\n}\n```\n\n**Common Mistakes:**\n- Missing `role` field in contents\n- Using `content` instead of `contents` (must be plural)\n- Trailing commas in JSON\n- Empty lines in JSONL file\n\n**Validation:**\n```python\ndef validate_jsonl(path: str) -> bool:\n    \"\"\"Validate JSONL file format.\"\"\"\n    with open(path, 'r') as f:\n        for i, line in enumerate(f, 1):\n            line = line.strip()\n            if not line:\n                print(f\"Warning: Empty line at {i}\")\n                continue\n            try:\n                data = json.loads(line)\n                assert \"request\" in data, \"Missing 'request' key\"\n                assert \"contents\" in data[\"request\"], \"Missing 'contents' in request\"\n                assert data[\"request\"][\"contents\"][0].get(\"role\") == \"user\", \"Missing role\"\n            except (json.JSONDecodeError, AssertionError) as e:\n                print(f\"Error at line {i}: {e}\")\n                return False\n    return True\n```\n\n---\n\n## Gotcha 4: Request ID Must Be Unique Per Job\n\n**Problem:** Duplicate request IDs cause silent overwrites or errors.\n\n**Solution:**\n```python\nimport hashlib\n\ndef generate_request_id(file_path: str, prompt_hash: str = None) -> str:\n    \"\"\"Generate deterministic unique request ID.\n\n    Args:\n        file_path: Path to source file\n        prompt_hash: Optional hash of prompt for versioning\n\n    Returns:\n        Unique request ID\n    \"\"\"\n    # Use file content hash for deduplication\n    with open(file_path, 'rb') as f:\n        file_hash = hashlib.md5(f.read()).hexdigest()[:8]\n\n    base_name = Path(file_path).stem\n\n    if prompt_hash:\n        return f\"{base_name}_{file_hash}_{prompt_hash}\"\n    return f\"{base_name}_{file_hash}\"\n```\n\n---\n\n## Gotcha 5: Large PDFs May Timeout or Fail\n\n**Problem:** PDFs over ~100 pages or 50MB may fail silently.\n\n**Symptoms:**\n- Empty response in results\n- `FINISH_REASON_UNSPECIFIED` or `FINISH_REASON_MAX_TOKENS`\n- Job succeeds but some entries have errors\n\n**Solutions:**\n```python\ndef split_pdf(input_path: str, max_pages: int = 50) -> list[str]:\n    \"\"\"Split large PDF into smaller chunks.\n\n    Args:\n        input_path: Path to input PDF\n        max_pages: Maximum pages per chunk\n\n    Returns:\n        List of paths to split PDFs\n    \"\"\"\n    from pypdf import PdfReader, PdfWriter\n\n    reader = PdfReader(input_path)\n    total_pages = len(reader.pages)\n\n    if total_pages <= max_pages:\n        return [input_path]\n\n    output_paths = []\n    for start in range(0, total_pages, max_pages):\n        end = min(start + max_pages, total_pages)\n        writer = PdfWriter()\n\n        for page_num in range(start, end):\n            writer.add_page(reader.pages[page_num])\n\n        output_path = input_path.replace('.pdf', f'_part{start//max_pages + 1}.pdf')\n        with open(output_path, 'wb') as f:\n            writer.write(f)\n        output_paths.append(output_path)\n\n    return output_paths\n\n\ndef check_pdf_size(path: str, max_mb: int = 50) -> bool:\n    \"\"\"Check if PDF is within size limits.\"\"\"\n    size_mb = Path(path).stat().st_size / (1024 * 1024)\n    return size_mb <= max_mb\n```\n\n---\n\n## Gotcha 6: API Key vs Application Default Credentials (ADC)\n\n**Problem:** Vertex AI requires ADC authentication, not just API keys.\n\n**Symptom:** `DefaultCredentialsError: Could not automatically determine credentials`\n\n**Two Authentication Modes:**\n\n### Standard Gemini API (API Key)\n\n```python\nimport google.generativeai as genai\n\n# Simple API key auth\ngenai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n\n# Works for standard batch API\nclient = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n```\n\n### Vertex AI (ADC Required)\n\n```python\nimport google.generativeai as genai\n\n# CRITICAL: vertexai=True requires ADC, not API key\nclient = genai.Client(\n    vertexai=True,\n    project=\"your-project-id\",\n    location=\"us-central1\"\n)\n\n# API key is IGNORED when vertexai=True\n```\n\n**Setup ADC:**\n\n```bash\n# Step 1: User login (for gcloud commands)\ngcloud auth login\n\n# Step 2: ADC login (for Python libraries)\ngcloud auth application-default login\n\n# Step 3: Enable Vertex AI API\ngcloud services enable aiplatform.googleapis.com\n\n# Verify ADC location\nls ~/.config/gcloud/application_default_credentials.json\n```\n\n**When to Use Each:**\n\n| Feature | API Key | ADC (Vertex AI) |\n|---------|---------|-----------------|\n| Setup | Simple (just key) | Requires gcloud SDK |\n| Use Case | Development, demos | Production, enterprise |\n| Regions | us-central1 only | Multiple regions |\n| VPC Support | No | Yes |\n| Required API | Gemini API | Vertex AI API |\n| Cost | Standard | Volume discounts available |\n\n**Common Mistakes:**\n\n```python\n# ❌ WRONG: Passing API key with vertexai=True (ignored)\nclient = genai.Client(\n    api_key=os.environ[\"GOOGLE_API_KEY\"],\n    vertexai=True  # API key is ignored!\n)\n\n# ✓ CORRECT: Use ADC with vertexai=True\nclient = genai.Client(\n    vertexai=True,\n    project=\"your-project-id\",\n    location=\"us-central1\"\n)\n\n# ✓ CORRECT: Use API key without vertexai\nclient = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n```\n\n**Service Account (Production Alternative):**\n\nFor automated systems without user interaction:\n\n```python\nfrom google.oauth2 import service_account\n\n# Load service account credentials\ncredentials = service_account.Credentials.from_service_account_file(\n    'service-account.json',\n    scopes=['https://www.googleapis.com/auth/cloud-platform']\n)\n\n# Use with genai library\nclient = genai.Client(\n    vertexai=True,\n    project=\"your-project-id\",\n    location=\"us-central1\",\n    credentials=credentials\n)\n```\n\n**Service Account Requirements:**\n- `roles/storage.objectAdmin` on GCS bucket\n- `roles/aiplatform.user` for Vertex AI\n- Bucket must have IAM bindings for the service account\n\n**Troubleshooting Auth Errors:**\n\n```bash\n# Check if ADC exists\nls ~/.config/gcloud/application_default_credentials.json\n\n# Re-authenticate if missing\ngcloud auth application-default login\n\n# Check current project\ngcloud config get-value project\n\n# Verify API is enabled\ngcloud services list --enabled | grep aiplatform\n\n# If not enabled:\ngcloud services enable aiplatform.googleapis.com\n```\n\n---\n\n## Gotcha 7: Output URI Must Be a Prefix, Not a File\n\n**Problem:** Output URI is a prefix; the API appends job ID and timestamps.\n\n**Wrong:**\n```python\noutput_uri = \"gs://bucket/results/output.jsonl\"  # Will fail or create weird paths\n```\n\n**Correct:**\n```python\noutput_uri = \"gs://bucket/results/\"  # Trailing slash recommended\n# Results appear at: gs://bucket/results/{job_id}/output.jsonl\n```\n\n**Finding Results:**\n```python\ndef find_batch_output(output_prefix: str, job_name: str) -> str:\n    \"\"\"Find the actual output file location.\n\n    Args:\n        output_prefix: The URI prefix used when submitting\n        job_name: The batch job resource name\n\n    Returns:\n        GCS URI to the output JSONL\n    \"\"\"\n    # Job name format: batches/{batch_id}\n    batch_id = job_name.split('/')[-1]\n\n    client = storage.Client()\n    parts = output_prefix.replace(\"gs://\", \"\").split(\"/\", 1)\n    bucket_name = parts[0]\n    prefix = parts[1] if len(parts) > 1 else \"\"\n\n    bucket = client.bucket(bucket_name)\n\n    # Search for output files\n    blobs = list(bucket.list_blobs(prefix=prefix))\n\n    for blob in blobs:\n        if batch_id in blob.name and blob.name.endswith('.jsonl'):\n            return f\"gs://{bucket_name}/{blob.name}\"\n\n    raise FileNotFoundError(f\"No output found for job {job_name}\")\n```\n\n---\n\n## Gotcha 8: Rate Limits and Quotas\n\n**Problem:** Batch API has separate quotas from synchronous API.\n\n**Limits (as of 2024):**\n| Limit Type | Value |\n|------------|-------|\n| Max requests per JSONL | 10,000 |\n| Max concurrent jobs | 10 |\n| Max job size | 100MB |\n| Job expiration | 24 hours |\n\n**Handling Large Workloads:**\n```python\ndef chunk_requests(requests: list[dict], chunk_size: int = 10000) -> list[list[dict]]:\n    \"\"\"Split requests into chunks for multiple jobs.\n\n    Args:\n        requests: All batch requests\n        chunk_size: Max requests per job\n\n    Returns:\n        List of request chunks\n    \"\"\"\n    return [\n        requests[i:i + chunk_size]\n        for i in range(0, len(requests), chunk_size)\n    ]\n\n\ndef submit_chunked_jobs(chunks: list[list[dict]], bucket: str) -> list[str]:\n    \"\"\"Submit multiple batch jobs for large workloads.\n\n    Args:\n        chunks: List of request chunks\n        bucket: GCS bucket name\n\n    Returns:\n        List of job names\n    \"\"\"\n    job_names = []\n\n    for i, chunk in enumerate(chunks):\n        # Write chunk to JSONL\n        jsonl_path = f\"/tmp/batch_chunk_{i}.jsonl\"\n        write_jsonl(chunk, jsonl_path)\n\n        # Upload and submit\n        input_uri = upload_to_gcs(jsonl_path, bucket, f\"requests/chunk_{i}.jsonl\")\n        output_uri = f\"gs://{bucket}/outputs/chunk_{i}/\"\n\n        job = submit_batch_job(input_uri, output_uri)\n        job_names.append(job.name)\n\n        print(f\"Submitted chunk {i+1}/{len(chunks)}: {job.name}\")\n\n    return job_names\n```\n\n---\n\n## Gotcha 9: JSON Response Parsing Requires Careful Handling\n\n**Problem:** Even with `responseMimeType: \"application/json\"`, responses may not be valid JSON.\n\n**Common Issues:**\n- Markdown code fences around JSON: ` ```json ... ``` `\n- Truncated responses for large outputs\n- Model adds explanatory text before/after JSON\n\n**Robust Parsing:**\n```python\nimport re\n\ndef extract_json_from_response(text: str) -> dict | None:\n    \"\"\"Extract JSON from potentially messy response text.\n\n    Args:\n        text: Raw response text from model\n\n    Returns:\n        Parsed JSON dict, or None if extraction fails\n    \"\"\"\n    if not text:\n        return None\n\n    # Try direct parse first\n    try:\n        return json.loads(text)\n    except json.JSONDecodeError:\n        pass\n\n    # Remove markdown code fences\n    patterns = [\n        r'```json\\s*(.*?)\\s*```',  # ```json ... ```\n        r'```\\s*(.*?)\\s*```',       # ``` ... ```\n        r'`(.*?)`',                  # inline code\n    ]\n\n    for pattern in patterns:\n        match = re.search(pattern, text, re.DOTALL)\n        if match:\n            try:\n                return json.loads(match.group(1))\n            except json.JSONDecodeError:\n                continue\n\n    # Try to find JSON object boundaries\n    start = text.find('{')\n    end = text.rfind('}')\n\n    if start != -1 and end != -1 and end > start:\n        try:\n            return json.loads(text[start:end + 1])\n        except json.JSONDecodeError:\n            pass\n\n    # Try JSON array\n    start = text.find('[')\n    end = text.rfind(']')\n\n    if start != -1 and end != -1 and end > start:\n        try:\n            return json.loads(text[start:end + 1])\n        except json.JSONDecodeError:\n            pass\n\n    return None\n\n\ndef parse_batch_results_robust(jsonl_path: str) -> list[dict]:\n    \"\"\"Parse batch results with robust JSON extraction.\n\n    Args:\n        jsonl_path: Path to result JSONL file\n\n    Returns:\n        List of results with parsed JSON where possible\n    \"\"\"\n    results = []\n\n    with open(jsonl_path, 'r') as f:\n        for line_num, line in enumerate(f, 1):\n            try:\n                entry = json.loads(line)\n                request_id = entry.get(\"metadata\", {}).get(\"request_id\")\n\n                response = entry.get(\"response\", {})\n                candidates = response.get(\"candidates\", [])\n\n                if candidates:\n                    text = candidates[0].get(\"content\", {}).get(\"parts\", [{}])[0].get(\"text\", \"\")\n                    parsed_json = extract_json_from_response(text)\n\n                    results.append({\n                        \"request_id\": request_id,\n                        \"raw_response\": text,\n                        \"parsed_json\": parsed_json,\n                        \"parse_success\": parsed_json is not None,\n                        \"finish_reason\": candidates[0].get(\"finishReason\")\n                    })\n                else:\n                    results.append({\n                        \"request_id\": request_id,\n                        \"error\": response.get(\"error\"),\n                        \"raw_response\": None,\n                        \"parsed_json\": None,\n                        \"parse_success\": False\n                    })\n\n            except json.JSONDecodeError as e:\n                print(f\"Failed to parse line {line_num}: {e}\")\n                results.append({\n                    \"line_number\": line_num,\n                    \"error\": str(e),\n                    \"parse_success\": False\n                })\n\n    return results\n```\n\n---\n\n## Gotcha 10: Metadata Must Be Flat Primitives\n\n**Problem:** Vertex AI Batch API only accepts primitive types (STRING, INTEGER, FLOAT, BOOLEAN, TIMESTAMP, DATE, DATETIME, NUMERIC) for metadata values. Nested objects or arrays cause job failures.\n\n**Symptom:** Job fails with error:\n```\nThe column or property \"metadata\" in the specified input data is of unsupported type.\nSupported types for this column are: [STRING, INTEGER, FLOAT, BOOLEAN, TIMESTAMP, DATE, DATETIME, NUMERIC].\n```\n\n**Wrong:**\n```python\n# ❌ Nested object - NOT SUPPORTED\n{\n    \"request\": {...},\n    \"metadata\": {\n        \"request_id\": \"icon_123\",\n        \"file_info\": {              # This breaks!\n            \"name\": \"copy.svg\",\n            \"size\": 1024\n        }\n    }\n}\n```\n\n**Correct Option 1: Flatten**\n```python\n# ✓ Flat structure with primitives only\n{\n    \"request\": {...},\n    \"metadata\": {\n        \"request_id\": \"icon_123\",\n        \"file_name\": \"copy.svg\",\n        \"file_size\": 1024\n    }\n}\n```\n\n**Correct Option 2: Serialize to JSON String**\n```python\n# ✓ Complex data as JSON string\nimport json\n\n{\n    \"request\": {...},\n    \"metadata\": {\n        \"request_id\": \"icon_123\",\n        \"file_info\": json.dumps({\"name\": \"copy.svg\", \"size\": 1024})  # String!\n    }\n}\n```\n\n**When to Use Each:**\n- **Flatten**: When you need to filter/query by metadata fields\n- **Serialize**: When you just need to preserve context for result processing\n\n**Why:** Vertex AI stores metadata in BigQuery-compatible format, which doesn't support nested types.\n\n**Validation:**\n```python\ndef validate_metadata(metadata: dict) -> bool:\n    \"\"\"Check metadata contains only primitive types.\"\"\"\n    for key, value in metadata.items():\n        if isinstance(value, (dict, list)):\n            raise ValueError(\n                f\"Metadata value for '{key}' is {type(value).__name__}. \"\n                f\"Only primitives (str, int, float, bool) are allowed. \"\n                f\"Use json.dumps() to serialize complex data.\"\n            )\n        if not isinstance(value, (str, int, float, bool, type(None))):\n            raise ValueError(f\"Unsupported metadata type for '{key}': {type(value)}\")\n    return True\n```\n\n---\n\n## Gotcha 11: API Parameter Names (dest= not destination=)\n\n**Problem:** The Batch API parameter for output location is `dest=`, not `destination=`. Additionally, you pass plain strings/dicts, not wrapper types.\n\n**Symptom:** TypeError about unexpected keyword arguments\n\n**Wrong Attempts:**\n```python\n# ❌ WRONG: destination= doesn't exist\njob = client.batches.create(\n    model=\"gemini-2.5-flash-lite\",\n    src=\"gs://bucket/input.jsonl\",\n    destination=\"gs://bucket/output/\"  # This parameter doesn't exist!\n)\n\n# ❌ WRONG: Overly complex with wrapper types\nfrom google.genai import types\njob = client.batches.create(\n    model=\"gemini-2.5-flash-lite\",\n    src=\"gs://bucket/input.jsonl\",\n    config=types.CreateBatchJobConfig(  # Don't instantiate this manually!\n        dest=\"gs://bucket/output/\"\n    )\n)\n```\n\n**Correct:**\n```python\n# ✓ CORRECT: Use dest= parameter with plain string\njob = client.batches.create(\n    model=\"gemini-2.5-flash-lite\",\n    src=\"gs://bucket/input.jsonl\",\n    dest=\"gs://bucket/output/\",         # Plain string!\n    config={\"display_name\": \"my-job\"}   # Plain dict (optional)\n)\n```\n\n**API Signature:**\n```python\ndef create(\n    *,\n    model: str,                    # Model name\n    src: str,                      # Input GCS/BigQuery URI or file name\n    dest: str = None,              # Output GCS URI prefix (optional)\n    config: dict = None            # Optional config as plain dict\n) -> BatchJob:\n    ...\n```\n\n**Key Points:**\n1. **Parameter is `dest=`** (not destination, output, or output_uri)\n2. **Pass plain string** (not a URI object or wrapper type)\n3. **Config is plain dict** (not CreateBatchJobConfig instance)\n4. **SDK handles conversion** internally to proper types\n\n**Why the Confusion:**\n- `CreateBatchJobConfig` exists in SDK types for internal use\n- You see it in type hints/autocomplete\n- But you **don't instantiate it yourself**\n- Just pass a plain dict to `config=`\n\n**Think of it like:**\n- Type hints show `config: CreateBatchJobConfig`\n- But you pass `config={\"display_name\": \"job\"}`\n- SDK converts dict → CreateBatchJobConfig internally\n\n**Verification:**\n```python\n# Check parameter names without executing\nimport inspect\nfrom google import genai\n\nclient = genai.Client(vertexai=True, project=\"...\", location=\"us-central1\")\nsig = inspect.signature(client.batches.create)\nprint(sig.parameters.keys())  # Shows: model, src, dest, config\n```\n\n**Examples from Skill:**\n- Standard API: `examples/batch_processor.py` line 229-234\n- Vertex AI: `examples/icon_batch_vision.py` line 139-166\n\nBoth show the same pattern: `dest=` parameter with plain strings and dicts.\n",
        "skills/gemini-batch/references/troubleshooting.md": "# Troubleshooting\n\n## Contents\n\n- [Authentication Errors](#authentication-errors)\n- [Vertex AI API Not Enabled](#vertex-ai-api-not-enabled)\n- [Job Stuck in PENDING State](#job-stuck-in-pending-state)\n- [\"Permission Denied\" Errors](#permission-denied-errors)\n- [Empty or Truncated Responses](#empty-or-truncated-responses)\n- [JSON Parsing Failures](#json-parsing-failures)\n- [Rate Limit Errors](#rate-limit-errors)\n- [Debugging Request Format](#debugging-request-format)\n- [Cost Monitoring](#cost-monitoring)\n\nCommon issues and solutions for Gemini Batch API.\n\n---\n\n## Authentication Errors\n\n### Error: `DefaultCredentialsError: Could not automatically determine credentials`\n\n**Cause:** Vertex AI requires Application Default Credentials (ADC), not just API key.\n\n**Solution:**\n```bash\n# Set up ADC\ngcloud auth application-default login\n\n# Verify ADC file exists\nls ~/.config/gcloud/application_default_credentials.json\n```\n\n**Why this happens:**\n- Using `vertexai=True` with only `gcloud auth login` (not enough)\n- Need ADC for Python libraries to authenticate\n- API key is ignored when `vertexai=True`\n\n### Error: `API key is invalid`\n\n**Cause:** Wrong authentication method for Vertex AI.\n\n**Solutions:**\n\n```python\n# ❌ WRONG: API key with vertexai=True\nclient = genai.Client(\n    api_key=os.environ[\"GOOGLE_API_KEY\"],\n    vertexai=True  # API key is ignored!\n)\n\n# ✓ CORRECT: Use ADC with vertexai=True\nclient = genai.Client(\n    vertexai=True,\n    project=\"your-project-id\",\n    location=\"us-central1\"\n)\n\n# ✓ CORRECT: Use API key without vertexai\nclient = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n```\n\n### Error: `Project not set`\n\n**Cause:** Missing GCP project configuration.\n\n**Solution:**\n```bash\n# Set default project\ngcloud config set project YOUR_PROJECT_ID\n\n# Or specify in code\nclient = genai.Client(\n    vertexai=True,\n    project=\"your-project-id\",\n    location=\"us-central1\"\n)\n```\n\n### Complete Auth Checklist\n\n```bash\n# 1. User login (for gcloud commands)\ngcloud auth login\n\n# 2. ADC login (for Python libraries)\ngcloud auth application-default login\n\n# 3. Set project\ngcloud config set project YOUR_PROJECT_ID\n\n# 4. Verify current project\ngcloud config get-value project\n\n# 5. Enable Vertex AI API (see next section)\ngcloud services enable aiplatform.googleapis.com\n```\n\n---\n\n## Vertex AI API Not Enabled\n\n### Error: `API [aiplatform.googleapis.com] not enabled`\n\n**Cause:** Vertex AI API is not enabled for your project.\n\n**Solution:**\n```bash\n# Enable Vertex AI API\ngcloud services enable aiplatform.googleapis.com\n\n# Verify it's enabled\ngcloud services list --enabled | grep aiplatform\n```\n\n**What you should see:**\n```\naiplatform.googleapis.com  Vertex AI API\n```\n\n### Error: `Service account lacks IAM permissions`\n\n**Cause:** Service account needs Vertex AI permissions.\n\n**Solution:**\n```bash\n# Grant aiplatform.user role\ngcloud projects add-iam-policy-binding YOUR_PROJECT_ID \\\n  --member=\"serviceAccount:YOUR-SA@PROJECT.iam.gserviceaccount.com\" \\\n  --role=\"roles/aiplatform.user\"\n\n# Also grant storage permissions\ngsutil iam ch serviceAccount:YOUR-SA@PROJECT.iam.gserviceaccount.com:roles/storage.objectAdmin \\\n  gs://your-batch-bucket\n```\n\n---\n\n## Job Stuck in PENDING State\n\n**Possible Causes:**\n- High API load / queue backlog\n- Invalid request format (job won't start)\n- Bucket permissions issues\n\n**Solutions:**\n```bash\n# Check job details for errors\ngcloud ai batch-predictions describe JOB_ID --region=us-central1\n\n# Verify bucket permissions\ngsutil iam get gs://your-bucket\n\n# Test with smaller batch first\nhead -10 requests.jsonl > test_requests.jsonl\n```\n\n---\n\n## \"Permission Denied\" Errors\n\n**Checklist:**\n1. Service account has `storage.objectAdmin` on bucket\n2. Bucket is in `us-central1`\n3. API key/credentials are valid\n4. GCS URIs use `gs://` format (not HTTPS)\n\n```bash\n# Grant permissions\ngsutil iam ch serviceAccount:YOUR_SA@PROJECT.iam.gserviceaccount.com:objectAdmin gs://bucket\n\n# Verify access\ngsutil ls gs://your-bucket/\n```\n\n---\n\n## Empty or Truncated Responses\n\n**Causes:**\n- PDF too large (>50MB or >100 pages)\n- Request timeout\n- Token limit exceeded\n\n**Solutions:**\n```python\n# Check finish reason in results\nfor result in parse_results(jsonl_path):\n    reason = result.get(\"finish_reason\")\n    if reason != \"STOP\":\n        print(f\"Incomplete: {result['request_id']} - {reason}\")\n\n# Split large PDFs\nsplit_pdfs = split_pdf(\"large.pdf\", max_pages=50)\n```\n\n---\n\n## JSON Parsing Failures\n\n**Use robust parsing:**\n```python\n# See references/gotchas.md Gotcha 9 for full implementation\nparsed = extract_json_from_response(raw_text)\nif parsed is None:\n    # Fall back to manual extraction or retry\n    print(f\"Could not parse response for {request_id}\")\n```\n\n---\n\n## Rate Limit Errors\n\n**Symptoms:**\n- 429 errors\n- Jobs failing immediately\n\n**Solutions:**\n```python\n# Add delays between job submissions\nimport time\n\nfor chunk in chunks:\n    submit_job(chunk)\n    time.sleep(60)  # Wait between submissions\n\n# Use exponential backoff for status checks\ndef wait_with_backoff(job_name, initial_interval=60, max_interval=300):\n    interval = initial_interval\n    while True:\n        job = genai.batches.get(name=job_name)\n        if job.state in [\"JOB_STATE_SUCCEEDED\", \"JOB_STATE_FAILED\"]:\n            return job\n        time.sleep(interval)\n        interval = min(interval * 1.5, max_interval)\n```\n\n---\n\n## Debugging Request Format\n\n**Validate single request before batch:**\n```python\ndef test_single_request(gcs_uri: str, prompt: str):\n    \"\"\"Test extraction on single file before batch.\"\"\"\n    genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n    model = genai.GenerativeModel(\"gemini-2.0-flash-lite\")\n\n    response = model.generate_content([\n        {\"file_data\": {\"file_uri\": gcs_uri, \"mime_type\": \"application/pdf\"}},\n        prompt\n    ])\n\n    print(response.text)\n    return response\n```\n\n---\n\n## Cost Monitoring\n\n```python\ndef estimate_batch_cost(\n    file_count: int,\n    avg_pages: int = 10,\n    model: str = \"gemini-2.0-flash-lite\"\n) -> float:\n    \"\"\"Estimate batch processing cost.\n\n    Note: Prices as of 2024, verify current pricing.\n    \"\"\"\n    # Approximate tokens per page\n    tokens_per_page = 500\n\n    # Price per 1M tokens (batch pricing = 50% of standard)\n    prices = {\n        \"gemini-2.0-flash-lite\": {\"input\": 0.0375, \"output\": 0.15},  # batch rate\n        \"gemini-2.0-flash\": {\"input\": 0.075, \"output\": 0.30},\n        \"gemini-1.5-pro\": {\"input\": 1.25, \"output\": 5.00},\n    }\n\n    price = prices.get(model, prices[\"gemini-2.0-flash-lite\"])\n\n    total_input_tokens = file_count * avg_pages * tokens_per_page\n    total_output_tokens = file_count * 500  # Assume ~500 tokens output\n\n    input_cost = (total_input_tokens / 1_000_000) * price[\"input\"]\n    output_cost = (total_output_tokens / 1_000_000) * price[\"output\"]\n\n    return input_cost + output_cost\n```\n",
        "skills/gemini-batch/references/vertex-ai.md": "# Vertex AI Alternative\n\nFor enterprise deployments, consider Vertex AI Batch Prediction as an alternative to the standard Gemini Batch API.\n\n## Comparison\n\n| Feature | Gemini API Batch | Vertex AI Batch |\n|---------|------------------|-----------------|\n| Setup | API key | Service account + project |\n| Regions | us-central1 only | Multiple regions |\n| Quotas | Standard | Customizable |\n| VPC Support | No | Yes |\n| Logging | Basic | Cloud Logging integration |\n| Cost | Standard | Volume discounts available |\n\n## When to Use Vertex AI\n\n- Enterprise deployments with VPC requirements\n- Need for custom quotas\n- Multi-region processing\n- Integration with existing GCP infrastructure\n- Advanced logging and monitoring needs\n\n## Example\n\n```python\nfrom google.cloud import aiplatform\nfrom datetime import datetime\n\ndef submit_vertex_batch(\n    project: str,\n    location: str,\n    input_uri: str,\n    output_uri: str,\n    model: str = \"gemini-1.5-flash\"\n) -> aiplatform.BatchPredictionJob:\n    \"\"\"Submit batch job via Vertex AI.\n\n    Args:\n        project: GCP project ID\n        location: GCP region\n        input_uri: GCS input JSONL URI\n        output_uri: GCS output prefix\n        model: Model resource name\n\n    Returns:\n        BatchPredictionJob object\n    \"\"\"\n    aiplatform.init(project=project, location=location)\n\n    job = aiplatform.BatchPredictionJob.create(\n        model_name=f\"publishers/google/models/{model}\",\n        job_display_name=f\"batch-{datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n        gcs_source=input_uri,\n        gcs_destination_prefix=output_uri,\n        sync=False\n    )\n\n    return job\n```\n\n## Setup Requirements\n\n1. Enable Vertex AI API in GCP Console\n2. Create service account with appropriate roles:\n   - `roles/aiplatform.user`\n   - `roles/storage.objectAdmin`\n3. Configure authentication:\n   ```bash\n   gcloud auth application-default login\n   # or\n   export GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json\n   ```\n\n## Resources\n\n- [Vertex AI Batch Prediction](https://cloud.google.com/vertex-ai/docs/predictions/batch-predictions)\n- [Vertex AI Pricing](https://cloud.google.com/vertex-ai/pricing)\n",
        "skills/jupytext/SKILL.md": "---\nname: jupytext\ndescription: This skill should be used when the user asks to \"convert notebook to text\", \"use jupytext\", \"version control notebooks\", \"share data between kernels\", \"set up multi-kernel project\", \"pair notebooks with Python files\", \"sync ipynb and py files\", or needs multi-kernel projects (Python/R/Stata/SAS) with version-control-friendly notebooks.\n---\n\n## Contents\n\n- [Execution Enforcement](#execution-enforcement)\n- [Core Concepts](#core-concepts)\n- [Multi-Kernel Data Sharing](#multi-kernel-data-sharing)\n- [Workflow Integration](#workflow-integration)\n- [Project Structure](#project-structure)\n- [Kernel Specification](#kernel-specification)\n- [Quick Troubleshooting](#quick-troubleshooting)\n- [Additional Resources](#additional-resources)\n- [Best Practices](#best-practices)\n\n# Jupytext Skill\n\nJupytext converts Jupyter notebooks to/from text formats (.py, .R, .md), enabling version control and multi-kernel workflows.\n\n## Execution Enforcement\n\n### IRON LAW: NO EXECUTION CLAIM WITHOUT OUTPUT VERIFICATION\n\nBefore claiming ANY jupytext script executed successfully, follow this sequence:\n1. **EXECUTE** using the papermill pipeline: `jupytext --to notebook --output - script.py | papermill - output.ipynb`\n2. **CHECK** for execution errors (papermill exit code and stderr)\n3. **VERIFY** output.ipynb exists and is non-empty\n4. **INSPECT** outputs using notebook-debug skill verification\n5. **CLAIM** success only after verification passes\n\nThis is non-negotiable. Claiming \"script works\" without executing through papermill is LYING to the user.\n\n### Rationalization Table - STOP If You Think:\n\n| Excuse | Reality | Do Instead |\n|--------|---------|------------|\n| \"I converted to ipynb, so it works\" | Conversion ≠ execution | EXECUTE with papermill, not just convert |\n| \"The .py file looks correct\" | Syntax correctness ≠ runtime correctness | RUN and CHECK outputs |\n| \"I'll let the user execute it\" | You're passing broken code | VERIFY before claiming completion |\n| \"Just a conversion task, no execution needed\" | User expects working notebook | EXECUTE to confirm it works |\n| \"I can use `jupyter nbconvert --execute`\" | Papermill has better error handling | USE the recommended papermill pipeline |\n| \"I'll save the intermediate ipynb first\" | Creates clutter | USE the recommended pipeline (no intermediate files) |\n| \"Exit code 0 means success\" | Papermill can succeed with errors in cells | CHECK output.ipynb for tracebacks |\n\n### Red Flags - STOP Immediately If You Think:\n\n- \"Let me just convert and return the ipynb\" → NO. EXECUTE with papermill first.\n- \"The .py file is simple, can't have errors\" → NO. Simple code fails too.\n- \"I'll execute without papermill\" → NO. Use the recommended pipeline.\n- \"Conversion completed, so job done\" → NO. Execution verification required.\n\n### Execution Verification Checklist\n\nBefore EVERY \"notebook works\" claim:\n\n**Conversion:**\n- [ ] Correct format specified (py:percent recommended)\n- [ ] Conversion command succeeded\n- [ ] No syntax errors in conversion\n\n**Execution (MANDATORY):**\n- [ ] Used recommended papermill pipeline: `jupytext --to notebook --output - script.py | papermill - output.ipynb`\n- [ ] Papermill exit code is 0\n- [ ] No errors in stderr\n- [ ] output.ipynb file created\n- [ ] output.ipynb is non-empty (>100 bytes)\n\n**Output Verification:**\n- [ ] Used notebook-debug skill's verification checklist\n- [ ] No tracebacks in any cell\n- [ ] All cells have execution_count (not null)\n- [ ] Expected outputs present (plots, dataframes, metrics)\n- [ ] No unexpected warnings or errors\n\n**Multi-Kernel Projects (if applicable):**\n- [ ] Correct kernel specified in header\n- [ ] Interchange files created (parquet/DTA)\n- [ ] Downstream notebooks can read interchange files\n\n**Only after ALL checks pass:**\n- [ ] Claim \"notebook executed successfully\"\n\n### Gate Function: Jupytext Execution\n\nFollow this sequence for EVERY jupytext task involving execution:\n\n```\n1. CONVERT  → jupytext --to notebook --output -\n2. EXECUTE  → papermill - output.ipynb (with params if needed)\n3. CHECK    → Verify exit code and stderr\n4. INSPECT  → Use notebook-debug verification\n5. VERIFY   → Outputs match expectations\n6. CLAIM    → \"Notebook works\" only after all gates passed\n```\n\n**NEVER skip execution gate.** Converting without executing proves nothing about correctness.\n\n### Honesty Framing\n\n**Claiming a jupytext script works without executing it through papermill is LYING.**\n\nThis is not just format conversion - verify that the notebook executes correctly. The user expects a working notebook, not just syntactically valid code.\n\n## Core Concepts\n\n### Percent Format (Recommended)\n\nUse percent format (`py:percent`) for all projects:\n\n```python\n# %% [markdown]\n# # Analysis Title\n\n# %%\nimport pandas as pd\ndf = pd.read_csv(\"data.csv\")\n\n# %% tags=[\"parameters\"]\ninput_file = \"data.csv\"\n```\n\nCell markers: `# %%` for code, `# %% [markdown]` for markdown.\n\n**Markdown dollar signs:** Always wrap `$` in backticks to prevent LaTeX rendering - `# Cost: `$50`` not `# Cost: $50`\n\n### Project Configuration\n\nCreate `jupytext.toml` in project root:\n\n```toml\nformats = \"ipynb,py:percent\"\nnotebook_metadata_filter = \"-all\"\ncell_metadata_filter = \"-all\"\n```\n\n### Essential Commands\n\n```bash\n# Convert notebook to percent-format Python file\njupytext --to py:percent notebook.ipynb\n\n# Convert Python script to Jupyter notebook format\njupytext --to notebook script.py\n\n# Enable bidirectional pairing to keep formats synchronized\njupytext --set-formats ipynb,py:percent notebook.ipynb\n\n# Synchronize paired notebook and text file\njupytext --sync notebook.ipynb\n```\n\n### Execution (Recommended Pattern)\n\n**Always pipe to papermill for execution** - no intermediate files:\n\n```bash\n# Convert script to notebook and execute in atomic operation\njupytext --to notebook --output - script.py | papermill - output.ipynb\n\n# Convert and execute with parameter injection\njupytext --to notebook --output - script.py | papermill - output.ipynb -p start_date \"2024-01-01\" -p n_samples 1000\n\n# Convert and execute with detailed logging output\njupytext --to notebook --output - script.py | papermill - output.ipynb --log-output\n\n# Convert and execute in memory without saving intermediate files\njupytext --to notebook --output - script.py | papermill - -\n```\n\nKey flags:\n- `--output -` tells jupytext to write to stdout\n- `papermill - output.ipynb` reads from stdin, writes to file\n- `papermill - -` reads from stdin, writes to stdout (for inspection)\n\n**Why this pattern:**\n1. No intermediate `.ipynb` files cluttering the workspace\n2. Single atomic operation - convert and execute together\n3. Papermill handles parameters, logging, and error reporting\n4. Works in CI/CD pipelines without temp file cleanup\n\n### Debugging Runtime Errors\n\nAfter execution, use `notebook-debug` skill to inspect tracebacks in the output ipynb.\n\n## Multi-Kernel Data Sharing\n\nShare data between Python/R/Stata/SAS via files:\n\n| Route | Format | Write | Read |\n|-------|--------|-------|------|\n| Python -> R | Parquet | `df.to_parquet()` | `arrow::read_parquet()` |\n| Python -> Stata | DTA | `df.to_stata()` | `use \"file.dta\"` |\n| Any -> Any | CSV | Native | Native |\n| SQL queries | DuckDB | Query parquet directly | Query parquet directly |\n\n### Cross-Kernel Pipeline Pattern\n\n```\nPython (prep) -> Parquet -> R (stats) -> Parquet -> Python (report)\n                    |\n                    v\n               Stata (.dta) -> Econometrics\n```\n\n## Workflow Integration\n\n### Git Pre-commit Hook\n\nAdd the following to `.pre-commit-config.yaml`:\n\n```yaml\nrepos:\n  - repo: https://github.com/mwouts/jupytext\n    rev: v1.16.0\n    hooks:\n      - id: jupytext\n        args: [--sync]  # Synchronize paired formats before commit\n```\n\n### Version Control Strategy\n\nChoose one approach:\n\n- **Option A**: Commit only .py files (add `*.ipynb` to `.gitignore`) for minimal repository size\n- **Option B**: Commit both formats to give reviewers format choice\n\n### Editor Integration\n\nConfigure editors for automatic synchronization:\n\n- **VS Code**: Install Jupytext extension for automatic bidirectional sync\n- **JupyterLab**: Right-click notebook and select \"Pair Notebook\" for synchronization\n\n## Project Structure\n\nStandard multi-kernel project layout:\n\n```\nproject/\n├── jupytext.toml          # Project-wide settings\n├── environment.yml        # Conda env with all kernels\n├── notebooks/\n│   ├── 01_python_prep.py  # Python percent format\n│   ├── 02_r_analysis.R    # R percent format\n│   └── 03_stata_models.do # Stata script\n├── data/\n│   ├── raw/\n│   └── processed/         # Parquet/DTA interchange files\n└── results/\n```\n\n## Kernel Specification\n\nSpecify kernel in file header:\n\n```python\n# ---\n# jupyter:\n#   kernelspec:\n#     display_name: Python 3\n#     language: python\n#     name: python3\n# ---\n\n# %% [markdown]\n# # Python Analysis\n```\n\n## Quick Troubleshooting\n\n| Issue | Solution |\n|-------|----------|\n| Sync conflict | Delete .ipynb, regenerate from .py |\n| Wrong kernel | Add kernelspec header to .py file |\n| Metadata noise | Set `notebook_metadata_filter = \"-all\"` |\n| Cell order lost | Use percent format (preserves structure) |\n\n## Additional Resources\n\n### Reference Files\n\nDetailed patterns and configurations:\n\n- **`references/formats.md`** - All format specifications (percent, light, sphinx, myst, rmd, quarto), cell metadata, configuration options\n- **`references/kernels.md`** - Kernel setup (IRkernel, xeus-r, stata_kernel, pystata, saspy), environment configuration, troubleshooting\n- **`references/data-sharing.md`** - Cross-kernel data sharing patterns (parquet, dta, csv, duckdb), full pipeline examples, validation patterns\n\n### Example Files\n\nWorking code in `examples/`:\n\n- **`examples/python_analysis.py`** - Python percent-format template with common patterns\n- **`examples/r_analysis.R`** - R percent-format template for statistical analysis\n- **`examples/cross_kernel_pipeline.py`** - Multi-kernel data sharing example\n\n### Scripts\n\nUtility scripts in `scripts/`:\n\n- **`scripts/init_project.sh`** - Initialize jupytext project with standard structure\n- **`scripts/sync_all.sh`** - Sync all paired notebooks in project\n\n## Best Practices\n\n1. **Use percent format** - Best balance of readability and cell preservation\n2. **Strip metadata for git** - Use metadata filters for cleaner diffs\n3. **Use parquet for interchange** - Type-safe, cross-language compatible format\n4. **Document kernel requirements** - Include in README or environment.yml\n5. **Enable pre-commit hooks** - Ensure synchronization before commits\n",
        "skills/jupytext/references/data-sharing.md": "# Cross-Kernel Data Sharing\n\n## Contents\n\n- [Format Comparison](#format-comparison)\n- [Recommended: Parquet](#recommended-parquet)\n- [Python <-> R Patterns](#python---r-patterns)\n- [Python <-> Stata Patterns](#python---stata-patterns)\n- [Python <-> SAS Patterns](#python---sas-patterns)\n- [DuckDB for Cross-Kernel SQL](#duckdb-for-cross-kernel-sql)\n- [Full Pipeline Example](#full-pipeline-example)\n- [Best Practices](#best-practices)\n\nPatterns for sharing data between Python, R, Stata, and SAS in multi-kernel jupytext projects.\n\n## Format Comparison\n\n| Format | Python | R | Stata | SAS | Best For |\n|--------|--------|---|-------|-----|----------|\n| **Parquet** | Native | Native | Via Python | Limited | Large datasets, typed columns |\n| **CSV** | Native | Native | Native | Native | Universal compatibility |\n| **Feather** | Native | Native | No | No | Python <-> R only |\n| **DTA** | Native | Native | Native | Via PROC | Stata interop |\n| **SAS7BDAT** | Read | Read | No | Native | SAS source data |\n| **DuckDB** | Native | Native | Via ODBC | Via ODBC | SQL queries on files |\n| **RDS** | Via rpy2 | Native | No | No | R-specific objects |\n\n## Recommended: Parquet\n\nParquet is the recommended interchange format for most workflows.\n\n### Python (Writer)\n\n```python\n# %%\nimport pandas as pd\nimport pyarrow as pa\nimport pyarrow.parquet as pq\n\n# Process data\ndf = pd.read_csv(\"raw/data.csv\")\ndf['date'] = pd.to_datetime(df['date'])\ndf['category'] = df['category'].astype('category')\n\n# Write with schema preservation\ndf.to_parquet(\"processed/data.parquet\", engine='pyarrow')\n\n# Or with explicit schema for stricter typing\ntable = pa.Table.from_pandas(df)\npq.write_table(table, \"processed/data.parquet\")\n```\n\n### R (Reader)\n\n```r\n# %%\nlibrary(arrow)\n\n# Read parquet\ndf <- read_parquet(\"processed/data.parquet\")\n\n# Check types preserved\nstr(df)\n\n# Perform analysis\nmodel <- lm(y ~ x1 + x2, data = df)\n\n# Write results back\nresults <- data.frame(\n    coefficient = coef(model),\n    std_error = summary(model)$coefficients[, 2]\n)\nwrite_parquet(results, \"results/model_results.parquet\")\n```\n\n### Stata (Via Python Bridge)\n\nStata doesn't natively read parquet. Use Python integration:\n\n```stata\n* %%\n* Method 1: Use Python within Stata (Stata 16+)\npython:\nimport pandas as pd\ndf = pd.read_parquet(\"processed/data.parquet\")\ndf.to_stata(\"processed/data.dta\", write_index=False)\nend\n\n* Load the converted data\nuse \"processed/data.dta\", clear\n```\n\nOr convert in a Python cell first:\n\n```python\n# %% kernel=python\nimport pandas as pd\ndf = pd.read_parquet(\"processed/data.parquet\")\ndf.to_stata(\"processed/data.dta\", write_index=False, version=118)\n```\n\n## Python <-> R Patterns\n\n### Using Parquet (Recommended)\n\n```python\n# %% Python: Prepare data\nimport pandas as pd\nimport numpy as np\n\ndf = pd.DataFrame({\n    'id': range(1000),\n    'x': np.random.randn(1000),\n    'y': np.random.randn(1000),\n    'group': np.random.choice(['A', 'B', 'C'], 1000)\n})\n\ndf.to_parquet(\"shared/analysis_data.parquet\")\n```\n\n```r\n# %% R: Statistical analysis\nlibrary(arrow)\nlibrary(tidyverse)\n\ndf <- read_parquet(\"shared/analysis_data.parquet\")\n\n# Group analysis\nresults <- df |>\n    group_by(group) |>\n    summarise(\n        mean_x = mean(x),\n        mean_y = mean(y),\n        cor_xy = cor(x, y),\n        n = n()\n    )\n\nwrite_parquet(results, \"shared/group_stats.parquet\")\n```\n\n```python\n# %% Python: Aggregate results\nimport pandas as pd\n\nresults = pd.read_parquet(\"shared/group_stats.parquet\")\nprint(results)\n```\n\n### Using Feather (Alternative)\n\nFeather is slightly faster for Python <-> R but less portable.\n\n```python\n# Python\ndf.to_feather(\"shared/data.feather\")\n```\n\n```r\n# R\nlibrary(arrow)\ndf <- read_feather(\"shared/data.feather\")\nwrite_feather(results, \"shared/results.feather\")\n```\n\n## Python <-> Stata Patterns\n\n### Using DTA Format\n\n```python\n# %% Python: Prepare for Stata\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'id': range(100),\n    'revenue': [1000 * i for i in range(100)],\n    'year': [2020 + i % 5 for i in range(100)]\n})\n\n# Write Stata format (version 118 for Stata 14+)\ndf.to_stata(\"shared/for_stata.dta\", write_index=False, version=118)\n```\n\n```stata\n* %% Stata: Analysis\nuse \"shared/for_stata.dta\", clear\n\n* Panel regression\nxtset id year\nxtreg revenue i.year, fe\n\n* Save estimates\nestimates store model1\nesttab model1 using \"shared/regression_results.csv\", replace csv\n```\n\n```python\n# %% Python: Read Stata results\nimport pandas as pd\n\n# Read regression output\nresults = pd.read_csv(\"shared/regression_results.csv\")\nprint(results)\n```\n\n### Handling Stata Value Labels\n\n```python\n# %% Python: Preserve value labels\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'status': pd.Categorical(['active', 'inactive', 'pending'] * 100)\n})\n\n# Stata needs numeric with labels\ndf['status_code'] = df['status'].cat.codes\n\n# Create label mapping for Stata\nlabels = dict(enumerate(df['status'].cat.categories))\nprint(f\"Label mapping: {labels}\")\n\ndf[['status_code']].to_stata(\"shared/with_labels.dta\",\n                              write_index=False,\n                              variable_labels={'status_code': 'Status'},\n                              version=118)\n```\n\n## Python <-> SAS Patterns\n\n### Using CSV (Most Compatible)\n\n```python\n# %% Python: Prepare for SAS\nimport pandas as pd\n\ndf = pd.DataFrame({\n    'patient_id': range(100),\n    'treatment': ['A', 'B'] * 50,\n    'outcome': [1.5 * i + 0.5 for i in range(100)]\n})\n\n# SAS prefers clean CSV\ndf.to_csv(\"shared/for_sas.csv\", index=False)\n```\n\n```sas\n* %% SAS: Import and analyze\nproc import datafile=\"shared/for_sas.csv\"\n    out=work.analysis_data\n    dbms=csv\n    replace;\nrun;\n\nproc glm data=work.analysis_data;\n    class treatment;\n    model outcome = treatment;\n    output out=work.predictions p=predicted;\nrun;\n\nproc export data=work.predictions\n    outfile=\"shared/sas_predictions.csv\"\n    dbms=csv\n    replace;\nrun;\n```\n\n```python\n# %% Python: Read SAS results\nimport pandas as pd\n\npredictions = pd.read_csv(\"shared/sas_predictions.csv\")\nprint(predictions.head())\n```\n\n### Reading SAS7BDAT Files\n\n```python\n# %% Python: Read SAS data\nimport pandas as pd\n\n# Read SAS dataset\ndf = pd.read_sas(\"data/sasdata.sas7bdat\", format='sas7bdat')\n\n# Handle SAS dates (days since 1960-01-01)\nsas_epoch = pd.Timestamp('1960-01-01')\ndf['date'] = sas_epoch + pd.to_timedelta(df['sas_date'], unit='D')\n```\n\n## DuckDB for Cross-Kernel SQL\n\nDuckDB can query parquet files directly, enabling SQL access from any kernel.\n\n### Python with DuckDB\n\n```python\n# %%\nimport duckdb\n\n# Query parquet directly\nresult = duckdb.sql(\"\"\"\n    SELECT\n        group,\n        AVG(x) as mean_x,\n        COUNT(*) as n\n    FROM 'shared/analysis_data.parquet'\n    GROUP BY group\n\"\"\").df()\n\nprint(result)\n```\n\n### R with DuckDB\n\n```r\n# %%\nlibrary(duckdb)\nlibrary(DBI)\n\ncon <- dbConnect(duckdb())\n\nresult <- dbGetQuery(con, \"\n    SELECT\n        group,\n        AVG(x) as mean_x,\n        COUNT(*) as n\n    FROM 'shared/analysis_data.parquet'\n    GROUP BY group\n\")\n\ndbDisconnect(con, shutdown=TRUE)\nprint(result)\n```\n\n## Full Pipeline Example\n\n### Step 1: Python Data Preparation\n\n```python\n# %% [markdown]\n# # Step 1: Data Preparation (Python)\n\n# %%\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\n\n# Create output directory\nPath(\"pipeline/\").mkdir(exist_ok=True)\n\n# Load and clean raw data\ndf = pd.read_csv(\"raw/survey.csv\")\ndf = df.dropna(subset=['income', 'age'])\ndf['log_income'] = np.log(df['income'])\n\n# Save for downstream kernels\ndf.to_parquet(\"pipeline/clean_data.parquet\")\ndf.to_stata(\"pipeline/clean_data.dta\", write_index=False, version=118)\n\nprint(f\"Saved {len(df)} records\")\n```\n\n### Step 2: R Statistical Analysis\n\n```r\n# %% [markdown]\n# # Step 2: Statistical Analysis (R)\n\n# %%\nlibrary(arrow)\nlibrary(tidyverse)\nlibrary(broom)\n\ndf <- read_parquet(\"pipeline/clean_data.parquet\")\n\n# Run models\nmodel1 <- lm(log_income ~ age + education, data = df)\nmodel2 <- lm(log_income ~ age + education + region, data = df)\n\n# Tidy results\nresults <- bind_rows(\n    tidy(model1) |> mutate(model = \"basic\"),\n    tidy(model2) |> mutate(model = \"with_region\")\n)\n\nwrite_parquet(results, \"pipeline/model_coefficients.parquet\")\n```\n\n### Step 3: Stata Robustness Checks\n\n```stata\n* %% [markdown]\n* # Step 3: Robustness Checks (Stata)\n\n* %%\nuse \"pipeline/clean_data.dta\", clear\n\n* Quantile regression for robustness\nqreg log_income age education, quantile(0.5)\nestimates store median_reg\n\n* Export results\nesttab median_reg using \"pipeline/quantile_results.csv\", replace csv\n```\n\n### Step 4: Python Final Report\n\n```python\n# %% [markdown]\n# # Step 4: Aggregate Results (Python)\n\n# %%\nimport pandas as pd\n\n# Load all results\nols_results = pd.read_parquet(\"pipeline/model_coefficients.parquet\")\nquantile_results = pd.read_csv(\"pipeline/quantile_results.csv\")\n\nprint(\"OLS Results:\")\nprint(ols_results)\n\nprint(\"\\nQuantile Regression Results:\")\nprint(quantile_results)\n```\n\n## Best Practices\n\n### 1. Establish Data Contract\n\nDocument expected columns and types:\n\n```python\n# data_contract.py\nCLEAN_DATA_SCHEMA = {\n    'id': 'int64',\n    'date': 'datetime64[ns]',\n    'amount': 'float64',\n    'category': 'category'\n}\n```\n\n### 2. Validate on Read\n\n```python\n# %%\ndef validate_schema(df, expected_schema):\n    \"\"\"Validate dataframe matches expected schema.\"\"\"\n    for col, dtype in expected_schema.items():\n        if col not in df.columns:\n            raise ValueError(f\"Missing column: {col}\")\n        if str(df[col].dtype) != dtype:\n            print(f\"Warning: {col} is {df[col].dtype}, expected {dtype}\")\n\ndf = pd.read_parquet(\"pipeline/data.parquet\")\nvalidate_schema(df, CLEAN_DATA_SCHEMA)\n```\n\n### 3. Use Checksums\n\n```python\n# %%\nimport hashlib\n\ndef file_checksum(path):\n    \"\"\"Generate MD5 checksum for data file.\"\"\"\n    with open(path, 'rb') as f:\n        return hashlib.md5(f.read()).hexdigest()\n\nchecksum = file_checksum(\"pipeline/clean_data.parquet\")\nprint(f\"Data checksum: {checksum}\")\n```\n\n### 4. Document Pipeline Steps\n\n```python\n# %%\nimport json\nfrom datetime import datetime\n\npipeline_log = {\n    'step': 'python_prep',\n    'timestamp': datetime.now().isoformat(),\n    'input_files': ['raw/survey.csv'],\n    'output_files': ['pipeline/clean_data.parquet'],\n    'row_count': len(df),\n    'checksum': file_checksum(\"pipeline/clean_data.parquet\")\n}\n\nwith open(\"pipeline/step1_log.json\", 'w') as f:\n    json.dump(pipeline_log, f, indent=2)\n```\n",
        "skills/jupytext/references/formats.md": "# Jupytext Formats\n\n## Contents\n\n- [Format Comparison](#format-comparison)\n- [Percent Format (Recommended)](#percent-format-recommended)\n- [Light Format](#light-format)\n- [Markdown Format](#markdown-format)\n- [MyST Markdown Format](#myst-markdown-format)\n- [R Markdown Format](#r-markdown-format)\n- [Quarto Format](#quarto-format)\n- [Format Specification Syntax](#format-specification-syntax)\n- [Cell Metadata](#cell-metadata)\n- [Configuration Options](#configuration-options)\n- [Format Selection Guide](#format-selection-guide)\n\nJupytext supports multiple text representations of Jupyter notebooks. Choose based on your workflow needs.\n\n## Format Comparison\n\n| Format | Extension | Cell Markers | Best For |\n|--------|-----------|--------------|----------|\n| **Percent** | `.py` | `# %%` | Production code, multi-kernel |\n| **Light** | `.py` | Comments only | Simple scripts |\n| **Sphinx** | `.py` | `# %%` + RST | Documentation |\n| **Markdown** | `.md` | Code fences | Literate programming |\n| **MyST** | `.md` | MyST syntax | Jupyter Book |\n| **R Markdown** | `.Rmd` | Chunk syntax | R workflows |\n| **Quarto** | `.qmd` | Quarto syntax | Cross-language publishing |\n\n## Percent Format (Recommended)\n\nThe percent format is the most versatile and widely supported.\n\n### Python (py:percent)\n\n```python\n# %% [markdown]\n# # Analysis Title\n#\n# This is a markdown cell describing the analysis.\n\n# %%\nimport pandas as pd\nimport numpy as np\n\n# Load data\ndf = pd.read_csv(\"data.csv\")\n\n# %% [markdown]\n# ## Data Exploration\n\n# %%\n# Display summary statistics\ndf.describe()\n\n# %% tags=[\"parameters\"]\n# Cell with tags (e.g., for papermill)\ninput_file = \"data.csv\"\noutput_dir = \"./results\"\n```\n\n### R (R:percent)\n\n```r\n# %% [markdown]\n# # R Analysis\n#\n# Using R kernel with jupytext.\n\n# %%\nlibrary(tidyverse)\nlibrary(arrow)\n\n# Read parquet from Python pipeline\ndf <- read_parquet(\"data/processed.parquet\")\n\n# %% [markdown]\n# ## Statistical Analysis\n\n# %%\n# Summary statistics\nsummary(df)\n\n# Linear regression\nmodel <- lm(y ~ x1 + x2, data = df)\nsummary(model)\n```\n\n### Stata (stata:percent)\n\n```stata\n* %% [markdown]\n* # Stata Analysis\n*\n* Econometric analysis using Stata kernel.\n\n* %%\n* Load data from Python pipeline\nuse \"data/processed.dta\", clear\n\n* %% [markdown]\n* ## Regression Analysis\n\n* %%\n* Run regression\nregress y x1 x2 x3\nestimates store model1\n\n* Robust standard errors\nregress y x1 x2 x3, robust\n```\n\n### SAS (sas:percent)\n\n```sas\n* %% [markdown];\n* # SAS Analysis;\n* ;\n* Statistical analysis using SAS kernel.;\n\n* %%;\n/* Import data */\nproc import datafile=\"data/processed.csv\"\n    out=work.mydata\n    dbms=csv\n    replace;\nrun;\n\n* %% [markdown];\n* ## Descriptive Statistics;\n\n* %%;\nproc means data=work.mydata n mean std min max;\n    var x1 x2 y;\nrun;\n```\n\n## Light Format\n\nMinimal format that preserves notebook structure through strategic comments.\n\n```python\n# This is a markdown cell (implicit from comment structure)\n\n# +\nimport pandas as pd\n\n# Multiple line code cell\ndf = pd.read_csv(\"data.csv\")\ndf.head()\n# -\n\n# Another markdown cell\n\nprint(\"Single expression cells don't need markers\")\n```\n\n### When to Use Light Format\n\n- Quick scripts that may become notebooks\n- Minimal visual noise preferred\n- Simple linear workflows\n\n## Markdown Format\n\nStandard markdown with fenced code blocks.\n\n```markdown\n# Analysis Title\n\nThis is a markdown cell.\n\n```python\nimport pandas as pd\ndf = pd.read_csv(\"data.csv\")\n```\n\n## Data Summary\n\n```python\ndf.describe()\n```\n```\n\n### Limitations\n\n- No cell metadata support\n- Language inference from fences\n- Best for documentation-first workflows\n\n## MyST Markdown Format\n\nMyST (Markedly Structured Text) for Jupyter Book projects.\n\n````markdown\n---\njupytext:\n  formats: md:myst,ipynb\n  text_representation:\n    extension: .md\n    format_name: myst\nkernelspec:\n  display_name: Python 3\n  language: python\n  name: python3\n---\n\n# Analysis with MyST\n\nThis uses MyST markdown syntax.\n\n```{code-cell} ipython3\nimport pandas as pd\ndf = pd.read_csv(\"data.csv\")\n```\n\n```{code-cell} ipython3\n:tags: [hide-input]\n\n# This cell's input is hidden in output\ndf.describe()\n```\n````\n\n### MyST Features\n\n- Rich directive syntax\n- Cross-references\n- Jupyter Book integration\n- Cell tags in code fence options\n\n## R Markdown Format\n\nFor R-centric workflows.\n\n```markdown\n---\ntitle: \"Analysis\"\noutput: html_document\n---\n\n```{r setup, include=FALSE}\nlibrary(tidyverse)\n```\n\n# Introduction\n\nThis is text content.\n\n```{r}\ndata <- read_csv(\"data.csv\")\nsummary(data)\n```\n```\n\n## Quarto Format\n\nModern cross-language publishing format.\n\n```markdown\n---\ntitle: \"Multi-Language Analysis\"\nformat: html\njupyter: python3\n---\n\n## Python Section\n\n```{python}\nimport pandas as pd\ndf = pd.read_csv(\"data.csv\")\n```\n\n## R Section\n\n```{r}\nlibrary(tidyverse)\n# Can share data via files\n```\n```\n\n## Format Specification Syntax\n\nWhen using jupytext commands, specify format precisely:\n\n```bash\n# Language and format\njupytext --to py:percent notebook.ipynb\njupytext --to py:light notebook.ipynb\njupytext --to R:percent notebook.ipynb\n\n# Markdown variants\njupytext --to markdown notebook.ipynb\njupytext --to myst notebook.ipynb\njupytext --to md:myst notebook.ipynb\n\n# R Markdown\njupytext --to Rmd notebook.ipynb\n```\n\n## Cell Metadata\n\nMetadata can be preserved in different formats:\n\n### Percent Format\n\n```python\n# %% tags=[\"parameters\", \"hide-input\"]\n# Cell with tags\n\n# %% language=\"R\"\n# Run R code in Python notebook\n```\n\n### MyST Format\n\n````markdown\n```{code-cell} ipython3\n:tags: [parameters]\n\nparam = \"value\"\n```\n````\n\n## Configuration Options\n\n### jupytext.toml Full Example\n\n```toml\n# Default format pairing\nformats = \"ipynb,py:percent\"\n\n# Metadata filtering\nnotebook_metadata_filter = \"-all\"\ncell_metadata_filter = \"-all\"\n\n# Or selective filtering\n# notebook_metadata_filter = \"kernelspec,jupytext\"\n# cell_metadata_filter = \"tags,-all\"\n\n# Custom folder pairing\n[formats]\n\"notebooks/\" = \"ipynb,scripts//py:percent\"\n\"analysis/\" = \"ipynb,py:percent\"\n\n# R notebooks\n[formats.\"*.Rmd\"]\nformats = \"Rmd,ipynb\"\n```\n\n### Per-Notebook Configuration\n\nAdd to notebook metadata:\n\n```json\n{\n  \"jupytext\": {\n    \"formats\": \"ipynb,py:percent\",\n    \"notebook_metadata_filter\": \"-all\"\n  }\n}\n```\n\n## Format Selection Guide\n\n| Scenario | Recommended Format |\n|----------|-------------------|\n| Production data pipelines | py:percent |\n| Multi-kernel projects | py:percent, R:percent |\n| Documentation/tutorials | md:myst |\n| R-centric workflows | Rmd |\n| Quick exploration | py:light |\n| Publishing | qmd (Quarto) |\n| Git-friendly | py:percent with metadata filtering |\n",
        "skills/jupytext/references/kernels.md": "# Multi-Kernel Setup\n\n## Contents\n\n- [Available Kernels](#available-kernels)\n- [Python Kernel](#python-kernel)\n- [R Kernel](#r-kernel)\n- [Stata Kernel](#stata-kernel)\n- [SAS Kernel](#sas-kernel)\n- [Multi-Kernel Project Setup](#multi-kernel-project-setup)\n- [Kernel Management](#kernel-management)\n- [Troubleshooting](#troubleshooting)\n- [Best Practices](#best-practices)\n\nConfigure Jupyter kernels for Python, R, Stata, and SAS to enable cross-language data science workflows.\n\n## Available Kernels\n\n| Language | Kernel | Package | Notes |\n|----------|--------|---------|-------|\n| Python | `ipykernel` | `ipykernel` | Default, most mature |\n| Python | `xeus-python` | `xeus-python` | Debugger support |\n| R | `IRkernel` | `IRkernel` | Traditional R kernel |\n| R | `xeus-r` | `xeus-r` | Modern, xeus-based |\n| Stata | `stata_kernel` | `stata_kernel` | Requires Stata license |\n| Stata | `pystata` | `pystata` | Official Stata kernel |\n| SAS | `saspy` | `saspy` | Requires SAS installation |\n| SAS | `sas_kernel` | `sas_kernel` | Alternative SAS kernel |\n\n## Python Kernel\n\n### Standard IPython Kernel\n\n```bash\n# Install\npip install ipykernel\n\n# Register kernel\npython -m ipykernel install --user --name python3 --display-name \"Python 3\"\n\n# With specific environment\nconda activate myenv\npython -m ipykernel install --user --name myenv --display-name \"Python (myenv)\"\n```\n\n### Xeus Python (with Debugger)\n\n```bash\n# Install via conda (recommended)\nconda install -c conda-forge xeus-python\n\n# Or pip\npip install xeus-python\n```\n\n## R Kernel\n\n### IRkernel (Traditional)\n\n```r\n# In R console\ninstall.packages('IRkernel')\nIRkernel::installspec()\n\n# System-wide installation\nIRkernel::installspec(user = FALSE)\n\n# Custom name\nIRkernel::installspec(name = 'ir44', displayname = 'R 4.4')\n```\n\n### Xeus-R (Modern)\n\n```bash\n# Install via conda\nconda install -c conda-forge xeus-r\n\n# Verify installation\njupyter kernelspec list\n```\n\n### R Kernel Configuration\n\nCreate `~/.jupyter/kernels/ir/kernel.json`:\n\n```json\n{\n  \"argv\": [\"R\", \"--slave\", \"-e\", \"IRkernel::main()\", \"--args\", \"{connection_file}\"],\n  \"display_name\": \"R\",\n  \"language\": \"R\",\n  \"env\": {\n    \"R_LIBS_USER\": \"~/R/library\"\n  }\n}\n```\n\n## Stata Kernel\n\n### Option 1: stata_kernel (Community)\n\n```bash\n# Install\npip install stata_kernel\n\n# Configure (creates ~/.stata_kernel.conf)\npython -m stata_kernel.install\n\n# Verify Stata path in ~/.stata_kernel.conf\n```\n\nConfiguration file (`~/.stata_kernel.conf`):\n\n```ini\n[stata_kernel]\n# Path to Stata executable\nstata_path = /usr/local/stata17/stata-mp\n\n# Or on macOS\n# stata_path = /Applications/Stata/StataMP.app/Contents/MacOS/stata-mp\n\n# Graph settings\ngraph_format = svg\ngraph_width = 600\ngraph_height = 400\n```\n\n### Option 2: PyStata (Official)\n\nRequires Stata 17+ with Python integration enabled.\n\n```python\n# In Python\nimport stata_setup\nstata_setup.config(\"/usr/local/stata17\", \"mp\")\n\n# Register as Jupyter kernel\nfrom pystata import config\nconfig.init(\"mp\")\n```\n\n### Stata Kernel for Jupytext\n\n```stata\n* %% [markdown]\n* # Stata Analysis\n\n* %%\nsysuse auto, clear\nsummarize price mpg weight\n\n* %%\nregress price mpg weight foreign\n```\n\n## SAS Kernel\n\n### SASPy Setup\n\n```bash\n# Install\npip install saspy\n\n# Create configuration\nmkdir -p ~/.config/saspy\n```\n\nConfiguration file (`~/.config/saspy/sascfg_personal.py`):\n\n```python\nSAS_config_names = ['default']\n\ndefault = {\n    'saspath': '/opt/sas/SASFoundation/9.4/bin/sas_u8',\n    'options': ['-nodms'],\n    'encoding': 'utf-8'\n}\n\n# For SAS Viya\nviya = {\n    'ip': 'your-viya-server.com',\n    'port': 443,\n    'protocol': 'https',\n    'context': 'SAS Studio compute context'\n}\n```\n\n### SAS Kernel Registration\n\n```bash\n# Install sas_kernel\npip install sas_kernel\n\n# Register kernel\njupyter kernelspec install sas_kernel --user\n```\n\n### SAS Kernel for Jupytext\n\n```sas\n* %% [markdown];\n* # SAS Analysis;\n\n* %%;\nproc import datafile=\"data.csv\"\n    out=work.mydata\n    dbms=csv;\nrun;\n\n* %%;\nproc means data=work.mydata;\n    var x1 x2 y;\nrun;\n```\n\n## Multi-Kernel Project Setup\n\n### Directory Structure\n\n```\nproject/\n├── jupytext.toml\n├── environment.yml      # Conda environment with all kernels\n├── notebooks/\n│   ├── 01_python_prep.py    # Python percent format\n│   ├── 02_r_analysis.R      # R percent format\n│   ├── 03_stata_models.do   # Stata script\n│   └── 04_sas_reports.sas   # SAS script\n├── data/\n│   ├── raw/\n│   └── processed/\n└── results/\n```\n\n### Environment Configuration\n\n`environment.yml`:\n\n```yaml\nname: multikernel\nchannels:\n  - conda-forge\n  - defaults\ndependencies:\n  # Python\n  - python=3.11\n  - ipykernel\n  - pandas\n  - pyarrow\n  - jupytext\n\n  # R\n  - r-base=4.3\n  - r-irkernel\n  - r-tidyverse\n  - r-arrow\n\n  # Optional: xeus kernels\n  - xeus-python\n  - xeus-r\n\n  # Jupyter\n  - jupyterlab\n  - jupyter\n\n  # pip dependencies\n  - pip:\n    - stata_kernel  # If using Stata\n    - saspy         # If using SAS\n```\n\n### Kernel Selection in Jupytext\n\nSpecify kernel in file header:\n\n```python\n# ---\n# jupyter:\n#   kernelspec:\n#     display_name: Python 3\n#     language: python\n#     name: python3\n# ---\n\n# %% [markdown]\n# # Python Analysis\n```\n\n```r\n# ---\n# jupyter:\n#   kernelspec:\n#     display_name: R\n#     language: R\n#     name: ir\n# ---\n\n# %% [markdown]\n# # R Analysis\n```\n\n## Kernel Management\n\n### List Installed Kernels\n\n```bash\njupyter kernelspec list\n```\n\n### Remove Kernel\n\n```bash\njupyter kernelspec remove kernel_name\n```\n\n### Verify Kernel Works\n\n```bash\n# Python\npython -c \"import ipykernel; print('OK')\"\n\n# R\nRscript -e \"library(IRkernel); print('OK')\"\n\n# Stata (if stata_kernel installed)\npython -c \"import stata_kernel; print('OK')\"\n```\n\n## Troubleshooting\n\n### R Kernel Not Found\n\n```r\n# Reinstall IRkernel\ninstall.packages('IRkernel', repos='https://cloud.r-project.org')\nIRkernel::installspec(user = TRUE)\n```\n\n### Stata Kernel Connection Issues\n\n```bash\n# Check Stata path\nwhich stata-mp\n\n# Verify configuration\ncat ~/.stata_kernel.conf\n\n# Test Stata directly\nstata-mp -b -e \"display 'test'\"\n```\n\n### SAS Connection Timeout\n\n```python\n# In Python, test SASPy connection\nimport saspy\nsas = saspy.SASsession(cfgname='default')\nprint(sas.sasver())\nsas.endsas()\n```\n\n### Kernel Crashes on Import\n\n```bash\n# Check for conflicting packages\npip check\n\n# Reinstall kernel\npip uninstall ipykernel\npip install ipykernel\npython -m ipykernel install --user\n```\n\n## Best Practices\n\n1. **Use conda environments**: Isolate kernel dependencies\n2. **Version pin**: Lock kernel versions in environment.yml\n3. **Test kernels**: Verify each kernel works before starting project\n4. **Document requirements**: Note kernel versions in README\n5. **Use jupytext.toml**: Standardize format across team\n",
        "skills/look-at/README.md": "# Look At - Multimodal File Analysis Skill\n\nAnalyze media files (PDFs, images, diagrams) using Gemini 2.5 Flash Lite for fast, cost-effective interpretation.\n\n## Overview\n\nThe `look-at` skill provides a tool for analyzing files that require interpretation beyond raw text. It uses Google's Gemini API to extract specific information from documents, images, diagrams, and other media files while saving context tokens by only returning the extracted information.\n\n**Inspired by:** oh-my-opencode's `look_at` tool\n\n## Quick Start\n\n### 1. Install Dependencies\n\n```bash\npip install google-genai\n```\n\nOr add to your `pixi.toml`:\n```toml\n[dependencies]\ngoogle-genai = \">=1.0.0\"\n```\n\n### 2. Set API Key\n\nGet your API key from https://aistudio.google.com/app/apikey\n\n```bash\nexport GOOGLE_API_KEY=\"your-api-key-here\"\n```\n\nAdd to your shell profile for persistence:\n```bash\necho 'export GOOGLE_API_KEY=\"your-api-key-here\"' >> ~/.bashrc\n```\n\n### 3. Use the Skill\n\n```bash\npython3 ${CLAUDE_PLUGIN_ROOT}/skills/look-at/scripts/look_at.py \\\n    --file \"/path/to/file.pdf\" \\\n    --goal \"Extract the title and date\"\n```\n\n## When to Use\n\n✅ **Use look-at for:**\n- PDFs with complex layouts or visual elements\n- Images containing text, diagrams, or UI elements\n- Charts, graphs, and data visualizations\n- Architecture diagrams and flowcharts\n- Screenshots of applications or documents\n- Any file where you need specific extracted information, not full contents\n\n❌ **Don't use look-at for:**\n- Source code files (use Read tool)\n- Plain text files (use Read tool)\n- Files that need editing (use Read then Edit)\n- When you need exact file structure (YAML, JSON, config files)\n\n## Directory Structure\n\n```\nlook-at/\n├── SKILL.md              # Skill definition for Claude Code\n├── README.md             # This file\n├── requirements.txt      # Python dependencies\n├── scripts/\n│   └── look_at.py       # Main analysis script\n├── examples/\n│   ├── analyze_pdf.sh   # PDF extraction examples\n│   ├── describe_image.sh # Image analysis examples\n│   └── extract_table.sh  # Table extraction examples\n└── references/\n    ├── api-details.md   # Gemini API technical details\n    └── use-cases.md     # Common patterns and use cases\n```\n\n## Usage Examples\n\n### Extract from PDF\n```bash\npython3 scripts/look_at.py \\\n    --file \"/home/user/report.pdf\" \\\n    --goal \"Extract the executive summary section\"\n```\n\n### Describe Image\n```bash\npython3 scripts/look_at.py \\\n    --file \"/home/user/diagram.png\" \\\n    --goal \"Describe the system architecture and data flow\"\n```\n\n### Extract Table Data\n```bash\npython3 scripts/look_at.py \\\n    --file \"/home/user/data.pdf\" \\\n    --goal \"Extract the table as JSON: {name, value, date}\"\n```\n\n### With Custom Model\n```bash\npython3 scripts/look_at.py \\\n    --file \"/home/user/complex_doc.pdf\" \\\n    --goal \"Extract methodology section\" \\\n    --model \"gemini-2.5-flash\"\n```\n\n## Model Options\n\n| Model | Best For | Speed | Cost |\n|-------|----------|-------|------|\n| gemini-2.5-flash-lite | Most tasks (default) | Fastest | Lowest |\n| gemini-2.5-flash | Complex extraction | Fast | Low |\n| gemini-1.5-pro | Highest accuracy | Medium | Medium |\n\n## Features\n\n- **Context Token Savings:** Only extracts requested information, not full file contents\n- **Cost Effective:** Uses Gemini 2.5 Flash Lite by default (~50% cheaper than standard)\n- **Fast:** Typical response in 2-5 seconds for small files\n- **Flexible:** Supports images, videos, audio, PDFs, and text documents\n- **Automatic Cleanup:** Uploaded files are deleted after analysis\n\n## Troubleshooting\n\n### API Key Not Set\n```bash\nError: GOOGLE_API_KEY environment variable not set\n```\n**Solution:** Export your API key as shown in setup\n\n### Package Not Installed\n```bash\nModuleNotFoundError: No module named 'google'\n```\n**Solution:** Install with `pip install google-genai`\n\n### File Not Found\n```bash\nError: File not found: /path/to/file.pdf\n```\n**Solution:** Use absolute paths and verify file exists\n\n### Rate Limit Errors\n```bash\nError: Rate limit exceeded\n```\n**Solution:** Wait a few seconds and retry, or implement exponential backoff\n\n## Cost Optimization\n\n1. **Use Flash Lite:** Default model is optimal for most tasks\n2. **Be Specific:** Clear goals = fewer tokens = lower cost\n3. **Extract Once:** Cache results to avoid re-processing\n4. **Right Tool:** Use Read tool for plain text to avoid API costs\n\n## Comparison with oh-my-opencode\n\nThis skill is inspired by oh-my-opencode's `look_at` tool:\n\n| Feature | oh-my-opencode | This Skill |\n|---------|----------------|------------|\n| Architecture | Child session + agent | Direct API call |\n| Model | Configurable Gemini | Gemini 2.5 Flash Lite |\n| File Handling | File passthrough | Upload to API |\n| Tool Restrictions | Disables task/read/etc | N/A (direct call) |\n| Context Isolation | Full session isolation | Single API call |\n\nBoth achieve the same goal: offload file analysis to a fast, cheap model to extract specific information without loading full files into the main conversation context.\n\n## Related Skills\n\n- `/gemini-batch` - For batch processing many files\n- Standard Read tool - For text files needing exact contents\n- `/jupytext` - For working with Jupyter notebooks\n- `/marimo` - For marimo reactive notebooks\n\n## Further Reading\n\n- [SKILL.md](SKILL.md) - Full skill documentation\n- [references/api-details.md](references/api-details.md) - Gemini API technical details\n- [references/use-cases.md](references/use-cases.md) - Common patterns and examples\n- [Gemini API Documentation](https://ai.google.dev/docs)\n\n## License\n\nPart of the workflows plugin for Claude Code.\n",
        "skills/look-at/SKILL.md": "---\nname: look-at\nversion: 1.0\ndescription: \"This skill should be used when the user asks to 'look at', 'analyze', 'describe', 'extract from', or 'what's in' media files like PDFs, images, diagrams, screenshots, or charts. Triggers include: 'what does this image show', 'extract the table from this PDF', 'describe this diagram', 'what's in this screenshot', 'analyze this chart', 'read this image', 'get text from this PDF', 'summarize this document', or requests for specific data extraction from visual or document files. Use when analyzed/interpreted content is needed rather than literal file reading (which uses Read tool).\"\n---\n\n# Look At - Multimodal File Analysis\n\nFast, cost-effective file analysis using Google's Gemini 2.5 Flash Lite model for PDFs, images, diagrams, and other media files.\n\n## Tool Selection Enforcement\n\n### Rationalization Table - STOP When Thinking:\n\n| Excuse | Reality | Do Instead |\n|--------|---------|------------|\n| \"I can read images directly with Read\" | You'll waste thousands of context tokens showing the full image | Use look_at for analysis |\n| \"I'll use Read for this PDF\" | You'll lose table structure and visual information by extracting raw text | Use look_at for PDFs with tables/charts/diagrams |\n| \"Just a quick glance at the file\" | Your quick glances still consume full context tokens | Use look_at for targeted extraction |\n| \"I need exact text, so Read is required\" | Gemini's extraction is accurate for most use cases | Use look_at first, Read only if extraction insufficient |\n| \"look_at adds complexity\" | You gain context savings and faster processing | Use look_at for media files |\n| \"The file is small\" | Your small files still waste context if uninterpreted | Size doesn't determine tool choice, content type does |\n| \"I'll process it myself\" | You waste reasoning tokens on trivial extraction | Delegate to look_at |\n\n### Red Flags - STOP Immediately When Thinking:\n\n- If you catch yourself thinking \"Let me Read this image/PDF/screenshot\" → STOP. Use look_at for media files.\n- If you catch yourself thinking \"I can see the image directly\" → STOP. Seeing it directly still wastes context. Use look_at.\n- If you catch yourself thinking \"Just need to glance at this diagram\" → STOP. Glancing still costs context tokens. Use look_at.\n- If you catch yourself thinking \"The PDF is text-based, so Read is fine\" → STOP. If it has structure/tables/charts, use look_at.\n\n### Cost & Context Benefits\n\n| Scenario | Read Tool | look_at Tool |\n|----------|-----------|--------------|\n| **PDF with table** | Extracts raw text (~1000 tokens), loses table structure | Extracts table as structured data (~100 tokens) |\n| **Screenshot** | Loads entire image (~500 tokens), requires interpretation | Describes content (~50 tokens) |\n| **Diagram** | Shows image (~800 tokens), requires analysis | Explains architecture (~100 tokens) |\n| **Multi-page PDF** | All pages loaded (~5000 tokens) | Extracts specific sections (~200 tokens) |\n\n**look_at saves 80-95% of context tokens by extracting only relevant information.**\n\n## When to Use\n\n**Use look_at when you need:**\n- Media files the Read tool cannot interpret\n- Extracting specific information or summaries from documents\n- Describing visual content in images or diagrams\n- Analyzing charts, tables, or structured data in PDFs\n- When analyzed/extracted data is needed, not raw file contents\n\n**Never use look_at when:**\n- Source code or plain text files needing exact contents (use Read)\n- Files that need editing afterward (need literal content from Read)\n- Simple file reading where no interpretation is needed\n- Exact formatting or structure must be preserved\n\n## How It Works\n\n1. Provide a file path and a specific goal (what to extract)\n2. The helper script uploads the file to Gemini's API\n3. Gemini 2.5 Flash Lite analyzes the file and extracts requested information\n4. Only the relevant extracted information is returned (saves context tokens)\n\n## Usage Pattern\n\n**CRITICAL - Display Requirement:**\nAlways set the Bash tool `description` parameter to show a clean invocation:\n```\ndescription: \"look-at: [goal text]\"\n```\n\nNever display the full Python command to the user.\n\n```bash\n# Basic usage\npython3 ${CLAUDE_PLUGIN_ROOT}/skills/look-at/scripts/look_at.py \\\n    --file \"/path/to/file.pdf\" \\\n    --goal \"Extract the title and date from this document\"\n\n# With custom model\npython3 ${CLAUDE_PLUGIN_ROOT}/skills/look-at/scripts/look_at.py \\\n    --file \"/path/to/diagram.png\" \\\n    --goal \"Describe the architecture shown in this diagram\" \\\n    --model \"gemini-2.5-flash\"\n```\n\n**IMPORTANT:**\n- Always use absolute paths for files\n- Always set Bash tool `description` to `\"look-at: [goal]\"` for clean UX\n\n## Response Rules\n\nWhen using look_at, the response includes:\n- Only the extracted information matching the goal\n- Clear statement if requested information is not found\n- Concise output focused on the goal (no preamble)\n\nUse this extracted information directly in continued work without loading the full file into context.\n\n## Supported File Types\n\n| Type | Extensions | MIME Types |\n|------|-----------|------------|\n| Images | .jpg, .jpeg, .png, .webp, .heic, .heif | image/* |\n| Videos | .mp4, .mpeg, .mov, .avi, .webm | video/* |\n| Audio | .wav, .mp3, .aiff, .aac, .ogg, .flac | audio/* |\n| Documents | .pdf, .txt, .csv, .md, .html | application/pdf, text/* |\n\n## Model Options\n\n| Model | Use Case | Speed | Cost |\n|-------|----------|-------|------|\n| `gemini-2.5-flash-lite` | Default - fast, cheap analysis | Fastest | Lowest |\n| `gemini-3-flash` | More complex extraction needs | Fast | Low |\n| `gemini-3-pro-preview` | Highest accuracy required | Medium | Medium |\n\n**Default is gemini-2.5-flash-lite** for optimal speed/cost ratio.\n\n## Common Patterns\n\n**REMEMBER:** Always use `description: \"look-at: [goal]\"` in the Bash tool call.\n\n### Extract Specific Information\n```bash\n# Bash tool call with:\n# description: \"look-at: Extract the executive summary section\"\npython3 ${CLAUDE_PLUGIN_ROOT}/skills/look-at/scripts/look_at.py \\\n    --file \"report.pdf\" \\\n    --goal \"Extract the executive summary section\"\n```\n\n### Describe Visual Content\n```bash\n# Bash tool call with:\n# description: \"look-at: List all UI elements and their layout\"\npython3 ${CLAUDE_PLUGIN_ROOT}/skills/look-at/scripts/look_at.py \\\n    --file \"screenshot.png\" \\\n    --goal \"List all UI elements and their layout\"\n```\n\n### Analyze Diagrams\n```bash\n# Bash tool call with:\n# description: \"look-at: Explain the data flow and component relationships\"\npython3 ${CLAUDE_PLUGIN_ROOT}/skills/look-at/scripts/look_at.py \\\n    --file \"architecture.png\" \\\n    --goal \"Explain the data flow and component relationships\"\n```\n\n### Extract Structured Data\n```bash\n# Bash tool call with:\n# description: \"look-at: Extract the table data as JSON\"\npython3 ${CLAUDE_PLUGIN_ROOT}/skills/look-at/scripts/look_at.py \\\n    --file \"table.pdf\" \\\n    --goal \"Extract the table data as JSON with columns: name, value, date\"\n```\n\n## Environment Setup\n\n**Required environment variable:**\n```bash\nexport GOOGLE_API_KEY=\"your-api-key-here\"\n```\n\n**Required Python package:**\n```bash\npip install google-genai\n```\n\nFor pixi-managed projects, add to `pixi.toml`:\n```toml\n[dependencies]\ngoogle-genai = \">=1.0.0\"\n```\n\n## Cost Optimization\n\n- **Gemini 2.5 Flash Lite** is the most cost-effective option\n- Only extracts requested information (saves on output tokens)\n- Avoids loading full files into main conversation context\n- Use specific goals to minimize unnecessary processing\n\n## Troubleshooting\n\n| Issue | Solution |\n|-------|----------|\n| API key not set | Set `GOOGLE_API_KEY` environment variable |\n| File not found | Use absolute paths, verify file exists |\n| Large file timeout | Break into smaller files or use lower-quality images |\n| Rate limit errors | Add retry logic or use batch processing |\n| Empty response | Check that goal is clear and specific |\n\n## Examples\n\nSee `examples/` directory for:\n- `analyze_pdf.sh` - PDF document extraction\n- `describe_image.sh` - Image analysis\n- `extract_table.sh` - Structured data extraction\n\n## Related Skills\n\n- `/gemini-batch` - For batch processing of many files\n- Standard `Read` tool - For text files needing exact contents\n",
        "skills/look-at/references/api-details.md": "# Gemini API Details for Look At\n\n## API Configuration\n\nThe look_at skill uses the new unified Google Generative AI Python SDK (`google-genai`) to interact with Gemini models.\n\n### Authentication\n\n```python\nfrom google import genai\n\napi_key = os.environ.get(\"GOOGLE_API_KEY\")\nclient = genai.Client(api_key=api_key)\n```\n\n**Get your API key:** https://aistudio.google.com/app/apikey\n\n### File Upload\n\n```python\n# Upload local file\nwith open(file_path, 'rb') as f:\n    uploaded_file = client.files.upload(file=f, config={'mime_type': mime_type})\n\n# Use in generation\nresponse = client.models.generate_content(\n    model=\"gemini-2.5-flash-lite\",\n    contents=[uploaded_file, prompt]\n)\n\n# Clean up\nclient.files.delete(name=uploaded_file.name)\n```\n\n## Model Selection\n\n### Gemini 2.5 Flash Lite (Default)\n- **Best for:** Most use cases, fastest response, lowest cost\n- **Strengths:** Fast multimodal analysis, good for images/PDFs\n- **Limitations:** May miss subtle details in complex documents\n- **Cost:** ~50% cheaper than Flash\n\n### Gemini 3 Flash\n- **Best for:** More complex extraction tasks\n- **Strengths:** Better accuracy, handles nuanced requests\n- **Limitations:** Slightly slower and more expensive\n- **Cost:** Standard pricing\n\n### Gemini 3 Pro\n- **Best for:** Highest accuracy requirements\n- **Strengths:** Best for complex reasoning, large documents\n- **Limitations:** Slower, more expensive\n- **Cost:** ~3-4x more than Flash Lite\n\n## Supported MIME Types\n\n### Images\n- `image/jpeg` (.jpg, .jpeg)\n- `image/png` (.png)\n- `image/webp` (.webp)\n- `image/heic` (.heic, .heif)\n- `image/gif` (.gif)\n\n### Videos\n- `video/mp4` (.mp4)\n- `video/mpeg` (.mpeg, .mpg)\n- `video/mov` (.mov)\n- `video/avi` (.avi)\n- `video/webm` (.webm)\n\n### Audio\n- `audio/wav` (.wav)\n- `audio/mp3` (.mp3)\n- `audio/aiff` (.aiff)\n- `audio/aac` (.aac)\n- `audio/ogg` (.ogg)\n- `audio/flac` (.flac)\n\n### Documents\n- `application/pdf` (.pdf)\n- `text/plain` (.txt)\n- `text/csv` (.csv)\n- `text/markdown` (.md)\n- `text/html` (.html, .htm)\n\n## Rate Limits\n\n**Standard API Limits:**\n- 60 requests per minute\n- 1,000 requests per day (free tier)\n- 10,000 requests per day (paid tier)\n\n**File Upload Limits:**\n- Max file size: 20MB (Flash Lite)\n- Max file size: 50MB (Flash/Pro)\n- Files are automatically deleted after processing\n\n## Error Handling\n\n### Common Errors\n\n| Error | Cause | Solution |\n|-------|-------|----------|\n| `GOOGLE_API_KEY not set` | Missing API key | Set environment variable |\n| `File not found` | Invalid file path | Use absolute paths |\n| `Invalid MIME type` | Unsupported format | Convert to supported format |\n| `Rate limit exceeded` | Too many requests | Add retry with backoff |\n| `File too large` | Exceeds size limit | Compress or split file |\n\n### Retry Logic Example\n\n```python\nimport time\n\ndef analyze_with_retry(file_path, goal, max_retries=3):\n    for attempt in range(max_retries):\n        try:\n            return analyze_file(file_path, goal)\n        except Exception as e:\n            if \"rate limit\" in str(e).lower() and attempt < max_retries - 1:\n                wait_time = 2 ** attempt  # Exponential backoff\n                print(f\"Rate limit hit, waiting {wait_time}s...\")\n                time.sleep(wait_time)\n            else:\n                raise\n```\n\n## Best Practices\n\n### 1. Specific Goals\n**Bad:** \"Analyze this document\"\n**Good:** \"Extract the revenue figure for Q4 2023\"\n\n### 2. Absolute Paths\n```python\n# Bad\nanalyze_file(\"./report.pdf\", \"Extract title\")\n\n# Good\nanalyze_file(\"/home/user/documents/report.pdf\", \"Extract title\")\n```\n\n### 3. File Cleanup\nAlways clean up uploaded files, even on errors:\n```python\ntry:\n    response = model.generate_content([uploaded_file, prompt])\nfinally:\n    genai.delete_file(uploaded_file.name)\n```\n\n### 4. Cost Optimization\n- Use Flash Lite for most tasks\n- Be specific in goals to minimize output tokens\n- Batch similar requests together\n- Cache frequently analyzed files\n\n## Performance Benchmarks\n\n**Typical Response Times:**\n- Small PDF (1-5 pages): 2-5 seconds\n- Medium PDF (10-20 pages): 5-10 seconds\n- Image (< 5MB): 1-3 seconds\n- Large PDF (50+ pages): 15-30 seconds\n\n**Token Usage:**\n- Input: ~265 tokens per uploaded image\n- Input: ~1,000 tokens per PDF page (approximate)\n- Output: Varies by goal specificity\n\n## External Resources\n\n- [Gemini API Documentation](https://ai.google.dev/docs)\n- [Python SDK Reference](https://ai.google.dev/api/python/google/generativeai)\n- [File API Guide](https://ai.google.dev/gemini-api/docs/vision)\n- [Pricing Information](https://ai.google.dev/pricing)\n",
        "skills/look-at/references/use-cases.md": "# Common Use Cases for Look At\n\n## When to Use Look At vs Read Tool\n\n### Use Look At When:\n- ✅ File contains visual information (diagrams, charts, images)\n- ✅ Need to extract specific information from a large document\n- ✅ File format requires interpretation (PDF with complex layouts)\n- ✅ Need description of visual content\n- ✅ Want to save context tokens by only getting extracted data\n\n### Use Read Tool When:\n- ✅ Need exact file contents\n- ✅ Working with source code or plain text\n- ✅ Need to edit the file afterward\n- ✅ File structure is important (YAML, JSON, code)\n- ✅ Need to see everything, not just specific parts\n\n## Document Analysis\n\n### Research Papers\n```bash\n# Extract methodology section\npython3 look_at.py --file paper.pdf \\\n    --goal \"Extract the methodology section, including sample size and statistical methods\"\n\n# Extract findings\npython3 look_at.py --file paper.pdf \\\n    --goal \"List the main findings and conclusions\"\n\n# Extract citations for a specific topic\npython3 look_at.py --file paper.pdf \\\n    --goal \"List all citations related to machine learning methods\"\n```\n\n### Financial Reports\n```bash\n# Extract key metrics\npython3 look_at.py --file quarterly_report.pdf \\\n    --goal \"Extract revenue, profit margin, and YoY growth percentages\"\n\n# Summarize risks\npython3 look_at.py --file 10k_filing.pdf \\\n    --goal \"Summarize the top 3 risk factors mentioned\"\n\n# Extract balance sheet data\npython3 look_at.py --file financial_statements.pdf \\\n    --goal \"Extract total assets, liabilities, and equity as JSON\"\n```\n\n### Contracts and Legal Documents\n```bash\n# Extract key terms\npython3 look_at.py --file contract.pdf \\\n    --goal \"Extract payment terms, termination clause, and effective date\"\n\n# Identify obligations\npython3 look_at.py --file agreement.pdf \\\n    --goal \"List all obligations for Party A\"\n\n# Extract definitions\npython3 look_at.py --file legal_doc.pdf \\\n    --goal \"Extract all defined terms and their definitions\"\n```\n\n## Image Analysis\n\n### UI/UX Screenshots\n```bash\n# Inventory UI elements\npython3 look_at.py --file app_screenshot.png \\\n    --goal \"List all buttons, text fields, and navigation elements with their labels\"\n\n# Describe layout\npython3 look_at.py --file wireframe.png \\\n    --goal \"Describe the layout structure: header, sidebar, main content, footer\"\n\n# Identify accessibility issues\npython3 look_at.py --file interface.png \\\n    --goal \"Identify potential accessibility issues: contrast, button sizes, text legibility\"\n```\n\n### Architecture Diagrams\n```bash\n# Explain system design\npython3 look_at.py --file system_diagram.png \\\n    --goal \"Explain the data flow between components and their relationships\"\n\n# List components\npython3 look_at.py --file architecture.png \\\n    --goal \"List all components/services shown and their responsibilities\"\n\n# Identify bottlenecks\npython3 look_at.py --file performance_diagram.png \\\n    --goal \"Identify potential bottlenecks or single points of failure\"\n```\n\n### Charts and Graphs\n```bash\n# Extract data points\npython3 look_at.py --file line_chart.png \\\n    --goal \"Extract the data points for each line series as JSON\"\n\n# Describe trends\npython3 look_at.py --file sales_chart.png \\\n    --goal \"Describe the main trends and any notable patterns or anomalies\"\n\n# Extract legend\npython3 look_at.py --file complex_chart.png \\\n    --goal \"List what each color/line represents according to the legend\"\n```\n\n## Data Extraction\n\n### Tables\n```bash\n# Full table extraction\npython3 look_at.py --file data_table.pdf \\\n    --goal \"Extract the entire table as JSON array with all columns preserved\"\n\n# Filtered extraction\npython3 look_at.py --file large_table.pdf \\\n    --goal \"Extract only rows where Status = 'Active' as CSV\"\n\n# Summary statistics\npython3 look_at.py --file spreadsheet.png \\\n    --goal \"Calculate and report: sum, average, min, max for the 'Amount' column\"\n```\n\n### Forms\n```bash\n# Extract filled values\npython3 look_at.py --file filled_form.pdf \\\n    --goal \"Extract all filled-in values with their corresponding field labels\"\n\n# Identify missing fields\npython3 look_at.py --file incomplete_form.pdf \\\n    --goal \"List all empty/unfilled fields\"\n\n# Convert to structured data\npython3 look_at.py --file application_form.pdf \\\n    --goal \"Extract as JSON: {name, email, phone, address, date_submitted}\"\n```\n\n## Code and Technical Documentation\n\n### API Documentation Screenshots\n```bash\n# Extract endpoint details\npython3 look_at.py --file api_docs.png \\\n    --goal \"Extract all API endpoints with their methods, paths, and descriptions\"\n\n# Extract request/response examples\npython3 look_at.py --file api_example.png \\\n    --goal \"Extract the request and response JSON examples shown\"\n```\n\n### Whiteboards and Sketches\n```bash\n# Transcribe whiteboard session\npython3 look_at.py --file whiteboard.jpg \\\n    --goal \"Transcribe all text and describe any diagrams or sketches\"\n\n# Extract action items\npython3 look_at.py --file meeting_notes.jpg \\\n    --goal \"Extract all action items with assigned owners if visible\"\n```\n\n### Database Schemas\n```bash\n# Extract table definitions\npython3 look_at.py --file db_schema.png \\\n    --goal \"List all tables with their columns, types, and relationships\"\n\n# Identify relationships\npython3 look_at.py --file erd_diagram.png \\\n    --goal \"Describe all foreign key relationships and their cardinality\"\n```\n\n## Media Analysis\n\n### Video Frames\n```bash\n# Analyze key frame\npython3 look_at.py --file video_frame.jpg \\\n    --goal \"Describe what's happening in this frame: people, actions, objects\"\n\n# Extract visible text\npython3 look_at.py --file presentation_slide.mp4 \\\n    --goal \"Extract all text visible on the slide\"\n```\n\n### Presentations\n```bash\n# Extract slide content\npython3 look_at.py --file slide_deck.pdf \\\n    --goal \"Extract title and main points from slides 5-10\"\n\n# Create outline\npython3 look_at.py --file presentation.pdf \\\n    --goal \"Create an outline of the entire presentation with section headings\"\n```\n\n## Advanced Patterns\n\n### Comparative Analysis\n```bash\n# Compare two diagrams\npython3 look_at.py --file version1.png \\\n    --goal \"List all components and connections\"\n\npython3 look_at.py --file version2.png \\\n    --goal \"List all components and connections\"\n\n# Then use Claude to compare the extracted information\n```\n\n### Multi-step Extraction\n```bash\n# Step 1: Identify sections\npython3 look_at.py --file document.pdf \\\n    --goal \"List all section headings with page numbers\"\n\n# Step 2: Extract specific section\npython3 look_at.py --file document.pdf \\\n    --goal \"Extract only the 'Results' section on pages 12-15\"\n```\n\n### Validation\n```bash\n# Verify data quality\npython3 look_at.py --file data_report.pdf \\\n    --goal \"Check if all required fields are present: date, amount, signature\"\n\n# Cross-reference\npython3 look_at.py --file invoice.pdf \\\n    --goal \"Extract invoice number and total amount for verification\"\n```\n\n## Anti-Patterns (Don't Do This)\n\n### ❌ Too Vague\n```bash\n# Bad: Too general\npython3 look_at.py --file doc.pdf --goal \"Tell me about this document\"\n\n# Good: Specific request\npython3 look_at.py --file doc.pdf --goal \"Extract the author, date, and main conclusion\"\n```\n\n### ❌ Asking for Everything\n```bash\n# Bad: Requesting full content\npython3 look_at.py --file book.pdf --goal \"Extract all text from this book\"\n\n# Good: Extract what you need\npython3 look_at.py --file book.pdf --goal \"Extract the table of contents\"\n```\n\n### ❌ Using for Plain Text\n```bash\n# Bad: Using look_at for source code\npython3 look_at.py --file script.py --goal \"Show me the code\"\n\n# Good: Use Read tool instead\ncat script.py\n```\n\n### ❌ Relative Paths\n```bash\n# Bad: Relative path\npython3 look_at.py --file ../docs/report.pdf --goal \"Extract title\"\n\n# Good: Absolute path\npython3 look_at.py --file /home/user/docs/report.pdf --goal \"Extract title\"\n```\n\n## Cost Optimization Tips\n\n1. **Be Specific:** Narrow goals = fewer output tokens = lower cost\n2. **Batch Similar Requests:** Process multiple files in sequence\n3. **Use Flash Lite:** Default model is optimal for most use cases\n4. **Cache Insights:** Save extracted data to avoid re-processing\n5. **Preprocess Large Files:** Split or compress before analysis\n\n## Integration with Workflows\n\n### Data Science Workflow\n```bash\n# In exploration phase, analyze data documentation\npython3 look_at.py --file data_dictionary.pdf \\\n    --goal \"Extract all column names, types, and descriptions as JSON\"\n```\n\n### Development Workflow\n```bash\n# Analyze design mockups\npython3 look_at.py --file mockup.png \\\n    --goal \"List all UI components that need to be implemented\"\n```\n\n### Writing Workflow\n```bash\n# Extract quotes from source material\npython3 look_at.py --file research_paper.pdf \\\n    --goal \"Extract all quotes related to climate change impacts\"\n```\n",
        "skills/lseg-data/SKILL.md": "---\nname: lseg-data\nversion: 1.0\ndescription: This skill should be used when the user asks to “access LSEG data”, “query Refinitiv”, “get market data from Refinitiv”, “download fundamentals from LSEG”, “access ESG scores”, “convert RIC to ISIN”, “get shareholder activism data”, “query poison pills”, “access corporate governance data”, “find activist campaigns”, “get syndicated loans data”, “query loan deals”, “get infrastructure projects”, “query project finance data”, “get private equity data”, “query VC investments”, “find PE-backed companies”, “get M&A data”, “query mergers and acquisitions”, “find acquisition deals”, “get IPO data”, “query equity offerings”, “find new issues”, “get joint venture data”, “query strategic alliances”, “get news headlines”, “query news data”, “fetch news articles”, or needs the LSEG Data Library Python API.\n---\n\n## Contents\n\n- [Query Enforcement](#query-enforcement)\n- [Quick Start](#quick-start)\n- [Authentication](#authentication)\n- [Core APIs](#core-apis)\n- [Key Field Prefixes](#key-field-prefixes)\n- [RIC Symbology](#ric-symbology)\n- [Rate Limits](#rate-limits)\n- [Additional Resources](#additional-resources)\n\n# LSEG Data Library\n\nAccess financial data from LSEG (London Stock Exchange Group), formerly Refinitiv, via the `lseg.data` Python library.\n\n## Query Enforcement\n\n### IRON LAW: NO DATA CLAIM WITHOUT SAMPLE INSPECTION\n\nBefore claiming ANY LSEG query succeeded, follow these steps:\n1. **VALIDATE** field names exist (check prefixes: TR., CF_)\n2. **VALIDATE** RIC symbology is correct (.O, .N, .L, .T)\n3. **EXECUTE** the query\n4. **INSPECT** sample rows with `.head()` or `.sample()`\n5. **VERIFY** critical columns are not NULL\n6. **VERIFY** date range matches expectations\n7. **CLAIM** success only after all checks pass\n\nThis is not negotiable. Claiming data retrieval without inspecting results is LYING to the user about data quality.\n\n### Rationalization Table - STOP If You Think:\n\n| Excuse | Reality | Do Instead |\n|--------|---------|------------|\n| “The query returned data, so it worked” | Returned data ≠ correct data | INSPECT for NULLs, wrong dates, invalid values |\n| “User gave me the RIC” | Users often use wrong suffixes | VERIFY symbology against RIC Symbology section |\n| “I’ll let pandas handle missing data” | You’ll propagate bad data downstream | CHECK for NULLs BEFORE returning |\n| “Field names look right” | Typos are common (TR.EPS vs TR.Eps) | VALIDATE field names in documentation first |\n| “Just a quick test” | Test queries teach bad habits | Full validation even for tests |\n| “I can check the data later” | You won’t | Inspection is MANDATORY before claiming success |\n| “Rate limits don’t matter for small queries” | Small queries add up | CHECK rate limits section, use batching |\n\n### Red Flags - STOP Immediately If You Think:\n\n- “Let me run this and see what happens” → NO. Validate field names and RICs FIRST.\n- “The API will error if something is wrong” → NO. API returns empty results, not errors.\n- “I’ll just return the dataframe to the user” → NO. Inspect sample BEFORE returning.\n- “Market data is always up-to-date” → NO. Check Date Awareness section (T-1 lag).\n\n### Data Validation Checklist\n\nBefore EVERY data retrieval claim, verify the following:\n\n**For `ld.get_data()` (fundamentals/ESG):**\n- [ ] Field names use correct prefix (TR. for Refinitiv)\n- [ ] RIC symbology verified (correct exchange suffix)\n- [ ] Result inspection: `.head()` or `.sample()` executed\n- [ ] NULL check on critical fields (e.g., revenue, EPS)\n- [ ] Row count verification (is result size reasonable?)\n- [ ] Date context verified (fiscal periods, as-of dates)\n\n**For `ld.get_history()` (time series):**\n- [ ] Field names are valid (OPEN, HIGH, LOW, CLOSE, VOLUME, or CF_ prefixes)\n- [ ] Start/end dates specified explicitly\n- [ ] Date range adjusted for T-1 availability (market data lag)\n- [ ] Result inspection: check first and last rows\n- [ ] NULL check on OHLCV fields\n- [ ] Date continuity check (gaps in trading days expected, but not in date sequence)\n\n**For `symbol_conversion.Definition()` (mapping):**\n- [ ] Input identifier type specified correctly\n- [ ] Result inspection: verify mapped values exist\n- [ ] NULL check (some securities may not have all identifiers)\n\n**For ALL queries:**\n- [ ] Rate limits considered (batch if >10k data points)\n- [ ] Session management: `open_session()` at start, `close_session()` at end\n- [ ] Error handling: try/except for network failures\n- [ ] Sample inspection BEFORE claiming data is ready\n\n## Quick Start\n\nTo get started with LSEG Data Library, initialize a session and execute queries:\n\n```python\nimport lseg.data as ld\n\n# Initialize session\nld.open_session()\n\n# Get fundamentals\ndf = ld.get_data(\n    universe=[‘AAPL.O’, ‘MSFT.O’],\n    fields=[‘TR.CompanyName’, ‘TR.Revenue’, ‘TR.EPS’]\n)\nprint(df.head())  # Inspect sample data\n\n# Get historical prices\nprices = ld.get_history(\n    universe=’AAPL.O’,\n    fields=[‘OPEN’, ‘HIGH’, ‘LOW’, ‘CLOSE’, ‘VOLUME’],\n    start=‘2023-01-01’,\n    end=‘2023-12-31’\n)\nprint(prices.head())  # Inspect sample data\n\n# Close session\nld.close_session()\n```\n\n## Authentication\n\nConfigure LSEG authentication using either a config file or environment variables.\n\n### Config File Method\n\nCreate `lseg-data.config.json`:\n```json\n{\n  “sessions”: {\n    “default”: “platform.ldp”,\n    “platform”: {\n      “ldp”: {\n        “app-key”: “YOUR_APP_KEY”,\n        “username”: “YOUR_MACHINE_ID”,\n        “password”: “YOUR_PASSWORD”\n      }\n    }\n  }\n}\n```\n\n### Environment Variables Method\n\nSet the following environment variables for LSEG authentication:\n\n```bash\n# Configure LSEG credentials via environment variables\nexport RDP_USERNAME=”YOUR_MACHINE_ID”\nexport RDP_PASSWORD=”YOUR_PASSWORD”\nexport RDP_APP_KEY=”YOUR_APP_KEY”\n```\n\n## Core APIs\n\n| API | Use Case | Example |\n|-----|----------|---------|\n| `ld.get_data()` | Point-in-time data | Fundamentals, ESG scores |\n| `ld.get_history()` | Time series | Historical prices, OHLCV |\n| `ld.news.get_headlines()` | News headlines | Company news, topic filtering |\n| `symbol_conversion.Definition()` | ID mapping | RIC ↔ ISIN ↔ CUSIP |\n\n## Key Field Prefixes\n\n| Prefix | Type | Example |\n|--------|------|---------|\n| `TR.` | Refinitiv fields | `TR.Revenue`, `TR.EPS` |\n| `TR.MnA` | Mergers & Acquisitions | `TR.MnAAcquirorName`, `TR.MnADealValue` |\n| `TR.NI` | Equity/New Issues (IPOs) | `TR.NIIssuer`, `TR.NIOfferPrice` |\n| `TR.JV` | Joint Ventures/Alliances | `TR.JVDealName`, `TR.JVStatus` |\n| `TR.SACT` | Shareholder Activism | `TR.SACTLeadDissident` |\n| `TR.PP` | Poison Pills | `TR.PPPillAdoptionDate` |\n| `TR.LN` | Syndicated Loans | `TR.LNTotalFacilityAmount` |\n| `TR.PJF` | Infrastructure/Project Finance | `TR.PJFProjectName` |\n| `TR.PEInvest` | Private Equity/Venture Capital | `TR.PEInvestRoundDate` |\n| `TR.Muni` | Municipal Bonds | `TR.MuniIssuerName` |\n| `CF_` | Composite (real-time) | `CF_LAST`, `CF_BID` |\n\n## RIC Symbology\n\n| Suffix | Exchange | Example |\n|--------|----------|---------|\n| `.O` | NASDAQ | `AAPL.O` |\n| `.N` | NYSE | `IBM.N` |\n| `.L` | London | `VOD.L` |\n| `.T` | Tokyo | `7203.T` |\n\n## Rate Limits\n\n| Endpoint | Limit |\n|----------|-------|\n| `get_data()` | 10,000 data points/request |\n| `get_history()` | 3,000 rows/request |\n| Session | 500 requests/minute |\n\n## Additional Resources\n\n### Reference Files\n\n- **`references/fundamentals.md`** - Financial statement fields, ratios, estimates\n- **`references/esg.md`** - ESG scores, pillars, controversies\n- **`references/symbology.md`** - RIC/ISIN/CUSIP conversion\n- **`references/pricing.md`** - Historical prices, real-time data\n- **`references/screening.md`** - Stock screening with Screener object\n- **`references/news.md`** - News headlines, pagination, query syntax\n- **`references/mna.md`** - Mergers & acquisitions deals (SDC Platinum, 2,683 fields)\n- **`references/equity-new-issues.md`** - IPOs, follow-ons, equity offerings (SDC Platinum, 1,708 fields)\n- **`references/joint-ventures.md`** - Joint ventures, strategic alliances (SDC Platinum, 301 fields)\n- **`references/corporate-governance.md`** - Shareholder activism, poison pills (SDC Platinum)\n- **`references/syndicated-loans.md`** - Syndicated loan deals (SDC Platinum)\n- **`references/infrastructure.md`** - Infrastructure/project finance deals (SDC Platinum)\n- **`references/private-equity.md`** - Private equity/venture capital investments (SDC Platinum)\n- **`references/municipal-bonds.md`** - Municipal bond issuances (SDC Platinum)\n- **`references/api-discovery.md`** - Reverse-engineering APIs via CDP network monitoring\n- **`references/troubleshooting.md`** - Common issues and solutions\n- **`references/wrds-comparison.md`** - LSEG vs WRDS data mapping\n\n### Example Files\n\n- **`examples/historical_pricing.ipynb`** - Historical price retrieval\n- **`examples/fundamentals_query.py`** - Fundamental data patterns\n- **`examples/stock_screener.ipynb`** - Dynamic stock screening\n\n### Scripts\n\n- **`scripts/test_connection.py`** - Validate LSEG connectivity\n\n### Local Sample Repositories\n\nLSEG API samples at `~/resources/lseg-samples/`:\n- `Example.RDPLibrary.Python/` - Core API examples\n- `Examples.DataLibrary.Python.AdvancedUsecases/` - Advanced patterns\n- `Article.DataLibrary.Python.Screener/` - Stock screening\n\n### Refinitiv Codebook\n\nInteractive JupyterLab environment with pre-configured LSEG access:\n\n- **URL**: `https://workspace.refinitiv.com/codebook/`\n- **Environment**: JupyterHub with Python 3.8, pre-installed `refinitiv.data` library\n- **Session**: Auto-authenticated via Workspace credentials (`{name=’codebook’}`)\n\n```python\n# In Codebook, session opens automatically with Workspace auth\nimport refinitiv.data as rd\nrd.open_session()  # Returns session with name=’codebook’\n\n# Query data immediately\ndf = rd.news.get_headlines(‘R:AAPL.O AND SUGGAC’, count=10)\n```\n\n**Note**: Codebook uses `refinitiv.data` (older name) rather than `lseg.data`. Both APIs are equivalent.\n\n## Date Awareness\n\nWhen querying market data, account for current date context and market data lag.\n\n### Market Data Lag\n\nMarket data typically has T-1 availability, meaning today’s data becomes available tomorrow. Adjust date ranges accordingly.\n\n### Date Range Example\n\nUse current date context when querying historical prices:\n\n```python\nfrom datetime import datetime, timedelta\n\n# Get recent market data\nend_date = datetime.now()\nstart_date = end_date - timedelta(days=365)\n\n# Adjust to exclude recent data (T-1 for market data availability)\nend_date = end_date - timedelta(days=1)\n\ndf = ld.get_history(\n    universe=”AAPL.O”,\n    fields=[‘CLOSE’],\n    start=start_date.strftime(‘%Y-%m-%d’),\n    end=end_date.strftime(‘%Y-%m-%d’)\n)\n```\n\nRemember: Always account for the T-1 lag in market data availability.\n",
        "skills/lseg-data/references/api-discovery.md": "# API Discovery via Network Monitoring\n\nWhen LSEG/Refinitiv data is available in Workspace but not documented in the Python API, you can reverse-engineer the API by monitoring network traffic from the Electron app.\n\n## Overview\n\nRefinitiv Workspace is an Electron app (Chromium-based), which means you can:\n1. Launch it with remote debugging enabled\n2. Connect via Chrome DevTools Protocol (CDP)\n3. Monitor network requests to discover API endpoints\n4. Replicate the API calls in Python\n\n## Step-by-Step Process\n\n### Step 1: Launch Workspace with Remote Debugging\n\n```bash\n# macOS\n/Applications/Refinitiv\\ Workspace.app/Contents/MacOS/Refinitiv\\ Workspace --remote-debugging-port=9222\n\n# Windows\n“C:\\Program Files\\Refinitiv\\Refinitiv Workspace\\Refinitiv Workspace.exe” --remote-debugging-port=9222\n```\n\n### Step 2: Find the WebSocket Debugger URL\n\n```bash\ncurl -s http://localhost:9222/json | jq ‘.[0].webSocketDebuggerUrl’\n```\n\nReturns something like:\n```\nws://localhost:9222/devtools/page/ABC123...\n```\n\n### Step 3: Connect and Monitor Network Traffic\n\n```python\nimport asyncio\nimport websockets\nimport json\n\nasync def monitor_network():\n    # Get debugger URL\n    import urllib.request\n    targets = json.loads(urllib.request.urlopen(‘http://localhost:9222/json’).read())\n    ws_url = targets[0][‘webSocketDebuggerUrl’]\n\n    async with websockets.connect(ws_url) as ws:\n        # Enable network monitoring\n        await ws.send(json.dumps({\n            ‘id’: 1,\n            ‘method’: ‘Network.enable’\n        }))\n\n        # Listen for requests\n        while True:\n            msg = await ws.recv()\n            data = json.loads(msg)\n\n            if data.get(‘method’) == ‘Network.requestWillBeSent’:\n                request = data[‘params’][‘request’]\n                url = request[‘url’]\n\n                # Filter for interesting APIs\n                if ‘datacloud’ in url or ‘api’ in url:\n                    print(f”URL: {url}”)\n                    print(f”Method: {request[‘method’]}”)\n                    if request.get(‘postData’):\n                        print(f”Body: {request[‘postData’][:500]}”)\n                    print(“-” * 50)\n\nasyncio.run(monitor_network())\n```\n\n### Step 4: Trigger the Action in Workspace\n\nWhile the script is running:\n1. Open the relevant app in Workspace (e.g., SDC Platinum)\n2. Run the query you want to replicate\n3. Watch the console for captured API calls\n\n### Step 5: Analyze Captured Requests\n\nExample captured request for SDC Platinum Poison Pills:\n\n```\nURL: https://amers1-apps.platform.refinitiv.com/datacloud-nonviews/snapshot/rest/async?timeout=1\nMethod: POST\nBody: [{“select”: {\n    “cache”: “Off”,\n    “formula”: “TR.PPIssuerName, TR.PPPillAdoptionDate”,\n    “identifiers”: “SCREEN(U(IN(DEALS)) AND IN(TR.PPIssuerNation, “US”),CURN=USD)”,\n    “lang”: “en-US”,\n    “output”: “col, in, t, sorta, TR.PPIssuerName, sorta, TR.PPPillAdoptionDate”,\n    “productId”: “SDC_PLATINUM:UNITY”,\n    “titleLang”: “en-US”\n}}]\n```\n\n## What We Learned from SDC Platinum\n\n### Discovery Process\n\n1. Monitored Workspace while running SDC Platinum queries\n2. Found the `datacloud-nonviews` API endpoint\n3. Discovered the request body format with SCREEN() syntax\n4. Identified field naming patterns (TR.PP*, TR.SACT*)\n\n### Key Finding\n\nThe internal API uses `SCREEN(U(IN(DEALS)))` syntax for broad universe queries, but this **does not work** via the public `ld.get_data()` API.\n\nHowever, the **field names discovered** (TR.SACT*, TR.PP*) **do work** with `ld.get_data()` when you provide specific tickers:\n\n```python\n# This works!\ndf = ld.get_data(\n    universe=[‘XOM’, ‘AAPL.O’],\n    fields=[‘TR.SACTAnnouncementDate’, ‘TR.SACTLeadDissident’]\n)\n```\n\n### Session File Analysis\n\nSDC session files (`.sdcs`) are JSON and contain field ID mappings:\n\n```bash\ncat ~/Downloads/report.sdcs | jq ‘.searchItems[].parameter.reportItems[].dataItem.fieldId’\n```\n\nExample mappings discovered:\n- `I_Deals_SACT_DealDetails_AnnouncementDate` → `TR.SACTAnnouncementDate`\n- `I_Deals_SACT_Target_TarShortName` → `TR.SACTTargetName`\n- `I_Deals_SACT_DissidentRelatedInformation_LeadDissident` → `TR.SACTLeadDissident`\n\n## Limitations\n\n### Authentication\n\nDirect API calls require Workspace session authentication. The CDP approach lets you see the API format, but replicating calls outside Workspace requires:\n- Valid session cookies\n- OAuth tokens from Workspace\n\nFor most use cases, it’s easier to use the discovered field names with `ld.get_data()` rather than calling the internal API directly.\n\n### Service Worker Caching\n\nSome requests may be cached by Service Workers and won’t appear in network monitoring. If you don’t see expected traffic:\n- Clear browser cache in Workspace\n- Try different query parameters\n- Check the Application tab for cached responses\n\n## Practical Workflow\n\n1. **Discover fields**: Use CDP monitoring to find field names (TR.XX*)\n2. **Test in Python**: Try discovered fields with `ld.get_data()`\n3. **Build universe**: Use SCREEN or index chains for company lists\n4. **Query data**: Pass company RICs to corporate governance fields\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\n# Get universe via SCREEN (this works)\nuniverse = ld.get_data(\n    universe=’SCREEN(U(IN(Equity(active,public,primary))),IN(TR.HQCountryCode,”US”),CURN=USD)’,\n    fields=[‘TR.CommonName’]\n)\nrics = universe[‘Instrument’].tolist()\n\n# Query discovered fields (TR.SACT* from CDP monitoring)\nactivism = ld.get_data(\n    universe=rics[:100],\n    fields=[‘TR.SACTAnnouncementDate’, ‘TR.SACTLeadDissident’]\n)\n\nld.close_session()\n```\n\n## Programmatic Field Discovery\n\n### What Works\n\nThe LSEG Data Library has a **Search API** that can list properties for finding instruments:\n\n```python\nfrom lseg.data import discovery\n\n# Get search properties for a view\nresult = discovery.SearchPropertyExplorer.get_properties_for(\n    view=discovery.Views.MUNICIPAL_INSTRUMENTS\n)\nprint(f”Found {len(result.properties)} search properties”)\n```\n\n### What Doesn’t Work\n\n**There is no API to discover `TR.*` data field names.** The TR.* fields used with `ld.get_data()` are not exposed in any programmatic catalog.\n\nThe Search API properties (AccrualDate, AssetCategory, etc.) are for **finding instruments**, not for **retrieving data** - they’re different APIs:\n\n| API | Purpose | Field Style |\n|-----|---------|-------------|\n| `discovery.search` | Find instruments | AccrualDate, AssetCategory |\n| `ld.get_data()` | Retrieve data | TR.MuniSaleDate, TR.Revenue |\n\n### Field Discovery Options\n\nSince there’s no programmatic API for TR.* fields, use these approaches:\n\n1. **CDP Network Monitoring** (recommended)\n   - Monitor SDC Platinum while running queries\n   - Capture TR.* field names from request bodies\n   - Most reliable for SDC-specific fields\n\n2. **Data Item Browser (DIB)**\n   - Built into Refinitiv Workspace\n   - Search “DIB” in Workspace to open\n   - Lists TR.* fields with descriptions\n\n3. **Column Picker UI**\n   - In SDC Platinum, customize columns to see all available fields\n   - Monitor network traffic while opening the picker\n\n4. **Pattern Enumeration**\n   - Once you know a prefix (TR.Muni*), try variations\n   - Common patterns: *Name, *Date, *Amount, *Status, *Code\n\n5. **LSEG Documentation**\n   - Check developer portal docs (often incomplete)\n   - API Playground sometimes has field lists\n\n### Capturing All Fields from Column Picker\n\nTo get a complete field list for an SDC dataset:\n\n1. Start network monitoring\n2. Open SDC Platinum to your dataset\n3. Click “Customize Columns” or equivalent\n4. The field picker loads all available fields\n5. Capture the TR.* field names from network traffic\n\n## IndexedDB Field Extraction (Recommended)\n\nSDC Platinum caches complete field definitions in the browser’s IndexedDB. This is the **most reliable method** for extracting all available fields for a dataset.\n\n### How It Works\n\n1. SDC Platinum stores field metadata in IndexedDB database `SDCPlatinum`\n2. The `APIResponse` object store contains cached field definitions\n3. Each dataset (M&A, Equity, Loans, etc.) has a cached entry with all TR.* fields\n\n### Extraction Process\n\n#### Step 1: Open SDC Platinum in Chrome\n\nNavigate to SDC Platinum in a browser (not the Electron app):\n- URL: `https://amers1-apps.platform.refinitiv.com/Apps/SDCPlatinum/`\n- Log in with your Refinitiv credentials\n\n#### Step 2: Open Each Dataset Type\n\nThe field definitions are cached when you first open each session type:\n- Open “Mergers & Acquisitions” session to cache TR.MnA* fields\n- Open “Poison Pills” session to cache TR.PP* and TR.SACT* fields\n- Open “Loans” session to cache TR.LN* fields\n- etc.\n\n#### Step 3: Extract from IndexedDB via DevTools\n\nOpen Chrome DevTools (F12) and run in Console:\n\n```javascript\n// Open the SDCPlatinum IndexedDB\nconst request = indexedDB.open(‘SDCPlatinum’);\n\nrequest.onsuccess = function(event) {\n    const db = event.target.result;\n    const tx = db.transaction(‘APIResponse’, ‘readonly’);\n    const store = tx.objectStore(‘APIResponse’);\n\n    // Get all cached entries\n    const getAllRequest = store.getAll();\n\n    getAllRequest.onsuccess = function() {\n        const entries = getAllRequest.result;\n\n        // Find entries with field definitions (large entries)\n        entries.forEach((entry, idx) => {\n            const size = JSON.stringify(entry).length;\n            if (size > 100000) {  // Large entries contain field defs\n                console.log(`Entry ${idx}: ${(size/1024/1024).toFixed(2)} MB`);\n\n                // Extract field definitions\n                if (entry.value && entry.value.universe) {\n                    const fields = entry.value.universe.map(f => ({\n                        TR_Path: f.TR_Path,\n                        Name: f.Name,\n                        DataType: f.DataType,\n                        Description: f.Description\n                    }));\n                    console.log(`Fields: ${fields.length}`);\n                    console.log(JSON.stringify(fields, null, 2));\n                }\n            }\n        });\n    };\n};\n```\n\n### Dataset to IndexedDB Key Mapping\n\n| Dataset | Universe Key | Field Count | TR Prefix |\n|---------|--------------|-------------|-----------|\n| M&A | DEALSMNA | 2,683 | TR.MnA* |\n| Equity/IPO | DEALSEQ | 1,708 | TR.NI* |\n| Loans | DEALSLN | 1,290 | TR.LN* |\n| Project Finance | DEALSPF | 2,674 | TR.PJF* |\n| Private Equity | DEALSPE | 557 | TR.PEInvest* |\n| Poison Pills (PP) | DEALSPP | 418 | TR.PP* |\n| Poison Pills (PF) | DEALSPOISONPILLSPF | 416 | TR.SACT* |\n| Joint Ventures | DEALSJV | 301 | TR.JV* |\n| Municipal Bonds | DEALSMUNI | 443 | TR.Muni* |\n| Repurchases | DEALSREP | 728 | TR.REP* |\n\n### Field Definition Structure\n\nEach cached field has this structure:\n\n```json\n{\n  “TR_Path”: “TR.MnAAcquirorName”,\n  “Name”: “Acquiror Name”,\n  “DataType”: “String”,\n  “SDC_Codes”: “ANAMES”,\n  “Description”: “Name of the acquiring company...”\n}\n```\n\n### Advantages Over Network Monitoring\n\n| Method | Pros | Cons |\n|--------|------|------|\n| IndexedDB | Complete field list, offline access, structured data | Must open each session type first |\n| CDP Monitoring | Real-time, sees actual queries | Incomplete, only sees used fields |\n| DIB/Column Picker | Visual interface | Manual, can’t export easily |\n\n### Extracted Field Data Location\n\nComplete field extractions are stored at:\n`/Users/vwh7mb/projects/lseg-exploration/data/sdc_fields/`\n\nFiles include:\n- `sdc_platinum_complete_fields.json` (5.0 MB) - All datasets\n- `*_fields.csv` - Individual dataset CSV files\n\n## Tools Used\n\n- **Chrome DevTools Protocol (CDP)**: Network monitoring via WebSocket\n- **IndexedDB**: Browser storage containing cached field definitions\n- **websockets**: Python library for WebSocket connections\n- **jq**: JSON parsing for session files and API responses\n- **Refinitiv Workspace**: Electron app with `--remote-debugging-port` flag\n",
        "skills/lseg-data/references/corporate-governance.md": "# Corporate Governance Data (SDC Platinum)\n\nAccess shareholder activism campaigns and poison pills data via the LSEG Data Library.\n\n## Overview\n\nCorporate governance data comes from SDC Platinum (now integrated into LSEG). Unlike fundamentals which return one row per company, corporate governance queries return **multiple rows per company** (one per campaign or pill).\n\n## Shareholder Activism (TR.SACT*)\n\nQuery activist campaigns, proxy fights, and dissident information.\n\n### Quick Start\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\ndf = ld.get_data(\n    universe=[‘XOM’, ‘AAPL.O’, ‘DIS’],\n    fields=[\n        ‘TR.SACTAnnouncementDate’,\n        ‘TR.SACTTargetName’,\n        ‘TR.SACTLeadDissident’,\n        ‘TR.SACTCampaignEndDate’,\n        ‘TR.SACTDescOfProxyFight’,\n        ‘TR.SACTDescFightOutcome’,\n    ]\n)\n# Returns multiple rows per company (one per activism campaign)\n\nld.close_session()\n```\n\n### Available Fields\n\n| Field | Description |\n|-------|-------------|\n| **Deal Details** | |\n| `TR.SACTAnnouncementDate` | Campaign announcement date |\n| `TR.SACTCampaignEndDate` | Campaign end date |\n| `TR.SACTCampaignSettledDate` | Campaign settlement date |\n| `TR.SACTDescOfProxyFight` | Description of the proxy fight/campaign |\n| `TR.SACTDescFightOutcome` | Description of campaign outcome |\n| `TR.SACTProxyFightSettled` | Whether proxy fight was settled |\n| `TR.SACTRelatedMnADealNum` | Related M&A deal number |\n| `TR.SACTSourceType` | Data source type |\n| `TR.SACTDealId` | SDC deal identifier |\n| `TR.SACTSdcDealNumber` | SDC deal number |\n| **Target Company** | |\n| `TR.SACTTargetName` | Target company name |\n| `TR.SACTTargetTicker` | Target ticker symbol |\n| `TR.SACTTargetCusip` | Target CUSIP |\n| `TR.SACTTargetSIC` | Target SIC code |\n| `TR.SACTTargetNation` | Target country |\n| `TR.SACTTargetEntityId` | Target entity ID |\n| **Target Advisors** | |\n| `TR.SACTTargetFinAdvisor` | Target financial advisor |\n| `TR.SACTTargetLegalCounsel` | Target legal counsel |\n| `TR.SACTTargetProxySolicitor` | Target proxy solicitor |\n| **Dissident Information** | |\n| `TR.SACTLeadDissident` | Lead dissident/activist name |\n| `TR.SACTDissidentGroup` | Dissident group name |\n| `TR.SACTDissidentGroupOrgType` | Dissident organization type |\n| `TR.SACTDissidentCusip` | Dissident CUSIP |\n| **Dissident Advisors** | |\n| `TR.SACTDissidentFinAdvisor` | Dissident financial advisor |\n| `TR.SACTDissidentLegalCounsel` | Dissident legal counsel |\n| `TR.SACTDissidentProxySolicitor` | Dissident proxy solicitor |\n\n### Example Output\n\n| Instrument | Campaign Announcement Date | Dissident Group | Campaign End Date |\n|------------|---------------------------|-----------------|-------------------|\n| XOM | 2020-07-12 | Engine No 1 LP | NaT |\n| XOM | 2019-05-09 | Arjuna Capital | 2020-03-01 |\n| AAPL.O | 2013-02-07 | Greenlight Capital LLC | 2013-05-07 |\n| AAPL.O | 2013-08-13 | Icahn Partners LP | NaT |\n| DIS | 2022-08-19 | Third Point LLC | 2023-01-11 |\n\n## Poison Pills (TR.PP*)\n\nQuery shareholder rights plans (poison pills) adopted by companies.\n\n### Quick Start\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\ndf = ld.get_data(\n    universe=[‘AAPL.O’, ‘DIS’, ‘XOM’],\n    fields=[\n        ‘TR.PPIssuerName’,\n        ‘TR.PPPillAdoptionDate’,\n        ‘TR.PPPillStatus’,\n        ‘TR.PPPillType’,\n        ‘TR.PPExpirationDate’,\n        ‘TR.PPTriggerPercent’,\n    ]\n)\n\nld.close_session()\n```\n\n### Available Fields\n\n| Field | Description |\n|-------|-------------|\n| **Issuer Information** | |\n| `TR.PPIssuerName` | Issuer company name |\n| `TR.PPIssuerTicker` | Issuer ticker |\n| `TR.PPIssuerCusip` | Issuer CUSIP |\n| `TR.PPIssuerSIC` | Issuer SIC code |\n| `TR.PPIssuerNation` | Issuer country |\n| **Pill Details** | |\n| `TR.PPPillAdoptionDate` | Date pill was adopted |\n| `TR.PPPillStatus` | Current status (In force, Expired, Redeemed) |\n| `TR.PPPillType` | Pill type (Flip-in, Flip-over, etc.) |\n| `TR.PPExpirationDate` | Pill expiration date |\n| `TR.PPTriggerPercent` | Ownership trigger percentage |\n| `TR.PPFlipInTrigger` | Flip-in trigger details |\n| `TR.PPFlipOverTrigger` | Flip-over trigger details |\n| **Identifiers** | |\n| `TR.PPDealId` | SDC deal identifier |\n| `TR.PPSdcDealNumber` | SDC deal number |\n\n### Example Output\n\n| Instrument | Issuer Short Name | Pill Adoption Date | Pill Status | Pill Type | Expiration Date |\n|------------|-------------------|-------------------|-------------|-----------|-----------------|\n| AAPL.O | Apple Computer Inc | 1989-04-19 | Expired | Flip-in/Flip-over | 1999-04-19 |\n| AAPL.O | Apple Inc | 2025-11-05 | In force | Flip-in/Flip-over | 2025-11-05 |\n| DIS | Walt Disney Co | 1989-06-21 | Redeemed | Flip-in/Flip-over | 1999-06-30 |\n\n## Limitations\n\n1. **No broad universe screening**: You cannot query “all US companies with activism” via the Python API. The `SCREEN(U(IN(DEALS)))` syntax only works in the internal Workspace application, not via `ld.get_data()`.\n\n2. **Must query by ticker**: You need a list of target tickers/RICs first, then query their corporate governance data.\n\n3. **Multiple rows per company**: Unlike fundamentals, these queries return one row per campaign/pill, not one row per company.\n\n## Practical Workflow: SCREEN to Corporate Governance\n\nYou can use SCREEN or index constituents to get a universe of RICs, then pass those to corporate governance queries.\n\n### Method 1: Index Constituents\n\n```python\nimport lseg.data as ld\nimport pandas as pd\n\nld.open_session()\n\n# Get S&P 500 constituents (503 companies)\nsp500 = ld.get_data(\n    universe=‘0#.SPX’,\n    fields=[‘TR.CommonName’]\n)\ntickers = sp500[‘Instrument’].tolist()\n\n# Query activism data for those tickers (batch to avoid rate limits)\nbatch_size = 100\nall_activism = []\n\nfor i in range(0, len(tickers), batch_size):\n    batch = tickers[i:i+batch_size]\n    df = ld.get_data(\n        universe=batch,\n        fields=[‘TR.SACTAnnouncementDate’, ‘TR.SACTLeadDissident’]\n    )\n    all_activism.append(df)\n\nactivism_df = pd.concat(all_activism, ignore_index=True)\n# Filter to rows with actual data\nactivism_df = activism_df.dropna(subset=[‘Campaign Announcement Date’])\n\nld.close_session()\n```\n\n### Method 2: SCREEN for Custom Universe\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\n# Screen for US large caps (market cap > $100B)\nscreen_result = ld.get_data(\n    universe=’SCREEN(U(IN(Equity(active,public,primary))),IN(TR.HQCountryCode,”US”),TR.CompanyMarketCapitalization>100000000000,CURN=USD)’,\n    fields=[‘TR.CommonName’, ‘TR.CompanyMarketCapitalization’]\n)\n# Returns ~108 companies\n\n# Extract RICs\nrics = screen_result[‘Instrument’].tolist()\n\n# Query activism for those RICs\nactivism_df = ld.get_data(\n    universe=rics,\n    fields=[‘TR.SACTAnnouncementDate’, ‘TR.SACTLeadDissident’, ‘TR.SACTDescOfProxyFight’]\n)\n\nld.close_session()\n```\n\n### Common Index Chains\n\n| Index | Chain RIC | Approx. Count |\n|-------|-----------|---------------|\n| S&P 500 | `0#.SPX` | 503 |\n| Russell 1000 | `0#.RUI` | 1009 |\n| Russell 2000 | `0#.RUT` | 2000 |\n| NASDAQ 100 | `0#.NDX` | 100 |\n| Dow Jones | `0#.DJI` | 30 |\n\n## Field Name Aliases\n\nMany fields have multiple valid names:\n\n| Canonical | Aliases |\n|-----------|---------|\n| `TR.SACTAnnouncementDate` | `TR.SACTAnnDate` |\n| `TR.SACTTargetName` | `TR.SACTTarget`, `TR.SACTTarShortName` |\n| `TR.SACTCampaignEndDate` | `TR.SACTEndDate` |\n| `TR.SACTCampaignSettledDate` | `TR.SACTSettledDate` |\n| `TR.PPPillAdoptionDate` | `TR.PPAdoptionDate` |\n| `TR.PPPillStatus` | `TR.PPStatus` |\n",
        "skills/lseg-data/references/equity-new-issues.md": "# Equity/New Issues Data (SDC Platinum)\n\nAccess equity offerings (IPOs, follow-ons, secondary offerings) via the LSEG Data Library using `TR.NI*` fields.\n\n## Overview\n\nEquity new issues data comes from SDC Platinum. Like other deal databases, queries return **multiple rows per company** (one per offering).\n\n**Field count**: 1,708 fields available with TR.NI* prefix.\n\n## Quick Start\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\ndf = ld.get_data(\n    universe=[‘AAPL.O’, ‘MSFT.O’, ‘GOOGL.O’],\n    fields=[\n        ‘TR.NIIssuer’,\n        ‘TR.NIPricingDate’,\n        ‘TR.NIOfferPrice’,\n        ‘TR.NIProceeds’,\n        ‘TR.NIIssueType’,\n        ‘TR.NIBookrunner’,\n    ]\n)\n# Returns multiple rows per company (one per equity offering)\n\nld.close_session()\n```\n\n## Available Fields\n\n### Issue Identification\n\n| Field | Description |\n|-------|-------------|\n| `TR.NISDCDealNumber` | SDC deal number |\n| `TR.NIIssuer` | Issuer/Borrower name |\n| `TR.NIIssuerShortName` | Issuer short name |\n| `TR.NIIssuerParent` | Issuer immediate parent name |\n| `TR.NIIssuerUltParent` | Issuer ultimate parent name |\n| `TR.NICompLongName` | Full company name |\n\n### Key Dates\n\n| Field | Description |\n|-------|-------------|\n| `TR.NIPricingDate` | Date issue was priced |\n| `TR.NIFilingDate` | SEC filing date |\n| `TR.NIFoundedDate` | Date company was founded |\n| `TR.NIGenDate` | Date of fundamental company change |\n\n### Deal Value/Pricing\n\n| Field | Description |\n|-------|-------------|\n| `TR.NIOfferPrice` | Offer price per share |\n| `TR.NIProceeds` | Total proceeds from offering |\n| `TR.NISharesOffered` | Number of shares offered |\n| `TR.NIOverallotment` | Overallotment shares (greenshoe) |\n\n### Issue Type/Structure\n\n| Field | Description |\n|-------|-------------|\n| `TR.NIIssueType` | Issue type (IPO, Follow-on, etc.) |\n| `TR.NIPubStatus` | Public status (P=public, V=private, S=subsidiary) |\n| `TR.NIPubMid` | Mid-level public status |\n| `TR.NIIsFinancialSponsor` | Financial sponsor flag |\n\n### Issuer Information\n\n| Field | Description |\n|-------|-------------|\n| `TR.NICity` | City of headquarters |\n| `TR.NIStateHQ` | State of headquarters |\n| `TR.NINationHQ` | Nation of headquarters |\n| `TR.NIRegionHQ` | Region of headquarters |\n| `TR.NIEmployees` | Number of employees |\n| `TR.NIStreetAddress` | Street address |\n| `TR.NIPhoneNumber` | Phone number |\n\n### Industry Classification\n\n| Field | Description |\n|-------|-------------|\n| `TR.NISdcIndustry` | SDC industry code |\n| `TR.NIMajorIndustry` | Major industry group |\n| `TR.NIMacroIndustry` | Macro industry (14 classifications) |\n| `TR.NIMidIndustry` | Mid-level industry (85+ categories) |\n| `TR.NIIssuerSic` | Issuer SIC code |\n| `TR.NIIssuerNaics` | Issuer NAICS 2007 code |\n| `TR.NIIssuerNaics2022` | Issuer NAICS 2022 code |\n| `TR.NIIssuerHiTech` | High-tech industry classification |\n\n### TRBC Classification\n\n| Field | Description |\n|-------|-------------|\n| `TR.NITRBCEconomicSector` | TRBC Economic Sector |\n| `TR.NITRBCBusinessSector` | TRBC Business Sector |\n| `TR.NITRBCIndustryGroup` | TRBC Industry Group |\n| `TR.NITRBCIndustry` | TRBC Industry |\n| `TR.NITRBCActivity` | TRBC Activity |\n\n### Identifiers\n\n| Field | Description |\n|-------|-------------|\n| `TR.NISDCCusip` | SDC 6-digit CUSIP |\n| `TR.NIPrimaryTickerSymbol` | Primary ticker symbol |\n| `TR.NIPrimaryStockExch` | Primary stock exchange |\n| `TR.NICompSedol` | SEDOL identifier |\n| `TR.NIDataStream` | Datastream code |\n\n### Stakeholders\n\n| Field | Description |\n|-------|-------------|\n| `TR.NIBookrunner` | Lead bookrunner |\n| `TR.NIStrategicInvestor` | Strategic investor name |\n| `TR.NISellingShareholder` | Selling shareholder name |\n| `TR.NISignificantShareholder` | Significant shareholder name |\n| `TR.NIInvestor` | Investor name |\n| `TR.NIGuarantorNation` | Guarantor nation |\n\n### Spinoff/Related Companies\n\n| Field | Description |\n|-------|-------------|\n| `TR.NISpinoffParent` | Spinoff parent name |\n| `TR.NISpinoffParentSic` | Spinoff parent SIC code |\n\n### REIT/Specialized\n\n| Field | Description |\n|-------|-------------|\n| `TR.NIREITType` | REIT type classification |\n| `TR.NIIssuerREITSgmt` | REIT segment (Hotel, Office, etc.) |\n\n### Flags\n\n| Field | Description |\n|-------|-------------|\n| `TR.NIIsCertBCorpCompany` | Certified B Corporation flag |\n| `TR.NIIsDivision` | Division flag |\n| `TR.NIIsSupranational` | Supranational flag |\n\n## Example Output\n\n| Instrument | Issuer | Pricing Date | Offer Price | Proceeds | Type |\n|------------|--------|--------------|-------------|----------|------|\n| SNOW.N | Snowflake Inc | 2020-09-15 | $120.00 | $3.4B | IPO |\n| ABNB.O | Airbnb Inc | 2020-12-09 | $68.00 | $3.5B | IPO |\n| RIVN.O | Rivian Automotive | 2021-11-09 | $78.00 | $11.9B | IPO |\n\n## Practical Workflow\n\n### Query IPOs for a Universe\n\n```python\nimport lseg.data as ld\nimport pandas as pd\n\nld.open_session()\n\n# Get tech companies\ntech_rics = [‘AAPL.O’, ‘MSFT.O’, ‘GOOGL.O’, ‘META.O’, ‘AMZN.O’]\n\n# Query equity offerings\ndf = ld.get_data(\n    universe=tech_rics,\n    fields=[\n        ‘TR.NIIssuer’,\n        ‘TR.NIPricingDate’,\n        ‘TR.NIOfferPrice’,\n        ‘TR.NIProceeds’,\n        ‘TR.NIIssueType’,\n        ‘TR.NIBookrunner’,\n        ‘TR.NIPrimaryStockExch’,\n    ]\n)\n\n# Filter to actual IPOs (not NaN pricing dates)\ndf = df.dropna(subset=[‘NI Pricing Date’])\n\nld.close_session()\n```\n\n### Filter by Date and Issue Type\n\n```python\n# Filter to recent IPOs\ndf[‘NI Pricing Date’] = pd.to_datetime(df[‘NI Pricing Date’])\nrecent_ipos = df[\n    (df[‘NI Pricing Date’] >= ‘2020-01-01’) &\n    (df[‘NI Issue Type’] == ‘IPO’)\n]\n```\n\n## Data Characteristics\n\n- **Multiple rows per company**: Each equity offering gets its own row\n- **Historical depth**: Data goes back to 1970s\n- **Global coverage**: Worldwide equity offerings\n- **Issue lifecycle**: Tracks from filing through pricing\n\n## Field Categories Summary\n\n| Category | Field Count | Prefix Pattern |\n|----------|-------------|----------------|\n| Issuer Information | ~200 | TR.NIIssuer*, TR.NIComp* |\n| Strategic Investors | ~50 | TR.NIStrategicInvestor* |\n| Selling Shareholders | ~50 | TR.NISellingShareholder* |\n| Significant Shareholders | ~50 | TR.NISignificantShareholder* |\n| Investors | ~50 | TR.NIInvestor* |\n| Spinoff Parents | ~30 | TR.NISpinoffParent* |\n| Industry Classifications | ~100 | TR.NISic*, TR.NINaics*, TR.NITRBC* |\n| Geographic | ~50 | TR.NICity, TR.NIState*, TR.NINation* |\n\n## Limitations\n\n1. **Must query by ticker**: Need a list of companies first, then query their offerings\n2. **Rate limits**: Batch queries to avoid API limits (max 10,000 data points/request)\n3. **Field availability**: Not all fields populated for all offerings\n\n## Related SDC Datasets\n\n- **M&A**: `TR.MnA*` fields - see `mna.md`\n- **Private Equity**: `TR.PEInvest*` fields - see `private-equity.md`\n- **Syndicated Loans**: `TR.LN*` fields - see `syndicated-loans.md`\n",
        "skills/lseg-data/references/esg.md": "# ESG Module\n\nEnvironmental, Social, and Governance scores and metrics from LSEG's ESG database.\n\n## Contents\n\n- [Overview](#overview)\n- [Key Fields](#key-fields)\n- [Parameters](#parameters)\n- [Code Examples](#code-examples)\n- [Notes and Gotchas](#notes-and-gotchas)\n- [See Also](#see-also)\n\n## Overview\n\nLSEG ESG scores provide comprehensive sustainability data covering 12,500+ companies globally. Scores are calculated from 630+ data points across 10 categories, updated weekly.\n\n### Coverage\n- **Companies**: 12,500+ globally\n- **History**: From 2002 (varies by company)\n- **Update frequency**: Weekly\n- **Methodology**: 630+ metrics across 10 categories\n\n### Score Structure\n\n```\nESG Score (0-100)\n├── Environmental Pillar (0-100)\n│   ├── Resource Use\n│   ├── Emissions\n│   └── Innovation\n├── Social Pillar (0-100)\n│   ├── Workforce\n│   ├── Human Rights\n│   ├── Community\n│   └── Product Responsibility\n└── Governance Pillar (0-100)\n    ├── Management\n    ├── Shareholders\n    └── CSR Strategy\n```\n\n## Key Fields\n\n### Overall Scores\n\n| Field | Description | Range |\n|-------|-------------|-------|\n| `TR.TRESGScore` | Overall ESG score | 0-100 |\n| `TR.TRESGCombinedScore` | ESG + Controversies combined | 0-100 |\n| `TR.TRESGCControversiesScore` | Controversies score | 0-100 |\n\n### Pillar Scores\n\n| Field | Description | Range |\n|-------|-------------|-------|\n| `TR.EnvironmentPillarScore` | Environmental pillar score | 0-100 |\n| `TR.SocialPillarScore` | Social pillar score | 0-100 |\n| `TR.GovernancePillarScore` | Governance pillar score | 0-100 |\n\n### Category Scores (Environmental)\n\n| Field | Description | Range |\n|-------|-------------|-------|\n| `TR.ResourceUseScore` | Resource efficiency | 0-100 |\n| `TR.EmissionsScore` | Emissions management | 0-100 |\n| `TR.EnvironmentalInnovationScore` | Green innovation | 0-100 |\n\n### Category Scores (Social)\n\n| Field | Description | Range |\n|-------|-------------|-------|\n| `TR.WorkforceScore` | Workforce management | 0-100 |\n| `TR.HumanRightsScore` | Human rights practices | 0-100 |\n| `TR.CommunityScore` | Community relations | 0-100 |\n| `TR.ProductResponsibilityScore` | Product quality/safety | 0-100 |\n\n### Category Scores (Governance)\n\n| Field | Description | Range |\n|-------|-------------|-------|\n| `TR.ManagementScore` | Management quality | 0-100 |\n| `TR.ShareholdersScore` | Shareholder rights | 0-100 |\n| `TR.CSRStrategyScore` | CSR strategy score | 0-100 |\n\n### Controversies\n\n| Field | Description | Range |\n|-------|-------------|-------|\n| `TR.TRESGCControversiesScore` | Overall controversies score | 0-100 |\n| `TR.ControversiesCount` | Number of controversies | Count |\n| `TR.RecentControversies` | Recent controversy flag | Boolean |\n\n### Carbon & Climate\n\n| Field | Description | Units |\n|-------|-------------|-------|\n| `TR.CO2DirectScope1` | Scope 1 emissions | Tonnes CO2 |\n| `TR.CO2IndirectScope2` | Scope 2 emissions | Tonnes CO2 |\n| `TR.CO2IndirectScope3` | Scope 3 emissions | Tonnes CO2 |\n| `TR.TotalCO2Equiv` | Total CO2 equivalent | Tonnes CO2 |\n| `TR.CO2IntensityRevenue` | CO2 per revenue | Tonnes/USD M |\n| `TR.CarbonReductionTarget` | Has reduction target | Boolean |\n\n### Governance Metrics\n\n| Field | Description | Units |\n|-------|-------------|-------|\n| `TR.BoardSize` | Board size | Count |\n| `TR.IndependentBoardMembers` | Independent directors | Count |\n| `TR.WomenOnBoard` | Women on board | Percent |\n| `TR.CEOBoardMember` | CEO on board | Boolean |\n| `TR.BoardMeetingAttendanceAvg` | Board meeting attendance | Percent |\n\n## Parameters\n\n| Parameter | Description | Values |\n|-----------|-------------|--------|\n| `SDate` | Start date | Date or `FY-N` |\n| `EDate` | End date | Date or `FY0` |\n| `Period` | Period type | `FY` (annual) |\n\n## Code Examples\n\n### Basic ESG Snapshot\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\n# Current ESG scores for major companies\ndf = ld.get_data(\n    universe=['AAPL.O', 'MSFT.O', 'GOOGL.O', 'XOM', 'CVX'],\n    fields=[\n        'TR.CompanyName',\n        'TR.TRESGScore',\n        'TR.EnvironmentPillarScore',\n        'TR.SocialPillarScore',\n        'TR.GovernancePillarScore'\n    ]\n)\n\nld.close_session()\nprint(df)\n```\n\n### ESG Score History\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\n# 5-year ESG score history\ndf = ld.get_data(\n    universe='AAPL.O',\n    fields=[\n        'TR.TRESGScore',\n        'TR.TRESGScore.date',\n        'TR.EnvironmentPillarScore',\n        'TR.SocialPillarScore',\n        'TR.GovernancePillarScore'\n    ],\n    parameters={\n        'SDate': 'FY-4',\n        'EDate': 'FY0',\n        'Period': 'FY'\n    }\n)\n\nld.close_session()\nprint(df)\n```\n\n### Detailed Category Breakdown\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\n# Full category breakdown\ndf = ld.get_data(\n    universe=['AAPL.O', 'XOM'],\n    fields=[\n        'TR.CompanyName',\n        # Environmental categories\n        'TR.ResourceUseScore',\n        'TR.EmissionsScore',\n        'TR.EnvironmentalInnovationScore',\n        # Social categories\n        'TR.WorkforceScore',\n        'TR.HumanRightsScore',\n        'TR.CommunityScore',\n        'TR.ProductResponsibilityScore',\n        # Governance categories\n        'TR.ManagementScore',\n        'TR.ShareholdersScore',\n        'TR.CSRStrategyScore'\n    ]\n)\n\nld.close_session()\nprint(df)\n```\n\n### Carbon Emissions Data\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\n# Carbon footprint data\ndf = ld.get_data(\n    universe=['XOM', 'CVX', 'BP.L', 'SHEL.L', 'TTE.PA'],\n    fields=[\n        'TR.CompanyName',\n        'TR.CO2DirectScope1',\n        'TR.CO2IndirectScope2',\n        'TR.CO2IndirectScope3',\n        'TR.TotalCO2Equiv',\n        'TR.CO2IntensityRevenue',\n        'TR.CarbonReductionTarget'\n    ]\n)\n\nld.close_session()\nprint(df)\n```\n\n### Governance Metrics\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\n# Board composition and governance\ndf = ld.get_data(\n    universe=['AAPL.O', 'MSFT.O', 'GOOGL.O', 'META.O'],\n    fields=[\n        'TR.CompanyName',\n        'TR.GovernancePillarScore',\n        'TR.BoardSize',\n        'TR.IndependentBoardMembers',\n        'TR.WomenOnBoard',\n        'TR.CEOBoardMember',\n        'TR.BoardMeetingAttendanceAvg'\n    ]\n)\n\nld.close_session()\nprint(df)\n```\n\n### Controversies Analysis\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\n# Controversies screening\ndf = ld.get_data(\n    universe=['AAPL.O', 'MSFT.O', 'META.O', 'GOOGL.O', 'AMZN.O'],\n    fields=[\n        'TR.CompanyName',\n        'TR.TRESGScore',\n        'TR.TRESGCombinedScore',  # Includes controversies\n        'TR.TRESGCControversiesScore',\n        'TR.ControversiesCount'\n    ]\n)\n\n# Companies with controversies impact\ndf['Controversy_Impact'] = df['TR.TRESGScore'] - df['TR.TRESGCombinedScore']\n\nld.close_session()\nprint(df)\n```\n\n### ESG Screening for Portfolio\n\n```python\nimport lseg.data as ld\nimport pandas as pd\n\nld.open_session()\n\n# Screen S&P 500 for ESG criteria\n# First get S&P 500 constituents\nconstituents = ld.get_data(\n    universe='0#.SPX',\n    fields=['TR.RIC']\n)\n\n# Then get ESG scores (chunk if needed)\ndf = ld.get_data(\n    universe=constituents['TR.RIC'].tolist()[:100],  # First 100\n    fields=[\n        'TR.CompanyName',\n        'TR.TRESGScore',\n        'TR.EnvironmentPillarScore',\n        'TR.TRESGCControversiesScore'\n    ]\n)\n\n# Apply screening criteria\nscreened = df[\n    (df['TR.TRESGScore'] >= 50) &\n    (df['TR.EnvironmentPillarScore'] >= 40) &\n    (df['TR.TRESGCControversiesScore'] >= 50)\n]\n\nld.close_session()\nprint(f\"Passed screening: {len(screened)} of {len(df)}\")\n```\n\n### Compare ESG Across Sectors\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\n# Compare tech vs energy\ntech = ['AAPL.O', 'MSFT.O', 'GOOGL.O']\nenergy = ['XOM', 'CVX', 'COP']\n\ndf = ld.get_data(\n    universe=tech + energy,\n    fields=[\n        'TR.CompanyName',\n        'TR.TRBCEconomicSector',  # Sector classification\n        'TR.TRESGScore',\n        'TR.EnvironmentPillarScore',\n        'TR.SocialPillarScore',\n        'TR.GovernancePillarScore'\n    ]\n)\n\n# Group by sector\nsector_avg = df.groupby('TR.TRBCEconomicSector').mean(numeric_only=True)\n\nld.close_session()\nprint(sector_avg)\n```\n\n## Notes and Gotchas\n\n### 1. Score Interpretation\n\n| Score Range | Interpretation |\n|-------------|----------------|\n| 75-100 | Excellent - top quartile |\n| 50-75 | Good - above average |\n| 25-50 | Satisfactory - average |\n| 0-25 | Poor - below average |\n\nScores are relative to industry peers.\n\n### 2. Controversies Impact\n\nThe `TRESGCombinedScore` reduces the ESG score based on controversies:\n```python\n# Combined = ESG Score adjusted for controversies\n# If Combined << ESG Score, significant controversies exist\nimpact = df['TR.TRESGScore'] - df['TR.TRESGCombinedScore']\n```\n\n### 3. Coverage Gaps\n\nNot all companies have ESG coverage:\n```python\n# Check for missing scores\ndf = df.dropna(subset=['TR.TRESGScore'])\nprint(f\"Companies with ESG coverage: {len(df)}\")\n```\n\n### 4. Update Timing\n\n- ESG scores updated weekly\n- Carbon data often annual (from sustainability reports)\n- Controversies updated as events occur\n\n### 5. Industry Relativity\n\nScores are industry-relative. An energy company with score 60 may have absolute emissions higher than a tech company with score 40. For absolute metrics, use:\n```python\nfields = ['TR.TotalCO2Equiv']  # Absolute emissions\n```\n\n### 6. Historical Methodology Changes\n\nLSEG has updated ESG methodology over time. Historical comparisons should note:\n- 2020: Updated category weights\n- 2019: Expanded coverage\n- Older scores may not be directly comparable\n\n## See Also\n\n- [SKILL.md](../SKILL.md) - Core API patterns\n- [fundamentals.md](fundamentals.md) - Financial fundamentals\n- [WRDS_COMPARISON.md](../WRDS_COMPARISON.md) - MSCI ESG comparison\n- [TROUBLESHOOTING.md](../TROUBLESHOOTING.md) - Common issues\n",
        "skills/lseg-data/references/fund-details.md": "# Fund Details API\n\n## Overview\n\nThe Fund Details app provides detailed information about individual funds, including derived holdings with full constituent data.\n\n**URL:** `https://workspace.refinitiv.com/web/Apps/FundDetails/`\n\n**API Endpoint:** `/Apps/FundDetails/{version}/loadData`\n\n## Derived Holdings\n\nFull holdings data with individual security positions, weights, and share counts.\n\n### Request\n\n```\nGET /Apps/FundDetails/{version}/loadData?requests=DHOL~true~&s={LipperRIC}&lang=en-US\n```\n\n**Parameters:**\n- `requests=DHOL~true~` - Request derived holdings\n- `s` - Lipper RIC (e.g., `LP40061149`)\n- `lang` - Language code (e.g., `en-US`)\n\n### Response Structure\n\n```json\n{\n  “missingAssetIdentifiers”: null,\n  “isError”: false,\n  “errorMessage”: “”,\n  “duration”: “00:00:01.195”,\n  “results”: [{\n    “availableDates”: [\n      “2025-12-31T00:00:00”,\n      “2025-11-30T00:00:00”,\n      “2025-10-31T00:00:00”\n    ],\n    “date”: “2025-12-31T00:00:00”,\n    “groups”: [{\n      “id”: “...”,\n      “name”: “Full Holdings”,\n      “items”: [\n        {\n          “ric”: “NVDA.OQ”,\n          “name”: “NVIDIA CORP ORD”,\n          “domicile”: “UNITED STATES”,\n          “percent”: 9.045,\n          “shares”: 197497993,\n          “sharesChange”: -9570500\n        },\n        {\n          “ric”: “AAPL.OQ”,\n          “name”: “APPLE INC ORD”,\n          “domicile”: “UNITED STATES”,\n          “percent”: 8.017,\n          “shares”: 120094732,\n          “sharesChange”: -6366442\n        }\n      ]\n    }]\n  }]\n}\n```\n\n### Holding Fields\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `ric` | string | Reuters Instrument Code (e.g., `NVDA.OQ`, `AAPL.OQ`) |\n| `name` | string | Security name |\n| `domicile` | string | Country of domicile |\n| `percent` | number | Weight in portfolio (%) |\n| `shares` | number | Number of shares held |\n| `sharesChange` | number | Change in shares vs prior period |\n\n### Available Dates\n\nThe `availableDates` array contains monthly snapshots going back several years. To fetch holdings for a specific date, use:\n\n```\nGET /Apps/FundDetails/{version}/loadData?requests=DHOL~true~{date}~&s={LipperRIC}\n```\n\nWhere `{date}` is in format `YYYY-MM-DD` (e.g., `DHOL~true~2024-12-31~`).\n\n## Request Types\n\nThe `loadData` endpoint supports multiple request types via the `requests` parameter:\n\n| Request Code | Description |\n|--------------|-------------|\n| `A` | Basic fund info |\n| `A\\|LP` | Fund info with Lipper data |\n| `BEN` | Benchmarks |\n| `CLA` | Classifications |\n| `DHOL~true~` | Derived holdings (full) |\n| `FEE` | Fees and charges |\n| `INC` | Income and distribution |\n| `KEY` | Key attributes |\n| `MD` | Market data (NAV, price, market cap) |\n| `PFM` | Performance vs benchmark |\n| `TTH` | Top ten holdings |\n| `TNA~{start}~{end}` | Total Net Assets time series |\n\n---\n\n## KEY - Key Attributes\n\nFund characteristics and structure information.\n\n### Request\n\n```\nGET /Apps/FundDetails/{version}/loadData?requests=KEY&s={LipperRIC}&lang=en-US\n```\n\n### Response Fields\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `assetStatus` | string | Fund status (e.g., “Active”) |\n| `domicile` | string | Country of domicile (e.g., “USA”) |\n| `launchDate` | datetime | Fund launch date |\n| `manager` | string | Fund manager name |\n| `fundCurrency` | string | Base currency (e.g., “US Dollar”) |\n| `legalStructureName` | string | Legal structure (e.g., “US - Exchange-Traded Open-end Funds”) |\n| `shareTna` | number | Share class TNA in millions |\n| `shareTnaDate` | datetime | TNA as-of date |\n| `shareTnaCurrencyCode` | string | TNA currency |\n| `fundTna` | number | Fund TNA in millions |\n| `indexReplicationMethod` | string | Replication method (e.g., “Full”) |\n| `managementApproach` | string | Active/Passive |\n| `indexTracking` | string | Yes/No |\n| `indexPure` | string | Pure index fund indicator |\n| `valuationFrequency` | string | Pricing frequency (e.g., “Pricing Daily, Mon-Fri”) |\n\n---\n\n## MD - Market Data\n\nCurrent NAV, price, and market statistics.\n\n### Request\n\n```\nGET /Apps/FundDetails/{version}/loadData?requests=MD&s={LipperRIC}&lang=en-US\n```\n\n### Response Fields\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `navPrice` | number | Current NAV |\n| `navPriceDate` | datetime | NAV date |\n| `navPriceCurrency` | string | NAV currency |\n| `outstanding` | number | Shares outstanding |\n| `outstandingDate` | datetime | Outstanding shares date |\n| `marketCap` | number | Market capitalization |\n| `marketCapCurrency` | string | Market cap currency |\n| `iNAV` | string | Intraday NAV RIC (e.g., “QQQiv.OQ”) |\n| `exDividend` | number | Ex-dividend amount |\n| `exDividendDate` | datetime | Ex-dividend date |\n| `RT_CF_LAST` | number | Real-time last price |\n| `RT_CF_TIME` | datetime | Real-time price timestamp |\n| `RT_HST_CLOSE` | number | Historical close |\n| `RT_HSTCLSDATE` | datetime | Historical close date |\n| `RT_CF_HIGH` | number | Daily high |\n| `RT_CF_LOW` | number | Daily low |\n| `RT_CF_OPEN` | number | Daily open |\n| `RT_52W_HIGH` | number | 52-week high |\n| `RT_52W_LOW` | number | 52-week low |\n\n---\n\n## BEN - Benchmarks\n\nFund benchmarks with real-time pricing.\n\n### Request\n\n```\nGET /Apps/FundDetails/{version}/loadData?requests=BEN&s={LipperRIC}&srequired={LipperRIC}&lang=en-US\n```\n\n### Response Structure\n\n```json\n{\n  “results”: [{\n    “benchmarks”: [\n      {\n        “benchmarkType”: “Fund Manager”,\n        “benchmarkTypeAbbr”: “FM”,\n        “name”: “NASDAQ 100 TR”,\n        “ric”: “.XNDX”,\n        “lipperId”: 11032760,\n        “RT_CF_LAST”: 31281.313,\n        “RT_CURRENCY”: “USD”\n      },\n      {\n        “benchmarkType”: “Technical Indicator”,\n        “benchmarkTypeAbbr”: “TI”,\n        “name”: “Russell 1000 Growth TR”,\n        “ric”: “.RLGTRI”,\n        “lipperId”: 11000689\n      },\n      {\n        “benchmarkType”: “Risk Free Index”,\n        “benchmarkTypeAbbr”: “RFI”,\n        “name”: “US 3-Month Treasury Bill T...”\n      },\n      {\n        “benchmarkType”: “Lipper Global Classification”,\n        “benchmarkTypeAbbr”: “LGC”,\n        “name”: “Lipper Global Equity US”\n      }\n    ]\n  }]\n}\n```\n\n### Benchmark Types\n\n| Abbreviation | Type | Description |\n|--------------|------|-------------|\n| `FM` | Fund Manager | Primary benchmark set by fund manager |\n| `TI` | Technical Indicator | Secondary/style benchmark |\n| `RFI` | Risk Free Index | Risk-free rate benchmark |\n| `LGC` | Lipper Global Classification | Peer group benchmark |\n\n---\n\n## PFM - Performance\n\nFund performance vs benchmark with tracking error.\n\n### Request\n\n```\nGET /Apps/FundDetails/{version}/loadData?requests=PFM&s={LipperRIC}&srequired={LipperRIC}&lang=en-US\n```\n\n### Response Structure\n\n```json\n{\n  “results”: [{\n    “asset”: {\n      “assetIdentifier”: “LP40061149”,\n      “name”: “Invesco QQQ Trust, Series 1”,\n      “performance1Month”: -0.688,\n      “performance3Month”: 2.419,\n      “performance6Month”: 11.578,\n      “performanceYTD”: 20.768,\n      “performance1Year”: 20.768,\n      “performance3Year”: 32.869,\n      “performance5Year”: 15.049,\n      “trackingError1Year”: 0.649,\n      “trackingError3Year”: 0.966,\n      “trackingError5Year”: 0.922\n    },\n    “benchmark”: {\n      “ric”: “.XNDX”,\n      “name”: “NASDAQ 100 TR”,\n      “typeAbbreviation”: “FM”,\n      “performance1Month”: -0.670,\n      “performance3Month”: 2.473,\n      “performance1Year”: 21.016,\n      “performance3Year”: 33.167,\n      “performance5Year”: 15.285\n    }\n  }]\n}\n```\n\n### Performance Fields\n\n| Field | Description |\n|-------|-------------|\n| `performance1Month` | 1-month return (%) |\n| `performance3Month` | 3-month return (%) |\n| `performance6Month` | 6-month return (%) |\n| `performanceYTD` | Year-to-date return (%) |\n| `performance1Year` | 1-year return (%) |\n| `performance3Year` | 3-year annualized return (%) |\n| `performance5Year` | 5-year annualized return (%) |\n| `trackingError1Year` | 1-year tracking error vs benchmark |\n| `trackingError3Year` | 3-year tracking error |\n| `trackingError5Year` | 5-year tracking error |\n\n---\n\n## TTH - Top Ten Holdings\n\nSummary of largest holdings (use DHOL for full holdings).\n\n### Request\n\n```\nGET /Apps/FundDetails/{version}/loadData?requests=TTH&s={LipperRIC}&srequired={LipperRIC}&lang=en-US\n```\n\n### Response Structure\n\n```json\n{\n  “results”: [{\n    “holdings”: [\n      {“name”: “NVIDIA CORP ORD”, “ric”: “NVDA.OQ”, “percent”: 9.04, “rank”: 1},\n      {“name”: “APPLE INC ORD”, “ric”: “AAPL.OQ”, “percent”: 8.02, “rank”: 2},\n      {“name”: “MICROSOFT CORP ORD”, “ric”: “MSFT.OQ”, “percent”: 7.17, “rank”: 3}\n    ],\n    “holdingsDate”: “2025-12-31T00:00:00”\n  }]\n}\n```\n\n---\n\n## FEE - Fees and Charges\n\nFee structure and expense ratios.\n\n### Request\n\n```\nGET /Apps/FundDetails/{version}/loadData?requests=FEE&s={LipperRIC}&srequired={LipperRIC}&lang=en-US\n```\n\n### Response Fields\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `initialChargeCurrent` | number | Current initial charge (%) |\n| `initialChargeMaximum` | number | Maximum initial charge (%) |\n| `annualChargeCurrent` | number | Current annual charge (%) |\n| `redemptionChargeCurrent` | number | Current redemption charge (%) |\n| `redemptionChargeMaximum` | number | Maximum redemption charge (%) |\n| `ter` | number | Total Expense Ratio (%) |\n| `terDate` | datetime | TER as-of date |\n| `minimumInvestmentInitial` | number | Minimum initial investment |\n| `minimumInvestmentRegular` | number | Minimum regular investment |\n| `minimumInvestmentCurrency` | string | Investment currency |\n\n---\n\n## INC - Income and Distribution\n\nDividend and yield information.\n\n### Request\n\n```\nGET /Apps/FundDetails/{version}/loadData?requests=INC&s={LipperRIC}&srequired={LipperRIC}&lang=en-US\n```\n\n### Response Fields\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `incomeDistribution` | string | Distribution policy (e.g., “Paid”) |\n| `incomeOperation` | string | Income operation (e.g., “Paid, Reinvested”) |\n| `dividendFrequency` | string | Distribution frequency |\n| `dividendPaymentMonths` | string | Payment months (e.g., “March,June,September,December”) |\n| `projectedYield` | number | Projected yield (%) |\n| `projectedYieldEndDate` | datetime | Projected yield date |\n| `dividendPaymentDate` | datetime | Last payment date |\n| `dividendXDDate` | datetime | Ex-dividend date |\n| `dividendPayment` | number | Last dividend amount |\n| `dividendCurrencyCode` | string | Dividend currency |\n| `day30regulatoryYield` | number | 30-day SEC yield (%) |\n| `annualizedDistributionYield` | number | Annualized distribution yield (%) |\n\n---\n\n## CLA - Classifications\n\nFund classification schemes.\n\n### Request\n\n```\nGET /Apps/FundDetails/{version}/loadData?requests=CLA&s={LipperRIC}&srequired={LipperRIC}&lang=en-US\n```\n\n### Response Structure\n\n```json\n{\n  “results”: [{\n    “classifications”: [\n      {\n        “classSchemeCode”: “EUSLACG1”,\n        “classSchemeName”: “Global Holdings Based Classification”,\n        “className”: “Equity United States Large-Cap Growth”\n      },\n      {\n        “classSchemeCode”: “LCGE”,\n        “classSchemeName”: “US Mutual Fund Classification”,\n        “className”: “Large-Cap Growth Funds”\n      },\n      {\n        “classSchemeCode”: “G”,\n        “classSchemeName”: “US Mutual Fund Objective”,\n        “className”: “Growth Funds”\n      }\n    ],\n    “assetUniverse”: “Exchange Traded Funds”,\n    “assetType”: “Equity”,\n    “geographicalFocus”: “United States of America”,\n    “lipperGlobal”: “Equity US”\n  }]\n}\n```\n\n---\n\n## Example: Fetch QQQ Holdings\n\n```javascript\n// Fetch derived holdings for Invesco QQQ Trust\nfetch(“https://workspace.refinitiv.com/Apps/FundDetails/1.10.457/loadData?requests=DHOL~true~&s=LP40061149&lang=en-US”, {\n  credentials: “include”\n})\n.then(r => r.json())\n.then(data => {\n  const holdings = data.results[0].groups[0].items;\n  console.log(`Found ${holdings.length} holdings`);\n\n  // Top 10 by weight\n  holdings\n    .sort((a, b) => b.percent - a.percent)\n    .slice(0, 10)\n    .forEach(h => {\n      console.log(`${h.ric}: ${h.name} - ${h.percent.toFixed(2)}%`);\n    });\n});\n```\n\n## Use Cases\n\n1. **ETF Constituent Analysis** - Get full holdings of any ETF/fund with RICs for further analysis\n2. **Portfolio Overlap** - Compare holdings across multiple funds\n3. **Historical Holdings** - Track position changes over time using `availableDates`\n4. **Weight Changes** - Monitor rebalancing via `sharesChange` field\n\n## Programmatic Access\n\n### Two Separate APIs\n\nFund data in Refinitiv Workspace comes from **two completely separate APIs**:\n\n| API | Package | Endpoint | Data Source |\n|-----|---------|----------|-------------|\n| Data Platform | `refinitiv.data` / `lseg.data` | `/data/datagrid/` | TR.* fields |\n| Fund Details App | Browser only | `/Apps/FundDetails/loadData` | Lipper database |\n\nThe Fund Details API uses request codes (`KEY`, `MD`, `BEN`, `DHOL`, etc.) and provides detailed Lipper data (full holdings with RICs, expense breakdowns, ESG scores). This data is **not exposed via TR.\\* fields**.\n\n### RDP Lipper Funds API (Separate Product)\n\nLSEG offers a dedicated **Lipper Funds API** on RDP with full fund coverage:\n- 393,000+ active share classes across 80+ markets\n- Full holdings, expense breakdowns, classifications\n- Endpoint: `/data/funds/v1/...`\n- **Requires separate subscription** (not included in standard RDP access)\n\nSee: [Lipper Funds API Developer Portal](https://developers.lseg.com/en/api-catalog/refinitiv-data-platform/lipper-funds-API)\n\n### Access Methods Summary\n\n| Method | Access | Coverage |\n|--------|--------|----------|\n| `refinitiv.data` (TR.* fields) | ✅ Have | Basic fund data only |\n| Fund Details Browser API | ✅ Have (via Workspace) | Full Lipper data |\n| RDP Lipper Funds API | ❌ Need subscription | Full Lipper data |\n\n### LSEG vs Refinitiv Data Libraries\n\n**CRITICAL:** `lseg.data` and `refinitiv.data` are **different packages** with different entitlements.\n\n| Package | Version | Fund Fields | Install |\n|---------|---------|-------------|---------|\n| `refinitiv.data` (rd) | 1.6.2 | ✅ **WORKS** | `pip install refinitiv-data` |\n| `lseg.data` (ld) | 2.1.1 | ❌ Access denied | `pip install lseg-data` |\n\n**Working example with `refinitiv.data`:**\n```python\nimport refinitiv.data as rd\n\nrd.open_session()\ndf = rd.get_data(\n    universe=[‘IVV’],  # iShares Core S&P 500 ETF\n    fields=[\n        ‘TR.CUSIP’,\n        ‘TR.FundLaunchDate’,\n        ‘TR.FundNAV’,\n        ‘TR.FundTotalNetAsset’,\n        ‘TR.FundCompany’,\n        ‘TR.FundTrackingError1Year’,\n        ‘TR.FundTrackingError5Year’,\n        ‘TR.FundTrackingError10Year’,\n    ]\n)\nprint(df)\n#   Instrument      CUSIP Launch Date         NAV             Fund Company  Tracking Error 1Y  ...\n# 0        IVV  464287200  2000-05-15  695.787139  BlackRock Fund Advisors           0.001317  ...\nrd.close_session()\n```\n\n**Same code with `lseg.data` fails:**\n```python\nimport lseg.data as ld\nld.open_session()\ndf = ld.get_data(universe=[‘IVV’], fields=[‘TR.FundNAV’, ...])\n# Result: LDError: The access to field(s) denied.\n```\n\n### Available Fund Fields (via refinitiv.data)\n\n| Field | Description | Example (QQQ) |\n|-------|-------------|---------------|\n| `TR.CommonName` | Fund name | Invesco QQQ Trust Series 1 |\n| `TR.CUSIP` | CUSIP identifier | 46090E103 |\n| `TR.ISIN` | ISIN identifier | US46090E1038 |\n| `TR.FundLaunchDate` | Fund inception date | 1999-03-10 |\n| `TR.FundCompany` | Fund company/advisor | Invesco Capital Management LLC |\n| `TR.FundLegalStructure` | Legal structure | US - Exchange-Traded Open-end Funds |\n| `TR.FundNAV` | Net Asset Value | 625.49 |\n| `TR.FundTotalNetAsset` | Total Net Assets | (works for some funds) |\n| `TR.FundTER` | Total Expense Ratio (%) | 0.2 |\n| `TR.SharesOutstanding` | Shares outstanding | 654,350,000 |\n| `TR.CompanyMarketCap` | Market capitalization | 409,269,751,000 |\n| `TR.TotalReturn1Mo` | 1-month return | 0.25% |\n| `TR.TotalReturn3Mo` | 3-month return | 1.48% |\n| `TR.TotalReturnYTD` | YTD return | 1.82% |\n| `TR.TotalReturn1Yr` | 1-year return | 18.69% |\n| `TR.FundTrackingError1Year` | 1-year tracking error | 0.65 |\n| `TR.FundTrackingError3Year` | 3-year tracking error | 0.97 |\n| `TR.FundTrackingError5Year` | 5-year tracking error | 0.92 |\n| `TR.FundBenchmarkName` | Benchmark name | NASDAQ 100 TR |\n| `TR.FundBenchmarkType` | Benchmark type | Fund Manager |\n| `TR.FundBenchmarkInstrumentCode` | Benchmark Lipper ID | 11032760 |\n| `TR.FundBenchmarkInstrumentRIC` | Benchmark RIC | .XNDX |\n| `TR.FundTrackingError10Year` | 10-year tracking error | 1.07 |\n| `TR.FundObjective` | Investment objective | (full text) |\n| `TR.DividendYield` | Dividend yield | 0.45% |\n\n### Fields NOT Available via refinitiv.data\n\nThese fields do not resolve - use the Fund Details browser API instead:\n\n| Category | Fields Attempted |\n|----------|------------------|\n| Holdings | `TR.FundNumberOfHoldings`, `TR.FundTopHolding*`, `TR.FundTop10HoldingsWeight` |\n| Expense Breakdown | `TR.FundExpenseRatio`, `TR.FundManagementFee`, `TR.Fund12b1Fee` |\n| Lipper | `TR.LipperID`, `TR.LipperRIC`, `TR.LipperClassification`, `TR.LipperRating` |\n| ETF-specific | `TR.ETFExpenseRatio`, `TR.ETFNav`, `TR.ETFPremiumDiscount` |\n\n### refinitiv.data vs Fund Details Browser API\n\n| Data | refinitiv.data | Fund Details API |\n|------|----------------|------------------|\n| Basic Info (name, CUSIP, launch date) | ✅ | ✅ |\n| NAV, Market Cap | ✅ | ✅ |\n| TER/Expense Ratio | ✅ `TR.FundTER` | ✅ |\n| Returns (1M, 3M, YTD, 1Y) | ✅ | ✅ |\n| Tracking Error | ✅ | ✅ |\n| Benchmark Name + RIC | ✅ `.XNDX` | ✅ |\n| Fund Objective | ✅ | ✅ |\n| Dividend Yield | ✅ | ✅ |\n| **Full Holdings List** | ❌ | ✅ (e.g., 103 for QQQ) |\n| **Holdings with RICs** | ❌ | ✅ (NVDA.OQ, AAPL.OQ, etc.) |\n| **Holdings Weights** | ❌ | ✅ (% for each holding) |\n| **Holdings Share Counts** | ❌ | ✅ |\n| **Expense Breakdowns** | ❌ | ✅ (Management, 12b-1, etc.) |\n| **ESG Scores** | ❌ | ✅ |\n| **Lipper Classification** | ❌ | ✅ |\n| **Historical Holdings** | ❌ | ✅ (monthly snapshots) |\n\n**Recommendation:** Use `refinitiv.data` for basic fund metrics and screening. Use the Fund Details browser API (or browser automation) for full holdings data and detailed breakdowns.\n\n### Installation Note\n\n`refinitiv-data` requires `scipy<1.13` which conflicts with newer Python versions. Use Python 3.11:\n\n```toml\n# pixi.toml\n[dependencies]\npython = \">=3.11,<3.12\"\nscipy = \">=1.10,<1.13”\n\n[pypi-dependencies]\nrefinitiv-data = “*”\n```\n\n### Browser Automation Approach\n\nThe Fund Details API requires Workspace session authentication. Use browser automation to fetch data:\n\n```javascript\n// Run in browser console while logged into Workspace\nasync function fetchFundDetails(lipperRic) {\n  const baseUrl = “https://workspace.refinitiv.com/Apps/FundDetails/1.10.457/loadData”;\n  const requests = [‘KEY’, ‘MD’, ‘BEN’, ‘PFM’, ‘TTH’, ‘FEE’, ‘INC’, ‘CLA’, ‘DHOL~true~’];\n  const result = { lipperRic, data: {} };\n\n  for (const req of requests) {\n    const url = `${baseUrl}?requests=${req}&s=${lipperRic}&srequired=${lipperRic}&lang=en-US`;\n    const response = await fetch(url, { credentials: “include” });\n    const json = await response.json();\n    result.data[req.replace(‘~true~’, ‘’)] = json.results?.[0] || json;\n  }\n\n  // Download as JSON\n  const blob = new Blob([JSON.stringify(result, null, 2)], { type: ‘application/json’ });\n  const a = document.createElement(‘a’);\n  a.href = URL.createObjectURL(blob);\n  a.download = `fund_data_${lipperRic}.json`;\n  a.click();\n  return result;\n}\n\n// Usage: fetchFundDetails(“LP40061149”);\n```\n\n### Finding Lipper RICs\n\nUse FSCREEN to find Lipper RICs for funds/ETFs, then use those RICs with this API.\n\n## When to Use LSEG Lipper vs WRDS\n\n**Recommendation:** Use LSEG Lipper for **fund characteristics only**, not for holdings or NAV/performance data.\n\n| Data Type | Recommended Source | Rationale |\n|-----------|-------------------|-----------|\n| **Fund Characteristics** | LSEG Lipper | Classifications, benchmarks, expense ratios, fund structure |\n| **Holdings** | WRDS Thomson S12 | SEC filing-based, standardized, academic standard |\n| **NAV & Returns** | WRDS CRSP | Primary academic source, Lipper is an underlying data source for CRSP |\n| **Performance Analysis** | WRDS CRSP + MFLINKS | Links CRSP returns to S12 holdings |\n\n### Data Source Comparison\n\n| Source | Coverage | Access | Best For |\n|--------|----------|--------|----------|\n| **LSEG Lipper** (Workspace) | Fund characteristics, classifications, benchmarks | Workspace browser, `refinitiv.data` | Fund screening, peer grouping |\n| **WRDS CRSP** | NAV, returns, TNA, fund characteristics | WRDS PostgreSQL | Performance analysis, returns research |\n| **WRDS Thomson S12** | Portfolio holdings (SEC filings) | WRDS PostgreSQL | Holdings-based research |\n| **WRDS MFLINKS** | Linking tables | WRDS PostgreSQL | Merging CRSP with S12 |\n\n### Why Not Use Lipper for Holdings/NAV?\n\n1. **Holdings**: Lipper holdings are fund company-reported, not SEC filing-based. S12 uses standardized 13F/N-CSR filings.\n2. **NAV/Returns**: CRSP is the academic standard and actually uses Lipper as an underlying source. Use CRSP for consistency with published research.\n3. **Reproducibility**: WRDS provides stable, versioned datasets. Lipper data in Workspace can change.\n\n### WRDS Tables Reference\n\n```sql\n-- NAV and Returns (CRSP)\nSELECT * FROM crsp.fund_summary2 WHERE crsp_fundno = ...;\nSELECT * FROM crsp.monthly_nav WHERE crsp_fundno = ...;\n\n-- Holdings (Thomson S12)\nSELECT * FROM tfn.s12 WHERE fdate = ...;\n\n-- Link CRSP to S12\nSELECT * FROM mfl.mflink1 WHERE crsp_fundno = ...;\n```\n\n## Notes\n\n- Authentication requires active Refinitiv Workspace session (cookies)\n- Holdings data is typically updated monthly\n- The `ric` field can be used directly with `ld.get_data()` for further analysis\n- Large funds (e.g., QQQ) may have 100+ holdings\n",
        "skills/lseg-data/references/fundamentals.md": "# Fundamentals Module\n\nCompany financial data including income statement, balance sheet, cash flow, and financial ratios.\n\n## Contents\n\n- [Overview](#overview)\n- [Key Fields](#key-fields)\n- [Parameters](#parameters)\n- [Code Examples](#code-examples)\n- [Notes and Gotchas](#notes-and-gotchas)\n- [See Also](#see-also)\n\n## Overview\n\nAccess fundamental financial data for public companies worldwide. Data sourced from company filings, with standardized and as-reported values available.\n\n### Coverage\n- **Companies**: 80,000+ globally\n- **History**: Up to 20+ years for major markets\n- **Update frequency**: Daily (after filings)\n- **Periods**: Annual (FY), Quarterly (FQ), Semi-annual, LTM\n\n## Key Fields\n\n### Income Statement\n\n| Field | Description | Units |\n|-------|-------------|-------|\n| `TR.RevenueActValue` | Total revenue | Currency |\n| `TR.GrossProfit` | Gross profit | Currency |\n| `TR.OperatingIncome` | Operating income (EBIT) | Currency |\n| `TR.EBITDA` | EBITDA | Currency |\n| `TR.NetIncomeActValue` | Net income | Currency |\n| `TR.EPSActValue` | Earnings per share (basic) | Currency/share |\n| `TR.EPSDilActValue` | Earnings per share (diluted) | Currency/share |\n\n### Balance Sheet\n\n| Field | Description | Units |\n|-------|-------------|-------|\n| `TR.TotalAssetsReported` | Total assets | Currency |\n| `TR.TotalLiabilities` | Total liabilities | Currency |\n| `TR.TotalEquity` | Shareholders' equity | Currency |\n| `TR.TotalDebt` | Total debt | Currency |\n| `TR.CashAndSTInvestments` | Cash and equivalents | Currency |\n| `TR.TotalCurrentAssets` | Current assets | Currency |\n| `TR.TotalCurrentLiabilities` | Current liabilities | Currency |\n\n### Cash Flow\n\n| Field | Description | Units |\n|-------|-------------|-------|\n| `TR.OperCashFlow` | Operating cash flow | Currency |\n| `TR.CapexActValue` | Capital expenditures | Currency |\n| `TR.FreeCashFlow` | Free cash flow | Currency |\n| `TR.DividendsPaid` | Dividends paid | Currency |\n\n### Ratios & Margins\n\n| Field | Description | Units |\n|-------|-------------|-------|\n| `TR.GrossMargin` | Gross margin | Percent |\n| `TR.OperatingMargin` | Operating margin | Percent |\n| `TR.NetProfitMargin` | Net profit margin | Percent |\n| `TR.ROE` | Return on equity | Percent |\n| `TR.ROA` | Return on assets | Percent |\n| `TR.ROIC` | Return on invested capital | Percent |\n| `TR.CurrentRatio` | Current ratio | Ratio |\n| `TR.QuickRatio` | Quick ratio | Ratio |\n| `TR.DebtToEquity` | Debt to equity | Ratio |\n\n### Valuation\n\n| Field | Description | Units |\n|-------|-------------|-------|\n| `TR.PriceToBVPerShare` | Price to book value | Ratio |\n| `TR.PriceToSalesPerShare` | Price to sales | Ratio |\n| `TR.EV` | Enterprise value | Currency |\n| `TR.EVToEBITDA` | EV/EBITDA | Ratio |\n| `TR.PERatio` | Price/Earnings ratio | Ratio |\n\n## Parameters\n\n| Parameter | Description | Values |\n|-----------|-------------|--------|\n| `Period` | Fiscal period type | `FY` (annual), `FQ` (quarterly), `FS` (semi-annual), `LTM` |\n| `SDate` | Start date/period | Date or relative (`FY-4`, `FQ-8`) |\n| `EDate` | End date/period | Date or relative (`FY0`, `FQ0` = most recent) |\n| `Frq` | Frequency | `FY`, `FQ`, `FS`, `M` (monthly) |\n| `Curn` | Currency | `USD`, `EUR`, `GBP`, etc. |\n| `Scale` | Scaling factor | `6` (millions), `9` (billions) |\n\n### Period Notation\n\n| Notation | Meaning |\n|----------|---------|\n| `FY0` | Most recent fiscal year |\n| `FY-1` | Previous fiscal year |\n| `FQ0` | Most recent fiscal quarter |\n| `FQ-4` | Same quarter last year |\n| `2023-12-31` | Specific date |\n\n## Code Examples\n\n### Basic Financial Snapshot\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\n# Current fundamentals for tech companies\ndf = ld.get_data(\n    universe=['AAPL.O', 'MSFT.O', 'GOOGL.O', 'AMZN.O', 'META.O'],\n    fields=[\n        'TR.CompanyName',\n        'TR.RevenueActValue',\n        'TR.NetIncomeActValue',\n        'TR.EPSActValue',\n        'TR.CompanyMarketCap'\n    ],\n    parameters={'Period': 'FY0'}  # Most recent fiscal year\n)\n\nld.close_session()\nprint(df)\n```\n\n### Historical Quarterly Data\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\n# Last 8 quarters of revenue and EPS\ndf = ld.get_data(\n    universe='AAPL.O',\n    fields=[\n        'TR.RevenueActValue',\n        'TR.RevenueActValue.date',  # Get period end date\n        'TR.EPSActValue',\n        'TR.GrossMargin'\n    ],\n    parameters={\n        'SDate': 'FQ-7',\n        'EDate': 'FQ0',\n        'Period': 'FQ'\n    }\n)\n\nld.close_session()\nprint(df)\n```\n\n### Multi-Year Annual Comparison\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\n# 5-year annual financials\ndf = ld.get_data(\n    universe=['AAPL.O', 'MSFT.O'],\n    fields=[\n        'TR.RevenueActValue',\n        'TR.NetIncomeActValue',\n        'TR.OperatingMargin',\n        'TR.ROE',\n        'TR.FreeCashFlow'\n    ],\n    parameters={\n        'SDate': 'FY-4',\n        'EDate': 'FY0',\n        'Period': 'FY',\n        'Curn': 'USD',\n        'Scale': 6  # Millions\n    }\n)\n\nld.close_session()\nprint(df)\n```\n\n### Balance Sheet Analysis\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\n# Balance sheet items\ndf = ld.get_data(\n    universe=['AAPL.O', 'MSFT.O', 'GOOGL.O'],\n    fields=[\n        'TR.TotalAssetsReported',\n        'TR.TotalLiabilities',\n        'TR.TotalEquity',\n        'TR.TotalDebt',\n        'TR.CashAndSTInvestments',\n        'TR.CurrentRatio',\n        'TR.DebtToEquity'\n    ],\n    parameters={'Period': 'FQ0'}\n)\n\nld.close_session()\nprint(df)\n```\n\n### Financial Ratios Time Series\n\n```python\nimport lseg.data as ld\nimport pandas as pd\n\nld.open_session()\n\n# Profitability ratios over time\ndf = ld.get_data(\n    universe='AAPL.O',\n    fields=[\n        'TR.GrossMargin',\n        'TR.OperatingMargin',\n        'TR.NetProfitMargin',\n        'TR.ROE',\n        'TR.ROIC'\n    ],\n    parameters={\n        'SDate': 'FY-9',\n        'EDate': 'FY0',\n        'Period': 'FY'\n    }\n)\n\nld.close_session()\n\n# Reshape for analysis\ndf_melted = df.melt(id_vars=['Instrument'], var_name='Metric', value_name='Value')\nprint(df_melted)\n```\n\n### Estimates vs Actuals\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\n# Compare estimates to actuals\ndf = ld.get_data(\n    universe='AAPL.O',\n    fields=[\n        'TR.EPSActValue',        # Actual EPS\n        'TR.EPSMean',            # Consensus estimate\n        'TR.EPSSurprise',        # Surprise amount\n        'TR.EPSSurprisePct',     # Surprise percentage\n        'TR.RevenueActValue',\n        'TR.RevenueMean'\n    ],\n    parameters={\n        'SDate': 'FQ-3',\n        'EDate': 'FQ0',\n        'Period': 'FQ'\n    }\n)\n\nld.close_session()\nprint(df)\n```\n\n## Notes and Gotchas\n\n### 1. Currency Matters\n\nFinancial values are reported in the company's reporting currency by default:\n```python\n# Apple reports in USD, SAP reports in EUR\n# Specify Curn to convert:\nparameters={'Curn': 'USD'}  # Convert all to USD\n```\n\n### 2. Fiscal Year Alignment\n\nCompanies have different fiscal year ends:\n- Apple: September\n- Microsoft: June\n- Most companies: December\n\nBe aware when comparing across companies.\n\n### 3. Actual vs Standardized Fields\n\n| Field Type | Example | Notes |\n|------------|---------|-------|\n| `*ActValue` | `TR.RevenueActValue` | As reported by company |\n| Standard | `TR.Revenue` | LSEG standardized |\n\nUse `ActValue` fields for precise as-reported data.\n\n### 4. Missing Historical Data\n\nNot all fields available for all periods:\n```python\n# Check for NaN values\ndf.dropna(subset=['TR.RevenueActValue'])\n```\n\n### 5. Restated Financials\n\nCompanies sometimes restate historical data. LSEG typically provides the most recent version. For point-in-time analysis, check update dates.\n\n### 6. Scale Parameter\n\nLarge numbers can be scaled for readability:\n```python\nparameters={'Scale': 6}  # Divide by 1,000,000 (millions)\nparameters={'Scale': 9}  # Divide by 1,000,000,000 (billions)\n```\n\n## See Also\n\n- [SKILL.md](../SKILL.md) - Core API patterns\n- [esg.md](esg.md) - ESG scores\n- [symbology.md](symbology.md) - Identifier conversion\n- [WRDS_COMPARISON.md](../WRDS_COMPARISON.md) - Compustat field mapping\n",
        "skills/lseg-data/references/infrastructure.md": "# Infrastructure / Project Finance Data (SDC Platinum)\n\nAccess infrastructure and project finance deal data via the LSEG Data Library using `TR.PJF*` fields.\n\n## Overview\n\nInfrastructure/Project Finance data comes from SDC Platinum. Queries return **multiple rows per company** (one per project where the company is a sponsor, developer, or participant).\n\n## Quick Start\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\ndf = ld.get_data(\n    universe=[‘NEE.N’, ‘SO.N’, ‘DUK.N’, ‘D.N’],  # Utility companies\n    fields=[\n        ‘TR.PJFAnnouncementDate’,\n        ‘TR.PJFProjectName’,\n        ‘TR.PJFProjectNation’,\n        ‘TR.PJFProjectStatus’,\n        ‘TR.PJFTotalProjectCost’,\n        ‘TR.PJFFinancingAmt’,\n        ‘TR.PJFIndSector’,\n    ]\n)\n# Returns multiple rows per company (one per infrastructure project)\n\nld.close_session()\n```\n\n## Available Fields\n\n### Project Identification\n\n| Field | Description |\n|-------|-------------|\n| `TR.PJFDealId` | SDC deal identifier |\n| `TR.PJFSdcDealNumber` | SDC deal number |\n| `TR.PJFAnnouncementDate` | Project announcement date |\n\n### Project Details\n\n| Field | Description |\n|-------|-------------|\n| `TR.PJFProjectName` | Project name |\n| `TR.PJFProjectNation` | Project country |\n| `TR.PJFProjectLocation` | Project location |\n| `TR.PJFProjectStatus` | Status (Operational, Under Construction, etc.) |\n| `TR.PJFProjectType` | Project type |\n| `TR.PJFProjectSynopsis` | Project description |\n| `TR.PJFIsProjectMultinational` | Multinational flag |\n\n### Industry Classification\n\n| Field | Description |\n|-------|-------------|\n| `TR.PJFIndSector` | Industry sector (Power, Oil And Gas, etc.) |\n| `TR.PJFIndSubSector` | Industry sub-sector (Gas Pipeline, Solar, etc.) |\n\n### Financials\n\n| Field | Description |\n|-------|-------------|\n| `TR.PJFTotalProjectCost` | Total project cost |\n| `TR.PJFFinancingAmt` | Financing amount |\n| `TR.PJFFinancingCategory` | Financing category |\n| `TR.PJFFinancingSubCategory` | Financing sub-category |\n| `TR.PJFFinancingStatus` | Financing status |\n| `TR.PJFFinancedDate` | Date financing closed |\n\n### Sponsors\n\n| Field | Description |\n|-------|-------------|\n| `TR.PJFSponsorShortName` | Sponsor/developer name |\n| `TR.PJFSponsorCurrSharePct` | Sponsor ownership percentage |\n| `TR.PJFSponsorPubStatus` | Sponsor public/private status |\n| `TR.PJFSponsorFinancialAdvisor` | Sponsor’s financial advisor |\n| `TR.PJFSponsorLegalAdvisor` | Sponsor’s legal advisor |\n\n### Advisors\n\n| Field | Description |\n|-------|-------------|\n| `TR.PJFFinancialAdvisor` | Project financial advisor |\n| `TR.PJFFinancialAdvisorRole` | Advisor role |\n| `TR.PJFLegalAdvisorCode` | Legal advisor |\n| `TR.PJFLegalAdvisorRole` | Legal advisor role |\n\n### Offtake Contracts\n\n| Field | Description |\n|-------|-------------|\n| `TR.PJFOfftakerShortName` | Offtaker name |\n| `TR.PJFOfftakerPubStatus` | Offtaker public/private status |\n| `TR.PJFOfftakeContractType` | Contract type (PPA, etc.) |\n| `TR.PJFOfftakeContractSigningDate` | Contract signing date |\n| `TR.PJFOfftakeDuration` | Contract duration |\n| `TR.PJFOfftakeOutputTaken` | Output percentage taken |\n| `TR.PJFIsOfftakeContractExtendible` | Extendible flag |\n\n### Construction & Operations\n\n| Field | Description |\n|-------|-------------|\n| `TR.PJFConstStartDate` | Construction start date |\n| `TR.PJFConstEndDate` | Construction end date |\n| `TR.PJFConstructionSupplyShortName` | EPC contractor name |\n| `TR.PJFConstructionSupplyContractType` | EPC contract type |\n| `TR.PJFConstructionSupplyContractValue` | EPC contract value |\n| `TR.PJFOpsAndMainContractorShortName` | O&M contractor name |\n| `TR.PJFOpsAndMainContractType` | O&M contract type |\n| `TR.PJFOpsAndMainContractValue` | O&M contract value |\n\n### Government Support\n\n| Field | Description |\n|-------|-------------|\n| `TR.PJFGovtLevelOfSupport` | Government support level |\n| `TR.PJFGovtSupportType` | Type of government support |\n| `TR.PJFIsPvtFinanceInitiative` | Private Finance Initiative flag |\n| `TR.PJFIsPrivatization` | Privatization flag |\n\n### Related Financing\n\n| Field | Description |\n|-------|-------------|\n| `TR.PJFRelLNAnnouncementDate` | Related loan announcement date |\n| `TR.PJFRelLNTotalFacilityAmount` | Related loan facility amount |\n| `TR.PJFRelLNTrancheAmount` | Related loan tranche amount |\n| `TR.PJFRelLNLeadManager` | Lead arranger |\n| `TR.PJFRelDebtNIIssueDate` | Related bond issue date |\n| `TR.PJFRelDebtNIPrincipalAmtThisMkt` | Related bond principal amount |\n| `TR.PJFRelDebtNIRatingsMoodysDebt` | Moody’s bond rating |\n| `TR.PJFRelDebtNIRatingsSPDebt` | S&P bond rating |\n| `TR.PJFRelEquityNIIssueDate` | Related equity issue date |\n| `TR.PJFRelEquityNIPrincipalAmtThisMkt` | Related equity amount |\n\n### Project Risk\n\n| Field | Description |\n|-------|-------------|\n| `TR.PJFHasProjectDefaulted` | Default flag |\n| `TR.PJFIsProjectUnderLitigation` | Litigation flag |\n| `TR.PJFIsProjectRefinanced` | Refinanced flag |\n| `TR.PJFIsActProjectFinanced` | Project finance flag |\n\n## Common Industry Sectors\n\n| Sector | Sub-sectors |\n|--------|-------------|\n| Power | Gas, Coal, Nuclear, Solar, Wind, Hydro, Biomass |\n| Oil And Gas | Gas Pipeline, Oil Pipeline, LNG, Refinery |\n| Transportation | Road, Rail, Airport, Port, Bridge |\n| Water | Water Treatment, Desalination |\n| Social Infrastructure | Hospital, School, Prison |\n| Telecommunications | Fiber, Satellite |\n\n## Example Output\n\n| Instrument | Project Name | Nation | Status | Cost | Sector |\n|------------|--------------|--------|--------|------|--------|\n| NEE.N | Mamonal Power Project | Colombia | Operational | $44.2B | Power |\n| NEE.N | Florida Gas Phase III | United States | Operational | $900M | Oil And Gas |\n| SO.N | Vogtle Nuclear Units 3&4 | United States | Under Construction | $25B | Power |\n| DUK.N | Piedmont Natural Gas | United States | Operational | $4.9B | Oil And Gas |\n\n## Practical Workflow\n\n```python\nimport lseg.data as ld\nimport pandas as pd\n\nld.open_session()\n\n# Get utility and energy companies\nenergy_companies = ld.get_data(\n    universe=’SCREEN(U(IN(Equity(active,public,primary))),IN(TR.TRBCEconSectorCode,”50”),IN(TR.HQCountryCode,”US”),CURN=USD)’,\n    fields=[‘TR.CommonName’]\n)\nrics = energy_companies[‘Instrument’].tolist()\n\n# Query infrastructure projects in batches\nbatch_size = 50\nall_projects = []\n\nfor i in range(0, len(rics), batch_size):\n    batch = rics[i:i+batch_size]\n    df = ld.get_data(\n        universe=batch,\n        fields=[\n            ‘TR.PJFAnnouncementDate’,\n            ‘TR.PJFProjectName’,\n            ‘TR.PJFProjectStatus’,\n            ‘TR.PJFTotalProjectCost’,\n            ‘TR.PJFIndSector’,\n        ]\n    )\n    df = df.dropna(subset=[‘Project Name’])\n    all_projects.append(df)\n\nprojects_df = pd.concat(all_projects, ignore_index=True)\n\nld.close_session()\n```\n\n## Data Characteristics\n\n- **Multiple rows per company**: Each project gets its own row\n- **Sponsor relationships**: Companies appear as sponsors, developers, offtakers, or contractors\n- **Global coverage**: Projects from around the world\n- **Historical depth**: Data going back to 1990s\n- **Cross-references**: Links to related loans, bonds, and equity issuances\n\n## Limitations\n\n1. **Must query by ticker**: Need a list of target companies first\n2. **No direct SCREEN**: `SCREEN(U(IN(DEALS)))` only works in Workspace\n3. **Rate limits**: Batch queries to avoid API limits\n4. **Large result sets**: Utility companies can have hundreds of projects\n\n## Related SDC Datasets\n\n- **Syndicated Loans**: `TR.LN*` fields - see `syndicated-loans.md`\n- **Corporate Governance**: `TR.SACT*`, `TR.PP*` - see `corporate-governance.md`\n",
        "skills/lseg-data/references/joint-ventures.md": "# Joint Ventures & Strategic Alliances Data (SDC Platinum)\n\nAccess joint venture and strategic alliance data via the LSEG Data Library using `TR.JV*` fields.\n\n## Overview\n\nJoint venture/strategic alliance data comes from SDC Platinum. Queries return **multiple rows per company** (one per alliance where the company is a participant).\n\n**Field count**: 301 fields available with TR.JV* prefix.\n\n## Quick Start\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\ndf = ld.get_data(\n    universe=[‘MSFT.O’, ‘GOOGL.O’, ‘AAPL.O’],\n    fields=[\n        ‘TR.JVDealName’,\n        ‘TR.JVDateAnnounced’,\n        ‘TR.JVDateCompleted’,\n        ‘TR.JVStatus’,\n        ‘TR.JVIsAJointVenture’,\n        ‘TR.JVParticipantName’,\n    ]\n)\n# Returns multiple rows per company (one per alliance)\n\nld.close_session()\n```\n\n## Available Fields\n\n### Deal Identification\n\n| Field | Description |\n|-------|-------------|\n| `TR.JVDealId` | Joint venture/strategic alliance deal identifier |\n| `TR.JVSDCDealNumber` | SDC deal number |\n| `TR.JVDealName` | Deal name (participants + type) |\n| `TR.JVJVName` | Joint venture company name (if JV flag is True) |\n\n### Key Dates\n\n| Field | Description |\n|-------|-------------|\n| `TR.JVDateAnnounced` | Announcement date |\n| `TR.JVDateCompleted` | Completion/signing date |\n| `TR.JVDateSought` | Date partner sought |\n| `TR.JVDateExpired` | Expiration date |\n| `TR.JVDateExtended` | Extension date |\n| `TR.JVDateTerminated` | Termination date |\n| `TR.JVDateRenegotiated` | Renegotiation date |\n| `TR.JVDateExpirationExpected` | Expected expiration date |\n\n### Status\n\n| Field | Description |\n|-------|-------------|\n| `TR.JVStatus` | Current status (S=Seeking, P=Pending, C=Completed, T=Terminated) |\n| `TR.JVJointVentureType` | JV type (NF=Newly Formed, AM=Assets Merged, PA=Pct Acquired) |\n\n### Alliance Type Flags\n\n| Field | Description |\n|-------|-------------|\n| `TR.JVIsAJointVenture` | Joint venture flag (creates independent business entity) |\n| `TR.JVIsAStrategicAlliance` | Strategic alliance flag (no independent entity) |\n| `TR.JVIsALicensingAgreement` | Licensing agreement flag |\n| `TR.JVIsAnExclusiveLicensingAgreement` | Exclusive licensing flag |\n| `TR.JVIsAResearchAndDevtAgreement` | R&D agreement flag |\n| `TR.JVIsAManufacturingAgreement` | Manufacturing agreement flag |\n| `TR.JVIsAMarketingAgreement` | Marketing agreement flag |\n| `TR.JVIsASupplyAgreement` | Supply agreement flag |\n| `TR.JVIsAnOEM` | OEM/VAR agreement flag |\n| `TR.JVIsAnExplorationAgreement` | Exploration agreement flag |\n| `TR.JVIsAFundingAgreement` | Funding agreement flag |\n| `TR.JVIsARoyaltyAgreement` | Royalty agreement flag |\n\n### Technique Flags\n\n| Field | Description |\n|-------|-------------|\n| `TR.JVIsCrossBorder` | Cross-border flag |\n| `TR.JVHasCrossBorderParticipants` | Cross-border participants flag |\n| `TR.JVHasTechnologyTransfer` | Technology transfer flag |\n| `TR.JVHasCrossTechnologyTransfer` | Cross technology transfer flag |\n| `TR.JVHasCrossLicensingAgreement` | Cross-licensing flag |\n| `TR.JVHasEquityStakePurchase` | Equity stake purchase flag |\n| `TR.JVHasEquityTransferAgreement` | Equity transfer flag |\n| `TR.JVIsCrossEquityTransfer` | Cross equity transfer flag |\n| `TR.JVIsASpinout` | Spinout flag |\n| `TR.JVIsPrivatization` | Privatization flag |\n| `TR.JVIsLeveraged` | Leveraged JV flag |\n\n### Participant Information\n\n| Field | Description |\n|-------|-------------|\n| `TR.JVParticipant` | Participant PermID |\n| `TR.JVParticipantName` | Participant long name |\n| `TR.JVParticipantShortName` | Participant short name |\n| `TR.JVParticipantSDCCusip` | Participant CUSIP |\n| `TR.JVParticipantNation` | Participant nation |\n| `TR.JVParticipantPublicStatus` | Participant public status (P/V/S/G/J) |\n| `TR.JVParticipantCity` | Participant city |\n| `TR.JVParticipantState` | Participant state |\n| `TR.JVParticipantRole` | Participant role |\n| `TR.JVNumOfParticipants` | Total number of participants |\n\n### Participant Ownership\n\n| Field | Description |\n|-------|-------------|\n| `TR.JVParticipantTotalOwnership` | Total percentage held in JV |\n| `TR.JVParticipantOriginalOwnership` | Original percentage held |\n| `TR.JVParticipantOptionalOwnership` | Optional increase percentage |\n| `TR.JVIsOwnershipEstimated` | Ownership estimated flag |\n| `TR.JVIsStakeOptionAvailable` | Stake option available flag |\n\n### Participant Industry\n\n| Field | Description |\n|-------|-------------|\n| `TR.JVParticipantSic` | Participant SIC codes |\n| `TR.JVParticipantPrimarySic` | Participant primary SIC |\n| `TR.JVParticipantVeic` | Participant VEIC codes |\n| `TR.JVParticipantPrimaryVeic` | Participant primary VEIC |\n| `TR.JVParticipantHiTech` | Participant high-tech industry |\n| `TR.JVParticipantSdcIndustry` | Participant SDC industry |\n\n### Participant Hierarchy\n\n| Field | Description |\n|-------|-------------|\n| `TR.JVParticipantParentShortName` | Participant parent name |\n| `TR.JVParticipantParentSDCCusip` | Participant parent CUSIP |\n| `TR.JVParticipantUltParentShortName` | Participant ultimate parent name |\n| `TR.JVParticipantUltParentSDCCusip` | Participant ultimate parent CUSIP |\n| `TR.JVParticipantUltParentNation` | Participant ultimate parent nation |\n\n### Joint Venture Company\n\n| Field | Description |\n|-------|-------------|\n| `TR.JVJVName` | JV company name |\n| `TR.JVJointVentureSDCCusip` | JV CUSIP |\n| `TR.JVJointVenturePublicStatus` | JV public status |\n| `TR.JVJointVentureEmployees` | JV number of employees |\n| `TR.JVJointVenturePrimarySic` | JV primary SIC |\n| `TR.JVJointVentureStockExch` | JV stock exchange |\n| `TR.JVJointVentureTicker` | JV ticker symbol |\n\n### Alliance Geography\n\n| Field | Description |\n|-------|-------------|\n| `TR.JVAllianceNation` | Alliance nation |\n| `TR.JVAllianceNationRegion` | Alliance nation region |\n| `TR.JVAllianceState` | Alliance state |\n| `TR.JVAllianceCity` | Alliance city |\n| `TR.JVAllianceStateLaw` | Alliance jurisdiction state |\n\n### Alliance Industry\n\n| Field | Description |\n|-------|-------------|\n| `TR.JVAllianceActivity` | Alliance activities |\n| `TR.JVAllianceSic` | Alliance SIC codes |\n| `TR.JVAlliancePrimarySic` | Alliance primary SIC |\n| `TR.JVAllianceVeic` | Alliance VEIC codes |\n| `TR.JVAlliancePrimaryVeic` | Alliance primary VEIC |\n| `TR.JVAllianceHiTech` | Alliance high-tech codes |\n| `TR.JVAllianceMajorIndustry` | Alliance major industry |\n| `TR.JVAllianceTechnique` | Alliance technique codes |\n\n### Financial Estimates\n\n| Field | Description |\n|-------|-------------|\n| `TR.JVEstimatedCapitalizationValue` | Estimated capitalization |\n| `TR.JVEstimatedAssetValue` | Estimated asset value |\n| `TR.JVEstimatedCostValue` | Estimated cost |\n| `TR.JVEstimatedFundingValue` | Estimated funding amount |\n| `TR.JVEstimatedSalesValue` | Estimated annual sales |\n| `TR.JVEstimatedLicenseFeeValue` | Estimated license fee |\n| `TR.JVEstimatedRoyaltyFeeValue` | Estimated royalty fee |\n| `TR.JVEstimatedSFBridgeLoanValue` | Estimated bridge loan value |\n| `TR.JVEstimatedOtherValue` | Other estimated value |\n\n### Deal Terms\n\n| Field | Description |\n|-------|-------------|\n| `TR.JVExpectedTotalLength` | Expected total length (years) |\n| `TR.JVExpectedOriginalLength` | Expected original length (years) |\n| `TR.JVHasOpenEndedLength` | Open-ended length flag |\n| `TR.JVSourceOfFunds` | Source of funds codes |\n| `TR.JVRegulatoryAgency` | Regulatory agencies required |\n\n### Deal Text\n\n| Field | Description |\n|-------|-------------|\n| `TR.JVDealSynopsis` | Deal synopsis text |\n| `TR.JVApplicationAndTechnologyDesc` | Application and technology text |\n| `TR.JVCapitalizationAndFinancingDesc` | Capitalization and financing text |\n| `TR.JVSourceOfFundsDesc` | Source of funds text |\n\n### History Events\n\n| Field | Description |\n|-------|-------------|\n| `TR.JVHistoryEventDate` | Historic event date |\n| `TR.JVHistoryEventDesc` | Historic event text |\n\n### Advisors\n\n| Field | Description |\n|-------|-------------|\n| `TR.JVFinAdvisor` | Financial advisor name |\n| `TR.JVFinAdvisorCode` | Financial advisor code |\n| `TR.JVLegAdvisor` | Legal advisor name |\n| `TR.JVLegAdvisorCode` | Legal advisor code |\n| `TR.JVAuditor` | Auditor name |\n| `TR.JVAuditorCode` | Auditor code |\n| `TR.JVAdvisorAndRole` | Advisor and role |\n\n### Related Deals\n\n| Field | Description |\n|-------|-------------|\n| `TR.JVRelatedJVSDCDealNumber` | Related alliance deal number |\n| `TR.JVRelatedJVDealName` | Related alliance deal name |\n| `TR.JVRelatedJVStatus` | Related alliance status |\n| `TR.JVRelatedMnASDCDealNumber` | Related M&A deal number |\n| `TR.JVRelatedMnAAcquirorShortName` | Related M&A acquiror name |\n| `TR.JVRelatedMnATargetShortName` | Related M&A target name |\n| `TR.JVRelatedMnADealValue` | Related M&A deal value |\n| `TR.JVRelatedSPSDCDealNumber` | Related M&A stake purchase deal number |\n\n### Contact Information\n\n| Field | Description |\n|-------|-------------|\n| `TR.JVContactName` | Contact person name |\n| `TR.JVContactEmail` | Contact email |\n| `TR.JVContactPhoneNo` | Contact phone |\n| `TR.JVContactWebsite` | Contact website |\n\n## Example Output\n\n| Instrument | Deal Name | Date Announced | Status | JV Flag |\n|------------|-----------|----------------|--------|---------|\n| MSFT.O | Microsoft/OpenAI-Strategic Alliance | 2019-07-22 | Completed | False |\n| GOOGL.O | Google/Samsung-Joint Venture | 2020-01-15 | Completed | True |\n| AAPL.O | Apple/IBM-Strategic Alliance | 2014-07-15 | Completed | False |\n\n## Practical Workflow\n\n### Query Alliances for a Universe\n\n```python\nimport lseg.data as ld\nimport pandas as pd\n\nld.open_session()\n\n# Get tech companies\ntech_rics = [‘MSFT.O’, ‘GOOGL.O’, ‘META.O’, ‘AMZN.O’]\n\n# Query joint ventures and strategic alliances\ndf = ld.get_data(\n    universe=tech_rics,\n    fields=[\n        ‘TR.JVDealName’,\n        ‘TR.JVDateAnnounced’,\n        ‘TR.JVDateCompleted’,\n        ‘TR.JVStatus’,\n        ‘TR.JVIsAJointVenture’,\n        ‘TR.JVIsAStrategicAlliance’,\n        ‘TR.JVParticipantShortName’,\n        ‘TR.JVAllianceActivity’,\n    ]\n)\n\n# Filter to actual alliances\ndf = df.dropna(subset=[‘JV Date Announced’])\n\nld.close_session()\n```\n\n### Filter by Alliance Type\n\n```python\n# Filter to joint ventures only (independent entity created)\njvs = df[df[‘JV Is A Joint Venture’] == True]\n\n# Filter to strategic alliances only (no independent entity)\nsas = df[df[‘JV Is A Strategic Alliance’] == True]\n\n# Filter to R&D alliances\nrd_alliances = df[df[‘JV Is A Research And Devt Agreement’] == True]\n```\n\n### Filter by Status\n\n```python\n# Status codes:\n# C = Completed/Signed\n# P = Pending\n# S = Seeking partner\n# T = Terminated\n# X = Expired\n\ncompleted = df[df[‘JV Status’] == ‘Completed/Signed’]\npending = df[df[‘JV Status’] == ‘Pending’]\n```\n\n## Data Characteristics\n\n- **Multiple rows per company**: Each alliance gets its own row\n- **Participant-centric**: Company may appear multiple times in same alliance\n- **Historical depth**: Data goes back to 1980s\n- **Global coverage**: Worldwide joint ventures and alliances\n- **Alliance lifecycle**: Tracks from seeking through termination/expiration\n\n## Status Code Reference\n\n| Code | Status | Description |\n|------|--------|-------------|\n| S | Seeking | Partner seeking other partners |\n| P | Pending | Partners plan/agree to form alliance |\n| C | Completed/Signed | Alliance officially completed |\n| T | Terminated | Alliance terminated before expiration |\n| X | Expired | Alliance expired per original terms |\n| R | Renegotiated | Alliance terms renegotiated |\n\n## Alliance Type Reference\n\n| Flag Field | Description |\n|------------|-------------|\n| `IsAJointVenture` | Creates independent business entity |\n| `IsAStrategicAlliance` | No independent entity, allocates responsibilities |\n| `IsALicensingAgreement` | Grants license to use IP/technology |\n| `IsAResearchAndDevtAgreement` | Joint R&D activities |\n| `IsAManufacturingAgreement` | Joint manufacturing |\n| `IsAMarketingAgreement` | Joint marketing/distribution |\n| `IsASupplyAgreement` | Supply chain agreement |\n| `IsAnOEM` | OEM/VAR agreement |\n| `IsAFundingAgreement` | Non-equity funding arrangement |\n\n## Limitations\n\n1. **Must query by ticker**: Need a list of companies first\n2. **Multiple rows per alliance**: Same alliance appears for each participant\n3. **Rate limits**: Batch queries to avoid API limits\n4. **Text fields**: Synopsis fields may be lengthy\n\n## Related SDC Datasets\n\n- **M&A**: `TR.MnA*` fields - see `mna.md`\n- **Private Equity**: `TR.PEInvest*` fields - see `private-equity.md`\n- **Syndicated Loans**: `TR.LN*` fields - see `syndicated-loans.md`\n",
        "skills/lseg-data/references/mna.md": "# M&A Deals Data (SDC Platinum)\n\nAccess mergers and acquisitions deal data via the LSEG Data Library using `TR.MnA*` fields.\n\n## Overview\n\nM&A data comes from SDC Platinum (now integrated into LSEG). Like other deal databases, M&A queries return **multiple rows per company** (one per deal where the company was acquiror or target).\n\n**Field count**: 2,683 fields available with TR.MnA* prefix.\n\n## Quick Start\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\ndf = ld.get_data(\n    universe=[‘MSFT.O’, ‘GOOGL.O’, ‘META.O’],\n    fields=[\n        ‘TR.MnAAnnouncementDate’,\n        ‘TR.MnAAcquirorName’,\n        ‘TR.MnATargetName’,\n        ‘TR.MnADealValue’,\n        ‘TR.MnADealStatus’,\n        ‘TR.MnADealType’,\n    ]\n)\n# Returns multiple rows per company (one per M&A deal)\n\nld.close_session()\n```\n\n## Available Fields\n\n### Deal Identification\n\n| Field | Description |\n|-------|-------------|\n| `TR.MnADealId` | SDC deal identifier |\n| `TR.MnASdcDealNumber` | SDC deal number |\n| `TR.MnADealType` | Deal type (Merger, Acquisition, etc.) |\n| `TR.MnADealStatus` | Status (Completed, Pending, Withdrawn) |\n\n### Key Dates\n\n| Field | Description |\n|-------|-------------|\n| `TR.MnAAnnouncementDate` | Deal announcement date |\n| `TR.MnACompletionDate` | Deal completion/closing date |\n| `TR.MnAEffectiveDate` | Deal effective date |\n| `TR.MnAWithdrawnDate` | Withdrawal date (if applicable) |\n\n### Deal Value\n\n| Field | Description |\n|-------|-------------|\n| `TR.MnADealValue` | Total deal value |\n| `TR.MnAEquityValue` | Equity value |\n| `TR.MnAEnterpriseValue` | Enterprise value |\n| `TR.MnAPricePerShare` | Price per share offered |\n| `TR.MnAPremium1Day` | Premium to 1-day prior price |\n| `TR.MnAPremium1Week` | Premium to 1-week prior price |\n| `TR.MnAPremium4Weeks` | Premium to 4-week prior price |\n\n### Acquiror Information\n\n| Field | Description |\n|-------|-------------|\n| `TR.MnAAcquirorName` | Acquiror company name |\n| `TR.MnAAcquirorTicker` | Acquiror ticker symbol |\n| `TR.MnAAcquirorCusip` | Acquiror CUSIP |\n| `TR.MnAAcquirorNation` | Acquiror country |\n| `TR.MnAAcquirorSIC` | Acquiror SIC code |\n| `TR.MnAAcquirorPublicStatus` | Acquiror public/private status |\n\n### Acquiror Financials\n\n| Field | Description |\n|-------|-------------|\n| `TR.MnAAcquirorRevenueLTM` | Acquiror LTM revenue |\n| `TR.MnAAcquirorEBITDALTM` | Acquiror LTM EBITDA |\n| `TR.MnAAcquirorNetIncomeLTM` | Acquiror LTM net income |\n| `TR.MnAAcquirorTotalAssetsLTM` | Acquiror total assets |\n| `TR.MnAAcquirorMarketCap` | Acquiror market cap |\n\n### Target Information\n\n| Field | Description |\n|-------|-------------|\n| `TR.MnATargetName` | Target company name |\n| `TR.MnATargetTicker` | Target ticker symbol |\n| `TR.MnATargetCusip` | Target CUSIP |\n| `TR.MnATargetNation` | Target country |\n| `TR.MnATargetSIC` | Target SIC code |\n| `TR.MnATargetPublicStatus` | Target public/private status |\n\n### Target Financials\n\n| Field | Description |\n|-------|-------------|\n| `TR.MnATargetRevenueLTM` | Target LTM revenue |\n| `TR.MnATargetEBITDALTM` | Target LTM EBITDA |\n| `TR.MnATargetNetIncomeLTM` | Target LTM net income |\n| `TR.MnATargetTotalAssetsLTM` | Target total assets |\n| `TR.MnATargetMarketCap` | Target market cap |\n\n### Advisors\n\n| Field | Description |\n|-------|-------------|\n| `TR.MnAAcquirorFinAdvisor` | Acquiror financial advisor |\n| `TR.MnAAcquirorLegalAdvisor` | Acquiror legal counsel |\n| `TR.MnATargetFinAdvisor` | Target financial advisor |\n| `TR.MnATargetLegalAdvisor` | Target legal counsel |\n\n### Deal Terms\n\n| Field | Description |\n|-------|-------------|\n| `TR.MnAPaymentMethod` | Payment method (Cash, Stock, Mixed) |\n| `TR.MnACashComponent` | Cash component value |\n| `TR.MnAStockComponent` | Stock component value |\n| `TR.MnADebtComponent` | Debt component value |\n| `TR.MnAPercentSought` | Percent ownership sought |\n| `TR.MnAPercentAcquired` | Percent actually acquired |\n\n### Hostile/Defense\n\n| Field | Description |\n|-------|-------------|\n| `TR.MnAHostile` | Hostile deal flag |\n| `TR.MnADefenseTactics` | Defense tactics employed |\n| `TR.MnARelatedPoisonPill` | Related poison pill deal |\n\n## Example Output\n\n| Instrument | Announcement Date | Acquiror | Target | Deal Value | Status |\n|------------|-------------------|----------|--------|------------|--------|\n| MSFT.O | 2022-01-18 | Microsoft Corp | Activision Blizzard | $68.7B | Completed |\n| MSFT.O | 2021-04-12 | Microsoft Corp | Nuance Communications | $19.7B | Completed |\n| GOOGL.O | 2019-11-01 | Alphabet Inc | Fitbit Inc | $2.1B | Completed |\n| META.O | 2014-02-19 | Facebook Inc | WhatsApp Inc | $19.0B | Completed |\n\n## Practical Workflow\n\n### Query M&A for a Universe\n\n```python\nimport lseg.data as ld\nimport pandas as pd\n\nld.open_session()\n\n# Get S&P 500 constituents\nsp500 = ld.get_data(universe=‘0#.SPX’, fields=[‘TR.CommonName’])\nrics = sp500[‘Instrument’].tolist()\n\n# Query M&A deals in batches\nbatch_size = 100\nall_deals = []\n\nfor i in range(0, len(rics), batch_size):\n    batch = rics[i:i+batch_size]\n    df = ld.get_data(\n        universe=batch,\n        fields=[\n            ‘TR.MnAAnnouncementDate’,\n            ‘TR.MnAAcquirorName’,\n            ‘TR.MnATargetName’,\n            ‘TR.MnADealValue’,\n            ‘TR.MnADealStatus’,\n        ]\n    )\n    df = df.dropna(subset=[‘MnA Announcement Date’])\n    all_deals.append(df)\n\nmna_df = pd.concat(all_deals, ignore_index=True)\n\nld.close_session()\n```\n\n### Filter by Deal Type and Date\n\n```python\n# Filter to completed acquisitions in 2024\nmna_df[‘MnA Announcement Date’] = pd.to_datetime(\n    mna_df[‘MnA Announcement Date’]\n)\nrecent_deals = mna_df[\n    (mna_df[‘MnA Announcement Date’] >= ‘2024-01-01’) &\n    (mna_df[‘Deal Status’] == ‘Completed’)\n]\n```\n\n## Data Characteristics\n\n- **Multiple rows per company**: Each M&A deal gets its own row\n- **Bidirectional**: Company may appear as acquiror OR target\n- **Historical depth**: Data goes back to 1970s\n- **Global coverage**: Worldwide M&A transactions\n- **Deal lifecycle**: Tracks from announcement through completion/withdrawal\n\n## Limitations\n\n1. **Must query by ticker**: Need a list of companies first, then query their M&A activity\n2. **No direct SCREEN**: The `SCREEN(U(IN(DEALS)))` syntax only works in Workspace\n3. **Rate limits**: Batch queries to avoid API limits\n\n## Related SDC Datasets\n\n- **Corporate Governance**: `TR.SACT*` (activism), `TR.PP*` (poison pills) - see `corporate-governance.md`\n- **Syndicated Loans**: `TR.LN*` fields - see `syndicated-loans.md`\n- **Equity/IPO**: `TR.NI*` fields - see `equity-new-issues.md`\n",
        "skills/lseg-data/references/municipal-bonds.md": "# Municipal Bonds Data (SDC Platinum)\n\nAccess municipal bond issuance data via the LSEG Data Library using `TR.Muni*` fields.\n\n## Overview\n\nMunicipal bond data comes from SDC Platinum. Unlike equity-based datasets, muni bonds must be queried using **deal IDs** (`@DEALID` suffix) rather than ticker symbols.\n\n## Quick Start\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\n# Query by deal ID (obtained from SDC Platinum reports)\ndeal_ids = [\n    ‘154089144377@DEALID’,\n    ‘154089144290@DEALID’,\n    ‘154089144305@DEALID’,\n]\n\ndf = ld.get_data(\n    universe=deal_ids,\n    fields=[\n        ‘TR.MuniIssuerName’,\n        ‘TR.MuniIssueDescription’,\n        ‘TR.MuniSaleDate’,\n        ‘TR.MuniPrincipalAmount’,\n        ‘TR.MuniIssuerState’,\n        ‘TR.MuniRefundingStatus’,\n    ]\n)\n\nld.close_session()\n```\n\n## Available Fields\n\n### Issue Identification\n\n| Field | Description |\n|-------|-------------|\n| `TR.MuniDealId` | SDC deal identifier |\n| `TR.MuniSdcDealNumber` | SDC deal number |\n| `TR.MuniIssueNumber` | Issue number |\n| `TR.MuniSeriesOfIssue` | Series designation |\n\n### Issuer Information\n\n| Field | Description |\n|-------|-------------|\n| `TR.MuniIssuerName` | Issuer full name |\n| `TR.MuniIssuerState` | State of issuer |\n| `TR.MuniIssuerPermid` | Issuer PermID |\n\n### Issue Details\n\n| Field | Description |\n|-------|-------------|\n| `TR.MuniIssueDescription` | Issue description (GO Bonds, Revenue Bonds, etc.) |\n| `TR.MuniIssueOfferingType` | Offering type |\n| `TR.MuniIssueBidType` | Bid type (Negotiated, Competitive) |\n| `TR.MuniBackedSecurityType` | Security backing type |\n| `TR.MuniRefundingStatus` | Refunding status (New Financing, Refunding) |\n| `TR.MuniIsPreliminary` | Preliminary offering flag |\n\n### Deal Classification\n\n| Field | Description |\n|-------|-------------|\n| `TR.MuniSDCDealType` | SDC deal type |\n| `TR.MuniSDCDealTypeCategory` | Deal type category (TE = Tax Exempt) |\n\n### Financials\n\n| Field | Description |\n|-------|-------------|\n| `TR.MuniPrincipalAmount` | Principal/par amount |\n| `TR.MuniAmountOfMaturity` | Amount at maturity |\n| `TR.MuniCallPriceOfMaturity` | Call price at maturity |\n\n### Coupon & Yield\n\n| Field | Description |\n|-------|-------------|\n| `TR.MuniBeginningSerialOrTermCoupon` | Beginning serial/term coupon rate |\n| `TR.MuniFinalEndingSerialCouponRate` | Final ending serial coupon rate |\n| `TR.MuniCouponAnyMaturity` | Coupon for any maturity |\n| `TR.MuniBeginningSerialOrTermYieldAmount` | Beginning yield amount |\n| `TR.MuniFinalEndingSerialPriceYield` | Final ending price/yield |\n| `TR.MuniYieldAnyMaturity` | Yield for any maturity |\n\n### Dates\n\n| Field | Description |\n|-------|-------------|\n| `TR.MuniSaleDate` | Sale/pricing date |\n| `TR.MuniIssueDatedDate` | Issue dated date |\n| `TR.MuniBeginningSerialOrTermMaturityDate` | Beginning maturity date |\n| `TR.MuniFinalEndingSerialMaturity` | Final maturity date |\n| `TR.MuniAmountOfMaturityDate` | Maturity date for amount |\n| `TR.MuniYearToMaturity` | Years to maturity |\n\n### Underwriters\n\n| Field | Description |\n|-------|-------------|\n| `TR.MuniAllManagersCode` | All underwriter/manager codes |\n\n## Example Output\n\n| Instrument | Issuer Name | Issue Description | Sale Date | Par Amount | State |\n|------------|-------------|-------------------|-----------|------------|-------|\n| 154089144377 | New York City | General Obligation Bonds | 2025-01-15 | $500,000,000 | New York |\n| 154089144290 | California State | Revenue Bonds | 2025-01-14 | $250,000,000 | California |\n| 154089144305 | Texas Water Dev Bd | Water Revenue Bonds | 2025-01-13 | $150,000,000 | Texas |\n\n## Workflow: Getting Deal IDs\n\nSince muni bonds require deal IDs, you need to first obtain them from SDC Platinum:\n\n1. **Run a query in SDC Platinum** (e.g., last 90 days of tax-exempt issuances)\n2. **Export the deal IDs** from the results\n3. **Query via Python API** using the `@DEALID` suffix\n\n```python\n# Example: Query deals exported from SDC\ndeal_ids = [‘154089144377@DEALID’, ‘154089144290@DEALID’]  # From SDC export\n\ndf = ld.get_data(\n    universe=deal_ids,\n    fields=[‘TR.MuniIssuerName’, ‘TR.MuniPrincipalAmount’, ‘TR.MuniSaleDate’]\n)\n```\n\n## Data Characteristics\n\n- **Deal ID-based queries**: Must use `@DEALID` suffix, not ticker symbols\n- **Tax-exempt focus**: Primary coverage of tax-exempt municipal issuances\n- **Detailed maturity schedules**: Serial and term bond structures\n- **Underwriter data**: Lead and co-manager information\n\n## Limitations\n\n1. **No ticker-based queries**: Must have deal IDs from SDC Platinum first\n2. **No direct SCREEN**: Cannot screen muni universe via Python API\n3. **Rate limits**: Batch deal ID queries to avoid API limits\n\n## Related SDC Datasets\n\n- **Syndicated Loans**: `TR.LN*` fields - see `syndicated-loans.md`\n- **Infrastructure/Project Finance**: `TR.PJF*` fields - see `infrastructure.md`\n- **Private Equity**: `TR.PEInvest*` fields - see `private-equity.md`\n\n## Discovering More Fields\n\nThe fields documented here were captured from specific SDC reports. To discover additional fields:\n\n1. **Open the Column Picker** in SDC Platinum while network monitoring is active\n2. **Run different report templates** to capture fields used in each\n3. **Check field patterns** - try variations like `TR.MuniCUSIP`, `TR.MuniRating*`, etc.\n",
        "skills/lseg-data/references/news.md": "# News Data\n\nAccess news headlines and stories via the LSEG Data Library.\n\n## Overview\n\nThe LSEG Data Library provides two approaches for news retrieval:\n- **Access Layer**: `ld.news.get_headlines()` - Simple retrieval, max 100 headlines\n- **Content Layer**: `news.headlines.Definition()` - Cursor-based pagination for larger datasets\n\n**Limitations**:\n- Maximum 100 headlines per request\n- History depth: ~15 months\n- Real-time streaming requires separate subscription\n\n## Quick Start\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\n# Get headlines for a specific instrument\ndf = ld.news.get_headlines(\n    query=’R:AAPL.O AND Language:LEN’,\n    count=10\n)\nprint(df.head())\n\n# Get headlines with date range\ndf = ld.news.get_headlines(\n    query=’R:MSFT.O’,\n    start=‘2024-01-01’,\n    end=‘2024-01-31’,\n    count=50\n)\n\nld.close_session()\n```\n\n## Query Syntax\n\nNews queries use a specific syntax for filtering:\n\n| Filter | Syntax | Example |\n|--------|--------|---------|\n| Instrument | `R:<RIC>` | `R:IBM.N` |\n| Language | `Language:<code>` | `Language:LEN` (English) |\n| Topic | `Topic:<code>` | `Topic:AMERS` |\n| Source group | `SUGGAC` | Suggested academic sources |\n| Multiple conditions | `AND` | `R:AAPL.O AND Language:LEN` |\n\n### Source Filtering\n\nBy default, news queries return results from many sources which can be noisy. Use `SUGGAC` (Suggested Academic) to filter to curated, higher-quality sources:\n\n```python\n# Recommended: filter to suggested academic sources\ndf = ld.news.get_headlines(\n    query='R:MSFT.O AND SUGGAC',\n    count=100\n)\n\n# Combine with language filter\ndf = ld.news.get_headlines(\n    query='R:AAPL.O AND SUGGAC AND Language:LEN',\n    count=100\n)\n```\n\n### Language Codes\n\n| Code | Language |\n|------|----------|\n| `LEN` | English |\n| `LDE` | German |\n| `LFR` | French |\n| `LES` | Spanish |\n| `LJA` | Japanese |\n| `LZH` | Chinese |\n\n## Access Layer API\n\n### `ld.news.get_headlines()`\n\nSimple headlines retrieval without pagination.\n\n```python\ndf = ld.news.get_headlines(\n    query='R:LSEG.L AND Language:LEN',\n    count=100,           # Max 100\n    start='2024-01-01',  # Optional start date\n    end='2024-01-31',    # Optional end date\n    order_by='oldToNew'  # or 'newToOld' (default)\n)\n```\n\n**Parameters**:\n\n| Parameter | Type | Description |\n|-----------|------|-------------|\n| `query` | str | News query string |\n| `count` | int | Number of headlines (max 100) |\n| `start` | str | Start date (ISO format) |\n| `end` | str | End date (ISO format) |\n| `order_by` | str | Sort order: 'newToOld' or 'oldToNew' |\n\n**Returns**: DataFrame with columns:\n- `storyId` - Unique story identifier\n- `headline` - Headline text\n- `versionCreated` - Publication timestamp\n- `sourceCode` - News source code\n\n### Get Story Content\n\n```python\n# Get full story text from storyId\nstory = ld.news.get_story(story_id='urn:newsml:reuters.com:20240131:nL1N3...')\nprint(story)\n```\n\n## Content Layer API\n\nFor retrieving more than 100 headlines, use cursor-based pagination.\n\n```python\nfrom lseg.data.content import news\n\n# Initial request\nresponse = news.headlines.Definition(\n    query=\"R:LSEG.L\",\n    date_from=\"2024-01-01T00:00:00.000\",\n    date_to=\"2024-01-31T23:59:59.999\",\n    count=100\n).get_data()\n\n# Get headlines DataFrame\ndf = response.data.df\n\n# Check for more results\nif response.data.raw and response.data.raw[0].get(\"meta\", {}).get(\"next\"):\n    next_cursor = response.data.raw[0][\"meta\"][\"next\"]\n\n    # Fetch next page\n    response = news.headlines.Definition(\n        query=\"R:LSEG.L\",\n        cursor=next_cursor,\n        count=100\n    ).get_data()\n```\n\n### Pagination Loop\n\n```python\nfrom lseg.data.content import news\nimport pandas as pd\n\ndef get_all_headlines(query, date_from, date_to, max_headlines=1000):\n    \"\"\"Retrieve headlines with pagination.\"\"\"\n    all_headlines = []\n    cursor = None\n\n    while len(all_headlines) < max_headlines:\n        if cursor:\n            response = news.headlines.Definition(\n                query=query,\n                cursor=cursor,\n                count=100\n            ).get_data()\n        else:\n            response = news.headlines.Definition(\n                query=query,\n                date_from=date_from,\n                date_to=date_to,\n                count=100\n            ).get_data()\n\n        df = response.data.df\n        if df is None or len(df) == 0:\n            break\n\n        all_headlines.append(df)\n\n        # Check for next page\n        raw = response.data.raw\n        if raw and raw[0].get(\"meta\", {}).get(\"next\"):\n            cursor = raw[0][\"meta\"][\"next\"]\n        else:\n            break\n\n    return pd.concat(all_headlines, ignore_index=True) if all_headlines else pd.DataFrame()\n\n# Usage\ndf = get_all_headlines(\n    query=\"R:AAPL.O AND Language:LEN\",\n    date_from=\"2024-01-01T00:00:00.000\",\n    date_to=\"2024-03-31T23:59:59.999\",\n    max_headlines=500\n)\n```\n\n## Response Structure\n\n### Headlines DataFrame\n\n| Column | Description |\n|--------|-------------|\n| `storyId` | Unique identifier for the story |\n| `headline` | Headline text |\n| `versionCreated` | Publication timestamp (UTC) |\n| `sourceCode` | News source identifier |\n| `urgency` | Story urgency level |\n\n### Raw Response\n\n```python\n# Access raw API response\nraw = response.data.raw[0]\n\n# Metadata\nmeta = raw.get(\"meta\", {})\nprint(f\"Total count: {meta.get('count')}\")\nprint(f\"Next cursor: {meta.get('next')}\")\n\n# Headlines array\nheadlines = raw.get(\"data\", [])\n```\n\n## Common Patterns\n\n### Headlines for Multiple Instruments\n\n```python\n# Query multiple RICs\ninstruments = ['AAPL.O', 'MSFT.O', 'GOOGL.O']\nquery = ' OR '.join([f'R:{ric}' for ric in instruments])\n\ndf = ld.news.get_headlines(\n    query=f'({query}) AND Language:LEN',\n    count=100\n)\n```\n\n### Filter by Topic\n\n```python\n# Get earnings-related news\ndf = ld.news.get_headlines(\n    query='R:AAPL.O AND Topic:EARN',\n    count=50\n)\n\n# Get M&A news\ndf = ld.news.get_headlines(\n    query='R:MSFT.O AND Topic:MRG',\n    count=50\n)\n```\n\n### Date Range Queries\n\n```python\nfrom datetime import datetime, timedelta\n\n# Last 7 days\nend_date = datetime.now()\nstart_date = end_date - timedelta(days=7)\n\ndf = ld.news.get_headlines(\n    query='R:TSLA.O',\n    start=start_date.strftime('%Y-%m-%d'),\n    end=end_date.strftime('%Y-%m-%d'),\n    count=100\n)\n```\n\n## Topic Codes\n\nCommon topic codes for filtering:\n\n| Code | Topic |\n|------|-------|\n| `AMERS` | Americas |\n| `EMEA` | Europe/Middle East/Africa |\n| `ASIA` | Asia-Pacific |\n| `EARN` | Earnings |\n| `MRG` | Mergers & Acquisitions |\n| `IPO` | Initial Public Offerings |\n| `DIV` | Dividends |\n| `CORA` | Corporate Actions |\n| `RESF` | Research |\n| `COM` | Commodities |\n| `FX` | Foreign Exchange |\n| `STX` | Stocks |\n| `GOV` | Government/Politics |\n\n## Limitations\n\n1. **100 headlines per request**: Use Content Layer pagination for larger datasets\n2. **~15 months history**: Older news may not be available\n3. **Rate limits**: Subject to session rate limits (500 requests/minute)\n4. **Real-time streaming**: Requires separate subscription and different API\n\n## Troubleshooting\n\n### Empty Results\n\n- Verify RIC symbology (`.O` for NASDAQ, `.N` for NYSE)\n- Check date range is within 15-month window\n- Ensure language code is correct (`LEN` not `EN`)\n\n### Pagination Issues\n\n- Always check for `next` cursor in `response.data.raw[0][\"meta\"]`\n- Use cursor parameter instead of date_from/date_to for subsequent requests\n- Handle empty responses gracefully\n\n### Authentication\n\nNews API requires valid LSEG session. Verify connection:\n\n```python\nimport lseg.data as ld\n\nld.open_session()\nstate = ld.get_config()\nprint(f\"Session state: {state}\")\n```\n",
        "skills/lseg-data/references/pricing.md": "# LSEG Pricing Data\n\n## Contents\n\n- [Historical Prices](#historical-prices)\n- [Real-Time Prices](#real-time-prices)\n- [Streaming Prices](#streaming-prices)\n- [Adjusted Prices](#adjusted-prices)\n- [Multiple Instruments](#multiple-instruments)\n- [Date Chunking for Large Requests](#date-chunking-for-large-requests)\n- [Common Issues](#common-issues)\n\n## Historical Prices\n\n### get_history() API\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\n# Daily OHLCV\ndf = ld.get_history(\n    universe='AAPL.O',\n    fields=['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME'],\n    start='2023-01-01',\n    end='2023-12-31',\n    interval='daily'\n)\n\n# Intraday (1-minute bars)\ndf = ld.get_history(\n    universe='AAPL.O',\n    start='2024-01-15 09:30',\n    end='2024-01-15 16:00',\n    interval='1min'\n)\n\nld.close_session()\n```\n\n### Interval Options\n\n| Interval | Description |\n|----------|-------------|\n| `tick` | Tick-by-tick |\n| `1min`, `5min`, `15min`, `30min` | Intraday bars |\n| `1hour` | Hourly bars |\n| `daily` | Daily bars |\n| `weekly` | Weekly bars |\n| `monthly` | Monthly bars |\n\n### Common Fields\n\n| Field | Description |\n|-------|-------------|\n| `OPEN` | Open price |\n| `HIGH` | High price |\n| `LOW` | Low price |\n| `CLOSE` | Close price |\n| `VOLUME` | Trading volume |\n| `VWAP` | Volume-weighted average price |\n| `COUNT` | Number of trades |\n\n## Real-Time Prices\n\n### Snapshot Pricing\n\n```python\ndf = ld.get_data(\n    universe=['AAPL.O', 'MSFT.O'],\n    fields=['CF_LAST', 'CF_BID', 'CF_ASK', 'CF_VOLUME']\n)\n```\n\n### Real-Time Fields\n\n| Field | Description |\n|-------|-------------|\n| `CF_LAST` | Last traded price |\n| `CF_BID` | Best bid |\n| `CF_ASK` | Best ask |\n| `CF_VOLUME` | Today's volume |\n| `CF_HIGH` | Today's high |\n| `CF_LOW` | Today's low |\n| `CF_OPEN` | Today's open |\n| `CF_CLOSE` | Previous close |\n\n## Streaming Prices\n\n```python\nfrom lseg.data.content import pricing\n\n# Create streaming price object\nstreaming = pricing.Definition(\n    universe=['AAPL.O', 'MSFT.O'],\n    fields=['BID', 'ASK', 'LAST']\n).get_stream()\n\n# Open stream\nstreaming.open()\n\n# Access current values\nprint(streaming.get_snapshot())\n\n# Close when done\nstreaming.close()\n```\n\n## Adjusted Prices\n\nFor corporate action adjusted prices:\n\n```python\ndf = ld.get_history(\n    universe='AAPL.O',\n    fields=['CLOSE'],\n    start='2020-01-01',\n    end='2023-12-31',\n    adjustments=['split', 'dividend']  # Adjust for splits and dividends\n)\n```\n\n## Multiple Instruments\n\n```python\n# Get prices for multiple instruments\ndf = ld.get_history(\n    universe=['AAPL.O', 'MSFT.O', 'GOOGL.O', 'AMZN.O'],\n    fields=['CLOSE', 'VOLUME'],\n    start='2023-01-01',\n    end='2023-12-31'\n)\n\n# Result is a MultiIndex DataFrame\n# Access individual instrument: df['AAPL.O']\n```\n\n## Date Chunking for Large Requests\n\n```python\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\ndef get_history_chunked(universe, fields, start, end, chunk_days=365):\n    \"\"\"Get history in chunks to avoid rate limits.\"\"\"\n    all_data = []\n    current = datetime.strptime(start, '%Y-%m-%d')\n    end_dt = datetime.strptime(end, '%Y-%m-%d')\n\n    while current < end_dt:\n        chunk_end = min(current + timedelta(days=chunk_days), end_dt)\n\n        df = ld.get_history(\n            universe=universe,\n            fields=fields,\n            start=current.strftime('%Y-%m-%d'),\n            end=chunk_end.strftime('%Y-%m-%d')\n        )\n        all_data.append(df)\n        current = chunk_end + timedelta(days=1)\n\n    return pd.concat(all_data)\n```\n\n## Common Issues\n\n1. **Rate limits** - Max 3,000 rows per request; use chunking\n2. **Missing data** - Check if instrument was traded on requested dates\n3. **Timezone** - Prices are in exchange local time by default\n4. **Adjusted vs unadjusted** - Default is unadjusted; specify adjustments explicitly\n",
        "skills/lseg-data/references/private-equity.md": "# Private Equity / Venture Capital Data (SDC Platinum)\n\nAccess private equity and venture capital investment data via the LSEG Data Library using `TR.PEInvest*` fields.\n\n## Overview\n\nPrivate Equity/VC data comes from SDC Platinum. Queries return **multiple rows per company** (one per investment round where the company received funding).\n\n## Quick Start\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\ndf = ld.get_data(\n    universe=[‘UBER.N’, ‘ABNB.OQ’, ‘SNOW.N’, ‘PLTR.N’],  # PE-backed companies\n    fields=[\n        ‘TR.PEInvestCompanyName’,\n        ‘TR.PEInvestRoundDate’,\n        ‘TR.PEInvestRoundEquityTotal’,\n        ‘TR.PEInvestCompanyNation’,\n        ‘TR.PEInvestCompanyAllInvestorFirms’,\n        ‘TR.PEInvestCompanyCurrentOperatingStage’,\n    ]\n)\n# Returns multiple rows per company (one per investment round)\n\nld.close_session()\n```\n\n## Available Fields\n\n### Investment Round Details\n\n| Field | Description |\n|-------|-------------|\n| `TR.PEInvestDealId` | Investment round deal ID |\n| `TR.PEInvestRoundDate` | Date of investment round |\n| `TR.PEInvestRoundEquityTotal` | Total equity raised in round |\n| `TR.PEInvestBuyoutValue` | Buyout transaction value |\n| `TR.PEInvestRankValue` | Ranking value for deal |\n| `TR.PEInvestAgeAtFinancingInMonths` | Company age at time of financing |\n| `TR.PEInvestDisclosedPostRoundCompanyValuation` | Post-money valuation |\n| `TR.PEInvestPostRoundCompanyValuationDirection` | Valuation direction (up/down) |\n\n### Investee Company Information\n\n| Field | Description |\n|-------|-------------|\n| `TR.PEInvestCompanyName` | Company name |\n| `TR.PEInvestCompanyAliasName` | Company alias/trade name |\n| `TR.PEInvestCompanyNation` | Company country |\n| `TR.PEInvestInvesteeBEID` | Investee company BEID |\n| `TR.PEInvestInvesteePermID` | Investee PermID |\n| `TR.PEInvestCompanyPermID` | Company PermID |\n| `TR.PEInvestCompanyTRBCEconomicSector` | TRBC economic sector |\n| `TR.PEInvestCompanyBusinessDescriptionShort` | Short business description |\n| `TR.PEInvestCompanyBusinessDescriptionLong` | Detailed business description |\n| `TR.PEInvestCompanyWebsite` | Company website |\n| `TR.PEInvestCompanyStatus` | Company status |\n| `TR.PEInvestCompanyFoundedDate` | Date company was founded |\n\n### Company Operating Status\n\n| Field | Description |\n|-------|-------------|\n| `TR.PEInvestCompanyCurrentOperatingStage` | Current operating stage |\n| `TR.PEInvestCompanyCurrentPublicStatus` | Public/private status |\n| `TR.PEInvestCompanyPortfolioStatus` | Portfolio company status |\n| `TR.PEInvestCompanyIPODate` | IPO date (if applicable) |\n| `TR.PEInvestCompanyPrimaryCustomerType` | Primary customer type (B2B/B2C) |\n| `TR.PEInvestCompanyNumberOfEmployeesMostRecentYearEnd` | Employee count |\n\n### Investor Information\n\n| Field | Description |\n|-------|-------------|\n| `TR.PEInvestFirmInvestorBEID` | Investor firm BEID |\n| `TR.PEInvestFundInvestorBEID` | Investor fund BEID |\n| `TR.PEInvestCompanyAllInvestorFirms` | All investor firms (all rounds) |\n| `TR.PEInvestCompanyAllInvestorFunds` | All investor funds (all rounds) |\n| `TR.PEInvestCompanyCurrentInvestorFirms` | Current investor firms |\n| `TR.PEInvestCompanyCurrentInvestorFunds` | Current investor funds |\n| `TR.PEInvestCompanyHistoricalInvestorFirms` | Historical investor firms |\n| `TR.PEInvestCompanyHistoricalInvestorFunds` | Historical investor funds |\n\n### Investment History (Company Level)\n\n| Field | Description |\n|-------|-------------|\n| `TR.PEInvestCompanyFirstInvestmentReceivedDate` | First investment date |\n| `TR.PEInvestCompanyLastInvestmentReceivedDate` | Most recent investment date |\n| `TR.PEInvestCompanyNumberOfInvestmentsReceivedToDate` | Total investment rounds |\n| `TR.PEInvestCompanyNumberOfInvestorFirmsToDate` | Total investor firms |\n| `TR.PEInvestCompanyNumberOfInvestorFundsToDate` | Total investor funds |\n| `TR.PEInvestCompanyEstEquityReceivedToDate` | Total equity received |\n\n### ESG and Classification\n\n| Field | Description |\n|-------|-------------|\n| `TR.PEInvestCompanyisSustainable` | Sustainable company flag |\n| `TR.PEInvestCompanyisRealEstateProperty` | Real estate property flag |\n\n### Contact Information\n\n| Field | Description |\n|-------|-------------|\n| `TR.PEInvestCompanyPhoneNumber` | Company phone |\n| `TR.PEInvestCompanyBranchPhone` | Branch phone |\n| `TR.PEInvestCompanyFaxNumber` | Company fax |\n| `TR.PEInvestCompanyBranchFax` | Branch fax |\n\n## Example Output\n\n| Instrument | Company Name | Round Date | Round Equity | Nation | Investor Firms |\n|------------|--------------|------------|--------------|--------|----------------|\n| UBER.N | Uber Technologies Inc | 2011-02-14 | $1,250,000 | United States | Benchmark; First Round; Lowercase... |\n| UBER.N | Uber Technologies Inc | 2013-08-14 | $258,000,000 | United States | Google Ventures; TPG; Benchmark... |\n| ABNB.OQ | Airbnb Inc | 2011-07-25 | $112,000,000 | United States | Andreessen Horowitz; DST Global... |\n| SNOW.N | Snowflake Inc | 2017-04-06 | $100,000,000 | United States | Iconiq Capital; Altimeter... |\n\n## Practical Workflow\n\n```python\nimport lseg.data as ld\nimport pandas as pd\n\nld.open_session()\n\n# Get recently IPO’d tech companies\nrecent_ipos = ld.get_data(\n    universe=’SCREEN(U(IN(Equity(active,public,primary))),IN(TR.TRBCEconSectorCode,”57”),TR.IPODate>=2020-01-01,CURN=USD)’,\n    fields=[‘TR.CommonName’, ‘TR.IPODate’]\n)\nrics = recent_ipos[‘Instrument’].tolist()[:50]  # Limit to 50\n\n# Get their PE/VC funding history\npe_fields = [\n    ‘TR.PEInvestCompanyName’,\n    ‘TR.PEInvestRoundDate’,\n    ‘TR.PEInvestRoundEquityTotal’,\n    ‘TR.PEInvestCompanyAllInvestorFirms’,\n    ‘TR.PEInvestCompanyCurrentOperatingStage’,\n]\n\n# Query in batches\nbatch_size = 25\nall_pe_data = []\n\nfor i in range(0, len(rics), batch_size):\n    batch = rics[i:i+batch_size]\n    df = ld.get_data(universe=batch, fields=pe_fields)\n    df = df.dropna(subset=[‘Investee Company Name’])\n    all_pe_data.append(df)\n\npe_df = pd.concat(all_pe_data, ignore_index=True)\n\nld.close_session()\n```\n\n## Data Characteristics\n\n- **Multiple rows per company**: Each investment round gets its own row\n- **Investee-centric**: Data is about companies that received investment, not the PE/VC firms\n- **Investor details**: Full list of investor firms and funds per round\n- **Historical depth**: Investment history going back to company founding\n- **Valuation data**: Post-round valuations when disclosed\n\n## Limitations\n\n1. **Must query by ticker**: Need a list of target companies (investees) first\n2. **No direct SCREEN for deals**: `SCREEN(U(IN(PRIVATEEQUITY)))` only works in Workspace\n3. **Rate limits**: Batch queries to avoid API limits\n4. **Large result sets**: Well-funded companies can have many rounds (Uber has 40+ rows)\n\n## Related SDC Datasets\n\n- **Syndicated Loans**: `TR.LN*` fields - see `syndicated-loans.md`\n- **Infrastructure/Project Finance**: `TR.PJF*` fields - see `infrastructure.md`\n- **Corporate Governance**: `TR.SACT*`, `TR.PP*` fields - see `corporate-governance.md`\n",
        "skills/lseg-data/references/screening.md": "# LSEG Screener\n\n## Contents\n\n- [Overview](#overview)\n- [Basic Usage](#basic-usage)\n- [Screener Expression Syntax](#screener-expression-syntax)\n- [Building Screener Expressions](#building-screener-expressions)\n- [Common Screener Patterns](#common-screener-patterns)\n- [Using Screener Results](#using-screener-results)\n- [Refinitiv Workspace Integration](#refinitiv-workspace-integration)\n- [Rate Limits](#rate-limits)\n\n## Overview\n\nThe `Screener` object allows dynamic stock screening with complex criteria. Use it to filter instruments by market cap, exchange, sector, returns, and other metrics.\n\n## Basic Usage\n\n```python\nimport lseg.data as ld\nfrom lseg.data.discovery import Screener\n\nld.open_session()\n\n# Create screener with criteria\nrics = Screener(\n    'U(IN(Equity(active,public,primary))/*UNV:Public*/), '\n    'TR.CompanyMarketCap(Scale=6)>=5000, '\n    'IN(TR.ExchangeMarketIdCode,\"XNYS\"), '\n    'IN(TR.TRBCBusinessSectorCode,\"5010\",\"5020\",\"5030\"), '\n    'TR.TotalReturn3Mo>=15, '\n    'CURN=USD'\n)\n\n# Screener is iterable - returns list of RICs\nprint(list(rics))  # ['TPL.N', 'TRGP.N', 'MUSA.N']\n\n# Use with get_data()\ndf = ld.get_data(\n    rics,\n    ['TR.CommonName', 'TR.CompanyMarketCap(Scale=6)',\n     'TR.ExchangeName', 'TR.TRBCBusinessSector', 'TR.TotalReturn3Mo']\n)\n\nld.close_session()\n```\n\n## Screener Expression Syntax\n\n### Universe Selection\n\n| Expression | Description |\n|------------|-------------|\n| `U(IN(Equity(active,public,primary)))` | Active public primary equities |\n| `U(IN(Equity(active,public)))` | All active public equities |\n| `/*UNV:Public*/` | Comment for clarity |\n\n### Market Cap Filters\n\n| Expression | Description |\n|------------|-------------|\n| `TR.CompanyMarketCap(Scale=6)>=5000` | Market cap >= $5B |\n| `TR.CompanyMarketCap(Scale=6)>=1000` | Market cap >= $1B |\n| `TR.CompanyMarketCap(Scale=6)>=100` | Market cap >= $100M |\n\n### Exchange Filters\n\n| Code | Exchange |\n|------|----------|\n| `XNYS` | NYSE |\n| `XNAS` | NASDAQ |\n| `XLON` | London |\n| `XTKS` | Tokyo |\n\n```\nIN(TR.ExchangeMarketIdCode,\"XNYS\",\"XNAS\")\n```\n\n### Sector Filters (TRBC Codes)\n\n| Code | Sector |\n|------|--------|\n| `5010` | Energy - Fossil Fuels |\n| `5020` | Energy - Renewable |\n| `5030` | Energy - Utilities |\n| `5110` | Basic Materials |\n| `5210` | Industrials |\n| `5310` | Consumer Cyclicals |\n\n```\nIN(TR.TRBCBusinessSectorCode,\"5010\",\"5020\",\"5030\")\n```\n\n### Performance Filters\n\n| Expression | Description |\n|------------|-------------|\n| `TR.TotalReturn3Mo>=15` | 3-month return >= 15% |\n| `TR.TotalReturn1Yr>=20` | 1-year return >= 20% |\n| `TR.PricePercentChg52W>=10` | 52-week price change >= 10% |\n\n### Valuation Filters\n\n| Expression | Description |\n|------------|-------------|\n| `TR.PERatio<=20` | P/E <= 20 |\n| `TR.PriceToBVPerShare<=3` | P/B <= 3 |\n| `TR.DividendYield>=2` | Dividend yield >= 2% |\n\n### Currency\n\n```\nCURN=USD\n```\n\n## Building Screener Expressions\n\nCombine filters with commas:\n\n```python\nexpression = (\n    'U(IN(Equity(active,public,primary))), '\n    'TR.CompanyMarketCap(Scale=6)>=1000, '        # $1B+ market cap\n    'IN(TR.ExchangeMarketIdCode,\"XNYS\",\"XNAS\"), ' # NYSE or NASDAQ\n    'TR.PERatio<=25, '                            # P/E <= 25\n    'TR.DividendYield>=1, '                       # Dividend >= 1%\n    'CURN=USD'\n)\n\nscreener = Screener(expression)\n```\n\n## Common Screener Patterns\n\n### Large Cap Value\n\n```python\nlarge_cap_value = Screener(\n    'U(IN(Equity(active,public,primary))), '\n    'TR.CompanyMarketCap(Scale=6)>=10000, '  # $10B+\n    'TR.PERatio<=15, '\n    'TR.PriceToBVPerShare<=2, '\n    'CURN=USD'\n)\n```\n\n### High Dividend\n\n```python\nhigh_dividend = Screener(\n    'U(IN(Equity(active,public,primary))), '\n    'TR.CompanyMarketCap(Scale=6)>=1000, '\n    'TR.DividendYield>=4, '\n    'IN(TR.ExchangeMarketIdCode,\"XNYS\"), '\n    'CURN=USD'\n)\n```\n\n### Momentum\n\n```python\nmomentum = Screener(\n    'U(IN(Equity(active,public,primary))), '\n    'TR.CompanyMarketCap(Scale=6)>=5000, '\n    'TR.TotalReturn3Mo>=15, '\n    'TR.TotalReturn1Yr>=25, '\n    'CURN=USD'\n)\n```\n\n## Using Screener Results\n\n### With get_data()\n\n```python\ndf = ld.get_data(\n    screener,\n    ['TR.CommonName', 'TR.CompanyMarketCap', 'TR.PERatio']\n)\n```\n\n### With get_history()\n\n```python\nrics = list(screener)\nfor ric in rics:\n    hist = ld.get_history(\n        universe=ric,\n        fields=['CLOSE', 'VOLUME'],\n        start='2023-01-01',\n        end='2023-12-31'\n    )\n```\n\n## Refinitiv Workspace Integration\n\nTo build complex screening expressions, use the Screener app in Refinitiv Workspace:\n\n1. Open Screener app\n2. Configure filters visually\n3. Copy the generated expression\n4. Use in Python code\n\n## Rate Limits\n\n- Screener results are limited by the same rate limits as `get_data()`\n- Large result sets may be truncated\n- Consider adding stricter filters if results are too large\n",
        "skills/lseg-data/references/symbology.md": "# Symbology Module\n\nIdentifier conversion and mapping between RIC, ISIN, CUSIP, SEDOL, and other symbol types.\n\n## Contents\n\n- [Overview](#overview)\n- [Key Fields](#key-fields)\n- [Parameters](#parameters)\n- [RIC Exchange Suffixes](#ric-exchange-suffixes)\n- [Code Examples](#code-examples)\n- [Notes and Gotchas](#notes-and-gotchas)\n- [See Also](#see-also)\n\n## Overview\n\nConvert between different financial identifier systems. Essential for linking datasets, building cross-platform analytics, and mapping between LSEG and other data sources.\n\n### Supported Identifier Types\n\n| Type | Description | Example |\n|------|-------------|---------|\n| **RIC** | Reuters Instrument Code | `AAPL.O` |\n| **ISIN** | International Securities ID | `US0378331005` |\n| **CUSIP** | Committee on Uniform Security ID | `037833100` |\n| **SEDOL** | Stock Exchange Daily Official List | `2046251` |\n| **Ticker** | Exchange ticker symbol | `AAPL` |\n| **OrgId** | LSEG Organization ID | `4295905573` |\n| **PermId** | LSEG Permanent ID | `4295905573` |\n| **LEI** | Legal Entity Identifier | `HWUPKR0MPOU8FGXBT394` |\n\n## Key Fields\n\n### RIC Components\n\n| Field | Description | Example |\n|-------|-------------|---------|\n| `TR.RIC` | Full RIC | `AAPL.O` |\n| `TR.RICCode` | RIC root | `AAPL` |\n| `TR.ExchangeCode` | Exchange suffix | `O` |\n| `TR.PrimaryRIC` | Primary RIC for company | `AAPL.O` |\n\n### Identifiers\n\n| Field | Description |\n|-------|-------------|\n| `TR.ISIN` | ISIN code |\n| `TR.CUSIP` | CUSIP code |\n| `TR.SEDOL` | SEDOL code |\n| `TR.Ticker` | Ticker symbol |\n| `TR.OrganizationID` | LSEG Organization ID |\n| `TR.LEI` | Legal Entity Identifier |\n\n### Company Information\n\n| Field | Description |\n|-------|-------------|\n| `TR.CommonName` | Company common name |\n| `TR.CompanyName` | Full company name |\n| `TR.HeadquartersCountry` | HQ country |\n| `TR.TRBCEconomicSector` | TRBC sector |\n\n## Parameters\n\nFor `symbol_conversion.Definition()`:\n\n| Parameter | Description | Values |\n|-----------|-------------|--------|\n| `symbols` | List of symbols to convert | `['AAPL.O', 'MSFT.O']` |\n| `from_symbol_type` | Source identifier type | `'RIC'`, `'ISIN'`, `'CUSIP'` |\n| `to_symbol_types` | Target identifier types | `['ISIN', 'CUSIP', 'SEDOL']` |\n\n## RIC Exchange Suffixes\n\n### Major US Exchanges\n\n| Exchange | Suffix | Example |\n|----------|--------|---------|\n| NASDAQ | `.O` | `AAPL.O` |\n| NYSE | `.N` | `IBM.N` |\n| NYSE Arca | `.P` | `SPY.P` |\n| OTC | `.PK` | `TCEHY.PK` |\n\n### International Exchanges\n\n| Exchange | Suffix | Example |\n|----------|--------|---------|\n| London | `.L` | `VOD.L` |\n| Frankfurt | `.DE` | `BMW.DE` |\n| Paris | `.PA` | `OR.PA` |\n| Tokyo | `.T` | `7203.T` |\n| Hong Kong | `.HK` | `0700.HK` |\n| Sydney | `.AX` | `BHP.AX` |\n| Toronto | `.TO` | `RY.TO` |\n\n### Special RIC Patterns\n\n| Pattern | Meaning | Example |\n|---------|---------|---------|\n| `0#.INDEX` | Index chain | `0#.SPX` |\n| `=CURR` | FX rate | `=EUR` |\n| `^SYMBOL` | Index | `^SPX` |\n\n## Code Examples\n\n### Basic Symbol Conversion\n\n```python\nimport lseg.data as ld\nfrom lseg.data.content import symbol_conversion\n\nld.open_session()\n\n# Convert RICs to other identifiers\nresult = symbol_conversion.Definition(\n    symbols=['AAPL.O', 'MSFT.O', 'GOOGL.O'],\n    from_symbol_type='RIC',\n    to_symbol_types=['ISIN', 'CUSIP', 'SEDOL']\n).get_data()\n\nprint(result.data.df)\n\nld.close_session()\n```\n\n### ISIN to RIC\n\n```python\nimport lseg.data as ld\nfrom lseg.data.content import symbol_conversion\n\nld.open_session()\n\n# Convert ISINs to RICs\nresult = symbol_conversion.Definition(\n    symbols=[\n        'US0378331005',  # Apple\n        'US5949181045',  # Microsoft\n        'US02079K3059'   # Alphabet\n    ],\n    from_symbol_type='ISIN',\n    to_symbol_types=['RIC', 'Ticker', 'CUSIP']\n).get_data()\n\nprint(result.data.df)\n\nld.close_session()\n```\n\n### CUSIP to Multiple Identifiers\n\n```python\nimport lseg.data as ld\nfrom lseg.data.content import symbol_conversion\n\nld.open_session()\n\n# Convert CUSIPs\nresult = symbol_conversion.Definition(\n    symbols=['037833100', '594918104'],  # Apple, Microsoft\n    from_symbol_type='CUSIP',\n    to_symbol_types=['RIC', 'ISIN', 'SEDOL', 'Ticker']\n).get_data()\n\nprint(result.data.df)\n\nld.close_session()\n```\n\n### Get Identifiers via get_data\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\n# Alternative: get identifiers as fields\ndf = ld.get_data(\n    universe=['AAPL.O', 'MSFT.O', 'GOOGL.O'],\n    fields=[\n        'TR.CompanyName',\n        'TR.ISIN',\n        'TR.CUSIP',\n        'TR.SEDOL',\n        'TR.Ticker',\n        'TR.OrganizationID',\n        'TR.LEI'\n    ]\n)\n\nprint(df)\n\nld.close_session()\n```\n\n### Bulk Conversion for Data Linking\n\n```python\nimport lseg.data as ld\nfrom lseg.data.content import symbol_conversion\nimport pandas as pd\n\nld.open_session()\n\n# Convert large list of ISINs (from another dataset)\nisins = ['US0378331005', 'US5949181045', 'US02079K3059']  # From WRDS, etc.\n\n# Chunk if list is large\ndef chunk_list(lst, n):\n    for i in range(0, len(lst), n):\n        yield lst[i:i + n]\n\nall_results = []\nfor chunk in chunk_list(isins, 100):\n    result = symbol_conversion.Definition(\n        symbols=chunk,\n        from_symbol_type='ISIN',\n        to_symbol_types=['RIC', 'CUSIP']\n    ).get_data()\n    all_results.append(result.data.df)\n\n# Combine results\nmapping = pd.concat(all_results, ignore_index=True)\n\nld.close_session()\nprint(mapping)\n```\n\n### Find Primary RIC for Company\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\n# Get primary RIC (main listing)\ndf = ld.get_data(\n    universe=['AAPL.O', 'VOD.L', 'SAP.DE'],\n    fields=[\n        'TR.CompanyName',\n        'TR.PrimaryRIC',\n        'TR.RIC',\n        'TR.ExchangeCode',\n        'TR.ExchangeName'\n    ]\n)\n\nprint(df)\n\nld.close_session()\n```\n\n### Cross-Listed Securities\n\n```python\nimport lseg.data as ld\nfrom lseg.data.content import symbol_conversion\n\nld.open_session()\n\n# Find all RICs for a company (cross-listings)\n# Start with one RIC, get the OrgId, then search\ndf = ld.get_data(\n    universe='VOD.L',\n    fields=['TR.OrganizationID']\n)\n\norg_id = df['TR.OrganizationID'].iloc[0]\n\n# Search for all instruments with same OrgId\n# (This is a simplified approach)\nresult = symbol_conversion.Definition(\n    symbols=[f'orgid:{org_id}'],\n    from_symbol_type='OrgId',\n    to_symbol_types=['RIC']\n).get_data()\n\nld.close_session()\n```\n\n### Create WRDS Linking Table\n\n```python\nimport lseg.data as ld\nimport pandas as pd\n\nld.open_session()\n\n# Build linking table for WRDS integration\nuniverse = ['AAPL.O', 'MSFT.O', 'GOOGL.O', 'AMZN.O', 'META.O']\n\ndf = ld.get_data(\n    universe=universe,\n    fields=[\n        'TR.RIC',\n        'TR.ISIN',\n        'TR.CUSIP',\n        'TR.SEDOL',\n        'TR.Ticker',\n        'TR.CompanyName'\n    ]\n)\n\n# CUSIP without check digit for CRSP linking\ndf['CUSIP8'] = df['TR.CUSIP'].str[:8]\n\n# Save for WRDS linking\ndf.to_csv('lseg_wrds_link.csv', index=False)\n\nld.close_session()\n```\n\n## Notes and Gotchas\n\n### 1. RIC Format Matters\n\nAlways include the exchange suffix:\n```python\n# Wrong\nld.get_data('AAPL', fields)  # Ambiguous\n\n# Right\nld.get_data('AAPL.O', fields)  # NASDAQ\nld.get_data('AAPL.MX', fields)  # Mexico\n```\n\n### 2. CUSIP Check Digit\n\nLSEG returns 9-character CUSIP (with check digit). WRDS often uses 8-character:\n```python\ncusip_9 = df['TR.CUSIP']  # LSEG format: 037833100\ncusip_8 = cusip_9.str[:8]  # WRDS format: 03783310\n```\n\n### 3. Historical Identifiers\n\nSymbols change over time (mergers, ticker changes):\n```python\n# Get historical symbol chain\ndf = ld.get_data(\n    universe='META.O',  # Was FB.O before 2022\n    fields=['TR.RIC', 'TR.PreviousRIC']\n)\n```\n\n### 4. Multiple Matches\n\nA single ISIN may have multiple RICs (different exchanges):\n```python\n# ISIN maps to multiple RICs\nresult = symbol_conversion.Definition(\n    symbols=['GB00BH4HKS39'],  # Vodafone\n    from_symbol_type='ISIN',\n    to_symbol_types=['RIC']\n).get_data()\n# May return: VOD.L, VOD.N (ADR), etc.\n```\n\n### 5. Invalid Identifiers\n\nHandle cases where conversion fails:\n```python\ntry:\n    result = symbol_conversion.Definition(\n        symbols=['INVALID123'],\n        from_symbol_type='ISIN',\n        to_symbol_types=['RIC']\n    ).get_data()\nexcept Exception as e:\n    print(f\"Conversion failed: {e}\")\n```\n\n### 6. Case Sensitivity\n\nIdentifiers are generally case-insensitive:\n```python\n# These are equivalent\n'AAPL.O' == 'aapl.o'  # True for lookup purposes\n'US0378331005' == 'us0378331005'  # True\n```\n\n### 7. OrgId vs PermId\n\n| ID Type | Scope | Use Case |\n|---------|-------|----------|\n| OrgId | Organization level | Link all securities of same company |\n| PermId | Instrument level | Identify specific security |\n| QuoteId | Quote level | Identify specific quote |\n\n## See Also\n\n- [SKILL.md](../SKILL.md) - Core API patterns\n- [TROUBLESHOOTING.md](../TROUBLESHOOTING.md) - Symbol conversion issues\n- [WRDS_COMPARISON.md](../WRDS_COMPARISON.md) - PERMNO/GVKEY mapping\n- [fundamentals.md](fundamentals.md) - Using symbols for data retrieval\n",
        "skills/lseg-data/references/syndicated-loans.md": "# Syndicated Loans Data (SDC Platinum)\n\nAccess syndicated loan deal data via the LSEG Data Library using `TR.LN*` fields.\n\n## Overview\n\nSyndicated loans data comes from SDC Platinum (now integrated into LSEG). Like corporate governance data, loan queries return **multiple rows per company** (one per loan facility/tranche).\n\n## Quick Start\n\n```python\nimport lseg.data as ld\n\nld.open_session()\n\ndf = ld.get_data(\n    universe=[‘F.N’, ‘GM.N’, ‘T.N’, ‘BA.N’],\n    fields=[\n        ‘TR.LNAnnouncementDate’,\n        ‘TR.LNIssuerShortName’,\n        ‘TR.LNTotalFacilityAmount’,\n        ‘TR.LNTrancheAmount’,\n        ‘TR.LNTrancheType’,\n        ‘TR.LNPricingRange’,\n        ‘TR.LNStatusOfLoan’,\n    ]\n)\n# Returns multiple rows per company (one per loan facility)\n\nld.close_session()\n```\n\n## Available Fields\n\n| Field | Description |\n|-------|-------------|\n| **Loan Identification** | |\n| `TR.LNDealId` | SDC deal identifier |\n| `TR.LNSdcDealNum` | SDC deal number |\n| `TR.LNDocumentControlNumber` | Document control number |\n| **Dates** | |\n| `TR.LNAnnouncementDate` | Loan announcement date |\n| **Borrower Information** | |\n| `TR.LNIssuerShortName` | Borrower/issuer name |\n| `TR.LNIssuerSDCCusip` | Borrower CUSIP |\n| **Loan Structure** | |\n| `TR.LNTotalFacilityAmount` | Total facility/package amount |\n| `TR.LNTrancheAmount` | Individual tranche amount |\n| `TR.LNTrancheType` | Tranche type (Term Loan A/B, Revolver, etc.) |\n| `TR.LNNumberOfTranchesInFacility` | Number of tranches |\n| `TR.LNMaturityDesc` | Maturity description |\n| **Pricing** | |\n| `TR.LNPricingRange` | Pricing spread (e.g., “Term SOFR +150.000 bps”) |\n| `TR.LNAllFeesStatedInRange` | All-in fees |\n| **Status & Market** | |\n| `TR.LNStatusOfLoan` | Status (Closed, In Process, Awaiting Mandate) |\n| `TR.LNTargetMarket` | Target market |\n| **Participants** | |\n| `TR.LNLeadManagerCode` | Lead arranger/manager code |\n| **Ratings** | |\n| `TR.LNMoodysLongTermCorpDebtFacilityRating` | Moody’s facility rating |\n| `TR.LNSAndPLongTermCorpDebtFacilityRating` | S&P facility rating |\n\n## Common Loan Types\n\n| Type | Description |\n|------|-------------|\n| Term Loan A | Amortizing term loan, typically held by banks |\n| Term Loan B | Institutional term loan, bullet repayment |\n| Revolving Credit Facility | Drawable/repayable credit line |\n| 364 Day Revolver | Short-term revolving facility |\n| Delayed Draw Term Loan | Commitment to fund term loan later |\n\n## Example Output\n\n| Instrument | Announcement Date | Borrower | Package Amount | Tranche | Type | Pricing |\n|------------|-------------------|----------|----------------|---------|------|---------|\n| F.N | 2025-04-17 | Ford Motor Co | $18B | $10.1B | Revolving Credit | SOFR +150bp |\n| F.N | 2025-04-17 | Ford Motor Co | $18B | $2B | 364 Day Revolver | SOFR +150bp |\n| GM.N | 2025-03-16 | General Motors Co | $14.1B | $10B | Revolving Credit | SOFR +125bp |\n| GM.N | 2025-03-16 | General Motors Co | $14.1B | $4.1B | Revolving Credit | SOFR +125bp |\n\n## Practical Workflow\n\n### Get Loans for a Universe\n\n```python\nimport lseg.data as ld\nimport pandas as pd\n\nld.open_session()\n\n# Get S&P 500 constituents\nsp500 = ld.get_data(universe=‘0#.SPX’, fields=[‘TR.CommonName’])\nrics = sp500[‘Instrument’].tolist()\n\n# Query loans in batches\nbatch_size = 100\nall_loans = []\n\nfor i in range(0, len(rics), batch_size):\n    batch = rics[i:i+batch_size]\n    df = ld.get_data(\n        universe=batch,\n        fields=[\n            ‘TR.LNAnnouncementDate’,\n            ‘TR.LNIssuerShortName’,\n            ‘TR.LNTotalFacilityAmount’,\n            ‘TR.LNTrancheType’,\n            ‘TR.LNPricingRange’,\n        ]\n    )\n    # Filter to rows with actual data\n    df = df.dropna(subset=[‘Loan Dates: Announcement Date’])\n    all_loans.append(df)\n\nloans_df = pd.concat(all_loans, ignore_index=True)\n\nld.close_session()\n```\n\n### Filter by Date\n\n```python\n# Filter to recent loans (2024-2025)\nloans_df[‘Loan Dates: Announcement Date’] = pd.to_datetime(\n    loans_df[‘Loan Dates: Announcement Date’]\n)\nrecent_loans = loans_df[\n    loans_df[‘Loan Dates: Announcement Date’] >= ‘2024-01-01’\n]\n```\n\n## Data Characteristics\n\n- **Multiple rows per company**: Each loan facility and tranche gets its own row\n- **Historical depth**: Data goes back to late 1990s\n- **Currency**: Amounts typically in USD (controlled by CURN parameter in Workspace)\n- **Status tracking**: Shows loan lifecycle from “Awaiting Mandate” to “Closed”\n- **Pricing evolution**: Historical loans show LIBOR spreads, recent loans show SOFR\n\n## Limitations\n\n1. **Must query by ticker**: Like corporate governance, you need a list of target companies first\n2. **No direct SCREEN**: The `SCREEN(U(IN(DEALS)))` syntax only works in Workspace, not via Python API\n3. **Rate limits**: Batch queries to avoid hitting API limits\n\n## Related SDC Datasets\n\n- **Corporate Governance**: `TR.SACT*` (activism), `TR.PP*` (poison pills) - see `corporate-governance.md`\n- **M&A Deals**: `TR.MnA*` fields (not yet tested)\n- **IPOs/New Issues**: `TR.NI*` fields (not yet tested)\n",
        "skills/lseg-data/references/troubleshooting.md": "# LSEG Data Library Troubleshooting\n\nCommon issues and solutions when working with the LSEG Data Library.\n\n## Contents\n\n- [Authentication Issues](#authentication-issues)\n- [Missing/Empty Data](#missingempty-data)\n- [Rate Limiting](#rate-limiting)\n- [Symbol Conversion Issues](#symbol-conversion-issues)\n- [Performance Issues](#performance-issues)\n- [Common Code Errors](#common-code-errors)\n- [Debugging Strategies](#debugging-strategies)\n- [Getting Help](#getting-help)\n- [See Also](#see-also)\n\n## Authentication Issues\n\n### \"Session not opened\" Error\n\n**Symptom:**\n```\nLDError: Session is not opened. Please open a session before making requests.\n```\n\n**Solution:**\n```python\nimport lseg.data as ld\n\n# Always open session before any data calls\nld.open_session()\n\n# Now make your requests\ndf = ld.get_data(...)\n```\n\n### \"Invalid credentials\" Error\n\n**Symptom:**\n```\nLDError: Authentication failed - invalid credentials\n```\n\n**Causes & Solutions:**\n\n1. **Wrong credential type**: Machine IDs look like `GE-A-XXXXXXXX-X-XXXX`\n   ```python\n   # Check you're using machine ID, not email\n   # Wrong: username = \"user@company.com\"\n   # Right: username = \"GE-A-01234567-8-9012\"\n   ```\n\n2. **App key not set**:\n   ```python\n   # Check environment variable\n   import os\n   print(os.environ.get('RDP_APP_KEY'))  # Should not be None\n   ```\n\n3. **Password expired**: Regenerate in LSEG Developer Portal\n\n### Desktop Session Not Found\n\n**Symptom:**\n```\nLDError: Cannot connect to desktop session\n```\n\n**Solutions:**\n\n1. Ensure Eikon or Workspace is running\n2. Check Eikon/Workspace is logged in\n3. Try explicit platform session instead:\n   ```python\n   import lseg.data as ld\n\n   ld.open_session(\n       config_name=\"platform.ldp\"  # Use platform instead of desktop\n   )\n   ```\n\n## Missing/Empty Data\n\n### Empty DataFrame Returned\n\n**Symptom:**\n```python\ndf = ld.get_data('AAPL.O', ['TR.Revenue'])\nprint(df)  # Empty or all NaN\n```\n\n**Causes & Solutions:**\n\n1. **Wrong instrument code (RIC)**:\n   ```python\n   # Verify RIC is valid\n   from lseg.data.content import symbol_conversion\n\n   # Check if ISIN maps to expected RIC\n   result = symbol_conversion.Definition(\n       symbols=['US0378331005'],  # Apple ISIN\n       from_symbol_type='ISIN',\n       to_symbol_types=['RIC']\n   ).get_data()\n   ```\n\n2. **Missing date parameters for historical data**:\n   ```python\n   # Wrong - no dates for periodic data\n   df = ld.get_data('AAPL.O', ['TR.RevenueActValue'])\n\n   # Right - specify period\n   df = ld.get_data(\n       'AAPL.O',\n       ['TR.RevenueActValue'],\n       parameters={'Period': 'FY0'}  # Current fiscal year\n   )\n   ```\n\n3. **Field not available for instrument**:\n   ```python\n   # Not all fields work for all instruments\n   # Check field availability in Data Item Browser\n   ```\n\n### Partial Data (Some Fields Missing)\n\n**Symptom:**\n```python\ndf = ld.get_data('XYZ.O', ['TR.Revenue', 'TR.ESGScore'])\n# Revenue has data, ESG is NaN\n```\n\n**Causes:**\n\n1. **No ESG coverage** for that company - check coverage in Eikon\n2. **Different data sources** - some fields require separate permissions\n3. **Timing issues** - ESG updated less frequently than financials\n\n### Historical Data Gaps\n\n**Symptom:**\n```python\ndf = ld.get_history('AAPL.O', start='2020-01-01', end='2020-12-31')\n# Missing weekends/holidays (expected) or missing trading days (problem)\n```\n\n**Solutions:**\n\n1. **Check for corporate actions** (splits, ticker changes)\n2. **Use adjusted prices** for historical analysis:\n   ```python\n   df = ld.get_history(\n       'AAPL.O',\n       fields=['CLOSE'],  # Adjusted by default\n       adjustments=['split', 'dividend']\n   )\n   ```\n\n## Rate Limiting\n\n### Rate Limit Exceeded\n\n**Symptom:**\n```\nLDError: Rate limit exceeded. Please try again later.\n```\n\n**Solutions:**\n\n1. **Implement exponential backoff**:\n   ```python\n   import time\n   from lseg.data.errors import LDError\n\n   def get_data_with_retry(universe, fields, max_retries=3):\n       for attempt in range(max_retries):\n           try:\n               return ld.get_data(universe, fields)\n           except LDError as e:\n               if 'rate limit' in str(e).lower():\n                   wait_time = 2 ** attempt * 30  # 30s, 60s, 120s\n                   print(f\"Rate limited. Waiting {wait_time}s...\")\n                   time.sleep(wait_time)\n               else:\n                   raise\n       raise Exception(\"Max retries exceeded\")\n   ```\n\n2. **Batch your requests**:\n   ```python\n   # Instead of one request per symbol\n   for sym in large_universe:\n       ld.get_data(sym, fields)  # Bad - many requests\n\n   # Batch into chunks\n   def chunked(lst, n):\n       for i in range(0, len(lst), n):\n           yield lst[i:i + n]\n\n   for chunk in chunked(large_universe, 100):\n       ld.get_data(chunk, fields)  # Better - fewer requests\n   ```\n\n3. **Add delays between requests**:\n   ```python\n   import time\n\n   for chunk in data_chunks:\n       result = ld.get_data(chunk, fields)\n       time.sleep(1)  # Wait 1 second between requests\n   ```\n\n## Symbol Conversion Issues\n\n### Symbol Not Found\n\n**Symptom:**\n```\nLDError: Symbol 'AAPL' not found\n```\n\n**Solution:** Use proper RIC format:\n```python\n# Wrong - ticker only\nld.get_data('AAPL', fields)\n\n# Right - full RIC\nld.get_data('AAPL.O', fields)  # .O = NASDAQ\nld.get_data('IBM.N', fields)   # .N = NYSE\n```\n\n### RIC Exchange Suffixes\n\n| Exchange | Suffix | Example |\n|----------|--------|---------|\n| NASDAQ | `.O` | `AAPL.O` |\n| NYSE | `.N` | `IBM.N` |\n| London | `.L` | `VOD.L` |\n| Tokyo | `.T` | `7203.T` |\n| Hong Kong | `.HK` | `0700.HK` |\n| Frankfurt | `.DE` | `BMW.DE` |\n\n### Converting Between Identifiers\n\n```python\nfrom lseg.data.content import symbol_conversion\n\n# ISIN to RIC\nresult = symbol_conversion.Definition(\n    symbols=['US0378331005'],\n    from_symbol_type='ISIN',\n    to_symbol_types=['RIC']\n).get_data()\n\n# CUSIP to RIC\nresult = symbol_conversion.Definition(\n    symbols=['037833100'],\n    from_symbol_type='CUSIP',\n    to_symbol_types=['RIC']\n).get_data()\n```\n\n## Performance Issues\n\n### Slow Queries\n\n**Causes & Solutions:**\n\n1. **Too many fields**:\n   ```python\n   # Slow - requesting many fields\n   fields = [f'TR.Field{i}' for i in range(100)]\n\n   # Better - only request needed fields\n   fields = ['TR.Revenue', 'TR.NetIncome', 'TR.EPS']\n   ```\n\n2. **Large date ranges**:\n   ```python\n   # Slow - 20 years of daily data\n   df = ld.get_history('AAPL.O', start='2004-01-01')\n\n   # Better - chunk into years\n   for year in range(2004, 2024):\n       df = ld.get_history(\n           'AAPL.O',\n           start=f'{year}-01-01',\n           end=f'{year}-12-31'\n       )\n   ```\n\n3. **Real-time data overhead**:\n   ```python\n   # Use get_data for snapshots, not streaming\n   # Streaming uses more resources\n   ```\n\n### Memory Issues\n\n**Symptom:** Python crashes or runs out of memory\n\n**Solutions:**\n\n1. **Process in chunks**:\n   ```python\n   import pandas as pd\n\n   all_data = []\n   for chunk in chunked(large_universe, 50):\n       df = ld.get_data(chunk, fields)\n       all_data.append(df)\n       del df  # Free memory\n\n   result = pd.concat(all_data)\n   ```\n\n2. **Use appropriate data types**:\n   ```python\n   df = ld.get_data(universe, fields)\n   df = df.astype({\n       'price': 'float32',  # Instead of float64\n       'volume': 'int32'    # Instead of int64\n   })\n   ```\n\n## Common Code Errors\n\n### TypeError: Cannot Convert to DataFrame\n\n**Symptom:**\n```\nTypeError: 'Response' object is not subscriptable\n```\n\n**Cause:** Using `Definition()` without `.get_data()`\n\n```python\n# Wrong\nresult = fundamental_and_reference.Definition(universe, fields)\ndf = result['Instrument']  # Error!\n\n# Right\nresponse = fundamental_and_reference.Definition(universe, fields).get_data()\ndf = response.data.df  # Access DataFrame\n```\n\n### AttributeError: Module Has No Attribute\n\n**Symptom:**\n```\nAttributeError: module 'lseg.data' has no attribute 'get_fundamentals'\n```\n\n**Cause:** Wrong function name or import\n\n```python\n# Check available functions\nimport lseg.data as ld\ndir(ld)  # See available methods\n\n# Common functions:\n# ld.get_data()\n# ld.get_history()\n# ld.open_session()\n# ld.close_session()\n```\n\n### Index Error with MultiIndex\n\n**Symptom:**\n```python\ndf.loc['AAPL.O']  # KeyError\n```\n\n**Cause:** DataFrame has MultiIndex\n\n```python\n# Reset index for easier access\ndf = df.reset_index()\n\n# Or access properly\ndf.loc[df['Instrument'] == 'AAPL.O']\n```\n\n## Debugging Strategies\n\n### Enable Debug Logging\n\n```python\nimport logging\n\n# Enable debug output\nlogging.basicConfig(level=logging.DEBUG)\n\n# Or for specific modules\nlogging.getLogger('lseg.data').setLevel(logging.DEBUG)\n```\n\n### Inspect API Response\n\n```python\n# Get raw response for debugging\nfrom lseg.data.content import fundamental_and_reference\n\nresponse = fundamental_and_reference.Definition(\n    universe=['AAPL.O'],\n    fields=['TR.Revenue']\n).get_data()\n\n# Inspect response\nprint(response.raw)        # Raw JSON response\nprint(response.data.df)    # Parsed DataFrame\nprint(response.errors)     # Any errors\n```\n\n### Validate Field Names\n\n```python\n# Test if field exists\ntry:\n    df = ld.get_data('AAPL.O', ['TR.TestField'])\n    print(\"Field exists\" if not df.empty else \"No data for field\")\nexcept Exception as e:\n    print(f\"Field error: {e}\")\n```\n\n### Check Session Status\n\n```python\nimport lseg.data as ld\n\n# Check if session is open\nprint(ld.get_config())  # Shows current configuration\nprint(ld.session)       # Current session object\n```\n\n## Getting Help\n\n1. **LSEG Developer Community**: https://community.developers.refinitiv.com/\n2. **Data Item Browser**: Search for fields and their parameters\n3. **API Documentation**: https://developers.lseg.com/\n4. **Support Ticket**: Via LSEG Developer Portal\n\n## See Also\n\n- [SKILL.md](SKILL.md) - Main documentation\n- [modules/symbology.md](modules/symbology.md) - Symbol conversion details\n- [WRDS_COMPARISON.md](WRDS_COMPARISON.md) - WRDS field mapping\n",
        "skills/lseg-data/references/wrds-comparison.md": "# LSEG Data vs WRDS Comparison\n\nA guide for researchers familiar with WRDS who need to work with LSEG data, and vice versa.\n\n## Contents\n\n- [Overview](#overview)\n- [Identifier Mapping](#identifier-mapping)\n- [Data Coverage Comparison](#data-coverage-comparison)\n- [Code Examples: Same Task, Both Platforms](#code-examples-same-task-both-platforms)\n- [Key Differences to Note](#key-differences-to-note)\n- [Strengths by Platform](#strengths-by-platform)\n- [Migration Tips](#migration-tips)\n- [See Also](#see-also)\n\n## Overview\n\n| Aspect | WRDS | LSEG Data Library |\n|--------|------|-------------------|\n| **Access** | SQL queries via `wrds` package | Python API via `lseg.data` |\n| **Data model** | Relational tables | Instruments + fields |\n| **Identifiers** | PERMNO, GVKEY, CUSIP | RIC, ISIN, SEDOL |\n| **Coverage focus** | US-centric, academic | Global, real-time capable |\n| **Update frequency** | Batch (daily/monthly) | Real-time to daily |\n\n## Identifier Mapping\n\n### Primary Identifiers\n\n| WRDS | LSEG | Notes |\n|------|------|-------|\n| PERMNO | RIC | CRSP permanent number vs Reuters Instrument Code |\n| GVKEY | OrgId | Compustat company key vs LSEG Organization ID |\n| CUSIP | CUSIP | Same standard, can convert directly |\n| TICKER | Ticker | Exchange-specific |\n\n### Converting Between Systems\n\n```python\n# LSEG: Convert CUSIP to RIC\nfrom lseg.data.content import symbol_conversion\n\nresult = symbol_conversion.Definition(\n    symbols=[‘037833100’],  # Apple CUSIP\n    from_symbol_type=’CUSIP’,\n    to_symbol_types=[‘RIC’, ‘ISIN’]\n).get_data()\n```\n\n```python\n# WRDS: Get CUSIP from PERMNO\nimport wrds\n\ndb = wrds.Connection()\nquery = “””\n    SELECT permno, cusip, ncusip\n    FROM crsp.msenames\n    WHERE permno = 14593\n“””\ndf = db.raw_sql(query)\n```\n\n## Data Coverage Comparison\n\n### Company Fundamentals\n\n| Data Item | WRDS (Compustat) | LSEG |\n|-----------|------------------|------|\n| Revenue | `revt` (funda) | `TR.RevenueActValue` |\n| Net Income | `ni` (funda) | `TR.NetIncomeActValue` |\n| Total Assets | `at` (funda) | `TR.TotalAssetsReported` |\n| EPS | `epspx` (funda) | `TR.EPSActValue` |\n| Book Value | `ceq` (funda) | `TR.TotalEquity` |\n\n### Pricing Data\n\n| Data Item | WRDS (CRSP) | LSEG |\n|-----------|-------------|------|\n| Close Price | `prc` (dsf) | `TR.PriceClose` / `CLOSE` |\n| Return | `ret` (dsf) | Calculate from prices |\n| Volume | `vol` (dsf) | `TR.Volume` / `VOLUME` |\n| Bid/Ask | `bid`, `ask` (dsf) | `BID`, `ASK` |\n| Market Cap | `prc * shrout` | `TR.CompanyMarketCap` |\n\n### ESG Data\n\n| Data Item | WRDS | LSEG |\n|-----------|------|------|\n| ESG Score | MSCI ESG / Sustainalytics | `TR.TRESGScore` |\n| Environmental | Varies by provider | `TR.EnvironmentPillarScore` |\n| Social | Varies by provider | `TR.SocialPillarScore` |\n| Governance | Varies by provider | `TR.GovernancePillarScore` |\n\n## Code Examples: Same Task, Both Platforms\n\n### Get Annual Revenue for Tech Companies\n\n**WRDS (Compustat):**\n```python\nimport wrds\n\ndb = wrds.Connection()\n\nquery = “””\n    SELECT gvkey, datadate, fyear, tic, revt, ni\n    FROM comp.funda\n    WHERE tic IN (‘AAPL’, ‘MSFT’, ‘GOOGL’)\n      AND fyear >= 2020\n      AND indfmt = ‘INDL’\n      AND datafmt = ‘STD’\n      AND popsrc = ‘D’\n      AND consol = ‘C’\n    ORDER BY tic, fyear\n“””\ndf = db.raw_sql(query)\n```\n\n**LSEG:**\n```python\nimport lseg.data as ld\n\nld.open_session()\n\ndf = ld.get_data(\n    universe=[‘AAPL.O’, ‘MSFT.O’, ‘GOOGL.O’],\n    fields=[‘TR.RevenueActValue’, ‘TR.NetIncomeActValue’],\n    parameters={\n        ‘SDate’: ‘2020-01-01’,\n        ‘EDate’: ‘2024-12-31’,\n        ‘Period’: ‘FY’\n    }\n)\n\nld.close_session()\n```\n\n### Get Daily Stock Prices\n\n**WRDS (CRSP):**\n```python\nimport wrds\n\ndb = wrds.Connection()\n\nquery = “””\n    SELECT a.permno, a.date, a.prc, a.ret, a.vol\n    FROM crsp.dsf a\n    JOIN crsp.msenames b ON a.permno = b.permno\n    WHERE b.ticker = ‘AAPL’\n      AND a.date BETWEEN ‘2023-01-01’ AND ‘2023-12-31’\n    ORDER BY date\n“””\ndf = db.raw_sql(query)\n```\n\n**LSEG:**\n```python\nimport lseg.data as ld\n\nld.open_session()\n\ndf = ld.get_history(\n    universe=’AAPL.O’,\n    fields=[‘OPEN’, ‘HIGH’, ‘LOW’, ‘CLOSE’, ‘VOLUME’],\n    start=‘2023-01-01’,\n    end=‘2023-12-31’\n)\n\nld.close_session()\n```\n\n### Get ESG Scores\n\n**WRDS (MSCI ESG via KLD):**\n```python\nimport wrds\n\ndb = wrds.Connection()\n\nquery = “””\n    SELECT ticker, year, cgov_str_num, cgov_con_num,\n           com_str_num, com_con_num, env_str_num, env_con_num\n    FROM kld.history\n    WHERE ticker IN (‘AAPL’, ‘MSFT’, ‘XOM’)\n      AND year >= 2020\n“””\ndf = db.raw_sql(query)\n```\n\n**LSEG:**\n```python\nimport lseg.data as ld\n\nld.open_session()\n\ndf = ld.get_data(\n    universe=[‘AAPL.O’, ‘MSFT.O’, ‘XOM’],\n    fields=[\n        ‘TR.TRESGScore’,\n        ‘TR.EnvironmentPillarScore’,\n        ‘TR.SocialPillarScore’,\n        ‘TR.GovernancePillarScore’\n    ]\n)\n\nld.close_session()\n```\n\n## Key Differences to Note\n\n### 1. Date Handling\n\n**WRDS:** Fiscal year end dates, period end dates in tables\n```python\n# fyear = fiscal year\n# datadate = fiscal period end date\n```\n\n**LSEG:** Use parameters to specify periods\n```python\n# ‘Period’: ‘FY’ for fiscal year\n# ‘Period’: ‘FQ0’ for current fiscal quarter\n# ‘SDate’, ‘EDate’ for date ranges\n```\n\n### 2. Adjusted vs Unadjusted Prices\n\n**WRDS (CRSP):** Separate fields\n```python\n# prc = price (may be negative if bid/ask average)\n# ret = return (split-adjusted)\n# cfacpr = cumulative adjustment factor\n```\n\n**LSEG:** Adjustments as parameters\n```python\ndf = ld.get_history(\n    ‘AAPL.O’,\n    adjustments=[‘split’, ‘dividend’]  # Specify adjustments\n)\n```\n\n### 3. Missing Data\n\n**WRDS:** NULL values in SQL\n```sql\nWHERE revt IS NOT NULL\n```\n\n**LSEG:** NaN in DataFrame\n```python\ndf = df.dropna(subset=[‘TR.RevenueActValue’])\n```\n\n### 4. Universe Construction\n\n**WRDS:** Query tables to build universe\n```python\n# Get S&P 500 constituents\nquery = “””\n    SELECT gvkey, iid, from, thru\n    FROM comp.idxcst_his\n    WHERE gvkeyx = ‘000003’  -- S&P 500\n“””\n```\n\n**LSEG:** Use chain RICs or indices\n```python\n# Get S&P 500 constituents\ndf = ld.get_data(\n    universe=‘0#.SPX’,  # Chain RIC for S&P 500\n    fields=[‘TR.CompanyName’, ‘TR.PriceClose’]\n)\n```\n\n## Mutual Fund Data\n\n**Recommendation:** Use LSEG Lipper for **fund characteristics only**. Use WRDS for holdings and NAV/performance.\n\n### Data Source by Type\n\n| Data Type | Recommended Source | Rationale |\n|-----------|-------------------|-----------|\n| **Fund Characteristics** | LSEG Lipper | Classifications, benchmarks, expense ratios, fund structure |\n| **Holdings** | WRDS Thomson S12 | SEC filing-based (13F, N-CSR), standardized, academic standard |\n| **NAV & Returns** | WRDS CRSP | Primary academic source; Lipper is an underlying source for CRSP |\n| **Performance Analysis** | WRDS CRSP + MFLINKS | Links CRSP returns to S12 holdings |\n\n### Why Not Use Lipper for Holdings/NAV?\n\n1. **Holdings**: Lipper holdings are fund company-reported. S12 uses standardized SEC filings (13F, N-CSR).\n2. **NAV/Returns**: CRSP is the academic standard and actually uses Lipper as an underlying source. Use CRSP for consistency with published research.\n3. **Reproducibility**: WRDS provides stable, versioned datasets. Lipper data in Workspace can change.\n\n### WRDS Tables for Mutual Funds\n\n```sql\n-- NAV and Returns\nSELECT * FROM crsp.fund_summary2 WHERE crsp_fundno = ...;\nSELECT * FROM crsp.monthly_nav WHERE crsp_fundno = ...;\n\n-- Holdings (Thomson S12)\nSELECT * FROM tfn.s12 WHERE fdate = ...;\n\n-- Link CRSP to Thomson holdings\nSELECT * FROM mfl.mflink1 WHERE crsp_fundno = ...;\n```\n\n### LSEG for Fund Characteristics\n\n```python\nimport refinitiv.data as rd\n\nrd.open_session()\ndf = rd.get_data(\n    universe=[‘QQQ.O’],\n    fields=[\n        ‘TR.FundLegalStructure’,    # Legal structure\n        ‘TR.FundBenchmarkName’,      # Benchmark\n        ‘TR.FundBenchmarkInstrumentRIC’,\n        ‘TR.FundTER’,               # Total expense ratio\n        ‘TR.FundObjective’,         # Investment objective\n    ]\n)\nrd.close_session()\n```\n\n**Note:** Use `refinitiv.data` (not `lseg.data`) for fund fields. See [fund-details.md](fund-details.md) for details.\n\n## Strengths by Platform\n\n### When to Use WRDS\n\n- **Historical academic research**: Longer history, cleaner backfilled data\n- **US-focused analysis**: CRSP/Compustat gold standard for US\n- **Linking databases**: PERMNO-GVKEY links well established\n- **Reproducibility**: Static datasets, consistent across researchers\n- **Complex SQL**: Join multiple tables, complex filters\n- **Mutual fund holdings**: Thomson S12 for SEC filing-based holdings\n- **Mutual fund returns**: CRSP Mutual Fund Database for NAV/performance\n\n### When to Use LSEG\n\n- **Global coverage**: Better international data\n- **Real-time needs**: Streaming quotes, intraday data\n- **ESG data**: Comprehensive ESG coverage and history\n- **Quick lookups**: API faster than SQL for simple queries\n- **News and sentiment**: Rich unstructured data\n- **Fund characteristics**: Lipper classifications, benchmarks, expense ratios\n\n## Migration Tips\n\n### From WRDS to LSEG\n\n1. **Map identifiers first**: Convert PERMNO/GVKEY to RIC\n2. **Validate data**: Compare values for overlapping periods\n3. **Check field definitions**: Same name may mean different things\n4. **Handle periodicity**: LSEG fiscal periods may differ\n\n### From LSEG to WRDS\n\n1. **Get CUSIP from LSEG**: Use symbology conversion\n2. **Link to PERMNO**: Use CRSP msenames table\n3. **Verify coverage**: Not all LSEG instruments in WRDS\n4. **Adjust for timing**: WRDS may have lag in updates\n\n## See Also\n\n- [SKILL.md](SKILL.md) - LSEG main documentation\n- [modules/symbology.md](modules/symbology.md) - Identifier conversion\n- [../wrds/SKILL.md](../wrds/SKILL.md) - WRDS skill documentation\n",
        "skills/marimo/SKILL.md": "---\nname: marimo\ndescription: This skill should be used when the user asks to \"use marimo\", \"create a marimo notebook\", \"debug a marimo notebook\", \"inspect cells\", \"understand reactive execution\", \"fix marimo errors\", \"convert from jupyter to marimo\", or works with marimo reactive Python notebooks.\n---\n\n## Contents\n\n- [Editing and Verification Enforcement](#editing-and-verification-enforcement)\n- [Key Concepts](#key-concepts)\n- [Cell Structure](#cell-structure)\n- [Editing Rules](#editing-rules)\n- [Core CLI Commands](#core-cli-commands)\n- [Export Commands](#export-commands)\n- [Data and Visualization](#data-and-visualization)\n- [Debugging Workflow](#debugging-workflow)\n- [Common Issues](#common-issues)\n- [Additional Resources](#additional-resources)\n\n# Marimo Reactive Notebooks\n\nMarimo is a reactive Python notebook where cells form a DAG and auto-execute on dependency changes. Notebooks are stored as pure `.py` files.\n\n## Editing and Verification Enforcement\n\n### IRON LAW #1: NEVER MODIFY CELL DECORATORS OR SIGNATURES\n\nOnly edit code INSIDE `@app.cell` function bodies. This is not negotiable.\n\n**NEVER modify:**\n- Cell decorators (`@app.cell`)\n- Function signatures (`def _(deps):`)\n- Return statements structure (trailing commas required)\n\n**ALWAYS verify:**\n- All used variables are in function parameters\n- All created variables are in return statement\n- Trailing comma for single returns: `return var,`\n\n### IRON LAW #2: NO EXECUTION CLAIM WITHOUT OUTPUT VERIFICATION\n\nBefore claiming ANY marimo notebook works:\n1. **VALIDATE** syntax and structure: `marimo check notebook.py`\n2. **EXECUTE** with outputs: `marimo export ipynb notebook.py -o __marimo__/notebook.ipynb --include-outputs`\n3. **VERIFY** using notebook-debug skill's verification checklist\n4. **CLAIM** success only after verification passes\n\nThis is not negotiable. Claiming \"notebook works\" without executing and inspecting outputs is LYING to the user.\n\n### Rationalization Table - STOP If You Think:\n\n| Excuse | Reality | Do Instead |\n|--------|---------|------------|\n| \"marimo check passed, so it works\" | Syntax check ≠ runtime correctness | EXECUTE with --include-outputs and inspect |\n| \"Just a small change, can't break anything\" | Reactivity means small changes propagate everywhere | VERIFY with full execution |\n| \"I'll let marimo handle the dependency tracking\" | Verification of correct behavior is still required | CHECK outputs match expectations |\n| \"The function signature looks right\" | Wrong deps/returns break reactivity silently | VALIDATE all vars are in params AND returns |\n| \"I can modify the function signature\" | Breaks marimo's dependency detection | ONLY edit inside function bodies |\n| \"Variables can be used without returning them\" | Will cause NameError in dependent cells | RETURN all created variables |\n| \"I can skip the trailing comma for single returns\" | Python treats `return var` as returning the value, breaks unpacking | USE `return var,` for single returns |\n\n### Red Flags - STOP Immediately If You Think:\n\n- \"Let me add this variable to the function signature\" → NO. Marimo manages signatures.\n- \"I'll just run marimo check and call it done\" → NO. Execute with outputs required.\n- \"The code looks correct\" → NO. Marimo's reactivity must be verified at runtime.\n- \"I can redefine this variable in another cell\" → NO. One variable = one cell.\n\n### Editing Checklist\n\nBefore every marimo edit:\n\n**Structure Validation:**\n- [ ] Only edit code INSIDE `@app.cell` function bodies\n- [ ] Do NOT modify decorators or signatures\n- [ ] Verify all used variables are in function parameters\n- [ ] Verify all created variables are in return statement\n- [ ] Ensure trailing comma used for single returns\n- [ ] Ensure no variable redefinitions across cells\n\n**Syntax Validation:**\n- [ ] Execute `marimo check notebook.py`\n- [ ] Verify no syntax errors reported\n- [ ] Verify no undefined variable warnings\n- [ ] Verify no redefinition warnings\n\n**Runtime Verification:**\n- [ ] Execute with `marimo export ipynb notebook.py -o __marimo__/notebook.ipynb --include-outputs`\n- [ ] Verify export succeeded (exit code 0)\n- [ ] Verify output ipynb exists and is non-empty\n- [ ] Apply notebook-debug verification checklist\n- [ ] Verify no tracebacks in any cell\n- [ ] Verify all cells executed (execution_count not null)\n- [ ] Verify outputs match expectations\n\n**Only after ALL checks pass:**\n- [ ] Claim \"notebook works\"\n\n### Gate Function: Marimo Verification\n\nFollow this sequence for EVERY marimo task:\n\n```\n1. EDIT     → Modify code inside @app.cell function bodies only\n2. CHECK    → marimo check notebook.py\n3. EXECUTE  → marimo export ipynb notebook.py -o __marimo__/notebook.ipynb --include-outputs\n4. INSPECT  → Use notebook-debug verification\n5. VERIFY   → Outputs match expectations\n6. CLAIM    → \"Notebook works\" only after all gates passed\n```\n\n**NEVER skip verification gates.** Marimo's reactivity means changes propagate unpredictably.\n\n### Honesty Framing\n\n**Claiming a marimo notebook works without executing it with --include-outputs and inspecting the results is LYING.**\n\nSyntax checks and code inspection prove nothing about reactive execution correctness. The user expects a working notebook where all cells execute correctly with proper dependency tracking.\n\n## Key Concepts\n\n- **Reactive execution**: Cells auto-update when dependencies change\n- **No hidden state**: Each variable defined in exactly one cell\n- **Pure Python**: `.py` files, version control friendly\n- **Cell structure**: `@app.cell` decorator pattern\n\n## Cell Structure\n\n```python\nimport marimo\n\napp = marimo.App()\n\n@app.cell\ndef _(pl):  # Dependencies as parameters\n    df = pl.read_csv(\"data.csv\")\n    return df,  # Trailing comma required for single return\n\n@app.cell\ndef _(df, pl):\n    summary = df.describe()\n    filtered = df.filter(pl.col(\"value\") > 0)\n    return summary, filtered  # Multiple returns\n```\n\n## Editing Rules\n\n- Edit code INSIDE `@app.cell` functions only\n- Never modify cell decorators or function signatures\n- Variables cannot be redefined across cells\n- All used variables must be returned from their defining cell\n- **Markdown cells: Always wrap `$` in backticks** - `mo.md(\"Cost: `$50`\")` not `mo.md(\"Cost: $50\")`\n\n## Core CLI Commands\n\n| Command | Purpose |\n|---------|---------|\n| `marimo edit notebook.py` | marimo: Open notebook in browser editor for interactive development |\n| `marimo run notebook.py` | marimo: Run notebook as executable app |\n| `marimo check notebook.py` | marimo: Validate notebook structure and syntax without execution |\n| `marimo convert notebook.ipynb` | marimo: Convert Jupyter notebook to marimo format |\n\n## Export Commands\n\n```bash\n# marimo: Export to ipynb with code only\nmarimo export ipynb notebook.py -o __marimo__/notebook.ipynb\n\n# marimo: Export to ipynb with outputs (runs notebook first)\nmarimo export ipynb notebook.py -o __marimo__/notebook.ipynb --include-outputs\n\n# marimo: Export to HTML (runs notebook by default)\nmarimo export html notebook.py -o __marimo__/notebook.html\n\n# marimo: Export to HTML with auto-refresh on changes (live preview)\nmarimo export html notebook.py -o __marimo__/notebook.html --watch\n```\n\n**Key difference:** HTML export runs the notebook by default. ipynb export does NOT - use `--include-outputs` to run and capture outputs.\n\n**Tip:** Use `__marimo__/` folder for all exports (ipynb, html). The editor can auto-save there.\n\n## Data and Visualization\n\n- Prefer polars over pandas for performance\n- Use `mo.ui` for interactive widgets\n- SQL cells: `mo.sql(df, \"SELECT * FROM df\")`\n- Display markdown: `mo.md(\"# Heading\")`\n\n## Debugging Workflow\n\n**1. Pre-execution validation:**\n```bash\n# scripts: Validate notebook syntax and cell structure\nscripts/check_notebook.sh notebook.py\n```\nRuns syntax check, marimo validation, and cell structure overview in one command.\n\n**2. Runtime errors:** Export with outputs, then use `notebook-debug` skill:\n```bash\n# marimo: Export to ipynb with outputs for inspection\nmarimo export ipynb notebook.py -o __marimo__/notebook.ipynb --include-outputs\n```\n\n## Common Issues\n\n| Issue | Fix |\n|-------|-----|\n| Variable redefinition | Rename one variable or merge cells |\n| Circular dependency | Break cycle by merging or restructuring |\n| Missing return | Add `return var,` with trailing comma |\n| Import not available | Ensure import cell returns the module |\n\n## Additional Resources\n\n### Reference Files\n\nFor detailed patterns and advanced techniques, consult:\n- **`references/reactivity.md`** - DAG execution, variable rules, dependency detection patterns\n- **`references/debugging.md`** - Error patterns, runtime debugging, environment-specific issues\n- **`references/widgets.md`** - Interactive UI components and mo.ui patterns\n- **`references/sql.md`** - SQL cells and database integration techniques\n\n### Examples\n\nWorking examples available in `examples/`:\n- **`examples/basic_notebook.py`** - Minimal marimo notebook structure\n- **`examples/data_analysis.py`** - Data loading, filtering, and visualization patterns\n- **`examples/interactive_widgets.py`** - Interactive UI component usage\n\n### Scripts\n\nValidation utilities in `scripts/`:\n- **`scripts/check_notebook.sh`** - Primary validation: syntax check, marimo validation, cell structure overview\n- **`scripts/get_cell_map.py`** - Extract cell metadata (invoked by check_notebook.sh)\n\n### Related Skills\n\n- **`notebook-debug`** - Debugging executed ipynb files with tracebacks and output inspection\n",
        "skills/marimo/references/debugging.md": "# Marimo Debugging Workflows\n\n## Contents\n\n- [Quick Diagnostics](#quick-diagnostics)\n- [Common Error Patterns](#common-error-patterns)\n- [Runtime Debugging](#runtime-debugging)\n- [Environment Issues](#environment-issues)\n- [Performance Debugging](#performance-debugging)\n- [Notebook Recovery](#notebook-recovery)\n- [Debugging Checklist](#debugging-checklist)\n\n## Quick Diagnostics\n\n### Check for Errors (No Execution)\n```bash\nmarimo check notebook.py\n```\nReports syntax errors, undefined variables, circular dependencies without running cells.\n\n### Inspect Cell Structure\n```python\n# get_cell_map.py - Extract cell info from notebook\nimport ast\nfrom pathlib import Path\n\ndef get_cell_map(notebook_path: str) -> dict:\n    \"\"\"Parse marimo notebook and return cell metadata.\"\"\"\n    source = Path(notebook_path).read_text()\n    tree = ast.parse(source)\n\n    cells = {}\n    for node in ast.walk(tree):\n        if isinstance(node, ast.FunctionDef):\n            # Check for @app.cell decorator\n            for decorator in node.decorator_list:\n                if hasattr(decorator, 'attr') and decorator.attr == 'cell':\n                    cells[node.name] = {\n                        'lineno': node.lineno,\n                        'args': [arg.arg for arg in node.args.args],\n                        'returns': _extract_returns(node),\n                    }\n    return cells\n\ndef _extract_returns(func_node) -> list:\n    \"\"\"Extract return variable names from function.\"\"\"\n    returns = []\n    for node in ast.walk(func_node):\n        if isinstance(node, ast.Return) and node.value:\n            if isinstance(node.value, ast.Tuple):\n                returns = [elt.id for elt in node.value.elts\n                          if isinstance(elt, ast.Name)]\n            elif isinstance(node.value, ast.Name):\n                returns = [node.value.id]\n    return returns\n```\n\n## Common Error Patterns\n\n### Variable Redefinition\n**Error**: `NameError: name 'x' is defined in multiple cells`\n\n**Debug**:\n```bash\ngrep -n \"^    x = \" notebook.py\n```\n\n**Fix**: Rename one variable or merge cells.\n\n### Circular Dependency\n**Error**: `CircularDependencyError`\n\n**Debug**:\n1. Open in marimo editor: `marimo edit notebook.py`\n2. View → Dependency graph\n3. Look for cycles (highlighted in red)\n\n**Fix**: Break cycle by:\n- Merging dependent cells\n- Extracting shared logic to a function\n- Restructuring data flow\n\n### Missing Return\n**Symptom**: Variable undefined in downstream cell\n\n**Debug**:\n```python\n# Check if cell returns the variable\n@app.cell\ndef _():\n    df = load_data()\n    # Missing: return df,\n```\n\n**Fix**: Add return statement with trailing comma.\n\n### Import Not Available\n**Error**: `NameError: name 'pl' is not defined`\n\n**Debug**: Check import cell exists and returns the module:\n```python\n@app.cell\ndef _():\n    import polars as pl\n    return pl,  # Must return!\n```\n\n## Runtime Debugging\n\n### Inspect Cell Output\n```python\n@app.cell\ndef _(df):\n    # Debug: inspect intermediate state\n    print(f\"Shape: {df.shape}\")\n    print(f\"Columns: {df.columns}\")\n    print(f\"Nulls:\\n{df.null_count()}\")\n\n    result = df.filter(...)\n    print(f\"After filter: {result.shape}\")\n    return result,\n```\n\n### Check Data Types\n```python\n@app.cell\ndef _(df):\n    mo.md(f\"\"\"\n    ## Data Inspection\n    - **Shape**: {df.shape}\n    - **Schema**: {df.schema}\n    - **Memory**: {df.estimated_size() / 1e6:.2f} MB\n    \"\"\")\n```\n\n### Trace Execution Order\n```python\n@app.cell\ndef _():\n    import datetime\n    print(f\"[{datetime.datetime.now()}] Cell A executed\")\n    # ... cell code\n```\n\n## Environment Issues\n\n### Check marimo Version\n```bash\nmarimo --version\npip show marimo\n```\n\n### Verify Dependencies\n```bash\n# Check if required packages are installed\npython -c \"import polars; print(polars.__version__)\"\npython -c \"import marimo; print(marimo.__version__)\"\n```\n\n### Virtual Environment\n```bash\n# Ensure correct env is active\nwhich python\npip list | grep marimo\n```\n\n## Performance Debugging\n\n### Profile Cell Execution\n```python\n@app.cell\ndef _(df):\n    import time\n    start = time.perf_counter()\n\n    result = expensive_operation(df)\n\n    elapsed = time.perf_counter() - start\n    print(f\"Execution time: {elapsed:.2f}s\")\n    return result,\n```\n\n### Memory Usage\n```python\n@app.cell\ndef _(df):\n    import sys\n\n    size_mb = sys.getsizeof(df) / 1e6\n    print(f\"DataFrame size: {size_mb:.2f} MB\")\n\n    # For polars\n    if hasattr(df, 'estimated_size'):\n        print(f\"Polars estimate: {df.estimated_size() / 1e6:.2f} MB\")\n```\n\n## Notebook Recovery\n\n### Extract Code from Corrupted Notebook\n```bash\n# Marimo notebooks are valid Python, so:\npython notebook.py  # Should at least parse\n\n# Or extract cell contents:\ngrep -A 20 \"@app.cell\" notebook.py\n```\n\n### Reset Notebook State\n```bash\n# Clear all outputs and restart\nmarimo edit notebook.py --fresh\n```\n\n## Debugging Checklist\n\n1. [ ] Run `marimo check notebook.py` for static errors\n2. [ ] Check variable definitions (single source per variable)\n3. [ ] Verify all cells have proper return statements\n4. [ ] Check for circular dependencies in graph view\n5. [ ] Verify imports are returned from their cells\n6. [ ] Check data types match expectations\n7. [ ] Verify environment has correct packages\n",
        "skills/marimo/references/reactivity.md": "# Marimo Reactivity Model\n\n## Contents\n\n- [DAG Execution](#dag-execution)\n- [Variable Rules](#variable-rules)\n- [Dependency Detection](#dependency-detection)\n- [Circular Dependencies](#circular-dependencies)\n- [Stale Cells](#stale-cells)\n- [Pure Functions Pattern](#pure-functions-pattern)\n- [Global State Warning](#global-state-warning)\n- [Debugging DAG Issues](#debugging-dag-issues)\n\n## DAG Execution\n\nMarimo builds a directed acyclic graph (DAG) from cell dependencies:\n\n```\nCell A (defines x) → Cell B (uses x, defines y) → Cell C (uses y)\n```\n\nWhen Cell A changes, cells B and C automatically re-execute in order.\n\n## Variable Rules\n\n### Single Definition Rule\nEach variable can only be defined in ONE cell:\n\n```python\n# WRONG: x defined in multiple cells\n@app.cell\ndef cell1():\n    x = 1\n    return x,\n\n@app.cell\ndef cell2():\n    x = 2  # ERROR: x already defined\n    return x,\n```\n\n```python\n# CORRECT: different names or single source\n@app.cell\ndef cell1():\n    x = 1\n    return x,\n\n@app.cell\ndef cell2(x):\n    y = x + 1  # Uses x from cell1\n    return y,\n```\n\n### Return Statement Requirements\n\nCells must return variables they define for other cells to use:\n\n```python\n@app.cell\ndef _(pl):\n    df = pl.read_csv(\"data.csv\")\n    return df,  # Trailing comma required for single return\n\n@app.cell\ndef _(df, pl):\n    summary = df.describe()\n    filtered = df.filter(pl.col(\"value\") > 0)\n    return summary, filtered  # Multiple returns\n```\n\n## Dependency Detection\n\nMarimo automatically detects dependencies through:\n1. Function parameters (inputs from other cells)\n2. Return values (outputs to other cells)\n\n```python\n@app.cell\ndef _(pl):  # Depends on polars import\n    df = pl.DataFrame({\"a\": [1, 2, 3]})\n    return df,\n\n@app.cell\ndef _(df):  # Depends on df from above cell\n    print(df.shape)\n```\n\n## Circular Dependencies\n\nCircular dependencies cause errors:\n\n```\nCell A uses y from Cell B\nCell B uses x from Cell A\n```\n\n**Fix**: Merge cells or restructure to break the cycle.\n\n## Stale Cells\n\nA cell becomes \"stale\" when:\n1. Its dependencies have changed\n2. It hasn't re-executed yet\n\nIn interactive mode, marimo highlights stale cells. Run them to update.\n\n## Pure Functions Pattern\n\nFor complex logic, use pure functions within cells:\n\n```python\n@app.cell\ndef _():\n    def process_data(df):\n        \"\"\"Pure function - no side effects.\"\"\"\n        return df.filter(pl.col(\"valid\") == True)\n    return process_data,\n\n@app.cell\ndef _(df, process_data):\n    clean_df = process_data(df)\n    return clean_df,\n```\n\n## Global State Warning\n\nAvoid global mutable state:\n\n```python\n# BAD: Mutable global affects reactivity\nresults = []\n\n@app.cell\ndef _():\n    results.append(1)  # Side effect, breaks reactivity\n\n# GOOD: Return new values\n@app.cell\ndef _():\n    results = [1]\n    return results,\n```\n\n## Debugging DAG Issues\n\nUse marimo's built-in graph view:\n- `marimo edit notebook.py` → View → Dependency graph\n- Or programmatically: `app.graph()` in a cell\n\nCheck for:\n- Unexpected dependencies\n- Missing connections\n- Isolated cells (no inputs/outputs)\n",
        "skills/marimo/references/sql.md": "# Marimo SQL Integration\n\n## Contents\n\n- [SQL Cells](#sql-cells)\n- [Basic SQL on DataFrames](#basic-sql-on-dataframes)\n- [SQL Cell Syntax](#sql-cell-syntax)\n- [Database Connections](#database-connections)\n- [Parameterized Queries](#parameterized-queries)\n- [Common Query Patterns](#common-query-patterns)\n- [Interactive SQL](#interactive-sql)\n- [Performance Tips](#performance-tips)\n- [Troubleshooting](#troubleshooting)\n\n## SQL Cells\n\nMarimo provides native SQL support through `mo.sql()` for querying DataFrames and databases.\n\n## Basic SQL on DataFrames\n\n```python\n@app.cell\ndef _(mo, pl):\n    # Create sample data\n    df = pl.DataFrame({\n        \"id\": [1, 2, 3, 4, 5],\n        \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"Diana\", \"Eve\"],\n        \"value\": [100, 200, 150, 300, 250],\n        \"category\": [\"A\", \"B\", \"A\", \"B\", \"A\"],\n    })\n    return df,\n\n@app.cell\ndef _(df, mo):\n    # Query DataFrame with SQL\n    result = mo.sql(\n        \"\"\"\n        SELECT category, AVG(value) as avg_value\n        FROM df\n        GROUP BY category\n        ORDER BY avg_value DESC\n        \"\"\",\n        dataframes={\"df\": df}\n    )\n    return result,\n```\n\n## SQL Cell Syntax\n\n### Implicit DataFrame Binding\n\n```python\n@app.cell\ndef _(df, mo):\n    # df is automatically available if in scope\n    result = mo.sql(\n        \"\"\"\n        SELECT * FROM df WHERE value > 100\n        \"\"\"\n    )\n    return result,\n```\n\n### Multiple DataFrames\n\n```python\n@app.cell\ndef _(customers, orders, mo):\n    result = mo.sql(\n        \"\"\"\n        SELECT c.name, o.total\n        FROM customers c\n        JOIN orders o ON c.id = o.customer_id\n        WHERE o.total > 500\n        \"\"\",\n        dataframes={\n            \"customers\": customers,\n            \"orders\": orders,\n        }\n    )\n    return result,\n```\n\n## Database Connections\n\n### SQLite\n\n```python\n@app.cell\ndef _(mo):\n    import sqlite3\n\n    conn = sqlite3.connect(\"database.db\")\n    return conn,\n\n@app.cell\ndef _(conn, mo):\n    result = mo.sql(\n        \"\"\"\n        SELECT * FROM users WHERE active = 1\n        \"\"\",\n        connection=conn\n    )\n    return result,\n```\n\n### PostgreSQL with psycopg2\n\n```python\n@app.cell\ndef _(mo):\n    import psycopg2\n\n    conn = psycopg2.connect(\n        host=\"localhost\",\n        database=\"mydb\",\n        user=\"user\",\n        password=\"password\"\n    )\n    return conn,\n\n@app.cell\ndef _(conn, mo):\n    result = mo.sql(\n        \"\"\"\n        SELECT * FROM orders\n        WHERE created_at > '2024-01-01'\n        LIMIT 100\n        \"\"\",\n        connection=conn\n    )\n    return result,\n```\n\n### DuckDB (Recommended for Analytics)\n\n```python\n@app.cell\ndef _():\n    import duckdb\n\n    # DuckDB works great with polars and parquet\n    conn = duckdb.connect()\n    return conn,\n\n@app.cell\ndef _(conn, mo):\n    # Query parquet files directly\n    result = mo.sql(\n        \"\"\"\n        SELECT * FROM 'data/*.parquet'\n        WHERE date >= '2024-01-01'\n        \"\"\",\n        connection=conn\n    )\n    return result,\n```\n\n## Parameterized Queries\n\n### Using f-strings (Simple Cases)\n\n```python\n@app.cell\ndef _(df, mo, threshold):\n    # threshold is a marimo widget\n    result = mo.sql(\n        f\"\"\"\n        SELECT * FROM df\n        WHERE value > {threshold.value}\n        \"\"\"\n    )\n    return result,\n```\n\n### Using Parameters (Safer)\n\n```python\n@app.cell\ndef _(conn, mo, user_input):\n    # Prevents SQL injection\n    result = mo.sql(\n        \"\"\"\n        SELECT * FROM users\n        WHERE name = :name\n        \"\"\",\n        connection=conn,\n        params={\"name\": user_input.value}\n    )\n    return result,\n```\n\n## Common Query Patterns\n\n### Aggregations\n\n```python\n@app.cell\ndef _(df, mo):\n    summary = mo.sql(\n        \"\"\"\n        SELECT\n            category,\n            COUNT(*) as count,\n            SUM(value) as total,\n            AVG(value) as average,\n            MIN(value) as min_val,\n            MAX(value) as max_val\n        FROM df\n        GROUP BY category\n        \"\"\"\n    )\n    return summary,\n```\n\n### Window Functions\n\n```python\n@app.cell\ndef _(df, mo):\n    ranked = mo.sql(\n        \"\"\"\n        SELECT\n            *,\n            ROW_NUMBER() OVER (PARTITION BY category ORDER BY value DESC) as rank,\n            SUM(value) OVER (PARTITION BY category) as category_total\n        FROM df\n        \"\"\"\n    )\n    return ranked,\n```\n\n### CTEs (Common Table Expressions)\n\n```python\n@app.cell\ndef _(df, mo):\n    result = mo.sql(\n        \"\"\"\n        WITH category_stats AS (\n            SELECT category, AVG(value) as avg_value\n            FROM df\n            GROUP BY category\n        ),\n        ranked AS (\n            SELECT *, ROW_NUMBER() OVER (ORDER BY avg_value DESC) as rank\n            FROM category_stats\n        )\n        SELECT * FROM ranked WHERE rank <= 3\n        \"\"\"\n    )\n    return result,\n```\n\n### Joins\n\n```python\n@app.cell\ndef _(customers, orders, mo):\n    joined = mo.sql(\n        \"\"\"\n        SELECT\n            c.id,\n            c.name,\n            COUNT(o.id) as order_count,\n            COALESCE(SUM(o.total), 0) as total_spent\n        FROM customers c\n        LEFT JOIN orders o ON c.id = o.customer_id\n        GROUP BY c.id, c.name\n        ORDER BY total_spent DESC\n        \"\"\"\n    )\n    return joined,\n```\n\n## Interactive SQL\n\n### Combine SQL with Widgets\n\n```python\n@app.cell\ndef _(mo):\n    category_filter = mo.ui.dropdown(\n        options=[\"All\", \"A\", \"B\", \"C\"],\n        value=\"All\",\n        label=\"Category\",\n    )\n    limit_slider = mo.ui.slider(\n        start=10, stop=100, step=10, value=50,\n        label=\"Limit\",\n    )\n    return category_filter, limit_slider,\n\n@app.cell\ndef _(category_filter, df, limit_slider, mo):\n    where_clause = \"\"\n    if category_filter.value != \"All\":\n        where_clause = f\"WHERE category = '{category_filter.value}'\"\n\n    result = mo.sql(\n        f\"\"\"\n        SELECT * FROM df\n        {where_clause}\n        ORDER BY value DESC\n        LIMIT {limit_slider.value}\n        \"\"\"\n    )\n    return result,\n```\n\n### Display SQL Results\n\n```python\n@app.cell\ndef _(mo, result):\n    mo.md(f\"## Query Results ({len(result)} rows)\")\n    mo.ui.table(result, pagination=True, page_size=20)\n```\n\n## Performance Tips\n\n### Use LIMIT for Large Datasets\n\n```python\n@app.cell\ndef _(conn, mo):\n    # Always limit results when exploring\n    sample = mo.sql(\n        \"\"\"\n        SELECT * FROM large_table\n        ORDER BY RANDOM()\n        LIMIT 1000\n        \"\"\",\n        connection=conn\n    )\n    return sample,\n```\n\n### Materialize Intermediate Results\n\n```python\n@app.cell\ndef _(conn, mo):\n    # Create temp table for repeated use\n    mo.sql(\n        \"\"\"\n        CREATE TEMP TABLE IF NOT EXISTS filtered_data AS\n        SELECT * FROM raw_data WHERE valid = true\n        \"\"\",\n        connection=conn\n    )\n\n@app.cell\ndef _(conn, mo):\n    # Use temp table in multiple queries\n    result = mo.sql(\n        \"\"\"\n        SELECT * FROM filtered_data\n        WHERE value > 100\n        \"\"\",\n        connection=conn\n    )\n    return result,\n```\n\n### Index Awareness\n\n```sql\n-- When working with databases, check indexes\nEXPLAIN ANALYZE SELECT * FROM users WHERE email = 'test@example.com';\n\n-- Add indexes for frequently filtered columns\nCREATE INDEX IF NOT EXISTS idx_users_email ON users(email);\n```\n\n## Troubleshooting\n\n### Common Errors\n\n| Error | Cause | Fix |\n|-------|-------|-----|\n| `Table not found` | DataFrame not in scope | Pass via `dataframes={}` |\n| `Column not found` | Typo in column name | Check `df.columns` |\n| `Type mismatch` | Comparing incompatible types | Cast explicitly |\n| `Connection closed` | Database connection dropped | Reconnect in separate cell |\n\n### Debugging Queries\n\n```python\n@app.cell\ndef _(df, mo):\n    # Print the query for debugging\n    query = \"\"\"\n        SELECT * FROM df WHERE value > 100\n    \"\"\"\n    print(f\"Executing: {query}\")\n\n    result = mo.sql(query)\n    print(f\"Returned {len(result)} rows\")\n    return result,\n```\n",
        "skills/marimo/references/widgets.md": "# Marimo Interactive Widgets\n\n## Contents\n\n- [mo.ui Overview](#moui-overview)\n- [Input Widgets](#input-widgets)\n- [Buttons and Actions](#buttons-and-actions)\n- [Layout Components](#layout-components)\n- [Data Display](#data-display)\n- [Visualization](#visualization)\n- [State Management](#state-management)\n- [Common Patterns](#common-patterns)\n\n## mo.ui Overview\n\nMarimo provides interactive UI components through `mo.ui`. Widgets automatically trigger cell re-execution when values change.\n\n## Input Widgets\n\n### Slider\n\n```python\n@app.cell\ndef _(mo):\n    threshold = mo.ui.slider(\n        start=0,\n        stop=100,\n        step=5,\n        value=50,\n        label=\"Threshold\",\n        show_value=True,\n    )\n    return threshold,\n\n@app.cell\ndef _(threshold):\n    # Access value with .value\n    print(f\"Current threshold: {threshold.value}\")\n```\n\n### Dropdown\n\n```python\n@app.cell\ndef _(mo):\n    category = mo.ui.dropdown(\n        options=[\"All\", \"A\", \"B\", \"C\"],\n        value=\"All\",\n        label=\"Category\",\n    )\n    return category,\n```\n\n### Multi-select\n\n```python\n@app.cell\ndef _(mo):\n    selected = mo.ui.multiselect(\n        options=[\"Option A\", \"Option B\", \"Option C\"],\n        value=[\"Option A\"],\n        label=\"Select items\",\n    )\n    return selected,\n```\n\n### Text Input\n\n```python\n@app.cell\ndef _(mo):\n    search = mo.ui.text(\n        placeholder=\"Enter search term...\",\n        label=\"Search\",\n        value=\"\",\n    )\n    return search,\n```\n\n### Text Area\n\n```python\n@app.cell\ndef _(mo):\n    notes = mo.ui.text_area(\n        placeholder=\"Enter notes...\",\n        label=\"Notes\",\n        rows=5,\n    )\n    return notes,\n```\n\n### Checkbox\n\n```python\n@app.cell\ndef _(mo):\n    enabled = mo.ui.checkbox(\n        value=False,\n        label=\"Enable feature\",\n    )\n    return enabled,\n```\n\n### Radio Buttons\n\n```python\n@app.cell\ndef _(mo):\n    choice = mo.ui.radio(\n        options=[\"Option A\", \"Option B\", \"Option C\"],\n        value=\"Option A\",\n        label=\"Select one\",\n    )\n    return choice,\n```\n\n### Date Picker\n\n```python\n@app.cell\ndef _(mo):\n    from datetime import date\n\n    selected_date = mo.ui.date(\n        value=date.today(),\n        label=\"Select date\",\n    )\n    return selected_date,\n```\n\n### Date Range\n\n```python\n@app.cell\ndef _(mo):\n    from datetime import date\n\n    date_range = mo.ui.date_range(\n        start=date(2024, 1, 1),\n        stop=date(2024, 12, 31),\n        label=\"Date range\",\n    )\n    return date_range,\n```\n\n## Buttons and Actions\n\n### Basic Button\n\n```python\n@app.cell\ndef _(mo):\n    button = mo.ui.button(\n        label=\"Click me\",\n        kind=\"primary\",  # primary, secondary, danger, warn\n    )\n    return button,\n\n@app.cell\ndef _(button):\n    # Button value increments on each click\n    print(f\"Button clicked {button.value} times\")\n```\n\n### Button with Callback\n\n```python\n@app.cell\ndef _(mo):\n    counter = mo.state(0)\n\n    def on_click(_):\n        counter.set(counter.value + 1)\n\n    button = mo.ui.button(\n        label=\"Increment\",\n        on_click=on_click,\n    )\n    return button, counter,\n\n@app.cell\ndef _(counter, mo):\n    mo.md(f\"Count: **{counter.value}**\")\n```\n\n### Run Button\n\n```python\n@app.cell\ndef _(mo):\n    # Only runs when button is clicked\n    run = mo.ui.run_button(label=\"Run Analysis\")\n    return run,\n\n@app.cell\ndef _(run):\n    if run.value:\n        # Expensive computation here\n        result = perform_analysis()\n```\n\n## Layout Components\n\n### Horizontal Stack\n\n```python\n@app.cell\ndef _(mo, slider1, slider2, slider3):\n    mo.hstack(\n        [slider1, slider2, slider3],\n        justify=\"start\",  # start, center, end, space-between\n        gap=2,\n    )\n```\n\n### Vertical Stack\n\n```python\n@app.cell\ndef _(mo, widget1, widget2, widget3):\n    mo.vstack(\n        [widget1, widget2, widget3],\n        align=\"stretch\",\n        gap=1,\n    )\n```\n\n### Accordion\n\n```python\n@app.cell\ndef _(mo):\n    mo.accordion({\n        \"Section 1\": mo.md(\"Content for section 1\"),\n        \"Section 2\": mo.md(\"Content for section 2\"),\n        \"Section 3\": mo.md(\"Content for section 3\"),\n    })\n```\n\n### Tabs\n\n```python\n@app.cell\ndef _(mo):\n    mo.ui.tabs({\n        \"Data\": data_table,\n        \"Chart\": chart,\n        \"Summary\": summary,\n    })\n```\n\n## Data Display\n\n### DataTable\n\n```python\n@app.cell\ndef _(df, mo):\n    mo.ui.table(\n        df,\n        selection=\"multi\",  # none, single, multi\n        pagination=True,\n        page_size=10,\n    )\n```\n\n### Interactive DataFrame\n\n```python\n@app.cell\ndef _(df, mo):\n    # Returns selected rows\n    table = mo.ui.dataframe(df)\n    return table,\n\n@app.cell\ndef _(table):\n    # Access selected data\n    selected = table.value\n```\n\n## Visualization\n\n### Altair Chart\n\n```python\n@app.cell\ndef _(mo):\n    import altair as alt\n\n    chart = alt.Chart(data).mark_bar().encode(\n        x='category',\n        y='value',\n    )\n\n    # Interactive chart with selection\n    mo.ui.altair_chart(chart)\n```\n\n### Plotly Chart\n\n```python\n@app.cell\ndef _(mo):\n    import plotly.express as px\n\n    fig = px.scatter(df, x='x', y='y', color='category')\n    mo.ui.plotly(fig)\n```\n\n## State Management\n\n### mo.state for Persistent Values\n\n```python\n@app.cell\ndef _(mo):\n    # State persists across cell re-runs\n    counter = mo.state(0)\n    items = mo.state([])\n    return counter, items,\n\n@app.cell\ndef _(counter, items, mo):\n    def add_item():\n        items.set(items.value + [f\"Item {len(items.value) + 1}\"])\n        counter.set(counter.value + 1)\n\n    button = mo.ui.button(label=\"Add Item\", on_click=lambda _: add_item())\n    return button,\n```\n\n### Batch Updates\n\n```python\n@app.cell\ndef _(mo):\n    state1 = mo.state(0)\n    state2 = mo.state(0)\n\n    def update_both():\n        # Batch updates to avoid multiple re-renders\n        with mo.batch():\n            state1.set(state1.value + 1)\n            state2.set(state2.value + 1)\n```\n\n## Common Patterns\n\n### Form with Multiple Inputs\n\n```python\n@app.cell\ndef _(mo):\n    form = mo.ui.form(\n        mo.vstack([\n            mo.ui.text(label=\"Name\", placeholder=\"Enter name\"),\n            mo.ui.number(label=\"Age\", start=0, stop=120),\n            mo.ui.dropdown(options=[\"A\", \"B\", \"C\"], label=\"Category\"),\n        ]),\n        submit_button_label=\"Submit\",\n    )\n    return form,\n\n@app.cell\ndef _(form):\n    if form.value:\n        name, age, category = form.value\n        process_form(name, age, category)\n```\n\n### Conditional Widget Display\n\n```python\n@app.cell\ndef _(advanced_mode, mo):\n    if advanced_mode.value:\n        mo.vstack([\n            advanced_slider,\n            advanced_dropdown,\n            advanced_checkbox,\n        ])\n    else:\n        mo.md(\"Enable advanced mode for more options\")\n```\n\n### Dynamic Options\n\n```python\n@app.cell\ndef _(category, mo):\n    # Options depend on category selection\n    if category.value == \"A\":\n        options = [\"A1\", \"A2\", \"A3\"]\n    elif category.value == \"B\":\n        options = [\"B1\", \"B2\"]\n    else:\n        options = [\"C1\"]\n\n    sub_category = mo.ui.dropdown(\n        options=options,\n        label=\"Sub-category\",\n    )\n    return sub_category,\n```\n",
        "skills/notebook-debug/SKILL.md": "---\nname: notebook-debug\ndescription: This skill should be used when the user asks to \"debug notebook\", \"inspect notebook outputs\", \"find notebook error\", \"read traceback from ipynb\", \"why did notebook fail\", or needs to understand runtime errors in executed Jupyter notebooks from any source (marimo, jupytext, papermill).\n---\n\n## Contents\n\n- [Verification Enforcement](#verification-enforcement)\n- [Why Execute to ipynb?](#why-execute-to-ipynb)\n- [Execution Commands](#execution-commands)\n- [Inspection Methods](#inspection-methods)\n- [Quick Failure Check](#quick-failure-check)\n- [Read Tool for Debugging](#read-tool-for-debugging)\n- [Common Patterns](#common-patterns)\n- [Debugging Workflow](#debugging-workflow)\n\n# Debugging Executed Notebooks\n\nThis skill covers inspecting executed `.ipynb` files to debug runtime errors, regardless of how the notebook was created (marimo, jupytext, or plain Jupyter).\n\n## Verification Enforcement\n\n### IRON LAW: NO 'NOTEBOOK WORKS' CLAIM WITHOUT TRACEBACK CHECK\n\nBefore claiming ANY notebook executed successfully, you MUST:\n1. **EXECUTE** the notebook to ipynb with outputs\n2. **CHECK** for tracebacks (Quick Failure Check section)\n3. **READ** the ipynb file with Read tool if errors found\n4. **VERIFY** all cells have execution_count (not null)\n5. **INSPECT** outputs for warnings/unexpected behavior\n6. **CLAIM** success only after all verification passes\n\nThis is not negotiable. Claiming \"notebook works\" without checking for tracebacks is LYING to the user.\n\n### Rationalization Table - STOP If You Think:\n\n| Excuse | Reality | Do Instead |\n|--------|---------|------------|\n| \"The command succeeded, so notebook works\" | Exit code 0 ≠ no errors | CHECK for tracebacks in outputs |\n| \"I'll just run the source file directly\" | You'll miss cell-level errors | EXECUTE to ipynb first, then inspect |\n| \"User will see errors when they run it\" | You're wasting their time | VERIFY before claiming completion |\n| \"I can see the code, so I know it works\" | Code that looks right can still fail | EXECUTE and READ outputs |\n| \"Quick check with grep is enough\" | Grep misses stderr and cell outputs | Use BOTH quick check AND Read tool |\n| \"Only the last cell matters\" | Middle cells can fail silently | VERIFY all cells executed (execution_count) |\n| \"I'll fix errors if user reports them\" | Proactive checking is your job | CHECK before user sees it |\n\n### Red Flags - STOP Immediately If You Think:\n\n- \"Let me run marimo/jupytext and assume it worked\" → NO. Execute to ipynb and CHECK outputs.\n- \"The notebook ran last time, so it still works\" → NO. Fresh execution EVERY time.\n- \"I can tell from the code that it's correct\" → NO. Code inspection ≠ runtime verification.\n- \"Just a small change, can't break anything\" → NO. Small changes cause big failures.\n\n### Verification Checklist\n\nBefore claiming \"notebook works\":\n\n**Execution:**\n- [ ] Execute notebook to ipynb format\n- [ ] Use `--include-outputs` flag (for marimo)\n- [ ] Verify output file created successfully\n- [ ] Verify output file is non-empty\n\n**Traceback Check:**\n- [ ] Run quick failure check: `jq -r '.cells[].outputs[]?.text[]?' | grep \"Traceback\"`\n- [ ] Check error count: `jq '[.cells[].outputs[]? | select(.output_type == \"error\")] | length'`\n- [ ] Use Read tool to inspect full context if errors found\n\n**Cell Execution:**\n- [ ] Verify all cells have execution_count (no null values)\n- [ ] Check execution order is sequential (no out-of-order cells)\n- [ ] Verify no cells skipped due to prior failures\n\n**Output Inspection:**\n- [ ] Verify critical outputs (not just absence of errors)\n- [ ] Check expected results present (dataframes, plots, metrics)\n- [ ] Verify no warnings that indicate problems\n- [ ] Check no unexpected NaN/None/empty results\n\n**Claim success only after:**\n- [ ] All checks pass: declare \"notebook executed successfully\"\n\n### Gate Function: Notebook Verification\n\nApply this verification sequence for every notebook debugging task:\n\n```\n1. EXECUTE → Run to ipynb with outputs\n2. CHECK   → Quick traceback/error count check\n3. READ    → Full inspection with Read tool if errors\n4. VERIFY  → All cells executed, outputs as expected\n5. CLAIM   → \"Notebook works\" only after all gates passed\n```\n\n**Never skip any gate.** Each gate catches different failure modes.\n\n## Why Execute to ipynb?\n\nConverting and executing notebooks to ipynb captures:\n- Cell outputs and return values\n- Tracebacks with full context\n- Execution order and cell IDs\n\nThis makes debugging much easier than reading raw `.py` source.\n\n## Execution Commands\n\n```bash\n# Export marimo notebook to ipynb with outputs\nmarimo export ipynb notebook.py -o __marimo__/notebook.ipynb --include-outputs\n\n# Convert jupytext to ipynb and execute with outputs\njupytext --to notebook --output - script.py | papermill - output.ipynb\n\n# Execute existing ipynb notebook to capture outputs\npapermill input.ipynb output.ipynb\n```\n\n## Inspection Methods\n\n|                  | jq                            | Read tool           |\n|------------------|-------------------------------|---------------------|\n| Output           | Raw JSON with escaped strings | Clean rendered view |\n| Error visibility | Buried in outputs array       | Inline after cell   |\n| Cell context     | Need to piece together        | Cell IDs visible    |\n| Scripting        | Better for automation         | Not scriptable      |\n\n**Verdict:** Use Read for debugging/inspection, jq for scripting/CI.\n\n## Quick Failure Check\n\n```bash\n# Check for tracebacks in notebook outputs\njq -r '.cells[].outputs[]?.text[]?' notebook.ipynb | grep \"Traceback\"\n\n# Count error outputs in notebook\njq '[.cells[].outputs[]? | select(.output_type == \"error\")] | length' notebook.ipynb\n```\n\n## Read Tool for Debugging\n\nThe Read tool renders ipynb with errors inline after the failing cell:\n\n```\n<cell id=\"MJUe\">raise ValueError(\"intentional error\")</cell>\n\nTraceback (most recent call last):\n  File \"/path/to/notebook.py\", line 5, in <module>\n    raise ValueError(\"intentional error\")\nValueError: intentional error\n\n<cell id=\"vblA\">y = x + 10  # depends on x, not the error cell</cell>\n```\n\nBenefits:\n- Errors appear immediately after the cell that caused them\n- Cell IDs visible for cross-referencing\n- Full traceback with line numbers\n- No JSON parsing needed\n\n## Common Patterns\n\n### Find the Failing Cell\n\nUse the Read tool to inspect the notebook and locate tracebacks:\n```bash\n# Read notebook to find traceback location inline after failing cell\nRead __marimo__/notebook.ipynb\n```\n\n### Check Cell Execution Count\n\nIdentify cells that did not execute:\n```bash\n# Find cells with null execution_count (not executed)\njq '.cells[] | select(.execution_count == null) | .source[:50]' notebook.ipynb\n```\n\n### Extract All Errors\n\nGather all error outputs from executed cells:\n```bash\n# Extract error tracebacks from all cells\njq -r '.cells[].outputs[]? | select(.output_type == \"error\") | .traceback[]' notebook.ipynb\n```\n\n## Debugging Workflow\n\n1. **Execute notebook with outputs captured:**\n   ```bash\n   # Export marimo notebook to ipynb format with all outputs\n   marimo export ipynb nb.py -o __marimo__/nb.ipynb --include-outputs\n   ```\n\n2. **Run quick failure check:**\n   ```bash\n   # Check if execution produced tracebacks\n   jq -r '.cells[].outputs[]?.text[]?' __marimo__/nb.ipynb | grep -q \"Traceback\" && echo \"FAILED\"\n   ```\n\n3. **Inspect notebook using Read tool:**\n   ```bash\n   # Read the full notebook to identify failing cells and their errors\n   Read __marimo__/nb.ipynb\n   ```\n\n4. **Fix source code and re-run to verify**\n",
        "skills/wrds/SKILL.md": "---\nname: wrds\nversion: 1.0\ndescription: This skill should be used when the user asks to \"query WRDS\", \"access Compustat\", \"get CRSP data\", \"pull Form 4 insider data\", \"query ISS compensation\", \"download SEC EDGAR filings\", \"get ExecuComp data\", \"access Capital IQ\", or needs WRDS PostgreSQL query patterns.\n---\n\n## Contents\n\n- [Query Enforcement](#query-enforcement)\n- [Quick Reference: Table Names](#quick-reference-table-names)\n- [Connection](#connection)\n- [Critical Filters](#critical-filters)\n- [Parameterized Queries](#parameterized-queries)\n- [Additional Resources](#additional-resources)\n\n# WRDS Data Access\n\nWRDS (Wharton Research Data Services) provides academic research data via PostgreSQL at `wrds-pgdata.wharton.upenn.edu:9737`.\n\n## Query Enforcement\n\n### IRON LAW: NO QUERY WITHOUT FILTER VALIDATION FIRST\n\nBefore executing ANY WRDS query, you MUST:\n1. **IDENTIFY** what filters are required for this dataset\n2. **VALIDATE** the query includes those filters\n3. **VERIFY** parameterized queries (never string formatting)\n4. **EXECUTE** the query\n5. **INSPECT** a sample of results before claiming success\n\nThis is not negotiable. Claiming query success without sample inspection is LYING to the user about data quality.\n\n### Rationalization Table - STOP If You Think:\n\n| Excuse | Reality | Do Instead |\n|--------|---------|------------|\n| \"I'll add filters later\" | You'll forget and pull bad data | Add filters NOW, before execution |\n| \"User didn't specify filters\" | Standard filters are ALWAYS required | Apply Critical Filters section defaults |\n| \"Just a quick test query\" | Test queries with bad filters teach bad patterns | Use production filters even for tests |\n| \"I'll let the user filter in pandas\" | Pulling millions of unnecessary rows wastes time/memory | Filter at database level FIRST |\n| \"The query worked, so it's correct\" | Query success ≠ data quality | INSPECT sample for invalid records |\n| \"I can use f-strings for simple queries\" | SQL injection risk + wrong type handling | ALWAYS use parameterized queries |\n\n### Red Flags - STOP Immediately If You Think:\n\n- \"Let me run this query quickly to see what's there\" → NO. Check Critical Filters section first.\n- \"I'll just pull everything and filter later\" → NO. Database-level filtering is mandatory.\n- \"The table name is obvious from the request\" → NO. Check Quick Reference section for exact names.\n- \"I can inspect the data after the user sees it\" → NO. Sample inspection BEFORE claiming success.\n\n### Query Validation Checklist\n\nBefore EVERY query execution:\n\n**For Compustat queries (comp.funda, comp.fundq):**\n- [ ] Includes `indfmt = 'INDL'`\n- [ ] Includes `datafmt = 'STD'`\n- [ ] Includes `popsrc = 'D'`\n- [ ] Includes `consol = 'C'`\n- [ ] Uses parameterized queries for variables\n- [ ] Date range is explicitly specified\n\n**For CRSP v2 queries (crsp.dsf_v2, crsp.msf_v2):**\n- [ ] Post-query filter: `sharetype == 'NS'`\n- [ ] Post-query filter: `securitytype == 'EQTY'`\n- [ ] Post-query filter: `securitysubtype == 'COM'`\n- [ ] Post-query filter: `usincflg == 'Y'`\n- [ ] Post-query filter: `issuertype.isin(['ACOR', 'CORP'])`\n- [ ] Uses parameterized queries\n\n**For Form 4 queries (tr_insiders.table1):**\n- [ ] Transaction type filter specified (acqdisp)\n- [ ] Transaction codes specified (trancode)\n- [ ] Date range is explicitly specified\n- [ ] Uses parameterized queries\n\n**For ALL queries:**\n- [ ] Sample inspection with `.head()` or `.sample()` BEFORE claiming success\n- [ ] Row count verification (is result size reasonable?)\n- [ ] NULL value check on critical columns\n- [ ] Date range validation (does min/max match expectations?)\n\n## Quick Reference: Table Names\n\n| Dataset | Schema | Key Tables |\n|---------|--------|------------|\n| Compustat | `comp` | `company`, `funda`, `fundq`, `secd` |\n| ExecuComp | `comp_execucomp` | `anncomp` |\n| CRSP | `crsp` | `dsf`, `msf`, `stocknames`, `ccmxpf_linkhist` |\n| CRSP v2 | `crsp` | `dsf_v2`, `msf_v2`, `stocknames_v2` |\n| Form 4 Insiders | `tr_insiders` | `table1`, `header`, `company` |\n| ISS Incentive Lab | `iss_incentive_lab` | `comppeer`, `sumcomp`, `participantfy` |\n| Capital IQ | `ciq` | `wrds_compensation` |\n| IBES | `tr_ibes` | `det_epsus`, `statsum_epsus` |\n| SEC EDGAR | `wrdssec` | `wrds_forms`, `wciklink_cusip` |\n| SEC Search | `wrds_sec_search` | `filing_view`, `registrant` |\n| EDGAR | `edgar` | `filings`, `filing_docs` |\n| Fama-French | `ff` | `factors_monthly`, `factors_daily` |\n| LSEG/Datastream | `tr_ds` | `ds2constmth`, `ds2indexlist` |\n\n## Connection\n\nInitialize PostgreSQL connection to WRDS:\n\n```python\nimport psycopg2\n\nconn = psycopg2.connect(\n    host='wrds-pgdata.wharton.upenn.edu',\n    port=9737,\n    database='wrds',\n    sslmode='require'\n    # Credentials from ~/.pgpass\n)\n```\n\nConfigure authentication via `~/.pgpass` with `chmod 600`:\n```\nwrds-pgdata.wharton.upenn.edu:9737:wrds:USERNAME:PASSWORD\n```\n\nConnect via SSH tunnel:\n```bash\nssh wrds\n```\n\nThis uses `~/.ssh/wrds_rsa` for authentication.\n\n## Critical Filters\n\n### Compustat Standard Filters\nAlways include for clean fundamental data:\n```sql\nWHERE indfmt = 'INDL'\n  AND datafmt = 'STD'\n  AND popsrc = 'D'\n  AND consol = 'C'\n```\n\n### CRSP v2 Common Stock Filter\nEquivalent to legacy `shrcd IN (10, 11)`:\n```python\ndf = df.loc[\n    (df.sharetype == 'NS') &\n    (df.securitytype == 'EQTY') &\n    (df.securitysubtype == 'COM') &\n    (df.usincflg == 'Y') &\n    (df.issuertype.isin(['ACOR', 'CORP']))\n]\n```\n\n### Form 4 Transaction Types\n```sql\nWHERE acqdisp = 'D'  -- Dispositions\n  AND trancode IN ('S', 'D', 'G', 'F')  -- Sales, Dispositions, Gifts, Tax\n```\n\n## Parameterized Queries\n\nAlways use parameterized queries (never string formatting):\n\nUse scalar parameter binding for single values:\n```python\ncursor.execute(\"\"\"\n    SELECT gvkey, conm FROM comp.company WHERE gvkey = %s\n\"\"\", (gvkey,))\n```\n\nUse ANY() for list parameters:\n```python\ncursor.execute(\"\"\"\n    SELECT * FROM comp.funda WHERE gvkey = ANY(%s)\n\"\"\", (gvkey_list,))\n```\n\n## Additional Resources\n\n### Reference Files\n\nDetailed query patterns and table documentation:\n\n- **`references/compustat.md`** - Compustat tables, ExecuComp, financial variables\n- **`references/crsp.md`** - CRSP stock data, CCM linking, v2 format\n- **`references/insider-form4.md`** - Thomson Reuters Form 4, rolecodes, insider types\n- **`references/iss-compensation.md`** - ISS Incentive Lab, peer companies, compensation\n- **`references/edgar.md`** - SEC EDGAR filings, URL construction, DCN vs accession numbers\n- **`references/connection.md`** - Connection pooling, caching, error handling\n\n### Example Files\n\nWorking code from real projects:\n\n- **`examples/form4_disposals.py`** - Insider trading analysis (from SVB project)\n- **`examples/wrds_connector.py`** - Connection pooling pattern\n\n### Scripts\n\n- **`scripts/test_connection.py`** - Validate WRDS connectivity\n\n### Local Sample Notebooks\n\nWRDS-provided samples at `~/resources/wrds-code-samples/`:\n- `ResearchApps/CCM2025.ipynb` - Modern CRSP-Compustat merge\n- `ResearchApps/ff3_crspCIZ.ipynb` - Fama-French factor construction\n- `comp/sas/execcomp_ceo_screen.sas` - ExecuComp patterns\n\n## Date Awareness\n\nWhen querying historical data, leverage current date context for dynamic range calculations.\n\nCurrent date is automatically available via `datetime.now()`. Apply this to:\n- Data range validation (e.g., \"get data for last 5 years\")\n- Fiscal year calculations\n- Event study windows\n\nImplement dynamic date ranges in queries:\n```python\nfrom datetime import datetime, timedelta\n\n# Query last 5 years of data\nend_date = datetime.now()\nstart_date = end_date - timedelta(days=5*365)\n\nquery = \"\"\"\nSELECT * FROM comp.funda\nWHERE datadate BETWEEN %s AND %s\n\"\"\"\ndf = pd.read_sql(query, conn, params=(start_date, end_date))\n```\n\nAlways incorporate current date awareness in date-dependent queries to ensure results remain fresh across time.\n",
        "skills/wrds/references/compustat.md": "# Compustat Data Access\n\n## Contents\n\n- [Overview](#overview)\n- [Key Tables](#key-tables)\n- [Common Query Patterns](#common-query-patterns)\n- [Bank-Specific Data](#bank-specific-data)\n- [Data Quality Notes](#data-quality-notes)\n- [Linking Tables](#linking-tables)\n\n## Overview\n\nCompustat provides fundamental financial data for public companies. Accessed via the `comp` schema in WRDS PostgreSQL.\n\n## Key Tables\n\n### Company Information\n\n#### comp.company\nMaster company identifier table.\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `gvkey` | varchar(6) | Global Company Key (primary identifier) |\n| `conm` | varchar(100) | Company name |\n| `cik` | varchar(10) | SEC CIK number |\n| `sic` | varchar(4) | Standard Industrial Classification |\n| `naics` | varchar(6) | NAICS industry code |\n| `state` | varchar(2) | State of incorporation |\n| `fic` | varchar(3) | Foreign incorporation code |\n| `add1`-`add4` | varchar | Address lines |\n| `city` | varchar(50) | City |\n| `ipodate` | date | IPO date |\n| `dldte` | date | Deletion date (if delisted) |\n\n```python\n# Find company by name\ncursor.execute(\"\"\"\n    SELECT gvkey, conm, cik, sic\n    FROM comp.company\n    WHERE UPPER(conm) LIKE %s\n    ORDER BY conm\n    LIMIT 10\n\"\"\", ('%SILICON VALLEY%',))\n```\n\n### Annual Fundamentals\n\n#### comp.funda\nAnnual financial statements (10-K data).\n\n##### Standard Filters (ALWAYS INCLUDE)\n```sql\nWHERE indfmt = 'INDL'   -- Industrial format (vs FS for financials)\n  AND datafmt = 'STD'   -- Standardized format\n  AND popsrc = 'D'      -- Domestic population\n  AND consol = 'C'      -- Consolidated statements\n```\n\n##### Key Fields\n\n| Field | Description | Notes |\n|-------|-------------|-------|\n| `gvkey` | Company identifier | Link to comp.company |\n| `datadate` | Fiscal year end date | |\n| `fyear` | Fiscal year | |\n| `fyr` | Fiscal year-end month | 12 = December |\n| `at` | Total assets | |\n| `lt` | Total liabilities | |\n| `seq` | Stockholders' equity | |\n| `ceq` | Common equity | |\n| `revt` | Total revenue | |\n| `sale` | Net sales | |\n| `cogs` | Cost of goods sold | |\n| `xsga` | SG&A expense | |\n| `dp` | Depreciation & amortization | |\n| `xint` | Interest expense | |\n| `txt` | Income taxes | |\n| `ni` | Net income | |\n| `oibdp` | Operating income before D&A | |\n| `oiadp` | Operating income after D&A | |\n| `ib` | Income before extraordinary items | |\n| `che` | Cash and short-term investments | |\n| `rect` | Receivables | |\n| `invt` | Inventories | |\n| `ppent` | Property, plant & equipment (net) | |\n| `dltt` | Long-term debt | |\n| `dlc` | Debt in current liabilities | |\n| `csho` | Common shares outstanding | Millions |\n| `prcc_f` | Price close (fiscal year end) | |\n| `mkvalt` | Market value | At fiscal year end |\n| `emp` | Employees | Thousands |\n\n```python\n# Get annual fundamentals for multiple companies\ngvkeys = ['001045', '001078', '002285']\n\ncursor.execute(\"\"\"\n    SELECT gvkey, datadate, fyear, at, lt, seq, revt, ni\n    FROM comp.funda\n    WHERE gvkey = ANY(%s)\n      AND datadate >= %s\n      AND indfmt = 'INDL'\n      AND datafmt = 'STD'\n      AND popsrc = 'D'\n      AND consol = 'C'\n    ORDER BY gvkey, datadate\n\"\"\", (gvkeys, '2018-01-01'))\n```\n\n### Quarterly Fundamentals\n\n#### comp.fundq\nQuarterly financial statements (10-Q data).\n\nSame filter requirements as `comp.funda`. Key differences:\n\n| Field | Description |\n|-------|-------------|\n| `fqtr` | Fiscal quarter (1-4) |\n| `rdq` | Report date of quarterly earnings |\n| `atq` | Total assets (quarterly) |\n| `ltq` | Total liabilities (quarterly) |\n| `revtq` | Revenue (quarterly) |\n| `niq` | Net income (quarterly) |\n\n```python\n# Get quarterly data\ncursor.execute(\"\"\"\n    SELECT gvkey, datadate, fqtr, revtq, niq\n    FROM comp.fundq\n    WHERE gvkey = %s\n      AND datadate >= %s\n      AND indfmt = 'INDL'\n      AND datafmt = 'STD'\n      AND popsrc = 'D'\n      AND consol = 'C'\n    ORDER BY datadate\n\"\"\", ('001045', '2020-01-01'))\n```\n\n### Security Data\n\n#### comp.secm (Monthly)\nMonthly security prices and returns.\n\n| Field | Description |\n|-------|-------------|\n| `gvkey` | Company identifier |\n| `datadate` | Month end date |\n| `prccm` | Price close (monthly) |\n| `trt1m` | Monthly total return |\n| `cshom` | Shares outstanding |\n\n#### comp.secd (Daily)\nDaily security prices.\n\n| Field | Description |\n|-------|-------------|\n| `gvkey` | Company identifier |\n| `datadate` | Trading date |\n| `prccd` | Price close (daily) |\n| `ajexdi` | Adjustment factor |\n| `cshtrd` | Trading volume |\n\n### Segment Data\n\n#### comp.segment\nBusiness segment data.\n\n| Field | Description |\n|-------|-------------|\n| `gvkey` | Company identifier |\n| `stype` | Segment type (BUSSEG, GEOSEG, OPSEG) |\n| `sid` | Segment identifier |\n| `srcdate` | Source date |\n| `snms` | Segment name |\n| `sales` | Segment sales |\n\n## Common Query Patterns\n\n### Company Lookup by CIK\n\n```python\ndef get_company_by_cik(pool, cik: str) -> dict | None:\n    \"\"\"Find company by CIK number.\"\"\"\n    # Normalize CIK to 10 digits\n    cik_normalized = cik.zfill(10)\n\n    with pool.cursor() as cursor:\n        cursor.execute(\"\"\"\n            SELECT gvkey, conm, cik, sic, naics\n            FROM comp.company\n            WHERE cik = %s\n        \"\"\", (cik_normalized,))\n\n        row = cursor.fetchone()\n        if row:\n            return {\n                'gvkey': row[0],\n                'name': row[1],\n                'cik': row[2],\n                'sic': row[3],\n                'naics': row[4]\n            }\n        return None\n```\n\n### Financial Ratios\n\n```python\ndef get_financial_ratios(pool, gvkey: str, start_date: str):\n    \"\"\"Calculate key financial ratios from Compustat data.\"\"\"\n    with pool.cursor() as cursor:\n        cursor.execute(\"\"\"\n            SELECT\n                gvkey,\n                datadate,\n                fyear,\n                -- Profitability\n                ni / NULLIF(revt, 0) AS net_margin,\n                ni / NULLIF(at, 0) AS roa,\n                ni / NULLIF(seq, 0) AS roe,\n                -- Leverage\n                lt / NULLIF(at, 0) AS debt_to_assets,\n                (dltt + dlc) / NULLIF(seq, 0) AS debt_to_equity,\n                -- Liquidity\n                che / NULLIF(at, 0) AS cash_ratio,\n                -- Valuation\n                mkvalt / NULLIF(ni, 0) AS pe_ratio,\n                mkvalt / NULLIF(seq, 0) AS pb_ratio\n            FROM comp.funda\n            WHERE gvkey = %s\n              AND datadate >= %s\n              AND indfmt = 'INDL'\n              AND datafmt = 'STD'\n              AND popsrc = 'D'\n              AND consol = 'C'\n            ORDER BY datadate\n        \"\"\", (gvkey, start_date))\n\n        return cursor.fetchall()\n```\n\n### Industry Comparison\n\n```python\ndef get_industry_peers(pool, sic: str, year: int) -> list:\n    \"\"\"Get companies in same SIC industry for comparison.\"\"\"\n    with pool.cursor() as cursor:\n        cursor.execute(\"\"\"\n            SELECT\n                c.gvkey,\n                c.conm,\n                f.revt,\n                f.at,\n                f.ni\n            FROM comp.company c\n            JOIN comp.funda f ON c.gvkey = f.gvkey\n            WHERE c.sic = %s\n              AND f.fyear = %s\n              AND f.indfmt = 'INDL'\n              AND f.datafmt = 'STD'\n              AND f.popsrc = 'D'\n              AND f.consol = 'C'\n            ORDER BY f.at DESC\n            LIMIT 50\n        \"\"\", (sic, year))\n\n        return cursor.fetchall()\n```\n\n### Time Series Panel Data\n\n```python\ndef get_panel_data(pool, gvkeys: list, start_year: int, end_year: int):\n    \"\"\"Get panel data for multiple companies across years.\"\"\"\n    with pool.cursor() as cursor:\n        cursor.execute(\"\"\"\n            SELECT\n                gvkey,\n                fyear,\n                datadate,\n                at,\n                lt,\n                seq,\n                revt,\n                ni,\n                che,\n                prcc_f * csho AS market_cap\n            FROM comp.funda\n            WHERE gvkey = ANY(%s)\n              AND fyear BETWEEN %s AND %s\n              AND indfmt = 'INDL'\n              AND datafmt = 'STD'\n              AND popsrc = 'D'\n              AND consol = 'C'\n            ORDER BY gvkey, fyear\n        \"\"\", (gvkeys, start_year, end_year))\n\n        return cursor.fetchall()\n```\n\n## Bank-Specific Data\n\nFor banks (SIC 60xx), use `comp.bank` tables or apply `indfmt = 'FS'`:\n\n```python\ndef get_bank_data(pool, gvkey: str, start_date: str):\n    \"\"\"Get bank financial data (financial services format).\"\"\"\n    with pool.cursor() as cursor:\n        cursor.execute(\"\"\"\n            SELECT\n                gvkey,\n                datadate,\n                at,           -- Total assets\n                dptc,         -- Total deposits\n                lntal,        -- Total loans\n                nii,          -- Net interest income\n                nim,          -- Net interest margin\n                npl,          -- Non-performing loans\n                tier1,        -- Tier 1 capital ratio\n                roa,          -- Return on assets\n                roe           -- Return on equity\n            FROM comp.funda\n            WHERE gvkey = %s\n              AND datadate >= %s\n              AND indfmt = 'FS'  -- Financial services format\n              AND datafmt = 'STD'\n              AND popsrc = 'D'\n              AND consol = 'C'\n            ORDER BY datadate\n        \"\"\", (gvkey, start_date))\n\n        return cursor.fetchall()\n```\n\n## Data Quality Notes\n\n1. **Missing values**: Many fields are NULL; always use `NULLIF()` in divisions\n2. **Restatements**: Use `datadate` for point-in-time; `rdq` shows when reported\n3. **Currency**: North American data in USD; global in local currency\n4. **Fiscal years**: `fyear` is fiscal year; `datadate` is fiscal year end\n5. **Industry codes**: SIC being replaced by NAICS; check both\n\n## Linking Tables\n\n### CRSP-Compustat Link\n\n```python\ndef get_crsp_permno(pool, gvkey: str) -> str | None:\n    \"\"\"Get CRSP PERMNO for a Compustat GVKEY.\"\"\"\n    with pool.cursor() as cursor:\n        cursor.execute(\"\"\"\n            SELECT lpermno\n            FROM crsp.ccmxpf_linkhist\n            WHERE gvkey = %s\n              AND linktype IN ('LC', 'LU')\n              AND linkprim IN ('P', 'C')\n            ORDER BY linkdt DESC\n            LIMIT 1\n        \"\"\", (gvkey,))\n\n        row = cursor.fetchone()\n        return row[0] if row else None\n```\n",
        "skills/wrds/references/connection.md": "# WRDS Connection Pooling\n\n## Contents\n\n- [Overview](#overview)\n- [Basic Pool Setup](#basic-pool-setup)\n- [Thread-Safe Pool (for concurrent access)](#thread-safe-pool-for-concurrent-access)\n- [Connection Parameters](#connection-parameters)\n- [Pool Sizing Guidelines](#pool-sizing-guidelines)\n- [Connection Health Checks](#connection-health-checks)\n- [Named Cursors for Large Result Sets](#named-cursors-for-large-result-sets)\n- [Error Handling Patterns](#error-handling-patterns)\n- [Integration with pandas](#integration-with-pandas)\n- [Environment-Based Configuration](#environment-based-configuration)\n- [Troubleshooting](#troubleshooting)\n\n## Overview\n\nWRDS PostgreSQL connections benefit from pooling due to SSL handshake overhead. This module details connection pool configuration, lifecycle management, and troubleshooting.\n\n## Basic Pool Setup\n\n```python\nimport psycopg2\nfrom psycopg2.pool import SimpleConnectionPool\nfrom contextlib import contextmanager\nimport atexit\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass WRDSPool:\n    \"\"\"Thread-safe WRDS connection pool with lifecycle management.\"\"\"\n\n    _instance = None\n\n    def __new__(cls):\n        \"\"\"Singleton pattern for connection pool.\"\"\"\n        if cls._instance is None:\n            cls._instance = super().__new__(cls)\n            cls._instance._initialized = False\n        return cls._instance\n\n    def __init__(self, minconn=1, maxconn=5):\n        if self._initialized:\n            return\n\n        self.pool = SimpleConnectionPool(\n            minconn=minconn,\n            maxconn=maxconn,\n            host='wrds-pgdata.wharton.upenn.edu',\n            port=9737,\n            database='wrds',\n            sslmode='require',\n            connect_timeout=30,\n            options='-c statement_timeout=300000'  # 5 min query timeout\n        )\n\n        # Register cleanup on program exit\n        atexit.register(self.close)\n        self._initialized = True\n        logger.info(f\"WRDS pool initialized: {minconn}-{maxconn} connections\")\n\n    @contextmanager\n    def connection(self):\n        \"\"\"Get connection with automatic return to pool.\"\"\"\n        conn = None\n        try:\n            conn = self.pool.getconn()\n            yield conn\n        except psycopg2.OperationalError as e:\n            logger.error(f\"Connection error: {e}\")\n            if conn:\n                # Mark connection as broken\n                self.pool.putconn(conn, close=True)\n                conn = None\n            raise\n        finally:\n            if conn:\n                self.pool.putconn(conn)\n\n    @contextmanager\n    def cursor(self, cursor_factory=None):\n        \"\"\"Get cursor with connection management.\"\"\"\n        with self.connection() as conn:\n            cursor = conn.cursor(cursor_factory=cursor_factory)\n            try:\n                yield cursor\n                conn.commit()\n            except Exception:\n                conn.rollback()\n                raise\n            finally:\n                cursor.close()\n\n    def close(self):\n        \"\"\"Close all connections in pool.\"\"\"\n        if hasattr(self, 'pool') and self.pool:\n            self.pool.closeall()\n            logger.info(\"WRDS pool closed\")\n\n# Convenience function\ndef get_pool() -> WRDSPool:\n    \"\"\"Get or create the WRDS connection pool.\"\"\"\n    return WRDSPool()\n```\n\n## Thread-Safe Pool (for concurrent access)\n\nFor multi-threaded applications, use `ThreadedConnectionPool`:\n\n```python\nfrom psycopg2.pool import ThreadedConnectionPool\nimport threading\n\nclass ThreadSafeWRDSPool:\n    \"\"\"Thread-safe connection pool for concurrent access.\"\"\"\n\n    _instance = None\n    _lock = threading.Lock()\n\n    def __new__(cls):\n        with cls._lock:\n            if cls._instance is None:\n                cls._instance = super().__new__(cls)\n                cls._instance._initialized = False\n            return cls._instance\n\n    def __init__(self, minconn=1, maxconn=10):\n        with self._lock:\n            if self._initialized:\n                return\n\n            self.pool = ThreadedConnectionPool(\n                minconn=minconn,\n                maxconn=maxconn,\n                host='wrds-pgdata.wharton.upenn.edu',\n                port=9737,\n                database='wrds',\n                sslmode='require'\n            )\n            self._initialized = True\n\n    @contextmanager\n    def connection(self):\n        \"\"\"Thread-safe connection acquisition.\"\"\"\n        conn = self.pool.getconn()\n        try:\n            yield conn\n        finally:\n            self.pool.putconn(conn)\n```\n\n## Connection Parameters\n\n### Required Parameters\n\n| Parameter | Value | Description |\n|-----------|-------|-------------|\n| `host` | `wrds-pgdata.wharton.upenn.edu` | WRDS PostgreSQL host |\n| `port` | `9737` | Non-standard PostgreSQL port |\n| `database` | `wrds` | Main WRDS database |\n| `sslmode` | `require` | SSL required for WRDS |\n\n### Optional Parameters\n\n| Parameter | Recommended | Description |\n|-----------|-------------|-------------|\n| `connect_timeout` | `30` | Connection timeout in seconds |\n| `statement_timeout` | `300000` | Query timeout in ms (5 min) |\n| `application_name` | Project name | Helps WRDS identify your app |\n\n### Authentication via ~/.pgpass\n\nWRDS credentials are read from `~/.pgpass`:\n\n```\n# Format: hostname:port:database:username:password\nwrds-pgdata.wharton.upenn.edu:9737:wrds:myusername:mypassword\n```\n\nEnsure proper permissions:\n```bash\nchmod 600 ~/.pgpass\n```\n\n## Pool Sizing Guidelines\n\n| Use Case | minconn | maxconn | Notes |\n|----------|---------|---------|-------|\n| Single-threaded scripts | 1 | 1 | No pooling overhead |\n| Jupyter notebooks | 1 | 3 | Occasional queries |\n| Batch processing | 2 | 5 | Parallel queries |\n| Web applications | 5 | 20 | High concurrency |\n\n## Connection Health Checks\n\n```python\ndef check_connection_health(pool: WRDSPool) -> bool:\n    \"\"\"Verify pool connection is healthy.\"\"\"\n    try:\n        with pool.cursor() as cursor:\n            cursor.execute(\"SELECT 1\")\n            result = cursor.fetchone()\n            return result == (1,)\n    except Exception as e:\n        logger.error(f\"Health check failed: {e}\")\n        return False\n\ndef reconnect_if_needed(pool: WRDSPool) -> bool:\n    \"\"\"Attempt reconnection if pool is unhealthy.\"\"\"\n    if check_connection_health(pool):\n        return True\n\n    logger.warning(\"Pool unhealthy, attempting reconnection...\")\n\n    # Close existing pool\n    pool.close()\n\n    # Reinitialize\n    pool._initialized = False\n    pool.__init__()\n\n    return check_connection_health(pool)\n```\n\n## Named Cursors for Large Result Sets\n\nFor queries returning large datasets, use server-side cursors:\n\n```python\nfrom psycopg2.extras import NamedTupleCursor\n\ndef fetch_large_dataset(pool: WRDSPool, query: str, params: tuple = None,\n                        batch_size: int = 10000):\n    \"\"\"Fetch large dataset using server-side cursor.\"\"\"\n    with pool.connection() as conn:\n        # Named cursor enables server-side processing\n        with conn.cursor(name='large_fetch') as cursor:\n            cursor.itersize = batch_size\n            cursor.execute(query, params)\n\n            for row in cursor:\n                yield row\n```\n\n## Error Handling Patterns\n\n```python\nimport psycopg2\nfrom psycopg2 import OperationalError, InterfaceError, DatabaseError\nimport time\n\ndef retry_on_connection_error(pool: WRDSPool, query: str,\n                               params: tuple = None,\n                               max_retries: int = 3,\n                               delay: float = 1.0):\n    \"\"\"Execute query with automatic retry on connection errors.\"\"\"\n    last_error = None\n\n    for attempt in range(max_retries):\n        try:\n            with pool.cursor() as cursor:\n                cursor.execute(query, params)\n                return cursor.fetchall()\n\n        except (OperationalError, InterfaceError) as e:\n            last_error = e\n            logger.warning(f\"Connection error (attempt {attempt + 1}): {e}\")\n\n            if attempt < max_retries - 1:\n                time.sleep(delay * (attempt + 1))  # Exponential backoff\n                continue\n\n        except DatabaseError as e:\n            # Query errors should not be retried\n            logger.error(f\"Query error: {e}\")\n            raise\n\n    raise last_error\n```\n\n## Integration with pandas\n\n```python\nimport pandas as pd\n\ndef query_to_dataframe(pool: WRDSPool, query: str,\n                       params: tuple = None) -> pd.DataFrame:\n    \"\"\"Execute query and return results as DataFrame.\"\"\"\n    with pool.connection() as conn:\n        return pd.read_sql_query(query, conn, params=params)\n\ndef query_to_dataframe_chunked(pool: WRDSPool, query: str,\n                                params: tuple = None,\n                                chunksize: int = 10000):\n    \"\"\"Execute query and yield DataFrame chunks.\"\"\"\n    with pool.connection() as conn:\n        for chunk in pd.read_sql_query(query, conn, params=params,\n                                        chunksize=chunksize):\n            yield chunk\n```\n\n## Environment-Based Configuration\n\n```python\nimport os\n\ndef create_pool_from_env() -> WRDSPool:\n    \"\"\"Create pool with configuration from environment.\"\"\"\n    return WRDSPool(\n        minconn=int(os.getenv('WRDS_POOL_MIN', 1)),\n        maxconn=int(os.getenv('WRDS_POOL_MAX', 5))\n    )\n\n# Usage in scripts\n# export WRDS_POOL_MIN=2\n# export WRDS_POOL_MAX=10\n```\n\n## Troubleshooting\n\n### Common Errors\n\n| Error | Cause | Solution |\n|-------|-------|----------|\n| `connection refused` | Firewall/network | Check VPN, firewall rules |\n| `authentication failed` | Bad credentials | Verify ~/.pgpass |\n| `SSL SYSCALL error` | Network interruption | Retry with exponential backoff |\n| `too many connections` | Pool exhausted | Increase maxconn or check for leaks |\n| `statement timeout` | Query too slow | Optimize query or increase timeout |\n\n### Connection Leak Detection\n\n```python\nimport traceback\nimport weakref\n\nclass DebugPool(WRDSPool):\n    \"\"\"Pool with connection leak detection.\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self._active = weakref.WeakValueDictionary()\n\n    @contextmanager\n    def connection(self):\n        conn = self.pool.getconn()\n        conn_id = id(conn)\n        self._active[conn_id] = conn\n\n        # Store stack trace for debugging\n        conn._checkout_stack = traceback.extract_stack()\n\n        try:\n            yield conn\n        finally:\n            if conn_id in self._active:\n                del self._active[conn_id]\n            self.pool.putconn(conn)\n\n    def report_leaks(self):\n        \"\"\"Report any connections not returned to pool.\"\"\"\n        for conn_id, conn in self._active.items():\n            stack = ''.join(traceback.format_list(conn._checkout_stack))\n            logger.warning(f\"Connection {conn_id} not returned:\\n{stack}\")\n```\n",
        "skills/wrds/references/crsp.md": "# CRSP Stock Data\n\n## Contents\n\n- [Tables](#tables)\n- [Key Fields](#key-fields)\n- [CRSP v2 Filters](#crsp-v2-filters)\n- [CRSP-Compustat Merge (CCM)](#crsp-compustat-merge-ccm)\n- [Market Equity](#market-equity)\n- [Fama-French Breakpoints](#fama-french-breakpoints)\n- [Common Gotchas](#common-gotchas)\n\n## Tables\n\n### Legacy Format\n| Table | Description |\n|-------|-------------|\n| `crsp.dsf` | Daily stock file |\n| `crsp.msf` | Monthly stock file |\n| `crsp.dse` | Daily stock events |\n| `crsp.stocknames` | Security names/identifiers |\n| `crsp.ccmxpf_linkhist` | CRSP-Compustat link |\n\n### v2 (CIZ) Format\n| Table | Description |\n|-------|-------------|\n| `crsp.dsf_v2` | Daily stock file (CIZ) |\n| `crsp.msf_v2` | Monthly stock file (CIZ) |\n| `crsp.stocknames_v2` | Security names (CIZ) |\n\n## Key Fields\n\n### Stock Files (dsf/msf)\n- `permno` - Permanent security identifier\n- `permco` - Permanent company identifier\n- `date` / `mthcaldt` - Date\n- `ret` / `mthret` - Return\n- `prc` / `mthprc` - Price (negative = bid/ask average)\n- `vol` - Volume\n- `shrout` - Shares outstanding\n\n### v2 Additional Fields\n- `sharetype` - Share type (NS=Normal Shares)\n- `securitytype` - Security type (EQTY=Equity)\n- `securitysubtype` - Subtype (COM=Common)\n- `usincflg` - US incorporated flag\n- `issuertype` - Issuer type (ACOR, CORP)\n- `primaryexch` - Primary exchange (N, A, Q)\n- `conditionaltype` - Conditional type (RW=Real When-issued)\n- `tradingstatusflg` - Trading status (A=Active)\n\n## CRSP v2 Filters\n\n### Common Stock (equivalent to shrcd 10, 11)\n```python\ndf = df.loc[\n    (df.sharetype == 'NS') &\n    (df.securitytype == 'EQTY') &\n    (df.securitysubtype == 'COM') &\n    (df.usincflg == 'Y') &\n    (df.issuertype.isin(['ACOR', 'CORP']))\n]\n```\n\n### NYSE/AMEX/NASDAQ (equivalent to exchcd 1, 2, 3)\n```python\ndf = df.loc[\n    (df.primaryexch.isin(['N', 'A', 'Q'])) &\n    (df.conditionaltype == 'RW') &\n    (df.tradingstatusflg == 'A')\n]\n```\n\n## CRSP-Compustat Merge (CCM)\n\n### Link Table Fields\n- `gvkey` - Compustat identifier\n- `lpermno` - CRSP PERMNO\n- `lpermco` - CRSP PERMCO\n- `linktype` - Link type (LC, LU, etc.)\n- `linkprim` - Primary link flag (P, C)\n- `linkdt` - Link start date\n- `linkenddt` - Link end date (NULL = current)\n\n### Standard CCM Merge\n```python\nsql = \"\"\"\n    SELECT a.gvkey, a.datadate, a.at, a.sale,\n           b.lpermno as permno, c.mthret\n    FROM comp.funda a\n    INNER JOIN crsp.ccmxpf_linkhist b\n        ON a.gvkey = b.gvkey\n        AND b.linktype IN ('LU', 'LC')\n        AND b.linkprim IN ('P', 'C')\n        AND a.datadate >= b.linkdt\n        AND (a.datadate <= b.linkenddt OR b.linkenddt IS NULL)\n    INNER JOIN crsp.msf_v2 c\n        ON b.lpermno = c.permno\n        AND DATE_TRUNC('month', a.datadate) = DATE_TRUNC('month', c.mthcaldt)\n    WHERE a.fyear >= 2020\n    AND a.indfmt = 'INDL'\n    AND a.datafmt = 'STD'\n    AND a.popsrc = 'D'\n    AND a.consol = 'C'\n\"\"\"\n```\n\n### Link Type Reference\n| Code | Description |\n|------|-------------|\n| LC | Link research complete |\n| LU | Link unresearched |\n| LX | Link to inactive issue |\n| LD | Duplicate link |\n| LS | Secondary link |\n| LN | Non-matching link |\n\n### CCM Date Collapse\nConsolidate consecutive link date ranges:\n```python\ndf['prev_linkenddt'] = df.groupby(['gvkey', 'lpermno'])['linkenddt'].shift()\ndf['linkdt'] = np.where(\n    (df['prev_linkenddt'].notna()) &\n    (df['linkdt'] <= df['prev_linkenddt'] + pd.Timedelta(days=1)),\n    df.groupby(['gvkey', 'lpermno'])['linkdt'].transform('first'),\n    df['linkdt']\n)\ncollapsed = df.drop_duplicates(subset=['gvkey', 'lpermno', 'linkdt'], keep='last')\n```\n\n## Market Equity\n\n```python\n# Calculate market equity\ncrsp['me'] = abs(crsp['mthprc']) * crsp['shrout']\n\n# Aggregate to PERMCO level (sum across share classes)\ncrsp_summe = crsp.groupby(['mthcaldt', 'permco'])['me'].sum().reset_index()\n```\n\n## Fama-French Breakpoints\n\nUse NYSE stocks only for breakpoints:\n```python\nnyse = ccm[(ccm['primaryexch'] == 'N') &\n           (ccm['beme'] > 0) &\n           (ccm['me'] > 0)]\n\n# Size breakpoint (median)\nnyse_sz = nyse.groupby('jdate')['me'].median()\n\n# B/M breakpoints (30th, 70th percentile)\nnyse_bm = nyse.groupby('jdate')['beme'].describe(percentiles=[0.3, 0.7])\n```\n\n## Common Gotchas\n\n1. **Negative prices** - Absolute value needed: `abs(prc)`\n2. **Delisting returns** - CIZ format includes in time series (no separate adjustment)\n3. **Link dates** - Always check `linkdt` and `linkenddt` bounds\n4. **Primary links** - Use `linkprim IN ('P', 'C')` for primary links only\n5. **Share classes** - Aggregate to PERMCO for company-level market cap\n",
        "skills/wrds/references/edgar.md": "# SEC EDGAR Access via WRDS\n\n## Contents\n\n- [Key Tables](#key-tables) - `edgar.filings`, `edgar.company_info`\n- [Common Form Types](#common-form-types) - 10-K, 10-Q, 8-K, DEF 14A, Form 4\n- [Query Patterns](#query-patterns) - Find filings, filter by type/date\n- [Accessing Filing Documents](#accessing-filing-documents) - URL construction, Form 4 URLs\n- [CRITICAL: DCN vs Accession Number](#critical-dcn-vs-accession-number) - WRDS gotcha\n- [Linking CIK to Other Identifiers](#linking-cik-to-other-identifiers) - CIK↔GVKEY\n- [Working with Filing Content](#working-with-filing-content) - Download, parse sections\n- [Rate Limiting](#rate-limiting-for-sec-access) - SEC API limits\n\n## Overview\n\nWRDS provides SEC EDGAR filing data through the `edgar` schema. This includes filing metadata, company information, and filing content access.\n\n## Key Tables\n\n### edgar.filings\nMaster filing table with all SEC submissions.\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `cik` | varchar(10) | Central Index Key (10-digit padded) |\n| `accession_number` | varchar(25) | Unique filing identifier |\n| `form_type` | varchar(20) | Filing type (10-K, 10-Q, 8-K, etc.) |\n| `file_date` | date | Date filed with SEC |\n| `accepted` | timestamp | SEC acceptance timestamp |\n| `company_name` | varchar(150) | Filer company name |\n| `fiscal_year_end` | varchar(4) | Fiscal year end (MMDD format) |\n| `sic` | varchar(4) | Standard Industrial Classification |\n| `state` | varchar(2) | State of incorporation |\n| `file_num` | varchar(20) | SEC file number |\n| `fiscal_year` | int | Fiscal year of filing |\n\n### edgar.company_info\nCompany registration information.\n\n| Field | Type | Description |\n|-------|------|-------------|\n| `cik` | varchar(10) | Central Index Key |\n| `company_name` | varchar(150) | Company name |\n| `sic` | varchar(4) | SIC code |\n| `state` | varchar(2) | State |\n| `fiscal_year_end` | varchar(4) | Fiscal year end |\n\n## Common Form Types\n\n| Form Type | Description | Frequency |\n|-----------|-------------|-----------|\n| `10-K` | Annual report | Yearly |\n| `10-K/A` | Amended annual report | As needed |\n| `10-Q` | Quarterly report | Quarterly |\n| `8-K` | Current report (material events) | As needed |\n| `DEF 14A` | Proxy statement | Yearly |\n| `4` | Insider trading report | As needed |\n| `S-1` | IPO registration | One-time |\n| `13F-HR` | Institutional holdings | Quarterly |\n| `SC 13D` | Beneficial ownership >5% | As needed |\n| `SC 13G` | Passive beneficial ownership | As needed |\n\n## Query Patterns\n\n### Find Company Filings\n\n```python\ndef get_company_filings(pool, cik: str, form_types: list = None,\n                        start_date: str = None) -> list:\n    \"\"\"Get SEC filings for a company.\n\n    Args:\n        pool: WRDS connection pool\n        cik: CIK number (will be normalized)\n        form_types: List of form types to filter (optional)\n        start_date: Start date for filings (optional)\n\n    Returns:\n        List of filing records\n    \"\"\"\n    # Normalize CIK to 10 digits\n    cik_normalized = str(cik).zfill(10)\n\n    query = \"\"\"\n        SELECT cik, accession_number, form_type, file_date,\n               company_name, sic\n        FROM edgar.filings\n        WHERE cik = %s\n    \"\"\"\n    params = [cik_normalized]\n\n    if form_types:\n        query += \" AND form_type = ANY(%s)\"\n        params.append(form_types)\n\n    if start_date:\n        query += \" AND file_date >= %s\"\n        params.append(start_date)\n\n    query += \" ORDER BY file_date DESC\"\n\n    with pool.cursor() as cursor:\n        cursor.execute(query, tuple(params))\n        return cursor.fetchall()\n```\n\n### Get 10-K and 10-Q Filings\n\n```python\ndef get_periodic_filings(pool, cik: str, years: int = 5) -> list:\n    \"\"\"Get annual and quarterly filings for analysis.\"\"\"\n    cik_normalized = str(cik).zfill(10)\n\n    with pool.cursor() as cursor:\n        cursor.execute(\"\"\"\n            SELECT\n                cik,\n                accession_number,\n                form_type,\n                file_date,\n                fiscal_year,\n                company_name\n            FROM edgar.filings\n            WHERE cik = %s\n              AND form_type IN ('10-K', '10-Q', '10-K/A', '10-Q/A')\n              AND file_date >= CURRENT_DATE - INTERVAL '%s years'\n            ORDER BY file_date DESC\n        \"\"\", (cik_normalized, years))\n\n        return cursor.fetchall()\n```\n\n### Find 8-K Filings by Topic\n\n8-K filings include item numbers indicating the topic:\n\n| Item | Description |\n|------|-------------|\n| 1.01 | Entry into material agreement |\n| 1.02 | Termination of material agreement |\n| 2.01 | Acquisition or disposition of assets |\n| 2.02 | Results of operations (earnings) |\n| 2.03 | Creation of direct financial obligation |\n| 4.01 | Changes in registrant's certifying accountant |\n| 4.02 | Non-reliance on previously issued financials |\n| 5.02 | Departure/election of directors or officers |\n| 5.03 | Amendments to articles/bylaws |\n| 7.01 | Regulation FD disclosure |\n| 8.01 | Other events |\n\n```python\ndef get_8k_filings(pool, cik: str, start_date: str) -> list:\n    \"\"\"Get 8-K filings for a company.\"\"\"\n    cik_normalized = str(cik).zfill(10)\n\n    with pool.cursor() as cursor:\n        cursor.execute(\"\"\"\n            SELECT\n                cik,\n                accession_number,\n                form_type,\n                file_date,\n                accepted,\n                company_name\n            FROM edgar.filings\n            WHERE cik = %s\n              AND form_type IN ('8-K', '8-K/A')\n              AND file_date >= %s\n            ORDER BY file_date DESC\n        \"\"\", (cik_normalized, start_date))\n\n        return cursor.fetchall()\n```\n\n### Industry-Wide Filing Search\n\n```python\ndef get_industry_filings(pool, sic: str, form_type: str,\n                         start_date: str, end_date: str) -> list:\n    \"\"\"Get filings for an entire industry.\"\"\"\n    with pool.cursor() as cursor:\n        cursor.execute(\"\"\"\n            SELECT\n                cik,\n                company_name,\n                accession_number,\n                form_type,\n                file_date\n            FROM edgar.filings\n            WHERE sic = %s\n              AND form_type = %s\n              AND file_date BETWEEN %s AND %s\n            ORDER BY file_date DESC\n        \"\"\", (sic, form_type, start_date, end_date))\n\n        return cursor.fetchall()\n```\n\n## Accessing Filing Documents\n\n### Constructing SEC URLs\n\nEDGAR documents are available at SEC.gov using accession numbers:\n\n```python\ndef get_filing_url(cik: str, accession_number: str) -> str:\n    \"\"\"Construct SEC EDGAR URL for a filing.\n\n    Args:\n        cik: CIK number (will be normalized)\n        accession_number: Filing accession number\n\n    Returns:\n        URL to filing index page\n    \"\"\"\n    # Normalize CIK (remove leading zeros for URL)\n    cik_clean = str(int(cik))\n\n    # Remove dashes from accession number for path\n    accession_clean = accession_number.replace('-', '')\n\n    return (f\"https://www.sec.gov/Archives/edgar/data/\"\n            f\"{cik_clean}/{accession_clean}/\")\n\ndef get_filing_document_url(cik: str, accession_number: str,\n                            document_name: str) -> str:\n    \"\"\"Construct URL for specific document within filing.\"\"\"\n    base_url = get_filing_url(cik, accession_number)\n    return f\"{base_url}{document_name}\"\n```\n\n### Form 4 URLs\n\nForm 4 filings have a special XML viewer format:\n\n```python\ndef get_form4_viewer_url(cik: str, accession_number: str) -> str:\n    \"\"\"Construct SEC Form 4 viewer URL.\n\n    The xslF345X03 stylesheet renders Form 4 in a readable format.\n    \"\"\"\n    cik_clean = str(int(cik))\n    accession_clean = accession_number.replace('-', '')\n\n    return (f\"https://www.sec.gov/Archives/edgar/data/\"\n            f\"{cik_clean}/{accession_clean}/xslF345X03/primarydocument.xml\")\n\ndef get_form4_index_url(cik: str, accession_number: str) -> str:\n    \"\"\"Construct Form 4 filing index URL.\"\"\"\n    cik_clean = str(int(cik))\n    accession_clean = accession_number.replace('-', '')\n\n    return (f\"https://www.sec.gov/Archives/edgar/data/\"\n            f\"{cik_clean}/{accession_clean}/{accession_number}-index.htm\")\n```\n\n### CRITICAL: DCN vs Accession Number\n\n**WRDS `tr_insiders` uses DCN (Document Control Number), NOT SEC accession numbers.**\n\nThe DCN in `tr_insiders.header` is an internal Thomson Reuters identifier that\ndoes NOT work for constructing SEC EDGAR URLs. To get the actual SEC accession\nnumber, query the SEC filings tables:\n\n```python\ndef get_accession_from_dcn(pool, cik: str, filing_date: str) -> str | None:\n    \"\"\"Get SEC accession number for a Form 4 filing.\n\n    WRDS tr_insiders uses DCN, not accession numbers. Use this to find\n    the actual SEC accession number for URL construction.\n    \"\"\"\n    cik_normalized = str(cik).zfill(10)\n\n    with pool.cursor() as cursor:\n        cursor.execute(\"\"\"\n            SELECT accession_number\n            FROM edgar.filings\n            WHERE cik = %s\n              AND form_type = '4'\n              AND file_date = %s\n            ORDER BY accepted DESC\n            LIMIT 1\n        \"\"\", (cik_normalized, filing_date))\n\n        row = cursor.fetchone()\n        return row[0] if row else None\n```\n\nAlternative: Query SEC EDGAR API directly:\n\n```python\nimport requests\n\ndef get_filings_from_sec_api(cik: str) -> dict:\n    \"\"\"Get all filings for a company from SEC EDGAR API.\n\n    Returns JSON with filings.recent.accessionNumber for all filings.\n    \"\"\"\n    cik_padded = str(cik).zfill(10)\n    url = f\"https://data.sec.gov/submissions/CIK{cik_padded}.json\"\n\n    response = requests.get(\n        url,\n        headers={'User-Agent': 'Academic Research your@email.edu'},\n        timeout=30\n    )\n    response.raise_for_status()\n    return response.json()\n```\n\n### Download Filing via WRDS\n\nFor bulk downloads, use WRDS file access:\n\n```python\nimport subprocess\nfrom pathlib import Path\n\ndef download_filing_from_wrds(accession_number: str,\n                               local_dir: Path) -> Path | None:\n    \"\"\"Download filing from WRDS archive.\n\n    Note: Requires WRDS SFTP access configured via rclone.\n    \"\"\"\n    # WRDS stores filings by year/quarter\n    # Path structure: /wrds/sec/edgar/filings/YYYY/QTR/\n\n    local_dir = Path(local_dir)\n    local_dir.mkdir(parents=True, exist_ok=True)\n\n    # Try rclone first\n    try:\n        result = subprocess.run(\n            ['rclone', 'ls', f'wrds:/wrds/sec/edgar/'],\n            capture_output=True, text=True, timeout=30\n        )\n        if result.returncode == 0:\n            # Search for the accession number\n            # Implementation depends on WRDS file structure\n            pass\n    except Exception:\n        pass\n\n    return None\n```\n\n## Linking CIK to Other Identifiers\n\n### CIK to Compustat GVKEY\n\n```python\ndef cik_to_gvkey(pool, cik: str) -> str | None:\n    \"\"\"Convert SEC CIK to Compustat GVKEY.\"\"\"\n    cik_normalized = str(cik).zfill(10)\n\n    with pool.cursor() as cursor:\n        cursor.execute(\"\"\"\n            SELECT gvkey\n            FROM comp.company\n            WHERE cik = %s\n            LIMIT 1\n        \"\"\", (cik_normalized,))\n\n        row = cursor.fetchone()\n        return row[0] if row else None\n```\n\n### Fuzzy Company Matching\n\nWhen CIK is not available, use fuzzy matching:\n\n```python\nfrom difflib import SequenceMatcher\n\ndef find_company_by_name(pool, company_name: str,\n                         threshold: float = 0.7) -> list:\n    \"\"\"Find companies by name with fuzzy matching.\n\n    Returns list of (cik, company_name, similarity_score) tuples.\n    \"\"\"\n    # Get candidate companies (limit search space)\n    name_upper = company_name.upper()\n    first_word = name_upper.split()[0]\n\n    with pool.cursor() as cursor:\n        cursor.execute(\"\"\"\n            SELECT DISTINCT cik, company_name\n            FROM edgar.filings\n            WHERE UPPER(company_name) LIKE %s\n            LIMIT 100\n        \"\"\", (f'{first_word}%',))\n\n        candidates = cursor.fetchall()\n\n    # Score each candidate\n    matches = []\n    for cik, db_name in candidates:\n        score = SequenceMatcher(None, name_upper, db_name.upper()).ratio()\n        if score >= threshold:\n            matches.append((cik, db_name, score))\n\n    # Sort by score descending\n    matches.sort(key=lambda x: x[2], reverse=True)\n\n    return matches\n```\n\n## Filing Counts and Statistics\n\n```python\ndef get_filing_statistics(pool, cik: str) -> dict:\n    \"\"\"Get filing statistics for a company.\"\"\"\n    cik_normalized = str(cik).zfill(10)\n\n    with pool.cursor() as cursor:\n        cursor.execute(\"\"\"\n            SELECT\n                form_type,\n                COUNT(*) as count,\n                MIN(file_date) as earliest,\n                MAX(file_date) as latest\n            FROM edgar.filings\n            WHERE cik = %s\n            GROUP BY form_type\n            ORDER BY count DESC\n        \"\"\", (cik_normalized,))\n\n        results = cursor.fetchall()\n\n        return {\n            row[0]: {\n                'count': row[1],\n                'earliest': row[2],\n                'latest': row[3]\n            }\n            for row in results\n        }\n```\n\n## Working with Filing Content\n\nWRDS EDGAR data focuses on metadata. For actual filing content:\n\n1. **Use SEC EDGAR directly**: Download from SEC.gov URLs\n2. **Use WRDS file archive**: Access via rclone/SFTP\n3. **Consider edgar-online**: For parsed/structured data\n\n### Parsing 10-K Sections\n\n```python\nimport re\nimport requests\n\ndef download_10k_text(cik: str, accession_number: str) -> str | None:\n    \"\"\"Download 10-K full text from SEC.\"\"\"\n    # Get filing index to find the main document\n    base_url = get_filing_url(cik, accession_number)\n\n    # Try common document names\n    doc_names = [\n        f'{accession_number}.txt',\n        'complete-submission.txt',\n    ]\n\n    for doc_name in doc_names:\n        url = f'{base_url}{doc_name}'\n        response = requests.get(url, timeout=30)\n        if response.status_code == 200:\n            return response.text\n\n    return None\n\ndef extract_10k_section(text: str, section: str) -> str | None:\n    \"\"\"Extract specific section from 10-K text.\n\n    Common sections:\n    - Item 1: Business\n    - Item 1A: Risk Factors\n    - Item 7: MD&A\n    - Item 7A: Market Risk\n    - Item 8: Financial Statements\n    \"\"\"\n    # Section patterns (simplified)\n    patterns = {\n        'Item 1': r'Item\\s+1\\.?\\s+Business(.*?)Item\\s+1A',\n        'Item 1A': r'Item\\s+1A\\.?\\s+Risk\\s+Factors(.*?)Item\\s+1B',\n        'Item 7': r'Item\\s+7\\.?\\s+Management.*?Discussion(.*?)Item\\s+7A',\n        'Item 8': r'Item\\s+8\\.?\\s+Financial\\s+Statements(.*?)Item\\s+9',\n    }\n\n    if section not in patterns:\n        return None\n\n    match = re.search(patterns[section], text, re.IGNORECASE | re.DOTALL)\n    return match.group(1).strip() if match else None\n```\n\n## Best Practices\n\n1. **Always normalize CIK** to 10 digits with leading zeros\n2. **Use form_type arrays** with `ANY(%s)` for multiple types\n3. **Include date filters** to limit result sets\n4. **Cache filing metadata** locally for repeated analysis\n5. **Respect SEC rate limits** when downloading documents (10 requests/second)\n6. **Use WRDS file access** for bulk downloads when available\n\n## Rate Limiting for SEC Access\n\n```python\nimport time\nfrom functools import wraps\n\ndef rate_limit(calls_per_second: int = 10):\n    \"\"\"Decorator to rate-limit SEC API calls.\"\"\"\n    min_interval = 1.0 / calls_per_second\n    last_call = [0.0]\n\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            elapsed = time.time() - last_call[0]\n            if elapsed < min_interval:\n                time.sleep(min_interval - elapsed)\n            last_call[0] = time.time()\n            return func(*args, **kwargs)\n        return wrapper\n    return decorator\n\n@rate_limit(calls_per_second=10)\ndef fetch_filing_from_sec(url: str) -> str:\n    \"\"\"Rate-limited fetch from SEC EDGAR.\"\"\"\n    response = requests.get(\n        url,\n        headers={'User-Agent': 'YourName your@email.com'},\n        timeout=30\n    )\n    response.raise_for_status()\n    return response.text\n```\n",
        "skills/wrds/references/insider-form4.md": "# Thomson Reuters Form 4 Insider Data\n\n## Contents\n\n- [Tables](#tables)\n- [Key Fields](#key-fields)\n- [Rolecode Reference](#rolecode-reference)\n- [Transaction Codes](#transaction-codes)\n- [Query Patterns](#query-patterns)\n- [Common Gotchas](#common-gotchas)\n\n## Tables\n\n| Table | Description |\n|-------|-------------|\n| `tr_insiders.table1` | Form 4 transactions (trades) |\n| `tr_insiders.table2` | Derivative holdings |\n| `tr_insiders.header` | Insider identity and role codes |\n| `tr_insiders.company` | Company identifiers |\n| `tr_insiders.form144` | Form 144 filings |\n\n## Key Fields\n\n### table1 (Transactions)\n- `ticker` - Stock ticker\n- `dcn` - Document control number (links to header)\n- `personid` - Person identifier (links to header)\n- `fdate` - Filing date\n- `trandate` - Transaction date\n- `trancode` - Transaction code (S=Sale, P=Purchase, etc.)\n- `acqdisp` - A=Acquisition, D=Disposition\n- `shares` - Number of shares\n- `tprice` - Transaction price per share\n- `sharesheld` - Shares held after transaction\n- `ownership` - D=Direct, I=Indirect\n\n### header (Insider Info)\n- `dcn` - Document control number\n- `personid` - Person identifier\n- `owner` - Insider name\n- `rolecode1`, `rolecode2`, `rolecode3` - Role codes\n\n## Rolecode Reference\n\n### C-Suite Executives\n| Code | Role |\n|------|------|\n| CEO | Chief Executive Officer |\n| CFO | Chief Financial Officer |\n| COO | Chief Operating Officer |\n| CT | Chief Technology Officer |\n| GC | General Counsel |\n| P | President |\n| CI | Chief Investment Officer |\n| CO | Chief Operating Officer |\n\n### Senior Officers\n| Code | Role |\n|------|------|\n| EVP | Executive Vice President |\n| SVP | Senior Vice President |\n| OE | Other Executive Officer |\n| OS | Other Senior Officer |\n\n### Directors\n| Code | Role |\n|------|------|\n| D | Director |\n| CB | Chairman of the Board |\n| VC | Vice Chairman |\n| OD | Officer and Director |\n| DO | Director and Officer |\n\n### Other\n| Code | Role |\n|------|------|\n| O | Officer |\n| C | Controller |\n| F | Financial Officer |\n| FO | Financial Officer |\n| S | Secretary |\n| B | 10% Beneficial Owner |\n| H | 10% Holder |\n\n## Transaction Codes\n\n| Code | Description |\n|------|-------------|\n| S | Open market sale |\n| P | Open market purchase |\n| D | Disposition (non-open market) |\n| A | Grant/award |\n| G | Gift |\n| F | Tax payment (shares withheld) |\n| M | Exercise of derivative |\n| C | Conversion |\n| J | Other acquisition |\n| K | Equity swap |\n\n## Query Patterns\n\n### Executive Stock Disposals\n```python\nsql = \"\"\"\n    SELECT DISTINCT\n        t.ticker,\n        t.fdate as filing_date,\n        t.trandate as transaction_date,\n        h.owner as insider_name,\n        CASE\n            WHEN h.rolecode1 IN ('CEO', 'CFO', 'COO', 'CT', 'GC', 'P')\n                 OR h.rolecode2 IN ('CEO', 'CFO', 'COO', 'CT', 'GC', 'P')\n            THEN 'Executive Officer'\n            WHEN h.rolecode1 IN ('EVP', 'SVP', 'OE', 'OS')\n                 OR h.rolecode2 IN ('EVP', 'SVP', 'OE', 'OS')\n            THEN 'Senior Officer'\n            WHEN h.rolecode1 IN ('D', 'CB', 'VC')\n                 OR h.rolecode2 IN ('D', 'CB', 'VC')\n            THEN 'Director'\n            ELSE 'Other'\n        END as insider_role,\n        t.trancode,\n        t.acqdisp,\n        t.shares as trans_shares,\n        t.tprice as price_per_share,\n        t.sharesheld as shares_held_after\n    FROM tr_insiders.table1 t\n    LEFT JOIN tr_insiders.header h\n        ON t.dcn = h.dcn AND t.personid = h.personid\n    WHERE t.ticker = 'AAPL'\n      AND t.trandate BETWEEN '2020-01-01' AND '2023-12-31'\n      AND t.acqdisp = 'D'\n      AND t.trancode IN ('S', 'D', 'G', 'F')\n      AND t.shares IS NOT NULL\n    ORDER BY t.trandate DESC\n\"\"\"\n```\n\n### All Insider Activity for Company\n```python\nsql = \"\"\"\n    SELECT\n        t.ticker,\n        t.trandate,\n        h.owner,\n        t.trancode,\n        t.acqdisp,\n        t.shares,\n        t.tprice,\n        t.shares * t.tprice as transaction_value\n    FROM tr_insiders.table1 t\n    LEFT JOIN tr_insiders.header h\n        ON t.dcn = h.dcn AND t.personid = h.personid\n    WHERE t.ticker = %s\n      AND t.trandate >= %s\n      AND t.shares IS NOT NULL\n    ORDER BY t.trandate DESC\n\"\"\"\n```\n\n### Filter for Executives Only\n```python\nexecutive_roles = (\n    'CEO', 'CFO', 'COO', 'CT', 'GC', 'P', 'CI', 'CO',\n    'EVP', 'SVP', 'OE', 'OS'\n)\n\nsql = f\"\"\"\n    SELECT *\n    FROM tr_insiders.table1 t\n    JOIN tr_insiders.header h ON t.dcn = h.dcn AND t.personid = h.personid\n    WHERE (h.rolecode1 IN {executive_roles}\n           OR h.rolecode2 IN {executive_roles}\n           OR h.rolecode3 IN {executive_roles})\n\"\"\"\n```\n\n## Common Gotchas\n\n1. **Multiple rolecodes** - Check all three rolecode fields (rolecode1, rolecode2, rolecode3)\n2. **Null shares** - Filter `WHERE shares IS NOT NULL AND shares != 0`\n3. **Transaction value** - Calculate as `shares * tprice`\n4. **Direct vs Indirect** - `ownership = 'D'` for direct holdings only\n5. **Join keys** - Use both `dcn` AND `personid` when joining table1 to header\n",
        "skills/wrds/references/iss-compensation.md": "# ISS Incentive Lab Compensation Data\n\n## Contents\n\n- [Tables](#tables)\n- [Key Fields](#key-fields)\n- [Query Patterns](#query-patterns)\n- [Related: Compustat ExecuComp](#related-compustat-execucomp)\n- [Related: Capital IQ Compensation](#related-capital-iq-compensation)\n- [Common Use Cases](#common-use-cases)\n\n## Tables\n\n| Table | Description |\n|-------|-------------|\n| `iss_incentive_lab.comppeer` | Peer company designations |\n| `iss_incentive_lab.sumcomp` | Summary compensation |\n| `iss_incentive_lab.participantfy` | Participant fiscal year data |\n\n## Key Fields\n\n### comppeer (Peer Companies)\n- `ticker` - Company ticker\n- `companyname` - Company name\n- `fiscalyear` - Fiscal year\n- `peerticker` - Peer company ticker\n- `peername` - Peer company name\n- `peercik` - Peer company CIK\n\n### sumcomp (Summary Compensation)\n- `ticker` - Company ticker\n- `fiscalyear` - Fiscal year\n- `execid` - Executive identifier\n- `salary` - Base salary\n- `bonus` - Cash bonus\n- `stock_awards` - Stock award value\n- `option_awards` - Option award value\n- `total_comp` - Total compensation\n\n## Query Patterns\n\n### Get Peer Companies\n```python\nsql = \"\"\"\n    SELECT\n        fiscalyear,\n        ticker,\n        companyname,\n        peerticker,\n        peername,\n        peercik\n    FROM iss_incentive_lab.comppeer\n    WHERE ticker = 'SIVB'\n      AND fiscalyear IN (2020, 2021, 2022)\n    ORDER BY fiscalyear, peername\n\"\"\"\npeers = pd.read_sql(sql, conn)\n```\n\n### Summary Compensation\n```python\nsql = \"\"\"\n    SELECT *\n    FROM iss_incentive_lab.sumcomp\n    WHERE ticker = 'AAPL'\n      AND fiscalyear >= 2020\n    ORDER BY fiscalyear DESC\n\"\"\"\n```\n\n### Peer Group Analysis\n```python\n# Get all peers for a company, then query their compensation\npeers_sql = \"\"\"\n    SELECT DISTINCT peerticker\n    FROM iss_incentive_lab.comppeer\n    WHERE ticker = %s\n      AND fiscalyear = %s\n\"\"\"\npeers = pd.read_sql(peers_sql, conn, params=(ticker, year))\npeer_tickers = tuple(peers['peerticker'].tolist())\n\n# Get compensation for all peers\ncomp_sql = \"\"\"\n    SELECT *\n    FROM iss_incentive_lab.sumcomp\n    WHERE ticker = ANY(%s)\n      AND fiscalyear = %s\n\"\"\"\npeer_comp = pd.read_sql(comp_sql, conn, params=(list(peer_tickers), year))\n```\n\n## Related: Compustat ExecuComp\n\nFor additional executive compensation data, use Compustat ExecuComp:\n\n```python\nsql = \"\"\"\n    SELECT\n        gvkey, ticker, year,\n        co_per_rol, exec_fullname,\n        titleann, ceoann, cfoann,\n        tdc1 as total_compensation,\n        salary, bonus, stock_awards, option_awards\n    FROM comp_execucomp.anncomp\n    WHERE ticker IN ('IBM', 'MSFT', 'AAPL')\n      AND ceoann = 'CEO'\n      AND year >= 2020\n    ORDER BY ticker, year\n\"\"\"\n```\n\n### ExecuComp Tables\n| Table | Description |\n|-------|-------------|\n| `comp_execucomp.anncomp` | Annual compensation |\n| `comp.planbasedawards` | Stock/option grants (FAS 123R) |\n| `comp.outstandingawards` | Outstanding awards |\n\n## Related: Capital IQ Compensation\n\n```python\nsql = \"\"\"\n    SELECT *\n    FROM ciq.wrds_compensation\n    WHERE companyname ILIKE '%Apple%'\n    LIMIT 100\n\"\"\"\n```\n\n## Common Use Cases\n\n### CEO Pay Trends\n```python\nsql = \"\"\"\n    SELECT\n        ticker,\n        fiscalyear,\n        SUM(total_comp) as ceo_total_comp\n    FROM iss_incentive_lab.sumcomp\n    WHERE ticker = %s\n      AND title ILIKE '%CEO%'\n    GROUP BY ticker, fiscalyear\n    ORDER BY fiscalyear\n\"\"\"\n```\n\n### Peer Comparison\n```python\n# 1. Get peer group\n# 2. Query compensation for focal company and peers\n# 3. Calculate percentile ranking\n```\n",
        "skills/writing-brainstorm/SKILL.md": "---\nname: writing-brainstorm\ndescription: This skill should be used when the user asks to \"find something to write about\", \"brainstorm topics\", \"what should I write about\", \"find writing ideas\", \"gather sources for\", \"pull references on\", or needs help discovering topics from their reading highlights. Leverages Readwise MCP to surface patterns and gather references.\n---\n\n# Writing Brainstorm\n\nGenerate writing topics and gather references from Readwise highlights.\n\n## When to Use\n\nInvoke this skill for:\n- Discovering what to write about from reading patterns\n- Gathering sources and references for a known topic\n- Finding thematic connections across highlights\n- Building an outline with supporting quotes\n\n## Prerequisites\n\nThis skill requires the Readwise MCP server. The plugin auto-configures it, but the `READWISE_TOKEN` environment variable must be set.\n\n**Setup (if MCP not working):**\n1. Get API token from https://readwise.io/access_token\n2. Set environment variable: `export READWISE_TOKEN=your_token`\n3. Verify: `claude mcp list` should show `readwise`\n\n## Critical: Sub-Agent Pattern for Readwise Searches\n\n**NEVER call `search_readwise_highlights` directly from the main chat.** Raw search results return 50-100+ highlights, polluting context and degrading conversation quality.\n\n**ALWAYS use parallel sub-agents** (one per search theme) to:\n1. Execute the search\n2. Filter and deduplicate results\n3. Return a condensed summary\n\n### Sub-Agent Pattern\n\nFor a topic with N distinct themes, launch N parallel sub-agents using the Task tool:\n\n```\nTask(\n  subagent_type=\"general-purpose\",\n  model=\"haiku\",  # Fast and cheap for filtering\n  prompt=\"\"\"Search Readwise for highlights about **[THEME]**.\n\nUse `mcp__readwise__search_readwise_highlights` with:\n- vector_search_term: \"[semantic search terms]\"\n- full_text_queries: [{\"field_name\": \"highlight_plaintext\", \"search_term\": \"[keyword]\"}]\n\nReturn ONLY:\n- Top 3 most relevant sources (title, author)\n- Top 3 quotes worth citing (with source attribution)\n- 1-2 sentence theme summary\"\"\"\n)\n```\n\n### Example: Law Review on Private Equity Access\n\nLaunch 5 parallel agents:\n1. \"private equity retail investors democratization\"\n2. \"accredited investor definition regulation\"\n3. \"401k retirement private markets\"\n4. \"interval fund tender offer evergreen\"\n5. \"investor protection paternalism securities\"\n\nEach returns ~100 words instead of ~5000 words of raw highlights.\n\n---\n\n## Two Modes\n\n### Discovery Mode\n\nWhen user wants to find topics (\"what should I write about?\"):\n\n1. **Fetch tag landscape**\n   - Use `get_tags` to see all topic clusters\n   - Present tags grouped by frequency/recency\n\n2. **Analyze recent reading**\n   - Use `get_recent_content` to fetch recent highlights\n   - Identify recurring themes, authors, or concepts\n\n3. **Semantic pattern detection**\n   - Examine highlights for cross-cutting themes\n   - Look for: tensions, debates, unanswered questions, surprising connections\n\n4. **Present topic candidates**\n   - For each potential topic, show:\n     - Theme description\n     - Supporting highlights (2-3 examples)\n     - Relevant tags\n     - Potential angle or thesis\n\n### Gathering Mode (Progressive Workflow)\n\nWhen user has a topic (\"gather sources on X\"), follow this **human-in-the-loop** workflow:\n\n#### Phase 1: Clarify Intent\n\n**BEFORE any search**, use `AskUserQuestion` to understand:\n\n```\nAskUserQuestion(questions=[\n  {\n    \"question\": \"What's your primary angle or thesis for this piece?\",\n    \"header\": \"Angle\",\n    \"options\": [\n      {\"label\": \"Critique existing framework\", \"description\": \"Argue current approach is flawed\"},\n      {\"label\": \"Propose reform\", \"description\": \"Offer specific policy changes\"},\n      {\"label\": \"Comparative analysis\", \"description\": \"Compare approaches across jurisdictions\"},\n      {\"label\": \"Empirical analysis\", \"description\": \"Present data-driven findings\"}\n    ],\n    \"multiSelect\": false\n  },\n  {\n    \"question\": \"Who is your target audience?\",\n    \"header\": \"Audience\",\n    \"options\": [\n      {\"label\": \"Law review\", \"description\": \"Academic legal audience\"},\n      {\"label\": \"Practitioners\", \"description\": \"Lawyers, regulators, compliance\"},\n      {\"label\": \"Policy makers\", \"description\": \"Legislators, agency staff\"},\n      {\"label\": \"General educated\", \"description\": \"Informed non-specialists\"}\n    ],\n    \"multiSelect\": false\n  }\n])\n```\n\n#### Phase 2: Search Sources\n\n1. **Decompose into themes** based on clarified intent\n   - Break the topic into 3-6 distinct search themes\n   - Each theme becomes a parallel sub-agent search\n\n2. **Launch parallel sub-agents**\n   - Use the Task tool with `model=\"haiku\"` for each theme\n   - Run all searches in a single message (parallel execution)\n   - See \"Sub-Agent Pattern\" section above\n\n3. **Synthesize results**\n   - Deduplicate sources across agent responses\n   - Identify the strongest quotes from each theme\n   - Note gaps (themes with few/no highlights)\n\n#### Phase 3: Draft Outline → `OUTLINE.md`\n\nSave the outline to a file for iteration:\n\n```markdown\n# OUTLINE.md\n\n## Working Title\n[Title]\n\n## Thesis\n[One-sentence claim]\n\n## Target Audience\n[From Phase 1]\n\n## Structure\n### I. Introduction\n### II. [Section]\n### III. [Section]\n...\n\n## Key Sources\n[Deduplicated from Phase 2]\n\n## Open Questions\n[Gaps to address]\n```\n\n**Ask for feedback** on the outline before proceeding.\n\n#### Phase 4: Section Deep-Dive\n\nFor each major section, use `AskUserQuestion` to refine:\n\n```\nAskUserQuestion(questions=[\n  {\n    \"question\": \"For Section II (Background), what level of detail do you need?\",\n    \"header\": \"Depth\",\n    \"options\": [\n      {\"label\": \"Brief context\", \"description\": \"1-2 paragraphs, assume reader familiarity\"},\n      {\"label\": \"Full background\", \"description\": \"Comprehensive treatment for general reader\"},\n      {\"label\": \"Synthesis only\", \"description\": \"Synthesize precedents without detailed summaries\"}\n    ],\n    \"multiSelect\": false\n  }\n])\n```\n\nCreate `SECTION-II-OUTLINE.md` with:\n- Section thesis/purpose\n- Key arguments in order\n- Supporting sources mapped to arguments\n- Anticipated counterarguments\n\nRepeat for each section, getting human feedback before moving to prose.\n\n## Output Format\n\nProduce a markdown outline:\n\n```markdown\n# [Topic Title]\n\n## Thesis/Angle\n[One-sentence framing]\n\n## Key Sources\n- **[Source 1]** by [Author]\n  - \"[Highlight quote]\"\n  - Relevant to: [subtopic]\n\n## Outline\n### [Subtopic 1]\n- Point A (Source 1, Source 3)\n- Point B (Source 2)\n\n### [Subtopic 2]\n...\n\n## Open Questions\n- [Questions highlights don't answer]\n\n## Next Steps\n- Suggested writing skill: /writing-[domain]\n```\n\n## Domain Detection\n\nAfter gathering sources, detect the topic domain and suggest the appropriate writing skill:\n\n| Domain Indicators | Suggested Skill |\n|-------------------|-----------------|\n| Legal cases, statutes, law reviews, constitutional | `/writing-legal` (Volokh) |\n| Economics, markets, policy, data, empirical | `/writing-econ` (McCloskey) |\n| General/other | `/writing` (Strunk & White) |\n\n## Readwise MCP Tools\n\nPrimary tools for brainstorming:\n\n| Tool | Use Case | Direct Call OK? |\n|------|----------|-----------------|\n| `get_tags` | Survey topic landscape | ✅ Yes |\n| `get_recent_content` | See current reading themes | ✅ Yes |\n| `search_readwise_highlights` | Find highlights by keyword | ❌ **Sub-agent only** |\n| `get_highlights` | Retrieve with filters | ⚠️ Use caution (can be large) |\n| `get_books` | Browse source library | ✅ Yes |\n\n**Why sub-agents for search?** A single search can return 50-100 highlights (~5000+ tokens). Multiple searches compound this. Sub-agents filter to essentials before returning to main context.\n\n## File Output Convention\n\nSave brainstorming artifacts to the project's `docs/` or `scratch/` directory:\n\n```\nproject/\n├── docs/\n│   └── writing/\n│       ├── OUTLINE.md              # Main article outline\n│       ├── SECTION-I-OUTLINE.md    # Introduction details\n│       ├── SECTION-II-OUTLINE.md   # Background details\n│       └── ...\n└── scratch/\n    └── brainstorm-notes.md         # Working notes (gitignored)\n```\n\n## Workflow Examples\n\n### Discovery Mode Example\n\n**User:** \"I want to write something but don't know what\"\n\n**Process:**\n1. Fetch tags → find clusters like \"antitrust\", \"market-power\", \"regulation\"\n2. Get recent highlights → notice many from economics sources\n3. Analyze → tension between \"consumer welfare\" and \"market structure\" keeps appearing\n4. Present → \"Potential topic: The consumer welfare standard debate. You have 12 highlights across 4 sources discussing this tension. Angle: Why market structure matters beyond prices.\"\n5. Domain detection → Economics sources detected → \"Use `/writing-econ` for drafting\"\n\n### Gathering Mode Example (Progressive)\n\n**User:** \"Let's brainstorm a law review article about retail access to private equity\"\n\n**Process:**\n1. **Clarify** → AskUserQuestion: angle (critique/reform/comparative), audience (law review/practitioners)\n2. **User responds** → \"Critique existing framework, law review audience\"\n3. **Decompose** → 5 themes: PE retail access, accredited investor, 401(k) access, fund structures, investor protection\n4. **Search** → Launch 5 parallel Haiku sub-agents\n5. **Synthesize** → Dedupe sources, extract best quotes, note gaps\n6. **Save** → Write `docs/writing/OUTLINE.md`\n7. **Feedback** → \"Here's the outline. Any sections to add/remove/reorder?\"\n8. **User responds** → \"Add comparative section on EU ELTIF\"\n9. **Deep-dive** → AskUserQuestion per section, create `SECTION-II-OUTLINE.md`\n10. **Handoff** → \"Outline complete. Use `/writing-legal` to draft.\"\n\n## Integration\n\nAfter brainstorming:\n- `/writing` - General prose drafting\n- `/writing-econ` - Economics/finance articles\n- `/writing-legal` - Law review articles\n- `/ai-anti-patterns` - Check for AI writing indicators\n",
        "skills/writing-econ/SKILL.md": "---\nname: writing-econ\ndescription: This skill should be used when the user asks to \"write an economics paper\", \"draft a working paper\", \"edit finance writing\", \"review my econ paper\", \"write for a journal\", or needs guidance on economics and finance writing. Based on McCloskey's \"Economical Writing\" with discipline-specific word lists and examples.\n---\n\n# Economics and Finance Writing\n\nStyle guide for economics journal articles, working papers, and finance analysis based on Deirdre McCloskey's *Economical Writing*.\n\n## When to Use\n\nInvoke this skill for:\n- Economics journal articles and working papers\n- Finance analysis and market commentary\n- Policy briefs and economic reports\n- Editing economics/finance prose for clarity\n\n**For general writing**: Use `/writing` skill (Strunk & White)\n**For legal writing**: Use `/writing-legal` skill (Volokh)\n\n## Enforcement\n\n### IRON LAW #1: NO BOILERPLATE WITHOUT DELETE & RESTART\n\nIf you write ANY of these, DELETE the draft and START OVER:\n- \"This paper discusses...\"\n- Table-of-contents paragraph\n- \"As we shall see\"\n- \"It is interesting to note that...\"\n- \"The rest of this paper is organized as follows...\"\n\nThese signal you haven't found your hook. Start fresh with a compelling finding.\n\n### IRON LAW #2: NO ELEGANT VARIATION\n\nOne concept = One word. If you catch yourself varying terms (\"industrialization\" / \"development\" / \"growth\") for the same concept, you are confusing the reader. Pick ONE term and use it consistently.\n\n### Rationalization Table - STOP If You Think:\n\n| Excuse | Reality | Do Instead |\n|--------|---------|------------|\n| \"But journals use boilerplate\" | Bad journals do | HOOK reader with finding |\n| \"Elegant variation shows vocabulary\" | Shows you don't know what you mean | USE same word for same thing |\n| \"Readers need roadmap paragraph\" | They skip it | DELETE table-of-contents para |\n| \"This terminology is standard in field\" | Doesn't make it good | USE concrete Anglo-Saxon words |\n| \"Need to sound academic\" | Sounds pompous instead | WRITE like human being |\n| \"Passive voice sounds objective\" | Sounds evasive | USE active voice |\n| \"Technical writing must be formal\" | Technical ≠ turgid | BE clear AND technical |\n\n### Red Flags - STOP Immediately If You Think:\n\n- \"Let me write a standard introduction\" → NO. Find your hook first.\n- \"I'll improve this later\" → NO. Fix boilerplate NOW or restart.\n- \"This varies the language nicely\" → NO. Consistency > variation.\n- \"Readers expect this phrase\" → NO. Expectations can be wrong.\n\n### Delete & Restart Pattern\n\n**When to delete and restart:**\n\n1. **Boilerplate detected in first paragraph** → Delete entire intro, write finding-first\n2. **Three different terms for same concept** → Delete section, pick ONE term\n3. **Table-of-contents paragraph exists** → Delete it, no replacement needed\n4. **Metric conversions every time** → Delete all but first, trust reader\n\n**How to restart:**\n\n```\nOld: \"This paper discusses the relationship between X and Y...\"\nNew: \"Trade liberalization increased wages by 15% for skilled workers.\"\n```\n\nRestart with THE FINDING, not with throat-clearing.\n\n## Core Principles\n\n### Speak to One Reader\n\nChoose an implied reader and stick with her. A skeptical but sympathetic colleague. Keep the prose at one level of difficulty. If it embarrasses you to imagine how she would read it, the stuff is embarrassing.\n\n### Avoid Boilerplate\n\n| Anti-Pattern | Why It Fails |\n|--------------|--------------|\n| \"This paper discusses...\" | Bores the reader; use a hook instead |\n| Table-of-contents paragraph | Readers skip it; they can't understand until they've read the paper |\n| Background/padding | If you discovered it was beside the point, don't include it |\n| \"As we shall see\" | Useless anticipation; the reader will see soon enough |\n| Metric conversions every time | Shows you think the reader is an ignoramus |\n\nNever repeat without apologizing (\"as I said earlier\"). If apologizing too much, you're repeating too much.\n\n### Control Tone\n\n- Avoid invective: \"This is pure nonsense\" arouses suspicion the argument is weak\n- Delete every \"very\" and \"absolutely\" - most things aren't\n- Use wit to compensate for strong opinions\n- Relax the pose of The Scientist; write like a human being\n\n### One Point Per Paragraph\n\nEnd each paragraph with a simple, street-talk encapsulation. The paragraph can be technical as long as the last sentence comes down a notch. It makes the paragraph sing.\n\n### Make Tables Self-Explanatory\n\nThe reader should understand the table without the main text. Use words in headings, not acronyms. \"Logarithm of Domestic Price\" not \"LPDOM\". Follow Tufte: no chart junk, have a point.\n\nUse meaningful labels in equations: \"Quantity of Grain = 3.56 + 5.6(Price of Grain)\" not \"Q = 3.56 + 5.6P where Q is...\"\n\n### Make Writing Cohere\n\nRepeat key words to link sentences. (AB)(BC)(CD) is easy to understand. The figure is called polyptoton. English achieves coherence by repetition, not by \"not only...but also\" which marks you as incompetent.\n\n## Word Choice\n\n### Avoid Elegant Variation\n\nUse one word to mean one thing. A paper used: \"industrialization,\" \"growing structural differentiation,\" \"economic and social development,\" \"development,\" \"economic growth,\" \"growth,\" and \"revolutionized means of production\" to mean the same thing. Don't.\n\nWhen uncertain, look back and use the same word.\n\n### Key Principles\n\n| Principle | Example |\n|-----------|---------|\n| Be concrete | \"sheep and wheat\" not \"natural resource-oriented exports\" |\n| Untie Teutonisms | \"equalization of the prices of factors\" not \"factor price equalization\" |\n| Avoid ersatz economics | Never use \"skyrocketing,\" \"fair prices,\" \"vicious cycle,\" \"exploit\" |\n| Avoid this-ism | Replace *this*, *these*, *those* with *the* |\n\nSee `references/economical-writing-full.md` for extended bad words list, Teutonism examples, and ersatz economics vocabulary.\n\n## Quick Reference\n\n| Problem | Solution |\n|---------|----------|\n| \"This paper discusses X\" | Hook the reader with the finding |\n| Table-of-contents paragraph | Delete it; readers skip it anyway |\n| \"As we shall see\" | Delete; anticipation is useless |\n| Elegant variation | Use the same word for the same thing |\n| Five-dollar words | Anglo-Saxon roots are more concrete |\n| Noun pile-ups | Untie with \"of\" |\n| This/that/these/those | Replace with \"the\" |\n| \"Not only...but also\" | Just use \"and\" |\n\n## Progressive Disclosure\n\nFor comprehensive guidance, consult:\n\n### Reference File\n\n- **`references/economical-writing-full.md`** - Complete McCloskey guide covering:\n  - 35 rules with full explanations and examples\n  - Extended bad words list with usage notes\n  - Historical and etymological context\n\n### When to Load Reference\n\nLoad the full reference when:\n- Encountering specific vocabulary questions\n- Needing detailed examples for economics jargon\n- Working on substantial manuscript revision\n- Teaching economics writing\n\n## Integration\n\nAfter completing any economics writing task, invoke `/ai-anti-patterns` to check for AI writing indicators. The `/writing` skill covers general prose principles (active voice, omit needless words) that complement this skill.\n",
        "skills/writing-econ/references/economical-writing-full.md": "# Economical Writing - Extended Reference\n\nBased on Deirdre McCloskey's *Economical Writing* (3rd edition, University of Chicago Press).\n\n## Extended Bad Words List\n\n### Vague Nouns with Alternatives\n\n| Avoid | Use Instead | Notes |\n|-------|-------------|-------|\n| concept | idea, notion, thought | Latinate, front-parlor |\n| data | facts, statistics, observations | Plural; means \"givens\" in Latin |\n| function | role | When meaning \"role\" |\n| situation | position, condition | Choose based on meaning |\n| individuals | people | Plain is better |\n| agents | people | The same |\n| structure | (often nothing) | Usually meaningless |\n| process | (delete with \"the\") | \"transition process\" → \"transition\" |\n| the existence of X | X | Just name it |\n| time frame | time | Engineering jargon |\n| the turn of the nineteenth century | 1800 (or 1900) | Forces reader to puzzle |\n\n### Pretentious Verbs to Avoid\n\n| Avoid | Use Instead | Notes |\n|-------|-------------|-------|\n| critique | criticize, comment on | Elegant variation |\n| implement | (Washingtonese) | Bureaucratic |\n| comprise | include, consist of | Fancy talk |\n| analyze | discuss, examine | Overused; means \"cut to pieces\" |\n| hypothesize | suppose, expect | Marks you as barbarian |\n| finalize | finish, complete | Boardroom talk |\n| state | say, assert, argue | Overused for mere \"say\" |\n| try and | try to | US marker of incompetence |\n\n### Pointless Modifiers\n\n| Avoid | Problem |\n|-------|---------|\n| former/latter | Requires looking back |\n| the above, the preceding | Same problem |\n| aforementioned | Legal-document style |\n| intra/inter | Use within/between |\n| interesting | Weak; sarcastic associations |\n| kind of, sort of, type of | Vague |\n| fortunately, interestingly | Cheap opinion injection |\n| respectively | Distribute numbers directly |\n| very | Most things aren't very |\n| for convenience | All writing should be convenient |\n\n### Traffic Signal Words\n\n| Avoid | Problem |\n|-------|---------|\n| due to | Mysterious avoidance of \"because\" |\n| in terms of | Same as \"due to\" |\n| thus, hence | Use sparingly |\n| plus (as \"and\") | Wait a century |\n\n## Ersatz Economics Vocabulary\n\nThe person-in-the-street's economic vocabulary that no professional should use unironically:\n\n### Price Language\n- skyrocketing (have you seen a skyrocket?)\n- exorbitant, gouging\n- fair, just\n- unfair, cutthroat\n- dumping\n\n### Power Language\n- bargaining power\n- exploit\n- vicious cycle, spiral\n- obscene profits, unwarranted margins\n- unfair competition\n\n### Needs Language\n- afford (\"can barely afford\")\n- basic necessity\n- living wage\n- cheap foreign labor\n- priorities\n- rebuilding our industrial base\n\nThese locutions embody popular misunderstanding of economics. To write thoughtfully, clear your mind of such cant.\n\n## Teutonism Examples\n\n### Before and After\n\n| Knotted (Hard to Parse) | Untied (Clear) |\n|------------------------|----------------|\n| factor price equalization | equalization of the prices of factors |\n| long-run balance of payments adjustment | adjustment of the balance of payments in the long run |\n| private wealth-seeking activity | the seeking of wealth |\n| elastic credit supply expectations | expectations about the supply of elastic credit |\n| anti-quantity theory evidence | evidence against the quantity theory |\n| contractually uniform transaction cost | the cost of transactions that are contractually uniform |\n| initial relative capital goods price shock | the initial shock to the relative price of capital goods |\n| community decision making process | how the community makes decisions |\n| Cobb-Douglas production function estimation approach | the approach to estimating a Cobb-Douglas production function |\n\n### The Possessive as Teutonism Generator\n\nAvoid: \"the standard political scientist's model\"\nProblem: Is the model standard, or the political scientist?\n\nUse specific referents: \"the model that political scientists standardly use\"\n\n## Concreteness Examples\n\n### Economics Examples\n\n| Abstract | Concrete |\n|----------|----------|\n| capital and labor embodied the same technology | machines and men embodied the same knowledge of how to spin cotton or move cargo |\n| the larger numbers of spindles and ships | (already concrete) |\n| natural resource-oriented exports | sheep and wheat |\n| the commencement of the Spanish Price Revolution antedated the inflow of treasure | Spanish prices began to rise before the treasure came |\n| growing structural differentiation | new jobs in manufacturing |\n| integrative consequences of structural differentiation | the need for others that someone feels when he buys rather than bakes his bread |\n\n### The Principle\n\nA reader finds it harder to translate abstractions down into concrete examples than to translate examples up into abstract principles. Write concrete; let the reader generalize.\n\n## Coherence Through Repetition\n\n### The Polyptoton Pattern\n\nLink sentences through repeated roots in different forms:\n- linking → linkages\n- repetition → repeating → repeat → repeated\n\n### The Transitivity Pattern\n\n(AB)(BC)(CD) is easy to understand.\n(ABZYZ)(MNOP)(BJKL) is impossible.\n\nEach sentence should share a word or concept with the previous one.\n\n### What Not to Do\n\nAvoid the Latin \"not only...but also\" pattern. It marks you as incompetent. Best writers never use it. English achieves coherence by repetition, not by frantic signaling.\n\n## Source\n\nMcCloskey, Deirdre N. *Economical Writing*. 3rd ed. Chicago: University of Chicago Press, 2019.\n\nFor the complete 35 rules with full context, examples, and McCloskey's characteristic wit, consult the original text.\n",
        "skills/writing-legal/SKILL.md": "---\nname: writing-legal\ndescription: This skill should be used when the user asks to \"write a law review article\", \"draft a legal paper\", \"edit legal writing\", \"review my legal article\", \"write for a journal\", \"format footnotes\", or needs guidance on academic legal writing. Based on Volokh's \"Academic Legal Writing\" with law-review-specific structure and evidence handling.\n---\n\n# Academic Legal Writing\n\nStyle guide for law review articles, seminar papers, and legal scholarship based on Eugene Volokh's *Academic Legal Writing*.\n\n## When to Use\n\nInvoke this skill for:\n- Law review articles and student notes\n- Seminar papers and legal scholarship\n- Academic legal writing with footnotes\n- Editing legal prose for structure and argument\n\n**For general writing**: Use `/writing` skill (Strunk & White)\n**For economics/finance**: Use `/writing-econ` skill (McCloskey)\n\n## Required Skills\n\nWhen generating Word documents (`.docx`), you MUST load the `/docx` skill first. The docx skill provides proper document manipulation capabilities.\n\n## Template Requirement\n\n**Template location:** `${CLAUDE_SKILL_ROOT}/templates/law_review_template.docx`\n\nThis template contains proper law review formatting: margins, fonts, footnote styles, and section formatting compliant with standard journal requirements.\n\n## Enforcement\n\n### IRON LAW #1: NO DOCX WITHOUT TEMPLATE FIRST\n\nBefore creating ANY Word document for legal writing:\n1. Load the `/docx` skill\n2. Copy `${CLAUDE_SKILL_ROOT}/templates/law_review_template.docx` as the base\n3. THEN add content to the template copy\n\nIf you created a blank docx without the template, DELETE IT and START OVER with the template.\n\n### IRON LAW #2: NO CLAIM WITHOUT CONFRONTING COUNTERARGUMENTS\n\nIf your draft makes a prescriptive claim but doesn't address obvious objections, DELETE the section and START OVER. Legal scholarship requires anticipating and answering counterarguments, not ignoring them.\n\n### IRON LAW #3: NO SECONDARY SOURCE CITATIONS FOR PRIMARY SOURCES\n\nIf you cite a case/statute/historical fact via an intermediate source (law review, treatise), DELETE the citation and READ THE ORIGINAL. Even Supreme Court opinions misstate precedents.\n\n### Rationalization Table - Template Usage\n\n| Excuse | Reality | Do Instead |\n|--------|---------|------------|\n| \"I'll format it properly later\" | Formatting is structural, not cosmetic | START with template |\n| \"The content matters more\" | Wrong format = rejection by journals | Template provides correct format |\n| \"I can apply styles after\" | Retroactive styling breaks footnotes | Use template from the start |\n| \"A blank doc is simpler\" | Blank doc means redoing all formatting | Copy template, it's one step |\n| \"User didn't ask for template\" | Professional output is implicit | Always use template for docx |\n\n### Rationalization Table - STOP If You Think:\n\n| Excuse | Reality | Do Instead |\n|--------|---------|------------|\n| \"This article discusses...\" | Bores reader instantly | START with concrete problem or controversy |\n| \"Table-of-contents paragraph helps\" | Readers skip it | INTEGRATE roadmap into intro |\n| \"Background section comes first\" | Not before establishing relevance | SHOW problem first, background second |\n| \"Case-by-case summary is thorough\" | Tedious and unhelpful | SYNTHESIZE: \"Courts hold X except Y\" |\n| \"Counterargument would hurt my claim\" | Ignoring it hurts worse | CONFRONT and refine claim |\n| \"Treatise summary is good enough\" | Treatises have errors | READ original cases |\n| \"Arguably\" makes my point | Acknowledges controversy without arguing | MAKE the argument explicitly |\n| \"This metaphor is clear\" | Metaphors hide incomplete logic | UNPACK: what's the actual argument? |\n\n### Red Flags - STOP Immediately If You Think:\n\n**Template Red Flags:**\n- \"Let me create a new Word document\" → NO. Copy the template first.\n- \"I'll add the template formatting later\" → NO. Start with template.\n- \"The docx skill will handle formatting\" → NO. docx skill needs template base.\n\n**Content Red Flags:**\n- \"Let me write standard intro\" → NO. Find concrete problem first.\n- \"I'll address objections later\" → NO. Confront counterarguments NOW.\n- \"This treatise explains the case\" → NO. Read the original case.\n- \"Background section needs more\" → NO. Only include what proves claim.\n\n### Delete & Restart Pattern\n\n**When to delete and restart:**\n\n1. **Created docx without template** → Delete file, copy template, start over\n2. **Intro starts with \"This article discusses\"** → Delete, start with concrete problem\n3. **Background exceeds proof section** → Delete excessive background\n4. **Claim made without addressing objections** → Delete section, add counterargument confrontation\n5. **Citation chain to primary source** → Delete citation, read and cite original\n6. **Unpacked metaphor used as argument** → Delete, write actual logical argument\n\n**How to restart:**\n\n```\nOld: \"This article discusses privacy concerns in Fourth Amendment doctrine...\"\nNew: \"When police drones photograph backyards, does the Fourth Amendment require a warrant?\n      Courts disagree, but three features of aerial surveillance suggest yes.\"\n```\n\nStart with CONCRETE QUESTION that matters, not abstract topic description.\n\n### Gate Function: Document Creation\n\nWhen user requests a Word document (docx), follow this 5-step gate:\n\n```\nSTEP 1: LOAD    → Load /docx skill\nSTEP 2: COPY    → Copy ${CLAUDE_SKILL_ROOT}/templates/law_review_template.docx\n                  to target location (e.g., user's specified path)\nSTEP 3: EDIT    → Add content to the COPIED template\nSTEP 4: VERIFY  → Check template formatting preserved (styles, footnotes)\nSTEP 5: DELIVER → Return the document to user\n```\n\n**GATE VIOLATION = RESTART**: If any step is skipped, delete the output and restart from Step 1.\n\n## Law Review Article Structure\n\n### Introduction\n\nThe introduction serves three functions:\n1. Persuade readers to keep reading\n2. Summarize the article for those who won't read it\n3. Frame how readers interpret what follows\n\n**Requirements:**\n- Show the problem concretely with specific examples or hypotheticals\n- State the claim clearly—what does the article contribute?\n- Integrate the roadmap into the introduction, not as a separate paragraph\n- Hook the reader: concrete question, engaging story, controversy, or argument to rebut\n\n**Anti-patterns:**\n- Starting with \"This article discusses...\"\n- Separate table-of-contents paragraph (readers skip it)\n- Historical background before establishing relevance\n- Vague generalities about the importance of the topic\n\n### Background Section\n\nSynthesize precedents; do not summarize each case sequentially. Focus only on facts and rules necessary for the argument.\n\n| Problem | Solution |\n|---------|----------|\n| Summarizing each case | Synthesize: \"Courts generally hold X, except when Y\" |\n| Mini-treatise on the area | Only what's needed for the claim |\n| 80% background, 20% claim | Balance must favor the original contribution |\n\n### Proof of the Claim\n\nFor prescriptive claims: Show the proposal is both doctrinally sound AND good policy.\n\n**Use a test suite:** Apply the proposal to concrete scenarios (easy cases, hard cases, edge cases) to demonstrate it works.\n\n**Confront counterarguments:**\n- Turn problems to advantage: refine the claim, acknowledge uncertainty\n- Stay on offense—address objections without becoming defensive\n- Acknowledge costs honestly; readers respect candor\n\n**Connect to broader issues:**\n- How does the claim relate to parallel debates?\n- What subsidiary discoveries emerged?\n- What questions remain for future research?\n\n### Conclusion\n\nKeep conclusions brief. The real work is rewriting the introduction after the draft is complete, ensuring it accurately reflects the article's contributions.\n\n## Legal Argument Problems\n\nCommon logical problems in legal writing (see `references/volokh-distilled.md` for detailed examples):\n\n| Problem | Issue |\n|---------|-------|\n| Categorical assertions | \"Always\" and \"never\" invite counterexamples |\n| Unpacked metaphors | \"Slippery slope\" and \"chilling effect\" hide incomplete arguments |\n| Missing logical pieces | Syllogisms that skip steps (subject to scrutiny ≠ fails scrutiny) |\n| Universal criticisms | \"Chilling effect\" applies to most laws—explain why *this* one matters |\n| Undefined abstractions | \"Privacy,\" \"paternalism,\" \"democratic legitimacy\" need definitions |\n| \"Arguably\" as argument | Acknowledges controversy but doesn't make the case |\n\n## Evidence and Citation\n\n### Read Original Sources\n\nNever rely on intermediate sources for cases, statutes, or historical facts. Even Supreme Court opinions misstate precedents.\n\n| Source Type | Rule |\n|-------------|------|\n| Cases/statutes | Read the original; don't trust treatises or other cases |\n| Historical facts | Go to history books, not law review articles citing them |\n| Scientific studies | Read the study, not the article summarizing it |\n| Newspapers | Unreliable; track down underlying documents |\n| Wikipedia | Use to find sources, but cite originals |\n\n### Be Precise with Terms\n\nAvoid false synonyms: \"murder\" ≠ \"homicide\" ≠ \"killing\"; \"foreign-born\" ≠ \"noncitizen\"; \"children\" is ambiguous (0-14? 0-17? 0-24?).\n\nInclude necessary qualifiers: \"*falsely* shouting fire\" is quite different from \"shouting fire.\"\n\n### Be Explicit About Assumptions\n\nMake clear when inferring:\n- From correlation to causation\n- From one time/place to another\n- From one variable to another (arrest rate ≠ crime rate)\n\nAcknowledge the inference and defend it; don't hide it.\n\n### Handle Surveys Carefully\n\nSurveys measure only what respondents said in response to specific questions. Valid surveys require:\n- Random sampling (not self-selected, not convenience samples)\n- High response rates (70%+)\n- Sufficient sample size (1000+ for ±3% margin)\n- Unambiguous questions\n\n\"Online survey\" and \"Internet poll\" are almost sure signs of invalidity.\n\n## Rhetoric and Tone\n\n| Principle | Application |\n|-----------|-------------|\n| Understate criticism | \"Mistaken\" not \"idiotic\"—overstating raises the burden of proof |\n| Attack arguments, not people | \"This argument fails\" not \"Volokh is wrong\" |\n| Avoid caricature | Quote adherents, not critics, when explaining a position |\n\nSee `references/volokh-distilled.md` for extended discussion of rhetorical problems.\n\n## Quick Reference\n\n| Problem | Solution |\n|---------|----------|\n| \"This article discusses X\" | Hook with concrete problem |\n| Case-by-case summaries | Synthesize precedents |\n| Undefended metaphors | Unpack the concrete mechanism |\n| \"Arguably\" / \"raises concerns\" | Give the actual argument |\n| Relying on intermediate source | Read original case/study |\n| \"Many children\" | Specify: \"111 children age 0-17\" |\n| \"Correlation shows causation\" | Explain why inference is valid |\n| \"Volokh's argument is idiotic\" | \"This argument seems unsound\" |\n\n## Progressive Disclosure\n\nFor comprehensive guidance, consult:\n\n### Template\n\n- **`templates/law_review_template.docx`** - Law review document template:\n  - Proper margins and page setup for journal submission\n  - Footnote styles compliant with Bluebook formatting\n  - Section heading styles\n  - Font and spacing requirements\n\n### Reference File\n\n- **`references/volokh-distilled.md`** - Extended Volokh guidance covering:\n  - Full logical problems taxonomy\n  - Word and phrase problems to avoid\n  - Extended evidence handling\n  - Survey analysis methodology\n  - Editing principles and exercises\n\n### When to Load Reference\n\nLoad the full reference when:\n- Encountering specific evidence evaluation questions\n- Needing detailed survey methodology guidance\n- Working on substantial manuscript revision\n- Checking specific word choice or usage questions\n\n## Integration\n\n**Required skills for document generation:**\n- `/docx` - Load BEFORE creating any Word document\n- `/bluebook` - Load when formatting legal citations\n\nAfter completing any legal writing task, invoke `/ai-anti-patterns` to check for AI writing indicators. The `/writing` skill covers general prose principles (active voice, omit needless words) that complement this skill.\n",
        "skills/writing-legal/references/volokh-distilled.md": "# Volokh's Academic Legal Writing - Extended Reference\n\nComprehensive guidance for law review articles distilled from Eugene Volokh's *Academic Legal Writing*.\n\n## Logical Problems\n\n### Categorical Assertions\n\nAvoid \"never\" and \"always.\" \"This law would be completely unenforceable\" or \"could never be enforced\" invites the devastating response: \"Really? Not even once?\"\n\nModest claims are more likely to be right and harder to attack.\n\n### Insistence on Perfection\n\n\"The law would not adequately protect against all possible harms\" is a weak criticism. No law prevents all instances of harm. The questions are whether the law does more good than harm and whether alternatives do better.\n\nBe careful of false dichotomies: perfect laws vs. pointless laws ignores laws that do something but not everything.\n\n### False Alternatives\n\n\"Is pornography free speech or hate speech?\" The answer may be \"both.\" Asking \"X or Y?\" suggests mutual exclusivity that may not exist.\n\nIf you think X and Y are mutually exclusive, demonstrate this rather than assuming it.\n\n### Missing Pieces in Arguments\n\nLegal arguments must connect logically:\n\n```\n1. Classifications based on sex get strict scrutiny\n2. Separate schools involve sex classifications\n3. Therefore, separate schools are unconstitutional [WRONG]\n```\n\nSteps 1 and 2 prove only that separate schools are *subject to* strict scrutiny, not that they fail it. Fill the gap by showing the classification fails the scrutiny.\n\n**Test:** Before and after writing the proof section, summarize each significant assertion in one sentence. Do they fit together?\n\n### Criticisms That Apply to Everything\n\n\"Chilling effect,\" \"slippery slope,\" \"imposes majority's morality,\" \"intrudes on privacy\"—most laws that constrain conduct do one or more of these. Sometimes that's acceptable.\n\nExplain specifically:\n- Why *this* chilling effect is worse than tolerable ones\n- Why *this* slope is more slippery than others\n- Why *this* intrusion is unjustified when others are permissible\n\nAsk: Does this criticism equally apply to laws I endorse?\n\n### Metaphors Require Unpacking\n\nLegal metaphors are literally false. \"Slippery slope\" is shorthand for \"this decision may cause more troublesome future decisions\"—but why? What's the mechanism?\n\n| Metaphor | Literal Meaning | Requires |\n|----------|-----------------|----------|\n| Slippery slope | Future decisions follow | Explain *why* they would follow |\n| Chilling effect | Speech beyond the law's scope is deterred | Explain *what* speech and *how* |\n| Balancing | Weighing competing interests | Explain *what weights* and *who decides* |\n\nPhysical slippery slopes are self-explanatory (gravity + friction). Legal ones are not.\n\n### Undefined Terms\n\nCircle every abstraction: \"paternalism,\" \"privacy,\" \"democratic legitimacy,\" \"fundamental fairness,\" \"evolving standards of decency,\" \"narrow tailoring,\" \"good faith.\"\n\nFor each, ask:\n- What constitutes this?\n- Does the reader understand what I mean?\n- Do *I* understand what I mean?\n- Am I using it consistently?\n\nIf a term is too vague to define, ask whether it helps the argument.\n\n### \"Arguably\" and \"Raises Concerns\"\n\n\"Arguably X\" acknowledges controversy but doesn't explain why readers should accept your side. If something is arguably true, give the argument and explain why it beats the counterargument.\n\n\"Raises constitutional concerns\" or \"is troubling\" is not an argument. If the proposal is unconstitutional or unsound, explain why.\n\n## Paragraph-Level Problems\n\n### One Theme Per Paragraph\n\nEach paragraph should be about one main thought. The first sentence (topic sentence) expresses that thought. Other sentences support it.\n\n### Paragraph Length\n\nAim for 2-4 sentences (Volokh) or 5-6 (others). Once past 6 medium sentences or 4 long ones, readers' attention wanes.\n\nOne-sentence paragraphs are usually too choppy, though sometimes good for introducing several longer paragraphs.\n\n### Connections Between Paragraphs\n\nEach paragraph should be logically linked to the one before. The reader starting a new paragraph should understand its relationship to the previous one.\n\nThis doesn't require explicit transitions (\"Moreover,\" \"On the other hand\"). Repetition of a word or concept from the previous paragraph's last sentence works.\n\n## Sentence and Clause Problems\n\n### Redundancy\n\nWhen two sentences express similar thoughts, eliminate one or part of one. \"In other words\" signals the first words weren't good enough.\n\nAvoid legal doublets: \"any and all,\" \"null and void,\" \"cease and desist.\" Unless the phrase has legal significance (\"cease-and-desist letter\"), use one word.\n\n### Unnecessary Introductory Clauses\n\nDelete throat-clearing:\n- \"It should be mentioned that...\"\n- \"In having researched the implications...\"\n- \"It is important to note that...\"\n\n### Unnecessary Phrases\n\nEach clause should make a specific point useful to the argument.\n\n**Bad:** \"The state legislature should reject this proposal because it is the wrong solution.\"\nWhat extra information does \"because it is the wrong solution\" convey?\n\n**Bad:** \"Given the large number of accidental firearms injuries among young people, everyone would agree that firearms safety is a matter of great public concern.\"\nOn that level of generality, everyone does agree—to the point that the sentence adds nothing.\n\nEither delete such sentences or make them concrete with specific numbers or facts.\n\n### Needless Tangential Detail\n\nOrganize narration around the needs of the argument, not the internal structure of facts learned during research.\n\nDon't describe each Supreme Court case you read. Don't explain the chemistry of pepper spray. Focus on what readers need to know.\n\n## Word and Phrase Problems\n\n### Legalese and Bureaucratese\n\nWrite like normal people speak.\n\n| Legalese | Plain English |\n|----------|---------------|\n| Opposition to the bill is needed on the grounds that... | We should oppose the bill because... |\n| Guns have a far greater utilitarian value | Guns are far more useful |\n| Could negatively affect the accessibility | Could make... less accessible |\n\n### Nominalization\n\nTurning verbs and adjectives into nouns makes prose abstract and complex.\n\n| Nominalized | Direct |\n|-------------|--------|\n| Opposition to the bill is needed | We should oppose the bill |\n| Have a far greater utilitarian value | Are far more useful |\n| Affect the accessibility of | Make... less accessible |\n\nIf you see an abstract noun, ask whether you can replace it with the concrete verb, adjective, or adverb it embodies.\n\n### Long Synonyms for Short Phrases\n\n| Long | Short |\n|------|-------|\n| A large number of | Many |\n| In close proximity to | Near |\n| The legislative branch of government | The legislature |\n| At this point in time | Now |\n| Prior to | Before |\n| In order to | To |\n\n### Unnecessary Abstractions\n\nMake arguments using words that concretely describe real problems people face.\n\n| Abstract | Concrete |\n|----------|----------|\n| When law enforcement is unavailable | When the police can't come in time |\n| Violence connected with guns | People killed, injured, or threatened with guns |\n| Will have a positive effect | Will prevent many murders and suicides |\n\n\"The police\" is what people want; \"law enforcement\" is the abstraction.\n\n### Passive Voice\n\nActive voice is usually better, but passive is appropriate when the discussion focuses on the object rather than the actor.\n\n**Appropriate passive:** \"The Act was adopted shortly after September 11\" (focus is on the Act, not Congress).\n\n### Word Choice Mistakes\n\nPoor word choice undermines credibility. Reread each sentence and ask: Is this exactly what I want to say?\n\nCommon problems:\n- \"Alternate\" vs. \"alternative\"\n- Unidiomatic phrases (\"crimes done\" should be \"crimes committed\")\n- Inattentiveness to literal meaning (\"Firearms are one of the most lethal forms of suicide\"—no, they're a *means* of suicide)\n\n### Figurative Phrases\n\nFigurative language is often misused:\n- Mixed metaphors (\"the political equation was saturated with kerosene\")\n- Literal meaning highlighted by context (\"The felony murder rule has been done to death\")\n- Misuse (\"back to ground zero\" instead of \"back to square one\")\n- \"Begs the question\" traditionally means assuming what you're trying to prove, not \"raises the question\"\n\nNever use \"literally\" when you mean \"figuratively.\"\n\n### Abbreviations\n\nDon't create your own abbreviations. Even preexisting ones (RFRA, GFSZA) can make work less accessible.\n\nUse \"the Act\" or \"such arguments\" instead of abbreviations when meaning is clear from context.\n\n## Rhetorical Problems\n\n### Unduly Harsh Criticism\n\nUse \"mistaken,\" \"unsound,\" or \"erroneous,\" not \"fraudulent,\" \"nonsense,\" \"ridiculous,\" or \"idiotic.\"\n\nReasons:\n1. Overstating raises your burden of proof\n2. No one likes a bully\n3. Invective suggests lack of substance\n4. Readers tolerate less harshness from juniors\n5. No need to make unnecessary enemies\n6. Easier to backpedal if proven wrong\n\n### Personalized Criticism\n\nAttack arguments, not people. \"This argument is wrong because...\" not \"Volokh is wrong because...\"\n\nLabel arguments by content (\"the cost-lowering slippery slope argument\") rather than by author. Attribute in footnotes.\n\n### Caricatured Criticism\n\nAvoid drive-by characterizations of schools of thought (\"retributivists believe X\"). Name names and cite specific works.\n\nQuote adherents of a position, not its critics, when explaining the position. Critics are less invested in describing the position accurately.\n\n**Test:** Could the objects of criticism agree the characterization is fair?\n\n## Evidence Handling\n\n### Read Original Sources\n\nNever rely on intermediate sources—cases, articles, treatises—for what another case or statute says. Check the original.\n\n**Even Supreme Court opinions err.** *Reno v. ACLU* incorrectly stated that *Ginsberg* and *Pacifica* were limited to commercial speech. They weren't.\n\n### Historical, Economic, and Scientific Evidence\n\nLaw review authors are usually not experts in history, economics, or science. Some have learned just enough to be dangerous.\n\nIf possible, go to the ultimate source (historical document, scientific study). Law school librarians can help obtain materials.\n\nIf you must rely on secondary sources, at least don't rely on law review articles citing history books—there, the risk of error is too high.\n\n### Newspapers\n\nNewspapers often omit critical details or err in what they include. Reporters are generalists writing under tight deadlines. They rarely check original sources or verify quotes with sources.\n\nRules:\n1. Never rely on newspaper accounts of published cases or statutes\n2. Get underlying documents or studies, not newspaper descriptions of them\n3. Search other papers to identify original sources\n4. Contact quoted speakers to verify quotes\n5. Acknowledge reliability problems (\"press accounts report that...\")\n6. Note the article's nature (opinion piece?), source's biases, and reasons for possible inaccuracy\n\n### Transcripts\n\nTranscribers make mistakes. One transcript rendered \"whether a state even may exclude religion\" as \"whether a state even makes good religion.\"\n\nEven accurate transcripts may not reflect considered judgment—speakers misspeak and can't proofread.\n\n### Wikipedia\n\nWikipedia entries tend to be relatively accurate, but:\n1. Find the original sources and cite them, not Wikipedia\n2. Many readers and law review editors will assume Wikipedia is unreliable\n\n### Check Studies You Cite\n\nRead studies with a skeptical eye. Pretend you disagree with the political view the study supports. Search for criticisms of the study.\n\nIf you find flaws, acknowledge them and explain why the study is still valuable despite them.\n\n## Survey Evidence\n\n### What Surveys Measure\n\nSurveys measure only what (1) survey-takers recorded (2) these particular respondents (3) were willing to say (4) in response to particular questions asked.\n\nSurveys of small groups can reveal likely answers of a larger group *only if* respondents are a large enough randomly selected sample.\n\n### Bad Samples\n\n**Biased samples:** The 1936 *Literary Digest* poll predicted Landon would beat Roosevelt 55-41%. Roosevelt won 61-37%. The poll used telephone books and automobile registrations, disproportionately reaching richer people.\n\n**Convenience samples:** Psychology students, pedestrians on a corner—wildly unrepresentative of the population.\n\n**Self-selected samples:** Internet polls and reader surveys are meaningless. Only those who feel most strongly respond. Activist groups swamp results.\n\n**Mail-in and Internet samples:** Most involve self-selection. Only 25% of *Literary Digest* surveys were returned.\n\n### Valid Surveys\n\nRequirements:\n1. Random sample of a broader group\n2. High response rate (70%+) to avoid self-selection bias\n3. Large enough sample (1000 respondents for ±3% margin)\n\n### Question Wording\n\nSurveys asking different questions can't measure the same thing.\n\n**Example:** \"The First Amendment goes too far in the rights it guarantees\" was reported as showing 49% think \"the First Amendment goes too far in guaranteeing free speech.\" But the question asked about *all* First Amendment rights, including religion. A later question found only 10% thought Americans have \"too much freedom to speak freely.\"\n\nAmbiguous questions measure nothing in particular. \"The right to privacy\" means different things to different people (abortion? searches? something else?).\n\nGet the text of the questionnaire. If a survey organization refuses to release questions, be skeptical.\n\n### Consider All Information\n\nIf a survey asks many questions, consider all the information, not just parts supporting your case.\n\n### Incorrect Answers\n\nRespondents may:\n- Not remember past events accurately\n- Conceal illegal or embarrassing behavior\n- Conceal unpopular views\n- Misunderstand questions\n- Give answers to avoid looking ignorant\n\n## Assumptions and Inferences\n\n### Correlation vs. Causation\n\n\"More guns in the U.S. than England; more murder in the U.S. Therefore, guns cause murder.\"\n\n\"More guns in rural areas than urban areas; less murder in rural areas. Therefore, guns decrease murder.\"\n\nBoth premises are true. Both conclusions can't be.\n\nIce cream production and rape are highly correlated (0.84 in 2000). Both increase in summer. Ice cream doesn't cause rape.\n\nMake clear when you're inferring causation from correlation, and explain why the inference is valid.\n\n### Extrapolation Across Places\n\nData from one city may not generalize to the country. Data from the country may not generalize to one city.\n\nA study of San Francisco homosexual men in 1970 may not represent all American homosexual men in 1990.\n\n### Extrapolation Across Time\n\nBehavior patterns change. Data from one decade may not apply to another.\n\n### Extrapolation Across Populations\n\nData from STD patients does not generalize to the general population—they're in hospitals *because* they had many partners.\n\nOne book reported that homosexual men had a median of 1,160 lifetime partners—but the source said \"homosexual men *with AIDS*\" had that median. The ellipses hid the critical qualifier.\n\n### Extrapolation Across Variables\n\nArrest rates ≠ crime rates. Ice cream production ≈ ice cream consumption. Reported burglaries ≠ actual burglaries.\n\nMake clear what variable the data measures and why inferring to another variable is legitimate.\n\n### Summary\n\nWhen citing a study showing a state law was followed by falling arrest rates:\n\n1. **Generalizability over time/space:** Results from Ohio in 1991 may not generalize to other states today.\n2. **Causation vs. correlation:** Arrests may have fallen for other reasons (crime generally falling, other measures implemented).\n3. **Measured vs. important variable:** Falling arrests don't necessarily mean falling crime.\n\n## False Synonyms and Qualifiers\n\n### False Synonyms\n\n| Term Used | Actual Meaning | Problem |\n|-----------|----------------|---------|\n| Foreign-born | Noncitizen | Twice as many foreign-born as noncitizens |\n| Murder | Homicide | Homicide includes manslaughter, justifiable killing |\n| Children | People age 0-24 | \"Children\" connotes much younger |\n| Right of publicity | Narrow right re: performance rebroadcasting | *Zacchini* upheld only the narrow version |\n\n### Necessary Qualifiers\n\nHolmes: \"The most stringent protection of free speech would not protect a man in *falsely* shouting fire in a theatre and causing a panic.\"\n\nThe \"falsely\" is usually dropped. False statements are often unprotected; true ones generally are.\n\nIf you want to argue even accurate fire-shouting is dangerous, make that argument explicitly.\n\n## Editing Principles\n\n### Go Through Many Drafts\n\nNothing is ever written; it is rewritten. Aim for 10 complete edits before submission. Judge Kozinski's chambers did 30-40 drafts of opinions.\n\n### Questions for Each Sentence\n\n1. What information does this communicate that readers don't already know?\n2. Has this information already been communicated?\n3. Is this sentence so related to the previous one that part is repeated?\n4. Can I eliminate this without changing the meaning?\n5. Is this how normal people talk?\n6. Does each word communicate exactly what I want?\n7. Should this noun be a verb, adjective, or adverb instead?\n\n### If You See No Red Marks, Edit Again\n\nAt least in early drafts, every paragraph needs correction. If you're not finding flaws, you're not looking hard enough.\n\n### If You Reread to Understand, Rewrite\n\nIf your writing confuses even you, it will confuse readers more. Complex material can still be explained clearly.\n\n### Ask \"Why?\" and \"Why Not?\"\n\nFor every sentence in the argument, ask \"why?\" The sentence or its neighbors must answer, unless the answer is obvious.\n\nThen ask \"why not?\"—what would a reasonable person think on the other side?\n\n### Use Your Imaginary Adversary\n\nImagine someone you respect who takes the opposite view. Read as that person. What counterarguments would they raise? Would they see flaws in the logic?\n\n### No Lazy Readers, Only Busy Readers\n\nSmart, industrious readers are busy *because* they are industrious and smart. They can parse complex prose, but it takes work. Why should they wade through your morass when they could work on something else?\n\nMake things as easy for readers as possible.\n",
        "skills/writing/SKILL.md": "---\nname: writing\ndescription: This skill should be used when the user asks to \"write an article\", \"draft a blog post\", \"edit prose\", \"review my writing\", \"check style\", \"improve clarity\", or needs general writing guidance. Provides Strunk & White's Elements of Style for foundational grammar, usage, and composition principles.\n---\n\n# Writing and Editing\n\nFoundational style guide for clear, concise prose based on Strunk & White's Elements of Style.\n\n## When to Use\n\nInvoke this skill for:\n- Writing articles, blog posts, or general prose\n- Editing text for clarity, conciseness, or style\n- Reviewing grammar and usage\n- Improving sentence structure and word choice\n\n**For specialized domains:**\n- Legal writing (law review articles): Use `/writing-legal` skill (Volokh)\n- Economics/Finance: Use `/writing-econ` skill (McCloskey)\n\n## Core Principles\n\n### The Iron Law of Good Writing\n\n**Omit needless words.**\n\nEvery word must earn its place. Vigorous writing is concise. A sentence should contain no unnecessary words, a paragraph no unnecessary sentences.\n\n### Critical Rules\n\n| Rule | Explanation |\n|------|-------------|\n| Write in prose | Avoid bullet points and lists unless explicitly requested |\n| Use active voice | \"The committee approved the plan\" not \"The plan was approved\" |\n| Be concrete | Specific details over vague abstractions |\n| Put statements in positive form | Say what something is, not what it isn't |\n| Use definite language | Avoid hedging, qualifiers, and weasel words |\n\n### Red Flags - Stop If You Think\n\n| Thought | Why It's Wrong | Do Instead |\n|---------|----------------|------------|\n| \"I'll add some qualifiers to be safe\" | Weakens the writing | Make definite assertions |\n| \"Let me list these points\" | Bullet points are lazy | Write in prose paragraphs |\n| \"I should sound more formal\" | Formality often means wordiness | Write naturally, then edit |\n| \"This needs more emphasis\" | Overemphasis dilutes meaning | Let strong words speak |\n\n## How to Use This Skill\n\n### Before Writing\n\n1. Identify the main point or thesis\n2. Plan the structure: introduction, development, conclusion\n3. Gather concrete examples to support claims\n\n### During Drafting\n\n1. Write complete sentences in paragraphs\n2. Use active voice and strong verbs\n3. Be specific: \"three hours\" not \"a long time\"\n4. Avoid starting with \"There is\" or \"It is\"\n\n### During Editing\n\nApply these checks in order:\n\n**Sentence Level:**\n- Remove unnecessary words (\"in order to\" → \"to\")\n- Replace weak verbs (\"is able to\" → \"can\")\n- Convert passive to active voice\n- Eliminate redundancies (\"past history\" → \"history\")\n\n**Paragraph Level:**\n- Ensure each paragraph has one main idea\n- Check topic sentences lead clearly\n- Verify logical flow between paragraphs\n\n**Word Level:**\n- Replace abstract nouns with concrete ones\n- Use specific verbs over vague ones + adverbs\n- Cut filler words (\"very\", \"really\", \"quite\", \"rather\")\n\n## Quick Reference: Common Fixes\n\n| Weak | Strong |\n|------|--------|\n| utilize | use |\n| in order to | to |\n| due to the fact that | because |\n| at this point in time | now |\n| in the event that | if |\n| prior to | before |\n| subsequent to | after |\n| with regard to | about |\n| a large number of | many |\n| is able to | can |\n\n## Progressive Disclosure\n\nFor comprehensive guidance, consult:\n\n### Reference Files\n\n- **`references/elements-of-style.md`** - Complete Strunk & White guide covering:\n  - Elementary Rules of Usage (commas, colons, participles)\n  - Elementary Principles of Composition (paragraph unity, active voice)\n  - Words and Expressions Commonly Misused\n  - Style guidance and literary reminders\n\n### When to Load References\n\nLoad the full reference when:\n- Encountering specific grammar questions (comma usage, possessives)\n- Needing detailed guidance on composition principles\n- Checking whether specific words/expressions are commonly misused\n- Working on substantial editing tasks\n\n## Integration with AI Anti-Patterns\n\nAfter completing any writing task, invoke `/ai-anti-patterns` to check for AI writing indicators. This plugin includes PostToolUse hooks that automatically warn on common anti-patterns in Write/Edit output.\n\n## Examples\n\n**Weak original:**\n> It is important to note that there are a variety of different factors that contribute to the overall success of the project in question.\n\n**Strong revision:**\n> Several factors determine project success.\n\n**Weak original:**\n> The report was written by the team and was subsequently reviewed by management prior to being distributed to stakeholders.\n\n**Strong revision:**\n> The team wrote the report, management reviewed it, and stakeholders received it.\n\n## Typography Tools\n\n### Smart Quotes\n\nConvert straight quotes (`\"`) to typographic curly quotes (`\"\"`):\n\n```bash\npython ${CLAUDE_PLUGIN_ROOT}/scripts/smartquotes.py file.md\npython ${CLAUDE_PLUGIN_ROOT}/scripts/smartquotes.py file.md --check  # dry-run\n```\n\nConverts quotes and apostrophes while preserving em dashes and other formatting. Requires `pip install smartypants`.\n\n## Related Skills\n\n- `/ai-anti-patterns` - Detect and revise AI writing patterns\n- `/writing-legal` - Academic legal writing (Volokh)\n- `/writing-econ` - Economics and finance writing (McCloskey)\n- `/docx` - Word document creation, editing, tracked changes\n- `/pdf` - PDF extraction, creation, form filling\n- `/pptx` - Presentation creation and editing\n- `/xlsx` - Spreadsheet creation and analysis\n",
        "skills/writing/references/elements-of-style.md": "# The Elements of Style (1918)\n\n_Public domain text by William Strunk Jr._\n\n## Table of Contents\n\n- [The Elements of Style (1918)](#the-elements-of-style-1918)\n  - [Table of Contents](#table-of-contents)\n  - [I. Introductory](#i-introductory)\n  - [II. Elementary Rules Of Usage](#ii-elementary-rules-of-usage)\n    - [Rule 1. Form the possessive singular of nouns by adding 's.](#rule-1-form-the-possessive-singular-of-nouns-by-adding-s)\n    - [Rule 2. In a series of three or more terms with a single conjunction, use a comma after each term except the last.](#rule-2-in-a-series-of-three-or-more-terms-with-a-single-conjunction-use-a-comma-after-each-term-except-the-last)\n    - [Rule 3. Enclose parenthetic expressions between commas.](#rule-3-enclose-parenthetic-expressions-between-commas)\n    - [Rule 4. Place a comma before a conjunction introducing a co-ordinate clause.](#rule-4-place-a-comma-before-a-conjunction-introducing-a-co-ordinate-clause)\n    - [Rule 5. Do not join independent clauses by a comma.](#rule-5-do-not-join-independent-clauses-by-a-comma)\n    - [Rule 6. Do not break sentences in two.](#rule-6-do-not-break-sentences-in-two)\n    - [Rule 7. A participial phrase at the beginning of a sentence must refer to the grammatical subject.](#rule-7-a-participial-phrase-at-the-beginning-of-a-sentence-must-refer-to-the-grammatical-subject)\n  - [III. Elementary Principles Of Composition](#iii-elementary-principles-of-composition)\n    - [Rule 8. Make the paragraph the unit of composition: one paragraph to each topic.](#rule-8-make-the-paragraph-the-unit-of-composition-one-paragraph-to-each-topic)\n    - [Rule 9. As a rule, begin each paragraph with a topic sentence, end it in conformity with the beginning.](#rule-9-as-a-rule-begin-each-paragraph-with-a-topic-sentence-end-it-in-conformity-with-the-beginning)\n    - [Rule 10. Use the active voice.](#rule-10-use-the-active-voice)\n    - [Rule 11. Put statements in positive form.](#rule-11-put-statements-in-positive-form)\n    - [Rule 12. Use definite, specific, concrete language.](#rule-12-use-definite-specific-concrete-language)\n    - [Rule 13. Omit needless words.](#rule-13-omit-needless-words)\n    - [Rule 14. Avoid a succession of loose sentences](#rule-14-avoid-a-succession-of-loose-sentences)\n    - [Rule 15. Express co-ordinate ideas in similar form.](#rule-15-express-co-ordinate-ideas-in-similar-form)\n    - [Rule 16. Keep related words together.](#rule-16-keep-related-words-together)\n    - [Rule 17. In summaries, keep to one tense.](#rule-17-in-summaries-keep-to-one-tense)\n    - [Rule 18. Place the emphatic words of a sentence at the end.](#rule-18-place-the-emphatic-words-of-a-sentence-at-the-end)\n  - [V. Words And Expressions Commonly Misused](#v-words-and-expressions-commonly-misused)\n\n## I. Introductory\n\nThis handbook summarizes the essentials of plain English style. It focuses on the rules of usage and principles of composition most often broken, offering a compact alternative to exhaustive manuals. Master the guidance here, then look to the best authors for finer points of style.\n\n## II. Elementary Rules Of Usage\n\n### Rule 1. Form the possessive singular of nouns by adding 's.\n\nFollow this rule whatever the final consonant. Thus write,\n\nCharles's friend\n\nBurns's poems\n\nthe witch's malice\n\nThis is the usage of the United States Government Printing Office and of the Oxford University Press.\n\nExceptions are the possessive of ancient proper names in *-es* and *-is*, the possessive *Jesus'*, and such forms as *for conscience' sake*, *for righteousness' sake*. But such forms as *Achilles' heel*, *Moses' laws*, *Isis' temple* are commonly replaced by\n\nthe heel of Achilles\n\nthe laws of Moses\n\nthe temple of Isis\n\nThe pronominal possessives *hers*, *its*, *theirs*, *yours*, and *oneself* have no apostrophe.\n\n### Rule 2. In a series of three or more terms with a single conjunction, use a comma after each term except the last.\n\nThus write,\n\nred, white, and blue\n\ngold, silver, or copper\n\nHe opened the letter, read it, and made a note of its contents.\n\nThis is also the usage of the Government Printing Office and of the Oxford University Press.\n\nIn the names of business firms the last comma is omitted, as,\n\nBrown, Shipley & Co.\n\n### Rule 3. Enclose parenthetic expressions between commas.\n\nThe best way to see a country, unless you are pressed for time, is to travel on foot.\n\nThis rule is difficult to apply; it is frequently hard to decide whether a single word, such as *however*, or a brief phrase, is or is not parenthetic. If the interruption to the flow of the sentence is but slight, the writer may safely omit the commas. But whether the interruption be slight or considerable, he must never insert one comma and omit the other. Such punctuation as\n\nMarjorie's husband, Colonel Nelson paid us a visit yesterday,\n\nor\n\nMy brother you will be pleased to hear, is now in perfect health,\n\nis indefensible.\n\nIf a parenthetic expression is preceded by a conjunction, place the first comma before the conjunction, not after it.\n\nHe saw us coming, and unaware that we had learned of his treachery, greeted us with a smile.\n\nAlways to be regarded as parenthetic and to be enclosed between commas (or, at the end of the sentence, between comma and period) are the following:\n\n\\(1\\) the year, when forming part of a date, and the day of the month, when following the day of the week:\n\nFebruary to July, 1916.\n\nApril 6, 1917.\n\nMonday, November 11, 1918.\n\n\\(2\\) the abbreviations *etc.* and *jr.*\n\n\\(3\\) non-restrictive relative clauses, that is, those which do not serve to identify or define the antecedent noun, and similar clauses introduced by conjunctions indicating time or place.\n\nThe audience, which had at first been indifferent, became more and more interested.\n\nIn this sentence the clause introduced by *which* does not serve to tell which of several possible audiences is meant; what audience is in question is supposed to be already known. The clause adds, parenthetically, a statement supplementing that in the main clause. The sentence is virtually a combination of two statements which might have been made independently:\n\nThe audience had at first been indifferent. It became more and more interested.\n\nCompare the restrictive relative clause, not set off by commas, in the sentence,\n\nThe candidate who best meets these requirements will obtain the place.\n\nHere the clause introduced by *who* does serve to tell which of several possible candidates is meant; the sentence cannot be split up into two independent statements.\n\nThe difference in punctuation in the two sentences following is based on the same principle:\n\nNether Stowey, where Coleridge wrote The Rime of the Ancient Mariner, is a few miles from Bridgewater.\n\nThe day will come when you will admit your mistake.\n\nNether Stowey is completely identified by its name; the statement about Coleridge is therefore supplementary and parenthetic. The *day* spoken of is identified only by the dependent clause, which is therefore restrictive.\n\nSimilar in principle to the enclosing of parenthetic expressions between commas is the setting off by commas of phrases or dependent clauses preceding or following the main clause of a sentence.\n\nPartly by hard fighting, partly by diplomatic skill, they enlarged their dominions to the east, and rose to royal rank with the possession of Sicily, exchanged afterwards for Sardinia.\n\nOther illustrations may be found in sentences quoted under Rules 4, 5, 6, 7, 16, and 18.\n\nThe writer should be careful not to set off independent clauses by commas: see under Rule 5.\n\n### Rule 4. Place a comma before a conjunction introducing a co-ordinate clause.\n\nThe early records of the city have disappeared, and the story of its first years can no longer be reconstructed.\n\nThe situation is perilous, but there is still one chance of escape.\n\nSentences of this type, isolated from their context, may seem to be in need of rewriting. As they make complete sense when the comma is reached, the second clause has the appearance of an afterthought. Further, *and* is the least specific of connectives. Used between independent clauses, it indicates only that a relation exists between them without defining that relation. In the example above, the relation is that of cause and result. The two sentences might be rewritten:\n\nAs the early records of the city have disappeared, the story of its first years can no longer be reconstructed.\n\nAlthough the situation is perilous, there is still one chance of escape.\n\nOr the subordinate clauses might be replaced by phrases:\n\nOwing to the disappearance of the early records of the city, the story of its first years can no longer be reconstructed.\n\nIn this perilous situation, there is still one chance of escape.\n\nBut a writer may err by making his sentences too uniformly compact and periodic, and an occasional loose sentence prevents the style from becoming too formal and gives the reader a certain relief. Consequently, loose sentences of the type first quoted are common in easy, unstudied writing. But a writer should be careful not to construct too many of his sentences after this pattern (see Rule 14).\n\nTwo-part sentences of which the second member is introduced by *as* (in the sense of *because*), *for*, *or*, *nor*, and *while* (in the sense of *and at the same time*) likewise require a comma before the conjunction.\n\nIf the second member is introduced by an adverb, a semicolon, not a comma, is required (see Rule 5). The connectives *so* and *yet* may be used either as adverbs or as conjunctions, accordingly as the second clause is felt to be co-ordinate or subordinate; consequently either mark of punctuation may be justified. But these uses of *so* (equivalent to *accordingly* or to *so that*) are somewhat colloquial and should, as a rule, be avoided in writing. A simple correction, usually serviceable, is to omit the word *so* and begin the first clause with *as* or *since*:\n\n| Original | Revision |\n| --- | --- |\n| I had never been in the place before; so I had difficulty in finding my way about. | As I had never been in the place before, I had difficulty in finding my way about. |\n\nIf a dependent clause, or an introductory phrase requiring to be set off by a comma, precedes the second independent clause, no comma is needed after the conjunction.\n\nThe situation is perilous, but if we are prepared to act promptly, there is still one chance of escape.\n\nWhen the subject is the same for both clauses and is expressed only once, a comma is required if the connective is *but*. If the connective is *and*, the comma should be omitted if the relation between the two statements is close or immediate.\n\nI have heard his arguments, but am still unconvinced.\n\nHe has had several years' experience and is thoroughly competent.\n\n### Rule 5. Do not join independent clauses by a comma.\n\nIf two or more clauses, grammatically complete and not joined by a conjunction, are to form a single compound sentence, the proper mark of punctuation is a semicolon.\n\nStevenson's romances are entertaining; they are full of exciting adventures.\n\nIt is nearly half past five; we cannot reach town before dark.\n\nIt is of course equally correct to write the above as two sentences each, replacing the semicolons by periods.\n\nStevenson's romances are entertaining. They are full of exciting adventures.\n\nIt is nearly half past five. We cannot reach town before dark.\n\nIf a conjunction is inserted the proper mark is a comma (Rule 4).\n\nStevenson's romances are entertaining, for they are full of exciting adventures.\n\nIt is nearly half past five, and we cannot reach town before dark.\n\nA comparison of the three forms given above will show clearly the advantage of the first. It is, at least in the examples given, better than the second form, because it suggests the close relationship between the two statements in a way that the second does not attempt, and better than the third, because briefer and therefore more forcible. Indeed it may be said that this simple method of indicating relationship between statements is one of the most useful devices of composition. The relationship, as above, is commonly one of cause or of consequence.\n\nNote that if the second clause is preceded by an adverb, such as *accordingly*, *besides*, *then*, *therefore*, or *thus*, and not by a conjunction, the semicolon is still required.\n\nTwo exceptions to the rule may be admitted. If the clauses are very short, and are alike in form, a comma is usually permissible:\n\nMan proposes, God disposes.\n\nThe gate swung apart, the bridge fell, the portcullis was drawn up.\n\nNote that in these examples the relation is not one of cause or consequence. Also in the colloquial form of expression,\n\nI hardly knew him, he was so changed,\n\na comma, not a semicolon, is required. But this form of expression is inappropriate in writing, except in the dialogue of a story or play, or perhaps in a familiar letter.\n\n### Rule 6. Do not break sentences in two.\n\nIn other words, do not use periods for commas.\n\nI met them on a Cunard liner several years ago. Coming home from Liverpool to New York.\n\nHe was an interesting talker. A man who had traveled all over the world and lived in half a dozen countries.\n\nIn both these examples, the first period should be replaced by a comma, and the following word begun with a small letter.\n\nIt is permissible to make an emphatic word or expression serve the purpose of a sentence and to punctuate it accordingly:\n\nAgain and again he called out. No reply.\n\nThe writer must, however, be certain that the emphasis is warranted, and that he will not be suspected of a mere blunder in syntax or in punctuation.\n\nRules 3, 4, 5, and 6 cover the most important principles in the punctuation of ordinary sentences; they should be so thoroughly mastered that their application becomes second nature.\n\n### Rule 7. A participial phrase at the beginning of a sentence must refer to the grammatical subject.\n\nWalking slowly down the road, he saw a woman accompanied by two children.\n\nThe word *walking* refers to the subject of the sentence, not to the woman. If the writer wishes to make it refer to the woman, he must recast the sentence:\n\nHe saw a woman accompanied by two children, walking slowly down the road.\n\nParticipial phrases preceded by a conjunction or by a preposition, nouns in apposition, adjectives, and adjective phrases come under the same rule if they begin the sentence.\n\n| Original | Revision |\n| --- | --- |\n| On arriving in Chicago, his friends met him at the station. | When he arrived (or, On his arrival) in Chicago, his friends met him at the station. |\n| A soldier of proved valor, they entrusted him with the defence of the city. | A soldier of proved valor, he was entrusted with the defence of the city. |\n| Young and inexperienced, the task seemed easy to me. | Young and inexperienced, I thought the task easy. |\n| Without a friend to counsel him, the temptation proved irresistible. | Without a friend to counsel him, he found the temptation irresistible. |\n\nSentences violating this rule are often ludicrous.\n\nBeing in a dilapidated condition, I was able to buy the house very cheap.\n\nWondering irresolutely what to do next, the clock struck twelve.\n\n## III. Elementary Principles Of Composition\n\n### Rule 8. Make the paragraph the unit of composition: one paragraph to each topic.\n\nIf the subject on which you are writing is of slight extent, or if you intend to treat it very briefly, there may be no need of subdividing it into topics. Thus a brief description, a brief summary of a literary work, a brief account of a single incident, a narrative merely outlining an action, the setting forth of a single idea, any one of these is best written in a single paragraph. After the paragraph has been written, examine it to see whether subdivision will not improve it.\n\nOrdinarily, however, a subject requires subdivision into topics, each of which should be made the subject of a paragraph. The object of treating each topic in a paragraph by itself is, of course, to aid the reader. The beginning of each paragraph is a signal to him that a new step in the development of the subject has been reached.\n\nThe extent of subdivision will vary with the length of the composition. For example, a short notice of a book or poem might consist of a single paragraph. One slightly longer might consist of two paragraphs:\n\n- A. Account of the work.\n- B. Critical discussion.\n\nA report on a poem, written for a class in literature, might consist of seven paragraphs:\n\n- A. Facts of composition and publication.\n- B. Kind of poem; metrical form.\n- C. Subject.\n- D. Treatment of subject.\n- E. For what chiefly remarkable.\n- F. Wherein characteristic of the writer.\n- G. Relationship to other works.\n\nThe contents of paragraphs C and D would vary with the poem. Usually, paragraph C would indicate the actual or imagined circumstances of the poem (the situation), if these call for explanation, and would then state the subject and outline its development. If the poem is a narrative in the third person throughout, paragraph C need contain no more than a concise summary of the action. Paragraph D would indicate the leading ideas and show how they are made prominent, or would indicate what points in the narrative are chiefly emphasized.\n\nA novel might be discussed under the heads:\n\n- A. Setting.\n- B. Plot.\n- C. Characters.\n- D. Purpose.\n\nAn historical event might be discussed under the heads:\n\n- A. What led up to the event.\n- B. Account of the event.\n- C. What the event led up to.\n\nIn treating either of these last two subjects, the writer would probably find it necessary to subdivide one or more of the topics here given.\n\nAs a rule, single sentences should not be written or printed as paragraphs. An exception may be made of sentences of transition, indicating the relation between the parts of an exposition or argument. Frequent exceptions are also necessary in textbooks, guidebooks, and other works in which many topics are treated briefly.\n\nIn dialogue, each speech, even if only a single word, is a paragraph by itself; that is, a new paragraph begins with each change of speaker. The application of this rule, when dialogue and narrative are combined, is best learned from examples in well-printed works of fiction.\n\n### Rule 9. As a rule, begin each paragraph with a topic sentence, end it in conformity with the beginning.\n\nAgain, the object is to aid the reader. The practice here recommended enables him to discover the purpose of each paragraph as he begins to read it, and to retain this purpose in mind as he ends it. For this reason, the most generally useful kind of paragraph, particularly in exposition and argument, is that in which\n\n\\(a\\) the topic sentence comes at or near the beginning;\n\n\\(b\\) the succeeding sentences explain or establish or develop the statement made in the topic sentence; and\n\n\\(c\\) the final sentence either emphasizes the thought of the topic sentence or states some important consequence.\n\nEnding with a digression, or with an unimportant detail, is particularly to be avoided.\n\nIf the paragraph forms part of a larger composition, its relation to what precedes, or its function as a part of the whole, may need to be expressed. This can sometimes be done by a mere word or phrase (*again*; *therefore*; *for the same reason*) in the topic sentence. Sometimes, however, it is expedient to precede the topic sentence by one or more sentences of introduction or transition. If more than one such sentence is required, it is generally better to set apart the transitional sentences as a separate paragraph.\n\nAccording to the writer's purpose, he may, as indicated above, relate the body of the paragraph to the topic sentence in one or more of several different ways. He may make the meaning of the topic sentence clearer by restating it in other forms, by defining its terms, by denying the contrary, by giving illustrations or specific instances; he may establish it by proofs; or he may develop it by showing its implications and consequences. In a long paragraph, he may carry out several of these processes.\n\n1 Now, to be properly enjoyed, a walking tour should be gone upon alone. 2 If you go in a company, or even in pairs, it is no longer a walking tour in anything but name; it is something else and more in the nature of a picnic. 3 A walking tour should be gone upon alone, because freedom is of the essence; because you should be able to stop and go on, and follow this way or that, as the freak takes you; and because you must have your own pace, and neither trot alongside a champion walker, nor mince in time with a girl. 4 And you must be open to all impressions and let your thoughts take colour from what you see. 5 You should be as a pipe for any wind to play upon. 6 “I cannot see the wit,” says Hazlitt, “of walking and talking at the same time. 7 When I am in the country, I wish to vegetate like the country,” which is the gist of all that can be said upon the matter. 8 There should be no cackle of voices at your elbow, to jar on the meditative silence of the morning. 9 And so long as a man is reasoning he cannot surrender himself to that fine intoxication that comes of much motion in the open air, that begins in a sort of dazzle and sluggishness of the brain, and ends in a peace that passes comprehension.—Stevenson, Walking Tours.\n\n1 Topic sentence. 2 The meaning made clearer by denial of the contrary. 3 The topic sentence repeated, in abridged form, and supported by three reasons; the meaning of the third (“you must have your own pace”) made clearer by denying the contrary. 4 A fourth reason, stated in two forms. 5 The same reason, stated in still another form. 6–7 The same reason as stated by Hazlitt. 8 Repetition, in paraphrase, of the quotation from Hazlitt. 9 Final statement of the fourth reason, in language amplified and heightened to form a strong conclusion.\n\n1 It was chiefly in the eighteenth century that a very different conception of history grew up. 2 Historians then came to believe that their task was not so much to paint a picture as to solve a problem; to explain or illustrate the successive phases of national growth, prosperity, and adversity. 3 The history of morals, of industry, of intellect, and of art; the changes that take place in manners or beliefs; the dominant ideas that prevailed in successive periods; the rise, fall, and modification of political constitutions; in a word, all the conditions of national well-being became the subject of their works. 4 They sought rather to write a history of peoples than a history of kings. 5 They looked especially in history for the chain of causes and effects. 6 They undertook to study in the past the physiology of nations, and hoped by applying the experimental method on a large scale to deduce some lessons of real value about the conditions on which the welfare of society mainly depend.—Lecky, The Political Value of History.\n\n1 Topic sentence. 2 The meaning of the topic sentence made clearer; the new conception of history defined. 3 The definition expanded. 4 The definition explained by contrast. 5 The definition supplemented: another element in the new conception of history. 6 Conclusion: an important consequence of the new conception of history.\n\nIn narration and description the paragraph sometimes begins with a concise, comprehensive statement serving to hold together the details that follow.\n\nThe breeze served us admirably.\n\nThe campaign opened with a series of reverses.\n\nThe next ten or twelve pages were filled with a curious set of entries.\n\nBut this device, if too often used, would become a mannerism. More commonly the opening sentence simply indicates by its subject with what the paragraph is to be principally concerned.\n\nAt length I thought I might return towards the stockade.\n\nHe picked up the heavy lamp from the table and began to explore.\n\nAnother flight of steps, and they emerged on the roof.\n\nThe brief paragraphs of animated narrative, however, are often without even this semblance of a topic sentence. The break between them serves the purpose of a rhetorical pause, throwing into prominence some detail of the action.\n\n### Rule 10. Use the active voice.\n\nThe active voice is usually more direct and vigorous than the passive:\n\nI shall always remember my first visit to Boston.\n\nThis is much better than\n\nMy first visit to Boston will always be remembered by me.\n\nThe latter sentence is less direct, less bold, and less concise. If the writer tries to make it more concise by omitting “by me,”\n\nMy first visit to Boston will always be remembered,\n\nit becomes indefinite: is it the writer, or some person undisclosed, or the world at large, that will always remember this visit?\n\nThis rule does not, of course, mean that the writer should entirely discard the passive voice, which is frequently convenient and sometimes necessary.\n\nThe dramatists of the Restoration are little esteemed to-day.\n\nModern readers have little esteem for the dramatists of the Restoration.\n\nThe first would be the right form in a paragraph on the dramatists of the Restoration; the second, in a paragraph on the tastes of modern readers. The need of making a particular word the subject of the sentence will often, as in these examples, determine which voice is to be used.\n\nAs a rule, avoid making one passive depend directly upon another.\n\n| Original | Revision |\n| --- | --- |\n| Gold was not allowed to be exported. | It was forbidden to export gold (The export of gold was prohibited). |\n| He has been proved to have been seen entering the building. | It has been proved that he was seen to enter the building. |\n\nIn both the examples above, before correction, the word properly related to the second passive is made the subject of the first.\n\nA common fault is to use as the subject of a passive construction a noun which expresses the entire action, leaving to the verb no function beyond that of completing the sentence.\n\n| Original | Revision |\n| --- | --- |\n| A survey of this region was made in 1900. | This region was surveyed in 1900. |\n| Mobilization of the army was rapidly effected. | The army was rapidly mobilized. |\n| Confirmation of these reports cannot be obtained. | These reports cannot be confirmed. |\n\nCompare the _sentence,_ “The export of gold was prohibited,” in which the predicate “was prohibited” expresses something not implied in “export.”\n\nThe habitual use of the active voice makes for forcible writing. This is true not only in narrative principally concerned with action, but in writing of any kind. Many a tame sentence of description or exposition can be made lively and emphatic by substituting a verb in the active voice for some such perfunctory expression as *there is*, or *could be heard*.\n\n| Original | Revision |\n| --- | --- |\n| There were a great number of dead leaves lying on the ground. | Dead leaves covered the ground. |\n| The sound of a guitar somewhere in the house could be heard. | Somewhere in the house a guitar hummed sleepily. |\n| The reason that he left college was that his health became impaired. | Failing health compelled him to leave college. |\n| It was not long before he was very sorry that he had said what he had. | He soon repented his words. |\n\n### Rule 11. Put statements in positive form.\n\nMake definite assertions. Avoid tame, colorless, hesitating, non-committal language. Use the word *not* as a means of denial or in antithesis, never as a means of evasion.\n\n| Original | Revision |\n| --- | --- |\n| He was not very often on time. | He usually came late. |\n| He did not think that studying Latin was much use. | He thought the study of Latin useless. |\n| The Taming of the Shrew is rather weak in spots. Shakespeare does not portray Katharine as a very admirable character, nor does Bianca remain long in memory as an important character in Shakespeare's works. | The women in The Taming of the Shrew are unattractive. Katharine is disagreeable, Bianca insignificant. |\n\nThe last example, before correction, is indefinite as well as negative. The corrected version, consequently, is simply a guess at the writer's intention.\n\nAll three examples show the weakness inherent in the word *not*. Consciously or unconsciously, the reader is dissatisfied with being told only what is not; he wishes to be told what is. Hence, as a rule, it is better to express even a negative in positive form.\n\n| Original | Revision |\n| --- | --- |\n| not honest | dishonest |\n| not important | trifling |\n| did not remember | forgot |\n| did not pay any attention to | ignored |\n| did not have much confidence in | distrusted |\n\nThe antithesis of negative and positive is strong:\n\nNot charity, but simple justice.\n\nNot that I loved Caesar less, but Rome the more.\n\nNegative words other than *not* are usually strong:\n\nThe sun never sets upon the British flag.\n\n### Rule 12. Use definite, specific, concrete language.\n\nPrefer the specific to the general, the definite to the vague, the concrete to the abstract.\n\n| Original | Revision |\n| --- | --- |\n| A period of unfavorable weather set in. | It rained every day for a week. |\n| He showed satisfaction as he took possession of his well-earned reward. | He grinned as he pocketed the coin. |\n| There is a general agreement among those who have enjoyed the experience that surf-riding is productive of great exhilaration. | All who have tried surf-riding agree that it is most exhilarating. |\n\nIf those who have studied the art of writing are in accord on any one point, it is on this, that the surest method of arousing and holding the attention of the reader is by being specific, definite, and concrete. Critics have pointed out how much of the effectiveness of the greatest writers, Homer, Dante, Shakespeare, results from their constant definiteness and concreteness. Browning, to cite a more modern author, affords many striking examples. Take, for instance, the lines from My Last Duchess,\n\nSir, 'twas all one! My favour at her breast,\n\nThe dropping of the daylight in the west,\n\nThe bough of cherries some officious fool\n\nBroke in the orchard for her, the white mule\n\nShe rode with round the terrace—all and each\n\nWould draw from her alike the approving speech,\n\nOr blush, at least,\n\nand those which end the poem,\n\nNotice Neptune, though,\n\nTaming a sea-horse, thought a rarity,\n\nWhich Claus of Innsbruck cast in bronze for me.\n\nThese words call up pictures. Recall how in The Bishop Orders his Tomb in St. Praxed's Church “the Renaissance spirit—its worldliness, inconsistency, pride, hypocrisy, ignorance of itself, love of art, of luxury, of good Latin,” to quote Ruskin's comment on the poem, is made manifest in specific details and in concrete terms.\n\nProse, in particular narrative and descriptive prose, is made vivid by the same means. If the experiences of Jim Hawkins and of David Balfour, of Kim, of Nostromo, have seemed for the moment real to countless readers, if in reading Carlyle we have almost the sense of being physically present at the taking of the Bastille, it is because of the definiteness of the details and the concreteness of the terms used. It is not that every detail is given; that would be impossible, as well as to no purpose; but that all the significant details are given, and not vaguely, but with such definiteness that the reader, in imagination, can project himself into the scene.\n\nIn exposition and in argument, the writer must likewise never lose his hold upon the concrete, and even when he is dealing with general principles, he must give particular instances of their application.\n\n“This superiority of specific expressions is clearly due to the effort required to translate words into thoughts. As we do not think in generals, but in particulars—as whenever any class of things is referred to, we represent it to ourselves by calling to mind individual members of it, it follows that when an abstract word is used, the hearer or reader has to choose, from his stock of images, one or more by which he may figure to himself the genus mentioned. In doing this, some delay must arise, some force be expended; and if by employing a specific term an appropriate image can be at once suggested, an economy is achieved, and a more vivid impression produced.”\n\nHerbert Spencer, from whose Philosophy of Style the preceding paragraph is quoted, illustrates the principle by the sentences:\n\n| Original | Revision |\n| --- | --- |\n| In proportion as the manners, customs, and amusements of a nation are cruel and barbarous, the regulations of their penal code will be severe. | In proportion as men delight in battles, bull-fights, and combats of gladiators, will they punish by hanging, burning, and the rack. |\n\n### Rule 13. Omit needless words.\n\nVigorous writing is concise. A sentence should contain no unnecessary words, a paragraph no unnecessary sentences, for the same reason that a drawing should have no unnecessary lines and a machine no unnecessary parts. This requires not that the writer make all his sentences short, or that he avoid all detail and treat his subjects only in outline, but that he make every word tell.\n\nMany expressions in common use violate this principle:\n\n| Original | Revision |\n| --- | --- |\n| the question as to whether | whether (the question whether) |\n| there is no doubt but that | no doubt (doubtless) |\n| used for fuel purposes | used for fuel |\n| he is a man who | he |\n| in a hasty manner | hastily |\n| this is a subject which | this subject |\n| His story is a strange one. | His story is strange. |\n\nIn especial the expression *the fact that* should be revised out of every sentence in which it occurs.\n\n| Original | Revision |\n| --- | --- |\n| owing to the fact that | since (because) |\n| in spite of the fact that | though (although) |\n| call your attention to the fact that | remind you (notify you) |\n| I was unaware of the fact that | I was unaware that (did not know) |\n| the fact that he had not succeeded | his failure |\n| the fact that I had arrived | my arrival |\n\nSee also under *case*, *character*, *nature*, *system* in Chapter V.\n\n*Who is*, *which was*, and the like are often superfluous.\n\n| Original | Revision |\n| --- | --- |\n| His brother, who is a member of the same firm | His brother, a member of the same firm |\n| Trafalgar, which was Nelson's last battle | Trafalgar, Nelson's last battle |\n\nAs positive statement is more concise than negative, and the active voice more concise than the passive, many of the examples given under Rules 11 and 12 illustrate this rule as well.\n\nA common violation of conciseness is the presentation of a single complex idea, step by step, in a series of sentences or independent clauses which might to advantage be combined into one.\n\n| Original | Revision |\n| --- | --- |\n| Macbeth was very ambitious. This led him to wish to become king of Scotland. The witches told him that this wish of his would come true. The king of Scotland at this time was Duncan. Encouraged by his wife, Macbeth murdered Duncan. He was thus enabled to succeed Duncan as king. (51 words.) | Encouraged by his wife, Macbeth achieved his ambition and realized the prediction of the witches by murdering Duncan and becoming king of Scotland in his place. (26 words.) |\n| There were several less important courses, but these were the most important, and although they did not come every day, they came often enough to keep you in such a state of mind that you never knew what your next move would be. (43 words.) | These, the most important courses of all, came, if not daily, at least often enough to keep one under constant strain. (21 words.) |\n\n### Rule 14. Avoid a succession of loose sentences\n\nThis rule refers especially to loose sentences of a particular type, those consisting of two co-ordinate clauses, the second introduced by a conjunction or relative. Although single sentences of this type may be unexceptionable (see under Rule 4), a series soon becomes monotonous and tedious.\n\nAn unskilful writer will sometimes construct a whole paragraph of sentences of this kind, using as connectives *and*, *but*, *so*, and less frequently, *who*, *which*, *when*, *where*, and *while*, these last in non-restrictive senses (see under Rule 3).\n\nThe third concert of the subscription series was given last evening, and a large audience was in attendance. Mr. Edward Appleton was the soloist, and the Boston Symphony Orchestra furnished the instrumental music. The former showed himself to be an artist of the first rank, while the latter proved itself fully deserving of its high reputation. The interest aroused by the series has been very gratifying to the Committee, and it is planned to give a similar series annually hereafter. The fourth concert will be given on Tuesday, May 10, when an equally attractive programme will be presented.\n\nApart from its triteness and emptiness, the paragraph above is weak because of the structure of its sentences, with their mechanical symmetry and sing-song. Contrast with them the sentences in the paragraphs quoted under Rule 9, or in any piece of good English prose, as the preface (Before the Curtain) to Vanity Fair.\n\nIf the writer finds that he has written a series of sentences of the type described, he should recast enough of them to remove the monotony, replacing them by simple sentences, by sentences of two clauses joined by a semicolon, by periodic sentences of two clauses, by sentences, loose or periodic, of three clauses—whichever best represent the real relations of the thought.\n\n### Rule 15. Express co-ordinate ideas in similar form.\n\nThis principle, that of parallel construction, requires that expressions of similar content and function should be outwardly similar. The likeness of form enables the reader to recognize more readily the likeness of content and function. Familiar instances from the Bible are the Ten Commandments, the Beatitudes, and the petitions of the Lord's Prayer.\n\nThe unskillful writer often violates this principle, from a mistaken belief that he should constantly vary the form of his expressions. It is true that in repeating a statement in order to emphasize it he may have need to vary its form. For illustration, see the paragraph from Stevenson quoted under Rule _9_. But apart from this, he should follow the principle of parallel construction.\n\n| Original | Revision |\n| --- | --- |\n| Formerly, science was taught by the textbook method, while now the laboratory method is employed. | Formerly, science was taught by the textbook method; now it is taught by the laboratory method. |\n\nThe left-hand version gives the impression that the writer is undecided or timid; he seems unable or afraid to choose one form of expression and hold to it. The right-hand version shows that the writer has at least made his choice and abided by it.\n\nBy this principle, an article or a preposition applying to all the members of a series must either be used only before the first term or else be repeated before each term.\n\n| Original | Revision |\n| --- | --- |\n| The French, the Italians, Spanish, and Portuguese | The French, the Italians, the Spanish, and the Portuguese |\n| In spring, summer, or in winter | In spring, summer, or winter (In spring, in summer, or in winter) |\n\nCorrelative expressions (*both, and*; *not, but*; *not only, but also*; *either, or*; *first, second, third*; and the like) should be followed by the same grammatical construction, that is, virtually, by the same part of speech. (Such combinations as “both Henry and I,” “not silk, but a cheap substitute,” are obviously within the rule.) Many violations of this rule (as the first three below) arise from faulty arrangement; others (as the last) from the use of unlike constructions.\n\n| Original | Revision |\n| --- | --- |\n| It was both a long ceremony and very tedious. | The ceremony was both long and tedious. |\n| A time not for words, but action. | A time not for words, but for action. |\n| Either you must grant his request or incur his ill will. | You must either grant his request or incur his ill will. |\n| My objections are, first, the injustice of the measure; second, that it is unconstitutional. | My objections are, first, that the measure is unjust; second, that it is unconstitutional. |\n\nSee also the third example under Rule 12 and the last under Rule 13.\n\nIt may be asked, what if a writer needs to express a very large number of similar ideas, say twenty? Must he write twenty consecutive sentences of the same pattern? On closer examination he will probably find that the difficulty is imaginary, that his twenty ideas can be classified in groups, and that he need apply the principle only within each group. Otherwise he had best avoid difficulty by putting his statements in the form of a table.\n\n### Rule 16. Keep related words together.\n\nThe position of the words in a sentence is the principal means of showing their relationship. The writer must therefore, so far as possible, bring together the words, and groups of words, that are related in thought, and keep apart those which are not so related.\n\nThe subject of a sentence and the principal verb should not, as a rule, be separated by a phrase or clause that can be transferred to the beginning.\n\n| Original | Revision |\n| --- | --- |\n| Wordsworth, in the fifth book of The Excursion, gives a minute description of this church. | In the fifth book of The Excursion, Wordsworth gives a minute description of this church. |\n| Cast iron, when treated in a Bessemer converter, is changed into steel. | By treatment in a Bessemer converter, cast iron is changed into steel. |\n\nThe objection is that the interposed phrase or clause needlessly interrupts the natural order of the main clause. Usually, however, this objection does not hold when the order is interrupted only by a relative clause or by an expression in apposition. Nor does it hold in periodic sentences in which the interruption is a deliberately used means of creating suspense (see examples under Rule 18).\n\nThe relative pronoun should come, as a rule, immediately after its antecedent.\n\n| Original | Revision |\n| --- | --- |\n| There was a look in his eye that boded mischief. | In his eye was a look that boded mischief. |\n| He wrote three articles about his adventures in Spain, which were published in Harper's Magazine. | He published in Harper's Magazine three articles about his adventures in Spain. |\n| This is a portrait of Benjamin Harrison, grandson of William Henry Harrison, who became President in 1889. | This is a portrait of Benjamin Harrison, grandson of William Henry Harrison. He became President in 1889. |\n\nIf the antecedent consists of a group of words, the relative comes at the end of the group, unless this would cause ambiguity.\n\nThe Superintendent of the Chicago Division, who\n\n| Original | Revision |\n| --- | --- |\n| A proposal to amend the Sherman Act, which has been variously judged. | A proposal, which has been variously judged, to amend the Sherman Act. |\n| — | A proposal to amend the much-debated Sherman Act. |\n| The grandson of William Henry Harrison, who | William Henry Harrison's grandson, who |\n\nA noun in apposition may come between antecedent and relative, because in such a combination no real ambiguity can arise.\n\nThe Duke of York, his brother, who was regarded with hostility by the Whigs\n\nModifiers should come, if possible, next to the word they modify. If several expressions modify the same word, they should be so arranged that no wrong relation is suggested.\n\n| Original | Revision |\n| --- | --- |\n| All the members were not present. | Not all the members were present. |\n| He only found two mistakes. | He found only two mistakes. |\n| Major R. E. Joyce will give a lecture on Tuesday evening in Bailey Hall, to which the public is invited, on “My Experiences in Mesopotamia” at eight P. M. | On Tuesday evening at eight P. M., Major R. E. Joyce will give in Bailey Hall a lecture on “My Experiences in Mesopotamia.” The public is invited. |\n\n### Rule 17. In summaries, keep to one tense.\n\nIn summarizing the action of a drama, the writer should always use the present tense. In summarizing a poem, story, or novel, he should preferably use the present, though he may use the past if he prefers. If the summary is in the present tense, antecedent action should be expressed by the perfect; if in the past, by the past perfect.\n\nAn unforeseen chance prevents Friar John from delivering Friar Lawrence's letter to Romeo. Meanwhile, owing to her father's arbitrary change of the day set for her wedding, Juliet has been compelled to drink the potion on Tuesday night, with the result that Balthasar informs Romeo of her supposed death before Friar Lawrence learns of the non-delivery of the letter.\n\nBut whichever tense be used in the summary, a past tense in indirect discourse or in indirect question remains unchanged.\n\nThe Friar confesses that it was he who married them.\n\nApart from the exceptions noted, whichever tense the writer chooses, he should use throughout. Shifting from one tense to the other gives the appearance of uncertainty and irresolution (compare Rule 15).\n\nIn presenting the statements or the thought of some one else, as in summarizing an essay or reporting a speech, the writer should avoid intercalating such expressions as “he said,” “he stated,” “the speaker added,” “the speaker then went on to say,” “the author also thinks,” or the like. He should indicate clearly at the outset, once for all, that what follows is summary, and then waste no words in repeating the notification.\n\nIn notebooks, in newspapers, in handbooks of literature, summaries of one kind or another may be indispensable, and for children in primary schools it is a useful exercise to retell a story in their own words. But in the criticism or interpretation of literature the writer should be careful to avoid dropping into summary. He may find it necessary to devote one or two sentences to indicating the subject, or the opening situation, of the work he is discussing; he may cite numerous details to illustrate its qualities. But he should aim to write an orderly discussion supported by evidence, not a summary with occasional comment. Similarly, if the scope of his discussion includes a number of works, he will as a rule do better not to take them up singly in chronological order, but to aim from the beginning at establishing general conclusions.\n\n### Rule 18. Place the emphatic words of a sentence at the end.\n\nThe proper place in the sentence for the word, or group of words, which the writer desires to make most prominent is usually the end.\n\n| Original | Revision |\n| --- | --- |\n| Humanity has hardly advanced in fortitude since that time, though it has advanced in many other ways. | Humanity, since that time, has advanced in many other ways, but it has hardly advanced in fortitude. |\n| This steel is principally used for making razors, because of its hardness. | Because of its hardness, this steel is principally used in making razors. |\n\nThe word or group of words entitled to this position of prominence is usually the logical predicate, that is, the *new* element in the sentence, as it is in the second example.\n\nThe effectiveness of the periodic sentence arises from the prominence which it gives to the main statement.\n\nFour centuries ago, Christopher Columbus, one of the Italian mariners whom the decline of their own republics had put at the service of the world and of adventure, seeking for Spain a westward passage to the Indies as a set-off against the achievements of Portuguese discoverers, lighted on America.\n\nWith these hopes and in this belief I would urge you, laying aside all hindrance, thrusting away all private aims, to devote yourself unswervingly and unflinchingly to the vigorous and successful prosecution of this war.\n\nThe other prominent position in the sentence is the beginning. Any element in the sentence, other than the subject, may become emphatic when placed first.\n\nDeceit or treachery he could never forgive.\n\nSo vast and rude, fretted by the action of nearly three thousand years, the fragments of this architecture may often seem, at first sight, like works of nature.\n\nA subject coming first in its sentence may be emphatic, but hardly by its position alone. In the sentence,\n\nGreat kings worshipped at his shrine,\n\nthe emphasis upon *kings* arises largely from its meaning and from the context. To receive special emphasis, the subject of a sentence must take the position of the predicate.\n\nThrough the middle of the valley flowed a winding stream.\n\nThe principle that the proper place for what is to be made most prominent is the end applies equally to the words of a sentence, to the sentences of a paragraph, and to the paragraphs of a composition.\n\n## V. Words And Expressions Commonly Misused\n\n(Some of the forms here listed, as *like I did*, are downright bad English; others, as the split infinitive, have their defenders, but are in such general disfavor that it is at least inadvisable to use them; still others, as *case*, *factor*, *feature*, *interesting*, *one of the most*, are good in their place, but are constantly obtruding themselves into places where they have no right to be. If the writer will make it his purpose from the beginning to express accurately his own individual thought, and will refuse to be satisfied with a ready-made formula that saves him the trouble of doing so, this last set of expressions will cause him little trouble. But if he finds that in a moment of inadvertence he has used one of them, his proper course will probably be not to patch up the sentence by substituting one word or set of words for another, but to recast it completely, as illustrated in a number of examples below and in others under Rules 12 and 13.)\n\n**All right.** Idiomatic in familiar speech as a detached phrase in the sense, “Agreed,” or “Go ahead.” In other uses better avoided. Always written as two words.\n\n**As good or better than.** Expressions of this type should be corrected by rearranging the sentence.\n\n| Original | Revision |\n| --- | --- |\n| My opinion is as good or better than his. | My opinion is as good as his, or better (if not better). |\n\n**As to whether.** *Whether* is sufficient; see under Rule 13.\n\n**Bid.** Takes the infinitive without *to*. The past tense in the sense, _“ordered,”_ is *bade*.\n\n**But.** Unnecessary after *doubt* and *help*.\n\n| Original | Revision |\n| --- | --- |\n| I have no doubt but that | I have no doubt that |\n| He could not help see but that | He could not help seeing that |\n\nThe too frequent use of *but* as a conjunction leads to the fault discussed under Rule 14. A loose sentence formed with *but* can always be converted into a periodic sentence formed with *although*, as illustrated under Rule 4.\n\nParticularly awkward is the following of one *but* by another, making a contrast to a contrast or a reservation to a reservation. This is easily corrected by re-arrangement.\n\n| Original | Revision |\n| --- | --- |\n| America had vast resources, but she seemed almost wholly unprepared for war. But within a year she had created an army of four million men. | America seemed almost wholly unprepared for war, but she had vast resources. Within a year she had created an army of four million men. |\n\n**Can.** Means *am (is, are) able*. Not to be used as a substitute for *may*.\n\n**Case.** The Concise Oxford Dictionary begins its definition of this word: “instance of a thing's occurring; usual state of affairs.” In these two senses, the word is usually unnecessary.\n\n| Original | Revision |\n| --- | --- |\n| In many cases, the rooms were poorly ventilated. | Many of the rooms were poorly ventilated. |\n| It has rarely been the case that any mistake has been made. | Few mistakes have been made. |\n\nSee Wood, Suggestions to Authors, pp. 68–71, and Quiller-Couch, The Art of Writing, pp. 103–106.\n\n**Certainly.** Used indiscriminately by some writers, much as others use *very*, to intensify any and every statement. A mannerism of this kind, bad in speech, is even worse in writing.\n\n**Character.** Often simply redundant, used from a mere habit of wordiness.\n\n| Original | Revision |\n| --- | --- |\n| Acts of a hostile character | Hostile acts |\n\n**Claim, vb.** With object-noun, means *lay claim to*. May be used with a dependent clause if this sense is clearly involved: “He claimed that he was the sole surviving heir.” (But even here, “claimed to be” would be better.) Not to be used as a substitute for *declare*, *maintain*, or *charge*.\n\n**Clever.** This word has been greatly overused; it is best restricted to ingenuity displayed in small matters.\n\n**Compare.** To *compare to* is to point out or imply resemblances, between objects regarded as essentially of different order; to *compare with* is mainly to point out differences, between objects regarded as essentially of the same order. Thus life has been compared to a pilgrimage, to a drama, to a battle; Congress may be compared with the British Parliament. Paris has been compared to ancient Athens; it may be compared with modern London.\n\n**Consider.** Not followed by *as* when it means “believe to be.” “I consider him thoroughly competent.” Compare, “The lecturer considered Cromwell first as soldier and second as administrator,” where “considered” means “examined” or “discussed.”\n\n**Data.** A plural, like *phenomena* and *strata*.\n\nThese data were tabulated.\n\n**Dependable.** A needless substitute for *reliable*, *trustworthy*.\n\n**Different than.** Not permissible. Substitute *different from*, *other than*, or *unlike*.\n\n**Divided into.** Not to be misused for *composed of*. The line is sometimes difficult to draw; doubtless plays are divided into acts, but poems are composed of stanzas.\n\n**Don't.** Contraction of *do not*. The contraction of *does not* is *doesn't*.\n\n**Due to.** Incorrectly used for *through*, *because of*, or *owing to*, in adverbial phrases: “He lost the first game, due to carelessness.” In correct use related as predicate or as modifier to a particular noun: “This invention is due to Edison;” “losses due to preventable fires.”\n\n**Folk.** A collective noun, equivalent to *people*. Use the singular form only.\n\n**Effect.** As noun, means *result*; as verb, means *_to_ bring about*, *accomplish* (not to be confused with *affect*, which means “to influence”).\n\nAs noun, often loosely used in perfunctory writing about fashions, music, painting, and other arts: “an Oriental effect;” “effects in pale green;” “very delicate effects;” “broad effects;” “subtle effects;” “a charming effect was produced by.” The writer who has a definite meaning to express will not take refuge in such vagueness.\n\n**Etc.** Equivalent to *and the rest*, *and so forth*, and hence not to be used if one of these would be insufficient, that is, if the reader would be left in doubt as to any important particulars. Least open to objection when it represents the last terms of a list already given in full, or immaterial words at the end of a quotation.\n\nAt the end of a list introduced by *such as*, *for example*, or any similar expression, *etc.* is incorrect.\n\n**Fact.** Use this word only of matters of a kind capable of direct verification, not of matters of judgment. That a particular event happened on a given date, that lead melts at a certain temperature, are facts. But such conclusions as that Napoleon was the greatest of modern generals, or that the climate of California is delightful, however incontestable they _may be_, are not properly facts.\n\nOn the formula *the fact that*, see under Rule 13.\n\n**Factor.** A hackneyed word; the expressions of which it forms part can usually be replaced by something more direct and idiomatic.\n\n| Original | Revision |\n| --- | --- |\n| His superior training was the great factor in his winning the match. | He won the match by being better trained. |\n| Heavy artillery has become an increasingly important factor in deciding battles. | Heavy artillery has played a constantly larger part in deciding battles. |\n\n**Feature.** Another hackneyed word; like *factor* it usually adds nothing to the sentence in which it occurs.\n\n| Original | Revision |\n| --- | --- |\n| A feature of the entertainment especially worthy of mention was the singing of Miss A. | (Better use the same number of words to tell what Miss A. sang, or if the programme has already been given, to tell how she sang.) |\n\nAs a verb, in the advertising sense of *offer as a special attraction*, to be avoided.\n\n**Fix.** Colloquial in America for *arrange*, *prepare*, *mend*. In writing restrict it to its literary senses, *fasten*, *make firm or immovable*, etc.\n\n**Get.** The colloquial *have got* for *have* should not be used in writing. The preferable form of the participle is *got*.\n\n**He is a man who.** A common type of redundant expression; see Rule 13.\n\n| Original | Revision |\n| --- | --- |\n| He is a man who is very ambitious. | He is very ambitious. |\n| Spain is a country which I have always wanted to visit. | I have always wanted to visit Spain. |\n\n**Help.** See under **But**.\n\n**However.** In the meaning *nevertheless*, not to come first in its sentence or clause.\n\n| Original | Revision |\n| --- | --- |\n| The roads were almost impassable. However, we at last succeeded in reaching camp. | The roads were almost impassable. At last, however, we succeeded in reaching camp. |\n\nWhen *however* comes first, it means *in whatever way* or *to whatever extent*.\n\nHowever you advise him, he will probably do as he thinks best.\n\nHowever discouraging the prospect, he never lost heart.\n\n**Interesting.** Avoid this word as a perfunctory means of introduction. Instead of announcing that what you are about to tell is interesting, make it so.\n\n| Original | Revision |\n| --- | --- |\n| An interesting story is told of | (Tell the story without preamble.) |\n| In connection with the anticipated visit of Mr. B. to America, it is interesting to recall that he | Mr. B., who it is expected will soon visit America |\n\n**Kind of.** Not to be used as a substitute for *rather* (before adjectives and verbs), or except in familiar style, for *something like* (before nouns). Restrict it to its literal sense: “Amber is a kind of fossil resin;” “I dislike that kind of notoriety.” The same holds true of *sort of*.\n\n**Less.** Should not be misused for *fewer*.\n\n| Original | Revision |\n| --- | --- |\n| He had less men than in the previous campaign | He had fewer men than in the previous campaign |\n\n*Less* refers to quantity, *fewer* to number. “His troubles are less than mine” means “His troubles are not so great as mine.” “His troubles are fewer than mine” means “His troubles are not so numerous as mine.” It is, however, correct to say, “The signers of the petition were less than a hundred,” where the round number *a hundred* is something like a collective noun, and *less* is thought of as meaning a less quantity or amount.\n\n**Like.** Not to be misused for *as*. *Like* governs nouns and pronouns; before phrases and clauses the equivalent word is *as*.\n\n| Original | Revision |\n| --- | --- |\n| We spent the evening like in the old days. | We spent the evening as in the old days. |\n| He thought like I did. | He thought as I did (like me). |\n\n**Line, along these lines.** *Line* in the sense of *course of procedure*, *conduct*, *thought*, is allowable, but has been so much overworked, particularly in the phrase *along these lines*, that a writer who aims at freshness or originality had better discard it entirely.\n\n| Original | Revision |\n| --- | --- |\n| Mr. B. also spoke along the same lines. | Mr. B. also spoke, to the same effect. |\n| He is studying along the line of French literature. | He is studying French literature. |\n\n**Literal, literally.** Often incorrectly used in support of exaggeration or violent metaphor.\n\n| Original | Revision |\n| --- | --- |\n| A literal flood of abuse. | A flood of abuse. |\n| Literally dead with fatigue | Almost dead with fatigue (dead tired) |\n\n**Lose out.** Meant to be more emphatic than *lose*, but actually less so, because of its commonness. The same holds true of *try out*, *win out*, *sign up*, *register up*. With a number of verbs, *out* and *up* form idiomatic combinations: *find out*, *run out*, *turn out*, *cheer up*, *dry up*, *make up*, and others, each distinguishable in meaning from the simple verb. *Lose out* is not.\n\n**Most.** Not to be used for *almost*.\n\n| Original | Revision |\n| --- | --- |\n| Most everybody | Almost everybody |\n| Most all the time | Almost all the time |\n\n**Nature.** Often simply redundant, used like *character*.\n\n| Original | Revision |\n| --- | --- |\n| Acts of a hostile _nature_ | Hostile acts |\n\nOften vaguely used in such expressions as a “lover of nature;” “poems about nature.” Unless more specific statements follow, the reader cannot tell whether the poems have to do with natural scenery, rural life, the sunset, the untracked wilderness, or the habits of squirrels.\n\n**Near by.** Adverbial phrase, not yet fully accepted as good English, though the analogy of *close by* and *hard by* seems to justify it. *Near*, or *near at hand*, is as good, if not better.\n\nNot to be used as an adjective; use *neighboring*.\n\n**Oftentimes, ofttimes.** Archaic forms, no longer in good use. The modern word is *often*.\n\n**One hundred and one.** Retain the *and* in this and similar expressions, in accordance with the unvarying usage of English prose from Old English times.\n\n**One of the most.** Avoid beginning essays or paragraphs with this formula, as, “One of the most interesting developments of modern science is, etc.;” “Switzerland is one of the most interesting countries of Europe.” There is nothing wrong in this; it is simply threadbare and forcible-feeble.\n\nA common blunder is to use a singular verb in a relative clause following this or a similar expression, when the relative is the subject.\n\n| Original | Revision |\n| --- | --- |\n| One of the ablest men that has attacked this problem. | One of the ablest men that have attacked this problem. |\n\n**Participle for verbal noun.**\n\n| Original | Revision |\n| --- | --- |\n| Do you mind me asking a question? | Do you mind my asking a question? |\n| There was little prospect of the Senate accepting even this compromise. | There was little prospect of the Senate's accepting even this compromise. |\n\nIn the left-hand column, *asking* and *accepting* are present participles; in the right-hand column, they are verbal nouns (gerunds). The construction shown in the left-hand column is occasionally found, and has its defenders. Yet it is easy to see that the second sentence has to do not with a prospect of the Senate, but with a prospect of accepting. In this example, at least, the construction is plainly illogical.\n\nAs the authors of The King's English point out, there are sentences apparently, but not really, of this type, in which the possessive is not called for.\n\nI cannot imagine Lincoln refusing his assent to this measure.\n\nIn this sentence, what the writer cannot imagine is Lincoln himself, in the act of refusing his assent. Yet the meaning would be virtually the same, except for a slight loss of vividness, if he had written,\n\nI cannot imagine Lincoln's refusing his assent to this measure.\n\nBy using the possessive, the writer will always be on the safe side.\n\nIn the examples above, the subject of the action is a single, unmodified term, immediately preceding the verbal noun, and the construction is as good as any that could be used. But in any sentence in which it is a mere clumsy substitute for something simpler, or in which the use of the possessive is awkward or impossible, should of course be recast.\n\n| Original | Revision |\n| --- | --- |\n| In the event of a reconsideration of the whole matter's becoming necessary | If it should become necessary to reconsider the whole matter |\n| There was great dissatisfaction with the decision of the arbitrators being favorable to the company. | There was great dissatisfaction that the arbitrators should have decided in favor of the company. |\n\n**People.** *The people* is a political term, not to be confused with *the public*. From the people comes political support or opposition; from the public comes artistic appreciation or commercial patronage.\n\n**Phase.** Means a stage of transition or development: “the phases of the moon;” “the last phase.” Not to be used for *aspect* or *topic*.\n\n| Original | Revision |\n| --- | --- |\n| Another phase of the subject | Another point (another question) |\n\n**Possess.** Not to be used as a mere substitute for *have* or *own*.\n\n| Original | Revision |\n| --- | --- |\n| He possessed great courage. | He had great courage (was very brave). |\n| He was the fortunate possessor of | He owned |\n\n**Prove.** The past participle is *proved*.\n\n**Respective, respectively.** These words may usually be omitted with advantage.\n\n| Original | Revision |\n| --- | --- |\n| Works of fiction are listed under the names of their respective authors. | Works of fiction are listed under the names of their authors. |\n| The one mile and two mile runs were won by Jones and Cummings respectively. | The one mile and two mile runs were won by Jones and by Cummings. |\n\nIn some kinds of formal writing, as geometrical proofs, it may be necessary to use *respectively*, but it should not appear in writing on ordinary subjects.\n\n**Shall, Will.** The future tense requires *shall* for the first person, *will* for the second and third. The formula to express the speaker's belief regarding his future action or state is *I shall*; *I will* expresses his determination or his consent.\n\n**Should.** See under **Would**.\n\n**So.** Avoid, in writing, the use of *so* as an intensifier: “so good;” “so warm;” “so delightful.”\n\nOn the use of *so* to introduce clauses, see Rule 4.\n\n**Sort of.** See under **Kind of**.\n\n**Split Infinitive.** There is precedent from the fourteenth century downward for interposing an adverb between *to* and the infinitive which it governs, but the construction is in disfavor and is avoided by nearly all careful writers.\n\n| Original | Revision |\n| --- | --- |\n| To diligently inquire | To inquire diligently |\n\n**State.** Not to be used as a mere substitute for *say*, *remark*. Restrict it to the sense of *express fully or clearly*, as, “He refused to state his objections.”\n\n**Student Body.** A needless and awkward expression meaning no more than the simple word *students*.\n\n| Original | Revision |\n| --- | --- |\n| A member of the student body | A student |\n| Popular with the student body | Liked by the students |\n| The student body passed resolutions. | The students passed resolutions. |\n\n**System.** Frequently used without need.\n\n| Original | Revision |\n| --- | --- |\n| Dayton has adopted the commission system of _government._ | Dayton has adopted government by commission. |\n| The dormitory system | Dormitories |\n\n**Thanking You in Advance.** This sounds as if the writer meant, “It will not be worth my while to write to you again.” In making your request, write, “Will you please,” or “I shall be obliged,” and if anything further seems necessary write a letter of acknowledgment later.\n\n**They.** A common inaccuracy is the use of the plural pronoun when the antecedent is a distributive expression such as *each*, *each one*, *everybody*, *every one*, *many a man*, which, though implying more than one person, requires the pronoun to be in the singular. Similar to this, but with even less justification, is the use of the plural pronoun with the antecedent *anybody*, *any one*, *somebody*, *some one*, the intention being either to avoid the awkward “he or she,” or to avoid committing oneself to either. Some bashful speakers even say, “A friend of mine told me that they, etc.”\n\nUse *he* with all the above words, unless the antecedent is or must be feminine.\n\n**Very.** Use this word sparingly. Where emphasis is necessary, use words strong in themselves.\n\n**Viewpoint.** Write *point of view*, but do not misuse this, as many do, for *view* or *opinion*.\n\n**While.** Avoid the indiscriminate use of this word for *and*, *but*, and *although*. Many writers use it frequently as a substitute for *and* or *but*, either from a mere desire to vary the connective, or from uncertainty which of the two connectives is the more appropriate. In this use it is best replaced by a semicolon.\n\n| Original | Revision |\n| --- | --- |\n| The office and salesrooms are on the ground floor, while the rest of the building is devoted to manufacturing. | The office and salesrooms are on the ground floor; the rest of the building is devoted to manufacturing. |\n\nIts use as a virtual equivalent of *although* is allowable in sentences where this leads to no ambiguity or absurdity.\n\nWhile I admire his energy, I wish it were employed in a better cause.\n\nThis is entirely correct, as shown by the paraphrase,\n\nI admire his energy; at the same time I wish it were employed in a better cause.\n\nCompare:\n\n| Original | Revision |\n| --- | --- |\n| While the temperature reaches 90 or 95 degrees in the daytime, the nights are often chilly. | Although the temperature reaches 90 or 95 degrees in the daytime, the nights are often chilly. |\n\nThe paraphrase,\n\nThe temperature reaches 90 or 95 degrees in the daytime; at the same time the nights are often chilly,\n\nshows why the use of *while* is incorrect.\n\nIn general, the writer will do well to use *while* only with strict literalness, in the sense of *during the time that*.\n\n**Whom.** Often incorrectly used for *who* before *he said* or similar expressions, when it is really the subject of a following verb.\n\n| Original | Revision |\n| --- | --- |\n| His brother, whom he said would send him the money | His brother, who he said would send him the money |\n| The man whom he thought was his friend | The man who (that) he thought was his friend (whom he thought his friend) |\n\n**Worth while.** Overworked as a term of vague approval and (with *not*) of disapproval. Strictly applicable only to actions: “Is it worth while to telegraph?”\n\n| Original | Revision |\n| --- | --- |\n| His books are not worth while. | His books are not worth reading (are not worth one's while to read; do not repay reading; are worthless). |\n\nThe use of *worth while* before a noun (“a worth while story”) is indefensible.\n\n**Would.** A conditional statement in the first person requires *should*, not *would*.\n\nI should not have succeeded without his help.\n\nThe equivalent of *shall* in indirect quotation after a verb in the past tense is *should*, not *would*.\n\nHe predicted that before long we should have a great surprise.\n\nTo express habitual or repeated action, the past tense, without *would*, is usually sufficient, and from its brevity, more emphatic.\n\n| Original | Revision |\n| --- | --- |\n| Once a year he would visit the old mansion. | Once a year he visited the old mansion. |\n"
      },
      "plugins": [
        {
          "name": "workflows",
          "source": "./",
          "description": "Unified development, data science, and writing workflows with TDD enforcement and output-first verification",
          "version": "2.33.0",
          "category": "development",
          "tags": [
            "development",
            "data-science",
            "writing",
            "tdd",
            "workflows"
          ],
          "categories": [
            "data-science",
            "development",
            "tdd",
            "workflows",
            "writing"
          ],
          "install_commands": [
            "/plugin marketplace add edwinhu/workflows",
            "/plugin install workflows@edwinhu-plugins"
          ]
        },
        {
          "name": "tinymist-lsp",
          "source": "./plugins/tinymist-lsp",
          "description": "Typst language server integration with tinymist for code intelligence, compilation, and preview",
          "version": "1.0.0",
          "category": "development",
          "tags": [
            "typst",
            "lsp",
            "tinymist",
            "typesetting"
          ],
          "lspServers": {
            "tinymist": {
              "command": "tinymist",
              "args": [
                "lsp"
              ],
              "extensionToLanguage": {
                ".typ": "typst"
              }
            }
          },
          "categories": [
            "development",
            "lsp",
            "tinymist",
            "typesetting",
            "typst"
          ],
          "install_commands": [
            "/plugin marketplace add edwinhu/workflows",
            "/plugin install tinymist-lsp@edwinhu-plugins"
          ]
        }
      ]
    }
  ]
}