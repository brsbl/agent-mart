{
  "author": {
    "id": "avifenesh",
    "display_name": "Avi Fenesh",
    "avatar_url": "https://avatars.githubusercontent.com/u/55848801?u=97b1a6138c4690d34b592a18d0a4e393220e3fe5&v=4"
  },
  "marketplaces": [
    {
      "name": "agentsys",
      "version": "5.1.0",
      "description": "13 specialized plugins for AI workflow automation - task orchestration, PR workflow, slop detection, code review, drift detection, enhancement analysis, documentation sync, repo mapping, perf investigations, topic research, agent config linting, cross-tool AI consultation, and structured AI debate",
      "repo_full_name": "avifenesh/agentsys",
      "repo_url": "https://github.com/avifenesh/agentsys",
      "repo_description": "AI writes code. This automates everything else · 13 plugins · 42 agents · 28 skills · for Claude Code, OpenCode, Codex.",
      "signals": {
        "stars": 437,
        "forks": 44,
        "pushed_at": "2026-02-18T09:16:37Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"agentsys\",\n  \"description\": \"13 specialized plugins for AI workflow automation - task orchestration, PR workflow, slop detection, code review, drift detection, enhancement analysis, documentation sync, repo mapping, perf investigations, topic research, agent config linting, cross-tool AI consultation, and structured AI debate\",\n  \"version\": \"5.1.0\",\n  \"owner\": {\n    \"name\": \"Avi Fenesh\",\n    \"url\": \"https://github.com/avifenesh\"\n  },\n  \"repository\": \"https://github.com/avifenesh/agentsys\",\n  \"keywords\": [\n    \"ai\",\n    \"llm\",\n    \"agents\",\n    \"agentic\",\n    \"claude-code\",\n    \"opencode\",\n    \"codex\",\n    \"mcp\",\n    \"automation\",\n    \"workflow\",\n    \"code-review\",\n    \"multi-agent\"\n  ],\n  \"plugins\": [\n    {\n      \"name\": \"next-task\",\n      \"source\": \"./plugins/next-task\",\n      \"description\": \"Master workflow orchestrator: autonomous workflow with model optimization (opus/sonnet/haiku), two-file state management, workflow enforcement gates, 14 specialist agents\",\n      \"version\": \"5.1.0\",\n      \"category\": \"productivity\"\n    },\n    {\n      \"name\": \"ship\",\n      \"source\": \"./plugins/ship\",\n      \"description\": \"Complete PR workflow: commit to production, skips review when called from next-task, removes task from registry on cleanup, automatic rollback\",\n      \"version\": \"5.1.0\",\n      \"category\": \"deployment\"\n    },\n    {\n      \"name\": \"deslop\",\n      \"source\": \"./plugins/deslop\",\n      \"description\": \"3-phase AI slop detection: regex patterns (HIGH), multi-pass analyzers (MEDIUM), CLI tools (LOW)\",\n      \"version\": \"5.1.0\",\n      \"category\": \"development\"\n    },\n    {\n      \"name\": \"audit-project\",\n      \"source\": \"./plugins/audit-project\",\n      \"description\": \"Multi-agent iterative code review until zero issues remain\",\n      \"version\": \"5.1.0\",\n      \"category\": \"development\"\n    },\n    {\n      \"name\": \"drift-detect\",\n      \"source\": \"./plugins/drift-detect\",\n      \"description\": \"Deep repository analysis to realign project plans with code reality - detects drift, gaps, and creates prioritized reconstruction plans\",\n      \"version\": \"5.1.0\",\n      \"category\": \"productivity\"\n    },\n    {\n      \"name\": \"enhance\",\n      \"source\": \"./plugins/enhance\",\n      \"description\": \"Master enhancement orchestrator: parallel analyzer execution for plugins, agents, docs, CLAUDE.md, and prompts with unified reporting\",\n      \"version\": \"5.1.0\",\n      \"category\": \"development\"\n    },\n    {\n      \"name\": \"sync-docs\",\n      \"source\": \"./plugins/sync-docs\",\n      \"description\": \"Standalone documentation sync: find outdated refs, update CHANGELOG, flag stale examples based on code changes\",\n      \"version\": \"5.1.0\",\n      \"category\": \"development\"\n    },\n    {\n      \"name\": \"repo-map\",\n      \"source\": \"./plugins/repo-map\",\n      \"description\": \"AST-based repository map generation using ast-grep with incremental updates for faster drift analysis\",\n      \"version\": \"5.1.0\",\n      \"category\": \"development\"\n    },\n    {\n      \"name\": \"perf\",\n      \"source\": \"./plugins/perf\",\n      \"description\": \"Rigorous performance investigation workflow with baselines, profiling, hypotheses, and evidence-backed decisions\",\n      \"version\": \"5.1.0\",\n      \"category\": \"development\"\n    },\n    {\n      \"name\": \"learn\",\n      \"source\": \"./plugins/learn\",\n      \"description\": \"Research topics online and create comprehensive learning guides with RAG-optimized indexes\",\n      \"version\": \"5.1.0\",\n      \"category\": \"productivity\"\n    },\n    {\n      \"name\": \"agnix\",\n      \"source\": \"./plugins/agnix\",\n      \"description\": \"Lint agent configuration files (SKILL.md, CLAUDE.md, hooks, MCP) against 155 rules across 10+ AI tools\",\n      \"version\": \"5.1.0\",\n      \"category\": \"development\"\n    },\n    {\n      \"name\": \"consult\",\n      \"source\": \"./plugins/consult\",\n      \"description\": \"Cross-tool AI consultation: get second opinions from Gemini CLI, Codex CLI, Claude Code, OpenCode, or Copilot CLI with model and thinking effort control\",\n      \"version\": \"5.1.0\",\n      \"category\": \"productivity\"\n    },\n    {\n      \"name\": \"debate\",\n      \"source\": \"./plugins/debate\",\n      \"description\": \"Structured multi-round debate between AI tools with proposer/challenger roles and verdict\",\n      \"version\": \"5.1.0\",\n      \"category\": \"productivity\"\n    }\n  ]\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"agentsys\",\n  \"version\": \"5.1.0\",\n  \"description\": \"Professional-grade slash commands for Claude Code with cross-platform support\",\n  \"keywords\": [\n    \"workflow\",\n    \"automation\",\n    \"code-review\",\n    \"ci-cd\",\n    \"deployment\",\n    \"slop-detection\",\n    \"task-management\"\n  ],\n  \"author\": {\n    \"name\": \"Avi Fenesh\",\n    \"url\": \"https://github.com/avifenesh\"\n  },\n  \"repository\": \"https://github.com/avifenesh/agentsys\",\n  \"license\": \"MIT\"\n}\n",
        "README.md": "<p align=\"center\">\n  <img src=\"site/assets/logo.png\" alt=\"AgentSys\" width=\"120\">\n</p>\n\n<h1 align=\"center\">AgentSys</h1>\n\n<p align=\"center\">\n  <strong>A modular runtime and orchestration system for AI agents.</strong>\n</p>\n\n> **Renamed from `awesome-slash`** — The `awesome-` prefix implies a curated list of links, but this project is a functional software suite and runtime. Please update your installs: `npm install -g agentsys`\n\n<p align=\"center\">\n  <a href=\"https://www.npmjs.com/package/agentsys\"><img src=\"https://img.shields.io/npm/v/agentsys.svg\" alt=\"npm version\"></a>\n  <a href=\"https://www.npmjs.com/package/agentsys\"><img src=\"https://img.shields.io/npm/dm/agentsys.svg\" alt=\"npm downloads\"></a>\n  <a href=\"https://github.com/avifenesh/agentsys/actions/workflows/ci.yml\"><img src=\"https://github.com/avifenesh/agentsys/actions/workflows/ci.yml/badge.svg\" alt=\"CI\"></a>\n  <a href=\"https://github.com/avifenesh/agentsys/stargazers\"><img src=\"https://img.shields.io/github/stars/avifenesh/agentsys.svg\" alt=\"GitHub stars\"></a>\n  <a href=\"https://opensource.org/licenses/MIT\"><img src=\"https://img.shields.io/badge/License-MIT-yellow.svg\" alt=\"License: MIT\"></a>\n  <a href=\"https://avifenesh.github.io/agentsys/\"><img src=\"https://img.shields.io/badge/Website-AgentSys-blue?style=flat&logo=github\" alt=\"Website\"></a>\n  <a href=\"https://github.com/hesreallyhim/awesome-claude-code\"><img src=\"https://awesome.re/mentioned-badge.svg\" alt=\"Mentioned in Awesome Claude Code\"></a>\n</p>\n\n<p align=\"center\">\n  <b>13 plugins · 42 agents · 28 skills · 26k lines of lib code · 3,357 tests · 3 platforms</b>\n</p>\n\n<p align=\"center\">\n  <a href=\"#commands\">Commands</a> · <a href=\"#installation\">Installation</a> · <a href=\"https://avifenesh.github.io/agentsys/\">Website</a> · <a href=\"https://github.com/avifenesh/agentsys/discussions\">Discussions</a>\n</p>\n\n<p align=\"center\">\n  <b>Built for Claude Code · Codex CLI · OpenCode</b>\n</p>\n\n<p align=\"center\"><em>New skills, agents, and integrations ship constantly. Follow for real-time updates:</em></p>\n<p align=\"center\">\n  <a href=\"https://x.com/avi_fenesh\"><img src=\"https://img.shields.io/badge/Follow-@avi__fenesh-1DA1F2?style=for-the-badge&logo=x&logoColor=white\" alt=\"Follow on X\"></a>\n</p>\n\n---\n\nAI models can write code. That's not the hard part anymore. The hard part is everything around it — task selection, branch management, code review, artifact cleanup, CI, PR comments, deployment. **AgentSys is the runtime that orchestrates agents to handle all of it** — structured pipelines, gated phases, specialized agents, and persistent state that survives session boundaries.\n\n---\n> Building custom skills, agents, hooks, or MCP tools? [agnix](https://github.com/avifenesh/agnix) is the CLI + LSP linter that catches config errors before they fail silently - real-time IDE validation, auto suggestions, auto-fix, and 155 rules for Cursor, Claude Code, Cline, Copilot, Codex, Windsurf, and more.\n\n## What This Is\n\nAn agent orchestration system — 13 plugins, 42 agents, and 28 skills that compose into structured pipelines for software development.\n\nEach agent has a single responsibility, a specific model assignment, and defined inputs/outputs. Pipelines enforce phase gates so agents can't skip steps. State persists across sessions so work survives interruptions.\n\nThe system runs on Claude Code, OpenCode, and Codex CLI. Install the plugins, get the runtime.\n\n---\n\n## The Approach\n\n**Code does code work. AI does AI work.**\n\n- **Detection**: regex, AST analysis, static analysis—fast, deterministic, no tokens wasted\n- **Judgment**: LLM calls for synthesis, planning, review—where reasoning matters\n- **Result**: 77% fewer tokens for [/drift-detect](#drift-detect) vs multi-agent approaches, certainty-graded findings throughout\n\n**Certainty levels exist because not all findings are equal:**\n\n| Level | Meaning | Action |\n|-------|---------|--------|\n| HIGH | Definitely a problem | Safe to auto-fix |\n| MEDIUM | Probably a problem | Needs context |\n| LOW | Might be a problem | Needs human judgment |\n\nThis came from testing on 1,000+ repositories.\n\n---\n\n## Commands\n\n<!-- GEN:START:readme-commands -->\n| Command | What it does |\n|---------|--------------|\n| [`/next-task`](#next-task) | Task → exploration → plan → implementation → review → ship |\n| [`/agnix`](#agnix) | **Lint agent configs** - 155 rules for Skills, Memory, Hooks, MCP across 10+ AI tools |\n| [`/ship`](#ship) | Branch → PR → CI → reviews addressed → merge → cleanup |\n| [`/deslop`](#deslop) | 3-phase detection pipeline, certainty-graded findings |\n| [`/perf`](#perf) | 10-phase performance investigation with baselines and profiling |\n| [`/drift-detect`](#drift-detect) | AST-based plan vs code analysis, finds what's documented but not built |\n| [`/audit-project`](#audit-project) | Multi-agent code review, iterates until issues resolved |\n| [`/enhance`](#enhance) | Analyzes prompts, agents, plugins, docs, hooks, skills |\n| [`/repo-map`](#repo-map) | AST symbol and import mapping via ast-grep |\n| [`/sync-docs`](#sync-docs) | Finds outdated references, stale examples, missing CHANGELOG entries |\n| [`/learn`](#learn) | Research any topic, gather online sources, create learning guide with RAG index |\n| [`/consult`](#consult) | Consult another AI CLI tool for a second opinion. Use when you want to cross-check ideas, get alternative approaches, or validate decisions with Gemini, Codex, Claude, OpenCode, or Copilot. |\n| [`/debate`](#debate) | Structured debate between two AI tools to stress-test ideas. Proposer/Challenger format with a verdict. |\n<!-- GEN:END:readme-commands -->\n\nEach command works standalone. Together, they compose into end-to-end pipelines.\n\n---\n\n## Skills\n\n<!-- GEN:START:readme-skills -->\n28 skills included across the plugins:\n\n| Category | Skills |\n|----------|--------|\n| **Performance** | `perf:perf-analyzer`, `perf:perf-baseline-manager`, `perf:perf-benchmarker`, `perf:perf-code-paths`, `perf:perf-investigation-logger`, `perf:perf-profiler`, `perf:perf-theory-gatherer`, `perf:perf-theory-tester` |\n| **Enhancement** | `enhance:enhance-agent-prompts`, `enhance:enhance-claude-memory`, `enhance:enhance-cross-file`, `enhance:enhance-docs`, `enhance:enhance-hooks`, `enhance:enhance-orchestrator`, `enhance:enhance-plugins`, `enhance:enhance-prompts`, `enhance:enhance-skills` |\n| **Workflow** | `next-task:discover-tasks`, `next-task:orchestrate-review`, `next-task:validate-delivery` |\n| **Cleanup** | `deslop:deslop`, `sync-docs:sync-docs` |\n| **Analysis** | `debate:debate`, `drift-detect:drift-analysis`, `repo-map:repo-mapping` |\n| **Productivity** | `consult:consult` |\n| **Learning** | `learn:learn` |\n| **Linting** | `agnix:agnix` |\n<!-- GEN:END:readme-skills -->\n\nSkills are the reusable implementation units. Agents invoke skills; commands orchestrate agents. When you install a plugin, its skills become available to all agents in that session.\n\n---\n\n## Quick Navigation\n\n| Section | What's there |\n|---------|--------------|\n| [The Approach](#the-approach) | Why it's built this way |\n| [Commands](#commands) | All 12 commands overview |\n| [Skills](#skills) | 28 skills across plugins |\n| [Command Details](#command-details) | Deep dive into each command |\n| [How Commands Work Together](#how-commands-work-together) | Standalone vs integrated |\n| [Design Philosophy](#design-philosophy) | The thinking behind the architecture |\n| [Installation](#installation) | Get started |\n| [Research & Testing](#research--testing) | What went into building this |\n| [Documentation](#documentation) | Links to detailed docs |\n\n---\n\n## Command Details\n\n### /next-task\n\n**Purpose:** Complete task-to-production automation.\n\n**What happens when you run it:**\n\n1. **Policy Selection** - Choose task source (GitHub issues, GitLab, local file), priority filter, stopping point\n2. **Task Discovery** - Shows top 5 prioritized tasks, you pick one\n3. **Worktree Setup** - Creates isolated branch and working directory\n4. **Exploration** - Deep codebase analysis to understand context\n5. **Planning** - Designs implementation approach\n6. **User Approval** - You review and approve the plan (last human interaction)\n7. **Implementation** - Executes the plan\n8. **Pre-Review** - Runs [deslop](#deslop)-agent and test-coverage-checker\n9. **Review Loop** - Multi-agent review iterates until clean\n10. **Delivery Validation** - Verifies tests pass, build passes, requirements met\n11. **Docs Update** - Updates CHANGELOG and related documentation\n12. **[Ship](#ship)** - Creates PR, monitors CI, addresses comments, merges\n\nPhase 9 uses the `orchestrate-review` skill to spawn parallel reviewers (code quality, security, performance, test coverage) plus conditional specialists.\n\n**Agents involved:**\n\n| Agent | Model | Role |\n|-------|-------|------|\n| task-discoverer | sonnet | Finds and ranks tasks from your source |\n| worktree-manager | haiku | Creates git worktrees and branches |\n| exploration-agent | opus | Deep codebase analysis before planning |\n| planning-agent | opus | Designs step-by-step implementation plan |\n| implementation-agent | opus | Writes the actual code |\n| test-coverage-checker | sonnet | Validates tests exist and are meaningful |\n| delivery-validator | sonnet | Final checks before shipping |\n| ci-monitor | haiku | Watches CI status |\n| ci-fixer | sonnet | Fixes CI failures and review comments |\n| simple-fixer | haiku | Executes mechanical edits |\n\n**Cross-plugin agent:**\n| Agent | Plugin | Role |\n|-------|--------|------|\n| deslop-agent | deslop | Removes AI artifacts before review |\n| sync-docs-agent | sync-docs | Updates documentation |\n\n**Usage:**\n\n```bash\n/next-task              # Start new workflow\n/next-task --resume     # Resume interrupted workflow\n/next-task --status     # Check current state\n/next-task --abort      # Cancel and cleanup\n```\n\n[Full workflow documentation →](./docs/workflows/NEXT-TASK.md)\n\n---\n\n### /agnix\n\n**Purpose:** Lint agent configurations before they break your workflow. The first dedicated linter for AI agent configs.\n\n**[agnix](https://github.com/avifenesh/agnix)** is a standalone open-source project that provides the validation engine. This plugin integrates it into your workflow.\n\n**The problem it solves:**\n\nAgent configurations are code. They affect behavior, security, and reliability. But unlike application code, they have no linting. You find out your SKILL.md is malformed when the agent fails. You discover your hooks have security issues when they're exploited. You realize your CLAUDE.md has conflicting rules when the AI behaves unexpectedly.\n\nagnix catches these issues before they cause problems.\n\n**What it validates:**\n\n| Category | What It Checks |\n|----------|----------------|\n| **Structure** | Required fields, valid YAML/JSON, proper frontmatter |\n| **Security** | Prompt injection vectors, overpermissive tools, exposed secrets |\n| **Consistency** | Conflicting rules, duplicate definitions, broken references |\n| **Best Practices** | Tool restrictions, model selection, trigger phrase quality |\n| **Cross-Platform** | Compatibility across Claude Code, Cursor, Copilot, Codex, OpenCode, Gemini CLI, Cline, and more |\n\n**155 validation rules** (57 auto-fixable) derived from:\n- Official tool specifications (Claude Code, Cursor, GitHub Copilot, Codex CLI, OpenCode, Gemini CLI, and more)\n- Research papers on agent reliability and prompt injection\n- Real-world testing across 500+ repositories\n- Community-reported issues and edge cases\n\n**Supported files:**\n\n| File Type | Examples |\n|-----------|----------|\n| Skills | `SKILL.md`, `*/SKILL.md` |\n| Memory | `CLAUDE.md`, `AGENTS.md`, `.github/CLAUDE.md` |\n| Hooks | `.claude/settings.json`, hooks configuration |\n| MCP | `*.mcp.json`, MCP server configs |\n| Cursor | `.cursor/rules/*.mdc`, `.cursorrules` |\n| Copilot | `.github/copilot-instructions.md` |\n\n**CI/CD Integration:**\n\nagnix outputs SARIF format for GitHub Code Scanning. Add it to your workflow:\n\n```yaml\n- name: Lint agent configs\n  run: agnix --format sarif > results.sarif\n- uses: github/codeql-action/upload-sarif@v3\n  with:\n    sarif_file: results.sarif\n```\n\n**Usage:**\n\n```bash\n/agnix                       # Validate current project\n/agnix --fix                 # Auto-fix fixable issues\n/agnix --strict              # Treat warnings as errors\n/agnix --target claude-code  # Only Claude Code rules\n/agnix --format sarif        # Output for GitHub Code Scanning\n```\n\n**Agent:** agnix-agent (sonnet model)\n\n**External tool:** Requires [agnix CLI](https://github.com/avifenesh/agnix)\n\n```bash\nnpm install -g agnix         # Install via npm\n# or\ncargo install agnix-cli      # Install via Cargo\n# or\nbrew install agnix           # Install via Homebrew (macOS)\n```\n\n**Why use agnix:**\n- Catch config errors before they cause agent failures\n- Enforce security best practices across your team\n- Maintain consistency as your agent configs grow\n- Integrate validation into CI/CD pipelines\n- Support multiple AI tools from one linter\n\n---\n\n### /ship\n\n**Purpose:** Takes your current branch from \"ready to commit\" to \"merged PR.\"\n\n**What happens when you run it:**\n\n1. **Pre-flight** - Detects CI platform, deployment platform, branch strategy\n2. **Commit** - Stages and commits with generated message (if uncommitted changes)\n3. **Push & PR** - Pushes branch, creates pull request\n4. **CI Monitor** - Waits for CI, retries on transient failures\n5. **Review Wait** - Waits 3 minutes for auto-reviewers (Copilot, Claude, Gemini, Codex)\n6. **Address Comments** - Handles every comment from every reviewer\n7. **Merge** - Merges when all comments resolved and CI passes\n8. **Deploy** - Deploys and validates (if multi-branch workflow)\n9. **Cleanup** - Removes worktree, closes issue, deletes branch\n\n**Platform Detection:**\n\n| Type | Detected |\n|------|----------|\n| CI | GitHub Actions, GitLab CI, CircleCI, Jenkins, Travis |\n| Deploy | Railway, Vercel, Netlify, Fly.io, Render |\n| Project | Node.js, Python, Rust, Go, Java |\n\n**Review Comment Handling:**\n\nEvery comment gets addressed. No exceptions. The workflow categorizes comments and handles each:\n- Code fixes get implemented\n- Style suggestions get applied\n- Questions get answered\n- False positives get explained\n\nIf something can't be fixed, the workflow replies explaining why and resolves the thread.\n\n**Usage:**\n\n```bash\n/ship                       # Full workflow\n/ship --dry-run             # Preview without executing\n/ship --strategy rebase     # Use rebase instead of squash\n```\n\n[Full workflow documentation →](./docs/workflows/SHIP.md)\n\n---\n\n### /deslop\n\n**Purpose:** Finds AI slop—debug statements, placeholder text, verbose comments, TODOs—and removes it.\n\n**How detection works:**\n\nThree phases run in sequence:\n\n1. **Phase 1: Regex Patterns** (HIGH certainty)\n   - `console.log`, `print()`, `dbg!()`, `println!()`\n   - `// TODO`, `// FIXME`, `// HACK`\n   - Empty catch blocks, disabled linters\n   - Hardcoded secrets (API keys, tokens)\n\n2. **Phase 2: Multi-Pass Analyzers** (MEDIUM certainty)\n   - Doc-to-code ratio (excessive comments)\n   - Verbosity ratio (AI preambles)\n   - Over-engineering patterns\n   - Buzzword inflation\n   - Dead code detection\n   - Stub functions\n\n3. **Phase 3: CLI Tools** (LOW certainty, optional)\n   - jscpd, madge, escomplex (JS/TS)\n   - pylint, radon (Python)\n   - golangci-lint (Go)\n   - clippy (Rust)\n\n**Languages supported:** JavaScript/TypeScript, Python, Rust, Go, Java\n\n**Usage:**\n\n```bash\n/deslop              # Report only (safe)\n/deslop apply        # Fix HIGH certainty issues\n/deslop apply src/ 10  # Fix 10 issues in src/\n```\n\n**Thoroughness levels:**\n\n- `quick` - Phase 1 only (fastest)\n- `normal` - Phase 1 + Phase 2 (default)\n- `deep` - All phases if tools available\n\n[Pattern reference →](./docs/reference/SLOP-PATTERNS.md)\n\n---\n\n### /perf\n\n**Purpose:** Structured performance investigation with baselines, profiling, and evidence-backed decisions.\n\n**10-phase methodology** (based on recorded real performance investigation sessions):\n\n1. **Setup** - Confirm scenario, success criteria, benchmark command\n2. **Baseline** - 60s minimum runs, PERF_METRICS markers required\n3. **Breaking Point** - Binary search to find failure threshold\n4. **Constraints** - CPU/memory limits, measure delta vs baseline\n5. **Hypotheses** - Generate up to 5 hypotheses with evidence and confidence\n6. **Code Paths** - Use repo-map to identify entrypoints and hot files\n7. **Profiling** - Language-specific tools (--cpu-prof, JFR, cProfile, pprof)\n8. **Optimization** - One change per experiment, 2+ validation passes\n9. **Decision** - Continue or stop based on measurable improvement\n10. **Consolidation** - Final baseline, evidence log, investigation complete\n\n**Agents and skills:**\n\n| Component | Role |\n|-----------|------|\n| perf-orchestrator | Coordinates all phases |\n| perf-theory-gatherer | Generates hypotheses from git history and code |\n| perf-theory-tester | Validates hypotheses with controlled experiments |\n| perf-analyzer | Synthesizes findings into recommendations |\n| perf-code-paths | Maps entrypoints and likely hot paths |\n| perf-investigation-logger | Structured evidence logging |\n\n**Usage:**\n\n```bash\n/perf                 # Start new investigation\n/perf --resume        # Resume previous investigation\n```\n\n**Phase flags (advanced):**\n\n```bash\n/perf --phase baseline --command \"npm run bench\" --version v1.2.0\n/perf --phase breaking-point --param-min 1 --param-max 500\n/perf --phase constraints --cpu 1 --memory 1GB\n/perf --phase hypotheses --hypotheses-file perf-hypotheses.json\n/perf --phase optimization --change \"reduce allocations\"\n/perf --phase decision --verdict stop --rationale \"no measurable improvement\"\n```\n\n---\n\n### /drift-detect\n\n**Purpose:** Compares your documentation and plans to what's actually in the code.\n\n**The problem it solves:**\n\nYour roadmap says \"user authentication: done.\" But is it actually implemented? Your GitHub issue says \"add dark mode.\" Is it already in the codebase? Plans drift from reality. This command finds the drift.\n\n**How it works:**\n\n1. **JavaScript collectors** gather data (fast, token-efficient)\n   - GitHub issues and their labels\n   - Documentation files\n   - Actual code exports and implementations\n\n2. **Single Opus call** performs semantic analysis\n   - Matches concepts, not strings (\"user auth\" matches `auth/`, `login.js`, `session.ts`)\n   - Identifies implemented but not documented\n   - Identifies documented but not implemented\n   - Finds stale issues that should be closed\n\n**Why this approach:**\n\nMulti-agent collection wastes tokens on coordination. JavaScript collectors are fast and deterministic. One well-prompted LLM call does the actual analysis. Result: 77% token reduction vs multi-agent approaches.\n\n**Tested on 1,000+ repositories** before release.\n\n**Usage:**\n\n```bash\n/drift-detect              # Full analysis\n/drift-detect --depth quick  # Quick scan\n```\n\n---\n\n### /audit-project\n\n**Purpose:** Multi-agent code review that iterates until issues are resolved.\n\n**What happens when you run it:**\n\nUp to 10 specialized role-based agents run based on your project:\n\n| Agent | When Active | Focus Area |\n|-------|-------------|------------|\n| code-quality-reviewer | Always | Code quality, error handling |\n| security-expert | Always | Vulnerabilities, auth, secrets |\n| performance-engineer | Always | N+1 queries, memory, blocking ops |\n| test-quality-guardian | Always | Coverage, edge cases, mocking |\n| architecture-reviewer | If 50+ files | Modularity, patterns, SOLID |\n| database-specialist | If DB detected | Queries, indexes, transactions |\n| api-designer | If API detected | REST, errors, pagination |\n| frontend-specialist | If frontend detected | Components, state, UX |\n| backend-specialist | If backend detected | Services, domain logic |\n| devops-reviewer | If CI/CD detected | Pipelines, configs, secrets |\n\nFindings are collected and categorized by severity (critical/high/medium/low). All non-false-positive issues get fixed automatically. The loop repeats until no open issues remain.\n\n**Usage:**\n\n```bash\n/audit-project                   # Full review\n/audit-project --quick           # Single pass\n/audit-project --resume          # Resume from queue file\n/audit-project --domain security # Security focus only\n/audit-project --recent          # Only recent changes\n```\n\n[Agent reference →](./docs/reference/AGENTS.md#audit-project-plugin-agents)\n\n---\n\n### /enhance\n\n**Purpose:** Analyzes your prompts, plugins, agents, docs, hooks, and skills for improvement opportunities.\n\n**Seven analyzers run in parallel:**\n\n| Analyzer | What it checks |\n|----------|----------------|\n| plugin-enhancer | Plugin structure, MCP tool definitions, security patterns |\n| agent-enhancer | Agent frontmatter, prompt quality |\n| claudemd-enhancer | CLAUDE.md/AGENTS.md structure, token efficiency |\n| docs-enhancer | Documentation readability, RAG optimization |\n| prompt-enhancer | Prompt engineering patterns, clarity, examples |\n| hooks-enhancer | Hook frontmatter, structure, safety |\n| skills-enhancer | SKILL.md structure, trigger phrases |\n\n**Each finding includes:**\n- Certainty level (HIGH/MEDIUM/LOW)\n- Specific location (file:line)\n- What's wrong\n- How to fix it\n- Whether it can be auto-fixed\n\n**Auto-learning:** Detects obvious false positives (pattern docs, workflow gates) and saves them for future runs. Reduces noise over time without manual suppression files.\n\n**Usage:**\n\n```bash\n/enhance                    # Run all analyzers\n/enhance --focus=agent      # Just agent prompts\n/enhance --apply            # Apply HIGH certainty fixes\n/enhance --show-suppressed  # Show what's being filtered\n/enhance --no-learn         # Analyze but don't save false positives\n```\n\n---\n\n### /repo-map\n\n**Purpose:** Builds an AST-based map of symbols and imports for fast repo analysis.\n\n**What it generates:**\n\n- Cached file→symbols map (exports, functions, classes)\n- Import graph for dependency hints\n\nOutput is cached at `{state-dir}/repo-map.json` and exposed via the MCP `repo_map` tool.\n\n**Why it matters:**\n\nTools like `/drift-detect` and planners can use the map instead of re-scanning the repo every time.\n\n**Usage:**\n\n```bash\n/repo-map init        # First-time map generation\n/repo-map update      # Incremental update\n/repo-map status      # Check freshness\n```\n\n**Required:** ast-grep (`sg`) must be installed.\n\n---\n\n### /sync-docs\n\n**Purpose:** Sync documentation with actual code changes—find outdated refs, update CHANGELOG, flag stale examples.\n\n**The problem it solves:**\n\nYou refactor `auth.js` into `auth/index.js`. Your README still says `import from './auth'`. You rename a function. Three docs still reference the old name. You ship a feature. CHANGELOG doesn't mention it. Documentation drifts from code. This command finds the drift.\n\n**What it detects:**\n\n| Category | Examples |\n|----------|----------|\n| Broken references | Imports to moved/renamed files, deleted exports |\n| Version mismatches | Doc says v2.0, package.json says v2.1 |\n| Stale code examples | Import paths that no longer exist |\n| Missing CHANGELOG | `feat:` and `fix:` commits without entries |\n\n**Auto-fixable vs flagged:**\n\n| Auto-fixable (apply mode) | Flagged for review |\n|---------------------------|-------------------|\n| Version number updates | Removed exports referenced in docs |\n| CHANGELOG entries for commits | Code examples needing context |\n| | Function renames |\n\n**Usage:**\n\n```bash\n/sync-docs              # Check what docs need updates (safe)\n/sync-docs apply        # Apply safe fixes\n/sync-docs report src/  # Check docs related to src/\n/sync-docs --all        # Full codebase scan\n```\n\n---\n\n### /learn\n\n**Purpose:** Research any topic online and create a comprehensive learning guide with RAG-optimized indexes.\n\n**What it does:**\n\n1. **Progressive Discovery** - Uses funnel approach (broad → specific → deep) to find quality sources\n2. **Quality Scoring** - Scores sources by authority, recency, depth, examples, uniqueness\n3. **Just-In-Time Extraction** - Fetches only high-scoring sources to save tokens\n4. **Synthesis** - Creates structured learning guide with examples and best practices\n5. **RAG Index** - Updates CLAUDE.md/AGENTS.md master index for future lookups\n6. **Enhancement** - Runs enhance:enhance-docs and enhance:enhance-prompts\n\n**Depth levels:**\n\n| Depth | Sources | Use Case |\n|-------|---------|----------|\n| brief | 10 | Quick overview |\n| medium | 20 | Default, balanced |\n| deep | 40 | Comprehensive |\n\n**Output structure:**\n\n```\nagent-knowledge/\n  CLAUDE.md                    # Master index (updated each run)\n  AGENTS.md                    # Index for OpenCode/Codex\n  recursion.md                 # Topic-specific guide\n  resources/\n    recursion-sources.json     # Source metadata with quality scores\n```\n\n**Usage:**\n\n```bash\n/learn recursion                    # Default (20 sources)\n/learn react hooks --depth=deep     # Comprehensive (40 sources)\n/learn kubernetes --depth=brief     # Quick overview (10 sources)\n/learn python async --no-enhance    # Skip enhancement pass\n```\n\n**Agent:** learn-agent (opus model for research quality)\n\n---\n\n### /consult\n\n**Purpose:** Get a second opinion from another AI CLI tool without leaving your current session.\n\n**What it does:**\n\n1. **Tool Detection** - Detects which AI CLI tools are installed (cross-platform)\n2. **Interactive Picker** - If no tool specified, shows only installed tools to choose from\n3. **Effort Mapping** - Maps effort levels to per-provider models and reasoning flags\n4. **Execution** - Runs the consultation with safe-mode defaults and 120s timeout\n5. **Session Continuity** - Saves session state for Claude and Gemini (supports `--continue`)\n\n**Supported tools:**\n\n| Tool | Default Model (high) | Reasoning Control |\n|------|---------------------|-------------------|\n| Claude | opus | max-turns |\n| Gemini | gemini-3-pro | built-in |\n| Codex | gpt-5.3-codex | model_reasoning_effort |\n| OpenCode | github-copilot/claude-opus-4-6 | --variant |\n| Copilot | (default) | none |\n\n**Usage:**\n\n```bash\n/consult \"Is this the right approach?\" --tool=gemini --effort=high\n/consult \"Review for performance issues\" --tool=codex\n/consult \"Suggest alternatives\" --tool=claude --effort=max\n/consult \"Continue from where we left off\" --continue\n/consult \"Explain this error\" --context=diff --tool=gemini\n```\n\n**Agent:** consult-agent (sonnet model for orchestration)\n\n---\n\n### /debate\n\n**Purpose:** Stress-test ideas through structured multi-round debate between two AI CLI tools.\n\n**What it does:**\n\n1. **Tool Detection** - Detects which AI CLI tools are installed (cross-platform)\n2. **Interactive Picker** - If no tools specified, prompts for proposer, challenger, effort, rounds, and context in a single batch question\n3. **Proposer/Challenger Format** - First tool argues for the topic; second tool challenges with evidence\n4. **Multi-Round Exchange** - Each round the proposer defends and the challenger responds (1–5 rounds)\n5. **Verdict** - Orchestrator delivers a final synthesis picking a winner with reasoning\n\n**Usage:**\n\n```bash\n# Natural language\n/debate codex vs gemini about microservices vs monolith\n/debate with claude and codex about our auth implementation\n/debate thoroughly gemini vs codex about database schema design\n/debate codex vs gemini 3 rounds about event sourcing\n\n# Explicit flags\n/debate \"Should we use event sourcing?\" --tools=claude,gemini --rounds=3 --effort=high\n/debate \"Valkey vs PostgreSQL for caching\" --tools=codex,opencode\n\n# With codebase context\n/debate \"Is our current approach correct?\" --tools=gemini,codex --context=diff\n```\n\n**Options:**\n\n| Flag | Description |\n|------|-------------|\n| `--tools=TOOL1,TOOL2` | Proposer and challenger (comma-separated) |\n| `--rounds=N` | Number of debate rounds, 1–5 (default: 2) |\n| `--effort=low\\|medium\\|high\\|max` | Reasoning depth per tool call |\n| `--context=diff\\|file=PATH\\|none` | Codebase context passed to both tools |\n\n**Agent:** debate-orchestrator (opus model for orchestration)\n\n---\n\n## How Commands Work Together\n\n**Standalone use:**\n\n```bash\n/deslop apply          # Just clean up your code\n/sync-docs             # Just check if docs need updates\n/ship                  # Just ship this branch\n/audit-project         # Just review the codebase\n```\n\n**Integrated workflow:**\n\nWhen you run [`/next-task`](#next-task), it orchestrates everything:\n\n```\n/next-task picks task → explores codebase → plans implementation\n    ↓\nimplementation-agent writes code\n    ↓\ndeslop-agent cleans AI artifacts\n    ↓\nPhase 9 review loop iterates until approved\n    ↓\ndelivery-validator checks requirements\n    ↓\nsync-docs-agent syncs documentation\n    ↓\n[/ship](#ship) creates PR → monitors CI → merges\n```\n\nThe workflow tracks state so you can resume from any point.\n\n---\n\n## Design Philosophy\n\n<details>\n<summary><strong>Architecture decisions and trade-offs</strong> (click to expand)</summary>\n\n### The Actual Problem\n\nFrontier models write good code. That's solved. What's not solved:\n\n- **Context management** - Models forget what they're doing mid-session\n- **Compaction amnesia** - Long sessions get summarized, losing critical state\n- **Task drift** - Without structure, agents wander from the actual goal\n- **Skipped steps** - Agents skip reviews, tests, or cleanup when not enforced\n- **Token waste** - Using LLM calls for work that static analysis can do faster\n- **Babysitting** - Manually orchestrating each phase of development\n- **Repetitive requests** - Asking for the same workflow every single session\n\n### How This Addresses It\n\n**1. One agent, one job, done extremely well**\n\nSame principle as good code: single responsibility. The exploration-agent explores. The implementation-agent implements. Phase 9 spawns multiple focused reviewers. No agent tries to do everything. Specialized agents, each with narrow scope and clear success criteria.\n\n**2. Pipeline with gates, not a monolith**\n\nSame principle as DevOps. Each step must pass before the next begins. Can't push before review. Can't merge before CI passes. Hooks enforce this—agents literally cannot skip phases.\n\n**3. Tools do tool work, agents do agent work**\n\nIf static analysis, regex, or a shell command can do it, don't ask an LLM. Pattern detection uses pre-indexed regex. File discovery uses glob. Platform detection uses file existence checks. The LLM only handles what requires judgment.\n\n**4. Agents don't need to know how tools work**\n\nThe slop detector returns findings with certainty levels. The agent doesn't need to understand the three-phase pipeline, the regex patterns, or the analyzer heuristics. Good tool design means the consumer doesn't need implementation details.\n\n**5. Build tools where tools don't exist**\n\nMany tasks lack existing tools. JavaScript collectors for drift-detect. Multi-pass analyzers for slop detection. The result: agents receive structured data, not raw problems to figure out.\n\n**6. Research-backed prompt engineering**\n\nDocumented techniques that measurably improve results:\n- **Progressive disclosure** - Agents see only what's needed for the current step\n- **Structured output** - JSON between delimiters, XML tags for sections\n- **Explicit constraints** - What agents MUST NOT do matters as much as what they do\n- **Few-shot examples** - Where patterns aren't obvious\n- **Tool calling over generation** - Let the model use tools rather than generate tool-like output\n\n**7. Validate plan and results, not every step**\n\nApprove the plan. See the results. The middle is automated. One plan approval unlocks autonomous execution through implementation, review, cleanup, and shipping.\n\n**8. Right model for the task**\n\nMatch model capability to task complexity:\n- **opus** - Exploration, planning, implementation, review orchestration\n- **sonnet** - Pattern matching, validation, discovery\n- **haiku** - Git operations, file moves, CI polling\n\nQuality compounds. Poor exploration → poor plan → poor implementation → review cycles. Early phases deserve the best model.\n\n**9. Persistent state survives sessions**\n\nTwo JSON files track everything: what task, what phase. Sessions can die and resume. Multiple sessions run in parallel on different tasks using separate worktrees.\n\n**10. Delegate everything automatable**\n\nAgents don't just write code. They:\n- Clean their own output (deslop-agent)\n- Update documentation (sync-docs-agent)\n- Fix CI failures (ci-fixer)\n- Respond to review comments\n- Check for plan drift ([/drift-detect](#drift-detect))\n- Analyze their own prompts ([/enhance](#enhance))\n\nIf it can be specified, it can be delegated.\n\n**11. Orchestrator stays high-level**\n\nThe main workflow orchestrator doesn't read files, search code, or write implementations. It launches specialized agents and receives their outputs. Keeps the orchestrator's context window available for coordination rather than filled with file contents.\n\n**12. Composable, not monolithic**\n\nEvery command works standalone. [`/deslop`](#deslop) cleans code without needing [`/next-task`](#next-task). [`/ship`](#ship) merges PRs without needing the full workflow. Pieces compose together, but each piece is useful on its own.\n\n### What This Gets You\n\n- **Run multiple sessions** - Different tasks in different worktrees, no interference\n- **Fast iteration** - Approve plan, check results, repeat\n- **Stay in the interesting parts** - Policy decisions, architecture choices, edge cases\n- **Minimal review burden** - Most issues caught and fixed before you see the output\n- **No repetitive requests** - The workflow you want, without asking each time\n- **Scale horizontally** - More sessions, more tasks, same oversight level\n\n</details>\n\n---\n\n## Installation\n\n### Claude Code (Recommended way)\n\n```bash\n/plugin marketplace add avifenesh/agentsys\n/plugin install next-task@agentsys\n/plugin install ship@agentsys\n```\n\n### All Platforms (npm)\n\n```bash\nnpm install -g agentsys && agentsys\n```\n\nInteractive installer for Claude Code, OpenCode, and Codex CLI.\n\n```bash\n# Non-interactive install\nagentsys --tool claude              # Single tool\nagentsys --tools \"claude,opencode\"  # Multiple tools\nagentsys --development              # Dev mode (bypasses marketplace)\n```\n\n[Full installation guide →](./docs/INSTALLATION.md)\n\n---\n\n## Requirements\n\n**Required:**\n- Git\n- Node.js 18+\n\n**For GitHub workflows:**\n- GitHub CLI (`gh`) authenticated\n\n**For GitLab workflows:**\n- GitLab CLI (`glab`) authenticated\n\n**For /repo-map:**\n- ast-grep (`sg`) installed\n\n**For /agnix:**\n- [agnix CLI](https://github.com/avifenesh/agnix) installed (`cargo install agnix-cli` or `brew install agnix`)\n\n**Local diagnostics (optional):**\n```bash\nnpm run detect   # Platform detection (CI, deploy, project type)\nnpm run verify   # Tool availability + versions\n```\n\n---\n\n## Research & Testing\n\nThe system is built on research, not guesswork.\n\n**Knowledge base** (`agent-docs/`): 8,000 lines of curated documentation from Anthropic, OpenAI, Google, and Microsoft covering:\n- Agent architecture and design patterns\n- Prompt engineering techniques\n- Function calling and tool use\n- Context efficiency and token optimization\n- Multi-agent systems and orchestration\n- Instruction following reliability\n\n**Testing:**\n- 1,818 tests passing\n- Drift-detect validated on 1,000+ repositories\n- E2E workflow testing across all commands\n- Cross-platform validation (Claude Code, OpenCode, Codex CLI)\n\n**Methodology:**\n- `/perf` investigation phases based on recorded real performance investigation sessions\n- Certainty levels derived from pattern analysis across repositories\n- Token optimization measured and validated (77% reduction in drift-detect)\n\n---\n\n## Documentation\n\n| Topic | Link |\n|-------|------|\n| Installation | [docs/INSTALLATION.md](./docs/INSTALLATION.md) |\n| Cross-Platform Setup | [docs/CROSS_PLATFORM.md](./docs/CROSS_PLATFORM.md) |\n| Usage Examples | [docs/USAGE.md](./docs/USAGE.md) |\n| Architecture | [docs/ARCHITECTURE.md](./docs/ARCHITECTURE.md) |\n\n### Workflow Deep-Dives\n\n| Workflow | Link |\n|----------|------|\n| /next-task Flow | [docs/workflows/NEXT-TASK.md](./docs/workflows/NEXT-TASK.md) |\n| /ship Flow | [docs/workflows/SHIP.md](./docs/workflows/SHIP.md) |\n\n### Reference\n\n| Topic | Link |\n|-------|------|\n| Slop Patterns | [docs/reference/SLOP-PATTERNS.md](./docs/reference/SLOP-PATTERNS.md) |\n| Agent Reference | [docs/reference/AGENTS.md](./docs/reference/AGENTS.md) |\n\n---\n\n## Support\n\n- **Issues:** [github.com/avifenesh/agentsys/issues](https://github.com/avifenesh/agentsys/issues)\n- **Discussions:** [github.com/avifenesh/agentsys/discussions](https://github.com/avifenesh/agentsys/discussions)\n\n---\n\nMIT License | Made by [Avi Fenesh](https://github.com/avifenesh)\n",
        "plugins/drift-detect/README.md": "# drift-detect\n\nDeep repository analysis to realign project plans with actual code reality.\n\n## Overview\n\nThe drift-detect plugin performs comprehensive analysis of your codebase to identify drift between documented plans and actual implementation. It uses pure JavaScript for data collection (no LLM overhead) and a single Opus call for deep semantic analysis.\n\n## Architecture\n\n```\n/drift-detect\n        │\n        ├─→ collectors.js (pure JavaScript)\n        │   ├─ scanGitHubState()     → issues, PRs, milestones\n        │   ├─ analyzeDocumentation() → docs, plans, checkboxes\n        │   └─ scanCodebase()        → structure, frameworks, health\n        │\n        └─→ plan-synthesizer (Opus)\n            └─ Deep semantic analysis with full context\n```\n\n**Data collection**: No LLM calls - pure JavaScript\n**Semantic analysis**: Single Opus call with complete context\n**Token efficiency**: ~77% reduction vs. previous multi-agent architecture\n\n## Features\n\n- **Efficient data collection**: JavaScript collectors for deterministic extraction\n- **Deep semantic analysis**: Single Opus call for cross-referencing and insights\n- **Drift detection**: Identifies where plans have diverged from reality\n- **Gap analysis**: Finds missing tests, documentation, and implementation\n- **Priority ranking**: Context-aware prioritization\n- **Command-line flags**: No persistent settings files needed\n\n## Commands\n\n### `/drift-detect`\n\nRun a comprehensive reality check scan.\n\n```\n/drift-detect                              # Full scan (default)\n/drift-detect --sources github,docs        # Specific sources\n/drift-detect --depth quick                # Quick scan\n/drift-detect --output file --file report.md  # Custom output\n```\n\n| Flag | Values | Default | Description |\n|------|--------|---------|-------------|\n| `--sources` | github,docs,code | all three | Which sources to scan |\n| `--depth` | quick, thorough | thorough | How deep to analyze |\n| `--output` | file, display, both | both | Where to output results |\n| `--file` | path | drift-detect-report.md | Output file path |\n\n## Agent\n\n| Agent | Purpose | Model |\n|-------|---------|-------|\n| `plan-synthesizer` | Deep semantic analysis, drift detection, prioritization | opus |\n\n## Workflow\n\n```\n/drift-detect\n        │\n        ├─→ Parse command flags\n        │\n        ├─→ JavaScript Data Collection (parallel, no LLM)\n        │   ├─ scanGitHubState()\n        │   ├─ analyzeDocumentation()\n        │   └─ scanCodebase()\n        │\n        └─→ Single Opus Analysis Call\n            ├─ Cross-reference docs vs code\n            ├─ Identify drift patterns\n            ├─ Find gaps\n            └─ Generate prioritized plan\n                    │\n                    ▼\n           Reality Check Report\n```\n\n## Data Sources\n\n### GitHub (`--sources github`)\n- Open issues categorized by labels (bug, feature, security)\n- Open pull requests with draft status\n- Milestones with due dates and completion\n- Stale items (> 90 days inactive)\n- Themes extracted from issue titles\n\n**Requires**: `gh` CLI installed and authenticated\n\n### Documentation (`--sources docs`)\n- README.md, CONTRIBUTING.md, CHANGELOG.md\n- PLAN.md, CLAUDE.md\n- docs/*.md\n- Checkbox completion rates\n- Feature lists and planned work\n\n### Code (`--sources code`)\n- Directory structure analysis\n- Framework detection (React, Express, Vue, etc.)\n- Test framework detection (Jest, Mocha, Vitest)\n- Health indicators (CI, linting, tests)\n- Implemented features\n\n## Output\n\nThe scan produces:\n\n1. **Executive Summary**: Overview of project state\n2. **Drift Analysis**: Where plans diverge from reality (with evidence)\n3. **Gap Analysis**: Missing tests, docs, implementation (with severity)\n4. **Cross-Reference**: Documented vs. implemented features\n5. **Reconstruction Plan**: Prioritized action items by timeframe\n\n### Example Output\n\n```markdown\n# Reality Check Report\n\n## Executive Summary\nProject has moderate drift: 8 stale priority issues and 20% plan completion.\nStrong code health (tests + CI) but documentation lags implementation.\n\n## Drift Analysis\n\n### Priority Neglect\n**Severity**: high\n8 high-priority issues inactive for 60+ days.\n**Recommendation**: Triage stale issues - close, reassign, or deprioritize.\n\n## Gap Analysis\n\n### No Automated Tests\n**Severity**: critical\n**Impact**: High risk of regressions, difficult to refactor safely.\n**Recommendation**: Add test framework and critical path coverage.\n\n## Prioritized Plan\n\n### Immediate (This Week)\n1. **Close issue #45** - already implemented\n2. **Address security vulnerability** in auth module\n\n### Short-Term (This Month)\n1. Add test coverage for API endpoints\n2. Update README to reflect current features\n```\n\n## Skills\n\n### drift-analysis\n\nProvides knowledge for:\n- Drift detection patterns and signals\n- Prioritization framework\n- Cross-reference matching logic\n- Output templates\n\n## Requirements\n\n- GitHub CLI (`gh`) for GitHub scanning\n- Git repository\n- Node.js\n\n## Breaking Changes from v1\n\n- `.claude/drift-detect.local.md` settings file no longer used\n- Use command flags instead: `--sources`, `--depth`, `--output`, `--file`\n- Three scanner agents replaced with JavaScript collectors\n\n## License\n\nMIT\n",
        "plugins/enhance/README.md": "# enhance\n\nMaster enhancement orchestrator for plugins, agents, prompts, docs, hooks, and skills.\n\n## Overview\n\nThe enhance plugin provides specialized analyzers for different content types, identifying issues and suggesting improvements based on prompt engineering best practices.\n\n## Architecture\n\n```\n/enhance\n    │\n    ├─→ /enhance:agent   → Agent-specific analysis (frontmatter, tool restrictions)\n    ├─→ /enhance:prompt  → General prompt patterns (clarity, structure, examples)\n    ├─→ /enhance:docs    → Documentation analysis (RAG optimization, readability)\n    ├─→ /enhance:plugin  → Plugin structure (MCP tools, security patterns)\n    ├─→ /enhance:claudemd → Project memory optimization (CLAUDE.md/AGENTS.md)\n    ├─→ /enhance:hooks   → Hook definitions (frontmatter, safety)\n    └─→ /enhance:skills  → SKILL.md structure and triggers\n```\n\n**Analysis depth**: Certainty-based findings (HIGH, MEDIUM, LOW)\n**Auto-fix**: Available for HIGH certainty issues with `--fix` flag\n**Model selection**: Opus for quality-critical analyzers, Sonnet for pattern-based checks\n\n## Commands\n\n### `/enhance`\n\nRun all applicable enhancers on current directory.\n\n```\n/enhance                    # Auto-detect and run all relevant analyzers\n/enhance --fix              # Apply HIGH certainty auto-fixes\n/enhance --verbose          # Include LOW certainty issues\n```\n\n### `/enhance:agent [target]`\n\nAnalyze agent prompt files for configuration and structure issues.\n\n```\n/enhance:agent                     # All agents in directory\n/enhance:agent my-agent.md         # Specific agent\n/enhance:agent --fix               # Apply auto-fixes\n```\n\n**Detects**: Missing frontmatter, unrestricted Bash, missing role section, tool configuration issues\n\n### `/enhance:prompt [target]`\n\nAnalyze prompts for prompt engineering best practices.\n\n```\n/enhance:prompt                    # All prompts in directory\n/enhance:prompt system-prompt.md   # Specific prompt\n/enhance:prompt --fix              # Apply auto-fixes\n```\n\n**Detects**: Vague instructions, missing examples, aggressive emphasis, structural issues, invalid code blocks (JSON/JS syntax, language mismatches, heading hierarchy)\n\n### `/enhance:docs [target]`\n\nAnalyze documentation for readability and RAG optimization.\n\n```\n/enhance:docs                      # All docs in directory\n/enhance:docs --ai                 # AI-only mode (aggressive optimization)\n/enhance:docs agent-docs/ --ai     # Specific directory\n```\n\n**Detects**: Verbose phrases, poor chunking, broken links, token inefficiency\n\n### `/enhance:plugin [target]`\n\nAnalyze plugin structure and MCP tool definitions.\n\n```\n/enhance:plugin                    # All plugins\n/enhance:plugin my-plugin          # Specific plugin\n/enhance:plugin --fix              # Apply auto-fixes\n```\n\n**Detects**: Missing schema fields, security patterns, version mismatches\n\n### `/enhance:claudemd`\n\nAnalyze project memory files (CLAUDE.md, AGENTS.md).\n\n```\n/enhance:claudemd                  # Find and analyze project memory\n/enhance:claudemd --fix            # Apply auto-fixes\n```\n\n**Detects**: Missing sections, broken references, README duplication, cross-platform issues\n\n### `/enhance:hooks`\n\nAnalyze hook definitions for frontmatter quality.\n\n```\n/enhance:hooks                     # All hook definitions\n/enhance:hooks pre-commit.md        # Specific hook\n```\n\n**Detects**: Missing frontmatter, missing name/description\n\n### `/enhance:skills`\n\nAnalyze SKILL.md files for required metadata and trigger clarity.\n\n```\n/enhance:skills                     # All SKILL.md files\n/enhance:skills enhance-docs         # Specific skill\n```\n\n**Detects**: Missing frontmatter, missing name/description, missing trigger phrase\n\n## Agents\n\n| Agent | Purpose | Model |\n|-------|---------|-------|\n| `agent-enhancer` | Frontmatter, tool restrictions, agent structure | opus |\n| `prompt-enhancer` | Clarity, examples, structure, anti-patterns | opus |\n| `docs-enhancer` | RAG optimization, readability, token efficiency | opus |\n| `plugin-enhancer` | MCP schemas, security patterns, structure | sonnet |\n| `claudemd-enhancer` | Project memory validation, cross-platform | opus |\n| `hooks-enhancer` | Hook frontmatter, structure, safety | sonnet |\n| `skills-enhancer` | SKILL.md structure, trigger phrases | sonnet |\n\n## Certainty Levels\n\n| Level | Meaning | Auto-Fixable |\n|-------|---------|--------------|\n| HIGH | Definite issues | Some |\n| MEDIUM | Likely improvements | No |\n| LOW | Advisory suggestions | No |\n\nLOW certainty issues only shown with `--verbose` flag.\n\n## Common Flags\n\n| Flag | Description |\n|------|-------------|\n| `--fix` | Apply HIGH certainty auto-fixes |\n| `--verbose` | Include LOW certainty issues |\n| `--dry-run` | Show what would be fixed without applying |\n| `--ai` | AI-only mode (docs analyzer) |\n| `--both` | Both audiences mode (docs analyzer, default) |\n\n## Output Format\n\nEach analyzer generates a markdown report:\n\n```markdown\n## Analysis: {name}\n\n**File**: {path}\n**Analyzed**: {timestamp}\n\n### Summary\n- HIGH: {count} issues\n- MEDIUM: {count} issues\n- LOW: {count} issues (verbose only)\n\n### {Category} Issues ({n})\n\n| Issue | Fix | Certainty |\n|-------|-----|-----------|\n| Description | Suggested fix | HIGH |\n```\n\n## Integration\n\nCan be invoked by:\n- Direct command: `/enhance:*`\n- Phase 9 review loop during workflow\n- `delivery-validator` before shipping\n- Individual analysis workflows\n\n## Requirements\n\n- Claude Code\n- Node.js (for lib functions)\n\n## License\n\nMIT\n",
        "plugins/perf/README.md": "# perf\n\nRigorous performance investigation workflow. `/perf` enforces sequential benchmarks, minimum run durations, and evidence-backed decision-making.\n\n## Command\n\n```\n/perf\n```\n\n## What it does\n\n- Establishes a baseline and persists results under `{state-dir}/perf/`\n- Runs controlled experiments one at a time\n- Performs profiling and hotspot analysis\n- Consolidates findings into a single baseline per version\n\n## Requirements\n\nAll behavior is governed by:\n- `docs/perf-requirements.md`\n- `docs/perf-research-methodology.md`\n\n## Inputs\n\n- Hypotheses can be supplied via `--hypotheses-file <path>` during the hypotheses phase.\n\n## Skills\n\n- `perf-theory-gatherer` - Hypothesis generation (git history + evidence)\n- `perf-code-paths` - Code-path discovery before profiling\n- `perf-theory-tester` - Controlled experiments for hypotheses\n- `perf-analyzer` - Evidence-backed perf recommendations\n- `perf-investigation-logger` - Structured log entries with evidence\n\n## Artifacts\n\n- `{state-dir}/perf/investigation.json`\n- `{state-dir}/perf/investigations/<id>.md`\n- `{state-dir}/perf/baselines/<version>.json`\n"
      },
      "plugins": [
        {
          "name": "next-task",
          "source": "./plugins/next-task",
          "description": "Master workflow orchestrator: autonomous workflow with model optimization (opus/sonnet/haiku), two-file state management, workflow enforcement gates, 14 specialist agents",
          "version": "5.1.0",
          "category": "productivity",
          "categories": [
            "productivity"
          ],
          "install_commands": [
            "/plugin marketplace add avifenesh/agentsys",
            "/plugin install next-task@agentsys"
          ]
        },
        {
          "name": "ship",
          "source": "./plugins/ship",
          "description": "Complete PR workflow: commit to production, skips review when called from next-task, removes task from registry on cleanup, automatic rollback",
          "version": "5.1.0",
          "category": "deployment",
          "categories": [
            "deployment"
          ],
          "install_commands": [
            "/plugin marketplace add avifenesh/agentsys",
            "/plugin install ship@agentsys"
          ]
        },
        {
          "name": "deslop",
          "source": "./plugins/deslop",
          "description": "3-phase AI slop detection: regex patterns (HIGH), multi-pass analyzers (MEDIUM), CLI tools (LOW)",
          "version": "5.1.0",
          "category": "development",
          "categories": [
            "development"
          ],
          "install_commands": [
            "/plugin marketplace add avifenesh/agentsys",
            "/plugin install deslop@agentsys"
          ]
        },
        {
          "name": "audit-project",
          "source": "./plugins/audit-project",
          "description": "Multi-agent iterative code review until zero issues remain",
          "version": "5.1.0",
          "category": "development",
          "categories": [
            "development"
          ],
          "install_commands": [
            "/plugin marketplace add avifenesh/agentsys",
            "/plugin install audit-project@agentsys"
          ]
        },
        {
          "name": "drift-detect",
          "source": "./plugins/drift-detect",
          "description": "Deep repository analysis to realign project plans with code reality - detects drift, gaps, and creates prioritized reconstruction plans",
          "version": "5.1.0",
          "category": "productivity",
          "categories": [
            "productivity"
          ],
          "install_commands": [
            "/plugin marketplace add avifenesh/agentsys",
            "/plugin install drift-detect@agentsys"
          ]
        },
        {
          "name": "enhance",
          "source": "./plugins/enhance",
          "description": "Master enhancement orchestrator: parallel analyzer execution for plugins, agents, docs, CLAUDE.md, and prompts with unified reporting",
          "version": "5.1.0",
          "category": "development",
          "categories": [
            "development"
          ],
          "install_commands": [
            "/plugin marketplace add avifenesh/agentsys",
            "/plugin install enhance@agentsys"
          ]
        },
        {
          "name": "sync-docs",
          "source": "./plugins/sync-docs",
          "description": "Standalone documentation sync: find outdated refs, update CHANGELOG, flag stale examples based on code changes",
          "version": "5.1.0",
          "category": "development",
          "categories": [
            "development"
          ],
          "install_commands": [
            "/plugin marketplace add avifenesh/agentsys",
            "/plugin install sync-docs@agentsys"
          ]
        },
        {
          "name": "repo-map",
          "source": "./plugins/repo-map",
          "description": "AST-based repository map generation using ast-grep with incremental updates for faster drift analysis",
          "version": "5.1.0",
          "category": "development",
          "categories": [
            "development"
          ],
          "install_commands": [
            "/plugin marketplace add avifenesh/agentsys",
            "/plugin install repo-map@agentsys"
          ]
        },
        {
          "name": "perf",
          "source": "./plugins/perf",
          "description": "Rigorous performance investigation workflow with baselines, profiling, hypotheses, and evidence-backed decisions",
          "version": "5.1.0",
          "category": "development",
          "categories": [
            "development"
          ],
          "install_commands": [
            "/plugin marketplace add avifenesh/agentsys",
            "/plugin install perf@agentsys"
          ]
        },
        {
          "name": "learn",
          "source": "./plugins/learn",
          "description": "Research topics online and create comprehensive learning guides with RAG-optimized indexes",
          "version": "5.1.0",
          "category": "productivity",
          "categories": [
            "productivity"
          ],
          "install_commands": [
            "/plugin marketplace add avifenesh/agentsys",
            "/plugin install learn@agentsys"
          ]
        },
        {
          "name": "agnix",
          "source": "./plugins/agnix",
          "description": "Lint agent configuration files (SKILL.md, CLAUDE.md, hooks, MCP) against 155 rules across 10+ AI tools",
          "version": "5.1.0",
          "category": "development",
          "categories": [
            "development"
          ],
          "install_commands": [
            "/plugin marketplace add avifenesh/agentsys",
            "/plugin install agnix@agentsys"
          ]
        },
        {
          "name": "consult",
          "source": "./plugins/consult",
          "description": "Cross-tool AI consultation: get second opinions from Gemini CLI, Codex CLI, Claude Code, OpenCode, or Copilot CLI with model and thinking effort control",
          "version": "5.1.0",
          "category": "productivity",
          "categories": [
            "productivity"
          ],
          "install_commands": [
            "/plugin marketplace add avifenesh/agentsys",
            "/plugin install consult@agentsys"
          ]
        },
        {
          "name": "debate",
          "source": "./plugins/debate",
          "description": "Structured multi-round debate between AI tools with proposer/challenger roles and verdict",
          "version": "5.1.0",
          "category": "productivity",
          "categories": [
            "productivity"
          ],
          "install_commands": [
            "/plugin marketplace add avifenesh/agentsys",
            "/plugin install debate@agentsys"
          ]
        }
      ]
    }
  ]
}