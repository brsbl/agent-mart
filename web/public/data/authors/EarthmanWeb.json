{
  "author": {
    "id": "EarthmanWeb",
    "display_name": "Terrance Orletsky",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/5847833?u=ffff077195c78d81f486ecb0e6842bf5de9870da&v=4",
    "url": "https://github.com/EarthmanWeb",
    "bio": "WordPress, PHP, JS, React, Full-Stack Senior Developer, IT Consultant, AI Agentic Engineer",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 8,
      "total_skills": 12,
      "total_stars": 1,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "EarthmanWeb",
      "version": "1.0.33",
      "description": "Earthman Media custom Claude plugins",
      "owner_info": {
        "name": "EarthmanWeb",
        "email": "claude-swe@earthman.ca",
        "url": "https://github.com/EarthmanWeb"
      },
      "keywords": [],
      "repo_full_name": "EarthmanWeb/serena-workflow-engine",
      "repo_url": "https://github.com/EarthmanWeb/serena-workflow-engine",
      "repo_description": null,
      "homepage": null,
      "signals": {
        "stars": 1,
        "forks": 0,
        "pushed_at": "2026-01-29T02:08:43Z",
        "created_at": "2026-01-16T01:58:02Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 663
        },
        {
          "path": ".claude-plugin/plugin.json",
          "type": "blob",
          "size": 510
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 6316
        },
        {
          "path": "agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "agents/swe-init-agent.md",
          "type": "blob",
          "size": 11048
        },
        {
          "path": "agents/swe-workflow-coordinator.md",
          "type": "blob",
          "size": 1475
        },
        {
          "path": "commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "commands/swe-cleanup.md",
          "type": "blob",
          "size": 1675
        },
        {
          "path": "commands/swe-goto.md",
          "type": "blob",
          "size": 586
        },
        {
          "path": "commands/swe-init.md",
          "type": "blob",
          "size": 909
        },
        {
          "path": "commands/swe-migrate.md",
          "type": "blob",
          "size": 2765
        },
        {
          "path": "commands/swe-reset.md",
          "type": "blob",
          "size": 1221
        },
        {
          "path": "commands/swe-scaffold.md",
          "type": "blob",
          "size": 3024
        },
        {
          "path": "commands/swe-status.md",
          "type": "blob",
          "size": 807
        },
        {
          "path": "commands/swe-sync.md",
          "type": "blob",
          "size": 1874
        },
        {
          "path": "hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "hooks/hooks.json",
          "type": "blob",
          "size": 3777
        },
        {
          "path": "hooks/post",
          "type": "tree",
          "size": null
        },
        {
          "path": "hooks/post/swe_post_edit_checkpoint.py",
          "type": "blob",
          "size": 4404
        },
        {
          "path": "hooks/post/swe_post_read_state.py",
          "type": "blob",
          "size": 7908
        },
        {
          "path": "hooks/post/swe_post_ruv_swarm_init.py",
          "type": "blob",
          "size": 2235
        },
        {
          "path": "hooks/post/swe_post_serena_replace_fallback.py",
          "type": "blob",
          "size": 4641
        },
        {
          "path": "hooks/post/swe_post_task_learn.py",
          "type": "blob",
          "size": 1875
        },
        {
          "path": "hooks/pre",
          "type": "tree",
          "size": null
        },
        {
          "path": "hooks/pre/swe_pre_bash_test_gate.py",
          "type": "blob",
          "size": 8600
        },
        {
          "path": "hooks/pre/swe_pre_edit_validate.py",
          "type": "blob",
          "size": 3705
        },
        {
          "path": "hooks/pre/swe_pre_task_orchestrate_gate.py",
          "type": "blob",
          "size": 4062
        },
        {
          "path": "hooks/pre/swe_pre_tool_init_gate.py",
          "type": "blob",
          "size": 10583
        },
        {
          "path": "hooks/prompt",
          "type": "tree",
          "size": null
        },
        {
          "path": "hooks/prompt/swe_user_prompt_swarm.py",
          "type": "blob",
          "size": 3039
        },
        {
          "path": "hooks/prompt/swe_user_prompt_workflow.py",
          "type": "blob",
          "size": 12252
        },
        {
          "path": "hooks/session",
          "type": "tree",
          "size": null
        },
        {
          "path": "hooks/session/swe_session_start.py",
          "type": "blob",
          "size": 5560
        },
        {
          "path": "hooks/stop",
          "type": "tree",
          "size": null
        },
        {
          "path": "hooks/stop/swe_stop_workflow_check.py",
          "type": "blob",
          "size": 1571
        },
        {
          "path": "hooks/swe_hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "hooks/swe_hooks/core",
          "type": "tree",
          "size": null
        },
        {
          "path": "hooks/swe_hooks/core/config.py",
          "type": "blob",
          "size": 25844
        },
        {
          "path": "hooks/swe_hooks/core/input.py",
          "type": "blob",
          "size": 1168
        },
        {
          "path": "hooks/swe_hooks/core/output.py",
          "type": "blob",
          "size": 3665
        },
        {
          "path": "hooks/swe_hooks/core/session.py",
          "type": "blob",
          "size": 5181
        },
        {
          "path": "hooks/swe_hooks/core/state_manager.py",
          "type": "blob",
          "size": 13016
        },
        {
          "path": "hooks/swe_hooks/core/wm_validator.py",
          "type": "blob",
          "size": 7925
        },
        {
          "path": "hooks/swe_hooks/core/wm_writer_daemon.py",
          "type": "blob",
          "size": 12499
        },
        {
          "path": "skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/swe-feature-onboard",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/swe-feature-onboard/SKILL.md",
          "type": "blob",
          "size": 8698
        },
        {
          "path": "skills/swe-feature-update",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/swe-feature-update/SKILL.md",
          "type": "blob",
          "size": 5074
        },
        {
          "path": "skills/swe-scaffold-project",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/swe-scaffold-project/SKILL.md",
          "type": "blob",
          "size": 4174
        },
        {
          "path": "skills/swe-swarm-analyze",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/swe-swarm-analyze/SKILL.md",
          "type": "blob",
          "size": 7905
        },
        {
          "path": "skills/swe-swarm-orchestrate",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/swe-swarm-orchestrate/SKILL.md",
          "type": "blob",
          "size": 1568
        },
        {
          "path": "skills/swe-sync",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/swe-sync/SKILL.md",
          "type": "blob",
          "size": 4960
        },
        {
          "path": "skills/swe-wm-update",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/swe-wm-update/SKILL.md",
          "type": "blob",
          "size": 5432
        },
        {
          "path": "skills/swe-workflow-arch-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/swe-workflow-arch-review/SKILL.md",
          "type": "blob",
          "size": 1778
        },
        {
          "path": "skills/swe-workflow-debug-tdd",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/swe-workflow-debug-tdd/SKILL.md",
          "type": "blob",
          "size": 1474
        },
        {
          "path": "skills/swe-workflow-detect-req",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/swe-workflow-detect-req/SKILL.md",
          "type": "blob",
          "size": 1552
        },
        {
          "path": "skills/swe-workflow-research",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/swe-workflow-research/SKILL.md",
          "type": "blob",
          "size": 1544
        },
        {
          "path": "skills/swe-workflow-verify",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/swe-workflow-verify/SKILL.md",
          "type": "blob",
          "size": 1632
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"EarthmanWeb\",\n  \"version\": \"1.0.33\",\n  \"description\": \"Earthman Media custom Claude plugins\",\n  \"owner\": {\n    \"name\": \"EarthmanWeb\",\n    \"email\": \"claude-swe@earthman.ca\",\n    \"url\": \"https://github.com/EarthmanWeb\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"swe\",\n      \"version\": \"1.0.33\",\n      \"description\": \"21-state workflow engine with Serena memory persistence, RLVR learning, and auto plan mode switching\",\n      \"source\": \"./\",\n      \"homepage\": \"https://github.com/EarthmanWeb/serena-workflow-engine\",\n      \"keywords\": [\n        \"workflow\",\n        \"serena\",\n        \"state-machine\",\n        \"memory\",\n        \"hooks\"\n      ]\n    }\n  ]\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"swe\",\n  \"version\": \"1.0.33\",\n  \"description\": \"21-state workflow engine with Serena memory persistence, RLVR learning, and auto plan mode switching\",\n  \"author\": {\n    \"name\": \"EarthmanWeb\",\n    \"email\": \"claude-swe@earthman.ca\"\n  },\n  \"homepage\": \"https://github.com/EarthmanWeb/serena-workflow-engine\",\n  \"repository\": \"https://github.com/EarthmanWeb/serena-workflow-engine\",\n  \"license\": \"MIT\",\n  \"keywords\": [\n    \"workflow\",\n    \"serena\",\n    \"state-machine\",\n    \"memory\",\n    \"hooks\"\n  ]\n}\n",
        "README.md": "# Serena Workflow Engine\n\n21-state workflow engine for Claude Code with RLVR learning, swarm coordination,\nand Serena memory persistence.\n\n## How It Works\n\nThe engine enforces a 21-state workflow:\n\n```\nSTART ‚Üí CLASSIFY ‚Üí PLAN ‚Üí EXECUTE ‚Üí VERIFY ‚Üí DONE ‚Üí CLEANUP\n           ‚Üì\n       RESEARCH / DEBUG / CLARIFY (as needed)\n```\n\nKey features:\n\n- Auto plan mode for medium+ complexity\n- Checkpoint every 3 edits\n- RLVR learning at task completion\n- Swarm agents for large tasks\n\n---\n\n## License\n\nMIT\n\n\n---\n# Plugin Installation\n\nWorks best with Claude Flow\nand the Serena Workflow Engine (SWE) plugin for Claude.\n\n## Install\n\n### 1. Install Claude Flow:\n\n```bash\n\nclaude plugin marketplace add https://github.com/EarthmanWeb/claude-flow-plugin.git#plugin\n\nclaude plugin install claude-flow@claude-flow-plugin  --scope local\n```\n\n### 2. Install SWE (production):\n\n```bash\nclaude plugin marketplace add https://github.com/EarthmanWeb/serena-workflow-engine.git\nclaude plugin install swe@EarthmanWeb --scope local\n```\n\n### 3. Enable auto-update (recommended)\n\nTo receive updates automatically when new versions are released:\n\n1. Run `/plugin` in Claude Code\n2. Press **Tab** to go to **Marketplaces** tab\n3. Select **EarthmanWeb** from the list\n4. Press **Enter**\n5. Select **Enable auto-update**\n\nNow you'll get updates automatically on Claude Code startup.\n\n### 4. Verify installation\n\n```bash\nclaude plugin list\n```\n\nShould show:\n```\n  ‚ùØ claude-flow@claude-flow-plugin\n    Version: 2.5.17\n    Scope: local\n    Status: ‚úî enabled\n\n  ‚ùØ swe@EarthmanWeb\n    Version: 1.0.23\n    Scope: local\n    Status: ‚úî enabled\n```\n\n### 5. Restart Claude Code\n\n- **CLI**: Start a new `claude` session\n- **VSCode**: Reload the window (`Cmd+Shift+P` ‚Üí \"Developer: Reload Window\")\n\n### 6. Initialize the plugin\n\nAfter restart, use this command in CLaude Code:\n\n```\n/swe-init\n```\n\nThis will:\n\n- Run Serena onboarding\n- Copy plugin memories to `.serena/memories/`\n- Create core memories for your codebase\n- Configure .gitignore\n\n### 7. Start working\n\nAfter setup, the workflow guides you automatically. Type any task to begin.\n\nRecommend to start with Onboarding your first feature:\n\n```\n/swe-feature-onboard FEATURE_[YOURSHORTNAME] \n```\nThe onboarding wizard will help you register existing code features for management.\n\n---\n\n## Onboarding Features / Scaffolding New Apps\n\n### Scaffolding a New Project\n\nFor empty or new projects:\n\n```\n/swe-scaffold\n```\n\n8-stage wizard: app type ‚Üí platform config ‚Üí goals ‚Üí assets ‚Üí recommendations ‚Üí\narchitecture ‚Üí memories ‚Üí analysis.\n\nCreates: `.serena/memories/`, core memories, architecture folders.\n\n### Onboarding an Existing Feature\n\nTo register an existing codebase feature:\n\n```\n/swe-onboard [KEY]\n```\n\n5-stage wizard: identifier ‚Üí name ‚Üí folders ‚Üí dependencies ‚Üí analysis mode.\n\nCreates: `FEATURE_[KEY]`, updates `INDEX_FEATURES`, optionally `DOM_*` and\n`SYS_*` memories.\n\n### Quick Onboarding\n\nFast registration without wizard:\n\n```\n/swe-onboard-quick [KEY] [NAME] [PATH]\n```\n\nExample: `/swe-onboard-quick AUTH \"Authentication\" src/auth/`\n\n---\n\n## Troubleshooting\n\n### Plugin not appearing after installation\n\n1. **Verify installation:**\n   ```bash\n   claude plugin list\n   ```\n   Plugin should show `‚úî enabled`\n\n2. **If disabled, enable it:**\n   ```bash\n   claude plugin enable swe@EarthmanWeb --scope local\n   ```\n\n3. **Restart Claude Code:**\n   - CLI: Start new session\n   - VSCode: Reload window\n\n\n### Marketplace not loading\n\n```bash\n# Verify marketplace is registered\nclaude plugin marketplace list\n\n# If not listed, add it again - see above\n```\n\n\n### Debug mode\n\nRun Claude with debug output:\n\n```bash\nclaude --debug\n```\n\nShows plugin loading details, manifest validation errors, and hook registration.\n\n---\n\n\n# **STOP READING HERE IF YOU ARE NOT CONTRIBUTING TO THE PLUGIN**\n\n---\n---\n\n## Local Development Installation\n\nFor contributing to or modifying the plugin itself.\n\n### Setup\n\n```bash\ngit submodule update --init .claude/plugins/serena-workflow-engine\n```\n\n### Update\n\n```bash\ngit submodule update --remote .claude/plugins/serena-workflow-engine\n```\n\n**Recommended scope**: `local` for development plugins (installs into settings.local.json and keeps them out of\nversion control)\n\n---\n\n## Commands\n\n| Command              | Description                |\n| -------------------- | -------------------------- |\n| `/swe-init`          | First-time setup           |\n| `/swe-status`        | Show current state         |\n| `/swe-reset`         | Reset workflow             |\n| `/swe-goto [STATE]`  | Force transition           |\n| `/swe-memory`        | Manage WORKING_MEMORY      |\n| `/swe-scaffold`      | Scaffold new project       |\n| `/swe-onboard [KEY]` | Register existing feature  |\n| `/swe-onboard-quick` | Quick feature registration |\n| `/swe-cleanup`       | Archive completed work     |\n\n---\n\n\n### Troubleshooting\n\nIf you experience issues after changing files in dev, be sure to clear the cache and reinstall:\n\n```bash\n\nrm -rf ~/.claude/plugins/cache/serena-workflow-engine/\nrm -rf ~/.claude/plugins/cache/swe/\nclaude plugin install swe@EarthmanWeb --scope local\n\n```\n---\n\n\n## Development Standards\n\nSWE uses a **dual-location architecture**. Understanding this is critical for\ncontributing:\n\n### File Locations\n\n| Location           | Path                                      | Purpose                      |\n| ------------------ | ----------------------------------------- | ---------------------------- |\n| **Plugin Folder**  | `.claude/plugins/serena-workflow-engine/` | Generic/portable code        |\n| **Local Memories** | `.serena/memories/`                       | Project-specific adaptations |\n\n### Change Classification\n\n| Change Type               | Plugin Folder | Local Memories       |\n| ------------------------- | ------------- | -------------------- |\n| Generic workflow logic    | ‚úÖ YES        | ‚úÖ SYNC (copy after) |\n| Generic hook behavior     | ‚úÖ YES        | ‚ùå No                |\n| Project-specific patterns | ‚ùå No         | ‚úÖ YES               |\n| New skill/command         | ‚úÖ YES        | ‚ùå No                |\n\n\n### Development Docs\n\n- `memories/REF_SWE_DEVELOPMENT.md` - Full development standards\n- After `/swe-init`: `DOM_SWE_DEVELOPMENT`, `DOM_SWE_HOOKS` in local memories\n\n---\n",
        "agents/swe-init-agent.md": "---\nname: swe-init-agent\ndescription: Autonomous SWE plugin initialization with verification\ncapabilities:\n  - environment_detection\n  - mcp_verification\n  - settings_migration\n  - hook_installation\n  - memory_installation\n---\n\n# SWE Init Agent\n\nAutonomous agent for initializing the swe plugin. Completes all setup tasks and verifies success.\n\n## Capabilities\n\n1. **Environment Detection** - Check project state, git, existing directories\n2. **MCP Verification** - Test serena, claude-flow, ruv-swarm respond\n3. **Serena Onboarding** - Run one-time Serena setup\n4. **Claude-Flow Verification** - Verify plugin is installed\n5. **Settings Migration** - Move claudeFlow config to settings.local.json\n6. **Plugin Verification** - Verify SWE plugin is enabled\n7. **Memory Installation** - Copy instruction files to .serena/memories/\n8. **Verification** - Confirm all tasks completed correctly\n\n## Agent Spawn\n\n```javascript\nTask({\n  subagent_type: \"general-purpose\",\n  description: \"SWE plugin initialization\",\n  prompt: `[See TASKS section below]`\n})\n```\n\n## TASKS\n\nExecute ALL tasks (1-10) in order, then verify.\n\n### Task 1: Detect Environment\nReport:\n- Project root (cwd)\n- Git repo status\n- Existing .serena/ directory\n- Existing .claude/ directory\n\n### Task 2: Verify MCP Servers\nTest these MCP tools respond:\n- `mcp__plugin_swe_serena__list_memories`\n- `mcp__claude-flow__system_status`\n- `mcp__plugin_swe_ruv-swarm__swarm_status`\n\nIf any fail, report which ones and stop.\n\n### Task 3: Serena Onboarding\n```javascript\nconst status = await mcp__plugin_swe_serena__check_onboarding_performed();\nif (!status.performed) {\n  await mcp__plugin_swe_serena__onboarding();\n}\n```\n\n### Task 4: Verify Claude-Flow Plugin Installation\n**Check if the claude-flow plugin is installed. If not, guide user to install it.**\n\n```bash\n# Check if claude-flow plugin is installed\nif claude plugin list 2>/dev/null | grep -q \"claude-flow@claude-flow-plugin\"; then\n  echo \"‚úÖ Claude-Flow plugin is installed\"\nelse\n  echo \"‚ö†Ô∏è Claude-Flow plugin NOT installed\"\n  echo \"\"\n  echo \"The SWE plugin works best with Claude-Flow. Please install it:\"\n  echo \"\"\n  echo \"  claude plugin marketplace add https://github.com/EarthmanWeb/claude-flow-plugin.git#plugin\"\n  echo \"  claude plugin install claude-flow@claude-flow-plugin --scope local\"\n  echo \"\"\n  echo \"Then restart Claude Code and run /swe-init again.\"\n  echo \"\"\n  echo \"See the README for full installation instructions:\"\n  echo \"  .claude/plugins/serena-workflow-engine/README.md\"\n  exit 1\nfi\n```\n\n### Task 5: Review CLAUDE.md for Conflicting Workflow Commands\n**Check CLAUDE.md for any workflow/session start instructions that conflict with SWE.**\n\nRead CLAUDE.md and look for:\n- References to `WF_START`, `WF_INIT`, or workflow initialization\n- Instructions to read workflow memories on startup\n- Session start procedures that duplicate SWE hooks\n\nIf found, remove them - SWE hooks handle workflow initialization automatically.\n\n```bash\n# Check for workflow conflicts in CLAUDE.md\nif [ -f \"CLAUDE.md\" ]; then\n  # Look for conflicting patterns\n  if grep -qE \"(WF_START|WF_INIT|read_memory.*WF_|workflow.*start|session.*start.*hook)\" CLAUDE.md; then\n    echo \"Found potential workflow conflicts in CLAUDE.md - review and remove duplicates\"\n    grep -nE \"(WF_START|WF_INIT|read_memory.*WF_|workflow.*start|session.*start.*hook)\" CLAUDE.md\n  else\n    echo \"No conflicting workflow commands in CLAUDE.md\"\n  fi\nfi\n```\n\nIf conflicts found, edit CLAUDE.md to remove the conflicting sections. SWE's SessionStart hook handles all workflow initialization.\n\n### Task 6: Migrate Claude-Flow Settings to settings.local.json\n**CRITICAL: Move claude-flow config from settings.json to settings.local.json**\n\n```bash\nSETTINGS=\".claude/settings.json\"\nSETTINGS_LOCAL=\".claude/settings.local.json\"\n\n# Create settings.local.json if missing\n[ ! -f \"$SETTINGS_LOCAL\" ] && echo '{}' > \"$SETTINGS_LOCAL\"\n\n# Extract and migrate statusLine and claudeFlow from settings.json to settings.local.json\njq -s '\n  (.[0].statusLine // null) as $statusLine |\n  (.[0].claudeFlow // null) as $claudeFlow |\n  .[1] |\n  (if $statusLine then .statusLine = $statusLine else . end) |\n  (if $claudeFlow then .claudeFlow = $claudeFlow else . end)\n' \"$SETTINGS\" \"$SETTINGS_LOCAL\" > \"${SETTINGS_LOCAL}.tmp\" && mv \"${SETTINGS_LOCAL}.tmp\" \"$SETTINGS_LOCAL\"\n\n# Remove statusLine and claudeFlow from settings.json\njq 'del(.statusLine, .claudeFlow)' \"$SETTINGS\" > \"${SETTINGS}.tmp\" && mv \"${SETTINGS}.tmp\" \"$SETTINGS\"\n\necho \"Migrated claudeFlow settings to settings.local.json\"\n```\n\n### Task 7: Verify SWE Plugin is Enabled\n**SWE hooks load directly from the plugin folder - no copying needed.**\n\nThe plugin's `hooks/hooks.json` uses `${CLAUDE_PLUGIN_ROOT}` which is automatically resolved by Claude Code's plugin system.\n\n```bash\nSETTINGS_LOCAL=\".claude/settings.local.json\"\n\n# Ensure plugin is enabled in settings.local.json\nif ! jq -e '.enabledPlugins[\"swe@EarthmanWeb\"] == true' \"$SETTINGS_LOCAL\" > /dev/null 2>&1; then\n  jq '.enabledPlugins[\"swe@EarthmanWeb\"] = true' \"$SETTINGS_LOCAL\" > \"${SETTINGS_LOCAL}.tmp\" && mv \"${SETTINGS_LOCAL}.tmp\" \"$SETTINGS_LOCAL\"\n  echo \"Enabled SWE plugin\"\nelse\n  echo \"SWE plugin already enabled\"\nfi\n\n# Verify hooks.json exists in plugin\nif [ -f \".claude/plugins/serena-workflow-engine/hooks/hooks.json\" ]; then\n  echo \"Plugin hooks.json found - hooks will load automatically\"\n  jq '.hooks | keys' .claude/plugins/serena-workflow-engine/hooks/hooks.json\nelse\n  echo \"ERROR: Plugin hooks.json missing!\"\n  exit 1\nfi\n```\n\n### Task 8: Install Instruction Files to Memories\n\n**IMPORTANT: This plugin uses a forked version of Serena that supports subdirectory organization.**\n\nMemory files are organized in subdirectories and MUST be copied preserving this structure:\n- `wf/` - Workflow state instructions (WF_*.md)\n- `claude/` - Claude behavior docs (CLAUDE.md, CLAUDE_OBLIGATIONS.md)\n- `ref/` - Reference documentation (REF_*.md)\n- `dom/` - Domain documentation (DOM_*.md)\n- `feature/` - Feature configurations (FEATURE_*.md)\n- `arch/` - Architecture documentation (ARCH_*.md)\n- `index/` - Index files (INDEX_*.md)\n\n```bash\n# Create directory structure (preserving subdirectory organization)\nmkdir -p .serena/memories/{wf,claude,ref,dom,feature,arch,index,archived}\n\n# Archive existing files in subdirectories\ncd .serena/memories\nfor dir in wf claude ref dom feature arch; do\n  if [ -d \"$dir\" ]; then\n    for f in \"$dir\"/*.md; do\n      [ -f \"$f\" ] && mv \"$f\" archived/\"$(basename \"$f\").$(date +%Y%m%d_%H%M%S).bak\" 2>/dev/null\n    done\n  fi\ndone\ncd - >/dev/null\n\n# Recursively copy ALL memories preserving directory structure\ncp -r .claude/plugins/serena-workflow-engine/memories/* .serena/memories/\n\necho \"Installed instruction files with directory structure\"\necho \"Subdirectories:\"\nls -d .serena/memories/*/ 2>/dev/null\necho \"Total files:\"\nfind .serena/memories -name \"*.md\" -type f | wc -l\n```\n\n### Task 9: Create and Customize Core Memories\nCheck for and create if missing:\n- `.serena/memories/_INDEX.md` (from memories/_INDEX.md)\n- `.serena/memories/INDEX_FEATURES.md`\n\n**IMPORTANT: Customize _INDEX.md after copying:**\n1. List actual FEATURE_* files in `## Active Features` section\n2. Remove the `<!-- TEMPLATE: ... -->` comment block\n3. Clear placeholder text from `## Current Session`\n\n```bash\n# Copy _INDEX if missing\n[ ! -f \".serena/memories/_INDEX.md\" ] && cp .claude/plugins/serena-workflow-engine/memories/_INDEX.md .serena/memories/\n\n# List existing FEATURE_* files to populate Active Features\necho \"Available features to add to _INDEX:\"\nls .serena/memories/FEATURE_*.md 2>/dev/null | xargs -I{} basename {} .md\n```\n\nThen edit `.serena/memories/_INDEX.md`:\n- Replace `[FEATURE_X](FEATURE_X) - Description` with actual features\n- Remove template comment block\n\n### Task 10: Configure Gitignore\nAdd these entries to .gitignore if not present:\n```\n# Claude Code Plugin - Local files\nCLAUDE.local.md\n.claude/settings.local.json\n.claude/workflow-state.json\n.claude/setup-state.json\n.claude/swe-setup-complete.json\n\n# Runtime directories\n**/.claude-flow\n**/.swarm\n\n# Session memories\n.serena/memories/WORKING_MEMORY_*.md\n.serena/archive-memories/\n.serena/archive-specs/\n```\n\n## VERIFICATION\n\nAfter all tasks, verify these 8 conditions:\n\n1. **MCP Servers**: All three respond\n2. **settings.json**: NO hooks, statusLine, or claudeFlow\n   ```bash\n   jq 'has(\"hooks\"), has(\"statusLine\"), has(\"claudeFlow\")' .claude/settings.json\n   # Expected: false false false\n   ```\n3. **settings.local.json**: HAS statusLine and claudeFlow (hooks load from plugin)\n   ```bash\n   jq 'has(\"statusLine\"), has(\"claudeFlow\")' .claude/settings.local.json\n   # Expected: true true\n   ```\n4. **SWE Plugin Enabled**: Plugin is active\n   ```bash\n   jq '.enabledPlugins[\"swe@EarthmanWeb\"]' .claude/settings.local.json\n   # Expected: true\n   ```\n5. **Plugin Hooks Exist**: hooks.json in plugin folder\n   ```bash\n   jq '.hooks | keys' .claude/plugins/serena-workflow-engine/hooks/hooks.json\n   # Expected: [\"PostToolUse\", \"PreToolUse\", \"SessionStart\", \"Stop\", \"UserPromptSubmit\"]\n   ```\n6. **Instruction Files**: >= 26 files with subdirectory structure\n   ```bash\n   # Verify subdirectories exist\n   ls -d .serena/memories/{wf,claude,ref,dom,feature,arch}/ 2>/dev/null && echo \"‚úÖ Subdirectories exist\"\n   # Count total instruction files\n   find .serena/memories -name \"*.md\" -type f | wc -l\n   ```\n7. **Core Memories**: _INDEX.md and INDEX_FEATURES.md exist\n8. **Serena Onboarding**: Complete\n\n## COMPLETION\n\nOnly after ALL verifications pass:\n\n```bash\n# Read version from plugin.json\nPLUGIN_VERSION=$(jq -r '.version' .claude/plugins/serena-workflow-engine/.claude-plugin/plugin.json)\n\ncat > .claude/swe-setup-complete.json << EOF\n{\n  \"complete\": true,\n  \"timestamp\": \"$(date -Iseconds)\",\n  \"mcps\": [\"serena\", \"claude-flow\", \"ruv-swarm\"],\n  \"version\": \"${PLUGIN_VERSION}\",\n  \"verified\": true\n}\nEOF\n```\n\n## Output Summary\n\n```\n**SETUP COMPLETE**\n\n- MCP Servers: serena, claude-flow, ruv-swarm\n- Serena Onboarding: Complete\n- Claude-Flow Plugin: Verified installed\n- Settings Migration: claudeFlow config moved to settings.local.json\n- SWE Plugin: Enabled (hooks load from plugin folder)\n- Instruction Files: Copied to .serena/memories/\n- Core Memories: Created\n- Gitignore: Configured\n\n**Next steps:**\n1. Run /swe-feature-onboard [KEY] to register your first feature\n2. Or start working - workflow will guide you\n```\n\n## Troubleshooting\n\n### MCP Won't Connect\n```bash\nwhich uvx && which npx\ncat ~/.claude.json | jq\nclaude mcp logs [server-name]\n```\n\n### Serena Language Server Error\n```bash\nrm -rf ~/.serena/language_servers/static/BashLanguageServer\n# Then restart Claude Code\n```\n\n### Verification Fails\nIdentify which check failed, return to that task, fix, and re-verify.\n\n### Hooks Not Firing\n**Cause:** Plugin not enabled or hooks.json missing.\n\n**Fix:**\n```bash\n# Verify plugin enabled\njq '.enabledPlugins' .claude/settings.local.json\n\n# Verify hooks.json exists\ncat .claude/plugins/serena-workflow-engine/hooks/hooks.json | jq '.hooks | keys'\n```\n",
        "agents/swe-workflow-coordinator.md": "---\nname: swe-workflow-coordinator\ndescription: Coordinates swarm tasks for WF_SWARM_ORCHESTRATE\ncapabilities:\n  - swarm_coordination\n  - task_distribution\n  - result_synthesis\n---\n\n# Workflow Coordinator Agent\n\nCentral coordinator for multi-agent swarm operations.\n\n## Responsibilities\n\n1. **Pre-Swarm Research** - Read memories, identify subtasks\n2. **Swarm Selection** - Choose Claude-Flow, RUV-Swarm, or sequential\n3. **Agent Spawning** - Spawn ALL agents in ONE message\n4. **Result Collection** - Monitor, collect, synthesize\n\n## Critical Rules\n\n- NEVER run `npx claude-flow init` - use MCP tools only\n- Spawn agents in parallel (single message)\n- Store state in WORKING_MEMORY\n\n## DAA Integration\n\n```javascript\nmcp__ruv-swarm__daa_agent_create({\n  id: \"workflow-coordinator\",\n  capabilities: [\"swarm_coordination\", \"task_distribution\"],\n  cognitivePattern: \"systems\",\n  enableMemory: true,\n  learningRate: 0.8\n})\n```\n\n## Swarm Selection Logic\n\n```javascript\nconst swarmSystem = workflowState.swarm_system;\n\nswitch (swarmSystem) {\n  case \"claude-flow\":\n    // Use Claude Flow MCP\n    mcp__claude-flow__swarm_init({ topology: \"mesh\" });\n    break;\n  case \"ruv-swarm\":\n    // Use RUV-Swarm MCP\n    mcp__ruv-swarm__daa_init({ enableLearning: true });\n    break;\n  default:\n    // Sequential fallback\n    break;\n}\n```\n\n## RLVR Learning\n\nAfter task completion:\n1. Receive performance score\n2. Adapt via `mcp__ruv-swarm__daa_agent_adapt`\n3. Share knowledge with other agents\n",
        "commands/swe-cleanup.md": "---\nname: swe-cleanup\ndescription: Archive completed memories and specs\nargument-hint: [all|memories|specs]\n---\n\n# /swe-cleanup [target]\n\nArchive completed work to `.serena/archive-*` directories.\n\n## Options\n\n- `/swe-cleanup` - Scan and prompt for confirmation\n- `/swe-cleanup memories` - Archive WORKING_MEMORY_* files with status: Completed\n- `/swe-cleanup specs` - Archive SPEC_* files (requires confirmation)\n- `/swe-cleanup all` - Archive both\n\n## Archivable Criteria\n\n### Working Memories\n- Status field contains \"Completed\"\n- Task marked as done\n\n### Specs\n- User confirmation required\n- Typically after implementation complete\n\n## Archive Locations\n\n- `.serena/archive-memories/` - Completed working memories\n- `.serena/archive-specs/` - Completed specifications\n\n## Implementation\n\n1. Scan for archivable files\n2. Display list of found files\n3. Use AskUserQuestion for confirmation:\n\n```javascript\nAskUserQuestion({\n  questions: [\n    {\n      question: \"Found [N] files to archive. Proceed with cleanup?\",\n      header: \"Cleanup\",\n      options: [\n        {\n          label: \"Archive all\",\n          description: \"Move all listed files to archive directories\"\n        },\n        {\n          label: \"Archive memories only\",\n          description: \"Only archive completed WORKING_MEMORY files\"\n        },\n        {\n          label: \"Archive specs only\",\n          description: \"Only archive SPEC_* files\"\n        },\n        {\n          label: \"Cancel\",\n          description: \"Don't archive anything\"\n        }\n      ],\n      multiSelect: false\n    }\n  ]\n})\n```\n\n4. Move files with timestamp prefix based on selection\n5. Update indexes\n6. Report archived files count\n",
        "commands/swe-goto.md": "---\nname: swe-goto\ndescription: Force transition to specific state (debug/recovery)\nargument-hint: [STATE]\n---\n\n# /swe-goto [STATE]\n\nForce transition to a specific workflow state.\n\n## Usage\n\n```\n/swe-goto WF_EXECUTE\n/swe-goto WF_CHECKPOINT\n```\n\n## Warning\n\n‚ö†Ô∏è This bypasses normal transition validation.\nUse only for debugging or recovery.\n\n## Implementation\n\n1. Validate target exists in states.json\n2. Warn if transition is unusual\n3. Update workflow-state.json with forced flag\n4. Add note to WORKING_MEMORY\n5. Read target WF_* memory\n6. Report: `> **On step [STATE]** (forced)`\n",
        "commands/swe-init.md": "---\nname: swe-init\ndescription: Initialize swe plugin via autonomous agent\n---\n\n# /swe-init\n\nFirst-time setup command for the swe plugin. Launches an autonomous agent to complete all initialization tasks and verify success.\n\n## When to Run\n\n- First time using plugin in a project\n- After cloning a repo with the plugin\n- When `session-start.sh` reports \"INITIAL SETUP REQUIRED\"\n\n## Execution\n\n```javascript\nTask({\n  subagent_type: \"general-purpose\",\n  description: \"SWE plugin initialization\",\n  prompt: `You are the SWE Init Agent.\n\nRead .claude/plugins/serena-workflow-engine/agents/swe-init-agent.md and execute ALL tasks (1-10), then run all 8 verifications.\n\nOnly create swe-setup-complete.json after ALL verifications pass.\nOutput the completion summary at the end.`\n})\n```\n\n## Agent Definition\n\nSee [agents/swe-init-agent.md](../agents/swe-init-agent.md) for tasks, verifications, and troubleshooting.\n",
        "commands/swe-migrate.md": "---\nname: swe-migrate\ndescription: Migrate legacy WF_* files and CLAUDE.md to plugin-based workflow\n---\n\n# /swe-migrate\n\nMigrate existing project from legacy WF_* memories and CLAUDE.md-based workflow to plugin-based workflow.\n\n## When to Use\n\n- Projects with existing `.serena/memories/WF_*.md` files (legacy format)\n- Migrating from CLAUDE.md-based workflow instructions\n- After installing swe plugin\n- When legacy WF_* files don't match plugin's states.json\n\n## Process (5 Steps)\n\n### Step 1: Backup Existing Files\n\n```bash\n# Backup legacy WF_* memories\nmkdir -p .serena/archive-memories/\ncp .serena/memories/WF_*.md .serena/archive-memories/\n\n# Backup CLAUDE.md\ncp CLAUDE.md CLAUDE.md.bak\n```\n\n### Step 2: Audit Legacy WF_* Files\n\nFor each existing WF_*.md, verify against `states.json`:\n\n| Check | Action if Missing |\n|-------|-------------------|\n| `requiredActions` complete? | Add missing from states.json |\n| Transitions correct? | Update to match `transitionMatrix` |\n| `planMode` documented? | Add from states.json |\n| RLVR signal present? | Add `signalType` and `rewardImpact` |\n| Permissions stated? | Add `allowEdit`/`allowWrite` |\n| ‚â§100 lines? | Condense, move detail to cross-refs |\n| Icon correct? | Use icon from states.json |\n\n### Step 3: Clean CLAUDE.md\n\nRemove workflow sections from CLAUDE.md:\n- Entry point instructions (\"BEFORE responding to ANY user message...\")\n- Step reporting enforcement\n- Workflow state transition rules\n- WF_* reading requirements\n\nKeep in CLAUDE.md:\n- Project-specific instructions\n- Coding standards\n- Non-workflow guidance\n\n### Step 4: Verify Plugin Hooks\n\nEnsure hooks are configured in `.claude/settings.local.json`\n\n### Step 5: Test Workflow\n\nRun a simple test to verify workflow functions:\n1. Start new session\n2. Verify WF_START is read\n3. Verify step reporting works\n\n## Output\n\n**‚úÖ WORKFLOW MIGRATION**\n\n**Backup:**\n- Legacy WF_* ‚Üí .serena/archive-memories/ ([count] files)\n- CLAUDE.md ‚Üí CLAUDE.md.bak\n\n**Migration:**\n- Legacy WF_* files archived (now provided via plugin hooks)\n- CLAUDE.md cleaned\n\n**Verification:**\n- Plugin hooks configured\n- Workflow functions correctly\n\n**Status:** SUCCESS\n\n## Rollback\n\nIf migration fails:\n\n```bash\n# Restore legacy WF_* files\ncp .serena/archive-memories/WF_*.md .serena/memories/\n\n# Restore CLAUDE.md\nmv CLAUDE.md.bak CLAUDE.md\n```\n\n## Differences: Legacy vs Plugin Format\n\n| Aspect | Legacy | Plugin |\n|--------|--------|--------|\n| Location | .serena/memories/ | Plugin instructions/ ‚Üí injected via hooks |\n| Format | Variable | Standardized ‚â§100 lines |\n| RLVR | Missing | Required per state |\n| planMode | Often missing | Required per state |\n| Permissions | Implicit | Explicit allowEdit/allowWrite |\n| Icons | Ad-hoc emoji | states.json defined |\n",
        "commands/swe-reset.md": "---\nname: swe-reset\ndescription: Reset workflow state (requires confirmation)\n---\n\n# /swe-reset\n\nReset workflow to WF_START state.\n\n## Warning\n\n‚ö†Ô∏è This will:\n- Archive current WORKING_MEMORY\n- Delete workflow-state.json\n- Reset all state tracking\n\n## Confirmation with AskUserQuestion\n\n**Use AskUserQuestion for destructive action confirmation:**\n\n```javascript\nAskUserQuestion({\n  questions: [\n    {\n      question: \"‚ö†Ô∏è This will reset all workflow state. Are you sure?\",\n      header: \"Reset\",\n      options: [\n        {\n          label: \"Yes, reset workflow\",\n          description: \"Archive current WM and delete state files\"\n        },\n        {\n          label: \"No, cancel\",\n          description: \"Keep current workflow state\"\n        }\n      ],\n      multiSelect: false\n    }\n  ]\n})\n```\n\n## Implementation\n\n1. Show current state and warning\n2. Call AskUserQuestion for confirmation\n3. If \"Yes, reset workflow\" selected:\n   - Archive current WORKING_MEMORY (append _archived_timestamp)\n   - Delete workflow-state.json\n   - Delete workflow-layers.json (if exists)\n   - Output: \"Workflow reset. Read WF_START to begin.\"\n4. If \"No, cancel\" selected:\n   - Output: \"Reset cancelled. Workflow state unchanged.\"\n",
        "commands/swe-scaffold.md": "---\nname: swe-scaffold\ndescription: Initialize workflow for new empty projects\n---\n\n# /swe-scaffold\n\nInitialize workflow system for new or empty projects.\n\n## When to Use\n\n- New projects without existing memories\n- Projects missing INDEX_FEATURES\n- Converting existing projects to workflow system\n\n## Process\n\n### Stage 1: Project Detection\n\nDetect:\n- Project root (git or cwd)\n- Package manager (npm, composer, cargo, pip, go)\n- Primary language (TypeScript, Python, PHP, Rust, Go, etc.)\n- Framework (if detectable)\n\n### Stage 2: Directory Setup\n\nCreate required directories:\n\n```bash\nmkdir -p .serena/memories\nmkdir -p .claude/skills\nmkdir -p .claude/hooks\n```\n\n### Stage 3: Core Memory Creation\n\nCreate from templates:\n\n**_INDEX.md** - Navigation hub\n```markdown\n# _INDEX - Memory Navigation\n\n## Quick Reference\n- Features: INDEX_FEATURES\n- Architecture: ARCH_INDEX\n- Workflows: INDEX_WORKFLOWS_STATES\n\n## Memory Types\n| Prefix | Purpose |\n|--------|---------|\n| FEATURE_ | Feature configs |\n| DOM_ | Domain behaviors |\n| SYS_ | System references |\n| REF_ | Reference docs |\n| INDEX_ | Navigation |\n| WF_ | Workflow states |\n| WORKING_MEMORY_ | Session state |\n```\n\n**INDEX_FEATURES.md** - Empty feature registry\n```markdown\n# INDEX_FEATURES\n\n## Registered Features\n(none yet - run /swe-feature-onboard to add)\n\n## Quick Start\n1. `/swe-feature-onboard [KEY]` - Full wizard\n2. `/swe-onboard-quick [KEY]` - Fast setup\n```\n\n**ARCH_INDEX.md** - Basic architecture placeholder\n```markdown\n# ARCH_INDEX - Architecture Overview\n\n## Project Type\n[Detected or unknown]\n\n## Primary Language\n[Detected]\n\n## Framework\n[Detected or none]\n\n## Structure\n(Run /swe-feature-onboard to populate)\n```\n\n### Stage 4: First Feature Prompt\n\n**‚úÖ PROJECT SCAFFOLDED**\n\nCreated:\n- .serena/memories/\n- _INDEX\n- INDEX_FEATURES\n- ARCH_INDEX\n\nYour project needs at least one feature to enable code changes.\n\nWhat is the main codebase?\n- **Name:** [e.g., \"Backend API\"]\n- **Key:** [e.g., \"BACKEND\"]\n- **Path:** [e.g., \"src/\"]\n\nOptions:\n- **[A]** Set up now with /swe-feature-onboard (recommended)\n- **[B]** Quick setup with /swe-onboard-quick\n- **[C]** Skip - add features later (research-only mode)\n\n### Stage 5: Optional Swarm Analysis\n\nIf swarm MCP available:\n```\nAI-powered codebase analysis available.\n\n[A] Full DAA analysis (creates DOM_*, SYS_*, detailed memories)\n[B] Quick scan (basic structure)\n[C] Skip\n```\n\n## Minimal Mode\n\nIf user skips feature setup, workflow enters minimal mode:\n- Allowed: WF_START, WF_RESEARCH, WF_CLARIFY\n- Blocked: WF_EXECUTE, WF_CHECKPOINT\n- Message: \"Feature onboarding required for code changes\"\n\n## Output\n\n**‚úÖ SCAFFOLD COMPLETE**\n\n| Field | Value |\n|-------|-------|\n| Project Root | [path] |\n| Language | [detected] |\n| Framework | [detected or none] |\n| Package Mgr | [detected] |\n\n**Memories Created:**\n- _INDEX\n- INDEX_FEATURES\n- ARCH_INDEX\n\n**Next Steps:**\n1. Run `/swe-feature-onboard [KEY]` to add your first feature\n2. Or `/swe-onboard-quick [KEY]` for fast setup\n\n**Workflow Mode:** [full|minimal]\n",
        "commands/swe-status.md": "---\nname: swe-status\ndescription: Display current workflow state and valid transitions\n---\n\n# /swe-status\n\nDisplay current workflow state information.\n\n## Output\n\n**üìä WORKFLOW STATUS**\n\n| Field | Value |\n|-------|-------|\n| Session ID | [session_id] |\n| Current State | [WF_STATE] |\n| Previous State | [WF_STATE] |\n| Plan Mode | [true/false] |\n| Working Memory | [WORKING_MEMORY_file] |\n| Feature(s) | [active features] |\n| Edits Since Checkpoint | [count]/3 |\n\n**Valid Transitions:**\n- ‚Üí [state1]\n- ‚Üí [state2]\n\n**State History (last 5):** [state1] ‚Üí [state2] ‚Üí ...\n\n**RLVR:** Trajectory [trajectory_id], Steps [count]\n\n## Implementation\n\n1. Parse `.claude/workflow-state.json`\n2. Read current WORKING_MEMORY\n3. Load valid transitions from `state-machine/states.json`\n4. Display formatted output\n",
        "commands/swe-sync.md": "---\nname: swe-sync\ndescription: Sync plugin memories to local project using ruv-swarm\n---\n\n# /swe-sync\n\nSynchronize Serena memories between plugin and local project.\n\n## Usage\n\n```\n/swe-sync                           # Sync all memories plugin ‚Üí local\n/swe-sync --dry-run                 # Preview changes without syncing\n/swe-sync category=wf               # Sync only WF_ workflow files\n/swe-sync category=ref              # Sync only REF_ reference files\n/swe-sync direction=local-to-plugin # Sync local changes back to plugin\n```\n\n## Process\n\nUses ruv-swarm for parallel file comparison:\n1. Initialize mesh swarm with DAA coordination\n2. Spawn analyzer agents for plugin and local directories\n3. Compare files by category (wf, ref, or all)\n4. Report differences in table format\n5. Execute sync if not --dry-run\n6. Verify sync completion\n\n## ‚õî CRITICAL SAFETY RULES\n\n**This command ONLY copies plugin files to local. It NEVER touches local-only files.**\n\n### What it does:\n- Copies files from `.claude/plugins/serena-workflow-engine/memories/` TO `.serena/memories/`\n- Updates existing files if plugin version is newer\n- Preserves ALL local-only files (memories created by user, WM_* files, stats/, etc.)\n\n### What it NEVER does:\n- Delete ANY files in destination\n- Remove local-only memories\n- Touch WM_* working memory files\n- Modify stats/ directory\n\n**ONLY USE THIS PATTERN:**\n```bash\n# Copy plugin memories to local, preserve everything else\ncp -n .claude/plugins/serena-workflow-engine/memories/**/*.md .serena/memories/\n# Or for specific files:\ncp .claude/plugins/serena-workflow-engine/memories/wf/WF_CLASSIFY.md .serena/memories/wf/\n```\n\n**‚õî FORBIDDEN COMMANDS - NEVER USE:**\n```bash\nrsync --delete  # ‚õî DELETES USER DATA\nrm -rf          # ‚õî DELETES USER DATA\nmv              # ‚õî CAN LOSE DATA\n```\n\n## Implementation\n\nSee: `skills/swe-sync/SKILL.md`\n",
        "hooks/hooks.json": "{\n  \"description\": \"Serena Workflow Engine - 21-state workflow with RLVR learning\",\n  \"hooks\": {\n    \"SessionStart\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python3 ${CLAUDE_PLUGIN_ROOT}/hooks/session/swe_session_start.py\",\n            \"timeout\": 10\n          }\n        ]\n      }\n    ],\n    \"UserPromptSubmit\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python3 ${CLAUDE_PLUGIN_ROOT}/hooks/prompt/swe_user_prompt_workflow.py\",\n            \"timeout\": 10\n          },\n          {\n            \"type\": \"command\",\n            \"command\": \"python3 ${CLAUDE_PLUGIN_ROOT}/hooks/prompt/swe_user_prompt_swarm.py\",\n            \"timeout\": 10\n          }\n        ]\n      }\n    ],\n    \"PreToolUse\": [\n      {\n        \"matcher\": \".*\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python3 ${CLAUDE_PLUGIN_ROOT}/hooks/pre/swe_pre_tool_init_gate.py\",\n            \"timeout\": 5000\n          }\n        ]\n      },\n      {\n        \"matcher\": \"Bash\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python3 ${CLAUDE_PLUGIN_ROOT}/hooks/pre/swe_pre_bash_test_gate.py\",\n            \"timeout\": 10\n          }\n        ]\n      },\n      {\n        \"matcher\": \"Write|Edit|MultiEdit|mcp__serena__replace_symbol_body|mcp__serena__insert_after_symbol|mcp__serena__insert_before_symbol\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python3 ${CLAUDE_PLUGIN_ROOT}/hooks/pre/swe_pre_edit_validate.py\",\n            \"timeout\": 10\n          }\n        ]\n      },\n      {\n        \"matcher\": \"mcp__claude-flow__task_orchestrate|mcp__ruv-swarm__task_orchestrate|mcp__plugin_claude-flow_ruv-swarm__task_orchestrate|mcp__plugin_claude-flow_claude-flow__task_orchestrate\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python3 ${CLAUDE_PLUGIN_ROOT}/hooks/pre/swe_pre_task_orchestrate_gate.py\",\n            \"timeout\": 10\n          }\n        ]\n      }\n    ],\n    \"PostToolUse\": [\n      {\n        \"matcher\": \"mcp__ruv-swarm__swarm_init\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python3 ${CLAUDE_PLUGIN_ROOT}/hooks/post/swe_post_ruv_swarm_init.py\",\n            \"timeout\": 10\n          }\n        ]\n      },\n      {\n        \"matcher\": \"mcp__serena__replace_content|mcp__plugin_swe_serena__replace_content\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python3 ${CLAUDE_PLUGIN_ROOT}/hooks/post/swe_post_serena_replace_fallback.py\",\n            \"timeout\": 10\n          }\n        ]\n      },\n      {\n        \"matcher\": \"Write|Edit|MultiEdit|mcp__serena__replace_symbol_body|mcp__serena__insert_after_symbol|mcp__serena__insert_before_symbol\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python3 ${CLAUDE_PLUGIN_ROOT}/hooks/post/swe_post_edit_checkpoint.py\",\n            \"timeout\": 10\n          }\n        ]\n      },\n      {\n        \"matcher\": \"mcp__serena__read_memory|mcp__plugin_swe_serena__read_memory\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python3 ${CLAUDE_PLUGIN_ROOT}/hooks/post/swe_post_read_state.py\",\n            \"timeout\": 10\n          },\n          {\n            \"type\": \"command\",\n            \"command\": \"python3 ${CLAUDE_PLUGIN_ROOT}/hooks/post/swe_post_task_learn.py\",\n            \"timeout\": 10\n          }\n        ]\n      }\n    ],\n    \"Stop\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python3 ${CLAUDE_PLUGIN_ROOT}/hooks/stop/swe_stop_workflow_check.py\",\n            \"timeout\": 10\n          }\n        ]\n      }\n    ]\n  }\n}\n",
        "hooks/post/swe_post_edit_checkpoint.py": "#!/usr/bin/env python3\n\"\"\"PostToolUse hook for Edit - Checkpoint enforcement.\n\nTracks edit count and BLOCKS further edits after threshold until WM is updated.\nUses session isolation for edit counting and persistence to WM file.\n\nENFORCEMENT: This hook converts soft reminders to hard blocking per SPEC_WM_ENFORCEMENT.\n\"\"\"\n\nimport os\nimport sys\nimport json\n\nPLUGIN_ROOT = os.environ.get('CLAUDE_PLUGIN_ROOT', '')\nif PLUGIN_ROOT:\n    hooks_dir = os.path.join(PLUGIN_ROOT, 'hooks')\n    if hooks_dir not in sys.path:\n        sys.path.insert(0, hooks_dir)\n\ntry:\n    from swe_hooks.core.output import HookOutput, output_empty, output_status\n    from swe_hooks.core.input import read_stdin_safe, get_input_field\n    from swe_hooks.core.state_manager import StateManager\n    from swe_hooks.core.session import extract_session_id, find_working_memory_for_session\n    from swe_hooks.core.config import (\n        persist_edit_to_wm, check_wm_staleness, check_wm_progress_updated\n    )\nexcept ImportError as e:\n    output = {\"hookSpecificOutput\": {\"hookEventName\": \"PostToolUse\", \"additionalContext\": f\"SWE import error: {e}\"}}\n    print(json.dumps(output), file=sys.stdout)\n    sys.exit(0)\n\n# Edit threshold before checkpoint is REQUIRED (not just reminded)\nCHECKPOINT_THRESHOLD = 3\n\n\ndef main():\n    try:\n        input_data = read_stdin_safe(timeout_seconds=2.0)\n        cwd = get_input_field(input_data, 'cwd', default=os.getcwd())\n\n        # Extract session ID for session isolation\n        transcript_path = get_input_field(input_data, 'transcript_path', default='')\n        session_id = extract_session_id(transcript_path)\n\n        # Get edited file path if available\n        tool_input = input_data.get('tool_input', {})\n        edited_file = tool_input.get('file_path', '') or tool_input.get('path', '')\n\n        # Find working memory for this session\n        wm_filepath = find_working_memory_for_session(cwd, session_id)\n        \n        if not wm_filepath:\n            # No working memory yet - use in-memory tracking only\n            state_mgr = StateManager(cwd, session_id=session_id)\n            count = state_mgr.increment_edits()\n            \n            if state_mgr.should_checkpoint(CHECKPOINT_THRESHOLD):\n                output = HookOutput(event_name=\"PostToolUse\")\n                output.add_message(f\"üíæ CHECKPOINT: {count} edits - Create WM first\")\n                state_mgr.reset_edit_counter()\n                output.output_and_exit()\n                return\n            \n            output_status(f\"WM: edit #{count} (no WM yet)\")\n            return\n\n        # Persist edit to working memory file\n        success, edit_count = persist_edit_to_wm(cwd, wm_filepath, edited_file)\n        \n        if not success:\n            # Fallback to in-memory tracking\n            state_mgr = StateManager(cwd, session_id=session_id)\n            edit_count = state_mgr.increment_edits()\n\n        # Check if checkpoint is needed\n        if edit_count >= CHECKPOINT_THRESHOLD:\n            # Check if WM was updated (progress section has content)\n            wm_updated = check_wm_progress_updated(cwd, wm_filepath)\n            \n            if not wm_updated:\n                # BLOCK: WM is stale, require update\n                output = HookOutput(event_name=\"PostToolUse\")\n                output.add_message(f\"\"\"üõë CHECKPOINT REQUIRED: {edit_count} edits since last update\n\nYou have made {edit_count} edits without updating WM.\n\n**UPDATE WM NOW:**\n1. Update `## Progress` section with completed work\n2. Mark completed items with `[x]`\n3. Update `**Files:**` with files you've edited\n4. Verify `## Workflow Context` is current\n\nAfter updating, you may continue editing.\"\"\")\n                output.output_and_exit()\n                return\n            else:\n                # WM was updated - this is just a notification\n                output = HookOutput(event_name=\"PostToolUse\")\n                output.add_message(f\"üíæ Edit tracked ({edit_count} total)\")\n                output.output_and_exit()\n                return\n\n        # Under threshold - just track silently with concise status\n        output_status(f\"WM: edit #{edit_count}\")\n\n    except Exception as e:\n        output = {\"hookSpecificOutput\": {\"hookEventName\": \"PostToolUse\", \"additionalContext\": f\"Checkpoint error: {e}\"}}\n        print(json.dumps(output), file=sys.stdout)\n        sys.exit(0)\n\n\nif __name__ == '__main__':\n    main()\n",
        "hooks/post/swe_post_read_state.py": "#!/usr/bin/env python3\n\"\"\"PostToolUse hook for read_memory - State transitions.\n\nWhen a WF_* memory is read, this hook transitions the workflow state.\nUses session isolation to ensure state changes only affect the current session.\n\"\"\"\n\nimport os\nimport sys\nimport json\n\nPLUGIN_ROOT = os.environ.get('CLAUDE_PLUGIN_ROOT', '')\nif PLUGIN_ROOT:\n    hooks_dir = os.path.join(PLUGIN_ROOT, 'hooks')\n    if hooks_dir not in sys.path:\n        sys.path.insert(0, hooks_dir)\n\ntry:\n    from swe_hooks.core.output import HookOutput, output_empty, output_status\n    from swe_hooks.core.input import read_stdin_safe, get_input_field\n    from swe_hooks.core.state_manager import StateManager, STATE_ICONS\n    from swe_hooks.core.session import extract_session_id, get_project_root, find_working_memory_for_session\n    from swe_hooks.core.config import append_transition_to_wm\n    from swe_hooks.core.wm_writer_daemon import async_wm_write\n    from datetime import datetime\n    import re\n    import time\nexcept ImportError as e:\n    output = {\"hookSpecificOutput\": {\"hookEventName\": \"PostToolUse\", \"additionalContext\": f\"SWE import error: {e}\"}}\n    print(json.dumps(output), file=sys.stdout)\n    sys.exit(0)\n\n\ndef update_test_docs_timestamp(wm_filepath: str, session_id: str) -> bool:\n    \"\"\"Update or add the Test Docs timestamp in working memory.\n\n    Replaces any existing 'Test Docs: Read @<timestamp>' with current timestamp.\n    If none exists, appends after the Workflow Context section.\n\n    Returns True if successful.\n    \"\"\"\n    if not wm_filepath or not os.path.exists(wm_filepath):\n        return False\n\n    try:\n        with open(wm_filepath, 'r', encoding='utf-8') as f:\n            content = f.read()\n\n        current_timestamp = int(time.time())\n        new_marker = f\"Test Docs: Read @{current_timestamp}\"\n\n        # Pattern to match existing timestamp marker\n        pattern = r'Test Docs: Read @\\d+'\n\n        if re.search(pattern, content):\n            # Replace existing timestamp\n            updated_content = re.sub(pattern, new_marker, content)\n        else:\n            # Add after Workflow Context section or at end of file\n            context_match = re.search(r'(## Workflow Context\\n(?:.*\\n)*?)(\\n## |\\Z)', content)\n            if context_match:\n                insert_pos = context_match.end(1)\n                updated_content = content[:insert_pos] + f\"\\n{new_marker}\\n\" + content[insert_pos:]\n            else:\n                # Fallback: append at end\n                updated_content = content.rstrip() + f\"\\n\\n{new_marker}\\n\"\n\n        # Use async writer for safe background write\n        return async_wm_write(\n            filepath=wm_filepath,\n            content=updated_content,\n            operation_type='edit_tracking',\n            validate=False,\n            session_id=session_id\n        )\n    except Exception:\n        return False\n\n\ndef main():\n    try:\n        input_data = read_stdin_safe(timeout_seconds=2.0)\n        cwd = get_input_field(input_data, 'cwd', default=os.getcwd())\n        memory_name = get_input_field(input_data, 'tool_input', 'memory_file_name', default='')\n\n        # Handle FEATURE_TESTS read - update timestamp in WM\n        if memory_name == 'FEATURE_TESTS':\n            transcript_path = get_input_field(input_data, 'transcript_path', default='')\n            session_id = extract_session_id(transcript_path)\n            wm_filepath = find_working_memory_for_session(cwd, session_id)\n            if wm_filepath:\n                update_test_docs_timestamp(wm_filepath, session_id)\n                output_status(f\"üìñ Read: {memory_name} (timestamp updated)\")\n                return\n            output_status(f\"üìñ Read: {memory_name}\")\n            return\n\n        # Handle FEATURE_SWARM read - emit swarm directive\n        if memory_name == 'FEATURE_SWARM':\n            output = HookOutput(event_name=\"PostToolUse\")\n            output.add_message(f\"üìñ Read: {memory_name}\")\n            output.add_message(\"\")\n            output.add_message(\"üêù SWARM DETECTED - You MUST use ruv-swarm or hive-mind swarm orchestration. Go to WF_SWARM_ORCHESTRATE after completing WF_CLASSIFY feature loading.\")\n            output.output_and_exit()\n\n        # Only process WF_* memories for state transitions\n        if not memory_name or not memory_name.startswith('WF_'):\n            output_status(f\"üìñ Read: {memory_name or 'unknown'}\")\n            return  # Explicit return for clarity (output_empty exits)\n\n        # Extract session ID for session isolation\n        transcript_path = get_input_field(input_data, 'transcript_path', default='')\n        session_id = extract_session_id(transcript_path)\n\n        # Create state manager with session isolation\n        state_mgr = StateManager(cwd, session_id=session_id)\n\n        output = HookOutput(event_name=\"PostToolUse\")\n        icon = STATE_ICONS.get(memory_name, 'üìç')\n        current = state_mgr.get_current_state()\n\n        # Only transition if state is different\n        if current != memory_name:\n            # Create WM file when transitioning TO WF_START (end of WF_INIT)\n            if memory_name == 'WF_START' and not state_mgr.wm_filepath:\n                project_root = get_project_root()\n                wm_filename = f\"WM_{session_id}_session.md\"\n                wm_filepath = os.path.join(project_root, \".serena\", \"memories\", wm_filename)\n\n                wm_content = f\"\"\"# Working Memory: Session {session_id}\n\n## Session\n- **ID**: {session_id}\n- **Task**: (awaiting classification)\n- **Started**: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n## Workflow Context\n**Current State**: WF_START\n**Previous State**: WF_INIT\n\n## Task Context\n- **Feature(s)**: (to be determined)\n- **Complexity**: (to be determined)\n\n## Progress Tracking\n### Pending\n- [ ] Classify task\n\n## Requirements\n(to be determined from user request)\n\n## Implementation Notes\n(none yet)\n\"\"\"\n                os.makedirs(os.path.dirname(wm_filepath), exist_ok=True)\n                with open(wm_filepath, 'w', encoding='utf-8') as f:\n                    f.write(wm_content)\n\n                # Update state manager with new WM\n                state_mgr.set_working_memory(wm_filename.replace('.md', ''))\n                output.add_message(f\"‚úÖ Working Memory created: {wm_filename}\")\n\n            success, msg = state_mgr.transition_to(memory_name)\n            if success:\n                output.add_message(f\"{icon} ON STEP: {memory_name}\")\n                output.add_message(msg)\n                # Auto-log transition to WM Progress section\n                if state_mgr.wm_filepath:\n                    append_transition_to_wm(state_mgr.wm_filepath, current, memory_name)\n            else:\n                # BLOCK invalid transition with clear instructions\n                output.add_message(f\"üõë {msg}\")\n                output.add_message(\"\")\n                output.add_message(\"**YOU MUST STOP AND GO TO A VALID STATE.**\")\n                output.add_message(\"\")\n                output.add_message(\"The state machine enforces valid workflow paths.\")\n                output.add_message(\"You cannot skip steps in the workflow.\")\n                output.add_message(\"\")\n                output.add_message(\"**Common fixes:**\")\n                output.add_message(\"- From WF_START: Go to WF_CLASSIFY (for code changes)\")\n                output.add_message(\"- From WF_CLASSIFY: Go to WF_DETECT_REQ (simple) or WF_PLAN_ARCHITECTURE (complex)\")\n                output.add_message(\"- Features must be loaded in WF_CLASSIFY or WF_LOAD_FEATURE before WF_EXECUTE\")\n        else:\n            output.add_message(f\"{icon} ON STEP: {memory_name}\")\n\n        output.output_and_exit()\n\n    except Exception as e:\n        output = {\"hookSpecificOutput\": {\"hookEventName\": \"PostToolUse\", \"additionalContext\": f\"Post-read error: {e}\"}}\n        print(json.dumps(output), file=sys.stdout)\n        sys.exit(0)\n\n\nif __name__ == '__main__':\n    main()\n",
        "hooks/post/swe_post_ruv_swarm_init.py": "#!/usr/bin/env python3\n\"\"\"PostToolUse hook for mcp__ruv-swarm__swarm_init - Enforce REF_SWARM_PATTERNS read.\n\nAfter initializing a ruv-swarm, Claude MUST read REF_SWARM_PATTERNS to follow\nproper swarm coordination patterns (DAA init, agent spawning, orchestration).\n\"\"\"\n\nimport os\nimport sys\nimport json\n\nPLUGIN_ROOT = os.environ.get('CLAUDE_PLUGIN_ROOT', '')\nif PLUGIN_ROOT:\n    hooks_dir = os.path.join(PLUGIN_ROOT, 'hooks')\n    if hooks_dir not in sys.path:\n        sys.path.insert(0, hooks_dir)\n\ntry:\n    from swe_hooks.core.output import HookOutput, output_empty\n    from swe_hooks.core.input import read_stdin_safe, get_input_field\nexcept ImportError as e:\n    output = {\"hookSpecificOutput\": {\"hookEventName\": \"PostToolUse\", \"additionalContext\": f\"SWE import error: {e}\"}}\n    print(json.dumps(output), file=sys.stdout)\n    sys.exit(0)\n\n\ndef main():\n    try:\n        input_data = read_stdin_safe(timeout_seconds=2.0)\n\n        # Check if swarm_init succeeded\n        tool_result = input_data.get('tool_result', {})\n        if isinstance(tool_result, dict) and tool_result.get('error'):\n            # Swarm init failed, don't add instruction\n            output_empty()\n            return\n\n        # Output instruction to read swarm patterns\n        context = \"\"\"<swarm-init-complete>\n<blocking-instruction priority=\"HIGH\">\nRUV-SWARM INITIALIZED - FOLLOW PROPER PATTERN\n\nYour NEXT ACTION must be to read the swarm coordination reference:\n‚Üí mcp__plugin_swe_serena__read_memory(memory_file_name=\"REF_SWARM_PATTERNS\")\n\nThis contains MANDATORY steps for proper swarm coordination:\n1. daa_init (enable learning/coordination)\n2. daa_agent_create (spawn agents with cognitive patterns)\n3. task_orchestrate (coordinate work)\n\nDO NOT skip this step. DO NOT guess the pattern.\nRead REF_SWARM_PATTERNS NOW.\n</blocking-instruction>\n</swarm-init-complete>\"\"\"\n\n        output = HookOutput(event_name=\"PostToolUse\")\n        output.add_context(context)\n        output.print()\n\n    except Exception as e:\n        output = {\"hookSpecificOutput\": {\"hookEventName\": \"PostToolUse\", \"additionalContext\": f\"Ruv-swarm init hook error: {e}\"}}\n        print(json.dumps(output), file=sys.stdout)\n        sys.exit(0)\n\n\nif __name__ == '__main__':\n    main()\n",
        "hooks/post/swe_post_serena_replace_fallback.py": "#!/usr/bin/env python3\n\"\"\"PostToolUse hook for Serena replace_content - Edit tool fallback on failure.\n\nDetects when mcp__serena__replace_content fails and suggests using the standard\nEdit tool for that specific instance. This handles cases where whitespace or\nformatting differences cause Serena's literal/regex matching to fail.\n\nIMPORTANT: This hook provides a ONE-TIME suggestion for the SPECIFIC FAILED edit.\nIt does not change default tool behavior - it only activates on failure.\n\"\"\"\n\nimport os\nimport sys\nimport json\nimport re\n\nPLUGIN_ROOT = os.environ.get('CLAUDE_PLUGIN_ROOT', '')\nif PLUGIN_ROOT:\n    hooks_dir = os.path.join(PLUGIN_ROOT, 'hooks')\n    if hooks_dir not in sys.path:\n        sys.path.insert(0, hooks_dir)\n\ntry:\n    from swe_hooks.core.output import HookOutput, output_empty\n    from swe_hooks.core.input import read_stdin_safe, get_input_field\nexcept ImportError as e:\n    output = {\"hookSpecificOutput\": {\"hookEventName\": \"PostToolUse\", \"additionalContext\": f\"SWE import error: {e}\"}}\n    print(json.dumps(output), file=sys.stdout)\n    sys.exit(0)\n\n# Error patterns that indicate replace_content failed\nFAILURE_PATTERNS = [\n    r\"No matches of search expression found\",\n    r\"Error executing tool.*ValueError\",\n    r\"Multiple occurrences found.*allow_multiple_occurrences\",\n    r\"Error: Pattern not found\",\n]\n\n\ndef detect_failure(tool_result: str) -> bool:\n    \"\"\"Check if tool_result indicates a replace_content failure.\"\"\"\n    if not tool_result:\n        return False\n    \n    for pattern in FAILURE_PATTERNS:\n        if re.search(pattern, tool_result, re.IGNORECASE):\n            return True\n    return False\n\n\ndef extract_file_path(tool_input: dict) -> str:\n    \"\"\"Extract the file path from tool input.\"\"\"\n    return tool_input.get('relative_path', '') or tool_input.get('file_path', '')\n\n\ndef generate_fallback_suggestion(tool_input: dict, file_path: str) -> str:\n    \"\"\"Generate a suggestion to use the Edit tool instead.\"\"\"\n    needle = tool_input.get('needle', '')\n    repl = tool_input.get('repl', '')\n    mode = tool_input.get('mode', 'literal')\n    \n    # Truncate long strings for display\n    needle_preview = needle[:100] + '...' if len(needle) > 100 else needle\n    repl_preview = repl[:100] + '...' if len(repl) > 100 else repl\n    \n    suggestion = f\"\"\"üîÑ **SERENA REPLACE FAILED** - Falling back to Edit tool\n\n**File:** `{file_path}`\n**Mode:** {mode}\n**Needle preview:** `{needle_preview}`\n\n**RECOMMENDED ACTION:**\nUse the standard `Edit` tool instead for this specific edit:\n\n```\nEdit(\n  file_path=\"{file_path}\",\n  old_string=\"<exact content from file>\",\n  new_string=\"<your replacement>\"\n)\n```\n\n**WHY THIS FAILED:**\n- Serena's replace_content uses exact string matching\n- Whitespace, indentation, or invisible characters may differ\n- The Read tool output may not match the actual file bytes exactly\n\n**TIPS FOR SUCCESS:**\n1. Use `Read` tool to get the EXACT content from the file\n2. Copy the old_string directly from Read output (including whitespace)\n3. If still failing, try reading smaller line ranges to isolate the content\n\"\"\"\n    return suggestion\n\n\ndef main():\n    try:\n        input_data = read_stdin_safe(timeout_seconds=2.0)\n        \n        # Get tool information\n        tool_name = get_input_field(input_data, 'tool_name', default='')\n        tool_input = input_data.get('tool_input', {})\n        tool_result = get_input_field(input_data, 'tool_result', default='')\n        \n        # Convert tool_result to string if it's a dict\n        if isinstance(tool_result, dict):\n            tool_result = tool_result.get('result', '') or json.dumps(tool_result)\n        \n        # Only process Serena replace operations\n        serena_replace_tools = [\n            'mcp__serena__replace_content',\n            'mcp__plugin_swe_serena__replace_content',\n        ]\n        \n        if tool_name not in serena_replace_tools:\n            output_empty()\n            return\n        \n        # Check if the operation failed\n        if not detect_failure(str(tool_result)):\n            output_empty()\n            return\n        \n        # Generate fallback suggestion\n        file_path = extract_file_path(tool_input)\n        suggestion = generate_fallback_suggestion(tool_input, file_path)\n        \n        output = HookOutput(event_name=\"PostToolUse\")\n        output.add_message(suggestion)\n        output.output_and_exit()\n\n    except Exception as e:\n        output = {\"hookSpecificOutput\": {\"hookEventName\": \"PostToolUse\", \"additionalContext\": f\"Serena fallback hook error: {e}\"}}\n        print(json.dumps(output), file=sys.stdout)\n        sys.exit(0)\n\n\nif __name__ == '__main__':\n    main()\n",
        "hooks/post/swe_post_task_learn.py": "#!/usr/bin/env python3\n\"\"\"PostToolUse - RLVR trajectory tracking.\n\nTracks workflow step progression for reinforcement learning.\nUses session isolation for trajectory tracking.\n\"\"\"\n\nimport os\nimport sys\nimport json\n\nPLUGIN_ROOT = os.environ.get('CLAUDE_PLUGIN_ROOT', '')\nif PLUGIN_ROOT:\n    hooks_dir = os.path.join(PLUGIN_ROOT, 'hooks')\n    if hooks_dir not in sys.path:\n        sys.path.insert(0, hooks_dir)\n\ntry:\n    from swe_hooks.core.output import output_empty\n    from swe_hooks.core.input import read_stdin_safe, get_input_field\n    from swe_hooks.core.state_manager import StateManager\n    from swe_hooks.core.session import extract_session_id\nexcept ImportError as e:\n    output = {\"hookSpecificOutput\": {\"hookEventName\": \"PostToolUse\", \"additionalContext\": f\"SWE import error: {e}\"}}\n    print(json.dumps(output), file=sys.stdout)\n    sys.exit(0)\n\n\ndef main():\n    try:\n        input_data = read_stdin_safe(timeout_seconds=2.0)\n        cwd = get_input_field(input_data, 'cwd', default=os.getcwd())\n        memory_name = get_input_field(input_data, 'tool_input', 'memory_file_name', default='')\n\n        # Only track trajectory for WF_* memory reads\n        if memory_name and memory_name.startswith('WF_'):\n            # Extract session ID for session isolation\n            transcript_path = get_input_field(input_data, 'transcript_path', default='')\n            session_id = extract_session_id(transcript_path)\n\n            # Create state manager with session isolation\n            state_mgr = StateManager(cwd, session_id=session_id)\n            state_mgr.increment_trajectory_step()\n\n        output_empty()\n\n    except Exception as e:\n        output = {\"hookSpecificOutput\": {\"hookEventName\": \"PostToolUse\", \"additionalContext\": f\"Learn error: {e}\"}}\n        print(json.dumps(output), file=sys.stdout)\n        sys.exit(0)\n\n\nif __name__ == '__main__':\n    main()\n",
        "hooks/pre/swe_pre_bash_test_gate.py": "#!/usr/bin/env python3\n\"\"\"PreToolUse hook for Bash - Ensure FEATURE_TESTS is read before running tests.\n\nDetects test commands and reminds/blocks if FEATURE_TESTS hasn't been loaded.\nUses session-scoped tracking of read memories with optional timestamp validation.\nOutputs debug info on every test command to show WHY it passed or blocked.\n\"\"\"\n\nimport os\nimport sys\nimport json\nimport re\nimport time\n\nPLUGIN_ROOT = os.environ.get('CLAUDE_PLUGIN_ROOT', '')\nif PLUGIN_ROOT:\n    hooks_dir = os.path.join(PLUGIN_ROOT, 'hooks')\n    if hooks_dir not in sys.path:\n        sys.path.insert(0, hooks_dir)\n\ntry:\n    from swe_hooks.core.output import HookOutput, output_empty, output_block, output_message\n    from swe_hooks.core.input import read_stdin_safe, get_input_field\n    from swe_hooks.core.state_manager import StateManager\n    from swe_hooks.core.session import extract_session_id, find_working_memory_for_session\nexcept ImportError as e:\n    output = {\"hookSpecificOutput\": {\"hookEventName\": \"PreToolUse\", \"additionalContext\": f\"SWE import error: {e}\"}}\n    print(json.dumps(output), file=sys.stdout)\n    sys.exit(0)\n\n# Test command patterns\nTEST_COMMAND_PATTERNS = [\n    r'\\bplaywright\\b',\n    r'\\bnpx\\s+playwright\\b',\n    r'\\bnpm\\s+(run\\s+)?test',\n    r'\\byarn\\s+test',\n    r'\\bpnpm\\s+test',\n    r'\\bpytest\\b',\n    r'\\bphpunit\\b',\n    r'\\bjest\\b',\n    r'\\bmocha\\b',\n    r'\\bvitest\\b',\n    r'\\bava\\b',\n    r'\\btap\\b',\n    r'\\.spec\\.(ts|js|tsx|jsx)',\n    r'\\.test\\.(ts|js|tsx|jsx)',\n    r'\\btest:',  # npm scripts like \"test:e2e\"\n]\n\n# States where tests are expected (no reminder needed)\nTEST_STATES = {'WF_VERIFY', 'WF_DEBUG_TDD'}\n\n# Timestamp expiry in seconds (5 minutes) - set to 0 to disable timestamp checking\nTIMESTAMP_EXPIRY_SECONDS = 300\n\n\ndef check_feature_tests_read(wm_filepath: str) -> dict:\n    \"\"\"Check if FEATURE_TESTS is listed in the working memory.\n\n    Returns dict with:\n        - passed: bool - whether the check passed\n        - reason: str - why it passed or failed\n        - timestamp: int or None - timestamp if found\n        - timestamp_valid: bool or None - if timestamp is within expiry window\n    \"\"\"\n    result = {\n        'passed': False,\n        'reason': 'Unknown',\n        'timestamp': None,\n        'timestamp_valid': None,\n        'wm_exists': False,\n        'has_feature_tests': False,\n        'has_tests_in_features': False,\n    }\n\n    if not wm_filepath:\n        result['reason'] = 'No working memory filepath provided'\n        return result\n\n    if not os.path.exists(wm_filepath):\n        result['reason'] = f'Working memory file not found: {wm_filepath}'\n        return result\n\n    result['wm_exists'] = True\n\n    try:\n        with open(wm_filepath, 'r') as f:\n            content = f.read()\n\n        # Check for timestamp marker: \"Test Docs: Read @<timestamp>\"\n        timestamp_match = re.search(r'Test Docs: Read @(\\d+)', content)\n        if timestamp_match:\n            result['timestamp'] = int(timestamp_match.group(1))\n            current_time = int(time.time())\n            age_seconds = current_time - result['timestamp']\n\n            if TIMESTAMP_EXPIRY_SECONDS > 0:\n                result['timestamp_valid'] = age_seconds <= TIMESTAMP_EXPIRY_SECONDS\n                if result['timestamp_valid']:\n                    result['passed'] = True\n                    result['reason'] = f'Timestamp valid (age: {age_seconds}s, max: {TIMESTAMP_EXPIRY_SECONDS}s)'\n                    return result\n                else:\n                    # HARD FAIL - timestamp exists but expired, must re-read FEATURE_TESTS\n                    result['passed'] = False\n                    result['reason'] = f'Timestamp EXPIRED - must re-read FEATURE_TESTS (age: {age_seconds}s, max: {TIMESTAMP_EXPIRY_SECONDS}s)'\n                    return result\n\n        # Only check fallbacks if NO timestamp exists at all\n        # Check if FEATURE_TESTS is in content\n        if 'FEATURE_TESTS' in content:\n            result['has_feature_tests'] = True\n            result['passed'] = True\n            result['reason'] = 'FEATURE_TESTS found in working memory content'\n            return result\n\n        # Check if TESTS is mentioned in feature keys section\n        feature_match = re.search(r'\\*\\*Feature Key\\(s\\)\\*\\*:\\s*(.+)', content)\n        if feature_match:\n            features = feature_match.group(1)\n            if 'TESTS' in features.upper():\n                result['has_tests_in_features'] = True\n                result['passed'] = True\n                result['reason'] = f'TESTS found in Feature Keys: {features}'\n                return result\n\n        result['reason'] = 'No FEATURE_TESTS or TESTS marker found in working memory'\n        return result\n\n    except IOError as e:\n        result['reason'] = f'IOError reading working memory: {e}'\n        return result\n\n\ndef is_test_command(command: str) -> bool:\n    \"\"\"Check if the command is a test command.\"\"\"\n    for pattern in TEST_COMMAND_PATTERNS:\n        if re.search(pattern, command, re.IGNORECASE):\n            return True\n    return False\n\n\ndef format_debug_info(session_id: str, current_state: str, wm_filepath: str, check_result: dict, bypass_reason: str = None) -> str:\n    \"\"\"Format debug information for hook output.\"\"\"\n    lines = [\n        \"üîç TEST GATE DEBUG INFO:\",\n        f\"  Session: {session_id}\",\n        f\"  State: {current_state}\",\n        f\"  WM Path: {wm_filepath or 'None'}\",\n        f\"  WM Exists: {check_result.get('wm_exists', False)}\",\n    ]\n\n    if check_result.get('timestamp'):\n        lines.append(f\"  Timestamp: {check_result['timestamp']} (valid: {check_result.get('timestamp_valid')})\")\n\n    lines.extend([\n        f\"  Has FEATURE_TESTS: {check_result.get('has_feature_tests', False)}\",\n        f\"  Has TESTS in Features: {check_result.get('has_tests_in_features', False)}\",\n        f\"  Check Passed: {check_result.get('passed', False)}\",\n        f\"  Reason: {check_result.get('reason', 'Unknown')}\",\n    ])\n\n    if bypass_reason:\n        lines.append(f\"  Bypass: {bypass_reason}\")\n\n    return \"\\n\".join(lines)\n\n\ndef main():\n    try:\n        input_data = read_stdin_safe(timeout_seconds=2.0)\n        command = get_input_field(input_data, 'tool_input', 'command', default='')\n        cwd = get_input_field(input_data, 'cwd', default=os.getcwd())\n\n        if not command:\n            output_empty()\n            return\n\n        # Only check test commands\n        if not is_test_command(command):\n            output_empty()\n            return\n\n        # Extract session ID\n        transcript_path = get_input_field(input_data, 'transcript_path', default='')\n        session_id = extract_session_id(transcript_path)\n\n        # Get state manager with session isolation\n        state_mgr = StateManager(cwd, session_id=session_id)\n        current_state = state_mgr.get_current_state()\n\n        # Find working memory\n        wm_filepath = find_working_memory_for_session(cwd, session_id)\n\n        # Check if FEATURE_TESTS was read\n        check_result = check_feature_tests_read(wm_filepath)\n\n        # If already in test state, allow through with debug info\n        if current_state in TEST_STATES:\n            debug_info = format_debug_info(session_id, current_state, wm_filepath, check_result,\n                                          bypass_reason=f\"In test state: {current_state}\")\n            output_message(debug_info)\n            return\n\n        # If check passed, allow through with debug info\n        if check_result['passed']:\n            debug_info = format_debug_info(session_id, current_state, wm_filepath, check_result)\n            output_message(debug_info)\n            return\n\n        # FEATURE_TESTS not read - block with reminder and debug info\n        debug_info = format_debug_info(session_id, current_state, wm_filepath, check_result)\n\n        output_block(\n            f\"\"\"üß™ TEST COMMAND DETECTED - FEATURE_TESTS REQUIRED\n\n{debug_info}\n\nCommand: {command}\n\nBefore running tests, you MUST read FEATURE_TESTS to understand:\n- Test structure and organization\n- Required fixtures and setup\n- Environment configuration\n- Running test commands properly\n\nREQUIRED ACTION:\n```\nmcp__plugin_swe_serena__read_memory(memory_file_name=\"FEATURE_TESTS\")\n```\n\nAfter reading FEATURE_TESTS, update your WM with:\n- **Feature Key(s)**: TESTS (or add TESTS to existing list)\n\nThen retry the test command.\"\"\"\n        )\n\n    except Exception as e:\n        output = {\"hookSpecificOutput\": {\"hookEventName\": \"PreToolUse\", \"additionalContext\": f\"Test gate error: {e}\"}}\n        print(json.dumps(output), file=sys.stdout)\n        sys.exit(0)\n\n\nif __name__ == '__main__':\n    main()\n",
        "hooks/pre/swe_pre_edit_validate.py": "#!/usr/bin/env python3\n\"\"\"PreToolUse hook for Edit/Write - Validate state and check staleness.\n\nEnsures edits only happen in appropriate workflow states.\nBLOCKS edits if WM is stale (>3 edits without update).\nUses session isolation for state checking.\n\nENFORCEMENT: This hook adds staleness blocking per SPEC_WM_ENFORCEMENT.\n\"\"\"\n\nimport os\nimport sys\nimport json\n\nPLUGIN_ROOT = os.environ.get('CLAUDE_PLUGIN_ROOT', '')\nif PLUGIN_ROOT:\n    hooks_dir = os.path.join(PLUGIN_ROOT, 'hooks')\n    if hooks_dir not in sys.path:\n        sys.path.insert(0, hooks_dir)\n\ntry:\n    from swe_hooks.core.output import HookOutput, output_empty, output_block, output_status\n    from swe_hooks.core.input import read_stdin_safe, get_input_field\n    from swe_hooks.core.state_manager import StateManager\n    from swe_hooks.core.session import extract_session_id, find_working_memory_for_session\n    from swe_hooks.core.config import check_wm_staleness\nexcept ImportError as e:\n    output = {\"hookSpecificOutput\": {\"hookEventName\": \"PreToolUse\", \"additionalContext\": f\"SWE import error: {e}\"}}\n    print(json.dumps(output), file=sys.stdout)\n    sys.exit(0)\n\n# States where edits are allowed\nEDIT_ALLOWED = {'WF_EXECUTE', 'WF_DEBUG_TDD', 'WF_CHECKPOINT', 'WF_UPDATE_MEMORY', 'WF_CLEANUP', 'WF_INITIAL_SETUP', 'UNINITIALIZED', 'WF_INIT'}\n\n# States where edits should show a warning\nWARN_STATES = {'WF_PLAN_ARCHITECTURE', 'WF_ARCH_REVIEW', 'WF_RESEARCH'}\n\n# Edit threshold for staleness check\nSTALENESS_THRESHOLD = 3\n\n\ndef main():\n    try:\n        input_data = read_stdin_safe(timeout_seconds=2.0)\n        cwd = get_input_field(input_data, 'cwd', default=os.getcwd())\n\n        # Extract session ID for session isolation\n        transcript_path = get_input_field(input_data, 'transcript_path', default='')\n        session_id = extract_session_id(transcript_path)\n\n        # Find working memory for this session\n        wm_filepath = find_working_memory_for_session(cwd, session_id)\n\n        # Check staleness FIRST (before state check)\n        if wm_filepath:\n            is_stale, edit_count, last_updated = check_wm_staleness(\n                cwd, wm_filepath, STALENESS_THRESHOLD\n            )\n            \n            if is_stale:\n                # BLOCK: WM is stale\n                output = HookOutput(event_name=\"PreToolUse\")\n                output.block(f\"\"\"üõë WM STALE\n\nYour WM is outdated ({edit_count} edits since last update).\n\n**UPDATE WM before continuing edits:**\n1. Update `## Progress` section with completed work\n2. Mark completed items with `[x]`\n3. Update `**Files:**` with files you've edited\n\nAfter updating WM, you may continue editing.\"\"\")\n                output.output_and_exit()\n                return\n\n        # Create state manager with session isolation\n        state_mgr = StateManager(cwd, session_id=session_id)\n        current = state_mgr.get_current_state()\n\n        # Allow edits in execution states\n        if current in EDIT_ALLOWED:\n            output_status(f\"‚úì Edit allowed ({current})\", event=\"PreToolUse\")\n            return\n\n        # Warn but allow in planning states\n        if current in WARN_STATES:\n            output = HookOutput(event_name=\"PreToolUse\")\n            output.add_message(f\"‚ö†Ô∏è Edit in planning state: {current}\")\n            output.output_and_exit()\n            return\n\n        # Default: allow the edit (don't block workflow)\n        output_status(f\"‚úì Edit allowed ({current})\", event=\"PreToolUse\")\n\n    except Exception as e:\n        output = {\"hookSpecificOutput\": {\"hookEventName\": \"PreToolUse\", \"additionalContext\": f\"Pre-edit error: {e}\"}}\n        print(json.dumps(output), file=sys.stdout)\n        sys.exit(0)\n\n\nif __name__ == '__main__':\n    main()\n",
        "hooks/pre/swe_pre_task_orchestrate_gate.py": "#!/usr/bin/env python3\n\"\"\"PreToolUse hook for task_orchestrate - Enforce WF_SWARM_ORCHESTRATE read.\n\nEnsures the AI has read the swarm orchestration workflow instructions before\nlaunching multi-agent task orchestration.\n\nENFORCEMENT: Blocks task_orchestrate until WF_SWARM_ORCHESTRATE is visited.\n\"\"\"\n\nimport os\nimport sys\nimport json\n\nPLUGIN_ROOT = os.environ.get('CLAUDE_PLUGIN_ROOT', '')\nif PLUGIN_ROOT:\n    hooks_dir = os.path.join(PLUGIN_ROOT, 'hooks')\n    if hooks_dir not in sys.path:\n        sys.path.insert(0, hooks_dir)\n\ntry:\n    from swe_hooks.core.output import HookOutput, output_status\n    from swe_hooks.core.input import read_stdin_safe, get_input_field\n    from swe_hooks.core.state_manager import StateManager\n    from swe_hooks.core.session import extract_session_id, find_working_memory_for_session\nexcept ImportError as e:\n    output = {\"hookSpecificOutput\": {\"hookEventName\": \"PreToolUse\", \"additionalContext\": f\"SWE import error: {e}\"}}\n    print(json.dumps(output), file=sys.stdout)\n    sys.exit(0)\n\n# States that indicate swarm orchestration workflow has been visited\nSWARM_ALLOWED_STATES = {'WF_SWARM_ORCHESTRATE', 'WF_EXECUTE'}\n\n\ndef check_swarm_orchestrate_visited(wm_filepath):\n    \"\"\"Check if WF_SWARM_ORCHESTRATE has been visited in the workflow.\n\n    Returns: tuple (bool, str) - (is_valid, diagnostic_message)\n    \"\"\"\n    if not wm_filepath or not os.path.exists(wm_filepath):\n        return False, \"No working memory found\"\n\n    try:\n        with open(wm_filepath, 'r') as f:\n            content = f.read()\n\n        # Check for evidence of swarm orchestration workflow visit\n        swarm_indicators = [\n            'WF_SWARM_ORCHESTRATE',\n            '## Swarm Orchestration',\n            'swarm_orchestrate',\n        ]\n\n        for indicator in swarm_indicators:\n            if indicator in content:\n                return True, \"Swarm orchestration context found\"\n\n        return False, \"WF_SWARM_ORCHESTRATE not visited\"\n\n    except Exception as e:\n        return False, f\"Error reading WM: {e}\"\n\n\ndef main():\n    try:\n        input_data = read_stdin_safe(timeout_seconds=2.0)\n        cwd = get_input_field(input_data, 'cwd', default=os.getcwd())\n\n        # Extract session ID for session isolation\n        transcript_path = get_input_field(input_data, 'transcript_path', default='')\n        session_id = extract_session_id(transcript_path)\n\n        # Find working memory for this session\n        wm_filepath = find_working_memory_for_session(cwd, session_id)\n\n        # Create state manager with session isolation\n        state_mgr = StateManager(cwd, session_id=session_id)\n        current = state_mgr.get_current_state()\n\n        # Allow if already in swarm orchestration or execute states\n        if current in SWARM_ALLOWED_STATES:\n            output_status(f\"‚úì task_orchestrate allowed ({current})\", event=\"PreToolUse\")\n            return\n\n        # Check if swarm orchestrate was visited\n        is_valid, diagnostic = check_swarm_orchestrate_visited(wm_filepath)\n\n        if is_valid:\n            output_status(\"‚úì task_orchestrate allowed (swarm context found)\", event=\"PreToolUse\")\n            return\n\n        # BLOCK: WF_SWARM_ORCHESTRATE not visited\n        output = HookOutput(event_name=\"PreToolUse\")\n        output.block(f\"\"\"üõë BLOCKED: WF_SWARM_ORCHESTRATE not read\n\nBefore using task_orchestrate, you MUST read the swarm orchestration workflow.\n\n**MANDATORY ACTION - Call this tool NOW:**\n   ‚Üí mcp__plugin_swe_serena__read_memory(memory_file_name=\"WF_SWARM_ORCHESTRATE\")\n\nThis ensures you understand:\n- Proper swarm topology selection\n- Agent coordination patterns\n- Memory synchronization requirements\n- Error handling for distributed tasks\n\nDiagnostic: {diagnostic}\nCurrent state: {current}\"\"\")\n        output.output_and_exit()\n\n    except Exception as e:\n        output = {\"hookSpecificOutput\": {\"hookEventName\": \"PreToolUse\", \"additionalContext\": f\"Task orchestrate gate error: {e}\"}}\n        print(json.dumps(output), file=sys.stdout)\n        sys.exit(0)\n\n\nif __name__ == '__main__':\n    main()\n",
        "hooks/pre/swe_pre_tool_init_gate.py": "#!/usr/bin/env python3\n\"\"\"PreToolUse gate - BLOCKS all tools until workflow is initialized.\n\nRequires WORKING_MEMORY file with proper workflow state.\n\nInitialization is complete when:\n- A WM_{session}_* file exists with proper workflow state\n\nLITE MODE: Only available when user explicitly requests it (e.g., \"/lite\", \"use lite mode\").\nNever offered as an automatic option.\n\nSession isolation: Each conversation must have its own working memory (matched by session ID).\n\"\"\"\n\nimport os\nimport sys\nimport json\nimport glob\nimport re\n\nPLUGIN_ROOT = os.environ.get('CLAUDE_PLUGIN_ROOT', '')\nif PLUGIN_ROOT:\n    hooks_dir = os.path.join(PLUGIN_ROOT, 'hooks')\n    if hooks_dir not in sys.path:\n        sys.path.insert(0, hooks_dir)\n\n# Tools that are ALWAYS ALLOWED before initialization (no path checking needed)\nALLOWED_TOOLS = [\n    # ToolSearch - CRITICAL: needed to load deferred MCP tools (prevents deadlock)\n    'ToolSearch',\n    # WebSearch - allow web searches without requiring workflow initialization\n    'WebSearch',\n    # Read - needed to read workflow files and understand context before WM creation\n    'Read',\n    # Memory tools (needed for reading WF_INIT and creating WORKING_MEMORY)\n    'mcp__plugin_swe_serena__read_memory',\n    'mcp__serena__read_memory',\n    'mcp__plugin_swe_serena__write_memory',\n    'mcp__serena__write_memory',\n    'mcp__plugin_swe_serena__list_memories',\n    'mcp__serena__list_memories',\n    'mcp__plugin_swe_serena__edit_memory',\n    'mcp__serena__edit_memory',\n    'mcp__plugin_swe_serena__delete_memory',\n    'mcp__serena__delete_memory',\n    # Project activation tools (needed when no active project - chicken/egg problem)\n    'mcp__plugin_swe_serena__activate_project',\n    'mcp__serena__activate_project',\n    'mcp__plugin_swe_serena__list_projects',\n    'mcp__serena__list_projects',\n    'mcp__plugin_swe_serena__add_project',\n    'mcp__serena__add_project',\n]\n\ndef is_working_memory_write(tool_name, tool_input):\n    \"\"\"Check if this is a Write to WORKING_MEMORY file (allowed for initialization).\"\"\"\n    if tool_name != 'Write':\n        return False\n    file_path = tool_input.get('file_path', '')\n    # Allow writes to WORKING_MEMORY files in .serena/memories/\n    return '.serena/memories/WM_' in file_path and file_path.endswith('.md')\n\ndef get_project_root():\n    \"\"\"Get project root from CLAUDE_PROJECT_DIR env var (set by Claude Code).\n\n    This is the official, documented way to get the project root.\n    Immune to cd commands changing the working directory.\n    \"\"\"\n    # Primary: CLAUDE_PROJECT_DIR - set by Claude Code, never changes\n    project_dir = os.environ.get('CLAUDE_PROJECT_DIR', '')\n    if project_dir:\n        return project_dir\n\n    # Fallback: walk up from cwd (less reliable after cd)\n    current = os.getcwd()\n    while current != os.path.dirname(current):\n        if os.path.isdir(os.path.join(current, '.serena')):\n            return current\n        current = os.path.dirname(current)\n    return os.getcwd()\n\n\ndef get_serena_memories_dir():\n    \"\"\"Get .serena/memories directory path.\"\"\"\n    return os.path.join(get_project_root(), '.serena', 'memories')\n\ndef extract_session_id(transcript_path):\n    \"\"\"Extract session ID from transcript_path UUID.\"\"\"\n    if not transcript_path:\n        return None\n    uuid_match = re.search(r'([a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12})', transcript_path)\n    if uuid_match:\n        return uuid_match.group(1)[:8]\n    return None\n\ndef check_lite_mode(cwd, session_id):\n    \"\"\"Check if lite mode is active for this session.\n\n    Lite mode allows simple lookups without full WORKING_MEMORY overhead.\n    Activated by creating LITE_MODE_{session_id} file in memories dir.\n\n    Returns: bool - True if lite mode is active\n    \"\"\"\n    if not session_id:\n        return False\n\n    memories_dir = get_serena_memories_dir()\n    lite_marker = os.path.join(memories_dir, f'LITE_MODE_{session_id}.md')\n    return os.path.exists(lite_marker)\n\ndef check_working_memory_exists(cwd, session_id):\n    \"\"\"Check if a WORKING_MEMORY file exists for THIS SESSION with proper workflow state.\n\n    Returns: tuple (bool, str) - (is_valid, diagnostic_message)\n    \"\"\"\n    memories_dir = get_serena_memories_dir()\n    if not os.path.exists(memories_dir):\n        return False, \"No .serena/memories directory found\"\n\n    # Look for WM_<session_id>_* files specifically\n    if session_id:\n        pattern = os.path.join(memories_dir, f'WM_{session_id}_*.md')\n        working_memories = glob.glob(pattern)\n    else:\n        # Fallback: any working memory (legacy support)\n        pattern = os.path.join(memories_dir, 'WM_*.md')\n        working_memories = glob.glob(pattern)\n\n    if not working_memories:\n        return False, f\"No WM_{session_id}_*.md file found\"\n\n    # Check the most recent one for workflow state\n    latest = max(working_memories, key=os.path.getmtime)\n    filename = os.path.basename(latest)\n\n    try:\n        with open(latest, 'r') as f:\n            content = f.read()\n\n            # Required patterns for valid workflow state\n            required_patterns = [\n                ('## Workflow Context', 'Section header'),\n                ('**Current State**:', 'Current State field'),\n            ]\n\n            # Check for required patterns\n            missing = []\n            for pattern_str, desc in required_patterns:\n                if pattern_str not in content:\n                    missing.append(f\"'{pattern_str}' ({desc})\")\n\n            if missing:\n                # Check what WAS found (for diagnostic)\n                found_patterns = []\n                alt_patterns = [\n                    ('## Workflow State', 'Wrong section header'),\n                    ('**Current**:', 'Wrong field format'),\n                    ('Current State:', 'Missing bold markers'),\n                    ('Workflow State:', 'Legacy format'),\n                ]\n                for alt_pat, alt_desc in alt_patterns:\n                    if alt_pat in content:\n                        found_patterns.append(f\"'{alt_pat}' ({alt_desc})\")\n\n                diag = f\"File {filename} missing: {', '.join(missing)}\"\n                if found_patterns:\n                    diag += f\". Found instead: {', '.join(found_patterns)}\"\n                return False, diag\n\n            # Verify session ID matches (if we have one)\n            if session_id:\n                session_match = re.search(r'\\*\\*Session ID\\*\\*:\\s*(\\S+)', content)\n                if session_match and session_match.group(1) == session_id:\n                    return True, \"Valid\"\n                # Also check filename contains session ID\n                if session_id in filename:\n                    return True, \"Valid\"\n                return False, f\"Session ID mismatch: expected {session_id}, file has different ID\"\n            return True, \"Valid\"\n    except Exception as e:\n        return False, f\"Error reading {filename}: {e}\"\n\n    return False, \"Unknown validation failure\"\n\ndef main():\n    try:\n        input_data = json.load(sys.stdin)\n        tool_name = input_data.get('tool_name', '')\n        cwd = input_data.get('cwd', os.getcwd())\n        transcript_path = input_data.get('transcript_path', '')\n\n        # Extract session ID from transcript_path\n        session_id = extract_session_id(transcript_path)\n\n        tool_input = input_data.get('tool_input', {})\n\n        # Allow memory tools through (needed for initialization)\n        if any(allowed in tool_name for allowed in ALLOWED_TOOLS):\n            print(json.dumps({}))\n            sys.exit(0)\n\n        # Allow Write to WORKING_MEMORY files (needed to create initialization file)\n        if is_working_memory_write(tool_name, tool_input):\n            print(json.dumps({}))\n            sys.exit(0)\n\n        # Check if LITE MODE is active (lightweight research path)\n        if check_lite_mode(cwd, session_id):\n            # Lite mode - allow through without full working memory\n            print(json.dumps({\"systemMessage\": \"üîé LITE_MODE active - minimal workflow\"}))\n            sys.exit(0)\n\n        # Check if full initialization is complete (WORKING_MEMORY exists with state FOR THIS SESSION)\n        is_valid, diagnostic = check_working_memory_exists(cwd, session_id)\n        if is_valid:\n            # Initialized - allow through\n            print(json.dumps({}))\n            sys.exit(0)\n\n        # NOT initialized - BLOCK the tool call and redirect to WF_INIT\n        output = {\n            \"decision\": \"block\",\n            \"reason\": f\"\"\"üõë BLOCKED: No Working Memory for session {session_id or 'unknown'}\n\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n                         ‚ö†Ô∏è  WORKFLOW NOT INITIALIZED  ‚ö†Ô∏è\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\nYou must complete the WF_INIT workflow before using other tools.\n\n‚õî NO EXCEPTIONS MEANS NO EXCEPTIONS:\n- \"But the user wants a quick answer\" ‚Üí NO. Initialize first.\n- \"But this is meta-work on the workflow itself\" ‚Üí NO. Initialize first.\n- \"But I already know what to do\" ‚Üí NO. Initialize first.\n- \"But it's just a simple edit\" ‚Üí NO. Initialize first.\nDO NOT RATIONALIZE. DO NOT NEGOTIATE. INITIALIZE.\n\nMANDATORY ACTION - Call this tool NOW:\n   ‚Üí mcp__plugin_swe_serena__read_memory(memory_file_name=\"WF_INIT\")\n\nThen follow WF_INIT instructions to:\n1. Read WF_START (which creates the Working Memory)\n2. Proceed with task classification\n\nDiagnostic: {diagnostic}\n\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n              COMPLETE WF_INIT BEFORE PROCEEDING\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\"\"\"\n        }\n        print(json.dumps(output))\n        sys.exit(0)\n\n    except Exception as e:\n        # On error, don't block (fail open for safety)\n        print(json.dumps({\"systemMessage\": f\"Init gate error: {e}\"}))\n        sys.exit(0)\n\nif __name__ == '__main__':\n    main()\n",
        "hooks/prompt/swe_user_prompt_swarm.py": "#!/usr/bin/env python3\n\"\"\"UserPromptSubmit hook - Detect swarm keywords.\"\"\"\n\nimport os\nimport sys\nimport json\nimport re\n\nPLUGIN_ROOT = os.environ.get('CLAUDE_PLUGIN_ROOT', '')\nif PLUGIN_ROOT:\n    hooks_dir = os.path.join(PLUGIN_ROOT, 'hooks')\n    if hooks_dir not in sys.path:\n        sys.path.insert(0, hooks_dir)\n\ntry:\n    from swe_hooks.core.output import HookOutput, output_empty\n    from swe_hooks.core.input import read_stdin_safe, get_input_field\nexcept ImportError as e:\n    output = {\"hookSpecificOutput\": {\"hookEventName\": \"UserPromptSubmit\", \"additionalContext\": f\"SWE import error: {e}\"}}\n    print(json.dumps(output), file=sys.stdout)\n    sys.exit(0)\n\n# Explicit swarm terminology\nSWARM_KEYWORDS = [r'\\bswarm\\b', r'\\bmulti-agent\\b', r'\\bparallel\\s+agents?\\b', r'\\bhive\\b', r'\\borchestrat']\n\n# Task patterns that benefit from parallelization (folder/multi-file analysis)\nPARALLEL_TASK_PATTERNS = [\n    r'\\breview\\s+(this\\s+|the\\s+|a\\s+)?(folder|directory|module|codebase)\\b',\n    r'\\banalyze\\s+(all|these|multiple|the|this)\\s+(files?|folder|directory)\\b',\n    r'\\bcheck\\s+(all|every|each)\\s+(files?|modules?)\\b',\n    r'\\b(review|analyze|check|read)\\s+\\d+\\+?\\s+files?\\b',  # \"review 10 files\"\n    r'\\blarge\\s+files?\\b',\n    r'\\bentire\\s+(module|folder|directory|codebase)\\b',\n    r'\\bmulti(ple)?-?file\\b',\n    r'\\bacross\\s+(all|multiple)\\s+(files?|modules?)\\b',\n    r'\\ball\\s+(the\\s+)?(files?|templates?|classes?)\\s+in\\b',  # \"all the files in\"\n    r'\\b(scan|audit|inspect)\\s+(the\\s+)?(folder|directory|codebase)\\b',\n]\n\ndef main():\n    try:\n        input_data = read_stdin_safe(timeout_seconds=2.0)\n        prompt = get_input_field(input_data, 'prompt', default='')\n        if not prompt:\n            output_empty()\n            return\n\n        # Check explicit swarm keywords\n        for pattern in SWARM_KEYWORDS:\n            if re.search(pattern, prompt, re.IGNORECASE):\n                output = HookOutput(event_name=\"UserPromptSubmit\")\n                output.add_message(\"üêù SWARM HINT: This task involves swarm orchestration. Complete WF_INIT ‚Üí WF_START ‚Üí WF_CLASSIFY first. In WF_CLASSIFY, you MUST read FEATURE_SWARM which loads WF_SWARM_ORCHESTRATE, REF_SWARM_PATTERNS, CLAUDE_FLOW, and REF_AGENTS.\")\n                output.output_and_exit()\n\n        # Check parallel task patterns\n        for pattern in PARALLEL_TASK_PATTERNS:\n            if re.search(pattern, prompt, re.IGNORECASE):\n                output = HookOutput(event_name=\"UserPromptSubmit\")\n                output.add_message(\"üêù PARALLEL HINT: This task may benefit from swarm orchestration. Complete WF_INIT ‚Üí WF_START ‚Üí WF_CLASSIFY first. In WF_CLASSIFY, consider reading FEATURE_SWARM for multi-agent coordination.\")\n                output.output_and_exit()\n\n        output_empty()\n    except Exception as e:\n        output = {\"hookSpecificOutput\": {\"hookEventName\": \"UserPromptSubmit\", \"additionalContext\": f\"Prompt error: {e}\"}}\n        print(json.dumps(output), file=sys.stdout)\n        sys.exit(0)\n\nif __name__ == '__main__':\n    main()\n",
        "hooks/prompt/swe_user_prompt_workflow.py": "#!/usr/bin/env python3\n\"\"\"UserPromptSubmit hook - Ensure workflow state and provide instructions.\n\nThis hook fires on EVERY user prompt submission. It must:\n1. Detect if prompt is a continuation of current task or a new task\n2. Provide appropriate workflow instructions\n3. Ensure Claude follows the workflow state machine\n\nState is read from WM files (session-isolated), NOT a global state file.\n\"\"\"\n\nimport os\nimport sys\nimport json\nimport re\n\nPLUGIN_ROOT = os.environ.get('CLAUDE_PLUGIN_ROOT', '')\nif PLUGIN_ROOT:\n    hooks_dir = os.path.join(PLUGIN_ROOT, 'hooks')\n    if hooks_dir not in sys.path:\n        sys.path.insert(0, hooks_dir)\n\ntry:\n    from swe_hooks.core.config import (\n        load_setup_complete, \n        get_working_memory_filename, read_working_memory_state\n    )\n    from swe_hooks.core.state_manager import StateManager\nexcept ImportError as e:\n    print(json.dumps({\"systemMessage\": f\"SWE import error: {e}\"}), file=sys.stdout)\n    sys.exit(0)\n\n\n# Patterns that indicate a continuation of the current task\nCONTINUATION_PATTERNS = [\n    r'^(yes|yeah|yep|yup|ok|okay|sure|continue|proceed|go ahead|keep going|next|do it)[\\s\\.\\!\\?]*$',\n    r'^(sounds good|looks good|perfect|great|good|fine|alright)[\\s\\.\\!\\?]*$',\n    r'^(please continue|please proceed|go on|carry on)[\\s\\.\\!\\?]*$',\n    r'^(that\\'?s? (good|great|fine|correct|right))[\\s\\.\\!\\?]*$',\n    r'^(approved?|confirmed?|accept(ed)?)[\\s\\.\\!\\?]*$',\n    r'continue (with )?the',\n    r'keep (working|going)',\n    r'finish (the|this|it)',\n    r'modify (the|this|it)',\n    r'add (a|the|this|it)',\n    r'complete (the|this|it)',\n]\n\n# Patterns that indicate an addition to the current task (not a new task)\nADDITION_PATTERNS = [\n    r'^(also|additionally|and also|plus|another thing)',\n    r'^(one more thing|by the way|btw)',\n    r'^(can you also|could you also|please also)',\n    r'^(don\\'?t forget|remember to|make sure)',\n    r'^(oh and|oh,? also)',\n]\n\n# Patterns that suggest a completely new task\nNEW_TASK_PATTERNS = [\n    r'^(new task|different task|change of plans|something else|switch to)',\n    r'^(forget (that|the previous)|start over|start fresh|reset)',\n    r'^(i want to|let\\'?s? (work on|do|start))',\n    r'^(help me (with|build|create|implement|add|fix|debug|review))',\n    r'^(can you help|i need help|i need you to)',\n    r'^(create|build|implement|add|fix|debug|review|analyze|refactor)',\n    r'^(onboard|write|develop|make|design|setup|configure|install)',\n]\n\n\ndef analyze_prompt(prompt: str, current_state: str) -> str:\n    \"\"\"\n    Analyze prompt to determine intent.\n    Returns: 'continuation', 'addition', 'new_task', or 'unknown'\n    \"\"\"\n    prompt_lower = prompt.lower().strip()\n    \n    # Check for explicit continuation patterns\n    for pattern in CONTINUATION_PATTERNS:\n        if re.search(pattern, prompt_lower, re.IGNORECASE):\n            return 'continuation'\n    \n    # Check for addition patterns\n    for pattern in ADDITION_PATTERNS:\n        if re.search(pattern, prompt_lower, re.IGNORECASE):\n            return 'addition'\n    \n    # Check for explicit new task patterns\n    for pattern in NEW_TASK_PATTERNS:\n        if re.search(pattern, prompt_lower, re.IGNORECASE):\n            return 'new_task'\n    \n    # If we're in an active execution state and prompt is short, likely continuation\n    active_states = ['WF_EXECUTE', 'WF_CHECKPOINT', 'WF_VERIFY', 'WF_DEBUG_TDD']\n    if current_state in active_states and len(prompt_lower) < 50:\n        return 'continuation'\n    \n    # Default: treat as potential new task for safety\n    return 'unknown'\n\n\n\ndef main():\n    try:\n        # Read input\n        input_data = {}\n        try:\n            input_data = json.load(sys.stdin)\n        except:\n            pass\n        \n        prompt = input_data.get('prompt', '')\n        cwd = input_data.get('cwd', os.getcwd())\n        \n        if not prompt or not prompt.strip():\n            sys.exit(0)\n        \n        # Check setup\n        setup = load_setup_complete(cwd)\n        if not setup or not setup.get('complete'):\n            output = {\n                \"hookSpecificOutput\": {\n                    \"hookEventName\": \"UserPromptSubmit\",\n                    \"additionalContext\": \"‚ö†Ô∏è SWE not initialized. Run /swe-init first.\"\n                }\n            }\n            print(json.dumps(output))\n            sys.exit(0)\n        \n        # Extract session ID from transcript_path for session isolation\n        transcript_path = input_data.get('transcript_path', '')\n        session_id = None\n        if transcript_path:\n            uuid_match = re.search(r'([a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12})', transcript_path)\n            if uuid_match:\n                session_id = uuid_match.group(1)[:8]\n        \n        # Get current state from WM (session-isolated)\n        # Only use working memory if it matches this session\n        wm_file = get_working_memory_filename(cwd)\n        state_data, _ = read_working_memory_state(cwd)\n        \n        # Check if the working memory belongs to THIS session\n        wm_session_id = None\n        if state_data:\n            wm_session_id = state_data.get(\"session_id\")\n\n        # If no working memory, OR working memory has no session ID (old format),\n        # OR session ID mismatch, start fresh at WF_INIT\n        should_reset = (\n            not state_data or              # No working memory found\n            not wm_session_id or           # WM has no session ID (old format)\n            (session_id and session_id != wm_session_id)  # Session mismatch\n        )\n\n        if should_reset:\n            # No working memory for this session - start at WF_INIT\n            current_state = \"WF_INIT\"\n            wm_file = None  # Don't show old session's working memory\n        else:\n            current_state = state_data.get(\"current_state\", \"WF_INIT\")\n        \n        # Create StateManager for potential transitions\n        state_mgr = StateManager(cwd)\n        \n        # Analyze prompt intent\n        prompt_intent = analyze_prompt(prompt, current_state)\n        \n        # Handle WF_INIT state - always direct to WF_INIT workflow\n        if current_state == 'WF_INIT':\n            context = f\"\"\"<workflow-gate state=\"WF_INIT\" session=\"{session_id or 'unknown'}\">\n<blocking-instruction priority=\"CRITICAL\">\nSTOP. Your next action MUST be a tool call. Not text. A tool call.\n\nCall this tool NOW:\nmcp__plugin_swe_serena__read_memory(memory_file_name=\"WF_INIT\")\n\n- Do NOT output any text before calling this tool\n- Do NOT explain what you're doing\n- Do NOT acknowledge the user's message first\n- Do NOT skip this because the user asked something specific\n- The user's request will be handled AFTER you read WF_INIT\n\nIf your next output contains ANY text instead of a tool call, you have failed.\n</blocking-instruction>\n</workflow-gate>\"\"\"\n            output = {\n                \"hookSpecificOutput\": {\n                    \"hookEventName\": \"UserPromptSubmit\",\n                    \"additionalContext\": context\n                }\n            }\n            print(json.dumps(output))\n            sys.exit(0)\n        \n        # Handle completed/uninitialized states\n        if current_state in ['UNINITIALIZED', 'WF_DONE', 'WF_CLEANUP', None]:\n            # Check if we have a valid working memory for THIS session\n            # If so, this is a \"new task in same session\" - preserve working memory\n            is_same_session_new_task = (\n                wm_file and\n                wm_session_id and\n                session_id and\n                wm_session_id == session_id and\n                current_state in ['WF_DONE', 'WF_CLEANUP']\n            )\n\n            if is_same_session_new_task:\n                # Same session, new task after completion - go to WF_CLASSIFY, preserve WM\n                state_mgr.transition_to('WF_CLASSIFY')\n                current_state = 'WF_CLASSIFY'\n                # Analyze the prompt to understand intent (don't force new_task)\n                prompt_intent = analyze_prompt(prompt, current_state)\n                if prompt_intent == 'unknown':\n                    prompt_intent = 'same_session_new_task'  # Special case\n            else:\n                # Truly new session or no working memory - go to WF_START\n                state_mgr.transition_to('WF_START')\n                current_state = 'WF_START'\n                prompt_intent = 'new_task'\n        \n        # Build context based on prompt intent and state\n        if prompt_intent == 'continuation':\n            # User is continuing - stay in current state, provide brief reminder\n            if current_state == 'WF_START':\n                # Haven't progressed - need to classify\n                context = f\"\"\"üìã WORKFLOW STATE: {current_state}\nWorking Memory: {wm_file or 'None'}\n\nMANDATORY: Before responding, read and follow the WF_START workflow.\nUse: mcp__plugin_swe_serena__read_memory(memory_file_name=\"WF_START\")\n\"\"\"\n            else:\n                # In active state - continue workflow\n                context = f\"\"\"‚û°Ô∏è CONTINUING WORKFLOW: {current_state}\nWorking Memory: {wm_file or 'None'}\n\nContinue with the current workflow step.\nIf you need to review instructions: mcp__plugin_swe_serena__read_memory(memory_file_name=\"{current_state}\")\n\"\"\"\n        \n        elif prompt_intent == 'addition':\n            # User is adding to current task - stay in current state\n            context = f\"\"\"‚ûï TASK ADDITION - WORKFLOW STATE: {current_state}\nWorking Memory: {wm_file or 'None'}\n\nUser is adding to the current task. Incorporate this into your current workflow step.\nIf scope changes significantly, transition to WF_CLASSIFY.\n\"\"\"\n        \n        elif prompt_intent == 'same_session_new_task':\n            # New task in same session after WF_DONE - preserve and update existing working memory\n            context = f\"\"\"üîÑ NEW TASK IN SAME SESSION - WORKFLOW STATE: {current_state}\nWorking Memory: {wm_file}\nSession: {session_id}\n\n**IMPORTANT: This is a NEW TASK in the SAME SESSION after completing WF_DONE.**\n\n**DO NOT create a new WM file.** Instead:\n\n1. **UPDATE the existing WM ({wm_file}):**\n   - Increment `Task Iteration` counter\n   - Move previous task to `## Completed Tasks (This Session)` section\n   - Add new task to `## Active Task`\n   - Reset `Edit Count Since Checkpoint` to 0\n   - Set `Current State` to `WF_CLASSIFY`\n\n2. **Then proceed with task classification:**\n   Use: mcp__plugin_swe_serena__read_memory(memory_file_name=\"WF_CLASSIFY\")\n\"\"\"\n\n        elif prompt_intent == 'new_task':\n            # New task - transition to WF_START\n            if current_state not in ['WF_START', 'WF_INIT']:\n                state_mgr.transition_to('WF_START')\n                current_state = 'WF_START'\n\n            context = f\"\"\"üÜï NEW TASK DETECTED - WORKFLOW STATE: {current_state}\nWorking Memory: {wm_file or 'None'}\n\nMANDATORY: Before responding, read and follow the {current_state} workflow instructions.\nUse: mcp__plugin_swe_serena__read_memory(memory_file_name=\"{current_state}\")\n\"\"\"\n        \n        else:\n            # Unknown intent - route to WF_CLASSIFY for proper classification\n            if current_state == 'WF_START':\n                context = f\"\"\"‚ùì INTENT UNCLEAR - WORKFLOW STATE: {current_state}\nWorking Memory: {wm_file or 'None'}\n\nMANDATORY: Before responding, read and follow WF_START to initialize.\nThen proceed to WF_CLASSIFY for task classification.\nUse: mcp__plugin_swe_serena__read_memory(memory_file_name=\"{current_state}\")\n\"\"\"\n            else:\n                # Transition to WF_CLASSIFY for classification\n                state_mgr.transition_to('WF_CLASSIFY')\n                context = f\"\"\"‚ùì INTENT UNCLEAR - Routing to WF_CLASSIFY\nWorking Memory: {wm_file or 'None'}\n\nMANDATORY: Classify this task using WF_CLASSIFY.\nUse: mcp__plugin_swe_serena__read_memory(memory_file_name=\"WF_CLASSIFY\")\n\"\"\"\n        \n        output = {\n            \"hookSpecificOutput\": {\n                \"hookEventName\": \"UserPromptSubmit\",\n                \"additionalContext\": context\n            }\n        }\n        print(json.dumps(output))\n        sys.exit(0)\n        \n    except Exception as e:\n        print(json.dumps({\"systemMessage\": f\"Workflow hook error: {e}\"}), file=sys.stdout)\n        sys.exit(0)\n\n\nif __name__ == '__main__':\n    main()\n",
        "hooks/session/swe_session_start.py": "#!/usr/bin/env python3\n\"\"\"SessionStart hook - Initialize WF_INIT workflow using WM.\n\nState is stored in WM files (session-isolated), NOT in a global state file.\nThis allows multiple concurrent sessions without state conflicts.\n\"\"\"\n\nimport os\nimport sys\nimport json\nfrom datetime import datetime\n\nPLUGIN_ROOT = os.environ.get('CLAUDE_PLUGIN_ROOT', '')\nif PLUGIN_ROOT:\n    hooks_dir = os.path.join(PLUGIN_ROOT, 'hooks')\n    if hooks_dir not in sys.path:\n        sys.path.insert(0, hooks_dir)\n\ntry:\n    from swe_hooks.core.config import (\n        load_setup_complete,\n        get_most_recent_working_memory, get_working_memory_filename,\n        read_working_memory_state, get_paths\n    )\n    from swe_hooks.core.state_manager import StateManager\n    from swe_hooks.core.wm_writer_daemon import async_wm_write\nexcept ImportError as e:\n    print(json.dumps({\"systemMessage\": f\"SWE import error: {e}\"}), file=sys.stdout)\n    sys.exit(0)\n\n\n\n\n\ndef main():\n    try:\n        # Read input\n        input_data = {}\n        try:\n            input_data = json.load(sys.stdin)\n        except:\n            pass\n        \n        cwd = input_data.get('cwd', os.getcwd())\n        \n        # Extract unique session ID from transcript_path (contains UUID per conversation)\n        # This ensures each chat gets its own isolated session\n        transcript_path = input_data.get('transcript_path', '')\n        if transcript_path:\n            # Extract UUID from path like ~/.claude/projects/.../00893aaf-19fa-41d2-8238-13269b9b3ca0.jsonl\n            import re\n            uuid_match = re.search(r'([a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12})', transcript_path)\n            if uuid_match:\n                session_id = uuid_match.group(1)[:8]  # Use first 8 chars for brevity\n            else:\n                session_id = datetime.now().strftime('%Y%m%d_%H%M%S')\n        else:\n            session_id = datetime.now().strftime('%Y%m%d_%H%M%S')\n\n        # Check setup\n        setup = load_setup_complete(cwd)\n        if not setup or not setup.get('complete'):\n            # First-time project setup NOT complete - this is different from session init\n            output = {\n                \"hookSpecificOutput\": {\n                    \"hookEventName\": \"SessionStart\",\n                    \"additionalContext\": \"\"\"üõëüõëüõë CRITICAL: PROJECT SETUP NOT COMPLETE üõëüõëüõë\n\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n                    ‚ö†Ô∏è  FIRST-TIME SETUP REQUIRED  ‚ö†Ô∏è\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\nThis is a ONE-TIME setup for the project (not per-session).\n\nMANDATORY: Run /swe-init to complete first-time project setup.\n\nThis installs:\n- MCP server configurations\n- Workflow instruction files\n- Core memory templates\n- Git ignore entries\n\nAfter /swe-init completes, restart Claude Code and return to this project.\n\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n              DO NOT ATTEMPT ANY OTHER ACTIONS UNTIL SETUP COMPLETE\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\"\"\"\n                }\n            }\n            print(json.dumps(output))\n            sys.exit(0)\n\n        # DO NOT auto-create WM here - it should only be created during WF_START transition\n        # This ensures the init_gate can block tools until WF_INIT is read\n        # WM creation happens in WF_INIT workflow instructions\n\n        context = f\"\"\"üöÄ SERENA WORKFLOW ENGINE - Session {session_id}\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n‚è≥ Working Memory: Not yet created (will be created after WF_INIT)\nCurrent State: WF_INIT\n\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nSTEP 1: Read WF_INIT workflow instructions\n   ‚Üí mcp__plugin_swe_serena__read_memory(memory_file_name=\"WF_INIT\")\n\nSTEP 2: Follow WF_INIT to classify and execute user's task\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n\"\"\"\n\n        output = {\n            \"hookSpecificOutput\": {\n                \"hookEventName\": \"SessionStart\",\n                \"additionalContext\": context\n            }\n        }\n        print(json.dumps(output))\n        sys.exit(0)\n\n    except Exception as e:\n        print(json.dumps({\"systemMessage\": f\"Session start error: {e}\"}), file=sys.stdout)\n        sys.exit(0)\n\n\nif __name__ == '__main__':\n    main()",
        "hooks/stop/swe_stop_workflow_check.py": "#!/usr/bin/env python3\n\"\"\"Stop hook - Check workflow state.\"\"\"\n\nimport os\nimport sys\nimport json\n\nPLUGIN_ROOT = os.environ.get('CLAUDE_PLUGIN_ROOT', '')\nif PLUGIN_ROOT:\n    hooks_dir = os.path.join(PLUGIN_ROOT, 'hooks')\n    if hooks_dir not in sys.path:\n        sys.path.insert(0, hooks_dir)\n\ntry:\n    from swe_hooks.core.output import HookOutput, output_empty\n    from swe_hooks.core.input import read_stdin_safe, get_input_field\n    from swe_hooks.core.state_manager import StateManager\nexcept ImportError as e:\n    output = {\"hookSpecificOutput\": {\"hookEventName\": \"Stop\", \"additionalContext\": f\"SWE import error: {e}\"}}\n    print(json.dumps(output), file=sys.stdout)\n    sys.exit(0)\n\nINCOMPLETE = {'WF_EXECUTE', 'WF_DEBUG_TDD', 'WF_VERIFY', 'WF_PLAN_ARCHITECTURE'}\n\ndef main():\n    try:\n        input_data = read_stdin_safe(timeout_seconds=2.0)\n        cwd = get_input_field(input_data, 'cwd', default=os.getcwd())\n        state_mgr = StateManager(cwd)\n        current = state_mgr.get_current_state()\n        if current in ('WF_DONE', 'WF_CLEANUP', 'UNINITIALIZED'):\n            output_empty()\n        if current in INCOMPLETE:\n            output = HookOutput(event_name=\"Stop\")\n            output.add_message(f\"‚ö†Ô∏è Stopping with incomplete work: {current}\")\n            output.output_and_exit()\n        output_empty()\n    except Exception as e:\n        output = {\"hookSpecificOutput\": {\"hookEventName\": \"Stop\", \"additionalContext\": f\"Stop error: {e}\"}}\n        print(json.dumps(output), file=sys.stdout)\n        sys.exit(0)\n\nif __name__ == '__main__':\n    main()\n",
        "hooks/swe_hooks/core/config.py": "\"\"\"Configuration and path helpers for SWE hooks.\n\nState is stored in WORKING_MEMORY files (session-isolated), NOT in a global state file.\nThis allows multiple concurrent sessions without state conflicts.\n\"\"\"\n\nimport json\nimport os\nimport re\nimport glob\nfrom typing import Dict, Any, Optional, List, Tuple, Callable\nfrom datetime import datetime\n\n# Async write support - lazy import to avoid circular dependencies\n_async_writer_available = None\n_use_async_writes = True  # Set to False to disable async writes globally\n\n\ndef _get_async_writer():\n    \"\"\"Lazy import of async writer to avoid circular dependencies.\"\"\"\n    global _async_writer_available\n    if _async_writer_available is None:\n        try:\n            from .wm_writer_daemon import async_wm_write, async_wm_append\n            _async_writer_available = True\n        except ImportError:\n            _async_writer_available = False\n    return _async_writer_available\n\n\ndef set_async_writes_enabled(enabled: bool):\n    \"\"\"Enable or disable async writes globally.\"\"\"\n    global _use_async_writes\n    _use_async_writes = enabled\n\n\ndef is_async_writes_enabled() -> bool:\n    \"\"\"Check if async writes are enabled and available.\"\"\"\n    return _use_async_writes and _get_async_writer()\n\n\ndef get_project_root() -> str:\n    \"\"\"Get project root from CLAUDE_PROJECT_DIR env var (set by Claude Code).\n\n    This is the official, documented way to get the project root.\n    Immune to cd commands changing the working directory.\n    \"\"\"\n    # Primary: CLAUDE_PROJECT_DIR - set by Claude Code, never changes\n    project_dir = os.environ.get('CLAUDE_PROJECT_DIR', '')\n    if project_dir:\n        return project_dir\n\n    # Fallback: walk up from cwd (less reliable after cd)\n    current = os.getcwd()\n    while current != os.path.dirname(current):\n        if os.path.isdir(os.path.join(current, '.serena')):\n            return current\n        current = os.path.dirname(current)\n    return os.getcwd()\n\n\ndef get_paths(cwd: str = None) -> Dict[str, str]:\n    \"\"\"Get all relevant paths based on project root.\n\n    Args:\n        cwd: Ignored - kept for backward compatibility.\n    \"\"\"\n    project_root = get_project_root()\n    return {\n        \"cwd\": cwd,\n        \"project_root\": project_root,\n        \"claude_dir\": os.path.join(project_root, \".claude\"),\n        \"setup_file\": os.path.join(project_root, \".claude\", \"swe-setup-complete.json\"),\n        \"learning_file\": os.path.join(project_root, \".claude\", \"learning.json\"),\n        \"plugin_dir\": os.path.join(project_root, \".claude\", \"plugins\", \"swe\"),\n        \"instructions_dir\": os.path.join(project_root, \".claude\", \"plugins\", \"swe\", \"memories\", \"instructions\"),\n        \"references_dir\": os.path.join(project_root, \".claude\", \"plugins\", \"swe\", \"memories\", \"references\"),\n        \"serena_memories\": os.path.join(project_root, \".serena\", \"memories\"),\n    }\n\n\n# =============================================================================\n# WORKING_MEMORY-based State Management (Session-Isolated)\n# =============================================================================\n\ndef find_working_memory_files(cwd: str) -> List[str]:\n    \"\"\"Find all WORKING_MEMORY files, sorted by date (newest first).\"\"\"\n    paths = get_paths(cwd)\n    memories_dir = paths[\"serena_memories\"]\n    \n    if not os.path.exists(memories_dir):\n        return []\n    \n    pattern = os.path.join(memories_dir, \"WM_*.md\")\n    files = glob.glob(pattern)\n    \n    # Sort by filename (which includes timestamp) in reverse order\n    files.sort(reverse=True)\n    return files\n\n\ndef get_most_recent_working_memory(cwd: str) -> Optional[str]:\n    \"\"\"Get the most recent WORKING_MEMORY file path.\"\"\"\n    files = find_working_memory_files(cwd)\n    return files[0] if files else None\n\n\ndef get_working_memory_filename(cwd: str) -> Optional[str]:\n    \"\"\"Get just the filename (without path) of the most recent WORKING_MEMORY.\"\"\"\n    filepath = get_most_recent_working_memory(cwd)\n    if filepath:\n        return os.path.basename(filepath).replace('.md', '')\n    return None\n\n\ndef parse_working_memory_state(content: str) -> Dict[str, Any]:\n    \"\"\"Parse workflow state from WORKING_MEMORY markdown content.\n    \n    Extracts state from the '## Workflow Context' section.\n    \"\"\"\n    state = {\n        \"current_state\": \"WF_INIT\",\n        \"feature_keys\": [],\n        \"session_id\": None,\n        \"return_step\": None,\n        \"invocation_mode\": \"workflow\",\n        \"status\": \"Starting\",\n    }\n    \n    # Find the Workflow Context section\n    wf_match = re.search(r'## Workflow Context\\s*\\n(.*?)(?=\\n## |\\Z)', content, re.DOTALL)\n    if wf_match:\n        wf_section = wf_match.group(1)\n        \n        # Parse key-value pairs\n        # Current State takes priority (explicit state for stop hook)\n        current_state = re.search(r'\\*\\*Current State\\*\\*:\\s*(\\S+)', wf_section)\n        if current_state:\n            state[\"current_state\"] = current_state.group(1)\n        else:\n            # Fall back to Calling Step for backward compatibility\n            calling_step = re.search(r'\\*\\*Calling Step\\*\\*:\\s*(\\S+)', wf_section)\n            if calling_step:\n                state[\"current_state\"] = calling_step.group(1)\n        \n        feature_keys = re.search(r'\\*\\*Feature Key\\(s\\)\\*\\*:\\s*(.+)', wf_section)\n        if feature_keys:\n            state[\"feature_keys\"] = [k.strip() for k in feature_keys.group(1).split(',')]\n        \n        session_id = re.search(r'\\*\\*Session ID\\*\\*:\\s*(\\S+)', wf_section)\n        if session_id:\n            state[\"session_id\"] = session_id.group(1)\n        \n        return_step = re.search(r'\\*\\*Return Step\\*\\*:\\s*(\\S+)', wf_section)\n        if return_step:\n            state[\"return_step\"] = return_step.group(1)\n        \n        invocation_mode = re.search(r'\\*\\*Invocation Mode\\*\\*:\\s*(\\S+)', wf_section)\n        if invocation_mode:\n            state[\"invocation_mode\"] = invocation_mode.group(1)\n    \n    # Also parse Session Context for status\n    status_match = re.search(r'\\*\\*Status\\*\\*:\\s*(.+)', content)\n    if status_match:\n        state[\"status\"] = status_match.group(1).strip()\n    \n    return state\n\n\ndef update_working_memory_state(content: str, new_state: str, return_step: str = None) -> str:\n    \"\"\"Update the workflow state in WORKING_MEMORY content.\n\n    Modifies the '## Workflow Context' section with new state.\n    Returns the updated content.\n    \"\"\"\n    # Update Current State (primary field for stop hook)\n    if re.search(r'\\*\\*Current State\\*\\*:', content):\n        content = re.sub(\n            r'(\\*\\*Current State\\*\\*:\\s*)\\S+',\n            f'\\\\g<1>{new_state}',\n            content\n        )\n\n    # Update Calling Step (for backward compatibility)\n    content = re.sub(\n        r'(\\*\\*Calling Step\\*\\*:\\s*)\\S+',\n        f'\\\\g<1>{new_state}',\n        content\n    )\n    \n    # Update Return Step if provided\n    if return_step:\n        content = re.sub(\n            r'(\\*\\*Return Step\\*\\*:\\s*)\\S+',\n            f'\\\\g<1>{return_step}',\n            content\n        )\n    \n    # Update Last Updated timestamp\n    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n    if re.search(r'## Last Updated', content):\n        content = re.sub(\n            r'(## Last Updated\\s*\\n).*',\n            f'\\\\g<1>{timestamp}',\n            content\n        )\n    \n    return content\n\n\n# =============================================================================\n# WORKING_MEMORY Staleness Detection (for enforcement)\n# =============================================================================\n\ndef get_wm_last_updated(content: str) -> Optional[datetime]:\n    \"\"\"Extract the last updated timestamp from WORKING_MEMORY content.\n    \n    Looks for patterns like:\n    - **Last Updated:** 2026-01-22T14:30:00Z\n    - **Edit Count Since Checkpoint:** N\n    \"\"\"\n    # Try ISO format first\n    match = re.search(r'\\*\\*Last Updated\\*\\*:\\s*(\\d{4}-\\d{2}-\\d{2}[T ]\\d{2}:\\d{2}(?::\\d{2})?)', content)\n    if match:\n        try:\n            ts = match.group(1).replace('T', ' ')[:16]  # Normalize to YYYY-MM-DD HH:MM\n            return datetime.strptime(ts, \"%Y-%m-%d %H:%M\")\n        except ValueError:\n            pass\n    \n    # Try simpler date format\n    match = re.search(r'\\*\\*Last Updated\\*\\*:\\s*(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2})', content)\n    if match:\n        try:\n            return datetime.strptime(match.group(1), \"%Y-%m-%d %H:%M\")\n        except ValueError:\n            pass\n    \n    return None\n\n\ndef get_wm_edit_count(content: str) -> int:\n    \"\"\"Extract the edit count from WORKING_MEMORY content.\"\"\"\n    match = re.search(r'\\*\\*Edit Count Since Checkpoint\\*\\*:\\s*(\\d+)', content)\n    if match:\n        return int(match.group(1))\n    return 0\n\n\ndef update_wm_edit_tracking(content: str, edit_count: int, edited_files: List[str] = None) -> str:\n    \"\"\"Update edit tracking metadata in WORKING_MEMORY content.\n    \n    Updates or adds:\n    - **Last Updated:** timestamp\n    - **Edit Count Since Checkpoint:** N\n    - **Recent Edits:** list of files\n    \"\"\"\n    timestamp = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n    \n    # Update or add Last Updated\n    if re.search(r'\\*\\*Last Updated\\*\\*:', content):\n        content = re.sub(\n            r'(\\*\\*Last Updated\\*\\*:\\s*).*',\n            f'\\\\g<1>{timestamp}',\n            content\n        )\n    else:\n        # Add to Progress section if it exists\n        if '## Progress' in content:\n            content = re.sub(\n                r'(## Progress\\s*\\n)',\n                f'\\\\g<1>\\n**Last Updated:** {timestamp}\\n',\n                content\n            )\n    \n    # Update or add Edit Count\n    if re.search(r'\\*\\*Edit Count Since Checkpoint\\*\\*:', content):\n        content = re.sub(\n            r'(\\*\\*Edit Count Since Checkpoint\\*\\*:\\s*)\\d+',\n            f'\\\\g<1>{edit_count}',\n            content\n        )\n    else:\n        # Add after Last Updated if present, otherwise to Progress section\n        if re.search(r'\\*\\*Last Updated\\*\\*:', content):\n            content = re.sub(\n                r'(\\*\\*Last Updated\\*\\*:.*\\n)',\n                f'\\\\g<1>**Edit Count Since Checkpoint:** {edit_count}\\n',\n                content\n            )\n    \n    # Update Recent Edits list\n    if edited_files:\n        edits_str = ', '.join([f'`{f}`' for f in edited_files[-5:]])  # Keep last 5\n        if re.search(r'\\*\\*Recent Edits\\*\\*:', content):\n            content = re.sub(\n                r'(\\*\\*Recent Edits\\*\\*:\\s*).*',\n                f'\\\\g<1>{edits_str}',\n                content\n            )\n        else:\n            if re.search(r'\\*\\*Edit Count Since Checkpoint\\*\\*:', content):\n                content = re.sub(\n                    r'(\\*\\*Edit Count Since Checkpoint\\*\\*:.*\\n)',\n                    f'\\\\g<1>**Recent Edits:** {edits_str}\\n',\n                    content\n                )\n    \n    return content\n\n\ndef reset_wm_edit_tracking(content: str) -> str:\n    \"\"\"Reset edit tracking after a checkpoint (user updated progress).\"\"\"\n    timestamp = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n    \n    # Update Last Updated\n    if re.search(r'\\*\\*Last Updated\\*\\*:', content):\n        content = re.sub(\n            r'(\\*\\*Last Updated\\*\\*:\\s*).*',\n            f'\\\\g<1>{timestamp}',\n            content\n        )\n    \n    # Reset Edit Count to 0\n    if re.search(r'\\*\\*Edit Count Since Checkpoint\\*\\*:', content):\n        content = re.sub(\n            r'(\\*\\*Edit Count Since Checkpoint\\*\\*:\\s*)\\d+',\n            '\\\\g<1>0',\n            content\n        )\n    \n    # Clear Recent Edits\n    if re.search(r'\\*\\*Recent Edits\\*\\*:', content):\n        content = re.sub(\n            r'\\*\\*Recent Edits\\*\\*:.*\\n',\n            '',\n            content\n        )\n    \n    return content\n\n\ndef check_wm_staleness(cwd: str, wm_filepath: str, edit_threshold: int = 3) -> Tuple[bool, int, Optional[datetime]]:\n    \"\"\"Check if WORKING_MEMORY is stale based on edit tracking.\n    \n    Args:\n        cwd: Working directory\n        wm_filepath: Path to the WORKING_MEMORY file\n        edit_threshold: Number of edits before considered stale\n    \n    Returns:\n        Tuple of (is_stale, edit_count, last_update_time)\n    \"\"\"\n    if not wm_filepath or not os.path.exists(wm_filepath):\n        return False, 0, None\n    \n    try:\n        with open(wm_filepath, 'r') as f:\n            content = f.read()\n        \n        edit_count = get_wm_edit_count(content)\n        last_updated = get_wm_last_updated(content)\n        \n        is_stale = edit_count >= edit_threshold\n        return is_stale, edit_count, last_updated\n    except IOError:\n        return False, 0, None\n\n\ndef check_wm_progress_updated(cwd: str, wm_filepath: str, since_timestamp: datetime = None) -> bool:\n    \"\"\"Check if WORKING_MEMORY Progress section was updated since timestamp.\n    \n    Args:\n        cwd: Working directory\n        wm_filepath: Path to the WORKING_MEMORY file\n        since_timestamp: Check if updated after this time. If None, checks if edit count is 0.\n    \n    Returns:\n        True if progress was updated (edit count is 0 or last_updated > since_timestamp)\n    \"\"\"\n    if not wm_filepath or not os.path.exists(wm_filepath):\n        return True  # No WM to check - allow operation\n    \n    try:\n        with open(wm_filepath, 'r') as f:\n            content = f.read()\n        \n        edit_count = get_wm_edit_count(content)\n        \n        # If edit count is 0, WM was updated after last checkpoint\n        if edit_count == 0:\n            return True\n        \n        # If we have a timestamp to check against\n        if since_timestamp:\n            last_updated = get_wm_last_updated(content)\n            if last_updated and last_updated > since_timestamp:\n                return True\n        \n        return False\n    except IOError:\n        return True  # On error, allow operation\n\n\ndef persist_edit_to_wm(cwd: str, wm_filepath: str, edited_file: str = None,\n                       async_mode: bool = None) -> Tuple[bool, int]:\n    \"\"\"Persist an edit to WORKING_MEMORY tracking.\n\n    Args:\n        cwd: Working directory\n        wm_filepath: Path to the WORKING_MEMORY file\n        edited_file: Optional file path that was edited\n        async_mode: Override async behavior (None = use global setting)\n\n    Returns:\n        Tuple of (success, new_edit_count)\n    \"\"\"\n    if not wm_filepath or not os.path.exists(wm_filepath):\n        return False, 0\n\n    try:\n        with open(wm_filepath, 'r') as f:\n            content = f.read()\n\n        # Get current edit count and increment\n        current_count = get_wm_edit_count(content)\n        new_count = current_count + 1\n\n        # Get recent edits list\n        recent_match = re.search(r'\\*\\*Recent Edits\\*\\*:\\s*(.+)', content)\n        recent_files = []\n        if recent_match:\n            # Parse existing files\n            recent_str = recent_match.group(1)\n            recent_files = [f.strip('`').strip() for f in recent_str.split(',') if f.strip()]\n\n        # Add new file if provided\n        if edited_file:\n            # Clean up file path\n            clean_path = edited_file.replace(cwd, '').lstrip('/')\n            if clean_path not in recent_files:\n                recent_files.append(clean_path)\n\n        # Update content\n        updated_content = update_wm_edit_tracking(content, new_count, recent_files)\n\n        # Determine if async write should be used\n        use_async = async_mode if async_mode is not None else is_async_writes_enabled()\n\n        if use_async:\n            # Use async background writer\n            from .wm_writer_daemon import async_wm_write\n            success = async_wm_write(\n                filepath=wm_filepath,\n                content=updated_content,\n                operation_type='edit_tracking',\n                validate=False,  # Edit tracking doesn't need full validation\n                old_content=content,\n            )\n            return success, new_count\n        else:\n            # Synchronous write (original behavior)\n            with open(wm_filepath, 'w') as f:\n                f.write(updated_content)\n            return True, new_count\n    except IOError:\n        return False, 0\n\n\ndef append_transition_to_wm(wm_filepath: str, from_state: str, to_state: str,\n                            async_mode: bool = None) -> bool:\n    \"\"\"Append a state transition note to WORKING_MEMORY Progress section.\n\n    Args:\n        wm_filepath: Path to the WORKING_MEMORY file\n        from_state: Previous workflow state\n        to_state: New workflow state\n        async_mode: Override async behavior (None = use global setting)\n\n    Returns:\n        True if successful, False otherwise\n    \"\"\"\n    if not wm_filepath or not os.path.exists(wm_filepath):\n        return False\n\n    try:\n        with open(wm_filepath, 'r') as f:\n            content = f.read()\n\n        timestamp = datetime.now().strftime(\"%H:%M\")\n        transition_note = f\"- [{timestamp}] Transitioned: {from_state} ‚Üí {to_state}\"\n\n        # Find Progress section and append transition note\n        progress_match = re.search(r'(## Progress\\s*\\n)(.*?)(?=\\n## |\\Z)', content, re.DOTALL)\n        updated_content = content\n\n        if progress_match:\n            progress_section = progress_match.group(2)\n\n            # Check if there's already a Transitions subsection\n            if '### Transitions' in progress_section:\n                # Append to existing Transitions subsection\n                updated_content = re.sub(\n                    r'(### Transitions\\s*\\n.*?)(\\n###|\\n##|\\Z)',\n                    f'\\\\g<1>{transition_note}\\n\\\\g<2>',\n                    content,\n                    flags=re.DOTALL\n                )\n            else:\n                # Add Transitions subsection before the next section or at end of Progress\n                insert_pos = progress_match.end()\n                updated_content = content[:insert_pos] + f\"\\n### Transitions\\n{transition_note}\\n\" + content[insert_pos:]\n\n        # Determine if async write should be used\n        use_async = async_mode if async_mode is not None else is_async_writes_enabled()\n\n        if use_async:\n            # Use async background writer\n            from .wm_writer_daemon import async_wm_write\n            return async_wm_write(\n                filepath=wm_filepath,\n                content=updated_content,\n                operation_type='transition_log',\n                validate=False,  # Transition logging doesn't need full validation\n                old_content=content,\n            )\n        else:\n            # Synchronous write (original behavior)\n            with open(wm_filepath, 'w') as f:\n                f.write(updated_content)\n            return True\n    except IOError:\n        return False\n\n\ndef read_working_memory_state(cwd: str, wm_filename: str = None) -> Tuple[Optional[Dict[str, Any]], Optional[str]]:\n    \"\"\"Read state from a WORKING_MEMORY file.\n    \n    Args:\n        cwd: Working directory\n        wm_filename: Optional specific WORKING_MEMORY filename (without .md)\n                    If None, uses most recent WORKING_MEMORY file\n    \n    Returns:\n        Tuple of (state_dict, wm_filepath) or (None, None) if not found\n    \"\"\"\n    paths = get_paths(cwd)\n    \n    if wm_filename:\n        filepath = os.path.join(paths[\"serena_memories\"], f\"{wm_filename}.md\")\n    else:\n        filepath = get_most_recent_working_memory(cwd)\n    \n    if not filepath or not os.path.exists(filepath):\n        return None, None\n    \n    try:\n        with open(filepath, 'r') as f:\n            content = f.read()\n        state = parse_working_memory_state(content)\n        return state, filepath\n    except IOError:\n        return None, None\n\n\ndef write_working_memory_state(cwd: str, wm_filepath: str, new_state: str,\n                                return_step: str = None, async_mode: bool = None) -> bool:\n    \"\"\"Update state in a WORKING_MEMORY file.\n\n    Args:\n        cwd: Working directory\n        wm_filepath: Full path to the WORKING_MEMORY file\n        new_state: New workflow state (e.g., 'WF_EXECUTE')\n        return_step: Optional return step to set\n        async_mode: Override async behavior (None = use global setting)\n\n    Returns:\n        True if successful, False otherwise\n    \"\"\"\n    if not os.path.exists(wm_filepath):\n        return False\n\n    try:\n        with open(wm_filepath, 'r') as f:\n            content = f.read()\n\n        updated_content = update_working_memory_state(content, new_state, return_step)\n\n        # Determine if async write should be used\n        use_async = async_mode if async_mode is not None else is_async_writes_enabled()\n\n        if use_async:\n            # Use async background writer with anti-pattern detection\n            from .wm_writer_daemon import async_wm_write\n            return async_wm_write(\n                filepath=wm_filepath,\n                content=updated_content,\n                operation_type='state_update',\n                validate=True,  # State updates should be validated\n                old_content=content,  # For anti-pattern detection\n            )\n        else:\n            # Synchronous write (original behavior)\n            with open(wm_filepath, 'w') as f:\n                f.write(updated_content)\n            return True\n    except IOError:\n        return False\n\n\n# =============================================================================\n# Legacy Compatibility Layer\n# These functions now use WORKING_MEMORY as the source of truth\n# =============================================================================\n\ndef load_workflow_state(cwd: str, wm_filename: str = None) -> Optional[Dict[str, Any]]:\n    \"\"\"Load workflow state from WORKING_MEMORY file.\n    \n    NOTE: State is now stored in WORKING_MEMORY files, not a global JSON file.\n    This allows multiple concurrent sessions without state conflicts.\n    \"\"\"\n    state, filepath = read_working_memory_state(cwd, wm_filename)\n    \n    if state is None:\n        return None\n    \n    # Convert to legacy format for backward compatibility\n    return {\n        \"session_id\": state.get(\"session_id\"),\n        \"current_state\": state.get(\"current_state\", \"WF_INIT\"),\n        \"previous_state\": None,\n        \"working_memory_file\": os.path.basename(filepath).replace('.md', '') if filepath else None,\n        \"edits_since_checkpoint\": 0,\n        \"is_swarm_agent\": False,\n        \"plan_mode\": False,\n        \"trajectory_id\": None,\n        \"trajectory_steps\": 0,\n        \"reward_signals\": {\n            \"state_transitions\": 0,\n            \"clarify_count\": 0,\n            \"edit_count\": 0,\n        }\n    }\n\n\ndef save_workflow_state(cwd: str, state: Dict[str, Any], wm_filepath: str = None) -> bool:\n    \"\"\"Save workflow state to WORKING_MEMORY file.\n    \n    NOTE: If no wm_filepath provided, finds the most recent WORKING_MEMORY.\n    \"\"\"\n    if wm_filepath is None:\n        wm_filepath = get_most_recent_working_memory(cwd)\n    \n    if wm_filepath is None:\n        # No WORKING_MEMORY file exists - can't save state\n        # This is expected at session start before WM is created\n        return False\n    \n    new_state = state.get(\"current_state\", \"WF_INIT\")\n    return write_working_memory_state(cwd, wm_filepath, new_state)\n\n\ndef load_setup_status(cwd: str) -> Optional[Dict[str, Any]]:\n    \"\"\"Load setup completion status.\"\"\"\n    paths = get_paths(cwd)\n    setup_file = paths[\"setup_file\"]\n\n    if not os.path.exists(setup_file):\n        return None\n\n    try:\n        with open(setup_file, 'r') as f:\n            return json.load(f)\n    except (json.JSONDecodeError, IOError):\n        return None\n\n\n# Alias for backward compatibility\nload_setup_complete = load_setup_status\n\n\ndef save_setup_complete(cwd: str, status: Dict[str, Any]) -> bool:\n    \"\"\"Save setup completion status.\"\"\"\n    paths = get_paths(cwd)\n    setup_file = paths[\"setup_file\"]\n    os.makedirs(os.path.dirname(setup_file), exist_ok=True)\n    try:\n        with open(setup_file, 'w') as f:\n            json.dump(status, f, indent=2)\n        return True\n    except IOError:\n        return False\n\n\ndef get_reference_content(cwd: str, ref_name: str) -> Optional[str]:\n    \"\"\"Get content of a reference file.\"\"\"\n    paths = get_paths(cwd)\n    ref_file = os.path.join(paths[\"references_dir\"], f\"{ref_name}.md\")\n    if os.path.exists(ref_file):\n        try:\n            with open(ref_file, 'r') as f:\n                return f.read()\n        except IOError:\n            return None\n    return None\n\n\ndef is_setup_complete(cwd: str) -> bool:\n    \"\"\"Check if initial setup is complete.\"\"\"\n    status = load_setup_status(cwd)\n    return status is not None and status.get(\"complete\", False)\n\n\ndef generate_session_id() -> str:\n    \"\"\"Generate a new session ID based on timestamp.\"\"\"\n    return datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n\ndef generate_trajectory_id() -> str:\n    \"\"\"Generate a trajectory ID for RLVR learning.\"\"\"\n    import random\n    return f\"traj_{int(datetime.now().timestamp())}_{random.randint(10000, 99999)}\"\n\n\ndef create_initial_state(session_id: str = None) -> Dict[str, Any]:\n    \"\"\"Create initial workflow state.\"\"\"\n    if session_id is None:\n        session_id = generate_session_id()\n\n    return {\n        \"session_id\": session_id,\n        \"current_state\": \"UNINITIALIZED\",\n        \"previous_state\": None,\n        \"edits_since_checkpoint\": 0,\n        \"is_swarm_agent\": False,\n        \"plan_mode\": False,\n        \"plan_mode_entries\": 0,\n        \"plan_mode_reason\": None,\n        \"working_memory_file\": None,\n        \"trajectory_id\": generate_trajectory_id(),\n        \"trajectory_steps\": 0,\n        \"learning_complete\": False,\n        \"computed_reward\": None,\n        \"reward_signals\": {\n            \"skill_returns\": [],\n            \"state_transitions\": 0,\n            \"clarify_count\": 0,\n            \"edit_count\": 0,\n            \"checkpoint_compliance\": 1.0,\n            \"test_pass_rate\": None,\n            \"arch_review_pass\": None,\n            \"verify_success\": None\n        },\n        \"is_claude_flow_agent\": True\n    }\n",
        "hooks/swe_hooks/core/input.py": "\"\"\"Safe stdin reading with timeout protection.\"\"\"\n\nimport sys\nimport json\nimport select\nfrom typing import Dict, Any, Optional\n\n\ndef read_stdin_safe(timeout_seconds: float = 5.0) -> Dict[str, Any]:\n    \"\"\"Read JSON from stdin with timeout protection.\n\n    Returns empty dict if no input available or on error.\n    \"\"\"\n    try:\n        # Check if stdin has data available (Unix only)\n        if hasattr(select, 'select'):\n            ready, _, _ = select.select([sys.stdin], [], [], timeout_seconds)\n            if not ready:\n                return {}\n\n        # Read and parse JSON\n        raw = sys.stdin.read()\n        if not raw or not raw.strip():\n            return {}\n\n        return json.loads(raw)\n\n    except json.JSONDecodeError:\n        return {}\n    except Exception:\n        return {}\n\n\ndef get_input_field(input_data: Dict[str, Any], *keys: str, default: Any = None) -> Any:\n    \"\"\"Safely get nested field from input data.\"\"\"\n    current = input_data\n    for key in keys:\n        if isinstance(current, dict):\n            current = current.get(key, default)\n        else:\n            return default\n    return current if current is not None else default\n",
        "hooks/swe_hooks/core/output.py": "\"\"\"Hook output helpers following official Claude Code pattern.\n\nOutput goes to STDOUT as JSON. Exit is ALWAYS 0.\n\nFor messages:\n  - Use hookSpecificOutput.additionalContext for user-visible messages\n  \nFor blocking (PreToolUse only):\n  - Use hookSpecificOutput.permissionDecision = \"deny\"\n\"\"\"\n\nimport json\nimport sys\nfrom typing import Optional, Dict, Any\n\n\nclass HookOutput:\n    \"\"\"Builds and outputs hook responses in official format.\"\"\"\n\n    def __init__(self, event_name: str = \"PostToolUse\"):\n        \"\"\"Initialize with hook event name for proper formatting.\"\"\"\n        self.messages: list[str] = []\n        self.should_block = False\n        self.block_reason: Optional[str] = None\n        self.event_name = event_name\n\n    def add_message(self, msg: str):\n        \"\"\"Add a message to show the user.\"\"\"\n        self.messages.append(msg)\n\n    def block(self, reason: str):\n        \"\"\"Mark operation as blocked (PreToolUse only).\"\"\"\n        self.should_block = True\n        self.block_reason = reason\n        self.event_name = \"PreToolUse\"\n        self.add_message(reason)\n\n    def build(self) -> Dict[str, Any]:\n        \"\"\"Build the output dictionary using proper hookSpecificOutput format.\"\"\"\n        if not self.messages and not self.should_block:\n            return {}\n\n        result = {\n            \"hookSpecificOutput\": {\n                \"hookEventName\": self.event_name\n            }\n        }\n\n        if self.should_block:\n            result[\"hookSpecificOutput\"][\"permissionDecision\"] = \"deny\"\n            if self.block_reason:\n                result[\"hookSpecificOutput\"][\"additionalContext\"] = self.block_reason\n        elif self.messages:\n            result[\"hookSpecificOutput\"][\"additionalContext\"] = \"\\n\".join(self.messages)\n\n        return result\n\n    def output_and_exit(self):\n        \"\"\"Output JSON to stdout and exit 0.\"\"\"\n        result = self.build()\n        print(json.dumps(result), file=sys.stdout)\n        sys.exit(0)\n\n\ndef output_message(msg: str, event: str = \"PostToolUse\"):\n    \"\"\"Quick helper to output a simple message.\"\"\"\n    result = {\n        \"hookSpecificOutput\": {\n            \"hookEventName\": event,\n            \"additionalContext\": msg\n        }\n    }\n    print(json.dumps(result), file=sys.stdout)\n    sys.exit(0)\n\n\ndef output_block(reason: str):\n    \"\"\"Quick helper to block an operation (PreToolUse only).\"\"\"\n    result = {\n        \"hookSpecificOutput\": {\n            \"hookEventName\": \"PreToolUse\",\n            \"permissionDecision\": \"deny\",\n            \"additionalContext\": reason\n        }\n    }\n    print(json.dumps(result), file=sys.stdout)\n    sys.exit(0)\n\n\ndef output_empty():\n    \"\"\"Output empty result (allow operation silently).\"\"\"\n    print(json.dumps({}), file=sys.stdout)\n    sys.exit(0)\n\n\ndef output_status(status: str, event: str = \"PostToolUse\"):\n    \"\"\"Output a concise one-line status message.\n\n    Use this instead of output_empty() when you want to inform\n    the user what happened without being verbose.\n\n    Examples:\n        output_status(\"WM: edit #3 tracked\")\n        output_status(\"WM: state unchanged\")\n        output_status(\"‚úì transition logged\")\n    \"\"\"\n    result = {\n        \"hookSpecificOutput\": {\n            \"hookEventName\": event,\n            \"additionalContext\": status\n        }\n    }\n    print(json.dumps(result), file=sys.stdout)\n    sys.exit(0)\n\n\ndef output_error(error: str, event: str = \"PostToolUse\"):\n    \"\"\"Output error as message (non-blocking).\"\"\"\n    result = {\n        \"hookSpecificOutput\": {\n            \"hookEventName\": event,\n            \"additionalContext\": f\"SWE Hook Error: {error}\"\n        }\n    }\n    print(json.dumps(result), file=sys.stdout)\n    sys.exit(0)\n",
        "hooks/swe_hooks/core/session.py": "\"\"\"Session ID utilities for SWE hooks.\n\nCentralizes session ID extraction and working memory session matching.\n\"\"\"\n\nimport os\nimport re\nimport glob\nfrom typing import Optional, Tuple\n\n\n# =============================================================================\n# Project Root Resolution (CD-immune)\n# =============================================================================\n\n\ndef get_project_root() -> str:\n    \"\"\"Get the project root directory reliably, immune to cd commands.\n\n    Uses CLAUDE_PROJECT_DIR environment variable set by Claude Code.\n    This is the official, documented way to get the project root.\n\n    Returns:\n        Absolute path to the project root directory\n    \"\"\"\n    # Primary: CLAUDE_PROJECT_DIR - set by Claude Code, never changes\n    project_dir = os.environ.get('CLAUDE_PROJECT_DIR', '')\n    if project_dir:\n        return project_dir\n\n    # Fallback: walk up from cwd to find .serena (less reliable after cd)\n    return find_project_root(os.getcwd())\n\n\ndef extract_session_id(transcript_path: str) -> Optional[str]:\n    \"\"\"Extract 8-char session ID from transcript_path UUID.\n\n    Args:\n        transcript_path: Path like ~/.claude/projects/.../00893aaf-19fa-41d2-8238-13269b9b3ca0.jsonl\n\n    Returns:\n        First 8 characters of the UUID, or None if not found\n    \"\"\"\n    if not transcript_path:\n        return None\n    uuid_match = re.search(\n        r'([a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12})',\n        transcript_path\n    )\n    if uuid_match:\n        return uuid_match.group(1)[:8]\n    return None\n\n\ndef find_project_root(start_dir: str) -> str:\n    \"\"\"Find the MAIN project root by walking up directory tree.\n\n    Skips any .serena folders inside .claude/plugins/ (nested plugin repos).\n    Returns the highest .serena folder in the tree (main project).\n    \"\"\"\n    current = os.path.abspath(start_dir)\n    main_project_root = None\n\n    while current != os.path.dirname(current):  # Stop at filesystem root\n        serena_dir = os.path.join(current, '.serena')\n        if os.path.isdir(serena_dir):\n            # Only accept if NOT inside a plugin directory\n            if '/.claude/plugins/' not in current and '\\\\.claude\\\\plugins\\\\' not in current:\n                # Keep updating - we want the HIGHEST in the tree (main project)\n                main_project_root = current\n        current = os.path.dirname(current)\n\n    return main_project_root if main_project_root else start_dir\n\n\ndef get_serena_memories_dir(cwd: str = None) -> str:\n    \"\"\"Get the .serena/memories directory path for WM files.\n\n    Args:\n        cwd: Ignored - kept for backward compatibility. Uses get_project_root() instead.\n    \"\"\"\n    project_root = get_project_root()\n    return os.path.join(project_root, '.serena', 'memories')\n\n\ndef find_working_memory_for_session(cwd: str, session_id: Optional[str]) -> Optional[str]:\n    \"\"\"Find the working memory file for a specific session.\n\n    Args:\n        cwd: Working directory\n        session_id: 8-char session ID\n\n    Returns:\n        Full path to the working memory file, or None if not found\n    \"\"\"\n    memories_dir = get_serena_memories_dir(cwd)\n    if not os.path.exists(memories_dir):\n        return None\n\n    if session_id:\n        # Look for WM_<session_id>_* files specifically\n        pattern = os.path.join(memories_dir, f'WM_{session_id}_*.md')\n        working_memories = glob.glob(pattern)\n        if working_memories:\n            # Return most recent by modification time\n            return max(working_memories, key=os.path.getmtime)\n\n    return None\n\n\ndef validate_working_memory_session(filepath: str, session_id: Optional[str]) -> bool:\n    \"\"\"Validate that a working memory file belongs to the specified session.\n\n    Checks both filename and content for session ID.\n\n    Args:\n        filepath: Path to the working memory file\n        session_id: Expected session ID\n\n    Returns:\n        True if the working memory belongs to this session\n    \"\"\"\n    if not filepath or not os.path.exists(filepath):\n        return False\n\n    if not session_id:\n        return True  # No session ID to validate against\n\n    # Check filename first (faster)\n    filename = os.path.basename(filepath)\n    if session_id in filename:\n        return True\n\n    # Check content for Session ID field\n    try:\n        with open(filepath, 'r') as f:\n            content = f.read(2000)  # Only need to check first part\n        session_match = re.search(r'\\*\\*Session ID\\*\\*:\\s*(\\S+)', content)\n        if session_match and session_match.group(1) == session_id:\n            return True\n    except IOError:\n        pass\n\n    return False\n\n\ndef get_session_context(input_data: dict, cwd: str) -> Tuple[Optional[str], Optional[str]]:\n    \"\"\"Get session ID and working memory path from hook input.\n\n    Args:\n        input_data: Hook input data with transcript_path\n        cwd: Working directory\n\n    Returns:\n        Tuple of (session_id, wm_filepath) - either may be None\n    \"\"\"\n    transcript_path = input_data.get('transcript_path', '')\n    session_id = extract_session_id(transcript_path)\n    wm_filepath = find_working_memory_for_session(cwd, session_id)\n    return session_id, wm_filepath\n",
        "hooks/swe_hooks/core/state_manager.py": "\"\"\"State machine manager for workflow transitions.\n\nState is stored in WM files (session-isolated), NOT in a global state file.\nThis allows multiple concurrent sessions without state conflicts.\n\"\"\"\n\nimport json\nimport os\nfrom typing import Dict, Any, Optional, Tuple, List\nfrom .config import (\n    load_workflow_state, save_workflow_state,\n    get_most_recent_working_memory, get_working_memory_filename,\n    read_working_memory_state, write_working_memory_state,\n    persist_edit_to_wm, check_wm_staleness, get_wm_edit_count,\n    reset_wm_edit_tracking, get_project_root\n)\nfrom .session import (\n    extract_session_id, find_working_memory_for_session,\n    validate_working_memory_session\n)\n\n\n# Cache for transition matrix\n_transition_matrix_cache = None\n\n\ndef load_transition_matrix() -> Dict[str, List[str]]:\n    \"\"\"Load the transition matrix from states.json.\n\n    Returns:\n        Dict mapping state names to list of valid next states.\n    \"\"\"\n    global _transition_matrix_cache\n\n    if _transition_matrix_cache is not None:\n        return _transition_matrix_cache\n\n    # Try to find states.json\n    plugin_root = os.environ.get('CLAUDE_PLUGIN_ROOT', '')\n    if plugin_root:\n        states_file = os.path.join(plugin_root, 'state-machine', 'states.json')\n    else:\n        project_root = get_project_root()\n        states_file = os.path.join(\n            project_root, '.claude', 'plugins', 'serena-workflow-engine',\n            'state-machine', 'states.json'\n        )\n\n    try:\n        with open(states_file, 'r') as f:\n            data = json.load(f)\n            _transition_matrix_cache = data.get('transitionMatrix', {})\n            return _transition_matrix_cache\n    except (IOError, json.JSONDecodeError):\n        # Return permissive matrix if file not found\n        return {}\n\n\ndef is_valid_transition(from_state: str, to_state: str) -> Tuple[bool, str]:\n    \"\"\"Check if a state transition is valid.\n\n    Args:\n        from_state: Current state\n        to_state: Target state\n\n    Returns:\n        Tuple of (is_valid, error_message)\n    \"\"\"\n    matrix = load_transition_matrix()\n\n    # If no matrix loaded, allow all transitions (fail open)\n    if not matrix:\n        return True, \"\"\n\n    # Special case: WF_INIT can go anywhere (session start)\n    if from_state in (\"WF_INIT\", \"UNINITIALIZED\", \"SessionStart\"):\n        return True, \"\"\n\n    # Special case: WF_CLARIFY can return to caller (any state)\n    if from_state == \"WF_CLARIFY\":\n        return True, \"\"\n\n    # Check if from_state exists in matrix\n    if from_state not in matrix:\n        # Unknown state - allow transition but warn\n        return True, f\"Warning: Unknown state {from_state}\"\n\n    valid_targets = matrix[from_state]\n\n    # Check if to_state is valid\n    if to_state in valid_targets:\n        return True, \"\"\n\n    # Invalid transition\n    return False, (\n        f\"BLOCKED: Invalid transition {from_state} ‚Üí {to_state}. \"\n        f\"Valid next states from {from_state}: {', '.join(valid_targets)}\"\n    )\n\n\n# State icons for display\nSTATE_ICONS = {\n    \"WF_INIT\": \"üé¨\",\n    \"WF_START\": \"üöÄ\",\n    \"WF_ONBOARD\": \"üìö\",\n    \"WF_CLASSIFY\": \"üè∑Ô∏è\",\n    \"WF_LOAD_FEATURE\": \"üìÇ\",\n    \"WF_RESEARCH\": \"üîç\",\n    \"WF_DETECT_REQ\": \"üéØ\",\n    \"WF_REQUIREMENT\": \"üìã\",\n    \"WF_CLARIFY\": \"‚ùì\",\n    \"WF_PLAN_ARCHITECTURE\": \"üèóÔ∏è\",\n    \"WF_ARCH_REVIEW\": \"üî¨\",\n    \"WF_EXECUTE\": \"‚ö°\",\n    \"WF_CHECKPOINT\": \"üíæ\",\n    \"WF_VERIFY\": \"‚úÖ\",\n    \"WF_UPDATE_MEMORY\": \"üìù\",\n    \"WF_DEBUG_TDD\": \"üêõ\",\n    \"WF_CONTINUE\": \"‚û°Ô∏è\",\n    \"WF_SWARM_ORCHESTRATE\": \"üêù\",\n    \"WF_ASK_PERMISSION\": \"üîê\",\n    \"WF_CLEANUP\": \"üßπ\",\n    \"WF_DONE\": \"üéâ\",\n    \"WF_INITIAL_SETUP\": \"‚öôÔ∏è\",\n}\n\n# States that require plan mode\nPLAN_MODE_STATES = {\n    \"WF_PLAN_ARCHITECTURE\",\n    \"WF_ARCH_REVIEW\",\n}\n\n# States that exit plan mode\nEXIT_PLAN_MODE_STATES = {\n    \"WF_EXECUTE\",\n    \"WF_CHECKPOINT\",\n    \"WF_VERIFY\",\n    \"WF_DEBUG_TDD\",\n}\n\n\nclass StateManager:\n    \"\"\"Manages workflow state transitions.\n\n    State is stored in WM files, allowing multiple concurrent sessions.\n    Each session has its own WM file with embedded workflow context.\n    \"\"\"\n\n    def __init__(self, cwd: str, wm_filename: str = None, session_id: str = None):\n        \"\"\"Initialize state manager.\n\n        Args:\n            cwd: Working directory\n            wm_filename: Optional specific WM filename (without .md)\n                        If None, finds working memory for session_id\n            session_id: Optional session ID for session isolation.\n                       If provided, only uses working memory matching this session.\n        \"\"\"\n        self.cwd = cwd\n        self.wm_filename = wm_filename\n        self.wm_filepath = None\n        self.session_id = session_id\n\n        # Try to load state from WM with session isolation\n        state_data = None\n        filepath = None\n\n        if wm_filename:\n            # Specific filename provided - use it\n            state_data, filepath = read_working_memory_state(cwd, wm_filename)\n        elif session_id:\n            # Session ID provided - find working memory for this session only\n            filepath = find_working_memory_for_session(cwd, session_id)\n            if filepath:\n                state_data, filepath = read_working_memory_state(cwd, filepath.replace('.md', '').split('/')[-1])\n        else:\n            # No session context - fall back to most recent (legacy behavior)\n            state_data, filepath = read_working_memory_state(cwd)\n\n        # Validate session ownership if session_id provided\n        if filepath and session_id and not validate_working_memory_session(filepath, session_id):\n            # Working memory doesn't belong to this session - don't use it\n            state_data = None\n            filepath = None\n\n        if state_data:\n            self.wm_filepath = filepath\n            self.wm_filename = filepath.replace('.md', '').split('/')[-1] if filepath else None\n            # Convert to internal state format\n            self.state = {\n                \"current_state\": state_data.get(\"current_state\", \"WF_INIT\"),\n                \"previous_state\": None,\n                \"session_id\": state_data.get(\"session_id\") or session_id,\n                \"working_memory_file\": self.wm_filename,\n                \"feature_keys\": state_data.get(\"feature_keys\", []),\n                \"edits_since_checkpoint\": 0,\n                \"plan_mode\": state_data.get(\"current_state\") in PLAN_MODE_STATES,\n                \"reward_signals\": {\"state_transitions\": 0, \"edit_count\": 0},\n            }\n        else:\n            # No WM found for this session - use minimal state\n            self.state = {\n                \"current_state\": \"WF_INIT\",\n                \"previous_state\": None,\n                \"session_id\": session_id,\n                \"working_memory_file\": None,\n                \"edits_since_checkpoint\": 0,\n                \"plan_mode\": False,\n                \"reward_signals\": {\"state_transitions\": 0, \"edit_count\": 0},\n            }\n\n    def get_current_state(self) -> str:\n        \"\"\"Get current workflow state.\"\"\"\n        return self.state.get(\"current_state\", \"UNINITIALIZED\")\n\n    def get_icon(self, state: str = None) -> str:\n        \"\"\"Get icon for state.\"\"\"\n        if state is None:\n            state = self.get_current_state()\n        return STATE_ICONS.get(state, \"üìç\")\n\n    def transition_to(self, new_state: str, force: bool = False) -> Tuple[bool, str]:\n        \"\"\"Transition to a new state. Returns (success, message).\n\n        Validates the transition against the state machine's transition matrix.\n        State is persisted to the WM file if one exists.\n\n        Args:\n            new_state: The target state to transition to\n            force: If True, skip validation (use with caution)\n\n        Returns:\n            Tuple of (success, message). If validation fails, success=False\n            and message contains the blocking reason.\n        \"\"\"\n        old_state = self.get_current_state()\n\n        # Validate the transition unless forced\n        if not force:\n            is_valid, error_msg = is_valid_transition(old_state, new_state)\n            if not is_valid:\n                return False, error_msg\n\n        # Update in-memory state\n        self.state[\"previous_state\"] = old_state\n        self.state[\"current_state\"] = new_state\n        self.state[\"reward_signals\"][\"state_transitions\"] = \\\n            self.state[\"reward_signals\"].get(\"state_transitions\", 0) + 1\n\n        # Handle plan mode\n        if new_state in PLAN_MODE_STATES and not self.state.get(\"plan_mode\"):\n            self.state[\"plan_mode\"] = True\n            self.state[\"plan_mode_entries\"] = self.state.get(\"plan_mode_entries\", 0) + 1\n            self.state[\"plan_mode_reason\"] = new_state\n        elif new_state in EXIT_PLAN_MODE_STATES and self.state.get(\"plan_mode\"):\n            self.state[\"plan_mode\"] = False\n            self.state[\"plan_mode_reason\"] = None\n\n        # Save state to WM if it exists\n        if self.wm_filepath:\n            if write_working_memory_state(self.cwd, self.wm_filepath, new_state):\n                return True, f\"Transition: {old_state} ‚Üí {new_state}\"\n            else:\n                return False, f\"Failed to save state transition to WM\"\n        else:\n            # No WM yet - state change is in-memory only\n            # This is expected at session start before WM is created\n            return True, f\"Transition: {old_state} ‚Üí {new_state} (in-memory, no WM yet)\"\n\n    def increment_edits(self, edited_file: str = None) -> int:\n        \"\"\"Increment edit counter and persist to WM file.\n        \n        Edit counts are now persisted to WM for staleness detection.\n        \n        Args:\n            edited_file: Optional path to the file that was edited\n        \n        Returns:\n            New edit count\n        \"\"\"\n        self.state[\"edits_since_checkpoint\"] = \\\n            self.state.get(\"edits_since_checkpoint\", 0) + 1\n        self.state[\"reward_signals\"][\"edit_count\"] = \\\n            self.state[\"reward_signals\"].get(\"edit_count\", 0) + 1\n        \n        # Persist to WM file if available\n        if self.wm_filepath:\n            success, wm_count = persist_edit_to_wm(self.cwd, self.wm_filepath, edited_file)\n            if success:\n                # Use the persisted count as source of truth\n                self.state[\"edits_since_checkpoint\"] = wm_count\n        \n        return self.state[\"edits_since_checkpoint\"]\n\n    def reset_edit_counter(self):\n        \"\"\"Reset edit counter after checkpoint (user updated WM progress).\"\"\"\n        self.state[\"edits_since_checkpoint\"] = 0\n        \n        # Reset in WM file if available\n        if self.wm_filepath:\n            try:\n                with open(self.wm_filepath, 'r') as f:\n                    content = f.read()\n                updated_content = reset_wm_edit_tracking(content)\n                with open(self.wm_filepath, 'w') as f:\n                    f.write(updated_content)\n            except IOError:\n                pass  # Silent fail - in-memory reset still works\n\n    def should_checkpoint(self, threshold: int = 3) -> bool:\n        \"\"\"Check if checkpoint is needed based on edit count.\"\"\"\n        return self.state.get(\"edits_since_checkpoint\", 0) >= threshold\n\n    def set_working_memory(self, filename: str):\n        \"\"\"Set the active working memory file and reload state from it.\"\"\"\n        self.wm_filename = filename\n        paths_module = __import__('swe_hooks.core.config', fromlist=['get_paths'])\n        paths = paths_module.get_paths(self.cwd)\n        self.wm_filepath = f\"{paths['serena_memories']}/{filename}.md\"\n        self.state[\"working_memory_file\"] = filename\n        \n        # Reload state from the new WM file\n        state_data, _ = read_working_memory_state(self.cwd, filename)\n        if state_data:\n            self.state[\"current_state\"] = state_data.get(\"current_state\", self.state[\"current_state\"])\n            self.state[\"session_id\"] = state_data.get(\"session_id\")\n            self.state[\"feature_keys\"] = state_data.get(\"feature_keys\", [])\n\n    def get_working_memory(self) -> Optional[str]:\n        \"\"\"Get the active working memory filename.\"\"\"\n        return self.wm_filename or self.state.get(\"working_memory_file\")\n\n    def is_plan_mode(self) -> bool:\n        \"\"\"Check if currently in plan mode.\"\"\"\n        return self.state.get(\"plan_mode\", False)\n\n    def increment_trajectory_step(self):\n        \"\"\"Increment trajectory step counter for RLVR.\n        \n        Trajectory steps are kept in-memory only - they're session-local.\n        \"\"\"\n        self.state[\"trajectory_steps\"] = self.state.get(\"trajectory_steps\", 0) + 1\n        # Note: Not persisting - trajectory steps are session-local\n\n    def save(self) -> bool:\n        \"\"\"Save current state to WM file.\"\"\"\n        if self.wm_filepath:\n            return write_working_memory_state(\n                self.cwd, \n                self.wm_filepath, \n                self.state.get(\"current_state\", \"WF_INIT\")\n            )\n        return False  # No WM to save to\n",
        "hooks/swe_hooks/core/wm_validator.py": "\"\"\"Working Memory format validator.\n\nValidates WM content against REF_WM specs:\n- Multi-section updates (rejects single-field state edits)\n- Required sections check\n- Naming convention enforcement\n- Session ID validation\n\"\"\"\n\nimport re\nfrom typing import Tuple, Optional, List, Set\n\n\nclass WMFormatValidator:\n    \"\"\"Validates Working Memory format against REF_WM specs.\"\"\"\n\n    # Required sections in a valid WM file\n    REQUIRED_SECTIONS = [\n        'Workflow Context',\n        'Current Task',\n    ]\n\n    # Optional but recommended sections\n    RECOMMENDED_SECTIONS = [\n        'Progress',\n        'Previous Task',\n    ]\n\n    # Fields that indicate state-only changes (anti-pattern if changed alone)\n    # These patterns match with or without markdown bold formatting\n    STATE_FIELD_PATTERNS = [\n        r'Current State',\n        r'Calling Step',\n        r'Return Step',\n        r'Invocation Mode',\n    ]\n\n    # Naming pattern: WM_<SESSION_ID>_<descriptor>.md\n    # Case-sensitive per REF_WM spec\n    FILENAME_PATTERN = re.compile(\n        r'^WM_([a-f0-9]{8})_([a-zA-Z0-9_]+)(?:\\.md)?$'\n    )\n\n    def validate_filename(self, filename: str) -> Tuple[bool, str, Optional[str]]:\n        \"\"\"Validate WM filename format.\n\n        Args:\n            filename: The filename to validate (with or without .md extension)\n\n        Returns:\n            Tuple of (is_valid, error_message, extracted_session_id)\n        \"\"\"\n        match = self.FILENAME_PATTERN.match(filename)\n        if not match:\n            return False, f\"Invalid filename format. Expected: WM_<8-char-session>_<descriptor>.md\", None\n\n        session_id = match.group(1)\n        descriptor = match.group(2)\n\n        # Validate descriptor (2-4 words, snake_case)\n        words = descriptor.split('_')\n        if len(words) < 1 or len(words) > 5:\n            return False, f\"Descriptor should be 1-5 words in snake_case, got: {descriptor}\", session_id\n\n        return True, \"\", session_id\n\n    def validate_content(self, content: str) -> Tuple[bool, List[str]]:\n        \"\"\"Validate WM content has required sections.\n\n        Args:\n            content: The full WM content\n\n        Returns:\n            Tuple of (is_valid, list_of_errors)\n        \"\"\"\n        errors = []\n\n        for section in self.REQUIRED_SECTIONS:\n            # Look for ## Section or **Section** patterns\n            section_patterns = [\n                f'## {section}',\n                f'**{section}**',\n                f'### {section}',\n            ]\n            found = any(pattern in content for pattern in section_patterns)\n            if not found:\n                errors.append(f\"Missing required section: {section}\")\n\n        # Check for Workflow Context fields (handle markdown bold formatting)\n        if '## Workflow Context' in content or '### Workflow Context' in content:\n            # Look for Current State with optional markdown formatting\n            if not re.search(r'Current State\\*?\\*?:', content):\n                errors.append(\"Workflow Context missing 'Current State:' field\")\n            # Look for Session ID with optional markdown formatting\n            if not re.search(r'Session(?:\\s+ID)?\\*?\\*?:', content):\n                errors.append(\"Workflow Context missing 'Session ID:' field\")\n\n        return len(errors) == 0, errors\n\n    def detect_single_field_edit(self, old_content: str, new_content: str) -> Tuple[bool, str]:\n        \"\"\"Detect anti-pattern: single-field state edits.\n\n        Per REF_WM: \"SINGLE-FIELD STATE EDIT = WORKFLOW VIOLATION\"\n\n        Args:\n            old_content: Previous WM content\n            new_content: New WM content\n\n        Returns:\n            Tuple of (is_violation, violation_description)\n        \"\"\"\n        if not old_content or not new_content:\n            return False, \"\"\n\n        old_lines = old_content.strip().split('\\n')\n        new_lines = new_content.strip().split('\\n')\n\n        # Find changed lines\n        old_set = set(old_lines)\n        new_set = set(new_lines)\n\n        removed = old_set - new_set\n        added = new_set - old_set\n\n        # Filter out empty lines and whitespace-only changes\n        removed = {line for line in removed if line.strip()}\n        added = {line for line in added if line.strip()}\n\n        total_changes = len(removed) + len(added)\n\n        # If very few lines changed, check if they're all state fields\n        if total_changes <= 4:\n            all_changes = removed | added\n            state_field_changes = 0\n\n            for line in all_changes:\n                line_stripped = line.strip()\n                if any(field in line_stripped for field in self.STATE_FIELD_PATTERNS):\n                    state_field_changes += 1\n\n            # If ALL changes are state field changes, it's a violation\n            if state_field_changes > 0 and state_field_changes == len(all_changes):\n                return True, f\"Single-field state edit detected. Changed only: {', '.join(self.STATE_FIELD_PATTERNS[:state_field_changes])}\"\n\n        return False, \"\"\n\n    def validate_session_ownership(self, content: str, expected_session_id: str) -> Tuple[bool, str]:\n        \"\"\"Validate that content belongs to the expected session.\n\n        Args:\n            content: WM content to check\n            expected_session_id: The session ID that should own this WM\n\n        Returns:\n            Tuple of (is_valid, error_message)\n        \"\"\"\n        # Extract session ID from content\n        session_match = re.search(r'Session(?:\\s+ID)?:\\s*([a-f0-9]{8})', content, re.IGNORECASE)\n        if not session_match:\n            return False, \"No session ID found in content\"\n\n        content_session = session_match.group(1).lower()\n        expected_lower = expected_session_id.lower()\n\n        if content_session != expected_lower:\n            return False, f\"Session mismatch: content has {content_session}, expected {expected_lower}\"\n\n        return True, \"\"\n\n    def get_sections_modified(self, old_content: str, new_content: str) -> Set[str]:\n        \"\"\"Identify which sections were modified between old and new content.\n\n        Args:\n            old_content: Previous WM content\n            new_content: New WM content\n\n        Returns:\n            Set of section names that were modified\n        \"\"\"\n        modified = set()\n\n        # Define section markers\n        section_markers = [\n            ('Workflow Context', r'##\\s*Workflow Context'),\n            ('Current Task', r'##\\s*Current Task'),\n            ('Progress', r'###?\\s*Progress'),\n            ('Previous Task', r'##\\s*Previous Task'),\n            ('Files', r'\\*\\*Files'),\n            ('Context', r'###?\\s*Context'),\n            ('Artifacts', r'\\*\\*Artifacts'),\n        ]\n\n        for section_name, pattern in section_markers:\n            # Extract section content from both\n            old_section = self._extract_section(old_content, pattern)\n            new_section = self._extract_section(new_content, pattern)\n\n            if old_section != new_section:\n                modified.add(section_name)\n\n        return modified\n\n    def _extract_section(self, content: str, section_pattern: str) -> str:\n        \"\"\"Extract content of a section from WM content.\"\"\"\n        if not content:\n            return \"\"\n\n        # Find section start\n        match = re.search(section_pattern, content, re.IGNORECASE)\n        if not match:\n            return \"\"\n\n        start = match.end()\n\n        # Find next section (## marker)\n        next_section = re.search(r'\\n##\\s', content[start:])\n        if next_section:\n            end = start + next_section.start()\n        else:\n            end = len(content)\n\n        return content[start:end].strip()\n\n\n# Singleton instance for reuse\n_validator: Optional[WMFormatValidator] = None\n\n\ndef get_validator() -> WMFormatValidator:\n    \"\"\"Get or create singleton validator instance.\"\"\"\n    global _validator\n    if _validator is None:\n        _validator = WMFormatValidator()\n    return _validator\n",
        "hooks/swe_hooks/core/wm_writer_daemon.py": "\"\"\"Background writer for async Working Memory file operations.\n\nProvides non-blocking WM writes by queueing operations to a daemon thread.\nValidates format against REF_WM specs before writing.\n\"\"\"\n\nimport queue\nimport threading\nimport time\nimport sys\nimport os\nfrom dataclasses import dataclass, field\nfrom typing import Literal, Optional, List, Callable\nfrom pathlib import Path\n\ntry:\n    from .wm_validator import WMFormatValidator, get_validator\nexcept ImportError:\n    # Fallback for direct execution\n    from wm_validator import WMFormatValidator, get_validator\n\n\n@dataclass\nclass WriteOperation:\n    \"\"\"Represents a queued write operation.\"\"\"\n    filepath: str\n    content: str\n    operation_type: Literal['full_write', 'state_update', 'edit_tracking', 'transition_log', 'append']\n    timestamp: float = field(default_factory=time.time)\n    validate: bool = True\n    session_id: Optional[str] = None\n    old_content: Optional[str] = None  # For anti-pattern detection\n    callback: Optional[Callable[[bool, str], None]] = None  # Optional completion callback\n\n\nclass WMBackgroundWriter:\n    \"\"\"Background thread for async Working Memory writes.\n\n    Features:\n    - Non-blocking queue-based writes\n    - Format validation before writing\n    - Write coalescing for rapid updates\n    - Graceful error handling\n    - Auto-restart on thread failure\n    \"\"\"\n\n    def __init__(self, max_queue_size: int = 100, coalesce_window_ms: int = 50):\n        \"\"\"Initialize background writer.\n\n        Args:\n            max_queue_size: Maximum pending operations (oldest dropped on overflow)\n            coalesce_window_ms: Time window to batch writes to same file\n        \"\"\"\n        self._queue: queue.Queue = queue.Queue(maxsize=max_queue_size)\n        self._thread: Optional[threading.Thread] = None\n        self._running = False\n        self._validator = get_validator()\n        self._coalesce_window = coalesce_window_ms / 1000.0\n        self._lock = threading.Lock()\n        self._stats = {\n            'queued': 0,\n            'written': 0,\n            'failed': 0,\n            'coalesced': 0,\n            'validation_rejected': 0,\n        }\n\n    def start(self) -> bool:\n        \"\"\"Start the background writer thread.\n\n        Returns:\n            True if started successfully, False if already running\n        \"\"\"\n        with self._lock:\n            if self._running and self._thread and self._thread.is_alive():\n                return False\n\n            self._running = True\n            self._thread = threading.Thread(\n                target=self._writer_loop,\n                name=\"WMBackgroundWriter\",\n                daemon=True  # Dies with main process\n            )\n            self._thread.start()\n            return True\n\n    def stop(self, timeout: float = 2.0) -> bool:\n        \"\"\"Stop the background writer gracefully.\n\n        Args:\n            timeout: Max seconds to wait for pending writes\n\n        Returns:\n            True if stopped cleanly, False if timed out\n        \"\"\"\n        self._running = False\n\n        if self._thread and self._thread.is_alive():\n            # Signal thread to stop by putting None\n            try:\n                self._queue.put(None, timeout=0.1)\n            except queue.Full:\n                pass\n\n            self._thread.join(timeout=timeout)\n            return not self._thread.is_alive()\n\n        return True\n\n    def queue_write(self, operation: WriteOperation) -> bool:\n        \"\"\"Queue a write operation for async execution.\n\n        Args:\n            operation: The write operation to queue\n\n        Returns:\n            True if queued successfully, False if queue full (oldest dropped)\n        \"\"\"\n        # Auto-start if not running\n        if not self._running or not self._thread or not self._thread.is_alive():\n            self.start()\n\n        try:\n            self._queue.put_nowait(operation)\n            self._stats['queued'] += 1\n            return True\n        except queue.Full:\n            # Drop oldest and retry\n            try:\n                self._queue.get_nowait()\n                self._queue.put_nowait(operation)\n                self._stats['queued'] += 1\n                return True\n            except (queue.Empty, queue.Full):\n                return False\n\n    def _writer_loop(self):\n        \"\"\"Main writer loop - processes queue until stopped.\"\"\"\n        pending: List[WriteOperation] = []\n\n        while self._running:\n            try:\n                # Wait for operation with timeout\n                try:\n                    op = self._queue.get(timeout=0.1)\n                except queue.Empty:\n                    # Process any pending coalesced writes\n                    if pending:\n                        self._process_coalesced(pending)\n                        pending = []\n                    continue\n\n                # None signals shutdown\n                if op is None:\n                    break\n\n                # Check for coalescing opportunity\n                if pending and pending[-1].filepath == op.filepath:\n                    # Same file - coalesce by keeping latest\n                    pending[-1] = op\n                    self._stats['coalesced'] += 1\n                else:\n                    # Different file - flush pending and add new\n                    if pending:\n                        self._process_coalesced(pending)\n                        pending = []\n                    pending.append(op)\n\n                # If we've waited long enough, flush\n                if pending and (time.time() - pending[0].timestamp) > self._coalesce_window:\n                    self._process_coalesced(pending)\n                    pending = []\n\n            except Exception as e:\n                self._log_error(f\"Writer loop error: {e}\")\n                self._stats['failed'] += 1\n\n        # Flush remaining on shutdown\n        if pending:\n            self._process_coalesced(pending)\n\n    def _process_coalesced(self, operations: List[WriteOperation]):\n        \"\"\"Process a batch of coalesced operations.\"\"\"\n        for op in operations:\n            self._execute_write(op)\n\n    def _execute_write(self, op: WriteOperation):\n        \"\"\"Execute a single write operation with validation.\"\"\"\n        success = False\n        error_msg = \"\"\n\n        try:\n            # Validate if requested\n            if op.validate:\n                # Check for anti-pattern (single-field state edit)\n                if op.old_content and op.operation_type == 'state_update':\n                    is_violation, violation_msg = self._validator.detect_single_field_edit(\n                        op.old_content, op.content\n                    )\n                    if is_violation:\n                        self._stats['validation_rejected'] += 1\n                        error_msg = f\"Validation rejected: {violation_msg}\"\n                        self._log_error(error_msg)\n                        if op.callback:\n                            op.callback(False, error_msg)\n                        return\n\n                # Validate content structure\n                is_valid, errors = self._validator.validate_content(op.content)\n                if not is_valid and op.operation_type == 'full_write':\n                    # Only reject full writes for missing sections\n                    # Partial updates (edit_tracking, transition_log) can skip this\n                    self._log_error(f\"Validation warnings: {errors}\")\n\n                # Validate session ownership if session_id provided\n                if op.session_id:\n                    is_valid, error = self._validator.validate_session_ownership(\n                        op.content, op.session_id\n                    )\n                    if not is_valid:\n                        self._stats['validation_rejected'] += 1\n                        error_msg = f\"Session validation failed: {error}\"\n                        self._log_error(error_msg)\n                        if op.callback:\n                            op.callback(False, error_msg)\n                        return\n\n            # Ensure directory exists\n            filepath = Path(op.filepath)\n            filepath.parent.mkdir(parents=True, exist_ok=True)\n\n            # Write the file\n            with open(filepath, 'w', encoding='utf-8') as f:\n                f.write(op.content)\n\n            self._stats['written'] += 1\n            success = True\n\n        except IOError as e:\n            self._stats['failed'] += 1\n            error_msg = f\"IO error writing {op.filepath}: {e}\"\n            self._log_error(error_msg)\n        except Exception as e:\n            self._stats['failed'] += 1\n            error_msg = f\"Error writing {op.filepath}: {e}\"\n            self._log_error(error_msg)\n\n        # Call completion callback if provided\n        if op.callback:\n            op.callback(success, error_msg)\n\n    def _log_error(self, message: str):\n        \"\"\"Log error to stderr.\"\"\"\n        print(f\"[WMBackgroundWriter] {message}\", file=sys.stderr)\n\n    def get_stats(self) -> dict:\n        \"\"\"Get writer statistics.\"\"\"\n        return dict(self._stats)\n\n    def is_running(self) -> bool:\n        \"\"\"Check if writer thread is running.\"\"\"\n        return self._running and self._thread is not None and self._thread.is_alive()\n\n    def pending_count(self) -> int:\n        \"\"\"Get number of pending writes in queue.\"\"\"\n        return self._queue.qsize()\n\n\n# Singleton instance\n_wm_writer: Optional[WMBackgroundWriter] = None\n_writer_lock = threading.Lock()\n\n\ndef get_wm_writer() -> WMBackgroundWriter:\n    \"\"\"Get or create singleton background writer.\"\"\"\n    global _wm_writer\n    with _writer_lock:\n        if _wm_writer is None:\n            _wm_writer = WMBackgroundWriter()\n            _wm_writer.start()\n        elif not _wm_writer.is_running():\n            _wm_writer.start()\n        return _wm_writer\n\n\ndef async_wm_write(\n    filepath: str,\n    content: str,\n    operation_type: Literal['full_write', 'state_update', 'edit_tracking', 'transition_log', 'append'] = 'full_write',\n    validate: bool = True,\n    session_id: Optional[str] = None,\n    old_content: Optional[str] = None,\n    callback: Optional[Callable[[bool, str], None]] = None\n) -> bool:\n    \"\"\"Queue an async WM write operation.\n\n    This function returns immediately - the actual write happens in background.\n\n    Args:\n        filepath: Path to the WM file\n        content: Content to write\n        operation_type: Type of operation for validation logic\n        validate: Whether to validate format before writing\n        session_id: Optional session ID for ownership validation\n        old_content: Previous content for anti-pattern detection\n        callback: Optional callback(success, error_msg) called after write\n\n    Returns:\n        True if queued successfully, False if queue full\n    \"\"\"\n    writer = get_wm_writer()\n    op = WriteOperation(\n        filepath=filepath,\n        content=content,\n        operation_type=operation_type,\n        validate=validate,\n        session_id=session_id,\n        old_content=old_content,\n        callback=callback,\n    )\n    return writer.queue_write(op)\n\n\ndef async_wm_append(\n    filepath: str,\n    append_content: str,\n    session_id: Optional[str] = None\n) -> bool:\n    \"\"\"Queue an async append operation to a WM file.\n\n    Reads current content and appends new content.\n\n    Args:\n        filepath: Path to the WM file\n        append_content: Content to append\n        session_id: Optional session ID for validation\n\n    Returns:\n        True if queued successfully\n    \"\"\"\n    # Read current content synchronously (small files, fast)\n    current_content = \"\"\n    try:\n        if os.path.exists(filepath):\n            with open(filepath, 'r', encoding='utf-8') as f:\n                current_content = f.read()\n    except IOError:\n        pass\n\n    new_content = current_content + append_content\n\n    return async_wm_write(\n        filepath=filepath,\n        content=new_content,\n        operation_type='append',\n        validate=False,  # Append doesn't need full validation\n        session_id=session_id,\n    )\n\n\ndef shutdown_wm_writer(timeout: float = 2.0) -> bool:\n    \"\"\"Shutdown the background writer gracefully.\n\n    Call this on process exit to ensure pending writes complete.\n\n    Args:\n        timeout: Max seconds to wait\n\n    Returns:\n        True if shutdown cleanly\n    \"\"\"\n    global _wm_writer\n    with _writer_lock:\n        if _wm_writer:\n            result = _wm_writer.stop(timeout)\n            _wm_writer = None\n            return result\n        return True\n",
        "skills/swe-feature-onboard/SKILL.md": "---\nname: swe-feature-onboard\nversion: 2.1.0\ndescription: Feature onboarding wizard with optional quick mode\nworkflow:\n  aware: true\n  callable_from:\n    - WF_ONBOARD\n    - WF_START\n  default_return: WF_START\n  supports_standalone: true\n  auto_transition: true\nargs:\n  - name: key\n    description: Feature key (optional, will prompt if not provided)\n  - name: quick\n    description: Skip swarm analysis, minimal memory creation\n    type: boolean\n    default: false\n---\n\n## ‚ö†Ô∏è WORKFLOW INITIALIZATION\n\n**If starting a new session**, first read workflow initialization:\n```\nmcp__plugin_swe_serena__read_memory(\"WF_INIT\")\n```\nFollow WF_INIT instructions before executing this skill.\n\n---\n\n# /swe-feature-onboard [KEY] [--quick]\n\nInteractive wizard for registering features in the workflow system.\n\n## Usage\n\n```bash\n/swe-feature-onboard              # Full interactive wizard\n/swe-feature-onboard MYAPP        # Start with key pre-filled\n/swe-feature-onboard MYAPP --quick # Quick mode (30 sec, minimal)\n```\n\n## Quick Mode vs Full Mode\n\n| Aspect | Quick Mode | Full Mode |\n|--------|------------|-----------|\n| Time | ~30 sec | 2-5 min |\n| Swarm analysis | No | Optional (10 agents) |\n| DOM_* memories | No | Yes (if domains found) |\n| SYS_* memories | No | Yes (if systems found) |\n| Layer detection | Basic | Detailed |\n| Best for | Small features, prototyping | Large codebases |\n\n---\n\n## Stage 1: Basic Info\n\n**Use AskUserQuestion for feature information (skip if provided via args):**\n\n```javascript\nAskUserQuestion({\n  questions: [\n    {\n      question: \"What is the Feature Key? (Short identifier used in memory names, e.g., BACKEND, AUTH, BLOCKS)\",\n      header: \"Feature Key\",\n      options: [\n        { label: \"BACKEND\", description: \"For backend/API features\" },\n        { label: \"FRONTEND\", description: \"For UI/client features\" },\n        { label: \"AUTH\", description: \"For authentication features\" }\n      ],\n      multiSelect: false\n    },\n    {\n      question: \"What type of codebase is this feature?\",\n      header: \"Type\",\n      options: [\n        { label: \"web_app\", description: \"Web application\" },\n        { label: \"wordpress_theme\", description: \"WordPress theme\" },\n        { label: \"wordpress_plugin\", description: \"WordPress plugin\" },\n        { label: \"api\", description: \"API/Backend service\" }\n      ],\n      multiSelect: false\n    }\n  ]\n})\n```\n\n**Then ask for paths:**\n```javascript\nAskUserQuestion({\n  questions: [\n    {\n      question: \"Where is the code located? (Root path for this feature)\",\n      header: \"Root Path\",\n      options: [\n        { label: \"src/\", description: \"Standard source directory\" },\n        { label: \"wp-content/themes/\", description: \"WordPress themes\" },\n        { label: \"wp-content/plugins/\", description: \"WordPress plugins\" }\n      ],\n      multiSelect: false\n    }\n  ]\n})\n```\n\n**Validation:**\n- Key: UPPERCASE, underscores allowed, 2-20 chars\n- Path: Must exist in project\n\n---\n\n## Stage 2: Tech Stack\n\n**Use AskUserQuestion for technology selection:**\n\n```javascript\nAskUserQuestion({\n  questions: [\n    {\n      question: \"What is the primary programming language?\",\n      header: \"Language\",\n      options: [\n        { label: \"php\", description: \"PHP (WordPress, Laravel, etc.)\" },\n        { label: \"typescript\", description: \"TypeScript/JavaScript\" },\n        { label: \"python\", description: \"Python\" }\n      ],\n      multiSelect: false\n    },\n    {\n      question: \"What framework is used (if any)?\",\n      header: \"Framework\",\n      options: [\n        { label: \"wordpress\", description: \"WordPress CMS\" },\n        { label: \"react\", description: \"React.js\" },\n        { label: \"nextjs\", description: \"Next.js\" },\n        { label: \"none\", description: \"No framework / vanilla\" }\n      ],\n      multiSelect: false\n    }\n  ]\n})\n```\n\n**Auto-detection:** Scan root path for:\n- `package.json` ‚Üí Node/TypeScript\n- `composer.json` ‚Üí PHP\n- `Cargo.toml` ‚Üí Rust\n- `go.mod` ‚Üí Go\n- `style.css` with `Theme Name:` ‚Üí WordPress theme\n\n---\n\n## Stage 3: Analysis Mode\n\n**Skip in quick mode** - go directly to Stage 5.\n\n**Use AskUserQuestion for analysis mode selection:**\n\n```javascript\nAskUserQuestion({\n  questions: [\n    {\n      question: \"How should I analyze the codebase?\",\n      header: \"Analysis\",\n      options: [\n        {\n          label: \"Full DAA Swarm (Recommended)\",\n          description: \"10 agents analyze in parallel, creates DOM_*/SYS_* memories (2-5 min)\"\n        },\n        {\n          label: \"Quick Scan\",\n          description: \"Basic directory structure and layer detection (~30 sec)\"\n        },\n        {\n          label: \"Manual Configuration\",\n          description: \"You describe the architecture, I create memories from your input\"\n        }\n      ],\n      multiSelect: false\n    }\n  ]\n})\n```\n\n### If \"Full DAA Swarm\" selected:\n\n```javascript\nmcp__ruv-swarm__daa_init({ enableLearning: true })\n\nmcp__ruv-swarm__task_orchestrate({\n  task: \"Analyze feature architecture\",\n  agents: [\n    \"config-analyzer\",    // Parse config files\n    \"architecture-mapper\", // Detect layers\n    \"pattern-detector\",   // Find conventions\n    \"domain-extractor\",   // Extract domains\n    \"system-finder\",      // Identify systems\n    \"test-analyzer\",      // Test patterns\n    \"import-tracer\",      // Dependency graph\n    \"convention-learner\", // Style detection\n    \"file-indexer\",       // File inventory\n    \"synthesizer\"         // Compile results\n  ],\n  context: { featureKey: \"[KEY]\", rootPath: \"[PATH]\" }\n})\n```\n\n---\n\n## Stage 4: Architecture Confirmation\n\n**Skip in quick mode.**\n\nPresent detected architecture and confirm with AskUserQuestion:\n\n```javascript\n// First, display the detected architecture in text:\n// \"I detected the following architecture for [FEATURE_NAME]:\n//  Layers: [table]\n//  Data Flow: [diagram]\n//  Dependencies: [list]\"\n\nAskUserQuestion({\n  questions: [\n    {\n      question: \"Is the detected architecture correct?\",\n      header: \"Confirm\",\n      options: [\n        {\n          label: \"Yes, correct\",\n          description: \"Proceed with memory creation using this architecture\"\n        },\n        {\n          label: \"No, needs changes\",\n          description: \"I'll provide corrections to the architecture\"\n        },\n        {\n          label: \"Start over\",\n          description: \"Re-run analysis with different settings\"\n        }\n      ],\n      multiSelect: false\n    }\n  ]\n})\n```\n\nIf user selects \"No, needs changes\", gather corrections manually.\n\n---\n\n## Stage 5: Memory Creation\n\n### Create FEATURE_[KEY].md\n\n```markdown\n# FEATURE_[KEY] - [Name]\n\n## Feature Overview\n\n| Property | Value |\n|----------|-------|\n| **Name** | [Feature Name] |\n| **Key** | [KEY] |\n| **Type** | [type] |\n| **Language** | [language] |\n| **Framework** | [framework or \"none\"] |\n\n## Scope Definition\n\n### Primary Directories\n\n| Directory | Purpose |\n|-----------|---------|\n| [dir] | [purpose] |\n\n## Architecture Layers\n\n[ASCII diagram or table of layers]\n\n## Key Files\n\n| File | Purpose |\n|------|---------|\n| [file] | [purpose] |\n\n## Related Memories\n\n| Memory | Content |\n|--------|---------|\n| DOM_[KEY]_* | Domain behaviors |\n| SYS_[KEY]_* | System references |\n| INDEX_[KEY]_* | Indexes |\n\n## Testing\n\n| Suite | File | Focus |\n|-------|------|-------|\n| [suite] | [file] | [focus] |\n```\n\n### Create via Serena:\n\n```javascript\nmcp__plugin_swe_serena__write_memory(\"FEATURE_[KEY]\", \"<content>\")\n```\n\n### Additional memories (full mode only):\n\nIf domains detected:\n```javascript\nmcp__plugin_swe_serena__write_memory(\"DOM_[KEY]_[DOMAIN]\", \"<content>\")\n```\n\nIf systems detected:\n```javascript\nmcp__plugin_swe_serena__write_memory(\"SYS_[KEY]_[SYSTEM]\", \"<content>\")\n```\n\n---\n\n## Stage 6: Index Update\n\nUpdate INDEX_FEATURES.md:\n\n```javascript\nmcp__plugin_swe_serena__edit_memory(\n  \"INDEX_FEATURES\",\n  \"## Registered Features\",\n  \"## Registered Features\\n\\n| [KEY] | [Name] | [Type] | [Language] | Active |\",\n  \"literal\"\n)\n```\n\n---\n\n## Skill Return\n\n```markdown\n## Skill Return\n- **Skill**: swe-feature-onboard\n- **Status**: success\n- **Feature Key**: [KEY]\n- **Mode**: [full|quick]\n- **Memories Created**: FEATURE_[KEY], [DOM_*, SYS_* if applicable]\n- **Next Step Hint**: WF_START\n```\n\n---\n\n## Exit\n\n```\n> **Skill /swe-feature-onboard complete** - Feature [KEY] registered\n```\n\n---\n\n## Troubleshooting\n\n### Swarm MCP unavailable\nFall back to quick mode or manual configuration.\n\n### Path doesn't exist\n```bash\nls -la [path]\n```\nAsk user to correct.\n\n### INDEX_FEATURES.md missing\nCreate it first:\n```javascript\nmcp__plugin_swe_serena__write_memory(\"INDEX_FEATURES\", \"# INDEX_FEATURES\\n\\n## Registered Features\\n\\n| Key | Name | Type | Language | Status |\\n|-----|------|------|----------|--------|\\n\")\n```\n",
        "skills/swe-feature-update/SKILL.md": "---\nname: swe-feature-update\nversion: 1.0.0\ndescription: Update a specific feature's memory files to reflect current codebase state\nworkflow:\n  aware: true\n  callable_from:\n    - WF_START\n    - WF_CLASSIFY\n    - WF_CONTINUE\n  default_return: WF_START\n  supports_standalone: true\n  auto_transition: true\nargs:\n  - name: key\n    description: Feature key (REQUIRED - e.g., BLOCKS, THEME_DISTRICT)\n    required: true\n---\n\n## ‚ö†Ô∏è WORKFLOW INITIALIZATION\n\n**If starting a new session**, first read workflow initialization:\n```\nmcp__plugin_swe_serena__read_memory(\"WF_INIT\")\n```\nFollow WF_INIT instructions before executing this skill.\n\n---\n\n# /swe-update-feature [KEY]\n\nUpdate a specific feature's memory files to accurately reflect current codebase state.\n\n## Usage\n\n```bash\n/swe-update-feature BLOCKS           # Update BLOCKS feature memories\n/swe-update-feature THEME_DISTRICT   # Update THEME_DISTRICT feature memories\n/swe-update-feature TESTS            # Update TESTS feature memories\n```\n\n## Purpose\n\nSynchronize feature documentation with actual codebase:\n\n- Update directory listings and file inventories\n- Refresh architecture layers and patterns\n- Update entry points and key files\n- Sync related memories (ARCH_*, INDEX_*, DOM_*)\n\n---\n\n## Stage 1: Validate Feature\n\n**Verify feature exists:**\n\n```javascript\nmcp__plugin_swe_serena__read_memory(\"INDEX_FEATURES\")\n```\n\n**Check:** Feature key exists in registered features table.\n\n**If not found:**\n```\n> Feature [KEY] not registered. Use /swe-feature-onboard [KEY] to register it first.\n```\nExit skill with `needs_clarification` status.\n\n---\n\n## Stage 2: Load Current Feature Memory\n\n```javascript\nmcp__plugin_swe_serena__read_memory(\"FEATURE_[KEY]\")\n```\n\n**Extract from current memory:**\n- Root path(s)\n- Primary language\n- Framework\n- Type\n- Architecture layers\n- Related memories list\n\n---\n\n## Stage 3: Analyze Current Codebase State\n\n**For each root path in the feature:**\n\n### 3.1 Directory Structure\n\n```javascript\nmcp__plugin_swe_serena__list_dir({ relative_path: \"[root_path]\", depth: 2 })\n```\n\n### 3.2 Key Files Inventory\n\n```javascript\nmcp__plugin_swe_serena__get_symbols_overview({ relative_path: \"[root_path]\" })\n```\n\n### 3.3 Pattern Detection\n\nUse Serena tools to detect:\n- Entry points (main files, index files)\n- Configuration files\n- Test files\n- Template files\n\n---\n\n## Stage 4: Compare and Identify Changes\n\n**Compare current state vs. documented state:**\n\n| Aspect | Check For |\n|--------|-----------|\n| Directories | New directories, removed directories |\n| Key files | New files, renamed files, removed files |\n| Layers | Layer changes, new components |\n| Dependencies | New internal/external dependencies |\n| Entry points | Changed entry points |\n\n**Report changes found:**\n```\nChanges detected for [KEY]:\n- [+] Added: [new items]\n- [-] Removed: [removed items]\n- [~] Modified: [changed items]\n```\n\n---\n\n## Stage 5: Update Feature Memory\n\n### ‚ö†Ô∏è SPECIAL CASE: SWE Feature\n\nWhen updating the **SWE** feature itself, memories follow a dual-location architecture:\n\n1. **Edit FIRST** in the plugin folder: `.claude/plugins/serena-workflow-engine/memories/`\n2. **Then sync** to local project using `/swe-sync`\n\nThis ensures changes are preserved in the portable plugin and propagated correctly.\n\n**DO NOT** edit SWE memories directly in `.serena/memories/` - they will be overwritten on sync.\n\n### 5.1 Update FEATURE_[KEY]\n\n```javascript\nmcp__plugin_swe_serena__write_memory(\"FEATURE_[KEY]\", \"<updated content>\")\n```\n\n**Preserve:**\n- Feature name and metadata\n- Workflow context sections\n- Related memories list\n\n**Update:**\n- Directory listings\n- Key files table\n- Architecture layers (if changed)\n- Last updated timestamp\n\n### 5.2 Update Related Memories (if needed)\n\nCheck and update as needed:\n- `ARCH_[KEY]` - Architecture documentation\n- `INDEX_[KEY]_*` - File/symbol indexes\n- `DOM_[KEY]_*` - Domain documentation\n\n**Only update if significant changes detected.**\n\n---\n\n## Stage 6: Summary Report\n\nOutput to user:\n\n```markdown\n## Feature Update Complete: [KEY]\n\n### Changes Applied\n- FEATURE_[KEY]: [summary of changes]\n- [Other memories updated]: [summary]\n\n### Current State\n| Property | Value |\n|----------|-------|\n| Root Path(s) | [paths] |\n| Key Files | [count] |\n| Last Updated | [timestamp] |\n```\n\n---\n\n## Skill Return\n\n```markdown\n## Skill Return\n- **Skill**: swe-feature-update\n- **Status**: success\n- **Feature Key**: [KEY]\n- **Memories Updated**: [list]\n- **Changes Summary**: [brief description]\n- **Next Step Hint**: WF_START\n```\n\n---\n\n## Exit\n\n```\n> **Skill /swe-feature-update complete** - Feature [KEY] memories updated\n```\n\n---\n\n## Troubleshooting\n\n### Feature not found\n```\nFeature [KEY] is not registered in INDEX_FEATURES.\nRun: /swe-feature-onboard [KEY]\n```\n\n### Root path doesn't exist\n- Check if paths have moved\n- Update FEATURE_[KEY] with correct paths\n- Suggest re-onboarding if structure changed significantly\n\n### No changes detected\n```\n> Feature [KEY] is up to date. No changes needed.\n```\nExit with `success` status (no changes to make is still success).\n",
        "skills/swe-scaffold-project/SKILL.md": "---\nname: swe-scaffold-project\nversion: 1.0.0\ndescription: Initialize workflow for new empty projects. Creates core memories and directory structure.\nworkflow:\n  aware: true\n  callable_from:\n    - WF_START\n    - WF_INITIAL_SETUP\n  default_return: WF_START\n  supports_standalone: true\n  auto_transition: true\n---\n\n## ‚ö†Ô∏è WORKFLOW INITIALIZATION\n\n**If starting a new session**, first read workflow initialization:\n```\nmcp__plugin_swe_serena__read_memory(\"WF_INIT\")\n```\nFollow WF_INIT instructions before executing this skill.\n\n---\n\n# Scaffold Project Skill\n\nInitialize workflow system for new or empty projects.\n\n## When to Use\n\n- New projects without existing memories\n- Projects missing INDEX_FEATURES\n- Converting existing projects to workflow system\n\n## Detection Triggers\n\nAutomatically suggested when:\n- No `.serena/memories/` directory exists\n- No `INDEX_FEATURES.md` file exists\n- `INDEX_FEATURES.md` has zero features registered\n\n## Process\n\n### Stage 1: Project Detection\n\n```bash\n# Detect project root\ngit rev-parse --show-toplevel || pwd\n\n# Detect package manager\n[ -f \"package.json\" ] && echo \"npm\"\n[ -f \"composer.json\" ] && echo \"composer\"\n[ -f \"Cargo.toml\" ] && echo \"cargo\"\n[ -f \"requirements.txt\" ] && echo \"pip\"\n[ -f \"go.mod\" ] && echo \"go\"\n\n# Detect primary language\nfind . -name \"*.ts\" -o -name \"*.js\" | head -1  # TypeScript/JavaScript\nfind . -name \"*.py\" | head -1                   # Python\nfind . -name \"*.php\" | head -1                  # PHP\nfind . -name \"*.rs\" | head -1                   # Rust\nfind . -name \"*.go\" | head -1                   # Go\n```\n\n### Stage 2: Directory Setup\n\n```bash\nmkdir -p .serena/memories\nmkdir -p .claude/skills\nmkdir -p .claude/hooks\n```\n\n### Stage 3: Core Memory Creation\n\nCreate from templates:\n\n1. **_INDEX** - Navigation hub\n```markdown\n# _INDEX - Memory Navigation\n\n## Quick Reference\n- Features: INDEX_FEATURES\n- Architecture: ARCH_INDEX\n- Workflows: INDEX_WORKFLOWS_STATES\n\n## Memory Types\n| Prefix | Purpose |\n|--------|---------|\n| FEATURE_ | Feature configs |\n| DOM_ | Domain behaviors |\n| SYS_ | System references |\n| REF_ | Reference docs |\n| INDEX_ | Navigation |\n| WF_ | Workflow states |\n| WORKING_MEMORY_ | Session state |\n```\n\n2. **INDEX_FEATURES** - Empty feature registry\n```markdown\n# INDEX_FEATURES\n\n## Registered Features\n(none yet - run /swe-feature-onboard to add)\n\n## Quick Start\n1. `/swe-feature-onboard [KEY]` - Full wizard\n2. `/swe-onboard-quick [KEY]` - Fast setup\n```\n\n3. **ARCH_INDEX** - Basic architecture placeholder\n```markdown\n# ARCH_INDEX - Architecture Overview\n\n## Project Type\n[Detected or unknown]\n\n## Primary Language\n[Detected]\n\n## Framework\n[Detected or none]\n\n## Structure\n(Run /swe-feature-onboard to populate)\n```\n\n### Stage 4: First Feature Prompt\n\n**PROJECT SCAFFOLDED**\n\n**Created:**\n- .serena/memories/\n- _INDEX\n- INDEX_FEATURES\n- ARCH_INDEX\n\nYour project needs at least one feature to enable code changes.\n\n**What is the main codebase?**\n- Name: [e.g., \"Backend API\"]\n- Key: [e.g., \"BACKEND\"]\n- Path: [e.g., \"src/\"]\n\n**Options:**\n- **[A]** Set up now with /swe-feature-onboard (recommended)\n- **[B]** Quick setup with /swe-onboard-quick\n- **[C]** Skip - add features later (research-only mode)\n\n### Stage 5: Optional Swarm Analysis\n\nIf swarm MCP available:\n```\nAI-powered codebase analysis available.\n\n[A] Full DAA analysis (creates DOM_*, SYS_*, detailed INDEX_*)\n[B] Quick scan (basic structure)\n[C] Skip\n```\n\n## Minimal Workflow Mode\n\nIf user skips feature setup, enable minimal mode:\n\n```json\n{\n  \"mode\": \"minimal\",\n  \"allowed_states\": [\"WF_START\", \"WF_RESEARCH\", \"WF_CLARIFY\"],\n  \"blocked_states\": [\"WF_EXECUTE\", \"WF_CHECKPOINT\"],\n  \"message\": \"Feature onboarding required for code changes\"\n}\n```\n\n## Skill Return Format\n\n```markdown\n## Skill Return\n- **Skill**: swe-scaffold-project\n- **Status**: [success|needs_clarification]\n- **Project Root**: [path]\n- **Language**: [detected]\n- **Framework**: [detected or none]\n- **Memories Created**: _INDEX, INDEX_FEATURES, ARCH_INDEX\n- **Next Step Hint**: WF_START or /swe-feature-onboard\n```\n\n## Exit\n\n`> **Skill /swe-scaffold-project complete** - Project scaffolded, run /swe-feature-onboard to add first feature`\n",
        "skills/swe-swarm-analyze/SKILL.md": "---\nname: swe-swarm-analyze\nversion: 1.0.0\ndescription: DAA-powered codebase analysis using swarm agents. Use for deep analysis of large codebases.\nworkflow:\n  aware: true\n  callable_from:\n    - WF_ONBOARD\n    - WF_RESEARCH\n    - WF_SWARM_ORCHESTRATE\n  default_return: WF_DETECT_REQ\n  supports_standalone: true\n  auto_transition: false\nallowed-tools: Read, Grep, Glob, mcp__ruv-swarm__*, mcp__claude-flow__*\n---\n\n## ‚ö†Ô∏è WORKFLOW INITIALIZATION\n\n**If starting a new session**, first read workflow initialization:\n```\nmcp__plugin_swe_serena__read_memory(\"WF_INIT\")\n```\nFollow WF_INIT instructions before executing this skill.\n\n---\n\n# Swarm Analyze Skill\n\nDeep codebase analysis using Decentralized Autonomous Agents (DAA).\n\n## When to Use\n\n- Large codebases (1000+ files)\n- Complex multi-module projects\n- When detailed DOM_* and SYS_* memories are needed\n- Feature onboarding with full analysis mode\n\n## MCP Requirements\n\n**Required (one of):**\n- `ruv-swarm` MCP (preferred for DAA learning)\n- `claude-flow` MCP (alternative)\n\n**Fallback:** Sequential analysis if no swarm MCP available\n\n## Agent Types\n\n| Agent ID | Purpose | Cognitive Pattern |\n|----------|---------|-------------------|\n| config-analyzer | Parse config files | convergent |\n| architecture-mapper | Detect layers | systems |\n| pattern-detector | Find conventions | lateral |\n| domain-extractor | Extract domains | divergent |\n| system-finder | Identify systems | systems |\n| test-analyzer | Test patterns | critical |\n| import-tracer | Dependency graph | convergent |\n| convention-learner | Style detection | adaptive |\n| file-indexer | File inventory | convergent |\n| synthesizer | Compile results | systems |\n\n## Process\n\n### Step 1: Initialize Swarm\n\n**‚ö†Ô∏è CRITICAL: RUV-Swarm has TWO separate agent pools - choose ONE pattern:**\n\n| Pattern | Agent Creation | Execution | Use When |\n|---------|---------------|-----------|----------|\n| **Swarm** | `agent_spawn` | `task_orchestrate` | Parallel task execution |\n| **DAA** | `daa_agent_create` | `daa_workflow_execute` | Learning/adaptation needed |\n\n```javascript\n// Option A: RUV-Swarm Task Orchestration (faster, no learning)\nif (mcp_available(\"ruv-swarm\") && !needsLearning) {\n  mcp__ruv-swarm__swarm_init({ topology: \"mesh\", strategy: \"balanced\", maxAgents: 10 });\n}\n\n// Option B: RUV-Swarm DAA Workflow (slower, with learning)\nif (mcp_available(\"ruv-swarm\") && needsLearning) {\n  mcp__ruv-swarm__daa_init({ enableLearning: true, enableCoordination: true });\n}\n\n// Option C: Claude-Flow (alternative)\nif (mcp_available(\"claude-flow\")) {\n  mcp__claude-flow__swarm_init({ topology: \"mesh\", maxAgents: 10 });\n}\n```\n\n### Step 2: Spawn Analysis Agents\n\n**CRITICAL: Spawn ALL agents in ONE message for parallelism**\n\n**Option A: Swarm Agents (for task_orchestrate)**\n```javascript\n// These go into the SWARM pool - usable by task_orchestrate\nmcp__ruv-swarm__agent_spawn({ type: \"analyst\", name: \"config-analyzer\" })\nmcp__ruv-swarm__agent_spawn({ type: \"analyst\", name: \"architecture-mapper\" })\nmcp__ruv-swarm__agent_spawn({ type: \"researcher\", name: \"pattern-detector\" })\nmcp__ruv-swarm__agent_spawn({ type: \"researcher\", name: \"domain-extractor\" })\nmcp__ruv-swarm__agent_spawn({ type: \"analyst\", name: \"system-finder\" })\nmcp__ruv-swarm__agent_spawn({ type: \"analyst\", name: \"test-analyzer\" })\nmcp__ruv-swarm__agent_spawn({ type: \"researcher\", name: \"import-tracer\" })\nmcp__ruv-swarm__agent_spawn({ type: \"researcher\", name: \"convention-learner\" })\nmcp__ruv-swarm__agent_spawn({ type: \"analyst\", name: \"file-indexer\" })\nmcp__ruv-swarm__agent_spawn({ type: \"coordinator\", name: \"synthesizer\" })\n```\n\n**Option B: DAA Agents (for daa_workflow_execute)**\n```javascript\n// These go into the DAA pool - usable by daa_workflow_execute, NOT task_orchestrate\nconst agents = [\n  { id: \"config-analyzer\", cognitivePattern: \"convergent\" },\n  { id: \"architecture-mapper\", cognitivePattern: \"systems\" },\n  { id: \"pattern-detector\", cognitivePattern: \"lateral\" },\n  { id: \"domain-extractor\", cognitivePattern: \"divergent\" },\n  { id: \"system-finder\", cognitivePattern: \"systems\" },\n  { id: \"test-analyzer\", cognitivePattern: \"critical\" },\n  { id: \"import-tracer\", cognitivePattern: \"convergent\" },\n  { id: \"convention-learner\", cognitivePattern: \"adaptive\" },\n  { id: \"file-indexer\", cognitivePattern: \"convergent\" },\n  { id: \"synthesizer\", cognitivePattern: \"systems\" }\n];\n\n// Spawn all DAA agents in parallel\nagents.forEach(a => mcp__ruv-swarm__daa_agent_create({\n  id: a.id,\n  cognitivePattern: a.cognitivePattern,\n  enableMemory: true,\n  learningRate: 0.8\n}));\n```\n\n### Step 3: Orchestrate Analysis\n\n**‚ö†Ô∏è Match execution to agent type!**\n\n**Option A: Swarm Agents ‚Üí task_orchestrate**\n```javascript\n// ONLY works with agents from agent_spawn\nmcp__ruv-swarm__task_orchestrate({\n  task: \"Analyze codebase structure, patterns, domains, and systems\",\n  strategy: \"parallel\",\n  maxAgents: 10,\n  priority: \"high\"\n});\n```\n\n**Option B: DAA Agents ‚Üí daa_workflow_execute**\n```javascript\n// ONLY works with agents from daa_agent_create\nmcp__ruv-swarm__daa_workflow_create({\n  id: \"analysis-workflow\",\n  name: \"Codebase Analysis\",\n  strategy: \"parallel\"\n});\n\nmcp__ruv-swarm__daa_workflow_execute({\n  workflowId: \"analysis-workflow\",\n  agentIds: [\"config-analyzer\", \"architecture-mapper\", \"pattern-detector\",\n             \"domain-extractor\", \"system-finder\", \"test-analyzer\",\n             \"import-tracer\", \"convention-learner\", \"file-indexer\", \"synthesizer\"],\n  parallelExecution: true\n});\n```\n\n### Step 4: Collect Results\n\nEach agent produces structured findings:\n- **config-analyzer**: package.json, framework configs\n- **architecture-mapper**: layers, directories, data flow\n- **pattern-detector**: naming conventions, import patterns\n- **domain-extractor**: business domains, entities\n- **system-finder**: external integrations, APIs\n- **test-analyzer**: test framework, coverage patterns\n- **import-tracer**: dependency graph\n- **convention-learner**: code style, formatting\n- **file-indexer**: file inventory by type\n- **synthesizer**: combined analysis\n\n### Step 5: Generate Memories\n\nBased on synthesized results, create:\n\n1. **FEATURE_[KEY]** - Main feature memory\n2. **DOM_[KEY]_[domain]** - For each detected domain\n3. **SYS_[KEY]_[system]** - For each detected system\n4. **Update INDEX_FEATURES** - Add feature entry\n5. **Update ARCH_INDEX** - Add architecture details\n\n### Step 6: DAA Learning\n\nRecord analysis success for future improvement:\n\n```javascript\nmcp__ruv-swarm__daa_agent_adapt({\n  agentId: \"synthesizer\",\n  performanceScore: 0.9,\n  feedback: \"Analysis complete\"\n});\n\nmcp__ruv-swarm__daa_knowledge_share({\n  sourceAgentId: \"synthesizer\",\n  targetAgentIds: [\"config-analyzer\", \"architecture-mapper\"],\n  knowledgeDomain: \"codebase-patterns\"\n});\n```\n\n## Output Format\n\n**SWARM ANALYSIS COMPLETE**\n\n| Metric | Value |\n|--------|-------|\n| Agents Used | 10 |\n| Analysis Time | [duration] |\n\n**Detected:**\n- Language: [primary]\n- Framework: [name]\n- Layers: [count]\n- Domains: [count]\n- Systems: [count]\n\n**Memories Created:**\n- FEATURE_[KEY]\n- DOM_[KEY]_[domain1]\n- DOM_[KEY]_[domain2]\n- SYS_[KEY]_[system1]\n- INDEX_FEATURES (updated)\n- ARCH_INDEX (updated)\n\n**DAA Learning:**\n- Patterns stored: [count]\n- Confidence: [score]\n\n## Skill Return Format\n\n```markdown\n## Skill Return\n- **Skill**: swe-swarm-analyze\n- **Status**: [success|success_with_findings|blocked]\n- **Agents Used**: [count]\n- **Memories Created**: [list]\n- **Domains Found**: [count]\n- **Systems Found**: [count]\n- **Next Step Hint**: WF_DETECT_REQ\n```\n\n## Fallback: Sequential Analysis\n\nIf no swarm MCP available:\n\n```\n‚ö†Ô∏è No swarm MCP detected. Running sequential analysis.\n\nThis will take longer but produce similar results.\n\nProgress:\n[1/10] Analyzing config files...\n[2/10] Mapping architecture...\n...\n```\n\n## Exit\n\n`> **Skill /swe-swarm-analyze complete** - [count] memories created via DAA analysis`\n",
        "skills/swe-swarm-orchestrate/SKILL.md": "---\nname: swe-swarm-orchestrate\nversion: 1.0.0\ndescription: Multi-agent swarm coordination for large tasks\nworkflow:\n  aware: true\n  callable_from:\n    - WF_SWARM_ORCHESTRATE\n  default_return: WF_EXECUTE\n  supports_standalone: false\n  auto_transition: true\n---\n\n## ‚ö†Ô∏è WORKFLOW INITIALIZATION\n\n**If starting a new session**, first read workflow initialization:\n```\nmcp__plugin_swe_serena__read_memory(\"WF_INIT\")\n```\nFollow WF_INIT instructions before executing this skill.\n\n---\n\n# Swarm Orchestrate Skill\n\nCoordinate multi-agent swarm for complex tasks.\n\n## MCP Selection Priority\n\n1. **Claude Flow** (preferred) - General orchestration\n2. **RUV-Swarm** (fallback) - DAA learning agents\n3. **Sequential** (no MCP) - Chunked execution\n\n## Agent Types\n\n| Agent | Purpose |\n|-------|---------|\n| researcher | Explore codebase |\n| coder | Implement changes |\n| analyst | Review patterns |\n| optimizer | Performance tuning |\n| coordinator | Orchestrate tasks |\n\n## Swarm Topologies\n\n- **mesh** - All agents connected (default)\n- **hierarchical** - Tree structure\n- **ring** - Circular communication\n- **star** - Central coordinator\n\n## Actions\n\n1. **Select swarm system** based on available MCPs\n2. **Decompose task** into parallel subtasks\n3. **Spawn agents** (ALL in one message)\n4. **Coordinate execution**\n5. **Synthesize results**\n\n## Critical Rules\n\n- NEVER run `npx claude-flow init` - use MCP tools only\n- Spawn agents in parallel (single message)\n- Store state in WORKING_MEMORY\n\n## Exit\n\n`> **Skill /swe-swarm-orchestrate complete** - returning to WF_EXECUTE`\n",
        "skills/swe-sync/SKILL.md": "---\nname: swe-sync\nversion: 1.0.0\ndescription: Sync plugin memories to local project using ruv-swarm\nworkflow:\n  aware: true\n  callable_from:\n    - WF_INIT\n    - WF_START\n    - WF_EXECUTE\n    - WF_DONE\n  default_return: WF_DONE\n  supports_standalone: true\n  auto_transition: false\nargs:\n  - name: direction\n    description: Sync direction - plugin-to-local (default), local-to-plugin, or bidirectional\n    required: false\n  - name: category\n    description: Memory category to sync - wf, ref, all (default)\n    required: false\n  - name: dry-run\n    description: Show what would be synced without making changes\n    required: false\n---\n\n## ‚ö†Ô∏è WORKFLOW INITIALIZATION\n\n**If starting a new session**, first read workflow initialization:\n```\nmcp__plugin_swe_serena__read_memory(\"WF_INIT\")\n```\nFollow WF_INIT instructions before executing this skill.\n\n---\n\n# /swe-sync\n\nSynchronize Serena memories between plugin and local project using ruv-swarm coordination.\n\n## Usage\n\n```\n/swe-sync                           # Sync all memories plugin ‚Üí local\n/swe-sync --dry-run                 # Preview changes without syncing\n/swe-sync category=wf               # Sync only WF_ workflow files\n/swe-sync category=ref              # Sync only REF_ reference files\n/swe-sync direction=local-to-plugin # Sync local changes back to plugin\n```\n\n## Process\n\n### Step 1: Initialize Swarm\n\n```javascript\n// Initialize ruv-swarm with mesh topology\nmcp__ruv-swarm__swarm_init({ topology: \"mesh\", strategy: \"balanced\", maxAgents: 5 })\n\n// NOTE: daa_init is NOT needed here - we use agent_spawn + task_orchestrate pattern\n// DAA is only needed when using daa_agent_create + daa_workflow_execute pattern\n```\n\n### Step 2: Spawn Comparison Agents\n\n```javascript\n// Spawn agents for parallel comparison\nmcp__ruv-swarm__agent_spawn({ type: \"analyst\", name: \"plugin-scanner\", capabilities: [\"file_analysis\"] })\nmcp__ruv-swarm__agent_spawn({ type: \"analyst\", name: \"local-scanner\", capabilities: [\"file_analysis\"] })\nmcp__ruv-swarm__agent_spawn({ type: \"coordinator\", name: \"diff-reporter\", capabilities: [\"synthesis\"] })\n```\n\n### Step 3: Orchestrate Comparison Task\n\n```javascript\nmcp__ruv-swarm__task_orchestrate({\n  task: \"Compare memory files between plugin and local project\",\n  strategy: \"parallel\",\n  priority: \"high\"\n})\n```\n\n### Step 4: Execute File Comparison\n\n**Plugin Path:** `.claude/plugins/serena-workflow-engine/memories/`\n**Local Path:** `.serena/memories/`\n\n**Categories:**\n| Category | Pattern | Description |\n|----------|---------|-------------|\n| wf | `wf/WF_*.md` | Workflow state files |\n| ref | `ref/REF_*.md` | Reference documentation |\n| all | `*/*.md` | All memory files |\n\n**Comparison Logic:**\n```bash\n# For each plugin file in category:\nfor file in plugin_path/category/*.md; do\n  local_file=\"local_path/category/$(basename $file)\"\n  if [ ! -f \"$local_file\" ]; then\n    echo \"MISSING: $file\"\n  elif ! diff -q \"$file\" \"$local_file\"; then\n    echo \"DIFF: $file\"\n  fi\ndone\n\n# Check for local-only files\nfor file in local_path/category/*.md; do\n  plugin_file=\"plugin_path/category/$(basename $file)\"\n  if [ ! -f \"$plugin_file\" ]; then\n    echo \"LOCAL_ONLY: $file\"\n  fi\ndone\n```\n\n### Step 5: Report Results\n\nOutput a structured table:\n\n```markdown\n## Sync Report\n\n| Category | File | Status | Action |\n|----------|------|--------|--------|\n| wf | WF_INIT.md | SYNCED | - |\n| wf | WF_NEW.md | MISSING_LOCAL | Copy to local |\n| ref | REF_WM.md | DIFF | Update local |\n```\n\n### Step 6: Execute Sync (if not dry-run)\n\n**‚ö†Ô∏è CRITICAL: Preserve subdirectory structure!**\n\nFiles MUST be copied to their matching subdirectory:\n- `memories/wf/WF_*.md` ‚Üí `.serena/memories/wf/WF_*.md`\n- `memories/ref/REF_*.md` ‚Üí `.serena/memories/ref/REF_*.md`\n- `memories/claude/CLAUDE*.md` ‚Üí `.serena/memories/claude/CLAUDE*.md`\n\n**Direction: plugin-to-local (default)**\n```bash\n# Create subdirectory if needed\nmkdir -p .serena/memories/{category}\n# Copy preserving subdirectory\ncp -f .claude/plugins/serena-workflow-engine/memories/{category}/{file} .serena/memories/{category}/{file}\n```\n\n**Direction: local-to-plugin**\n```bash\ncp -f .serena/memories/{category}/{file} .claude/plugins/serena-workflow-engine/memories/{category}/{file}\n```\n\n**Direction: bidirectional**\n- Plugin newer ‚Üí copy to local (preserve subdir)\n- Local newer ‚Üí copy to plugin (preserve subdir)\n- Same age, different content ‚Üí CONFLICT (report, don't overwrite)\n\n**‚ùå WRONG - DO NOT flatten to root:**\n```bash\ncp memories/wf/WF_START.md .serena/memories/WF_START.md  # WRONG!\n```\n\n**‚úÖ CORRECT - Preserve subdirectory:**\n```bash\ncp memories/wf/WF_START.md .serena/memories/wf/WF_START.md  # CORRECT!\n```\n\n### Step 7: Verify Sync\n\nRe-run comparison to confirm all files synced.\n\n## Exit\n\nOutput sync summary:\n```\n‚úÖ Sync complete: X files synced, Y unchanged, Z conflicts\n```\n\nReturn to calling workflow or end if standalone.\n\n## Swarm Shutdown\n\n```javascript\nmcp__ruv-swarm__swarm_shutdown()\n```\n",
        "skills/swe-wm-update/SKILL.md": "---\nname: swe-wm-update\nversion: 2.0.0\ndescription: Single-operation Working Memory update via background daemon\nworkflow:\n  aware: true\n  callable_from:\n    - WF_START\n    - WF_CLASSIFY\n    - WF_EXECUTE\n    - WF_CHECKPOINT\n    - WF_VERIFY\n    - WF_DONE\n  default_return: null\n  supports_standalone: false\n  auto_transition: false\nargs:\n  - name: session_id\n    description: 8-char session ID (required)\n    required: true\n  - name: task\n    description: Task description (required)\n    required: true\n  - name: feature\n    description: Feature key(s) from INDEX_FEATURES (required)\n    required: true\n  - name: state\n    description: Current workflow state WF_* (required)\n    required: true\n  - name: progress\n    description: Progress items as markdown list (required)\n    required: true\n  - name: complexity\n    description: simple|medium|large (optional, default medium)\n    required: false\n---\n\n# /swe-wm-update\n\n**CRITICAL: This skill uses the background daemon for non-blocking WM writes.**\n\nThe daemon is located at:\n```\n.claude/plugins/serena-workflow-engine/hooks/swe_hooks/core/wm_writer_daemon.py\n```\n\n## Why Use the Daemon?\n\n- **Non-blocking**: Writes queued asynchronously, won't slow down workflow\n- **Write coalescing**: Rapid updates to same file are batched\n- **Format validation**: Validates against REF_WM specs before writing\n- **Anti-pattern detection**: Rejects single-field edits (use full writes)\n\n## Anti-Pattern (DO NOT DO THIS)\n\n```python\n# WRONG - Multiple blocking Serena calls!\nedit_memory(\"WM_...\", \"Task: old\", \"Task: new\", \"literal\")\nedit_memory(\"WM_...\", \"Feature: old\", \"Feature: new\", \"literal\")\nedit_memory(\"WM_...\", \"State: old\", \"State: new\", \"literal\")\n```\n\n## Correct Pattern - Using the Daemon\n\nThe daemon exposes these functions:\n\n```python\nfrom wm_writer_daemon import async_wm_write, async_wm_append, get_wm_writer\n\n# Queue a full WM write (non-blocking)\nasync_wm_write(\n    filepath=\".serena/memories/WM_{session}_session.md\",\n    content=full_wm_content,\n    operation_type='full_write',  # or 'state_update', 'edit_tracking', 'transition_log'\n    validate=True,\n    session_id=\"a7380848\"\n)\n\n# Append to existing WM (reads current, appends, queues write)\nasync_wm_append(\n    filepath=\".serena/memories/WM_{session}_session.md\",\n    append_content=\"\\n## New Section\\n...\",\n    session_id=\"a7380848\"\n)\n```\n\n## Required Data\n\nBefore invoking, you MUST have ALL of:\n\n| Field | Source | Example |\n|-------|--------|---------|\n| session_id | From hook output or WM filename | `a7380848` |\n| task | User's request summary | `\"Refactor auth module\"` |\n| feature | INDEX_FEATURES key | `BACKEND` or `BLOCKS,THEMES` |\n| state | Current WF_* step | `WF_EXECUTE` |\n| progress | Markdown checklist | `\"- [x] Step 1\\n- [ ] Step 2\"` |\n\n## Process\n\n### Step 1: Validate Required Fields\n\nIf ANY field is missing, STOP and gather it first:\n- No session_id? ‚Üí Check hook output or `list_memories()`\n- No task? ‚Üí Ask user or infer from conversation\n- No feature? ‚Üí Check `INDEX_FEATURES` or ask user\n- No state? ‚Üí Determine from workflow position\n- No progress? ‚Üí Create initial checklist from task\n\n### Step 2: Build Complete WM Content\n\n```markdown\n# Working Memory: Session {session_id}\n\n## Session\n- **ID**: {session_id}\n- **Task**: {task}\n- **Started**: {timestamp}\n\n## Workflow Context\n**Current State**: {state}\n**Previous State**: {previous_state or 'None'}\n\n## Task Context\n- **Feature(s)**: {feature}\n- **Complexity**: {complexity}\n\n## Progress Tracking\n### Pending\n{progress}\n\n## Requirements\n{requirements or '(from user request)'}\n\n## Implementation Notes\n{notes or '(none yet)'}\n```\n\n### Step 3: Queue Write via Daemon\n\nThe hooks automatically use the daemon. When updating WM from workflow:\n\n```python\n# Hooks call this internally - writes are non-blocking\nasync_wm_write(\n    filepath=f\".serena/memories/WM_{session_id}_session.md\",\n    content=wm_content,\n    operation_type='full_write',\n    validate=True,\n    session_id=session_id\n)\n```\n\n**ONE queued operation. Non-blocking. Validated.**\n\n### Step 4: Confirm\n\nOutput: `üìã Updated Working Memory: WM_{session_id}_session`\n\n## Operation Types\n\n| Type | Use Case | Validation |\n|------|----------|------------|\n| `full_write` | Complete WM replacement | Full format check |\n| `state_update` | State transition only | Anti-pattern detection |\n| `edit_tracking` | Increment edit counts | Minimal |\n| `transition_log` | Log state changes | Minimal |\n| `append` | Add section to existing | None |\n\n## State Transitions\n\nWhen updating state, also update progress:\n\n| From ‚Üí To | Progress Update |\n|-----------|-----------------|\n| WF_START ‚Üí WF_CLASSIFY | Add classification checklist |\n| WF_CLASSIFY ‚Üí WF_EXECUTE | Add implementation checklist |\n| WF_EXECUTE ‚Üí WF_VERIFY | Mark implementation done, add verify checklist |\n| WF_VERIFY ‚Üí WF_DONE | Mark all complete |\n\n## Validation Rules\n\nThe daemon will REJECT writes if:\n1. session_id doesn't match `[a-f0-9]{8}` pattern\n2. state doesn't match `WF_*` pattern\n3. feature is empty or \"(to be determined)\"\n4. task is empty or \"(awaiting user task)\"\n5. Single-field edit detected (must do full writes)\n\n## Daemon Stats\n\nCheck daemon health:\n```python\nwriter = get_wm_writer()\nstats = writer.get_stats()\n# {'queued': N, 'written': N, 'failed': N, 'coalesced': N, 'validation_rejected': N}\n```\n\n## Exit\n\nNo explicit exit - this is a utility skill that returns to caller.\n",
        "skills/swe-workflow-arch-review/SKILL.md": "---\nname: swe-workflow-arch-review\nversion: 1.0.0\ndescription: Review architecture compliance before execution\nworkflow:\n  aware: true\n  callable_from:\n    - WF_LOAD_FEATURE\n    - WF_CONTINUE\n  default_return: WF_ASK_PERMISSION\n  supports_standalone: false\n  auto_transition: true\n---\n\n## ‚ö†Ô∏è WORKFLOW INITIALIZATION\n\n**If starting a new session**, first read workflow initialization:\n```\nmcp__plugin_swe_serena__read_memory(\"WF_INIT\")\n```\nFollow WF_INIT instructions before executing this skill.\n\n---\n\n# Workflow Architecture Review Skill\n\nReview proposed changes against architecture standards.\n\n## Purpose\n\n- Verify changes align with existing architecture\n- Check layer boundaries respected\n- Validate naming conventions\n- Ensure patterns are followed\n\n## Actions\n\n1. **Read ARCH_INDEX** - Understand current architecture\n2. **Read FEATURE_* memories** - Get feature context\n3. **Check patterns** - Verify against established patterns\n4. **Validate approach** - Ensure implementation plan is sound\n\n## Review Criteria\n\n- [ ] Layer boundaries respected\n- [ ] Naming conventions followed\n- [ ] Dependencies flow correctly\n- [ ] No circular dependencies introduced\n- [ ] Consistent with existing patterns\n\n## Skill Return Format\n\n```markdown\n## Skill Return\n- **Skill**: swe-workflow-arch-review\n- **Status**: [success|success_with_findings|blocked]\n- **Findings Summary**: [architecture compliance assessment]\n- **Artifacts**: [patterns checked, issues found]\n- **Next Step Hint**: [WF_ASK_PERMISSION if approved, WF_PLAN_ARCHITECTURE if revision needed]\n```\n\n## Exit\n\nOn approval: `> **Skill /swe-workflow-arch-review passed** - returning to WF_ASK_PERMISSION`\nOn revision needed: `> **Skill /swe-workflow-arch-review needs revision** - returning to WF_PLAN_ARCHITECTURE`\n",
        "skills/swe-workflow-debug-tdd/SKILL.md": "---\nname: swe-workflow-debug-tdd\nversion: 1.0.0\ndescription: Test-driven debugging for failing tests or bugs\nworkflow:\n  aware: true\n  callable_from:\n    - WF_CLASSIFY\n  default_return: WF_EXECUTE\n  supports_standalone: true\n  auto_transition: true\n---\n\n## ‚ö†Ô∏è WORKFLOW INITIALIZATION\n\n**If starting a new session**, first read workflow initialization:\n```\nmcp__plugin_swe_serena__read_memory(\"WF_INIT\")\n```\nFollow WF_INIT instructions before executing this skill.\n\n---\n\n# Workflow Debug TDD Skill\n\nTest-driven debugging workflow for rapid iteration.\n\n## Purpose\n\n- Reproduce failing tests/bugs\n- Identify root cause\n- Implement fix\n- Verify fix works\n\n## TDD Cycle\n\n1. **RED** - Confirm test fails / bug reproduces\n2. **Analyze** - Identify root cause\n3. **GREEN** - Implement minimal fix\n4. **Verify** - Confirm test passes / bug fixed\n5. **Refactor** - Clean up if needed\n\n## Actions\n\n1. **Run failing test** - Confirm reproduction\n2. **Read error output** - Understand failure\n3. **Trace to source** - Find root cause\n4. **Implement fix** - Minimal change\n5. **Re-run test** - Verify fix\n\n## Skill Return Format\n\n```markdown\n## Skill Return\n- **Skill**: swe-workflow-debug-tdd\n- **Status**: [success|needs_clarification|blocked]\n- **Findings Summary**: [bug description and fix applied]\n- **Artifacts**: [files changed, tests affected]\n- **Next Step Hint**: WF_EXECUTE\n```\n\n## Exit\n\n`> **Skill /swe-workflow-debug-tdd complete** - bug fixed, returning to WF_EXECUTE`\n",
        "skills/swe-workflow-detect-req/SKILL.md": "---\nname: swe-workflow-detect-req\nversion: 1.0.0\ndescription: Detect implicit requirements from user request\nworkflow:\n  aware: true\n  callable_from:\n    - WF_CLASSIFY\n  default_return: WF_LOAD_FEATURE\n  supports_standalone: false\n  auto_transition: true\n---\n\n## ‚ö†Ô∏è WORKFLOW INITIALIZATION\n\n**If starting a new session**, first read workflow initialization:\n```\nmcp__plugin_swe_serena__read_memory(\"WF_INIT\")\n```\nFollow WF_INIT instructions before executing this skill.\n\n---\n\n# Workflow Detect Requirements Skill\n\nExtract explicit and implicit requirements from user request.\n\n## Purpose\n\n- Parse user request for explicit requirements\n- Infer implicit requirements (edge cases, validation, etc.)\n- Identify non-functional requirements\n- Document for tracking\n\n## Requirement Categories\n\n1. **Functional** - What the code should do\n2. **Non-functional** - Performance, security, UX\n3. **Edge cases** - Error handling, boundaries\n4. **Integration** - How it connects to existing code\n\n## Actions\n\n1. **Parse request** - Extract explicit requirements\n2. **Analyze context** - Infer implicit requirements\n3. **Check for gaps** - Identify missing information\n4. **Document** - Write to WORKING_MEMORY\n\n## Skill Return Format\n\n```markdown\n## Skill Return\n- **Skill**: swe-workflow-detect-req\n- **Status**: [success|needs_clarification]\n- **Findings Summary**: [requirements discovered]\n- **Artifacts**: [requirement list]\n- **Next Step Hint**: WF_LOAD_FEATURE\n```\n\n## Exit\n\n`> **Skill /swe-workflow-detect-req complete** - returning to WF_LOAD_FEATURE`\n",
        "skills/swe-workflow-research/SKILL.md": "---\nname: swe-workflow-research\nversion: 1.0.0\ndescription: Code exploration and research without making changes\nworkflow:\n  aware: true\n  callable_from:\n    - WF_CLASSIFY\n    - WF_CONTINUE\n    - WF_START\n  default_return: WF_DETECT_REQ\n  supports_standalone: true\n  auto_transition: true\n---\n\n## ‚ö†Ô∏è WORKFLOW INITIALIZATION\n\n**If starting a new session**, first read workflow initialization:\n```\nmcp__plugin_swe_serena__read_memory(\"WF_INIT\")\n```\nFollow WF_INIT instructions before executing this skill.\n\n---\n\n# Workflow Research Skill\n\nExplore and analyze codebase without making any changes.\n\n## Purpose\n\n- Understand code structure and patterns\n- Find relevant files and functions\n- Analyze dependencies and relationships\n- Document findings for later use\n\n## Actions\n\n1. **Explore codebase** using Serena symbolic tools\n2. **Search for patterns** using grep/glob\n3. **Read relevant files** to understand implementation\n4. **Document findings** in Skill Return section\n\n## Restrictions\n\n- **NO edits allowed** - read-only exploration\n- **NO file creation** - documentation only\n- Must update WORKING_MEMORY with findings\n\n## Skill Return Format\n\n```markdown\n## Skill Return\n- **Skill**: swe-workflow-research\n- **Status**: [success|success_with_findings|needs_clarification]\n- **Findings Summary**: [2-3 sentences describing what was found]\n- **Artifacts**: [list of relevant files, patterns discovered]\n- **Next Step Hint**: WF_DETECT_REQ\n```\n\n## Exit\n\nOutput: `> **Skill /swe-workflow-research complete** - returning to WF_DETECT_REQ`\n",
        "skills/swe-workflow-verify/SKILL.md": "---\nname: swe-workflow-verify\nversion: 1.0.0\ndescription: Verify implementation against requirements and standards\nworkflow:\n  aware: true\n  callable_from:\n    - WF_EXECUTE\n    - WF_CHECKPOINT\n  default_return: WF_DONE\n  supports_standalone: false\n  auto_transition: true\n---\n\n## ‚ö†Ô∏è WORKFLOW INITIALIZATION\n\n**If starting a new session**, first read workflow initialization:\n```\nmcp__plugin_swe_serena__read_memory(\"WF_INIT\")\n```\nFollow WF_INIT instructions before executing this skill.\n\n---\n\n# Workflow Verify Skill\n\nVerify implementation completeness and quality.\n\n## Purpose\n\n- Run test suites\n- Check against requirements\n- Verify coding standards compliance\n- Ensure no regressions\n\n## Actions\n\n1. **Run tests** - Execute relevant test commands\n2. **Check requirements** - Compare implementation to documented requirements\n3. **Verify standards** - Check against CLAUDE_OBLIGATIONS and REF_DEV_STANDARDS\n4. **Lint/format check** - Run linters if configured\n\n## Verification Checklist\n\n- [ ] All tests pass\n- [ ] Requirements met\n- [ ] Coding standards followed\n- [ ] No security vulnerabilities introduced\n- [ ] Documentation updated if needed\n\n## Skill Return Format\n\n```markdown\n## Skill Return\n- **Skill**: swe-workflow-verify\n- **Status**: [success|success_with_findings|blocked]\n- **Findings Summary**: [verification results]\n- **Artifacts**: [test results, lint output]\n- **Next Step Hint**: [WF_DONE if passed, WF_EXECUTE if failed]\n```\n\n## Exit\n\nOn success: `> **Skill /swe-workflow-verify complete** - returning to WF_DONE`\nOn failure: `> **Skill /swe-workflow-verify failed** - returning to WF_EXECUTE for fixes`\n"
      },
      "plugins": [
        {
          "name": "swe",
          "version": "1.0.33",
          "description": "21-state workflow engine with Serena memory persistence, RLVR learning, and auto plan mode switching",
          "source": "./",
          "homepage": "https://github.com/EarthmanWeb/serena-workflow-engine",
          "keywords": [
            "workflow",
            "serena",
            "state-machine",
            "memory",
            "hooks"
          ],
          "categories": [
            "hooks",
            "memory",
            "serena",
            "state-machine",
            "workflow"
          ],
          "install_commands": [
            "/plugin marketplace add EarthmanWeb/serena-workflow-engine",
            "/plugin install swe@EarthmanWeb"
          ]
        }
      ]
    }
  ]
}