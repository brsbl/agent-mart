{
  "author": {
    "id": "Context-Engine-AI",
    "display_name": "Context Engine Inc",
    "type": "Organization",
    "avatar_url": "https://avatars.githubusercontent.com/u/256224968?v=4",
    "url": "https://github.com/Context-Engine-AI",
    "bio": null,
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 0,
      "total_skills": 3,
      "total_stars": 305,
      "total_forks": 34
    }
  },
  "marketplaces": [
    {
      "name": "context-engine-skills",
      "version": null,
      "description": "Context-Engine codebase search and retrieval skills",
      "owner_info": {
        "name": "m1rl0k"
      },
      "keywords": [],
      "repo_full_name": "Context-Engine-AI/Context-Engine",
      "repo_url": "https://github.com/Context-Engine-AI/Context-Engine",
      "repo_description": "Context-Engine MCP - Agentic Context Compression Suite",
      "homepage": "https://context-engine.ai",
      "signals": {
        "stars": 305,
        "forks": 34,
        "pushed_at": "2026-01-29T14:05:15Z",
        "created_at": "2025-10-08T22:34:56Z",
        "license": "NOASSERTION"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 486
        },
        {
          "path": ".codex",
          "type": "tree",
          "size": null
        },
        {
          "path": ".codex/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": ".codex/skills/context-engine",
          "type": "tree",
          "size": null
        },
        {
          "path": ".codex/skills/context-engine/SKILL.md",
          "type": "blob",
          "size": 3554
        },
        {
          "path": ".codex/skills/context-engine/references",
          "type": "tree",
          "size": null
        },
        {
          "path": ".codex/skills/context-engine/references/patterns.md",
          "type": "blob",
          "size": 2921
        },
        {
          "path": ".codex/skills/context-engine/references/tool-reference.md",
          "type": "blob",
          "size": 3789
        },
        {
          "path": ".skills",
          "type": "tree",
          "size": null
        },
        {
          "path": ".skills/mcp-tool-selection",
          "type": "tree",
          "size": null
        },
        {
          "path": ".skills/mcp-tool-selection/SKILL.md",
          "type": "blob",
          "size": 3772
        },
        {
          "path": "README.md",
          "type": "blob",
          "size": 8002
        },
        {
          "path": "bench",
          "type": "tree",
          "size": null
        },
        {
          "path": "bench/README.md",
          "type": "blob",
          "size": 2925
        },
        {
          "path": "ctx-mcp-bridge",
          "type": "tree",
          "size": null
        },
        {
          "path": "ctx-mcp-bridge/README.md",
          "type": "blob",
          "size": 6526
        },
        {
          "path": "deploy",
          "type": "tree",
          "size": null
        },
        {
          "path": "deploy/helm",
          "type": "tree",
          "size": null
        },
        {
          "path": "deploy/helm/context-engine",
          "type": "tree",
          "size": null
        },
        {
          "path": "deploy/helm/context-engine/README.md",
          "type": "blob",
          "size": 12581
        },
        {
          "path": "deploy/kubernetes",
          "type": "tree",
          "size": null
        },
        {
          "path": "deploy/kubernetes/README.md",
          "type": "blob",
          "size": 16243
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/neo4j_graph",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/neo4j_graph/README.md",
          "type": "blob",
          "size": 9874
        },
        {
          "path": "scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "scripts/ctx_cli",
          "type": "tree",
          "size": null
        },
        {
          "path": "scripts/ctx_cli/README.md",
          "type": "blob",
          "size": 5754
        },
        {
          "path": "scripts/graph_backends",
          "type": "tree",
          "size": null
        },
        {
          "path": "scripts/graph_backends/README.md",
          "type": "blob",
          "size": 5814
        },
        {
          "path": "skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/context-engine",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/context-engine/SKILL.md",
          "type": "blob",
          "size": 13154
        },
        {
          "path": "vscode-extension",
          "type": "tree",
          "size": null
        },
        {
          "path": "vscode-extension/context-engine-uploader",
          "type": "tree",
          "size": null
        },
        {
          "path": "vscode-extension/context-engine-uploader/README.md",
          "type": "blob",
          "size": 18450
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"context-engine-skills\",\n  \"owner\": {\n    \"name\": \"m1rl0k\"\n  },\n  \"metadata\": {\n    \"description\": \"Context-Engine codebase search and retrieval skills\",\n    \"version\": \"1.0.0\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"context-engine\",\n      \"description\": \"Codebase search and context retrieval using hybrid semantic/lexical search with neural reranking\",\n      \"source\": \"./\",\n      \"strict\": false,\n      \"skills\": [\n        \"./skills/context-engine\"\n      ]\n    }\n  ]\n}\n\n",
        ".codex/skills/context-engine/SKILL.md": "---\nname: context-engine\ndescription: Hybrid semantic/lexical code search with neural reranking via MCP tools. Use when Codex needs to search a codebase, find implementations, understand how code works, find callers/definitions, search git history, or store/retrieve knowledge. IMPORTANT - Always prefer these MCP tools over grep/find/cat for code exploration.\n---\n\n# Context Engine MCP Tools\n\nHybrid vector search (semantic + lexical) with neural reranking for codebase retrieval.\n\n## Core Decision Tree\n\n```\nNeed to find code?\n├── Simple lookup → info_request\n├── Need filters/control → repo_search\n├── Want LLM explanation → context_answer\n├── Find similar patterns → pattern_search (if enabled)\n├── Find relationships → symbol_graph (DEFAULT, always available)\n└── Store/recall knowledge → memory_store, memory_find\n```\n\n## Primary Tools\n\n**repo_search** - Main code search tool:\n```json\n{\"query\": \"authentication middleware\", \"limit\": 10, \"include_snippet\": true}\n```\nMulti-query: `{\"query\": [\"auth handler\", \"login validation\"]}`\n\n**symbol_graph** - Find callers, definitions, importers (ALWAYS available):\n```json\n{\"symbol\": \"authenticate\", \"query_type\": \"callers\", \"limit\": 10}\n{\"symbol\": \"UserService\", \"query_type\": \"definition\"}\n{\"symbol\": \"utils\", \"query_type\": \"importers\"}\n```\nUse `depth=2` for multi-hop (callers of callers).\n\n**context_answer** - LLM-generated explanation with citations:\n```json\n{\"query\": \"How does the caching layer work?\", \"budget_tokens\": 2000}\n```\n\n**info_request** - Quick natural language lookup:\n```json\n{\"info_request\": \"how does user auth work\", \"include_explanation\": true}\n```\n\n## Memory Tools\n\n```json\n// Store knowledge\n{\"information\": \"Auth uses JWT with 24h expiry\", \"metadata\": {\"topic\": \"auth\"}}\n\n// Find stored knowledge\n{\"query\": \"token expiration\", \"limit\": 5}\n\n// Blend code + memories\n{\"query\": \"auth flow\", \"include_memories\": true}\n```\n\n## Specialized Search\n\n| Tool | Use Case | Example |\n|------|----------|---------|\n| `search_tests_for` | Find tests | `{\"query\": \"UserService\"}` |\n| `search_config_for` | Find config | `{\"query\": \"database connection\"}` |\n| `search_callers_for` | Quick caller search | `{\"query\": \"processPayment\"}` |\n| `search_commits_for` | Git history | `{\"query\": \"fixed auth bug\"}` |\n| `pattern_search` | Similar code patterns | `{\"query\": \"retry with backoff\"}` |\n\n## Index Management\n\n- `qdrant_index_root` - Index workspace (run first!)\n- `qdrant_status` - Check index health\n- `qdrant_prune` - Remove deleted files\n\n## Best Practices\n\n1. **NEVER use grep/cat/find for code exploration** - Use MCP tools instead\n2. **Start with `symbol_graph`** for all relationship queries\n3. **Use multi-query** for complex searches: pass 2-3 variations\n4. **Two-phase search**: Discovery (`limit=3, compact=true`) → Deep dive (`limit=8, include_snippet=true`)\n5. **Fire parallel calls** - Multiple independent searches in one message\n6. **Set session defaults early**: `set_session_defaults(output_format=\"toon\", compact=true)`\n\n## Filters (for repo_search)\n\n- `language` - python, typescript, go, etc.\n- `under` - Path prefix: `\"src/api/\"`\n- `path_glob` - Include patterns: `[\"**/*.ts\"]`\n- `not_glob` - Exclude patterns: `[\"**/test_*\"]`\n- `repo` - Repository filter: `[\"frontend\", \"backend\"]` or `\"*\"` for all\n\n## References\n\nFor detailed API documentation, see:\n- [references/tool-reference.md](references/tool-reference.md) - Complete tool parameters\n- [references/patterns.md](references/patterns.md) - Common search patterns\n\n",
        ".codex/skills/context-engine/references/patterns.md": "# Common Search Patterns\n\n## Session Bootstrap\n\nAlways start a session with defaults to avoid repeating parameters:\n```json\n// set_session_defaults\n{\"output_format\": \"toon\", \"compact\": true, \"limit\": 5}\n```\n\n## Two-Phase Search Strategy\n\n### Phase 1: Discovery (find relevant areas)\n```json\n{\"query\": \"authentication\", \"limit\": 3, \"compact\": true, \"per_path\": 1}\n```\n\n### Phase 2: Deep Dive (get details)\n```json\n{\"query\": \"JWT token validation\", \"limit\": 8, \"include_snippet\": true, \"context_lines\": 5}\n```\n\n## Multi-Query Fusion\n\nFor complex concepts, pass multiple query variations:\n```json\n{\n  \"query\": [\"authentication handler\", \"login middleware\", \"auth validation\"],\n  \"limit\": 10\n}\n```\n\n## Finding Callers (symbol_graph)\n\nDirect callers:\n```json\n{\"symbol\": \"processPayment\", \"query_type\": \"callers\", \"limit\": 15}\n```\n\nCallers of callers (multi-hop):\n```json\n{\"symbol\": \"processPayment\", \"query_type\": \"callers\", \"depth\": 2, \"limit\": 20}\n```\n\n## Finding Definitions\n\n```json\n{\"symbol\": \"UserService\", \"query_type\": \"definition\"}\n```\n\n## Finding Importers\n\n```json\n{\"symbol\": \"utils/helpers\", \"query_type\": \"importers\", \"limit\": 10}\n```\n\n## Cross-Repo Search\n\nSearch specific repos:\n```json\n{\"query\": \"shared types\", \"repo\": [\"frontend\", \"backend\"]}\n```\n\nSearch all indexed repos:\n```json\n{\"query\": \"shared types\", \"repo\": \"*\"}\n```\n\n## Filtering by Language/Path\n\n```json\n{\n  \"query\": \"error handling\",\n  \"language\": \"python\",\n  \"under\": \"src/api/\",\n  \"not_glob\": [\"**/test_*\", \"**/*_test.*\"]\n}\n```\n\n## Pattern Search (if enabled)\n\nFind retry patterns:\n```json\n{\"query\": \"retry with exponential backoff\", \"limit\": 10}\n```\n\nFind error handling:\n```json\n{\"query\": \"try: ... except: logger.error()\", \"query_mode\": \"code\"}\n```\n\nCross-language (Go pattern → Python/Rust):\n```json\n{\"query\": \"if err != nil { return err }\", \"language\": \"go\", \"target_languages\": [\"python\", \"rust\"]}\n```\n\n## Git History Search\n\nFind commits about a topic:\n```json\n{\"query\": \"fixed authentication bug\", \"limit\": 10}\n```\n\nFile change history:\n```json\n{\"path\": \"src/api/auth.py\", \"include_commits\": true}\n```\n\n## Memory Patterns\n\nStore architectural decision:\n```json\n{\n  \"information\": \"Auth service uses JWT with 24h expiry. Refresh tokens last 7 days.\",\n  \"metadata\": {\"topic\": \"auth\", \"kind\": \"decision\"}\n}\n```\n\nFind stored knowledge:\n```json\n{\"query\": \"token expiration\", \"limit\": 5}\n```\n\nBlend code search with memories:\n```json\n{\n  \"query\": \"authentication flow\",\n  \"include_memories\": true,\n  \"per_source_limits\": {\"code\": 6, \"memory\": 3}\n}\n```\n\n## Anti-Patterns (AVOID)\n\n❌ `grep -r \"auth\" .` → Use `repo_search(\"authentication mechanisms\")`\n❌ `cat file.py` to understand → Use `context_answer(\"how does file.py work\")`\n❌ `find . -name \"*.py\"` → Use `repo_search` with `path_glob`\n❌ Sequential searches → Fire parallel calls in one message\n❌ `limit=20, include_snippet=true` → Token waste, use two-phase instead\n\n",
        ".codex/skills/context-engine/references/tool-reference.md": "# Context Engine Tool Reference\n\nComplete parameter reference for all MCP tools.\n\n## repo_search / code_search\n\nPrimary hybrid search tool. Reranking enabled by default.\n\n| Parameter | Type | Description |\n|-----------|------|-------------|\n| `query` | string/list | Search query (multi-query fuses results) |\n| `limit` | int | Max results (default 10) |\n| `per_path` | int | Max results per file (default 2) |\n| `include_snippet` | bool | Include code snippets |\n| `context_lines` | int | Lines of context around matches |\n| `language` | string | Filter by language |\n| `under` | string | Path prefix filter |\n| `path_glob` | list | Include patterns |\n| `not_glob` | list | Exclude patterns |\n| `symbol` | string | Symbol name filter |\n| `repo` | string/list | Repository filter (\"*\" for all) |\n| `rerank_enabled` | bool | Enable neural reranking (default true) |\n| `output_format` | string | \"json\" or \"toon\" (compact) |\n| `compact` | bool | Minimal response fields |\n\n## symbol_graph\n\nAST-backed symbol relationship queries. Always available.\n\n| Parameter | Type | Description |\n|-----------|------|-------------|\n| `symbol` | string | Symbol to analyze |\n| `query_type` | string | \"callers\", \"definition\", \"importers\", \"callees\" |\n| `depth` | int | Traversal depth (1=direct, 2+=multi-hop) |\n| `limit` | int | Max results (default 20) |\n| `language` | string | Filter by language |\n| `under` | string | Path prefix filter |\n| `repo` | string | Repository filter |\n\n## context_answer\n\nLLM-generated answers with code citations.\n\n| Parameter | Type | Description |\n|-----------|------|-------------|\n| `query` | string/list | Question requiring explanation |\n| `budget_tokens` | int | Token budget for context |\n| `max_tokens` | int | Max tokens for answer |\n| `expand` | bool | Generate query expansions |\n| `include_snippet` | bool | Include code in response |\n| `language` | string | Filter retrieval |\n| `under` | string | Path prefix filter |\n\n## info_request\n\nSimplified discovery with optional explanations.\n\n| Parameter | Type | Description |\n|-----------|------|-------------|\n| `info_request` | string | Natural language query |\n| `include_explanation` | bool | Add NL summary |\n| `include_relationships` | bool | Add imports/calls info |\n| `limit` | int | Max results |\n\n## pattern_search (Optional)\n\nStructural code pattern matching. May not be enabled in all deployments.\n\n| Parameter | Type | Description |\n|-----------|------|-------------|\n| `query` | string | Code snippet OR pattern description |\n| `query_mode` | string | \"code\", \"description\", or \"auto\" |\n| `language` | string | Language hint for code examples |\n| `target_languages` | list | Filter results to languages |\n| `min_score` | float | Minimum similarity (default 0.3) |\n| `aroma_rerank` | bool | AROMA structural reranking |\n\n## Memory Tools\n\n**memory_store**\n| Parameter | Type | Description |\n|-----------|------|-------------|\n| `information` | string | Knowledge to store |\n| `metadata` | object | Tags, topic, priority, etc. |\n\n**memory_find**\n| Parameter | Type | Description |\n|-----------|------|-------------|\n| `query` | string | Search query |\n| `limit` | int | Max results |\n| `kind` | string | Filter by type |\n| `topic` | string | Filter by topic |\n\n**context_search**\n| Parameter | Type | Description |\n|-----------|------|-------------|\n| `query` | string | Search query |\n| `include_memories` | bool | Blend with stored memories |\n| `per_source_limits` | object | `{\"code\": 6, \"memory\": 3}` |\n\n## Index Management\n\n**qdrant_index_root** - `{\"recreate\": true}` to drop existing data\n**qdrant_index** - `{\"subdir\": \"src/\"}` for partial index\n**qdrant_prune** - Remove stale entries\n**qdrant_status** - Check health\n**set_session_defaults** - Set collection, output_format, compact, limit\n\n",
        ".skills/mcp-tool-selection/SKILL.md": "---\nname: mcp-tool-selection\ndescription: Decision rules for when to use Context Engine MCP semantic search vs grep/literal file tools. Use this skill when starting exploration, debugging, or answering \"where/why\" questions about code.\n---\n\n# MCP Tool Selection Rules\n\n**Core principle:** Context Engine MCP tools are primary for exploring code and history. Start with MCP for exploration, debugging, or \"where/why\" questions; use literal search/file-open only for narrow exact-literal lookups.\n\n## STOP — Do NOT Use Read File or Grep for Exploration\n\n**DO NOT use `Read File`, `grep`, `ripgrep`, `cat`, `find`, or any filesystem search tool for code exploration.**\nYou have MCP tools that are faster, smarter, and return ranked, contextual results.\n\n- About to `Read` a file to understand it? → use `repo_search` or `context_answer`\n- About to `grep` for a symbol? → use `symbol_graph` or `search_callers_for`\n- About to `grep -r` for a concept? → use `repo_search` with natural language\n- About to `find`/`ls` for project structure? → use `workspace_info` or `qdrant_status`\n\nThe ONLY acceptable use of grep/Read: confirming exact literal strings (e.g., `REDIS_HOST`), or reading a file you already located via MCP for editing.\n\n## Use Context Engine MCP Tools When\n\n- Exploring or don't know exact strings/symbols\n- Need semantic or cross-file understanding (relationships, patterns, architecture)\n- Want ranked results with surrounding context, not just line hits\n- Asking conceptual/architectural or \"where/why\" behavior questions\n- Need rich context/snippets around matches\n- Finding callers, definitions, or importers of any symbol\n\n## Use Literal Search/File-Open Only When\n\n- Know exact string/function/variable or error message\n- Only need to confirm existence or file/line quickly (not to understand behavior)\n\n## Grep Anti-Patterns (DON'T)\n\n```bash\ngrep -r \"auth\" .        # → Use MCP: \"authentication mechanisms\"\ngrep -r \"cache\" .       # → Use MCP: \"caching strategies\"  \ngrep -r \"error\" .       # → Use MCP: \"error handling patterns\"\ngrep -r \"database\" .    # → Use MCP: \"database operations\"\n# Also DON'T:\nRead File to understand a module  # → Use repo_search or context_answer\nRead File to find callers         # → Use symbol_graph\nfind/ls for project structure     # → Use workspace_info\n```\n\n## Literal Search Patterns (DO)\n\n```bash\ngrep -rn \"UserAlreadyExists\" .      # Specific error class\ngrep -rn \"def authenticate_user\" .  # Exact function name\ngrep -rn \"REDIS_HOST\" .             # Exact environment variable\n```\n\n## Quick Decision Heuristic\n\n| Question Type | Tool |\n|--------------|------|\n| \"Where is X implemented?\" | MCP `repo_search` |\n| \"Who calls this and show code?\" | MCP `symbol_graph` — **DEFAULT for all graph queries, always available** |\n| \"Where is X defined?\" | MCP `symbol_graph` (query_type=\"definition\") |\n| \"What imports X?\" | MCP `symbol_graph` (query_type=\"importers\") |\n| \"Callers of callers? Multi-hop?\" | MCP `symbol_graph` (depth=2+) or `neo4j_graph_query` (if NEO4J_GRAPH=1) |\n| \"What breaks if I change X?\" | MCP `neo4j_graph_query` (ONLY if available, else use `symbol_graph`) |\n| \"Circular dependencies?\" | MCP `neo4j_graph_query` (ONLY if available) |\n| \"How does authentication work?\" | MCP `context_answer` |\n| \"High-level module overview?\" | MCP `info_request` (with explanations) |\n| \"Does REDIS_HOST exist?\" | Literal grep |\n| \"Why did behavior change?\" | `search_commits_for` + `change_history_for_path` |\n\n> **`symbol_graph`** is ALWAYS available (Qdrant-backed). **`neo4j_graph_query`** is ONLY available when `NEO4J_GRAPH=1`. If `neo4j_graph_query` is not in your tool list, use `symbol_graph` for everything. Never error about missing Neo4j.\n\n**If in doubt → start with MCP**\n\n",
        "README.md": "[![CI](https://github.com/m1rl0k/Context-Engine/actions/workflows/ci.yml/badge.svg)](https://github.com/m1rl0k/Context-Engine/actions/workflows/ci.yml)\n[![npm version](https://img.shields.io/npm/v/@context-engine-bridge/context-engine-mcp-bridge.svg)](https://www.npmjs.com/package/@context-engine-bridge/context-engine-mcp-bridge)\n[![VS Code Marketplace](https://img.shields.io/visual-studio-marketplace/i/context-engine.context-engine-uploader.svg?label=VS%20Code)](https://marketplace.visualstudio.com/items?itemName=context-engine.context-engine-uploader)\n\n\n**Documentation:** [Getting Started](docs/GETTING_STARTED.md) · README · [Configuration](docs/CONFIGURATION.md) · [IDE Clients](docs/IDE_CLIENTS.md) · [MCP API](docs/MCP_API.md) · [ctx CLI](docs/CTX_CLI.md) · [Memory Guide](docs/MEMORY_GUIDE.md) · [Architecture](docs/ARCHITECTURE.md) · [Multi-Repo](docs/MULTI_REPO_COLLECTIONS.md) · [Observability](docs/OBSERVABILITY.md) · [Kubernetes](deploy/kubernetes/README.md) · [VS Code Extension](docs/vscode-extension.md) · [Troubleshooting](docs/TROUBLESHOOTING.md) · [Development](docs/DEVELOPMENT.md)\n\n---\n\n## Context-Engine\n\nOpen-core, self-improving code search that gets smarter every time you use it.\n\n---\n\n## Quick Start\n\n### Install the CLI\n\n```bash\n# Using pip\npip install context-engine\n\n# Or using uv (recommended)\nuv pip install context-engine\n```\n\nThis installs the `ctx` command (also available as `ctx-cli`).\n\n### One Command Setup\n\n```bash\nctx quickstart\n```\n\nThis single command starts all services, indexes your codebase, and warms up models.\n\n### Common Commands\n\n```bash\nctx status              # Check service health\nctx reset --mcp         # Reset with HTTP MCP endpoints (for Codex, modern clients)\nctx reset --mcp --db-reset  # Hard reset: wipe database and rebuild everything\nctx search \"auth flow\"  # Search your codebase\nctx answer \"How does caching work?\"  # Get answers with citations\n```\n\nSee [ctx CLI Reference](docs/CTX_CLI.md) for all commands.\n\n<details>\n<summary><b>Legacy: Makefile Commands</b></summary>\n\nThe ctx CLI deprecates the Makefile, but legacy commands retest available:\n\n```bash\ngit clone https://github.com/m1rl0k/Context-Engine.git && cd Context-Engine\nmake bootstrap  # Equivalent to: ctx quickstart\nmake reset      # Equivalent to: ctx reset --mcp\n```\n\n</details>\n\n---\n\n### Enterprise-Ready Features\n\n- **Built-in authentication** with session management (optional)\n- **Unified MCP endpoint** that combines indexer and memory services\n- **Automatic collection injection** for workspace-aware queries\n\n**Direct HTTP endpoints:**\n```json\n{\n  \"mcpServers\": {\n    \"qdrant-indexer\": { \"url\": \"http://localhost:8003/mcp\" },\n    \"memory\": { \"url\": \"http://localhost:8002/mcp\" }\n  }\n}\n```\n\n*See [docs/IDE_CLIENTS.md](docs/IDE_CLIENTS.md) for MCP configuration examples and [docs/MCP_API.md](docs/MCP_API.md) for the complete API reference.*\n\n---\n\n## Agent Skills (Codex / Claude / Gemini / Augment)\n\nContext-Engine includes agent skills that teach AI coding assistants how to use the MCP tools effectively.\n\n**For Codex (OpenAI):**\n\nInstall directly from GitHub using the `$skill-installer`:\n```t\n$skill-installer install https://github.com/Context-Engine-AI/Context-Engine/tree/test/.codex/skills/context-engine\n```\n\nOr copy manually:\n```bash\n# Global install\ncp -r .codex/skills/context-engine ~/.codex/skills/\n\n# Or project-specific\ncp -r .codex/skills/context-engine /path/to/your/project/.codex/skills/\n```\n\nRestart Codex after installing to pick up the new skill.\n\n**For Claude:**\n```bash\ncp CLAUDE.md /path/to/your/project/\n```\n\n**For Gemini:**\n```bash\ncp GEMINI.md /path/to/your/project/\n```\n\n**For Augment:**\n```bash\ncp -r .augment /path/to/your/project/\n```\n\nSkills teach agents to prefer Context-Engine MCP tools over grep/find/cat for code exploration.\n\n---\n\n## How It Works\n\n### Local Mode Architecture\n*Zero auth, single-tenant, perfect for personal use*\n\n```mermaid\nflowchart TB\n    subgraph client[\"CLIENT LAYER\"]\n        direction LR\n        IDE[\"<b>IDE / AI Tool</b><br/>Claude, Cursor, etc.\"]\n        VSC[\"<b>VS Code Extension</b><br/>File Watcher\"]\n    end\n\n    subgraph mcp[\"MCP LAYER\"]\n        direction LR\n        subgraph search[\"Search Services\"]\n            MCP_SSE[\"<b>Memory MCP</b><br/>:8000 SSE\"]\n            MCP_HTTP[\"<b>Memory MCP</b><br/>:8002 RMCP\"]\n        end\n        subgraph index[\"Index Services\"]\n            IDX_SSE[\"<b>Indexer MCP</b><br/>:8001 SSE\"]\n            IDX_HTTP[\"<b>Indexer MCP</b><br/>:8003 RMCP\"]\n        end\n    end\n\n    subgraph processing[\"PROCESSING LAYER\"]\n        direction LR\n        EMB[\"<b>Embedding Service</b><br/>:8100-8101<br/>ONNX (2 replicas)\"]\n        LLAMA[\"<b>LLM Decoder</b><br/>:8080<br/>llama.cpp\"]\n        LEARN[\"<b>Learning Worker</b><br/>Background<br/>Adaptive Reranker\"]\n        WATCH[\"<b>Watcher</b><br/>File Monitor<br/>Auto-reindex\"]\n    end\n\n    subgraph storage[\"STORAGE LAYER\"]\n        direction LR\n        QDRANT[(\"<b>Qdrant</b><br/>:6333/:6334<br/>Vector DB\")]\n        REDIS[(\"<b>Redis</b><br/>:6379<br/>Cache/State\")]\n        FS[(\"<b>Filesystem</b><br/>/work<br/>Direct Access\")]\n    end\n\n    %% Client connections\n    IDE -->|\"MCP Protocol\"| MCP_SSE & MCP_HTTP\n    IDE -->|\"MCP Protocol\"| IDX_SSE & IDX_HTTP\n    VSC -->|\"File Sync\"| FS\n\n    %% MCP to Processing\n    MCP_SSE & MCP_HTTP -->|\"embed()\"| EMB\n    IDX_SSE & IDX_HTTP -->|\"embed()\"| EMB\n    IDX_SSE & IDX_HTTP -->|\"expand query\"| LLAMA\n\n    %% Processing to Storage\n    EMB -->|\"vectors\"| QDRANT\n    LEARN -->|\"update weights\"| QDRANT\n    WATCH -->|\"file events\"| FS\n    WATCH -->|\"reindex\"| QDRANT\n\n    %% Storage connections\n    MCP_SSE & MCP_HTTP -->|\"search\"| QDRANT\n    IDX_SSE & IDX_HTTP -->|\"upsert\"| QDRANT\n    IDX_SSE & IDX_HTTP -->|\"state\"| REDIS\n\n    %% Styling - GitHub light/dark compatible\n    classDef clientStyle fill:#4a90d9,stroke:#2563eb,stroke-width:2px,color:#fff\n    classDef mcpStyle fill:#8b5cf6,stroke:#6d28d9,stroke-width:2px,color:#fff\n    classDef processStyle fill:#f59e0b,stroke:#d97706,stroke-width:2px,color:#000\n    classDef storageStyle fill:#10b981,stroke:#059669,stroke-width:2px,color:#fff\n\n    class IDE,VSC clientStyle\n    class MCP_SSE,MCP_HTTP,IDX_SSE,IDX_HTTP mcpStyle\n    class EMB,LLAMA,LEARN,WATCH processStyle\n    class QDRANT,REDIS,FS storageStyle\n```\n\n<details>\n<summary><b>Service Port Reference</b></summary>\n\n| Service | Port | Protocol | Description |\n|---------|------|----------|-------------|\n| Memory MCP (SSE) | 8000 | SSE | Legacy streaming transport |\n| Memory MCP (RMCP) | 8002 | HTTP | Modern streamable HTTP |\n| Indexer MCP (SSE) | 8001 | SSE | Legacy streaming transport |\n| Indexer MCP (RMCP) | 8003 | HTTP | Modern streamable HTTP |\n| Upload Service | 8004 | HTTP | Delta bundle uploads |\n| Embedding Service | 8100-8101 | HTTP | ONNX embeddings (2 replicas) |\n| LLM Decoder | 8080 | HTTP | llama.cpp query expansion |\n| Qdrant | 6333/6334 | HTTP/gRPC | Vector database |\n| Redis | 6379 | TCP | Cache and state backend |\n\n</details>\n\n---\n\n## Benchmarks\n\n### CoSQA (Dense Retrieval, No Rerank)\n\n| Method | MRR | R@1 | R@5 | R@10 | NDCG@10 |\n|--------|-----|-----|-----|------|---------|\n| **Context-Engine (Jina-Code)** | **0.276** | 0.146 | 0.448 | 0.658 | 0.365 |\n| Context-Engine (BGE-base) | 0.253 | 0.150 | 0.374 | 0.550 | 0.322 |\n| CodeT5+ embedding | 0.266 | - | - | - | - |\n| BM25 (Lucene) | 0.167 | - | - | - | - |\n| BoW | 0.065 | - | - | - | - |\n\n*Corpus: 20,604 code snippets | 500 queries | Pure dense retrieval, no reranking*\n*Jina-Code: jinaai/jina-embeddings-v2-base-code (code-specific, 8k context)*\n\n### CoIR Benchmark (Full Corpus, Dense Retrieval)\n\n| Benchmark | Corpus | Queries | NDCG@10 |\n|-----------|--------|---------|---------|\n| **CodeSearchNet-Python** | 280K | 14.9K | **74.37%** |\n| **CodeSearchNet-Go** | 280K | 14.9K | **74.51%** |\n| **CodeSearchNet-JavaScript** | 280K | 14.9K | **57.19%** |\n\n*Full CoIR corpus evaluation with dense retrieval (Jina-Code embeddings)*\n\n---\n\n## License\n\nBUSL-1.1\n",
        "bench/README.md": "# Context-Engine Benchmark Suite\n\nReproducible retrieval quality benchmarks with Hit@k, MRR, and latency metrics.\n\n## Quick Start\n\n### 1. Clone the public snapshot\n\n```bash\npython bench/clone_snapshot.py --manifest bench/datasets/public_v1.json\n```\n\nThis clones kubernetes@v1.28.0, vscode@1.86.0, and transformers@v4.37.0 to `bench/data/`.\n\n### 2. Index into Qdrant\n\n```bash\n# Index each repo (adjust paths as needed)\npython scripts/ingest_code.py --root bench/data/kubernetes_kubernetes --collection ctx-bench-k8s\npython scripts/ingest_code.py --root bench/data/microsoft_vscode --collection ctx-bench-vscode\npython scripts/ingest_code.py --root bench/data/huggingface_transformers --collection ctx-bench-hf\n\n# Or create a combined collection\npython scripts/ingest_code.py --root bench/data --collection ctx-bench-public-v1\n```\n\n### 3. Run quality evaluation\n\n```bash\n# Single model, single config\npython bench/eval_quality.py \\\n  --collection ctx-bench-public-v1 \\\n  --model \"BAAI/bge-base-en-v1.5\" \\\n  --gold-file bench/gold/public_v1.queries.jsonl\n```\n\n**Output:**\n```\nMRR: 0.5800\nHit@1: 0.4500\nHit@5: 0.7200\nHit@10: 0.8000\n```\n\n### 4. Run full matrix comparison\n\n```bash\n# Compare models\npython bench/run_matrix.py \\\n  --src ctx-bench-public-v1 \\\n  --gold-file bench/gold/public_v1.queries.jsonl \\\n  --models \"BAAI/bge-base-en-v1.5,sentence-transformers/all-MiniLM-L6-v2\"\n\n# Compare models × configs (A/B testing)\npython bench/run_matrix.py \\\n  --src ctx-bench-public-v1 \\\n  --gold-file bench/gold/public_v1.queries.jsonl \\\n  --config-file bench/configs/ctx_ab_configs.json \\\n  --models \"BAAI/bge-base-en-v1.5\" \\\n  --output results/bench_matrix.json\n```\n\n## Files\n\n| File | Purpose |\n|------|---------|\n| `datasets/public_v1.json` | Snapshot manifest (repos + pinned refs) |\n| `gold/public_v1.queries.jsonl` | 30 gold queries with expected file paths |\n| `configs/ctx_ab_configs.json` | A/B config variants (rerank on/off, RRF weights, etc.) |\n| `clone_snapshot.py` | Clone repos at pinned commits |\n| `eval_quality.py` | Compute Hit@k, MRR against gold set |\n| `eval.py` | Latency harness (p50/p95, Jaccard overlap) |\n| `run_matrix.py` | Orchestrate (model × config) comparison |\n| `copy-coll.py` | Clone/re-embed collections for model comparison |\n\n## Gold Query Format\n\n```jsonl\n{\"id\": \"k8s-eviction-001\", \"query\": \"where is pod eviction logic\", \"repo\": \"kubernetes/kubernetes\", \"relevant\": [{\"path\": \"pkg/kubelet/eviction/eviction_manager.go\"}], \"task_type\": \"navigation\"}\n```\n\n## Metrics\n\n- **Hit@k**: Did any of the top-k results match expected files?\n- **MRR**: Mean Reciprocal Rank (1/rank of first correct result)\n- **Latency p50/p95**: Response time percentiles\n\n## Adding Your Own Queries\n\nEdit `bench/gold/public_v1.queries.jsonl` or create a new file:\n\n```bash\npython bench/eval_quality.py \\\n  --collection my-collection \\\n  --model \"BAAI/bge-base-en-v1.5\" \\\n  --gold-file bench/gold/my_queries.jsonl\n```\n",
        "ctx-mcp-bridge/README.md": "# Context Engine MCP Bridge\n\n`@context-engine-bridge/context-engine-mcp-bridge` provides the `ctxce` CLI, a\nModel Context Protocol (MCP) bridge that speaks to the Context Engine indexer\nand memory servers and exposes them as a single MCP server.\n\nIt is primarily used by the VS Code **Context Engine Uploader** extension,\navailable on the Marketplace:\n\n- <https://marketplace.visualstudio.com/items?itemName=context-engine.context-engine-uploader>\n\nThe bridge can also be run standalone (e.g. from a terminal, or wired into\nother MCP clients) as long as the Context Engine stack is running.\n\n## Prerequisites\n\n- Node.js **>= 18** (see `engines` in `package.json`).\n- A running Context Engine stack (e.g. via `docker-compose.yml`) with:\n  - MCP indexer HTTP endpoint (default: `http://localhost:8003/mcp`).\n  - MCP memory HTTP endpoint (optional, default: `http://localhost:8002/mcp`).\n- For optional auth:\n  - The upload/auth services must be configured with `CTXCE_AUTH_ENABLED=1` and\n    a reachable auth backend URL (e.g. `http://localhost:8004`).\n\n## Installation\n\nYou can install the package globally, or run it via `npx`.\n\n### Global install\n\n```bash\nnpm install -g @context-engine-bridge/context-engine-mcp-bridge\n```\n\nThis installs the `ctxce` (and `ctxce-bridge`) CLI in your PATH.\n\n### Using npx (no global install)\n\n```bash\nnpx @context-engine-bridge/context-engine-mcp-bridge ctxce --help\n```\n\nThe examples below assume `ctxce` is available on your PATH; if you use `npx`,\njust prefix commands with `npx @context-engine-bridge/context-engine-mcp-bridge`.\n\n## CLI overview\n\nThe main entrypoint is:\n\n```bash\nctxce <command> [...args]\n```\n\nSupported commands (from `src/cli.js`):\n\n- `ctxce mcp-serve`        – stdio MCP bridge (for stdio-based MCP clients).\n- `ctxce mcp-http-serve`   – HTTP MCP bridge (for HTTP-based MCP clients).\n- `ctxce auth <subcmd>`    – auth helper commands (`login`, `status`, `logout`).\n\n### Environment variables\n\nThese environment variables are respected by the bridge:\n\n- `CTXCE_INDEXER_URL` – MCP indexer URL (default: `http://localhost:8003/mcp`).\n- `CTXCE_MEMORY_URL`  – MCP memory URL, or empty/omitted to disable memory\n  (default: `http://localhost:8002/mcp`).\n- `CTXCE_HTTP_PORT`   – port for `mcp-http-serve` (default: `30810`).\n\nFor auth (optional, shared with the upload/auth backend):\n\n- `CTXCE_AUTH_ENABLED`       – whether auth is enabled in the backend.\n- `CTXCE_AUTH_BACKEND_URL`   – auth backend URL (e.g. `http://localhost:8004`).\n- `CTXCE_AUTH_TOKEN`         – dev/shared token for `ctxce auth login`.\n- `CTXCE_AUTH_SESSION_TTL_SECONDS` – session TTL / sliding expiry (seconds).\n\nThe CLI also stores auth sessions in `~/.ctxce/auth.json`, keyed by backend URL.\n\n## Running the MCP bridge (stdio)\n\nThe stdio bridge is suitable for MCP clients that speak stdio directly (for\nexample, certain editors or tools that expect an MCP server on stdin/stdout).\n\n```bash\nctxce mcp-serve \\\n  --workspace /path/to/your/workspace \\\n  --indexer-url http://localhost:8003/mcp \\\n  --memory-url http://localhost:8002/mcp\n```\n\nFlags:\n\n- `--workspace` / `--path` – workspace root (default: current working directory).\n- `--indexer-url`          – override indexer URL (default: `CTXCE_INDEXER_URL` or\n  `http://localhost:8003/mcp`).\n- `--memory-url`           – override memory URL (default: `CTXCE_MEMORY_URL` or\n  disabled when empty).\n\n## Running the MCP bridge (HTTP)\n\nThe HTTP bridge exposes the MCP server via an HTTP endpoint (default\n`http://127.0.0.1:30810/mcp`) and is what the VS Code extension uses in its\n`http` transport mode.\n\n```bash\nctxce mcp-http-serve \\\n  --workspace /path/to/your/workspace \\\n  --indexer-url http://localhost:8003/mcp \\\n  --memory-url http://localhost:8002/mcp \\\n  --port 30810\n```\n\nFlags:\n\n- `--workspace` / `--path` – workspace root (default: current working directory).\n- `--indexer-url`          – MCP indexer URL.\n- `--memory-url`           – MCP memory URL (or omit/empty to disable memory).\n- `--port`                 – HTTP port for the bridge (default: `CTXCE_HTTP_PORT`\n  or `30810`).\n\nOnce running, you can point an MCP client at:\n\n```text\nhttp://127.0.0.1:<port>/mcp\n```\n\n## Auth helper commands (`ctxce auth ...`)\n\nThese commands are used both by the VS Code extension and standalone flows to\nlog in and manage auth sessions for the backend.\n\n### Login (token)\n\n```bash\nctxce auth login \\\n  --backend-url http://localhost:8004 \\\n  --token $CTXCE_AUTH_SHARED_TOKEN\n```\n\nThis hits the backend `/auth/login` endpoint and stores a session entry in\n`~/.ctxce/auth.json` under the given backend URL.\n\n### Login (username/password)\n\n```bash\nctxce auth login \\\n  --backend-url http://localhost:8004 \\\n  --username your-user \\\n  --password your-password\n```\n\nThis calls `/auth/login/password` and persists the returned session the same\nway as the token flow.\n\n### Status\n\nHuman-readable status:\n\n```bash\nctxce auth status --backend-url http://localhost:8004\n```\n\nMachine-readable status (used by the VS Code extension):\n\n```bash\nctxce auth status --backend-url http://localhost:8004 --json\n```\n\nThe `--json` variant prints a single JSON object to stdout, for example:\n\n```json\n{\n  \"backendUrl\": \"http://localhost:8004\",\n  \"state\": \"ok\",           // \"ok\" | \"missing\" | \"expired\" | \"missing_backend\"\n  \"sessionId\": \"...\",\n  \"userId\": \"user-123\",\n  \"expiresAt\": 0           // 0 or a Unix timestamp\n}\n```\n\nExit codes:\n\n- `0` – `state: \"ok\"` (valid session present).\n- `1` – `state: \"missing\"` or `\"missing_backend\"`.\n- `2` – `state: \"expired\"`.\n\n### Logout\n\n```bash\nctxce auth logout --backend-url http://localhost:8004\n```\n\nRemoves the stored auth entry for the given backend URL from\n`~/.ctxce/auth.json`.\n\n## Relationship to the VS Code extension\n\nThe VS Code **Context Engine Uploader** extension is the recommended way to use\nthis bridge for day-to-day development. It:\n\n- Launches the standalone upload client to push code into the remote stack.\n- Starts/stops the MCP HTTP bridge (`ctxce mcp-http-serve`) for the active\n  workspace when `autoStartMcpBridge` is enabled.\n- Uses `ctxce auth status --json` and `ctxce auth login` under the hood to\n  manage user sessions via UI prompts.\n\nThis package README is aimed at advanced users who want to:\n\n- Run the MCP bridge outside of VS Code.\n- Integrate the Context Engine MCP servers with other MCP-compatible clients.\n\nYou can safely mix both approaches: the extension and the standalone bridge\nshare the same auth/session storage in `~/.ctxce/auth.json`.\n",
        "deploy/helm/context-engine/README.md": "# Context-Engine Helm Chart\n\nSelf-hosted semantic code search and memory via MCP.\n\n## Prerequisites\n\n- Kubernetes 1.19+\n- Helm 3.2.0+\n- PV provisioner support (for persistent storage)\n- Storage classes: `gp3-sc` (block) and `efs-sc` (shared filesystem) or equivalents\n\n## Installation\n\n### Quick Start\n\n```bash\n# Add local chart\nhelm install ce-dev ./deploy/helm/context-engine \\\n  --namespace context-engine \\\n  --create-namespace\n```\n\n### With Custom Values\n\n```bash\n# Copy the example values and customize\ncp deploy/helm/context-engine/values-example.yaml deploy/kubernetes/values-mycompany.yaml\n# Edit deploy/kubernetes/values-mycompany.yaml with your settings\n\n# Install with custom values\nhelm install ce-mycompany ./deploy/helm/context-engine \\\n  -f ./deploy/kubernetes/values-mycompany.yaml \\\n  --namespace context-engine \\\n  --create-namespace\n```\n\n**Note**: Customer-specific values files should be stored in `deploy/kubernetes/` (gitignored) to keep sensitive configuration separate from the chart.\n\n### From OCI Registry (when published)\n\n```bash\nhelm install ce-prod oci://ghcr.io/context-engine-ai/charts/context-engine \\\n  --version 0.1.0 \\\n  --namespace context-engine \\\n  --create-namespace \\\n  -f custom-values.yaml\n```\n\n## Uninstall\n\n```bash\nhelm uninstall ce-dev --namespace context-engine\n```\n\n## Configuration\n\n### Global Settings\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `global.environment` | Environment name (dev, staging, prod) | `dev` |\n| `global.team` | Team label for resources | `ai` |\n| `global.appName` | Application name for labels | `context-engine` |\n\n### Image\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `image.repository` | Image repository | `context-engine` |\n| `image.tag` | Image tag (defaults to Chart appVersion) | `\"\"` |\n| `image.pullPolicy` | Pull policy | `IfNotPresent` |\n| `image.pullSecrets` | Image pull secrets | `[]` |\n\n### Namespace\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `namespace.create` | Create namespace | `true` |\n| `namespace.name` | Namespace name | `context-engine` |\n\n### Qdrant\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `qdrant.enabled` | Enable Qdrant | `true` |\n| `qdrant.image.repository` | Qdrant image | `qdrant/qdrant` |\n| `qdrant.image.tag` | Qdrant version | `latest` |\n| `qdrant.replicas` | Number of replicas | `1` |\n| `qdrant.service.httpPort` | HTTP port | `6333` |\n| `qdrant.service.grpcPort` | gRPC port | `6334` |\n| `qdrant.externalService.enabled` | Enable NodePort service | `true` |\n| `qdrant.externalService.httpNodePort` | HTTP NodePort | `30333` |\n| `qdrant.persistence.enabled` | Enable persistence | `true` |\n| `qdrant.persistence.storageClassName` | Storage class | `gp3-sc` |\n| `qdrant.persistence.size` | Storage size | `50Gi` |\n| `qdrant.resources.requests.cpu` | CPU request | `1` |\n| `qdrant.resources.requests.memory` | Memory request | `8Gi` |\n| `qdrant.resources.limits.cpu` | CPU limit | `4` |\n| `qdrant.resources.limits.memory` | Memory limit | `24Gi` |\n\n### MCP Indexer HTTP\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `mcpIndexerHttp.enabled` | Enable indexer | `true` |\n| `mcpIndexerHttp.replicas` | Number of replicas | `1` |\n| `mcpIndexerHttp.service.port` | Service port | `8003` |\n| `mcpIndexerHttp.externalService.nodePort` | NodePort | `30806` |\n| `mcpIndexerHttp.autoscaling.enabled` | Enable HPA | `true` |\n| `mcpIndexerHttp.autoscaling.minReplicas` | Min replicas | `1` |\n| `mcpIndexerHttp.autoscaling.maxReplicas` | Max replicas | `4` |\n| `mcpIndexerHttp.resources.requests.memory` | Memory request | `8Gi` |\n| `mcpIndexerHttp.resources.limits.memory` | Memory limit | `16Gi` |\n\n### MCP Memory HTTP\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `mcpMemoryHttp.enabled` | Enable memory service | `true` |\n| `mcpMemoryHttp.replicas` | Number of replicas | `1` |\n| `mcpMemoryHttp.service.port` | Service port | `8002` |\n| `mcpMemoryHttp.externalService.nodePort` | NodePort | `30804` |\n| `mcpMemoryHttp.autoscaling.enabled` | Enable HPA | `true` |\n| `mcpMemoryHttp.autoscaling.minReplicas` | Min replicas | `1` |\n| `mcpMemoryHttp.autoscaling.maxReplicas` | Max replicas | `3` |\n\n### Upload Service\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `uploadService.enabled` | Enable upload service | `true` |\n| `uploadService.replicas` | Number of replicas | `1` |\n| `uploadService.service.port` | Service port | `8002` |\n| `uploadService.service.nodePort` | NodePort | `30810` |\n| `uploadService.autoscaling.enabled` | Enable HPA | `true` |\n\n### Watcher\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `watcher.enabled` | Enable watcher | `true` |\n| `watcher.replicas` | Number of replicas | `1` |\n| `watcher.initContainers.waitForQdrant.enabled` | Wait for Qdrant | `true` |\n| `watcher.initContainers.initCollection.enabled` | Init collection | `true` |\n\n### Learning Reranker Worker\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `learningRerankerWorker.enabled` | Enable learning worker | `true` |\n| `learningRerankerWorker.replicas` | Number of replicas | `1` |\n| `learningRerankerWorker.autoscaling.enabled` | Enable HPA | `true` |\n\n### Persistence (Shared PVCs)\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `persistence.codeRepos.enabled` | Enable code-repos PVC | `true` |\n| `persistence.codeRepos.storageClassName` | Storage class | `efs-sc` |\n| `persistence.codeRepos.size` | Storage size | `50Gi` |\n| `persistence.codeMetadata.enabled` | Enable metadata PVC | `true` |\n| `persistence.codeMetadata.size` | Storage size | `10Gi` |\n| `persistence.codeModels.enabled` | Enable models PVC | `true` |\n| `persistence.codeModels.size` | Storage size | `20Gi` |\n\n### Ingress\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `ingress.enabled` | Enable ingress | `true` |\n| `ingress.className` | Ingress class | `nginx` |\n| `ingress.host` | Hostname | `\"\"` |\n| `ingress.tls` | TLS configuration | `[]` |\n| `ingress.admin.enabled` | Enable admin ingress | `true` |\n\n### Configuration (ConfigMap)\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `config.collectionName` | Qdrant collection name | `codebase` |\n| `config.embeddingModel` | Embedding model | `BAAI/bge-base-en-v1.5` |\n| `config.embeddingProvider` | Embedding provider | `fastembed` |\n| `config.reranker.enabled` | Enable reranker | `1` |\n| `config.reranker.model` | Reranker model | `jinaai/jina-reranker-v2-base-multilingual` |\n| `config.refrag.enabled` | Enable ReFRAG | `1` |\n| `config.refrag.runtime` | Decoder runtime | `glm` |\n| `config.glm.apiBase` | GLM API base URL | `\"\"` |\n| `config.glm.apiKey` | GLM API key | `\"\"` |\n| `config.glm.model` | GLM model | `glm-4.7` |\n| `config.auth.enabled` | Enable auth | `0` |\n| `config.extraEnv` | Additional env vars | `{}` |\n\n## Examples\n\n### Minimal Installation (Dev/Testing)\n\n```yaml\n# values-minimal.yaml\nqdrant:\n  persistence:\n    storageClassName: standard\n    size: 10Gi\n\npersistence:\n  codeRepos:\n    storageClassName: standard\n    size: 10Gi\n  codeMetadata:\n    storageClassName: standard\n    size: 5Gi\n  codeModels:\n    storageClassName: standard\n    size: 5Gi\n\n# Disable optional components\nlearningRerankerWorker:\n  enabled: false\n\ningress:\n  enabled: false\n```\n\n### Production with TLS\n\n```yaml\n# values-prod.yaml\nimage:\n  repository: 535002867043.dkr.ecr.us-east-1.amazonaws.com/context-engine\n  tag: v1.0.0\n\nconfig:\n  collectionName: production-codebase\n  auth:\n    enabled: \"1\"\n    sharedToken: \"your-token-here\"\n\ningress:\n  enabled: true\n  className: alb\n  host: ce.example.com\n  annotations:\n    alb.ingress.kubernetes.io/scheme: internet-facing\n    alb.ingress.kubernetes.io/certificate-arn: arn:aws:acm:...\n  tls:\n    - hosts:\n        - ce.example.com\n      secretName: ce-tls\n```\n\n### With GLM Decoder\n\n```yaml\n# values-with-decoder.yaml\nconfig:\n  refrag:\n    mode: \"1\"\n    decoder: \"1\"\n    decoderMode: prompt\n    runtime: glm\n  glm:\n    apiBase: \"https://api.z.ai/api/coding/paas/v4/\"\n    apiKey: \"your-api-key\"\n    model: glm-4.7\n```\n\n### Multi-Repo Mode\n\n```yaml\n# values-multi-repo.yaml\nconfig:\n  multiRepoMode: \"1\"\n  repoAutoFilter: \"1\"\n  collectionName: multi-repo-collection\n\nwatcher:\n  env:\n    MULTI_REPO_MODE: \"1\"\n```\n\n## Architecture\n\n```\n┌─────────────────────────────────────────────────────────────────┐\n│                        Ingress (nginx)                          │\n│  /indexer → mcp-indexer-http    /memory → mcp-memory-http       │\n│  /upload → upload-service       /qdrant → qdrant                │\n└──────────────────────────────┬──────────────────────────────────┘\n                               │\n     ┌─────────────────────────┼─────────────────────────┐\n     │                         │                         │\n┌────┴────┐              ┌─────┴─────┐            ┌──────┴──────┐\n│ Indexer │              │  Memory   │            │   Upload    │\n│  HTTP   │              │   HTTP    │            │   Service   │\n└────┬────┘              └─────┬─────┘            └──────┬──────┘\n     │                         │                         │\n     └─────────────────────────┼─────────────────────────┘\n                               │\n                         ┌─────┴─────┐\n                         │  Qdrant   │\n                         │(StatefulSet)\n                         └───────────┘\n                               ▲\n     ┌─────────────────────────┼─────────────────────────┐\n     │                         │                         │\n┌────┴────┐              ┌─────┴─────┐            ┌──────┴──────┐\n│ Watcher │              │ Learning  │            │   Shared    │\n│         │              │  Worker   │            │    PVCs     │\n└─────────┘              └───────────┘            └─────────────┘\n```\n\n## Storage Classes\n\nThe chart expects two types of storage:\n\n1. **Block storage** (`gp3-sc`): For Qdrant StatefulSet (ReadWriteOnce)\n2. **Shared filesystem** (`efs-sc`): For code-repos, metadata, models (ReadWriteMany)\n\n### AWS EKS Example\n\n```yaml\n# gp3-sc.yaml\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: gp3-sc\nprovisioner: ebs.csi.aws.com\nparameters:\n  type: gp3\nvolumeBindingMode: WaitForFirstConsumer\nallowVolumeExpansion: true\n\n---\n# efs-sc.yaml\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: efs-sc\nprovisioner: efs.csi.aws.com\nparameters:\n  provisioningMode: efs-ap\n  fileSystemId: fs-xxxxxxxxx\n  directoryPerms: \"700\"\n```\n\n## Upgrading\n\n```bash\nhelm upgrade ce-dev ./deploy/helm/context-engine \\\n  -f values-dev.yaml \\\n  --namespace context-engine\n```\n\n## Troubleshooting\n\n### Check Pod Status\n\n```bash\nkubectl get pods -n context-engine\nkubectl describe pod <pod-name> -n context-engine\n```\n\n### View Logs\n\n```bash\n# Indexer logs\nkubectl logs -n context-engine -l app.kubernetes.io/component=mcp-indexer-http\n\n# Watcher logs\nkubectl logs -n context-engine -l app.kubernetes.io/component=watcher\n\n# Qdrant logs\nkubectl logs -n context-engine -l app.kubernetes.io/component=qdrant\n```\n\n### Common Issues\n\n1. **Pods pending**: Check PVC status and storage class availability\n2. **Watcher init fails**: Verify Qdrant is running and accessible\n3. **Memory OOM**: Increase memory limits for indexer/memory services\n4. **Ingress not working**: Verify ingress controller and annotations\n\n## License\n\nBUSL-1.1\n",
        "deploy/kubernetes/README.md": "# Kubernetes Deployment Guide\n\n**Documentation:** [README](../../README.md) · [Configuration](../../docs/CONFIGURATION.md) · [IDE Clients](../../docs/IDE_CLIENTS.md) · [MCP API](../../docs/MCP_API.md) · [ctx CLI](../../docs/CTX_CLI.md) · [Memory Guide](../../docs/MEMORY_GUIDE.md) · [Architecture](../../docs/ARCHITECTURE.md) · [Multi-Repo](../../docs/MULTI_REPO_COLLECTIONS.md) · Kubernetes · [VS Code Extension](../../docs/vscode-extension.md) · [Troubleshooting](../../docs/TROUBLESHOOTING.md) · [Development](../../docs/DEVELOPMENT.md)\n\n---\n\n## Overview\n\nThis directory contains Kubernetes manifests for deploying Context Engine on a remote cluster using **Kustomize**. This enables:\n\n- **Remote development** from thin clients with cluster-based heavy lifting\n- **Multi-repository indexing** with unified `codebase` collection\n- **Scalable architecture** with independent watcher deployments per repo\n- **Kustomize-based configuration** for easy customization and overlays\n\n## Architecture\n\n```mermaid\ngraph TB\n    subgraph cluster[\"Kubernetes Cluster (namespace: context-engine)\"]\n        subgraph ingress[\"Ingress Layer\"]\n            nginx[\"NGINX Ingress<br/>Routes: /qdrant, /mcp/*, /mcp-http/*, /llamacpp\"]\n        end\n\n        subgraph services[\"Core Services\"]\n            qdrant[\"Qdrant StatefulSet<br/>Port: 6333<br/>Vector Database\"]\n\n            subgraph mcp[\"MCP Services (4 Deployments)\"]\n                mcp_mem_sse[\"Memory SSE<br/>Port: 8000\"]\n                mcp_mem_http[\"Memory HTTP<br/>Port: 8002\"]\n                mcp_idx_sse[\"Indexer SSE<br/>Port: 8001<br/>(HPA: 1-5 replicas)\"]\n                mcp_idx_http[\"Indexer HTTP<br/>Port: 8003\"]\n            end\n\n            llama[\"Llama.cpp Deployment<br/>Port: 8080<br/>Init: Model Download\"]\n            watcher[\"Watcher Deployment<br/>Watches: /work\"]\n        end\n\n        subgraph security[\"Security & Scaling\"]\n            rbac[\"RBAC: ServiceAccount<br/>(context-engine)\"]\n            netpol[\"NetworkPolicy<br/>Intra-namespace ingress<br/>for watcher/indexer/init\"]\n            hpa[\"HPA: mcp-indexer<br/>1-5 replicas @ 70% CPU\"]\n        end\n\n        subgraph storage[\"Persistent Storage (HostPath)\"]\n            qdrant_vol[\"Qdrant Data<br/>/tmp/context-engine-qdrant\"]\n            models_vol[\"LLM Models<br/>/tmp/context-engine-models\"]\n            work_vol[\"Workspace<br/>/tmp/context-engine-work\"]\n        end\n    end\n\n    nginx --> qdrant\n    nginx --> mcp\n    nginx --> llama\n\n    mcp --> qdrant\n    llama -.-> mcp\n    watcher --> qdrant\n\n    qdrant --> qdrant_vol\n    llama --> models_vol\n    watcher --> work_vol\n\n    style nginx fill:#e1f5ff\n    style qdrant fill:#fff4e1\n    style mcp fill:#e8f5e9\n    style llama fill:#f3e5f5\n    style watcher fill:#fce4ec\n    style security fill:#fff9c4\n    style storage fill:#e0e0e0\n```\n\n## Quick Start\n\n### Prerequisites\n\n- Kubernetes cluster (1.19+)\n- `kubectl` configured to access your cluster\n- `kustomize` (optional, kubectl has built-in support)\n- Docker image built and pushed to a registry\n\n### 1. Build and Push Image\n\n```bash\n# Build unified image\ndocker build -t your-registry/context-engine:latest .\n\n# Push to registry\ndocker push your-registry/context-engine:latest\n```\n\n### 2. Update Image References\n\nEdit `kustomization.yaml` to use your registry:\n\n```yaml\nimages:\n  - name: context-engine\n    newName: your-registry/context-engine\n    newTag: latest\n```\n\n### 3. Deploy Using Kustomize\n\n```bash\n# Option 1: Using the deploy script with Kustomize (recommended)\n./deploy.sh --use-kustomize --registry your-registry/context-engine --tag latest --deploy-ingress\n\n# Option 2: Using kubectl with kustomize directly\nkubectl apply -k .\n\n# Option 3: Using kustomize CLI\nkustomize build . | kubectl apply -f -\n\n# Option 4: Using the deploy script without Kustomize (legacy)\n./deploy.sh --registry your-registry/context-engine --tag latest --deploy-ingress\n```\n\n**Deploy Script Flags:**\n- `--use-kustomize`: Use Kustomize for declarative image management (recommended)\n- `--registry <registry/name>`: Docker registry and image name (default: context-engine)\n- `--tag <tag>`: Image tag (default: latest)\n- `--deploy-ingress`: Deploy NGINX ingress routes\n- `--skip-llamacpp`: Skip llama.cpp decoder deployment\n\n### 4. Deploy Using Makefile\n\n```bash\n# Deploy all services\nmake deploy\n\n# Or deploy core services only\nmake deploy-core\n\n# Check status\nmake status\n```\n\n### 5. Verify Deployment\n\n```bash\n# Check all pods are running\nkubectl get pods -n context-engine\n\n# Check services\nkubectl get svc -n context-engine\n\n# View logs\nmake logs-service SERVICE=mcp-memory\n```\n\n### 6. Access Services\n\n```bash\n# Port forward to localhost\nmake port-forward\n\n# Or access via NodePort\n# Qdrant: http://<node-ip>:30333\n# MCP Memory: http://<node-ip>:30800\n# MCP Indexer: http://<node-ip>:30802\n```\n\n## Configuration\n\n### Automatic Model Download\n\nThe Llama.cpp deployment includes an **init container** that automatically downloads the model on first startup:\n\n- **Default Model**: Qwen2.5-1.5B-Instruct (Q8_0 quantization, ~1.7GB)\n- **Download Location**: `/tmp/context-engine-models/` on the Kubernetes node\n- **Behavior**: Downloads only if model doesn't exist (idempotent)\n- **Good balance**: Fast, accurate, small footprint\n\nTo use a different model, edit `configmap.yaml`:\n\n```yaml\n# Model download configuration\nLLAMACPP_MODEL_URL: \"https://huggingface.co/your-org/your-model/resolve/main/model.gguf\"\nLLAMACPP_MODEL_NAME: \"model.gguf\"\n```\n\n**Alternative Models**:\n- **Qwen2.5-0.5B-Instruct-Q8** (~500MB) - Tiny, very fast\n- **Qwen2.5-1.5B-Instruct-Q8** (default, ~1.7GB) - Best balance\n- **Granite-3.0-3B-Instruct-Q8** (~3.2GB) - Higher quality\n- **Phi-3-mini-4k-instruct-Q8** (~4GB) - High quality\n\n### Environment Variables (ConfigMap)\n\nKey environment variables in `configmap.yaml`:\n\n```yaml\nCOLLECTION_NAME: \"codebase\"           # Unified collection for all repos\nEMBEDDING_MODEL: \"BAAI/bge-base-en-v1.5\"\nQDRANT_URL: \"http://qdrant:6333\"\nINDEX_MICRO_CHUNKS: \"1\"\nMAX_MICRO_CHUNKS_PER_FILE: \"200\"\nWATCH_DEBOUNCE_SECS: \"1.5\"\n```\n\nRedis-backed .codebase state (K8s):\n\n```yaml\nCODEBASE_STATE_BACKEND: \"redis\"        # or set CODEBASE_STATE_REDIS_ENABLED: \"1\"\nCODEBASE_STATE_REDIS_URL: \"redis://redis:6379/0\"\n```\n\n#### Syncing `configmap.yaml` from `.env`\n\nIf you treat a `.env` file as the source of truth for configuration, you can use the helper script `scripts/sync_env_to_k8s.py` to keep `deploy/kubernetes/configmap.yaml` and the workloads in sync:\n\n```bash\ncd /path/to/Context-Engine\npython3 scripts/sync_env_to_k8s.py --env-file .env --k8s-dir deploy/kubernetes\n```\n\nThis will:\n\n- Regenerate `deploy/kubernetes/configmap.yaml` so its `data:` keys match the provided `.env` (excluding sensitive keys such as `GLM_API_KEY` by default).\n- Ensure all Deployments and Jobs in `deploy/kubernetes/` include:\n\n  ```yaml\n  envFrom:\n    - configMapRef:\n        name: context-engine-config\n  ```\n\nIn CI (for example Bamboo), you can run the same script against the workspace copy of the manifests before `kustomize build . | kubectl apply -f -`, and then provide any sensitive values (such as `GLM_API_KEY`) via Kubernetes `Secret` resources or per-environment overrides instead of committing them to git.\n\n### Persistent Volumes\n\nThe deployment uses HostPath volumes for simplicity (suitable for single-node clusters like minikube):\n\n1. **qdrant-storage**: Stores Qdrant vector database\n   - Path: `/tmp/context-engine-qdrant`\n   - Type: DirectoryOrCreate\n\n2. **models-storage**: Stores LLM models for llama.cpp\n   - Path: `/tmp/context-engine-models`\n   - Type: DirectoryOrCreate\n\n3. **work-storage**: Stores workspace/repository code\n   - Path: `/tmp/context-engine-work`\n   - Type: DirectoryOrCreate\n   - Mounted at: `/work` in containers\n\nFor multi-node production clusters, replace HostPath with PersistentVolumeClaims (PVCs) backed by network storage (NFS, Ceph, cloud provider volumes).\n\n### Resource Requests/Limits\n\nAdjust based on your cluster capacity:\n\n```yaml\n# Qdrant (memory-intensive)\nresources:\n  requests:\n    memory: \"4Gi\"\n    cpu: \"2\"\n  limits:\n    memory: \"8Gi\"\n    cpu: \"4\"\n\n# MCP Servers (moderate)\nresources:\n  requests:\n    memory: \"2Gi\"\n    cpu: \"1\"\n  limits:\n    memory: \"4Gi\"\n    cpu: \"2\"\n\n# Watchers (light)\nresources:\n  requests:\n    memory: \"512Mi\"\n    cpu: \"500m\"\n  limits:\n    memory: \"1Gi\"\n    cpu: \"1\"\n```\n\n## Workspace Setup\n\n### Indexing Your Codebase\n\nThe deployment indexes the codebase mounted at `/work` inside containers, which maps to `/tmp/context-engine-work` on the host.\n\n1. **Copy your codebase to the workspace volume**:\n   ```bash\n   # For minikube (single-node)\n   minikube ssh\n   sudo mkdir -p /tmp/context-engine-work\n   exit\n\n   # Copy your code\n   kubectl cp /local/path/to/your/repo context-engine/watcher-<pod-id>:/work\n\n   # Or mount directly on the host\n   cp -r /local/path/to/your/repo /tmp/context-engine-work/\n   ```\n\n2. **Verify indexing**:\n   ```bash\n   # Check watcher logs\n   kubectl logs -f deployment/watcher -n context-engine\n\n   # Check indexer job completion\n   kubectl get jobs -n context-engine\n\n   # Check collection status via MCP\n   kubectl port-forward -n context-engine svc/mcp-indexer 8001:8001\n   curl -X POST http://localhost:8001/mcp \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/call\",\"params\":{\"name\":\"qdrant_status\",\"arguments\":{}}}'\n   ```\n\n### Workspace Volume Structure\n\n```\n/work/                          # Container mount point\n├── .codebase/                  # Indexing metadata\n│   └── state.json\n├── src/                        # Your source code\n├── tests/\n├── docs/\n└── ...\n```\n\n**Note**: The current deployment uses a single workspace at `/work`. For multi-repository setups, you can:\n- Use subdirectories under `/work` (e.g., `/work/backend`, `/work/frontend`)\n- Deploy multiple watcher instances with different `WATCH_ROOT` environment variables\n- Use a unified collection or separate collections per repository\n\n## Accessing Services\n\n### From Within Cluster\n\nServices are accessible via Kubernetes DNS:\n\n- Qdrant: `http://qdrant:6333`\n- Memory MCP: `http://mcp-memory:8000/sse`\n- Indexer MCP: `http://mcp-indexer:8001/sse`\n\n### From Outside Cluster\n\n#### Option 1: Port Forwarding (Development)\n\n```bash\n# Forward MCP services to localhost\nkubectl port-forward -n context-engine svc/mcp-memory 8000:8000\nkubectl port-forward -n context-engine svc/mcp-indexer 8001:8001\nkubectl port-forward -n context-engine svc/qdrant 6333:6333\n```\n\nThen configure your IDE to use `http://localhost:8000/sse` and `http://localhost:8001/sse`.\n\n#### Option 2: Ingress (Production)\n\n```yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: context-engine-ingress\n  namespace: context-engine\nspec:\n  rules:\n  - host: mcp.your-domain.com\n    http:\n      paths:\n      - path: /memory\n        pathType: Prefix\n        backend:\n          service:\n            name: mcp-memory\n            port:\n              number: 8000\n      - path: /indexer\n        pathType: Prefix\n        backend:\n          service:\n            name: mcp-indexer\n            port:\n              number: 8001\n```\n\n#### Option 3: LoadBalancer (Cloud)\n\nChange service type to `LoadBalancer` in service manifests:\n\n```yaml\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 8000\n    targetPort: 8000\n```\n\n## Monitoring and Maintenance\n\n### Health Checks\n\n```bash\n# Check Qdrant health\nkubectl exec -n context-engine qdrant-0 -- curl -f http://localhost:6333/readyz\n\n# Check MCP server health\nkubectl exec -n context-engine deployment/mcp-memory -- curl -f http://localhost:18000/health\nkubectl exec -n context-engine deployment/mcp-indexer -- curl -f http://localhost:18001/health\n```\n\n### Logs\n\n```bash\n# View logs for specific service\nkubectl logs -f -n context-engine deployment/mcp-memory\nkubectl logs -f -n context-engine deployment/mcp-indexer\nkubectl logs -f -n context-engine deployment/watcher\n\n# View logs for all watchers (if multiple)\nkubectl logs -f -n context-engine -l component=watcher\n```\n\n### Collection Status\n\n```bash\n# Port forward indexer MCP\nkubectl port-forward -n context-engine svc/mcp-indexer 8001:8001\n\n# Check collection status\ncurl -X POST http://localhost:8001/mcp \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"jsonrpc\":\"2.0\",\"id\":1,\"method\":\"tools/call\",\"params\":{\"name\":\"qdrant_status\",\"arguments\":{}}}'\n```\n\n### Backup and Restore\n\n#### Backup Qdrant Data\n\n```bash\n# Create snapshot\nkubectl exec -n context-engine qdrant-0 -- \\\n  curl -X POST http://localhost:6333/collections/codebase/snapshots\n\n# Copy snapshot to local\nkubectl cp context-engine/qdrant-0:/qdrant/storage/snapshots/codebase-snapshot.tar \\\n  ./backup/codebase-snapshot.tar\n```\n\n#### Restore Qdrant Data\n\n```bash\n# Copy snapshot to pod\nkubectl cp ./backup/codebase-snapshot.tar \\\n  context-engine/qdrant-0:/qdrant/storage/snapshots/\n\n# Restore snapshot\nkubectl exec -n context-engine qdrant-0 -- \\\n  curl -X PUT http://localhost:6333/collections/codebase/snapshots/upload \\\n  -F 'snapshot=@/qdrant/storage/snapshots/codebase-snapshot.tar'\n```\n\n## Troubleshooting\n\n### Pods Not Starting\n\n```bash\n# Check pod status\nkubectl describe pod -n context-engine <pod-name>\n\n# Check events\nkubectl get events -n context-engine --sort-by='.lastTimestamp'\n```\n\n### Persistent Volume Issues\n\n```bash\n# Check PV/PVC status\nkubectl get pv,pvc -n context-engine\n\n# Check PVC events\nkubectl describe pvc -n context-engine <pvc-name>\n```\n\n### Watcher Not Indexing\n\n```bash\n# Check watcher logs\nkubectl logs -f -n context-engine deployment/watcher\n\n# Verify volume mount\nkubectl exec -n context-engine deployment/watcher -- ls -la /work\n\n# Check Qdrant connectivity\nkubectl exec -n context-engine deployment/watcher -- \\\n  curl -f http://qdrant:6333/readyz\n```\n\n### MCP Connection Issues\n\n```bash\n# Test SSE endpoint\nkubectl exec -n context-engine deployment/mcp-indexer -- \\\n  curl -H \"Accept: text/event-stream\" http://localhost:8001/sse\n\n# Check service endpoints\nkubectl get endpoints -n context-engine\n```\n\n## Scaling\n\n### Horizontal Scaling\n\n- **MCP Servers**: Can run multiple replicas behind a service\n- **Watchers**: One per repository (do not scale horizontally)\n- **Qdrant**: Single instance (StatefulSet with replicas=1)\n\n### Vertical Scaling\n\nAdjust resource requests/limits based on workload:\n\n```bash\n# Edit deployment\nkubectl edit deployment -n context-engine mcp-indexer\n\n# Or patch\nkubectl patch deployment -n context-engine mcp-indexer -p \\\n  '{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"mcp-indexer\",\"resources\":{\"requests\":{\"memory\":\"4Gi\"}}}]}}}}'\n```\n\n## Security Considerations\n\n### Implemented Security Features\n\n1. **RBAC (Role-Based Access Control)**\n   - ServiceAccount: `context-engine` created in `rbac.yaml`\n   - Applied to all Deployments and Jobs\n   - Provides pod identity for Kubernetes API authentication\n   - Future: Add Role/RoleBinding for fine-grained permissions\n\n2. **NetworkPolicy (Soft Hardening - Option B)**\n   - Policy: `allow-intra-namespace-ingress-internal` in `networkpolicy.yaml`\n   - Scope: Applies to watcher, indexer, and init pods\n   - Rules: Allows ingress only from pods in the same namespace\n   - No egress restrictions (external downloads and Qdrant access work)\n   - MCP services and Qdrant remain accessible via Ingress/NodePort\n   - Future: Implement Option A (default-deny with explicit allow rules)\n\n3. **HorizontalPodAutoscaler (HPA)**\n   - Target: mcp-indexer deployment\n   - Min replicas: 1, Max replicas: 5\n   - Trigger: 70% CPU utilization\n   - Prevents resource exhaustion under load\n\n### Additional Security Recommendations\n\n4. **Secrets Management**: Use Kubernetes secrets or external secret managers for sensitive data\n5. **TLS**: Enable TLS for external access via Ingress with cert-manager\n6. **Resource Quotas**: Set namespace resource quotas to prevent resource exhaustion\n7. **Pod Security Standards**: Apply restricted pod security standards\n8. **Image Security**: Use signed images and vulnerability scanning\n\n## See Also\n\n- [Multi-Repository Collections Guide](../../docs/MULTI_REPO_COLLECTIONS.md)\n- [MCP API Reference](../../docs/MCP_API.md)\n- [Architecture Overview](../../docs/ARCHITECTURE.md)\n",
        "plugins/neo4j_graph/README.md": "# Neo4j Knowledge Graph Plugin\n\nStandalone Neo4j graph backend plugin for Context-Engine.\n\n## Licensing Requirements\n\n### Context-Engine Neo4j Plugin License\n\n**Free for:**\n- Local development and testing\n- Evaluation and proof-of-concept\n- Non-commercial personal projects\n\n**Commercial license required for:**\n- Production deployments\n- Commercial use (revenue-generating applications)\n- Redistribution or inclusion in commercial products\n- Hosted/managed services\n\n**Contact for commercial licensing:** mirlok89@gmail.com\n\n### Neo4j Database License\n\nThis plugin also requires Neo4j database software, licensed separately by Neo4j, Inc.:\n\n| Neo4j Edition | License | Use Case |\n|---------------|---------|----------|\n| **Community Edition** | GPL v3 | Open source projects, development, testing |\n| **Enterprise Edition** | Commercial | Production deployments requiring enterprise features |\n| **AuraDB (Cloud)** | Subscription | Managed cloud service |\n\nYou must independently comply with [Neo4j's licensing terms](https://neo4j.com/licensing/).\n\nNeo4j® is a registered trademark of Neo4j, Inc.\n\n---\n\n## Overview\n\nThis plugin provides a Neo4j-based graph backend as an alternative to the default Qdrant graph storage. It enables:\n\n- **Rich graph traversals** - Multi-hop caller/callee chains via Cypher\n- **Graph algorithms** - PageRank, community detection, path finding\n- **Knowledge graph** - Semantic relationships beyond calls/imports\n- **Graph RAG** - Context retrieval using graph structure\n\n## Installation\n\nCopy the plugin directory to your Context-Engine deployment:\n\n```bash\ncp -r plugins/neo4j_graph /path/to/your/deployment/plugins/\n```\n\nInstall the Neo4j driver:\n\n```bash\npip install neo4j>=5.0.0\n```\n\n## Configuration\n\n### Environment Variables\n\n| Variable | Required | Default | Description |\n|----------|----------|---------|-------------|\n| `NEO4J_GRAPH` | Yes | `0` | Set to `1` to enable Neo4j backend |\n| `NEO4J_PASSWORD` | Yes | - | Neo4j authentication password |\n| `NEO4J_URI` | No | `bolt://neo4j:7687` | Neo4j Bolt connection URI |\n| `NEO4J_USER` | No | `neo4j` | Neo4j username |\n| `NEO4J_DATABASE` | No | `neo4j` | Neo4j database name |\n| `NEO4J_MAX_POOL_SIZE` | No | `50` | Connection pool size |\n\n### Docker Compose\n\nUse the provided compose file to add Neo4j to your stack:\n\n```bash\ndocker compose -f docker-compose.yml -f docker-compose.neo4j.yml up -d\n```\n\nThis:\n- Starts Neo4j 5.x with APOC plugins\n- Connects to the Context-Engine network\n- Configures indexer/MCP services with Neo4j env vars\n\n## Architecture\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    Context-Engine Core                       │\n├─────────────────────────────────────────────────────────────┤\n│  scripts/graph_backends/                                     │\n│  ├── __init__.py      # Backend factory (loads plugin)      │\n│  ├── base.py          # GraphBackend ABC, GraphEdge         │\n│  ├── qdrant_backend.py # Default Qdrant implementation      │\n│  └── ingest_adapter.py # Unified API for indexer            │\n└─────────────────────────────────────────────────────────────┘\n                              │\n                              │ NEO4J_GRAPH=1\n                              ▼\n┌─────────────────────────────────────────────────────────────┐\n│                    Neo4j Plugin                              │\n├─────────────────────────────────────────────────────────────┤\n│  plugins/neo4j_graph/                                        │\n│  ├── __init__.py        # Plugin exports                    │\n│  ├── backend.py         # Neo4jGraphBackend implementation  │\n│  ├── knowledge_graph.py # Advanced graph features           │\n│  ├── schema.py          # Node/relationship types           │\n│  ├── plugin.py          # Plugin manifest & registration    │\n│  └── base.py            # Standalone interface copy         │\n└─────────────────────────────────────────────────────────────┘\n```\n\n## Indexing Flow\n\nWhen `NEO4J_GRAPH=1`, the indexing pipeline routes graph edges to Neo4j:\n\n```\nCode File → AST Analysis → calls/imports extracted\n                              │\n                              ▼\n                    extract_call_edges()\n                    extract_import_edges()\n                              │\n                              ▼\n                    GraphEdge objects\n                              │\n                              ▼\n                    ingest_adapter.upsert_edges()\n                              │\n                              ▼\n                    get_graph_backend()\n                              │\n              ┌───────────────┴───────────────┐\n              │                               │\n        NEO4J_GRAPH=0                   NEO4J_GRAPH=1\n              │                               │\n              ▼                               ▼\n     QdrantGraphBackend              Neo4jGraphBackend\n              │                               │\n              ▼                               ▼\n     Qdrant _graph collection      Neo4j CALLS/IMPORTS rels\n```\n\n## Graph Schema\n\n### Nodes\n\n| Label | Properties | Description |\n|-------|------------|-------------|\n| `Symbol` | `name`, `repo`, `path`, `collection`, `start_line` | Code symbol (function/class/method) |\n\n### Relationships\n\n| Type | Description | Properties |\n|------|-------------|------------|\n| `CALLS` | Function calls function | `edge_id`, `collection`, `caller_path`, `start_line`, `end_line`, `language` |\n| `IMPORTS` | File imports module | `edge_id`, `collection`, `caller_path`, `language` |\n\n## Usage\n\n### Health Check\n\n```python\nfrom plugins.neo4j_graph.plugin import register_plugin\n\nmanifest = register_plugin(\"1.0.0\")\nhealth = manifest.health_check()\nprint(health)\n# {'plugin': 'context-engine-neo4j-graph', 'healthy': True, 'checks': {...}}\n```\n\n### Direct Backend Access\n\n```python\nfrom plugins.neo4j_graph import Neo4jGraphBackend\n\nbackend = Neo4jGraphBackend()\ncallers = backend.get_callers(\"codebase\", \"my_function\", repo=\"my-repo\")\n```\n\n### Via Core (Recommended)\n\n```python\n# Set NEO4J_GRAPH=1 in environment\nfrom scripts.graph_backends import get_graph_backend\n\nbackend = get_graph_backend()  # Returns Neo4jGraphBackend\ncallers = backend.get_callers(\"codebase\", \"my_function\")\n```\n\n## CLI Commands\n\nThe plugin includes a CLI for testing and managing Neo4j graph data.\n\n### Check Status\n\n```bash\nNEO4J_URI=\"bolt://localhost:7687\" \\\nNEO4J_PASSWORD=\"your_password\" \\\npython -m plugins.neo4j_graph status\n```\n\nOutput:\n```\nBackend: neo4j\nURI: bolt://localhost:7687\n\nGraph Stats:\n  Symbols: 4671\n  CALLS edges: 15347\n  IMPORTS edges: 2101\n\n✓ Neo4j connection OK\n```\n\n### Backfill from Qdrant\n\nExtract graph edges from the main Qdrant collection (using `metadata.calls` and `metadata.imports` fields) and populate Neo4j:\n\n```bash\nNEO4J_URI=\"bolt://localhost:7687\" \\\nNEO4J_PASSWORD=\"your_password\" \\\nQDRANT_URL=\"http://localhost:6333\" \\\npython -m plugins.neo4j_graph backfill --collection my-collection\n```\n\nOptions:\n- `--collection`, `-c`: Main collection name (required)\n- `--limit`, `-l`: Max edges to backfill (default: all)\n\n### Index Directory\n\nIndex a codebase directly to Neo4j using AST analysis:\n\n```bash\nNEO4J_URI=\"bolt://localhost:7687\" \\\nNEO4J_PASSWORD=\"your_password\" \\\npython -m plugins.neo4j_graph index --path /path/to/code --repo my-repo\n```\n\nOptions:\n- `--path`, `-p`: Directory to index (required)\n- `--repo`, `-r`: Repository name (default: directory name)\n\n### Query Graph\n\nQuery the graph for callers, callees, or importers of a symbol:\n\n```bash\nNEO4J_URI=\"bolt://localhost:7687\" \\\nNEO4J_PASSWORD=\"your_password\" \\\npython -m plugins.neo4j_graph query --symbol my_function --type callers\n```\n\nOutput:\n```\nCallers of 'my_function' (5 found):\n  main (scripts/app.py)\n  process_data (scripts/pipeline.py)\n  handle_request (scripts/api.py)\n  ...\n```\n\nOptions:\n- `--symbol`, `-s`: Symbol name to query (required)\n- `--type`, `-t`: Query type - `callers`, `callees`, or `imports` (default: callers)\n- `--limit`, `-l`: Maximum results to return (default: 20)\n\nQuery types:\n- `callers`: Find all functions/methods that call this symbol\n- `callees`: Find all functions/methods this symbol calls\n- `imports`: Find all files that import this module/symbol\n\n## Testing\n\nRun isolated plugin tests:\n\n```bash\ncd plugins/neo4j_graph\npip install pytest neo4j\nNEO4J_PASSWORD=test pytest tests/ -v\n```\n\nSkip tests requiring live Neo4j:\n\n```bash\npytest tests/ -v -m \"not neo4j\"\n```\n\n## Files\n\n| File | Purpose |\n|------|---------|\n| `backend.py` | `Neo4jGraphBackend` - implements `GraphBackend` interface |\n| `knowledge_graph.py` | `Neo4jKnowledgeGraph` - advanced graph features |\n| `schema.py` | `NodeType`, `RelationType`, `GraphNode`, `GraphRelationship` |\n| `plugin.py` | Plugin manifest, `register_plugin()`, health checks |\n| `base.py` | Standalone copy of `GraphBackend` ABC for independence |\n",
        "scripts/ctx_cli/README.md": "# ctx CLI\n\nUnified command-line interface for Context-Engine.\n\n## Installation\n\n```bash\n# Using uv (recommended - 10-100x faster)\nuv sync\n\n# Or using pip (legacy)\npip install -e .\n```\n\n## Quick Start\n\nGet up and running with a single command:\n\n```bash\nctx quickstart\n```\n\nThis will:\n1. Configure your environment\n2. Start all services\n3. Index your codebase\n4. Warm up embedding models\n\n### Quickstart Options\n\n| Flag | Description |\n|------|-------------|\n| `--no-llama` | Skip the local LLM container (for users without GPU or using cloud APIs like OpenAI/GLM) |\n| `--no-index` | Skip initial codebase indexing |\n| `--no-warmup` | Skip model warmup step |\n| `--build` | Rebuild Docker containers before starting |\n| `--recreate` | Recreate Qdrant collection (drops existing data) |\n| `--import-repos` | Copy external repos into dev-workspace for indexing |\n\n**Example: Lightweight setup without local LLM:**\n```bash\nctx quickstart --no-llama\n```\n\nThis is ideal when:\n- You don't have a GPU or sufficient RAM for local LLM inference\n- You're using cloud LLM APIs (OpenAI, GLM, MiniMax) configured in `.env`\n- You want faster startup and lower resource usage\n\n## Commands\n\n### Getting Started\n\n| Command | Description |\n|---------|-------------|\n| `ctx quickstart` | One command to rule them all - full setup |\n| `ctx init [--full]` | Interactive setup wizard |\n| `ctx doctor` | Diagnose issues with actionable fixes |\n\n### Service Management\n\n| Command | Description |\n|---------|-------------|\n| `ctx up [--build] [--wait N]` | Start services |\n| `ctx down [--volumes]` | Stop services |\n| `ctx restart [--build]` | Restart services |\n| `ctx status [--json] [--verbose]` | Show stack health, model state, cache stats |\n| `ctx logs [SERVICE] [-f] [--tail N]` | View service logs |\n| `ctx warmup [--status]` | Preload models for fast queries |\n\n### Search & Retrieval\n\n| Command | Description |\n|---------|-------------|\n| `ctx search <query> [options]` | Semantic code search |\n| `ctx answer <query> [options]` | LLM-generated answers with citations |\n| `ctx memory store <info> [--tags]` | Store knowledge in memory |\n| `ctx memory find <query> [--kind]` | Search stored memories |\n| `ctx graph callers <symbol>` | Find who calls a symbol |\n| `ctx graph definition <symbol>` | Find where symbol is defined |\n| `ctx graph importers <symbol>` | Find what imports a module |\n| `ctx graph callees <symbol>` | Find what a symbol calls |\n| `ctx pattern <query> [--mode]` | Find structurally similar code |\n\n### Indexing\n\n| Command | Description |\n|---------|-------------|\n| `ctx index [path] [--watch]` | Index codebase (local/mounted) |\n| `ctx sync [path] [--watch]` | Upload/sync to remote server |\n| `ctx prune [--collection]` | Remove stale entries |\n| `ctx collections list` | List all collections |\n| `ctx collections create NAME` | Create new collection |\n| `ctx collections delete NAME` | Delete collection |\n\n### Remote Sync (VS Code Extension Equivalent)\n\n| Command | Description |\n|---------|-------------|\n| `ctx sync` | Force sync current directory |\n| `ctx sync --watch` | Watch mode with auto-sync |\n| `ctx sync --git-history` | Include git commit metadata |\n| `ctx sync --endpoint URL` | Use custom upload endpoint |\n\n### IDE Integration\n\n| Command | Description |\n|---------|-------------|\n| `ctx bridge generate claude` | Generate Claude Desktop config |\n| `ctx bridge generate cursor` | Generate Cursor IDE config |\n| `ctx bridge generate windsurf` | Generate Windsurf config |\n| `ctx bridge generate all` | Generate all IDE configs |\n\n### Configuration\n\n| Command | Description |\n|---------|-------------|\n| `ctx config [--get K] [--set K=V]` | View/edit configuration |\n| `ctx completion [bash\\|zsh\\|fish]` | Shell completions |\n\n## Examples\n\n```bash\n# Quick start for new users\nctx quickstart\n\n# Check system health\nctx doctor\n\n# Start services and monitor logs\nctx up --build\nctx logs indexer -f\n\n# Search the codebase\nctx search \"database connection\" --language python --snippet\nctx answer \"how does the indexing pipeline work?\"\n\n# Memory operations\nctx memory store \"JWT tokens are used for auth\" --kind explanation --tags topic=auth\nctx memory find \"authentication\" --limit 5\n\n# Symbol graph navigation\nctx graph callers authenticate --depth 2\nctx graph definition MCPClient --language python\nctx graph importers qdrant_client\n\n# Pattern search\nctx pattern \"try: ... except: pass\" --snippet\nctx pattern \"retry with backoff\" --mode description\n\n# Manage collections\nctx collections list\nctx collections create my-project\nctx collections switch my-project\n\n# Generate IDE configs\nctx bridge generate all\n\n# Monitor and maintain\nctx status --verbose\nctx warmup --status\nctx index --watch\n```\n\n## Shell Completion\n\n```bash\neval \"$(ctx completion bash)\"   # Bash\neval \"$(ctx completion zsh)\"    # Zsh\nctx completion fish | source    # Fish\n```\n\n## Configuration\n\nConfig loaded from `./.ctxrc` or `~/.ctxrc`:\n\n```ini\n[indexer]\nurl = http://localhost:8003\ntimeout = 30\n\n[memory]\nurl = http://localhost:8002\n\n[search]\ndefault_limit = 10\ndefault_collection = codebase\n\n[docker]\ncompose_file = compose.yaml\n```\n\n## Environment Variables\n\n| Variable | Description | Default |\n|----------|-------------|---------|\n| `MCP_INDEXER_URL` | Indexer HTTP endpoint | `http://localhost:8003/mcp` |\n| `MCP_MEMORY_URL` | Memory HTTP endpoint | `http://localhost:8002/mcp` |\n| `COLLECTION_NAME` | Default collection | `codebase` |\n| `COMPOSE_FILE` | Docker compose file | `compose.yaml` |\n\n## Troubleshooting\n\nRun the doctor command to diagnose issues:\n\n```bash\nctx doctor\n```\n\nCommon fixes:\n- **Services not running**: `ctx up`\n- **Models not loaded**: `ctx warmup`\n- **Stale index**: `ctx prune && ctx index`\n- **Config issues**: `ctx init --env-only`\n",
        "scripts/graph_backends/README.md": "# Graph Backends (Open Core)\n\nQdrant-based graph storage for symbol relationships.\n\n## Overview\n\nThis module provides a pluggable graph storage layer for code symbol relationships.\nThe **Qdrant backend** is the default, included in open core.\n\nFor advanced graph features, see the [Neo4j Plugin](../../plugins/neo4j_graph/).\n\n## Backends\n\n| Backend | Location | Use Case | Enable |\n|---------|----------|----------|--------|\n| **Qdrant** | `scripts/graph_backends/` | Default, lightweight | Default |\n| **Neo4j** | `plugins/neo4j_graph/` | Production, advanced | `NEO4J_GRAPH=1` |\n\n## Architecture\n\n```\n┌─────────────────────────────────────────────────────────────────────────┐\n│                         Indexing Pipeline                               │\n├─────────────────────────────────────────────────────────────────────────┤\n│                                                                         │\n│  Code File → AST Analysis → calls/imports → ingest_adapter             │\n│                                                   │                     │\n│                                    ┌──────────────┴──────────────┐     │\n│                                    ▼                             ▼     │\n│                          ┌─────────────────┐          ┌───────────────┐│\n│                          │ QdrantBackend   │          │ Neo4jBackend  ││\n│                          │ (open core)     │          │ (plugin)      ││\n│                          └────────┬────────┘          └───────┬───────┘│\n│                                   │                           │        │\n│                                   ▼                           ▼        │\n│                          ┌─────────────────┐          ┌───────────────┐│\n│                          │ Qdrant          │          │ Neo4j         ││\n│                          │ *_graph coll    │          │ Database      ││\n│                          └─────────────────┘          └───────────────┘│\n└─────────────────────────────────────────────────────────────────────────┘\n```\n\n## Module Structure\n\n```\nscripts/graph_backends/\n├── __init__.py          # Backend factory, loads plugin if NEO4J_GRAPH=1\n├── base.py              # GraphBackend ABC, GraphEdge, GraphQueryResult\n├── qdrant_backend.py    # Default Qdrant implementation\n├── ingest_adapter.py    # Unified API for indexer pipeline\n└── README.md            # This file\n```\n\n## Core Components\n\n### `base.py` - Interface\n\n```python\nclass GraphEdge:\n    \"\"\"Represents a call/import relationship.\"\"\"\n    id: str\n    caller_symbol: str\n    callee_symbol: str\n    caller_path: str\n    edge_type: str  # \"calls\" or \"imports\"\n    repo: str\n    # Optional: start_line, end_line, language, caller_point_id\n\nclass GraphBackend(ABC):\n    \"\"\"Abstract base class for graph storage backends.\"\"\"\n\n    def ensure_graph_store(self, base_collection: str) -> Optional[str]: ...\n    def upsert_edges(self, graph_store: str, edges: List[GraphEdge]) -> int: ...\n    def delete_edges_by_path(self, graph_store: str, path: str) -> int: ...\n    def get_callers(self, graph_store: str, symbol: str) -> List[Dict]: ...\n    def get_callees(self, graph_store: str, symbol: str) -> List[Dict]: ...\n    def get_importers(self, graph_store: str, module: str) -> List[Dict]: ...\n```\n\n### `ingest_adapter.py` - Pipeline Integration\n\nThe adapter routes edge operations to the active backend:\n\n```python\nfrom scripts.graph_backends.ingest_adapter import (\n    ensure_graph_store,\n    extract_call_edges,\n    extract_import_edges,\n    upsert_edges,\n    delete_edges_by_path,\n)\n\n# During indexing:\ngraph_store = ensure_graph_store(client, \"my-collection\")\nedges = extract_call_edges(symbol_path=\"main\", calls=[\"helper\"], ...)\nupsert_edges(client, graph_store, edges)\n```\n\n## Usage\n\n### Get Backend\n\n```python\nfrom scripts.graph_backends import get_graph_backend, GRAPH_BACKEND_TYPE\n\nbackend = get_graph_backend()  # Singleton\nprint(GRAPH_BACKEND_TYPE)  # \"qdrant\" or \"neo4j\"\n```\n\n### Query Relationships\n\n```python\ngraph_store = \"collection_graph\" if GRAPH_BACKEND_TYPE == \"qdrant\" else \"collection\"\n\n# Find callers of a function\ncallers = backend.get_callers(graph_store, \"my_function\", repo=\"my-repo\")\n\n# Find what a function calls\ncallees = backend.get_callees(graph_store, \"my_function\")\n\n# Find files that import a module\nimporters = backend.get_importers(graph_store, \"os\", repo=\"my-repo\")\n```\n\n## Neo4j Plugin\n\nFor advanced features (PageRank, path finding, knowledge graph), enable the plugin:\n\n```bash\n# Copy plugin to deployment\ncp -r plugins/neo4j_graph /path/to/deployment/plugins/\n\n# Install driver\npip install neo4j>=5.0.0\n\n# Enable\nexport NEO4J_GRAPH=1\nexport NEO4J_PASSWORD=your_password\n\n# Start with Neo4j\ndocker compose -f docker-compose.yml -f docker-compose.neo4j.yml up -d\n```\n\nSee [plugins/neo4j_graph/README.md](../../plugins/neo4j_graph/README.md) for details.\n",
        "skills/context-engine/SKILL.md": "---\nname: context-engine\ndescription: Hybrid semantic/lexical code search with neural reranking via MCP tools. Use when searching a codebase, finding implementations, understanding how code works, finding callers/definitions, searching git history, or storing/retrieving knowledge. IMPORTANT - Always prefer these MCP tools over grep/find/cat for code exploration.\n---\n\n# Context-Engine\n\nSearch and retrieve code context from any codebase using hybrid vector search (semantic + lexical) with neural reranking.\n\n## Decision Tree: Choosing the Right Tool\n\n```\nWhat do you need?\n    |\n    +-- Find code locations/implementations\n    |       |\n    |       +-- Simple query --> info_request\n    |       +-- Need filters/control --> repo_search\n    |\n    +-- Understand how something works\n    |       |\n    |       +-- Want LLM explanation --> context_answer\n    |       +-- Just code snippets --> repo_search with include_snippet=true\n    |\n    +-- Find similar code patterns (retry loops, error handling, etc.)\n    |       |\n    |       +-- Have code example --> pattern_search with code snippet (if enabled)\n    |       +-- Describe pattern --> pattern_search with natural language (if enabled)\n    |\n    +-- Find specific file types\n    |       |\n    |       +-- Test files --> search_tests_for\n    |       +-- Config files --> search_config_for\n    |\n    +-- Find relationships\n    |       |\n    |       +-- Who calls this function --> symbol_graph (DEFAULT, always available)\n    |       +-- Who imports this module --> symbol_graph OR search_importers_for\n    |       +-- Where is this defined --> symbol_graph (query_type=\"definition\")\n    |       +-- Symbol graph navigation (callers/defs/importers) --> symbol_graph (ALWAYS use this first)\n    |       +-- Multi-hop callers (callers of callers) --> symbol_graph (depth=2+) OR neo4j_graph_query (if NEO4J_GRAPH=1)\n    |       +-- Impact analysis (what breaks if I change X) --> neo4j_graph_query (ONLY if available)\n    |       +-- Dependency graph --> neo4j_graph_query (ONLY if available)\n    |       +-- Circular dependency detection --> neo4j_graph_query (ONLY if available)\n    |\n    +-- Git history --> search_commits_for\n    |\n    +-- Store/recall knowledge --> memory_store, memory_find\n    |\n    +-- Blend code + notes --> context_search with include_memories=true\n```\n\n## Primary Search: repo_search\n\nUse `repo_search` (or its alias `code_search`) for most code lookups. Reranking is ON by default.\n\n```json\n{\n  \"query\": \"database connection handling\",\n  \"limit\": 10,\n  \"include_snippet\": true,\n  \"context_lines\": 3\n}\n```\n\nReturns:\n```json\n{\n  \"results\": [\n    {\"score\": 3.2, \"path\": \"src/db/pool.py\", \"symbol\": \"ConnectionPool\", \"start_line\": 45, \"end_line\": 78, \"snippet\": \"...\"}\n  ],\n  \"total\": 8,\n  \"used_rerank\": true\n}\n```\n\n**Multi-query for better recall** - pass a list to fuse results:\n```json\n{\n  \"query\": [\"auth middleware\", \"authentication handler\", \"login validation\"]\n}\n```\n\n**Apply filters** to narrow results:\n```json\n{\n  \"query\": \"error handling\",\n  \"language\": \"python\",\n  \"under\": \"src/api/\",\n  \"not_glob\": [\"**/test_*\", \"**/*_test.*\"]\n}\n```\n\n**Search across repos**:\n```json\n{\n  \"query\": \"shared types\",\n  \"repo\": [\"frontend\", \"backend\"]\n}\n```\nUse `repo: \"*\"` to search all indexed repos.\n\n### Available Filters\n\n- `language` - Filter by programming language\n- `under` - Path prefix (e.g., \"src/api/\")\n- `path_glob` - Include patterns (e.g., [\"**/*.ts\", \"lib/**\"])\n- `not_glob` - Exclude patterns (e.g., [\"**/test_*\"])\n- `symbol` - Symbol name match\n- `kind` - AST node type (function, class, etc.)\n- `ext` - File extension\n- `repo` - Repository filter for multi-repo setups\n- `case` - Case-sensitive matching\n\n## Simple Lookup: info_request\n\nUse `info_request` for natural language queries with minimal parameters:\n\n```json\n{\n  \"info_request\": \"how does user authentication work\"\n}\n```\n\nAdd explanations:\n```json\n{\n  \"info_request\": \"database connection pooling\",\n  \"include_explanation\": true\n}\n```\n\n## Q&A with Citations: context_answer\n\nUse `context_answer` when you need an LLM-generated explanation grounded in code:\n\n```json\n{\n  \"query\": \"How does the caching layer invalidate entries?\",\n  \"budget_tokens\": 2000\n}\n```\n\nReturns an answer with file/line citations. Use `expand: true` to generate query variations for better retrieval.\n\n## Pattern Search: pattern_search (Optional)\n\n> **Note:** This tool may not be available in all deployments. If pattern detection is disabled, calls return `{\"ok\": false, \"error\": \"Pattern search module not available\"}`.\n\nFind structurally similar code patterns across all languages. Accepts **either** code examples **or** natural language descriptions—auto-detects which.\n\n**Code example query** - find similar control flow:\n```json\n{\n  \"query\": \"for i in range(3): try: ... except: time.sleep(2**i)\",\n  \"limit\": 10,\n  \"include_snippet\": true\n}\n```\n\n**Natural language query** - describe the pattern:\n```json\n{\n  \"query\": \"retry with exponential backoff\",\n  \"limit\": 10,\n  \"include_snippet\": true\n}\n```\n\n**Cross-language search** - Python pattern finds Go/Rust/Java equivalents:\n```json\n{\n  \"query\": \"if err != nil { return err }\",\n  \"language\": \"go\",\n  \"limit\": 10\n}\n```\n\n**Explicit mode override** - force code or description mode:\n```json\n{\n  \"query\": \"error handling\",\n  \"query_mode\": \"description\",\n  \"limit\": 10\n}\n```\n\n**Key parameters:**\n- `query` - Code snippet OR natural language description\n- `query_mode` - `\"code\"`, `\"description\"`, or `\"auto\"` (default)\n- `language` - Language hint for code examples (python, go, rust, etc.)\n- `limit` - Max results (default 10)\n- `min_score` - Minimum similarity threshold (default 0.3)\n- `include_snippet` - Include code snippets in results\n- `context_lines` - Lines of context around matches\n- `aroma_rerank` - Enable AROMA structural reranking (default true)\n- `aroma_alpha` - Weight for AROMA vs original score (default 0.6)\n- `target_languages` - Filter results to specific languages\n\n**Returns:**\n```json\n{\n  \"ok\": true,\n  \"results\": [...],\n  \"total\": 5,\n  \"query_signature\": \"L2_2_B0_T2_M0\",\n  \"query_mode\": \"code\",\n  \"search_mode\": \"aroma\"\n}\n```\n\nThe `query_signature` encodes control flow: `L` (loops), `B` (branches), `T` (try/except), `M` (match).\n\n## Specialized Search Tools\n\n**search_tests_for** - Find test files:\n```json\n{\"query\": \"UserService\", \"limit\": 10}\n```\n\n**search_config_for** - Find config files:\n```json\n{\"query\": \"database connection\", \"limit\": 5}\n```\n\n**search_callers_for** - Find callers of a symbol:\n```json\n{\"query\": \"processPayment\", \"language\": \"typescript\"}\n```\n\n**search_importers_for** - Find importers:\n```json\n{\"query\": \"utils/helpers\", \"limit\": 10}\n```\n\n**symbol_graph** - Symbol graph navigation (callers / definition / importers):\n```json\n{\"symbol\": \"ASTAnalyzer\", \"query_type\": \"definition\", \"limit\": 10}\n```\n```json\n{\"symbol\": \"get_embedding_model\", \"query_type\": \"callers\", \"under\": \"scripts/\", \"limit\": 10}\n```\n```json\n{\"symbol\": \"qdrant_client\", \"query_type\": \"importers\", \"limit\": 10}\n```\n- Supports `language`, `under`, `depth`, and `output_format` like other tools.\n- Use `depth=2` or `depth=3` for multi-hop traversals (callers of callers).\n- If there are no graph hits, it falls back to semantic search.\n- **Note**: Results are \"hydrated\" with ~500-char source snippets for immediate context.\n\n**neo4j_graph_query** - Advanced graph traversals (OPTIONAL — ONLY available when NEO4J_GRAPH=1):\n\n> **If `neo4j_graph_query` is not in your MCP tool list, it is NOT enabled. Use `symbol_graph` for all graph queries instead. Do NOT error or warn about missing Neo4j.**\n\n```json\n{\"symbol\": \"normalize_path\", \"query_type\": \"impact\", \"depth\": 2}\n```\n```json\n{\"symbol\": \"get_embedding_model\", \"query_type\": \"transitive_callers\", \"depth\": 2}\n```\n```json\n{\"symbol\": \"run_hybrid_search\", \"query_type\": \"dependencies\", \"limit\": 15}\n```\n\n**Query types (only when neo4j_graph_query is available):**\n| Type | Description |\n|------|-------------|\n| `callers` | Who calls this symbol? (depth 1) |\n| `callees` | What does this symbol call? (depth 1) |\n| `transitive_callers` | Multi-hop callers (up to depth) |\n| `transitive_callees` | Multi-hop callees (up to depth) |\n| `impact` | What breaks if I change this? (reverse transitive) |\n| `dependencies` | What does this depend on? (calls + imports) |\n| `cycles` | Detect circular dependencies |\n\n\n\n**search_commits_for** - Search git history:\n```json\n{\"query\": \"fixed authentication bug\", \"limit\": 10}\n```\n\n**change_history_for_path** - File change summary:\n```json\n{\"path\": \"src/api/auth.py\", \"include_commits\": true}\n```\n\n## Memory: Store and Recall Knowledge\n\nUse `memory_store` to persist information for later retrieval:\n```json\n{\n  \"information\": \"Auth service uses JWT tokens with 24h expiry. Refresh tokens last 7 days.\",\n  \"metadata\": {\"topic\": \"auth\", \"date\": \"2024-01\"}\n}\n```\n\nUse `memory_find` to retrieve stored knowledge by similarity:\n```json\n{\"query\": \"token expiration\", \"limit\": 5}\n```\n\nUse `context_search` to blend code results with stored memories:\n```json\n{\n  \"query\": \"authentication flow\",\n  \"include_memories\": true,\n  \"per_source_limits\": {\"code\": 6, \"memory\": 3}\n}\n```\n\n## Index Management\n\n**qdrant_index_root** - First-time setup or full reindex:\n```json\n{}\n```\nWith recreate (drops existing data):\n```json\n{\"recreate\": true}\n```\n\n**qdrant_index** - Index only a subdirectory:\n```json\n{\"subdir\": \"src/\"}\n```\n\n**qdrant_prune** - Remove deleted files from index:\n```json\n{}\n```\n\n**qdrant_status** - Check index health:\n```json\n{}\n```\n\n**qdrant_list** - List all collections:\n```json\n{}\n```\n\n## Workspace Tools\n\n**workspace_info** - Get current workspace and collection:\n```json\n{}\n```\n\n**list_workspaces** - List all indexed workspaces:\n```json\n{}\n```\n\n**collection_map** - View collection-to-repo mappings:\n```json\n{\"include_samples\": true}\n```\n\n**set_session_defaults** - Set defaults for session:\n```json\n{\"collection\": \"my-project\", \"language\": \"python\"}\n```\n\n## Query Expansion\n\n**expand_query** - Generate query variations for better recall:\n```json\n{\"query\": \"auth flow\", \"max_new\": 2}\n```\n\n## Output Formats\n\n- `json` (default) - Structured output\n- `toon` - Token-efficient compressed format\n\nSet via `output_format` parameter.\n\n## Aliases and Compat Wrappers\n\n**Aliases:**\n- `code_search` = `repo_search` (identical behavior)\n\n**Cross-server tools:**\n- `memory_store` / `memory_find` — Memory server tools for persistent knowledge\n\nCompat wrappers accept alternate parameter names:\n- `repo_search_compat` - Accepts `q`, `text`, `top_k` as aliases\n- `context_answer_compat` - Accepts `q`, `text` as aliases\n\nUse the primary tools when possible. Compat wrappers exist for legacy clients.\n\n## Error Handling\n\nTools return structured errors, typically via `error` field and sometimes `ok: false`:\n```json\n{\"ok\": false, \"error\": \"Collection not found. Run qdrant_index_root first.\"}\n{\"error\": \"Timeout during rerank\"}\n```\n\nCommon issues:\n- **Collection not found** - Run `qdrant_index_root` to create the index\n- **Empty results** - Broaden query, check filters, verify index exists\n- **Timeout on rerank** - Set `rerank_enabled: false` or reduce `limit`\n\n## Best Practices\n\n1. **NEVER use Read File or grep for exploration** - Use MCP tools (`repo_search`, `symbol_graph`, `context_answer`) instead. The ONLY acceptable use of Read/grep is confirming exact literal strings.\n2. **Default to `symbol_graph` for all graph queries** - It is always available. Only use `neo4j_graph_query` if the tool appears in your MCP tool list.\n3. **Start broad, then filter** - Begin with a semantic query, add filters if too many results\n4. **Use multi-query** - Pass 2-3 query variations for better recall on complex searches\n5. **Include snippets** - Set `include_snippet: true` to see code context in results\n6. **Store decisions** - Use `memory_store` to save architectural decisions and context for later\n7. **Check index health** - Run `qdrant_status` if searches return unexpected results\n8. **Prune after refactors** - Run `qdrant_prune` after moving/deleting files\n9. **Index before search** - Always run `qdrant_index_root` on first use or after cloning a repo\n10. **Use pattern_search for structural matching** - When looking for code with similar control flow (retry loops, error handling), use `pattern_search` instead of `repo_search` (if enabled)\n11. **Describe patterns in natural language** - `pattern_search` understands \"retry with backoff\" just as well as actual code examples (if enabled)\n12. **Fire independent searches in parallel** - Call multiple `repo_search`, `symbol_graph`, etc. in the same message block for 2-3x speedup\n13. **Use TOON format for discovery** - Set `output_format: \"toon\"` for 60-80% token reduction on exploratory queries\n14. **Bootstrap sessions with defaults** - Call `set_session_defaults(output_format=\"toon\", compact=true)` early to avoid repeating params\n15. **Two-phase search** - Discovery first (`limit=3, compact=true`), then deep dive (`limit=5-8, include_snippet=true`) on targets\n16. **Use fallback chains** - If `context_answer` times out, fall back to `repo_search` + `info_request(include_explanation=true)`\n\n",
        "vscode-extension/context-engine-uploader/README.md": "Context Engine Uploader\n=======================\n\nInstall\n-------\n- Install from the VS Code Marketplace (search for \"Context Engine Uploader\" or publisher `context-engine`). You can also install it directly from the Extensions view in VS Code.\n\nFeatures\n--------\n- Runs a force sync (`Index Codebase`) followed by watch mode to keep a remote Context Engine instance in sync with your workspace.\n- Auto-detects the first workspace folder as the default target path, storing it in workspace settings so the extension is portable.\n- Provides commands and a status-bar button:\n  - `Context Engine Uploader: Index Codebase` – force sync + watch with spinner feedback.\n  - `Context Engine Uploader: Start/Stop/Restart` for manual lifecycle control.\n- Streams detailed logs into the `Context Engine Upload` output channel for visibility into both force sync and watch phases.\n- Status bar shows current state (indexing spinner, purple watching state) so you always know if uploads are active.\n\nConfiguration\n-------------\n- `Run On Startup` auto-triggers force sync + watch after VS Code finishes loading.\n- `Python Path`, `Endpoint`, `Extra Force Args`, `Extra Watch Args`, and `Interval Seconds` can be tuned via standard VS Code settings.\n- `Target Path` is auto-filled from the workspace but can be overridden if you need to upload a different folder.\n- **Python dependencies:** the extension runs the standalone upload client via your configured `pythonPath`. Ensure the interpreter has `requests`, `urllib3`, `charset_normalizer`, and `watchdog` installed. Run `python3 -m pip install requests urllib3 charset_normalizer watchdog` (or replace `python3` with your configured path) before starting the uploader.\n- **Path mapping:** `Host Root` + `Container Root` control how local paths are rewritten before reaching the remote service. By default the host root mirrors your `Target Path` and the container root is `/work`, which keeps Windows paths working without extra config.\n- **Prompt+ decoder:** set `Context Engine Uploader: Decoder Url` (default `http://localhost:8081`, auto-appends `/completion`) to point at your local llama.cpp decoder. For Ollama, set it to `http://localhost:11434/api/chat`. Turn on `Use Gpu Decoder` to set `USE_GPU_DECODER=1` so ctx.py prefers the GPU llama.cpp sidecar. Prompt+ automatically runs the bundled `scripts/ctx.py` when an embedded copy is available, falling back to the workspace version if not.\n- **Claude/Windsurf MCP config:**\n  - `MCP Indexer Url` and `MCP Memory Url` control the URLs written into the project-local `.mcp.json` (Claude) and Windsurf `mcp_config.json` when you run the `Write MCP Config` command. These URLs are used **literally** (e.g. `http://localhost:8001/sse` or `http://localhost:8003/mcp`).\n  - `MCP Server Mode` (`contextEngineUploader.mcpServerMode`) controls *what* servers are written:\n    - `bridge`: write a single `context-engine` server that talks to the `ctxce` MCP bridge.\n    - `direct`: write two servers, `qdrant-indexer` and `memory`, that talk directly to the configured URLs.\n  - `MCP Transport Mode` (`contextEngineUploader.mcpTransportMode`) controls *how* those servers talk:\n    - `sse-remote` (default): use stdio MCP processes behind an SSE tunnel (`bridge-stdio` / `direct-sse`).\n    - `http`: use HTTP MCP endpoints directly (`bridge-http` / `direct-http`).\n  - Common combinations:\n    - `bridge` + `sse-remote` → **bridge-stdio**: write a single `context-engine` stdio server that runs `ctxce mcp-serve` behind an SSE tunnel.\n    - `bridge` + `http` → **bridge-http**: write a single `context-engine` HTTP server that points at the local `ctxce mcp-http-serve` URL (e.g. `http://127.0.0.1:30810/mcp`).\n    - `direct` + `http` → **direct-http**: write separate HTTP servers for the indexer and memory MCP backends.\n- **MCP config on startup:**\n  - `contextEngineUploader.autoWriteMcpConfigOnStartup` (default `false`) controls whether the extension automatically runs the same logic as `Write MCP Config` on activation. When enabled, it refreshes `.mcp.json`, Windsurf `mcp_config.json`, and the Claude hook (`.claude/settings.local.json`) to match your current settings and the installed extension version. If `scaffoldCtxConfig` is also `true`, this startup path will additionally scaffold/update `ctx_config.json` and `.env` as described below.\n- **CTX + GLM settings:**\n  - `contextEngineUploader.ctxIndexerUrl` is copied into `.env` (as `MCP_INDEXER_URL`) so the embedded `ctx.py` knows which MCP indexer to call when enhancing prompts.\n  - `contextEngineUploader.glmApiKey`, `glmApiBase`, and `glmModel` are used when scaffolding `ctx_config.json`/`.env` to pre-fill GLM decoder options. Existing non-placeholder values are preserved, so you can override them in the files at any time.\n- **Git history upload settings:**\n  - `contextEngineUploader.gitMaxCommits` controls `REMOTE_UPLOAD_GIT_MAX_COMMITS`, bounding how many commits the upload client includes per bundle (set to 0 to disable git history).\n  - `contextEngineUploader.gitSince` controls `REMOTE_UPLOAD_GIT_SINCE`, letting you constrain the git log window (e.g. `2 years ago` or `2023-01-01`).\n- **Context scaffolding:**\n  - `contextEngineUploader.scaffoldCtxConfig` (default `true`) controls whether the extension keeps a minimal `ctx_config.json` + `.env` in sync with your workspace. When enabled, running `Write MCP Config` or `Write CTX Config` will reuse the workspace’s existing files (if present) and only backfill placeholder or missing values from the bundled `env.example` plus the inferred collection name. Existing custom values are preserved.\n  - The scaffolder also enforces CTX defaults (e.g., `MULTI_REPO_MODE=1`, `REFRAG_RUNTIME=glm`, `REFRAG_DECODER=1`) so the embedded `ctx.py` is ready for remote uploads, regardless of the “Use GLM Decoder” toggle.\n  - `contextEngineUploader.surfaceQdrantCollectionHint` gates whether the Claude hook adds a hint line with the Qdrant collection ID when ctx is enhancing prompts. This setting is also respected when the extension writes `.claude/settings.local.json`.\n\nMCP bridge (ctx-mcp-bridge) & MCP config lifecycle\n---------------------------------------------------\n- The MCP bridge (`@context-engine-bridge/context-engine-mcp-bridge`, CLI `ctxce`) is a small local MCP server that fans out to two upstream MCP services: the Qdrant indexer and the memory/search backend. The VS Code extension can drive it in two ways:\n  - **Bridge stdio (`bridge-stdio`)** – a stdio MCP server (`ctxce mcp-serve`) wrapped behind an SSE tunnel.\n  - **Bridge HTTP (`bridge-http`)** – an HTTP MCP server (`ctxce mcp-http-serve`) listening on `http://127.0.0.1:<port>/mcp`.\n- Why use the bridge instead of two direct MCP entries?\n  - **Single server entry:** IDEs only need to register one MCP server (`context-engine`) instead of juggling separate `qdrant-indexer` and `memory` entries, avoiding coordination mistakes.\n  - **Shared session defaults:** the bridge loads `ctx_config.json` and injects collection name, repo metadata, and any other ctx defaults so every IDE window talks to the right collection without hand-editing `.mcp.json`.\n  - **Per-user credential isolation:** each IDE maintains its own MCP session while the bridge multiplexes upstream calls. When you enable backend auth (via `CTXCE_AUTH_ENABLED` and `ctxce auth ...` sessions), uploads and MCP calls are gated by per-user sessions, so multiple IDEs can share the same stack while still having isolated access control and preferences. See **Optional auth with the MCP bridge (PoC)** below for details.\n  - **Flexible transport:** stdio mode works everywhere (even when HTTP ports aren’t reachable), while HTTP mode keeps Claude/Windsurf happy when they want direct URLs; the extension automatically writes the right flavor.\n  - **Centralized logging & health:** when the bridge process runs once per workspace you get a single stream of logs (`Context Engine Upload` output) and a single port to probe for health checks instead of multiple MCP child processes per IDE.\n- When you run **`Write MCP Config`**, the extension:\n  - Writes `.mcp.json` in the workspace for Claude Code.\n  - Optionally writes Windsurf's `mcp_config.json` (when `mcpWindsurfEnabled=true`).\n  - Optionally writes Augment's `settings.json` (when `mcpAugmentEnabled=true`).\n  - Optionally writes Antigravity's `mcp_config.json` (when `mcpAntigravityEnabled=true`).\n  - Optionally writes Cursor's `~/.cursor/mcp.json` (when `mcpCursorEnabled=true`).\n  - Optionally scaffolds `ctx_config.json` + `.env` (when `scaffoldCtxConfig=true`).\n- The effective wiring mode is determined by the two MCP settings:\n  - `mcpServerMode = bridge`, `mcpTransportMode = sse-remote` → **bridge-stdio**.\n  - `mcpServerMode = bridge`, `mcpTransportMode = http` → **bridge-http**.\n  - `mcpServerMode = direct`, `mcpTransportMode = sse-remote` → **direct-sse** (two stdio `mcp-remote` servers).\n  - `mcpServerMode = direct`, `mcpTransportMode = http` → **direct-http** (two HTTP servers, no bridge).\n- In **bridge-stdio**, the configs run the `ctxce mcp-serve` CLI via `npx` (for example,\n  `npx @context-engine-bridge/context-engine-mcp-bridge ctxce mcp-serve`), passing the\n  workspace path (auto-detected from the uploader target path) plus `--indexer-url`\n  and `--memory-url` derived from the MCP settings.\n- In **bridge-http**, the extension can also **manage the bridge process**:\n  - `autoStartMcpBridge=true` and `mcpServerMode='bridge'` with `mcpTransportMode='http'` → the extension starts `ctxce mcp-http-serve` in the background for the active workspace using `mcpBridgePort`.\n  - The resulting HTTP URL (`http://127.0.0.1:<mcpBridgePort>/mcp`) is written into `.mcp.json` and Windsurf’s `mcp_config.json` as the `context-engine` server URL.\n  - In **stdio or direct modes**, the HTTP bridge is **not** auto-started; only the explicit `Start MCP HTTP Bridge` command will launch it.\n- Bridge settings are **workspace-scoped**, so different workspaces can choose different modes and ports (e.g., one workspace using stdio bridge, another using HTTP bridge on a different port).\n\nCursor Integration\n------------------\n\nEnable `mcpCursorEnabled` in settings to write MCP config to `~/.cursor/mcp.json`.\n\n**Caveats:**\n- Cursor uses a **global** MCP config at `~/.cursor/mcp.json` (not per-project like Claude's `.mcp.json`).\n- After updating the config, you must **restart Cursor** for changes to take effect.\n- Cursor's MCP support requires the `http` transport mode. Set `mcpTransportMode` to `http`.\n- If using bridge mode, ensure the HTTP bridge is running (`autoStartMcpBridge=true`).\n- Custom config path: set `cursorMcpPath` to override the default `~/.cursor/mcp.json` location.\n\nOptional auth with the MCP bridge (PoC)\n--------------------------------------\n\nAuth is **off by default** and fully opt-in. When enabled, the MCP indexer and\nmemory servers expect a valid `session` id (issued by the backend) on protected\ntools. The bridge CLI (`ctxce auth ...`) is the primary way to obtain and cache\nthat session.\n\nHigh-level steps:\n\n- Enable auth on the remote stack (e.g. dev-remote compose):\n  - Set `CTXCE_AUTH_ENABLED=1` in the upload/indexer environment.\n  - Optionally set `CTXCE_AUTH_SHARED_TOKEN` for token-based login.\n  - Optional: set `CTXCE_AUTH_ADMIN_TOKEN` for creating additional users via `/auth/users`.\n  - Optional (dev-only): set `CTXCE_AUTH_ALLOW_OPEN_TOKEN_LOGIN=1` **only** if you want `/auth/login`\n    to issue sessions even when `CTXCE_AUTH_SHARED_TOKEN` is unset. By default (`0`/unset),\n    token-based login is disabled when no shared token is configured.\n- Point the bridge at the auth backend:\n  - In your local shell (where you run the `ctxce` CLI via `npx`), you can either:\n    - Explicitly set `CTXCE_AUTH_BACKEND_URL` to the upload service URL (e.g. `http://localhost:8004`), or\n    - Let the CLI discover the backend URL in this order when you run `ctxce auth login`:\n      `--backend-url` / `--auth-url` → `CTXCE_AUTH_BACKEND_URL` → any stored auth entry →\n      the uploader's `upload_endpoint` (`CTXCE_UPLOAD_ENDPOINT` / `UPLOAD_ENDPOINT`) →\n      `http://localhost:8004`.\n\n**Auto-setup for local users (recommended):**\n\nThe simplest way to authenticate is to configure the shared token in VS Code settings.\nThe extension will automatically set up auth on activation—no manual CLI commands needed:\n\n1. Add these settings to your VS Code `settings.json` (workspace or user):\n\n   ```json\n   {\n     \"contextEngineUploader.endpoint\": \"http://localhost:8004\",\n     \"contextEngineUploader.authSharedToken\": \"change-me-dev-token\"\n   }\n   ```\n\n2. Reload VS Code. The extension will:\n   - Check if auth is enabled on the backend (`/auth/status`)\n   - If no valid session exists, automatically write the token to `~/.ctxce/auth.json`\n   - The watcher, bridge, and MCP tools will then authenticate seamlessly\n\nThis auto-setup only runs when:\n- `authSharedToken` is configured in settings\n- Auth is enabled on the backend (`CTXCE_AUTH_ENABLED=1`)\n- No valid session already exists in `~/.ctxce/auth.json`\n\n**If you're a dev without auth enabled** (`AUTH_ENABLED=0` or not set), the extension\nwill detect this via `/auth/status` and skip auth setup entirely. Everything works\nwithout auth—no configuration needed. The auto-setup is completely transparent.\n\nThe extension uses a two-tier fallback when auth IS enabled:\n- **Option A (default):** Writes the token directly to `~/.ctxce/auth.json`\n- **Option C (fallback):** If direct write fails, triggers `ctxce auth login` in silent mode\n\n**Manual token-based login (alternative):**\n\n```bash\nexport CTXCE_AUTH_BACKEND_URL=http://localhost:8004   # optional when using this extension\nexport CTXCE_AUTH_TOKEN=change-me-dev-token   # must match CTXCE_AUTH_SHARED_TOKEN in the stack\n\n# Obtain a session and cache it under ~/.ctxce/auth.json\nnpx @context-engine-bridge/context-engine-mcp-bridge ctxce auth login\n\n# Check status (optional)\nnpx @context-engine-bridge/context-engine-mcp-bridge ctxce auth status\n```\n\nUsername/password login (when you have real users):\n\n- First, create the initial user (once) via `/auth/users` while the auth DB is\n  empty (no admin token required). This is typically done with a small script\n  or curl call against the upload service, for example:\n\n  ```bash\n  curl -X POST http://localhost:8004/auth/users \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"username\":\"you@example.com\",\"password\":\"your-password\"}'\n  ```\n\n- Then login via the bridge:\n\n```bash\nnpx @context-engine-bridge/context-engine-mcp-bridge ctxce auth login \\\n  --username you@example.com \\\n  --password 'your-password'\n```\n\nIn both modes, the bridge stores the returned `session_id` keyed by\n`CTXCE_AUTH_BACKEND_URL` and automatically injects it into all MCP tool calls\nas the `session` field. Once you have at least one entry in `~/.ctxce/auth.json`,\nthe MCP bridge used by the extension will discover and reuse that session\nautomatically; MCP configs do not need to set `CTXCE_AUTH_BACKEND_URL` in their\n`env` blocks. If `CTXCE_AUTH_ENABLED` is off on the backend, these auth settings\nare ignored and the bridge behaves exactly as before.\n\nSession lifetime:\n\n- By default, issued sessions do **not** expire (`CTXCE_AUTH_SESSION_TTL_SECONDS`\n  defaults to `0`).\n- Operators who want expiry can set `CTXCE_AUTH_SESSION_TTL_SECONDS` (in seconds)\n  on the backend services. Values `> 0` enable a sliding window: active sessions\n  are refreshed when validated; values `<= 0` disable expiry.\n\nWorkspace-level ctx integration\n-------------------------------\n- The VSIX bundles an `env.example` template plus the ctx hook/CLI so you can dogfood the workflow without copying files manually.\n- When scaffolding is enabled (see above), running the `Context Engine Uploader: Write CTX Config (ctx_config.json/.env)` command will:\n  - Infer the collection name from the standalone upload client (`--show-mapping`).\n  - Create or update `ctx_config.json` with that collection and sensible defaults (GLM runtime, `default_mode`, `require_context`, etc.).\n  - Create or update `.env` from the bundled template, ensuring CTX-critical values such as `MULTI_REPO_MODE=1`, `REFRAG_RUNTIME=glm`, and `REFRAG_DECODER=1` are set. Non-placeholder values (e.g., a real `GLM_API_KEY`) are left alone.\n- You still own the files: if you need a custom value, edit `.env` or `ctx_config.json` directly. The scaffolder only touches keys that are missing, empty, or obviously placeholders.\n- The Claude hook + ctx prompt enhancement is currently wired for Linux/dev-remote environments only. On other platforms, MCP config and uploading still work, but the automatic prompt rewrite hook is disabled.\n\nCommands\n--------\n- Command Palette → “Context Engine Uploader” exposes Start/Stop/Restart/Index Codebase and Prompt+ (unicorn) rewrite commands.\n- Status-bar button (`Index Codebase`) mirrors Start/Stop/Restart/Index status, while the `Prompt+` status button runs the ctx rewrite command on the current selection.\n- `Context Engine Uploader: Write MCP Config (.mcp.json)` writes or updates a project-local `.mcp.json` (plus Windsurf `mcp_config.json` when enabled) using the currently selected bridge/direct + transport modes. If bridge-http is required and not yet running, the extension starts `ctxce mcp-http-serve` before writing configs.\n- `Context Engine Uploader: Write CTX Config (ctx_config.json/.env)` scaffolds the ctx config + env files as described above. This command runs automatically after `Write MCP Config` if scaffolding is enabled, but it is also exposed in the Command Palette for manual use.\n- `Context Engine Uploader: Upload Git History (force sync bundle)` triggers a one-off force sync using the configured git history settings, producing a bundle that includes a `metadata/git_history.json` manifest for remote lineage ingestion.\n- `Context Engine Uploader: Start MCP HTTP Bridge` launches `ctxce mcp-http-serve` using the workspace’s resolved target path, MCP URLs, and configured `mcpBridgePort`. Use this when you want to run the HTTP bridge manually (e.g., testing unpublished builds or sharing a port across IDEs).\n- `Context Engine Uploader: Stop MCP HTTP Bridge` gracefully terminates a running HTTP bridge process.\n\nLogs\n----\nOpen `View → Output → Context Engine Upload` to see the remote uploader’s stdout/stderr, including any errors from the Python client.\n"
      },
      "plugins": [
        {
          "name": "context-engine",
          "description": "Codebase search and context retrieval using hybrid semantic/lexical search with neural reranking",
          "source": "./",
          "strict": false,
          "skills": [
            "./skills/context-engine"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add Context-Engine-AI/Context-Engine",
            "/plugin install context-engine@context-engine-skills"
          ]
        }
      ]
    }
  ]
}