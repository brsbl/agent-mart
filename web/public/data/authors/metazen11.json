{
  "author": {
    "id": "metazen11",
    "display_name": "MZ",
    "avatar_url": "https://avatars.githubusercontent.com/u/83803364?u=d4d3680a591596c52e51bb9026488d0bff84d6a9&v=4"
  },
  "marketplaces": [
    {
      "name": "metazen11-tools",
      "version": null,
      "description": "AI coding agent tools by metazen11",
      "repo_full_name": "metazen11/agent-memory",
      "repo_url": "https://github.com/metazen11/agent-memory",
      "repo_description": "Cross-platform persistent memory service for AI coding agents",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-02-21T14:38:23Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"metazen11-tools\",\n  \"owner\": {\n    \"name\": \"metazen11\",\n    \"email\": \"metazen@artofmetazen.com\"\n  },\n  \"metadata\": {\n    \"description\": \"AI coding agent tools by metazen11\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"agent-memory\",\n      \"source\": \"./\",\n      \"description\": \"Persistent cross-session memory for AI coding agents. Drop-in replacement for claude-mem with PostgreSQL + pgvector, auto-recovery, and multi-agent support.\",\n      \"version\": \"1.0.0\",\n      \"category\": \"memory\",\n      \"tags\": [\"memory\", \"persistent\", \"pgvector\", \"embeddings\", \"cross-session\"]\n    }\n  ]\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"agent-memory\",\n  \"description\": \"Persistent cross-session memory for AI coding agents. Records what was learned, built, fixed, and decided, then makes it searchable via hybrid vector + full-text search. Drop-in replacement for claude-mem.\",\n  \"version\": \"1.0.0\",\n  \"author\": {\n    \"name\": \"metazen11\",\n    \"email\": \"metazen@artofmetazen.com\"\n  },\n  \"homepage\": \"https://github.com/metazen11/agent-memory\",\n  \"repository\": \"https://github.com/metazen11/agent-memory\",\n  \"license\": \"MIT\",\n  \"keywords\": [\n    \"memory\",\n    \"persistent\",\n    \"cross-session\",\n    \"pgvector\",\n    \"embeddings\",\n    \"observations\",\n    \"claude-mem-replacement\"\n  ]\n}\n",
        "README.md": "# agent-memory\n\nPersistent memory for AI coding agents that build, maintain, and enhance long-lived projects.\n\nMost memory solutions assume your relationship with a project ends at `git push`. This one doesn't. If you maintain production systems, ship continuous improvements, and need your agent to remember why that Docker port was changed 4 months ago — agent-memory is built for you.\n\nRecords what was learned, built, fixed, and decided during each session, then makes it searchable via semantic + full-text hybrid search. Claude Code's built-in `MEMORY.md` gives you 200 lines of pinned notes. agent-memory gives you a searchable journal across thousands of observations — so accumulated context becomes a competitive advantage, not a truncated file.\n\nWorks with Claude Code out of the box. Designed to support any AI coding agent via REST API or MCP.\n\n## Quick Start\n\n```bash\ngit clone https://github.com/metazen11/agent-memory.git\ncd agent-memory\nnode install.js\n```\n\nThe installer handles everything:\n- Creates Python venv and installs dependencies\n- Downloads embedding model (~400MB) and observation LLM (~1GB)\n- Generates `.env` with random Postgres password\n- Starts Docker (PostgreSQL + pgvector)\n- Starts FastAPI server on port 3377\n- Registers MCP server, hooks, and skills in Claude Code\n\n### Commands\n\n```bash\nnode install.js              # Full setup + install\nnode install.js --status     # Show what's installed and running\nnode install.js --start      # Start services (Docker + FastAPI)\nnode install.js --stop       # Stop services\nnode install.js --migrate    # Run pending database migrations\nnode install.js --migrate --dry-run  # Preview migrations (no changes)\nnode install.js --migrate --backup   # Backup tables, then migrate\nnode install.js --backup     # Backup mem_* tables only\nnode install.js --uninstall  # Remove hooks, MCP, skills\n```\n\n### Prerequisites\n\n- **Docker** *(or external PostgreSQL)* — macOS: `brew install --cask docker` | Linux: `sudo apt install docker.io docker-compose-plugin`\n- **Python 3.12+** — macOS: `brew install python@3.12` | Linux: `sudo apt install python3.12 python3.12-venv`\n- **Node.js** — for the installer and hooks\n\n## Architecture\n\n```\n┌─────────────────────────────────────────────────────────┐\n│  Claude Code Session                                    │\n│                                                         │\n│  session-start hook ──► Health check → auto-start       │\n│                     └──► Inject MCP guide + context     │\n│  post-tool-use hook ──► POST /api/queue (fire & forget) │\n│  session-end hook   ──► PATCH /api/sessions/:id         │\n└──────────────┬──────────────────────────────────────────┘\n               │ HTTP (localhost:3377)\n┌──────────────▼──────────────────────────────────────────┐\n│  FastAPI Server (uvicorn, port 3377)                    │\n│                                                         │\n│  /api/queue ──► observation_queue table                  │\n│  /api/observations ──► CRUD + hybrid search             │\n│  /api/sessions ──► session lifecycle                     │\n│  /api/admin ──► stats, re-embed                         │\n│                                                         │\n│  Queue Worker (background asyncio task)                 │\n│  ├─ Dequeue pending items (FOR UPDATE SKIP LOCKED)      │\n│  ├─ Generate observation via LLM (local GGUF → Haiku)   │\n│  ├─ Embed via sentence-transformers (in-process)        │\n│  └─ Insert into mem_observations with vector            │\n└──────────────┬──────────────────────────────────────────┘\n               │\n┌──────────────▼──────────────────────────────────────────┐\n│  MCP Server (stdio, separate process)                   │\n│  Registered in ~/.claude/.mcp.json                      │\n│                                                         │\n│  Tools: search, timeline, get_observations, save_memory │\n│  Own DB pool + embedding model (zero FastAPI deps)      │\n└──────────────┬──────────────────────────────────────────┘\n               │\n┌──────────────▼──────────────────────────────────────────┐\n│  PostgreSQL 16 + pgvector (Docker)                      │\n│  Tables: mem_* prefixed (avoids collisions)             │\n└─────────────────────────────────────────────────────────┘\n```\n\n## How It Works\n\n### Recording (write path)\n\nEvery tool call in your coding session is captured:\n\n1. **PostToolUse hook** fires (fire-and-forget, ~40ms)\n2. Tool call data queued to `/api/queue`\n3. Background worker dequeues with `FOR UPDATE SKIP LOCKED`\n4. Local LLM extracts structured observation (title, type, narrative, facts)\n5. Sentence-transformers generates 768-dim embedding\n6. Inserted into PostgreSQL with pgvector index\n\n### Retrieval (read path)\n\nSearch past sessions via MCP tools (3-layer workflow):\n\n1. `search(query)` — hybrid vector + full-text search, returns IDs (~50-100 tokens/result)\n2. `timeline(anchor=ID)` — context around interesting results\n3. `get_observations([IDs])` — full details only for filtered IDs\n\nNever skip to step 3. Always filter first. 10x token savings.\n\n### Auto-start\n\nThe session-start hook automatically starts services if they're not running. No manual intervention needed after initial install.\n\n## Configuration\n\n### .env\n\nGenerated by `install.js`. Key settings:\n\n| Variable | Default | Description |\n|----------|---------|-------------|\n| `POSTGRES_USER` | `agentmem` | PostgreSQL user |\n| `POSTGRES_PASSWORD` | *(generated)* | PostgreSQL password |\n| `POSTGRES_HOST` | `localhost` | PostgreSQL host |\n| `POSTGRES_PORT` | `5433` | PostgreSQL port |\n| `POSTGRES_DB` | `agent_memory` | Database name |\n| `DATABASE_URL` | *(built from above)* | Full URL override |\n| `EMBEDDING_MODEL` | `nomic-ai/nomic-embed-text-v1.5` | Sentence-transformers model |\n| `OBSERVATION_LLM_MODEL` | *(path to .gguf)* | Local LLM for observation extraction |\n| `ANTHROPIC_API_KEY` | *(empty)* | Haiku fallback if no local LLM |\n| `PORT` | `3377` | FastAPI server port |\n\n### Existing Database (Bring Your Own Postgres)\n\nIf you already have a PostgreSQL 16+ instance with pgvector, set `DATABASE_URL` in `.env`:\n\n```bash\nDATABASE_URL=postgresql://user:pass@host:5433/dbname\n```\n\nWhen `DATABASE_URL` is set, the installer:\n- Skips Docker entirely (no container needed)\n- Runs versioned SQL migrations against your database\n- Creates all `mem_`-prefixed tables (avoids collisions with other apps)\n\nRequirements for external databases:\n- PostgreSQL 16+ with the `vector` extension (pgvector)\n- A database and user with CREATE TABLE / CREATE EXTENSION permissions\n\n### Schema Migrations\n\nThe database schema is managed by versioned SQL migrations in `scripts/migrations/`:\n\n```\nscripts/migrations/\n├── 001-initial-schema.sql     # Tables, indexes, pgvector extension\n├── 002-add-new-feature.sql    # Future migrations...\n└── ...\n```\n\nMigrations run automatically:\n- During `node install.js` (step 7)\n- On every FastAPI server startup\n- Via `python scripts/run_migrations.py` (manual)\n\nEach migration runs exactly once. A `mem_schema_migrations` table tracks which have been applied.\n\n## Components\n\n### FastAPI Server (`app/`)\n\n| File | Purpose |\n|------|---------|\n| `main.py` | App lifecycle (pool init, migrations, queue worker) |\n| `migrate.py` | Versioned SQL migration runner |\n| `config.py` | Pydantic settings from `.env` |\n| `db.py` | asyncpg connection pool |\n| `models.py` | Pydantic schemas |\n| `embeddings.py` | Sentence-transformers in-process embeddings (768-dim) |\n| `observation_llm.py` | Local GGUF (Qwen2.5-1.5B) with Anthropic Haiku fallback |\n| `queue_worker.py` | Background asyncio task, processes queue items |\n| `routes/` | Health, observations, sessions, admin endpoints |\n\n### MCP Server (`mcp_server.py`)\n\nSelf-contained stdio MCP server. Own DB pool and embedding model — zero dependency on FastAPI.\n\n### Hooks (`hooks/`)\n\n| Hook | Event | Timeout | Description |\n|------|-------|---------|-------------|\n| `session-start.js` | SessionStart | 60s | Health check, auto-start services, inject context |\n| `post-tool-use.js` | PostToolUse | 5s | Fire-and-forget observation capture |\n| `session-end.js` | Stop | 10s | Mark session completed |\n| `ensure-services.js` | *(internal)* | — | Starts Docker + FastAPI when called by session-start |\n\n### Skills (`skills/`)\n\n`/mem-search` — User-invocable skill for searching past sessions.\n\n## API Endpoints\n\n### Health & Admin\n\n| Method | Path | Description |\n|--------|------|-------------|\n| `GET` | `/api/health` | DB, embeddings, queue depth |\n| `GET` | `/api/admin/stats` | Counts and type breakdown |\n| `POST` | `/api/admin/re-embed` | Background re-embed job |\n\n### Observations\n\n| Method | Path | Description |\n|--------|------|-------------|\n| `POST` | `/api/queue` | Queue tool call for async extraction |\n| `POST` | `/api/observations` | Create observation directly |\n| `GET` | `/api/observations` | List with filters |\n| `POST` | `/api/observations/search` | Hybrid search |\n\n### Sessions\n\n| Method | Path | Description |\n|--------|------|-------------|\n| `POST` | `/api/sessions` | Start new session |\n| `PATCH` | `/api/sessions/{id}` | Update session status |\n| `GET` | `/api/sessions` | List sessions |\n\n## Database Schema\n\nAll tables use the `mem_` prefix.\n\n| Table | Purpose |\n|-------|---------|\n| `embedding_models` | Registry of embedding models |\n| `mem_projects` | Auto-created from working directory |\n| `mem_sessions` | One per coding session |\n| `mem_observations` | Core memory unit with embeddings |\n| `mem_observation_queue` | Async processing queue |\n\n### Search Strategy\n\nHybrid search using **Reciprocal Rank Fusion (RRF)** with k=60:\n1. **Vector search** — cosine similarity via pgvector HNSW index\n2. **Full-text search** — PostgreSQL tsvector with weighted fields\n3. **RRF fusion** — `score = sum(1/(60+rank))` across both result sets\n\n## Multi-Agent Support\n\nThe system is agent-agnostic. The hooks are the Claude-specific integration layer.\n\n**REST API** — Any agent can POST to `/api/queue` and GET from `/api/observations`.\n\n**MCP** — Register `mcp_server.py` in any MCP-compatible agent's config.\n\n**Direct SQL** — Query `mem_observations` with pgvector operators.\n\nSee **[docs/PRIMER.md](docs/PRIMER.md)** for the full multi-agent integration guide with config snippets for Claude Code, Cursor, Windsurf, Cline, Codex CLI, Zed, VS Code Copilot, and custom agents.\n\n## Why Replace claude-mem?\n\nThis project was built as a direct replacement for [claude-mem](https://github.com/thedotmack/claude-mem) after hitting persistent stability issues:\n\n- **PostToolUse hook hangs** — claude-mem's `PostToolUse` hook uses `matcher: \"*\"` with a 120-second timeout. It fires on every single tool call, spawns worker-service daemons, and frequently hangs waiting for ChromaDB sync. This blocks Claude Code after every tool use. The fix (removing the hook from `hooks.json`) gets overwritten on every plugin update.\n- **Zombie processes** — The worker-service daemons accumulate. We've seen 50-80+ zombie `worker-service` processes in a single session, consuming memory and CPU.\n- **ChromaDB crashes on Apple Silicon** — ChromaDB 1.5.0's Rust bindings (`chromadb_rust_bindings.abi3.so`) segfault on macOS ARM64 due to a thread-safety bug. Multiple tokio workers contend on a mutex, causing SIGSEGV.\n- **No real vector search** — claude-mem uses ChromaDB/SQLite locally, which doesn't scale well and lacks proper hybrid search. agent-memory uses PostgreSQL + pgvector with HNSW indexes and Reciprocal Rank Fusion (vector + full-text).\n- **No auto-recovery** — When claude-mem's database or services go down, they stay down. agent-memory's session-start hook auto-detects unhealthy services and restarts Docker containers and the FastAPI server automatically.\n- **Fire-and-forget hooks** — agent-memory's PostToolUse hook writes stdout immediately and exits in ~30ms. The HTTP POST to the queue is unref'd so it never blocks the Node.js event loop. claude-mem's hook blocks until its worker completes.\n\nIf you're currently using claude-mem and experiencing hangs, crashes, or zombie processes, agent-memory is a drop-in replacement with a migration script included.\n\n## Migration from claude-mem\n\n```bash\nsource .venv/bin/activate\npython scripts/migrate_claude_mem.py       # migrate without embeddings\npython scripts/migrate_claude_mem.py --embed  # migrate with embeddings\npython scripts/re_embed.py --only-missing  # embed missing observations\n```\n\n## Debug\n\n| Hook | Default | Toggle |\n|------|---------|--------|\n| session-start | ON | `AGENT_MEMORY_DEBUG=0` |\n| post-tool-use | OFF | `AGENT_MEMORY_DEBUG=1` |\n| session-end | ON | `AGENT_MEMORY_DEBUG=0` |\n\n```bash\nAGENT_MEMORY_DEBUG=1 claude   # enable all\n```\n\n## Docker\n\n```bash\ncd docker && docker compose up -d     # start\ncd docker && docker compose down      # stop\ncd docker && docker compose down -v   # reset (destroys data)\n```\n"
      },
      "plugins": [
        {
          "name": "agent-memory",
          "source": "./",
          "description": "Persistent cross-session memory for AI coding agents. Drop-in replacement for claude-mem with PostgreSQL + pgvector, auto-recovery, and multi-agent support.",
          "version": "1.0.0",
          "category": "memory",
          "tags": [
            "memory",
            "persistent",
            "pgvector",
            "embeddings",
            "cross-session"
          ],
          "categories": [
            "cross-session",
            "embeddings",
            "memory",
            "persistent",
            "pgvector"
          ],
          "install_commands": [
            "/plugin marketplace add metazen11/agent-memory",
            "/plugin install agent-memory@metazen11-tools"
          ]
        }
      ]
    }
  ]
}