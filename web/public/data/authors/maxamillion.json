{
  "author": {
    "id": "maxamillion",
    "display_name": "Adam Miller",
    "avatar_url": "https://avatars.githubusercontent.com/u/839000?u=53519f89e1407c71e803f0135ca2fc076062881f&v=4"
  },
  "marketplaces": [
    {
      "name": "maxamillion-agentskill-redhat-contribution-report",
      "version": null,
      "description": "Evaluate Red Hat employee contributions to open source projects using LDAP org traversal and GitHub analysis",
      "repo_full_name": "maxamillion/agentskill-redhat-contribution-report",
      "repo_url": "https://github.com/maxamillion/agentskill-redhat-contribution-report",
      "repo_description": "AgentSkilll to evaluate level of contribution by Red Hat to an open source project",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-02-10T21:20:06Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"$schema\": \"https://anthropic.com/claude-code/marketplace.schema.json\",\n  \"name\": \"maxamillion-agentskill-redhat-contribution-report\",\n  \"description\": \"Evaluate Red Hat employee contributions to open source projects using LDAP org traversal and GitHub analysis\",\n  \"owner\": {\n    \"name\": \"Adam Miller\",\n    \"email\": \"admiller@redhat.com\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"redhat-contribution-report\",\n      \"description\": \"Evaluates Red Hat contributions to OSS projects across PRs, maintainership, governance, roadmap influence, and leadership roles\",\n      \"author\": {\n        \"name\": \"Adam Miller\",\n        \"email\": \"admiller@redhat.com\"\n      },\n      \"source\": \"./redhat-contribution-report\",\n      \"category\": \"analysis\",\n      \"homepage\": \"https://github.com/maxamillion/agentskill-redhat-contribution-report\"\n    }\n  ]\n}\n",
        "README.md": "# Red Hat Open Source Contribution Report\n\nA [Claude Code AgentSkill](https://agentskills.io/home) that evaluates Red Hat employee contributions to open source projects.\n\n## What It Does\n\nGiven an organizational leader's email address and a list of open source projects, this skill:\n\n1. **Discovers employees** by traversing Red Hat's internal LDAP hierarchy from the specified manager down through all reports\n2. **Resolves GitHub identities** from LDAP attributes (`rhatSocialURL`), git commit email matching, and GitHub user search\n3. **Evaluates 5 KPIs** per project using parallel sub-agents:\n   - **PR/Commit Contributions** — Code authored or co-authored by Red Hat employees\n   - **Release Management** — Release managers who are Red Hat employees\n   - **Maintainer/Reviewer/Approver Roles** — Red Hat employees in OWNERS, CODEOWNERS, MAINTAINERS files\n   - **Roadmap Influence** — Enhancement proposals and features led by Red Hat employees\n   - **Leadership Roles** — Governance positions (TAC, Steering Committee, Advisory Board) held by Red Hat employees\n4. **Generates a report** with per-employee role identification, per-project KPI scores, cross-project comparison, and confidence tracking\n\n## Prerequisites\n\n- **Operating System:** RHEL or Fedora Linux\n- **Network:** Red Hat internal network access (VPN)\n- **Kerberos:** Valid TGT (`kinit your-uid@REDHAT.COM`)\n- **LDAP Client:** `openldap-clients` package installed\n  ```bash\n  # Fedora\n  sudo dnf install openldap-clients\n\n  # RHEL\n  sudo yum install openldap-clients\n  ```\n- **GitHub CLI:** `gh` authenticated with your GitHub account\n  ```bash\n  sudo dnf install gh\n  gh auth login\n  ```\n- **Claude Code:** With this plugin installed\n\n## Installation\n\n### From Marketplace\n\nFirst, add the marketplace source (inside Claude Code):\n\n```\n/plugin marketplace add maxamillion/agentskill-redhat-contribution-report\n```\n\nThen install the plugin:\n\n```\n/plugin install redhat-contribution-report@maxamillion-agentskill-redhat-contribution-report\n```\n\n### From Source\n\nClone this repository and add it as a local plugin (inside Claude Code):\n\n```bash\ngit clone https://github.com/maxamillion/agentskill-redhat-contribution-report.git\n```\n\n```\n/plugin marketplace add /path/to/agentskill-redhat-contribution-report\n/plugin install redhat-contribution-report@maxamillion-agentskill-redhat-contribution-report\n```\n\n## Usage\n\n```\n/redhat-contribution-report <manager_email> <project1> [project2] [project3] ...\n```\n\n### Examples\n\nEvaluate Red Hat AI Engineering contributions to ML/AI projects:\n```\n/redhat-contribution-report manager@redhat.com kubeflow/kubeflow kserve/kserve mlflow/mlflow vllm-project/vllm\n```\n\nEvaluate a single project:\n```\n/redhat-contribution-report manager@redhat.com kubernetes/kubernetes\n```\n\n### Arguments\n\n| Argument | Required | Description |\n|----------|----------|-------------|\n| `manager_email` | Yes | Email of the org leader whose reports to evaluate (e.g., `manager@redhat.com`) |\n| `project(s)` | Yes (1+) | GitHub repositories in `owner/repo` format |\n\n## Output\n\nReports are saved to:\n```\nreports/YYYY-MM-DD-redhat-contribution-eval.md\n```\n\n### Report Contents\n\n- **Executive Summary** with overall scores across all projects\n- **Employee Roster** with GitHub username resolution coverage\n- **Per-Project Sections** containing:\n  - Employee contribution table (name, GitHub username, project roles)\n  - 5 KPI evaluations with scores (1-5), evidence, and confidence levels\n- **Cross-Project Comparison** table\n- **Data Quality & Methodology** notes\n\n### Scoring Scale\n\nEach KPI is scored 1-5:\n\n| Score | Label |\n|-------|-------|\n| 5 | Dominant/Primary presence |\n| 4 | Major contributor |\n| 3 | Significant contributor |\n| 2 | Minor/peripheral involvement |\n| 1 | No involvement found |\n\n### Confidence Levels\n\n| Level | Meaning |\n|-------|---------|\n| High | Data from authoritative sources (LDAP, GitHub API, governance files) |\n| Medium | Data from semi-structured sources or email-matched employees |\n| Low | Data from web search or name-matched employees |\n| Not Found | Could not find data for this metric |\n\n## Architecture\n\n```\nSKILL.md (orchestrator)\n  ├── Phase 1: Input parsing & prerequisite checks\n  ├── Phase 2: LDAP org traversal (GSSAPI auth)\n  ├── Phase 3: GitHub username resolution\n  ├── Phase 4: Parallel sub-agents (one per project)\n  │     ├── KPI 1: PR/Commit analysis (gh CLI)\n  │     ├── KPI 2: Release management (gh CLI)\n  │     ├── KPI 3: Governance files (OWNERS, CODEOWNERS, etc.)\n  │     ├── KPI 4: Roadmap issues & proposals (gh CLI)\n  │     └── KPI 5: Leadership roles (governance docs + web search)\n  ├── Phase 5: Result collection & merging\n  └── Phase 6: Report generation\n```\n\n## File Structure\n\n```\nredhat-contribution-report/\n├── .claude-plugin/\n│   └── plugin.json                  # Plugin identity\n└── skills/\n    └── redhat-contribution-report/\n        ├── SKILL.md                 # Main orchestrator\n        ├── assets/\n        │   └── scoring-rubric.json  # KPI scoring thresholds\n        └── references/\n            ├── LDAP-GUIDE.md        # LDAP connection & traversal docs\n            ├── DATA-SOURCES.md      # gh CLI commands by KPI\n            ├── REPORT-TEMPLATE.md   # Output format specification\n            └── RESEARCH-PROMPTS.md  # Sub-agent prompt templates\n```\n\n## License\n\nMIT\n"
      },
      "plugins": [
        {
          "name": "redhat-contribution-report",
          "description": "Evaluates Red Hat contributions to OSS projects across PRs, maintainership, governance, roadmap influence, and leadership roles",
          "author": {
            "name": "Adam Miller",
            "email": "admiller@redhat.com"
          },
          "source": "./redhat-contribution-report",
          "category": "analysis",
          "homepage": "https://github.com/maxamillion/agentskill-redhat-contribution-report",
          "categories": [
            "analysis"
          ],
          "install_commands": [
            "/plugin marketplace add maxamillion/agentskill-redhat-contribution-report",
            "/plugin install redhat-contribution-report@maxamillion-agentskill-redhat-contribution-report"
          ]
        }
      ]
    },
    {
      "name": "claude-oss-eval-plugin",
      "version": null,
      "description": "15-phase OSS framework evaluation methodology with AI bias prevention. Evaluates open source projects for adoption decisions with rigorous safeguards against common AI analysis pitfalls.",
      "repo_full_name": "maxamillion/claude-oss-eval-plugin",
      "repo_url": "https://github.com/maxamillion/claude-oss-eval-plugin",
      "repo_description": "Claude Code skills to evaluate open source projects",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-01-19T17:10:31Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"claude-oss-eval-plugin\",\n  \"owner\": {\n    \"name\": \"Adam Miller\",\n    \"url\": \"https://github.com/maxamillion\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"oss-eval\",\n      \"source\": \"./\",\n      \"description\": \"15-phase OSS framework evaluation methodology with AI bias prevention. Evaluates open source projects for adoption decisions with rigorous safeguards against common AI analysis pitfalls.\",\n      \"version\": \"1.0.5\",\n      \"homepage\": \"https://github.com/maxamillion/claude-oss-eval-plugin\",\n      \"repository\": \"https://github.com/maxamillion/claude-oss-eval-plugin\",\n      \"license\": \"MIT\"\n    }\n  ]\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"oss-eval\",\n  \"description\": \"15-phase OSS framework evaluation methodology with AI bias prevention. Evaluates open source projects for adoption decisions with rigorous safeguards against common AI analysis pitfalls.\",\n  \"version\": \"1.0.5\",\n  \"author\": {\n    \"name\": \"Adam Miller\",\n    \"url\": \"https://github.com/maxamillion\"\n  },\n  \"repository\": \"https://github.com/maxamillion/claude-oss-eval-plugin\",\n  \"license\": \"MIT\",\n  \"keywords\": [\n    \"oss\",\n    \"evaluation\",\n    \"framework\",\n    \"adoption\",\n    \"analysis\",\n    \"bias-prevention\"\n  ]\n}\n",
        "README.md": "# OSS Evaluation Claude Plugin\n\nA comprehensive Claude Code plugin implementing a 15-phase methodology for evaluating open source software frameworks with built-in safeguards against AI analysis pitfalls.\n\nThis plugin is a work in progress and is subject to change.\n\n## Attribution and Acknowledgments\n\nThe methodology used here to evaluate OSS frameworks was created by [@jwforres](https://github.com/jwforres) and [@n1hility](https://github.com/n1hility), and adapted here as a Claude Code Plugin.\n\n## Overview\n\nThis plugin provides a structured, bias-resistant approach to evaluating OSS frameworks for adoption decisions. It addresses common AI analysis problems including:\n\n- **Stale Knowledge**: Forces web verification of all metrics\n- **False Differentiation**: Systematic cross-platform feature checking\n- **OSS/Commercial Conflation**: Mandatory `[OSS]`/`[PAID]` annotations\n- **Complexity Overestimation**: Component-level effort breakdown\n- **Baseline Drift**: Locked comparison criteria from Phase 1\n- **Marketing Language**: Technical translation requirements\n\n## Installation\n\n### Option 1: Plugin Marketplace (Recommended)\n\nInstall directly within Claude Code using the plugin system:\n\n```bash\n# Add the marketplace (one time)\n/plugin marketplace add maxamillion/claude-oss-eval-plugin\n\n# Install the plugin\n/plugin install oss-eval\n```\n\nThe plugin will be available immediately. Commands are namespaced as `/oss-eval:command`.\n\n### Option 2: Local Development\n\nFor testing or contributing to the plugin:\n\n```bash\n# Clone the repository\ngit clone https://github.com/maxamillion/claude-oss-eval-plugin.git\n\n# Run Claude Code with the plugin directory\nclaude --plugin-dir /path/to/claude-oss-eval-plugin\n```\n\n### Option 3: Project Scope Installation\n\nShare the plugin with your team via git:\n\n```bash\n# Add marketplace and install with project scope\n/plugin marketplace add maxamillion/claude-oss-eval-plugin\n/plugin install oss-eval --scope project\n```\n\nThis adds the plugin configuration to your project's `.claude/` directory.\n\n### Plugin Management\n\n```bash\n# List installed plugins\n/plugin list\n\n# Update to latest version\n/plugin update oss-eval\n\n# Disable temporarily\n/plugin disable oss-eval\n\n# Re-enable\n/plugin enable oss-eval\n\n# Uninstall\n/plugin uninstall oss-eval\n```\n\n## Quick Start\n\n### Recommended: Single Command (Automated)\n\nRun a complete 15-phase evaluation with a single command:\n\n```bash\n# Full automated evaluation\n/oss-eval:run Python web frameworks\n\n# With interactive checkpoints for user decisions\n/oss-eval:run JavaScript state management --interactive\n\n# Stop after Phase 6 for interim review\n/oss-eval:run container orchestration --to-phase 6\n\n# Resume an interrupted evaluation\n/oss-eval:run --resume\n```\n\n### Alternative: Manual Step-by-Step\n\nFor more control, run phases individually:\n\n```bash\n# Initialize a new evaluation\n/oss-eval:start Python web frameworks\n\n# Check current progress\n/oss-eval:status\n\n# Work through phases sequentially\n/oss-eval:discover     # Phase 1\n/oss-eval:analyze      # Phase 2\n/oss-eval:matrix       # Phase 3\n# ... continue through all 15 phases\n\n# Generate reports\n/oss-eval:report --interim  # After Phase 6\n/oss-eval:report            # After Phase 15\n```\n\n## The 15-Phase Methodology\n\n### Discovery & Analysis (Phases 1-6)\n\n| Phase | Command | Purpose |\n|-------|---------|---------|\n| 1 | `/oss-eval:discover` | Web search discovery of candidates |\n| 2 | `/oss-eval:analyze` | Detailed candidate analysis |\n| 3 | `/oss-eval:matrix` | Feature comparison matrix |\n| 4 | `/oss-eval:licensing` | License and dependency analysis |\n| 5 | `/oss-eval:community` | Community health assessment |\n| 6 | `/oss-eval:risk` | Quantified risk scoring |\n\n**Milestone**: After Phase 6, generate interim report with `/oss-eval:report --interim`\n\n### Technical Deep-Dive (Phases 7-9)\n\n| Phase | Command | Purpose |\n|-------|---------|---------|\n| 7 | `/oss-eval:architecture` | Code-level architecture analysis |\n| 8 | `/oss-eval:requirements` | Requirements alignment mapping |\n| 9 | `/oss-eval:gaps` | Gap mitigation strategy |\n\n### Integration Analysis (Phases 10-12)\n\n| Phase | Command | Purpose |\n|-------|---------|---------|\n| 10 | `/oss-eval:ui` | UI integration assessment |\n| 11 | `/oss-eval:costs` | Total cost of ownership |\n| 12 | `/oss-eval:dx` | Developer experience evaluation |\n\n### Validation (Phases 13-15)\n\n| Phase | Command | Purpose |\n|-------|---------|---------|\n| 13 | `/oss-eval:context` | Product context integration |\n| 14 | `/oss-eval:hybrid` | Hybrid strategy exploration |\n| 15 | `/oss-eval:validate` | Adversarial review & validation |\n\n**Final**: Generate complete report with `/oss-eval:report`\n\n## Key Features\n\n### Bias Prevention Skills\n\nThree core skills loaded automatically during evaluation:\n\n1. **`bias-prevention`**: 12 pitfall prevention rules\n2. **`feature-verification`**: Cross-platform capability checking\n3. **`source-validation`**: Web source credibility verification\n\n### Isolated Adversarial Review\n\nPhase 15 uses an isolated sub-agent for unbiased review:\n\n```yaml\nagent: general-purpose\ncontext: fork  # No access to prior evaluation context\n```\n\nThis ensures the recommendation is stress-tested by a fresh perspective.\n\n### Required Annotations\n\nAll features in the matrix must include availability tags:\n\n- `[OSS]` - Open source availability\n- `[PAID]` - Requires paid/enterprise tier\n- `[PLUGIN]` - Requires additional plugin\n- `[COMMUNITY]` - Community-maintained only\n- `[DEPRECATED]` - Being phased out\n- `[BETA]` - Not production-ready\n\n### Evidence Requirements\n\nEvery claim requires verification:\n\n```markdown\n<!-- Required format -->\nFastAPI has 78,234 GitHub stars [Verified: 2025-01-16 via github.com]\n```\n\n## Directory Structure\n\n```\nclaude-oss-eval-plugin/\n├── .claude-plugin/\n│   ├── plugin.json           # Plugin manifest\n│   └── marketplace.json      # Marketplace configuration\n├── commands/\n│   ├── oss-eval.md           # Main entry point (manual mode)\n│   ├── oss-run.md            # Automated orchestrator (recommended)\n│   ├── oss-discover.md       # Phase 1\n│   ├── oss-analyze.md        # Phase 2\n│   ├── oss-matrix.md         # Phase 3\n│   ├── oss-licensing.md      # Phase 4\n│   ├── oss-community.md      # Phase 5\n│   ├── oss-risk.md           # Phase 6\n│   ├── oss-architecture.md   # Phase 7\n│   ├── oss-requirements.md   # Phase 8\n│   ├── oss-gaps.md           # Phase 9\n│   ├── oss-ui.md             # Phase 10\n│   ├── oss-costs.md          # Phase 11\n│   ├── oss-dx.md             # Phase 12\n│   ├── oss-context.md        # Phase 13\n│   ├── oss-hybrid.md         # Phase 14\n│   ├── oss-validate.md       # Phase 15\n│   ├── oss-report.md         # Report generation\n│   └── oss-status.md         # Status checking\n├── skills/\n│   ├── bias-prevention/\n│   │   └── SKILL.md          # 12 pitfall prevention rules\n│   ├── feature-verification/\n│   │   └── SKILL.md          # Cross-platform checking\n│   └── source-validation/\n│       └── SKILL.md          # Source credibility rules\n├── agents/\n│   ├── adversarial-reviewer.md  # Isolated validation agent\n│   └── discovery-agent.md       # Web search discovery agent\n├── templates/\n│   ├── feature-matrix.md     # Feature comparison template\n│   ├── risk-assessment.md    # Risk scoring template\n│   └── final-report.md       # Executive summary template\n└── README.md\n```\n\n## Evaluation Workspace\n\nWhen you start an evaluation, a `.oss-eval/` directory is created:\n\n```\n.oss-eval/\n├── config.json                # Evaluation configuration\n├── progress.md                # Phase completion tracking\n├── baseline-criteria.md       # Locked comparison criteria\n├── phase-01-discovery/\n│   ├── candidates.md\n│   └── sources.md\n├── phase-02-analysis/\n│   ├── candidate-a.md\n│   └── summary.md\n├── phase-03-features/\n│   └── feature-matrix.md\n├── phase-04-licensing/\n│   └── licensing-analysis.md\n├── phase-05-community/\n│   └── community-health.md\n├── phase-06-risk/\n│   └── risk-assessment.md\n├── phase-07-architecture/\n│   ├── candidate-a/\n│   │   └── code-analysis.md\n│   └── candidate-b/\n├── phase-08-requirements/\n│   └── requirements-alignment.md\n├── phase-09-gaps/\n│   └── gap-mitigation.md\n├── phase-10-ui/\n│   └── ui-integration.md\n├── phase-11-costs/\n│   └── operational-costs.md\n├── phase-12-dx/\n│   └── developer-experience.md\n├── phase-13-context/\n│   └── product-context.md\n├── phase-14-hybrid/\n│   └── hybrid-strategies.md\n├── phase-15-validation/\n│   ├── adversarial-review.md\n│   ├── dissenting-views.md\n│   └── final-validation.md\n├── interim-report.md          # Generated after Phase 6\n└── final-report.md            # Generated after Phase 15\n```\n\n## The 12 AI Analysis Pitfalls\n\nThis plugin specifically addresses these common issues:\n\n| # | Pitfall | Prevention |\n|---|---------|------------|\n| 1 | Stale/Outdated Knowledge | WebSearch verification required |\n| 2 | False Feature Differentiation | Cross-platform terminology mapping |\n| 3 | OSS/Commercial Conflation | Mandatory [OSS]/[PAID] tags |\n| 4 | Complexity Overestimation | Component-level breakdown |\n| 5 | Baseline Drift | Locked criteria from Phase 1 |\n| 6 | Marketing Language | Technical translation required |\n| 7 | Popularity Bias | Technical merit over stars |\n| 8 | Recency Bias | Full history consideration |\n| 9 | Confirmation Bias | Adversarial review process |\n| 10 | Halo Effect | Independent dimension scoring |\n| 11 | Anchoring Bias | Consistent checklists |\n| 12 | Sunk Cost Bias | \"None suitable\" is valid |\n\n## Example Evaluation\n\n### Automated (Recommended)\n\n```bash\n# Complete evaluation with a single command\n/oss-eval:run Python web frameworks\n\n# Output:\n# ═══════════════════════════════════════════════════════════════\n#   OSS EVALUATION: Python web frameworks\n#   Mode: Automated Full Run\n#   Phases: 1-15\n# ═══════════════════════════════════════════════════════════════\n#\n# Starting comprehensive 15-phase evaluation...\n# [Phases execute automatically with progress updates]\n#\n# ═══════════════════════════════════════════════════════════════\n#   OSS EVALUATION COMPLETE\n# ═══════════════════════════════════════════════════════════════\n# RECOMMENDATION: FastAPI\n# Confidence: 87%\n```\n\n### With Interactive Checkpoints\n\n```bash\n# Pause at key decision points\n/oss-eval:run Python web frameworks --interactive\n\n# Pauses after Phase 6 to confirm candidate selection\n# Pauses after Phase 14 to confirm recommendation before adversarial review\n```\n\n### Manual Step-by-Step\n\n```bash\n# Initialize evaluation\n/oss-eval:start Python web frameworks\n\n# Run phases individually\n/oss-eval:discover     # Phase 1\n/oss-eval:analyze      # Phase 2\n/oss-eval:matrix       # Phase 3\n# ... continue through all 15 phases\n\n# Check progress anytime\n/oss-eval:status\n\n# Generate reports\n/oss-eval:report --interim  # After Phase 6\n/oss-eval:report            # After Phase 15\n```\n\n## Best Practices\n\n1. **Complete phases sequentially** - Each phase builds on previous findings\n2. **Don't skip the adversarial review** - Phase 15 catches blind spots\n3. **Use web search for all metrics** - Never trust cached knowledge for numbers\n4. **Document rejected candidates** - Explain why alternatives weren't chosen\n5. **Preserve dissenting views** - Even if not adopted, document them\n6. **Maintain baseline criteria** - Don't shift goalposts during evaluation\n\n## Contributing\n\nContributions welcome! Please ensure any additions:\n\n- Follow the bias prevention principles\n- Include evidence requirements\n- Document clearly with examples\n- Add appropriate checkpoints\n\n## License\n\nMIT License - See LICENSE file for details.\n"
      },
      "plugins": [
        {
          "name": "oss-eval",
          "source": "./",
          "description": "15-phase OSS framework evaluation methodology with AI bias prevention. Evaluates open source projects for adoption decisions with rigorous safeguards against common AI analysis pitfalls.",
          "version": "1.0.5",
          "homepage": "https://github.com/maxamillion/claude-oss-eval-plugin",
          "repository": "https://github.com/maxamillion/claude-oss-eval-plugin",
          "license": "MIT",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add maxamillion/claude-oss-eval-plugin",
            "/plugin install oss-eval@claude-oss-eval-plugin"
          ]
        }
      ]
    }
  ]
}