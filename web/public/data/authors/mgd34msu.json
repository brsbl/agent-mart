{
  "author": {
    "id": "mgd34msu",
    "display_name": "Michael Davis",
    "avatar_url": "https://avatars.githubusercontent.com/u/18431027?u=948c04c86a72ea649007575eedcaa5e083e89a00&v=4"
  },
  "marketplaces": [
    {
      "name": "goodvibes-market",
      "version": null,
      "description": "goodvibes plugin marketplace",
      "repo_full_name": "mgd34msu/goodvibes-plugin",
      "repo_url": "https://github.com/mgd34msu/goodvibes-plugin",
      "repo_description": "Claude Code plugin that replaces native tools with token-efficient precision equivalents. 75 MCP tools, 11 specialized agents, persistent cross-session memory, and 7-layer token optimization that compounds savings from per-operation verbosity control through dual-layer caching to orchestration-level efficiency.",
      "signals": {
        "stars": 3,
        "forks": 0,
        "pushed_at": "2026-02-20T15:22:23Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"goodvibes-market\",\n  \"owner\": {\n    \"name\": \"Mike Davis\",\n    \"email\": \"mgd34msu@gmail.com\"\n  },\n  \"metadata\": {\n    \"description\": \"goodvibes plugin marketplace\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"goodvibes\",\n      \"source\": \"./plugins/goodvibes\",\n      \"description\": \"Comprehensive Claude Code plugin with agents, skills, tools, hooks, and MCP servers for full-stack development.\",\n      \"version\": \"1.0.0\",\n      \"author\": {\n        \"name\": \"Mike Davis\"\n      }\n    }\n  ]\n}\n",
        "README.md": "# GoodVibes Plugin\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Version](https://img.shields.io/badge/version-1.2.30-blue.svg)](https://github.com/mgd34msu/goodvibes-plugin)\n[![Claude Code Plugin](https://img.shields.io/badge/Claude%20Code-Plugin-purple.svg)](https://claude.com/claude-code)\n\n> Plug in. Receive good vibes.\n\nA Claude Code plugin that replaces native tools with token-efficient precision equivalents, adds 70 MCP tools across 5 engines, and orchestrates 11 specialized agents with persistent cross-session memory.\n\n## At a Glance\n\n| Component | Count | What You Get |\n|-----------|-------|--------------|\n| Agents | 11 | Specialized roles (Opus/Sonnet) for engineering, review, testing, architecture, deployment, integration, planning |\n| Skills | 25 | Tiered knowledge modules: protocol, orchestration, outcome, quality |\n| MCP Tools | 70 | Token-efficient tools across 5 specialized engines |\n| Hooks | 11 | Lifecycle automation (tool redirection, context injection, error recovery, setup) |\n| Output Styles | 2 | Interactive (vibecoding) or fully autonomous (justvibes) |\n| Templates | 3 | Production scaffolds |\n\n## Why GoodVibes?\n\n### Token Efficiency\n\nToken consumption in AI coding sessions follows a layered pattern: individual operations add tokens, round trips resend conversation context, sessions accumulate state, and knowledge either persists or gets rediscovered. GoodVibes optimizes all seven layers.\n\n#### Layer 1: Per-Operation Savings\n\nNative tools return maximum output regardless of need. Precision tools let you request exactly the detail level required.\n\n*Note: Token estimates below are for typical small-to-medium files (~50-100 lines). Savings scale linearly with file size (e.g., a 500-line file would be ~5,000 tokens native vs. the same low precision overhead).*\n\n| Operation | Native Tool | Precision Tool | Savings |\n|-----------|-------------|----------------|---------|\n| Check if a file exists | `Read` returns full content (~500+ tokens) | `precision_read` with `count_only` (~15 tokens) | ~97% |\n| Count files matching a pattern | `Glob` returns all paths (~200+ tokens) | `precision_glob` with `count_only` (~15 tokens) | ~92% |\n| Check if a pattern exists in code | `Grep` returns all matches with context (~300+ tokens) | `precision_grep` with `count_only` (~15 tokens) | ~95% |\n| Re-read an unchanged file | `Read` returns full content again (~500+ tokens) | `precision_read` returns cache hit (~20 tokens) | ~96% |\n| Get function signatures from a file | `Read` returns entire file (~500+ tokens) | `precision_read` with `symbols` extract (~50 tokens) | ~90% |\n\n**Mechanisms:**\n- **Verbosity levels** (4-6 per tool): `count_only`, `files_only`, `minimal`, `standard`, `verbose`. Tools default to minimal output automatically — `precision_edit` defaults to `minimal`, `precision_grep` to `files_only`, `precision_glob` to `paths_only`. Savings are automatic even without explicit requests.\n- **Extract modes** (`precision_read`): `content`, `outline`, `symbols`, `ast`, `lines`. Get function signatures (~50 tokens) instead of full file content (~500+ tokens). 75-95% savings.\n- **Token budget pagination**: Large results auto-paginate to stay within a specified token limit. Prevents single responses from consuming disproportionate context.\n- **AST pattern matching** (`precision_edit`): More precise than regex, fewer false positives, fewer failed edits requiring retry.\n\n#### Layer 2: Per-Round-Trip Savings\n\nEvery API call resends the entire conversation (system prompt + tool definitions + all messages). Fewer calls = less overhead.\n\n- **Batch operations**: Read 10 files, edit 5 files, run 3 commands, fetch 5 URLs — each in a single tool call. Eliminates N-1 round trips.\n- **discover tool**: Runs grep + glob + symbol queries simultaneously in one call. Results keyed by query ID. 5 searches in 1 round trip instead of 5.\n- **Atomic transactions**: `precision_edit` and `precision_write` in atomic mode. If any operation fails, all roll back. Prevents partial failures that require re-investigation (which costs more round trips).\n\nQuick example:\n```\nReading 10 files:\n  Native: 10 calls x (full conversation prefix resent each time)\n  Precision: 1 call x (conversation prefix sent once)\n  = 9 fewer prefix resends\n```\n\n#### Layer 3: Per-Session Savings\n\nState tracked within a session avoids redundant work.\n\n- **File state caching**: SHA256 hash-based. Re-reading an unchanged file returns ~20 tokens instead of full content. In edit-verify-edit cycles, this compounds rapidly.\n- **Search cache**: Last 20 grep results stored by query ID. Enables incremental refinement without re-running expensive searches.\n- **Stack detection caching**: `detect_stack` results cached to `.goodvibes/detected-stack.json`. Re-detection skipped within session.\n- **Context injection at session start**: SessionStart hook gathers context types in parallel (stack, git, environment, TODOs, health, folder structure, memory, ports) and injects them upfront. Agents skip discovery.\n- **Conditional context sections**: Context builder omits healthy sections entirely. If no health warnings exist, no health section is injected. Saves 200-500 tokens on healthy projects.\n- **Subagent context pre-loading**: SubagentStart hook injects project name, git branch, and stack info into every subagent at spawn. No per-agent discovery needed.\n\n#### Layer 4: Cross-Session Savings\n\nKnowledge persists across conversations. Same problem next week? Already documented.\n\n- **Memory system**: `.goodvibes/memory/` stores decisions, patterns, failures, and preferences in structured JSON. Agents read memory before acting. An agent that would spend 5K+ tokens debugging a known issue instead reads a 200-token failure record.\n- **PostToolUseFailure logging**: Failed tool attempts are logged with root cause and prevention guidance. Future sessions inherit this knowledge automatically.\n- **Learn-and-abandon pattern**: Fix attempts are capped. If the issue is upstream (in a package you can't change), you don't burn tokens trying to fix it again — every future session reads the failure record and skips the investigation entirely.\n\n#### Layer 5: Infrastructure Savings (Dual-Layer Caching)\n\nPrecision engine's local file cache and Anthropic's remote prompt cache operate at different layers and compound:\n\n| Layer | What It Does | Impact |\n|-------|--------------|--------|\n| **Local (MCP)** | Caches file state by content hash | Shrinks token volume added to conversation |\n| **Remote (Anthropic)** | Caches conversation prefix | Discounts per-token cost for cached turns |\n\nWithout local caching, re-reading a file adds full content to the conversation every time. With local caching, only the first read adds full content; subsequent reads return cache hits (~20 tokens each). This keeps the conversation prefix smaller.\n\nSince Anthropic's prompt cache pricing uses multipliers (cache reads at ~10% of base input price), a smaller prefix means cheaper cache operations on every turn.\n\n```\nRe-reading a 500-line file 3 times during a session:\n  Native tools:  5,000 + 5,000 + 5,000 = 15,000 tokens added to conversation\n  Precision:     5,000 + 20 + 20       = 5,040 tokens added\n\nOver 20 files read multiple times:\n  Native:    ~100K+ tokens x cache rates = expensive prefix\n  Precision: ~20K tokens x cache rates   = 80% reduction in cache cost\n```\n\n**Context window longevity:** Slower conversation growth delays context compaction. Compaction rewrites the conversation prefix, which means the remote cache no longer matches, requiring a new cache write. Precision caching keeps the remote cache hot longer, avoiding repeated cold starts.\n\n#### Layer 6: Prevention Savings\n\nStructured error handling prevents expensive failure cascades.\n\n- **3-phase fix loop**: Systematic escalation (internal -> docs -> community -> internet) with capped attempts instead of random debugging that burns tokens.\n- **Blocker classification**: Output style classifies blockers by type (issue/error/other) with specific recovery strategies. Structured response = targeted fix = fewer wasted tokens.\n- **Atomic transactions with rollback**: Failed batch operations roll back cleanly. No partial corruption requiring manual investigation.\n\n#### Layer 7: Orchestration Savings\n\nThe output style enforces patterns that keep the entire agent tree efficient.\n\n- **Orchestrator stays lean**: \"You ARE the orchestrator. Coordination, NOT implementation.\" The main context — the most expensive one because it persists across the whole session — never bloats with file contents or grep results. All implementation happens in subagent contexts that are discarded after completion.\n- **Mandatory precision tools for all agents**: The output style and PreToolUse hook force precision tools across the entire agent tree. One rogue subagent using native `Read` in a loop would burn thousands of tokens. This prevents it.\n- **Planned execution**: \"Plan all work\" instruction means agents execute targeted operations instead of speculative exploration. Pre-meditated work = fewer wasted reads and searches.\n- **Parallel agents with background execution**: Up to 6 agents run concurrently in background. Parallel execution plus explicit instructions not to monitor agents via Task Output unless absolutely necessary (and even then to use the non-blocking version), and to wait for a Task Completion notification means fewer wasted tokens and the ability to keep conversing and planning in the main conversation context while work is done in the background.\n\n#### Summary\n\nThese seven layers compound: per-operation savings reduce round-trip overhead, which shrinks per-session context growth, which delays compaction, which keeps the remote cache hot, while cross-session memory prevents rediscovering solved problems, and orchestration patterns ensure the entire agent tree operates efficiently. For API users paying per token, this directly reduces cost. For Pro/Max subscribers, it means less of your weekly allocation consumed per session, allowing more work before hitting limits.\n\n### Transparent Tool Upgrade\n\nA PreToolUse hook intercepts Claude's native Read, Edit, Write, Glob, and Grep calls and redirects them to precision equivalents. The hook fires on every tool call — Claude requests `Read`, the hook blocks it and tells Claude to use `precision_read` instead. This happens for all agents including subagents.\n\nThis means the efficiency gains are automatic — Claude uses precision tools without configuration.\n\n### 11 Specialized Agents\n\nDomain-specific agents (engineer, reviewer, tester, architect, deployer, 3 integrators, planner, 2 factories) each bring focused expertise. Opus-powered agents handle complex work; Sonnet-powered agents handle high-volume tasks.\n\n### Persistent Memory\n\nA two-tier memory system stores decisions, patterns, failures, and preferences in `.goodvibes/memory/`. Agents read these files before acting. The PostToolUseFailure hook automatically logs failures after exhausting its 3-phase fix loop. Same bug next session? Already documented.\n\n### Quality Loops\n\nWRFC (Write-Review-Fix-Check) loops enforce a mandatory review cycle on every unit of work. No code reaches a commit without passing review.\n\n**The loop:**\n\n```\n1. WORK   ->  Spawn agent to implement the task (background)\n2. REVIEW ->  Spawn reviewer to check the work (background)\n3. Evaluate:\n   |  PASS -> Proceed to step 5\n   |  FAIL -> Enter Fix-Check cycle:\n   |         FIX   ->  Spawn agent to address all issues (background)\n   |         CHECK ->  Spawn reviewer to re-check (background)\n   |         Repeat until PASS (or max attempts reached)\n4. COMMIT ->  Git commit the verified work\n5. LOG    ->  Update .goodvibes/ memory and logs\n6. REPORT ->  Report complete, loop for next task\n```\n\n**Key properties:**\n\n- **Per-task, not per-batch.** Each unit of work gets its own WRFC cycle. A phase with 4 tasks runs 4 independent loops.\n- **All agents run in background.** The orchestrator coordinates; it never implements. Up to 6 agents run concurrently.\n- **No issue is too minor.** Reviewers flag everything — major, minor, nitpick. All must be addressed before the loop passes.\n- **Fix-Check is iterative.** If the fix introduces new issues, the reviewer catches them. The loop continues until the reviewer returns zero issues.\n- **Failures are logged.** If max fix attempts are exhausted, the failure is recorded in `.goodvibes/memory/failures.json` with root cause and prevention guidance.\n- **Commit gates on review.** Code is only committed after the reviewer confirms zero issues. No exceptions.\n\nThe orchestrator maintains WRFC loops across concurrent tasks — when one task's reviewer returns PASS, the orchestrator commits that work and checks for newly unblocked tasks, keeping agent utilization high.\n\n### Two Execution Modes\n\nvibecoding (interactive: shows progress, explains decisions, asks on ambiguity) and justvibes (autonomous: silent execution, auto-chains tasks, logs everything).\n\n## Installation\n\n```bash\nclaude plugin marketplace add mgd34msu/goodvibes-plugin\nclaude plugin install goodvibes@goodvibes-market\n```\n\nAfter installation, run the Setup hook to pre-write CLAUDE.md chain files:\n```bash\nclaude --init-only\n```\n\nThis ensures all GoodVibes instruction files are in place before your first session. On each session start, the SessionStart hook:\n- Detects your project stack (frameworks, languages, tools)\n- Analyzes git status (branch, uncommitted changes)\n- Checks project health (missing dependencies, build issues)\n- Verifies CLAUDE.md chain files (writes any that are missing)\n- Injects project context into Claude's system message\n\nSet your output style:\n```bash\n/output-style goodvibes:vibecoding   # Interactive mode\n/output-style goodvibes:justvibes    # Autonomous mode\n```\n\n## Precision Engine - 12 Tools\n\nThe core of GoodVibes. 12 tools that replace Claude Code's native tools with enhanced, token-efficient alternatives.\n\n### Tool Overview\n\n| Tool | Replaces | Key Enhancements |\n|------|----------|------------------|\n| precision_read | Read | Batch reads, extract modes (content/outline/symbols/ast/lines), image viewing (PNG/JPG/GIF/WebP/BMP/ICO/TIFF/AVIF/SVG as visual blocks with magic byte validation), PDF text extraction with page ranges, Jupyter notebook cells, token budgets with pagination, file state caching |\n| precision_write | Write | Batch writes, fail_if_exists/overwrite/backup modes, atomic transactions with rollback, dry run, auto directory creation, base64 content support |\n| precision_edit | Edit | Batch edits, match modes (exact/fuzzy/regex/ast_pattern with AST-Grep captures), occurrence selection (first/last/Nth/all), context hints (near_line/in_function/in_class/after/before), atomic transactions with rollback, dry run, whitespace/case sensitivity toggles |\n| precision_grep | Grep | Batch queries with parallel execution, output modes (count_only/files_only/locations/matches/context), context expansion (line/block/function/class), negation search, find-replace preview with backreference support, relevance ranking, cross-file relationship tracing, whole word matching |\n| precision_glob | Glob | Presets (typescript/javascript/styles/config/tests), size/date/content filters, output modes (count_only/paths_only/with_stats/with_preview), backend selection (fast-glob/ripgrep), symlink following |\n| precision_exec | Bash | Batch commands with parallel execution, expectation checking (exit code/stdout/stderr), retry engine (configurable backoff for transient failures), pattern-based termination, safe mode (blocks rm -rf, dd, etc.), background process lifecycle management |\n| precision_fetch | WebFetch | Full HTTP client: 7 methods (GET/POST/PUT/DELETE/PATCH/HEAD/OPTIONS), service registry with auto-auth, per-request auth (none/bearer/basic/api-key/custom-headers), 12 extraction modes (raw/text/json/markdown/structured/summary/code_blocks/tables/links/metadata/readable/pdf), body encoding (json/form/multipart/raw), query params, CSS selectors, response headers/cookies/redirect chains/timing, 15-min TTL cache |\n| precision_notebook | NotebookEdit | Batch operations with auto-index adjustment, cell targeting by cell_id (with metadata.id fallback), output clearing per cell, auto cell_id generation for nbformat 4.5+ |\n| precision_agent | (unique) | Spawn headless Claude sessions with dossier-based context injection. Background-only execution, multi-provider support (Claude, Gemini, Codex), project context auto-injection, scope/acceptance criteria definition, model override per call |\n| discover | (unique) | Parallel multi-query: run grep + glob + symbol + structural (AST pattern) queries simultaneously, results keyed by query ID |\n| precision_symbols | (unique) | Workspace-wide or per-file symbol search, kind filtering (10 kinds), export/private filtering, signature extraction with JSDoc/docstrings, grouping by file/kind, multi-language (TypeScript, JavaScript, Python, Rust, Go) |\n| precision_config | (unique) | Runtime configuration for precision engine (get/set/reload), sandbox mode, cache tuning, execution defaults, session state KV store, telemetry queries, hook management |\n\n### Batch Operations\n\nRead 10 files, edit 5 files, run 3 commands, fetch 5 URLs — each in a single tool call. Reduces round trips and context overhead.\n\n### Atomic Transactions\n\nprecision_edit and precision_write support transaction modes (atomic/partial/none). In atomic mode, if any operation fails, all changes roll back. Every edit generates a rollback ID for manual undo.\n\n### Advanced Matching\n\nprecision_edit supports 4 match modes:\n- **exact**: literal string match (default)\n- **fuzzy**: whitespace-insensitive matching\n- **regex**: full regex with capture group support ($1-$9, $$, $&, $`, $')\n- **ast_pattern**: AST-Grep structural patterns with captures ($VAR for single nodes, $$$VAR for sequences) across 18 languages (JavaScript, TypeScript, Python, Rust, Go, C, C++, Java, Kotlin, Swift, Ruby, PHP, C#, Scala, Bash, HTML, CSS, Lua)\n\n### Multi-Format Reading\n\nprecision_read handles more than text:\n- **Images** (.png, .jpg, .gif, .webp, .svg): returned as MCP ImageContent blocks — Claude sees them visually\n- **PDFs**: per-page text extraction via pdf-parse, `pages` parameter for ranges (e.g., \"1-5\"), max 20 pages per request\n- **Jupyter notebooks** (.ipynb): parsed as JSON, formatted with cell types (code/markdown) and outputs\n- **SVG files** get both text content and visual image representation\n\n### Safety\n\nprecision_exec includes a safe mode that blocks destructive commands matching patterns like `rm -rf /`, `rmdir /`, `dd if=/dev/`. Expectation checking verifies exit codes and output content after execution.\n\n### Context Expansion\n\nprecision_grep can expand matches beyond the matched line to enclosing block, function, or class scope using Tree-Sitter AST analysis.\n\n### HTTP Client & Authentication\n\nprecision_fetch operates as a full HTTP client, not just a page fetcher:\n- **Service registry**: Named API services with stored base URLs and credentials. Auto-auth resolves service name to authenticated requests without passing credentials each time\n- **Per-request auth**: 5 auth types (none, bearer, basic, api-key, custom-headers) configurable per URL\n- **Body encoding**: 4 body types (json, form, multipart, raw) with automatic content-type headers\n- **Query parameters**: Key-value params auto-appended to URLs\n- **Response inspection**: Response headers, cookies (with domain/path/expiry), redirect chains, and request timing (DNS/connect/TTFB/total)\n- **401 retry**: Automatic token refresh and retry on authentication failures\n\n## Analysis Engine - 20 Tools\n\n| Category | Tools |\n|----------|-------|\n| Detection | detect_stack, check_versions, scan_patterns, read_config, get_conventions |\n| Code Quality | find_dead_code, get_api_surface, safe_delete_check, find_circular_deps |\n| Validation | detect_breaking_changes, semantic_diff, validate_implementation, validate_edits_preview, validate_api_contract |\n| Security | env_audit, scan_for_secrets, check_permissions |\n| Debugging | parse_error_stack, explain_type_error |\n\nKey capabilities:\n- **TypeScript Language Service** for precise reference tracking, dead code detection, and breaking change analysis\n- **40+ secret patterns** covering AWS, Azure, Google, GitHub, Stripe, Slack, private keys, and database connection strings\n- **LLM-powered analysis** for convention detection, breaking change assessment, and type error explanation\n- **Virtual snapshot validation** — preview edit impact without modifying files\n\n## Project Engine - 20 Tools\n\n| Category | Tools |\n|----------|-------|\n| Scaffolding | scaffold_project, list_templates |\n| Status | plugin_status, project_issues |\n| API | generate_openapi, get_api_routes |\n| Database | get_database_schema, get_prisma_operations, query_database |\n| Maintenance | upgrade_package, analyze_bundle, analyze_dependencies, find_circular_deps |\n| Testing | find_tests_for_file, get_test_coverage, suggest_test_cases, generate_fixture |\n| Types | generate_types, sync_api_types |\n| Git | create_pull_request, resolve_merge_conflict |\n\nKey capabilities:\n- **Multi-ORM schema parsing**: Prisma, Drizzle, TypeORM, and raw SQL\n- **Multi-database query execution**: PostgreSQL, MySQL, SQLite with safety guards (readonly mode, auto-LIMIT, EXPLAIN plans)\n- **Route extraction**: Next.js, Express, Fastify, Hono\n- **Coverage report parsing**: lcov and istanbul formats\n- **Bundle analysis**: size analysis, duplicate detection, tree-shaking impact, optimization suggestions\n- **OpenAPI 3.0.3 generation** from discovered API routes\n\n\n## Frontend Engine - 11 Tools\n\n| Tool | Purpose |\n|------|---------|\n| get_react_component_tree | Extract component hierarchy with props and parent-child relationships |\n| analyze_stacking_context | Debug z-index issues and stacking context creation |\n| analyze_responsive_breakpoints | Audit Tailwind responsive classes across breakpoints |\n| trace_component_state | Trace state and props through component trees, detect prop drilling |\n| analyze_render_triggers | Find unnecessary re-renders, missing memoization, unstable references |\n| analyze_layout_hierarchy | Debug CSS layout with sizing constraints and Tailwind class parsing |\n| diagnose_overflow | Find overflow causes with constraint chain analysis |\n| get_accessibility_tree | Generate accessibility tree with WCAG 2.1 AA compliance checking |\n| get_sizing_strategy | Analyze how element size is determined (fixed, flex, grid, content) |\n| analyze_event_flow | Trace event propagation, detect nested clickable conflicts |\n| analyze_tailwind_conflicts | Find conflicting and redundant Tailwind classes |\n\n## Registry Engine - 7 Tools\n\n| Tool | Purpose |\n|------|---------|\n| search_skills | Search skills by query and category |\n| search_agents | Search agents by capability |\n| search_tools | Search MCP tools |\n| recommend_skills | Context-aware skill recommendations |\n| get_skill_content | Load skill content into context |\n| get_agent_content | Load agent definition |\n| skill_dependencies | Resolve skill dependency chain |\n\n## Agents\n\n11 specialized agents with distinct expertise. The orchestrator spawns them for focused tasks — each consults memory, applies relevant skills, and returns results.\n\n| Agent | Model | Specialization |\n|-------|-------|----------------|\n| engineer | Opus | Full-stack: APIs, databases, auth, components, routing, styling |\n| reviewer | Opus | Code quality, security, type safety, WRFC loop execution |\n| tester | Sonnet | Test generation, coverage analysis, fixture creation, 100% coverage goal |\n| architect | Opus | System design, architecture decisions, dependency mapping |\n| deployer | Sonnet | CI/CD, Docker, cloud deployment (Vercel, AWS, Railway, Fly.io) |\n| integrator-ai | Opus | AI/LLM integrations (OpenAI, Anthropic, Vercel AI SDK, RAG, embeddings) |\n| integrator-services | Sonnet | Payments (Stripe), email (Resend), CMS (Sanity, Contentful), uploads (S3, Cloudinary) |\n| integrator-state | Sonnet | State management (Zustand, Redux, Jotai, TanStack Query), forms, real-time |\n| planner | Opus | Task breakdown, batch planning, workflow orchestration |\n| agent-factory | Opus | Create new specialized agents |\n| skill-factory | Opus | Create new skills and slash commands |\n\n## Skills - 25 Total\n\nOrganized into 4 tiers with progressive loading — protocol skills are always active, others load when relevant to the task.\n\n| Tier | Count | Skills | Loading |\n|------|-------|--------|---------|\n| **Protocol** | 5 | precision-mastery, gather-plan-apply, review-scoring, goodvibes-memory, error-recovery | Always active |\n| **Orchestration** | 2 | task-orchestration, fullstack-feature | On multi-agent tasks |\n| **Outcome** | 11 | ai-integration, api-design, authentication, component-architecture, database-layer, deployment, payment-integration, service-integration, state-management, styling-system, testing-strategy | When task matches domain |\n| **Quality** | 7 | accessibility-audit, code-review, debugging, performance-audit, project-onboarding, refactoring, security-audit | On review/audit tasks |\n\n**Protocol skills** are embedded in every agent's context via the subagent protocol chain — they're too critical for token efficiency and execution patterns to depend on lazy loading.\n\n**Outcome and quality skills** load proactively when Claude detects a matching task. Each skill includes a `## Resources` tree pointing to scripts and reference materials the agent can navigate as needed.\n\n**Fallback**: If a skill doesn't load automatically, the registry engine's `get_skill_content` tool serves as an escape hatch.\n\n## Hooks - 11 Types\n\nLifecycle hooks run transparently on every session. They're the mechanism behind tool redirection, context injection, and automatic error recovery.\n\n| Hook | Trigger | What It Does |\n|------|---------|-------------|\n| Setup | `claude --init` / `claude --init-only` | Pre-writes CLAUDE.md chain files (import directives + prompt files) so they exist before any session starts. Matches `init` trigger. Avoids race conditions where SessionStart isn't fast enough to write files before Claude reads them |\n| PreToolUse (Bash) | Before Bash execution | Platform path mapping (Windows/Linux), shell safety analysis, git commit quality gates |\n| PreToolUse (Native) | Before Read/Edit/Write/Glob/Grep | Blocks native tool, redirects to precision-engine equivalent |\n| PostToolUseFailure | After Bash failure | 3-phase progressive fix loop: Phase 1 (internal knowledge) -> Phase 2 (official docs hints) -> Phase 3 (community docs hints). Logs failures to `.goodvibes/memory/failures.json` after all phases exhausted |\n| SessionStart | Session begins | Detects project stack, analyzes git status, checks project health, creates/updates CLAUDE.md, injects context into system message, builds project file index |\n| SessionEnd | Session ends | Persists session state |\n| SubagentStart | Agent spawns | Injects context for GoodVibes agents (stack info, git branch, project name), tracks agent telemetry |\n| SubagentStop | Agent completes | Cleans up agent tracking, updates analytics |\n| PreCompact | Before context compaction | Creates checkpoint commit if uncommitted changes exist, generates session summary |\n| Stop | Stop button pressed | Saves current state |\n| UserPromptSubmit | User sends message | Processes user input |\n\n## Output Styles\n\nTwo execution modes for different workflows. Set via `/output-style goodvibes:vibecoding` or `/output-style goodvibes:justvibes`.\n\n| Setting | vibecoding | justvibes |\n|---------|-----------|------------|\n| Description | Autonomous coding with communication | Fully autonomous silent execution |\n| show_progress | true | false |\n| explain_decisions | true | false |\n| ask_on_ambiguity | true | false |\n| auto_chain | false | true |\n| max_autonomous_batches | 1 | unlimited |\n| checkpoint_frequency | per_batch | per_phase |\n| parallel_agents | 6 | 6 |\n| recovery (issues/errors) | ask_user_with_options | fix_review_loop |\n| recovery (other) | ask_user | choose_best_option_silent |\n| max_fix_attempts | 3 | 3 |\n| fix_attempt strategy | one_shot (all sources at once) | cumulative (staged escalation) |\n| default output mode | standard | minimal |\n| show_diffs | true | false |\n| show_telemetry | summary | none |\n| log_activity | false | true |\n\n## Memory System\n\nTwo-tier persistent memory. Session logs track the current session. Cross-session memory persists across conversations.\n\n### Session Logs (`.goodvibes/logs/`)\n\n- `decisions.md` — Architectural choices with options considered, rationale, implications\n- `errors.md` — Failures categorized by type (TOOL_FAILURE, BUILD_ERROR, TEST_FAILURE, etc.) with root cause and resolution\n- `activity.md` — Completed work that passed review (primarily used in justvibes mode)\n\n### Cross-Session Memory (`.goodvibes/memory/`)\n\n- `decisions.json` — Decision records with category, scope, confidence (max 1000 entries, auto-prunes oldest)\n- `patterns.json` — Proven approaches with example files and keywords (max 500)\n- `failures.json` — Failed approaches with root cause and prevention guidance (max 500)\n- `preferences.json` — User conventions (code style, naming, patterns)\n\nAgents read memory before acting. The PostToolUseFailure hook automatically records failures after its 3-phase fix loop is exhausted.\n\n## Telemetry\n\nBuilt-in telemetry tracks tool usage, session activity, and performance metrics in a local SQLite database (sql.js WASM). Query via `precision_config action=telemetry` with filters for tool, status, session_id, and date range. All data stays local — nothing is sent externally.\n\n## Configuration\n\nGoodVibes works out of the box. Minimal configuration needed.\n\n### Path Sandboxing\n\nControls whether precision tools can access files outside the project root. Disabled by default.\n\n```bash\n/goodvibes:sandbox true    # Enable (restrict to project root)\n/goodvibes:sandbox false   # Disable (allow external paths, default)\n```\n\n### Service Registry\n\nNamed API services with stored credentials for precision_fetch auto-auth:\n\n```bash\n/goodvibes:services add OpenAI    # Configure a new API service\n/goodvibes:services list           # Show registered services\n/goodvibes:services test OpenAI    # Test service connectivity\n```\n\n### Output Style\n\nSwitch execution modes:\n\n```bash\n/output-style goodvibes:vibecoding\n/output-style goodvibes:justvibes\n```\n\n## Slash Commands\n\n| Command | Purpose |\n|---------|---------|\n| `/goodvibes:sandbox` | Toggle path sandboxing (true/false) |\n| `/goodvibes:plugin` | Plugin management (update, status, config) |\n| `/goodvibes:search` | Search skills, agents, or tools |\n| `/goodvibes:services` | Manage precision_fetch service registry (add, remove, test, auth) |\n| `/goodvibes:load-skill` | Load a skill's content into context |\n| `/goodvibes:codebase-review` | Full codebase audit with parallel agent remediation |\n\n## License\n\nMIT License - see [LICENSE](LICENSE) for details.\n\n---\n\n<p align=\"center\">\n  <b>Plug in, receive good vibes</b>\n  <br><br>\n  <code>claude plugin marketplace add mgd34msu/goodvibes-plugin</code>\n  <br>\n  <code>claude plugin install goodvibes@goodvibes-market</code>\n</p>\n",
        "plugins/goodvibes/README.md": "# GoodVibes Plugin\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Version](https://img.shields.io/badge/version-1.2.30-blue.svg)](https://github.com/mgd34msu/goodvibes-plugin)\n[![Claude Code Plugin](https://img.shields.io/badge/Claude%20Code-Plugin-purple.svg)](https://claude.com/claude-code)\n\n> Plug in. Receive good vibes.\n\nA Claude Code plugin that replaces native tools with token-efficient precision equivalents, adds 70 MCP tools across 5 engines, and orchestrates 11 specialized agents with persistent cross-session memory.\n\n## At a Glance\n\n| Component | Count | What You Get |\n|-----------|-------|--------------|\n| Agents | 11 | Specialized roles (Opus/Sonnet) for engineering, review, testing, architecture, deployment, integration, planning |\n| Skills | 25 | Tiered knowledge modules: protocol, orchestration, outcome, quality |\n| MCP Tools | 70 | Token-efficient tools across 5 specialized engines |\n| Hooks | 11 | Lifecycle automation (tool redirection, context injection, error recovery, setup) |\n| Output Styles | 2 | Interactive (vibecoding) or fully autonomous (justvibes) |\n| Templates | 3 | Production scaffolds |\n\n## Why GoodVibes?\n\n### Token Efficiency\n\nToken consumption in AI coding sessions follows a layered pattern: individual operations add tokens, round trips resend conversation context, sessions accumulate state, and knowledge either persists or gets rediscovered. GoodVibes optimizes all seven layers.\n\n#### Layer 1: Per-Operation Savings\n\nNative tools return maximum output regardless of need. Precision tools let you request exactly the detail level required.\n\n*Note: Token estimates below are for typical small-to-medium files (~50-100 lines). Savings scale linearly with file size (e.g., a 500-line file would be ~5,000 tokens native vs. the same low precision overhead).*\n\n| Operation | Native Tool | Precision Tool | Savings |\n|-----------|-------------|----------------|---------|\n| Check if a file exists | `Read` returns full content (~500+ tokens) | `precision_read` with `count_only` (~15 tokens) | ~97% |\n| Count files matching a pattern | `Glob` returns all paths (~200+ tokens) | `precision_glob` with `count_only` (~15 tokens) | ~92% |\n| Check if a pattern exists in code | `Grep` returns all matches with context (~300+ tokens) | `precision_grep` with `count_only` (~15 tokens) | ~95% |\n| Re-read an unchanged file | `Read` returns full content again (~500+ tokens) | `precision_read` returns cache hit (~20 tokens) | ~96% |\n| Get function signatures from a file | `Read` returns entire file (~500+ tokens) | `precision_read` with `symbols` extract (~50 tokens) | ~90% |\n\n**Mechanisms:**\n- **Verbosity levels** (4-6 per tool): `count_only`, `files_only`, `minimal`, `standard`, `verbose`. Tools default to minimal output automatically — `precision_edit` defaults to `minimal`, `precision_grep` to `files_only`, `precision_glob` to `paths_only`. Savings are automatic even without explicit requests.\n- **Extract modes** (`precision_read`): `content`, `outline`, `symbols`, `ast`, `lines`. Get function signatures (~50 tokens) instead of full file content (~500+ tokens). 75-95% savings.\n- **Token budget pagination**: Large results auto-paginate to stay within a specified token limit. Prevents single responses from consuming disproportionate context.\n- **AST pattern matching** (`precision_edit`): More precise than regex, fewer false positives, fewer failed edits requiring retry.\n\n#### Layer 2: Per-Round-Trip Savings\n\nEvery API call resends the entire conversation (system prompt + tool definitions + all messages). Fewer calls = less overhead.\n\n- **Batch operations**: Read 10 files, edit 5 files, run 3 commands, fetch 5 URLs — each in a single tool call. Eliminates N-1 round trips.\n- **discover tool**: Runs grep + glob + symbol queries simultaneously in one call. Results keyed by query ID. 5 searches in 1 round trip instead of 5.\n- **Atomic transactions**: `precision_edit` and `precision_write` in atomic mode. If any operation fails, all roll back. Prevents partial failures that require re-investigation (which costs more round trips).\n\nQuick example:\n```\nReading 10 files:\n  Native: 10 calls x (full conversation prefix resent each time)\n  Precision: 1 call x (conversation prefix sent once)\n  = 9 fewer prefix resends\n```\n\n#### Layer 3: Per-Session Savings\n\nState tracked within a session avoids redundant work.\n\n- **File state caching**: SHA256 hash-based. Re-reading an unchanged file returns ~20 tokens instead of full content. In edit-verify-edit cycles, this compounds rapidly.\n- **Search cache**: Last 20 grep results stored by query ID. Enables incremental refinement without re-running expensive searches.\n- **Stack detection caching**: `detect_stack` results cached to `.goodvibes/detected-stack.json`. Re-detection skipped within session.\n- **Context injection at session start**: SessionStart hook gathers context types in parallel (stack, git, environment, TODOs, health, folder structure, memory, ports) and injects them upfront. Agents skip discovery.\n- **Conditional context sections**: Context builder omits healthy sections entirely. If no health warnings exist, no health section is injected. Saves 200-500 tokens on healthy projects.\n- **Subagent context pre-loading**: SubagentStart hook injects project name, git branch, and stack info into every subagent at spawn. No per-agent discovery needed.\n\n#### Layer 4: Cross-Session Savings\n\nKnowledge persists across conversations. Same problem next week? Already documented.\n\n- **Memory system**: `.goodvibes/memory/` stores decisions, patterns, failures, and preferences in structured JSON. Agents read memory before acting. An agent that would spend 5K+ tokens debugging a known issue instead reads a 200-token failure record.\n- **PostToolUseFailure logging**: Failed tool attempts are logged with root cause and prevention guidance. Future sessions inherit this knowledge automatically.\n- **Learn-and-abandon pattern**: Fix attempts are capped. If the issue is upstream (in a package you can't change), you don't burn tokens trying to fix it again — every future session reads the failure record and skips the investigation entirely.\n\n#### Layer 5: Infrastructure Savings (Dual-Layer Caching)\n\nPrecision engine's local file cache and Anthropic's remote prompt cache operate at different layers and compound:\n\n| Layer | What It Does | Impact |\n|-------|--------------|--------|\n| **Local (MCP)** | Caches file state by content hash | Shrinks token volume added to conversation |\n| **Remote (Anthropic)** | Caches conversation prefix | Discounts per-token cost for cached turns |\n\nWithout local caching, re-reading a file adds full content to the conversation every time. With local caching, only the first read adds full content; subsequent reads return cache hits (~20 tokens each). This keeps the conversation prefix smaller.\n\nSince Anthropic's prompt cache pricing uses multipliers (cache reads at ~10% of base input price), a smaller prefix means cheaper cache operations on every turn.\n\n```\nRe-reading a 500-line file 3 times during a session:\n  Native tools:  5,000 + 5,000 + 5,000 = 15,000 tokens added to conversation\n  Precision:     5,000 + 20 + 20       = 5,040 tokens added\n\nOver 20 files read multiple times:\n  Native:    ~100K+ tokens x cache rates = expensive prefix\n  Precision: ~20K tokens x cache rates   = 80% reduction in cache cost\n```\n\n**Context window longevity:** Slower conversation growth delays context compaction. Compaction rewrites the conversation prefix, which means the remote cache no longer matches, requiring a new cache write. Precision caching keeps the remote cache hot longer, avoiding repeated cold starts.\n\n#### Layer 6: Prevention Savings\n\nStructured error handling prevents expensive failure cascades.\n\n- **3-phase fix loop**: Systematic escalation (internal -> docs -> community -> internet) with capped attempts instead of random debugging that burns tokens.\n- **Blocker classification**: Output style classifies blockers by type (issue/error/other) with specific recovery strategies. Structured response = targeted fix = fewer wasted tokens.\n- **Atomic transactions with rollback**: Failed batch operations roll back cleanly. No partial corruption requiring manual investigation.\n\n#### Layer 7: Orchestration Savings\n\nThe output style enforces patterns that keep the entire agent tree efficient.\n\n- **Orchestrator stays lean**: \"You ARE the orchestrator. Coordination, NOT implementation.\" The main context — the most expensive one because it persists across the whole session — never bloats with file contents or grep results. All implementation happens in subagent contexts that are discarded after completion.\n- **Mandatory precision tools for all agents**: The output style and PreToolUse hook force precision tools across the entire agent tree. One rogue subagent using native `Read` in a loop would burn thousands of tokens. This prevents it.\n- **Planned execution**: \"Plan all work\" instruction means agents execute targeted operations instead of speculative exploration. Pre-meditated work = fewer wasted reads and searches.\n- **Parallel agents with background execution**: Up to 6 agents run concurrently in background. Parallel execution plus explicit instructions not to monitor agents via Task Output unless absolutely necessary (and even then to use the non-blocking version), and to wait for a Task Completion notification means fewer wasted tokens and the ability to keep conversing and planning in the main conversation context while work is done in the background.\n\n#### Summary\n\nThese seven layers compound: per-operation savings reduce round-trip overhead, which shrinks per-session context growth, which delays compaction, which keeps the remote cache hot, while cross-session memory prevents rediscovering solved problems, and orchestration patterns ensure the entire agent tree operates efficiently. For API users paying per token, this directly reduces cost. For Pro/Max subscribers, it means less of your weekly allocation consumed per session, allowing more work before hitting limits.\n\n### Transparent Tool Upgrade\n\nA PreToolUse hook intercepts Claude's native Read, Edit, Write, Glob, and Grep calls and redirects them to precision equivalents. The hook fires on every tool call — Claude requests `Read`, the hook blocks it and tells Claude to use `precision_read` instead. This happens for all agents including subagents.\n\nThis means the efficiency gains are automatic — Claude uses precision tools without configuration.\n\n### 11 Specialized Agents\n\nDomain-specific agents (engineer, reviewer, tester, architect, deployer, 3 integrators, planner, 2 factories) each bring focused expertise. Opus-powered agents handle complex work; Sonnet-powered agents handle high-volume tasks.\n\n### Persistent Memory\n\nA two-tier memory system stores decisions, patterns, failures, and preferences in `.goodvibes/memory/`. Agents read these files before acting. The PostToolUseFailure hook automatically logs failures after exhausting its 3-phase fix loop. Same bug next session? Already documented.\n\n### Quality Loops\n\nWRFC (Write-Review-Fix-Check) loops enforce a mandatory review cycle on every unit of work. No code reaches a commit without passing review.\n\n**The loop:**\n\n```\n1. WORK   ->  Spawn agent to implement the task (background)\n2. REVIEW ->  Spawn reviewer to check the work (background)\n3. Evaluate:\n   |  PASS -> Proceed to step 5\n   |  FAIL -> Enter Fix-Check cycle:\n   |         FIX   ->  Spawn agent to address all issues (background)\n   |         CHECK ->  Spawn reviewer to re-check (background)\n   |         Repeat until PASS (or max attempts reached)\n4. COMMIT ->  Git commit the verified work\n5. LOG    ->  Update .goodvibes/ memory and logs\n6. REPORT ->  Report complete, loop for next task\n```\n\n**Key properties:**\n\n- **Per-task, not per-batch.** Each unit of work gets its own WRFC cycle. A phase with 4 tasks runs 4 independent loops.\n- **All agents run in background.** The orchestrator coordinates; it never implements. Up to 6 agents run concurrently.\n- **No issue is too minor.** Reviewers flag everything — major, minor, nitpick. All must be addressed before the loop passes.\n- **Fix-Check is iterative.** If the fix introduces new issues, the reviewer catches them. The loop continues until the reviewer returns zero issues.\n- **Failures are logged.** If max fix attempts are exhausted, the failure is recorded in `.goodvibes/memory/failures.json` with root cause and prevention guidance.\n- **Commit gates on review.** Code is only committed after the reviewer confirms zero issues. No exceptions.\n\nThe orchestrator maintains WRFC loops across concurrent tasks — when one task's reviewer returns PASS, the orchestrator commits that work and checks for newly unblocked tasks, keeping agent utilization high.\n\n### Two Execution Modes\n\nvibecoding (interactive: shows progress, explains decisions, asks on ambiguity) and justvibes (autonomous: silent execution, auto-chains tasks, logs everything).\n\n## Installation\n\n```bash\nclaude plugin marketplace add mgd34msu/goodvibes-plugin\nclaude plugin install goodvibes@goodvibes-market\n```\n\nAfter installation, run the Setup hook to pre-write CLAUDE.md chain files:\n```bash\nclaude --init-only\n```\n\nThis ensures all GoodVibes instruction files are in place before your first session. On each session start, the SessionStart hook:\n- Detects your project stack (frameworks, languages, tools)\n- Analyzes git status (branch, uncommitted changes)\n- Checks project health (missing dependencies, build issues)\n- Verifies CLAUDE.md chain files (writes any that are missing)\n- Injects project context into Claude's system message\n\nSet your output style:\n```bash\n/output-style goodvibes:vibecoding   # Interactive mode\n/output-style goodvibes:justvibes    # Autonomous mode\n```\n\n## Precision Engine - 12 Tools\n\nThe core of GoodVibes. 12 tools that replace Claude Code's native tools with enhanced, token-efficient alternatives.\n\n### Tool Overview\n\n| Tool | Replaces | Key Enhancements |\n|------|----------|------------------|\n| precision_read | Read | Batch reads, extract modes (content/outline/symbols/ast/lines), image viewing (PNG/JPG/GIF/WebP/BMP/ICO/TIFF/AVIF/SVG as visual blocks with magic byte validation), PDF text extraction with page ranges, Jupyter notebook cells, token budgets with pagination, file state caching |\n| precision_write | Write | Batch writes, fail_if_exists/overwrite/backup modes, atomic transactions with rollback, dry run, auto directory creation, base64 content support |\n| precision_edit | Edit | Batch edits, match modes (exact/fuzzy/regex/ast_pattern with AST-Grep captures), occurrence selection (first/last/Nth/all), context hints (near_line/in_function/in_class/after/before), atomic transactions with rollback, dry run, whitespace/case sensitivity toggles |\n| precision_grep | Grep | Batch queries with parallel execution, output modes (count_only/files_only/locations/matches/context), context expansion (line/block/function/class), negation search, find-replace preview with backreference support, relevance ranking, cross-file relationship tracing, whole word matching |\n| precision_glob | Glob | Presets (typescript/javascript/styles/config/tests), size/date/content filters, output modes (count_only/paths_only/with_stats/with_preview), backend selection (fast-glob/ripgrep), symlink following |\n| precision_exec | Bash | Batch commands with parallel execution, expectation checking (exit code/stdout/stderr), retry engine (configurable backoff for transient failures), pattern-based termination, safe mode (blocks rm -rf, dd, etc.), background process lifecycle management |\n| precision_fetch | WebFetch | Full HTTP client: 7 methods (GET/POST/PUT/DELETE/PATCH/HEAD/OPTIONS), service registry with auto-auth, per-request auth (none/bearer/basic/api-key/custom-headers), 12 extraction modes (raw/text/json/markdown/structured/summary/code_blocks/tables/links/metadata/readable/pdf), body encoding (json/form/multipart/raw), query params, CSS selectors, response headers/cookies/redirect chains/timing, 15-min TTL cache |\n| precision_notebook | NotebookEdit | Batch operations with auto-index adjustment, cell targeting by cell_id (with metadata.id fallback), output clearing per cell, auto cell_id generation for nbformat 4.5+ |\n| precision_agent | (unique) | Spawn headless Claude sessions with dossier-based context injection. Background-only execution, multi-provider support (Claude, Gemini, Codex), project context auto-injection, scope/acceptance criteria definition, model override per call |\n| discover | (unique) | Parallel multi-query: run grep + glob + symbol + structural (AST pattern) queries simultaneously, results keyed by query ID |\n| precision_symbols | (unique) | Workspace-wide or per-file symbol search, kind filtering (10 kinds), export/private filtering, signature extraction with JSDoc/docstrings, grouping by file/kind, multi-language (TypeScript, JavaScript, Python, Rust, Go) |\n| precision_config | (unique) | Runtime configuration for precision engine (get/set/reload), sandbox mode, cache tuning, execution defaults, session state KV store, telemetry queries, hook management |\n\n### Batch Operations\n\nRead 10 files, edit 5 files, run 3 commands, fetch 5 URLs — each in a single tool call. Reduces round trips and context overhead.\n\n### Atomic Transactions\n\nprecision_edit and precision_write support transaction modes (atomic/partial/none). In atomic mode, if any operation fails, all changes roll back. Every edit generates a rollback ID for manual undo.\n\n### Advanced Matching\n\nprecision_edit supports 4 match modes:\n- **exact**: literal string match (default)\n- **fuzzy**: whitespace-insensitive matching\n- **regex**: full regex with capture group support ($1-$9, $$, $&, $`, $')\n- **ast_pattern**: AST-Grep structural patterns with captures ($VAR for single nodes, $$$VAR for sequences) across 18 languages (JavaScript, TypeScript, Python, Rust, Go, C, C++, Java, Kotlin, Swift, Ruby, PHP, C#, Scala, Bash, HTML, CSS, Lua)\n\n### Multi-Format Reading\n\nprecision_read handles more than text:\n- **Images** (.png, .jpg, .gif, .webp, .svg): returned as MCP ImageContent blocks — Claude sees them visually\n- **PDFs**: per-page text extraction via pdf-parse, `pages` parameter for ranges (e.g., \"1-5\"), max 20 pages per request\n- **Jupyter notebooks** (.ipynb): parsed as JSON, formatted with cell types (code/markdown) and outputs\n- **SVG files** get both text content and visual image representation\n\n### Safety\n\nprecision_exec includes a safe mode that blocks destructive commands matching patterns like `rm -rf /`, `rmdir /`, `dd if=/dev/`. Expectation checking verifies exit codes and output content after execution.\n\n### Context Expansion\n\nprecision_grep can expand matches beyond the matched line to enclosing block, function, or class scope using Tree-Sitter AST analysis.\n\n### HTTP Client & Authentication\n\nprecision_fetch operates as a full HTTP client, not just a page fetcher:\n- **Service registry**: Named API services with stored base URLs and credentials. Auto-auth resolves service name to authenticated requests without passing credentials each time\n- **Per-request auth**: 5 auth types (none, bearer, basic, api-key, custom-headers) configurable per URL\n- **Body encoding**: 4 body types (json, form, multipart, raw) with automatic content-type headers\n- **Query parameters**: Key-value params auto-appended to URLs\n- **Response inspection**: Response headers, cookies (with domain/path/expiry), redirect chains, and request timing (DNS/connect/TTFB/total)\n- **401 retry**: Automatic token refresh and retry on authentication failures\n\n## Analysis Engine - 20 Tools\n\n| Category | Tools |\n|----------|-------|\n| Detection | detect_stack, check_versions, scan_patterns, read_config, get_conventions |\n| Code Quality | find_dead_code, get_api_surface, safe_delete_check, find_circular_deps |\n| Validation | detect_breaking_changes, semantic_diff, validate_implementation, validate_edits_preview, validate_api_contract |\n| Security | env_audit, scan_for_secrets, check_permissions |\n| Debugging | parse_error_stack, explain_type_error |\n\nKey capabilities:\n- **TypeScript Language Service** for precise reference tracking, dead code detection, and breaking change analysis\n- **40+ secret patterns** covering AWS, Azure, Google, GitHub, Stripe, Slack, private keys, and database connection strings\n- **LLM-powered analysis** for convention detection, breaking change assessment, and type error explanation\n- **Virtual snapshot validation** — preview edit impact without modifying files\n\n## Project Engine - 20 Tools\n\n| Category | Tools |\n|----------|-------|\n| Scaffolding | scaffold_project, list_templates |\n| Status | plugin_status, project_issues |\n| API | generate_openapi, get_api_routes |\n| Database | get_database_schema, get_prisma_operations, query_database |\n| Maintenance | upgrade_package, analyze_bundle, analyze_dependencies, find_circular_deps |\n| Testing | find_tests_for_file, get_test_coverage, suggest_test_cases, generate_fixture |\n| Types | generate_types, sync_api_types |\n| Git | create_pull_request, resolve_merge_conflict |\n\nKey capabilities:\n- **Multi-ORM schema parsing**: Prisma, Drizzle, TypeORM, and raw SQL\n- **Multi-database query execution**: PostgreSQL, MySQL, SQLite with safety guards (readonly mode, auto-LIMIT, EXPLAIN plans)\n- **Route extraction**: Next.js, Express, Fastify, Hono\n- **Coverage report parsing**: lcov and istanbul formats\n- **Bundle analysis**: size analysis, duplicate detection, tree-shaking impact, optimization suggestions\n- **OpenAPI 3.0.3 generation** from discovered API routes\n\n\n## Frontend Engine - 11 Tools\n\n| Tool | Purpose |\n|------|---------|\n| get_react_component_tree | Extract component hierarchy with props and parent-child relationships |\n| analyze_stacking_context | Debug z-index issues and stacking context creation |\n| analyze_responsive_breakpoints | Audit Tailwind responsive classes across breakpoints |\n| trace_component_state | Trace state and props through component trees, detect prop drilling |\n| analyze_render_triggers | Find unnecessary re-renders, missing memoization, unstable references |\n| analyze_layout_hierarchy | Debug CSS layout with sizing constraints and Tailwind class parsing |\n| diagnose_overflow | Find overflow causes with constraint chain analysis |\n| get_accessibility_tree | Generate accessibility tree with WCAG 2.1 AA compliance checking |\n| get_sizing_strategy | Analyze how element size is determined (fixed, flex, grid, content) |\n| analyze_event_flow | Trace event propagation, detect nested clickable conflicts |\n| analyze_tailwind_conflicts | Find conflicting and redundant Tailwind classes |\n\n## Registry Engine - 7 Tools\n\n| Tool | Purpose |\n|------|---------|\n| search_skills | Search skills by query and category |\n| search_agents | Search agents by capability |\n| search_tools | Search MCP tools |\n| recommend_skills | Context-aware skill recommendations |\n| get_skill_content | Load skill content into context |\n| get_agent_content | Load agent definition |\n| skill_dependencies | Resolve skill dependency chain |\n\n## Agents\n\n11 specialized agents with distinct expertise. The orchestrator spawns them for focused tasks — each consults memory, applies relevant skills, and returns results.\n\n| Agent | Model | Specialization |\n|-------|-------|----------------|\n| engineer | Opus | Full-stack: APIs, databases, auth, components, routing, styling |\n| reviewer | Opus | Code quality, security, type safety, WRFC loop execution |\n| tester | Sonnet | Test generation, coverage analysis, fixture creation, 100% coverage goal |\n| architect | Opus | System design, architecture decisions, dependency mapping |\n| deployer | Sonnet | CI/CD, Docker, cloud deployment (Vercel, AWS, Railway, Fly.io) |\n| integrator-ai | Opus | AI/LLM integrations (OpenAI, Anthropic, Vercel AI SDK, RAG, embeddings) |\n| integrator-services | Sonnet | Payments (Stripe), email (Resend), CMS (Sanity, Contentful), uploads (S3, Cloudinary) |\n| integrator-state | Sonnet | State management (Zustand, Redux, Jotai, TanStack Query), forms, real-time |\n| planner | Opus | Task breakdown, batch planning, workflow orchestration |\n| agent-factory | Opus | Create new specialized agents |\n| skill-factory | Opus | Create new skills and slash commands |\n\n## Skills - 25 Total\n\nOrganized into 4 tiers with progressive loading — protocol skills are always active, others load when relevant to the task.\n\n| Tier | Count | Skills | Loading |\n|------|-------|--------|---------|\n| **Protocol** | 5 | precision-mastery, gather-plan-apply, review-scoring, goodvibes-memory, error-recovery | Always active |\n| **Orchestration** | 2 | task-orchestration, fullstack-feature | On multi-agent tasks |\n| **Outcome** | 11 | ai-integration, api-design, authentication, component-architecture, database-layer, deployment, payment-integration, service-integration, state-management, styling-system, testing-strategy | When task matches domain |\n| **Quality** | 7 | accessibility-audit, code-review, debugging, performance-audit, project-onboarding, refactoring, security-audit | On review/audit tasks |\n\n**Protocol skills** are embedded in every agent's context via the subagent protocol chain — they're too critical for token efficiency and execution patterns to depend on lazy loading.\n\n**Outcome and quality skills** load proactively when Claude detects a matching task. Each skill includes a `## Resources` tree pointing to scripts and reference materials the agent can navigate as needed.\n\n**Fallback**: If a skill doesn't load automatically, the registry engine's `get_skill_content` tool serves as an escape hatch.\n\n## Hooks - 11 Types\n\nLifecycle hooks run transparently on every session. They're the mechanism behind tool redirection, context injection, and automatic error recovery.\n\n| Hook | Trigger | What It Does |\n|------|---------|-------------|\n| Setup | `claude --init` / `claude --init-only` | Pre-writes CLAUDE.md chain files (import directives + prompt files) so they exist before any session starts. Matches `init` trigger. Avoids race conditions where SessionStart isn't fast enough to write files before Claude reads them |\n| PreToolUse (Bash) | Before Bash execution | Platform path mapping (Windows/Linux), shell safety analysis, git commit quality gates |\n| PreToolUse (Native) | Before Read/Edit/Write/Glob/Grep | Blocks native tool, redirects to precision-engine equivalent |\n| PostToolUseFailure | After Bash failure | 3-phase progressive fix loop: Phase 1 (internal knowledge) -> Phase 2 (official docs hints) -> Phase 3 (community docs hints). Logs failures to `.goodvibes/memory/failures.json` after all phases exhausted |\n| SessionStart | Session begins | Detects project stack, analyzes git status, checks project health, creates/updates CLAUDE.md, injects context into system message, builds project file index |\n| SessionEnd | Session ends | Persists session state |\n| SubagentStart | Agent spawns | Injects context for GoodVibes agents (stack info, git branch, project name), tracks agent telemetry |\n| SubagentStop | Agent completes | Cleans up agent tracking, updates analytics |\n| PreCompact | Before context compaction | Creates checkpoint commit if uncommitted changes exist, generates session summary |\n| Stop | Stop button pressed | Saves current state |\n| UserPromptSubmit | User sends message | Processes user input |\n\n## Output Styles\n\nTwo execution modes for different workflows. Set via `/output-style goodvibes:vibecoding` or `/output-style goodvibes:justvibes`.\n\n| Setting | vibecoding | justvibes |\n|---------|-----------|------------|\n| Description | Autonomous coding with communication | Fully autonomous silent execution |\n| show_progress | true | false |\n| explain_decisions | true | false |\n| ask_on_ambiguity | true | false |\n| auto_chain | false | true |\n| max_autonomous_batches | 1 | unlimited |\n| checkpoint_frequency | per_batch | per_phase |\n| parallel_agents | 6 | 6 |\n| recovery (issues/errors) | ask_user_with_options | fix_review_loop |\n| recovery (other) | ask_user | choose_best_option_silent |\n| max_fix_attempts | 3 | 3 |\n| fix_attempt strategy | one_shot (all sources at once) | cumulative (staged escalation) |\n| default output mode | standard | minimal |\n| show_diffs | true | false |\n| show_telemetry | summary | none |\n| log_activity | false | true |\n\n## Memory System\n\nTwo-tier persistent memory. Session logs track the current session. Cross-session memory persists across conversations.\n\n### Session Logs (`.goodvibes/logs/`)\n\n- `decisions.md` — Architectural choices with options considered, rationale, implications\n- `errors.md` — Failures categorized by type (TOOL_FAILURE, BUILD_ERROR, TEST_FAILURE, etc.) with root cause and resolution\n- `activity.md` — Completed work that passed review (primarily used in justvibes mode)\n\n### Cross-Session Memory (`.goodvibes/memory/`)\n\n- `decisions.json` — Decision records with category, scope, confidence (max 1000 entries, auto-prunes oldest)\n- `patterns.json` — Proven approaches with example files and keywords (max 500)\n- `failures.json` — Failed approaches with root cause and prevention guidance (max 500)\n- `preferences.json` — User conventions (code style, naming, patterns)\n\nAgents read memory before acting. The PostToolUseFailure hook automatically records failures after its 3-phase fix loop is exhausted.\n\n## Telemetry\n\nBuilt-in telemetry tracks tool usage, session activity, and performance metrics in a local SQLite database (sql.js WASM). Query via `precision_config action=telemetry` with filters for tool, status, session_id, and date range. All data stays local — nothing is sent externally.\n\n## Configuration\n\nGoodVibes works out of the box. Minimal configuration needed.\n\n### Path Sandboxing\n\nControls whether precision tools can access files outside the project root. Disabled by default.\n\n```bash\n/goodvibes:sandbox true    # Enable (restrict to project root)\n/goodvibes:sandbox false   # Disable (allow external paths, default)\n```\n\n### Service Registry\n\nNamed API services with stored credentials for precision_fetch auto-auth:\n\n```bash\n/goodvibes:services add OpenAI    # Configure a new API service\n/goodvibes:services list           # Show registered services\n/goodvibes:services test OpenAI    # Test service connectivity\n```\n\n### Output Style\n\nSwitch execution modes:\n\n```bash\n/output-style goodvibes:vibecoding\n/output-style goodvibes:justvibes\n```\n\n## Slash Commands\n\n| Command | Purpose |\n|---------|---------|\n| `/goodvibes:sandbox` | Toggle path sandboxing (true/false) |\n| `/goodvibes:plugin` | Plugin management (update, status, config) |\n| `/goodvibes:search` | Search skills, agents, or tools |\n| `/goodvibes:services` | Manage precision_fetch service registry (add, remove, test, auth) |\n| `/goodvibes:load-skill` | Load a skill's content into context |\n| `/goodvibes:codebase-review` | Full codebase audit with parallel agent remediation |\n\n## License\n\nMIT License - see [LICENSE](LICENSE) for details.\n\n---\n\n<p align=\"center\">\n  <b>Plug in, receive good vibes</b>\n  <br><br>\n  <code>claude plugin marketplace add mgd34msu/goodvibes-plugin</code>\n  <br>\n  <code>claude plugin install goodvibes@goodvibes-market</code>\n</p>\n"
      },
      "plugins": [
        {
          "name": "goodvibes",
          "source": "./plugins/goodvibes",
          "description": "Comprehensive Claude Code plugin with agents, skills, tools, hooks, and MCP servers for full-stack development.",
          "version": "1.0.0",
          "author": {
            "name": "Mike Davis"
          },
          "categories": [],
          "install_commands": [
            "/plugin marketplace add mgd34msu/goodvibes-plugin",
            "/plugin install goodvibes@goodvibes-market"
          ]
        }
      ]
    }
  ]
}