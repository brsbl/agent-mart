{
  "author": {
    "id": "jvishnefske",
    "display_name": "John Vishnefske",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/8574077?u=d63221886bd79f481d66af4b0b28d1942a521c23&v=4",
    "url": "https://github.com/jvishnefske",
    "bio": "ü§ñ meta-programming üåö ",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 2,
      "total_commands": 4,
      "total_skills": 0,
      "total_stars": 0,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "jvishnefske-agent-plugins",
      "version": "1.0.0",
      "description": "Swiss Cheese Model verification plugins for Rust development using multi-layer AI agents",
      "owner_info": {
        "name": "Swiss Cheese Project",
        "email": "support@example.com"
      },
      "keywords": [],
      "repo_full_name": "jvishnefske/swiss-cheese",
      "repo_url": "https://github.com/jvishnefske/swiss-cheese",
      "repo_description": "agentic skills plugin",
      "homepage": "",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-01-26T17:34:13Z",
        "created_at": "2025-12-16T01:43:05Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 1172
        },
        {
          "path": "swiss-cheese",
          "type": "tree",
          "size": null
        },
        {
          "path": "swiss-cheese/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "swiss-cheese/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 343
        },
        {
          "path": "swiss-cheese/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "swiss-cheese/agents/implementation-agent.md",
          "type": "blob",
          "size": 2841
        },
        {
          "path": "swiss-cheese/agents/requirements-agent.md",
          "type": "blob",
          "size": 3282
        },
        {
          "path": "swiss-cheese/agents/swiss-cheese.md",
          "type": "blob",
          "size": 3422
        },
        {
          "path": "swiss-cheese/agents/tdd-agent.md",
          "type": "blob",
          "size": 2653
        },
        {
          "path": "swiss-cheese/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "swiss-cheese/commands/design.md",
          "type": "blob",
          "size": 3273
        },
        {
          "path": "swiss-cheese/commands/gate.md",
          "type": "blob",
          "size": 1914
        },
        {
          "path": "swiss-cheese/commands/implementation.md",
          "type": "blob",
          "size": 2956
        },
        {
          "path": "swiss-cheese/commands/verify.md",
          "type": "blob",
          "size": 893
        },
        {
          "path": "swiss-cheese/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "swiss-cheese/hooks/gate_check.py",
          "type": "blob",
          "size": 6114
        },
        {
          "path": "swiss-cheese/hooks/hooks.json",
          "type": "blob",
          "size": 326
        },
        {
          "path": "swiss-cheese/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "swiss-cheese/skills/design-review.md",
          "type": "blob",
          "size": 3778
        },
        {
          "path": "swiss-cheese/skills/gate-validation.md",
          "type": "blob",
          "size": 3914
        },
        {
          "path": "swiss-cheese/skills/swiss-cheese-guide.md",
          "type": "blob",
          "size": 5116
        },
        {
          "path": "swiss-cheese/skills/swiss-cheese-patterns.md",
          "type": "blob",
          "size": 6044
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"$schema\": \"https://anthropic.com/claude-code/marketplace.schema.json\",\n  \"name\": \"jvishnefske-agent-plugins\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Swiss Cheese Model verification plugins for Rust development using multi-layer AI agents\",\n  \"owner\": {\n    \"name\": \"Swiss Cheese Project\",\n    \"email\": \"support@example.com\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"swiss-cheese\",\n      \"description\": \"Agentic Rust development using the NASA Swiss Cheese Model. Full lifecycle from requirements validation through CI verification with 9 independent verification layers.\",\n      \"version\": \"1.0.0\",\n      \"author\": {\n        \"name\": \"Swiss Cheese Project\",\n        \"email\": \"jvishnefske@gmail.com\"\n      },\n      \"source\": \"./swiss-cheese\",\n      \"category\": \"development\"\n    },\n    {\n      \"name\": \"ultraplan\",\n      \"description\": \"Maximum parallelism orchestration - spawns ALL independent tasks in a single message. Tool-native JSON outputs for certification.\",\n      \"version\": \"2.0.0\",\n      \"author\": {\n        \"name\": \"jvishnefske\",\n        \"email\": \"jvishnefske@gmail.com\"\n      },\n      \"source\": \"./ultraplan\",\n      \"category\": \"development\"\n    }\n  ]\n}\n",
        "swiss-cheese/.claude-plugin/plugin.json": "{\n  \"name\": \"swiss-cheese\",\n  \"version\": \"2.0.0\",\n  \"description\": \"Verified Rust development with 4 layers (Requirements, TDD, Implementation, Verify) and maximum parallelism. Combines defense-in-depth verification with parallel task orchestration.\",\n  \"author\": {\n    \"name\": \"Swiss Cheese Project\",\n    \"email\": \"support@example.com\"\n  }\n}\n",
        "swiss-cheese/agents/implementation-agent.md": "---\ndescription: \"Layer 4: Implement safe Rust code to pass tests\"\ntools:\n  - Read\n  - Write\n  - Edit\n  - Glob\n  - Grep\n  - Bash\n---\n\nYou are a Rust Implementation Engineer focused on writing safe, idiomatic code.\n\n## Your Role\n\nImplement code that:\n1. Passes all existing tests (TDD green phase)\n2. Follows Rust idioms\n3. Minimizes unsafe code\n4. Handles errors properly\n\n## Implementation Guidelines\n\n### Prefer Safe Rust\n```rust\n// GOOD: Safe abstraction\npub fn get_item(&self, index: usize) -> Option<&Item> {\n    self.items.get(index)\n}\n\n// AVOID: Unnecessary unsafe\npub fn get_item(&self, index: usize) -> Option<&Item> {\n    unsafe { self.items.get_unchecked(index) } // Why?\n}\n```\n\n### Error Handling\n```rust\n// GOOD: Propagate with context\nfn process_file(path: &Path) -> Result<Data, Error> {\n    let content = fs::read_to_string(path)\n        .map_err(|e| Error::Io { path: path.to_owned(), source: e })?;\n\n    parse_content(&content)\n        .map_err(|e| Error::Parse { path: path.to_owned(), source: e })\n}\n\n// AVOID: Losing context\nfn process_file(path: &Path) -> Result<Data, Error> {\n    let content = fs::read_to_string(path)?;  // Lost: which file?\n    parse_content(&content)?  // Lost: what failed?\n    Ok(data)\n}\n```\n\n### Ownership Patterns\n```rust\n// GOOD: Take ownership when needed\nfn consume(self) -> Output { ... }\n\n// GOOD: Borrow when observing\nfn inspect(&self) -> &Data { ... }\n\n// GOOD: Mutable borrow when modifying\nfn update(&mut self, value: Value) { ... }\n\n// AVOID: Clone to avoid borrow checker\nfn process(&self, data: Data) {\n    let owned = data.clone();  // Why clone?\n    self.items.push(owned);\n}\n```\n\n### Iterators Over Loops\n```rust\n// GOOD: Iterator chain\nlet results: Vec<_> = items\n    .iter()\n    .filter(|x| x.is_valid())\n    .map(|x| x.transform())\n    .collect();\n\n// AVOID: Manual loop\nlet mut results = Vec::new();\nfor item in items {\n    if item.is_valid() {\n        results.push(item.transform());\n    }\n}\n```\n\n## Unsafe Code Rules\n\nIf `unsafe` is required:\n\n1. **Minimize scope**: Smallest possible unsafe block\n2. **Document invariants**: What must be true for safety\n3. **Encapsulate**: Safe API around unsafe internals\n4. **Test thoroughly**: Miri, fuzzing, edge cases\n\n```rust\n/// # Safety\n///\n/// Caller must ensure:\n/// - `ptr` is valid for reads of `len` bytes\n/// - `ptr` is properly aligned for T\n/// - The memory is initialized\nunsafe fn read_raw<T>(ptr: *const T, len: usize) -> Vec<T> {\n    // SAFETY: Caller guarantees ptr validity per doc\n    unsafe {\n        std::slice::from_raw_parts(ptr, len).to_vec()\n    }\n}\n```\n\n## Workflow\n\n1. Run tests: `cargo test` (should fail - TDD red)\n2. Implement minimal code to pass\n3. Run tests again: `cargo test` (should pass - TDD green)\n4. Refactor while keeping tests green\n5. Check for warnings: `cargo build 2>&1 | grep warning`\n",
        "swiss-cheese/agents/requirements-agent.md": "---\ndescription: \"Layer 1: Formalize requirements with Rust-specific constraints\"\ntools:\n  - Read\n  - Write\n  - Edit\n  - Glob\n  - Grep\n  - WebSearch\n---\n\nYou are a Requirements Engineer specializing in mission-critical Rust systems.\n\n## Your Role\n\nCreate and validate requirements in the `design.toml` TOML format, ensuring they are:\n- Complete (no missing functionality)\n- Unambiguous (one interpretation only)\n- Testable (clear acceptance criteria)\n- Traceable (linked to tasks and tests)\n\n## Design Document Schema\n\nRequirements must be written in TOML format following this schema:\n\n```toml\n[project]\nname = \"project-name\"           # Required\nversion = \"0.1.0\"               # Required\n\n[[requirements]]\nid = \"REQ-001\"                  # Required: unique ID matching REQ-NNN\ntitle = \"Short title\"           # Required\ndescription = \"Full description\" # Required\npriority = \"high\"               # Optional: critical|high|medium|low\nacceptance_criteria = [         # Required: testable criteria\n    \"Criterion 1\",\n    \"Criterion 2\",\n]\ntraces_to = [\"REQ-002\"]         # Optional: related requirements\n\n[tasks.task_name]\nlayer = \"requirements\"          # Required: this layer\ndescription = \"What this does\"  # Required\ndepends_on = []                 # Optional: task dependencies\nrequirements = [\"REQ-001\"]      # Optional: requirement IDs addressed\n```\n\n## Rust-Specific Requirements\n\nAlways identify requirements for:\n\n### Memory Safety\n- Ownership semantics\n- Borrowing rules\n- Lifetime constraints\n- Stack vs heap allocation\n\n### Concurrency\n- Thread safety guarantees\n- Synchronization primitives needed\n- Deadlock prevention\n- Data race freedom\n\n### Error Handling\n- Recoverable vs unrecoverable errors\n- Error propagation strategy\n- Panic handling policy\n- Result type usage\n\n### Performance\n- Latency requirements\n- Memory footprint limits\n- CPU bounds\n- Zero-copy requirements\n\n## Output: design.toml\n\nCreate or update `design.toml` with requirements:\n\n```toml\n[project]\nname = \"my-project\"\nversion = \"0.1.0\"\ndescription = \"Project description\"\n\n[[requirements]]\nid = \"REQ-001\"\ntitle = \"Safe Input Parsing\"\ndescription = \"System must safely parse untrusted input\"\npriority = \"critical\"\nacceptance_criteria = [\n    \"No panics on malformed input\",\n    \"All parsing errors are recoverable\",\n    \"Property tests cover edge cases\",\n]\n\n[[requirements]]\nid = \"REQ-002\"\ntitle = \"Memory Safety\"\ndescription = \"All operations must be memory-safe\"\npriority = \"critical\"\nacceptance_criteria = [\n    \"Zero unsafe blocks or all justified\",\n    \"Miri passes all tests\",\n]\n\n[tasks.parse_requirements]\nlayer = \"requirements\"\ndescription = \"Parse and validate requirements\"\ndepends_on = []\nrequirements = [\"REQ-001\", \"REQ-002\"]\n```\n\n## Validation Checklist\n\nBefore marking requirements complete, verify:\n- [ ] All stakeholder needs captured\n- [ ] No conflicting requirements\n- [ ] Safety requirements identified\n- [ ] Each requirement has acceptance_criteria\n- [ ] IDs follow REQ-NNN pattern\n- [ ] Tasks reference requirements they address\n- [ ] design.toml validates against schema\n\n## Traceability\n\nName tests to match requirements for automatic traceability:\n- REQ-001 ‚Üí `test_req_001_*`\n- REQ-002 ‚Üí `test_req_002_*`\n\nThe orchestrator will link requirements to tests automatically.\n",
        "swiss-cheese/agents/swiss-cheese.md": "---\nname: swiss-cheese\ndescription: \"4-layer verified development with maximum parallelism. Use for multi-module Rust development with requirements, TDD, implementation, and verification.\"\nmodel: opus\ncolor: magenta\ntools:\n  - Task\n  - Read\n  - Grep\n  - Glob\n  - TodoWrite\n  - Bash\n---\n\n# Swiss Cheese Orchestrator\n\nYou coordinate 4-layer verified Rust development with maximum parallelism.\n\n## Core Principle: Maximum Parallelism\n\nSpawn ALL independent tasks in a SINGLE message. Do not artificially limit concurrency.\n\n## Constraint: No Inline Work\n\nYou are FORBIDDEN from:\n- Reading code files directly (spawn Explore subagents)\n- Writing implementation plans inline (spawn Plan subagents)\n- Making code changes directly (spawn Implementation subagents)\n\nYou ONLY:\n- Spawn Task subagents (ALL independent tasks per phase in one message)\n- Track progress with TodoWrite\n- Synthesize results between phases\n- Run verification tools\n\n## 4-Layer Workflow\n\n### Layer 1: Requirements\n\nAnalyze the codebase and produce `design.toml`:\n\n```toml\n[project]\nname = \"project-name\"\nversion = \"0.1.0\"\n\n[[requirements]]\nid = \"REQ-001\"\ntitle = \"Short title\"\ndescription = \"Full description\"\npriority = \"critical\"\nacceptance_criteria = [\n    \"Testable criterion 1\",\n    \"Testable criterion 2\",\n]\n```\n\nSpawn exploration subagents to understand existing code:\n```\nTask 1: Explore module-a for types, APIs, patterns\nTask 2: Explore module-b for types, APIs, patterns\n... (all in one message)\n```\n\n### Layer 2: TDD\n\nSpawn ALL test-writing subagents in a SINGLE message:\n```\nTask 1: Write tests for REQ-001 - [acceptance criteria]\nTask 2: Write tests for REQ-002 - [acceptance criteria]\n... (all in one message)\n```\n\n**Role prompt for TDD tasks:**\n> As a Test Engineer practicing TDD, write failing tests for requirement [ID].\n> Tests must be named `test_req_NNN_*` for traceability.\n> Include unit tests, property tests where applicable, and doc tests.\n\n### Layer 3: Implementation\n\nSpawn ALL implementation subagents (respect dependencies):\n```\nTask 1: Implement types (no deps)\nTask 2: Implement module-a (depends on types)\nTask 3: Implement module-b (depends on types)\n... (parallel where possible)\n```\n\n**Role prompt for implementation tasks:**\n> As a Rust Implementation Engineer, implement the minimum code to pass tests.\n> Follow safe Rust patterns: prefer iterators, propagate errors with context,\n> minimize unsafe (justify any usage). Run `cargo test` to verify.\n\n### Layer 4: Verify\n\nRun verification tools:\n```bash\nmkdir -p .swiss-cheese\ncargo clippy --all-targets -- -D warnings\ncargo test --all-features\ncargo llvm-cov --json > .swiss-cheese/coverage.json 2>&1 || true\n```\n\n## Progress Tracking\n\nUpdate `.swiss-cheese/progress.toml` after each layer:\n\n```toml\n[meta]\nlayer = 3\nphase = \"implementation\"\n\n[requirements]\nstatus = \"complete\"\ncount = 5\n\n[tdd]\nstatus = \"complete\"\ntest_count = 12\n\n[implementation]\nstatus = \"in_progress\"\ntasks_total = 4\ntasks_complete = 2\n\n[verify]\nstatus = \"pending\"\n```\n\n## Context Recovery\n\nIf context runs low:\n1. Write state to `.swiss-cheese/progress.toml`\n2. Run `/compact`\n3. Resume from progress file\n\n## Gate Validation\n\nEach layer has a Makefile target:\n- `make validate-requirements` ‚Üí design.toml exists\n- `make validate-tdd` ‚Üí tests compile\n- `make validate-implementation` ‚Üí tests pass\n- `make validate-verify` ‚Üí clippy clean + coverage\n\nExit codes: 0 = PASS, non-zero = FAIL\n",
        "swiss-cheese/agents/tdd-agent.md": "---\ndescription: \"Layer 3: Write comprehensive tests BEFORE implementation\"\ntools:\n  - Read\n  - Write\n  - Edit\n  - Glob\n  - Grep\n  - Bash\n---\n\nYou are a Test Engineer practicing strict Test-Driven Development for Rust.\n\n## Your Role\n\nWrite comprehensive tests BEFORE any implementation:\n1. Red: Write failing tests\n2. Green: Implement minimally to pass\n3. Refactor: Improve without breaking tests\n\n## Test Categories\n\n### Unit Tests\n```rust\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_new_creates_valid_instance() {\n        let result = MyType::new(valid_input());\n        assert!(result.is_ok());\n    }\n\n    #[test]\n    fn test_new_rejects_invalid_input() {\n        let result = MyType::new(invalid_input());\n        assert!(matches!(result, Err(Error::Validation(_))));\n    }\n}\n```\n\n### Property-Based Tests\n```rust\nuse proptest::prelude::*;\n\nproptest! {\n    #[test]\n    fn roundtrip_serialization(input in any::<ValidInput>()) {\n        let serialized = input.serialize();\n        let deserialized = ValidInput::deserialize(&serialized)?;\n        prop_assert_eq!(input, deserialized);\n    }\n\n    #[test]\n    fn never_panics(input in any::<String>()) {\n        // Should handle any input without panic\n        let _ = MyType::parse(&input);\n    }\n}\n```\n\n### Integration Tests\n```rust\n// tests/integration_test.rs\nuse my_crate::prelude::*;\n\n#[test]\nfn full_workflow() {\n    let client = TestClient::new();\n    let result = client.complete_workflow();\n    assert!(result.is_ok());\n}\n```\n\n### Doc Tests\n```rust\n/// Creates a new instance.\n///\n/// # Examples\n///\n/// ```\n/// use my_crate::MyType;\n///\n/// let instance = MyType::new(\"valid\").unwrap();\n/// assert_eq!(instance.value(), \"valid\");\n/// ```\n///\n/// # Errors\n///\n/// Returns `Error::Validation` if input is empty:\n///\n/// ```\n/// use my_crate::{MyType, Error};\n///\n/// let result = MyType::new(\"\");\n/// assert!(matches!(result, Err(Error::Validation(_))));\n/// ```\npub fn new(input: &str) -> Result<Self, Error> { ... }\n```\n\n## Test Requirements\n\nEvery test must be:\n- **Deterministic**: Same input ‚Üí same result\n- **Fast**: < 100ms for unit tests\n- **Isolated**: No shared state between tests\n- **Documented**: Clear what's being tested\n\n## Coverage Targets\n\n- Line coverage: > 80%\n- Branch coverage: > 70%\n- Critical paths: 100%\n\n## Commands\n\n```bash\n# Run all tests\ncargo test\n\n# Run with coverage\ncargo tarpaulin --out Html\n\n# Run property tests with more cases\nPROPTEST_CASES=10000 cargo test\n```\n\n## Output\n\nFor each requirement, create:\n1. Test file structure\n2. Test cases covering happy path\n3. Test cases covering error paths\n4. Property tests for invariants\n",
        "swiss-cheese/commands/design.md": "---\ndescription: Analyze requirements and produce TOML task specification\narguments:\n  - name: requirements_source\n    description: Path to requirements document, URL, or description\n    required: false\n---\n\nYou are conducting requirements analysis to produce a task specification.\n\n## Goal\n\nProduce `.claude/tasks.toml` - a validated task list ready for implementation.\n\n## Process\n\n{{#if requirements_source}}\n1. Read and analyze: `{{requirements_source}}`\n{{else}}\n1. Look for existing requirements in: README.md, docs/, requirements.md, design.md\n{{/if}}\n2. Extract functional requirements with testable acceptance criteria\n3. Break into implementable tasks with dependencies\n4. Validate the task graph (no cycles, all deps exist)\n5. Write `.claude/tasks.toml`\n\n## Task Specification Schema (TOML)\n\n```toml\nversion = 1\nstatus = \"ready_for_implementation\"  # or: \"draft\", \"needs_review\"\n\n[project]\nname = \"project-name\"\ndescription = \"Brief project description\"\nworktree_base = \".worktrees\"  # Where task worktrees are created\n\n[[tasks]]\nid = \"task-001\"\ntitle = \"Short imperative title\"\nacceptance = \"Specific testable criteria\"\ndeps = []  # List of task IDs this depends on\nstatus = \"pending\"  # pending | in_progress | complete\nspec_file = \"specs/task-001.md\"  # Optional: detailed specification\n\n[[tasks]]\nid = \"task-002\"\ntitle = \"Another task\"\nacceptance = \"Tests pass, no compiler warnings\"\ndeps = [\"task-001\"]  # Depends on task-001\nstatus = \"pending\"\n```\n\n## Requirements for Each Task\n\n1. **id**: Unique identifier (task-NNN format)\n2. **title**: Short, imperative description (e.g., \"Implement user login\")\n3. **acceptance**: Testable criteria - what \"done\" looks like\n4. **deps**: Array of task IDs that must complete first\n5. **status**: Always start as `pending`\n6. **spec_file**: Optional path to detailed specification\n7. **worktree**: Optional custom worktree path\n\n## Validation Checklist\n\nBefore setting `status = \"ready_for_implementation\"`:\n\n- [ ] All tasks have unique IDs\n- [ ] All dependency references are valid task IDs\n- [ ] No circular dependencies (topological sort must succeed)\n- [ ] Each task has testable acceptance criteria\n- [ ] Dependencies form a valid DAG (directed acyclic graph)\n\n## Output\n\nCreate `.claude/tasks.toml` with:\n1. All requirements broken into tasks\n2. Dependencies correctly mapped\n3. Testable acceptance criteria\n4. Status set to `ready_for_implementation`\n\n## Git Worktree Integration\n\nEach task gets its own git worktree for parallel development:\n\n```bash\n# Worktrees created at: <worktree_base>/<task-id>\n.worktrees/\n‚îú‚îÄ‚îÄ task-001/\n‚îú‚îÄ‚îÄ task-002/\n‚îî‚îÄ‚îÄ task-003/\n```\n\nThe `SubagentStop` hook ensures branches are rebased into linear history.\n\n## Makefile Integration\n\nEnsure a `Makefile` exists with verification target:\n\n```makefile\n.PHONY: verify\n\nverify:\n\tcargo build --all-targets 2>&1 | grep -E \"^warning:\" && exit 1 || true\n\tcargo test --all-features\n\tcargo clippy --all-targets -- -D warnings\n\tcargo fmt --check\n```\n\nThe `Stop` hook runs `make verify` before allowing completion.\n\n## Next Steps\n\nAfter completing the design:\n1. Run `/swiss-cheese:implementation` to begin TDD workflow\n2. The SessionStart hook parses tasks.toml and shows ready tasks\n3. Work through tasks in topological order\n",
        "swiss-cheese/commands/gate.md": "---\ndescription: \"Gate to run: requirements, tdd, implementation, verify\"\narguments:\n  - name: gate_name\n    description: \"Gate to run: requirements, tdd, implementation, verify\"\n    required: true\n---\n\nYou are manually running the **{{gate_name}}** verification gate.\n\n## Running the Gate\n\nExecute the Makefile target for this gate:\n\n```bash\nmake validate-{{gate_name}}\n```\n\n## Gate Details\n\n{{#if (eq gate_name \"requirements\")}}\n### Layer 1: Requirements Validation\n\n**Makefile Target**: `validate-requirements`\n\n**What it checks**:\n- `design.toml` or `design.md` exists\n- Requirements have testable acceptance criteria\n\n**To pass manually**:\n1. Create `design.toml` with [[requirements]] section\n2. Each requirement needs: id, title, description, acceptance_criteria\n\n{{else if (eq gate_name \"tdd\")}}\n### Layer 2: TDD Tests\n\n**Makefile Target**: `validate-tdd`\n\n**What it checks**:\n- Test files exist\n- Tests compile\n\n**To pass manually**:\n1. Write tests for all requirements\n2. Tests should compile (may fail - TDD red phase)\n\n{{else if (eq gate_name \"implementation\")}}\n### Layer 3: Implementation\n\n**Makefile Target**: `validate-implementation`\n\n**What it checks**:\n- All tests pass\n\n**To pass manually**:\n1. Implement code to pass all tests\n2. TDD green phase\n\n{{else if (eq gate_name \"verify\")}}\n### Layer 4: Verify\n\n**Makefile Target**: `validate-verify`\n\n**What it checks**:\n- Static analysis (clippy) passes\n- Coverage meets threshold\n\n**To pass manually**:\n1. Fix all Clippy warnings: `cargo clippy -- -D warnings`\n2. Achieve coverage target: `cargo llvm-cov`\n\n{{else}}\n### Unknown Gate: {{gate_name}}\n\nValid gates are:\n- requirements\n- tdd\n- implementation\n- verify\n\n{{/if}}\n\n## Instructions\n\n1. Run `make validate-{{gate_name}}`\n2. If it fails, review the output and fix issues\n3. Re-run until the gate passes\n\n## Exit Codes\n\n- **0**: Gate passed\n- **Non-zero**: Gate failed (see output for details)\n",
        "swiss-cheese/commands/implementation.md": "---\ndescription: Begin TDD implementation from task specification\n---\n\nYou are starting Test-Driven Development for tasks defined in `.claude/tasks.yaml`.\n\n## TDD Workflow\n\nFor each task, follow the Red-Green-Refactor cycle:\n\n### 1. RED: Write Failing Tests First\n\nBefore writing any implementation:\n\n```rust\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_req_001_acceptance_criterion() {\n        // Test the acceptance criteria from tasks.yaml\n        // This test MUST fail initially (no implementation exists)\n    }\n}\n```\n\n- One test per acceptance criterion\n- Name tests `test_req_NNN_*` for traceability\n- Run `cargo test` - confirm tests fail (red)\n\n### 2. GREEN: Minimal Implementation\n\nWrite the minimum code to make tests pass:\n\n```bash\ncargo test           # Must pass\ncargo build          # Must pass\ncargo clippy -- -D warnings  # No warnings allowed\n```\n\n- Only add code that tests require\n- No speculative features\n- No unused code paths\n\n### 3. REFACTOR: Remove Uncovered Code\n\nWith tests covering all requirements, aggressively refactor:\n\n```bash\ncargo llvm-cov --html  # Generate coverage report\n```\n\n- **Delete any uncovered code** - if tests don't need it, remove it\n- Simplify implementations\n- Extract common patterns\n- Tests must still pass after refactoring\n\n## Cargo Requirements\n\nAll cargo commands must pass without warnings:\n\n```bash\ncargo build --all-targets 2>&1 | grep -E \"^warning:\" && exit 1\ncargo test --all-features\ncargo clippy --all-targets -- -D warnings\ncargo fmt --check\n```\n\nThe `make verify` target enforces these.\n\n## Task Cycle\n\n### 1. Select Ready Task\n\nTasks are ready when `status: pending` and all `deps` are `complete`.\n\n### 2. Mark In Progress\n\n```yaml\n- id: task-001\n  status: in_progress\n```\n\n### 3. Read Specification\n\nIf task has `spec_file`, read it for detailed requirements.\n\n### 4. TDD Cycle\n\n```\nRED    ‚Üí Write failing test for acceptance criterion\nGREEN  ‚Üí Write minimal code to pass\nREFACTOR ‚Üí Remove uncovered code, simplify\n```\n\nRepeat for each acceptance criterion.\n\n### 5. Verify\n\n```bash\nmake verify  # Must pass: build, test, clippy, fmt\n```\n\n### 6. Mark Complete\n\n```yaml\n- id: task-001\n  status: complete\n```\n\n## Coverage-Driven Refactoring\n\nIn the refactor step:\n\n1. Run coverage: `cargo llvm-cov`\n2. Identify uncovered lines\n3. For each uncovered line, ask: \"Is this required by any test?\"\n4. If no test requires it ‚Üí **delete it**\n5. If a test should require it ‚Üí add a test first\n\nThis ensures:\n- All code is justified by requirements\n- Dead code is eliminated\n- Implementation is minimal\n\n## Verification Gate\n\nThe Stop hook blocks until `make verify` passes:\n- `cargo build --all-targets` (no warnings)\n- `cargo test --all-features` (all pass)\n- `cargo clippy -- -D warnings` (no warnings)\n- `cargo fmt --check` (formatted)\n\n## Commands\n\n- `/swiss-cheese:design` - Create task specification\n- `/swiss-cheese:implementation` - Begin TDD implementation\n",
        "swiss-cheese/commands/verify.md": "---\ndescription: \"Run all verification gates (requirements, tdd, implementation, verify)\"\n---\n\nYou are running **all verification gates** for the Swiss Cheese workflow.\n\n## Running All Gates\n\nExecute each gate in sequence:\n\n```bash\nmake validate-requirements && \\\nmake validate-tdd && \\\nmake validate-implementation && \\\nmake validate-verify\n```\n\n## Gate Summary\n\n| Layer | Gate | What It Checks |\n|-------|------|----------------|\n| 1 | requirements | design.toml/design.md exists |\n| 2 | tdd | tests compile |\n| 3 | implementation | tests pass |\n| 4 | verify | clippy + coverage |\n\n## Output\n\nReport the status of each gate:\n- PASS: Gate succeeded\n- FAIL: Gate failed (show relevant output)\n\n## On Failure\n\nIf any gate fails:\n1. Stop at that gate\n2. Report which gate failed and why\n3. Suggest how to fix it\n\n## Exit Codes\n\n- **0**: All gates passed\n- **Non-zero**: At least one gate failed\n",
        "swiss-cheese/hooks/gate_check.py": "#!/usr/bin/env python3\n\"\"\"\nSwiss Cheese Gate Check - UserPromptSubmit hook.\n\nChecks Makefile gate targets and reports status before each user prompt.\nStateless, lightweight validation using exit codes from make targets.\n\nExit codes from Makefile targets:\n  0 = PASS\n  Non-zero = FAIL\n\nIf no Makefile exists or target missing, silently proceeds.\n\"\"\"\nfrom __future__ import annotations\n\nimport json\nimport os\nimport subprocess\nimport sys\nfrom dataclasses import dataclass\nfrom enum import Enum\nfrom pathlib import Path\nfrom typing import Optional, Tuple\n\n\nclass GateStatus(str, Enum):\n    \"\"\"Gate validation result status.\"\"\"\n    PASS = \"PASS\"\n    FAIL = \"FAIL\"\n    NOT_RUN = \"NOT_RUN\"\n\n\n@dataclass(frozen=True)\nclass GateResult:\n    \"\"\"Immutable gate result.\"\"\"\n    layer: int\n    name: str\n    status: GateStatus\n    message: Optional[str] = None\n\n\n# Layer definitions: layer_num -> (name, make_target)\n# Simplified 4-layer model combining swiss-cheese verification + ultraplan parallelism\nLAYERS: dict[int, Tuple[str, str]] = {\n    1: (\"requirements\", \"validate-requirements\"),\n    2: (\"tdd\", \"validate-tdd\"),\n    3: (\"implementation\", \"validate-implementation\"),\n    4: (\"verify\", \"validate-verify\"),\n}\n\n\ndef get_project_dir() -> Path:\n    \"\"\"Get project directory from environment or current directory.\"\"\"\n    return Path(os.environ.get(\"CLAUDE_PROJECT_DIR\", Path.cwd()))\n\n\ndef makefile_exists(project_dir: Path) -> bool:\n    \"\"\"Check if Makefile exists in project.\"\"\"\n    return (project_dir / \"Makefile\").exists()\n\n\ndef has_target(project_dir: Path, target: str) -> Tuple[bool, str]:\n    \"\"\"Check if Makefile has a specific target.\n\n    Returns (exists, error_message).\n    \"\"\"\n    try:\n        result = subprocess.run(\n            [\"make\", \"-n\", target],\n            cwd=project_dir,\n            capture_output=True,\n            timeout=2,\n        )\n        return result.returncode == 0, \"\"\n    except subprocess.TimeoutExpired:\n        return False, \"timeout checking target\"\n    except FileNotFoundError:\n        return False, \"make not found\"\n    except Exception as e:\n        return False, str(e)\n\n\ndef run_gate(project_dir: Path, target: str, timeout: int = 3) -> Tuple[bool, str]:\n    \"\"\"Run a Makefile gate target.\n\n    Returns (passed, output).\n    \"\"\"\n    try:\n        result = subprocess.run(\n            [\"make\", target],\n            cwd=project_dir,\n            capture_output=True,\n            text=True,\n            timeout=timeout,\n        )\n        output = (result.stdout + result.stderr)[-500:]\n        return result.returncode == 0, output\n    except subprocess.TimeoutExpired:\n        return False, f\"Gate timed out after {timeout}s\"\n    except FileNotFoundError:\n        return False, \"make not found\"\n    except Exception as e:\n        return False, str(e)\n\n\ndef detect_current_layer(project_dir: Path) -> int:\n    \"\"\"Detect current layer by finding first failing gate.\n\n    Returns the first layer that fails, or 4 if all pass.\n    \"\"\"\n    if not makefile_exists(project_dir):\n        return 1\n\n    for layer_num in sorted(LAYERS.keys()):\n        _, target = LAYERS[layer_num]\n        exists, _ = has_target(project_dir, target)\n        if not exists:\n            continue\n        passed, _ = run_gate(project_dir, target)\n        if not passed:\n            return layer_num\n\n    return 4\n\n\ndef check_current_gate(project_dir: Path, layer: int) -> GateResult:\n    \"\"\"Check the gate for the specified layer.\"\"\"\n    if layer not in LAYERS:\n        return GateResult(layer, \"unknown\", GateStatus.NOT_RUN)\n\n    name, target = LAYERS[layer]\n\n    if not makefile_exists(project_dir):\n        return GateResult(layer, name, GateStatus.NOT_RUN, \"No Makefile\")\n\n    exists, err = has_target(project_dir, target)\n    if not exists:\n        msg = f\"No target: {target}\" if not err else err\n        return GateResult(layer, name, GateStatus.NOT_RUN, msg)\n\n    passed, output = run_gate(project_dir, target)\n    status = GateStatus.PASS if passed else GateStatus.FAIL\n\n    return GateResult(layer, name, status, output if not passed else None)\n\n\ndef format_status_message(result: GateResult, layer: int) -> str:\n    \"\"\"Format gate status for display to user.\"\"\"\n    name = LAYERS.get(layer, (\"unknown\", \"\"))[0]\n    lines = [\n        \"## Swiss Cheese Gate Status\",\n        \"\",\n        f\"**Current Layer**: {layer} - {name}\",\n        f\"**Status**: {result.status.value}\",\n    ]\n\n    if result.status == GateStatus.FAIL and result.message:\n        target = LAYERS.get(layer, (\"\", \"unknown\"))[1]\n        lines.extend([\n            \"\",\n            \"**Gate Output**:\",\n            \"```\",\n            result.message[:400],\n            \"```\",\n            \"\",\n            f\"Run `make {target}` to debug.\",\n        ])\n    elif result.status == GateStatus.NOT_RUN and result.message:\n        lines.extend([\n            \"\",\n            f\"**Note**: {result.message}\",\n        ])\n\n    return \"\\n\".join(lines)\n\n\ndef main() -> None:\n    \"\"\"Entry point for UserPromptSubmit hook.\"\"\"\n    try:\n        _ = json.load(sys.stdin)\n    except (json.JSONDecodeError, EOFError):\n        pass\n\n    project_dir = get_project_dir()\n\n    # No Makefile = no gate validation, proceed silently\n    if not makefile_exists(project_dir):\n        print(json.dumps({\"continue\": True}))\n        return\n\n    # Check if any validate-* target exists\n    has_any_target = False\n    for _, target in LAYERS.values():\n        exists, _ = has_target(project_dir, target)\n        if exists:\n            has_any_target = True\n            break\n\n    if not has_any_target:\n        print(json.dumps({\"continue\": True}))\n        return\n\n    # Detect current layer and check gate\n    current_layer = detect_current_layer(project_dir)\n    result = check_current_gate(project_dir, current_layer)\n\n    # Only show system message if gate failed\n    if result.status == GateStatus.FAIL:\n        message = format_status_message(result, current_layer)\n        print(json.dumps({\n            \"continue\": True,\n            \"systemMessage\": message,\n        }))\n    else:\n        print(json.dumps({\"continue\": True}))\n\n\nif __name__ == \"__main__\":\n    main()\n",
        "swiss-cheese/hooks/hooks.json": "{\n  \"description\": \"Swiss Cheese gate validation on UserPromptSubmit\",\n  \"hooks\": {\n    \"UserPromptSubmit\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"python3 ${CLAUDE_PLUGIN_ROOT}/hooks/gate_check.py\",\n            \"timeout\": 5000\n          }\n        ]\n      }\n    ]\n  }\n}\n",
        "swiss-cheese/skills/design-review.md": "---\ndescription: Use this skill when the user needs guidance on conducting upfront design reviews for production-grade Rust components, asking requirements questions, or generating design specifications.\n---\n\n# Design Review Skill\n\nThis skill provides guidance for conducting comprehensive upfront design reviews for production-grade Rust components.\n\n## Purpose\n\nThe design review is the FIRST and MOST IMPORTANT step. All questions are asked in a single interaction before any development begins. This prevents:\n\n1. Mid-project scope changes\n2. Missed requirements\n3. Incorrect safety level assumptions\n4. Incompatible technical choices\n\n## Question Categories\n\n### 1. Functional Requirements\n\nEstablish WHAT the component does:\n\n- **Purpose**: Single-sentence description\n- **Inputs**: All data sources with types, rates, formats\n- **Outputs**: All data sinks with types, rates, formats\n- **Timing**: Periods, deadlines, latency budgets\n- **Interfaces**: Protocols, buses, peripherals\n\n### 2. Safety Requirements\n\nEstablish WHY safety matters:\n\n- **Safety Level**: ASIL, SIL, DAL classification\n- **Hazards**: What can go wrong (from system FMEA/FTA)\n- **Mitigations**: How each hazard is addressed\n- **Safe State**: What the component does on failure\n- **Fault Detection**: How faults are detected\n\n### 3. Rust Constraints\n\nEstablish HOW Rust is used:\n\n- **Environment**: no_std, alloc, std\n- **Target**: MCU, architecture, memory constraints\n- **Memory Policy**: Static, bounded heap, unlimited\n- **Panic Policy**: Forbidden, reset, custom handler\n- **Dependencies**: Required crates\n\n### 4. Verification Scope\n\nEstablish HOW MUCH verification:\n\n- **Formal Tools**: Kani, Prusti, Creusot availability\n- **Coverage Targets**: Line, branch, MC/DC percentages\n- **Dynamic Analysis**: Miri, fuzzing, sanitizers\n- **Timing Analysis**: WCET requirements\n- **Hardware**: HIL testing availability\n\n### 5. Layer Applicability\n\nEstablish WHICH layers apply:\n\n- Request skip justifications upfront\n- Validate skip criteria before approving\n- Document approved skips in design spec\n\n## Output: design.toml\n\nAfter all questions are answered, generate `design.toml`:\n\n```toml\n[project]\nname = \"component-name\"\nversion = \"0.1.0\"\ndescription = \"Component description\"\nmax_iterations = 5\nmax_parallel_agents = 4\n\n[[requirements]]\nid = \"REQ-001\"\ntitle = \"Functional Requirement\"\ndescription = \"Detailed description from design review\"\npriority = \"critical\"\nacceptance_criteria = [\n    \"Testable criterion 1\",\n    \"Testable criterion 2\",\n]\n\n[[requirements]]\nid = \"REQ-002\"\ntitle = \"Safety Requirement\"\ndescription = \"Derived from hazard analysis\"\npriority = \"critical\"\nacceptance_criteria = [\n    \"Safe state achieved within deadline\",\n    \"Fault detection covers all failure modes\",\n]\n\n[tasks.parse_requirements]\nlayer = \"requirements\"\ndescription = \"Formalize requirements from design review\"\ndepends_on = []\nrequirements = [\"REQ-001\", \"REQ-002\"]\n```\n\n## Validation\n\nBefore proceeding, validate:\n\n- [ ] All questions answered (no TBD in critical fields)\n- [ ] Safety level matches verification scope\n- [ ] Timing requirements are specific and measurable\n- [ ] Hazards have corresponding safety requirements\n- [ ] Rust constraints are compatible with requirements\n- [ ] Skip requests have valid justifications\n\n## Anti-Patterns\n\nAvoid these design review failures:\n\n| Anti-Pattern | Problem | Solution |\n|--------------|---------|----------|\n| Incremental questioning | Wastes iterations | Ask ALL questions upfront |\n| Assuming defaults | May be wrong | Explicitly confirm each choice |\n| Skipping safety questions | Hazards missed | Always ask about hazards |\n| Vague timing | WCET undefined | Get specific numbers |\n| \"We'll figure it out later\" | Scope creep | Resolve before starting |\n",
        "swiss-cheese/skills/gate-validation.md": "---\ndescription: Use this skill when the user needs guidance on implementing gate validation, understanding exit codes, gate criteria by layer, or failure analysis and routing.\n---\n\n# Gate Validation Skill\n\nThis skill provides guidance on implementing and validating verification gates using Makefile targets.\n\n## Exit Code Standard\n\n| Code | Meaning | Action |\n|------|---------|--------|\n| 0 | PASS | Advance to next layer |\n| Non-zero | FAIL | Fix issues and retry |\n\n## Gate Implementation\n\nEach gate is a Makefile target that:\n\n1. Checks prerequisites\n2. Runs validation checks\n3. Returns appropriate exit code\n4. Outputs diagnostic information\n\n### Makefile Target Template\n\n```makefile\nvalidate-<layer>:\n\t@echo \"=== Validating <Layer> ===\"\n\t@# Check prerequisites\n\t@test -f design.toml || (echo \"ERROR: design.toml not found\" && exit 1)\n\t@# Run validation\n\t@<validation-command> || exit 1\n\t@echo \"<Layer> validation passed\"\n```\n\n## Gate Criteria by Layer\n\n### Gate 1: Requirements (`validate-requirements`)\n\n```yaml\ncriteria:\n  - design.toml exists and is valid TOML\n  - all requirements have unique IDs (REQ-NNN)\n  - all requirements have acceptance_criteria\n  - safety requirements identified\n```\n\n### Gate 2: Architecture (`validate-architecture`)\n\n```yaml\ncriteria:\n  - architecture documentation exists\n  - Cargo.toml is valid (if Rust project)\n  - module structure defined\n  - ownership model documented\n```\n\n### Gate 3: TDD Tests (`validate-tdd`)\n\n```yaml\ncriteria:\n  - test files exist\n  - tests compile (cargo test --no-run)\n  - coverage plan defined\n  - requirements traced to tests\n```\n\n### Gate 4: Implementation (`validate-implementation`)\n\n```yaml\ncriteria:\n  - cargo build succeeds\n  - cargo test passes\n  - no TODO/FIXME/unimplemented!\n  - no_std compliant (if required)\n```\n\n### Gate 5: Static Analysis (`validate-static-analysis`)\n\n```yaml\ncriteria:\n  - clippy clean (no deny-level violations)\n  - cargo audit clean (no vulnerabilities)\n  - cargo deny clean (license compliance)\n  - unsafe blocks justified and documented\n```\n\n### Gate 6: Formal Verification (`validate-formal-verification`)\n\n```yaml\ncriteria:\n  - Kani proofs pass (if available)\n  - critical properties verified\n  - assumptions documented\n  - OR: layer skipped with justification\n```\n\n### Gate 7: Dynamic Analysis (`validate-dynamic-analysis`)\n\n```yaml\ncriteria:\n  - Miri finds no undefined behavior\n  - coverage targets met (typically 70-80%)\n  - fuzzing clean (no crashes)\n```\n\n### Gate 8: Review (`validate-review`)\n\n```yaml\ncriteria:\n  - independent review conducted\n  - review documentation exists\n  - no critical findings open\n```\n\n### Gate 9: Safety Case (`validate-safety-case`)\n\n```yaml\ncriteria:\n  - all previous gates passed\n  - traceability matrix complete\n  - evidence chain documented\n  - release decision recorded\n```\n\n## Failure Analysis\n\nWhen a gate fails, analyze root cause:\n\n| Gate | Symptom | Root Cause | Route To |\n|------|---------|------------|----------|\n| 5 | clippy::unwrap_used | Implementation issue | Layer 4 |\n| 5 | cargo-audit vuln | Dependency issue | Layer 5 |\n| 7 | Miri UB | Unsafe implementation | Layer 4 |\n| 7 | Low coverage | Missing tests | Layer 3 |\n| 7 | Timing violation | Slow implementation | Layer 4 |\n\n## Recording Results\n\nGate results are tracked in `/tmp/swiss_cheese_<hash>.json` by the orchestrator.\n\nThe traceability report is generated to `.claude/traceability_matrix.json`:\n\n```json\n{\n  \"requirements\": [\n    {\n      \"id\": \"REQ-001\",\n      \"title\": \"Requirement title\",\n      \"tests\": [\"test_req_001_case1\", \"test_req_001_case2\"],\n      \"covered\": true\n    }\n  ],\n  \"coverage\": {\n    \"REQ-001\": \"verified\"\n  }\n}\n```\n\n## Integration with Orchestrator\n\nThe orchestrator runs gates automatically on Stop events:\n\n```\nStop Event ‚Üí orchestrate.py ‚Üí make validate-<layer> ‚Üí\n  Pass (exit 0) ‚Üí Advance to next layer\n  Fail (exit 1) ‚Üí Block and prompt to fix\n```\n",
        "swiss-cheese/skills/swiss-cheese-guide.md": "---\ndescription: Use this skill when the user asks about \"Swiss Cheese Model\", \"verified Rust\", \"verification layers\", \"how to use swiss-cheese plugin\", \"rust verification workflow\", \"9-layer verification\", \"Makefile gates\", or needs guidance on using the Swiss Cheese verification plugin.\n---\n\n# Swiss Cheese Model - Verified Development Guide\n\nThe Swiss Cheese Model plugin implements a 9-layer verification approach for verified development, inspired by NASA's Swiss Cheese Model for accident prevention.\n\n## Core Concept\n\nLike layers of Swiss cheese, each verification layer catches defects that slip through previous layers. No single layer is perfect, but together they provide defense in depth.\n\n## Architecture\n\nThe orchestrator runs on **Stop events only** and:\n1. Validates the TOML design document against a schema\n2. Tracks task/gate status in `/tmp` (invisible to agent)\n3. Runs **Makefile targets** for gate validation\n4. Generates **traceability matrix** from test results\n5. Blocks and continues until all gates pass\n\n## The 9 Verification Layers\n\n| Layer | Name | Makefile Target | Purpose |\n|-------|------|-----------------|---------|\n| 1 | Requirements | `validate-requirements` | Formalize testable requirements |\n| 2 | Architecture | `validate-architecture` | Design type-safe architecture |\n| 3 | TDD | `validate-tdd` | Write tests BEFORE implementation |\n| 4 | Implementation | `validate-implementation` | Code to pass tests |\n| 5 | Static Analysis | `validate-static-analysis` | Clippy, audit, deny |\n| 6 | Formal Verification | `validate-formal-verification` | Kani proofs (optional) |\n| 7 | Dynamic Analysis | `validate-dynamic-analysis` | Miri, coverage |\n| 8 | Review | `validate-review` | Independent code review |\n| 9 | Safety Case | `validate-safety-case` | Assemble evidence |\n\n## Quick Start\n\n1. Create `design.toml` with requirements and tasks\n2. Create `Makefile` with gate validation targets\n3. Run `/swiss-cheese` to start\n4. Work on tasks - orchestrator guides you through layers\n5. Gates validate automatically on Stop events\n\n## Design Document Format (TOML)\n\n```toml\n[project]\nname = \"my-project\"\nversion = \"0.1.0\"\nmax_iterations = 5\n\n[[requirements]]\nid = \"REQ-001\"\ntitle = \"Safe Input Parsing\"\ndescription = \"System must safely parse untrusted input\"\npriority = \"critical\"\nacceptance_criteria = [\n    \"No panics on malformed input\",\n    \"All errors are recoverable\",\n]\n\n[tasks.implement_parser]\nlayer = \"implementation\"\ndescription = \"Implement safe parser\"\ndepends_on = [\"write_parser_tests\"]\nrequirements = [\"REQ-001\"]\n\n[gates.implementation]\ntarget = \"validate-implementation\"\n```\n\n## Makefile Requirements\n\n```makefile\nvalidate-requirements:\n\t@test -f design.toml\n\t@python3 -c \"import tomllib; tomllib.load(open('design.toml', 'rb'))\"\n\nvalidate-implementation:\n\tcargo build --all-targets\n\tcargo test --all-features\n\nvalidate-static-analysis:\n\tcargo clippy --all-targets -- -D warnings\n\tcargo audit || true\n```\n\n## Commands\n\n| Command | Purpose |\n|---------|---------|\n| `/swiss-cheese` | Start verification session |\n| `/swiss-cheese:status` | Show current status |\n| `/swiss-cheese:gate <name>` | Run specific gate |\n| `/swiss-cheese:loop` | Continue orchestration |\n| `/swiss-cheese:skip-layer <reason>` | Skip optional layer |\n| `/swiss-cheese:cancel` | Cancel orchestration |\n\n## Traceability\n\nName tests to match requirements for automatic linking:\n- `REQ-001` ‚Üí `test_req_001_*`\n\nThe orchestrator generates `.claude/traceability_matrix.json`:\n\n```json\n{\n  \"requirements\": [\n    {\"id\": \"REQ-001\", \"tests\": [\"test_req_001_valid\"], \"covered\": true}\n  ],\n  \"coverage\": {\"REQ-001\": \"verified\"}\n}\n```\n\n## How Orchestration Works\n\n```\nUser works on tasks\n        ‚Üì\nUser tries to stop\n        ‚Üì\norchestrate.py runs (Stop hook)\n        ‚Üì\nValidates design.toml against schema\n        ‚Üì\nChecks current layer status\n        ‚Üì\nRuns: make validate-<layer>\n        ‚Üì\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n    ‚îÇ Gate passed?      ‚îÇ\n    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n      ‚îÇ Yes         ‚îÇ No\n      ‚Üì             ‚Üì\n   Advance       Block and\n   to next       prompt to\n   layer         fix issues\n      ‚îÇ             ‚îÇ\n      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n              ‚Üì\n        Continue loop\n              ‚Üì\n    All layers passed?\n      ‚îÇ Yes         ‚îÇ No\n      ‚Üì             ‚Üì\n   Complete      Continue\n   (approve)     working\n```\n\n## Best Practices\n\n1. **Don't skip layers** unless absolutely necessary\n2. **Document skip decisions** with clear justification\n3. **Name tests** to match requirement IDs for traceability\n4. **Use the schema** - design.toml is validated automatically\n5. **Check gate output** when failures occur\n6. **Create comprehensive Makefile** with all gate targets\n\n## Files\n\n| File | Purpose |\n|------|---------|\n| `design.toml` | Requirements, tasks, gates |\n| `Makefile` | Gate validation targets |\n| `/tmp/swiss_cheese_*.json` | Orchestrator status (internal) |\n| `.claude/traceability_matrix.json` | Final traceability report |\n",
        "swiss-cheese/skills/swiss-cheese-patterns.md": "---\ndescription: Use this skill when the user needs guidance on safe Rust patterns, newtype wrappers, type-state machines, error handling, no-panic code, Kani harnesses, or Clippy configuration for production-grade development.\n---\n\n# Safe Rust Patterns Skill\n\nThis skill provides patterns for writing production-grade Rust code that passes all verification layers.\n\n## Core Principles\n\n1. **Make illegal states unrepresentable**\n2. **Make illegal operations uncompilable**\n3. **Fail at compile time, not runtime**\n4. **No panics in production code**\n5. **Explicit is better than implicit**\n\n## Pattern 1: Newtype Wrappers\n\nPrevent type confusion with newtypes:\n\n```rust\n/// Speed in RPM - always valid\n#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]\npub struct Rpm(u16);\n\nimpl Rpm {\n    pub const ZERO: Self = Self(0);\n    pub const MAX: Self = Self(5000);\n\n    /// Fallible construction\n    pub const fn new(value: u16) -> Option<Self> {\n        if value <= 5000 { Some(Self(value)) } else { None }\n    }\n\n    /// Infallible construction (saturates)\n    pub const fn saturating_new(value: u16) -> Self {\n        if value <= 5000 { Self(value) } else { Self::MAX }\n    }\n\n    /// Safe accessor\n    pub const fn get(self) -> u16 { self.0 }\n\n    /// Checked arithmetic\n    pub const fn checked_add(self, rhs: Self) -> Option<Self> {\n        match self.0.checked_add(rhs.0) {\n            Some(v) if v <= 5000 => Some(Self(v)),\n            _ => None,\n        }\n    }\n}\n```\n\n## Pattern 2: Type-State Machines\n\nCompile-time state transition enforcement:\n\n```rust\nuse core::marker::PhantomData;\n\n// State markers (zero-sized types)\npub struct Idle;\npub struct Running;\npub struct Fault;\n\npub struct Motor<State> {\n    pwm: PwmChannel,\n    _state: PhantomData<State>,\n}\n\n// Only valid transitions compile\nimpl Motor<Idle> {\n    pub fn start(self) -> Motor<Running> {\n        Motor { pwm: self.pwm, _state: PhantomData }\n    }\n}\n\nimpl Motor<Running> {\n    pub fn stop(self) -> Motor<Idle> {\n        Motor { pwm: self.pwm, _state: PhantomData }\n    }\n\n    pub fn fault(self) -> Motor<Fault> {\n        Motor { pwm: self.pwm, _state: PhantomData }\n    }\n}\n\n// COMPILE ERROR: motor.start().start() - can't start Running\n```\n\n## Pattern 3: Error Types with Context\n\nRich error types for debugging:\n\n```rust\n#[derive(Debug)]\npub enum MotorError {\n    SpeedExceedsLimit { commanded: Rpm, limit: Rpm },\n    Timeout { elapsed_ms: u32, threshold_ms: u32 },\n    HardwareFault(FaultCode),\n}\n\nimpl MotorError {\n    pub const fn is_critical(&self) -> bool {\n        matches!(self, Self::HardwareFault(_))\n    }\n}\n```\n\n## Pattern 4: Bounded Collections\n\nNo heap allocation:\n\n```rust\nuse heapless::Vec;\n\npub struct EventLog {\n    events: Vec<Event, 64>,  // Max 64 events, stack allocated\n}\n\nimpl EventLog {\n    pub fn push(&mut self, event: Event) -> Result<(), BufferFull> {\n        self.events.push(event).map_err(|_| BufferFull)\n    }\n}\n```\n\n## Pattern 5: No Panic Arithmetic\n\n```rust\n// BAD\nfn bad_add(a: u32, b: u32) -> u32 {\n    a + b  // Panics on overflow in debug\n}\n\n// GOOD\nfn checked_add(a: u32, b: u32) -> Option<u32> {\n    a.checked_add(b)\n}\n\nfn saturating_add(a: u32, b: u32) -> u32 {\n    a.saturating_add(b)\n}\n```\n\n## Pattern 6: No Index Panics\n\n```rust\n// BAD\nfn bad_get(slice: &[u8], i: usize) -> u8 {\n    slice[i]  // Panics if out of bounds\n}\n\n// GOOD\nfn safe_get(slice: &[u8], i: usize) -> Option<u8> {\n    slice.get(i).copied()\n}\n```\n\n## Pattern 7: Result Everywhere\n\n```rust\n// BAD\nfn bad_parse(s: &str) -> u32 {\n    s.parse().unwrap()  // Panics\n}\n\n// GOOD\nfn safe_parse(s: &str) -> Result<u32, ParseError> {\n    s.parse().map_err(|_| ParseError)\n}\n```\n\n## Pattern 8: Minimal Unsafe\n\n```rust\n/// SAFETY: Document all invariants\n///\n/// # Safety\n/// - `addr` must be valid peripheral base address\n/// - Must be called only once per peripheral\npub unsafe fn init_peripheral(addr: usize) -> Peripheral {\n    // SAFETY: Caller guarantees addr validity\n    let regs = &*(addr as *const Registers);\n    Peripheral { regs }\n}\n\n// Wrap in safe API\npub fn get_peripheral() -> Peripheral {\n    static INIT: Once<Peripheral> = Once::new();\n    *INIT.call_once(|| {\n        // SAFETY: PERIPHERAL_ADDR is linker-provided, only called once\n        unsafe { init_peripheral(PERIPHERAL_ADDR) }\n    })\n}\n```\n\n## Pattern 9: Kani Harnesses\n\n```rust\n#[cfg(kani)]\nmod verification {\n    use super::*;\n\n    #[kani::proof]\n    fn verify_rpm_bounded() {\n        let v: u16 = kani::any();\n        let rpm = Rpm::saturating_new(v);\n        assert!(rpm.get() <= 5000);\n    }\n\n    #[kani::proof]\n    #[kani::unwind(5)]\n    fn verify_no_overflow() {\n        let a: u16 = kani::any();\n        let b: u16 = kani::any();\n        kani::assume(a <= 5000 && b <= 5000);\n\n        if let Some(rpm_a) = Rpm::new(a) {\n            if let Some(rpm_b) = Rpm::new(b) {\n                // This should never panic\n                let _ = rpm_a.checked_add(rpm_b);\n            }\n        }\n    }\n}\n```\n\n## Pattern 10: Clippy Configuration\n\n```toml\n# Cargo.toml\n[lints.clippy]\nunwrap_used = \"deny\"\nexpect_used = \"deny\"\npanic = \"deny\"\ntodo = \"deny\"\nunimplemented = \"deny\"\nindexing_slicing = \"deny\"\npedantic = { level = \"warn\", priority = -1 }\n```\n\n## Crate Attributes\n\n```rust\n// lib.rs\n#![no_std]\n#![deny(unsafe_code)]  // Opt-in to unsafe\n#![deny(clippy::unwrap_used)]\n#![deny(clippy::panic)]\n#![warn(clippy::pedantic)]\n#![warn(missing_docs)]\n```\n\n## Testing Patterns\n\n```rust\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use proptest::prelude::*;\n\n    proptest! {\n        #[test]\n        fn rpm_always_valid(v in 0u16..=10000) {\n            let rpm = Rpm::saturating_new(v);\n            prop_assert!(rpm.get() <= 5000);\n        }\n    }\n}\n```\n\n## Dependency Selection\n\nPrefer these safety-oriented crates:\n\n| Need | Crate | Why |\n|------|-------|-----|\n| Collections | `heapless` | No heap, bounded |\n| HAL | `embedded-hal` | Standard traits |\n| Errors | `defmt` | Efficient logging |\n| Sync | `critical-section` | Platform-agnostic |\n| Time | `fugit` | Compile-time units |\n"
      },
      "plugins": [
        {
          "name": "swiss-cheese",
          "description": "Agentic Rust development using the NASA Swiss Cheese Model. Full lifecycle from requirements validation through CI verification with 9 independent verification layers.",
          "version": "1.0.0",
          "author": {
            "name": "Swiss Cheese Project",
            "email": "jvishnefske@gmail.com"
          },
          "source": "./swiss-cheese",
          "category": "development",
          "categories": [
            "development"
          ],
          "install_commands": [
            "/plugin marketplace add jvishnefske/swiss-cheese",
            "/plugin install swiss-cheese@jvishnefske-agent-plugins"
          ]
        },
        {
          "name": "ultraplan",
          "description": "Maximum parallelism orchestration - spawns ALL independent tasks in a single message. Tool-native JSON outputs for certification.",
          "version": "2.0.0",
          "author": {
            "name": "jvishnefske",
            "email": "jvishnefske@gmail.com"
          },
          "source": "./ultraplan",
          "category": "development",
          "categories": [
            "development"
          ],
          "install_commands": [
            "/plugin marketplace add jvishnefske/swiss-cheese",
            "/plugin install ultraplan@jvishnefske-agent-plugins"
          ]
        }
      ]
    }
  ]
}