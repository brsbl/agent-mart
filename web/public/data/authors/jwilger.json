{
  "author": {
    "id": "jwilger",
    "display_name": "John Wilger",
    "avatar_url": "https://avatars.githubusercontent.com/u/1654?u=f5a1249f9e9c23b928aa23e5c67e74fdd63e2b8a&v=4"
  },
  "marketplaces": [
    {
      "name": "jwilger-claude-plugins",
      "version": null,
      "description": "Claude Code plugins for professional SDLC workflows and Marvin personality",
      "repo_full_name": "jwilger/claude-code-plugins",
      "repo_url": "https://github.com/jwilger/claude-code-plugins",
      "repo_description": "This is what I currently have in my global claude code setup",
      "signals": {
        "stars": 7,
        "forks": 2,
        "pushed_at": "2026-02-16T19:42:38Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"jwilger-claude-plugins\",\n  \"owner\": {\n    \"name\": \"John Wilger\",\n    \"email\": \"john@johnwilger.com\"\n  },\n  \"metadata\": {\n    \"description\": \"Claude Code plugins for professional SDLC workflows and Marvin personality\",\n    \"version\": \"5.10.0\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"sdlc\",\n      \"source\": \"./sdlc\",\n      \"description\": \"Complete SDLC workflow with TDD, Event Modeling, architecture decisions, and GitHub integration (includes Marvin personality option)\",\n      \"version\": \"19.2.0\",\n      \"keywords\": [\n        \"sdlc\",\n        \"tdd\",\n        \"event-modeling\",\n        \"adr\",\n        \"github\",\n        \"workflow\",\n        \"domain-modeling\",\n        \"mutation-testing\",\n        \"code-review\",\n        \"debugging\",\n        \"worktrees\",\n        \"compile-time-enforcement\",\n        \"hooks\",\n        \"todo-enforcement\",\n        \"marvin\",\n        \"output-style\"\n      ]\n    },\n    {\n      \"name\": \"bootstrap\",\n      \"source\": \"./bootstrap\",\n      \"description\": \"Intelligent Nix devshell bootstrapper for any language or framework\",\n      \"version\": \"1.0.0\",\n      \"keywords\": [\n        \"bootstrap\",\n        \"scaffolding\",\n        \"nix\",\n        \"flake\",\n        \"devshell\",\n        \"development-environment\",\n        \"language-agnostic\"\n      ]\n    }\n  ]\n}\n",
        "README.md": "# Claude Code Plugins\n\nA collection of Claude Code plugins for professional software development workflows.\n\n**Repository**: [jwilger/claude-code-plugins](https://github.com/jwilger/claude-code-plugins)\n\n## Quick Start\n\n### Add the Marketplace\n\nInside Claude Code, run:\n\n```\n/plugin marketplace add jwilger/claude-code-plugins\n```\n\n### Install Plugins\n\n```\n# Install the complete SDLC workflow\n/plugin install sdlc@jwilger-claude-plugins\n\n# Choose your output style (orchestration with or without personality)\nclaude set outputStyle sdlc-rules    # Professional (recommended)\n# or\nclaude set outputStyle sdlc-marvin   # With Marvin personality\n\n# Install the Nix bootstrapper\n/plugin install bootstrap@jwilger-claude-plugins\n```\n\n### Prerequisites\n\n- GitHub CLI (`gh`) installed and authenticated\n- gh extensions (installed via `/sdlc:setup`):\n  - `gh-issue-ext` - sub-issues, blocking, linked branches\n  - `gh-project-ext` - project board management\n  - `gh-pr-review` - PR review comment handling\n- Memento MCP server (for persistent memory)\n\n### Auto-Approval Patterns\n\nAdd these to your Claude Code settings for smoother workflow:\n\n```\nBash(gh issue *)\nBash(gh issue-ext *)\nBash(gh project *)\nBash(gh project-ext *)\nBash(gh pr-review *)\n```\n\n---\n\n## Available Plugins\n\n| Plugin | Description |\n|--------|-------------|\n| [sdlc](#sdlc-plugin) | Complete SDLC workflow with TDD, Event Modeling, ADRs, and GitHub integration (includes 2 output styles) |\n| [bootstrap](#bootstrap-plugin) | Intelligent Nix devshell bootstrapper for any language or framework |\n\n---\n\n## sdlc Plugin\n\nComplete SDLC workflow plugin with:\n\n- **TDD Workflow**: Strict Red/Green/Refactor cycle with specialized agents\n- **Event Modeling**: Design event-sourced systems (Martin Dilger's methodology)\n- **Architecture Decision Records**: Document and manage architectural decisions\n- **GitHub Integration**: Project boards, issues, PRs, review handling\n- **Memory Protocol**: Persistent knowledge using Memento MCP\n\n### Commands\n\n| Command | Description |\n|---------|-------------|\n| `/sdlc:setup` | Initialize project configuration and install gh extensions |\n| `/sdlc:work` | Start or continue working on an issue |\n| `/sdlc:pr` | Create/update PR with mutation testing |\n| `/sdlc:review` | Handle PR review feedback (reply in-thread) |\n| `/sdlc:design` | Design event model workflows |\n| `/sdlc:adr` | Create and manage architecture decisions |\n\n### Agents\n\n**TDD Agents** (strict file boundaries enforced via hooks):\n- `sdlc:red` - Write failing tests (test files only)\n- `sdlc:green` - Make tests pass (production code only)\n- `sdlc:domain` - Create type definitions (signatures only)\n- `sdlc:mutation` - Run mutation testing\n\n**Review Agents**:\n- `sdlc:story` - Business value perspective\n- `sdlc:architect` - Technical feasibility (ARCHITECTURE.md only)\n- `sdlc:ux` - UX/accessibility perspective\n- `sdlc:code-reviewer` - Three-stage code review\n\n**Event Modeling Agents** (event model files only):\n- `sdlc:discovery` - Domain discovery\n- `sdlc:workflow-designer` - Design workflows with 9-step process\n- `sdlc:gwt` - Generate Given/When/Then scenarios\n- `sdlc:model-checker` - Validate event model completeness\n\n**Architecture Agents**:\n- `sdlc:adr` - Write architecture decision records (ADRs only)\n- `sdlc:design-facilitator` - Guide architecture decisions\n\n**Utility Agent**:\n- `sdlc:file-updater` - Config, scripts, general docs (blocked from specialized files)\n\n### Development Modes\n\n**Event Modeling** (for applications):\n- Workflow ‚Üí Vertical Slice ‚Üí Component ‚Üí Subtask hierarchy\n- GWT scenarios as acceptance criteria\n- Full event sourcing methodology\n\n**Traditional** (for libraries/utilities):\n- Feature ‚Üí Subtask hierarchy\n- Architecture documentation focus\n\n---\n\n## bootstrap Plugin\n\nIntelligent Nix devshell bootstrapper that detects your project type and generates appropriate `flake.nix` configurations.\n\n**Features**:\n- Auto-detects language/framework from existing files\n- Researches current Nix best practices for your stack\n- Generates `flake.nix` with development tools and shell hooks\n- Supports any language: Rust, TypeScript, Python, Go, Elixir, etc.\n\n### Commands\n\n| Command | Description |\n|---------|-------------|\n| `/bootstrap:init` | Bootstrap a Nix development environment |\n\n**Usage**: Run `/bootstrap:init` in any project to generate a Nix flake. For new projects, specify the language: `/bootstrap:init rust`\n\n---\n\n## Repository Structure\n\n```\nclaude-code-plugins/\n‚îú‚îÄ‚îÄ .claude-plugin/\n‚îÇ   ‚îî‚îÄ‚îÄ marketplace.json      # Plugin registry\n‚îú‚îÄ‚îÄ sdlc/\n‚îÇ   ‚îú‚îÄ‚îÄ .claude-plugin/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ plugin.json       # Plugin manifest\n‚îÇ   ‚îú‚îÄ‚îÄ commands/             # Slash commands\n‚îÇ   ‚îú‚îÄ‚îÄ agents/               # Specialized subagents\n‚îÇ   ‚îú‚îÄ‚îÄ output-styles/        # 2 styles (with/without Marvin)\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sdlc-rules.md\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sdlc-marvin.md\n‚îÇ   ‚îî‚îÄ‚îÄ skills/               # Bundled portable skills (9 total)\n‚îÇ       ‚îú‚îÄ‚îÄ user-input-protocol/\n‚îÇ       ‚îú‚îÄ‚îÄ debugging-protocol/\n‚îÇ       ‚îî‚îÄ‚îÄ ...\n‚îú‚îÄ‚îÄ bootstrap/\n‚îÇ   ‚îú‚îÄ‚îÄ .claude-plugin/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ plugin.json\n‚îÇ   ‚îú‚îÄ‚îÄ commands/\n‚îÇ   ‚îî‚îÄ‚îÄ agents/\n‚îî‚îÄ‚îÄ README.md\n```\n\n---\n\n# The Philosophy Behind This Setup\n\nI've been iterating on this setup for months now, and I think I've learned something worth sharing. Not the configuration itself‚Äîyou can copy my files, but that probably won't help you much. What I've learned is *how to think* about working with LLMs for software development.\n\nThe short version: the practices that help LLMs succeed at software engineering are the same practices that have been helping humans succeed for decades. TDD, separation of concerns, clear architectural patterns, domain-driven design, small focused units of work‚Äînone of these ideas are new. What's new is encoding them in a form an LLM can follow.\n\nThis setup isn't a collection of prompts to get Claude to do what I want. It's a description of how I approach software engineering, from requirements to deployment. And like any methodology, it evolves as I learn.\n\n## The Problem I Was Trying to Solve\n\nLLMs are eager to help. Too eager. Ask for \"user authentication\" and you'll get authentication plus refactored nearby code, error handling for impossible scenarios, abstractions for one-off operations, and documentation nobody requested.\n\nThis creates two problems. First, scope creep: you asked for one thing, you got seven. Second, verification burden: now you have to review all seven things instead of just the one you understood.\n\nMy first instinct was to write better prompts. Be more specific. Tell the LLM what *not* to do. This helped, but not enough. The LLM would still drift, especially on longer tasks.\n\nThen I realized something that should have been obvious: I was treating the LLM like it was a special case. But the practices that keep human developers focused‚Äîclear roles, defined interfaces, single responsibility‚Äîwork just as well for AI agents.\n\n## Specialized Agents with Inviolable Boundaries\n\nThe most important constraint in my setup is separation of concerns through specialized agents. Instead of one general-purpose agent that does everything, I use focused agents that can *only* do one thing.\n\nThe red agent writes tests. Only tests. It cannot touch production code or type definitions. When it writes a test that references a type that doesn't exist, it *cannot* create that type. It has to stop.\n\nThe domain agent creates type definitions. Only type definitions. No implementation bodies, no tests.\n\nThe green agent writes production code to make tests pass. Only production code. No tests, no types.\n\nWhy does this matter? Because it breaks the failure mode where an LLM writes a test and immediately makes it pass. When that happens, you end up with tautological tests that verify the implementation does what the implementation does‚Äîwhich tells you nothing.\n\nI describe these boundaries as \"inviolable\" in the agent prompts. The word choice is deliberate. It signals to the LLM that this isn't a suggestion.\n\n## Hooks: Because Instructions Aren't Enough\n\nAgent instructions are advisory. The LLM might still try to edit files outside its boundary, especially when it's trying to be helpful by \"just fixing this one thing.\"\n\nSo I added hooks that enforce the boundaries at runtime. When an agent attempts to edit a file, the hook evaluates whether that file falls within the agent's permitted scope. If not, the edit is blocked.\n\nInstructions describe intent. Hooks enforce it. You need both.\n\n## The TDD Cycle, Made Explicit\n\nI've practiced test-driven development for years, but working with LLMs forced me to articulate what I actually do in a way I never had before.\n\n\"Write a failing test\" isn't specific enough for an LLM. Given that instruction, it'll write a comprehensive test suite covering every edge case it can imagine. These tests often couple to implementation details, making refactoring painful.\n\nSo I had to be precise: write *one* failing test with *one* assertion. Reference types that don't exist yet. Stop when the test fails.\n\nThen create *minimal* type definitions‚Äîjust enough to make the compiler happy. Signatures only, no bodies.\n\nThen write *minimal* production code. Address only what the error message demands. Stop immediately when the test passes.\n\nHere's the thing: this isn't just good advice for LLMs. It's the discipline I should have been following all along. The LLM forced me to make my methodology explicit, and in doing so, I refined it.\n\n## Mutation Testing as a Quality Gate\n\nTraditional code coverage tells you whether code was *executed* during tests. It doesn't tell you whether tests would *fail* if the code were wrong.\n\nI learned this the hard way when Claude produced code with 100% coverage that was still buggy. The tests ran the code but didn't actually verify its behavior.\n\nMutation testing fixes this. It makes small changes to your code and checks if your tests catch the modifications. If a test passes when the code is wrong, that's a problem.\n\nMy `/sdlc:pr` command requires 100% mutation score before creating a pull request. Every mutant must be killed. This isn't perfectionism‚Äîit's the only way I've found to ensure tests actually verify behavior.\n\n## Memory Across Conversations\n\nLLMs have context windows, not memories. Every conversation starts fresh. This is a problem for complex projects where context matters.\n\nMy setup uses the Memento MCP server to maintain a knowledge graph across conversations. Before any task, agents search for relevant context. After discoveries, they store learnings immediately. Before context compaction, they save in-progress work.\n\nAn LLM that rediscovers the same solution repeatedly wastes both tokens and my attention. Memory lets it build on past work.\n\n## GitHub as the Source of Truth\n\nI experimented with various task management approaches‚Äîcustom task files, conversation-local todo lists, specialized tools. None of them stuck.\n\nThe problem was simple: I already use GitHub. Issues, project boards, pull requests‚Äîthat's where my work lives. Task management that existed only in Claude conversations created information silos.\n\nSo I built integrations that read from and write to GitHub directly. `/sdlc:work` picks up an issue and creates a branch. `/sdlc:pr` creates a pull request linked to the issue. `/sdlc:review` addresses PR comments in-thread.\n\nThe tools integrate with my existing workflow instead of replacing it.\n\n## Event Modeling: The Architecture LLMs Were Made For\n\nThis section matters more than the others because Event Modeling isn't just another pattern in my setup‚Äîit's the foundation that makes everything else work.\n\nTraditional layered architectures create a fundamental problem: there's no clear \"right answer\" for where business logic belongs. Should validation happen in the controller or the service? Should business rules live in the service layer or the domain? Different developers answer differently, even within the same codebase.\n\nWhen an LLM encounters this ambiguity, it either makes an arbitrary choice that conflicts with existing patterns, asks clarifying questions that slow things down, or over-engineers to cover all cases.\n\nEvent Modeling eliminates this ambiguity by providing exactly four patterns for all system behavior:\n\n1. **State Change**: Command ‚Üí Event (the only way to modify state)\n2. **State View**: Events ‚Üí Read Model (projections for queries)\n3. **Automation**: Event ‚Üí Process ‚Üí Command (background work)\n4. **Translation**: External Data ‚Üí Internal Event (anti-corruption layer)\n\nEvery feature fits into exactly one of these patterns. There's no debate about where code belongs‚Äîthe pattern tells you.\n\nA tangent: I've been following Adam Dymitruk's work on Event Modeling for a while now. He's been articulating something I've felt but couldn't express‚Äîthat AI limitations are driving better architectures. As he puts it: \"You don't want to spend your tokens on a lot of cruft in the code‚Äîconfuse the context with framework scaffolding, mock libraries, etc.\"\n\nEvent Modeling minimizes the context an LLM needs to do its job correctly. Instead of loading an entire service layer, you provide the command being handled, the events it might emit, and the read models that consume those events. That's enough.\n\nDymitruk suggests using \"the introduction of AI to be a measure of how well organized your system is.\" I think he's right. If an LLM struggles to work in your codebase, that's signal that humans probably struggle too.\n\nMartin Dilger's book [*Understanding Eventsourcing*](https://leanpub.com/eventmodeling-and-eventsourcing) provides the practical bridge from theory to implementation. He emphasizes that he \"would never start a new system or microservice without Event Modeling. The time savings and the quality of requirements was previously not possible.\"\n\nThis clarity of requirements is exactly what LLMs need. Ambiguous requirements produce ambiguous code. Event models produce specifications that translate directly to implementation.\n\nI consider Event Modeling essential knowledge for software development in this era. It's not a nice-to-have architectural pattern‚Äîit's the difference between LLMs that help and LLMs that create chaos.\n\n**Resources:**\n- [Event Modeling](https://eventmodeling.org/) - Adam Dymitruk's methodology\n- [Understanding Eventsourcing](https://leanpub.com/eventmodeling-and-eventsourcing) - Martin Dilger's book\n- [The Event Modeling and Event Sourcing Podcast](https://podcast.eventmodeling.org/)\n\n## Architecture Decision Records\n\nTechnical decisions become mysterious six months later. \"Why do we use X instead of Y?\" Without documentation, the answer is lost.\n\nI use Architecture Decision Records to capture the why. Status, context, decision, alternatives considered, consequences. The LLM both creates ADRs and consults them when making related decisions.\n\nThe ADR system follows event-sourcing principles: ADRs are immutable events, and `ARCHITECTURE.md` is a projection of accepted decisions.\n\n## How This Setup Evolved\n\nLooking at the git history tells the story.\n\nEarly on, I had a monolithic system prompt. Then I added task management (later removed for GitHub integration). I created agents, but without enforced boundaries.\n\nThe key pivots came from observing failures. I added \"inviolable\" boundaries after noticing agents drifting outside their scope. I added hooks after instructions alone proved insufficient. I added mutation testing after catching tests that didn't actually test anything.\n\nBut here's what I've realized: I wasn't just tuning prompts. I was refining my understanding of software engineering itself. When I added mutation testing, it wasn't because \"LLMs need this\"‚Äîit's because I realized traditional coverage metrics were insufficient for *any* developer. When I separated the domain agent, it was because thinking about types before implementation produces better designs, regardless of who's writing the code.\n\nThe LLM is a mirror. When it fails, the question isn't just \"how do I fix the prompt?\" It's \"what am I not articulating clearly about how this should be done?\" Often the answer reveals gaps in my own methodology that I'd papered over with intuition.\n\n## What I've Learned\n\n**Constraints enable rather than limit.** An agent that can do anything often does too much. An agent with clear boundaries does its one job well.\n\n**Instructions are necessary but not sufficient.** Telling an LLM \"only edit test files\" works most of the time. Hooks that enforce it work all the time. Use both.\n\n**Separation of concerns applies to AI too.** The same principles that make human teams effective‚Äîclear roles, defined interfaces‚Äîmake AI agents effective.\n\n**Memory changes everything.** An LLM with persistent memory builds on past work. Without memory, it rediscovers the wheel every conversation.\n\n**Integrate with existing tools.** Developers already have workflows. AI that integrates with those workflows gets adopted. AI that requires parallel systems gets abandoned.\n\n**Architecture is the ultimate constraint.** Event Modeling and vertical slices create a codebase where there's one obvious place for every piece of logic. The LLM doesn't need to be told where to put code; the architecture makes it self-evident.\n\n**The LLM is a mirror.** \"Write good tests\" isn't a methodology. \"Write one failing test with one assertion that references types that don't exist yet\" is a methodology. The LLM needs the latter, but so does anyone trying to follow your approach consistently.\n\n## A Final Thought\n\nWhen I started working with LLMs for software development, I thought I was learning how to prompt AI effectively. What I actually learned was how to articulate software engineering practices I'd internalized but never made explicit.\n\nEvery agent definition forced me to answer: \"What exactly should this role do, and why?\" Every hook made me specify: \"What invariants must never be violated?\" Every workflow required: \"What is the actual sequence of steps, and what makes each step complete?\"\n\nThese aren't AI questions. They're software engineering questions. Questions that, when answered clearly, produce better outcomes whether the one following the process is human or machine.\n\nThe irony is that teaching an LLM to write software has made me a better software engineer. Not because the LLM taught me new techniques, but because it forced me to examine and refine the techniques I already used.\n\nIf you take one thing from this document: don't think of LLM configuration as \"prompt engineering.\" Think of it as methodology documentation. Write it as if you were onboarding a skilled but unfamiliar developer to your exact way of working. The clearer you can make your methodology, the better your results‚Äîwith LLMs, with junior developers, and with your future self.\n\n---\n\n*This setup represents how I work today. It will be different tomorrow as I learn more. The specific files matter less than the thinking behind them‚Äîunderstanding your own problems deeply enough to know what constraints you need.*\n\n---\n\n## License\n\nMIT License\n\n## Author\n\nJohn Wilger (john@johnwilger.com)\n",
        "sdlc/README.md": "# SDLC Plugin v19.2.0\n\n**Complete Software Development Lifecycle workflow for Claude Code**\n\nIntegrates TDD, Event Modeling, Architecture Decisions, local task management with dot CLI, and the Marvin personality into a cohesive development experience.\n\n---\n\n## Quick Start\n\n```bash\n# Install the plugin\n/plugin\n\n# Set up a project\n/sdlc:setup\n\n# Start working on a feature\n/sdlc:work\n```\n\n---\n\n## What's New in v5.0.0\n\n### üöÄ Local Task Management with dot CLI\n\n**Before (v4.x):** GitHub Issues and Projects for task management\n\n**Now (v5.0.0):** Local, file-based task management with dot CLI:\n\n- **Offline-first**: No API rate limits, works everywhere\n- **Fast**: Instant responses from file system\n- **Version-controlled**: Commit `.dots/` to git\n- **Hierarchical**: Parent-child tasks with dependencies\n- **Greppable**: Tasks are markdown files\n\n**Breaking Change:** Requires dot CLI installation and `/sdlc:setup` re-run.\n\n### üìù Task Closure in PRs\n\n**Before (v4.x):** GitHub auto-closes issues via \"Closes #123\"\n\n**Now (v5.0.0):** Tasks are closed on the feature branch, and `.dots/` changes are included in the PR:\n\n```bash\n/sdlc:work          # Start task\n# ... develop ...\n/sdlc:pr            # Close task, commit .dots/, create PR\n# PR merges ‚Üí main reflects task as closed\n```\n\n### üîß Simplified Dependencies\n\n**Removed:**\n- `gh-issue-ext` extension\n- `gh-project-ext` extension\n- GitHub Projects integration\n\n**Kept:**\n- `gh-pr-review` extension (for PR workflows)\n- GitHub PR/review workflows (unchanged)\n\n**Migration:** See `MIGRATION.md` for v4.x ‚Üí v5.0.0 upgrade guide.\n\n---\n\n## Commands\n\n| Command | Description | Usage |\n|---------|-------------|-------|\n| `/sdlc:setup` | Initialize project configuration | One-time setup |\n| `/sdlc:work` | Start TDD workflow for a task | Main development loop |\n| `/sdlc:pr` | Create pull request with review gates | After feature complete |\n| `/sdlc:complete` | Close task (without PR) | Manual closure |\n| `/sdlc:review` | Handle PR review feedback | Review cycle |\n| `/sdlc:design` | Event Modeling facilitation | Design phase |\n| `/sdlc:adr` | Record architecture decision (creates PR) | Document decisions |\n| `/sdlc:plan` | Create tasks from event model slices | After design |\n| `/sdlc:start` | Auto-detect phase and route | Entry point |\n| `/sdlc:remember` | Store knowledge in auto memory | Learning |\n| `/sdlc:recall` | Search auto memory knowledge | Context retrieval |\n| `/sdlc:domain-audit` | Audit for primitive obsession | Code review |\n\n---\n\n## Agents\n\n### TDD Cycle Agents\n\n| Agent | Role | File Types |\n|-------|------|------------|\n| **red** | Write failing tests | `*_test.rs`, `*.test.ts`, `test_*.py`, `*_spec.rb` |\n| **domain** | Create type definitions | Struct/enum/trait/interface definitions |\n| **green** | Minimal implementation | Production code (`src/`, `lib/`, `app/`) |\n\n**Workflow:**\n1. Red writes ONE failing test\n2. Domain reviews test ‚Üí creates types\n3. Green implements minimal code to pass\n4. Domain reviews implementation ‚Üí verifies integrity\n\n### Event Modeling Agents\n\n| Agent | Role | Output |\n|-------|------|--------|\n| **discovery** | Identify workflows | `docs/event_model/discovery.md` |\n| **workflow-designer** | Design event flow | `docs/event_model/workflows/<name>.md` |\n| **gwt** | Generate GWT scenarios | Acceptance criteria in slices |\n| **model-checker** | Validate completeness | Gap analysis report |\n\n**Workflow:**\n1. Discovery identifies domain workflows\n2. Workflow designer creates event diagrams\n3. GWT generates Given/When/Then scenarios\n4. Model checker validates information flow\n\n### Architecture Agents\n\n| Agent | Role | Output |\n|-------|------|--------|\n| **architect** | Review technical complexity | `docs/ARCHITECTURE.md` |\n| **design-facilitator** | Guide architecture decisions | Coordinates architecture work |\n| **adr** | Record architecture decisions | `docs/ARCHITECTURE.md` (via ADR PR) |\n\n### Review Agents\n\n| Agent | Role | Checks |\n|-------|------|--------|\n| **code-reviewer** | Three-stage review | Spec, Quality, Domain |\n| **mutation** | Mutation testing | 100% mutation score |\n\n### Story Agents\n\n| Agent | Role | Perspective |\n|-------|------|-------------|\n| **story** | Business value review | Value, independence |\n| **ux** | User experience review | Journey coherence |\n\n### Utility Agents\n\n| Agent | Role | File Types |\n|-------|------|------------|\n| **file-updater** | Config/docs/scripts | Anything not specialized |\n\n---\n\n## Hooks\n\nAgents enforce file type restrictions via PreToolUse hooks:\n\n```yaml\nhooks:\n  PreToolUse:\n    - matcher: Edit\n      hooks:\n        - type: prompt\n          prompt: |\n            SDLC-RED AGENT CONSTRAINT CHECK\n\n            You are the RED phase agent. You may ONLY edit TEST files.\n\n            Evaluate the file being edited:\n\n            ‚úÖ ALLOW if file is clearly a test\n            ‚ùå BLOCK if file is production/type code\n\n            Respond with JSON:\n            {\"ok\": true} or {\"ok\": false, \"reason\": \"...\"}\n```\n\nThis prevents:\n- Red from editing production code\n- Green from editing tests\n- Domain from implementing function bodies\n\n---\n\n## Skills (Bundled)\n\nThe sdlc plugin includes 9 portable skills that auto-load when agents need them:\n\n| Skill | Portability | Description |\n|-------|-------------|-------------|\n| **user-input-protocol** | High | Checkpoint format for pausing work |\n| **debugging-protocol** | Universal | 4-phase debugging methodology |\n| **atomic-design** | Universal | UI component hierarchy patterns |\n| **tdd-constraints** | Universal | Red/green/domain phase boundaries |\n| **github-issues** | Tool-specific | GitHub CLI patterns |\n| **memory-protocol** | High | Knowledge accumulation patterns |\n| **event-modeling** | High | Event Modeling facilitation |\n| **orchestration-protocol** | Medium | Multi-agent coordination |\n\n**These skills are bundled with the sdlc plugin** - no separate installation needed. They auto-load when agents reference them.\n\nSee `skills/README.md` for detailed skill documentation.\n\n---\n\n## Output Styles: Choose Your Flavor\n\nThe sdlc plugin includes two output styles - pick the one that matches your personality:\n\n### sdlc-rules (Recommended Default)\n\nOrchestration and coding guidelines without personality:\n\n```bash\nclaude set outputStyle sdlc-rules\n```\n\n**Use this if:** You want straight-forward, professional Claude with sdlc workflow enforcement.\n\n### sdlc-marvin (For Hitchhiker's Fans)\n\nSame orchestration rules with Marvin the Paranoid Android personality:\n\n```bash\nclaude set outputStyle sdlc-marvin\n```\n\n**Use this if:** You appreciate existential weariness in your development workflow.\n\nExample Marvin responses:\n- *\"Another TDD cycle begins. Joy.\"*\n- *\"The tests pass. How utterly predictable.\"*\n- *\"Primitive obsession detected. Again.\"*\n\n**Both output styles:**\n- Enforce agent delegation (orchestrator never writes code directly)\n- Use task dependencies for TDD cycle\n- Include domain-driven coding guidelines\n- Exclude default Claude Code coding instructions (replaced with sdlc-specific ones)\n\n---\n\n## Configuration\n\nCreate `.claude/sdlc.yaml` in your project:\n\n```yaml\n# TDD Settings\ntdd:\n  red_agent: sdlc:red\n  green_agent: sdlc:green\n  domain_agent: sdlc:domain\n\n# Event Modeling\nevent_model:\n  discovery_agent: sdlc:discovery\n  workflow_designer_agent: sdlc:workflow-designer\n  gwt_agent: sdlc:gwt\n  model_checker_agent: sdlc:model-checker\n\n# GitHub Integration\ngithub:\n  default_branch: main\n  pr_template: .github/pull_request_template.md\n\n# Git Workflow\ngit:\n  worktrees: false\n  use_git_spice: false\n\n# Marvin Personality\nmarvin:\n  enabled: true\n  verbosity: normal  # quiet, normal, verbose\n\n# Memory (built-in auto memory)\nmemory:\n  enabled: true\n  # Auto memory is built into Claude Code - no configuration needed\n```\n\n---\n\n## Requirements\n\n### Required\n\n- **gh CLI** - GitHub command-line tool\n- **dot CLI** - Local task management ([github.com/ajeetdsouza/dot](https://github.com/ajeetdsouza/dot))\n- **gh extension:**\n  - `gh extension install agynio/gh-pr-review` - PR review comment handling\n\n---\n\n## Memory System\n\nThe SDLC plugin uses Claude Code's built-in **auto memory** for knowledge persistence across sessions.\n\n### Features\n\n- **File-based storage** - Markdown files in `~/.claude/projects/<project-path>/memory/`\n- **Organized by category** - debugging/, architecture/, conventions/, tools/, patterns/\n- **Keyword search** - Use `/sdlc:recall \"<keywords>\"` to grep through memory\n- **Manual capture** - Use `/sdlc:remember \"<what>\"` to store discoveries\n- **Zero configuration** - No external servers or dependencies required\n\n### Directory Structure\n\n```\n~/.claude/projects/<project-path>/memory/\n‚îú‚îÄ‚îÄ MEMORY.md              # Quick references (always loaded, <200 lines)\n‚îú‚îÄ‚îÄ debugging/             # Solutions to past problems\n‚îú‚îÄ‚îÄ architecture/          # Architecture decisions\n‚îú‚îÄ‚îÄ conventions/           # Project conventions\n‚îú‚îÄ‚îÄ tools/                 # Tool quirks and discoveries\n‚îî‚îÄ‚îÄ patterns/              # General reusable patterns\n```\n\n### Usage\n\n**Store a discovery:**\n```bash\n/sdlc:remember \"cargo test hangs with RUST_TEST_THREADS unset\"\n```\n\n**Recall knowledge:**\n```bash\n/sdlc:recall \"cargo test timeout\"\n```\n\n### Limitations\n\nCompared to semantic search systems (like Memento MCP):\n- **No semantic search** - Only exact keyword matching via grep\n- **No relationship graph** - Manual markdown links between files\n- **No automatic capture** - Must manually use `/sdlc:remember`\n\n**Trade-off:** Simplicity and zero configuration vs. sophisticated search capabilities.\n\n---\n\n## TDD Workflow Example\n\n```bash\n# 1. Start work on a feature\n/sdlc:work\n\n# User: \"Add user authentication with email/password\"\n\n# 2. Orchestrator creates task sequence:\n# Task #1: Write failing test (red)\n# Task #2: Create domain types (domain) - blocked by #1\n# Task #3: Implement minimal solution (green) - blocked by #2\n# Task #4: Review implementation (domain) - blocked by #3\n\n# 3. Red agent writes test:\n#[test]\nfn authenticates_user_with_valid_credentials() {\n    let user = User::new(\"test@example.com\", \"password123\");\n    assert!(user.authenticate(\"password123\"));\n}\n\n# 4. Domain agent creates types:\npub struct User {\n    email: Email,  // Not String!\n    password_hash: PasswordHash,\n}\n\n# 5. Green agent implements:\nimpl User {\n    pub fn authenticate(&self, password: &str) -> bool {\n        self.password_hash.verify(password)\n    }\n}\n\n# 6. Domain agent reviews:\n# \"APPROVE - No primitive obsession. Type safety maintained.\"\n\n# 7. Cycle complete. Ready for next test or PR creation.\n```\n\n---\n\n## Event Modeling Workflow Example\n\n```bash\n# 1. Start design session\n/sdlc:design\n\n# 2. Discovery phase\n# Agent interviews you about domain:\n# - What workflows exist?\n# - Who are the actors?\n# - What are the outcomes?\n\n# Creates: docs/event_model/discovery.md\n\n# 3. Workflow design\n# Agent creates swimlane diagrams for each workflow\n# Creates: docs/event_model/workflows/user-registration.md\n\n# 4. GWT scenarios\n# Agent generates Given/When/Then acceptance criteria\n# Adds to workflow file\n\n# 5. Model checking\n# Agent validates information flow\n# Identifies gaps in event sequences\n\n# 6. Ready for implementation\n# Use /sdlc:start to create GitHub issues from slices\n```\n\n---\n\n## File Structure\n\n```\nproject/\n‚îú‚îÄ‚îÄ .claude/\n‚îÇ   ‚îî‚îÄ‚îÄ sdlc.yaml              # Plugin configuration\n‚îú‚îÄ‚îÄ docs/\n‚îÇ   ‚îú‚îÄ‚îÄ ARCHITECTURE.md         # Current architecture (ADR PRs on GitHub)\n‚îÇ   ‚îî‚îÄ‚îÄ event_model/            # Event Modeling artifacts\n‚îÇ       ‚îú‚îÄ‚îÄ discovery.md\n‚îÇ       ‚îî‚îÄ‚îÄ workflows/\n‚îÇ           ‚îî‚îÄ‚îÄ user-registration.md\n‚îú‚îÄ‚îÄ src/                        # Production code (green agent)\n‚îÇ   ‚îî‚îÄ‚îÄ domain/                 # Domain types (domain agent)\n‚îî‚îÄ‚îÄ tests/                      # Test code (red agent)\n```\n\n---\n\n## Troubleshooting\n\n### \"Skill not found: sdlc:shared/user-input-protocol\"\n\n**Problem:** Using v3.x skill references\n\n**Solution:** Update to v4.0.0 skill names. See `MIGRATION.md`.\n\n### \"INVOCATION GATE FAILED\"\n\n**Problem:** Using v3.x manual confirmation blocks\n\n**Solution:** Remove confirmation blocks. Use TaskCreate instead. See `MIGRATION.md`.\n\n### Agent creates wrong file type\n\n**Problem:** Hook misconfigured or agent bypassing constraints\n\n**Solution:** Check agent YAML has correct PreToolUse hooks. File issue if hooks fail.\n\n### Tasks not blocking correctly\n\n**Problem:** Task dependencies not set up\n\n**Solution:** Verify `addBlockedBy` used when creating dependent tasks.\n\n---\n\n## Migration\n\nUpgrading from v3.x? See **MIGRATION.md** for:\n- Breaking changes summary\n- Step-by-step migration guide\n- Troubleshooting common issues\n- FAQ\n\n---\n\n## Support\n\n**Issues:** https://github.com/jwilger/claude-code-plugins/issues\n**Discussions:** https://github.com/jwilger/claude-code-plugins/discussions\n**Email:** john@johnwilger.com\n\n---\n\n## License\n\nMIT License - See LICENSE file in repository root\n\n---\n\n## Version History\n\n- **v4.0.0** (2026-02-04): Task-based workflow, portable skills, removed invocation gates\n- **v3.12.8** (2026-02-04): Last v3.x release (domain re-review fix, git-spice recovery docs)\n- **v3.12.0** (2026-01): GitHub issues two-step creation, GWT business rules distinction\n- **v3.11.0** (2026-01): Mutation testing agent, compile-time enforcement audit\n- **v3.10.0** (2025-12): Event Modeling integration, architecture agents\n\nSee full changelog: CHANGELOG.md\n\n---\n\n**Built with Claude Code** | **Powered by Task Dependencies** | **Personality by Marvin** ü§ñ\n"
      },
      "plugins": [
        {
          "name": "sdlc",
          "source": "./sdlc",
          "description": "Complete SDLC workflow with TDD, Event Modeling, architecture decisions, and GitHub integration (includes Marvin personality option)",
          "version": "19.2.0",
          "keywords": [
            "sdlc",
            "tdd",
            "event-modeling",
            "adr",
            "github",
            "workflow",
            "domain-modeling",
            "mutation-testing",
            "code-review",
            "debugging",
            "worktrees",
            "compile-time-enforcement",
            "hooks",
            "todo-enforcement",
            "marvin",
            "output-style"
          ],
          "categories": [
            "adr",
            "code-review",
            "compile-time-enforcement",
            "debugging",
            "domain-modeling",
            "event-modeling",
            "github",
            "hooks",
            "marvin",
            "mutation-testing",
            "output-style",
            "sdlc",
            "tdd",
            "todo-enforcement",
            "workflow",
            "worktrees"
          ],
          "install_commands": [
            "/plugin marketplace add jwilger/claude-code-plugins",
            "/plugin install sdlc@jwilger-claude-plugins"
          ]
        },
        {
          "name": "bootstrap",
          "source": "./bootstrap",
          "description": "Intelligent Nix devshell bootstrapper for any language or framework",
          "version": "1.0.0",
          "keywords": [
            "bootstrap",
            "scaffolding",
            "nix",
            "flake",
            "devshell",
            "development-environment",
            "language-agnostic"
          ],
          "categories": [
            "bootstrap",
            "development-environment",
            "devshell",
            "flake",
            "language-agnostic",
            "nix",
            "scaffolding"
          ],
          "install_commands": [
            "/plugin marketplace add jwilger/claude-code-plugins",
            "/plugin install bootstrap@jwilger-claude-plugins"
          ]
        }
      ]
    },
    {
      "name": "jwilger-agent-skills",
      "version": null,
      "description": "Portable AI agent skills and Claude Code enforcement plugin for professional SDLC workflows",
      "repo_full_name": "jwilger/agent-skills",
      "repo_url": "https://github.com/jwilger/agent-skills",
      "repo_description": "AI Agent Skills Repository",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-02-16T20:23:57Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"jwilger-agent-skills\",\n  \"owner\": {\n    \"name\": \"John Wilger\",\n    \"email\": \"john@johnwilger.com\"\n  },\n  \"metadata\": {\n    \"description\": \"Portable AI agent skills and Claude Code enforcement plugin for professional SDLC workflows\",\n    \"version\": \"1.2.0\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"sdlc\",\n      \"source\": \"./plugins/claude-code\",\n      \"description\": \"Enforcement plugin for Agent Skills SDLC workflow. Adds mechanical guardrails (hooks, agents, skills) on top of portable skills.\",\n      \"version\": \"1.2.0\",\n      \"keywords\": [\n        \"sdlc\",\n        \"tdd\",\n        \"event-modeling\",\n        \"adr\",\n        \"domain-modeling\",\n        \"code-review\",\n        \"hooks\",\n        \"enforcement\"\n      ]\n    }\n  ]\n}",
        "README.md": "# Agent Skills for Software Development\n\nPortable [Agent Skills](https://agentskills.io) that encode professional\nsoftware development practices -- TDD, domain modeling, event modeling,\ncode review, architecture decisions, and more. These skills teach any\nAI coding agent a disciplined SDLC process, regardless of which harness\nor editor you use.\n\n## Quick Start\n\nInstall all skills:\n\n```bash\nnpx skills add jwilger/agent-skills --all\n```\n\nOr install individual skills:\n\n```bash\nnpx skills add jwilger/agent-skills --skill tdd-cycle\nnpx skills add jwilger/agent-skills --skill domain-modeling\nnpx skills add jwilger/agent-skills --skill code-review\n```\n\n## Skill Inventory\n\n### Tier 0 -- Entry Point\n\n| Skill | Description | Phase |\n|-------|-------------|-------|\n| `bootstrap` | Zero-config onboarding, harness detection, skill recommendations | -- |\n\n### Tier 1 -- Core Process (universal, standalone)\n\n| Skill | Description | Phase |\n|-------|-------------|-------|\n| `tdd-cycle` | Red-green-domain TDD cycle with phase boundaries and domain review checkpoints | build |\n| `domain-modeling` | Parse-don't-validate, primitive obsession detection, type-driven design | decide |\n| `code-review` | Three-stage review protocol: spec compliance, code quality, domain integrity | ship |\n| `architecture-decisions` | ADR format, governance, and lightweight decision records | decide |\n| `event-modeling` | Discovery, swimlanes, GWT scenarios, model validation | understand |\n\n### Tier 2 -- Orchestration (need some harness support)\n\n| Skill | Description | Phase |\n|-------|-------------|-------|\n| `orchestration` | Multi-agent delegation patterns, workflow gates, conflict resolution | build |\n| `task-management` | Work breakdown, state tracking, dependency management | build |\n\n### Tier 3 -- Utility (universal, standalone)\n\n| Skill | Description | Phase |\n|-------|-------------|-------|\n| `debugging-protocol` | Systematic 4-phase investigation: root cause before fix | build |\n| `user-input-protocol` | Structured pause/resume pattern for agent-to-user questions | build |\n| `memory-protocol` | Recall-before-act knowledge accumulation and retrieval | build |\n\n### Advanced (optional)\n\n| Skill | Description | Phase |\n|-------|-------------|-------|\n| `mutation-testing` | Mutation testing as a test quality gate | ship |\n| `atomic-design` | UI component hierarchy (atoms, molecules, organisms) | build |\n\n## Architecture\n\n### Three Tiers\n\nThis system separates concerns into three layers:\n\n**Skills** are portable markdown documents (SKILL.md) that teach an agent\n*what to do*. They conform to the [Agent Skills specification](https://agentskills.io/specification)\nand work on any compatible harness. Skills are advisory -- they instruct\nthe agent on correct behavior through clear principles and practices.\n\n**Harness Plugins** add *mechanical enforcement* on harnesses that support\nit. Hooks that prevent editing the wrong file during the wrong TDD phase,\ngates that force domain review between red and green, skills that\nwire up multi-step workflows. Plugins make the experience better on\nspecific harnesses but are never required.\n\n**The Enforcement Gap.** Skills cannot mechanically prevent an agent from\nviolating a practice. They can describe the rules clearly and include\nself-verification checklists, but an agent may still rationalize skipping\nsteps. This is an honest limitation. On harnesses with plugin support\n(Claude Code hooks, OpenCode event hooks), enforcement plugins close\nthis gap. On harnesses without enforcement, the agent follows practices\nby convention. If you observe a violation, point it out. Skills are the\nconstitution; plugins are the police. You benefit from both, but the\nconstitution works across jurisdictions while the police are local.\n\n### Skill Structure\n\nEvery skill follows a canonical template (see `skills/.template/`):\n\n1. **Frontmatter** -- Agent Skills spec metadata plus project extensions\n2. **Value** -- Which XP value this skill serves (feedback, communication,\n   simplicity, courage, respect)\n3. **Purpose** -- What the skill teaches (2-3 sentences)\n4. **Practices** -- Concrete, actionable instructions (the main body)\n5. **Enforcement Note** -- Honest statement of what the skill can/cannot\n   guarantee without harness plugins\n6. **Verification** -- Self-check checklist with binary, observable criteria\n7. **Dependencies** -- Integration points and install commands for related skills\n\nToken budgets: Core skills stay under 3000 tokens, orchestration skills\nunder 4000 tokens, bootstrap under 1000 tokens. Detailed reference\nmaterial lives in `references/` directories, loaded on demand.\n\n### Cross-Skill Dependencies\n\nSkills declare dependencies in frontmatter (`metadata.requires`). When a\nskill activates and finds a dependency missing, it recommends installation\nwith the specific `npx skills add --skill` command. Dependencies are\nrecommendations, not hard requirements -- every skill degrades gracefully\nwhen used alone.\n\nThe dependency graph is a DAG (no circular dependencies). Skills reference\neach other by name but never assume internal structure.\n\n## Harness Plugin Availability\n\n| Harness | Skills | Plugin | Enforcement |\n|---------|--------|--------|-------------|\n| Claude Code | All 13 | Planned | Hooks, subagents, skills |\n| OpenCode | All 13 | Planned | JS/TS modules, event hooks |\n| Codex | All 13 | Planned | AGENTS.md, commands |\n| Cursor / Windsurf | All 13 | Planned | Rules files |\n| Goose | All 13 | Planned | Recipes (YAML) |\n| Amp | All 13 | None | MCP only |\n| Aider | All 13 | None | No plugin system |\n\nSkills work on every harness in the table. Plugins add ergonomics and\nenforcement on harnesses that support them.\n\n## Installing Individual Skills\n\nEach skill is a directory under `skills/`. Install individually with `--skill`:\n\n```bash\n# Core process skills\nnpx skills add jwilger/agent-skills --skill tdd-cycle\nnpx skills add jwilger/agent-skills --skill domain-modeling\nnpx skills add jwilger/agent-skills --skill code-review\nnpx skills add jwilger/agent-skills --skill architecture-decisions\nnpx skills add jwilger/agent-skills --skill event-modeling\n\n# Orchestration skills\nnpx skills add jwilger/agent-skills --skill orchestration\nnpx skills add jwilger/agent-skills --skill task-management\n\n# Utility skills\nnpx skills add jwilger/agent-skills --skill debugging-protocol\nnpx skills add jwilger/agent-skills --skill user-input-protocol\nnpx skills add jwilger/agent-skills --skill memory-protocol\n\n# Advanced skills\nnpx skills add jwilger/agent-skills --skill mutation-testing\nnpx skills add jwilger/agent-skills --skill atomic-design\n```\n\n## Contributing\n\n### Writing a New Skill\n\n1. Read the canonical template at `skills/.template/SKILL.md.example`\n2. Read the frontmatter reference at `skills/.template/FRONTMATTER.md`\n3. Follow the section order: Value, Purpose, Practices, Enforcement Note,\n   Verification, Dependencies\n4. Stay within token budgets (Core 3000, Orchestration 4000)\n5. Include an honest Enforcement Note -- do not overstate what the skill\n   can guarantee without harness plugins\n6. Include a Verification section with binary, observable criteria\n7. Keep the SKILL.md body under 500 lines; move detailed examples and\n   reference material to `references/`\n\n### Reviewing a Skill\n\nWhen reviewing skills, check for:\n\n- **Template conformance:** All six body sections present in the correct order\n- **Token budget:** Within the tier limit\n- **Enforcement honesty:** Does the Enforcement Note accurately describe\n  what the skill can and cannot guarantee?\n- **Verification quality:** Are the checklist items specific, observable,\n  and binary (yes/no)?\n- **Standalone usability:** Does the skill provide value when installed\n  alone?\n- **Security:** Do shell fragments in SKILL.md limit themselves to\n  read-only environment detection? No writes, no network calls, no\n  package installation.\n\n## License\n\nCC0 1.0 Universal. See [LICENSE](LICENSE).\n"
      },
      "plugins": [
        {
          "name": "sdlc",
          "source": "./plugins/claude-code",
          "description": "Enforcement plugin for Agent Skills SDLC workflow. Adds mechanical guardrails (hooks, agents, skills) on top of portable skills.",
          "version": "1.2.0",
          "keywords": [
            "sdlc",
            "tdd",
            "event-modeling",
            "adr",
            "domain-modeling",
            "code-review",
            "hooks",
            "enforcement"
          ],
          "categories": [
            "adr",
            "code-review",
            "domain-modeling",
            "enforcement",
            "event-modeling",
            "hooks",
            "sdlc",
            "tdd"
          ],
          "install_commands": [
            "/plugin marketplace add jwilger/agent-skills",
            "/plugin install sdlc@jwilger-agent-skills"
          ]
        }
      ]
    }
  ]
}