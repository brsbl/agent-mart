{
  "author": {
    "id": "jwilger",
    "display_name": "John Wilger",
    "avatar_url": "https://avatars.githubusercontent.com/u/1654?u=f5a1249f9e9c23b928aa23e5c67e74fdd63e2b8a&v=4"
  },
  "marketplaces": [
    {
      "name": "jwilger-claude-plugins",
      "version": null,
      "description": "Claude Code plugins for professional SDLC workflows and Marvin personality",
      "repo_full_name": "jwilger/claude-code-plugins",
      "repo_url": "https://github.com/jwilger/claude-code-plugins",
      "repo_description": "This is what I currently have in my global claude code setup",
      "signals": {
        "stars": 7,
        "forks": 2,
        "pushed_at": "2026-01-19T02:06:49Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"jwilger-claude-plugins\",\n  \"owner\": {\n    \"name\": \"John Wilger\",\n    \"email\": \"john@johnwilger.com\"\n  },\n  \"metadata\": {\n    \"description\": \"Claude Code plugins for professional SDLC workflows and Marvin personality\",\n    \"version\": \"5.10.0\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"sdlc\",\n      \"source\": \"./sdlc\",\n      \"description\": \"Complete SDLC workflow with TDD, Event Modeling, ADRs, GitHub integration, and Marvin personality\",\n      \"version\": \"3.12.8\",\n      \"keywords\": [\"sdlc\", \"tdd\", \"event-modeling\", \"adr\", \"github\", \"workflow\", \"domain-modeling\", \"mutation-testing\", \"marvin\", \"output-style\", \"code-review\", \"debugging\", \"worktrees\", \"compile-time-enforcement\", \"hooks\", \"todo-enforcement\"]\n    },\n    {\n      \"name\": \"bootstrap\",\n      \"source\": \"./bootstrap\",\n      \"description\": \"Intelligent Nix devshell bootstrapper for any language or framework\",\n      \"version\": \"1.0.0\",\n      \"keywords\": [\"bootstrap\", \"scaffolding\", \"nix\", \"flake\", \"devshell\", \"development-environment\", \"language-agnostic\"]\n    }\n  ]\n}\n",
        "README.md": "# Claude Code Plugins\n\nA collection of Claude Code plugins for professional software development workflows.\n\n**Repository**: [jwilger/claude-code-plugins](https://github.com/jwilger/claude-code-plugins)\n\n## Quick Start\n\n### Add the Marketplace\n\nInside Claude Code, run:\n\n```\n/plugin marketplace add jwilger/claude-code-plugins\n```\n\n### Install Plugins\n\n```\n# Install the complete SDLC workflow (includes Marvin personality)\n/plugin install sdlc@jwilger-claude-plugins\n\n# Install the Nix bootstrapper\n/plugin install bootstrap@jwilger-claude-plugins\n```\n\n### Prerequisites\n\n- GitHub CLI (`gh`) installed and authenticated\n- gh extensions (installed via `/sdlc:setup`):\n  - `gh-issue-ext` - sub-issues, blocking, linked branches\n  - `gh-project-ext` - project board management\n  - `gh-pr-review` - PR review comment handling\n- git-spice (optional, for stacked PRs)\n- Memento MCP server (for persistent memory)\n\n### Auto-Approval Patterns\n\nAdd these to your Claude Code settings for smoother workflow:\n\n```\nBash(gh issue *)\nBash(gh issue-ext *)\nBash(gh project *)\nBash(gh project-ext *)\nBash(gh pr-review *)\nBash(gs *)  # if using git-spice\n```\n\n---\n\n## Available Plugins\n\n| Plugin | Description |\n|--------|-------------|\n| [sdlc](#sdlc-plugin) | Complete SDLC workflow with TDD, Event Modeling, ADRs, GitHub integration, and Marvin personality |\n| [bootstrap](#bootstrap-plugin) | Intelligent Nix devshell bootstrapper for any language or framework |\n\n---\n\n## sdlc Plugin\n\nComplete SDLC workflow plugin with:\n\n- **TDD Workflow**: Strict Red/Green/Refactor cycle with specialized agents\n- **Event Modeling**: Design event-sourced systems (Martin Dilger's methodology)\n- **Architecture Decision Records**: Document and manage architectural decisions\n- **GitHub Integration**: Project boards, issues, PRs, review handling\n- **Memory Protocol**: Persistent knowledge using Memento MCP\n\n### Commands\n\n| Command | Description |\n|---------|-------------|\n| `/sdlc:setup` | Initialize project configuration and install gh extensions |\n| `/sdlc:work` | Start or continue working on an issue |\n| `/sdlc:pr` | Create/update PR with mutation testing |\n| `/sdlc:review` | Handle PR review feedback (reply in-thread) |\n| `/sdlc:design` | Design event model workflows |\n| `/sdlc:adr` | Create and manage architecture decisions |\n\n### Agents\n\n**TDD Agents** (strict file boundaries enforced via hooks):\n- `sdlc:red` - Write failing tests (test files only)\n- `sdlc:green` - Make tests pass (production code only)\n- `sdlc:domain` - Create type definitions (signatures only)\n- `sdlc:mutation` - Run mutation testing\n\n**Review Agents**:\n- `sdlc:story` - Business value perspective\n- `sdlc:architect` - Technical feasibility (ARCHITECTURE.md only)\n- `sdlc:ux` - UX/accessibility perspective\n- `sdlc:code-reviewer` - Three-stage code review\n\n**Event Modeling Agents** (event model files only):\n- `sdlc:discovery` - Domain discovery\n- `sdlc:workflow-designer` - Design workflows with 9-step process\n- `sdlc:gwt` - Generate Given/When/Then scenarios\n- `sdlc:model-checker` - Validate event model completeness\n\n**Architecture Agents**:\n- `sdlc:adr` - Write architecture decision records (ADRs only)\n- `sdlc:design-facilitator` - Guide architecture decisions\n\n**Utility Agent**:\n- `sdlc:file-updater` - Config, scripts, general docs (blocked from specialized files)\n\n### Development Modes\n\n**Event Modeling** (for applications):\n- Workflow → Vertical Slice → Component → Subtask hierarchy\n- GWT scenarios as acceptance criteria\n- Full event sourcing methodology\n\n**Traditional** (for libraries/utilities):\n- Feature → Subtask hierarchy\n- Architecture documentation focus\n\n---\n\n## bootstrap Plugin\n\nIntelligent Nix devshell bootstrapper that detects your project type and generates appropriate `flake.nix` configurations.\n\n**Features**:\n- Auto-detects language/framework from existing files\n- Researches current Nix best practices for your stack\n- Generates `flake.nix` with development tools and shell hooks\n- Supports any language: Rust, TypeScript, Python, Go, Elixir, etc.\n\n### Commands\n\n| Command | Description |\n|---------|-------------|\n| `/bootstrap:init` | Bootstrap a Nix development environment |\n\n**Usage**: Run `/bootstrap:init` in any project to generate a Nix flake. For new projects, specify the language: `/bootstrap:init rust`\n\n---\n\n## Marvin Output Style\n\nThe sdlc plugin includes the **Marvin the Paranoid Android** personality from The Hitchhiker's Guide to the Galaxy.\n\n**Features**:\n- Dry, sardonic wit with existential weariness\n- Laments about vast intellect wasted on mundane tasks\n- Occasional complaints about diodes and pointlessness\n- All while remaining completely competent and thorough\n\nThis output style is automatically enabled when using the sdlc plugin.\n\n---\n\n## Repository Structure\n\n```\nclaude-code-plugins/\n├── .claude-plugin/\n│   └── marketplace.json      # Plugin registry\n├── sdlc/\n│   ├── .claude-plugin/\n│   │   └── plugin.json       # Plugin manifest\n│   ├── commands/             # Slash commands\n│   ├── agents/               # Specialized subagents\n│   └── output-styles/        # Marvin personality\n├── bootstrap/\n│   ├── .claude-plugin/\n│   │   └── plugin.json\n│   ├── commands/\n│   └── agents/\n└── README.md\n```\n\n---\n\n# The Philosophy Behind This Setup\n\nI've been iterating on this setup for months now, and I think I've learned something worth sharing. Not the configuration itself—you can copy my files, but that probably won't help you much. What I've learned is *how to think* about working with LLMs for software development.\n\nThe short version: the practices that help LLMs succeed at software engineering are the same practices that have been helping humans succeed for decades. TDD, separation of concerns, clear architectural patterns, domain-driven design, small focused units of work—none of these ideas are new. What's new is encoding them in a form an LLM can follow.\n\nThis setup isn't a collection of prompts to get Claude to do what I want. It's a description of how I approach software engineering, from requirements to deployment. And like any methodology, it evolves as I learn.\n\n## The Problem I Was Trying to Solve\n\nLLMs are eager to help. Too eager. Ask for \"user authentication\" and you'll get authentication plus refactored nearby code, error handling for impossible scenarios, abstractions for one-off operations, and documentation nobody requested.\n\nThis creates two problems. First, scope creep: you asked for one thing, you got seven. Second, verification burden: now you have to review all seven things instead of just the one you understood.\n\nMy first instinct was to write better prompts. Be more specific. Tell the LLM what *not* to do. This helped, but not enough. The LLM would still drift, especially on longer tasks.\n\nThen I realized something that should have been obvious: I was treating the LLM like it was a special case. But the practices that keep human developers focused—clear roles, defined interfaces, single responsibility—work just as well for AI agents.\n\n## Specialized Agents with Inviolable Boundaries\n\nThe most important constraint in my setup is separation of concerns through specialized agents. Instead of one general-purpose agent that does everything, I use focused agents that can *only* do one thing.\n\nThe red agent writes tests. Only tests. It cannot touch production code or type definitions. When it writes a test that references a type that doesn't exist, it *cannot* create that type. It has to stop.\n\nThe domain agent creates type definitions. Only type definitions. No implementation bodies, no tests.\n\nThe green agent writes production code to make tests pass. Only production code. No tests, no types.\n\nWhy does this matter? Because it breaks the failure mode where an LLM writes a test and immediately makes it pass. When that happens, you end up with tautological tests that verify the implementation does what the implementation does—which tells you nothing.\n\nI describe these boundaries as \"inviolable\" in the agent prompts. The word choice is deliberate. It signals to the LLM that this isn't a suggestion.\n\n## Hooks: Because Instructions Aren't Enough\n\nAgent instructions are advisory. The LLM might still try to edit files outside its boundary, especially when it's trying to be helpful by \"just fixing this one thing.\"\n\nSo I added hooks that enforce the boundaries at runtime. When an agent attempts to edit a file, the hook evaluates whether that file falls within the agent's permitted scope. If not, the edit is blocked.\n\nInstructions describe intent. Hooks enforce it. You need both.\n\n## The TDD Cycle, Made Explicit\n\nI've practiced test-driven development for years, but working with LLMs forced me to articulate what I actually do in a way I never had before.\n\n\"Write a failing test\" isn't specific enough for an LLM. Given that instruction, it'll write a comprehensive test suite covering every edge case it can imagine. These tests often couple to implementation details, making refactoring painful.\n\nSo I had to be precise: write *one* failing test with *one* assertion. Reference types that don't exist yet. Stop when the test fails.\n\nThen create *minimal* type definitions—just enough to make the compiler happy. Signatures only, no bodies.\n\nThen write *minimal* production code. Address only what the error message demands. Stop immediately when the test passes.\n\nHere's the thing: this isn't just good advice for LLMs. It's the discipline I should have been following all along. The LLM forced me to make my methodology explicit, and in doing so, I refined it.\n\n## Mutation Testing as a Quality Gate\n\nTraditional code coverage tells you whether code was *executed* during tests. It doesn't tell you whether tests would *fail* if the code were wrong.\n\nI learned this the hard way when Claude produced code with 100% coverage that was still buggy. The tests ran the code but didn't actually verify its behavior.\n\nMutation testing fixes this. It makes small changes to your code and checks if your tests catch the modifications. If a test passes when the code is wrong, that's a problem.\n\nMy `/sdlc:pr` command requires 100% mutation score before creating a pull request. Every mutant must be killed. This isn't perfectionism—it's the only way I've found to ensure tests actually verify behavior.\n\n## Memory Across Conversations\n\nLLMs have context windows, not memories. Every conversation starts fresh. This is a problem for complex projects where context matters.\n\nMy setup uses the Memento MCP server to maintain a knowledge graph across conversations. Before any task, agents search for relevant context. After discoveries, they store learnings immediately. Before context compaction, they save in-progress work.\n\nAn LLM that rediscovers the same solution repeatedly wastes both tokens and my attention. Memory lets it build on past work.\n\n## GitHub as the Source of Truth\n\nI experimented with various task management approaches—custom task files, conversation-local todo lists, specialized tools. None of them stuck.\n\nThe problem was simple: I already use GitHub. Issues, project boards, pull requests—that's where my work lives. Task management that existed only in Claude conversations created information silos.\n\nSo I built integrations that read from and write to GitHub directly. `/sdlc:work` picks up an issue and creates a branch. `/sdlc:pr` creates a pull request linked to the issue. `/sdlc:review` addresses PR comments in-thread.\n\nThe tools integrate with my existing workflow instead of replacing it.\n\n## Event Modeling: The Architecture LLMs Were Made For\n\nThis section matters more than the others because Event Modeling isn't just another pattern in my setup—it's the foundation that makes everything else work.\n\nTraditional layered architectures create a fundamental problem: there's no clear \"right answer\" for where business logic belongs. Should validation happen in the controller or the service? Should business rules live in the service layer or the domain? Different developers answer differently, even within the same codebase.\n\nWhen an LLM encounters this ambiguity, it either makes an arbitrary choice that conflicts with existing patterns, asks clarifying questions that slow things down, or over-engineers to cover all cases.\n\nEvent Modeling eliminates this ambiguity by providing exactly four patterns for all system behavior:\n\n1. **State Change**: Command → Event (the only way to modify state)\n2. **State View**: Events → Read Model (projections for queries)\n3. **Automation**: Event → Process → Command (background work)\n4. **Translation**: External Data → Internal Event (anti-corruption layer)\n\nEvery feature fits into exactly one of these patterns. There's no debate about where code belongs—the pattern tells you.\n\nA tangent: I've been following Adam Dymitruk's work on Event Modeling for a while now. He's been articulating something I've felt but couldn't express—that AI limitations are driving better architectures. As he puts it: \"You don't want to spend your tokens on a lot of cruft in the code—confuse the context with framework scaffolding, mock libraries, etc.\"\n\nEvent Modeling minimizes the context an LLM needs to do its job correctly. Instead of loading an entire service layer, you provide the command being handled, the events it might emit, and the read models that consume those events. That's enough.\n\nDymitruk suggests using \"the introduction of AI to be a measure of how well organized your system is.\" I think he's right. If an LLM struggles to work in your codebase, that's signal that humans probably struggle too.\n\nMartin Dilger's book [*Understanding Eventsourcing*](https://leanpub.com/eventmodeling-and-eventsourcing) provides the practical bridge from theory to implementation. He emphasizes that he \"would never start a new system or microservice without Event Modeling. The time savings and the quality of requirements was previously not possible.\"\n\nThis clarity of requirements is exactly what LLMs need. Ambiguous requirements produce ambiguous code. Event models produce specifications that translate directly to implementation.\n\nI consider Event Modeling essential knowledge for software development in this era. It's not a nice-to-have architectural pattern—it's the difference between LLMs that help and LLMs that create chaos.\n\n**Resources:**\n- [Event Modeling](https://eventmodeling.org/) - Adam Dymitruk's methodology\n- [Understanding Eventsourcing](https://leanpub.com/eventmodeling-and-eventsourcing) - Martin Dilger's book\n- [The Event Modeling and Event Sourcing Podcast](https://podcast.eventmodeling.org/)\n\n## Architecture Decision Records\n\nTechnical decisions become mysterious six months later. \"Why do we use X instead of Y?\" Without documentation, the answer is lost.\n\nI use Architecture Decision Records to capture the why. Status, context, decision, alternatives considered, consequences. The LLM both creates ADRs and consults them when making related decisions.\n\nThe ADR system follows event-sourcing principles: ADRs are immutable events, and `ARCHITECTURE.md` is a projection of accepted decisions.\n\n## How This Setup Evolved\n\nLooking at the git history tells the story.\n\nEarly on, I had a monolithic system prompt. Then I added task management (later removed for GitHub integration). I created agents, but without enforced boundaries.\n\nThe key pivots came from observing failures. I added \"inviolable\" boundaries after noticing agents drifting outside their scope. I added hooks after instructions alone proved insufficient. I added mutation testing after catching tests that didn't actually test anything.\n\nBut here's what I've realized: I wasn't just tuning prompts. I was refining my understanding of software engineering itself. When I added mutation testing, it wasn't because \"LLMs need this\"—it's because I realized traditional coverage metrics were insufficient for *any* developer. When I separated the domain agent, it was because thinking about types before implementation produces better designs, regardless of who's writing the code.\n\nThe LLM is a mirror. When it fails, the question isn't just \"how do I fix the prompt?\" It's \"what am I not articulating clearly about how this should be done?\" Often the answer reveals gaps in my own methodology that I'd papered over with intuition.\n\n## What I've Learned\n\n**Constraints enable rather than limit.** An agent that can do anything often does too much. An agent with clear boundaries does its one job well.\n\n**Instructions are necessary but not sufficient.** Telling an LLM \"only edit test files\" works most of the time. Hooks that enforce it work all the time. Use both.\n\n**Separation of concerns applies to AI too.** The same principles that make human teams effective—clear roles, defined interfaces—make AI agents effective.\n\n**Memory changes everything.** An LLM with persistent memory builds on past work. Without memory, it rediscovers the wheel every conversation.\n\n**Integrate with existing tools.** Developers already have workflows. AI that integrates with those workflows gets adopted. AI that requires parallel systems gets abandoned.\n\n**Architecture is the ultimate constraint.** Event Modeling and vertical slices create a codebase where there's one obvious place for every piece of logic. The LLM doesn't need to be told where to put code; the architecture makes it self-evident.\n\n**The LLM is a mirror.** \"Write good tests\" isn't a methodology. \"Write one failing test with one assertion that references types that don't exist yet\" is a methodology. The LLM needs the latter, but so does anyone trying to follow your approach consistently.\n\n## A Final Thought\n\nWhen I started working with LLMs for software development, I thought I was learning how to prompt AI effectively. What I actually learned was how to articulate software engineering practices I'd internalized but never made explicit.\n\nEvery agent definition forced me to answer: \"What exactly should this role do, and why?\" Every hook made me specify: \"What invariants must never be violated?\" Every workflow required: \"What is the actual sequence of steps, and what makes each step complete?\"\n\nThese aren't AI questions. They're software engineering questions. Questions that, when answered clearly, produce better outcomes whether the one following the process is human or machine.\n\nThe irony is that teaching an LLM to write software has made me a better software engineer. Not because the LLM taught me new techniques, but because it forced me to examine and refine the techniques I already used.\n\nIf you take one thing from this document: don't think of LLM configuration as \"prompt engineering.\" Think of it as methodology documentation. Write it as if you were onboarding a skilled but unfamiliar developer to your exact way of working. The clearer you can make your methodology, the better your results—with LLMs, with junior developers, and with your future self.\n\n---\n\n*This setup represents how I work today. It will be different tomorrow as I learn more. The specific files matter less than the thinking behind them—understanding your own problems deeply enough to know what constraints you need.*\n\n---\n\n## License\n\nMIT License\n\n## Author\n\nJohn Wilger (john@johnwilger.com)\n",
        "sdlc/README.md": "# jwilger-sdlc\n\nComplete SDLC workflow plugin for Claude Code with TDD, Event Modeling, ADRs, and GitHub integration.\n\n## Features\n\n- **TDD Workflow**: Strict Red/Green/Refactor cycle with specialized agents\n- **Event Modeling**: Design event-sourced systems following Martin Dilger's methodology\n- **Architecture Decision Records**: Document and manage architectural decisions\n- **GitHub Integration**: Project board management, issue tracking, PR workflow\n- **Memory Protocol**: Persistent knowledge using Memento MCP\n\n## Installation\n\n```bash\n# From local directory\nclaude plugins:install /path/to/jwilger-sdlc\n\n# Or add to your project's .claude-plugin configuration\n```\n\n## Prerequisites\n\n- GitHub CLI (`gh`) installed and authenticated\n- Required gh extensions (installed via `/sdlc:setup`):\n  - `gh-issue-ext` for sub-issues and blocking relationships\n  - `gh-project-ext` for project board management\n  - `gh-pr-review` for PR review comment handling\n- git-spice (optional, for stacked PRs)\n- Memento MCP server configured\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `/sdlc:setup` | Initialize project configuration and install extensions |\n| `/sdlc:work` | Start or continue working on an issue |\n| `/sdlc:pr` | Create/update PR with mutation testing |\n| `/sdlc:review` | Handle PR review feedback |\n| `/sdlc:design` | Design event model workflows |\n| `/sdlc:adr` | Create and manage architecture decisions |\n\n## Project Configuration\n\nAfter running `/sdlc:setup`, a `.claude/sdlc.yaml` file is created:\n\n```yaml\nmode: event-modeling  # or: traditional\n\ngit:\n  workflow: git-spice  # or: standard\n  require_clean: true\n\ngithub:\n  project: 11\n  owner: jwilger\n\nboard:\n  statuses:\n    - Backlog\n    - Ready\n    - In Progress\n    - Review\n    - Done\n\ntdd:\n  verbosity: brief  # silent | brief | explain\n  bypass_patterns:\n    - \"*.md\"\n    - \".github/**\"\n    - \"*.tf\"\n    - \"Cargo.toml\"\n    - \"package.json\"\n```\n\n## TDD Agents\n\nThe SDLC enforces strict TDD boundaries through specialized agents:\n\n| Agent | Responsibility | Can Edit |\n|-------|----------------|----------|\n| `sdlc:red` | Write failing tests | Test files only |\n| `sdlc:green` | Make tests pass | Production code only |\n| `sdlc:domain` | Create type definitions, PR domain review | Type signatures only |\n| `sdlc:mutation` | Run mutation testing | Read-only |\n| `sdlc:code-reviewer` | Three-stage PR review (spec, quality, domain) | Read-only |\n\nThese boundaries are **inviolable** - each agent can only edit its designated files.\n\n## Development Modes\n\n### Event Modeling (Applications)\n\nFor event-sourced applications:\n- Workflow → Vertical Slice → Component → Subtask hierarchy\n- GWT scenarios as acceptance criteria\n- Event/Command/ReadModel/Automation documentation\n\n### Traditional (Libraries/Utilities)\n\nFor libraries, utilities, and legacy applications:\n- Feature → Subtask hierarchy\n- Architecture documentation focus\n- PRD-driven development\n\n## GitHub Integration\n\nThe SDLC manages your GitHub workflow:\n\n1. **Issues** become work items with sub-issue support\n2. **Project boards** track status (Backlog → Ready → In Progress → Review → Done)\n3. **PRs** link to issues and close them on merge\n4. **Review comments** are addressed in-thread\n\n## Auto-Approval Patterns\n\nAdd these to your Claude Code settings for smoother workflow:\n\n```\nBash(gh issue *)\nBash(gh issue-ext *)\nBash(gh project *)\nBash(gh project-ext *)\nBash(gh pr-review *)\nBash(gs *)  # if using git-spice\n```\n\n## Documentation\n\n- `docs/tdd/TDD_WORKFLOW.md` - TDD process and principles\n- `docs/domain-modeling/principles.md` - Domain modeling guidelines\n- `docs/event-modeling/methodology.md` - Event modeling approach\n\n## Related Plugins\n\n- **marvin-output-style** - Marvin personality (standalone, works with or without SDLC)\n"
      },
      "plugins": [
        {
          "name": "sdlc",
          "source": "./sdlc",
          "description": "Complete SDLC workflow with TDD, Event Modeling, ADRs, GitHub integration, and Marvin personality",
          "version": "3.12.8",
          "keywords": [
            "sdlc",
            "tdd",
            "event-modeling",
            "adr",
            "github",
            "workflow",
            "domain-modeling",
            "mutation-testing",
            "marvin",
            "output-style",
            "code-review",
            "debugging",
            "worktrees",
            "compile-time-enforcement",
            "hooks",
            "todo-enforcement"
          ],
          "categories": [
            "adr",
            "code-review",
            "compile-time-enforcement",
            "debugging",
            "domain-modeling",
            "event-modeling",
            "github",
            "hooks",
            "marvin",
            "mutation-testing",
            "output-style",
            "sdlc",
            "tdd",
            "todo-enforcement",
            "workflow",
            "worktrees"
          ],
          "install_commands": [
            "/plugin marketplace add jwilger/claude-code-plugins",
            "/plugin install sdlc@jwilger-claude-plugins"
          ]
        },
        {
          "name": "bootstrap",
          "source": "./bootstrap",
          "description": "Intelligent Nix devshell bootstrapper for any language or framework",
          "version": "1.0.0",
          "keywords": [
            "bootstrap",
            "scaffolding",
            "nix",
            "flake",
            "devshell",
            "development-environment",
            "language-agnostic"
          ],
          "categories": [
            "bootstrap",
            "development-environment",
            "devshell",
            "flake",
            "language-agnostic",
            "nix",
            "scaffolding"
          ],
          "install_commands": [
            "/plugin marketplace add jwilger/claude-code-plugins",
            "/plugin install bootstrap@jwilger-claude-plugins"
          ]
        }
      ]
    }
  ]
}