{
  "author": {
    "id": "mberto10",
    "display_name": "mberto10",
    "avatar_url": "https://avatars.githubusercontent.com/u/187267963?v=4"
  },
  "marketplaces": [
    {
      "name": "mberto-compound",
      "version": null,
      "description": "Personal collection of Claude Code plugins, commands, and configurations",
      "repo_full_name": "mberto10/mberto-compound",
      "repo_url": "https://github.com/mberto10/mberto-compound",
      "repo_description": "Personal collection of Claude Code plugins, commands, and configurations",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-02-16T21:44:06Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"mberto-compound\",\n  \"owner\": {\n    \"name\": \"Maximilian Bruhn\",\n    \"email\": \"puzzle.ai.studio@gmail.com\"\n  },\n  \"metadata\": {\n    \"description\": \"Personal collection of Claude Code plugins, commands, and configurations\",\n    \"version\": \"1.0.0\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"langfuse-analyzer\",\n      \"source\": \"./plugins/langfuse-analyzer\",\n      \"description\": \"Surgical Langfuse trace retrieval with multiple output modes for LLM-friendly debugging and optimization workflows\",\n      \"version\": \"0.1.0\",\n      \"author\": {\n        \"name\": \"Writing Ecosystem Team\"\n      },\n      \"homepage\": \"https://github.com/mberto10/mberto-compound\",\n      \"repository\": \"https://github.com/mberto10/mberto-compound\",\n      \"license\": \"MIT\",\n      \"keywords\": [\n        \"langfuse\",\n        \"tracing\",\n        \"debugging\",\n        \"observability\",\n        \"optimization\"\n      ],\n      \"category\": \"observability\"\n    },\n    {\n      \"name\": \"langdock-dev\",\n      \"source\": \"./plugins/langdock-dev\",\n      \"description\": \"Build Langdock integration actions and use Langdock APIs with live documentation fetching\",\n      \"version\": \"0.1.0\",\n      \"author\": {\n        \"name\": \"Maximilian Bruhn\",\n        \"email\": \"puzzle.ai.studio@gmail.com\"\n      },\n      \"homepage\": \"https://github.com/mberto10/mberto-compound\",\n      \"repository\": \"https://github.com/mberto10/mberto-compound\",\n      \"license\": \"MIT\",\n      \"keywords\": [\n        \"langdock\",\n        \"integrations\",\n        \"actions\",\n        \"api\",\n        \"development\"\n      ],\n      \"category\": \"development\"\n    },\n    {\n      \"name\": \"writing-studio\",\n      \"source\": \"./plugins/writing-studio\",\n      \"description\": \"Comprehensive writing assistant with quality loop workflow: deep discovery, voice profiles, iterative self-critique, and publication-ready output\",\n      \"version\": \"2.0.0\",\n      \"author\": {\n        \"name\": \"Maximilian Bruhn\",\n        \"email\": \"puzzle.ai.studio@gmail.com\"\n      },\n      \"homepage\": \"https://github.com/mberto10/mberto-compound\",\n      \"repository\": \"https://github.com/mberto10/mberto-compound\",\n      \"license\": \"MIT\",\n      \"keywords\": [\n        \"writing\",\n        \"style\",\n        \"drafting\",\n        \"editing\",\n        \"brainstorming\",\n        \"content\",\n        \"workflow\",\n        \"critique\",\n        \"voice\",\n        \"quality-loop\"\n      ],\n      \"category\": \"writing\"\n    },\n    {\n      \"name\": \"work-toolkit\",\n      \"source\": \"./plugins/work-toolkit\",\n      \"description\": \"Personal management plugin for daily planning with Linear, German business communication, and YouTrack documentation\",\n      \"version\": \"0.1.0\",\n      \"author\": {\n        \"name\": \"Maximilian Bruhn\",\n        \"email\": \"puzzle.ai.studio@gmail.com\"\n      },\n      \"homepage\": \"https://github.com/mberto10/mberto-compound\",\n      \"repository\": \"https://github.com/mberto10/mberto-compound\",\n      \"license\": \"MIT\",\n      \"keywords\": [\n        \"productivity\",\n        \"planning\",\n        \"linear\",\n        \"youtrack\",\n        \"communication\",\n        \"german\",\n        \"documentation\"\n      ],\n      \"category\": \"productivity\"\n    },\n    {\n      \"name\": \"openai-apps-sdk\",\n      \"source\": \"./plugins/openai-apps-sdk\",\n      \"description\": \"Comprehensive toolkit for building MCP servers with the OpenAI Apps SDK. Provides skills, commands, and agents for creating ChatGPT apps with Python and TypeScript.\",\n      \"version\": \"0.1.0\",\n      \"author\": {\n        \"name\": \"Maximilian Bruhn\",\n        \"email\": \"puzzle.ai.studio@gmail.com\"\n      },\n      \"homepage\": \"https://github.com/mberto10/mberto-compound\",\n      \"repository\": \"https://github.com/mberto10/mberto-compound\",\n      \"license\": \"MIT\",\n      \"keywords\": [\n        \"openai\",\n        \"apps-sdk\",\n        \"mcp\",\n        \"model-context-protocol\",\n        \"chatgpt\",\n        \"mcp-server\",\n        \"widgets\"\n      ],\n      \"category\": \"development\"\n    },\n    {\n      \"name\": \"compound-loop\",\n      \"source\": \"./plugins/compound-loop\",\n      \"description\": \"Structured feedback loop for capturing learnings from plugin usage anywhere and consolidating them into improvements\",\n      \"version\": \"0.1.0\",\n      \"author\": {\n        \"name\": \"Maximilian Bruhn\",\n        \"email\": \"puzzle.ai.studio@gmail.com\"\n      },\n      \"homepage\": \"https://github.com/mberto10/mberto-compound\",\n      \"repository\": \"https://github.com/mberto10/mberto-compound\",\n      \"license\": \"MIT\",\n      \"keywords\": [\n        \"compounding\",\n        \"feedback-loop\",\n        \"learning\",\n        \"meta\",\n        \"self-improvement\"\n      ],\n      \"category\": \"meta\"\n    },\n    {\n      \"name\": \"continuous-compound\",\n      \"source\": \"./plugins/continuous-compound\",\n      \"description\": \"Long-running agent continuity via Linear + compound loop learning extraction\",\n      \"version\": \"1.0.0\",\n      \"author\": {\n        \"name\": \"Maximilian Bruhn\",\n        \"email\": \"puzzle.ai.studio@gmail.com\"\n      },\n      \"homepage\": \"https://github.com/mberto10/mberto-compound\",\n      \"repository\": \"https://github.com/mberto10/mberto-compound\",\n      \"license\": \"MIT\",\n      \"keywords\": [\n        \"linear\",\n        \"continuity\",\n        \"compound-loop\",\n        \"long-running-tasks\"\n      ],\n      \"category\": \"productivity\"\n    },\n    {\n      \"name\": \"daily-metrics\",\n      \"source\": \"./plugins/daily-metrics\",\n      \"description\": \"Personal tracking and goal management system with Supabase integration\",\n      \"version\": \"0.1.0\",\n      \"author\": {\n        \"name\": \"Maximilian Bruhn\",\n        \"email\": \"puzzle.ai.studio@gmail.com\"\n      },\n      \"homepage\": \"https://github.com/mberto10/mberto-compound\",\n      \"repository\": \"https://github.com/mberto10/mberto-compound\",\n      \"license\": \"MIT\",\n      \"keywords\": [\n        \"habits\",\n        \"tracking\",\n        \"goals\",\n        \"metrics\",\n        \"personal-development\"\n      ],\n      \"category\": \"personal\"\n    },\n    {\n      \"name\": \"ux-evaluator\",\n      \"source\": \"./plugins/ux-evaluator\",\n      \"description\": \"Frontend UX evaluation using User Lifecycle Framework and Playwright browser automation\",\n      \"version\": \"0.1.0\",\n      \"author\": {\n        \"name\": \"Dispatch Team\"\n      },\n      \"homepage\": \"https://github.com/mberto10/mberto-compound\",\n      \"repository\": \"https://github.com/mberto10/mberto-compound\",\n      \"license\": \"MIT\",\n      \"keywords\": [\n        \"ux\",\n        \"frontend\",\n        \"evaluation\",\n        \"playwright\",\n        \"user-lifecycle\",\n        \"testing\"\n      ],\n      \"category\": \"testing\"\n    },\n    {\n      \"name\": \"agentic-optimization-loop\",\n      \"source\": \"./plugins/agentic-optimization-loop\",\n      \"description\": \"Iterative optimization loops for AI agents with hypothesis-driven improvement cycles. Guides you through Build -> Evaluate -> Analyze -> Improve -> Compound cycles with persistent state.\",\n      \"version\": \"0.1.0\",\n      \"author\": {\n        \"name\": \"Maximilian Bruhn\",\n        \"email\": \"puzzle.ai.studio@gmail.com\"\n      },\n      \"homepage\": \"https://github.com/mberto10/mberto-compound\",\n      \"repository\": \"https://github.com/mberto10/mberto-compound\",\n      \"license\": \"MIT\",\n      \"keywords\": [\n        \"optimization\",\n        \"agentic\",\n        \"hypothesis-driven\",\n        \"improvement-cycles\",\n        \"evaluation\"\n      ],\n      \"category\": \"development\"\n    },\n    {\n      \"name\": \"compound-engineering\",\n      \"source\": \"./plugins/compound-engineering\",\n      \"description\": \"Portable compound engineering workflow: Plan, Work, Review, Compound. Powered by subsystem knowledge files for dependency-aware planning and contract verification. Each unit of work makes subsequent work easier.\",\n      \"version\": \"0.1.0\",\n      \"author\": {\n        \"name\": \"Maximilian Bruhn\",\n        \"email\": \"puzzle.ai.studio@gmail.com\"\n      },\n      \"homepage\": \"https://github.com/mberto10/mberto-compound\",\n      \"repository\": \"https://github.com/mberto10/mberto-compound\",\n      \"license\": \"MIT\",\n      \"keywords\": [\n        \"compound-engineering\",\n        \"planning\",\n        \"subsystem-knowledge\",\n        \"contract-verification\",\n        \"workflow\"\n      ],\n      \"category\": \"development\"\n    }\n  ]\n}",
        "README.md": "# Claude Marketplace\n\nPersonal collection of Claude Code plugins, commands, agents, skills, and configurations.\n\n## Installation\n\n### Add the Marketplace\n\nIn Claude Code, run:\n\n\n/plugin marketplace add mberto10/mberto-compound\n```\n\n### Install Plugins\n\nAfter adding the marketplace, install plugins with:\n\n```\n/plugin install example-plugin@mberto-compound\n```\n\n### Other Commands\n\n```bash\n# Browse all plugins\n/plugin\n\n# List known marketplaces\n/plugin marketplace list\n\n# Update marketplace\n/plugin marketplace update mberto-compound\n\n# Remove marketplace\n/plugin marketplace remove mberto-compound\n```\n\n## Available Plugins\n\n| Plugin | Description | Category |\n|--------|-------------|----------|\n| `example-plugin` | Example plugin demonstrating structure for commands, agents, skills, and hooks | utility |\n\n## Structure\n\n```\nclaude-marketplace/\n├── .claude-plugin/\n│   └── marketplace.json      # Marketplace configuration\n└── plugins/\n    └── example-plugin/       # Example plugin (template)\n        ├── .claude-plugin/\n        │   └── plugin.json   # Plugin metadata\n        ├── .mcp.json         # MCP server configuration\n        ├── agents/           # Custom agents\n        ├── commands/         # Slash commands\n        ├── hooks/            # Lifecycle hooks\n        └── skills/           # Autonomous skills\n```\n\n## Creating New Plugins\n\n1. Create a new directory under `plugins/`:\n   ```bash\n   mkdir -p plugins/my-plugin/{commands,agents,skills,hooks,.claude-plugin}\n   ```\n\n2. Add `.claude-plugin/plugin.json`:\n   ```json\n   {\n     \"name\": \"my-plugin\",\n     \"version\": \"1.0.0\",\n     \"description\": \"My custom plugin\",\n     \"author\": {\n       \"name\": \"Your Name\"\n     },\n     \"license\": \"MIT\"\n   }\n   ```\n\n3. Add components as needed:\n   - **Commands**: `.md` files in `commands/`\n   - **Agents**: `.md` files in `agents/`\n   - **Skills**: Directories in `skills/` with `SKILL.md`\n   - **Hooks**: `hooks.json` in `hooks/`\n   - **MCP Servers**: `.mcp.json` in plugin root\n\n4. Register in `.claude-plugin/marketplace.json`:\n   ```json\n   {\n     \"plugins\": [\n       {\n         \"name\": \"my-plugin\",\n         \"source\": \"./plugins/my-plugin\",\n         \"description\": \"My custom plugin\",\n         \"version\": \"1.0.0\",\n         \"author\": {\n           \"name\": \"Your Name\"\n         },\n         \"category\": \"utility\"\n       }\n     ]\n   }\n   ```\n\n## Using in Team Projects\n\nAdd to your project's `.claude/settings.json` for automatic installation:\n\n```json\n{\n  \"extraKnownMarketplaces\": {\n    \"mberto-compound\": {\n      \"source\": {\n        \"source\": \"github\",\n        \"repo\": \"mberto10/mberto-compound\"\n      }\n    }\n  },\n  \"enabledPlugins\": [\n    \"example-plugin@mberto-compound\"\n  ]\n}\n```\n\n## License\n\nMIT\n",
        "plugins/langfuse-analyzer/README.md": "# langfuse-analyzer\n\nOverview of the plugin surface area for Langfuse-based agent engineering workflows.\n\n## What this plugin covers\n\n- Langfuse instrumentation and observability\n- Trace/session/score analysis\n- Prompt and schema management\n- Dataset curation and experiment execution\n- Evaluation infrastructure setup (`eval_infra_v1`) and compatibility export\n\n## Commands (overview)\n\n| Command | Purpose |\n|---|---|\n| `agent-eval-init` | Interview + tracing-context scan to generate an initial eval-infra planning doc |\n| `optimize-bootstrap` | Bootstrap optimization prerequisites and export eval handoff snapshot for `/optimize` |\n| `agent-eval-infra` | Inspect/bootstrap/export Langfuse-first evaluation infrastructure |\n| `agent-eval-setup` | Discover an agent and set up eval infrastructure end-to-end |\n| `agent-eval` | Run evaluation cycles, analyze failures, and report findings |\n| `setup-dataset` | Interactive dataset + judge bootstrap with `eval_infra_v1` metadata |\n\n## Skills (overview)\n\n| Skill | Focus |\n|---|---|\n| `langfuse-agent-advisor` | Strategy and planning for agent quality improvement |\n| `langfuse-annotation-manager` | Human annotation and scoring workflows |\n| `langfuse-data-retrieval` | Targeted trace retrieval for debugging and analysis |\n| `langfuse-dataset-management` | Dataset creation and trace-to-dataset curation |\n| `langfuse-eval-infrastructure` | Canonical eval contract, judges, baseline, and snapshot export |\n| `langfuse-experiment-runner` | Running experiments and analyzing run results |\n| `Langfuse Instrumentation Setup` | Adding Langfuse traces/spans/generations correctly |\n| `langfuse-prompt-management` | Prompt CRUD, versioning, and label promotion |\n| `langfuse-schema-validator` | Contract checks between prompt output schema and function schema |\n| `langfuse-score-analytics` | Score trends, distributions, and regression detection |\n| `langfuse-session-analysis` | Multi-trace session flow and session-level diagnostics |\n| `langfuse-trace-analysis` | Root-cause analysis linking traces to code behavior |\n\n## Key references\n\n- `references/eval-infra-schema.md`\n- `references/eval-calibration-protocol.md`\n\n## Current evaluation architecture (high level)\n\n- Source of truth: Langfuse dataset metadata (`eval_infra_v1`)\n- Judge definitions: Langfuse prompt registry (`judge-*`)\n- Local handoff snapshots:\n  - `.claude/eval-infra/<agent>.json`\n  - `.claude/eval-infra/<agent>.yaml`\n  - `.claude/agent-eval/<agent>.yaml` (compatibility projection)\n",
        "plugins/writing-studio/README.md": "# Writing Studio\n\nA writing assistant built around the **plan-work-review-compound** loop with taste profiles that evolve through use.\n\n## The Loop\n\n```\nYOU PLAN → WRITE (skill) → YOU REVIEW → REVIEW (skill) → COMPOUND (profile evolves)\n```\n\n1. **Plan** (you) — Look at a text, decide what to write, give direction\n2. **Work** (`/write`) — The taste-writer skill writes in the active profile's voice\n3. **Review** (`/review`) — You give feedback, the taste-reviewer proposes profile-aligned rewrites\n4. **Compound** (`/profile compound`) — Feedback patterns get absorbed into the taste profile itself\n\nOver time, your taste profiles get sharper because they absorb your preferences.\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `/write [topic]` | Write content using a taste profile |\n| `/review [file]` | Review writing against a taste profile, propose rewrites |\n| `/profile [samples]` | Create a new taste profile from writing samples |\n| `/profile compound` | Refine an existing taste profile based on feedback patterns |\n\n## Taste Profiles\n\nTaste profiles live in `taste-profiles/` and capture 12 dimensions of a writing voice:\n\n1. Voice Architecture\n2. Tonal Signature\n3. Structural Patterns\n4. Vocabulary Fingerprint\n5. Rhythm & Cadence\n6. Rhetorical Devices\n7. Cognitive Patterns\n8. Emotional Register\n9. Authority Stance\n10. Reader Relationship\n11. Topic Treatment\n12. Distinctive Markers\n\n### Creating Profiles\n\n```bash\n# From writing samples\n/profile path/to/samples/\n\n# From a single file\n/profile my-writing.md\n```\n\n### Compounding Profiles\n\nAfter write/review cycles, when you notice the profile consistently misses something:\n\n```bash\n/profile compound\n```\n\nThis captures your feedback patterns into the profile itself.\n\n## Skills\n\n| Skill | Role in Loop |\n|-------|-------------|\n| **taste-writer** | Writes content in the active profile's voice |\n| **taste-reviewer** | Translates your feedback into profile-aligned rewrites |\n| **taste-profiler** | Creates and compounds taste profiles |\n\n## License\n\nMIT\n",
        "plugins/work-toolkit/README.md": "# work-toolkit\n\nPersonal management plugin for daily planning with Linear, German business communication, YouTrack documentation, and meeting preparation.\n\n## Features\n\n- **Daily Planning** - Morning routine with Linear task review and prioritization\n- **Meeting Preparation** - JF, stakeholder updates, and Lenkungsausschuss prep\n- **German Communication** - Email drafting for status updates and meeting follow-ups\n- **Content Structuring** - Presentations, documentation, and milestone planning\n- **Linear Integration** - Query and manage personal tasks\n- **YouTrack Integration** - Project documentation and KW updates\n\n## Installation\n\n```bash\n/plugin work-toolkit\n```\n\n## Prerequisites\n\nSet environment variables:\n\n```bash\n# Linear API\nexport LINEAR_API_KEY=\"lin_api_xxxxxxxxxxxxxxxx\"\n\n# YouTrack API\nexport YOUTRACK_API_TOKEN=\"perm:xxxxxxxxxxxxxxxx\"\n```\n\n## Commands\n\n### Daily Workflow\n| Command | Description | Example |\n|---------|-------------|---------|\n| `/start-day` | Morning planning session | `/start-day today` |\n| `/linear` | Manage Linear tasks | `/linear tasks` |\n\n### Communication\n| Command | Description | Example |\n|---------|-------------|---------|\n| `/draft-email` | Draft German emails | `/draft-email status RAG Update` |\n| `/weekly-email` | Compile Lenkungsausschuss update | `/weekly-email --kw=51` |\n\n### Meeting Preparation\n| Command | Description | Example |\n|---------|-------------|---------|\n| `/prepare-jf` | Prepare Jour Fixe meeting | `/prepare-jf \"RAG Pipeline\"` |\n| `/prepare-update` | Prepare update for audience | `/prepare-update stakeholder` |\n\n### Project Planning\n| Command | Description | Example |\n|---------|-------------|---------|\n| `/generate-milestones` | Generate project milestones | `/generate-milestones \"Chatbot\"` |\n| `/structure` | Structure content | `/structure pres Architecture` |\n\n### YouTrack\n| Command | Description | Example |\n|---------|-------------|---------|\n| `/youtrack` | Query YouTrack | `/youtrack get AI-74` |\n| `/update-youtrack-epic` | Post KW update | `/update-youtrack-epic \"Project\"` |\n\n## Skills\n\nAuto-activating knowledge:\n\n- **Meetings Workflow** - JF prep, stakeholder updates, agenda templates\n- **YouTrack Dashboard** - YouTrack API, KW updates, project tracking\n- **Linear Workflow** - Task management, daily planning\n- **German Business Communication** - Email templates, tone guidance\n- **Content Structuring** - Presentations, documentation, milestone planning\n\n## Workflows\n\n### Daily Workflow\n```\nMorning:   /start-day → Review Linear → Plan day\nDuring:    Work tasks → /linear progress <id>\nComms:     /draft-email status → Review → Send\nEvening:   /linear done <id> → Update YouTrack docs\n```\n\n### Weekly Workflow\n```\nMonday:    /start-day week → Plan weekly priorities\nFriday:    /weekly-email → Send Lenkungsausschuss update\n           /update-youtrack-epic → Update project KW comments\n```\n\n### Meeting Preparation\n```\nBefore JF:       /prepare-jf \"Project\" → Review → Print/Share\nBefore Update:   /prepare-update stakeholder → Tailor message\nNew Project:     /generate-milestones \"Project\" → Review → Create issues\n```\n\n## Helper Tools\n\nCLI scripts in `helper_tools/`:\n\n```bash\n# Linear\npython helper_tools/linear/linear.py tasks\npython helper_tools/linear/linear.py create \"New task\"\npython helper_tools/linear/linear.py done ABC-123\n\n# YouTrack\npython helper_tools/youtrack/yt.py get AI-74\npython helper_tools/youtrack/yt.py comment AI-74 \"Update text\"\npython helper_tools/youtrack/get_kw_updates.py --kw=51\n```\n\n## Project Structure\n\n```\nwork-toolkit/\n├── .claude-plugin/plugin.json\n├── skills/\n│   ├── meetings-workflow/      # NEW: JF and update prep\n│   ├── youtrack-dashboard/\n│   ├── linear-workflow/\n│   ├── communication/\n│   └── structuring/\n├── commands/\n│   ├── start-day.md\n│   ├── draft-email.md\n│   ├── structure.md\n│   ├── linear.md\n│   ├── youtrack.md\n│   ├── update-youtrack-epic.md\n│   ├── weekly-email.md\n│   ├── prepare-jf.md           # NEW\n│   ├── prepare-update.md       # NEW\n│   └── generate-milestones.md  # NEW\n└── helper_tools/\n    ├── linear/\n    └── youtrack/\n```\n\n## Configuration\n\n### Linear\n- Get API key from Linear Settings → API\n- Key format: `lin_api_xxxxx`\n\n### YouTrack\n- Base URL: `https://fazit.youtrack.cloud`\n- Get token from Profile → Account Security\n- Default project: AI (ID: 0-331)\n",
        "plugins/openai-apps-sdk/README.md": "# OpenAI Apps SDK Plugin\n\nA comprehensive Claude Code plugin for building MCP servers with the OpenAI Apps SDK. Provides skills, commands, and agents for creating ChatGPT apps with Python and TypeScript.\n\n## Features\n\n### Skills (8)\n\n#### Development Skills\n\n| Skill | Triggers | Purpose |\n|-------|----------|---------|\n| **mcp-server-architecture** | \"create MCP server\", \"set up server\" | Core setup, transport types, SDK patterns |\n| **mcp-tool-design** | \"define tool\", \"tool schema\", \"inputSchema\" | Tool definitions, annotations, schemas |\n| **mcp-widget-development** | \"build widget\", \"window.openai\" | HTML widgets, ChatGPT UI integration |\n| **mcp-authentication** | \"OAuth\", \"authentication\", \"security\" | OAuth 2.1, protected resources |\n| **mcp-state-management** | \"widget state\", \"session\", \"persist\" | State APIs, session management |\n| **mcp-deployment-testing** | \"deploy MCP\", \"test server\", \"ngrok\" | HTTPS, testing, ChatGPT connectors |\n\n#### UX Design Skills\n\n| Skill | Triggers | Purpose |\n|-------|----------|---------|\n| **mcp-ux-brainstorming** | \"brainstorm app ideas\", \"design ChatGPT app\", \"ideate widget UX\" | MCP-native design thinking, concept evaluation |\n| **mcp-widget-patterns** | \"widget pattern\", \"inline card\", \"carousel\", \"fullscreen mode\" | Widget pattern catalog with implementations |\n\n### Commands (2)\n\n| Command | Usage | Purpose |\n|---------|-------|---------|\n| `/openai-apps-sdk:scaffold` | `/scaffold --lang python` | Generate starter MCP server project |\n| `/openai-apps-sdk:validate` | `/validate` | Check server against best practices |\n\n### Agents (1)\n\n| Agent | Triggers | Purpose |\n|-------|----------|---------|\n| **mcp-server-reviewer** | \"review my MCP server\" | Comprehensive code review |\n\n## Installation\n\n### Option 1: Clone to plugins directory\n\n```bash\ngit clone <repo-url> ~/.claude/plugins/openai-apps-sdk\n```\n\n### Option 2: Local development\n\n```bash\nclaude --plugin-dir /path/to/openai-apps-sdk\n```\n\n## Usage\n\n### Get started with a new server\n\n```\n> /openai-apps-sdk:scaffold --lang python\n```\n\nThis creates a minimal MCP server project with:\n- Server file with example tool\n- Widget template\n- Configuration files\n- README with setup instructions\n\n### Validate your implementation\n\n```\n> /openai-apps-sdk:validate\n```\n\nChecks your MCP server for:\n- Tool definition best practices\n- Response pattern correctness\n- Security issues\n- Widget compliance\n\n### Get help while developing\n\nAsk questions that trigger skills:\n\n```\n> How do I create an MCP tool?\n> How do I handle OAuth in my MCP server?\n> How do I persist widget state?\n```\n\n### Brainstorm and design UX\n\nUse the UX design skills for ideation:\n\n```\n> Help me brainstorm a ChatGPT app for my restaurant booking service\n> What widget pattern should I use for showing search results?\n> How should I design the user experience for my e-commerce app?\n```\n\n### Request a code review\n\n```\n> Review my MCP server and check for issues\n```\n\n## Supported Languages\n\n- **Python** - Using FastMCP and the official Python SDK\n- **TypeScript** - Using @modelcontextprotocol/sdk\n\n## Key Documentation Sources\n\n| Resource | URL |\n|----------|-----|\n| Apps SDK Docs | https://developers.openai.com/apps-sdk/ |\n| Apps SDK Reference | https://developers.openai.com/apps-sdk/reference/ |\n| UI Kit | https://github.com/openai/apps-sdk-ui |\n| UX Principles | https://developers.openai.com/apps-sdk/concepts/ux-principles/ |\n| UI Guidelines | https://developers.openai.com/apps-sdk/concepts/ui-guidelines/ |\n| MCP Specification | https://modelcontextprotocol.io/specification/ |\n| Python SDK | https://github.com/modelcontextprotocol/python-sdk |\n| TypeScript SDK | https://github.com/modelcontextprotocol/typescript-sdk |\n| Examples Repo | https://github.com/openai/openai-apps-sdk-examples |\n\n## Development\n\n### Plugin Structure\n\n```\nopenai-apps-sdk/\n├── .claude-plugin/\n│   └── plugin.json\n├── skills/\n│   ├── mcp-server-architecture/   # Server setup & SDKs\n│   ├── mcp-tool-design/           # Tool schemas & annotations\n│   ├── mcp-widget-development/    # Widget HTML & window.openai\n│   ├── mcp-authentication/        # OAuth & security\n│   ├── mcp-state-management/      # State persistence\n│   ├── mcp-deployment-testing/    # Deploy & test\n│   ├── mcp-ux-brainstorming/      # UX ideation & evaluation\n│   └── mcp-widget-patterns/       # Widget pattern catalog\n├── commands/\n│   ├── scaffold.md\n│   └── validate.md\n├── agents/\n│   └── mcp-server-reviewer.md\n└── templates/\n    ├── python/\n    └── typescript/\n```\n\n### Testing\n\nTest the plugin by running Claude Code with:\n\n```bash\nclaude --plugin-dir /path/to/openai-apps-sdk\n```\n\nThen test:\n- Skills trigger on appropriate questions\n- Commands work correctly\n- Agent provides helpful reviews\n\n## License\n\nMIT\n",
        "plugins/compound-loop/README.md": "# Compound Loop Plugin\n\nThis plugin provides a structured improvement cycle for Claude Code workflows, centered on the loop:\n**Plan → Work → Review → Compound**. The goal is to convert session learnings into reusable, testable\nknowledge so each iteration becomes more capable than the last. The plugin focuses on skills,\ncommands, and references (hooks are intentionally out of scope here). See\n`references/compounding-methodology.md` for the underlying philosophy and decision gates.\n\n## Commands\n\n### `/compound:reflect`\nCapture learnings from the current session into a structured artifact. This produces 1-line,\ntestable learnings with source references and a prioritized list of proposed changes.\n\n### `/compound:discover`\nExtract repeatable patterns from recent work and generate specifications for new components\n(skills, commands, agents). This is for creating *new* modular capabilities.\n\n### `/compound:consolidate`\nReview pending learning artifacts, get explicit approval, and implement the approved changes into\nthe plugin source.\n\n## Skills\n\n- **Improvement Cycle Setup**: The in-the-moment mindset for noticing friction and encoding\n  learnings while you work.\n- **Reflection Craft**: A structured workflow for converting session outcomes into actionable,\n  testable learnings.\n- **Discovery Craft**: A pattern-extraction workflow that selects the right component type and\n  produces implementation-ready specs.\n- **Consolidation Craft**: The review and implementation workflow that turns learnings into\n  permanent improvements.\n\n## References\n\n- **Compounding Methodology**: The philosophy, heuristics, and decision gates for what to encode\n  and how to keep improvements high-signal.\n",
        "plugins/daily-metrics/README.md": "# daily-metrics\n\nPersonal tracking and goal management plugin for Claude Code, integrated with Supabase.\n\n## Features\n\n- **Daily Logging**: Parse freeform notes into structured metric entries with preview\n- **Progress Visualization**: ASCII charts with flexible timeframes and period comparison\n- **Metric Management**: Create, update, and organize trackable metrics\n- **Goal Tracking**: Set targets, track streaks, monitor completion rates\n- **Periodic Reviews**: Weekly/monthly summaries with trend analysis and adjustment suggestions\n\n## Prerequisites\n\n- Supabase MCP server connected to project `ezwdpxbbqmsqqmafqxpw`\n- Database schema with:\n  - `tracking_categories`\n  - `metric_definitions`\n  - `daily_entries`\n  - `metric_versions`\n\n## Installation\n\n### Option 1: Plugin directory flag\n```bash\nclaude --plugin-dir /path/to/daily-metrics\n```\n\n### Option 2: Copy to plugins folder\n```bash\ncp -r daily-metrics ~/.claude/plugins/\n```\n\n## Commands\n\n| Command | Description | Example |\n|---------|-------------|---------|\n| `/log` | Log daily entries from freeform text | `/log meditated, slept 7h, weight 74.8kg` |\n| `/progress` | Visualize progress with ASCII charts | `/progress weight last 30 days` |\n| `/metrics` | Manage metric definitions | `/metrics create`, `/metrics list` |\n| `/goals` | Set and track goals | `/goals set meditation`, `/goals streaks` |\n| `/review` | Run periodic reviews | `/review week`, `/review month` |\n\n## Usage Examples\n\n### Logging Daily Entries\n```\n/log Did my morning meditation, read for 45 minutes, skipped exercise.\n     Slept about 7.5 hours. Weight at 74.8kg, feeling good - mood 8/10.\n```\n\nThe plugin will:\n1. Parse your freeform text\n2. Show a preview table of extracted metrics\n3. Ask for confirmation before saving\n\n### Viewing Progress\n```\n/progress              # Overview dashboard\n/progress weight       # Weight trend\n/progress sleep last 14 days\n/progress this week vs last\n```\n\n### Setting Goals\n```\n/goals set meditation   # Set a goal for meditation (streaks, completion rate)\n/goals view            # See all goal progress\n/goals streaks         # View current and best streaks\n```\n\n### Weekly Reviews\n```\n/review week           # Analyze last 7 days with insights\n/review month          # Monthly summary with trends\n```\n\n## Components\n\n### Commands (5)\n- `log.md` - Parse and save daily entries\n- `progress.md` - Generate ASCII visualizations\n- `metrics.md` - CRUD for metric definitions\n- `goals.md` - Goal setting and tracking\n- `review.md` - Periodic review analysis\n\n### Agent (1)\n- `entry-parser` - Parses natural language into structured metrics\n\n### Skills (2)\n- `goal-methodology` - SMART goals, habit formation, adjustment strategies\n- `ascii-charts` - Patterns for terminal-based data visualization\n\n## Database Schema\n\nThe plugin works with this Supabase schema:\n\n```\ntracking_categories     # Habits, Health, Sleep, Nutrition, Exercise, Mood\n       ↓\nmetric_definitions      # What you track (name, data_type, unit, goals)\n       ↓\ndaily_entries          # Your actual data (date + value)\n       ↓\nmetric_versions        # Audit trail of definition changes\n```\n\n## Author\n\nMaximilian Bruhn\n",
        "plugins/ux-evaluator/README.md": "# UX Evaluator Plugin\n\nFrontend UX evaluation and production readiness testing using the User Lifecycle Framework and Playwright browser automation.\n\n## Overview\n\nThis plugin provides three complementary evaluation modes:\n\n1. **UX Evaluation** (`/ux-eval`) - Assess user experience quality against heuristics\n2. **Dogfooding** (`/dogfood`) - Experience the product as a real user, then trace issues to code\n3. **MCP Evaluation** (`/mcp-eval`) - Evaluate MCP-powered apps through conversational intent lens\n\n**Core principle:** \"As a user of this product, I can understand everything, it works flawlessly, and I see a lot of value out of it.\"\n\n## Three Evaluation Modes\n\n```\n┌───────────────────────────────────────────────────────────────────────────────────────────────┐\n│  /ux-eval                    /dogfood                      /mcp-eval                          │\n│  ─────────                   ─────────                     ──────────                         │\n│  UX Quality Assessment       Production Readiness          MCP App Evaluation                 │\n│                                                                                               │\n│  \"Does this feel right?\"     \"Does this work?\"             \"Does the tool→widget chain       │\n│                                                             serve user intents?\"              │\n│                                                                                               │\n│  • Apply heuristics          • Experience as user          • Derive persona from concept     │\n│  • Evaluate clarity          • Note confusion/friction     • Walk UI as that persona         │\n│  • Check accessibility       • Assess value delivery       • Evaluate each screen's chain    │\n│  • Generate UX report        • Trace issues to code        • Detect MCP failure patterns     │\n│                                                            • Categorize by layer             │\n│                                                                                               │\n│  Output: UX issues           Output: Experience report     Output: Improvements by layer     │\n│  with recommendations        + Technical analysis          (schema/output/widget/flow)       │\n└───────────────────────────────────────────────────────────────────────────────────────────────┘\n```\n\n**Recommended workflow:**\n1. Run `/dogfood` first - make sure it works\n2. Run `/ux-eval` second - make sure it feels right\n3. Run `/mcp-eval` for MCP apps - ensure tool→widget chain serves intents\n\n## MCP Evaluation Framework\n\nThe `/mcp-eval` mode uses a specialized framework for MCP-powered apps:\n\n### Why MCP Apps Need Different Evaluation\n\nFor MCP apps, users arrive at screens via LLM conversations. The evaluation must consider:\n- What tool calls would be made to serve the user's intent\n- Whether the tool output contains what the widget needs\n- Whether the widget presents information appropriately for the intent\n\n### MCP-Specific Failure Patterns\n\n| Pattern | Description |\n|---------|-------------|\n| Over-clarifying | Asking what could be inferred from context |\n| Under-clarifying | Committing without gathering necessary constraints |\n| Tool ping-pong | Multiple calls that could be batched |\n| Widget mismatch | Wrong display type for the user's intent |\n| Poor edit loop | Cannot refine without starting over |\n| No commit gate | Irreversible action without confirmation |\n| Error opacity | Technical errors shown verbatim |\n\n### Improvement Layers\n\nImprovements are categorized by what needs to change:\n\n| Layer | What Changes | Example |\n|-------|--------------|---------|\n| Tool Schema | Parameter definitions | Add `flexibility` param |\n| Tool Output | Response structure | Include `recommended` flag |\n| Widget | Display, controls | Add filter controls |\n| Flow | Screen sequence | Add confirmation step |\n\n### Two Modes\n\n- **Hypothetical tracing** - Infer tool calls from UI and codebase\n- **Actual tool calling** - Call MCP tools via HTTP endpoint to verify\n\n## User Lifecycle Framework\n\nThe `/ux-eval` and `/dogfood` modes use the 8-phase User Lifecycle Framework:\n\n| Phase | User Question | Goal |\n|-------|---------------|------|\n| DISCOVER | \"Why should I care?\" | Communicate value, convert visitors |\n| SIGN UP | \"Let me in\" | Frictionless authentication |\n| ONBOARD | \"Help me get started\" | Guide through initial setup |\n| ACTIVATE | \"Aha! This is useful\" | Deliver first value moment |\n| ADOPT | \"This is how I use it\" | Establish core usage loop |\n| ENGAGE | \"I check this regularly\" | Build habit, bring users back |\n| RETAIN | \"I can't work without this\" | Demonstrate ongoing value |\n| EXPAND | \"I want more\" | Growth, upgrades, referrals |\n\n## Usage\n\n### UX Evaluation\n\n```\n/ux-eval\n```\n\nInteractively asks for:\n1. Product context source (Linear or local file)\n2. Evaluation phase (lifecycle phase or custom focus)\n3. Starting URL\n\n**Output:**\n- UX report with heuristic assessment\n- Severity-rated findings\n- ASCII flow diagrams\n- Linear issues (optional)\n\n### Dogfooding (Production Readiness)\n\n```\n/dogfood\n```\n\nInteractively asks for:\n1. Product concept source (Linear or local file)\n2. Target flow (onboarding, core features, etc.)\n3. Starting URL\n4. Run technical analysis? (Yes/No)\n\n**Output:**\n- Experience report (user perspective)\n- Technical analysis (code investigation) - if selected\n- Combined Linear project with issues (optional)\n\n## Dogfooding: Two-Agent System\n\nThe dogfooding mode uses two specialized agents:\n\n```\n┌─────────────────────────────────────────────────────────────────────┐\n│  DOGFOODING EVALUATOR (User Perspective)                            │\n│  ─────────────────────────────────────────                          │\n│  • Adopts target user mindset from product concept                  │\n│  • Walks through the product naturally                              │\n│  • Documents: confusion, friction, broken features, missing value   │\n│  • Does NOT read code - stays in user perspective                   │\n│                                                                     │\n│  Output: Experience Report                                          │\n│  \"As a user, I found these issues...\"                               │\n└─────────────────────────────────────────────────────────────────────┘\n                              │\n                              ▼\n┌─────────────────────────────────────────────────────────────────────┐\n│  TECHNICAL DEBUGGER (Developer Perspective)                         │\n│  ──────────────────────────────────────────                         │\n│  • Takes experience report as input                                 │\n│  • Investigates codebase for each finding                           │\n│  • Traces issues to specific file:line locations                    │\n│  • Provides recommended code fixes                                  │\n│                                                                     │\n│  Output: Technical Analysis                                         │\n│  \"These issues stem from these code locations...\"                   │\n└─────────────────────────────────────────────────────────────────────┘\n```\n\n### Example Dogfooding Flow\n\n```\nUser: /dogfood \"onboarding flow\"\n\n─────────────────────────────────────────────────────────────────────\n\nDOGFOODING EVALUATOR runs...\n\nWalking onboarding as a new user...\n\nStep 1: Landed on /onboard ✓\nStep 2: Filled profile form ✓\nStep 3: Clicked \"Save\" → Nothing happened ✗\n        No feedback, no error, button just didn't respond\nStep 4: Refreshed page → My data is gone\n\nFINDING: Profile data doesn't persist after form submission\nIMPACT: Critical - Cannot proceed with onboarding\n\n─────────────────────────────────────────────────────────────────────\n\nTECHNICAL DEBUGGER runs...\n\nInvestigating: \"Profile save does nothing\"\n\n1. Found form component: src/components/OnboardingForm.tsx\n2. Found onSubmit handler at line 47\n3. Handler calls updateProfile() but doesn't await result\n4. API call returns 401 - auth token not included in headers\n\nROOT CAUSE: Auth header missing in API client\nLOCATION: src/services/api.ts:23\n\nRECOMMENDED FIX:\n+ 'Authorization': `Bearer ${getAuthToken()}`\n\n─────────────────────────────────────────────────────────────────────\n```\n\n## Product Context\n\nBefore evaluation, define your product context:\n\n### Option 1: Linear Document\n\nCreate a Linear document with your product concept:\n\n```markdown\n# Product Concept\n\n**Product Name:** Dispatch\n**Value Proposition:** Editorial command center that saves content teams 2 hours per day\n**Target User:** Content managers, editors, publishers\n**Core Loop:** Create briefing → Review AI suggestions → Publish\n**Success Metrics:** Time to first published briefing\n\n## Key Features\n- AI-powered content suggestions\n- Team collaboration\n- Multi-channel publishing\n\n## User Goals\n1. Create professional briefings quickly\n2. Maintain consistent brand voice\n3. Collaborate with team efficiently\n```\n\n### Option 2: Local File\n\nCreate `product_concept.md` or `.claude/ux-evaluator.local.md`:\n\n```yaml\n---\nproduct_name: \"Dispatch\"\nvalue_proposition: \"Editorial command center that saves content teams 2 hours per day\"\ntarget_user: \"Content managers, editors, publishers\"\ncore_loop: \"Create briefing → Review AI suggestions → Publish\"\nsuccess_metrics: \"Time to first published briefing\"\ndev_server_url: \"http://localhost:3000\"\n---\n\n# Product Concept\n\n[Additional context about features, goals, etc.]\n```\n\n## Requirements\n\n- **Playwright MCP**: Browser automation tools (required)\n- **Linear MCP**: For creating projects/issues from findings (optional)\n\n## Components\n\n### Commands\n\n| Command | Purpose |\n|---------|---------|\n| `/ux-eval` | UX quality assessment with heuristics |\n| `/dogfood` | Production readiness through user experience |\n| `/mcp-eval` | MCP app evaluation through conversational intent |\n\n### Agents\n\n| Agent | Role |\n|-------|------|\n| `ux-evaluator` | Autonomous UX assessment against heuristics |\n| `dogfooding-evaluator` | User perspective - experiences product naturally |\n| `technical-debugger` | Developer perspective - traces issues to code |\n| `infrastructure-auditor` | Backend verification - checks if services are connected |\n| `mcp-evaluator` | MCP app evaluation - walks UI through intent lens |\n\n### Skills\n\n`user-lifecycle-framework` - Core knowledge including:\n- 8 lifecycle phases with evaluation criteria\n- Phase-specific heuristics\n- Report templates with ASCII diagrams\n- Journey evaluation methodology\n- Technical investigation patterns\n\n`mcp-evaluation-framework` - MCP-specific knowledge including:\n- Turn-based evaluation schema\n- MCP failure pattern detection\n- Improvement layer categorization\n- Intent derivation from product concepts\n\n`backend-readiness-framework` - Backend production readiness knowledge including:\n- Infrastructure reality validation\n- Security, performance, reliability, observability, and data integrity layers\n- Scoring guidance and report templates\n\n## Output Examples\n\n### UX Evaluation Report\n\n```\nOVERALL UX SCORE: 72/100\n\nClarity      [████████████████░░░░] 80%\nEfficiency   [██████████████░░░░░░] 70%\nFeedback     [████████████░░░░░░░░] 60%\nRecovery     [██████████████████░░] 90%\nAccessibility[██████████░░░░░░░░░░] 50%\n```\n\n### Dogfooding Report\n\n```\nVISION ALIGNMENT\n\nPromise                          Delivered?\n───────                          ──────────\n\"Editorial command center\"       ◐ Partially\n\"Save 2 hours per day\"           ○ Not yet\n\"AI-powered suggestions\"         ● Yes\n\nProduction Readiness: 65%\nReady for: Beta users\nBlocking issues: 2\n```\n\n### Technical Analysis\n\n```\n┌────────────────────────┬──────────┬──────────────────────────────────┐\n│ Flow                   │ Status   │ Notes                            │\n├────────────────────────┼──────────┼──────────────────────────────────┤\n│ Form → Database        │ ✓ PASS   │ User record created correctly    │\n│ Database → Profile UI  │ ⚠ WARN   │ Avatar shows placeholder         │\n│ Signup → Welcome Email │ ✗ FAIL   │ SMTP not configured              │\n└────────────────────────┴──────────┴──────────────────────────────────┘\n```\n\n## File Structure\n\n```\nux-evaluator/\n├── .claude-plugin/\n│   └── plugin.json\n├── commands/\n│   ├── ux-eval.md              # UX quality assessment\n│   ├── dogfood.md              # Production readiness testing\n│   └── mcp-eval.md             # MCP app evaluation\n├── agents/\n│   ├── ux-evaluator.md         # Heuristic-based UX evaluation\n│   ├── dogfooding-evaluator.md # User perspective evaluation\n│   ├── technical-debugger.md   # Code investigation\n│   ├── infrastructure-auditor.md # Backend verification\n│   └── mcp-evaluator.md        # MCP app evaluation\n├── skills/\n│   ├── user-lifecycle-framework/\n│   │   ├── SKILL.md\n│   │   └── references/\n│   │       ├── phase-heuristics.md\n│   │       ├── report-templates.md\n│   │       ├── journey-evaluation.md\n│   │       └── technical-investigation.md\n│   └── mcp-evaluation-framework/\n│       ├── SKILL.md\n│       └── references/\n│           ├── turn-evaluation-schema.md\n│           ├── failure-patterns.md\n│           ├── improvement-layers.md\n│           └── intent-derivation.md\n│   └── backend-readiness-framework/\n│       ├── SKILL.md\n│       └── references/\n│           ├── layer-checklists.md\n│           ├── report-template.md\n│           └── scoring-guidance.md\n├── examples/\n│   └── ux-evaluator.local.md.example\n└── README.md\n```\n\n## Best Practices\n\n1. **Start with dogfooding** - Ensure things work before evaluating UX\n2. **Use detailed product concept** - Better context = better evaluation\n3. **Evaluate one flow at a time** - More focused, actionable findings\n4. **Run technical analysis** - Get code-level fixes, not just symptoms\n5. **Create Linear issues** - Turn findings into trackable work\n",
        "plugins/agentic-optimization-loop/README.md": "# Agentic Optimization Loop\n\nContract-driven optimization controller for iterative AI-agent improvement.\n\nThis plugin no longer owns evaluation setup. It consumes canonical evaluation state prepared by `langfuse-analyzer` and runs a strict optimization loop.\n\n## Architecture\n\n```\nLangfuse Analyzer (eval setup owner)\n  -> exports .claude/eval-infra/<agent>.yaml|json\n  -> stores canonical state in Langfuse metadata/prompts/runs\n\nAgentic Optimization Loop (this plugin)\n  -> validates contract snapshot + live identifiers\n  -> defines optimization target (dimensions/signals/levers)\n  -> runs init -> hypothesize -> experiment -> analyze -> compound\n  -> performs diagnosis during analyze and decision in compound\n```\n\n## Core Concepts\n\n| Concept | Meaning |\n|---|---|\n| Goal | What metric/outcome to improve |\n| Dimensions | Quality facets to optimize (e.g. correctness, safety) |\n| Signals | Measurable scores/metrics for each dimension (canonical 0-1) |\n| Levers | What can change (config/prompt/grader/code) |\n| Guards | Hard regression boundaries; violations trigger rollback |\n| Slices | Segment-level checks to avoid hidden regressions |\n\n## Lever Strategy\n\nSingle loop, configurable lever cardinality:\n\n- `single` mode: exactly 1 lever per iteration\n- `multi` mode: 2..N levers per iteration\n- default for `multi`: `N=3`\n- hard cap: `N=5`\n\nDecision policy is unchanged across both modes (same strict guards and rollback criteria).\n\n## Commands\n\n### `/optimize [agent]`\n\nPrimary interactive loop command.\n\nNew arguments:\n- `--lever-mode single|multi` (default `single`)\n- `--max-levers N` (`1..5`; default `1` for single, `3` for multi)\n\n### `/optimize-status [agent]`\n\nRead-only status including lever strategy fields (`lever_mode`, `max_levers`, `current_lever_set_size`).\n\n### `/cloud-optimize [iterations]`\n\nGenerate cloud execution prompts with explicit lever cardinality policy and strict guard instructions.\n\n### Eval Bootstrap\n\nOptimization bootstrap/setup now lives in `langfuse-analyzer` via `/optimize-bootstrap`.\n\n## Contract Dependency\n\nExpected local contract snapshot path:\n\n- `.claude/eval-infra/<agent>.yaml`\n- `.claude/eval-infra/<agent>.json`\n\n`/optimize` fails fast if contract is missing/incomplete or live identifiers do not validate.\n\nSee:\n- `references/eval-contract.md`\n- `references/lever-strategy.md`\n\n## Minimal State Model\n\nThis plugin should operate with only two files:\n\n1. **Eval handoff snapshot (read-only):**\n   - `.claude/eval-infra/<agent>.yaml|json`\n2. **Optimization state (read/write):**\n   - `.claude/optimization-loops/<agent>/journal.yaml`\n\nTarget definition and lever scope are stored directly in `journal.yaml` under `meta.target` and `meta.levers`.\nNo separate `target.yaml` is required.\n\n## Journal State\n\nState remains in:\n\n```\n.claude/optimization-loops/<agent>/journal.yaml\n```\n\nAdditional fields:\n- `loop.lever_mode`\n- `loop.max_levers`\n- `iterations[].lever_set`\n- `iterations[].lever_set_size`\n- `iterations[].attribution_confidence`\n- `meta.target` (goal/dimensions/constraints)\n- `meta.levers` (main knob, allowed scope, frozen scope)\n\n## Notes\n\n- Canonical score semantics are `0-1` for gating and decisions.\n- Any `0-10` representation is display-only and non-authoritative.\n- This plugin is read-only with respect to evaluation infrastructure objects.\n\n## Local Langfuse Helper Surface\n\nHelpers live in:\n\n`/Users/max/mberto-compound/plugins/agentic-optimization-loop/skills/optimization-loop/helpers/`\n\n- `contract_resolver.py`: contract load + live Langfuse object validation\n- `run_metrics_reader.py`: baseline/candidate comparison (normalized)\n- `failure_pack_reader.py`: low-scoring item extraction for diagnosis\n- `trace_retriever.py`: trace-by-id, last-N, metadata/tag/time filters, score filters, and modes (`minimal|io|prompts|flow|full`)\n- `langfuse_client.py`: local auth client + connection test\n"
      },
      "plugins": [
        {
          "name": "langfuse-analyzer",
          "source": "./plugins/langfuse-analyzer",
          "description": "Surgical Langfuse trace retrieval with multiple output modes for LLM-friendly debugging and optimization workflows",
          "version": "0.1.0",
          "author": {
            "name": "Writing Ecosystem Team"
          },
          "homepage": "https://github.com/mberto10/mberto-compound",
          "repository": "https://github.com/mberto10/mberto-compound",
          "license": "MIT",
          "keywords": [
            "langfuse",
            "tracing",
            "debugging",
            "observability",
            "optimization"
          ],
          "category": "observability",
          "categories": [
            "debugging",
            "langfuse",
            "observability",
            "optimization",
            "tracing"
          ],
          "install_commands": [
            "/plugin marketplace add mberto10/mberto-compound",
            "/plugin install langfuse-analyzer@mberto-compound"
          ]
        },
        {
          "name": "langdock-dev",
          "source": "./plugins/langdock-dev",
          "description": "Build Langdock integration actions and use Langdock APIs with live documentation fetching",
          "version": "0.1.0",
          "author": {
            "name": "Maximilian Bruhn",
            "email": "puzzle.ai.studio@gmail.com"
          },
          "homepage": "https://github.com/mberto10/mberto-compound",
          "repository": "https://github.com/mberto10/mberto-compound",
          "license": "MIT",
          "keywords": [
            "langdock",
            "integrations",
            "actions",
            "api",
            "development"
          ],
          "category": "development",
          "categories": [
            "actions",
            "api",
            "development",
            "integrations",
            "langdock"
          ],
          "install_commands": [
            "/plugin marketplace add mberto10/mberto-compound",
            "/plugin install langdock-dev@mberto-compound"
          ]
        },
        {
          "name": "writing-studio",
          "source": "./plugins/writing-studio",
          "description": "Comprehensive writing assistant with quality loop workflow: deep discovery, voice profiles, iterative self-critique, and publication-ready output",
          "version": "2.0.0",
          "author": {
            "name": "Maximilian Bruhn",
            "email": "puzzle.ai.studio@gmail.com"
          },
          "homepage": "https://github.com/mberto10/mberto-compound",
          "repository": "https://github.com/mberto10/mberto-compound",
          "license": "MIT",
          "keywords": [
            "writing",
            "style",
            "drafting",
            "editing",
            "brainstorming",
            "content",
            "workflow",
            "critique",
            "voice",
            "quality-loop"
          ],
          "category": "writing",
          "categories": [
            "brainstorming",
            "content",
            "critique",
            "drafting",
            "editing",
            "quality-loop",
            "style",
            "voice",
            "workflow",
            "writing"
          ],
          "install_commands": [
            "/plugin marketplace add mberto10/mberto-compound",
            "/plugin install writing-studio@mberto-compound"
          ]
        },
        {
          "name": "work-toolkit",
          "source": "./plugins/work-toolkit",
          "description": "Personal management plugin for daily planning with Linear, German business communication, and YouTrack documentation",
          "version": "0.1.0",
          "author": {
            "name": "Maximilian Bruhn",
            "email": "puzzle.ai.studio@gmail.com"
          },
          "homepage": "https://github.com/mberto10/mberto-compound",
          "repository": "https://github.com/mberto10/mberto-compound",
          "license": "MIT",
          "keywords": [
            "productivity",
            "planning",
            "linear",
            "youtrack",
            "communication",
            "german",
            "documentation"
          ],
          "category": "productivity",
          "categories": [
            "communication",
            "documentation",
            "german",
            "linear",
            "planning",
            "productivity",
            "youtrack"
          ],
          "install_commands": [
            "/plugin marketplace add mberto10/mberto-compound",
            "/plugin install work-toolkit@mberto-compound"
          ]
        },
        {
          "name": "openai-apps-sdk",
          "source": "./plugins/openai-apps-sdk",
          "description": "Comprehensive toolkit for building MCP servers with the OpenAI Apps SDK. Provides skills, commands, and agents for creating ChatGPT apps with Python and TypeScript.",
          "version": "0.1.0",
          "author": {
            "name": "Maximilian Bruhn",
            "email": "puzzle.ai.studio@gmail.com"
          },
          "homepage": "https://github.com/mberto10/mberto-compound",
          "repository": "https://github.com/mberto10/mberto-compound",
          "license": "MIT",
          "keywords": [
            "openai",
            "apps-sdk",
            "mcp",
            "model-context-protocol",
            "chatgpt",
            "mcp-server",
            "widgets"
          ],
          "category": "development",
          "categories": [
            "apps-sdk",
            "chatgpt",
            "development",
            "mcp",
            "mcp-server",
            "model-context-protocol",
            "openai",
            "widgets"
          ],
          "install_commands": [
            "/plugin marketplace add mberto10/mberto-compound",
            "/plugin install openai-apps-sdk@mberto-compound"
          ]
        },
        {
          "name": "compound-loop",
          "source": "./plugins/compound-loop",
          "description": "Structured feedback loop for capturing learnings from plugin usage anywhere and consolidating them into improvements",
          "version": "0.1.0",
          "author": {
            "name": "Maximilian Bruhn",
            "email": "puzzle.ai.studio@gmail.com"
          },
          "homepage": "https://github.com/mberto10/mberto-compound",
          "repository": "https://github.com/mberto10/mberto-compound",
          "license": "MIT",
          "keywords": [
            "compounding",
            "feedback-loop",
            "learning",
            "meta",
            "self-improvement"
          ],
          "category": "meta",
          "categories": [
            "compounding",
            "feedback-loop",
            "learning",
            "meta",
            "self-improvement"
          ],
          "install_commands": [
            "/plugin marketplace add mberto10/mberto-compound",
            "/plugin install compound-loop@mberto-compound"
          ]
        },
        {
          "name": "continuous-compound",
          "source": "./plugins/continuous-compound",
          "description": "Long-running agent continuity via Linear + compound loop learning extraction",
          "version": "1.0.0",
          "author": {
            "name": "Maximilian Bruhn",
            "email": "puzzle.ai.studio@gmail.com"
          },
          "homepage": "https://github.com/mberto10/mberto-compound",
          "repository": "https://github.com/mberto10/mberto-compound",
          "license": "MIT",
          "keywords": [
            "linear",
            "continuity",
            "compound-loop",
            "long-running-tasks"
          ],
          "category": "productivity",
          "categories": [
            "compound-loop",
            "continuity",
            "linear",
            "long-running-tasks",
            "productivity"
          ],
          "install_commands": [
            "/plugin marketplace add mberto10/mberto-compound",
            "/plugin install continuous-compound@mberto-compound"
          ]
        },
        {
          "name": "daily-metrics",
          "source": "./plugins/daily-metrics",
          "description": "Personal tracking and goal management system with Supabase integration",
          "version": "0.1.0",
          "author": {
            "name": "Maximilian Bruhn",
            "email": "puzzle.ai.studio@gmail.com"
          },
          "homepage": "https://github.com/mberto10/mberto-compound",
          "repository": "https://github.com/mberto10/mberto-compound",
          "license": "MIT",
          "keywords": [
            "habits",
            "tracking",
            "goals",
            "metrics",
            "personal-development"
          ],
          "category": "personal",
          "categories": [
            "goals",
            "habits",
            "metrics",
            "personal",
            "personal-development",
            "tracking"
          ],
          "install_commands": [
            "/plugin marketplace add mberto10/mberto-compound",
            "/plugin install daily-metrics@mberto-compound"
          ]
        },
        {
          "name": "ux-evaluator",
          "source": "./plugins/ux-evaluator",
          "description": "Frontend UX evaluation using User Lifecycle Framework and Playwright browser automation",
          "version": "0.1.0",
          "author": {
            "name": "Dispatch Team"
          },
          "homepage": "https://github.com/mberto10/mberto-compound",
          "repository": "https://github.com/mberto10/mberto-compound",
          "license": "MIT",
          "keywords": [
            "ux",
            "frontend",
            "evaluation",
            "playwright",
            "user-lifecycle",
            "testing"
          ],
          "category": "testing",
          "categories": [
            "evaluation",
            "frontend",
            "playwright",
            "testing",
            "user-lifecycle",
            "ux"
          ],
          "install_commands": [
            "/plugin marketplace add mberto10/mberto-compound",
            "/plugin install ux-evaluator@mberto-compound"
          ]
        },
        {
          "name": "agentic-optimization-loop",
          "source": "./plugins/agentic-optimization-loop",
          "description": "Iterative optimization loops for AI agents with hypothesis-driven improvement cycles. Guides you through Build -> Evaluate -> Analyze -> Improve -> Compound cycles with persistent state.",
          "version": "0.1.0",
          "author": {
            "name": "Maximilian Bruhn",
            "email": "puzzle.ai.studio@gmail.com"
          },
          "homepage": "https://github.com/mberto10/mberto-compound",
          "repository": "https://github.com/mberto10/mberto-compound",
          "license": "MIT",
          "keywords": [
            "optimization",
            "agentic",
            "hypothesis-driven",
            "improvement-cycles",
            "evaluation"
          ],
          "category": "development",
          "categories": [
            "agentic",
            "development",
            "evaluation",
            "hypothesis-driven",
            "improvement-cycles",
            "optimization"
          ],
          "install_commands": [
            "/plugin marketplace add mberto10/mberto-compound",
            "/plugin install agentic-optimization-loop@mberto-compound"
          ]
        },
        {
          "name": "compound-engineering",
          "source": "./plugins/compound-engineering",
          "description": "Portable compound engineering workflow: Plan, Work, Review, Compound. Powered by subsystem knowledge files for dependency-aware planning and contract verification. Each unit of work makes subsequent work easier.",
          "version": "0.1.0",
          "author": {
            "name": "Maximilian Bruhn",
            "email": "puzzle.ai.studio@gmail.com"
          },
          "homepage": "https://github.com/mberto10/mberto-compound",
          "repository": "https://github.com/mberto10/mberto-compound",
          "license": "MIT",
          "keywords": [
            "compound-engineering",
            "planning",
            "subsystem-knowledge",
            "contract-verification",
            "workflow"
          ],
          "category": "development",
          "categories": [
            "compound-engineering",
            "contract-verification",
            "development",
            "planning",
            "subsystem-knowledge",
            "workflow"
          ],
          "install_commands": [
            "/plugin marketplace add mberto10/mberto-compound",
            "/plugin install compound-engineering@mberto-compound"
          ]
        }
      ]
    }
  ]
}