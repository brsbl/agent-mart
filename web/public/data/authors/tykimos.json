{
  "author": {
    "id": "tykimos",
    "display_name": "Taeyoung Kim",
    "avatar_url": "https://avatars.githubusercontent.com/u/5064408?u=6c15980fb5c97b3dcf2e67c44e523be9dac03779&v=4"
  },
  "marketplaces": [
    {
      "name": "ssw-plugin",
      "version": null,
      "description": "Sun and Space Weather toolkit for Claude Code",
      "repo_full_name": "tykimos/ssw-plugin",
      "repo_url": "https://github.com/tykimos/ssw-plugin",
      "repo_description": "Sun and Space Weather Claude Code Plugin - solar data download, preprocessing, ML, and visualization",
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2026-02-07T01:48:42Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"$schema\": \"https://anthropic.com/claude-code/marketplace.schema.json\",\n  \"name\": \"ssw-plugin\",\n  \"description\": \"Sun and Space Weather toolkit for Claude Code\",\n  \"owner\": {\n    \"name\": \"sswlab\",\n    \"url\": \"https://github.com/sswlab\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"ssw-plugin\",\n      \"description\": \"Solar observation data download, ML preprocessing, deep learning, and visualization for SDO, STEREO, and Solar Orbiter missions\",\n      \"version\": \"1.0.0\",\n      \"source\": \"./\",\n      \"category\": \"science\",\n      \"homepage\": \"https://github.com/sswlab/ssw-plugin\",\n      \"tags\": [\"solar\", \"space-weather\", \"heliophysics\", \"ML\", \"deep-learning\", \"SDO\", \"STEREO\", \"Solar-Orbiter\", \"EUV\", \"FITS\"]\n    }\n  ]\n}\n",
        ".claude-plugin/plugin.json": "{\n  \"name\": \"ssw-plugin\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Sun and Space Weather toolkit - solar data download, preprocessing, ML training, and visualization\",\n  \"skills\": \"./skills/\"\n}\n",
        "README.md": "# SSW Plugin for Claude Code\n\nSun and Space Weather (SSW) toolkit for [Claude Code](https://claude.ai/). Download, preprocess, visualize, and apply machine learning to solar observation data from SDO, STEREO, and Solar Orbiter missions.\n\n---\n\n## Table of Contents\n\n- [What is a Claude Code Plugin?](#what-is-a-claude-code-plugin)\n- [Installation](#installation)\n  - [Step 1: Add Marketplace](#step-1-add-marketplace)\n  - [Step 2: Install Plugin](#step-2-install-plugin)\n  - [Step 3: Verify Installation](#step-3-verify-installation)\n  - [Step 4: Install Python Dependencies](#step-4-install-python-dependencies)\n- [Plugin Management](#plugin-management)\n- [Skills Overview](#skills-overview)\n- [Workflow](#workflow)\n- [Skill 1: ssw-download](#skill-1-ssw-download)\n- [Skill 2: ssw-prep](#skill-2-ssw-prep)\n- [Skill 3: ssw-ml](#skill-3-ssw-ml)\n- [Skill 4: ssw-viz](#skill-4-ssw-viz)\n- [Natural Language Usage](#natural-language-usage)\n- [Example Gallery](#example-gallery)\n  - [Example 1: Download STEREO Data](#example-1-download-stereo-data)\n  - [Example 2: Download Solar Orbiter Data](#example-2-download-solar-orbiter-data)\n  - [Example 3: Visualize STEREO Multi-Wavelength Pair](#example-3-visualize-stereo-multi-wavelength-pair)\n  - [Example 4: Visualize Solar Orbiter Multi-Wavelength Pair](#example-4-visualize-solar-orbiter-multi-wavelength-pair)\n  - [Example 5: Pixel Intensity Distribution](#example-5-pixel-intensity-distribution)\n- [For Plugin Developers](#for-plugin-developers)\n  - [Plugin Structure](#plugin-structure)\n  - [How to Create Your Own Plugin](#how-to-create-your-own-plugin)\n  - [Publishing as a Marketplace](#publishing-as-a-marketplace)\n- [Dependencies](#dependencies)\n- [License](#license)\n\n---\n\n## What is a Claude Code Plugin?\n\nClaude Code plugins are extensions that add new capabilities to the Claude Code CLI. A plugin can provide:\n\n- **Skills** - Slash commands (e.g., `/ssw-plugin:ssw-download`) that give Claude specialized knowledge and workflows\n- **Agents** - Custom subagent definitions for specialized tasks\n- **Hooks** - Event handlers that respond to Claude Code lifecycle events\n- **MCP Servers** - External tool integrations via Model Context Protocol\n- **LSP Servers** - Code intelligence via Language Server Protocol\n\nPlugins are distributed through **marketplaces** - Git repositories that catalog one or more plugins. Users add a marketplace, then install individual plugins from it.\n\n---\n\n## Installation\n\n### Step 1: Add Marketplace\n\nOpen Claude Code and register the ssw-plugin marketplace:\n\n**Option A: Inside Claude Code (interactive)**\n\n```\n/plugin marketplace add https://github.com/tykimos/ssw-plugin.git\n```\n\n**Option B: From terminal (CLI)**\n\n```bash\nclaude plugin marketplace add https://github.com/tykimos/ssw-plugin.git\n```\n\nThis clones the repository to `~/.claude/plugins/marketplaces/ssw-plugin/` and registers it in `~/.claude/plugins/known_marketplaces.json`.\n\n### Step 2: Install Plugin\n\n**Option A: Inside Claude Code (interactive)**\n\n```\n/plugin install ssw-plugin@ssw-plugin\n```\n\nThe format is `<plugin-name>@<marketplace-name>`.\n\n**Option B: From terminal (CLI)**\n\n```bash\nclaude plugin install ssw-plugin@ssw-plugin\n```\n\n**Option C: Interactive plugin manager**\n\n```\n/plugin\n```\n\nThis opens the plugin manager UI. Navigate to the **Discover** tab to browse and install available plugins.\n\n#### Installation Scopes\n\nYou can control where the plugin is available:\n\n```bash\n# Available in all your projects (default)\nclaude plugin install ssw-plugin@ssw-plugin --scope user\n\n# Available only in current project, shared with team via git\nclaude plugin install ssw-plugin@ssw-plugin --scope project\n\n# Available only in current project, not shared (gitignored)\nclaude plugin install ssw-plugin@ssw-plugin --scope local\n```\n\n| Scope | Settings File | Shared via Git | Use Case |\n|-------|---------------|----------------|----------|\n| `user` | `~/.claude/settings.json` | No | Personal use across all projects |\n| `project` | `.claude/settings.json` | Yes | Team-wide plugin for a project |\n| `local` | `.claude/settings.local.json` | No | Personal use for one project |\n\n### Step 3: Verify Installation\n\nAfter installation, verify the plugin is active:\n\n```\n/plugin\n```\n\nYou should see `ssw-plugin` listed as **Enabled**. The following slash commands should be available:\n\n- `/ssw-plugin:ssw-download`\n- `/ssw-plugin:ssw-prep`\n- `/ssw-plugin:ssw-ml`\n- `/ssw-plugin:ssw-viz`\n\nYou can also test by typing `/ssw-` and checking autocomplete suggestions.\n\n### Step 4: Install Python Dependencies\n\nThe plugin skills require Python packages. Install them in your environment:\n\n```bash\n# Core: solar data download and preprocessing\npip install git+https://github.com/sswlab/ssw-tools\npip install sunpy matplotlib astropy aiapy\n\n# Optional: for ML tasks (ssw-ml skill)\npip install torch torchvision scikit-image\n\n# Optional: for logging in batch processing\npip install loguru\n```\n\n---\n\n## Plugin Management\n\nCommon plugin management commands:\n\n```bash\n# List all installed plugins\n/plugin\n\n# Enable a disabled plugin\n/plugin enable ssw-plugin@ssw-plugin\n\n# Disable without uninstalling\n/plugin disable ssw-plugin@ssw-plugin\n\n# Uninstall completely\n/plugin uninstall ssw-plugin@ssw-plugin\n\n# Update to latest version\n/plugin update ssw-plugin@ssw-plugin\n\n# List registered marketplaces\n/plugin marketplace list\n\n# Update marketplace catalog\n/plugin marketplace update ssw-plugin\n\n# Remove marketplace\n/plugin marketplace remove ssw-plugin\n```\n\n### Where Files Are Stored\n\n| Path | Purpose |\n|------|---------|\n| `~/.claude/plugins/known_marketplaces.json` | Registered marketplace sources |\n| `~/.claude/plugins/installed_plugins.json` | Installed plugin manifest |\n| `~/.claude/plugins/marketplaces/ssw-plugin/` | Marketplace repository (git clone) |\n| `~/.claude/plugins/cache/ssw-plugin/ssw-plugin/1.0.0/` | Installed plugin files (cached copy) |\n| `~/.claude/settings.json` | Plugin enable/disable settings |\n\n### Auto-Updates\n\nBy default, third-party marketplaces do not auto-update. To enable:\n\n1. Open `/plugin` -> **Marketplaces** tab\n2. Toggle auto-update for `ssw-plugin`\n\nOr set the environment variable:\n\n```bash\nexport FORCE_AUTOUPDATE_PLUGINS=true\n```\n\n---\n\n## Skills Overview\n\n| Skill | Command | Description |\n|-------|---------|-------------|\n| **ssw-download** | `/ssw-plugin:ssw-download` | Download solar observation data (SDO, STEREO, Solar Orbiter) |\n| **ssw-prep** | `/ssw-plugin:ssw-prep` | Preprocess raw FITS data into ML-ready format |\n| **ssw-ml** | `/ssw-plugin:ssw-ml` | Train and evaluate deep learning models on solar data |\n| **ssw-viz** | `/ssw-plugin:ssw-viz` | Visualize solar images, ML results, and analysis |\n\nSkills can be invoked in two ways:\n1. **Slash command**: Type `/ssw-plugin:ssw-download` directly\n2. **Natural language**: Just describe what you need (e.g., \"Download Solar Orbiter data for June 2024\") and Claude will automatically invoke the appropriate skill\n\n## Workflow\n\n```\n1. Download          2. Preprocess        3. Train ML          4. Visualize\n   ssw-download  -->    ssw-prep     -->    ssw-ml       -->    ssw-viz\n   (Raw FITS)        (ML-ready FITS)     (Model + Pred)     (Plots & Anim)\n```\n\n---\n\n## Skill 1: ssw-download\n\nDownload solar observation data from multiple space missions.\n\n### Supported Missions\n\n| Mission | Instrument | Wavelengths | Registration |\n|---------|-----------|-------------|-------------|\n| **SDO** | AIA | 94, 131, 171, 193, 211, 304, 335 A | JSOC (free, required) |\n| **STEREO-A/B** | SECCHI/EUVI | 171, 304 A | Not required |\n| **Solar Orbiter** | EUI/FSI | 174, 304 A | Not required |\n\n### Data Availability\n\n| Mission | Period | Notes |\n|---------|--------|-------|\n| SDO/AIA | 2010 - present | Continuous, 12s cadence |\n| STEREO-A | 2006 - present | Active |\n| STEREO-B | 2006 - 2014 | Contact lost |\n| Solar Orbiter/EUI | 2020 - present | Intermittent |\n\n### Usage Examples\n\n**Solar Orbiter (EUI 174A + 304A pair)**\n\n```python\nfrom ssw_tools.download_data.solo_down import run_solo\nfrom datetime import datetime\n\nsd = datetime.strptime(\"2024-06-01T00:00\", \"%Y-%m-%dT%H:%M\")\nrun_solo(sd, None, delta_hours=12, out_path='./solo_data/',\n         level=1, tolerance_min=15, cadence_min=1440)\n```\n\n**STEREO (EUVI 171A + 304A pair)**\n\n```python\nfrom ssw_tools.download_data.stereo_down import run_stereo\nfrom datetime import datetime\n\nsd = datetime.strptime(\"2024-06-06T00:00\", \"%Y-%m-%dT%H:%M\")\nrun_stereo(sd, None, delta_hours=12, out_path='./stereo_data/',\n           level=1, tolerance_min=15, cadence_min=1440)\n```\n\n**SDO/AIA (via SunPy Fido)**\n\n> Requires free JSOC registration: http://jsoc.stanford.edu/ajax/register_email.html\n\n```python\nfrom sunpy.net import Fido, attrs as a\nimport astropy.units as u\n\nresult = Fido.search(\n    a.Time('2024-01-01T00:00', '2024-01-01T00:01'),\n    a.jsoc.Series('aia.lev1_euv_12s'),\n    a.jsoc.Wavelength(193*u.AA),\n    a.jsoc.Segment('image'),\n    a.jsoc.Notify('your@email.com')  # JSOC registered email\n)\nfiles = Fido.fetch(result, path='./sdo_data/')\n```\n\n**CLI Interface**\n\n```bash\npython -m ssw_tools.download_data.main \\\n    --target solo \\\n    --start_date 2024-06-01T00:00 \\\n    --delta_hours 12 \\\n    --tolerance_min 15 \\\n    --cadence_min 1440\n```\n\nTargets: `solo`, `stereo-a`, `stereo-b`\n\n### Download Parameters\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `start_date` | Search start (datetime) | required |\n| `end_date` | Search end (None = same as start) | `None` |\n| `delta_hours` | Search window +/- hours | `12` |\n| `out_path` | Output directory | required |\n| `level` | Processing level (1 or 2) | `1` |\n| `tolerance_min` | Max gap between wavelength pairs (min) | `15` |\n| `cadence_min` | Time step for series (1440 = daily) | `1440` |\n\n---\n\n## Skill 2: ssw-prep\n\nPreprocess SDO/AIA Level 1 FITS data into standardized ML-ready format.\n\n### Pipeline\n\n```\nRaw AIA Level 1 FITS (4096x4096, variable orientation/brightness)\n    |\n    +-- 1. Pointing Correction    --> Fix spacecraft orientation errors\n    +-- 2. Registration           --> North-up, center disk, resample to fixed size\n    +-- 3. Degradation Correction --> Compensate sensor aging over mission lifetime\n    +-- 4. Exposure Normalization --> DN -> DN/s (standardize brightness)\n    |\n    v\nML-Ready (1024x1024, float32, DN/s, north-up, centered)\n```\n\n### Quick Start\n\n```python\nfrom sunpy.map import Map\nimport astropy.units as u\nfrom aiapy.calibrate.util import get_correction_table, get_pointing_table\nfrom ssw_tools.prep.sdo_aia import aia_prep_ml\n\n# Load raw FITS\naia_map = Map('aia_lev1_file.fits')\n\n# Fetch calibration tables\npointing_table = get_pointing_table(aia_map.date - 6*u.h, aia_map.date + 6*u.h)\ncorrection_table = get_correction_table()\n\n# Preprocess\nprep_map = aia_prep_ml(\n    aia_map,\n    pointing_table=pointing_table,\n    correction_table=correction_table,\n    resolution=1024,\n    padding_factor=0.1\n)\n\n# Save\nprep_map.save('prep_193A.fits', overwrite=True)\n```\n\n### Batch Processing\n\n```python\nfrom pathlib import Path\nfrom sunpy.map import Map\nimport astropy.units as u\nfrom aiapy.calibrate.util import get_correction_table, get_pointing_table\nfrom ssw_tools.prep.sdo_aia import aia_prep_ml\nfrom loguru import logger\n\ninput_dir = Path('./raw/')\noutput_dir = Path('./prep/')\noutput_dir.mkdir(exist_ok=True)\n\ncorrection_table = get_correction_table()  # fetch once, reuse\n\nfor fits_file in sorted(input_dir.glob('*.fits')):\n    try:\n        m = Map(str(fits_file))\n        pt = get_pointing_table(m.date - 6*u.h, m.date + 6*u.h)\n        prep = aia_prep_ml(m, pt, correction_table, resolution=1024, padding_factor=0.1)\n        prep.save(str(output_dir / f'prep_{m.wavelength.value:.0f}A_{m.date.isot}.fits'),\n                  overwrite=True)\n        logger.info(f'Done: {fits_file.name}')\n    except Exception as e:\n        logger.error(f'Failed: {fits_file.name}: {e}')\n```\n\n### Preprocessing Parameters\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `aia_map` | SunPy Map of AIA Level 1 data | required |\n| `pointing_table` | Pointing calibration table | `None` |\n| `correction_table` | Degradation correction table | `None` |\n| `resolution` | Output pixel size (512 / 1024 / 2048) | `1024` |\n| `padding_factor` | Extra space around solar disk (0.1 = 10%) | `0.1` |\n\n### Output Format\n\n| Property | Value |\n|----------|-------|\n| Data type | float32 |\n| Units | DN/s (data number per second) |\n| Orientation | Solar north up (CROTA2=0) |\n| Centering | Solar disk centered in frame |\n| Metadata | FITS header updated with calibration info |\n\n---\n\n## Skill 3: ssw-ml\n\nBuild, train, and evaluate deep learning models on preprocessed solar data.\n\n### Common ML Tasks\n\n| Task | Architecture | Input / Output |\n|------|-------------|----------------|\n| Instrument Translation | U-Net, Pix2Pix | Image A -> Image B (e.g., STEREO -> SDO) |\n| Super Resolution | SRCNN, EDSR | Low-res -> High-res EUV |\n| Flare Prediction | CNN+LSTM, ResNet | Time series -> Flare class |\n| Coronal Hole Segmentation | U-Net, SegNet | EUV image -> Binary mask |\n| Active Region Classification | ResNet, EfficientNet | EUV patch -> Class label |\n| Image Generation/Filling | GAN, Diffusion | Partial -> Complete solar disk |\n\n### FITS DataLoader (PyTorch)\n\n```python\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom sunpy.map import Map\nfrom pathlib import Path\nimport numpy as np\n\nclass SolarFITSDataset(Dataset):\n    def __init__(self, fits_dir, wavelengths=None, transform=None):\n        self.fits_dir = Path(fits_dir)\n        self.transform = transform\n        self.files = sorted(self.fits_dir.glob('*.fits'))\n        if wavelengths:\n            self.files = [f for f in self.files\n                         if any(f'{wl}A' in f.name for wl in wavelengths)]\n\n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, idx):\n        smap = Map(str(self.files[idx]))\n        data = smap.data.astype(np.float32)\n        data = np.clip(data, 0, None)\n        data = np.log1p(data)\n        data = data / data.max() if data.max() > 0 else data\n        tensor = torch.from_numpy(data).unsqueeze(0)  # [1, H, W]\n        if self.transform:\n            tensor = self.transform(tensor)\n        metadata = {\n            'wavelength': float(smap.wavelength.value),\n            'date': str(smap.date.isot),\n            'filename': self.files[idx].name\n        }\n        return tensor, metadata\n\n# Usage\ndataset = SolarFITSDataset('./prep_data/', wavelengths=[171, 193, 304])\nloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=4)\n```\n\n### Paired Multi-Wavelength DataLoader\n\n```python\nclass PairedSolarDataset(Dataset):\n    def __init__(self, input_dir, target_dir, transform=None):\n        self.input_files = sorted(Path(input_dir).glob('*.fits'))\n        self.target_files = sorted(Path(target_dir).glob('*.fits'))\n        self.transform = transform\n        assert len(self.input_files) == len(self.target_files)\n\n    def __len__(self):\n        return len(self.input_files)\n\n    def _load(self, path):\n        data = Map(str(path)).data.astype(np.float32)\n        data = np.clip(data, 0, None)\n        data = np.log1p(data)\n        data = data / (data.max() + 1e-8)\n        return torch.from_numpy(data).unsqueeze(0)\n\n    def __getitem__(self, idx):\n        inp = self._load(self.input_files[idx])\n        tgt = self._load(self.target_files[idx])\n        if self.transform:\n            inp, tgt = self.transform(inp), self.transform(tgt)\n        return inp, tgt\n```\n\n### U-Net Model\n\nReference: [InstrumentToInstrument](https://github.com/RobertJaro/InstrumentToInstrument/)\n\n```python\nimport torch.nn as nn\n\nclass UNetBlock(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n        )\n\n    def forward(self, x):\n        return self.conv(x)\n\nclass SolarUNet(nn.Module):\n    def __init__(self, in_channels=1, out_channels=1, features=[64, 128, 256, 512]):\n        super().__init__()\n        self.downs = nn.ModuleList()\n        self.ups = nn.ModuleList()\n        self.pool = nn.MaxPool2d(2)\n\n        for f in features:\n            self.downs.append(UNetBlock(in_channels, f))\n            in_channels = f\n\n        self.bottleneck = UNetBlock(features[-1], features[-1] * 2)\n\n        for f in reversed(features):\n            self.ups.append(nn.ConvTranspose2d(f * 2, f, 2, stride=2))\n            self.ups.append(UNetBlock(f * 2, f))\n\n        self.final = nn.Conv2d(features[0], out_channels, 1)\n\n    def forward(self, x):\n        skips = []\n        for down in self.downs:\n            x = down(x)\n            skips.append(x)\n            x = self.pool(x)\n        x = self.bottleneck(x)\n        skips = skips[::-1]\n        for i in range(0, len(self.ups), 2):\n            x = self.ups[i](x)\n            skip = skips[i // 2]\n            if x.shape != skip.shape:\n                x = nn.functional.interpolate(x, size=skip.shape[2:])\n            x = torch.cat([skip, x], dim=1)\n            x = self.ups[i + 1](x)\n        return self.final(x)\n```\n\n### Training Loop\n\n```python\ndef train_solar_model(model, train_loader, val_loader, epochs=50, lr=1e-4,\n                      device='cuda', save_dir='./checkpoints/'):\n    Path(save_dir).mkdir(exist_ok=True)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5)\n    criterion = nn.MSELoss()\n    model = model.to(device)\n    best_val_loss = float('inf')\n\n    for epoch in range(epochs):\n        model.train()\n        train_loss = 0\n        for inputs, targets in train_loader:\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n        train_loss /= len(train_loader)\n\n        model.eval()\n        val_loss = 0\n        with torch.no_grad():\n            for inputs, targets in val_loader:\n                inputs, targets = inputs.to(device), targets.to(device)\n                outputs = model(inputs)\n                val_loss += criterion(outputs, targets).item()\n        val_loss /= len(val_loader)\n\n        scheduler.step(val_loss)\n        print(f'Epoch {epoch+1}/{epochs} - Train: {train_loss:.6f}, Val: {val_loss:.6f}')\n\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            torch.save(model.state_dict(), f'{save_dir}/best_model.pth')\n\n    return model\n```\n\n### Evaluation Metrics\n\n```python\nfrom skimage.metrics import structural_similarity as ssim\nfrom skimage.metrics import peak_signal_noise_ratio as psnr\n\ndef evaluate_solar_model(model, test_loader, device='cuda'):\n    model.eval()\n    metrics = {'mse': [], 'mae': [], 'psnr': [], 'ssim': []}\n    with torch.no_grad():\n        for inputs, targets in test_loader:\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = model(inputs)\n            for i in range(outputs.shape[0]):\n                pred = outputs[i, 0].cpu().numpy()\n                true = targets[i, 0].cpu().numpy()\n                metrics['mse'].append(np.mean((pred - true) ** 2))\n                metrics['mae'].append(np.mean(np.abs(pred - true)))\n                metrics['psnr'].append(psnr(true, pred, data_range=true.max() - true.min()))\n                metrics['ssim'].append(ssim(true, pred, data_range=true.max() - true.min()))\n    for k, v in metrics.items():\n        print(f'{k.upper()}: {np.mean(v):.6f} +/- {np.std(v):.6f}')\n    return metrics\n```\n\n### Inference\n\n```python\ndef predict(model, fits_path, device='cuda'):\n    smap = Map(fits_path)\n    data = smap.data.astype(np.float32)\n    data = np.clip(data, 0, None)\n    data = np.log1p(data)\n    data = data / (data.max() + 1e-8)\n    tensor = torch.from_numpy(data).unsqueeze(0).unsqueeze(0).to(device)\n    model.eval()\n    with torch.no_grad():\n        output = model(tensor)\n    result = output[0, 0].cpu().numpy()\n    result = np.expm1(result * np.log1p(smap.data.max()))\n    return result\n```\n\n---\n\n## Skill 4: ssw-viz\n\nVisualize solar observation data, preprocessing results, and ML model outputs.\n\n### Single Image Display\n\n```python\nimport matplotlib.pyplot as plt\nfrom sunpy.map import Map\nfrom astropy.visualization import ImageNormalize, AsinhStretch\n\nsmap = Map('preprocessed.fits')\n\nfig = plt.figure(figsize=(8, 8))\nax = fig.add_subplot(projection=smap)\nsmap.plot(axes=ax, norm=ImageNormalize(vmin=0, vmax=5000, stretch=AsinhStretch(0.01)))\nsmap.draw_limb(axes=ax, color='white', linewidth=0.5)\nsmap.draw_grid(axes=ax, color='white', linewidth=0.5, alpha=0.3)\nax.set_title(f'SDO/AIA {smap.wavelength} - {smap.date.iso[:19]}')\nplt.colorbar(ax.images[0], ax=ax, fraction=0.046, pad=0.04, label='DN/s')\nplt.savefig('solar_image.png', dpi=300, bbox_inches='tight')\n```\n\n### Wavelength-Specific Colormaps\n\nSunPy auto-selects the correct colormap, or specify manually:\n\n| Wavelength | Colormap | Feature |\n|------------|----------|---------|\n| 94 A | `sdoaia094` | Flare plasma (green) |\n| 131 A | `sdoaia131` | Flare/transition (teal) |\n| 171 A | `sdoaia171` | Corona (gold) |\n| 193 A | `sdoaia193` | Corona (bronze) |\n| 211 A | `sdoaia211` | Active regions (purple) |\n| 304 A | `sdoaia304` | Chromosphere (red) |\n| 335 A | `sdoaia335` | Active regions (blue) |\n\n### Normalization Options\n\n```python\nfrom astropy.visualization import (\n    ImageNormalize, AsinhStretch, LogStretch, SqrtStretch, HistEqStretch\n)\n\n# Best for solar EUV (reveals faint coronal features)\nnorm = ImageNormalize(vmin=0, vmax=5000, stretch=AsinhStretch(0.01))\n\n# High dynamic range\nnorm = ImageNormalize(vmin=1, vmax=10000, stretch=LogStretch())\n\n# Maximize local contrast\nnorm = ImageNormalize(stretch=HistEqStretch(smap.data))\n```\n\n### Multi-Wavelength Panel\n\n```python\nwavelengths = [171, 193, 211, 304]\nfiles = [f'prep_{wl}A.fits' for wl in wavelengths]\nmaps = [Map(f) for f in files]\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 14),\n                          subplot_kw={'projection': maps[0]})\n\nfor ax, smap in zip(axes.flatten(), maps):\n    smap.plot(axes=ax, norm=ImageNormalize(vmin=0, vmax=5000,\n              stretch=AsinhStretch(0.01)))\n    smap.draw_limb(axes=ax, color='white', linewidth=0.5)\n    ax.set_title(f'{smap.wavelength}')\n\nplt.suptitle(f'Multi-Wavelength - {maps[0].date.iso[:10]}', fontsize=16)\nplt.tight_layout()\nplt.savefig('multi_wavelength.png', dpi=300, bbox_inches='tight')\n```\n\n### Before/After Preprocessing Comparison\n\n```python\nfig = plt.figure(figsize=(16, 8))\nraw, prep = Map('raw.fits'), Map('prep.fits')\n\nax1 = fig.add_subplot(121, projection=raw)\nraw.plot(axes=ax1)\nax1.set_title('Raw Level 1')\n\nax2 = fig.add_subplot(122, projection=prep)\nprep.plot(axes=ax2, norm=ImageNormalize(vmin=0, vmax=5000, stretch=AsinhStretch(0.01)))\nax2.set_title('ML-Preprocessed')\n\nplt.savefig('before_after.png', dpi=300, bbox_inches='tight')\n```\n\n### ML Model Output Comparison\n\n```python\nimport numpy as np\n\nfig, axes = plt.subplots(1, 3, figsize=(20, 7))\n\ninput_data = Map('input_171A.fits').data\ntarget_data = Map('target_193A.fits').data\nprediction = np.load('model_output.npy')\n\nnorm = ImageNormalize(vmin=0, stretch=AsinhStretch(0.01))\n\naxes[0].imshow(input_data, origin='lower', cmap='sdoaia171', norm=norm)\naxes[0].set_title('Input (171A)')\n\naxes[1].imshow(prediction, origin='lower', cmap='sdoaia193', norm=norm)\naxes[1].set_title('Prediction (193A)')\n\naxes[2].imshow(target_data, origin='lower', cmap='sdoaia193', norm=norm)\naxes[2].set_title('Ground Truth (193A)')\n\nfor ax in axes:\n    ax.axis('off')\n\nplt.tight_layout()\nplt.savefig('ml_comparison.png', dpi=300, bbox_inches='tight')\n```\n\n### Difference / Error Map\n\n```python\ndiff = prediction - target_data\n\nfig, ax = plt.subplots(figsize=(8, 8))\nim = ax.imshow(diff, origin='lower', cmap='RdBu_r', vmin=-500, vmax=500)\nax.set_title('Prediction Error (Pred - Truth)')\nax.axis('off')\nplt.colorbar(im, ax=ax, fraction=0.046, label='DN/s difference')\nplt.savefig('error_map.png', dpi=300, bbox_inches='tight')\n```\n\n### Time-Lapse Animation\n\n```python\nimport matplotlib.animation as animation\nfrom pathlib import Path\n\nfits_files = sorted(Path('./prep_data/').glob('*.fits'))\nmaps = [Map(str(f)) for f in fits_files]\n\nfig = plt.figure(figsize=(8, 8))\nax = fig.add_subplot(projection=maps[0])\nnorm = ImageNormalize(vmin=0, vmax=5000, stretch=AsinhStretch(0.01))\nmaps[0].plot(axes=ax, norm=norm)\n\ndef update(frame):\n    ax.clear()\n    maps[frame].plot(axes=ax, norm=norm)\n    ax.set_title(f'{maps[frame].date.iso[:19]}')\n\nani = animation.FuncAnimation(fig, update, frames=len(maps), interval=200)\nani.save('timelapse.mp4', writer='ffmpeg', dpi=150)\n```\n\n### Pixel Distribution\n\n```python\ndata = Map('prep.fits').data.flatten()\ndata = data[data > 0]\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\naxes[0].hist(data, bins=200, color='steelblue', edgecolor='none')\naxes[0].set_xlabel('DN/s'); axes[0].set_title('Linear')\n\naxes[1].hist(np.log10(data), bins=200, color='coral', edgecolor='none')\naxes[1].set_xlabel('log10(DN/s)'); axes[1].set_title('Log Scale')\n\nplt.tight_layout()\nplt.savefig('distribution.png', dpi=300, bbox_inches='tight')\n```\n\n---\n\n## Natural Language Usage\n\nYou don't have to memorize slash commands. Just describe what you need in natural language and Claude will automatically invoke the appropriate skill:\n\n| What you say | Skill triggered |\n|-------------|----------------|\n| \"Download Solar Orbiter data for June 2024\" | ssw-download |\n| \"SDO 193A download\" | ssw-download |\n| \"STEREO data from 2024\" | ssw-download |\n| \"Preprocess these AIA FITS files for ML\" | ssw-prep |\n| \"Calibrate and normalize the solar images\" | ssw-prep |\n| \"Train a U-Net on the solar data\" | ssw-ml |\n| \"Build a flare prediction model\" | ssw-ml |\n| \"Show me a multi-wavelength comparison\" | ssw-viz |\n| \"Create a solar time-lapse animation\" | ssw-viz |\n| \"Plot the pixel distribution\" | ssw-viz |\n\nKorean is also supported:\n\n| What you say | Skill triggered |\n|-------------|----------------|\n| \"태양 관측 데이터 다운로드해줘\" | ssw-download |\n| \"AIA 데이터 전처리해줘\" | ssw-prep |\n| \"태양 딥러닝 모델 학습해줘\" | ssw-ml |\n| \"태양 이미지 시각화해줘\" | ssw-viz |\n\n---\n\n## Example Gallery\n\nReal examples run with this plugin. All outputs below are from actual execution.\n\n### Example 1: Download STEREO Data\n\nDownload a STEREO-A EUVI 171A + 304A wavelength pair for 2024-06-06:\n\n```python\nfrom ssw_tools.download_data.stereo_down import run_stereo\nfrom datetime import datetime\n\nsd = datetime.strptime(\"2024-06-06T00:00\", \"%Y-%m-%dT%H:%M\")\nrun_stereo(sd, None, delta_hours=12, out_path='./stereo_data/',\n           level=1, tolerance_min=15, cadence_min=1440)\n```\n\n**Execution log:**\n\n```\n------------ Nearest from 2024-06-06 00:00:00 ------------\nStart Time_171    2024-06-06 00:07:00\nStart Time_304    2024-06-06 00:05:45\n\n------------ Download ------------\n20240606_000700_n4euA.fts: 100%|██████████| 8.41M/8.41M [00:05<00:00]\n20240606_000545_n4euA.fts: 100%|██████████| 8.41M/8.41M [00:03<00:00]\n\n------------ Download Complete ------------\n['stereo_data/stereo-174/20240606_000700_n4euA.fts']\n['stereo_data/stereo-304/20240606_000545_n4euA.fts']\n```\n\n**Output**: Two FITS files (~8.4 MB each) in `stereo-174/` and `stereo-304/` subdirectories.\n\n### Example 2: Download Solar Orbiter Data\n\nDownload a Solar Orbiter EUI/FSI 174A + 304A wavelength pair for 2024-06-01:\n\n```python\nfrom ssw_tools.download_data.solo_down import run_solo\nfrom datetime import datetime\n\nsd = datetime.strptime(\"2024-06-01T00:00\", \"%Y-%m-%dT%H:%M\")\nrun_solo(sd, None, delta_hours=12, out_path='./solo_data/',\n         level=1, tolerance_min=15, cadence_min=1440)\n```\n\n**Execution log:**\n\n```\n------------ 15분 이내로 촬영된 데이터 쌍 후보 ------------\n            Start Time_174          Start Time_304\n72 2024-06-01 00:00:45.206 2024-06-01 00:00:15.207\n\n------------ Nearest from 2024-06-01 00:00:00 ------------\nStart Time_174    2024-06-01 00:00:45.206000\nStart Time_304    2024-06-01 00:00:15.207000\n\nsolo_L1_eui-fsi174-image_20240601T000045206_V02.fits: 100%|██████████| 2.51M/2.51M\nsolo_L1_eui-fsi304-image_20240601T000015207_V02.fits: 100%|██████████| 2.32M/2.32M\n\n------------ Download Complete ------------\n['solo_data/solo/174/solo_L1_eui-fsi174-image_20240601T000045206_V02.fits']\n['solo_data/solo/304/solo_L1_eui-fsi304-image_20240601T000015207_V02.fits']\n```\n\n**Output**: Two FITS files (~2.5 MB each) in `solo/174/` and `solo/304/` subdirectories.\n\n### Example 3: Visualize STEREO Multi-Wavelength Pair\n\n```python\nimport matplotlib.pyplot as plt\nfrom astropy.io import fits\nfrom astropy.visualization import ImageNormalize, AsinhStretch\nimport numpy as np\nimport sunpy.visualization.colormaps  # registers SDO AIA colormaps\n\nf171 = fits.open('./stereo_data/stereo-174/20240606_000700_n4euA.fts')\nf304 = fits.open('./stereo_data/stereo-304/20240606_000545_n4euA.fts')\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 8))\n\nfor ax, f, cmap, title in [\n    (axes[0], f171, 'sdoaia171', 'STEREO-A EUVI 171A'),\n    (axes[1], f304, 'sdoaia304', 'STEREO-A EUVI 304A'),\n]:\n    data = f[0].data.astype(np.float32)\n    norm = ImageNormalize(vmin=0, vmax=np.percentile(data, 99.5), stretch=AsinhStretch(0.01))\n    ax.imshow(data, origin='lower', cmap=cmap, norm=norm)\n    ax.set_title(title, fontsize=14, color='white')\n    ax.axis('off')\n\nplt.savefig('stereo_pair.png', dpi=150, bbox_inches='tight', facecolor='black')\n```\n\n**Result:**\n\n![STEREO-A EUVI Multi-Wavelength Pair](examples/stereo_pair.png)\n\n*STEREO-A SECCHI/EUVI 171A (corona, gold) and 304A (chromosphere, red) observed on 2024-06-06. Active regions with bright loops are visible in both wavelengths.*\n\n### Example 4: Visualize Solar Orbiter Multi-Wavelength Pair\n\n```python\nf174 = fits.open('./solo_data/solo/174/solo_L1_eui-fsi174-image_20240601T000045206_V02.fits')\nf304 = fits.open('./solo_data/solo/304/solo_L1_eui-fsi304-image_20240601T000015207_V02.fits')\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 8))\n\n# Note: Solar Orbiter EUI data is in HDU[1] (CompImageHDU)\nfor ax, f, cmap, title in [\n    (axes[0], f174, 'sdoaia171', 'Solar Orbiter EUI/FSI 174A'),\n    (axes[1], f304, 'sdoaia304', 'Solar Orbiter EUI/FSI 304A'),\n]:\n    data = f[1].data.astype(np.float32)\n    pos = data[data > 0]\n    norm = ImageNormalize(vmin=0, vmax=np.percentile(pos, 99.5), stretch=AsinhStretch(0.01))\n    ax.imshow(data, origin='lower', cmap=cmap, norm=norm)\n    ax.set_title(title, fontsize=14, color='white')\n    ax.axis('off')\n\nplt.savefig('solo_pair.png', dpi=150, bbox_inches='tight', facecolor='black')\n```\n\n**Result:**\n\n![Solar Orbiter EUI/FSI Multi-Wavelength Pair](examples/solo_pair.png)\n\n*Solar Orbiter EUI/FSI 174A (corona) and 304A (chromosphere) observed on 2024-06-01. The smaller apparent solar disk reflects Solar Orbiter's varying distance from the Sun.*\n\n### Example 5: Pixel Intensity Distribution\n\n```python\nf = fits.open('./stereo_data/stereo-174/20240606_000700_n4euA.fts')\ndata = f[0].data.astype(np.float32).flatten()\ndata = data[data > 0]\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\naxes[0].hist(data, bins=200, color='#FFD700', edgecolor='none')\naxes[0].set_xlabel('DN')\naxes[0].set_title('Linear Scale')\n\naxes[1].hist(np.log10(data), bins=200, color='#FF6347', edgecolor='none')\naxes[1].set_xlabel('log10(DN)')\naxes[1].set_title('Log Scale')\n\nplt.suptitle('Pixel Intensity Distribution', fontweight='bold')\nplt.savefig('pixel_dist.png', dpi=150, bbox_inches='tight')\n```\n\n**Result:**\n\n![Pixel Intensity Distribution](examples/pixel_dist.png)\n\n*STEREO-A EUVI 171A pixel intensity distribution. The linear scale (left) shows the highly skewed nature of EUV intensities. The log scale (right) reveals a bimodal distribution: the main peak (~10^2.9 DN) represents quiet Sun, while the extended tail corresponds to active regions and bright loops.*\n\n### Tips from Running These Examples\n\n| Tip | Details |\n|-----|---------|\n| **SunPy colormaps** | Import `sunpy.visualization.colormaps` to register `sdoaia171`, `sdoaia304`, etc. |\n| **Solar Orbiter HDU** | EUI data is in `HDU[1]` (CompImageHDU), not `HDU[0]` |\n| **STEREO HDU** | EUVI data is in `HDU[0]` (PrimaryHDU) |\n| **Normalization** | Use `AsinhStretch(0.01)` for EUV images to reveal faint coronal features |\n| **Negative pixels** | Filter with `data[data > 0]` before computing percentiles |\n| **Tolerance** | Set `tolerance_min=15` to ensure wavelength pairs are taken within 15 minutes of each other |\n\n---\n\n## For Plugin Developers\n\n### Plugin Structure\n\n```\nssw-plugin/\n├── .claude-plugin/\n│   ├── plugin.json           # Plugin manifest (metadata)\n│   └── marketplace.json      # Marketplace catalog (for distribution)\n├── skills/\n│   ├── ssw-download/\n│   │   └── SKILL.md          # Download skill definition\n│   ├── ssw-prep/\n│   │   └── SKILL.md          # Preprocessing skill definition\n│   ├── ssw-ml/\n│   │   └── SKILL.md          # ML skill definition\n│   └── ssw-viz/\n│       └── SKILL.md          # Visualization skill definition\n└── README.md\n```\n\n**Important**: Only `plugin.json` and `marketplace.json` go inside `.claude-plugin/`. All other components (skills, agents, hooks, etc.) must be at the **plugin root level**.\n\n### How to Create Your Own Plugin\n\n#### 1. Create the directory structure\n\n```bash\nmkdir -p my-plugin/.claude-plugin\nmkdir -p my-plugin/skills/my-skill\n```\n\n#### 2. Create the manifest (`plugin.json`)\n\n```json\n{\n  \"name\": \"my-plugin\",\n  \"version\": \"1.0.0\",\n  \"description\": \"What your plugin does\",\n  \"author\": {\n    \"name\": \"Your Name\",\n    \"email\": \"you@example.com\"\n  },\n  \"repository\": \"https://github.com/you/my-plugin\",\n  \"license\": \"MIT\",\n  \"skills\": \"./skills/\"\n}\n```\n\n#### 3. Create a skill (`SKILL.md`)\n\n```yaml\n---\nname: my-skill\ndescription: \"When to use this skill. Triggers: 'keyword1', 'keyword2'\"\n---\n\n# My Skill\n\nInstructions for Claude when this skill is invoked.\n\n## Usage\n\nYour skill documentation here...\n```\n\n**SKILL.md frontmatter fields:**\n\n| Field | Purpose | Example |\n|-------|---------|---------|\n| `name` | Slash command name | `my-skill` -> `/my-plugin:my-skill` |\n| `description` | When Claude should auto-invoke this skill | `\"Analyze CSV data...\"` |\n| `disable-model-invocation` | Prevent Claude from auto-invoking (manual only) | `true` |\n| `user-invocable` | Hide from slash menu (background knowledge only) | `false` |\n| `allowed-tools` | Restrict available tools | `Read, Grep, Write` |\n| `model` | Override model for this skill | `claude-sonnet-4-5` |\n| `context` | Run in isolated subagent | `fork` |\n| `agent` | Subagent type (with `context: fork`) | `Explore` |\n| `argument-hint` | Autocomplete hint | `[filename] [format]` |\n\n#### 4. Test locally\n\n```bash\n# Test without installing\nclaude --plugin-dir ./my-plugin\n\n# Validate structure\n/plugin validate ./my-plugin\n```\n\n#### 5. Push to GitHub\n\n```bash\ncd my-plugin\ngit init && git add -A && git commit -m \"Initial release\"\ngit remote add origin https://github.com/you/my-plugin.git\ngit push -u origin main\n```\n\n### Publishing as a Marketplace\n\nTo let others install your plugin, add a marketplace catalog file:\n\n#### 1. Create `marketplace.json`\n\nCreate `.claude-plugin/marketplace.json` in your repo:\n\n```json\n{\n  \"name\": \"my-plugin\",\n  \"description\": \"Description of your marketplace\",\n  \"owner\": {\n    \"name\": \"Your Name\",\n    \"email\": \"you@example.com\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"my-plugin\",\n      \"description\": \"What this plugin does\",\n      \"version\": \"1.0.0\",\n      \"source\": \".\",\n      \"author\": {\n        \"name\": \"Your Name\"\n      },\n      \"category\": \"science\",\n      \"tags\": [\"keyword1\", \"keyword2\"]\n    }\n  ]\n}\n```\n\n**Source options for plugins in marketplace:**\n\n```json\n// Relative path (same repo)\n\"source\": \".\"\n\n// Another GitHub repo\n\"source\": {\n  \"source\": \"github\",\n  \"repo\": \"owner/repo\",\n  \"ref\": \"v1.0.0\"\n}\n\n// Any Git URL\n\"source\": {\n  \"source\": \"url\",\n  \"url\": \"https://gitlab.com/team/plugin.git\",\n  \"ref\": \"main\"\n}\n\n// npm package\n\"source\": {\n  \"source\": \"npm\",\n  \"package\": \"@org/plugin\"\n}\n```\n\n#### 2. Users install your plugin\n\n```bash\n# Step 1: Add your marketplace\n/plugin marketplace add https://github.com/you/my-plugin.git\n\n# Step 2: Install the plugin\n/plugin install my-plugin@my-plugin\n```\n\n### Multi-Plugin Marketplace\n\nIf you want to distribute multiple plugins from one marketplace:\n\n```\nmy-marketplace/\n├── .claude-plugin/\n│   └── marketplace.json        # Lists all plugins\n├── plugins/\n│   ├── plugin-a/\n│   │   ├── .claude-plugin/\n│   │   │   └── plugin.json\n│   │   └── skills/\n│   └── plugin-b/\n│       ├── .claude-plugin/\n│       │   └── plugin.json\n│       └── skills/\n└── README.md\n```\n\n```json\n{\n  \"name\": \"my-marketplace\",\n  \"plugins\": [\n    {\n      \"name\": \"plugin-a\",\n      \"source\": \"./plugins/plugin-a\",\n      \"version\": \"1.0.0\"\n    },\n    {\n      \"name\": \"plugin-b\",\n      \"source\": \"./plugins/plugin-b\",\n      \"version\": \"2.0.0\"\n    }\n  ]\n}\n```\n\n---\n\n## Dependencies\n\n| Package | Required For | Install |\n|---------|-------------|---------|\n| [ssw-tools](https://github.com/sswlab/ssw-tools) | Download & preprocessing | `pip install git+https://github.com/sswlab/ssw-tools` |\n| [SunPy](https://sunpy.org/) | Solar data I/O, maps | `pip install sunpy` |\n| [astropy](https://www.astropy.org/) | FITS handling, units | `pip install astropy` |\n| [aiapy](https://aiapy.readthedocs.io/) | AIA calibration tables | `pip install aiapy` |\n| [matplotlib](https://matplotlib.org/) | Plotting and animation | `pip install matplotlib` |\n| [PyTorch](https://pytorch.org/) | Deep learning (ssw-ml) | `pip install torch torchvision` |\n| [scikit-image](https://scikit-image.org/) | SSIM, PSNR metrics (ssw-ml) | `pip install scikit-image` |\n| [loguru](https://github.com/Delgan/loguru) | Logging (optional) | `pip install loguru` |\n\n## License\n\nMIT\n"
      },
      "plugins": [
        {
          "name": "ssw-plugin",
          "description": "Solar observation data download, ML preprocessing, deep learning, and visualization for SDO, STEREO, and Solar Orbiter missions",
          "version": "1.0.0",
          "source": "./",
          "category": "science",
          "homepage": "https://github.com/sswlab/ssw-plugin",
          "tags": [
            "solar",
            "space-weather",
            "heliophysics",
            "ML",
            "deep-learning",
            "SDO",
            "STEREO",
            "Solar-Orbiter",
            "EUV",
            "FITS"
          ],
          "categories": [
            "deep-learning",
            "euv",
            "fits",
            "heliophysics",
            "ml",
            "science",
            "sdo",
            "solar",
            "solar-orbiter",
            "space-weather",
            "stereo"
          ],
          "install_commands": [
            "/plugin marketplace add tykimos/ssw-plugin",
            "/plugin install ssw-plugin@ssw-plugin"
          ]
        }
      ]
    }
  ]
}