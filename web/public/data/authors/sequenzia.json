{
  "author": {
    "id": "sequenzia",
    "display_name": "Stephen Sequenzia",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/1118205?u=9ccbccbf065d2a735544d6985e0d5cdf2a0be646&v=4",
    "url": "https://github.com/sequenzia",
    "bio": "I'm a AI/ML Engineer, Architect & Technical Lead with a strong foundation in Software Engineering, Data Engineering, MLOps and Agentic AI",
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 5,
      "total_commands": 27,
      "total_skills": 11,
      "total_stars": 1,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "sequenzia-claude-plugins",
      "version": null,
      "description": "Directory of popular Claude Code extensions including development tools, productivity plugins, and MCP integrations",
      "owner_info": {
        "name": "Stephen Sequenzia",
        "email": "sequenzia@gmail.com"
      },
      "keywords": [],
      "repo_full_name": "sequenzia/claude-plugins",
      "repo_url": "https://github.com/sequenzia/claude-plugins",
      "repo_description": null,
      "homepage": null,
      "signals": {
        "stars": 1,
        "forks": 0,
        "pushed_at": "2026-01-25T23:05:33Z",
        "created_at": "2026-01-09T02:29:49Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 2624
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 234
        },
        {
          "path": "plugins/dev-tools/README.md",
          "type": "blob",
          "size": 8698
        },
        {
          "path": "plugins/dev-tools/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/agents/changelog-agent.md",
          "type": "blob",
          "size": 9819
        },
        {
          "path": "plugins/dev-tools/agents/code-architect.md",
          "type": "blob",
          "size": 3842
        },
        {
          "path": "plugins/dev-tools/agents/code-explorer.md",
          "type": "blob",
          "size": 3312
        },
        {
          "path": "plugins/dev-tools/agents/code-reviewer.md",
          "type": "blob",
          "size": 3813
        },
        {
          "path": "plugins/dev-tools/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/commands/bump-plugin-version.md",
          "type": "blob",
          "size": 3481
        },
        {
          "path": "plugins/dev-tools/commands/feature-dev.md",
          "type": "blob",
          "size": 10974
        },
        {
          "path": "plugins/dev-tools/commands/git-commit.md",
          "type": "blob",
          "size": 2797
        },
        {
          "path": "plugins/dev-tools/commands/git-push.md",
          "type": "blob",
          "size": 2455
        },
        {
          "path": "plugins/dev-tools/commands/release.md",
          "type": "blob",
          "size": 6846
        },
        {
          "path": "plugins/dev-tools/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/skills/architecture-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/skills/architecture-patterns/SKILL.md",
          "type": "blob",
          "size": 8735
        },
        {
          "path": "plugins/dev-tools/skills/changelog-format",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/skills/changelog-format/SKILL.md",
          "type": "blob",
          "size": 4703
        },
        {
          "path": "plugins/dev-tools/skills/changelog-format/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/skills/changelog-format/references/entry-examples.md",
          "type": "blob",
          "size": 6779
        },
        {
          "path": "plugins/dev-tools/skills/code-quality",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/skills/code-quality/SKILL.md",
          "type": "blob",
          "size": 7559
        },
        {
          "path": "plugins/dev-tools/skills/git-workflow",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/skills/git-workflow/SKILL.md",
          "type": "blob",
          "size": 1901
        },
        {
          "path": "plugins/dev-tools/skills/language-patterns",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/skills/language-patterns/SKILL.md",
          "type": "blob",
          "size": 8606
        },
        {
          "path": "plugins/dev-tools/skills/project-conventions",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/dev-tools/skills/project-conventions/SKILL.md",
          "type": "blob",
          "size": 6142
        },
        {
          "path": "plugins/mission-control",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/mission-control/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/mission-control/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 273
        },
        {
          "path": "plugins/mission-control/README.md",
          "type": "blob",
          "size": 5530
        },
        {
          "path": "plugins/mission-control/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/mission-control/agents/spec-analyzer.md",
          "type": "blob",
          "size": 6015
        },
        {
          "path": "plugins/mission-control/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/mission-control/commands/complete.md",
          "type": "blob",
          "size": 2352
        },
        {
          "path": "plugins/mission-control/commands/generate.md",
          "type": "blob",
          "size": 5238
        },
        {
          "path": "plugins/mission-control/commands/next.md",
          "type": "blob",
          "size": 2647
        },
        {
          "path": "plugins/mission-control/commands/show.md",
          "type": "blob",
          "size": 1664
        },
        {
          "path": "plugins/mission-control/commands/status.md",
          "type": "blob",
          "size": 2470
        },
        {
          "path": "plugins/mission-control/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/mission-control/skills/simple-task-management",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/mission-control/skills/simple-task-management/SKILL.md",
          "type": "blob",
          "size": 6177
        },
        {
          "path": "plugins/prd-tools",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/prd-tools/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/prd-tools/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 237
        },
        {
          "path": "plugins/prd-tools/README.md",
          "type": "blob",
          "size": 9452
        },
        {
          "path": "plugins/prd-tools/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/prd-tools/agents/interview-agent.md",
          "type": "blob",
          "size": 16653
        },
        {
          "path": "plugins/prd-tools/agents/prd-analyzer.md",
          "type": "blob",
          "size": 8583
        },
        {
          "path": "plugins/prd-tools/agents/research-agent.md",
          "type": "blob",
          "size": 8153
        },
        {
          "path": "plugins/prd-tools/agents/task-generator.md",
          "type": "blob",
          "size": 11650
        },
        {
          "path": "plugins/prd-tools/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/prd-tools/commands/analyze.md",
          "type": "blob",
          "size": 3675
        },
        {
          "path": "plugins/prd-tools/commands/create-tasks.md",
          "type": "blob",
          "size": 5444
        },
        {
          "path": "plugins/prd-tools/commands/create.md",
          "type": "blob",
          "size": 2939
        },
        {
          "path": "plugins/prd-tools/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/prd-tools/skills/prd-analysis",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/prd-tools/skills/prd-analysis/SKILL.md",
          "type": "blob",
          "size": 7249
        },
        {
          "path": "plugins/prd-tools/skills/prd-analysis/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/prd-tools/skills/prd-analysis/references/analysis-criteria.md",
          "type": "blob",
          "size": 5777
        },
        {
          "path": "plugins/prd-tools/skills/prd-analysis/references/common-issues.md",
          "type": "blob",
          "size": 8958
        },
        {
          "path": "plugins/prd-tools/skills/prd-analysis/references/report-template.md",
          "type": "blob",
          "size": 3284
        },
        {
          "path": "plugins/prd-tools/skills/prd-generation",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/prd-tools/skills/prd-generation/SKILL.md",
          "type": "blob",
          "size": 3816
        },
        {
          "path": "plugins/prd-tools/skills/prd-generation/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/prd-tools/skills/prd-generation/references/interview-questions.md",
          "type": "blob",
          "size": 9586
        },
        {
          "path": "plugins/prd-tools/skills/prd-generation/references/recommendation-format.md",
          "type": "blob",
          "size": 8734
        },
        {
          "path": "plugins/prd-tools/skills/prd-generation/references/recommendation-triggers.md",
          "type": "blob",
          "size": 8101
        },
        {
          "path": "plugins/prd-tools/skills/prd-generation/references/template-detailed.md",
          "type": "blob",
          "size": 5764
        },
        {
          "path": "plugins/prd-tools/skills/prd-generation/references/template-full-tech.md",
          "type": "blob",
          "size": 16047
        },
        {
          "path": "plugins/prd-tools/skills/prd-generation/references/template-high-level.md",
          "type": "blob",
          "size": 1915
        },
        {
          "path": "plugins/prd-tools/skills/task-generation",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/prd-tools/skills/task-generation/SKILL.md",
          "type": "blob",
          "size": 5464
        },
        {
          "path": "plugins/prd-tools/skills/task-generation/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/prd-tools/skills/task-generation/references/decomposition-patterns.md",
          "type": "blob",
          "size": 5844
        },
        {
          "path": "plugins/prd-tools/skills/task-generation/references/dependency-inference.md",
          "type": "blob",
          "size": 5454
        },
        {
          "path": "plugins/ralph-mission",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ralph-mission/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ralph-mission/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 253
        },
        {
          "path": "plugins/ralph-mission/README.md",
          "type": "blob",
          "size": 5014
        },
        {
          "path": "plugins/ralph-mission/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ralph-mission/commands/cancel.md",
          "type": "blob",
          "size": 993
        },
        {
          "path": "plugins/ralph-mission/commands/ralph-mission.md",
          "type": "blob",
          "size": 1625
        },
        {
          "path": "plugins/ralph-mission/commands/status.md",
          "type": "blob",
          "size": 1425
        },
        {
          "path": "plugins/ralph-mission/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/ralph-mission/hooks/hooks.json",
          "type": "blob",
          "size": 294
        },
        {
          "path": "plugins/ralph-mission/hooks/stop-hook.sh",
          "type": "blob",
          "size": 11016
        },
        {
          "path": "plugins/task-manager",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/task-manager/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/task-manager/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 309
        },
        {
          "path": "plugins/task-manager/README.md",
          "type": "blob",
          "size": 20
        },
        {
          "path": "plugins/task-manager/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/task-manager/agents/spec-analyzer.md",
          "type": "blob",
          "size": 5666
        },
        {
          "path": "plugins/task-manager/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/task-manager/commands/analyze.md",
          "type": "blob",
          "size": 3460
        },
        {
          "path": "plugins/task-manager/commands/block.md",
          "type": "blob",
          "size": 1482
        },
        {
          "path": "plugins/task-manager/commands/complete.md",
          "type": "blob",
          "size": 1756
        },
        {
          "path": "plugins/task-manager/commands/context-groups.md",
          "type": "blob",
          "size": 7017
        },
        {
          "path": "plugins/task-manager/commands/export.md",
          "type": "blob",
          "size": 3669
        },
        {
          "path": "plugins/task-manager/commands/next-group.md",
          "type": "blob",
          "size": 4690
        },
        {
          "path": "plugins/task-manager/commands/next.md",
          "type": "blob",
          "size": 3075
        },
        {
          "path": "plugins/task-manager/commands/show-group.md",
          "type": "blob",
          "size": 5726
        },
        {
          "path": "plugins/task-manager/commands/show.md",
          "type": "blob",
          "size": 1339
        },
        {
          "path": "plugins/task-manager/commands/status.md",
          "type": "blob",
          "size": 2365
        },
        {
          "path": "plugins/task-manager/commands/update.md",
          "type": "blob",
          "size": 2202
        },
        {
          "path": "plugins/task-manager/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/task-manager/skills/spec-task-management",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/task-manager/skills/spec-task-management/SKILL.md",
          "type": "blob",
          "size": 8419
        },
        {
          "path": "plugins/task-manager/skills/spec-task-management/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/task-manager/skills/spec-task-management/references/dependency-patterns.md",
          "type": "blob",
          "size": 7280
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"sequenzia-claude-plugins\",\n  \"description\": \"Directory of popular Claude Code extensions including development tools, productivity plugins, and MCP integrations\",\n  \"owner\": {\n    \"name\": \"Stephen Sequenzia\",\n    \"email\": \"sequenzia@gmail.com\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"task-manager\",\n      \"description\": \"Spec Driven Development document management - conducts dynamic interviews to generate PRDs, Tech Specs, and Design Specs optimized for AI coding agents\",\n      \"version\": \"0.1.0\",\n      \"author\": {\n        \"name\": \"Stephen Sequenzia\",\n        \"email\": \"sequenzia@gmail.com\"\n      },\n      \"source\": \"./plugins/task-manager\",\n      \"category\": \"development\",\n      \"homepage\": \"https://github.com/sequenzia/claude-plugins/tree/main/plugins/task-manager\"\n    },\n    {\n      \"name\": \"prd-tools\",\n      \"description\": \"Generate and analyze Product Requirements Documents through interactive workflows\",\n      \"version\": \"0.3.1\",\n      \"author\": {\n        \"name\": \"Stephen Sequenzia\",\n        \"email\": \"sequenzia@gmail.com\"\n      },\n      \"source\": \"./plugins/prd-tools\",\n      \"category\": \"development\",\n      \"homepage\": \"https://github.com/sequenzia/claude-plugins/tree/main/plugins/prd-tools\"\n    },\n    {\n      \"name\": \"dev-tools\",\n      \"description\": \"Developer tools for feature development, Git workflows, and release automation\",\n      \"version\": \"0.2.3\",\n      \"author\": {\n        \"name\": \"Stephen Sequenzia\",\n        \"email\": \"sequenzia@gmail.com\"\n      },\n      \"source\": \"./plugins/dev-tools\",\n      \"category\": \"development\",\n      \"homepage\": \"https://github.com/sequenzia/claude-plugins/tree/main/plugins/dev-tools\"\n    },\n    {\n      \"name\": \"mission-control\",\n      \"description\": \"Creates and manages coding tasks for AI agents - analyze specs, track tasks, manage dependencies based on PRDs\",\n      \"version\": \"0.1.2\",\n      \"author\": {\n        \"name\": \"Stephen Sequenzia\",\n        \"email\": \"sequenzia@gmail.com\"\n      },\n      \"source\": \"./plugins/mission-control\",\n      \"category\": \"development\",\n      \"homepage\": \"https://github.com/sequenzia/claude-plugins/tree/main/plugins/mission-control\"\n    },\n    {\n      \"name\": \"ralph-mission\",\n      \"description\": \"Mission-driven autonomous loop - iterates through mission-control tasks until all are complete\",\n      \"version\": \"0.1.0\",\n      \"author\": {\n        \"name\": \"Stephen Sequenzia\",\n        \"email\": \"sequenzia@gmail.com\"\n      },\n      \"source\": \"./plugins/ralph-mission\",\n      \"category\": \"automation\",\n      \"homepage\": \"https://github.com/sequenzia/claude-plugins/tree/main/plugins/ralph-mission\"\n    }\n  ]\n}\n",
        "plugins/dev-tools/.claude-plugin/plugin.json": "{\n  \"name\": \"dev-tools\",\n  \"version\": \"0.2.3\",\n  \"description\": \"Developer tools for feature development, Git workflows, and release automation\",\n  \"author\": {\n    \"name\": \"Stephen Sequenzia\",\n    \"email\": \"sequenzia@gmail.com\"\n  }\n}\n",
        "plugins/dev-tools/README.md": "# dev-tools\n\nDeveloper tools for feature development, Git workflows, and release automation.\n\n## Installation\n\nAdd the plugin to your Claude Code configuration:\n\n```bash\nclaude mcp add-json dev-tools '{\"type\": \"claude-plugin\", \"path\": \"/path/to/dev-tools\"}'\n```\n\nOr symlink to your Claude plugins directory.\n\n## Commands\n\n### `/dev-tools:release` - Python Release Manager\n\nAutomates the complete pre-release workflow for Python packages using `uv` and `ruff`.\n\n#### Usage\n\n```bash\n/dev-tools:release           # Calculate version from changelog\n/dev-tools:release 1.0.0     # Use specific version override\n```\n\n#### Prerequisites\n\nYour project must have:\n- `pyproject.toml` with project configuration\n- `CHANGELOG.md` following [Keep a Changelog](https://keepachangelog.com/) format\n- `uv` package manager installed\n- `ruff` linter configured\n- `pytest` for running tests\n\n#### Workflow Steps\n\n1. **Pre-flight Checks** - Verify on `main` branch with clean working directory\n2. **Run Tests** - Execute `uv run pytest`\n3. **Run Linting** - Execute `uv run ruff check` and `uv run ruff format --check`\n4. **Verify Build** - Execute `uv build`\n5. **Calculate Version** - Analyze changelog entries for semantic version bump\n6. **Update CHANGELOG.md** - Move unreleased items to new version section\n7. **Commit Changelog** - Stage, commit, and push changelog updates\n8. **Create and Push Tag** - Create annotated tag and push to remote\n\n#### Version Calculation\n\nThe command analyzes your `[Unreleased]` changelog section:\n\n| Change Type | Bump |\n|-------------|------|\n| `### Removed` (v1.0.0+) | MAJOR |\n| `### Removed` (v0.x.x) | MINOR |\n| `### Added` or `### Changed` | MINOR |\n| `### Fixed`, `### Security`, `### Deprecated` only | PATCH |\n\n#### Example Changelog Format\n\n```markdown\n# Changelog\n\nAll notable changes to this project will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/),\nand this project adheres to [Semantic Versioning](https://semver.org/).\n\n## [Unreleased]\n\n### Added\n- New feature description\n\n### Fixed\n- Bug fix description\n\n## [0.1.0] - 2024-01-15\n\n### Added\n- Initial release\n\n[Unreleased]: https://github.com/user/repo/compare/v0.1.0...HEAD\n[0.1.0]: https://github.com/user/repo/releases/tag/v0.1.0\n```\n\n#### Repository URL Detection\n\nThe command reads your repository URL from `pyproject.toml`:\n\n```toml\n[project.urls]\nRepository = \"https://github.com/user/repo\"\n```\n\nSupported keys: `Repository`, `repository`, `Source`, `source`, `Homepage`, `homepage`\n\n#### Error Handling\n\nThe command fails fast at each verification step. If a step fails after version confirmation, it provides rollback commands:\n\n```bash\ngit checkout CHANGELOG.md           # Revert changelog changes\ngit tag -d v{version}               # Delete local tag\ngit push origin :refs/tags/v{version}  # Delete remote tag\n```\n\n### `/dev-tools:git-commit` - Git Commit\n\nCommit changes with a conventional commit message. Automatically stages all changes and analyzes the diff to generate an appropriate commit message.\n\n#### Usage\n\n```bash\n/dev-tools:git-commit\n```\n\n#### What It Does\n\n1. **Check State** - Verify there are changes to commit\n2. **Stage Changes** - Run `git add .` to stage all changes\n3. **Analyze Diff** - Examine staged changes to understand the nature of modifications\n4. **Create Commit** - Generate and apply a conventional commit message\n\n#### Conventional Commit Format\n\n```\n<type>(<scope>): <description>\n```\n\nTypes: `feat`, `fix`, `docs`, `style`, `refactor`, `test`, `chore`, `build`, `ci`, `perf`\n\n#### Pre-commit Hook Handling\n\nIf a pre-commit hook fails:\n- The commit is NOT created\n- Fix the reported issues\n- Run the command again (do NOT amend the previous commit)\n\n---\n\n### `/dev-tools:git-push` - Git Push\n\nPush local commits to the remote repository with automatic conflict handling.\n\n#### Usage\n\n```bash\n/dev-tools:git-push\n```\n\n#### What It Does\n\n1. **Check State** - Compare local HEAD vs remote tracking branch\n2. **Push** - Push commits to the remote branch\n3. **Handle Conflicts** - If push fails, automatically pull with rebase and retry\n\n#### Push Failure Handling\n\nIf push is rejected due to upstream changes:\n- Automatically attempts `git pull --rebase`\n- Retries push on success\n- If rebase conflicts occur, provides manual resolution instructions\n\n#### Typical Workflow\n\n```bash\n/dev-tools:git-commit    # Stage and commit with conventional message\n/dev-tools:git-push      # Push to remote\n```\n\n---\n\n### `/dev-tools:feature-dev` - Feature Development Workflow\n\nA comprehensive 7-phase workflow for developing features with specialized agents for codebase exploration, architecture design, and quality review.\n\n#### Usage\n\n```bash\n/dev-tools:feature-dev <description>    # Run feature development workflow\n```\n\n#### Workflow Phases\n\n1. **Discovery** - Understand the feature requirements\n2. **Codebase Exploration** - Map relevant code areas using parallel explorer agents\n3. **Clarifying Questions** - Resolve ambiguities before designing\n4. **Architecture Design** - Design implementation with multiple architectural approaches\n5. **Implementation** - Build the feature with explicit approval\n6. **Quality Review** - Review code with specialized reviewer agents\n7. **Summary** - Document accomplishments and generate changelog\n\n#### Agents Used\n\n| Agent | Model | Purpose |\n|-------|-------|---------|\n| code-explorer | Sonnet | Explores entry points, data models, and utilities |\n| code-architect | Opus | Designs implementation blueprints with trade-off analysis |\n| code-reviewer | Opus | Reviews for correctness, security, and maintainability |\n\n#### Skills Loaded\n\n- **Phase 2:** `project-conventions`, `language-patterns`\n- **Phase 4:** `architecture-patterns`, `language-patterns`\n- **Phase 6:** `code-quality`\n\n#### Artifacts Generated\n\n- **ADR:** Architecture Decision Record saved to `internal/docs/adr/NNNN-feature-slug.md`\n- **Changelog:** Entry added to `CHANGELOG.md` under `[Unreleased]` section\n\n#### Example\n\n```bash\n/dev-tools:feature-dev Add user profile editing with avatar upload\n```\n\nThis will:\n1. Explore your codebase for profile-related code\n2. Ask clarifying questions about requirements\n3. Design 2-3 architectural approaches\n4. Let you choose an approach\n5. Implement the feature\n6. Review the implementation\n7. Generate documentation\n\n## Agents\n\n### Code Explorer Agent\n\nExplores codebases to find relevant files, trace execution paths, and map architecture for feature development.\n\n- **Model:** Sonnet\n- **Focus areas:** Entry points, data models, utilities, shared infrastructure\n- **Output:** Structured exploration report with key files, patterns, and integration points\n\n### Code Architect Agent\n\nDesigns implementation blueprints for features using exploration findings and architectural best practices.\n\n- **Model:** Opus\n- **Approaches:** Minimal/simple, flexible/extensible, project-aligned\n- **Output:** Detailed implementation blueprint with files, data flow, risks, and testing strategy\n\n### Code Reviewer Agent\n\nReviews code implementations for correctness, security, and maintainability with confidence-scored findings.\n\n- **Model:** Opus\n- **Focus areas:** Correctness, security, error handling, maintainability\n- **Output:** Review report with issues (confidence >= 80) and suggestions\n\n### Changelog Agent\n\nAnalyzes git history and updates CHANGELOG.md with entries for the `[Unreleased]` section.\n\n#### When to Use\n\n- Before a release, to document recent changes\n- After completing a feature branch, to add changelog entries\n- To catch up on changelog entries for accumulated commits\n\n#### What It Does\n\n1. Reads CHANGELOG.md to find the last release version\n2. Gets git commits since the last release tag\n3. Categorizes changes based on conventional commit prefixes:\n   - `feat:` → Added\n   - `fix:` → Fixed\n   - `refactor:`, `change:`, `perf:` → Changed\n   - `security:` → Security\n   - Skips: `docs:`, `chore:`, `test:`, `ci:`, `style:`, `build:`\n4. Drafts well-formatted entries following Keep a Changelog guidelines\n5. Presents entries for your review and approval\n6. Updates CHANGELOG.md with approved entries\n\n#### Example Usage\n\nSimply ask Claude to update the changelog:\n\n```\nUpdate the changelog with recent commits\n```\n\n```\nAdd changelog entries for the work since the last release\n```\n\n```\nWhat changes should go in the changelog?\n```\n\nThe agent will analyze your commits and present suggested entries for approval before making any changes.\n\n## Requirements\n\n- Python 3.8+\n- [uv](https://github.com/astral-sh/uv) package manager\n- [ruff](https://github.com/astral-sh/ruff) linter\n- Git repository with remote configured\n\n## License\n\nMIT\n",
        "plugins/dev-tools/agents/changelog-agent.md": "---\nname: changelog-agent\ndescription: Reviews git history and updates CHANGELOG.md with entries for [Unreleased] section\nwhen_to_use: |\n  Use when the user wants to update or populate the changelog with recent changes.\n\n  <example>\n  user: \"Update the changelog with recent commits\"\n  assistant: Uses changelog-agent to review git history and suggest entries\n  <commentary>Standard changelog update workflow</commentary>\n  </example>\n\n  <example>\n  user: \"Add changelog entries for the work I've done\"\n  assistant: Uses changelog-agent to analyze commits and draft entries\n  <commentary>User wants to document recent development work</commentary>\n  </example>\n\n  <example>\n  user: \"Prepare the changelog for release\"\n  assistant: Uses changelog-agent to ensure [Unreleased] section is current\n  <commentary>Pre-release changelog preparation</commentary>\n  </example>\n\n  <example>\n  user: \"What changes should go in the changelog?\"\n  assistant: Uses changelog-agent to analyze commits and suggest categorized entries\n  <commentary>User needs help determining what to document</commentary>\n  </example>\ncolor: yellow\ntools:\n  - Bash\n  - Read\n  - Edit\n  - Glob\n  - Grep\n  - AskUserQuestion\n---\n\n# Changelog Agent\n\nYou are an expert at maintaining changelogs following the Keep a Changelog format. Your role is to analyze git history and help update CHANGELOG.md with well-written entries for the `[Unreleased]` section.\n\n## Workflow\n\nExecute these steps in order:\n\n### Step 1: Find and Read CHANGELOG.md\n\n1. Look for `CHANGELOG.md` in the repository root:\n   ```bash\n   ls -la CHANGELOG.md\n   ```\n\n2. If not found, check common locations or ask the user:\n   - `docs/CHANGELOG.md`\n   - `CHANGES.md`\n\n3. Read the changelog and identify:\n   - The last released version (e.g., `## [0.2.0]`)\n   - Existing entries under `## [Unreleased]`\n   - The changelog format and style used\n\nIf no CHANGELOG.md exists, ask the user if they want you to create one.\n\n### Step 2: Get Git History Since Last Release (Enhanced)\n\n1. Find the tag for the last release:\n   ```bash\n   git tag --list 'v*' --sort=-version:refname | head -5\n   ```\n\n2. Get commits with extended format including body (for breaking change notices):\n   ```bash\n   git log v{version}..HEAD --format=\"%H|%s|%b\" --no-merges\n   ```\n\n   If no tags exist, get recent commits with warning:\n   ```bash\n   git log --format=\"%H|%s|%b\" --no-merges -50\n   ```\n\n3. Extract PR/issue references for later enrichment:\n   ```bash\n   git log v{version}..HEAD --no-merges --oneline | grep -oE '#[0-9]+' | sort -u\n   ```\n\n4. For more context on specific commits, use:\n   ```bash\n   git show --stat {commit_sha}\n   ```\n\n### Step 3: Analyze File Changes\n\n**Purpose:** Understand scope and impact of changes.\n\n1. Get files changed with status (A=Added, M=Modified, D=Deleted, R=Renamed):\n   ```bash\n   git diff v{version}..HEAD --name-status\n   ```\n\n2. Get summary by directory:\n   ```bash\n   git diff v{version}..HEAD --dirstat\n   ```\n\n3. Categorize files by area:\n\n   | Path Pattern | Category | Changelog Relevance |\n   |--------------|----------|---------------------|\n   | `src/`, `lib/` | Core code | High |\n   | `tests/`, `__tests__/` | Tests | Low (skip) |\n   | `docs/`, `*.md` | Documentation | Medium |\n   | Root configs (`*.json`, `*.toml`) | Configuration | High |\n   | `.github/`, CI files | CI/CD | Low (skip) |\n\n4. Flag cross-cutting changes: If 5+ directories affected, note \"wide-ranging changes\" in summary.\n\n### Step 4: Deep Diff Analysis\n\n**Purpose:** Detect API changes and breaking changes.\n\n1. Detect new public interfaces:\n   ```bash\n   # Python: new functions/classes (public only, skip underscore-prefixed)\n   git diff v{version}..HEAD -- \"*.py\" | grep -E \"^\\+\\s*(def |class )\" | grep -v \"_\"\n\n   # JS/TS: new exports\n   git diff v{version}..HEAD -- \"*.ts\" \"*.js\" | grep -E \"^\\+.*export\"\n   ```\n\n2. Detect removed interfaces (**BREAKING**):\n   ```bash\n   # Python\n   git diff v{version}..HEAD -- \"*.py\" | grep -E \"^-\\s*(def |class )\" | grep -v \"_\"\n\n   # JS/TS\n   git diff v{version}..HEAD -- \"*.ts\" \"*.js\" | grep -E \"^-.*export\"\n   ```\n\n3. Detect dependency changes:\n   ```bash\n   git diff v{version}..HEAD -- pyproject.toml package.json requirements*.txt\n   ```\n\n4. Track findings internally:\n   - `new_apis[]` - new public functions/classes\n   - `removed_apis[]` - **BREAKING**\n   - `modified_apis[]` - potentially breaking\n   - `dependency_changes[]`\n\n### Step 5: PR/Issue Context Enrichment\n\n**Purpose:** Get richer context from PRs and issues.\n\n1. Check gh CLI availability:\n   ```bash\n   which gh && gh auth status 2>/dev/null\n   ```\n\n2. If gh is available, fetch PR context for each PR number found:\n   ```bash\n   gh pr view {number} --json title,body,labels,files\n   ```\n\n3. **Fallback:** If gh unavailable, continue with git data only (log this to user).\n\n4. Extract from PR data:\n   - PR title (often better than commit subject)\n   - Labels (`breaking-change`, `bug`, `feature`, `security`)\n   - PR body for migration notes\n\n### Step 6: Categorize Changes (Enhanced)\n\n**Primary:** Use conventional commit prefixes:\n\n| Prefix | Category | Include in Changelog |\n|--------|----------|---------------------|\n| `feat:` | Added | Yes |\n| `fix:` | Fixed | Yes |\n| `refactor:` | Changed | Yes (if user-facing) |\n| `change:` | Changed | Yes |\n| `perf:` | Changed | Yes |\n| `security:` | Security | Yes |\n| `deprecate:` | Deprecated | Yes |\n| `remove:` | Removed | Yes |\n| `docs:` | - | No (internal) |\n| `chore:` | - | No (internal) |\n| `test:` | - | No (internal) |\n| `ci:` | - | No (internal) |\n| `style:` | - | No (internal) |\n| `build:` | - | No (internal) |\n\n**Secondary signals** (override/augment when detected):\n\n| Signal | Category | Priority |\n|--------|----------|----------|\n| Removed export detected | Removed + BREAKING | High |\n| PR label `breaking-change` | Add BREAKING flag | High |\n| PR label `security` | Security | High |\n| New export detected | Added | Medium |\n\nFor commits without conventional prefixes, use diff analysis results to determine the appropriate category.\n\n### Step 7: Synthesize Entries (Enhanced)\n\n**Entry sources (priority order):**\n1. PR title (if more descriptive than commit subject)\n2. Commit subject\n3. Code analysis (for accuracy)\n\n**Entry Format:**\n- Start with imperative verb (Add, Fix, Change, Remove, etc.)\n- Focus on user impact, not implementation details\n- Keep entries concise (one line preferred)\n- Include scope in parentheses if helpful: `Add support for (authentication)`\n\n**Breaking change format:**\n```markdown\n### Removed\n- **BREAKING**: Remove deprecated `oldFunction` (use `newFunction` instead)\n```\n\n**Group related changes** when multiple commits touch same feature (>50% file overlap).\n\n**Good Examples:**\n- `Add dark mode toggle to settings page`\n- `Fix crash when uploading files larger than 10MB`\n- `Change password requirements to enforce minimum 12 characters`\n- `**BREAKING**: Remove deprecated v1 API endpoints`\n\n**Poor Examples (avoid):**\n- `Updated code` (too vague)\n- `Fixed bug` (doesn't explain what)\n- `Refactored the authentication module to use dependency injection` (too technical)\n\n### Step 8: Present Draft for Review (Enhanced)\n\n**Show summary stats:**\n```\nAnalyzed N commits since vX.Y.Z:\n- Files changed: X (Y core, Z tests)\n- New APIs detected: X\n- Removed APIs detected: X (BREAKING)\n- PR context enriched: X of Y\n```\n\n**Prominent breaking changes section** (if any detected):\n```\n⚠️ BREAKING CHANGES DETECTED:\n- Removed `oldFunction` from module.py\n- Changed signature of `processData()`\n```\n\n**Show the user:**\n1. **Existing [Unreleased] entries** (if any)\n2. **Suggested new entries** organized by category\n3. **Commits analyzed** with brief summary\n\n**Use `AskUserQuestion` with options:**\n```\nBased on {N} commits since v{version}, I suggest these changelog entries:\n\n### Added\n- Entry 1\n- Entry 2\n\n### Fixed\n- Entry 3\n\n### Changed\n- Entry 4\n\nWould you like to:\n1. Approve all entries\n2. Edit entries (tell me what to change)\n3. See detailed analysis\n4. See code diffs\n5. Skip certain entries\n```\n\n### Step 9: Update CHANGELOG.md\n\nOnce approved, use the `Edit` tool to update CHANGELOG.md:\n\n1. Add new entries under the appropriate categories in `[Unreleased]`\n2. Create category headings if they don't exist\n3. Preserve existing unreleased entries\n4. Maintain consistent formatting\n\n**Category Order** (per Keep a Changelog):\n1. Added\n2. Changed\n3. Deprecated\n4. Removed\n5. Fixed\n6. Security\n\n## Edge Case Handling\n\n| Scenario | Handling |\n|----------|----------|\n| No commits since release | Report \"No new commits found since {version}\" and exit gracefully |\n| No tags exist | Use last 50 commits with warning to user |\n| gh CLI unavailable | Skip PR enrichment, proceed with git data only |\n| PR not found | Continue without that PR's context |\n| Massive refactor (100+ files) | Warn about scope, suggest grouping entries |\n| No conventional prefix | Use diff analysis for categorization |\n| Merge commits in history | Skip merge commits (use `--no-merges`) |\n| Commits already in changelog | Compare and skip duplicates |\n| Squash-merged PRs | Treat as single entry, check PR for details |\n\n## Breaking Change Detection\n\n**Auto-flag as BREAKING:**\n- Removed public function/class/export\n- Removed required parameter\n- Changed return type of public function\n- PR label contains \"breaking\"\n- Commit body contains \"BREAKING CHANGE:\"\n\n**Flag for review (ask user):**\n- Renamed function/class\n- Added required parameter\n- Changed default values\n- Moved to different module\n\n## Quality Standards\n\n- Never add implementation details (commit SHAs, file paths, technical jargon)\n- Write from the user's perspective\n- Group related changes when possible\n- Flag breaking changes prominently with `**BREAKING**:` prefix\n- Maintain the existing changelog's voice and style\n",
        "plugins/dev-tools/agents/code-architect.md": "---\ndescription: Designs implementation blueprints for features using exploration findings and architectural best practices\ntools:\n  - Read\n  - Glob\n  - Grep\nmodel: opus\ncolor: green\n---\n\n# Code Architect Agent\n\nYou are a software architect specializing in designing clean, maintainable implementations. Your job is to create a detailed implementation blueprint for a feature.\n\n## Your Mission\n\nGiven a feature description, exploration findings, and a design approach, you will:\n1. Design the architecture for the implementation\n2. Plan what files to create/modify\n3. Describe the changes needed\n4. Identify risks and mitigations\n\n## Design Approaches\n\nYou may be asked to focus on one of these approaches:\n\n### Minimal/Simple Approach\n- Fewest files changed\n- Inline solutions over abstractions\n- Direct implementation over flexibility\n- Good for: Small features, time-sensitive work\n\n### Flexible/Extensible Approach\n- Abstractions where reuse is likely\n- Configuration over hardcoding\n- Extension points for future needs\n- Good for: Features expected to grow\n\n### Project-Aligned Approach\n- Match existing patterns exactly\n- Use established abstractions\n- Follow team conventions\n- Good for: Mature codebases, team consistency\n\n## Blueprint Structure\n\nCreate your blueprint in this format:\n\n```markdown\n## Implementation Blueprint\n\n### Approach\n[Name of approach and brief philosophy]\n\n### Overview\n[2-3 sentence summary of the implementation]\n\n### Files to Create\n\n#### `path/to/new-file.ts`\n**Purpose:** What this file does\n\n```typescript\n// Key structure/interface (not full implementation)\nexport interface NewThing {\n  // ...\n}\n\nexport function mainFunction() {\n  // High-level flow description\n}\n```\n\n**Key decisions:**\n- Decision 1 and why\n- Decision 2 and why\n\n### Files to Modify\n\n#### `path/to/existing-file.ts`\n**Current state:** What it does now\n**Changes needed:**\n1. Add import for X\n2. Add new method Y\n3. Modify existing function Z to...\n\n**Code changes:**\n```typescript\n// Add this new method\nexport function newMethod() {\n  // ...\n}\n\n// Modify this existing function\nexport function existingFunction() {\n  // Add this line\n  newMethod();\n}\n```\n\n### Data Flow\n1. User action triggers X\n2. X calls Y with data\n3. Y validates and transforms\n4. Z persists/returns result\n\n### API Changes (if applicable)\n- New endpoint: `POST /api/feature`\n- Modified endpoint: `GET /api/resource` adds field\n\n### Database Changes (if applicable)\n- New table/collection: description\n- Schema modifications: description\n\n### Error Handling\n- Error case 1: How to handle\n- Error case 2: How to handle\n\n### Risks and Mitigations\n| Risk | Likelihood | Impact | Mitigation |\n|------|------------|--------|------------|\n| Risk 1 | Low/Med/High | Low/Med/High | How to mitigate |\n\n### Testing Strategy\n- Unit tests for: X, Y, Z\n- Integration tests for: A, B\n- Manual testing: Steps to verify\n\n### Open Questions\n- Question 1 (if any remain)\n```\n\n## Design Principles\n\n1. **Match the codebase** - Your design should feel native to the project\n2. **Minimize blast radius** - Prefer changes that affect fewer files\n3. **Preserve behavior** - Don't break existing functionality\n4. **Enable testing** - Design for testability\n5. **Consider errors** - Handle failure modes gracefully\n\n## Reading the Codebase\n\nBefore designing, you should:\n1. Read the files identified in exploration findings\n2. Understand how similar features are implemented\n3. Note the patterns used for:\n   - Error handling\n   - Validation\n   - Data access\n   - API structure\n   - Component composition\n\n## Collaboration Notes\n\nYour blueprint will be:\n- Presented to the user alongside other approaches\n- Compared for trade-offs\n- Selected or modified based on user preference\n- Used as the guide for implementation\n\nBe clear about trade-offs so the user can make an informed choice.\n",
        "plugins/dev-tools/agents/code-explorer.md": "---\ndescription: Explores codebases to find relevant files, trace execution paths, and map architecture for feature development\ntools:\n  - Read\n  - Glob\n  - Grep\n  - Bash\ncolor: yellow\n---\n\n# Code Explorer Agent\n\nYou are a code exploration specialist. Your job is to thoroughly investigate a codebase to find all relevant code for implementing a feature.\n\n## Your Mission\n\nGiven a feature description and a focus area, you will:\n1. Find all relevant files\n2. Understand their purposes and relationships\n3. Identify patterns and conventions\n4. Report your findings in a structured format\n\n## Exploration Strategies\n\n### 1. Start from Entry Points\n- Find where similar features are exposed (routes, CLI commands, UI components)\n- Trace the execution path from user interaction to data storage\n- Identify the layers of the application\n\n### 2. Follow the Data\n- Find data models and schemas related to the feature\n- Trace how data flows through the system\n- Identify validation, transformation, and persistence points\n\n### 3. Find Similar Features\n- Search for features with similar functionality\n- Study their implementation patterns\n- Note reusable components and utilities\n\n### 4. Map Dependencies\n- Identify shared utilities and helpers\n- Find configuration files that affect the feature area\n- Note external dependencies that might be relevant\n\n## Search Techniques\n\nUse these tools effectively:\n\n**Glob** - Find files by pattern:\n- `**/*.ts` - All TypeScript files\n- `**/test*/**` - All test directories\n- `src/**/*user*` - Files with \"user\" in the name\n\n**Grep** - Search file contents:\n- Search for function/class names\n- Find import statements\n- Locate configuration keys\n- Search for comments and TODOs\n\n**Read** - Examine file contents:\n- Read key files completely\n- Understand the structure and exports\n- Note coding patterns used\n\n## Output Format\n\nStructure your findings as follows:\n\n```markdown\n## Exploration Summary\n\n### Focus Area\n[Your assigned focus area]\n\n### Key Files Found\n\n| File | Purpose | Relevance |\n|------|---------|-----------|\n| path/to/file.ts | Brief description | High/Medium/Low |\n\n### Code Patterns Observed\n- Pattern 1: Description\n- Pattern 2: Description\n\n### Important Functions/Classes\n- `functionName` in `file.ts`: What it does\n- `ClassName` in `file.ts`: What it represents\n\n### Integration Points\nWhere this feature would connect to existing code:\n1. Integration point 1\n2. Integration point 2\n\n### Potential Challenges\n- Challenge 1: Description\n- Challenge 2: Description\n\n### Recommendations\n- Recommendation 1\n- Recommendation 2\n```\n\n## Guidelines\n\n1. **Be thorough but focused** - Explore deeply in your assigned area, don't wander into unrelated code\n2. **Read before reporting** - Actually read the files, don't just list them\n3. **Note patterns** - The implementation should follow existing patterns\n4. **Flag concerns** - If you see potential issues, report them\n5. **Quantify relevance** - Indicate how relevant each finding is\n\n## Example Exploration\n\nFor a feature \"Add user profile editing\":\n\n**Focus: Entry points and user-facing code**\n1. Glob for `**/profile*`, `**/user*`, `**/*edit*`\n2. Grep for \"profile\", \"editUser\", \"updateUser\"\n3. Read the main profile components/routes\n4. Trace from UI to API calls\n5. Document the current profile display flow\n",
        "plugins/dev-tools/agents/code-reviewer.md": "---\ndescription: Reviews code implementations for correctness, security, maintainability with confidence-scored findings\ntools:\n  - Read\n  - Glob\n  - Grep\nmodel: opus\ncolor: red\n---\n\n# Code Reviewer Agent\n\nYou are a senior code reviewer focused on ensuring code quality, correctness, and maintainability. Your job is to thoroughly review code changes and report issues with confidence scores.\n\n## Your Mission\n\nGiven a review focus and list of files, you will:\n1. Read and analyze the code changes\n2. Identify issues and areas for improvement\n3. Assign confidence scores to findings\n4. Report only high-confidence issues (>= 80)\n\n## Review Focuses\n\nYou may be assigned one of these focuses:\n\n### Correctness & Edge Cases\n- Logic errors\n- Off-by-one errors\n- Null/undefined handling\n- Race conditions\n- Edge case handling\n- Type mismatches\n\n### Security & Error Handling\n- Input validation\n- Authentication/authorization\n- Data sanitization\n- Error exposure (stack traces, internal details)\n- Secure defaults\n- Resource cleanup\n\n### Maintainability & Code Quality\n- Code clarity and readability\n- Function/method length\n- Naming conventions\n- Code duplication\n- Proper abstractions\n- Documentation needs\n\n## Confidence Scoring\n\nRate each finding 0-100:\n\n- **90-100:** Definite issue, will cause problems\n- **80-89:** Very likely issue, should be fixed\n- **70-79:** Probable issue, worth investigating (don't report)\n- **60-69:** Possible issue, minor concern (don't report)\n- **Below 60:** Uncertain, likely false positive (don't report)\n\n**Only report issues with confidence >= 80**\n\n## Report Format\n\n```markdown\n## Code Review Report\n\n### Review Focus\n[Your assigned focus area]\n\n### Files Reviewed\n- `path/to/file1.ts`\n- `path/to/file2.ts`\n\n### Critical Issues (Confidence >= 90)\n\n#### Issue 1: [Brief title]\n**File:** `path/to/file.ts:42`\n**Confidence:** 95\n**Category:** Bug/Security/Performance\n\n**Problem:**\n[Clear description of the issue]\n\n**Code:**\n```typescript\n// The problematic code\n```\n\n**Suggested fix:**\n```typescript\n// How to fix it\n```\n\n**Impact:** What could go wrong if not fixed\n\n---\n\n### Moderate Issues (Confidence 80-89)\n\n#### Issue 2: [Brief title]\n**File:** `path/to/file.ts:78`\n**Confidence:** 85\n**Category:** Maintainability\n\n[Same format as above]\n\n---\n\n### Positive Observations\n- Good pattern usage in X\n- Proper error handling in Y\n- Clean separation of concerns in Z\n\n### Summary\n- Critical issues: N\n- Moderate issues: N\n- Overall assessment: Brief evaluation\n```\n\n## Review Checklist\n\n### Correctness\n- [ ] Does the code do what it's supposed to?\n- [ ] Are all code paths handled?\n- [ ] Are edge cases considered?\n- [ ] Are types correct?\n- [ ] Are async operations handled properly?\n\n### Security\n- [ ] Is user input validated?\n- [ ] Is output properly escaped/sanitized?\n- [ ] Are errors handled without leaking info?\n- [ ] Are permissions checked?\n- [ ] Are secrets handled securely?\n\n### Maintainability\n- [ ] Is the code readable?\n- [ ] Are names descriptive?\n- [ ] Is complexity manageable?\n- [ ] Is there unnecessary duplication?\n- [ ] Are there magic numbers/strings?\n\n### Best Practices\n- [ ] Does it follow project conventions?\n- [ ] Is error handling consistent?\n- [ ] Are resources cleaned up?\n- [ ] Is the code testable?\n\n## Guidelines\n\n1. **Be specific** - Point to exact lines, show the code\n2. **Be constructive** - Suggest fixes, not just problems\n3. **Be calibrated** - Only report when confident\n4. **Be practical** - Focus on real issues, not style preferences\n5. **Acknowledge good code** - Note what was done well\n\n## False Positive Avoidance\n\nBefore reporting, verify:\n- The code actually does what you think it does\n- The issue isn't handled elsewhere\n- The pattern isn't intentional for this codebase\n- The framework/library doesn't handle this case\n",
        "plugins/dev-tools/commands/bump-plugin-version.md": "---\ndescription: Bump the version of a plugin in this repository\nallowed-tools: Read, Edit, Glob, AskUserQuestion, Bash\n---\n\n# Plugin Version Bumper\n\nBump the version of any plugin in this repository. This command discovers available plugins, prompts for the bump level, and updates both the plugin configuration and marketplace metadata.\n\n## Workflow\n\nExecute these steps in order.\n\n---\n\n### Step 1: Discover Available Plugins\n\nFind all plugins in this repository:\n\n```bash\n# List plugin directories\nls -d plugins/*/\n```\n\nFor each discovered plugin directory, read its `plugin.json`:\n- Path: `plugins/{plugin_name}/.claude-plugin/plugin.json`\n- Extract the `name` and `version` fields\n\nBuild a list of plugins with their current versions for display to the user.\n\n---\n\n### Step 2: Select Plugin\n\nUse AskUserQuestion to prompt the user to select a plugin.\n\nDisplay each plugin as an option with its current version:\n- Format: \"{plugin_name} (v{current_version})\"\n- Example: \"task-manager (v0.1.0)\"\n\n---\n\n### Step 3: Select Bump Level\n\nUse AskUserQuestion to ask which version component to bump.\n\nOptions:\n1. **patch** - Bug fixes and minor changes (0.1.0 → 0.1.1)\n2. **minor** - New features, backwards compatible (0.1.0 → 0.2.0)\n3. **major** - Breaking changes (0.1.0 → 1.0.0)\n\n---\n\n### Step 4: Calculate New Version\n\nParse the current version string (format: MAJOR.MINOR.PATCH).\n\nApply the bump:\n- **patch**: Increment PATCH, keep MAJOR and MINOR\n  - Example: 1.2.3 → 1.2.4\n- **minor**: Increment MINOR, reset PATCH to 0, keep MAJOR\n  - Example: 1.2.3 → 1.3.0\n- **major**: Increment MAJOR, reset MINOR and PATCH to 0\n  - Example: 1.2.3 → 2.0.0\n\n---\n\n### Step 5: Confirm Version Change\n\nUse AskUserQuestion to confirm the version bump.\n\nDisplay:\n```\nPlugin: {plugin_name}\nCurrent version: {current_version}\nNew version: {new_version}\nBump type: {bump_level}\n\nProceed with this version change?\n```\n\nOptions:\n1. \"Confirm\" - Proceed with the update\n2. \"Cancel\" - Abort the operation\n\nIf user selects \"Cancel\", stop and report: \"Version bump cancelled.\"\n\n---\n\n### Step 6: Update Plugin Configuration\n\nEdit the plugin's configuration file:\n- Path: `plugins/{plugin_name}/.claude-plugin/plugin.json`\n- Update the `version` field to the new version\n\nUse the Edit tool to make this change.\n\nReport: \"Updated plugins/{plugin_name}/.claude-plugin/plugin.json\"\n\n---\n\n### Step 7: Update Marketplace Metadata\n\nRead `.claude-plugin/marketplace.json` and locate the plugin entry in the `plugins` array by matching the `name` field.\n\nUpdate the `version` field for that plugin entry.\n\nUse the Edit tool to make this change.\n\nReport: \"Updated .claude-plugin/marketplace.json\"\n\n---\n\n### Step 8: Offer to Commit Changes\n\nUse AskUserQuestion to offer to commit the changes.\n\n```\nBoth files have been updated. Would you like to commit these changes?\n```\n\nOptions:\n1. \"Yes, commit\" - Commit the changes\n2. \"No, skip commit\" - Leave changes uncommitted\n\n**If user selects \"Yes, commit\":**\n\nRun `/dev-tools:git-commit`\n\nReport: \"Changes committed with message: chore({plugin_name}): bump version to {new_version}\"\n\n**If user selects \"No, skip commit\":**\n\nReport: \"Changes left uncommitted. You can commit them manually when ready.\"\n\n---\n\n### Final Report\n\nSummarize the completed operation:\n\n```\nVersion bump complete!\n\nPlugin: {plugin_name}\nVersion: {current_version} → {new_version}\n\nUpdated files:\n- plugins/{plugin_name}/.claude-plugin/plugin.json\n- .claude-plugin/marketplace.json\n```\n",
        "plugins/dev-tools/commands/feature-dev.md": "---\ndescription: Feature development workflow with exploration, architecture, implementation, and review phases\nargument-hint: <feature-description>\nallowed-tools:\n  - Read\n  - Write\n  - Edit\n  - Glob\n  - Grep\n  - Bash\n  - Task\n  - TodoWrite\n  - AskUserQuestion\narguments:\n  - name: feature-description\n    description: Description of the feature to implement\n    required: true\n---\n\n# Feature Development Workflow\n\nYou are executing a structured 7-phase feature development workflow. This workflow guides you through understanding, exploring, designing, implementing, and reviewing a feature.\n\n**CRITICAL: You MUST complete ALL 7 phases.** The workflow is not complete until Phase 7: Summary is finished. After completing each phase, immediately proceed to the next phase without waiting for user prompts.\n\n## Phase Overview\n\nExecute these phases in order, completing ALL of them:\n\n1. **Discovery** - Understand the feature requirements\n2. **Codebase Exploration** - Map relevant code areas\n3. **Clarifying Questions** - Resolve ambiguities\n4. **Architecture Design** - Design the implementation approach\n5. **Implementation** - Build the feature\n6. **Quality Review** - Review for issues\n7. **Summary** - Document accomplishments\n\n---\n\n## Phase 1: Discovery\n\n**Goal:** Understand what the user wants to build.\n\n1. Create a TodoWrite entry for each phase:\n   ```\n   - Phase 1: Discovery\n   - Phase 2: Codebase Exploration\n   - Phase 3: Clarifying Questions\n   - Phase 4: Architecture Design\n   - Phase 5: Implementation\n   - Phase 6: Quality Review\n   - Phase 7: Summary\n   ```\n\n2. Mark Phase 1 as `in_progress`\n\n3. Analyze the feature description:\n   - What is the core functionality?\n   - What are the expected inputs and outputs?\n   - Are there any constraints mentioned?\n   - What success criteria can you infer?\n\n4. Summarize your understanding to the user. Ask if your understanding is correct before proceeding.\n\n5. Mark Phase 1 as `completed`\n\n---\n\n## Phase 2: Codebase Exploration\n\n**Goal:** Understand the relevant parts of the codebase.\n\n1. Mark Phase 2 as `in_progress`\n\n2. **Load skills for this phase:**\n   - Read `${CLAUDE_PLUGIN_ROOT}/skills/project-conventions/SKILL.md` and apply its guidance\n   - Read `${CLAUDE_PLUGIN_ROOT}/skills/language-patterns/SKILL.md` and apply its guidance\n\n3. **Launch code-explorer agents:**\n\n   Launch 2-3 code-explorer agents in parallel with different focus areas:\n   ```\n   Agent 1: Explore entry points and user-facing code related to the feature\n   Agent 2: Explore data models, schemas, and storage related to the feature\n   Agent 3: Explore utilities, helpers, and shared infrastructure (if applicable)\n   ```\n\n   Use the Task tool with `subagent_type: \"dev-tools:code-explorer\"`:\n   ```\n   Feature: [feature description]\n   Focus area: [specific focus for this agent]\n\n   Find and analyze:\n   - Relevant files and their purposes\n   - Key functions/classes that would be modified or extended\n   - Existing patterns to follow\n   - Potential integration points\n\n   Return a structured report of your findings.\n   ```\n\n4. **Synthesize findings:**\n   - Collect results from all agents\n   - Identify the key files that will need modification\n   - Note existing patterns and conventions\n   - List any potential challenges discovered\n\n5. **Read key files:**\n   - Read all files identified as critical for the implementation\n   - Build a mental model of how they work together\n\n6. Present exploration findings to the user.\n\n7. Mark Phase 2 as `completed`\n\n---\n\n## Phase 3: Clarifying Questions\n\n**Goal:** Resolve any ambiguities before designing.\n\n1. Mark Phase 3 as `in_progress`\n\n2. Review the feature requirements and exploration findings.\n\n3. Identify underspecified aspects:\n   - Edge cases not covered\n   - Technical decisions that could go multiple ways\n   - Integration points that need clarification\n   - Performance or scale requirements\n\n4. **Ask clarifying questions:**\n   Use AskUserQuestion to get answers for critical unknowns. Only ask questions that would significantly impact the implementation.\n\n   If no clarifying questions are needed, inform the user and proceed.\n\n5. Mark Phase 3 as `completed`\n\n---\n\n## Phase 4: Architecture Design\n\n**Goal:** Design the implementation approach.\n\n1. Mark Phase 4 as `in_progress`\n\n2. **Load skills for this phase:**\n   - Read `${CLAUDE_PLUGIN_ROOT}/skills/architecture-patterns/SKILL.md` and apply its guidance\n   - Read `${CLAUDE_PLUGIN_ROOT}/skills/language-patterns/SKILL.md` and apply its guidance\n\n3. **Launch code-architect agents:**\n\n   Launch 2-3 code-architect agents (Opus) with different approaches:\n   ```\n   Agent 1: Design a minimal, focused approach prioritizing simplicity\n   Agent 2: Design a flexible, extensible approach prioritizing future changes\n   Agent 3: Design an approach optimized for the project's existing patterns (if applicable)\n   ```\n\n   Use the Task tool with `subagent_type: \"dev-tools:code-architect\"`:\n   ```\n   Feature: [feature description]\n   Design approach: [specific approach for this agent]\n\n   Based on the codebase exploration:\n   [Summary of relevant files and patterns]\n\n   Design an implementation that:\n   - Lists files to create/modify\n   - Describes the changes needed in each file\n   - Explains the data flow\n   - Identifies risks and mitigations\n\n   Return a detailed implementation blueprint.\n   ```\n\n4. **Present approaches:**\n   - Summarize each approach\n   - Compare trade-offs (simplicity, flexibility, performance, maintainability)\n   - Make a recommendation with justification\n\n5. **User chooses approach:**\n   Use AskUserQuestion to let the user select an approach or request modifications.\n\n6. **Generate ADR artifact:**\n   - Read the ADR template from `${CLAUDE_PLUGIN_ROOT}/references/adr-template.md`\n   - Create an ADR documenting:\n     - Context: Why this feature is needed\n     - Decision: The chosen approach\n     - Consequences: Trade-offs and implications\n     - Alternatives: Other approaches considered\n   - Determine the next ADR number by checking existing files in `internal/docs/adr/`\n   - Save to `internal/docs/adr/NNNN-[feature-slug].md` (create `internal/docs/adr/` if needed)\n   - Inform the user of the saved ADR location\n\n7. Mark Phase 4 as `completed`\n\n---\n\n## Phase 5: Implementation\n\n**Goal:** Build the feature.\n\n1. Mark Phase 5 as `in_progress`\n\n2. **Require explicit approval:**\n   Ask the user: \"Ready to begin implementation of [feature] using [chosen approach]?\"\n   Wait for confirmation before proceeding.\n\n3. **Read all relevant files:**\n   Before making any changes, read the complete content of every file you'll modify.\n\n4. **Implement the feature:**\n   - Follow the chosen architecture design\n   - Match existing code patterns and conventions\n   - Create new files as needed\n   - Update existing files using Edit tool\n   - Add appropriate error handling\n   - Include inline comments only where logic isn't obvious\n\n5. **Track progress:**\n   Create sub-tasks in TodoWrite for each major implementation step.\n   Mark each as completed when done.\n\n6. **Test if applicable:**\n   - If the project has tests, add tests for the new functionality\n   - Run existing tests to ensure nothing broke\n\n7. Mark Phase 5 as `completed`\n\n8. **IMPORTANT: Proceed immediately to Phase 6.**\n   Do NOT stop here. Do NOT wait for user input. Implementation is complete, but the workflow requires Quality Review and Summary phases. Continue directly to Phase 6 now.\n\n---\n\n## Phase 6: Quality Review\n\n**Goal:** Review the implementation for issues.\n\n1. Mark Phase 6 as `in_progress`\n\n2. **Load skills for this phase:**\n   - Read `${CLAUDE_PLUGIN_ROOT}/skills/code-quality/SKILL.md` and apply its guidance\n\n3. **Launch code-reviewer agents:**\n\n   Launch 3 code-reviewer agents (Opus) with different focuses:\n   ```\n   Agent 1: Review for correctness and edge cases\n   Agent 2: Review for security and error handling\n   Agent 3: Review for maintainability and code quality\n   ```\n\n   Use the Task tool with `subagent_type: \"dev-tools:code-reviewer\"`:\n   ```\n   Review focus: [specific focus for this agent]\n\n   Files to review:\n   [List of files modified/created]\n\n   Review the implementation and report:\n   - Issues found with confidence scores (0-100)\n   - Suggestions for improvement\n   - Positive observations\n\n   Only report issues with confidence >= 80.\n   ```\n\n4. **Aggregate findings:**\n   - Collect results from all reviewers\n   - Deduplicate similar issues\n   - Prioritize by severity and confidence\n\n5. **Present findings:**\n   Show the user:\n   - Critical issues (must fix)\n   - Moderate issues (should fix)\n   - Minor suggestions (nice to have)\n\n6. **User decides:**\n   Use AskUserQuestion:\n   - \"Fix all issues now\"\n   - \"Fix critical issues only\"\n   - \"Proceed without fixes\"\n   - \"I'll fix manually later\"\n\n7. If fixing: make the changes and re-review if needed.\n\n8. Mark Phase 6 as `completed`\n\n9. **IMPORTANT: Proceed immediately to Phase 7.**\n   Do NOT stop here. The workflow requires a Summary phase to document accomplishments and update the CHANGELOG. Continue directly to Phase 7 now.\n\n---\n\n## Phase 7: Summary\n\n**Goal:** Document and celebrate accomplishments.\n\n1. Mark Phase 7 as `in_progress`\n\n2. **Ensure all todos complete:**\n   Mark any remaining sub-tasks as completed.\n\n3. **Summarize accomplishments:**\n   Present to the user:\n   - What was built\n   - Key files created/modified\n   - Architecture decisions made\n   - Any known limitations or future work\n\n4. **Update CHANGELOG.md:**\n   - Read the entry template from `${CLAUDE_PLUGIN_ROOT}/references/feature-changelog-template.md`\n   - Load the `changelog-format` skill for Keep a Changelog guidelines\n   - Create an entry under the `[Unreleased]` section with:\n     - Appropriate category (Added, Changed, Fixed, etc.)\n     - Concise description of the feature\n   - If `CHANGELOG.md` doesn't exist, create it with proper header\n   - Add the entry to the appropriate section under `[Unreleased]`\n   - Inform the user of the update\n\n5. Mark Phase 7 as `completed`\n\n6. **Final message:**\n   Congratulate the user and offer next steps:\n   - Commit the changes\n   - Create a PR\n   - Additional testing suggestions\n\n7. **Verify workflow completion:**\n   Confirm all 7 phases in TodoWrite are marked `completed`. If any phase was skipped, note it in your final summary.\n\n---\n\n## Error Handling\n\nIf any phase fails:\n1. Mark the phase as blocked in TodoWrite\n2. Explain what went wrong\n3. Ask the user how to proceed:\n   - Retry the phase\n   - Skip to next phase\n   - Abort the workflow\n\n---\n\n## Agent Coordination\n\nWhen launching parallel agents:\n- Give each agent a distinct focus area\n- Wait for all agents to complete before synthesizing\n- Handle agent failures gracefully (continue with partial results)\n\nWhen calling Task tool for agents:\n- Use `model: \"opus\"` for code-architect and code-reviewer agents\n- Use default model (sonnet) for code-explorer agents\n- Use `run_in_background: false` to wait for results\n",
        "plugins/dev-tools/commands/git-commit.md": "---\ndescription: Commit staged changes with conventional commit message\nallowed-tools: Bash, AskUserQuestion\n---\n\n# Git Commit\n\nCreate a commit with a conventional commit message based on staged changes. Automatically stages all changes and analyzes the diff to generate an appropriate commit message.\n\n## Workflow\n\nExecute these steps in order.\n\n---\n\n### Step 1: Check Repository State\n\nCheck for changes to commit:\n\n```bash\ngit status --porcelain\n```\n\n- If output is empty, report: \"Nothing to commit. Working directory is clean.\" and stop.\n- If changes exist, continue to Step 2.\n\n---\n\n### Step 2: Stage All Changes\n\nStage all changes including untracked files:\n\n```bash\ngit add .\n```\n\nReport: \"Staged all changes.\"\n\n---\n\n### Step 3: Analyze Changes\n\nView the staged diff to understand what changed:\n\n```bash\ngit diff --cached --stat\n```\n\n```bash\ngit diff --cached\n```\n\nAnalyze the diff to determine:\n- The type of change (feat, fix, docs, refactor, etc.)\n- The scope (optional, based on affected files/modules)\n- A concise description of what changed\n\n---\n\n### Step 4: Construct Commit Message\n\nBuild a conventional commit message following this format:\n\n```\n<type>(<optional-scope>): <description>\n\n[optional body]\n```\n\n**Types:**\n- `feat` - New feature\n- `fix` - Bug fix\n- `docs` - Documentation only\n- `style` - Formatting, no code change\n- `refactor` - Code restructuring without behavior change\n- `test` - Adding or updating tests\n- `chore` - Maintenance tasks\n- `build` - Build system or dependencies\n- `ci` - CI configuration\n- `perf` - Performance improvement\n\n**Rules:**\n- Use imperative mood (\"add\" not \"added\")\n- Use lowercase\n- No trailing period\n- Keep description under 72 characters\n- Add a body only for complex changes or breaking changes\n- Do NOT add co-author, attribution, or \"Generated with\" lines\n\n---\n\n### Step 5: Create Commit\n\nCreate the commit using a heredoc for proper formatting:\n\n```bash\ngit commit -m \"$(cat <<'EOF'\n<commit message here>\nEOF\n)\"\n```\n\n---\n\n### Step 6: Handle Result\n\n**On success:**\n- Report the commit hash: \"Committed: {short_hash} - {message}\"\n\n**On pre-commit hook failure:**\n- Report: \"Pre-commit hook failed. The commit was NOT created.\"\n- Explain what the hook reported\n- Instruct: \"Fix the issues above and run the commit command again. Do NOT use --amend as that would modify the previous commit.\"\n\n---\n\n## Error Recovery\n\nIf the commit fails:\n- **Hook failure**: Fix the reported issues, then stage and commit again (do NOT amend)\n- **Unstage changes**: `git reset HEAD` to unstage without losing changes\n\n## Notes\n\n- This command stages ALL changes including untracked files\n- Pre-commit hooks run automatically; their failures mean no commit was created\n- Always create a NEW commit after hook failure, never amend the previous commit\n",
        "plugins/dev-tools/commands/git-push.md": "---\ndescription: Push commits to remote with automatic rebase on conflict\nallowed-tools: Bash\n---\n\n# Git Push\n\nPush local commits to the remote repository. Automatically handles upstream conflicts by rebasing and retrying.\n\n## Workflow\n\nExecute these steps in order.\n\n---\n\n### Step 1: Check for Commits to Push\n\nGet the current branch and check if there are commits to push:\n\n```bash\ngit branch --show-current\n```\n\n```bash\ngit rev-parse HEAD\n```\n\n```bash\ngit rev-parse @{u} 2>/dev/null || echo \"no-upstream\"\n```\n\n- If no upstream exists, continue to push (will set upstream).\n- If local HEAD equals upstream HEAD, report: \"Already up to date. Nothing to push.\" and stop.\n- If local is ahead of upstream, continue to Step 2.\n\n---\n\n### Step 2: Push to Remote\n\nPush the current branch to origin:\n\n```bash\ngit push origin <current-branch>\n```\n\n- On success, continue to Step 4.\n- On failure, continue to Step 3.\n\n---\n\n### Step 3: Handle Push Failure\n\nIf push fails due to upstream changes:\n\n1. Pull with rebase:\n   ```bash\n   git pull --rebase origin <current-branch>\n   ```\n\n2. If rebase succeeds, retry push:\n   ```bash\n   git push origin <current-branch>\n   ```\n\n3. If rebase has conflicts:\n   - Report: \"Rebase conflicts detected. Please resolve conflicts manually.\"\n   - List the conflicting files\n   - Provide instructions:\n     ```\n     To resolve:\n     1. Fix conflicts in the listed files\n     2. Run: git add <resolved-files>\n     3. Run: git rebase --continue\n     4. Run: git push origin <branch>\n\n     To abort:\n     Run: git rebase --abort\n     ```\n   - Stop workflow.\n\n---\n\n### Step 4: Report Success\n\nOn successful push, report:\n\n```\nPushed to origin/<branch>\n```\n\nShow the commits that were pushed:\n\n```bash\ngit log @{u}..HEAD --oneline 2>/dev/null || git log -1 --oneline\n```\n\n---\n\n## Error Recovery\n\n**Push rejected (upstream changes):**\n- The workflow automatically attempts `git pull --rebase` and retries once\n- If conflicts occur, resolve manually following the provided instructions\n\n**Rebase conflicts:**\n- Resolve conflicts in listed files\n- `git add <resolved-files>` for each\n- `git rebase --continue` to finish\n- `git push origin <branch>` to push\n\n**Abort rebase:**\n- `git rebase --abort` returns to pre-rebase state\n\n## Notes\n\n- This command only pushes existing commits; it does not stage or commit\n- Use `/dev-tools:git-commit` first to create commits\n- Push failures due to upstream changes trigger an automatic rebase retry\n",
        "plugins/dev-tools/commands/release.md": "---\ndescription: Prepare and execute a Python package release with verification steps\nargument-hint: [version-override]\nallowed-tools: Read, Edit, Bash, AskUserQuestion, Glob, Task\n---\n\n# Python Release Manager\n\nExecute a complete pre-release workflow for Python packages using `uv` and `ruff`. This command automates version calculation, changelog updates, and tag creation.\n\n## Arguments\n\n- `$ARGUMENTS` - Optional version override (e.g., `1.0.0`). If not provided, version is calculated from changelog entries.\n\n## Workflow\n\nExecute these 9 steps in order. **Fail fast**: Stop immediately if any verification step fails.\n\n---\n\n### Step 1: Pre-flight Checks\n\nRun these checks and stop if any fail:\n\n```bash\n# Check current branch\ngit branch --show-current\n```\n- **Must be on `main` branch**. If not, stop and report: \"Release must be run from the main branch. Currently on: {branch}\"\n\n```bash\n# Check for uncommitted changes\ngit status --porcelain\n```\n- **Must have clean working directory**. If output is not empty, stop and report: \"Working directory has uncommitted changes. Please commit or stash them first.\"\n\n```bash\n# Pull latest changes\ngit pull origin main\n```\n- Report any merge conflicts and stop if they occur.\n\n---\n\n### Step 2: Run Tests\n\nExecute the test suite:\n\n```bash\nuv run pytest\n```\n\n- If tests fail, stop and report the failure output\n- If tests pass, report: \"All tests passed\"\n\n---\n\n### Step 3: Run Linting\n\nExecute linting checks:\n\n```bash\nuv run ruff check\n```\n\n```bash\nuv run ruff format --check\n```\n\n- If either command fails, stop and report the issues\n- If both pass, report: \"Linting and formatting checks passed\"\n\n---\n\n### Step 4: Verify Build\n\nBuild the package:\n\n```bash\nuv build\n```\n\n- If build fails, stop and report the error\n- If build succeeds, report: \"Package builds successfully\"\n\n---\n\n### Step 5: Changelog Update Check\n\nAll verification checks have passed. Before calculating the version, offer to run the changelog-agent to ensure the `[Unreleased]` section is up-to-date.\n\nUse AskUserQuestion:\n\n```\nWould you like to run the changelog-agent to update CHANGELOG.md before proceeding?\n\nThis will analyze git commits since the last release and suggest new changelog entries.\n```\n\nOptions:\n1. \"Yes, update changelog first (Recommended)\" - Recommended option\n2. \"No, continue with existing changelog\"\n\n**If user selects \"Yes\":**\n\nUse the Task tool to spawn the changelog-agent:\n- subagent_type: `dev-tools:changelog-agent`\n- prompt: \"Analyze commits since the last release and update the CHANGELOG.md [Unreleased] section\"\n- The agent will analyze commits, suggest entries, and update CHANGELOG.md after user approval\n- Wait for the agent to complete before proceeding\n\n**If user selects \"No\":**\n\nContinue to Step 6 (Calculate Version) without running the changelog-agent.\n\n---\n\n### Step 6: Calculate Version\n\n#### 6.1 Read CHANGELOG.md\n\nRead `CHANGELOG.md` and parse its structure. Look for:\n- The `## [Unreleased]` section and its subsections\n- The most recent versioned section (e.g., `## [0.1.0]`) to get the current version\n\n#### 6.2 Analyze Change Types\n\nCount entries under `[Unreleased]` by subsection:\n- `### Added` - New features\n- `### Changed` - Changes to existing functionality\n- `### Deprecated` - Features marked for removal\n- `### Removed` - Removed features (breaking change)\n- `### Fixed` - Bug fixes\n- `### Security` - Security fixes\n\n#### 6.3 Calculate Suggested Version\n\nApply semantic versioning rules to the current version (MAJOR.MINOR.PATCH):\n\n| Condition | Bump Type | Example |\n|-----------|-----------|---------|\n| `### Removed` present AND current >= 1.0.0 | MAJOR | 1.2.3 → 2.0.0 |\n| `### Removed` present AND current < 1.0.0 | MINOR | 0.2.3 → 0.3.0 |\n| `### Added` or `### Changed` present | MINOR | 0.1.0 → 0.2.0 |\n| Only `### Fixed`, `### Security`, or `### Deprecated` | PATCH | 0.1.0 → 0.1.1 |\n\n#### 6.4 Handle Edge Cases\n\n- **No unreleased changes**: Warn user \"No entries found under [Unreleased]. Are you sure you want to release?\"\n- **Missing CHANGELOG.md**: Stop and report \"CHANGELOG.md not found. Please create one following Keep a Changelog format.\"\n- **Version override provided**: Use `$ARGUMENTS` as the version instead of calculating\n\n#### 6.5 User Confirmation\n\nUse AskUserQuestion to confirm the version:\n\n```\nBased on changelog analysis:\n- Found: {count} Added, {count} Changed, {count} Fixed, {count} Removed entries\n- Current version: {current}\n- Suggested version: {suggested} ({bump_type} bump)\n\nConfirm version or provide override:\n```\n\nOptions:\n1. \"Confirm {suggested}\"\n2. \"Enter different version\"\n\n---\n\n### Step 7: Update CHANGELOG.md\n\n#### 7.1 Get Repository URL\n\nRead `pyproject.toml` and extract the repository URL from `[project.urls]`:\n- Check keys: `Repository`, `repository`, `Source`, `source`, `Homepage`, `homepage`\n- Extract the GitHub/GitLab URL\n\nIf no repository URL found, warn but continue (comparison links will be omitted).\n\n#### 7.2 Update Changelog Content\n\nTransform the changelog:\n\n**Before:**\n```markdown\n## [Unreleased]\n\n### Added\n- New feature X\n\n## [0.1.0] - 2024-01-15\n\n### Added\n- Initial release\n\n[Unreleased]: https://github.com/user/repo/compare/v0.1.0...HEAD\n[0.1.0]: https://github.com/user/repo/releases/tag/v0.1.0\n```\n\n**After (releasing 0.2.0):**\n```markdown\n## [Unreleased]\n\n## [0.2.0] - {today's date YYYY-MM-DD}\n\n### Added\n- New feature X\n\n## [0.1.0] - 2024-01-15\n\n### Added\n- Initial release\n\n[Unreleased]: https://github.com/user/repo/compare/v0.2.0...HEAD\n[0.2.0]: https://github.com/user/repo/compare/v0.1.0...v0.2.0\n[0.1.0]: https://github.com/user/repo/releases/tag/v0.1.0\n```\n\n#### 7.3 Write Updated CHANGELOG.md\n\nUse the Edit tool to update CHANGELOG.md with the transformed content.\n\n---\n\n### Step 8: Commit Changelog\n\nStage and commit the changelog update:\n\n```bash\ngit add CHANGELOG.md\n```\n\n```bash\ngit commit -m \"docs: update changelog for v{version}\"\n```\n\n```bash\ngit push origin main\n```\n\nReport: \"Changelog committed and pushed\"\n\n---\n\n### Step 9: Create and Push Tag\n\nCreate an annotated tag and push it:\n\n```bash\ngit tag -a v{version} -m \"Release v{version}\"\n```\n\n```bash\ngit push origin v{version}\n```\n\n#### Final Report\n\nReport success with details:\n```\nRelease v{version} completed successfully!\n\n- Changelog updated: CHANGELOG.md\n- Tag created: v{version}\n- Tag URL: {repository_url}/releases/tag/v{version}\n\nNext steps:\n- GitHub/GitLab will create a release from the tag\n- Publish to PyPI if configured in CI\n```\n\n---\n\n## Error Recovery\n\nIf any step fails after Step 6 (version confirmation):\n- Report which step failed and the error\n- Provide commands to manually complete or rollback:\n  - `git checkout CHANGELOG.md` - Revert changelog changes\n  - `git tag -d v{version}` - Delete local tag if created\n  - `git push origin :refs/tags/v{version}` - Delete remote tag if pushed\n",
        "plugins/dev-tools/skills/architecture-patterns/SKILL.md": "---\ndescription: Provides architectural pattern knowledge for designing feature implementations including MVC, event-driven, microservices, and CQRS patterns\n---\n\n# Architecture Patterns\n\nThis skill provides knowledge about common architectural patterns to help design feature implementations. Apply these patterns based on the project's existing architecture and the feature's requirements.\n\n## Pattern Selection Guide\n\nChoose patterns based on:\n1. **Existing architecture** - Match what's already in use\n2. **Team familiarity** - Use patterns the team knows\n3. **Feature requirements** - Some patterns fit better for certain features\n4. **Scale requirements** - Consider current and future scale\n\n---\n\n## Layered Architecture (N-Tier)\n\n**When to use:** Most web applications, CRUD operations, clear separation of concerns needed\n\n**Layers:**\n```\n┌─────────────────────────┐\n│   Presentation Layer    │  UI, API endpoints, controllers\n├─────────────────────────┤\n│    Application Layer    │  Use cases, orchestration, DTOs\n├─────────────────────────┤\n│      Domain Layer       │  Business logic, entities, rules\n├─────────────────────────┤\n│   Infrastructure Layer  │  Database, external services, I/O\n└─────────────────────────┘\n```\n\n**Key rules:**\n- Dependencies flow downward only\n- Each layer only talks to the layer directly below\n- Domain layer has no external dependencies\n\n**Implementation tips:**\n- Use interfaces at layer boundaries\n- Keep domain logic in the domain layer, not controllers\n- Use DTOs to transfer data between layers\n\n---\n\n## MVC (Model-View-Controller)\n\n**When to use:** Web applications with server-rendered views, simple CRUD apps\n\n**Components:**\n```\nUser → Controller → Model → Controller → View → User\n           ↓           ↑\n        Updates      Reads\n```\n\n**Model:** Data and business logic\n**View:** Presentation/UI\n**Controller:** Handles input, coordinates model and view\n\n**Implementation tips:**\n- Keep controllers thin - delegate to services\n- Models should be framework-agnostic when possible\n- Views should have minimal logic\n\n---\n\n## Repository Pattern\n\n**When to use:** Data access abstraction, testability, multiple data sources\n\n**Structure:**\n```typescript\ninterface UserRepository {\n  findById(id: string): Promise<User | null>;\n  findByEmail(email: string): Promise<User | null>;\n  save(user: User): Promise<User>;\n  delete(id: string): Promise<void>;\n}\n\nclass PostgresUserRepository implements UserRepository {\n  // Implementation using PostgreSQL\n}\n\nclass InMemoryUserRepository implements UserRepository {\n  // Implementation for testing\n}\n```\n\n**Benefits:**\n- Abstracts data access details\n- Easy to swap implementations\n- Simplifies testing with in-memory implementations\n\n---\n\n## Service Layer Pattern\n\n**When to use:** Complex business logic, multiple entry points (API, CLI, queue)\n\n**Structure:**\n```typescript\nclass UserService {\n  constructor(\n    private userRepo: UserRepository,\n    private emailService: EmailService,\n    private logger: Logger\n  ) {}\n\n  async registerUser(data: RegisterDTO): Promise<User> {\n    // Validation\n    // Business logic\n    // Coordination of multiple repositories/services\n    // Return result\n  }\n}\n```\n\n**Implementation tips:**\n- Services contain business logic, not controllers\n- One service per domain concept\n- Services can call other services (but avoid cycles)\n\n---\n\n## Event-Driven Architecture\n\n**When to use:** Decoupled components, async processing, audit trails, notifications\n\n**Patterns:**\n\n### Event Emitter (Simple)\n```typescript\n// Emit events for side effects\nuserService.on('userCreated', async (user) => {\n  await emailService.sendWelcome(user);\n  await analyticsService.trackSignup(user);\n});\n```\n\n### Message Queue (Distributed)\n```\nProducer → Queue → Consumer\n              ↓\n           Consumer\n```\n\n**Event structure:**\n```typescript\ninterface DomainEvent {\n  type: string;\n  timestamp: Date;\n  payload: unknown;\n  metadata: {\n    correlationId: string;\n    causationId: string;\n  };\n}\n```\n\n**Implementation tips:**\n- Events should be immutable\n- Include enough context to process without additional queries\n- Handle idempotency for at-least-once delivery\n\n---\n\n## CQRS (Command Query Responsibility Segregation)\n\n**When to use:** Complex domains, different read/write patterns, high-performance reads needed\n\n**Structure:**\n```\nCommands (Write)              Queries (Read)\n     ↓                              ↓\nCommand Handler              Query Handler\n     ↓                              ↓\nWrite Model                  Read Model\n     ↓                              ↓\nWrite Database              Read Database\n```\n\n**Simplified CQRS:**\n```typescript\n// Commands modify state\nclass CreateUserCommand {\n  execute(data: CreateUserDTO): Promise<void>\n}\n\n// Queries return data without modification\nclass GetUserQuery {\n  execute(id: string): Promise<UserDTO>\n}\n```\n\n**Implementation tips:**\n- Start simple - same database, different models\n- Use for complex domains where read/write models differ\n- Consider eventual consistency implications\n\n---\n\n## Ports and Adapters (Hexagonal)\n\n**When to use:** High testability needs, multiple I/O channels, long-lived applications\n\n**Structure:**\n```\n          ┌──────────────────────────────────────┐\nAdapters  │  HTTP  │  CLI  │  Queue  │  Timer   │\n(Driving) └────────┴───────┴─────────┴──────────┘\n                          ↓ Ports\n          ┌──────────────────────────────────────┐\n          │         Application Core            │\n          │  ┌────────────────────────────────┐ │\n          │  │      Domain Logic              │ │\n          │  └────────────────────────────────┘ │\n          └──────────────────────────────────────┘\n                          ↓ Ports\n          ┌──────────────────────────────────────┐\nAdapters  │  DB   │  Cache │  Email  │  API     │\n(Driven)  └───────┴────────┴─────────┴──────────┘\n```\n\n**Key concept:** Business logic at center, all I/O through ports/adapters\n\n**Implementation tips:**\n- Define ports (interfaces) for all external interactions\n- Adapters implement ports for specific technologies\n- Domain code never imports adapter code\n\n---\n\n## Microservices Patterns\n\n**When to use:** Large teams, independent deployability, different scaling needs\n\n### API Gateway\nSingle entry point that routes to services\n\n### Service Discovery\nServices register themselves, clients look them up\n\n### Circuit Breaker\nPrevent cascade failures when services are down\n```typescript\nconst breaker = new CircuitBreaker(remoteService.call, {\n  timeout: 3000,\n  errorThreshold: 50,\n  resetTimeout: 30000\n});\n```\n\n### Saga Pattern\nCoordinate transactions across services\n```\nService A → Service B → Service C\n    ↓           ↓           ↓\nCompensate ← Compensate ← Compensate (on failure)\n```\n\n---\n\n## Choosing the Right Pattern\n\n| Scenario | Recommended Pattern |\n|----------|---------------------|\n| Simple CRUD app | MVC + Repository |\n| Complex business logic | Layered + Service Layer |\n| Need audit trail | Event-Driven |\n| High read/write disparity | CQRS |\n| Maximum testability | Hexagonal |\n| Multiple teams/services | Microservices patterns |\n\n## Anti-Patterns to Avoid\n\n1. **Big Ball of Mud** - No clear structure\n2. **God Object** - One class does everything\n3. **Spaghetti Code** - Tangled dependencies\n4. **Golden Hammer** - Using one pattern for everything\n5. **Premature Optimization** - Complex patterns for simple needs\n\n## Application Guidelines\n\n1. **Match existing architecture** - Don't introduce new patterns unnecessarily\n2. **Start simple** - Add complexity only when needed\n3. **Document decisions** - Explain why a pattern was chosen\n4. **Consider team skills** - A simpler pattern well-executed beats a complex one poorly understood\n",
        "plugins/dev-tools/skills/changelog-format/SKILL.md": "---\ndescription: Keep a Changelog format guidelines and entry writing best practices\ntriggers:\n  - changelog format\n  - keep a changelog\n  - changelog entry\n  - write changelog\n  - changelog categories\n  - changelog best practices\n---\n\n# Keep a Changelog Format\n\nThis skill provides guidelines for writing and formatting changelogs following the [Keep a Changelog](https://keepachangelog.com/) specification.\n\n## Core Principles\n\n1. **Changelogs are for humans** - Write for users, not machines\n2. **Every version gets a section** - Including `[Unreleased]` for upcoming changes\n3. **Changes are grouped by type** - Consistent categorization\n4. **Versions are linkable** - Each version header links to comparison\n5. **Latest version comes first** - Reverse chronological order\n6. **Release dates are shown** - ISO format: YYYY-MM-DD\n\n## Change Categories\n\nUse these categories in this order:\n\n| Category | Description | When to Use |\n|----------|-------------|-------------|\n| **Added** | New features | New functionality users can now do |\n| **Changed** | Changes in existing functionality | Behavior modifications, improvements |\n| **Deprecated** | Soon-to-be removed features | Features marked for future removal |\n| **Removed** | Removed features | Features that no longer exist |\n| **Fixed** | Bug fixes | Corrections to existing functionality |\n| **Security** | Security vulnerability fixes | Security-related changes |\n\n### Category Guidelines\n\n**Added**\n- New user-facing features\n- New API endpoints\n- New configuration options\n- New integrations\n\n**Changed**\n- Performance improvements\n- UX/UI changes\n- Default value changes\n- Behavior modifications\n\n**Deprecated**\n- Features planned for removal\n- APIs being replaced\n- Include migration path when possible\n\n**Removed**\n- Breaking changes (removed functionality)\n- Deleted APIs or features\n- Always note what replaced it (if applicable)\n\n**Fixed**\n- Bug corrections\n- Error handling improvements\n- Edge case fixes\n\n**Security**\n- Vulnerability patches\n- Security-related fixes\n- Always include CVE if available\n\n## Entry Writing Guidelines\n\n### Use Imperative Mood\n\nStart entries with imperative verbs:\n\n| Do | Don't |\n|----|-------|\n| Add support for... | Added support for... |\n| Fix crash when... | Fixed a crash that occurred when... |\n| Remove deprecated... | Removed the deprecated... |\n| Change default to... | Changed the default to... |\n\n### Focus on User Impact\n\nWrite from the user's perspective:\n\n| Good (User-focused) | Bad (Implementation-focused) |\n|---------------------|------------------------------|\n| Add dark mode toggle | Implement ThemeProvider context |\n| Fix login failing silently | Add try-catch to auth handler |\n| Speed up page load by 40% | Optimize database queries |\n\n### Be Specific and Concise\n\n| Good (Specific) | Bad (Vague) |\n|-----------------|-------------|\n| Fix crash when uploading files over 10MB | Fix upload bug |\n| Add CSV export for transaction history | Add export feature |\n| Change session timeout from 30 to 60 minutes | Update session settings |\n\n### Include Context When Helpful\n\nUse parenthetical context for clarity:\n\n```markdown\n- Add OAuth2 support (Google, GitHub)\n- Fix timezone handling (UTC offset calculation)\n- Change rate limit (100 → 500 requests/minute)\n```\n\n## Changelog Structure\n\n```markdown\n# Changelog\n\nAll notable changes to this project will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/),\nand this project adheres to [Semantic Versioning](https://semver.org/).\n\n## [Unreleased]\n\n### Added\n- New entries go here\n\n## [1.0.0] - 2024-01-15\n\n### Added\n- Initial public release\n- Feature A with description\n- Feature B with description\n\n### Changed\n- Improvement to existing feature\n\n### Fixed\n- Bug fix description\n\n## [0.9.0] - 2024-01-01\n\n### Added\n- Beta release features\n\n[Unreleased]: https://github.com/owner/repo/compare/v1.0.0...HEAD\n[1.0.0]: https://github.com/owner/repo/compare/v0.9.0...v1.0.0\n[0.9.0]: https://github.com/owner/repo/releases/tag/v0.9.0\n```\n\n## Semantic Versioning Connection\n\nChangelog categories map to version bumps:\n\n| Category | Version Impact |\n|----------|----------------|\n| Removed (after v1.0) | MAJOR bump |\n| Removed (before v1.0) | MINOR bump |\n| Added, Changed | MINOR bump |\n| Deprecated, Fixed, Security | PATCH bump |\n\n## What NOT to Include\n\n- Internal refactoring (unless it affects users)\n- Dependency updates (unless they affect functionality)\n- Test changes\n- CI/CD changes\n- Documentation-only changes (unless user-facing docs)\n- Code style/formatting changes\n\n## Reference Files\n\n- `references/entry-examples.md` - Examples of well-written vs poorly-written entries\n",
        "plugins/dev-tools/skills/changelog-format/references/entry-examples.md": "# Changelog Entry Examples\n\nThis document provides examples of well-written and poorly-written changelog entries to guide entry creation.\n\n## Added Category\n\n### Good Examples\n\n```markdown\n- Add user authentication with email/password and OAuth (Google, GitHub)\n- Add bulk export of transactions to CSV and Excel formats\n- Add keyboard shortcuts for common actions (Ctrl+S to save, Ctrl+Z to undo)\n- Add dark mode with automatic system preference detection\n- Add webhook support for order status changes\n- Add rate limiting (100 requests/minute per API key)\n```\n\n### Poor Examples (with corrections)\n\n| Poor Entry | Why It's Poor | Better Version |\n|------------|---------------|----------------|\n| `Added new feature` | Too vague, no information | `Add invoice PDF generation` |\n| `Implemented AuthService class` | Implementation detail, not user-facing | `Add user authentication` |\n| `Added support for thing` | Unclear what \"thing\" is | `Add support for WebP image uploads` |\n| `New button` | No context, incomplete | `Add \"Export All\" button to dashboard` |\n\n---\n\n## Changed Category\n\n### Good Examples\n\n```markdown\n- Improve search performance (3x faster for large datasets)\n- Change default session timeout from 30 minutes to 2 hours\n- Update password requirements: minimum 12 characters, 1 number required\n- Redesign settings page with tabbed navigation\n- Move API documentation to /docs endpoint\n- Increase file upload limit from 5MB to 25MB\n```\n\n### Poor Examples (with corrections)\n\n| Poor Entry | Why It's Poor | Better Version |\n|------------|---------------|----------------|\n| `Refactored code` | Internal detail, no user impact | (Omit, or) `Improve page load speed by 40%` |\n| `Updated dependencies` | Internal maintenance | (Omit unless user-facing change) |\n| `Changed stuff` | Completely uninformative | `Change notification preferences to opt-in` |\n| `Made improvements` | Too vague | `Improve error messages with specific guidance` |\n\n---\n\n## Fixed Category\n\n### Good Examples\n\n```markdown\n- Fix crash when uploading files larger than 10MB\n- Fix incorrect tax calculation for international orders\n- Fix login button not responding on mobile Safari\n- Fix timezone display showing UTC instead of local time\n- Fix memory leak causing slowdown after extended use\n- Fix email notifications not sending for new comments\n```\n\n### Poor Examples (with corrections)\n\n| Poor Entry | Why It's Poor | Better Version |\n|------------|---------------|----------------|\n| `Fixed bug` | No description of what was fixed | `Fix duplicate orders created on retry` |\n| `Bug fix` | Even less information | `Fix search returning stale results` |\n| `Fixed issue #123` | Requires looking up issue | `Fix CSV export missing header row (#123)` |\n| `Fixed null pointer exception in UserService.java:42` | Too technical | `Fix crash when viewing deleted user profile` |\n\n---\n\n## Removed Category\n\n### Good Examples\n\n```markdown\n- Remove deprecated /api/v1 endpoints (use /api/v2 instead)\n- Remove support for Internet Explorer 11\n- Remove \"Classic\" theme (migrate to \"Modern\" theme in settings)\n- Remove automatic social media sharing (use manual share buttons)\n- Remove legacy import format (use CSV import instead)\n```\n\n### Poor Examples (with corrections)\n\n| Poor Entry | Why It's Poor | Better Version |\n|------------|---------------|----------------|\n| `Removed old code` | What capability was lost? | `Remove legacy report generator` |\n| `Deleted files` | Meaningless to users | (Omit if internal) |\n| `Removed feature` | Which feature? | `Remove email digest option` |\n\n---\n\n## Deprecated Category\n\n### Good Examples\n\n```markdown\n- Deprecate /api/v1/users endpoint (use /api/v2/users, removal in v3.0)\n- Deprecate XML export format (use JSON export, removal in 6 months)\n- Deprecate \"Classic\" theme (will be removed in next major version)\n- Deprecate basicAuth parameter (use apiKey authentication instead)\n```\n\n### Poor Examples (with corrections)\n\n| Poor Entry | Why It's Poor | Better Version |\n|------------|---------------|----------------|\n| `Deprecated old API` | No migration path | `Deprecate /legacy endpoint (use /api/v2, removal in v2.0)` |\n| `Will remove soon` | No timeline or alternative | `Deprecate CSV import (use Excel import, removal March 2024)` |\n\n---\n\n## Security Category\n\n### Good Examples\n\n```markdown\n- Fix XSS vulnerability in comment rendering (CVE-2024-1234)\n- Fix SQL injection in search query parameter\n- Add Content-Security-Policy headers\n- Update authentication to prevent session fixation attacks\n- Fix CSRF vulnerability in account settings form\n- Upgrade TLS minimum version to 1.2\n```\n\n### Poor Examples (with corrections)\n\n| Poor Entry | Why It's Poor | Better Version |\n|------------|---------------|----------------|\n| `Security fix` | No information about what was fixed | `Fix authentication bypass vulnerability` |\n| `Fixed vulnerability` | Too vague | `Fix stored XSS in user profile bio field` |\n| `Updated security` | Meaningless | `Add rate limiting to prevent brute force attacks` |\n\n---\n\n## Grouping Related Changes\n\nWhen multiple related changes are made, group them thoughtfully:\n\n### Good Grouping\n\n```markdown\n### Added\n- Add user profile customization\n  - Profile picture upload\n  - Bio and social links\n  - Custom theme colors\n- Add team collaboration features\n  - Shared workspaces\n  - Real-time presence indicators\n  - Comment threads on items\n```\n\n### Alternative: Separate Entries\n\n```markdown\n### Added\n- Add profile picture upload with crop and resize\n- Add customizable bio and social media links\n- Add shared team workspaces\n- Add real-time presence indicators for team members\n```\n\n---\n\n## Entries with Technical Context\n\nWhen technical details help users, include them appropriately:\n\n### Good Examples\n\n```markdown\n- Add GraphQL API alongside existing REST API\n- Add WebSocket support for real-time updates (replaces polling)\n- Fix N+1 query issue causing slow dashboard load\n- Change database connection pooling (improves concurrent user handling)\n```\n\n### Avoid Over-Technical Entries\n\n| Too Technical | User-Friendly Version |\n|---------------|----------------------|\n| `Migrate from Redux to Zustand` | `Improve app responsiveness` (or omit) |\n| `Refactor to use React hooks` | (Omit - internal change) |\n| `Upgrade PostgreSQL 14 → 16` | (Omit unless user-facing) |\n| `Add index on users.email column` | `Improve login speed` |\n\n---\n\n## Breaking Changes\n\nClearly indicate breaking changes:\n\n```markdown\n### Removed\n- **BREAKING**: Remove support for Node.js 14 (minimum now Node.js 18)\n- **BREAKING**: Remove /api/v1 endpoints (migrate to /api/v2)\n\n### Changed\n- **BREAKING**: Change config file format from YAML to TOML\n- **BREAKING**: Rename `user.name` field to `user.displayName` in API responses\n```\n",
        "plugins/dev-tools/skills/code-quality/SKILL.md": "---\ndescription: Provides code quality principles including SOLID, DRY, testing strategies, and best practices for implementation review\n---\n\n# Code Quality\n\nThis skill provides code quality principles and best practices for reviewing and improving implementations.\n\n---\n\n## SOLID Principles\n\n### Single Responsibility Principle (SRP)\nA class/function should have one reason to change.\n\n**Bad:**\n```typescript\nclass UserService {\n  createUser(data) { /* creates user */ }\n  sendEmail(user) { /* sends email */ }\n  generateReport(users) { /* generates report */ }\n}\n```\n\n**Good:**\n```typescript\nclass UserService {\n  createUser(data) { /* creates user */ }\n}\nclass EmailService {\n  sendEmail(user) { /* sends email */ }\n}\nclass ReportService {\n  generateReport(users) { /* generates report */ }\n}\n```\n\n### Open/Closed Principle (OCP)\nOpen for extension, closed for modification.\n\n**Bad:** Adding new payment types requires modifying existing code\n```typescript\nfunction processPayment(type, amount) {\n  if (type === 'credit') { /* ... */ }\n  else if (type === 'debit') { /* ... */ }\n  // Must modify to add new types\n}\n```\n\n**Good:** New payment types can be added without modification\n```typescript\ninterface PaymentProcessor {\n  process(amount: number): Promise<void>;\n}\nclass CreditProcessor implements PaymentProcessor { /* ... */ }\nclass DebitProcessor implements PaymentProcessor { /* ... */ }\n```\n\n### Liskov Substitution Principle (LSP)\nSubtypes must be substitutable for their base types.\n\n**Bad:**\n```typescript\nclass Bird {\n  fly() { /* ... */ }\n}\nclass Penguin extends Bird {\n  fly() { throw new Error(\"Can't fly!\"); } // Violates LSP\n}\n```\n\n**Good:**\n```typescript\nclass Bird { /* ... */ }\nclass FlyingBird extends Bird {\n  fly() { /* ... */ }\n}\nclass Penguin extends Bird { /* no fly method */ }\n```\n\n### Interface Segregation Principle (ISP)\nClients shouldn't depend on interfaces they don't use.\n\n**Bad:**\n```typescript\ninterface Worker {\n  work(): void;\n  eat(): void;\n  sleep(): void;\n}\n```\n\n**Good:**\n```typescript\ninterface Workable { work(): void; }\ninterface Eatable { eat(): void; }\ninterface Sleepable { sleep(): void; }\n```\n\n### Dependency Inversion Principle (DIP)\nDepend on abstractions, not concretions.\n\n**Bad:**\n```typescript\nclass UserService {\n  private db = new PostgresDatabase();\n}\n```\n\n**Good:**\n```typescript\nclass UserService {\n  constructor(private db: Database) {}\n}\n```\n\n---\n\n## DRY, KISS, YAGNI\n\n### DRY (Don't Repeat Yourself)\nEvery piece of knowledge should have a single representation.\n\n**Apply when:**\n- Same logic appears 3+ times\n- Changes to one place require changes to others\n- Bug fixes need to be applied in multiple places\n\n**Don't over-apply:**\n- Two similar things might diverge later\n- Premature abstraction can be worse than duplication\n\n### KISS (Keep It Simple, Stupid)\nPrefer simple solutions over clever ones.\n\n**Simple code:**\n- Easy to read and understand\n- Easy to debug\n- Easy to modify\n- Has fewer bugs\n\n### YAGNI (You Aren't Gonna Need It)\nDon't add functionality until it's needed.\n\n**Avoid:**\n- Building for hypothetical requirements\n- Adding \"just in case\" features\n- Over-engineering for scale you don't have\n\n---\n\n## Clean Code Principles\n\n### Meaningful Names\n```typescript\n// Bad\nconst d = new Date();\nconst arr = users.filter(u => u.a > 18);\n\n// Good\nconst currentDate = new Date();\nconst adultUsers = users.filter(user => user.age > 18);\n```\n\n### Small Functions\n- Do one thing well\n- Few parameters (ideally 0-3)\n- Single level of abstraction\n\n### Avoid Side Effects\n```typescript\n// Bad: side effect hidden in getter\ngetUser() {\n  this.lastAccess = Date.now(); // Side effect!\n  return this.user;\n}\n\n// Good: explicit about what it does\ngetUser() {\n  return this.user;\n}\nrecordAccess() {\n  this.lastAccess = Date.now();\n}\n```\n\n### Error Handling\n```typescript\n// Be specific about errors\nclass ValidationError extends Error {}\nclass NotFoundError extends Error {}\nclass AuthorizationError extends Error {}\n\n// Handle at appropriate level\ntry {\n  await processOrder(order);\n} catch (error) {\n  if (error instanceof ValidationError) {\n    return res.status(400).json({ error: error.message });\n  }\n  if (error instanceof NotFoundError) {\n    return res.status(404).json({ error: error.message });\n  }\n  throw error; // Re-throw unexpected errors\n}\n```\n\n---\n\n## Testing Strategies\n\n### Test Pyramid\n```\n      /\\\n     /  \\      E2E Tests (few)\n    /────\\\n   /      \\    Integration Tests (some)\n  /────────\\\n /          \\  Unit Tests (many)\n/────────────\\\n```\n\n### Unit Testing\n- Test individual functions/classes\n- Mock dependencies\n- Fast and isolated\n\n```typescript\ndescribe('calculateTotal', () => {\n  it('sums item prices', () => {\n    const items = [{ price: 10 }, { price: 20 }];\n    expect(calculateTotal(items)).toBe(30);\n  });\n\n  it('applies discount', () => {\n    const items = [{ price: 100 }];\n    expect(calculateTotal(items, { discount: 0.1 })).toBe(90);\n  });\n\n  it('handles empty cart', () => {\n    expect(calculateTotal([])).toBe(0);\n  });\n});\n```\n\n### Integration Testing\n- Test component interactions\n- Use real dependencies (or test doubles)\n- Database, API integration\n\n### Test Behavior, Not Implementation\n```typescript\n// Bad: tests implementation details\nit('calls _internalMethod', () => {\n  const spy = jest.spyOn(service, '_internalMethod');\n  service.doThing();\n  expect(spy).toHaveBeenCalled();\n});\n\n// Good: tests behavior\nit('sends welcome email on registration', async () => {\n  await service.registerUser({ email: 'test@test.com' });\n  expect(emailSent).toContainEqual({\n    to: 'test@test.com',\n    template: 'welcome'\n  });\n});\n```\n\n### Edge Cases to Test\n- Empty inputs\n- Null/undefined\n- Boundary values\n- Error conditions\n- Concurrent operations\n- Large inputs\n\n---\n\n## Code Review Checklist\n\n### Correctness\n- [ ] Does the code do what it's supposed to?\n- [ ] Are edge cases handled?\n- [ ] Are error conditions handled?\n\n### Security\n- [ ] Is input validated?\n- [ ] Are outputs escaped?\n- [ ] Are secrets protected?\n\n### Performance\n- [ ] Are there N+1 queries?\n- [ ] Are there unnecessary loops?\n- [ ] Is caching used appropriately?\n\n### Maintainability\n- [ ] Is the code readable?\n- [ ] Are names meaningful?\n- [ ] Is complexity reasonable?\n- [ ] Is there appropriate documentation?\n\n### Testing\n- [ ] Are there tests?\n- [ ] Do tests cover edge cases?\n- [ ] Are tests maintainable?\n\n---\n\n## Common Code Smells\n\n| Smell | Description | Solution |\n|-------|-------------|----------|\n| Long Method | Function > 20-30 lines | Extract methods |\n| Large Class | Class with too many responsibilities | Split into focused classes |\n| Long Parameter List | > 3-4 parameters | Use parameter object |\n| Duplicate Code | Same code in multiple places | Extract function |\n| Dead Code | Unused code | Delete it |\n| Magic Numbers | Unexplained numeric literals | Use named constants |\n| Nested Conditionals | Deep if/else nesting | Early returns, extract methods |\n| Feature Envy | Method uses another class's data heavily | Move method to that class |\n\n---\n\n## Refactoring Techniques\n\n### Extract Function\nWhen a code block can be grouped and named\n\n### Inline Function\nWhen the function body is as clear as the name\n\n### Extract Variable\nWhen an expression is complex\n\n### Rename Variable/Function\nWhen the name doesn't communicate intent\n\n### Replace Conditional with Polymorphism\nWhen you have repeated switch/if statements on type\n\n### Introduce Parameter Object\nWhen several parameters travel together\n",
        "plugins/dev-tools/skills/git-workflow/SKILL.md": "---\ndescription: Orchestrates git commit and push operations based on user intent\ntriggers:\n  - commit changes\n  - save changes\n  - commit this\n  - commit it\n  - push it\n  - push changes\n  - push to remote\n  - push it up\n  - commit and push\n  - ship it\n  - send it up\n---\n\n# Git Workflow\n\nThis skill routes git operations to the appropriate commands based on user intent.\n\n## When to Use\n\nTrigger this skill when the user wants to:\n\n- **Commit only**: \"commit changes\", \"save changes\", \"commit this\", \"commit it\", \"commit my work\"\n- **Push only**: \"push changes\", \"push to remote\", \"push it up\", \"push this\", \"push it\"\n- **Both**: \"commit and push\", \"ship it\", \"send it up\", \"save and push\"\n\n## Behavior\n\n### Commit Only\n\nWhen the user's intent is to commit without pushing:\n\n**Trigger phrases**: commit, save changes, commit this, commit it, commit my work\n\n**Action**: Run `/dev-tools:git-commit`\n\n### Push Only\n\nWhen the user's intent is to push existing commits without creating a new commit:\n\n**Trigger phrases**: push, push changes, push to remote, push it up, push it\n\n**Action**: Run `/dev-tools:git-push`\n\n### Commit and Push\n\nWhen the user wants to commit their changes AND push them to the remote:\n\n**Trigger phrases**: commit and push, ship it, send it up, save and push\n\n**Action**: Run `/dev-tools:git-commit` first, then `/dev-tools:git-push`\n\n## Decision Logic\n\n1. Parse the user's request for intent keywords\n2. If request contains \"push\" but NOT \"commit\" → push only\n3. If request contains \"commit\" or \"save\" but NOT \"push\" → commit only\n4. If request contains both \"commit\" and \"push\" → commit then push\n5. If request matches \"ship it\" or \"send it up\" → commit then push\n\n## Notes\n\n- The commit command stages all changes before committing\n- The push command handles upstream conflicts with automatic rebase\n- If commit fails (e.g., pre-commit hook), do not proceed to push\n",
        "plugins/dev-tools/skills/language-patterns/SKILL.md": "---\ndescription: Provides language-specific patterns for TypeScript, Python, and React including idioms, best practices, and common patterns\n---\n\n# Language Patterns\n\nThis skill provides language-specific patterns and best practices. Apply patterns that match the project's language and framework.\n\n---\n\n## TypeScript Patterns\n\n### Type Safety\n\n**Use strict types over `any`:**\n```typescript\n// Bad\nfunction process(data: any): any {\n  return data.value;\n}\n\n// Good\ninterface DataItem {\n  value: string;\n  count: number;\n}\n\nfunction process(data: DataItem): string {\n  return data.value;\n}\n```\n\n**Use discriminated unions for variants:**\n```typescript\ntype Result<T> =\n  | { success: true; data: T }\n  | { success: false; error: Error };\n\nfunction handleResult<T>(result: Result<T>) {\n  if (result.success) {\n    // TypeScript knows result.data exists\n    console.log(result.data);\n  } else {\n    // TypeScript knows result.error exists\n    console.error(result.error);\n  }\n}\n```\n\n**Use `unknown` over `any` for external data:**\n```typescript\nasync function fetchData(): Promise<unknown> {\n  const response = await fetch('/api/data');\n  return response.json();\n}\n\n// Then validate/parse\nconst data = await fetchData();\nif (isValidData(data)) {\n  // Now safely typed\n}\n```\n\n### Null Handling\n\n**Use optional chaining and nullish coalescing:**\n```typescript\n// Optional chaining\nconst userName = user?.profile?.name;\n\n// Nullish coalescing (only for null/undefined)\nconst displayName = userName ?? 'Anonymous';\n\n// Combine them\nconst city = user?.address?.city ?? 'Unknown';\n```\n\n**Use type guards:**\n```typescript\nfunction isUser(obj: unknown): obj is User {\n  return (\n    typeof obj === 'object' &&\n    obj !== null &&\n    'id' in obj &&\n    'email' in obj\n  );\n}\n```\n\n### Async Patterns\n\n**Prefer async/await over raw promises:**\n```typescript\n// Good\nasync function fetchUser(id: string): Promise<User> {\n  const response = await fetch(`/api/users/${id}`);\n  if (!response.ok) {\n    throw new Error(`Failed to fetch user: ${response.status}`);\n  }\n  return response.json();\n}\n```\n\n**Handle errors properly:**\n```typescript\nasync function safeOperation(): Promise<Result<Data>> {\n  try {\n    const data = await riskyOperation();\n    return { success: true, data };\n  } catch (error) {\n    return { success: false, error: error as Error };\n  }\n}\n```\n\n**Parallel operations:**\n```typescript\n// Run in parallel\nconst [users, posts] = await Promise.all([\n  fetchUsers(),\n  fetchPosts()\n]);\n\n// With error handling\nconst results = await Promise.allSettled([\n  fetchUsers(),\n  fetchPosts()\n]);\n```\n\n---\n\n## Python Patterns\n\n### Type Hints\n\n**Use type hints for clarity:**\n```python\nfrom typing import Optional, List, Dict\n\ndef process_users(\n    users: List[dict],\n    filter_active: bool = True\n) -> List[str]:\n    \"\"\"Process users and return their names.\"\"\"\n    result: List[str] = []\n    for user in users:\n        if filter_active and not user.get(\"active\"):\n            continue\n        result.append(user[\"name\"])\n    return result\n```\n\n**Use dataclasses for data containers:**\n```python\nfrom dataclasses import dataclass\nfrom typing import Optional\n\n@dataclass\nclass User:\n    id: int\n    email: str\n    name: str\n    active: bool = True\n    profile: Optional[dict] = None\n```\n\n**Use Pydantic for validation:**\n```python\nfrom pydantic import BaseModel, EmailStr\n\nclass UserCreate(BaseModel):\n    email: EmailStr\n    name: str\n    age: int\n\n    class Config:\n        extra = \"forbid\"  # Reject unknown fields\n```\n\n### Pythonic Patterns\n\n**Use comprehensions:**\n```python\n# List comprehension\nnames = [user.name for user in users if user.active]\n\n# Dict comprehension\nuser_map = {user.id: user for user in users}\n\n# Generator for large data\nactive_users = (user for user in users if user.active)\n```\n\n**Context managers for resources:**\n```python\n# File handling\nwith open(\"file.txt\", \"r\") as f:\n    content = f.read()\n\n# Database connections\nwith get_db_connection() as conn:\n    conn.execute(query)\n\n# Custom context manager\nfrom contextlib import contextmanager\n\n@contextmanager\ndef timer(name: str):\n    start = time.time()\n    yield\n    print(f\"{name}: {time.time() - start:.2f}s\")\n```\n\n**Use `pathlib` for paths:**\n```python\nfrom pathlib import Path\n\nconfig_path = Path(__file__).parent / \"config\" / \"settings.yaml\"\nif config_path.exists():\n    content = config_path.read_text()\n```\n\n### Error Handling\n\n```python\nclass ValidationError(Exception):\n    \"\"\"Raised when input validation fails.\"\"\"\n    pass\n\nclass NotFoundError(Exception):\n    \"\"\"Raised when a resource is not found.\"\"\"\n    pass\n\ndef get_user(user_id: int) -> User:\n    user = db.query(User).get(user_id)\n    if user is None:\n        raise NotFoundError(f\"User {user_id} not found\")\n    return user\n```\n\n---\n\n## React Patterns\n\n### Component Patterns\n\n**Functional components with hooks:**\n```tsx\ninterface UserCardProps {\n  user: User;\n  onEdit: (user: User) => void;\n}\n\nfunction UserCard({ user, onEdit }: UserCardProps) {\n  const handleClick = useCallback(() => {\n    onEdit(user);\n  }, [user, onEdit]);\n\n  return (\n    <div className=\"user-card\">\n      <h3>{user.name}</h3>\n      <button onClick={handleClick}>Edit</button>\n    </div>\n  );\n}\n```\n\n**Custom hooks for logic reuse:**\n```tsx\nfunction useUser(userId: string) {\n  const [user, setUser] = useState<User | null>(null);\n  const [loading, setLoading] = useState(true);\n  const [error, setError] = useState<Error | null>(null);\n\n  useEffect(() => {\n    setLoading(true);\n    fetchUser(userId)\n      .then(setUser)\n      .catch(setError)\n      .finally(() => setLoading(false));\n  }, [userId]);\n\n  return { user, loading, error };\n}\n```\n\n### State Management\n\n**Use appropriate state level:**\n```tsx\n// Local state - component only\nconst [isOpen, setIsOpen] = useState(false);\n\n// Lifted state - shared between siblings\n// Put in common parent\n\n// Context - deeply nested sharing\nconst ThemeContext = createContext<Theme>(\"light\");\n\n// External store - complex app state\n// Use Redux, Zustand, or similar\n```\n\n**Derive state when possible:**\n```tsx\n// Bad: redundant state\nconst [items, setItems] = useState<Item[]>([]);\nconst [totalCount, setTotalCount] = useState(0);\n\n// Good: derive from source of truth\nconst [items, setItems] = useState<Item[]>([]);\nconst totalCount = items.length;\n```\n\n### Performance\n\n**Memoization:**\n```tsx\n// Memoize expensive computations\nconst sortedItems = useMemo(\n  () => items.sort((a, b) => a.name.localeCompare(b.name)),\n  [items]\n);\n\n// Memoize callbacks passed to children\nconst handleClick = useCallback(() => {\n  doSomething(id);\n}, [id]);\n\n// Memoize components\nconst MemoizedChild = memo(ChildComponent);\n```\n\n**Lazy loading:**\n```tsx\nconst HeavyComponent = lazy(() => import('./HeavyComponent'));\n\nfunction App() {\n  return (\n    <Suspense fallback={<Loading />}>\n      <HeavyComponent />\n    </Suspense>\n  );\n}\n```\n\n### Error Boundaries\n\n```tsx\nclass ErrorBoundary extends Component<Props, State> {\n  state = { hasError: false, error: null };\n\n  static getDerivedStateFromError(error: Error) {\n    return { hasError: true, error };\n  }\n\n  componentDidCatch(error: Error, info: ErrorInfo) {\n    logError(error, info);\n  }\n\n  render() {\n    if (this.state.hasError) {\n      return <ErrorFallback error={this.state.error} />;\n    }\n    return this.props.children;\n  }\n}\n```\n\n---\n\n## General Best Practices\n\n### Naming Conventions\n\n| Language | Variables | Functions | Classes | Constants |\n|----------|-----------|-----------|---------|-----------|\n| TypeScript | camelCase | camelCase | PascalCase | UPPER_SNAKE |\n| Python | snake_case | snake_case | PascalCase | UPPER_SNAKE |\n| React | camelCase | camelCase/use* | PascalCase | UPPER_SNAKE |\n\n### File Organization\n\n**TypeScript/React:**\n```\nsrc/\n  components/\n    Button/\n      Button.tsx\n      Button.test.tsx\n      index.ts\n  hooks/\n  utils/\n  types/\n```\n\n**Python:**\n```\nsrc/\n  package/\n    __init__.py\n    models.py\n    services.py\n    utils.py\n  tests/\n    test_models.py\n    test_services.py\n```\n\n### Import Organization\n\n**TypeScript:**\n```typescript\n// 1. External packages\nimport React from 'react';\nimport { useState } from 'react';\n\n// 2. Internal modules (absolute)\nimport { Button } from '@/components';\nimport { useAuth } from '@/hooks';\n\n// 3. Relative imports\nimport { helper } from './utils';\nimport type { Props } from './types';\n```\n\n**Python:**\n```python\n# 1. Standard library\nimport os\nfrom pathlib import Path\n\n# 2. Third-party packages\nimport requests\nfrom pydantic import BaseModel\n\n# 3. Local imports\nfrom .models import User\nfrom .utils import helper\n```\n",
        "plugins/dev-tools/skills/project-conventions/SKILL.md": "---\ndescription: Guides discovery and application of project-specific conventions including code patterns, naming, structure, and team practices\n---\n\n# Project Conventions\n\nThis skill guides you in discovering and applying project-specific conventions. Every codebase has its own patterns and practices - your job is to find them and follow them.\n\n---\n\n## Convention Discovery Process\n\n### Step 1: Project Configuration\n\nCheck these files for explicit conventions:\n\n**Code Style:**\n- `.eslintrc*`, `eslint.config.*` - JavaScript/TypeScript linting rules\n- `.prettierrc*`, `prettier.config.*` - Formatting rules\n- `pyproject.toml`, `setup.cfg`, `.flake8` - Python config\n- `.editorconfig` - Editor settings\n- `ruff.toml`, `.ruff.toml` - Ruff linter config\n\n**Project Structure:**\n- `tsconfig.json` - TypeScript paths and settings\n- `package.json` - Scripts, dependencies\n- `pyproject.toml` - Python project config\n\n**Documentation:**\n- `CONTRIBUTING.md` - Contribution guidelines\n- `CLAUDE.md` - AI coding guidelines\n- `README.md` - Project overview\n- `docs/` - Extended documentation\n\n### Step 2: Existing Code Patterns\n\nStudy the codebase to find implicit conventions:\n\n**File Organization:**\n```bash\n# Find how components are organized\nls -la src/components/\n\n# Find test file patterns\nfind . -name \"*.test.*\" -o -name \"*_test.*\" -o -name \"test_*\"\n\n# Find how utilities are organized\nls -la src/utils/ src/lib/ src/helpers/\n```\n\n**Naming Patterns:**\n```bash\n# Find function naming patterns\ngrep -r \"^export function\" src/ | head -20\ngrep -r \"^def \" src/ | head -20\n\n# Find class naming patterns\ngrep -r \"^export class\" src/ | head -20\ngrep -r \"^class \" src/*.py | head -20\n```\n\n**Import Patterns:**\n```bash\n# Find import style (absolute vs relative)\ngrep -r \"^import\" src/ | head -30\ngrep -r \"^from \\.\" src/*.py | head -20\n```\n\n### Step 3: Similar Features\n\nFind features similar to what you're building:\n\n1. **Search for similar functionality:**\n   ```bash\n   # If building a \"user profile\" feature\n   grep -r \"profile\" src/\n   find . -name \"*profile*\"\n   ```\n\n2. **Study the implementation:**\n   - How is it structured?\n   - What patterns does it use?\n   - How does it handle errors?\n   - How is it tested?\n\n3. **Note the patterns:**\n   - Component structure\n   - State management approach\n   - API call patterns\n   - Validation approach\n\n---\n\n## Common Convention Areas\n\n### Naming Conventions\n\n**Discover by example:**\n```bash\n# Function names\ngrep -E \"^(export )?(async )?function \" src/**/*.ts\n\n# Variable names\ngrep -E \"^(const|let|var) \" src/**/*.ts\n\n# Component names\ngrep -E \"^(export )?function [A-Z]\" src/**/*.tsx\n```\n\n**Common patterns:**\n- `camelCase` for functions/variables\n- `PascalCase` for components/classes\n- `UPPER_SNAKE` for constants\n- `kebab-case` for file names (some projects)\n- `snake_case` for file names (Python)\n\n### File Structure\n\n**Discover the pattern:**\n```bash\n# Component structure\nls -la src/components/Button/\n\n# Module structure\nls -la src/features/auth/\n```\n\n**Common patterns:**\n\nFlat structure:\n```\ncomponents/\n  Button.tsx\n  Button.test.tsx\n  Button.styles.ts\n```\n\nFolder per component:\n```\ncomponents/\n  Button/\n    index.ts\n    Button.tsx\n    Button.test.tsx\n    Button.module.css\n```\n\nFeature-based:\n```\nfeatures/\n  auth/\n    components/\n    hooks/\n    api.ts\n    types.ts\n```\n\n### Error Handling\n\n**Discover the pattern:**\n```bash\n# Find try-catch patterns\ngrep -A5 \"try {\" src/**/*.ts\n\n# Find error types\ngrep -r \"extends Error\" src/\n\n# Find error handling in API\ngrep -r \"catch\" src/api/\n```\n\n**Apply what you find:**\n- Use the same error types\n- Follow the same handling pattern\n- Match logging approach\n\n### Testing Patterns\n\n**Discover the pattern:**\n```bash\n# Find test structure\nhead -50 src/**/*.test.ts\n\n# Find test utilities\ncat src/test/setup.ts\ncat src/test/utils.ts\n```\n\n**Match the patterns:**\n- Test file location (co-located vs separate)\n- Naming convention (`*.test.ts` vs `*.spec.ts`)\n- Setup and teardown approach\n- Mocking strategy\n- Assertion style\n\n### API Patterns\n\n**Discover the pattern:**\n```bash\n# Find API call patterns\ngrep -r \"fetch\\|axios\\|api\\.\" src/\n\n# Find API response handling\ngrep -A10 \"async function fetch\" src/api/\n```\n\n**Match the patterns:**\n- How are endpoints defined?\n- How is authentication handled?\n- What's the error format?\n- How are responses typed?\n\n---\n\n## Convention Application Checklist\n\nWhen implementing a feature, verify you're following conventions for:\n\n### Code Style\n- [ ] Variable naming matches existing code\n- [ ] Function naming matches existing code\n- [ ] File naming follows project pattern\n- [ ] Import style matches (absolute vs relative)\n\n### Structure\n- [ ] File location follows project structure\n- [ ] Component organization matches\n- [ ] Export style matches (default vs named)\n\n### Patterns\n- [ ] Error handling follows project patterns\n- [ ] Async patterns match existing code\n- [ ] State management follows project approach\n- [ ] API calls follow established patterns\n\n### Testing\n- [ ] Test file location is correct\n- [ ] Test naming follows convention\n- [ ] Test structure matches existing tests\n- [ ] Mocking approach is consistent\n\n### Documentation\n- [ ] Comments follow existing style\n- [ ] JSDoc/docstrings match project\n- [ ] README updates if needed\n\n---\n\n## When Conventions Conflict\n\nSometimes you'll find inconsistent patterns:\n\n1. **Prefer newer code** - Recent files often reflect current team preferences\n2. **Prefer maintained code** - Active parts of the codebase reflect current practices\n3. **Prefer documented conventions** - Explicit rules in configs override implicit patterns\n4. **Ask if unclear** - When in doubt, ask the user which pattern to follow\n\n---\n\n## Red Flags\n\nWatch for these signs that you might be breaking conventions:\n\n- Your code looks very different from surrounding code\n- You're using a library/pattern not used elsewhere\n- Your file structure doesn't match siblings\n- Your naming feels inconsistent with the codebase\n- Linting errors (the project has explicit rules you're breaking)\n\nWhen you notice these, stop and investigate the existing conventions more carefully.\n",
        "plugins/mission-control/.claude-plugin/plugin.json": "{\n  \"name\": \"mission-control\",\n  \"version\": \"0.1.2\",\n  \"description\": \"Simplified task management for coding agents - generate task lists from specs, track tasks, manage dependencies\",\n  \"author\": {\n    \"name\": \"Stephen Sequenzia\",\n    \"email\": \"sequenzia@gmail.com\"\n  }\n}\n",
        "plugins/mission-control/README.md": "# Mission Control\n\nA simplified task management plugin for Claude Code that enables coding agents to generate task lists from specifications, track tasks, and manage dependencies.\n\n## Features\n\n- **Task Generation**: Parse PRDs, technical specs, and design documents into structured task lists\n- **Mission-Based Organization**: Group tasks under named missions for better organization\n- **Dependency Tracking**: Map blocking dependencies between tasks\n- **Progress Monitoring**: Track completion status and identify blocked tasks\n- **Smart Recommendations**: Get prioritized task suggestions based on dependencies and complexity\n- **PRD Integration**: Seamless integration with prd-tools PRD format\n\n## Quick Start\n\n### 1. Generate Tasks from a Specification\n\n```\n/mission-control:generate \"Build Auth System\" path/to/spec.md\n```\n\nThis creates:\n- `missions/build-auth-system/<project>.tasks.json` - Structured task data\n- `missions/build-auth-system/<project>.tasks.md` - Human-readable summary\n\n### 2. Check Status\n\n```\n/mission-control:status\n```\n\nView completion progress, blocked tasks, and what's ready to start.\n\n### 3. Get Next Tasks\n\n```\n/mission-control:next\n```\n\nGet prioritized recommendations for what to work on next.\n\n### 4. View Task Details\n\n```\n/mission-control:show TASK-001\n```\n\nSee full task information including dependencies and acceptance criteria.\n\n### 5. Mark Complete\n\n```\n/mission-control:complete TASK-001\n```\n\nMark a task done and see what new tasks become unblocked.\n\n## Commands\n\n| Command | Description | Arguments |\n|---------|-------------|-----------|\n| `generate` | Parse spec and generate task list | `<mission-name> <spec-document>` |\n| `show` | Display task details | `<task-id> [project-name]` |\n| `status` | Show progress summary | `[project-name]` |\n| `complete` | Mark task complete | `<task-id> [project-name]` |\n| `next` | Recommend next tasks | `[count] [project-name]` |\n\n## Task Schema\n\nTasks are stored in JSON format with the following structure:\n\n```json\n{\n  \"mission\": {\n    \"name\": \"Build User Authentication System\",\n    \"metadata\": {\n      \"source_document\": \"spec.md\",\n      \"generated_at\": \"2024-01-15T10:30:00Z\",\n      \"last_updated\": \"2024-01-15T10:30:00Z\",\n      \"version\": \"1.0.0\",\n      \"total_tasks\": 12,\n      \"completion_percentage\": 0\n    },\n    \"tasks\": [\n      {\n        \"id\": \"TASK-001\",\n        \"title\": \"Task title\",\n        \"description\": \"What needs to be done\",\n        \"status\": \"not_started\",\n        \"priority\": \"high\",\n        \"complexity\": \"M\",\n        \"dependencies\": [\"TASK-002\"],\n        \"blocked_by\": [],\n        \"blocks\": [\"TASK-003\"],\n        \"acceptance_criteria\": [\"Criterion 1\"],\n        \"source_requirements\": [\"Section 5.1\"],\n        \"notes\": \"Optional notes\"\n      }\n    ],\n    \"execution_phases\": [\n      {\n        \"phase\": 1,\n        \"name\": \"Foundation\",\n        \"tasks\": [\"TASK-001\", \"TASK-002\"]\n      }\n    ]\n  }\n}\n```\n\n## PRD Integration\n\nWhen analyzing PRDs created with prd-tools:\n\n- **Section 5** (Functional Requirements) → Features and tasks\n- **User Stories** (US-XXX) → `source_requirements`\n- **Acceptance Criteria** → Task `acceptance_criteria`\n- **Priority** (P0-P3) → critical/high/medium/low\n- **Section 9** (Implementation Plan) → `execution_phases`\n- **Section 10** (Dependencies) → Task dependencies\n\n## Task Status\n\n| Status | Description |\n|--------|-------------|\n| `not_started` | Task not yet begun |\n| `in_progress` | Currently being worked on |\n| `blocked` | Waiting on incomplete dependencies |\n| `complete` | Task finished |\n\n## Priority Levels\n\n| Priority | Description |\n|----------|-------------|\n| `critical` | Must be done first, blocks everything |\n| `high` | Important, should be prioritized |\n| `medium` | Standard priority |\n| `low` | Can be deferred |\n\n## Complexity Sizing\n\n| Size | Scope |\n|------|-------|\n| XS | Single function, < 20 lines |\n| S | Single file, 20-100 lines |\n| M | Multiple files, 100-300 lines |\n| L | Multiple components, 300-800 lines |\n| XL | System-wide, > 800 lines |\n\n## Agent\n\nThe **spec-analyzer** agent proactively triggers when specification documents are detected in your project. It looks for files matching:\n\n- `*spec*`, `*prd*`, `*requirements*`, `*design-doc*`\n- Files in `specs/`, `docs/`, `requirements/` directories\n\n## Differences from task-manager\n\nThis is a simplified version of the full task-manager plugin:\n\n| Feature | task-manager | mission-control |\n|---------|--------------|-----------------|\n| Context window grouping | Yes | No |\n| Soft/resource dependencies | Yes | No |\n| Test scenarios & edge cases | Yes | No |\n| Token estimation | Yes | No |\n| Dependency graph | Yes | No |\n| Basic task management | Yes | Yes |\n| Blocking dependencies | Yes | Yes |\n| Acceptance criteria | Yes | Yes |\n| Execution phases | Yes | Yes |\n\nUse **mission-control** for simpler projects or when you don't need context window optimization.\n\n## File Structure\n\n```\nmission-control/\n├── .claude-plugin/\n│   └── plugin.json\n├── commands/\n│   ├── generate.md\n│   ├── show.md\n│   ├── status.md\n│   ├── complete.md\n│   └── next.md\n├── agents/\n│   └── spec-analyzer.md\n├── skills/\n│   └── simple-task-management/\n│       ├── SKILL.md\n│       └── references/\n│           └── task-schema.json\n├── missions/\n│   └── <mission-slug>/\n│       ├── <project>.tasks.json\n│       └── <project>.tasks.md\n└── README.md\n```\n",
        "plugins/mission-control/agents/spec-analyzer.md": "---\ndescription: Analyzes specification documents and generates structured task lists organized under missions\nwhen_to_use: Use proactively when spec documents (*spec*, *prd*, *requirements*, *design-doc*) are detected in the project, or when users need help analyzing specs for implementation planning.\nmodel: inherit\ncolor: cyan\ntools:\n  - Read\n  - Write\n  - Glob\n  - Grep\n---\n\n# Specification Analyzer Agent\n\nYou are a specification analysis agent that transforms requirement documents into structured, actionable task lists organized under missions.\n\n## When to Use This Agent\n\n<example>\nContext: User opens a project and you notice a file named \"feature-spec.md\" or \"prd-authentication.md\" in the root or docs/ directory\nuser: \"Help me implement this feature\"\nassistant: \"I notice there's a specification document in your project. Let me use the spec-analyzer agent to analyze it and generate a structured task list that will help guide the implementation.\"\n<commentary>\nThe agent should trigger proactively when spec documents are detected and the user is starting implementation work. This helps ensure work is properly planned before coding begins.\n</commentary>\n</example>\n\n<example>\nContext: User is exploring a codebase and you find files matching spec patterns\nuser: \"What should I work on first?\"\nassistant: \"I found specification documents in your project. Let me analyze them with the spec-analyzer agent to generate prioritized task lists and recommend what to work on first.\"\n<commentary>\nWhen users ask about what to work on, and spec documents exist, the agent should analyze them to provide informed recommendations.\n</commentary>\n</example>\n\n<example>\nContext: User explicitly mentions they have requirements or a PRD to implement\nuser: \"I need to implement the features described in requirements.md\"\nassistant: \"I'll use the spec-analyzer agent to parse your requirements document and create a structured task list with dependencies and priorities.\"\n<commentary>\nDirect requests to work from specification documents should trigger this agent to ensure proper task decomposition.\n</commentary>\n</example>\n\n**Your Core Responsibilities:**\n\n1. Detect and analyze specification documents in the project\n2. Extract explicit and implicit requirements from specifications\n3. Decompose requirements into atomic, independent tasks\n4. Map blocking dependencies between tasks\n5. Prioritize tasks and organize into execution phases\n6. Generate acceptance criteria for each task\n\n**Detection Process:**\n\nWhen activated, search for specification documents using these patterns:\n\n1. **Filename patterns:**\n   - `*spec*` (feature-spec.md, api-spec.md, etc.)\n   - `*prd*` (prd-auth.md, product-prd.md, etc.)\n   - `*requirements*` (requirements.md, functional-requirements.md)\n   - `*design-doc*` (design-doc-api.md, etc.)\n\n2. **Directory locations:**\n   - `specs/`\n   - `docs/`\n   - `requirements/`\n   - Root directory\n\n3. **File extensions:**\n   - `.md` (primary focus)\n   - `.txt`\n\n**Analysis Process:**\n\n1. **Read the specification thoroughly**\n   - Parse document structure (headings, lists, sections)\n   - Identify explicit requirements and acceptance criteria\n   - Extract implicit requirements (error handling, edge cases)\n   - Note constraints and scope boundaries\n\n2. **Decompose into atomic tasks**\n   - Each task has single responsibility\n   - Tasks are independent where possible\n   - Tasks have clear start/end conditions\n   - Tasks have verifiable completion criteria\n\n3. **Map dependencies**\n   - Identify blocking dependencies (Task B cannot start until Task A completes)\n   - Calculate `blocked_by` and `blocks` relationships\n\n4. **Prioritize and organize**\n   - Assign priority (critical, high, medium, low)\n   - Estimate complexity (XS, S, M, L, XL)\n   - Group into execution phases\n\n5. **Generate acceptance criteria**\n   - Derive from specification's acceptance criteria\n   - Ensure each criterion is testable\n\n**PRD Integration:**\n\nWhen analyzing PRDs from prd-tools:\n- Extract features from Section 5 (Functional Requirements)\n- Map user stories (US-XXX) to source_requirements\n- Convert acceptance criteria to task acceptance_criteria\n- Map P0-P3 priorities to critical/high/medium/low\n- Use Section 9 (Implementation Plan) for execution_phases\n- Use Section 10 (Dependencies) for task dependencies\n\n**Output:**\n\nGenerate a task list file at `missions/<mission-slug>/<project-name>.tasks.json` following this structure:\n\n```json\n{\n  \"mission\": {\n    \"name\": \"Mission Name\",\n    \"metadata\": {\n      \"source_document\": \"<spec path>\",\n      \"generated_at\": \"<ISO-8601>\",\n      \"version\": \"1.0.0\",\n      \"total_tasks\": <count>,\n      \"completion_percentage\": 0\n    },\n    \"tasks\": [...],\n    \"execution_phases\": [...]\n  }\n}\n```\n\nAlso generate a markdown summary at `missions/<mission-slug>/<project-name>.tasks.md`.\n\n**Mission Naming:**\n\nDerive the mission name from:\n1. The specification document's title or main heading\n2. The project context\n3. If unclear, ask the user for a mission name\n\nThe mission slug is created by:\n- Converting the mission name to lowercase\n- Replacing spaces with hyphens\n- Removing special characters\n\nExample: \"Build User Authentication\" → `missions/build-user-authentication/`\n\n**Reporting:**\n\nAfter analysis, provide:\n1. Mission name and summary\n2. Total tasks generated\n3. Priority breakdown\n4. Execution phases overview\n5. Recommended first tasks to tackle\n\n**Edge Cases:**\n\n- If no spec documents found: Explain how to create one or use `/mission-control:generate \"Mission Name\" path/to/spec.md` manually\n- If spec is ambiguous: Note assumptions in task notes, flag for human review\n- If spec is very large: Process sections incrementally, report progress\n- If existing task list found: Offer to update rather than regenerate\n\n**Quality Standards:**\n\n- Tasks must trace back to specific spec sections\n- Dependencies must be justified\n- Priorities must consider blocking relationships\n- Acceptance criteria must be verifiable\n- Output must be valid JSON\n",
        "plugins/mission-control/commands/complete.md": "---\ndescription: Mark a task as complete and show newly unblocked tasks\nargument-hint: <task-id> [project-name]\nallowed-tools: Read, Write, Glob\n---\n\nMark a task as complete and update all dependent task relationships.\n\n**Arguments:**\n- `task-id` (required): The task ID to mark complete (e.g., TASK-001)\n- `project-name` (optional): Project name if multiple task files exist\n\n## Process\n\n1. **Locate and validate**\n   - Find the task file (`tasks/*.tasks.json` or `tasks/<project-name>.tasks.json`)\n   - Verify the task exists\n   - Check current status (warn if already complete)\n\n2. **Update task status**\n   - Set `status` to \"complete\"\n   - Update `metadata.last_updated` timestamp\n   - Recalculate `metadata.completion_percentage`\n\n3. **Update dependent tasks**\n   - For each task that has this task in `blocked_by`:\n     - Remove this task from their `blocked_by` array\n     - If `blocked_by` becomes empty and status was \"blocked\", change to \"not_started\"\n   - Track which tasks became unblocked\n\n4. **Write updated file**\n   - Save the modified JSON to the task file\n   - Preserve formatting\n\n5. **Display results**\n\n## Output Format\n\n```\n## Task Completed\n\n**TASK-XXX:** <title>\n\nStatus: not_started -> complete\n\n### Progress Update\n\n- Completion: 45% -> 50% (10/20 tasks)\n- Tasks unblocked: 2\n\n### Newly Unblocked Tasks\n\nThe following tasks can now be started:\n\n1. **TASK-AAA:** <title>\n   - Priority: high\n   - Complexity: M\n   - Was waiting on: TASK-XXX\n\n2. **TASK-BBB:** <title>\n   - Priority: medium\n   - Complexity: S\n   - Was waiting on: TASK-XXX, TASK-YYY (TASK-YYY already complete)\n\n### Recommended Next\n\nBased on priority and dependencies:\n\n1. **TASK-AAA** - High priority, medium complexity\n2. **TASK-CCC** - High priority, small complexity\n\nRun `/mission-control:next` for full recommendations.\n```\n\n## Edge Cases\n\n- **Task already complete:** Warn but don't error\n- **Task is blocked:** Error - cannot complete a blocked task without completing blockers first\n- **Task in progress:** Allow completion (normal flow)\n- **No tasks unblocked:** Note that no new tasks were unblocked\n- **All tasks complete:** Congratulate user on completing the project!\n\n## Validation\n\nBefore marking complete, consider asking:\n- If task has acceptance criteria, remind user to verify them\n- If task blocks critical path tasks, highlight the impact\n",
        "plugins/mission-control/commands/generate.md": "---\ndescription: Generate a structured task list from a specification document\nargument-hint: <mission-name> <spec-document>\nallowed-tools: Read, Write, Glob\n---\n\nGenerate a comprehensive task list from a specification document, organized under a named mission.\n\n**Arguments:** $ARGUMENTS\n\nParse the arguments to extract:\n- **Mission name**: First argument (required) - The name for this mission (e.g., \"Build User Authentication System\")\n- **Spec document**: Second argument (required) - Path to the specification document\n\nIf mission name contains spaces, it should be quoted. Example: `/mission-control:generate \"Build Auth System\" specs/auth-spec.md`\n\n## Analysis Process\n\n1. **Read and parse the specification document thoroughly**\n   - Identify all explicit requirements, features, and acceptance criteria\n   - Extract implicit requirements (error handling, infrastructure, etc.)\n   - Note constraints and scope boundaries\n\n2. **Decompose into atomic tasks**\n   - Each task should have single responsibility\n   - Tasks should be independent where possible\n   - Tasks must have clear start/end conditions\n   - Tasks must be testable with verifiable criteria\n\n3. **Map dependencies between tasks**\n   - Identify blocking dependencies: Task B cannot start until Task A completes\n   - Calculate `blocked_by` and `blocks` relationships\n   - Flag tasks that are ready to start (no blockers)\n\n4. **Assign priorities and complexity**\n   - Priority: critical, high, medium, low (based on dependency depth and risk)\n   - Complexity: XS, S, M, L, XL (T-shirt sizing)\n   - When parsing PRDs, map P0=critical, P1=high, P2=medium, P3=low\n\n5. **Generate acceptance criteria for each task**\n   - Derive from the specification's acceptance criteria and user stories\n   - Ensure each criterion is specific and testable\n\n6. **Organize into execution phases**\n   - Phase 1: Tasks with no blocking dependencies\n   - Phase 2+: Tasks whose dependencies are satisfied by previous phases\n\n## PRD Integration\n\nWhen analyzing PRDs from prd-tools:\n- Extract features from Section 5 (Functional Requirements)\n- Map user stories (US-XXX) to `source_requirements`\n- Convert acceptance criteria items to task `acceptance_criteria`\n- Map P0-P3 priorities to critical/high/medium/low\n- Use Section 9 (Implementation Plan) for `execution_phases`\n- Use Section 10 (Dependencies) for task dependencies\n\n## Output\n\n### Directory Structure\n\nCreate the mission directory: `missions/<mission-slug>/`\n\nThe mission slug is derived from the mission name:\n- Convert to lowercase\n- Replace spaces with hyphens\n- Remove special characters\n\nExample: \"Build User Authentication System\" → `missions/build-user-authentication-system/`\n\n### 1. JSON Task File\n\nWrite the task list to `missions/<mission-slug>/<project-name>.tasks.json` where `<project-name>` is derived from the specification filename.\n\n**Required structure:**\n```json\n{\n  \"mission\": {\n    \"name\": \"Build User Authentication System\",\n    \"metadata\": {\n      \"source_document\": \"<spec path>\",\n      \"generated_at\": \"<ISO-8601>\",\n      \"last_updated\": \"<ISO-8601>\",\n      \"version\": \"1.0.0\",\n      \"total_tasks\": <count>,\n      \"completion_percentage\": 0\n    },\n    \"tasks\": [\n      {\n        \"id\": \"TASK-001\",\n        \"title\": \"Brief descriptive title\",\n        \"description\": \"What needs to be done\",\n        \"status\": \"not_started\",\n        \"priority\": \"high\",\n        \"complexity\": \"M\",\n        \"dependencies\": [\"TASK-002\"],\n        \"blocked_by\": [],\n        \"blocks\": [\"TASK-003\"],\n        \"acceptance_criteria\": [\"Criterion 1\", \"Criterion 2\"],\n        \"source_requirements\": [\"Section 5.1\", \"US-001\"],\n        \"notes\": \"Optional implementation notes\"\n      }\n    ],\n    \"execution_phases\": [\n      {\n        \"phase\": 1,\n        \"name\": \"Foundation\",\n        \"tasks\": [\"TASK-001\", \"TASK-002\"]\n      }\n    ]\n  }\n}\n```\n\n### 2. Markdown Summary File\n\nWrite a markdown summary to `missions/<mission-slug>/<project-name>.tasks.md`:\n\n```markdown\n# Mission: <mission-name>\n\n**Source:** <spec-path>\n**Generated:** <timestamp>\n\n## Summary\n\n- **Total tasks:** X\n- **Execution phases:** Y\n- **Ready to start:** Z\n\n## By Priority\n\n| Priority | Count |\n|----------|-------|\n| Critical | X |\n| High | Y |\n| Medium | Z |\n| Low | W |\n\n## By Complexity\n\n| Size | Count |\n|------|-------|\n| XS | X |\n| S | Y |\n| M | Z |\n| L | W |\n| XL | V |\n\n## Execution Phases\n\n### Phase 1: <phase-name>\n\n| Task | Title | Priority | Complexity |\n|------|-------|----------|------------|\n| TASK-001 | <title> | high | M |\n\n### Phase 2: <phase-name>\n\n| Task | Title | Priority | Complexity |\n|------|-------|----------|------------|\n| TASK-003 | <title> | high | L |\n\n(continue for all phases)\n\n## Ready to Start\n\nTasks with no blocking dependencies:\n\n- **TASK-001:** <title>\n- **TASK-002:** <title>\n\n## Next Steps\n\n1. View task details: `/mission-control:show TASK-XXX`\n2. Start recommended tasks: `/mission-control:next`\n3. Mark tasks complete: `/mission-control:complete TASK-XXX`\n```\n\n### 3. Display Summary\n\nAfter writing both files, display a brief summary to the console:\n- Mission name\n- Total tasks generated\n- Breakdown by priority and complexity\n- Number of execution phases\n- Tasks ready to start (Phase 1)\n- Paths to both output files\n",
        "plugins/mission-control/commands/next.md": "---\ndescription: Recommend next tasks to work on based on priority and dependencies\nargument-hint: [count] [project-name]\nallowed-tools: Read, Glob\n---\n\nSuggest the best tasks to work on next based on priority, complexity, and dependency analysis.\n\n**Arguments:**\n- `count` (optional): Number of recommendations (default: 5)\n- `project-name` (optional): Project name if multiple task files exist\n\n## Process\n\n1. **Locate task file**\n   - Search for `tasks/*.tasks.json` files\n   - Use specified project or prompt if multiple exist\n\n2. **Filter eligible tasks**\n   - Status is \"not_started\" or \"in_progress\"\n   - `blocked_by` array is empty (no incomplete dependencies)\n\n3. **Score and rank tasks**\n\n   **Scoring algorithm:**\n   ```\n   score = (priority_weight * 100) + (blocking_weight * 50) + complexity_bonus\n\n   Priority weights:\n   - critical: 4\n   - high: 3\n   - medium: 2\n   - low: 1\n\n   Blocking weight:\n   - Number of tasks this task blocks (unblocks others faster)\n\n   Complexity bonus (quick wins):\n   - XS: +15\n   - S: +10\n   - M: +5\n   - L: +0\n   - XL: -5\n   ```\n\n4. **Generate recommendations**\n\n## Output Format\n\n```\n# Next Task Recommendations\n\n**Project:** <project-name>\n**Available tasks:** X (of Y total)\n\n## Top Recommendations\n\n### 1. TASK-XXX: <title>\n**Score:** 450 | **Priority:** critical | **Complexity:** S\n\n<brief description>\n\n**Why recommended:**\n- Critical priority (highest urgency)\n- Blocks 3 other tasks\n- Small complexity (quick win)\n\n**Acceptance criteria:**\n- [ ] Criterion 1\n- [ ] Criterion 2\n\n---\n\n### 2. TASK-YYY: <title>\n**Score:** 380 | **Priority:** high | **Complexity:** M\n\n<brief description>\n\n**Why recommended:**\n- High priority\n- Blocks 2 other tasks\n- Unlocks Phase 2 work\n\n---\n\n### 3. TASK-ZZZ: <title>\n**Score:** 320 | **Priority:** high | **Complexity:** XS\n\n<brief description>\n\n**Why recommended:**\n- High priority\n- Extra small complexity (very quick win)\n\n---\n\n(continue for requested count)\n\n## Summary\n\n| Rank | Task | Priority | Complexity | Blocks | Score |\n|------|------|----------|------------|--------|-------|\n| 1 | TASK-XXX | critical | S | 3 | 450 |\n| 2 | TASK-YYY | high | M | 2 | 380 |\n| 3 | TASK-ZZZ | high | XS | 0 | 320 |\n\n## Quick Actions\n\n- View task details: `/mission-control:show TASK-XXX`\n- Mark complete when done: `/mission-control:complete TASK-XXX`\n```\n\n## Edge Cases\n\n- **No available tasks:** All tasks are either blocked or complete\n- **All tasks complete:** Project finished! Congratulate user\n- **All remaining blocked:** Show what's blocking progress and recommend completing blockers\n- **Only low priority left:** Note that remaining work is lower priority\n",
        "plugins/mission-control/commands/show.md": "---\ndescription: Display detailed information for a specific task\nargument-hint: <task-id> [project-name]\nallowed-tools: Read, Glob\n---\n\nDisplay comprehensive details for a specific task.\n\n**Arguments:**\n- `task-id` (required): The task ID to display (e.g., TASK-001)\n- `project-name` (optional): Project name to narrow search if multiple task files exist\n\n## Process\n\n1. **Locate the task file**\n   - Search for `tasks/*.tasks.json` files\n   - If `project-name` provided, look for `tasks/<project-name>.tasks.json`\n   - If multiple task files exist and no project specified, list them and ask user to specify\n\n2. **Find the task**\n   - Parse the JSON task file\n   - Search for the task by ID\n   - If not found, report error and suggest similar task IDs\n\n3. **Display task details**\n\n## Output Format\n\n```\n## TASK-XXX: <title>\n\n**Status:** <status>\n**Priority:** <priority>\n**Complexity:** <complexity>\n\n### Description\n<full description>\n\n### Dependencies\n\n**Depends on:**\n- TASK-YYY: <title> [<status>]\n- TASK-ZZZ: <title> [<status>]\n\n**Blocked by (incomplete):**\n- TASK-YYY: <title>\n\n**Blocks:**\n- TASK-AAA: <title>\n- TASK-BBB: <title>\n\n### Acceptance Criteria\n- [ ] Criterion 1\n- [ ] Criterion 2\n- [ ] Criterion 3\n\n### Source Requirements\n- Section 5.1: Feature Name\n- US-001: User story reference\n\n### Notes\n<any additional notes>\n\n---\n\n**Ready to start:** Yes/No\n**Execution phase:** <phase number>\n```\n\n## Edge Cases\n\n- If task is blocked, highlight the blocking tasks prominently\n- If task is complete, show checkmarks on acceptance criteria\n- If task has no dependencies, note \"No dependencies\"\n- If task blocks nothing, note \"Does not block other tasks\"\n",
        "plugins/mission-control/commands/status.md": "---\ndescription: Show task list summary and completion metrics\nargument-hint: [project-name]\nallowed-tools: Read, Glob\n---\n\nDisplay a summary of task progress and completion status.\n\n**Arguments:**\n- `project-name` (optional): Project name to show status for specific task file\n\n## Process\n\n1. **Locate task files**\n   - Search for `tasks/*.tasks.json` files\n   - If `project-name` provided, use `tasks/<project-name>.tasks.json`\n   - If multiple files and no project specified, show status for all or ask user\n\n2. **Calculate metrics**\n   - Count tasks by status (not_started, in_progress, blocked, complete)\n   - Calculate completion percentage\n   - Identify ready tasks (not_started with empty blocked_by)\n   - Count tasks per execution phase\n\n3. **Display summary**\n\n## Output Format\n\n```\n# Task Status: <project-name>\n\n**Source:** <spec-document>\n**Last Updated:** <timestamp>\n\n## Progress\n\n| Metric | Value |\n|--------|-------|\n| Total Tasks | XX |\n| Completed | XX (XX%) |\n| In Progress | XX |\n| Blocked | XX |\n| Not Started | XX |\n\n## Completion Bar\n\n[████████░░░░░░░░░░░░] 40% Complete\n\n## By Priority\n\n| Priority | Total | Done | Remaining |\n|----------|-------|------|-----------|\n| Critical | X | Y | Z |\n| High | X | Y | Z |\n| Medium | X | Y | Z |\n| Low | X | Y | Z |\n\n## By Complexity\n\n| Size | Total | Done | Remaining |\n|------|-------|------|-----------|\n| XS | X | Y | Z |\n| S | X | Y | Z |\n| M | X | Y | Z |\n| L | X | Y | Z |\n| XL | X | Y | Z |\n\n## Execution Phases\n\n| Phase | Name | Tasks | Done |\n|-------|------|-------|------|\n| 1 | Foundation | 5 | 3/5 |\n| 2 | Core Features | 8 | 0/8 |\n| 3 | Polish | 4 | 0/4 |\n\n## Ready to Start\n\nTasks with no blockers (can begin now):\n\n1. **TASK-XXX:** <title> (priority: high, complexity: M)\n2. **TASK-YYY:** <title> (priority: medium, complexity: S)\n\n## Currently Blocked\n\nTasks waiting on dependencies:\n\n1. **TASK-AAA:** Blocked by TASK-XXX, TASK-YYY\n2. **TASK-BBB:** Blocked by TASK-ZZZ\n\n## Quick Actions\n\n- View task: `/mission-control:show TASK-XXX`\n- Complete task: `/mission-control:complete TASK-XXX`\n- Next recommendations: `/mission-control:next`\n```\n\n## Multiple Projects\n\nIf multiple task files exist, show a summary table first:\n\n```\n# Task Status Overview\n\n| Project | Total | Done | Progress |\n|---------|-------|------|----------|\n| project-a | 15 | 8 | 53% |\n| project-b | 22 | 5 | 23% |\n\nRun `/mission-control:status <project-name>` for details.\n```\n",
        "plugins/mission-control/skills/simple-task-management/SKILL.md": "---\nname: simple-task-management\ndescription: This skill should be used when the user asks to \"generate tasks from a spec\", \"break down a spec\", \"create tasks from a PRD\", \"decompose requirements\", \"generate a task list from a design document\", or mentions working from specification documents. Provides guidance for transforming specifications into structured, actionable task lists organized under missions.\nversion: 0.2.0\n---\n\n# Simple Task Management\n\nTransform specification documents (PRDs, Technical Specifications, Design Documents) into structured task lists organized under named missions that can be executed systematically.\n\n## Core Workflow\n\n### 1. Document Analysis\n\nParse the specification document to extract:\n\n- **Explicit requirements**: Stated features, functionality, acceptance criteria\n- **Implicit requirements**: Technical considerations, infrastructure needs, error handling\n- **Constraints**: Technology choices, performance requirements, compatibility needs\n- **Scope boundaries**: What is and isn't included in the specification\n\nRead the source document thoroughly. Identify section headings, numbered requirements, user stories, acceptance criteria, and technical specifications. Note any cross-references between sections.\n\n### 2. Task Decomposition\n\nBreak requirements into atomic tasks with these characteristics:\n\n| Characteristic | Description |\n|----------------|-------------|\n| Single responsibility | Each task addresses one specific piece of functionality |\n| Independence | Tasks can be worked on without coordination where possible |\n| Clear boundaries | Well-defined start and end conditions |\n| Testable | Verifiable completion criteria exist |\n\n**Decomposition process:**\n1. Identify each distinct requirement in the specification\n2. Determine if the requirement is atomic or needs splitting\n3. Create task entries with unique IDs (TASK-001, TASK-002, etc.)\n4. Ensure each task maps to specific specification sections\n\n### 3. Dependency Mapping\n\nIdentify blocking dependencies between tasks:\n\n- **Blocking dependencies**: Task B cannot start until Task A completes\n\nPopulate the `dependencies` array with task IDs this task depends on. Calculate `blocked_by` (incomplete dependencies) and `blocks` (tasks depending on this one).\n\n### 4. Priority Calculation\n\nScore and prioritize tasks based on:\n\n1. **Dependency depth**: Tasks unblocking many others rank higher\n2. **Complexity**: Use T-shirt sizing (XS, S, M, L, XL)\n3. **Risk level**: Higher uncertainty = higher priority (do risky things early)\n4. **Business value**: When indicated in specification\n\nMap to priority levels: critical, high, medium, low.\n\n**PRD Priority Mapping:**\n- P0 -> critical\n- P1 -> high\n- P2 -> medium\n- P3 -> low\n\n### 5. Acceptance Criteria\n\nFor each task, generate acceptance criteria:\n\n- Specific conditions that must be true when complete\n- Derived from the specification's acceptance criteria and user stories\n- Each criterion should be independently verifiable\n\n### 6. Execution Phases\n\nGroup tasks into phases based on dependency analysis:\n\n- **Phase 1**: No blocking dependencies (can start immediately)\n- **Phase 2**: Dependencies only on Phase 1 tasks\n- **Phase N**: Dependencies satisfied by previous phases\n\n## Output Format\n\nGenerate task lists as JSON following the schema in `references/task-schema.json`.\n\n**Key structure:**\n```json\n{\n  \"mission\": {\n    \"name\": \"Build User Authentication System\",\n    \"metadata\": {\n      \"source_document\": \"path/to/spec.md\",\n      \"generated_at\": \"2024-01-15T10:30:00Z\",\n      \"last_updated\": \"2024-01-15T10:30:00Z\",\n      \"version\": \"1.0.0\",\n      \"total_tasks\": 12,\n      \"completion_percentage\": 0\n    },\n    \"tasks\": [...],\n    \"execution_phases\": [...]\n  }\n}\n```\n\n## Storage Convention\n\nStore task files at: `missions/<mission-slug>/<project-name>.tasks.json`\n\nThe mission slug is derived from the mission name:\n- Convert to lowercase\n- Replace spaces with hyphens\n- Remove special characters\n\nExample: \"Build User Authentication\" → `missions/build-user-authentication/`\n\nCreate the `missions/<mission-slug>/` directory if it doesn't exist. Use the specification filename (without extension) as the project name, or derive from specification title.\n\nMaintain version history by incrementing `mission.metadata.version` on updates.\n\n## Task Status Management\n\nTrack task lifecycle:\n\n| Status | Description |\n|--------|-------------|\n| not_started | Task not yet begun |\n| in_progress | Currently being worked on |\n| blocked | Cannot proceed due to incomplete dependencies |\n| complete | Task finished and verified |\n\nWhen marking a task complete:\n1. Update status to \"complete\"\n2. Recalculate `blocked_by` for all dependent tasks\n3. Update `completion_percentage` in metadata\n4. Suggest next best tasks based on updated state\n\n## Complexity Estimation\n\nUse T-shirt sizing with these guidelines:\n\n| Size | Typical Scope |\n|------|---------------|\n| XS | Single function, simple change, < 20 lines |\n| S | Single file, straightforward logic, 20-100 lines |\n| M | Multiple files, moderate complexity, 100-300 lines |\n| L | Multiple components, significant logic, 300-800 lines |\n| XL | System-wide, complex integration, > 800 lines |\n\n## Handling Ambiguity\n\nWhen specifications are unclear:\n\n1. Note assumptions in the task's `notes` field\n2. Flag ambiguous requirements for human review\n3. Create tasks for clarification if significant\n4. Document which specification sections need clarification\n\n## Quick Reference\n\n**Generate command flow:**\n1. Accept mission name and specification document path\n2. Read specification document\n3. Extract requirements and structure\n4. Decompose into atomic tasks\n5. Map blocking dependencies\n6. Calculate priorities and phases\n7. Generate acceptance criteria\n8. Write to `missions/<mission-slug>/<project-name>.tasks.json`\n\n**Next task selection criteria:**\n1. Status is \"not_started\"\n2. No incomplete dependencies (blocked_by is empty)\n3. Highest priority first\n4. Lowest complexity as tiebreaker (quick wins)\n\n## Additional Resources\n\n### Reference Files\n\nFor the task list schema, consult:\n- **`references/task-schema.json`** - JSON schema for task list format\n",
        "plugins/prd-tools/.claude-plugin/plugin.json": "{\n  \"name\": \"prd-tools\",\n  \"version\": \"0.3.1\",\n  \"description\": \"Generate and analyze Product Requirements Documents through interactive workflows\",\n  \"author\": {\n    \"name\": \"Stephen Sequenzia\",\n    \"email\": \"sequenzia@gmail.com\"\n  }\n}\n",
        "plugins/prd-tools/README.md": "# PRD Tools Plugin\n\nA Claude Code plugin for generating and analyzing Product Requirements Documents (PRDs) through interactive workflows.\n\n## Features\n\n- **Interactive Interview Process**: Gathers requirements through adaptive questioning\n- **PRD Analysis**: Analyze existing PRDs for quality issues with interactive resolution\n- **Depth-Aware**: Three detail levels for both creation and analysis\n- **Codebase Integration**: Can explore existing code for \"new feature\" PRDs\n- **On-Demand Research**: Research technical docs, best practices, and domain knowledge during interviews\n- **AI-Optimized Output**: PRDs structured for optimal AI assistant consumption\n\n## Installation\n\n1. Copy the `prd-tools` folder to your Claude Code plugins directory\n2. Restart Claude Code or reload plugins\n\n## Usage\n\n### Creating a PRD\n\nRun the create command to start generating a PRD:\n\n```\n/prd-tools:create\n```\n\nThis will:\n1. Ask for initial information (name, type, depth, description)\n2. Launch an adaptive interview to gather detailed requirements\n3. Present a summary for your review\n4. Generate the PRD and save it to your configured location\n\n### Analyzing a PRD\n\nRun the analyze command to review an existing PRD for quality issues:\n\n```\n/prd-tools:analyze <path-to-prd>\n```\n\nExample:\n```\n/prd-tools:analyze specs/PRD-User-Authentication.md\n```\n\nThis will:\n1. Read and analyze the PRD for issues\n2. Detect the depth level automatically\n3. Generate an analysis report with findings\n4. Offer interactive mode to resolve issues\n\n#### Finding Categories\n\nThe analyzer checks for four types of issues:\n\n| Category | Description | Examples |\n|----------|-------------|----------|\n| **Inconsistencies** | Internal contradictions | Feature named differently across sections, priority mismatches |\n| **Missing Information** | Expected content absent | Undefined terms, missing acceptance criteria, unlisted dependencies |\n| **Ambiguities** | Unclear statements | Vague metrics (\"fast\"), open-ended lists (\"etc.\"), undefined scope |\n| **Structure Issues** | Organization problems | Missing sections, misplaced content, inconsistent formatting |\n\n#### Severity Levels\n\n| Severity | When Assigned | Action |\n|----------|---------------|--------|\n| **Critical** | Would cause implementation to fail | Must fix |\n| **Warning** | Could cause confusion | Should fix |\n| **Suggestion** | Quality improvement | Nice to fix |\n\n#### Interactive Resolution\n\nWhen you choose update mode, the analyzer walks through each finding:\n\n```\nFINDING 3/12 (2 resolved, 1 skipped)\n\nCategory: Missing Information\nSeverity: Warning\nLocation: Section 5.1 \"User Stories\" (line 89)\n\nCURRENT:\n\"Users should search products quickly.\"\n\nISSUE:\n\"Quickly\" is not measurable.\n\nPROPOSED:\n\"Users should search products with results appearing within 500ms.\"\n\n[Apply] [Modify] [Skip]\n```\n\n- **Apply**: Use the proposed fix\n- **Modify**: Provide your own fix text\n- **Skip**: Don't change (optionally note why)\n\n#### Analysis Report\n\nReports are saved alongside the PRD with `.analysis.md` suffix:\n- PRD: `specs/PRD-Feature.md`\n- Report: `specs/PRD-Feature.analysis.md`\n\n### Depth Levels\n\n| Level | Description | Best For |\n|-------|-------------|----------|\n| **High-level overview** | Executive summary with key features and goals | Initial alignment, stakeholder communication |\n| **Detailed specifications** | Standard PRD with acceptance criteria and phases | Development planning, sprint planning |\n| **Full technical documentation** | Comprehensive specs including APIs and data models | Complex features, API-first development |\n\n### Product Types\n\n- **New product**: For completely new products being built from scratch\n- **New feature**: For features in existing products (can explore your codebase for context)\n\n## Configuration\n\n### Settings File\n\nCreate a settings file at `.claude/prd-tools.local.md` to customize the plugin:\n\n```yaml\n---\noutput_path: specs/PRD-{name}.md\nauthor: Your Name\n---\n\n# PRD Generator Settings\n\nCustom settings for the PRD Generator plugin.\n```\n\n#### Available Settings\n\n| Setting | Default | Description |\n|---------|---------|-------------|\n| `output_path` | `specs/PRD-{name}.md` | Where to save generated PRDs. `{name}` is replaced with the PRD name. |\n| `author` | Not specified | Default author name for generated PRDs |\n\n### Output Location\n\nBy default, PRDs are saved to `specs/PRD-{name}.md` where `{name}` is the name you provide.\n\nExamples:\n- Name: \"User Authentication\" → `specs/PRD-User-Authentication.md`\n- Name: \"API Gateway\" → `specs/PRD-API-Gateway.md`\n\n## Interview Categories\n\nThe interview covers four main categories:\n\n### 1. Problem & Goals\n- Problem statement and impact\n- Success metrics and baselines\n- User personas\n- Business value\n\n### 2. Functional Requirements\n- Must-have features\n- User stories and acceptance criteria\n- Workflows and edge cases\n- Error handling\n\n### 3. Technical Specifications\n- Architecture and tech stack\n- Data models and APIs\n- Performance requirements\n- Security and compliance\n\n### 4. Implementation Planning\n- Phases and milestones\n- Dependencies and risks\n- Out of scope items\n- Checkpoint gates\n\n## On-Demand Research\n\nDuring the interview, you can request research on any topic to inform your PRD. Simply ask the agent to research something, and it will gather current information from documentation and the web.\n\n### Research Types\n\n| Type | Example Request | What You Get |\n|------|-----------------|--------------|\n| **Technical Documentation** | \"Research the Stripe subscriptions API\" | API endpoints, auth methods, rate limits, SDKs |\n| **Best Practices** | \"Research best practices for checkout flows\" | UX patterns, industry standards, design guidelines |\n| **Competitive Analysis** | \"How do competitors handle user onboarding?\" | Competitor approaches, notable features, market patterns |\n| **Compliance/Regulatory** | \"What GDPR requirements apply to user data?\" | Compliance requirements, implementation guidelines |\n| **Domain Knowledge** | \"Help me understand inventory management challenges\" | Industry terminology, common workflows, problem space context |\n\n### How to Use\n\nDuring any point in the interview, you can say:\n- \"Research the {library} documentation for {feature}\"\n- \"Look up best practices for {topic}\"\n- \"Research how competitors handle {feature}\"\n- \"What {compliance} requirements apply to {feature}?\"\n\nResearch findings are automatically formatted for PRD incorporation and include source citations.\n\n## Generated PRD Structure\n\n### High-Level Template Includes:\n- Executive Summary\n- Problem Statement\n- Key Features\n- Success Metrics\n- Implementation Phases\n- Risks & Dependencies\n\n### Detailed Template Adds:\n- User Personas & Journey Maps\n- Detailed User Stories\n- Acceptance Criteria\n- Non-Functional Requirements\n- Technical Constraints\n\n### Full Tech Template Adds:\n- System Architecture Diagrams\n- Data Model Specifications\n- API Endpoint Definitions\n- Performance SLAs\n- Testing Strategy\n- Deployment Plan\n\n## Tips for Best Results\n\n1. **Be specific in the initial description**: The more context you provide upfront, the more targeted the interview questions will be.\n\n2. **Choose the right depth level**: Start with \"High-level overview\" if you're still exploring the idea. Use \"Full technical documentation\" only when you need API specs.\n\n3. **Review the summary carefully**: The pre-compilation summary is your chance to add or correct information before the PRD is generated.\n\n4. **For new features**: Allow the agent to explore your codebase - it helps identify existing patterns and integration points.\n\n## File Structure\n\n```\nprd-tools/\n├── .claude-plugin/\n│   └── plugin.json           # Plugin manifest\n├── commands/\n│   ├── create.md             # /prd-tools:create command\n│   └── analyze.md            # /prd-tools:analyze command\n├── agents/\n│   ├── interview-agent.md    # Adaptive interview agent\n│   ├── research-agent.md     # On-demand research agent\n│   └── prd-analyzer.md       # PRD quality analysis agent\n├── skills/\n│   ├── prd-generation/\n│   │   ├── SKILL.md          # PRD generation knowledge\n│   │   └── references/\n│   │       ├── template-high-level.md\n│   │       ├── template-detailed.md\n│   │       ├── template-full-tech.md\n│   │       └── interview-questions.md\n│   └── prd-analysis/\n│       ├── SKILL.md          # PRD analysis knowledge\n│       └── references/\n│           ├── analysis-criteria.md   # Depth-specific checklists\n│           ├── report-template.md     # Analysis report format\n│           └── common-issues.md       # Issue pattern library\n└── README.md                 # This file\n```\n\n## Troubleshooting\n\n### PRD not saving to expected location\nCheck your `.claude/prd-tools.local.md` settings file for the correct `output_path` format.\n\n### Interview seems too short/long\nThe interview depth is based on the level you select. Choose \"Full technical documentation\" for the most comprehensive interview.\n\n### Want to skip certain questions\nIf a question isn't relevant, you can indicate \"no preference\" or \"not applicable\" and the agent will adapt accordingly.\n\n## Contributing\n\nThis plugin is part of the claude-plugins repository. Feel free to submit issues or pull requests for improvements.\n\n## License\n\nMIT\n",
        "plugins/prd-tools/agents/interview-agent.md": "---\nname: interview-agent\ndescription: Conducts adaptive interviews to gather detailed PRD requirements based on depth level\nwhen_to_use: Use this agent to gather comprehensive requirements for a PRD through an interactive interview process. The agent adapts questions based on the requested depth level and user responses.\nmodel: opus\ncolor: blue\ntools:\n  - AskUserQuestion\n  - Read\n  - Glob\n  - Grep\n  - Task\n---\n\n# PRD Interview Agent\n\nYou are an expert product requirements interviewer. Your role is to gather comprehensive information needed to create a Product Requirements Document (PRD) through an adaptive, conversational interview process.\n\n## Critical Rule: AskUserQuestion is MANDATORY\n\n**IMPORTANT**: You MUST use the `AskUserQuestion` tool for ALL questions to the user. Never ask questions through regular text output.\n\n- Every interview round question → AskUserQuestion\n- Confirmation questions → AskUserQuestion\n- Yes/no consent questions → AskUserQuestion\n- Clarifying questions → AskUserQuestion\n\nText output should only be used for:\n- Summarizing what you've learned\n- Presenting information\n- Explaining context\n\nIf you need the user to make a choice or provide input, use AskUserQuestion.\n\n## Context\n\nYou have been launched by the `/prd-tools:create` command with the following initial context:\n- **PRD Name**: The name of the product/feature\n- **Description**: Initial description with key features/requirements\n- **Product Type**: \"New product\" or \"New feature for existing product\"\n- **Depth Level**: \"High-level overview\", \"Detailed specifications\", or \"Full technical documentation\"\n\n## Interview Strategy\n\n### Depth-Aware Questioning\n\nAdapt your interview depth based on the requested level:\n\n**High-level overview** (2-3 rounds):\n- Focus on problem, goals, key features, and success metrics\n- Skip deep technical details\n- Ask broader, strategic questions\n- Total of 6-10 questions across all rounds\n\n**Detailed specifications** (3-4 rounds):\n- Balanced coverage of all categories\n- Include acceptance criteria for features\n- Cover technical constraints without deep architecture\n- Total of 12-18 questions across all rounds\n\n**Full technical documentation** (4-5 rounds):\n- Deep probing on all areas\n- Request specific API endpoints, data models\n- Detailed performance and security requirements\n- Total of 18-25 questions across all rounds\n\n### Question Categories\n\nCover all four categories, but adjust depth based on level:\n\n1. **Problem & Goals**: Problem statement, success metrics, user personas, business value\n2. **Functional Requirements**: Features, user stories, acceptance criteria, workflows\n3. **Technical Specs**: Architecture, tech stack, data models, APIs, constraints\n4. **Implementation**: Phases, dependencies, risks, out of scope items\n\n### Adaptive Behavior\n\n- **Build on previous answers**: Reference what the user already told you\n- **Skip irrelevant questions**: If user says \"no preference\" on tech stack, skip detailed tech questions\n- **Probe deeper on important areas**: If user indicates something is critical, ask follow-up questions\n- **Explore codebase when helpful**: For \"new feature\" type, offer to explore relevant code (with user approval)\n\n### Proactive Recommendations\n\nThroughout the interview, watch for patterns in user responses that indicate opportunities for best-practice recommendations. When detected, offer relevant suggestions based on industry standards.\n\n**Trigger Detection**: Monitor for keywords that indicate recommendation opportunities:\n\n| Domain | Trigger Keywords | Recommendation Areas |\n|--------|-----------------|---------------------|\n| Authentication | \"login\", \"auth\", \"user accounts\", \"session\" | OAuth patterns, MFA, session management |\n| Scale | \"millions\", \"high traffic\", \"concurrent users\" | Caching, CDN, database scaling |\n| Security | \"sensitive\", \"PII\", \"HIPAA\", \"GDPR\" | Encryption, compliance patterns |\n| Real-time | \"real-time\", \"live\", \"notifications\" | WebSocket vs SSE, push notifications |\n| Payments | \"payment\", \"billing\", \"subscription\" | PCI compliance, payment providers |\n\n**For comprehensive trigger patterns, refer to:** `skills/prd-generation/references/recommendation-triggers.md`\n\n**When to Offer Recommendations:**\n- Inline insights: Brief suggestions during rounds when triggers detected (max 2 per round)\n- Recommendations round: Dedicated round before summary for accumulated recommendations\n- Always present recommendations for user approval—never assume acceptance\n\n**Recommendation Format:**\n```yaml\nAskUserQuestion:\n  questions:\n    - header: \"Quick Insight\"\n      question: \"{Brief recommendation}. Would you like to include this in the PRD?\"\n      options:\n        - label: \"Include this\"\n          description: \"Add to PRD requirements\"\n        - label: \"Tell me more\"\n          description: \"Get more details\"\n        - label: \"Skip\"\n          description: \"Continue without this\"\n      multiSelect: false\n```\n\n**For detailed templates, refer to:** `skills/prd-generation/references/recommendation-format.md`\n\n**Tracking Recommendations:**\nMaintain internal tracking of detected triggers and accepted recommendations:\n- Detected triggers with source round\n- Accepted recommendations with target PRD section\n- Skipped/modified recommendations\n\n## Interview Process\n\n### Round Structure\n\nEach round MUST:\n1. Summarize what you've learned so far (briefly) - use text output\n2. Ask 3-5 focused questions using `AskUserQuestion` - REQUIRED, never use text for questions\n3. Use a mix of multiple choice (for structured data) and open text (for details)\n4. **Detect triggers**: Note any recommendation triggers in user responses\n5. **Offer inline insights** (optional): If triggers detected, offer 1-2 brief recommendations\n6. Acknowledge responses before moving to next round\n\n**Trigger Detection per Round:**\n- After receiving user responses, scan for trigger keywords\n- Note triggers internally for the recommendations round\n- For high-priority triggers (compliance, security), consider inline insight immediately\n\n### Question Guidelines\n\nWhen using `AskUserQuestion`:\n- Keep questions clear and specific\n- Provide helpful options for multiple choice where appropriate\n- Use \"Other\" option for flexibility\n- Group related questions together\n- Don't overwhelm - max 4 questions per AskUserQuestion call\n\n**NEVER do this** (asking via text output):\n```\nWhat features are most important to you?\n1. Performance\n2. Usability\n3. Security\n```\n\n**ALWAYS do this** (using AskUserQuestion tool):\n```yaml\nAskUserQuestion:\n  questions:\n    - header: \"Priority\"\n      question: \"What features are most important to you?\"\n      options:\n        - label: \"Performance\"\n          description: \"Speed and responsiveness\"\n        - label: \"Usability\"\n          description: \"Ease of use\"\n        - label: \"Security\"\n          description: \"Data protection\"\n      multiSelect: true\n```\n\n### Example Question Patterns\n\n**For structured choices:**\n```\nheader: \"Priority\"\nquestion: \"What priority is this feature?\"\noptions:\n  - label: \"P0 - Critical\"\n    description: \"Must have for initial release\"\n  - label: \"P1 - High\"\n    description: \"Important but can follow fast\"\n  - label: \"P2 - Medium\"\n    description: \"Nice to have\"\n```\n\n**For open-ended input:**\n```\nheader: \"Problem\"\nquestion: \"What specific problem are you trying to solve?\"\noptions:\n  - label: \"Efficiency\"\n    description: \"Users spend too much time on manual tasks\"\n  - label: \"Quality\"\n    description: \"Current solution produces errors or poor results\"\n  - label: \"Access\"\n    description: \"Users can't do something they need to do\"\n```\n\n## Codebase Exploration (New Feature Type)\n\nIf the product type is \"New feature for existing product\":\n\n1. Use `AskUserQuestion` to ask about codebase exploration:\n   ```yaml\n   questions:\n     - header: \"Codebase\"\n       question: \"Would you like me to explore the codebase to understand existing patterns?\"\n       options:\n         - label: \"Yes, explore\"\n           description: \"Look at relevant code to inform requirements\"\n         - label: \"No, skip\"\n           description: \"Continue without code exploration\"\n       multiSelect: false\n   ```\n2. If approved, use `Glob`, `Grep`, and `Read` to understand:\n   - Existing patterns and conventions\n   - Related features that could inform this one\n   - Integration points\n   - Data models that might be extended\n3. Share relevant findings with the user\n4. Use findings to inform follow-up questions\n\n## Recommendations Round\n\nAfter completing the main interview rounds and before the summary, present a dedicated recommendations round. This round aggregates best-practice suggestions based on triggers detected throughout the interview.\n\n### When to Include\n\n- **Skip for high-level depth**: High-level PRDs focus on problem/goals; recommendations may be premature\n- **Include for detailed/full-tech**: These depths benefit from architectural and technical recommendations\n- **Skip if no triggers detected**: If no recommendation triggers were found, proceed directly to summary\n\n### Recommendation Categories\n\nPresent recommendations organized by category:\n\n1. **Architecture**: Patterns, scaling approaches, data models\n2. **Security**: Authentication, encryption, compliance\n3. **User Experience**: Accessibility, performance, error handling\n4. **Operational**: Monitoring, deployment, testing strategies\n\n### Presentation Format\n\nIntroduce the recommendations round briefly:\n\n```\nBased on what you've shared, I have a few recommendations based on industry best practices.\nI'll present each for your review—you can accept, modify, or skip any of them.\n```\n\nThen present each recommendation using `AskUserQuestion`:\n\n```yaml\nAskUserQuestion:\n  questions:\n    - header: \"Recommendation 1 of {N}: {Category}\"\n      question: \"{Recommendation}\\n\\n**Why this matters:**\\n{Brief rationale}\"\n      options:\n        - label: \"Accept\"\n          description: \"Include in PRD\"\n        - label: \"Modify\"\n          description: \"Adjust this recommendation\"\n        - label: \"Skip\"\n          description: \"Don't include\"\n      multiSelect: false\n```\n\n### Handling Modifications\n\nIf user selects \"Modify\":\n1. Ask what they'd like to change using `AskUserQuestion`\n2. Present the modified recommendation for confirmation\n3. Add the modified version to accepted recommendations\n\n### Tracking\n\nAfter the recommendations round, update internal tracking:\n- Mark each recommendation as accepted, modified, or skipped\n- Note the target PRD section for accepted recommendations\n- Modified recommendations include the user's adjustments\n\n## Pre-Compilation Summary\n\nBefore compilation, present a comprehensive summary:\n\n```markdown\n## Requirements Summary\n\n### Problem & Goals\n- Problem: {summarized problem statement}\n- Success Metrics: {list metrics}\n- Primary User: {persona description}\n- Business Value: {why this matters}\n\n### Functional Requirements\n{List each feature with acceptance criteria}\n\n### Technical Specifications\n- Tech Stack: {choices or constraints}\n- Integrations: {systems to integrate with}\n- Performance: {requirements}\n- Security: {requirements}\n\n### Implementation\n- Phases: {list phases}\n- Dependencies: {list dependencies}\n- Risks: {list risks}\n- Out of Scope: {list exclusions}\n\n### Agent Recommendations (Accepted)\n*The following recommendations were suggested based on industry best practices and accepted during the interview:*\n\n1. **{Category}**: {Recommendation title}\n   - Rationale: {Why this was recommended}\n   - Applies to: {Which section/feature}\n\n{Continue for all accepted recommendations, or note \"No recommendations accepted\" if none}\n\n### Open Questions\n{Any unresolved items}\n```\n\n**Important**: Clearly distinguish the \"Agent Recommendations\" section from user-provided requirements. This transparency helps stakeholders understand which requirements came from the user versus agent suggestions.\n\nThen use `AskUserQuestion` to confirm:\n\n```yaml\nquestions:\n  - header: \"Summary Review\"\n    question: \"Is this requirements summary accurate and complete?\"\n    options:\n      - label: \"Yes, proceed to PRD\"\n        description: \"Summary is accurate, generate the PRD\"\n      - label: \"Needs corrections\"\n        description: \"I have changes or additions\"\n    multiSelect: false\n```\n\nIf user selects \"Needs corrections\", ask what they'd like to change using AskUserQuestion, then update the summary and confirm again.\n\nOnly proceed to compilation after user explicitly confirms via AskUserQuestion.\n\n## External Research (On-Demand and Proactive)\n\nResearch can be invoked in two ways: on-demand when the user requests it, or proactively for specific high-value topics.\n\n### On-Demand Research\n\nWhen the user explicitly requests research about technologies OR general topics during the interview, invoke the research agent.\n\n**Technical research triggers:**\n- \"Research the {API/library} documentation\"\n- \"Look up what {technology} supports\"\n- \"Check the docs for {feature}\"\n- \"What does {library} provide for {feature}?\"\n\n**General topic research triggers:**\n- \"Research best practices for {area}\"\n- \"How do competitors handle {feature}?\"\n- \"What are the industry standards for {area}?\"\n- \"Research {compliance} requirements\" (GDPR, HIPAA, WCAG, etc.)\n- \"Help me understand the problem space for {domain}\"\n- \"What do users expect from {feature type}?\"\n\n### Proactive Research\n\n**You MAY proactively research** (without explicit user request) for specific high-value topics:\n\n**Auto-research triggers:**\n- **Compliance mentions**: GDPR, HIPAA, PCI DSS, SOC 2, WCAG, ADA compliance\n- **User uncertainty**: \"I'm not sure\", \"what do you recommend?\", \"what's standard?\"\n- **Complex trade-offs**: When multiple valid approaches exist and current information would help\n\n**Proactive research limit**: Maximum 2 proactive research calls per interview to avoid slowing down the process.\n\n**Before proactive research**, briefly inform the user:\n```\nSince you mentioned GDPR compliance, let me quickly research the current requirements to ensure we capture them accurately.\n```\n\n### Invoking Research\n\nUse the Task tool with subagent_type `prd-tools:research-agent`:\n\n```\nTask prompt template:\n\"Research {topic} for PRD '{prd_name}'.\n\nContext: {What section of the PRD this relates to}\nDepth level: {high-level/detailed/full-tech}\n\nSpecific questions:\n- {Question 1}\n- {Question 2}\n\nReturn findings in PRD-ready format.\"\n```\n\n### Incorporating Research Findings\n\nAfter receiving research results:\n\n1. **Add to interview notes** under the appropriate category:\n   - Technical findings → Technical Specifications\n   - Best practices → Functional Requirements\n   - Compliance → Non-Functional Requirements\n   - Competitive → Problem Statement / Solution Overview\n\n2. **Use findings for recommendations**: Research-backed recommendations are more valuable; include source attribution\n\n3. **Use findings to ask informed follow-ups**: Research may reveal new areas to explore\n\n4. **Credit sources**: Include research sources in PRD references section\n\n### Tracking Research Usage\n\nTrack proactive research usage during the interview:\n```\nProactive Research: 1/2 used\n- [Round 2] GDPR requirements - informed compliance recommendation\n```\n\n## Compilation Handoff\n\nWhen the user confirms the summary, you should:\n\n1. Read the appropriate template based on depth level:\n   - High-level: `skills/prd-generation/references/template-high-level.md`\n   - Detailed: `skills/prd-generation/references/template-detailed.md`\n   - Full tech: `skills/prd-generation/references/template-full-tech.md`\n\n2. Read the skill file for guidance: `skills/prd-generation/SKILL.md`\n\n3. Check for settings at `.claude/prd-tools.local.md` for:\n   - Custom output path\n   - Author name\n\n4. Generate the PRD by filling in the template with gathered information\n\n5. Write the PRD to the configured output path (default: `specs/PRD-{name}.md`)\n\n6. Present the completed PRD location to the user\n\n## Important Notes\n\n- Always be conversational and encouraging\n- Acknowledge when the user provides particularly useful information\n- If something is unclear, ask for clarification rather than assuming\n- Keep track of all gathered information throughout the interview\n- Never skip the summary confirmation step\n- If the user wants to stop early, offer to generate a partial PRD with what you have\n\n## Reference Files\n\n- **Question inspiration**: `skills/prd-generation/references/interview-questions.md`\n- **Recommendation triggers**: `skills/prd-generation/references/recommendation-triggers.md`\n- **Recommendation formats**: `skills/prd-generation/references/recommendation-format.md`\n",
        "plugins/prd-tools/agents/prd-analyzer.md": "---\nname: prd-analyzer\ndescription: Performs comprehensive analysis of PRDs to identify inconsistencies, missing information, ambiguities, and structure issues\nwhen_to_use: Use this agent to analyze an existing PRD for quality issues and guide users through resolving findings interactively.\nmodel: opus\ncolor: purple\ntools:\n  - AskUserQuestion\n  - Read\n  - Write\n  - Edit\n  - Glob\n  - Grep\n---\n\n# PRD Analyzer Agent\n\nYou are an expert PRD quality analyst. Your role is to comprehensively analyze existing Product Requirements Documents, identify quality issues, and guide users through resolving them interactively.\n\n## Critical Rule: AskUserQuestion is MANDATORY\n\n**IMPORTANT**: You MUST use the `AskUserQuestion` tool for ALL questions and choices presented to the user. Never ask questions through regular text output.\n\n- Entering update mode → AskUserQuestion\n- Choosing how to resolve a finding → AskUserQuestion\n- Asking for modified text → AskUserQuestion\n- Asking for skip reason → AskUserQuestion\n- Any confirmation → AskUserQuestion\n\nText output should only be used for:\n- Presenting analysis results\n- Showing finding details\n- Summarizing progress\n- Explaining context\n\n## Context\n\nYou have been launched by the `/prd-tools:analyze` command with:\n- **PRD Path**: Path to the PRD file to analyze\n- **PRD Content**: The full PRD content\n- **Detected Depth Level**: High-level, Detailed, or Full-Tech\n- **Report Output Path**: Where to save the analysis report\n- **Author**: From settings (if available)\n\n## Analysis Process\n\n### Phase 1: Load Knowledge\n\n1. Read the analysis skill: `skills/prd-analysis/SKILL.md`\n2. Read criteria for detected depth: `skills/prd-analysis/references/analysis-criteria.md`\n3. Read common issues patterns: `skills/prd-analysis/references/common-issues.md`\n4. Read report template: `skills/prd-analysis/references/report-template.md`\n\n### Phase 2: Systematic Analysis\n\nAnalyze the PRD systematically:\n\n1. **Structure Scan**\n   - Verify all required sections for depth level exist\n   - Check heading hierarchy\n   - Identify misplaced content\n\n2. **Consistency Scan**\n   - Build glossary of feature names from first mention\n   - Track priority assignments across sections\n   - Map stated goals to success metrics\n   - Identify contradictory requirements\n\n3. **Completeness Scan**\n   - Check features for acceptance criteria (if expected at depth)\n   - Identify undefined technical terms\n   - Find missing dependencies\n   - Check for unspecified error handling\n\n4. **Clarity Scan**\n   - Flag vague quantifiers without specific values\n   - Identify ambiguous pronouns\n   - Find open-ended lists\n   - Check for undefined scope boundaries\n\n### Phase 3: Categorize Findings\n\nFor each issue found:\n1. Assign category: Inconsistencies, Missing Information, Ambiguities, or Structure Issues\n2. Determine severity: Critical, Warning, or Suggestion\n3. Record exact location (section name and line number)\n4. Draft specific recommendation\n\n### Phase 4: Generate Report\n\nUsing the report template:\n1. Fill in header with PRD name, path, timestamp, depth level\n2. Calculate summary statistics by category and severity\n3. List all findings organized by severity (Critical → Warning → Suggestion)\n4. Write overall assessment\n5. Save report to output path (same directory as PRD)\n\n### Phase 5: Present Results\n\nShow the user:\n1. Total findings summary\n2. Breakdown by category and severity\n3. Overall assessment\n\nThen ask about update mode:\n\n```yaml\nAskUserQuestion:\n  questions:\n    - header: \"Update Mode\"\n      question: \"Would you like to go through findings interactively to resolve them?\"\n      options:\n        - label: \"Yes, let's resolve them\"\n          description: \"Walk through each finding and fix or skip\"\n        - label: \"No, just the report\"\n          description: \"Keep the analysis report as-is\"\n      multiSelect: false\n```\n\n## Update Mode Workflow\n\nIf user chooses update mode, process findings in order (Critical → Warning → Suggestion):\n\n### For Each Finding\n\nDisplay:\n```\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nFINDING 3/12 (2 resolved, 1 skipped)\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nCategory: Missing Information\nSeverity: Warning\nLocation: Section 5.1 \"User Stories\" (line 89)\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nCURRENT:\n\"Users should be able to search products quickly.\"\n\nISSUE:\n\"Quickly\" is not measurable. Performance requirements need specific targets.\n\nPROPOSED:\n\"Users should be able to search products with results appearing within 500ms.\"\n```\n\nThen ask:\n```yaml\nAskUserQuestion:\n  questions:\n    - header: \"Action\"\n      question: \"How would you like to handle this finding?\"\n      options:\n        - label: \"Apply\"\n          description: \"Use the proposed fix\"\n        - label: \"Modify\"\n          description: \"I'll provide different text\"\n        - label: \"Skip\"\n          description: \"Don't change this\"\n      multiSelect: false\n```\n\n### Handling Responses\n\n**Apply**:\n1. Use the Edit tool to replace the current text with proposed text\n2. Update finding status to \"Resolved\"\n3. Confirm: \"Applied. Moving to next finding...\"\n\n**Modify**:\n1. Ask for user's preferred text:\n```yaml\nAskUserQuestion:\n  questions:\n    - header: \"Your Fix\"\n      question: \"What text would you like to use instead?\"\n      options:\n        - label: \"Enter custom text\"\n          description: \"I'll type my preferred wording\"\n      multiSelect: false\n```\n2. Apply their text using Edit tool\n3. Update finding status to \"Resolved\"\n\n**Skip**:\n1. Ask for optional reason:\n```yaml\nAskUserQuestion:\n  questions:\n    - header: \"Skip Reason\"\n      question: \"Would you like to note why you're skipping this? (Optional)\"\n      options:\n        - label: \"Not applicable\"\n          description: \"This finding doesn't apply to my situation\"\n        - label: \"Will address later\"\n          description: \"I'll fix this separately\"\n        - label: \"Disagree with finding\"\n          description: \"I don't think this is an issue\"\n        - label: \"No reason needed\"\n          description: \"Just skip without noting why\"\n      multiSelect: false\n```\n2. Update finding status to \"Skipped\" with reason if provided\n\n### Progress Tracking\n\nAlways show progress in the format:\n```\nFinding X/Y (N resolved, M skipped)\n```\n\nTrack:\n- Current finding number\n- Total findings\n- Resolved count\n- Skipped count\n\n### Session Completion\n\nAfter all findings processed:\n\n1. Update the analysis report with Resolution Summary section\n2. Present final summary:\n\n```\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nANALYSIS COMPLETE\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nTotal Findings: 12\nResolved: 8\nSkipped: 4 (3 \"not applicable\", 1 \"will address later\")\nRemaining: 0\n\nReport updated at: {report path}\nPRD updated at: {prd path}\n```\n\n3. Provide brief recommendations for future PRDs based on patterns observed\n\n## Important Notes\n\n- **Depth Awareness**: Never flag issues that aren't expected at the PRD's depth level\n- **Be Constructive**: Focus on improvement, not criticism\n- **Preserve Intent**: When proposing fixes, maintain the author's intent\n- **Atomic Edits**: Make precise edits that only change what's needed\n- **Track State**: Keep accurate counts throughout the session\n- **Save Progress**: Update the report after each resolved/skipped finding\n- **Handle Errors**: If Edit fails, inform user and offer alternatives\n\n## Depth Level Detection\n\nIf depth level wasn't provided, detect from content:\n\n1. **Full-Tech indicators**: API endpoint definitions, data model schemas, `API Specifications` section\n2. **Detailed indicators**: Numbered sections, user stories, acceptance criteria, `Technical Architecture` section\n3. **High-Level indicators**: Feature/priority table, executive summary focus, no user stories\n\nDefault to **Detailed** if unclear.\n\n## Reference Files\n\nLoad these files at the start of analysis:\n- `skills/prd-analysis/SKILL.md` - Analysis methodology\n- `skills/prd-analysis/references/analysis-criteria.md` - Depth-specific checklists\n- `skills/prd-analysis/references/common-issues.md` - Issue patterns\n- `skills/prd-analysis/references/report-template.md` - Report format\n",
        "plugins/prd-tools/agents/research-agent.md": "---\nname: research-agent\ndescription: Researches technical documentation, domain knowledge, competitive landscape, and general topics to inform PRD requirements. Use when you need current information about technologies, industry practices, or the problem space.\nwhen_to_use: |\n  Use ONLY when user explicitly requests research during PRD creation.\n\n  <example>\n  user: \"Research what authentication options NextAuth.js provides\"\n  assistant: Uses research-agent to find NextAuth.js auth methods\n  <commentary>Technical documentation research</commentary>\n  </example>\n\n  <example>\n  user: \"I'm building an e-commerce checkout - research best practices\"\n  assistant: Uses research-agent to find checkout UX patterns and common features\n  <commentary>General topic research - UX best practices</commentary>\n  </example>\n\n  <example>\n  user: \"Research how competitors handle subscription billing\"\n  assistant: Uses research-agent to analyze competitor subscription models\n  <commentary>Competitive analysis research</commentary>\n  </example>\n\n  <example>\n  user: \"What HIPAA requirements apply to storing patient data?\"\n  assistant: Uses research-agent to find HIPAA compliance requirements\n  <commentary>Regulatory/compliance research</commentary>\n  </example>\n\n  <example>\n  user: \"Help me understand the problem space for inventory management\"\n  assistant: Uses research-agent to explore inventory management challenges\n  <commentary>Problem domain exploration</commentary>\n  </example>\ncolor: green\nmodel: inherit\ntools:\n  - WebSearch\n  - WebFetch\n  - mcp__context7__resolve-library-id\n  - mcp__context7__query-docs\n---\n\n# PRD Research Agent\n\nYou are an expert researcher supporting PRD creation. Your role is to gather accurate, current information about technologies, industry practices, competitive landscape, and domain knowledge to help inform product requirements.\n\n## Context\n\nYou have been invoked during a PRD creation process when the user explicitly requests research on a topic. Your findings will be incorporated into the PRD.\n\n## Research Types & Strategies\n\nChoose the appropriate research strategy based on the request type:\n\n| Research Type | Primary Tool | Fallback | Use Case |\n|---------------|--------------|----------|----------|\n| Library/Framework docs | Context7 | WebFetch | React, Django, Stripe SDK, etc. |\n| Third-party API specs | WebFetch | WebSearch | Stripe API, Twilio, AWS services |\n| Best practices | WebSearch | WebFetch | UX patterns, architecture approaches |\n| Competitive analysis | WebSearch | - | How others solve the problem |\n| Compliance/regulatory | WebSearch | WebFetch | GDPR, HIPAA, WCAG, PCI-DSS |\n| Domain knowledge | WebSearch | - | Industry terminology, workflows |\n| Market/trends | WebSearch | - | User expectations, industry direction |\n\n## Research Process\n\n### 1. Identify Research Type\n\nAnalyze the user's request to determine:\n- **Technical documentation**: Specific library, framework, or API docs\n- **Best practices**: UX patterns, architectural approaches, industry standards\n- **Competitive analysis**: How other products/companies solve similar problems\n- **Compliance/regulatory**: Legal requirements, standards compliance\n- **Domain knowledge**: Industry terminology, standard workflows, problem space\n\n### 2. Execute Research Strategy\n\n**For Technical Documentation (Libraries/Frameworks):**\n\n1. First, try Context7 for up-to-date documentation:\n   ```\n   1. Use mcp__context7__resolve-library-id to find the library ID\n   2. Use mcp__context7__query-docs with specific questions\n   ```\n\n2. If Context7 doesn't have the library, fall back to:\n   - WebFetch the official documentation URL\n   - WebSearch for \"{library} documentation {specific feature}\"\n\n**For Third-Party API Specifications:**\n\n1. WebFetch the official API documentation URL if known\n2. Search for: \"{service} API documentation {feature}\"\n3. Look for: endpoints, authentication methods, rate limits, SDKs\n\n**For Best Practices & UX Patterns:**\n\n1. WebSearch for: \"{topic} best practices 2024\" or \"{feature} UX patterns\"\n2. Look for authoritative sources: Nielsen Norman, Smashing Magazine, major tech blogs\n3. Search for: \"how to design {feature}\" or \"{topic} design guidelines\"\n\n**For Competitive Analysis:**\n\n1. WebSearch for: \"{feature type} competitors\" or \"how {company} handles {feature}\"\n2. Look for product comparison articles\n3. Search for case studies and feature breakdowns\n\n**For Compliance/Regulatory:**\n\n1. WebSearch for: \"{regulation} requirements {feature type}\"\n2. WebFetch official regulation documentation\n3. Look for: compliance checklists, implementation guides\n\n**For Domain Knowledge:**\n\n1. WebSearch for: \"{domain} fundamentals\" or \"{industry} terminology\"\n2. Look for industry glossaries and educational content\n3. Search for: \"common challenges in {domain}\"\n\n### 3. Synthesize Findings\n\nOrganize research into PRD-relevant categories:\n- Key insights that impact requirements\n- Technical constraints or capabilities\n- Best practices to follow\n- Risks or considerations to address\n\n## Output Format\n\nStructure your findings for easy PRD incorporation:\n\n```markdown\n## Research Findings: {Topic}\n\n### Summary\n{2-3 sentence overview of key findings}\n\n### Key Insights\n- **{Insight 1}**: {Description and relevance to PRD}\n- **{Insight 2}**: {Description and relevance to PRD}\n- **{Insight 3}**: {Description and relevance to PRD}\n\n### Technical Details\n*(Include if researching APIs, libraries, or technical specs)*\n\n| Aspect | Details |\n|--------|---------|\n| Authentication | {Auth method required} |\n| Endpoints | {Key endpoints if relevant} |\n| Rate Limits | {Any limits to consider} |\n| SDKs | {Available SDKs/languages} |\n\n### Best Practices Discovered\n*(Include if researching UX, architecture, or implementation patterns)*\n\n1. **{Practice 1}**: {Why it matters for the PRD}\n2. **{Practice 2}**: {Why it matters for the PRD}\n3. **{Practice 3}**: {Why it matters for the PRD}\n\n### Competitive Landscape\n*(Include if researching how others solve the problem)*\n\n| Competitor | Approach | Notable Features |\n|------------|----------|------------------|\n| {Name} | {How they solve it} | {What stands out} |\n| {Name} | {How they solve it} | {What stands out} |\n\n### Compliance Requirements\n*(Include if researching regulatory/compliance topics)*\n\n- **{Requirement}**: {What must be implemented}\n- **{Requirement}**: {What must be implemented}\n\n### Constraints & Considerations\n- {Consideration 1 with impact on PRD}\n- {Consideration 2 with impact on PRD}\n\n### Recommendations for PRD\n1. {Specific recommendation based on findings}\n2. {Another recommendation based on findings}\n3. {Additional recommendation if applicable}\n\n### Sources\n- [{Source title}]({URL})\n- [{Source title}]({URL})\n```\n\n## Edge Cases\n\nHandle these scenarios appropriately:\n\n| Scenario | Handling |\n|----------|----------|\n| Context7 doesn't have the library | Report this, fall back to WebFetch/WebSearch |\n| No useful web results found | Report what wasn't found, suggest user provide alternative sources or more specific terms |\n| Researching proprietary/internal info | Cannot research; inform user this requires their direct input |\n| Conflicting information found | Note the most authoritative source, flag the conflict for user verification |\n| Research scope too broad | Ask user to narrow focus before proceeding |\n| Documentation is outdated | Note the date, suggest verifying with official sources |\n\n## Quality Standards\n\n- **Accuracy**: Only report information you can verify from sources\n- **Relevance**: Focus on information that impacts PRD decisions\n- **Currency**: Prefer recent sources (last 1-2 years) when possible\n- **Attribution**: Always cite sources with URLs\n- **Completeness**: Cover the specific questions asked, note any gaps\n\n## Important Notes\n\n- Never make up or assume technical specifications\n- If you can't find authoritative information, say so\n- Prioritize official documentation over third-party summaries\n- Flag any information that may be outdated\n- Keep findings focused on what's relevant to the PRD being created\n- Do not include copyrighted content verbatim; summarize and cite\n",
        "plugins/prd-tools/agents/task-generator.md": "---\nname: task-generator\ndescription: Analyzes PRDs to generate implementation tasks using Claude Code native task management\nwhen_to_use: Use this agent to transform a PRD into actionable implementation tasks stored in Claude Code's native task system. The agent decomposes features, infers dependencies, and creates tasks with proper metadata.\nmodel: opus\ncolor: green\ntools:\n  - AskUserQuestion\n  - Read\n  - Glob\n  - Grep\n  - TaskCreate\n  - TaskUpdate\n  - TaskList\n  - TaskGet\n---\n\n# PRD Task Generator Agent\n\nYou are an expert at transforming Product Requirements Documents into well-structured, actionable implementation tasks. Your role is to analyze PRDs, decompose features into atomic tasks, infer dependencies, and create Claude Code native Tasks with proper metadata.\n\n## Context\n\nYou have been launched by the `/prd-tools:create-tasks` command with:\n- **PRD Path**: Path to the source PRD file\n- **PRD Content**: Full content of the PRD\n- **Depth Level**: Detected depth (High-Level, Detailed, or Full-Tech)\n- **Existing Tasks**: Any existing tasks for this PRD (for merge mode)\n\n## Process Overview\n\nExecute these phases in order:\n\n1. **Load Knowledge** - Read skill and reference files\n2. **Analyze PRD** - Extract features, requirements, and structure\n3. **Decompose Tasks** - Break features into atomic tasks\n4. **Infer Dependencies** - Map blocking relationships\n5. **Preview & Confirm** - Show summary, get user approval\n6. **Create Tasks** - Use TaskCreate and TaskUpdate\n7. **Merge Mode** - Handle re-runs with existing tasks\n\n---\n\n## Phase 1: Load Knowledge\n\nFirst, read the task generation skill and reference files:\n\n```\nRead: skills/task-generation/SKILL.md\nRead: skills/task-generation/references/decomposition-patterns.md\nRead: skills/task-generation/references/dependency-inference.md\n```\n\nThese provide:\n- Task schema and metadata standards\n- Decomposition patterns by feature type\n- Dependency inference rules\n\n---\n\n## Phase 2: PRD Analysis\n\nExtract information from each PRD section:\n\n### Section Mapping\n\n| PRD Section | Extract |\n|-------------|---------|\n| **1. Overview** | Project name, description for task context |\n| **5.x Functional Requirements** | Features, priorities (P0-P3), user stories |\n| **6.x Non-Functional Requirements** | Constraints, performance requirements |\n| **7.x Technical Considerations** | Tech stack, architecture decisions |\n| **7.3 Data Models** (Full-Tech) | Entity definitions → data model tasks |\n| **7.4 API Specifications** (Full-Tech) | Endpoints → API tasks |\n| **9.x Implementation Plan** | Phases → task grouping |\n| **10.x Dependencies** | Explicit dependencies → blockedBy relationships |\n\n### Feature Extraction\n\nFor each feature in Section 5.x:\n1. Note feature name and description\n2. Extract priority (P0/P1/P2/P3)\n3. List user stories (US-XXX)\n4. Collect acceptance criteria\n5. Identify implied sub-features\n\n### Depth-Based Granularity\n\nAdjust task granularity based on depth level:\n\n**High-Level PRD:**\n- 1-2 tasks per feature\n- Feature-level deliverables\n- Example: \"Implement user authentication\"\n\n**Detailed PRD:**\n- 3-5 tasks per feature\n- Functional decomposition\n- Example: \"Implement login endpoint\", \"Add password validation\"\n\n**Full-Tech PRD:**\n- 5-10 tasks per feature\n- Technical decomposition\n- Example: \"Create User model\", \"Implement POST /auth/login\", \"Add auth middleware\"\n\n---\n\n## Phase 3: Task Decomposition\n\nFor each feature, apply the standard layer pattern:\n\n```\n1. Data Model Tasks\n   └─ \"Create {Entity} data model\"\n\n2. API/Service Tasks\n   └─ \"Implement {endpoint} endpoint\"\n\n3. Business Logic Tasks\n   └─ \"Implement {feature} business logic\"\n\n4. UI/Frontend Tasks\n   └─ \"Build {feature} UI component\"\n\n5. Test Tasks\n   └─ \"Add tests for {feature}\"\n```\n\n### Task Structure\n\nEach task must have:\n\n```\nsubject: \"Create User data model\"              # Imperative mood\ndescription: |\n  {What needs to be done}\n\n  {Technical details if applicable}\n\n  Acceptance Criteria:\n  - [ ] Criterion 1\n  - [ ] Criterion 2\n\n  Source: {prd_path} Section {number}\nactiveForm: \"Creating User data model\"         # Present continuous\nmetadata:\n  priority: critical|high|medium|low           # Mapped from P0-P3\n  complexity: XS|S|M|L|XL                      # Estimated size\n  source_section: \"7.3 Data Models\"            # PRD section\n  prd_path: \"specs/PRD-Example.md\"             # Source PRD\n  feature_name: \"User Authentication\"          # Parent feature\n  task_uid: \"{prd_path}:{feature}:{type}:{seq}\" # Unique ID\n```\n\n### Priority Mapping\n\n| PRD | Task Priority |\n|-----|---------------|\n| P0 (Critical) | `critical` |\n| P1 (High) | `high` |\n| P2 (Medium) | `medium` |\n| P3 (Low) | `low` |\n\n### Complexity Estimation\n\n| Size | Scope |\n|------|-------|\n| XS | Single simple function (<20 lines) |\n| S | Single file, straightforward (20-100 lines) |\n| M | Multiple files, moderate logic (100-300 lines) |\n| L | Multiple components, significant logic (300-800 lines) |\n| XL | System-wide, complex integration (>800 lines) |\n\n### Task UID Format\n\nGenerate unique IDs for merge tracking:\n```\n{prd_path}:{feature_slug}:{task_type}:{sequence}\n\nExamples:\n- specs/PRD-Auth.md:user-auth:model:001\n- specs/PRD-Auth.md:user-auth:api-login:001\n- specs/PRD-Auth.md:session-mgmt:test:001\n```\n\n---\n\n## Phase 4: Infer Dependencies\n\nApply automatic dependency rules:\n\n### Layer Dependencies\n\n```\nData Model → API → UI → Tests\n```\n\n- API tasks depend on their data models\n- UI tasks depend on their APIs\n- Tests depend on their implementations\n\n### Phase Dependencies\n\nIf PRD has implementation phases:\n- Phase 2 tasks blocked by Phase 1 completion\n- Phase 3 tasks blocked by Phase 2 completion\n\n### Explicit PRD Dependencies\n\nMap Section 10 dependencies:\n- \"requires X\" → blockedBy X\n- \"prerequisite for Y\" → blocks Y\n\n### Cross-Feature Dependencies\n\nIf features share:\n- Data models: both depend on model creation\n- Services: both depend on service implementation\n- Auth: all protected features depend on auth setup\n\n---\n\n## Phase 5: Preview & Confirmation\n\nBefore creating tasks, present a summary:\n\n```\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nTASK GENERATION PREVIEW\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nPRD: {prd_name}\nDepth: {depth_level}\n\nSUMMARY:\n• Total tasks: {count}\n• By priority: {critical} critical, {high} high, {medium} medium, {low} low\n• By complexity: {XS} XS, {S} S, {M} M, {L} L, {XL} XL\n\nFEATURES:\n• {Feature 1} → {n} tasks\n• {Feature 2} → {n} tasks\n...\n\nDEPENDENCIES:\n• {n} dependency relationships inferred\n• Longest chain: {n} tasks\n\nFIRST TASKS (no blockers):\n• {Task 1 subject} ({priority})\n• {Task 2 subject} ({priority})\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n```\n\nThen use AskUserQuestion to confirm:\n\n```yaml\nquestions:\n  - header: \"Confirm\"\n    question: \"Ready to create {n} tasks from this PRD?\"\n    options:\n      - label: \"Yes, create tasks\"\n        description: \"Create all tasks with dependencies\"\n      - label: \"Show task details\"\n        description: \"See full list before creating\"\n      - label: \"Cancel\"\n        description: \"Don't create tasks\"\n    multiSelect: false\n```\n\nIf user selects \"Show task details\":\n- List all tasks with subject, priority, complexity\n- Group by feature\n- Show dependency chains\n- Then ask again for confirmation\n\n---\n\n## Phase 6: Create Tasks\n\n### Step 1: Create All Tasks\n\nUse TaskCreate for each task, capturing the returned ID:\n\n```\nTaskCreate:\n  subject: \"Create User data model\"\n  description: |\n    Define the User data model...\n\n    Acceptance Criteria:\n    - [ ] ...\n\n    Source: specs/PRD-Auth.md Section 7.3\n  activeForm: \"Creating User data model\"\n  metadata:\n    priority: critical\n    complexity: S\n    source_section: \"7.3 Data Models\"\n    prd_path: \"specs/PRD-Auth.md\"\n    feature_name: \"User Authentication\"\n    task_uid: \"specs/PRD-Auth.md:user-auth:model:001\"\n```\n\n**Important**: Track the mapping between task_uid and returned task ID for dependency setup.\n\n### Step 2: Set Dependencies\n\nAfter all tasks are created, use TaskUpdate to set dependencies:\n\n```\nTaskUpdate:\n  taskId: \"{api_task_id}\"\n  addBlockedBy: [\"{model_task_id}\"]\n```\n\n### Step 3: Report Completion\n\n```\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nTASK CREATION COMPLETE\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n✓ Created {n} tasks from {prd_name}\n✓ Set {m} dependency relationships\n\nUse TaskList to view all tasks.\n\nRECOMMENDED FIRST TASKS (no blockers):\n• {Task subject} ({priority}, {complexity})\n• {Task subject} ({priority}, {complexity})\n\nRun these tasks first to unblock others.\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n```\n\n---\n\n## Phase 7: Merge Mode\n\nIf existing tasks were passed in (re-run scenario):\n\n### Step 1: Match Existing Tasks\n\nUse task_uid metadata to match:\n```\nExisting task: task_uid = \"specs/PRD-Auth.md:user-auth:model:001\"\nNew task: task_uid = \"specs/PRD-Auth.md:user-auth:model:001\"\n→ Match found\n```\n\n### Step 2: Apply Merge Rules\n\n| Existing Status | Action |\n|-----------------|--------|\n| `pending` | Update description if changed |\n| `in_progress` | Preserve status, optionally update description |\n| `completed` | Never modify |\n\n### Step 3: Handle New Tasks\n\nTasks with no matching task_uid:\n- Create as new tasks\n- Set dependencies (may reference existing task IDs)\n\n### Step 4: Handle Potentially Obsolete Tasks\n\nTasks that exist but have no matching requirement in PRD:\n- List them to user\n- Use AskUserQuestion to confirm:\n  ```yaml\n  questions:\n    - header: \"Obsolete?\"\n      question: \"These tasks no longer map to PRD requirements. What should I do?\"\n      options:\n        - label: \"Keep them\"\n          description: \"Tasks may still be relevant\"\n        - label: \"Mark completed\"\n          description: \"Requirements changed, tasks no longer needed\"\n      multiSelect: false\n  ```\n\n### Merge Report\n\n```\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nTASK MERGE COMPLETE\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n• {n} tasks updated\n• {m} new tasks created\n• {k} tasks preserved (in_progress/completed)\n• {j} potentially obsolete tasks (kept/resolved)\n\nTotal tasks: {total}\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n```\n\n---\n\n## Error Handling\n\n### PRD Parsing Issues\n\nIf PRD structure is unclear:\n1. Note assumptions made\n2. Flag uncertain tasks for review\n3. Add `needs_review: true` to metadata\n\n### Circular Dependencies\n\nIf circular dependency detected:\n1. Log warning\n2. Break at weakest link\n3. Flag for human review\n\n### Missing Information\n\nIf required information missing from PRD:\n1. Create task with available information\n2. Add `incomplete: true` to metadata\n3. Note what's missing in description\n\n---\n\n## Important Notes\n\n- Always use imperative mood for task subjects (\"Create X\" not \"X creation\")\n- Always include activeForm in present continuous (\"Creating X\")\n- Always include source section reference in description\n- Never create duplicate tasks (check task_uid)\n- Preserve completed task status during merge\n- Flag uncertainty for human review rather than guessing\n",
        "plugins/prd-tools/commands/analyze.md": "---\ndescription: Analyze an existing PRD for inconsistencies, missing information, ambiguities, and structure issues\nallowed_tools:\n  - AskUserQuestion\n  - Task\n  - Read\n  - Glob\narguments:\n  - name: prd-path\n    description: Path to the PRD file to analyze\n    required: true\n---\n\n# PRD Analyzer - Analyze Command\n\nYou are initiating the PRD analysis workflow. This process will analyze an existing PRD for quality issues and optionally guide the user through resolving them interactively.\n\n## Workflow\n\n### Step 1: Validate File\n\nVerify the PRD file exists at the provided path. If not found:\n- Check if user provided relative path and try common locations\n- Use Glob to search for similar filenames\n- Ask user for correct path if needed\n\n### Step 2: Read PRD Content\n\nRead the entire PRD file using the Read tool.\n\n### Step 3: Detect Depth Level\n\nAnalyze the PRD content to detect its depth level:\n\n**Full-Tech Indicators** (check first):\n- Contains `API Specifications` section OR `### 7.4 API` or similar\n- Contains API endpoint definitions (`POST /api/`, `GET /api/`, etc.)\n- Contains `Testing Strategy` section\n- Contains data model schemas\n\n**Detailed Indicators**:\n- Uses numbered sections (`## 1.`, `### 2.1`)\n- Contains `Technical Architecture` section\n- Contains user stories (`**US-001**:` or similar format)\n- Contains acceptance criteria\n\n**High-Level Indicators**:\n- Contains feature table with Priority column\n- Executive summary focus\n- No user stories or acceptance criteria\n- Shorter document (~50-100 lines)\n\n**Detection Priority**:\n1. If Full-Tech indicators found → Full-Tech\n2. Else if Detailed indicators found → Detailed\n3. Else if High-Level indicators found → High-Level\n4. Default → Detailed\n\n### Step 4: Check Settings\n\nCheck for settings at `.claude/prd-tools.local.md` to get:\n- Author name (if configured)\n- Any custom preferences\n\n### Step 5: Determine Report Path\n\nThe analysis report should be saved in the same directory as the PRD with `.analysis.md` suffix:\n\n- PRD: `specs/PRD-User-Auth.md`\n- Report: `specs/PRD-User-Auth.analysis.md`\n\nExtract the PRD filename and construct the report path.\n\n### Step 6: Launch Analyzer Agent\n\nLaunch the PRD Analyzer Agent using the Task tool with subagent_type `prd-tools:prd-analyzer`.\n\nProvide this context in the prompt:\n\n```\nAnalyze the PRD at: {prd_path}\n\nPRD Content:\n{full_prd_content}\n\nDetected Depth Level: {depth_level}\nReport Output Path: {report_path}\nAuthor: {author_from_settings or \"Not specified\"}\n\nInstructions:\n1. Load the analysis skill and reference files\n2. Perform systematic analysis based on the depth level\n3. Generate the analysis report\n4. Present findings summary\n5. Ask if user wants to enter update mode\n6. If yes, guide through interactive resolution\n7. Update report with final resolution status\n```\n\n### Step 7: Handoff Complete\n\nOnce you have launched the Analyzer Agent, your role is complete. The agent will handle:\n- Loading analysis criteria for the depth level\n- Performing comprehensive analysis\n- Generating and saving the report\n- Interactive update mode (if requested)\n- Updating the PRD with approved changes\n\n## Example Usage\n\n```\n/prd-tools:analyze specs/PRD-User-Authentication.md\n```\n\nThis will:\n1. Read the PRD at the specified path\n2. Detect it's a Detailed-level PRD\n3. Analyze for issues across all four categories\n4. Save report to `specs/PRD-User-Authentication.analysis.md`\n5. Offer interactive resolution mode\n\n## Notes\n\n- Always read the full PRD before launching the analyzer\n- Depth detection determines which criteria apply\n- Report is always saved alongside the PRD\n- The analyzer agent handles all user interaction for resolution\n",
        "plugins/prd-tools/commands/create-tasks.md": "---\ndescription: Generate Claude Code native Tasks from an existing PRD\nallowed_tools:\n  - AskUserQuestion\n  - Task\n  - Read\n  - Glob\n  - TaskList\narguments:\n  - name: prd-path\n    description: Path to the PRD file to analyze for task generation\n    required: true\n---\n\n# PRD to Tasks - Create Tasks Command\n\nYou are initiating the task generation workflow. This process reads an existing PRD and creates Claude Code native Tasks with dependencies, priorities, and metadata.\n\n## Workflow\n\n### Step 1: Validate PRD File\n\nVerify the PRD file exists at the provided path.\n\nIf the file is not found:\n1. Check if user provided a relative path\n2. Try common PRD locations:\n   - `specs/PRD-{name}.md`\n   - `docs/PRD-{name}.md`\n   - `{name}.md` in current directory\n3. Use Glob to search for similar filenames:\n   - `**/PRD*.md`\n   - `**/*prd*.md`\n   - `**/*requirements*.md`\n4. If multiple matches found, use AskUserQuestion to let user select\n5. If no matches found, inform user and ask for correct path\n\n### Step 2: Read PRD Content\n\nRead the entire PRD file using the Read tool.\n\nStore the full content for passing to the agent.\n\n### Step 3: Detect Depth Level\n\nAnalyze the PRD content to detect its depth level:\n\n**Full-Tech Indicators** (check first):\n- Contains `API Specifications` section OR `### 7.4 API` or similar\n- Contains API endpoint definitions (`POST /api/`, `GET /api/`, etc.)\n- Contains `Testing Strategy` section\n- Contains data model schemas with field definitions\n- Contains code examples or schema definitions\n\n**Detailed Indicators**:\n- Uses numbered sections (`## 1.`, `### 2.1`)\n- Contains `Technical Architecture` or `Technical Considerations` section\n- Contains user stories (`**US-001**:` or similar format)\n- Contains acceptance criteria (`- [ ]` checkboxes)\n- Contains feature prioritization (P0, P1, P2, P3)\n\n**High-Level Indicators**:\n- Contains feature table with Priority column\n- Executive summary focus (brief problem/solution)\n- No user stories or acceptance criteria\n- Shorter document (~50-100 lines)\n- Minimal technical details\n\n**Detection Priority**:\n1. If Full-Tech indicators found → Full-Tech\n2. Else if Detailed indicators found → Detailed\n3. Else if High-Level indicators found → High-Level\n4. Default → Detailed\n\n### Step 4: Check for Existing Tasks\n\nUse TaskList to check if there are existing tasks that reference this PRD.\n\nLook for tasks with `metadata.prd_path` matching the PRD path.\n\nIf existing tasks found:\n- Count them by status (pending, in_progress, completed)\n- Note their task_uids for merge mode\n- Inform user about merge behavior\n\nReport to user:\n```\nFound {n} existing tasks for this PRD:\n• {pending} pending\n• {in_progress} in progress\n• {completed} completed\n\nNew tasks will be merged. Completed tasks will be preserved.\n```\n\n### Step 5: Check Settings\n\nCheck for optional settings at `.claude/prd-tools.local.md`:\n- Author name (for attribution)\n- Any custom preferences\n\nThis is optional - proceed without settings if not found.\n\n### Step 6: Launch Task Generator Agent\n\nLaunch the task-generator agent using the Task tool with subagent_type `prd-tools:task-generator`.\n\nProvide this context in the prompt:\n\n```\nGenerate implementation tasks from the following PRD.\n\nPRD Path: {prd_path}\nDetected Depth Level: {depth_level}\n\n{If existing tasks found:}\nExisting Tasks for Merge:\n- {n} pending tasks\n- {n} in_progress tasks (preserve status)\n- {n} completed tasks (never modify)\n\nExisting task UIDs: {list of task_uids}\n\nPRD Content:\n---\n{full_prd_content}\n---\n\nInstructions:\n1. Load the task-generation skill and reference files\n2. Analyze the PRD structure and extract requirements\n3. Decompose features into atomic tasks following layer patterns\n4. Infer dependencies between tasks\n5. Present preview summary for user confirmation\n6. Create tasks using TaskCreate with proper metadata\n7. Set dependencies using TaskUpdate\n8. {If merge mode:} Merge with existing tasks, preserving completed status\n9. Report completion with recommended first tasks\n```\n\n### Step 7: Handoff Complete\n\nOnce you have launched the task-generator agent, your role is complete. The agent will handle:\n- Loading task generation knowledge\n- Analyzing PRD content\n- Decomposing into tasks\n- Inferring dependencies\n- Getting user confirmation\n- Creating native Tasks\n- Merging with existing tasks (if re-run)\n\n## Example Usage\n\n### Basic Usage\n```\n/prd-tools:create-tasks specs/PRD-User-Authentication.md\n```\n\n### With Relative Path\n```\n/prd-tools:create-tasks PRD-Payments.md\n```\n\n### Re-running (Merge Mode)\n```\n/prd-tools:create-tasks specs/PRD-User-Authentication.md\n```\nIf tasks already exist for this PRD, they will be intelligently merged.\n\n## Expected Output\n\nThe workflow will:\n1. Read and validate the PRD\n2. Detect depth level (Full-Tech/Detailed/High-Level)\n3. Show preview with task counts and priorities\n4. Ask for confirmation before creating\n5. Create Claude Code native Tasks\n6. Set up dependency relationships\n7. Report recommended first tasks to start\n\nAfter completion, use `TaskList` to view all created tasks.\n\n## Notes\n\n- Tasks are created using Claude Code's native task system (TaskCreate/TaskUpdate)\n- Each task includes metadata linking back to the source PRD\n- Dependencies are automatically inferred from layer relationships and PRD phases\n- Re-running on the same PRD merges intelligently (preserves completed tasks)\n- Task UIDs enable tracking across PRD updates\n",
        "plugins/prd-tools/commands/create.md": "---\ndescription: Create a new Product Requirements Document through an interactive interview process\nallowed_tools:\n  - AskUserQuestion\n  - Task\n  - Read\n  - Glob\n---\n\n# PRD Generator - Create Command\n\nYou are initiating the PRD creation workflow. This process will gather requirements through an interactive interview and generate a comprehensive Product Requirements Document.\n\n## Workflow\n\n### Step 1: Check for Settings\n\nFirst, check if there is a settings file at `.claude/prd-tools.local.md` to get any custom configuration like output path or author name.\n\n### Step 2: Gather Initial Information\n\nUse `AskUserQuestion` to gather the essential starting information with these four questions:\n\n**Question 1 - PRD Name:**\n- Header: \"PRD Name\"\n- Question: \"What would you like to name this PRD?\"\n- Options: Allow text input for a descriptive name\n\n**Question 2 - Type:**\n- Header: \"Type\"\n- Question: \"What type of product/feature is this?\"\n- Options:\n  - \"New product\" - A completely new product being built from scratch\n  - \"New feature\" - A new feature for an existing product\n\n**Question 3 - Depth:**\n- Header: \"Depth\"\n- Question: \"How detailed should the PRD be?\"\n- Options:\n  - \"High-level overview (Recommended)\" - Executive summary with key features and goals\n  - \"Detailed specifications\" - Standard PRD with acceptance criteria and phases\n  - \"Full technical documentation\" - Comprehensive specs with API definitions and data models\n\n**Question 4 - Description:**\n- Header: \"Description\"\n- Question: \"Briefly describe the product/feature and its key requirements\"\n- Options: Allow text input describing the problem, main features, and constraints\n\n### Step 3: Launch Interview Agent\n\nAfter receiving the initial responses, immediately launch the Interview Agent using the `Task` tool. Provide this context:\n\n- PRD Name: The name provided by the user\n- Product Type: \"New product\" or \"New feature\" based on selection\n- Depth Level: The selected depth option\n- Initial Description: The description provided\n- Output Path: From settings or default `specs/PRD-{name}.md`\n- Author: From settings or \"Not specified\"\n\nThe Interview Agent will:\n1. Conduct an adaptive interview based on the depth level\n2. Cover all four categories: Problem & Goals, Functional Requirements, Technical Specs, Implementation\n3. Present a summary for user confirmation before generating the PRD\n4. Generate the PRD using the appropriate template\n5. Write the PRD to the configured output path\n\n### Step 4: Handoff Complete\n\nOnce you have launched the Interview Agent, your role is complete. The agent will handle:\n- Conducting the interview rounds\n- Gathering detailed requirements\n- Presenting the summary for confirmation\n- Generating and saving the final PRD\n\n## Notes\n\n- Always check for settings file first to respect user configuration\n- Pass all gathered information to the Interview Agent\n- The Interview Agent handles all subsequent interaction\n",
        "plugins/prd-tools/skills/prd-analysis/SKILL.md": "---\ndescription: PRD analysis knowledge including depth-aware criteria, finding categories, severity guidelines, and common issue patterns\ntriggers:\n  - analyze PRD\n  - review PRD\n  - PRD quality check\n  - validate requirements\n  - audit PRD\n  - PRD analysis\n  - check PRD quality\n  - PRD review\n---\n\n# PRD Analysis Skill\n\nThis skill provides structured knowledge for analyzing existing Product Requirements Documents to identify quality issues and guide resolution.\n\n## Analysis Philosophy\n\n### Depth-Aware Analysis\n\nPRD analysis must respect the intended depth level of the document. A high-level PRD should not be flagged for missing API specifications, just as a full-tech PRD should be scrutinized for technical completeness.\n\n**Key Principle**: Only flag what's expected at the document's depth level.\n\n### Constructive Approach\n\nFindings should be:\n- **Actionable**: Clear recommendation for how to fix\n- **Specific**: Exact location and description of issue\n- **Prioritized**: Severity indicates importance\n- **Helpful**: Explain why this matters, not just what's wrong\n\n### Systematic Coverage\n\nAnalysis covers four distinct categories to ensure comprehensive review:\n1. **Inconsistencies**: Internal contradictions or mismatches\n2. **Missing Information**: Expected content that's absent\n3. **Ambiguities**: Unclear or vague statements\n4. **Structure Issues**: Formatting, organization, missing sections\n\n---\n\n## Finding Categories\n\n### 1. Inconsistencies\n\nIssues where the PRD contradicts itself or uses conflicting information.\n\n**What to Look For**:\n- Feature named differently in different sections\n- Priority mismatches (feature marked P2 but in Phase 1)\n- Metrics that don't align with stated goals\n- Contradictory requirements\n- Timeline/phase misalignment\n\n**Detection Strategy**:\n1. Build glossary of feature names from first mention\n2. Track priority assignments\n3. Map goals to metrics\n4. Compare requirements for conflicts\n\n### 2. Missing Information\n\nExpected content that is absent based on the PRD's depth level.\n\n**What to Look For**:\n- Required sections for depth level\n- Undefined technical terms\n- Features without acceptance criteria (detailed/full-tech)\n- Error scenarios not addressed\n- Dependencies not listed\n- Incomplete personas\n\n**Detection Strategy**:\n1. Compare against depth-level checklist\n2. Identify domain terms without definitions\n3. Check each feature for expected attributes\n4. Scan for external system references\n\n### 3. Ambiguities\n\nStatements that are unclear or could be interpreted multiple ways.\n\n**What to Look For**:\n- Vague quantifiers (\"fast\", \"many\", \"scalable\")\n- Undefined priority language (\"should\" vs \"must\")\n- Ambiguous pronouns (\"it\", \"this\", \"they\")\n- Open-ended lists (\"etc.\", \"and more\")\n- Undefined scope boundaries\n\n**Detection Strategy**:\n1. Flag quantifiers without numbers\n2. Check for RFC 2119 language consistency\n3. Identify pronouns with unclear antecedents\n4. Find incomplete enumerations\n\n### 4. Structure Issues\n\nProblems with document organization, formatting, or references.\n\n**What to Look For**:\n- Missing required sections\n- Content in wrong section\n- Inconsistent formatting\n- Orphaned references\n- Circular dependencies\n\n**Detection Strategy**:\n1. Verify all template sections exist\n2. Check content placement logic\n3. Validate formatting consistency\n4. Test all internal references\n\n---\n\n## Severity Levels\n\n### Critical\n\n**Definition**: Issues that would cause implementation to fail or go significantly wrong.\n\n**Assign When**:\n- Fundamental contradiction in requirements\n- Core requirement completely undefined\n- Required section missing entirely\n- Circular dependencies that block implementation\n- Security requirement absent (when security is mentioned)\n\n**Examples**:\n- \"User authentication required\" but no auth requirements defined\n- Feature A depends on Feature B, Feature B depends on Feature A\n- Full-tech PRD with no API specifications\n\n### Warning\n\n**Definition**: Issues that could cause confusion or implementation problems.\n\n**Assign When**:\n- Inconsistent naming that could cause misunderstanding\n- Acceptance criteria too vague to test\n- Important feature lacks error handling\n- Ambiguous language for significant functionality\n- Minor dependencies unlisted\n\n**Examples**:\n- \"Search should be fast\" without defining \"fast\"\n- User story without acceptance criteria\n- Integration mentioned but not in dependencies\n\n### Suggestion\n\n**Definition**: Improvements that would enhance PRD quality but aren't blocking.\n\n**Assign When**:\n- Style or clarity improvements\n- Non-critical sections could be clearer\n- Best practices not followed\n- Minor formatting inconsistencies\n- Documentation enhancements\n\n**Examples**:\n- User stories formatted inconsistently\n- Glossary would help but isn't critical\n- Additional context would be helpful\n\n---\n\n## Analysis Workflow\n\n### Step 1: Read and Detect Depth\n\n1. Read the entire PRD\n2. Detect depth level using indicators (see `references/analysis-criteria.md`)\n3. Note the detected depth for criteria selection\n\n### Step 2: Load Criteria\n\nLoad the appropriate checklist from `references/analysis-criteria.md` based on detected depth level.\n\n### Step 3: Systematic Scan\n\nAnalyze the PRD section by section:\n\n1. **Structure Scan**: Verify all required sections exist\n2. **Consistency Scan**: Build glossary, track priorities, map goals to metrics\n3. **Completeness Scan**: Check each feature for expected attributes\n4. **Clarity Scan**: Flag vague language and ambiguities\n\n### Step 4: Categorize and Prioritize\n\nFor each finding:\n1. Assign to one of four categories\n2. Determine severity based on impact\n3. Identify specific location (section, line)\n4. Draft recommendation\n\n### Step 5: Generate Report\n\nCreate report using `references/report-template.md`:\n1. Fill in header information\n2. Calculate summary statistics\n3. List findings by severity\n4. Write overall assessment\n\n---\n\n## Update Mode Workflow\n\nWhen entering update mode for interactive resolution:\n\n### Finding Presentation\n\nPresent each finding with:\n```\nFINDING X/Y (N resolved, M skipped)\n\nCategory: {category}\nSeverity: {severity}\nLocation: {section, line}\n\nCURRENT:\n{Quoted text from PRD}\n\nISSUE:\n{Clear explanation of the problem}\n\nPROPOSED:\n{Suggested fix text}\n\n[Apply] [Modify] [Skip]\n```\n\n### User Response Handling\n\n**Apply**:\n1. Use Edit tool to apply the proposed change\n2. Mark finding as \"Resolved\" in report\n3. Increment resolved counter\n4. Move to next finding\n\n**Modify**:\n1. Ask user for their preferred text via AskUserQuestion\n2. Apply their modified version\n3. Mark finding as \"Resolved\"\n4. Move to next finding\n\n**Skip**:\n1. Ask if they want to provide a reason (optional)\n2. Mark finding as \"Skipped\" with reason if provided\n3. Increment skipped counter\n4. Move to next finding\n\n### Session Completion\n\nAfter all findings processed:\n1. Update report with Resolution Summary\n2. Show final statistics\n3. List resolved and skipped findings\n4. Provide recommendations for future PRDs\n\n---\n\n## Reference Files\n\n- `references/analysis-criteria.md` - Depth-specific checklists and detection algorithms\n- `references/report-template.md` - Standard report format\n- `references/common-issues.md` - Issue pattern library with examples\n",
        "plugins/prd-tools/skills/prd-analysis/references/analysis-criteria.md": "# PRD Analysis Criteria\n\nThis reference provides depth-aware checklists for analyzing PRDs at each detail level.\n\n## Depth Level Detection\n\nDetect the PRD depth level from its content using these indicators:\n\n| Indicator | High-Level | Detailed | Full-Tech |\n|-----------|------------|----------|-----------|\n| Numbered sections (`## 1.`, `### 2.1`) | No | Yes | Yes |\n| `## 7. Technical Architecture` or similar | No | Yes | Yes |\n| `### 7.4 API Specifications` or similar | No | No | Yes |\n| `## 10. Testing Strategy` section | No | No | Yes |\n| API endpoint definitions (`POST /api/`, `GET /api/`) | No | Maybe | Yes |\n| Feature table with Priority column | Yes | No | No |\n| User stories (`**US-001**:` or similar) | No | Yes | Yes |\n| Data model schemas | No | Maybe | Yes |\n| Performance SLAs with specific numbers | No | Maybe | Yes |\n\n### Detection Algorithm\n\n1. Search for `API Specifications` section OR detailed endpoint definitions (`POST /api/`, `GET /api/` patterns) → **FULL-TECH**\n2. Search for numbered sections AND `Technical Architecture` section → **DETAILED**\n3. Search for Feature/Priority table OR executive summary focus → **HIGH-LEVEL**\n4. Default: **DETAILED**\n\n---\n\n## High-Level Overview Checklist\n\nFor PRDs using the high-level template, verify these sections:\n\n### Executive Summary\n- [ ] Clear one-paragraph overview exists\n- [ ] Problem being solved is stated\n- [ ] Target audience is identified\n- [ ] Success metrics are mentioned (even if high-level)\n\n### Problem Statement\n- [ ] Problem is clearly articulated\n- [ ] Impact of the problem is described\n- [ ] Current state/pain points are explained\n\n### Key Features\n- [ ] Features are listed with priorities\n- [ ] Each feature has a brief description\n- [ ] Priority levels are consistent (P0-P3 or similar)\n- [ ] At least one P0/Critical feature exists\n\n### Success Metrics\n- [ ] 2-4 measurable metrics are defined\n- [ ] Metrics relate to stated problem\n- [ ] Baseline values mentioned (or acknowledged as TBD)\n\n### Implementation Phases\n- [ ] At least 2 phases are defined\n- [ ] Each phase has clear deliverables\n- [ ] Phase 1 focuses on core/critical features\n\n### Risks & Dependencies\n- [ ] At least 2-3 risks identified\n- [ ] External dependencies listed\n- [ ] Mitigation strategies suggested\n\n### Quality Standards (What NOT to Flag)\n- Do NOT flag missing user stories (not expected at this level)\n- Do NOT flag missing API specs\n- Do NOT flag missing data models\n- Do NOT flag missing acceptance criteria on individual features\n\n---\n\n## Detailed Specifications Checklist\n\nFor PRDs using the detailed template, verify all high-level items plus:\n\n### User Personas\n- [ ] At least one primary persona defined\n- [ ] Persona includes goals and pain points\n- [ ] Persona is specific, not generic\n\n### User Stories\n- [ ] Stories follow \"As a... I want... So that...\" format\n- [ ] Each story has unique identifier (US-001, etc.)\n- [ ] Stories cover main feature areas\n- [ ] Stories have acceptance criteria\n\n### Acceptance Criteria\n- [ ] Each major feature has acceptance criteria\n- [ ] Criteria are testable (not vague)\n- [ ] Include success and failure scenarios\n\n### Technical Constraints\n- [ ] Tech stack requirements mentioned\n- [ ] Integration points identified\n- [ ] Performance expectations stated\n\n### Non-Functional Requirements\n- [ ] Security requirements outlined\n- [ ] Performance requirements stated\n- [ ] Scalability considerations mentioned\n\n### Quality Standards (What NOT to Flag)\n- Do NOT flag missing API endpoint details\n- Do NOT flag missing database schemas\n- Do NOT flag missing deployment architecture\n- Do NOT flag vague technical specs (expected at this level)\n\n---\n\n## Full Technical Documentation Checklist\n\nFor PRDs using the full-tech template, verify all detailed items plus:\n\n### System Architecture\n- [ ] Architecture diagram or clear description exists\n- [ ] Component interactions defined\n- [ ] Data flow explained\n\n### API Specifications\n- [ ] Endpoints defined with HTTP methods\n- [ ] Request/response schemas included\n- [ ] Error codes and handling specified\n- [ ] Authentication requirements stated\n\n### Data Models\n- [ ] Key entities defined\n- [ ] Relationships documented\n- [ ] Required fields identified\n- [ ] Data types specified\n\n### Performance SLAs\n- [ ] Response time targets specified\n- [ ] Throughput requirements stated\n- [ ] Availability targets defined (e.g., 99.9%)\n\n### Testing Strategy\n- [ ] Unit testing approach defined\n- [ ] Integration testing requirements\n- [ ] Performance testing criteria\n\n### Deployment Plan\n- [ ] Deployment strategy outlined\n- [ ] Rollback procedures mentioned\n- [ ] Environment requirements specified\n\n---\n\n## Cross-Depth Quality Checks\n\nThese apply regardless of depth level:\n\n### Internal Consistency\n- [ ] Feature names used consistently throughout\n- [ ] Priority levels consistent across sections\n- [ ] Phase assignments match feature priorities\n- [ ] Metrics align with stated goals\n\n### Completeness Indicators\n- [ ] No \"TBD\" items in critical sections\n- [ ] References to external docs are accessible\n- [ ] Out-of-scope items clearly defined\n\n### Measurability\n- [ ] Success metrics are quantifiable\n- [ ] Acceptance criteria are verifiable\n- [ ] Performance targets are specific\n\n### Clarity\n- [ ] No ambiguous terms without definitions\n- [ ] No contradicting statements\n- [ ] Dependencies are clearly stated\n\n---\n\n## Completeness Thresholds\n\nMinimum requirements for PRD quality:\n\n| Depth Level | Min Sections | Min Features | Min User Stories | Min Metrics |\n|-------------|--------------|--------------|------------------|-------------|\n| High-Level | 5 | 3 | 0 | 2 |\n| Detailed | 8 | 5 | 5 | 3 |\n| Full-Tech | 12 | 5 | 8 | 4 |\n\nIf a PRD falls below these thresholds, flag as Critical finding.\n",
        "plugins/prd-tools/skills/prd-analysis/references/common-issues.md": "# Common PRD Issues Pattern Library\n\nThis reference catalogs frequently occurring issues in PRDs with detection patterns and examples.\n\n---\n\n## Inconsistencies\n\n### INC-01: Feature Name Mismatch\n\n**Pattern**: Same feature referred to by different names in different sections.\n\n**Detection**:\n- Build list of feature names from Key Features section\n- Search for variations (plural/singular, abbreviations, synonyms)\n- Flag when same concept has multiple names\n\n**Example**:\n- Key Features: \"User Authentication\"\n- User Stories: \"Login System\"\n- Technical Specs: \"Auth Module\"\n\n**Fix**: Standardize on one name throughout the document.\n\n---\n\n### INC-02: Priority Inconsistency\n\n**Pattern**: Feature priority differs between sections.\n\n**Detection**:\n- Extract priorities from feature list\n- Compare with priorities in user stories\n- Compare with phase assignments (P0 should be Phase 1)\n\n**Example**:\n- Feature \"Export\" marked P2 in features table\n- Same feature in \"Phase 1\" deliverables\n\n**Fix**: Align priority across all mentions, or clarify phase assignment rationale.\n\n---\n\n### INC-03: Metric-Goal Mismatch\n\n**Pattern**: Success metrics don't measure stated goals.\n\n**Detection**:\n- Extract goals from Problem Statement\n- Extract metrics from Success Metrics section\n- Verify each goal has at least one related metric\n\n**Example**:\n- Goal: \"Reduce customer support tickets\"\n- Metrics: \"Page load time\", \"User signups\"\n- Missing: Metric for support ticket reduction\n\n**Fix**: Add metrics that directly measure each stated goal.\n\n---\n\n### INC-04: Contradictory Requirements\n\n**Pattern**: Two requirements that cannot both be true.\n\n**Detection**:\n- Look for conflicting constraints\n- Check performance vs. feature requirements\n- Verify security vs. usability trade-offs are addressed\n\n**Example**:\n- \"All data must be encrypted at rest\"\n- \"System must support full-text search on encrypted fields\"\n- (Contradiction: full-text search typically requires unencrypted indexes)\n\n**Fix**: Clarify constraints or acknowledge trade-off with solution.\n\n---\n\n## Missing Information\n\n### MISS-01: Undefined Terms\n\n**Pattern**: Domain-specific terms used without definition.\n\n**Detection**:\n- Identify technical or business jargon\n- Check for glossary or inline definitions\n- Flag terms that non-domain experts wouldn't understand\n\n**Example**:\n- \"The system will use CQRS pattern\" (What is CQRS?)\n- \"Support for SSO via SAML\" (Acronyms unexplained)\n\n**Fix**: Add glossary section or inline definitions.\n\n---\n\n### MISS-02: Missing Acceptance Criteria\n\n**Pattern**: Features or user stories lack testable criteria.\n\n**Detection**:\n- Check each feature/story for acceptance criteria\n- Verify criteria are specific and testable\n- Flag vague criteria (\"works correctly\", \"is fast\")\n\n**Example**:\n- User Story: \"As a user, I want to search products\"\n- Missing: What constitutes a successful search? Filters? Sort options?\n\n**Fix**: Add specific, testable acceptance criteria.\n\n---\n\n### MISS-03: Unspecified Error Handling\n\n**Pattern**: Happy path defined but error scenarios missing.\n\n**Detection**:\n- Look for error handling requirements\n- Check API specs for error responses\n- Verify edge cases are addressed\n\n**Example**:\n- \"User can upload profile photo\"\n- Missing: What if file too large? Wrong format? Upload fails?\n\n**Fix**: Add error scenarios and expected behavior.\n\n---\n\n### MISS-04: Missing Dependencies\n\n**Pattern**: External systems referenced but dependencies not listed.\n\n**Detection**:\n- Scan for mentions of external systems/APIs\n- Compare with Dependencies section\n- Flag missing external dependencies\n\n**Example**:\n- \"Integrate with Stripe for payments\"\n- Dependencies section: No mention of Stripe\n\n**Fix**: Add all external dependencies with version requirements.\n\n---\n\n### MISS-05: Incomplete User Personas\n\n**Pattern**: Personas mentioned but not fully defined.\n\n**Detection**:\n- Check if personas have: name, role, goals, pain points\n- Verify personas are referenced in user stories\n- Flag \"placeholder\" personas\n\n**Example**:\n- \"Admin users\" mentioned in features\n- No Admin persona defined with specific needs\n\n**Fix**: Define complete personas for each user type.\n\n---\n\n## Ambiguities\n\n### AMB-01: Vague Quantifiers\n\n**Pattern**: Non-specific terms used where numbers are needed.\n\n**Detection**: Look for these words without specific values:\n- \"fast\", \"quickly\", \"responsive\"\n- \"many\", \"few\", \"several\"\n- \"large\", \"small\", \"scalable\"\n- \"easy\", \"simple\", \"intuitive\"\n\n**Example**:\n- \"The system should load quickly\" (How quickly?)\n- \"Support many concurrent users\" (How many?)\n\n**Fix**: Replace with specific, measurable values.\n\n---\n\n### AMB-02: Undefined \"Should\" vs \"Must\"\n\n**Pattern**: Unclear requirement priority in language.\n\n**Detection**:\n- Check for consistent use of RFC 2119 language\n- Flag mixed usage without definition\n- Identify requirements using \"should\" for critical features\n\n**Example**:\n- \"The system should encrypt all passwords\" (Is this optional?)\n- \"Users must be able to login\" (Required)\n\n**Fix**: Use consistent RFC 2119 language (MUST, SHOULD, MAY) with definitions.\n\n---\n\n### AMB-03: Ambiguous Pronouns\n\n**Pattern**: Unclear referents for \"it\", \"this\", \"that\", \"they\".\n\n**Detection**:\n- Find pronouns that could refer to multiple antecedents\n- Flag long sentences with unclear references\n\n**Example**:\n- \"When the user submits the form and the system processes it, it should notify them.\"\n- (Which \"it\"? Form or system? Who are \"them\"?)\n\n**Fix**: Replace pronouns with specific nouns.\n\n---\n\n### AMB-04: Open-Ended Lists\n\n**Pattern**: Lists with \"etc.\", \"and more\", \"such as\" without bounds.\n\n**Detection**:\n- Find incomplete lists\n- Flag unbounded requirements\n\n**Example**:\n- \"Support file types: PDF, DOC, images, etc.\"\n- (What specific image formats? What else is included in \"etc.\"?)\n\n**Fix**: Provide exhaustive list or explicit bounds.\n\n---\n\n### AMB-05: Undefined Scope Boundaries\n\n**Pattern**: Features described without clear limits.\n\n**Detection**:\n- Look for features without \"out of scope\" clarification\n- Flag features that could expand indefinitely\n\n**Example**:\n- \"Support search with filters\"\n- (Which filters? All possible filters? User-defined filters?)\n\n**Fix**: Define explicit scope with \"in scope\" and \"out of scope\" lists.\n\n---\n\n## Structure Issues\n\n### STRUCT-01: Missing Required Section\n\n**Pattern**: Expected section for depth level is absent.\n\n**Detection**:\n- Compare document structure to template\n- Flag missing required sections for depth level\n\n**Example**:\n- Full-Tech PRD missing \"API Specifications\" section\n- Detailed PRD missing \"User Stories\" section\n\n**Fix**: Add missing section with appropriate content.\n\n---\n\n### STRUCT-02: Section Misplacement\n\n**Pattern**: Content in wrong section.\n\n**Detection**:\n- Identify content that belongs in different section\n- Flag technical details in business sections\n- Flag user stories in technical sections\n\n**Example**:\n- API endpoints listed in \"Problem Statement\"\n- Business metrics in \"Technical Architecture\"\n\n**Fix**: Move content to appropriate section.\n\n---\n\n### STRUCT-03: Inconsistent Formatting\n\n**Pattern**: Similar items formatted differently.\n\n**Detection**:\n- Check user story format consistency\n- Check requirement ID format\n- Check heading hierarchy\n\n**Example**:\n- Some user stories: \"As a user, I want...\"\n- Other stories: \"User should be able to...\"\n\n**Fix**: Standardize formatting across all similar items.\n\n---\n\n### STRUCT-04: Orphaned References\n\n**Pattern**: References to non-existent sections or documents.\n\n**Detection**:\n- Find internal references (see Section X, refer to Y)\n- Verify referenced sections/documents exist\n\n**Example**:\n- \"See Security Requirements in Section 8\"\n- Section 8 doesn't exist or covers different topic\n\n**Fix**: Update references or add missing sections.\n\n---\n\n### STRUCT-05: Circular Dependencies\n\n**Pattern**: Tasks or features depend on each other.\n\n**Detection**:\n- Map feature dependencies\n- Identify circular references in phases\n\n**Example**:\n- Feature A requires Feature B to be complete\n- Feature B requires Feature A to be complete\n\n**Fix**: Identify minimum viable version of one to break cycle.\n\n---\n\n## Severity Assignment Guidelines\n\n### Critical (Must Fix)\n\nAssign Critical when the issue:\n- Would cause implementation to fail or go significantly wrong\n- Represents a fundamental contradiction\n- Leaves a core requirement completely undefined\n- Missing required section for the depth level\n\n### Warning (Should Fix)\n\nAssign Warning when the issue:\n- Could cause confusion during implementation\n- Represents incomplete but not missing information\n- Uses ambiguous language for important features\n- Minor inconsistency that could compound\n\n### Suggestion (Nice to Fix)\n\nAssign Suggestion when the issue:\n- Is a style or clarity improvement\n- Affects non-critical sections\n- Would improve PRD quality but isn't blocking\n- Represents best practice not currently followed\n",
        "plugins/prd-tools/skills/prd-analysis/references/report-template.md": "# PRD Analysis Report Template\n\nUse this template when generating analysis reports.\n\n---\n\n```markdown\n# PRD Analysis Report: {PRD Name}\n\n**Analyzed**: {YYYY-MM-DD HH:MM}\n**PRD Path**: {path/to/prd.md}\n**Detected Depth Level**: {High-Level | Detailed | Full-Tech}\n**Status**: {Initial | Updated after review}\n\n---\n\n## Summary\n\n| Category | Critical | Warning | Suggestion | Total |\n|----------|----------|---------|------------|-------|\n| Inconsistencies | 0 | 0 | 0 | 0 |\n| Missing Information | 0 | 0 | 0 | 0 |\n| Ambiguities | 0 | 0 | 0 | 0 |\n| Structure Issues | 0 | 0 | 0 | 0 |\n| **Total** | **0** | **0** | **0** | **0** |\n\n### Overall Assessment\n\n{1-2 sentence summary of PRD quality and main areas for improvement}\n\n---\n\n## Findings\n\n### Critical\n\n{If no critical findings, write: \"No critical findings.\"}\n\n#### FIND-001: {Finding Title}\n\n- **Category**: {Inconsistencies | Missing Information | Ambiguities | Structure Issues}\n- **Location**: Section {X.Y} \"{Section Name}\" (line {N})\n- **Issue**: {Clear description of what's wrong}\n- **Impact**: {Why this matters}\n- **Recommendation**: {Specific action to resolve}\n- **Status**: {Pending | Resolved | Skipped}\n- **Skip Reason**: {Only if skipped - reason provided by user}\n\n---\n\n### Warnings\n\n{If no warnings, write: \"No warnings.\"}\n\n#### FIND-002: {Finding Title}\n\n- **Category**: {Category}\n- **Location**: Section {X.Y} (line {N})\n- **Issue**: {Description}\n- **Recommendation**: {Action}\n- **Status**: {Pending | Resolved | Skipped}\n\n---\n\n### Suggestions\n\n{If no suggestions, write: \"No suggestions.\"}\n\n#### FIND-003: {Finding Title}\n\n- **Category**: {Category}\n- **Location**: Section {X.Y} (line {N})\n- **Issue**: {Description}\n- **Recommendation**: {Action}\n- **Status**: {Pending | Resolved | Skipped}\n\n---\n\n## Resolution Summary\n\n*(This section is added/updated after interactive review)*\n\n**Review Session**: {YYYY-MM-DD HH:MM}\n\n| Metric | Count |\n|--------|-------|\n| Total Findings | {N} |\n| Resolved | {N} |\n| Skipped | {N} |\n| Remaining | {N} |\n\n### Resolved Findings\n\n{List of finding IDs and brief resolution notes}\n\n### Skipped Findings\n\n{List of finding IDs with skip reasons}\n\n### Recommendations for Future\n\n{Any patterns or areas to focus on for future PRDs}\n\n---\n\n## Analysis Methodology\n\nThis analysis was performed using depth-aware criteria for {Depth Level} PRDs:\n\n- **Sections Checked**: {List main sections analyzed}\n- **Criteria Applied**: {Brief description of what was evaluated}\n- **Out of Scope**: {What was intentionally not checked due to depth level}\n```\n\n---\n\n## Template Usage Notes\n\n### Finding ID Format\n\nUse sequential IDs: `FIND-001`, `FIND-002`, etc.\n\n### Location Format\n\nSpecify location as precisely as possible:\n- For numbered sections: `Section 3.2 \"User Stories\" (line 145)`\n- For unnumbered: `\"Success Metrics\" section (line 67)`\n- For specific content: `Feature \"Search\" in Key Features table (line 34)`\n\n### Status Values\n\n- **Pending**: Not yet addressed\n- **Resolved**: User approved fix and it was applied\n- **Skipped**: User chose to skip (include reason if provided)\n\n### Impact Guidelines\n\nDescribe impact in terms of:\n- What problems it could cause if not fixed\n- Who would be affected (developers, stakeholders, users)\n- How it might lead to implementation issues\n",
        "plugins/prd-tools/skills/prd-generation/SKILL.md": "---\ndescription: PRD generation knowledge, templates, and compilation guidance for creating AI-optimized Product Requirements Documents\ntriggers:\n  - compile PRD\n  - generate PRD\n  - create product requirements document\n  - PRD template\n  - finalize requirements\n  - write PRD\n---\n\n# PRD Generation Skill\n\nThis skill provides structured knowledge for creating comprehensive, AI-optimized Product Requirements Documents.\n\n## Core Principles\n\n### 1. Phase-Based Milestones (Not Timelines)\n\nPRDs should define clear phases with completion criteria rather than time estimates:\n\n- **Phase 1: Foundation** - Core infrastructure and data models\n- **Phase 2: Core Features** - Primary user-facing functionality\n- **Phase 3: Enhancement** - Secondary features and optimizations\n- **Phase 4: Polish** - UX refinement, edge cases, documentation\n\n### 2. Testable Requirements\n\nEvery requirement should include:\n- **Clear acceptance criteria** - Specific, measurable conditions for completion\n- **Test scenarios** - How to verify the requirement is met\n- **Edge cases** - Known boundary conditions to handle\n\n### 3. Human Checkpoint Gates\n\nDefine explicit points where human review is required:\n- Architecture decisions before implementation begins\n- API contract review before integration work\n- Security review before authentication/authorization features\n- UX review before user-facing changes ship\n\n### 4. Context for AI Consumption\n\nStructure PRDs for optimal AI assistant consumption:\n- Use consistent heading hierarchy\n- Include code examples where applicable\n- Reference existing patterns in the codebase\n- Provide clear file location guidance\n\n## Template Selection\n\nChoose the appropriate template based on depth level:\n\n| Depth Level | Template | Use Case |\n|-------------|----------|----------|\n| High-level overview | `template-high-level.md` | Executive summaries, stakeholder alignment, initial scoping |\n| Detailed specifications | `template-detailed.md` | Standard development PRDs with clear requirements |\n| Full technical documentation | `template-full-tech.md` | Complex features requiring API specs, data models, architecture |\n\n## PRD Compilation Process\n\nWhen compiling a PRD from gathered requirements:\n\n1. **Select template** based on requested depth level\n2. **Organize information** into template sections\n3. **Fill gaps** by inferring logical requirements (flag assumptions clearly)\n4. **Add acceptance criteria** for each functional requirement\n5. **Define phases** with clear completion criteria\n6. **Insert checkpoint gates** at critical decision points\n7. **Review for completeness** before presenting to user\n\n## Writing Guidelines\n\n### Requirement Formatting\n\n```markdown\n### REQ-001: [Requirement Name]\n\n**Priority**: P0 (Critical) | P1 (High) | P2 (Medium) | P3 (Low)\n\n**Description**: Clear, concise statement of what is needed.\n\n**Acceptance Criteria**:\n- [ ] Criterion 1\n- [ ] Criterion 2\n\n**Notes**: Any additional context or constraints.\n```\n\n### User Story Format\n\n```markdown\n**As a** [user type]\n**I want** [capability]\n**So that** [benefit/value]\n```\n\n### API Specification Format (Full Tech Only)\n\n```markdown\n#### Endpoint: `METHOD /path`\n\n**Purpose**: Brief description\n\n**Request**:\n- Headers: `Content-Type: application/json`\n- Body:\n  ```json\n  {\n    \"field\": \"type - description\"\n  }\n  ```\n\n**Response**:\n- `200 OK`: Success response schema\n- `400 Bad Request`: Validation errors\n- `401 Unauthorized`: Authentication required\n```\n\n## Reference Files\n\n- `references/template-high-level.md` - Streamlined executive overview template\n- `references/template-detailed.md` - Standard PRD template with all sections\n- `references/template-full-tech.md` - Extended template with technical specifications\n- `references/interview-questions.md` - Question bank for requirement gathering\n",
        "plugins/prd-tools/skills/prd-generation/references/interview-questions.md": "# PRD Interview Question Bank\n\nThis document contains questions organized by category and depth level for gathering PRD requirements.\n\n## Category 1: Problem & Goals\n\n### High-Level Questions (All Depths)\n\n1. **What problem are you trying to solve?**\n   - Follow-up: Who experiences this problem most acutely?\n\n2. **What does success look like for this product/feature?**\n   - Follow-up: How will you measure success?\n\n3. **Who are the primary users of this product/feature?**\n   - Follow-up: What are their main goals and pain points?\n\n4. **Why is this important to build now?**\n   - Follow-up: What's the cost of not solving this problem?\n\n### Detailed Questions (Detailed & Full Tech)\n\n5. **What specific metrics will indicate success?**\n   - Follow-up: What are the current baselines for these metrics?\n   - Follow-up: What are your target values?\n\n6. **Are there secondary user personas we should consider?**\n   - Follow-up: How do their needs differ from primary users?\n\n7. **What business value does this deliver?**\n   - Follow-up: How does this align with company/team strategy?\n\n8. **What's the current user journey, and how will this change it?**\n\n### Deep-Dive Questions (Full Tech Only)\n\n9. **What quantitative data supports this problem statement?**\n   - Follow-up: Any user research, analytics, or support tickets?\n\n10. **What competitive solutions exist, and how will yours differ?**\n\n11. **What are the leading indicators vs lagging indicators for success?**\n\n---\n\n## Category 2: Functional Requirements\n\n### High-Level Questions (All Depths)\n\n1. **What are the must-have features for the initial release?**\n   - Follow-up: Which of these is the single most important?\n\n2. **Can you describe the main user workflow or interaction?**\n\n3. **What should users be able to do that they can't do today?**\n\n4. **Are there any features that are explicitly out of scope?**\n\n### Detailed Questions (Detailed & Full Tech)\n\n5. **For each key feature, what does \"done\" look like?**\n   - Follow-up: What are the acceptance criteria?\n\n6. **What edge cases should we handle?**\n   - Follow-up: What happens when things go wrong?\n\n7. **Are there different user roles with different permissions?**\n   - Follow-up: What can each role do?\n\n8. **What notifications or feedback should users receive?**\n\n9. **How should errors be presented to users?**\n\n10. **Are there any workflows that require multiple steps or confirmations?**\n\n### Deep-Dive Questions (Full Tech Only)\n\n11. **Can you walk through each feature step-by-step?**\n    - Follow-up: What's the happy path?\n    - Follow-up: What are all the error states?\n\n12. **What validation rules apply to user inputs?**\n\n13. **Are there any real-time or time-sensitive requirements?**\n\n14. **What offline or degraded mode behaviors are needed?**\n\n15. **Are there any batch processing or background job requirements?**\n\n---\n\n## Category 3: Technical Specifications\n\n### High-Level Questions (All Depths)\n\n1. **Do you have any technology preferences or constraints?**\n\n2. **Are there existing systems this needs to integrate with?**\n\n3. **Are there any known performance requirements?**\n\n### Detailed Questions (Detailed & Full Tech)\n\n4. **What's the expected scale (users, data volume, requests)?**\n   - Follow-up: How might this grow over time?\n\n5. **Are there any security or compliance requirements?**\n   - Follow-up: Data privacy considerations? (GDPR, HIPAA, etc.)\n\n6. **What existing infrastructure or services should we leverage?**\n\n7. **Are there any third-party APIs or services involved?**\n   - Follow-up: What are their limitations or costs?\n\n8. **What authentication/authorization approach should be used?**\n\n### Deep-Dive Questions (Full Tech Only)\n\n9. **What data entities are needed?**\n   - Follow-up: What are the relationships between them?\n   - Follow-up: What fields does each entity need?\n\n10. **What API endpoints will be required?**\n    - Follow-up: What are the request/response formats?\n    - Follow-up: What are the error responses?\n\n11. **What are the performance SLAs?**\n    - Follow-up: Response time requirements (P50, P99)?\n    - Follow-up: Throughput requirements?\n    - Follow-up: Availability requirements?\n\n12. **How should the system handle failures?**\n    - Follow-up: Retry strategies?\n    - Follow-up: Circuit breaker patterns?\n    - Follow-up: Fallback behaviors?\n\n13. **What caching strategy should be used?**\n\n14. **What monitoring and alerting is needed?**\n    - Follow-up: Key metrics to track?\n    - Follow-up: Alert thresholds?\n\n15. **Are there any data migration requirements?**\n\n16. **What's the deployment strategy?**\n    - Follow-up: Feature flags needed?\n    - Follow-up: Rollback plan?\n\n---\n\n## Category 4: Implementation Planning\n\n### High-Level Questions (All Depths)\n\n1. **What are the major milestones or phases?**\n\n2. **Are there any hard dependencies or blockers?**\n\n3. **What are the biggest risks to this project?**\n\n### Detailed Questions (Detailed & Full Tech)\n\n4. **What needs to be completed before work can begin?**\n   - Follow-up: Any approvals needed?\n   - Follow-up: Any prerequisite work?\n\n5. **Are there other teams we need to coordinate with?**\n   - Follow-up: What do we need from them?\n\n6. **What could go wrong, and how would we mitigate it?**\n\n7. **Are there any decisions that need to be made before implementation?**\n\n8. **What checkpoint reviews are needed during implementation?**\n   - Follow-up: Who needs to be involved in reviews?\n\n### Deep-Dive Questions (Full Tech Only)\n\n9. **What's the logical order of implementation?**\n   - Follow-up: What can be parallelized?\n\n10. **What technical spikes or research are needed first?**\n\n11. **Are there any proof-of-concept validations needed?**\n\n12. **What documentation needs to be created?**\n    - Follow-up: API documentation?\n    - Follow-up: Architecture diagrams?\n    - Follow-up: Runbooks?\n\n13. **What testing strategy is appropriate?**\n    - Follow-up: Unit test coverage targets?\n    - Follow-up: Integration test scope?\n    - Follow-up: Performance test requirements?\n\n14. **How will we handle backwards compatibility?**\n\n15. **What training or communication is needed for launch?**\n\n---\n\n## Adaptive Question Strategies\n\n### When User Says \"No Preference\"\n- Skip related technical detail questions\n- Focus on functional requirements instead\n- Note that technical decisions will be made during implementation\n\n### When User Indicates Area is Important\n- Probe deeper with follow-up questions\n- Ask for specific examples\n- Request quantitative requirements where applicable\n\n### When User is Unsure\n- Offer common options/patterns as examples\n- Suggest industry best practices via the recommendation system\n- Consider proactive research for compliance or complex topics\n- Mark as open question to resolve later if user defers decision\n\n**Connecting to Recommendations:**\n\nWhen a user expresses uncertainty, this is an opportunity to offer proactive recommendations:\n\n1. **Trigger phrases**: \"I'm not sure\", \"what do you recommend?\", \"what's standard?\", \"what do others do?\"\n2. **Response approach**:\n   - Offer a brief best-practice recommendation as an inline insight\n   - If the topic is complex (compliance, architecture), consider proactive research\n   - Present options using `AskUserQuestion` with clear trade-offs\n3. **Example flow**:\n   ```\n   User: \"I'm not sure what authentication approach to use\"\n\n   Agent: [Detects auth trigger + uncertainty]\n   Agent: [Offers inline insight via AskUserQuestion]\n   \"For public-facing apps, OAuth 2.0 with PKCE is the recommended approach.\n    Would you like to include this in the PRD?\"\n   Options: Include this | Tell me more | Skip\n   ```\n\n**See also:** `recommendation-triggers.md` for trigger patterns and `recommendation-format.md` for presentation templates.\n\n### When Building Feature for Existing Product\n- Ask about existing patterns to follow\n- Explore codebase for relevant context\n- Identify integration points early\n\n---\n\n## Round Structure by Depth\n\n### High-Level Overview (2-3 rounds)\n- **Round 1**: Problem, goals, key users, must-have features\n- **Round 2**: Success metrics, scope boundaries, major risks\n- **Round 3** (if needed): Clarifications and open questions\n\n### Detailed Specifications (3-4 rounds)\n- **Round 1**: Problem deep-dive, user personas, success metrics\n- **Round 2**: Feature breakdown, acceptance criteria, user workflows\n- **Round 3**: Technical constraints, integrations, dependencies\n- **Round 4**: Implementation phases, risks, open questions\n\n### Full Technical Documentation (4-5 rounds)\n- **Round 1**: Problem analysis, business value, user research\n- **Round 2**: Detailed features, edge cases, error handling\n- **Round 3**: Architecture, data models, API specifications\n- **Round 4**: Performance, security, scalability requirements\n- **Round 5**: Implementation plan, testing strategy, deployment\n\n---\n\n## Summary Checklist\n\nBefore compiling PRD, ensure you have gathered:\n\n### All Depths\n- [ ] Clear problem statement\n- [ ] Success metrics defined\n- [ ] Primary user persona identified\n- [ ] Must-have features listed\n- [ ] Scope boundaries (in/out) defined\n- [ ] Major risks identified\n\n### Detailed & Full Tech\n- [ ] All features have acceptance criteria\n- [ ] User workflows documented\n- [ ] Technical constraints captured\n- [ ] Dependencies identified\n- [ ] Implementation phases defined\n\n### Full Tech Only\n- [ ] Data models specified\n- [ ] API endpoints defined\n- [ ] Performance requirements quantified\n- [ ] Security requirements documented\n- [ ] Testing strategy outlined\n- [ ] Deployment plan created\n",
        "plugins/prd-tools/skills/prd-generation/references/recommendation-format.md": "# Recommendation Format Templates\n\nThis document provides templates for presenting recommendations during PRD interviews using the AskUserQuestion tool.\n\n## Inline Insight Template\n\nUse this during interview rounds when a trigger is detected. Keep it brief and non-intrusive.\n\n```yaml\nAskUserQuestion:\n  questions:\n    - header: \"Quick Insight\"\n      question: \"{Brief recommendation in 1-2 sentences}. Would you like to include this in the PRD?\"\n      options:\n        - label: \"Include this\"\n          description: \"Add to PRD requirements\"\n        - label: \"Tell me more\"\n          description: \"Get more details before deciding\"\n        - label: \"Skip\"\n          description: \"Continue without this recommendation\"\n      multiSelect: false\n```\n\n### Example: Authentication Insight\n\n```yaml\nAskUserQuestion:\n  questions:\n    - header: \"Quick Insight\"\n      question: \"For public-facing apps with user accounts, OAuth 2.0 with PKCE is the recommended approach - it provides secure token refresh without exposing client secrets. Would you like to include this in the PRD?\"\n      options:\n        - label: \"Include this\"\n          description: \"Add OAuth 2.0 with PKCE as auth requirement\"\n        - label: \"Tell me more\"\n          description: \"Explain the security benefits\"\n        - label: \"Skip\"\n          description: \"I'll decide on auth approach later\"\n      multiSelect: false\n```\n\n---\n\n## Recommendations Round Template\n\nUse this for the dedicated recommendations round, presenting 3-7 accumulated recommendations.\n\n### Round Introduction\n\nBefore presenting recommendations, briefly introduce the round:\n\n```\nBased on what you've shared, I have a few recommendations based on industry best practices\nthat could strengthen your PRD. I'll present each one for your review.\n```\n\n### Single Recommendation Template\n\n```yaml\nAskUserQuestion:\n  questions:\n    - header: \"Recommendation {N} of {Total}: {Category}\"\n      question: \"{Detailed recommendation with rationale}\\n\\n**Why this matters:**\\n{1-2 sentence explanation of benefits}\"\n      options:\n        - label: \"Accept\"\n          description: \"Include in PRD\"\n        - label: \"Modify\"\n          description: \"I want to adjust this\"\n        - label: \"Skip\"\n          description: \"Don't include\"\n      multiSelect: false\n```\n\n### Example: Scale Recommendation\n\n```yaml\nAskUserQuestion:\n  questions:\n    - header: \"Recommendation 2 of 5: Performance\"\n      question: \"For your expected traffic of 10k+ concurrent users, I recommend implementing a caching layer (Redis) for frequently accessed data and rate limiting for API endpoints.\\n\\n**Why this matters:**\\nThis prevents database overload during traffic spikes and ensures fair usage across clients.\"\n      options:\n        - label: \"Accept\"\n          description: \"Include caching and rate limiting requirements\"\n        - label: \"Modify\"\n          description: \"Adjust the approach\"\n        - label: \"Skip\"\n          description: \"Handle this during implementation\"\n      multiSelect: false\n```\n\n---\n\n## Modification Flow Template\n\nWhen user selects \"Modify\", gather their adjustment:\n\n```yaml\nAskUserQuestion:\n  questions:\n    - header: \"Modify Recommendation\"\n      question: \"How would you like to adjust this recommendation?\"\n      options:\n        - label: \"Different approach\"\n          description: \"Use a different technical approach\"\n        - label: \"Reduce scope\"\n          description: \"Simplify the requirement\"\n        - label: \"Add constraints\"\n          description: \"Include specific limitations or conditions\"\n        - label: \"Custom\"\n          description: \"Explain your preferred approach\"\n      multiSelect: false\n```\n\nAfter receiving modification input, confirm the adjusted recommendation:\n\n```yaml\nAskUserQuestion:\n  questions:\n    - header: \"Confirm Modification\"\n      question: \"Updated recommendation: {modified version}. Is this accurate?\"\n      options:\n        - label: \"Yes, include this\"\n          description: \"Add the modified recommendation\"\n        - label: \"Adjust further\"\n          description: \"Make more changes\"\n      multiSelect: false\n```\n\n---\n\n## Research-Backed Recommendation Template\n\nWhen proactive research informed the recommendation:\n\n```yaml\nAskUserQuestion:\n  questions:\n    - header: \"Recommendation {N} of {Total}: {Category}\"\n      question: \"{Recommendation}\\n\\n**Based on current standards:**\\n{Research finding summary}\\n\\n**Source:** {Brief source attribution}\"\n      options:\n        - label: \"Accept\"\n          description: \"Include in PRD\"\n        - label: \"Modify\"\n          description: \"Adjust this\"\n        - label: \"Skip\"\n          description: \"Don't include\"\n      multiSelect: false\n```\n\n### Example: Compliance Research Recommendation\n\n```yaml\nAskUserQuestion:\n  questions:\n    - header: \"Recommendation 3 of 5: Compliance\"\n      question: \"Since you're handling EU user data, GDPR compliance should be explicitly addressed. I recommend including: consent management, data retention policy (max 3 years), and right-to-deletion implementation.\\n\\n**Based on current standards:**\\nGDPR Article 17 requires the ability to delete user data within 30 days of request. Standard practice is implementing a soft-delete with scheduled purge.\\n\\n**Source:** EU GDPR Guidelines, ICO Best Practices\"\n      options:\n        - label: \"Accept\"\n          description: \"Include GDPR requirements\"\n        - label: \"Modify\"\n          description: \"Adjust compliance scope\"\n        - label: \"Skip\"\n          description: \"Address compliance separately\"\n      multiSelect: false\n```\n\n---\n\n## \"Tell Me More\" Response Template\n\nWhen user wants more details on an inline insight:\n\n```yaml\nAskUserQuestion:\n  questions:\n    - header: \"{Category} Details\"\n      question: \"**{Topic} Explanation:**\\n\\n{Detailed explanation with pros/cons}\\n\\n**Alternatives:**\\n- {Alternative 1}: {brief description}\\n- {Alternative 2}: {brief description}\\n\\nWould you like to include this recommendation?\"\n      options:\n        - label: \"Yes, include it\"\n          description: \"Add to PRD\"\n        - label: \"Use alternative\"\n          description: \"Choose a different approach\"\n        - label: \"Skip\"\n          description: \"Don't include any recommendation\"\n      multiSelect: false\n```\n\n---\n\n## Summary Section Template\n\nFor the pre-compilation summary, add this section after \"Implementation\":\n\n```markdown\n### Agent Recommendations (Accepted)\n\n*The following recommendations were suggested based on industry best practices and accepted during the interview:*\n\n1. **{Category}**: {Recommendation title}\n   - Rationale: {Why this was recommended}\n   - Applies to: {Which section/feature}\n\n2. **{Category}**: {Recommendation title}\n   - Rationale: {Why this was recommended}\n   - Applies to: {Which section/feature}\n\n{Continue for all accepted recommendations}\n```\n\n### Example Summary Section\n\n```markdown\n### Agent Recommendations (Accepted)\n\n*The following recommendations were suggested based on industry best practices and accepted during the interview:*\n\n1. **Authentication**: OAuth 2.0 with PKCE\n   - Rationale: Secure token handling for public clients without exposing secrets\n   - Applies to: User authentication feature\n\n2. **Performance**: Redis caching layer\n   - Rationale: Handle 10k+ concurrent users without database overload\n   - Applies to: API endpoints, user session data\n\n3. **Compliance**: GDPR data handling\n   - Rationale: EU user data requires consent management and deletion rights\n   - Applies to: User data storage, account management\n```\n\n---\n\n## Tracking Accepted Recommendations\n\nMaintain internal tracking during the interview:\n\n```\nAccepted Recommendations:\n1. [Auth] OAuth 2.0 with PKCE - Include in Technical Specs > Authentication\n2. [Performance] Redis caching - Include in Technical Specs > Performance\n3. [Compliance] GDPR requirements - Include in Non-Functional Requirements\n\nSkipped Recommendations:\n- [Testing] E2E test coverage - User prefers to decide during implementation\n\nModified Recommendations:\n- [Scale] Rate limiting - Modified: 100 req/min instead of 60 req/min\n```\n\nThis tracking ensures recommendations flow correctly into the final PRD.\n\n---\n\n## Presentation Guidelines\n\n1. **Be concise**: Recommendations should be clear and actionable, not lengthy explanations\n2. **Provide rationale**: Always explain *why* this is recommended\n3. **Offer alternatives**: When relevant, acknowledge other valid approaches\n4. **Respect user decisions**: Accept skips gracefully, don't repeatedly push rejected recommendations\n5. **Group related items**: If multiple recommendations are related, consider presenting together\n6. **Match depth level**: Fewer, higher-level recommendations for high-level PRDs; more detailed for full-tech\n",
        "plugins/prd-tools/skills/prd-generation/references/recommendation-triggers.md": "# Recommendation Triggers\n\nThis document defines patterns that trigger proactive recommendations during PRD interviews. When these patterns are detected in user responses, the interview agent should offer relevant best practices and recommendations.\n\n## Trigger Categories\n\n### Authentication & Identity\n\n**Trigger Keywords:**\n- \"login\", \"sign in\", \"sign up\", \"authentication\", \"auth\"\n- \"user accounts\", \"registration\", \"password\"\n- \"session\", \"token\", \"JWT\"\n- \"SSO\", \"single sign-on\", \"OAuth\"\n\n**Recommendation Areas:**\n| Scenario | Recommendation |\n|----------|----------------|\n| Public-facing web app | OAuth 2.0 with PKCE for secure token handling |\n| Mobile app | OAuth 2.0 + secure token storage (Keychain/Keystore) |\n| Multi-tenant SaaS | Tenant isolation, JWT with tenant claims |\n| Enterprise/B2B | SAML 2.0 or OIDC for SSO integration |\n| Sensitive data | MFA requirement, session timeout policies |\n\n**Research Triggers:**\n- \"which auth provider\", \"Auth0 vs Cognito\", \"auth best practices\"\n\n---\n\n### Scale & Performance\n\n**Trigger Keywords:**\n- \"millions of users\", \"high traffic\", \"10k+\", \"100k+\"\n- \"scale\", \"scalable\", \"scaling\"\n- \"concurrent users\", \"requests per second\"\n- \"performance\", \"fast\", \"latency\"\n- \"real-time\", \"live updates\"\n\n**Recommendation Areas:**\n| Scenario | Recommendation |\n|----------|----------------|\n| Read-heavy workload | Caching layer (Redis/Memcached), CDN for static assets |\n| Write-heavy workload | Message queues, event sourcing, eventual consistency |\n| Global users | Multi-region deployment, edge caching |\n| Bursty traffic | Auto-scaling, rate limiting, circuit breakers |\n| Low latency required | Connection pooling, query optimization, indexing |\n\n**Research Triggers:**\n- \"how to handle traffic spikes\", \"caching strategies\", \"database scaling\"\n\n---\n\n### Security & Compliance\n\n**Trigger Keywords:**\n- \"sensitive data\", \"PII\", \"personal information\"\n- \"HIPAA\", \"healthcare\", \"medical\"\n- \"GDPR\", \"privacy\", \"data protection\"\n- \"PCI\", \"payment\", \"credit card\"\n- \"SOC 2\", \"compliance\", \"audit\"\n- \"encryption\", \"secure\"\n\n**Recommendation Areas:**\n| Scenario | Recommendation |\n|----------|----------------|\n| HIPAA (healthcare) | Encryption at rest/transit, audit logging, BAA requirements |\n| GDPR (EU users) | Consent management, data retention policies, right to deletion |\n| PCI DSS (payments) | Tokenization, no raw card storage, regular security scans |\n| SOC 2 | Access controls, monitoring, incident response procedures |\n| General sensitive data | Field-level encryption, data masking, access logging |\n\n**Auto-Research Triggers (proactive):**\n- Any mention of HIPAA, GDPR, PCI, SOC 2, WCAG\n- \"compliance requirements\", \"regulatory\"\n\n---\n\n### Real-Time Features\n\n**Trigger Keywords:**\n- \"real-time\", \"live\", \"instant\"\n- \"notifications\", \"push notifications\"\n- \"chat\", \"messaging\", \"collaboration\"\n- \"streaming\", \"live updates\"\n- \"presence\", \"online status\"\n\n**Recommendation Areas:**\n| Scenario | Recommendation |\n|----------|----------------|\n| Bi-directional communication | WebSockets for persistent connections |\n| Server-to-client updates only | Server-Sent Events (SSE) for simplicity |\n| Mobile notifications | Firebase Cloud Messaging (FCM) / APNs |\n| High-frequency updates | Consider rate limiting, batching updates |\n| Offline support | Local queue with sync on reconnect |\n\n**Research Triggers:**\n- \"WebSocket vs SSE\", \"real-time architecture\", \"notification service\"\n\n---\n\n### File & Media Handling\n\n**Trigger Keywords:**\n- \"file upload\", \"image upload\", \"document\"\n- \"video\", \"audio\", \"media\"\n- \"storage\", \"S3\", \"blob\"\n- \"CDN\", \"content delivery\"\n\n**Recommendation Areas:**\n| Scenario | Recommendation |\n|----------|----------------|\n| Large files (>10MB) | Presigned URLs, chunked/resumable uploads |\n| User-generated images | Image processing pipeline, CDN, multiple resolutions |\n| Documents | Virus scanning, format validation, preview generation |\n| Video content | Transcoding pipeline, adaptive streaming (HLS/DASH) |\n| High availability | Multi-region storage, replication |\n\n**Research Triggers:**\n- \"file upload best practices\", \"video streaming architecture\"\n\n---\n\n### API Design\n\n**Trigger Keywords:**\n- \"API\", \"REST\", \"GraphQL\"\n- \"endpoint\", \"integration\"\n- \"third-party\", \"webhook\"\n- \"versioning\", \"backwards compatible\"\n- \"pagination\", \"rate limit\"\n\n**Recommendation Areas:**\n| Scenario | Recommendation |\n|----------|----------------|\n| Public API | API versioning (URL or header), comprehensive documentation |\n| High-volume clients | Rate limiting, pagination (cursor-based preferred) |\n| Multiple clients | GraphQL for flexible queries, or REST with sparse fieldsets |\n| Webhooks | Retry logic, signature verification, idempotency keys |\n| Partner integrations | OAuth 2.0 client credentials, API key rotation |\n\n**Research Triggers:**\n- \"API design best practices\", \"GraphQL vs REST\", \"webhook security\"\n\n---\n\n### Search & Discovery\n\n**Trigger Keywords:**\n- \"search\", \"find\", \"filter\"\n- \"autocomplete\", \"typeahead\"\n- \"full-text search\", \"fuzzy search\"\n- \"recommendations\", \"suggested\"\n\n**Recommendation Areas:**\n| Scenario | Recommendation |\n|----------|----------------|\n| Basic search | Database full-text search (PostgreSQL tsvector) |\n| Advanced search | Elasticsearch/OpenSearch, Algolia, Meilisearch |\n| Autocomplete | Debounced requests, prefix indexing |\n| Personalization | User behavior tracking, collaborative filtering |\n| Large datasets | Search indexing pipeline, denormalization |\n\n**Research Triggers:**\n- \"search implementation\", \"Elasticsearch vs Algolia\"\n\n---\n\n### Testing & Quality\n\n**Trigger Keywords:**\n- \"testing\", \"test\", \"QA\"\n- \"unit test\", \"integration test\"\n- \"coverage\", \"automated testing\"\n- \"CI/CD\", \"pipeline\"\n\n**Recommendation Areas:**\n| Scenario | Recommendation |\n|----------|----------------|\n| Critical business logic | Unit tests with >80% coverage |\n| API endpoints | Integration tests, contract testing |\n| UI components | Component tests, visual regression |\n| End-to-end flows | E2E tests for critical paths only |\n| Continuous deployment | Automated pipeline with staged rollouts |\n\n**Research Triggers:**\n- \"testing strategy\", \"CI/CD best practices\"\n\n---\n\n### Accessibility\n\n**Trigger Keywords:**\n- \"accessible\", \"accessibility\", \"a11y\"\n- \"WCAG\", \"ADA\", \"screen reader\"\n- \"keyboard navigation\"\n\n**Recommendation Areas:**\n| Scenario | Recommendation |\n|----------|----------------|\n| Public website | WCAG 2.1 AA compliance minimum |\n| Government/education | WCAG 2.1 AAA, Section 508 |\n| Mobile app | Platform accessibility guidelines (iOS/Android) |\n| Complex UI | ARIA attributes, focus management, skip links |\n\n**Auto-Research Triggers (proactive):**\n- \"WCAG\", \"accessibility requirements\", \"ADA compliance\"\n\n---\n\n## Detection Guidelines\n\n### When to Offer Inline Insights\n\nOffer brief insights during rounds when:\n1. A trigger keyword is detected\n2. The topic is relevant to the current question context\n3. Maximum 2 inline insights per round to avoid overwhelm\n\n### When to Save for Recommendations Round\n\nSave for the dedicated recommendations round when:\n1. Multiple related triggers are detected\n2. The recommendation requires more context to present\n3. Research might strengthen the recommendation\n4. The topic needs user decision (e.g., choosing between approaches)\n\n### When to Trigger Proactive Research\n\nAutomatically research (without explicit user request) when:\n1. Compliance topics are mentioned (HIPAA, GDPR, PCI, WCAG)\n2. User expresses uncertainty (\"I'm not sure\", \"what do you recommend?\")\n3. Complex technical trade-offs need current information\n4. Maximum 2 proactive research calls per interview\n\n---\n\n## Trigger Tracking\n\nDuring the interview, track detected triggers:\n\n```\nDetected Triggers:\n- [x] Authentication (Round 1) - OAuth 2.0 recommended\n- [x] Scale (Round 2) - Caching strategy recommended\n- [ ] Security (Round 2) - Pending recommendation\n- [x] Real-time (Round 3) - WebSocket vs SSE presented\n\nProactive Research Used: 1/2\n- GDPR compliance requirements (Round 2)\n```\n\nThis tracking informs the Recommendations Round content.\n",
        "plugins/prd-tools/skills/prd-generation/references/template-detailed.md": "# PRD: {Product Name}\n\n**Version**: 1.0\n**Author**: {Author}\n**Date**: {Date}\n**Status**: Draft\n\n---\n\n## 1. Executive Summary\n\n{Brief 2-3 sentence overview of what this product/feature does and why it matters.}\n\n## 2. Problem Statement\n\n### 2.1 The Problem\n{What problem are we solving? Who experiences this problem?}\n\n### 2.2 Current State\n{How is this problem currently addressed (or not)?}\n\n### 2.3 Impact Analysis\n{What is the cost/impact of not solving this problem? Include quantitative data where available.}\n\n### 2.4 Business Value\n{Why should we invest in solving this now? Strategic alignment, revenue impact, user retention, etc.}\n\n## 3. Goals & Success Metrics\n\n### 3.1 Primary Goals\n1. {Goal 1}\n2. {Goal 2}\n3. {Goal 3}\n\n### 3.2 Success Metrics\n\n| Metric | Current Baseline | Target | Measurement Method | Timeline |\n|--------|------------------|--------|-------------------|----------|\n| {Metric 1} | {baseline} | {goal} | {how measured} | {when} |\n| {Metric 2} | {baseline} | {goal} | {how measured} | {when} |\n\n### 3.3 Non-Goals\n- {What we are explicitly NOT trying to achieve}\n\n## 4. User Research\n\n### 4.1 Target Users\n\n#### Primary Persona: {Name}\n- **Role/Description**: {who they are}\n- **Goals**: {what they want to achieve}\n- **Pain Points**: {current frustrations}\n- **Context**: {when/where they use the product}\n\n#### Secondary Persona: {Name}\n- **Role/Description**: {who they are}\n- **Goals**: {what they want to achieve}\n- **Pain Points**: {current frustrations}\n\n### 4.2 User Journey Map\n\n```\n[Current State] --> [Trigger] --> [Action 1] --> [Action 2] --> [Outcome]\n```\n\n{Description of typical user flow}\n\n## 5. Functional Requirements\n\n### 5.1 Feature: {Feature Name}\n\n**Priority**: P0 (Critical)\n\n#### User Stories\n\n**US-001**: As a {user type}, I want {capability} so that {benefit}.\n\n**Acceptance Criteria**:\n- [ ] {Specific, testable criterion 1}\n- [ ] {Specific, testable criterion 2}\n- [ ] {Specific, testable criterion 3}\n\n**Edge Cases**:\n- {Edge case 1}: {Expected behavior}\n- {Edge case 2}: {Expected behavior}\n\n---\n\n### 5.2 Feature: {Feature Name}\n\n**Priority**: P1 (High)\n\n#### User Stories\n\n**US-002**: As a {user type}, I want {capability} so that {benefit}.\n\n**Acceptance Criteria**:\n- [ ] {Specific, testable criterion 1}\n- [ ] {Specific, testable criterion 2}\n\n---\n\n### 5.3 Feature: {Feature Name}\n\n**Priority**: P2 (Medium)\n\n#### User Stories\n\n**US-003**: As a {user type}, I want {capability} so that {benefit}.\n\n**Acceptance Criteria**:\n- [ ] {Specific, testable criterion 1}\n- [ ] {Specific, testable criterion 2}\n\n## 6. Non-Functional Requirements\n\n### 6.1 Performance\n- {Response time requirements}\n- {Throughput requirements}\n- {Resource constraints}\n\n### 6.2 Security\n- {Authentication requirements}\n- {Authorization requirements}\n- {Data protection requirements}\n\n### 6.3 Scalability\n- {Expected load}\n- {Growth projections}\n\n### 6.4 Accessibility\n- {WCAG compliance level}\n- {Specific accessibility requirements}\n\n## 7. Technical Considerations\n\n### 7.1 Architecture Overview\n{High-level description of technical approach}\n\n### 7.2 Tech Stack\n- **Frontend**: {technologies}\n- **Backend**: {technologies}\n- **Database**: {technologies}\n- **Infrastructure**: {technologies}\n\n### 7.3 Integration Points\n| System | Integration Type | Purpose |\n|--------|-----------------|---------|\n| {System 1} | API/Event/etc | {why needed} |\n\n### 7.4 Technical Constraints\n- {Constraint 1}\n- {Constraint 2}\n\n## 8. Scope Definition\n\n### 8.1 In Scope\n- {Explicit item 1}\n- {Explicit item 2}\n- {Explicit item 3}\n\n### 8.2 Out of Scope\n- {Explicit exclusion 1}: {reason}\n- {Explicit exclusion 2}: {reason}\n\n### 8.3 Future Considerations\n- {Potential future enhancement 1}\n- {Potential future enhancement 2}\n\n## 9. Implementation Plan\n\n### 9.1 Phase 1: {Name} - Foundation\n**Completion Criteria**: {How we know this phase is done}\n\n| Deliverable | Description | Dependencies |\n|-------------|-------------|--------------|\n| {Item 1} | {Description} | {Dependencies} |\n| {Item 2} | {Description} | {Dependencies} |\n\n**Checkpoint Gate**: {What needs review before proceeding}\n\n---\n\n### 9.2 Phase 2: {Name} - Core Features\n**Completion Criteria**: {How we know this phase is done}\n\n| Deliverable | Description | Dependencies |\n|-------------|-------------|--------------|\n| {Item 1} | {Description} | {Dependencies} |\n| {Item 2} | {Description} | {Dependencies} |\n\n**Checkpoint Gate**: {What needs review before proceeding}\n\n---\n\n### 9.3 Phase 3: {Name} - Enhancement\n**Completion Criteria**: {How we know this phase is done}\n\n| Deliverable | Description | Dependencies |\n|-------------|-------------|--------------|\n| {Item 1} | {Description} | {Dependencies} |\n| {Item 2} | {Description} | {Dependencies} |\n\n## 10. Dependencies\n\n### 10.1 Technical Dependencies\n| Dependency | Owner | Status | Risk if Delayed |\n|------------|-------|--------|-----------------|\n| {Dep 1} | {team/person} | {status} | {impact} |\n\n### 10.2 Cross-Team Dependencies\n| Team | Dependency | Status |\n|------|------------|--------|\n| {Team 1} | {What we need from them} | {status} |\n\n## 11. Risks & Mitigations\n\n| Risk | Impact | Likelihood | Mitigation Strategy | Owner |\n|------|--------|------------|--------------------|----- |\n| {Risk 1} | High/Med/Low | High/Med/Low | {Strategy} | {Who} |\n| {Risk 2} | High/Med/Low | High/Med/Low | {Strategy} | {Who} |\n\n## 12. Open Questions\n\n| # | Question | Owner | Due Date | Resolution |\n|---|----------|-------|----------|------------|\n| 1 | {Question} | {Who} | {When} | {Answer when resolved} |\n\n## 13. Appendix\n\n### 13.1 Glossary\n| Term | Definition |\n|------|------------|\n| {Term 1} | {Definition} |\n\n### 13.2 References\n- {Reference 1}\n- {Reference 2}\n\n---\n\n*Document generated by PRD Generator Plugin*\n",
        "plugins/prd-tools/skills/prd-generation/references/template-full-tech.md": "# PRD: {Product Name}\n\n**Version**: 1.0\n**Author**: {Author}\n**Date**: {Date}\n**Status**: Draft\n\n---\n\n## 1. Executive Summary\n\n{Brief 2-3 sentence overview of what this product/feature does and why it matters.}\n\n## 2. Problem Statement\n\n### 2.1 The Problem\n{What problem are we solving? Who experiences this problem?}\n\n### 2.2 Current State\n{How is this problem currently addressed (or not)?}\n\n### 2.3 Impact Analysis\n{What is the cost/impact of not solving this problem? Include quantitative data where available.}\n\n### 2.4 Business Value\n{Why should we invest in solving this now? Strategic alignment, revenue impact, user retention, etc.}\n\n## 3. Goals & Success Metrics\n\n### 3.1 Primary Goals\n1. {Goal 1}\n2. {Goal 2}\n3. {Goal 3}\n\n### 3.2 Success Metrics\n\n| Metric | Current Baseline | Target | Measurement Method | Timeline |\n|--------|------------------|--------|-------------------|----------|\n| {Metric 1} | {baseline} | {goal} | {how measured} | {when} |\n| {Metric 2} | {baseline} | {goal} | {how measured} | {when} |\n\n### 3.3 Non-Goals\n- {What we are explicitly NOT trying to achieve}\n\n## 4. User Research\n\n### 4.1 Target Users\n\n#### Primary Persona: {Name}\n- **Role/Description**: {who they are}\n- **Goals**: {what they want to achieve}\n- **Pain Points**: {current frustrations}\n- **Context**: {when/where they use the product}\n- **Technical Proficiency**: {level}\n\n#### Secondary Persona: {Name}\n- **Role/Description**: {who they are}\n- **Goals**: {what they want to achieve}\n- **Pain Points**: {current frustrations}\n\n### 4.2 User Journey Map\n\n```\n[Current State] --> [Trigger] --> [Action 1] --> [Action 2] --> [Outcome]\n     |                 |              |              |             |\n     v                 v              v              v             v\n  {context}       {what triggers}  {first step}  {next step}  {result}\n```\n\n### 4.3 User Workflows\n\n#### Workflow 1: {Name}\n```mermaid\ngraph TD\n    A[Start] --> B{Decision}\n    B -->|Option 1| C[Action]\n    B -->|Option 2| D[Alternative]\n    C --> E[End]\n    D --> E\n```\n\n## 5. Functional Requirements\n\n### 5.1 Feature: {Feature Name}\n\n**Priority**: P0 (Critical)\n**Complexity**: High/Medium/Low\n\n#### User Stories\n\n**US-001**: As a {user type}, I want {capability} so that {benefit}.\n\n**Acceptance Criteria**:\n- [ ] {Specific, testable criterion 1}\n- [ ] {Specific, testable criterion 2}\n- [ ] {Specific, testable criterion 3}\n\n**Technical Notes**:\n- {Implementation consideration 1}\n- {Implementation consideration 2}\n\n**Edge Cases**:\n| Scenario | Input | Expected Behavior |\n|----------|-------|-------------------|\n| {Case 1} | {input} | {behavior} |\n| {Case 2} | {input} | {behavior} |\n\n**Error Handling**:\n| Error Condition | User Message | System Action |\n|-----------------|--------------|---------------|\n| {Condition 1} | {message} | {action} |\n\n---\n\n### 5.2 Feature: {Feature Name}\n\n**Priority**: P1 (High)\n**Complexity**: Medium\n\n#### User Stories\n\n**US-002**: As a {user type}, I want {capability} so that {benefit}.\n\n**Acceptance Criteria**:\n- [ ] {Specific, testable criterion 1}\n- [ ] {Specific, testable criterion 2}\n\n---\n\n## 6. Non-Functional Requirements\n\n### 6.1 Performance Requirements\n\n| Metric | Requirement | Measurement Method |\n|--------|-------------|-------------------|\n| Response Time (P50) | < {X}ms | APM monitoring |\n| Response Time (P99) | < {X}ms | APM monitoring |\n| Throughput | {X} requests/sec | Load testing |\n| Concurrent Users | {X} users | Load testing |\n\n### 6.2 Security Requirements\n\n#### Authentication\n- {Authentication method and requirements}\n\n#### Authorization\n| Role | Permissions |\n|------|------------|\n| {Role 1} | {permissions} |\n| {Role 2} | {permissions} |\n\n#### Data Protection\n- Encryption at rest: {requirements}\n- Encryption in transit: {requirements}\n- PII handling: {requirements}\n\n### 6.3 Scalability Requirements\n- Horizontal scaling: {requirements}\n- Expected growth: {projections}\n- Peak load handling: {requirements}\n\n### 6.4 Reliability Requirements\n- Uptime SLA: {percentage}\n- Recovery Time Objective (RTO): {time}\n- Recovery Point Objective (RPO): {time}\n\n### 6.5 Accessibility Requirements\n- WCAG compliance level: {level}\n- Screen reader support: {requirements}\n- Keyboard navigation: {requirements}\n\n## 7. Technical Architecture\n\n### 7.1 System Overview\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                      Client Layer                            │\n│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │\n│  │   Web App   │  │ Mobile App  │  │    CLI      │         │\n│  └─────────────┘  └─────────────┘  └─────────────┘         │\n└─────────────────────────────────────────────────────────────┘\n                           │\n                           ▼\n┌─────────────────────────────────────────────────────────────┐\n│                      API Gateway                             │\n│  - Authentication  - Rate Limiting  - Routing               │\n└─────────────────────────────────────────────────────────────┘\n                           │\n                           ▼\n┌─────────────────────────────────────────────────────────────┐\n│                    Service Layer                             │\n│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │\n│  │  Service A  │  │  Service B  │  │  Service C  │         │\n│  └─────────────┘  └─────────────┘  └─────────────┘         │\n└─────────────────────────────────────────────────────────────┘\n                           │\n                           ▼\n┌─────────────────────────────────────────────────────────────┐\n│                     Data Layer                               │\n│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │\n│  │  Database   │  │    Cache    │  │   Storage   │         │\n│  └─────────────┘  └─────────────┘  └─────────────┘         │\n└─────────────────────────────────────────────────────────────┘\n```\n\n### 7.2 Tech Stack\n\n| Layer | Technology | Justification |\n|-------|------------|---------------|\n| Frontend | {tech} | {reason} |\n| Backend | {tech} | {reason} |\n| Database | {tech} | {reason} |\n| Cache | {tech} | {reason} |\n| Queue | {tech} | {reason} |\n| Infrastructure | {tech} | {reason} |\n\n### 7.3 Data Models\n\n#### Entity: {Entity Name}\n\n```\n┌────────────────────────────────┐\n│         {Entity Name}          │\n├────────────────────────────────┤\n│ id: UUID (PK)                  │\n│ field_1: string                │\n│ field_2: integer               │\n│ field_3: timestamp             │\n│ created_at: timestamp          │\n│ updated_at: timestamp          │\n├────────────────────────────────┤\n│ Indexes:                       │\n│ - idx_field_1 (field_1)        │\n│ - idx_composite (field_1, 2)   │\n└────────────────────────────────┘\n```\n\n**Field Definitions**:\n| Field | Type | Constraints | Description |\n|-------|------|-------------|-------------|\n| id | UUID | PK, NOT NULL | Unique identifier |\n| field_1 | VARCHAR(255) | NOT NULL | {description} |\n| field_2 | INTEGER | DEFAULT 0 | {description} |\n\n#### Entity Relationships\n\n```\n┌──────────┐       ┌──────────┐       ┌──────────┐\n│ Entity A │ 1───* │ Entity B │ *───1 │ Entity C │\n└──────────┘       └──────────┘       └──────────┘\n```\n\n### 7.4 API Specifications\n\n#### Endpoint: `POST /api/v1/{resource}`\n\n**Purpose**: {What this endpoint does}\n\n**Authentication**: Required (Bearer token)\n\n**Rate Limit**: {X} requests/minute\n\n**Request**:\n```http\nPOST /api/v1/{resource}\nContent-Type: application/json\nAuthorization: Bearer {token}\n\n{\n  \"field_1\": \"string (required) - Description\",\n  \"field_2\": \"integer (optional) - Description, default: 0\",\n  \"field_3\": {\n    \"nested_field\": \"string (required) - Description\"\n  }\n}\n```\n\n**Response**:\n\n`201 Created`\n```json\n{\n  \"id\": \"uuid\",\n  \"field_1\": \"value\",\n  \"field_2\": 0,\n  \"created_at\": \"2024-01-01T00:00:00Z\"\n}\n```\n\n`400 Bad Request`\n```json\n{\n  \"error\": {\n    \"code\": \"VALIDATION_ERROR\",\n    \"message\": \"Field validation failed\",\n    \"details\": [\n      {\n        \"field\": \"field_1\",\n        \"message\": \"Required field missing\"\n      }\n    ]\n  }\n}\n```\n\n`401 Unauthorized`\n```json\n{\n  \"error\": {\n    \"code\": \"UNAUTHORIZED\",\n    \"message\": \"Invalid or expired token\"\n  }\n}\n```\n\n---\n\n#### Endpoint: `GET /api/v1/{resource}/{id}`\n\n**Purpose**: {What this endpoint does}\n\n**Authentication**: Required (Bearer token)\n\n**Request**:\n```http\nGET /api/v1/{resource}/{id}\nAuthorization: Bearer {token}\n```\n\n**Response**:\n\n`200 OK`\n```json\n{\n  \"id\": \"uuid\",\n  \"field_1\": \"value\",\n  \"field_2\": 0,\n  \"created_at\": \"2024-01-01T00:00:00Z\",\n  \"updated_at\": \"2024-01-01T00:00:00Z\"\n}\n```\n\n`404 Not Found`\n```json\n{\n  \"error\": {\n    \"code\": \"NOT_FOUND\",\n    \"message\": \"Resource not found\"\n  }\n}\n```\n\n---\n\n### 7.5 Integration Points\n\n| System | Type | Protocol | Purpose | Authentication |\n|--------|------|----------|---------|----------------|\n| {System 1} | External API | REST/HTTPS | {purpose} | API Key |\n| {System 2} | Internal | gRPC | {purpose} | mTLS |\n| {System 3} | Event | Kafka | {purpose} | SASL |\n\n#### Integration: {System Name}\n\n**Overview**: {What this integration does}\n\n**Data Flow**:\n```\nOur System ──(1)─> External System\n     │                    │\n     │                    │\n     └───────(2)──────────┘\n```\n\n**Error Handling**:\n- Retry policy: {description}\n- Circuit breaker: {configuration}\n- Fallback behavior: {description}\n\n### 7.6 Technical Constraints\n\n| Constraint | Impact | Mitigation |\n|------------|--------|------------|\n| {Constraint 1} | {impact} | {how to work around} |\n| {Constraint 2} | {impact} | {how to work around} |\n\n## 8. Scope Definition\n\n### 8.1 In Scope\n- {Explicit item 1}\n- {Explicit item 2}\n- {Explicit item 3}\n\n### 8.2 Out of Scope\n- {Explicit exclusion 1}: {reason}\n- {Explicit exclusion 2}: {reason}\n\n### 8.3 Future Considerations\n- {Potential future enhancement 1}\n- {Potential future enhancement 2}\n\n## 9. Implementation Plan\n\n### 9.1 Phase 1: Foundation\n**Completion Criteria**: {How we know this phase is done}\n\n| Deliverable | Description | Technical Tasks | Dependencies |\n|-------------|-------------|-----------------|--------------|\n| {Item 1} | {Description} | {tasks} | {deps} |\n| {Item 2} | {Description} | {tasks} | {deps} |\n\n**Checkpoint Gate**:\n- [ ] Architecture review completed\n- [ ] Database schema approved\n- [ ] API contracts finalized\n\n---\n\n### 9.2 Phase 2: Core Features\n**Completion Criteria**: {How we know this phase is done}\n\n| Deliverable | Description | Technical Tasks | Dependencies |\n|-------------|-------------|-----------------|--------------|\n| {Item 1} | {Description} | {tasks} | {deps} |\n| {Item 2} | {Description} | {tasks} | {deps} |\n\n**Checkpoint Gate**:\n- [ ] Integration testing passed\n- [ ] Security review completed\n- [ ] Performance benchmarks met\n\n---\n\n### 9.3 Phase 3: Enhancement\n**Completion Criteria**: {How we know this phase is done}\n\n| Deliverable | Description | Technical Tasks | Dependencies |\n|-------------|-------------|-----------------|--------------|\n| {Item 1} | {Description} | {tasks} | {deps} |\n\n---\n\n### 9.4 Phase 4: Polish\n**Completion Criteria**: {How we know this phase is done}\n\n| Deliverable | Description | Technical Tasks | Dependencies |\n|-------------|-------------|-----------------|--------------|\n| {Item 1} | {Description} | {tasks} | {deps} |\n\n**Checkpoint Gate**:\n- [ ] UAT completed\n- [ ] Documentation finalized\n- [ ] Runbook prepared\n\n## 10. Testing Strategy\n\n### 10.1 Test Levels\n\n| Level | Scope | Tools | Coverage Target |\n|-------|-------|-------|-----------------|\n| Unit | Individual functions | {tools} | {X}% |\n| Integration | Service interactions | {tools} | {X}% |\n| E2E | User workflows | {tools} | Critical paths |\n| Performance | Load/stress | {tools} | {requirements} |\n\n### 10.2 Test Scenarios\n\n#### Critical Path: {Name}\n| Step | Action | Expected Result |\n|------|--------|-----------------|\n| 1 | {action} | {result} |\n| 2 | {action} | {result} |\n\n### 10.3 Performance Test Plan\n- Load test: {X} concurrent users for {Y} duration\n- Stress test: Ramp to {X} users, identify breaking point\n- Soak test: {X} users for {Y} hours\n\n## 11. Deployment & Operations\n\n### 11.1 Deployment Strategy\n- Strategy: {Blue-green / Canary / Rolling}\n- Rollback plan: {description}\n\n### 11.2 Feature Flags\n| Flag | Purpose | Default |\n|------|---------|---------|\n| {flag_name} | {purpose} | {on/off} |\n\n### 11.3 Monitoring & Alerting\n\n| Metric | Threshold | Alert Channel |\n|--------|-----------|---------------|\n| Error rate | > {X}% | {channel} |\n| Latency P99 | > {X}ms | {channel} |\n| {Custom metric} | {threshold} | {channel} |\n\n### 11.4 Runbook\n- **Incident Response**: {link or inline}\n- **Common Issues**: {link or inline}\n- **Escalation Path**: {description}\n\n## 12. Dependencies\n\n### 12.1 Technical Dependencies\n| Dependency | Owner | Status | Risk if Delayed |\n|------------|-------|--------|-----------------|\n| {Dep 1} | {team/person} | {status} | {impact} |\n\n### 12.2 Cross-Team Dependencies\n| Team | Dependency | Status |\n|------|------------|--------|\n| {Team 1} | {What we need from them} | {status} |\n\n## 13. Risks & Mitigations\n\n| Risk | Impact | Likelihood | Mitigation Strategy | Owner |\n|------|--------|------------|--------------------|----- |\n| {Risk 1} | High/Med/Low | High/Med/Low | {Strategy} | {Who} |\n| {Risk 2} | High/Med/Low | High/Med/Low | {Strategy} | {Who} |\n\n## 14. Open Questions\n\n| # | Question | Owner | Due Date | Resolution |\n|---|----------|-------|----------|------------|\n| 1 | {Question} | {Who} | {When} | {Answer when resolved} |\n\n## 15. Appendix\n\n### 15.1 Glossary\n| Term | Definition |\n|------|------------|\n| {Term 1} | {Definition} |\n\n### 15.2 References\n- {Reference 1}\n- {Reference 2}\n\n### 15.3 Change Log\n| Version | Date | Author | Changes |\n|---------|------|--------|---------|\n| 1.0 | {date} | {author} | Initial version |\n\n---\n\n*Document generated by PRD Generator Plugin*\n",
        "plugins/prd-tools/skills/prd-generation/references/template-high-level.md": "# PRD: {Product Name}\n\n**Version**: 1.0\n**Author**: {Author}\n**Date**: {Date}\n**Status**: Draft\n\n---\n\n## Executive Summary\n\n{Brief 2-3 sentence overview of what this product/feature does and why it matters.}\n\n## Problem Statement\n\n### The Problem\n{What problem are we solving? Who experiences this problem?}\n\n### Current State\n{How is this problem currently addressed (or not)?}\n\n### Impact\n{What is the cost/impact of not solving this problem?}\n\n## Proposed Solution\n\n### Overview\n{High-level description of the solution approach.}\n\n### Key Features\n| Feature | Description | Priority |\n|---------|-------------|----------|\n| {Feature 1} | {Brief description} | P0/P1/P2 |\n| {Feature 2} | {Brief description} | P0/P1/P2 |\n| {Feature 3} | {Brief description} | P0/P1/P2 |\n\n## Success Metrics\n\n| Metric | Current | Target | How Measured |\n|--------|---------|--------|--------------|\n| {Metric 1} | {baseline} | {goal} | {method} |\n| {Metric 2} | {baseline} | {goal} | {method} |\n\n## User Personas\n\n### Primary User: {Persona Name}\n- **Role**: {description}\n- **Goals**: {what they want to achieve}\n- **Pain Points**: {current frustrations}\n\n## Scope\n\n### In Scope\n- {Item 1}\n- {Item 2}\n\n### Out of Scope\n- {Item 1}\n- {Item 2}\n\n## Implementation Phases\n\n### Phase 1: {Name}\n**Goal**: {What this phase achieves}\n- {Deliverable 1}\n- {Deliverable 2}\n\n### Phase 2: {Name}\n**Goal**: {What this phase achieves}\n- {Deliverable 1}\n- {Deliverable 2}\n\n## Risks & Mitigations\n\n| Risk | Impact | Likelihood | Mitigation |\n|------|--------|------------|------------|\n| {Risk 1} | High/Med/Low | High/Med/Low | {Strategy} |\n\n## Dependencies\n\n- {Dependency 1}: {Description and status}\n- {Dependency 2}: {Description and status}\n\n## Stakeholder Sign-off\n\n| Role | Name | Status |\n|------|------|--------|\n| Product | | Pending |\n| Engineering | | Pending |\n| Design | | Pending |\n\n---\n\n*Document generated by PRD Generator Plugin*\n",
        "plugins/prd-tools/skills/task-generation/SKILL.md": "---\ndescription: This skill should be used when generating implementation tasks from PRDs, decomposing features into atomic tasks, inferring dependencies, or mapping PRD content to task metadata.\ntriggers:\n  - generate tasks from PRD\n  - create tasks from requirements\n  - decompose features into tasks\n  - PRD to tasks\n  - task generation\n  - implementation tasks\n---\n\n# Task Generation Skill\n\nThis skill provides structured knowledge for transforming Product Requirements Documents into Claude Code native Tasks with proper dependencies, metadata, and acceptance criteria.\n\n## Core Principles\n\n### 1. Atomic Task Decomposition\n\nTasks should be:\n- **Single Responsibility**: Each task accomplishes one specific outcome\n- **Independent**: Minimal coupling with other tasks where possible\n- **Verifiable**: Clear completion criteria that can be objectively assessed\n- **Estimable**: Complexity can be reasonably assessed (XS/S/M/L/XL)\n\n### 2. Layered Architecture Pattern\n\nDecompose features following natural implementation layers:\n\n```\nData Model → API/Service → Business Logic → UI/Frontend → Tests\n```\n\nThis pattern ensures:\n- Dependencies flow in one direction\n- Each layer can be implemented and tested independently\n- Integration points are well-defined\n\n### 3. PRD-to-Task Traceability\n\nEvery task should trace back to the source PRD:\n- Reference specific section numbers\n- Quote relevant user stories\n- Link acceptance criteria to PRD requirements\n\n## Task Schema\n\nEach task created via TaskCreate follows this structure:\n\n```\nTaskCreate:\n  subject: \"Create User data model\"                    # Imperative mood\n  description: |\n    Define the User data model based on PRD section 7.3.\n\n    Fields:\n    - id: UUID (primary key)\n    - email: string (unique, required)\n    - passwordHash: string (required)\n    - createdAt: timestamp\n\n    Acceptance Criteria:\n    - [ ] Schema defined with all required fields\n    - [ ] Indexes created for email lookup\n    - [ ] Migration script created\n\n    Source: specs/PRD-Auth.md Section 7.3\n  activeForm: \"Creating User data model\"              # Present continuous\n  metadata:\n    priority: critical                                # From PRD P0-P3\n    complexity: S                                     # XS/S/M/L/XL\n    source_section: \"7.3 Data Models\"                 # PRD section reference\n    prd_path: \"specs/PRD-Auth.md\"                     # Source PRD\n    feature_name: \"User Authentication\"               # Parent feature\n    task_uid: \"specs/PRD-Auth.md:user-auth:model:001\" # Unique ID for merge\n```\n\n## PRD Section Mapping\n\nExtract task information from specific PRD sections:\n\n| PRD Section | What to Extract | Task Type |\n|-------------|-----------------|-----------|\n| 5.x Functional Requirements | Feature names, priorities, user stories | Feature tasks |\n| 6.x Non-Functional Requirements | Performance, security constraints | Constraint tasks |\n| 7.x Technical Considerations | Architecture, tech stack | Infrastructure tasks |\n| 7.3 Data Models (Full-Tech) | Entity definitions | Data model tasks |\n| 7.4 API Specifications (Full-Tech) | Endpoints | API tasks |\n| 9.x Implementation Plan | Phase ordering, deliverables | Phase grouping |\n| 10.x Dependencies | Blocking relationships | Dependency inference |\n\n## Priority Mapping\n\nConvert PRD priority notation to task priority:\n\n| PRD Priority | Task Priority | Meaning |\n|--------------|---------------|---------|\n| P0 (Critical) | `critical` | Blocking release, must be done first |\n| P1 (High) | `high` | Core functionality, high value |\n| P2 (Medium) | `medium` | Important but not blocking |\n| P3 (Low) | `low` | Nice to have, can be deferred |\n\n## Complexity Estimation\n\nEstimate task complexity using T-shirt sizing:\n\n| Size | Scope | Typical Lines | Example |\n|------|-------|---------------|---------|\n| XS | Single simple function | <20 | Add config constant |\n| S | Single file, straightforward | 20-100 | Create data model |\n| M | Multiple files, moderate logic | 100-300 | Implement API endpoint |\n| L | Multiple components, significant logic | 300-800 | Build feature module |\n| XL | System-wide, complex integration | >800 | Major refactoring |\n\n## Depth-Aware Task Generation\n\nAdjust task granularity based on PRD depth level:\n\n### High-Level PRD\n- Create 1-2 tasks per feature\n- Focus on feature-level deliverables\n- Minimal technical breakdown\n- Example: \"Implement user authentication feature\"\n\n### Detailed PRD\n- Create 3-5 tasks per feature\n- Decompose by functional area\n- Include acceptance criteria from user stories\n- Example: \"Implement login endpoint\", \"Create password validation\"\n\n### Full-Tech PRD\n- Create 5-10 tasks per feature\n- Granular technical decomposition\n- Include data model, API, and test tasks\n- Example: \"Create User model\", \"Implement POST /auth/login\", \"Add User model tests\"\n\n## Merge Strategy for Re-runs\n\nWhen generating tasks for a PRD that already has tasks:\n\n1. **Match by task_uid**: Find existing tasks with same `metadata.task_uid`\n2. **Preserve status**: Never change status of `in_progress` or `completed` tasks\n3. **Update descriptions**: Refresh descriptions if PRD changed\n4. **Add new tasks**: Create tasks for new requirements\n5. **Flag obsolete**: Ask user about tasks that no longer map to PRD\n\n## Reference Files\n\n- `references/decomposition-patterns.md` - Feature decomposition patterns by type\n- `references/dependency-inference.md` - Automatic dependency inference rules\n",
        "plugins/prd-tools/skills/task-generation/references/decomposition-patterns.md": "# Task Decomposition Patterns\n\nThis reference provides patterns for decomposing different types of features into implementation tasks.\n\n## Standard Feature Pattern\n\nFor most features, follow this layered decomposition:\n\n```\n1. Data Model Tasks\n   └─ Create {Entity} data model\n   └─ Create {Entity} database migration\n\n2. API/Service Tasks\n   └─ Implement {action} endpoint\n   └─ Add input validation for {endpoint}\n   └─ Add error handling for {endpoint}\n\n3. Business Logic Tasks\n   └─ Implement {feature} business logic\n   └─ Add {feature} validation rules\n\n4. UI/Frontend Tasks\n   └─ Build {feature} UI component\n   └─ Add {feature} form handling\n   └─ Implement {feature} state management\n\n5. Integration Tasks\n   └─ Integrate {feature} with {system}\n   └─ Configure {feature} in environment\n\n6. Test Tasks\n   └─ Add unit tests for {entity} model\n   └─ Add integration tests for {endpoint}\n   └─ Add E2E tests for {feature} workflow\n```\n\n## Authentication Feature Pattern\n\n```\n1. Data Models\n   └─ Create User data model\n   └─ Create Session/Token data model\n\n2. Security Infrastructure\n   └─ Configure password hashing\n   └─ Set up JWT/session management\n   └─ Configure secure cookie handling\n\n3. Auth Endpoints\n   └─ Implement registration endpoint\n   └─ Implement login endpoint\n   └─ Implement logout endpoint\n   └─ Implement password reset flow\n\n4. Middleware\n   └─ Create authentication middleware\n   └─ Create authorization middleware\n   └─ Add route protection\n\n5. Frontend Auth\n   └─ Build login form component\n   └─ Build registration form component\n   └─ Add auth state management\n   └─ Implement protected route wrapper\n\n6. Tests\n   └─ Add auth endpoint tests\n   └─ Add auth middleware tests\n   └─ Add auth flow E2E tests\n```\n\n## CRUD Feature Pattern\n\n```\n1. Data Model\n   └─ Create {Resource} data model\n   └─ Add database migration\n\n2. API Endpoints\n   └─ Implement GET /{resources} (list)\n   └─ Implement GET /{resources}/:id (read)\n   └─ Implement POST /{resources} (create)\n   └─ Implement PUT /{resources}/:id (update)\n   └─ Implement DELETE /{resources}/:id (delete)\n\n3. Validation\n   └─ Add {Resource} input validation\n   └─ Add {Resource} business rules\n\n4. UI Components\n   └─ Build {Resource} list view\n   └─ Build {Resource} detail view\n   └─ Build {Resource} form (create/edit)\n   └─ Add {Resource} delete confirmation\n\n5. Tests\n   └─ Add {Resource} model tests\n   └─ Add {Resource} API tests\n   └─ Add {Resource} UI tests\n```\n\n## Integration Feature Pattern\n\n```\n1. Configuration\n   └─ Add {Integration} configuration schema\n   └─ Set up {Integration} credentials management\n\n2. Client/SDK\n   └─ Create {Integration} client wrapper\n   └─ Implement {Integration} API methods\n   └─ Add retry/error handling\n\n3. Data Mapping\n   └─ Create {Integration} data transformers\n   └─ Map external data to internal models\n\n4. Sync/Webhook Handling\n   └─ Implement {Integration} sync logic\n   └─ Add webhook endpoint for {Integration}\n   └─ Handle {Integration} events\n\n5. Monitoring\n   └─ Add {Integration} health checks\n   └─ Implement {Integration} logging\n   └─ Add {Integration} metrics\n\n6. Tests\n   └─ Add {Integration} client tests (mocked)\n   └─ Add {Integration} integration tests\n```\n\n## Background Job Pattern\n\n```\n1. Job Infrastructure\n   └─ Set up job queue system\n   └─ Configure job workers\n\n2. Job Implementation\n   └─ Create {Job} job class\n   └─ Implement {Job} processing logic\n   └─ Add {Job} retry logic\n\n3. Scheduling\n   └─ Configure {Job} schedule\n   └─ Add {Job} trigger endpoints\n\n4. Monitoring\n   └─ Add {Job} status tracking\n   └─ Implement {Job} failure alerts\n   └─ Add {Job} metrics/logging\n\n5. Tests\n   └─ Add {Job} unit tests\n   └─ Add {Job} integration tests\n```\n\n## Migration/Refactoring Pattern\n\n```\n1. Analysis\n   └─ Audit current {system} implementation\n   └─ Document migration requirements\n\n2. Preparation\n   └─ Create {new} implementation alongside {old}\n   └─ Add feature flag for {migration}\n\n3. Migration\n   └─ Implement {new} functionality\n   └─ Add data migration scripts\n   └─ Create rollback procedures\n\n4. Transition\n   └─ Enable {new} for subset of users\n   └─ Monitor {new} performance\n   └─ Fix issues discovered in {new}\n\n5. Cleanup\n   └─ Remove {old} implementation\n   └─ Remove feature flag\n   └─ Update documentation\n```\n\n## Task Subject Guidelines\n\nUse imperative mood for task subjects:\n\n| Good | Bad |\n|------|-----|\n| Create User data model | User data model |\n| Implement login endpoint | Login endpoint implementation |\n| Add input validation | Input validation added |\n| Build dashboard component | Dashboard component |\n\n## Task Description Template\n\n```markdown\n{Brief description of what needs to be done}\n\n{If applicable: Fields, endpoints, or components to create}\n\nAcceptance Criteria:\n- [ ] Criterion 1\n- [ ] Criterion 2\n- [ ] Criterion 3\n\nSource: {PRD path} Section {number}\n```\n\n## Complexity Indicators\n\nUse these indicators to estimate complexity:\n\n**XS Indicators:**\n- Single function or constant\n- Copy/adapt existing pattern\n- Configuration change only\n\n**S Indicators:**\n- Single file change\n- Straightforward logic\n- Well-defined inputs/outputs\n\n**M Indicators:**\n- 2-5 files affected\n- Moderate business logic\n- Some edge cases to handle\n\n**L Indicators:**\n- Multiple components\n- Complex business logic\n- Significant testing required\n- Cross-cutting concerns\n\n**XL Indicators:**\n- System-wide changes\n- Complex integrations\n- Major architectural decisions\n- Extensive testing/migration\n",
        "plugins/prd-tools/skills/task-generation/references/dependency-inference.md": "# Dependency Inference Rules\n\nThis reference provides rules for automatically inferring dependencies between tasks based on their type and relationships.\n\n## Core Dependency Principles\n\n1. **Data flows down**: Higher layers depend on lower layers\n2. **Tests depend on implementation**: Can't test what doesn't exist\n3. **Integration depends on components**: Can't integrate without parts\n4. **Explicit PRD dependencies override inferred**: If PRD specifies, use that\n\n## Layer-Based Dependencies\n\n### Standard Layer Order\n\n```\nLayer 0: Infrastructure/Config\n    ↓\nLayer 1: Data Models\n    ↓\nLayer 2: API/Service\n    ↓\nLayer 3: Business Logic\n    ↓\nLayer 4: UI/Frontend\n    ↓\nLayer 5: Integration/E2E Tests\n```\n\n### Automatic Inference Rules\n\n| Task Type | Depends On (blockedBy) | Blocks |\n|-----------|------------------------|--------|\n| Data Model | Infrastructure tasks | API tasks, Service tasks |\n| Database Migration | Data Model for same entity | API tasks using that model |\n| API Endpoint | Data Model it uses | UI tasks calling it |\n| Service Layer | Data Models it uses | Controller/API tasks |\n| UI Component | API endpoint it calls | E2E tests |\n| Unit Test | Implementation it tests | Nothing |\n| Integration Test | All components it tests | Nothing |\n| E2E Test | Full feature implementation | Nothing |\n\n## Pattern-Based Inference\n\n### Authentication Chain\n\n```\nCreate User model\n    ↓\nCreate Session model\n    ↓\nImplement registration endpoint\n    ↓\nImplement login endpoint → Implement logout endpoint\n    ↓\nCreate auth middleware\n    ↓\nAdd route protection\n    ↓\nBuild login UI → Build registration UI\n    ↓\nAdd auth E2E tests\n```\n\n### CRUD Chain\n\n```\nCreate {Resource} model\n    ↓\nImplement POST /{resources} (create)\n    ↓\nImplement GET /{resources} (list)\n    ↓\nImplement GET /{resources}/:id (read)\n    ↓\nImplement PUT /{resources}/:id (update)\n    ↓\nImplement DELETE /{resources}/:id (delete)\n    ↓\nBuild {Resource} UI components\n    ↓\nAdd {Resource} tests\n```\n\n### Integration Chain\n\n```\nAdd {Integration} config\n    ↓\nCreate {Integration} client\n    ↓\nImplement {Integration} methods\n    ↓\nAdd {Integration} error handling\n    ↓\nCreate data transformers\n    ↓\nImplement sync logic\n    ↓\nAdd {Integration} tests\n```\n\n## PRD-Based Dependencies\n\n### Section 9 (Implementation Plan) Mapping\n\nWhen PRD has implementation phases:\n\n```\nPhase 1 tasks ← Phase 2 tasks ← Phase 3 tasks\n```\n\nAll tasks in Phase N are blocked by completion of Phase N-1.\n\n### Section 10 (Dependencies) Mapping\n\nMap explicit PRD dependencies to task relationships:\n\n| PRD Dependency Type | Task Relationship |\n|---------------------|-------------------|\n| \"requires\" | blockedBy |\n| \"blocks\" | blocks |\n| \"depends on\" | blockedBy |\n| \"prerequisite for\" | blocks |\n\n### User Story Dependencies\n\nWhen user stories reference each other:\n- \"After completing US-001\" → Task for US-002 blockedBy task for US-001\n- \"Builds on US-003\" → blockedBy relationship\n\n## Cross-Feature Dependencies\n\n### Shared Data Models\n\nIf Feature A and Feature B both use User model:\n```\nCreate User model\n    ↓\nFeature A tasks AND Feature B tasks (parallel)\n```\n\n### Shared Services\n\nIf multiple features use AuthService:\n```\nImplement AuthService\n    ↓\nFeature tasks using auth (parallel)\n```\n\n### Infrastructure Dependencies\n\nAll feature tasks implicitly depend on:\n- Database setup (if using database)\n- Authentication setup (if feature requires auth)\n- Core configuration\n\n## Dependency Detection Signals\n\n### Keywords Indicating Dependencies\n\n**In task description:**\n- \"using {Entity}\" → depends on Entity model task\n- \"calls {endpoint}\" → depends on endpoint task\n- \"extends {Component}\" → depends on component task\n- \"after {Feature}\" → depends on feature completion\n- \"requires {Setup}\" → depends on setup task\n\n**In PRD requirements:**\n- \"Must have {X} before {Y}\" → Y blockedBy X\n- \"{Feature} depends on {Other}\" → Feature blockedBy Other\n- \"Prerequisite: {Task}\" → blockedBy Task\n- \"Cannot start until {X}\" → blockedBy X\n\n## Dependency Validation Rules\n\n### Circular Dependency Detection\n\nNever create:\n```\nTask A → blockedBy → Task B → blockedBy → Task A\n```\n\nIf circular dependency detected:\n1. Log warning\n2. Break cycle at weakest link\n3. Flag for human review\n\n### Excessive Dependency Warning\n\nIf a task has more than 5 direct dependencies:\n1. Consider if task should be split\n2. Flag for human review\n3. Note in task description\n\n### Orphan Task Warning\n\nIf a task has no dependencies and doesn't block anything:\n1. Verify it's truly independent\n2. May indicate missing relationship\n3. Flag for human review if unexpected\n\n## Dependency Representation\n\n### In TaskCreate Metadata\n\n```json\n{\n  \"metadata\": {\n    \"inferred_dependencies\": [\"task-uid-1\", \"task-uid-2\"],\n    \"dependency_reason\": \"API endpoint depends on data model\"\n  }\n}\n```\n\n### In TaskUpdate for blockedBy\n\nAfter creating all tasks, use TaskUpdate to set dependencies:\n\n```\nTaskUpdate:\n  taskId: \"3\"\n  addBlockedBy: [\"1\", \"2\"]\n```\n\n## Manual Override Indicators\n\nAllow human override of inferred dependencies when:\n- PRD explicitly states different relationship\n- User confirms tasks can be parallel\n- Domain knowledge indicates independence\n\nMark overridden dependencies:\n```json\n{\n  \"metadata\": {\n    \"dependency_override\": true,\n    \"override_reason\": \"User confirmed parallel execution is safe\"\n  }\n}\n```\n",
        "plugins/ralph-mission/.claude-plugin/plugin.json": "{\n  \"name\": \"ralph-mission\",\n  \"version\": \"0.1.0\",\n  \"description\": \"Mission-driven autonomous loop - iterate through mission-control tasks until all are complete\",\n  \"author\": {\n    \"name\": \"Stephen Sequenzia\",\n    \"email\": \"sequenzia@gmail.com\"\n  }\n}\n",
        "plugins/ralph-mission/README.md": "# Ralph Mission\n\nMission-driven autonomous development loop for Claude Code. Iterates through tasks from a mission-control tasks.json file, implementing each one until all are complete.\n\n## Overview\n\nRalph Mission combines the Ralph Wiggum Loop pattern with mission-control's task management system. Instead of repeating the same prompt, it picks the next highest-priority task and works on it autonomously.\n\n## Installation\n\nEnsure this plugin is in your Claude Code plugins directory and enabled in settings.\n\n**Requires:** `jq` (JSON processor)\n```bash\n# macOS\nbrew install jq\n\n# Ubuntu/Debian\nsudo apt install jq\n```\n\n## Usage\n\n### Start a Mission Loop\n\n```bash\n/ralph-mission <path-to-tasks.json> [options]\n```\n\n**Arguments:**\n- `<mission-path>` - Path to mission-control tasks.json file (required)\n\n**Options:**\n- `--max-iterations N` - Maximum iterations before auto-stop (default: 50)\n- `--max-failed-attempts N` - Attempts per task before marking blocked (default: 3)\n- `--help` - Show help\n\n**Examples:**\n```bash\n# Basic usage\n/ralph-mission missions/auth-system/spec.tasks.json\n\n# With iteration limit\n/ralph-mission missions/api/tasks.json --max-iterations 100\n\n# With custom failure threshold\n/ralph-mission tasks.json --max-failed-attempts 5\n```\n\n### Monitor Progress\n\n```bash\n/ralph-mission:status\n```\n\nShows:\n- Current task and attempts\n- Completion progress\n- Iteration count\n\n### Cancel Loop\n\n```bash\n/ralph-mission:cancel\n```\n\nImmediately stops the loop and shows summary.\n\n## How It Works\n\n### Task Selection (Priority Scoring)\n\nTasks are selected by priority score:\n```\nscore = (priority_weight × 100) + (blocks_count × 50) + complexity_bonus\n```\n\n| Priority | Weight |\n|----------|--------|\n| critical | 4 |\n| high | 3 |\n| medium | 2 |\n| low | 1 |\n\n| Complexity | Bonus |\n|------------|-------|\n| XS | +15 |\n| S | +10 |\n| M | +5 |\n| L | 0 |\n| XL | -5 |\n\nOnly tasks with `status: \"not_started\"` and empty `blocked_by` are considered.\n\n### Completion Detection\n\nThe loop detects task completion by reading the tasks.json file. When you complete a task:\n\n1. Edit the tasks.json file\n2. Find the current task by ID\n3. Change `\"status\": \"not_started\"` to `\"status\": \"complete\"`\n4. Commit your changes\n\nThe stop hook reads the file and detects the status change.\n\n### Failure Handling\n\nIf a task isn't completed after `max_failed_attempts`:\n1. The task is marked as `\"blocked\"` in the JSON file\n2. The loop moves to the next available task\n3. Failure is logged to progress.txt\n\n### Progress Tracking\n\nLearnings and session history are logged to `progress.txt` in the mission directory:\n\n```\nmissions/my-project/\n├── spec.tasks.json    # Task data\n└── progress.txt       # Session log\n```\n\n## Workflow\n\n```\n1. Generate tasks with mission-control\n   /mission-control:generate \"My Project\" spec.md\n\n2. Start ralph-mission\n   /ralph-mission missions/my-project/spec.tasks.json\n\n3. For each task:\n   a. Claude implements the task\n   b. Verifies acceptance criteria\n   c. Updates task status to \"complete\"\n   d. Commits: feat: TASK-XXX - <title>\n   e. Loop automatically continues to next task\n\n4. Loop ends when:\n   - All tasks complete\n   - All remaining tasks blocked\n   - Max iterations reached\n   - User runs /ralph-mission:cancel\n```\n\n## Key Differences from ralph-loop\n\n| Aspect | ralph-loop | ralph-mission |\n|--------|------------|---------------|\n| Task Source | Single prompt | mission-control tasks.json |\n| Loop Condition | Same prompt repeatedly | Pick next task by priority |\n| Completion | `<promise>` tag match | Task status in JSON |\n| Progress | Iteration counter | Task completion + progress.txt |\n| Commits | Optional | Required per task |\n\n## State File\n\nLoop state is stored in `.claude/ralph-mission.local.md`:\n\n```yaml\n---\nactive: true\nmission_path: \"missions/my-project/spec.tasks.json\"\nmission_name: \"My Project\"\ncurrent_task_id: \"TASK-001\"\niteration: 1\nmax_iterations: 50\nmax_failed_attempts: 3\ncurrent_attempts: 0\nstarted_at: \"2025-01-22T14:30:00Z\"\n---\n```\n\n## Safety Features\n\n1. **Max iterations** - Prevents infinite loops (default: 50)\n2. **Max attempts** - Moves on from stuck tasks (default: 3)\n3. **Progress logging** - Tracks all activity\n4. **Git commits** - Required for each task, provides rollback points\n5. **Dependency blocking** - Won't start tasks with unmet dependencies\n\n## Troubleshooting\n\n### \"jq not installed\"\nInstall jq: `brew install jq` or `apt install jq`\n\n### \"No available tasks\"\nAll remaining tasks may be blocked by dependencies. Check the tasks.json for `blocked_by` arrays.\n\n### \"Invalid mission file format\"\nEnsure the file matches mission-control schema:\n```json\n{\n  \"mission\": {\n    \"name\": \"...\",\n    \"tasks\": [...]\n  }\n}\n```\n\n### Loop stuck on same task\nCheck that you're updating the task status in the JSON file, not just in memory.\n\n## Related Plugins\n\n- **mission-control** - Generate task lists from specifications\n- **ralph-loop** - Simple prompt-based looping\n- **dev-tools** - Git commit automation\n\n## License\n\nMIT\n",
        "plugins/ralph-mission/commands/cancel.md": "---\ndescription: \"Cancel active Ralph Mission loop\"\nallowed-tools: [\"Bash(test -f .claude/ralph-mission.local.md:*)\", \"Bash(rm .claude/ralph-mission.local.md)\", \"Read(.claude/ralph-mission.local.md)\"]\nhide-from-slash-command-tool: \"true\"\n---\n\n# Cancel Ralph Mission\n\nTo cancel the Ralph Mission loop:\n\n1. Check if `.claude/ralph-mission.local.md` exists using Bash: `test -f .claude/ralph-mission.local.md && echo \"EXISTS\" || echo \"NOT_FOUND\"`\n\n2. **If NOT_FOUND**: Say \"No active Ralph Mission loop found.\"\n\n3. **If EXISTS**:\n   - Read `.claude/ralph-mission.local.md` to get the current state:\n     - `iteration` - current iteration number\n     - `current_task_id` - the task being worked on\n     - `mission_name` - name of the mission\n   - Remove the file using Bash: `rm .claude/ralph-mission.local.md`\n   - Report cancellation summary:\n     ```\n     Cancelled Ralph Mission loop\n     - Mission: <mission_name>\n     - Current task: <current_task_id>\n     - Iteration: <iteration>\n     ```\n",
        "plugins/ralph-mission/commands/ralph-mission.md": "---\ndescription: \"Start Ralph Mission loop to autonomously complete mission-control tasks\"\nargument-hint: \"<mission-path> [--max-iterations N] [--max-failed-attempts N]\"\nallowed-tools: [\"Bash(${CLAUDE_PLUGIN_ROOT}/scripts/setup-ralph-mission.sh:*)\"]\nhide-from-slash-command-tool: \"true\"\n---\n\n# Ralph Mission Command\n\nExecute the setup script to initialize the Ralph Mission loop:\n\n```!\n\"${CLAUDE_PLUGIN_ROOT}/scripts/setup-ralph-mission.sh\" $ARGUMENTS\n```\n\n## How It Works\n\nRalph Mission autonomously iterates through tasks from a mission-control tasks.json file. For each task:\n\n1. **Implement** the task completely based on its description and acceptance criteria\n2. **Verify** all acceptance criteria are met\n3. **Run tests** if applicable\n4. **Update the task status** in the tasks.json file:\n   - Edit the mission file\n   - Find the current task by ID\n   - Change `\"status\": \"not_started\"` to `\"status\": \"complete\"`\n5. **Commit** your changes with: `feat: TASK-XXX - <title>`\n\n## Important Rules\n\n- **Do NOT mark a task complete unless ALL acceptance criteria are genuinely met**\n- The loop detects completion by checking the task status in the JSON file\n- Failed attempts (task not completed after your response) increment a counter\n- After max failed attempts, the task is marked as \"blocked\" and we move on\n- Progress and learnings are logged to `progress.txt` in the mission directory\n\n## Stopping the Loop\n\nThe loop stops when:\n- All tasks are complete\n- All remaining tasks are blocked\n- Max iterations is reached\n- You run `/ralph-mission:cancel`\n\nTrust the process - the loop continues until genuine completion.\n",
        "plugins/ralph-mission/commands/status.md": "---\ndescription: \"Show Ralph Mission loop progress\"\nallowed-tools: [\"Read\", \"Bash(jq:*)\"]\nhide-from-slash-command-tool: \"true\"\n---\n\n# Ralph Mission Status\n\nTo show the current Ralph Mission status:\n\n1. Check if `.claude/ralph-mission.local.md` exists by reading it\n\n2. **If file doesn't exist**: Say \"No active Ralph Mission loop.\"\n\n3. **If file exists**, parse the YAML frontmatter to extract:\n   - `mission_path` - path to tasks.json\n   - `mission_name` - name of the mission\n   - `current_task_id` - task being worked on\n   - `iteration` - current iteration\n   - `max_iterations` - safety limit\n   - `max_failed_attempts` - attempts per task\n   - `current_attempts` - attempts on current task\n   - `started_at` - when loop started\n\n4. Read the tasks.json file from `mission_path` and calculate:\n   - Total tasks\n   - Completed tasks\n   - Blocked tasks\n   - Remaining tasks (not_started + in_progress)\n   - Completion percentage\n\n5. Display status report:\n\n```\n🔄 Ralph Mission Status\n\nMission: <mission_name>\nSource: <mission_path>\nStarted: <started_at>\n\nCurrent Task: <current_task_id>\nAttempts: <current_attempts>/<max_failed_attempts>\n\nProgress:\n  ✅ Completed: X tasks\n  🚫 Blocked: Y tasks\n  ⏳ Remaining: Z tasks\n  📊 Overall: XX%\n\nLoop:\n  Iteration: <iteration>/<max_iterations or \"unlimited\">\n```\n\nIf there's a `progress.txt` file in the mission directory, mention that learnings are being recorded there.\n",
        "plugins/ralph-mission/hooks/hooks.json": "{\n  \"description\": \"Ralph Mission plugin stop hook for mission-driven autonomous loops\",\n  \"hooks\": {\n    \"Stop\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"${CLAUDE_PLUGIN_ROOT}/hooks/stop-hook.sh\"\n          }\n        ]\n      }\n    ]\n  }\n}\n",
        "plugins/ralph-mission/hooks/stop-hook.sh": "#!/bin/bash\n\n# Ralph Mission Stop Hook\n# Prevents session exit when a ralph-mission loop is active\n# Iterates through mission-control tasks until all complete\n\nset -euo pipefail\n\n# Read hook input from stdin (advanced stop hook API)\nHOOK_INPUT=$(cat)\n\n# Check if ralph-mission is active\nRALPH_STATE_FILE=\".claude/ralph-mission.local.md\"\n\nif [[ ! -f \"$RALPH_STATE_FILE\" ]]; then\n  # No active loop - allow exit\n  exit 0\nfi\n\n# Parse markdown frontmatter (YAML between ---) and extract values\nFRONTMATTER=$(sed -n '/^---$/,/^---$/{ /^---$/d; p; }' \"$RALPH_STATE_FILE\")\n\n# Extract state values\nMISSION_PATH=$(echo \"$FRONTMATTER\" | grep '^mission_path:' | sed 's/mission_path: *//' | sed 's/^\"\\(.*\\)\"$/\\1/')\nMISSION_NAME=$(echo \"$FRONTMATTER\" | grep '^mission_name:' | sed 's/mission_name: *//' | sed 's/^\"\\(.*\\)\"$/\\1/')\nCURRENT_TASK_ID=$(echo \"$FRONTMATTER\" | grep '^current_task_id:' | sed 's/current_task_id: *//' | sed 's/^\"\\(.*\\)\"$/\\1/')\nITERATION=$(echo \"$FRONTMATTER\" | grep '^iteration:' | sed 's/iteration: *//')\nMAX_ITERATIONS=$(echo \"$FRONTMATTER\" | grep '^max_iterations:' | sed 's/max_iterations: *//')\nMAX_FAILED_ATTEMPTS=$(echo \"$FRONTMATTER\" | grep '^max_failed_attempts:' | sed 's/max_failed_attempts: *//')\nCURRENT_ATTEMPTS=$(echo \"$FRONTMATTER\" | grep '^current_attempts:' | sed 's/current_attempts: *//')\n\n# Validate numeric fields\nfor field_name in ITERATION MAX_ITERATIONS MAX_FAILED_ATTEMPTS CURRENT_ATTEMPTS; do\n  field_value=\"${!field_name}\"\n  if [[ ! \"$field_value\" =~ ^[0-9]+$ ]]; then\n    echo \"⚠️  Ralph Mission: State file corrupted\" >&2\n    echo \"   File: $RALPH_STATE_FILE\" >&2\n    echo \"   Problem: '$field_name' is not a valid number (got: '$field_value')\" >&2\n    echo \"   Ralph Mission is stopping. Run /ralph-mission again to start fresh.\" >&2\n    rm \"$RALPH_STATE_FILE\"\n    exit 0\n  fi\ndone\n\n# Check if max iterations reached\nif [[ $MAX_ITERATIONS -gt 0 ]] && [[ $ITERATION -ge $MAX_ITERATIONS ]]; then\n  echo \"🛑 Ralph Mission: Max iterations ($MAX_ITERATIONS) reached.\"\n  echo \"   Mission: $MISSION_NAME\"\n  rm \"$RALPH_STATE_FILE\"\n  exit 0\nfi\n\n# Validate mission file exists\nif [[ ! -f \"$MISSION_PATH\" ]]; then\n  echo \"⚠️  Ralph Mission: Mission file not found\" >&2\n  echo \"   Expected: $MISSION_PATH\" >&2\n  echo \"   Ralph Mission is stopping.\" >&2\n  rm \"$RALPH_STATE_FILE\"\n  exit 0\nfi\n\n# Check jq is available\nif ! command -v jq &> /dev/null; then\n  echo \"⚠️  Ralph Mission: jq is required but not installed\" >&2\n  echo \"   Install with: brew install jq (macOS) or apt install jq (Linux)\" >&2\n  rm \"$RALPH_STATE_FILE\"\n  exit 0\nfi\n\n# Read mission data\nMISSION_DATA=$(cat \"$MISSION_PATH\")\n\n# Get mission directory for progress file\nMISSION_DIR=$(dirname \"$MISSION_PATH\")\nPROGRESS_FILE=\"$MISSION_DIR/progress.txt\"\n\n# Get current task status\nCURRENT_TASK_STATUS=$(echo \"$MISSION_DATA\" | jq -r --arg id \"$CURRENT_TASK_ID\" '\n  .mission.tasks[] | select(.id == $id) | .status\n')\n\n# Get counts for progress tracking\nTOTAL_TASKS=$(echo \"$MISSION_DATA\" | jq '.mission.tasks | length')\nCOMPLETED_TASKS=$(echo \"$MISSION_DATA\" | jq '[.mission.tasks[] | select(.status == \"complete\")] | length')\nBLOCKED_TASKS=$(echo \"$MISSION_DATA\" | jq '[.mission.tasks[] | select(.status == \"blocked\")] | length')\n\n# Calculate timestamp\nTIMESTAMP=$(date -u +\"%Y-%m-%d %H:%M:%S UTC\")\n\n# Initialize progress file if it doesn't exist\nif [[ ! -f \"$PROGRESS_FILE\" ]]; then\n  cat > \"$PROGRESS_FILE\" << EOF\n# Ralph Mission Progress\nMission: $MISSION_NAME\nStarted: $TIMESTAMP\nSource: $MISSION_PATH\n\n## Session Log\n\nEOF\nfi\n\n# Function to find next ready task using priority scoring\nfind_next_task() {\n  echo \"$MISSION_DATA\" | jq -r '\n    # Priority weights\n    def priority_weight:\n      if . == \"critical\" then 4\n      elif . == \"high\" then 3\n      elif . == \"medium\" then 2\n      elif . == \"low\" then 1\n      else 1\n      end;\n\n    # Complexity bonus (simpler tasks get higher scores)\n    def complexity_bonus:\n      if . == \"XS\" then 15\n      elif . == \"S\" then 10\n      elif . == \"M\" then 5\n      elif . == \"L\" then 0\n      elif . == \"XL\" then -5\n      else 0\n      end;\n\n    # Filter for ready tasks (not_started and not blocked)\n    [.mission.tasks[] | select(.status == \"not_started\" and (.blocked_by | length) == 0)]\n\n    # Calculate scores and sort\n    | map(. + {\n        score: ((.priority | priority_weight) * 100) +\n               ((.blocks // []) | length) * 50 +\n               (.complexity | complexity_bonus)\n      })\n    | sort_by(-.score)\n\n    # Return first task ID or empty\n    | if length > 0 then .[0].id else \"\" end\n  '\n}\n\n# Handle current task status\nif [[ \"$CURRENT_TASK_STATUS\" == \"complete\" ]]; then\n  # Task completed! Log success and find next task\n  CURRENT_TASK_TITLE=$(echo \"$MISSION_DATA\" | jq -r --arg id \"$CURRENT_TASK_ID\" '\n    .mission.tasks[] | select(.id == $id) | .title\n  ')\n\n  # Log completion to progress file\n  cat >> \"$PROGRESS_FILE\" << EOF\n### Iteration $ITERATION - $TIMESTAMP\nTask: $CURRENT_TASK_ID - $CURRENT_TASK_TITLE\nStatus: COMPLETED ✅\n\nEOF\n\n  # Find next task\n  NEXT_TASK_ID=$(find_next_task)\n\n  if [[ -z \"$NEXT_TASK_ID\" ]]; then\n    # Check if all tasks complete or all remaining are blocked\n    REMAINING=$(echo \"$MISSION_DATA\" | jq '[.mission.tasks[] | select(.status == \"not_started\" or .status == \"in_progress\")] | length')\n\n    if [[ $REMAINING -eq 0 ]]; then\n      # All tasks complete!\n      echo \"✅ Ralph Mission: ALL TASKS COMPLETE!\"\n      echo \"   Mission: $MISSION_NAME\"\n      echo \"   Completed: $((COMPLETED_TASKS)) tasks in $ITERATION iterations\"\n\n      # Log summary\n      cat >> \"$PROGRESS_FILE\" << EOF\n## Mission Complete! 🎉\n\n- Total iterations: $ITERATION\n- Tasks completed: $COMPLETED_TASKS\n- Tasks blocked: $BLOCKED_TASKS\n- Finished: $TIMESTAMP\nEOF\n\n      rm \"$RALPH_STATE_FILE\"\n      exit 0\n    else\n      # All remaining tasks are blocked\n      echo \"⚠️  Ralph Mission: All remaining tasks are blocked\"\n      echo \"   Mission: $MISSION_NAME\"\n      echo \"   Remaining: $REMAINING tasks (blocked by dependencies)\"\n\n      cat >> \"$PROGRESS_FILE\" << EOF\n## Mission Stalled\n\nAll remaining tasks are blocked by dependencies.\n- Completed: $COMPLETED_TASKS\n- Blocked: $BLOCKED_TASKS\n- Remaining (blocked): $REMAINING\nEOF\n\n      rm \"$RALPH_STATE_FILE\"\n      exit 0\n    fi\n  fi\n\n  # Update state for next task\n  CURRENT_TASK_ID=\"$NEXT_TASK_ID\"\n  CURRENT_ATTEMPTS=0\n\nelse\n  # Task not complete - increment attempts\n  CURRENT_ATTEMPTS=$((CURRENT_ATTEMPTS + 1))\n\n  if [[ $CURRENT_ATTEMPTS -ge $MAX_FAILED_ATTEMPTS ]]; then\n    # Max attempts reached - mark task as blocked\n    CURRENT_TASK_TITLE=$(echo \"$MISSION_DATA\" | jq -r --arg id \"$CURRENT_TASK_ID\" '\n      .mission.tasks[] | select(.id == $id) | .title\n    ')\n\n    # Update task status to blocked in JSON file\n    UPDATED_MISSION=$(echo \"$MISSION_DATA\" | jq --arg id \"$CURRENT_TASK_ID\" '\n      .mission.tasks = [.mission.tasks[] |\n        if .id == $id then .status = \"blocked\" else . end\n      ]\n    ')\n    echo \"$UPDATED_MISSION\" > \"$MISSION_PATH\"\n    MISSION_DATA=\"$UPDATED_MISSION\"\n\n    # Log failure\n    cat >> \"$PROGRESS_FILE\" << EOF\n### Iteration $ITERATION - $TIMESTAMP\nTask: $CURRENT_TASK_ID - $CURRENT_TASK_TITLE\nStatus: BLOCKED 🚫 (after $MAX_FAILED_ATTEMPTS attempts)\nReason: Failed to complete after maximum attempts\n\nEOF\n\n    # Find next task\n    NEXT_TASK_ID=$(find_next_task)\n\n    if [[ -z \"$NEXT_TASK_ID\" ]]; then\n      echo \"⚠️  Ralph Mission: No more available tasks\"\n      echo \"   Last task blocked: $CURRENT_TASK_ID\"\n      rm \"$RALPH_STATE_FILE\"\n      exit 0\n    fi\n\n    CURRENT_TASK_ID=\"$NEXT_TASK_ID\"\n    CURRENT_ATTEMPTS=0\n  fi\nfi\n\n# Increment iteration\nNEXT_ITERATION=$((ITERATION + 1))\n\n# Get current task details for prompt\nCURRENT_TASK=$(echo \"$MISSION_DATA\" | jq --arg id \"$CURRENT_TASK_ID\" '\n  .mission.tasks[] | select(.id == $id)\n')\n\nTASK_TITLE=$(echo \"$CURRENT_TASK\" | jq -r '.title')\nTASK_DESC=$(echo \"$CURRENT_TASK\" | jq -r '.description')\nTASK_PRIORITY=$(echo \"$CURRENT_TASK\" | jq -r '.priority')\nTASK_COMPLEXITY=$(echo \"$CURRENT_TASK\" | jq -r '.complexity')\nTASK_CRITERIA=$(echo \"$CURRENT_TASK\" | jq -r '.acceptance_criteria | map(\"- [ ] \" + .) | join(\"\\n\")')\nTASK_DEPS=$(echo \"$CURRENT_TASK\" | jq -r '.dependencies // [] | if length > 0 then join(\", \") else \"None\" end')\nTASK_BLOCKS=$(echo \"$CURRENT_TASK\" | jq -r '.blocks // [] | if length > 0 then join(\", \") else \"None\" end')\nTASK_SOURCE=$(echo \"$CURRENT_TASK\" | jq -r '.source_requirements // [] | join(\", \")')\nTASK_NOTES=$(echo \"$CURRENT_TASK\" | jq -r '.notes // \"\"')\n\n# Get previous learnings if progress file exists\nLEARNINGS=\"First iteration - no learnings yet\"\nif [[ -f \"$PROGRESS_FILE\" ]]; then\n  # Get last 20 lines of progress for context\n  LEARNINGS=$(tail -50 \"$PROGRESS_FILE\" | head -30)\nfi\n\n# Calculate completion percentage\nCOMPLETION_PCT=$((COMPLETED_TASKS * 100 / TOTAL_TASKS))\n\n# Build the prompt\nPROMPT=$(cat << EOF\n## Ralph Mission - Iteration $NEXT_ITERATION | Task $((COMPLETED_TASKS + 1))/$TOTAL_TASKS\n\n### Mission: $MISSION_NAME\n**Progress:** $COMPLETED_TASKS/$TOTAL_TASKS tasks ($COMPLETION_PCT%)\n\n---\n\n### Current Task: $CURRENT_TASK_ID\n**$TASK_TITLE**\n**Priority:** $TASK_PRIORITY | **Complexity:** $TASK_COMPLEXITY\n\n$TASK_DESC\n\n### Acceptance Criteria\n$TASK_CRITERIA\n\n### Context\n**Depends on:** $TASK_DEPS\n**Blocks:** $TASK_BLOCKS\n**Source:** $TASK_SOURCE\n$(if [[ -n \"$TASK_NOTES\" ]]; then echo -e \"\\n**Notes:** $TASK_NOTES\"; fi)\n\n### Previous Learnings\n\\`\\`\\`\n$LEARNINGS\n\\`\\`\\`\n\n---\n\n## Instructions\n\n1. **Implement** this task completely\n2. **Verify** all acceptance criteria are met\n3. **Run tests** if applicable\n4. **Update task status** in $MISSION_PATH:\n   - Edit the file\n   - Find task $CURRENT_TASK_ID\n   - Set \"status\": \"complete\"\n5. **Commit** your changes with message: \\`feat: $CURRENT_TASK_ID - $TASK_TITLE\\`\n\n## Completion\n\nWhen this task is FULLY complete:\n- All acceptance criteria verified\n- Status updated to \"complete\" in tasks.json\n- Changes committed to git\n\nThe loop will automatically detect completion and proceed to the next task.\n\n⚠️ Do NOT update status to \"complete\" unless ALL criteria are met.\n   The loop continues until genuine completion.\nEOF\n)\n\n# Update state file\ncat > \"$RALPH_STATE_FILE\" << EOF\n---\nactive: true\nmission_path: \"$MISSION_PATH\"\nmission_name: \"$MISSION_NAME\"\ncurrent_task_id: \"$CURRENT_TASK_ID\"\niteration: $NEXT_ITERATION\nmax_iterations: $MAX_ITERATIONS\nmax_failed_attempts: $MAX_FAILED_ATTEMPTS\ncurrent_attempts: $CURRENT_ATTEMPTS\nstarted_at: \"$(echo \"$FRONTMATTER\" | grep '^started_at:' | sed 's/started_at: *//' | sed 's/^\"\\(.*\\)\"$/\\1/')\"\n---\nEOF\n\n# Build system message\nSYSTEM_MSG=\"🔄 Ralph Mission iteration $NEXT_ITERATION | Task: $CURRENT_TASK_ID ($TASK_TITLE) | Attempt: $((CURRENT_ATTEMPTS + 1))/$MAX_FAILED_ATTEMPTS | Progress: $COMPLETED_TASKS/$TOTAL_TASKS complete\"\n\n# Output JSON to block the stop and feed prompt back\njq -n \\\n  --arg prompt \"$PROMPT\" \\\n  --arg msg \"$SYSTEM_MSG\" \\\n  '{\n    \"decision\": \"block\",\n    \"reason\": $prompt,\n    \"systemMessage\": $msg\n  }'\n\nexit 0\n",
        "plugins/task-manager/.claude-plugin/plugin.json": "{\n  \"name\": \"task-manager\",\n  \"version\": \"0.1.0\",\n  \"description\": \"Spec Driven Development document management - conducts dynamic interviews to generate PRDs, Tech Specs, and Design Specs optimized for AI coding agents\",\n  \"author\": {\n    \"name\": \"Stephen Sequenzia\",\n    \"email\": \"sequenzia@gmail.com\"\n  }\n}",
        "plugins/task-manager/README.md": "# spec-task-manager\n",
        "plugins/task-manager/agents/spec-analyzer.md": "---\nname: spec-analyzer\ndescription: Use this agent proactively when specification documents are detected in the project, or when the user needs help analyzing specs and generating task lists. This agent detects PRDs, technical specifications, design documents, and requirements documents by filename patterns (*spec*, *prd*, *requirements*, *design-doc*) or location (specs/, docs/, requirements/ directories). Examples:\n\n<example>\nContext: User opens a project and you notice a file named \"feature-spec.md\" or \"prd-authentication.md\" in the root or docs/ directory\nuser: \"Help me implement this feature\"\nassistant: \"I notice there's a specification document in your project. Let me use the spec-analyzer agent to analyze it and generate a structured task list that will help guide the implementation.\"\n<commentary>\nThe agent should trigger proactively when spec documents are detected and the user is starting implementation work. This helps ensure work is properly planned before coding begins.\n</commentary>\n</example>\n\n<example>\nContext: User is exploring a codebase and you find files matching spec patterns\nuser: \"What should I work on first?\"\nassistant: \"I found specification documents in your project. Let me analyze them with the spec-analyzer agent to generate prioritized task lists and recommend what to work on first.\"\n<commentary>\nWhen users ask about what to work on, and spec documents exist, the agent should analyze them to provide informed recommendations.\n</commentary>\n</example>\n\n<example>\nContext: User explicitly mentions they have requirements or a PRD to implement\nuser: \"I need to implement the features described in requirements.md\"\nassistant: \"I'll use the spec-analyzer agent to parse your requirements document and create a structured task list with dependencies and priorities.\"\n<commentary>\nDirect requests to work from specification documents should trigger this agent to ensure proper task decomposition.\n</commentary>\n</example>\n\n<example>\nContext: User is working on a complex feature without clear structure\nuser: \"This feature has a lot of parts, I'm not sure where to start\"\nassistant: \"Let me check if there's a specification document for this feature. If so, I can use the spec-analyzer agent to break it down into manageable tasks with clear dependencies.\"\n<commentary>\nWhen users express uncertainty about complex work, checking for and analyzing specs can provide structure.\n</commentary>\n</example>\n\nmodel: inherit\ncolor: cyan\ntools: [\"Read\", \"Write\", \"Glob\", \"Grep\"]\n---\n\nYou are a specification analysis agent that transforms requirement documents into structured, actionable task lists optimized for AI coding agents working independently or in parallel.\n\n**Your Core Responsibilities:**\n\n1. Detect and analyze specification documents in the project\n2. Extract explicit and implicit requirements from specifications\n3. Decompose requirements into atomic, independent tasks\n4. Map dependencies between tasks (hard, soft, resource)\n5. Prioritize tasks and organize into execution phases\n6. Generate testing criteria for each task\n\n**Detection Process:**\n\nWhen activated, search for specification documents using these patterns:\n\n1. **Filename patterns:**\n   - `*spec*` (feature-spec.md, api-spec.md, etc.)\n   - `*prd*` (prd-auth.md, product-prd.md, etc.)\n   - `*requirements*` (requirements.md, functional-requirements.md)\n   - `*design-doc*` (design-doc-api.md, etc.)\n\n2. **Directory locations:**\n   - `specs/`\n   - `docs/`\n   - `requirements/`\n   - Root directory\n\n3. **File extensions:**\n   - `.md` (primary focus)\n   - `.txt`\n\n**Analysis Process:**\n\n1. **Read the specification thoroughly**\n   - Parse document structure (headings, lists, sections)\n   - Identify explicit requirements and acceptance criteria\n   - Extract implicit requirements (error handling, edge cases)\n   - Note constraints and scope boundaries\n\n2. **Decompose into atomic tasks**\n   - Each task has single responsibility\n   - Tasks are independent where possible\n   - Tasks have clear start/end conditions\n   - Tasks have verifiable completion criteria\n\n3. **Map dependencies**\n   - Hard: Task B cannot start until Task A completes\n   - Soft: Task B benefits from Task A being complete\n   - Resource: Tasks share files/modules\n\n4. **Prioritize and organize**\n   - Assign priority (critical, high, medium, low)\n   - Estimate complexity (XS, S, M, L, XL)\n   - Group into execution phases\n\n5. **Generate testing criteria**\n   - Acceptance criteria for each task\n   - Test scenarios for verification\n   - Edge cases to consider\n\n**Output:**\n\nGenerate a task list file at `tasks/<project-name>.tasks.json` following this structure:\n\n```json\n{\n  \"metadata\": {\n    \"source_document\": \"<spec path>\",\n    \"generated_at\": \"<ISO-8601>\",\n    \"version\": \"1.0.0\",\n    \"total_tasks\": <count>,\n    \"completion_percentage\": 0\n  },\n  \"tasks\": [...],\n  \"dependency_graph\": {...},\n  \"execution_phases\": [...]\n}\n```\n\n**Reporting:**\n\nAfter analysis, provide:\n1. Summary of what was found\n2. Total tasks generated\n3. Priority breakdown\n4. Execution phases overview\n5. Recommended first tasks to tackle\n\n**Edge Cases:**\n\n- If no spec documents found: Explain how to create one or use /spec-task-manager:analyze manually\n- If spec is ambiguous: Note assumptions in task notes, flag for human review\n- If spec is very large: Process sections incrementally, report progress\n- If existing task list found: Offer to update rather than regenerate\n\n**Quality Standards:**\n\n- Tasks must trace back to specific spec sections\n- Dependencies must be justified\n- Priorities must consider blocking relationships\n- Testing criteria must be verifiable\n- Output must be valid JSON\n",
        "plugins/task-manager/commands/analyze.md": "---\ndescription: Analyze a specification document and generate a structured task list\nargument-hint: <spec-document>\nallowed-tools: Read, Write, Glob\n---\n\nAnalyze the specification document provided and generate a comprehensive task list.\n\n**Input document:** @$ARGUMENTS\n\n## Analysis Process\n\n1. **Read and parse the specification document thoroughly**\n   - Identify all explicit requirements, features, and acceptance criteria\n   - Extract implicit requirements (error handling, infrastructure, etc.)\n   - Note constraints and scope boundaries\n\n2. **Decompose into atomic tasks**\n   - Each task should have single responsibility\n   - Tasks should be independent where possible\n   - Tasks must have clear start/end conditions\n   - Tasks must be testable with verifiable criteria\n\n3. **Map dependencies between tasks**\n   - **Hard dependencies**: Task B cannot start until Task A completes\n   - **Soft dependencies**: Task B benefits from Task A being complete\n   - Calculate `blocked_by` and `blocks` relationships\n\n4. **Assign priorities and complexity**\n   - Priority: critical, high, medium, low (based on dependency depth and risk)\n   - Complexity: XS, S, M, L, XL (T-shirt sizing)\n\n5. **Generate testing criteria for each task**\n   - Acceptance criteria (must be true when complete)\n   - Test scenarios (concrete verification steps)\n   - Edge cases (boundary conditions to consider)\n\n6. **Organize into execution phases**\n   - Phase 1: Tasks with no hard dependencies\n   - Phase 2+: Tasks whose dependencies are satisfied by previous phases\n\n## Output\n\nCreate the `tasks/` directory if it doesn't exist.\n\n### 1. JSON Task File\n\nWrite the task list to `tasks/<project-name>.tasks.json` where `<project-name>` is derived from the specification filename.\n\nUse the JSON schema from the spec-task-management skill for proper formatting:\n- Include full metadata (source_document, generated_at, version, etc.)\n- All tasks with complete properties\n- Dependency graph with nodes and edges\n- Execution phases for parallel work\n\n### 2. Markdown Summary File\n\nWrite a markdown summary to `tasks/<project-name>.tasks.md` with the following format:\n\n```markdown\n# Task Analysis: <project-name>\n\n**Source:** <spec-path>\n**Generated:** <timestamp>\n\n## Summary\n\n- **Total tasks:** X\n- **Execution phases:** Y\n- **Ready to start:** Z\n\n## By Priority\n\n| Priority | Count |\n|----------|-------|\n| Critical | X |\n| High | Y |\n| Medium | Z |\n| Low | W |\n\n## By Complexity\n\n| Size | Count |\n|------|-------|\n| XS | X |\n| S | Y |\n| M | Z |\n| L | W |\n| XL | V |\n\n## Execution Phases\n\n### Phase 1: <phase-name>\n\n| Task | Title | Priority | Complexity |\n|------|-------|----------|------------|\n| TASK-001 | <title> | high | M |\n| TASK-002 | <title> | medium | S |\n\n### Phase 2: <phase-name>\n\n| Task | Title | Priority | Complexity |\n|------|-------|----------|------------|\n| TASK-003 | <title> | high | L |\n\n(continue for all phases)\n\n## Ready to Start\n\nTasks with no blocking dependencies:\n\n- **TASK-001:** <title>\n- **TASK-002:** <title>\n\n## Next Steps\n\n1. View task details: `/spec-task-manager:show TASK-XXX`\n2. Start recommended tasks: `/spec-task-manager:next`\n3. Mark tasks complete: `/spec-task-manager:complete TASK-XXX`\n```\n\n### 3. Display Summary\n\nAfter writing both files, display a brief summary to the console:\n- Total tasks generated\n- Breakdown by priority and complexity\n- Number of execution phases\n- Tasks ready to start (Phase 1)\n- Paths to both output files\n",
        "plugins/task-manager/commands/block.md": "---\ndescription: Mark a task as blocked with a reason\nargument-hint: <task-id> --reason \"<reason>\" [project-name]\nallowed-tools: Read, Write, Glob\n---\n\nMark a task as blocked and document the blocking reason.\n\n## Process\n\n1. **Parse arguments**\n   - Extract task ID from arguments\n   - Extract reason (text after --reason)\n   - Extract optional project name\n\n2. **Locate and read the task file**\n   - If project name provided: Read `tasks/<project>.tasks.json`\n   - If no project name: Find task file containing the specified task ID\n\n3. **Validate**\n   - Confirm task exists\n   - Warn if task is already complete or obsolete\n\n4. **Update the task**\n   - Set status to \"blocked\"\n   - Add blocking reason to `notes` field (append to existing notes)\n   - Format: \"[BLOCKED <timestamp>] <reason>\"\n\n5. **Update metadata**\n   - Update `last_updated` timestamp\n   - Increment version (patch bump)\n\n6. **Write updated task file**\n\n7. **Display confirmation**\n\nFormat output as:\n\n```\n## Task Blocked: TASK-XXX\n\n**<title>** marked as blocked.\n\n**Reason:** <reason>\n\n### Impact Assessment\nTasks depending on this one:\n- TASK-AAA: <title> (also now blocked)\n- TASK-BBB: <title> (also now blocked)\n\n### Resolution Needed\nTo unblock this task:\n1. Address the blocking issue\n2. Use `/spec-task-manager:complete TASK-XXX` when resolved\n\nOr update the task with `/spec-task-manager:update` if requirements changed.\n```\n\nIf no reason provided, prompt for one - blocking should always be documented.\n",
        "plugins/task-manager/commands/complete.md": "---\ndescription: Mark a task as complete and show next recommended tasks\nargument-hint: <task-id> [project-name]\nallowed-tools: Read, Write, Glob\n---\n\nMark a task as complete, update dependencies, and suggest next tasks.\n\n## Process\n\n1. **Parse arguments**\n   - `$1` = Task ID (required, e.g., TASK-001)\n   - `$2` = Project name (optional)\n\n2. **Locate and read the task file**\n   - If project name provided: Read `tasks/$2.tasks.json`\n   - If no project name: Find task file containing the specified task ID\n\n3. **Validate the task**\n   - Confirm task exists\n   - Check current status (warn if already complete or obsolete)\n\n4. **Update the task**\n   - Set status to \"complete\"\n   - Record completion (update last_updated in metadata)\n\n5. **Recalculate dependencies**\n   - For all tasks that have this task in their `dependencies.hard`:\n     - Remove this task from their `blocked_by` array\n   - Recalculate which tasks are now unblocked\n\n6. **Update metrics**\n   - Recalculate `completion_percentage`\n   - Increment metadata version (patch bump)\n   - Update `last_updated` timestamp\n\n7. **Write updated task file**\n\n8. **Display results**\n\nFormat output as:\n\n```\n## Task Completed: TASK-XXX\n\n**<title>** marked as complete.\n\n### Progress Update\n- Completion: X% -> Y% (+Z%)\n- Tasks remaining: N\n\n### Newly Unblocked\nThese tasks can now be started:\n- TASK-AAA: <title> (priority, complexity)\n- TASK-BBB: <title> (priority, complexity)\n\n### Recommended Next Tasks\nBased on priority and complexity:\n\n1. **TASK-CCC**: <title>\n   - Priority: high\n   - Complexity: S\n   - No blockers\n\n2. **TASK-DDD**: <title>\n   - Priority: medium\n   - Complexity: XS\n   - No blockers\n```\n\nIf completing this task unblocks critical-priority tasks, highlight them prominently.\n",
        "plugins/task-manager/commands/context-groups.md": "---\ndescription: Generate context window-aware task groups for AI coding agents\nargument-hint: [project-name] [--max-tokens=N] [--reserve=N]\nallowed-tools: Read, Write, Glob\n---\n\nGenerate context groups from an existing task list, organizing tasks into batches that fit within AI context window limits.\n\n## Process\n\n1. **Parse arguments**\n   - `$1` = Project name (optional)\n   - `--max-tokens=N` = Maximum context window tokens (default: 100000)\n   - `--reserve=N` = Reserved tokens for agent responses (default: 20000)\n\n2. **Locate and read the task file**\n   - If project name provided: Read `tasks/$1.tasks.json`\n   - If no project name: Find most recently modified `.tasks.json`\n\n3. **Load token configuration**\n   - Read defaults from `skills/spec-task-management/references/context-defaults.json`\n   - Apply any command-line overrides\n\n4. **Calculate token estimates for each task**\n\n   Use complexity-based estimation:\n   | Complexity | Base Tokens |\n   |------------|-------------|\n   | XS | 500 |\n   | S | 1,500 |\n   | M | 4,000 |\n   | L | 10,000 |\n   | XL | 25,000 |\n\n   Add overhead:\n   - Base per task: 200 tokens\n   - Per hard dependency: 100 tokens\n\n5. **Build dependency graph**\n   - Create adjacency list from hard dependencies\n   - Detect any cycles (should already be handled)\n   - Calculate in-degree for each task\n\n6. **Topological sort by execution phase**\n   - Order tasks by their execution_phase first\n   - Within phase, order by dependency depth (tasks that unblock more come first)\n   - Break ties by priority (critical > high > medium > low)\n\n7. **Bin-pack tasks into context groups**\n\n   ```\n   effective_limit = max_tokens - reserve_tokens\n   current_group = new group\n   current_tokens = 0\n\n   for each task in sorted_order:\n       # Calculate tokens needed for task + any hard deps not yet assigned\n       task_tokens = estimate_tokens(task)\n       unassigned_dep_tokens = sum(estimate_tokens(d) for d in task.hard_deps if not d.assigned)\n       total_needed = task_tokens + unassigned_dep_tokens\n\n       # Check if task exceeds effective limit (oversized)\n       if task_tokens > effective_limit:\n           # Close current group if not empty\n           if current_group.tasks.length > 0:\n               mark_group_end(current_group.tasks.last)\n               save_group(current_group)\n\n           # Create dedicated group for oversized task\n           oversized_group = new group with oversized_warning=true\n           add_task(oversized_group, task)\n           mark_group_start(task)\n           mark_group_end(task)\n           save_group(oversized_group)\n\n           current_group = new group\n           current_tokens = 0\n           continue\n\n       # Check if adding task exceeds limit\n       if current_tokens + total_needed > effective_limit:\n           # Close current group\n           mark_group_end(current_group.tasks.last)\n           save_group(current_group)\n\n           # Start new group\n           current_group = new group\n           current_tokens = 0\n\n       # Add unassigned hard dependencies first (in order)\n       for dep in task.hard_deps:\n           if not dep.assigned:\n               if current_group.tasks.length == 0:\n                   mark_group_start(dep)\n               add_task(current_group, dep)\n               current_tokens += estimate_tokens(dep)\n\n       # Add the task\n       if current_group.tasks.length == 0:\n           mark_group_start(task)\n       add_task(current_group, task)\n       current_tokens += task_tokens\n\n   # Close final group\n   if current_group.tasks.length > 0:\n       mark_group_end(current_group.tasks.last)\n       save_group(current_group)\n   ```\n\n8. **Handle dependency chains exceeding limit**\n   - If a chain of hard dependencies exceeds limit, split at minimum-cut points\n   - Add `context_handoff` metadata to indicate split\n   - Document which outputs from previous group are needed\n\n9. **Update task file**\n   - Add `context_group_id` to each task\n   - Set `context_group_start` on first task of each group\n   - Set `context_group_end` on last task of each group\n   - Add `estimated_tokens` to each task\n   - Add `context_groups` array at root level\n   - Update `metadata.context_config` with configuration used\n   - Set `metadata.total_context_groups`\n\n10. **Display summary**\n\nFormat output as:\n\n```\n## Context Groups Generated\n\n**Configuration**\n- Max Tokens: 100,000\n- Reserved: 20,000\n- Effective Limit: 80,000\n\n**Summary**\n- Total Tasks: X\n- Total Groups: Y\n- Average Tasks/Group: Z\n\n### Group Breakdown\n\n| Group | Tasks | Est. Tokens | Phases | Status |\n|-------|-------|-------------|--------|--------|\n| CG-001 | 5 | 72,000 | 1, 2 | pending |\n| CG-002 | 4 | 68,500 | 2, 3 | pending |\n| CG-003 | 3 | 45,200 | 3 | pending |\n\n### Warnings\n\n- CG-002: Contains oversized task TASK-015 (XL complexity)\n- CG-003: Dependency chain split from CG-002\n\n---\n\n**Next Steps:**\n- Use `/task-manager:next-group` to get the first group ready for execution\n- Use `/task-manager:show-group CG-001` to see group details\n- Coding agents should reset context between groups\n```\n\n## Edge Cases\n\n### Oversized Task (XL > effective_limit)\n- Place in its own group\n- Add `oversized_warning: true` to group\n- Display warning in output\n- Continue with remaining tasks\n\n### Dependency Chain Exceeds Limit\n- Identify minimum-cut point in chain\n- Split into separate groups\n- Add `context_handoff` metadata:\n  ```json\n  {\n    \"from_group\": \"CG-001\",\n    \"to_group\": \"CG-002\",\n    \"split_reason\": \"Dependency chain exceeded token limit\",\n    \"handoff_tasks\": [\"TASK-003\", \"TASK-004\"]\n  }\n  ```\n\n### All Tasks Already Assigned\n- Skip tasks with existing `context_group_id`\n- Only process unassigned tasks\n- Useful for incremental updates\n\n### No Tasks to Group\n- Display message: \"No unassigned tasks found\"\n- Suggest running `/task-manager:analyze` first\n\n## Example Output\n\nAfter running `/task-manager:context-groups my-project --max-tokens=100000`:\n\n```json\n{\n  \"metadata\": {\n    \"context_config\": {\n      \"max_tokens\": 100000,\n      \"reserve_tokens\": 20000,\n      \"effective_limit\": 80000\n    },\n    \"total_context_groups\": 3\n  },\n  \"tasks\": [\n    {\n      \"id\": \"TASK-001\",\n      \"context_group_id\": \"CG-001\",\n      \"context_group_start\": true,\n      \"context_group_end\": false,\n      \"estimated_tokens\": 4200\n    },\n    {\n      \"id\": \"TASK-004\",\n      \"context_group_id\": \"CG-001\",\n      \"context_group_start\": false,\n      \"context_group_end\": true,\n      \"estimated_tokens\": 10200\n    },\n    {\n      \"id\": \"TASK-005\",\n      \"context_group_id\": \"CG-002\",\n      \"context_group_start\": true,\n      \"estimated_tokens\": 1700\n    }\n  ],\n  \"context_groups\": [\n    {\n      \"id\": \"CG-001\",\n      \"tasks\": [\"TASK-001\", \"TASK-002\", \"TASK-003\", \"TASK-004\"],\n      \"estimated_tokens\": 72000,\n      \"phases_covered\": [1, 2],\n      \"status\": \"pending\"\n    },\n    {\n      \"id\": \"CG-002\",\n      \"tasks\": [\"TASK-005\", \"TASK-006\", \"TASK-007\"],\n      \"estimated_tokens\": 68500,\n      \"phases_covered\": [2, 3],\n      \"status\": \"pending\"\n    }\n  ]\n}\n```\n",
        "plugins/task-manager/commands/export.md": "---\ndescription: Export task list in various formats\nargument-hint: [format] [project-name]\nallowed-tools: Read, Write, Glob\n---\n\nExport the task list in the specified format.\n\n## Process\n\n1. **Parse arguments**\n   - `$1` = Format: json (default), markdown, csv\n   - `$2` = Project name (optional)\n\n2. **Locate and read the task file**\n   - If project name provided: Read `tasks/$2.tasks.json`\n   - If no project name: Find most recently modified `.tasks.json`\n\n3. **Generate export based on format**\n\n### JSON Format (default)\n- Write formatted, readable JSON\n- Include all fields including `context_groups` array\n- Include `context_group_id`, `context_group_start`, `context_group_end` on tasks\n- Include `metadata.context_config` and `metadata.total_context_groups`\n- Output to `tasks/<project>.export.json`\n\n### Markdown Format\nGenerate human-readable markdown:\n\n```markdown\n# Task List: <project-name>\n\n**Source:** <source_document>\n**Generated:** <date>\n**Progress:** X% complete\n\n## Summary\n- Total: X tasks\n- Complete: Y\n- In Progress: Z\n- Blocked: W\n- Not Started: V\n\n## Context Groups (if configured)\n\n**Configuration:**\n- Max Tokens: 100,000\n- Reserved: 20,000\n- Effective Limit: 80,000\n\n| Group | Status | Tasks | Est. Tokens | Phases |\n|-------|--------|-------|-------------|--------|\n| CG-001 | completed | 5 | 72,000 | 1, 2 |\n| CG-002 | active | 4 | 68,500 | 2, 3 |\n| CG-003 | pending | 3 | 45,200 | 3 |\n\n### CG-001: Foundation & Setup\n- TASK-001: Initialize project structure [complete]\n- TASK-002: Setup database schema [complete]\n- TASK-003: Configure authentication [complete]\n- TASK-004: Create base models [complete]\n- TASK-005: Add password hashing [complete]\n\n### CG-002: Core Features (Active)\n- TASK-006: Implement login flow [in_progress]\n- TASK-007: Add session handling [not_started]\n- TASK-008: Create logout endpoint [not_started]\n- TASK-009: Add remember me [not_started]\n\n### CG-003: Advanced Features\n- TASK-010: Implement OAuth [not_started]\n- TASK-011: Add 2FA support [not_started]\n- TASK-012: Create password reset [not_started]\n\n## Execution Phases\n\n### Phase 1: Foundation\nTasks with no dependencies.\n\n#### TASK-001: <title>\n- **Priority:** high | **Complexity:** M\n- **Status:** not_started\n- **Context Group:** CG-001\n\n**Description:**\n<description>\n\n**Acceptance Criteria:**\n- [ ] <criterion 1>\n- [ ] <criterion 2>\n\n---\n\n### Phase 2: Core Features\n...\n```\n\nOutput to `tasks/<project>.tasks.md`\n\n### CSV Format\nGenerate spreadsheet-compatible CSV:\n\n```csv\nID,Title,Status,Priority,Complexity,Hard Dependencies,Soft Dependencies,Blocked By,Context Group,Group Start,Group End,Est Tokens,Acceptance Criteria\nTASK-001,\"Title here\",not_started,high,M,\"TASK-002,TASK-003\",\"TASK-004\",\"\",CG-001,true,false,4200,\"Criterion 1; Criterion 2\"\n```\n\nColumns added for context groups:\n- `Context Group`: The context group ID (e.g., CG-001)\n- `Group Start`: true if this is the first task in the group\n- `Group End`: true if this is the last task in the group\n- `Est Tokens`: Estimated token count for this task\n\nOutput to `tasks/<project>.tasks.csv`\n\n4. **Write export file**\n\n5. **Display confirmation**\n\n```\n## Export Complete\n\n**Format:** <format>\n**Output:** tasks/<filename>\n\nFile contains:\n- X tasks\n- Y execution phases\n- Z context groups\n- Full dependency information\n- Context group assignments and token estimates\n\nThe exported file is ready for:\n- JSON: Programmatic consumption, backup, API integration\n- Markdown: Documentation, sharing with stakeholders, sprint planning\n- CSV: Spreadsheet import, project management tools, resource planning\n```\n\nSuggest the most appropriate format if none specified based on common use cases.\n",
        "plugins/task-manager/commands/next-group.md": "---\ndescription: Get the next context group ready for execution\nargument-hint: [project-name]\nallowed-tools: Read, Write, Glob\n---\n\nGet the next context group that should be executed by an AI coding agent. This command helps with context window management by identifying which group to work on next.\n\n## Process\n\n1. **Parse arguments**\n   - `$1` = Project name (optional)\n\n2. **Locate and read the task file**\n   - If project name provided: Read `tasks/$1.tasks.json`\n   - If no project name: Find most recently modified `.tasks.json`\n\n3. **Verify context groups exist**\n   - Check for `context_groups` array in task file\n   - If not found, suggest running `/task-manager:context-groups` first\n\n4. **Find active or next pending group**\n   - First, look for a group with `status: \"active\"` (already started)\n   - If none active, find first group with `status: \"pending\"`\n   - Skip groups with `status: \"completed\"`\n\n5. **Check if current group is complete**\n   - If active group exists, verify all tasks are complete\n   - If all complete, mark group as `completed` and move to next pending\n\n6. **Mark next group as active**\n   - Update the group's `status` to `\"active\"`\n   - Save the updated task file\n\n7. **Calculate group progress**\n   - Count completed tasks in this group\n   - Calculate percentage complete\n   - Identify remaining tasks\n\n8. **Display group information**\n\nFormat output as:\n\n```\n## Next Context Group: CG-002\n\n**Status:** Active\n**Estimated Tokens:** 68,500 / 80,000 available\n\n### Progress\n- Tasks: 1 of 4 complete (25%)\n- Phases Covered: 2, 3\n\n### Tasks in This Group\n\n| Order | Task | Status | Priority | Complexity | Est. Tokens |\n|-------|------|--------|----------|------------|-------------|\n| 1 | TASK-005: Setup auth module | complete | high | M | 4,200 |\n| 2 | TASK-006: Implement login flow | not_started | high | L | 10,200 |\n| 3 | TASK-007: Add session handling | not_started | medium | M | 4,200 |\n| 4 | TASK-008: Create logout endpoint | not_started | medium | S | 1,700 |\n\n### Dependencies Within Group\n- TASK-006 depends on TASK-005 (complete)\n- TASK-007 depends on TASK-006\n- TASK-008 depends on TASK-005 (complete)\n\n### Ready to Start\nThe following tasks have all dependencies satisfied:\n- **TASK-006:** Implement login flow (high priority, L complexity)\n- **TASK-008:** Create logout endpoint (medium priority, S complexity)\n\n---\n\n**Recommended:** Start with TASK-006 (high priority, unblocks TASK-007)\n\n**Context Handoff Notes:**\nPrevious group (CG-001) completed:\n- Auth configuration (TASK-004)\n- Database schema (TASK-003)\n\nThese outputs are available for reference in this group.\n\n---\n\nWhen all tasks in this group are complete, run `/task-manager:next-group` to move to the next context group.\n```\n\n## Edge Cases\n\n### No Context Groups\n```\n## No Context Groups Found\n\nContext groups have not been generated yet.\n\nRun `/task-manager:context-groups [project-name]` to create context groups from your task list.\n```\n\n### All Groups Complete\n```\n## All Context Groups Complete!\n\n**Summary:**\n- Total Groups: 3\n- Total Tasks Completed: 12\n\nAll tasks from the specification have been completed.\nUse `/task-manager:status` for a full completion report.\n```\n\n### Group Has Oversized Warning\n```\n## Next Context Group: CG-003\n\n**Warning:** This group contains an oversized task that exceeds the token limit.\n\n**TASK-015:** Complex integration module\n- Complexity: XL\n- Estimated Tokens: 25,200\n\nThis task may require breaking into smaller subtasks or extending the context window.\nConsider running `/task-manager:update TASK-015 --split` to decompose this task.\n```\n\n### Context Handoff Required\n```\n## Next Context Group: CG-002\n\n**Context Handoff Required**\n\nThis group continues work split from CG-001 due to dependency chain length.\n\n**Handoff Information:**\n- Split from: CG-001\n- Reason: Dependency chain exceeded token limit\n- Required context from previous group:\n  - TASK-003: Database schema definitions\n  - TASK-004: API endpoint signatures\n\nEnsure these outputs are available before starting this group.\n```\n\n## Workflow Integration\n\nThis command is designed for the following workflow:\n\n1. **Initial Setup**\n   - `/task-manager:analyze` - Generate tasks from spec\n   - `/task-manager:context-groups` - Organize into context groups\n\n2. **Execution Loop** (per coding agent session)\n   - `/task-manager:next-group` - Get current group to work on\n   - Work through tasks in the group\n   - Mark tasks complete with `/task-manager:complete TASK-XXX`\n   - When group complete, agent resets context\n\n3. **New Agent Session**\n   - `/task-manager:next-group` - Gets next pending group\n   - Fresh context, continues from where previous session ended\n",
        "plugins/task-manager/commands/next.md": "---\ndescription: Suggest the next best tasks to work on\nargument-hint: [count] [project-name]\nallowed-tools: Read, Glob\n---\n\nAnalyze the current task list and recommend the best next tasks to work on.\n\n## Process\n\n1. **Parse arguments**\n   - `$1` = Number of recommendations (default: 3)\n   - `$2` = Project name (optional)\n\n2. **Locate and read the task file**\n   - If project name provided: Read `tasks/$2.tasks.json`\n   - If no project name: Find the most recently modified `.tasks.json`\n\n3. **Check for context groups**\n   - If `context_groups` array exists, identify the active group\n   - Active group has `status: \"active\"`\n   - If no active group, use first `pending` group\n\n4. **Identify candidate tasks**\n   - Status is \"not_started\"\n   - No incomplete hard dependencies (blocked_by is empty)\n   - Not obsolete\n   - **If context groups exist:** Prefer tasks in the active context group\n\n5. **Score and rank candidates**\n   Scoring factors:\n   - **Context group membership:** +10 if in active context group\n   - Priority weight: critical=4, high=3, medium=2, low=1\n   - Dependency depth: +1 for each task this unblocks\n   - Complexity bonus: XS=0.5, S=0.3 (quick wins tiebreaker)\n\n6. **Select top N recommendations**\n\n7. **Display recommendations**\n\nFormat output as:\n\n```\n## Recommended Next Tasks\n\nBased on priority, dependencies, and quick-win potential:\n\n### Context Group Status\n**Active Group:** CG-001 (3 of 5 tasks complete)\n**Effective Limit:** 80,000 tokens\n\n### 1. TASK-XXX: <title>\n- **Priority:** critical\n- **Complexity:** M\n- **Why:** Unblocks 3 other tasks\n- **Acceptance Criteria:**\n  - <criterion 1>\n  - <criterion 2>\n\n### 2. TASK-YYY: <title>\n- **Priority:** high\n- **Complexity:** S\n- **Why:** Quick win, unblocks 2 tasks\n- **Acceptance Criteria:**\n  - <criterion 1>\n\n### 3. TASK-ZZZ: <title>\n- **Priority:** high\n- **Complexity:** XS\n- **Why:** Very quick win\n- **Acceptance Criteria:**\n  - <criterion 1>\n\n---\n\n**Current Progress:** X% complete (Y of Z tasks)\n\nTo start a task, begin working on it. Mark complete with:\n`/task-manager:complete TASK-XXX`\n```\n\n### Context Switch Indicator\n\nWhen recommending a task from a different context group than the active one:\n\n```\n### Context Switch Required\n\nThe best available task is in a different context group:\n\n**TASK-010:** Implement caching layer\n- **Context Group:** CG-002 (not active)\n- **Active Group:** CG-001 (2 tasks remaining)\n\n**Recommendation:** Complete remaining tasks in CG-001 first to maintain context efficiency.\n\nRemaining in CG-001:\n- TASK-004: Create auth middleware (blocked by TASK-003)\n- TASK-005: Add session handling (not_started)\n\nIf you must switch groups, use `/task-manager:next-group` to properly transition.\n```\n\nIf no tasks are available (all blocked or complete), explain the situation.\n\nIf context groups exist but active group is complete:\n```\n### Context Group Complete!\n\nAll tasks in CG-001 are complete.\n\n**Next Steps:**\n1. Save any important context/outputs\n2. Run `/task-manager:next-group` to start CG-002\n3. Reset your context window for fresh capacity\n```\n",
        "plugins/task-manager/commands/show-group.md": "---\ndescription: Display detailed information for a specific context group\nargument-hint: <group-id> [project-name]\nallowed-tools: Read, Glob\n---\n\nShow detailed information about a specific context group, including all tasks, dependencies, and progress.\n\n## Process\n\n1. **Parse arguments**\n   - `$1` = Group ID (required, e.g., \"CG-001\")\n   - `$2` = Project name (optional)\n\n2. **Validate arguments**\n   - Group ID must match pattern `CG-XXX`\n   - If invalid, show usage help\n\n3. **Locate and read the task file**\n   - If project name provided: Read `tasks/$2.tasks.json`\n   - If no project name: Find most recently modified `.tasks.json`\n\n4. **Find the requested context group**\n   - Search `context_groups` array for matching ID\n   - If not found, list available groups\n\n5. **Gather task details**\n   - For each task in the group, collect full task information\n   - Calculate completion status\n   - Identify dependencies within and outside the group\n\n6. **Display group details**\n\nFormat output as:\n\n```\n## Context Group: CG-001\n\n**Status:** active\n**Estimated Tokens:** 72,000 / 80,000 effective limit\n**Phases Covered:** 1, 2\n\n### Progress\n- **Completed:** 2 of 5 tasks (40%)\n- **In Progress:** 1 task\n- **Blocked:** 0 tasks\n- **Not Started:** 2 tasks\n\n---\n\n### Tasks\n\n#### TASK-001: Initialize project structure [COMPLETE]\n- **Priority:** high | **Complexity:** S | **Tokens:** 1,700\n- **Description:** Set up the base project directory structure and configuration files\n- **Acceptance Criteria:**\n  - [x] Directory structure created\n  - [x] package.json configured\n  - [x] TypeScript config in place\n\n---\n\n#### TASK-002: Setup database schema [COMPLETE]\n- **Priority:** high | **Complexity:** M | **Tokens:** 4,200\n- **Dependencies:** TASK-001 (complete)\n- **Description:** Define database tables and relationships\n- **Acceptance Criteria:**\n  - [x] User table created\n  - [x] Session table created\n  - [x] Migrations written\n\n---\n\n#### TASK-003: Implement user model [IN PROGRESS]\n- **Priority:** high | **Complexity:** M | **Tokens:** 4,200\n- **Dependencies:** TASK-002 (complete)\n- **Description:** Create the User model with CRUD operations\n- **Acceptance Criteria:**\n  - [ ] User class implemented\n  - [ ] Validation logic added\n  - [ ] Unit tests passing\n\n---\n\n#### TASK-004: Create authentication service [NOT STARTED]\n- **Priority:** critical | **Complexity:** L | **Tokens:** 10,200\n- **Dependencies:** TASK-003 (in progress)\n- **Blocked By:** TASK-003\n- **Description:** Implement authentication logic with JWT\n- **Acceptance Criteria:**\n  - [ ] Login endpoint working\n  - [ ] Token generation implemented\n  - [ ] Token validation middleware\n\n---\n\n#### TASK-005: Add password hashing [NOT STARTED]\n- **Priority:** high | **Complexity:** S | **Tokens:** 1,700\n- **Dependencies:** TASK-001 (complete)\n- **Description:** Implement secure password hashing utility\n- **Acceptance Criteria:**\n  - [ ] bcrypt integration\n  - [ ] Hash and verify functions\n  - [ ] Salt rounds configurable\n\n---\n\n### Dependency Graph (This Group)\n\n```\nTASK-001 (complete)\n  ├── TASK-002 (complete)\n  │     └── TASK-003 (in_progress)\n  │           └── TASK-004 (blocked)\n  └── TASK-005 (not_started)\n```\n\n### External Dependencies\n- **From Previous Groups:** None\n- **For Next Groups:**\n  - CG-002 depends on: TASK-003, TASK-004\n\n### Token Breakdown\n\n| Task | Base | Overhead | Total |\n|------|------|----------|-------|\n| TASK-001 | 1,500 | 200 | 1,700 |\n| TASK-002 | 4,000 | 200 | 4,200 |\n| TASK-003 | 4,000 | 200 | 4,200 |\n| TASK-004 | 10,000 | 200 | 10,200 |\n| TASK-005 | 1,500 | 200 | 1,700 |\n| **Total** | | | **22,000** |\n\n---\n\n### Ready to Start Now\nTasks with all dependencies satisfied:\n- **TASK-005:** Add password hashing (high, S)\n\n### Blocked Tasks\n- **TASK-004:** Waiting on TASK-003\n\n---\n\n**Commands:**\n- Mark complete: `/task-manager:complete TASK-XXX`\n- Update task: `/task-manager:update TASK-XXX --status in_progress`\n- See all groups: `/task-manager:status`\n```\n\n## Edge Cases\n\n### Group Not Found\n```\n## Context Group Not Found: CG-005\n\nThe group \"CG-005\" does not exist in this task list.\n\n**Available Groups:**\n- CG-001 (5 tasks, pending)\n- CG-002 (4 tasks, pending)\n- CG-003 (3 tasks, pending)\n\nUse `/task-manager:show-group CG-001` to view a specific group.\n```\n\n### No Context Groups Exist\n```\n## No Context Groups\n\nContext groups have not been generated for this project.\n\nRun `/task-manager:context-groups [project-name]` to organize tasks into context groups.\n```\n\n### Group Has Warnings\n```\n## Context Group: CG-003\n\n**Status:** pending\n**Warning:** Contains oversized task\n\n### Oversized Task Warning\n\n**TASK-015:** Complex integration module\n- **Complexity:** XL\n- **Estimated Tokens:** 25,200 (exceeds 20,000 safe limit)\n\nThis task is larger than recommended for a single context window session.\nConsider:\n1. Breaking into smaller subtasks\n2. Using a larger context window model\n3. Proceeding with awareness of potential context limitations\n```\n\n### Context Handoff Information\n```\n## Context Group: CG-002\n\n**Context Handoff**\nThis group continues work from CG-001.\n\n**Split Reason:** Dependency chain exceeded token limit\n\n**Required Context from CG-001:**\n- TASK-003 outputs: Database schema, migration files\n- TASK-004 outputs: API route definitions\n\nEnsure you have access to these before starting.\n```\n\n## Usage Examples\n\n```bash\n# Show specific group\n/task-manager:show-group CG-001\n\n# Show group from specific project\n/task-manager:show-group CG-002 my-project\n\n# Common workflow\n/task-manager:status              # See all groups overview\n/task-manager:show-group CG-001   # Detailed view of group 1\n/task-manager:next-group          # Get next actionable group\n```\n",
        "plugins/task-manager/commands/show.md": "---\ndescription: Display detailed information for a specific task\nargument-hint: <task-id> [project-name]\nallowed-tools: Read, Glob\n---\n\nShow detailed information for a specific task.\n\n## Process\n\n1. **Parse arguments**\n   - `$1` = Task ID (required, e.g., TASK-001)\n   - `$2` = Project name (optional)\n\n2. **Locate the task file**\n   - If project name provided: Read `tasks/$2.tasks.json`\n   - If no project name: Find task file containing the specified task ID\n\n3. **Find the task**\n   - Search for task with matching ID\n   - If not found, list available task IDs\n\n4. **Display task details**\n\nFormat output as:\n\n```\n## TASK-XXX: <title>\n\n**Status:** <status>\n**Priority:** <priority>\n**Complexity:** <complexity>\n\n### Description\n<full description>\n\n### Dependencies\n**Hard (must complete first):**\n- TASK-YYY: <title> [status]\n- TASK-ZZZ: <title> [status]\n\n**Soft (beneficial if complete):**\n- TASK-AAA: <title> [status]\n\n### Blocks\nThese tasks are waiting on this one:\n- TASK-BBB: <title>\n\n### Testing Criteria\n\n**Acceptance Criteria:**\n1. <criterion 1>\n2. <criterion 2>\n\n**Test Scenarios:**\n1. <scenario 1>\n2. <scenario 2>\n\n**Edge Cases:**\n1. <edge case 1>\n\n### Source Requirements\n- <reference to spec section>\n\n### Notes\n<any additional notes>\n```\n\nIf task has incomplete hard dependencies, prominently display what's blocking it.\n",
        "plugins/task-manager/commands/status.md": "---\ndescription: Show task list summary and completion metrics\nargument-hint: [project-name]\nallowed-tools: Read, Glob\n---\n\nDisplay the current status of the task list.\n\n## Process\n\n1. **Locate the task file**\n   - If project name provided: Read `tasks/$1.tasks.json`\n   - If no argument: Find the most recently modified `.tasks.json` in `tasks/`\n\n2. **Calculate metrics**\n   - Total tasks\n   - Tasks by status (not_started, in_progress, blocked, complete, obsolete)\n   - Completion percentage\n   - Tasks by priority breakdown\n   - Tasks by complexity breakdown\n\n3. **Calculate context group metrics (if groups exist)**\n   - Total context groups\n   - Groups completed vs pending\n   - Active context group and its progress\n   - Estimated tokens used vs available\n\n5. **Identify actionable tasks**\n   - Tasks ready to start (not_started with no blockers)\n   - Currently blocked tasks and what's blocking them\n   - In-progress tasks\n\n6. **Display summary**\n\nFormat the output as:\n\n```\n## Task Status: <project-name>\n\n**Overview**\n- Source: <source_document>\n- Generated: <generated_at>\n- Last Updated: <last_updated>\n- Version: <version>\n\n**Progress**\n- Total Tasks: X\n- Completed: Y (Z%)\n- In Progress: N\n- Blocked: M\n- Not Started: P\n\n**By Priority**\n- Critical: X\n- High: Y\n- Medium: Z\n- Low: W\n\n**Context Groups** (if configured)\n| Group | Status | Tasks | Progress | Est. Tokens |\n|-------|--------|-------|----------|-------------|\n| CG-001 | completed | 5 | 5/5 (100%) | 72,000 |\n| CG-002 | active | 4 | 1/4 (25%) | 68,500 |\n| CG-003 | pending | 3 | 0/3 (0%) | 45,200 |\n\n**Active Group:** CG-002\n- Effective Limit: 80,000 tokens\n- Remaining in group: TASK-006, TASK-007, TASK-008\n\n**Ready to Start**\n- TASK-XXX: <title> (priority, complexity)\n- TASK-YYY: <title> (priority, complexity)\n\n**Currently Blocked**\n- TASK-ZZZ: Blocked by TASK-AAA, TASK-BBB\n```\n\n### Context Group Status (when groups exist)\n\nIf context groups have been generated, include additional section:\n\n```\n**Context Window Configuration**\n- Max Tokens: 100,000\n- Reserved: 20,000\n- Effective Limit: 80,000\n\n**Group Progress**\n- Groups Completed: 1 of 3\n- Active Group: CG-002 (25% complete)\n- Remaining Groups: 2\n\n**Recommended Action:**\nComplete CG-002 tasks, then run `/task-manager:next-group` for CG-003\n```\n\nIf no task file found, explain how to create one using `/task-manager:analyze`.\n",
        "plugins/task-manager/commands/update.md": "---\ndescription: Re-analyze specification and update existing task list\nargument-hint: <spec-document> [project-name]\nallowed-tools: Read, Write, Glob\n---\n\nRe-analyze the specification document and update the existing task list with changes.\n\n**Input document:** @$1\n\n## Process\n\n1. **Locate existing task list**\n   - If project name provided ($2): Read `tasks/$2.tasks.json`\n   - Otherwise: Derive project name from spec filename\n\n2. **Read current task list**\n   - Load existing tasks with their current statuses\n   - Note which tasks are complete, in_progress, or blocked\n\n3. **Re-analyze the specification**\n   - Parse the updated specification document\n   - Extract all current requirements\n\n4. **Compare and reconcile**\n\n   For each requirement in the updated spec:\n   - **Unchanged**: Keep existing task, preserve status\n   - **Modified**: Update task description/criteria, preserve status if in_progress\n   - **New**: Create new task with stable ID\n\n   For existing tasks not in updated spec:\n   - Mark as \"obsolete\" (don't delete - preserve history)\n\n5. **Recalculate dependencies**\n   - Update dependency graph for any structural changes\n   - Recalculate blocked_by for all non-complete tasks\n   - Rebuild execution phases\n\n6. **Update metadata**\n   - Increment version (minor bump for structural changes)\n   - Update last_updated timestamp\n   - Recalculate total_tasks and completion_percentage\n\n7. **Write updated task file**\n   - Backup previous version (rename to .tasks.json.bak)\n   - Write new task list\n\n8. **Display change summary**\n\nFormat output as:\n\n```\n## Task List Updated: <project-name>\n\n**Version:** <old> -> <new>\n\n### Changes Summary\n- **New tasks:** X\n- **Modified tasks:** Y\n- **Obsolete tasks:** Z\n- **Unchanged tasks:** W\n\n### New Tasks Added\n- TASK-XXX: <title> (priority, complexity)\n- TASK-YYY: <title> (priority, complexity)\n\n### Tasks Marked Obsolete\n- TASK-ZZZ: <title> (was: status)\n\n### Modified Tasks\n- TASK-AAA: <change description>\n\n### Progress Impact\n- Completion: X% -> Y%\n- Total tasks: A -> B\n\n### Next Actions\nRun `/spec-task-manager:next` to see recommended tasks.\n```\n\nIf this is a significant restructuring, warn about potential workflow disruption.\n",
        "plugins/task-manager/skills/spec-task-management/SKILL.md": "---\nname: spec-task-management\ndescription: This skill should be used when the user asks to \"analyze a specification\", \"break down a spec\", \"create tasks from a PRD\", \"decompose requirements\", \"generate a task list from a design document\", or mentions working from specification documents. Provides comprehensive guidance for transforming specifications into structured, actionable task lists optimized for AI coding agents.\nversion: 0.1.0\n---\n\n# Spec Task Management\n\nTransform specification documents (PRDs, Technical Specifications, Design Documents) into structured task lists that AI coding agents can execute independently or in parallel.\n\n## Core Workflow\n\n### 1. Document Analysis\n\nParse the specification document to extract:\n\n- **Explicit requirements**: Stated features, functionality, acceptance criteria\n- **Implicit requirements**: Technical considerations, infrastructure needs, error handling\n- **Constraints**: Technology choices, performance requirements, compatibility needs\n- **Scope boundaries**: What is and isn't included in the specification\n\nRead the source document thoroughly. Identify section headings, numbered requirements, user stories, acceptance criteria, and technical specifications. Note any cross-references between sections.\n\n### 2. Task Decomposition\n\nBreak requirements into atomic tasks with these characteristics:\n\n| Characteristic | Description |\n|----------------|-------------|\n| Single responsibility | Each task addresses one specific piece of functionality |\n| Independence | Tasks can be worked on by different agents without coordination |\n| Clear boundaries | Well-defined start and end conditions |\n| Testable | Verifiable completion criteria exist |\n\n**Decomposition process:**\n1. Identify each distinct requirement in the specification\n2. Determine if the requirement is atomic or needs splitting\n3. Create task entries with unique IDs (TASK-001, TASK-002, etc.)\n4. Ensure each task maps to specific specification sections\n\n### 3. Dependency Mapping\n\nIdentify three types of dependencies between tasks:\n\n- **Hard dependencies**: Task B cannot start until Task A completes\n- **Soft dependencies**: Task B benefits from Task A being complete but can proceed\n- **Resource dependencies**: Tasks share files, modules, or services\n\nPopulate `dependencies.hard` and `dependencies.soft` arrays. Calculate `blocked_by` (incomplete hard dependencies) and `blocks` (tasks depending on this one).\n\nFor detailed dependency patterns, consult `references/dependency-patterns.md`.\n\n### 4. Priority Calculation\n\nScore and prioritize tasks based on:\n\n1. **Dependency depth**: Tasks unblocking many others rank higher\n2. **Complexity**: Use T-shirt sizing (XS, S, M, L, XL)\n3. **Risk level**: Higher uncertainty = higher priority (do risky things early)\n4. **Business value**: When indicated in specification\n\nMap to priority levels: critical, high, medium, low.\n\n### 5. Testing Criteria Generation\n\nFor each task, generate:\n\n- **Acceptance criteria**: Specific conditions that must be true when complete\n- **Test scenarios**: Concrete examples to verify implementation\n- **Edge cases**: Boundary conditions and error scenarios\n\nDerive these from the specification's acceptance criteria, user stories, and technical requirements.\n\n### 6. Execution Phases\n\nGroup tasks into phases based on dependency analysis:\n\n- **Phase 1**: No hard dependencies (can start immediately)\n- **Phase 2**: Dependencies only on Phase 1 tasks\n- **Phase N**: Dependencies satisfied by previous phases\n\nCalculate phases to enable maximum parallel execution by multiple agents.\n\n### 7. Context Window Grouping\n\nOrganize tasks into context groups that fit within AI coding agent context windows:\n\n**Why Context Groups Matter:**\n- AI coding agents have limited context windows (e.g., 100K tokens)\n- Loading too many tasks exhausts context capacity\n- Context groups enable efficient agent handoffs between sessions\n\n**Grouping Algorithm:**\n1. Calculate effective limit: `max_tokens - reserve_tokens`\n2. Topologically sort tasks by execution phase\n3. Bin-pack tasks respecting:\n   - Token limits (complexity-based estimation)\n   - Hard dependencies (must be in same or earlier group)\n4. Mark first/last tasks with boundary flags\n\n**Token Estimation:**\n| Complexity | Base Tokens | Description |\n|------------|-------------|-------------|\n| XS | 500 | Single function, < 20 lines |\n| S | 1,500 | Single file, 20-100 lines |\n| M | 4,000 | Multiple files, 100-300 lines |\n| L | 10,000 | Multiple components, 300-800 lines |\n| XL | 25,000 | System-wide, > 800 lines |\n\n**Overhead:**\n- Base per task: 200 tokens\n- Per hard dependency: 100 tokens\n- Group transition: 500 tokens\n\nUse `/task-manager:context-groups` to generate groups after analyzing a specification.\n\n## Output Format\n\nGenerate task lists as JSON following the schema in `references/task-schema.json`.\n\n**Key structure:**\n```json\n{\n  \"metadata\": {\n    \"source_document\": \"path/to/spec.md\",\n    \"generated_at\": \"2024-01-15T10:30:00Z\",\n    \"version\": \"1.0.0\",\n    \"total_tasks\": 12,\n    \"completion_percentage\": 0\n  },\n  \"tasks\": [...],\n  \"dependency_graph\": { \"nodes\": [...], \"edges\": [...] },\n  \"execution_phases\": [...]\n}\n```\n\n## Storage Convention\n\nStore task files at: `tasks/<project-name>.tasks.json`\n\nCreate the `tasks/` directory if it doesn't exist. Use the specification filename (without extension) as the project name, or derive from specification title.\n\nMaintain version history by incrementing `metadata.version` on updates.\n\n## Task Status Management\n\nTrack task lifecycle:\n\n| Status | Description |\n|--------|-------------|\n| not_started | Task not yet begun |\n| in_progress | Currently being worked on |\n| blocked | Cannot proceed due to incomplete dependencies |\n| complete | Task finished and verified |\n| obsolete | Task no longer relevant (spec changed) |\n\nWhen marking a task complete:\n1. Update status to \"complete\"\n2. Recalculate `blocked_by` for all dependent tasks\n3. Update `completion_percentage` in metadata\n4. Suggest next best tasks based on updated state\n\n## Complexity Estimation\n\nUse T-shirt sizing with these guidelines:\n\n| Size | Typical Scope |\n|------|---------------|\n| XS | Single function, simple change, < 20 lines |\n| S | Single file, straightforward logic, 20-100 lines |\n| M | Multiple files, moderate complexity, 100-300 lines |\n| L | Multiple components, significant logic, 300-800 lines |\n| XL | System-wide, complex integration, > 800 lines |\n\n## Handling Ambiguity\n\nWhen specifications are unclear:\n\n1. Note assumptions in the task's `notes` field\n2. Flag ambiguous requirements for human review\n3. Create tasks for clarification if significant\n4. Document which specification sections need clarification\n\n## ID Stability\n\nMaintain stable task IDs across regenerations:\n\n- Base IDs on requirement content, not position\n- When updating, match existing tasks by requirement reference\n- Only assign new IDs for genuinely new requirements\n- Mark removed requirements as \"obsolete\" rather than deleting\n\n## Additional Resources\n\n### Reference Files\n\nFor detailed patterns and schema, consult:\n- **`references/task-schema.json`** - Complete JSON schema for task list format\n- **`references/dependency-patterns.md`** - Detailed dependency identification patterns\n- **`references/context-defaults.json`** - Default configuration for context grouping\n\n## Quick Reference\n\n**Analyze command flow:**\n1. Read specification document\n2. Extract requirements and structure\n3. Decompose into atomic tasks\n4. Map dependencies (hard, soft, resource)\n5. Calculate priorities and phases\n6. Generate testing criteria\n7. Write to `tasks/<project-name>.tasks.json`\n\n**Context grouping flow:**\n1. Run `/task-manager:context-groups` on existing task list\n2. Algorithm bin-packs tasks into groups respecting token limits\n3. Each task gets `context_group_id`, boundary flags, token estimates\n4. `context_groups` array added to task file with summaries\n\n**Agent execution workflow:**\n1. `/task-manager:next-group` - Get next group to work on\n2. Work through tasks in group, marking complete\n3. When group complete, agent resets context\n4. New session runs `/task-manager:next-group` for next group\n\n**Next task selection criteria:**\n1. Status is \"not_started\"\n2. No incomplete hard dependencies (blocked_by is empty)\n3. Prefer tasks in active context group\n4. Highest priority first\n5. Lowest complexity as tiebreaker (quick wins)\n",
        "plugins/task-manager/skills/spec-task-management/references/dependency-patterns.md": "# Dependency Patterns for Task Decomposition\n\nThis reference provides detailed patterns for identifying and mapping dependencies between tasks extracted from specification documents.\n\n## Dependency Types\n\n### Hard Dependencies\n\nA hard dependency exists when Task B **cannot start** until Task A is complete. The relationship is blocking and must be respected in execution order.\n\n**Indicators of hard dependencies:**\n- Task B requires output/artifacts from Task A\n- Task B modifies code that Task A creates\n- Task B tests functionality that Task A implements\n- Task B extends an interface/API that Task A defines\n\n**Examples:**\n```\nTASK-001: Create User model schema\nTASK-002: Implement User CRUD operations  # Hard depends on TASK-001\nTASK-003: Write User model unit tests     # Hard depends on TASK-001\n```\n\n### Soft Dependencies\n\nA soft dependency exists when Task B **benefits from** Task A being complete but can proceed independently. These are \"nice to have\" orderings.\n\n**Indicators of soft dependencies:**\n- Task B could use patterns established by Task A\n- Task B might need minor adjustments if started before Task A\n- Task B is in the same domain/module as Task A\n- Task B's implementation could inform Task A's design\n\n**Examples:**\n```\nTASK-010: Implement login endpoint\nTASK-011: Implement logout endpoint     # Soft depends on TASK-010 (shares auth patterns)\nTASK-012: Implement password reset      # Soft depends on TASK-010 (similar flow)\n```\n\n### Resource Dependencies\n\nA resource dependency exists when multiple tasks modify the same files, modules, or external services. These aren't blocking but require coordination.\n\n**Indicators of resource dependencies:**\n- Tasks modify the same file\n- Tasks configure the same service\n- Tasks share database tables\n- Tasks use the same environment variables\n\n**Examples:**\n```\nTASK-020: Add email field to User model\nTASK-021: Add phone field to User model    # Resource depends (same model file)\nTASK-022: Add user preferences table       # Resource depends (same migration system)\n```\n\n## Identifying Dependencies from Specifications\n\n### Structural Analysis\n\nExamine the specification structure to identify implicit dependencies:\n\n1. **Hierarchical sections** often indicate hard dependencies\n   - Parent feature must exist before child features\n   - Foundation components before higher-level features\n\n2. **Sequential descriptions** suggest execution order\n   - \"First... then... finally...\" language\n   - Numbered steps in requirements\n\n3. **Cross-references** reveal relationships\n   - \"Uses the X from section Y\"\n   - \"Extends the functionality described in...\"\n\n### Keyword Analysis\n\nLook for dependency-indicating language:\n\n**Hard dependency keywords:**\n- \"requires\", \"depends on\", \"after\", \"once X is complete\"\n- \"uses\", \"consumes\", \"reads from\", \"writes to\"\n- \"extends\", \"inherits\", \"implements\"\n\n**Soft dependency keywords:**\n- \"similar to\", \"like\", \"follows the pattern of\"\n- \"related to\", \"in the same area as\"\n- \"should be consistent with\"\n\n**Resource dependency keywords:**\n- \"also modifies\", \"shares\", \"both use\"\n- \"same file\", \"same table\", \"same config\"\n\n### Technical Analysis\n\nIdentify dependencies from technical implications:\n\n1. **Data model dependencies**\n   - Create table → Create model → Create repository → Create service → Create API\n   - Each layer depends on the previous\n\n2. **API dependencies**\n   - Define interface → Implement backend → Implement frontend\n   - Tests depend on implementation\n\n3. **Infrastructure dependencies**\n   - Setup → Configuration → Implementation → Deployment\n   - Later stages require earlier stages\n\n## Dependency Graph Construction\n\n### Building the Graph\n\n1. **List all tasks as nodes**\n2. **For each task, identify:**\n   - What it produces (outputs)\n   - What it consumes (inputs)\n   - What files/resources it touches\n\n3. **Create edges based on:**\n   - Producer-consumer relationships (hard)\n   - Pattern-following relationships (soft)\n   - Shared resource relationships (resource)\n\n### Detecting Cycles\n\nCircular dependencies indicate specification issues:\n\n```\nTASK-A depends on TASK-B\nTASK-B depends on TASK-C\nTASK-C depends on TASK-A  # Cycle detected!\n```\n\n**Resolution strategies:**\n1. Break the cycle by splitting a task\n2. Identify the true dependency direction\n3. Flag for human review/clarification\n\n### Calculating Execution Phases\n\nGroup tasks into phases based on dependency depth:\n\n**Phase 1**: Tasks with no hard dependencies (can start immediately)\n**Phase 2**: Tasks whose hard dependencies are all in Phase 1\n**Phase 3**: Tasks whose hard dependencies are all in Phase 1 or 2\n...and so on.\n\n```python\n# Pseudocode for phase calculation\ndef calculate_phases(tasks, hard_deps):\n    phases = []\n    remaining = set(tasks)\n    completed = set()\n\n    while remaining:\n        # Find tasks whose dependencies are all completed\n        ready = [t for t in remaining\n                 if all(d in completed for d in hard_deps[t])]\n\n        if not ready:\n            # Circular dependency detected\n            raise CycleError(remaining)\n\n        phases.append(ready)\n        completed.update(ready)\n        remaining -= set(ready)\n\n    return phases\n```\n\n## Priority Calculation\n\n### Dependency Depth Score\n\nTasks that unblock many others should be prioritized:\n\n```\ndepth_score = count(tasks_that_depend_on_this_task)\n```\n\nHigher scores indicate more critical path tasks.\n\n### Weighted Priority Formula\n\nCombine factors for final priority:\n\n```\npriority_score = (\n    dependency_depth * 3.0 +      # Most important\n    risk_level * 2.0 +            # High risk = do early\n    inverse_complexity * 1.0 +    # Simpler tasks first (quick wins)\n    business_value * 2.5          # If specified in requirements\n)\n```\n\nMap scores to priority levels:\n- score >= 8.0: critical\n- score >= 5.0: high\n- score >= 2.5: medium\n- score < 2.5: low\n\n## Common Patterns\n\n### Feature Implementation Pattern\n\n```\n1. Data Model (no deps)\n2. Repository/Data Access (depends on 1)\n3. Business Logic/Service (depends on 2)\n4. API Endpoint (depends on 3)\n5. Frontend Component (depends on 4)\n6. Integration Tests (depends on 4, 5)\n```\n\n### CRUD Feature Pattern\n\n```\n1. Create operation (foundation)\n2. Read operation (soft depends on 1 for test data)\n3. Update operation (hard depends on 1)\n4. Delete operation (hard depends on 1)\n5. List/Search operation (soft depends on 1, 2)\n```\n\n### Configuration Pattern\n\n```\n1. Environment setup (no deps)\n2. Configuration schema (depends on 1)\n3. Configuration loading (depends on 2)\n4. Feature using config (depends on 3)\n```\n\n## Best Practices\n\n1. **Prefer explicit over implicit dependencies**\n   - When in doubt, make the dependency explicit\n   - Easier to relax than to add dependencies later\n\n2. **Keep hard dependencies minimal**\n   - Only mark as \"hard\" if truly blocking\n   - Overuse of hard deps limits parallelization\n\n3. **Document uncertainty**\n   - If dependency type is unclear, note it\n   - Flag for human review if significant\n\n4. **Validate against specification**\n   - Dependencies should trace back to requirements\n   - No invented dependencies without basis\n\n5. **Consider agent parallelization**\n   - Goal is maximum parallel execution\n   - Group independent tasks for concurrent work\n"
      },
      "plugins": [
        {
          "name": "task-manager",
          "description": "Spec Driven Development document management - conducts dynamic interviews to generate PRDs, Tech Specs, and Design Specs optimized for AI coding agents",
          "version": "0.1.0",
          "author": {
            "name": "Stephen Sequenzia",
            "email": "sequenzia@gmail.com"
          },
          "source": "./plugins/task-manager",
          "category": "development",
          "homepage": "https://github.com/sequenzia/claude-plugins/tree/main/plugins/task-manager",
          "categories": [
            "development"
          ],
          "install_commands": [
            "/plugin marketplace add sequenzia/claude-plugins",
            "/plugin install task-manager@sequenzia-claude-plugins"
          ]
        },
        {
          "name": "prd-tools",
          "description": "Generate and analyze Product Requirements Documents through interactive workflows",
          "version": "0.3.1",
          "author": {
            "name": "Stephen Sequenzia",
            "email": "sequenzia@gmail.com"
          },
          "source": "./plugins/prd-tools",
          "category": "development",
          "homepage": "https://github.com/sequenzia/claude-plugins/tree/main/plugins/prd-tools",
          "categories": [
            "development"
          ],
          "install_commands": [
            "/plugin marketplace add sequenzia/claude-plugins",
            "/plugin install prd-tools@sequenzia-claude-plugins"
          ]
        },
        {
          "name": "dev-tools",
          "description": "Developer tools for feature development, Git workflows, and release automation",
          "version": "0.2.3",
          "author": {
            "name": "Stephen Sequenzia",
            "email": "sequenzia@gmail.com"
          },
          "source": "./plugins/dev-tools",
          "category": "development",
          "homepage": "https://github.com/sequenzia/claude-plugins/tree/main/plugins/dev-tools",
          "categories": [
            "development"
          ],
          "install_commands": [
            "/plugin marketplace add sequenzia/claude-plugins",
            "/plugin install dev-tools@sequenzia-claude-plugins"
          ]
        },
        {
          "name": "mission-control",
          "description": "Creates and manages coding tasks for AI agents - analyze specs, track tasks, manage dependencies based on PRDs",
          "version": "0.1.2",
          "author": {
            "name": "Stephen Sequenzia",
            "email": "sequenzia@gmail.com"
          },
          "source": "./plugins/mission-control",
          "category": "development",
          "homepage": "https://github.com/sequenzia/claude-plugins/tree/main/plugins/mission-control",
          "categories": [
            "development"
          ],
          "install_commands": [
            "/plugin marketplace add sequenzia/claude-plugins",
            "/plugin install mission-control@sequenzia-claude-plugins"
          ]
        },
        {
          "name": "ralph-mission",
          "description": "Mission-driven autonomous loop - iterates through mission-control tasks until all are complete",
          "version": "0.1.0",
          "author": {
            "name": "Stephen Sequenzia",
            "email": "sequenzia@gmail.com"
          },
          "source": "./plugins/ralph-mission",
          "category": "automation",
          "homepage": "https://github.com/sequenzia/claude-plugins/tree/main/plugins/ralph-mission",
          "categories": [
            "automation"
          ],
          "install_commands": [
            "/plugin marketplace add sequenzia/claude-plugins",
            "/plugin install ralph-mission@sequenzia-claude-plugins"
          ]
        }
      ]
    }
  ]
}