{
  "author": {
    "id": "hiroshi75",
    "display_name": "Hiroshi75",
    "avatar_url": "https://avatars.githubusercontent.com/u/29772157?v=4"
  },
  "marketplaces": [
    {
      "name": "langgraph-architect",
      "version": null,
      "description": "LangGraph development accelerator - Architecture patterns, parallel module development, and data-driven optimization for building AI agents",
      "repo_full_name": "hiroshi75/langgraph-architect",
      "repo_url": "https://github.com/hiroshi75/langgraph-architect",
      "repo_description": null,
      "signals": {
        "stars": 0,
        "forks": 0,
        "pushed_at": "2025-12-01T12:57:35Z"
      },
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"langgraph-architect\",\n  \"owner\": {\n    \"name\": \"Hiroshi Ayukawa\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"langgraph-architect\",\n      \"description\": \"LangGraph development accelerator - Architecture patterns, parallel module development, and data-driven optimization for building AI agents\",\n      \"source\": \"./langgraph-architect\"\n    }\n  ]\n}\n",
        "README.md": "# LangGraph Architect Plugin\n\n**Build LangGraph agents faster. Optimize them systematically.**\n\nA Claude Code plugin that provides architecture patterns, parallel development workflows, and data-driven optimization for LangGraph applications.\n\n![LangGraph Architect in Action](./img/main_ss.gif)\n\n```\n# Install\n/plugin marketplace add hiroshi75/langgraph-architect\n/plugin install langgraph-architect@langgraph-architect\n```\n\n## What You Get\n\n### 1. Instant LangGraph Expertise\n\nClaude automatically provides architecture guidance when you work with LangGraph:\n\n```\nBuild a Gemini+grounding deep-research agent that runs on the CLI using LangGraph.\n```\n\n40+ documentation files covering:\n\n- Core concepts (State, Node, Edge)\n- 6 architecture patterns (Routing, Agent, Parallelization, etc.)\n- Memory management (Checkpointer, Store, Persistence)\n- Tool integration and advanced features\n- Model ID references for Claude, Gemini, and OpenAI\n\n### 2. Parallel Development with Subagents\n\nBreak complex graphs into modules. Build them simultaneously.\n\n```\nYour request: \"Build a chatbot with intent analysis and RAG search\"\n\nClaude decomposes → spawns parallel agents:\n  ├─ langgraph-engineer 1: Intent module (analyze → classify → route)\n  └─ langgraph-engineer 2: RAG module (retrieve → rerank → generate)\n\nBoth run in parallel → integrate into complete graph\n```\n\n### 3. Prompt-Level Optimization (fine-tune)\n\nThe `fine-tune` skill optimizes your LangGraph prompts without changing graph structure. It activates automatically when Claude detects optimization needs, or invoke manually by `/fine-tune`.\n\n```bash\n/fine-tune Fine-Tuning objective: Increase concreteness.\nRevise the base prompt so that the generated reports become more concrete and technical, not abstract or generic. Require the model to use specific components, data flows, algorithms, failure modes, and examples.\nUse an LLM-based evaluator to assess “concreteness,” and place the evaluation script under eval/. Use that evaluator during tuning.\n```\n\n**Auto-activation triggers:**\n\n- \"improve accuracy\", \"reduce cost\", \"optimize prompts\"\n- \"the output is not good enough\", \"responses are inconsistent\"\n\n**4-Phase Workflow:**\n\n```\nPhase 1: Baseline    → Measure current accuracy, latency, cost\nPhase 2: Analysis    → Identify underperforming nodes and patterns\nPhase 3: Optimize    → Apply techniques (few-shot, CoT, constraints)\nPhase 4: Validate    → Statistical validation (3-5 runs) and apply\n```\n\n**Typical gains:** Accuracy +10-20%, Cost -20-60%\n\n### 4. Architecture-Level Optimization (arch-tune)\n\nThe `/arch-tune` command explores multiple graph structure improvements in parallel:\n\n```bash\n/arch-tune \"Improve latency to under 2.0s and accuracy to 90%\"\n```\n\nWhat happens:\n\n1. **Analyze** current graph and generate 3-5 improvement proposals\n2. **Implement** each proposal in isolated git worktrees (parallel)\n3. **Optimize** prompts and parameters for each variant (parallel)\n4. **Compare** results with statistical validation\n5. **Merge** the winner with your approval\n\n**Typical gains:** Latency -20-50%, Accuracy +10-30%\n\n## Skills\n\n| Skill                 | Purpose                                                        |\n| --------------------- | -------------------------------------------------------------- |\n| `langgraph-architect` | Architecture patterns and implementation guidance              |\n| `fine-tune`           | Iterative prompt optimization without changing graph structure |\n| `arch-analysis`       | Analyze bottlenecks and generate improvement proposals         |\n\n## Agents\n\n| Agent                 | Role                                               |\n| --------------------- | -------------------------------------------------- |\n| `langgraph-engineer`  | Implements complete functional modules (2-5 nodes) |\n| `langgraph-tuner`     | Executes optimization workflow with evaluation     |\n| `proposal-comparator` | Compares results and recommends best option        |\n| `merge-coordinator`   | Handles user approval and git operations           |\n\n## Commands\n\n| Command      | Description                                          |\n| ------------ | ---------------------------------------------------- |\n| `/arch-tune` | Full optimization pipeline with parallel exploration |\n\n## Quick Examples\n\n### Get Architecture Guidance\n\nJust start coding. Claude provides patterns automatically.\n\n```python\n# Working on a RAG agent? Claude suggests:\n# - retrieve → rerank → generate pattern\n# - Checkpointer for conversation memory\n# - Subgraph for modular RAG logic\n```\n\n### Optimize an Existing Graph\n\n```bash\n# Prompt-level optimization (no structure changes). It can be auto-triggered or manual by `/fine-tune`.\n/fine-tune \"Increase accuracy by 15%\"\n```\n\n```bash\n# Architecture-level optimization (structure changes)\n/arch-tune \"Reduce latency by 30%\"\n```\n\n### Build Modules in Parallel\n\nFor complex applications, Claude spawns multiple `langgraph-engineer` agents:\n\n```\nTask: Customer support bot with routing, RAG, and escalation\n\nParallel execution:\n├─ Agent 1: Intent routing module\n├─ Agent 2: RAG search module\n└─ Agent 3: Human escalation module\n\nResult: Complete implementation in ~20 min instead of ~60 min\n```\n\n## How arch-tune Works\n\n```\n┌─────────────────────────────────────────────────────────────────┐\n│  Phase 1: Analysis (arch-analysis skill)                        │\n│  - Measure baseline performance                                 │\n│  - Analyze graph structure                                      │\n│  - Generate 3-5 improvement proposals                           │\n└─────────────────────────────────────────────────────────────────┘\n                              ↓\n┌─────────────────────────────────────────────────────────────────┐\n│  Phase 2: Implementation (parallel langgraph-engineers)         │\n│                                                                 │\n│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐          │\n│  │ Proposal 1   │  │ Proposal 2   │  │ Proposal 3   │          │\n│  │ (worktree)   │  │ (worktree)   │  │ (worktree)   │          │\n│  └──────────────┘  └──────────────┘  └──────────────┘          │\n└─────────────────────────────────────────────────────────────────┘\n                              ↓\n┌─────────────────────────────────────────────────────────────────┐\n│  Phase 3: Optimization (parallel langgraph-tuners)              │\n│  - Run fine-tune skill on each variant                          │\n│  - Evaluate with statistical validation (3-5 runs)              │\n└─────────────────────────────────────────────────────────────────┘\n                              ↓\n┌─────────────────────────────────────────────────────────────────┐\n│  Phase 4: Comparison (proposal-comparator)                      │\n│  - Calculate goal achievement scores                            │\n│  - Risk-adjusted ranking                                        │\n│  - Clear recommendation with rationale                          │\n└─────────────────────────────────────────────────────────────────┘\n                              ↓\n┌─────────────────────────────────────────────────────────────────┐\n│  Phase 5: Merge (merge-coordinator)                             │\n│  - Present results to user                                      │\n│  - Merge selected proposal                                      │\n│  - Clean up worktrees and branches                              │\n└─────────────────────────────────────────────────────────────────┘\n```\n\n## Requirements\n\n- Claude Code CLI\n- Git (for arch-tune worktree operations)\n- Python environment with LangGraph installed\n\n## File Structure\n\n```\n.claude-plugin/\n├── plugin.json\n\nskills/\n├── langgraph-architect/      # 40+ documentation files\n│   ├── SKILL.md\n│   ├── 01_core_concepts_*.md\n│   ├── 02_graph_architecture_*.md\n│   ├── 03_memory_management_*.md\n│   ├── 04_tool_integration_*.md\n│   ├── 05_advanced_features_*.md\n│   ├── 06_llm_model_ids*.md\n│   └── example_*.md\n├── fine-tune/             # Prompt optimization skill\n│   ├── SKILL.md\n│   ├── workflow*.md\n│   ├── evaluation*.md\n│   └── prompt_*.md\n└── arch-analysis/         # Architecture analysis skill\n    └── SKILL.md\n\nagents/\n├── langgraph-engineer.md  # Module implementation specialist\n├── langgraph-tuner.md     # Optimization execution specialist\n├── proposal-comparator.md # Results comparison specialist\n└── merge-coordinator.md   # Merge and cleanup coordinator\n\ncommands/\n└── arch-tune.md           # Full optimization pipeline\n```\n\n## License\n\nMIT\n\n## Links\n\n- [LangGraph Official Documentation](https://docs.langchain.com/oss/python/langgraph/overview)\n- [LangGraph GitHub](https://github.com/langchain-ai/langgraph)\n"
      },
      "plugins": [
        {
          "name": "langgraph-architect",
          "description": "LangGraph development accelerator - Architecture patterns, parallel module development, and data-driven optimization for building AI agents",
          "source": "./langgraph-architect",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add hiroshi75/langgraph-architect",
            "/plugin install langgraph-architect@langgraph-architect"
          ]
        }
      ]
    }
  ]
}