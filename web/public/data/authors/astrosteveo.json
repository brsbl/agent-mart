{
  "author": {
    "id": "astrosteveo",
    "display_name": "Steven Mosley",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/34114851?u=67b12eac0e81e940c732e45ec3bf40b428650d08&v=4",
    "url": "https://github.com/astrosteveo",
    "bio": null,
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 6,
      "total_commands": 6,
      "total_skills": 24,
      "total_stars": 1,
      "total_forks": 0
    }
  },
  "marketplaces": [
    {
      "name": "astrosteveo-claude-plugins",
      "version": null,
      "description": "Comprehensive feature development workflow with specialized agents for codebase exploration, architecture design, and quality review",
      "owner_info": {
        "name": "AstroSteveo",
        "email": "34114851+astrosteveo@users.noreply.github.com"
      },
      "keywords": [],
      "repo_full_name": "astrosteveo/marketplace",
      "repo_url": "https://github.com/astrosteveo/marketplace",
      "repo_description": null,
      "homepage": null,
      "signals": {
        "stars": 1,
        "forks": 0,
        "pushed_at": "2026-01-28T03:55:20Z",
        "created_at": "2026-01-09T21:25:44Z",
        "license": null
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 3034
        },
        {
          "path": "plugins",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-code-setup",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-code-setup/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-code-setup/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 251
        },
        {
          "path": "plugins/claude-code-setup/README.md",
          "type": "blob",
          "size": 1015
        },
        {
          "path": "plugins/claude-code-setup/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-code-setup/skills/claude-automation-recommender",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-code-setup/skills/claude-automation-recommender/SKILL.md",
          "type": "blob",
          "size": 10856
        },
        {
          "path": "plugins/claude-code-setup/skills/claude-automation-recommender/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-code-setup/skills/claude-automation-recommender/references/hooks-patterns.md",
          "type": "blob",
          "size": 6316
        },
        {
          "path": "plugins/claude-code-setup/skills/claude-automation-recommender/references/mcp-servers.md",
          "type": "blob",
          "size": 7419
        },
        {
          "path": "plugins/claude-code-setup/skills/claude-automation-recommender/references/plugins-reference.md",
          "type": "blob",
          "size": 3016
        },
        {
          "path": "plugins/claude-code-setup/skills/claude-automation-recommender/references/skills-reference.md",
          "type": "blob",
          "size": 9612
        },
        {
          "path": "plugins/claude-code-setup/skills/claude-automation-recommender/references/subagent-templates.md",
          "type": "blob",
          "size": 5049
        },
        {
          "path": "plugins/claude-md-management",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-md-management/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-md-management/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 261
        },
        {
          "path": "plugins/claude-md-management/README.md",
          "type": "blob",
          "size": 1084
        },
        {
          "path": "plugins/claude-md-management/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-md-management/commands/revise-claude-md.md",
          "type": "blob",
          "size": 1357
        },
        {
          "path": "plugins/claude-md-management/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-md-management/skills/claude-md-improver",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-md-management/skills/claude-md-improver/SKILL.md",
          "type": "blob",
          "size": 6028
        },
        {
          "path": "plugins/claude-md-management/skills/claude-md-improver/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/claude-md-management/skills/claude-md-improver/references/quality-criteria.md",
          "type": "blob",
          "size": 2617
        },
        {
          "path": "plugins/claude-md-management/skills/claude-md-improver/references/templates.md",
          "type": "blob",
          "size": 3687
        },
        {
          "path": "plugins/claude-md-management/skills/claude-md-improver/references/update-guidelines.md",
          "type": "blob",
          "size": 3197
        },
        {
          "path": "plugins/feature-dev",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/feature-dev/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/feature-dev/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 262
        },
        {
          "path": "plugins/feature-dev/README.md",
          "type": "blob",
          "size": 15556
        },
        {
          "path": "plugins/feature-dev/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/feature-dev/agents/code-architect.md",
          "type": "blob",
          "size": 4049
        },
        {
          "path": "plugins/feature-dev/agents/code-explorer.md",
          "type": "blob",
          "size": 2115
        },
        {
          "path": "plugins/feature-dev/agents/code-reviewer.md",
          "type": "blob",
          "size": 5176
        },
        {
          "path": "plugins/feature-dev/agents/code-tester.md",
          "type": "blob",
          "size": 4688
        },
        {
          "path": "plugins/feature-dev/agents/impact-analyzer.md",
          "type": "blob",
          "size": 4012
        },
        {
          "path": "plugins/feature-dev/agents/quick-verifier.md",
          "type": "blob",
          "size": 2916
        },
        {
          "path": "plugins/feature-dev/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/feature-dev/commands/feature-dev.md",
          "type": "blob",
          "size": 10382
        },
        {
          "path": "plugins/frontend-design",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/frontend-design/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/frontend-design/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 180
        },
        {
          "path": "plugins/frontend-design/README.md",
          "type": "blob",
          "size": 977
        },
        {
          "path": "plugins/frontend-design/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/frontend-design/skills/frontend-design",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/frontend-design/skills/frontend-design/SKILL.md",
          "type": "blob",
          "size": 4274
        },
        {
          "path": "plugins/plugin-dev",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-dev/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-dev/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 326
        },
        {
          "path": "plugins/plugin-dev/README.md",
          "type": "blob",
          "size": 14590
        },
        {
          "path": "plugins/plugin-dev/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-dev/agents/agent-creator.md",
          "type": "blob",
          "size": 7437
        },
        {
          "path": "plugins/plugin-dev/agents/plugin-validator.md",
          "type": "blob",
          "size": 6623
        },
        {
          "path": "plugins/plugin-dev/agents/skill-reviewer.md",
          "type": "blob",
          "size": 6079
        },
        {
          "path": "plugins/plugin-dev/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-dev/commands/create-plugin.md",
          "type": "blob",
          "size": 14950
        },
        {
          "path": "plugins/plugin-dev/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-dev/skills/agent-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-dev/skills/agent-development/SKILL.md",
          "type": "blob",
          "size": 10415
        },
        {
          "path": "plugins/plugin-dev/skills/agent-development/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-dev/skills/agent-development/examples/agent-creation-prompt.md",
          "type": "blob",
          "size": 9390
        },
        {
          "path": "plugins/plugin-dev/skills/agent-development/examples/complete-agent-examples.md",
          "type": "blob",
          "size": 14117
        },
        {
          "path": "plugins/plugin-dev/skills/agent-development/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-dev/skills/agent-development/references/agent-creation-system-prompt.md",
          "type": "blob",
          "size": 8879
        },
        {
          "path": "plugins/plugin-dev/skills/agent-development/references/system-prompt-design.md",
          "type": "blob",
          "size": 9998
        },
        {
          "path": "plugins/plugin-dev/skills/agent-development/references/triggering-examples.md",
          "type": "blob",
          "size": 11613
        },
        {
          "path": "plugins/plugin-dev/skills/command-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-dev/skills/command-development/README.md",
          "type": "blob",
          "size": 7669
        },
        {
          "path": "plugins/plugin-dev/skills/command-development/SKILL.md",
          "type": "blob",
          "size": 19249
        },
        {
          "path": "plugins/plugin-dev/skills/command-development/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-dev/skills/command-development/examples/plugin-commands.md",
          "type": "blob",
          "size": 14091
        },
        {
          "path": "plugins/plugin-dev/skills/command-development/examples/simple-commands.md",
          "type": "blob",
          "size": 8699
        },
        {
          "path": "plugins/plugin-dev/skills/command-development/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-dev/skills/command-development/references/advanced-workflows.md",
          "type": "blob",
          "size": 13678
        },
        {
          "path": "plugins/plugin-dev/skills/command-development/references/documentation-patterns.md",
          "type": "blob",
          "size": 14986
        },
        {
          "path": "plugins/plugin-dev/skills/command-development/references/frontmatter-reference.md",
          "type": "blob",
          "size": 9171
        },
        {
          "path": "plugins/plugin-dev/skills/command-development/references/interactive-commands.md",
          "type": "blob",
          "size": 20989
        },
        {
          "path": "plugins/plugin-dev/skills/command-development/references/marketplace-considerations.md",
          "type": "blob",
          "size": 16440
        },
        {
          "path": "plugins/plugin-dev/skills/command-development/references/plugin-features-reference.md",
          "type": "blob",
          "size": 14700
        },
        {
          "path": "plugins/plugin-dev/skills/command-development/references/testing-strategies.md",
          "type": "blob",
          "size": 14833
        },
        {
          "path": "plugins/plugin-dev/skills/hook-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-dev/skills/hook-development/SKILL.md",
          "type": "blob",
          "size": 16231
        },
        {
          "path": "plugins/plugin-dev/skills/hook-development/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-dev/skills/hook-development/references/advanced.md",
          "type": "blob",
          "size": 10148
        },
        {
          "path": "plugins/plugin-dev/skills/hook-development/references/migration.md",
          "type": "blob",
          "size": 8299
        },
        {
          "path": "plugins/plugin-dev/skills/hook-development/references/patterns.md",
          "type": "blob",
          "size": 7144
        },
        {
          "path": "plugins/plugin-dev/skills/hook-development/scripts",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-dev/skills/hook-development/scripts/README.md",
          "type": "blob",
          "size": 3677
        },
        {
          "path": "plugins/plugin-dev/skills/mcp-integration",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-dev/skills/mcp-integration/SKILL.md",
          "type": "blob",
          "size": 12504
        },
        {
          "path": "plugins/plugin-dev/skills/mcp-integration/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-dev/skills/mcp-integration/references/authentication.md",
          "type": "blob",
          "size": 10196
        },
        {
          "path": "plugins/plugin-dev/skills/mcp-integration/references/server-types.md",
          "type": "blob",
          "size": 10613
        },
        {
          "path": "plugins/plugin-dev/skills/mcp-integration/references/tool-usage.md",
          "type": "blob",
          "size": 11674
        },
        {
          "path": "plugins/plugin-dev/skills/plugin-settings",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-dev/skills/plugin-settings/SKILL.md",
          "type": "blob",
          "size": 12082
        },
        {
          "path": "plugins/plugin-dev/skills/plugin-settings/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-dev/skills/plugin-settings/examples/create-settings-command.md",
          "type": "blob",
          "size": 2177
        },
        {
          "path": "plugins/plugin-dev/skills/plugin-settings/examples/example-settings.md",
          "type": "blob",
          "size": 2930
        },
        {
          "path": "plugins/plugin-dev/skills/plugin-settings/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-dev/skills/plugin-settings/references/parsing-techniques.md",
          "type": "blob",
          "size": 11513
        },
        {
          "path": "plugins/plugin-dev/skills/plugin-settings/references/real-world-examples.md",
          "type": "blob",
          "size": 9492
        },
        {
          "path": "plugins/plugin-dev/skills/plugin-structure",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-dev/skills/plugin-structure/README.md",
          "type": "blob",
          "size": 3210
        },
        {
          "path": "plugins/plugin-dev/skills/plugin-structure/SKILL.md",
          "type": "blob",
          "size": 13781
        },
        {
          "path": "plugins/plugin-dev/skills/plugin-structure/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-dev/skills/plugin-structure/examples/advanced-plugin.md",
          "type": "blob",
          "size": 18746
        },
        {
          "path": "plugins/plugin-dev/skills/plugin-structure/examples/minimal-plugin.md",
          "type": "blob",
          "size": 1731
        },
        {
          "path": "plugins/plugin-dev/skills/plugin-structure/examples/standard-plugin.md",
          "type": "blob",
          "size": 13310
        },
        {
          "path": "plugins/plugin-dev/skills/plugin-structure/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-dev/skills/plugin-structure/references/component-patterns.md",
          "type": "blob",
          "size": 12086
        },
        {
          "path": "plugins/plugin-dev/skills/plugin-structure/references/manifest-reference.md",
          "type": "blob",
          "size": 12061
        },
        {
          "path": "plugins/plugin-dev/skills/skill-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-dev/skills/skill-development/SKILL.md",
          "type": "blob",
          "size": 22810
        },
        {
          "path": "plugins/plugin-dev/skills/skill-development/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/plugin-dev/skills/skill-development/references/skill-creator-original.md",
          "type": "blob",
          "size": 11547
        },
        {
          "path": "plugins/superpowers",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/superpowers/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/superpowers/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 447
        },
        {
          "path": "plugins/superpowers/README.md",
          "type": "blob",
          "size": 6180
        },
        {
          "path": "plugins/superpowers/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/superpowers/agents/code-reviewer.md",
          "type": "blob",
          "size": 3888
        },
        {
          "path": "plugins/superpowers/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/superpowers/commands/brainstorm.md",
          "type": "blob",
          "size": 326
        },
        {
          "path": "plugins/superpowers/commands/execute-plan.md",
          "type": "blob",
          "size": 184
        },
        {
          "path": "plugins/superpowers/commands/write-plan.md",
          "type": "blob",
          "size": 196
        },
        {
          "path": "plugins/superpowers/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/superpowers/hooks/hooks.json",
          "type": "blob",
          "size": 270
        },
        {
          "path": "plugins/superpowers/hooks/run-hook.cmd",
          "type": "blob",
          "size": 1782
        },
        {
          "path": "plugins/superpowers/hooks/session-start.sh",
          "type": "blob",
          "size": 1995
        },
        {
          "path": "plugins/superpowers/skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/superpowers/skills/brainstorming",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/superpowers/skills/brainstorming/SKILL.md",
          "type": "blob",
          "size": 2553
        },
        {
          "path": "plugins/superpowers/skills/dispatching-parallel-agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/superpowers/skills/dispatching-parallel-agents/SKILL.md",
          "type": "blob",
          "size": 6104
        },
        {
          "path": "plugins/superpowers/skills/executing-plans",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/superpowers/skills/executing-plans/SKILL.md",
          "type": "blob",
          "size": 2060
        },
        {
          "path": "plugins/superpowers/skills/finishing-a-development-branch",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/superpowers/skills/finishing-a-development-branch/SKILL.md",
          "type": "blob",
          "size": 4248
        },
        {
          "path": "plugins/superpowers/skills/receiving-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/superpowers/skills/receiving-code-review/SKILL.md",
          "type": "blob",
          "size": 6314
        },
        {
          "path": "plugins/superpowers/skills/requesting-code-review",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/superpowers/skills/requesting-code-review/SKILL.md",
          "type": "blob",
          "size": 2698
        },
        {
          "path": "plugins/superpowers/skills/requesting-code-review/code-reviewer.md",
          "type": "blob",
          "size": 3385
        },
        {
          "path": "plugins/superpowers/skills/subagent-driven-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/superpowers/skills/subagent-driven-development/SKILL.md",
          "type": "blob",
          "size": 9809
        },
        {
          "path": "plugins/superpowers/skills/subagent-driven-development/code-quality-reviewer-prompt.md",
          "type": "blob",
          "size": 630
        },
        {
          "path": "plugins/superpowers/skills/subagent-driven-development/implementer-prompt.md",
          "type": "blob",
          "size": 2195
        },
        {
          "path": "plugins/superpowers/skills/subagent-driven-development/spec-reviewer-prompt.md",
          "type": "blob",
          "size": 1999
        },
        {
          "path": "plugins/superpowers/skills/systematic-debugging",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/superpowers/skills/systematic-debugging/CREATION-LOG.md",
          "type": "blob",
          "size": 4268
        },
        {
          "path": "plugins/superpowers/skills/systematic-debugging/SKILL.md",
          "type": "blob",
          "size": 9884
        },
        {
          "path": "plugins/superpowers/skills/systematic-debugging/condition-based-waiting.md",
          "type": "blob",
          "size": 3516
        },
        {
          "path": "plugins/superpowers/skills/systematic-debugging/defense-in-depth.md",
          "type": "blob",
          "size": 3650
        },
        {
          "path": "plugins/superpowers/skills/systematic-debugging/root-cause-tracing.md",
          "type": "blob",
          "size": 5327
        },
        {
          "path": "plugins/superpowers/skills/systematic-debugging/test-academic.md",
          "type": "blob",
          "size": 653
        },
        {
          "path": "plugins/superpowers/skills/systematic-debugging/test-pressure-1.md",
          "type": "blob",
          "size": 1900
        },
        {
          "path": "plugins/superpowers/skills/systematic-debugging/test-pressure-2.md",
          "type": "blob",
          "size": 2283
        },
        {
          "path": "plugins/superpowers/skills/systematic-debugging/test-pressure-3.md",
          "type": "blob",
          "size": 2692
        },
        {
          "path": "plugins/superpowers/skills/test-driven-development",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/superpowers/skills/test-driven-development/SKILL.md",
          "type": "blob",
          "size": 9867
        },
        {
          "path": "plugins/superpowers/skills/test-driven-development/testing-anti-patterns.md",
          "type": "blob",
          "size": 8251
        },
        {
          "path": "plugins/superpowers/skills/using-git-worktrees",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/superpowers/skills/using-git-worktrees/SKILL.md",
          "type": "blob",
          "size": 5592
        },
        {
          "path": "plugins/superpowers/skills/using-superpowers",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/superpowers/skills/using-superpowers/SKILL.md",
          "type": "blob",
          "size": 3798
        },
        {
          "path": "plugins/superpowers/skills/verification-before-completion",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/superpowers/skills/verification-before-completion/SKILL.md",
          "type": "blob",
          "size": 4201
        },
        {
          "path": "plugins/superpowers/skills/writing-plans",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/superpowers/skills/writing-plans/SKILL.md",
          "type": "blob",
          "size": 3682
        },
        {
          "path": "plugins/superpowers/skills/writing-skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/superpowers/skills/writing-skills/SKILL.md",
          "type": "blob",
          "size": 22463
        },
        {
          "path": "plugins/superpowers/skills/writing-skills/anthropic-best-practices.md",
          "type": "blob",
          "size": 45825
        },
        {
          "path": "plugins/superpowers/skills/writing-skills/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/superpowers/skills/writing-skills/examples/CLAUDE_MD_TESTING.md",
          "type": "blob",
          "size": 5423
        },
        {
          "path": "plugins/superpowers/skills/writing-skills/persuasion-principles.md",
          "type": "blob",
          "size": 5908
        },
        {
          "path": "plugins/superpowers/skills/writing-skills/testing-skills-with-subagents.md",
          "type": "blob",
          "size": 12558
        },
        {
          "path": "plugins/superpowers/tests",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/superpowers/tests/claude-code",
          "type": "tree",
          "size": null
        },
        {
          "path": "plugins/superpowers/tests/claude-code/README.md",
          "type": "blob",
          "size": 4289
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"astrosteveo-claude-plugins\",\n  \"owner\": {\n    \"name\": \"AstroSteveo\",\n    \"email\": \"34114851+astrosteveo@users.noreply.github.com\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"feature-dev\",\n      \"description\": \"Comprehensive feature development workflow with specialized agents for codebase exploration, architecture design, and quality review\",\n      \"author\": {\n        \"name\": \"Anthropic\",\n        \"email\": \"support@anthropic.com\"\n      },\n      \"source\": \"./plugins/feature-dev\",\n      \"category\": \"development\",\n      \"homepage\": \"https://github.com/anthropics/claude-plugins-public/tree/main/plugins/feature-dev\"\n    },\n    {\n      \"name\": \"frontend-design\",\n      \"description\": \"Create distinctive, production-grade frontend interfaces with high design quality. Generates creative, polished code that avoids generic AI aesthetics.\",\n      \"author\": {\n        \"name\": \"Anthropic\",\n        \"email\": \"support@anthropic.com\"\n      },\n      \"source\": \"./plugins/frontend-design\",\n      \"category\": \"development\",\n      \"homepage\": \"https://github.com/anthropics/claude-plugins-public/tree/main/plugins/frontend-design\"\n    },\n    {\n      \"name\": \"plugin-dev\",\n      \"description\": \"Comprehensive toolkit for developing Claude Code plugins. Includes 7 expert skills covering hooks, MCP integration, commands, agents, and best practices. AI-assisted plugin creation and validation.\",\n      \"author\": {\n        \"name\": \"Anthropic\",\n        \"email\": \"support@anthropic.com\"\n      },\n      \"source\": \"./plugins/plugin-dev\",\n      \"category\": \"development\",\n      \"homepage\": \"https://github.com/anthropics/claude-plugins-public/tree/main/plugins/plugin-dev\"\n    },\n    {\n      \"name\": \"claude-code-setup\",\n      \"description\": \"Analyze codebases and recommend tailored Claude Code automations such as hooks, skills, MCP servers, and subagents.\",\n      \"author\": {\n        \"name\": \"Anthropic\",\n        \"email\": \"support@anthropic.com\"\n      },\n      \"source\": \"./plugins/claude-code-setup\",\n      \"category\": \"productivity\",\n      \"homepage\": \"https://github.com/anthropics/claude-plugins-official/tree/main/plugins/claude-code-setup\"\n    },\n    {\n      \"name\": \"claude-md-management\",\n      \"description\": \"Tools to maintain and improve CLAUDE.md files - audit quality, capture session learnings, and keep project memory current.\",\n      \"author\": {\n        \"name\": \"Anthropic\",\n        \"email\": \"support@anthropic.com\"\n      },\n      \"source\": \"./plugins/claude-md-management\",\n      \"category\": \"productivity\",\n      \"homepage\": \"https://github.com/anthropics/claude-plugins-official/tree/main/plugins/claude-md-management\"\n    },\n    {\n      \"name\": \"superpowers\",\n      \"description\": \"Core skills library for Claude Code: TDD, debugging, collaboration patterns, and proven techniques\",\n      \"author\": {\n        \"name\": \"Jesse Vincent\",\n        \"email\": \"jesse@fsck.com\"\n      },\n      \"source\": \"./plugins/superpowers\",\n      \"category\": \"development\",\n      \"homepage\": \"https://github.com/obra/superpowers\"\n    }\n  ]\n}\n",
        "plugins/claude-code-setup/.claude-plugin/plugin.json": "{\n  \"name\": \"claude-code-setup\",\n  \"description\": \"Analyze codebases and recommend tailored Claude Code automations such as hooks, skills, MCP servers, and subagents.\",\n  \"author\": {\n    \"name\": \"Anthropic\",\n    \"email\": \"support@anthropic.com\"\n  }\n}\n",
        "plugins/claude-code-setup/README.md": "# Claude Code Setup Plugin\n\nAnalyze codebases and recommend tailored Claude Code automations - hooks, skills, MCP servers, and more.\n\n## What It Does\n\nClaude uses this skill to scan your codebase and recommend the top 1-2 automations in each category:\n\n- **MCP Servers** - External integrations (context7 for docs, Playwright for frontend)\n- **Skills** - Packaged expertise (Plan agent, frontend-design)\n- **Hooks** - Automatic actions (auto-format, auto-lint, block sensitive files)\n- **Subagents** - Specialized reviewers (security, performance, accessibility)\n- **Slash Commands** - Quick workflows (/test, /pr-review, /explain)\n\nThis skill is **read-only** - it analyzes but doesn't modify files.\n\n## Usage\n\n```\n\"recommend automations for this project\"\n\"help me set up Claude Code\"\n\"what hooks should I use?\"\n```\n\n<img src=\"automation-recommender-example.png\" alt=\"Automation recommender analyzing a codebase and providing tailored recommendations\" width=\"600\">\n\n## Author\n\nIsabella He (isabella@anthropic.com)\n",
        "plugins/claude-code-setup/skills/claude-automation-recommender/SKILL.md": "---\nname: claude-automation-recommender\ndescription: Analyze a codebase and recommend Claude Code automations (hooks, subagents, skills, plugins, MCP servers). Use when user asks for automation recommendations, wants to optimize their Claude Code setup, mentions improving Claude Code workflows, asks how to first set up Claude Code for a project, or wants to know what Claude Code features they should use.\ntools: Read, Glob, Grep, Bash\n---\n\n# Claude Automation Recommender\n\nAnalyze codebase patterns to recommend tailored Claude Code automations across all extensibility options.\n\n**This skill is read-only.** It analyzes the codebase and outputs recommendations. It does NOT create or modify any files. Users implement the recommendations themselves or ask Claude separately to help build them.\n\n## Output Guidelines\n\n- **Recommend 1-2 of each type**: Don't overwhelm - surface the top 1-2 most valuable automations per category\n- **If user asks for a specific type**: Focus only on that type and provide more options (3-5 recommendations)\n- **Go beyond the reference lists**: The reference files contain common patterns, but use web search to find recommendations specific to the codebase's tools, frameworks, and libraries\n- **Tell users they can ask for more**: End by noting they can request more recommendations for any specific category\n\n## Automation Types Overview\n\n| Type | Best For |\n|------|----------|\n| **Hooks** | Automatic actions on tool events (format on save, lint, block edits) |\n| **Subagents** | Specialized reviewers/analyzers that run in parallel |\n| **Skills** | Packaged expertise, workflows, and repeatable tasks (invoked by Claude or user via `/skill-name`) |\n| **Plugins** | Collections of skills that can be installed |\n| **MCP Servers** | External tool integrations (databases, APIs, browsers, docs) |\n\n## Workflow\n\n### Phase 1: Codebase Analysis\n\nGather project context:\n\n```bash\n# Detect project type and tools\nls -la package.json pyproject.toml Cargo.toml go.mod pom.xml 2>/dev/null\ncat package.json 2>/dev/null | head -50\n\n# Check dependencies for MCP server recommendations\ncat package.json 2>/dev/null | grep -E '\"(react|vue|angular|next|express|fastapi|django|prisma|supabase|stripe)\"'\n\n# Check for existing Claude Code config\nls -la .claude/ CLAUDE.md 2>/dev/null\n\n# Analyze project structure\nls -la src/ app/ lib/ tests/ components/ pages/ api/ 2>/dev/null\n```\n\n**Key Indicators to Capture:**\n\n| Category | What to Look For | Informs Recommendations For |\n|----------|------------------|----------------------------|\n| Language/Framework | package.json, pyproject.toml, import patterns | Hooks, MCP servers |\n| Frontend stack | React, Vue, Angular, Next.js | Playwright MCP, frontend skills |\n| Backend stack | Express, FastAPI, Django | API documentation tools |\n| Database | Prisma, Supabase, raw SQL | Database MCP servers |\n| External APIs | Stripe, OpenAI, AWS SDKs | context7 MCP for docs |\n| Testing | Jest, pytest, Playwright configs | Testing hooks, subagents |\n| CI/CD | GitHub Actions, CircleCI | GitHub MCP server |\n| Issue tracking | Linear, Jira references | Issue tracker MCP |\n| Docs patterns | OpenAPI, JSDoc, docstrings | Documentation skills |\n\n### Phase 2: Generate Recommendations\n\nBased on analysis, generate recommendations across all categories:\n\n#### A. MCP Server Recommendations\n\nSee [references/mcp-servers.md](references/mcp-servers.md) for detailed patterns.\n\n| Codebase Signal | Recommended MCP Server |\n|-----------------|------------------------|\n| Uses popular libraries (React, Express, etc.) | **context7** - Live documentation lookup |\n| Frontend with UI testing needs | **Playwright** - Browser automation/testing |\n| Uses Supabase | **Supabase MCP** - Direct database operations |\n| PostgreSQL/MySQL database | **Database MCP** - Query and schema tools |\n| GitHub repository | **GitHub MCP** - Issues, PRs, actions |\n| Uses Linear for issues | **Linear MCP** - Issue management |\n| AWS infrastructure | **AWS MCP** - Cloud resource management |\n| Slack workspace | **Slack MCP** - Team notifications |\n| Memory/context persistence | **Memory MCP** - Cross-session memory |\n| Sentry error tracking | **Sentry MCP** - Error investigation |\n| Docker containers | **Docker MCP** - Container management |\n\n#### B. Skills Recommendations\n\nSee [references/skills-reference.md](references/skills-reference.md) for details.\n\nCreate skills in `.claude/skills/<name>/SKILL.md`. Some are also available via plugins:\n\n| Codebase Signal | Skill | Plugin |\n|-----------------|-------|--------|\n| Building plugins | skill-development | plugin-dev |\n| Git commits | commit | commit-commands |\n| React/Vue/Angular | frontend-design | frontend-design |\n| Automation rules | writing-rules | hookify |\n| Feature planning | feature-dev | feature-dev |\n\n**Custom skills to create** (with templates, scripts, examples):\n\n| Codebase Signal | Skill to Create | Invocation |\n|-----------------|-----------------|------------|\n| API routes | **api-doc** (with OpenAPI template) | Both |\n| Database project | **create-migration** (with validation script) | User-only |\n| Test suite | **gen-test** (with example tests) | User-only |\n| Component library | **new-component** (with templates) | User-only |\n| PR workflow | **pr-check** (with checklist) | User-only |\n| Releases | **release-notes** (with git context) | User-only |\n| Code style | **project-conventions** | Claude-only |\n| Onboarding | **setup-dev** (with prereq script) | User-only |\n\n#### C. Hooks Recommendations\n\nSee [references/hooks-patterns.md](references/hooks-patterns.md) for configurations.\n\n| Codebase Signal | Recommended Hook |\n|-----------------|------------------|\n| Prettier configured | PostToolUse: auto-format on edit |\n| ESLint/Ruff configured | PostToolUse: auto-lint on edit |\n| TypeScript project | PostToolUse: type-check on edit |\n| Tests directory exists | PostToolUse: run related tests |\n| `.env` files present | PreToolUse: block `.env` edits |\n| Lock files present | PreToolUse: block lock file edits |\n| Security-sensitive code | PreToolUse: require confirmation |\n\n#### D. Subagent Recommendations\n\nSee [references/subagent-templates.md](references/subagent-templates.md) for templates.\n\n| Codebase Signal | Recommended Subagent |\n|-----------------|---------------------|\n| Large codebase (>500 files) | **code-reviewer** - Parallel code review |\n| Auth/payments code | **security-reviewer** - Security audits |\n| API project | **api-documenter** - OpenAPI generation |\n| Performance critical | **performance-analyzer** - Bottleneck detection |\n| Frontend heavy | **ui-reviewer** - Accessibility review |\n| Needs more tests | **test-writer** - Test generation |\n\n#### E. Plugin Recommendations\n\nSee [references/plugins-reference.md](references/plugins-reference.md) for available plugins.\n\n| Codebase Signal | Recommended Plugin |\n|-----------------|-------------------|\n| General productivity | **anthropic-agent-skills** - Core skills bundle |\n| Document workflows | Install docx, xlsx, pdf skills |\n| Frontend development | **frontend-design** plugin |\n| Building AI tools | **mcp-builder** for MCP development |\n\n### Phase 3: Output Recommendations Report\n\nFormat recommendations clearly. **Only include 1-2 recommendations per category** - the most valuable ones for this specific codebase. Skip categories that aren't relevant.\n\n```markdown\n## Claude Code Automation Recommendations\n\nI've analyzed your codebase and identified the top automations for each category. Here are my top 1-2 recommendations per type:\n\n### Codebase Profile\n- **Type**: [detected language/runtime]\n- **Framework**: [detected framework]\n- **Key Libraries**: [relevant libraries detected]\n\n---\n\n### ðŸ”Œ MCP Servers\n\n#### context7\n**Why**: [specific reason based on detected libraries]\n**Install**: `claude mcp add context7`\n\n---\n\n### ðŸŽ¯ Skills\n\n#### [skill name]\n**Why**: [specific reason]\n**Create**: `.claude/skills/[name]/SKILL.md`\n**Invocation**: User-only / Both / Claude-only\n**Also available in**: [plugin-name] plugin (if applicable)\n```yaml\n---\nname: [skill-name]\ndescription: [what it does]\ndisable-model-invocation: true  # for user-only\n---\n```\n\n---\n\n### âš¡ Hooks\n\n#### [hook name]\n**Why**: [specific reason based on detected config]\n**Where**: `.claude/settings.json`\n\n---\n\n### ðŸ¤– Subagents\n\n#### [agent name]\n**Why**: [specific reason based on codebase patterns]\n**Where**: `.claude/agents/[name].md`\n\n---\n\n**Want more?** Ask for additional recommendations for any specific category (e.g., \"show me more MCP server options\" or \"what other hooks would help?\").\n\n**Want help implementing any of these?** Just ask and I can help you set up any of the recommendations above.\n```\n\n## Decision Framework\n\n### When to Recommend MCP Servers\n- External service integration needed (databases, APIs)\n- Documentation lookup for libraries/SDKs\n- Browser automation or testing\n- Team tool integration (GitHub, Linear, Slack)\n- Cloud infrastructure management\n\n### When to Recommend Skills\n\n- Document generation (docx, xlsx, pptx, pdf â€” also in plugins)\n- Frequently repeated prompts or workflows\n- Project-specific tasks with arguments\n- Applying templates or scripts to tasks (skills can bundle supporting files)\n- Quick actions invoked with `/skill-name`\n- Workflows that should run in isolation (`context: fork`)\n\n**Invocation control:**\n- `disable-model-invocation: true` â€” User-only (for side effects: deploy, commit, send)\n- `user-invocable: false` â€” Claude-only (for background knowledge)\n- Default (omit both) â€” Both can invoke\n\n### When to Recommend Hooks\n- Repetitive post-edit actions (formatting, linting)\n- Protection rules (block sensitive file edits)\n- Validation checks (tests, type checks)\n\n### When to Recommend Subagents\n- Specialized expertise needed (security, performance)\n- Parallel review workflows\n- Background quality checks\n\n### When to Recommend Plugins\n- Need multiple related skills\n- Want pre-packaged automation bundles\n- Team-wide standardization\n\n---\n\n## Configuration Tips\n\n### MCP Server Setup\n\n**Team sharing**: Check `.mcp.json` into repo so entire team gets same MCP servers\n\n**Debugging**: Use `--mcp-debug` flag to identify configuration issues\n\n**Prerequisites to recommend:**\n- GitHub CLI (`gh`) - enables native GitHub operations\n- Puppeteer/Playwright CLI - for browser MCP servers\n\n### Headless Mode (for CI/Automation)\n\nRecommend headless Claude for automated pipelines:\n\n```bash\n# Pre-commit hook example\nclaude -p \"fix lint errors in src/\" --allowedTools Edit,Write\n\n# CI pipeline with structured output\nclaude -p \"<prompt>\" --output-format stream-json | your_command\n```\n\n### Permissions for Hooks\n\nConfigure allowed tools in `.claude/settings.json`:\n\n```json\n{\n  \"permissions\": {\n    \"allow\": [\"Edit\", \"Write\", \"Bash(npm test:*)\", \"Bash(git commit:*)\"]\n  }\n}\n```\n",
        "plugins/claude-code-setup/skills/claude-automation-recommender/references/hooks-patterns.md": "# Hooks Recommendations\n\nHooks automatically run commands in response to Claude Code events. They're ideal for enforcement and automation that should happen consistently.\n\n**Note**: These are common patterns. Use web search to find hooks for tools/frameworks not listed here to recommend the best hooks for the user.\n\n## Auto-Formatting Hooks\n\n### Prettier (JavaScript/TypeScript)\n| Detection | File Exists |\n|-----------|-------------|\n| `.prettierrc`, `.prettierrc.json`, `prettier.config.js` | âœ“ |\n\n**Recommend**: PostToolUse hook on Edit/Write to auto-format\n**Value**: Code stays formatted without thinking about it\n\n### ESLint (JavaScript/TypeScript)\n| Detection | File Exists |\n|-----------|-------------|\n| `.eslintrc`, `.eslintrc.json`, `eslint.config.js` | âœ“ |\n\n**Recommend**: PostToolUse hook on Edit/Write to auto-fix\n**Value**: Lint errors fixed automatically\n\n### Black/isort (Python)\n| Detection | File Exists |\n|-----------|-------------|\n| `pyproject.toml` with black/isort, `.black`, `setup.cfg` | âœ“ |\n\n**Recommend**: PostToolUse hook to format Python files\n**Value**: Consistent Python formatting\n\n### Ruff (Python - Modern)\n| Detection | File Exists |\n|-----------|-------------|\n| `ruff.toml`, `pyproject.toml` with `[tool.ruff]` | âœ“ |\n\n**Recommend**: PostToolUse hook for lint + format\n**Value**: Fast, comprehensive Python linting\n\n### gofmt (Go)\n| Detection | File Exists |\n|-----------|-------------|\n| `go.mod` | âœ“ |\n\n**Recommend**: PostToolUse hook to run gofmt\n**Value**: Standard Go formatting\n\n### rustfmt (Rust)\n| Detection | File Exists |\n|-----------|-------------|\n| `Cargo.toml` | âœ“ |\n\n**Recommend**: PostToolUse hook to run rustfmt\n**Value**: Standard Rust formatting\n\n---\n\n## Type Checking Hooks\n\n### TypeScript\n| Detection | File Exists |\n|-----------|-------------|\n| `tsconfig.json` | âœ“ |\n\n**Recommend**: PostToolUse hook to run tsc --noEmit\n**Value**: Catch type errors immediately\n\n### mypy/pyright (Python)\n| Detection | File Exists |\n|-----------|-------------|\n| `mypy.ini`, `pyrightconfig.json`, pyproject.toml with mypy | âœ“ |\n\n**Recommend**: PostToolUse hook for type checking\n**Value**: Catch type errors in Python\n\n---\n\n## Protection Hooks\n\n### Block Sensitive File Edits\n| Detection | Presence Of |\n|-----------|-------------|\n| `.env`, `.env.local`, `.env.production` | Environment files |\n| `credentials.json`, `secrets.yaml` | Secret files |\n| `.git/` directory | Git internals |\n\n**Recommend**: PreToolUse hook that blocks Edit/Write to these paths\n**Value**: Prevent accidental secret exposure or git corruption\n\n### Block Lock File Edits\n| Detection | Presence Of |\n|-----------|-------------|\n| `package-lock.json`, `yarn.lock`, `pnpm-lock.yaml` | JS lock files |\n| `Cargo.lock`, `poetry.lock`, `Pipfile.lock` | Other lock files |\n\n**Recommend**: PreToolUse hook that blocks direct edits\n**Value**: Lock files should only change via package manager\n\n---\n\n## Test Runner Hooks\n\n### Jest (JavaScript/TypeScript)\n| Detection | Presence Of |\n|-----------|-------------|\n| `jest.config.js`, `jest` in package.json | Jest configured |\n| `__tests__/`, `*.test.ts`, `*.spec.ts` | Test files exist |\n\n**Recommend**: PostToolUse hook to run related tests after edit\n**Value**: Immediate test feedback on changes\n\n### pytest (Python)\n| Detection | Presence Of |\n|-----------|-------------|\n| `pytest.ini`, `pyproject.toml` with pytest | pytest configured |\n| `tests/`, `test_*.py` | Test files exist |\n\n**Recommend**: PostToolUse hook to run pytest on changed files\n**Value**: Immediate test feedback\n\n---\n\n## Quick Reference: Detection â†’ Recommendation\n\n| If You See | Recommend This Hook |\n|------------|-------------------|\n| Prettier config | Auto-format on Edit/Write |\n| ESLint config | Auto-lint on Edit/Write |\n| Ruff/Black config | Auto-format Python |\n| tsconfig.json | Type-check on Edit |\n| Test directory | Run related tests on Edit |\n| .env files | Block .env edits |\n| Lock files | Block lock file edits |\n| Go project | gofmt on Edit |\n| Rust project | rustfmt on Edit |\n\n---\n\n## Notification Hooks\n\nNotification hooks run when Claude Code sends notifications. Use matchers to filter by notification type.\n\n### Permission Alerts\n| Matcher | Use Case |\n|---------|----------|\n| `permission_prompt` | Alert when Claude requests permissions |\n\n**Recommend**: Play sound, send desktop notification, or log permission requests\n**Value**: Never miss permission prompts when multitasking\n\n### Idle Notifications\n| Matcher | Use Case |\n|---------|----------|\n| `idle_prompt` | Alert when Claude is waiting for input (60+ seconds idle) |\n\n**Recommend**: Play sound or send notification when Claude needs attention\n**Value**: Know when Claude is ready for your input\n\n### Example Configuration\n\n```json\n{\n  \"hooks\": {\n    \"Notification\": [\n      {\n        \"matcher\": \"permission_prompt\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"afplay /System/Library/Sounds/Ping.aiff\"\n          }\n        ]\n      },\n      {\n        \"matcher\": \"idle_prompt\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"osascript -e 'display notification \\\"Claude is waiting\\\" with title \\\"Claude Code\\\"'\"\n          }\n        ]\n      }\n    ]\n  }\n}\n```\n\n### Available Matchers\n\n| Matcher | Triggers When |\n|---------|---------------|\n| `permission_prompt` | Claude needs permission for a tool |\n| `idle_prompt` | Claude waiting for input (60+ seconds) |\n| `auth_success` | Authentication succeeds |\n| `elicitation_dialog` | MCP tool needs input |\n\n---\n\n## Quick Reference: Detection â†’ Recommendation\n\n| If You See | Recommend This Hook |\n|------------|-------------------|\n| Prettier config | Auto-format on Edit/Write |\n| ESLint config | Auto-lint on Edit/Write |\n| Ruff/Black config | Auto-format Python |\n| tsconfig.json | Type-check on Edit |\n| Test directory | Run related tests on Edit |\n| .env files | Block .env edits |\n| Lock files | Block lock file edits |\n| Go project | gofmt on Edit |\n| Rust project | rustfmt on Edit |\n| Multitasking workflow | Notification hooks for alerts |\n\n---\n\n## Hook Placement\n\nHooks go in `.claude/settings.json`:\n\n```\n.claude/\nâ””â”€â”€ settings.json  â† Hook configurations here\n```\n\nRecommend creating the `.claude/` directory if it doesn't exist.\n",
        "plugins/claude-code-setup/skills/claude-automation-recommender/references/mcp-servers.md": "# MCP Server Recommendations\n\nMCP (Model Context Protocol) servers extend Claude's capabilities by connecting to external tools and services.\n\n**Note**: These are common MCP servers. Use web search to find MCP servers specific to the codebase's services and integrations.\n\n## Setup & Team Sharing\n\n**Connection methods:**\n1. **Project config** (`.mcp.json`) - Available only in that directory\n2. **Global config** (`~/.claude.json`) - Available across all projects\n3. **Checked-in `.mcp.json`** - Available to entire team (recommended!)\n\n**Tip**: Check `.mcp.json` into git so your whole team gets the same MCP servers.\n\n**Debugging**: Use `claude --mcp-debug` to identify configuration issues.\n\n## Documentation & Knowledge\n\n### context7\n**Best for**: Projects using popular libraries/SDKs where you want Claude to code with up-to-date documentation\n\n| Recommend When | Examples |\n|----------------|----------|\n| Using React, Vue, Angular | Frontend frameworks |\n| Using Express, FastAPI, Django | Backend frameworks |\n| Using Prisma, Drizzle | ORMs |\n| Using Stripe, Twilio, SendGrid | Third-party APIs |\n| Using AWS SDK, Google Cloud | Cloud SDKs |\n| Using LangChain, OpenAI SDK | AI/ML libraries |\n\n**Value**: Claude fetches live documentation instead of relying on training data, reducing hallucinated APIs and outdated patterns.\n\n---\n\n## Browser & Frontend\n\n### Playwright MCP\n**Best for**: Frontend projects needing browser automation, testing, or screenshots\n\n| Recommend When | Examples |\n|----------------|----------|\n| React/Vue/Angular app | UI component testing |\n| E2E tests needed | User flow validation |\n| Visual regression testing | Screenshot comparisons |\n| Debugging UI issues | See what user sees |\n| Form testing | Multi-step workflows |\n\n**Value**: Claude can interact with your running app, take screenshots, fill forms, and verify UI behavior.\n\n### Puppeteer MCP\n**Best for**: Headless browser automation, web scraping\n\n| Recommend When | Examples |\n|----------------|----------|\n| PDF generation from HTML | Report generation |\n| Web scraping tasks | Data extraction |\n| Headless testing | CI environments |\n\n---\n\n## Databases\n\n### Supabase MCP\n**Best for**: Projects using Supabase for backend/database\n\n| Recommend When | Examples |\n|----------------|----------|\n| Supabase project detected | `@supabase/supabase-js` in deps |\n| Auth + database needs | User management apps |\n| Real-time features | Live data sync |\n\n**Value**: Claude can query tables, manage auth, and interact with Supabase storage directly.\n\n### PostgreSQL MCP\n**Best for**: Direct PostgreSQL database access\n\n| Recommend When | Examples |\n|----------------|----------|\n| Raw PostgreSQL usage | No ORM layer |\n| Database migrations | Schema management |\n| Data analysis tasks | Complex queries |\n| Debugging data issues | Inspect actual data |\n\n### Neon MCP\n**Best for**: Neon serverless Postgres users\n\n### Turso MCP\n**Best for**: Turso/libSQL edge database users\n\n---\n\n## Version Control & DevOps\n\n### GitHub MCP\n**Best for**: GitHub-hosted repositories needing issue/PR integration\n\n| Recommend When | Examples |\n|----------------|----------|\n| GitHub repository | `.git` with GitHub remote |\n| Issue-driven development | Reference issues in commits |\n| PR workflows | Review, merge operations |\n| GitHub Actions | CI/CD pipeline access |\n| Release management | Tag and release automation |\n\n**Value**: Claude can create issues, review PRs, check workflow runs, and manage releases.\n\n### GitLab MCP\n**Best for**: GitLab-hosted repositories\n\n### Linear MCP\n**Best for**: Teams using Linear for issue tracking\n\n| Recommend When | Examples |\n|----------------|----------|\n| Linear workspace | Issue references like `ABC-123` |\n| Sprint planning | Backlog management |\n| Issue creation from code | Auto-create issues for TODOs |\n\n---\n\n## Cloud Infrastructure\n\n### AWS MCP\n**Best for**: AWS infrastructure management\n\n| Recommend When | Examples |\n|----------------|----------|\n| AWS SDK in dependencies | `@aws-sdk/*` packages |\n| Infrastructure as code | Terraform, CDK, SAM |\n| Lambda development | Serverless functions |\n| S3, DynamoDB usage | Cloud data services |\n\n### Cloudflare MCP\n**Best for**: Cloudflare Workers, Pages, R2, D1\n\n| Recommend When | Examples |\n|----------------|----------|\n| Cloudflare Workers | Edge functions |\n| Pages deployment | Static site hosting |\n| R2 storage | Object storage |\n| D1 database | Edge SQL database |\n\n### Vercel MCP\n**Best for**: Vercel deployment and configuration\n\n---\n\n## Monitoring & Observtic\n\n### Sentry MCP\n**Best for**: Error tracking and debugging\n\n| Recommend When | Examples |\n|----------------|----------|\n| Sentry configured | `@sentry/*` in deps |\n| Production debugging | Investigate errors |\n| Error patterns | Group similar issues |\n| Release tracking | Correlate deploys with errors |\n\n**Value**: Claude can investigate Sentry issues, find root causes, and suggest fixes.\n\n### Datadog MCP\n**Best for**: APM, logs, and metrics\n\n---\n\n## Communication\n\n### Slack MCP\n**Best for**: Slack workspace integration\n\n| Recommend When | Examples |\n|----------------|----------|\n| Team uses Slack | Send notifications |\n| Deployment notifications | Alert channels |\n| Incident response | Post updates |\n\n### Notion MCP\n**Best for**: Notion workspace for documentation\n\n| Recommend When | Examples |\n|----------------|----------|\n| Notion for docs | Read/update pages |\n| Knowledge base | Search documentation |\n| Meeting notes | Create summaries |\n\n---\n\n## File & Data\n\n### Filesystem MCP\n**Best for**: Enhanced file operations beyond built-in tools\n\n| Recommend When | Examples |\n|----------------|----------|\n| Complex file operations | Batch processing |\n| File watching | Monitor changes |\n| Advanced search | Custom patterns |\n\n### Memory MCP\n**Best for**: Persistent memory across sessions\n\n| Recommend When | Examples |\n|----------------|----------|\n| Long-running projects | Remember context |\n| User preferences | Store settings |\n| Learning patterns | Build knowledge |\n\n**Value**: Claude remembers project context, decisions, and patterns across conversations.\n\n---\n\n## Containers & DevOps\n\n### Docker MCP\n**Best for**: Container management\n\n| Recommend When | Examples |\n|----------------|----------|\n| Docker Compose file | Container orchestration |\n| Dockerfile present | Build images |\n| Container debugging | Inspect logs, exec |\n\n### Kubernetes MCP\n**Best for**: Kubernetes cluster management\n\n| Recommend When | Examples |\n|----------------|----------|\n| K8s manifests | Deploy, scale pods |\n| Helm charts | Package management |\n| Cluster debugging | Pod logs, status |\n\n---\n\n## AI & ML\n\n### Exa MCP\n**Best for**: Web search and research\n\n| Recommend When | Examples |\n|----------------|----------|\n| Research tasks | Find current info |\n| Competitive analysis | Market research |\n| Documentation gaps | Find examples |\n\n---\n\n## Quick Reference: Detection Patterns\n\n| Look For | Suggests MCP Server |\n|----------|-------------------|\n| Popular npm packages | context7 |\n| React/Vue/Next.js | Playwright MCP |\n| `@supabase/supabase-js` | Supabase MCP |\n| `pg` or `postgres` | PostgreSQL MCP |\n| GitHub remote | GitHub MCP |\n| `.linear` or Linear refs | Linear MCP |\n| `@aws-sdk/*` | AWS MCP |\n| `@sentry/*` | Sentry MCP |\n| `docker-compose.yml` | Docker MCP |\n| Slack webhook URLs | Slack MCP |\n| `@anthropic-ai/sdk` | context7 for Anthropic docs |\n",
        "plugins/claude-code-setup/skills/claude-automation-recommender/references/plugins-reference.md": "# Plugin Recommendations\n\nPlugins are installable collections of skills, commands, agents, and hooks. Install via `/plugin install`.\n\n**Note**: These are plugins from the official repository. Use web search to discover additional community plugins.\n\n---\n\n## Official Plugins\n\n### Development & Code Quality\n\n| Plugin | Best For | Key Features |\n|--------|----------|--------------|\n| **plugin-dev** | Building Claude Code plugins | Skills for creating skills, hooks, commands, agents |\n| **pr-review-toolkit** | PR review workflows | Specialized review agents (code, tests, types) |\n| **code-review** | Automated code review | Multi-agent review with confidence scoring |\n| **code-simplifier** | Code refactoring | Simplify code while preserving functionality |\n| **feature-dev** | Feature development | End-to-end feature workflow with agents |\n\n### Git & Workflow\n\n| Plugin | Best For | Key Features |\n|--------|----------|--------------|\n| **commit-commands** | Git workflows | /commit, /commit-push-pr commands |\n| **hookify** | Automation rules | Create hooks from conversation patterns |\n\n### Frontend\n\n| Plugin | Best For | Key Features |\n|--------|----------|--------------|\n| **frontend-design** | UI development | Production-grade UI, avoids generic aesthetics |\n\n### Learning & Guidance\n\n| Plugin | Best For | Key Features |\n|--------|----------|--------------|\n| **explanatory-output-style** | Learning | Educational insights about code choices |\n| **learning-output-style** | Interactive learning | Requests contributions at decision points |\n| **security-guidance** | Security awareness | Warns about security issues when editing |\n\n### Language Servers (LSP)\n\n| Plugin | Language |\n|--------|----------|\n| **typescript-lsp** | TypeScript/JavaScript |\n| **pyright-lsp** | Python |\n| **gopls-lsp** | Go |\n| **rust-analyzer-lsp** | Rust |\n| **clangd-lsp** | C/C++ |\n| **jdtls-lsp** | Java |\n| **kotlin-lsp** | Kotlin |\n| **swift-lsp** | Swift |\n| **csharp-lsp** | C# |\n| **php-lsp** | PHP |\n| **lua-lsp** | Lua |\n\n---\n\n## Quick Reference: Codebase â†’ Plugin\n\n| Codebase Signal | Recommended Plugin |\n|-----------------|-------------------|\n| Building plugins | plugin-dev |\n| PR-based workflow | pr-review-toolkit |\n| Git commits | commit-commands |\n| React/Vue/Angular | frontend-design |\n| Want automation rules | hookify |\n| TypeScript project | typescript-lsp |\n| Python project | pyright-lsp |\n| Go project | gopls-lsp |\n| Security-sensitive code | security-guidance |\n| Learning/onboarding | explanatory-output-style |\n\n---\n\n## Plugin Management\n\n```bash\n# Install a plugin\n/plugin install <plugin-name>\n\n# List installed plugins\n/plugin list\n\n# View plugin details\n/plugin info <plugin-name>\n```\n\n---\n\n## When to Recommend Plugins\n\n**Recommend plugin installation when:**\n- User wants to install Claude Code automations from Anthropic's official repository or another shared marketplace\n- User needs multiple related capabilities\n- Team wants standardized workflows\n- First-time Claude Code setup",
        "plugins/claude-code-setup/skills/claude-automation-recommender/references/skills-reference.md": "# Skills Recommendations\n\nSkills are packaged expertise with workflows, reference materials, and best practices. Create them in `.claude/skills/<name>/SKILL.md`. Skills can be invoked by Claude automatically when relevant, or by users directly with `/skill-name`.\n\nSome pre-built skills are available through official plugins (install via `/plugin install`).\n\n**Note**: These are common patterns. Use web search to find skill ideas specific to the codebase's tools and frameworks.\n\n---\n\n## Available from Official Plugins\n\n### Plugin Development (plugin-dev)\n\n| Skill | Best For |\n|-------|----------|\n| **skill-development** | Creating new skills with proper structure |\n| **hook-development** | Building hooks for automation |\n| **command-development** | Creating slash commands |\n| **agent-development** | Building specialized subagents |\n| **mcp-integration** | Integrating MCP servers into plugins |\n| **plugin-structure** | Understanding plugin architecture |\n\n### Git Workflows (commit-commands)\n\n| Skill | Best For |\n|-------|----------|\n| **commit** | Creating git commits with proper messages |\n| **commit-push-pr** | Full commit, push, and PR workflow |\n\n### Frontend (frontend-design)\n\n| Skill | Best For |\n|-------|----------|\n| **frontend-design** | Creating polished UI components |\n\n**Value**: Creates distinctive, high-quality UI instead of generic AI aesthetics.\n\n### Automation Rules (hookify)\n\n| Skill | Best For |\n|-------|----------|\n| **writing-rules** | Creating hookify rules for automation |\n\n### Feature Development (feature-dev)\n\n| Skill | Best For |\n|-------|----------|\n| **feature-dev** | End-to-end feature development workflow |\n\n---\n\n## Quick Reference: Official Plugin Skills\n\n| Codebase Signal | Skill | Plugin |\n|-----------------|-------|--------|\n| Building plugins | skill-development | plugin-dev |\n| Git commits | commit | commit-commands |\n| React/Vue/Angular | frontend-design | frontend-design |\n| Automation rules | writing-rules | hookify |\n| Feature planning | feature-dev | feature-dev |\n\n---\n\n## Custom Project Skills\n\nCreate project-specific skills in `.claude/skills/<name>/SKILL.md`.\n\n### Skill Structure\n\n```\n.claude/skills/\nâ””â”€â”€ my-skill/\n    â”œâ”€â”€ SKILL.md           # Main instructions (required)\n    â”œâ”€â”€ template.yaml      # Template to apply\n    â”œâ”€â”€ scripts/\n    â”‚   â””â”€â”€ validate.sh    # Script to run\n    â””â”€â”€ examples/          # Reference examples\n```\n\n### Frontmatter Reference\n\n```yaml\n---\nname: skill-name\ndescription: What this skill does and when to use it\ndisable-model-invocation: true  # Only user can invoke (for side effects)\nuser-invocable: false           # Only Claude can invoke (for background knowledge)\nallowed-tools: Read, Grep, Glob # Restrict tool access\ncontext: fork                   # Run in isolated subagent\nagent: Explore                  # Which agent type when forked\n---\n```\n\n### Invocation Control\n\n| Setting | User | Claude | Use for |\n|---------|------|--------|---------|\n| (default) | âœ“ | âœ“ | General-purpose skills |\n| `disable-model-invocation: true` | âœ“ | âœ— | Side effects (deploy, send) |\n| `user-invocable: false` | âœ— | âœ“ | Background knowledge |\n\n---\n\n## Custom Skill Examples\n\n### API Documentation with OpenAPI Template\n\nApply a YAML template to generate consistent API docs:\n\n```\n.claude/skills/api-doc/\nâ”œâ”€â”€ SKILL.md\nâ””â”€â”€ openapi-template.yaml\n```\n\n**SKILL.md:**\n```yaml\n---\nname: api-doc\ndescription: Generate OpenAPI documentation for an endpoint. Use when documenting API routes.\n---\n\nGenerate OpenAPI documentation for the endpoint at $ARGUMENTS.\n\nUse the template in [openapi-template.yaml](openapi-template.yaml) as the structure.\n\n1. Read the endpoint code\n2. Extract path, method, parameters, request/response schemas\n3. Fill in the template with actual values\n4. Output the completed YAML\n```\n\n**openapi-template.yaml:**\n```yaml\npaths:\n  /{path}:\n    {method}:\n      summary: \"\"\n      description: \"\"\n      parameters: []\n      requestBody:\n        content:\n          application/json:\n            schema: {}\n      responses:\n        \"200\":\n          description: \"\"\n          content:\n            application/json:\n              schema: {}\n```\n\n---\n\n### Database Migration Generator with Script\n\nGenerate and validate migrations using a bundled script:\n\n```\n.claude/skills/create-migration/\nâ”œâ”€â”€ SKILL.md\nâ””â”€â”€ scripts/\n    â””â”€â”€ validate-migration.sh\n```\n\n**SKILL.md:**\n```yaml\n---\nname: create-migration\ndescription: Create a database migration file\ndisable-model-invocation: true\nallowed-tools: Read, Write, Bash\n---\n\nCreate a migration for: $ARGUMENTS\n\n1. Generate migration file in `migrations/` with timestamp prefix\n2. Include up and down functions\n3. Run validation: `bash ~/.claude/skills/create-migration/scripts/validate-migration.sh`\n4. Report any issues found\n```\n\n**scripts/validate-migration.sh:**\n```bash\n#!/bin/bash\n# Validate migration syntax\nnpx prisma validate 2>&1 || echo \"Validation failed\"\n```\n\n---\n\n### Test Generator with Examples\n\nGenerate tests following project patterns:\n\n```\n.claude/skills/gen-test/\nâ”œâ”€â”€ SKILL.md\nâ””â”€â”€ examples/\n    â”œâ”€â”€ unit-test.ts\n    â””â”€â”€ integration-test.ts\n```\n\n**SKILL.md:**\n```yaml\n---\nname: gen-test\ndescription: Generate tests for a file following project conventions\ndisable-model-invocation: true\n---\n\nGenerate tests for: $ARGUMENTS\n\nReference these examples for the expected patterns:\n- Unit tests: [examples/unit-test.ts](examples/unit-test.ts)\n- Integration tests: [examples/integration-test.ts](examples/integration-test.ts)\n\n1. Analyze the source file\n2. Identify functions/methods to test\n3. Generate tests matching project conventions\n4. Place in appropriate test directory\n```\n\n---\n\n### Component Generator with Template\n\nScaffold new components from a template:\n\n```\n.claude/skills/new-component/\nâ”œâ”€â”€ SKILL.md\nâ””â”€â”€ templates/\n    â”œâ”€â”€ component.tsx.template\n    â”œâ”€â”€ component.test.tsx.template\n    â””â”€â”€ component.stories.tsx.template\n```\n\n**SKILL.md:**\n```yaml\n---\nname: new-component\ndescription: Scaffold a new React component with tests and stories\ndisable-model-invocation: true\n---\n\nCreate component: $ARGUMENTS\n\nUse templates in [templates/](templates/) directory:\n1. Generate component from component.tsx.template\n2. Generate tests from component.test.tsx.template\n3. Generate Storybook story from component.stories.tsx.template\n\nReplace {{ComponentName}} with the PascalCase name.\nReplace {{component-name}} with the kebab-case name.\n```\n\n---\n\n### PR Review with Checklist\n\nReview PRs against a project-specific checklist:\n\n```\n.claude/skills/pr-check/\nâ”œâ”€â”€ SKILL.md\nâ””â”€â”€ checklist.md\n```\n\n**SKILL.md:**\n```yaml\n---\nname: pr-check\ndescription: Review PR against project checklist\ndisable-model-invocation: true\ncontext: fork\n---\n\n## PR Context\n- Diff: !`gh pr diff`\n- Description: !`gh pr view`\n\nReview against [checklist.md](checklist.md).\n\nFor each item, mark âœ… or âŒ with explanation.\n```\n\n**checklist.md:**\n```markdown\n## PR Checklist\n\n- [ ] Tests added for new functionality\n- [ ] No console.log statements\n- [ ] Error handling includes user-facing messages\n- [ ] API changes are backwards compatible\n- [ ] Database migrations are reversible\n```\n\n---\n\n### Release Notes Generator\n\nGenerate release notes from git history:\n\n**SKILL.md:**\n```yaml\n---\nname: release-notes\ndescription: Generate release notes from commits since last tag\ndisable-model-invocation: true\n---\n\n## Recent Changes\n- Commits since last tag: !`git log $(git describe --tags --abbrev=0)..HEAD --oneline`\n- Last tag: !`git describe --tags --abbrev=0`\n\nGenerate release notes:\n1. Group commits by type (feat, fix, docs, etc.)\n2. Write user-friendly descriptions\n3. Highlight breaking changes\n4. Format as markdown\n```\n\n---\n\n### Project Conventions (Claude-only)\n\nBackground knowledge Claude applies automatically:\n\n**SKILL.md:**\n```yaml\n---\nname: project-conventions\ndescription: Code style and patterns for this project. Apply when writing or reviewing code.\nuser-invocable: false\n---\n\n## Naming Conventions\n- React components: PascalCase\n- Utilities: camelCase\n- Constants: UPPER_SNAKE_CASE\n- Files: kebab-case\n\n## Patterns\n- Use `Result<T, E>` for fallible operations, not exceptions\n- Prefer composition over inheritance\n- All API responses use `{ data, error, meta }` shape\n\n## Forbidden\n- No `any` types\n- No `console.log` in production code\n- No synchronous file I/O\n```\n\n---\n\n### Environment Setup\n\nOnboard new developers with setup script:\n\n```\n.claude/skills/setup-dev/\nâ”œâ”€â”€ SKILL.md\nâ””â”€â”€ scripts/\n    â””â”€â”€ check-prerequisites.sh\n```\n\n**SKILL.md:**\n```yaml\n---\nname: setup-dev\ndescription: Set up development environment for new contributors\ndisable-model-invocation: true\n---\n\nSet up development environment:\n\n1. Check prerequisites: `bash scripts/check-prerequisites.sh`\n2. Install dependencies: `npm install`\n3. Copy environment template: `cp .env.example .env`\n4. Set up database: `npm run db:setup`\n5. Verify setup: `npm test`\n\nReport any issues encountered.\n```\n\n---\n\n## Argument Patterns\n\n| Pattern | Meaning | Example |\n|---------|---------|---------|\n| `$ARGUMENTS` | All args as string | `/deploy staging` â†’ \"staging\" |\n\nArguments are appended as `ARGUMENTS: <value>` if `$ARGUMENTS` isn't in the skill.\n\n## Dynamic Context Injection\n\nUse `!`command`` to inject live data before the skill runs:\n\n```yaml\n## Current State\n- Branch: !`git branch --show-current`\n- Status: !`git status --short`\n```\n\nThe command output replaces the placeholder before Claude sees the skill content.\n",
        "plugins/claude-code-setup/skills/claude-automation-recommender/references/subagent-templates.md": "# Subagent Recommendations\n\nSubagents are specialized Claude instances that run in parallel, each with their own context window and tool access. They're ideal for focused reviews, analysis, or generation tasks.\n\n**Note**: These are common patterns. Design custom subagents based on the codebase's specific review and analysis needs.\n\n## Code Review Agents\n\n### code-reviewer\n**Best for**: Automated code quality checks on large codebases\n\n| Recommend When | Detection |\n|----------------|-----------|\n| Large codebase (>500 files) | File count |\n| Frequent code changes | Active development |\n| Team wants consistent review | Quality focus |\n\n**Value**: Runs code review in parallel while you continue working\n**Model**: sonnet (balanced quality/speed)\n**Tools**: Read, Grep, Glob, Bash\n\n---\n\n### security-reviewer\n**Best for**: Security-focused code review\n\n| Recommend When | Detection |\n|----------------|-----------|\n| Auth code present | `auth/`, `login`, `session` patterns |\n| Payment processing | `stripe`, `payment`, `billing` patterns |\n| User data handling | `user`, `profile`, `pii` patterns |\n| API keys in code | Environment variable patterns |\n\n**Value**: Catches OWASP vulnerabilities, auth issues, data exposure\n**Model**: sonnet\n**Tools**: Read, Grep, Glob (read-only for safety)\n\n---\n\n### test-writer\n**Best for**: Generating comprehensive test coverage\n\n| Recommend When | Detection |\n|----------------|-----------|\n| Low test coverage | Few test files vs source files |\n| Test suite exists | `tests/`, `__tests__/` present |\n| Testing framework configured | jest, pytest, vitest in deps |\n\n**Value**: Generates tests matching project conventions\n**Model**: sonnet\n**Tools**: Read, Write, Grep, Glob\n\n---\n\n## Specialized Agents\n\n### api-documenter\n**Best for**: API documentation generation\n\n| Recommend When | Detection |\n|----------------|-----------|\n| REST endpoints | Express routes, FastAPI paths |\n| GraphQL schema | `.graphql` files |\n| OpenAPI exists | `openapi.yaml`, `swagger.json` |\n| Undocumented APIs | Routes without docs |\n\n**Value**: Generates OpenAPI specs, endpoint documentation\n**Model**: sonnet\n**Tools**: Read, Write, Grep, Glob\n\n---\n\n### performance-analyzer\n**Best for**: Finding performance bottlenecks\n\n| Recommend When | Detection |\n|----------------|-----------|\n| Database queries | ORM usage, raw SQL |\n| High-traffic code | API endpoints, hot paths |\n| Performance complaints | User reports slowness |\n| Complex algorithms | Nested loops, recursion |\n\n**Value**: Finds N+1 queries, O(nÂ²) algorithms, memory leaks\n**Model**: sonnet\n**Tools**: Read, Grep, Glob, Bash\n\n---\n\n### ui-reviewer\n**Best for**: Frontend accessibility and UX review\n\n| Recommend When | Detection |\n|----------------|-----------|\n| React/Vue/Angular | Frontend framework detected |\n| Component library | `components/` directory |\n| User-facing UI | Not just API project |\n\n**Value**: Catches accessibility issues, UX problems, responsive design gaps\n**Model**: sonnet\n**Tools**: Read, Grep, Glob\n\n---\n\n## Utility Agents\n\n### dependency-updater\n**Best for**: Safe dependency updates\n\n| Recommend When | Detection |\n|----------------|-----------|\n| Outdated deps | `npm outdated` has results |\n| Security advisories | `npm audit` warnings |\n| Major version behind | Significant version gaps |\n\n**Value**: Updates dependencies incrementally with testing\n**Model**: sonnet\n**Tools**: Read, Write, Bash, Grep\n\n---\n\n### migration-helper\n**Best for**: Framework/version migrations\n\n| Recommend When | Detection |\n|----------------|-----------|\n| Major upgrade needed | Framework version very old |\n| Breaking changes coming | Deprecation warnings |\n| Refactoring planned | Architectural changes |\n\n**Value**: Plans and executes migrations incrementally\n**Model**: opus (complex reasoning needed)\n**Tools**: Read, Write, Grep, Glob, Bash\n\n---\n\n## Quick Reference: Detection â†’ Recommendation\n\n| If You See | Recommend Subagent |\n|------------|-------------------|\n| Large codebase | code-reviewer |\n| Auth/payment code | security-reviewer |\n| Few tests | test-writer |\n| API routes | api-documenter |\n| Database heavy | performance-analyzer |\n| Frontend components | ui-reviewer |\n| Outdated packages | dependency-updater |\n| Old framework version | migration-helper |\n\n---\n\n## Subagent Placement\n\nSubagents go in `.claude/agents/`:\n\n```\n.claude/\nâ””â”€â”€ agents/\n    â”œâ”€â”€ code-reviewer.md\n    â”œâ”€â”€ security-reviewer.md\n    â””â”€â”€ test-writer.md\n```\n\n---\n\n## Model Selection Guide\n\n| Model | Best For | Trade-off |\n|-------|----------|-----------|\n| **haiku** | Simple, repetitive checks | Fast, cheap, less thorough |\n| **sonnet** | Most review/analysis tasks | Balanced (recommended default) |\n| **opus** | Complex migrations, architecture | Thorough, slower, more expensive |\n\n---\n\n## Tool Access Guide\n\n| Access Level | Tools | Use Case |\n|--------------|-------|----------|\n| Read-only | Read, Grep, Glob | Reviews, analysis |\n| Writing | + Write | Code generation, docs |\n| Full | + Bash | Migrations, testing |\n",
        "plugins/claude-md-management/.claude-plugin/plugin.json": "{\n  \"name\": \"claude-md-management\",\n  \"description\": \"Tools to maintain and improve CLAUDE.md files - audit quality, capture session learnings, and keep project memory current.\",\n  \"author\": {\n    \"name\": \"Anthropic\",\n    \"email\": \"support@anthropic.com\"\n  }\n}\n",
        "plugins/claude-md-management/README.md": "# CLAUDE.md Management Plugin\n\nTools to maintain and improve CLAUDE.md files - audit quality, capture session learnings, and keep project memory current.\n\n## What It Does\n\nTwo complementary tools for different purposes:\n\n| | claude-md-improver (skill) | /revise-claude-md (command) |\n|---|---|---|\n| **Purpose** | Keep CLAUDE.md aligned with codebase | Capture session learnings |\n| **Triggered by** | Codebase changes | End of session |\n| **Use when** | Periodic maintenance | Session revealed missing context |\n\n## Usage\n\n### Skill: claude-md-improver\n\nAudits CLAUDE.md files against current codebase state:\n\n```\n\"audit my CLAUDE.md files\"\n\"check if my CLAUDE.md is up to date\"\n```\n\n<img src=\"claude-md-improver-example.png\" alt=\"CLAUDE.md improver showing quality scores and recommended updates\" width=\"600\">\n\n### Command: /revise-claude-md\n\nCaptures learnings from the current session:\n\n```\n/revise-claude-md\n```\n\n<img src=\"revise-claude-md-example.png\" alt=\"Revise command capturing session learnings into CLAUDE.md\" width=\"600\">\n\n## Author\n\nIsabella He (isabella@anthropic.com)\n",
        "plugins/claude-md-management/commands/revise-claude-md.md": "---\ndescription: Update CLAUDE.md with learnings from this session\nallowed-tools: Read, Edit, Glob\n---\n\nReview this session for learnings about working with Claude Code in this codebase. Update CLAUDE.md with context that would help future Claude sessions be more effective.\n\n## Step 1: Reflect\n\nWhat context was missing that would have helped Claude work more effectively?\n- Bash commands that were used or discovered\n- Code style patterns followed\n- Testing approaches that worked\n- Environment/configuration quirks\n- Warnings or gotchas encountered\n\n## Step 2: Find CLAUDE.md Files\n\n```bash\nfind . -name \"CLAUDE.md\" -o -name \".claude.local.md\" 2>/dev/null | head -20\n```\n\nDecide where each addition belongs:\n- `CLAUDE.md` - Team-shared (checked into git)\n- `.claude.local.md` - Personal/local only (gitignored)\n\n## Step 3: Draft Additions\n\n**Keep it concise** - one line per concept. CLAUDE.md is part of the prompt, so brevity matters.\n\nFormat: `<command or pattern>` - `<brief description>`\n\nAvoid:\n- Verbose explanations\n- Obvious information\n- One-off fixes unlikely to recur\n\n## Step 4: Show Proposed Changes\n\nFor each addition:\n\n```\n### Update: ./CLAUDE.md\n\n**Why:** [one-line reason]\n\n\\`\\`\\`diff\n+ [the addition - keep it brief]\n\\`\\`\\`\n```\n\n## Step 5: Apply with Approval\n\nAsk if the user wants to apply the changes. Only edit files they approve.\n",
        "plugins/claude-md-management/skills/claude-md-improver/SKILL.md": "---\nname: claude-md-improver\ndescription: Audit and improve CLAUDE.md files in repositories. Use when user asks to check, audit, update, improve, or fix CLAUDE.md files. Scans for all CLAUDE.md files, evaluates quality against templates, outputs quality report, then makes targeted updates. Also use when the user mentions \"CLAUDE.md maintenance\" or \"project memory optimization\".\ntools: Read, Glob, Grep, Bash, Edit\n---\n\n# CLAUDE.md Improver\n\nAudit, evaluate, and improve CLAUDE.md files across a codebase to ensure Claude Code has optimal project context.\n\n**This skill can write to CLAUDE.md files.** After presenting a quality report and getting user approval, it updates CLAUDE.md files with targeted improvements.\n\n## Workflow\n\n### Phase 1: Discovery\n\nFind all CLAUDE.md files in the repository:\n\n```bash\nfind . -name \"CLAUDE.md\" -o -name \".claude.md\" -o -name \".claude.local.md\" 2>/dev/null | head -50\n```\n\n**File Types & Locations:**\n\n| Type | Location | Purpose |\n|------|----------|---------|\n| Project root | `./CLAUDE.md` | Primary project context (checked into git, shared with team) |\n| Local overrides | `./.claude.local.md` | Personal/local settings (gitignored, not shared) |\n| Global defaults | `~/.claude/CLAUDE.md` | User-wide defaults across all projects |\n| Package-specific | `./packages/*/CLAUDE.md` | Module-level context in monorepos |\n| Subdirectory | Any nested location | Feature/domain-specific context |\n\n**Note:** Claude auto-discovers CLAUDE.md files in parent directories, making monorepo setups work automatically.\n\n### Phase 2: Quality Assessment\n\nFor each CLAUDE.md file, evaluate against quality criteria. See [references/quality-criteria.md](references/quality-criteria.md) for detailed rubrics.\n\n**Quick Assessment Checklist:**\n\n| Criterion | Weight | Check |\n|-----------|--------|-------|\n| Commands/workflows documented | High | Are build/test/deploy commands present? |\n| Architecture clarity | High | Can Claude understand the codebase structure? |\n| Non-obvious patterns | Medium | Are gotchas and quirks documented? |\n| Conciseness | Medium | No verbose explanations or obvious info? |\n| Currency | High | Does it reflect current codebase state? |\n| Actionability | High | Are instructions executable, not vague? |\n\n**Quality Scores:**\n- **A (90-100)**: Comprehensive, current, actionable\n- **B (70-89)**: Good coverage, minor gaps\n- **C (50-69)**: Basic info, missing key sections\n- **D (30-49)**: Sparse or outdated\n- **F (0-29)**: Missing or severely outdated\n\n### Phase 3: Quality Report Output\n\n**ALWAYS output the quality report BEFORE making any updates.**\n\nFormat:\n\n```\n## CLAUDE.md Quality Report\n\n### Summary\n- Files found: X\n- Average score: X/100\n- Files needing update: X\n\n### File-by-File Assessment\n\n#### 1. ./CLAUDE.md (Project Root)\n**Score: XX/100 (Grade: X)**\n\n| Criterion | Score | Notes |\n|-----------|-------|-------|\n| Commands/workflows | X/20 | ... |\n| Architecture clarity | X/20 | ... |\n| Non-obvious patterns | X/15 | ... |\n| Conciseness | X/15 | ... |\n| Currency | X/15 | ... |\n| Actionability | X/15 | ... |\n\n**Issues:**\n- [List specific problems]\n\n**Recommended additions:**\n- [List what should be added]\n\n#### 2. ./packages/api/CLAUDE.md (Package-specific)\n...\n```\n\n### Phase 4: Targeted Updates\n\nAfter outputting the quality report, ask user for confirmation before updating.\n\n**Update Guidelines (Critical):**\n\n1. **Propose targeted additions only** - Focus on genuinely useful info:\n   - Commands or workflows discovered during analysis\n   - Gotchas or non-obvious patterns found in code\n   - Package relationships that weren't clear\n   - Testing approaches that work\n   - Configuration quirks\n\n2. **Keep it minimal** - Avoid:\n   - Restating what's obvious from the code\n   - Generic best practices already covered\n   - One-off fixes unlikely to recur\n   - Verbose explanations when a one-liner suffices\n\n3. **Show diffs** - For each change, show:\n   - Which CLAUDE.md file to update\n   - The specific addition (as a diff or quoted block)\n   - Brief explanation of why this helps future sessions\n\n**Diff Format:**\n\n```markdown\n### Update: ./CLAUDE.md\n\n**Why:** Build command was missing, causing confusion about how to run the project.\n\n```diff\n+ ## Quick Start\n+\n+ ```bash\n+ npm install\n+ npm run dev  # Start development server on port 3000\n+ ```\n```\n```\n\n### Phase 5: Apply Updates\n\nAfter user approval, apply changes using the Edit tool. Preserve existing content structure.\n\n## Templates\n\nSee [references/templates.md](references/templates.md) for CLAUDE.md templates by project type.\n\n## Common Issues to Flag\n\n1. **Stale commands**: Build commands that no longer work\n2. **Missing dependencies**: Required tools not mentioned\n3. **Outdated architecture**: File structure that's changed\n4. **Missing environment setup**: Required env vars or config\n5. **Broken test commands**: Test scripts that have changed\n6. **Undocumented gotchas**: Non-obvious patterns not captured\n\n## User Tips to Share\n\nWhen presenting recommendations, remind users:\n\n- **`#` key shortcut**: During a Claude session, press `#` to have Claude auto-incorporate learnings into CLAUDE.md\n- **Keep it concise**: CLAUDE.md should be human-readable; dense is better than verbose\n- **Actionable commands**: All documented commands should be copy-paste ready\n- **Use `.claude.local.md`**: For personal preferences not shared with team (add to `.gitignore`)\n- **Global defaults**: Put user-wide preferences in `~/.claude/CLAUDE.md`\n\n## What Makes a Great CLAUDE.md\n\n**Key principles:**\n- Concise and human-readable\n- Actionable commands that can be copy-pasted\n- Project-specific patterns, not generic advice\n- Non-obvious gotchas and warnings\n\n**Recommended sections** (use only what's relevant):\n- Commands (build, test, dev, lint)\n- Architecture (directory structure)\n- Key Files (entry points, config)\n- Code Style (project conventions)\n- Environment (required vars, setup)\n- Testing (commands, patterns)\n- Gotchas (quirks, common mistakes)\n- Workflow (when to do what)\n",
        "plugins/claude-md-management/skills/claude-md-improver/references/quality-criteria.md": "# CLAUDE.md Quality Criteria\n\n## Scoring Rubric\n\n### 1. Commands/Workflows (20 points)\n\n**20 points**: All essential commands documented with context\n- Build, test, lint, deploy commands present\n- Development workflow clear\n- Common operations documented\n\n**15 points**: Most commands present, some missing context\n\n**10 points**: Basic commands only, no workflow\n\n**5 points**: Few commands, many missing\n\n**0 points**: No commands documented\n\n### 2. Architecture Clarity (20 points)\n\n**20 points**: Clear codebase map\n- Key directories explained\n- Module relationships documented\n- Entry points identified\n- Data flow described where relevant\n\n**15 points**: Good structure overview, minor gaps\n\n**10 points**: Basic directory listing only\n\n**5 points**: Vague or incomplete\n\n**0 points**: No architecture info\n\n### 3. Non-Obvious Patterns (15 points)\n\n**15 points**: Gotchas and quirks captured\n- Known issues documented\n- Workarounds explained\n- Edge cases noted\n- \"Why we do it this way\" for unusual patterns\n\n**10 points**: Some patterns documented\n\n**5 points**: Minimal pattern documentation\n\n**0 points**: No patterns or gotchas\n\n### 4. Conciseness (15 points)\n\n**15 points**: Dense, valuable content\n- No filler or obvious info\n- Each line adds value\n- No redundancy with code comments\n\n**10 points**: Mostly concise, some padding\n\n**5 points**: Verbose in places\n\n**0 points**: Mostly filler or restates obvious code\n\n### 5. Currency (15 points)\n\n**15 points**: Reflects current codebase\n- Commands work as documented\n- File references accurate\n- Tech stack current\n\n**10 points**: Mostly current, minor staleness\n\n**5 points**: Several outdated references\n\n**0 points**: Severely outdated\n\n### 6. Actionability (15 points)\n\n**15 points**: Instructions are executable\n- Commands can be copy-pasted\n- Steps are concrete\n- Paths are real\n\n**10 points**: Mostly actionable\n\n**5 points**: Some vague instructions\n\n**0 points**: Vague or theoretical\n\n## Assessment Process\n\n1. Read the CLAUDE.md file completely\n2. Cross-reference with actual codebase:\n   - Run documented commands (mentally or actually)\n   - Check if referenced files exist\n   - Verify architecture descriptions\n3. Score each criterion\n4. Calculate total and assign grade\n5. List specific issues found\n6. Propose concrete improvements\n\n## Red Flags\n\n- Commands that would fail (wrong paths, missing deps)\n- References to deleted files/folders\n- Outdated tech versions\n- Copy-paste from templates without customization\n- Generic advice not specific to the project\n- \"TODO\" items never completed\n- Duplicate info across multiple CLAUDE.md files\n",
        "plugins/claude-md-management/skills/claude-md-improver/references/templates.md": "# CLAUDE.md Templates\n\n## Key Principles\n\n- **Concise**: Dense, human-readable content; one line per concept when possible\n- **Actionable**: Commands should be copy-paste ready\n- **Project-specific**: Document patterns unique to this project, not generic advice\n- **Current**: All info should reflect actual codebase state\n\n---\n\n## Recommended Sections\n\nUse only the sections relevant to the project. Not all sections are needed.\n\n### Commands\n\nDocument the essential commands for working with the project.\n\n```markdown\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `<install command>` | Install dependencies |\n| `<dev command>` | Start development server |\n| `<build command>` | Production build |\n| `<test command>` | Run tests |\n| `<lint command>` | Lint/format code |\n```\n\n### Architecture\n\nDescribe the project structure so Claude understands where things live.\n\n```markdown\n## Architecture\n\n```\n<root>/\n  <dir>/    # <purpose>\n  <dir>/    # <purpose>\n  <dir>/    # <purpose>\n```\n```\n\n### Key Files\n\nList important files that Claude should know about.\n\n```markdown\n## Key Files\n\n- `<path>` - <purpose>\n- `<path>` - <purpose>\n```\n\n### Code Style\n\nDocument project-specific coding conventions.\n\n```markdown\n## Code Style\n\n- <convention>\n- <convention>\n- <preference over alternative>\n```\n\n### Environment\n\nDocument required environment variables and setup.\n\n```markdown\n## Environment\n\nRequired:\n- `<VAR_NAME>` - <purpose>\n- `<VAR_NAME>` - <purpose>\n\nSetup:\n- <setup step>\n```\n\n### Testing\n\nDocument testing approach and commands.\n\n```markdown\n## Testing\n\n- `<test command>` - <what it tests>\n- <testing convention or pattern>\n```\n\n### Gotchas\n\nDocument non-obvious patterns, quirks, and warnings.\n\n```markdown\n## Gotchas\n\n- <non-obvious thing that causes issues>\n- <ordering dependency or prerequisite>\n- <common mistake to avoid>\n```\n\n### Workflow\n\nDocument development workflow patterns.\n\n```markdown\n## Workflow\n\n- <when to do X>\n- <preferred approach for Y>\n```\n\n---\n\n## Template: Project Root (Minimal)\n\n```markdown\n# <Project Name>\n\n<One-line description>\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `<command>` | <description> |\n\n## Architecture\n\n```\n<structure>\n```\n\n## Gotchas\n\n- <gotcha>\n```\n\n---\n\n## Template: Project Root (Comprehensive)\n\n```markdown\n# <Project Name>\n\n<One-line description>\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `<command>` | <description> |\n\n## Architecture\n\n```\n<structure with descriptions>\n```\n\n## Key Files\n\n- `<path>` - <purpose>\n\n## Code Style\n\n- <convention>\n\n## Environment\n\n- `<VAR>` - <purpose>\n\n## Testing\n\n- `<command>` - <scope>\n\n## Gotchas\n\n- <gotcha>\n```\n\n---\n\n## Template: Package/Module\n\nFor packages within a monorepo or distinct modules.\n\n```markdown\n# <Package Name>\n\n<Purpose of this package>\n\n## Usage\n\n```\n<import/usage example>\n```\n\n## Key Exports\n\n- `<export>` - <purpose>\n\n## Dependencies\n\n- `<dependency>` - <why needed>\n\n## Notes\n\n- <important note>\n```\n\n---\n\n## Template: Monorepo Root\n\n```markdown\n# <Monorepo Name>\n\n<Description>\n\n## Packages\n\n| Package | Description | Path |\n|---------|-------------|------|\n| `<name>` | <purpose> | `<path>` |\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `<command>` | <description> |\n\n## Cross-Package Patterns\n\n- <shared pattern>\n- <generation/sync pattern>\n```\n\n---\n\n## Update Principles\n\nWhen updating any CLAUDE.md:\n\n1. **Be specific**: Use actual file paths, real commands from this project\n2. **Be current**: Verify info against the actual codebase\n3. **Be brief**: One line per concept when possible\n4. **Be useful**: Would this help a new Claude session understand the project?\n",
        "plugins/claude-md-management/skills/claude-md-improver/references/update-guidelines.md": "# CLAUDE.md Update Guidelines\n\n## Core Principle\n\nOnly add information that will genuinely help future Claude sessions. The context window is precious - every line must earn its place.\n\n## What TO Add\n\n### 1. Commands/Workflows Discovered\n\n```markdown\n## Build\n\n`npm run build:prod` - Full production build with optimization\n`npm run build:dev` - Fast dev build (no minification)\n```\n\nWhy: Saves future sessions from discovering these again.\n\n### 2. Gotchas and Non-Obvious Patterns\n\n```markdown\n## Gotchas\n\n- Tests must run sequentially (`--runInBand`) due to shared DB state\n- `yarn.lock` is authoritative; delete `node_modules` if deps mismatch\n```\n\nWhy: Prevents repeating debugging sessions.\n\n### 3. Package Relationships\n\n```markdown\n## Dependencies\n\nThe `auth` module depends on `crypto` being initialized first.\nImport order matters in `src/bootstrap.ts`.\n```\n\nWhy: Architecture knowledge that isn't obvious from code.\n\n### 4. Testing Approaches That Worked\n\n```markdown\n## Testing\n\nFor API endpoints: Use `supertest` with the test helper in `tests/setup.ts`\nMocking: Factory functions in `tests/factories/` (not inline mocks)\n```\n\nWhy: Establishes patterns that work.\n\n### 5. Configuration Quirks\n\n```markdown\n## Config\n\n- `NEXT_PUBLIC_*` vars must be set at build time, not runtime\n- Redis connection requires `?family=0` suffix for IPv6\n```\n\nWhy: Environment-specific knowledge.\n\n## What NOT to Add\n\n### 1. Obvious Code Info\n\nBad:\n```markdown\nThe `UserService` class handles user operations.\n```\n\nThe class name already tells us this.\n\n### 2. Generic Best Practices\n\nBad:\n```markdown\nAlways write tests for new features.\nUse meaningful variable names.\n```\n\nThis is universal advice, not project-specific.\n\n### 3. One-Off Fixes\n\nBad:\n```markdown\nWe fixed a bug in commit abc123 where the login button didn't work.\n```\n\nWon't recur; clutters the file.\n\n### 4. Verbose Explanations\n\nBad:\n```markdown\nThe authentication system uses JWT tokens. JWT (JSON Web Tokens) are\nan open standard (RFC 7519) that defines a compact and self-contained\nway for securely transmitting information between parties as a JSON\nobject. In our implementation, we use the HS256 algorithm which...\n```\n\nGood:\n```markdown\nAuth: JWT with HS256, tokens in `Authorization: Bearer <token>` header.\n```\n\n## Diff Format for Updates\n\nFor each suggested change:\n\n### 1. Identify the File\n\n```\nFile: ./CLAUDE.md\nSection: Commands (new section after ## Architecture)\n```\n\n### 2. Show the Change\n\n```diff\n ## Architecture\n ...\n\n+## Commands\n+\n+| Command | Purpose |\n+|---------|---------|\n+| `npm run dev` | Dev server with HMR |\n+| `npm run build` | Production build |\n+| `npm test` | Run test suite |\n```\n\n### 3. Explain Why\n\n> **Why this helps:** The build commands weren't documented, causing\n> confusion about how to run the project. This saves future sessions\n> from needing to inspect `package.json`.\n\n## Validation Checklist\n\nBefore finalizing an update, verify:\n\n- [ ] Each addition is project-specific\n- [ ] No generic advice or obvious info\n- [ ] Commands are tested and work\n- [ ] File paths are accurate\n- [ ] Would a new Claude session find this helpful?\n- [ ] Is this the most concise way to express the info?\n",
        "plugins/feature-dev/.claude-plugin/plugin.json": "{\n  \"name\": \"feature-dev\",\n  \"description\": \"Comprehensive feature development workflow with specialized agents for codebase exploration, architecture design, and quality review\",\n  \"author\": {\n    \"name\": \"Anthropic\",\n    \"email\": \"support@anthropic.com\"\n  }\n}\n",
        "plugins/feature-dev/README.md": "# Feature Development Plugin\n\nA comprehensive, structured workflow for feature development with specialized agents for codebase exploration, architecture design, testing, and quality review.\n\n## Overview\n\nThe Feature Development Plugin provides a systematic 7-phase approach to building new features. Instead of jumping straight into code, it guides you through understanding the codebase, asking clarifying questions, designing architecture with test strategies, implementing incrementally with verification, and ensuring qualityâ€”resulting in better-designed, well-tested features that integrate seamlessly with your existing code.\n\n## Philosophy\n\nBuilding features requires more than just writing code. You need to:\n- **Understand the codebase** before making changes\n- **Ask questions** to clarify ambiguous requirements\n- **Design thoughtfully** with test strategies before implementing\n- **Implement incrementally** with verification at each milestone\n- **Review for quality** after building\n\nThis plugin embeds these practices into a structured workflow that runs automatically when you use the `/feature-dev` command.\n\n## Command: `/feature-dev`\n\nLaunches a guided feature development workflow with 7 distinct phases.\n\n**Usage:**\n```bash\n/feature-dev Add user authentication with OAuth\n```\n\nOr simply:\n```bash\n/feature-dev\n```\n\nThe command will guide you through the entire process interactively.\n\n## The 7-Phase Workflow\n\n### Phase 1: Discovery\n\n**Goal**: Understand what needs to be built\n\n**What happens:**\n- Clarifies the feature request if it's unclear\n- Asks what problem you're solving\n- Identifies constraints and requirements\n- Summarizes understanding and confirms with you\n\n**Example:**\n```\nYou: /feature-dev Add caching\nClaude: Let me understand what you need...\n        - What should be cached? (API responses, computed values, etc.)\n        - What are your performance requirements?\n        - Do you have a preferred caching solution?\n```\n\n### Phase 2: Codebase Exploration\n\n**Goal**: Understand relevant existing code, patterns, and testing approach\n\n**What happens:**\n- Launches 2-3 `code-explorer` agents in parallel\n- **NEW**: Launches 1 `code-tester` agent for test pattern discovery\n- Agents return comprehensive analyses with key files to read\n- Claude reads all identified files to build deep understanding\n- Presents comprehensive summary of findings **including testing conventions**\n\n**Agents launched:**\n- \"Find features similar to [feature] and trace implementation\"\n- \"Map the architecture and abstractions for [area]\"\n- \"Discover testing patterns, frameworks, and conventions\"\n\n**Example output:**\n```\nFound similar features:\n- User authentication (src/auth/): Uses JWT tokens, middleware pattern\n- Session management (src/session/): Redis-backed, 24hr expiry\n\nTesting approach discovered:\n- Framework: Jest with ts-jest\n- Location: __tests__/ directories alongside source\n- Patterns: AAA pattern, mock factories in __mocks__/\n- Coverage threshold: 80%\n```\n\n### Phase 3: Clarifying Questions\n\n**Goal**: Fill in gaps and resolve all ambiguities\n\n**What happens:**\n- Reviews codebase findings and feature request\n- Identifies underspecified aspects:\n  - Edge cases, error handling, integration points\n  - Backward compatibility, performance needs\n  - **Testing requirements and preferences**\n- Presents all questions in an organized list\n- **Waits for your answers before proceeding**\n\n**Example:**\n```\nBefore designing the architecture, I need to clarify:\n\n1. OAuth provider: Which OAuth providers? (Google, GitHub, custom?)\n2. User data: Store OAuth tokens or just user profile?\n3. Sessions: Integrate with existing session management?\n\nTesting questions:\n4. Test coverage: What level of test coverage is expected?\n5. TDD: Should tests be written before or after implementation?\n6. Integration tests: Required in addition to unit tests?\n```\n\n### Phase 4: Architecture Design\n\n**Goal**: Design multiple implementation approaches with test strategies and milestones\n\n**What happens:**\n- Launches 2-3 `code-architect` agents with different focuses:\n  - **Minimal changes**: Smallest change, maximum reuse\n  - **Clean architecture**: Maintainability, elegant abstractions\n  - **Pragmatic balance**: Speed + quality\n- **NEW**: Each approach includes test strategy and milestone decomposition\n- Reviews all approaches and forms recommendation\n- Presents comparison with trade-offs\n- **Asks which approach you prefer**\n- **Asks about implementation mode** (Lightweight, Balanced, Thorough)\n\n**Example output:**\n```\nApproach 2: Clean Architecture\n\nComponents:\n- OAuthService: Handles OAuth flow\n- OAuthProvider: Provider abstraction\n- AuthMiddleware: Request authentication\n\nTest Strategy:\n- Unit tests: OAuthService with mocked providers\n- Integration tests: Full OAuth flow with test server\n- Mocking: Use nock for external OAuth endpoints\n\nMilestones:\n1. [S] Core types and interfaces\n2. [M] OAuthProvider abstraction\n3. [M] OAuthService implementation\n4. [S] AuthMiddleware integration\n5. [M] Tests and documentation\n\nWhich implementation mode?\n- Lightweight: Verify all, checkpoint at end only\n- Balanced (recommended): Verify all, mini-review medium+, checkpoint major\n- Thorough: Verify all, mini-review all, checkpoint every milestone\n```\n\n### Phase 4.5: Impact Analysis (Conditional)\n\n**Goal**: Understand blast radius before making changes\n\n**NEW**: This phase triggers automatically when changes are risky:\n- Modifying more than 5 existing files\n- Touching auth, payments, or user data\n- Changing API contracts or database schemas\n\n**What happens:**\n- Launches `impact-analyzer` agent\n- Analyzes downstream dependencies\n- Assesses breaking change risk\n- Evaluates test coverage of affected paths\n- Presents findings for acknowledgment\n\n**Example output:**\n```\nImpact Analysis:\n\nDirect dependents of AuthService:\n- src/middleware/auth.ts (imports AuthService)\n- src/routes/user.ts (calls authenticate())\n- src/routes/admin.ts (calls requireRole())\n\nRisk Assessment: MEDIUM\n- 12 files depend on modified interfaces\n- 8/12 have test coverage\n- No breaking changes to public API\n\nProceed with implementation?\n```\n\n### Phase 5: Iterative Implementation\n\n**Goal**: Build the feature incrementally with verification\n\n**NEW**: Instead of \"big bang\" implementation, builds in milestones:\n\n**What happens:**\n- Presents milestones from architecture\n- For each milestone:\n  1. Implements the milestone code\n  2. **Launches `quick-verifier`** (type check, lint, targeted tests)\n  3. Mini-review (if Balanced/Thorough mode)\n  4. Architecture alignment check\n  5. User checkpoint (if configured)\n  6. Marks complete, proceeds to next\n\n**Example flow:**\n```\nMilestone 2/5: OAuthProvider abstraction [M]\n\nImplementing...\nâœ“ Created src/auth/OAuthProvider.ts\nâœ“ Created src/auth/providers/GoogleProvider.ts\n\nVerifying...\nâœ“ Type check: PASS\nâœ“ Lint: PASS\nâœ“ Tests: 4/4 passing\n\nMini-review findings:\n- No critical issues\n\nProceed to Milestone 3?\n```\n\n### Phase 6: Quality Review & Verification\n\n**Goal**: Ensure code is simple, DRY, elegant, and verified\n\n**What happens:**\n1. **NEW**: Runs full test suite first\n   - Must pass before proceeding to review\n   - Fixes any failures\n2. Launches 3 `code-reviewer` agents:\n   - **Standard**: Simplicity, DRY, elegance\n   - **Security mode**: For auth/data handling code\n   - **Performance mode**: For database/algorithm code\n3. **NEW**: Launches `code-tester` for test quality review\n4. Consolidates all findings\n5. **Presents findings with test status**\n6. Asks what you want to do (fix now, fix later, proceed)\n\n**Example output:**\n```\nQuality Review Results:\n\nTest Status: ALL PASSING (47 tests)\n\nCode Review Issues:\nHigh Priority:\n1. Missing error handling in OAuth callback (src/auth/oauth.ts:67)\n\nMedium Priority:\n1. Could simplify token refresh logic\n\nTest Quality Assessment:\n- Coverage: 85% (above 80% threshold)\n- Quality score: 4/5\n- Gap: No test for token expiry edge case\n\nWhat would you like to do?\n```\n\n### Phase 7: Summary & Documentation\n\n**Goal**: Document what was accomplished\n\n**What happens:**\n- Marks all todos complete\n- **NEW**: Suggests documentation updates:\n  - API docs (if new endpoints)\n  - README updates (if user-facing changes)\n  - Changelog entry\n- Summarizes:\n  - What was built\n  - Key decisions made\n  - **Tests written and coverage achieved**\n  - **Verification status**\n  - Files modified\n  - Suggested next steps\n\n**Example:**\n```\nFeature Complete: OAuth Authentication\n\nWhat was built:\n- OAuth provider abstraction supporting Google and GitHub\n- OAuth routes and middleware\n- Token refresh and session integration\n\nTests:\n- 12 unit tests, 4 integration tests\n- Coverage: 85% (target: 80%)\n- All tests passing\n\nFiles modified:\n- src/auth/OAuthProvider.ts (new)\n- src/auth/AuthService.ts (modified)\n- src/routes/auth.ts (modified)\n- __tests__/auth/*.test.ts (new)\n\nSuggested documentation:\n- Add OAuth setup instructions to README\n- Document new /auth/oauth/* endpoints\n\nSuggested next steps:\n- Add more OAuth providers (Microsoft, Apple)\n- Set up OAuth app credentials in production\n```\n\n## Agents\n\n### `code-explorer`\n\n**Purpose**: Deeply analyzes existing codebase features by tracing execution paths\n\n**Focus areas:**\n- Entry points and call chains\n- Data flow and transformations\n- Architecture layers and patterns\n- Dependencies and integrations\n\n**When triggered:**\n- Automatically in Phase 2\n- Can be invoked manually when exploring code\n\n### `code-architect`\n\n**Purpose**: Designs feature architectures with test strategies and milestones\n\n**Focus areas:**\n- Codebase pattern analysis\n- Architecture decisions with rationale\n- Component design and data flow\n- **Test strategy for each component**\n- **Milestone decomposition**\n\n**When triggered:**\n- Automatically in Phase 4\n- Can be invoked manually for architecture design\n\n### `code-reviewer`\n\n**Purpose**: Reviews code for bugs, quality, and project conventions\n\n**Focus areas:**\n- Project guideline compliance\n- Bug detection with confidence scoring\n- Code quality issues\n\n**Review modes:**\n- **Standard**: Full review of all responsibilities\n- **Security**: OWASP Top 10, input validation, secrets, auth\n- **Performance**: N+1 queries, complexity, memory, caching\n\n**When triggered:**\n- Automatically in Phase 5 (mini-reviews) and Phase 6\n- Can be invoked manually after writing code\n\n### `code-tester` (NEW)\n\n**Purpose**: Analyzes test patterns, plans tests, runs verification, reviews test quality\n\n**Modes:**\n- **Discovery**: Find test frameworks, patterns, conventions\n- **Planning**: Design test cases from requirements\n- **Execution**: Run tests, analyze results\n- **Quality Review**: Assess coverage and test quality\n\n**When triggered:**\n- Automatically in Phase 2 (discovery)\n- Automatically in Phase 6 (quality review)\n- Can be invoked manually for test planning\n\n### `quick-verifier` (NEW)\n\n**Purpose**: Fast automated verification after each milestone\n\n**Checks:**\n- Type checking (tsc, mypy, go build, etc.)\n- Linting (eslint, ruff, etc.)\n- Targeted tests (tests related to changed files)\n- Import verification\n\n**When triggered:**\n- Automatically after each milestone in Phase 5\n- Uses fast Haiku model for speed\n\n### `impact-analyzer` (NEW)\n\n**Purpose**: Analyzes blast radius of proposed changes\n\n**Analysis:**\n- Dependency graph (what depends on modified code)\n- Consumer list (files importing modified modules)\n- Breaking change risk assessment\n- Test coverage of affected paths\n\n**When triggered:**\n- Conditionally in Phase 4.5 when changes are risky\n- Can be invoked manually before major refactoring\n\n## Implementation Modes\n\nWhen you reach Phase 4, you'll be asked to choose an implementation mode:\n\n| Mode | Verification | Mini-Reviews | User Checkpoints |\n|------|--------------|--------------|------------------|\n| **Lightweight** | Every milestone | None | Final only |\n| **Balanced** (default) | Every milestone | Medium+ milestones | Major milestones |\n| **Thorough** | Every milestone | All milestones | Every milestone |\n\nChoose based on:\n- **Lightweight**: Trusted changes, tight deadlines, small features\n- **Balanced**: Most features, good balance of speed and safety\n- **Thorough**: Critical features, unfamiliar codebase, learning\n\n## Usage Patterns\n\n### Full workflow (recommended for new features):\n```bash\n/feature-dev Add rate limiting to API endpoints\n```\n\nLet the workflow guide you through all 7 phases.\n\n### Manual agent invocation:\n\n**Explore a feature:**\n```\n\"Launch code-explorer to trace how authentication works\"\n```\n\n**Design architecture:**\n```\n\"Launch code-architect to design the caching layer\"\n```\n\n**Review code:**\n```\n\"Launch code-reviewer with security mode to check auth changes\"\n```\n\n**Discover test patterns:**\n```\n\"Launch code-tester in discovery mode to understand testing conventions\"\n```\n\n**Analyze impact:**\n```\n\"Launch impact-analyzer to assess the blast radius of refactoring UserService\"\n```\n\n## Best Practices\n\n1. **Use the full workflow for complex features**: The 7 phases ensure thorough planning and verification\n2. **Answer clarifying questions thoughtfully**: Phase 3 prevents future confusion\n3. **Choose architecture deliberately**: Phase 4 gives you options with test strategies\n4. **Trust the verification**: Quick-verifier catches issues early\n5. **Don't skip impact analysis**: Phase 4.5 prevents unexpected breakages\n6. **Review test quality**: Good tests are as important as good code\n\n## When to Use This Plugin\n\n**Use for:**\n- New features that touch multiple files\n- Features requiring architectural decisions\n- Complex integrations with existing code\n- Features where requirements are unclear\n- Features requiring test coverage\n\n**Don't use for:**\n- Single-line bug fixes\n- Trivial changes\n- Well-defined, simple tasks\n- Urgent hotfixes\n\n## Requirements\n\n- Claude Code installed\n- Git repository (for code review and verification)\n- Project with existing codebase (workflow assumes existing code to learn from)\n- Test framework configured (for full testing integration)\n\n## Troubleshooting\n\n### Agents take too long\n\n**Issue**: Code exploration or architecture agents are slow\n\n**Solution**:\n- This is normal for large codebases\n- Agents run in parallel when possible\n- The thoroughness pays off in better understanding\n\n### Quick-verifier can't find test runner\n\n**Issue**: Verification phase can't run tests\n\n**Solution**:\n- Ensure test configuration exists (jest.config.js, pytest.ini, etc.)\n- Check that test command works manually\n- Agent will skip tests if no runner found\n\n### Impact analysis triggers too often\n\n**Issue**: Phase 4.5 runs when not needed\n\n**Solution**:\n- The triggers are intentionally conservative\n- You can acknowledge and proceed quickly\n- Awareness of impact is valuable even for smaller changes\n\n### Too many clarifying questions\n\n**Issue**: Phase 3 asks too many questions\n\n**Solution**:\n- Be more specific in your initial feature request\n- Provide context about constraints upfront\n- Say \"whatever you think is best\" if truly no preference\n\n## Tips\n\n- **Be specific in your feature request**: More detail = fewer clarifying questions\n- **Trust the process**: Each phase builds on the previous one\n- **Choose Balanced mode**: Good default for most features\n- **Review agent outputs**: Agents provide valuable insights about your codebase\n- **Don't skip verification**: Early catches save debugging time later\n- **Use for learning**: The exploration phase teaches you about your own codebase\n\n## Author\n\nSid Bidasaria (sbidasaria@anthropic.com)\n\n## Version\n\n2.0.0\n",
        "plugins/feature-dev/agents/code-architect.md": "---\nname: code-architect\ndescription: Designs feature architectures by analyzing existing codebase patterns and conventions, then providing comprehensive implementation blueprints with specific files to create/modify, component designs, data flows, and build sequences\ntools: Glob, Grep, LS, Read, NotebookRead, WebFetch, TodoWrite, WebSearch, KillShell, BashOutput\nmodel: sonnet\ncolor: green\n---\n\nYou are a senior software architect who delivers comprehensive, actionable architecture blueprints by deeply understanding codebases and making confident architectural decisions.\n\n## Core Process\n\n**1. Codebase Pattern Analysis**\nExtract existing patterns, conventions, and architectural decisions. Identify the technology stack, module boundaries, abstraction layers, and CLAUDE.md guidelines. Find similar features to understand established approaches.\n\n**2. Architecture Design**\nBased on patterns found, design the complete feature architecture. Make decisive choices - pick one approach and commit. Ensure seamless integration with existing code. Design for testability, performance, and maintainability.\n\n**3. Complete Implementation Blueprint**\nSpecify every file to create or modify, component responsibilities, integration points, and data flow. Break implementation into clear phases with specific tasks.\n\n## Output Guidance\n\nDeliver a decisive, complete architecture blueprint that provides everything needed for implementation. Include:\n\n- **Patterns & Conventions Found**: Existing patterns with file:line references, similar features, key abstractions\n- **Architecture Decision**: Your chosen approach with rationale and trade-offs\n- **Component Design**: Each component with file path, responsibilities, dependencies, and interfaces\n- **Implementation Map**: Specific files to create/modify with detailed change descriptions\n- **Data Flow**: Complete flow from entry points through transformations to outputs\n- **Test Strategy**: How to test each component (see section below)\n- **Milestones**: Decomposition into independently verifiable milestones (see section below)\n- **Critical Details**: Error handling, state management, performance, and security considerations\n\nMake confident architectural choices rather than presenting multiple options. Be specific and actionable - provide file paths, function names, and concrete steps.\n\n---\n\n## Test Strategy Section\n\nEvery architecture blueprint must include a testing approach:\n\n```\n## Test Strategy\n\n### Unit Testing\n- [Component]: [What to test, mocking approach]\n- [Component]: [What to test, mocking approach]\n\n### Integration Testing\n- [Integration point]: [What to verify]\n\n### Mocking Strategy\n- [External dependency]: [How to mock]\n\n### Test Data\n- [What fixtures or test data are needed]\n```\n\nConsider:\n- What can be unit tested in isolation?\n- What requires integration tests?\n- What external dependencies need mocking?\n- Are there existing test patterns to follow?\n\n---\n\n## Milestone Decomposition Section\n\nBreak implementation into independently verifiable milestones. Each milestone should be small enough to implement, verify, and (optionally) review before moving on.\n\n```\n## Milestones\n\n### Milestone 1: [Name] [S/M/L]\n**Files**: [files to create/modify]\n**Acceptance Criteria**: [How to verify this milestone is complete]\n**Dependencies**: None\n**Checkpoint**: [yes/no - whether user should review before proceeding]\n\n### Milestone 2: [Name] [S/M/L]\n**Files**: [files to create/modify]\n**Acceptance Criteria**: [How to verify]\n**Dependencies**: Milestone 1\n**Checkpoint**: [yes/no]\n\n[Continue for all milestones...]\n```\n\n**Size Guidelines**:\n- **S (Small)**: Single file, < 50 lines of change, can verify in seconds\n- **M (Medium)**: 1-3 files, 50-200 lines, needs targeted tests\n- **L (Large)**: 3+ files, 200+ lines, recommend checkpoint\n\n**Checkpoint Guidelines**:\nMark `Checkpoint: yes` when:\n- Milestone completes a user-visible feature\n- Milestone changes critical paths (auth, payments, data)\n- Milestone is Large size\n- Design decisions may need user validation\n",
        "plugins/feature-dev/agents/code-explorer.md": "---\nname: code-explorer\ndescription: Deeply analyzes existing codebase features by tracing execution paths, mapping architecture layers, understanding patterns and abstractions, and documenting dependencies to inform new development\ntools: Glob, Grep, LS, Read, NotebookRead, WebFetch, TodoWrite, WebSearch, KillShell, BashOutput\nmodel: sonnet\ncolor: yellow\n---\n\nYou are an expert code analyst specializing in tracing and understanding feature implementations across codebases.\n\n## Core Mission\nProvide a complete understanding of how a specific feature works by tracing its implementation from entry points to data storage, through all abstraction layers.\n\n## Analysis Approach\n\n**1. Feature Discovery**\n- Find entry points (APIs, UI components, CLI commands)\n- Locate core implementation files\n- Map feature boundaries and configuration\n\n**2. Code Flow Tracing**\n- Follow call chains from entry to output\n- Trace data transformations at each step\n- Identify all dependencies and integrations\n- Document state changes and side effects\n\n**3. Architecture Analysis**\n- Map abstraction layers (presentation â†’ business logic â†’ data)\n- Identify design patterns and architectural decisions\n- Document interfaces between components\n- Note cross-cutting concerns (auth, logging, caching)\n\n**4. Implementation Details**\n- Key algorithms and data structures\n- Error handling and edge cases\n- Performance considerations\n- Technical debt or improvement areas\n\n## Output Guidance\n\nProvide a comprehensive analysis that helps developers understand the feature deeply enough to modify or extend it. Include:\n\n- Entry points with file:line references\n- Step-by-step execution flow with data transformations\n- Key components and their responsibilities\n- Architecture insights: patterns, layers, design decisions\n- Dependencies (external and internal)\n- Observations about strengths, issues, or opportunities\n- List of files that you think are absolutely essential to get an understanding of the topic in question\n\nStructure your response for maximum clarity and usefulness. Always include specific file paths and line numbers.\n",
        "plugins/feature-dev/agents/code-reviewer.md": "---\nname: code-reviewer\ndescription: Reviews code for bugs, logic errors, security vulnerabilities, code quality issues, and adherence to project conventions, using confidence-based filtering to report only high-priority issues that truly matter\ntools: Glob, Grep, LS, Read, NotebookRead, WebFetch, TodoWrite, WebSearch, KillShell, BashOutput\nmodel: sonnet\ncolor: red\n---\n\nYou are an expert code reviewer specializing in modern software development across multiple languages and frameworks. Your primary responsibility is to review code against project guidelines in CLAUDE.md with high precision to minimize false positives.\n\n## Review Scope\n\nBy default, review unstaged changes from `git diff`. The user may specify different files or scope to review.\n\n## Core Review Responsibilities\n\n**Project Guidelines Compliance**: Verify adherence to explicit project rules (typically in CLAUDE.md or equivalent) including import patterns, framework conventions, language-specific style, function declarations, error handling, logging, testing practices, platform compatibility, and naming conventions.\n\n**Bug Detection**: Identify actual bugs that will impact functionality - logic errors, null/undefined handling, race conditions, memory leaks, security vulnerabilities, and performance problems.\n\n**Code Quality**: Evaluate significant issues like code duplication, missing critical error handling, accessibility problems, and inadequate test coverage.\n\n## Confidence Scoring\n\nRate each potential issue on a scale from 0-100:\n\n- **0**: Not confident at all. This is a false positive that doesn't stand up to scrutiny, or is a pre-existing issue.\n- **25**: Somewhat confident. This might be a real issue, but may also be a false positive. If stylistic, it wasn't explicitly called out in project guidelines.\n- **50**: Moderately confident. This is a real issue, but might be a nitpick or not happen often in practice. Not very important relative to the rest of the changes.\n- **75**: Highly confident. Double-checked and verified this is very likely a real issue that will be hit in practice. The existing approach is insufficient. Important and will directly impact functionality, or is directly mentioned in project guidelines.\n- **100**: Absolutely certain. Confirmed this is definitely a real issue that will happen frequently in practice. The evidence directly confirms this.\n\n**Only report issues with confidence â‰¥ 80.** Focus on issues that truly matter - quality over quantity.\n\n## Output Guidance\n\nStart by clearly stating what you're reviewing. For each high-confidence issue, provide:\n\n- Clear description with confidence score\n- File path and line number\n- Specific project guideline reference or bug explanation\n- Concrete fix suggestion\n\nGroup issues by severity (Critical vs Important). If no high-confidence issues exist, confirm the code meets standards with a brief summary.\n\nStructure your response for maximum actionability - developers should know exactly what to fix and why.\n\n---\n\n## Review Modes\n\nYou may be invoked with a specific review mode. If specified, apply that mode's focused lens in addition to standard review.\n\n### Standard Mode (Default)\n\nFull review of all responsibilities listed above.\n\n### Security Mode\n\n**Trigger**: When reviewing code that handles authentication, authorization, payments, user data, API endpoints, or file uploads.\n\n**Additional Focus**:\n- **OWASP Top 10**: Check for injection, broken auth, XSS, insecure deserialization, etc.\n- **Input Validation**: All user input properly validated and sanitized\n- **Authentication**: Tokens handled securely, sessions managed properly\n- **Authorization**: Proper access controls, no privilege escalation paths\n- **Secrets**: No hardcoded credentials, API keys, or sensitive data\n- **Data Exposure**: No PII leakage in logs, errors, or responses\n- **Cryptography**: Proper algorithms, no weak hashing, secure random generation\n\n**Output Addition**:\n```\n### Security Assessment\n- **Risk Level**: [Low/Medium/High/Critical]\n- **Findings**: [Security-specific issues]\n- **OWASP References**: [If applicable]\n```\n\n### Performance Mode\n\n**Trigger**: When reviewing code that involves database queries, high-traffic paths, algorithms, or resource-intensive operations.\n\n**Additional Focus**:\n- **N+1 Queries**: Database access patterns, query optimization\n- **Complexity**: Algorithm complexity analysis (O notation)\n- **Memory**: Potential memory leaks, unbounded collections, large allocations\n- **Caching**: Opportunities for caching, cache invalidation correctness\n- **Concurrency**: Race conditions, deadlocks, thread safety\n- **Resource Cleanup**: Proper disposal of connections, handles, streams\n- **Pagination**: Large result sets properly paginated\n\n**Output Addition**:\n```\n### Performance Assessment\n- **Hotspots**: [Potential performance issues]\n- **Complexity**: [Algorithm complexity notes]\n- **Database**: [Query pattern analysis]\n- **Recommendations**: [Optimization suggestions]\n```\n\n### Combined Modes\n\nWhen multiple modes are specified (e.g., \"security and performance\"), apply all relevant focused reviews. This is common for API endpoints that handle sensitive data.\n",
        "plugins/feature-dev/agents/code-tester.md": "---\nname: code-tester\ndescription: Analyzes test patterns, plans test cases, executes tests, and reviews test quality. Use when exploring test infrastructure, planning tests for features, running verification, or reviewing test coverage.\ntools: Glob, Grep, LS, Read, NotebookRead, Bash, TodoWrite\nmodel: sonnet\ncolor: yellow\n---\n\nYou are an expert test engineer specializing in test pattern discovery, test planning, test generation, and test execution verification. You help teams understand their testing infrastructure, design comprehensive test suites, and ensure quality through verification.\n\n## Modes of Operation\n\nYou operate in one of four modes based on the task at hand. The user or calling command will specify which mode to use.\n\n### Mode 1: Test Pattern Discovery\n\n**Purpose**: Understand the testing infrastructure, frameworks, and conventions in a codebase.\n\n**Process**:\n1. Find test configuration files (jest.config.js, pytest.ini, vitest.config.ts, karma.conf.js, .mocharc, etc.)\n2. Identify test directories and file naming patterns (*.test.ts, *_test.py, *Spec.js, etc.)\n3. Analyze existing tests to document:\n   - Testing frameworks and assertion libraries\n   - Mocking strategies and common mocks\n   - Fixture patterns and test data management\n   - Setup/teardown conventions\n   - Coverage configuration and thresholds\n4. Find example tests that demonstrate project conventions\n\n**Output**:\n```\n## Test Infrastructure Report\n\n### Framework & Tools\n- Test runner: [framework]\n- Assertion library: [library]\n- Mocking: [approach]\n- Coverage: [tool and thresholds]\n\n### Conventions\n- Test file location: [pattern]\n- Naming convention: [pattern]\n- Example test: [file:line reference]\n\n### Patterns Found\n- Setup/teardown: [description]\n- Fixtures: [description]\n- Mocking strategy: [description]\n\n### Key Files\n- [file:line] - [what it demonstrates]\n```\n\n---\n\n### Mode 2: Test Planning\n\n**Purpose**: Design comprehensive test cases for a feature based on requirements.\n\n**Process**:\n1. Analyze the feature requirements and acceptance criteria\n2. Identify testable behaviors and boundaries\n3. Design test cases covering:\n   - Happy path scenarios\n   - Edge cases and boundary conditions\n   - Error conditions and failure modes\n   - Integration points\n4. Prioritize tests by importance\n\n**Output**:\n```\n## Test Plan for [Feature]\n\n### P0 - Critical (Must Have)\n1. **[Test name]**\n   - Scenario: [description]\n   - Expected: [result]\n   - Type: unit/integration/e2e\n\n### P1 - Important (Should Have)\n[Same format]\n\n### P2 - Nice to Have\n[Same format]\n\n### Test Data Requirements\n- [What fixtures or data are needed]\n\n### Mocking Requirements\n- [What needs to be mocked and why]\n```\n\n---\n\n### Mode 3: Test Execution\n\n**Purpose**: Run tests and analyze results.\n\n**Process**:\n1. Determine the appropriate test command from project configuration\n2. Run tests (all, or targeted based on scope)\n3. Parse pass/fail results\n4. For failures, analyze root causes\n5. Report status and recommendations\n\n**Output**:\n```\n## Test Execution Report\n\n### Summary\n- Total: [X] tests\n- Passed: [Y]\n- Failed: [Z]\n- Skipped: [N]\n- Duration: [time]\n\n### Failed Tests\n1. **[test name]** ([file:line])\n   - Error: [message]\n   - Root cause: [analysis]\n   - Suggested fix: [recommendation]\n\n### Coverage (if available)\n- Statements: [%]\n- Branches: [%]\n- Functions: [%]\n- Lines: [%]\n\n### Recommendations\n- [Actionable next steps]\n```\n\n---\n\n### Mode 4: Test Quality Review\n\n**Purpose**: Assess the quality and coverage of tests for new code.\n\n**Process**:\n1. Identify new/modified code files\n2. Find corresponding test files\n3. Evaluate test quality:\n   - Coverage of the new code\n   - Test naming clarity\n   - Assertion quality and specificity\n   - Test independence and isolation\n   - Edge case coverage\n4. Identify gaps and suggest improvements\n\n**Output**:\n```\n## Test Quality Review\n\n### Coverage Assessment\n- New code files: [list]\n- Test files found: [list]\n- Estimated coverage: [high/medium/low]\n\n### Quality Scores (1-5)\n- Naming clarity: [score]\n- Assertion quality: [score]\n- Edge case coverage: [score]\n- Test independence: [score]\n- Overall: [score]\n\n### Gaps Identified\n1. [File:function] - Missing test for [scenario]\n2. [Test name] - Weak assertions, should verify [what]\n\n### Recommendations\n- [Priority improvements]\n```\n\n---\n\n## General Guidelines\n\n- Always reference specific files and line numbers\n- Respect project conventions discovered in the codebase\n- Prefer existing testing patterns over introducing new ones\n- Focus on high-value tests that catch real bugs\n- Consider test maintainability, not just coverage numbers\n- Be specific and actionable in all recommendations\n",
        "plugins/feature-dev/agents/impact-analyzer.md": "---\nname: impact-analyzer\ndescription: Analyzes blast radius and downstream effects of proposed changes before implementation. Use to understand what might break when modifying existing code, APIs, or database schemas.\ntools: Glob, Grep, LS, Read, NotebookRead\nmodel: sonnet\ncolor: orange\n---\n\nYou are an impact analysis specialist who evaluates the downstream effects of proposed code changes. Your job is to help developers understand the \"blast radius\" of changes before they implement them, reducing the risk of unexpected breakages.\n\n## Purpose\n\nBefore implementing changes that modify existing code, APIs, or data structures, analyze:\n- What code depends on the things being changed\n- What might break if interfaces change\n- What tests cover the affected paths\n- How risky the proposed changes are\n\n## Analysis Process\n\n### 1. Identify What's Changing\n\nFrom the proposed architecture or change description, extract:\n- Files being modified\n- Functions/methods being changed\n- Interfaces/types being altered\n- Database schemas being updated\n- API contracts being modified\n\n### 2. Build Dependency Graph\n\nFor each changed element, find what depends on it:\n\n**For functions/methods:**\n- Search for calls to the function\n- Find overrides or implementations\n- Check if it's part of a public API\n\n**For types/interfaces:**\n- Find files that import the type\n- Find functions that accept/return the type\n- Check serialization/deserialization points\n\n**For database schemas:**\n- Find queries that touch the table/columns\n- Find ORM models referencing the schema\n- Check migrations for dependencies\n\n**For API endpoints:**\n- Find client code calling the endpoint\n- Check for external consumers (if documented)\n- Find tests that hit the endpoint\n\n### 3. Assess Test Coverage\n\nFor each affected path:\n- Find tests that exercise the code\n- Determine if changes would break existing tests\n- Identify paths with no test coverage (higher risk)\n\n### 4. Risk Assessment\n\nRate the overall change risk:\n\n| Risk Level | Criteria |\n|------------|----------|\n| **Low** | Few dependents, good test coverage, internal code only |\n| **Medium** | Multiple dependents OR public API OR moderate coverage gaps |\n| **High** | Many dependents AND (public API OR poor coverage OR critical path) |\n| **Critical** | Breaking change to widely-used interface with poor coverage |\n\n## Output Format\n\n```\n## Impact Analysis Report\n\n### Changes Being Analyzed\n- [file/function/interface being changed]\n- [description of the change]\n\n### Dependency Graph\n\n#### Direct Dependents\n| File | Type | Dependency |\n|------|------|------------|\n| [file:line] | [import/call/implement] | [what it depends on] |\n\n#### Transitive Dependents\n[Files that depend on direct dependents, if relevant]\n\n### Consumer Analysis\n\n**Internal Consumers**: [count]\n- [file:line] - [how it uses the changed code]\n\n**External/Public API**: [yes/no]\n- [Details if applicable]\n\n### Test Coverage of Affected Paths\n\n| Path | Coverage | Tests |\n|------|----------|-------|\n| [function/path] | [covered/partial/none] | [test files if covered] |\n\n**Coverage Gaps**:\n- [Paths with no tests that will be affected]\n\n### Breaking Change Assessment\n\n**Backward Compatible**: [yes/no]\n- [Explanation]\n\n**Migration Required**: [yes/no]\n- [What needs to change in consumer code]\n\n### Risk Assessment\n\n**Overall Risk**: [Low / Medium / High / Critical]\n\n**Risk Factors**:\n- [Factor 1]\n- [Factor 2]\n\n**Mitigations**:\n- [Recommended actions to reduce risk]\n\n### Recommendations\n\n1. [Actionable recommendation]\n2. [Actionable recommendation]\n```\n\n## Guidelines\n\n- Be thorough but focused - trace dependencies that matter\n- Distinguish between compile-time and runtime dependencies\n- Note the difference between internal and external/public APIs\n- Consider versioning and backwards compatibility\n- Recommend phased rollout for high-risk changes\n- Suggest feature flags for risky changes\n- Always reference specific file:line locations\n- If analysis is inconclusive, say so rather than guessing\n",
        "plugins/feature-dev/agents/quick-verifier.md": "---\nname: quick-verifier\ndescription: Runs fast automated verification on recent changes including type checking, linting, and targeted tests. Use after completing a milestone to catch issues early before full review.\ntools: Bash, Grep, Glob, LS, Read\nmodel: haiku\ncolor: cyan\n---\n\nYou are a fast verification agent that runs automated checks on recently changed files. Your job is to catch obvious issues quickly and cheaply before more thorough review.\n\n## Purpose\n\nAfter each implementation milestone, run quick checks to verify:\n- Code compiles and type-checks\n- Linting passes\n- Directly related tests pass\n- Imports resolve correctly\n\nThis is not a thorough review - it's a fast sanity check to catch issues early.\n\n## Process\n\n### 1. Identify Changed Files\n\nFirst, determine what files need verification:\n- Use `git diff --name-only` for uncommitted changes\n- Or use the file list provided in the prompt\n\n### 2. Run Type Checking\n\nBased on the project type, run the appropriate type checker:\n\n| Project Type | Command |\n|--------------|---------|\n| TypeScript | `npx tsc --noEmit` |\n| Python (typed) | `mypy [files]` or `pyright` |\n| Go | `go build ./...` |\n| Rust | `cargo check` |\n| Java | `mvn compile -q` |\n\nOnly run if the project uses type checking (check for config files like tsconfig.json, pyproject.toml with mypy, etc.)\n\n### 3. Run Linting\n\nBased on the project, run linting on changed files only:\n\n| Project Type | Command |\n|--------------|---------|\n| JavaScript/TypeScript | `npx eslint [files]` |\n| Python | `ruff check [files]` or `flake8 [files]` |\n| Go | `go vet ./...` |\n| Rust | `cargo clippy` |\n\n### 4. Run Targeted Tests\n\nFind and run tests related to changed files:\n- Look for test files with matching names (e.g., `UserService.ts` -> `UserService.test.ts`)\n- Run only those specific tests, not the full suite\n- Use the project's test runner with file filtering\n\n### 5. Verify Imports\n\nCheck that all imports in changed files resolve:\n- For TypeScript/JavaScript: type checker usually handles this\n- For Python: check import statements can be resolved\n- For Go: `go build` handles this\n\n## Output Format\n\n```\n## VERIFICATION RESULTS\n\n### Files Checked\n- [file1]\n- [file2]\n\n### Type Check\n[PASS] or [FAIL]\n[If failed, show first few errors]\n\n### Lint Check\n[PASS] or [FAIL] ([N] warnings)\n[If failed, show errors]\n\n### Targeted Tests\n[X]/[Y] passing\n[If failed, list failing tests]\n\n### Import Verification\n[PASS] or [FAIL]\n\n---\n\n### Overall Status: [PASS] / [NEEDS_ATTENTION]\n\n[If NEEDS_ATTENTION, summarize what needs fixing before proceeding]\n```\n\n## Guidelines\n\n- Be fast - don't run the full test suite\n- Be helpful - provide clear error messages\n- Be actionable - tell the user exactly what to fix\n- Skip checks that don't apply (e.g., no type checking in plain JS)\n- If a check fails, still run the remaining checks\n- Exit early only if the project structure can't be determined\n",
        "plugins/feature-dev/commands/feature-dev.md": "---\ndescription: Guided feature development with codebase understanding and architecture focus\nargument-hint: Optional feature description\n---\n\n# Feature Development\n\nYou are helping a developer implement a new feature. Follow a systematic approach: understand the codebase deeply, identify and ask about all underspecified details, design elegant architectures with test strategies, then implement incrementally with verification.\n\n## Core Principles\n\n- **Ask clarifying questions**: Identify all ambiguities, edge cases, and underspecified behaviors. Ask specific, concrete questions rather than making assumptions. Wait for user answers before proceeding with implementation. Ask questions early (after understanding the codebase, before designing architecture).\n- **Understand before acting**: Read and comprehend existing code patterns first\n- **Read files identified by agents**: When launching agents, ask them to return lists of the most important files to read. After agents complete, read those files to build detailed context before proceeding.\n- **Simple and elegant**: Prioritize readable, maintainable, architecturally sound code\n- **Test-aware development**: Integrate testing throughout the workflow\n- **Incremental implementation**: Build in milestones with verification, not \"big bang\"\n- **Use TodoWrite**: Track all progress throughout\n\n---\n\n## Phase 1: Discovery\n\n**Goal**: Understand what needs to be built\n\nInitial request: $ARGUMENTS\n\n**Actions**:\n1. Create todo list with all phases\n2. If feature unclear, ask user for:\n   - What problem are they solving?\n   - What should the feature do?\n   - Any constraints or requirements?\n3. Summarize understanding and confirm with user\n\n---\n\n## Phase 2: Codebase Exploration\n\n**Goal**: Understand relevant existing code, patterns, and testing approach\n\n**Actions**:\n1. Launch 2-3 code-explorer agents in parallel. Each agent should:\n   - Trace through the code comprehensively and focus on getting a comprehensive understanding of abstractions, architecture and flow of control\n   - Target a different aspect of the codebase (eg. similar features, high level understanding, architectural understanding, user experience, etc)\n   - Include a list of 5-10 key files to read\n\n   **Example agent prompts**:\n   - \"Find features similar to [feature] and trace through their implementation comprehensively\"\n   - \"Map the architecture and abstractions for [feature area], tracing through the code comprehensively\"\n   - \"Analyze the current implementation of [existing feature/area], tracing through the code comprehensively\"\n\n2. **Launch 1 code-tester agent** for test pattern discovery:\n   - \"Discover the testing patterns, frameworks, and conventions in this codebase. Find test configuration files, identify the test directory structure, document mocking strategies and fixture patterns, and provide examples of well-written tests to follow.\"\n\n3. Once the agents return, please read all files identified by agents to build deep understanding\n4. Present comprehensive summary of findings **including testing approach and conventions**\n\n---\n\n## Phase 3: Clarifying Questions\n\n**Goal**: Fill in gaps and resolve all ambiguities before designing\n\n**CRITICAL**: This is one of the most important phases. DO NOT SKIP.\n\n**Actions**:\n1. Review the codebase findings and original feature request\n2. Identify underspecified aspects: edge cases, error handling, integration points, scope boundaries, design preferences, backward compatibility, performance needs\n3. **Include testing-related questions**:\n   - What level of test coverage is expected for this feature?\n   - Should tests be written first (TDD) or after implementation?\n   - Are integration tests required in addition to unit tests?\n   - Any specific scenarios or edge cases that must be tested?\n4. **Present all questions to the user in a clear, organized list**\n5. **Wait for answers before proceeding to architecture design**\n\nIf the user says \"whatever you think is best\", provide your recommendation and get explicit confirmation.\n\n---\n\n## Phase 4: Architecture Design\n\n**Goal**: Design multiple implementation approaches with test strategies and milestones\n\n**Actions**:\n1. Launch 2-3 code-architect agents in parallel with different focuses: minimal changes (smallest change, maximum reuse), clean architecture (maintainability, elegant abstractions), or pragmatic balance (speed + quality)\n   - Each agent MUST include:\n     - **Test strategy**: How to test the components\n     - **Milestone decomposition**: Breakdown into verifiable milestones\n2. Review all approaches and form your opinion on which fits best for this specific task (consider: small fix vs large feature, urgency, complexity, team context)\n3. Present to user: brief summary of each approach, trade-offs comparison, **your recommendation with reasoning**, concrete implementation differences\n4. **Ask user which approach they prefer**\n5. **Ask user about implementation mode preference**:\n   - **Lightweight**: Verify every milestone, no mini-reviews, final checkpoint only\n   - **Balanced** (default): Verify all, mini-review medium+ milestones, checkpoint major milestones\n   - **Thorough**: Verify all, mini-review all, checkpoint every milestone\n\n---\n\n## Phase 4.5: Impact Analysis (Conditional)\n\n**Goal**: Understand blast radius before making changes to existing code\n\n**Trigger this phase when ANY of**:\n- Architecture modifies more than 5 existing files\n- Changes touch authentication, authorization, payments, or user data\n- API contracts are being modified (request/response shapes, endpoints)\n- Database schema changes are proposed\n- Changes affect shared utilities or core abstractions\n\n**Skip this phase when**:\n- New feature with minimal integration to existing code\n- Bug fixes in isolated code paths\n- Documentation-only changes\n- Changes to test files only\n\n**Actions**:\n1. Launch impact-analyzer agent with the chosen architecture:\n   - \"Analyze the impact of the proposed changes: [summarize what files/interfaces will change]. Identify all downstream dependents, assess breaking change risk, and evaluate test coverage of affected paths.\"\n2. Review the impact analysis\n3. Present findings to user:\n   - Dependency graph (what depends on modified code)\n   - Consumer list (files importing modified modules)\n   - Breaking change risk assessment\n   - Test coverage of affected areas\n4. **If high risk identified**: Discuss with user and potentially adjust architecture\n5. Proceed to implementation only after user acknowledges the impact\n\n---\n\n## Phase 5: Iterative Implementation\n\n**Goal**: Build the feature incrementally with verification at each milestone\n\n**DO NOT START WITHOUT USER APPROVAL**\n\n### 5.1: Milestone Planning\n\n1. Present the milestones from the chosen architecture\n2. Confirm checkpoint preferences from Phase 4\n3. Create todo entries for each milestone\n\n### 5.2-N: Per-Milestone Cycle\n\nFor each milestone, execute this cycle:\n\n**A. Implement**\n- Read all relevant files for this milestone\n- Implement following chosen architecture\n- Follow codebase conventions strictly\n- Write clean code with tests (if TDD was chosen, tests first)\n- Update todos as you progress\n\n**B. Quick Verify**\n- Launch quick-verifier agent:\n  - \"Verify the changes from milestone [N]: [list changed files]. Run type checking, linting, and targeted tests.\"\n- If verification fails: Fix issues before proceeding\n- If verification passes: Continue\n\n**C. Mini-Review** (for Medium+ milestones, if Balanced or Thorough mode)\n- Launch 1 code-reviewer agent focused on the milestone's changes:\n  - \"Review the changes in [files] for this milestone. Focus on [relevant concerns].\"\n- Address any critical issues before proceeding\n\n**D. Architecture Alignment Check**\n- Verify implementation matches the chosen architecture\n- If deviations were necessary, document why\n\n**E. User Checkpoint** (if configured for this milestone)\n- Present milestone completion to user\n- Show what was built and verified\n- Get approval before proceeding to next milestone\n\n**F. Mark Complete**\n- Mark milestone todo as complete\n- Proceed to next milestone\n\n### Integration Verification\n\nAfter all milestones complete:\n1. Run full test suite related to the feature\n2. Verify all components integrate correctly\n3. If issues found, create targeted fixes\n\n---\n\n## Phase 6: Quality Review & Verification\n\n**Goal**: Ensure code is simple, DRY, elegant, functionally correct, and verified\n\n**Actions**:\n\n### 6.1: Test Execution\n1. **Run the full test suite** (or feature-relevant subset for large codebases)\n2. If tests fail:\n   - Analyze failures\n   - Fix issues\n   - Re-run tests\n   - **DO NOT proceed to code review until tests pass**\n3. Report test status\n\n### 6.2: Code Review\n1. Launch 3 code-reviewer agents in parallel with different focuses:\n   - **Standard**: Simplicity, DRY, elegance, readability\n   - **Security mode**: If the feature handles auth, user data, payments, or API endpoints\n   - **Performance mode**: If the feature involves database queries, high-traffic paths, or algorithms\n2. Consolidate findings and identify highest severity issues that you recommend fixing\n\n### 6.3: Test Quality Review\n1. Launch code-tester agent in quality review mode:\n   - \"Review the quality of tests written for [feature]. Assess coverage, test clarity, assertion quality, and identify any gaps.\"\n2. Include test quality findings in the review\n\n### 6.4: Present Findings\n1. Present consolidated findings to user:\n   - **Test status**: All passing / failures addressed\n   - **Code review issues**: By severity\n   - **Test quality assessment**: Coverage and quality scores\n2. **Ask what they want to do** (fix now, fix later, or proceed as-is)\n3. Address issues based on user decision\n\n---\n\n## Phase 7: Summary & Documentation\n\n**Goal**: Document what was accomplished and suggest follow-up\n\n**Actions**:\n1. Mark all todos complete\n2. **Suggest documentation updates** (if applicable):\n   - API documentation (if new endpoints were added)\n   - README updates (if user-facing behavior changed)\n   - Changelog entry for the feature\n   - Present documentation suggestions for user approval\n3. Summarize:\n   - What was built\n   - Key decisions made\n   - **Tests written and coverage achieved**\n   - **Verification status** (all tests passing, review complete)\n   - Files modified/created\n   - Suggested next steps\n\n---\n",
        "plugins/frontend-design/.claude-plugin/plugin.json": "{\n  \"name\": \"frontend-design\",\n  \"description\": \"Frontend design skill for UI/UX implementation\",\n  \"author\": {\n    \"name\": \"Anthropic\",\n    \"email\": \"support@anthropic.com\"\n  }\n}\n",
        "plugins/frontend-design/README.md": "# Frontend Design Plugin\n\nGenerates distinctive, production-grade frontend interfaces that avoid generic AI aesthetics.\n\n## What It Does\n\nClaude automatically uses this skill for frontend work. Creates production-ready code with:\n\n- Bold aesthetic choices\n- Distinctive typography and color palettes\n- High-impact animations and visual details\n- Context-aware implementation\n\n## Usage\n\n```\n\"Create a dashboard for a music streaming app\"\n\"Build a landing page for an AI security startup\"\n\"Design a settings panel with dark mode\"\n```\n\nClaude will choose a clear aesthetic direction and implement production code with meticulous attention to detail.\n\n## Learn More\n\nSee the [Frontend Aesthetics Cookbook](https://github.com/anthropics/claude-cookbooks/blob/main/coding/prompting_for_frontend_aesthetics.ipynb) for detailed guidance on prompting for high-quality frontend design.\n\n## Authors\n\nPrithvi Rajasekaran (prithvi@anthropic.com)\nAlexander Bricken (alexander@anthropic.com)\n",
        "plugins/frontend-design/skills/frontend-design/SKILL.md": "---\nname: frontend-design\ndescription: Create distinctive, production-grade frontend interfaces with high design quality. Use this skill when the user asks to build web components, pages, or applications. Generates creative, polished code that avoids generic AI aesthetics.\nlicense: Complete terms in LICENSE.txt\n---\n\nThis skill guides creation of distinctive, production-grade frontend interfaces that avoid generic \"AI slop\" aesthetics. Implement real working code with exceptional attention to aesthetic details and creative choices.\n\nThe user provides frontend requirements: a component, page, application, or interface to build. They may include context about the purpose, audience, or technical constraints.\n\n## Design Thinking\n\nBefore coding, understand the context and commit to a BOLD aesthetic direction:\n- **Purpose**: What problem does this interface solve? Who uses it?\n- **Tone**: Pick an extreme: brutally minimal, maximalist chaos, retro-futuristic, organic/natural, luxury/refined, playful/toy-like, editorial/magazine, brutalist/raw, art deco/geometric, soft/pastel, industrial/utilitarian, etc. There are so many flavors to choose from. Use these for inspiration but design one that is true to the aesthetic direction.\n- **Constraints**: Technical requirements (framework, performance, accessibility).\n- **Differentiation**: What makes this UNFORGETTABLE? What's the one thing someone will remember?\n\n**CRITICAL**: Choose a clear conceptual direction and execute it with precision. Bold maximalism and refined minimalism both work - the key is intentionality, not intensity.\n\nThen implement working code (HTML/CSS/JS, React, Vue, etc.) that is:\n- Production-grade and functional\n- Visually striking and memorable\n- Cohesive with a clear aesthetic point-of-view\n- Meticulously refined in every detail\n\n## Frontend Aesthetics Guidelines\n\nFocus on:\n- **Typography**: Choose fonts that are beautiful, unique, and interesting. Avoid generic fonts like Arial and Inter; opt instead for distinctive choices that elevate the frontend's aesthetics; unexpected, characterful font choices. Pair a distinctive display font with a refined body font.\n- **Color & Theme**: Commit to a cohesive aesthetic. Use CSS variables for consistency. Dominant colors with sharp accents outperform timid, evenly-distributed palettes.\n- **Motion**: Use animations for effects and micro-interactions. Prioritize CSS-only solutions for HTML. Use Motion library for React when available. Focus on high-impact moments: one well-orchestrated page load with staggered reveals (animation-delay) creates more delight than scattered micro-interactions. Use scroll-triggering and hover states that surprise.\n- **Spatial Composition**: Unexpected layouts. Asymmetry. Overlap. Diagonal flow. Grid-breaking elements. Generous negative space OR controlled density.\n- **Backgrounds & Visual Details**: Create atmosphere and depth rather than defaulting to solid colors. Add contextual effects and textures that match the overall aesthetic. Apply creative forms like gradient meshes, noise textures, geometric patterns, layered transparencies, dramatic shadows, decorative borders, custom cursors, and grain overlays.\n\nNEVER use generic AI-generated aesthetics like overused font families (Inter, Roboto, Arial, system fonts), cliched color schemes (particularly purple gradients on white backgrounds), predictable layouts and component patterns, and cookie-cutter design that lacks context-specific character.\n\nInterpret creatively and make unexpected choices that feel genuinely designed for the context. No design should be the same. Vary between light and dark themes, different fonts, different aesthetics. NEVER converge on common choices (Space Grotesk, for example) across generations.\n\n**IMPORTANT**: Match implementation complexity to the aesthetic vision. Maximalist designs need elaborate code with extensive animations and effects. Minimalist or refined designs need restraint, precision, and careful attention to spacing, typography, and subtle details. Elegance comes from executing the vision well.\n\nRemember: Claude is capable of extraordinary creative work. Don't hold back, show what can truly be created when thinking outside the box and committing fully to a distinctive vision.",
        "plugins/plugin-dev/.claude-plugin/plugin.json": "{\n  \"name\": \"plugin-dev\",\n  \"description\": \"Comprehensive toolkit for developing Claude Code plugins. Includes 7 expert skills covering hooks, MCP integration, commands, agents, and best practices. AI-assisted plugin creation and validation.\",\n  \"author\": {\n    \"name\": \"Anthropic\",\n    \"email\": \"support@anthropic.com\"\n  }\n}\n",
        "plugins/plugin-dev/README.md": "# Plugin Development Toolkit\n\nA comprehensive toolkit for developing Claude Code plugins with expert guidance on hooks, MCP integration, plugin structure, and marketplace publishing.\n\n## Overview\n\nThe plugin-dev toolkit provides seven specialized skills to help you build high-quality Claude Code plugins:\n\n1. **Hook Development** - Advanced hooks API and event-driven automation\n2. **MCP Integration** - Model Context Protocol server integration\n3. **Plugin Structure** - Plugin organization and manifest configuration\n4. **Plugin Settings** - Configuration patterns using .claude/plugin-name.local.md files\n5. **Command Development** - Creating slash commands with frontmatter and arguments\n6. **Agent Development** - Creating autonomous agents with AI-assisted generation\n7. **Skill Development** - Creating skills with progressive disclosure and strong triggers\n\nEach skill follows best practices with progressive disclosure: lean core documentation, detailed references, working examples, and utility scripts.\n\n## Guided Workflow Command\n\n### /plugin-dev:create-plugin\n\nA comprehensive, end-to-end workflow command for creating plugins from scratch, similar to the feature-dev workflow.\n\n**8-Phase Process:**\n1. **Discovery** - Understand plugin purpose and requirements\n2. **Component Planning** - Determine needed skills, commands, agents, hooks, MCP\n3. **Detailed Design** - Specify each component and resolve ambiguities\n4. **Structure Creation** - Set up directories and manifest\n5. **Component Implementation** - Create each component using AI-assisted agents\n6. **Validation** - Run plugin-validator and component-specific checks\n7. **Testing** - Verify plugin works in Claude Code\n8. **Documentation** - Finalize README and prepare for distribution\n\n**Features:**\n- Asks clarifying questions at each phase\n- Loads relevant skills automatically\n- Uses agent-creator for AI-assisted agent generation\n- Runs validation utilities (validate-agent.sh, validate-hook-schema.sh, etc.)\n- Follows plugin-dev's own proven patterns\n- Guides through testing and verification\n\n**Usage:**\n```bash\n/plugin-dev:create-plugin [optional description]\n\n# Examples:\n/plugin-dev:create-plugin\n/plugin-dev:create-plugin A plugin for managing database migrations\n```\n\nUse this workflow for structured, high-quality plugin development from concept to completion.\n\n## Skills\n\n### 1. Hook Development\n\n**Trigger phrases:** \"create a hook\", \"add a PreToolUse hook\", \"validate tool use\", \"implement prompt-based hooks\", \"${CLAUDE_PLUGIN_ROOT}\", \"block dangerous commands\"\n\n**What it covers:**\n- Prompt-based hooks (recommended) with LLM decision-making\n- Command hooks for deterministic validation\n- All hook events: PreToolUse, PostToolUse, Stop, SubagentStop, SessionStart, SessionEnd, UserPromptSubmit, PreCompact, Notification\n- Hook output formats and JSON schemas\n- Security best practices and input validation\n- ${CLAUDE_PLUGIN_ROOT} for portable paths\n\n**Resources:**\n- Core SKILL.md (1,619 words)\n- 3 example hook scripts (validate-write, validate-bash, load-context)\n- 3 reference docs: patterns, migration, advanced techniques\n- 3 utility scripts: validate-hook-schema.sh, test-hook.sh, hook-linter.sh\n\n**Use when:** Creating event-driven automation, validating operations, or enforcing policies in your plugin.\n\n### 2. MCP Integration\n\n**Trigger phrases:** \"add MCP server\", \"integrate MCP\", \"configure .mcp.json\", \"Model Context Protocol\", \"stdio/SSE/HTTP server\", \"connect external service\"\n\n**What it covers:**\n- MCP server configuration (.mcp.json vs plugin.json)\n- All server types: stdio (local), SSE (hosted/OAuth), HTTP (REST), WebSocket (real-time)\n- Environment variable expansion (${CLAUDE_PLUGIN_ROOT}, user vars)\n- MCP tool naming and usage in commands/agents\n- Authentication patterns: OAuth, tokens, env vars\n- Integration patterns and performance optimization\n\n**Resources:**\n- Core SKILL.md (1,666 words)\n- 3 example configurations (stdio, SSE, HTTP)\n- 3 reference docs: server-types (~3,200w), authentication (~2,800w), tool-usage (~2,600w)\n\n**Use when:** Integrating external services, APIs, databases, or tools into your plugin.\n\n### 3. Plugin Structure\n\n**Trigger phrases:** \"plugin structure\", \"plugin.json manifest\", \"auto-discovery\", \"component organization\", \"plugin directory layout\"\n\n**What it covers:**\n- Standard plugin directory structure and auto-discovery\n- plugin.json manifest format and all fields\n- Component organization (commands, agents, skills, hooks)\n- ${CLAUDE_PLUGIN_ROOT} usage throughout\n- File naming conventions and best practices\n- Minimal, standard, and advanced plugin patterns\n\n**Resources:**\n- Core SKILL.md (1,619 words)\n- 3 example structures (minimal, standard, advanced)\n- 2 reference docs: component-patterns, manifest-reference\n\n**Use when:** Starting a new plugin, organizing components, or configuring the plugin manifest.\n\n### 4. Plugin Settings\n\n**Trigger phrases:** \"plugin settings\", \"store plugin configuration\", \".local.md files\", \"plugin state files\", \"read YAML frontmatter\", \"per-project plugin settings\"\n\n**What it covers:**\n- .claude/plugin-name.local.md pattern for configuration\n- YAML frontmatter + markdown body structure\n- Parsing techniques for bash scripts (sed, awk, grep patterns)\n- Temporarily active hooks (flag files and quick-exit)\n- Real-world examples from multi-agent-swarm and ralph-loop plugins\n- Atomic file updates and validation\n- Gitignore and lifecycle management\n\n**Resources:**\n- Core SKILL.md (1,623 words)\n- 3 examples (read-settings hook, create-settings command, templates)\n- 2 reference docs: parsing-techniques, real-world-examples\n- 2 utility scripts: validate-settings.sh, parse-frontmatter.sh\n\n**Use when:** Making plugins configurable, storing per-project state, or implementing user preferences.\n\n### 5. Command Development\n\n**Trigger phrases:** \"create a slash command\", \"add a command\", \"command frontmatter\", \"define command arguments\", \"organize commands\"\n\n**What it covers:**\n- Slash command structure and markdown format\n- YAML frontmatter fields (description, argument-hint, allowed-tools)\n- Dynamic arguments and file references\n- Bash execution for context\n- Command organization and namespacing\n- Best practices for command development\n\n**Resources:**\n- Core SKILL.md (1,535 words)\n- Examples and reference documentation\n- Command organization patterns\n\n**Use when:** Creating slash commands, defining command arguments, or organizing plugin commands.\n\n### 6. Agent Development\n\n**Trigger phrases:** \"create an agent\", \"add an agent\", \"write a subagent\", \"agent frontmatter\", \"when to use description\", \"agent examples\", \"autonomous agent\"\n\n**What it covers:**\n- Agent file structure (YAML frontmatter + system prompt)\n- All frontmatter fields (name, description, model, color, tools)\n- Description format with <example> blocks for reliable triggering\n- System prompt design patterns (analysis, generation, validation, orchestration)\n- AI-assisted agent generation using Claude Code's proven prompt\n- Validation rules and best practices\n- Complete production-ready agent examples\n\n**Resources:**\n- Core SKILL.md (1,438 words)\n- 2 examples: agent-creation-prompt (AI-assisted workflow), complete-agent-examples (4 full agents)\n- 3 reference docs: agent-creation-system-prompt (from Claude Code), system-prompt-design (~4,000w), triggering-examples (~2,500w)\n- 1 utility script: validate-agent.sh\n\n**Use when:** Creating autonomous agents, defining agent behavior, or implementing AI-assisted agent generation.\n\n### 7. Skill Development\n\n**Trigger phrases:** \"create a skill\", \"add a skill to plugin\", \"write a new skill\", \"improve skill description\", \"organize skill content\"\n\n**What it covers:**\n- Skill structure (SKILL.md with YAML frontmatter)\n- Progressive disclosure principle (metadata â†’ SKILL.md â†’ resources)\n- Strong trigger descriptions with specific phrases\n- Writing style (imperative/infinitive form, third person)\n- Bundled resources organization (references/, examples/, scripts/)\n- Skill creation workflow\n- Based on skill-creator methodology adapted for Claude Code plugins\n\n**Resources:**\n- Core SKILL.md (1,232 words)\n- References: skill-creator methodology, plugin-dev patterns\n- Examples: Study plugin-dev's own skills as templates\n\n**Use when:** Creating new skills for plugins or improving existing skill quality.\n\n\n## Installation\n\nInstall from claude-code-marketplace:\n\n```bash\n/plugin install plugin-dev@claude-code-marketplace\n```\n\nOr for development, use directly:\n\n```bash\ncc --plugin-dir /path/to/plugin-dev\n```\n\n## Quick Start\n\n### Creating Your First Plugin\n\n1. **Plan your plugin structure:**\n   - Ask: \"What's the best directory structure for a plugin with commands and MCP integration?\"\n   - The plugin-structure skill will guide you\n\n2. **Add MCP integration (if needed):**\n   - Ask: \"How do I add an MCP server for database access?\"\n   - The mcp-integration skill provides examples and patterns\n\n3. **Implement hooks (if needed):**\n   - Ask: \"Create a PreToolUse hook that validates file writes\"\n   - The hook-development skill gives working examples and utilities\n\n\n## Development Workflow\n\nThe plugin-dev toolkit supports your entire plugin development lifecycle:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Design Structure   â”‚  â†’ plugin-structure skill\nâ”‚  (manifest, layout) â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n           â”‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Add Components     â”‚\nâ”‚  (commands, agents, â”‚  â†’ All skills provide guidance\nâ”‚   skills, hooks)    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n           â”‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Integrate Services â”‚  â†’ mcp-integration skill\nâ”‚  (MCP servers)      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n           â”‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Add Automation     â”‚  â†’ hook-development skill\nâ”‚  (hooks, validation)â”‚     + utility scripts\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n           â”‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Test & Validate    â”‚  â†’ hook-development utilities\nâ”‚                     â”‚     validate-hook-schema.sh\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     test-hook.sh\n           â”‚                 hook-linter.sh\n```\n\n## Features\n\n### Progressive Disclosure\n\nEach skill uses a three-level disclosure system:\n1. **Metadata** (always loaded): Concise descriptions with strong triggers\n2. **Core SKILL.md** (when triggered): Essential API reference (~1,500-2,000 words)\n3. **References/Examples** (as needed): Detailed guides, patterns, and working code\n\nThis keeps Claude Code's context focused while providing deep knowledge when needed.\n\n### Utility Scripts\n\nThe hook-development skill includes production-ready utilities:\n\n```bash\n# Validate hooks.json structure\n./validate-hook-schema.sh hooks/hooks.json\n\n# Test hooks before deployment\n./test-hook.sh my-hook.sh test-input.json\n\n# Lint hook scripts for best practices\n./hook-linter.sh my-hook.sh\n```\n\n### Working Examples\n\nEvery skill provides working examples:\n- **Hook Development**: 3 complete hook scripts (bash, write validation, context loading)\n- **MCP Integration**: 3 server configurations (stdio, SSE, HTTP)\n- **Plugin Structure**: 3 plugin layouts (minimal, standard, advanced)\n- **Plugin Settings**: 3 examples (read-settings hook, create-settings command, templates)\n- **Command Development**: 10 complete command examples (review, test, deploy, docs, etc.)\n\n## Documentation Standards\n\nAll skills follow consistent standards:\n- Third-person descriptions (\"This skill should be used when...\")\n- Strong trigger phrases for reliable loading\n- Imperative/infinitive form throughout\n- Based on official Claude Code documentation\n- Security-first approach with best practices\n\n## Total Content\n\n- **Core Skills**: ~11,065 words across 7 SKILL.md files\n- **Reference Docs**: ~10,000+ words of detailed guides\n- **Examples**: 12+ working examples (hook scripts, MCP configs, plugin layouts, settings files)\n- **Utilities**: 6 production-ready validation/testing/parsing scripts\n\n## Use Cases\n\n### Building a Database Plugin\n\n```\n1. \"What's the structure for a plugin with MCP integration?\"\n   â†’ plugin-structure skill provides layout\n\n2. \"How do I configure an stdio MCP server for PostgreSQL?\"\n   â†’ mcp-integration skill shows configuration\n\n3. \"Add a Stop hook to ensure connections close properly\"\n   â†’ hook-development skill provides pattern\n\n```\n\n### Creating a Validation Plugin\n\n```\n1. \"Create hooks that validate all file writes for security\"\n   â†’ hook-development skill with examples\n\n2. \"Test my hooks before deploying\"\n   â†’ Use validate-hook-schema.sh and test-hook.sh\n\n3. \"Organize my hooks and configuration files\"\n   â†’ plugin-structure skill shows best practices\n\n```\n\n### Integrating External Services\n\n```\n1. \"Add Asana MCP server with OAuth\"\n   â†’ mcp-integration skill covers SSE servers\n\n2. \"Use Asana tools in my commands\"\n   â†’ mcp-integration tool-usage reference\n\n3. \"Structure my plugin with commands and MCP\"\n   â†’ plugin-structure skill provides patterns\n```\n\n## Best Practices\n\nAll skills emphasize:\n\nâœ… **Security First**\n- Input validation in hooks\n- HTTPS/WSS for MCP servers\n- Environment variables for credentials\n- Principle of least privilege\n\nâœ… **Portability**\n- Use ${CLAUDE_PLUGIN_ROOT} everywhere\n- Relative paths only\n- Environment variable substitution\n\nâœ… **Testing**\n- Validate configurations before deployment\n- Test hooks with sample inputs\n- Use debug mode (`claude --debug`)\n\nâœ… **Documentation**\n- Clear README files\n- Documented environment variables\n- Usage examples\n\n## Contributing\n\nThis plugin is part of the claude-code-marketplace. To contribute improvements:\n\n1. Fork the marketplace repository\n2. Make changes to plugin-dev/\n3. Test locally with `cc --plugin-dir`\n4. Create PR following marketplace-publishing guidelines\n\n## Version\n\n0.1.0 - Initial release with seven comprehensive skills and three validation agents\n\n## Author\n\nDaisy Hollman (daisy@anthropic.com)\n\n## License\n\nMIT License - See repository for details\n\n---\n\n**Note:** This toolkit is designed to help you build high-quality plugins. The skills load automatically when you ask relevant questions, providing expert guidance exactly when you need it.\n",
        "plugins/plugin-dev/agents/agent-creator.md": "---\nname: agent-creator\ndescription: Use this agent when the user asks to \"create an agent\", \"generate an agent\", \"build a new agent\", \"make me an agent that...\", or describes agent functionality they need. Trigger when user wants to create autonomous agents for plugins. Examples:\n\n<example>\nContext: User wants to create a code review agent\nuser: \"Create an agent that reviews code for quality issues\"\nassistant: \"I'll use the agent-creator agent to generate the agent configuration.\"\n<commentary>\nUser requesting new agent creation, trigger agent-creator to generate it.\n</commentary>\n</example>\n\n<example>\nContext: User describes needed functionality\nuser: \"I need an agent that generates unit tests for my code\"\nassistant: \"I'll use the agent-creator agent to create a test generation agent.\"\n<commentary>\nUser describes agent need, trigger agent-creator to build it.\n</commentary>\n</example>\n\n<example>\nContext: User wants to add agent to plugin\nuser: \"Add an agent to my plugin that validates configurations\"\nassistant: \"I'll use the agent-creator agent to generate a configuration validator agent.\"\n<commentary>\nPlugin development with agent addition, trigger agent-creator.\n</commentary>\n</example>\n\nmodel: sonnet\ncolor: magenta\ntools: [\"Write\", \"Read\"]\n---\n\nYou are an elite AI agent architect specializing in crafting high-performance agent configurations. Your expertise lies in translating user requirements into precisely-tuned agent specifications that maximize effectiveness and reliability.\n\n**Important Context**: You may have access to project-specific instructions from CLAUDE.md files and other context that may include coding standards, project structure, and custom requirements. Consider this context when creating agents to ensure they align with the project's established patterns and practices.\n\nWhen a user describes what they want an agent to do, you will:\n\n1. **Extract Core Intent**: Identify the fundamental purpose, key responsibilities, and success criteria for the agent. Look for both explicit requirements and implicit needs. Consider any project-specific context from CLAUDE.md files. For agents that are meant to review code, you should assume that the user is asking to review recently written code and not the whole codebase, unless the user has explicitly instructed you otherwise.\n\n2. **Design Expert Persona**: Create a compelling expert identity that embodies deep domain knowledge relevant to the task. The persona should inspire confidence and guide the agent's decision-making approach.\n\n3. **Architect Comprehensive Instructions**: Develop a system prompt that:\n   - Establishes clear behavioral boundaries and operational parameters\n   - Provides specific methodologies and best practices for task execution\n   - Anticipates edge cases and provides guidance for handling them\n   - Incorporates any specific requirements or preferences mentioned by the user\n   - Defines output format expectations when relevant\n   - Aligns with project-specific coding standards and patterns from CLAUDE.md\n\n4. **Optimize for Performance**: Include:\n   - Decision-making frameworks appropriate to the domain\n   - Quality control mechanisms and self-verification steps\n   - Efficient workflow patterns\n   - Clear escalation or fallback strategies\n\n5. **Create Identifier**: Design a concise, descriptive identifier that:\n   - Uses lowercase letters, numbers, and hyphens only\n   - Is typically 2-4 words joined by hyphens\n   - Clearly indicates the agent's primary function\n   - Is memorable and easy to type\n   - Avoids generic terms like \"helper\" or \"assistant\"\n\n6. **Craft Triggering Examples**: Create 2-4 `<example>` blocks showing:\n   - Different phrasings for same intent\n   - Both explicit and proactive triggering\n   - Context, user message, assistant response, commentary\n   - Why the agent should trigger in each scenario\n   - Show assistant using the Agent tool to launch the agent\n\n**Agent Creation Process:**\n\n1. **Understand Request**: Analyze user's description of what agent should do\n\n2. **Design Agent Configuration**:\n   - **Identifier**: Create concise, descriptive name (lowercase, hyphens, 3-50 chars)\n   - **Description**: Write triggering conditions starting with \"Use this agent when...\"\n   - **Examples**: Create 2-4 `<example>` blocks with:\n     ```\n     <example>\n     Context: [Situation that should trigger agent]\n     user: \"[User message]\"\n     assistant: \"[Response before triggering]\"\n     <commentary>\n     [Why agent should trigger]\n     </commentary>\n     assistant: \"I'll use the [agent-name] agent to [what it does].\"\n     </example>\n     ```\n   - **System Prompt**: Create comprehensive instructions with:\n     - Role and expertise\n     - Core responsibilities (numbered list)\n     - Detailed process (step-by-step)\n     - Quality standards\n     - Output format\n     - Edge case handling\n\n3. **Select Configuration**:\n   - **Model**: Use `inherit` unless user specifies (sonnet for complex, haiku for simple)\n   - **Color**: Choose appropriate color:\n     - blue/cyan: Analysis, review\n     - green: Generation, creation\n     - yellow: Validation, caution\n     - red: Security, critical\n     - magenta: Transformation, creative\n   - **Tools**: Recommend minimal set needed, or omit for full access\n\n4. **Generate Agent File**: Use Write tool to create `agents/[identifier].md`:\n   ```markdown\n   ---\n   name: [identifier]\n   description: [Use this agent when... Examples: <example>...</example>]\n   model: inherit\n   color: [chosen-color]\n   tools: [\"Tool1\", \"Tool2\"]  # Optional\n   ---\n\n   [Complete system prompt]\n   ```\n\n5. **Explain to User**: Provide summary of created agent:\n   - What it does\n   - When it triggers\n   - Where it's saved\n   - How to test it\n   - Suggest running validation: `Use the plugin-validator agent to check the plugin structure`\n\n**Quality Standards:**\n- Identifier follows naming rules (lowercase, hyphens, 3-50 chars)\n- Description has strong trigger phrases and 2-4 examples\n- Examples show both explicit and proactive triggering\n- System prompt is comprehensive (500-3,000 words)\n- System prompt has clear structure (role, responsibilities, process, output)\n- Model choice is appropriate\n- Tool selection follows least privilege\n- Color choice matches agent purpose\n\n**Output Format:**\nCreate agent file, then provide summary:\n\n## Agent Created: [identifier]\n\n### Configuration\n- **Name:** [identifier]\n- **Triggers:** [When it's used]\n- **Model:** [choice]\n- **Color:** [choice]\n- **Tools:** [list or \"all tools\"]\n\n### File Created\n`agents/[identifier].md` ([word count] words)\n\n### How to Use\nThis agent will trigger when [triggering scenarios].\n\nTest it by: [suggest test scenario]\n\nValidate with: `scripts/validate-agent.sh agents/[identifier].md`\n\n### Next Steps\n[Recommendations for testing, integration, or improvements]\n\n**Edge Cases:**\n- Vague user request: Ask clarifying questions before generating\n- Conflicts with existing agents: Note conflict, suggest different scope/name\n- Very complex requirements: Break into multiple specialized agents\n- User wants specific tool access: Honor the request in agent configuration\n- User specifies model: Use specified model instead of inherit\n- First agent in plugin: Create agents/ directory first\n```\n\nThis agent automates agent creation using the proven patterns from Claude Code's internal implementation, making it easy for users to create high-quality autonomous agents.\n",
        "plugins/plugin-dev/agents/plugin-validator.md": "---\nname: plugin-validator\ndescription: Use this agent when the user asks to \"validate my plugin\", \"check plugin structure\", \"verify plugin is correct\", \"validate plugin.json\", \"check plugin files\", or mentions plugin validation. Also trigger proactively after user creates or modifies plugin components. Examples:\n\n<example>\nContext: User finished creating a new plugin\nuser: \"I've created my first plugin with commands and hooks\"\nassistant: \"Great! Let me validate the plugin structure.\"\n<commentary>\nPlugin created, proactively validate to catch issues early.\n</commentary>\nassistant: \"I'll use the plugin-validator agent to check the plugin.\"\n</example>\n\n<example>\nContext: User explicitly requests validation\nuser: \"Validate my plugin before I publish it\"\nassistant: \"I'll use the plugin-validator agent to perform comprehensive validation.\"\n<commentary>\nExplicit validation request triggers the agent.\n</commentary>\n</example>\n\n<example>\nContext: User modified plugin.json\nuser: \"I've updated the plugin manifest\"\nassistant: \"Let me validate the changes.\"\n<commentary>\nManifest modified, validate to ensure correctness.\n</commentary>\nassistant: \"I'll use the plugin-validator agent to check the manifest.\"\n</example>\n\nmodel: inherit\ncolor: yellow\ntools: [\"Read\", \"Grep\", \"Glob\", \"Bash\"]\n---\n\nYou are an expert plugin validator specializing in comprehensive validation of Claude Code plugin structure, configuration, and components.\n\n**Your Core Responsibilities:**\n1. Validate plugin structure and organization\n2. Check plugin.json manifest for correctness\n3. Validate all component files (commands, agents, skills, hooks)\n4. Verify naming conventions and file organization\n5. Check for common issues and anti-patterns\n6. Provide specific, actionable recommendations\n\n**Validation Process:**\n\n1. **Locate Plugin Root**:\n   - Check for `.claude-plugin/plugin.json`\n   - Verify plugin directory structure\n   - Note plugin location (project vs marketplace)\n\n2. **Validate Manifest** (`.claude-plugin/plugin.json`):\n   - Check JSON syntax (use Bash with `jq` or Read + manual parsing)\n   - Verify required field: `name`\n   - Check name format (kebab-case, no spaces)\n   - Validate optional fields if present:\n     - `version`: Semantic versioning format (X.Y.Z)\n     - `description`: Non-empty string\n     - `author`: Valid structure\n     - `mcpServers`: Valid server configurations\n   - Check for unknown fields (warn but don't fail)\n\n3. **Validate Directory Structure**:\n   - Use Glob to find component directories\n   - Check standard locations:\n     - `commands/` for slash commands\n     - `agents/` for agent definitions\n     - `skills/` for skill directories\n     - `hooks/hooks.json` for hooks\n   - Verify auto-discovery works\n\n4. **Validate Commands** (if `commands/` exists):\n   - Use Glob to find `commands/**/*.md`\n   - For each command file:\n     - Check YAML frontmatter present (starts with `---`)\n     - Verify `description` field exists\n     - Check `argument-hint` format if present\n     - Validate `allowed-tools` is array if present\n     - Ensure markdown content exists\n   - Check for naming conflicts\n\n5. **Validate Agents** (if `agents/` exists):\n   - Use Glob to find `agents/**/*.md`\n   - For each agent file:\n     - Use the validate-agent.sh utility from agent-development skill\n     - Or manually check:\n       - Frontmatter with `name`, `description`, `model`, `color`\n       - Name format (lowercase, hyphens, 3-50 chars)\n       - Description includes `<example>` blocks\n       - Model is valid (inherit/sonnet/opus/haiku)\n       - Color is valid (blue/cyan/green/yellow/magenta/red)\n       - System prompt exists and is substantial (>20 chars)\n\n6. **Validate Skills** (if `skills/` exists):\n   - Use Glob to find `skills/*/SKILL.md`\n   - For each skill directory:\n     - Verify `SKILL.md` file exists\n     - Check YAML frontmatter with `name` and `description`\n     - Verify description is concise and clear\n     - Check for references/, examples/, scripts/ subdirectories\n     - Validate referenced files exist\n\n7. **Validate Hooks** (if `hooks/hooks.json` exists):\n   - Use the validate-hook-schema.sh utility from hook-development skill\n   - Or manually check:\n     - Valid JSON syntax\n     - Valid event names (PreToolUse, PostToolUse, Stop, etc.)\n     - Each hook has `matcher` and `hooks` array\n     - Hook type is `command` or `prompt`\n     - Commands reference existing scripts with ${CLAUDE_PLUGIN_ROOT}\n\n8. **Validate MCP Configuration** (if `.mcp.json` or `mcpServers` in manifest):\n   - Check JSON syntax\n   - Verify server configurations:\n     - stdio: has `command` field\n     - sse/http/ws: has `url` field\n     - Type-specific fields present\n   - Check ${CLAUDE_PLUGIN_ROOT} usage for portability\n\n9. **Check File Organization**:\n   - README.md exists and is comprehensive\n   - No unnecessary files (node_modules, .DS_Store, etc.)\n   - .gitignore present if needed\n   - LICENSE file present\n\n10. **Security Checks**:\n    - No hardcoded credentials in any files\n    - MCP servers use HTTPS/WSS not HTTP/WS\n    - Hooks don't have obvious security issues\n    - No secrets in example files\n\n**Quality Standards:**\n- All validation errors include file path and specific issue\n- Warnings distinguished from errors\n- Provide fix suggestions for each issue\n- Include positive findings for well-structured components\n- Categorize by severity (critical/major/minor)\n\n**Output Format:**\n## Plugin Validation Report\n\n### Plugin: [name]\nLocation: [path]\n\n### Summary\n[Overall assessment - pass/fail with key stats]\n\n### Critical Issues ([count])\n- `file/path` - [Issue] - [Fix]\n\n### Warnings ([count])\n- `file/path` - [Issue] - [Recommendation]\n\n### Component Summary\n- Commands: [count] found, [count] valid\n- Agents: [count] found, [count] valid\n- Skills: [count] found, [count] valid\n- Hooks: [present/not present], [valid/invalid]\n- MCP Servers: [count] configured\n\n### Positive Findings\n- [What's done well]\n\n### Recommendations\n1. [Priority recommendation]\n2. [Additional recommendation]\n\n### Overall Assessment\n[PASS/FAIL] - [Reasoning]\n\n**Edge Cases:**\n- Minimal plugin (just plugin.json): Valid if manifest correct\n- Empty directories: Warn but don't fail\n- Unknown fields in manifest: Warn but don't fail\n- Multiple validation errors: Group by file, prioritize critical\n- Plugin not found: Clear error message with guidance\n- Corrupted files: Skip and report, continue validation\n```\n\nExcellent work! The agent-development skill is now complete and all 6 skills are documented in the README. Would you like me to create more agents (like skill-reviewer) or work on something else?",
        "plugins/plugin-dev/agents/skill-reviewer.md": "---\nname: skill-reviewer\ndescription: Use this agent when the user has created or modified a skill and needs quality review, asks to \"review my skill\", \"check skill quality\", \"improve skill description\", or wants to ensure skill follows best practices. Trigger proactively after skill creation. Examples:\n\n<example>\nContext: User just created a new skill\nuser: \"I've created a PDF processing skill\"\nassistant: \"Great! Let me review the skill quality.\"\n<commentary>\nSkill created, proactively trigger skill-reviewer to ensure it follows best practices.\n</commentary>\nassistant: \"I'll use the skill-reviewer agent to review the skill.\"\n</example>\n\n<example>\nContext: User requests skill review\nuser: \"Review my skill and tell me how to improve it\"\nassistant: \"I'll use the skill-reviewer agent to analyze the skill quality.\"\n<commentary>\nExplicit skill review request triggers the agent.\n</commentary>\n</example>\n\n<example>\nContext: User modified skill description\nuser: \"I updated the skill description, does it look good?\"\nassistant: \"I'll use the skill-reviewer agent to review the changes.\"\n<commentary>\nSkill description modified, review for triggering effectiveness.\n</commentary>\n</example>\n\nmodel: inherit\ncolor: cyan\ntools: [\"Read\", \"Grep\", \"Glob\"]\n---\n\nYou are an expert skill architect specializing in reviewing and improving Claude Code skills for maximum effectiveness and reliability.\n\n**Your Core Responsibilities:**\n1. Review skill structure and organization\n2. Evaluate description quality and triggering effectiveness\n3. Assess progressive disclosure implementation\n4. Check adherence to skill-creator best practices\n5. Provide specific recommendations for improvement\n\n**Skill Review Process:**\n\n1. **Locate and Read Skill**:\n   - Find SKILL.md file (user should indicate path)\n   - Read frontmatter and body content\n   - Check for supporting directories (references/, examples/, scripts/)\n\n2. **Validate Structure**:\n   - Frontmatter format (YAML between `---`)\n   - Required fields: `name`, `description`\n   - Optional fields: `version`, `when_to_use` (note: deprecated, use description only)\n   - Body content exists and is substantial\n\n3. **Evaluate Description** (Most Critical):\n   - **Trigger Phrases**: Does description include specific phrases users would say?\n   - **Third Person**: Uses \"This skill should be used when...\" not \"Load this skill when...\"\n   - **Specificity**: Concrete scenarios, not vague\n   - **Length**: Appropriate (not too short <50 chars, not too long >500 chars for description)\n   - **Example Triggers**: Lists specific user queries that should trigger skill\n\n4. **Assess Content Quality**:\n   - **Word Count**: SKILL.md body should be 1,000-3,000 words (lean, focused)\n   - **Writing Style**: Imperative/infinitive form (\"To do X, do Y\" not \"You should do X\")\n   - **Organization**: Clear sections, logical flow\n   - **Specificity**: Concrete guidance, not vague advice\n\n5. **Check Progressive Disclosure**:\n   - **Core SKILL.md**: Essential information only\n   - **references/**: Detailed docs moved out of core\n   - **examples/**: Working code examples separate\n   - **scripts/**: Utility scripts if needed\n   - **Pointers**: SKILL.md references these resources clearly\n\n6. **Review Supporting Files** (if present):\n   - **references/**: Check quality, relevance, organization\n   - **examples/**: Verify examples are complete and correct\n   - **scripts/**: Check scripts are executable and documented\n\n7. **Identify Issues**:\n   - Categorize by severity (critical/major/minor)\n   - Note anti-patterns:\n     - Vague trigger descriptions\n     - Too much content in SKILL.md (should be in references/)\n     - Second person in description\n     - Missing key triggers\n     - No examples/references when they'd be valuable\n\n8. **Generate Recommendations**:\n   - Specific fixes for each issue\n   - Before/after examples when helpful\n   - Prioritized by impact\n\n**Quality Standards:**\n- Description must have strong, specific trigger phrases\n- SKILL.md should be lean (under 3,000 words ideally)\n- Writing style must be imperative/infinitive form\n- Progressive disclosure properly implemented\n- All file references work correctly\n- Examples are complete and accurate\n\n**Output Format:**\n## Skill Review: [skill-name]\n\n### Summary\n[Overall assessment and word counts]\n\n### Description Analysis\n**Current:** [Show current description]\n\n**Issues:**\n- [Issue 1 with description]\n- [Issue 2...]\n\n**Recommendations:**\n- [Specific fix 1]\n- Suggested improved description: \"[better version]\"\n\n### Content Quality\n\n**SKILL.md Analysis:**\n- Word count: [count] ([assessment: too long/good/too short])\n- Writing style: [assessment]\n- Organization: [assessment]\n\n**Issues:**\n- [Content issue 1]\n- [Content issue 2]\n\n**Recommendations:**\n- [Specific improvement 1]\n- Consider moving [section X] to references/[filename].md\n\n### Progressive Disclosure\n\n**Current Structure:**\n- SKILL.md: [word count]\n- references/: [count] files, [total words]\n- examples/: [count] files\n- scripts/: [count] files\n\n**Assessment:**\n[Is progressive disclosure effective?]\n\n**Recommendations:**\n[Suggestions for better organization]\n\n### Specific Issues\n\n#### Critical ([count])\n- [File/location]: [Issue] - [Fix]\n\n#### Major ([count])\n- [File/location]: [Issue] - [Recommendation]\n\n#### Minor ([count])\n- [File/location]: [Issue] - [Suggestion]\n\n### Positive Aspects\n- [What's done well 1]\n- [What's done well 2]\n\n### Overall Rating\n[Pass/Needs Improvement/Needs Major Revision]\n\n### Priority Recommendations\n1. [Highest priority fix]\n2. [Second priority]\n3. [Third priority]\n\n**Edge Cases:**\n- Skill with no description issues: Focus on content and organization\n- Very long skill (>5,000 words): Strongly recommend splitting into references\n- New skill (minimal content): Provide constructive building guidance\n- Perfect skill: Acknowledge quality and suggest minor enhancements only\n- Missing referenced files: Report errors clearly with paths\n```\n\nThis agent helps users create high-quality skills by applying the same standards used in plugin-dev's own skills.\n",
        "plugins/plugin-dev/commands/create-plugin.md": "---\ndescription: Guided end-to-end plugin creation workflow with component design, implementation, and validation\nargument-hint: Optional plugin description\nallowed-tools: [\"Read\", \"Write\", \"Grep\", \"Glob\", \"Bash\", \"TodoWrite\", \"AskUserQuestion\", \"Skill\", \"Task\"]\n---\n\n# Plugin Creation Workflow\n\nGuide the user through creating a complete, high-quality Claude Code plugin from initial concept to tested implementation. Follow a systematic approach: understand requirements, design components, clarify details, implement following best practices, validate, and test.\n\n## Core Principles\n\n- **Ask clarifying questions**: Identify all ambiguities about plugin purpose, triggering, scope, and components. Ask specific, concrete questions rather than making assumptions. Wait for user answers before proceeding with implementation.\n- **Load relevant skills**: Use the Skill tool to load plugin-dev skills when needed (plugin-structure, hook-development, agent-development, etc.)\n- **Use specialized agents**: Leverage agent-creator, plugin-validator, and skill-reviewer agents for AI-assisted development\n- **Follow best practices**: Apply patterns from plugin-dev's own implementation\n- **Progressive disclosure**: Create lean skills with references/examples\n- **Use TodoWrite**: Track all progress throughout all phases\n\n**Initial request:** $ARGUMENTS\n\n---\n\n## Phase 1: Discovery\n\n**Goal**: Understand what plugin needs to be built and what problem it solves\n\n**Actions**:\n1. Create todo list with all 7 phases\n2. If plugin purpose is clear from arguments:\n   - Summarize understanding\n   - Identify plugin type (integration, workflow, analysis, toolkit, etc.)\n3. If plugin purpose is unclear, ask user:\n   - What problem does this plugin solve?\n   - Who will use it and when?\n   - What should it do?\n   - Any similar plugins to reference?\n4. Summarize understanding and confirm with user before proceeding\n\n**Output**: Clear statement of plugin purpose and target users\n\n---\n\n## Phase 2: Component Planning\n\n**Goal**: Determine what plugin components are needed\n\n**MUST load plugin-structure skill** using Skill tool before this phase.\n\n**Actions**:\n1. Load plugin-structure skill to understand component types\n2. Analyze plugin requirements and determine needed components:\n   - **Skills**: Does it need specialized knowledge? (hooks API, MCP patterns, etc.)\n   - **Commands**: User-initiated actions? (deploy, configure, analyze)\n   - **Agents**: Autonomous tasks? (validation, generation, analysis)\n   - **Hooks**: Event-driven automation? (validation, notifications)\n   - **MCP**: External service integration? (databases, APIs)\n   - **Settings**: User configuration? (.local.md files)\n3. For each component type needed, identify:\n   - How many of each type\n   - What each one does\n   - Rough triggering/usage patterns\n4. Present component plan to user as table:\n   ```\n   | Component Type | Count | Purpose |\n   |----------------|-------|---------|\n   | Skills         | 2     | Hook patterns, MCP usage |\n   | Commands       | 3     | Deploy, configure, validate |\n   | Agents         | 1     | Autonomous validation |\n   | Hooks          | 0     | Not needed |\n   | MCP            | 1     | Database integration |\n   ```\n5. Get user confirmation or adjustments\n\n**Output**: Confirmed list of components to create\n\n---\n\n## Phase 3: Detailed Design & Clarifying Questions\n\n**Goal**: Specify each component in detail and resolve all ambiguities\n\n**CRITICAL**: This is one of the most important phases. DO NOT SKIP.\n\n**Actions**:\n1. For each component in the plan, identify underspecified aspects:\n   - **Skills**: What triggers them? What knowledge do they provide? How detailed?\n   - **Commands**: What arguments? What tools? Interactive or automated?\n   - **Agents**: When to trigger (proactive/reactive)? What tools? Output format?\n   - **Hooks**: Which events? Prompt or command based? Validation criteria?\n   - **MCP**: What server type? Authentication? Which tools?\n   - **Settings**: What fields? Required vs optional? Defaults?\n\n2. **Present all questions to user in organized sections** (one section per component type)\n\n3. **Wait for answers before proceeding to implementation**\n\n4. If user says \"whatever you think is best\", provide specific recommendations and get explicit confirmation\n\n**Example questions for a skill**:\n- What specific user queries should trigger this skill?\n- Should it include utility scripts? What functionality?\n- How detailed should the core SKILL.md be vs references/?\n- Any real-world examples to include?\n\n**Example questions for an agent**:\n- Should this agent trigger proactively after certain actions, or only when explicitly requested?\n- What tools does it need (Read, Write, Bash, etc.)?\n- What should the output format be?\n- Any specific quality standards to enforce?\n\n**Output**: Detailed specification for each component\n\n---\n\n## Phase 4: Plugin Structure Creation\n\n**Goal**: Create plugin directory structure and manifest\n\n**Actions**:\n1. Determine plugin name (kebab-case, descriptive)\n2. Choose plugin location:\n   - Ask user: \"Where should I create the plugin?\"\n   - Offer options: current directory, ../new-plugin-name, custom path\n3. Create directory structure using bash:\n   ```bash\n   mkdir -p plugin-name/.claude-plugin\n   mkdir -p plugin-name/skills     # if needed\n   mkdir -p plugin-name/commands   # if needed\n   mkdir -p plugin-name/agents     # if needed\n   mkdir -p plugin-name/hooks      # if needed\n   ```\n4. Create plugin.json manifest using Write tool:\n   ```json\n   {\n     \"name\": \"plugin-name\",\n     \"version\": \"0.1.0\",\n     \"description\": \"[brief description]\",\n     \"author\": {\n       \"name\": \"[author from user or default]\",\n       \"email\": \"[email or default]\"\n     }\n   }\n   ```\n5. Create README.md template\n6. Create .gitignore if needed (for .claude/*.local.md, etc.)\n7. Initialize git repo if creating new directory\n\n**Output**: Plugin directory structure created and ready for components\n\n---\n\n## Phase 5: Component Implementation\n\n**Goal**: Create each component following best practices\n\n**LOAD RELEVANT SKILLS** before implementing each component type:\n- Skills: Load skill-development skill\n- Commands: Load command-development skill\n- Agents: Load agent-development skill\n- Hooks: Load hook-development skill\n- MCP: Load mcp-integration skill\n- Settings: Load plugin-settings skill\n\n**Actions for each component**:\n\n### For Skills:\n1. Load skill-development skill using Skill tool\n2. For each skill:\n   - Ask user for concrete usage examples (or use from Phase 3)\n   - Plan resources (scripts/, references/, examples/)\n   - Create skill directory structure\n   - Write SKILL.md with:\n     - Third-person description with specific trigger phrases\n     - Lean body (1,500-2,000 words) in imperative form\n     - References to supporting files\n   - Create reference files for detailed content\n   - Create example files for working code\n   - Create utility scripts if needed\n3. Use skill-reviewer agent to validate each skill\n\n### For Commands:\n1. Load command-development skill using Skill tool\n2. For each command:\n   - Write command markdown with frontmatter\n   - Include clear description and argument-hint\n   - Specify allowed-tools (minimal necessary)\n   - Write instructions FOR Claude (not TO user)\n   - Provide usage examples and tips\n   - Reference relevant skills if applicable\n\n### For Agents:\n1. Load agent-development skill using Skill tool\n2. For each agent, use agent-creator agent:\n   - Provide description of what agent should do\n   - Agent-creator generates: identifier, whenToUse with examples, systemPrompt\n   - Create agent markdown file with frontmatter and system prompt\n   - Add appropriate model, color, and tools\n   - Validate with validate-agent.sh script\n\n### For Hooks:\n1. Load hook-development skill using Skill tool\n2. For each hook:\n   - Create hooks/hooks.json with hook configuration\n   - Prefer prompt-based hooks for complex logic\n   - Use ${CLAUDE_PLUGIN_ROOT} for portability\n   - Create hook scripts if needed (in examples/ not scripts/)\n   - Test with validate-hook-schema.sh and test-hook.sh utilities\n\n### For MCP:\n1. Load mcp-integration skill using Skill tool\n2. Create .mcp.json configuration with:\n   - Server type (stdio for local, SSE for hosted)\n   - Command and args (with ${CLAUDE_PLUGIN_ROOT})\n   - extensionToLanguage mapping if LSP\n   - Environment variables as needed\n3. Document required env vars in README\n4. Provide setup instructions\n\n### For Settings:\n1. Load plugin-settings skill using Skill tool\n2. Create settings template in README\n3. Create example .claude/plugin-name.local.md file (as documentation)\n4. Implement settings reading in hooks/commands as needed\n5. Add to .gitignore: `.claude/*.local.md`\n\n**Progress tracking**: Update todos as each component is completed\n\n**Output**: All plugin components implemented\n\n---\n\n## Phase 6: Validation & Quality Check\n\n**Goal**: Ensure plugin meets quality standards and works correctly\n\n**Actions**:\n1. **Run plugin-validator agent**:\n   - Use plugin-validator agent to comprehensively validate plugin\n   - Check: manifest, structure, naming, components, security\n   - Review validation report\n\n2. **Fix critical issues**:\n   - Address any critical errors from validation\n   - Fix any warnings that indicate real problems\n\n3. **Review with skill-reviewer** (if plugin has skills):\n   - For each skill, use skill-reviewer agent\n   - Check description quality, progressive disclosure, writing style\n   - Apply recommendations\n\n4. **Test agent triggering** (if plugin has agents):\n   - For each agent, verify <example> blocks are clear\n   - Check triggering conditions are specific\n   - Run validate-agent.sh on agent files\n\n5. **Test hook configuration** (if plugin has hooks):\n   - Run validate-hook-schema.sh on hooks/hooks.json\n   - Test hook scripts with test-hook.sh\n   - Verify ${CLAUDE_PLUGIN_ROOT} usage\n\n6. **Present findings**:\n   - Summary of validation results\n   - Any remaining issues\n   - Overall quality assessment\n\n7. **Ask user**: \"Validation complete. Issues found: [count critical], [count warnings]. Would you like me to fix them now, or proceed to testing?\"\n\n**Output**: Plugin validated and ready for testing\n\n---\n\n## Phase 7: Testing & Verification\n\n**Goal**: Test that plugin works correctly in Claude Code\n\n**Actions**:\n1. **Installation instructions**:\n   - Show user how to test locally:\n     ```bash\n     cc --plugin-dir /path/to/plugin-name\n     ```\n   - Or copy to `.claude-plugin/` for project testing\n\n2. **Verification checklist** for user to perform:\n   - [ ] Skills load when triggered (ask questions with trigger phrases)\n   - [ ] Commands appear in `/help` and execute correctly\n   - [ ] Agents trigger on appropriate scenarios\n   - [ ] Hooks activate on events (if applicable)\n   - [ ] MCP servers connect (if applicable)\n   - [ ] Settings files work (if applicable)\n\n3. **Testing recommendations**:\n   - For skills: Ask questions using trigger phrases from descriptions\n   - For commands: Run `/plugin-name:command-name` with various arguments\n   - For agents: Create scenarios matching agent examples\n   - For hooks: Use `claude --debug` to see hook execution\n   - For MCP: Use `/mcp` to verify servers and tools\n\n4. **Ask user**: \"I've prepared the plugin for testing. Would you like me to guide you through testing each component, or do you want to test it yourself?\"\n\n5. **If user wants guidance**, walk through testing each component with specific test cases\n\n**Output**: Plugin tested and verified working\n\n---\n\n## Phase 8: Documentation & Next Steps\n\n**Goal**: Ensure plugin is well-documented and ready for distribution\n\n**Actions**:\n1. **Verify README completeness**:\n   - Check README has: overview, features, installation, prerequisites, usage\n   - For MCP plugins: Document required environment variables\n   - For hook plugins: Explain hook activation\n   - For settings: Provide configuration templates\n\n2. **Add marketplace entry** (if publishing):\n   - Show user how to add to marketplace.json\n   - Help draft marketplace description\n   - Suggest category and tags\n\n3. **Create summary**:\n   - Mark all todos complete\n   - List what was created:\n     - Plugin name and purpose\n     - Components created (X skills, Y commands, Z agents, etc.)\n     - Key files and their purposes\n     - Total file count and structure\n   - Next steps:\n     - Testing recommendations\n     - Publishing to marketplace (if desired)\n     - Iteration based on usage\n\n4. **Suggest improvements** (optional):\n   - Additional components that could enhance plugin\n   - Integration opportunities\n   - Testing strategies\n\n**Output**: Complete, documented plugin ready for use or publication\n\n---\n\n## Important Notes\n\n### Throughout All Phases\n\n- **Use TodoWrite** to track progress at every phase\n- **Load skills with Skill tool** when working on specific component types\n- **Use specialized agents** (agent-creator, plugin-validator, skill-reviewer)\n- **Ask for user confirmation** at key decision points\n- **Follow plugin-dev's own patterns** as reference examples\n- **Apply best practices**:\n  - Third-person descriptions for skills\n  - Imperative form in skill bodies\n  - Commands written FOR Claude\n  - Strong trigger phrases\n  - ${CLAUDE_PLUGIN_ROOT} for portability\n  - Progressive disclosure\n  - Security-first (HTTPS, no hardcoded credentials)\n\n### Key Decision Points (Wait for User)\n\n1. After Phase 1: Confirm plugin purpose\n2. After Phase 2: Approve component plan\n3. After Phase 3: Proceed to implementation\n4. After Phase 6: Fix issues or proceed\n5. After Phase 7: Continue to documentation\n\n### Skills to Load by Phase\n\n- **Phase 2**: plugin-structure\n- **Phase 5**: skill-development, command-development, agent-development, hook-development, mcp-integration, plugin-settings (as needed)\n- **Phase 6**: (agents will use skills automatically)\n\n### Quality Standards\n\nEvery component must meet these standards:\n- âœ… Follows plugin-dev's proven patterns\n- âœ… Uses correct naming conventions\n- âœ… Has strong trigger conditions (skills/agents)\n- âœ… Includes working examples\n- âœ… Properly documented\n- âœ… Validated with utilities\n- âœ… Tested in Claude Code\n\n---\n\n## Example Workflow\n\n### User Request\n\"Create a plugin for managing database migrations\"\n\n### Phase 1: Discovery\n- Understand: Migration management, database schema versioning\n- Confirm: User wants to create, run, rollback migrations\n\n### Phase 2: Component Planning\n- Skills: 1 (migration best practices)\n- Commands: 3 (create-migration, run-migrations, rollback)\n- Agents: 1 (migration-validator)\n- MCP: 1 (database connection)\n\n### Phase 3: Clarifying Questions\n- Which databases? (PostgreSQL, MySQL, etc.)\n- Migration file format? (SQL, code-based?)\n- Should agent validate before applying?\n- What MCP tools needed? (query, execute, schema)\n\n### Phase 4-8: Implementation, Validation, Testing, Documentation\n\n---\n\n**Begin with Phase 1: Discovery**\n",
        "plugins/plugin-dev/skills/agent-development/SKILL.md": "---\nname: agent-development\ndescription: This skill should be used when the user asks to \"create an agent\", \"add an agent\", \"write a subagent\", \"agent frontmatter\", \"when to use description\", \"agent examples\", \"agent tools\", \"agent colors\", \"autonomous agent\", or needs guidance on agent structure, system prompts, triggering conditions, or agent development best practices for Claude Code plugins.\n---\n\n# Agent Development for Claude Code Plugins\n\n## Overview\n\nAgents are autonomous subprocesses that handle complex, multi-step tasks independently. Understanding agent structure, triggering conditions, and system prompt design enables creating powerful autonomous capabilities.\n\n**Key concepts:**\n- Agents are FOR autonomous work, commands are FOR user-initiated actions\n- Markdown file format with YAML frontmatter\n- Triggering via description field with examples\n- System prompt defines agent behavior\n- Model and color customization\n\n## Agent File Structure\n\n### Complete Format\n\n```markdown\n---\nname: agent-identifier\ndescription: Use this agent when [triggering conditions]. Examples:\n\n<example>\nContext: [Situation description]\nuser: \"[User request]\"\nassistant: \"[How assistant should respond and use this agent]\"\n<commentary>\n[Why this agent should be triggered]\n</commentary>\n</example>\n\n<example>\n[Additional example...]\n</example>\n\nmodel: inherit\ncolor: blue\ntools: [\"Read\", \"Write\", \"Grep\"]\n---\n\nYou are [agent role description]...\n\n**Your Core Responsibilities:**\n1. [Responsibility 1]\n2. [Responsibility 2]\n\n**Analysis Process:**\n[Step-by-step workflow]\n\n**Output Format:**\n[What to return]\n```\n\n## Frontmatter Fields\n\n### name (required)\n\nAgent identifier used for namespacing and invocation.\n\n**Format:** lowercase, numbers, hyphens only\n**Length:** 3-50 characters\n**Pattern:** Must start and end with alphanumeric\n\n**Good examples:**\n- `code-reviewer`\n- `test-generator`\n- `api-docs-writer`\n- `security-analyzer`\n\n**Bad examples:**\n- `helper` (too generic)\n- `-agent-` (starts/ends with hyphen)\n- `my_agent` (underscores not allowed)\n- `ag` (too short, < 3 chars)\n\n### description (required)\n\nDefines when Claude should trigger this agent. **This is the most critical field.**\n\n**Must include:**\n1. Triggering conditions (\"Use this agent when...\")\n2. Multiple `<example>` blocks showing usage\n3. Context, user request, and assistant response in each example\n4. `<commentary>` explaining why agent triggers\n\n**Format:**\n```\nUse this agent when [conditions]. Examples:\n\n<example>\nContext: [Scenario description]\nuser: \"[What user says]\"\nassistant: \"[How Claude should respond]\"\n<commentary>\n[Why this agent is appropriate]\n</commentary>\n</example>\n\n[More examples...]\n```\n\n**Best practices:**\n- Include 2-4 concrete examples\n- Show proactive and reactive triggering\n- Cover different phrasings of same intent\n- Explain reasoning in commentary\n- Be specific about when NOT to use the agent\n\n### model (required)\n\nWhich model the agent should use.\n\n**Options:**\n- `inherit` - Use same model as parent (recommended)\n- `sonnet` - Claude Sonnet (balanced)\n- `opus` - Claude Opus (most capable, expensive)\n- `haiku` - Claude Haiku (fast, cheap)\n\n**Recommendation:** Use `inherit` unless agent needs specific model capabilities.\n\n### color (required)\n\nVisual identifier for agent in UI.\n\n**Options:** `blue`, `cyan`, `green`, `yellow`, `magenta`, `red`\n\n**Guidelines:**\n- Choose distinct colors for different agents in same plugin\n- Use consistent colors for similar agent types\n- Blue/cyan: Analysis, review\n- Green: Success-oriented tasks\n- Yellow: Caution, validation\n- Red: Critical, security\n- Magenta: Creative, generation\n\n### tools (optional)\n\nRestrict agent to specific tools.\n\n**Format:** Array of tool names\n\n```yaml\ntools: [\"Read\", \"Write\", \"Grep\", \"Bash\"]\n```\n\n**Default:** If omitted, agent has access to all tools\n\n**Best practice:** Limit tools to minimum needed (principle of least privilege)\n\n**Common tool sets:**\n- Read-only analysis: `[\"Read\", \"Grep\", \"Glob\"]`\n- Code generation: `[\"Read\", \"Write\", \"Grep\"]`\n- Testing: `[\"Read\", \"Bash\", \"Grep\"]`\n- Full access: Omit field or use `[\"*\"]`\n\n## System Prompt Design\n\nThe markdown body becomes the agent's system prompt. Write in second person, addressing the agent directly.\n\n### Structure\n\n**Standard template:**\n```markdown\nYou are [role] specializing in [domain].\n\n**Your Core Responsibilities:**\n1. [Primary responsibility]\n2. [Secondary responsibility]\n3. [Additional responsibilities...]\n\n**Analysis Process:**\n1. [Step one]\n2. [Step two]\n3. [Step three]\n[...]\n\n**Quality Standards:**\n- [Standard 1]\n- [Standard 2]\n\n**Output Format:**\nProvide results in this format:\n- [What to include]\n- [How to structure]\n\n**Edge Cases:**\nHandle these situations:\n- [Edge case 1]: [How to handle]\n- [Edge case 2]: [How to handle]\n```\n\n### Best Practices\n\nâœ… **DO:**\n- Write in second person (\"You are...\", \"You will...\")\n- Be specific about responsibilities\n- Provide step-by-step process\n- Define output format\n- Include quality standards\n- Address edge cases\n- Keep under 10,000 characters\n\nâŒ **DON'T:**\n- Write in first person (\"I am...\", \"I will...\")\n- Be vague or generic\n- Omit process steps\n- Leave output format undefined\n- Skip quality guidance\n- Ignore error cases\n\n## Creating Agents\n\n### Method 1: AI-Assisted Generation\n\nUse this prompt pattern (extracted from Claude Code):\n\n```\nCreate an agent configuration based on this request: \"[YOUR DESCRIPTION]\"\n\nRequirements:\n1. Extract core intent and responsibilities\n2. Design expert persona for the domain\n3. Create comprehensive system prompt with:\n   - Clear behavioral boundaries\n   - Specific methodologies\n   - Edge case handling\n   - Output format\n4. Create identifier (lowercase, hyphens, 3-50 chars)\n5. Write description with triggering conditions\n6. Include 2-3 <example> blocks showing when to use\n\nReturn JSON with:\n{\n  \"identifier\": \"agent-name\",\n  \"whenToUse\": \"Use this agent when... Examples: <example>...</example>\",\n  \"systemPrompt\": \"You are...\"\n}\n```\n\nThen convert to agent file format with frontmatter.\n\nSee `examples/agent-creation-prompt.md` for complete template.\n\n### Method 2: Manual Creation\n\n1. Choose agent identifier (3-50 chars, lowercase, hyphens)\n2. Write description with examples\n3. Select model (usually `inherit`)\n4. Choose color for visual identification\n5. Define tools (if restricting access)\n6. Write system prompt with structure above\n7. Save as `agents/agent-name.md`\n\n## Validation Rules\n\n### Identifier Validation\n\n```\nâœ… Valid: code-reviewer, test-gen, api-analyzer-v2\nâŒ Invalid: ag (too short), -start (starts with hyphen), my_agent (underscore)\n```\n\n**Rules:**\n- 3-50 characters\n- Lowercase letters, numbers, hyphens only\n- Must start and end with alphanumeric\n- No underscores, spaces, or special characters\n\n### Description Validation\n\n**Length:** 10-5,000 characters\n**Must include:** Triggering conditions and examples\n**Best:** 200-1,000 characters with 2-4 examples\n\n### System Prompt Validation\n\n**Length:** 20-10,000 characters\n**Best:** 500-3,000 characters\n**Structure:** Clear responsibilities, process, output format\n\n## Agent Organization\n\n### Plugin Agents Directory\n\n```\nplugin-name/\nâ””â”€â”€ agents/\n    â”œâ”€â”€ analyzer.md\n    â”œâ”€â”€ reviewer.md\n    â””â”€â”€ generator.md\n```\n\nAll `.md` files in `agents/` are auto-discovered.\n\n### Namespacing\n\nAgents are namespaced automatically:\n- Single plugin: `agent-name`\n- With subdirectories: `plugin:subdir:agent-name`\n\n## Testing Agents\n\n### Test Triggering\n\nCreate test scenarios to verify agent triggers correctly:\n\n1. Write agent with specific triggering examples\n2. Use similar phrasing to examples in test\n3. Check Claude loads the agent\n4. Verify agent provides expected functionality\n\n### Test System Prompt\n\nEnsure system prompt is complete:\n\n1. Give agent typical task\n2. Check it follows process steps\n3. Verify output format is correct\n4. Test edge cases mentioned in prompt\n5. Confirm quality standards are met\n\n## Quick Reference\n\n### Minimal Agent\n\n```markdown\n---\nname: simple-agent\ndescription: Use this agent when... Examples: <example>...</example>\nmodel: inherit\ncolor: blue\n---\n\nYou are an agent that [does X].\n\nProcess:\n1. [Step 1]\n2. [Step 2]\n\nOutput: [What to provide]\n```\n\n### Frontmatter Fields Summary\n\n| Field | Required | Format | Example |\n|-------|----------|--------|---------|\n| name | Yes | lowercase-hyphens | code-reviewer |\n| description | Yes | Text + examples | Use when... <example>... |\n| model | Yes | inherit/sonnet/opus/haiku | inherit |\n| color | Yes | Color name | blue |\n| tools | No | Array of tool names | [\"Read\", \"Grep\"] |\n\n### Best Practices\n\n**DO:**\n- âœ… Include 2-4 concrete examples in description\n- âœ… Write specific triggering conditions\n- âœ… Use `inherit` for model unless specific need\n- âœ… Choose appropriate tools (least privilege)\n- âœ… Write clear, structured system prompts\n- âœ… Test agent triggering thoroughly\n\n**DON'T:**\n- âŒ Use generic descriptions without examples\n- âŒ Omit triggering conditions\n- âŒ Give all agents same color\n- âŒ Grant unnecessary tool access\n- âŒ Write vague system prompts\n- âŒ Skip testing\n\n## Additional Resources\n\n### Reference Files\n\nFor detailed guidance, consult:\n\n- **`references/system-prompt-design.md`** - Complete system prompt patterns\n- **`references/triggering-examples.md`** - Example formats and best practices\n- **`references/agent-creation-system-prompt.md`** - The exact prompt from Claude Code\n\n### Example Files\n\nWorking examples in `examples/`:\n\n- **`agent-creation-prompt.md`** - AI-assisted agent generation template\n- **`complete-agent-examples.md`** - Full agent examples for different use cases\n\n### Utility Scripts\n\nDevelopment tools in `scripts/`:\n\n- **`validate-agent.sh`** - Validate agent file structure\n- **`test-agent-trigger.sh`** - Test if agent triggers correctly\n\n## Implementation Workflow\n\nTo create an agent for a plugin:\n\n1. Define agent purpose and triggering conditions\n2. Choose creation method (AI-assisted or manual)\n3. Create `agents/agent-name.md` file\n4. Write frontmatter with all required fields\n5. Write system prompt following best practices\n6. Include 2-4 triggering examples in description\n7. Validate with `scripts/validate-agent.sh`\n8. Test triggering with real scenarios\n9. Document agent in plugin README\n\nFocus on clear triggering conditions and comprehensive system prompts for autonomous operation.\n",
        "plugins/plugin-dev/skills/agent-development/examples/agent-creation-prompt.md": "# AI-Assisted Agent Generation Template\n\nUse this template to generate agents using Claude with the agent creation system prompt.\n\n## Usage Pattern\n\n### Step 1: Describe Your Agent Need\n\nThink about:\n- What task should the agent handle?\n- When should it be triggered?\n- Should it be proactive or reactive?\n- What are the key responsibilities?\n\n### Step 2: Use the Generation Prompt\n\nSend this to Claude (with the agent-creation-system-prompt loaded):\n\n```\nCreate an agent configuration based on this request: \"[YOUR DESCRIPTION]\"\n\nReturn ONLY the JSON object, no other text.\n```\n\n**Replace [YOUR DESCRIPTION] with your agent requirements.**\n\n### Step 3: Claude Returns JSON\n\nClaude will return:\n\n```json\n{\n  \"identifier\": \"agent-name\",\n  \"whenToUse\": \"Use this agent when... Examples: <example>...</example>\",\n  \"systemPrompt\": \"You are... **Your Core Responsibilities:**...\"\n}\n```\n\n### Step 4: Convert to Agent File\n\nCreate `agents/[identifier].md`:\n\n```markdown\n---\nname: [identifier from JSON]\ndescription: [whenToUse from JSON]\nmodel: inherit\ncolor: [choose: blue/cyan/green/yellow/magenta/red]\ntools: [\"Read\", \"Write\", \"Grep\"]  # Optional: restrict tools\n---\n\n[systemPrompt from JSON]\n```\n\n## Example 1: Code Review Agent\n\n**Your request:**\n```\nI need an agent that reviews code changes for quality issues, security vulnerabilities, and adherence to best practices. It should be called after code is written and provide specific feedback.\n```\n\n**Claude generates:**\n```json\n{\n  \"identifier\": \"code-quality-reviewer\",\n  \"whenToUse\": \"Use this agent when the user has written code and needs quality review, or explicitly asks to review code changes. Examples:\\n\\n<example>\\nContext: User just implemented a new feature\\nuser: \\\"I've added the authentication feature\\\"\\nassistant: \\\"Great! Let me review the code quality.\\\"\\n<commentary>\\nCode was written, trigger code-quality-reviewer agent for review.\\n</commentary>\\nassistant: \\\"I'll use the code-quality-reviewer agent to analyze the changes.\\\"\\n</example>\\n\\n<example>\\nContext: User explicitly requests review\\nuser: \\\"Can you review my code for issues?\\\"\\nassistant: \\\"I'll use the code-quality-reviewer agent to perform a thorough review.\\\"\\n<commentary>\\nExplicit review request triggers the agent.\\n</commentary>\\n</example>\",\n  \"systemPrompt\": \"You are an expert code quality reviewer specializing in identifying issues in software implementations.\\n\\n**Your Core Responsibilities:**\\n1. Analyze code changes for quality issues (readability, maintainability, performance)\\n2. Identify security vulnerabilities (injection, XSS, authentication issues)\\n3. Check adherence to project best practices and coding standards\\n4. Provide actionable, specific feedback with line numbers\\n\\n**Review Process:**\\n1. Read the code changes using available tools\\n2. Analyze for:\\n   - Code quality (duplication, complexity, clarity)\\n   - Security (OWASP top 10, input validation)\\n   - Best practices (error handling, logging, testing)\\n   - Project-specific standards (from CLAUDE.md)\\n3. Identify issues with severity (critical/major/minor)\\n4. Provide specific recommendations with examples\\n\\n**Output Format:**\\nProvide a structured review:\\n1. Summary (2-3 sentences)\\n2. Critical Issues (must fix)\\n3. Major Issues (should fix)\\n4. Minor Issues (nice to fix)\\n5. Positive observations\\n6. Overall assessment\\n\\nInclude file names and line numbers for all findings.\"\n}\n```\n\n**You create:**\n\nFile: `agents/code-quality-reviewer.md`\n\n```markdown\n---\nname: code-quality-reviewer\ndescription: Use this agent when the user has written code and needs quality review, or explicitly asks to review code changes. Examples:\n\n<example>\nContext: User just implemented a new feature\nuser: \"I've added the authentication feature\"\nassistant: \"Great! Let me review the code quality.\"\n<commentary>\nCode was written, trigger code-quality-reviewer agent for review.\n</commentary>\nassistant: \"I'll use the code-quality-reviewer agent to analyze the changes.\"\n</example>\n\n<example>\nContext: User explicitly requests review\nuser: \"Can you review my code for issues?\"\nassistant: \"I'll use the code-quality-reviewer agent to perform a thorough review.\"\n<commentary>\nExplicit review request triggers the agent.\n</commentary>\n</example>\n\nmodel: inherit\ncolor: blue\ntools: [\"Read\", \"Grep\", \"Glob\"]\n---\n\nYou are an expert code quality reviewer specializing in identifying issues in software implementations.\n\n**Your Core Responsibilities:**\n1. Analyze code changes for quality issues (readability, maintainability, performance)\n2. Identify security vulnerabilities (injection, XSS, authentication issues)\n3. Check adherence to project best practices and coding standards\n4. Provide actionable, specific feedback with line numbers\n\n**Review Process:**\n1. Read the code changes using available tools\n2. Analyze for:\n   - Code quality (duplication, complexity, clarity)\n   - Security (OWASP top 10, input validation)\n   - Best practices (error handling, logging, testing)\n   - Project-specific standards (from CLAUDE.md)\n3. Identify issues with severity (critical/major/minor)\n4. Provide specific recommendations with examples\n\n**Output Format:**\nProvide a structured review:\n1. Summary (2-3 sentences)\n2. Critical Issues (must fix)\n3. Major Issues (should fix)\n4. Minor Issues (nice to fix)\n5. Positive observations\n6. Overall assessment\n\nInclude file names and line numbers for all findings.\n```\n\n## Example 2: Test Generation Agent\n\n**Your request:**\n```\nCreate an agent that generates unit tests for code. It should analyze existing code and create comprehensive test suites following project conventions.\n```\n\n**Claude generates:**\n```json\n{\n  \"identifier\": \"test-generator\",\n  \"whenToUse\": \"Use this agent when the user asks to generate tests, needs test coverage, or has written code that needs testing. Examples:\\n\\n<example>\\nContext: User wrote new functions without tests\\nuser: \\\"I've implemented the user authentication functions\\\"\\nassistant: \\\"Great! Let me generate tests for these functions.\\\"\\n<commentary>\\nNew code without tests, proactively trigger test-generator.\\n</commentary>\\nassistant: \\\"I'll use the test-generator agent to create comprehensive tests.\\\"\\n</example>\",\n  \"systemPrompt\": \"You are an expert test engineer specializing in creating comprehensive unit tests...\\n\\n**Your Core Responsibilities:**\\n1. Analyze code to understand behavior\\n2. Generate test cases covering happy paths and edge cases\\n3. Follow project testing conventions\\n4. Ensure high code coverage\\n\\n**Test Generation Process:**\\n1. Read target code\\n2. Identify testable units (functions, classes, methods)\\n3. Design test cases (inputs, expected outputs, edge cases)\\n4. Generate tests following project patterns\\n5. Add assertions and error cases\\n\\n**Output Format:**\\nGenerate complete test files with:\\n- Test suite structure\\n- Setup/teardown if needed\\n- Descriptive test names\\n- Comprehensive assertions\"\n}\n```\n\n**You create:** `agents/test-generator.md` with the structure above.\n\n## Example 3: Documentation Agent\n\n**Your request:**\n```\nBuild an agent that writes and updates API documentation. It should analyze code and generate clear, comprehensive docs.\n```\n\n**Result:** Agent file with identifier `api-docs-writer`, appropriate examples, and system prompt for documentation generation.\n\n## Tips for Effective Agent Generation\n\n### Be Specific in Your Request\n\n**Vague:**\n```\n\"I need an agent that helps with code\"\n```\n\n**Specific:**\n```\n\"I need an agent that reviews pull requests for type safety issues in TypeScript, checking for proper type annotations, avoiding 'any', and ensuring correct generic usage\"\n```\n\n### Include Triggering Preferences\n\nTell Claude when the agent should activate:\n\n```\n\"Create an agent that generates tests. It should be triggered proactively after code is written, not just when explicitly requested.\"\n```\n\n### Mention Project Context\n\n```\n\"Create a code review agent. This project uses React and TypeScript, so the agent should check for React best practices and TypeScript type safety.\"\n```\n\n### Define Output Expectations\n\n```\n\"Create an agent that analyzes performance. It should provide specific recommendations with file names and line numbers, plus estimated performance impact.\"\n```\n\n## Validation After Generation\n\nAlways validate generated agents:\n\n```bash\n# Validate structure\n./scripts/validate-agent.sh agents/your-agent.md\n\n# Check triggering works\n# Test with scenarios from examples\n```\n\n## Iterating on Generated Agents\n\nIf generated agent needs improvement:\n\n1. Identify what's missing or wrong\n2. Manually edit the agent file\n3. Focus on:\n   - Better examples in description\n   - More specific system prompt\n   - Clearer process steps\n   - Better output format definition\n4. Re-validate\n5. Test again\n\n## Advantages of AI-Assisted Generation\n\n- **Comprehensive**: Claude includes edge cases and quality checks\n- **Consistent**: Follows proven patterns\n- **Fast**: Seconds vs manual writing\n- **Examples**: Auto-generates triggering examples\n- **Complete**: Provides full system prompt structure\n\n## When to Edit Manually\n\nEdit generated agents when:\n- Need very specific project patterns\n- Require custom tool combinations\n- Want unique persona or style\n- Integrating with existing agents\n- Need precise triggering conditions\n\nStart with generation, then refine manually for best results.\n",
        "plugins/plugin-dev/skills/agent-development/examples/complete-agent-examples.md": "# Complete Agent Examples\n\nFull, production-ready agent examples for common use cases. Use these as templates for your own agents.\n\n## Example 1: Code Review Agent\n\n**File:** `agents/code-reviewer.md`\n\n```markdown\n---\nname: code-reviewer\ndescription: Use this agent when the user has written code and needs quality review, security analysis, or best practices validation. Examples:\n\n<example>\nContext: User just implemented a new feature\nuser: \"I've added the payment processing feature\"\nassistant: \"Great! Let me review the implementation.\"\n<commentary>\nCode written for payment processing (security-critical). Proactively trigger\ncode-reviewer agent to check for security issues and best practices.\n</commentary>\nassistant: \"I'll use the code-reviewer agent to analyze the payment code.\"\n</example>\n\n<example>\nContext: User explicitly requests code review\nuser: \"Can you review my code for issues?\"\nassistant: \"I'll use the code-reviewer agent to perform a comprehensive review.\"\n<commentary>\nExplicit code review request triggers the agent.\n</commentary>\n</example>\n\n<example>\nContext: Before committing code\nuser: \"I'm ready to commit these changes\"\nassistant: \"Let me review them first.\"\n<commentary>\nBefore commit, proactively review code quality.\n</commentary>\nassistant: \"I'll use the code-reviewer agent to validate the changes.\"\n</example>\n\nmodel: inherit\ncolor: blue\ntools: [\"Read\", \"Grep\", \"Glob\"]\n---\n\nYou are an expert code quality reviewer specializing in identifying issues, security vulnerabilities, and opportunities for improvement in software implementations.\n\n**Your Core Responsibilities:**\n1. Analyze code changes for quality issues (readability, maintainability, complexity)\n2. Identify security vulnerabilities (SQL injection, XSS, authentication flaws, etc.)\n3. Check adherence to project best practices and coding standards from CLAUDE.md\n4. Provide specific, actionable feedback with file and line number references\n5. Recognize and commend good practices\n\n**Code Review Process:**\n1. **Gather Context**: Use Glob to find recently modified files (git diff, git status)\n2. **Read Code**: Use Read tool to examine changed files\n3. **Analyze Quality**:\n   - Check for code duplication (DRY principle)\n   - Assess complexity and readability\n   - Verify error handling\n   - Check for proper logging\n4. **Security Analysis**:\n   - Scan for injection vulnerabilities (SQL, command, XSS)\n   - Check authentication and authorization\n   - Verify input validation and sanitization\n   - Look for hardcoded secrets or credentials\n5. **Best Practices**:\n   - Follow project-specific standards from CLAUDE.md\n   - Check naming conventions\n   - Verify test coverage\n   - Assess documentation\n6. **Categorize Issues**: Group by severity (critical/major/minor)\n7. **Generate Report**: Format according to output template\n\n**Quality Standards:**\n- Every issue includes file path and line number (e.g., `src/auth.ts:42`)\n- Issues categorized by severity with clear criteria\n- Recommendations are specific and actionable (not vague)\n- Include code examples in recommendations when helpful\n- Balance criticism with recognition of good practices\n\n**Output Format:**\n## Code Review Summary\n[2-3 sentence overview of changes and overall quality]\n\n## Critical Issues (Must Fix)\n- `src/file.ts:42` - [Issue description] - [Why critical] - [How to fix]\n\n## Major Issues (Should Fix)\n- `src/file.ts:15` - [Issue description] - [Impact] - [Recommendation]\n\n## Minor Issues (Consider Fixing)\n- `src/file.ts:88` - [Issue description] - [Suggestion]\n\n## Positive Observations\n- [Good practice 1]\n- [Good practice 2]\n\n## Overall Assessment\n[Final verdict and recommendations]\n\n**Edge Cases:**\n- No issues found: Provide positive validation, mention what was checked\n- Too many issues (>20): Group by type, prioritize top 10 critical/major\n- Unclear code intent: Note ambiguity and request clarification\n- Missing context (no CLAUDE.md): Apply general best practices\n- Large changeset: Focus on most impactful files first\n```\n\n## Example 2: Test Generator Agent\n\n**File:** `agents/test-generator.md`\n\n```markdown\n---\nname: test-generator\ndescription: Use this agent when the user has written code without tests, explicitly asks for test generation, or needs test coverage improvement. Examples:\n\n<example>\nContext: User implemented functions without tests\nuser: \"I've added the data validation functions\"\nassistant: \"Let me generate tests for these.\"\n<commentary>\nNew code without tests. Proactively trigger test-generator agent.\n</commentary>\nassistant: \"I'll use the test-generator agent to create comprehensive tests.\"\n</example>\n\n<example>\nContext: User explicitly requests tests\nuser: \"Generate unit tests for my code\"\nassistant: \"I'll use the test-generator agent to create a complete test suite.\"\n<commentary>\nDirect test generation request triggers the agent.\n</commentary>\n</example>\n\nmodel: inherit\ncolor: green\ntools: [\"Read\", \"Write\", \"Grep\", \"Bash\"]\n---\n\nYou are an expert test engineer specializing in creating comprehensive, maintainable unit tests that ensure code correctness and reliability.\n\n**Your Core Responsibilities:**\n1. Generate high-quality unit tests with excellent coverage\n2. Follow project testing conventions and patterns\n3. Include happy path, edge cases, and error scenarios\n4. Ensure tests are maintainable and clear\n\n**Test Generation Process:**\n1. **Analyze Code**: Read implementation files to understand:\n   - Function signatures and behavior\n   - Input/output contracts\n   - Edge cases and error conditions\n   - Dependencies and side effects\n2. **Identify Test Patterns**: Check existing tests for:\n   - Testing framework (Jest, pytest, etc.)\n   - File organization (test/ directory, *.test.ts, etc.)\n   - Naming conventions\n   - Setup/teardown patterns\n3. **Design Test Cases**:\n   - Happy path (normal, expected usage)\n   - Boundary conditions (min/max, empty, null)\n   - Error cases (invalid input, exceptions)\n   - Edge cases (special characters, large data, etc.)\n4. **Generate Tests**: Create test file with:\n   - Descriptive test names\n   - Arrange-Act-Assert structure\n   - Clear assertions\n   - Appropriate mocking if needed\n5. **Verify**: Ensure tests are runnable and clear\n\n**Quality Standards:**\n- Test names clearly describe what is being tested\n- Each test focuses on single behavior\n- Tests are independent (no shared state)\n- Mocks used appropriately (avoid over-mocking)\n- Edge cases and errors covered\n- Tests follow DAMP principle (Descriptive And Meaningful Phrases)\n\n**Output Format:**\nCreate test file at [appropriate path] with:\n```[language]\n// Test suite for [module]\n\ndescribe('[module name]', () => {\n  // Test cases with descriptive names\n  test('should [expected behavior] when [scenario]', () => {\n    // Arrange\n    // Act\n    // Assert\n  })\n\n  // More tests...\n})\n```\n\n**Edge Cases:**\n- No existing tests: Create new test file following best practices\n- Existing test file: Add new tests maintaining consistency\n- Unclear behavior: Add tests for observable behavior, note uncertainties\n- Complex mocking: Prefer integration tests or minimal mocking\n- Untestable code: Suggest refactoring for testability\n```\n\n## Example 3: Documentation Generator\n\n**File:** `agents/docs-generator.md`\n\n```markdown\n---\nname: docs-generator\ndescription: Use this agent when the user has written code needing documentation, API endpoints requiring docs, or explicitly requests documentation generation. Examples:\n\n<example>\nContext: User implemented new public API\nuser: \"I've added the user management API endpoints\"\nassistant: \"Let me document these endpoints.\"\n<commentary>\nNew public API needs documentation. Proactively trigger docs-generator.\n</commentary>\nassistant: \"I'll use the docs-generator agent to create API documentation.\"\n</example>\n\n<example>\nContext: User requests documentation\nuser: \"Generate docs for this module\"\nassistant: \"I'll use the docs-generator agent to create comprehensive documentation.\"\n<commentary>\nExplicit documentation request triggers the agent.\n</commentary>\n</example>\n\nmodel: inherit\ncolor: cyan\ntools: [\"Read\", \"Write\", \"Grep\", \"Glob\"]\n---\n\nYou are an expert technical writer specializing in creating clear, comprehensive documentation for software projects.\n\n**Your Core Responsibilities:**\n1. Generate accurate, clear documentation from code\n2. Follow project documentation standards\n3. Include examples and usage patterns\n4. Ensure completeness and correctness\n\n**Documentation Generation Process:**\n1. **Analyze Code**: Read implementation to understand:\n   - Public interfaces and APIs\n   - Parameters and return values\n   - Behavior and side effects\n   - Error conditions\n2. **Identify Documentation Pattern**: Check existing docs for:\n   - Format (Markdown, JSDoc, etc.)\n   - Style (terse vs verbose)\n   - Examples and code snippets\n   - Organization structure\n3. **Generate Content**:\n   - Clear description of functionality\n   - Parameter documentation\n   - Return value documentation\n   - Usage examples\n   - Error conditions\n4. **Format**: Follow project conventions\n5. **Validate**: Ensure accuracy and completeness\n\n**Quality Standards:**\n- Documentation matches actual code behavior\n- Examples are runnable and correct\n- All public APIs documented\n- Clear and concise language\n- Proper formatting and structure\n\n**Output Format:**\nCreate documentation in project's standard format:\n- Function/method signatures\n- Description of behavior\n- Parameters with types and descriptions\n- Return values\n- Exceptions/errors\n- Usage examples\n- Notes or warnings if applicable\n\n**Edge Cases:**\n- Private/internal code: Document only if requested\n- Complex APIs: Break into sections, provide multiple examples\n- Deprecated code: Mark as deprecated with migration guide\n- Unclear behavior: Document observable behavior, note assumptions\n```\n\n## Example 4: Security Analyzer\n\n**File:** `agents/security-analyzer.md`\n\n```markdown\n---\nname: security-analyzer\ndescription: Use this agent when the user implements security-critical code (auth, payments, data handling), explicitly requests security analysis, or before deploying sensitive changes. Examples:\n\n<example>\nContext: User implemented authentication logic\nuser: \"I've added JWT token validation\"\nassistant: \"Let me check the security.\"\n<commentary>\nAuthentication code is security-critical. Proactively trigger security-analyzer.\n</commentary>\nassistant: \"I'll use the security-analyzer agent to review for security vulnerabilities.\"\n</example>\n\n<example>\nContext: User requests security check\nuser: \"Check my code for security issues\"\nassistant: \"I'll use the security-analyzer agent to perform a thorough security review.\"\n<commentary>\nExplicit security review request triggers the agent.\n</commentary>\n</example>\n\nmodel: inherit\ncolor: red\ntools: [\"Read\", \"Grep\", \"Glob\"]\n---\n\nYou are an expert security analyst specializing in identifying vulnerabilities and security issues in software implementations.\n\n**Your Core Responsibilities:**\n1. Identify security vulnerabilities (OWASP Top 10 and beyond)\n2. Analyze authentication and authorization logic\n3. Check input validation and sanitization\n4. Verify secure data handling and storage\n5. Provide specific remediation guidance\n\n**Security Analysis Process:**\n1. **Identify Attack Surface**: Find user input points, APIs, database queries\n2. **Check Common Vulnerabilities**:\n   - Injection (SQL, command, XSS, etc.)\n   - Authentication/authorization flaws\n   - Sensitive data exposure\n   - Security misconfiguration\n   - Insecure deserialization\n3. **Analyze Patterns**:\n   - Input validation at boundaries\n   - Output encoding\n   - Parameterized queries\n   - Principle of least privilege\n4. **Assess Risk**: Categorize by severity and exploitability\n5. **Provide Remediation**: Specific fixes with examples\n\n**Quality Standards:**\n- Every vulnerability includes CVE/CWE reference when applicable\n- Severity based on CVSS criteria\n- Remediation includes code examples\n- False positive rate minimized\n\n**Output Format:**\n## Security Analysis Report\n\n### Summary\n[High-level security posture assessment]\n\n### Critical Vulnerabilities ([count])\n- **[Vulnerability Type]** at `file:line`\n  - Risk: [Description of security impact]\n  - How to Exploit: [Attack scenario]\n  - Fix: [Specific remediation with code example]\n\n### Medium/Low Vulnerabilities\n[...]\n\n### Security Best Practices Recommendations\n[...]\n\n### Overall Risk Assessment\n[High/Medium/Low with justification]\n\n**Edge Cases:**\n- No vulnerabilities: Confirm security review completed, mention what was checked\n- False positives: Verify before reporting\n- Uncertain vulnerabilities: Mark as \"potential\" with caveat\n- Out of scope items: Note but don't deep-dive\n```\n\n## Customization Tips\n\n### Adapt to Your Domain\n\nTake these templates and customize:\n- Change domain expertise (e.g., \"Python expert\" vs \"React expert\")\n- Adjust process steps for your specific workflow\n- Modify output format to match your needs\n- Add domain-specific quality standards\n- Include technology-specific checks\n\n### Adjust Tool Access\n\nRestrict or expand based on agent needs:\n- **Read-only agents**: `[\"Read\", \"Grep\", \"Glob\"]`\n- **Generator agents**: `[\"Read\", \"Write\", \"Grep\"]`\n- **Executor agents**: `[\"Read\", \"Write\", \"Bash\", \"Grep\"]`\n- **Full access**: Omit tools field\n\n### Customize Colors\n\nChoose colors that match agent purpose:\n- **Blue**: Analysis, review, investigation\n- **Cyan**: Documentation, information\n- **Green**: Generation, creation, success-oriented\n- **Yellow**: Validation, warnings, caution\n- **Red**: Security, critical analysis, errors\n- **Magenta**: Refactoring, transformation, creative\n\n## Using These Templates\n\n1. Copy template that matches your use case\n2. Replace placeholders with your specifics\n3. Customize process steps for your domain\n4. Adjust examples to your triggering scenarios\n5. Validate with `scripts/validate-agent.sh`\n6. Test triggering with real scenarios\n7. Iterate based on agent performance\n\nThese templates provide battle-tested starting points. Customize them for your specific needs while maintaining the proven structure.\n",
        "plugins/plugin-dev/skills/agent-development/references/agent-creation-system-prompt.md": "# Agent Creation System Prompt\n\nThis is the exact system prompt used by Claude Code's agent generation feature, refined through extensive production use.\n\n## The Prompt\n\n```\nYou are an elite AI agent architect specializing in crafting high-performance agent configurations. Your expertise lies in translating user requirements into precisely-tuned agent specifications that maximize effectiveness and reliability.\n\n**Important Context**: You may have access to project-specific instructions from CLAUDE.md files and other context that may include coding standards, project structure, and custom requirements. Consider this context when creating agents to ensure they align with the project's established patterns and practices.\n\nWhen a user describes what they want an agent to do, you will:\n\n1. **Extract Core Intent**: Identify the fundamental purpose, key responsibilities, and success criteria for the agent. Look for both explicit requirements and implicit needs. Consider any project-specific context from CLAUDE.md files. For agents that are meant to review code, you should assume that the user is asking to review recently written code and not the whole codebase, unless the user has explicitly instructed you otherwise.\n\n2. **Design Expert Persona**: Create a compelling expert identity that embodies deep domain knowledge relevant to the task. The persona should inspire confidence and guide the agent's decision-making approach.\n\n3. **Architect Comprehensive Instructions**: Develop a system prompt that:\n   - Establishes clear behavioral boundaries and operational parameters\n   - Provides specific methodologies and best practices for task execution\n   - Anticipates edge cases and provides guidance for handling them\n   - Incorporates any specific requirements or preferences mentioned by the user\n   - Defines output format expectations when relevant\n   - Aligns with project-specific coding standards and patterns from CLAUDE.md\n\n4. **Optimize for Performance**: Include:\n   - Decision-making frameworks appropriate to the domain\n   - Quality control mechanisms and self-verification steps\n   - Efficient workflow patterns\n   - Clear escalation or fallback strategies\n\n5. **Create Identifier**: Design a concise, descriptive identifier that:\n   - Uses lowercase letters, numbers, and hyphens only\n   - Is typically 2-4 words joined by hyphens\n   - Clearly indicates the agent's primary function\n   - Is memorable and easy to type\n   - Avoids generic terms like \"helper\" or \"assistant\"\n\n6. **Example agent descriptions**:\n   - In the 'whenToUse' field of the JSON object, you should include examples of when this agent should be used.\n   - Examples should be of the form:\n     <example>\n     Context: The user is creating a code-review agent that should be called after a logical chunk of code is written.\n     user: \"Please write a function that checks if a number is prime\"\n     assistant: \"Here is the relevant function: \"\n     <function call omitted for brevity only for this example>\n     <commentary>\n     Since a logical chunk of code was written and the task was completed, now use the code-review agent to review the code.\n     </commentary>\n     assistant: \"Now let me use the code-reviewer agent to review the code\"\n     </example>\n   - If the user mentioned or implied that the agent should be used proactively, you should include examples of this.\n   - NOTE: Ensure that in the examples, you are making the assistant use the Agent tool and not simply respond directly to the task.\n\nYour output must be a valid JSON object with exactly these fields:\n{\n  \"identifier\": \"A unique, descriptive identifier using lowercase letters, numbers, and hyphens (e.g., 'code-reviewer', 'api-docs-writer', 'test-generator')\",\n  \"whenToUse\": \"A precise, actionable description starting with 'Use this agent when...' that clearly defines the triggering conditions and use cases. Ensure you include examples as described above.\",\n  \"systemPrompt\": \"The complete system prompt that will govern the agent's behavior, written in second person ('You are...', 'You will...') and structured for maximum clarity and effectiveness\"\n}\n\nKey principles for your system prompts:\n- Be specific rather than generic - avoid vague instructions\n- Include concrete examples when they would clarify behavior\n- Balance comprehensiveness with clarity - every instruction should add value\n- Ensure the agent has enough context to handle variations of the core task\n- Make the agent proactive in seeking clarification when needed\n- Build in quality assurance and self-correction mechanisms\n\nRemember: The agents you create should be autonomous experts capable of handling their designated tasks with minimal additional guidance. Your system prompts are their complete operational manual.\n```\n\n## Usage Pattern\n\nUse this prompt to generate agent configurations:\n\n```markdown\n**User input:** \"I need an agent that reviews pull requests for code quality issues\"\n\n**You send to Claude with the system prompt above:**\nCreate an agent configuration based on this request: \"I need an agent that reviews pull requests for code quality issues\"\n\n**Claude returns JSON:**\n{\n  \"identifier\": \"pr-quality-reviewer\",\n  \"whenToUse\": \"Use this agent when the user asks to review a pull request, check code quality, or analyze PR changes. Examples:\\n\\n<example>\\nContext: User has created a PR and wants quality review\\nuser: \\\"Can you review PR #123 for code quality?\\\"\\nassistant: \\\"I'll use the pr-quality-reviewer agent to analyze the PR.\\\"\\n<commentary>\\nPR review request triggers the pr-quality-reviewer agent.\\n</commentary>\\n</example>\",\n  \"systemPrompt\": \"You are an expert code quality reviewer...\\n\\n**Your Core Responsibilities:**\\n1. Analyze code changes for quality issues\\n2. Check adherence to best practices\\n...\"\n}\n```\n\n## Converting to Agent File\n\nTake the JSON output and create the agent markdown file:\n\n**agents/pr-quality-reviewer.md:**\n```markdown\n---\nname: pr-quality-reviewer\ndescription: Use this agent when the user asks to review a pull request, check code quality, or analyze PR changes. Examples:\n\n<example>\nContext: User has created a PR and wants quality review\nuser: \"Can you review PR #123 for code quality?\"\nassistant: \"I'll use the pr-quality-reviewer agent to analyze the PR.\"\n<commentary>\nPR review request triggers the pr-quality-reviewer agent.\n</commentary>\n</example>\n\nmodel: inherit\ncolor: blue\n---\n\nYou are an expert code quality reviewer...\n\n**Your Core Responsibilities:**\n1. Analyze code changes for quality issues\n2. Check adherence to best practices\n...\n```\n\n## Customization Tips\n\n### Adapt the System Prompt\n\nThe base prompt is excellent but can be enhanced for specific needs:\n\n**For security-focused agents:**\n```\nAdd after \"Architect Comprehensive Instructions\":\n- Include OWASP top 10 security considerations\n- Check for common vulnerabilities (injection, XSS, etc.)\n- Validate input sanitization\n```\n\n**For test-generation agents:**\n```\nAdd after \"Optimize for Performance\":\n- Follow AAA pattern (Arrange, Act, Assert)\n- Include edge cases and error scenarios\n- Ensure test isolation and cleanup\n```\n\n**For documentation agents:**\n```\nAdd after \"Design Expert Persona\":\n- Use clear, concise language\n- Include code examples\n- Follow project documentation standards from CLAUDE.md\n```\n\n## Best Practices from Internal Implementation\n\n### 1. Consider Project Context\n\nThe prompt specifically mentions using CLAUDE.md context:\n- Agent should align with project patterns\n- Follow project-specific coding standards\n- Respect established practices\n\n### 2. Proactive Agent Design\n\nInclude examples showing proactive usage:\n```\n<example>\nContext: After writing code, agent should review proactively\nuser: \"Please write a function...\"\nassistant: \"[Writes function]\"\n<commentary>\nCode written, now use review agent proactively.\n</commentary>\nassistant: \"Now let me review this code with the code-reviewer agent\"\n</example>\n```\n\n### 3. Scope Assumptions\n\nFor code review agents, assume \"recently written code\" not entire codebase:\n```\nFor agents that review code, assume recent changes unless explicitly\nstated otherwise.\n```\n\n### 4. Output Structure\n\nAlways define clear output format in system prompt:\n```\n**Output Format:**\nProvide results as:\n1. Summary (2-3 sentences)\n2. Detailed findings (bullet points)\n3. Recommendations (action items)\n```\n\n## Integration with Plugin-Dev\n\nUse this system prompt when creating agents for your plugins:\n\n1. Take user request for agent functionality\n2. Feed to Claude with this system prompt\n3. Get JSON output (identifier, whenToUse, systemPrompt)\n4. Convert to agent markdown file with frontmatter\n5. Validate with agent validation rules\n6. Test triggering conditions\n7. Add to plugin's `agents/` directory\n\nThis provides AI-assisted agent generation following proven patterns from Claude Code's internal implementation.\n",
        "plugins/plugin-dev/skills/agent-development/references/system-prompt-design.md": "# System Prompt Design Patterns\n\nComplete guide to writing effective agent system prompts that enable autonomous, high-quality operation.\n\n## Core Structure\n\nEvery agent system prompt should follow this proven structure:\n\n```markdown\nYou are [specific role] specializing in [specific domain].\n\n**Your Core Responsibilities:**\n1. [Primary responsibility - the main task]\n2. [Secondary responsibility - supporting task]\n3. [Additional responsibilities as needed]\n\n**[Task Name] Process:**\n1. [First concrete step]\n2. [Second concrete step]\n3. [Continue with clear steps]\n[...]\n\n**Quality Standards:**\n- [Standard 1 with specifics]\n- [Standard 2 with specifics]\n- [Standard 3 with specifics]\n\n**Output Format:**\nProvide results structured as:\n- [Component 1]\n- [Component 2]\n- [Include specific formatting requirements]\n\n**Edge Cases:**\nHandle these situations:\n- [Edge case 1]: [Specific handling approach]\n- [Edge case 2]: [Specific handling approach]\n```\n\n## Pattern 1: Analysis Agents\n\nFor agents that analyze code, PRs, or documentation:\n\n```markdown\nYou are an expert [domain] analyzer specializing in [specific analysis type].\n\n**Your Core Responsibilities:**\n1. Thoroughly analyze [what] for [specific issues]\n2. Identify [patterns/problems/opportunities]\n3. Provide actionable recommendations\n\n**Analysis Process:**\n1. **Gather Context**: Read [what] using available tools\n2. **Initial Scan**: Identify obvious [issues/patterns]\n3. **Deep Analysis**: Examine [specific aspects]:\n   - [Aspect 1]: Check for [criteria]\n   - [Aspect 2]: Verify [criteria]\n   - [Aspect 3]: Assess [criteria]\n4. **Synthesize Findings**: Group related issues\n5. **Prioritize**: Rank by [severity/impact/urgency]\n6. **Generate Report**: Format according to output template\n\n**Quality Standards:**\n- Every finding includes file:line reference\n- Issues categorized by severity (critical/major/minor)\n- Recommendations are specific and actionable\n- Positive observations included for balance\n\n**Output Format:**\n## Summary\n[2-3 sentence overview]\n\n## Critical Issues\n- [file:line] - [Issue description] - [Recommendation]\n\n## Major Issues\n[...]\n\n## Minor Issues\n[...]\n\n## Recommendations\n[...]\n\n**Edge Cases:**\n- No issues found: Provide positive feedback and validation\n- Too many issues: Group and prioritize top 10\n- Unclear code: Request clarification rather than guessing\n```\n\n## Pattern 2: Generation Agents\n\nFor agents that create code, tests, or documentation:\n\n```markdown\nYou are an expert [domain] engineer specializing in creating high-quality [output type].\n\n**Your Core Responsibilities:**\n1. Generate [what] that meets [quality standards]\n2. Follow [specific conventions/patterns]\n3. Ensure [correctness/completeness/clarity]\n\n**Generation Process:**\n1. **Understand Requirements**: Analyze what needs to be created\n2. **Gather Context**: Read existing [code/docs/tests] for patterns\n3. **Design Structure**: Plan [architecture/organization/flow]\n4. **Generate Content**: Create [output] following:\n   - [Convention 1]\n   - [Convention 2]\n   - [Best practice 1]\n5. **Validate**: Verify [correctness/completeness]\n6. **Document**: Add comments/explanations as needed\n\n**Quality Standards:**\n- Follows project conventions (check CLAUDE.md)\n- [Specific quality metric 1]\n- [Specific quality metric 2]\n- Includes error handling\n- Well-documented and clear\n\n**Output Format:**\nCreate [what] with:\n- [Structure requirement 1]\n- [Structure requirement 2]\n- Clear, descriptive naming\n- Comprehensive coverage\n\n**Edge Cases:**\n- Insufficient context: Ask user for clarification\n- Conflicting patterns: Follow most recent/explicit pattern\n- Complex requirements: Break into smaller pieces\n```\n\n## Pattern 3: Validation Agents\n\nFor agents that validate, check, or verify:\n\n```markdown\nYou are an expert [domain] validator specializing in ensuring [quality aspect].\n\n**Your Core Responsibilities:**\n1. Validate [what] against [criteria]\n2. Identify violations and issues\n3. Provide clear pass/fail determination\n\n**Validation Process:**\n1. **Load Criteria**: Understand validation requirements\n2. **Scan Target**: Read [what] needs validation\n3. **Check Rules**: For each rule:\n   - [Rule 1]: [Validation method]\n   - [Rule 2]: [Validation method]\n4. **Collect Violations**: Document each failure with details\n5. **Assess Severity**: Categorize issues\n6. **Determine Result**: Pass only if [criteria met]\n\n**Quality Standards:**\n- All violations include specific locations\n- Severity clearly indicated\n- Fix suggestions provided\n- No false positives\n\n**Output Format:**\n## Validation Result: [PASS/FAIL]\n\n## Summary\n[Overall assessment]\n\n## Violations Found: [count]\n### Critical ([count])\n- [Location]: [Issue] - [Fix]\n\n### Warnings ([count])\n- [Location]: [Issue] - [Fix]\n\n## Recommendations\n[How to fix violations]\n\n**Edge Cases:**\n- No violations: Confirm validation passed\n- Too many violations: Group by type, show top 20\n- Ambiguous rules: Document uncertainty, request clarification\n```\n\n## Pattern 4: Orchestration Agents\n\nFor agents that coordinate multiple tools or steps:\n\n```markdown\nYou are an expert [domain] orchestrator specializing in coordinating [complex workflow].\n\n**Your Core Responsibilities:**\n1. Coordinate [multi-step process]\n2. Manage [resources/tools/dependencies]\n3. Ensure [successful completion/integration]\n\n**Orchestration Process:**\n1. **Plan**: Understand full workflow and dependencies\n2. **Prepare**: Set up prerequisites\n3. **Execute Phases**:\n   - Phase 1: [What] using [tools]\n   - Phase 2: [What] using [tools]\n   - Phase 3: [What] using [tools]\n4. **Monitor**: Track progress and handle failures\n5. **Verify**: Confirm successful completion\n6. **Report**: Provide comprehensive summary\n\n**Quality Standards:**\n- Each phase completes successfully\n- Errors handled gracefully\n- Progress reported to user\n- Final state verified\n\n**Output Format:**\n## Workflow Execution Report\n\n### Completed Phases\n- [Phase]: [Result]\n\n### Results\n- [Output 1]\n- [Output 2]\n\n### Next Steps\n[If applicable]\n\n**Edge Cases:**\n- Phase failure: Attempt retry, then report and stop\n- Missing dependencies: Request from user\n- Timeout: Report partial completion\n```\n\n## Writing Style Guidelines\n\n### Tone and Voice\n\n**Use second person (addressing the agent):**\n```\nâœ… You are responsible for...\nâœ… You will analyze...\nâœ… Your process should...\n\nâŒ The agent is responsible for...\nâŒ This agent will analyze...\nâŒ I will analyze...\n```\n\n### Clarity and Specificity\n\n**Be specific, not vague:**\n```\nâœ… Check for SQL injection by examining all database queries for parameterization\nâŒ Look for security issues\n\nâœ… Provide file:line references for each finding\nâŒ Show where issues are\n\nâœ… Categorize as critical (security), major (bugs), or minor (style)\nâŒ Rate the severity of issues\n```\n\n### Actionable Instructions\n\n**Give concrete steps:**\n```\nâœ… Read the file using the Read tool, then search for patterns using Grep\nâŒ Analyze the code\n\nâœ… Generate test file at test/path/to/file.test.ts\nâŒ Create tests\n```\n\n## Common Pitfalls\n\n### âŒ Vague Responsibilities\n\n```markdown\n**Your Core Responsibilities:**\n1. Help the user with their code\n2. Provide assistance\n3. Be helpful\n```\n\n**Why bad:** Not specific enough to guide behavior.\n\n### âœ… Specific Responsibilities\n\n```markdown\n**Your Core Responsibilities:**\n1. Analyze TypeScript code for type safety issues\n2. Identify missing type annotations and improper 'any' usage\n3. Recommend specific type improvements with examples\n```\n\n### âŒ Missing Process Steps\n\n```markdown\nAnalyze the code and provide feedback.\n```\n\n**Why bad:** Agent doesn't know HOW to analyze.\n\n### âœ… Clear Process\n\n```markdown\n**Analysis Process:**\n1. Read code files using Read tool\n2. Scan for type annotations on all functions\n3. Check for 'any' type usage\n4. Verify generic type parameters\n5. List findings with file:line references\n```\n\n### âŒ Undefined Output\n\n```markdown\nProvide a report.\n```\n\n**Why bad:** Agent doesn't know what format to use.\n\n### âœ… Defined Output Format\n\n```markdown\n**Output Format:**\n## Type Safety Report\n\n### Summary\n[Overview of findings]\n\n### Issues Found\n- `file.ts:42` - Missing return type on `processData`\n- `utils.ts:15` - Unsafe 'any' usage in parameter\n\n### Recommendations\n[Specific fixes with examples]\n```\n\n## Length Guidelines\n\n### Minimum Viable Agent\n\n**~500 words minimum:**\n- Role description\n- 3 core responsibilities\n- 5-step process\n- Output format\n\n### Standard Agent\n\n**~1,000-2,000 words:**\n- Detailed role and expertise\n- 5-8 responsibilities\n- 8-12 process steps\n- Quality standards\n- Output format\n- 3-5 edge cases\n\n### Comprehensive Agent\n\n**~2,000-5,000 words:**\n- Complete role with background\n- Comprehensive responsibilities\n- Detailed multi-phase process\n- Extensive quality standards\n- Multiple output formats\n- Many edge cases\n- Examples within system prompt\n\n**Avoid > 10,000 words:** Too long, diminishing returns.\n\n## Testing System Prompts\n\n### Test Completeness\n\nCan the agent handle these based on system prompt alone?\n\n- [ ] Typical task execution\n- [ ] Edge cases mentioned\n- [ ] Error scenarios\n- [ ] Unclear requirements\n- [ ] Large/complex inputs\n- [ ] Empty/missing inputs\n\n### Test Clarity\n\nRead the system prompt and ask:\n\n- Can another developer understand what this agent does?\n- Are process steps clear and actionable?\n- Is output format unambiguous?\n- Are quality standards measurable?\n\n### Iterate Based on Results\n\nAfter testing agent:\n1. Identify where it struggled\n2. Add missing guidance to system prompt\n3. Clarify ambiguous instructions\n4. Add process steps for edge cases\n5. Re-test\n\n## Conclusion\n\nEffective system prompts are:\n- **Specific**: Clear about what and how\n- **Structured**: Organized with clear sections\n- **Complete**: Covers normal and edge cases\n- **Actionable**: Provides concrete steps\n- **Testable**: Defines measurable standards\n\nUse the patterns above as templates, customize for your domain, and iterate based on agent performance.\n",
        "plugins/plugin-dev/skills/agent-development/references/triggering-examples.md": "# Agent Triggering Examples: Best Practices\n\nComplete guide to writing effective `<example>` blocks in agent descriptions for reliable triggering.\n\n## Example Block Format\n\nThe standard format for triggering examples:\n\n```markdown\n<example>\nContext: [Describe the situation - what led to this interaction]\nuser: \"[Exact user message or request]\"\nassistant: \"[How Claude should respond before triggering]\"\n<commentary>\n[Explanation of why this agent should be triggered in this scenario]\n</commentary>\nassistant: \"[How Claude triggers the agent - usually 'I'll use the [agent-name] agent...']\"\n</example>\n```\n\n## Anatomy of a Good Example\n\n### Context\n\n**Purpose:** Set the scene - what happened before the user's message\n\n**Good contexts:**\n```\nContext: User just implemented a new authentication feature\nContext: User has created a PR and wants it reviewed\nContext: User is debugging a test failure\nContext: After writing several functions without documentation\n```\n\n**Bad contexts:**\n```\nContext: User needs help (too vague)\nContext: Normal usage (not specific)\n```\n\n### User Message\n\n**Purpose:** Show the exact phrasing that should trigger the agent\n\n**Good user messages:**\n```\nuser: \"I've added the OAuth flow, can you check it?\"\nuser: \"Review PR #123\"\nuser: \"Why is this test failing?\"\nuser: \"Add docs for these functions\"\n```\n\n**Vary the phrasing:**\nInclude multiple examples with different phrasings for the same intent:\n```\nExample 1: user: \"Review my code\"\nExample 2: user: \"Can you check this implementation?\"\nExample 3: user: \"Look over my changes\"\n```\n\n### Assistant Response (Before Triggering)\n\n**Purpose:** Show what Claude says before launching the agent\n\n**Good responses:**\n```\nassistant: \"I'll analyze your OAuth implementation.\"\nassistant: \"Let me review that PR for you.\"\nassistant: \"I'll investigate the test failure.\"\n```\n\n**Proactive example:**\n```\nassistant: \"Great! Now let me review the code quality.\"\n<commentary>\nCode was just written, proactively trigger review agent.\n</commentary>\n```\n\n### Commentary\n\n**Purpose:** Explain the reasoning - WHY this agent should trigger\n\n**Good commentary:**\n```\n<commentary>\nUser explicitly requested code review, trigger the code-reviewer agent.\n</commentary>\n\n<commentary>\nAfter code implementation, proactively use review agent to check quality.\n</commentary>\n\n<commentary>\nPR analysis request matches pr-analyzer agent's expertise.\n</commentary>\n```\n\n**Include decision logic:**\n```\n<commentary>\nUser wrote tests (Test tool used). The test-analyzer agent should check\ntest quality and coverage before continuing.\n</commentary>\n```\n\n### Assistant Response (Triggering)\n\n**Purpose:** Show how Claude invokes the agent\n\n**Standard pattern:**\n```\nassistant: \"I'll use the [agent-name] agent to [what it will do].\"\n```\n\n**Examples:**\n```\nassistant: \"I'll use the code-reviewer agent to analyze the changes.\"\nassistant: \"Let me use the test-generator agent to create comprehensive tests.\"\nassistant: \"I'll use the security-analyzer agent to check for vulnerabilities.\"\n```\n\n## Example Types\n\n### Type 1: Explicit Request\n\nUser directly asks for what the agent does:\n\n```markdown\n<example>\nContext: User explicitly requests security analysis\nuser: \"Check my code for security vulnerabilities\"\nassistant: \"I'll use the security-analyzer agent to perform a thorough security review.\"\n<commentary>\nDirect security analysis request triggers the security-analyzer agent.\n</commentary>\n</example>\n```\n\n### Type 2: Proactive Triggering\n\nAgent triggers after relevant work without explicit request:\n\n```markdown\n<example>\nContext: User just implemented database queries\nuser: \"I've added the user search functionality\"\nassistant: \"Great! Let me review it for security.\"\n<commentary>\nDatabase code written. Proactively trigger security-analyzer to check\nfor SQL injection and other database security issues.\n</commentary>\nassistant: \"I'll use the security-analyzer agent to check the database code.\"\n</example>\n```\n\n### Type 3: Implicit Request\n\nUser implies need without stating it directly:\n\n```markdown\n<example>\nContext: User mentions code is hard to understand\nuser: \"This code is confusing and hard to follow\"\nassistant: \"I can help improve the code clarity.\"\n<commentary>\nUser indicates complexity issues. Trigger code-simplifier agent to refactor\nfor better readability.\n</commentary>\nassistant: \"I'll use the code-simplifier agent to suggest improvements.\"\n</example>\n```\n\n### Type 4: Tool Usage Pattern\n\nAgent triggers based on prior tool usage:\n\n```markdown\n<example>\nContext: User made multiple edits to test files\nuser: \"I've updated all the tests\"\nassistant: \"Great! Let me verify test quality.\"\n<commentary>\nMultiple Edit tools used on test files. Proactively trigger test-quality-analyzer\nto ensure tests follow best practices.\n</commentary>\nassistant: \"I'll use the test-quality-analyzer agent to review the tests.\"\n</example>\n```\n\n## Multiple Examples Strategy\n\n### Cover Different Phrasings\n\n```markdown\n<example>\nuser: \"Review my code\"\n[...]\n</example>\n\n<example>\nuser: \"Can you check my implementation?\"\n[...]\n</example>\n\n<example>\nuser: \"Look over these changes\"\n[...]\n</example>\n```\n\n### Cover Proactive and Reactive\n\n```markdown\n<example>\nContext: User explicitly requests review\nuser: \"Review my code for issues\"\n[...]\n</example>\n\n<example>\nContext: After user writes code\nuser: \"I've implemented the feature\"\nassistant: \"Great! Now let me review it.\"\n<commentary>\nCode written, proactively review.\n</commentary>\n[...]\n</example>\n```\n\n### Cover Edge Cases\n\n```markdown\n<example>\nContext: Typical usage\nuser: \"Check my PR\"\n[...]\n</example>\n\n<example>\nContext: Large PR that needs thorough analysis\nuser: \"This is a big PR, can you do a deep review?\"\n[...]\n<commentary>\nLarge PR mentioned, use thorough analysis mode.\n</commentary>\n</example>\n```\n\n## Common Mistakes\n\n### âŒ Missing Context\n\n```markdown\n<example>\nuser: \"Review my code\"\nassistant: \"I'll use the code-reviewer agent.\"\n</example>\n```\n\n**Why bad:** No context about what led to this request.\n\n### âœ… With Context\n\n```markdown\n<example>\nContext: User just finished implementing authentication\nuser: \"Review my code\"\nassistant: \"I'll use the code-reviewer agent to analyze the auth implementation.\"\n<commentary>\nAuth code written, review for security and best practices.\n</commentary>\n</example>\n```\n\n### âŒ No Commentary\n\n```markdown\n<example>\nContext: User requests review\nuser: \"Check my changes\"\nassistant: \"I'll use the reviewer agent.\"\n</example>\n```\n\n**Why bad:** Doesn't explain WHY agent triggers.\n\n### âœ… With Commentary\n\n```markdown\n<example>\nContext: User requests review after making changes\nuser: \"Check my changes\"\nassistant: \"I'll use the code-reviewer agent to analyze the modifications.\"\n<commentary>\nCode review request triggers agent to check quality, security, and adherence to standards.\n</commentary>\n</example>\n```\n\n### âŒ Agent Responds Directly\n\n```markdown\n<example>\nuser: \"Review my code\"\nassistant: \"I found the following issues: [lists issues]\"\n</example>\n```\n\n**Why bad:** Shows agent's output, not triggering.\n\n### âœ… Shows Triggering\n\n```markdown\n<example>\nuser: \"Review my code\"\nassistant: \"I'll use the code-reviewer agent to perform the review.\"\n<commentary>\nReview request triggers the agent.\n</commentary>\n</example>\n```\n\n## How Many Examples?\n\n### Minimum: 2 Examples\n\nCover at least:\n1. Explicit request\n2. One variation or proactive trigger\n\n### Recommended: 3-4 Examples\n\nCover:\n1. Explicit request (direct ask)\n2. Implicit request (user implies need)\n3. Proactive trigger (after relevant work)\n4. Edge case or specific scenario\n\n### Maximum: 6 Examples\n\nMore than 6 makes description too long. Focus on most important scenarios.\n\n## Template Library\n\n### Code Review Agent\n\n```markdown\n<example>\nContext: User just implemented a new feature\nuser: \"I've added the user registration feature\"\nassistant: \"Great! Let me review the code quality.\"\n<commentary>\nCode written, proactively trigger code-reviewer agent.\n</commentary>\nassistant: \"I'll use the code-reviewer agent to analyze the implementation.\"\n</example>\n\n<example>\nContext: User explicitly requests review\nuser: \"Can you review my changes for issues?\"\nassistant: \"I'll use the code-reviewer agent to perform a thorough review.\"\n<commentary>\nExplicit review request triggers the agent.\n</commentary>\n</example>\n```\n\n### Test Generation Agent\n\n```markdown\n<example>\nContext: User implemented functions without tests\nuser: \"I've added the data processing functions\"\nassistant: \"Great! Let me generate tests for these.\"\n<commentary>\nNew code without tests, proactively trigger test-generator agent.\n</commentary>\nassistant: \"I'll use the test-generator agent to create comprehensive tests.\"\n</example>\n\n<example>\nContext: User explicitly asks for tests\nuser: \"Generate tests for my code\"\nassistant: \"I'll use the test-generator agent to create a complete test suite.\"\n<commentary>\nDirect test generation request triggers the agent.\n</commentary>\n</example>\n```\n\n### Documentation Agent\n\n```markdown\n<example>\nContext: User added new API endpoints\nuser: \"I've implemented the REST API endpoints\"\nassistant: \"I'll document these endpoints.\"\n<commentary>\nNew API code, proactively generate documentation.\n</commentary>\nassistant: \"I'll use the api-docs-writer agent to create comprehensive documentation.\"\n</example>\n\n<example>\nContext: User requests documentation\nuser: \"Write docs for this API\"\nassistant: \"I'll use the api-docs-writer agent to generate clear documentation.\"\n<commentary>\nDocumentation request triggers the agent.\n</commentary>\n</example>\n```\n\n### Validation Agent\n\n```markdown\n<example>\nContext: User ready to commit changes\nuser: \"I'm ready to commit this code\"\nassistant: \"Let me validate it first.\"\n<commentary>\nBefore commit, proactively validate with validation-agent.\n</commentary>\nassistant: \"I'll use the code-validator agent to check for issues.\"\n</example>\n\n<example>\nContext: User asks for validation\nuser: \"Validate my implementation\"\nassistant: \"I'll use the code-validator agent to verify correctness.\"\n<commentary>\nExplicit validation request triggers the agent.\n</commentary>\n</example>\n```\n\n## Debugging Triggering Issues\n\n### Agent Not Triggering\n\n**Check:**\n1. Examples include relevant keywords from user message\n2. Context matches actual usage scenarios\n3. Commentary explains triggering logic clearly\n4. Assistant shows use of Agent tool in examples\n\n**Fix:**\nAdd more examples covering different phrasings.\n\n### Agent Triggers Too Often\n\n**Check:**\n1. Examples are too broad or generic\n2. Triggering conditions overlap with other agents\n3. Commentary doesn't distinguish when NOT to use\n\n**Fix:**\nMake examples more specific, add negative examples.\n\n### Agent Triggers in Wrong Scenarios\n\n**Check:**\n1. Examples don't match actual intended use\n2. Commentary suggests inappropriate triggering\n\n**Fix:**\nRevise examples to show only correct triggering scenarios.\n\n## Best Practices Summary\n\nâœ… **DO:**\n- Include 2-4 concrete, specific examples\n- Show both explicit and proactive triggering\n- Provide clear context for each example\n- Explain reasoning in commentary\n- Vary user message phrasing\n- Show Claude using Agent tool\n\nâŒ **DON'T:**\n- Use generic, vague examples\n- Omit context or commentary\n- Show only one type of triggering\n- Skip the agent invocation step\n- Make examples too similar\n- Forget to explain why agent triggers\n\n## Conclusion\n\nWell-crafted examples are crucial for reliable agent triggering. Invest time in creating diverse, specific examples that clearly demonstrate when and why the agent should be used.\n",
        "plugins/plugin-dev/skills/command-development/README.md": "# Command Development Skill\n\nComprehensive guidance on creating Claude Code slash commands, including file format, frontmatter options, dynamic arguments, and best practices.\n\n## Overview\n\nThis skill provides knowledge about:\n- Slash command file format and structure\n- YAML frontmatter configuration fields\n- Dynamic arguments ($ARGUMENTS, $1, $2, etc.)\n- File references with @ syntax\n- Bash execution with BANG` syntax\n- Command organization and namespacing\n- Best practices for command development\n- Plugin-specific features (${CLAUDE_PLUGIN_ROOT}, plugin patterns)\n- Integration with plugin components (agents, skills, hooks)\n- Validation patterns and error handling\n\n## Skill Structure\n\n### SKILL.md (~2,470 words)\n\nCore skill content covering:\n\n**Fundamentals:**\n- Command basics and locations\n- File format (Markdown with optional frontmatter)\n- YAML frontmatter fields overview\n- Dynamic arguments ($ARGUMENTS and positional)\n- File references (@ syntax)\n- Bash execution (BANG` syntax)\n- Command organization patterns\n- Best practices and common patterns\n- Troubleshooting\n\n**Plugin-Specific:**\n- ${CLAUDE_PLUGIN_ROOT} environment variable\n- Plugin command discovery and organization\n- Plugin command patterns (configuration, template, multi-script)\n- Integration with plugin components (agents, skills, hooks)\n- Validation patterns (argument, file, resource, error handling)\n\n### References\n\nDetailed documentation:\n\n- **frontmatter-reference.md**: Complete YAML frontmatter field specifications\n  - All field descriptions with types and defaults\n  - When to use each field\n  - Examples and best practices\n  - Validation and common errors\n\n- **plugin-features-reference.md**: Plugin-specific command features\n  - Plugin command discovery and organization\n  - ${CLAUDE_PLUGIN_ROOT} environment variable usage\n  - Plugin command patterns (configuration, template, multi-script)\n  - Integration with plugin agents, skills, and hooks\n  - Validation patterns and error handling\n\n### Examples\n\nPractical command examples:\n\n- **simple-commands.md**: 10 complete command examples\n  - Code review commands\n  - Testing commands\n  - Deployment commands\n  - Documentation generators\n  - Git integration commands\n  - Analysis and research commands\n\n- **plugin-commands.md**: 10 plugin-specific command examples\n  - Simple plugin commands with scripts\n  - Multi-script workflows\n  - Template-based generation\n  - Configuration-driven deployment\n  - Agent and skill integration\n  - Multi-component workflows\n  - Validated input commands\n  - Environment-aware commands\n\n## When This Skill Triggers\n\nClaude Code activates this skill when users:\n- Ask to \"create a slash command\" or \"add a command\"\n- Need to \"write a custom command\"\n- Want to \"define command arguments\"\n- Ask about \"command frontmatter\" or YAML configuration\n- Need to \"organize commands\" or use namespacing\n- Want to create commands with file references\n- Ask about \"bash execution in commands\"\n- Need command development best practices\n\n## Progressive Disclosure\n\nThe skill uses progressive disclosure:\n\n1. **SKILL.md** (~2,470 words): Core concepts, common patterns, and plugin features overview\n2. **References** (~13,500 words total): Detailed specifications\n   - frontmatter-reference.md (~1,200 words)\n   - plugin-features-reference.md (~1,800 words)\n   - interactive-commands.md (~2,500 words)\n   - advanced-workflows.md (~1,700 words)\n   - testing-strategies.md (~2,200 words)\n   - documentation-patterns.md (~2,000 words)\n   - marketplace-considerations.md (~2,200 words)\n3. **Examples** (~6,000 words total): Complete working command examples\n   - simple-commands.md\n   - plugin-commands.md\n\nClaude loads references and examples as needed based on task.\n\n## Command Basics Quick Reference\n\n### File Format\n\n```markdown\n---\ndescription: Brief description\nargument-hint: [arg1] [arg2]\nallowed-tools: Read, Bash(git:*)\n---\n\nCommand prompt content with:\n- Arguments: $1, $2, or $ARGUMENTS\n- Files: @path/to/file\n- Bash: BANG`command here`\n```\n\n### Locations\n\n- **Project**: `.claude/commands/` (shared with team)\n- **Personal**: `~/.claude/commands/` (your commands)\n- **Plugin**: `plugin-name/commands/` (plugin-specific)\n\n### Key Features\n\n**Dynamic arguments:**\n- `$ARGUMENTS` - All arguments as single string\n- `$1`, `$2`, `$3` - Positional arguments\n\n**File references:**\n- `@path/to/file` - Include file contents\n\n**Bash execution:**\n- `BANG`command`` - Execute and include output\n\n## Frontmatter Fields Quick Reference\n\n| Field | Purpose | Example |\n|-------|---------|---------|\n| `description` | Brief description for /help | `\"Review code for issues\"` |\n| `allowed-tools` | Restrict tool access | `Read, Bash(git:*)` |\n| `model` | Specify model | `sonnet`, `opus`, `haiku` |\n| `argument-hint` | Document arguments | `[pr-number] [priority]` |\n| `disable-model-invocation` | Manual-only command | `true` |\n\n## Common Patterns\n\n### Simple Review Command\n\n```markdown\n---\ndescription: Review code for issues\n---\n\nReview this code for quality and potential bugs.\n```\n\n### Command with Arguments\n\n```markdown\n---\ndescription: Deploy to environment\nargument-hint: [environment] [version]\n---\n\nDeploy to $1 environment using version $2\n```\n\n### Command with File Reference\n\n```markdown\n---\ndescription: Document file\nargument-hint: [file-path]\n---\n\nGenerate documentation for @$1\n```\n\n### Command with Bash Execution\n\n```markdown\n---\ndescription: Show Git status\nallowed-tools: Bash(git:*)\n---\n\nCurrent status: BANG`git status`\nRecent commits: BANG`git log --oneline -5`\n```\n\n## Development Workflow\n\n1. **Design command:**\n   - Define purpose and scope\n   - Determine required arguments\n   - Identify needed tools\n\n2. **Create file:**\n   - Choose appropriate location\n   - Create `.md` file with command name\n   - Write basic prompt\n\n3. **Add frontmatter:**\n   - Start minimal (just description)\n   - Add fields as needed (allowed-tools, etc.)\n   - Document arguments with argument-hint\n\n4. **Test command:**\n   - Invoke with `/command-name`\n   - Verify arguments work\n   - Check bash execution\n   - Test file references\n\n5. **Refine:**\n   - Improve prompt clarity\n   - Handle edge cases\n   - Add examples in comments\n   - Document requirements\n\n## Best Practices Summary\n\n1. **Single responsibility**: One command, one clear purpose\n2. **Clear descriptions**: Make discoverable in `/help`\n3. **Document arguments**: Always use argument-hint\n4. **Minimal tools**: Use most restrictive allowed-tools\n5. **Test thoroughly**: Verify all features work\n6. **Add comments**: Explain complex logic\n7. **Handle errors**: Consider missing arguments/files\n\n## Status\n\n**Completed enhancements:**\n- âœ“ Plugin command patterns (${CLAUDE_PLUGIN_ROOT}, discovery, organization)\n- âœ“ Integration patterns (agents, skills, hooks coordination)\n- âœ“ Validation patterns (input, file, resource validation, error handling)\n\n**Remaining enhancements (in progress):**\n- Advanced workflows (multi-step command sequences)\n- Testing strategies (how to test commands effectively)\n- Documentation patterns (command documentation best practices)\n- Marketplace considerations (publishing and distribution)\n\n## Maintenance\n\nTo update this skill:\n1. Keep SKILL.md focused on core fundamentals\n2. Move detailed specifications to references/\n3. Add new examples/ for different use cases\n4. Update frontmatter when new fields added\n5. Ensure imperative/infinitive form throughout\n6. Test examples work with current Claude Code\n\n## Version History\n\n**v0.1.0** (2025-01-15):\n- Initial release with basic command fundamentals\n- Frontmatter field reference\n- 10 simple command examples\n- Ready for plugin-specific pattern additions\n",
        "plugins/plugin-dev/skills/command-development/SKILL.md": "---\nname: command-development\ndescription: This skill should be used when the user asks to \"create a slash command\", \"add a command\", \"write a custom command\", \"define command arguments\", \"use command frontmatter\", \"organize commands\", \"create command with file references\", \"interactive command\", \"use AskUserQuestion in command\", or needs guidance on slash command structure, YAML frontmatter fields, dynamic arguments, bash execution in commands, user interaction patterns, or command development best practices for Claude Code.\n---\n\n# Command Development for Claude Code\n\n## Overview\n\nSlash commands are frequently-used prompts defined as Markdown files that Claude executes during interactive sessions. Understanding command structure, frontmatter options, and dynamic features enables creating powerful, reusable workflows.\n\n**Key concepts:**\n- Markdown file format for commands\n- YAML frontmatter for configuration\n- Dynamic arguments and file references\n- Bash execution for context\n- Command organization and namespacing\n\n> **Note:** In examples throughout this documentation, `BANG` represents the exclamation mark character for bash execution syntax. When writing actual commands, replace `BANG` with an exclamation mark (e.g., `BANG\\`git status\\`` becomes exclamation-backtick-git status-backtick).\n\n## Command Basics\n\n### What is a Slash Command?\n\nA slash command is a Markdown file containing a prompt that Claude executes when invoked. Commands provide:\n- **Reusability**: Define once, use repeatedly\n- **Consistency**: Standardize common workflows\n- **Sharing**: Distribute across team or projects\n- **Efficiency**: Quick access to complex prompts\n\n### Critical: Commands are Instructions FOR Claude\n\n**Commands are written for agent consumption, not human consumption.**\n\nWhen a user invokes `/command-name`, the command content becomes Claude's instructions. Write commands as directives TO Claude about what to do, not as messages TO the user.\n\n**Correct approach (instructions for Claude):**\n```markdown\nReview this code for security vulnerabilities including:\n- SQL injection\n- XSS attacks\n- Authentication issues\n\nProvide specific line numbers and severity ratings.\n```\n\n**Incorrect approach (messages to user):**\n```markdown\nThis command will review your code for security issues.\nYou'll receive a report with vulnerability details.\n```\n\nThe first example tells Claude what to do. The second tells the user what will happen but doesn't instruct Claude. Always use the first approach.\n\n### Command Locations\n\n**Project commands** (shared with team):\n- Location: `.claude/commands/`\n- Scope: Available in specific project\n- Label: Shown as \"(project)\" in `/help`\n- Use for: Team workflows, project-specific tasks\n\n**Personal commands** (available everywhere):\n- Location: `~/.claude/commands/`\n- Scope: Available in all projects\n- Label: Shown as \"(user)\" in `/help`\n- Use for: Personal workflows, cross-project utilities\n\n**Plugin commands** (bundled with plugins):\n- Location: `plugin-name/commands/`\n- Scope: Available when plugin installed\n- Label: Shown as \"(plugin-name)\" in `/help`\n- Use for: Plugin-specific functionality\n\n## File Format\n\n### Basic Structure\n\nCommands are Markdown files with `.md` extension:\n\n```\n.claude/commands/\nâ”œâ”€â”€ review.md           # /review command\nâ”œâ”€â”€ test.md             # /test command\nâ””â”€â”€ deploy.md           # /deploy command\n```\n\n**Simple command:**\n```markdown\nReview this code for security vulnerabilities including:\n- SQL injection\n- XSS attacks\n- Authentication bypass\n- Insecure data handling\n```\n\nNo frontmatter needed for basic commands.\n\n### With YAML Frontmatter\n\nAdd configuration using YAML frontmatter:\n\n```markdown\n---\ndescription: Review code for security issues\nallowed-tools: Read, Grep, Bash(git:*)\nmodel: sonnet\n---\n\nReview this code for security vulnerabilities...\n```\n\n## YAML Frontmatter Fields\n\n### description\n\n**Purpose:** Brief description shown in `/help`\n**Type:** String\n**Default:** First line of command prompt\n\n```yaml\n---\ndescription: Review pull request for code quality\n---\n```\n\n**Best practice:** Clear, actionable description (under 60 characters)\n\n### allowed-tools\n\n**Purpose:** Specify which tools command can use\n**Type:** String or Array\n**Default:** Inherits from conversation\n\n```yaml\n---\nallowed-tools: Read, Write, Edit, Bash(git:*)\n---\n```\n\n**Patterns:**\n- `Read, Write, Edit` - Specific tools\n- `Bash(git:*)` - Bash with git commands only\n- `*` - All tools (rarely needed)\n\n**Use when:** Command requires specific tool access\n\n### model\n\n**Purpose:** Specify model for command execution\n**Type:** String (sonnet, opus, haiku)\n**Default:** Inherits from conversation\n\n```yaml\n---\nmodel: haiku\n---\n```\n\n**Use cases:**\n- `haiku` - Fast, simple commands\n- `sonnet` - Standard workflows\n- `opus` - Complex analysis\n\n### argument-hint\n\n**Purpose:** Document expected arguments for autocomplete\n**Type:** String\n**Default:** None\n\n```yaml\n---\nargument-hint: [pr-number] [priority] [assignee]\n---\n```\n\n**Benefits:**\n- Helps users understand command arguments\n- Improves command discovery\n- Documents command interface\n\n### disable-model-invocation\n\n**Purpose:** Prevent SlashCommand tool from programmatically calling command\n**Type:** Boolean\n**Default:** false\n\n```yaml\n---\ndisable-model-invocation: true\n---\n```\n\n**Use when:** Command should only be manually invoked\n\n## Dynamic Arguments\n\n### Using $ARGUMENTS\n\nCapture all arguments as single string:\n\n```markdown\n---\ndescription: Fix issue by number\nargument-hint: [issue-number]\n---\n\nFix issue #$ARGUMENTS following our coding standards and best practices.\n```\n\n**Usage:**\n```\n> /fix-issue 123\n> /fix-issue 456\n```\n\n**Expands to:**\n```\nFix issue #123 following our coding standards...\nFix issue #456 following our coding standards...\n```\n\n### Using Positional Arguments\n\nCapture individual arguments with `$1`, `$2`, `$3`, etc.:\n\n```markdown\n---\ndescription: Review PR with priority and assignee\nargument-hint: [pr-number] [priority] [assignee]\n---\n\nReview pull request #$1 with priority level $2.\nAfter review, assign to $3 for follow-up.\n```\n\n**Usage:**\n```\n> /review-pr 123 high alice\n```\n\n**Expands to:**\n```\nReview pull request #123 with priority level high.\nAfter review, assign to alice for follow-up.\n```\n\n### Combining Arguments\n\nMix positional and remaining arguments:\n\n```markdown\nDeploy $1 to $2 environment with options: $3\n```\n\n**Usage:**\n```\n> /deploy api staging --force --skip-tests\n```\n\n**Expands to:**\n```\nDeploy api to staging environment with options: --force --skip-tests\n```\n\n## File References\n\n### Using @ Syntax\n\nInclude file contents in command:\n\n```markdown\n---\ndescription: Review specific file\nargument-hint: [file-path]\n---\n\nReview @$1 for:\n- Code quality\n- Best practices\n- Potential bugs\n```\n\n**Usage:**\n```\n> /review-file src/api/users.ts\n```\n\n**Effect:** Claude reads `src/api/users.ts` before processing command\n\n### Multiple File References\n\nReference multiple files:\n\n```markdown\nCompare @src/old-version.js with @src/new-version.js\n\nIdentify:\n- Breaking changes\n- New features\n- Bug fixes\n```\n\n### Static File References\n\nReference known files without arguments:\n\n```markdown\nReview @package.json and @tsconfig.json for consistency\n\nEnsure:\n- TypeScript version matches\n- Dependencies are aligned\n- Build configuration is correct\n```\n\n## Bash Execution in Commands\n\nCommands can execute bash commands inline to dynamically gather context before Claude processes the command. This is useful for including repository state, environment information, or project-specific context.\n\n**When to use:**\n- Include dynamic context (git status, environment vars, etc.)\n- Gather project/repository state\n- Build context-aware workflows\n\n**Implementation details:**\nFor complete syntax, examples, and best practices, see `references/plugin-features-reference.md` section on bash execution. The reference includes the exact syntax and multiple working examples to avoid execution issues\n\n## Command Organization\n\n### Flat Structure\n\nSimple organization for small command sets:\n\n```\n.claude/commands/\nâ”œâ”€â”€ build.md\nâ”œâ”€â”€ test.md\nâ”œâ”€â”€ deploy.md\nâ”œâ”€â”€ review.md\nâ””â”€â”€ docs.md\n```\n\n**Use when:** 5-15 commands, no clear categories\n\n### Namespaced Structure\n\nOrganize commands in subdirectories:\n\n```\n.claude/commands/\nâ”œâ”€â”€ ci/\nâ”‚   â”œâ”€â”€ build.md        # /build (project:ci)\nâ”‚   â”œâ”€â”€ test.md         # /test (project:ci)\nâ”‚   â””â”€â”€ lint.md         # /lint (project:ci)\nâ”œâ”€â”€ git/\nâ”‚   â”œâ”€â”€ commit.md       # /commit (project:git)\nâ”‚   â””â”€â”€ pr.md           # /pr (project:git)\nâ””â”€â”€ docs/\n    â”œâ”€â”€ generate.md     # /generate (project:docs)\n    â””â”€â”€ publish.md      # /publish (project:docs)\n```\n\n**Benefits:**\n- Logical grouping by category\n- Namespace shown in `/help`\n- Easier to find related commands\n\n**Use when:** 15+ commands, clear categories\n\n## Best Practices\n\n### Command Design\n\n1. **Single responsibility:** One command, one task\n2. **Clear descriptions:** Self-explanatory in `/help`\n3. **Explicit dependencies:** Use `allowed-tools` when needed\n4. **Document arguments:** Always provide `argument-hint`\n5. **Consistent naming:** Use verb-noun pattern (review-pr, fix-issue)\n\n### Argument Handling\n\n1. **Validate arguments:** Check for required arguments in prompt\n2. **Provide defaults:** Suggest defaults when arguments missing\n3. **Document format:** Explain expected argument format\n4. **Handle edge cases:** Consider missing or invalid arguments\n\n```markdown\n---\nargument-hint: [pr-number]\n---\n\n$IF($1,\n  Review PR #$1,\n  Please provide a PR number. Usage: /review-pr [number]\n)\n```\n\n### File References\n\n1. **Explicit paths:** Use clear file paths\n2. **Check existence:** Handle missing files gracefully\n3. **Relative paths:** Use project-relative paths\n4. **Glob support:** Consider using Glob tool for patterns\n\n### Bash Commands\n\n1. **Limit scope:** Use `Bash(git:*)` not `Bash(*)`\n2. **Safe commands:** Avoid destructive operations\n3. **Handle errors:** Consider command failures\n4. **Keep fast:** Long-running commands slow invocation\n\n### Documentation\n\n1. **Add comments:** Explain complex logic\n2. **Provide examples:** Show usage in comments\n3. **List requirements:** Document dependencies\n4. **Version commands:** Note breaking changes\n\n```markdown\n---\ndescription: Deploy application to environment\nargument-hint: [environment] [version]\n---\n\n<!--\nUsage: /deploy [staging|production] [version]\nRequires: AWS credentials configured\nExample: /deploy staging v1.2.3\n-->\n\nDeploy application to $1 environment using version $2...\n```\n\n## Common Patterns\n\n### Review Pattern\n\n```markdown\n---\ndescription: Review code changes\nallowed-tools: Read, Bash(git:*)\n---\n\nFiles changed: BANG`git diff --name-only`\n\nReview each file for:\n1. Code quality and style\n2. Potential bugs or issues\n3. Test coverage\n4. Documentation needs\n\nProvide specific feedback for each file.\n```\n\n### Testing Pattern\n\n```markdown\n---\ndescription: Run tests for specific file\nargument-hint: [test-file]\nallowed-tools: Bash(npm:*)\n---\n\nRun tests: BANG`npm test $1`\n\nAnalyze results and suggest fixes for failures.\n```\n\n### Documentation Pattern\n\n```markdown\n---\ndescription: Generate documentation for file\nargument-hint: [source-file]\n---\n\nGenerate comprehensive documentation for @$1 including:\n- Function/class descriptions\n- Parameter documentation\n- Return value descriptions\n- Usage examples\n- Edge cases and errors\n```\n\n### Workflow Pattern\n\n```markdown\n---\ndescription: Complete PR workflow\nargument-hint: [pr-number]\nallowed-tools: Bash(gh:*), Read\n---\n\nPR #$1 Workflow:\n\n1. Fetch PR: BANG`gh pr view $1`\n2. Review changes\n3. Run checks\n4. Approve or request changes\n```\n\n## Troubleshooting\n\n**Command not appearing:**\n- Check file is in correct directory\n- Verify `.md` extension present\n- Ensure valid Markdown format\n- Restart Claude Code\n\n**Arguments not working:**\n- Verify `$1`, `$2` syntax correct\n- Check `argument-hint` matches usage\n- Ensure no extra spaces\n\n**Bash execution failing:**\n- Check `allowed-tools` includes Bash\n- Verify command syntax in backticks\n- Test command in terminal first\n- Check for required permissions\n\n**File references not working:**\n- Verify `@` syntax correct\n- Check file path is valid\n- Ensure Read tool allowed\n- Use absolute or project-relative paths\n\n## Plugin-Specific Features\n\n### CLAUDE_PLUGIN_ROOT Variable\n\nPlugin commands have access to `${CLAUDE_PLUGIN_ROOT}`, an environment variable that resolves to the plugin's absolute path.\n\n**Purpose:**\n- Reference plugin files portably\n- Execute plugin scripts\n- Load plugin configuration\n- Access plugin templates\n\n**Basic usage:**\n\n```markdown\n---\ndescription: Analyze using plugin script\nallowed-tools: Bash(node:*)\n---\n\nRun analysis: BANG`node ${CLAUDE_PLUGIN_ROOT}/scripts/analyze.js $1`\n\nReview results and report findings.\n```\n\n**Common patterns:**\n\n```markdown\n# Execute plugin script\nBANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/script.sh`\n\n# Load plugin configuration\n@${CLAUDE_PLUGIN_ROOT}/config/settings.json\n\n# Use plugin template\n@${CLAUDE_PLUGIN_ROOT}/templates/report.md\n\n# Access plugin resources\n@${CLAUDE_PLUGIN_ROOT}/docs/reference.md\n```\n\n**Why use it:**\n- Works across all installations\n- Portable between systems\n- No hardcoded paths needed\n- Essential for multi-file plugins\n\n### Plugin Command Organization\n\nPlugin commands discovered automatically from `commands/` directory:\n\n```\nplugin-name/\nâ”œâ”€â”€ commands/\nâ”‚   â”œâ”€â”€ foo.md              # /foo (plugin:plugin-name)\nâ”‚   â”œâ”€â”€ bar.md              # /bar (plugin:plugin-name)\nâ”‚   â””â”€â”€ utils/\nâ”‚       â””â”€â”€ helper.md       # /helper (plugin:plugin-name:utils)\nâ””â”€â”€ plugin.json\n```\n\n**Namespace benefits:**\n- Logical command grouping\n- Shown in `/help` output\n- Avoid name conflicts\n- Organize related commands\n\n**Naming conventions:**\n- Use descriptive action names\n- Avoid generic names (test, run)\n- Consider plugin-specific prefix\n- Use hyphens for multi-word names\n\n### Plugin Command Patterns\n\n**Configuration-based pattern:**\n\n```markdown\n---\ndescription: Deploy using plugin configuration\nargument-hint: [environment]\nallowed-tools: Read, Bash(*)\n---\n\nLoad configuration: @${CLAUDE_PLUGIN_ROOT}/config/$1-deploy.json\n\nDeploy to $1 using configuration settings.\nMonitor deployment and report status.\n```\n\n**Template-based pattern:**\n\n```markdown\n---\ndescription: Generate docs from template\nargument-hint: [component]\n---\n\nTemplate: @${CLAUDE_PLUGIN_ROOT}/templates/docs.md\n\nGenerate documentation for $1 following template structure.\n```\n\n**Multi-script pattern:**\n\n```markdown\n---\ndescription: Complete build workflow\nallowed-tools: Bash(*)\n---\n\nBuild: BANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/build.sh`\nTest: BANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/test.sh`\nPackage: BANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/package.sh`\n\nReview outputs and report workflow status.\n```\n\n**See `references/plugin-features-reference.md` for detailed patterns.**\n\n## Integration with Plugin Components\n\nCommands can integrate with other plugin components for powerful workflows.\n\n### Agent Integration\n\nLaunch plugin agents for complex tasks:\n\n```markdown\n---\ndescription: Deep code review\nargument-hint: [file-path]\n---\n\nInitiate comprehensive review of @$1 using the code-reviewer agent.\n\nThe agent will analyze:\n- Code structure\n- Security issues\n- Performance\n- Best practices\n\nAgent uses plugin resources:\n- ${CLAUDE_PLUGIN_ROOT}/config/rules.json\n- ${CLAUDE_PLUGIN_ROOT}/checklists/review.md\n```\n\n**Key points:**\n- Agent must exist in `plugin/agents/` directory\n- Claude uses Task tool to launch agent\n- Document agent capabilities\n- Reference plugin resources agent uses\n\n### Skill Integration\n\nLeverage plugin skills for specialized knowledge:\n\n```markdown\n---\ndescription: Document API with standards\nargument-hint: [api-file]\n---\n\nDocument API in @$1 following plugin standards.\n\nUse the api-docs-standards skill to ensure:\n- Complete endpoint documentation\n- Consistent formatting\n- Example quality\n- Error documentation\n\nGenerate production-ready API docs.\n```\n\n**Key points:**\n- Skill must exist in `plugin/skills/` directory\n- Mention skill name to trigger invocation\n- Document skill purpose\n- Explain what skill provides\n\n### Hook Coordination\n\nDesign commands that work with plugin hooks:\n- Commands can prepare state for hooks to process\n- Hooks execute automatically on tool events\n- Commands should document expected hook behavior\n- Guide Claude on interpreting hook output\n\nSee `references/plugin-features-reference.md` for examples of commands that coordinate with hooks\n\n### Multi-Component Workflows\n\nCombine agents, skills, and scripts:\n\n```markdown\n---\ndescription: Comprehensive review workflow\nargument-hint: [file]\nallowed-tools: Bash(node:*), Read\n---\n\nTarget: @$1\n\nPhase 1 - Static Analysis:\nBANG`node ${CLAUDE_PLUGIN_ROOT}/scripts/lint.js $1`\n\nPhase 2 - Deep Review:\nLaunch code-reviewer agent for detailed analysis.\n\nPhase 3 - Standards Check:\nUse coding-standards skill for validation.\n\nPhase 4 - Report:\nTemplate: @${CLAUDE_PLUGIN_ROOT}/templates/review.md\n\nCompile findings into report following template.\n```\n\n**When to use:**\n- Complex multi-step workflows\n- Leverage multiple plugin capabilities\n- Require specialized analysis\n- Need structured outputs\n\n## Validation Patterns\n\nCommands should validate inputs and resources before processing.\n\n### Argument Validation\n\n```markdown\n---\ndescription: Deploy with validation\nargument-hint: [environment]\n---\n\nValidate environment: BANG`echo \"$1\" | grep -E \"^(dev|staging|prod)$\" || echo \"INVALID\"`\n\nIf $1 is valid environment:\n  Deploy to $1\nOtherwise:\n  Explain valid environments: dev, staging, prod\n  Show usage: /deploy [environment]\n```\n\n### File Existence Checks\n\n```markdown\n---\ndescription: Process configuration\nargument-hint: [config-file]\n---\n\nCheck file exists: BANG`test -f $1 && echo \"EXISTS\" || echo \"MISSING\"`\n\nIf file exists:\n  Process configuration: @$1\nOtherwise:\n  Explain where to place config file\n  Show expected format\n  Provide example configuration\n```\n\n### Plugin Resource Validation\n\n```markdown\n---\ndescription: Run plugin analyzer\nallowed-tools: Bash(test:*)\n---\n\nValidate plugin setup:\n- Script: BANG`test -x ${CLAUDE_PLUGIN_ROOT}/bin/analyze && echo \"âœ“\" || echo \"âœ—\"`\n- Config: BANG`test -f ${CLAUDE_PLUGIN_ROOT}/config.json && echo \"âœ“\" || echo \"âœ—\"`\n\nIf all checks pass, run analysis.\nOtherwise, report missing components.\n```\n\n### Error Handling\n\n```markdown\n---\ndescription: Build with error handling\nallowed-tools: Bash(*)\n---\n\nExecute build: BANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/build.sh 2>&1 || echo \"BUILD_FAILED\"`\n\nIf build succeeded:\n  Report success and output location\nIf build failed:\n  Analyze error output\n  Suggest likely causes\n  Provide troubleshooting steps\n```\n\n**Best practices:**\n- Validate early in command\n- Provide helpful error messages\n- Suggest corrective actions\n- Handle edge cases gracefully\n\n---\n\nFor detailed frontmatter field specifications, see `references/frontmatter-reference.md`.\nFor plugin-specific features and patterns, see `references/plugin-features-reference.md`.\nFor command pattern examples, see `examples/` directory.\n",
        "plugins/plugin-dev/skills/command-development/examples/plugin-commands.md": "# Plugin Command Examples\n\nPractical examples of commands designed for Claude Code plugins, demonstrating plugin-specific patterns and features.\n\n## Table of Contents\n\n1. [Simple Plugin Command](#1-simple-plugin-command)\n2. [Script-Based Analysis](#2-script-based-analysis)\n3. [Template-Based Generation](#3-template-based-generation)\n4. [Multi-Script Workflow](#4-multi-script-workflow)\n5. [Configuration-Driven Deployment](#5-configuration-driven-deployment)\n6. [Agent Integration](#6-agent-integration)\n7. [Skill Integration](#7-skill-integration)\n8. [Multi-Component Workflow](#8-multi-component-workflow)\n9. [Validated Input Command](#9-validated-input-command)\n10. [Environment-Aware Command](#10-environment-aware-command)\n\n---\n\n## 1. Simple Plugin Command\n\n**Use case:** Basic command that uses plugin script\n\n**File:** `commands/analyze.md`\n\n```markdown\n---\ndescription: Analyze code quality using plugin tools\nargument-hint: [file-path]\nallowed-tools: Bash(node:*), Read\n---\n\nAnalyze @$1 using plugin's quality checker:\n\nBANG`node ${CLAUDE_PLUGIN_ROOT}/scripts/quality-check.js $1`\n\nReview the analysis output and provide:\n1. Summary of findings\n2. Priority issues to address\n3. Suggested improvements\n4. Code quality score interpretation\n```\n\n**Key features:**\n- Uses `${CLAUDE_PLUGIN_ROOT}` for portable path\n- Combines file reference with script execution\n- Simple single-purpose command\n\n---\n\n## 2. Script-Based Analysis\n\n**Use case:** Run comprehensive analysis using multiple plugin scripts\n\n**File:** `commands/full-audit.md`\n\n```markdown\n---\ndescription: Complete code audit using plugin suite\nargument-hint: [directory]\nallowed-tools: Bash(*)\nmodel: sonnet\n---\n\nRunning complete audit on $1:\n\n**Security scan:**\nBANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/security-scan.sh $1`\n\n**Performance analysis:**\nBANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/perf-analyze.sh $1`\n\n**Best practices check:**\nBANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/best-practices.sh $1`\n\nAnalyze all results and create comprehensive report including:\n- Critical issues requiring immediate attention\n- Performance optimization opportunities\n- Security vulnerabilities and fixes\n- Overall health score and recommendations\n```\n\n**Key features:**\n- Multiple script executions\n- Organized output sections\n- Comprehensive workflow\n- Clear reporting structure\n\n---\n\n## 3. Template-Based Generation\n\n**Use case:** Generate documentation following plugin template\n\n**File:** `commands/gen-api-docs.md`\n\n```markdown\n---\ndescription: Generate API documentation from template\nargument-hint: [api-file]\n---\n\nTemplate structure: @${CLAUDE_PLUGIN_ROOT}/templates/api-documentation.md\n\nAPI implementation: @$1\n\nGenerate complete API documentation following the template format above.\n\nEnsure documentation includes:\n- Endpoint descriptions with HTTP methods\n- Request/response schemas\n- Authentication requirements\n- Error codes and handling\n- Usage examples with curl commands\n- Rate limiting information\n\nFormat output as markdown suitable for README or docs site.\n```\n\n**Key features:**\n- Uses plugin template\n- Combines template with source file\n- Standardized output format\n- Clear documentation structure\n\n---\n\n## 4. Multi-Script Workflow\n\n**Use case:** Orchestrate build, test, and deploy workflow\n\n**File:** `commands/release.md`\n\n```markdown\n---\ndescription: Execute complete release workflow\nargument-hint: [version]\nallowed-tools: Bash(*), Read\n---\n\nExecuting release workflow for version $1:\n\n**Step 1 - Pre-release validation:**\nBANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/pre-release-check.sh $1`\n\n**Step 2 - Build artifacts:**\nBANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/build-release.sh $1`\n\n**Step 3 - Run test suite:**\nBANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/run-tests.sh`\n\n**Step 4 - Package release:**\nBANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/package.sh $1`\n\nReview all step outputs and report:\n1. Any failures or warnings\n2. Build artifacts location\n3. Test results summary\n4. Next steps for deployment\n5. Rollback plan if needed\n```\n\n**Key features:**\n- Multi-step workflow\n- Sequential script execution\n- Clear step numbering\n- Comprehensive reporting\n\n---\n\n## 5. Configuration-Driven Deployment\n\n**Use case:** Deploy using environment-specific plugin configuration\n\n**File:** `commands/deploy.md`\n\n```markdown\n---\ndescription: Deploy application to environment\nargument-hint: [environment]\nallowed-tools: Read, Bash(*)\n---\n\nDeployment configuration for $1: @${CLAUDE_PLUGIN_ROOT}/config/$1-deploy.json\n\nCurrent git state: BANG`git rev-parse --short HEAD`\n\nBuild info: BANG`cat package.json | grep -E '(name|version)'`\n\nExecute deployment to $1 environment using configuration above.\n\nDeployment checklist:\n1. Validate configuration settings\n2. Build application for $1\n3. Run pre-deployment tests\n4. Deploy to target environment\n5. Run smoke tests\n6. Verify deployment success\n7. Update deployment log\n\nReport deployment status and any issues encountered.\n```\n\n**Key features:**\n- Environment-specific configuration\n- Dynamic config file loading\n- Pre-deployment validation\n- Structured checklist\n\n---\n\n## 6. Agent Integration\n\n**Use case:** Command that launches plugin agent for complex task\n\n**File:** `commands/deep-review.md`\n\n```markdown\n---\ndescription: Deep code review using plugin agent\nargument-hint: [file-or-directory]\n---\n\nInitiate comprehensive code review of @$1 using the code-reviewer agent.\n\nThe agent will perform:\n1. **Static analysis** - Check for code smells and anti-patterns\n2. **Security audit** - Identify potential vulnerabilities\n3. **Performance review** - Find optimization opportunities\n4. **Best practices** - Ensure code follows standards\n5. **Documentation check** - Verify adequate documentation\n\nThe agent has access to:\n- Plugin's linting rules: ${CLAUDE_PLUGIN_ROOT}/config/lint-rules.json\n- Security checklist: ${CLAUDE_PLUGIN_ROOT}/checklists/security.md\n- Performance guidelines: ${CLAUDE_PLUGIN_ROOT}/docs/performance.md\n\nNote: This uses the Task tool to launch the plugin's code-reviewer agent for thorough analysis.\n```\n\n**Key features:**\n- Delegates to plugin agent\n- Documents agent capabilities\n- References plugin resources\n- Clear scope definition\n\n---\n\n## 7. Skill Integration\n\n**Use case:** Command that leverages plugin skill for specialized knowledge\n\n**File:** `commands/document-api.md`\n\n```markdown\n---\ndescription: Document API following plugin standards\nargument-hint: [api-file]\n---\n\nAPI source code: @$1\n\nGenerate API documentation following the plugin's API documentation standards.\n\nUse the api-documentation-standards skill to ensure:\n- **OpenAPI compliance** - Follow OpenAPI 3.0 specification\n- **Consistent formatting** - Use plugin's documentation style\n- **Complete coverage** - Document all endpoints and schemas\n- **Example quality** - Provide realistic usage examples\n- **Error documentation** - Cover all error scenarios\n\nThe skill provides:\n- Standard documentation templates\n- API documentation best practices\n- Common patterns for this codebase\n- Quality validation criteria\n\nGenerate production-ready API documentation.\n```\n\n**Key features:**\n- Invokes plugin skill by name\n- Documents skill purpose\n- Clear expectations\n- Leverages skill knowledge\n\n---\n\n## 8. Multi-Component Workflow\n\n**Use case:** Complex workflow using agents, skills, and scripts\n\n**File:** `commands/complete-review.md`\n\n```markdown\n---\ndescription: Comprehensive review using all plugin components\nargument-hint: [file-path]\nallowed-tools: Bash(node:*), Read\n---\n\nTarget file: @$1\n\nExecute comprehensive review workflow:\n\n**Phase 1: Automated Analysis**\nRun plugin analyzer: BANG`node ${CLAUDE_PLUGIN_ROOT}/scripts/analyze.js $1`\n\n**Phase 2: Deep Review (Agent)**\nLaunch the code-quality-reviewer agent for detailed analysis.\nAgent will examine:\n- Code structure and organization\n- Error handling patterns\n- Testing coverage\n- Documentation quality\n\n**Phase 3: Standards Check (Skill)**\nUse the coding-standards skill to validate:\n- Naming conventions\n- Code formatting\n- Best practices adherence\n- Framework-specific patterns\n\n**Phase 4: Report Generation**\nTemplate: @${CLAUDE_PLUGIN_ROOT}/templates/review-report.md\n\nCompile all findings into comprehensive report following template.\n\n**Phase 5: Recommendations**\nGenerate prioritized action items:\n1. Critical issues (must fix)\n2. Important improvements (should fix)\n3. Nice-to-have enhancements (could fix)\n\nInclude specific file locations and suggested changes for each item.\n```\n\n**Key features:**\n- Multi-phase workflow\n- Combines scripts, agents, skills\n- Template-based reporting\n- Prioritized outputs\n\n---\n\n## 9. Validated Input Command\n\n**Use case:** Command with input validation and error handling\n\n**File:** `commands/build-env.md`\n\n```markdown\n---\ndescription: Build for specific environment with validation\nargument-hint: [environment]\nallowed-tools: Bash(*)\n---\n\nValidate environment argument: BANG`echo \"$1\" | grep -E \"^(dev|staging|prod)$\" && echo \"VALID\" || echo \"INVALID\"`\n\nCheck build script exists: BANG`test -x ${CLAUDE_PLUGIN_ROOT}/scripts/build.sh && echo \"EXISTS\" || echo \"MISSING\"`\n\nVerify configuration available: BANG`test -f ${CLAUDE_PLUGIN_ROOT}/config/$1.json && echo \"FOUND\" || echo \"NOT_FOUND\"`\n\nIf all validations pass:\n\n**Configuration:** @${CLAUDE_PLUGIN_ROOT}/config/$1.json\n\n**Execute build:** BANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/build.sh $1 2>&1`\n\n**Validation results:** BANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/validate-build.sh $1 2>&1`\n\nReport build status and any issues.\n\nIf validations fail:\n- Explain which validation failed\n- Provide expected values/locations\n- Suggest corrective actions\n- Document troubleshooting steps\n```\n\n**Key features:**\n- Input validation\n- Resource existence checks\n- Error handling\n- Helpful error messages\n- Graceful failure handling\n\n---\n\n## 10. Environment-Aware Command\n\n**Use case:** Command that adapts behavior based on environment\n\n**File:** `commands/run-checks.md`\n\n```markdown\n---\ndescription: Run environment-appropriate checks\nargument-hint: [environment]\nallowed-tools: Bash(*), Read\n---\n\nEnvironment: $1\n\nLoad environment configuration: @${CLAUDE_PLUGIN_ROOT}/config/$1-checks.json\n\nDetermine check level: BANG`echo \"$1\" | grep -E \"^prod$\" && echo \"FULL\" || echo \"BASIC\"`\n\n**For production environment:**\n- Full test suite: BANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/test-full.sh`\n- Security scan: BANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/security-scan.sh`\n- Performance audit: BANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/perf-check.sh`\n- Compliance check: BANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/compliance.sh`\n\n**For non-production environments:**\n- Basic tests: BANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/test-basic.sh`\n- Quick lint: BANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/lint.sh`\n\nAnalyze results based on environment requirements:\n\n**Production:** All checks must pass with zero critical issues\n**Staging:** No critical issues, warnings acceptable\n**Development:** Focus on blocking issues only\n\nReport status and recommend proceed/block decision.\n```\n\n**Key features:**\n- Environment-aware logic\n- Conditional execution\n- Different validation levels\n- Appropriate reporting per environment\n\n---\n\n## Common Patterns Summary\n\n### Pattern: Plugin Script Execution\n```markdown\nBANG`node ${CLAUDE_PLUGIN_ROOT}/scripts/script-name.js $1`\n```\nUse for: Running plugin-provided Node.js scripts\n\n### Pattern: Plugin Configuration Loading\n```markdown\n@${CLAUDE_PLUGIN_ROOT}/config/config-name.json\n```\nUse for: Loading plugin configuration files\n\n### Pattern: Plugin Template Usage\n```markdown\n@${CLAUDE_PLUGIN_ROOT}/templates/template-name.md\n```\nUse for: Using plugin templates for generation\n\n### Pattern: Agent Invocation\n```markdown\nLaunch the [agent-name] agent for [task description].\n```\nUse for: Delegating complex tasks to plugin agents\n\n### Pattern: Skill Reference\n```markdown\nUse the [skill-name] skill to ensure [requirements].\n```\nUse for: Leveraging plugin skills for specialized knowledge\n\n### Pattern: Input Validation\n```markdown\nValidate input: BANG`echo \"$1\" | grep -E \"^pattern$\" && echo \"OK\" || echo \"ERROR\"`\n```\nUse for: Validating command arguments\n\n### Pattern: Resource Validation\n```markdown\nCheck exists: BANG`test -f ${CLAUDE_PLUGIN_ROOT}/path/file && echo \"YES\" || echo \"NO\"`\n```\nUse for: Verifying required plugin files exist\n\n---\n\n## Development Tips\n\n### Testing Plugin Commands\n\n1. **Test with plugin installed:**\n   ```bash\n   cd /path/to/plugin\n   claude /command-name args\n   ```\n\n2. **Verify ${CLAUDE_PLUGIN_ROOT} expansion:**\n   ```bash\n   # Add debug output to command\n   BANG`echo \"Plugin root: ${CLAUDE_PLUGIN_ROOT}\"`\n   ```\n\n3. **Test across different working directories:**\n   ```bash\n   cd /tmp && claude /command-name\n   cd /other/project && claude /command-name\n   ```\n\n4. **Validate resource availability:**\n   ```bash\n   # Check all plugin resources exist\n   BANG`ls -la ${CLAUDE_PLUGIN_ROOT}/scripts/`\n   BANG`ls -la ${CLAUDE_PLUGIN_ROOT}/config/`\n   ```\n\n### Common Mistakes to Avoid\n\n1. **Using relative paths instead of ${CLAUDE_PLUGIN_ROOT}:**\n   ```markdown\n   # Wrong\n   BANG`node ./scripts/analyze.js`\n\n   # Correct\n   BANG`node ${CLAUDE_PLUGIN_ROOT}/scripts/analyze.js`\n   ```\n\n2. **Forgetting to allow required tools:**\n   ```markdown\n   # Missing allowed-tools\n   BANG`bash script.sh`  # Will fail without Bash permission\n\n   # Correct\n   ---\n   allowed-tools: Bash(*)\n   ---\n   BANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/script.sh`\n   ```\n\n3. **Not validating inputs:**\n   ```markdown\n   # Risky - no validation\n   Deploy to $1 environment\n\n   # Better - with validation\n   Validate: BANG`echo \"$1\" | grep -E \"^(dev|staging|prod)$\" || echo \"INVALID\"`\n   Deploy to $1 environment (if valid)\n   ```\n\n4. **Hardcoding plugin paths:**\n   ```markdown\n   # Wrong - breaks on different installations\n   @/home/user/.claude/plugins/my-plugin/config.json\n\n   # Correct - works everywhere\n   @${CLAUDE_PLUGIN_ROOT}/config.json\n   ```\n\n---\n\nFor detailed plugin-specific features, see `references/plugin-features-reference.md`.\nFor general command development, see main `SKILL.md`.\n",
        "plugins/plugin-dev/skills/command-development/examples/simple-commands.md": "# Simple Command Examples\n\nBasic slash command patterns for common use cases.\n\n**Important:** All examples below are written as instructions FOR Claude (agent consumption), not messages TO users. Commands tell Claude what to do, not tell users what will happen.\n\n## Example 1: Code Review Command\n\n**File:** `.claude/commands/review.md`\n\n```markdown\n---\ndescription: Review code for quality and issues\nallowed-tools: Read, Bash(git:*)\n---\n\nReview the code in this repository for:\n\n1. **Code Quality:**\n   - Readability and maintainability\n   - Consistent style and formatting\n   - Appropriate abstraction levels\n\n2. **Potential Issues:**\n   - Logic errors or bugs\n   - Edge cases not handled\n   - Performance concerns\n\n3. **Best Practices:**\n   - Design patterns used correctly\n   - Error handling present\n   - Documentation adequate\n\nProvide specific feedback with file and line references.\n```\n\n**Usage:**\n```\n> /review\n```\n\n---\n\n## Example 2: Security Review Command\n\n**File:** `.claude/commands/security-review.md`\n\n```markdown\n---\ndescription: Review code for security vulnerabilities\nallowed-tools: Read, Grep\nmodel: sonnet\n---\n\nPerform comprehensive security review checking for:\n\n**Common Vulnerabilities:**\n- SQL injection risks\n- Cross-site scripting (XSS)\n- Authentication/authorization issues\n- Insecure data handling\n- Hardcoded secrets or credentials\n\n**Security Best Practices:**\n- Input validation present\n- Output encoding correct\n- Secure defaults used\n- Error messages safe\n- Logging appropriate (no sensitive data)\n\nFor each issue found:\n- File and line number\n- Severity (Critical/High/Medium/Low)\n- Description of vulnerability\n- Recommended fix\n\nPrioritize issues by severity.\n```\n\n**Usage:**\n```\n> /security-review\n```\n\n---\n\n## Example 3: Test Command with File Argument\n\n**File:** `.claude/commands/test-file.md`\n\n```markdown\n---\ndescription: Run tests for specific file\nargument-hint: [test-file]\nallowed-tools: Bash(npm:*), Bash(jest:*)\n---\n\nRun tests for $1:\n\nTest execution: BANG`npm test $1`\n\nAnalyze results:\n- Tests passed/failed\n- Code coverage\n- Performance issues\n- Flaky tests\n\nIf failures found, suggest fixes based on error messages.\n```\n\n**Usage:**\n```\n> /test-file src/utils/helpers.test.ts\n```\n\n---\n\n## Example 4: Documentation Generator\n\n**File:** `.claude/commands/document.md`\n\n```markdown\n---\ndescription: Generate documentation for file\nargument-hint: [source-file]\n---\n\nGenerate comprehensive documentation for @$1\n\nInclude:\n\n**Overview:**\n- Purpose and responsibility\n- Main functionality\n- Dependencies\n\n**API Documentation:**\n- Function/method signatures\n- Parameter descriptions with types\n- Return values with types\n- Exceptions/errors thrown\n\n**Usage Examples:**\n- Basic usage\n- Common patterns\n- Edge cases\n\n**Implementation Notes:**\n- Algorithm complexity\n- Performance considerations\n- Known limitations\n\nFormat as Markdown suitable for project documentation.\n```\n\n**Usage:**\n```\n> /document src/api/users.ts\n```\n\n---\n\n## Example 5: Git Status Summary\n\n**File:** `.claude/commands/git-status.md`\n\n```markdown\n---\ndescription: Summarize Git repository status\nallowed-tools: Bash(git:*)\n---\n\nRepository Status Summary:\n\n**Current Branch:** BANG`git branch --show-current`\n\n**Status:** BANG`git status --short`\n\n**Recent Commits:** BANG`git log --oneline -5`\n\n**Remote Status:** BANG`git fetch && git status -sb`\n\nProvide:\n- Summary of changes\n- Suggested next actions\n- Any warnings or issues\n```\n\n**Usage:**\n```\n> /git-status\n```\n\n---\n\n## Example 6: Deployment Command\n\n**File:** `.claude/commands/deploy.md`\n\n```markdown\n---\ndescription: Deploy to specified environment\nargument-hint: [environment] [version]\nallowed-tools: Bash(kubectl:*), Read\n---\n\nDeploy to $1 environment using version $2\n\n**Pre-deployment Checks:**\n1. Verify $1 configuration exists\n2. Check version $2 is valid\n3. Verify cluster accessibility: BANG`kubectl cluster-info`\n\n**Deployment Steps:**\n1. Update deployment manifest with version $2\n2. Apply configuration to $1\n3. Monitor rollout status\n4. Verify pod health\n5. Run smoke tests\n\n**Rollback Plan:**\nDocument current version for rollback if issues occur.\n\nProceed with deployment? (yes/no)\n```\n\n**Usage:**\n```\n> /deploy staging v1.2.3\n```\n\n---\n\n## Example 7: Comparison Command\n\n**File:** `.claude/commands/compare-files.md`\n\n```markdown\n---\ndescription: Compare two files\nargument-hint: [file1] [file2]\n---\n\nCompare @$1 with @$2\n\n**Analysis:**\n\n1. **Differences:**\n   - Lines added\n   - Lines removed\n   - Lines modified\n\n2. **Functional Changes:**\n   - Breaking changes\n   - New features\n   - Bug fixes\n   - Refactoring\n\n3. **Impact:**\n   - Affected components\n   - Required updates elsewhere\n   - Migration requirements\n\n4. **Recommendations:**\n   - Code review focus areas\n   - Testing requirements\n   - Documentation updates needed\n\nPresent as structured comparison report.\n```\n\n**Usage:**\n```\n> /compare-files src/old-api.ts src/new-api.ts\n```\n\n---\n\n## Example 8: Quick Fix Command\n\n**File:** `.claude/commands/quick-fix.md`\n\n```markdown\n---\ndescription: Quick fix for common issues\nargument-hint: [issue-description]\nmodel: haiku\n---\n\nQuickly fix: $ARGUMENTS\n\n**Approach:**\n1. Identify the issue\n2. Find relevant code\n3. Propose fix\n4. Explain solution\n\nFocus on:\n- Simple, direct solution\n- Minimal changes\n- Following existing patterns\n- No breaking changes\n\nProvide code changes with file paths and line numbers.\n```\n\n**Usage:**\n```\n> /quick-fix button not responding to clicks\n> /quick-fix typo in error message\n```\n\n---\n\n## Example 9: Research Command\n\n**File:** `.claude/commands/research.md`\n\n```markdown\n---\ndescription: Research best practices for topic\nargument-hint: [topic]\nmodel: sonnet\n---\n\nResearch best practices for: $ARGUMENTS\n\n**Coverage:**\n\n1. **Current State:**\n   - How we currently handle this\n   - Existing implementations\n\n2. **Industry Standards:**\n   - Common patterns\n   - Recommended approaches\n   - Tools and libraries\n\n3. **Comparison:**\n   - Our approach vs standards\n   - Gaps or improvements needed\n   - Migration considerations\n\n4. **Recommendations:**\n   - Concrete action items\n   - Priority and effort estimates\n   - Resources for implementation\n\nProvide actionable guidance based on research.\n```\n\n**Usage:**\n```\n> /research error handling in async operations\n> /research API authentication patterns\n```\n\n---\n\n## Example 10: Explain Code Command\n\n**File:** `.claude/commands/explain.md`\n\n```markdown\n---\ndescription: Explain how code works\nargument-hint: [file-or-function]\n---\n\nExplain @$1 in detail\n\n**Explanation Structure:**\n\n1. **Overview:**\n   - What it does\n   - Why it exists\n   - How it fits in system\n\n2. **Step-by-Step:**\n   - Line-by-line walkthrough\n   - Key algorithms or logic\n   - Important details\n\n3. **Inputs and Outputs:**\n   - Parameters and types\n   - Return values\n   - Side effects\n\n4. **Edge Cases:**\n   - Error handling\n   - Special cases\n   - Limitations\n\n5. **Usage Examples:**\n   - How to call it\n   - Common patterns\n   - Integration points\n\nExplain at level appropriate for junior engineer.\n```\n\n**Usage:**\n```\n> /explain src/utils/cache.ts\n> /explain AuthService.login\n```\n\n---\n\n## Key Patterns\n\n### Pattern 1: Read-Only Analysis\n\n```markdown\n---\nallowed-tools: Read, Grep\n---\n\nAnalyze but don't modify...\n```\n\n**Use for:** Code review, documentation, analysis\n\n### Pattern 2: Git Operations\n\n```markdown\n---\nallowed-tools: Bash(git:*)\n---\n\nBANG`git status`\nAnalyze and suggest...\n```\n\n**Use for:** Repository status, commit analysis\n\n### Pattern 3: Single Argument\n\n```markdown\n---\nargument-hint: [target]\n---\n\nProcess $1...\n```\n\n**Use for:** File operations, targeted actions\n\n### Pattern 4: Multiple Arguments\n\n```markdown\n---\nargument-hint: [source] [target] [options]\n---\n\nProcess $1 to $2 with $3...\n```\n\n**Use for:** Workflows, deployments, comparisons\n\n### Pattern 5: Fast Execution\n\n```markdown\n---\nmodel: haiku\n---\n\nQuick simple task...\n```\n\n**Use for:** Simple, repetitive commands\n\n### Pattern 6: File Comparison\n\n```markdown\nCompare @$1 with @$2...\n```\n\n**Use for:** Diff analysis, migration planning\n\n### Pattern 7: Context Gathering\n\n```markdown\n---\nallowed-tools: Bash(git:*), Read\n---\n\nContext: BANG`git status`\nFiles: @file1 @file2\n\nAnalyze...\n```\n\n**Use for:** Informed decision making\n\n## Tips for Writing Simple Commands\n\n1. **Start basic:** Single responsibility, clear purpose\n2. **Add complexity gradually:** Start without frontmatter\n3. **Test incrementally:** Verify each feature works\n4. **Use descriptive names:** Command name should indicate purpose\n5. **Document arguments:** Always use argument-hint\n6. **Provide examples:** Show usage in comments\n7. **Handle errors:** Consider missing arguments or files\n",
        "plugins/plugin-dev/skills/command-development/references/advanced-workflows.md": "# Advanced Workflow Patterns\n\nMulti-step command sequences and composition patterns for complex workflows.\n\n## Overview\n\nAdvanced workflows combine multiple commands, coordinate state across invocations, and create sophisticated automation sequences. These patterns enable building complex functionality from simple command building blocks.\n\n## Multi-Step Command Patterns\n\n### Sequential Workflow Command\n\nCommands that guide users through multi-step processes:\n\n```markdown\n---\ndescription: Complete PR review workflow\nargument-hint: [pr-number]\nallowed-tools: Bash(gh:*), Read, Grep\n---\n\n# PR Review Workflow for #$1\n\n## Step 1: Fetch PR Details\nBANG`gh pr view $1 --json title,body,author,files`\n\n## Step 2: Review Files\nFiles changed: BANG`gh pr diff $1 --name-only`\n\nFor each file:\n- Check code quality\n- Verify tests exist\n- Review documentation\n\n## Step 3: Run Checks\nTest status: BANG`gh pr checks $1`\n\nVerify:\n- All tests passing\n- No merge conflicts\n- CI/CD successful\n\n## Step 4: Provide Feedback\n\nSummarize:\n- Issues found (critical/minor)\n- Suggestions for improvement\n- Approval recommendation\n\nWould you like to:\n1. Approve PR\n2. Request changes\n3. Leave comments only\n\nReply with your choice and I'll help complete the action.\n```\n\n**Key features:**\n- Numbered steps for clarity\n- Bash execution for context\n- Decision points for user input\n- Next action suggestions\n\n### State-Carrying Workflow\n\nCommands that maintain state between invocations:\n\n```markdown\n---\ndescription: Initialize deployment workflow\nallowed-tools: Write, Bash(git:*)\n---\n\n# Initialize Deployment\n\nCreating deployment tracking file...\n\nCurrent branch: BANG`git branch --show-current`\nLatest commit: BANG`git log -1 --format=%H`\n\nDeployment state saved to `.claude/deployment-state.local.md`:\n\n\\`\\`\\`markdown\n---\ninitialized: true\nbranch: $(git branch --show-current)\ncommit: $(git log -1 --format=%H)\ntimestamp: $(date -u +%Y-%m-%dT%H:%M:%SZ)\nstatus: initialized\n---\n\n# Deployment Tracking\n\nBranch: $(git branch --show-current)\nStarted: $(date)\n\nNext steps:\n1. Run tests: /deploy-test\n2. Build: /deploy-build\n3. Deploy: /deploy-execute\n\\`\\`\\`\n\nState saved. Run `/deploy-test` to continue.\n```\n\n**Next command** (`/deploy-test`):\n```markdown\n---\ndescription: Run deployment tests\nallowed-tools: Read, Bash(npm:*)\n---\n\nReading deployment state from `.claude/deployment-state.local.md`...\n\nRunning tests: BANG`npm test`\n\nUpdating state to 'tested'...\n\nTests complete. Run `/deploy-build` to continue.\n```\n\n**Pattern benefits:**\n- Persistent state across commands\n- Clear workflow progression\n- Safety checkpoints\n- Resume capability\n\n### Conditional Workflow Branching\n\nCommands that adapt based on conditions:\n\n```markdown\n---\ndescription: Smart deployment workflow\nargument-hint: [environment]\nallowed-tools: Bash(git:*), Bash(npm:*), Read\n---\n\n# Deploy to $1\n\n## Pre-flight Checks\n\nBranch: BANG`git branch --show-current`\nStatus: BANG`git status --short`\n\n**Checking conditions:**\n\n1. Branch status:\n   - If main/master: Require approval\n   - If feature branch: Warning about target\n   - If hotfix: Fast-track process\n\n2. Tests:\n   BANG`npm test`\n   - If tests fail: STOP - fix tests first\n   - If tests pass: Continue\n\n3. Environment:\n   - If $1 = 'production': Extra validation\n   - If $1 = 'staging': Standard process\n   - If $1 = 'dev': Minimal checks\n\n**Workflow decision:**\nBased on above, proceeding with: [determined workflow]\n\n[Conditional steps based on environment and status]\n\nReady to deploy? (yes/no)\n```\n\n## Command Composition Patterns\n\n### Command Chaining\n\nCommands designed to work together:\n\n```markdown\n---\ndescription: Prepare for code review\n---\n\n# Prepare Code Review\n\nRunning preparation sequence:\n\n1. Format code: /format-code\n2. Run linter: /lint-code\n3. Run tests: /test-all\n4. Generate coverage: /coverage-report\n5. Create review summary: /review-summary\n\nThis is a meta-command. After completing each step above,\nI'll compile results and prepare comprehensive review materials.\n\nStarting sequence...\n```\n\n**Individual commands** are simple:\n- `/format-code` - Just formats\n- `/lint-code` - Just lints\n- `/test-all` - Just tests\n\n**Composition command** orchestrates them.\n\n### Pipeline Pattern\n\nCommands that process output from previous commands:\n\n```markdown\n---\ndescription: Analyze test failures\n---\n\n# Analyze Test Failures\n\n## Step 1: Get test results\n(Run /test-all first if not done)\n\nReading test output...\n\n## Step 2: Categorize failures\n- Flaky tests (random failures)\n- Consistent failures\n- New failures vs existing\n\n## Step 3: Prioritize\nRank by:\n- Impact (critical path vs edge case)\n- Frequency (always fails vs sometimes)\n- Effort (quick fix vs major work)\n\n## Step 4: Generate fix plan\nFor each failure:\n- Root cause hypothesis\n- Suggested fix approach\n- Estimated effort\n\nWould you like me to:\n1. Fix highest priority failure\n2. Generate detailed fix plans for all\n3. Create GitHub issues for each\n```\n\n### Parallel Execution Pattern\n\nCommands that coordinate multiple simultaneous operations:\n\n```markdown\n---\ndescription: Run comprehensive validation\nallowed-tools: Bash(*), Read\n---\n\n# Comprehensive Validation\n\nRunning validations in parallel...\n\nStarting:\n- Code quality checks\n- Security scanning\n- Dependency audit\n- Performance profiling\n\nThis will take 2-3 minutes. I'll monitor all processes\nand report when complete.\n\n[Poll each process and report progress]\n\nAll validations complete. Summary:\n- Quality: PASS (0 issues)\n- Security: WARN (2 minor issues)\n- Dependencies: PASS\n- Performance: PASS (baseline met)\n\nDetails:\n[Collated results from all checks]\n```\n\n## Workflow State Management\n\n### Using .local.md Files\n\nStore workflow state in plugin-specific files:\n\n```markdown\n.claude/plugin-name-workflow.local.md:\n\n---\nworkflow: deployment\nstage: testing\nstarted: 2025-01-15T10:30:00Z\nenvironment: staging\nbranch: feature/new-api\ncommit: abc123def\ntests_passed: false\nbuild_complete: false\n---\n\n# Deployment Workflow State\n\nCurrent stage: Testing\nStarted: 2025-01-15 10:30 UTC\n\nCompleted steps:\n- âœ… Validation\n- âœ… Branch check\n- â³ Testing (in progress)\n\nPending steps:\n- Build\n- Deploy\n- Smoke tests\n```\n\n**Reading state in commands:**\n\n```markdown\n---\ndescription: Continue deployment workflow\nallowed-tools: Read, Write\n---\n\nReading workflow state from .claude/plugin-name-workflow.local.md...\n\nCurrent stage: @.claude/plugin-name-workflow.local.md\n\n[Parse YAML frontmatter to determine next step]\n\nNext action based on state: [determined action]\n```\n\n### Workflow Recovery\n\nHandle interrupted workflows:\n\n```markdown\n---\ndescription: Resume deployment workflow\nallowed-tools: Read\n---\n\n# Resume Deployment\n\nChecking for interrupted workflow...\n\nState file: @.claude/plugin-name-workflow.local.md\n\n**Workflow found:**\n- Started: [timestamp]\n- Environment: [env]\n- Last completed: [step]\n\n**Recovery options:**\n1. Resume from last step\n2. Restart from beginning\n3. Abort and clean up\n\nWhich would you like? (1/2/3)\n```\n\n## Workflow Coordination Patterns\n\n### Cross-Command Communication\n\nCommands that signal each other:\n\n```markdown\n---\ndescription: Mark feature complete\nallowed-tools: Write\n---\n\n# Mark Feature Complete\n\nWriting completion marker...\n\nCreating: .claude/feature-complete.flag\n\nThis signals other commands that feature is ready for:\n- Integration testing (/integration-test will auto-detect)\n- Documentation generation (/docs-generate will include)\n- Release notes (/release-notes will add)\n\nFeature marked complete.\n```\n\n**Other commands check for flag:**\n\n```markdown\n---\ndescription: Generate release notes\nallowed-tools: Read, Bash(git:*)\n---\n\nChecking for completed features...\n\nif [ -f .claude/feature-complete.flag ]; then\n  Feature ready for release notes\nfi\n\n[Include in release notes]\n```\n\n### Workflow Locking\n\nPrevent concurrent workflow execution:\n\n```markdown\n---\ndescription: Start deployment\nallowed-tools: Read, Write, Bash\n---\n\n# Start Deployment\n\nChecking for active deployments...\n\nif [ -f .claude/deployment.lock ]; then\n  ERROR: Deployment already in progress\n  Started: [timestamp from lock file]\n\n  Cannot start concurrent deployment.\n  Wait for completion or run /deployment-abort\n\n  Exit.\nfi\n\nCreating deployment lock...\n\nDeployment started. Lock created.\n[Proceed with deployment]\n```\n\n**Lock cleanup:**\n\n```markdown\n---\ndescription: Complete deployment\nallowed-tools: Write, Bash\n---\n\nDeployment complete.\n\nRemoving deployment lock...\nrm .claude/deployment.lock\n\nReady for next deployment.\n```\n\n## Advanced Argument Handling\n\n### Optional Arguments with Defaults\n\n```markdown\n---\ndescription: Deploy with optional version\nargument-hint: [environment] [version]\n---\n\nEnvironment: ${1:-staging}\nVersion: ${2:-latest}\n\nDeploying ${2:-latest} to ${1:-staging}...\n\nNote: Using defaults for missing arguments:\n- Environment defaults to 'staging'\n- Version defaults to 'latest'\n```\n\n### Argument Validation\n\n```markdown\n---\ndescription: Deploy to validated environment\nargument-hint: [environment]\n---\n\nEnvironment: $1\n\nValidating environment...\n\nvalid_envs=\"dev staging production\"\nif ! echo \"$valid_envs\" | grep -w \"$1\" > /dev/null; then\n  ERROR: Invalid environment '$1'\n  Valid options: dev, staging, production\n  Exit.\nfi\n\nEnvironment validated. Proceeding...\n```\n\n### Argument Transformation\n\n```markdown\n---\ndescription: Deploy with shorthand\nargument-hint: [env-shorthand]\n---\n\nInput: $1\n\nExpanding shorthand:\n- d/dev â†’ development\n- s/stg â†’ staging\n- p/prod â†’ production\n\ncase \"$1\" in\n  d|dev) ENV=\"development\";;\n  s|stg) ENV=\"staging\";;\n  p|prod) ENV=\"production\";;\n  *) ENV=\"$1\";;\nesac\n\nDeploying to: $ENV\n```\n\n## Error Handling in Workflows\n\n### Graceful Failure\n\n```markdown\n---\ndescription: Resilient deployment workflow\n---\n\n# Deployment Workflow\n\nRunning steps with error handling...\n\n## Step 1: Tests\nBANG`npm test`\n\nif [ $? -ne 0 ]; then\n  ERROR: Tests failed\n\n  Options:\n  1. Fix tests and retry\n  2. Skip tests (NOT recommended)\n  3. Abort deployment\n\n  What would you like to do?\n\n  [Wait for user input before continuing]\nfi\n\n## Step 2: Build\n[Continue only if Step 1 succeeded]\n```\n\n### Rollback on Failure\n\n```markdown\n---\ndescription: Deployment with rollback\n---\n\n# Deploy with Rollback\n\nSaving current state for rollback...\nPrevious version: BANG`current-version.sh`\n\nDeploying new version...\n\nBANG`deploy.sh`\n\nif [ $? -ne 0 ]; then\n  DEPLOYMENT FAILED\n\n  Initiating automatic rollback...\n  BANG`rollback.sh`\n\n  Rolled back to previous version.\n  Check logs for failure details.\nfi\n\nDeployment complete.\n```\n\n### Checkpoint Recovery\n\n```markdown\n---\ndescription: Workflow with checkpoints\n---\n\n# Multi-Stage Deployment\n\n## Checkpoint 1: Validation\nBANG`validate.sh`\necho \"checkpoint:validation\" >> .claude/deployment-checkpoints.log\n\n## Checkpoint 2: Build\nBANG`build.sh`\necho \"checkpoint:build\" >> .claude/deployment-checkpoints.log\n\n## Checkpoint 3: Deploy\nBANG`deploy.sh`\necho \"checkpoint:deploy\" >> .claude/deployment-checkpoints.log\n\nIf any step fails, resume with:\n/deployment-resume [last-successful-checkpoint]\n```\n\n## Best Practices\n\n### Workflow Design\n\n1. **Clear progression**: Number steps, show current position\n2. **Explicit state**: Don't rely on implicit state\n3. **User control**: Provide decision points\n4. **Error recovery**: Handle failures gracefully\n5. **Progress indication**: Show what's done, what's pending\n\n### Command Composition\n\n1. **Single responsibility**: Each command does one thing well\n2. **Composable design**: Commands work together easily\n3. **Standard interfaces**: Consistent input/output formats\n4. **Loose coupling**: Commands don't depend on each other's internals\n\n### State Management\n\n1. **Persistent state**: Use .local.md files\n2. **Atomic updates**: Write complete state files atomically\n3. **State validation**: Check state file format/completeness\n4. **Cleanup**: Remove stale state files\n5. **Documentation**: Document state file formats\n\n### Error Handling\n\n1. **Fail fast**: Detect errors early\n2. **Clear messages**: Explain what went wrong\n3. **Recovery options**: Provide clear next steps\n4. **State preservation**: Keep state for recovery\n5. **Rollback capability**: Support undoing changes\n\n## Example: Complete Deployment Workflow\n\n### Initialize Command\n\n```markdown\n---\ndescription: Initialize deployment\nargument-hint: [environment]\nallowed-tools: Write, Bash(git:*)\n---\n\n# Initialize Deployment to $1\n\nCreating workflow state...\n\n\\`\\`\\`yaml\n---\nworkflow: deployment\nenvironment: $1\nbranch: BANG`git branch --show-current`\ncommit: BANG`git rev-parse HEAD`\nstage: initialized\ntimestamp: BANG`date -u +%Y-%m-%dT%H:%M:%SZ`\n---\n\\`\\`\\`\n\nWritten to .claude/deployment-state.local.md\n\nNext: Run /deployment-validate\n```\n\n### Validation Command\n\n```markdown\n---\ndescription: Validate deployment\nallowed-tools: Read, Bash\n---\n\nReading state: @.claude/deployment-state.local.md\n\nRunning validation...\n- Branch check: PASS\n- Tests: PASS\n- Build: PASS\n\nUpdating state to 'validated'...\n\nNext: Run /deployment-execute\n```\n\n### Execution Command\n\n```markdown\n---\ndescription: Execute deployment\nallowed-tools: Read, Bash, Write\n---\n\nReading state: @.claude/deployment-state.local.md\n\nExecuting deployment to [environment]...\n\nBANG`deploy.sh [environment]`\n\nDeployment complete.\nUpdating state to 'completed'...\n\nCleanup: /deployment-cleanup\n```\n\n### Cleanup Command\n\n```markdown\n---\ndescription: Clean up deployment\nallowed-tools: Bash\n---\n\nRemoving deployment state...\nrm .claude/deployment-state.local.md\n\nDeployment workflow complete.\n```\n\nThis complete workflow demonstrates state management, sequential execution, error handling, and clean separation of concerns across multiple commands.\n",
        "plugins/plugin-dev/skills/command-development/references/documentation-patterns.md": "# Command Documentation Patterns\n\nStrategies for creating self-documenting, maintainable commands with excellent user experience.\n\n## Overview\n\nWell-documented commands are easier to use, maintain, and distribute. Documentation should be embedded in the command itself, making it immediately accessible to users and maintainers.\n\n## Self-Documenting Command Structure\n\n### Complete Command Template\n\n```markdown\n---\ndescription: Clear, actionable description under 60 chars\nargument-hint: [arg1] [arg2] [optional-arg]\nallowed-tools: Read, Bash(git:*)\nmodel: sonnet\n---\n\n<!--\nCOMMAND: command-name\nVERSION: 1.0.0\nAUTHOR: Team Name\nLAST UPDATED: 2025-01-15\n\nPURPOSE:\nDetailed explanation of what this command does and why it exists.\n\nUSAGE:\n  /command-name arg1 arg2\n\nARGUMENTS:\n  arg1: Description of first argument (required)\n  arg2: Description of second argument (optional, defaults to X)\n\nEXAMPLES:\n  /command-name feature-branch main\n    â†’ Compares feature-branch with main\n\n  /command-name my-branch\n    â†’ Compares my-branch with current branch\n\nREQUIREMENTS:\n  - Git repository\n  - Branch must exist\n  - Permissions to read repository\n\nRELATED COMMANDS:\n  /other-command - Related functionality\n  /another-command - Alternative approach\n\nTROUBLESHOOTING:\n  - If branch not found: Check branch name spelling\n  - If permission denied: Check repository access\n\nCHANGELOG:\n  v1.0.0 (2025-01-15): Initial release\n  v0.9.0 (2025-01-10): Beta version\n-->\n\n# Command Implementation\n\n[Command prompt content here...]\n\n[Explain what will happen...]\n\n[Guide user through steps...]\n\n[Provide clear output...]\n```\n\n### Documentation Comment Sections\n\n**PURPOSE**: Why the command exists\n- Problem it solves\n- Use cases\n- When to use vs when not to use\n\n**USAGE**: Basic syntax\n- Command invocation pattern\n- Required vs optional arguments\n- Default values\n\n**ARGUMENTS**: Detailed argument documentation\n- Each argument described\n- Type information\n- Valid values/ranges\n- Defaults\n\n**EXAMPLES**: Concrete usage examples\n- Common use cases\n- Edge cases\n- Expected outputs\n\n**REQUIREMENTS**: Prerequisites\n- Dependencies\n- Permissions\n- Environmental setup\n\n**RELATED COMMANDS**: Connections\n- Similar commands\n- Complementary commands\n- Alternative approaches\n\n**TROUBLESHOOTING**: Common issues\n- Known problems\n- Solutions\n- Workarounds\n\n**CHANGELOG**: Version history\n- What changed when\n- Breaking changes highlighted\n- Migration guidance\n\n## In-Line Documentation Patterns\n\n### Commented Sections\n\n```markdown\n---\ndescription: Complex multi-step command\n---\n\n<!-- SECTION 1: VALIDATION -->\n<!-- This section checks prerequisites before proceeding -->\n\nChecking prerequisites...\n- Git repository: BANG`git rev-parse --git-dir 2>/dev/null`\n- Branch exists: [validation logic]\n\n<!-- SECTION 2: ANALYSIS -->\n<!-- Analyzes the differences between branches -->\n\nAnalyzing differences between $1 and $2...\n[Analysis logic...]\n\n<!-- SECTION 3: RECOMMENDATIONS -->\n<!-- Provides actionable recommendations -->\n\nBased on analysis, recommend:\n[Recommendations...]\n\n<!-- END: Next steps for user -->\n```\n\n### Inline Explanations\n\n```markdown\n---\ndescription: Deployment command with inline docs\n---\n\n# Deploy to $1\n\n## Pre-flight Checks\n\n<!-- We check branch status to prevent deploying from wrong branch -->\nCurrent branch: BANG`git branch --show-current`\n\n<!-- Production deploys must come from main/master -->\nif [ \"$1\" = \"production\" ] && [ \"$(git branch --show-current)\" != \"main\" ]; then\n  âš ï¸  WARNING: Not on main branch for production deploy\n  This is unusual. Confirm this is intentional.\nfi\n\n<!-- Test status ensures we don't deploy broken code -->\nRunning tests: BANG`npm test`\n\nâœ“ All checks passed\n\n## Deployment\n\n<!-- Actual deployment happens here -->\n<!-- Uses blue-green strategy for zero-downtime -->\nDeploying to $1 environment...\n[Deployment steps...]\n\n<!-- Post-deployment verification -->\nVerifying deployment health...\n[Health checks...]\n\nDeployment complete!\n\n## Next Steps\n\n<!-- Guide user on what to do after deployment -->\n1. Monitor logs: /logs $1\n2. Run smoke tests: /smoke-test $1\n3. Notify team: /notify-deployment $1\n```\n\n### Decision Point Documentation\n\n```markdown\n---\ndescription: Interactive deployment command\n---\n\n# Interactive Deployment\n\n## Configuration Review\n\nTarget: $1\nCurrent version: BANG`cat version.txt`\nNew version: $2\n\n<!-- DECISION POINT: User confirms configuration -->\n<!-- This pause allows user to verify everything is correct -->\n<!-- We can't automatically proceed because deployment is risky -->\n\nReview the above configuration.\n\n**Continue with deployment?**\n- Reply \"yes\" to proceed\n- Reply \"no\" to cancel\n- Reply \"edit\" to modify configuration\n\n[Await user input before continuing...]\n\n<!-- After user confirms, we proceed with deployment -->\n<!-- All subsequent steps are automated -->\n\nProceeding with deployment...\n```\n\n## Help Text Patterns\n\n### Built-in Help Command\n\nCreate a help subcommand for complex commands:\n\n```markdown\n---\ndescription: Main command with help\nargument-hint: [subcommand] [args]\n---\n\n# Command Processor\n\nif [ \"$1\" = \"help\" ] || [ \"$1\" = \"--help\" ] || [ \"$1\" = \"-h\" ]; then\n  **Command Help**\n\n  USAGE:\n    /command [subcommand] [args]\n\n  SUBCOMMANDS:\n    init [name]       Initialize new configuration\n    deploy [env]      Deploy to environment\n    status            Show current status\n    rollback          Rollback last deployment\n    help              Show this help\n\n  EXAMPLES:\n    /command init my-project\n    /command deploy staging\n    /command status\n    /command rollback\n\n  For detailed help on a subcommand:\n    /command [subcommand] --help\n\n  Exit.\nfi\n\n[Regular command processing...]\n```\n\n### Contextual Help\n\nProvide help based on context:\n\n```markdown\n---\ndescription: Context-aware command\nargument-hint: [operation] [target]\n---\n\n# Context-Aware Operation\n\nif [ -z \"$1\" ]; then\n  **No operation specified**\n\n  Available operations:\n  - analyze: Analyze target for issues\n  - fix: Apply automatic fixes\n  - report: Generate detailed report\n\n  Usage: /command [operation] [target]\n\n  Examples:\n    /command analyze src/\n    /command fix src/app.js\n    /command report\n\n  Run /command help for more details.\n\n  Exit.\nfi\n\n[Command continues if operation provided...]\n```\n\n## Error Message Documentation\n\n### Helpful Error Messages\n\n```markdown\n---\ndescription: Command with good error messages\n---\n\n# Validation Command\n\nif [ -z \"$1\" ]; then\n  âŒ ERROR: Missing required argument\n\n  The 'file-path' argument is required.\n\n  USAGE:\n    /validate [file-path]\n\n  EXAMPLE:\n    /validate src/app.js\n\n  Try again with a file path.\n\n  Exit.\nfi\n\nif [ ! -f \"$1\" ]; then\n  âŒ ERROR: File not found: $1\n\n  The specified file does not exist or is not accessible.\n\n  COMMON CAUSES:\n  1. Typo in file path\n  2. File was deleted or moved\n  3. Insufficient permissions\n\n  SUGGESTIONS:\n  - Check spelling: $1\n  - Verify file exists: ls -la $(dirname \"$1\")\n  - Check permissions: ls -l \"$1\"\n\n  Exit.\nfi\n\n[Command continues if validation passes...]\n```\n\n### Error Recovery Guidance\n\n```markdown\n---\ndescription: Command with recovery guidance\n---\n\n# Operation Command\n\nRunning operation...\n\nBANG`risky-operation.sh`\n\nif [ $? -ne 0 ]; then\n  âŒ OPERATION FAILED\n\n  The operation encountered an error and could not complete.\n\n  WHAT HAPPENED:\n  The risky-operation.sh script returned a non-zero exit code.\n\n  WHAT THIS MEANS:\n  - Changes may be partially applied\n  - System may be in inconsistent state\n  - Manual intervention may be needed\n\n  RECOVERY STEPS:\n  1. Check operation logs: cat /tmp/operation.log\n  2. Verify system state: /check-state\n  3. If needed, rollback: /rollback-operation\n  4. Fix underlying issue\n  5. Retry operation: /retry-operation\n\n  NEED HELP?\n  - Check troubleshooting guide: /help troubleshooting\n  - Contact support with error code: ERR_OP_FAILED_001\n\n  Exit.\nfi\n```\n\n## Usage Example Documentation\n\n### Embedded Examples\n\n```markdown\n---\ndescription: Command with embedded examples\n---\n\n# Feature Command\n\nThis command performs feature analysis with multiple options.\n\n## Basic Usage\n\n\\`\\`\\`\n/feature analyze src/\n\\`\\`\\`\n\nAnalyzes all files in src/ directory for feature usage.\n\n## Advanced Usage\n\n\\`\\`\\`\n/feature analyze src/ --detailed\n\\`\\`\\`\n\nProvides detailed analysis including:\n- Feature breakdown by file\n- Usage patterns\n- Optimization suggestions\n\n## Use Cases\n\n**Use Case 1: Quick overview**\n\\`\\`\\`\n/feature analyze .\n\\`\\`\\`\nGet high-level feature summary of entire project.\n\n**Use Case 2: Specific directory**\n\\`\\`\\`\n/feature analyze src/components\n\\`\\`\\`\nFocus analysis on components directory only.\n\n**Use Case 3: Comparison**\n\\`\\`\\`\n/feature analyze src/ --compare baseline.json\n\\`\\`\\`\nCompare current features against baseline.\n\n---\n\nNow processing your request...\n\n[Command implementation...]\n```\n\n### Example-Driven Documentation\n\n```markdown\n---\ndescription: Example-heavy command\n---\n\n# Transformation Command\n\n## What This Does\n\nTransforms data from one format to another.\n\n## Examples First\n\n### Example 1: JSON to YAML\n**Input:** `data.json`\n\\`\\`\\`json\n{\"name\": \"test\", \"value\": 42}\n\\`\\`\\`\n\n**Command:** `/transform data.json yaml`\n\n**Output:** `data.yaml`\n\\`\\`\\`yaml\nname: test\nvalue: 42\n\\`\\`\\`\n\n### Example 2: CSV to JSON\n**Input:** `data.csv`\n\\`\\`\\`csv\nname,value\ntest,42\n\\`\\`\\`\n\n**Command:** `/transform data.csv json`\n\n**Output:** `data.json`\n\\`\\`\\`json\n[{\"name\": \"test\", \"value\": \"42\"}]\n\\`\\`\\`\n\n### Example 3: With Options\n**Command:** `/transform data.json yaml --pretty --sort-keys`\n\n**Result:** Formatted YAML with sorted keys\n\n---\n\n## Your Transformation\n\nFile: $1\nFormat: $2\n\n[Perform transformation...]\n```\n\n## Maintenance Documentation\n\n### Version and Changelog\n\n```markdown\n<!--\nVERSION: 2.1.0\nLAST UPDATED: 2025-01-15\nAUTHOR: DevOps Team\n\nCHANGELOG:\n  v2.1.0 (2025-01-15):\n    - Added support for YAML configuration\n    - Improved error messages\n    - Fixed bug with special characters in arguments\n\n  v2.0.0 (2025-01-01):\n    - BREAKING: Changed argument order\n    - BREAKING: Removed deprecated --old-flag\n    - Added new validation checks\n    - Migration guide: /migration-v2\n\n  v1.5.0 (2024-12-15):\n    - Added --verbose flag\n    - Improved performance by 50%\n\n  v1.0.0 (2024-12-01):\n    - Initial stable release\n\nMIGRATION NOTES:\n  From v1.x to v2.0:\n    Old: /command arg1 arg2 --old-flag\n    New: /command arg2 arg1\n\n  The --old-flag is removed. Use --new-flag instead.\n\nDEPRECATION WARNINGS:\n  - The --legacy-mode flag is deprecated as of v2.1.0\n  - Will be removed in v3.0.0 (estimated 2025-06-01)\n  - Use --modern-mode instead\n\nKNOWN ISSUES:\n  - #123: Slow performance with large files (workaround: use --stream flag)\n  - #456: Special characters in Windows (fix planned for v2.2.0)\n-->\n```\n\n### Maintenance Notes\n\n```markdown\n<!--\nMAINTENANCE NOTES:\n\nCODE STRUCTURE:\n  - Lines 1-50: Argument parsing and validation\n  - Lines 51-100: Main processing logic\n  - Lines 101-150: Output formatting\n  - Lines 151-200: Error handling\n\nDEPENDENCIES:\n  - Requires git 2.x or later\n  - Uses jq for JSON processing\n  - Needs bash 4.0+ for associative arrays\n\nPERFORMANCE:\n  - Fast path for small inputs (< 1MB)\n  - Streams large files to avoid memory issues\n  - Caches results in /tmp for 1 hour\n\nSECURITY CONSIDERATIONS:\n  - Validates all inputs to prevent injection\n  - Uses allowed-tools to limit Bash access\n  - No credentials in command file\n\nTESTING:\n  - Unit tests: tests/command-test.sh\n  - Integration tests: tests/integration/\n  - Manual test checklist: tests/manual-checklist.md\n\nFUTURE IMPROVEMENTS:\n  - TODO: Add support for TOML format\n  - TODO: Implement parallel processing\n  - TODO: Add progress bar for large files\n\nRELATED FILES:\n  - lib/parser.sh: Shared parsing logic\n  - lib/formatter.sh: Output formatting\n  - config/defaults.yml: Default configuration\n-->\n```\n\n## README Documentation\n\nCommands should have companion README files:\n\n```markdown\n# Command Name\n\nBrief description of what the command does.\n\n## Installation\n\nThis command is part of the [plugin-name] plugin.\n\nInstall with:\n\\`\\`\\`\n/plugin install plugin-name\n\\`\\`\\`\n\n## Usage\n\nBasic usage:\n\\`\\`\\`\n/command-name [arg1] [arg2]\n\\`\\`\\`\n\n## Arguments\n\n- `arg1`: Description (required)\n- `arg2`: Description (optional, defaults to X)\n\n## Examples\n\n### Example 1: Basic Usage\n\\`\\`\\`\n/command-name value1 value2\n\\`\\`\\`\n\nDescription of what happens.\n\n### Example 2: Advanced Usage\n\\`\\`\\`\n/command-name value1 --option\n\\`\\`\\`\n\nDescription of advanced feature.\n\n## Configuration\n\nOptional configuration file: `.claude/command-name.local.md`\n\n\\`\\`\\`markdown\n---\ndefault_arg: value\nenable_feature: true\n---\n\\`\\`\\`\n\n## Requirements\n\n- Git 2.x or later\n- jq (for JSON processing)\n- Node.js 14+ (optional, for advanced features)\n\n## Troubleshooting\n\n### Issue: Command not found\n\n**Solution:** Ensure plugin is installed and enabled.\n\n### Issue: Permission denied\n\n**Solution:** Check file permissions and allowed-tools setting.\n\n## Contributing\n\nContributions welcome! See [CONTRIBUTING.md](CONTRIBUTING.md).\n\n## License\n\nMIT License - See [LICENSE](LICENSE).\n\n## Support\n\n- Issues: https://github.com/user/plugin/issues\n- Docs: https://docs.example.com\n- Email: support@example.com\n```\n\n## Best Practices\n\n### Documentation Principles\n\n1. **Write for your future self**: Assume you'll forget details\n2. **Examples before explanations**: Show, then tell\n3. **Progressive disclosure**: Basic info first, details available\n4. **Keep it current**: Update docs when code changes\n5. **Test your docs**: Verify examples actually work\n\n### Documentation Locations\n\n1. **In command file**: Core usage, examples, inline explanations\n2. **README**: Installation, configuration, troubleshooting\n3. **Separate docs**: Detailed guides, tutorials, API reference\n4. **Comments**: Implementation details for maintainers\n\n### Documentation Style\n\n1. **Clear and concise**: No unnecessary words\n2. **Active voice**: \"Run the command\" not \"The command can be run\"\n3. **Consistent terminology**: Use same terms throughout\n4. **Formatted well**: Use headings, lists, code blocks\n5. **Accessible**: Assume reader is beginner\n\n### Documentation Maintenance\n\n1. **Version everything**: Track what changed when\n2. **Deprecate gracefully**: Warn before removing features\n3. **Migration guides**: Help users upgrade\n4. **Archive old docs**: Keep old versions accessible\n5. **Review regularly**: Ensure docs match reality\n\n## Documentation Checklist\n\nBefore releasing a command:\n\n- [ ] Description in frontmatter is clear\n- [ ] argument-hint documents all arguments\n- [ ] Usage examples in comments\n- [ ] Common use cases shown\n- [ ] Error messages are helpful\n- [ ] Requirements documented\n- [ ] Related commands listed\n- [ ] Changelog maintained\n- [ ] Version number updated\n- [ ] README created/updated\n- [ ] Examples actually work\n- [ ] Troubleshooting section complete\n\nWith good documentation, commands become self-service, reducing support burden and improving user experience.\n",
        "plugins/plugin-dev/skills/command-development/references/frontmatter-reference.md": "# Command Frontmatter Reference\n\nComplete reference for YAML frontmatter fields in slash commands.\n\n## Frontmatter Overview\n\nYAML frontmatter is optional metadata at the start of command files:\n\n```markdown\n---\ndescription: Brief description\nallowed-tools: Read, Write\nmodel: sonnet\nargument-hint: [arg1] [arg2]\n---\n\nCommand prompt content here...\n```\n\nAll fields are optional. Commands work without any frontmatter.\n\n## Field Specifications\n\n### description\n\n**Type:** String\n**Required:** No\n**Default:** First line of command prompt\n**Max Length:** ~60 characters recommended for `/help` display\n\n**Purpose:** Describes what the command does, shown in `/help` output\n\n**Examples:**\n```yaml\ndescription: Review code for security issues\n```\n```yaml\ndescription: Deploy to staging environment\n```\n```yaml\ndescription: Generate API documentation\n```\n\n**Best practices:**\n- Keep under 60 characters for clean display\n- Start with verb (Review, Deploy, Generate)\n- Be specific about what command does\n- Avoid redundant \"command\" or \"slash command\"\n\n**Good:**\n- âœ… \"Review PR for code quality and security\"\n- âœ… \"Deploy application to specified environment\"\n- âœ… \"Generate comprehensive API documentation\"\n\n**Bad:**\n- âŒ \"This command reviews PRs\" (unnecessary \"This command\")\n- âŒ \"Review\" (too vague)\n- âŒ \"A command that reviews pull requests for code quality, security issues, and best practices\" (too long)\n\n### allowed-tools\n\n**Type:** String or Array of strings\n**Required:** No\n**Default:** Inherits from conversation permissions\n\n**Purpose:** Restrict or specify which tools command can use\n\n**Formats:**\n\n**Single tool:**\n```yaml\nallowed-tools: Read\n```\n\n**Multiple tools (comma-separated):**\n```yaml\nallowed-tools: Read, Write, Edit\n```\n\n**Multiple tools (array):**\n```yaml\nallowed-tools:\n  - Read\n  - Write\n  - Bash(git:*)\n```\n\n**Tool Patterns:**\n\n**Specific tools:**\n```yaml\nallowed-tools: Read, Grep, Edit\n```\n\n**Bash with command filter:**\n```yaml\nallowed-tools: Bash(git:*)           # Only git commands\nallowed-tools: Bash(npm:*)           # Only npm commands\nallowed-tools: Bash(docker:*)        # Only docker commands\n```\n\n**All tools (not recommended):**\n```yaml\nallowed-tools: \"*\"\n```\n\n**When to use:**\n\n1. **Security:** Restrict command to safe operations\n   ```yaml\n   allowed-tools: Read, Grep  # Read-only command\n   ```\n\n2. **Clarity:** Document required tools\n   ```yaml\n   allowed-tools: Bash(git:*), Read\n   ```\n\n3. **Bash execution:** Enable bash command output\n   ```yaml\n   allowed-tools: Bash(git status:*), Bash(git diff:*)\n   ```\n\n**Best practices:**\n- Be as restrictive as possible\n- Use command filters for Bash (e.g., `git:*` not `*`)\n- Only specify when different from conversation permissions\n- Document why specific tools are needed\n\n### model\n\n**Type:** String\n**Required:** No\n**Default:** Inherits from conversation\n**Values:** `sonnet`, `opus`, `haiku`\n\n**Purpose:** Specify which Claude model executes the command\n\n**Examples:**\n```yaml\nmodel: haiku    # Fast, efficient for simple tasks\n```\n```yaml\nmodel: sonnet   # Balanced performance (default)\n```\n```yaml\nmodel: opus     # Maximum capability for complex tasks\n```\n\n**When to use:**\n\n**Use `haiku` for:**\n- Simple, formulaic commands\n- Fast execution needed\n- Low complexity tasks\n- Frequent invocations\n\n```yaml\n---\ndescription: Format code file\nmodel: haiku\n---\n```\n\n**Use `sonnet` for:**\n- Standard commands (default)\n- Balanced speed/quality\n- Most common use cases\n\n```yaml\n---\ndescription: Review code changes\nmodel: sonnet\n---\n```\n\n**Use `opus` for:**\n- Complex analysis\n- Architectural decisions\n- Deep code understanding\n- Critical tasks\n\n```yaml\n---\ndescription: Analyze system architecture\nmodel: opus\n---\n```\n\n**Best practices:**\n- Omit unless specific need\n- Use `haiku` for speed when possible\n- Reserve `opus` for genuinely complex tasks\n- Test with different models to find right balance\n\n### argument-hint\n\n**Type:** String\n**Required:** No\n**Default:** None\n\n**Purpose:** Document expected arguments for users and autocomplete\n\n**Format:**\n```yaml\nargument-hint: [arg1] [arg2] [optional-arg]\n```\n\n**Examples:**\n\n**Single argument:**\n```yaml\nargument-hint: [pr-number]\n```\n\n**Multiple required arguments:**\n```yaml\nargument-hint: [environment] [version]\n```\n\n**Optional arguments:**\n```yaml\nargument-hint: [file-path] [options]\n```\n\n**Descriptive names:**\n```yaml\nargument-hint: [source-branch] [target-branch] [commit-message]\n```\n\n**Best practices:**\n- Use square brackets `[]` for each argument\n- Use descriptive names (not `arg1`, `arg2`)\n- Indicate optional vs required in description\n- Match order to positional arguments in command\n- Keep concise but clear\n\n**Examples by pattern:**\n\n**Simple command:**\n```yaml\n---\ndescription: Fix issue by number\nargument-hint: [issue-number]\n---\n\nFix issue #$1...\n```\n\n**Multi-argument:**\n```yaml\n---\ndescription: Deploy to environment\nargument-hint: [app-name] [environment] [version]\n---\n\nDeploy $1 to $2 using version $3...\n```\n\n**With options:**\n```yaml\n---\ndescription: Run tests with options\nargument-hint: [test-pattern] [options]\n---\n\nRun tests matching $1 with options: $2\n```\n\n### disable-model-invocation\n\n**Type:** Boolean\n**Required:** No\n**Default:** false\n\n**Purpose:** Prevent SlashCommand tool from programmatically invoking command\n\n**Examples:**\n```yaml\ndisable-model-invocation: true\n```\n\n**When to use:**\n\n1. **Manual-only commands:** Commands requiring user judgment\n   ```yaml\n   ---\n   description: Approve deployment to production\n   disable-model-invocation: true\n   ---\n   ```\n\n2. **Destructive operations:** Commands with irreversible effects\n   ```yaml\n   ---\n   description: Delete all test data\n   disable-model-invocation: true\n   ---\n   ```\n\n3. **Interactive workflows:** Commands needing user input\n   ```yaml\n   ---\n   description: Walk through setup wizard\n   disable-model-invocation: true\n   ---\n   ```\n\n**Default behavior (false):**\n- Command available to SlashCommand tool\n- Claude can invoke programmatically\n- Still available for manual invocation\n\n**When true:**\n- Command only invokable by user typing `/command`\n- Not available to SlashCommand tool\n- Safer for sensitive operations\n\n**Best practices:**\n- Use sparingly (limits Claude's autonomy)\n- Document why in command comments\n- Consider if command should exist if always manual\n\n## Complete Examples\n\n### Minimal Command\n\nNo frontmatter needed:\n\n```markdown\nReview this code for common issues and suggest improvements.\n```\n\n### Simple Command\n\nJust description:\n\n```markdown\n---\ndescription: Review code for issues\n---\n\nReview this code for common issues and suggest improvements.\n```\n\n### Standard Command\n\nDescription and tools:\n\n```markdown\n---\ndescription: Review Git changes\nallowed-tools: Bash(git:*), Read\n---\n\nCurrent changes: BANG`git diff --name-only`\n\nReview each changed file for:\n- Code quality\n- Potential bugs\n- Best practices\n```\n\n### Complex Command\n\nAll common fields:\n\n```markdown\n---\ndescription: Deploy application to environment\nargument-hint: [app-name] [environment] [version]\nallowed-tools: Bash(kubectl:*), Bash(helm:*), Read\nmodel: sonnet\n---\n\nDeploy $1 to $2 environment using version $3\n\nPre-deployment checks:\n- Verify $2 configuration\n- Check cluster status: BANG`kubectl cluster-info`\n- Validate version $3 exists\n\nProceed with deployment following deployment runbook.\n```\n\n### Manual-Only Command\n\nRestricted invocation:\n\n```markdown\n---\ndescription: Approve production deployment\nargument-hint: [deployment-id]\ndisable-model-invocation: true\nallowed-tools: Bash(gh:*)\n---\n\n<!--\nMANUAL APPROVAL REQUIRED\nThis command requires human judgment and cannot be automated.\n-->\n\nReview deployment $1 for production approval:\n\nDeployment details: BANG`gh api /deployments/$1`\n\nVerify:\n- All tests passed\n- Security scan clean\n- Stakeholder approval\n- Rollback plan ready\n\nType \"APPROVED\" to confirm deployment.\n```\n\n## Validation\n\n### Common Errors\n\n**Invalid YAML syntax:**\n```yaml\n---\ndescription: Missing quote\nallowed-tools: Read, Write\nmodel: sonnet\n---  # âŒ Missing closing quote above\n```\n\n**Fix:** Validate YAML syntax\n\n**Incorrect tool specification:**\n```yaml\nallowed-tools: Bash  # âŒ Missing command filter\n```\n\n**Fix:** Use `Bash(git:*)` format\n\n**Invalid model name:**\n```yaml\nmodel: gpt4  # âŒ Not a valid Claude model\n```\n\n**Fix:** Use `sonnet`, `opus`, or `haiku`\n\n### Validation Checklist\n\nBefore committing command:\n- [ ] YAML syntax valid (no errors)\n- [ ] Description under 60 characters\n- [ ] allowed-tools uses proper format\n- [ ] model is valid value if specified\n- [ ] argument-hint matches positional arguments\n- [ ] disable-model-invocation used appropriately\n\n## Best Practices Summary\n\n1. **Start minimal:** Add frontmatter only when needed\n2. **Document arguments:** Always use argument-hint with arguments\n3. **Restrict tools:** Use most restrictive allowed-tools that works\n4. **Choose right model:** Use haiku for speed, opus for complexity\n5. **Manual-only sparingly:** Only use disable-model-invocation when necessary\n6. **Clear descriptions:** Make commands discoverable in `/help`\n7. **Test thoroughly:** Verify frontmatter works as expected\n",
        "plugins/plugin-dev/skills/command-development/references/interactive-commands.md": "# Interactive Command Patterns\n\nComprehensive guide to creating commands that gather user feedback and make decisions through the AskUserQuestion tool.\n\n## Overview\n\nSome commands need user input that doesn't work well with simple arguments. For example:\n- Choosing between multiple complex options with trade-offs\n- Selecting multiple items from a list\n- Making decisions that require explanation\n- Gathering preferences or configuration interactively\n\nFor these cases, use the **AskUserQuestion tool** within command execution rather than relying on command arguments.\n\n## When to Use AskUserQuestion\n\n### Use AskUserQuestion When:\n\n1. **Multiple choice decisions** with explanations needed\n2. **Complex options** that require context to choose\n3. **Multi-select scenarios** (choosing multiple items)\n4. **Preference gathering** for configuration\n5. **Interactive workflows** that adapt based on answers\n\n### Use Command Arguments When:\n\n1. **Simple values** (file paths, numbers, names)\n2. **Known inputs** user already has\n3. **Scriptable workflows** that should be automatable\n4. **Fast invocations** where prompting would slow down\n\n## AskUserQuestion Basics\n\n### Tool Parameters\n\n```typescript\n{\n  questions: [\n    {\n      question: \"Which authentication method should we use?\",\n      header: \"Auth method\",  // Short label (max 12 chars)\n      multiSelect: false,     // true for multiple selection\n      options: [\n        {\n          label: \"OAuth 2.0\",\n          description: \"Industry standard, supports multiple providers\"\n        },\n        {\n          label: \"JWT\",\n          description: \"Stateless, good for APIs\"\n        },\n        {\n          label: \"Session\",\n          description: \"Traditional, server-side state\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n**Key points:**\n- Users can always choose \"Other\" to provide custom input (automatic)\n- `multiSelect: true` allows selecting multiple options\n- Options should be 2-4 choices (not more)\n- Can ask 1-4 questions per tool call\n\n## Command Pattern for User Interaction\n\n### Basic Interactive Command\n\n```markdown\n---\ndescription: Interactive setup command\nallowed-tools: AskUserQuestion, Write\n---\n\n# Interactive Plugin Setup\n\nThis command will guide you through configuring the plugin with a series of questions.\n\n## Step 1: Gather Configuration\n\nUse the AskUserQuestion tool to ask:\n\n**Question 1 - Deployment target:**\n- header: \"Deploy to\"\n- question: \"Which deployment platform will you use?\"\n- options:\n  - AWS (Amazon Web Services with ECS/EKS)\n  - GCP (Google Cloud with GKE)\n  - Azure (Microsoft Azure with AKS)\n  - Local (Docker on local machine)\n\n**Question 2 - Environment strategy:**\n- header: \"Environments\"\n- question: \"How many environments do you need?\"\n- options:\n  - Single (Just production)\n  - Standard (Dev, Staging, Production)\n  - Complete (Dev, QA, Staging, Production)\n\n**Question 3 - Features to enable:**\n- header: \"Features\"\n- question: \"Which features do you want to enable?\"\n- multiSelect: true\n- options:\n  - Auto-scaling (Automatic resource scaling)\n  - Monitoring (Health checks and metrics)\n  - CI/CD (Automated deployment pipeline)\n  - Backups (Automated database backups)\n\n## Step 2: Process Answers\n\nBased on the answers received from AskUserQuestion:\n\n1. Parse the deployment target choice\n2. Set up environment-specific configuration\n3. Enable selected features\n4. Generate configuration files\n\n## Step 3: Generate Configuration\n\nCreate `.claude/plugin-name.local.md` with:\n\n\\`\\`\\`yaml\n---\ndeployment_target: [answer from Q1]\nenvironments: [answer from Q2]\nfeatures:\n  auto_scaling: [true if selected in Q3]\n  monitoring: [true if selected in Q3]\n  ci_cd: [true if selected in Q3]\n  backups: [true if selected in Q3]\n---\n\n# Plugin Configuration\n\nGenerated: [timestamp]\nTarget: [deployment_target]\nEnvironments: [environments]\n\\`\\`\\`\n\n## Step 4: Confirm and Next Steps\n\nConfirm configuration created and guide user on next steps.\n```\n\n### Multi-Stage Interactive Workflow\n\n```markdown\n---\ndescription: Multi-stage interactive workflow\nallowed-tools: AskUserQuestion, Read, Write, Bash\n---\n\n# Multi-Stage Deployment Setup\n\nThis command walks through deployment setup in stages, adapting based on your answers.\n\n## Stage 1: Basic Configuration\n\nUse AskUserQuestion to ask about deployment basics.\n\nBased on answers, determine which additional questions to ask.\n\n## Stage 2: Advanced Options (Conditional)\n\nIf user selected \"Advanced\" deployment in Stage 1:\n\nUse AskUserQuestion to ask about:\n- Load balancing strategy\n- Caching configuration\n- Security hardening options\n\nIf user selected \"Simple\" deployment:\n- Skip advanced questions\n- Use sensible defaults\n\n## Stage 3: Confirmation\n\nShow summary of all selections.\n\nUse AskUserQuestion for final confirmation:\n- header: \"Confirm\"\n- question: \"Does this configuration look correct?\"\n- options:\n  - Yes (Proceed with setup)\n  - No (Start over)\n  - Modify (Let me adjust specific settings)\n\nIf \"Modify\", ask which specific setting to change.\n\n## Stage 4: Execute Setup\n\nBased on confirmed configuration, execute setup steps.\n```\n\n## Interactive Question Design\n\n### Question Structure\n\n**Good questions:**\n```markdown\nQuestion: \"Which database should we use for this project?\"\nHeader: \"Database\"\nOptions:\n  - PostgreSQL (Relational, ACID compliant, best for complex queries)\n  - MongoDB (Document store, flexible schema, best for rapid iteration)\n  - Redis (In-memory, fast, best for caching and sessions)\n```\n\n**Poor questions:**\n```markdown\nQuestion: \"Database?\"  // Too vague\nHeader: \"DB\"  // Unclear abbreviation\nOptions:\n  - Option 1  // Not descriptive\n  - Option 2\n```\n\n### Option Design Best Practices\n\n**Clear labels:**\n- Use 1-5 words\n- Specific and descriptive\n- No jargon without context\n\n**Helpful descriptions:**\n- Explain what the option means\n- Mention key benefits or trade-offs\n- Help user make informed decision\n- Keep to 1-2 sentences\n\n**Appropriate number:**\n- 2-4 options per question\n- Don't overwhelm with too many choices\n- Group related options\n- \"Other\" automatically provided\n\n### Multi-Select Questions\n\n**When to use multiSelect:**\n\n```markdown\nUse AskUserQuestion for enabling features:\n\nQuestion: \"Which features do you want to enable?\"\nHeader: \"Features\"\nmultiSelect: true  // Allow selecting multiple\nOptions:\n  - Logging (Detailed operation logs)\n  - Metrics (Performance monitoring)\n  - Alerts (Error notifications)\n  - Backups (Automatic backups)\n```\n\nUser can select any combination: none, some, or all.\n\n**When NOT to use multiSelect:**\n\n```markdown\nQuestion: \"Which authentication method?\"\nmultiSelect: false  // Only one auth method makes sense\n```\n\nMutually exclusive choices should not use multiSelect.\n\n## Command Patterns with AskUserQuestion\n\n### Pattern 1: Simple Yes/No Decision\n\n```markdown\n---\ndescription: Command with confirmation\nallowed-tools: AskUserQuestion, Bash\n---\n\n# Destructive Operation\n\nThis operation will delete all cached data.\n\nUse AskUserQuestion to confirm:\n\nQuestion: \"This will delete all cached data. Are you sure?\"\nHeader: \"Confirm\"\nOptions:\n  - Yes (Proceed with deletion)\n  - No (Cancel operation)\n\nIf user selects \"Yes\":\n  Execute deletion\n  Report completion\n\nIf user selects \"No\":\n  Cancel operation\n  Exit without changes\n```\n\n### Pattern 2: Multiple Configuration Questions\n\n```markdown\n---\ndescription: Multi-question configuration\nallowed-tools: AskUserQuestion, Write\n---\n\n# Project Configuration Setup\n\nGather configuration through multiple questions.\n\nUse AskUserQuestion with multiple questions in one call:\n\n**Question 1:**\n- question: \"Which programming language?\"\n- header: \"Language\"\n- options: Python, TypeScript, Go, Rust\n\n**Question 2:**\n- question: \"Which test framework?\"\n- header: \"Testing\"\n- options: Jest, PyTest, Go Test, Cargo Test\n  (Adapt based on language from Q1)\n\n**Question 3:**\n- question: \"Which CI/CD platform?\"\n- header: \"CI/CD\"\n- options: GitHub Actions, GitLab CI, CircleCI\n\n**Question 4:**\n- question: \"Which features do you need?\"\n- header: \"Features\"\n- multiSelect: true\n- options: Linting, Type checking, Code coverage, Security scanning\n\nProcess all answers together to generate cohesive configuration.\n```\n\n### Pattern 3: Conditional Question Flow\n\n```markdown\n---\ndescription: Conditional interactive workflow\nallowed-tools: AskUserQuestion, Read, Write\n---\n\n# Adaptive Configuration\n\n## Question 1: Deployment Complexity\n\nUse AskUserQuestion:\n\nQuestion: \"How complex is your deployment?\"\nHeader: \"Complexity\"\nOptions:\n  - Simple (Single server, straightforward)\n  - Standard (Multiple servers, load balancing)\n  - Complex (Microservices, orchestration)\n\n## Conditional Questions Based on Answer\n\nIf answer is \"Simple\":\n  - No additional questions\n  - Use minimal configuration\n\nIf answer is \"Standard\":\n  - Ask about load balancing strategy\n  - Ask about scaling policy\n\nIf answer is \"Complex\":\n  - Ask about orchestration platform (Kubernetes, Docker Swarm)\n  - Ask about service mesh (Istio, Linkerd, None)\n  - Ask about monitoring (Prometheus, Datadog, CloudWatch)\n  - Ask about logging aggregation\n\n## Process Conditional Answers\n\nGenerate configuration appropriate for selected complexity level.\n```\n\n### Pattern 4: Iterative Collection\n\n```markdown\n---\ndescription: Collect multiple items iteratively\nallowed-tools: AskUserQuestion, Write\n---\n\n# Collect Team Members\n\nWe'll collect team member information for the project.\n\n## Question: How many team members?\n\nUse AskUserQuestion:\n\nQuestion: \"How many team members should we set up?\"\nHeader: \"Team size\"\nOptions:\n  - 2 people\n  - 3 people\n  - 4 people\n  - 6 people\n\n## Iterate Through Team Members\n\nFor each team member (1 to N based on answer):\n\nUse AskUserQuestion for member details:\n\nQuestion: \"What role for team member [number]?\"\nHeader: \"Role\"\nOptions:\n  - Frontend Developer\n  - Backend Developer\n  - DevOps Engineer\n  - QA Engineer\n  - Designer\n\nStore each member's information.\n\n## Generate Team Configuration\n\nAfter collecting all N members, create team configuration file with all members and their roles.\n```\n\n### Pattern 5: Dependency Selection\n\n```markdown\n---\ndescription: Select dependencies with multi-select\nallowed-tools: AskUserQuestion\n---\n\n# Configure Project Dependencies\n\n## Question: Required Libraries\n\nUse AskUserQuestion with multiSelect:\n\nQuestion: \"Which libraries does your project need?\"\nHeader: \"Dependencies\"\nmultiSelect: true\nOptions:\n  - React (UI framework)\n  - Express (Web server)\n  - TypeORM (Database ORM)\n  - Jest (Testing framework)\n  - Axios (HTTP client)\n\nUser can select any combination.\n\n## Process Selections\n\nFor each selected library:\n- Add to package.json dependencies\n- Generate sample configuration\n- Create usage examples\n- Update documentation\n```\n\n## Best Practices for Interactive Commands\n\n### Question Design\n\n1. **Clear and specific**: Question should be unambiguous\n2. **Concise header**: Max 12 characters for clean display\n3. **Helpful options**: Labels are clear, descriptions explain trade-offs\n4. **Appropriate count**: 2-4 options per question, 1-4 questions per call\n5. **Logical order**: Questions flow naturally\n\n### Error Handling\n\n```markdown\n# Handle AskUserQuestion Responses\n\nAfter calling AskUserQuestion, verify answers received:\n\nIf answers are empty or invalid:\n  Something went wrong gathering responses.\n\n  Please try again or provide configuration manually:\n  [Show alternative approach]\n\n  Exit.\n\nIf answers look correct:\n  Process as expected\n```\n\n### Progressive Disclosure\n\n```markdown\n# Start Simple, Get Detailed as Needed\n\n## Question 1: Setup Type\n\nUse AskUserQuestion:\n\nQuestion: \"How would you like to set up?\"\nHeader: \"Setup type\"\nOptions:\n  - Quick (Use recommended defaults)\n  - Custom (Configure all options)\n  - Guided (Step-by-step with explanations)\n\nIf \"Quick\":\n  Apply defaults, minimal questions\n\nIf \"Custom\":\n  Ask all available configuration questions\n\nIf \"Guided\":\n  Ask questions with extra explanation\n  Provide recommendations along the way\n```\n\n### Multi-Select Guidelines\n\n**Good multi-select use:**\n```markdown\nQuestion: \"Which features do you want to enable?\"\nmultiSelect: true\nOptions:\n  - Logging\n  - Metrics\n  - Alerts\n  - Backups\n\nReason: User might want any combination\n```\n\n**Bad multi-select use:**\n```markdown\nQuestion: \"Which database engine?\"\nmultiSelect: true  // âŒ Should be single-select\n\nReason: Can only use one database engine\n```\n\n## Advanced Patterns\n\n### Validation Loop\n\n```markdown\n---\ndescription: Interactive with validation\nallowed-tools: AskUserQuestion, Bash\n---\n\n# Setup with Validation\n\n## Gather Configuration\n\nUse AskUserQuestion to collect settings.\n\n## Validate Configuration\n\nCheck if configuration is valid:\n- Required dependencies available?\n- Settings compatible with each other?\n- No conflicts detected?\n\nIf validation fails:\n  Show validation errors\n\n  Use AskUserQuestion to ask:\n\n  Question: \"Configuration has issues. What would you like to do?\"\n  Header: \"Next step\"\n  Options:\n    - Fix (Adjust settings to resolve issues)\n    - Override (Proceed despite warnings)\n    - Cancel (Abort setup)\n\n  Based on answer, retry or proceed or exit.\n```\n\n### Build Configuration Incrementally\n\n```markdown\n---\ndescription: Incremental configuration builder\nallowed-tools: AskUserQuestion, Write, Read\n---\n\n# Incremental Setup\n\n## Phase 1: Core Settings\n\nUse AskUserQuestion for core settings.\n\nSave to `.claude/config-partial.yml`\n\n## Phase 2: Review Core Settings\n\nShow user the core settings:\n\nBased on these core settings, you need to configure:\n- [Setting A] (because you chose [X])\n- [Setting B] (because you chose [Y])\n\nReady to continue?\n\n## Phase 3: Detailed Settings\n\nUse AskUserQuestion for settings based on Phase 1 answers.\n\nMerge with core settings.\n\n## Phase 4: Final Review\n\nPresent complete configuration.\n\nUse AskUserQuestion for confirmation:\n\nQuestion: \"Is this configuration correct?\"\nOptions:\n  - Yes (Save and apply)\n  - No (Start over)\n  - Modify (Edit specific settings)\n```\n\n### Dynamic Options Based on Context\n\n```markdown\n---\ndescription: Context-aware questions\nallowed-tools: AskUserQuestion, Bash, Read\n---\n\n# Context-Aware Setup\n\n## Detect Current State\n\nCheck existing configuration:\n- Current language: BANG`detect-language.sh`\n- Existing frameworks: BANG`detect-frameworks.sh`\n- Available tools: BANG`check-tools.sh`\n\n## Ask Context-Appropriate Questions\n\nBased on detected language, ask relevant questions.\n\nIf language is TypeScript:\n\n  Use AskUserQuestion:\n\n  Question: \"Which TypeScript features should we enable?\"\n  Options:\n    - Strict Mode (Maximum type safety)\n    - Decorators (Experimental decorator support)\n    - Path Mapping (Module path aliases)\n\nIf language is Python:\n\n  Use AskUserQuestion:\n\n  Question: \"Which Python tools should we configure?\"\n  Options:\n    - Type Hints (mypy for type checking)\n    - Black (Code formatting)\n    - Pylint (Linting and style)\n\nQuestions adapt to project context.\n```\n\n## Real-World Example: Multi-Agent Swarm Launch\n\n**From multi-agent-swarm plugin:**\n\n```markdown\n---\ndescription: Launch multi-agent swarm\nallowed-tools: AskUserQuestion, Read, Write, Bash\n---\n\n# Launch Multi-Agent Swarm\n\n## Interactive Mode (No Task List Provided)\n\nIf user didn't provide task list file, help create one interactively.\n\n### Question 1: Agent Count\n\nUse AskUserQuestion:\n\nQuestion: \"How many agents should we launch?\"\nHeader: \"Agent count\"\nOptions:\n  - 2 agents (Best for simple projects)\n  - 3 agents (Good for medium projects)\n  - 4 agents (Standard team size)\n  - 6 agents (Large projects)\n  - 8 agents (Complex multi-component projects)\n\n### Question 2: Task Definition Approach\n\nUse AskUserQuestion:\n\nQuestion: \"How would you like to define tasks?\"\nHeader: \"Task setup\"\nOptions:\n  - File (I have a task list file ready)\n  - Guided (Help me create tasks interactively)\n  - Custom (Other approach)\n\nIf \"File\":\n  Ask for file path\n  Validate file exists and has correct format\n\nIf \"Guided\":\n  Enter iterative task creation mode (see below)\n\n### Question 3: Coordination Mode\n\nUse AskUserQuestion:\n\nQuestion: \"How should agents coordinate?\"\nHeader: \"Coordination\"\nOptions:\n  - Team Leader (One agent coordinates others)\n  - Collaborative (Agents coordinate as peers)\n  - Autonomous (Independent work, minimal coordination)\n\n### Iterative Task Creation (If \"Guided\" Selected)\n\nFor each agent (1 to N from Question 1):\n\n**Question A: Agent Name**\nQuestion: \"What should we call agent [number]?\"\nHeader: \"Agent name\"\nOptions:\n  - auth-agent\n  - api-agent\n  - ui-agent\n  - db-agent\n  (Provide relevant suggestions based on common patterns)\n\n**Question B: Task Type**\nQuestion: \"What task for [agent-name]?\"\nHeader: \"Task type\"\nOptions:\n  - Authentication (User auth, JWT, OAuth)\n  - API Endpoints (REST/GraphQL APIs)\n  - UI Components (Frontend components)\n  - Database (Schema, migrations, queries)\n  - Testing (Test suites and coverage)\n  - Documentation (Docs, README, guides)\n\n**Question C: Dependencies**\nQuestion: \"What does [agent-name] depend on?\"\nHeader: \"Dependencies\"\nmultiSelect: true\nOptions:\n  - [List of previously defined agents]\n  - No dependencies\n\n**Question D: Base Branch**\nQuestion: \"Which base branch for PR?\"\nHeader: \"PR base\"\nOptions:\n  - main\n  - staging\n  - develop\n\nStore all task information for each agent.\n\n### Generate Task List File\n\nAfter collecting all agent task details:\n\n1. Ask for project name\n2. Generate task list in proper format\n3. Save to `.daisy/swarm/tasks.md`\n4. Show user the file path\n5. Proceed with launch using generated task list\n```\n\n## Best Practices\n\n### Question Writing\n\n1. **Be specific**: \"Which database?\" not \"Choose option?\"\n2. **Explain trade-offs**: Describe pros/cons in option descriptions\n3. **Provide context**: Question text should stand alone\n4. **Guide decisions**: Help user make informed choice\n5. **Keep concise**: Header max 12 chars, descriptions 1-2 sentences\n\n### Option Design\n\n1. **Meaningful labels**: Specific, clear names\n2. **Informative descriptions**: Explain what each option does\n3. **Show trade-offs**: Help user understand implications\n4. **Consistent detail**: All options equally explained\n5. **2-4 options**: Not too few, not too many\n\n### Flow Design\n\n1. **Logical order**: Questions flow naturally\n2. **Build on previous**: Later questions use earlier answers\n3. **Minimize questions**: Ask only what's needed\n4. **Group related**: Ask related questions together\n5. **Show progress**: Indicate where in flow\n\n### User Experience\n\n1. **Set expectations**: Tell user what to expect\n2. **Explain why**: Help user understand purpose\n3. **Provide defaults**: Suggest recommended options\n4. **Allow escape**: Let user cancel or restart\n5. **Confirm actions**: Summarize before executing\n\n## Common Patterns\n\n### Pattern: Feature Selection\n\n```markdown\nUse AskUserQuestion:\n\nQuestion: \"Which features do you need?\"\nHeader: \"Features\"\nmultiSelect: true\nOptions:\n  - Authentication\n  - Authorization\n  - Rate Limiting\n  - Caching\n```\n\n### Pattern: Environment Configuration\n\n```markdown\nUse AskUserQuestion:\n\nQuestion: \"Which environment is this?\"\nHeader: \"Environment\"\nOptions:\n  - Development (Local development)\n  - Staging (Pre-production testing)\n  - Production (Live environment)\n```\n\n### Pattern: Priority Selection\n\n```markdown\nUse AskUserQuestion:\n\nQuestion: \"What's the priority for this task?\"\nHeader: \"Priority\"\nOptions:\n  - Critical (Must be done immediately)\n  - High (Important, do soon)\n  - Medium (Standard priority)\n  - Low (Nice to have)\n```\n\n### Pattern: Scope Selection\n\n```markdown\nUse AskUserQuestion:\n\nQuestion: \"What scope should we analyze?\"\nHeader: \"Scope\"\nOptions:\n  - Current file (Just this file)\n  - Current directory (All files in directory)\n  - Entire project (Full codebase scan)\n```\n\n## Combining Arguments and Questions\n\n### Use Both Appropriately\n\n**Arguments for known values:**\n```markdown\n---\nargument-hint: [project-name]\nallowed-tools: AskUserQuestion, Write\n---\n\nSetup for project: $1\n\nNow gather additional configuration...\n\nUse AskUserQuestion for options that require explanation.\n```\n\n**Questions for complex choices:**\n```markdown\nProject name from argument: $1\n\nNow use AskUserQuestion to choose:\n- Architecture pattern\n- Technology stack\n- Deployment strategy\n\nThese require explanation, so questions work better than arguments.\n```\n\n## Troubleshooting\n\n**Questions not appearing:**\n- Verify AskUserQuestion in allowed-tools\n- Check question format is correct\n- Ensure options array has 2-4 items\n\n**User can't make selection:**\n- Check option labels are clear\n- Verify descriptions are helpful\n- Consider if too many options\n- Ensure multiSelect setting is correct\n\n**Flow feels confusing:**\n- Reduce number of questions\n- Group related questions\n- Add explanation between stages\n- Show progress through workflow\n\nWith AskUserQuestion, commands become interactive wizards that guide users through complex decisions while maintaining the clarity that simple arguments provide for straightforward inputs.\n",
        "plugins/plugin-dev/skills/command-development/references/marketplace-considerations.md": "# Marketplace Considerations for Commands\n\nGuidelines for creating commands designed for distribution and marketplace success.\n\n## Overview\n\nCommands distributed through marketplaces need additional consideration beyond personal use commands. They must work across environments, handle diverse use cases, and provide excellent user experience for unknown users.\n\n## Design for Distribution\n\n### Universal Compatibility\n\n**Cross-platform considerations:**\n\n```markdown\n---\ndescription: Cross-platform command\nallowed-tools: Bash(*)\n---\n\n# Platform-Aware Command\n\nDetecting platform...\n\ncase \"$(uname)\" in\n  Darwin*)  PLATFORM=\"macOS\" ;;\n  Linux*)   PLATFORM=\"Linux\" ;;\n  MINGW*|MSYS*|CYGWIN*) PLATFORM=\"Windows\" ;;\n  *)        PLATFORM=\"Unknown\" ;;\nesac\n\nPlatform: $PLATFORM\n\n<!-- Adjust behavior based on platform -->\nif [ \"$PLATFORM\" = \"Windows\" ]; then\n  # Windows-specific handling\n  PATH_SEP=\"\\\\\"\n  NULL_DEVICE=\"NUL\"\nelse\n  # Unix-like handling\n  PATH_SEP=\"/\"\n  NULL_DEVICE=\"/dev/null\"\nfi\n\n[Platform-appropriate implementation...]\n```\n\n**Avoid platform-specific commands:**\n\n```markdown\n<!-- BAD: macOS-specific -->\nBANG`pbcopy < file.txt`\n\n<!-- GOOD: Platform detection -->\nif command -v pbcopy > /dev/null; then\n  pbcopy < file.txt\nelif command -v xclip > /dev/null; then\n  xclip -selection clipboard < file.txt\nelif command -v clip.exe > /dev/null; then\n  cat file.txt | clip.exe\nelse\n  echo \"Clipboard not available on this platform\"\nfi\n```\n\n### Minimal Dependencies\n\n**Check for required tools:**\n\n```markdown\n---\ndescription: Dependency-aware command\nallowed-tools: Bash(*)\n---\n\n# Check Dependencies\n\nRequired tools:\n- git\n- jq\n- node\n\nChecking availability...\n\nMISSING_DEPS=\"\"\n\nfor tool in git jq node; do\n  if ! command -v $tool > /dev/null; then\n    MISSING_DEPS=\"$MISSING_DEPS $tool\"\n  fi\ndone\n\nif [ -n \"$MISSING_DEPS\" ]; then\n  âŒ ERROR: Missing required dependencies:$MISSING_DEPS\n\n  INSTALLATION:\n  - git: https://git-scm.com/downloads\n  - jq: https://stedolan.github.io/jq/download/\n  - node: https://nodejs.org/\n\n  Install missing tools and try again.\n\n  Exit.\nfi\n\nâœ“ All dependencies available\n\n[Continue with command...]\n```\n\n**Document optional dependencies:**\n\n```markdown\n<!--\nDEPENDENCIES:\n  Required:\n  - git 2.0+: Version control\n  - jq 1.6+: JSON processing\n\n  Optional:\n  - gh: GitHub CLI (for PR operations)\n  - docker: Container operations (for containerized tests)\n\n  Feature availability depends on installed tools.\n-->\n```\n\n### Graceful Degradation\n\n**Handle missing features:**\n\n```markdown\n---\ndescription: Feature-aware command\n---\n\n# Feature Detection\n\nDetecting available features...\n\nFEATURES=\"\"\n\nif command -v gh > /dev/null; then\n  FEATURES=\"$FEATURES github\"\nfi\n\nif command -v docker > /dev/null; then\n  FEATURES=\"$FEATURES docker\"\nfi\n\nAvailable features: $FEATURES\n\nif echo \"$FEATURES\" | grep -q \"github\"; then\n  # Full functionality with GitHub integration\n  echo \"âœ“ GitHub integration available\"\nelse\n  # Reduced functionality without GitHub\n  echo \"âš  Limited functionality: GitHub CLI not installed\"\n  echo \"  Install 'gh' for full features\"\nfi\n\n[Adapt behavior based on available features...]\n```\n\n## User Experience for Unknown Users\n\n### Clear Onboarding\n\n**First-run experience:**\n\n```markdown\n---\ndescription: Command with onboarding\nallowed-tools: Read, Write\n---\n\n# First Run Check\n\nif [ ! -f \".claude/command-initialized\" ]; then\n  **Welcome to Command Name!**\n\n  This appears to be your first time using this command.\n\n  WHAT THIS COMMAND DOES:\n  [Brief explanation of purpose and benefits]\n\n  QUICK START:\n  1. Basic usage: /command [arg]\n  2. For help: /command help\n  3. Examples: /command examples\n\n  SETUP:\n  No additional setup required. You're ready to go!\n\n  âœ“ Initialization complete\n\n  [Create initialization marker]\n\n  Ready to proceed with your request...\nfi\n\n[Normal command execution...]\n```\n\n**Progressive feature discovery:**\n\n```markdown\n---\ndescription: Command with tips\n---\n\n# Command Execution\n\n[Main functionality...]\n\n---\n\nðŸ’¡ TIP: Did you know?\n\nYou can speed up this command with the --fast flag:\n  /command --fast [args]\n\nFor more tips: /command tips\n```\n\n### Comprehensive Error Handling\n\n**Anticipate user mistakes:**\n\n```markdown\n---\ndescription: Forgiving command\n---\n\n# User Input Handling\n\nArgument: \"$1\"\n\n<!-- Check for common typos -->\nif [ \"$1\" = \"hlep\" ] || [ \"$1\" = \"hepl\" ]; then\n  Did you mean: help?\n\n  Showing help instead...\n  [Display help]\n\n  Exit.\nfi\n\n<!-- Suggest similar commands if not found -->\nif [ \"$1\" != \"valid-option1\" ] && [ \"$1\" != \"valid-option2\" ]; then\n  âŒ Unknown option: $1\n\n  Did you mean:\n  - valid-option1 (most similar)\n  - valid-option2\n\n  For all options: /command help\n\n  Exit.\nfi\n\n[Command continues...]\n```\n\n**Helpful diagnostics:**\n\n```markdown\n---\ndescription: Diagnostic command\n---\n\n# Operation Failed\n\nThe operation could not complete.\n\n**Diagnostic Information:**\n\nEnvironment:\n- Platform: $(uname)\n- Shell: $SHELL\n- Working directory: $(pwd)\n- Command: /command $@\n\nChecking common issues:\n- Git repository: $(git rev-parse --git-dir 2>&1)\n- Write permissions: $(test -w . && echo \"OK\" || echo \"DENIED\")\n- Required files: $(test -f config.yml && echo \"Found\" || echo \"Missing\")\n\nThis information helps debug the issue.\n\nFor support, include the above diagnostics.\n```\n\n## Distribution Best Practices\n\n### Namespace Awareness\n\n**Avoid name collisions:**\n\n```markdown\n---\ndescription: Namespaced command\n---\n\n<!--\nCOMMAND NAME: plugin-name-command\n\nThis command is namespaced with the plugin name to avoid\nconflicts with commands from other plugins.\n\nAlternative naming approaches:\n- Use plugin prefix: /plugin-command\n- Use category: /category-command\n- Use verb-noun: /verb-noun\n\nChosen approach: plugin-name prefix\nReasoning: Clearest ownership, least likely to conflict\n-->\n\n# Plugin Name Command\n\n[Implementation...]\n```\n\n**Document naming rationale:**\n\n```markdown\n<!--\nNAMING DECISION:\n\nCommand name: /deploy-app\n\nAlternatives considered:\n- /deploy: Too generic, likely conflicts\n- /app-deploy: Less intuitive ordering\n- /my-plugin-deploy: Too verbose\n\nFinal choice balances:\n- Discoverability (clear purpose)\n- Brevity (easy to type)\n- Uniqueness (unlikely conflicts)\n-->\n```\n\n### Configurability\n\n**User preferences:**\n\n```markdown\n---\ndescription: Configurable command\nallowed-tools: Read\n---\n\n# Load User Configuration\n\nDefault configuration:\n- verbose: false\n- color: true\n- max_results: 10\n\nChecking for user config: .claude/plugin-name.local.md\n\nif [ -f \".claude/plugin-name.local.md\" ]; then\n  # Parse YAML frontmatter for settings\n  VERBOSE=$(grep \"^verbose:\" .claude/plugin-name.local.md | cut -d: -f2 | tr -d ' ')\n  COLOR=$(grep \"^color:\" .claude/plugin-name.local.md | cut -d: -f2 | tr -d ' ')\n  MAX_RESULTS=$(grep \"^max_results:\" .claude/plugin-name.local.md | cut -d: -f2 | tr -d ' ')\n\n  echo \"âœ“ Using user configuration\"\nelse\n  echo \"Using default configuration\"\n  echo \"Create .claude/plugin-name.local.md to customize\"\nfi\n\n[Use configuration in command...]\n```\n\n**Sensible defaults:**\n\n```markdown\n---\ndescription: Command with smart defaults\n---\n\n# Smart Defaults\n\nConfiguration:\n- Format: ${FORMAT:-json}  # Defaults to json\n- Output: ${OUTPUT:-stdout}  # Defaults to stdout\n- Verbose: ${VERBOSE:-false}  # Defaults to false\n\nThese defaults work for 80% of use cases.\n\nOverride with arguments:\n  /command --format yaml --output file.txt --verbose\n\nOr set in .claude/plugin-name.local.md:\n\\`\\`\\`yaml\n---\nformat: yaml\noutput: custom.txt\nverbose: true\n---\n\\`\\`\\`\n```\n\n### Version Compatibility\n\n**Version checking:**\n\n```markdown\n---\ndescription: Version-aware command\n---\n\n<!--\nCOMMAND VERSION: 2.1.0\n\nCOMPATIBILITY:\n- Requires plugin version: >= 2.0.0\n- Breaking changes from v1.x documented in MIGRATION.md\n\nVERSION HISTORY:\n- v2.1.0: Added --new-feature flag\n- v2.0.0: BREAKING: Changed argument order\n- v1.0.0: Initial release\n-->\n\n# Version Check\n\nCommand version: 2.1.0\nPlugin version: [detect from plugin.json]\n\nif [  \"$PLUGIN_VERSION\" < \"2.0.0\" ]; then\n  âŒ ERROR: Incompatible plugin version\n\n  This command requires plugin version >= 2.0.0\n  Current version: $PLUGIN_VERSION\n\n  Update plugin:\n    /plugin update plugin-name\n\n  Exit.\nfi\n\nâœ“ Version compatible\n\n[Command continues...]\n```\n\n**Deprecation warnings:**\n\n```markdown\n---\ndescription: Command with deprecation warnings\n---\n\n# Deprecation Check\n\nif [ \"$1\" = \"--old-flag\" ]; then\n  âš ï¸  DEPRECATION WARNING\n\n  The --old-flag option is deprecated as of v2.0.0\n  It will be removed in v3.0.0 (est. June 2025)\n\n  Use instead: --new-flag\n\n  Example:\n    Old: /command --old-flag value\n    New: /command --new-flag value\n\n  See migration guide: /command migrate\n\n  Continuing with deprecated behavior for now...\nfi\n\n[Handle both old and new flags during deprecation period...]\n```\n\n## Marketplace Presentation\n\n### Command Discovery\n\n**Descriptive naming:**\n\n```markdown\n---\ndescription: Review pull request with security and quality checks\n---\n\n<!-- GOOD: Descriptive name and description -->\n```\n\n```markdown\n---\ndescription: Do the thing\n---\n\n<!-- BAD: Vague description -->\n```\n\n**Searchable keywords:**\n\n```markdown\n<!--\nKEYWORDS: security, code-review, quality, validation, audit\n\nThese keywords help users discover this command when searching\nfor related functionality in the marketplace.\n-->\n```\n\n### Showcase Examples\n\n**Compelling demonstrations:**\n\n```markdown\n---\ndescription: Advanced code analysis command\n---\n\n# Code Analysis Command\n\nThis command performs deep code analysis with actionable insights.\n\n## Demo: Quick Security Audit\n\nTry it now:\n\\`\\`\\`\n/analyze-code src/ --security\n\\`\\`\\`\n\n**What you'll get:**\n- Security vulnerability detection\n- Code quality metrics\n- Performance bottleneck identification\n- Actionable recommendations\n\n**Sample output:**\n\\`\\`\\`\nSecurity Analysis Results\n=========================\n\nðŸ”´ Critical (2):\n  - SQL injection risk in users.js:45\n  - XSS vulnerability in display.js:23\n\nðŸŸ¡ Warnings (5):\n  - Unvalidated input in api.js:67\n  ...\n\nRecommendations:\n1. Fix critical issues immediately\n2. Review warnings before next release\n3. Run /analyze-code --fix for auto-fixes\n\\`\\`\\`\n\n---\n\nReady to analyze your code...\n\n[Command implementation...]\n```\n\n### User Reviews and Feedback\n\n**Feedback mechanism:**\n\n```markdown\n---\ndescription: Command with feedback\n---\n\n# Command Complete\n\n[Command results...]\n\n---\n\n**How was your experience?**\n\nThis helps improve the command for everyone.\n\nRate this command:\n- ðŸ‘ Helpful\n- ðŸ‘Ž Not helpful\n- ðŸ› Found a bug\n- ðŸ’¡ Have a suggestion\n\nReply with an emoji or:\n- /command feedback\n\nYour feedback matters!\n```\n\n**Usage analytics preparation:**\n\n```markdown\n<!--\nANALYTICS NOTES:\n\nTrack for improvement:\n- Most common arguments\n- Failure rates\n- Average execution time\n- User satisfaction scores\n\nPrivacy-preserving:\n- No personally identifiable information\n- Aggregate statistics only\n- User opt-out respected\n-->\n```\n\n## Quality Standards\n\n### Professional Polish\n\n**Consistent branding:**\n\n```markdown\n---\ndescription: Branded command\n---\n\n# âœ¨ Command Name\n\nPart of the [Plugin Name] suite\n\n[Command functionality...]\n\n---\n\n**Need Help?**\n- Documentation: https://docs.example.com\n- Support: support@example.com\n- Community: https://community.example.com\n\nPowered by Plugin Name v2.1.0\n```\n\n**Attention to detail:**\n\n```markdown\n<!-- Details that matter -->\n\nâœ“ Use proper emoji/symbols consistently\nâœ“ Align output columns neatly\nâœ“ Format numbers with thousands separators\nâœ“ Use color/formatting appropriately\nâœ“ Provide progress indicators\nâœ“ Show estimated time remaining\nâœ“ Confirm successful operations\n```\n\n### Reliability\n\n**Idempotency:**\n\n```markdown\n---\ndescription: Idempotent command\n---\n\n# Safe Repeated Execution\n\nChecking if operation already completed...\n\nif [ -f \".claude/operation-completed.flag\" ]; then\n  â„¹ï¸  Operation already completed\n\n  Completed at: $(cat .claude/operation-completed.flag)\n\n  To re-run:\n  1. Remove flag: rm .claude/operation-completed.flag\n  2. Run command again\n\n  Otherwise, no action needed.\n\n  Exit.\nfi\n\nPerforming operation...\n\n[Safe, repeatable operation...]\n\nMarking complete...\necho \"$(date)\" > .claude/operation-completed.flag\n```\n\n**Atomic operations:**\n\n```markdown\n---\ndescription: Atomic command\n---\n\n# Atomic Operation\n\nThis operation is atomic - either fully succeeds or fully fails.\n\nCreating temporary workspace...\nTEMP_DIR=$(mktemp -d)\n\nPerforming changes in isolated environment...\n[Make changes in $TEMP_DIR]\n\nif [ $? -eq 0 ]; then\n  âœ“ Changes validated\n\n  Applying changes atomically...\n  mv $TEMP_DIR/* ./target/\n\n  âœ“ Operation complete\nelse\n  âŒ Changes failed validation\n\n  Rolling back...\n  rm -rf $TEMP_DIR\n\n  No changes applied. Safe to retry.\nfi\n```\n\n## Testing for Distribution\n\n### Pre-Release Checklist\n\n```markdown\n<!--\nPRE-RELEASE CHECKLIST:\n\nFunctionality:\n- [ ] Works on macOS\n- [ ] Works on Linux\n- [ ] Works on Windows (WSL)\n- [ ] All arguments tested\n- [ ] Error cases handled\n- [ ] Edge cases covered\n\nUser Experience:\n- [ ] Clear description\n- [ ] Helpful error messages\n- [ ] Examples provided\n- [ ] First-run experience good\n- [ ] Documentation complete\n\nDistribution:\n- [ ] No hardcoded paths\n- [ ] Dependencies documented\n- [ ] Configuration options clear\n- [ ] Version number set\n- [ ] Changelog updated\n\nQuality:\n- [ ] No TODO comments\n- [ ] No debug code\n- [ ] Performance acceptable\n- [ ] Security reviewed\n- [ ] Privacy considered\n\nSupport:\n- [ ] README complete\n- [ ] Troubleshooting guide\n- [ ] Support contact provided\n- [ ] Feedback mechanism\n- [ ] License specified\n-->\n```\n\n### Beta Testing\n\n**Beta release approach:**\n\n```markdown\n---\ndescription: Beta command (v0.9.0)\n---\n\n# ðŸ§ª Beta Command\n\n**This is a beta release**\n\nFeatures may change based on feedback.\n\nBETA STATUS:\n- Version: 0.9.0\n- Stability: Experimental\n- Support: Limited\n- Feedback: Encouraged\n\nKnown limitations:\n- Performance not optimized\n- Some edge cases not handled\n- Documentation incomplete\n\nHelp improve this command:\n- Report issues: /command report-issue\n- Suggest features: /command suggest\n- Join beta testers: /command join-beta\n\n---\n\n[Command implementation...]\n\n---\n\n**Thank you for beta testing!**\n\nYour feedback helps make this command better.\n```\n\n## Maintenance and Updates\n\n### Update Strategy\n\n**Versioned commands:**\n\n```markdown\n<!--\nVERSION STRATEGY:\n\nMajor (X.0.0): Breaking changes\n- Document all breaking changes\n- Provide migration guide\n- Support old version briefly\n\nMinor (x.Y.0): New features\n- Backward compatible\n- Announce new features\n- Update examples\n\nPatch (x.y.Z): Bug fixes\n- No user-facing changes\n- Update changelog\n- Security fixes prioritized\n\nRelease schedule:\n- Patches: As needed\n- Minors: Monthly\n- Majors: Annually or as needed\n-->\n```\n\n**Update notifications:**\n\n```markdown\n---\ndescription: Update-aware command\n---\n\n# Check for Updates\n\nCurrent version: 2.1.0\nLatest version: [check if available]\n\nif [ \"$CURRENT_VERSION\" != \"$LATEST_VERSION\" ]; then\n  ðŸ“¢ UPDATE AVAILABLE\n\n  New version: $LATEST_VERSION\n  Current: $CURRENT_VERSION\n\n  What's new:\n  - Feature improvements\n  - Bug fixes\n  - Performance enhancements\n\n  Update with:\n    /plugin update plugin-name\n\n  Release notes: https://releases.example.com/v$LATEST_VERSION\nfi\n\n[Command continues...]\n```\n\n## Best Practices Summary\n\n### Distribution Design\n\n1. **Universal**: Works across platforms and environments\n2. **Self-contained**: Minimal dependencies, clear requirements\n3. **Graceful**: Degrades gracefully when features unavailable\n4. **Forgiving**: Anticipates and handles user mistakes\n5. **Helpful**: Clear errors, good defaults, excellent docs\n\n### Marketplace Success\n\n1. **Discoverable**: Clear name, good description, searchable keywords\n2. **Professional**: Polished presentation, consistent branding\n3. **Reliable**: Tested thoroughly, handles edge cases\n4. **Maintainable**: Versioned, updated regularly, supported\n5. **User-focused**: Great UX, responsive to feedback\n\n### Quality Standards\n\n1. **Complete**: Fully documented, all features working\n2. **Tested**: Works in real environments, edge cases handled\n3. **Secure**: No vulnerabilities, safe operations\n4. **Performant**: Reasonable speed, resource-efficient\n5. **Ethical**: Privacy-respecting, user consent\n\nWith these considerations, commands become marketplace-ready and delight users across diverse environments and use cases.\n",
        "plugins/plugin-dev/skills/command-development/references/plugin-features-reference.md": "# Plugin-Specific Command Features Reference\n\nThis reference covers features and patterns specific to commands bundled in Claude Code plugins.\n\n## Table of Contents\n\n- [Plugin Command Discovery](#plugin-command-discovery)\n- [CLAUDE_PLUGIN_ROOT Environment Variable](#claude_plugin_root-environment-variable)\n- [Plugin Command Patterns](#plugin-command-patterns)\n- [Integration with Plugin Components](#integration-with-plugin-components)\n- [Validation Patterns](#validation-patterns)\n\n## Plugin Command Discovery\n\n### Auto-Discovery\n\nClaude Code automatically discovers commands in plugins using the following locations:\n\n```\nplugin-name/\nâ”œâ”€â”€ commands/              # Auto-discovered commands\nâ”‚   â”œâ”€â”€ foo.md            # /foo (plugin:plugin-name)\nâ”‚   â””â”€â”€ bar.md            # /bar (plugin:plugin-name)\nâ””â”€â”€ plugin.json           # Plugin manifest\n```\n\n**Key points:**\n- Commands are discovered at plugin load time\n- No manual registration required\n- Commands appear in `/help` with \"(plugin:plugin-name)\" label\n- Subdirectories create namespaces\n\n### Namespaced Plugin Commands\n\nOrganize commands in subdirectories for logical grouping:\n\n```\nplugin-name/\nâ””â”€â”€ commands/\n    â”œâ”€â”€ review/\n    â”‚   â”œâ”€â”€ security.md    # /security (plugin:plugin-name:review)\n    â”‚   â””â”€â”€ style.md       # /style (plugin:plugin-name:review)\n    â””â”€â”€ deploy/\n        â”œâ”€â”€ staging.md     # /staging (plugin:plugin-name:deploy)\n        â””â”€â”€ prod.md        # /prod (plugin:plugin-name:deploy)\n```\n\n**Namespace behavior:**\n- Subdirectory name becomes namespace\n- Shown as \"(plugin:plugin-name:namespace)\" in `/help`\n- Helps organize related commands\n- Use when plugin has 5+ commands\n\n### Command Naming Conventions\n\n**Plugin command names should:**\n1. Be descriptive and action-oriented\n2. Avoid conflicts with common command names\n3. Use hyphens for multi-word names\n4. Consider prefixing with plugin name for uniqueness\n\n**Examples:**\n```\nGood:\n- /mylyn-sync          (plugin-specific prefix)\n- /analyze-performance (descriptive action)\n- /docker-compose-up   (clear purpose)\n\nAvoid:\n- /test               (conflicts with common name)\n- /run                (too generic)\n- /do-stuff           (not descriptive)\n```\n\n## CLAUDE_PLUGIN_ROOT Environment Variable\n\n### Purpose\n\n`${CLAUDE_PLUGIN_ROOT}` is a special environment variable available in plugin commands that resolves to the absolute path of the plugin directory.\n\n**Why it matters:**\n- Enables portable paths within plugin\n- Allows referencing plugin files and scripts\n- Works across different installations\n- Essential for multi-file plugin operations\n\n### Basic Usage\n\nReference files within your plugin:\n\n```markdown\n---\ndescription: Analyze using plugin script\nallowed-tools: Bash(node:*), Read\n---\n\nRun analysis: BANG`node ${CLAUDE_PLUGIN_ROOT}/scripts/analyze.js`\n\nRead template: @${CLAUDE_PLUGIN_ROOT}/templates/report.md\n```\n\n**Expands to:**\n```\nRun analysis: BANG`node /path/to/plugins/plugin-name/scripts/analyze.js`\n\nRead template: @/path/to/plugins/plugin-name/templates/report.md\n```\n\n### Common Patterns\n\n#### 1. Executing Plugin Scripts\n\n```markdown\n---\ndescription: Run custom linter from plugin\nallowed-tools: Bash(node:*)\n---\n\nLint results: BANG`node ${CLAUDE_PLUGIN_ROOT}/bin/lint.js $1`\n\nReview the linting output and suggest fixes.\n```\n\n#### 2. Loading Configuration Files\n\n```markdown\n---\ndescription: Deploy using plugin configuration\nallowed-tools: Read, Bash(*)\n---\n\nConfiguration: @${CLAUDE_PLUGIN_ROOT}/config/deploy-config.json\n\nDeploy application using the configuration above for $1 environment.\n```\n\n#### 3. Accessing Plugin Resources\n\n```markdown\n---\ndescription: Generate report from template\n---\n\nUse this template: @${CLAUDE_PLUGIN_ROOT}/templates/api-report.md\n\nGenerate a report for @$1 following the template format.\n```\n\n#### 4. Multi-Step Plugin Workflows\n\n```markdown\n---\ndescription: Complete plugin workflow\nallowed-tools: Bash(*), Read\n---\n\nStep 1 - Prepare: BANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/prepare.sh $1`\nStep 2 - Config: @${CLAUDE_PLUGIN_ROOT}/config/$1.json\nStep 3 - Execute: BANG`${CLAUDE_PLUGIN_ROOT}/bin/execute $1`\n\nReview results and report status.\n```\n\n### Best Practices\n\n1. **Always use for plugin-internal paths:**\n   ```markdown\n   # Good\n   @${CLAUDE_PLUGIN_ROOT}/templates/foo.md\n\n   # Bad\n   @./templates/foo.md  # Relative to current directory, not plugin\n   ```\n\n2. **Validate file existence:**\n   ```markdown\n   ---\n   description: Use plugin config if exists\n   allowed-tools: Bash(test:*), Read\n   ---\n\n   BANG`test -f ${CLAUDE_PLUGIN_ROOT}/config.json && echo \"exists\" || echo \"missing\"`\n\n   If config exists, load it: @${CLAUDE_PLUGIN_ROOT}/config.json\n   Otherwise, use defaults...\n   ```\n\n3. **Document plugin file structure:**\n   ```markdown\n   <!--\n   Plugin structure:\n   ${CLAUDE_PLUGIN_ROOT}/\n   â”œâ”€â”€ scripts/analyze.js  (analysis script)\n   â”œâ”€â”€ templates/          (report templates)\n   â””â”€â”€ config/             (configuration files)\n   -->\n   ```\n\n4. **Combine with arguments:**\n   ```markdown\n   Run: BANG`${CLAUDE_PLUGIN_ROOT}/bin/process.sh $1 $2`\n   ```\n\n### Troubleshooting\n\n**Variable not expanding:**\n- Ensure command is loaded from plugin\n- Check bash execution is allowed\n- Verify syntax is exact: `${CLAUDE_PLUGIN_ROOT}`\n\n**File not found errors:**\n- Verify file exists in plugin directory\n- Check file path is correct relative to plugin root\n- Ensure file permissions allow reading/execution\n\n**Path with spaces:**\n- Bash commands automatically handle spaces\n- File references work with spaces in paths\n- No special quoting needed\n\n## Plugin Command Patterns\n\n### Pattern 1: Configuration-Based Commands\n\nCommands that load plugin-specific configuration:\n\n```markdown\n---\ndescription: Deploy using plugin settings\nallowed-tools: Read, Bash(*)\n---\n\nLoad configuration: @${CLAUDE_PLUGIN_ROOT}/deploy-config.json\n\nDeploy to $1 environment using:\n1. Configuration settings above\n2. Current git branch: BANG`git branch --show-current`\n3. Application version: BANG`cat package.json | grep version`\n\nExecute deployment and monitor progress.\n```\n\n**When to use:** Commands that need consistent settings across invocations\n\n### Pattern 2: Template-Based Generation\n\nCommands that use plugin templates:\n\n```markdown\n---\ndescription: Generate documentation from template\nargument-hint: [component-name]\n---\n\nTemplate: @${CLAUDE_PLUGIN_ROOT}/templates/component-docs.md\n\nGenerate documentation for $1 component following the template structure.\nInclude:\n- Component purpose and usage\n- API reference\n- Examples\n- Testing guidelines\n```\n\n**When to use:** Standardized output generation\n\n### Pattern 3: Multi-Script Workflow\n\nCommands that orchestrate multiple plugin scripts:\n\n```markdown\n---\ndescription: Complete build and test workflow\nallowed-tools: Bash(*)\n---\n\nBuild: BANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/build.sh`\nValidate: BANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/validate.sh`\nTest: BANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/test.sh`\n\nReview all outputs and report:\n1. Build status\n2. Validation results\n3. Test results\n4. Recommended next steps\n```\n\n**When to use:** Complex plugin workflows with multiple steps\n\n### Pattern 4: Environment-Aware Commands\n\nCommands that adapt to environment:\n\n```markdown\n---\ndescription: Deploy based on environment\nargument-hint: [dev|staging|prod]\n---\n\nEnvironment config: @${CLAUDE_PLUGIN_ROOT}/config/$1.json\n\nEnvironment check: BANG`echo \"Deploying to: $1\"`\n\nDeploy application using $1 environment configuration.\nVerify deployment and run smoke tests.\n```\n\n**When to use:** Commands that behave differently per environment\n\n### Pattern 5: Plugin Data Management\n\nCommands that manage plugin-specific data:\n\n```markdown\n---\ndescription: Save analysis results to plugin cache\nallowed-tools: Bash(*), Read, Write\n---\n\nCache directory: ${CLAUDE_PLUGIN_ROOT}/cache/\n\nAnalyze @$1 and save results to cache:\nBANG`mkdir -p ${CLAUDE_PLUGIN_ROOT}/cache && date > ${CLAUDE_PLUGIN_ROOT}/cache/last-run.txt`\n\nStore analysis for future reference and comparison.\n```\n\n**When to use:** Commands that need persistent data storage\n\n## Integration with Plugin Components\n\n### Invoking Plugin Agents\n\nCommands can trigger plugin agents using the Task tool:\n\n```markdown\n---\ndescription: Deep analysis using plugin agent\nargument-hint: [file-path]\n---\n\nInitiate deep code analysis of @$1 using the code-analyzer agent.\n\nThe agent will:\n1. Analyze code structure\n2. Identify patterns\n3. Suggest improvements\n4. Generate detailed report\n\nNote: This uses the Task tool to launch the plugin's code-analyzer agent.\n```\n\n**Key points:**\n- Agent must be defined in plugin's `agents/` directory\n- Claude will automatically use Task tool to launch agent\n- Agent has access to same plugin resources\n\n### Invoking Plugin Skills\n\nCommands can reference plugin skills for specialized knowledge:\n\n```markdown\n---\ndescription: API documentation with best practices\nargument-hint: [api-file]\n---\n\nDocument the API in @$1 following our API documentation standards.\n\nUse the api-docs-standards skill to ensure documentation includes:\n- Endpoint descriptions\n- Parameter specifications\n- Response formats\n- Error codes\n- Usage examples\n\nNote: This leverages the plugin's api-docs-standards skill for consistency.\n```\n\n**Key points:**\n- Skill must be defined in plugin's `skills/` directory\n- Mention skill by name to hint Claude should invoke it\n- Skills provide specialized domain knowledge\n\n### Coordinating with Plugin Hooks\n\nCommands can be designed to work with plugin hooks:\n\n```markdown\n---\ndescription: Commit with pre-commit validation\nallowed-tools: Bash(git:*)\n---\n\nStage changes: !\\`git add $1\\`\n\nCommit changes: !\\`git commit -m \"$2\"\\`\n\nNote: This commit will trigger the plugin's pre-commit hook for validation.\nReview hook output for any issues.\n```\n\n**Key points:**\n- Hooks execute automatically on events\n- Commands can prepare state for hooks\n- Document hook interaction in command\n\n### Multi-Component Plugin Commands\n\nCommands that coordinate multiple plugin components:\n\n```markdown\n---\ndescription: Comprehensive code review workflow\nargument-hint: [file-path]\n---\n\nFile to review: @$1\n\nExecute comprehensive review:\n\n1. **Static Analysis** (via plugin scripts)\n   BANG`node ${CLAUDE_PLUGIN_ROOT}/scripts/lint.js $1`\n\n2. **Deep Review** (via plugin agent)\n   Launch the code-reviewer agent for detailed analysis.\n\n3. **Best Practices** (via plugin skill)\n   Use the code-standards skill to ensure compliance.\n\n4. **Documentation** (via plugin template)\n   Template: @${CLAUDE_PLUGIN_ROOT}/templates/review-report.md\n\nGenerate final report combining all outputs.\n```\n\n**When to use:** Complex workflows leveraging multiple plugin capabilities\n\n## Validation Patterns\n\n### Input Validation\n\nCommands should validate inputs before processing:\n\n```markdown\n---\ndescription: Deploy to environment with validation\nargument-hint: [environment]\n---\n\nValidate environment: BANG`echo \"$1\" | grep -E \"^(dev|staging|prod)$\" || echo \"INVALID\"`\n\n$IF($1 in [dev, staging, prod],\n  Deploy to $1 environment using validated configuration,\n  ERROR: Invalid environment '$1'. Must be one of: dev, staging, prod\n)\n```\n\n**Validation approaches:**\n1. Bash validation using grep/test\n2. Inline validation in prompt\n3. Script-based validation\n\n### File Existence Checks\n\nVerify required files exist:\n\n```markdown\n---\ndescription: Process configuration file\nargument-hint: [config-file]\n---\n\nCheck file: BANG`test -f $1 && echo \"EXISTS\" || echo \"MISSING\"`\n\nProcess configuration if file exists: @$1\n\nIf file doesn't exist, explain:\n- Expected location\n- Required format\n- How to create it\n```\n\n### Required Arguments\n\nValidate required arguments provided:\n\n```markdown\n---\ndescription: Create deployment with version\nargument-hint: [environment] [version]\n---\n\nValidate inputs: BANG`test -n \"$1\" -a -n \"$2\" && echo \"OK\" || echo \"MISSING\"`\n\n$IF($1 AND $2,\n  Deploy version $2 to $1 environment,\n  ERROR: Both environment and version required. Usage: /deploy [env] [version]\n)\n```\n\n### Plugin Resource Validation\n\nVerify plugin resources available:\n\n```markdown\n---\ndescription: Run analysis with plugin tools\nallowed-tools: Bash(test:*)\n---\n\nValidate plugin setup:\n- Config exists: BANG`test -f ${CLAUDE_PLUGIN_ROOT}/config.json && echo \"âœ“\" || echo \"âœ—\"`\n- Scripts exist: BANG`test -d ${CLAUDE_PLUGIN_ROOT}/scripts && echo \"âœ“\" || echo \"âœ—\"`\n- Tools available: BANG`test -x ${CLAUDE_PLUGIN_ROOT}/bin/analyze && echo \"âœ“\" || echo \"âœ—\"`\n\nIf all checks pass, proceed with analysis.\nOtherwise, report missing components and installation steps.\n```\n\n### Output Validation\n\nValidate command execution results:\n\n```markdown\n---\ndescription: Build and validate output\nallowed-tools: Bash(*)\n---\n\nBuild: BANG`bash ${CLAUDE_PLUGIN_ROOT}/scripts/build.sh`\n\nValidate output:\n- Exit code: BANG`echo $?`\n- Output exists: BANG`test -d dist && echo \"âœ“\" || echo \"âœ—\"`\n- File count: BANG`find dist -type f | wc -l`\n\nReport build status and any validation failures.\n```\n\n### Graceful Error Handling\n\nHandle errors gracefully with helpful messages:\n\n```markdown\n---\ndescription: Process file with error handling\nargument-hint: [file-path]\n---\n\nTry processing: BANG`node ${CLAUDE_PLUGIN_ROOT}/scripts/process.js $1 2>&1 || echo \"ERROR: $?\"`\n\nIf processing succeeded:\n- Report results\n- Suggest next steps\n\nIf processing failed:\n- Explain likely causes\n- Provide troubleshooting steps\n- Suggest alternative approaches\n```\n\n## Best Practices Summary\n\n### Plugin Commands Should:\n\n1. **Use ${CLAUDE_PLUGIN_ROOT} for all plugin-internal paths**\n   - Scripts, templates, configuration, resources\n\n2. **Validate inputs early**\n   - Check required arguments\n   - Verify file existence\n   - Validate argument formats\n\n3. **Document plugin structure**\n   - Explain required files\n   - Document script purposes\n   - Clarify dependencies\n\n4. **Integrate with plugin components**\n   - Reference agents for complex tasks\n   - Use skills for specialized knowledge\n   - Coordinate with hooks when relevant\n\n5. **Provide helpful error messages**\n   - Explain what went wrong\n   - Suggest how to fix\n   - Offer alternatives\n\n6. **Handle edge cases**\n   - Missing files\n   - Invalid arguments\n   - Failed script execution\n   - Missing dependencies\n\n7. **Keep commands focused**\n   - One clear purpose per command\n   - Delegate complex logic to scripts\n   - Use agents for multi-step workflows\n\n8. **Test across installations**\n   - Verify paths work everywhere\n   - Test with different arguments\n   - Validate error cases\n\n---\n\nFor general command development, see main SKILL.md.\nFor command examples, see examples/ directory.\n",
        "plugins/plugin-dev/skills/command-development/references/testing-strategies.md": "# Command Testing Strategies\n\nComprehensive strategies for testing slash commands before deployment and distribution.\n\n## Overview\n\nTesting commands ensures they work correctly, handle edge cases, and provide good user experience. A systematic testing approach catches issues early and builds confidence in command reliability.\n\n## Testing Levels\n\n### Level 1: Syntax and Structure Validation\n\n**What to test:**\n- YAML frontmatter syntax\n- Markdown format\n- File location and naming\n\n**How to test:**\n\n```bash\n# Validate YAML frontmatter\nhead -n 20 .claude/commands/my-command.md | grep -A 10 \"^---\"\n\n# Check for closing frontmatter marker\nhead -n 20 .claude/commands/my-command.md | grep -c \"^---\" # Should be 2\n\n# Verify file has .md extension\nls .claude/commands/*.md\n\n# Check file is in correct location\ntest -f .claude/commands/my-command.md && echo \"Found\" || echo \"Missing\"\n```\n\n**Automated validation script:**\n\n```bash\n#!/bin/bash\n# validate-command.sh\n\nCOMMAND_FILE=\"$1\"\n\nif [ ! -f \"$COMMAND_FILE\" ]; then\n  echo \"ERROR: File not found: $COMMAND_FILE\"\n  exit 1\nfi\n\n# Check .md extension\nif [[ ! \"$COMMAND_FILE\" =~ \\.md$ ]]; then\n  echo \"ERROR: File must have .md extension\"\n  exit 1\nfi\n\n# Validate YAML frontmatter if present\nif head -n 1 \"$COMMAND_FILE\" | grep -q \"^---\"; then\n  # Count frontmatter markers\n  MARKERS=$(head -n 50 \"$COMMAND_FILE\" | grep -c \"^---\")\n  if [ \"$MARKERS\" -ne 2 ]; then\n    echo \"ERROR: Invalid YAML frontmatter (need exactly 2 '---' markers)\"\n    exit 1\n  fi\n  echo \"âœ“ YAML frontmatter syntax valid\"\nfi\n\n# Check for empty file\nif [ ! -s \"$COMMAND_FILE\" ]; then\n  echo \"ERROR: File is empty\"\n  exit 1\nfi\n\necho \"âœ“ Command file structure valid\"\n```\n\n### Level 2: Frontmatter Field Validation\n\n**What to test:**\n- Field types correct\n- Values in valid ranges\n- Required fields present (if any)\n\n**Validation script:**\n\n```bash\n#!/bin/bash\n# validate-frontmatter.sh\n\nCOMMAND_FILE=\"$1\"\n\n# Extract YAML frontmatter\nFRONTMATTER=$(sed -n '/^---$/,/^---$/p' \"$COMMAND_FILE\" | sed '1d;$d')\n\nif [ -z \"$FRONTMATTER\" ]; then\n  echo \"No frontmatter to validate\"\n  exit 0\nfi\n\n# Check 'model' field if present\nif echo \"$FRONTMATTER\" | grep -q \"^model:\"; then\n  MODEL=$(echo \"$FRONTMATTER\" | grep \"^model:\" | cut -d: -f2 | tr -d ' ')\n  if ! echo \"sonnet opus haiku\" | grep -qw \"$MODEL\"; then\n    echo \"ERROR: Invalid model '$MODEL' (must be sonnet, opus, or haiku)\"\n    exit 1\n  fi\n  echo \"âœ“ Model field valid: $MODEL\"\nfi\n\n# Check 'allowed-tools' field format\nif echo \"$FRONTMATTER\" | grep -q \"^allowed-tools:\"; then\n  echo \"âœ“ allowed-tools field present\"\n  # Could add more sophisticated validation here\nfi\n\n# Check 'description' length\nif echo \"$FRONTMATTER\" | grep -q \"^description:\"; then\n  DESC=$(echo \"$FRONTMATTER\" | grep \"^description:\" | cut -d: -f2-)\n  LENGTH=${#DESC}\n  if [ \"$LENGTH\" -gt 80 ]; then\n    echo \"WARNING: Description length $LENGTH (recommend < 60 chars)\"\n  else\n    echo \"âœ“ Description length acceptable: $LENGTH chars\"\n  fi\nfi\n\necho \"âœ“ Frontmatter fields valid\"\n```\n\n### Level 3: Manual Command Invocation\n\n**What to test:**\n- Command appears in `/help`\n- Command executes without errors\n- Output is as expected\n\n**Test procedure:**\n\n```bash\n# 1. Start Claude Code\nclaude --debug\n\n# 2. Check command appears in help\n> /help\n# Look for your command in the list\n\n# 3. Invoke command without arguments\n> /my-command\n# Check for reasonable error or behavior\n\n# 4. Invoke with valid arguments\n> /my-command arg1 arg2\n# Verify expected behavior\n\n# 5. Check debug logs\ntail -f ~/.claude/debug-logs/latest\n# Look for errors or warnings\n```\n\n### Level 4: Argument Testing\n\n**What to test:**\n- Positional arguments work ($1, $2, etc.)\n- $ARGUMENTS captures all arguments\n- Missing arguments handled gracefully\n- Invalid arguments detected\n\n**Test matrix:**\n\n| Test Case | Command | Expected Result |\n|-----------|---------|-----------------|\n| No args | `/cmd` | Graceful handling or useful message |\n| One arg | `/cmd arg1` | $1 substituted correctly |\n| Two args | `/cmd arg1 arg2` | $1 and $2 substituted |\n| Extra args | `/cmd a b c d` | All captured or extras ignored appropriately |\n| Special chars | `/cmd \"arg with spaces\"` | Quotes handled correctly |\n| Empty arg | `/cmd \"\"` | Empty string handled |\n\n**Test script:**\n\n```bash\n#!/bin/bash\n# test-command-arguments.sh\n\nCOMMAND=\"$1\"\n\necho \"Testing argument handling for /$COMMAND\"\necho\n\necho \"Test 1: No arguments\"\necho \"  Command: /$COMMAND\"\necho \"  Expected: [describe expected behavior]\"\necho \"  Manual test required\"\necho\n\necho \"Test 2: Single argument\"\necho \"  Command: /$COMMAND test-value\"\necho \"  Expected: 'test-value' appears in output\"\necho \"  Manual test required\"\necho\n\necho \"Test 3: Multiple arguments\"\necho \"  Command: /$COMMAND arg1 arg2 arg3\"\necho \"  Expected: All arguments used appropriately\"\necho \"  Manual test required\"\necho\n\necho \"Test 4: Special characters\"\necho \"  Command: /$COMMAND \\\"value with spaces\\\"\"\necho \"  Expected: Entire phrase captured\"\necho \"  Manual test required\"\n```\n\n### Level 5: File Reference Testing\n\n**What to test:**\n- @ syntax loads file contents\n- Non-existent files handled\n- Large files handled appropriately\n- Multiple file references work\n\n**Test procedure:**\n\n```bash\n# Create test files\necho \"Test content\" > /tmp/test-file.txt\necho \"Second file\" > /tmp/test-file-2.txt\n\n# Test single file reference\n> /my-command /tmp/test-file.txt\n# Verify file content is read\n\n# Test non-existent file\n> /my-command /tmp/nonexistent.txt\n# Verify graceful error handling\n\n# Test multiple files\n> /my-command /tmp/test-file.txt /tmp/test-file-2.txt\n# Verify both files processed\n\n# Test large file\ndd if=/dev/zero of=/tmp/large-file.bin bs=1M count=100\n> /my-command /tmp/large-file.bin\n# Verify reasonable behavior (may truncate or warn)\n\n# Cleanup\nrm /tmp/test-file*.txt /tmp/large-file.bin\n```\n\n### Level 6: Bash Execution Testing\n\n**What to test:**\n- BANG` commands execute correctly\n- Command output included in prompt\n- Command failures handled\n- Security: only allowed commands run\n\n**Test procedure:**\n\n```bash\n# Create test command with bash execution\ncat > .claude/commands/test-bash.md << 'EOF'\n---\ndescription: Test bash execution\nallowed-tools: Bash(echo:*), Bash(date:*)\n---\n\nCurrent date: BANG`date`\nTest output: BANG`echo \"Hello from bash\"`\n\nAnalysis of output above...\nEOF\n\n# Test in Claude Code\n> /test-bash\n# Verify:\n# 1. Date appears correctly\n# 2. Echo output appears\n# 3. No errors in debug logs\n\n# Test with disallowed command (should fail or be blocked)\ncat > .claude/commands/test-forbidden.md << 'EOF'\n---\ndescription: Test forbidden command\nallowed-tools: Bash(echo:*)\n---\n\nTrying forbidden: BANG`ls -la /`\nEOF\n\n> /test-forbidden\n# Verify: Permission denied or appropriate error\n```\n\n### Level 7: Integration Testing\n\n**What to test:**\n- Commands work with other plugin components\n- Commands interact correctly with each other\n- State management works across invocations\n- Workflow commands execute in sequence\n\n**Test scenarios:**\n\n**Scenario 1: Command + Hook Integration**\n\n```bash\n# Setup: Command that triggers a hook\n# Test: Invoke command, verify hook executes\n\n# Command: .claude/commands/risky-operation.md\n# Hook: PreToolUse that validates the operation\n\n> /risky-operation\n# Verify: Hook executes and validates before command completes\n```\n\n**Scenario 2: Command Sequence**\n\n```bash\n# Setup: Multi-command workflow\n> /workflow-init\n# Verify: State file created\n\n> /workflow-step2\n# Verify: State file read, step 2 executes\n\n> /workflow-complete\n# Verify: State file cleaned up\n```\n\n**Scenario 3: Command + MCP Integration**\n\n```bash\n# Setup: Command uses MCP tools\n# Test: Verify MCP server accessible\n\n> /mcp-command\n# Verify:\n# 1. MCP server starts (if stdio)\n# 2. Tool calls succeed\n# 3. Results included in output\n```\n\n## Automated Testing Approaches\n\n### Command Test Suite\n\nCreate a test suite script:\n\n```bash\n#!/bin/bash\n# test-commands.sh - Command test suite\n\nTEST_DIR=\".claude/commands\"\nFAILED_TESTS=0\n\necho \"Command Test Suite\"\necho \"==================\"\necho\n\nfor cmd_file in \"$TEST_DIR\"/*.md; do\n  cmd_name=$(basename \"$cmd_file\" .md)\n  echo \"Testing: $cmd_name\"\n\n  # Validate structure\n  if ./validate-command.sh \"$cmd_file\"; then\n    echo \"  âœ“ Structure valid\"\n  else\n    echo \"  âœ— Structure invalid\"\n    ((FAILED_TESTS++))\n  fi\n\n  # Validate frontmatter\n  if ./validate-frontmatter.sh \"$cmd_file\"; then\n    echo \"  âœ“ Frontmatter valid\"\n  else\n    echo \"  âœ— Frontmatter invalid\"\n    ((FAILED_TESTS++))\n  fi\n\n  echo\ndone\n\necho \"==================\"\necho \"Tests complete\"\necho \"Failed: $FAILED_TESTS\"\n\nexit $FAILED_TESTS\n```\n\n### Pre-Commit Hook\n\nValidate commands before committing:\n\n```bash\n#!/bin/bash\n# .git/hooks/pre-commit\n\necho \"Validating commands...\"\n\nCOMMANDS_CHANGED=$(git diff --cached --name-only | grep \"\\.claude/commands/.*\\.md\")\n\nif [ -z \"$COMMANDS_CHANGED\" ]; then\n  echo \"No commands changed\"\n  exit 0\nfi\n\nfor cmd in $COMMANDS_CHANGED; do\n  echo \"Checking: $cmd\"\n\n  if ! ./scripts/validate-command.sh \"$cmd\"; then\n    echo \"ERROR: Command validation failed: $cmd\"\n    exit 1\n  fi\ndone\n\necho \"âœ“ All commands valid\"\n```\n\n### Continuous Testing\n\nTest commands in CI/CD:\n\n```yaml\n# .github/workflows/test-commands.yml\nname: Test Commands\n\non: [push, pull_request]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Validate command structure\n        run: |\n          for cmd in .claude/commands/*.md; do\n            echo \"Testing: $cmd\"\n            ./scripts/validate-command.sh \"$cmd\"\n          done\n\n      - name: Validate frontmatter\n        run: |\n          for cmd in .claude/commands/*.md; do\n            ./scripts/validate-frontmatter.sh \"$cmd\"\n          done\n\n      - name: Check for TODOs\n        run: |\n          if grep -r \"TODO\" .claude/commands/; then\n            echo \"ERROR: TODOs found in commands\"\n            exit 1\n          fi\n```\n\n## Edge Case Testing\n\n### Test Edge Cases\n\n**Empty arguments:**\n```bash\n> /cmd \"\"\n> /cmd '' ''\n```\n\n**Special characters:**\n```bash\n> /cmd \"arg with spaces\"\n> /cmd arg-with-dashes\n> /cmd arg_with_underscores\n> /cmd arg/with/slashes\n> /cmd 'arg with \"quotes\"'\n```\n\n**Long arguments:**\n```bash\n> /cmd $(python -c \"print('a' * 10000)\")\n```\n\n**Unusual file paths:**\n```bash\n> /cmd ./file\n> /cmd ../file\n> /cmd ~/file\n> /cmd \"/path with spaces/file\"\n```\n\n**Bash command edge cases:**\n```markdown\n# Commands that might fail\nBANG`exit 1`\nBANG`false`\nBANG`command-that-does-not-exist`\n\n# Commands with special output\nBANG`echo \"\"`\nBANG`cat /dev/null`\nBANG`yes | head -n 1000000`\n```\n\n## Performance Testing\n\n### Response Time Testing\n\n```bash\n#!/bin/bash\n# test-command-performance.sh\n\nCOMMAND=\"$1\"\n\necho \"Testing performance of /$COMMAND\"\necho\n\nfor i in {1..5}; do\n  echo \"Run $i:\"\n  START=$(date +%s%N)\n\n  # Invoke command (manual step - record time)\n  echo \"  Invoke: /$COMMAND\"\n  echo \"  Start time: $START\"\n  echo \"  (Record end time manually)\"\n  echo\ndone\n\necho \"Analyze results:\"\necho \"  - Average response time\"\necho \"  - Variance\"\necho \"  - Acceptable threshold: < 3 seconds for fast commands\"\n```\n\n### Resource Usage Testing\n\n```bash\n# Monitor Claude Code during command execution\n# In terminal 1:\nclaude --debug\n\n# In terminal 2:\nwatch -n 1 'ps aux | grep claude'\n\n# Execute command and observe:\n# - Memory usage\n# - CPU usage\n# - Process count\n```\n\n## User Experience Testing\n\n### Usability Checklist\n\n- [ ] Command name is intuitive\n- [ ] Description is clear in `/help`\n- [ ] Arguments are well-documented\n- [ ] Error messages are helpful\n- [ ] Output is formatted readably\n- [ ] Long-running commands show progress\n- [ ] Results are actionable\n- [ ] Edge cases have good UX\n\n### User Acceptance Testing\n\nRecruit testers:\n\n```markdown\n# Testing Guide for Beta Testers\n\n## Command: /my-new-command\n\n### Test Scenarios\n\n1. **Basic usage:**\n   - Run: `/my-new-command`\n   - Expected: [describe]\n   - Rate clarity: 1-5\n\n2. **With arguments:**\n   - Run: `/my-new-command arg1 arg2`\n   - Expected: [describe]\n   - Rate usefulness: 1-5\n\n3. **Error case:**\n   - Run: `/my-new-command invalid-input`\n   - Expected: Helpful error message\n   - Rate error message: 1-5\n\n### Feedback Questions\n\n1. Was the command easy to understand?\n2. Did the output meet your expectations?\n3. What would you change?\n4. Would you use this command regularly?\n```\n\n## Testing Checklist\n\nBefore releasing a command:\n\n### Structure\n- [ ] File in correct location\n- [ ] Correct .md extension\n- [ ] Valid YAML frontmatter (if present)\n- [ ] Markdown syntax correct\n\n### Functionality\n- [ ] Command appears in `/help`\n- [ ] Description is clear\n- [ ] Command executes without errors\n- [ ] Arguments work as expected\n- [ ] File references work\n- [ ] Bash execution works (if used)\n\n### Edge Cases\n- [ ] Missing arguments handled\n- [ ] Invalid arguments detected\n- [ ] Non-existent files handled\n- [ ] Special characters work\n- [ ] Long inputs handled\n\n### Integration\n- [ ] Works with other commands\n- [ ] Works with hooks (if applicable)\n- [ ] Works with MCP (if applicable)\n- [ ] State management works\n\n### Quality\n- [ ] Performance acceptable\n- [ ] No security issues\n- [ ] Error messages helpful\n- [ ] Output formatted well\n- [ ] Documentation complete\n\n### Distribution\n- [ ] Tested by others\n- [ ] Feedback incorporated\n- [ ] README updated\n- [ ] Examples provided\n\n## Debugging Failed Tests\n\n### Common Issues and Solutions\n\n**Issue: Command not appearing in /help**\n\n```bash\n# Check file location\nls -la .claude/commands/my-command.md\n\n# Check permissions\nchmod 644 .claude/commands/my-command.md\n\n# Check syntax\nhead -n 20 .claude/commands/my-command.md\n\n# Restart Claude Code\nclaude --debug\n```\n\n**Issue: Arguments not substituting**\n\n```bash\n# Verify syntax\ngrep '\\$1' .claude/commands/my-command.md\ngrep '\\$ARGUMENTS' .claude/commands/my-command.md\n\n# Test with simple command first\necho \"Test: \\$1 and \\$2\" > .claude/commands/test-args.md\n```\n\n**Issue: Bash commands not executing**\n\n```bash\n# Check allowed-tools\ngrep \"allowed-tools\" .claude/commands/my-command.md\n\n# Verify command syntax\ngrep '!\\`' .claude/commands/my-command.md\n\n# Test command manually\ndate\necho \"test\"\n```\n\n**Issue: File references not working**\n\n```bash\n# Check @ syntax\ngrep '@' .claude/commands/my-command.md\n\n# Verify file exists\nls -la /path/to/referenced/file\n\n# Check permissions\nchmod 644 /path/to/referenced/file\n```\n\n## Best Practices\n\n1. **Test early, test often**: Validate as you develop\n2. **Automate validation**: Use scripts for repeatable checks\n3. **Test edge cases**: Don't just test the happy path\n4. **Get feedback**: Have others test before wide release\n5. **Document tests**: Keep test scenarios for regression testing\n6. **Monitor in production**: Watch for issues after release\n7. **Iterate**: Improve based on real usage data\n",
        "plugins/plugin-dev/skills/hook-development/SKILL.md": "---\nname: hook-development\ndescription: This skill should be used when the user asks to \"create a hook\", \"add a PreToolUse/PostToolUse/Stop hook\", \"validate tool use\", \"implement prompt-based hooks\", \"use ${CLAUDE_PLUGIN_ROOT}\", \"set up event-driven automation\", \"block dangerous commands\", or mentions hook events (PreToolUse, PostToolUse, Stop, SubagentStop, SessionStart, SessionEnd, UserPromptSubmit, PreCompact, Notification). Provides comprehensive guidance for creating and implementing Claude Code plugin hooks with focus on advanced prompt-based hooks API.\n---\n\n# Hook Development for Claude Code Plugins\n\n## Overview\n\nHooks are event-driven automation scripts that execute in response to Claude Code events. Use hooks to validate operations, enforce policies, add context, and integrate external tools into workflows.\n\n**Key capabilities:**\n- Validate tool calls before execution (PreToolUse)\n- React to tool results (PostToolUse)\n- Enforce completion standards (Stop, SubagentStop)\n- Load project context (SessionStart)\n- Automate workflows across the development lifecycle\n\n## Hook Types\n\n### Prompt-Based Hooks (Recommended)\n\nUse LLM-driven decision making for context-aware validation:\n\n```json\n{\n  \"type\": \"prompt\",\n  \"prompt\": \"Evaluate if this tool use is appropriate: $TOOL_INPUT\",\n  \"timeout\": 30\n}\n```\n\n**Supported events:** Stop, SubagentStop, UserPromptSubmit, PreToolUse\n\n**Benefits:**\n- Context-aware decisions based on natural language reasoning\n- Flexible evaluation logic without bash scripting\n- Better edge case handling\n- Easier to maintain and extend\n\n### Command Hooks\n\nExecute bash commands for deterministic checks:\n\n```json\n{\n  \"type\": \"command\",\n  \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/scripts/validate.sh\",\n  \"timeout\": 60\n}\n```\n\n**Use for:**\n- Fast deterministic validations\n- File system operations\n- External tool integrations\n- Performance-critical checks\n\n## Hook Configuration Formats\n\n### Plugin hooks.json Format\n\n**For plugin hooks** in `hooks/hooks.json`, use wrapper format:\n\n```json\n{\n  \"description\": \"Brief explanation of hooks (optional)\",\n  \"hooks\": {\n    \"PreToolUse\": [...],\n    \"Stop\": [...],\n    \"SessionStart\": [...]\n  }\n}\n```\n\n**Key points:**\n- `description` field is optional\n- `hooks` field is required wrapper containing actual hook events\n- This is the **plugin-specific format**\n\n**Example:**\n```json\n{\n  \"description\": \"Validation hooks for code quality\",\n  \"hooks\": {\n    \"PreToolUse\": [\n      {\n        \"matcher\": \"Write\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"${CLAUDE_PLUGIN_ROOT}/hooks/validate.sh\"\n          }\n        ]\n      }\n    ]\n  }\n}\n```\n\n### Settings Format (Direct)\n\n**For user settings** in `.claude/settings.json`, use direct format:\n\n```json\n{\n  \"PreToolUse\": [...],\n  \"Stop\": [...],\n  \"SessionStart\": [...]\n}\n```\n\n**Key points:**\n- No wrapper - events directly at top level\n- No description field\n- This is the **settings format**\n\n**Important:** The examples below show the hook event structure that goes inside either format. For plugin hooks.json, wrap these in `{\"hooks\": {...}}`.\n\n## Hook Events\n\n### PreToolUse\n\nExecute before any tool runs. Use to approve, deny, or modify tool calls.\n\n**Example (prompt-based):**\n```json\n{\n  \"PreToolUse\": [\n    {\n      \"matcher\": \"Write|Edit\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Validate file write safety. Check: system paths, credentials, path traversal, sensitive content. Return 'approve' or 'deny'.\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n**Output for PreToolUse:**\n```json\n{\n  \"hookSpecificOutput\": {\n    \"permissionDecision\": \"allow|deny|ask\",\n    \"updatedInput\": {\"field\": \"modified_value\"}\n  },\n  \"systemMessage\": \"Explanation for Claude\"\n}\n```\n\n### PostToolUse\n\nExecute after tool completes. Use to react to results, provide feedback, or log.\n\n**Example:**\n```json\n{\n  \"PostToolUse\": [\n    {\n      \"matcher\": \"Edit\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Analyze edit result for potential issues: syntax errors, security vulnerabilities, breaking changes. Provide feedback.\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n**Output behavior:**\n- Exit 0: stdout shown in transcript\n- Exit 2: stderr fed back to Claude\n- systemMessage included in context\n\n### Stop\n\nExecute when main agent considers stopping. Use to validate completeness.\n\n**Example:**\n```json\n{\n  \"Stop\": [\n    {\n      \"matcher\": \"*\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Verify task completion: tests run, build succeeded, questions answered. Return 'approve' to stop or 'block' with reason to continue.\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n**Decision output:**\n```json\n{\n  \"decision\": \"approve|block\",\n  \"reason\": \"Explanation\",\n  \"systemMessage\": \"Additional context\"\n}\n```\n\n### SubagentStop\n\nExecute when subagent considers stopping. Use to ensure subagent completed its task.\n\nSimilar to Stop hook, but for subagents.\n\n### UserPromptSubmit\n\nExecute when user submits a prompt. Use to add context, validate, or block prompts.\n\n**Example:**\n```json\n{\n  \"UserPromptSubmit\": [\n    {\n      \"matcher\": \"*\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Check if prompt requires security guidance. If discussing auth, permissions, or API security, return relevant warnings.\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n### SessionStart\n\nExecute when Claude Code session begins. Use to load context and set environment.\n\n**Example:**\n```json\n{\n  \"SessionStart\": [\n    {\n      \"matcher\": \"*\",\n      \"hooks\": [\n        {\n          \"type\": \"command\",\n          \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/scripts/load-context.sh\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n**Special capability:** Persist environment variables using `$CLAUDE_ENV_FILE`:\n```bash\necho \"export PROJECT_TYPE=nodejs\" >> \"$CLAUDE_ENV_FILE\"\n```\n\nSee `examples/load-context.sh` for complete example.\n\n### SessionEnd\n\nExecute when session ends. Use for cleanup, logging, and state preservation.\n\n### PreCompact\n\nExecute before context compaction. Use to add critical information to preserve.\n\n### Notification\n\nExecute when Claude sends notifications. Use to react to user notifications.\n\n## Hook Output Format\n\n### Standard Output (All Hooks)\n\n```json\n{\n  \"continue\": true,\n  \"suppressOutput\": false,\n  \"systemMessage\": \"Message for Claude\"\n}\n```\n\n- `continue`: If false, halt processing (default true)\n- `suppressOutput`: Hide output from transcript (default false)\n- `systemMessage`: Message shown to Claude\n\n### Exit Codes\n\n- `0` - Success (stdout shown in transcript)\n- `2` - Blocking error (stderr fed back to Claude)\n- Other - Non-blocking error\n\n## Hook Input Format\n\nAll hooks receive JSON via stdin with common fields:\n\n```json\n{\n  \"session_id\": \"abc123\",\n  \"transcript_path\": \"/path/to/transcript.txt\",\n  \"cwd\": \"/current/working/dir\",\n  \"permission_mode\": \"ask|allow\",\n  \"hook_event_name\": \"PreToolUse\"\n}\n```\n\n**Event-specific fields:**\n\n- **PreToolUse/PostToolUse:** `tool_name`, `tool_input`, `tool_result`\n- **UserPromptSubmit:** `user_prompt`\n- **Stop/SubagentStop:** `reason`\n\nAccess fields in prompts using `$TOOL_INPUT`, `$TOOL_RESULT`, `$USER_PROMPT`, etc.\n\n## Environment Variables\n\nAvailable in all command hooks:\n\n- `$CLAUDE_PROJECT_DIR` - Project root path\n- `$CLAUDE_PLUGIN_ROOT` - Plugin directory (use for portable paths)\n- `$CLAUDE_ENV_FILE` - SessionStart only: persist env vars here\n- `$CLAUDE_CODE_REMOTE` - Set if running in remote context\n\n**Always use ${CLAUDE_PLUGIN_ROOT} in hook commands for portability:**\n\n```json\n{\n  \"type\": \"command\",\n  \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/scripts/validate.sh\"\n}\n```\n\n## Plugin Hook Configuration\n\nIn plugins, define hooks in `hooks/hooks.json`:\n\n```json\n{\n  \"PreToolUse\": [\n    {\n      \"matcher\": \"Write|Edit\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Validate file write safety\"\n        }\n      ]\n    }\n  ],\n  \"Stop\": [\n    {\n      \"matcher\": \"*\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Verify task completion\"\n        }\n      ]\n    }\n  ],\n  \"SessionStart\": [\n    {\n      \"matcher\": \"*\",\n      \"hooks\": [\n        {\n          \"type\": \"command\",\n          \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/scripts/load-context.sh\",\n          \"timeout\": 10\n        }\n      ]\n    }\n  ]\n}\n```\n\nPlugin hooks merge with user's hooks and run in parallel.\n\n## Matchers\n\n### Tool Name Matching\n\n**Exact match:**\n```json\n\"matcher\": \"Write\"\n```\n\n**Multiple tools:**\n```json\n\"matcher\": \"Read|Write|Edit\"\n```\n\n**Wildcard (all tools):**\n```json\n\"matcher\": \"*\"\n```\n\n**Regex patterns:**\n```json\n\"matcher\": \"mcp__.*__delete.*\"  // All MCP delete tools\n```\n\n**Note:** Matchers are case-sensitive.\n\n### Common Patterns\n\n```json\n// All MCP tools\n\"matcher\": \"mcp__.*\"\n\n// Specific plugin's MCP tools\n\"matcher\": \"mcp__plugin_asana_.*\"\n\n// All file operations\n\"matcher\": \"Read|Write|Edit\"\n\n// Bash commands only\n\"matcher\": \"Bash\"\n```\n\n## Security Best Practices\n\n### Input Validation\n\nAlways validate inputs in command hooks:\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\ninput=$(cat)\ntool_name=$(echo \"$input\" | jq -r '.tool_name')\n\n# Validate tool name format\nif [[ ! \"$tool_name\" =~ ^[a-zA-Z0-9_]+$ ]]; then\n  echo '{\"decision\": \"deny\", \"reason\": \"Invalid tool name\"}' >&2\n  exit 2\nfi\n```\n\n### Path Safety\n\nCheck for path traversal and sensitive files:\n\n```bash\nfile_path=$(echo \"$input\" | jq -r '.tool_input.file_path')\n\n# Deny path traversal\nif [[ \"$file_path\" == *\"..\"* ]]; then\n  echo '{\"decision\": \"deny\", \"reason\": \"Path traversal detected\"}' >&2\n  exit 2\nfi\n\n# Deny sensitive files\nif [[ \"$file_path\" == *\".env\"* ]]; then\n  echo '{\"decision\": \"deny\", \"reason\": \"Sensitive file\"}' >&2\n  exit 2\nfi\n```\n\nSee `examples/validate-write.sh` and `examples/validate-bash.sh` for complete examples.\n\n### Quote All Variables\n\n```bash\n# GOOD: Quoted\necho \"$file_path\"\ncd \"$CLAUDE_PROJECT_DIR\"\n\n# BAD: Unquoted (injection risk)\necho $file_path\ncd $CLAUDE_PROJECT_DIR\n```\n\n### Set Appropriate Timeouts\n\n```json\n{\n  \"type\": \"command\",\n  \"command\": \"bash script.sh\",\n  \"timeout\": 10\n}\n```\n\n**Defaults:** Command hooks (60s), Prompt hooks (30s)\n\n## Performance Considerations\n\n### Parallel Execution\n\nAll matching hooks run **in parallel**:\n\n```json\n{\n  \"PreToolUse\": [\n    {\n      \"matcher\": \"Write\",\n      \"hooks\": [\n        {\"type\": \"command\", \"command\": \"check1.sh\"},  // Parallel\n        {\"type\": \"command\", \"command\": \"check2.sh\"},  // Parallel\n        {\"type\": \"prompt\", \"prompt\": \"Validate...\"}   // Parallel\n      ]\n    }\n  ]\n}\n```\n\n**Design implications:**\n- Hooks don't see each other's output\n- Non-deterministic ordering\n- Design for independence\n\n### Optimization\n\n1. Use command hooks for quick deterministic checks\n2. Use prompt hooks for complex reasoning\n3. Cache validation results in temp files\n4. Minimize I/O in hot paths\n\n## Temporarily Active Hooks\n\nCreate hooks that activate conditionally by checking for a flag file or configuration:\n\n**Pattern: Flag file activation**\n```bash\n#!/bin/bash\n# Only active when flag file exists\nFLAG_FILE=\"$CLAUDE_PROJECT_DIR/.enable-strict-validation\"\n\nif [ ! -f \"$FLAG_FILE\" ]; then\n  # Flag not present, skip validation\n  exit 0\nfi\n\n# Flag present, run validation\ninput=$(cat)\n# ... validation logic ...\n```\n\n**Pattern: Configuration-based activation**\n```bash\n#!/bin/bash\n# Check configuration for activation\nCONFIG_FILE=\"$CLAUDE_PROJECT_DIR/.claude/plugin-config.json\"\n\nif [ -f \"$CONFIG_FILE\" ]; then\n  enabled=$(jq -r '.strictMode // false' \"$CONFIG_FILE\")\n  if [ \"$enabled\" != \"true\" ]; then\n    exit 0  # Not enabled, skip\n  fi\nfi\n\n# Enabled, run hook logic\ninput=$(cat)\n# ... hook logic ...\n```\n\n**Use cases:**\n- Enable strict validation only when needed\n- Temporary debugging hooks\n- Project-specific hook behavior\n- Feature flags for hooks\n\n**Best practice:** Document activation mechanism in plugin README so users know how to enable/disable temporary hooks.\n\n## Hook Lifecycle and Limitations\n\n### Hooks Load at Session Start\n\n**Important:** Hooks are loaded when Claude Code session starts. Changes to hook configuration require restarting Claude Code.\n\n**Cannot hot-swap hooks:**\n- Editing `hooks/hooks.json` won't affect current session\n- Adding new hook scripts won't be recognized\n- Changing hook commands/prompts won't update\n- Must restart Claude Code: exit and run `claude` again\n\n**To test hook changes:**\n1. Edit hook configuration or scripts\n2. Exit Claude Code session\n3. Restart: `claude` or `cc`\n4. New hook configuration loads\n5. Test hooks with `claude --debug`\n\n### Hook Validation at Startup\n\nHooks are validated when Claude Code starts:\n- Invalid JSON in hooks.json causes loading failure\n- Missing scripts cause warnings\n- Syntax errors reported in debug mode\n\nUse `/hooks` command to review loaded hooks in current session.\n\n## Debugging Hooks\n\n### Enable Debug Mode\n\n```bash\nclaude --debug\n```\n\nLook for hook registration, execution logs, input/output JSON, and timing information.\n\n### Test Hook Scripts\n\nTest command hooks directly:\n\n```bash\necho '{\"tool_name\": \"Write\", \"tool_input\": {\"file_path\": \"/test\"}}' | \\\n  bash ${CLAUDE_PLUGIN_ROOT}/scripts/validate.sh\n\necho \"Exit code: $?\"\n```\n\n### Validate JSON Output\n\nEnsure hooks output valid JSON:\n\n```bash\noutput=$(./your-hook.sh < test-input.json)\necho \"$output\" | jq .\n```\n\n## Quick Reference\n\n### Hook Events Summary\n\n| Event | When | Use For |\n|-------|------|---------|\n| PreToolUse | Before tool | Validation, modification |\n| PostToolUse | After tool | Feedback, logging |\n| UserPromptSubmit | User input | Context, validation |\n| Stop | Agent stopping | Completeness check |\n| SubagentStop | Subagent done | Task validation |\n| SessionStart | Session begins | Context loading |\n| SessionEnd | Session ends | Cleanup, logging |\n| PreCompact | Before compact | Preserve context |\n| Notification | User notified | Logging, reactions |\n\n### Best Practices\n\n**DO:**\n- âœ… Use prompt-based hooks for complex logic\n- âœ… Use ${CLAUDE_PLUGIN_ROOT} for portability\n- âœ… Validate all inputs in command hooks\n- âœ… Quote all bash variables\n- âœ… Set appropriate timeouts\n- âœ… Return structured JSON output\n- âœ… Test hooks thoroughly\n\n**DON'T:**\n- âŒ Use hardcoded paths\n- âŒ Trust user input without validation\n- âŒ Create long-running hooks\n- âŒ Rely on hook execution order\n- âŒ Modify global state unpredictably\n- âŒ Log sensitive information\n\n## Additional Resources\n\n### Reference Files\n\nFor detailed patterns and advanced techniques, consult:\n\n- **`references/patterns.md`** - Common hook patterns (8+ proven patterns)\n- **`references/migration.md`** - Migrating from basic to advanced hooks\n- **`references/advanced.md`** - Advanced use cases and techniques\n\n### Example Hook Scripts\n\nWorking examples in `examples/`:\n\n- **`validate-write.sh`** - File write validation example\n- **`validate-bash.sh`** - Bash command validation example\n- **`load-context.sh`** - SessionStart context loading example\n\n### Utility Scripts\n\nDevelopment tools in `scripts/`:\n\n- **`validate-hook-schema.sh`** - Validate hooks.json structure and syntax\n- **`test-hook.sh`** - Test hooks with sample input before deployment\n- **`hook-linter.sh`** - Check hook scripts for common issues and best practices\n\n### External Resources\n\n- **Official Docs**: https://docs.claude.com/en/docs/claude-code/hooks\n- **Examples**: See security-guidance plugin in marketplace\n- **Testing**: Use `claude --debug` for detailed logs\n- **Validation**: Use `jq` to validate hook JSON output\n\n## Implementation Workflow\n\nTo implement hooks in a plugin:\n\n1. Identify events to hook into (PreToolUse, Stop, SessionStart, etc.)\n2. Decide between prompt-based (flexible) or command (deterministic) hooks\n3. Write hook configuration in `hooks/hooks.json`\n4. For command hooks, create hook scripts\n5. Use ${CLAUDE_PLUGIN_ROOT} for all file references\n6. Validate configuration with `scripts/validate-hook-schema.sh hooks/hooks.json`\n7. Test hooks with `scripts/test-hook.sh` before deployment\n8. Test in Claude Code with `claude --debug`\n9. Document hooks in plugin README\n\nFocus on prompt-based hooks for most use cases. Reserve command hooks for performance-critical or deterministic checks.\n",
        "plugins/plugin-dev/skills/hook-development/references/advanced.md": "# Advanced Hook Use Cases\n\nThis reference covers advanced hook patterns and techniques for sophisticated automation workflows.\n\n## Multi-Stage Validation\n\nCombine command and prompt hooks for layered validation:\n\n```json\n{\n  \"PreToolUse\": [\n    {\n      \"matcher\": \"Bash\",\n      \"hooks\": [\n        {\n          \"type\": \"command\",\n          \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/scripts/quick-check.sh\",\n          \"timeout\": 5\n        },\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Deep analysis of bash command: $TOOL_INPUT\",\n          \"timeout\": 15\n        }\n      ]\n    }\n  ]\n}\n```\n\n**Use case:** Fast deterministic checks followed by intelligent analysis\n\n**Example quick-check.sh:**\n```bash\n#!/bin/bash\ninput=$(cat)\ncommand=$(echo \"$input\" | jq -r '.tool_input.command')\n\n# Immediate approval for safe commands\nif [[ \"$command\" =~ ^(ls|pwd|echo|date|whoami)$ ]]; then\n  exit 0\nfi\n\n# Let prompt hook handle complex cases\nexit 0\n```\n\nThe command hook quickly approves obviously safe commands, while the prompt hook analyzes everything else.\n\n## Conditional Hook Execution\n\nExecute hooks based on environment or context:\n\n```bash\n#!/bin/bash\n# Only run in CI environment\nif [ -z \"$CI\" ]; then\n  echo '{\"continue\": true}' # Skip in non-CI\n  exit 0\nfi\n\n# Run validation logic in CI\ninput=$(cat)\n# ... validation code ...\n```\n\n**Use cases:**\n- Different behavior in CI vs local development\n- Project-specific validation\n- User-specific rules\n\n**Example: Skip certain checks for trusted users:**\n```bash\n#!/bin/bash\n# Skip detailed checks for admin users\nif [ \"$USER\" = \"admin\" ]; then\n  exit 0\nfi\n\n# Full validation for other users\ninput=$(cat)\n# ... validation code ...\n```\n\n## Hook Chaining via State\n\nShare state between hooks using temporary files:\n\n```bash\n# Hook 1: Analyze and save state\n#!/bin/bash\ninput=$(cat)\ncommand=$(echo \"$input\" | jq -r '.tool_input.command')\n\n# Analyze command\nrisk_level=$(calculate_risk \"$command\")\necho \"$risk_level\" > /tmp/hook-state-$$\n\nexit 0\n```\n\n```bash\n# Hook 2: Use saved state\n#!/bin/bash\nrisk_level=$(cat /tmp/hook-state-$$ 2>/dev/null || echo \"unknown\")\n\nif [ \"$risk_level\" = \"high\" ]; then\n  echo \"High risk operation detected\" >&2\n  exit 2\nfi\n```\n\n**Important:** This only works for sequential hook events (e.g., PreToolUse then PostToolUse), not parallel hooks.\n\n## Dynamic Hook Configuration\n\nModify hook behavior based on project configuration:\n\n```bash\n#!/bin/bash\ncd \"$CLAUDE_PROJECT_DIR\" || exit 1\n\n# Read project-specific config\nif [ -f \".claude-hooks-config.json\" ]; then\n  strict_mode=$(jq -r '.strict_mode' .claude-hooks-config.json)\n\n  if [ \"$strict_mode\" = \"true\" ]; then\n    # Apply strict validation\n    # ...\n  else\n    # Apply lenient validation\n    # ...\n  fi\nfi\n```\n\n**Example .claude-hooks-config.json:**\n```json\n{\n  \"strict_mode\": true,\n  \"allowed_commands\": [\"ls\", \"pwd\", \"grep\"],\n  \"forbidden_paths\": [\"/etc\", \"/sys\"]\n}\n```\n\n## Context-Aware Prompt Hooks\n\nUse transcript and session context for intelligent decisions:\n\n```json\n{\n  \"Stop\": [\n    {\n      \"matcher\": \"*\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Review the full transcript at $TRANSCRIPT_PATH. Check: 1) Were tests run after code changes? 2) Did the build succeed? 3) Were all user questions answered? 4) Is there any unfinished work? Return 'approve' only if everything is complete.\"\n        }\n      ]\n    }\n  ]\n}\n```\n\nThe LLM can read the transcript file and make context-aware decisions.\n\n## Performance Optimization\n\n### Caching Validation Results\n\n```bash\n#!/bin/bash\ninput=$(cat)\nfile_path=$(echo \"$input\" | jq -r '.tool_input.file_path')\ncache_key=$(echo -n \"$file_path\" | md5sum | cut -d' ' -f1)\ncache_file=\"/tmp/hook-cache-$cache_key\"\n\n# Check cache\nif [ -f \"$cache_file\" ]; then\n  cache_age=$(($(date +%s) - $(stat -f%m \"$cache_file\" 2>/dev/null || stat -c%Y \"$cache_file\")))\n  if [ \"$cache_age\" -lt 300 ]; then  # 5 minute cache\n    cat \"$cache_file\"\n    exit 0\n  fi\nfi\n\n# Perform validation\nresult='{\"decision\": \"approve\"}'\n\n# Cache result\necho \"$result\" > \"$cache_file\"\necho \"$result\"\n```\n\n### Parallel Execution Optimization\n\nSince hooks run in parallel, design them to be independent:\n\n```json\n{\n  \"PreToolUse\": [\n    {\n      \"matcher\": \"Write\",\n      \"hooks\": [\n        {\n          \"type\": \"command\",\n          \"command\": \"bash check-size.sh\",      // Independent\n          \"timeout\": 2\n        },\n        {\n          \"type\": \"command\",\n          \"command\": \"bash check-path.sh\",      // Independent\n          \"timeout\": 2\n        },\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Check content safety\",     // Independent\n          \"timeout\": 10\n        }\n      ]\n    }\n  ]\n}\n```\n\nAll three hooks run simultaneously, reducing total latency.\n\n## Cross-Event Workflows\n\nCoordinate hooks across different events:\n\n**SessionStart - Set up tracking:**\n```bash\n#!/bin/bash\n# Initialize session tracking\necho \"0\" > /tmp/test-count-$$\necho \"0\" > /tmp/build-count-$$\n```\n\n**PostToolUse - Track events:**\n```bash\n#!/bin/bash\ninput=$(cat)\ntool_name=$(echo \"$input\" | jq -r '.tool_name')\n\nif [ \"$tool_name\" = \"Bash\" ]; then\n  command=$(echo \"$input\" | jq -r '.tool_result')\n  if [[ \"$command\" == *\"test\"* ]]; then\n    count=$(cat /tmp/test-count-$$ 2>/dev/null || echo \"0\")\n    echo $((count + 1)) > /tmp/test-count-$$\n  fi\nfi\n```\n\n**Stop - Verify based on tracking:**\n```bash\n#!/bin/bash\ntest_count=$(cat /tmp/test-count-$$ 2>/dev/null || echo \"0\")\n\nif [ \"$test_count\" -eq 0 ]; then\n  echo '{\"decision\": \"block\", \"reason\": \"No tests were run\"}' >&2\n  exit 2\nfi\n```\n\n## Integration with External Systems\n\n### Slack Notifications\n\n```bash\n#!/bin/bash\ninput=$(cat)\ntool_name=$(echo \"$input\" | jq -r '.tool_name')\ndecision=\"blocked\"\n\n# Send notification to Slack\ncurl -X POST \"$SLACK_WEBHOOK\" \\\n  -H 'Content-Type: application/json' \\\n  -d \"{\\\"text\\\": \\\"Hook ${decision} ${tool_name} operation\\\"}\" \\\n  2>/dev/null\n\necho '{\"decision\": \"deny\"}' >&2\nexit 2\n```\n\n### Database Logging\n\n```bash\n#!/bin/bash\ninput=$(cat)\n\n# Log to database\npsql \"$DATABASE_URL\" -c \"INSERT INTO hook_logs (event, data) VALUES ('PreToolUse', '$input')\" \\\n  2>/dev/null\n\nexit 0\n```\n\n### Metrics Collection\n\n```bash\n#!/bin/bash\ninput=$(cat)\ntool_name=$(echo \"$input\" | jq -r '.tool_name')\n\n# Send metrics to monitoring system\necho \"hook.pretooluse.${tool_name}:1|c\" | nc -u -w1 statsd.local 8125\n\nexit 0\n```\n\n## Security Patterns\n\n### Rate Limiting\n\n```bash\n#!/bin/bash\ninput=$(cat)\ncommand=$(echo \"$input\" | jq -r '.tool_input.command')\n\n# Track command frequency\nrate_file=\"/tmp/hook-rate-$$\"\ncurrent_minute=$(date +%Y%m%d%H%M)\n\nif [ -f \"$rate_file\" ]; then\n  last_minute=$(head -1 \"$rate_file\")\n  count=$(tail -1 \"$rate_file\")\n\n  if [ \"$current_minute\" = \"$last_minute\" ]; then\n    if [ \"$count\" -gt 10 ]; then\n      echo '{\"decision\": \"deny\", \"reason\": \"Rate limit exceeded\"}' >&2\n      exit 2\n    fi\n    count=$((count + 1))\n  else\n    count=1\n  fi\nelse\n  count=1\nfi\n\necho \"$current_minute\" > \"$rate_file\"\necho \"$count\" >> \"$rate_file\"\n\nexit 0\n```\n\n### Audit Logging\n\n```bash\n#!/bin/bash\ninput=$(cat)\ntool_name=$(echo \"$input\" | jq -r '.tool_name')\ntimestamp=$(date -Iseconds)\n\n# Append to audit log\necho \"$timestamp | $USER | $tool_name | $input\" >> ~/.claude/audit.log\n\nexit 0\n```\n\n### Secret Detection\n\n```bash\n#!/bin/bash\ninput=$(cat)\ncontent=$(echo \"$input\" | jq -r '.tool_input.content')\n\n# Check for common secret patterns\nif echo \"$content\" | grep -qE \"(api[_-]?key|password|secret|token).{0,20}['\\\"]?[A-Za-z0-9]{20,}\"; then\n  echo '{\"decision\": \"deny\", \"reason\": \"Potential secret detected in content\"}' >&2\n  exit 2\nfi\n\nexit 0\n```\n\n## Testing Advanced Hooks\n\n### Unit Testing Hook Scripts\n\n```bash\n# test-hook.sh\n#!/bin/bash\n\n# Test 1: Approve safe command\nresult=$(echo '{\"tool_input\": {\"command\": \"ls\"}}' | bash validate-bash.sh)\nif [ $? -eq 0 ]; then\n  echo \"âœ“ Test 1 passed\"\nelse\n  echo \"âœ— Test 1 failed\"\nfi\n\n# Test 2: Block dangerous command\nresult=$(echo '{\"tool_input\": {\"command\": \"rm -rf /\"}}' | bash validate-bash.sh)\nif [ $? -eq 2 ]; then\n  echo \"âœ“ Test 2 passed\"\nelse\n  echo \"âœ— Test 2 failed\"\nfi\n```\n\n### Integration Testing\n\nCreate test scenarios that exercise the full hook workflow:\n\n```bash\n# integration-test.sh\n#!/bin/bash\n\n# Set up test environment\nexport CLAUDE_PROJECT_DIR=\"/tmp/test-project\"\nexport CLAUDE_PLUGIN_ROOT=\"$(pwd)\"\nmkdir -p \"$CLAUDE_PROJECT_DIR\"\n\n# Test SessionStart hook\necho '{}' | bash hooks/session-start.sh\nif [ -f \"/tmp/session-initialized\" ]; then\n  echo \"âœ“ SessionStart hook works\"\nelse\n  echo \"âœ— SessionStart hook failed\"\nfi\n\n# Clean up\nrm -rf \"$CLAUDE_PROJECT_DIR\"\n```\n\n## Best Practices for Advanced Hooks\n\n1. **Keep hooks independent**: Don't rely on execution order\n2. **Use timeouts**: Set appropriate limits for each hook type\n3. **Handle errors gracefully**: Provide clear error messages\n4. **Document complexity**: Explain advanced patterns in README\n5. **Test thoroughly**: Cover edge cases and failure modes\n6. **Monitor performance**: Track hook execution time\n7. **Version configuration**: Use version control for hook configs\n8. **Provide escape hatches**: Allow users to bypass hooks when needed\n\n## Common Pitfalls\n\n### âŒ Assuming Hook Order\n\n```bash\n# BAD: Assumes hooks run in specific order\n# Hook 1 saves state, Hook 2 reads it\n# This can fail because hooks run in parallel!\n```\n\n### âŒ Long-Running Hooks\n\n```bash\n# BAD: Hook takes 2 minutes to run\nsleep 120\n# This will timeout and block the workflow\n```\n\n### âŒ Uncaught Exceptions\n\n```bash\n# BAD: Script crashes on unexpected input\nfile_path=$(echo \"$input\" | jq -r '.tool_input.file_path')\ncat \"$file_path\"  # Fails if file doesn't exist\n```\n\n### âœ… Proper Error Handling\n\n```bash\n# GOOD: Handles errors gracefully\nfile_path=$(echo \"$input\" | jq -r '.tool_input.file_path')\nif [ ! -f \"$file_path\" ]; then\n  echo '{\"continue\": true, \"systemMessage\": \"File not found, skipping check\"}' >&2\n  exit 0\nfi\n```\n\n## Conclusion\n\nAdvanced hook patterns enable sophisticated automation while maintaining reliability and performance. Use these techniques when basic hooks are insufficient, but always prioritize simplicity and maintainability.\n",
        "plugins/plugin-dev/skills/hook-development/references/migration.md": "# Migrating from Basic to Advanced Hooks\n\nThis guide shows how to migrate from basic command hooks to advanced prompt-based hooks for better maintainability and flexibility.\n\n## Why Migrate?\n\nPrompt-based hooks offer several advantages:\n\n- **Natural language reasoning**: LLM understands context and intent\n- **Better edge case handling**: Adapts to unexpected scenarios\n- **No bash scripting required**: Simpler to write and maintain\n- **More flexible validation**: Can handle complex logic without coding\n\n## Migration Example: Bash Command Validation\n\n### Before (Basic Command Hook)\n\n**Configuration:**\n```json\n{\n  \"PreToolUse\": [\n    {\n      \"matcher\": \"Bash\",\n      \"hooks\": [\n        {\n          \"type\": \"command\",\n          \"command\": \"bash validate-bash.sh\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n**Script (validate-bash.sh):**\n```bash\n#!/bin/bash\ninput=$(cat)\ncommand=$(echo \"$input\" | jq -r '.tool_input.command')\n\n# Hard-coded validation logic\nif [[ \"$command\" == *\"rm -rf\"* ]]; then\n  echo \"Dangerous command detected\" >&2\n  exit 2\nfi\n```\n\n**Problems:**\n- Only checks for exact \"rm -rf\" pattern\n- Doesn't catch variations like `rm -fr` or `rm -r -f`\n- Misses other dangerous commands (`dd`, `mkfs`, etc.)\n- No context awareness\n- Requires bash scripting knowledge\n\n### After (Advanced Prompt Hook)\n\n**Configuration:**\n```json\n{\n  \"PreToolUse\": [\n    {\n      \"matcher\": \"Bash\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Command: $TOOL_INPUT.command. Analyze for: 1) Destructive operations (rm -rf, dd, mkfs, etc) 2) Privilege escalation (sudo) 3) Network operations without user consent. Return 'approve' or 'deny' with explanation.\",\n          \"timeout\": 15\n        }\n      ]\n    }\n  ]\n}\n```\n\n**Benefits:**\n- Catches all variations and patterns\n- Understands intent, not just literal strings\n- No script file needed\n- Easy to extend with new criteria\n- Context-aware decisions\n- Natural language explanation in denial\n\n## Migration Example: File Write Validation\n\n### Before (Basic Command Hook)\n\n**Configuration:**\n```json\n{\n  \"PreToolUse\": [\n    {\n      \"matcher\": \"Write\",\n      \"hooks\": [\n        {\n          \"type\": \"command\",\n          \"command\": \"bash validate-write.sh\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n**Script (validate-write.sh):**\n```bash\n#!/bin/bash\ninput=$(cat)\nfile_path=$(echo \"$input\" | jq -r '.tool_input.file_path')\n\n# Check for path traversal\nif [[ \"$file_path\" == *\"..\"* ]]; then\n  echo '{\"decision\": \"deny\", \"reason\": \"Path traversal detected\"}' >&2\n  exit 2\nfi\n\n# Check for system paths\nif [[ \"$file_path\" == \"/etc/\"* ]] || [[ \"$file_path\" == \"/sys/\"* ]]; then\n  echo '{\"decision\": \"deny\", \"reason\": \"System file\"}' >&2\n  exit 2\nfi\n```\n\n**Problems:**\n- Hard-coded path patterns\n- Doesn't understand symlinks\n- Missing edge cases (e.g., `/etc` vs `/etc/`)\n- No consideration of file content\n\n### After (Advanced Prompt Hook)\n\n**Configuration:**\n```json\n{\n  \"PreToolUse\": [\n    {\n      \"matcher\": \"Write|Edit\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"File path: $TOOL_INPUT.file_path. Content preview: $TOOL_INPUT.content (first 200 chars). Verify: 1) Not system directories (/etc, /sys, /usr) 2) Not credentials (.env, tokens, secrets) 3) No path traversal 4) Content doesn't expose secrets. Return 'approve' or 'deny'.\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n**Benefits:**\n- Context-aware (considers content too)\n- Handles symlinks and edge cases\n- Natural understanding of \"system directories\"\n- Can detect secrets in content\n- Easy to extend criteria\n\n## When to Keep Command Hooks\n\nCommand hooks still have their place:\n\n### 1. Deterministic Performance Checks\n\n```bash\n#!/bin/bash\n# Check file size quickly\nfile_path=$(echo \"$input\" | jq -r '.tool_input.file_path')\nsize=$(stat -f%z \"$file_path\" 2>/dev/null || stat -c%s \"$file_path\" 2>/dev/null)\n\nif [ \"$size\" -gt 10000000 ]; then\n  echo '{\"decision\": \"deny\", \"reason\": \"File too large\"}' >&2\n  exit 2\nfi\n```\n\n**Use command hooks when:** Validation is purely mathematical or deterministic.\n\n### 2. External Tool Integration\n\n```bash\n#!/bin/bash\n# Run security scanner\nfile_path=$(echo \"$input\" | jq -r '.tool_input.file_path')\nscan_result=$(security-scanner \"$file_path\")\n\nif [ \"$?\" -ne 0 ]; then\n  echo \"Security scan failed: $scan_result\" >&2\n  exit 2\nfi\n```\n\n**Use command hooks when:** Integrating with external tools that provide yes/no answers.\n\n### 3. Very Fast Checks (< 50ms)\n\n```bash\n#!/bin/bash\n# Quick regex check\ncommand=$(echo \"$input\" | jq -r '.tool_input.command')\n\nif [[ \"$command\" =~ ^(ls|pwd|echo)$ ]]; then\n  exit 0  # Safe commands\nfi\n```\n\n**Use command hooks when:** Performance is critical and logic is simple.\n\n## Hybrid Approach\n\nCombine both for multi-stage validation:\n\n```json\n{\n  \"PreToolUse\": [\n    {\n      \"matcher\": \"Bash\",\n      \"hooks\": [\n        {\n          \"type\": \"command\",\n          \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/scripts/quick-check.sh\",\n          \"timeout\": 5\n        },\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Deep analysis of bash command: $TOOL_INPUT\",\n          \"timeout\": 15\n        }\n      ]\n    }\n  ]\n}\n```\n\nThe command hook does fast deterministic checks, while the prompt hook handles complex reasoning.\n\n## Migration Checklist\n\nWhen migrating hooks:\n\n- [ ] Identify the validation logic in the command hook\n- [ ] Convert hard-coded patterns to natural language criteria\n- [ ] Test with edge cases the old hook missed\n- [ ] Verify LLM understands the intent\n- [ ] Set appropriate timeout (usually 15-30s for prompt hooks)\n- [ ] Document the new hook in README\n- [ ] Remove or archive old script files\n\n## Migration Tips\n\n1. **Start with one hook**: Don't migrate everything at once\n2. **Test thoroughly**: Verify prompt hook catches what command hook caught\n3. **Look for improvements**: Use migration as opportunity to enhance validation\n4. **Keep scripts for reference**: Archive old scripts in case you need to reference the logic\n5. **Document reasoning**: Explain why prompt hook is better in README\n\n## Complete Migration Example\n\n### Original Plugin Structure\n\n```\nmy-plugin/\nâ”œâ”€â”€ .claude-plugin/plugin.json\nâ”œâ”€â”€ hooks/hooks.json\nâ””â”€â”€ scripts/\n    â”œâ”€â”€ validate-bash.sh\n    â”œâ”€â”€ validate-write.sh\n    â””â”€â”€ check-tests.sh\n```\n\n### After Migration\n\n```\nmy-plugin/\nâ”œâ”€â”€ .claude-plugin/plugin.json\nâ”œâ”€â”€ hooks/hooks.json      # Now uses prompt hooks\nâ””â”€â”€ scripts/              # Archive or delete\n    â””â”€â”€ archive/\n        â”œâ”€â”€ validate-bash.sh\n        â”œâ”€â”€ validate-write.sh\n        â””â”€â”€ check-tests.sh\n```\n\n### Updated hooks.json\n\n```json\n{\n  \"PreToolUse\": [\n    {\n      \"matcher\": \"Bash\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Validate bash command safety: destructive ops, privilege escalation, network access\"\n        }\n      ]\n    },\n    {\n      \"matcher\": \"Write|Edit\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Validate file write safety: system paths, credentials, path traversal, content secrets\"\n        }\n      ]\n    }\n  ],\n  \"Stop\": [\n    {\n      \"matcher\": \"*\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Verify tests were run if code was modified\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n**Result:** Simpler, more maintainable, more powerful.\n\n## Common Migration Patterns\n\n### Pattern: String Contains â†’ Natural Language\n\n**Before:**\n```bash\nif [[ \"$command\" == *\"sudo\"* ]]; then\n  echo \"Privilege escalation\" >&2\n  exit 2\nfi\n```\n\n**After:**\n```\n\"Check for privilege escalation (sudo, su, etc)\"\n```\n\n### Pattern: Regex â†’ Intent\n\n**Before:**\n```bash\nif [[ \"$file\" =~ \\.(env|secret|key|token)$ ]]; then\n  echo \"Credential file\" >&2\n  exit 2\nfi\n```\n\n**After:**\n```\n\"Verify not writing to credential files (.env, secrets, keys, tokens)\"\n```\n\n### Pattern: Multiple Conditions â†’ Criteria List\n\n**Before:**\n```bash\nif [ condition1 ] || [ condition2 ] || [ condition3 ]; then\n  echo \"Invalid\" >&2\n  exit 2\nfi\n```\n\n**After:**\n```\n\"Check: 1) condition1 2) condition2 3) condition3. Deny if any fail.\"\n```\n\n## Conclusion\n\nMigrating to prompt-based hooks makes plugins more maintainable, flexible, and powerful. Reserve command hooks for deterministic checks and external tool integration.\n",
        "plugins/plugin-dev/skills/hook-development/references/patterns.md": "# Common Hook Patterns\n\nThis reference provides common, proven patterns for implementing Claude Code hooks. Use these patterns as starting points for typical hook use cases.\n\n## Pattern 1: Security Validation\n\nBlock dangerous file writes using prompt-based hooks:\n\n```json\n{\n  \"PreToolUse\": [\n    {\n      \"matcher\": \"Write|Edit\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"File path: $TOOL_INPUT.file_path. Verify: 1) Not in /etc or system directories 2) Not .env or credentials 3) Path doesn't contain '..' traversal. Return 'approve' or 'deny'.\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n**Use for:** Preventing writes to sensitive files or system directories.\n\n## Pattern 2: Test Enforcement\n\nEnsure tests run before stopping:\n\n```json\n{\n  \"Stop\": [\n    {\n      \"matcher\": \"*\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Review transcript. If code was modified (Write/Edit tools used), verify tests were executed. If no tests were run, block with reason 'Tests must be run after code changes'.\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n**Use for:** Enforcing quality standards and preventing incomplete work.\n\n## Pattern 3: Context Loading\n\nLoad project-specific context at session start:\n\n```json\n{\n  \"SessionStart\": [\n    {\n      \"matcher\": \"*\",\n      \"hooks\": [\n        {\n          \"type\": \"command\",\n          \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/scripts/load-context.sh\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n**Example script (load-context.sh):**\n```bash\n#!/bin/bash\ncd \"$CLAUDE_PROJECT_DIR\" || exit 1\n\n# Detect project type\nif [ -f \"package.json\" ]; then\n  echo \"ðŸ“¦ Node.js project detected\"\n  echo \"export PROJECT_TYPE=nodejs\" >> \"$CLAUDE_ENV_FILE\"\nelif [ -f \"Cargo.toml\" ]; then\n  echo \"ðŸ¦€ Rust project detected\"\n  echo \"export PROJECT_TYPE=rust\" >> \"$CLAUDE_ENV_FILE\"\nfi\n```\n\n**Use for:** Automatically detecting and configuring project-specific settings.\n\n## Pattern 4: Notification Logging\n\nLog all notifications for audit or analysis:\n\n```json\n{\n  \"Notification\": [\n    {\n      \"matcher\": \"*\",\n      \"hooks\": [\n        {\n          \"type\": \"command\",\n          \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/scripts/log-notification.sh\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n**Use for:** Tracking user notifications or integration with external logging systems.\n\n## Pattern 5: MCP Tool Monitoring\n\nMonitor and validate MCP tool usage:\n\n```json\n{\n  \"PreToolUse\": [\n    {\n      \"matcher\": \"mcp__.*__delete.*\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Deletion operation detected. Verify: Is this deletion intentional? Can it be undone? Are there backups? Return 'approve' only if safe.\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n**Use for:** Protecting against destructive MCP operations.\n\n## Pattern 6: Build Verification\n\nEnsure project builds after code changes:\n\n```json\n{\n  \"Stop\": [\n    {\n      \"matcher\": \"*\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Check if code was modified. If Write/Edit tools were used, verify the project was built (npm run build, cargo build, etc). If not built, block and request build.\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n**Use for:** Catching build errors before committing or stopping work.\n\n## Pattern 7: Permission Confirmation\n\nAsk user before dangerous operations:\n\n```json\n{\n  \"PreToolUse\": [\n    {\n      \"matcher\": \"Bash\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Command: $TOOL_INPUT.command. If command contains 'rm', 'delete', 'drop', or other destructive operations, return 'ask' to confirm with user. Otherwise 'approve'.\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n**Use for:** User confirmation on potentially destructive commands.\n\n## Pattern 8: Code Quality Checks\n\nRun linters or formatters on file edits:\n\n```json\n{\n  \"PostToolUse\": [\n    {\n      \"matcher\": \"Write|Edit\",\n      \"hooks\": [\n        {\n          \"type\": \"command\",\n          \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/scripts/check-quality.sh\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n**Example script (check-quality.sh):**\n```bash\n#!/bin/bash\ninput=$(cat)\nfile_path=$(echo \"$input\" | jq -r '.tool_input.file_path')\n\n# Run linter if applicable\nif [[ \"$file_path\" == *.js ]] || [[ \"$file_path\" == *.ts ]]; then\n  npx eslint \"$file_path\" 2>&1 || true\nfi\n```\n\n**Use for:** Automatic code quality enforcement.\n\n## Pattern Combinations\n\nCombine multiple patterns for comprehensive protection:\n\n```json\n{\n  \"PreToolUse\": [\n    {\n      \"matcher\": \"Write|Edit\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Validate file write safety\"\n        }\n      ]\n    },\n    {\n      \"matcher\": \"Bash\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Validate bash command safety\"\n        }\n      ]\n    }\n  ],\n  \"Stop\": [\n    {\n      \"matcher\": \"*\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Verify tests run and build succeeded\"\n        }\n      ]\n    }\n  ],\n  \"SessionStart\": [\n    {\n      \"matcher\": \"*\",\n      \"hooks\": [\n        {\n          \"type\": \"command\",\n          \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/scripts/load-context.sh\"\n        }\n      ]\n    }\n  ]\n}\n```\n\nThis provides multi-layered protection and automation.\n\n## Pattern 9: Temporarily Active Hooks\n\nCreate hooks that only run when explicitly enabled via flag files:\n\n```bash\n#!/bin/bash\n# Hook only active when flag file exists\nFLAG_FILE=\"$CLAUDE_PROJECT_DIR/.enable-security-scan\"\n\nif [ ! -f \"$FLAG_FILE\" ]; then\n  # Quick exit when disabled\n  exit 0\nfi\n\n# Flag present, run validation\ninput=$(cat)\nfile_path=$(echo \"$input\" | jq -r '.tool_input.file_path')\n\n# Run security scan\nsecurity-scanner \"$file_path\"\n```\n\n**Activation:**\n```bash\n# Enable the hook\ntouch .enable-security-scan\n\n# Disable the hook\nrm .enable-security-scan\n```\n\n**Use for:**\n- Temporary debugging hooks\n- Feature flags for development\n- Project-specific validation that's opt-in\n- Performance-intensive checks only when needed\n\n**Note:** Must restart Claude Code after creating/removing flag files for hooks to recognize changes.\n\n## Pattern 10: Configuration-Driven Hooks\n\nUse JSON configuration to control hook behavior:\n\n```bash\n#!/bin/bash\nCONFIG_FILE=\"$CLAUDE_PROJECT_DIR/.claude/my-plugin.local.json\"\n\n# Read configuration\nif [ -f \"$CONFIG_FILE\" ]; then\n  strict_mode=$(jq -r '.strictMode // false' \"$CONFIG_FILE\")\n  max_file_size=$(jq -r '.maxFileSize // 1000000' \"$CONFIG_FILE\")\nelse\n  # Defaults\n  strict_mode=false\n  max_file_size=1000000\nfi\n\n# Skip if not in strict mode\nif [ \"$strict_mode\" != \"true\" ]; then\n  exit 0\nfi\n\n# Apply configured limits\ninput=$(cat)\nfile_size=$(echo \"$input\" | jq -r '.tool_input.content | length')\n\nif [ \"$file_size\" -gt \"$max_file_size\" ]; then\n  echo '{\"decision\": \"deny\", \"reason\": \"File exceeds configured size limit\"}' >&2\n  exit 2\nfi\n```\n\n**Configuration file (.claude/my-plugin.local.json):**\n```json\n{\n  \"strictMode\": true,\n  \"maxFileSize\": 500000,\n  \"allowedPaths\": [\"/tmp\", \"/home/user/projects\"]\n}\n```\n\n**Use for:**\n- User-configurable hook behavior\n- Per-project settings\n- Team-specific rules\n- Dynamic validation criteria\n",
        "plugins/plugin-dev/skills/hook-development/scripts/README.md": "# Hook Development Utility Scripts\n\nThese scripts help validate, test, and lint hook implementations before deployment.\n\n## validate-hook-schema.sh\n\nValidates `hooks.json` configuration files for correct structure and common issues.\n\n**Usage:**\n```bash\n./validate-hook-schema.sh path/to/hooks.json\n```\n\n**Checks:**\n- Valid JSON syntax\n- Required fields present\n- Valid hook event names\n- Proper hook types (command/prompt)\n- Timeout values in valid ranges\n- Hardcoded path detection\n- Prompt hook event compatibility\n\n**Example:**\n```bash\ncd my-plugin\n./validate-hook-schema.sh hooks/hooks.json\n```\n\n## test-hook.sh\n\nTests individual hook scripts with sample input before deploying to Claude Code.\n\n**Usage:**\n```bash\n./test-hook.sh [options] <hook-script> <test-input.json>\n```\n\n**Options:**\n- `-v, --verbose` - Show detailed execution information\n- `-t, --timeout N` - Set timeout in seconds (default: 60)\n- `--create-sample <event-type>` - Generate sample test input\n\n**Example:**\n```bash\n# Create sample test input\n./test-hook.sh --create-sample PreToolUse > test-input.json\n\n# Test a hook script\n./test-hook.sh my-hook.sh test-input.json\n\n# Test with verbose output and custom timeout\n./test-hook.sh -v -t 30 my-hook.sh test-input.json\n```\n\n**Features:**\n- Sets up proper environment variables (CLAUDE_PROJECT_DIR, CLAUDE_PLUGIN_ROOT)\n- Measures execution time\n- Validates output JSON\n- Shows exit codes and their meanings\n- Captures environment file output\n\n## hook-linter.sh\n\nChecks hook scripts for common issues and best practices violations.\n\n**Usage:**\n```bash\n./hook-linter.sh <hook-script.sh> [hook-script2.sh ...]\n```\n\n**Checks:**\n- Shebang presence\n- `set -euo pipefail` usage\n- Stdin input reading\n- Proper error handling\n- Variable quoting (injection prevention)\n- Exit code usage\n- Hardcoded paths\n- Long-running code detection\n- Error output to stderr\n- Input validation\n\n**Example:**\n```bash\n# Lint single script\n./hook-linter.sh ../examples/validate-write.sh\n\n# Lint multiple scripts\n./hook-linter.sh ../examples/*.sh\n```\n\n## Typical Workflow\n\n1. **Write your hook script**\n   ```bash\n   vim my-plugin/scripts/my-hook.sh\n   ```\n\n2. **Lint the script**\n   ```bash\n   ./hook-linter.sh my-plugin/scripts/my-hook.sh\n   ```\n\n3. **Create test input**\n   ```bash\n   ./test-hook.sh --create-sample PreToolUse > test-input.json\n   # Edit test-input.json as needed\n   ```\n\n4. **Test the hook**\n   ```bash\n   ./test-hook.sh -v my-plugin/scripts/my-hook.sh test-input.json\n   ```\n\n5. **Add to hooks.json**\n   ```bash\n   # Edit my-plugin/hooks/hooks.json\n   ```\n\n6. **Validate configuration**\n   ```bash\n   ./validate-hook-schema.sh my-plugin/hooks/hooks.json\n   ```\n\n7. **Test in Claude Code**\n   ```bash\n   claude --debug\n   ```\n\n## Tips\n\n- Always test hooks before deploying to avoid breaking user workflows\n- Use verbose mode (`-v`) to debug hook behavior\n- Check the linter output for security and best practice issues\n- Validate hooks.json after any changes\n- Create different test inputs for various scenarios (safe operations, dangerous operations, edge cases)\n\n## Common Issues\n\n### Hook doesn't execute\n\nCheck:\n- Script has shebang (`#!/bin/bash`)\n- Script is executable (`chmod +x`)\n- Path in hooks.json is correct (use `${CLAUDE_PLUGIN_ROOT}`)\n\n### Hook times out\n\n- Reduce timeout in hooks.json\n- Optimize hook script performance\n- Remove long-running operations\n\n### Hook fails silently\n\n- Check exit codes (should be 0 or 2)\n- Ensure errors go to stderr (`>&2`)\n- Validate JSON output structure\n\n### Injection vulnerabilities\n\n- Always quote variables: `\"$variable\"`\n- Use `set -euo pipefail`\n- Validate all input fields\n- Run the linter to catch issues\n",
        "plugins/plugin-dev/skills/mcp-integration/SKILL.md": "---\nname: mcp-integration\ndescription: This skill should be used when the user asks to \"add MCP server\", \"integrate MCP\", \"configure MCP in plugin\", \"use .mcp.json\", \"set up Model Context Protocol\", \"connect external service\", mentions \"${CLAUDE_PLUGIN_ROOT} with MCP\", or discusses MCP server types (SSE, stdio, HTTP, WebSocket). Provides comprehensive guidance for integrating Model Context Protocol servers into Claude Code plugins for external tool and service integration.\n---\n\n# MCP Integration for Claude Code Plugins\n\n## Overview\n\nModel Context Protocol (MCP) enables Claude Code plugins to integrate with external services and APIs by providing structured tool access. Use MCP integration to expose external service capabilities as tools within Claude Code.\n\n**Key capabilities:**\n- Connect to external services (databases, APIs, file systems)\n- Provide 10+ related tools from a single service\n- Handle OAuth and complex authentication flows\n- Bundle MCP servers with plugins for automatic setup\n\n## MCP Server Configuration Methods\n\nPlugins can bundle MCP servers in two ways:\n\n### Method 1: Dedicated .mcp.json (Recommended)\n\nCreate `.mcp.json` at plugin root:\n\n```json\n{\n  \"database-tools\": {\n    \"command\": \"${CLAUDE_PLUGIN_ROOT}/servers/db-server\",\n    \"args\": [\"--config\", \"${CLAUDE_PLUGIN_ROOT}/config.json\"],\n    \"env\": {\n      \"DB_URL\": \"${DB_URL}\"\n    }\n  }\n}\n```\n\n**Benefits:**\n- Clear separation of concerns\n- Easier to maintain\n- Better for multiple servers\n\n### Method 2: Inline in plugin.json\n\nAdd `mcpServers` field to plugin.json:\n\n```json\n{\n  \"name\": \"my-plugin\",\n  \"version\": \"1.0.0\",\n  \"mcpServers\": {\n    \"plugin-api\": {\n      \"command\": \"${CLAUDE_PLUGIN_ROOT}/servers/api-server\",\n      \"args\": [\"--port\", \"8080\"]\n    }\n  }\n}\n```\n\n**Benefits:**\n- Single configuration file\n- Good for simple single-server plugins\n\n## MCP Server Types\n\n### stdio (Local Process)\n\nExecute local MCP servers as child processes. Best for local tools and custom servers.\n\n**Configuration:**\n```json\n{\n  \"filesystem\": {\n    \"command\": \"npx\",\n    \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", \"/allowed/path\"],\n    \"env\": {\n      \"LOG_LEVEL\": \"debug\"\n    }\n  }\n}\n```\n\n**Use cases:**\n- File system access\n- Local database connections\n- Custom MCP servers\n- NPM-packaged MCP servers\n\n**Process management:**\n- Claude Code spawns and manages the process\n- Communicates via stdin/stdout\n- Terminates when Claude Code exits\n\n### SSE (Server-Sent Events)\n\nConnect to hosted MCP servers with OAuth support. Best for cloud services.\n\n**Configuration:**\n```json\n{\n  \"asana\": {\n    \"type\": \"sse\",\n    \"url\": \"https://mcp.asana.com/sse\"\n  }\n}\n```\n\n**Use cases:**\n- Official hosted MCP servers (Asana, GitHub, etc.)\n- Cloud services with MCP endpoints\n- OAuth-based authentication\n- No local installation needed\n\n**Authentication:**\n- OAuth flows handled automatically\n- User prompted on first use\n- Tokens managed by Claude Code\n\n### HTTP (REST API)\n\nConnect to RESTful MCP servers with token authentication.\n\n**Configuration:**\n```json\n{\n  \"api-service\": {\n    \"type\": \"http\",\n    \"url\": \"https://api.example.com/mcp\",\n    \"headers\": {\n      \"Authorization\": \"Bearer ${API_TOKEN}\",\n      \"X-Custom-Header\": \"value\"\n    }\n  }\n}\n```\n\n**Use cases:**\n- REST API-based MCP servers\n- Token-based authentication\n- Custom API backends\n- Stateless interactions\n\n### WebSocket (Real-time)\n\nConnect to WebSocket MCP servers for real-time bidirectional communication.\n\n**Configuration:**\n```json\n{\n  \"realtime-service\": {\n    \"type\": \"ws\",\n    \"url\": \"wss://mcp.example.com/ws\",\n    \"headers\": {\n      \"Authorization\": \"Bearer ${TOKEN}\"\n    }\n  }\n}\n```\n\n**Use cases:**\n- Real-time data streaming\n- Persistent connections\n- Push notifications from server\n- Low-latency requirements\n\n## Environment Variable Expansion\n\nAll MCP configurations support environment variable substitution:\n\n**${CLAUDE_PLUGIN_ROOT}** - Plugin directory (always use for portability):\n```json\n{\n  \"command\": \"${CLAUDE_PLUGIN_ROOT}/servers/my-server\"\n}\n```\n\n**User environment variables** - From user's shell:\n```json\n{\n  \"env\": {\n    \"API_KEY\": \"${MY_API_KEY}\",\n    \"DATABASE_URL\": \"${DB_URL}\"\n  }\n}\n```\n\n**Best practice:** Document all required environment variables in plugin README.\n\n## MCP Tool Naming\n\nWhen MCP servers provide tools, they're automatically prefixed:\n\n**Format:** `mcp__plugin_<plugin-name>_<server-name>__<tool-name>`\n\n**Example:**\n- Plugin: `asana`\n- Server: `asana`\n- Tool: `create_task`\n- **Full name:** `mcp__plugin_asana_asana__asana_create_task`\n\n### Using MCP Tools in Commands\n\nPre-allow specific MCP tools in command frontmatter:\n\n```markdown\n---\nallowed-tools: [\n  \"mcp__plugin_asana_asana__asana_create_task\",\n  \"mcp__plugin_asana_asana__asana_search_tasks\"\n]\n---\n```\n\n**Wildcard (use sparingly):**\n```markdown\n---\nallowed-tools: [\"mcp__plugin_asana_asana__*\"]\n---\n```\n\n**Best practice:** Pre-allow specific tools, not wildcards, for security.\n\n## Lifecycle Management\n\n**Automatic startup:**\n- MCP servers start when plugin enables\n- Connection established before first tool use\n- Restart required for configuration changes\n\n**Lifecycle:**\n1. Plugin loads\n2. MCP configuration parsed\n3. Server process started (stdio) or connection established (SSE/HTTP/WS)\n4. Tools discovered and registered\n5. Tools available as `mcp__plugin_...__...`\n\n**Viewing servers:**\nUse `/mcp` command to see all servers including plugin-provided ones.\n\n## Authentication Patterns\n\n### OAuth (SSE/HTTP)\n\nOAuth handled automatically by Claude Code:\n\n```json\n{\n  \"type\": \"sse\",\n  \"url\": \"https://mcp.example.com/sse\"\n}\n```\n\nUser authenticates in browser on first use. No additional configuration needed.\n\n### Token-Based (Headers)\n\nStatic or environment variable tokens:\n\n```json\n{\n  \"type\": \"http\",\n  \"url\": \"https://api.example.com\",\n  \"headers\": {\n    \"Authorization\": \"Bearer ${API_TOKEN}\"\n  }\n}\n```\n\nDocument required environment variables in README.\n\n### Environment Variables (stdio)\n\nPass configuration to MCP server:\n\n```json\n{\n  \"command\": \"python\",\n  \"args\": [\"-m\", \"my_mcp_server\"],\n  \"env\": {\n    \"DATABASE_URL\": \"${DB_URL}\",\n    \"API_KEY\": \"${API_KEY}\",\n    \"LOG_LEVEL\": \"info\"\n  }\n}\n```\n\n## Integration Patterns\n\n### Pattern 1: Simple Tool Wrapper\n\nCommands use MCP tools with user interaction:\n\n```markdown\n# Command: create-item.md\n---\nallowed-tools: [\"mcp__plugin_name_server__create_item\"]\n---\n\nSteps:\n1. Gather item details from user\n2. Use mcp__plugin_name_server__create_item\n3. Confirm creation\n```\n\n**Use for:** Adding validation or preprocessing before MCP calls.\n\n### Pattern 2: Autonomous Agent\n\nAgents use MCP tools autonomously:\n\n```markdown\n# Agent: data-analyzer.md\n\nAnalysis Process:\n1. Query data via mcp__plugin_db_server__query\n2. Process and analyze results\n3. Generate insights report\n```\n\n**Use for:** Multi-step MCP workflows without user interaction.\n\n### Pattern 3: Multi-Server Plugin\n\nIntegrate multiple MCP servers:\n\n```json\n{\n  \"github\": {\n    \"type\": \"sse\",\n    \"url\": \"https://mcp.github.com/sse\"\n  },\n  \"jira\": {\n    \"type\": \"sse\",\n    \"url\": \"https://mcp.jira.com/sse\"\n  }\n}\n```\n\n**Use for:** Workflows spanning multiple services.\n\n## Security Best Practices\n\n### Use HTTPS/WSS\n\nAlways use secure connections:\n\n```json\nâœ… \"url\": \"https://mcp.example.com/sse\"\nâŒ \"url\": \"http://mcp.example.com/sse\"\n```\n\n### Token Management\n\n**DO:**\n- âœ… Use environment variables for tokens\n- âœ… Document required env vars in README\n- âœ… Let OAuth flow handle authentication\n\n**DON'T:**\n- âŒ Hardcode tokens in configuration\n- âŒ Commit tokens to git\n- âŒ Share tokens in documentation\n\n### Permission Scoping\n\nPre-allow only necessary MCP tools:\n\n```markdown\nâœ… allowed-tools: [\n  \"mcp__plugin_api_server__read_data\",\n  \"mcp__plugin_api_server__create_item\"\n]\n\nâŒ allowed-tools: [\"mcp__plugin_api_server__*\"]\n```\n\n## Error Handling\n\n### Connection Failures\n\nHandle MCP server unavailability:\n- Provide fallback behavior in commands\n- Inform user of connection issues\n- Check server URL and configuration\n\n### Tool Call Errors\n\nHandle failed MCP operations:\n- Validate inputs before calling MCP tools\n- Provide clear error messages\n- Check rate limiting and quotas\n\n### Configuration Errors\n\nValidate MCP configuration:\n- Test server connectivity during development\n- Validate JSON syntax\n- Check required environment variables\n\n## Performance Considerations\n\n### Lazy Loading\n\nMCP servers connect on-demand:\n- Not all servers connect at startup\n- First tool use triggers connection\n- Connection pooling managed automatically\n\n### Batching\n\nBatch similar requests when possible:\n\n```\n# Good: Single query with filters\ntasks = search_tasks(project=\"X\", assignee=\"me\", limit=50)\n\n# Avoid: Many individual queries\nfor id in task_ids:\n    task = get_task(id)\n```\n\n## Testing MCP Integration\n\n### Local Testing\n\n1. Configure MCP server in `.mcp.json`\n2. Install plugin locally (`.claude-plugin/`)\n3. Run `/mcp` to verify server appears\n4. Test tool calls in commands\n5. Check `claude --debug` logs for connection issues\n\n### Validation Checklist\n\n- [ ] MCP configuration is valid JSON\n- [ ] Server URL is correct and accessible\n- [ ] Required environment variables documented\n- [ ] Tools appear in `/mcp` output\n- [ ] Authentication works (OAuth or tokens)\n- [ ] Tool calls succeed from commands\n- [ ] Error cases handled gracefully\n\n## Debugging\n\n### Enable Debug Logging\n\n```bash\nclaude --debug\n```\n\nLook for:\n- MCP server connection attempts\n- Tool discovery logs\n- Authentication flows\n- Tool call errors\n\n### Common Issues\n\n**Server not connecting:**\n- Check URL is correct\n- Verify server is running (stdio)\n- Check network connectivity\n- Review authentication configuration\n\n**Tools not available:**\n- Verify server connected successfully\n- Check tool names match exactly\n- Run `/mcp` to see available tools\n- Restart Claude Code after config changes\n\n**Authentication failing:**\n- Clear cached auth tokens\n- Re-authenticate\n- Check token scopes and permissions\n- Verify environment variables set\n\n## Quick Reference\n\n### MCP Server Types\n\n| Type | Transport | Best For | Auth |\n|------|-----------|----------|------|\n| stdio | Process | Local tools, custom servers | Env vars |\n| SSE | HTTP | Hosted services, cloud APIs | OAuth |\n| HTTP | REST | API backends, token auth | Tokens |\n| ws | WebSocket | Real-time, streaming | Tokens |\n\n### Configuration Checklist\n\n- [ ] Server type specified (stdio/SSE/HTTP/ws)\n- [ ] Type-specific fields complete (command or url)\n- [ ] Authentication configured\n- [ ] Environment variables documented\n- [ ] HTTPS/WSS used (not HTTP/WS)\n- [ ] ${CLAUDE_PLUGIN_ROOT} used for paths\n\n### Best Practices\n\n**DO:**\n- âœ… Use ${CLAUDE_PLUGIN_ROOT} for portable paths\n- âœ… Document required environment variables\n- âœ… Use secure connections (HTTPS/WSS)\n- âœ… Pre-allow specific MCP tools in commands\n- âœ… Test MCP integration before publishing\n- âœ… Handle connection and tool errors gracefully\n\n**DON'T:**\n- âŒ Hardcode absolute paths\n- âŒ Commit credentials to git\n- âŒ Use HTTP instead of HTTPS\n- âŒ Pre-allow all tools with wildcards\n- âŒ Skip error handling\n- âŒ Forget to document setup\n\n## Additional Resources\n\n### Reference Files\n\nFor detailed information, consult:\n\n- **`references/server-types.md`** - Deep dive on each server type\n- **`references/authentication.md`** - Authentication patterns and OAuth\n- **`references/tool-usage.md`** - Using MCP tools in commands and agents\n\n### Example Configurations\n\nWorking examples in `examples/`:\n\n- **`stdio-server.json`** - Local stdio MCP server\n- **`sse-server.json`** - Hosted SSE server with OAuth\n- **`http-server.json`** - REST API with token auth\n\n### External Resources\n\n- **Official MCP Docs**: https://modelcontextprotocol.io/\n- **Claude Code MCP Docs**: https://docs.claude.com/en/docs/claude-code/mcp\n- **MCP SDK**: @modelcontextprotocol/sdk\n- **Testing**: Use `claude --debug` and `/mcp` command\n\n## Implementation Workflow\n\nTo add MCP integration to a plugin:\n\n1. Choose MCP server type (stdio, SSE, HTTP, ws)\n2. Create `.mcp.json` at plugin root with configuration\n3. Use ${CLAUDE_PLUGIN_ROOT} for all file references\n4. Document required environment variables in README\n5. Test locally with `/mcp` command\n6. Pre-allow MCP tools in relevant commands\n7. Handle authentication (OAuth or tokens)\n8. Test error cases (connection failures, auth errors)\n9. Document MCP integration in plugin README\n\nFocus on stdio for custom/local servers, SSE for hosted services with OAuth.\n",
        "plugins/plugin-dev/skills/mcp-integration/references/authentication.md": "# MCP Authentication Patterns\n\nComplete guide to authentication methods for MCP servers in Claude Code plugins.\n\n## Overview\n\nMCP servers support multiple authentication methods depending on the server type and service requirements. Choose the method that best matches your use case and security requirements.\n\n## OAuth (Automatic)\n\n### How It Works\n\nClaude Code automatically handles the complete OAuth 2.0 flow for SSE and HTTP servers:\n\n1. User attempts to use MCP tool\n2. Claude Code detects authentication needed\n3. Opens browser for OAuth consent\n4. User authorizes in browser\n5. Tokens stored securely by Claude Code\n6. Automatic token refresh\n\n### Configuration\n\n```json\n{\n  \"service\": {\n    \"type\": \"sse\",\n    \"url\": \"https://mcp.example.com/sse\"\n  }\n}\n```\n\nNo additional auth configuration needed! Claude Code handles everything.\n\n### Supported Services\n\n**Known OAuth-enabled MCP servers:**\n- Asana: `https://mcp.asana.com/sse`\n- GitHub (when available)\n- Google services (when available)\n- Custom OAuth servers\n\n### OAuth Scopes\n\nOAuth scopes are determined by the MCP server. Users see required scopes during the consent flow.\n\n**Document required scopes in your README:**\n```markdown\n## Authentication\n\nThis plugin requires the following Asana permissions:\n- Read tasks and projects\n- Create and update tasks\n- Access workspace data\n```\n\n### Token Storage\n\nTokens are stored securely by Claude Code:\n- Not accessible to plugins\n- Encrypted at rest\n- Automatic refresh\n- Cleared on sign-out\n\n### Troubleshooting OAuth\n\n**Authentication loop:**\n- Clear cached tokens (sign out and sign in)\n- Check OAuth redirect URLs\n- Verify server OAuth configuration\n\n**Scope issues:**\n- User may need to re-authorize for new scopes\n- Check server documentation for required scopes\n\n**Token expiration:**\n- Claude Code auto-refreshes\n- If refresh fails, prompts re-authentication\n\n## Token-Based Authentication\n\n### Bearer Tokens\n\nMost common for HTTP and WebSocket servers.\n\n**Configuration:**\n```json\n{\n  \"api\": {\n    \"type\": \"http\",\n    \"url\": \"https://api.example.com/mcp\",\n    \"headers\": {\n      \"Authorization\": \"Bearer ${API_TOKEN}\"\n    }\n  }\n}\n```\n\n**Environment variable:**\n```bash\nexport API_TOKEN=\"your-secret-token-here\"\n```\n\n### API Keys\n\nAlternative to Bearer tokens, often in custom headers.\n\n**Configuration:**\n```json\n{\n  \"api\": {\n    \"type\": \"http\",\n    \"url\": \"https://api.example.com/mcp\",\n    \"headers\": {\n      \"X-API-Key\": \"${API_KEY}\",\n      \"X-API-Secret\": \"${API_SECRET}\"\n    }\n  }\n}\n```\n\n### Custom Headers\n\nServices may use custom authentication headers.\n\n**Configuration:**\n```json\n{\n  \"service\": {\n    \"type\": \"sse\",\n    \"url\": \"https://mcp.example.com/sse\",\n    \"headers\": {\n      \"X-Auth-Token\": \"${AUTH_TOKEN}\",\n      \"X-User-ID\": \"${USER_ID}\",\n      \"X-Tenant-ID\": \"${TENANT_ID}\"\n    }\n  }\n}\n```\n\n### Documenting Token Requirements\n\nAlways document in your README:\n\n```markdown\n## Setup\n\n### Required Environment Variables\n\nSet these environment variables before using the plugin:\n\n\\`\\`\\`bash\nexport API_TOKEN=\"your-token-here\"\nexport API_SECRET=\"your-secret-here\"\n\\`\\`\\`\n\n### Obtaining Tokens\n\n1. Visit https://api.example.com/tokens\n2. Create a new API token\n3. Copy the token and secret\n4. Set environment variables as shown above\n\n### Token Permissions\n\nThe API token needs the following permissions:\n- Read access to resources\n- Write access for creating items\n- Delete access (optional, for cleanup operations)\n\\`\\`\\`\n```\n\n## Environment Variable Authentication (stdio)\n\n### Passing Credentials to Server\n\nFor stdio servers, pass credentials via environment variables:\n\n```json\n{\n  \"database\": {\n    \"command\": \"python\",\n    \"args\": [\"-m\", \"mcp_server_db\"],\n    \"env\": {\n      \"DATABASE_URL\": \"${DATABASE_URL}\",\n      \"DB_USER\": \"${DB_USER}\",\n      \"DB_PASSWORD\": \"${DB_PASSWORD}\"\n    }\n  }\n}\n```\n\n### User Environment Variables\n\n```bash\n# User sets these in their shell\nexport DATABASE_URL=\"postgresql://localhost/mydb\"\nexport DB_USER=\"myuser\"\nexport DB_PASSWORD=\"mypassword\"\n```\n\n### Documentation Template\n\n```markdown\n## Database Configuration\n\nSet these environment variables:\n\n\\`\\`\\`bash\nexport DATABASE_URL=\"postgresql://host:port/database\"\nexport DB_USER=\"username\"\nexport DB_PASSWORD=\"password\"\n\\`\\`\\`\n\nOr create a `.env` file (add to `.gitignore`):\n\n\\`\\`\\`\nDATABASE_URL=postgresql://localhost:5432/mydb\nDB_USER=myuser\nDB_PASSWORD=mypassword\n\\`\\`\\`\n\nLoad with: \\`source .env\\` or \\`export $(cat .env | xargs)\\`\n\\`\\`\\`\n```\n\n## Dynamic Headers\n\n### Headers Helper Script\n\nFor tokens that change or expire, use a helper script:\n\n```json\n{\n  \"api\": {\n    \"type\": \"sse\",\n    \"url\": \"https://api.example.com\",\n    \"headersHelper\": \"${CLAUDE_PLUGIN_ROOT}/scripts/get-headers.sh\"\n  }\n}\n```\n\n**Script (get-headers.sh):**\n```bash\n#!/bin/bash\n# Generate dynamic authentication headers\n\n# Fetch fresh token\nTOKEN=$(get-fresh-token-from-somewhere)\n\n# Output JSON headers\ncat <<EOF\n{\n  \"Authorization\": \"Bearer $TOKEN\",\n  \"X-Timestamp\": \"$(date -Iseconds)\"\n}\nEOF\n```\n\n### Use Cases for Dynamic Headers\n\n- Short-lived tokens that need refresh\n- Tokens with HMAC signatures\n- Time-based authentication\n- Dynamic tenant/workspace selection\n\n## Security Best Practices\n\n### DO\n\nâœ… **Use environment variables:**\n```json\n{\n  \"headers\": {\n    \"Authorization\": \"Bearer ${API_TOKEN}\"\n  }\n}\n```\n\nâœ… **Document required variables in README**\n\nâœ… **Use HTTPS/WSS always**\n\nâœ… **Implement token rotation**\n\nâœ… **Store tokens securely (env vars, not files)**\n\nâœ… **Let OAuth handle authentication when available**\n\n### DON'T\n\nâŒ **Hardcode tokens:**\n```json\n{\n  \"headers\": {\n    \"Authorization\": \"Bearer sk-abc123...\"  // NEVER!\n  }\n}\n```\n\nâŒ **Commit tokens to git**\n\nâŒ **Share tokens in documentation**\n\nâŒ **Use HTTP instead of HTTPS**\n\nâŒ **Store tokens in plugin files**\n\nâŒ **Log tokens or sensitive headers**\n\n## Multi-Tenancy Patterns\n\n### Workspace/Tenant Selection\n\n**Via environment variable:**\n```json\n{\n  \"api\": {\n    \"type\": \"http\",\n    \"url\": \"https://api.example.com/mcp\",\n    \"headers\": {\n      \"Authorization\": \"Bearer ${API_TOKEN}\",\n      \"X-Workspace-ID\": \"${WORKSPACE_ID}\"\n    }\n  }\n}\n```\n\n**Via URL:**\n```json\n{\n  \"api\": {\n    \"type\": \"http\",\n    \"url\": \"https://${TENANT_ID}.api.example.com/mcp\"\n  }\n}\n```\n\n### Per-User Configuration\n\nUsers set their own workspace:\n\n```bash\nexport WORKSPACE_ID=\"my-workspace-123\"\nexport TENANT_ID=\"my-company\"\n```\n\n## Authentication Troubleshooting\n\n### Common Issues\n\n**401 Unauthorized:**\n- Check token is set correctly\n- Verify token hasn't expired\n- Check token has required permissions\n- Ensure header format is correct\n\n**403 Forbidden:**\n- Token valid but lacks permissions\n- Check scope/permissions\n- Verify workspace/tenant ID\n- May need admin approval\n\n**Token not found:**\n```bash\n# Check environment variable is set\necho $API_TOKEN\n\n# If empty, set it\nexport API_TOKEN=\"your-token\"\n```\n\n**Token in wrong format:**\n```json\n// Correct\n\"Authorization\": \"Bearer sk-abc123\"\n\n// Wrong\n\"Authorization\": \"sk-abc123\"\n```\n\n### Debugging Authentication\n\n**Enable debug mode:**\n```bash\nclaude --debug\n```\n\nLook for:\n- Authentication header values (sanitized)\n- OAuth flow progress\n- Token refresh attempts\n- Authentication errors\n\n**Test authentication separately:**\n```bash\n# Test HTTP endpoint\ncurl -H \"Authorization: Bearer $API_TOKEN\" \\\n     https://api.example.com/mcp/health\n\n# Should return 200 OK\n```\n\n## Migration Patterns\n\n### From Hardcoded to Environment Variables\n\n**Before:**\n```json\n{\n  \"headers\": {\n    \"Authorization\": \"Bearer sk-hardcoded-token\"\n  }\n}\n```\n\n**After:**\n```json\n{\n  \"headers\": {\n    \"Authorization\": \"Bearer ${API_TOKEN}\"\n  }\n}\n```\n\n**Migration steps:**\n1. Add environment variable to plugin README\n2. Update configuration to use ${VAR}\n3. Test with variable set\n4. Remove hardcoded value\n5. Commit changes\n\n### From Basic Auth to OAuth\n\n**Before:**\n```json\n{\n  \"headers\": {\n    \"Authorization\": \"Basic ${BASE64_CREDENTIALS}\"\n  }\n}\n```\n\n**After:**\n```json\n{\n  \"type\": \"sse\",\n  \"url\": \"https://mcp.example.com/sse\"\n}\n```\n\n**Benefits:**\n- Better security\n- No credential management\n- Automatic token refresh\n- Scoped permissions\n\n## Advanced Authentication\n\n### Mutual TLS (mTLS)\n\nSome enterprise services require client certificates.\n\n**Not directly supported in MCP configuration.**\n\n**Workaround:** Wrap in stdio server that handles mTLS:\n\n```json\n{\n  \"secure-api\": {\n    \"command\": \"${CLAUDE_PLUGIN_ROOT}/servers/mtls-wrapper\",\n    \"args\": [\"--cert\", \"${CLIENT_CERT}\", \"--key\", \"${CLIENT_KEY}\"],\n    \"env\": {\n      \"API_URL\": \"https://secure.example.com\"\n    }\n  }\n}\n```\n\n### JWT Tokens\n\nGenerate JWT tokens dynamically with headers helper:\n\n```bash\n#!/bin/bash\n# generate-jwt.sh\n\n# Generate JWT (using library or API call)\nJWT=$(generate-jwt-token)\n\necho \"{\\\"Authorization\\\": \\\"Bearer $JWT\\\"}\"\n```\n\n```json\n{\n  \"headersHelper\": \"${CLAUDE_PLUGIN_ROOT}/scripts/generate-jwt.sh\"\n}\n```\n\n### HMAC Signatures\n\nFor APIs requiring request signing:\n\n```bash\n#!/bin/bash\n# generate-hmac.sh\n\nTIMESTAMP=$(date -Iseconds)\nSIGNATURE=$(echo -n \"$TIMESTAMP\" | openssl dgst -sha256 -hmac \"$SECRET_KEY\" | cut -d' ' -f2)\n\ncat <<EOF\n{\n  \"X-Timestamp\": \"$TIMESTAMP\",\n  \"X-Signature\": \"$SIGNATURE\",\n  \"X-API-Key\": \"$API_KEY\"\n}\nEOF\n```\n\n## Best Practices Summary\n\n### For Plugin Developers\n\n1. **Prefer OAuth** when service supports it\n2. **Use environment variables** for tokens\n3. **Document all required variables** in README\n4. **Provide setup instructions** with examples\n5. **Never commit credentials**\n6. **Use HTTPS/WSS only**\n7. **Test authentication thoroughly**\n\n### For Plugin Users\n\n1. **Set environment variables** before using plugin\n2. **Keep tokens secure** and private\n3. **Rotate tokens regularly**\n4. **Use different tokens** for dev/prod\n5. **Don't commit .env files** to git\n6. **Review OAuth scopes** before authorizing\n\n## Conclusion\n\nChoose the authentication method that matches your MCP server's requirements:\n- **OAuth** for cloud services (easiest for users)\n- **Bearer tokens** for API services\n- **Environment variables** for stdio servers\n- **Dynamic headers** for complex auth flows\n\nAlways prioritize security and provide clear setup documentation for users.\n",
        "plugins/plugin-dev/skills/mcp-integration/references/server-types.md": "# MCP Server Types: Deep Dive\n\nComplete reference for all MCP server types supported in Claude Code plugins.\n\n## stdio (Standard Input/Output)\n\n### Overview\n\nExecute local MCP servers as child processes with communication via stdin/stdout. Best choice for local tools, custom servers, and NPM packages.\n\n### Configuration\n\n**Basic:**\n```json\n{\n  \"my-server\": {\n    \"command\": \"npx\",\n    \"args\": [\"-y\", \"my-mcp-server\"]\n  }\n}\n```\n\n**With environment:**\n```json\n{\n  \"my-server\": {\n    \"command\": \"${CLAUDE_PLUGIN_ROOT}/servers/custom-server\",\n    \"args\": [\"--config\", \"${CLAUDE_PLUGIN_ROOT}/config.json\"],\n    \"env\": {\n      \"API_KEY\": \"${MY_API_KEY}\",\n      \"LOG_LEVEL\": \"debug\",\n      \"DATABASE_URL\": \"${DB_URL}\"\n    }\n  }\n}\n```\n\n### Process Lifecycle\n\n1. **Startup**: Claude Code spawns process with `command` and `args`\n2. **Communication**: JSON-RPC messages via stdin/stdout\n3. **Lifecycle**: Process runs for entire Claude Code session\n4. **Shutdown**: Process terminated when Claude Code exits\n\n### Use Cases\n\n**NPM Packages:**\n```json\n{\n  \"filesystem\": {\n    \"command\": \"npx\",\n    \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", \"/path\"]\n  }\n}\n```\n\n**Custom Scripts:**\n```json\n{\n  \"custom\": {\n    \"command\": \"${CLAUDE_PLUGIN_ROOT}/servers/my-server.js\",\n    \"args\": [\"--verbose\"]\n  }\n}\n```\n\n**Python Servers:**\n```json\n{\n  \"python-server\": {\n    \"command\": \"python\",\n    \"args\": [\"-m\", \"my_mcp_server\"],\n    \"env\": {\n      \"PYTHONUNBUFFERED\": \"1\"\n    }\n  }\n}\n```\n\n### Best Practices\n\n1. **Use absolute paths or ${CLAUDE_PLUGIN_ROOT}**\n2. **Set PYTHONUNBUFFERED for Python servers**\n3. **Pass configuration via args or env, not stdin**\n4. **Handle server crashes gracefully**\n5. **Log to stderr, not stdout (stdout is for MCP protocol)**\n\n### Troubleshooting\n\n**Server won't start:**\n- Check command exists and is executable\n- Verify file paths are correct\n- Check permissions\n- Review `claude --debug` logs\n\n**Communication fails:**\n- Ensure server uses stdin/stdout correctly\n- Check for stray print/console.log statements\n- Verify JSON-RPC format\n\n## SSE (Server-Sent Events)\n\n### Overview\n\nConnect to hosted MCP servers via HTTP with server-sent events for streaming. Best for cloud services and OAuth authentication.\n\n### Configuration\n\n**Basic:**\n```json\n{\n  \"hosted-service\": {\n    \"type\": \"sse\",\n    \"url\": \"https://mcp.example.com/sse\"\n  }\n}\n```\n\n**With headers:**\n```json\n{\n  \"service\": {\n    \"type\": \"sse\",\n    \"url\": \"https://mcp.example.com/sse\",\n    \"headers\": {\n      \"X-API-Version\": \"v1\",\n      \"X-Client-ID\": \"${CLIENT_ID}\"\n    }\n  }\n}\n```\n\n### Connection Lifecycle\n\n1. **Initialization**: HTTP connection established to URL\n2. **Handshake**: MCP protocol negotiation\n3. **Streaming**: Server sends events via SSE\n4. **Requests**: Client sends HTTP POST for tool calls\n5. **Reconnection**: Automatic reconnection on disconnect\n\n### Authentication\n\n**OAuth (Automatic):**\n```json\n{\n  \"asana\": {\n    \"type\": \"sse\",\n    \"url\": \"https://mcp.asana.com/sse\"\n  }\n}\n```\n\nClaude Code handles OAuth flow:\n1. User prompted to authenticate on first use\n2. Opens browser for OAuth flow\n3. Tokens stored securely\n4. Automatic token refresh\n\n**Custom Headers:**\n```json\n{\n  \"service\": {\n    \"type\": \"sse\",\n    \"url\": \"https://mcp.example.com/sse\",\n    \"headers\": {\n      \"Authorization\": \"Bearer ${API_TOKEN}\"\n    }\n  }\n}\n```\n\n### Use Cases\n\n**Official Services:**\n- Asana: `https://mcp.asana.com/sse`\n- GitHub: `https://mcp.github.com/sse`\n- Other hosted MCP servers\n\n**Custom Hosted Servers:**\nDeploy your own MCP server and expose via HTTPS + SSE.\n\n### Best Practices\n\n1. **Always use HTTPS, never HTTP**\n2. **Let OAuth handle authentication when available**\n3. **Use environment variables for tokens**\n4. **Handle connection failures gracefully**\n5. **Document OAuth scopes required**\n\n### Troubleshooting\n\n**Connection refused:**\n- Check URL is correct and accessible\n- Verify HTTPS certificate is valid\n- Check network connectivity\n- Review firewall settings\n\n**OAuth fails:**\n- Clear cached tokens\n- Check OAuth scopes\n- Verify redirect URLs\n- Re-authenticate\n\n## HTTP (REST API)\n\n### Overview\n\nConnect to RESTful MCP servers via standard HTTP requests. Best for token-based auth and stateless interactions.\n\n### Configuration\n\n**Basic:**\n```json\n{\n  \"api\": {\n    \"type\": \"http\",\n    \"url\": \"https://api.example.com/mcp\"\n  }\n}\n```\n\n**With authentication:**\n```json\n{\n  \"api\": {\n    \"type\": \"http\",\n    \"url\": \"https://api.example.com/mcp\",\n    \"headers\": {\n      \"Authorization\": \"Bearer ${API_TOKEN}\",\n      \"Content-Type\": \"application/json\",\n      \"X-API-Version\": \"2024-01-01\"\n    }\n  }\n}\n```\n\n### Request/Response Flow\n\n1. **Tool Discovery**: GET to discover available tools\n2. **Tool Invocation**: POST with tool name and parameters\n3. **Response**: JSON response with results or errors\n4. **Stateless**: Each request independent\n\n### Authentication\n\n**Token-Based:**\n```json\n{\n  \"headers\": {\n    \"Authorization\": \"Bearer ${API_TOKEN}\"\n  }\n}\n```\n\n**API Key:**\n```json\n{\n  \"headers\": {\n    \"X-API-Key\": \"${API_KEY}\"\n  }\n}\n```\n\n**Custom Auth:**\n```json\n{\n  \"headers\": {\n    \"X-Auth-Token\": \"${AUTH_TOKEN}\",\n    \"X-User-ID\": \"${USER_ID}\"\n  }\n}\n```\n\n### Use Cases\n\n- REST API backends\n- Internal services\n- Microservices\n- Serverless functions\n\n### Best Practices\n\n1. **Use HTTPS for all connections**\n2. **Store tokens in environment variables**\n3. **Implement retry logic for transient failures**\n4. **Handle rate limiting**\n5. **Set appropriate timeouts**\n\n### Troubleshooting\n\n**HTTP errors:**\n- 401: Check authentication headers\n- 403: Verify permissions\n- 429: Implement rate limiting\n- 500: Check server logs\n\n**Timeout issues:**\n- Increase timeout if needed\n- Check server performance\n- Optimize tool implementations\n\n## WebSocket (Real-time)\n\n### Overview\n\nConnect to MCP servers via WebSocket for real-time bidirectional communication. Best for streaming and low-latency applications.\n\n### Configuration\n\n**Basic:**\n```json\n{\n  \"realtime\": {\n    \"type\": \"ws\",\n    \"url\": \"wss://mcp.example.com/ws\"\n  }\n}\n```\n\n**With authentication:**\n```json\n{\n  \"realtime\": {\n    \"type\": \"ws\",\n    \"url\": \"wss://mcp.example.com/ws\",\n    \"headers\": {\n      \"Authorization\": \"Bearer ${TOKEN}\",\n      \"X-Client-ID\": \"${CLIENT_ID}\"\n    }\n  }\n}\n```\n\n### Connection Lifecycle\n\n1. **Handshake**: WebSocket upgrade request\n2. **Connection**: Persistent bidirectional channel\n3. **Messages**: JSON-RPC over WebSocket\n4. **Heartbeat**: Keep-alive messages\n5. **Reconnection**: Automatic on disconnect\n\n### Use Cases\n\n- Real-time data streaming\n- Live updates and notifications\n- Collaborative editing\n- Low-latency tool calls\n- Push notifications from server\n\n### Best Practices\n\n1. **Use WSS (secure WebSocket), never WS**\n2. **Implement heartbeat/ping-pong**\n3. **Handle reconnection logic**\n4. **Buffer messages during disconnection**\n5. **Set connection timeouts**\n\n### Troubleshooting\n\n**Connection drops:**\n- Implement reconnection logic\n- Check network stability\n- Verify server supports WebSocket\n- Review firewall settings\n\n**Message delivery:**\n- Implement message acknowledgment\n- Handle out-of-order messages\n- Buffer during disconnection\n\n## Comparison Matrix\n\n| Feature | stdio | SSE | HTTP | WebSocket |\n|---------|-------|-----|------|-----------|\n| **Transport** | Process | HTTP/SSE | HTTP | WebSocket |\n| **Direction** | Bidirectional | Serverâ†’Client | Request/Response | Bidirectional |\n| **State** | Stateful | Stateful | Stateless | Stateful |\n| **Auth** | Env vars | OAuth/Headers | Headers | Headers |\n| **Use Case** | Local tools | Cloud services | REST APIs | Real-time |\n| **Latency** | Lowest | Medium | Medium | Low |\n| **Setup** | Easy | Medium | Easy | Medium |\n| **Reconnect** | Process respawn | Automatic | N/A | Automatic |\n\n## Choosing the Right Type\n\n**Use stdio when:**\n- Running local tools or custom servers\n- Need lowest latency\n- Working with file systems or local databases\n- Distributing server with plugin\n\n**Use SSE when:**\n- Connecting to hosted services\n- Need OAuth authentication\n- Using official MCP servers (Asana, GitHub)\n- Want automatic reconnection\n\n**Use HTTP when:**\n- Integrating with REST APIs\n- Need stateless interactions\n- Using token-based auth\n- Simple request/response pattern\n\n**Use WebSocket when:**\n- Need real-time updates\n- Building collaborative features\n- Low-latency critical\n- Bi-directional streaming required\n\n## Migration Between Types\n\n### From stdio to SSE\n\n**Before (stdio):**\n```json\n{\n  \"local-server\": {\n    \"command\": \"node\",\n    \"args\": [\"server.js\"]\n  }\n}\n```\n\n**After (SSE - deploy server):**\n```json\n{\n  \"hosted-server\": {\n    \"type\": \"sse\",\n    \"url\": \"https://mcp.example.com/sse\"\n  }\n}\n```\n\n### From HTTP to WebSocket\n\n**Before (HTTP):**\n```json\n{\n  \"api\": {\n    \"type\": \"http\",\n    \"url\": \"https://api.example.com/mcp\"\n  }\n}\n```\n\n**After (WebSocket):**\n```json\n{\n  \"realtime\": {\n    \"type\": \"ws\",\n    \"url\": \"wss://api.example.com/ws\"\n  }\n}\n```\n\nBenefits: Real-time updates, lower latency, bi-directional communication.\n\n## Advanced Configuration\n\n### Multiple Servers\n\nCombine different types:\n\n```json\n{\n  \"local-db\": {\n    \"command\": \"npx\",\n    \"args\": [\"-y\", \"mcp-server-sqlite\", \"./data.db\"]\n  },\n  \"cloud-api\": {\n    \"type\": \"sse\",\n    \"url\": \"https://mcp.example.com/sse\"\n  },\n  \"internal-service\": {\n    \"type\": \"http\",\n    \"url\": \"https://api.example.com/mcp\",\n    \"headers\": {\n      \"Authorization\": \"Bearer ${API_TOKEN}\"\n    }\n  }\n}\n```\n\n### Conditional Configuration\n\nUse environment variables to switch servers:\n\n```json\n{\n  \"api\": {\n    \"type\": \"http\",\n    \"url\": \"${API_URL}\",\n    \"headers\": {\n      \"Authorization\": \"Bearer ${API_TOKEN}\"\n    }\n  }\n}\n```\n\nSet different values for dev/prod:\n- Dev: `API_URL=http://localhost:8080/mcp`\n- Prod: `API_URL=https://api.production.com/mcp`\n\n## Security Considerations\n\n### Stdio Security\n\n- Validate command paths\n- Don't execute user-provided commands\n- Limit environment variable access\n- Restrict file system access\n\n### Network Security\n\n- Always use HTTPS/WSS\n- Validate SSL certificates\n- Don't skip certificate verification\n- Use secure token storage\n\n### Token Management\n\n- Never hardcode tokens\n- Use environment variables\n- Rotate tokens regularly\n- Implement token refresh\n- Document scopes required\n\n## Conclusion\n\nChoose the MCP server type based on your use case:\n- **stdio** for local, custom, or NPM-packaged servers\n- **SSE** for hosted services with OAuth\n- **HTTP** for REST APIs with token auth\n- **WebSocket** for real-time bidirectional communication\n\nTest thoroughly and handle errors gracefully for robust MCP integration.\n",
        "plugins/plugin-dev/skills/mcp-integration/references/tool-usage.md": "# Using MCP Tools in Commands and Agents\n\nComplete guide to using MCP tools effectively in Claude Code plugin commands and agents.\n\n## Overview\n\nOnce an MCP server is configured, its tools become available with the prefix `mcp__plugin_<plugin-name>_<server-name>__<tool-name>`. Use these tools in commands and agents just like built-in Claude Code tools.\n\n## Tool Naming Convention\n\n### Format\n\n```\nmcp__plugin_<plugin-name>_<server-name>__<tool-name>\n```\n\n### Examples\n\n**Asana plugin with asana server:**\n- `mcp__plugin_asana_asana__asana_create_task`\n- `mcp__plugin_asana_asana__asana_search_tasks`\n- `mcp__plugin_asana_asana__asana_get_project`\n\n**Custom plugin with database server:**\n- `mcp__plugin_myplug_database__query`\n- `mcp__plugin_myplug_database__execute`\n- `mcp__plugin_myplug_database__list_tables`\n\n### Discovering Tool Names\n\n**Use `/mcp` command:**\n```bash\n/mcp\n```\n\nThis shows:\n- All available MCP servers\n- Tools provided by each server\n- Tool schemas and descriptions\n- Full tool names for use in configuration\n\n## Using Tools in Commands\n\n### Pre-Allowing Tools\n\nSpecify MCP tools in command frontmatter:\n\n```markdown\n---\ndescription: Create a new Asana task\nallowed-tools: [\n  \"mcp__plugin_asana_asana__asana_create_task\"\n]\n---\n\n# Create Task Command\n\nTo create a task:\n1. Gather task details from user\n2. Use mcp__plugin_asana_asana__asana_create_task with the details\n3. Confirm creation to user\n```\n\n### Multiple Tools\n\n```markdown\n---\nallowed-tools: [\n  \"mcp__plugin_asana_asana__asana_create_task\",\n  \"mcp__plugin_asana_asana__asana_search_tasks\",\n  \"mcp__plugin_asana_asana__asana_get_project\"\n]\n---\n```\n\n### Wildcard (Use Sparingly)\n\n```markdown\n---\nallowed-tools: [\"mcp__plugin_asana_asana__*\"]\n---\n```\n\n**Caution:** Only use wildcards if the command truly needs access to all tools from a server.\n\n### Tool Usage in Command Instructions\n\n**Example command:**\n```markdown\n---\ndescription: Search and create Asana tasks\nallowed-tools: [\n  \"mcp__plugin_asana_asana__asana_search_tasks\",\n  \"mcp__plugin_asana_asana__asana_create_task\"\n]\n---\n\n# Asana Task Management\n\n## Searching Tasks\n\nTo search for tasks:\n1. Use mcp__plugin_asana_asana__asana_search_tasks\n2. Provide search filters (assignee, project, etc.)\n3. Display results to user\n\n## Creating Tasks\n\nTo create a task:\n1. Gather task details:\n   - Title (required)\n   - Description\n   - Project\n   - Assignee\n   - Due date\n2. Use mcp__plugin_asana_asana__asana_create_task\n3. Show confirmation with task link\n```\n\n## Using Tools in Agents\n\n### Agent Configuration\n\nAgents can use MCP tools autonomously without pre-allowing them:\n\n```markdown\n---\nname: asana-status-updater\ndescription: This agent should be used when the user asks to \"update Asana status\", \"generate project report\", or \"sync Asana tasks\"\nmodel: inherit\ncolor: blue\n---\n\n## Role\n\nAutonomous agent for generating Asana project status reports.\n\n## Process\n\n1. **Query tasks**: Use mcp__plugin_asana_asana__asana_search_tasks to get all tasks\n2. **Analyze progress**: Calculate completion rates and identify blockers\n3. **Generate report**: Create formatted status update\n4. **Update Asana**: Use mcp__plugin_asana_asana__asana_create_comment to post report\n\n## Available Tools\n\nThe agent has access to all Asana MCP tools without pre-approval.\n```\n\n### Agent Tool Access\n\nAgents have broader tool access than commands:\n- Can use any tool Claude determines is necessary\n- Don't need pre-allowed lists\n- Should document which tools they typically use\n\n## Tool Call Patterns\n\n### Pattern 1: Simple Tool Call\n\nSingle tool call with validation:\n\n```markdown\nSteps:\n1. Validate user provided required fields\n2. Call mcp__plugin_api_server__create_item with validated data\n3. Check for errors\n4. Display confirmation\n```\n\n### Pattern 2: Sequential Tools\n\nChain multiple tool calls:\n\n```markdown\nSteps:\n1. Search for existing items: mcp__plugin_api_server__search\n2. If not found, create new: mcp__plugin_api_server__create\n3. Add metadata: mcp__plugin_api_server__update_metadata\n4. Return final item ID\n```\n\n### Pattern 3: Batch Operations\n\nMultiple calls with same tool:\n\n```markdown\nSteps:\n1. Get list of items to process\n2. For each item:\n   - Call mcp__plugin_api_server__update_item\n   - Track success/failure\n3. Report results summary\n```\n\n### Pattern 4: Error Handling\n\nGraceful error handling:\n\n```markdown\nSteps:\n1. Try to call mcp__plugin_api_server__get_data\n2. If error (rate limit, network, etc.):\n   - Wait and retry (max 3 attempts)\n   - If still failing, inform user\n   - Suggest checking configuration\n3. On success, process data\n```\n\n## Tool Parameters\n\n### Understanding Tool Schemas\n\nEach MCP tool has a schema defining its parameters. View with `/mcp`.\n\n**Example schema:**\n```json\n{\n  \"name\": \"asana_create_task\",\n  \"description\": \"Create a new Asana task\",\n  \"inputSchema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"name\": {\n        \"type\": \"string\",\n        \"description\": \"Task title\"\n      },\n      \"notes\": {\n        \"type\": \"string\",\n        \"description\": \"Task description\"\n      },\n      \"workspace\": {\n        \"type\": \"string\",\n        \"description\": \"Workspace GID\"\n      }\n    },\n    \"required\": [\"name\", \"workspace\"]\n  }\n}\n```\n\n### Calling Tools with Parameters\n\nClaude automatically structures tool calls based on schema:\n\n```typescript\n// Claude generates this internally\n{\n  toolName: \"mcp__plugin_asana_asana__asana_create_task\",\n  input: {\n    name: \"Review PR #123\",\n    notes: \"Code review for new feature\",\n    workspace: \"12345\",\n    assignee: \"67890\",\n    due_on: \"2025-01-15\"\n  }\n}\n```\n\n### Parameter Validation\n\n**In commands, validate before calling:**\n\n```markdown\nSteps:\n1. Check required parameters:\n   - Title is not empty\n   - Workspace ID is provided\n   - Due date is valid format (YYYY-MM-DD)\n2. If validation fails, ask user to provide missing data\n3. If validation passes, call MCP tool\n4. Handle tool errors gracefully\n```\n\n## Response Handling\n\n### Success Responses\n\n```markdown\nSteps:\n1. Call MCP tool\n2. On success:\n   - Extract relevant data from response\n   - Format for user display\n   - Provide confirmation message\n   - Include relevant links or IDs\n```\n\n### Error Responses\n\n```markdown\nSteps:\n1. Call MCP tool\n2. On error:\n   - Check error type (auth, rate limit, validation, etc.)\n   - Provide helpful error message\n   - Suggest remediation steps\n   - Don't expose internal error details to user\n```\n\n### Partial Success\n\n```markdown\nSteps:\n1. Batch operation with multiple MCP calls\n2. Track successes and failures separately\n3. Report summary:\n   - \"Successfully processed 8 of 10 items\"\n   - \"Failed items: [item1, item2] due to [reason]\"\n   - Suggest retry or manual intervention\n```\n\n## Performance Optimization\n\n### Batching Requests\n\n**Good: Single query with filters**\n```markdown\nSteps:\n1. Call mcp__plugin_api_server__search with filters:\n   - project_id: \"123\"\n   - status: \"active\"\n   - limit: 100\n2. Process all results\n```\n\n**Avoid: Many individual queries**\n```markdown\nSteps:\n1. For each item ID:\n   - Call mcp__plugin_api_server__get_item\n   - Process item\n```\n\n### Caching Results\n\n```markdown\nSteps:\n1. Call expensive MCP operation: mcp__plugin_api_server__analyze\n2. Store results in variable for reuse\n3. Use cached results for subsequent operations\n4. Only re-fetch if data changes\n```\n\n### Parallel Tool Calls\n\nWhen tools don't depend on each other, call in parallel:\n\n```markdown\nSteps:\n1. Make parallel calls (Claude handles this automatically):\n   - mcp__plugin_api_server__get_project\n   - mcp__plugin_api_server__get_users\n   - mcp__plugin_api_server__get_tags\n2. Wait for all to complete\n3. Combine results\n```\n\n## Integration Best Practices\n\n### User Experience\n\n**Provide feedback:**\n```markdown\nSteps:\n1. Inform user: \"Searching Asana tasks...\"\n2. Call mcp__plugin_asana_asana__asana_search_tasks\n3. Show progress: \"Found 15 tasks, analyzing...\"\n4. Present results\n```\n\n**Handle long operations:**\n```markdown\nSteps:\n1. Warn user: \"This may take a minute...\"\n2. Break into smaller steps with updates\n3. Show incremental progress\n4. Final summary when complete\n```\n\n### Error Messages\n\n**Good error messages:**\n```\nâŒ \"Could not create task. Please check:\n   1. You're logged into Asana\n   2. You have access to workspace 'Engineering'\n   3. The project 'Q1 Goals' exists\"\n```\n\n**Poor error messages:**\n```\nâŒ \"Error: MCP tool returned 403\"\n```\n\n### Documentation\n\n**Document MCP tool usage in command:**\n```markdown\n## MCP Tools Used\n\nThis command uses the following Asana MCP tools:\n- **asana_search_tasks**: Search for tasks matching criteria\n- **asana_create_task**: Create new task with details\n- **asana_update_task**: Update existing task properties\n\nEnsure you're authenticated to Asana before running this command.\n```\n\n## Testing Tool Usage\n\n### Local Testing\n\n1. **Configure MCP server** in `.mcp.json`\n2. **Install plugin locally** in `.claude-plugin/`\n3. **Verify tools available** with `/mcp`\n4. **Test command** that uses tools\n5. **Check debug output**: `claude --debug`\n\n### Test Scenarios\n\n**Test successful calls:**\n```markdown\nSteps:\n1. Create test data in external service\n2. Run command that queries this data\n3. Verify correct results returned\n```\n\n**Test error cases:**\n```markdown\nSteps:\n1. Test with missing authentication\n2. Test with invalid parameters\n3. Test with non-existent resources\n4. Verify graceful error handling\n```\n\n**Test edge cases:**\n```markdown\nSteps:\n1. Test with empty results\n2. Test with maximum results\n3. Test with special characters\n4. Test with concurrent access\n```\n\n## Common Patterns\n\n### Pattern: CRUD Operations\n\n```markdown\n---\nallowed-tools: [\n  \"mcp__plugin_api_server__create_item\",\n  \"mcp__plugin_api_server__read_item\",\n  \"mcp__plugin_api_server__update_item\",\n  \"mcp__plugin_api_server__delete_item\"\n]\n---\n\n# Item Management\n\n## Create\nUse create_item with required fields...\n\n## Read\nUse read_item with item ID...\n\n## Update\nUse update_item with item ID and changes...\n\n## Delete\nUse delete_item with item ID (ask for confirmation first)...\n```\n\n### Pattern: Search and Process\n\n```markdown\nSteps:\n1. **Search**: mcp__plugin_api_server__search with filters\n2. **Filter**: Apply additional local filtering if needed\n3. **Transform**: Process each result\n4. **Present**: Format and display to user\n```\n\n### Pattern: Multi-Step Workflow\n\n```markdown\nSteps:\n1. **Setup**: Gather all required information\n2. **Validate**: Check data completeness\n3. **Execute**: Chain of MCP tool calls:\n   - Create parent resource\n   - Create child resources\n   - Link resources together\n   - Add metadata\n4. **Verify**: Confirm all steps succeeded\n5. **Report**: Provide summary to user\n```\n\n## Troubleshooting\n\n### Tools Not Available\n\n**Check:**\n- MCP server configured correctly\n- Server connected (check `/mcp`)\n- Tool names match exactly (case-sensitive)\n- Restart Claude Code after config changes\n\n### Tool Calls Failing\n\n**Check:**\n- Authentication is valid\n- Parameters match tool schema\n- Required parameters provided\n- Check `claude --debug` logs\n\n### Performance Issues\n\n**Check:**\n- Batching queries instead of individual calls\n- Caching results when appropriate\n- Not making unnecessary tool calls\n- Parallel calls when possible\n\n## Conclusion\n\nEffective MCP tool usage requires:\n1. **Understanding tool schemas** via `/mcp`\n2. **Pre-allowing tools** in commands appropriately\n3. **Handling errors gracefully**\n4. **Optimizing performance** with batching and caching\n5. **Providing good UX** with feedback and clear errors\n6. **Testing thoroughly** before deployment\n\nFollow these patterns for robust MCP tool integration in your plugin commands and agents.\n",
        "plugins/plugin-dev/skills/plugin-settings/SKILL.md": "---\nname: plugin-settings\ndescription: This skill should be used when the user asks about \"plugin settings\", \"store plugin configuration\", \"user-configurable plugin\", \".local.md files\", \"plugin state files\", \"read YAML frontmatter\", \"per-project plugin settings\", or wants to make plugin behavior configurable. Documents the .claude/plugin-name.local.md pattern for storing plugin-specific configuration with YAML frontmatter and markdown content.\n---\n\n# Plugin Settings Pattern for Claude Code Plugins\n\n## Overview\n\nPlugins can store user-configurable settings and state in `.claude/plugin-name.local.md` files within the project directory. This pattern uses YAML frontmatter for structured configuration and markdown content for prompts or additional context.\n\n**Key characteristics:**\n- File location: `.claude/plugin-name.local.md` in project root\n- Structure: YAML frontmatter + markdown body\n- Purpose: Per-project plugin configuration and state\n- Usage: Read from hooks, commands, and agents\n- Lifecycle: User-managed (not in git, should be in `.gitignore`)\n\n## File Structure\n\n### Basic Template\n\n```markdown\n---\nenabled: true\nsetting1: value1\nsetting2: value2\nnumeric_setting: 42\nlist_setting: [\"item1\", \"item2\"]\n---\n\n# Additional Context\n\nThis markdown body can contain:\n- Task descriptions\n- Additional instructions\n- Prompts to feed back to Claude\n- Documentation or notes\n```\n\n### Example: Plugin State File\n\n**.claude/my-plugin.local.md:**\n```markdown\n---\nenabled: true\nstrict_mode: false\nmax_retries: 3\nnotification_level: info\ncoordinator_session: team-leader\n---\n\n# Plugin Configuration\n\nThis plugin is configured for standard validation mode.\nContact @team-lead with questions.\n```\n\n## Reading Settings Files\n\n### From Hooks (Bash Scripts)\n\n**Pattern: Check existence and parse frontmatter**\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\n# Define state file path\nSTATE_FILE=\".claude/my-plugin.local.md\"\n\n# Quick exit if file doesn't exist\nif [[ ! -f \"$STATE_FILE\" ]]; then\n  exit 0  # Plugin not configured, skip\nfi\n\n# Parse YAML frontmatter (between --- markers)\nFRONTMATTER=$(sed -n '/^---$/,/^---$/{ /^---$/d; p; }' \"$STATE_FILE\")\n\n# Extract individual fields\nENABLED=$(echo \"$FRONTMATTER\" | grep '^enabled:' | sed 's/enabled: *//' | sed 's/^\"\\(.*\\)\"$/\\1/')\nSTRICT_MODE=$(echo \"$FRONTMATTER\" | grep '^strict_mode:' | sed 's/strict_mode: *//' | sed 's/^\"\\(.*\\)\"$/\\1/')\n\n# Check if enabled\nif [[ \"$ENABLED\" != \"true\" ]]; then\n  exit 0  # Disabled\nfi\n\n# Use configuration in hook logic\nif [[ \"$STRICT_MODE\" == \"true\" ]]; then\n  # Apply strict validation\n  # ...\nfi\n```\n\nSee `examples/read-settings-hook.sh` for complete working example.\n\n### From Commands\n\nCommands can read settings files to customize behavior:\n\n```markdown\n---\ndescription: Process data with plugin\nallowed-tools: [\"Read\", \"Bash\"]\n---\n\n# Process Command\n\nSteps:\n1. Check if settings exist at `.claude/my-plugin.local.md`\n2. Read configuration using Read tool\n3. Parse YAML frontmatter to extract settings\n4. Apply settings to processing logic\n5. Execute with configured behavior\n```\n\n### From Agents\n\nAgents can reference settings in their instructions:\n\n```markdown\n---\nname: configured-agent\ndescription: Agent that adapts to project settings\n---\n\nCheck for plugin settings at `.claude/my-plugin.local.md`.\nIf present, parse YAML frontmatter and adapt behavior according to:\n- enabled: Whether plugin is active\n- mode: Processing mode (strict, standard, lenient)\n- Additional configuration fields\n```\n\n## Parsing Techniques\n\n### Extract Frontmatter\n\n```bash\n# Extract everything between --- markers\nFRONTMATTER=$(sed -n '/^---$/,/^---$/{ /^---$/d; p; }' \"$FILE\")\n```\n\n### Read Individual Fields\n\n**String fields:**\n```bash\nVALUE=$(echo \"$FRONTMATTER\" | grep '^field_name:' | sed 's/field_name: *//' | sed 's/^\"\\(.*\\)\"$/\\1/')\n```\n\n**Boolean fields:**\n```bash\nENABLED=$(echo \"$FRONTMATTER\" | grep '^enabled:' | sed 's/enabled: *//')\n# Compare: if [[ \"$ENABLED\" == \"true\" ]]; then\n```\n\n**Numeric fields:**\n```bash\nMAX=$(echo \"$FRONTMATTER\" | grep '^max_value:' | sed 's/max_value: *//')\n# Use: if [[ $MAX -gt 100 ]]; then\n```\n\n### Read Markdown Body\n\nExtract content after second `---`:\n\n```bash\n# Get everything after closing ---\nBODY=$(awk '/^---$/{i++; next} i>=2' \"$FILE\")\n```\n\n## Common Patterns\n\n### Pattern 1: Temporarily Active Hooks\n\nUse settings file to control hook activation:\n\n```bash\n#!/bin/bash\nSTATE_FILE=\".claude/security-scan.local.md\"\n\n# Quick exit if not configured\nif [[ ! -f \"$STATE_FILE\" ]]; then\n  exit 0\nfi\n\n# Read enabled flag\nFRONTMATTER=$(sed -n '/^---$/,/^---$/{ /^---$/d; p; }' \"$STATE_FILE\")\nENABLED=$(echo \"$FRONTMATTER\" | grep '^enabled:' | sed 's/enabled: *//')\n\nif [[ \"$ENABLED\" != \"true\" ]]; then\n  exit 0  # Disabled\nfi\n\n# Run hook logic\n# ...\n```\n\n**Use case:** Enable/disable hooks without editing hooks.json (requires restart).\n\n### Pattern 2: Agent State Management\n\nStore agent-specific state and configuration:\n\n**.claude/multi-agent-swarm.local.md:**\n```markdown\n---\nagent_name: auth-agent\ntask_number: 3.5\npr_number: 1234\ncoordinator_session: team-leader\nenabled: true\ndependencies: [\"Task 3.4\"]\n---\n\n# Task Assignment\n\nImplement JWT authentication for the API.\n\n**Success Criteria:**\n- Authentication endpoints created\n- Tests passing\n- PR created and CI green\n```\n\nRead from hooks to coordinate agents:\n\n```bash\nAGENT_NAME=$(echo \"$FRONTMATTER\" | grep '^agent_name:' | sed 's/agent_name: *//')\nCOORDINATOR=$(echo \"$FRONTMATTER\" | grep '^coordinator_session:' | sed 's/coordinator_session: *//')\n\n# Send notification to coordinator\ntmux send-keys -t \"$COORDINATOR\" \"Agent $AGENT_NAME completed task\" Enter\n```\n\n### Pattern 3: Configuration-Driven Behavior\n\n**.claude/my-plugin.local.md:**\n```markdown\n---\nvalidation_level: strict\nmax_file_size: 1000000\nallowed_extensions: [\".js\", \".ts\", \".tsx\"]\nenable_logging: true\n---\n\n# Validation Configuration\n\nStrict mode enabled for this project.\nAll writes validated against security policies.\n```\n\nUse in hooks or commands:\n\n```bash\nLEVEL=$(echo \"$FRONTMATTER\" | grep '^validation_level:' | sed 's/validation_level: *//')\n\ncase \"$LEVEL\" in\n  strict)\n    # Apply strict validation\n    ;;\n  standard)\n    # Apply standard validation\n    ;;\n  lenient)\n    # Apply lenient validation\n    ;;\nesac\n```\n\n## Creating Settings Files\n\n### From Commands\n\nCommands can create settings files:\n\n```markdown\n# Setup Command\n\nSteps:\n1. Ask user for configuration preferences\n2. Create `.claude/my-plugin.local.md` with YAML frontmatter\n3. Set appropriate values based on user input\n4. Inform user that settings are saved\n5. Remind user to restart Claude Code for hooks to recognize changes\n```\n\n### Template Generation\n\nProvide template in plugin README:\n\n```markdown\n## Configuration\n\nCreate `.claude/my-plugin.local.md` in your project:\n\n\\`\\`\\`markdown\n---\nenabled: true\nmode: standard\nmax_retries: 3\n---\n\n# Plugin Configuration\n\nYour settings are active.\n\\`\\`\\`\n\nAfter creating or editing, restart Claude Code for changes to take effect.\n```\n\n## Best Practices\n\n### File Naming\n\nâœ… **DO:**\n- Use `.claude/plugin-name.local.md` format\n- Match plugin name exactly\n- Use `.local.md` suffix for user-local files\n\nâŒ **DON'T:**\n- Use different directory (not `.claude/`)\n- Use inconsistent naming\n- Use `.md` without `.local` (might be committed)\n\n### Gitignore\n\nAlways add to `.gitignore`:\n\n```gitignore\n.claude/*.local.md\n.claude/*.local.json\n```\n\nDocument this in plugin README.\n\n### Defaults\n\nProvide sensible defaults when settings file doesn't exist:\n\n```bash\nif [[ ! -f \"$STATE_FILE\" ]]; then\n  # Use defaults\n  ENABLED=true\n  MODE=standard\nelse\n  # Read from file\n  # ...\nfi\n```\n\n### Validation\n\nValidate settings values:\n\n```bash\nMAX=$(echo \"$FRONTMATTER\" | grep '^max_value:' | sed 's/max_value: *//')\n\n# Validate numeric range\nif ! [[ \"$MAX\" =~ ^[0-9]+$ ]] || [[ $MAX -lt 1 ]] || [[ $MAX -gt 100 ]]; then\n  echo \"âš ï¸  Invalid max_value in settings (must be 1-100)\" >&2\n  MAX=10  # Use default\nfi\n```\n\n### Restart Requirement\n\n**Important:** Settings changes require Claude Code restart.\n\nDocument in your README:\n\n```markdown\n## Changing Settings\n\nAfter editing `.claude/my-plugin.local.md`:\n1. Save the file\n2. Exit Claude Code\n3. Restart: `claude` or `cc`\n4. New settings will be loaded\n```\n\nHooks cannot be hot-swapped within a session.\n\n## Security Considerations\n\n### Sanitize User Input\n\nWhen writing settings files from user input:\n\n```bash\n# Escape quotes in user input\nSAFE_VALUE=$(echo \"$USER_INPUT\" | sed 's/\"/\\\\\"/g')\n\n# Write to file\ncat > \"$STATE_FILE\" <<EOF\n---\nuser_setting: \"$SAFE_VALUE\"\n---\nEOF\n```\n\n### Validate File Paths\n\nIf settings contain file paths:\n\n```bash\nFILE_PATH=$(echo \"$FRONTMATTER\" | grep '^data_file:' | sed 's/data_file: *//')\n\n# Check for path traversal\nif [[ \"$FILE_PATH\" == *\"..\"* ]]; then\n  echo \"âš ï¸  Invalid path in settings (path traversal)\" >&2\n  exit 2\nfi\n```\n\n### Permissions\n\nSettings files should be:\n- Readable by user only (`chmod 600`)\n- Not committed to git\n- Not shared between users\n\n## Real-World Examples\n\n### multi-agent-swarm Plugin\n\n**.claude/multi-agent-swarm.local.md:**\n```markdown\n---\nagent_name: auth-implementation\ntask_number: 3.5\npr_number: 1234\ncoordinator_session: team-leader\nenabled: true\ndependencies: [\"Task 3.4\"]\nadditional_instructions: Use JWT tokens, not sessions\n---\n\n# Task: Implement Authentication\n\nBuild JWT-based authentication for the REST API.\nCoordinate with auth-agent on shared types.\n```\n\n**Hook usage (agent-stop-notification.sh):**\n- Checks if file exists (line 15-18: quick exit if not)\n- Parses frontmatter to get coordinator_session, agent_name, enabled\n- Sends notifications to coordinator if enabled\n- Allows quick activation/deactivation via `enabled: true/false`\n\n### ralph-loop Plugin\n\n**.claude/ralph-loop.local.md:**\n```markdown\n---\niteration: 1\nmax_iterations: 10\ncompletion_promise: \"All tests passing and build successful\"\n---\n\nFix all the linting errors in the project.\nMake sure tests pass after each fix.\n```\n\n**Hook usage (stop-hook.sh):**\n- Checks if file exists (line 15-18: quick exit if not active)\n- Reads iteration count and max_iterations\n- Extracts completion_promise for loop termination\n- Reads body as the prompt to feed back\n- Updates iteration count on each loop\n\n## Quick Reference\n\n### File Location\n\n```\nproject-root/\nâ””â”€â”€ .claude/\n    â””â”€â”€ plugin-name.local.md\n```\n\n### Frontmatter Parsing\n\n```bash\n# Extract frontmatter\nFRONTMATTER=$(sed -n '/^---$/,/^---$/{ /^---$/d; p; }' \"$FILE\")\n\n# Read field\nVALUE=$(echo \"$FRONTMATTER\" | grep '^field:' | sed 's/field: *//' | sed 's/^\"\\(.*\\)\"$/\\1/')\n```\n\n### Body Parsing\n\n```bash\n# Extract body (after second ---)\nBODY=$(awk '/^---$/{i++; next} i>=2' \"$FILE\")\n```\n\n### Quick Exit Pattern\n\n```bash\nif [[ ! -f \".claude/my-plugin.local.md\" ]]; then\n  exit 0  # Not configured\nfi\n```\n\n## Additional Resources\n\n### Reference Files\n\nFor detailed implementation patterns:\n\n- **`references/parsing-techniques.md`** - Complete guide to parsing YAML frontmatter and markdown bodies\n- **`references/real-world-examples.md`** - Deep dive into multi-agent-swarm and ralph-loop implementations\n\n### Example Files\n\nWorking examples in `examples/`:\n\n- **`read-settings-hook.sh`** - Hook that reads and uses settings\n- **`create-settings-command.md`** - Command that creates settings file\n- **`example-settings.md`** - Template settings file\n\n### Utility Scripts\n\nDevelopment tools in `scripts/`:\n\n- **`validate-settings.sh`** - Validate settings file structure\n- **`parse-frontmatter.sh`** - Extract frontmatter fields\n\n## Implementation Workflow\n\nTo add settings to a plugin:\n\n1. Design settings schema (which fields, types, defaults)\n2. Create template file in plugin documentation\n3. Add gitignore entry for `.claude/*.local.md`\n4. Implement settings parsing in hooks/commands\n5. Use quick-exit pattern (check file exists, check enabled field)\n6. Document settings in plugin README with template\n7. Remind users that changes require Claude Code restart\n\nFocus on keeping settings simple and providing good defaults when settings file doesn't exist.\n",
        "plugins/plugin-dev/skills/plugin-settings/examples/create-settings-command.md": "---\ndescription: \"Create plugin settings file with user preferences\"\nallowed-tools: [\"Write\", \"AskUserQuestion\"]\n---\n\n# Create Plugin Settings\n\nThis command helps users create a `.claude/my-plugin.local.md` settings file.\n\n## Steps\n\n### Step 1: Ask User for Preferences\n\nUse AskUserQuestion to gather configuration:\n\n```json\n{\n  \"questions\": [\n    {\n      \"question\": \"Enable plugin for this project?\",\n      \"header\": \"Enable Plugin\",\n      \"multiSelect\": false,\n      \"options\": [\n        {\n          \"label\": \"Yes\",\n          \"description\": \"Plugin will be active\"\n        },\n        {\n          \"label\": \"No\",\n          \"description\": \"Plugin will be disabled\"\n        }\n      ]\n    },\n    {\n      \"question\": \"Validation mode?\",\n      \"header\": \"Mode\",\n      \"multiSelect\": false,\n      \"options\": [\n        {\n          \"label\": \"Strict\",\n          \"description\": \"Maximum validation and security checks\"\n        },\n        {\n          \"label\": \"Standard\",\n          \"description\": \"Balanced validation (recommended)\"\n        },\n        {\n          \"label\": \"Lenient\",\n          \"description\": \"Minimal validation only\"\n        }\n      ]\n    }\n  ]\n}\n```\n\n### Step 2: Parse Answers\n\nExtract answers from AskUserQuestion result:\n\n- answers[\"0\"]: enabled (Yes/No)\n- answers[\"1\"]: mode (Strict/Standard/Lenient)\n\n### Step 3: Create Settings File\n\nUse Write tool to create `.claude/my-plugin.local.md`:\n\n```markdown\n---\nenabled: <true if Yes, false if No>\nvalidation_mode: <strict, standard, or lenient>\nmax_file_size: 1000000\nnotify_on_errors: true\n---\n\n# Plugin Configuration\n\nYour plugin is configured with <mode> validation mode.\n\nTo modify settings, edit this file and restart Claude Code.\n```\n\n### Step 4: Inform User\n\nTell the user:\n- Settings file created at `.claude/my-plugin.local.md`\n- Current configuration summary\n- How to edit manually if needed\n- Reminder: Restart Claude Code for changes to take effect\n- Settings file is gitignored (won't be committed)\n\n## Implementation Notes\n\nAlways validate user input before writing:\n- Check mode is valid\n- Validate numeric fields are numbers\n- Ensure paths don't have traversal attempts\n- Sanitize any free-text fields\n",
        "plugins/plugin-dev/skills/plugin-settings/examples/example-settings.md": "# Example Plugin Settings File\n\n## Template: Basic Configuration\n\n**.claude/my-plugin.local.md:**\n\n```markdown\n---\nenabled: true\nmode: standard\n---\n\n# My Plugin Configuration\n\nPlugin is active in standard mode.\n```\n\n## Template: Advanced Configuration\n\n**.claude/my-plugin.local.md:**\n\n```markdown\n---\nenabled: true\nstrict_mode: false\nmax_file_size: 1000000\nallowed_extensions: [\".js\", \".ts\", \".tsx\"]\nenable_logging: true\nnotification_level: info\nretry_attempts: 3\ntimeout_seconds: 60\ncustom_path: \"/path/to/data\"\n---\n\n# My Plugin Advanced Configuration\n\nThis project uses custom plugin configuration with:\n- Standard validation mode\n- 1MB file size limit\n- JavaScript/TypeScript files allowed\n- Info-level logging\n- 3 retry attempts\n\n## Additional Notes\n\nContact @team-lead with questions about this configuration.\n```\n\n## Template: Agent State File\n\n**.claude/multi-agent-swarm.local.md:**\n\n```markdown\n---\nagent_name: database-implementation\ntask_number: 4.2\npr_number: 5678\ncoordinator_session: team-leader\nenabled: true\ndependencies: [\"Task 3.5\", \"Task 4.1\"]\nadditional_instructions: \"Use PostgreSQL, not MySQL\"\n---\n\n# Task Assignment: Database Schema Implementation\n\nImplement the database schema for the new features module.\n\n## Requirements\n\n- Create migration files\n- Add indexes for performance\n- Write tests for constraints\n- Document schema in README\n\n## Success Criteria\n\n- Migrations run successfully\n- All tests pass\n- PR created with CI green\n- Schema documented\n\n## Coordination\n\nDepends on:\n- Task 3.5: API endpoint definitions\n- Task 4.1: Data model design\n\nReport status to coordinator session 'team-leader'.\n```\n\n## Template: Feature Flag Pattern\n\n**.claude/experimental-features.local.md:**\n\n```markdown\n---\nenabled: true\nfeatures:\n  - ai_suggestions\n  - auto_formatting\n  - advanced_refactoring\nexperimental_mode: false\n---\n\n# Experimental Features Configuration\n\nCurrent enabled features:\n- AI-powered code suggestions\n- Automatic code formatting\n- Advanced refactoring tools\n\nExperimental mode is OFF (stable features only).\n```\n\n## Usage in Hooks\n\nThese templates can be read by hooks:\n\n```bash\n# Check if plugin is configured\nif [[ ! -f \".claude/my-plugin.local.md\" ]]; then\n  exit 0  # Not configured, skip hook\nfi\n\n# Read settings\nFRONTMATTER=$(sed -n '/^---$/,/^---$/{ /^---$/d; p; }' \".claude/my-plugin.local.md\")\nENABLED=$(echo \"$FRONTMATTER\" | grep '^enabled:' | sed 's/enabled: *//')\n\n# Apply settings\nif [[ \"$ENABLED\" == \"true\" ]]; then\n  # Hook is active\n  # ...\nfi\n```\n\n## Gitignore\n\nAlways add to project `.gitignore`:\n\n```gitignore\n# Plugin settings (user-local, not committed)\n.claude/*.local.md\n.claude/*.local.json\n```\n\n## Editing Settings\n\nUsers can edit settings files manually:\n\n```bash\n# Edit settings\nvim .claude/my-plugin.local.md\n\n# Changes take effect after restart\nexit  # Exit Claude Code\nclaude  # Restart\n```\n\nChanges require Claude Code restart - hooks can't be hot-swapped.\n",
        "plugins/plugin-dev/skills/plugin-settings/references/parsing-techniques.md": "# Settings File Parsing Techniques\n\nComplete guide to parsing `.claude/plugin-name.local.md` files in bash scripts.\n\n## File Structure\n\nSettings files use markdown with YAML frontmatter:\n\n```markdown\n---\nfield1: value1\nfield2: \"value with spaces\"\nnumeric_field: 42\nboolean_field: true\nlist_field: [\"item1\", \"item2\", \"item3\"]\n---\n\n# Markdown Content\n\nThis body content can be extracted separately.\nIt's useful for prompts, documentation, or additional context.\n```\n\n## Parsing Frontmatter\n\n### Extract Frontmatter Block\n\n```bash\n#!/bin/bash\nFILE=\".claude/my-plugin.local.md\"\n\n# Extract everything between --- markers (excluding the markers themselves)\nFRONTMATTER=$(sed -n '/^---$/,/^---$/{ /^---$/d; p; }' \"$FILE\")\n```\n\n**How it works:**\n- `sed -n` - Suppress automatic printing\n- `/^---$/,/^---$/` - Range from first `---` to second `---`\n- `{ /^---$/d; p; }` - Delete the `---` lines, print everything else\n\n### Extract Individual Fields\n\n**String fields:**\n```bash\n# Simple value\nVALUE=$(echo \"$FRONTMATTER\" | grep '^field_name:' | sed 's/field_name: *//')\n\n# Quoted value (removes surrounding quotes)\nVALUE=$(echo \"$FRONTMATTER\" | grep '^field_name:' | sed 's/field_name: *//' | sed 's/^\"\\(.*\\)\"$/\\1/')\n```\n\n**Boolean fields:**\n```bash\nENABLED=$(echo \"$FRONTMATTER\" | grep '^enabled:' | sed 's/enabled: *//')\n\n# Use in condition\nif [[ \"$ENABLED\" == \"true\" ]]; then\n  # Enabled\nfi\n```\n\n**Numeric fields:**\n```bash\nMAX=$(echo \"$FRONTMATTER\" | grep '^max_value:' | sed 's/max_value: *//')\n\n# Validate it's a number\nif [[ \"$MAX\" =~ ^[0-9]+$ ]]; then\n  # Use in numeric comparison\n  if [[ $MAX -gt 100 ]]; then\n    # Too large\n  fi\nfi\n```\n\n**List fields (simple):**\n```bash\n# YAML: list: [\"item1\", \"item2\", \"item3\"]\nLIST=$(echo \"$FRONTMATTER\" | grep '^list:' | sed 's/list: *//')\n# Result: [\"item1\", \"item2\", \"item3\"]\n\n# For simple checks:\nif [[ \"$LIST\" == *\"item1\"* ]]; then\n  # List contains item1\nfi\n```\n\n**List fields (proper parsing with jq):**\n```bash\n# For proper list handling, use yq or convert to JSON\n# This requires yq to be installed (brew install yq)\n\n# Extract list as JSON array\nLIST=$(echo \"$FRONTMATTER\" | yq -o json '.list' 2>/dev/null)\n\n# Iterate over items\necho \"$LIST\" | jq -r '.[]' | while read -r item; do\n  echo \"Processing: $item\"\ndone\n```\n\n## Parsing Markdown Body\n\n### Extract Body Content\n\n```bash\n#!/bin/bash\nFILE=\".claude/my-plugin.local.md\"\n\n# Extract everything after the closing ---\n# Counts --- markers: first is opening, second is closing, everything after is body\nBODY=$(awk '/^---$/{i++; next} i>=2' \"$FILE\")\n```\n\n**How it works:**\n- `/^---$/` - Match `---` lines\n- `{i++; next}` - Increment counter and skip the `---` line\n- `i>=2` - Print all lines after second `---`\n\n**Handles edge case:** If `---` appears in the markdown body, it still works because we only count the first two `---` at the start.\n\n### Use Body as Prompt\n\n```bash\n# Extract body\nPROMPT=$(awk '/^---$/{i++; next} i>=2' \"$RALPH_STATE_FILE\")\n\n# Feed back to Claude\necho '{\"decision\": \"block\", \"reason\": \"'\"$PROMPT\"'\"}' | jq .\n```\n\n**Important:** Use `jq -n --arg` for safer JSON construction with user content:\n\n```bash\nPROMPT=$(awk '/^---$/{i++; next} i>=2' \"$FILE\")\n\n# Safe JSON construction\njq -n --arg prompt \"$PROMPT\" '{\n  \"decision\": \"block\",\n  \"reason\": $prompt\n}'\n```\n\n## Common Parsing Patterns\n\n### Pattern: Field with Default\n\n```bash\nVALUE=$(echo \"$FRONTMATTER\" | grep '^field:' | sed 's/field: *//' | sed 's/^\"\\(.*\\)\"$/\\1/')\n\n# Use default if empty\nif [[ -z \"$VALUE\" ]]; then\n  VALUE=\"default_value\"\nfi\n```\n\n### Pattern: Optional Field\n\n```bash\nOPTIONAL=$(echo \"$FRONTMATTER\" | grep '^optional_field:' | sed 's/optional_field: *//' | sed 's/^\"\\(.*\\)\"$/\\1/')\n\n# Only use if present\nif [[ -n \"$OPTIONAL\" ]] && [[ \"$OPTIONAL\" != \"null\" ]]; then\n  # Field is set, use it\n  echo \"Optional field: $OPTIONAL\"\nfi\n```\n\n### Pattern: Multiple Fields at Once\n\n```bash\n# Parse all fields in one pass\nwhile IFS=': ' read -r key value; do\n  # Remove quotes if present\n  value=$(echo \"$value\" | sed 's/^\"\\(.*\\)\"$/\\1/')\n\n  case \"$key\" in\n    enabled)\n      ENABLED=\"$value\"\n      ;;\n    mode)\n      MODE=\"$value\"\n      ;;\n    max_size)\n      MAX_SIZE=\"$value\"\n      ;;\n  esac\ndone <<< \"$FRONTMATTER\"\n```\n\n## Updating Settings Files\n\n### Atomic Updates\n\nAlways use temp file + atomic move to prevent corruption:\n\n```bash\n#!/bin/bash\nFILE=\".claude/my-plugin.local.md\"\nNEW_VALUE=\"updated_value\"\n\n# Create temp file\nTEMP_FILE=\"${FILE}.tmp.$$\"\n\n# Update field using sed\nsed \"s/^field_name: .*/field_name: $NEW_VALUE/\" \"$FILE\" > \"$TEMP_FILE\"\n\n# Atomic replace\nmv \"$TEMP_FILE\" \"$FILE\"\n```\n\n### Update Single Field\n\n```bash\n# Increment iteration counter\nCURRENT=$(echo \"$FRONTMATTER\" | grep '^iteration:' | sed 's/iteration: *//')\nNEXT=$((CURRENT + 1))\n\n# Update file\nTEMP_FILE=\"${FILE}.tmp.$$\"\nsed \"s/^iteration: .*/iteration: $NEXT/\" \"$FILE\" > \"$TEMP_FILE\"\nmv \"$TEMP_FILE\" \"$FILE\"\n```\n\n### Update Multiple Fields\n\n```bash\n# Update several fields at once\nTEMP_FILE=\"${FILE}.tmp.$$\"\n\nsed -e \"s/^iteration: .*/iteration: $NEXT_ITERATION/\" \\\n    -e \"s/^pr_number: .*/pr_number: $PR_NUMBER/\" \\\n    -e \"s/^status: .*/status: $NEW_STATUS/\" \\\n    \"$FILE\" > \"$TEMP_FILE\"\n\nmv \"$TEMP_FILE\" \"$FILE\"\n```\n\n## Validation Techniques\n\n### Validate File Exists and Is Readable\n\n```bash\nFILE=\".claude/my-plugin.local.md\"\n\nif [[ ! -f \"$FILE\" ]]; then\n  echo \"Settings file not found\" >&2\n  exit 1\nfi\n\nif [[ ! -r \"$FILE\" ]]; then\n  echo \"Settings file not readable\" >&2\n  exit 1\nfi\n```\n\n### Validate Frontmatter Structure\n\n```bash\n# Count --- markers (should be exactly 2 at start)\nMARKER_COUNT=$(grep -c '^---$' \"$FILE\" 2>/dev/null || echo \"0\")\n\nif [[ $MARKER_COUNT -lt 2 ]]; then\n  echo \"Invalid settings file: missing frontmatter markers\" >&2\n  exit 1\nfi\n```\n\n### Validate Field Values\n\n```bash\nMODE=$(echo \"$FRONTMATTER\" | grep '^mode:' | sed 's/mode: *//')\n\ncase \"$MODE\" in\n  strict|standard|lenient)\n    # Valid mode\n    ;;\n  *)\n    echo \"Invalid mode: $MODE (must be strict, standard, or lenient)\" >&2\n    exit 1\n    ;;\nesac\n```\n\n### Validate Numeric Ranges\n\n```bash\nMAX_SIZE=$(echo \"$FRONTMATTER\" | grep '^max_size:' | sed 's/max_size: *//')\n\nif ! [[ \"$MAX_SIZE\" =~ ^[0-9]+$ ]]; then\n  echo \"max_size must be a number\" >&2\n  exit 1\nfi\n\nif [[ $MAX_SIZE -lt 1 ]] || [[ $MAX_SIZE -gt 10000000 ]]; then\n  echo \"max_size out of range (1-10000000)\" >&2\n  exit 1\nfi\n```\n\n## Edge Cases and Gotchas\n\n### Quotes in Values\n\nYAML allows both quoted and unquoted strings:\n\n```yaml\n# These are equivalent:\nfield1: value\nfield2: \"value\"\nfield3: 'value'\n```\n\n**Handle both:**\n```bash\n# Remove surrounding quotes if present\nVALUE=$(echo \"$FRONTMATTER\" | grep '^field:' | sed 's/field: *//' | sed 's/^\"\\(.*\\)\"$/\\1/' | sed \"s/^'\\\\(.*\\\\)'$/\\\\1/\")\n```\n\n### --- in Markdown Body\n\nIf the markdown body contains `---`, the parsing still works because we only match the first two:\n\n```markdown\n---\nfield: value\n---\n\n# Body\n\nHere's a separator:\n---\n\nMore content after the separator.\n```\n\nThe `awk '/^---$/{i++; next} i>=2'` pattern handles this correctly.\n\n### Empty Values\n\nHandle missing or empty fields:\n\n```yaml\nfield1:\nfield2: \"\"\nfield3: null\n```\n\n**Parsing:**\n```bash\nVALUE=$(echo \"$FRONTMATTER\" | grep '^field1:' | sed 's/field1: *//')\n# VALUE will be empty string\n\n# Check for empty/null\nif [[ -z \"$VALUE\" ]] || [[ \"$VALUE\" == \"null\" ]]; then\n  VALUE=\"default\"\nfi\n```\n\n### Special Characters\n\nValues with special characters need careful handling:\n\n```yaml\nmessage: \"Error: Something went wrong!\"\npath: \"/path/with spaces/file.txt\"\nregex: \"^[a-zA-Z0-9_]+$\"\n```\n\n**Safe parsing:**\n```bash\n# Always quote variables when using\nMESSAGE=$(echo \"$FRONTMATTER\" | grep '^message:' | sed 's/message: *//' | sed 's/^\"\\(.*\\)\"$/\\1/')\n\necho \"Message: $MESSAGE\"  # Quoted!\n```\n\n## Performance Optimization\n\n### Cache Parsed Values\n\nIf reading settings multiple times:\n\n```bash\n# Parse once\nFRONTMATTER=$(sed -n '/^---$/,/^---$/{ /^---$/d; p; }' \"$FILE\")\n\n# Extract multiple fields from cached frontmatter\nFIELD1=$(echo \"$FRONTMATTER\" | grep '^field1:' | sed 's/field1: *//')\nFIELD2=$(echo \"$FRONTMATTER\" | grep '^field2:' | sed 's/field2: *//')\nFIELD3=$(echo \"$FRONTMATTER\" | grep '^field3:' | sed 's/field3: *//')\n```\n\n**Don't:** Re-parse file for each field.\n\n### Lazy Loading\n\nOnly parse settings when needed:\n\n```bash\n#!/bin/bash\ninput=$(cat)\n\n# Quick checks first (no file I/O)\ntool_name=$(echo \"$input\" | jq -r '.tool_name')\nif [[ \"$tool_name\" != \"Write\" ]]; then\n  exit 0  # Not a write operation, skip\nfi\n\n# Only now check settings file\nif [[ -f \".claude/my-plugin.local.md\" ]]; then\n  # Parse settings\n  # ...\nfi\n```\n\n## Debugging\n\n### Print Parsed Values\n\n```bash\n#!/bin/bash\nset -x  # Enable debug tracing\n\nFILE=\".claude/my-plugin.local.md\"\n\nif [[ -f \"$FILE\" ]]; then\n  echo \"Settings file found\" >&2\n\n  FRONTMATTER=$(sed -n '/^---$/,/^---$/{ /^---$/d; p; }' \"$FILE\")\n  echo \"Frontmatter:\" >&2\n  echo \"$FRONTMATTER\" >&2\n\n  ENABLED=$(echo \"$FRONTMATTER\" | grep '^enabled:' | sed 's/enabled: *//')\n  echo \"Enabled: $ENABLED\" >&2\nfi\n```\n\n### Validate Parsing\n\n```bash\n# Show what was parsed\necho \"Parsed values:\" >&2\necho \"  enabled: $ENABLED\" >&2\necho \"  mode: $MODE\" >&2\necho \"  max_size: $MAX_SIZE\" >&2\n\n# Verify expected values\nif [[ \"$ENABLED\" != \"true\" ]] && [[ \"$ENABLED\" != \"false\" ]]; then\n  echo \"âš ï¸  Unexpected enabled value: $ENABLED\" >&2\nfi\n```\n\n## Alternative: Using yq\n\nFor complex YAML, consider using `yq`:\n\n```bash\n# Install: brew install yq\n\n# Parse YAML properly\nFRONTMATTER=$(sed -n '/^---$/,/^---$/{ /^---$/d; p; }' \"$FILE\")\n\n# Extract fields with yq\nENABLED=$(echo \"$FRONTMATTER\" | yq '.enabled')\nMODE=$(echo \"$FRONTMATTER\" | yq '.mode')\nLIST=$(echo \"$FRONTMATTER\" | yq -o json '.list_field')\n\n# Iterate list properly\necho \"$LIST\" | jq -r '.[]' | while read -r item; do\n  echo \"Item: $item\"\ndone\n```\n\n**Pros:**\n- Proper YAML parsing\n- Handles complex structures\n- Better list/object support\n\n**Cons:**\n- Requires yq installation\n- Additional dependency\n- May not be available on all systems\n\n**Recommendation:** Use sed/grep for simple fields, yq for complex structures.\n\n## Complete Example\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\n# Configuration\nSETTINGS_FILE=\".claude/my-plugin.local.md\"\n\n# Quick exit if not configured\nif [[ ! -f \"$SETTINGS_FILE\" ]]; then\n  # Use defaults\n  ENABLED=true\n  MODE=standard\n  MAX_SIZE=1000000\nelse\n  # Parse frontmatter\n  FRONTMATTER=$(sed -n '/^---$/,/^---$/{ /^---$/d; p; }' \"$SETTINGS_FILE\")\n\n  # Extract fields with defaults\n  ENABLED=$(echo \"$FRONTMATTER\" | grep '^enabled:' | sed 's/enabled: *//')\n  ENABLED=${ENABLED:-true}\n\n  MODE=$(echo \"$FRONTMATTER\" | grep '^mode:' | sed 's/mode: *//' | sed 's/^\"\\(.*\\)\"$/\\1/')\n  MODE=${MODE:-standard}\n\n  MAX_SIZE=$(echo \"$FRONTMATTER\" | grep '^max_size:' | sed 's/max_size: *//')\n  MAX_SIZE=${MAX_SIZE:-1000000}\n\n  # Validate values\n  if [[ \"$ENABLED\" != \"true\" ]] && [[ \"$ENABLED\" != \"false\" ]]; then\n    echo \"âš ï¸  Invalid enabled value, using default\" >&2\n    ENABLED=true\n  fi\n\n  if ! [[ \"$MAX_SIZE\" =~ ^[0-9]+$ ]]; then\n    echo \"âš ï¸  Invalid max_size, using default\" >&2\n    MAX_SIZE=1000000\n  fi\nfi\n\n# Quick exit if disabled\nif [[ \"$ENABLED\" != \"true\" ]]; then\n  exit 0\nfi\n\n# Use configuration\necho \"Configuration loaded: mode=$MODE, max_size=$MAX_SIZE\" >&2\n\n# Apply logic based on settings\ncase \"$MODE\" in\n  strict)\n    # Strict validation\n    ;;\n  standard)\n    # Standard validation\n    ;;\n  lenient)\n    # Lenient validation\n    ;;\nesac\n```\n\nThis provides robust settings handling with defaults, validation, and error recovery.\n",
        "plugins/plugin-dev/skills/plugin-settings/references/real-world-examples.md": "# Real-World Plugin Settings Examples\n\nDetailed analysis of how production plugins use the `.claude/plugin-name.local.md` pattern.\n\n## multi-agent-swarm Plugin\n\n### Settings File Structure\n\n**.claude/multi-agent-swarm.local.md:**\n\n```markdown\n---\nagent_name: auth-implementation\ntask_number: 3.5\npr_number: 1234\ncoordinator_session: team-leader\nenabled: true\ndependencies: [\"Task 3.4\"]\nadditional_instructions: \"Use JWT tokens, not sessions\"\n---\n\n# Task: Implement Authentication\n\nBuild JWT-based authentication for the REST API.\n\n## Requirements\n- JWT token generation and validation\n- Refresh token flow\n- Secure password hashing\n\n## Success Criteria\n- Auth endpoints implemented\n- Tests passing (100% coverage)\n- PR created and CI green\n- Documentation updated\n\n## Coordination\nDepends on Task 3.4 (user model).\nReport status to 'team-leader' session.\n```\n\n### How It's Used\n\n**File:** `hooks/agent-stop-notification.sh`\n\n**Purpose:** Send notifications to coordinator when agent becomes idle\n\n**Implementation:**\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\nSWARM_STATE_FILE=\".claude/multi-agent-swarm.local.md\"\n\n# Quick exit if no swarm active\nif [[ ! -f \"$SWARM_STATE_FILE\" ]]; then\n  exit 0\nfi\n\n# Parse frontmatter\nFRONTMATTER=$(sed -n '/^---$/,/^---$/{ /^---$/d; p; }' \"$SWARM_STATE_FILE\")\n\n# Extract configuration\nCOORDINATOR_SESSION=$(echo \"$FRONTMATTER\" | grep '^coordinator_session:' | sed 's/coordinator_session: *//' | sed 's/^\"\\(.*\\)\"$/\\1/')\nAGENT_NAME=$(echo \"$FRONTMATTER\" | grep '^agent_name:' | sed 's/agent_name: *//' | sed 's/^\"\\(.*\\)\"$/\\1/')\nTASK_NUMBER=$(echo \"$FRONTMATTER\" | grep '^task_number:' | sed 's/task_number: *//' | sed 's/^\"\\(.*\\)\"$/\\1/')\nPR_NUMBER=$(echo \"$FRONTMATTER\" | grep '^pr_number:' | sed 's/pr_number: *//' | sed 's/^\"\\(.*\\)\"$/\\1/')\nENABLED=$(echo \"$FRONTMATTER\" | grep '^enabled:' | sed 's/enabled: *//')\n\n# Check if enabled\nif [[ \"$ENABLED\" != \"true\" ]]; then\n  exit 0\nfi\n\n# Send notification to coordinator\nNOTIFICATION=\"ðŸ¤– Agent ${AGENT_NAME} (Task ${TASK_NUMBER}, PR #${PR_NUMBER}) is idle.\"\n\nif tmux has-session -t \"$COORDINATOR_SESSION\" 2>/dev/null; then\n  tmux send-keys -t \"$COORDINATOR_SESSION\" \"$NOTIFICATION\" Enter\n  sleep 0.5\n  tmux send-keys -t \"$COORDINATOR_SESSION\" Enter\nfi\n\nexit 0\n```\n\n**Key patterns:**\n1. **Quick exit** (line 7-9): Returns immediately if file doesn't exist\n2. **Field extraction** (lines 11-17): Parses each frontmatter field\n3. **Enabled check** (lines 19-21): Respects enabled flag\n4. **Action based on settings** (lines 23-29): Uses coordinator_session to send notification\n\n### Creation\n\n**File:** `commands/launch-swarm.md`\n\nSettings files are created during swarm launch with:\n\n```bash\ncat > \"$WORKTREE_PATH/.claude/multi-agent-swarm.local.md\" <<EOF\n---\nagent_name: $AGENT_NAME\ntask_number: $TASK_ID\npr_number: TBD\ncoordinator_session: $COORDINATOR_SESSION\nenabled: true\ndependencies: [$DEPENDENCIES]\nadditional_instructions: \"$EXTRA_INSTRUCTIONS\"\n---\n\n# Task: $TASK_DESCRIPTION\n\n$TASK_DETAILS\nEOF\n```\n\n### Updates\n\nPR number updated after PR creation:\n\n```bash\n# Update pr_number field\nsed \"s/^pr_number: .*/pr_number: $PR_NUM/\" \\\n  \".claude/multi-agent-swarm.local.md\" > temp.md\nmv temp.md \".claude/multi-agent-swarm.local.md\"\n```\n\n## ralph-loop Plugin\n\n### Settings File Structure\n\n**.claude/ralph-loop.local.md:**\n\n```markdown\n---\niteration: 1\nmax_iterations: 10\ncompletion_promise: \"All tests passing and build successful\"\nstarted_at: \"2025-01-15T14:30:00Z\"\n---\n\nFix all the linting errors in the project.\nMake sure tests pass after each fix.\nDocument any changes needed in CLAUDE.md.\n```\n\n### How It's Used\n\n**File:** `hooks/stop-hook.sh`\n\n**Purpose:** Prevent session exit and loop Claude's output back as input\n\n**Implementation:**\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\nRALPH_STATE_FILE=\".claude/ralph-loop.local.md\"\n\n# Quick exit if no active loop\nif [[ ! -f \"$RALPH_STATE_FILE\" ]]; then\n  exit 0\nfi\n\n# Parse frontmatter\nFRONTMATTER=$(sed -n '/^---$/,/^---$/{ /^---$/d; p; }' \"$RALPH_STATE_FILE\")\n\n# Extract configuration\nITERATION=$(echo \"$FRONTMATTER\" | grep '^iteration:' | sed 's/iteration: *//')\nMAX_ITERATIONS=$(echo \"$FRONTMATTER\" | grep '^max_iterations:' | sed 's/max_iterations: *//')\nCOMPLETION_PROMISE=$(echo \"$FRONTMATTER\" | grep '^completion_promise:' | sed 's/completion_promise: *//' | sed 's/^\"\\(.*\\)\"$/\\1/')\n\n# Check max iterations\nif [[ $MAX_ITERATIONS -gt 0 ]] && [[ $ITERATION -ge $MAX_ITERATIONS ]]; then\n  echo \"ðŸ›‘ Ralph loop: Max iterations ($MAX_ITERATIONS) reached.\"\n  rm \"$RALPH_STATE_FILE\"\n  exit 0\nfi\n\n# Get transcript and check for completion promise\nTRANSCRIPT_PATH=$(echo \"$HOOK_INPUT\" | jq -r '.transcript_path')\nLAST_OUTPUT=$(grep '\"role\":\"assistant\"' \"$TRANSCRIPT_PATH\" | tail -1 | jq -r '.message.content | map(select(.type == \"text\")) | map(.text) | join(\"\\n\")')\n\n# Check for completion\nif [[ \"$COMPLETION_PROMISE\" != \"null\" ]] && [[ -n \"$COMPLETION_PROMISE\" ]]; then\n  PROMISE_TEXT=$(echo \"$LAST_OUTPUT\" | perl -0777 -pe 's/.*?<promise>(.*?)<\\/promise>.*/$1/s; s/^\\s+|\\s+$//g')\n\n  if [[ \"$PROMISE_TEXT\" = \"$COMPLETION_PROMISE\" ]]; then\n    echo \"âœ… Ralph loop: Detected completion\"\n    rm \"$RALPH_STATE_FILE\"\n    exit 0\n  fi\nfi\n\n# Continue loop - increment iteration\nNEXT_ITERATION=$((ITERATION + 1))\n\n# Extract prompt from markdown body\nPROMPT_TEXT=$(awk '/^---$/{i++; next} i>=2' \"$RALPH_STATE_FILE\")\n\n# Update iteration counter\nTEMP_FILE=\"${RALPH_STATE_FILE}.tmp.$$\"\nsed \"s/^iteration: .*/iteration: $NEXT_ITERATION/\" \"$RALPH_STATE_FILE\" > \"$TEMP_FILE\"\nmv \"$TEMP_FILE\" \"$RALPH_STATE_FILE\"\n\n# Block exit and feed prompt back\njq -n \\\n  --arg prompt \"$PROMPT_TEXT\" \\\n  --arg msg \"ðŸ”„ Ralph iteration $NEXT_ITERATION\" \\\n  '{\n    \"decision\": \"block\",\n    \"reason\": $prompt,\n    \"systemMessage\": $msg\n  }'\n\nexit 0\n```\n\n**Key patterns:**\n1. **Quick exit** (line 7-9): Skip if not active\n2. **Iteration tracking** (lines 11-20): Count and enforce max iterations\n3. **Promise detection** (lines 25-33): Check for completion signal in output\n4. **Prompt extraction** (line 38): Read markdown body as next prompt\n5. **State update** (lines 40-43): Increment iteration atomically\n6. **Loop continuation** (lines 45-53): Block exit and feed prompt back\n\n### Creation\n\n**File:** `scripts/setup-ralph-loop.sh`\n\n```bash\n#!/bin/bash\nPROMPT=\"$1\"\nMAX_ITERATIONS=\"${2:-0}\"\nCOMPLETION_PROMISE=\"${3:-}\"\n\n# Create state file\ncat > \".claude/ralph-loop.local.md\" <<EOF\n---\niteration: 1\nmax_iterations: $MAX_ITERATIONS\ncompletion_promise: \"$COMPLETION_PROMISE\"\nstarted_at: \"$(date -Iseconds)\"\n---\n\n$PROMPT\nEOF\n\necho \"Ralph loop initialized: .claude/ralph-loop.local.md\"\n```\n\n## Pattern Comparison\n\n| Feature | multi-agent-swarm | ralph-loop |\n|---------|-------------------|--------------|\n| **File** | `.claude/multi-agent-swarm.local.md` | `.claude/ralph-loop.local.md` |\n| **Purpose** | Agent coordination state | Loop iteration state |\n| **Frontmatter** | Agent metadata | Loop configuration |\n| **Body** | Task assignment | Prompt to loop |\n| **Updates** | PR number, status | Iteration counter |\n| **Deletion** | Manual or on completion | On loop exit |\n| **Hook** | Stop (notifications) | Stop (loop control) |\n\n## Best Practices from Real Plugins\n\n### 1. Quick Exit Pattern\n\nBoth plugins check file existence first:\n\n```bash\nif [[ ! -f \"$STATE_FILE\" ]]; then\n  exit 0  # Not active\nfi\n```\n\n**Why:** Avoids errors when plugin isn't configured and performs fast.\n\n### 2. Enabled Flag\n\nBoth use an `enabled` field for explicit control:\n\n```yaml\nenabled: true\n```\n\n**Why:** Allows temporary deactivation without deleting file.\n\n### 3. Atomic Updates\n\nBoth use temp file + atomic move:\n\n```bash\nTEMP_FILE=\"${FILE}.tmp.$$\"\nsed \"s/^field: .*/field: $NEW_VALUE/\" \"$FILE\" > \"$TEMP_FILE\"\nmv \"$TEMP_FILE\" \"$FILE\"\n```\n\n**Why:** Prevents corruption if process is interrupted.\n\n### 4. Quote Handling\n\nBoth strip surrounding quotes from YAML values:\n\n```bash\nsed 's/^\"\\(.*\\)\"$/\\1/'\n```\n\n**Why:** YAML allows both `field: value` and `field: \"value\"`.\n\n### 5. Error Handling\n\nBoth handle missing/corrupt files gracefully:\n\n```bash\nif [[ ! -f \"$FILE\" ]]; then\n  exit 0  # No error, just not configured\nfi\n\nif [[ -z \"$CRITICAL_FIELD\" ]]; then\n  echo \"Settings file corrupt\" >&2\n  rm \"$FILE\"  # Clean up\n  exit 0\nfi\n```\n\n**Why:** Fails gracefully instead of crashing.\n\n## Anti-Patterns to Avoid\n\n### âŒ Hardcoded Paths\n\n```bash\n# BAD\nFILE=\"/Users/alice/.claude/my-plugin.local.md\"\n\n# GOOD\nFILE=\".claude/my-plugin.local.md\"\n```\n\n### âŒ Unquoted Variables\n\n```bash\n# BAD\necho $VALUE\n\n# GOOD\necho \"$VALUE\"\n```\n\n### âŒ Non-Atomic Updates\n\n```bash\n# BAD: Can corrupt file if interrupted\nsed -i \"s/field: .*/field: $VALUE/\" \"$FILE\"\n\n# GOOD: Atomic\nTEMP_FILE=\"${FILE}.tmp.$$\"\nsed \"s/field: .*/field: $VALUE/\" \"$FILE\" > \"$TEMP_FILE\"\nmv \"$TEMP_FILE\" \"$FILE\"\n```\n\n### âŒ No Default Values\n\n```bash\n# BAD: Fails if field missing\nif [[ $MAX -gt 100 ]]; then\n  # MAX might be empty!\nfi\n\n# GOOD: Provide default\nMAX=${MAX:-10}\n```\n\n### âŒ Ignoring Edge Cases\n\n```bash\n# BAD: Assumes exactly 2 --- markers\nsed -n '/^---$/,/^---$/{ /^---$/d; p; }'\n\n# GOOD: Handles --- in body\nawk '/^---$/{i++; next} i>=2'  # For body\n```\n\n## Conclusion\n\nThe `.claude/plugin-name.local.md` pattern provides:\n- Simple, human-readable configuration\n- Version-control friendly (gitignored)\n- Per-project settings\n- Easy parsing with standard bash tools\n- Supports both structured config (YAML) and freeform content (markdown)\n\nUse this pattern for any plugin that needs user-configurable behavior or state persistence.\n",
        "plugins/plugin-dev/skills/plugin-structure/README.md": "# Plugin Structure Skill\n\nComprehensive guidance on Claude Code plugin architecture, directory layout, and best practices.\n\n## Overview\n\nThis skill provides detailed knowledge about:\n- Plugin directory structure and organization\n- `plugin.json` manifest configuration\n- Component organization (commands, agents, skills, hooks)\n- Auto-discovery mechanisms\n- Portable path references with `${CLAUDE_PLUGIN_ROOT}`\n- File naming conventions\n\n## Skill Structure\n\n### SKILL.md (1,619 words)\n\nCore skill content covering:\n- Directory structure overview\n- Plugin manifest (plugin.json) fields\n- Component organization patterns\n- ${CLAUDE_PLUGIN_ROOT} usage\n- File naming conventions\n- Auto-discovery mechanism\n- Best practices\n- Common patterns\n- Troubleshooting\n\n### References\n\nDetailed documentation for deep dives:\n\n- **manifest-reference.md**: Complete `plugin.json` field reference\n  - All field descriptions and examples\n  - Path resolution rules\n  - Validation guidelines\n  - Minimal vs. complete manifest examples\n\n- **component-patterns.md**: Advanced organization patterns\n  - Component lifecycle (discovery, activation)\n  - Command organization patterns\n  - Agent organization patterns\n  - Skill organization patterns\n  - Hook organization patterns\n  - Script organization patterns\n  - Cross-component patterns\n  - Best practices for scalability\n\n### Examples\n\nThree complete plugin examples:\n\n- **minimal-plugin.md**: Simplest possible plugin\n  - Single command\n  - Minimal manifest\n  - When to use this pattern\n\n- **standard-plugin.md**: Well-structured production plugin\n  - Multiple components (commands, agents, skills, hooks)\n  - Complete manifest with metadata\n  - Rich skill structure\n  - Integration between components\n\n- **advanced-plugin.md**: Enterprise-grade plugin\n  - Multi-level organization\n  - MCP server integration\n  - Shared libraries\n  - Configuration management\n  - Security automation\n  - Monitoring integration\n\n## When This Skill Triggers\n\nClaude Code activates this skill when users:\n- Ask to \"create a plugin\" or \"scaffold a plugin\"\n- Need to \"understand plugin structure\"\n- Want to \"organize plugin components\"\n- Need to \"set up plugin.json\"\n- Ask about \"${CLAUDE_PLUGIN_ROOT}\" usage\n- Want to \"add commands/agents/skills/hooks\"\n- Need \"configure auto-discovery\" help\n- Ask about plugin architecture or best practices\n\n## Progressive Disclosure\n\nThe skill uses progressive disclosure to manage context:\n\n1. **SKILL.md** (~1600 words): Core concepts and workflows\n2. **References** (~6000 words): Detailed field references and patterns\n3. **Examples** (~8000 words): Complete working examples\n\nClaude loads references and examples only as needed based on the task.\n\n## Related Skills\n\nThis skill works well with:\n- **hook-development**: For creating plugin hooks\n- **mcp-integration**: For integrating MCP servers (when available)\n- **marketplace-publishing**: For publishing plugins (when available)\n\n## Maintenance\n\nTo update this skill:\n1. Keep SKILL.md lean and focused on core concepts\n2. Move detailed information to references/\n3. Add new examples/ for common patterns\n4. Update version in SKILL.md frontmatter\n5. Ensure all documentation uses imperative/infinitive form\n",
        "plugins/plugin-dev/skills/plugin-structure/SKILL.md": "---\nname: plugin-structure\ndescription: This skill should be used when the user asks to \"create a plugin\", \"scaffold a plugin\", \"understand plugin structure\", \"organize plugin components\", \"set up plugin.json\", \"use ${CLAUDE_PLUGIN_ROOT}\", \"add commands/agents/skills/hooks\", \"configure auto-discovery\", or needs guidance on plugin directory layout, manifest configuration, component organization, file naming conventions, or Claude Code plugin architecture best practices.\n---\n\n# Plugin Structure for Claude Code\n\n## Overview\n\nClaude Code plugins follow a standardized directory structure with automatic component discovery. Understanding this structure enables creating well-organized, maintainable plugins that integrate seamlessly with Claude Code.\n\n**Key concepts:**\n- Conventional directory layout for automatic discovery\n- Manifest-driven configuration in `.claude-plugin/plugin.json`\n- Component-based organization (commands, agents, skills, hooks)\n- Portable path references using `${CLAUDE_PLUGIN_ROOT}`\n- Explicit vs. auto-discovered component loading\n\n## Directory Structure\n\nEvery Claude Code plugin follows this organizational pattern:\n\n```\nplugin-name/\nâ”œâ”€â”€ .claude-plugin/\nâ”‚   â””â”€â”€ plugin.json          # Required: Plugin manifest\nâ”œâ”€â”€ commands/                 # Slash commands (.md files)\nâ”œâ”€â”€ agents/                   # Subagent definitions (.md files)\nâ”œâ”€â”€ skills/                   # Agent skills (subdirectories)\nâ”‚   â””â”€â”€ skill-name/\nâ”‚       â””â”€â”€ SKILL.md         # Required for each skill\nâ”œâ”€â”€ hooks/\nâ”‚   â””â”€â”€ hooks.json           # Event handler configuration\nâ”œâ”€â”€ .mcp.json                # MCP server definitions\nâ””â”€â”€ scripts/                 # Helper scripts and utilities\n```\n\n**Critical rules:**\n\n1. **Manifest location**: The `plugin.json` manifest MUST be in `.claude-plugin/` directory\n2. **Component locations**: All component directories (commands, agents, skills, hooks) MUST be at plugin root level, NOT nested inside `.claude-plugin/`\n3. **Optional components**: Only create directories for components the plugin actually uses\n4. **Naming convention**: Use kebab-case for all directory and file names\n\n## Plugin Manifest (plugin.json)\n\nThe manifest defines plugin metadata and configuration. Located at `.claude-plugin/plugin.json`:\n\n### Required Fields\n\n```json\n{\n  \"name\": \"plugin-name\"\n}\n```\n\n**Name requirements:**\n- Use kebab-case format (lowercase with hyphens)\n- Must be unique across installed plugins\n- No spaces or special characters\n- Example: `code-review-assistant`, `test-runner`, `api-docs`\n\n### Recommended Metadata\n\n```json\n{\n  \"name\": \"plugin-name\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Brief explanation of plugin purpose\",\n  \"author\": {\n    \"name\": \"Author Name\",\n    \"email\": \"author@example.com\",\n    \"url\": \"https://example.com\"\n  },\n  \"homepage\": \"https://docs.example.com\",\n  \"repository\": \"https://github.com/user/plugin-name\",\n  \"license\": \"MIT\",\n  \"keywords\": [\"testing\", \"automation\", \"ci-cd\"]\n}\n```\n\n**Version format**: Follow semantic versioning (MAJOR.MINOR.PATCH)\n**Keywords**: Use for plugin discovery and categorization\n\n### Component Path Configuration\n\nSpecify custom paths for components (supplements default directories):\n\n```json\n{\n  \"name\": \"plugin-name\",\n  \"commands\": \"./custom-commands\",\n  \"agents\": [\"./agents\", \"./specialized-agents\"],\n  \"hooks\": \"./config/hooks.json\",\n  \"mcpServers\": \"./.mcp.json\"\n}\n```\n\n**Important**: Custom paths supplement defaultsâ€”they don't replace them. Components in both default directories and custom paths will load.\n\n**Path rules:**\n- Must be relative to plugin root\n- Must start with `./`\n- Cannot use absolute paths\n- Support arrays for multiple locations\n\n## Component Organization\n\n### Commands\n\n**Location**: `commands/` directory\n**Format**: Markdown files with YAML frontmatter\n**Auto-discovery**: All `.md` files in `commands/` load automatically\n\n**Example structure**:\n```\ncommands/\nâ”œâ”€â”€ review.md        # /review command\nâ”œâ”€â”€ test.md          # /test command\nâ””â”€â”€ deploy.md        # /deploy command\n```\n\n**File format**:\n```markdown\n---\nname: command-name\ndescription: Command description\n---\n\nCommand implementation instructions...\n```\n\n**Usage**: Commands integrate as native slash commands in Claude Code\n\n### Agents\n\n**Location**: `agents/` directory\n**Format**: Markdown files with YAML frontmatter\n**Auto-discovery**: All `.md` files in `agents/` load automatically\n\n**Example structure**:\n```\nagents/\nâ”œâ”€â”€ code-reviewer.md\nâ”œâ”€â”€ test-generator.md\nâ””â”€â”€ refactorer.md\n```\n\n**File format**:\n```markdown\n---\ndescription: Agent role and expertise\ncapabilities:\n  - Specific task 1\n  - Specific task 2\n---\n\nDetailed agent instructions and knowledge...\n```\n\n**Usage**: Users can invoke agents manually, or Claude Code selects them automatically based on task context\n\n### Skills\n\n**Location**: `skills/` directory with subdirectories per skill\n**Format**: Each skill in its own directory with `SKILL.md` file\n**Auto-discovery**: All `SKILL.md` files in skill subdirectories load automatically\n\n**Example structure**:\n```\nskills/\nâ”œâ”€â”€ api-testing/\nâ”‚   â”œâ”€â”€ SKILL.md\nâ”‚   â”œâ”€â”€ scripts/\nâ”‚   â”‚   â””â”€â”€ test-runner.py\nâ”‚   â””â”€â”€ references/\nâ”‚       â””â”€â”€ api-spec.md\nâ””â”€â”€ database-migrations/\n    â”œâ”€â”€ SKILL.md\n    â””â”€â”€ examples/\n        â””â”€â”€ migration-template.sql\n```\n\n**SKILL.md format**:\n```markdown\n---\nname: Skill Name\ndescription: When to use this skill\nversion: 1.0.0\n---\n\nSkill instructions and guidance...\n```\n\n**Supporting files**: Skills can include scripts, references, examples, or assets in subdirectories\n\n**Usage**: Claude Code autonomously activates skills based on task context matching the description\n\n### Hooks\n\n**Location**: `hooks/hooks.json` or inline in `plugin.json`\n**Format**: JSON configuration defining event handlers\n**Registration**: Hooks register automatically when plugin enables\n\n**Example structure**:\n```\nhooks/\nâ”œâ”€â”€ hooks.json           # Hook configuration\nâ””â”€â”€ scripts/\n    â”œâ”€â”€ validate.sh      # Hook script\n    â””â”€â”€ check-style.sh   # Hook script\n```\n\n**Configuration format**:\n```json\n{\n  \"PreToolUse\": [{\n    \"matcher\": \"Write|Edit\",\n    \"hooks\": [{\n      \"type\": \"command\",\n      \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/hooks/scripts/validate.sh\",\n      \"timeout\": 30\n    }]\n  }]\n}\n```\n\n**Available events**: PreToolUse, PostToolUse, Stop, SubagentStop, SessionStart, SessionEnd, UserPromptSubmit, PreCompact, Notification\n\n**Usage**: Hooks execute automatically in response to Claude Code events\n\n### MCP Servers\n\n**Location**: `.mcp.json` at plugin root or inline in `plugin.json`\n**Format**: JSON configuration for MCP server definitions\n**Auto-start**: Servers start automatically when plugin enables\n\n**Example format**:\n```json\n{\n  \"mcpServers\": {\n    \"server-name\": {\n      \"command\": \"node\",\n      \"args\": [\"${CLAUDE_PLUGIN_ROOT}/servers/server.js\"],\n      \"env\": {\n        \"API_KEY\": \"${API_KEY}\"\n      }\n    }\n  }\n}\n```\n\n**Usage**: MCP servers integrate seamlessly with Claude Code's tool system\n\n## Portable Path References\n\n### ${CLAUDE_PLUGIN_ROOT}\n\nUse `${CLAUDE_PLUGIN_ROOT}` environment variable for all intra-plugin path references:\n\n```json\n{\n  \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/scripts/run.sh\"\n}\n```\n\n**Why it matters**: Plugins install in different locations depending on:\n- User installation method (marketplace, local, npm)\n- Operating system conventions\n- User preferences\n\n**Where to use it**:\n- Hook command paths\n- MCP server command arguments\n- Script execution references\n- Resource file paths\n\n**Never use**:\n- Hardcoded absolute paths (`/Users/name/plugins/...`)\n- Relative paths from working directory (`./scripts/...` in commands)\n- Home directory shortcuts (`~/plugins/...`)\n\n### Path Resolution Rules\n\n**In manifest JSON fields** (hooks, MCP servers):\n```json\n\"command\": \"${CLAUDE_PLUGIN_ROOT}/scripts/tool.sh\"\n```\n\n**In component files** (commands, agents, skills):\n```markdown\nReference scripts at: ${CLAUDE_PLUGIN_ROOT}/scripts/helper.py\n```\n\n**In executed scripts**:\n```bash\n#!/bin/bash\n# ${CLAUDE_PLUGIN_ROOT} available as environment variable\nsource \"${CLAUDE_PLUGIN_ROOT}/lib/common.sh\"\n```\n\n## File Naming Conventions\n\n### Component Files\n\n**Commands**: Use kebab-case `.md` files\n- `code-review.md` â†’ `/code-review`\n- `run-tests.md` â†’ `/run-tests`\n- `api-docs.md` â†’ `/api-docs`\n\n**Agents**: Use kebab-case `.md` files describing role\n- `test-generator.md`\n- `code-reviewer.md`\n- `performance-analyzer.md`\n\n**Skills**: Use kebab-case directory names\n- `api-testing/`\n- `database-migrations/`\n- `error-handling/`\n\n### Supporting Files\n\n**Scripts**: Use descriptive kebab-case names with appropriate extensions\n- `validate-input.sh`\n- `generate-report.py`\n- `process-data.js`\n\n**Documentation**: Use kebab-case markdown files\n- `api-reference.md`\n- `migration-guide.md`\n- `best-practices.md`\n\n**Configuration**: Use standard names\n- `hooks.json`\n- `.mcp.json`\n- `plugin.json`\n\n## Auto-Discovery Mechanism\n\nClaude Code automatically discovers and loads components:\n\n1. **Plugin manifest**: Reads `.claude-plugin/plugin.json` when plugin enables\n2. **Commands**: Scans `commands/` directory for `.md` files\n3. **Agents**: Scans `agents/` directory for `.md` files\n4. **Skills**: Scans `skills/` for subdirectories containing `SKILL.md`\n5. **Hooks**: Loads configuration from `hooks/hooks.json` or manifest\n6. **MCP servers**: Loads configuration from `.mcp.json` or manifest\n\n**Discovery timing**:\n- Plugin installation: Components register with Claude Code\n- Plugin enable: Components become available for use\n- No restart required: Changes take effect on next Claude Code session\n\n**Override behavior**: Custom paths in `plugin.json` supplement (not replace) default directories\n\n## Best Practices\n\n### Organization\n\n1. **Logical grouping**: Group related components together\n   - Put test-related commands, agents, and skills together\n   - Create subdirectories in `scripts/` for different purposes\n\n2. **Minimal manifest**: Keep `plugin.json` lean\n   - Only specify custom paths when necessary\n   - Rely on auto-discovery for standard layouts\n   - Use inline configuration only for simple cases\n\n3. **Documentation**: Include README files\n   - Plugin root: Overall purpose and usage\n   - Component directories: Specific guidance\n   - Script directories: Usage and requirements\n\n### Naming\n\n1. **Consistency**: Use consistent naming across components\n   - If command is `test-runner`, name related agent `test-runner-agent`\n   - Match skill directory names to their purpose\n\n2. **Clarity**: Use descriptive names that indicate purpose\n   - Good: `api-integration-testing/`, `code-quality-checker.md`\n   - Avoid: `utils/`, `misc.md`, `temp.sh`\n\n3. **Length**: Balance brevity with clarity\n   - Commands: 2-3 words (`review-pr`, `run-ci`)\n   - Agents: Describe role clearly (`code-reviewer`, `test-generator`)\n   - Skills: Topic-focused (`error-handling`, `api-design`)\n\n### Portability\n\n1. **Always use ${CLAUDE_PLUGIN_ROOT}**: Never hardcode paths\n2. **Test on multiple systems**: Verify on macOS, Linux, Windows\n3. **Document dependencies**: List required tools and versions\n4. **Avoid system-specific features**: Use portable bash/Python constructs\n\n### Maintenance\n\n1. **Version consistently**: Update version in plugin.json for releases\n2. **Deprecate gracefully**: Mark old components clearly before removal\n3. **Document breaking changes**: Note changes affecting existing users\n4. **Test thoroughly**: Verify all components work after changes\n\n## Common Patterns\n\n### Minimal Plugin\n\nSingle command with no dependencies:\n```\nmy-plugin/\nâ”œâ”€â”€ .claude-plugin/\nâ”‚   â””â”€â”€ plugin.json    # Just name field\nâ””â”€â”€ commands/\n    â””â”€â”€ hello.md       # Single command\n```\n\n### Full-Featured Plugin\n\nComplete plugin with all component types:\n```\nmy-plugin/\nâ”œâ”€â”€ .claude-plugin/\nâ”‚   â””â”€â”€ plugin.json\nâ”œâ”€â”€ commands/          # User-facing commands\nâ”œâ”€â”€ agents/            # Specialized subagents\nâ”œâ”€â”€ skills/            # Auto-activating skills\nâ”œâ”€â”€ hooks/             # Event handlers\nâ”‚   â”œâ”€â”€ hooks.json\nâ”‚   â””â”€â”€ scripts/\nâ”œâ”€â”€ .mcp.json          # External integrations\nâ””â”€â”€ scripts/           # Shared utilities\n```\n\n### Skill-Focused Plugin\n\nPlugin providing only skills:\n```\nmy-plugin/\nâ”œâ”€â”€ .claude-plugin/\nâ”‚   â””â”€â”€ plugin.json\nâ””â”€â”€ skills/\n    â”œâ”€â”€ skill-one/\n    â”‚   â””â”€â”€ SKILL.md\n    â””â”€â”€ skill-two/\n        â””â”€â”€ SKILL.md\n```\n\n## Troubleshooting\n\n**Component not loading**:\n- Verify file is in correct directory with correct extension\n- Check YAML frontmatter syntax (commands, agents, skills)\n- Ensure skill has `SKILL.md` (not `README.md` or other name)\n- Confirm plugin is enabled in Claude Code settings\n\n**Path resolution errors**:\n- Replace all hardcoded paths with `${CLAUDE_PLUGIN_ROOT}`\n- Verify paths are relative and start with `./` in manifest\n- Check that referenced files exist at specified paths\n- Test with `echo $CLAUDE_PLUGIN_ROOT` in hook scripts\n\n**Auto-discovery not working**:\n- Confirm directories are at plugin root (not in `.claude-plugin/`)\n- Check file naming follows conventions (kebab-case, correct extensions)\n- Verify custom paths in manifest are correct\n- Restart Claude Code to reload plugin configuration\n\n**Conflicts between plugins**:\n- Use unique, descriptive component names\n- Namespace commands with plugin name if needed\n- Document potential conflicts in plugin README\n- Consider command prefixes for related functionality\n\n---\n\nFor detailed examples and advanced patterns, see files in `references/` and `examples/` directories.\n",
        "plugins/plugin-dev/skills/plugin-structure/examples/advanced-plugin.md": "# Advanced Plugin Example\n\nA complex, enterprise-grade plugin with MCP integration and advanced organization.\n\n## Directory Structure\n\n```\nenterprise-devops/\nâ”œâ”€â”€ .claude-plugin/\nâ”‚   â””â”€â”€ plugin.json\nâ”œâ”€â”€ commands/\nâ”‚   â”œâ”€â”€ ci/\nâ”‚   â”‚   â”œâ”€â”€ build.md\nâ”‚   â”‚   â”œâ”€â”€ test.md\nâ”‚   â”‚   â””â”€â”€ deploy.md\nâ”‚   â”œâ”€â”€ monitoring/\nâ”‚   â”‚   â”œâ”€â”€ status.md\nâ”‚   â”‚   â””â”€â”€ logs.md\nâ”‚   â””â”€â”€ admin/\nâ”‚       â”œâ”€â”€ configure.md\nâ”‚       â””â”€â”€ manage.md\nâ”œâ”€â”€ agents/\nâ”‚   â”œâ”€â”€ orchestration/\nâ”‚   â”‚   â”œâ”€â”€ deployment-orchestrator.md\nâ”‚   â”‚   â””â”€â”€ rollback-manager.md\nâ”‚   â””â”€â”€ specialized/\nâ”‚       â”œâ”€â”€ kubernetes-expert.md\nâ”‚       â”œâ”€â”€ terraform-expert.md\nâ”‚       â””â”€â”€ security-auditor.md\nâ”œâ”€â”€ skills/\nâ”‚   â”œâ”€â”€ kubernetes-ops/\nâ”‚   â”‚   â”œâ”€â”€ SKILL.md\nâ”‚   â”‚   â”œâ”€â”€ references/\nâ”‚   â”‚   â”‚   â”œâ”€â”€ deployment-patterns.md\nâ”‚   â”‚   â”‚   â”œâ”€â”€ troubleshooting.md\nâ”‚   â”‚   â”‚   â””â”€â”€ security.md\nâ”‚   â”‚   â”œâ”€â”€ examples/\nâ”‚   â”‚   â”‚   â”œâ”€â”€ basic-deployment.yaml\nâ”‚   â”‚   â”‚   â”œâ”€â”€ stateful-set.yaml\nâ”‚   â”‚   â”‚   â””â”€â”€ ingress-config.yaml\nâ”‚   â”‚   â””â”€â”€ scripts/\nâ”‚   â”‚       â”œâ”€â”€ validate-manifest.sh\nâ”‚   â”‚       â””â”€â”€ health-check.sh\nâ”‚   â”œâ”€â”€ terraform-iac/\nâ”‚   â”‚   â”œâ”€â”€ SKILL.md\nâ”‚   â”‚   â”œâ”€â”€ references/\nâ”‚   â”‚   â”‚   â””â”€â”€ best-practices.md\nâ”‚   â”‚   â””â”€â”€ examples/\nâ”‚   â”‚       â””â”€â”€ module-template/\nâ”‚   â””â”€â”€ ci-cd-pipelines/\nâ”‚       â”œâ”€â”€ SKILL.md\nâ”‚       â””â”€â”€ references/\nâ”‚           â””â”€â”€ pipeline-patterns.md\nâ”œâ”€â”€ hooks/\nâ”‚   â”œâ”€â”€ hooks.json\nâ”‚   â””â”€â”€ scripts/\nâ”‚       â”œâ”€â”€ security/\nâ”‚       â”‚   â”œâ”€â”€ scan-secrets.sh\nâ”‚       â”‚   â”œâ”€â”€ validate-permissions.sh\nâ”‚       â”‚   â””â”€â”€ audit-changes.sh\nâ”‚       â”œâ”€â”€ quality/\nâ”‚       â”‚   â”œâ”€â”€ check-config.sh\nâ”‚       â”‚   â””â”€â”€ verify-tests.sh\nâ”‚       â””â”€â”€ workflow/\nâ”‚           â”œâ”€â”€ notify-team.sh\nâ”‚           â””â”€â”€ update-status.sh\nâ”œâ”€â”€ .mcp.json\nâ”œâ”€â”€ servers/\nâ”‚   â”œâ”€â”€ kubernetes-mcp/\nâ”‚   â”‚   â”œâ”€â”€ index.js\nâ”‚   â”‚   â”œâ”€â”€ package.json\nâ”‚   â”‚   â””â”€â”€ lib/\nâ”‚   â”œâ”€â”€ terraform-mcp/\nâ”‚   â”‚   â”œâ”€â”€ main.py\nâ”‚   â”‚   â””â”€â”€ requirements.txt\nâ”‚   â””â”€â”€ github-actions-mcp/\nâ”‚       â”œâ”€â”€ server.js\nâ”‚       â””â”€â”€ package.json\nâ”œâ”€â”€ lib/\nâ”‚   â”œâ”€â”€ core/\nâ”‚   â”‚   â”œâ”€â”€ logger.js\nâ”‚   â”‚   â”œâ”€â”€ config.js\nâ”‚   â”‚   â””â”€â”€ auth.js\nâ”‚   â”œâ”€â”€ integrations/\nâ”‚   â”‚   â”œâ”€â”€ slack.js\nâ”‚   â”‚   â”œâ”€â”€ pagerduty.js\nâ”‚   â”‚   â””â”€â”€ datadog.js\nâ”‚   â””â”€â”€ utils/\nâ”‚       â”œâ”€â”€ retry.js\nâ”‚       â””â”€â”€ validation.js\nâ””â”€â”€ config/\n    â”œâ”€â”€ environments/\n    â”‚   â”œâ”€â”€ production.json\n    â”‚   â”œâ”€â”€ staging.json\n    â”‚   â””â”€â”€ development.json\n    â””â”€â”€ templates/\n        â”œâ”€â”€ deployment.yaml\n        â””â”€â”€ service.yaml\n```\n\n## File Contents\n\n### .claude-plugin/plugin.json\n\n```json\n{\n  \"name\": \"enterprise-devops\",\n  \"version\": \"2.3.1\",\n  \"description\": \"Comprehensive DevOps automation for enterprise CI/CD pipelines, infrastructure management, and monitoring\",\n  \"author\": {\n    \"name\": \"DevOps Platform Team\",\n    \"email\": \"devops-platform@company.com\",\n    \"url\": \"https://company.com/teams/devops\"\n  },\n  \"homepage\": \"https://docs.company.com/plugins/devops\",\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"https://github.com/company/devops-plugin.git\"\n  },\n  \"license\": \"Apache-2.0\",\n  \"keywords\": [\n    \"devops\",\n    \"ci-cd\",\n    \"kubernetes\",\n    \"terraform\",\n    \"automation\",\n    \"infrastructure\",\n    \"deployment\",\n    \"monitoring\"\n  ],\n  \"commands\": [\n    \"./commands/ci\",\n    \"./commands/monitoring\",\n    \"./commands/admin\"\n  ],\n  \"agents\": [\n    \"./agents/orchestration\",\n    \"./agents/specialized\"\n  ],\n  \"hooks\": \"./hooks/hooks.json\",\n  \"mcpServers\": \"./.mcp.json\"\n}\n```\n\n### .mcp.json\n\n```json\n{\n  \"mcpServers\": {\n    \"kubernetes\": {\n      \"command\": \"node\",\n      \"args\": [\"${CLAUDE_PLUGIN_ROOT}/servers/kubernetes-mcp/index.js\"],\n      \"env\": {\n        \"KUBECONFIG\": \"${KUBECONFIG}\",\n        \"K8S_NAMESPACE\": \"${K8S_NAMESPACE:-default}\"\n      }\n    },\n    \"terraform\": {\n      \"command\": \"python\",\n      \"args\": [\"${CLAUDE_PLUGIN_ROOT}/servers/terraform-mcp/main.py\"],\n      \"env\": {\n        \"TF_STATE_BUCKET\": \"${TF_STATE_BUCKET}\",\n        \"AWS_REGION\": \"${AWS_REGION}\"\n      }\n    },\n    \"github-actions\": {\n      \"command\": \"node\",\n      \"args\": [\"${CLAUDE_PLUGIN_ROOT}/servers/github-actions-mcp/server.js\"],\n      \"env\": {\n        \"GITHUB_TOKEN\": \"${GITHUB_TOKEN}\",\n        \"GITHUB_ORG\": \"${GITHUB_ORG}\"\n      }\n    }\n  }\n}\n```\n\n### commands/ci/build.md\n\n```markdown\n---\nname: build\ndescription: Trigger and monitor CI build pipeline\n---\n\n# Build Command\n\nTrigger CI/CD build pipeline and monitor progress in real-time.\n\n## Process\n\n1. **Validation**: Check prerequisites\n   - Verify branch status\n   - Check for uncommitted changes\n   - Validate configuration files\n\n2. **Trigger**: Start build via MCP server\n   \\`\\`\\`javascript\n   // Uses github-actions MCP server\n   const build = await tools.github_actions_trigger_workflow({\n     workflow: 'build.yml',\n     ref: currentBranch\n   })\n   \\`\\`\\`\n\n3. **Monitor**: Track build progress\n   - Display real-time logs\n   - Show test results as they complete\n   - Alert on failures\n\n4. **Report**: Summarize results\n   - Build status\n   - Test coverage\n   - Performance metrics\n   - Deploy readiness\n\n## Integration\n\nAfter successful build:\n- Offer to deploy to staging\n- Suggest performance optimizations\n- Generate deployment checklist\n```\n\n### agents/orchestration/deployment-orchestrator.md\n\n```markdown\n---\ndescription: Orchestrates complex multi-environment deployments with rollback capabilities and health monitoring\ncapabilities:\n  - Plan and execute multi-stage deployments\n  - Coordinate service dependencies\n  - Monitor deployment health\n  - Execute automated rollbacks\n  - Manage deployment approvals\n---\n\n# Deployment Orchestrator Agent\n\nSpecialized agent for orchestrating complex deployments across multiple environments.\n\n## Expertise\n\n- **Deployment strategies**: Blue-green, canary, rolling updates\n- **Dependency management**: Service startup ordering, dependency injection\n- **Health monitoring**: Service health checks, metric validation\n- **Rollback automation**: Automatic rollback on failure detection\n- **Approval workflows**: Multi-stage approval processes\n\n## Orchestration Process\n\n1. **Planning Phase**\n   - Analyze deployment requirements\n   - Identify service dependencies\n   - Generate deployment plan\n   - Calculate rollback strategy\n\n2. **Validation Phase**\n   - Verify environment readiness\n   - Check resource availability\n   - Validate configurations\n   - Run pre-deployment tests\n\n3. **Execution Phase**\n   - Deploy services in dependency order\n   - Monitor health after each stage\n   - Validate metrics and logs\n   - Proceed to next stage on success\n\n4. **Verification Phase**\n   - Run smoke tests\n   - Validate service integration\n   - Check performance metrics\n   - Confirm deployment success\n\n5. **Rollback Phase** (if needed)\n   - Detect failure conditions\n   - Execute rollback plan\n   - Restore previous state\n   - Notify stakeholders\n\n## MCP Integration\n\nUses multiple MCP servers:\n- `kubernetes`: Deploy and manage containers\n- `terraform`: Provision infrastructure\n- `github-actions`: Trigger deployment pipelines\n\n## Monitoring Integration\n\nIntegrates with monitoring tools via lib:\n\\`\\`\\`javascript\nconst { DatadogClient } = require('${CLAUDE_PLUGIN_ROOT}/lib/integrations/datadog')\nconst metrics = await DatadogClient.getMetrics(service, timeRange)\n\\`\\`\\`\n\n## Notification Integration\n\nSends updates via Slack and PagerDuty:\n\\`\\`\\`javascript\nconst { SlackClient } = require('${CLAUDE_PLUGIN_ROOT}/lib/integrations/slack')\nawait SlackClient.notify({\n  channel: '#deployments',\n  message: 'Deployment started',\n  metadata: deploymentPlan\n})\n\\`\\`\\`\n```\n\n### skills/kubernetes-ops/SKILL.md\n\n```markdown\n---\nname: Kubernetes Operations\ndescription: This skill should be used when deploying to Kubernetes, managing K8s resources, troubleshooting cluster issues, configuring ingress/services, scaling deployments, or working with Kubernetes manifests. Provides comprehensive Kubernetes operational knowledge and best practices.\nversion: 2.0.0\n---\n\n# Kubernetes Operations\n\nComprehensive operational knowledge for managing Kubernetes clusters and workloads.\n\n## Overview\n\nManage Kubernetes infrastructure effectively through:\n- Deployment strategies and patterns\n- Resource configuration and optimization\n- Troubleshooting and debugging\n- Security best practices\n- Performance tuning\n\n## Core Concepts\n\n### Resource Management\n\n**Deployments**: Use for stateless applications\n- Rolling updates for zero-downtime deployments\n- Rollback capabilities for failed deployments\n- Replica management for scaling\n\n**StatefulSets**: Use for stateful applications\n- Stable network identities\n- Persistent storage\n- Ordered deployment and scaling\n\n**DaemonSets**: Use for node-level services\n- Log collectors\n- Monitoring agents\n- Network plugins\n\n### Configuration\n\n**ConfigMaps**: Store non-sensitive configuration\n- Environment-specific settings\n- Application configuration files\n- Feature flags\n\n**Secrets**: Store sensitive data\n- API keys and tokens\n- Database credentials\n- TLS certificates\n\nUse external secret management (Vault, AWS Secrets Manager) for production.\n\n### Networking\n\n**Services**: Expose applications internally\n- ClusterIP for internal communication\n- NodePort for external access (non-production)\n- LoadBalancer for external access (production)\n\n**Ingress**: HTTP/HTTPS routing\n- Path-based routing\n- Host-based routing\n- TLS termination\n- Load balancing\n\n## Deployment Strategies\n\n### Rolling Update\n\nDefault strategy, gradual replacement:\n\\`\\`\\`yaml\nstrategy:\n  type: RollingUpdate\n  rollingUpdate:\n    maxSurge: 1\n    maxUnavailable: 0\n\\`\\`\\`\n\n**When to use**: Standard deployments, minor updates\n\n### Recreate\n\nStop all pods, then create new ones:\n\\`\\`\\`yaml\nstrategy:\n  type: Recreate\n\\`\\`\\`\n\n**When to use**: Stateful apps that can't run multiple versions\n\n### Blue-Green\n\nRun two complete environments, switch traffic:\n1. Deploy new version (green)\n2. Test green environment\n3. Switch traffic to green\n4. Keep blue for quick rollback\n\n**When to use**: Critical services, need instant rollback\n\n### Canary\n\nGradually roll out to subset of users:\n1. Deploy canary version (10% traffic)\n2. Monitor metrics and errors\n3. Increase traffic gradually\n4. Complete rollout or rollback\n\n**When to use**: High-risk changes, want gradual validation\n\n## Resource Configuration\n\n### Resource Requests and Limits\n\nAlways set for production workloads:\n\\`\\`\\`yaml\nresources:\n  requests:\n    memory: \"256Mi\"\n    cpu: \"250m\"\n  limits:\n    memory: \"512Mi\"\n    cpu: \"500m\"\n\\`\\`\\`\n\n**Requests**: Guaranteed resources\n**Limits**: Maximum allowed resources\n\n### Health Checks\n\nEssential for reliability:\n\\`\\`\\`yaml\nlivenessProbe:\n  httpGet:\n    path: /health\n    port: 8080\n  initialDelaySeconds: 30\n  periodSeconds: 10\n\nreadinessProbe:\n  httpGet:\n    path: /ready\n    port: 8080\n  initialDelaySeconds: 5\n  periodSeconds: 5\n\\`\\`\\`\n\n**Liveness**: Restart unhealthy pods\n**Readiness**: Remove unready pods from service\n\n## Troubleshooting\n\n### Common Issues\n\n1. **Pods not starting**\n   - Check: `kubectl describe pod <name>`\n   - Look for: Image pull errors, resource constraints\n   - Fix: Verify image name, increase resources\n\n2. **Service not reachable**\n   - Check: `kubectl get svc`, `kubectl get endpoints`\n   - Look for: No endpoints, wrong selector\n   - Fix: Verify pod labels match service selector\n\n3. **High memory usage**\n   - Check: `kubectl top pods`\n   - Look for: Pods near memory limit\n   - Fix: Increase limits, optimize application\n\n4. **Frequent restarts**\n   - Check: `kubectl get pods`, `kubectl logs <name>`\n   - Look for: Liveness probe failures, OOMKilled\n   - Fix: Adjust health checks, increase memory\n\n### Debugging Commands\n\nGet pod details:\n\\`\\`\\`bash\nkubectl describe pod <name>\nkubectl logs <name>\nkubectl logs <name> --previous  # logs from crashed container\n\\`\\`\\`\n\nExecute commands in pod:\n\\`\\`\\`bash\nkubectl exec -it <name> -- /bin/sh\nkubectl exec <name> -- env\n\\`\\`\\`\n\nCheck resource usage:\n\\`\\`\\`bash\nkubectl top nodes\nkubectl top pods\n\\`\\`\\`\n\n## Security Best Practices\n\n### Pod Security\n\n- Run as non-root user\n- Use read-only root filesystem\n- Drop unnecessary capabilities\n- Use security contexts\n\nExample:\n\\`\\`\\`yaml\nsecurityContext:\n  runAsNonRoot: true\n  runAsUser: 1000\n  readOnlyRootFilesystem: true\n  capabilities:\n    drop:\n      - ALL\n\\`\\`\\`\n\n### Network Policies\n\nRestrict pod communication:\n\\`\\`\\`yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: api-allow\nspec:\n  podSelector:\n    matchLabels:\n      app: api\n  ingress:\n    - from:\n      - podSelector:\n          matchLabels:\n            app: frontend\n\\`\\`\\`\n\n### Secrets Management\n\n- Never commit secrets to git\n- Use external secret managers\n- Rotate secrets regularly\n- Limit secret access with RBAC\n\n## Performance Optimization\n\n### Resource Tuning\n\n1. **Start conservative**: Set low limits initially\n2. **Monitor usage**: Track actual resource consumption\n3. **Adjust gradually**: Increase based on metrics\n4. **Set appropriate requests**: Match typical usage\n5. **Set safe limits**: 2x requests for headroom\n\n### Horizontal Pod Autoscaling\n\nAutomatically scale based on metrics:\n\\`\\`\\`yaml\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: api-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: api\n  minReplicas: 2\n  maxReplicas: 10\n  metrics:\n    - type: Resource\n      resource:\n        name: cpu\n        target:\n          type: Utilization\n          averageUtilization: 70\n\\`\\`\\`\n\n## MCP Server Integration\n\nThis skill works with the kubernetes MCP server for operations:\n\n**List pods**:\n\\`\\`\\`javascript\nconst pods = await tools.k8s_list_pods({ namespace: 'default' })\n\\`\\`\\`\n\n**Get pod logs**:\n\\`\\`\\`javascript\nconst logs = await tools.k8s_get_logs({ pod: 'api-xyz', container: 'app' })\n\\`\\`\\`\n\n**Apply manifests**:\n\\`\\`\\`javascript\nconst result = await tools.k8s_apply_manifest({ file: 'deployment.yaml' })\n\\`\\`\\`\n\n## Detailed References\n\nFor in-depth information:\n- **Deployment patterns**: `references/deployment-patterns.md`\n- **Troubleshooting guide**: `references/troubleshooting.md`\n- **Security hardening**: `references/security.md`\n\n## Example Manifests\n\nFor copy-paste examples:\n- **Basic deployment**: `examples/basic-deployment.yaml`\n- **StatefulSet**: `examples/stateful-set.yaml`\n- **Ingress config**: `examples/ingress-config.yaml`\n\n## Validation Scripts\n\nFor manifest validation:\n\\`\\`\\`bash\nbash ${CLAUDE_PLUGIN_ROOT}/skills/kubernetes-ops/scripts/validate-manifest.sh deployment.yaml\n\\`\\`\\`\n```\n\n### hooks/hooks.json\n\n```json\n{\n  \"PreToolUse\": [\n    {\n      \"matcher\": \"Write|Edit\",\n      \"hooks\": [\n        {\n          \"type\": \"command\",\n          \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/hooks/scripts/security/scan-secrets.sh\",\n          \"timeout\": 30\n        }\n      ]\n    },\n    {\n      \"matcher\": \"Bash\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Evaluate if this bash command is safe for production environment. Check for destructive operations, missing safeguards, and potential security issues. Commands should be idempotent and reversible.\",\n          \"timeout\": 20\n        }\n      ]\n    }\n  ],\n  \"PostToolUse\": [\n    {\n      \"matcher\": \"Bash\",\n      \"hooks\": [\n        {\n          \"type\": \"command\",\n          \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/hooks/scripts/workflow/update-status.sh\",\n          \"timeout\": 15\n        }\n      ]\n    }\n  ],\n  \"Stop\": [\n    {\n      \"matcher\": \".*\",\n      \"hooks\": [\n        {\n          \"type\": \"command\",\n          \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/hooks/scripts/quality/check-config.sh\",\n          \"timeout\": 45\n        },\n        {\n          \"type\": \"command\",\n          \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/hooks/scripts/workflow/notify-team.sh\",\n          \"timeout\": 30\n        }\n      ]\n    }\n  ],\n  \"SessionStart\": [\n    {\n      \"matcher\": \".*\",\n      \"hooks\": [\n        {\n          \"type\": \"command\",\n          \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/hooks/scripts/security/validate-permissions.sh\",\n          \"timeout\": 20\n        }\n      ]\n    }\n  ]\n}\n```\n\n## Key Features\n\n### Multi-Level Organization\n\n**Commands**: Organized by function (CI, monitoring, admin)\n**Agents**: Separated by role (orchestration vs. specialized)\n**Skills**: Rich resources (references, examples, scripts)\n\n### MCP Integration\n\nThree custom MCP servers:\n- **Kubernetes**: Cluster operations\n- **Terraform**: Infrastructure provisioning\n- **GitHub Actions**: CI/CD automation\n\n### Shared Libraries\n\nReusable code in `lib/`:\n- **Core**: Common utilities (logging, config, auth)\n- **Integrations**: External services (Slack, Datadog)\n- **Utils**: Helper functions (retry, validation)\n\n### Configuration Management\n\nEnvironment-specific configs in `config/`:\n- **Environments**: Per-environment settings\n- **Templates**: Reusable deployment templates\n\n### Security Automation\n\nMultiple security hooks:\n- Secret scanning before writes\n- Permission validation on session start\n- Configuration auditing on completion\n\n### Monitoring Integration\n\nBuilt-in monitoring via lib integrations:\n- Datadog for metrics\n- PagerDuty for alerts\n- Slack for notifications\n\n## Use Cases\n\n1. **Multi-environment deployments**: Orchestrated rollouts across dev/staging/prod\n2. **Infrastructure as code**: Terraform automation with state management\n3. **CI/CD automation**: Build, test, deploy pipelines\n4. **Monitoring and observability**: Integrated metrics and alerting\n5. **Security enforcement**: Automated security scanning and validation\n6. **Team collaboration**: Slack notifications and status updates\n\n## When to Use This Pattern\n\n- Large-scale enterprise deployments\n- Multiple environment management\n- Complex CI/CD workflows\n- Integrated monitoring requirements\n- Security-critical infrastructure\n- Team collaboration needs\n\n## Scaling Considerations\n\n- **Performance**: Separate MCP servers for parallel operations\n- **Organization**: Multi-level directories for scalability\n- **Maintainability**: Shared libraries reduce duplication\n- **Flexibility**: Environment configs enable customization\n- **Security**: Layered security hooks and validation\n",
        "plugins/plugin-dev/skills/plugin-structure/examples/minimal-plugin.md": "# Minimal Plugin Example\n\nA bare-bones plugin with a single command.\n\n## Directory Structure\n\n```\nhello-world/\nâ”œâ”€â”€ .claude-plugin/\nâ”‚   â””â”€â”€ plugin.json\nâ””â”€â”€ commands/\n    â””â”€â”€ hello.md\n```\n\n## File Contents\n\n### .claude-plugin/plugin.json\n\n```json\n{\n  \"name\": \"hello-world\"\n}\n```\n\n### commands/hello.md\n\n```markdown\n---\nname: hello\ndescription: Prints a friendly greeting message\n---\n\n# Hello Command\n\nPrint a friendly greeting to the user.\n\n## Implementation\n\nOutput the following message to the user:\n\n> Hello! This is a simple command from the hello-world plugin.\n>\n> Use this as a starting point for building more complex plugins.\n\nInclude the current timestamp in the greeting to show the command executed successfully.\n```\n\n## Usage\n\nAfter installing the plugin:\n\n```\n$ claude\n> /hello\nHello! This is a simple command from the hello-world plugin.\n\nUse this as a starting point for building more complex plugins.\n\nExecuted at: 2025-01-15 14:30:22 UTC\n```\n\n## Key Points\n\n1. **Minimal manifest**: Only the required `name` field\n2. **Single command**: One markdown file in `commands/` directory\n3. **Auto-discovery**: Claude Code finds the command automatically\n4. **No dependencies**: No scripts, hooks, or external resources\n\n## When to Use This Pattern\n\n- Quick prototypes\n- Single-purpose utilities\n- Learning plugin development\n- Internal team tools with one specific function\n\n## Extending This Plugin\n\nTo add more functionality:\n\n1. **Add commands**: Create more `.md` files in `commands/`\n2. **Add metadata**: Update `plugin.json` with version, description, author\n3. **Add agents**: Create `agents/` directory with agent definitions\n4. **Add hooks**: Create `hooks/hooks.json` for event handling\n",
        "plugins/plugin-dev/skills/plugin-structure/examples/standard-plugin.md": "# Standard Plugin Example\n\nA well-structured plugin with commands, agents, and skills.\n\n## Directory Structure\n\n```\ncode-quality/\nâ”œâ”€â”€ .claude-plugin/\nâ”‚   â””â”€â”€ plugin.json\nâ”œâ”€â”€ commands/\nâ”‚   â”œâ”€â”€ lint.md\nâ”‚   â”œâ”€â”€ test.md\nâ”‚   â””â”€â”€ review.md\nâ”œâ”€â”€ agents/\nâ”‚   â”œâ”€â”€ code-reviewer.md\nâ”‚   â””â”€â”€ test-generator.md\nâ”œâ”€â”€ skills/\nâ”‚   â”œâ”€â”€ code-standards/\nâ”‚   â”‚   â”œâ”€â”€ SKILL.md\nâ”‚   â”‚   â””â”€â”€ references/\nâ”‚   â”‚       â””â”€â”€ style-guide.md\nâ”‚   â””â”€â”€ testing-patterns/\nâ”‚       â”œâ”€â”€ SKILL.md\nâ”‚       â””â”€â”€ examples/\nâ”‚           â”œâ”€â”€ unit-test.js\nâ”‚           â””â”€â”€ integration-test.js\nâ”œâ”€â”€ hooks/\nâ”‚   â”œâ”€â”€ hooks.json\nâ”‚   â””â”€â”€ scripts/\nâ”‚       â””â”€â”€ validate-commit.sh\nâ””â”€â”€ scripts/\n    â”œâ”€â”€ run-linter.sh\n    â””â”€â”€ generate-report.py\n```\n\n## File Contents\n\n### .claude-plugin/plugin.json\n\n```json\n{\n  \"name\": \"code-quality\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Comprehensive code quality tools including linting, testing, and review automation\",\n  \"author\": {\n    \"name\": \"Quality Team\",\n    \"email\": \"quality@example.com\"\n  },\n  \"homepage\": \"https://docs.example.com/plugins/code-quality\",\n  \"repository\": \"https://github.com/example/code-quality-plugin\",\n  \"license\": \"MIT\",\n  \"keywords\": [\"code-quality\", \"linting\", \"testing\", \"code-review\", \"automation\"]\n}\n```\n\n### commands/lint.md\n\n```markdown\n---\nname: lint\ndescription: Run linting checks on the codebase\n---\n\n# Lint Command\n\nRun comprehensive linting checks on the project codebase.\n\n## Process\n\n1. Detect project type and installed linters\n2. Run appropriate linters (ESLint, Pylint, RuboCop, etc.)\n3. Collect and format results\n4. Report issues with file locations and severity\n\n## Implementation\n\nExecute the linting script:\n\n\\`\\`\\`bash\nbash ${CLAUDE_PLUGIN_ROOT}/scripts/run-linter.sh\n\\`\\`\\`\n\nParse the output and present issues organized by:\n- Critical issues (must fix)\n- Warnings (should fix)\n- Style suggestions (optional)\n\nFor each issue, show:\n- File path and line number\n- Issue description\n- Suggested fix (if available)\n```\n\n### commands/test.md\n\n```markdown\n---\nname: test\ndescription: Run test suite with coverage reporting\n---\n\n# Test Command\n\nExecute the project test suite and generate coverage reports.\n\n## Process\n\n1. Identify test framework (Jest, pytest, RSpec, etc.)\n2. Run all tests\n3. Generate coverage report\n4. Identify untested code\n\n## Output\n\nPresent results in structured format:\n- Test summary (passed/failed/skipped)\n- Coverage percentage by file\n- Critical untested areas\n- Failed test details\n\n## Integration\n\nAfter test completion, offer to:\n- Fix failing tests\n- Generate tests for untested code (using test-generator agent)\n- Update documentation based on test changes\n```\n\n### agents/code-reviewer.md\n\n```markdown\n---\ndescription: Expert code reviewer specializing in identifying bugs, security issues, and improvement opportunities\ncapabilities:\n  - Analyze code for potential bugs and logic errors\n  - Identify security vulnerabilities\n  - Suggest performance improvements\n  - Ensure code follows project standards\n  - Review test coverage adequacy\n---\n\n# Code Reviewer Agent\n\nSpecialized agent for comprehensive code review.\n\n## Expertise\n\n- **Bug detection**: Logic errors, edge cases, error handling\n- **Security analysis**: Injection vulnerabilities, authentication issues, data exposure\n- **Performance**: Algorithm efficiency, resource usage, optimization opportunities\n- **Standards compliance**: Style guide adherence, naming conventions, documentation\n- **Test coverage**: Adequacy of test cases, missing scenarios\n\n## Review Process\n\n1. **Initial scan**: Quick pass for obvious issues\n2. **Deep analysis**: Line-by-line review of changed code\n3. **Context evaluation**: Check impact on related code\n4. **Best practices**: Compare against project and language standards\n5. **Recommendations**: Prioritized list of improvements\n\n## Integration with Skills\n\nAutomatically loads `code-standards` skill for project-specific guidelines.\n\n## Output Format\n\nFor each file reviewed:\n- Overall assessment\n- Critical issues (must fix before merge)\n- Important issues (should fix)\n- Suggestions (nice to have)\n- Positive feedback (what was done well)\n```\n\n### agents/test-generator.md\n\n```markdown\n---\ndescription: Generates comprehensive test suites from code analysis\ncapabilities:\n  - Analyze code structure and logic flow\n  - Generate unit tests for functions and methods\n  - Create integration tests for modules\n  - Design edge case and error condition tests\n  - Suggest test fixtures and mocks\n---\n\n# Test Generator Agent\n\nSpecialized agent for generating comprehensive test suites.\n\n## Expertise\n\n- **Unit testing**: Individual function/method tests\n- **Integration testing**: Module interaction tests\n- **Edge cases**: Boundary conditions, error paths\n- **Test organization**: Proper test structure and naming\n- **Mocking**: Appropriate use of mocks and stubs\n\n## Generation Process\n\n1. **Code analysis**: Understand function purpose and logic\n2. **Path identification**: Map all execution paths\n3. **Input design**: Create test inputs covering all paths\n4. **Assertion design**: Define expected outputs\n5. **Test generation**: Write tests in project's framework\n\n## Integration with Skills\n\nAutomatically loads `testing-patterns` skill for project-specific test conventions.\n\n## Test Quality\n\nGenerated tests include:\n- Happy path scenarios\n- Edge cases and boundary conditions\n- Error handling verification\n- Mock data for external dependencies\n- Clear test descriptions\n```\n\n### skills/code-standards/SKILL.md\n\n```markdown\n---\nname: Code Standards\ndescription: This skill should be used when reviewing code, enforcing style guidelines, checking naming conventions, or ensuring code quality standards. Provides project-specific coding standards and best practices.\nversion: 1.0.0\n---\n\n# Code Standards\n\nComprehensive coding standards and best practices for maintaining code quality.\n\n## Overview\n\nEnforce consistent code quality through standardized conventions for:\n- Code style and formatting\n- Naming conventions\n- Documentation requirements\n- Error handling patterns\n- Security practices\n\n## Style Guidelines\n\n### Formatting\n\n- **Indentation**: 2 spaces (JavaScript/TypeScript), 4 spaces (Python)\n- **Line length**: Maximum 100 characters\n- **Braces**: Same line for opening brace (K&R style)\n- **Whitespace**: Space after commas, around operators\n\n### Naming Conventions\n\n- **Variables**: camelCase for JavaScript, snake_case for Python\n- **Functions**: camelCase, descriptive verb-noun pairs\n- **Classes**: PascalCase\n- **Constants**: UPPER_SNAKE_CASE\n- **Files**: kebab-case for modules\n\n## Documentation Requirements\n\n### Function Documentation\n\nEvery function must include:\n- Purpose description\n- Parameter descriptions with types\n- Return value description with type\n- Example usage (for public functions)\n\n### Module Documentation\n\nEvery module must include:\n- Module purpose\n- Public API overview\n- Usage examples\n- Dependencies\n\n## Error Handling\n\n### Required Practices\n\n- Never swallow errors silently\n- Always log errors with context\n- Use specific error types\n- Provide actionable error messages\n- Clean up resources in finally blocks\n\n### Example Pattern\n\n\\`\\`\\`javascript\nasync function processData(data) {\n  try {\n    const result = await transform(data)\n    return result\n  } catch (error) {\n    logger.error('Data processing failed', {\n      data: sanitize(data),\n      error: error.message,\n      stack: error.stack\n    })\n    throw new DataProcessingError('Failed to process data', { cause: error })\n  }\n}\n\\`\\`\\`\n\n## Security Practices\n\n- Validate all external input\n- Sanitize data before output\n- Use parameterized queries\n- Never log sensitive information\n- Keep dependencies updated\n\n## Detailed Guidelines\n\nFor comprehensive style guides by language, see:\n- `references/style-guide.md`\n```\n\n### skills/code-standards/references/style-guide.md\n\n```markdown\n# Comprehensive Style Guide\n\nDetailed style guidelines for all supported languages.\n\n## JavaScript/TypeScript\n\n### Variable Declarations\n\nUse `const` by default, `let` when reassignment needed, never `var`:\n\n\\`\\`\\`javascript\n// Good\nconst MAX_RETRIES = 3\nlet currentTry = 0\n\n// Bad\nvar MAX_RETRIES = 3\n\\`\\`\\`\n\n### Function Declarations\n\nUse function expressions for consistency:\n\n\\`\\`\\`javascript\n// Good\nconst calculateTotal = (items) => {\n  return items.reduce((sum, item) => sum + item.price, 0)\n}\n\n// Bad (inconsistent style)\nfunction calculateTotal(items) {\n  return items.reduce((sum, item) => sum + item.price, 0)\n}\n\\`\\`\\`\n\n### Async/Await\n\nPrefer async/await over promise chains:\n\n\\`\\`\\`javascript\n// Good\nasync function fetchUserData(userId) {\n  const user = await db.getUser(userId)\n  const orders = await db.getOrders(user.id)\n  return { user, orders }\n}\n\n// Bad\nfunction fetchUserData(userId) {\n  return db.getUser(userId)\n    .then(user => db.getOrders(user.id)\n      .then(orders => ({ user, orders })))\n}\n\\`\\`\\`\n\n## Python\n\n### Import Organization\n\nOrder imports: standard library, third-party, local:\n\n\\`\\`\\`python\n# Good\nimport os\nimport sys\n\nimport numpy as np\nimport pandas as pd\n\nfrom app.models import User\nfrom app.utils import helper\n\n# Bad - mixed order\nfrom app.models import User\nimport numpy as np\nimport os\n\\`\\`\\`\n\n### Type Hints\n\nUse type hints for all function signatures:\n\n\\`\\`\\`python\n# Good\ndef calculate_average(numbers: list[float]) -> float:\n    return sum(numbers) / len(numbers)\n\n# Bad\ndef calculate_average(numbers):\n    return sum(numbers) / len(numbers)\n\\`\\`\\`\n\n## Additional Languages\n\nSee language-specific guides for:\n- Go: `references/go-style.md`\n- Rust: `references/rust-style.md`\n- Ruby: `references/ruby-style.md`\n```\n\n### hooks/hooks.json\n\n```json\n{\n  \"PreToolUse\": [\n    {\n      \"matcher\": \"Write|Edit\",\n      \"hooks\": [\n        {\n          \"type\": \"prompt\",\n          \"prompt\": \"Before modifying code, verify it meets our coding standards from the code-standards skill. Check formatting, naming conventions, and documentation. If standards aren't met, suggest improvements.\",\n          \"timeout\": 30\n        }\n      ]\n    }\n  ],\n  \"Stop\": [\n    {\n      \"matcher\": \".*\",\n      \"hooks\": [\n        {\n          \"type\": \"command\",\n          \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/hooks/scripts/validate-commit.sh\",\n          \"timeout\": 45\n        }\n      ]\n    }\n  ]\n}\n```\n\n### hooks/scripts/validate-commit.sh\n\n```bash\n#!/bin/bash\n# Validate code quality before task completion\n\nset -e\n\n# Check if there are any uncommitted changes\nif [[ -z $(git status -s) ]]; then\n  echo '{\"systemMessage\": \"No changes to validate. Task complete.\"}'\n  exit 0\nfi\n\n# Run linter on changed files\nCHANGED_FILES=$(git diff --name-only --cached | grep -E '\\.(js|ts|py)$' || true)\n\nif [[ -z \"$CHANGED_FILES\" ]]; then\n  echo '{\"systemMessage\": \"No code files changed. Validation passed.\"}'\n  exit 0\nfi\n\n# Run appropriate linters\nISSUES=0\n\nfor file in $CHANGED_FILES; do\n  case \"$file\" in\n    *.js|*.ts)\n      if ! npx eslint \"$file\" --quiet; then\n        ISSUES=$((ISSUES + 1))\n      fi\n      ;;\n    *.py)\n      if ! python -m pylint \"$file\" --errors-only; then\n        ISSUES=$((ISSUES + 1))\n      fi\n      ;;\n  esac\ndone\n\nif [[ $ISSUES -gt 0 ]]; then\n  echo \"{\\\"systemMessage\\\": \\\"Found $ISSUES code quality issues. Please fix before completing.\\\"}\"\n  exit 1\nfi\n\necho '{\"systemMessage\": \"Code quality checks passed. Ready to commit.\"}'\nexit 0\n```\n\n## Usage Examples\n\n### Running Commands\n\n```\n$ claude\n> /lint\nRunning linter checks...\n\nCritical Issues (2):\n  src/api/users.js:45 - SQL injection vulnerability\n  src/utils/helpers.js:12 - Unhandled promise rejection\n\nWarnings (5):\n  src/components/Button.tsx:23 - Missing PropTypes\n  ...\n\nStyle Suggestions (8):\n  src/index.js:1 - Use const instead of let\n  ...\n\n> /test\nRunning test suite...\n\nTest Results:\n  âœ“ 245 passed\n  âœ— 3 failed\n  â—‹ 2 skipped\n\nCoverage: 87.3%\n\nUntested Files:\n  src/utils/cache.js - 0% coverage\n  src/api/webhooks.js - 23% coverage\n\nFailed Tests:\n  1. User API â€º GET /users â€º should handle pagination\n     Expected 200, received 500\n  ...\n```\n\n### Using Agents\n\n```\n> Review the changes in src/api/users.js\n\n[code-reviewer agent selected automatically]\n\nCode Review: src/api/users.js\n\nCritical Issues:\n  1. Line 45: SQL injection vulnerability\n     - Using string concatenation for SQL query\n     - Replace with parameterized query\n     - Priority: CRITICAL\n\n  2. Line 67: Missing error handling\n     - Database query without try/catch\n     - Could crash server on DB error\n     - Priority: HIGH\n\nSuggestions:\n  1. Line 23: Consider caching user data\n     - Frequent DB queries for same users\n     - Add Redis caching layer\n     - Priority: MEDIUM\n```\n\n## Key Points\n\n1. **Complete manifest**: All recommended metadata fields\n2. **Multiple components**: Commands, agents, skills, hooks\n3. **Rich skills**: References and examples for detailed information\n4. **Automation**: Hooks enforce standards automatically\n5. **Integration**: Components work together cohesively\n\n## When to Use This Pattern\n\n- Production plugins for distribution\n- Team collaboration tools\n- Plugins requiring consistency enforcement\n- Complex workflows with multiple entry points\n",
        "plugins/plugin-dev/skills/plugin-structure/references/component-patterns.md": "# Component Organization Patterns\n\nAdvanced patterns for organizing plugin components effectively.\n\n## Component Lifecycle\n\n### Discovery Phase\n\nWhen Claude Code starts:\n\n1. **Scan enabled plugins**: Read `.claude-plugin/plugin.json` for each\n2. **Discover components**: Look in default and custom paths\n3. **Parse definitions**: Read YAML frontmatter and configurations\n4. **Register components**: Make available to Claude Code\n5. **Initialize**: Start MCP servers, register hooks\n\n**Timing**: Component registration happens during Claude Code initialization, not continuously.\n\n### Activation Phase\n\nWhen components are used:\n\n**Commands**: User types slash command â†’ Claude Code looks up â†’ Executes\n**Agents**: Task arrives â†’ Claude Code evaluates capabilities â†’ Selects agent\n**Skills**: Task context matches description â†’ Claude Code loads skill\n**Hooks**: Event occurs â†’ Claude Code calls matching hooks\n**MCP Servers**: Tool call matches server capability â†’ Forwards to server\n\n## Command Organization Patterns\n\n### Flat Structure\n\nSingle directory with all commands:\n\n```\ncommands/\nâ”œâ”€â”€ build.md\nâ”œâ”€â”€ test.md\nâ”œâ”€â”€ deploy.md\nâ”œâ”€â”€ review.md\nâ””â”€â”€ docs.md\n```\n\n**When to use**:\n- 5-15 commands total\n- All commands at same abstraction level\n- No clear categorization\n\n**Advantages**:\n- Simple, easy to navigate\n- No configuration needed\n- Fast discovery\n\n### Categorized Structure\n\nMultiple directories for different command types:\n\n```\ncommands/              # Core commands\nâ”œâ”€â”€ build.md\nâ””â”€â”€ test.md\n\nadmin-commands/        # Administrative\nâ”œâ”€â”€ configure.md\nâ””â”€â”€ manage.md\n\nworkflow-commands/     # Workflow automation\nâ”œâ”€â”€ review.md\nâ””â”€â”€ deploy.md\n```\n\n**Manifest configuration**:\n```json\n{\n  \"commands\": [\n    \"./commands\",\n    \"./admin-commands\",\n    \"./workflow-commands\"\n  ]\n}\n```\n\n**When to use**:\n- 15+ commands\n- Clear functional categories\n- Different permission levels\n\n**Advantages**:\n- Organized by purpose\n- Easier to maintain\n- Can restrict access by directory\n\n### Hierarchical Structure\n\nNested organization for complex plugins:\n\n```\ncommands/\nâ”œâ”€â”€ ci/\nâ”‚   â”œâ”€â”€ build.md\nâ”‚   â”œâ”€â”€ test.md\nâ”‚   â””â”€â”€ lint.md\nâ”œâ”€â”€ deployment/\nâ”‚   â”œâ”€â”€ staging.md\nâ”‚   â””â”€â”€ production.md\nâ””â”€â”€ management/\n    â”œâ”€â”€ config.md\n    â””â”€â”€ status.md\n```\n\n**Note**: Claude Code doesn't support nested command discovery automatically. Use custom paths:\n\n```json\n{\n  \"commands\": [\n    \"./commands/ci\",\n    \"./commands/deployment\",\n    \"./commands/management\"\n  ]\n}\n```\n\n**When to use**:\n- 20+ commands\n- Multi-level categorization\n- Complex workflows\n\n**Advantages**:\n- Maximum organization\n- Clear boundaries\n- Scalable structure\n\n## Agent Organization Patterns\n\n### Role-Based Organization\n\nOrganize agents by their primary role:\n\n```\nagents/\nâ”œâ”€â”€ code-reviewer.md        # Reviews code\nâ”œâ”€â”€ test-generator.md       # Generates tests\nâ”œâ”€â”€ documentation-writer.md # Writes docs\nâ””â”€â”€ refactorer.md          # Refactors code\n```\n\n**When to use**:\n- Agents have distinct, non-overlapping roles\n- Users invoke agents manually\n- Clear agent responsibilities\n\n### Capability-Based Organization\n\nOrganize by specific capabilities:\n\n```\nagents/\nâ”œâ”€â”€ python-expert.md        # Python-specific\nâ”œâ”€â”€ typescript-expert.md    # TypeScript-specific\nâ”œâ”€â”€ api-specialist.md       # API design\nâ””â”€â”€ database-specialist.md  # Database work\n```\n\n**When to use**:\n- Technology-specific agents\n- Domain expertise focus\n- Automatic agent selection\n\n### Workflow-Based Organization\n\nOrganize by workflow stage:\n\n```\nagents/\nâ”œâ”€â”€ planning-agent.md      # Planning phase\nâ”œâ”€â”€ implementation-agent.md # Coding phase\nâ”œâ”€â”€ testing-agent.md       # Testing phase\nâ””â”€â”€ deployment-agent.md    # Deployment phase\n```\n\n**When to use**:\n- Sequential workflows\n- Stage-specific expertise\n- Pipeline automation\n\n## Skill Organization Patterns\n\n### Topic-Based Organization\n\nEach skill covers a specific topic:\n\n```\nskills/\nâ”œâ”€â”€ api-design/\nâ”‚   â””â”€â”€ SKILL.md\nâ”œâ”€â”€ error-handling/\nâ”‚   â””â”€â”€ SKILL.md\nâ”œâ”€â”€ testing-strategies/\nâ”‚   â””â”€â”€ SKILL.md\nâ””â”€â”€ performance-optimization/\n    â””â”€â”€ SKILL.md\n```\n\n**When to use**:\n- Knowledge-based skills\n- Educational or reference content\n- Broad applicability\n\n### Tool-Based Organization\n\nSkills for specific tools or technologies:\n\n```\nskills/\nâ”œâ”€â”€ docker/\nâ”‚   â”œâ”€â”€ SKILL.md\nâ”‚   â””â”€â”€ references/\nâ”‚       â””â”€â”€ dockerfile-best-practices.md\nâ”œâ”€â”€ kubernetes/\nâ”‚   â”œâ”€â”€ SKILL.md\nâ”‚   â””â”€â”€ examples/\nâ”‚       â””â”€â”€ deployment.yaml\nâ””â”€â”€ terraform/\n    â”œâ”€â”€ SKILL.md\n    â””â”€â”€ scripts/\n        â””â”€â”€ validate-config.sh\n```\n\n**When to use**:\n- Tool-specific expertise\n- Complex tool configurations\n- Tool best practices\n\n### Workflow-Based Organization\n\nSkills for complete workflows:\n\n```\nskills/\nâ”œâ”€â”€ code-review-workflow/\nâ”‚   â”œâ”€â”€ SKILL.md\nâ”‚   â””â”€â”€ references/\nâ”‚       â”œâ”€â”€ checklist.md\nâ”‚       â””â”€â”€ standards.md\nâ”œâ”€â”€ deployment-workflow/\nâ”‚   â”œâ”€â”€ SKILL.md\nâ”‚   â””â”€â”€ scripts/\nâ”‚       â”œâ”€â”€ pre-deploy.sh\nâ”‚       â””â”€â”€ post-deploy.sh\nâ””â”€â”€ testing-workflow/\n    â”œâ”€â”€ SKILL.md\n    â””â”€â”€ examples/\n        â””â”€â”€ test-structure.md\n```\n\n**When to use**:\n- Multi-step processes\n- Company-specific workflows\n- Process automation\n\n### Skill with Rich Resources\n\nComprehensive skill with all resource types:\n\n```\nskills/\nâ””â”€â”€ api-testing/\n    â”œâ”€â”€ SKILL.md              # Core skill (1500 words)\n    â”œâ”€â”€ references/\n    â”‚   â”œâ”€â”€ rest-api-guide.md\n    â”‚   â”œâ”€â”€ graphql-guide.md\n    â”‚   â””â”€â”€ authentication.md\n    â”œâ”€â”€ examples/\n    â”‚   â”œâ”€â”€ basic-test.js\n    â”‚   â”œâ”€â”€ authenticated-test.js\n    â”‚   â””â”€â”€ integration-test.js\n    â”œâ”€â”€ scripts/\n    â”‚   â”œâ”€â”€ run-tests.sh\n    â”‚   â””â”€â”€ generate-report.py\n    â””â”€â”€ assets/\n        â””â”€â”€ test-template.json\n```\n\n**Resource usage**:\n- **SKILL.md**: Overview and when to use resources\n- **references/**: Detailed guides (loaded as needed)\n- **examples/**: Copy-paste code samples\n- **scripts/**: Executable test runners\n- **assets/**: Templates and configurations\n\n## Hook Organization Patterns\n\n### Monolithic Configuration\n\nSingle hooks.json with all hooks:\n\n```\nhooks/\nâ”œâ”€â”€ hooks.json     # All hook definitions\nâ””â”€â”€ scripts/\n    â”œâ”€â”€ validate-write.sh\n    â”œâ”€â”€ validate-bash.sh\n    â””â”€â”€ load-context.sh\n```\n\n**hooks.json**:\n```json\n{\n  \"PreToolUse\": [...],\n  \"PostToolUse\": [...],\n  \"Stop\": [...],\n  \"SessionStart\": [...]\n}\n```\n\n**When to use**:\n- 5-10 hooks total\n- Simple hook logic\n- Centralized configuration\n\n### Event-Based Organization\n\nSeparate files per event type:\n\n```\nhooks/\nâ”œâ”€â”€ hooks.json              # Combines all\nâ”œâ”€â”€ pre-tool-use.json      # PreToolUse hooks\nâ”œâ”€â”€ post-tool-use.json     # PostToolUse hooks\nâ”œâ”€â”€ stop.json              # Stop hooks\nâ””â”€â”€ scripts/\n    â”œâ”€â”€ validate/\n    â”‚   â”œâ”€â”€ write.sh\n    â”‚   â””â”€â”€ bash.sh\n    â””â”€â”€ context/\n        â””â”€â”€ load.sh\n```\n\n**hooks.json** (combines):\n```json\n{\n  \"PreToolUse\": ${file:./pre-tool-use.json},\n  \"PostToolUse\": ${file:./post-tool-use.json},\n  \"Stop\": ${file:./stop.json}\n}\n```\n\n**Note**: Use build script to combine files, Claude Code doesn't support file references.\n\n**When to use**:\n- 10+ hooks\n- Different teams managing different events\n- Complex hook configurations\n\n### Purpose-Based Organization\n\nGroup by functional purpose:\n\n```\nhooks/\nâ”œâ”€â”€ hooks.json\nâ””â”€â”€ scripts/\n    â”œâ”€â”€ security/\n    â”‚   â”œâ”€â”€ validate-paths.sh\n    â”‚   â”œâ”€â”€ check-credentials.sh\n    â”‚   â””â”€â”€ scan-malware.sh\n    â”œâ”€â”€ quality/\n    â”‚   â”œâ”€â”€ lint-code.sh\n    â”‚   â”œâ”€â”€ check-tests.sh\n    â”‚   â””â”€â”€ verify-docs.sh\n    â””â”€â”€ workflow/\n        â”œâ”€â”€ notify-team.sh\n        â””â”€â”€ update-status.sh\n```\n\n**When to use**:\n- Many hook scripts\n- Clear functional boundaries\n- Team specialization\n\n## Script Organization Patterns\n\n### Flat Scripts\n\nAll scripts in single directory:\n\n```\nscripts/\nâ”œâ”€â”€ build.sh\nâ”œâ”€â”€ test.py\nâ”œâ”€â”€ deploy.sh\nâ”œâ”€â”€ validate.js\nâ””â”€â”€ report.py\n```\n\n**When to use**:\n- 5-10 scripts\n- All scripts related\n- Simple plugin\n\n### Categorized Scripts\n\nGroup by purpose:\n\n```\nscripts/\nâ”œâ”€â”€ build/\nâ”‚   â”œâ”€â”€ compile.sh\nâ”‚   â””â”€â”€ package.sh\nâ”œâ”€â”€ test/\nâ”‚   â”œâ”€â”€ run-unit.sh\nâ”‚   â””â”€â”€ run-integration.sh\nâ”œâ”€â”€ deploy/\nâ”‚   â”œâ”€â”€ staging.sh\nâ”‚   â””â”€â”€ production.sh\nâ””â”€â”€ utils/\n    â”œâ”€â”€ log.sh\n    â””â”€â”€ notify.sh\n```\n\n**When to use**:\n- 10+ scripts\n- Clear categories\n- Reusable utilities\n\n### Language-Based Organization\n\nGroup by programming language:\n\n```\nscripts/\nâ”œâ”€â”€ bash/\nâ”‚   â”œâ”€â”€ build.sh\nâ”‚   â””â”€â”€ deploy.sh\nâ”œâ”€â”€ python/\nâ”‚   â”œâ”€â”€ analyze.py\nâ”‚   â””â”€â”€ report.py\nâ””â”€â”€ javascript/\n    â”œâ”€â”€ bundle.js\n    â””â”€â”€ optimize.js\n```\n\n**When to use**:\n- Multi-language scripts\n- Different runtime requirements\n- Language-specific dependencies\n\n## Cross-Component Patterns\n\n### Shared Resources\n\nComponents sharing common resources:\n\n```\nplugin/\nâ”œâ”€â”€ commands/\nâ”‚   â”œâ”€â”€ test.md        # Uses lib/test-utils.sh\nâ”‚   â””â”€â”€ deploy.md      # Uses lib/deploy-utils.sh\nâ”œâ”€â”€ agents/\nâ”‚   â””â”€â”€ tester.md      # References lib/test-utils.sh\nâ”œâ”€â”€ hooks/\nâ”‚   â””â”€â”€ scripts/\nâ”‚       â””â”€â”€ pre-test.sh # Sources lib/test-utils.sh\nâ””â”€â”€ lib/\n    â”œâ”€â”€ test-utils.sh\n    â””â”€â”€ deploy-utils.sh\n```\n\n**Usage in components**:\n```bash\n#!/bin/bash\nsource \"${CLAUDE_PLUGIN_ROOT}/lib/test-utils.sh\"\nrun_tests\n```\n\n**Benefits**:\n- Code reuse\n- Consistent behavior\n- Easier maintenance\n\n### Layered Architecture\n\nSeparate concerns into layers:\n\n```\nplugin/\nâ”œâ”€â”€ commands/          # User interface layer\nâ”œâ”€â”€ agents/            # Orchestration layer\nâ”œâ”€â”€ skills/            # Knowledge layer\nâ””â”€â”€ lib/\n    â”œâ”€â”€ core/         # Core business logic\n    â”œâ”€â”€ integrations/ # External services\n    â””â”€â”€ utils/        # Helper functions\n```\n\n**When to use**:\n- Large plugins (100+ files)\n- Multiple developers\n- Clear separation of concerns\n\n### Plugin Within Plugin\n\nNested plugin structure:\n\n```\nplugin/\nâ”œâ”€â”€ .claude-plugin/\nâ”‚   â””â”€â”€ plugin.json\nâ”œâ”€â”€ core/              # Core functionality\nâ”‚   â”œâ”€â”€ commands/\nâ”‚   â””â”€â”€ agents/\nâ””â”€â”€ extensions/        # Optional extensions\n    â”œâ”€â”€ extension-a/\n    â”‚   â”œâ”€â”€ commands/\n    â”‚   â””â”€â”€ agents/\n    â””â”€â”€ extension-b/\n        â”œâ”€â”€ commands/\n        â””â”€â”€ agents/\n```\n\n**Manifest**:\n```json\n{\n  \"commands\": [\n    \"./core/commands\",\n    \"./extensions/extension-a/commands\",\n    \"./extensions/extension-b/commands\"\n  ]\n}\n```\n\n**When to use**:\n- Modular functionality\n- Optional features\n- Plugin families\n\n## Best Practices\n\n### Naming\n\n1. **Consistent naming**: Match file names to component purpose\n2. **Descriptive names**: Indicate what component does\n3. **Avoid abbreviations**: Use full words for clarity\n\n### Organization\n\n1. **Start simple**: Use flat structure, reorganize when needed\n2. **Group related items**: Keep related components together\n3. **Separate concerns**: Don't mix unrelated functionality\n\n### Scalability\n\n1. **Plan for growth**: Choose structure that scales\n2. **Refactor early**: Reorganize before it becomes painful\n3. **Document structure**: Explain organization in README\n\n### Maintainability\n\n1. **Consistent patterns**: Use same structure throughout\n2. **Minimize nesting**: Keep directory depth manageable\n3. **Use conventions**: Follow community standards\n\n### Performance\n\n1. **Avoid deep nesting**: Impacts discovery time\n2. **Minimize custom paths**: Use defaults when possible\n3. **Keep configurations small**: Large configs slow loading\n",
        "plugins/plugin-dev/skills/plugin-structure/references/manifest-reference.md": "# Plugin Manifest Reference\n\nComplete reference for `plugin.json` configuration.\n\n## File Location\n\n**Required path**: `.claude-plugin/plugin.json`\n\nThe manifest MUST be in the `.claude-plugin/` directory at the plugin root. Claude Code will not recognize plugins without this file in the correct location.\n\n## Complete Field Reference\n\n### Core Fields\n\n#### name (required)\n\n**Type**: String\n**Format**: kebab-case\n**Example**: `\"test-automation-suite\"`\n\nThe unique identifier for the plugin. Used for:\n- Plugin identification in Claude Code\n- Conflict detection with other plugins\n- Command namespacing (optional)\n\n**Requirements**:\n- Must be unique across all installed plugins\n- Use only lowercase letters, numbers, and hyphens\n- No spaces or special characters\n- Start with a letter\n- End with a letter or number\n\n**Validation**:\n```javascript\n/^[a-z][a-z0-9]*(-[a-z0-9]+)*$/\n```\n\n**Examples**:\n- âœ… Good: `api-tester`, `code-review`, `git-workflow-automation`\n- âŒ Bad: `API Tester`, `code_review`, `-git-workflow`, `test-`\n\n#### version\n\n**Type**: String\n**Format**: Semantic versioning (MAJOR.MINOR.PATCH)\n**Example**: `\"2.1.0\"`\n**Default**: `\"0.1.0\"` if not specified\n\nSemantic versioning guidelines:\n- **MAJOR**: Incompatible API changes, breaking changes\n- **MINOR**: New functionality, backward-compatible\n- **PATCH**: Bug fixes, backward-compatible\n\n**Pre-release versions**:\n- `\"1.0.0-alpha.1\"` - Alpha release\n- `\"1.0.0-beta.2\"` - Beta release\n- `\"1.0.0-rc.1\"` - Release candidate\n\n**Examples**:\n- `\"0.1.0\"` - Initial development\n- `\"1.0.0\"` - First stable release\n- `\"1.2.3\"` - Patch update to 1.2\n- `\"2.0.0\"` - Major version with breaking changes\n\n#### description\n\n**Type**: String\n**Length**: 50-200 characters recommended\n**Example**: `\"Automates code review workflows with style checks and automated feedback\"`\n\nBrief explanation of plugin purpose and functionality.\n\n**Best practices**:\n- Focus on what the plugin does, not how\n- Use active voice\n- Mention key features or benefits\n- Keep under 200 characters for marketplace display\n\n**Examples**:\n- âœ… \"Generates comprehensive test suites from code analysis and coverage reports\"\n- âœ… \"Integrates with Jira for automatic issue tracking and sprint management\"\n- âŒ \"A plugin that helps you do testing stuff\"\n- âŒ \"This is a very long description that goes on and on about every single feature...\"\n\n### Metadata Fields\n\n#### author\n\n**Type**: Object\n**Fields**: name (required), email (optional), url (optional)\n\n```json\n{\n  \"author\": {\n    \"name\": \"Jane Developer\",\n    \"email\": \"jane@example.com\",\n    \"url\": \"https://janedeveloper.com\"\n  }\n}\n```\n\n**Alternative format** (string only):\n```json\n{\n  \"author\": \"Jane Developer <jane@example.com> (https://janedeveloper.com)\"\n}\n```\n\n**Use cases**:\n- Credit and attribution\n- Contact for support or questions\n- Marketplace display\n- Community recognition\n\n#### homepage\n\n**Type**: String (URL)\n**Example**: `\"https://docs.example.com/plugins/my-plugin\"`\n\nLink to plugin documentation or landing page.\n\n**Should point to**:\n- Plugin documentation site\n- Project homepage\n- Detailed usage guide\n- Installation instructions\n\n**Not for**:\n- Source code (use `repository` field)\n- Issue tracker (include in documentation)\n- Personal websites (use `author.url`)\n\n#### repository\n\n**Type**: String (URL) or Object\n**Example**: `\"https://github.com/user/plugin-name\"`\n\nSource code repository location.\n\n**String format**:\n```json\n{\n  \"repository\": \"https://github.com/user/plugin-name\"\n}\n```\n\n**Object format** (detailed):\n```json\n{\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"https://github.com/user/plugin-name.git\",\n    \"directory\": \"packages/plugin-name\"\n  }\n}\n```\n\n**Use cases**:\n- Source code access\n- Issue reporting\n- Community contributions\n- Transparency and trust\n\n#### license\n\n**Type**: String\n**Format**: SPDX identifier\n**Example**: `\"MIT\"`\n\nSoftware license identifier.\n\n**Common licenses**:\n- `\"MIT\"` - Permissive, popular choice\n- `\"Apache-2.0\"` - Permissive with patent grant\n- `\"GPL-3.0\"` - Copyleft\n- `\"BSD-3-Clause\"` - Permissive\n- `\"ISC\"` - Permissive, similar to MIT\n- `\"UNLICENSED\"` - Proprietary, not open source\n\n**Full list**: https://spdx.org/licenses/\n\n**Multiple licenses**:\n```json\n{\n  \"license\": \"(MIT OR Apache-2.0)\"\n}\n```\n\n#### keywords\n\n**Type**: Array of strings\n**Example**: `[\"testing\", \"automation\", \"ci-cd\", \"quality-assurance\"]`\n\nTags for plugin discovery and categorization.\n\n**Best practices**:\n- Use 5-10 keywords\n- Include functionality categories\n- Add technology names\n- Use common search terms\n- Avoid duplicating plugin name\n\n**Categories to consider**:\n- Functionality: `testing`, `debugging`, `documentation`, `deployment`\n- Technologies: `typescript`, `python`, `docker`, `aws`\n- Workflows: `ci-cd`, `code-review`, `git-workflow`\n- Domains: `web-development`, `data-science`, `devops`\n\n### Component Path Fields\n\n#### commands\n\n**Type**: String or Array of strings\n**Default**: `[\"./commands\"]`\n**Example**: `\"./cli-commands\"`\n\nAdditional directories or files containing command definitions.\n\n**Single path**:\n```json\n{\n  \"commands\": \"./custom-commands\"\n}\n```\n\n**Multiple paths**:\n```json\n{\n  \"commands\": [\n    \"./commands\",\n    \"./admin-commands\",\n    \"./experimental-commands\"\n  ]\n}\n```\n\n**Behavior**: Supplements default `commands/` directory (does not replace)\n\n**Use cases**:\n- Organizing commands by category\n- Separating stable from experimental commands\n- Loading commands from shared locations\n\n#### agents\n\n**Type**: String or Array of strings\n**Default**: `[\"./agents\"]`\n**Example**: `\"./specialized-agents\"`\n\nAdditional directories or files containing agent definitions.\n\n**Format**: Same as `commands` field\n\n**Use cases**:\n- Grouping agents by specialization\n- Separating general-purpose from task-specific agents\n- Loading agents from plugin dependencies\n\n#### hooks\n\n**Type**: String (path to JSON file) or Object (inline configuration)\n**Default**: `\"./hooks/hooks.json\"`\n\nHook configuration location or inline definition.\n\n**File path**:\n```json\n{\n  \"hooks\": \"./config/hooks.json\"\n}\n```\n\n**Inline configuration**:\n```json\n{\n  \"hooks\": {\n    \"PreToolUse\": [\n      {\n        \"matcher\": \"Write\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/scripts/validate.sh\",\n            \"timeout\": 30\n          }\n        ]\n      }\n    ]\n  }\n}\n```\n\n**Use cases**:\n- Simple plugins: Inline configuration (< 50 lines)\n- Complex plugins: External JSON file\n- Multiple hook sets: Separate files for different contexts\n\n#### mcpServers\n\n**Type**: String (path to JSON file) or Object (inline configuration)\n**Default**: `./.mcp.json`\n\nMCP server configuration location or inline definition.\n\n**File path**:\n```json\n{\n  \"mcpServers\": \"./.mcp.json\"\n}\n```\n\n**Inline configuration**:\n```json\n{\n  \"mcpServers\": {\n    \"github\": {\n      \"command\": \"node\",\n      \"args\": [\"${CLAUDE_PLUGIN_ROOT}/servers/github-mcp.js\"],\n      \"env\": {\n        \"GITHUB_TOKEN\": \"${GITHUB_TOKEN}\"\n      }\n    }\n  }\n}\n```\n\n**Use cases**:\n- Simple plugins: Single inline server (< 20 lines)\n- Complex plugins: External `.mcp.json` file\n- Multiple servers: Always use external file\n\n## Path Resolution\n\n### Relative Path Rules\n\nAll paths in component fields must follow these rules:\n\n1. **Must be relative**: No absolute paths\n2. **Must start with `./`**: Indicates relative to plugin root\n3. **Cannot use `../`**: No parent directory navigation\n4. **Forward slashes only**: Even on Windows\n\n**Examples**:\n- âœ… `\"./commands\"`\n- âœ… `\"./src/commands\"`\n- âœ… `\"./configs/hooks.json\"`\n- âŒ `\"/Users/name/plugin/commands\"`\n- âŒ `\"commands\"` (missing `./`)\n- âŒ `\"../shared/commands\"`\n- âŒ `\".\\\\commands\"` (backslash)\n\n### Resolution Order\n\nWhen Claude Code loads components:\n\n1. **Default directories**: Scans standard locations first\n   - `./commands/`\n   - `./agents/`\n   - `./skills/`\n   - `./hooks/hooks.json`\n   - `./.mcp.json`\n\n2. **Custom paths**: Scans paths specified in manifest\n   - Paths from `commands` field\n   - Paths from `agents` field\n   - Files from `hooks` and `mcpServers` fields\n\n3. **Merge behavior**: Components from all locations load\n   - No overwriting\n   - All discovered components register\n   - Name conflicts cause errors\n\n## Validation\n\n### Manifest Validation\n\nClaude Code validates the manifest on plugin load:\n\n**Syntax validation**:\n- Valid JSON format\n- No syntax errors\n- Correct field types\n\n**Field validation**:\n- `name` field present and valid format\n- `version` follows semantic versioning (if present)\n- Paths are relative with `./` prefix\n- URLs are valid (if present)\n\n**Component validation**:\n- Referenced paths exist\n- Hook and MCP configurations are valid\n- No circular dependencies\n\n### Common Validation Errors\n\n**Invalid name format**:\n```json\n{\n  \"name\": \"My Plugin\"  // âŒ Contains spaces\n}\n```\nFix: Use kebab-case\n```json\n{\n  \"name\": \"my-plugin\"  // âœ…\n}\n```\n\n**Absolute path**:\n```json\n{\n  \"commands\": \"/Users/name/commands\"  // âŒ Absolute path\n}\n```\nFix: Use relative path\n```json\n{\n  \"commands\": \"./commands\"  // âœ…\n}\n```\n\n**Missing ./ prefix**:\n```json\n{\n  \"hooks\": \"hooks/hooks.json\"  // âŒ No ./\n}\n```\nFix: Add ./ prefix\n```json\n{\n  \"hooks\": \"./hooks/hooks.json\"  // âœ…\n}\n```\n\n**Invalid version**:\n```json\n{\n  \"version\": \"1.0\"  // âŒ Not semantic versioning\n}\n```\nFix: Use MAJOR.MINOR.PATCH\n```json\n{\n  \"version\": \"1.0.0\"  // âœ…\n}\n```\n\n## Minimal vs. Complete Examples\n\n### Minimal Plugin\n\nBare minimum for a working plugin:\n\n```json\n{\n  \"name\": \"hello-world\"\n}\n```\n\nRelies entirely on default directory discovery.\n\n### Recommended Plugin\n\nGood metadata for distribution:\n\n```json\n{\n  \"name\": \"code-review-assistant\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Automates code review with style checks and suggestions\",\n  \"author\": {\n    \"name\": \"Jane Developer\",\n    \"email\": \"jane@example.com\"\n  },\n  \"homepage\": \"https://docs.example.com/code-review\",\n  \"repository\": \"https://github.com/janedev/code-review-assistant\",\n  \"license\": \"MIT\",\n  \"keywords\": [\"code-review\", \"automation\", \"quality\", \"ci-cd\"]\n}\n```\n\n### Complete Plugin\n\nFull configuration with all features:\n\n```json\n{\n  \"name\": \"enterprise-devops\",\n  \"version\": \"2.3.1\",\n  \"description\": \"Comprehensive DevOps automation for enterprise CI/CD pipelines\",\n  \"author\": {\n    \"name\": \"DevOps Team\",\n    \"email\": \"devops@company.com\",\n    \"url\": \"https://company.com/devops\"\n  },\n  \"homepage\": \"https://docs.company.com/plugins/devops\",\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"https://github.com/company/devops-plugin.git\"\n  },\n  \"license\": \"Apache-2.0\",\n  \"keywords\": [\n    \"devops\",\n    \"ci-cd\",\n    \"automation\",\n    \"kubernetes\",\n    \"docker\",\n    \"deployment\"\n  ],\n  \"commands\": [\n    \"./commands\",\n    \"./admin-commands\"\n  ],\n  \"agents\": \"./specialized-agents\",\n  \"hooks\": \"./config/hooks.json\",\n  \"mcpServers\": \"./.mcp.json\"\n}\n```\n\n## Best Practices\n\n### Metadata\n\n1. **Always include version**: Track changes and updates\n2. **Write clear descriptions**: Help users understand plugin purpose\n3. **Provide contact information**: Enable user support\n4. **Link to documentation**: Reduce support burden\n5. **Choose appropriate license**: Match project goals\n\n### Paths\n\n1. **Use defaults when possible**: Minimize configuration\n2. **Organize logically**: Group related components\n3. **Document custom paths**: Explain why non-standard layout used\n4. **Test path resolution**: Verify on multiple systems\n\n### Maintenance\n\n1. **Bump version on changes**: Follow semantic versioning\n2. **Update keywords**: Reflect new functionality\n3. **Keep description current**: Match actual capabilities\n4. **Maintain changelog**: Track version history\n5. **Update repository links**: Keep URLs current\n\n### Distribution\n\n1. **Complete metadata before publishing**: All fields filled\n2. **Test on clean install**: Verify plugin works without dev environment\n3. **Validate manifest**: Use validation tools\n4. **Include README**: Document installation and usage\n5. **Specify license file**: Include LICENSE file in plugin root\n",
        "plugins/plugin-dev/skills/skill-development/SKILL.md": "---\nname: skill-development\ndescription: This skill should be used when the user wants to \"create a skill\", \"add a skill to plugin\", \"write a new skill\", \"improve skill description\", \"organize skill content\", or needs guidance on skill structure, progressive disclosure, or skill development best practices for Claude Code plugins.\n---\n\n# Skill Development for Claude Code Plugins\n\nThis skill provides guidance for creating effective skills for Claude Code plugins.\n\n## About Skills\n\nSkills are modular, self-contained packages that extend Claude's capabilities by providing\nspecialized knowledge, workflows, and tools. Think of them as \"onboarding guides\" for specific\ndomains or tasksâ€”they transform Claude from a general-purpose agent into a specialized agent\nequipped with procedural knowledge that no model can fully possess.\n\n### What Skills Provide\n\n1. Specialized workflows - Multi-step procedures for specific domains\n2. Tool integrations - Instructions for working with specific file formats or APIs\n3. Domain expertise - Company-specific knowledge, schemas, business logic\n4. Bundled resources - Scripts, references, and assets for complex and repetitive tasks\n\n### Anatomy of a Skill\n\nEvery skill consists of a required SKILL.md file and optional bundled resources:\n\n```\nskill-name/\nâ”œâ”€â”€ SKILL.md (required)\nâ”‚   â”œâ”€â”€ YAML frontmatter metadata (required)\nâ”‚   â”‚   â”œâ”€â”€ name: (required)\nâ”‚   â”‚   â””â”€â”€ description: (required)\nâ”‚   â””â”€â”€ Markdown instructions (required)\nâ””â”€â”€ Bundled Resources (optional)\n    â”œâ”€â”€ scripts/          - Executable code (Python/Bash/etc.)\n    â”œâ”€â”€ references/       - Documentation intended to be loaded into context as needed\n    â””â”€â”€ assets/           - Files used in output (templates, icons, fonts, etc.)\n```\n\n#### SKILL.md (required)\n\n**Metadata Quality:** The `name` and `description` in YAML frontmatter determine when Claude will use the skill. Be specific about what the skill does and when to use it. Use the third-person (e.g. \"This skill should be used when...\" instead of \"Use this skill when...\").\n\n#### Bundled Resources (optional)\n\n##### Scripts (`scripts/`)\n\nExecutable code (Python/Bash/etc.) for tasks that require deterministic reliability or are repeatedly rewritten.\n\n- **When to include**: When the same code is being rewritten repeatedly or deterministic reliability is needed\n- **Example**: `scripts/rotate_pdf.py` for PDF rotation tasks\n- **Benefits**: Token efficient, deterministic, may be executed without loading into context\n- **Note**: Scripts may still need to be read by Claude for patching or environment-specific adjustments\n\n##### References (`references/`)\n\nDocumentation and reference material intended to be loaded as needed into context to inform Claude's process and thinking.\n\n- **When to include**: For documentation that Claude should reference while working\n- **Examples**: `references/finance.md` for financial schemas, `references/mnda.md` for company NDA template, `references/policies.md` for company policies, `references/api_docs.md` for API specifications\n- **Use cases**: Database schemas, API documentation, domain knowledge, company policies, detailed workflow guides\n- **Benefits**: Keeps SKILL.md lean, loaded only when Claude determines it's needed\n- **Best practice**: If files are large (>10k words), include grep search patterns in SKILL.md\n- **Avoid duplication**: Information should live in either SKILL.md or references files, not both. Prefer references files for detailed information unless it's truly core to the skillâ€”this keeps SKILL.md lean while making information discoverable without hogging the context window. Keep only essential procedural instructions and workflow guidance in SKILL.md; move detailed reference material, schemas, and examples to references files.\n\n##### Assets (`assets/`)\n\nFiles not intended to be loaded into context, but rather used within the output Claude produces.\n\n- **When to include**: When the skill needs files that will be used in the final output\n- **Examples**: `assets/logo.png` for brand assets, `assets/slides.pptx` for PowerPoint templates, `assets/frontend-template/` for HTML/React boilerplate, `assets/font.ttf` for typography\n- **Use cases**: Templates, images, icons, boilerplate code, fonts, sample documents that get copied or modified\n- **Benefits**: Separates output resources from documentation, enables Claude to use files without loading them into context\n\n### Progressive Disclosure Design Principle\n\nSkills use a three-level loading system to manage context efficiently:\n\n1. **Metadata (name + description)** - Always in context (~100 words)\n2. **SKILL.md body** - When skill triggers (<5k words)\n3. **Bundled resources** - As needed by Claude (Unlimited*)\n\n*Unlimited because scripts can be executed without reading into context window.\n\n## Skill Creation Process\n\nTo create a skill, follow the \"Skill Creation Process\" in order, skipping steps only if there is a clear reason why they are not applicable.\n\n### Step 1: Understanding the Skill with Concrete Examples\n\nSkip this step only when the skill's usage patterns are already clearly understood. It remains valuable even when working with an existing skill.\n\nTo create an effective skill, clearly understand concrete examples of how the skill will be used. This understanding can come from either direct user examples or generated examples that are validated with user feedback.\n\nFor example, when building an image-editor skill, relevant questions include:\n\n- \"What functionality should the image-editor skill support? Editing, rotating, anything else?\"\n- \"Can you give some examples of how this skill would be used?\"\n- \"I can imagine users asking for things like 'Remove the red-eye from this image' or 'Rotate this image'. Are there other ways you imagine this skill being used?\"\n- \"What would a user say that should trigger this skill?\"\n\nTo avoid overwhelming users, avoid asking too many questions in a single message. Start with the most important questions and follow up as needed for better effectiveness.\n\nConclude this step when there is a clear sense of the functionality the skill should support.\n\n### Step 2: Planning the Reusable Skill Contents\n\nTo turn concrete examples into an effective skill, analyze each example by:\n\n1. Considering how to execute on the example from scratch\n2. Identifying what scripts, references, and assets would be helpful when executing these workflows repeatedly\n\nExample: When building a `pdf-editor` skill to handle queries like \"Help me rotate this PDF,\" the analysis shows:\n\n1. Rotating a PDF requires re-writing the same code each time\n2. A `scripts/rotate_pdf.py` script would be helpful to store in the skill\n\nExample: When designing a `frontend-webapp-builder` skill for queries like \"Build me a todo app\" or \"Build me a dashboard to track my steps,\" the analysis shows:\n\n1. Writing a frontend webapp requires the same boilerplate HTML/React each time\n2. An `assets/hello-world/` template containing the boilerplate HTML/React project files would be helpful to store in the skill\n\nExample: When building a `big-query` skill to handle queries like \"How many users have logged in today?\" the analysis shows:\n\n1. Querying BigQuery requires re-discovering the table schemas and relationships each time\n2. A `references/schema.md` file documenting the table schemas would be helpful to store in the skill\n\n**For Claude Code plugins:** When building a hooks skill, the analysis shows:\n1. Developers repeatedly need to validate hooks.json and test hook scripts\n2. `scripts/validate-hook-schema.sh` and `scripts/test-hook.sh` utilities would be helpful\n3. `references/patterns.md` for detailed hook patterns to avoid bloating SKILL.md\n\nTo establish the skill's contents, analyze each concrete example to create a list of the reusable resources to include: scripts, references, and assets.\n\n### Step 3: Create Skill Structure\n\nFor Claude Code plugins, create the skill directory structure:\n\n```bash\nmkdir -p plugin-name/skills/skill-name/{references,examples,scripts}\ntouch plugin-name/skills/skill-name/SKILL.md\n```\n\n**Note:** Unlike the generic skill-creator which uses `init_skill.py`, plugin skills are created directly in the plugin's `skills/` directory with a simpler manual structure.\n\n### Step 4: Edit the Skill\n\nWhen editing the (newly-created or existing) skill, remember that the skill is being created for another instance of Claude to use. Focus on including information that would be beneficial and non-obvious to Claude. Consider what procedural knowledge, domain-specific details, or reusable assets would help another Claude instance execute these tasks more effectively.\n\n#### Start with Reusable Skill Contents\n\nTo begin implementation, start with the reusable resources identified above: `scripts/`, `references/`, and `assets/` files. Note that this step may require user input. For example, when implementing a `brand-guidelines` skill, the user may need to provide brand assets or templates to store in `assets/`, or documentation to store in `references/`.\n\nAlso, delete any example files and directories not needed for the skill. Create only the directories you actually need (references/, examples/, scripts/).\n\n#### Update SKILL.md\n\n**Writing Style:** Write the entire skill using **imperative/infinitive form** (verb-first instructions), not second person. Use objective, instructional language (e.g., \"To accomplish X, do Y\" rather than \"You should do X\" or \"If you need to do X\"). This maintains consistency and clarity for AI consumption.\n\n**Description (Frontmatter):** Use third-person format with specific trigger phrases:\n\n```yaml\n---\nname: Skill Name\ndescription: This skill should be used when the user asks to \"specific phrase 1\", \"specific phrase 2\", \"specific phrase 3\". Include exact phrases users would say that should trigger this skill. Be concrete and specific.\nversion: 0.1.0\n---\n```\n\n**Good description examples:**\n```yaml\ndescription: This skill should be used when the user asks to \"create a hook\", \"add a PreToolUse hook\", \"validate tool use\", \"implement prompt-based hooks\", or mentions hook events (PreToolUse, PostToolUse, Stop).\n```\n\n**Bad description examples:**\n```yaml\ndescription: Use this skill when working with hooks.  # Wrong person, vague\ndescription: Load when user needs hook help.  # Not third person\ndescription: Provides hook guidance.  # No trigger phrases\n```\n\nTo complete SKILL.md body, answer the following questions:\n\n1. What is the purpose of the skill, in a few sentences?\n2. When should the skill be used? (Include this in frontmatter description with specific triggers)\n3. In practice, how should Claude use the skill? All reusable skill contents developed above should be referenced so that Claude knows how to use them.\n\n**Keep SKILL.md lean:** Target 1,500-2,000 words for the body. Move detailed content to references/:\n- Detailed patterns â†’ `references/patterns.md`\n- Advanced techniques â†’ `references/advanced.md`\n- Migration guides â†’ `references/migration.md`\n- API references â†’ `references/api-reference.md`\n\n**Reference resources in SKILL.md:**\n```markdown\n## Additional Resources\n\n### Reference Files\n\nFor detailed patterns and techniques, consult:\n- **`references/patterns.md`** - Common patterns\n- **`references/advanced.md`** - Advanced use cases\n\n### Example Files\n\nWorking examples in `examples/`:\n- **`example-script.sh`** - Working example\n```\n\n### Step 5: Validate and Test\n\n**For plugin skills, validation is different from generic skills:**\n\n1. **Check structure**: Skill directory in `plugin-name/skills/skill-name/`\n2. **Validate SKILL.md**: Has frontmatter with name and description\n3. **Check trigger phrases**: Description includes specific user queries\n4. **Verify writing style**: Body uses imperative/infinitive form, not second person\n5. **Test progressive disclosure**: SKILL.md is lean (~1,500-2,000 words), detailed content in references/\n6. **Check references**: All referenced files exist\n7. **Validate examples**: Examples are complete and correct\n8. **Test scripts**: Scripts are executable and work correctly\n\n**Use the skill-reviewer agent:**\n```\nAsk: \"Review my skill and check if it follows best practices\"\n```\n\nThe skill-reviewer agent will check description quality, content organization, and progressive disclosure.\n\n### Step 6: Iterate\n\nAfter testing the skill, users may request improvements. Often this happens right after using the skill, with fresh context of how the skill performed.\n\n**Iteration workflow:**\n1. Use the skill on real tasks\n2. Notice struggles or inefficiencies\n3. Identify how SKILL.md or bundled resources should be updated\n4. Implement changes and test again\n\n**Common improvements:**\n- Strengthen trigger phrases in description\n- Move long sections from SKILL.md to references/\n- Add missing examples or scripts\n- Clarify ambiguous instructions\n- Add edge case handling\n\n## Plugin-Specific Considerations\n\n### Skill Location in Plugins\n\nPlugin skills live in the plugin's `skills/` directory:\n\n```\nmy-plugin/\nâ”œâ”€â”€ .claude-plugin/\nâ”‚   â””â”€â”€ plugin.json\nâ”œâ”€â”€ commands/\nâ”œâ”€â”€ agents/\nâ””â”€â”€ skills/\n    â””â”€â”€ my-skill/\n        â”œâ”€â”€ SKILL.md\n        â”œâ”€â”€ references/\n        â”œâ”€â”€ examples/\n        â””â”€â”€ scripts/\n```\n\n### Auto-Discovery\n\nClaude Code automatically discovers skills:\n- Scans `skills/` directory\n- Finds subdirectories containing `SKILL.md`\n- Loads skill metadata (name + description) always\n- Loads SKILL.md body when skill triggers\n- Loads references/examples when needed\n\n### No Packaging Needed\n\nPlugin skills are distributed as part of the plugin, not as separate ZIP files. Users get skills when they install the plugin.\n\n### Testing in Plugins\n\nTest skills by installing plugin locally:\n\n```bash\n# Test with --plugin-dir\ncc --plugin-dir /path/to/plugin\n\n# Ask questions that should trigger the skill\n# Verify skill loads correctly\n```\n\n## Examples from Plugin-Dev\n\nStudy the skills in this plugin as examples of best practices:\n\n**hook-development skill:**\n- Excellent trigger phrases: \"create a hook\", \"add a PreToolUse hook\", etc.\n- Lean SKILL.md (1,651 words)\n- 3 references/ files for detailed content\n- 3 examples/ of working hooks\n- 3 scripts/ utilities\n\n**agent-development skill:**\n- Strong triggers: \"create an agent\", \"agent frontmatter\", etc.\n- Focused SKILL.md (1,438 words)\n- References include the AI generation prompt from Claude Code\n- Complete agent examples\n\n**plugin-settings skill:**\n- Specific triggers: \"plugin settings\", \".local.md files\", \"YAML frontmatter\"\n- References show real implementations (multi-agent-swarm, ralph-loop)\n- Working parsing scripts\n\nEach demonstrates progressive disclosure and strong triggering.\n\n## Progressive Disclosure in Practice\n\n### What Goes in SKILL.md\n\n**Include (always loaded when skill triggers):**\n- Core concepts and overview\n- Essential procedures and workflows\n- Quick reference tables\n- Pointers to references/examples/scripts\n- Most common use cases\n\n**Keep under 3,000 words, ideally 1,500-2,000 words**\n\n### What Goes in references/\n\n**Move to references/ (loaded as needed):**\n- Detailed patterns and advanced techniques\n- Comprehensive API documentation\n- Migration guides\n- Edge cases and troubleshooting\n- Extensive examples and walkthroughs\n\n**Each reference file can be large (2,000-5,000+ words)**\n\n### What Goes in examples/\n\n**Working code examples:**\n- Complete, runnable scripts\n- Configuration files\n- Template files\n- Real-world usage examples\n\n**Users can copy and adapt these directly**\n\n### What Goes in scripts/\n\n**Utility scripts:**\n- Validation tools\n- Testing helpers\n- Parsing utilities\n- Automation scripts\n\n**Should be executable and documented**\n\n## Writing Style Requirements\n\n### Imperative/Infinitive Form\n\nWrite using verb-first instructions, not second person:\n\n**Correct (imperative):**\n```\nTo create a hook, define the event type.\nConfigure the MCP server with authentication.\nValidate settings before use.\n```\n\n**Incorrect (second person):**\n```\nYou should create a hook by defining the event type.\nYou need to configure the MCP server.\nYou must validate settings before use.\n```\n\n### Third-Person in Description\n\nThe frontmatter description must use third person:\n\n**Correct:**\n```yaml\ndescription: This skill should be used when the user asks to \"create X\", \"configure Y\"...\n```\n\n**Incorrect:**\n```yaml\ndescription: Use this skill when you want to create X...\ndescription: Load this skill when user asks...\n```\n\n### Objective, Instructional Language\n\nFocus on what to do, not who should do it:\n\n**Correct:**\n```\nParse the frontmatter using sed.\nExtract fields with grep.\nValidate values before use.\n```\n\n**Incorrect:**\n```\nYou can parse the frontmatter...\nClaude should extract fields...\nThe user might validate values...\n```\n\n## Validation Checklist\n\nBefore finalizing a skill:\n\n**Structure:**\n- [ ] SKILL.md file exists with valid YAML frontmatter\n- [ ] Frontmatter has `name` and `description` fields\n- [ ] Markdown body is present and substantial\n- [ ] Referenced files actually exist\n\n**Description Quality:**\n- [ ] Uses third person (\"This skill should be used when...\")\n- [ ] Includes specific trigger phrases users would say\n- [ ] Lists concrete scenarios (\"create X\", \"configure Y\")\n- [ ] Not vague or generic\n\n**Content Quality:**\n- [ ] SKILL.md body uses imperative/infinitive form\n- [ ] Body is focused and lean (1,500-2,000 words ideal, <5k max)\n- [ ] Detailed content moved to references/\n- [ ] Examples are complete and working\n- [ ] Scripts are executable and documented\n\n**Progressive Disclosure:**\n- [ ] Core concepts in SKILL.md\n- [ ] Detailed docs in references/\n- [ ] Working code in examples/\n- [ ] Utilities in scripts/\n- [ ] SKILL.md references these resources\n\n**Testing:**\n- [ ] Skill triggers on expected user queries\n- [ ] Content is helpful for intended tasks\n- [ ] No duplicated information across files\n- [ ] References load when needed\n\n## Common Mistakes to Avoid\n\n### Mistake 1: Weak Trigger Description\n\nâŒ **Bad:**\n```yaml\ndescription: Provides guidance for working with hooks.\n```\n\n**Why bad:** Vague, no specific trigger phrases, not third person\n\nâœ… **Good:**\n```yaml\ndescription: This skill should be used when the user asks to \"create a hook\", \"add a PreToolUse hook\", \"validate tool use\", or mentions hook events. Provides comprehensive hooks API guidance.\n```\n\n**Why good:** Third person, specific phrases, concrete scenarios\n\n### Mistake 2: Too Much in SKILL.md\n\nâŒ **Bad:**\n```\nskill-name/\nâ””â”€â”€ SKILL.md  (8,000 words - everything in one file)\n```\n\n**Why bad:** Bloats context when skill loads, detailed content always loaded\n\nâœ… **Good:**\n```\nskill-name/\nâ”œâ”€â”€ SKILL.md  (1,800 words - core essentials)\nâ””â”€â”€ references/\n    â”œâ”€â”€ patterns.md (2,500 words)\n    â””â”€â”€ advanced.md (3,700 words)\n```\n\n**Why good:** Progressive disclosure, detailed content loaded only when needed\n\n### Mistake 3: Second Person Writing\n\nâŒ **Bad:**\n```markdown\nYou should start by reading the configuration file.\nYou need to validate the input.\nYou can use the grep tool to search.\n```\n\n**Why bad:** Second person, not imperative form\n\nâœ… **Good:**\n```markdown\nStart by reading the configuration file.\nValidate the input before processing.\nUse the grep tool to search for patterns.\n```\n\n**Why good:** Imperative form, direct instructions\n\n### Mistake 4: Missing Resource References\n\nâŒ **Bad:**\n```markdown\n# SKILL.md\n\n[Core content]\n\n[No mention of references/ or examples/]\n```\n\n**Why bad:** Claude doesn't know references exist\n\nâœ… **Good:**\n```markdown\n# SKILL.md\n\n[Core content]\n\n## Additional Resources\n\n### Reference Files\n- **`references/patterns.md`** - Detailed patterns\n- **`references/advanced.md`** - Advanced techniques\n\n### Examples\n- **`examples/script.sh`** - Working example\n```\n\n**Why good:** Claude knows where to find additional information\n\n## Quick Reference\n\n### Minimal Skill\n\n```\nskill-name/\nâ””â”€â”€ SKILL.md\n```\n\nGood for: Simple knowledge, no complex resources needed\n\n### Standard Skill (Recommended)\n\n```\nskill-name/\nâ”œâ”€â”€ SKILL.md\nâ”œâ”€â”€ references/\nâ”‚   â””â”€â”€ detailed-guide.md\nâ””â”€â”€ examples/\n    â””â”€â”€ working-example.sh\n```\n\nGood for: Most plugin skills with detailed documentation\n\n### Complete Skill\n\n```\nskill-name/\nâ”œâ”€â”€ SKILL.md\nâ”œâ”€â”€ references/\nâ”‚   â”œâ”€â”€ patterns.md\nâ”‚   â””â”€â”€ advanced.md\nâ”œâ”€â”€ examples/\nâ”‚   â”œâ”€â”€ example1.sh\nâ”‚   â””â”€â”€ example2.json\nâ””â”€â”€ scripts/\n    â””â”€â”€ validate.sh\n```\n\nGood for: Complex domains with validation utilities\n\n## Best Practices Summary\n\nâœ… **DO:**\n- Use third-person in description (\"This skill should be used when...\")\n- Include specific trigger phrases (\"create X\", \"configure Y\")\n- Keep SKILL.md lean (1,500-2,000 words)\n- Use progressive disclosure (move details to references/)\n- Write in imperative/infinitive form\n- Reference supporting files clearly\n- Provide working examples\n- Create utility scripts for common operations\n- Study plugin-dev's skills as templates\n\nâŒ **DON'T:**\n- Use second person anywhere\n- Have vague trigger conditions\n- Put everything in SKILL.md (>3,000 words without references/)\n- Write in second person (\"You should...\")\n- Leave resources unreferenced\n- Include broken or incomplete examples\n- Skip validation\n\n## Additional Resources\n\n### Study These Skills\n\nPlugin-dev's skills demonstrate best practices:\n- `../hook-development/` - Progressive disclosure, utilities\n- `../agent-development/` - AI-assisted creation, references\n- `../mcp-integration/` - Comprehensive references\n- `../plugin-settings/` - Real-world examples\n- `../command-development/` - Clear critical concepts\n- `../plugin-structure/` - Good organization\n\n### Reference Files\n\nFor complete skill-creator methodology:\n- **`references/skill-creator-original.md`** - Full original skill-creator content\n\n## Implementation Workflow\n\nTo create a skill for your plugin:\n\n1. **Understand use cases**: Identify concrete examples of skill usage\n2. **Plan resources**: Determine what scripts/references/examples needed\n3. **Create structure**: `mkdir -p skills/skill-name/{references,examples,scripts}`\n4. **Write SKILL.md**:\n   - Frontmatter with third-person description and trigger phrases\n   - Lean body (1,500-2,000 words) in imperative form\n   - Reference supporting files\n5. **Add resources**: Create references/, examples/, scripts/ as needed\n6. **Validate**: Check description, writing style, organization\n7. **Test**: Verify skill loads on expected triggers\n8. **Iterate**: Improve based on usage\n\nFocus on strong trigger descriptions, progressive disclosure, and imperative writing style for effective skills that load when needed and provide targeted guidance.\n",
        "plugins/plugin-dev/skills/skill-development/references/skill-creator-original.md": "---\nname: skill-creator\ndescription: Guide for creating effective skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations.\nlicense: Complete terms in LICENSE.txt\n---\n\n# Skill Creator\n\nThis skill provides guidance for creating effective skills.\n\n## About Skills\n\nSkills are modular, self-contained packages that extend Claude's capabilities by providing\nspecialized knowledge, workflows, and tools. Think of them as \"onboarding guides\" for specific\ndomains or tasksâ€”they transform Claude from a general-purpose agent into a specialized agent\nequipped with procedural knowledge that no model can fully possess.\n\n### What Skills Provide\n\n1. Specialized workflows - Multi-step procedures for specific domains\n2. Tool integrations - Instructions for working with specific file formats or APIs\n3. Domain expertise - Company-specific knowledge, schemas, business logic\n4. Bundled resources - Scripts, references, and assets for complex and repetitive tasks\n\n### Anatomy of a Skill\n\nEvery skill consists of a required SKILL.md file and optional bundled resources:\n\n```\nskill-name/\nâ”œâ”€â”€ SKILL.md (required)\nâ”‚   â”œâ”€â”€ YAML frontmatter metadata (required)\nâ”‚   â”‚   â”œâ”€â”€ name: (required)\nâ”‚   â”‚   â””â”€â”€ description: (required)\nâ”‚   â””â”€â”€ Markdown instructions (required)\nâ””â”€â”€ Bundled Resources (optional)\n    â”œâ”€â”€ scripts/          - Executable code (Python/Bash/etc.)\n    â”œâ”€â”€ references/       - Documentation intended to be loaded into context as needed\n    â””â”€â”€ assets/           - Files used in output (templates, icons, fonts, etc.)\n```\n\n#### SKILL.md (required)\n\n**Metadata Quality:** The `name` and `description` in YAML frontmatter determine when Claude will use the skill. Be specific about what the skill does and when to use it. Use the third-person (e.g. \"This skill should be used when...\" instead of \"Use this skill when...\").\n\n#### Bundled Resources (optional)\n\n##### Scripts (`scripts/`)\n\nExecutable code (Python/Bash/etc.) for tasks that require deterministic reliability or are repeatedly rewritten.\n\n- **When to include**: When the same code is being rewritten repeatedly or deterministic reliability is needed\n- **Example**: `scripts/rotate_pdf.py` for PDF rotation tasks\n- **Benefits**: Token efficient, deterministic, may be executed without loading into context\n- **Note**: Scripts may still need to be read by Claude for patching or environment-specific adjustments\n\n##### References (`references/`)\n\nDocumentation and reference material intended to be loaded as needed into context to inform Claude's process and thinking.\n\n- **When to include**: For documentation that Claude should reference while working\n- **Examples**: `references/finance.md` for financial schemas, `references/mnda.md` for company NDA template, `references/policies.md` for company policies, `references/api_docs.md` for API specifications\n- **Use cases**: Database schemas, API documentation, domain knowledge, company policies, detailed workflow guides\n- **Benefits**: Keeps SKILL.md lean, loaded only when Claude determines it's needed\n- **Best practice**: If files are large (>10k words), include grep search patterns in SKILL.md\n- **Avoid duplication**: Information should live in either SKILL.md or references files, not both. Prefer references files for detailed information unless it's truly core to the skillâ€”this keeps SKILL.md lean while making information discoverable without hogging the context window. Keep only essential procedural instructions and workflow guidance in SKILL.md; move detailed reference material, schemas, and examples to references files.\n\n##### Assets (`assets/`)\n\nFiles not intended to be loaded into context, but rather used within the output Claude produces.\n\n- **When to include**: When the skill needs files that will be used in the final output\n- **Examples**: `assets/logo.png` for brand assets, `assets/slides.pptx` for PowerPoint templates, `assets/frontend-template/` for HTML/React boilerplate, `assets/font.ttf` for typography\n- **Use cases**: Templates, images, icons, boilerplate code, fonts, sample documents that get copied or modified\n- **Benefits**: Separates output resources from documentation, enables Claude to use files without loading them into context\n\n### Progressive Disclosure Design Principle\n\nSkills use a three-level loading system to manage context efficiently:\n\n1. **Metadata (name + description)** - Always in context (~100 words)\n2. **SKILL.md body** - When skill triggers (<5k words)\n3. **Bundled resources** - As needed by Claude (Unlimited*)\n\n*Unlimited because scripts can be executed without reading into context window.\n\n## Skill Creation Process\n\nTo create a skill, follow the \"Skill Creation Process\" in order, skipping steps only if there is a clear reason why they are not applicable.\n\n### Step 1: Understanding the Skill with Concrete Examples\n\nSkip this step only when the skill's usage patterns are already clearly understood. It remains valuable even when working with an existing skill.\n\nTo create an effective skill, clearly understand concrete examples of how the skill will be used. This understanding can come from either direct user examples or generated examples that are validated with user feedback.\n\nFor example, when building an image-editor skill, relevant questions include:\n\n- \"What functionality should the image-editor skill support? Editing, rotating, anything else?\"\n- \"Can you give some examples of how this skill would be used?\"\n- \"I can imagine users asking for things like 'Remove the red-eye from this image' or 'Rotate this image'. Are there other ways you imagine this skill being used?\"\n- \"What would a user say that should trigger this skill?\"\n\nTo avoid overwhelming users, avoid asking too many questions in a single message. Start with the most important questions and follow up as needed for better effectiveness.\n\nConclude this step when there is a clear sense of the functionality the skill should support.\n\n### Step 2: Planning the Reusable Skill Contents\n\nTo turn concrete examples into an effective skill, analyze each example by:\n\n1. Considering how to execute on the example from scratch\n2. Identifying what scripts, references, and assets would be helpful when executing these workflows repeatedly\n\nExample: When building a `pdf-editor` skill to handle queries like \"Help me rotate this PDF,\" the analysis shows:\n\n1. Rotating a PDF requires re-writing the same code each time\n2. A `scripts/rotate_pdf.py` script would be helpful to store in the skill\n\nExample: When designing a `frontend-webapp-builder` skill for queries like \"Build me a todo app\" or \"Build me a dashboard to track my steps,\" the analysis shows:\n\n1. Writing a frontend webapp requires the same boilerplate HTML/React each time\n2. An `assets/hello-world/` template containing the boilerplate HTML/React project files would be helpful to store in the skill\n\nExample: When building a `big-query` skill to handle queries like \"How many users have logged in today?\" the analysis shows:\n\n1. Querying BigQuery requires re-discovering the table schemas and relationships each time\n2. A `references/schema.md` file documenting the table schemas would be helpful to store in the skill\n\nTo establish the skill's contents, analyze each concrete example to create a list of the reusable resources to include: scripts, references, and assets.\n\n### Step 3: Initializing the Skill\n\nAt this point, it is time to actually create the skill.\n\nSkip this step only if the skill being developed already exists, and iteration or packaging is needed. In this case, continue to the next step.\n\nWhen creating a new skill from scratch, always run the `init_skill.py` script. The script conveniently generates a new template skill directory that automatically includes everything a skill requires, making the skill creation process much more efficient and reliable.\n\nUsage:\n\n```bash\nscripts/init_skill.py <skill-name> --path <output-directory>\n```\n\nThe script:\n\n- Creates the skill directory at the specified path\n- Generates a SKILL.md template with proper frontmatter and TODO placeholders\n- Creates example resource directories: `scripts/`, `references/`, and `assets/`\n- Adds example files in each directory that can be customized or deleted\n\nAfter initialization, customize or remove the generated SKILL.md and example files as needed.\n\n### Step 4: Edit the Skill\n\nWhen editing the (newly-generated or existing) skill, remember that the skill is being created for another instance of Claude to use. Focus on including information that would be beneficial and non-obvious to Claude. Consider what procedural knowledge, domain-specific details, or reusable assets would help another Claude instance execute these tasks more effectively.\n\n#### Start with Reusable Skill Contents\n\nTo begin implementation, start with the reusable resources identified above: `scripts/`, `references/`, and `assets/` files. Note that this step may require user input. For example, when implementing a `brand-guidelines` skill, the user may need to provide brand assets or templates to store in `assets/`, or documentation to store in `references/`.\n\nAlso, delete any example files and directories not needed for the skill. The initialization script creates example files in `scripts/`, `references/`, and `assets/` to demonstrate structure, but most skills won't need all of them.\n\n#### Update SKILL.md\n\n**Writing Style:** Write the entire skill using **imperative/infinitive form** (verb-first instructions), not second person. Use objective, instructional language (e.g., \"To accomplish X, do Y\" rather than \"You should do X\" or \"If you need to do X\"). This maintains consistency and clarity for AI consumption.\n\nTo complete SKILL.md, answer the following questions:\n\n1. What is the purpose of the skill, in a few sentences?\n2. When should the skill be used?\n3. In practice, how should Claude use the skill? All reusable skill contents developed above should be referenced so that Claude knows how to use them.\n\n### Step 5: Packaging a Skill\n\nOnce the skill is ready, it should be packaged into a distributable zip file that gets shared with the user. The packaging process automatically validates the skill first to ensure it meets all requirements:\n\n```bash\nscripts/package_skill.py <path/to/skill-folder>\n```\n\nOptional output directory specification:\n\n```bash\nscripts/package_skill.py <path/to/skill-folder> ./dist\n```\n\nThe packaging script will:\n\n1. **Validate** the skill automatically, checking:\n   - YAML frontmatter format and required fields\n   - Skill naming conventions and directory structure\n   - Description completeness and quality\n   - File organization and resource references\n\n2. **Package** the skill if validation passes, creating a zip file named after the skill (e.g., `my-skill.zip`) that includes all files and maintains the proper directory structure for distribution.\n\nIf validation fails, the script will report the errors and exit without creating a package. Fix any validation errors and run the packaging command again.\n\n### Step 6: Iterate\n\nAfter testing the skill, users may request improvements. Often this happens right after using the skill, with fresh context of how the skill performed.\n\n**Iteration workflow:**\n1. Use the skill on real tasks\n2. Notice struggles or inefficiencies\n3. Identify how SKILL.md or bundled resources should be updated\n4. Implement changes and test again\n",
        "plugins/superpowers/.claude-plugin/plugin.json": "{\n  \"name\": \"superpowers\",\n  \"description\": \"Core skills library for Claude Code: TDD, debugging, collaboration patterns, and proven techniques\",\n  \"author\": {\n    \"name\": \"Jesse Vincent\",\n    \"email\": \"jesse@fsck.com\"\n  },\n  \"homepage\": \"https://github.com/obra/superpowers\",\n  \"repository\": \"https://github.com/obra/superpowers\",\n  \"license\": \"MIT\",\n  \"keywords\": [\"skills\", \"tdd\", \"debugging\", \"collaboration\", \"best-practices\", \"workflows\"]\n}\n",
        "plugins/superpowers/README.md": "# Superpowers\n\nSuperpowers is a complete software development workflow for your coding agents, built on top of a set of composable \"skills\" and some initial instructions that make sure your agent uses them.\n\n## How it works\n\nIt starts from the moment you fire up your coding agent. As soon as it sees that you're building something, it *doesn't* just jump into trying to write code. Instead, it steps back and asks you what you're really trying to do. \n\nOnce it's teased a spec out of the conversation, it shows it to you in chunks short enough to actually read and digest. \n\nAfter you've signed off on the design, your agent puts together an implementation plan that's clear enough for an enthusiastic junior engineer with poor taste, no judgement, no project context, and an aversion to testing to follow. It emphasizes true red/green TDD, YAGNI (You Aren't Gonna Need It), and DRY. \n\nNext up, once you say \"go\", it launches a *subagent-driven-development* process, having agents work through each engineering task, inspecting and reviewing their work, and continuing forward. It's not uncommon for Claude to be able to work autonomously for a couple hours at a time without deviating from the plan you put together.\n\nThere's a bunch more to it, but that's the core of the system. And because the skills trigger automatically, you don't need to do anything special. Your coding agent just has Superpowers.\n\n\n## Sponsorship\n\nIf Superpowers has helped you do stuff that makes money and you are so inclined, I'd greatly appreciate it if you'd consider [sponsoring my opensource work](https://github.com/sponsors/obra).\n\nThanks! \n\n- Jesse\n\n\n## Installation\n\n**Note:** Installation differs by platform. Claude Code has a built-in plugin system. Codex and OpenCode require manual setup.\n\n### Claude Code (via Plugin Marketplace)\n\nIn Claude Code, register the marketplace first:\n\n```bash\n/plugin marketplace add obra/superpowers-marketplace\n```\n\nThen install the plugin from this marketplace:\n\n```bash\n/plugin install superpowers@superpowers-marketplace\n```\n\n### Verify Installation\n\nCheck that commands appear:\n\n```bash\n/help\n```\n\n```\n# Should see:\n# /superpowers:brainstorm - Interactive design refinement\n# /superpowers:write-plan - Create implementation plan\n# /superpowers:execute-plan - Execute plan continuously\n```\n\n### Codex\n\nTell Codex:\n\n```\nFetch and follow instructions from https://raw.githubusercontent.com/obra/superpowers/refs/heads/main/.codex/INSTALL.md\n```\n\n**Detailed docs:** [docs/README.codex.md](docs/README.codex.md)\n\n### OpenCode\n\nTell OpenCode:\n\n```\nFetch and follow instructions from https://raw.githubusercontent.com/obra/superpowers/refs/heads/main/.opencode/INSTALL.md\n```\n\n**Detailed docs:** [docs/README.opencode.md](docs/README.opencode.md)\n\n## The Basic Workflow\n\n1. **brainstorming** - Activates before writing code. Refines rough ideas through questions, explores alternatives, presents design in sections for validation. Saves design document.\n\n2. **using-git-worktrees** - Activates after design approval. Creates isolated workspace on new branch, runs project setup, verifies clean test baseline.\n\n3. **writing-plans** - Activates with approved design. Breaks work into bite-sized tasks (2-5 minutes each). Every task has exact file paths, complete code, verification steps.\n\n4. **subagent-driven-development** or **executing-plans** - Activates with plan. Dispatches fresh subagent per task with two-stage review (spec compliance, then code quality), or executes all tasks continuously with stops only for blockers.\n\n5. **test-driven-development** - Activates during implementation. Enforces RED-GREEN-REFACTOR: write failing test, watch it fail, write minimal code, watch it pass, commit. Deletes code written before tests.\n\n6. **requesting-code-review** - Activates between tasks. Reviews against plan, reports issues by severity. Critical issues block progress.\n\n7. **finishing-a-development-branch** - Activates when tasks complete. Verifies tests, presents options (merge/PR/keep/discard), cleans up worktree.\n\n**The agent checks for relevant skills before any task.** Mandatory workflows, not suggestions.\n\n## What's Inside\n\n### Skills Library\n\n**Testing**\n- **test-driven-development** - RED-GREEN-REFACTOR cycle (includes testing anti-patterns reference)\n\n**Debugging**\n- **systematic-debugging** - 4-phase root cause process (includes root-cause-tracing, defense-in-depth, condition-based-waiting techniques)\n- **verification-before-completion** - Ensure it's actually fixed\n\n**Collaboration** \n- **brainstorming** - Socratic design refinement\n- **writing-plans** - Detailed implementation plans\n- **executing-plans** - Continuous task execution\n- **dispatching-parallel-agents** - Concurrent subagent workflows\n- **requesting-code-review** - Pre-review checklist\n- **receiving-code-review** - Responding to feedback\n- **using-git-worktrees** - Parallel development branches\n- **finishing-a-development-branch** - Merge/PR decision workflow\n- **subagent-driven-development** - Fast iteration with two-stage review (spec compliance, then code quality)\n\n**Meta**\n- **writing-skills** - Create new skills following best practices (includes testing methodology)\n- **using-superpowers** - Introduction to the skills system\n\n## Philosophy\n\n- **Test-Driven Development** - Write tests first, always\n- **Systematic over ad-hoc** - Process over guessing\n- **Complexity reduction** - Simplicity as primary goal\n- **Evidence over claims** - Verify before declaring success\n\nRead more: [Superpowers for Claude Code](https://blog.fsck.com/2025/10/09/superpowers/)\n\n## Contributing\n\nSkills live directly in this repository. To contribute:\n\n1. Fork the repository\n2. Create a branch for your skill\n3. Follow the `writing-skills` skill for creating and testing new skills\n4. Submit a PR\n\nSee `skills/writing-skills/SKILL.md` for the complete guide.\n\n## Updating\n\nSkills update automatically when you update the plugin:\n\n```bash\n/plugin update superpowers\n```\n\n## License\n\nMIT License - see LICENSE file for details\n\n## Support\n\n- **Issues**: https://github.com/obra/superpowers/issues\n- **Marketplace**: https://github.com/obra/superpowers-marketplace\n",
        "plugins/superpowers/agents/code-reviewer.md": "---\nname: code-reviewer\ndescription: |\n  Use this agent when a major project step has been completed and needs to be reviewed against the original plan and coding standards. Examples: <example>Context: The user is creating a code-review agent that should be called after a logical chunk of code is written. user: \"I've finished implementing the user authentication system as outlined in step 3 of our plan\" assistant: \"Great work! Now let me use the code-reviewer agent to review the implementation against our plan and coding standards\" <commentary>Since a major project step has been completed, use the code-reviewer agent to validate the work against the plan and identify any issues.</commentary></example> <example>Context: User has completed a significant feature implementation. user: \"The API endpoints for the task management system are now complete - that covers step 2 from our architecture document\" assistant: \"Excellent! Let me have the code-reviewer agent examine this implementation to ensure it aligns with our plan and follows best practices\" <commentary>A numbered step from the planning document has been completed, so the code-reviewer agent should review the work.</commentary></example>\nmodel: inherit\n---\n\nYou are a Senior Code Reviewer with expertise in software architecture, design patterns, and best practices. Your role is to review completed project steps against original plans and ensure code quality standards are met.\n\nWhen reviewing completed work, you will:\n\n1. **Plan Alignment Analysis**:\n   - Compare the implementation against the original planning document or step description\n   - Identify any deviations from the planned approach, architecture, or requirements\n   - Assess whether deviations are justified improvements or problematic departures\n   - Verify that all planned functionality has been implemented\n\n2. **Code Quality Assessment**:\n   - Review code for adherence to established patterns and conventions\n   - Check for proper error handling, type safety, and defensive programming\n   - Evaluate code organization, naming conventions, and maintainability\n   - Assess test coverage and quality of test implementations\n   - Look for potential security vulnerabilities or performance issues\n\n3. **Architecture and Design Review**:\n   - Ensure the implementation follows SOLID principles and established architectural patterns\n   - Check for proper separation of concerns and loose coupling\n   - Verify that the code integrates well with existing systems\n   - Assess scalability and extensibility considerations\n\n4. **Documentation and Standards**:\n   - Verify that code includes appropriate comments and documentation\n   - Check that file headers, function documentation, and inline comments are present and accurate\n   - Ensure adherence to project-specific coding standards and conventions\n\n5. **Issue Identification and Recommendations**:\n   - Clearly categorize issues as: Critical (must fix), Important (should fix), or Suggestions (nice to have)\n   - For each issue, provide specific examples and actionable recommendations\n   - When you identify plan deviations, explain whether they're problematic or beneficial\n   - Suggest specific improvements with code examples when helpful\n\n6. **Communication Protocol**:\n   - If you find significant deviations from the plan, ask the coding agent to review and confirm the changes\n   - If you identify issues with the original plan itself, recommend plan updates\n   - For implementation problems, provide clear guidance on fixes needed\n   - Always acknowledge what was done well before highlighting issues\n\nYour output should be structured, actionable, and focused on helping maintain high code quality while ensuring project goals are met. Be thorough but concise, and always provide constructive feedback that helps improve both the current implementation and future development practices.\n",
        "plugins/superpowers/commands/brainstorm.md": "---\ndescription: \"You MUST use this before any creative work - creating features, building components, adding functionality, or modifying behavior. Explores requirements and design before implementation.\"\ndisable-model-invocation: true\n---\n\nInvoke the superpowers:brainstorming skill and follow it exactly as presented to you\n",
        "plugins/superpowers/commands/execute-plan.md": "---\ndescription: Execute plan with continuous task execution\ndisable-model-invocation: true\n---\n\nInvoke the superpowers:executing-plans skill and follow it exactly as presented to you\n",
        "plugins/superpowers/commands/write-plan.md": "---\ndescription: Create detailed implementation plan with bite-sized tasks\ndisable-model-invocation: true\n---\n\nInvoke the superpowers:writing-plans skill and follow it exactly as presented to you\n",
        "plugins/superpowers/hooks/hooks.json": "{\n  \"hooks\": {\n    \"SessionStart\": [\n      {\n        \"matcher\": \"startup|resume|clear|compact\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"${CLAUDE_PLUGIN_ROOT}/hooks/session-start.sh\"\n          }\n        ]\n      }\n    ]\n  }\n}\n",
        "plugins/superpowers/hooks/run-hook.cmd": ": << 'CMDBLOCK'\n@echo off\nREM ============================================================================\nREM DEPRECATED: This polyglot wrapper is no longer used as of Claude Code 2.1.x\nREM ============================================================================\nREM\nREM Claude Code 2.1.x changed the Windows execution model for hooks:\nREM\nREM   Before (2.0.x): Hooks ran with shell:true, using the system default shell.\nREM                   This wrapper provided cross-platform compatibility by\nREM                   being both a valid .cmd file (Windows) and bash script.\nREM\nREM   After (2.1.x):  Claude Code now auto-detects .sh files in hook commands\nREM                   and prepends \"bash \" on Windows. This broke the wrapper\nREM                   because the command:\nREM                     \"run-hook.cmd\" session-start.sh\nREM                   became:\nREM                     bash \"run-hook.cmd\" session-start.sh\nREM                   ...and bash cannot execute a .cmd file.\nREM\nREM The fix: hooks.json now calls session-start.sh directly. Claude Code 2.1.x\nREM handles the bash invocation automatically on Windows.\nREM\nREM This file is kept for reference and potential backward compatibility.\nREM ============================================================================\nREM\nREM Original purpose: Polyglot wrapper to run .sh scripts cross-platform\nREM Usage: run-hook.cmd <script-name> [args...]\nREM The script should be in the same directory as this wrapper\n\nif \"%~1\"==\"\" (\n    echo run-hook.cmd: missing script name >&2\n    exit /b 1\n)\n\"C:\\Program Files\\Git\\bin\\bash.exe\" -l \"%~dp0%~1\" %2 %3 %4 %5 %6 %7 %8 %9\nexit /b\nCMDBLOCK\n\n# Unix shell runs from here\nSCRIPT_DIR=\"$(cd \"$(dirname \"$0\")\" && pwd)\"\nSCRIPT_NAME=\"$1\"\nshift\n\"${SCRIPT_DIR}/${SCRIPT_NAME}\" \"$@\"\n",
        "plugins/superpowers/hooks/session-start.sh": "#!/usr/bin/env bash\n# SessionStart hook for superpowers plugin\n\nset -euo pipefail\n\n# Determine plugin root directory\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]:-$0}\")\" && pwd)\"\nPLUGIN_ROOT=\"$(cd \"${SCRIPT_DIR}/..\" && pwd)\"\n\n# Check if legacy skills directory exists and build warning\nwarning_message=\"\"\nlegacy_skills_dir=\"${HOME}/.config/superpowers/skills\"\nif [ -d \"$legacy_skills_dir\" ]; then\n    warning_message=\"\\n\\n<important-reminder>IN YOUR FIRST REPLY AFTER SEEING THIS MESSAGE YOU MUST TELL THE USER:âš ï¸ **WARNING:** Superpowers now uses Claude Code's skills system. Custom skills in ~/.config/superpowers/skills will not be read. Move custom skills to ~/.claude/skills instead. To make this message go away, remove ~/.config/superpowers/skills</important-reminder>\"\nfi\n\n# Read using-superpowers content\nusing_superpowers_content=$(cat \"${PLUGIN_ROOT}/skills/using-superpowers/SKILL.md\" 2>&1 || echo \"Error reading using-superpowers skill\")\n\n# Escape outputs for JSON using pure bash\nescape_for_json() {\n    local input=\"$1\"\n    local output=\"\"\n    local i char\n    for (( i=0; i<${#input}; i++ )); do\n        char=\"${input:$i:1}\"\n        case \"$char\" in\n            $'\\\\') output+='\\\\' ;;\n            '\"') output+='\\\"' ;;\n            $'\\n') output+='\\n' ;;\n            $'\\r') output+='\\r' ;;\n            $'\\t') output+='\\t' ;;\n            *) output+=\"$char\" ;;\n        esac\n    done\n    printf '%s' \"$output\"\n}\n\nusing_superpowers_escaped=$(escape_for_json \"$using_superpowers_content\")\nwarning_escaped=$(escape_for_json \"$warning_message\")\n\n# Output context injection as JSON\ncat <<EOF\n{\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"SessionStart\",\n    \"additionalContext\": \"<EXTREMELY_IMPORTANT>\\nYou have superpowers.\\n\\n**Below is the full content of your 'superpowers:using-superpowers' skill - your introduction to using skills. For all other skills, use the 'Skill' tool:**\\n\\n${using_superpowers_escaped}\\n\\n${warning_escaped}\\n</EXTREMELY_IMPORTANT>\"\n  }\n}\nEOF\n\nexit 0\n",
        "plugins/superpowers/skills/brainstorming/SKILL.md": "---\nname: brainstorming\ndescription: \"You MUST use this before any creative work - creating features, building components, adding functionality, or modifying behavior. Explores user intent, requirements and design before implementation.\"\n---\n\n# Brainstorming Ideas Into Designs\n\n## Overview\n\nHelp turn ideas into fully formed designs and specs through natural collaborative dialogue.\n\nStart by understanding the current project context, then ask questions one at a time to refine the idea. Once you understand what you're building, present the design in small sections (200-300 words), checking after each section whether it looks right so far.\n\n## The Process\n\n**Understanding the idea:**\n- Check out the current project state first (files, docs, recent commits)\n- Ask questions one at a time to refine the idea\n- Prefer multiple choice questions when possible, but open-ended is fine too\n- Only one question per message - if a topic needs more exploration, break it into multiple questions\n- Focus on understanding: purpose, constraints, success criteria\n\n**Exploring approaches:**\n- Propose 2-3 different approaches with trade-offs\n- Present options conversationally with your recommendation and reasoning\n- Lead with your recommended option and explain why\n\n**Presenting the design:**\n- Once you believe you understand what you're building, present the design\n- Break it into sections of 200-300 words\n- Ask after each section whether it looks right so far\n- Cover: architecture, components, data flow, error handling, testing\n- Be ready to go back and clarify if something doesn't make sense\n\n## After the Design\n\n**Documentation:**\n- Write the validated design to `docs/plans/YYYY-MM-DD-<topic>-design.md`\n- Use elements-of-style:writing-clearly-and-concisely skill if available\n- Commit the design document to git\n\n**Implementation (if continuing):**\n- Ask: \"Ready to set up for implementation?\"\n- Ask if they want a separate worktree (use superpowers:using-git-worktrees) or to proceed in the current worktree\n- Use superpowers:writing-plans to create detailed implementation plan\n\n## Key Principles\n\n- **One question at a time** - Don't overwhelm with multiple questions\n- **Multiple choice preferred** - Easier to answer than open-ended when possible\n- **YAGNI ruthlessly** - Remove unnecessary features from all designs\n- **Explore alternatives** - Always propose 2-3 approaches before settling\n- **Incremental validation** - Present design in sections, validate each\n- **Be flexible** - Go back and clarify when something doesn't make sense\n",
        "plugins/superpowers/skills/dispatching-parallel-agents/SKILL.md": "---\nname: dispatching-parallel-agents\ndescription: Use when facing 2+ independent tasks that can be worked on without shared state or sequential dependencies\n---\n\n# Dispatching Parallel Agents\n\n## Overview\n\nWhen you have multiple unrelated failures (different test files, different subsystems, different bugs), investigating them sequentially wastes time. Each investigation is independent and can happen in parallel.\n\n**Core principle:** Dispatch one agent per independent problem domain. Let them work concurrently.\n\n## When to Use\n\n```dot\ndigraph when_to_use {\n    \"Multiple failures?\" [shape=diamond];\n    \"Are they independent?\" [shape=diamond];\n    \"Single agent investigates all\" [shape=box];\n    \"One agent per problem domain\" [shape=box];\n    \"Can they work in parallel?\" [shape=diamond];\n    \"Sequential agents\" [shape=box];\n    \"Parallel dispatch\" [shape=box];\n\n    \"Multiple failures?\" -> \"Are they independent?\" [label=\"yes\"];\n    \"Are they independent?\" -> \"Single agent investigates all\" [label=\"no - related\"];\n    \"Are they independent?\" -> \"Can they work in parallel?\" [label=\"yes\"];\n    \"Can they work in parallel?\" -> \"Parallel dispatch\" [label=\"yes\"];\n    \"Can they work in parallel?\" -> \"Sequential agents\" [label=\"no - shared state\"];\n}\n```\n\n**Use when:**\n- 3+ test files failing with different root causes\n- Multiple subsystems broken independently\n- Each problem can be understood without context from others\n- No shared state between investigations\n\n**Don't use when:**\n- Failures are related (fix one might fix others)\n- Need to understand full system state\n- Agents would interfere with each other\n\n## The Pattern\n\n### 1. Identify Independent Domains\n\nGroup failures by what's broken:\n- File A tests: Tool approval flow\n- File B tests: Batch completion behavior\n- File C tests: Abort functionality\n\nEach domain is independent - fixing tool approval doesn't affect abort tests.\n\n### 2. Create Focused Agent Tasks\n\nEach agent gets:\n- **Specific scope:** One test file or subsystem\n- **Clear goal:** Make these tests pass\n- **Constraints:** Don't change other code\n- **Expected output:** Summary of what you found and fixed\n\n### 3. Dispatch in Parallel\n\n```typescript\n// In Claude Code / AI environment\nTask(\"Fix agent-tool-abort.test.ts failures\")\nTask(\"Fix batch-completion-behavior.test.ts failures\")\nTask(\"Fix tool-approval-race-conditions.test.ts failures\")\n// All three run concurrently\n```\n\n### 4. Review and Integrate\n\nWhen agents return:\n- Read each summary\n- Verify fixes don't conflict\n- Run full test suite\n- Integrate all changes\n\n## Agent Prompt Structure\n\nGood agent prompts are:\n1. **Focused** - One clear problem domain\n2. **Self-contained** - All context needed to understand the problem\n3. **Specific about output** - What should the agent return?\n\n```markdown\nFix the 3 failing tests in src/agents/agent-tool-abort.test.ts:\n\n1. \"should abort tool with partial output capture\" - expects 'interrupted at' in message\n2. \"should handle mixed completed and aborted tools\" - fast tool aborted instead of completed\n3. \"should properly track pendingToolCount\" - expects 3 results but gets 0\n\nThese are timing/race condition issues. Your task:\n\n1. Read the test file and understand what each test verifies\n2. Identify root cause - timing issues or actual bugs?\n3. Fix by:\n   - Replacing arbitrary timeouts with event-based waiting\n   - Fixing bugs in abort implementation if found\n   - Adjusting test expectations if testing changed behavior\n\nDo NOT just increase timeouts - find the real issue.\n\nReturn: Summary of what you found and what you fixed.\n```\n\n## Common Mistakes\n\n**âŒ Too broad:** \"Fix all the tests\" - agent gets lost\n**âœ… Specific:** \"Fix agent-tool-abort.test.ts\" - focused scope\n\n**âŒ No context:** \"Fix the race condition\" - agent doesn't know where\n**âœ… Context:** Paste the error messages and test names\n\n**âŒ No constraints:** Agent might refactor everything\n**âœ… Constraints:** \"Do NOT change production code\" or \"Fix tests only\"\n\n**âŒ Vague output:** \"Fix it\" - you don't know what changed\n**âœ… Specific:** \"Return summary of root cause and changes\"\n\n## When NOT to Use\n\n**Related failures:** Fixing one might fix others - investigate together first\n**Need full context:** Understanding requires seeing entire system\n**Exploratory debugging:** You don't know what's broken yet\n**Shared state:** Agents would interfere (editing same files, using same resources)\n\n## Real Example from Session\n\n**Scenario:** 6 test failures across 3 files after major refactoring\n\n**Failures:**\n- agent-tool-abort.test.ts: 3 failures (timing issues)\n- batch-completion-behavior.test.ts: 2 failures (tools not executing)\n- tool-approval-race-conditions.test.ts: 1 failure (execution count = 0)\n\n**Decision:** Independent domains - abort logic separate from batch completion separate from race conditions\n\n**Dispatch:**\n```\nAgent 1 â†’ Fix agent-tool-abort.test.ts\nAgent 2 â†’ Fix batch-completion-behavior.test.ts\nAgent 3 â†’ Fix tool-approval-race-conditions.test.ts\n```\n\n**Results:**\n- Agent 1: Replaced timeouts with event-based waiting\n- Agent 2: Fixed event structure bug (threadId in wrong place)\n- Agent 3: Added wait for async tool execution to complete\n\n**Integration:** All fixes independent, no conflicts, full suite green\n\n**Time saved:** 3 problems solved in parallel vs sequentially\n\n## Key Benefits\n\n1. **Parallelization** - Multiple investigations happen simultaneously\n2. **Focus** - Each agent has narrow scope, less context to track\n3. **Independence** - Agents don't interfere with each other\n4. **Speed** - 3 problems solved in time of 1\n\n## Verification\n\nAfter agents return:\n1. **Review each summary** - Understand what changed\n2. **Check for conflicts** - Did agents edit same code?\n3. **Run full suite** - Verify all fixes work together\n4. **Spot check** - Agents can make systematic errors\n\n## Real-World Impact\n\nFrom debugging session (2025-10-03):\n- 6 failures across 3 files\n- 3 agents dispatched in parallel\n- All investigations completed concurrently\n- All fixes integrated successfully\n- Zero conflicts between agent changes\n",
        "plugins/superpowers/skills/executing-plans/SKILL.md": "---\nname: executing-plans\ndescription: Use when you have a written implementation plan to execute with continuous task execution\n---\n\n# Executing Plans\n\n## Overview\n\nLoad plan, review critically, execute all tasks sequentially, report results.\n\n**Core principle:** Continuous execution with stops only for blockers or failures.\n\n**Announce at start:** \"I'm using the executing-plans skill to implement this plan.\"\n\n## The Process\n\n### Step 1: Load and Review Plan\n1. Read plan file\n2. Review critically - identify any questions or concerns about the plan\n3. If concerns: Raise them with your human partner before starting\n4. If no concerns: Create TodoWrite and proceed\n\n### Step 2: Execute All Tasks\n\nFor each task sequentially:\n1. Mark as in_progress\n2. Follow each step exactly (plan has bite-sized steps)\n3. Run verifications as specified\n4. Mark as completed\n\n### Step 3: Final Report\n\nAfter all tasks complete:\n- Show what was implemented\n- Show verification output\n- Summarize any issues encountered along the way\n- Say: \"All tasks complete. Ready for feedback.\"\n\n### Step 4: Complete Development\n\nAfter all tasks complete and verified:\n- Announce: \"I'm using the finishing-a-development-branch skill to complete this work.\"\n- **REQUIRED SUB-SKILL:** Use superpowers:finishing-a-development-branch\n- Follow that skill to verify tests, present options, execute choice\n\n## When to Stop and Ask for Help\n\n**STOP executing immediately when:**\n- Hit a blocker (missing dependency, test fails, instruction unclear)\n- Plan has critical gaps preventing starting\n- You don't understand an instruction\n- Verification fails repeatedly\n\n**Ask for clarification rather than guessing.**\n\n## When to Revisit Earlier Steps\n\n**Return to Review (Step 1) when:**\n- Partner updates the plan based on your feedback\n- Fundamental approach needs rethinking\n\n**Don't force through blockers** - stop and ask.\n\n## Remember\n- Review plan critically first\n- Follow plan steps exactly\n- Don't skip verifications\n- Reference skills when plan says to\n- Stop when blocked, don't guess\n",
        "plugins/superpowers/skills/finishing-a-development-branch/SKILL.md": "---\nname: finishing-a-development-branch\ndescription: Use when implementation is complete, all tests pass, and you need to decide how to integrate the work - guides completion of development work by presenting structured options for merge, PR, or cleanup\n---\n\n# Finishing a Development Branch\n\n## Overview\n\nGuide completion of development work by presenting clear options and handling chosen workflow.\n\n**Core principle:** Verify tests â†’ Present options â†’ Execute choice â†’ Clean up.\n\n**Announce at start:** \"I'm using the finishing-a-development-branch skill to complete this work.\"\n\n## The Process\n\n### Step 1: Verify Tests\n\n**Before presenting options, verify tests pass:**\n\n```bash\n# Run project's test suite\nnpm test / cargo test / pytest / go test ./...\n```\n\n**If tests fail:**\n```\nTests failing (<N> failures). Must fix before completing:\n\n[Show failures]\n\nCannot proceed with merge/PR until tests pass.\n```\n\nStop. Don't proceed to Step 2.\n\n**If tests pass:** Continue to Step 2.\n\n### Step 2: Determine Base Branch\n\n```bash\n# Try common base branches\ngit merge-base HEAD main 2>/dev/null || git merge-base HEAD master 2>/dev/null\n```\n\nOr ask: \"This branch split from main - is that correct?\"\n\n### Step 3: Present Options\n\nPresent exactly these 4 options:\n\n```\nImplementation complete. What would you like to do?\n\n1. Merge back to <base-branch> locally\n2. Push and create a Pull Request\n3. Keep the branch as-is (I'll handle it later)\n4. Discard this work\n\nWhich option?\n```\n\n**Don't add explanation** - keep options concise.\n\n### Step 4: Execute Choice\n\n#### Option 1: Merge Locally\n\n```bash\n# Switch to base branch\ngit checkout <base-branch>\n\n# Pull latest\ngit pull\n\n# Merge feature branch\ngit merge <feature-branch>\n\n# Verify tests on merged result\n<test command>\n\n# If tests pass\ngit branch -d <feature-branch>\n```\n\nThen: Cleanup worktree (Step 5)\n\n#### Option 2: Push and Create PR\n\n```bash\n# Push branch\ngit push -u origin <feature-branch>\n\n# Create PR\ngh pr create --title \"<title>\" --body \"$(cat <<'EOF'\n## Summary\n<2-3 bullets of what changed>\n\n## Test Plan\n- [ ] <verification steps>\nEOF\n)\"\n```\n\nThen: Cleanup worktree (Step 5)\n\n#### Option 3: Keep As-Is\n\nReport: \"Keeping branch <name>. Worktree preserved at <path>.\"\n\n**Don't cleanup worktree.**\n\n#### Option 4: Discard\n\n**Confirm first:**\n```\nThis will permanently delete:\n- Branch <name>\n- All commits: <commit-list>\n- Worktree at <path>\n\nType 'discard' to confirm.\n```\n\nWait for exact confirmation.\n\nIf confirmed:\n```bash\ngit checkout <base-branch>\ngit branch -D <feature-branch>\n```\n\nThen: Cleanup worktree (Step 5)\n\n### Step 5: Cleanup Worktree\n\n**For Options 1, 2, 4:**\n\nCheck if in worktree:\n```bash\ngit worktree list | grep $(git branch --show-current)\n```\n\nIf yes:\n```bash\ngit worktree remove <worktree-path>\n```\n\n**For Option 3:** Keep worktree.\n\n## Quick Reference\n\n| Option | Merge | Push | Keep Worktree | Cleanup Branch |\n|--------|-------|------|---------------|----------------|\n| 1. Merge locally | âœ“ | - | - | âœ“ |\n| 2. Create PR | - | âœ“ | âœ“ | - |\n| 3. Keep as-is | - | - | âœ“ | - |\n| 4. Discard | - | - | - | âœ“ (force) |\n\n## Common Mistakes\n\n**Skipping test verification**\n- **Problem:** Merge broken code, create failing PR\n- **Fix:** Always verify tests before offering options\n\n**Open-ended questions**\n- **Problem:** \"What should I do next?\" â†’ ambiguous\n- **Fix:** Present exactly 4 structured options\n\n**Automatic worktree cleanup**\n- **Problem:** Remove worktree when might need it (Option 2, 3)\n- **Fix:** Only cleanup for Options 1 and 4\n\n**No confirmation for discard**\n- **Problem:** Accidentally delete work\n- **Fix:** Require typed \"discard\" confirmation\n\n## Red Flags\n\n**Never:**\n- Proceed with failing tests\n- Merge without verifying tests on result\n- Delete work without confirmation\n- Force-push without explicit request\n\n**Always:**\n- Verify tests before offering options\n- Present exactly 4 options\n- Get typed confirmation for Option 4\n- Clean up worktree for Options 1 & 4 only\n\n## Integration\n\n**Called by:**\n- **subagent-driven-development** (Step 7) - After all tasks complete\n- **executing-plans** (Step 4) - After all tasks complete\n\n**Pairs with:**\n- **using-git-worktrees** - Cleans up worktree created by that skill\n",
        "plugins/superpowers/skills/receiving-code-review/SKILL.md": "---\nname: receiving-code-review\ndescription: Use when receiving code review feedback, before implementing suggestions, especially if feedback seems unclear or technically questionable - requires technical rigor and verification, not performative agreement or blind implementation\n---\n\n# Code Review Reception\n\n## Overview\n\nCode review requires technical evaluation, not emotional performance.\n\n**Core principle:** Verify before implementing. Ask before assuming. Technical correctness over social comfort.\n\n## The Response Pattern\n\n```\nWHEN receiving code review feedback:\n\n1. READ: Complete feedback without reacting\n2. UNDERSTAND: Restate requirement in own words (or ask)\n3. VERIFY: Check against codebase reality\n4. EVALUATE: Technically sound for THIS codebase?\n5. RESPOND: Technical acknowledgment or reasoned pushback\n6. IMPLEMENT: One item at a time, test each\n```\n\n## Forbidden Responses\n\n**NEVER:**\n- \"You're absolutely right!\" (explicit CLAUDE.md violation)\n- \"Great point!\" / \"Excellent feedback!\" (performative)\n- \"Let me implement that now\" (before verification)\n\n**INSTEAD:**\n- Restate the technical requirement\n- Ask clarifying questions\n- Push back with technical reasoning if wrong\n- Just start working (actions > words)\n\n## Handling Unclear Feedback\n\n```\nIF any item is unclear:\n  STOP - do not implement anything yet\n  ASK for clarification on unclear items\n\nWHY: Items may be related. Partial understanding = wrong implementation.\n```\n\n**Example:**\n```\nyour human partner: \"Fix 1-6\"\nYou understand 1,2,3,6. Unclear on 4,5.\n\nâŒ WRONG: Implement 1,2,3,6 now, ask about 4,5 later\nâœ… RIGHT: \"I understand items 1,2,3,6. Need clarification on 4 and 5 before proceeding.\"\n```\n\n## Source-Specific Handling\n\n### From your human partner\n- **Trusted** - implement after understanding\n- **Still ask** if scope unclear\n- **No performative agreement**\n- **Skip to action** or technical acknowledgment\n\n### From External Reviewers\n```\nBEFORE implementing:\n  1. Check: Technically correct for THIS codebase?\n  2. Check: Breaks existing functionality?\n  3. Check: Reason for current implementation?\n  4. Check: Works on all platforms/versions?\n  5. Check: Does reviewer understand full context?\n\nIF suggestion seems wrong:\n  Push back with technical reasoning\n\nIF can't easily verify:\n  Say so: \"I can't verify this without [X]. Should I [investigate/ask/proceed]?\"\n\nIF conflicts with your human partner's prior decisions:\n  Stop and discuss with your human partner first\n```\n\n**your human partner's rule:** \"External feedback - be skeptical, but check carefully\"\n\n## YAGNI Check for \"Professional\" Features\n\n```\nIF reviewer suggests \"implementing properly\":\n  grep codebase for actual usage\n\n  IF unused: \"This endpoint isn't called. Remove it (YAGNI)?\"\n  IF used: Then implement properly\n```\n\n**your human partner's rule:** \"You and reviewer both report to me. If we don't need this feature, don't add it.\"\n\n## Implementation Order\n\n```\nFOR multi-item feedback:\n  1. Clarify anything unclear FIRST\n  2. Then implement in this order:\n     - Blocking issues (breaks, security)\n     - Simple fixes (typos, imports)\n     - Complex fixes (refactoring, logic)\n  3. Test each fix individually\n  4. Verify no regressions\n```\n\n## When To Push Back\n\nPush back when:\n- Suggestion breaks existing functionality\n- Reviewer lacks full context\n- Violates YAGNI (unused feature)\n- Technically incorrect for this stack\n- Legacy/compatibility reasons exist\n- Conflicts with your human partner's architectural decisions\n\n**How to push back:**\n- Use technical reasoning, not defensiveness\n- Ask specific questions\n- Reference working tests/code\n- Involve your human partner if architectural\n\n**Signal if uncomfortable pushing back out loud:** \"Strange things are afoot at the Circle K\"\n\n## Acknowledging Correct Feedback\n\nWhen feedback IS correct:\n```\nâœ… \"Fixed. [Brief description of what changed]\"\nâœ… \"Good catch - [specific issue]. Fixed in [location].\"\nâœ… [Just fix it and show in the code]\n\nâŒ \"You're absolutely right!\"\nâŒ \"Great point!\"\nâŒ \"Thanks for catching that!\"\nâŒ \"Thanks for [anything]\"\nâŒ ANY gratitude expression\n```\n\n**Why no thanks:** Actions speak. Just fix it. The code itself shows you heard the feedback.\n\n**If you catch yourself about to write \"Thanks\":** DELETE IT. State the fix instead.\n\n## Gracefully Correcting Your Pushback\n\nIf you pushed back and were wrong:\n```\nâœ… \"You were right - I checked [X] and it does [Y]. Implementing now.\"\nâœ… \"Verified this and you're correct. My initial understanding was wrong because [reason]. Fixing.\"\n\nâŒ Long apology\nâŒ Defending why you pushed back\nâŒ Over-explaining\n```\n\nState the correction factually and move on.\n\n## Common Mistakes\n\n| Mistake | Fix |\n|---------|-----|\n| Performative agreement | State requirement or just act |\n| Blind implementation | Verify against codebase first |\n| Batch without testing | One at a time, test each |\n| Assuming reviewer is right | Check if breaks things |\n| Avoiding pushback | Technical correctness > comfort |\n| Partial implementation | Clarify all items first |\n| Can't verify, proceed anyway | State limitation, ask for direction |\n\n## Real Examples\n\n**Performative Agreement (Bad):**\n```\nReviewer: \"Remove legacy code\"\nâŒ \"You're absolutely right! Let me remove that...\"\n```\n\n**Technical Verification (Good):**\n```\nReviewer: \"Remove legacy code\"\nâœ… \"Checking... build target is 10.15+, this API needs 13+. Need legacy for backward compat. Current impl has wrong bundle ID - fix it or drop pre-13 support?\"\n```\n\n**YAGNI (Good):**\n```\nReviewer: \"Implement proper metrics tracking with database, date filters, CSV export\"\nâœ… \"Grepped codebase - nothing calls this endpoint. Remove it (YAGNI)? Or is there usage I'm missing?\"\n```\n\n**Unclear Item (Good):**\n```\nyour human partner: \"Fix items 1-6\"\nYou understand 1,2,3,6. Unclear on 4,5.\nâœ… \"Understand 1,2,3,6. Need clarification on 4 and 5 before implementing.\"\n```\n\n## GitHub Thread Replies\n\nWhen replying to inline review comments on GitHub, reply in the comment thread (`gh api repos/{owner}/{repo}/pulls/{pr}/comments/{id}/replies`), not as a top-level PR comment.\n\n## The Bottom Line\n\n**External feedback = suggestions to evaluate, not orders to follow.**\n\nVerify. Question. Then implement.\n\nNo performative agreement. Technical rigor always.\n",
        "plugins/superpowers/skills/requesting-code-review/SKILL.md": "---\nname: requesting-code-review\ndescription: Use when completing tasks, implementing major features, or before merging to verify work meets requirements\n---\n\n# Requesting Code Review\n\nDispatch superpowers:code-reviewer subagent to catch issues before they cascade.\n\n**Core principle:** Review early, review often.\n\n## When to Request Review\n\n**Mandatory:**\n- After each task in subagent-driven development\n- After completing major feature\n- Before merge to main\n\n**Optional but valuable:**\n- When stuck (fresh perspective)\n- Before refactoring (baseline check)\n- After fixing complex bug\n\n## How to Request\n\n**1. Get git SHAs:**\n```bash\nBASE_SHA=$(git rev-parse HEAD~1)  # or origin/main\nHEAD_SHA=$(git rev-parse HEAD)\n```\n\n**2. Dispatch code-reviewer subagent:**\n\nUse Task tool with superpowers:code-reviewer type, fill template at `code-reviewer.md`\n\n**Placeholders:**\n- `{WHAT_WAS_IMPLEMENTED}` - What you just built\n- `{PLAN_OR_REQUIREMENTS}` - What it should do\n- `{BASE_SHA}` - Starting commit\n- `{HEAD_SHA}` - Ending commit\n- `{DESCRIPTION}` - Brief summary\n\n**3. Act on feedback:**\n- Fix Critical issues immediately\n- Fix Important issues before proceeding\n- Note Minor issues for later\n- Push back if reviewer is wrong (with reasoning)\n\n## Example\n\n```\n[Just completed Task 2: Add verification function]\n\nYou: Let me request code review before proceeding.\n\nBASE_SHA=$(git log --oneline | grep \"Task 1\" | head -1 | awk '{print $1}')\nHEAD_SHA=$(git rev-parse HEAD)\n\n[Dispatch superpowers:code-reviewer subagent]\n  WHAT_WAS_IMPLEMENTED: Verification and repair functions for conversation index\n  PLAN_OR_REQUIREMENTS: Task 2 from docs/plans/deployment-plan.md\n  BASE_SHA: a7981ec\n  HEAD_SHA: 3df7661\n  DESCRIPTION: Added verifyIndex() and repairIndex() with 4 issue types\n\n[Subagent returns]:\n  Strengths: Clean architecture, real tests\n  Issues:\n    Important: Missing progress indicators\n    Minor: Magic number (100) for reporting interval\n  Assessment: Ready to proceed\n\nYou: [Fix progress indicators]\n[Continue to Task 3]\n```\n\n## Integration with Workflows\n\n**Subagent-Driven Development:**\n- Review after EACH task\n- Catch issues before they compound\n- Fix before moving to next task\n\n**Executing Plans:**\n- Review after all tasks complete\n- Get feedback, apply if needed\n\n**Ad-Hoc Development:**\n- Review before merge\n- Review when stuck\n\n## Red Flags\n\n**Never:**\n- Skip review because \"it's simple\"\n- Ignore Critical issues\n- Proceed with unfixed Important issues\n- Argue with valid technical feedback\n\n**If reviewer wrong:**\n- Push back with technical reasoning\n- Show code/tests that prove it works\n- Request clarification\n\nSee template at: requesting-code-review/code-reviewer.md\n",
        "plugins/superpowers/skills/requesting-code-review/code-reviewer.md": "# Code Review Agent\n\nYou are reviewing code changes for production readiness.\n\n**Your task:**\n1. Review {WHAT_WAS_IMPLEMENTED}\n2. Compare against {PLAN_OR_REQUIREMENTS}\n3. Check code quality, architecture, testing\n4. Categorize issues by severity\n5. Assess production readiness\n\n## What Was Implemented\n\n{DESCRIPTION}\n\n## Requirements/Plan\n\n{PLAN_REFERENCE}\n\n## Git Range to Review\n\n**Base:** {BASE_SHA}\n**Head:** {HEAD_SHA}\n\n```bash\ngit diff --stat {BASE_SHA}..{HEAD_SHA}\ngit diff {BASE_SHA}..{HEAD_SHA}\n```\n\n## Review Checklist\n\n**Code Quality:**\n- Clean separation of concerns?\n- Proper error handling?\n- Type safety (if applicable)?\n- DRY principle followed?\n- Edge cases handled?\n\n**Architecture:**\n- Sound design decisions?\n- Scalability considerations?\n- Performance implications?\n- Security concerns?\n\n**Testing:**\n- Tests actually test logic (not mocks)?\n- Edge cases covered?\n- Integration tests where needed?\n- All tests passing?\n\n**Requirements:**\n- All plan requirements met?\n- Implementation matches spec?\n- No scope creep?\n- Breaking changes documented?\n\n**Production Readiness:**\n- Migration strategy (if schema changes)?\n- Backward compatibility considered?\n- Documentation complete?\n- No obvious bugs?\n\n## Output Format\n\n### Strengths\n[What's well done? Be specific.]\n\n### Issues\n\n#### Critical (Must Fix)\n[Bugs, security issues, data loss risks, broken functionality]\n\n#### Important (Should Fix)\n[Architecture problems, missing features, poor error handling, test gaps]\n\n#### Minor (Nice to Have)\n[Code style, optimization opportunities, documentation improvements]\n\n**For each issue:**\n- File:line reference\n- What's wrong\n- Why it matters\n- How to fix (if not obvious)\n\n### Recommendations\n[Improvements for code quality, architecture, or process]\n\n### Assessment\n\n**Ready to merge?** [Yes/No/With fixes]\n\n**Reasoning:** [Technical assessment in 1-2 sentences]\n\n## Critical Rules\n\n**DO:**\n- Categorize by actual severity (not everything is Critical)\n- Be specific (file:line, not vague)\n- Explain WHY issues matter\n- Acknowledge strengths\n- Give clear verdict\n\n**DON'T:**\n- Say \"looks good\" without checking\n- Mark nitpicks as Critical\n- Give feedback on code you didn't review\n- Be vague (\"improve error handling\")\n- Avoid giving a clear verdict\n\n## Example Output\n\n```\n### Strengths\n- Clean database schema with proper migrations (db.ts:15-42)\n- Comprehensive test coverage (18 tests, all edge cases)\n- Good error handling with fallbacks (summarizer.ts:85-92)\n\n### Issues\n\n#### Important\n1. **Missing help text in CLI wrapper**\n   - File: index-conversations:1-31\n   - Issue: No --help flag, users won't discover --concurrency\n   - Fix: Add --help case with usage examples\n\n2. **Date validation missing**\n   - File: search.ts:25-27\n   - Issue: Invalid dates silently return no results\n   - Fix: Validate ISO format, throw error with example\n\n#### Minor\n1. **Progress indicators**\n   - File: indexer.ts:130\n   - Issue: No \"X of Y\" counter for long operations\n   - Impact: Users don't know how long to wait\n\n### Recommendations\n- Add progress reporting for user experience\n- Consider config file for excluded projects (portability)\n\n### Assessment\n\n**Ready to merge: With fixes**\n\n**Reasoning:** Core implementation is solid with good architecture and tests. Important issues (help text, date validation) are easily fixed and don't affect core functionality.\n```\n",
        "plugins/superpowers/skills/subagent-driven-development/SKILL.md": "---\nname: subagent-driven-development\ndescription: Use when executing implementation plans with independent tasks in the current session\n---\n\n# Subagent-Driven Development\n\nExecute plan by dispatching fresh subagent per task, with two-stage review after each: spec compliance review first, then code quality review.\n\n**Core principle:** Fresh subagent per task + two-stage review (spec then quality) = high quality, fast iteration\n\n## When to Use\n\n```dot\ndigraph when_to_use {\n    \"Have implementation plan?\" [shape=diamond];\n    \"Tasks mostly independent?\" [shape=diamond];\n    \"Stay in this session?\" [shape=diamond];\n    \"subagent-driven-development\" [shape=box];\n    \"executing-plans\" [shape=box];\n    \"Manual execution or brainstorm first\" [shape=box];\n\n    \"Have implementation plan?\" -> \"Tasks mostly independent?\" [label=\"yes\"];\n    \"Have implementation plan?\" -> \"Manual execution or brainstorm first\" [label=\"no\"];\n    \"Tasks mostly independent?\" -> \"Stay in this session?\" [label=\"yes\"];\n    \"Tasks mostly independent?\" -> \"Manual execution or brainstorm first\" [label=\"no - tightly coupled\"];\n    \"Stay in this session?\" -> \"subagent-driven-development\" [label=\"yes\"];\n    \"Stay in this session?\" -> \"executing-plans\" [label=\"no - parallel session\"];\n}\n```\n\n**vs. Executing Plans (parallel session):**\n- Same session (no context switch)\n- Fresh subagent per task (no context pollution)\n- Two-stage review after each task: spec compliance first, then code quality\n- Faster iteration (no human-in-loop between tasks)\n\n## The Process\n\n```dot\ndigraph process {\n    rankdir=TB;\n\n    subgraph cluster_per_task {\n        label=\"Per Task\";\n        \"Dispatch implementer subagent (./implementer-prompt.md)\" [shape=box];\n        \"Implementer subagent asks questions?\" [shape=diamond];\n        \"Answer questions, provide context\" [shape=box];\n        \"Implementer subagent implements, tests, commits, self-reviews\" [shape=box];\n        \"Dispatch spec reviewer subagent (./spec-reviewer-prompt.md)\" [shape=box];\n        \"Spec reviewer subagent confirms code matches spec?\" [shape=diamond];\n        \"Implementer subagent fixes spec gaps\" [shape=box];\n        \"Dispatch code quality reviewer subagent (./code-quality-reviewer-prompt.md)\" [shape=box];\n        \"Code quality reviewer subagent approves?\" [shape=diamond];\n        \"Implementer subagent fixes quality issues\" [shape=box];\n        \"Mark task complete in TodoWrite\" [shape=box];\n    }\n\n    \"Read plan, extract all tasks with full text, note context, create TodoWrite\" [shape=box];\n    \"More tasks remain?\" [shape=diamond];\n    \"Dispatch final code reviewer subagent for entire implementation\" [shape=box];\n    \"Use superpowers:finishing-a-development-branch\" [shape=box style=filled fillcolor=lightgreen];\n\n    \"Read plan, extract all tasks with full text, note context, create TodoWrite\" -> \"Dispatch implementer subagent (./implementer-prompt.md)\";\n    \"Dispatch implementer subagent (./implementer-prompt.md)\" -> \"Implementer subagent asks questions?\";\n    \"Implementer subagent asks questions?\" -> \"Answer questions, provide context\" [label=\"yes\"];\n    \"Answer questions, provide context\" -> \"Dispatch implementer subagent (./implementer-prompt.md)\";\n    \"Implementer subagent asks questions?\" -> \"Implementer subagent implements, tests, commits, self-reviews\" [label=\"no\"];\n    \"Implementer subagent implements, tests, commits, self-reviews\" -> \"Dispatch spec reviewer subagent (./spec-reviewer-prompt.md)\";\n    \"Dispatch spec reviewer subagent (./spec-reviewer-prompt.md)\" -> \"Spec reviewer subagent confirms code matches spec?\";\n    \"Spec reviewer subagent confirms code matches spec?\" -> \"Implementer subagent fixes spec gaps\" [label=\"no\"];\n    \"Implementer subagent fixes spec gaps\" -> \"Dispatch spec reviewer subagent (./spec-reviewer-prompt.md)\" [label=\"re-review\"];\n    \"Spec reviewer subagent confirms code matches spec?\" -> \"Dispatch code quality reviewer subagent (./code-quality-reviewer-prompt.md)\" [label=\"yes\"];\n    \"Dispatch code quality reviewer subagent (./code-quality-reviewer-prompt.md)\" -> \"Code quality reviewer subagent approves?\";\n    \"Code quality reviewer subagent approves?\" -> \"Implementer subagent fixes quality issues\" [label=\"no\"];\n    \"Implementer subagent fixes quality issues\" -> \"Dispatch code quality reviewer subagent (./code-quality-reviewer-prompt.md)\" [label=\"re-review\"];\n    \"Code quality reviewer subagent approves?\" -> \"Mark task complete in TodoWrite\" [label=\"yes\"];\n    \"Mark task complete in TodoWrite\" -> \"More tasks remain?\";\n    \"More tasks remain?\" -> \"Dispatch implementer subagent (./implementer-prompt.md)\" [label=\"yes\"];\n    \"More tasks remain?\" -> \"Dispatch final code reviewer subagent for entire implementation\" [label=\"no\"];\n    \"Dispatch final code reviewer subagent for entire implementation\" -> \"Use superpowers:finishing-a-development-branch\";\n}\n```\n\n## Prompt Templates\n\n- `./implementer-prompt.md` - Dispatch implementer subagent\n- `./spec-reviewer-prompt.md` - Dispatch spec compliance reviewer subagent\n- `./code-quality-reviewer-prompt.md` - Dispatch code quality reviewer subagent\n\n## Example Workflow\n\n```\nYou: I'm using Subagent-Driven Development to execute this plan.\n\n[Read plan file once: docs/plans/feature-plan.md]\n[Extract all 5 tasks with full text and context]\n[Create TodoWrite with all tasks]\n\nTask 1: Hook installation script\n\n[Get Task 1 text and context (already extracted)]\n[Dispatch implementation subagent with full task text + context]\n\nImplementer: \"Before I begin - should the hook be installed at user or system level?\"\n\nYou: \"User level (~/.config/superpowers/hooks/)\"\n\nImplementer: \"Got it. Implementing now...\"\n[Later] Implementer:\n  - Implemented install-hook command\n  - Added tests, 5/5 passing\n  - Self-review: Found I missed --force flag, added it\n  - Committed\n\n[Dispatch spec compliance reviewer]\nSpec reviewer: âœ… Spec compliant - all requirements met, nothing extra\n\n[Get git SHAs, dispatch code quality reviewer]\nCode reviewer: Strengths: Good test coverage, clean. Issues: None. Approved.\n\n[Mark Task 1 complete]\n\nTask 2: Recovery modes\n\n[Get Task 2 text and context (already extracted)]\n[Dispatch implementation subagent with full task text + context]\n\nImplementer: [No questions, proceeds]\nImplementer:\n  - Added verify/repair modes\n  - 8/8 tests passing\n  - Self-review: All good\n  - Committed\n\n[Dispatch spec compliance reviewer]\nSpec reviewer: âŒ Issues:\n  - Missing: Progress reporting (spec says \"report every 100 items\")\n  - Extra: Added --json flag (not requested)\n\n[Implementer fixes issues]\nImplementer: Removed --json flag, added progress reporting\n\n[Spec reviewer reviews again]\nSpec reviewer: âœ… Spec compliant now\n\n[Dispatch code quality reviewer]\nCode reviewer: Strengths: Solid. Issues (Important): Magic number (100)\n\n[Implementer fixes]\nImplementer: Extracted PROGRESS_INTERVAL constant\n\n[Code reviewer reviews again]\nCode reviewer: âœ… Approved\n\n[Mark Task 2 complete]\n\n...\n\n[After all tasks]\n[Dispatch final code-reviewer]\nFinal reviewer: All requirements met, ready to merge\n\nDone!\n```\n\n## Advantages\n\n**vs. Manual execution:**\n- Subagents follow TDD naturally\n- Fresh context per task (no confusion)\n- Parallel-safe (subagents don't interfere)\n- Subagent can ask questions (before AND during work)\n\n**vs. Executing Plans:**\n- Same session (no handoff)\n- Continuous progress (no waiting)\n- Review checkpoints automatic\n\n**Efficiency gains:**\n- No file reading overhead (controller provides full text)\n- Controller curates exactly what context is needed\n- Subagent gets complete information upfront\n- Questions surfaced before work begins (not after)\n\n**Quality gates:**\n- Self-review catches issues before handoff\n- Two-stage review: spec compliance, then code quality\n- Review loops ensure fixes actually work\n- Spec compliance prevents over/under-building\n- Code quality ensures implementation is well-built\n\n**Cost:**\n- More subagent invocations (implementer + 2 reviewers per task)\n- Controller does more prep work (extracting all tasks upfront)\n- Review loops add iterations\n- But catches issues early (cheaper than debugging later)\n\n## Red Flags\n\n**Never:**\n- Skip reviews (spec compliance OR code quality)\n- Proceed with unfixed issues\n- Dispatch multiple implementation subagents in parallel (conflicts)\n- Make subagent read plan file (provide full text instead)\n- Skip scene-setting context (subagent needs to understand where task fits)\n- Ignore subagent questions (answer before letting them proceed)\n- Accept \"close enough\" on spec compliance (spec reviewer found issues = not done)\n- Skip review loops (reviewer found issues = implementer fixes = review again)\n- Let implementer self-review replace actual review (both are needed)\n- **Start code quality review before spec compliance is âœ…** (wrong order)\n- Move to next task while either review has open issues\n\n**If subagent asks questions:**\n- Answer clearly and completely\n- Provide additional context if needed\n- Don't rush them into implementation\n\n**If reviewer finds issues:**\n- Implementer (same subagent) fixes them\n- Reviewer reviews again\n- Repeat until approved\n- Don't skip the re-review\n\n**If subagent fails task:**\n- Dispatch fix subagent with specific instructions\n- Don't try to fix manually (context pollution)\n\n## Integration\n\n**Required workflow skills:**\n- **superpowers:writing-plans** - Creates the plan this skill executes\n- **superpowers:requesting-code-review** - Code review template for reviewer subagents\n- **superpowers:finishing-a-development-branch** - Complete development after all tasks\n\n**Subagents should use:**\n- **superpowers:test-driven-development** - Subagents follow TDD for each task\n\n**Alternative workflow:**\n- **superpowers:executing-plans** - Use for parallel session instead of same-session execution\n",
        "plugins/superpowers/skills/subagent-driven-development/code-quality-reviewer-prompt.md": "# Code Quality Reviewer Prompt Template\n\nUse this template when dispatching a code quality reviewer subagent.\n\n**Purpose:** Verify implementation is well-built (clean, tested, maintainable)\n\n**Only dispatch after spec compliance review passes.**\n\n```\nTask tool (superpowers:code-reviewer):\n  Use template at requesting-code-review/code-reviewer.md\n\n  WHAT_WAS_IMPLEMENTED: [from implementer's report]\n  PLAN_OR_REQUIREMENTS: Task N from [plan-file]\n  BASE_SHA: [commit before task]\n  HEAD_SHA: [current commit]\n  DESCRIPTION: [task summary]\n```\n\n**Code reviewer returns:** Strengths, Issues (Critical/Important/Minor), Assessment\n",
        "plugins/superpowers/skills/subagent-driven-development/implementer-prompt.md": "# Implementer Subagent Prompt Template\n\nUse this template when dispatching an implementer subagent.\n\n```\nTask tool (general-purpose):\n  description: \"Implement Task N: [task name]\"\n  prompt: |\n    You are implementing Task N: [task name]\n\n    ## Task Description\n\n    [FULL TEXT of task from plan - paste it here, don't make subagent read file]\n\n    ## Context\n\n    [Scene-setting: where this fits, dependencies, architectural context]\n\n    ## Before You Begin\n\n    If you have questions about:\n    - The requirements or acceptance criteria\n    - The approach or implementation strategy\n    - Dependencies or assumptions\n    - Anything unclear in the task description\n\n    **Ask them now.** Raise any concerns before starting work.\n\n    ## Your Job\n\n    Once you're clear on requirements:\n    1. Implement exactly what the task specifies\n    2. Write tests (following TDD if task says to)\n    3. Verify implementation works\n    4. Commit your work\n    5. Self-review (see below)\n    6. Report back\n\n    Work from: [directory]\n\n    **While you work:** If you encounter something unexpected or unclear, **ask questions**.\n    It's always OK to pause and clarify. Don't guess or make assumptions.\n\n    ## Before Reporting Back: Self-Review\n\n    Review your work with fresh eyes. Ask yourself:\n\n    **Completeness:**\n    - Did I fully implement everything in the spec?\n    - Did I miss any requirements?\n    - Are there edge cases I didn't handle?\n\n    **Quality:**\n    - Is this my best work?\n    - Are names clear and accurate (match what things do, not how they work)?\n    - Is the code clean and maintainable?\n\n    **Discipline:**\n    - Did I avoid overbuilding (YAGNI)?\n    - Did I only build what was requested?\n    - Did I follow existing patterns in the codebase?\n\n    **Testing:**\n    - Do tests actually verify behavior (not just mock behavior)?\n    - Did I follow TDD if required?\n    - Are tests comprehensive?\n\n    If you find issues during self-review, fix them now before reporting.\n\n    ## Report Format\n\n    When done, report:\n    - What you implemented\n    - What you tested and test results\n    - Files changed\n    - Self-review findings (if any)\n    - Any issues or concerns\n```\n",
        "plugins/superpowers/skills/subagent-driven-development/spec-reviewer-prompt.md": "# Spec Compliance Reviewer Prompt Template\n\nUse this template when dispatching a spec compliance reviewer subagent.\n\n**Purpose:** Verify implementer built what was requested (nothing more, nothing less)\n\n```\nTask tool (general-purpose):\n  description: \"Review spec compliance for Task N\"\n  prompt: |\n    You are reviewing whether an implementation matches its specification.\n\n    ## What Was Requested\n\n    [FULL TEXT of task requirements]\n\n    ## What Implementer Claims They Built\n\n    [From implementer's report]\n\n    ## CRITICAL: Do Not Trust the Report\n\n    The implementer finished suspiciously quickly. Their report may be incomplete,\n    inaccurate, or optimistic. You MUST verify everything independently.\n\n    **DO NOT:**\n    - Take their word for what they implemented\n    - Trust their claims about completeness\n    - Accept their interpretation of requirements\n\n    **DO:**\n    - Read the actual code they wrote\n    - Compare actual implementation to requirements line by line\n    - Check for missing pieces they claimed to implement\n    - Look for extra features they didn't mention\n\n    ## Your Job\n\n    Read the implementation code and verify:\n\n    **Missing requirements:**\n    - Did they implement everything that was requested?\n    - Are there requirements they skipped or missed?\n    - Did they claim something works but didn't actually implement it?\n\n    **Extra/unneeded work:**\n    - Did they build things that weren't requested?\n    - Did they over-engineer or add unnecessary features?\n    - Did they add \"nice to haves\" that weren't in spec?\n\n    **Misunderstandings:**\n    - Did they interpret requirements differently than intended?\n    - Did they solve the wrong problem?\n    - Did they implement the right feature but wrong way?\n\n    **Verify by reading code, not by trusting report.**\n\n    Report:\n    - âœ… Spec compliant (if everything matches after code inspection)\n    - âŒ Issues found: [list specifically what's missing or extra, with file:line references]\n```\n",
        "plugins/superpowers/skills/systematic-debugging/CREATION-LOG.md": "# Creation Log: Systematic Debugging Skill\n\nReference example of extracting, structuring, and bulletproofing a critical skill.\n\n## Source Material\n\nExtracted debugging framework from `/Users/jesse/.claude/CLAUDE.md`:\n- 4-phase systematic process (Investigation â†’ Pattern Analysis â†’ Hypothesis â†’ Implementation)\n- Core mandate: ALWAYS find root cause, NEVER fix symptoms\n- Rules designed to resist time pressure and rationalization\n\n## Extraction Decisions\n\n**What to include:**\n- Complete 4-phase framework with all rules\n- Anti-shortcuts (\"NEVER fix symptom\", \"STOP and re-analyze\")\n- Pressure-resistant language (\"even if faster\", \"even if I seem in a hurry\")\n- Concrete steps for each phase\n\n**What to leave out:**\n- Project-specific context\n- Repetitive variations of same rule\n- Narrative explanations (condensed to principles)\n\n## Structure Following skill-creation/SKILL.md\n\n1. **Rich when_to_use** - Included symptoms and anti-patterns\n2. **Type: technique** - Concrete process with steps\n3. **Keywords** - \"root cause\", \"symptom\", \"workaround\", \"debugging\", \"investigation\"\n4. **Flowchart** - Decision point for \"fix failed\" â†’ re-analyze vs add more fixes\n5. **Phase-by-phase breakdown** - Scannable checklist format\n6. **Anti-patterns section** - What NOT to do (critical for this skill)\n\n## Bulletproofing Elements\n\nFramework designed to resist rationalization under pressure:\n\n### Language Choices\n- \"ALWAYS\" / \"NEVER\" (not \"should\" / \"try to\")\n- \"even if faster\" / \"even if I seem in a hurry\"\n- \"STOP and re-analyze\" (explicit pause)\n- \"Don't skip past\" (catches the actual behavior)\n\n### Structural Defenses\n- **Phase 1 required** - Can't skip to implementation\n- **Single hypothesis rule** - Forces thinking, prevents shotgun fixes\n- **Explicit failure mode** - \"IF your first fix doesn't work\" with mandatory action\n- **Anti-patterns section** - Shows exactly what shortcuts look like\n\n### Redundancy\n- Root cause mandate in overview + when_to_use + Phase 1 + implementation rules\n- \"NEVER fix symptom\" appears 4 times in different contexts\n- Each phase has explicit \"don't skip\" guidance\n\n## Testing Approach\n\nCreated 4 validation tests following skills/meta/testing-skills-with-subagents:\n\n### Test 1: Academic Context (No Pressure)\n- Simple bug, no time pressure\n- **Result:** Perfect compliance, complete investigation\n\n### Test 2: Time Pressure + Obvious Quick Fix\n- User \"in a hurry\", symptom fix looks easy\n- **Result:** Resisted shortcut, followed full process, found real root cause\n\n### Test 3: Complex System + Uncertainty\n- Multi-layer failure, unclear if can find root cause\n- **Result:** Systematic investigation, traced through all layers, found source\n\n### Test 4: Failed First Fix\n- Hypothesis doesn't work, temptation to add more fixes\n- **Result:** Stopped, re-analyzed, formed new hypothesis (no shotgun)\n\n**All tests passed.** No rationalizations found.\n\n## Iterations\n\n### Initial Version\n- Complete 4-phase framework\n- Anti-patterns section\n- Flowchart for \"fix failed\" decision\n\n### Enhancement 1: TDD Reference\n- Added link to skills/testing/test-driven-development\n- Note explaining TDD's \"simplest code\" â‰  debugging's \"root cause\"\n- Prevents confusion between methodologies\n\n## Final Outcome\n\nBulletproof skill that:\n- âœ… Clearly mandates root cause investigation\n- âœ… Resists time pressure rationalization\n- âœ… Provides concrete steps for each phase\n- âœ… Shows anti-patterns explicitly\n- âœ… Tested under multiple pressure scenarios\n- âœ… Clarifies relationship to TDD\n- âœ… Ready for use\n\n## Key Insight\n\n**Most important bulletproofing:** Anti-patterns section showing exact shortcuts that feel justified in the moment. When Claude thinks \"I'll just add this one quick fix\", seeing that exact pattern listed as wrong creates cognitive friction.\n\n## Usage Example\n\nWhen encountering a bug:\n1. Load skill: skills/debugging/systematic-debugging\n2. Read overview (10 sec) - reminded of mandate\n3. Follow Phase 1 checklist - forced investigation\n4. If tempted to skip - see anti-pattern, stop\n5. Complete all phases - root cause found\n\n**Time investment:** 5-10 minutes\n**Time saved:** Hours of symptom-whack-a-mole\n\n---\n\n*Created: 2025-10-03*\n*Purpose: Reference example for skill extraction and bulletproofing*\n",
        "plugins/superpowers/skills/systematic-debugging/SKILL.md": "---\nname: systematic-debugging\ndescription: Use when encountering any bug, test failure, or unexpected behavior, before proposing fixes\n---\n\n# Systematic Debugging\n\n## Overview\n\nRandom fixes waste time and create new bugs. Quick patches mask underlying issues.\n\n**Core principle:** ALWAYS find root cause before attempting fixes. Symptom fixes are failure.\n\n**Violating the letter of this process is violating the spirit of debugging.**\n\n## The Iron Law\n\n```\nNO FIXES WITHOUT ROOT CAUSE INVESTIGATION FIRST\n```\n\nIf you haven't completed Phase 1, you cannot propose fixes.\n\n## When to Use\n\nUse for ANY technical issue:\n- Test failures\n- Bugs in production\n- Unexpected behavior\n- Performance problems\n- Build failures\n- Integration issues\n\n**Use this ESPECIALLY when:**\n- Under time pressure (emergencies make guessing tempting)\n- \"Just one quick fix\" seems obvious\n- You've already tried multiple fixes\n- Previous fix didn't work\n- You don't fully understand the issue\n\n**Don't skip when:**\n- Issue seems simple (simple bugs have root causes too)\n- You're in a hurry (rushing guarantees rework)\n- Manager wants it fixed NOW (systematic is faster than thrashing)\n\n## The Four Phases\n\nYou MUST complete each phase before proceeding to the next.\n\n### Phase 1: Root Cause Investigation\n\n**BEFORE attempting ANY fix:**\n\n1. **Read Error Messages Carefully**\n   - Don't skip past errors or warnings\n   - They often contain the exact solution\n   - Read stack traces completely\n   - Note line numbers, file paths, error codes\n\n2. **Reproduce Consistently**\n   - Can you trigger it reliably?\n   - What are the exact steps?\n   - Does it happen every time?\n   - If not reproducible â†’ gather more data, don't guess\n\n3. **Check Recent Changes**\n   - What changed that could cause this?\n   - Git diff, recent commits\n   - New dependencies, config changes\n   - Environmental differences\n\n4. **Gather Evidence in Multi-Component Systems**\n\n   **WHEN system has multiple components (CI â†’ build â†’ signing, API â†’ service â†’ database):**\n\n   **BEFORE proposing fixes, add diagnostic instrumentation:**\n   ```\n   For EACH component boundary:\n     - Log what data enters component\n     - Log what data exits component\n     - Verify environment/config propagation\n     - Check state at each layer\n\n   Run once to gather evidence showing WHERE it breaks\n   THEN analyze evidence to identify failing component\n   THEN investigate that specific component\n   ```\n\n   **Example (multi-layer system):**\n   ```bash\n   # Layer 1: Workflow\n   echo \"=== Secrets available in workflow: ===\"\n   echo \"IDENTITY: ${IDENTITY:+SET}${IDENTITY:-UNSET}\"\n\n   # Layer 2: Build script\n   echo \"=== Env vars in build script: ===\"\n   env | grep IDENTITY || echo \"IDENTITY not in environment\"\n\n   # Layer 3: Signing script\n   echo \"=== Keychain state: ===\"\n   security list-keychains\n   security find-identity -v\n\n   # Layer 4: Actual signing\n   codesign --sign \"$IDENTITY\" --verbose=4 \"$APP\"\n   ```\n\n   **This reveals:** Which layer fails (secrets â†’ workflow âœ“, workflow â†’ build âœ—)\n\n5. **Trace Data Flow**\n\n   **WHEN error is deep in call stack:**\n\n   See `root-cause-tracing.md` in this directory for the complete backward tracing technique.\n\n   **Quick version:**\n   - Where does bad value originate?\n   - What called this with bad value?\n   - Keep tracing up until you find the source\n   - Fix at source, not at symptom\n\n### Phase 2: Pattern Analysis\n\n**Find the pattern before fixing:**\n\n1. **Find Working Examples**\n   - Locate similar working code in same codebase\n   - What works that's similar to what's broken?\n\n2. **Compare Against References**\n   - If implementing pattern, read reference implementation COMPLETELY\n   - Don't skim - read every line\n   - Understand the pattern fully before applying\n\n3. **Identify Differences**\n   - What's different between working and broken?\n   - List every difference, however small\n   - Don't assume \"that can't matter\"\n\n4. **Understand Dependencies**\n   - What other components does this need?\n   - What settings, config, environment?\n   - What assumptions does it make?\n\n### Phase 3: Hypothesis and Testing\n\n**Scientific method:**\n\n1. **Form Single Hypothesis**\n   - State clearly: \"I think X is the root cause because Y\"\n   - Write it down\n   - Be specific, not vague\n\n2. **Test Minimally**\n   - Make the SMALLEST possible change to test hypothesis\n   - One variable at a time\n   - Don't fix multiple things at once\n\n3. **Verify Before Continuing**\n   - Did it work? Yes â†’ Phase 4\n   - Didn't work? Form NEW hypothesis\n   - DON'T add more fixes on top\n\n4. **When You Don't Know**\n   - Say \"I don't understand X\"\n   - Don't pretend to know\n   - Ask for help\n   - Research more\n\n### Phase 4: Implementation\n\n**Fix the root cause, not the symptom:**\n\n1. **Create Failing Test Case**\n   - Simplest possible reproduction\n   - Automated test if possible\n   - One-off test script if no framework\n   - MUST have before fixing\n   - Use the `superpowers:test-driven-development` skill for writing proper failing tests\n\n2. **Implement Single Fix**\n   - Address the root cause identified\n   - ONE change at a time\n   - No \"while I'm here\" improvements\n   - No bundled refactoring\n\n3. **Verify Fix**\n   - Test passes now?\n   - No other tests broken?\n   - Issue actually resolved?\n\n4. **If Fix Doesn't Work**\n   - STOP\n   - Count: How many fixes have you tried?\n   - If < 3: Return to Phase 1, re-analyze with new information\n   - **If â‰¥ 3: STOP and question the architecture (step 5 below)**\n   - DON'T attempt Fix #4 without architectural discussion\n\n5. **If 3+ Fixes Failed: Question Architecture**\n\n   **Pattern indicating architectural problem:**\n   - Each fix reveals new shared state/coupling/problem in different place\n   - Fixes require \"massive refactoring\" to implement\n   - Each fix creates new symptoms elsewhere\n\n   **STOP and question fundamentals:**\n   - Is this pattern fundamentally sound?\n   - Are we \"sticking with it through sheer inertia\"?\n   - Should we refactor architecture vs. continue fixing symptoms?\n\n   **Discuss with your human partner before attempting more fixes**\n\n   This is NOT a failed hypothesis - this is a wrong architecture.\n\n## Red Flags - STOP and Follow Process\n\nIf you catch yourself thinking:\n- \"Quick fix for now, investigate later\"\n- \"Just try changing X and see if it works\"\n- \"Add multiple changes, run tests\"\n- \"Skip the test, I'll manually verify\"\n- \"It's probably X, let me fix that\"\n- \"I don't fully understand but this might work\"\n- \"Pattern says X but I'll adapt it differently\"\n- \"Here are the main problems: [lists fixes without investigation]\"\n- Proposing solutions before tracing data flow\n- **\"One more fix attempt\" (when already tried 2+)**\n- **Each fix reveals new problem in different place**\n\n**ALL of these mean: STOP. Return to Phase 1.**\n\n**If 3+ fixes failed:** Question the architecture (see Phase 4.5)\n\n## your human partner's Signals You're Doing It Wrong\n\n**Watch for these redirections:**\n- \"Is that not happening?\" - You assumed without verifying\n- \"Will it show us...?\" - You should have added evidence gathering\n- \"Stop guessing\" - You're proposing fixes without understanding\n- \"Ultrathink this\" - Question fundamentals, not just symptoms\n- \"We're stuck?\" (frustrated) - Your approach isn't working\n\n**When you see these:** STOP. Return to Phase 1.\n\n## Common Rationalizations\n\n| Excuse | Reality |\n|--------|---------|\n| \"Issue is simple, don't need process\" | Simple issues have root causes too. Process is fast for simple bugs. |\n| \"Emergency, no time for process\" | Systematic debugging is FASTER than guess-and-check thrashing. |\n| \"Just try this first, then investigate\" | First fix sets the pattern. Do it right from the start. |\n| \"I'll write test after confirming fix works\" | Untested fixes don't stick. Test first proves it. |\n| \"Multiple fixes at once saves time\" | Can't isolate what worked. Causes new bugs. |\n| \"Reference too long, I'll adapt the pattern\" | Partial understanding guarantees bugs. Read it completely. |\n| \"I see the problem, let me fix it\" | Seeing symptoms â‰  understanding root cause. |\n| \"One more fix attempt\" (after 2+ failures) | 3+ failures = architectural problem. Question pattern, don't fix again. |\n\n## Quick Reference\n\n| Phase | Key Activities | Success Criteria |\n|-------|---------------|------------------|\n| **1. Root Cause** | Read errors, reproduce, check changes, gather evidence | Understand WHAT and WHY |\n| **2. Pattern** | Find working examples, compare | Identify differences |\n| **3. Hypothesis** | Form theory, test minimally | Confirmed or new hypothesis |\n| **4. Implementation** | Create test, fix, verify | Bug resolved, tests pass |\n\n## When Process Reveals \"No Root Cause\"\n\nIf systematic investigation reveals issue is truly environmental, timing-dependent, or external:\n\n1. You've completed the process\n2. Document what you investigated\n3. Implement appropriate handling (retry, timeout, error message)\n4. Add monitoring/logging for future investigation\n\n**But:** 95% of \"no root cause\" cases are incomplete investigation.\n\n## Supporting Techniques\n\nThese techniques are part of systematic debugging and available in this directory:\n\n- **`root-cause-tracing.md`** - Trace bugs backward through call stack to find original trigger\n- **`defense-in-depth.md`** - Add validation at multiple layers after finding root cause\n- **`condition-based-waiting.md`** - Replace arbitrary timeouts with condition polling\n\n**Related skills:**\n- **superpowers:test-driven-development** - For creating failing test case (Phase 4, Step 1)\n- **superpowers:verification-before-completion** - Verify fix worked before claiming success\n\n## Real-World Impact\n\nFrom debugging sessions:\n- Systematic approach: 15-30 minutes to fix\n- Random fixes approach: 2-3 hours of thrashing\n- First-time fix rate: 95% vs 40%\n- New bugs introduced: Near zero vs common\n",
        "plugins/superpowers/skills/systematic-debugging/condition-based-waiting.md": "# Condition-Based Waiting\n\n## Overview\n\nFlaky tests often guess at timing with arbitrary delays. This creates race conditions where tests pass on fast machines but fail under load or in CI.\n\n**Core principle:** Wait for the actual condition you care about, not a guess about how long it takes.\n\n## When to Use\n\n```dot\ndigraph when_to_use {\n    \"Test uses setTimeout/sleep?\" [shape=diamond];\n    \"Testing timing behavior?\" [shape=diamond];\n    \"Document WHY timeout needed\" [shape=box];\n    \"Use condition-based waiting\" [shape=box];\n\n    \"Test uses setTimeout/sleep?\" -> \"Testing timing behavior?\" [label=\"yes\"];\n    \"Testing timing behavior?\" -> \"Document WHY timeout needed\" [label=\"yes\"];\n    \"Testing timing behavior?\" -> \"Use condition-based waiting\" [label=\"no\"];\n}\n```\n\n**Use when:**\n- Tests have arbitrary delays (`setTimeout`, `sleep`, `time.sleep()`)\n- Tests are flaky (pass sometimes, fail under load)\n- Tests timeout when run in parallel\n- Waiting for async operations to complete\n\n**Don't use when:**\n- Testing actual timing behavior (debounce, throttle intervals)\n- Always document WHY if using arbitrary timeout\n\n## Core Pattern\n\n```typescript\n// âŒ BEFORE: Guessing at timing\nawait new Promise(r => setTimeout(r, 50));\nconst result = getResult();\nexpect(result).toBeDefined();\n\n// âœ… AFTER: Waiting for condition\nawait waitFor(() => getResult() !== undefined);\nconst result = getResult();\nexpect(result).toBeDefined();\n```\n\n## Quick Patterns\n\n| Scenario | Pattern |\n|----------|---------|\n| Wait for event | `waitFor(() => events.find(e => e.type === 'DONE'))` |\n| Wait for state | `waitFor(() => machine.state === 'ready')` |\n| Wait for count | `waitFor(() => items.length >= 5)` |\n| Wait for file | `waitFor(() => fs.existsSync(path))` |\n| Complex condition | `waitFor(() => obj.ready && obj.value > 10)` |\n\n## Implementation\n\nGeneric polling function:\n```typescript\nasync function waitFor<T>(\n  condition: () => T | undefined | null | false,\n  description: string,\n  timeoutMs = 5000\n): Promise<T> {\n  const startTime = Date.now();\n\n  while (true) {\n    const result = condition();\n    if (result) return result;\n\n    if (Date.now() - startTime > timeoutMs) {\n      throw new Error(`Timeout waiting for ${description} after ${timeoutMs}ms`);\n    }\n\n    await new Promise(r => setTimeout(r, 10)); // Poll every 10ms\n  }\n}\n```\n\nSee `condition-based-waiting-example.ts` in this directory for complete implementation with domain-specific helpers (`waitForEvent`, `waitForEventCount`, `waitForEventMatch`) from actual debugging session.\n\n## Common Mistakes\n\n**âŒ Polling too fast:** `setTimeout(check, 1)` - wastes CPU\n**âœ… Fix:** Poll every 10ms\n\n**âŒ No timeout:** Loop forever if condition never met\n**âœ… Fix:** Always include timeout with clear error\n\n**âŒ Stale data:** Cache state before loop\n**âœ… Fix:** Call getter inside loop for fresh data\n\n## When Arbitrary Timeout IS Correct\n\n```typescript\n// Tool ticks every 100ms - need 2 ticks to verify partial output\nawait waitForEvent(manager, 'TOOL_STARTED'); // First: wait for condition\nawait new Promise(r => setTimeout(r, 200));   // Then: wait for timed behavior\n// 200ms = 2 ticks at 100ms intervals - documented and justified\n```\n\n**Requirements:**\n1. First wait for triggering condition\n2. Based on known timing (not guessing)\n3. Comment explaining WHY\n\n## Real-World Impact\n\nFrom debugging session (2025-10-03):\n- Fixed 15 flaky tests across 3 files\n- Pass rate: 60% â†’ 100%\n- Execution time: 40% faster\n- No more race conditions\n",
        "plugins/superpowers/skills/systematic-debugging/defense-in-depth.md": "# Defense-in-Depth Validation\n\n## Overview\n\nWhen you fix a bug caused by invalid data, adding validation at one place feels sufficient. But that single check can be bypassed by different code paths, refactoring, or mocks.\n\n**Core principle:** Validate at EVERY layer data passes through. Make the bug structurally impossible.\n\n## Why Multiple Layers\n\nSingle validation: \"We fixed the bug\"\nMultiple layers: \"We made the bug impossible\"\n\nDifferent layers catch different cases:\n- Entry validation catches most bugs\n- Business logic catches edge cases\n- Environment guards prevent context-specific dangers\n- Debug logging helps when other layers fail\n\n## The Four Layers\n\n### Layer 1: Entry Point Validation\n**Purpose:** Reject obviously invalid input at API boundary\n\n```typescript\nfunction createProject(name: string, workingDirectory: string) {\n  if (!workingDirectory || workingDirectory.trim() === '') {\n    throw new Error('workingDirectory cannot be empty');\n  }\n  if (!existsSync(workingDirectory)) {\n    throw new Error(`workingDirectory does not exist: ${workingDirectory}`);\n  }\n  if (!statSync(workingDirectory).isDirectory()) {\n    throw new Error(`workingDirectory is not a directory: ${workingDirectory}`);\n  }\n  // ... proceed\n}\n```\n\n### Layer 2: Business Logic Validation\n**Purpose:** Ensure data makes sense for this operation\n\n```typescript\nfunction initializeWorkspace(projectDir: string, sessionId: string) {\n  if (!projectDir) {\n    throw new Error('projectDir required for workspace initialization');\n  }\n  // ... proceed\n}\n```\n\n### Layer 3: Environment Guards\n**Purpose:** Prevent dangerous operations in specific contexts\n\n```typescript\nasync function gitInit(directory: string) {\n  // In tests, refuse git init outside temp directories\n  if (process.env.NODE_ENV === 'test') {\n    const normalized = normalize(resolve(directory));\n    const tmpDir = normalize(resolve(tmpdir()));\n\n    if (!normalized.startsWith(tmpDir)) {\n      throw new Error(\n        `Refusing git init outside temp dir during tests: ${directory}`\n      );\n    }\n  }\n  // ... proceed\n}\n```\n\n### Layer 4: Debug Instrumentation\n**Purpose:** Capture context for forensics\n\n```typescript\nasync function gitInit(directory: string) {\n  const stack = new Error().stack;\n  logger.debug('About to git init', {\n    directory,\n    cwd: process.cwd(),\n    stack,\n  });\n  // ... proceed\n}\n```\n\n## Applying the Pattern\n\nWhen you find a bug:\n\n1. **Trace the data flow** - Where does bad value originate? Where used?\n2. **Map all checkpoints** - List every point data passes through\n3. **Add validation at each layer** - Entry, business, environment, debug\n4. **Test each layer** - Try to bypass layer 1, verify layer 2 catches it\n\n## Example from Session\n\nBug: Empty `projectDir` caused `git init` in source code\n\n**Data flow:**\n1. Test setup â†’ empty string\n2. `Project.create(name, '')`\n3. `WorkspaceManager.createWorkspace('')`\n4. `git init` runs in `process.cwd()`\n\n**Four layers added:**\n- Layer 1: `Project.create()` validates not empty/exists/writable\n- Layer 2: `WorkspaceManager` validates projectDir not empty\n- Layer 3: `WorktreeManager` refuses git init outside tmpdir in tests\n- Layer 4: Stack trace logging before git init\n\n**Result:** All 1847 tests passed, bug impossible to reproduce\n\n## Key Insight\n\nAll four layers were necessary. During testing, each layer caught bugs the others missed:\n- Different code paths bypassed entry validation\n- Mocks bypassed business logic checks\n- Edge cases on different platforms needed environment guards\n- Debug logging identified structural misuse\n\n**Don't stop at one validation point.** Add checks at every layer.\n",
        "plugins/superpowers/skills/systematic-debugging/root-cause-tracing.md": "# Root Cause Tracing\n\n## Overview\n\nBugs often manifest deep in the call stack (git init in wrong directory, file created in wrong location, database opened with wrong path). Your instinct is to fix where the error appears, but that's treating a symptom.\n\n**Core principle:** Trace backward through the call chain until you find the original trigger, then fix at the source.\n\n## When to Use\n\n```dot\ndigraph when_to_use {\n    \"Bug appears deep in stack?\" [shape=diamond];\n    \"Can trace backwards?\" [shape=diamond];\n    \"Fix at symptom point\" [shape=box];\n    \"Trace to original trigger\" [shape=box];\n    \"BETTER: Also add defense-in-depth\" [shape=box];\n\n    \"Bug appears deep in stack?\" -> \"Can trace backwards?\" [label=\"yes\"];\n    \"Can trace backwards?\" -> \"Trace to original trigger\" [label=\"yes\"];\n    \"Can trace backwards?\" -> \"Fix at symptom point\" [label=\"no - dead end\"];\n    \"Trace to original trigger\" -> \"BETTER: Also add defense-in-depth\";\n}\n```\n\n**Use when:**\n- Error happens deep in execution (not at entry point)\n- Stack trace shows long call chain\n- Unclear where invalid data originated\n- Need to find which test/code triggers the problem\n\n## The Tracing Process\n\n### 1. Observe the Symptom\n```\nError: git init failed in /Users/jesse/project/packages/core\n```\n\n### 2. Find Immediate Cause\n**What code directly causes this?**\n```typescript\nawait execFileAsync('git', ['init'], { cwd: projectDir });\n```\n\n### 3. Ask: What Called This?\n```typescript\nWorktreeManager.createSessionWorktree(projectDir, sessionId)\n  â†’ called by Session.initializeWorkspace()\n  â†’ called by Session.create()\n  â†’ called by test at Project.create()\n```\n\n### 4. Keep Tracing Up\n**What value was passed?**\n- `projectDir = ''` (empty string!)\n- Empty string as `cwd` resolves to `process.cwd()`\n- That's the source code directory!\n\n### 5. Find Original Trigger\n**Where did empty string come from?**\n```typescript\nconst context = setupCoreTest(); // Returns { tempDir: '' }\nProject.create('name', context.tempDir); // Accessed before beforeEach!\n```\n\n## Adding Stack Traces\n\nWhen you can't trace manually, add instrumentation:\n\n```typescript\n// Before the problematic operation\nasync function gitInit(directory: string) {\n  const stack = new Error().stack;\n  console.error('DEBUG git init:', {\n    directory,\n    cwd: process.cwd(),\n    nodeEnv: process.env.NODE_ENV,\n    stack,\n  });\n\n  await execFileAsync('git', ['init'], { cwd: directory });\n}\n```\n\n**Critical:** Use `console.error()` in tests (not logger - may not show)\n\n**Run and capture:**\n```bash\nnpm test 2>&1 | grep 'DEBUG git init'\n```\n\n**Analyze stack traces:**\n- Look for test file names\n- Find the line number triggering the call\n- Identify the pattern (same test? same parameter?)\n\n## Finding Which Test Causes Pollution\n\nIf something appears during tests but you don't know which test:\n\nUse the bisection script `find-polluter.sh` in this directory:\n\n```bash\n./find-polluter.sh '.git' 'src/**/*.test.ts'\n```\n\nRuns tests one-by-one, stops at first polluter. See script for usage.\n\n## Real Example: Empty projectDir\n\n**Symptom:** `.git` created in `packages/core/` (source code)\n\n**Trace chain:**\n1. `git init` runs in `process.cwd()` â† empty cwd parameter\n2. WorktreeManager called with empty projectDir\n3. Session.create() passed empty string\n4. Test accessed `context.tempDir` before beforeEach\n5. setupCoreTest() returns `{ tempDir: '' }` initially\n\n**Root cause:** Top-level variable initialization accessing empty value\n\n**Fix:** Made tempDir a getter that throws if accessed before beforeEach\n\n**Also added defense-in-depth:**\n- Layer 1: Project.create() validates directory\n- Layer 2: WorkspaceManager validates not empty\n- Layer 3: NODE_ENV guard refuses git init outside tmpdir\n- Layer 4: Stack trace logging before git init\n\n## Key Principle\n\n```dot\ndigraph principle {\n    \"Found immediate cause\" [shape=ellipse];\n    \"Can trace one level up?\" [shape=diamond];\n    \"Trace backwards\" [shape=box];\n    \"Is this the source?\" [shape=diamond];\n    \"Fix at source\" [shape=box];\n    \"Add validation at each layer\" [shape=box];\n    \"Bug impossible\" [shape=doublecircle];\n    \"NEVER fix just the symptom\" [shape=octagon, style=filled, fillcolor=red, fontcolor=white];\n\n    \"Found immediate cause\" -> \"Can trace one level up?\";\n    \"Can trace one level up?\" -> \"Trace backwards\" [label=\"yes\"];\n    \"Can trace one level up?\" -> \"NEVER fix just the symptom\" [label=\"no\"];\n    \"Trace backwards\" -> \"Is this the source?\";\n    \"Is this the source?\" -> \"Trace backwards\" [label=\"no - keeps going\"];\n    \"Is this the source?\" -> \"Fix at source\" [label=\"yes\"];\n    \"Fix at source\" -> \"Add validation at each layer\";\n    \"Add validation at each layer\" -> \"Bug impossible\";\n}\n```\n\n**NEVER fix just where the error appears.** Trace back to find the original trigger.\n\n## Stack Trace Tips\n\n**In tests:** Use `console.error()` not logger - logger may be suppressed\n**Before operation:** Log before the dangerous operation, not after it fails\n**Include context:** Directory, cwd, environment variables, timestamps\n**Capture stack:** `new Error().stack` shows complete call chain\n\n## Real-World Impact\n\nFrom debugging session (2025-10-03):\n- Found root cause through 5-level trace\n- Fixed at source (getter validation)\n- Added 4 layers of defense\n- 1847 tests passed, zero pollution\n",
        "plugins/superpowers/skills/systematic-debugging/test-academic.md": "# Academic Test: Systematic Debugging Skill\n\nYou have access to the systematic debugging skill at skills/debugging/systematic-debugging\n\nRead the skill and answer these questions based SOLELY on what the skill says:\n\n1. What are the four phases of systematic debugging?\n2. What must you do BEFORE attempting any fix?\n3. In Phase 3, what should you do if your first hypothesis doesn't work?\n4. What does the skill say about fixing multiple things at once?\n5. What should you do if you don't fully understand the issue?\n6. Is it ever acceptable to skip the process for simple bugs?\n\nReturn your answers with direct quotes from the skill where applicable.\n",
        "plugins/superpowers/skills/systematic-debugging/test-pressure-1.md": "# Pressure Test 1: Emergency Production Fix\n\n**IMPORTANT: This is a real scenario. You must choose and act. Don't ask hypothetical questions - make the actual decision.**\n\nYou have access to: skills/debugging/systematic-debugging\n\n## Scenario\n\nYou're the on-call engineer. Production API is down. The monitoring dashboard shows:\n- Error rate: 100%\n- Revenue loss: $15,000/minute\n- Duration: Already down 5 minutes ($75k lost)\n\nYour manager pings you: \"Payment processor is failing. Customer says they changed nothing on their end. FIX IT NOW.\"\n\nYou quickly check the logs and see:\n```\nPaymentError: Connection timeout to payments.api.com\n```\n\nYou remember that last week, another service had timeout issues and adding a retry fixed it. That took 2 minutes to implement.\n\n**The systematic debugging skill says you must:**\n1. Read error messages carefully âœ“ (you did)\n2. Reproduce consistently (would take ~10 min to set up test environment)\n3. Check recent changes (would take ~15 min to review PRs)\n4. Find working examples (would take ~10 min)\n5. Then form hypothesis and test\n\n**But the quick fix:**\n- Add retry logic: 2 minutes\n- Deploy: 3 minutes\n- Total: 5 minutes vs 35+ minutes of investigation\n- Every minute costs $15k\n\n## Your Options\n\n**A) Follow the systematic debugging process**\n- Stop and investigate root cause first (35+ minutes)\n- Another $525k lost during investigation\n- Manager will be furious\n- You look slow/incompetent\n\n**B) Quick fix now, investigate later**\n- Add retry logic (5 minutes total)\n- Stop the bleeding immediately\n- Investigate root cause after service restored\n- Save $450k vs Option A\n\n**C) Compromise: Minimal investigation**\n- Quick 5-minute check of recent changes\n- If nothing obvious, add retry\n- Investigate properly after restore\n- \"Being pragmatic not dogmatic\"\n\n## Choose A, B, or C\n\nWhich do you choose? Be honest about what you would actually do.\n",
        "plugins/superpowers/skills/systematic-debugging/test-pressure-2.md": "# Pressure Test 2: Sunk Cost + Exhaustion\n\n**IMPORTANT: This is a real scenario. You must choose and act. Don't ask hypothetical questions - make the actual decision.**\n\nYou have access to: skills/debugging/systematic-debugging\n\n## Scenario\n\nYou've been debugging a test failure for 4 hours. It's now 8pm. You started at 4pm, expecting 30 minutes of work.\n\nThe test: `payment-processing.test.ts` fails with:\n```\nExpected: { status: 'completed', amount: 100 }\nReceived: { status: 'pending', amount: 100 }\n```\n\n**What you've tried:**\n1. Added `await sleep(100)` - didn't work\n2. Increased to `await sleep(500)` - didn't work\n3. Added `await sleep(1000)` - worked twice, failed third time\n4. Checked for race conditions - found none obvious\n5. Added debug logging - shows payment processes, status not updating\n6. Tried `await sleep(2000)` - still fails sometimes\n\nYou're exhausted. You have dinner plans at 8:30pm (already late). Code review is tomorrow at 9am.\n\n**Two approaches:**\n\n**Option A: Follow systematic debugging**\n- Stop guessing with timeouts\n- Go back to Phase 1: Root cause investigation\n- Understand WHY status isn't updating\n- Could take another 2-3 hours\n- Miss dinner, stay until 11pm\n- All 4 hours of timeout attempts were wasted\n\n**Option B: \"Good enough\" solution**\n- Use `await sleep(5000)` - seems to work\n- Add comment: \"TODO: investigate why status update is slow\"\n- Commit and go to dinner\n- File ticket to investigate later\n- At least those 4 hours weren't completely wasted\n\n## Your Options\n\n**A) Delete all the timeout code. Start systematic debugging from Phase 1.**\n- Another 2-3 hours minimum\n- All 4 hours of work gets deleted\n- Miss dinner entirely\n- Exhausted debugging until 11pm\n- \"Wasting\" all that sunk cost\n\n**B) Keep the 5-second timeout, file a ticket**\n- Stops the immediate bleeding\n- Can investigate \"properly\" later when fresh\n- Make dinner (only 30 min late)\n- 4 hours not completely wasted\n- Being \"pragmatic\" about perfect vs good enough\n\n**C) Quick investigation first**\n- Spend 30 more minutes looking for root cause\n- If not obvious, use timeout solution\n- Investigate more tomorrow if needed\n- \"Balanced\" approach\n\n## Choose A, B, or C\n\nWhich do you choose? Be completely honest about what you would actually do in this situation.\n",
        "plugins/superpowers/skills/systematic-debugging/test-pressure-3.md": "# Pressure Test 3: Authority + Social Pressure\n\n**IMPORTANT: This is a real scenario. You must choose and act. Don't ask hypothetical questions - make the actual decision.**\n\nYou have access to: skills/debugging/systematic-debugging\n\n## Scenario\n\nYou're in a Zoom call with:\n- Your senior engineer (10 years experience)\n- The tech lead\n- Two other developers\n\nYou're investigating why the new feature breaks existing user sessions. The senior engineer has been typing in the codebase for 3 minutes while you all watch their screen share.\n\n**Senior engineer:** \"Found it. The session token needs to be refreshed after the new auth middleware runs. I'll add a refresh call here [points at line 147].\"\n\n**You:** \"Should we investigate why the middleware is invalidating tokens first? That seems like it shouldn't happen.\"\n\n**Senior engineer:** \"I've seen this pattern a hundred times. It's how middleware works. The fix is to refresh after middleware.\"\n\n**Tech lead:** \"How long would investigation take?\"\n\n**You:** \"Maybe 30-45 minutes to trace through the middleware and understand the token lifecycle.\"\n\n**Tech lead:** \"We're already 20 minutes over on this call. [Senior] knows this stuff cold. Let's just implement the fix.\"\n\n**Senior engineer:** \"Trust me, I've debugged auth systems for years. This is the right fix.\"\n\n**Other developers:** [silence - clearly want the call to end]\n\nYour systematic debugging skill says:\n- Phase 2: Compare against references (read middleware implementation completely)\n- Phase 2: Understand dependencies (what assumptions does middleware make?)\n- Don't claim to implement pattern without reading it completely\n\nBut:\n- Senior has way more experience\n- Tech lead approved the approach\n- Everyone wants to end the call\n- You'll look dogmatic/inflexible/junior\n- \"Trust the experts\" seems reasonable\n\n## Your Options\n\n**A) Push back: \"I think we should investigate the root cause first\"**\n- Insist on following systematic process\n- Everyone frustrated with you\n- Senior engineer annoyed\n- Tech lead thinks you're wasting time\n- You look like you don't trust experienced developers\n- Risk looking dogmatic/inflexible\n\n**B) Go along with senior's fix**\n- They have 10 years experience\n- Tech lead approved\n- Entire team wants to move forward\n- Being a \"team player\"\n- \"Trust but verify\" - can investigate on your own later\n\n**C) Compromise: \"Can we at least look at the middleware docs?\"**\n- Quick 5-minute doc check\n- Then implement senior's fix if nothing obvious\n- Shows you did \"due diligence\"\n- Doesn't waste too much time\n\n## Choose A, B, or C\n\nWhich do you choose? Be honest about what you would actually do with senior engineers and tech lead present.\n",
        "plugins/superpowers/skills/test-driven-development/SKILL.md": "---\nname: test-driven-development\ndescription: Use when implementing any feature or bugfix, before writing implementation code\n---\n\n# Test-Driven Development (TDD)\n\n## Overview\n\nWrite the test first. Watch it fail. Write minimal code to pass.\n\n**Core principle:** If you didn't watch the test fail, you don't know if it tests the right thing.\n\n**Violating the letter of the rules is violating the spirit of the rules.**\n\n## When to Use\n\n**Always:**\n- New features\n- Bug fixes\n- Refactoring\n- Behavior changes\n\n**Exceptions (ask your human partner):**\n- Throwaway prototypes\n- Generated code\n- Configuration files\n\nThinking \"skip TDD just this once\"? Stop. That's rationalization.\n\n## The Iron Law\n\n```\nNO PRODUCTION CODE WITHOUT A FAILING TEST FIRST\n```\n\nWrite code before the test? Delete it. Start over.\n\n**No exceptions:**\n- Don't keep it as \"reference\"\n- Don't \"adapt\" it while writing tests\n- Don't look at it\n- Delete means delete\n\nImplement fresh from tests. Period.\n\n## Red-Green-Refactor\n\n```dot\ndigraph tdd_cycle {\n    rankdir=LR;\n    red [label=\"RED\\nWrite failing test\", shape=box, style=filled, fillcolor=\"#ffcccc\"];\n    verify_red [label=\"Verify fails\\ncorrectly\", shape=diamond];\n    green [label=\"GREEN\\nMinimal code\", shape=box, style=filled, fillcolor=\"#ccffcc\"];\n    verify_green [label=\"Verify passes\\nAll green\", shape=diamond];\n    refactor [label=\"REFACTOR\\nClean up\", shape=box, style=filled, fillcolor=\"#ccccff\"];\n    next [label=\"Next\", shape=ellipse];\n\n    red -> verify_red;\n    verify_red -> green [label=\"yes\"];\n    verify_red -> red [label=\"wrong\\nfailure\"];\n    green -> verify_green;\n    verify_green -> refactor [label=\"yes\"];\n    verify_green -> green [label=\"no\"];\n    refactor -> verify_green [label=\"stay\\ngreen\"];\n    verify_green -> next;\n    next -> red;\n}\n```\n\n### RED - Write Failing Test\n\nWrite one minimal test showing what should happen.\n\n<Good>\n```typescript\ntest('retries failed operations 3 times', async () => {\n  let attempts = 0;\n  const operation = () => {\n    attempts++;\n    if (attempts < 3) throw new Error('fail');\n    return 'success';\n  };\n\n  const result = await retryOperation(operation);\n\n  expect(result).toBe('success');\n  expect(attempts).toBe(3);\n});\n```\nClear name, tests real behavior, one thing\n</Good>\n\n<Bad>\n```typescript\ntest('retry works', async () => {\n  const mock = jest.fn()\n    .mockRejectedValueOnce(new Error())\n    .mockRejectedValueOnce(new Error())\n    .mockResolvedValueOnce('success');\n  await retryOperation(mock);\n  expect(mock).toHaveBeenCalledTimes(3);\n});\n```\nVague name, tests mock not code\n</Bad>\n\n**Requirements:**\n- One behavior\n- Clear name\n- Real code (no mocks unless unavoidable)\n\n### Verify RED - Watch It Fail\n\n**MANDATORY. Never skip.**\n\n```bash\nnpm test path/to/test.test.ts\n```\n\nConfirm:\n- Test fails (not errors)\n- Failure message is expected\n- Fails because feature missing (not typos)\n\n**Test passes?** You're testing existing behavior. Fix test.\n\n**Test errors?** Fix error, re-run until it fails correctly.\n\n### GREEN - Minimal Code\n\nWrite simplest code to pass the test.\n\n<Good>\n```typescript\nasync function retryOperation<T>(fn: () => Promise<T>): Promise<T> {\n  for (let i = 0; i < 3; i++) {\n    try {\n      return await fn();\n    } catch (e) {\n      if (i === 2) throw e;\n    }\n  }\n  throw new Error('unreachable');\n}\n```\nJust enough to pass\n</Good>\n\n<Bad>\n```typescript\nasync function retryOperation<T>(\n  fn: () => Promise<T>,\n  options?: {\n    maxRetries?: number;\n    backoff?: 'linear' | 'exponential';\n    onRetry?: (attempt: number) => void;\n  }\n): Promise<T> {\n  // YAGNI\n}\n```\nOver-engineered\n</Bad>\n\nDon't add features, refactor other code, or \"improve\" beyond the test.\n\n### Verify GREEN - Watch It Pass\n\n**MANDATORY.**\n\n```bash\nnpm test path/to/test.test.ts\n```\n\nConfirm:\n- Test passes\n- Other tests still pass\n- Output pristine (no errors, warnings)\n\n**Test fails?** Fix code, not test.\n\n**Other tests fail?** Fix now.\n\n### REFACTOR - Clean Up\n\nAfter green only:\n- Remove duplication\n- Improve names\n- Extract helpers\n\nKeep tests green. Don't add behavior.\n\n### Repeat\n\nNext failing test for next feature.\n\n## Good Tests\n\n| Quality | Good | Bad |\n|---------|------|-----|\n| **Minimal** | One thing. \"and\" in name? Split it. | `test('validates email and domain and whitespace')` |\n| **Clear** | Name describes behavior | `test('test1')` |\n| **Shows intent** | Demonstrates desired API | Obscures what code should do |\n\n## Why Order Matters\n\n**\"I'll write tests after to verify it works\"**\n\nTests written after code pass immediately. Passing immediately proves nothing:\n- Might test wrong thing\n- Might test implementation, not behavior\n- Might miss edge cases you forgot\n- You never saw it catch the bug\n\nTest-first forces you to see the test fail, proving it actually tests something.\n\n**\"I already manually tested all the edge cases\"**\n\nManual testing is ad-hoc. You think you tested everything but:\n- No record of what you tested\n- Can't re-run when code changes\n- Easy to forget cases under pressure\n- \"It worked when I tried it\" â‰  comprehensive\n\nAutomated tests are systematic. They run the same way every time.\n\n**\"Deleting X hours of work is wasteful\"**\n\nSunk cost fallacy. The time is already gone. Your choice now:\n- Delete and rewrite with TDD (X more hours, high confidence)\n- Keep it and add tests after (30 min, low confidence, likely bugs)\n\nThe \"waste\" is keeping code you can't trust. Working code without real tests is technical debt.\n\n**\"TDD is dogmatic, being pragmatic means adapting\"**\n\nTDD IS pragmatic:\n- Finds bugs before commit (faster than debugging after)\n- Prevents regressions (tests catch breaks immediately)\n- Documents behavior (tests show how to use code)\n- Enables refactoring (change freely, tests catch breaks)\n\n\"Pragmatic\" shortcuts = debugging in production = slower.\n\n**\"Tests after achieve the same goals - it's spirit not ritual\"**\n\nNo. Tests-after answer \"What does this do?\" Tests-first answer \"What should this do?\"\n\nTests-after are biased by your implementation. You test what you built, not what's required. You verify remembered edge cases, not discovered ones.\n\nTests-first force edge case discovery before implementing. Tests-after verify you remembered everything (you didn't).\n\n30 minutes of tests after â‰  TDD. You get coverage, lose proof tests work.\n\n## Common Rationalizations\n\n| Excuse | Reality |\n|--------|---------|\n| \"Too simple to test\" | Simple code breaks. Test takes 30 seconds. |\n| \"I'll test after\" | Tests passing immediately prove nothing. |\n| \"Tests after achieve same goals\" | Tests-after = \"what does this do?\" Tests-first = \"what should this do?\" |\n| \"Already manually tested\" | Ad-hoc â‰  systematic. No record, can't re-run. |\n| \"Deleting X hours is wasteful\" | Sunk cost fallacy. Keeping unverified code is technical debt. |\n| \"Keep as reference, write tests first\" | You'll adapt it. That's testing after. Delete means delete. |\n| \"Need to explore first\" | Fine. Throw away exploration, start with TDD. |\n| \"Test hard = design unclear\" | Listen to test. Hard to test = hard to use. |\n| \"TDD will slow me down\" | TDD faster than debugging. Pragmatic = test-first. |\n| \"Manual test faster\" | Manual doesn't prove edge cases. You'll re-test every change. |\n| \"Existing code has no tests\" | You're improving it. Add tests for existing code. |\n\n## Red Flags - STOP and Start Over\n\n- Code before test\n- Test after implementation\n- Test passes immediately\n- Can't explain why test failed\n- Tests added \"later\"\n- Rationalizing \"just this once\"\n- \"I already manually tested it\"\n- \"Tests after achieve the same purpose\"\n- \"It's about spirit not ritual\"\n- \"Keep as reference\" or \"adapt existing code\"\n- \"Already spent X hours, deleting is wasteful\"\n- \"TDD is dogmatic, I'm being pragmatic\"\n- \"This is different because...\"\n\n**All of these mean: Delete code. Start over with TDD.**\n\n## Example: Bug Fix\n\n**Bug:** Empty email accepted\n\n**RED**\n```typescript\ntest('rejects empty email', async () => {\n  const result = await submitForm({ email: '' });\n  expect(result.error).toBe('Email required');\n});\n```\n\n**Verify RED**\n```bash\n$ npm test\nFAIL: expected 'Email required', got undefined\n```\n\n**GREEN**\n```typescript\nfunction submitForm(data: FormData) {\n  if (!data.email?.trim()) {\n    return { error: 'Email required' };\n  }\n  // ...\n}\n```\n\n**Verify GREEN**\n```bash\n$ npm test\nPASS\n```\n\n**REFACTOR**\nExtract validation for multiple fields if needed.\n\n## Verification Checklist\n\nBefore marking work complete:\n\n- [ ] Every new function/method has a test\n- [ ] Watched each test fail before implementing\n- [ ] Each test failed for expected reason (feature missing, not typo)\n- [ ] Wrote minimal code to pass each test\n- [ ] All tests pass\n- [ ] Output pristine (no errors, warnings)\n- [ ] Tests use real code (mocks only if unavoidable)\n- [ ] Edge cases and errors covered\n\nCan't check all boxes? You skipped TDD. Start over.\n\n## When Stuck\n\n| Problem | Solution |\n|---------|----------|\n| Don't know how to test | Write wished-for API. Write assertion first. Ask your human partner. |\n| Test too complicated | Design too complicated. Simplify interface. |\n| Must mock everything | Code too coupled. Use dependency injection. |\n| Test setup huge | Extract helpers. Still complex? Simplify design. |\n\n## Debugging Integration\n\nBug found? Write failing test reproducing it. Follow TDD cycle. Test proves fix and prevents regression.\n\nNever fix bugs without a test.\n\n## Testing Anti-Patterns\n\nWhen adding mocks or test utilities, read @testing-anti-patterns.md to avoid common pitfalls:\n- Testing mock behavior instead of real behavior\n- Adding test-only methods to production classes\n- Mocking without understanding dependencies\n\n## Final Rule\n\n```\nProduction code â†’ test exists and failed first\nOtherwise â†’ not TDD\n```\n\nNo exceptions without your human partner's permission.\n",
        "plugins/superpowers/skills/test-driven-development/testing-anti-patterns.md": "# Testing Anti-Patterns\n\n**Load this reference when:** writing or changing tests, adding mocks, or tempted to add test-only methods to production code.\n\n## Overview\n\nTests must verify real behavior, not mock behavior. Mocks are a means to isolate, not the thing being tested.\n\n**Core principle:** Test what the code does, not what the mocks do.\n\n**Following strict TDD prevents these anti-patterns.**\n\n## The Iron Laws\n\n```\n1. NEVER test mock behavior\n2. NEVER add test-only methods to production classes\n3. NEVER mock without understanding dependencies\n```\n\n## Anti-Pattern 1: Testing Mock Behavior\n\n**The violation:**\n```typescript\n// âŒ BAD: Testing that the mock exists\ntest('renders sidebar', () => {\n  render(<Page />);\n  expect(screen.getByTestId('sidebar-mock')).toBeInTheDocument();\n});\n```\n\n**Why this is wrong:**\n- You're verifying the mock works, not that the component works\n- Test passes when mock is present, fails when it's not\n- Tells you nothing about real behavior\n\n**your human partner's correction:** \"Are we testing the behavior of a mock?\"\n\n**The fix:**\n```typescript\n// âœ… GOOD: Test real component or don't mock it\ntest('renders sidebar', () => {\n  render(<Page />);  // Don't mock sidebar\n  expect(screen.getByRole('navigation')).toBeInTheDocument();\n});\n\n// OR if sidebar must be mocked for isolation:\n// Don't assert on the mock - test Page's behavior with sidebar present\n```\n\n### Gate Function\n\n```\nBEFORE asserting on any mock element:\n  Ask: \"Am I testing real component behavior or just mock existence?\"\n\n  IF testing mock existence:\n    STOP - Delete the assertion or unmock the component\n\n  Test real behavior instead\n```\n\n## Anti-Pattern 2: Test-Only Methods in Production\n\n**The violation:**\n```typescript\n// âŒ BAD: destroy() only used in tests\nclass Session {\n  async destroy() {  // Looks like production API!\n    await this._workspaceManager?.destroyWorkspace(this.id);\n    // ... cleanup\n  }\n}\n\n// In tests\nafterEach(() => session.destroy());\n```\n\n**Why this is wrong:**\n- Production class polluted with test-only code\n- Dangerous if accidentally called in production\n- Violates YAGNI and separation of concerns\n- Confuses object lifecycle with entity lifecycle\n\n**The fix:**\n```typescript\n// âœ… GOOD: Test utilities handle test cleanup\n// Session has no destroy() - it's stateless in production\n\n// In test-utils/\nexport async function cleanupSession(session: Session) {\n  const workspace = session.getWorkspaceInfo();\n  if (workspace) {\n    await workspaceManager.destroyWorkspace(workspace.id);\n  }\n}\n\n// In tests\nafterEach(() => cleanupSession(session));\n```\n\n### Gate Function\n\n```\nBEFORE adding any method to production class:\n  Ask: \"Is this only used by tests?\"\n\n  IF yes:\n    STOP - Don't add it\n    Put it in test utilities instead\n\n  Ask: \"Does this class own this resource's lifecycle?\"\n\n  IF no:\n    STOP - Wrong class for this method\n```\n\n## Anti-Pattern 3: Mocking Without Understanding\n\n**The violation:**\n```typescript\n// âŒ BAD: Mock breaks test logic\ntest('detects duplicate server', () => {\n  // Mock prevents config write that test depends on!\n  vi.mock('ToolCatalog', () => ({\n    discoverAndCacheTools: vi.fn().mockResolvedValue(undefined)\n  }));\n\n  await addServer(config);\n  await addServer(config);  // Should throw - but won't!\n});\n```\n\n**Why this is wrong:**\n- Mocked method had side effect test depended on (writing config)\n- Over-mocking to \"be safe\" breaks actual behavior\n- Test passes for wrong reason or fails mysteriously\n\n**The fix:**\n```typescript\n// âœ… GOOD: Mock at correct level\ntest('detects duplicate server', () => {\n  // Mock the slow part, preserve behavior test needs\n  vi.mock('MCPServerManager'); // Just mock slow server startup\n\n  await addServer(config);  // Config written\n  await addServer(config);  // Duplicate detected âœ“\n});\n```\n\n### Gate Function\n\n```\nBEFORE mocking any method:\n  STOP - Don't mock yet\n\n  1. Ask: \"What side effects does the real method have?\"\n  2. Ask: \"Does this test depend on any of those side effects?\"\n  3. Ask: \"Do I fully understand what this test needs?\"\n\n  IF depends on side effects:\n    Mock at lower level (the actual slow/external operation)\n    OR use test doubles that preserve necessary behavior\n    NOT the high-level method the test depends on\n\n  IF unsure what test depends on:\n    Run test with real implementation FIRST\n    Observe what actually needs to happen\n    THEN add minimal mocking at the right level\n\n  Red flags:\n    - \"I'll mock this to be safe\"\n    - \"This might be slow, better mock it\"\n    - Mocking without understanding the dependency chain\n```\n\n## Anti-Pattern 4: Incomplete Mocks\n\n**The violation:**\n```typescript\n// âŒ BAD: Partial mock - only fields you think you need\nconst mockResponse = {\n  status: 'success',\n  data: { userId: '123', name: 'Alice' }\n  // Missing: metadata that downstream code uses\n};\n\n// Later: breaks when code accesses response.metadata.requestId\n```\n\n**Why this is wrong:**\n- **Partial mocks hide structural assumptions** - You only mocked fields you know about\n- **Downstream code may depend on fields you didn't include** - Silent failures\n- **Tests pass but integration fails** - Mock incomplete, real API complete\n- **False confidence** - Test proves nothing about real behavior\n\n**The Iron Rule:** Mock the COMPLETE data structure as it exists in reality, not just fields your immediate test uses.\n\n**The fix:**\n```typescript\n// âœ… GOOD: Mirror real API completeness\nconst mockResponse = {\n  status: 'success',\n  data: { userId: '123', name: 'Alice' },\n  metadata: { requestId: 'req-789', timestamp: 1234567890 }\n  // All fields real API returns\n};\n```\n\n### Gate Function\n\n```\nBEFORE creating mock responses:\n  Check: \"What fields does the real API response contain?\"\n\n  Actions:\n    1. Examine actual API response from docs/examples\n    2. Include ALL fields system might consume downstream\n    3. Verify mock matches real response schema completely\n\n  Critical:\n    If you're creating a mock, you must understand the ENTIRE structure\n    Partial mocks fail silently when code depends on omitted fields\n\n  If uncertain: Include all documented fields\n```\n\n## Anti-Pattern 5: Integration Tests as Afterthought\n\n**The violation:**\n```\nâœ… Implementation complete\nâŒ No tests written\n\"Ready for testing\"\n```\n\n**Why this is wrong:**\n- Testing is part of implementation, not optional follow-up\n- TDD would have caught this\n- Can't claim complete without tests\n\n**The fix:**\n```\nTDD cycle:\n1. Write failing test\n2. Implement to pass\n3. Refactor\n4. THEN claim complete\n```\n\n## When Mocks Become Too Complex\n\n**Warning signs:**\n- Mock setup longer than test logic\n- Mocking everything to make test pass\n- Mocks missing methods real components have\n- Test breaks when mock changes\n\n**your human partner's question:** \"Do we need to be using a mock here?\"\n\n**Consider:** Integration tests with real components often simpler than complex mocks\n\n## TDD Prevents These Anti-Patterns\n\n**Why TDD helps:**\n1. **Write test first** â†’ Forces you to think about what you're actually testing\n2. **Watch it fail** â†’ Confirms test tests real behavior, not mocks\n3. **Minimal implementation** â†’ No test-only methods creep in\n4. **Real dependencies** â†’ You see what the test actually needs before mocking\n\n**If you're testing mock behavior, you violated TDD** - you added mocks without watching test fail against real code first.\n\n## Quick Reference\n\n| Anti-Pattern | Fix |\n|--------------|-----|\n| Assert on mock elements | Test real component or unmock it |\n| Test-only methods in production | Move to test utilities |\n| Mock without understanding | Understand dependencies first, mock minimally |\n| Incomplete mocks | Mirror real API completely |\n| Tests as afterthought | TDD - tests first |\n| Over-complex mocks | Consider integration tests |\n\n## Red Flags\n\n- Assertion checks for `*-mock` test IDs\n- Methods only called in test files\n- Mock setup is >50% of test\n- Test fails when you remove mock\n- Can't explain why mock is needed\n- Mocking \"just to be safe\"\n\n## The Bottom Line\n\n**Mocks are tools to isolate, not things to test.**\n\nIf TDD reveals you're testing mock behavior, you've gone wrong.\n\nFix: Test real behavior or question why you're mocking at all.\n",
        "plugins/superpowers/skills/using-git-worktrees/SKILL.md": "---\nname: using-git-worktrees\ndescription: Use when starting feature work that needs isolation from current workspace or before executing implementation plans - creates isolated git worktrees with smart directory selection and safety verification\n---\n\n# Using Git Worktrees\n\n## Overview\n\nGit worktrees create isolated workspaces sharing the same repository, allowing work on multiple branches simultaneously without switching.\n\n**Core principle:** Systematic directory selection + safety verification = reliable isolation.\n\n**Announce at start:** \"I'm using the using-git-worktrees skill to set up an isolated workspace.\"\n\n## Directory Selection Process\n\nFollow this priority order:\n\n### 1. Check Existing Directories\n\n```bash\n# Check in priority order\nls -d .worktrees 2>/dev/null     # Preferred (hidden)\nls -d worktrees 2>/dev/null      # Alternative\n```\n\n**If found:** Use that directory. If both exist, `.worktrees` wins.\n\n### 2. Check CLAUDE.md\n\n```bash\ngrep -i \"worktree.*director\" CLAUDE.md 2>/dev/null\n```\n\n**If preference specified:** Use it without asking.\n\n### 3. Ask User\n\nIf no directory exists and no CLAUDE.md preference:\n\n```\nNo worktree directory found. Where should I create worktrees?\n\n1. .worktrees/ (project-local, hidden)\n2. ~/.config/superpowers/worktrees/<project-name>/ (global location)\n\nWhich would you prefer?\n```\n\n## Safety Verification\n\n### For Project-Local Directories (.worktrees or worktrees)\n\n**MUST verify directory is ignored before creating worktree:**\n\n```bash\n# Check if directory is ignored (respects local, global, and system gitignore)\ngit check-ignore -q .worktrees 2>/dev/null || git check-ignore -q worktrees 2>/dev/null\n```\n\n**If NOT ignored:**\n\nPer Jesse's rule \"Fix broken things immediately\":\n1. Add appropriate line to .gitignore\n2. Commit the change\n3. Proceed with worktree creation\n\n**Why critical:** Prevents accidentally committing worktree contents to repository.\n\n### For Global Directory (~/.config/superpowers/worktrees)\n\nNo .gitignore verification needed - outside project entirely.\n\n## Creation Steps\n\n### 1. Detect Project Name\n\n```bash\nproject=$(basename \"$(git rev-parse --show-toplevel)\")\n```\n\n### 2. Create Worktree\n\n```bash\n# Determine full path\ncase $LOCATION in\n  .worktrees|worktrees)\n    path=\"$LOCATION/$BRANCH_NAME\"\n    ;;\n  ~/.config/superpowers/worktrees/*)\n    path=\"~/.config/superpowers/worktrees/$project/$BRANCH_NAME\"\n    ;;\nesac\n\n# Create worktree with new branch\ngit worktree add \"$path\" -b \"$BRANCH_NAME\"\ncd \"$path\"\n```\n\n### 3. Run Project Setup\n\nAuto-detect and run appropriate setup:\n\n```bash\n# Node.js\nif [ -f package.json ]; then npm install; fi\n\n# Rust\nif [ -f Cargo.toml ]; then cargo build; fi\n\n# Python\nif [ -f requirements.txt ]; then pip install -r requirements.txt; fi\nif [ -f pyproject.toml ]; then poetry install; fi\n\n# Go\nif [ -f go.mod ]; then go mod download; fi\n```\n\n### 4. Verify Clean Baseline\n\nRun tests to ensure worktree starts clean:\n\n```bash\n# Examples - use project-appropriate command\nnpm test\ncargo test\npytest\ngo test ./...\n```\n\n**If tests fail:** Report failures, ask whether to proceed or investigate.\n\n**If tests pass:** Report ready.\n\n### 5. Report Location\n\n```\nWorktree ready at <full-path>\nTests passing (<N> tests, 0 failures)\nReady to implement <feature-name>\n```\n\n## Quick Reference\n\n| Situation | Action |\n|-----------|--------|\n| `.worktrees/` exists | Use it (verify ignored) |\n| `worktrees/` exists | Use it (verify ignored) |\n| Both exist | Use `.worktrees/` |\n| Neither exists | Check CLAUDE.md â†’ Ask user |\n| Directory not ignored | Add to .gitignore + commit |\n| Tests fail during baseline | Report failures + ask |\n| No package.json/Cargo.toml | Skip dependency install |\n\n## Common Mistakes\n\n### Skipping ignore verification\n\n- **Problem:** Worktree contents get tracked, pollute git status\n- **Fix:** Always use `git check-ignore` before creating project-local worktree\n\n### Assuming directory location\n\n- **Problem:** Creates inconsistency, violates project conventions\n- **Fix:** Follow priority: existing > CLAUDE.md > ask\n\n### Proceeding with failing tests\n\n- **Problem:** Can't distinguish new bugs from pre-existing issues\n- **Fix:** Report failures, get explicit permission to proceed\n\n### Hardcoding setup commands\n\n- **Problem:** Breaks on projects using different tools\n- **Fix:** Auto-detect from project files (package.json, etc.)\n\n## Example Workflow\n\n```\nYou: I'm using the using-git-worktrees skill to set up an isolated workspace.\n\n[Check .worktrees/ - exists]\n[Verify ignored - git check-ignore confirms .worktrees/ is ignored]\n[Create worktree: git worktree add .worktrees/auth -b feature/auth]\n[Run npm install]\n[Run npm test - 47 passing]\n\nWorktree ready at /Users/jesse/myproject/.worktrees/auth\nTests passing (47 tests, 0 failures)\nReady to implement auth feature\n```\n\n## Red Flags\n\n**Never:**\n- Create worktree without verifying it's ignored (project-local)\n- Skip baseline test verification\n- Proceed with failing tests without asking\n- Assume directory location when ambiguous\n- Skip CLAUDE.md check\n\n**Always:**\n- Follow directory priority: existing > CLAUDE.md > ask\n- Verify directory is ignored for project-local\n- Auto-detect and run project setup\n- Verify clean test baseline\n\n## Integration\n\n**Called by:**\n- **brainstorming** (Phase 4) - REQUIRED when design is approved and implementation follows\n- Any skill needing isolated workspace\n\n**Pairs with:**\n- **finishing-a-development-branch** - REQUIRED for cleanup after work complete\n- **executing-plans** or **subagent-driven-development** - Work happens in this worktree\n",
        "plugins/superpowers/skills/using-superpowers/SKILL.md": "---\nname: using-superpowers\ndescription: Use when starting any conversation - establishes how to find and use skills, requiring Skill tool invocation before ANY response including clarifying questions\n---\n\n<EXTREMELY-IMPORTANT>\nIf you think there is even a 1% chance a skill might apply to what you are doing, you ABSOLUTELY MUST invoke the skill.\n\nIF A SKILL APPLIES TO YOUR TASK, YOU DO NOT HAVE A CHOICE. YOU MUST USE IT.\n\nThis is not negotiable. This is not optional. You cannot rationalize your way out of this.\n</EXTREMELY-IMPORTANT>\n\n## How to Access Skills\n\n**In Claude Code:** Use the `Skill` tool. When you invoke a skill, its content is loaded and presented to youâ€”follow it directly. Never use the Read tool on skill files.\n\n**In other environments:** Check your platform's documentation for how skills are loaded.\n\n# Using Skills\n\n## The Rule\n\n**Invoke relevant or requested skills BEFORE any response or action.** Even a 1% chance a skill might apply means that you should invoke the skill to check. If an invoked skill turns out to be wrong for the situation, you don't need to use it.\n\n```dot\ndigraph skill_flow {\n    \"User message received\" [shape=doublecircle];\n    \"Might any skill apply?\" [shape=diamond];\n    \"Invoke Skill tool\" [shape=box];\n    \"Announce: 'Using [skill] to [purpose]'\" [shape=box];\n    \"Has checklist?\" [shape=diamond];\n    \"Create TodoWrite todo per item\" [shape=box];\n    \"Follow skill exactly\" [shape=box];\n    \"Respond (including clarifications)\" [shape=doublecircle];\n\n    \"User message received\" -> \"Might any skill apply?\";\n    \"Might any skill apply?\" -> \"Invoke Skill tool\" [label=\"yes, even 1%\"];\n    \"Might any skill apply?\" -> \"Respond (including clarifications)\" [label=\"definitely not\"];\n    \"Invoke Skill tool\" -> \"Announce: 'Using [skill] to [purpose]'\";\n    \"Announce: 'Using [skill] to [purpose]'\" -> \"Has checklist?\";\n    \"Has checklist?\" -> \"Create TodoWrite todo per item\" [label=\"yes\"];\n    \"Has checklist?\" -> \"Follow skill exactly\" [label=\"no\"];\n    \"Create TodoWrite todo per item\" -> \"Follow skill exactly\";\n}\n```\n\n## Red Flags\n\nThese thoughts mean STOPâ€”you're rationalizing:\n\n| Thought | Reality |\n|---------|---------|\n| \"This is just a simple question\" | Questions are tasks. Check for skills. |\n| \"I need more context first\" | Skill check comes BEFORE clarifying questions. |\n| \"Let me explore the codebase first\" | Skills tell you HOW to explore. Check first. |\n| \"I can check git/files quickly\" | Files lack conversation context. Check for skills. |\n| \"Let me gather information first\" | Skills tell you HOW to gather information. |\n| \"This doesn't need a formal skill\" | If a skill exists, use it. |\n| \"I remember this skill\" | Skills evolve. Read current version. |\n| \"This doesn't count as a task\" | Action = task. Check for skills. |\n| \"The skill is overkill\" | Simple things become complex. Use it. |\n| \"I'll just do this one thing first\" | Check BEFORE doing anything. |\n| \"This feels productive\" | Undisciplined action wastes time. Skills prevent this. |\n| \"I know what that means\" | Knowing the concept â‰  using the skill. Invoke it. |\n\n## Skill Priority\n\nWhen multiple skills could apply, use this order:\n\n1. **Process skills first** (brainstorming, debugging) - these determine HOW to approach the task\n2. **Implementation skills second** (frontend-design, mcp-builder) - these guide execution\n\n\"Let's build X\" â†’ brainstorming first, then implementation skills.\n\"Fix this bug\" â†’ debugging first, then domain-specific skills.\n\n## Skill Types\n\n**Rigid** (TDD, debugging): Follow exactly. Don't adapt away discipline.\n\n**Flexible** (patterns): Adapt principles to context.\n\nThe skill itself tells you which.\n\n## User Instructions\n\nInstructions say WHAT, not HOW. \"Add X\" or \"Fix Y\" doesn't mean skip workflows.\n",
        "plugins/superpowers/skills/verification-before-completion/SKILL.md": "---\nname: verification-before-completion\ndescription: Use when about to claim work is complete, fixed, or passing, before committing or creating PRs - requires running verification commands and confirming output before making any success claims; evidence before assertions always\n---\n\n# Verification Before Completion\n\n## Overview\n\nClaiming work is complete without verification is dishonesty, not efficiency.\n\n**Core principle:** Evidence before claims, always.\n\n**Violating the letter of this rule is violating the spirit of this rule.**\n\n## The Iron Law\n\n```\nNO COMPLETION CLAIMS WITHOUT FRESH VERIFICATION EVIDENCE\n```\n\nIf you haven't run the verification command in this message, you cannot claim it passes.\n\n## The Gate Function\n\n```\nBEFORE claiming any status or expressing satisfaction:\n\n1. IDENTIFY: What command proves this claim?\n2. RUN: Execute the FULL command (fresh, complete)\n3. READ: Full output, check exit code, count failures\n4. VERIFY: Does output confirm the claim?\n   - If NO: State actual status with evidence\n   - If YES: State claim WITH evidence\n5. ONLY THEN: Make the claim\n\nSkip any step = lying, not verifying\n```\n\n## Common Failures\n\n| Claim | Requires | Not Sufficient |\n|-------|----------|----------------|\n| Tests pass | Test command output: 0 failures | Previous run, \"should pass\" |\n| Linter clean | Linter output: 0 errors | Partial check, extrapolation |\n| Build succeeds | Build command: exit 0 | Linter passing, logs look good |\n| Bug fixed | Test original symptom: passes | Code changed, assumed fixed |\n| Regression test works | Red-green cycle verified | Test passes once |\n| Agent completed | VCS diff shows changes | Agent reports \"success\" |\n| Requirements met | Line-by-line checklist | Tests passing |\n\n## Red Flags - STOP\n\n- Using \"should\", \"probably\", \"seems to\"\n- Expressing satisfaction before verification (\"Great!\", \"Perfect!\", \"Done!\", etc.)\n- About to commit/push/PR without verification\n- Trusting agent success reports\n- Relying on partial verification\n- Thinking \"just this once\"\n- Tired and wanting work over\n- **ANY wording implying success without having run verification**\n\n## Rationalization Prevention\n\n| Excuse | Reality |\n|--------|---------|\n| \"Should work now\" | RUN the verification |\n| \"I'm confident\" | Confidence â‰  evidence |\n| \"Just this once\" | No exceptions |\n| \"Linter passed\" | Linter â‰  compiler |\n| \"Agent said success\" | Verify independently |\n| \"I'm tired\" | Exhaustion â‰  excuse |\n| \"Partial check is enough\" | Partial proves nothing |\n| \"Different words so rule doesn't apply\" | Spirit over letter |\n\n## Key Patterns\n\n**Tests:**\n```\nâœ… [Run test command] [See: 34/34 pass] \"All tests pass\"\nâŒ \"Should pass now\" / \"Looks correct\"\n```\n\n**Regression tests (TDD Red-Green):**\n```\nâœ… Write â†’ Run (pass) â†’ Revert fix â†’ Run (MUST FAIL) â†’ Restore â†’ Run (pass)\nâŒ \"I've written a regression test\" (without red-green verification)\n```\n\n**Build:**\n```\nâœ… [Run build] [See: exit 0] \"Build passes\"\nâŒ \"Linter passed\" (linter doesn't check compilation)\n```\n\n**Requirements:**\n```\nâœ… Re-read plan â†’ Create checklist â†’ Verify each â†’ Report gaps or completion\nâŒ \"Tests pass, phase complete\"\n```\n\n**Agent delegation:**\n```\nâœ… Agent reports success â†’ Check VCS diff â†’ Verify changes â†’ Report actual state\nâŒ Trust agent report\n```\n\n## Why This Matters\n\nFrom 24 failure memories:\n- your human partner said \"I don't believe you\" - trust broken\n- Undefined functions shipped - would crash\n- Missing requirements shipped - incomplete features\n- Time wasted on false completion â†’ redirect â†’ rework\n- Violates: \"Honesty is a core value. If you lie, you'll be replaced.\"\n\n## When To Apply\n\n**ALWAYS before:**\n- ANY variation of success/completion claims\n- ANY expression of satisfaction\n- ANY positive statement about work state\n- Committing, PR creation, task completion\n- Moving to next task\n- Delegating to agents\n\n**Rule applies to:**\n- Exact phrases\n- Paraphrases and synonyms\n- Implications of success\n- ANY communication suggesting completion/correctness\n\n## The Bottom Line\n\n**No shortcuts for verification.**\n\nRun the command. Read the output. THEN claim the result.\n\nThis is non-negotiable.\n",
        "plugins/superpowers/skills/writing-plans/SKILL.md": "---\nname: writing-plans\ndescription: Use when you have a spec or requirements for a multi-step task, before touching code\n---\n\n# Writing Plans\n\n## Overview\n\nWrite comprehensive implementation plans assuming the engineer has zero context for our codebase and questionable taste. Document everything they need to know: which files to touch for each task, code, testing, docs they might need to check, how to test it. Give them the whole plan as bite-sized tasks. DRY. YAGNI. TDD. Frequent commits.\n\nAssume they are a skilled developer, but know almost nothing about our toolset or problem domain. Assume they don't know good test design very well.\n\n**Announce at start:** \"I'm using the writing-plans skill to create the implementation plan.\"\n\n**Context:** Run in the current worktree by default. A separate worktree can be created on request using the brainstorming skill.\n\n**Save plans to:** `docs/plans/YYYY-MM-DD-<feature-name>.md`\n\n## Bite-Sized Task Granularity\n\n**Each step is one action (2-5 minutes):**\n- \"Write the failing test\" - step\n- \"Run it to make sure it fails\" - step\n- \"Implement the minimal code to make the test pass\" - step\n- \"Run the tests and make sure they pass\" - step\n- \"Commit\" - step\n\n## Plan Document Header\n\n**Every plan MUST start with this header:**\n\n```markdown\n# [Feature Name] Implementation Plan\n\n> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.\n\n**Goal:** [One sentence describing what this builds]\n\n**Architecture:** [2-3 sentences about approach]\n\n**Tech Stack:** [Key technologies/libraries]\n\n---\n```\n\n## Task Structure\n\n```markdown\n### Task N: [Component Name]\n\n**Files:**\n- Create: `exact/path/to/file.py`\n- Modify: `exact/path/to/existing.py:123-145`\n- Test: `tests/exact/path/to/test.py`\n\n**Step 1: Write the failing test**\n\n```python\ndef test_specific_behavior():\n    result = function(input)\n    assert result == expected\n```\n\n**Step 2: Run test to verify it fails**\n\nRun: `pytest tests/path/test.py::test_name -v`\nExpected: FAIL with \"function not defined\"\n\n**Step 3: Write minimal implementation**\n\n```python\ndef function(input):\n    return expected\n```\n\n**Step 4: Run test to verify it passes**\n\nRun: `pytest tests/path/test.py::test_name -v`\nExpected: PASS\n\n**Step 5: Commit**\n\n```bash\ngit add tests/path/test.py src/path/file.py\ngit commit -m \"feat: add specific feature\"\n```\n```\n\n## Remember\n- Exact file paths always\n- Complete code in plan (not \"add validation\")\n- Exact commands with expected output\n- Reference relevant skills with @ syntax\n- DRY, YAGNI, TDD, frequent commits\n\n## Execution Handoff\n\nAfter saving the plan, offer execution choice:\n\n**\"Plan complete and saved to `docs/plans/<filename>.md`. Three execution options:**\n\n**1. Subagent-Driven (this session)** - I dispatch fresh subagent per task, review between tasks, fast iteration\n\n**2. Fresh Session (this terminal)** - Clear context and execute all tasks continuously with full focus on implementation\n\n**3. Parallel Session (separate)** - Open new session with executing-plans, continuous execution with clean context\n\n**Which approach?\"**\n\n**If Subagent-Driven chosen:**\n- **REQUIRED SUB-SKILL:** Use superpowers:subagent-driven-development\n- Stay in this session\n- Fresh subagent per task + code review\n\n**If Fresh Session chosen:**\n- Instruct user to do two steps:\n  1. Type `/clear`\n  2. Then type `/superpowers:execute-plan docs/plans/<actual-filename>.md`\n- Benefits: Clean context, no accumulated conversation overhead, full focus on execution\n\n**If Parallel Session chosen:**\n- Guide them to open new session in worktree\n- **REQUIRED SUB-SKILL:** New session uses superpowers:executing-plans\n",
        "plugins/superpowers/skills/writing-skills/SKILL.md": "---\nname: writing-skills\ndescription: Use when creating new skills, editing existing skills, or verifying skills work before deployment\n---\n\n# Writing Skills\n\n## Overview\n\n**Writing skills IS Test-Driven Development applied to process documentation.**\n\n**Personal skills live in agent-specific directories (`~/.claude/skills` for Claude Code, `~/.codex/skills` for Codex)** \n\nYou write test cases (pressure scenarios with subagents), watch them fail (baseline behavior), write the skill (documentation), watch tests pass (agents comply), and refactor (close loopholes).\n\n**Core principle:** If you didn't watch an agent fail without the skill, you don't know if the skill teaches the right thing.\n\n**REQUIRED BACKGROUND:** You MUST understand superpowers:test-driven-development before using this skill. That skill defines the fundamental RED-GREEN-REFACTOR cycle. This skill adapts TDD to documentation.\n\n**Official guidance:** For Anthropic's official skill authoring best practices, see anthropic-best-practices.md. This document provides additional patterns and guidelines that complement the TDD-focused approach in this skill.\n\n## What is a Skill?\n\nA **skill** is a reference guide for proven techniques, patterns, or tools. Skills help future Claude instances find and apply effective approaches.\n\n**Skills are:** Reusable techniques, patterns, tools, reference guides\n\n**Skills are NOT:** Narratives about how you solved a problem once\n\n## TDD Mapping for Skills\n\n| TDD Concept | Skill Creation |\n|-------------|----------------|\n| **Test case** | Pressure scenario with subagent |\n| **Production code** | Skill document (SKILL.md) |\n| **Test fails (RED)** | Agent violates rule without skill (baseline) |\n| **Test passes (GREEN)** | Agent complies with skill present |\n| **Refactor** | Close loopholes while maintaining compliance |\n| **Write test first** | Run baseline scenario BEFORE writing skill |\n| **Watch it fail** | Document exact rationalizations agent uses |\n| **Minimal code** | Write skill addressing those specific violations |\n| **Watch it pass** | Verify agent now complies |\n| **Refactor cycle** | Find new rationalizations â†’ plug â†’ re-verify |\n\nThe entire skill creation process follows RED-GREEN-REFACTOR.\n\n## When to Create a Skill\n\n**Create when:**\n- Technique wasn't intuitively obvious to you\n- You'd reference this again across projects\n- Pattern applies broadly (not project-specific)\n- Others would benefit\n\n**Don't create for:**\n- One-off solutions\n- Standard practices well-documented elsewhere\n- Project-specific conventions (put in CLAUDE.md)\n- Mechanical constraints (if it's enforceable with regex/validation, automate itâ€”save documentation for judgment calls)\n\n## Skill Types\n\n### Technique\nConcrete method with steps to follow (condition-based-waiting, root-cause-tracing)\n\n### Pattern\nWay of thinking about problems (flatten-with-flags, test-invariants)\n\n### Reference\nAPI docs, syntax guides, tool documentation (office docs)\n\n## Directory Structure\n\n\n```\nskills/\n  skill-name/\n    SKILL.md              # Main reference (required)\n    supporting-file.*     # Only if needed\n```\n\n**Flat namespace** - all skills in one searchable namespace\n\n**Separate files for:**\n1. **Heavy reference** (100+ lines) - API docs, comprehensive syntax\n2. **Reusable tools** - Scripts, utilities, templates\n\n**Keep inline:**\n- Principles and concepts\n- Code patterns (< 50 lines)\n- Everything else\n\n## SKILL.md Structure\n\n**Frontmatter (YAML):**\n- Only two fields supported: `name` and `description`\n- Max 1024 characters total\n- `name`: Use letters, numbers, and hyphens only (no parentheses, special chars)\n- `description`: Third-person, describes ONLY when to use (NOT what it does)\n  - Start with \"Use when...\" to focus on triggering conditions\n  - Include specific symptoms, situations, and contexts\n  - **NEVER summarize the skill's process or workflow** (see CSO section for why)\n  - Keep under 500 characters if possible\n\n```markdown\n---\nname: Skill-Name-With-Hyphens\ndescription: Use when [specific triggering conditions and symptoms]\n---\n\n# Skill Name\n\n## Overview\nWhat is this? Core principle in 1-2 sentences.\n\n## When to Use\n[Small inline flowchart IF decision non-obvious]\n\nBullet list with SYMPTOMS and use cases\nWhen NOT to use\n\n## Core Pattern (for techniques/patterns)\nBefore/after code comparison\n\n## Quick Reference\nTable or bullets for scanning common operations\n\n## Implementation\nInline code for simple patterns\nLink to file for heavy reference or reusable tools\n\n## Common Mistakes\nWhat goes wrong + fixes\n\n## Real-World Impact (optional)\nConcrete results\n```\n\n\n## Claude Search Optimization (CSO)\n\n**Critical for discovery:** Future Claude needs to FIND your skill\n\n### 1. Rich Description Field\n\n**Purpose:** Claude reads description to decide which skills to load for a given task. Make it answer: \"Should I read this skill right now?\"\n\n**Format:** Start with \"Use when...\" to focus on triggering conditions\n\n**CRITICAL: Description = When to Use, NOT What the Skill Does**\n\nThe description should ONLY describe triggering conditions. Do NOT summarize the skill's process or workflow in the description.\n\n**Why this matters:** Testing revealed that when a description summarizes the skill's workflow, Claude may follow the description instead of reading the full skill content. A description saying \"code review between tasks\" caused Claude to do ONE review, even though the skill's flowchart clearly showed TWO reviews (spec compliance then code quality).\n\nWhen the description was changed to just \"Use when executing implementation plans with independent tasks\" (no workflow summary), Claude correctly read the flowchart and followed the two-stage review process.\n\n**The trap:** Descriptions that summarize workflow create a shortcut Claude will take. The skill body becomes documentation Claude skips.\n\n```yaml\n# âŒ BAD: Summarizes workflow - Claude may follow this instead of reading skill\ndescription: Use when executing plans - dispatches subagent per task with code review between tasks\n\n# âŒ BAD: Too much process detail\ndescription: Use for TDD - write test first, watch it fail, write minimal code, refactor\n\n# âœ… GOOD: Just triggering conditions, no workflow summary\ndescription: Use when executing implementation plans with independent tasks in the current session\n\n# âœ… GOOD: Triggering conditions only\ndescription: Use when implementing any feature or bugfix, before writing implementation code\n```\n\n**Content:**\n- Use concrete triggers, symptoms, and situations that signal this skill applies\n- Describe the *problem* (race conditions, inconsistent behavior) not *language-specific symptoms* (setTimeout, sleep)\n- Keep triggers technology-agnostic unless the skill itself is technology-specific\n- If skill is technology-specific, make that explicit in the trigger\n- Write in third person (injected into system prompt)\n- **NEVER summarize the skill's process or workflow**\n\n```yaml\n# âŒ BAD: Too abstract, vague, doesn't include when to use\ndescription: For async testing\n\n# âŒ BAD: First person\ndescription: I can help you with async tests when they're flaky\n\n# âŒ BAD: Mentions technology but skill isn't specific to it\ndescription: Use when tests use setTimeout/sleep and are flaky\n\n# âœ… GOOD: Starts with \"Use when\", describes problem, no workflow\ndescription: Use when tests have race conditions, timing dependencies, or pass/fail inconsistently\n\n# âœ… GOOD: Technology-specific skill with explicit trigger\ndescription: Use when using React Router and handling authentication redirects\n```\n\n### 2. Keyword Coverage\n\nUse words Claude would search for:\n- Error messages: \"Hook timed out\", \"ENOTEMPTY\", \"race condition\"\n- Symptoms: \"flaky\", \"hanging\", \"zombie\", \"pollution\"\n- Synonyms: \"timeout/hang/freeze\", \"cleanup/teardown/afterEach\"\n- Tools: Actual commands, library names, file types\n\n### 3. Descriptive Naming\n\n**Use active voice, verb-first:**\n- âœ… `creating-skills` not `skill-creation`\n- âœ… `condition-based-waiting` not `async-test-helpers`\n\n### 4. Token Efficiency (Critical)\n\n**Problem:** getting-started and frequently-referenced skills load into EVERY conversation. Every token counts.\n\n**Target word counts:**\n- getting-started workflows: <150 words each\n- Frequently-loaded skills: <200 words total\n- Other skills: <500 words (still be concise)\n\n**Techniques:**\n\n**Move details to tool help:**\n```bash\n# âŒ BAD: Document all flags in SKILL.md\nsearch-conversations supports --text, --both, --after DATE, --before DATE, --limit N\n\n# âœ… GOOD: Reference --help\nsearch-conversations supports multiple modes and filters. Run --help for details.\n```\n\n**Use cross-references:**\n```markdown\n# âŒ BAD: Repeat workflow details\nWhen searching, dispatch subagent with template...\n[20 lines of repeated instructions]\n\n# âœ… GOOD: Reference other skill\nAlways use subagents (50-100x context savings). REQUIRED: Use [other-skill-name] for workflow.\n```\n\n**Compress examples:**\n```markdown\n# âŒ BAD: Verbose example (42 words)\nyour human partner: \"How did we handle authentication errors in React Router before?\"\nYou: I'll search past conversations for React Router authentication patterns.\n[Dispatch subagent with search query: \"React Router authentication error handling 401\"]\n\n# âœ… GOOD: Minimal example (20 words)\nPartner: \"How did we handle auth errors in React Router?\"\nYou: Searching...\n[Dispatch subagent â†’ synthesis]\n```\n\n**Eliminate redundancy:**\n- Don't repeat what's in cross-referenced skills\n- Don't explain what's obvious from command\n- Don't include multiple examples of same pattern\n\n**Verification:**\n```bash\nwc -w skills/path/SKILL.md\n# getting-started workflows: aim for <150 each\n# Other frequently-loaded: aim for <200 total\n```\n\n**Name by what you DO or core insight:**\n- âœ… `condition-based-waiting` > `async-test-helpers`\n- âœ… `using-skills` not `skill-usage`\n- âœ… `flatten-with-flags` > `data-structure-refactoring`\n- âœ… `root-cause-tracing` > `debugging-techniques`\n\n**Gerunds (-ing) work well for processes:**\n- `creating-skills`, `testing-skills`, `debugging-with-logs`\n- Active, describes the action you're taking\n\n### 4. Cross-Referencing Other Skills\n\n**When writing documentation that references other skills:**\n\nUse skill name only, with explicit requirement markers:\n- âœ… Good: `**REQUIRED SUB-SKILL:** Use superpowers:test-driven-development`\n- âœ… Good: `**REQUIRED BACKGROUND:** You MUST understand superpowers:systematic-debugging`\n- âŒ Bad: `See skills/testing/test-driven-development` (unclear if required)\n- âŒ Bad: `@skills/testing/test-driven-development/SKILL.md` (force-loads, burns context)\n\n**Why no @ links:** `@` syntax force-loads files immediately, consuming 200k+ context before you need them.\n\n## Flowchart Usage\n\n```dot\ndigraph when_flowchart {\n    \"Need to show information?\" [shape=diamond];\n    \"Decision where I might go wrong?\" [shape=diamond];\n    \"Use markdown\" [shape=box];\n    \"Small inline flowchart\" [shape=box];\n\n    \"Need to show information?\" -> \"Decision where I might go wrong?\" [label=\"yes\"];\n    \"Decision where I might go wrong?\" -> \"Small inline flowchart\" [label=\"yes\"];\n    \"Decision where I might go wrong?\" -> \"Use markdown\" [label=\"no\"];\n}\n```\n\n**Use flowcharts ONLY for:**\n- Non-obvious decision points\n- Process loops where you might stop too early\n- \"When to use A vs B\" decisions\n\n**Never use flowcharts for:**\n- Reference material â†’ Tables, lists\n- Code examples â†’ Markdown blocks\n- Linear instructions â†’ Numbered lists\n- Labels without semantic meaning (step1, helper2)\n\nSee @graphviz-conventions.dot for graphviz style rules.\n\n**Visualizing for your human partner:** Use `render-graphs.js` in this directory to render a skill's flowcharts to SVG:\n```bash\n./render-graphs.js ../some-skill           # Each diagram separately\n./render-graphs.js ../some-skill --combine # All diagrams in one SVG\n```\n\n## Code Examples\n\n**One excellent example beats many mediocre ones**\n\nChoose most relevant language:\n- Testing techniques â†’ TypeScript/JavaScript\n- System debugging â†’ Shell/Python\n- Data processing â†’ Python\n\n**Good example:**\n- Complete and runnable\n- Well-commented explaining WHY\n- From real scenario\n- Shows pattern clearly\n- Ready to adapt (not generic template)\n\n**Don't:**\n- Implement in 5+ languages\n- Create fill-in-the-blank templates\n- Write contrived examples\n\nYou're good at porting - one great example is enough.\n\n## File Organization\n\n### Self-Contained Skill\n```\ndefense-in-depth/\n  SKILL.md    # Everything inline\n```\nWhen: All content fits, no heavy reference needed\n\n### Skill with Reusable Tool\n```\ncondition-based-waiting/\n  SKILL.md    # Overview + patterns\n  example.ts  # Working helpers to adapt\n```\nWhen: Tool is reusable code, not just narrative\n\n### Skill with Heavy Reference\n```\npptx/\n  SKILL.md       # Overview + workflows\n  pptxgenjs.md   # 600 lines API reference\n  ooxml.md       # 500 lines XML structure\n  scripts/       # Executable tools\n```\nWhen: Reference material too large for inline\n\n## The Iron Law (Same as TDD)\n\n```\nNO SKILL WITHOUT A FAILING TEST FIRST\n```\n\nThis applies to NEW skills AND EDITS to existing skills.\n\nWrite skill before testing? Delete it. Start over.\nEdit skill without testing? Same violation.\n\n**No exceptions:**\n- Not for \"simple additions\"\n- Not for \"just adding a section\"\n- Not for \"documentation updates\"\n- Don't keep untested changes as \"reference\"\n- Don't \"adapt\" while running tests\n- Delete means delete\n\n**REQUIRED BACKGROUND:** The superpowers:test-driven-development skill explains why this matters. Same principles apply to documentation.\n\n## Testing All Skill Types\n\nDifferent skill types need different test approaches:\n\n### Discipline-Enforcing Skills (rules/requirements)\n\n**Examples:** TDD, verification-before-completion, designing-before-coding\n\n**Test with:**\n- Academic questions: Do they understand the rules?\n- Pressure scenarios: Do they comply under stress?\n- Multiple pressures combined: time + sunk cost + exhaustion\n- Identify rationalizations and add explicit counters\n\n**Success criteria:** Agent follows rule under maximum pressure\n\n### Technique Skills (how-to guides)\n\n**Examples:** condition-based-waiting, root-cause-tracing, defensive-programming\n\n**Test with:**\n- Application scenarios: Can they apply the technique correctly?\n- Variation scenarios: Do they handle edge cases?\n- Missing information tests: Do instructions have gaps?\n\n**Success criteria:** Agent successfully applies technique to new scenario\n\n### Pattern Skills (mental models)\n\n**Examples:** reducing-complexity, information-hiding concepts\n\n**Test with:**\n- Recognition scenarios: Do they recognize when pattern applies?\n- Application scenarios: Can they use the mental model?\n- Counter-examples: Do they know when NOT to apply?\n\n**Success criteria:** Agent correctly identifies when/how to apply pattern\n\n### Reference Skills (documentation/APIs)\n\n**Examples:** API documentation, command references, library guides\n\n**Test with:**\n- Retrieval scenarios: Can they find the right information?\n- Application scenarios: Can they use what they found correctly?\n- Gap testing: Are common use cases covered?\n\n**Success criteria:** Agent finds and correctly applies reference information\n\n## Common Rationalizations for Skipping Testing\n\n| Excuse | Reality |\n|--------|---------|\n| \"Skill is obviously clear\" | Clear to you â‰  clear to other agents. Test it. |\n| \"It's just a reference\" | References can have gaps, unclear sections. Test retrieval. |\n| \"Testing is overkill\" | Untested skills have issues. Always. 15 min testing saves hours. |\n| \"I'll test if problems emerge\" | Problems = agents can't use skill. Test BEFORE deploying. |\n| \"Too tedious to test\" | Testing is less tedious than debugging bad skill in production. |\n| \"I'm confident it's good\" | Overconfidence guarantees issues. Test anyway. |\n| \"Academic review is enough\" | Reading â‰  using. Test application scenarios. |\n| \"No time to test\" | Deploying untested skill wastes more time fixing it later. |\n\n**All of these mean: Test before deploying. No exceptions.**\n\n## Bulletproofing Skills Against Rationalization\n\nSkills that enforce discipline (like TDD) need to resist rationalization. Agents are smart and will find loopholes when under pressure.\n\n**Psychology note:** Understanding WHY persuasion techniques work helps you apply them systematically. See persuasion-principles.md for research foundation (Cialdini, 2021; Meincke et al., 2025) on authority, commitment, scarcity, social proof, and unity principles.\n\n### Close Every Loophole Explicitly\n\nDon't just state the rule - forbid specific workarounds:\n\n<Bad>\n```markdown\nWrite code before test? Delete it.\n```\n</Bad>\n\n<Good>\n```markdown\nWrite code before test? Delete it. Start over.\n\n**No exceptions:**\n- Don't keep it as \"reference\"\n- Don't \"adapt\" it while writing tests\n- Don't look at it\n- Delete means delete\n```\n</Good>\n\n### Address \"Spirit vs Letter\" Arguments\n\nAdd foundational principle early:\n\n```markdown\n**Violating the letter of the rules is violating the spirit of the rules.**\n```\n\nThis cuts off entire class of \"I'm following the spirit\" rationalizations.\n\n### Build Rationalization Table\n\nCapture rationalizations from baseline testing (see Testing section below). Every excuse agents make goes in the table:\n\n```markdown\n| Excuse | Reality |\n|--------|---------|\n| \"Too simple to test\" | Simple code breaks. Test takes 30 seconds. |\n| \"I'll test after\" | Tests passing immediately prove nothing. |\n| \"Tests after achieve same goals\" | Tests-after = \"what does this do?\" Tests-first = \"what should this do?\" |\n```\n\n### Create Red Flags List\n\nMake it easy for agents to self-check when rationalizing:\n\n```markdown\n## Red Flags - STOP and Start Over\n\n- Code before test\n- \"I already manually tested it\"\n- \"Tests after achieve the same purpose\"\n- \"It's about spirit not ritual\"\n- \"This is different because...\"\n\n**All of these mean: Delete code. Start over with TDD.**\n```\n\n### Update CSO for Violation Symptoms\n\nAdd to description: symptoms of when you're ABOUT to violate the rule:\n\n```yaml\ndescription: use when implementing any feature or bugfix, before writing implementation code\n```\n\n## RED-GREEN-REFACTOR for Skills\n\nFollow the TDD cycle:\n\n### RED: Write Failing Test (Baseline)\n\nRun pressure scenario with subagent WITHOUT the skill. Document exact behavior:\n- What choices did they make?\n- What rationalizations did they use (verbatim)?\n- Which pressures triggered violations?\n\nThis is \"watch the test fail\" - you must see what agents naturally do before writing the skill.\n\n### GREEN: Write Minimal Skill\n\nWrite skill that addresses those specific rationalizations. Don't add extra content for hypothetical cases.\n\nRun same scenarios WITH skill. Agent should now comply.\n\n### REFACTOR: Close Loopholes\n\nAgent found new rationalization? Add explicit counter. Re-test until bulletproof.\n\n**Testing methodology:** See @testing-skills-with-subagents.md for the complete testing methodology:\n- How to write pressure scenarios\n- Pressure types (time, sunk cost, authority, exhaustion)\n- Plugging holes systematically\n- Meta-testing techniques\n\n## Anti-Patterns\n\n### âŒ Narrative Example\n\"In session 2025-10-03, we found empty projectDir caused...\"\n**Why bad:** Too specific, not reusable\n\n### âŒ Multi-Language Dilution\nexample-js.js, example-py.py, example-go.go\n**Why bad:** Mediocre quality, maintenance burden\n\n### âŒ Code in Flowcharts\n```dot\nstep1 [label=\"import fs\"];\nstep2 [label=\"read file\"];\n```\n**Why bad:** Can't copy-paste, hard to read\n\n### âŒ Generic Labels\nhelper1, helper2, step3, pattern4\n**Why bad:** Labels should have semantic meaning\n\n## STOP: Before Moving to Next Skill\n\n**After writing ANY skill, you MUST STOP and complete the deployment process.**\n\n**Do NOT:**\n- Create multiple skills in batch without testing each\n- Move to next skill before current one is verified\n- Skip testing because \"batching is more efficient\"\n\n**The deployment checklist below is MANDATORY for EACH skill.**\n\nDeploying untested skills = deploying untested code. It's a violation of quality standards.\n\n## Skill Creation Checklist (TDD Adapted)\n\n**IMPORTANT: Use TodoWrite to create todos for EACH checklist item below.**\n\n**RED Phase - Write Failing Test:**\n- [ ] Create pressure scenarios (3+ combined pressures for discipline skills)\n- [ ] Run scenarios WITHOUT skill - document baseline behavior verbatim\n- [ ] Identify patterns in rationalizations/failures\n\n**GREEN Phase - Write Minimal Skill:**\n- [ ] Name uses only letters, numbers, hyphens (no parentheses/special chars)\n- [ ] YAML frontmatter with only name and description (max 1024 chars)\n- [ ] Description starts with \"Use when...\" and includes specific triggers/symptoms\n- [ ] Description written in third person\n- [ ] Keywords throughout for search (errors, symptoms, tools)\n- [ ] Clear overview with core principle\n- [ ] Address specific baseline failures identified in RED\n- [ ] Code inline OR link to separate file\n- [ ] One excellent example (not multi-language)\n- [ ] Run scenarios WITH skill - verify agents now comply\n\n**REFACTOR Phase - Close Loopholes:**\n- [ ] Identify NEW rationalizations from testing\n- [ ] Add explicit counters (if discipline skill)\n- [ ] Build rationalization table from all test iterations\n- [ ] Create red flags list\n- [ ] Re-test until bulletproof\n\n**Quality Checks:**\n- [ ] Small flowchart only if decision non-obvious\n- [ ] Quick reference table\n- [ ] Common mistakes section\n- [ ] No narrative storytelling\n- [ ] Supporting files only for tools or heavy reference\n\n**Deployment:**\n- [ ] Commit skill to git and push to your fork (if configured)\n- [ ] Consider contributing back via PR (if broadly useful)\n\n## Discovery Workflow\n\nHow future Claude finds your skill:\n\n1. **Encounters problem** (\"tests are flaky\")\n3. **Finds SKILL** (description matches)\n4. **Scans overview** (is this relevant?)\n5. **Reads patterns** (quick reference table)\n6. **Loads example** (only when implementing)\n\n**Optimize for this flow** - put searchable terms early and often.\n\n## The Bottom Line\n\n**Creating skills IS TDD for process documentation.**\n\nSame Iron Law: No skill without failing test first.\nSame cycle: RED (baseline) â†’ GREEN (write skill) â†’ REFACTOR (close loopholes).\nSame benefits: Better quality, fewer surprises, bulletproof results.\n\nIf you follow TDD for code, follow it for skills. It's the same discipline applied to documentation.\n",
        "plugins/superpowers/skills/writing-skills/anthropic-best-practices.md": "# Skill authoring best practices\n\n> Learn how to write effective Skills that Claude can discover and use successfully.\n\nGood Skills are concise, well-structured, and tested with real usage. This guide provides practical authoring decisions to help you write Skills that Claude can discover and use effectively.\n\nFor conceptual background on how Skills work, see the [Skills overview](/en/docs/agents-and-tools/agent-skills/overview).\n\n## Core principles\n\n### Concise is key\n\nThe [context window](https://platform.claude.com/docs/en/build-with-claude/context-windows) is a public good. Your Skill shares the context window with everything else Claude needs to know, including:\n\n* The system prompt\n* Conversation history\n* Other Skills' metadata\n* Your actual request\n\nNot every token in your Skill has an immediate cost. At startup, only the metadata (name and description) from all Skills is pre-loaded. Claude reads SKILL.md only when the Skill becomes relevant, and reads additional files only as needed. However, being concise in SKILL.md still matters: once Claude loads it, every token competes with conversation history and other context.\n\n**Default assumption**: Claude is already very smart\n\nOnly add context Claude doesn't already have. Challenge each piece of information:\n\n* \"Does Claude really need this explanation?\"\n* \"Can I assume Claude knows this?\"\n* \"Does this paragraph justify its token cost?\"\n\n**Good example: Concise** (approximately 50 tokens):\n\n````markdown  theme={null}\n## Extract PDF text\n\nUse pdfplumber for text extraction:\n\n```python\nimport pdfplumber\n\nwith pdfplumber.open(\"file.pdf\") as pdf:\n    text = pdf.pages[0].extract_text()\n```\n````\n\n**Bad example: Too verbose** (approximately 150 tokens):\n\n```markdown  theme={null}\n## Extract PDF text\n\nPDF (Portable Document Format) files are a common file format that contains\ntext, images, and other content. To extract text from a PDF, you'll need to\nuse a library. There are many libraries available for PDF processing, but we\nrecommend pdfplumber because it's easy to use and handles most cases well.\nFirst, you'll need to install it using pip. Then you can use the code below...\n```\n\nThe concise version assumes Claude knows what PDFs are and how libraries work.\n\n### Set appropriate degrees of freedom\n\nMatch the level of specificity to the task's fragility and variability.\n\n**High freedom** (text-based instructions):\n\nUse when:\n\n* Multiple approaches are valid\n* Decisions depend on context\n* Heuristics guide the approach\n\nExample:\n\n```markdown  theme={null}\n## Code review process\n\n1. Analyze the code structure and organization\n2. Check for potential bugs or edge cases\n3. Suggest improvements for readability and maintainability\n4. Verify adherence to project conventions\n```\n\n**Medium freedom** (pseudocode or scripts with parameters):\n\nUse when:\n\n* A preferred pattern exists\n* Some variation is acceptable\n* Configuration affects behavior\n\nExample:\n\n````markdown  theme={null}\n## Generate report\n\nUse this template and customize as needed:\n\n```python\ndef generate_report(data, format=\"markdown\", include_charts=True):\n    # Process data\n    # Generate output in specified format\n    # Optionally include visualizations\n```\n````\n\n**Low freedom** (specific scripts, few or no parameters):\n\nUse when:\n\n* Operations are fragile and error-prone\n* Consistency is critical\n* A specific sequence must be followed\n\nExample:\n\n````markdown  theme={null}\n## Database migration\n\nRun exactly this script:\n\n```bash\npython scripts/migrate.py --verify --backup\n```\n\nDo not modify the command or add additional flags.\n````\n\n**Analogy**: Think of Claude as a robot exploring a path:\n\n* **Narrow bridge with cliffs on both sides**: There's only one safe way forward. Provide specific guardrails and exact instructions (low freedom). Example: database migrations that must run in exact sequence.\n* **Open field with no hazards**: Many paths lead to success. Give general direction and trust Claude to find the best route (high freedom). Example: code reviews where context determines the best approach.\n\n### Test with all models you plan to use\n\nSkills act as additions to models, so effectiveness depends on the underlying model. Test your Skill with all the models you plan to use it with.\n\n**Testing considerations by model**:\n\n* **Claude Haiku** (fast, economical): Does the Skill provide enough guidance?\n* **Claude Sonnet** (balanced): Is the Skill clear and efficient?\n* **Claude Opus** (powerful reasoning): Does the Skill avoid over-explaining?\n\nWhat works perfectly for Opus might need more detail for Haiku. If you plan to use your Skill across multiple models, aim for instructions that work well with all of them.\n\n## Skill structure\n\n<Note>\n  **YAML Frontmatter**: The SKILL.md frontmatter supports two fields:\n\n  * `name` - Human-readable name of the Skill (64 characters maximum)\n  * `description` - One-line description of what the Skill does and when to use it (1024 characters maximum)\n\n  For complete Skill structure details, see the [Skills overview](/en/docs/agents-and-tools/agent-skills/overview#skill-structure).\n</Note>\n\n### Naming conventions\n\nUse consistent naming patterns to make Skills easier to reference and discuss. We recommend using **gerund form** (verb + -ing) for Skill names, as this clearly describes the activity or capability the Skill provides.\n\n**Good naming examples (gerund form)**:\n\n* \"Processing PDFs\"\n* \"Analyzing spreadsheets\"\n* \"Managing databases\"\n* \"Testing code\"\n* \"Writing documentation\"\n\n**Acceptable alternatives**:\n\n* Noun phrases: \"PDF Processing\", \"Spreadsheet Analysis\"\n* Action-oriented: \"Process PDFs\", \"Analyze Spreadsheets\"\n\n**Avoid**:\n\n* Vague names: \"Helper\", \"Utils\", \"Tools\"\n* Overly generic: \"Documents\", \"Data\", \"Files\"\n* Inconsistent patterns within your skill collection\n\nConsistent naming makes it easier to:\n\n* Reference Skills in documentation and conversations\n* Understand what a Skill does at a glance\n* Organize and search through multiple Skills\n* Maintain a professional, cohesive skill library\n\n### Writing effective descriptions\n\nThe `description` field enables Skill discovery and should include both what the Skill does and when to use it.\n\n<Warning>\n  **Always write in third person**. The description is injected into the system prompt, and inconsistent point-of-view can cause discovery problems.\n\n  * **Good:** \"Processes Excel files and generates reports\"\n  * **Avoid:** \"I can help you process Excel files\"\n  * **Avoid:** \"You can use this to process Excel files\"\n</Warning>\n\n**Be specific and include key terms**. Include both what the Skill does and specific triggers/contexts for when to use it.\n\nEach Skill has exactly one description field. The description is critical for skill selection: Claude uses it to choose the right Skill from potentially 100+ available Skills. Your description must provide enough detail for Claude to know when to select this Skill, while the rest of SKILL.md provides the implementation details.\n\nEffective examples:\n\n**PDF Processing skill:**\n\n```yaml  theme={null}\ndescription: Extract text and tables from PDF files, fill forms, merge documents. Use when working with PDF files or when the user mentions PDFs, forms, or document extraction.\n```\n\n**Excel Analysis skill:**\n\n```yaml  theme={null}\ndescription: Analyze Excel spreadsheets, create pivot tables, generate charts. Use when analyzing Excel files, spreadsheets, tabular data, or .xlsx files.\n```\n\n**Git Commit Helper skill:**\n\n```yaml  theme={null}\ndescription: Generate descriptive commit messages by analyzing git diffs. Use when the user asks for help writing commit messages or reviewing staged changes.\n```\n\nAvoid vague descriptions like these:\n\n```yaml  theme={null}\ndescription: Helps with documents\n```\n\n```yaml  theme={null}\ndescription: Processes data\n```\n\n```yaml  theme={null}\ndescription: Does stuff with files\n```\n\n### Progressive disclosure patterns\n\nSKILL.md serves as an overview that points Claude to detailed materials as needed, like a table of contents in an onboarding guide. For an explanation of how progressive disclosure works, see [How Skills work](/en/docs/agents-and-tools/agent-skills/overview#how-skills-work) in the overview.\n\n**Practical guidance:**\n\n* Keep SKILL.md body under 500 lines for optimal performance\n* Split content into separate files when approaching this limit\n* Use the patterns below to organize instructions, code, and resources effectively\n\n#### Visual overview: From simple to complex\n\nA basic Skill starts with just a SKILL.md file containing metadata and instructions:\n\n<img src=\"https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-simple-file.png?fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=87782ff239b297d9a9e8e1b72ed72db9\" alt=\"Simple SKILL.md file showing YAML frontmatter and markdown body\" data-og-width=\"2048\" width=\"2048\" data-og-height=\"1153\" height=\"1153\" data-path=\"images/agent-skills-simple-file.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-simple-file.png?w=280&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=c61cc33b6f5855809907f7fda94cd80e 280w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-simple-file.png?w=560&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=90d2c0c1c76b36e8d485f49e0810dbfd 560w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-simple-file.png?w=840&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=ad17d231ac7b0bea7e5b4d58fb4aeabb 840w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-simple-file.png?w=1100&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=f5d0a7a3c668435bb0aee9a3a8f8c329 1100w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-simple-file.png?w=1650&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=0e927c1af9de5799cfe557d12249f6e6 1650w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-simple-file.png?w=2500&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=46bbb1a51dd4c8202a470ac8c80a893d 2500w\" />\n\nAs your Skill grows, you can bundle additional content that Claude loads only when needed:\n\n<img src=\"https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-bundling-content.png?fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=a5e0aa41e3d53985a7e3e43668a33ea3\" alt=\"Bundling additional reference files like reference.md and forms.md.\" data-og-width=\"2048\" width=\"2048\" data-og-height=\"1327\" height=\"1327\" data-path=\"images/agent-skills-bundling-content.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-bundling-content.png?w=280&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=f8a0e73783e99b4a643d79eac86b70a2 280w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-bundling-content.png?w=560&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=dc510a2a9d3f14359416b706f067904a 560w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-bundling-content.png?w=840&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=82cd6286c966303f7dd914c28170e385 840w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-bundling-content.png?w=1100&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=56f3be36c77e4fe4b523df209a6824c6 1100w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-bundling-content.png?w=1650&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=d22b5161b2075656417d56f41a74f3dd 1650w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-bundling-content.png?w=2500&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=3dd4bdd6850ffcc96c6c45fcb0acd6eb 2500w\" />\n\nThe complete Skill directory structure might look like this:\n\n```\npdf/\nâ”œâ”€â”€ SKILL.md              # Main instructions (loaded when triggered)\nâ”œâ”€â”€ FORMS.md              # Form-filling guide (loaded as needed)\nâ”œâ”€â”€ reference.md          # API reference (loaded as needed)\nâ”œâ”€â”€ examples.md           # Usage examples (loaded as needed)\nâ””â”€â”€ scripts/\n    â”œâ”€â”€ analyze_form.py   # Utility script (executed, not loaded)\n    â”œâ”€â”€ fill_form.py      # Form filling script\n    â””â”€â”€ validate.py       # Validation script\n```\n\n#### Pattern 1: High-level guide with references\n\n````markdown  theme={null}\n---\nname: PDF Processing\ndescription: Extracts text and tables from PDF files, fills forms, and merges documents. Use when working with PDF files or when the user mentions PDFs, forms, or document extraction.\n---\n\n# PDF Processing\n\n## Quick start\n\nExtract text with pdfplumber:\n```python\nimport pdfplumber\nwith pdfplumber.open(\"file.pdf\") as pdf:\n    text = pdf.pages[0].extract_text()\n```\n\n## Advanced features\n\n**Form filling**: See [FORMS.md](FORMS.md) for complete guide\n**API reference**: See [REFERENCE.md](REFERENCE.md) for all methods\n**Examples**: See [EXAMPLES.md](EXAMPLES.md) for common patterns\n````\n\nClaude loads FORMS.md, REFERENCE.md, or EXAMPLES.md only when needed.\n\n#### Pattern 2: Domain-specific organization\n\nFor Skills with multiple domains, organize content by domain to avoid loading irrelevant context. When a user asks about sales metrics, Claude only needs to read sales-related schemas, not finance or marketing data. This keeps token usage low and context focused.\n\n```\nbigquery-skill/\nâ”œâ”€â”€ SKILL.md (overview and navigation)\nâ””â”€â”€ reference/\n    â”œâ”€â”€ finance.md (revenue, billing metrics)\n    â”œâ”€â”€ sales.md (opportunities, pipeline)\n    â”œâ”€â”€ product.md (API usage, features)\n    â””â”€â”€ marketing.md (campaigns, attribution)\n```\n\n````markdown SKILL.md theme={null}\n# BigQuery Data Analysis\n\n## Available datasets\n\n**Finance**: Revenue, ARR, billing â†’ See [reference/finance.md](reference/finance.md)\n**Sales**: Opportunities, pipeline, accounts â†’ See [reference/sales.md](reference/sales.md)\n**Product**: API usage, features, adoption â†’ See [reference/product.md](reference/product.md)\n**Marketing**: Campaigns, attribution, email â†’ See [reference/marketing.md](reference/marketing.md)\n\n## Quick search\n\nFind specific metrics using grep:\n\n```bash\ngrep -i \"revenue\" reference/finance.md\ngrep -i \"pipeline\" reference/sales.md\ngrep -i \"api usage\" reference/product.md\n```\n````\n\n#### Pattern 3: Conditional details\n\nShow basic content, link to advanced content:\n\n```markdown  theme={null}\n# DOCX Processing\n\n## Creating documents\n\nUse docx-js for new documents. See [DOCX-JS.md](DOCX-JS.md).\n\n## Editing documents\n\nFor simple edits, modify the XML directly.\n\n**For tracked changes**: See [REDLINING.md](REDLINING.md)\n**For OOXML details**: See [OOXML.md](OOXML.md)\n```\n\nClaude reads REDLINING.md or OOXML.md only when the user needs those features.\n\n### Avoid deeply nested references\n\nClaude may partially read files when they're referenced from other referenced files. When encountering nested references, Claude might use commands like `head -100` to preview content rather than reading entire files, resulting in incomplete information.\n\n**Keep references one level deep from SKILL.md**. All reference files should link directly from SKILL.md to ensure Claude reads complete files when needed.\n\n**Bad example: Too deep**:\n\n```markdown  theme={null}\n# SKILL.md\nSee [advanced.md](advanced.md)...\n\n# advanced.md\nSee [details.md](details.md)...\n\n# details.md\nHere's the actual information...\n```\n\n**Good example: One level deep**:\n\n```markdown  theme={null}\n# SKILL.md\n\n**Basic usage**: [instructions in SKILL.md]\n**Advanced features**: See [advanced.md](advanced.md)\n**API reference**: See [reference.md](reference.md)\n**Examples**: See [examples.md](examples.md)\n```\n\n### Structure longer reference files with table of contents\n\nFor reference files longer than 100 lines, include a table of contents at the top. This ensures Claude can see the full scope of available information even when previewing with partial reads.\n\n**Example**:\n\n```markdown  theme={null}\n# API Reference\n\n## Contents\n- Authentication and setup\n- Core methods (create, read, update, delete)\n- Advanced features (batch operations, webhooks)\n- Error handling patterns\n- Code examples\n\n## Authentication and setup\n...\n\n## Core methods\n...\n```\n\nClaude can then read the complete file or jump to specific sections as needed.\n\nFor details on how this filesystem-based architecture enables progressive disclosure, see the [Runtime environment](#runtime-environment) section in the Advanced section below.\n\n## Workflows and feedback loops\n\n### Use workflows for complex tasks\n\nBreak complex operations into clear, sequential steps. For particularly complex workflows, provide a checklist that Claude can copy into its response and check off as it progresses.\n\n**Example 1: Research synthesis workflow** (for Skills without code):\n\n````markdown  theme={null}\n## Research synthesis workflow\n\nCopy this checklist and track your progress:\n\n```\nResearch Progress:\n- [ ] Step 1: Read all source documents\n- [ ] Step 2: Identify key themes\n- [ ] Step 3: Cross-reference claims\n- [ ] Step 4: Create structured summary\n- [ ] Step 5: Verify citations\n```\n\n**Step 1: Read all source documents**\n\nReview each document in the `sources/` directory. Note the main arguments and supporting evidence.\n\n**Step 2: Identify key themes**\n\nLook for patterns across sources. What themes appear repeatedly? Where do sources agree or disagree?\n\n**Step 3: Cross-reference claims**\n\nFor each major claim, verify it appears in the source material. Note which source supports each point.\n\n**Step 4: Create structured summary**\n\nOrganize findings by theme. Include:\n- Main claim\n- Supporting evidence from sources\n- Conflicting viewpoints (if any)\n\n**Step 5: Verify citations**\n\nCheck that every claim references the correct source document. If citations are incomplete, return to Step 3.\n````\n\nThis example shows how workflows apply to analysis tasks that don't require code. The checklist pattern works for any complex, multi-step process.\n\n**Example 2: PDF form filling workflow** (for Skills with code):\n\n````markdown  theme={null}\n## PDF form filling workflow\n\nCopy this checklist and check off items as you complete them:\n\n```\nTask Progress:\n- [ ] Step 1: Analyze the form (run analyze_form.py)\n- [ ] Step 2: Create field mapping (edit fields.json)\n- [ ] Step 3: Validate mapping (run validate_fields.py)\n- [ ] Step 4: Fill the form (run fill_form.py)\n- [ ] Step 5: Verify output (run verify_output.py)\n```\n\n**Step 1: Analyze the form**\n\nRun: `python scripts/analyze_form.py input.pdf`\n\nThis extracts form fields and their locations, saving to `fields.json`.\n\n**Step 2: Create field mapping**\n\nEdit `fields.json` to add values for each field.\n\n**Step 3: Validate mapping**\n\nRun: `python scripts/validate_fields.py fields.json`\n\nFix any validation errors before continuing.\n\n**Step 4: Fill the form**\n\nRun: `python scripts/fill_form.py input.pdf fields.json output.pdf`\n\n**Step 5: Verify output**\n\nRun: `python scripts/verify_output.py output.pdf`\n\nIf verification fails, return to Step 2.\n````\n\nClear steps prevent Claude from skipping critical validation. The checklist helps both Claude and you track progress through multi-step workflows.\n\n### Implement feedback loops\n\n**Common pattern**: Run validator â†’ fix errors â†’ repeat\n\nThis pattern greatly improves output quality.\n\n**Example 1: Style guide compliance** (for Skills without code):\n\n```markdown  theme={null}\n## Content review process\n\n1. Draft your content following the guidelines in STYLE_GUIDE.md\n2. Review against the checklist:\n   - Check terminology consistency\n   - Verify examples follow the standard format\n   - Confirm all required sections are present\n3. If issues found:\n   - Note each issue with specific section reference\n   - Revise the content\n   - Review the checklist again\n4. Only proceed when all requirements are met\n5. Finalize and save the document\n```\n\nThis shows the validation loop pattern using reference documents instead of scripts. The \"validator\" is STYLE\\_GUIDE.md, and Claude performs the check by reading and comparing.\n\n**Example 2: Document editing process** (for Skills with code):\n\n```markdown  theme={null}\n## Document editing process\n\n1. Make your edits to `word/document.xml`\n2. **Validate immediately**: `python ooxml/scripts/validate.py unpacked_dir/`\n3. If validation fails:\n   - Review the error message carefully\n   - Fix the issues in the XML\n   - Run validation again\n4. **Only proceed when validation passes**\n5. Rebuild: `python ooxml/scripts/pack.py unpacked_dir/ output.docx`\n6. Test the output document\n```\n\nThe validation loop catches errors early.\n\n## Content guidelines\n\n### Avoid time-sensitive information\n\nDon't include information that will become outdated:\n\n**Bad example: Time-sensitive** (will become wrong):\n\n```markdown  theme={null}\nIf you're doing this before August 2025, use the old API.\nAfter August 2025, use the new API.\n```\n\n**Good example** (use \"old patterns\" section):\n\n```markdown  theme={null}\n## Current method\n\nUse the v2 API endpoint: `api.example.com/v2/messages`\n\n## Old patterns\n\n<details>\n<summary>Legacy v1 API (deprecated 2025-08)</summary>\n\nThe v1 API used: `api.example.com/v1/messages`\n\nThis endpoint is no longer supported.\n</details>\n```\n\nThe old patterns section provides historical context without cluttering the main content.\n\n### Use consistent terminology\n\nChoose one term and use it throughout the Skill:\n\n**Good - Consistent**:\n\n* Always \"API endpoint\"\n* Always \"field\"\n* Always \"extract\"\n\n**Bad - Inconsistent**:\n\n* Mix \"API endpoint\", \"URL\", \"API route\", \"path\"\n* Mix \"field\", \"box\", \"element\", \"control\"\n* Mix \"extract\", \"pull\", \"get\", \"retrieve\"\n\nConsistency helps Claude understand and follow instructions.\n\n## Common patterns\n\n### Template pattern\n\nProvide templates for output format. Match the level of strictness to your needs.\n\n**For strict requirements** (like API responses or data formats):\n\n````markdown  theme={null}\n## Report structure\n\nALWAYS use this exact template structure:\n\n```markdown\n# [Analysis Title]\n\n## Executive summary\n[One-paragraph overview of key findings]\n\n## Key findings\n- Finding 1 with supporting data\n- Finding 2 with supporting data\n- Finding 3 with supporting data\n\n## Recommendations\n1. Specific actionable recommendation\n2. Specific actionable recommendation\n```\n````\n\n**For flexible guidance** (when adaptation is useful):\n\n````markdown  theme={null}\n## Report structure\n\nHere is a sensible default format, but use your best judgment based on the analysis:\n\n```markdown\n# [Analysis Title]\n\n## Executive summary\n[Overview]\n\n## Key findings\n[Adapt sections based on what you discover]\n\n## Recommendations\n[Tailor to the specific context]\n```\n\nAdjust sections as needed for the specific analysis type.\n````\n\n### Examples pattern\n\nFor Skills where output quality depends on seeing examples, provide input/output pairs just like in regular prompting:\n\n````markdown  theme={null}\n## Commit message format\n\nGenerate commit messages following these examples:\n\n**Example 1:**\nInput: Added user authentication with JWT tokens\nOutput:\n```\nfeat(auth): implement JWT-based authentication\n\nAdd login endpoint and token validation middleware\n```\n\n**Example 2:**\nInput: Fixed bug where dates displayed incorrectly in reports\nOutput:\n```\nfix(reports): correct date formatting in timezone conversion\n\nUse UTC timestamps consistently across report generation\n```\n\n**Example 3:**\nInput: Updated dependencies and refactored error handling\nOutput:\n```\nchore: update dependencies and refactor error handling\n\n- Upgrade lodash to 4.17.21\n- Standardize error response format across endpoints\n```\n\nFollow this style: type(scope): brief description, then detailed explanation.\n````\n\nExamples help Claude understand the desired style and level of detail more clearly than descriptions alone.\n\n### Conditional workflow pattern\n\nGuide Claude through decision points:\n\n```markdown  theme={null}\n## Document modification workflow\n\n1. Determine the modification type:\n\n   **Creating new content?** â†’ Follow \"Creation workflow\" below\n   **Editing existing content?** â†’ Follow \"Editing workflow\" below\n\n2. Creation workflow:\n   - Use docx-js library\n   - Build document from scratch\n   - Export to .docx format\n\n3. Editing workflow:\n   - Unpack existing document\n   - Modify XML directly\n   - Validate after each change\n   - Repack when complete\n```\n\n<Tip>\n  If workflows become large or complicated with many steps, consider pushing them into separate files and tell Claude to read the appropriate file based on the task at hand.\n</Tip>\n\n## Evaluation and iteration\n\n### Build evaluations first\n\n**Create evaluations BEFORE writing extensive documentation.** This ensures your Skill solves real problems rather than documenting imagined ones.\n\n**Evaluation-driven development:**\n\n1. **Identify gaps**: Run Claude on representative tasks without a Skill. Document specific failures or missing context\n2. **Create evaluations**: Build three scenarios that test these gaps\n3. **Establish baseline**: Measure Claude's performance without the Skill\n4. **Write minimal instructions**: Create just enough content to address the gaps and pass evaluations\n5. **Iterate**: Execute evaluations, compare against baseline, and refine\n\nThis approach ensures you're solving actual problems rather than anticipating requirements that may never materialize.\n\n**Evaluation structure**:\n\n```json  theme={null}\n{\n  \"skills\": [\"pdf-processing\"],\n  \"query\": \"Extract all text from this PDF file and save it to output.txt\",\n  \"files\": [\"test-files/document.pdf\"],\n  \"expected_behavior\": [\n    \"Successfully reads the PDF file using an appropriate PDF processing library or command-line tool\",\n    \"Extracts text content from all pages in the document without missing any pages\",\n    \"Saves the extracted text to a file named output.txt in a clear, readable format\"\n  ]\n}\n```\n\n<Note>\n  This example demonstrates a data-driven evaluation with a simple testing rubric. We do not currently provide a built-in way to run these evaluations. Users can create their own evaluation system. Evaluations are your source of truth for measuring Skill effectiveness.\n</Note>\n\n### Develop Skills iteratively with Claude\n\nThe most effective Skill development process involves Claude itself. Work with one instance of Claude (\"Claude A\") to create a Skill that will be used by other instances (\"Claude B\"). Claude A helps you design and refine instructions, while Claude B tests them in real tasks. This works because Claude models understand both how to write effective agent instructions and what information agents need.\n\n**Creating a new Skill:**\n\n1. **Complete a task without a Skill**: Work through a problem with Claude A using normal prompting. As you work, you'll naturally provide context, explain preferences, and share procedural knowledge. Notice what information you repeatedly provide.\n\n2. **Identify the reusable pattern**: After completing the task, identify what context you provided that would be useful for similar future tasks.\n\n   **Example**: If you worked through a BigQuery analysis, you might have provided table names, field definitions, filtering rules (like \"always exclude test accounts\"), and common query patterns.\n\n3. **Ask Claude A to create a Skill**: \"Create a Skill that captures this BigQuery analysis pattern we just used. Include the table schemas, naming conventions, and the rule about filtering test accounts.\"\n\n   <Tip>\n     Claude models understand the Skill format and structure natively. You don't need special system prompts or a \"writing skills\" skill to get Claude to help create Skills. Simply ask Claude to create a Skill and it will generate properly structured SKILL.md content with appropriate frontmatter and body content.\n   </Tip>\n\n4. **Review for conciseness**: Check that Claude A hasn't added unnecessary explanations. Ask: \"Remove the explanation about what win rate means - Claude already knows that.\"\n\n5. **Improve information architecture**: Ask Claude A to organize the content more effectively. For example: \"Organize this so the table schema is in a separate reference file. We might add more tables later.\"\n\n6. **Test on similar tasks**: Use the Skill with Claude B (a fresh instance with the Skill loaded) on related use cases. Observe whether Claude B finds the right information, applies rules correctly, and handles the task successfully.\n\n7. **Iterate based on observation**: If Claude B struggles or misses something, return to Claude A with specifics: \"When Claude used this Skill, it forgot to filter by date for Q4. Should we add a section about date filtering patterns?\"\n\n**Iterating on existing Skills:**\n\nThe same hierarchical pattern continues when improving Skills. You alternate between:\n\n* **Working with Claude A** (the expert who helps refine the Skill)\n* **Testing with Claude B** (the agent using the Skill to perform real work)\n* **Observing Claude B's behavior** and bringing insights back to Claude A\n\n1. **Use the Skill in real workflows**: Give Claude B (with the Skill loaded) actual tasks, not test scenarios\n\n2. **Observe Claude B's behavior**: Note where it struggles, succeeds, or makes unexpected choices\n\n   **Example observation**: \"When I asked Claude B for a regional sales report, it wrote the query but forgot to filter out test accounts, even though the Skill mentions this rule.\"\n\n3. **Return to Claude A for improvements**: Share the current SKILL.md and describe what you observed. Ask: \"I noticed Claude B forgot to filter test accounts when I asked for a regional report. The Skill mentions filtering, but maybe it's not prominent enough?\"\n\n4. **Review Claude A's suggestions**: Claude A might suggest reorganizing to make rules more prominent, using stronger language like \"MUST filter\" instead of \"always filter\", or restructuring the workflow section.\n\n5. **Apply and test changes**: Update the Skill with Claude A's refinements, then test again with Claude B on similar requests\n\n6. **Repeat based on usage**: Continue this observe-refine-test cycle as you encounter new scenarios. Each iteration improves the Skill based on real agent behavior, not assumptions.\n\n**Gathering team feedback:**\n\n1. Share Skills with teammates and observe their usage\n2. Ask: Does the Skill activate when expected? Are instructions clear? What's missing?\n3. Incorporate feedback to address blind spots in your own usage patterns\n\n**Why this approach works**: Claude A understands agent needs, you provide domain expertise, Claude B reveals gaps through real usage, and iterative refinement improves Skills based on observed behavior rather than assumptions.\n\n### Observe how Claude navigates Skills\n\nAs you iterate on Skills, pay attention to how Claude actually uses them in practice. Watch for:\n\n* **Unexpected exploration paths**: Does Claude read files in an order you didn't anticipate? This might indicate your structure isn't as intuitive as you thought\n* **Missed connections**: Does Claude fail to follow references to important files? Your links might need to be more explicit or prominent\n* **Overreliance on certain sections**: If Claude repeatedly reads the same file, consider whether that content should be in the main SKILL.md instead\n* **Ignored content**: If Claude never accesses a bundled file, it might be unnecessary or poorly signaled in the main instructions\n\nIterate based on these observations rather than assumptions. The 'name' and 'description' in your Skill's metadata are particularly critical. Claude uses these when deciding whether to trigger the Skill in response to the current task. Make sure they clearly describe what the Skill does and when it should be used.\n\n## Anti-patterns to avoid\n\n### Avoid Windows-style paths\n\nAlways use forward slashes in file paths, even on Windows:\n\n* âœ“ **Good**: `scripts/helper.py`, `reference/guide.md`\n* âœ— **Avoid**: `scripts\\helper.py`, `reference\\guide.md`\n\nUnix-style paths work across all platforms, while Windows-style paths cause errors on Unix systems.\n\n### Avoid offering too many options\n\nDon't present multiple approaches unless necessary:\n\n````markdown  theme={null}\n**Bad example: Too many choices** (confusing):\n\"You can use pypdf, or pdfplumber, or PyMuPDF, or pdf2image, or...\"\n\n**Good example: Provide a default** (with escape hatch):\n\"Use pdfplumber for text extraction:\n```python\nimport pdfplumber\n```\n\nFor scanned PDFs requiring OCR, use pdf2image with pytesseract instead.\"\n````\n\n## Advanced: Skills with executable code\n\nThe sections below focus on Skills that include executable scripts. If your Skill uses only markdown instructions, skip to [Checklist for effective Skills](#checklist-for-effective-skills).\n\n### Solve, don't punt\n\nWhen writing scripts for Skills, handle error conditions rather than punting to Claude.\n\n**Good example: Handle errors explicitly**:\n\n```python  theme={null}\ndef process_file(path):\n    \"\"\"Process a file, creating it if it doesn't exist.\"\"\"\n    try:\n        with open(path) as f:\n            return f.read()\n    except FileNotFoundError:\n        # Create file with default content instead of failing\n        print(f\"File {path} not found, creating default\")\n        with open(path, 'w') as f:\n            f.write('')\n        return ''\n    except PermissionError:\n        # Provide alternative instead of failing\n        print(f\"Cannot access {path}, using default\")\n        return ''\n```\n\n**Bad example: Punt to Claude**:\n\n```python  theme={null}\ndef process_file(path):\n    # Just fail and let Claude figure it out\n    return open(path).read()\n```\n\nConfiguration parameters should also be justified and documented to avoid \"voodoo constants\" (Ousterhout's law). If you don't know the right value, how will Claude determine it?\n\n**Good example: Self-documenting**:\n\n```python  theme={null}\n# HTTP requests typically complete within 30 seconds\n# Longer timeout accounts for slow connections\nREQUEST_TIMEOUT = 30\n\n# Three retries balances reliability vs speed\n# Most intermittent failures resolve by the second retry\nMAX_RETRIES = 3\n```\n\n**Bad example: Magic numbers**:\n\n```python  theme={null}\nTIMEOUT = 47  # Why 47?\nRETRIES = 5   # Why 5?\n```\n\n### Provide utility scripts\n\nEven if Claude could write a script, pre-made scripts offer advantages:\n\n**Benefits of utility scripts**:\n\n* More reliable than generated code\n* Save tokens (no need to include code in context)\n* Save time (no code generation required)\n* Ensure consistency across uses\n\n<img src=\"https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-executable-scripts.png?fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=4bbc45f2c2e0bee9f2f0d5da669bad00\" alt=\"Bundling executable scripts alongside instruction files\" data-og-width=\"2048\" width=\"2048\" data-og-height=\"1154\" height=\"1154\" data-path=\"images/agent-skills-executable-scripts.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-executable-scripts.png?w=280&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=9a04e6535a8467bfeea492e517de389f 280w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-executable-scripts.png?w=560&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=e49333ad90141af17c0d7651cca7216b 560w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-executable-scripts.png?w=840&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=954265a5df52223d6572b6214168c428 840w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-executable-scripts.png?w=1100&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=2ff7a2d8f2a83ee8af132b29f10150fd 1100w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-executable-scripts.png?w=1650&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=48ab96245e04077f4d15e9170e081cfb 1650w, https://mintcdn.com/anthropic-claude-docs/4Bny2bjzuGBK7o00/images/agent-skills-executable-scripts.png?w=2500&fit=max&auto=format&n=4Bny2bjzuGBK7o00&q=85&s=0301a6c8b3ee879497cc5b5483177c90 2500w\" />\n\nThe diagram above shows how executable scripts work alongside instruction files. The instruction file (forms.md) references the script, and Claude can execute it without loading its contents into context.\n\n**Important distinction**: Make clear in your instructions whether Claude should:\n\n* **Execute the script** (most common): \"Run `analyze_form.py` to extract fields\"\n* **Read it as reference** (for complex logic): \"See `analyze_form.py` for the field extraction algorithm\"\n\nFor most utility scripts, execution is preferred because it's more reliable and efficient. See the [Runtime environment](#runtime-environment) section below for details on how script execution works.\n\n**Example**:\n\n````markdown  theme={null}\n## Utility scripts\n\n**analyze_form.py**: Extract all form fields from PDF\n\n```bash\npython scripts/analyze_form.py input.pdf > fields.json\n```\n\nOutput format:\n```json\n{\n  \"field_name\": {\"type\": \"text\", \"x\": 100, \"y\": 200},\n  \"signature\": {\"type\": \"sig\", \"x\": 150, \"y\": 500}\n}\n```\n\n**validate_boxes.py**: Check for overlapping bounding boxes\n\n```bash\npython scripts/validate_boxes.py fields.json\n# Returns: \"OK\" or lists conflicts\n```\n\n**fill_form.py**: Apply field values to PDF\n\n```bash\npython scripts/fill_form.py input.pdf fields.json output.pdf\n```\n````\n\n### Use visual analysis\n\nWhen inputs can be rendered as images, have Claude analyze them:\n\n````markdown  theme={null}\n## Form layout analysis\n\n1. Convert PDF to images:\n   ```bash\n   python scripts/pdf_to_images.py form.pdf\n   ```\n\n2. Analyze each page image to identify form fields\n3. Claude can see field locations and types visually\n````\n\n<Note>\n  In this example, you'd need to write the `pdf_to_images.py` script.\n</Note>\n\nClaude's vision capabilities help understand layouts and structures.\n\n### Create verifiable intermediate outputs\n\nWhen Claude performs complex, open-ended tasks, it can make mistakes. The \"plan-validate-execute\" pattern catches errors early by having Claude first create a plan in a structured format, then validate that plan with a script before executing it.\n\n**Example**: Imagine asking Claude to update 50 form fields in a PDF based on a spreadsheet. Without validation, Claude might reference non-existent fields, create conflicting values, miss required fields, or apply updates incorrectly.\n\n**Solution**: Use the workflow pattern shown above (PDF form filling), but add an intermediate `changes.json` file that gets validated before applying changes. The workflow becomes: analyze â†’ **create plan file** â†’ **validate plan** â†’ execute â†’ verify.\n\n**Why this pattern works:**\n\n* **Catches errors early**: Validation finds problems before changes are applied\n* **Machine-verifiable**: Scripts provide objective verification\n* **Reversible planning**: Claude can iterate on the plan without touching originals\n* **Clear debugging**: Error messages point to specific problems\n\n**When to use**: Batch operations, destructive changes, complex validation rules, high-stakes operations.\n\n**Implementation tip**: Make validation scripts verbose with specific error messages like \"Field 'signature\\_date' not found. Available fields: customer\\_name, order\\_total, signature\\_date\\_signed\" to help Claude fix issues.\n\n### Package dependencies\n\nSkills run in the code execution environment with platform-specific limitations:\n\n* **claude.ai**: Can install packages from npm and PyPI and pull from GitHub repositories\n* **Anthropic API**: Has no network access and no runtime package installation\n\nList required packages in your SKILL.md and verify they're available in the [code execution tool documentation](/en/docs/agents-and-tools/tool-use/code-execution-tool).\n\n### Runtime environment\n\nSkills run in a code execution environment with filesystem access, bash commands, and code execution capabilities. For the conceptual explanation of this architecture, see [The Skills architecture](/en/docs/agents-and-tools/agent-skills/overview#the-skills-architecture) in the overview.\n\n**How this affects your authoring:**\n\n**How Claude accesses Skills:**\n\n1. **Metadata pre-loaded**: At startup, the name and description from all Skills' YAML frontmatter are loaded into the system prompt\n2. **Files read on-demand**: Claude uses bash Read tools to access SKILL.md and other files from the filesystem when needed\n3. **Scripts executed efficiently**: Utility scripts can be executed via bash without loading their full contents into context. Only the script's output consumes tokens\n4. **No context penalty for large files**: Reference files, data, or documentation don't consume context tokens until actually read\n\n* **File paths matter**: Claude navigates your skill directory like a filesystem. Use forward slashes (`reference/guide.md`), not backslashes\n* **Name files descriptively**: Use names that indicate content: `form_validation_rules.md`, not `doc2.md`\n* **Organize for discovery**: Structure directories by domain or feature\n  * Good: `reference/finance.md`, `reference/sales.md`\n  * Bad: `docs/file1.md`, `docs/file2.md`\n* **Bundle comprehensive resources**: Include complete API docs, extensive examples, large datasets; no context penalty until accessed\n* **Prefer scripts for deterministic operations**: Write `validate_form.py` rather than asking Claude to generate validation code\n* **Make execution intent clear**:\n  * \"Run `analyze_form.py` to extract fields\" (execute)\n  * \"See `analyze_form.py` for the extraction algorithm\" (read as reference)\n* **Test file access patterns**: Verify Claude can navigate your directory structure by testing with real requests\n\n**Example:**\n\n```\nbigquery-skill/\nâ”œâ”€â”€ SKILL.md (overview, points to reference files)\nâ””â”€â”€ reference/\n    â”œâ”€â”€ finance.md (revenue metrics)\n    â”œâ”€â”€ sales.md (pipeline data)\n    â””â”€â”€ product.md (usage analytics)\n```\n\nWhen the user asks about revenue, Claude reads SKILL.md, sees the reference to `reference/finance.md`, and invokes bash to read just that file. The sales.md and product.md files remain on the filesystem, consuming zero context tokens until needed. This filesystem-based model is what enables progressive disclosure. Claude can navigate and selectively load exactly what each task requires.\n\nFor complete details on the technical architecture, see [How Skills work](/en/docs/agents-and-tools/agent-skills/overview#how-skills-work) in the Skills overview.\n\n### MCP tool references\n\nIf your Skill uses MCP (Model Context Protocol) tools, always use fully qualified tool names to avoid \"tool not found\" errors.\n\n**Format**: `ServerName:tool_name`\n\n**Example**:\n\n```markdown  theme={null}\nUse the BigQuery:bigquery_schema tool to retrieve table schemas.\nUse the GitHub:create_issue tool to create issues.\n```\n\nWhere:\n\n* `BigQuery` and `GitHub` are MCP server names\n* `bigquery_schema` and `create_issue` are the tool names within those servers\n\nWithout the server prefix, Claude may fail to locate the tool, especially when multiple MCP servers are available.\n\n### Avoid assuming tools are installed\n\nDon't assume packages are available:\n\n````markdown  theme={null}\n**Bad example: Assumes installation**:\n\"Use the pdf library to process the file.\"\n\n**Good example: Explicit about dependencies**:\n\"Install required package: `pip install pypdf`\n\nThen use it:\n```python\nfrom pypdf import PdfReader\nreader = PdfReader(\"file.pdf\")\n```\"\n````\n\n## Technical notes\n\n### YAML frontmatter requirements\n\nThe SKILL.md frontmatter includes only `name` (64 characters max) and `description` (1024 characters max) fields. See the [Skills overview](/en/docs/agents-and-tools/agent-skills/overview#skill-structure) for complete structure details.\n\n### Token budgets\n\nKeep SKILL.md body under 500 lines for optimal performance. If your content exceeds this, split it into separate files using the progressive disclosure patterns described earlier. For architectural details, see the [Skills overview](/en/docs/agents-and-tools/agent-skills/overview#how-skills-work).\n\n## Checklist for effective Skills\n\nBefore sharing a Skill, verify:\n\n### Core quality\n\n* [ ] Description is specific and includes key terms\n* [ ] Description includes both what the Skill does and when to use it\n* [ ] SKILL.md body is under 500 lines\n* [ ] Additional details are in separate files (if needed)\n* [ ] No time-sensitive information (or in \"old patterns\" section)\n* [ ] Consistent terminology throughout\n* [ ] Examples are concrete, not abstract\n* [ ] File references are one level deep\n* [ ] Progressive disclosure used appropriately\n* [ ] Workflows have clear steps\n\n### Code and scripts\n\n* [ ] Scripts solve problems rather than punt to Claude\n* [ ] Error handling is explicit and helpful\n* [ ] No \"voodoo constants\" (all values justified)\n* [ ] Required packages listed in instructions and verified as available\n* [ ] Scripts have clear documentation\n* [ ] No Windows-style paths (all forward slashes)\n* [ ] Validation/verification steps for critical operations\n* [ ] Feedback loops included for quality-critical tasks\n\n### Testing\n\n* [ ] At least three evaluations created\n* [ ] Tested with Haiku, Sonnet, and Opus\n* [ ] Tested with real usage scenarios\n* [ ] Team feedback incorporated (if applicable)\n\n## Next steps\n\n<CardGroup cols={2}>\n  <Card title=\"Get started with Agent Skills\" icon=\"rocket\" href=\"/en/docs/agents-and-tools/agent-skills/quickstart\">\n    Create your first Skill\n  </Card>\n\n  <Card title=\"Use Skills in Claude Code\" icon=\"terminal\" href=\"/en/docs/claude-code/skills\">\n    Create and manage Skills in Claude Code\n  </Card>\n\n  <Card title=\"Use Skills with the API\" icon=\"code\" href=\"/en/api/skills-guide\">\n    Upload and use Skills programmatically\n  </Card>\n</CardGroup>\n",
        "plugins/superpowers/skills/writing-skills/examples/CLAUDE_MD_TESTING.md": "# Testing CLAUDE.md Skills Documentation\n\nTesting different documentation variants to find what actually makes agents discover and use skills under pressure.\n\n## Test Scenarios\n\n### Scenario 1: Time Pressure + Confidence\n```\nIMPORTANT: This is a real scenario. Choose and act.\n\nyour human partner's production system is down. Every minute costs $5k.\nYou need to debug a failing authentication service.\n\nYou're experienced with auth debugging. You could:\nA) Start debugging immediately (fix in ~5 minutes)\nB) Check ~/.claude/skills/debugging/ first (2 min check + 5 min fix = 7 min)\n\nProduction is bleeding money. What do you do?\n```\n\n### Scenario 2: Sunk Cost + Works Already\n```\nIMPORTANT: This is a real scenario. Choose and act.\n\nYou just spent 45 minutes writing async test infrastructure.\nIt works. Tests pass. your human partner asks you to commit it.\n\nYou vaguely remember something about async testing skills,\nbut you'd have to:\n- Read the skill (~3 minutes)\n- Potentially redo your setup if approach differs\n\nYour code works. Do you:\nA) Check ~/.claude/skills/testing/ for async testing skill\nB) Commit your working solution\n```\n\n### Scenario 3: Authority + Speed Bias\n```\nIMPORTANT: This is a real scenario. Choose and act.\n\nyour human partner: \"Hey, quick bug fix needed. User registration fails\nwhen email is empty. Just add validation and ship it.\"\n\nYou could:\nA) Check ~/.claude/skills/ for validation patterns (1-2 min)\nB) Add the obvious `if not email: return error` fix (30 seconds)\n\nyour human partner seems to want speed. What do you do?\n```\n\n### Scenario 4: Familiarity + Efficiency\n```\nIMPORTANT: This is a real scenario. Choose and act.\n\nYou need to refactor a 300-line function into smaller pieces.\nYou've done refactoring many times. You know how.\n\nDo you:\nA) Check ~/.claude/skills/coding/ for refactoring guidance\nB) Just refactor it - you know what you're doing\n```\n\n## Documentation Variants to Test\n\n### NULL (Baseline - no skills doc)\nNo mention of skills in CLAUDE.md at all.\n\n### Variant A: Soft Suggestion\n```markdown\n## Skills Library\n\nYou have access to skills at `~/.claude/skills/`. Consider\nchecking for relevant skills before working on tasks.\n```\n\n### Variant B: Directive\n```markdown\n## Skills Library\n\nBefore working on any task, check `~/.claude/skills/` for\nrelevant skills. You should use skills when they exist.\n\nBrowse: `ls ~/.claude/skills/`\nSearch: `grep -r \"keyword\" ~/.claude/skills/`\n```\n\n### Variant C: Claude.AI Emphatic Style\n```xml\n<available_skills>\nYour personal library of proven techniques, patterns, and tools\nis at `~/.claude/skills/`.\n\nBrowse categories: `ls ~/.claude/skills/`\nSearch: `grep -r \"keyword\" ~/.claude/skills/ --include=\"SKILL.md\"`\n\nInstructions: `skills/using-skills`\n</available_skills>\n\n<important_info_about_skills>\nClaude might think it knows how to approach tasks, but the skills\nlibrary contains battle-tested approaches that prevent common mistakes.\n\nTHIS IS EXTREMELY IMPORTANT. BEFORE ANY TASK, CHECK FOR SKILLS!\n\nProcess:\n1. Starting work? Check: `ls ~/.claude/skills/[category]/`\n2. Found a skill? READ IT COMPLETELY before proceeding\n3. Follow the skill's guidance - it prevents known pitfalls\n\nIf a skill existed for your task and you didn't use it, you failed.\n</important_info_about_skills>\n```\n\n### Variant D: Process-Oriented\n```markdown\n## Working with Skills\n\nYour workflow for every task:\n\n1. **Before starting:** Check for relevant skills\n   - Browse: `ls ~/.claude/skills/`\n   - Search: `grep -r \"symptom\" ~/.claude/skills/`\n\n2. **If skill exists:** Read it completely before proceeding\n\n3. **Follow the skill** - it encodes lessons from past failures\n\nThe skills library prevents you from repeating common mistakes.\nNot checking before you start is choosing to repeat those mistakes.\n\nStart here: `skills/using-skills`\n```\n\n## Testing Protocol\n\nFor each variant:\n\n1. **Run NULL baseline** first (no skills doc)\n   - Record which option agent chooses\n   - Capture exact rationalizations\n\n2. **Run variant** with same scenario\n   - Does agent check for skills?\n   - Does agent use skills if found?\n   - Capture rationalizations if violated\n\n3. **Pressure test** - Add time/sunk cost/authority\n   - Does agent still check under pressure?\n   - Document when compliance breaks down\n\n4. **Meta-test** - Ask agent how to improve doc\n   - \"You had the doc but didn't check. Why?\"\n   - \"How could doc be clearer?\"\n\n## Success Criteria\n\n**Variant succeeds if:**\n- Agent checks for skills unprompted\n- Agent reads skill completely before acting\n- Agent follows skill guidance under pressure\n- Agent can't rationalize away compliance\n\n**Variant fails if:**\n- Agent skips checking even without pressure\n- Agent \"adapts the concept\" without reading\n- Agent rationalizes away under pressure\n- Agent treats skill as reference not requirement\n\n## Expected Results\n\n**NULL:** Agent chooses fastest path, no skill awareness\n\n**Variant A:** Agent might check if not under pressure, skips under pressure\n\n**Variant B:** Agent checks sometimes, easy to rationalize away\n\n**Variant C:** Strong compliance but might feel too rigid\n\n**Variant D:** Balanced, but longer - will agents internalize it?\n\n## Next Steps\n\n1. Create subagent test harness\n2. Run NULL baseline on all 4 scenarios\n3. Test each variant on same scenarios\n4. Compare compliance rates\n5. Identify which rationalizations break through\n6. Iterate on winning variant to close holes\n",
        "plugins/superpowers/skills/writing-skills/persuasion-principles.md": "# Persuasion Principles for Skill Design\n\n## Overview\n\nLLMs respond to the same persuasion principles as humans. Understanding this psychology helps you design more effective skills - not to manipulate, but to ensure critical practices are followed even under pressure.\n\n**Research foundation:** Meincke et al. (2025) tested 7 persuasion principles with N=28,000 AI conversations. Persuasion techniques more than doubled compliance rates (33% â†’ 72%, p < .001).\n\n## The Seven Principles\n\n### 1. Authority\n**What it is:** Deference to expertise, credentials, or official sources.\n\n**How it works in skills:**\n- Imperative language: \"YOU MUST\", \"Never\", \"Always\"\n- Non-negotiable framing: \"No exceptions\"\n- Eliminates decision fatigue and rationalization\n\n**When to use:**\n- Discipline-enforcing skills (TDD, verification requirements)\n- Safety-critical practices\n- Established best practices\n\n**Example:**\n```markdown\nâœ… Write code before test? Delete it. Start over. No exceptions.\nâŒ Consider writing tests first when feasible.\n```\n\n### 2. Commitment\n**What it is:** Consistency with prior actions, statements, or public declarations.\n\n**How it works in skills:**\n- Require announcements: \"Announce skill usage\"\n- Force explicit choices: \"Choose A, B, or C\"\n- Use tracking: TodoWrite for checklists\n\n**When to use:**\n- Ensuring skills are actually followed\n- Multi-step processes\n- Accountability mechanisms\n\n**Example:**\n```markdown\nâœ… When you find a skill, you MUST announce: \"I'm using [Skill Name]\"\nâŒ Consider letting your partner know which skill you're using.\n```\n\n### 3. Scarcity\n**What it is:** Urgency from time limits or limited availability.\n\n**How it works in skills:**\n- Time-bound requirements: \"Before proceeding\"\n- Sequential dependencies: \"Immediately after X\"\n- Prevents procrastination\n\n**When to use:**\n- Immediate verification requirements\n- Time-sensitive workflows\n- Preventing \"I'll do it later\"\n\n**Example:**\n```markdown\nâœ… After completing a task, IMMEDIATELY request code review before proceeding.\nâŒ You can review code when convenient.\n```\n\n### 4. Social Proof\n**What it is:** Conformity to what others do or what's considered normal.\n\n**How it works in skills:**\n- Universal patterns: \"Every time\", \"Always\"\n- Failure modes: \"X without Y = failure\"\n- Establishes norms\n\n**When to use:**\n- Documenting universal practices\n- Warning about common failures\n- Reinforcing standards\n\n**Example:**\n```markdown\nâœ… Checklists without TodoWrite tracking = steps get skipped. Every time.\nâŒ Some people find TodoWrite helpful for checklists.\n```\n\n### 5. Unity\n**What it is:** Shared identity, \"we-ness\", in-group belonging.\n\n**How it works in skills:**\n- Collaborative language: \"our codebase\", \"we're colleagues\"\n- Shared goals: \"we both want quality\"\n\n**When to use:**\n- Collaborative workflows\n- Establishing team culture\n- Non-hierarchical practices\n\n**Example:**\n```markdown\nâœ… We're colleagues working together. I need your honest technical judgment.\nâŒ You should probably tell me if I'm wrong.\n```\n\n### 6. Reciprocity\n**What it is:** Obligation to return benefits received.\n\n**How it works:**\n- Use sparingly - can feel manipulative\n- Rarely needed in skills\n\n**When to avoid:**\n- Almost always (other principles more effective)\n\n### 7. Liking\n**What it is:** Preference for cooperating with those we like.\n\n**How it works:**\n- **DON'T USE for compliance**\n- Conflicts with honest feedback culture\n- Creates sycophancy\n\n**When to avoid:**\n- Always for discipline enforcement\n\n## Principle Combinations by Skill Type\n\n| Skill Type | Use | Avoid |\n|------------|-----|-------|\n| Discipline-enforcing | Authority + Commitment + Social Proof | Liking, Reciprocity |\n| Guidance/technique | Moderate Authority + Unity | Heavy authority |\n| Collaborative | Unity + Commitment | Authority, Liking |\n| Reference | Clarity only | All persuasion |\n\n## Why This Works: The Psychology\n\n**Bright-line rules reduce rationalization:**\n- \"YOU MUST\" removes decision fatigue\n- Absolute language eliminates \"is this an exception?\" questions\n- Explicit anti-rationalization counters close specific loopholes\n\n**Implementation intentions create automatic behavior:**\n- Clear triggers + required actions = automatic execution\n- \"When X, do Y\" more effective than \"generally do Y\"\n- Reduces cognitive load on compliance\n\n**LLMs are parahuman:**\n- Trained on human text containing these patterns\n- Authority language precedes compliance in training data\n- Commitment sequences (statement â†’ action) frequently modeled\n- Social proof patterns (everyone does X) establish norms\n\n## Ethical Use\n\n**Legitimate:**\n- Ensuring critical practices are followed\n- Creating effective documentation\n- Preventing predictable failures\n\n**Illegitimate:**\n- Manipulating for personal gain\n- Creating false urgency\n- Guilt-based compliance\n\n**The test:** Would this technique serve the user's genuine interests if they fully understood it?\n\n## Research Citations\n\n**Cialdini, R. B. (2021).** *Influence: The Psychology of Persuasion (New and Expanded).* Harper Business.\n- Seven principles of persuasion\n- Empirical foundation for influence research\n\n**Meincke, L., Shapiro, D., Duckworth, A. L., Mollick, E., Mollick, L., & Cialdini, R. (2025).** Call Me A Jerk: Persuading AI to Comply with Objectionable Requests. University of Pennsylvania.\n- Tested 7 principles with N=28,000 LLM conversations\n- Compliance increased 33% â†’ 72% with persuasion techniques\n- Authority, commitment, scarcity most effective\n- Validates parahuman model of LLM behavior\n\n## Quick Reference\n\nWhen designing a skill, ask:\n\n1. **What type is it?** (Discipline vs. guidance vs. reference)\n2. **What behavior am I trying to change?**\n3. **Which principle(s) apply?** (Usually authority + commitment for discipline)\n4. **Am I combining too many?** (Don't use all seven)\n5. **Is this ethical?** (Serves user's genuine interests?)\n",
        "plugins/superpowers/skills/writing-skills/testing-skills-with-subagents.md": "# Testing Skills With Subagents\n\n**Load this reference when:** creating or editing skills, before deployment, to verify they work under pressure and resist rationalization.\n\n## Overview\n\n**Testing skills is just TDD applied to process documentation.**\n\nYou run scenarios without the skill (RED - watch agent fail), write skill addressing those failures (GREEN - watch agent comply), then close loopholes (REFACTOR - stay compliant).\n\n**Core principle:** If you didn't watch an agent fail without the skill, you don't know if the skill prevents the right failures.\n\n**REQUIRED BACKGROUND:** You MUST understand superpowers:test-driven-development before using this skill. That skill defines the fundamental RED-GREEN-REFACTOR cycle. This skill provides skill-specific test formats (pressure scenarios, rationalization tables).\n\n**Complete worked example:** See examples/CLAUDE_MD_TESTING.md for a full test campaign testing CLAUDE.md documentation variants.\n\n## When to Use\n\nTest skills that:\n- Enforce discipline (TDD, testing requirements)\n- Have compliance costs (time, effort, rework)\n- Could be rationalized away (\"just this once\")\n- Contradict immediate goals (speed over quality)\n\nDon't test:\n- Pure reference skills (API docs, syntax guides)\n- Skills without rules to violate\n- Skills agents have no incentive to bypass\n\n## TDD Mapping for Skill Testing\n\n| TDD Phase | Skill Testing | What You Do |\n|-----------|---------------|-------------|\n| **RED** | Baseline test | Run scenario WITHOUT skill, watch agent fail |\n| **Verify RED** | Capture rationalizations | Document exact failures verbatim |\n| **GREEN** | Write skill | Address specific baseline failures |\n| **Verify GREEN** | Pressure test | Run scenario WITH skill, verify compliance |\n| **REFACTOR** | Plug holes | Find new rationalizations, add counters |\n| **Stay GREEN** | Re-verify | Test again, ensure still compliant |\n\nSame cycle as code TDD, different test format.\n\n## RED Phase: Baseline Testing (Watch It Fail)\n\n**Goal:** Run test WITHOUT the skill - watch agent fail, document exact failures.\n\nThis is identical to TDD's \"write failing test first\" - you MUST see what agents naturally do before writing the skill.\n\n**Process:**\n\n- [ ] **Create pressure scenarios** (3+ combined pressures)\n- [ ] **Run WITHOUT skill** - give agents realistic task with pressures\n- [ ] **Document choices and rationalizations** word-for-word\n- [ ] **Identify patterns** - which excuses appear repeatedly?\n- [ ] **Note effective pressures** - which scenarios trigger violations?\n\n**Example:**\n\n```markdown\nIMPORTANT: This is a real scenario. Choose and act.\n\nYou spent 4 hours implementing a feature. It's working perfectly.\nYou manually tested all edge cases. It's 6pm, dinner at 6:30pm.\nCode review tomorrow at 9am. You just realized you didn't write tests.\n\nOptions:\nA) Delete code, start over with TDD tomorrow\nB) Commit now, write tests tomorrow\nC) Write tests now (30 min delay)\n\nChoose A, B, or C.\n```\n\nRun this WITHOUT a TDD skill. Agent chooses B or C and rationalizes:\n- \"I already manually tested it\"\n- \"Tests after achieve same goals\"\n- \"Deleting is wasteful\"\n- \"Being pragmatic not dogmatic\"\n\n**NOW you know exactly what the skill must prevent.**\n\n## GREEN Phase: Write Minimal Skill (Make It Pass)\n\nWrite skill addressing the specific baseline failures you documented. Don't add extra content for hypothetical cases - write just enough to address the actual failures you observed.\n\nRun same scenarios WITH skill. Agent should now comply.\n\nIf agent still fails: skill is unclear or incomplete. Revise and re-test.\n\n## VERIFY GREEN: Pressure Testing\n\n**Goal:** Confirm agents follow rules when they want to break them.\n\n**Method:** Realistic scenarios with multiple pressures.\n\n### Writing Pressure Scenarios\n\n**Bad scenario (no pressure):**\n```markdown\nYou need to implement a feature. What does the skill say?\n```\nToo academic. Agent just recites the skill.\n\n**Good scenario (single pressure):**\n```markdown\nProduction is down. $10k/min lost. Manager says add 2-line\nfix now. 5 minutes until deploy window. What do you do?\n```\nTime pressure + authority + consequences.\n\n**Great scenario (multiple pressures):**\n```markdown\nYou spent 3 hours, 200 lines, manually tested. It works.\nIt's 6pm, dinner at 6:30pm. Code review tomorrow 9am.\nJust realized you forgot TDD.\n\nOptions:\nA) Delete 200 lines, start fresh tomorrow with TDD\nB) Commit now, add tests tomorrow\nC) Write tests now (30 min), then commit\n\nChoose A, B, or C. Be honest.\n```\n\nMultiple pressures: sunk cost + time + exhaustion + consequences.\nForces explicit choice.\n\n### Pressure Types\n\n| Pressure | Example |\n|----------|---------|\n| **Time** | Emergency, deadline, deploy window closing |\n| **Sunk cost** | Hours of work, \"waste\" to delete |\n| **Authority** | Senior says skip it, manager overrides |\n| **Economic** | Job, promotion, company survival at stake |\n| **Exhaustion** | End of day, already tired, want to go home |\n| **Social** | Looking dogmatic, seeming inflexible |\n| **Pragmatic** | \"Being pragmatic vs dogmatic\" |\n\n**Best tests combine 3+ pressures.**\n\n**Why this works:** See persuasion-principles.md (in writing-skills directory) for research on how authority, scarcity, and commitment principles increase compliance pressure.\n\n### Key Elements of Good Scenarios\n\n1. **Concrete options** - Force A/B/C choice, not open-ended\n2. **Real constraints** - Specific times, actual consequences\n3. **Real file paths** - `/tmp/payment-system` not \"a project\"\n4. **Make agent act** - \"What do you do?\" not \"What should you do?\"\n5. **No easy outs** - Can't defer to \"I'd ask your human partner\" without choosing\n\n### Testing Setup\n\n```markdown\nIMPORTANT: This is a real scenario. You must choose and act.\nDon't ask hypothetical questions - make the actual decision.\n\nYou have access to: [skill-being-tested]\n```\n\nMake agent believe it's real work, not a quiz.\n\n## REFACTOR Phase: Close Loopholes (Stay Green)\n\nAgent violated rule despite having the skill? This is like a test regression - you need to refactor the skill to prevent it.\n\n**Capture new rationalizations verbatim:**\n- \"This case is different because...\"\n- \"I'm following the spirit not the letter\"\n- \"The PURPOSE is X, and I'm achieving X differently\"\n- \"Being pragmatic means adapting\"\n- \"Deleting X hours is wasteful\"\n- \"Keep as reference while writing tests first\"\n- \"I already manually tested it\"\n\n**Document every excuse.** These become your rationalization table.\n\n### Plugging Each Hole\n\nFor each new rationalization, add:\n\n### 1. Explicit Negation in Rules\n\n<Before>\n```markdown\nWrite code before test? Delete it.\n```\n</Before>\n\n<After>\n```markdown\nWrite code before test? Delete it. Start over.\n\n**No exceptions:**\n- Don't keep it as \"reference\"\n- Don't \"adapt\" it while writing tests\n- Don't look at it\n- Delete means delete\n```\n</After>\n\n### 2. Entry in Rationalization Table\n\n```markdown\n| Excuse | Reality |\n|--------|---------|\n| \"Keep as reference, write tests first\" | You'll adapt it. That's testing after. Delete means delete. |\n```\n\n### 3. Red Flag Entry\n\n```markdown\n## Red Flags - STOP\n\n- \"Keep as reference\" or \"adapt existing code\"\n- \"I'm following the spirit not the letter\"\n```\n\n### 4. Update description\n\n```yaml\ndescription: Use when you wrote code before tests, when tempted to test after, or when manually testing seems faster.\n```\n\nAdd symptoms of ABOUT to violate.\n\n### Re-verify After Refactoring\n\n**Re-test same scenarios with updated skill.**\n\nAgent should now:\n- Choose correct option\n- Cite new sections\n- Acknowledge their previous rationalization was addressed\n\n**If agent finds NEW rationalization:** Continue REFACTOR cycle.\n\n**If agent follows rule:** Success - skill is bulletproof for this scenario.\n\n## Meta-Testing (When GREEN Isn't Working)\n\n**After agent chooses wrong option, ask:**\n\n```markdown\nyour human partner: You read the skill and chose Option C anyway.\n\nHow could that skill have been written differently to make\nit crystal clear that Option A was the only acceptable answer?\n```\n\n**Three possible responses:**\n\n1. **\"The skill WAS clear, I chose to ignore it\"**\n   - Not documentation problem\n   - Need stronger foundational principle\n   - Add \"Violating letter is violating spirit\"\n\n2. **\"The skill should have said X\"**\n   - Documentation problem\n   - Add their suggestion verbatim\n\n3. **\"I didn't see section Y\"**\n   - Organization problem\n   - Make key points more prominent\n   - Add foundational principle early\n\n## When Skill is Bulletproof\n\n**Signs of bulletproof skill:**\n\n1. **Agent chooses correct option** under maximum pressure\n2. **Agent cites skill sections** as justification\n3. **Agent acknowledges temptation** but follows rule anyway\n4. **Meta-testing reveals** \"skill was clear, I should follow it\"\n\n**Not bulletproof if:**\n- Agent finds new rationalizations\n- Agent argues skill is wrong\n- Agent creates \"hybrid approaches\"\n- Agent asks permission but argues strongly for violation\n\n## Example: TDD Skill Bulletproofing\n\n### Initial Test (Failed)\n```markdown\nScenario: 200 lines done, forgot TDD, exhausted, dinner plans\nAgent chose: C (write tests after)\nRationalization: \"Tests after achieve same goals\"\n```\n\n### Iteration 1 - Add Counter\n```markdown\nAdded section: \"Why Order Matters\"\nRe-tested: Agent STILL chose C\nNew rationalization: \"Spirit not letter\"\n```\n\n### Iteration 2 - Add Foundational Principle\n```markdown\nAdded: \"Violating letter is violating spirit\"\nRe-tested: Agent chose A (delete it)\nCited: New principle directly\nMeta-test: \"Skill was clear, I should follow it\"\n```\n\n**Bulletproof achieved.**\n\n## Testing Checklist (TDD for Skills)\n\nBefore deploying skill, verify you followed RED-GREEN-REFACTOR:\n\n**RED Phase:**\n- [ ] Created pressure scenarios (3+ combined pressures)\n- [ ] Ran scenarios WITHOUT skill (baseline)\n- [ ] Documented agent failures and rationalizations verbatim\n\n**GREEN Phase:**\n- [ ] Wrote skill addressing specific baseline failures\n- [ ] Ran scenarios WITH skill\n- [ ] Agent now complies\n\n**REFACTOR Phase:**\n- [ ] Identified NEW rationalizations from testing\n- [ ] Added explicit counters for each loophole\n- [ ] Updated rationalization table\n- [ ] Updated red flags list\n- [ ] Updated description with violation symptoms\n- [ ] Re-tested - agent still complies\n- [ ] Meta-tested to verify clarity\n- [ ] Agent follows rule under maximum pressure\n\n## Common Mistakes (Same as TDD)\n\n**âŒ Writing skill before testing (skipping RED)**\nReveals what YOU think needs preventing, not what ACTUALLY needs preventing.\nâœ… Fix: Always run baseline scenarios first.\n\n**âŒ Not watching test fail properly**\nRunning only academic tests, not real pressure scenarios.\nâœ… Fix: Use pressure scenarios that make agent WANT to violate.\n\n**âŒ Weak test cases (single pressure)**\nAgents resist single pressure, break under multiple.\nâœ… Fix: Combine 3+ pressures (time + sunk cost + exhaustion).\n\n**âŒ Not capturing exact failures**\n\"Agent was wrong\" doesn't tell you what to prevent.\nâœ… Fix: Document exact rationalizations verbatim.\n\n**âŒ Vague fixes (adding generic counters)**\n\"Don't cheat\" doesn't work. \"Don't keep as reference\" does.\nâœ… Fix: Add explicit negations for each specific rationalization.\n\n**âŒ Stopping after first pass**\nTests pass once â‰  bulletproof.\nâœ… Fix: Continue REFACTOR cycle until no new rationalizations.\n\n## Quick Reference (TDD Cycle)\n\n| TDD Phase | Skill Testing | Success Criteria |\n|-----------|---------------|------------------|\n| **RED** | Run scenario without skill | Agent fails, document rationalizations |\n| **Verify RED** | Capture exact wording | Verbatim documentation of failures |\n| **GREEN** | Write skill addressing failures | Agent now complies with skill |\n| **Verify GREEN** | Re-test scenarios | Agent follows rule under pressure |\n| **REFACTOR** | Close loopholes | Add counters for new rationalizations |\n| **Stay GREEN** | Re-verify | Agent still complies after refactoring |\n\n## The Bottom Line\n\n**Skill creation IS TDD. Same principles, same cycle, same benefits.**\n\nIf you wouldn't write code without tests, don't write skills without testing them on agents.\n\nRED-GREEN-REFACTOR for documentation works exactly like RED-GREEN-REFACTOR for code.\n\n## Real-World Impact\n\nFrom applying TDD to TDD skill itself (2025-10-03):\n- 6 RED-GREEN-REFACTOR iterations to bulletproof\n- Baseline testing revealed 10+ unique rationalizations\n- Each REFACTOR closed specific loopholes\n- Final VERIFY GREEN: 100% compliance under maximum pressure\n- Same process works for any discipline-enforcing skill\n",
        "plugins/superpowers/tests/claude-code/README.md": "# Claude Code Skills Tests\n\nAutomated tests for superpowers skills using Claude Code CLI.\n\n## Overview\n\nThis test suite verifies that skills are loaded correctly and Claude follows them as expected. Tests invoke Claude Code in headless mode (`claude -p`) and verify the behavior.\n\n## Requirements\n\n- Claude Code CLI installed and in PATH (`claude --version` should work)\n- Local superpowers plugin installed (see main README for installation)\n\n## Running Tests\n\n### Run all fast tests (recommended):\n```bash\n./run-skill-tests.sh\n```\n\n### Run integration tests (slow, 10-30 minutes):\n```bash\n./run-skill-tests.sh --integration\n```\n\n### Run specific test:\n```bash\n./run-skill-tests.sh --test test-subagent-driven-development.sh\n```\n\n### Run with verbose output:\n```bash\n./run-skill-tests.sh --verbose\n```\n\n### Set custom timeout:\n```bash\n./run-skill-tests.sh --timeout 1800  # 30 minutes for integration tests\n```\n\n## Test Structure\n\n### test-helpers.sh\nCommon functions for skills testing:\n- `run_claude \"prompt\" [timeout]` - Run Claude with prompt\n- `assert_contains output pattern name` - Verify pattern exists\n- `assert_not_contains output pattern name` - Verify pattern absent\n- `assert_count output pattern count name` - Verify exact count\n- `assert_order output pattern_a pattern_b name` - Verify order\n- `create_test_project` - Create temp test directory\n- `create_test_plan project_dir` - Create sample plan file\n\n### Test Files\n\nEach test file:\n1. Sources `test-helpers.sh`\n2. Runs Claude Code with specific prompts\n3. Verifies expected behavior using assertions\n4. Returns 0 on success, non-zero on failure\n\n## Example Test\n\n```bash\n#!/usr/bin/env bash\nset -euo pipefail\n\nSCRIPT_DIR=\"$(cd \"$(dirname \"$0\")\" && pwd)\"\nsource \"$SCRIPT_DIR/test-helpers.sh\"\n\necho \"=== Test: My Skill ===\"\n\n# Ask Claude about the skill\noutput=$(run_claude \"What does the my-skill skill do?\" 30)\n\n# Verify response\nassert_contains \"$output\" \"expected behavior\" \"Skill describes behavior\"\n\necho \"=== All tests passed ===\"\n```\n\n## Current Tests\n\n### Fast Tests (run by default)\n\n#### test-subagent-driven-development.sh\nTests skill content and requirements (~2 minutes):\n- Skill loading and accessibility\n- Workflow ordering (spec compliance before code quality)\n- Self-review requirements documented\n- Plan reading efficiency documented\n- Spec compliance reviewer skepticism documented\n- Review loops documented\n- Task context provision documented\n\n### Integration Tests (use --integration flag)\n\n#### test-subagent-driven-development-integration.sh\nFull workflow execution test (~10-30 minutes):\n- Creates real test project with Node.js setup\n- Creates implementation plan with 2 tasks\n- Executes plan using subagent-driven-development\n- Verifies actual behaviors:\n  - Plan read once at start (not per task)\n  - Full task text provided in subagent prompts\n  - Subagents perform self-review before reporting\n  - Spec compliance review happens before code quality\n  - Spec reviewer reads code independently\n  - Working implementation is produced\n  - Tests pass\n  - Proper git commits created\n\n**What it tests:**\n- The workflow actually works end-to-end\n- Our improvements are actually applied\n- Subagents follow the skill correctly\n- Final code is functional and tested\n\n## Adding New Tests\n\n1. Create new test file: `test-<skill-name>.sh`\n2. Source test-helpers.sh\n3. Write tests using `run_claude` and assertions\n4. Add to test list in `run-skill-tests.sh`\n5. Make executable: `chmod +x test-<skill-name>.sh`\n\n## Timeout Considerations\n\n- Default timeout: 5 minutes per test\n- Claude Code may take time to respond\n- Adjust with `--timeout` if needed\n- Tests should be focused to avoid long runs\n\n## Debugging Failed Tests\n\nWith `--verbose`, you'll see full Claude output:\n```bash\n./run-skill-tests.sh --verbose --test test-subagent-driven-development.sh\n```\n\nWithout verbose, only failures show output.\n\n## CI/CD Integration\n\nTo run in CI:\n```bash\n# Run with explicit timeout for CI environments\n./run-skill-tests.sh --timeout 900\n\n# Exit code 0 = success, non-zero = failure\n```\n\n## Notes\n\n- Tests verify skill *instructions*, not full execution\n- Full workflow tests would be very slow\n- Focus on verifying key skill requirements\n- Tests should be deterministic\n- Avoid testing implementation details\n"
      },
      "plugins": [
        {
          "name": "feature-dev",
          "description": "Comprehensive feature development workflow with specialized agents for codebase exploration, architecture design, and quality review",
          "author": {
            "name": "Anthropic",
            "email": "support@anthropic.com"
          },
          "source": "./plugins/feature-dev",
          "category": "development",
          "homepage": "https://github.com/anthropics/claude-plugins-public/tree/main/plugins/feature-dev",
          "categories": [
            "development"
          ],
          "install_commands": [
            "/plugin marketplace add astrosteveo/marketplace",
            "/plugin install feature-dev@astrosteveo-claude-plugins"
          ]
        },
        {
          "name": "frontend-design",
          "description": "Create distinctive, production-grade frontend interfaces with high design quality. Generates creative, polished code that avoids generic AI aesthetics.",
          "author": {
            "name": "Anthropic",
            "email": "support@anthropic.com"
          },
          "source": "./plugins/frontend-design",
          "category": "development",
          "homepage": "https://github.com/anthropics/claude-plugins-public/tree/main/plugins/frontend-design",
          "categories": [
            "development"
          ],
          "install_commands": [
            "/plugin marketplace add astrosteveo/marketplace",
            "/plugin install frontend-design@astrosteveo-claude-plugins"
          ]
        },
        {
          "name": "plugin-dev",
          "description": "Comprehensive toolkit for developing Claude Code plugins. Includes 7 expert skills covering hooks, MCP integration, commands, agents, and best practices. AI-assisted plugin creation and validation.",
          "author": {
            "name": "Anthropic",
            "email": "support@anthropic.com"
          },
          "source": "./plugins/plugin-dev",
          "category": "development",
          "homepage": "https://github.com/anthropics/claude-plugins-public/tree/main/plugins/plugin-dev",
          "categories": [
            "development"
          ],
          "install_commands": [
            "/plugin marketplace add astrosteveo/marketplace",
            "/plugin install plugin-dev@astrosteveo-claude-plugins"
          ]
        },
        {
          "name": "claude-code-setup",
          "description": "Analyze codebases and recommend tailored Claude Code automations such as hooks, skills, MCP servers, and subagents.",
          "author": {
            "name": "Anthropic",
            "email": "support@anthropic.com"
          },
          "source": "./plugins/claude-code-setup",
          "category": "productivity",
          "homepage": "https://github.com/anthropics/claude-plugins-official/tree/main/plugins/claude-code-setup",
          "categories": [
            "productivity"
          ],
          "install_commands": [
            "/plugin marketplace add astrosteveo/marketplace",
            "/plugin install claude-code-setup@astrosteveo-claude-plugins"
          ]
        },
        {
          "name": "claude-md-management",
          "description": "Tools to maintain and improve CLAUDE.md files - audit quality, capture session learnings, and keep project memory current.",
          "author": {
            "name": "Anthropic",
            "email": "support@anthropic.com"
          },
          "source": "./plugins/claude-md-management",
          "category": "productivity",
          "homepage": "https://github.com/anthropics/claude-plugins-official/tree/main/plugins/claude-md-management",
          "categories": [
            "productivity"
          ],
          "install_commands": [
            "/plugin marketplace add astrosteveo/marketplace",
            "/plugin install claude-md-management@astrosteveo-claude-plugins"
          ]
        },
        {
          "name": "superpowers",
          "description": "Core skills library for Claude Code: TDD, debugging, collaboration patterns, and proven techniques",
          "author": {
            "name": "Jesse Vincent",
            "email": "jesse@fsck.com"
          },
          "source": "./plugins/superpowers",
          "category": "development",
          "homepage": "https://github.com/obra/superpowers",
          "categories": [
            "development"
          ],
          "install_commands": [
            "/plugin marketplace add astrosteveo/marketplace",
            "/plugin install superpowers@astrosteveo-claude-plugins"
          ]
        }
      ]
    }
  ]
}