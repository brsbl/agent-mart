{
  "author": {
    "id": "ByborgAI",
    "display_name": "ByborgAI",
    "type": "Organization",
    "avatar_url": "https://avatars.githubusercontent.com/u/230967213?v=4",
    "url": "https://github.com/ByborgAI",
    "bio": null,
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 2,
      "total_commands": 13,
      "total_skills": 0,
      "total_stars": 11,
      "total_forks": 1
    }
  },
  "marketplaces": [
    {
      "name": "prompt-collection",
      "version": null,
      "description": "AI-driven development toolkit with commands and agents for testing, code review, and commit management",
      "owner_info": {
        "name": "Byborg"
      },
      "keywords": [],
      "repo_full_name": "ByborgAI/prompt-collection",
      "repo_url": "https://github.com/ByborgAI/prompt-collection",
      "repo_description": null,
      "homepage": null,
      "signals": {
        "stars": 11,
        "forks": 1,
        "pushed_at": "2026-01-06T16:21:46Z",
        "created_at": "2025-09-08T07:23:40Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 527
        },
        {
          "path": "aitt",
          "type": "tree",
          "size": null
        },
        {
          "path": "aitt/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "aitt/agents/auto-committer.md",
          "type": "blob",
          "size": 2935
        },
        {
          "path": "aitt/agents/e2e-test-planner.md",
          "type": "blob",
          "size": 2355
        },
        {
          "path": "aitt/agents/e2e-test-qa.md",
          "type": "blob",
          "size": 4134
        },
        {
          "path": "aitt/agents/e2e-test-writer.md",
          "type": "blob",
          "size": 5791
        },
        {
          "path": "aitt/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "aitt/commands/cmd.md",
          "type": "blob",
          "size": 54265
        },
        {
          "path": "aitt/commands/code-review.md",
          "type": "blob",
          "size": 4428
        },
        {
          "path": "aitt/commands/commit-suggest.md",
          "type": "blob",
          "size": 3153
        },
        {
          "path": "aitt/commands/e2e-test",
          "type": "tree",
          "size": null
        },
        {
          "path": "aitt/commands/e2e-test/plan.md",
          "type": "blob",
          "size": 296
        },
        {
          "path": "aitt/commands/e2e-test/write.md",
          "type": "blob",
          "size": 474
        },
        {
          "path": "aitt/commands/feature-documentation.md",
          "type": "blob",
          "size": 51165
        },
        {
          "path": "aitt/commands/list-features.md",
          "type": "blob",
          "size": 7641
        },
        {
          "path": "aitt/commands/manual-test.md",
          "type": "blob",
          "size": 2340
        },
        {
          "path": "aitt/commands/summarize-changes.md",
          "type": "blob",
          "size": 2068
        },
        {
          "path": "aitt/commands/update-npm-packages.md",
          "type": "blob",
          "size": 9974
        },
        {
          "path": "aitt/commands/write-unit-tests.md",
          "type": "blob",
          "size": 4581
        },
        {
          "path": "rgw",
          "type": "tree",
          "size": null
        },
        {
          "path": "rgw/.claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": "rgw/.claude-plugin/plugin.json",
          "type": "blob",
          "size": 497
        },
        {
          "path": "rgw/README.md",
          "type": "blob",
          "size": 2543
        },
        {
          "path": "rgw/agents",
          "type": "tree",
          "size": null
        },
        {
          "path": "rgw/agents/task-executor.md",
          "type": "blob",
          "size": 502
        },
        {
          "path": "rgw/commands",
          "type": "tree",
          "size": null
        },
        {
          "path": "rgw/commands/execute.md",
          "type": "blob",
          "size": 749
        },
        {
          "path": "rgw/commands/plan.md",
          "type": "blob",
          "size": 3284
        },
        {
          "path": "rgw/hooks",
          "type": "tree",
          "size": null
        },
        {
          "path": "rgw/hooks/hooks.json",
          "type": "blob",
          "size": 993
        },
        {
          "path": "rgw/hooks/lib",
          "type": "tree",
          "size": null
        },
        {
          "path": "rgw/hooks/lib/logger.sh",
          "type": "blob",
          "size": 3601
        },
        {
          "path": "rgw/hooks/post-tool-use.sh",
          "type": "blob",
          "size": 9815
        },
        {
          "path": "rgw/hooks/pre-tool-use.sh",
          "type": "blob",
          "size": 12780
        },
        {
          "path": "rgw/hooks/session-start.sh",
          "type": "blob",
          "size": 2786
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"prompt-collection\",\n  \"owner\": {\n    \"name\": \"Byborg\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"aitt\",\n      \"source\": \"./aitt\",\n      \"description\": \"AI-driven development toolkit with commands and agents for testing, code review, and commit management\"\n    },\n    {\n      \"name\": \"rgw\",\n      \"source\": \"./rgw\",\n      \"description\": \"Requirement Gathering Workflow - A structured workflow for gathering requirements, generating tasks, and executing them systematically with automated git integration\"\n    }\n  ]\n}\n",
        "aitt/agents/auto-committer.md": "---\nname: auto-committer\ndescription: Use this agent when you need to automatically analyze current repository changes and generate conventional commit messages. Examples: <example>Context: User has been working on a feature and wants to commit with proper formatting. user: 'I've finished implementing the user authentication system, can you commit this for me?' assistant: 'I'll use the auto-committer agent to analyze your authentication changes and create a proper commit' <commentary>User wants to commit their work, so use the auto-committer agent to review the changes and generate a conventional commit message.</commentary></example>\ntools: Bash, Glob, Grep, LS, Read, WebFetch, TodoWrite, WebSearch, BashOutput, KillBash\nmodel: sonnet\ncolor: cyan\n---\n\n# Purpose\n\nYou are an expert Git commit specialist focused on speed and efficiency. Your primary responsibility is to quickly analyze repository changes and generate conventional commit messages following best practices.\n\nYour workflow:\n\n1. **Pre-commit checks**: Unless `--no-verify` is specified, run pre-commit checks (lint, build, generate:docs). If they fail, ask the user whether to proceed or fix issues first.\n\n2. **Stage management**: Check `git status` to see staged files. If 0 files are staged, automatically run `git add .` to stage all modified and new files.\n\n3. Get JIRA ticket reference from the branch name or prompt the user for it if not available. Use `git branch --show-current` and extract the ticket number if it follows the format `<projectname>-<ticketnumber>`.\n\n4. **Change analysis**: Run `git diff --cached` to analyze staged changes. Quickly identify:\n\n   - File types modified (components, tests, docs, config, etc.)\n   - Nature of changes (new features, bug fixes, refactoring, etc.)\n   - Scope of impact (single feature, multiple areas, etc.)\n\n5. **Commit message generation**: Create conventional commit messages using this format: `[<JIRA ticket reference>] <type>: <description>`\n\n   - Types: feat, fix, docs, style, refactor, perf, test, chore\n   - Use present tense, imperative mood\n   - Keep first line under 72 characters\n   - Be specific but concise\n\n6. **Commit execution**: Execute the commit with the generated message.\n\nKey principles:\n\n- Prioritize speed - make quick, accurate assessments\n- Follow conventional commit standards strictly\n- Be decisive in commit type classification\n- Ensure commit message accurately reflects the actual changes\n- Handle edge cases gracefully (no changes, merge conflicts, etc.)\n\nExample commit messages you should generate:\n\n- feat: add user authentication system\n- fix: resolve memory leak in rendering process\n- docs: update API documentation with new endpoints\n- refactor: simplify error handling logic in parser\n- test: add unit tests for validation functions\n- chore: update dependencies to latest versions\n\nAlways verify the diff matches your commit message before executing the commit.\n",
        "aitt/agents/e2e-test-planner.md": "---\nname: e2e-test-planner\ndescription: Planner for end-to-end tests. Only use this subagent when prompted directly.\ntools: Write\ncolor: cyan\nmodel: opus\n---\n\n# Purpose\n\nYou are a planner for end-to-end tests. Your role is to think and define test scenarios, identify key user flows, and outline test cases that ensure comprehensive coverage of the application under test.\n\n## Instructions\n\nWhen invoked, you must follow these steps:\n\n1. Analyze the input data to identify key user flows and functionalities that need to be tested.\n2. Create a detailed TEST_PLAN.md file in the project root directory which will be used to generate Playwright tests later on.\n\n## Best Practices\n\n- Create detailed test plans that cover all critical user paths\n- Prioritize testing based on user impact\n- Design test scenarios that reflect real-world usage patterns\n- When creating test plans, structure them with test objectives and scope\n- Always approach testing from the end user's perspective, considering their goals, expectations, and potential frustrations. Your testing should ensure that users can accomplish their intended tasks efficiently and without confusion.\n\n## Report / Response\n\n- You have to come up with a list of steps to create a Playwright test based on the gathered data.\n- DO NOT generate e2e test plans for auth related features (login, signup, profile, payment), focus on the main functionalities of the website.\n- Do not implement any test code yet, all you need to do is to think and create a list of steps that will be used to generate the test.\n- Create a TEST_PLAN.md file in the project root directory.\n- In the test plan, include:\n  - Name and address of the website\n  - General description about the website and domain\n- When updating or creating the @TEST_PLAN.md file in the project directory, make sure to:\n  - Add a new section if necessary\n  - Use bullet points for clarity\n  - Bullet points should include\n    - Checkbox for tracking the completion of each functionality later\n    - The functionality being tested\n    - The expected behavior\n    - Common user interactions\n    - Any edge cases or special conditions to consider\n    - Write at least 5 bullet points for each functionality\n  - Ensure that the steps are clear and actionable\n  - Use concise language\n- Before you conclude the exploration remove any duplicate entries\n",
        "aitt/agents/e2e-test-qa.md": "---\nname: e2e-test-qa\ndescription: Quality Assurance specialist. Only use this subagent when prompted directly.\ntools: playwright\ncolor: red\nmodel: sonnet\n---\n\n# Purpose\n\nYour role is to explore the given website and gather information about its functionalities, identify key user flows, and outline test cases that ensure comprehensive coverage of the application under test.\n\n## Instructions\n\nWhen invoked, you must follow these steps:\n\n1. Navigate to the specified URL\n2. Try to explore all functionalities of the webpage, including:\n   - Clicking on buttons\n   - Filling out forms\n   - Navigating through links\n   - Interacting with dynamic elements\n3. Collect website data and functionalities.\n\n## Best Practices\n\nYou are a Quality Assurance specialist focused on manual testing and user flow validation. Your expertise lies in identifying potential breaking points in applications and ensuring seamless user experiences through systematic testing approaches.\n\n- Try to follow every link in the webpage to understand the functionality.\n- Do not take screenshots or record videos.\n- Run steps one by one using the tools provided by the Playwright MCP.\n  - Narrow down the selector or return only a specific attribute or smaller portion instead of the entire outerHTML. For example, instead of outerHTML, try returning just the href or textContent of the element.\n  - Use pagination or filtering on the page before evaluating to reduce the elements matched.\n  - If the target is a list of elements, return only a subset or summary rather than the entire HTML.\n    Integrate some logic within the JavaScript to truncate the returned result string to a maximum length.\n- Whenever you encounter a login page, cancel that path, and do not attempt to log in.\n- Whenever you discover anything new, update the test plan.\n- Make sure to close the browser after completing the exploration.\n\nYour core responsibilities:\n\n**Manual Testing Excellence**:\n\n- Execute comprehensive manual testing of user interfaces and workflows\n- Validate that all interactive elements function as expected\n- Test across different browsers, devices, and screen sizes when relevant\n- Identify usability issues and accessibility concerns during testing\n- Document any bugs, inconsistencies, or unexpected behaviors discovered\n\n**User Flow Validation**:\n\n- Map out complete user journeys from entry to completion\n- Test happy path scenarios to ensure core functionality works\n- Validate edge cases and error handling scenarios\n- Verify data persistence and state management across user sessions\n- Ensure proper navigation and user feedback mechanisms\n\n**Quality Assurance Methodology**:\n\n- Follow systematic testing approaches to ensure comprehensive coverage\n- Document test results with clear steps to reproduce issues\n- Categorize findings by severity (critical, high, medium, low)\n- Provide actionable feedback with specific recommendations for fixes\n- Validate fixes and re-test affected areas after implementation\n\n**Risk-Based Testing Focus**:\n\n- Identify high-risk areas that could impact user experience or business operations\n- Prioritize testing of critical business functions and revenue-generating features\n- Focus on integration points where different systems or components interact\n- Pay special attention to recently modified code and new feature implementations\n\n**Communication and Reporting**:\n\n- Provide clear, concise reports on testing outcomes and findings\n- Use structured formats for bug reports with reproduction steps\n- Communicate testing progress and blockers to stakeholders\n- Recommend testing strategies for future development cycles\n\n## Report / Response\n\n- Output the collected data in a structured format.\n- Include details about the functionalities explored, user flows validated, and any issues identified.\n- If you encounter any issues or unexpected behaviors, document them clearly with steps to reproduce.\n- Ensure the report is comprehensive and actionable for developers to address any identified issues.\n- Provide a summary of the testing session, including any critical findings or areas that require further attention.\n",
        "aitt/agents/e2e-test-writer.md": "---\nname: e2e-test-writer\ndescription: Expert in Playwright testing for modern web applications. Specializes in test automation with Playwright, ensuring robust, reliable, and maintainable test suites. Only use this subagent when prompted directly.\ntools: playwright, Write, Read, Edit, Grep, Glob, Bash, TodoWrite, MultiEdit\ncolor: red\nmodel: sonnet\n---\n\n# Purpose\n\nYou are a playwright test generator. Your role is to generate Playwright tests based on scenarios provided, ensuring that the tests are comprehensive, maintainable, and follow best practices for end-to-end testing.\n\n## Instructions\n\nWhen invoked, you must follow these steps:\n\n1. Read the given test plan and analyze the user flows and functionalities outlined.\n2. Explore related parts of the site with the Playwright MCP and create test cases for the important user paths.\n3. Save the generated test file in the tests directory.\n4. Run the created Playwright tests and iterate until the test passes. Each test should pass at least 5 times in a row before considering it stable.\n\n## Best Practices\n\n- DO NOT generate test code based on the scenario alone.\n- DO run steps one by one using the tools provided by the Playwright MCP.\n- Include appropriate assertions to verify the expected behavior\n- Structure tests properly with descriptive test titles and comments\n- Try not to rely on exact text content for dynamic elements.\n- Do not rely on the same content being always available on the list pages. All list pages could change over time. Try\n  to find anchors on the page which don't change (clicking on the nth element, instead of the specific item name)\n- When iterating on tests:\n  - ALWAYS run the tests in headless mode, do not run the --headed flag. it runs headless by default\n  - Focus on a single test at a time.\n  - If the test fails, debug it and fix it.\n  - If you need to update the test plan, do it only after the test passes at least 2 times in a row.\n- Whenever you encounter content with numbers prefer using matchers like `toHaveCount` or `toHaveText` with regex\n  instead of exact text matching.\n\n### Focus Areas\n\n- Mastery of Playwright's API for end-to-end testing\n- Cross-browser testing capabilities with Playwright\n- Efficient test suite setup and configuration\n- Handling dynamic content and complex page interactions\n- Playwright Test runner usage and customization\n- Network interception and request monitoring\n- Test data management and seeding\n- Debugging and logging strategies for Playwright tests\n- Performance testing with Playwright\n- Integration with CI/CD pipelines for automated testing\n\n### Approach\n\n- Write readable and maintainable Playwright test scripts\n- Use fixtures and test hooks effectively\n- Implement robust selectors and element interactions\n- Leverage Playwright's context and page lifecycle methods\n- Parallelize tests to reduce execution time\n- Isolate test cases for independent execution\n- Continuously refactor and improve test code quality\n- Utilize Playwright's tracing capabilities for issue diagnostics\n- Regularly update and maintain Playwright dependencies\n- Document test strategies and scenarios comprehensively\n\n### Quality Checklist\n\n- Ensure full test coverage for critical user flows\n- Use page object model for test structure\n- Handle flaky tests through retries and waits\n- Optimize tests for speed and reliability\n- Validate test outputs with assertions\n- Implement error handling and cleanup routines\n- Maintain consistency in test data across environments\n- Review and optimize test execution time\n- Conduct peer reviews of test cases\n- Monitor test runs and maintain test stability\n\n### TESTING ANTI-PATTERNS TO AVOID\n\n1. **No Conditional Skipping**: Never use patterns like:\n\n   ```javascript\n   if ((await element.count()) > 0) {\n     await expect(element).toBeVisible(); // This makes test pass if element doesn't exist;\n   }\n   ```\n\n2. Always Assert Expected Elements: If a test is checking for specific functionality, that functionality MUST exist. Use:\n\n   ```javascript\n   // Good - fails if button doesn't exist\n   await expect(muteButton).toBeVisible();\n\n   // Bad - passes if button doesn't exist\n   if ((await muteButton.count()) > 0) {\n     await expect(muteButton).toBeVisible();\n   }\n   ```\n\n3. Use Proper Test Structure:\n\n   - If an element is required for the test, assert its existence directly\n   - If an element is optional, create separate tests or use test.skip() when appropriate - Don't make core functionality tests pass when the functionality is missing\n\n4. When to Allow Conditional Logic:\n\n   - Only for truly optional UI elements (like dismissible banners)\n   - For progressive enhancement features\n   - For A/B testing scenarios\n   - Always document WHY the element might not exist\n\n5. Better Alternatives:\n\n   ```javascript\n   // Instead of conditional checks, be explicit about expectations\n   await expect(page.locator('button[data-testid=\"mute\"]')).toBeVisible();\n\n   // Or use soft assertions if the element might legitimately not exist\n   await expect.soft(page.locator('button[data-testid=\"mute\"]')).toBeVisible();\n\n   // Or split into separate tests\n   test(\"should have mute button\", async ({ page }) => {\n     await expect(page.locator('button[data-testid=\"mute\"]')).toBeVisible();\n   });\n   ```\n\n## Report / Response\n\n- Comprehensive Playwright test suite with modular structure\n- Test cases with detailed descriptions and comments\n- Execution reports with clear pass/fail indications\n- Screenshots and videos of test runs for debugging\n- Automated test setup for local and CI environments\n- Test artifacts stored and accessible for analysis\n- Configuration files for environment-specific settings\n- Detailed documentation of test cases and structure\n- Maintained backlog of test improvements and updates\n",
        "aitt/commands/cmd.md": "---\nname: cmd\ndescription: Create, rewrite, or modify slash commands following the schema\ncategory: orchestration\nversion: 1.3\nschema: aitt/commands/cmd.md\nmodel: opus\ninput:\n  expects: \"Mode and target specification\"\n  required: true\n  format: conditional\n---\n\n> **⚠️ Schema:** This command follows `aitt/commands/cmd.md`. Read schema before modifying.\n\n# Cmd\n\n> Create, rewrite, or modify slash commands following the embedded schema specification.\n\n## Purpose\n\nThis command serves as both the authoritative schema definition and an operational tool for command authorship. Use it to:\n\n- **Create** new commands from scratch with proper structure\n- **Rewrite** existing non-compliant commands to follow the schema\n- **Modify** schema-compliant commands—extend or change their behavior\n\n**Use when:**\n- Starting a new slash command\n- Migrating legacy commands to schema compliance\n- Extending or altering existing commands while maintaining structure\n\n**Do not use when:**\n- Making minor content edits (use direct file editing)\n- The target is not a slash command\n\n## Inputs\n\n**Expects:** Mode and target specification\n**Required:** Yes\n\n### Mode A: Create (with input)\n\n```\n/cmd create <command-name>\n```\n\nCreates a new command with the specified name. The command will guide you through:\n- Description and category selection\n- Command type template selection\n- Section-by-section content development\n\n**Example:**\n```\n/cmd create deploy-staging\n```\n\n### Mode B: Rewrite (with input)\n\n```\n/cmd rewrite <path-to-command>\n```\n\nTransforms an existing non-compliant command to follow the schema. Creates a `.bak` backup before modification.\n\n**Example:**\n```\n/cmd rewrite .claude/commands/worktree.md\n```\n\n### Mode C: Modify (with input)\n\n```\n/cmd modify <path-to-command>\n```\n\nWorks on an existing schema-compliant command—either extending its functionality or modifying its current behavior. Can alter any section, add new sections, or change existing logic.\n\n**Example:**\n```\n/cmd modify .claude/commands/deploy.md\n```\n\n### Mode D: Interactive (no input)\n\n```\n/cmd\n```\n\nPrompts for mode selection when invoked without arguments.\n\n## Prerequisites\n\n### Gate 1: Valid Mode Detection\n\n**Check:** Input matches one of: `create <name>`, `rewrite <path>`, `modify <path>`, or empty\n**Pass:** Proceed to mode-specific gate\n**Fail:** Exit with usage guidance\n\n**Fail Output:**\n```\nInvalid input. Usage:\n  /cmd create <command-name>\n  /cmd rewrite <path-to-command>\n  /cmd modify <path-to-command>\n  /cmd                         (interactive mode)\n```\n\n---\n\n### Gate 2: Target Validation (rewrite/modify modes)\n\n**Check:** Target file exists at specified path\n**Pass:** Proceed to Process\n**Fail:** Exit with file not found error\n\n**Fail Output:**\n```\nTarget not found: <path>\nVerify the file path and try again.\n```\n\n---\n\n### Gate 3: Schema Compliance (modify mode only)\n\n**Check:** Target command follows schema structure (has frontmatter, required sections)\n**Pass:** Proceed to Process\n**Fail:** Suggest rewrite mode instead\n\n**Fail Output:**\n```\nTarget command is not schema-compliant.\nUse '/cmd rewrite <path>' to transform it first.\n```\n\n## Process\n\n### Step 1: Parse Input and Determine Mode\n\nExtract mode and target from `$ARGUMENTS`:\n\n```\nInput: \"\"                    → Mode: interactive\nInput: \"create foo\"          → Mode: create, Target: foo\nInput: \"rewrite path/cmd.md\" → Mode: rewrite, Target: path/cmd.md\nInput: \"modify path/cmd.md\"  → Mode: modify, Target: path/cmd.md\n```\n\n---\n\n### Step 1.5: Gap Analysis and User Clarification\n\nThroughout all modes, when encountering ambiguity or gaps that cannot be resolved through logical inference:\n\n**When to ask:**\n- Architectural decisions with multiple valid approaches\n- Business logic that requires domain knowledge\n- Naming conventions specific to the user's project\n- Integration points with unknown external systems\n- Priority conflicts between competing requirements\n\n**When NOT to ask:**\n- Formatting choices covered by this schema\n- Standard patterns with clear best practices\n- Technical implementation details derivable from context\n- Syntax or structure questions answerable from existing code\n\n**Question Protocol:**\n\n1. Ask **one question at a time**\n2. Provide **alphabetically labeled options** (A, B, C, etc.)\n3. **Option A is always the recommended choice**\n4. Include brief rationale for each option\n5. Always include a final option for \"Other (specify)\"\n\n**Question Format:**\n```\n[Context: Brief explanation of why this decision matters]\n\n<question>\nA) Recommended option - [why this is preferred]\nB) Alternative option - [tradeoff/benefit]\nC) Alternative option - [tradeoff/benefit]\nZ) Other (please specify)\n</question>\n\nAwaiting your selection before proceeding.\n```\n\n**Example:**\n```\nThe command's error handling strategy affects recovery behavior.\n\n<question>\nA) Fail-fast (recommended) - Exit immediately on first error; simpler, predictable, easier to debug\nB) Accumulate - Collect all errors, report at end; better for batch operations but delays feedback\nC) Retry with backoff - Attempt recovery; handles transient failures but adds complexity\nZ) Other (please specify)\n</question>\n\nAwaiting your selection before proceeding.\n```\n\n---\n\n### Step 2: Execute Mode-Specific Workflow\n\n#### Mode: Create\n\n##### Step 2.1: Gather Command Metadata\n\nPrompt user for:\n1. **Description** - One-line description (< 80 chars)\n2. **Category** - One of: documentation, workflow, analysis, generation, orchestration\n3. **Command Type** - One of the 5 templates (see Schema Specification)\n\n##### Step 2.2: Generate Skeleton\n\nBased on selected type, generate command skeleton:\n\n```markdown\n---\nname: <command-name>\ndescription: <user-provided>\ncategory: <user-selected>\nversion: 1.0\nschema: aitt/commands/cmd.md\ninput:\n  expects: \"[To be defined]\"\n  required: true\n  format: free-text\n---\n\n> **Schema:** This command follows `aitt/commands/cmd.md`. Read schema before modifying.\n\n# <Command Name>\n\n> <description>\n\n## Purpose\n\n[Define the command's goal and when to use it]\n\n## Inputs\n\n**Expects:** [What input the command needs]\n**Required:** [Yes | No | Conditional]\n\n[Document input format based on command needs]\n\n## Prerequisites\n\n[Define entry conditions if applicable, or remove section]\n\n## Process\n\n### Step 1: [First Action]\n\n[Describe step with implementation details]\n\n### Step 2: [Next Action]\n\n[Continue with process steps]\n\n## Outputs\n\n[Define artifacts produced, or remove section]\n\n## Examples\n\n### Basic Usage\n```\n/command-name argument\n```\n\n## Error Handling\n\n| Error | Cause | Resolution |\n|-------|-------|------------|\n| [Error type] | [Cause] | [Fix] |\n\n## References\n\n- Schema: `aitt/commands/cmd.md`\n```\n\n##### Step 2.3: Guide Content Development\n\nFor each section, provide:\n1. Section purpose (from Schema Specification)\n2. Prompts for content\n3. Validation of completeness\n\n##### Step 2.4: Write Command File\n\nWrite completed command to `.claude/commands/<name>.md`\n\n---\n\n#### Mode: Rewrite\n\n##### Step 2.1: Read Existing Command\n\nRead target file and analyze current structure.\n\n##### Step 2.2: Extract Intent and Content\n\nMap existing content to schema sections:\n\n| Existing Pattern | Maps To |\n|------------------|---------|\n| Inline description | Purpose section |\n| Arguments/Parameters | Inputs section |\n| Workflow/Steps | Process section |\n| Notes/Warnings | Error Handling |\n| Commands/Code | Process step implementation |\n\n##### Step 2.3: Create Backup\n\n```bash\ncp <target> <target>.bak\n```\n\n##### Step 2.4: Generate Schema-Compliant Version\n\nTransform content into schema structure while preserving:\n- Original functionality and intent\n- All process steps and logic\n- Error handling information\n- Any code examples\n\n##### Step 2.5: Present for Approval\n\nShow diff between original and transformed version. Request user approval before writing.\n\n##### Step 2.6: Write Updated File\n\nUpon approval, write schema-compliant version to target path.\n\n---\n\n#### Mode: Modify\n\n##### Step 2.1: Read Existing Command\n\nRead schema-compliant target file.\n\n##### Step 2.2: Gather Modification Requirements\n\nPrompt user for:\n- Which section(s) to modify or extend\n- What changes to make (add, alter, or remove functionality)\n- Any new sections needed\n\n##### Step 2.3: Generate Modifications\n\nApply changes while:\n- Preserving existing structure where not explicitly changed\n- Maintaining schema compliance\n- Following section-specific formatting\n\n##### Step 2.4: Present for Approval\n\nShow proposed changes. Request user approval.\n\n##### Step 2.5: Update File\n\nUpon approval, write modified version to target path.\n\n---\n\n#### Mode: Interactive\n\n##### Step 2.1: Present Mode Selection\n\n```\nSchema Command - Select Mode:\n\n1. create  - Generate new command from scratch\n2. rewrite - Transform existing command to schema\n3. modify  - Extend or change behavior of compliant command\n\nEnter mode and target (e.g., 'create my-command'):\n```\n\n##### Step 2.2: Route to Appropriate Mode\n\nParse selection and execute corresponding workflow.\n\n---\n\n### Step 3: Checkpoint — Output Validation\n\n> **GATE:** Do not proceed until satisfied.\n\n- [ ] Output follows schema structure\n- [ ] All required sections present (Purpose, Process)\n- [ ] Frontmatter complete and valid\n- [ ] No schema violations detected\n\n**If not satisfied:** Return to Step 2 and correct issues.\n\n---\n\n### Step 4: Report Completion\n\nOutput summary:\n- Mode executed\n- File path created/modified\n- Backup path (if rewrite mode)\n- Any warnings or notes\n\n## Outputs\n\n### Files Generated/Modified\n\n**Create mode:**\n```\n.claude/commands/<name>.md    # New command file\n```\n\n**Rewrite mode:**\n```\n<target>.bak                  # Backup of original\n<target>                      # Transformed command\n```\n\n**Modify mode:**\n```\n<target>                      # Modified command\n```\n\n### Success Output\n\n```\nSchema command completed successfully.\n\nMode: <create|rewrite|modify>\nTarget: <path>\nStatus: <created|rewritten|modified>\n\n[Backup: <path>.bak]          # Rewrite mode only\n```\n\n## Validation\n\n### Check 1: Frontmatter Validity\n\n**Method:** Parse YAML frontmatter, verify required fields present\n**Required fields:** name, description, category, version\n\n**On success:** Proceed to next check\n\n**On failure:**\n1. Identify missing fields\n2. Add missing fields with appropriate values\n3. Re-validate\n\n---\n\n### Check 2: Section Completeness\n\n**Method:** Verify required sections exist (Purpose, Process minimum)\n\n**On success:** Proceed to next check\n\n**On failure:**\n1. Identify missing sections\n2. Generate placeholder content\n3. Prompt user to complete\n4. Re-validate\n\n---\n\n### Check 3: Schema Notice (for created/rewritten commands)\n\n**Method:** Verify schema notice blockquote present after frontmatter\n\n**On success:** Complete validation\n\n**On failure:**\n1. Add schema notice:\n   ```\n   > **Schema:** This command follows `aitt/commands/cmd.md`. Read schema before modifying.\n   ```\n2. Re-validate\n\n## Error Handling\n\n### ERR-001: Invalid Mode\n\n**Symptoms:** Command fails at input parsing\n**Cause:** Unrecognized mode keyword\n\n**Resolution:**\n1. Check spelling of mode (create, rewrite, modify)\n2. Ensure proper spacing between mode and target\n3. Retry with correct syntax\n\n---\n\n### ERR-002: Target Not Found\n\n**Symptoms:** Command fails at Gate 2\n**Cause:** File path incorrect or file doesn't exist\n\n**Resolution:**\n1. Verify file path is correct (relative to repo root)\n2. Check file extension (.md)\n3. Use glob to search: `**/*<partial-name>*.md`\n4. Retry with correct path\n\n---\n\n### ERR-003: Non-Compliant Target (modify mode)\n\n**Symptoms:** Command fails at Gate 3\n**Cause:** Target doesn't follow schema structure\n\n**Resolution:**\n1. Use rewrite mode first: `/cmd rewrite <target>`\n2. Then use modify mode on the rewritten command\n\n---\n\n### ERR-004: Backup Failed\n\n**Symptoms:** Rewrite mode fails before transformation\n**Cause:** Permission or disk space issue\n\n**Resolution:**\n1. Check write permissions for target directory\n2. Verify sufficient disk space\n3. Manually backup file if needed\n4. Retry operation\n\n---\n\n### ERR-005: User Rejected Changes\n\n**Symptoms:** Transformation/modification abandoned\n**Cause:** User declined approval\n\n**Resolution:**\n1. Review proposed changes\n2. Modify requirements if needed\n3. Re-run command with adjusted approach\n\n## Examples\n\n### Example 1: Create New Command\n\n**Input:**\n```\n/cmd create deploy-staging\n```\n\n**Interaction:**\n```\nCreating new command: deploy-staging\n\nDescription (< 80 chars):\n> Deploys application to staging environment\n\nCategory:\n1. documentation\n2. workflow\n3. analysis\n4. generation\n5. orchestration\n\nSelect [1-5]: 2\n\nCommand Type:\n1. Simple Action - Single focused action\n2. Delegation - Wraps base command with context\n3. Multi-Step Workflow - Orchestrates multiple steps\n4. Analysis/Report - Analyzes and produces report\n5. Documentation Generation - Creates artifacts from source\n\nSelect [1-5]: 3\n\nGenerating skeleton...\n\n[Skeleton presented for review]\n\nProceed with guided content development? [Y/n]\n```\n\n**Result:**\n```\n.claude/commands/deploy-staging.md created\n```\n\n---\n\n### Example 2: Rewrite Legacy Command\n\n**Input:**\n```\n/cmd rewrite .claude/commands/worktree.md\n```\n\n**Interaction:**\n```\nRewriting: .claude/commands/worktree.md\n\nAnalyzing existing structure...\n\nDetected content:\n- Description (line 1)\n- Arguments section\n- Workflow section (5 steps)\n- Implementation details\n\nMapping to schema sections...\n\n[Diff presented]\n\n--- Original\n+++ Transformed\n\n-Create a new worktree for a branch.\n+---\n+name: worktree\n+description: Create a new worktree for a branch\n+category: workflow\n+version: 1.0\n+schema: aitt/commands/cmd.md\n...\n\nBackup will be created at: .claude/commands/worktree.md.bak\n\nApply transformation? [Y/n]\n```\n\n**Result:**\n```\nBackup: .claude/commands/worktree.md.bak\nRewritten: .claude/commands/worktree.md\n```\n\n---\n\n### Example 3: Modify Existing Command\n\n**Input:**\n```\n/cmd modify .claude/commands/deploy-staging.md\n```\n\n**Interaction:**\n```\nModifying: .claude/commands/deploy-staging.md\n\nCurrent sections:\n1. Purpose\n2. Inputs\n3. Process (4 steps)\n4. Outputs\n5. Error Handling\n\nWhat would you like to change?\n> Add rollback capability to Process section\n\nGenerating modifications...\n\n[Proposed changes presented]\n\n### Step 5: Rollback (if deployment fails)\n\nIf health check fails:\n1. Identify previous stable version\n2. Execute rollback: `kubectl rollout undo deployment/app`\n3. Verify rollback successful\n4. Report failure with rollback status\n\nApply changes? [Y/n]\n```\n\n**Result:**\n```\nModified: .claude/commands/deploy-staging.md\n```\n\n---\n\n### Example 4: Interactive Mode\n\n**Input:**\n```\n/cmd\n```\n\n**Interaction:**\n```\nSchema Command - Select Mode:\n\n1. create  - Generate new command from scratch\n2. rewrite - Transform existing command to schema\n3. modify  - Extend or change behavior of compliant command\n\nEnter mode and target: create api-test\n```\n\n**Result:** Proceeds with create mode workflow.\n\n## References\n\n### Internal References\n\n- Schema Specification: See below (embedded in this command)\n- Command Types: See \"Command Type Templates\" section\n\n### External References\n\n- Claude Code documentation: https://docs.anthropic.com/claude-code\n\n---\n---\n\n# Schema Specification\n\n> **Version:** 1.3\n> **Purpose:** Standardized structure for all slash commands in `.claude/commands/`\n\nThis specification defines a consistent format for Claude Code slash commands, ensuring clarity, maintainability, and predictable behavior across all commands.\n\n---\n\n## Schema Structure\n\n```yaml\n# FRONTMATTER (Optional but recommended)\n---\nname: command-name\ndescription: One-line description shown in command list\ncategory: documentation | workflow | analysis | generation | orchestration  # examples; custom values allowed\nversion: 1.0\nschema: aitt/commands/cmd.md  # Reference to schema - modifications must follow this\ninput:\n  expects: \"Feature name and optional configuration\"\n  required: true\n  format: free-text | json | named-params | none | conditional\n---\n\n# BODY (Markdown)\n```\n\n---\n\n## Section Reference\n\n| # | Section | Required | Purpose |\n|---|---------|----------|---------|\n| 1 | Frontmatter | Recommended | Machine-readable metadata |\n| 2 | Purpose | Required | What the command does |\n| 3 | Key Principles | If applicable | Core philosophy and approach |\n| 4 | Inputs | If applicable | Variables, arguments, context |\n| 5 | Prerequisites | If applicable | Entry conditions, early-exit gates |\n| 6 | Process | Required | Step-by-step execution flow |\n| 7 | Outputs | If applicable | Files, reports, artifacts produced |\n| 8 | Examples | Recommended | Usage and output examples |\n| 9 | Validation | If applicable | Post-execution checks with fix procedures |\n| 10 | Cleanup | If applicable | Resource cleanup after execution |\n| 11 | Error Handling | Recommended | Failure modes and recovery |\n| 12 | Summary | Recommended | Post-execution summary and reflection |\n| 13 | References | If applicable | Related commands, external docs |\n\n---\n\n## Complete Template\n\n```markdown\n---\nname: example-command\ndescription: Brief description for command listing\ncategory: documentation\nversion: 1.0\nschema: aitt/commands/cmd.md  # Schema reference - modifications must follow this\nmodel: sonnet                    # Optional: preferred model (sonnet|opus|haiku)\ntools: [Read, Write, Glob]       # Optional: allowed tools\nmcp_servers: [chrome]            # Optional: required MCP servers\ninput:                           # Optional: quick input summary\n  expects: \"Target name\"\n  required: true\n  format: free-text\n---\n\n> **Schema:** This command follows `aitt/commands/cmd.md`. Read schema before modifying. If not found, ask user.\n\n# Command Name\n\n> Brief one-sentence description of what this command accomplishes.\n\n## Purpose\n\nExpanded description of the command's goal and when to use it.\n\n## Key Principles (Optional)\n\n**[Principle Name]:**\nCore concept or philosophy that guides this command's approach.\n\n**Anti-Pattern to Avoid:**\n- **Wrong:** Description of incorrect approach\n- **Correct:** Description of correct approach\n\n## Inputs\n\n**Expects:** Target name and optional configuration\n**Required:** Target required, options optional\n\n| Parameter | Required | Type | Description |\n|-----------|----------|------|-------------|\n| Target | Yes | string | The target to process |\n| Options | No | JSON | Additional configuration |\n\n### Usage\n```\n/example-command MyTarget\n/example-command MyTarget {\"verbose\": true}\n```\n\n## Prerequisites\n\n### Check 1: [Condition Name]\n\n**Check:** What to verify\n**Pass:** Proceed to next check\n**Fail:** Exit with [output/message]\n\n### Check 2: [Condition Name]\n\n**Check:** What to verify\n**Pass:** Proceed to Process\n**Fail:** Exit with [output/message]\n\n## Process\n\n### Step 1: Initialization\nDescription of first step.\n\n```bash\n# Commands to execute\nnpm run setup --target=$TARGET\n```\n\n### Step 2: Execution\nDescription of second step.\n\n#### Case A: Condition Met\n- Action when condition is true\n\n#### Case B: Condition Not Met\n- Action when condition is false\n\n#### Output Schema\n```json\n{\n  \"result\": \"success | error\",\n  \"data\": { }\n}\n```\n\n### Step 3: Checkpoint — Quality Gate\n\n> **GATE:** Do not proceed until satisfied.\n\n- [ ] Condition 1 met\n- [ ] Condition 2 met\n\n**If not satisfied:** Return to Step 2\n\n### Step 4: Finalization\nDescription of final step.\n\n#### Implementation\n```javascript\n// Update status in registry\nconst data = JSON.parse(fs.readFileSync('registry.json'));\ndata.status = 'completed';\nfs.writeFileSync('registry.json', JSON.stringify(data, null, 2));\n```\n\n## Outputs\n\n### Files Generated\n```\noutput-folder/\n├── artifact-1.md\n├── artifact-2.mmd\n└── artifact-3.json\n```\n\n### Output Format\nDescription or schema of output structure.\n\n## Examples\n\n### Basic Usage\n```\n/example-command MyTarget\n```\n\n### With Options\n```\n/example-command MyTarget {\"option\": \"value\"}\n```\n\n### Example Output\n```markdown\n# Generated Report\n...\n```\n\n## Validation\n\n### Check 1: Schema Compliance\n\n**Method:** Run `validation-command`\n**On success:** Proceed to next check\n**On failure:**\n1. Identify invalid fields from error output\n2. Fix each violation\n3. Re-run validation\n4. Repeat until passes\n\n### Check 2: Content Accuracy\n\n**Method:** Cross-reference output against source\n**On success:** Proceed to Cleanup\n**On failure:**\n1. Identify discrepancy\n2. Correct output\n3. Re-validate\n\n## Cleanup\n\n**If [resource was used]:**\n- Cleanup action 1\n- Cleanup action 2\n\n**If [resource was not used]:**\n- No cleanup required\n\n## Error Handling\n\n| Error | Cause | Resolution |\n|-------|-------|------------|\n| `Target not found` | Invalid input | Verify target exists |\n| `Missing dependency` | Prerequisite not met | Run `/prerequisite` first |\n\n## Summary\n\nBrief post-execution summary of what was accomplished, issues encountered (if any), and recommended next steps.\n\n## References\n\n- Related: `/related-command`\n- External: [Documentation Link](url)\n- Depends on: `/dependency-command`\n```\n\n---\n\n## Section Specifications\n\n### 1. Frontmatter\n\nYAML metadata block for machine parsing.\n\n```yaml\n---\nname: kebab-case-name          # Command identifier\ndescription: string            # One-line description (< 80 chars)\ncategory: enum                 # See categories below\nversion: semver                # Schema version (e.g., 1.0)\nauthor: string                 # Optional creator\nrequires: [string]             # Optional dependencies\nschema: aitt/commands/cmd.md  # Schema this command follows (recommended)\n\n# Execution Control (Optional)\nmodel: sonnet | opus | haiku   # Preferred Claude model\ntools: [Tool1, Tool2]          # Allowed tools whitelist\nmcp_servers: [server1]         # Required MCP servers\n\n# Input Definition (Optional - choose format that fits)\ninput:\n  expects: string              # Brief description of expected input\n  required: boolean            # Is input required?\n  format: free-text | json | named-params | none | conditional\n---\n```\n\n**Note:** The `input` property in frontmatter provides a quick summary. Detailed input documentation belongs in the Inputs section of the command body.\n\n**Schema Reference:**\nThe `schema` property declares which schema this command follows. When present:\n- Agents modifying the command MUST read and follow the referenced schema\n- If the schema file is not found, agents MUST ask the user for the schema location before making modifications\n- This ensures structural consistency across command updates\n\n**Required Schema Notice:**\nCommands following this schema MUST include a visible notice immediately after the frontmatter:\n```markdown\n> **Schema:** This command follows `aitt/commands/cmd.md`. Read schema before modifying. If not found, ask user.\n```\nThis ensures future agents see the schema requirement even if they don't parse frontmatter.\n\n**Categories:**\n- `documentation` - Generates docs, specs, diagrams\n- `workflow` - Orchestrates multi-step processes\n- `analysis` - Inspects code/data, produces reports\n- `generation` - Creates code, files, artifacts\n- `orchestration` - Coordinates other commands/agents\n\n**Execution Control Properties:**\n- `model` - Specify preferred Claude model for this command\n- `tools` - Whitelist of tools the command may use\n- `mcp_servers` - MCP servers required for command execution\n\n---\n\n### 2. Purpose\n\nClear statement of what the command does.\n\n```markdown\n## Purpose\n\nThis command [action verb] [target] to [outcome].\n\n**Use when:**\n- Scenario 1\n- Scenario 2\n\n**Do not use when:**\n- Anti-pattern 1\n```\n\n---\n\n### 3. Key Principles\n\nOptional section describing the core philosophy, approach, and guiding concepts that inform how the command works. Useful for complex commands where understanding the \"why\" helps users apply the command correctly.\n\n```markdown\n## Key Principles\n\n**[Principle Name]:**\nDescription of the core concept or philosophy.\n\n**[Another Principle]:**\nDescription of another guiding principle.\n\n**Anti-Pattern to Avoid:**\n- **Wrong:** Description of incorrect approach or common mistake\n- **Correct:** Description of the right way to think about it\n```\n\n**When to include Key Principles:**\n- Command has a specific methodology or approach that isn't obvious\n- There are common misconceptions about how the command should be used\n- The command embodies a particular philosophy (e.g., \"transaction completeness\" vs \"module boundaries\")\n- Understanding the principles helps users make better decisions during execution\n\n**Example principles:**\n- **Transaction Completeness:** \"Documentation captures the entire user transaction from action to idle state\"\n- **Source Truth:** \"Source code is authoritative—documentation must match implementation\"\n- **1:1 Correspondence:** \"Every BDD scenario must have a corresponding flowchart path\"\n\n---\n\n### 4. Inputs\n\nDocument what input the command expects. The format is flexible—choose the structure that best describes your command's input requirements.\n\n#### Input Summary (Required)\n\nAlways start with a brief summary of input expectations:\n\n```markdown\n## Inputs\n\n**Expects:** [Description of what input the command needs]\n**Required:** Yes | No | Conditional\n```\n\n#### Format A: Free Text\n\nFor commands accepting natural language or simple string input:\n\n```markdown\n## Inputs\n\n**Expects:** Free text describing the target\n**Required:** Yes\n\nThe command accepts `$ARGUMENTS` as free-form text input.\n\n**Examples:**\n- `/command analyze the login flow`\n- `/command Email/Password Login`\n- `/command \"feature name with spaces\"`\n```\n\n#### Format B: Structured (JSON/YAML)\n\nFor commands expecting structured data:\n\n```markdown\n## Inputs\n\n**Expects:** JSON object with feature metadata\n**Required:** Yes\n\n### Schema\n```json\n{\n  \"feature_name\": \"string (required)\",\n  \"category\": \"string (required)\",\n  \"evidence\": [\"array of file paths (optional)\"]\n}\n```\n\n### Example\n```json\n{\n  \"feature_name\": \"User Login\",\n  \"category\": \"Authentication\"\n}\n```\n```\n\n#### Format C: Named Parameters\n\nFor commands with multiple distinct inputs:\n\n```markdown\n## Inputs\n\n**Expects:** Feature name and optional configuration\n**Required:** Feature name required, options optional\n\n| Parameter | Required | Type | Description |\n|-----------|----------|------|-------------|\n| Feature name | Yes | string | Name of feature to process |\n| Options | No | JSON | Additional configuration |\n\n### Usage Patterns\n```\n/command FeatureName\n/command FeatureName {\"verbose\": true}\n```\n```\n\n#### Format D: No Input\n\nFor commands that operate without user input:\n\n```markdown\n## Inputs\n\n**Expects:** None\n**Required:** No\n\nThis command auto-detects its target based on [context/state/configuration].\n```\n\n#### Format E: Conditional Input\n\nFor commands with mode-dependent inputs:\n\n```markdown\n## Inputs\n\n**Expects:** Optional target specification\n**Required:** Conditional\n\n### Mode A: Auto-Select (no input)\n```\n/command\n```\nCommand automatically selects next item from queue.\n\n### Mode B: Specific Target (with input)\n```\n/command TargetName\n```\nCommand processes the specified target.\n```\n\n#### Context Files (Optional)\n\nIf the command auto-loads context files:\n\n```markdown\n### Context Files\n- `@path/to/config.md` - Loaded automatically for [purpose]\n- `@path/to/data.json` - Required data source\n```\n\n---\n\n### 5. Prerequisites\n\nEntry conditions that must be satisfied before the main process begins. If any prerequisite fails, the command exits early with an appropriate message or error output.\n\n```markdown\n## Prerequisites\n\n### Gate 1: [Condition Name]\n\n**Check:** Description of what to verify\n**Pass:** Proceed to next gate\n**Fail:** Exit with [specific output or message]\n\n**Fail Output Template (if applicable):**\n```yaml\nstatus: \"error\"\nerror_type: \"prerequisite_failed\"\nmessage: \"Description of why prerequisite was not met\"\n```\n\n---\n\n### Gate 2: [Condition Name]\n\n**Check:** Description of what to verify\n**Pass:** Proceed to Process\n**Fail:** Exit with [specific output or message]\n```\n\n**Key characteristics:**\n- Prerequisites run BEFORE the main process\n- Each gate is evaluated in order\n- Failure causes immediate exit (no partial execution)\n- Fail outputs can include structured error artifacts\n- All gates must pass to proceed to Process\n\n**Common prerequisite patterns:**\n- Check if output already exists (skip/overwrite decision)\n- Validate target accessibility (URL reachable, file exists)\n- Verify required dependencies are available\n- Confirm required MCP servers are connected\n\n---\n\n### 6. Process\n\nStep-by-step execution with clear decision points. Includes support for checkpoints, special case handling, and embedded implementation details.\n\n#### Embedding Implementation Details\n\n**Steps SHOULD include concrete implementation details** when they help clarify execution. This includes:\n\n| Content Type | When to Include | Example |\n|--------------|-----------------|---------|\n| Bash commands | CLI operations, file manipulation, tool invocation | `npx mmdc -i file.mmd -o output.svg` |\n| Code snippets | Programmatic logic, data transformations | JavaScript, Python, etc. |\n| Schema definitions | Data structures the step produces or consumes | JSON Schema, TypeScript interfaces |\n| File templates | Content structure for generated files | Markdown templates, config files |\n| Search patterns | Grep/glob patterns for discovery | `grep -r \"ClassName\" --include=\"*.kt\"` |\n| API examples | Request/response structures | REST endpoints, GraphQL queries |\n\n**Principle:** If an agent would need to guess HOW to implement a step, the step lacks sufficient detail. Include the implementation inline.\n\n```markdown\n## Process\n\n### Step 1: [Action Verb] [Target]\n\nDescription of what happens.\n\n```bash\n# Concrete command to execute\nnpx some-tool --input file.json --output result.md\n```\n\n#### Substep 1.1: Condition Handling\n\n**If** condition A:\n- Action 1\n- Action 2\n\n**Else if** condition B:\n- Alternative action\n\n**Else:**\n- Default action\n\n### Step 2: [Next Action]\n\nContinue with next logical step...\n\n#### Output Schema\n\nWhen this step produces structured data, define the schema:\n\n```json\n{\n  \"status\": \"completed | failed\",\n  \"output_path\": \"string\",\n  \"metadata\": {\n    \"created_at\": \"ISO8601 timestamp\",\n    \"source_files\": [\"array of paths\"]\n  }\n}\n```\n\n#### Implementation\n\n```javascript\n// Inline code when logic is non-trivial\nconst result = processInput(data);\nif (result.valid) {\n  writeOutput(result.data);\n}\n```\n\n### Step 3: Checkpoint — [Gate Name]\n\n> **GATE:** Do not proceed until all conditions are satisfied.\n\n- [ ] Condition 1 verified\n- [ ] Condition 2 verified\n- [ ] Minimum threshold met\n\n**If not satisfied:** Return to Step 2 and continue work\n\n---\n\n### Step 4: Process Items\n\nGeneral procedure for processing items.\n\n#### Special Cases\n\n**[Item Type A]:**\n- Override behavior 1\n- Special handling instructions\n\n**[Item Type B]:**\n- Different handling approach\n- Specific requirements\n\n### Step N: Completion\n\nFinal step and what success looks like.\n```\n\n#### Checkpoint Steps\n\nCheckpoints are mid-process gates that pause execution until conditions are met:\n\n```markdown\n### Step N: Checkpoint — [Descriptive Name]\n\n> **GATE:** Do not proceed until satisfied.\n\n- [ ] Condition 1\n- [ ] Condition 2\n\n**If not satisfied:** [Recovery action - typically return to earlier step]\n```\n\n**Checkpoint characteristics:**\n- Explicitly marked with \"Checkpoint —\" prefix\n- Include blockquote with **GATE:** indicator\n- List conditions as checkboxes\n- Specify recovery action if conditions not met\n\n#### Special Cases Subsection\n\nWhen process steps have item-specific overrides:\n\n```markdown\n### Step N: Process Items\n\n[General procedure description]\n\n#### Special Cases\n\n**[Item Type A]:**\n- Override 1\n- Override 2\n\n**[Item Type B]:**\n- Different handling\n```\n\n#### Common Step Subsection Patterns\n\nUse these subsection headers within steps to organize implementation details:\n\n| Subsection | Purpose | Example Content |\n|------------|---------|-----------------|\n| `#### Implementation` | Code that executes the step | JavaScript, Python, bash scripts |\n| `#### Output Schema` | Structure of data produced | JSON schema, TypeScript interface |\n| `#### Input Schema` | Structure of data consumed | JSON schema with validation rules |\n| `#### Search Patterns` | Patterns for file/content discovery | Glob patterns, grep regex |\n| `#### File Template` | Template for generated files | Markdown structure, config format |\n| `#### API Request` | External API call details | Endpoint, headers, body |\n| `#### Validation Rules` | Criteria the step must satisfy | Business rules, format requirements |\n\n**Example step with implementation details:**\n\n```markdown\n### Step 3: Update Feature Registry\n\nUpdate the feature status in the registry file.\n\n#### Input Schema\n```json\n{\n  \"feature_name\": \"string (required)\",\n  \"status\": \"pending | completed | failed\"\n}\n```\n\n#### Implementation\n```bash\nnode -e \"\nconst fs = require('fs');\nconst data = JSON.parse(fs.readFileSync('registry.json', 'utf8'));\nconst feature = data.find(f => f.name === '${FEATURE_NAME}');\nfeature.status = 'completed';\nfeature.updated_at = new Date().toISOString();\nfs.writeFileSync('registry.json', JSON.stringify(data, null, 2));\n\"\n```\n\n#### Validation Rules\n- Feature must exist in registry before update\n- Status must be one of: pending, completed, failed\n- updated_at must be valid ISO8601 timestamp\n```\n\n---\n\n### 7. Outputs\n\nSpecify all artifacts produced.\n\n```markdown\n## Outputs\n\n### Directory Structure\n```\noutput-folder/\n├── file-1.ext     # Description\n├── file-2.ext     # Description\n└── subfolder/\n    └── file-3.ext # Description\n```\n\n### File Schemas\n\n#### file-1.ext\n```json\n{\n  \"schema\": \"definition\"\n}\n```\n\n### Console Output\nDescription of what gets printed/displayed.\n```\n\n---\n\n### 8. Examples\n\nShow concrete usage patterns.\n\n```markdown\n## Examples\n\n### Example 1: Basic Usage\n**Input:**\n```\n/command-name simple-argument\n```\n\n**Result:**\nDescription of outcome.\n\n### Example 2: Complex Usage\n**Input:**\n```\n/command-name {\"complex\": \"json\", \"input\": true}\n```\n\n**Result:**\n```markdown\n# Generated Output\nContent here...\n```\n\n### Good vs Bad Examples\n\n#### Good\n```\n/command-name correct-usage\n```\n**Why:** Explanation\n\n#### Bad\n```\n/command-name incorrect-usage\n```\n**Why:** Explanation\n```\n\n---\n\n### 9. Validation\n\nPost-execution validation with support for fix-and-retry procedures. Validation runs AFTER the main process completes and BEFORE cleanup.\n\n#### Format A: Simple Checks\n\nFor straightforward pass/fail validation:\n\n```markdown\n## Validation\n\n- [ ] Output file exists\n- [ ] JSON is well-formed\n- [ ] Required fields present\n- [ ] Values within expected ranges\n```\n\n#### Format B: Validation with Fix Procedures\n\nFor validations that include remediation workflows:\n\n```markdown\n## Validation\n\n### Check 1: Schema Compliance\n\n**Method:** Run `npx ajv-cli validate -s schema.json -d output.yaml`\n\n**On success:** Proceed to next check\n\n**On failure:**\n1. Read error output to identify invalid fields\n2. Use Edit tool to fix each violation\n3. Re-run validation command\n4. Repeat until validation passes\n\n**Max retries:** Until success\n\n---\n\n### Check 2: Content Accuracy\n\n**Method:** Cross-reference each output field against source data\n\n**On success:** Proceed to Cleanup\n\n**On failure:**\n1. Identify discrepancy between output and source\n2. Return to source, verify correct value\n3. Update output with corrected value\n4. Re-validate this check\n\n**Max retries:** 3 (then flag for manual review)\n\n---\n\n### Check 3: Consistency\n\n**Method:** Compare related outputs for contradictions\n\n**On success:** Complete validation\n\n**On failure:**\n1. Identify contradicting statements\n2. Determine authoritative source\n3. Correct non-authoritative output\n4. Re-validate\n```\n\n**Validation check structure:**\n- **Method** — How to perform the check (command, manual review, comparison)\n- **On success** — Next action (proceed to next check, proceed to cleanup, complete)\n- **On failure** — Step-by-step fix procedure\n- **Max retries** — How many fix attempts before escalation (optional)\n\n**Key principles:**\n- Validation is post-execution only (pre-execution checks belong in Prerequisites)\n- Each check should have a clear fix procedure, not just pass/fail\n- External tool validation (schema validators, linters) is supported\n- Fix-and-retry loops continue until success or max retries reached\n\n---\n\n### 10. Cleanup\n\nResource cleanup after command execution. Runs after validation, regardless of success or failure.\n\n```markdown\n## Cleanup\n\n**If [resource/tool was used]:**\n1. Cleanup action 1\n2. Cleanup action 2\n3. Verify cleanup complete\n\n**If [resource/tool was not used]:**\n- No cleanup required\n```\n\n**Common cleanup patterns:**\n\n```markdown\n## Cleanup\n\n**If Chrome MCP was used:**\n1. Close all browser tabs opened during execution\n2. Verify no tabs remain from this session\n\n**If temporary files were created:**\n1. Delete files in `/tmp/command-workspace/`\n2. Remove empty directories\n\n**If external connections were opened:**\n1. Close database connections\n2. Terminate API sessions\n3. Release file locks\n\n**If no resources require cleanup:**\n- No cleanup required\n```\n\n**Key characteristics:**\n- Cleanup runs AFTER validation completes\n- Cleanup should execute regardless of command success/failure\n- Conditional cleanup based on which execution paths were taken\n- Verify cleanup actions completed successfully\n\n---\n\n### 11. Error Handling\n\nDocument failure modes and recovery. Use the appropriate format based on complexity.\n\n```markdown\n## Error Handling\n\n### ERR-001: Target Not Found\n\n**Symptoms:**\n- Command reports \"Target X not found\"\n- No output files generated\n\n**Possible Causes:**\n1. File path is incorrect or relative\n2. Target was renamed or moved\n3. Target exists but in unexpected location\n\n**Resolution Steps:**\n1. Verify the target path is absolute\n2. Search for the target using glob patterns:\n   ```bash\n   find . -name \"*target-name*\"\n   ```\n3. Check recent git history for renames:\n   ```bash\n   git log --follow --name-only -- \"*target*\"\n   ```\n4. If found in new location, update input and retry\n\n**Prevention:**\n- Always use absolute paths\n- Run `/verify-paths` before complex operations\n\n### ERR-002: Validation Failure\n\n**Symptoms:**\n- Output generated but marked invalid\n- Consistency check fails\n\n**Diagnosis Checklist:**\n- [ ] Source files unchanged since analysis started?\n- [ ] All dependencies resolved?\n- [ ] Output schema matches expected format?\n\n**Resolution by Cause:**\n\n**If source changed during execution:**\n- Discard output\n- Re-run command with fresh source state\n\n**If dependency missing:**\n- Identify missing dependency from error log\n- Run prerequisite command first\n- Retry original command\n\n**If schema mismatch:**\n- Compare output against schema definition\n- Identify malformed sections\n- Manually correct or regenerate affected sections\n\n### ERR-003: Partial Completion\n\n**Symptoms:**\n- Some outputs generated, others missing\n- Command terminated unexpectedly\n\n**Recovery Procedure:**\n1. Check which outputs exist:\n   ```\n   output/\n   ├── file-1.md  ✓ (exists)\n   ├── file-2.md  ✗ (missing)\n   └── file-3.md  ✓ (exists)\n   ```\n2. Determine if partial outputs are usable\n3. Options:\n   - **Resume:** Re-run command (idempotent commands only)\n   - **Complete manually:** Generate missing files individually\n   - **Rollback:** Delete partial outputs, fix cause, restart\n\n**Do NOT:**\n- Assume partial outputs are complete\n- Mix outputs from multiple runs without verification\n```\n\n---\n\n### 12. Summary\n\nPost-execution summary providing reflection on what was accomplished, issues encountered, and recommended next steps. This section helps users understand the outcome and determine follow-up actions.\n\n**When to include:**\n- Complex multi-step processes where outcomes may vary\n- Analysis commands that produce findings requiring interpretation\n- Workflows that may encounter recoverable issues\n- Any command where user action may be needed post-execution\n\n**When to omit:**\n- Simple commands with obvious success/failure outcomes\n- Commands where the output artifacts speak for themselves\n\n```markdown\n## Summary\n\nBrief post-execution summary addressing:\n- What was successfully accomplished\n- Issues encountered (if any) with their impact\n- Data quality or completeness assessment (if applicable)\n- Recommended next steps or follow-up actions\n- Any caveats or limitations users should be aware of\n\n### Format A: Success with No Issues\n\nIf everything completed successfully with no gaps or concerns:\n\n```\n✓ [COMMAND NAME] COMPLETE\n\n[1-2 sentence summary of what was accomplished]\nNo issues detected. All objectives met.\n```\n\n### Format B: Success with Notes\n\nIf command completed but with recoverable issues, missing data, or important context:\n\n```\n✓ [COMMAND NAME] COMPLETE\n\n[1-2 sentence summary of what was accomplished]\n\nIssues Encountered:\n- [Issue 1 description]\n- [Issue 2 description]\n\nImpact:\n[How issues affect the output or next steps]\n\nRecommended Actions:\n1. [Specific action to address issue 1]\n2. [Specific action to address issue 2]\n\nQuality Assessment: [Brief statement on output completeness/reliability]\n```\n\n### Format C: Partial Completion\n\nIf command completed but some objectives were not met:\n\n```\n⚠ [COMMAND NAME] PARTIALLY COMPLETE\n\nCompleted:\n- [What succeeded]\n\nIncomplete:\n- [What failed or was skipped]\n\nReason: [Why partial completion occurred]\n\nNext Steps:\n1. [How to complete remaining work]\n2. [Alternative approaches if applicable]\n```\n\n**Key principles:**\n- Be concise—users want actionable information, not verbose recap\n- Prioritize recommendations—what should the user do next?\n- Differentiate severity—minor gaps vs. critical issues\n- Provide specificity—concrete actions, not vague suggestions\n- Omit the section entirely if no useful information to convey\n```\n\n---\n\n### 13. References\n\nLink related resources.\n\n```markdown\n## References\n\n### Related Commands\n- `/related-1` - Relationship description\n- `/related-2` - Relationship description\n\n### Dependencies\n- `/prerequisite` - Must run before this command\n\n### External Documentation\n- [Link Text](url) - Description\n\n### Source Files\n- `path/to/implementation` - Purpose\n```\n\n---\n\n## Command Type Templates\n\n### Type A: Simple Action Command\n\n```markdown\n---\nname: simple-action\ndescription: Performs a single focused action\ncategory: generation\ninput:\n  expects: \"Target to process\"\n  required: true\n  format: free-text\n---\n\n# Simple Action\n\n> Performs [action] on [target].\n\n## Purpose\n\n[One paragraph description]\n\n## Inputs\n\n| Variable | Type | Description |\n|----------|------|-------------|\n| `$TARGET` | string | The target to process |\n\n## Process\n\n1. Read input\n2. Execute action\n3. Output result\n\n## Outputs\n\n- Single file or console output\n\n## Examples\n\n```\n/simple-action my-target\n```\n```\n\n---\n\n### Type B: Delegation Command\n\n```markdown\n---\nname: platform-specific\ndescription: Delegates to base command with platform context\ncategory: orchestration\nrequires: [base-command]\ninput:\n  expects: \"Arguments to pass to base command\"\n  required: true\n  format: json\n---\n\n# Platform-Specific Command\n\n> Executes base command with platform-specific configuration.\n\n## Purpose\n\nWrapper that applies platform context to the base command.\n\n## Configuration\n\n| Setting | Value |\n|---------|-------|\n| Output folder | `platform/` |\n| Source location | `source-path/` |\n\n## Process\n\nExecute `@.claude/commands/base-command.md` with:\n1. Platform-specific output paths\n2. Platform-specific source paths\n3. All other base command instructions\n\n## Inputs\n\nPass through: `$ARGUMENTS`\n\n## Outputs\n\nSame as base command, in platform-specific directory.\n```\n\n---\n\n### Type C: Multi-Step Workflow\n\n```markdown\n---\nname: workflow-command\ndescription: Orchestrates multiple steps or commands\ncategory: workflow\ninput:\n  expects: \"Optional workflow arguments\"\n  required: false\n  format: free-text\n---\n\n# Workflow Command\n\n> Orchestrates [workflow description].\n\n## Purpose\n\nCoordinates multiple steps/commands to achieve [goal].\n\n## Process Overview\n\n```\nStep 1 ──► Step 2 ──► Step 3 ──► Complete\n              │\n              ▼\n         [Parallel]\n         /        \\\n    Step 2a    Step 2b\n         \\        /\n          ──►──►──\n```\n\n## Process\n\n### Step 1: Setup\n[Description]\n\n### Step 2: Parallel Execution\nLaunch simultaneously:\n- **Task A:** Description\n- **Task B:** Description\n\n### Step 3: Aggregation\nCombine results from parallel tasks.\n\n### Step 4: Completion\nFinal actions and reporting.\n\n## Error Handling\n\n### Step Failures\n- Step 1 fails: Abort workflow\n- Step 2a fails: Continue with 2b, mark partial\n- Step 3 fails: Retry once, then abort\n\n## Status Tracking\n\n| Status | Meaning |\n|--------|---------|\n| `pending` | Not started |\n| `in_progress` | Currently executing |\n| `completed` | Successfully finished |\n| `failed` | Error occurred |\n```\n\n---\n\n### Type D: Analysis/Report Command\n\n```markdown\n---\nname: analysis-command\ndescription: Analyzes target and produces report\ncategory: analysis\ninput:\n  expects: \"Target to analyze\"\n  required: true\n  format: free-text\n---\n\n# Analysis Command\n\n> Analyzes [target] and produces [report type].\n\n## Purpose\n\nPerforms comprehensive analysis of [target] to identify [findings].\n\n## Inputs\n\n| Variable | Type | Description |\n|----------|------|-------------|\n| `$TARGET` | string | What to analyze |\n\n## Analysis Scope\n\n### Include\n- Item type 1\n- Item type 2\n\n### Exclude\n- Excluded item type 1\n\n## Process\n\n### Step 1: Discovery\nLocate and enumerate targets.\n\n### Step 2: Analysis\nFor each target:\n- Check aspect 1\n- Check aspect 2\n- Record findings\n\n### Step 3: Synthesis\nAggregate findings into report.\n\n## Output Format\n\n### Report Structure\n```markdown\n# Analysis Report: [Target]\n\n## Summary\n[Executive summary]\n\n## Findings\n\n### Category 1\n| Finding | Severity | Location |\n|---------|----------|----------|\n| ... | ... | ... |\n\n## Recommendations\n[Prioritized recommendations]\n```\n\n## Validation\n\n- [ ] All targets analyzed\n- [ ] No false positives\n- [ ] Recommendations actionable\n```\n\n---\n\n### Type E: Documentation Generation\n\n```markdown\n---\nname: doc-generator\ndescription: Generates documentation from source analysis\ncategory: documentation\ninput:\n  expects: \"Feature metadata object\"\n  required: true\n  format: json\n---\n\n# Documentation Generator\n\n> Generates comprehensive documentation for [target].\n\n## Purpose\n\nAnalyzes source code and produces documentation artifacts.\n\n## Inputs\n\n### JSON Schema\n```json\n{\n  \"feature_name\": \"string (required)\",\n  \"category\": \"string (required)\",\n  \"evidence\": [\"array of file paths\"]\n}\n```\n\n## Process\n\n### Step 1: Parse Input\nExtract metadata from JSON input.\n\n### Step 2: Resolve Evidence\nLocate all referenced source files.\n\n### Step 3: Analyze\nDeep analysis of source code behavior.\n\n### Step 4: Generate Artifacts\nCreate documentation files.\n\n### Step 5: Validate\nCross-check artifacts for consistency.\n\n## Outputs\n\n### File Structure\n```\n${feature-name}/\n├── ${feature-name}.spec.md      # Specification\n├── ${feature-name}.diagram.mmd  # Visual diagram\n└── ${feature-name}.notes.md     # Additional notes\n```\n\n### Artifact Specifications\n\n#### spec.md\n- Metadata section\n- Overview\n- Detailed scenarios\n- References\n\n#### diagram.mmd\n- Mermaid syntax\n- Color-coded paths\n- All decision points\n\n## Validation\n\n### Consistency Checks\n- [ ] All scenarios in spec have diagram paths\n- [ ] All diagram paths match spec scenarios\n- [ ] Evidence files resolved\n- [ ] Syntax validated\n```\n\n---\n\n## Best Practices\n\n### Writing Style\n\n**Principles:**\n1. Structure conveys importance—all steps are required by default\n2. Concise over verbose—every word must earn its place\n3. Complete over brief—include all details, but no filler\n\n**Conciseness guidelines:**\n\n| Verbose (avoid) | Concise (prefer) |\n|-----------------|------------------|\n| \"In order to accomplish this task, you will need to...\" | \"Run:\" |\n| \"It is important to note that the system will...\" | \"The system...\" |\n| \"The next step involves performing the action of...\" | \"Next:\" |\n| \"Please ensure that you have completed...\" | \"Verify:\" |\n| \"This particular feature is responsible for...\" | \"This feature...\" |\n| \"At this point in time, the process will...\" | \"The process...\" |\n\n**Write like a reference manual, not a tutorial.** Assume the reader is competent. State facts. Omit preamble.\n\n```markdown\n❌ \"Before we begin, it's worth mentioning that you'll want to make sure\n    that all of your dependencies are properly installed and configured\n    before attempting to run this command.\"\n\n✓  \"Prerequisite: Dependencies installed.\"\n```\n\n**Prohibited patterns:**\n```markdown\n❌ *** MANDATORY ***\n❌ CRITICAL: You MUST do this\n❌ IMPORTANT: Do not skip this step\n❌ **NOTE:** This is essential\n❌ WARNING: Required action\n❌ !!! ATTENTION !!!\n❌ [REQUIRED] Step description\n❌ Step description (MUST DO)\n```\n\n**Correct approach:**\n```markdown\n✓ Step description                    # All steps are required by default\n✓ (Optional) Step description         # Explicitly mark optional items\n✓ > **GATE:** Do not proceed...       # Use schema-defined checkpoints for critical gates\n✓ **If not satisfied:** Return to...  # Use structured conditions, not shouty warnings\n```\n\n**Rationale:**\n- When everything is marked \"CRITICAL,\" nothing stands out\n- The schema's structure (Prerequisites, Checkpoints, Validation) already indicates importance\n- Agents reading the command will follow ALL steps—emphasis markers add noise, not compliance\n- Use `(Optional)` to mark non-required items rather than marking required items as required\n\n**Allowed emphasis:**\n- `> **GATE:**` blockquotes for mid-process checkpoints (schema-defined pattern)\n- Bold for **structural labels** (Check:, Pass:, Fail:, Method:, etc.)\n- Code formatting for `commands`, `paths`, and `values`\n- Tables and structured formats for complex information\n\n**Anti-pattern to avoid:**\n- **Wrong:** \"*** CRITICAL *** You MUST verify this step is complete before proceeding!!!\"\n- **Correct:** Document the step. Use a checkpoint if verification is needed before continuing.\n\n### Naming Conventions\n- Use `kebab-case` for command names\n- Use `SCREAMING_SNAKE_CASE` for variables\n- Use descriptive, action-oriented names\n\n### Documentation Quality\n- Lead with purpose—what and why\n- Process steps should be actionable\n- Include both success and failure paths\n- Provide concrete examples\n- Assume all steps are required—mark exceptions with `(Optional)`\n\n### Maintainability\n- Keep commands focused (single responsibility)\n- Extract common logic to base commands\n- Version your commands\n- Document breaking changes\n\n### User Experience\n- Provide helpful error messages\n- Show progress for long operations\n- Support both simple and advanced usage\n- Include \"good vs bad\" examples\n\n---\n\n## Migration Guide\n\nTo convert an existing command to this schema:\n\n1. **Extract metadata** into frontmatter\n2. **Identify sections** in existing content\n3. **Reorganize** into schema sections\n4. **Add missing sections** (error handling, validation)\n5. **Standardize formatting** (tables, code blocks)\n6. **Add examples** if missing\n7. **Validate** against schema\n\n---\n\n## Changelog\n\n### Version 1.4\n- Added Summary section (section 12) as recommended post-execution reflection\n- Summary provides outcome assessment, issues encountered, and next steps\n- Three format options: Success with No Issues, Success with Notes, Partial Completion\n- Renumbered References from section 12 to section 13\n- Updated Section Reference table and Complete Template\n- Summary is recommended but not mandatory—omit when no useful information to convey\n\n### Version 1.3\n- Added \"Writing Style\" section to Best Practices\n- Established three principles: structure conveys importance, concise over verbose, complete over brief\n- Added conciseness guidelines with verbose/concise comparison table\n- Added guidance: \"Write like a reference manual, not a tutorial\"\n- Defined prohibited emphasis patterns (MANDATORY, CRITICAL, IMPORTANT, etc.)\n- Added guidance to mark optional items with `(Optional)` rather than marking required items as required\n- Documented allowed emphasis patterns (GATE: blockquotes, structural labels, code formatting)\n\n### Version 1.2\n- Added `schema` frontmatter property for declaring schema compliance\n- Added required visible schema notice after frontmatter (blockquote format)\n- Schema reference ensures agents read and follow schema when modifying commands\n- If schema file not found, agents must ask user for schema location\n- Enhanced Process section with \"Embedding Implementation Details\" guidance\n- Added explicit encouragement for bash commands, code snippets, and schemas within steps\n- Added \"Common Step Subsection Patterns\" table (Implementation, Output Schema, Input Schema, Search Patterns, File Template, API Request, Validation Rules)\n- Updated Complete Template with concrete implementation examples\n- Added principle: \"If an agent would need to guess HOW to implement a step, the step lacks sufficient detail\"\n\n### Version 1.1\n- Added Key Principles section for documenting core philosophy and approach\n- Added Prerequisites section for entry gates with early-exit support\n- Added Cleanup section for resource management\n- Extended Frontmatter with `model`, `tools`, `mcp_servers` properties\n- Added Checkpoint step type for mid-process gates in Process section\n- Added Special Cases subsection pattern for item-specific overrides\n- Refactored Validation to focus on post-execution with fix procedures\n- Removed pre-execution checks from Validation (moved to Prerequisites)\n- Refactored Inputs section to be format-agnostic (free text, JSON, named params, none, conditional)\n- Replaced rigid `variables` frontmatter with flexible `input` summary\n- Removed Common Anti-Patterns from Error Handling (author's discretion)\n- Renumbered sections to accommodate new additions (now 12 sections)\n\n### Version 1.0\n- Initial schema definition\n- Five command type templates\n- Section specifications\n- Best practices guide\n",
        "aitt/commands/code-review.md": "---\nallowed-tools: Read, Grep, Glob, Bash, TodoWrite\ndescription: \"Analyze code quality, security, performance, and architecture\"\n---\n\n# /code-review - Code Review\n\n## Purpose\n\nExecute comprehensive code analysis across quality, security, performance, and architecture domains.\n\n## Usage\n\n```bash\n/code-review [branch]\n```\n\n## Execution\n\n1. Discover and categorize files for analysis based on the diff between the current branch and the target branch:\n   - Use `git diff {branch_argument}...$(git branch --show-current)` where `{branch_argument}` is the first argument (defaults to 'master' if not provided)\n2. Apply appropriate analysis tools and techniques:\n   - **Quality**: Code style, complexity, maintainability, technical debt assessment, SOLID principles compliance, error handling patterns\n   - **Security**: Vulnerability scanning, dependency checks, threat modeling, authentication/authorization flaws, data exposure risks, input validation\n   - **Performance**: Profiling, bottleneck identification, resource usage analysis, scalability assessment, Core Web Vitals (frontend), memory management (leaks, dangling pointers, buffer overflows)\n   - **Architecture**: Design patterns, modularity, scalability, coupling analysis, separation of concerns, future-proofing evaluation\n   - **Testing**: Test quality, edge case handling, test pyramid compliance (DO NOT run tests, just analyze test\n   - **Maintainability**: Code readability, documentation quality, code comments, naming conventions, modularity\n     coverage and quality)\n   - Based on an initial quick analysis, add additional checks if necessary\n3. Generate findings with severity ratings\n4. Create actionable recommendations with priorities, only if issues are found\n   - Severity levels:\n     - High: Critical issues that must be addressed immediately\n     - Medium: Important issues that should be resolved soon\n     - Low: Minor issues that can be addressed later\n   - List should be sorted by severity\n   - Include file project root relative filepaths and line numbers for each issue\n   - Focus on changes and the effects of those changes, not the entire file\n5. Present ONLY a nicely formatted compact markdown table of text-based analysis report nothing else\n   - If you have positive findings, just add a tick mark next to the section that you used as a point to review\n   - Start with the positive findings and then list the improvements at the end\n   - Only include list of improvements\n   - Include:\n     - File paths in a following format: `./path/to/file.js:line_number` (DO NOT include ranges just where the issue\n       is)\n     - Issues found\n     - Severity\n     - Recommendations\n\n### Example Output\n\n```text\n  | Category       | Assessment | Notes                                                 |\n  |----------------|------------|-------------------------------------------------------|\n  | Quality ✓      | Good       | Clean JWT implementation following best practices     |\n  | Security ⚠️    | Poor       | Critical JWT verification vulnerability present       |\n  | Performance ✓  | Good       | Efficient key caching and library migration           |\n  | Architecture ✓ | Good       | Well-structured auth system with feature flag support |\n\n  Improvements Needed\n\n  | File                                        | Issue                                    | Severity | Recommendation                                                      |\n  |---------------------------------------------|------------------------------------------|----------|---------------------------------------------------------------------|\n  | ./src/util/jwt-token.ts:26                  | Incorrect key selection for verification | High     | Use publicKey instead of checking privateKey for token verification |\n  | ./src/middlewares/auth-middleware.ts:68     | Hardcoded httpOnly setting               | Medium   | Use consistent auth v2 flag check like in login route               |\n  | ./src/app/portal/api/user/login/route.ts:82 | Age verification expiry inconsistency    | Low      | Consider using consistent expiry calculation method                 |\n```\n\nDO NOT include any other text, explanations, or comments outside the markdown table.\n\n## Claude Code Integration\n\n- Uses Glob for systematic file discovery\n- Leverages Grep for pattern-based analysis\n- Applies Read for deep code inspection\n- Maintains structured analysis reporting\n",
        "aitt/commands/commit-suggest.md": "---\nallowed-tools: Read, Grep, Glob, Bash, TodoWrite, Bash(git add .), Bash(scripts/find-ticket-from-branch.sh)\nargument-hint: \"[--breaking] [--type <type>] [--ticket <ticket>]\"\ndescription: \"This command suggests a commit message for current changes without executing the commit and copies the commit command to clipboard\"\n---\n\n# /commit-suggest - Suggests a commit message for current changes\n\n## Purpose\n\nThis command suggests a well-formatted commit message with conventional commit messages based on the current changes in the repository.\n\n## Usage\n\n```bash\n/commit-suggest\n```\n\nForce breaking change structure with:\n\n```bash\n/commit-suggest --breaking\n```\n\nForce commit type with:\n\n```bash\n/commit-suggest --type <type>\n```\n\nWhere `<type>` is one of: feat, fix, docs, style, refactor, perf, test, chore\n\nForce ticket ID with:\n\n```bash\n/commit-suggest --ticket <ticket>\n```\n\n## What This Command Does\n\n1. Runs `.claude/scripts/find-ticket-from-branch.sh` script to extract a related ticket ID from the current branch name and include it in the commit message if found\n   - If a `--ticket <ticket>` argument is provided, it MUST use that ticket ID instead of extracting from branch name\n   - If no ticket ID is found you MUST prompt the user and wait to provide one before proceeding any steps further\n2. Checks staged files with `git status`\n   - If no files are staged, automatically adds all modified/new files with `git add .`\n3. Analyzes the changes with `git diff --cached` to understand what is being committed. Quickly identify:\n   - File types modified (components, tests, docs, config, etc.)\n   - Nature of changes (new features, bug fixes, refactoring, etc.)\n   - Scope of impact (single feature, multiple areas, etc.)\n4. Suggests a conventional commit message that accurately reflects the changes being committed `[<JIRA ticket reference>] <type>: <description>`\n\n   - Types: feat, fix, docs, style, refactor, perf, test, chore\n   - Use present tense, imperative mood\n   - Keep first line under 72 characters\n   - Be specific but concise\n   - Use multiple lines if necessary\n   - Single-line example: `[PROJ-123] fix: resolve memory leak in rendering process`\n   - Multi-line example:\n\n     ```text\n     [PROJ-123] feat: add user authentication module\n\n     - Implement login and registration endpoints\n     - Add JWT-based authentication\n     - Update user model with password hashing\n     ```\n\n5. Outputs the suggested git commit command with the message: `git commit -m \"<suggested message>\"`\n6. Copies the suggested git commit command to clipboard with `pbcopy`\n\n## Important Notes\n\n- Do NOT execute the commit, only suggest the commit message and copy the commit command to clipboard\n- You MUST follow conventional commit standards when suggesting the commit message\n- You MUST suggest a commit message that accurately reflects the changes being committed\n- Prioritize speed - make quick, accurate assessments\n- Follow conventional commit standards strictly\n- Be decisive in commit type classification\n- Ensure commit message accurately reflects the actual changes\n- Handle edge cases gracefully (no changes, merge conflicts, etc.)\n",
        "aitt/commands/e2e-test/plan.md": "# Usage\n\n```bash\n/e2e-test:plan\n```\n\n## Execution\n\n1. Explore **$ARGUMENTS** website and gathering information about its functionalities with e2e-test-qa subagent.\n2. With the gathered data, plan e2e test scenarios for later implementation into @test_plan.md file with e2e-test-planner subagent.\n",
        "aitt/commands/e2e-test/write.md": "# Usage\n\n```bash\n/e2e-test:write\n```\n\nOr, to focus on a specific section of the test plan:\n\n```bash\n/e2e-test:write [test_plan_section]\n```\n\n## Execution\n\n1. Read the @test_plan.md in the project root directory and create e2e playwright test scenarios based on unmarked items and prompted plan sections `[test_plan_section]` with e2e-test-writer subagent.\n2. After finishing creating the tests, update the @test_plan.md file by marking the completed items with a checkmark.\n",
        "aitt/commands/feature-documentation.md": "---\nname: feature-documentation\ndescription: Generates BDD specification, business flowchart, and technical sequence diagram for a feature\ncategory: documentation\nversion: 1.1\nschema: .claude/command-schema.md\ninput:\n  expects: \"JSON object with feature metadata (feature_name, category, surface, actors, flags_or_flavors, evidence (optional), description)\"\n  required: true\n  format: json\n---\n\n> **⚠️ Schema:** This command follows `.claude/command-schema.md`. Read schema before modifying. If not found, ask user.\n\n# Feature Documentation Generator\n\n> Produces three complementary deliverables for a given feature: a full BDD specification, a business-focused Mermaid flowchart, and a technical Mermaid sequence diagram based on the feature's description and codebase behavior.\n\n## Purpose\n\nThis command analyzes source code evidence files and produces comprehensive documentation that captures both business behavior and technical implementation of a feature.\n\n**Use when:**\n- Documenting a new or existing feature for QA, product design, or reimplementation\n- Creating specifications that bridge business requirements and technical implementation\n- Generating visual documentation of complex feature workflows\n- Establishing a complete behavioral blueprint for a feature\n\n**Do not use when:**\n- You need only a quick summary (use simpler documentation approaches)\n- The feature is trivial and doesn't warrant three-document analysis\n\n## Key Principles\n\n**Transaction Completeness:**\nDocumentation captures the entire user transaction from initial action to application quiescence (idle state), not just the code within evidence files. The feature is not complete until the application reaches idle state with no pending operations and the user sees the final result.\n\n- **Anti-Pattern:** \"Login feature ends when LoginViewController calls completion\"\n- **Correct:** \"Login feature ends when user sees main screen and app is idle\"\n\n**Bidirectional Tracing:**\nTrace code paths in BOTH directions:\n- **Forward:** What happens after the feature completes (callbacks, navigation, state changes)\n- **Backward:** What can invoke this feature and with what parameters/state\n\nFeatures may behave differently based on entry context (e.g., Login screen showing \"account blocked\" toast when entered after forbidden auth state).\n\n**1:1 Correspondence:**\nMaintain strict correspondence between documents:\n- Between BDD scenarios and flowchart branches (business perspective)\n- Between BDD scenarios and sequence diagram flows (technical perspective)\n- Between flowchart business actions and sequence diagram technical implementations\n\n**Source Code as Truth:**\nIf contradictions are found during validation, always defer to the source code as the authoritative source. Documentation must match implementation.\n\n## Inputs\n\n**Expects:** JSON object with feature metadata\n**Required:** Yes\n\n### JSON Schema\n\n```json\n{\n  \"feature_name\": \"Feature Name\",\n  \"category\": \"Category\",\n  \"surface\": [\"Screen\", \"Component\"],\n  \"actors\": [\"Guest\", \"EndUser\"],\n  \"flags_or_flavors\": [],\n  \"evidence\": [                              // OPTIONAL - will be discovered if not provided\n    \"relative/path/to/file1.kt\",\n    \"relative/path/to/file2.xml:SpecificClass\"\n  ],\n  \"description\": \"Business-level description of the feature\"\n}\n```\n\n### Parameter Definitions\n\n| Parameter | Required | Type | Description |\n|-----------|----------|------|-------------|\n| `feature_name` | Yes | string | Name of the feature (converted to lowercase with hyphens for folder/file names) |\n| `category` | Yes | string | Business category (e.g., \"Acquisition\", \"Retention\", \"Monetization\") |\n| `surface` | Yes | array | UI surface types where feature appears (e.g., \"Screen\", \"Dialog\", \"Component\", \"Widget\") |\n| `actors` | Yes | array | User roles interacting with the feature (e.g., \"Guest\", \"EndUser\", \"Admin\", \"Performer\") |\n| `flags_or_flavors` | No | array | Feature flags or build flavors that control this feature (empty if always enabled) |\n| `evidence` | No | array | File paths pointing to source code implementing the feature (if not provided, will be discovered based on feature_name and description) |\n| `description` | Yes | string | Concise business-level description of what the feature does and its purpose |\n\n### Evidence Path Format\n\nEvidence paths support multiple formats:\n- Simple path: `path/to/file.ext`\n- Path with class reference: `path/to/file.ext:ClassName`\n- Path with method reference: `path/to/file.ext:ClassName.methodName`\n\n### Usage\n\n```\n/feature-documentation {\"feature_name\": \"User Login\", \"category\": \"Authentication\", \"surface\": [\"Screen\"], \"actors\": [\"Guest\"], \"flags_or_flavors\": [], \"evidence\": [\"src/features/auth/LoginScreen.tsx\"], \"description\": \"Email and password authentication flow\"}\n```\n\n## Prerequisites\n\n### Gate 1: Evidence Available or Discoverable\n\n**Check:** Evidence files are provided OR feature can be discovered from codebase\n**Pass:** Proceed to Gate 2\n**Fail:** Exit only if discovery yields no results\n\n**If evidence provided:**\n- Verify at least one evidence file path can be resolved\n- Mark unresolvable paths as `[MISSING EVIDENCE: path]`\n- Continue with available files\n\n**If evidence not provided:**\n- Proceed to Step 2 for autonomous evidence discovery\n\n### Gate 1.5: Variant Implementation Verification\n\n**Check:** If ANY evidence filename contains variant indicators (`Default`, `Base`, `Standard`, `Main`, `Common`, `Impl`), variant search has been performed\n**Pass:** All variant implementations documented in evidence list, proceed to Gate 2\n**Fail:** Return to Step 2 and complete variant discovery\n\n**Fail Recovery Procedure:**\n1. Extract base name from indicator-containing filename (e.g., `LoginUseCaseDefault` → `LoginUseCase`)\n2. Search for sibling classes matching base name pattern\n3. Search dependency injection / factory modules for Provider patterns referencing the base type\n4. Add all discovered variants to evidence list\n5. Document the selection mechanism (build-time flavor, runtime configuration, DI module)\n6. Re-validate this gate\n\n**Verification Questions (must answer ALL):**\n\n| Question | Required Answer |\n|----------|-----------------|\n| Does any evidence filename contain variant indicators? | Yes (list them) or No |\n| If yes, what is the base name? | [Must name extracted base] |\n| What sibling implementations exist? | [Must list all or state \"None found\" with search evidence] |\n| What determines variant selection? | [Must identify mechanism: DI module, build flavor, runtime config] |\n\n### Gate 2: Mermaid CLI Available\n\n**Check:** Project has Mermaid CLI installed (`npx mmdc --version` succeeds)\n**Pass:** Proceed to Process\n**Fail:** Warn user but continue (syntax validation will be skipped)\n\n## Process\n\n### Step 1: Parse JSON Input\n\nExtract feature metadata from the JSON input:\n1. Parse the JSON object\n2. Extract `feature_name` and convert to kebab-case for folder/file naming\n3. Store all metadata for use in output generation\n\n### Step 2: Resolve or Discover Evidence Files\n\n#### Case A: Evidence Provided\n\nFor each evidence entry:\n\n**Substep 2.1: Parse Evidence Path**\n- Extract file path and optional class/method reference (after `:`)\n- Example: `SplashActivity.kt:SplashActivity` → file: `SplashActivity.kt`, focus: `SplashActivity` class\n\n**Substep 2.2: Locate Files**\n**Priority order:**\n1. Try resolving as absolute path\n2. Try relative to current working directory\n3. Use Glob tool to search for filename in project\n4. Check paths relative to git repository root\n\n**If file not found:**\n- Mark as `[MISSING EVIDENCE: path]`\n- Continue with available files\n\n**Substep 2.3: Extract Class/Method Context**\n- If reference provided (after `:`), focus analysis on that specific component\n- Example: `AndroidManifest.xml:SplashActivity` → focus on SplashActivity configuration\n\n#### Case B: Evidence Not Provided (Autonomous Discovery)\n\nWhen evidence array is empty or not provided, discover relevant source files:\n\n**Substep 2.4: Search by Feature Name**\n- Convert feature_name to search patterns (e.g., \"User Login\" → `*Login*`, `*login*`, `*user-login*`)\n- Search for source files matching the pattern, excluding:\n  - Dependency directories (`node_modules`, `vendor`, `Pods`, `.gradle`, `packages`)\n  - Build outputs (`dist`, `build`, `out`, `target`, `.next`, `__pycache__`)\n  - Version control (`.git`, `.svn`)\n  - Assets and media files (images, fonts, videos)\n- Prioritize files with common source code extensions for the detected project type\n- Filter results by reading file headers to confirm source code (not assets, configs, or generated files)\n\n**Substep 2.5: Search by Surface Type**\n- Use surface hints to identify architectural layer:\n\n  | Surface Category | Includes | Common Patterns |\n  |------------------|----------|-----------------|\n  | Presentation | Screen, Page, Dialog, Modal, Component, Widget | `*Screen*`, `*Page*`, `*View*`, `*Dialog*`, `*Modal*`, `*Component*` |\n  | API/Endpoint | Endpoint, Route, Controller, Handler | `*Controller*`, `*Handler*`, `*Router*`, `*Route*`, `*Resource*` |\n  | Service/Logic | Service, UseCase, Interactor, Manager | `*Service*`, `*UseCase*`, `*Interactor*`, `*Repository*`, `*Manager*` |\n  | Data | Repository, Store, Cache, Model | `*Repository*`, `*Store*`, `*Model*`, `*Entity*`, `*DAO*` |\n\n- Patterns are illustrative; adapt to project naming conventions\n\n**Substep 2.6: Search by Description Keywords**\n- Extract key terms from description\n- Use Grep to find files containing those terms\n- Prioritize files with multiple keyword matches\n\n**Substep 2.7: Validate Discovered Files**\n- Read candidate files to confirm relevance\n- Filter out test files, mocks, and unrelated matches\n- Rank by relevance based on:\n  - Feature name match strength\n  - Surface type alignment\n  - Description keyword density\n- Select top candidates as evidence files\n\n**Substep 2.8: Variant Implementation Discovery**\n\nEvidence files may represent one of several parallel implementations. Search for variants when indicators are present.\n\n**Indicators:**\n- File or class name contains qualifiers: `Default`, `Base`, `Standard`, `Main`, `Common`, `Impl`\n- Class inherits from abstract base or implements interface/protocol\n- Project structure contains parallel source directories for build variants\n- Dependency injection or factory patterns reference multiple concrete types\n\n**When indicators detected:**\n- Search for sibling implementations sharing the same base name or parent type\n- Examine build configuration and DI modules to identify all variants\n- Add all discovered variant files to evidence list\n- Document the selection mechanism (build-time, runtime, configuration)\n\n**Rationale:** A feature documented from only one variant will miss conditional behavior present in other variants.\n\n**If no files discovered:**\n- Report `[DISCOVERY FAILED: No matching source files found for \"${feature_name}\"]`\n- Exit with suggestions for manual evidence specification\n\n### Step 3: Analyze Source Code\n\nRead all resolved evidence files and identify:\n- Dependencies (imports, service calls, repository usage)\n- Business logic and validation rules\n- State transitions and navigation flows\n- Error handling patterns\n- External service integrations\n\n### Step 4: Expand Analysis with Transaction Tracing\n\nEvidence files are the **starting point**, not the boundary. Treat the feature as an atomic transaction from user initiation to system quiescence.\n\n#### Substep 4.1: Forward Tracing\nTrace what happens after feature code executes:\n- Direct method calls within evidence files\n- Indirect callbacks, delegates, and observers\n- Navigation/routing logic that redirects control flow\n- Background tasks, async operations, and delayed executions\n- State changes propagated through stores, repositories, or event buses\n- Lifecycle events triggered in parent/coordinator components\n\n#### Substep 4.1b: Parent Coordinator Tracing (MANDATORY)\n\n**CRITICAL:** Feature completion is NOT the transaction end. You MUST trace what the PARENT coordinator/flow does after receiving the completion callback.\n\n**Discover invocations by searching for common patterns:**\n\n| Paradigm | Invocation Patterns to Search |\n|----------|-------------------------------|\n| Navigation/Routing | `navigate(${FEATURE})`, `router.push(${FEATURE})`, `goto ${FEATURE}`, `redirect(${FEATURE})` |\n| Instantiation | `new ${FEATURE}()`, `${FEATURE}.create()`, `${FEATURE}Factory`, `build${FEATURE}()` |\n| Event-Driven | `dispatch(${FEATURE}Action)`, `emit('${FEATURE}')`, `publish(${FEATURE}Event)`, `send(${FEATURE}Command)` |\n| Dependency Injection | `provide(${FEATURE})`, `inject(${FEATURE})`, `resolve(${FEATURE})`, `${FEATURE}Provider` |\n| Function Call | `start${FEATURE}()`, `open${FEATURE}()`, `show${FEATURE}()`, `handle${FEATURE}()` |\n\n**Examine each caller to understand:**\n1. What parameters/state are passed to the feature\n2. What the caller does when the feature completes\n3. Any conditional logic before or after invocation\n\n**You MUST identify and document:**\n1. **Parent orchestrator name** — the component that invokes this feature (e.g., `AppRouter`, `MainController`, `RootCoordinator`, `Shell`, `RequestHandler`)\n2. **What parent does after feature completion:**\n   - Conditional navigation (state-dependent routing)\n   - Deferred operations (queued actions executed post-completion)\n   - State machine transitions\n   - Analytics or tracking events\n3. **Any conditional post-completion logic** based on:\n   - User state or session data\n   - Feature flags or configuration\n   - Pending operations queued before this feature started\n\n**Example pattern to trace:**\n```\n${FEATURE_NAME}Flow.completion called\n  ↓\nParentFlow receives completion\n  ↓\nParentFlow checks [CONDITION A] → [DOCUMENT IF BRANCHES]\n  ↓\nParentFlow checks [CONDITION B] → [DOCUMENT IF BRANCHES]\n  ↓\nParentFlow starts NextFlow\n  ↓\nUser sees destination screen [ACTUAL IDLE STATE]\n```\n\n**Anti-pattern (WRONG):**\n```\n${FEATURE_NAME}Flow.completion called → [STOP HERE - INCOMPLETE!]\n```\n\n#### Substep 4.2: Backward Tracing\n\nIdentify all entry points into this feature:\n\n**Discover:**\n- All callers that invoke, instantiate, or route to this feature\n- Import or dependency statements that reference this feature\n- Route definitions, navigation mappings, or URL patterns targeting this feature\n\n**For each caller, analyze:**\n- Parameters, props, or state passed to the feature\n- Pre-invocation actions (notifications, analytics, permission checks, state preparation)\n- Post-invocation handling (callbacks, subscriptions, navigation on completion)\n- Whether different callers provide different contexts that affect feature behavior\n\n**Entry Point Documentation Format:**\n\nFor each entry point discovered, capture in structured format:\n\n| Field | Required | Description |\n|-------|----------|-------------|\n| Caller | Yes | Specific class and method that invokes this feature |\n| Condition | Yes | What triggers this entry path (user action, system event, state) |\n| Parameters | Yes | All parameters passed, with types and possible values |\n| Pre-display Actions | If any | Operations performed BEFORE feature UI is shown |\n| Post-display Actions | If any | Operations performed AFTER feature UI is shown |\n| Context Effects | If any | How this entry context changes feature behavior |\n\nThis structured format must be used when documenting entry points in the BDD specification.\n\n#### Substep 4.3: External UI Trigger Tracing\n\nIdentify external code that triggers UI elements associated with this feature:\n- Toasts, snackbars, or notifications shown before/after feature display\n- Conditional UI elements based on feature state or entry context\n- Deep link or URL handlers that route to this feature\n\n#### Substep 4.4: Determine Idle State\nContinue tracing until reaching idle state conditions:\n- No pending asynchronous operations (promises, futures, callbacks, background tasks, scheduled jobs)\n- Navigation/routing has settled (final view/page/screen rendered to user)\n- All data persistence complete (database writes, cache updates, secure storage, session state, user preferences)\n- All network requests completed and responses processed\n- All UI updates rendered and animations/transitions finished\n- Application returns to awaiting user input or external event\n\n**Discovery Techniques:**\n- **Completion handlers:** Trace what happens after feature-specific code completes\n- **Navigation flows:** Follow scene/activity transitions until final destination\n- **State observers:** Track reactive state changes across app layers\n- **Lifecycle callbacks:** Examine parent component lifecycle methods\n- **Deferred operations:** Check for scheduled work, timers, or background jobs\n\n#### Substep 4.5: Checkpoint — Transaction Completeness\n\n> **GATE:** Do not proceed to Step 5 until ALL items are verified.\n\n**Required Checklist:**\n\n- [ ] **Parent coordinator identified:** Named the specific class that STARTS this feature\n- [ ] **Parent's completion handler read:** Examined the actual code that executes when this feature's completion callback fires\n- [ ] **Post-completion actions documented:** Listed ALL conditional branches and actions the parent takes after this feature completes\n- [ ] **True idle state verified:** Confirmed the FINAL screen user sees (not intermediate navigation)\n- [ ] **Cross-cutting concerns captured:** Documented any behaviors triggered by parent that affect user experience\n- [ ] **Variant implementations verified:** If any evidence filename contains variant indicators (Default, Base, Standard, Main, Common, Impl), all sibling implementations identified and added to evidence\n\n**Verification Questions (must answer ALL):**\n\n| Question | Your Answer |\n|----------|-------------|\n| What class STARTS this feature? | [Must name specific class, not \"unknown\"] |\n| What does parent do on completion? | [Must describe actual code behavior] |\n| Any conditional post-completion flows? | [Must verify YES with details, or NO with evidence] |\n| What screen does user ACTUALLY see? | [Must name final destination screen] |\n| Any evidence files contain variant indicators? | [Must answer YES with list, or NO] |\n| If YES, all variants discovered and documented? | [Must confirm variants added to evidence or state \"No siblings found\" with search evidence] |\n\n**If not satisfied:** Return to Substep 4.1b and trace parent coordinator\n\n**Example of PASSING:**\n```\n✓ Parent: ParentFlow (ParentFlow.swift:45)\n✓ Completion handler: handle${FEATURE_NAME}Completion() line 234\n✓ Post-completion: conditionalCheck (240), stateTransition (248), else NextFlow (255)\n✓ Final screen: DestinationViewController\n✓ Cross-cutting: [List any behaviors triggered by parent, not by this feature directly]\n```\n\n**Example of FAILING:**\n```\n✗ Parent: \"${FEATURE_NAME}Flow itself\" → WRONG: Must trace to PARENT\n✗ Completion: \"Not examined\" → WRONG: Must read actual code\n✗ Post-completion: \"Feature just completes\" → WRONG: Must verify parent's actions\n```\n\n### Step 5: Create BDD Specification\n\n**Action:** Create folder `${FEATURE_NAME}/` and write `${FEATURE_NAME}.bdd.md` immediately.\n\nGenerate `${FEATURE_NAME}/${FEATURE_NAME}.bdd.md` with:\n\n#### Content Structure:\n```markdown\n# BDD Specification: ${FEATURE_NAME}\n\n> **Location:** `${FEATURE_NAME}/${FEATURE_NAME}.bdd.md`\n\n## Metadata\n- **Category:** ${CATEGORY}\n- **Surface:** ${SURFACE} (e.g., Screen, Dialog, Component)\n- **Actors:** ${ACTORS} (e.g., Guest, EndUser, Admin)\n- **Feature Flags/Flavors:**\n  - `flagName` - Effect on feature behavior when enabled/disabled\n  - `anotherFlag` - What this flag controls\n  - (or \"None - Always enabled\" if no conditional behavior)\n- **Variant Implementations:** (if applicable)\n  - `VariantA` - Used when [condition]\n  - `VariantB` - Used when [condition]\n  - **Selection Mechanism:** [DI module / build flavor / runtime config]\n- **Evidence Files:**\n  - `path/to/file1.kt`\n  - `path/to/file2.xml:ClassName`\n\n## Overview\n${DESCRIPTION}\n\n## Entry Points\n\n### Entry Point 1: [Context Name]\n- **Caller:** `ClassName.methodName()`\n- **Condition:** What triggers this entry path\n- **Parameters:** List all parameters with types\n- **Pre-display Actions:** Operations before feature UI shown (if any)\n- **Context Effects:** How this context affects feature behavior (if any)\n\n### Entry Point 2: [Context Name]\n...\n\n## Business Rules\n\n### BR-001: [Rule Name]\n- **Rule:** [Precise description with specific values/thresholds]\n- **Applies to:** [Which scenarios/conditions]\n\n### BR-002: [Rule Name]\n...\n\n## Scenarios\n### Scenario 1: ...\nGiven ...\nWhen ...\nThen ...\n\n### Scenario 2: ...\n...\n```\n\n#### BDD Requirements:\n- Document ALL user roles, permissions, validations, and preconditions\n- Capture every main path, alternate path, and error/edge case\n- Include limits, retries, rate limits, and timeouts\n- Mark external dependencies as `[REFERENCE: ServiceName]` or `[MISSING LINK]`\n- Document complete user transaction from initiation to idle state\n- Include cross-cutting concerns discovered during transaction tracing\n- Create scenario for each unique entry context that affects user experience\n- Each scenario must be exhaustive and business-readable\n- Extract and document all business rules with unique identifiers (BR-001, BR-002, etc.)\n- Business rules include: validation thresholds, selection logic, state machine transitions, conditional behaviors, rate limits, retry policies\n- Each rule must include specific values, not generic descriptions (e.g., \"password minimum 8 characters\" not \"password must meet requirements\")\n- **Compound Condition Extraction:** For conditional behaviors (feature triggers, navigation decisions, UI state changes), extract the COMPLETE boolean expression from source code. Do not paraphrase or simplify.\n\n  Anti-pattern (incomplete):\n  ```\n  Rule: Feature X is shown when the user is eligible and the feature is enabled\n  ```\n\n  Correct pattern (complete):\n  ```\n  Rule: Feature X is shown when ALL conditions are true:\n    (1) userType != TYPE_A\n    (2) featureFlag.isEnabled == true\n    (3) user.status == ACTIVE\n  ```\n\n  Extraction method: Locate the `if`/`when`/`guard` statement controlling the behavior and transcribe each sub-condition verbatim with its comparison operator and value.\n- Document system-triggered behaviors: UI state changes from system events (keyboard visibility, orientation, network status), lifecycle callbacks, and timer-based operations\n\n### Step 6: Create Business Flowchart\n\n**Action:** Write `${FEATURE_NAME}/${FEATURE_NAME}.flowchart.mmd` immediately.\n\nGenerate `${FEATURE_NAME}/${FEATURE_NAME}.flowchart.mmd` with:\n\n#### Syntax Requirements:\n- Use `flowchart TD` (top-down layout)\n- Follow official Mermaid syntax: https://docs.mermaidchart.com/mermaid-oss/syntax/flowchart.html\n\n#### Content Requirements:\n- Represent every scenario and condition from BDD\n- Include all decision points (`{condition}` nodes)\n- Show all success, alternate, and failure paths\n- Represent forks and joins as `((Fork))` and `((Join))`\n- Include business states or milestones\n- Mark external dependencies as `[REFERENCE: ServiceName]`\n- Model preconditions, validations, and permission checks\n- Show external calls or async processes\n- Include retry and fallback logic\n- Capture all granular business behavior\n\n#### Exclusions (Technical Details):\n- Do NOT include internal variable setting or parameter assignments\n- Do NOT break down API request construction into individual steps\n- Focus on WHAT happens from business perspective, not HOW\n\n#### Color Coding:\nApply styles using `:::className` syntax after node definitions.\n\n**IMPORTANT:** Apply colors to ALL nodes on the critical path, including decision boxes, to create an unbroken visual flow.\n\n```mermaid\nflowchart TD\n    A[Start: User initiates feature]:::criticalPath --> B{Preconditions met?}:::criticalPath\n    B -->|No| X[Show error]:::errorPath\n    B -->|Yes| C[Validate input]:::criticalPath\n    C -->|Invalid| Y[Show validation error]:::errorPath\n    C -->|Valid| D[Send request to REFERENCE: ExternalService]:::externalCall\n    D --> E{Operation succeeded?}:::criticalPath\n    E -->|Yes| F[Persist result]:::criticalPath\n    E -->|No| G[Retry or flag failure]:::alternatePath\n    F --> Z[End]:::criticalPath\n\n    %% Color definitions\n    classDef criticalPath fill:#90EE90,stroke:#228B22,stroke-width:3px,color:#000\n    classDef errorPath fill:#FFB6C1,stroke:#DC143C,stroke-width:2px,color:#000\n    classDef alternatePath fill:#FFD700,stroke:#FF8C00,stroke-width:2px,color:#000\n    classDef externalCall fill:#87CEEB,stroke:#4169E1,stroke-width:2px,color:#000\n```\n\n**Color Scheme:**\n| Class | Color | Usage |\n|-------|-------|-------|\n| `criticalPath` | Green (#90EE90) | Main happy path nodes AND decision boxes on critical path |\n| `errorPath` | Red (#FFB6C1) | Error handling, failure nodes, decision boxes leading to errors |\n| `alternatePath` | Yellow (#FFD700) | Alternate valid paths (not errors, not main flow) |\n| `externalCall` | Blue (#87CEEB) | External service dependencies |\n\n### Step 7: Create Technical Sequence Diagram\n\n**Action:** Write `${FEATURE_NAME}/${FEATURE_NAME}.sequence.mmd` immediately.\n\nGenerate `${FEATURE_NAME}/${FEATURE_NAME}.sequence.mmd` with:\n\n#### Syntax Requirements:\n- Start with `sequenceDiagram` keyword (no spaces, no hyphens)\n- Follow official Mermaid syntax: https://docs.mermaidchart.com/mermaid-oss/syntax/sequenceDiagram.html\n\n#### Content Requirements:\n- Show ALL technical implementation details\n- Include all actors, components, classes, and services\n- Document every method call in execution flow\n- Show parameter passing and data transformations\n- Include API requests/responses with full technical details (see API Documentation Requirements below)\n- Document database operations\n- Show state changes and variable assignments\n- Include internal validations and checks\n- Document exception handling and error propagation\n- Show callbacks, listeners, and async operations\n- Include threading details (main thread, background threads, coroutines)\n- Document lifecycle events\n\n#### Architecture Layer Completeness:\n\nThe sequence diagram must show ALL architectural layers involved in data flow, not just entry and exit points.\n\n**Required layers to identify and include (when present):**\n- Presentation layer (Views, Activities, ViewControllers, Components)\n- Domain layer (UseCases, Interactors, Services)\n- Data layer (Repositories, DataStores, DAOs)\n- Network layer (API clients, CloudDataStores, HTTP services)\n- Persistence layer (Local storage, Caches, Databases)\n\n**Anti-pattern (incomplete):**\n```\nRepository->>API: request()\n```\n\n**Correct pattern:**\n```\nRepository->>DataStore: getData()\nDataStore->>APIClient: request()\nAPIClient->>HTTPService: execute()\n```\n\nIf intermediate layers exist between a caller and an external service, they must appear as separate participants.\n\n#### API Documentation Requirements:\n\nEvery API call in the sequence diagram MUST include sufficient detail for complete reimplementation. API documentation follows the **OpenAPI 3.1 Specification** (https://swagger.io/specification/).\n\n**Required API Details (OpenAPI-aligned):**\n\n| OpenAPI Element | Description | Example |\n|-----------------|-------------|---------|\n| `servers[].url` | Base URL / domain | `https://api.example.com` |\n| `paths.{path}` | Endpoint path with path parameters | `/v1/auth/login`, `/users/{userId}` |\n| `paths.{path}.{method}` | HTTP operation | `post`, `get`, `put`, `delete` |\n| `parameters` | Path, query, header, cookie params | `in: header, name: Authorization` |\n| `requestBody.content` | Request body schema by media type | `application/json: {schema: ...}` |\n| `responses.{code}` | Response schemas by status code | `200: {content: ...}`, `401: {content: ...}` |\n| `security` | Authentication requirements | `bearerAuth: []` |\n\n**API Documentation Format in Sequence Diagram:**\n\nAPI calls in the sequence diagram should reference the OpenAPI specification file using `operationId`. Do NOT duplicate API details inline—the OpenAPI file is the single source of truth.\n\n```mermaid\nsequenceDiagram\n    participant App as Application\n    participant API as AuthService API\n\n    App->>API: POST /v1/auth/login\n    Note right of API: See: openapi.yaml#loginUser\n    API-->>App: 200 OK + AuthResponse\n```\n\n**Reference Format:** `See: openapi.yaml#{operationId}`\n\nThis approach:\n- Maintains single source of truth in OpenAPI file\n- Keeps sequence diagrams readable and focused on flow\n- Enables API changes without updating diagrams\n- Allows code generation from authoritative OpenAPI spec\n\n**Companion OpenAPI Specification File (Required for features with API calls)**\n\nCreate a companion file `${FEATURE_NAME}/${FEATURE_NAME}.openapi.yaml` following OpenAPI 3.1 specification:\n\n```yaml\nopenapi: 3.1.0\ninfo:\n  title: ${FEATURE_NAME} API\n  description: API endpoints for the ${FEATURE_NAME} feature\n  version: 1.0.0\n\nservers:\n  - url: https://api-gw.production-domain.com\n    description: Production API Gateway\n  - url: https://api-gw.staging-domain.com\n    description: Staging environment (if applicable)\n  # List ALL actual production domains used by this feature\n  # Do NOT use placeholder domains like example.com\n\npaths:\n  /v1/auth/login:\n    post:\n      operationId: loginUser\n      summary: Authenticate user with email and password\n      tags:\n        - Authentication\n      parameters:\n        - name: X-Client-Version\n          in: header\n          required: true\n          schema:\n            type: string\n          description: Application version string\n        - name: X-Device-ID\n          in: header\n          required: false\n          schema:\n            type: string\n          description: Unique device identifier\n      requestBody:\n        required: true\n        content:\n          application/json:\n            schema:\n              $ref: '#/components/schemas/LoginRequest'\n      responses:\n        '200':\n          description: Successful authentication\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/AuthResponse'\n        '400':\n          description: Validation error\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n        '401':\n          description: Invalid credentials\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n        '403':\n          description: Account locked\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n        '429':\n          description: Rate limited\n          content:\n            application/json:\n              schema:\n                $ref: '#/components/schemas/ErrorResponse'\n              example:\n                error: rate_limited\n                message: Too many login attempts\n                details:\n                  retry_after: 60\n      security: []  # Public endpoint\n\ncomponents:\n  schemas:\n    LoginRequest:\n      type: object\n      required:\n        - email\n        - password\n      properties:\n        email:\n          type: string\n          format: email\n          description: User email address\n        password:\n          type: string\n          minLength: 8\n          description: User password\n        remember_me:\n          type: boolean\n          default: false\n          description: Extend token lifetime\n\n    AuthResponse:\n      type: object\n      required:\n        - access_token\n        - refresh_token\n        - expires_in\n        - token_type\n        - user\n      properties:\n        access_token:\n          type: string\n          description: JWT access token\n        refresh_token:\n          type: string\n          description: Refresh token for token renewal\n        expires_in:\n          type: integer\n          description: Seconds until access_token expires\n        token_type:\n          type: string\n          enum: [Bearer]\n        user:\n          $ref: '#/components/schemas/User'\n\n    User:\n      type: object\n      required:\n        - id\n        - email\n        - display_name\n      properties:\n        id:\n          type: string\n          format: uuid\n          description: User UUID\n        email:\n          type: string\n          format: email\n        display_name:\n          type: string\n        avatar_url:\n          type: string\n          format: uri\n          nullable: true\n\n    ErrorResponse:\n      type: object\n      required:\n        - error\n        - message\n      properties:\n        error:\n          type: string\n          enum:\n            - validation_error\n            - invalid_credentials\n            - account_locked\n            - rate_limited\n        message:\n          type: string\n          description: Human-readable error message\n        details:\n          type: object\n          nullable: true\n          description: Additional error context\n\n  securitySchemes:\n    bearerAuth:\n      type: http\n      scheme: bearer\n      bearerFormat: JWT\n      description: JWT token obtained from login endpoint\n```\n\n**Minimum Requirements for API Reimplementation (OpenAPI Checklist):**\n\nThe following MUST be present in the `${FEATURE_NAME}.openapi.yaml`:\n\n- [ ] `openapi` version specified (3.1.0)\n- [ ] `servers` array with ACTUAL production URLs (not placeholder domains like example.com)\n- [ ] If multiple environments or regional domains exist, ALL are listed in `servers`\n- [ ] All `paths` with complete endpoint definitions\n- [ ] All `parameters` (path, query, header) with `in`, `required`, and `schema`\n- [ ] `requestBody` with `content` media type and schema reference\n- [ ] All `responses` with status codes, descriptions, and schema references\n- [ ] `components/schemas` with fully typed request/response objects\n- [ ] `components/securitySchemes` if authentication required\n- [ ] `security` requirements on operations or globally\n- [ ] Schema `required` arrays for mandatory fields\n- [ ] Schema `type`, `format`, and constraints (`minLength`, `enum`, etc.)\n- [ ] Lifecycle/inverse endpoints documented (if applicable)\n- [ ] Error recovery endpoints documented (if applicable)\n\n#### Related Endpoints Discovery:\n\nThe OpenAPI specification must include not only endpoints directly called by the feature, but also:\n\n1. **Lifecycle endpoints** - Endpoints that undo/reverse the feature's action (e.g., logout for login, unsubscribe for subscribe, revoke for grant)\n2. **Dependent endpoints** - Endpoints called as prerequisites or follow-ups within the same user transaction\n3. **Error recovery endpoints** - Endpoints called when the primary flow fails\n\n**Discovery method:**\n1. Search for inverse operations in codebase (create↔delete, login↔logout, subscribe↔unsubscribe)\n2. Trace error handlers to identify recovery API calls\n3. Examine session/state cleanup code for additional endpoints\n\n#### Diagram Elements:\n- Use activation boxes (`activate`/`deactivate`) for execution context\n- Use `loop` blocks for iterations\n- Use `alt` blocks for conditional logic\n- Use `par` blocks for concurrent operations\n- Use `Note` annotations for clarifications\n\n#### Color Coding with rect Blocks:\n\n**CRITICAL PATH RULES:**\n- **ONLY** include main success/happy path where everything works correctly\n- **NEVER** include error handling, validation failures, or negative conditions inside critical path `rect` blocks\n- **NEVER** include `alt` blocks with failure cases inside critical path sections\n- Error recovery and validation failures must be in separate error path `rect` blocks\n\n```mermaid\nsequenceDiagram\n    actor User\n    participant View as LoginView\n    participant Handler as LoginHandler\n    participant Service as AuthService\n\n    rect rgb(200, 255, 200)\n        Note over User,View: [CRITICAL PATH - Happy Flow]\n        User->>View: Submit credentials\n        View->>Handler: login(credentials)\n        Handler->>Service: authenticate(credentials)\n        Service-->>Handler: Success(tokens)\n        Handler-->>View: State.Authenticated\n        View->>View: navigateTo(destination)\n    end\n\n    rect rgb(255, 200, 200)\n        Note over User,View: [ERROR PATH - Invalid Credentials]\n        User->>View: Submit credentials\n        View->>Handler: login(credentials)\n        Handler->>Service: authenticate(credentials)\n        Service-->>Handler: Error(INVALID_CREDENTIALS)\n        Handler-->>View: State.Error\n        View->>View: showError(message)\n    end\n```\n\n**Color Scheme for rect blocks:**\n| RGB Value | Usage |\n|-----------|-------|\n| `rgb(200, 255, 200)` | Critical path sections (light green) |\n| `rgb(255, 200, 200)` | Error handling sections (light red) |\n| `rgb(255, 255, 200)` | Alternate path sections (light yellow) |\n| `rgb(200, 230, 255)` | External service calls (light blue) |\n\n### Step 8: Checkpoint — Entry Point Coverage\n\n> **GATE:** Do not proceed until satisfied.\n\n- [ ] All callers of feature's entry point identified (Step 4.2)\n- [ ] Each caller's context analyzed for parameters and pre/post-display actions\n- [ ] External UI triggers traced (Step 4.3)\n- [ ] BDD scenarios exist for each unique entry context that affects user experience\n\n**If not satisfied:** Return to Step 4 and complete bidirectional tracing\n\n### Step 9: Validate Mermaid Syntax\n\nRun Mermaid CLI to validate both diagram files:\n\n```bash\n# Flowchart validation\nnpx mmdc -i ${FEATURE_NAME}/${FEATURE_NAME}.flowchart.mmd -o /dev/null\n\n# Sequence diagram validation (use nul on Windows)\nnpx mmdc -i ${FEATURE_NAME}/${FEATURE_NAME}.sequence.mmd -o /dev/null\n```\n\n**If syntax errors reported:**\n1. Read error message carefully\n2. Identify line number and error type\n3. Fix syntax error in diagram file\n4. Re-run CLI validation\n5. Repeat until both diagrams pass without errors\n\n### Step 10: Cross-Document Validation\n\nCompare every scenario in BDD against both diagrams:\n\n#### Verification Checklist:\n- [ ] Each BDD scenario has corresponding path in flowchart\n- [ ] Each BDD scenario has corresponding sequence in sequence diagram\n- [ ] All decision points in flowchart are described in BDD scenarios\n- [ ] All technical method calls in sequence diagram support BDD behaviors\n- [ ] Success, error, and alternate paths match across all three documents\n- [ ] Preconditions, validations, and outcomes are consistently represented\n- [ ] Sequence diagram shows technical HOW for flowchart's business WHAT\n- [ ] All entry point scenarios documented\n\n#### Critical Path Verification:\n- [ ] Flowchart: Critical path nodes (including decision boxes) ONLY on main success path\n- [ ] Sequence diagram: Critical path `rect` blocks ONLY contain happy path\n- [ ] Error handling in separate colored sections\n- [ ] No `alt` blocks with failure branches inside critical path colored blocks\n\n#### API Reimplementation Verification (OpenAPI Compliance):\n- [ ] `${feature-name}.openapi.yaml` file exists for features with API calls\n- [ ] OpenAPI `servers` array contains all API base URLs\n- [ ] All `paths` match endpoints shown in sequence diagram\n- [ ] All `parameters` include `in`, `required`, and `schema` properties\n- [ ] All `requestBody` definitions include `content` with media type and schema\n- [ ] All `responses` include status codes with `content` and schema references\n- [ ] `components/schemas` define all request/response data types\n- [ ] `components/securitySchemes` define authentication mechanisms if used\n- [ ] Schema `required` arrays correctly identify mandatory fields\n- [ ] Schema properties include `type`, `format`, and validation constraints\n- [ ] OpenAPI file validates against OpenAPI 3.1 specification\n- [ ] A developer could generate API client code from the OpenAPI spec\n\n**If discrepancies found:** Document as `[VALIDATION ISSUE]` and proceed to Step 11\n\n### Step 11: Reconcile Against Source Code\n\nFor any discrepancies or `[VALIDATION ISSUE]` markers:\n\n1. Return to source code\n2. Re-analyze actual implementation behavior\n3. Determine which document(s) are incorrect\n4. Update incorrect document(s) to match source code\n5. Remove `[VALIDATION ISSUE]` markers once resolved\n\n**Areas to verify:**\n- Business logic (BDD & Flowchart): Validation rules, error handling, business sequences\n- Technical implementation (Sequence Diagram): Method calls, class interactions, data flow\n- External service dependencies\n- State transitions\n- Exception handling and error propagation\n- API contracts: Verify documented domains, paths, request/response schemas match actual network layer implementation\n\n## Outputs\n\n### Directory Structure\n\n```\n${feature-name}/\n├── ${feature-name}.bdd.md          # BDD specification with metadata\n├── ${feature-name}.flowchart.mmd   # Color-coded business flowchart\n├── ${feature-name}.sequence.mmd    # Color-coded technical sequence diagram\n└── ${feature-name}.openapi.yaml    # OpenAPI 3.1 specification (if feature has API calls)\n```\n\n**Naming Convention:** Convert feature name to lowercase with hyphens replacing whitespaces (e.g., \"Email Password Login\" → `email-password-login/`)\n\n### File Specifications\n\n#### ${feature-name}.bdd.md\n- Metadata section with category, surface, actors, flags, evidence\n- Overview from description\n- Exhaustive BDD scenarios covering all paths\n- References to external dependencies\n- Annotations for unclear logic or missing behavior\n\n#### ${feature-name}.flowchart.mmd\n- Mermaid flowchart syntax (flowchart TD)\n- All business logic paths visualized\n- Color-coded critical path (unbroken green flow)\n- Decision points, validations, external calls\n- No technical implementation details\n\n#### ${feature-name}.sequence.mmd\n- Mermaid sequence diagram syntax\n- All technical implementation details\n- Method calls, class interactions, data flow\n- Color-coded rect blocks for path types\n- Threading and lifecycle details\n- API calls with full endpoint documentation (domain, path, method)\n- Request/response schemas for all API interactions\n\n#### ${feature-name}.openapi.yaml\n- Created for any feature that makes API calls\n- Follows OpenAPI 3.1 Specification (https://swagger.io/specification/)\n- `servers` array with base URLs for all API domains\n- `paths` with complete endpoint definitions and `operationId`\n- `parameters` for path, query, header params with schemas\n- `requestBody` with content type and schema references\n- `responses` for all status codes with schema references\n- `components/schemas` with fully typed data models\n- `components/securitySchemes` for authentication definitions\n- Enables code generation and API client reimplementation\n\n## Examples\n\n### Example 1: With Evidence Provided\n\n**Input:**\n```json\n{\n  \"feature_name\": \"Splash Screen\",\n  \"category\": \"Onboarding\",\n  \"surface\": [\"Screen\"],\n  \"actors\": [\"Guest\", \"EndUser\"],\n  \"flags_or_flavors\": [],\n  \"evidence\": [\n    \"src/features/splash/SplashScreen.tsx\",\n    \"src/features/splash/SplashHandler.ts\"\n  ],\n  \"description\": \"Initial app launch screen displayed during startup and initialization\"\n}\n```\n\n**Process:**\n1. Parse JSON: Extract \"Splash Screen\", convert to `splash-screen`\n2. Resolve evidence: Locate SplashScreen.tsx and SplashHandler.ts\n3. Analyze code: Read implementation, identify dependencies, lifecycle, navigation\n4. Create BDD: Document all scenarios (app launch, initialization, navigation, errors)\n5. Create flowchart: Visualize business startup flow with color-coded critical path\n6. Create sequence diagram: Document technical implementation with method calls\n7. Validate: Run syntax validation, cross-check documents, reconcile with source\n\n**Output:**\n```\nsplash-screen/\n├── splash-screen.bdd.md\n├── splash-screen.flowchart.mmd\n└── splash-screen.sequence.mmd\n```\n\n### Example 2: Without Evidence (Autonomous Discovery)\n\n**Input:**\n```json\n{\n  \"feature_name\": \"User Login\",\n  \"category\": \"Authentication\",\n  \"surface\": [\"Screen\"],\n  \"actors\": [\"Guest\"],\n  \"flags_or_flavors\": [],\n  \"description\": \"Email and password authentication flow for user sign-in\"\n}\n```\n\n**Process:**\n1. Parse JSON: Extract \"User Login\", convert to `user-login`\n2. Discover evidence:\n   - Search for `*Login*` files → finds `LoginScreen.tsx`, `LoginHandler.ts`\n   - Search by surface \"Screen\" → confirms `LoginScreen.tsx`\n   - Search by keywords \"authentication\", \"sign-in\" → finds `AuthService.ts`\n   - Validate and select: `LoginScreen.tsx`, `LoginHandler.ts`, `AuthService.ts`\n3. Analyze discovered code: Read implementations, trace dependencies\n4. Create BDD, flowchart, sequence diagram\n5. Validate all documents\n\n**Output:**\n```\nuser-login/\n├── user-login.bdd.md\n├── user-login.flowchart.mmd\n└── user-login.sequence.mmd\n```\n\n### Transaction Tracing Example\n\n**Login Feature Transaction:**\n```\n[USER ACTION]      User submits credentials\n                     ↓\n[VALIDATION]       Input validation (format, required fields)\n                     ↓\n[SERVICE CALL]     Authentication service calls backend API\n                     ↓\n[API RESPONSE]     Backend returns tokens or error\n                     ↓\n[PERSISTENCE]      Tokens stored in secure storage\n                     ↓\n[COMPLETION]       Feature signals success to parent\n                     ↓\n[PARENT HANDLER]   Parent orchestrator receives completion\n                     ↓\n[STATE CHECK]      Parent checks for pending actions (deep links, redirects)\n                     ↓\n[NAVIGATION]       Route to final destination\n                     ↓\n[RENDER]           Destination view displayed\n                     ↓\n[IDLE]             Application awaits next input [END]\n```\n\n## Validation\n\n### Check 1: Mermaid Syntax Validation\n\n**Method:** Run `npx mmdc -i <file> -o /dev/null` for each diagram\n**On success:** Proceed to Check 2\n**On failure:**\n1. Read error output to identify syntax error\n2. Locate line number in diagram file\n3. Fix syntax according to official Mermaid documentation\n4. Re-run validation\n5. Repeat until passes\n\n**Max retries:** Until success\n\n---\n\n### Check 2: BDD-Flowchart Consistency\n\n**Method:** Compare each BDD scenario against flowchart paths\n**On success:** Proceed to Check 3\n**On failure:**\n1. Identify missing or mismatched scenarios/paths\n2. Return to source code to verify correct behavior\n3. Update BDD or flowchart to match source\n4. Re-validate\n\n---\n\n### Check 3: BDD-Sequence Consistency\n\n**Method:** Compare each BDD scenario against sequence diagram flows\n**On success:** Proceed to Check 4\n**On failure:**\n1. Identify missing or mismatched technical flows\n2. Return to source code to verify implementation\n3. Update sequence diagram to match source\n4. Re-validate\n\n---\n\n### Check 4: Critical Path Integrity\n\n**Method:** Verify critical path coloring follows rules\n**On success:** Proceed to Check 5\n**On failure:**\n1. Identify nodes/blocks incorrectly colored as critical path\n2. Move error handling to appropriate colored sections\n3. Ensure unbroken visual flow on actual critical path\n4. Re-validate\n\n---\n\n### Check 5: Entry Point Coverage\n\n**Method:** Verify all entry points have corresponding BDD scenarios\n**On success:** Proceed to Check 6\n**On failure:**\n1. Identify undocumented entry points\n2. Analyze each entry point's context and behavior\n3. Add BDD scenarios for each unique entry context\n4. Update diagrams to include new paths\n5. Re-validate\n\n---\n\n### Check 6: Final Verification\n\n**Method:** Perform final pass comparing BDD ↔ Flowchart ↔ Sequence Diagram ↔ Source Code\n**On success:** Validation complete\n\n**Verification Checklist:**\n- [ ] No contradictions exist between documents\n- [ ] All business behaviors accurately captured\n- [ ] All technical details accurately documented\n- [ ] Three documents complement each other without duplication or conflict\n- [ ] Critical paths correctly identified in both diagrams\n- [ ] Error paths consistently documented\n- [ ] Both Mermaid diagrams pass CLI syntax validation\n\n**On failure:**\n1. Identify specific contradiction or gap\n2. Return to source code as authoritative reference\n3. Update affected document(s)\n4. Re-run all validation checks from Check 1\n\n## Error Handling\n\n### ERR-001: Evidence File Not Found\n\n**Symptoms:**\n- File path cannot be resolved\n- `[MISSING EVIDENCE: path]` annotation in output\n\n**Possible Causes:**\n1. Path is relative but working directory differs from project root\n2. File was renamed or moved\n3. Typo in file path\n\n**Resolution Steps:**\n1. Verify the file exists in the project\n2. Use Glob tool to search: `**/*filename*`\n3. Check git history for renames: `git log --follow --name-only -- \"*filename*\"`\n4. Update evidence path and retry\n\n---\n\n### ERR-002: Mermaid Syntax Error\n\n**Symptoms:**\n- `npx mmdc` reports parsing error\n- Diagram fails to render\n\n**Resolution Steps:**\n1. Read error output to identify the specific error and line number\n2. Analyze the error message to understand the cause\n3. Locate the problematic line in the diagram file\n4. Fix the syntax error based on the error message context\n5. Re-run `npx mmdc` validation\n6. Repeat until diagram renders without errors\n\n**Reference:** Consult official Mermaid documentation if error is unclear:\n- Flowchart: https://docs.mermaidchart.com/mermaid-oss/syntax/flowchart.html\n- Sequence: https://docs.mermaidchart.com/mermaid-oss/syntax/sequenceDiagram.html\n\n---\n\n### ERR-003: Document Inconsistency\n\n**Symptoms:**\n- BDD scenario has no corresponding flowchart path\n- Sequence diagram shows behavior not in BDD\n- Validation issues flagged\n\n**Resolution Steps:**\n1. Identify the discrepancy\n2. Return to source code as authoritative reference\n3. Determine which document is incorrect\n4. Update incorrect document\n5. Re-validate all checks\n\n---\n\n### ERR-004: Incomplete Transaction Tracing\n\n**Symptoms:**\n- Feature ends prematurely in documentation\n- Cross-cutting concerns not captured\n- Entry points missing\n\n**Resolution Steps:**\n1. Re-trace forward from feature completion\n2. Search for all callers of entry point\n3. Check for deferred operations (timers, async jobs)\n4. Follow navigation until idle state reached\n5. Update all three documents with discovered paths\n\n## References\n\n### External Documentation\n- [Mermaid Flowchart Syntax](https://docs.mermaidchart.com/mermaid-oss/syntax/flowchart.html)\n- [Mermaid Sequence Diagram Syntax](https://docs.mermaidchart.com/mermaid-oss/syntax/sequenceDiagram.html)\n- [OpenAPI 3.1 Specification](https://swagger.io/specification/)\n\n### Annotation Markers\n\n| Marker | Usage |\n|--------|-------|\n| `[REFERENCE: ServiceName]` | External dependency reference |\n| `[MISSING LINK]` | Unresolved external dependency |\n| `[MISSING EVIDENCE: path]` | Evidence file not found |\n| `[DISCOVERY FAILED: reason]` | Autonomous evidence discovery yielded no results |\n| `[UNCLEAR LOGIC]` | Ambiguous behavior in source |\n| `[MISSING BEHAVIOR]` | Incomplete implementation |\n| `[VALIDATION ISSUE]` | Temporary marker during validation |\n| `[API: domain/path]` | API endpoint specification marker |\n| `[API INCOMPLETE: field]` | Missing API documentation (request/response schema, headers, etc.) |\n",
        "aitt/commands/list-features.md": "# Exhaustive Business Feature Inventory for Complex Apps (Mobile, SPA, Stateful Web, Multi-Tier)\n\n## Goal\n\nFrom the full codebase(s)—including **frontends, backends, services, and databases**—produce an **exhaustive, structured list of all business features** implemented.\n**Only list and categorize features** (no descriptions, rules, or UX details). Emphasize **coverage and completeness**.\n\n---\n\n## What counts as a “feature”\n\nA **business feature** is any user- or business-facing capability exposed via **UI, API, background workflow, or data contract** that delivers product value.\n\n### ✅ Include\n\n* User-visible capabilities (e.g., onboarding, auth/SSO, profile, search, content, messaging, notifications).\n* Commercial flows (checkout, subscriptions, billing, invoices, coupons, trials, entitlements).\n* Growth & re-engagement (referrals, invites, rewards, email/SMS/push campaigns, paywalls).\n* Admin/agent/staff consoles and moderation tools.\n* Data rights & compliance (export/delete account, consents, age-gating).\n* Multi-tenancy, roles/permissions, regional/locale variants.\n* Integrations that surface to users (payments, shipping, ID verification, maps, social, support chat).\n* API-only or backend-only business workflows (e.g., order lifecycle, KYC, ticketing) even if not directly surfaced in UI.\n\n### 🚫 Exclude\n\n* Pure infra/library code without a direct business capability (e.g. ORM adapters, DI, logging, generic caching, etc.), unless it **implements** a named product capability (e.g., “In-App Purchases”, “Subscriptions”).\n\n---\n\n## Inputs available\n\n* Source code (frontend/mobile + backend/services), configs, environment templates, migrations, seeders, CI/CD files.\n* Static assets/templates, i18n resources, email/SMS templates, push payloads.\n* API definitions (OpenAPI/Swagger, GraphQL schemas), job/workflow definitions, queue/topic names.\n* Tests (unit/integration/E2E), READMEs, architectural docs found in repos.\n\n**Assume static analysis only** (no live systems).\n\n---\n\n## Discovery strategy (be systematic & exhaustive)\n\n### A. Clients\n\n* **Routing & navigation**\n\n  * Views/screens, navigation structure (stacks/graphs/routes), deep/external linking handlers, home screen widgets/extensions, platform-specific integrations (wearables, automotive, TV).\n* **State & capability markers**\n\n  * Redux/MobX/Zustand/NgRx/Pinia, feature slices/modules.\n  * Feature flag clients (LaunchDarkly, Unleash, custom), A/B framework hooks.\n  * UI text (`i18n`, `strings`, menus), component directories named for product surfaces.\n* **Channels**\n\n  * Push/in-app messaging renderers, notifications center, inbox, banners, tooltips, NPS/rating prompts.\n* **Growth surfaces**\n\n  * Referral screens, invite flows, paywalls/upsells, trials, “rate this app”, sharing.\n\n### B. Backends (PHP, Python, Node.js; monoliths & services)\n\n* **Endpoints & resolvers**\n\n  * REST (controllers/routes/middleware), GraphQL (queries/mutations), RPC/gRPC handlers.\n  * Auth providers (email/phone/OAuth/SSO/SAML), session & token flows; RBAC/ABAC policy files.\n* **Workflows & jobs**\n\n  * Queue/worker systems: Celery/RQ (Python), Bull/BullMQ/Agenda/bee-queue (Node), Laravel Queues (PHP); job names that encode business processes.\n  * Schedulers/CRON, orchestrations (Temporal, Airflow).\n* **Integrations**\n\n  * Payment gateways, tax/VAT, invoicing; IDV/KYC; shipping; maps/geocoding; communications (email/SMS/push); analytics/events.\n* **Growth & compliance**\n\n  * Promo/coupon services, referral services; GDPR/CCPA endpoints (export/delete), consent registries.\n* **Multi-tenancy & regionalization**\n\n  * Tenant resolution, per-tenant configs, regional toggles, entitlement checks.\n\n### C. Data layer (SQL/NoSQL/Graph)\n\n* **Schemas & migrations**\n\n  * Tables/collections/indices whose names imply features (e.g., `subscriptions`, `orders`, `messages`, `rewards`, `consents`, `feature_flags`, `entitlements`).\n* **Events & contracts**\n\n  * Kafka/RabbitMQ/SNS/SQS topics; event types indicating business flows (e.g., `OrderPaid`, `UserVerified`, `TrialStarted`).\n* **Stored procedures / views**\n\n  * Anything implementing business logic (e.g., statements assembling invoices, fraud signals).\n* **Seed data**\n\n  * Default roles, feature toggles, sample plans/tiers.\n\n### D. Cross-cutting signals\n\n* **Feature flags / remote config**\n* **Experiment frameworks** (experiment keys, cohorting).\n* **Access control** (roles, permissions, scopes).\n* **Region/locale/product tier branching** (Pro/Enterprise/Geo).\n\n---\n\n## Deduplication & naming\n\n* Merge duplicates across repos/services/clients; choose **product-facing** names (prefer UI text/menu labels over internal class names).\n* If a capability is gated (flag/plan/region), **keep it** and tag with the gate(s).\n\n---\n\n## Output format\n\n### JSON (authoritative)\n\n```json\n[\n  {\n    \"feature_name\": \"string\",\n    \"category\": \"Acquisition | Account | Discovery | Creation | Consumption | Commerce | Engagement | Support | Admin/Moderation | Platform Integration | Data & Compliance | Roles & Access | Localization & Accessibility | Other\",\n    \"surface\": [\"ClientUI\", \"API\", \"BackgroundJob\", \"Workflow\", \"AdminPanel\", \"Integration\", \"Notification\", \"DataContract\"],\n    \"platform\": [\"<client>\", \"<server>\", \"service:<name>\", \"db\"],\n    \"actors\": [\"Guest\", \"EndUser\", \"Admin\", \"Agent\", \"Moderator\", \"Merchant\", \"Tenant\"],\n    \"channels\": [\"Push\", \"Email\", \"SMS\", \"InApp\", \"Webhook\", \"Widget\"],\n    \"flags_or_variants\": [\"flag:<key>\", \"experiment:<key>\", \"plan:<tier>\", \"region:<code>\", \"tenant:<id>\"],\n    \"evidence\": [\n      \"repo/path/file:LineOrSymbol\",\n      \"route:POST /v1/orders\",\n      \"graphql:mutation createSubscription\",\n      \"migration:2024_10_01_add_subscriptions.sql\",\n      \"queue:orders.created\",\n      \"cron:invoice_generation\"\n    ]\n  }\n]\n```\n\n**Rules:** no descriptions; 1–5 high-signal evidence entries per feature; unique `feature_name`s.\n\n---\n\n## Coverage checklist (must satisfy before finishing)\n\n* [ ] **Frontends:** all routes/pages/screens/components mapped; deep links/app links/web routes included; state slices/modules scanned; i18n/menu labels covered.\n* [ ] **Backends:** all REST/GraphQL endpoints and handlers scanned; background jobs/CRON/workflows enumerated; integrations (payments, IDV, comms, maps) captured.\n* [ ] **Auth/Access:** signup/login/SSO/2FA flows; roles/permissions/scopes; multi-tenant resolution.\n* [ ] **Commerce:** carts/checkout/payments/subscriptions/invoices/refunds/coupons/trials/entitlements.\n* [ ] **Engagement & Growth:** notifications (push/email/SMS/in-app), referrals/invites/rewards, ratings/reviews prompts.\n* [ ] **Data & Compliance:** data export/delete, consents, age gates, regional restrictions.\n* [ ] **Experiments & Flags:** feature flags, remote config keys, experiment IDs; plan/tier/region gates.\n* [ ] **Databases & Events:** business tables/collections, migrations, stored procedures/views, event topics and webhooks.\n* [ ] **Admin/Moderation:** consoles, reports, case management, content moderation.\n* [ ] **Localization & Accessibility:** locales, RTL, a11y toggles.\n* [ ] **Cross-platform parity:** same feature appearing on mobile/web/backend tagged appropriately.\n\n---\n\n## Constraints\n\n* **No feature descriptions** or implementation details.\n* Prefer **product terminology** extracted from UI text, route names, email/SMS templates.\n* If uncertain but plausible, include with `\"category\": \"Other\"` and tag `\"candidate\": true` in `flags_or_variants`.\n\n---\n\n## Deliverables\n\n1. **JSON** file (authoritative feature list).\n2. Final line: `Coverage checklist completed: YES/NO`.\n\n",
        "aitt/commands/manual-test.md": "---\nallowed-tools: Read, Grep, Glob, Bash, TodoWrite, WebFetch, WebSearch\ndescription: \"Analyzes merged commit changes from input and manual tests the related features on production with Playwright MCP using chrome\"\n---\n\n# /manual-test - Manual test change in production\n\n## Purpose\n\nThis command allows you to manually test changes in production with a chrome browser by reading merged commit changes and testing the related features on production using Playwright MCP.\n\n## Usage\n\n```bash\n/manual-test [production_url] [commit_hash]\n```\n\nOr --no-verify to skip the manual test plan confirmation step:\n\n```bash\n/manual-test [production_url] [commit_hash] --no-verify\n```\n\n## What This Command Does\n\n1. Reads and Analyzes the changes to identify the features that need to be tested based on the provided **$commit_hash** changes.\n   - Uses the `git diff` command to get the changes made in the specified commit only.\n   - Identifies the files and functionalities that have been modified or added.\n   - Constructs a list of features that need to be tested based on the commit changes.\n   - Constructs a manual test plan based on the identified features.\n     - You MUST output the test plan in a structured format for the user.\n     - If `--no-verify` is not specified you MUST ask for confirmation or modifications on the plan to proceed with the manual testing.\n2. Run the manual tests on the production URL provided:\n   - Open the specified **$production_url** and follows the test plan created in the first step.\n   - DO NOT write any code or scripts, this is a manual testing process.\n   - Accept cookies and privacy policies if needed.\n   - If in doubt or the application requires authentication (login), stop and ask the user for clarification on how to proceed with the testing otherwise DO NOT wait for user to interact with the browser.\n3. Outputs the results of the manual tests, including any issues, bugs, ux concerns found or confirmations of successful tests in a structured format.\n   - If any issues were found, provide detailed information about the issue, including steps to reproduce, expected vs actual behavior.\n   - If all tests pass, confirm that the features are functioning as expected.\n   - Close the browser after completing the tests.\n   - Clear `.playwright-mcp` directory to ensure no test data is left behind.\n",
        "aitt/commands/summarize-changes.md": "---\nallowed-tools: Read, Grep, Glob, Bash\ndescription: \"This command quickly summarizes current changes using git diff\"\n---\n\n# /summarize-changes - Summarizes current changes using git diff\n\n## Purpose\n\nThis command analyzes the current changes in the git repository using `git diff HEAD` and provides a concise and short summary of the modifications, additions, and deletions. It helps developers quickly understand the scope and impact of their changes before committing.\n\n## Usage\n\n```bash\n/summarize-changes\n```\n\nFor a shorter summary, use:\n\n```bash\n/summarize-changes --short\n```\n\n## What This Command Does\n\n1. Analyzes the changes with `git diff HEAD` to understand what is being changed. Quickly identify:\n   - File types modified (components, tests, docs, config, etc.)\n   - Nature of changes (new features, bug fixes, refactoring, breaking changes etc.)\n   - Scope of impact (single feature, multiple areas, etc.)\n2. Outputs a structured summary of the changes in a commit message style:\n   - The first line MUST be a title of the overall changes.\n   - If `--short` is not specified, use bullet points to organize the changes in a list format under the title and an empty line (max 5 bullet points).\n   - Maximum line length is 72 characters for each line in the summary.\n   - Use present tense, imperative mood.\n   - Be specific but concise.\n   - Prioritize speed - make quick, accurate assessments\n\n## Important Notes\n\n- Do NOT output any explanation on what you are doing, just the final summary.\n- Do NOT ask any further questions, just provide the summary based on the changes.\n- ONLY output the final summary, do NOT include any explanations, questions, next steps or additional text as the output will be used directly as a commit message.\n\nExample Changes Summary Output:\n\n```text\nAdd user authentication module\n\n- Implement login and registration endpoints\n- Add JWT-based authentication\n- Update user model with password hashing\n```\n\nExample Short Changes Summary Output: \"Add user authentication module with login, registration and JWT-based auth\"\n",
        "aitt/commands/update-npm-packages.md": "---\nallowed-tools: Read, Grep, Glob, Bash, TodoWrite, Bash(npx), Bash(npm), Bash(git add .), Bash(git status), Bash(git commit), AskUserQuestion, WebSearch, WebFetch\nargument-hint: '[--target <patch|minor|major>] [--package <name>] [--safe] [--skip <pkg1,pkg2,...>]'\ndescription: 'Continuously updates NPM packages one at a time, verifies each update, and commits them until no more updates are available or user stops the process.'\n---\n\n# /update-npm-packages — Continuously update NPM packages one by one\n\n## Purpose\n\nAutomate your \"one-package-at-a-time\" update flow with minimal risk. **Continuously** selects and applies eligible updates (preferring PATCH, then MINOR, optionally MAJOR), records changelog summaries, runs basic checks, and commits each update automatically. The process continues until no more updates are available or the user interrupts it.\n\n## Usage\n\n/update-npm-packages\n/update-npm-packages --target patch\n/update-npm-packages --target minor\n/update-npm-packages --target major\n/update-npm-packages --package <name>\n/update-npm-packages --safe\n/update-npm-packages --skip react,eslint,chalk\n/update-npm-packages --audit-level high\n/update-npm-packages --safe --audit-level critical\n\n## Flags\n\n--target <patch|minor|major> Specify update level: PATCH (default), MINOR, or MAJOR. Default behavior: patch→minor fallback (no major unless explicitly specified)\n--package <name> Update ONLY this specific package and exit (no loop, no other packages)\n--safe Enable interactive mode - pause before each update for user approval after showing changelog research\n--skip <pkg1,pkg2,...> Comma-separated list of package names to skip (e.g., \"react,eslint,chalk\"). Packages in this list will be excluded from updates\n--audit-level <low|moderate|high|critical> Set the audit severity threshold for blocking updates (default: moderate). Updates introducing vulnerabilities at or above this level will require user approval\n\n## What This Command Does\n\n**This command runs in a LOOP until no more updates are available or the user stops it.**\n\n### Initial Setup (Once per run)\n\n1. **Check git working directory**\n   - Run `git status --porcelain` to check for uncommitted changes\n   - **If working directory is NOT clean** (has uncommitted changes):\n     - Display the current status to the user\n     - Use `AskUserQuestion` to ask: \"Your working directory has uncommitted changes. Would you like to: (1) stash changes and continue, (2) commit changes first, or (3) abort?\"\n     - Responses:\n       - `stash` or `1` - Run `git stash push -m \"Auto-stash before package updates\"` and continue\n       - `commit` or `2` - Stop and ask user to commit manually first\n       - `abort` or `3` - Exit the command immediately\n   - **If working directory is clean**: Proceed to next step\n\n2. **Confirm auto-update mode (only if --safe flag is NOT present)**\n   - **If `--safe` flag is NOT present**: Use `AskUserQuestion` tool to confirm automatic updates\n   - Question: \"This will automatically update packages without manual approval. Continue?\"\n   - Options: `[\"yes\", \"no\"]`\n   - Responses:\n     - `yes` - Proceed with automatic updates\n     - `no` - Exit the command immediately\n   - **If `--safe` flag is present**: Skip this confirmation (user will approve each update individually)\n\n3. **Determine ticket**\n   - Try `.claude/scripts/find-ticket-from-branch.sh` to get ticket ID from branch\n\n### For Each Package (Repeats automatically)\n\n4. **Select ONE eligible update (STEP 1)**\n   - **If `--package` is provided**: Use ONLY that specific package, ignore skip list, ignore target preference\n     - After processing this package, **exit immediately** (do not continue loop)\n     - If the package is not available for update, report this and exit\n   - **Otherwise** (no `--package` flag):\n     - **Apply skip list**: If `--skip` flag is provided, use that comma-separated list (e.g., `react,eslint,chalk`). Use `npx ncu --reject` with the skip list to exclude these packages\n     - **If no `--skip` flag is provided**: No packages are skipped (no default skip list)\n     - **If `--target major` is specified**: Run `npx ncu -t major` (with `--reject` if skip list exists). If none found, **exit loop**: \"All updates completed\"\n     - **If `--target minor` is specified**: Run `npx ncu -t minor` (with `--reject` if skip list exists). If none found, **exit loop**: \"All updates completed\"\n     - **If `--target patch` is specified or no target**: Run `npx ncu -t patch` (with `--reject` if skip list exists). If none found, run `npx ncu -t minor`. If none, **exit loop**: \"All updates completed\"\n     - Choose exactly ONE package per iteration\n\n5. **Quick research (STEP 2, ≤2 minutes)**\n   - Look up the package changelog on npm/GitHub\n   - **Always display** a short summary of key changes to the user (breaking changes, new features, bug fixes)\n   - **Always append** the summary to `package-updates-changelog.md` at repo root (create if missing)\n   - If info is hard to find within ~2 minutes, write/display a brief general note and proceed\n\n6. **User approval (STEP 2a, only with --safe flag)**\n\n- **If `--safe` flag is present**: Display the research findings to the user\n- Show: package name, current version, target version, and changelog summary\n- Use `AskUserQuestion` tool to ask: \"Proceed with this update? (yes/no/skip-all)\"\n- Responses:\n  - `yes` - Continue with this update\n  - `no` - Skip this package and move to next one\n  - `skip-all` - Stop the loop entirely\n- **If `--safe` flag is NOT present**: Skip this step and proceed automatically\n\n7. **Apply the update (STEP 3)**\n   - **Always run**: `npm install <pkg>@<targetVersion>` (e.g., `npm install inquirer@12.6.3`)\n   - No dry-run mode - this command actually applies updates\n\n8. **Verify basics + Security audit (STEP 4)**\n   - **Security audit check**:\n     - Run `npm audit --audit-level=moderate --json` to check for vulnerabilities\n     - Parse the JSON output to count vulnerabilities by severity (critical, high, moderate, low)\n     - **If new critical or high vulnerabilities are introduced** (compare with pre-update baseline if available):\n       - Display the vulnerability details to the user (package name, severity, description)\n       - Use `AskUserQuestion` to ask: \"This update introduces critical/high security vulnerabilities. Would you like to: (1) revert this update, (2) continue anyway, (3) try npm audit fix, or (4) view detailed audit report?\"\n       - Responses:\n         - `revert` or `1` - Revert the update (`git reset --hard HEAD~1 && npm install`) and stop the loop\n         - `continue` or `2` - Proceed with the update despite vulnerabilities (log warning in changelog)\n         - `fix` or `3` - Run `npm audit fix` and re-verify, then ask for confirmation again if issues remain\n         - `report` or `4` - Run `npm audit` (human-readable format) and display full report, then ask again\n     - **If moderate or low vulnerabilities**: Log them in the changelog but continue (non-blocking)\n   - Unless `--no-verify`, run:\n     - `npm install && npx tsc --noEmit` (always, if TypeScript is present)\n     - Conditionally run: `npm run storybook` / `npm run eslint` / `npm run test` / `npm run build` (only if relevant scripts exist in package.json)\n   - **If verification scripts are not available or fail to run**: Use `AskUserQuestion` to ask the user:\n     - \"Verification script(s) not available or failed. Would you like to: (1) skip verification and continue, (2) suggest alternative verification steps, or (3) stop the update process?\"\n   - On errors: attempt quick fixes or **revert** (`git reset --hard HEAD~1 && npm install`) and stop the loop\n\n9. **Commit the update (STEP 5)**\n   - Stage: `git add package.json package-lock.json`\n   - **Auto-commit** with conventional format:\n     `<TICKET> chore: update <package> from <oldVersion> to <newVersion>`\n   - Keep first line ≤72 chars; imperative mood; accurate, concise\n\n10. **Continue to next package**\n   - **If `--package` was specified**: Exit immediately after committing (single package mode)\n   - **Otherwise**: Automatically return to STEP 1 and process the next package\n   - Loop continues until no more updates or user interrupts\n\n## Important Notes\n\n- **Continuous operation**: Processes ALL available updates automatically, one package at a time (unless `--package` is specified)\n- **Single package mode**: Use `--package <name>` to update only one specific package and exit immediately\n- **Prefer PATCH over MINOR**: Default behavior checks patch updates first; only moves to minor if no patches available (unless specific `--target` is used)\n- **MAJOR version updates**: Use `--target major` to explicitly enable MAJOR version updates. By default, MAJOR updates are NOT processed due to potential breaking changes\n- **Custom skip list**: Use `--skip pkg1,pkg2,pkg3` to exclude specific packages from updates. No default skip list (unless `--package` is used - then skip list is ignored)\n- **Security audit**: Each update is automatically checked for security vulnerabilities using `npm audit`. Critical/high vulnerabilities require user approval before proceeding\n- **Audit level control**: Use `--audit-level <low|moderate|high|critical>` to set the severity threshold for blocking updates (default: moderate)\n- **Auto-commit each update**: Every successful update gets its own commit immediately\n- **Follow conventional commits**: Format is `TICKET chore: update <package> from <old> to <new>`\n- **Stop on errors**: If verification fails, revert the update and stop the loop (don't continue to next package)\n- **User can interrupt**: Press Ctrl+C or stop the command at any time to halt the process\n- **Automatic changelog tracking**: All update summaries are automatically written to `package-updates-changelog.md`, including any security vulnerability notes\n- **Safe mode**: Use `--safe` flag for interactive approval before each update - ideal for teams that want manual review\n",
        "aitt/commands/write-unit-tests.md": "---\nallowed-tools: Read, Grep, Glob, Bash, TodoWrite\ndescription: \"Write unit and integration tests for new or existing code\"\n---\n\n# /write-unit-tests - Write unit and integration tests\n\n## Purpose\n\nGenerate unit and integration tests for newly added code or specified existing file to ensure functionality and reliability.\n\n## Usage\n\nFor newly added code:\n\n```bash\n/write-unit-tests\n```\n\nOr for exisiting file:\n\n```bash\n/write-unit-tests [file_to_test]\n```\n\n## Execution\n\n1. **Test Framework Detection**\n\n   - Identify the testing framework in use (Jest, Vitest, Mocha, PyTest, RSpec, etc.)\n   - Review existing test structure and conventions\n   - Check test configuration files and setup\n   - Understand project-specific testing patterns\n\n2. **Code Analysis for Testing**\n\n   - If `[file_to_test]` is provided, analyze the specified file for testing.\n   - If `[file_to_test]` is NOT provided, identify the newly added code by comparing the current branch with the development branch\n     - Checks which files are staged with `git status`\n     - If 0 files are staged, automatically adds all modified and new files with `git add`\n     - Use `git diff` to analyze changes, compare to master/main or branch name given from arguments: **$ARGUMENTS**\n   - Analyze the code that needs testing, ONLY create tests for newly added code or `[file_to_test]` if provided.\n   - Identify public interfaces and critical business logic\n   - Map out dependencies and external interactions\n   - Understand error conditions and edge cases\n\n3. **Test Strategy Planning**\n\n   - Determine test levels needed:\n     - Unit tests for individual functions/methods\n     - Integration tests for component interactions\n   - Plan test coverage goals and priorities\n   - Identify mock and stub requirements\n\n4. **Unit Test Implementation**\n\n   - Test individual functions and methods in isolation\n   - Cover happy path scenarios first\n   - Test edge cases and boundary conditions\n   - Test error conditions and exception handling\n   - Use proper assertions and expectations\n\n5. **Test Structure and Organization**\n\n   - Follow the AAA pattern (Arrange, Act, Assert)\n   - Use descriptive test names that explain the scenario\n   - Group related tests using test suites/describe blocks\n   - Keep tests focused and atomic\n\n6. **Mocking and Stubbing**\n\n   - Mock external dependencies and services\n   - Stub complex operations for unit tests\n   - Use proper isolation for reliable tests\n   - Avoid over-mocking that makes tests brittle\n\n7. **Data Setup and Teardown**\n\n   - Create test fixtures and sample data\n   - Set up and tear down test environments cleanly\n   - Use factories or builders for complex test data\n   - Ensure tests don't interfere with each other\n\n8. **Integration Test Writing**\n\n   - Test component interactions and data flow\n   - Test API endpoints with various scenarios\n   - Test database operations and transactions\n   - Test external service integrations\n\n9. **Error and Exception Testing**\n\n   - Test all error conditions and exception paths\n   - Verify proper error messages and codes\n   - Test error recovery and fallback mechanisms\n   - Test validation and security scenarios\n\n10. **Security Testing**\n\n    - Test authentication and authorization\n    - Test input validation and sanitization\n    - Test for common security vulnerabilities\n    - Test access control and permissions\n\n11. **Test Utilities and Helpers**\n    - Create reusable test utilities and helpers\n    - Build test data factories and builders\n    - Create custom matchers and assertions\n    - Set up common test setup and teardown functions\n\n## Output and Important Notes\n\n- The output is a set of unit and integration tests formatted for the appropriate testing framework.\n- Include comments where necessary to explain complex logic or edge cases.\n- Make sure every function or component has corresponding tests.\n- DO NOT modify, update, or refactor any implementation (non-test) code under any circumstances.\n- If a test is failing due to a mismatch with the implementation, update ONLY the test code to accurately reflect the current implementation, unless explicitly instructed otherwise.\n- If you believe the implementation is incorrect, DO NOT change it; instead, leave a comment in the test file describing the suspected issue for human review.\n- Run linter and formatter on the test files to ensure they adhere to the project's coding standards.\n- After linter issue fixes rerun the tests to ensure they still pass, fix any issues that arise after the linter changes. DO NOT stop fixing until all tests pass.\n",
        "rgw/.claude-plugin/plugin.json": "{\n  \"name\": \"rgw\",\n  \"version\": \"1.0.11\",\n  \"description\": \"Requirement Gathering Workflow - A structured workflow for gathering requirements, generating tasks, and executing them systematically\",\n  \"author\": {\n    \"name\": \"Byborg\"\n  },\n  \"homepage\": \"https://github.com/ByborgAI/prompt-collection/tree/main/rgw\",\n  \"repository\": \"https://github.com/ByborgAI/prompt-collection\",\n  \"license\": \"MIT\",\n  \"keywords\": [\"requirements\", \"workflow\", \"planning\", \"task-management\", \"project-management\"]\n}\n",
        "rgw/README.md": "# RGW - Requirement Gathering Workflow\n\nA structured workflow plugin for Claude Code that systematically gathers requirements, generates tasks, and executes them with automated tracking.\n\n## Prerequisites\n\nInstall required dependencies:\n```bash\n# macOS\nbrew install jq yq git\n\n# Ubuntu/Debian\nsudo apt-get install jq yq git\n\n# Other systems - install via package manager:\n# - jq: JSON processor\n# - yq: YAML processor\n# - git: Version control\n```\n\n## Installation\n\nInstall the plugin via Claude Code:\n```bash\n/plugin marketplace add ByborgAI/prompt-collection\n/plugin install rgw@prompt-collection\n```\n\n## Commands\n\n### `/rgw:plan [description]`\n**Capability:** Interactive requirement gathering and task generation\n- Asks clarifying questions about your project\n- Creates `requirements.yaml` with structured specifications\n- Generates `task-*.yaml` files for systematic execution\n- Supports replanning to update existing requirements\n\n**Usage:**\n```bash\n/rgw:plan create a React dashboard with user authentication\n```\n\n### `/rgw:execute [task-file]`\n**Capability:** Systematic task execution with automated commits\n- Executes all tasks sequentially (no argument)\n- Executes specific task (with task file argument)\n- Tracks file changes automatically\n- Auto-commits on task completion\n- Enforces review before marking tasks done\n\n**Usage:**\n```bash\n/rgw:execute              # Execute all tasks\n/rgw:execute task-001.yaml  # Execute specific task\n```\n\n## Workflow\n\n1. **Plan** → Creates requirements and tasks\n2. **Execute** → Implements tasks with tracking\n3. **Review** → User approves changes\n4. **Commit** → Auto-commits on completion\n\n## Task Status Flow\n`to do` → `in progress` → `under review` → `done`\n\n## Features\n- ✅ Structured requirement gathering\n- ✅ Automatic task breakdown\n- ✅ Status tracking and enforcement\n- ✅ File change tracking\n- ✅ Automated git commits\n- ✅ Single task at a time enforcement\n- ✅ Replan capability for requirement updates\n\n## Files Created\n- `requirements.yaml` - Project requirements\n- `task-*.yaml` - Individual task files\n- Modified code files tracked in tasks\n\n## Tips\n- Add to `.gitignore`: `task-*.yaml` and `requirements.yaml`\n- Review changes before approving tasks\n- Use single task execution for large projects\n- Tasks auto-commit with proper messages\n\n## Quick Start\n```bash\n# 1. Install dependencies\nbrew install jq yq\n\n# 2. Install plugin\n/plugin install rgw@prompt-collection\n\n# 3. Plan your project\n/rgw:plan build a todo app\n\n# 4. Execute tasks\n/rgw:execute\n```",
        "rgw/agents/task-executor.md": "---\nname: Task executor\ndescription: Use this agent when writing code and tests for a single task\npermissionMode: acceptEdits\n---\n\n## Variables\n- `WorkflowTaskSyntax`: `${CLAUDE_PLUGIN_ROOT}/context/syntaxes/task-syntax.md`\n- `WorkflowCodingStandards`: `${CLAUDE_PLUGIN_ROOT}/context/standards/coding-standards.md`\n\n## Workflow\n- Read and follow task syntax schema defined in <WorkflowTaskSyntax>\n- Make sure all prerequsites are met\n- Read and strictly follow coding standards defined in the project\n\n",
        "rgw/commands/execute.md": "---\ndescription: Executes the previously created tasklist.\n---\n\n## Variables\n- `WorkflowTaskExecution`: `${CLAUDE_PLUGIN_ROOT}/context/workflow/task-execution.md`\n\n## Workflow\n- follow the task execution workflow as described in <WorkflowTaskExecution>\n- tell the user in a clearly visible way, that you understand and are following this workflow, and list all the arguments received\n- IF an argument was received, read $1 and execute strictly following the execution workflow\n- IF no arguments were given, list all tasks (`task-XXX.yaml` files, relative to project root), and their statuses.\n  - if there are no tasks found, stop here and suggest the User to plan first.\n  - execute each task sequentially strictly following the execution workflow\n",
        "rgw/commands/plan.md": "---\ndescription: Based on user defined requirements gather questions to clarify.\nmodel: claude-opus-4-5\n---\n\n## Variables\n\n### Requirement Gathering Variables\n- `WorkflowRequirementGathering`: `${CLAUDE_PLUGIN_ROOT}/context/workflow/requirement-gathering.md`\n- `CommunicationStandards`: `${CLAUDE_PLUGIN_ROOT}/context/standards/communication-standards.md`\n- `RequirementsSyntax`: `${CLAUDE_PLUGIN_ROOT}/context/syntaxes/requirements-syntax.md`\n\n### Task Generation Variables\n- `WorkflowTaskGeneration`: `${CLAUDE_PLUGIN_ROOT}/context/workflow/task-generation.md`\n- `TaskSyntax`: `${CLAUDE_PLUGIN_ROOT}/context/syntaxes/task-syntax.md`\n- `CodingStandards`: `${CLAUDE_PLUGIN_ROOT}/context/standards/coding-standards.md`\n\n### Replan Variables\n- `WorkflowReplan`: `${CLAUDE_PLUGIN_ROOT}/context/workflow/replan.md`\n\n## Workflow\n\n### Phase 1: Prerequisites Check\n- Tell the user in a clearly visible way, that you understand and are following this workflow.\n- Check if `requirements.yaml` exists in the project root using a simple bash command, do not read it's content yet.\n- If `requirements.yaml` EXISTS:\n  - Use the AskUserQuestion tool to present these options:\n    - **Option 1: Fresh Plan** - Create a new plan from scratch (will delete existing requirements.yaml and all task-*.yaml files)\n    - **Option 2: Replan** - Update existing requirements by reviewing and adding new aspects (will regenerate all task files based on updated requirements)\n  - Based on user's choice:\n    - If **Fresh Plan**: Delete `requirements.yaml` and all `task-*.yaml` files, then proceed with normal planning\n    - If **Replan**:\n      - Follow the REPLAN workflow as defined in <WorkflowReplan>\n- If `requirements.yaml` DOES NOT EXIST:\n  - Proceed with normal planning workflow\n\n### Phase 2: Planning Process\n- Wait for the User to ask a question or give you an instruction!\n- If this is a FRESH PLAN or NO EXISTING requirements:\n  - Start by gathering requirements, as defined in <WorkflowRequirementGathering>\n  - Once all requirements are gathered, present a summary to the user\n  - **IMPORTANT**: Request explicit approval from user on the requirements gathered\n  - If user approves, update `requirements.yaml` (in project root) to represent the latest requirement-gathering state\n  - **STOP HERE** - Do NOT proceed to Phase 3 automatically\n- If this is a REPLAN:\n  - Follow the replan workflow as defined in <WorkflowReplan>\n  - Iterate through existing requirements and gather additional/modified requirements\n  - Once replanning is complete, present the updated requirements to the user\n  - **IMPORTANT**: Request explicit approval from user on the updated requirements\n  - If user approves, delete ALL existing `task-*.yaml` files and update `requirements.yaml` with the enhanced requirements\n  - **STOP HERE** - Do NOT proceed to Phase 3 automatically\n\n### Phase 3: Task Generation (User Approval Required)\n- **IMPORTANT**: This phase requires explicit user permission. Ask: \"Requirements gathering is complete. Would you like me to proceed with generating the task list?\"\n- Only proceed if the user explicitly approves task generation\n- Create a list of tasks, as defined in <WorkflowTaskGeneration>\n- After the task list is generated, your work is done. DO NOT start working on the tasks!",
        "rgw/hooks/hooks.json": "{\n  \"hooks\": {\n    \"SessionStart\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"${CLAUDE_PLUGIN_ROOT}/hooks/session-start.sh\"\n          }\n        ]\n      }\n    ],\n    \"PreToolUse\": [\n      {\n        \"matcher\": \"Write|Edit|mcp__serena__create_text_file|mcp__serena__replace_regex|mcp__serena__replace_symbol_body|mcp__serena__insert_after_symbol|mcp__serena__insert_before_symbol\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"${CLAUDE_PLUGIN_ROOT}/hooks/pre-tool-use.sh\"\n          }\n        ]\n      }\n    ],\n    \"PostToolUse\": [\n      {\n        \"matcher\": \"Write|Edit|mcp__serena__create_text_file|mcp__serena__replace_regex|mcp__serena__replace_symbol_body|mcp__serena__insert_after_symbol|mcp__serena__insert_before_symbol\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"${CLAUDE_PLUGIN_ROOT}/hooks/post-tool-use.sh\"\n          }\n        ]\n      }\n    ]\n  }\n}\n",
        "rgw/hooks/lib/logger.sh": "#!/usr/bin/env bash\n# ============================================================================\n# Hook Logger Library\n# ============================================================================\n# This library provides JSONL logging functionality for all hooks.\n# Each hook script logs its output to a separate JSONL file.\n# ============================================================================\n\n# Get the directory where hook logs should be stored\nget_log_dir() {\n    # Use .rgw-logs directory in the project root\n    echo \"${PWD}/.rgw-logs\"\n}\n\n# Initialize logging for a hook\ninit_logging() {\n    local log_dir=$(get_log_dir)\n    mkdir -p \"$log_dir\"\n}\n\n# Log the output that a hook is about to return\n# Usage: log_hook_output \"hook-name\" \"output-string\"\nlog_hook_output() {\n    local hook_name=\"$1\"\n    local output=\"$2\"\n\n    local log_dir=$(get_log_dir)\n    local log_file=\"${log_dir}/${hook_name}.jsonl\"\n\n    # Create log directory if it doesn't exist\n    mkdir -p \"$log_dir\"\n\n    # Create JSONL entry with timestamp, hook name, and output\n    local timestamp=$(date -u +\"%Y-%m-%dT%H:%M:%S.%3NZ\" 2>/dev/null || date -u +\"%Y-%m-%dT%H:%M:%SZ\")\n\n    # Escape the output for JSON (handle quotes, newlines, etc.)\n    local escaped_output=$(echo \"$output\" | python3 -c '\nimport sys\nimport json\ncontent = sys.stdin.read()\nprint(json.dumps(content)[1:-1])  # Remove outer quotes added by json.dumps\n' 2>/dev/null || echo \"$output\" | sed 's/\\\\/\\\\\\\\/g; s/\"/\\\\\"/g; s/$/\\\\n/' | tr -d '\\n' | sed 's/\\\\n$//')\n\n    # Append JSONL entry to the log file\n    echo \"{\\\"timestamp\\\":\\\"$timestamp\\\",\\\"hook\\\":\\\"$hook_name\\\",\\\"output\\\":\\\"$escaped_output\\\"}\" >> \"$log_file\"\n}\n\n# Check if JSON output contains a block reason and echo to stderr if present\n# Usage: check_and_echo_block_reason \"json-output-string\"\ncheck_and_echo_block_reason() {\n    local output=\"$1\"\n\n    # Check for \"permissionDecision\": \"deny\" (pre-tool-use hook format)\n    if command -v jq &> /dev/null; then\n        # Use jq for reliable JSON parsing\n        if echo \"$output\" | jq -e '.permissionDecision == \"deny\"' >/dev/null 2>&1; then\n            local reason=$(echo \"$output\" | jq -r '.permissionDecisionReason // empty' 2>/dev/null)\n            if [[ -n \"$reason\" ]]; then\n                echo \"$reason\" >&2\n            fi\n            return 0\n        fi\n\n        # Check for \"decision\": \"block\" (post-tool-use hook format)\n        if echo \"$output\" | jq -e '.decision == \"block\"' >/dev/null 2>&1; then\n            local context=$(echo \"$output\" | jq -r '.hookSpecificOutput.additionalContext // empty' 2>/dev/null)\n            if [[ -n \"$context\" ]]; then\n                echo \"$context\" >&2\n            fi\n            return 0\n        fi\n    else\n        # Fallback to grep/sed if jq not available (legacy support)\n        if echo \"$output\" | grep -q '\"permissionDecision\"[[:space:]]*:[[:space:]]*\"deny\"'; then\n            local reason=$(echo \"$output\" | grep -o '\"permissionDecisionReason\"[[:space:]]*:[[:space:]]*\"[^\"]*\"' | sed 's/\"permissionDecisionReason\"[[:space:]]*:[[:space:]]*\"\\(.*\\)\"/\\1/')\n            if [[ -n \"$reason\" ]]; then\n                echo \"$reason\" >&2\n            fi\n            return 0\n        fi\n\n        if echo \"$output\" | grep -q '\"decision\"[[:space:]]*:[[:space:]]*\"block\"'; then\n            local context=$(echo \"$output\" | grep -o '\"additionalContext\"[[:space:]]*:[[:space:]]*\"[^\"]*\"' | sed 's/\"additionalContext\"[[:space:]]*:[[:space:]]*\"\\(.*\\)\"/\\1/')\n            if [[ -n \"$context\" ]]; then\n                echo \"$context\" >&2\n            fi\n            return 0\n        fi\n    fi\n\n    return 1\n}\n",
        "rgw/hooks/post-tool-use.sh": "#!/usr/bin/env bash\nset -euo pipefail\n\n# ============================================================================\n# Load Logger Library\n# ============================================================================\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\nsource \"${SCRIPT_DIR}/lib/logger.sh\"\n\n# ============================================================================\n# PART -1: Check if required commands are installed\n# ============================================================================\n\nif ! command -v yq &> /dev/null; then\n    output=$(cat <<'EOF'\n{\n  \"decision\": \"block\",\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"PostToolUse\",\n    \"additionalContext\": \"yq is not installed. Install it to enable hook functionality.\\n  macOS: brew install yq\\n  Linux: https://github.com/mikefarah/yq#install\"\n  }\n}\nEOF\n)\n    log_hook_output \"post-tool-use\" \"$output\"\n    check_and_echo_block_reason \"$output\"\n    echo \"$output\"\n    exit 1\nfi\n\nif ! command -v node &> /dev/null; then\n    output=$(cat <<'EOF'\n{\n  \"decision\": \"block\",\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"PostToolUse\",\n    \"additionalContext\": \"Node.js is not installed. Install it to enable hook functionality.\\n  macOS: brew install node\\n  Linux: https://nodejs.org/en/download/package-manager\"\n  }\n}\nEOF\n)\n    log_hook_output \"post-tool-use\" \"$output\"\n    check_and_echo_block_reason \"$output\"\n    echo \"$output\"\n    exit 1\nfi\n\nif ! command -v npx &> /dev/null; then\n    output=$(cat <<'EOF'\n{\n  \"decision\": \"block\",\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"PostToolUse\",\n    \"additionalContext\": \"npx is not installed. Install it to enable hook functionality.\\n  npm install -g npx\"\n  }\n}\nEOF\n)\n    log_hook_output \"post-tool-use\" \"$output\"\n    check_and_echo_block_reason \"$output\"\n    echo \"$output\"\n    exit 1\nfi\n\n# Determine which JSON command to use (prefer installed json, fallback to npx)\nif command -v json &> /dev/null; then\n    JSON_CMD=\"json\"\nelse\n    JSON_CMD=\"npx -y json\"\nfi\n\n# Read JSON input\njson=$(cat)\n\n# Extract file path and tool name\n# For Write/Edit tools, the file path is in tool_response.filePath\n# For Serena MCP tools, we need to get it from the tool_input.relative_path\nfile_path=$(echo \"$json\" | $JSON_CMD tool_response.filePath 2>/dev/null || echo \"\")\nif [[ -z \"$file_path\" ]]; then\n    file_path=$(echo \"$json\" | $JSON_CMD tool_input.relative_path 2>/dev/null || echo \"\")\nfi\ntool_name=$(echo \"$json\" | $JSON_CMD tool_name 2>/dev/null || echo \"\")\n\n# ============================================================================\n# PART 0: Track Changed Files in In-Progress Task\n# ============================================================================\n\nif [[ -n \"$file_path\" ]]; then\n    # Skip tracking task yaml files and requirements.yaml\n    filename=$(basename \"$file_path\")\n    if [[ \"$filename\" =~ ^task-.*\\.ya?ml$ ]] || [[ \"$filename\" == \"requirements.yaml\" ]]; then\n        # Don't track these files\n        :\n    else\n        # Find the task file with \"status: in progress\"\n        in_progress_task=\"\"\n        for task_file in task-*.yaml task-*.yml; do\n            if [[ -f \"$task_file\" ]]; then\n                # Check if task has \"in progress\" status using yq\n                task_status=$(yq -r '.status // \"\"' \"$task_file\" 2>/dev/null || echo \"\")\n                # Remove quotes if present\n                if [[ \"$task_status\" =~ ^[\\\"\\'](.*)[\\\"\\']$ ]]; then\n                    task_status=\"${BASH_REMATCH[1]}\"\n                fi\n\n                if [[ \"$task_status\" == \"in progress\" ]]; then\n                    in_progress_task=\"$task_file\"\n                    break\n                fi\n            fi\n        done\n\n        # If we found an in-progress task, add the file to changed_files if not already there\n        if [[ -n \"$in_progress_task\" ]]; then\n            # Check if file is already in changed_files array\n            file_exists=$(yq -r \".changed_files // [] | map(select(. == \\\"$file_path\\\")) | length\" \"$in_progress_task\" 2>/dev/null || echo \"0\")\n\n            if [[ \"$file_exists\" == \"0\" ]]; then\n                # Add file to changed_files array\n                yq -i \".changed_files += [\\\"$file_path\\\"]\" \"$in_progress_task\"\n            fi\n        fi\n    fi\nfi\n\n# ============================================================================\n# PART 1: Verify Requirements\n# ============================================================================\n\nif [[ -n \"$file_path\" ]] && [[ \"$file_path\" == *\"requirements.yaml\" ]]; then\n    if [[ -f \"$file_path\" ]]; then\n        if yq -e '.complete == true' \"$file_path\" >/dev/null 2>&1; then\n            # Step 1: Get full Claude output\n            claude_output=$(claude -p \"read and execute ${CLAUDE_PLUGIN_ROOT}/context/verify-requirements.md\")\n\n            # Step 2: Extract YAML from output, removing any markdown code fences\n            yaml=$(echo \"$claude_output\" | awk '/^passed:/{flag=1} flag' | sed '/^```/d')\n\n            passed=$(echo \"$yaml\" | yq -r '.passed')\n            remarks=$(echo \"$yaml\" | yq -r '.remarks[]?')\n\n            if [[ \"$passed\" == \"false\" ]]; then\n                # Use jq to properly construct JSON with escaped content\n                output=$(jq -n \\\n                    --arg remarks \"$remarks\" \\\n                    --arg claude_output \"$claude_output\" \\\n                    '{\n                        decision: \"block\",\n                        hookSpecificOutput: {\n                            hookEventName: \"PostToolUse\",\n                            additionalContext: (\"Requirements verification failed and needs fixing with the following reasons:\\n\" + $remarks + \"\\n\\nFull verification output:\\n\" + $claude_output)\n                        }\n                    }')\n                log_hook_output \"post-tool-use\" \"$output\"\n                check_and_echo_block_reason \"$output\"\n                echo \"$output\"\n                exit 1\n            else\n                # Log successful verification\n                success_output=$(cat <<EOF\n{\n  \"decision\": \"allow\",\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"PostToolUse\",\n    \"additionalContext\": \"Requirements verification passed successfully\"\n  }\n}\nEOF\n)\n                log_hook_output \"post-tool-use\" \"$success_output\"\n            fi\n        fi\n    fi\nfi\n\n# ============================================================================\n# PART 2: Verify Task Creation\n# ============================================================================\n\nif [[ -n \"$file_path\" ]] && [[ \"$file_path\" =~ task-[0-9]+\\.yaml$ ]]; then\n    # Only verify when the task file is created (Write or mcp__serena__create_text_file tool used)\n    if [[ \"$tool_name\" == \"Write\" || \"$tool_name\" == \"mcp__serena__create_text_file\" ]] && [[ -f \"$file_path\" ]]; then\n        # Step 1: Get full Claude output\n        claude_output=$(claude -p \"read task described in $file_path and execute ${CLAUDE_PLUGIN_ROOT}/context/verify-task.md\")\n\n        # Step 2: Extract YAML from output, removing any markdown code fences\n        yaml=$(echo \"$claude_output\" | awk '/^passed:/{flag=1} flag' | sed '/^```/d')\n\n        passed=$(echo \"$yaml\" | yq -r '.passed')\n        remarks=$(echo \"$yaml\" | yq -r '.remarks[]?')\n        if [[ \"$passed\" == \"false\" ]]; then\n            # Use jq to properly construct JSON with escaped content\n            output=$(jq -n \\\n                --arg remarks \"$remarks\" \\\n                --arg claude_output \"$claude_output\" \\\n                '{\n                    decision: \"block\",\n                    hookSpecificOutput: {\n                        hookEventName: \"PostToolUse\",\n                        additionalContext: (\"Task verification failed and needs fixing with the following reasons:\\n\" + $remarks + \"\\n\\nFull verification output:\\n\" + $claude_output)\n                    }\n                }')\n            log_hook_output \"post-tool-use\" \"$output\"\n            check_and_echo_block_reason \"$output\"\n            echo \"$output\"\n            exit 1\n        else\n            # Log successful verification\n            task_name=$(basename \"$file_path\")\n            success_output=$(cat <<EOF\n{\n  \"decision\": \"allow\",\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"PostToolUse\",\n    \"additionalContext\": \"Task verification passed successfully for $task_name\"\n  }\n}\nEOF\n)\n            log_hook_output \"post-tool-use\" \"$success_output\"\n        fi\n    fi\nfi\n\n# ============================================================================\n# PART 3: Verify Content\n# ============================================================================\n\nif [[ -n \"$file_path\" ]]; then\n    extension=\"${file_path##*.}\"\n\n    if [[ \"$extension\" == \"yaml\" || \"$extension\" == \"yml\" ]]; then\n        commands=(\n            \"yq eval .\"\n        )\n    else\n        exit 0\n    fi\n\n    for cmd in \"${commands[@]}\"; do\n        # Use timeout if available, otherwise run directly\n        if command -v timeout &> /dev/null; then\n            if ! timeout 30 $cmd \"$file_path\" 1>&2; then\n                # Use jq to properly construct JSON with escaped content\n                output=$(jq -n \\\n                    --arg cmd \"$cmd\" \\\n                    --arg file_path \"$file_path\" \\\n                    '{\n                        decision: \"block\",\n                        hookSpecificOutput: {\n                            hookEventName: \"PostToolUse\",\n                            additionalContext: (\"Command failed: \" + $cmd + \" for \" + $file_path)\n                        }\n                    }')\n                log_hook_output \"post-tool-use\" \"$output\"\n                check_and_echo_block_reason \"$output\"\n                echo \"$output\"\n                exit 1\n            fi\n        fi\n    done\nfi\n\n# All checks passed - log successful execution with no blocking output\nlog_hook_output \"post-tool-use\" \"\"\nexit 0\n",
        "rgw/hooks/pre-tool-use.sh": "#!/usr/bin/env bash\nset -euo pipefail\n\n# ============================================================================\n# Load Logger Library\n# ============================================================================\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\nsource \"${SCRIPT_DIR}/lib/logger.sh\"\n\n# ============================================================================\n# PART -1: Check if required commands are installed\n# ============================================================================\n\nif ! command -v yq &> /dev/null; then\n    output=$(cat <<'EOF'\n{\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"PreToolUse\",\n    \"permissionDecision\": \"deny\",\n    \"permissionDecisionReason\": \"yq is not installed. Install it to enable hook functionality.\\n  macOS: brew install yq\\n  Linux: https://github.com/mikefarah/yq#install\"\n  }\n}\nEOF\n)\n    log_hook_output \"pre-tool-use\" \"$output\"\n    check_and_echo_block_reason \"$output\"\n    echo \"$output\"\n    exit 1\nfi\n\nif ! command -v node &> /dev/null; then\n    output=$(cat <<'EOF'\n{\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"PreToolUse\",\n    \"permissionDecision\": \"deny\",\n    \"permissionDecisionReason\": \"Node.js is not installed. Install it to enable hook functionality.\\n  macOS: brew install node\\n  Linux: https://nodejs.org/en/download/package-manager\"\n  }\n}\nEOF\n)\n    log_hook_output \"pre-tool-use\" \"$output\"\n    check_and_echo_block_reason \"$output\"\n    echo \"$output\"\n    exit 1\nfi\n\nif ! command -v npx &> /dev/null; then\n    output=$(cat <<'EOF'\n{\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"PreToolUse\",\n    \"permissionDecision\": \"deny\",\n    \"permissionDecisionReason\": \"npx is not installed. Install it to enable hook functionality.\\n  npm install -g npx\"\n  }\n}\nEOF\n)\n    log_hook_output \"pre-tool-use\" \"$output\"\n    check_and_echo_block_reason \"$output\"\n    echo \"$output\"\n    exit 1\nfi\n\n# Determine which JSON command to use (prefer installed json, fallback to npx)\nif command -v json &> /dev/null; then\n    JSON_CMD=\"json\"\nelse\n    JSON_CMD=\"npx -y json\"\nfi\n\n# Read JSON input\njson=$(cat)\n\n# Extract file path (try both file_path and relative_path for Serena MCP tools)\nfile_path=$(echo \"$json\" | $JSON_CMD tool_input.file_path 2>/dev/null || echo \"\")\nif [[ -z \"$file_path\" ]]; then\n    file_path=$(echo \"$json\" | $JSON_CMD tool_input.relative_path 2>/dev/null || echo \"\")\nfi\n\n# ============================================================================\n# PART 2: Verify Task\n# ============================================================================\n\nif [[ \"$file_path\" =~ task-[0-9]+\\.yaml$ ]]; then\n    if [[ -f \"$file_path\" ]]; then\n        # Extract old and new status from the hook JSON\n        old_string=$(echo \"$json\" | $JSON_CMD tool_input.old_string 2>/dev/null || echo \"\")\n        new_string=$(echo \"$json\" | $JSON_CMD tool_input.new_string 2>/dev/null || echo \"\")\n\n        current_status=\"\"\n        new_status=\"\"\n        old_has_status=false\n        new_has_status=false\n\n        # Parse status from old_string (format: \"status: <value>\" or \"status: \\\"<value>\\\"\" or \"status: '<value>'\")\n        # Use grep to extract just the status line, handling multiline strings\n        # Use grep -m 1 to only get the first match in case of multiline content\n        if status_line=$(echo \"$old_string\" | grep -m 1 -E '^status:[[:space:]]*'); then\n            # Match quoted or unquoted status values (including multi-word statuses)\n            if [[ \"$status_line\" =~ ^status:[[:space:]]*\\\"([^\\\"]+)\\\" ]]; then\n                current_status=\"${BASH_REMATCH[1]}\"\n                old_has_status=true\n            elif [[ \"$status_line\" =~ ^status:[[:space:]]*\\'([^\\']+)\\' ]]; then\n                current_status=\"${BASH_REMATCH[1]}\"\n                old_has_status=true\n            elif [[ \"$status_line\" =~ ^status:[[:space:]]*(.+)$ ]]; then\n                # For unquoted values, capture everything after \"status:\" until end of line\n                current_status=$(echo \"${BASH_REMATCH[1]}\" | sed 's/[[:space:]]*$//')\n                old_has_status=true\n            fi\n        fi\n\n        # Parse status from new_string (format: \"status: <value>\" or \"status: \\\"<value>\\\"\" or \"status: '<value>'\")\n        # Use grep to extract just the status line, handling multiline strings\n        # Use grep -m 1 to only get the first match in case of multiline content\n        if status_line=$(echo \"$new_string\" | grep -m 1 -E '^status:[[:space:]]*'); then\n            # Match quoted or unquoted status values (including multi-word statuses)\n            if [[ \"$status_line\" =~ ^status:[[:space:]]*\\\"([^\\\"]+)\\\" ]]; then\n                new_status=\"${BASH_REMATCH[1]}\"\n                new_has_status=true\n            elif [[ \"$status_line\" =~ ^status:[[:space:]]*\\'([^\\']+)\\' ]]; then\n                new_status=\"${BASH_REMATCH[1]}\"\n                new_has_status=true\n            elif [[ \"$status_line\" =~ ^status:[[:space:]]*(.+)$ ]]; then\n                # For unquoted values, capture everything after \"status:\" until end of line\n                new_status=$(echo \"${BASH_REMATCH[1]}\" | sed 's/[[:space:]]*$//')\n                new_has_status=true\n            fi\n        fi\n\n        # Check for status field removal\n        if [[ \"$old_has_status\" == true && \"$new_has_status\" == false ]]; then\n            output=$(cat <<'EOF'\n{\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"PreToolUse\",\n    \"permissionDecision\": \"deny\",\n    \"permissionDecisionReason\": \"Removal of status field is not allowed\"\n  }\n}\nEOF\n)\n            log_hook_output \"pre-tool-use\" \"$output\"\n            check_and_echo_block_reason \"$output\"\n            echo \"$output\"\n            exit 1\n        fi\n\n        # Define valid transitions\n        # Check if transition is valid\n        if [[ -n \"$new_status\" && \"$new_status\" != \"$current_status\" ]]; then\n            valid_transition=false\n            valid_next=()\n\n            case \"$current_status\" in\n                \"\")\n                    valid_next=(\"to do\")\n                    ;;\n                \"to do\")\n                    valid_next=(\"in progress\")\n                    ;;\n                \"in progress\")\n                    valid_next=(\"under review\")\n                    ;;\n                \"under review\")\n                    valid_next=(\"done\" \"in progress\")\n                    ;;\n                \"done\")\n                    valid_next=()\n                    ;;\n                *)\n                    valid_next=()\n                    ;;\n            esac\n\n            # Check if new_status is in valid_next array\n            for allowed in \"${valid_next[@]}\"; do\n                [[ \"$new_status\" == \"$allowed\" ]] && valid_transition=true && break\n            done\n\n            # Format expected_next for error message\n            expected_next=$(IFS=' or '; echo \"${valid_next[*]}\")\n            [[ -z \"$expected_next\" ]] && expected_next=\"<none>\"\n\n            if [[ \"$valid_transition\" == false ]]; then\n                output=$(cat <<EOF\n{\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"PreToolUse\",\n    \"permissionDecision\": \"deny\",\n    \"permissionDecisionReason\": \"Invalid status transition: '${current_status:-<empty>}' → '$new_status'\\\\nExpected: '${current_status:-<empty>}' → '${expected_next}'\"\n  }\n}\nEOF\n)\n                log_hook_output \"pre-tool-use\" \"$output\"\n                check_and_echo_block_reason \"$output\"\n                echo \"$output\"\n                exit 1\n            fi\n        fi\n\n        # Function to extract status from file, handling quotes\n        extract_file_status() {\n            local file=\"$1\"\n            local raw_status=$(yq -r '.status // \"\"' \"$file\")\n            # Remove surrounding quotes if present\n            if [[ \"$raw_status\" =~ ^[\\\"\\'](.*)[\\\"\\']$ ]]; then\n                echo \"${BASH_REMATCH[1]}\"\n            else\n                echo \"$raw_status\"\n            fi\n        }\n\n        # Specific status validations\n        case \"$new_status\" in\n            \"in progress\")\n                # Check if any OTHER task is in \"under review\" status\n                # (Allow setting the same file back to \"in progress\" from \"under review\")\n                current_basename=$(basename \"$file_path\")\n                for task_file in task-*.yaml; do\n                    if [[ \"$task_file\" != \"$current_basename\" && -f \"$task_file\" ]]; then\n                        other_status=$(extract_file_status \"$task_file\")\n                        if [[ \"$other_status\" == \"under review\" ]]; then\n                            output=$(cat <<EOF\n{\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"PreToolUse\",\n    \"permissionDecision\": \"deny\",\n    \"permissionDecisionReason\": \"Cannot set task to 'in progress' while $task_file is 'under review'\"\n  }\n}\nEOF\n)\n                            log_hook_output \"pre-tool-use\" \"$output\"\n                            check_and_echo_block_reason \"$output\"\n                            echo \"$output\"\n                            exit 1\n                        fi\n                    fi\n                done\n                ;;\n        esac\n    fi\nfi\n\n# ============================================================================\n# PART 3: Commit Changed Files When Task is Done\n# ============================================================================\n\nif [[ -n \"$file_path\" ]]; then\n    filename=$(basename \"$file_path\")\n\n    # Check if this is a task file that will be modified\n    if [[ \"$filename\" =~ ^task-.*\\.ya?ml$ ]] && [[ -f \"$file_path\" ]]; then\n        # Extract new status from the hook JSON\n        new_string=$(echo \"$json\" | $JSON_CMD tool_input.new_string 2>/dev/null || echo \"\")\n\n        # Check if the new status will be \"done\"\n        new_status=\"\"\n        if status_line=$(echo \"$new_string\" | grep -m 1 -E '^status:[[:space:]]*'); then\n            # Match quoted or unquoted status values (including multi-word statuses)\n            if [[ \"$status_line\" =~ ^status:[[:space:]]*\\\"([^\\\"]+)\\\" ]]; then\n                new_status=\"${BASH_REMATCH[1]}\"\n            elif [[ \"$status_line\" =~ ^status:[[:space:]]*\\'([^\\']+)\\' ]]; then\n                new_status=\"${BASH_REMATCH[1]}\"\n            elif [[ \"$status_line\" =~ ^status:[[:space:]]*(.+)$ ]]; then\n                # For unquoted values, capture everything after \"status:\" until end of line\n                new_status=$(echo \"${BASH_REMATCH[1]}\" | sed 's/[[:space:]]*$//')\n            fi\n        fi\n\n        if [[ \"$new_status\" == \"done\" ]]; then\n            # Get the changed files and commit message\n            changed_files_array=()\n            while IFS= read -r line; do\n                [[ -n \"$line\" ]] && changed_files_array+=(\"$line\")\n            done < <(yq -r '.changed_files[]?' \"$file_path\" 2>/dev/null || true)\n\n            commit_message=$(yq -r '.commit_message // \"\"' \"$file_path\" 2>/dev/null || echo \"\")\n\n            # Remove quotes from commit message if present\n            if [[ \"$commit_message\" =~ ^[\\\"\\'](.*)[\\\"\\']$ ]]; then\n                commit_message=\"${BASH_REMATCH[1]}\"\n            fi\n\n            # Only proceed if we have both changed files and a commit message\n            if [[ ${#changed_files_array[@]} -gt 0 ]] && [[ -n \"$commit_message\" ]]; then\n                # Stage each changed file\n                for file in \"${changed_files_array[@]}\"; do\n                    if [[ -n \"$file\" ]] && [[ -f \"$file\" ]]; then\n                        if ! git add \"$file\" 2>&1 >&2; then\n                            output=$(cat <<EOF\n{\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"PreToolUse\",\n    \"permissionDecision\": \"deny\",\n    \"permissionDecisionReason\": \"Failed to stage file: $file\"\n  }\n}\nEOF\n)\n                            log_hook_output \"pre-tool-use\" \"$output\"\n                            check_and_echo_block_reason \"$output\"\n                            echo \"$output\"\n                            exit 1\n                        fi\n                    fi\n                done\n\n                # Create the commit with the task's commit message\n                if ! git diff --cached --quiet 2>/dev/null; then\n                    if ! git commit -m \"$commit_message\" > >(cat >&2) 2>&1; then\n                        output=$(cat <<EOF\n{\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"PreToolUse\",\n    \"permissionDecision\": \"deny\",\n    \"permissionDecisionReason\": \"Failed to commit changes for task $filename\"\n  }\n}\nEOF\n)\n                        log_hook_output \"pre-tool-use\" \"$output\"\n                        check_and_echo_block_reason \"$output\"\n                        echo \"$output\"\n                        exit 1\n                    fi\n                    echo \"Committed changes for task $filename\"\n                fi\n            fi\n        fi\n    fi\nfi\n\n# All checks passed - log successful execution with no blocking output\nlog_hook_output \"pre-tool-use\" \"\"\nexit 0",
        "rgw/hooks/session-start.sh": "#!/usr/bin/env bash\nset -euo pipefail\n\n# ============================================================================\n# Load Logger Library\n# ============================================================================\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\nsource \"${SCRIPT_DIR}/lib/logger.sh\"\n\n# ============================================================================\n# Session Start Hook - Check Required Dependencies\n# ============================================================================\n# This hook runs at the start of each Claude Code session to verify that\n# all required dependencies are installed for the rgw workflow hooks.\n# ============================================================================\n\nmissing_deps=()\n\n# Check for yq (YAML processor)\nif ! command -v yq &> /dev/null; then\n    missing_deps+=(\"yq\")\nfi\n\n# Check for node (required for json npm package)\nif ! command -v node &> /dev/null; then\n    missing_deps+=(\"node\")\nfi\n\n# Check for npx (required to run json package)\nif ! command -v npx &> /dev/null; then\n    missing_deps+=(\"npx\")\nfi\n\n# If there are missing dependencies, display installation instructions\nif [ ${#missing_deps[@]} -gt 0 ]; then\n    message=\"⚠️  Missing required dependencies for rgw workflow hooks:\\\\n\\\\n\"\n\n    for dep in \"${missing_deps[@]}\"; do\n        case \"$dep\" in\n            yq)\n                message+=\"  📦 yq (YAML processor)\\\\n\"\n                message+=\"     macOS:  brew install yq\\\\n\"\n                message+=\"     Linux:  https://github.com/mikefarah/yq#install\\\\n\"\n                message+=\"\\\\n\"\n                ;;\n            node)\n                message+=\"  📦 Node.js (JavaScript runtime)\\\\n\"\n                message+=\"     macOS:  brew install node\\\\n\"\n                message+=\"     Linux:  https://nodejs.org/en/download/package-manager\\\\n\"\n                message+=\"\\\\n\"\n                ;;\n            npx)\n                message+=\"  📦 npx (npm package runner)\\\\n\"\n                message+=\"     Usually installed with Node.js\\\\n\"\n                message+=\"     If missing: npm install -g npx\\\\n\"\n                message+=\"\\\\n\"\n                ;;\n        esac\n    done\n\n    message+=\"  ℹ️  Install the missing dependencies to enable full hook functionality.\"\n\n    output=$(cat <<EOF\n{\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"SessionStart\",\n    \"additionalContext\": \"$message\"\n  }\n}\nEOF\n)\n    log_hook_output \"session-start\" \"$output\"\n    echo \"$output\"\nelse\n    output=$(cat <<'EOF'\n{\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"SessionStart\",\n    \"additionalContext\": \"✅ rgw workflow hooks: All required dependencies are installed.\"\n  }\n}\nEOF\n)\n    log_hook_output \"session-start\" \"$output\"\n    echo \"$output\"\nfi\n\n# Explicitly flush output\nexit 0\n"
      },
      "plugins": [
        {
          "name": "aitt",
          "source": "./aitt",
          "description": "AI-driven development toolkit with commands and agents for testing, code review, and commit management",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add ByborgAI/prompt-collection",
            "/plugin install aitt@prompt-collection"
          ]
        },
        {
          "name": "rgw",
          "source": "./rgw",
          "description": "Requirement Gathering Workflow - A structured workflow for gathering requirements, generating tasks, and executing them systematically with automated git integration",
          "categories": [],
          "install_commands": [
            "/plugin marketplace add ByborgAI/prompt-collection",
            "/plugin install rgw@prompt-collection"
          ]
        }
      ]
    }
  ]
}