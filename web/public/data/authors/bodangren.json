{
  "author": {
    "id": "bodangren",
    "display_name": "bodangren",
    "type": "User",
    "avatar_url": "https://avatars.githubusercontent.com/u/17874742?v=4",
    "url": "https://github.com/bodangren",
    "bio": null,
    "stats": {
      "total_marketplaces": 1,
      "total_plugins": 1,
      "total_commands": 0,
      "total_skills": 13,
      "total_stars": 9,
      "total_forks": 2
    }
  },
  "marketplaces": [
    {
      "name": "bodangren-skills",
      "version": null,
      "description": "SynthesisFlow - Modular spec-driven AI development methodology",
      "owner_info": {
        "name": "Daniel Bo",
        "email": "bodangren@gmail.com"
      },
      "keywords": [],
      "repo_full_name": "bodangren/git-workflow",
      "repo_url": "https://github.com/bodangren/git-workflow",
      "repo_description": "Spec-Driven Git Workflow plugin for Claude Code - Comprehensive development workflow with GitHub integration, sprint management, and brownfield migration support",
      "homepage": null,
      "signals": {
        "stars": 9,
        "forks": 2,
        "pushed_at": "2025-12-06T01:42:50Z",
        "created_at": "2025-10-21T11:26:58Z",
        "license": "MIT"
      },
      "file_tree": [
        {
          "path": ".claude-plugin",
          "type": "tree",
          "size": null
        },
        {
          "path": ".claude-plugin/marketplace.json",
          "type": "blob",
          "size": 772
        },
        {
          "path": "skills",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/agent-integrator",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/agent-integrator/SKILL.md",
          "type": "blob",
          "size": 4763
        },
        {
          "path": "skills/change-integrator",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/change-integrator/SKILL.md",
          "type": "blob",
          "size": 9806
        },
        {
          "path": "skills/doc-indexer",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/doc-indexer/SKILL.md",
          "type": "blob",
          "size": 5793
        },
        {
          "path": "skills/doc-validator",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/doc-validator/SKILL.md",
          "type": "blob",
          "size": 3509
        },
        {
          "path": "skills/frontend-design",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/frontend-design/SKILL.md",
          "type": "blob",
          "size": 4275
        },
        {
          "path": "skills/issue-executor",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/issue-executor/SKILL.md",
          "type": "blob",
          "size": 5667
        },
        {
          "path": "skills/issue-executor/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/issue-executor/references/work-on-issue.md",
          "type": "blob",
          "size": 15447
        },
        {
          "path": "skills/prd-authoring",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/prd-authoring/SKILL.md",
          "type": "blob",
          "size": 8052
        },
        {
          "path": "skills/prd-authoring/examples",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/prd-authoring/examples/01-product-brief-example.md",
          "type": "blob",
          "size": 7433
        },
        {
          "path": "skills/prd-authoring/examples/02-research-example.md",
          "type": "blob",
          "size": 11367
        },
        {
          "path": "skills/prd-authoring/examples/03-prd-example-abbreviated.md",
          "type": "blob",
          "size": 15989
        },
        {
          "path": "skills/prd-authoring/examples/IMPLEMENTATION_SUMMARY.md",
          "type": "blob",
          "size": 11493
        },
        {
          "path": "skills/prd-authoring/examples/QUICK_START.md",
          "type": "blob",
          "size": 8596
        },
        {
          "path": "skills/prd-authoring/examples/README.md",
          "type": "blob",
          "size": 7061
        },
        {
          "path": "skills/prd-authoring/examples/workflow-test-log.md",
          "type": "blob",
          "size": 12151
        },
        {
          "path": "skills/project-init",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/project-init/SKILL.md",
          "type": "blob",
          "size": 6954
        },
        {
          "path": "skills/project-migrate",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/project-migrate/SKILL.md",
          "type": "blob",
          "size": 5169
        },
        {
          "path": "skills/skill-lister",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/skill-lister/SKILL.md",
          "type": "blob",
          "size": 4343
        },
        {
          "path": "skills/spec-authoring",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/spec-authoring/SKILL.md",
          "type": "blob",
          "size": 5224
        },
        {
          "path": "skills/sprint-manager",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/sprint-manager/SKILL.md",
          "type": "blob",
          "size": 7817
        },
        {
          "path": "skills/sprint-manager/references",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/sprint-manager/references/implementer-prompt-template.md",
          "type": "blob",
          "size": 3128
        },
        {
          "path": "skills/sprint-manager/references/integrator-prompt-template.md",
          "type": "blob",
          "size": 2945
        },
        {
          "path": "skills/sprint-manager/references/review-prompt-template.md",
          "type": "blob",
          "size": 3643
        },
        {
          "path": "skills/sprint-planner",
          "type": "tree",
          "size": null
        },
        {
          "path": "skills/sprint-planner/SKILL.md",
          "type": "blob",
          "size": 4859
        }
      ],
      "files": {
        ".claude-plugin/marketplace.json": "{\n  \"name\": \"bodangren-skills\",\n  \"owner\": {\n    \"name\": \"Daniel Bo\",\n    \"email\": \"bodangren@gmail.com\"\n  },\n  \"metadata\": {\n    \"description\": \"SynthesisFlow - Modular spec-driven AI development methodology\",\n    \"version\": \"2.1.0\"\n  },\n  \"plugins\": [\n    {\n      \"name\": \"synthesisflow-skills\",\n      \"description\": \"SynthesisFlow: Modular skills for spec-driven development with hybrid LLM-guided + helper-script architecture\",\n      \"source\": \"./skills\",\n      \"strict\": false,\n      \"skills\": [\n        \"./project-init\",\n        \"./project-migrate\",\n        \"./prd-authoring\",\n        \"./doc-indexer\",\n        \"./spec-authoring\",\n        \"./sprint-planner\",\n        \"./issue-executor\",\n        \"./change-integrator\",\n        \"./agent-integrator\"\n      ]\n    }\n  ]\n}\n",
        "skills/agent-integrator/SKILL.md": "---\nname: agent-integrator\ndescription: Use this skill to create or update the root AGENTS.md file to register AgenticDev skills for AI agent discovery. Triggers include \"register AgenticDev\", \"update AGENTS.md\", \"setup agent guide\", or initializing a new project.\n---\n\n# Agent Integrator Skill\n\n## Purpose\n\nIdempotently create or update the AGENTS.md file in a project to register AgenticDev skills for discovery by AI agents. This skill ensures that any compatible AI agent working in the repository can discover and use the AgenticDev methodology and available skills.\n\n## When to Use\n\nUse this skill in the following situations:\n\n- After running project-init to initialize AgenticDev in a new project\n- When installing AgenticDev skills in an existing project\n- After adding new skills to the `.claude/skills/` directory\n- Updating the agent guide with new workflow information\n- Ensuring AI agents can discover available AgenticDev capabilities\n\n## Prerequisites\n\n- Project has `.claude/skills/` directory with AgenticDev skills installed\n- Write permissions to project root directory\n- Optional: Existing AGENTS.md file (script creates if missing)\n\n## AGENTS.md Purpose\n\nThe AGENTS.md file serves as a discovery mechanism for AI agents:\n\n- **Agent Discovery**: AI agents read this file to learn about available workflows\n- **Methodology Documentation**: Explains AgenticDev philosophy and core principles\n- **Skill Catalog**: Lists all available skills and their purposes\n- **Getting Started**: Provides entry point for new agents working in the project\n\n## Workflow\n\n### Step 1: Determine If Update Is Needed\n\nCheck if AGENTS.md needs to be created or updated:\n\n```bash\n# Check if file exists\nls -la AGENTS.md\n\n# Check if AgenticDev section exists\ngrep \"SYNTHESIS_FLOW\" AGENTS.md\n```\n\n### Step 2: Run the Helper Script\n\nExecute the script to update AGENTS.md:\n\n```bash\n# Use default location (AGENTS.md in project root)\nbash scripts/update-agents-file.sh\n\n# Or specify custom location\nbash scripts/update-agents-file.sh -f path/to/custom-agents.md\n```\n\n### Step 3: Understand What the Script Does\n\nThe helper script uses an idempotent update strategy:\n\n1. **Creates file if missing**:\n   - Uses `touch` to ensure target file exists\n   - Safe to run even if file doesn't exist yet\n\n2. **Checks for existing content**:\n   - Looks for `<!-- SYNTHESIS_FLOW_START -->` marker\n   - Determines if this is an update or initial creation\n\n3. **Updates existing content**:\n   - If markers found, replaces content between markers\n   - Preserves any other content in the file\n   - Uses awk to safely replace marked section\n\n4. **Adds new content**:\n   - If markers not found, appends AgenticDev guide to end of file\n   - Adds both start and end markers for future updates\n\n5. **Preserves other content**:\n   - Only modifies content between markers\n   - Safe to run multiple times (idempotent)\n   - Won't overwrite other project documentation\n\n### Step 4: Verify the Update\n\nCheck that AGENTS.md was updated correctly:\n\n```bash\n# View the file\ncat AGENTS.md\n\n# Verify markers are present\ngrep -A 5 \"SYNTHESIS_FLOW_START\" AGENTS.md\n```\n\n### Step 5: Commit the Changes\n\nIf the update looks correct, commit to the repository:\n\n```bash\ngit add AGENTS.md\ngit commit -m \"docs: Update AGENTS.md with AgenticDev guide\"\ngit push\n```\n\n## Error Handling\n\n### Permission Denied\n\n**Symptom**: Script cannot write to AGENTS.md\n\n**Solution**:\n- Check file permissions: `ls -la AGENTS.md`\n- Ensure you have write access to project root\n- Run with appropriate permissions\n\n### Marker Corruption\n\n**Symptom**: Content between markers is malformed\n\n**Solution**:\n- Manually edit AGENTS.md to fix markers\n- Ensure both `<!-- SYNTHESIS_FLOW_START -->` and `<!-- SYNTHESIS_FLOW_END -->` are present\n- Re-run script to regenerate content\n\n### Custom File Path Issues\n\n**Symptom**: Script creates file in wrong location\n\n**Solution**:\n- Use `-f` flag with full path: `bash scripts/update-agents-file.sh -f /full/path/to/file.md`\n- Verify path exists: `mkdir -p /path/to/directory`\n- Check current working directory\n\n## Notes\n\n- **Idempotent design**: Safe to run multiple times without side effects\n- **Preserves other content**: Only updates content between markers\n- **Marker-based**: Uses HTML comments as markers (invisible in rendered markdown)\n- **Default location**: AGENTS.md in project root (standard convention)\n- **Custom locations**: Use `-f` flag for alternative file paths\n- **Run after setup**: Typically run once after project-init, then rarely\n- **Update when skills change**: Re-run if new skills are added or removed\n- **AI agent discovery**: Helps agents understand available AgenticDev capabilities\n- **Version control**: Commit AGENTS.md so all contributors see the guide\n",
        "skills/change-integrator/SKILL.md": "---\nname: change-integrator\ndescription: Use this skill after a code PR is merged to integrate approved specs, update the retrospective with learnings, and clean up branches. It now automatically summarizes the retrospective file to keep it concise. Triggers include \"integrate change\", \"post-merge cleanup\", or completing a feature implementation.\n---\n\n# Change Integrator Skill\n\n## Purpose\n\nPerform post-merge integration tasks after a code PR is successfully merged. This skill completes the development cycle by moving approved specs from `docs/changes/` to `docs/specs/`, updating the retrospective with learnings, cleaning up feature branches, and updating project board status. It ensures the repository remains clean and the documentation reflects the current state.\n\nA key feature of this skill is the **automated maintenance of `RETROSPECTIVE.md`**. When the file grows too large, the script automatically uses the Gemini CLI to summarize older entries, keeping the document concise and readable while preserving key historical learnings.\n\n## When to Use\n\nUse this skill in the following situations:\n\n- After a code PR is merged to main\n- Completing a feature that had a spec proposal\n- Finalizing a task and cleaning up branches\n- Updating retrospective with completed work\n- Moving approved specs to source-of-truth location\n\n## Prerequisites\n\n- Code PR has been merged to main branch\n- Feature branch name is known\n- PR number is known\n- Project board item ID is known (if using project boards)\n- `gh` CLI tool installed and authenticated\n- `gemini` CLI tool installed and authenticated\n- Currently on main branch with latest changes\n\n## Workflow\n\n### Step 1: Verify PR is Merged\n\nBefore running integration, confirm the PR was successfully merged:\n\n```bash\ngh pr view PR_NUMBER --json state,mergedAt\n```\n\nEnsure the state is \"MERGED\" and mergedAt timestamp is populated.\n\n### Step 2: Identify Integration Needs\n\nDetermine what needs to be integrated:\n- **Spec files**: Was this a feature with a spec proposal in `docs/changes/`?\n- **Branch cleanup**: What is the feature branch name?\n- **Project board**: What is the item ID to mark as done?\n- **Retrospective**: What were the key learnings from this task?\n\n### Step 3: Run the Helper Script (Optional)\n\nIf using the automated script for integration:\n\n```bash\nbash scripts/integrate-change.sh -p PR_NUMBER -b BRANCH_NAME -i ITEM_ID -w \"WENT_WELL\" -l \"LESSON\" [-c CHANGE_DIR]\n```\n\n**Parameters**:\n- `-p`: PR number that was merged\n- `-b`: Feature branch name (e.g., `feat/45-restructure-doc-indexer`)\n- `-i`: Project board item ID\n- `-w`: A quote about what went well.\n- `-l`: A quote about the key lesson learned.\n- `-c`: Optional path to change proposal directory (e.g., `docs/changes/my-feature`)\n\n### Step 4: Understand What the Script Does\n\nThe helper script automates these steps:\n\n1.  **Verifies PR is merged**: Queries GitHub API and aborts if PR is not in MERGED state.\n2.  **Switches to main and pulls**: Ensures work is on the latest main branch.\n3.  **Deletes feature branch**: Removes both remote and local branches.\n4.  **Integrates spec files (if applicable)**: Moves `spec-delta.md` to `docs/specs/` and commits the change.\n5.  **Updates project board**: Sets the task status to \"Done\".\n6.  **Updates retrospective**: Appends a new entry. If `RETROSPECTIVE.md` exceeds a line limit (e.g., 150 lines), it **automatically summarizes older sprint entries** using the Gemini CLI to keep the file manageable.\n7.  **Pushes all changes**: Pushes integration commits to main.\n\n### Step 5: Manual Integration (Alternative)\n\nIf not using the script, perform these steps manually:\n\n#### 5a. Switch to Main and Update\n\n```bash\ngit switch main\ngit pull\n```\n\n#### 5b. Delete Feature Branch\n\n```bash\n# Delete remote branch\ngit push origin --delete feat/45-restructure-doc-indexer\n\n# Delete local branch\ngit branch -D feat/45-restructure-doc-indexor\n```\n\n#### 5c. Integrate Spec Files (If Applicable)\n\nIf the feature had a spec proposal:\n\n```bash\n# Identify the change directory\nls docs/changes/\n\n# Move spec-delta to specs\nSPEC_NAME=\"my-feature\"\ncp docs/changes/$SPEC_NAME/spec-delta.md docs/specs/$SPEC_NAME.md\n\n# Remove change directory\nrm -r docs/changes/$SPEC_NAME\n\n# Commit integration\ngit add docs/\ngit commit -m \"docs: Integrate approved spec from feat/45-my-feature\"\n```\n\n#### 5d. Update Project Board\n\n```bash\ngh project item-edit \\\n  --project-id PROJECT_ID \\\n  --id ITEM_ID \\\n  --field-id FIELD_ID \\\n  --single-select-option-id DONE_OPTION_ID\n```\n\n#### 5e. Update Retrospective\n\nAdd learnings to RETROSPECTIVE.md following the established format. See the retrospective for examples.\n\n```bash\n# Edit RETROSPECTIVE.md to add entry\ngit add RETROSPECTIVE.md\ngit commit -m \"docs: Add retrospective for PR #45\"\n```\n\n#### 5f. Push Changes\n\n```bash\ngit push\n```\n\n### Step 6: Verify Integration\n\nAfter integration completes:\n\n```bash\n# Verify branch deleted\ngit branch -a | grep feat/45\n\n# Verify spec integrated (if applicable)\nls docs/specs/\n\n# Verify retrospective updated\ntail -20 RETROSPECTIVE.md\n\n# Verify project board updated\ngh project item-list PROJECT_NUMBER --owner @me\n```\n\n## Automated Retrospective Summarization\n\nTo prevent `RETROSPECTIVE.md` from becoming unmanageably long, the `integrate-change.sh` script includes an automated summarization feature powered by the Gemini CLI.\n\n**How it works:**\n1.  **Threshold Check**: Before adding a new entry, the script checks the line count of `RETROSPECTIVE.md`.\n2.  **Trigger**: If the line count exceeds a defined threshold (e.g., 150 lines), the summarization process is triggered.\n3.  **Preservation**: The script preserves the initial sections of the file, including the introduction and the \"Historical Learnings\" section.\n4.  **Summarization**: It takes the older sprint entries, sends them to the `gemini` CLI, and requests a concise summary that preserves key learnings and markdown structure.\n5.  **Reconstruction**: The script then overwrites `RETROSPECTIVE.md` with the preserved header, a new \"Summarized Sprints (via Gemini)\" section, and the newly generated summary.\n6.  **New Entry**: Finally, it appends the new retrospective entry to the freshly summarized file.\n\nThis ensures that the file remains a valuable and readable source of information without requiring manual pruning.\n\n## Error Handling\n\n### PR Not Merged\n\n**Symptom**: Script reports PR is not in MERGED state\n\n**Solution**:\n- Verify PR number is correct\n- Wait for PR to be merged\n- Check auto-merge status if enabled\n- Manually merge PR if needed\n\n### Branch Already Deleted\n\n**Symptom**: Git reports branch doesn't exist\n\n**Solution**:\n- This is normal if auto-merge deleted the branch\n- Continue with remaining integration steps\n- Script handles this gracefully with `|| echo \"...\"`\n\n### Spec Directory Not Found\n\n**Symptom**: Script cannot find change directory\n\n**Solution**:\n- Verify the change directory path is correct\n- Check if this feature even had a spec proposal\n- Skip spec integration step if not applicable\n- Use `-c` flag only when spec exists\n\n### Permission Denied on Project Board\n\n**Symptom**: GitHub API returns 403 error\n\n**Solution**:\n- Verify project board IDs are correct\n- Ensure you have write access to the project\n- Check `gh` authentication: `gh auth status`\n- Update script configuration variables if needed\n\n### Gemini CLI Issues\n\n**Symptom**: The script fails during the \"Updating retrospective...\" step with an error related to the `gemini` command.\n\n**Solution**:\n- Ensure the `gemini` CLI is installed and in your system's PATH.\n- Verify you are authenticated. Run `gemini auth` if needed.\n- Check for any Gemini API-related issues or outages.\n- If the issue persists, you can temporarily increase the `RETROSPECTIVE_MAX_LINES` variable in the script to bypass the summarization and add your entry.\n\n### Retrospective Format Issues\n\n**Symptom**: The automated summary has formatting problems or seems to have lost critical information.\n\n**Solution**:\n- The summarization is automated and may not be perfect. The original, unsummarized content is not retained by the script.\n- You can review the commit history for `RETROSPECTIVE.md` in git to find the previous version if you need to recover information.\n- Manually edit the summarized content to fix any formatting issues.\n- Consider adjusting the prompt sent to the Gemini CLI within the `summarize_retrospective` function in the script for better results in the future.\n\n## Configuration Notes\n\nThe script uses these hardcoded configuration variables (lines 31-33):\n\n```bash\nPROJECT_ID=\"PVT_kwHOARC_Ns4BG9YU\"\nFIELD_ID=\"PVTSSF_lAHOARC_Ns4BG9YUzg32qas\"  # Workflow Stage\nDONE_OPTION_ID=\"6bc77efe\"\n```\n\n**To adapt for your project:**\n1. Find your project ID: `gh project list --owner @me`\n2. Find field ID: `gh api graphql -f query='...'` (see GitHub docs)\n3. Find done option ID: Query project field values\n4. Update these variables in the script\n\n**Note**: A future version should detect these dynamically.\n\n## Notes\n\n- **Run after PR is merged**: This is post-merge cleanup, not pre-merge preparation\n- **Spec integration is optional**: Only for features that started with spec proposals\n- **Retrospective is required**: Always update with learnings from completed work\n- **Branch cleanup prevents clutter**: Keeps repository clean and organized\n- **Project board sync**: Ensures status accurately reflects completed work\n- **Manual steps work too**: Script is a convenience, not required\n- **Integration commits go to main**: These are documentation updates, not code changes\n- **Keep retrospective focused**: Capture what worked, what didn't, and key lessons\n- **One PR per integration**: Run the workflow once per merged PR\n- **Script is not fully automated**: Still requires parameters and decision-making",
        "skills/doc-indexer/SKILL.md": "---\nname: doc-indexer\ndescription: Use this skill at the beginning of any session or when needing to understand available project documentation. Provides just-in-time context by scanning YAML frontmatter from all markdown files in the docs/ directory without loading full content.\n---\n\n# Document Indexer Skill\n\n## Purpose\n\nProvide just-in-time context about available project documentation without loading full file content into the context window. The doc-indexer scans all markdown files in the `docs/` directory, extracts their YAML frontmatter metadata, and returns a structured map of available documentation. This enables efficient discovery of specs, plans, retrospectives, and other documentation while minimizing token usage.\n\n## When to Use\n\nUse this skill in the following situations:\n\n- At the beginning of any work session to understand the current state of documentation\n- When starting work on a new issue to identify relevant specs and context\n- Before proposing changes to understand existing specifications\n- When planning a sprint to review available approved specs\n- Anytime you need an overview of project documentation without reading full files\n\n## Prerequisites\n\n- The project must have a `docs/` directory\n- Documentation files should follow the convention of including YAML frontmatter\n- The `jq` tool is NOT required (script works without it)\n\n## Workflow\n\n### Step 1: Run the Documentation Scanner\n\nExecute the helper script to scan all markdown files in the docs/ directory:\n\n```bash\nbash scripts/scan-docs.sh\n```\n\nThis will output a human-readable summary showing each document's frontmatter metadata.\n\nFor machine-readable JSON output (useful for programmatic processing):\n\n```bash\nbash scripts/scan-docs.sh -j\n```\n\n### Step 2: Review the Documentation Map\n\nThe scanner returns information about all markdown files found in `docs/`, including:\n\n- **File path**: Location of the documentation file\n- **Frontmatter metadata**: Key-value pairs from YAML frontmatter (title, status, type, etc.)\n- **Compliance warnings**: Files missing YAML frontmatter are flagged\n\n**Example human-readable output**:\n```\n---\nfile: docs/specs/001-synthesis-flow.md\ntitle: AgenticDev Methodology\nstatus: approved\ntype: spec\n---\nfile: docs/changes/my-feature/proposal.md\ntitle: My Feature Proposal\nstatus: in-review\ntype: proposal\n[WARNING] Non-compliant file (no frontmatter): docs/README.md\n```\n\n**Example JSON output**:\n```json\n[\n  {\n    \"file\": \"docs/specs/001-synthesis-flow.md\",\n    \"compliant\": true,\n    \"frontmatter\": {\n      \"title\": \"AgenticDev Methodology\",\n      \"status\": \"approved\",\n      \"type\": \"spec\"\n    }\n  },\n  {\n    \"file\": \"docs/README.md\",\n    \"compliant\": false,\n    \"frontmatter\": null\n  }\n]\n```\n\n### Step 3: Use the Map to Identify Relevant Documentation\n\nBased on the documentation map, identify which specific files to read for your current task:\n\n- **For implementation work**: Look for approved specs related to your issue\n- **For spec proposals**: Review existing specs to understand the current state\n- **For sprint planning**: Identify approved specs ready for implementation\n- **For learning context**: Find retrospectives and design docs\n\n### Step 4: Read Specific Documentation Files\n\nOnce you've identified relevant files from the map, use the Read tool to load their full content:\n\n```bash\n# Example: Read a specific spec identified from the map\nRead docs/specs/001-synthesis-flow.md\n```\n\nThis two-step approach (scan first, then read selectively) minimizes token usage while ensuring you have access to all necessary context.\n\n## Error Handling\n\n### No docs/ Directory\n\n**Symptom**: Script reports \"No such file or directory\"\n\n**Solution**:\n- Verify you're in the project root directory\n- Check if the project has been initialized with `project-init` skill\n- Create `docs/` directory structure if needed\n\n### Files Missing Frontmatter\n\n**Symptom**: Script outputs \"[WARNING] Non-compliant file (no frontmatter): ...\"\n\n**Impact**: These files won't have structured metadata in the output\n\n**Solution**:\n- Add YAML frontmatter to documentation files for better discoverability\n- Frontmatter should be at the top of the file between `---` markers\n- Example format:\n  ```markdown\n  ---\n  title: My Document\n  status: draft\n  type: design\n  ---\n\n  # Document content starts here\n  ```\n\n### Script Permission Errors\n\n**Symptom**: \"Permission denied\" when running the script\n\n**Solution**:\n```bash\nchmod +x scripts/scan-docs.sh\n```\n\n## Output Interpretation Guide\n\n### Frontmatter Fields\n\nCommon frontmatter fields you'll encounter:\n\n- **title**: Human-readable document title\n- **status**: Document state (draft, in-review, approved, archived)\n- **type**: Document category (spec, proposal, design, retrospective, plan)\n- **epic**: Associated epic issue number\n- **sprint**: Sprint identifier\n- **author**: Document author\n- **created**: Creation date\n- **updated**: Last update date\n\n### Using JSON Output Programmatically\n\nThe JSON output mode is particularly useful when:\n\n- Filtering documents by specific criteria (e.g., only approved specs)\n- Counting documents by type or status\n- Building automated workflows\n- Integrating with other tools\n\nExample using `jq` to filter approved specs:\n```bash\nbash scripts/scan-docs.sh -j | jq '.[] | select(.frontmatter.status == \"approved\")'\n```\n\n## Notes\n\n- The scanner is non-invasive and read-only - it never modifies files\n- Large projects with many docs benefit most from this just-in-time approach\n- The script scans recursively through all subdirectories in `docs/`\n- Empty frontmatter sections are treated as non-compliant\n- The scan is fast and can be run frequently without performance concerns\n- Consider running this at the start of each work session to stay current with documentation changes\n",
        "skills/doc-validator/SKILL.md": "---\nname: doc-validator\ndescription: Use this skill to validate that Markdown files are in standard locations. Scans for .md files outside of predefined allowed directories and outputs warnings to prevent documentation sprawl. Triggers include \"validate docs\", \"check markdown locations\", or as part of quality checks.\ncategory: project\n---\n\n# Doc Validator\n\n## Purpose\n\nScan the repository for Markdown files (`.md`) located outside of predefined, allowed directories. This skill helps prevent documentation sprawl and enforces a consistent repository structure by warning about `.md` files in non-standard locations.\n\n## When to Use\n\nUse this skill in the following situations:\n\n- During code reviews to ensure documentation is properly organized\n- As part of CI/CD quality checks\n- Before merging changes that add new documentation\n- When auditing the repository for documentation compliance\n- Called automatically by other skills (issue-executor, change-integrator)\n\n## Prerequisites\n\n- Standard bash utilities (`find`, `bash`)\n- Project follows AgenticDev directory conventions\n\n## Workflow\n\n### Step 1: Run the Validator\n\nExecute the validator script to scan for misplaced Markdown files:\n\n```bash\nbash skills/doc-validator/scripts/doc-validator.sh\n```\n\n### Step 2: Review Warnings\n\nThe script outputs warnings for any `.md` files found in non-standard locations:\n\n```\nWARNING: Markdown file in non-standard location: ./src/notes.md\nWARNING: Markdown file in non-standard location: ./scripts/temp-docs.md\n```\n\n### Step 3: Take Action\n\nFor each warning:\n\n1. **Determine if the file should exist**: Is it temporary or abandoned?\n2. **Move to proper location**: Relocate to `docs/` or appropriate skill directory\n3. **Add to allowed patterns**: If it's a legitimate exception (update the script)\n4. **Remove the file**: If it's no longer needed\n\n## Allowed Patterns\n\nThe validator considers these locations as standard and will not warn about them:\n\n- **Root-level documentation**: `README.md`, `LICENSE`, `AGENTS.md`, `RETROSPECTIVE.md`\n- **Main docs directory**: `docs/**/*.md` (all subdirectories)\n- **Skill documentation**:\n  - `skills/*/SKILL.md`\n  - `skills/*/references/*.md`\n  - `skills/*/examples/*.md`\n  - `.claude/skills/*/SKILL.md`\n  - `.claude/skills/*/references/*.md`\n  - `.claude/skills/*/examples/*.md`\n\n## Error Handling\n\n### False Positives\n\n**Symptom**: The validator warns about a file that should be allowed\n\n**Solution**:\n- Check if the file matches an allowed pattern\n- If it's a legitimate location not covered by current patterns, update `doc-validator.sh`\n- Add the new pattern to the `ALLOWED_PATTERNS` array\n\n### Script Not Finding Files\n\n**Symptom**: The script runs but finds no files or fewer files than expected\n\n**Solution**:\n- Verify you're running from the repository root\n- Check file permissions\n- Ensure `.md` files exist in the repository\n\n### Permission Denied\n\n**Symptom**: Script cannot access certain directories\n\n**Solution**:\n- Check directory permissions\n- Ensure the script is executable: `chmod +x skills/doc-validator/scripts/doc-validator.sh`\n\n## Notes\n\n- **Non-destructive**: The script only reports issues, it does not move or delete files\n- **Excludes**: Automatically skips `.git/` and `.agenticdev-backup-*` directories\n- **Integration**: Designed to be called by other skills as part of quality checks\n- **Extensible**: Easy to add new allowed patterns by updating the script\n- **CI-friendly**: Returns parsable output suitable for automated checks\n",
        "skills/frontend-design/SKILL.md": "---\nname: frontend-design\ndescription: Create distinctive, production-grade frontend interfaces with high design quality. Use this skill when the user asks to build web components, pages, or applications. Generates creative, polished code that avoids generic AI aesthetics.\nlicense: Complete terms in LICENSE.txt\n---\n\nThis skill guides creation of distinctive, production-grade frontend interfaces that avoid generic \"AI slop\" aesthetics. Implement real working code with exceptional attention to aesthetic details and creative choices.\n\nThe user provides frontend requirements: a component, page, application, or interface to build. They may include context about the purpose, audience, or technical constraints.\n\n## Design Thinking\n\nBefore coding, understand the context and commit to a BOLD aesthetic direction:\n- **Purpose**: What problem does this interface solve? Who uses it?\n- **Tone**: Pick an extreme: brutally minimal, maximalist chaos, retro-futuristic, organic/natural, luxury/refined, playful/toy-like, editorial/magazine, brutalist/raw, art deco/geometric, soft/pastel, industrial/utilitarian, etc. There are so many flavors to choose from. Use these for inspiration but design one that is true to the aesthetic direction.\n- **Constraints**: Technical requirements (framework, performance, accessibility).\n- **Differentiation**: What makes this UNFORGETTABLE? What's the one thing someone will remember?\n\n**CRITICAL**: Choose a clear conceptual direction and execute it with precision. Bold maximalism and refined minimalism both work - the key is intentionality, not intensity.\n\nThen implement working code (HTML/CSS/JS, React, Vue, etc.) that is:\n- Production-grade and functional\n- Visually striking and memorable\n- Cohesive with a clear aesthetic point-of-view\n- Meticulously refined in every detail\n\n## Frontend Aesthetics Guidelines\n\nFocus on:\n- **Typography**: Choose fonts that are beautiful, unique, and interesting. Avoid generic fonts like Arial and Inter; opt instead for distinctive choices that elevate the frontend's aesthetics; unexpected, characterful font choices. Pair a distinctive display font with a refined body font.\n- **Color & Theme**: Commit to a cohesive aesthetic. Use CSS variables for consistency. Dominant colors with sharp accents outperform timid, evenly-distributed palettes.\n- **Motion**: Use animations for effects and micro-interactions. Prioritize CSS-only solutions for HTML. Use Motion library for React when available. Focus on high-impact moments: one well-orchestrated page load with staggered reveals (animation-delay) creates more delight than scattered micro-interactions. Use scroll-triggering and hover states that surprise.\n- **Spatial Composition**: Unexpected layouts. Asymmetry. Overlap. Diagonal flow. Grid-breaking elements. Generous negative space OR controlled density.\n- **Backgrounds & Visual Details**: Create atmosphere and depth rather than defaulting to solid colors. Add contextual effects and textures that match the overall aesthetic. Apply creative forms like gradient meshes, noise textures, geometric patterns, layered transparencies, dramatic shadows, decorative borders, custom cursors, and grain overlays.\n\nNEVER use generic AI-generated aesthetics like overused font families (Inter, Roboto, Arial, system fonts), cliched color schemes (particularly purple gradients on white backgrounds), predictable layouts and component patterns, and cookie-cutter design that lacks context-specific character.\n\nInterpret creatively and make unexpected choices that feel genuinely designed for the context. No design should be the same. Vary between light and dark themes, different fonts, different aesthetics. NEVER converge on common choices (Space Grotesk, for example) across generations.\n\n**IMPORTANT**: Match implementation complexity to the aesthetic vision. Maximalist designs need elaborate code with extensive animations and effects. Minimalist or refined designs need restraint, precision, and careful attention to spacing, typography, and subtle details. Elegance comes from executing the vision well.\n\nRemember: Claude is capable of extraordinary creative work. Don't hold back, show what can truly be created when thinking outside the box and committing fully to a distinctive vision.\n",
        "skills/issue-executor/SKILL.md": "---\nname: issue-executor\ndescription: Use this skill to start work on a GitHub issue. It synthesizes all relevant context (specs, retrospective, issue details) using the Gemini CLI to generate a step-by-step implementation plan, then creates a feature branch to begin work. Triggers include \"start work on issue #X\" or \"implement issue\".\n---\n\n# Issue Executor\n\n## Purpose\n\nTo kickstart the development workflow for a single GitHub issue by generating a comprehensive, context-aware implementation plan. This skill leverages the Gemini CLI to synthesize issue details, relevant specifications, and historical learnings from the project retrospective into a clear, actionable plan. It then creates an isolated feature branch, setting the stage for focused, spec-driven development.\n\n## When to Use\n\nUse this skill in the following situations:\n\n- Starting work on a planned GitHub issue from the current sprint.\n- Beginning a work session and wanting a synthesized plan before coding.\n- Needing to load and understand all context for an issue efficiently.\n\n## Prerequisites\n\n- GitHub repository with issues created (via sprint-planner skill).\n- Git working directory is clean (no uncommitted changes).\n- Currently on the `main` branch.\n- `gh` CLI tool installed and authenticated.\n- `jq` tool installed for JSON parsing.\n- `gemini` CLI tool installed and authenticated.\n- Project has a `docs/` structure with specs and a `RETROSPECTIVE.md`.\n\n## Core Principles\n\n### Context is King\n\nInstead of just viewing files, the skill synthesizes all relevant context into a coherent plan:\n- **Issue details**: Requirements and acceptance criteria.\n- **Spec files**: All specifications referenced in the issue.\n- **Retrospective**: Learnings from past work to avoid repeating mistakes.\n\n### Isolation\n\nAll work happens on a dedicated feature branch to:\n- Protect the `main` branch from work-in-progress.\n- Enable a clean Pull Request workflow.\n- Allow abandoning work without impacting the main codebase.\n\n### Atomic Work\n\nEach issue represents a single, well-defined task that can be completed and reviewed as a unit.\n\n## Workflow\n\n### Step 1: Identify the Issue\n\nDetermine which issue to work on. The user specifies the issue number (e.g., #45).\n\n### Step 2: Run the Helper Script\n\nExecute the `work-on-issue.sh` script with the issue number:\n\n```bash\nbash scripts/work-on-issue.sh 45\n```\n\n### Step 3: Understand What the Script Does\n\nThe helper script automates these critical setup steps:\n\n1.  **Validates Prerequisites**: Checks for `jq`, a clean git status, and being on the `main` branch.\n2.  **Fetches Issue Details**: Retrieves the issue title and body from GitHub.\n3.  **Finds Context Files**: Locates all referenced spec files (`.md`) in `docs/specs/` or `docs/changes/` and identifies `RETROSPECTIVE.md`.\n4.  **Synthesizes Implementation Plan**: Constructs a detailed prompt with the issue details and file context (`@file` syntax) and calls the `gemini` CLI. It asks Gemini to produce a step-by-step implementation plan based on all provided information.\n5.  **Displays the Plan**: Prints the generated plan from Gemini to the console.\n6.  **Creates Feature Branch**: Generates a conventional branch name (e.g., `feat/45-restructure-doc-indexer`) and checks it out.\n7.  **Confirms Readiness**: Displays a success message confirming that the branch is ready and the plan has been generated.\n\n### Step 4: Review the Implementation Plan\n\nAfter the script completes, carefully review the implementation plan generated by Gemini. This plan is your starting guide for the implementation, synthesized from all available project context.\n\n### Step 5: Begin Implementation\n\nWith the plan and feature branch ready:\n\n1.  Follow the steps outlined in the generated plan.\n2.  Write code that meets the acceptance criteria.\n3.  Test your changes thoroughly.\n4.  Commit work incrementally.\n5.  Push to the remote branch when ready to create a Pull Request.\n\n## Error Handling\n\n### Working Directory Not Clean / Not on Main Branch\n\n**Symptom**: Script reports uncommitted changes or that you are not on the `main` branch.\n**Solution**: Commit, stash, or discard your changes. Switch back to the `main` branch before re-running the script.\n\n### Missing `jq` or `gemini` Tool\n\n**Symptom**: Script reports that `jq` or `gemini` is not installed.\n**Solution**: Install the required tool. For `jq`, use `sudo apt install jq` or `brew install jq`. For `gemini`, follow its official installation instructions.\n\n### Gemini CLI Issues\n\n**Symptom**: The script fails while generating the implementation plan, showing an error from the `gemini` command.\n**Solution**:\n- Ensure the `gemini` CLI is installed correctly and is in your system's PATH.\n- Verify your authentication status with `gemini auth`.\n- Check for Gemini API outages or connectivity issues.\n- Examine the prompt being sent to Gemini for any syntax errors.\n\n### Spec File Not Found\n\n**Symptom**: The script runs, but the plan doesn't seem to include context from a spec file you expected.\n**Solution**:\n- Ensure the issue body explicitly references the spec file with its full path (e.g., `docs/specs/my-spec.md`). The script only includes files that are directly mentioned.\n- Verify the referenced file path is correct and the file exists.\n\n## Notes\n\n- The script's primary output is now an **actionable implementation plan**, not just a list of files.\n- The quality of the plan depends on the quality of the input (issue description, specs, retrospective).\n- The generated plan is a guide; use your own expertise to adapt and improve it as you work.\n- Branch naming follows the convention: `feat/ISSUE_NUMBER-kebab-case-title`.",
        "skills/issue-executor/references/work-on-issue.md": "# Work on Issue Workflow\n\nSelect and start work on a specific issue from assigned GitHub issues.\n\n## Purpose\n\nLoad full context for an issue and create a feature branch to begin implementation. Ensures clean workflow start with all necessary context loaded before any code is written.\n\n## When to Use\n\nUse this workflow when:\n- Starting work on a new issue\n- Switching between issues\n- After completing previous issue\n- Beginning work session\n\n## Workflow\n\n### 1. Verify Clean Working State\n\n```bash\n# Check current branch is clean\nCURRENT_BRANCH=$(git branch --show-current)\nif [ \"$CURRENT_BRANCH\" != \"main\" ]; then\n  echo \"⚠ Currently on branch: $CURRENT_BRANCH\"\n  echo \"Finish current work or switch to main first.\"\n  exit 1\nfi\n\n# Check for uncommitted changes\nif [ -n \"$(git status --porcelain)\" ]; then\n  echo \"⚠ Uncommitted changes detected\"\n  git status\n  echo \"Commit or stash changes before starting new issue.\"\n  exit 1\nfi\n```\n\n### 2. Get Current User's Assigned Issues\n\n```bash\n# Get all open issues assigned to current user\ngh issue list \\\n  --assignee @me \\\n  --state open \\\n  --json number,title,labels,milestone,createdAt \\\n  --limit 50 | jq '.'\n```\n\n### 3. Get Milestone Details for Context\n\n```bash\n# Get current sprint milestones\ngh api repos/:owner/:repo/milestones \\\n  --jq '.[] | select(.state == \"open\") | {number, title, state, dueOn}' \\\n  | jq -s 'sort_by(.dueOn)'\n```\n\n### 4. Check for Spec Conflicts\n\nFor each candidate issue, verify no conflicting work in progress:\n\n```bash\n# Extract affected specs from issue body\nISSUE_NUM=123\nAFFECTED_SPECS=$(gh issue view $ISSUE_NUM --json body --jq .body \\\n  | rg \"Affected Specs.*\" -A 5 \\\n  | rg \"docs/specs/([^/]+)\" -o -r '$1')\n\n# Check if any other open issues affect same specs\nfor SPEC in $AFFECTED_SPECS; do\n  CONFLICTS=$(gh issue list \\\n    --assignee @me \\\n    --state open \\\n    --search \"docs/specs/$SPEC in:body\" \\\n    --json number,title)\n\n  if [ $(echo \"$CONFLICTS\" | jq 'length') -gt 1 ]; then\n    echo \"⚠ Conflict detected: Multiple issues affect $SPEC\"\n    echo \"$CONFLICTS\" | jq -r '.[] | \"#\\(.number) - \\(.title)\"'\n  fi\ndone\n```\n\n### 5. Analyze and Recommend Issues\n\nSort and prioritize issues by:\n\n1. **Priority**: P0 > P1 > P2 > P3\n2. **Sprint alignment**: Current milestone first\n3. **Spec readiness**: Issues with existing specs\n4. **Dependencies**: Non-blocked issues first\n\n```bash\n# Parse priorities from labels\nP0_ISSUES=$(gh issue list --assignee @me --state open --label \"priority:P0\" --json number,title,milestone)\nP1_ISSUES=$(gh issue list --assignee @me --state open --label \"priority:P1\" --json number,title,milestone)\nP2_ISSUES=$(gh issue list --assignee @me --state open --label \"priority:P2\" --json number,title,milestone)\n\n# Show recommendations\necho \"=== Recommended Issues ===\"\necho \"\"\necho \"Priority P0 (Critical):\"\necho \"$P0_ISSUES\" | jq -r '.[] | \"  #\\(.number) - \\(.title) [\\(.milestone.title)]\"'\necho \"\"\necho \"Priority P1 (High):\"\necho \"$P1_ISSUES\" | jq -r '.[] | \"  #\\(.number) - \\(.title) [\\(.milestone.title)]\"'\necho \"\"\necho \"Priority P2 (Medium):\"\necho \"$P2_ISSUES\" | jq -r '.[] | \"  #\\(.number) - \\(.title) [\\(.milestone.title)]\"'\n```\n\nPresent top 3-5 recommendations:\n```\nTop recommendations:\n\n1. #201 - Curriculum Framework (P1, S2) ✓ Specs ready\n2. #202 - Lesson Player (P1, S2) ✓ Specs ready\n3. #203 - Virtual Laboratory System (P2, S2) ⚠ Depends on #201\n\nWhich issue would you like to start? (Enter number)\n```\n\n### 6. Read Full Issue Details\n\nAfter user selects issue:\n\n```bash\nISSUE_NUMBER=201\n\n# Read complete issue\ngh issue view $ISSUE_NUMBER\n\n# Read ALL comments (including review suggestions)\ngh issue view $ISSUE_NUMBER --comments\n```\n\n**IMPORTANT**: Pay special attention to review comments posted by `review-sprint`. These may include:\n- Architecture compliance suggestions\n- Wording and clarity improvements\n- Planning enhancements\n- Spec change recommendations\n\nConsider these suggestions during implementation but use your judgment on how to apply them.\n\n### 7. Extract and Validate Spec References\n\n```bash\n# Get issue body\nISSUE_BODY=$(gh issue view $ISSUE_NUMBER --json body --jq .body)\n\n# Extract affected specs\nAFFECTED_SPECS=$(echo \"$ISSUE_BODY\" | rg \"Affected Specs\" -A 10 | rg \"docs/specs/[^)]+\")\n\n# Verify each spec exists\necho \"Validating spec references...\"\nfor SPEC_PATH in $AFFECTED_SPECS; do\n  if [ -f \"$SPEC_PATH\" ]; then\n    echo \"✓ Found: $SPEC_PATH\"\n  else\n    echo \"✗ Missing: $SPEC_PATH\"\n    echo \"\"\n    echo \"⚠ Spec not found. Run 'init-spec' to create it first.\"\n    exit 1\n  fi\ndone\n```\n\n### 8. Check Related Issues and Dependencies\n\n```bash\n# Look for \"Related Issues\" section in issue body\nRELATED_ISSUES=$(echo \"$ISSUE_BODY\" | rg \"Related Issues\" -A 5 | rg \"#[0-9]+\" -o)\n\nif [ -n \"$RELATED_ISSUES\" ]; then\n  echo \"=== Related Issues ===\"\n  for RELATED in $RELATED_ISSUES; do\n    RELATED_NUM=$(echo \"$RELATED\" | tr -d '#')\n    RELATED_STATE=$(gh issue view $RELATED_NUM --json state --jq .state)\n    RELATED_TITLE=$(gh issue view $RELATED_NUM --json title --jq .title)\n\n    if [ \"$RELATED_STATE\" = \"OPEN\" ]; then\n      echo \"⚠ $RELATED - $RELATED_TITLE (OPEN - may be dependency)\"\n    else\n      echo \"✓ $RELATED - $RELATED_TITLE (CLOSED)\"\n    fi\n  done\nfi\n\n# Check for blocking issues\nBLOCKING=$(echo \"$ISSUE_BODY\" | rg -i \"blocked by|depends on\" -A 2)\nif [ -n \"$BLOCKING\" ]; then\n  echo \"\"\n  echo \"⚠ Warning: This issue may have dependencies:\"\n  echo \"$BLOCKING\"\n  echo \"\"\n  read -p \"Continue anyway? (y/n) \" -n 1 -r\n  echo\n  if [[ ! $REPLY =~ ^[Yy]$ ]]; then\n    echo \"Aborted. Select a different issue.\"\n    exit 1\n  fi\nfi\n```\n\n### 9. Read Affected Specs\n\n```bash\necho \"=== Reading Affected Specs ===\"\nfor SPEC_PATH in $AFFECTED_SPECS; do\n  echo \"\"\n  echo \"--- $SPEC_PATH ---\"\n  cat \"$SPEC_PATH\"\n  echo \"\"\ndone\n\n# If spec has design.md, read it too\nfor SPEC_PATH in $AFFECTED_SPECS; do\n  SPEC_DIR=$(dirname \"$SPEC_PATH\")\n  DESIGN_PATH=\"$SPEC_DIR/design.md\"\n\n  if [ -f \"$DESIGN_PATH\" ]; then\n    echo \"--- $DESIGN_PATH ---\"\n    cat \"$DESIGN_PATH\"\n    echo \"\"\n  fi\ndone\n```\n\n### 10. Read Development Retrospective\n\nRead accumulated learnings to inform implementation:\n\n```bash\nif [ -f \"RETROSPECTIVE.md\" ]; then\n  echo \"\"\n  echo \"=== Development Retrospective ===\"\n  cat RETROSPECTIVE.md\n  echo \"\"\n  echo \"Consider these learnings during implementation:\"\n  echo \"  - Apply success patterns from recent issues\"\n  echo \"  - Avoid known friction points\"\n  echo \"  - Reference well-specified capabilities\"\n  echo \"  - Follow active improvement initiatives\"\n  echo \"\"\nelif [ -f \"docs/RETROSPECTIVE.md\" ]; then\n  echo \"\"\n  echo \"=== Development Retrospective ===\"\n  cat docs/RETROSPECTIVE.md\n  echo \"\"\n  echo \"Consider these learnings during implementation.\"\n  echo \"\"\nelse\n  echo \"\"\n  echo \"ℹ No RETROSPECTIVE.md found (this is normal for first few issues)\"\n  echo \"\"\nfi\n```\n\n**Purpose**: The retrospective captures:\n- **Recent patterns**: What worked/didn't work in last 3-5 issues\n- **Historical wisdom**: Compressed learnings from earlier issues\n- **Spec quality**: Which specs are good references vs need improvement\n- **Active improvements**: Current process improvements being tracked\n\nThis context helps avoid repeating past mistakes and apply proven patterns.\n\n### 11. Create Feature Branch\n\n```bash\n# Extract title and create kebab-case branch name\nTITLE=$(gh issue view $ISSUE_NUMBER --json title --jq .title)\nKEBAB_TITLE=$(echo \"$TITLE\" | tr '[:upper:]' '[:lower:]' | sed -E 's/[^a-z0-9]+/-/g;s/^-|-$//g' | cut -c1-40)\n\n# Determine branch prefix from change type\nCHANGE_TYPE=$(echo \"$ISSUE_BODY\" | rg \"\\[x\\] (ADDED|MODIFIED|REMOVED)\" -o -r '$1')\n\ncase \"$CHANGE_TYPE\" in\n  \"ADDED\")\n    PREFIX=\"feat\"\n    ;;\n  \"MODIFIED\")\n    PREFIX=\"feat\"  # or \"refactor\" depending on scope\n    ;;\n  \"REMOVED\")\n    PREFIX=\"refactor\"\n    ;;\n  *)\n    # Infer from labels\n    if echo \"$ISSUE_BODY\" | rg -q \"type:bug\"; then\n      PREFIX=\"fix\"\n    elif echo \"$ISSUE_BODY\" | rg -q \"type:chore\"; then\n      PREFIX=\"chore\"\n    else\n      PREFIX=\"feat\"\n    fi\n    ;;\nesac\n\nBRANCH_NAME=\"${PREFIX}/${ISSUE_NUMBER}-${KEBAB_TITLE}\"\n\n# Create and switch to branch\ngit switch -c \"$BRANCH_NAME\"\n\necho \"✓ Created and switched to: $BRANCH_NAME\"\n```\n\n### 12. Initial Setup\n\nCheck if any setup is needed:\n\n```bash\n# Check if package.json changed recently (might need npm install)\nMAIN_PACKAGE_DATE=$(git log -1 --format=\"%ai\" main -- package.json 2>/dev/null)\nif [ -n \"$MAIN_PACKAGE_DATE\" ]; then\n  echo \"Note: package.json was updated recently ($MAIN_PACKAGE_DATE)\"\n  echo \"Running npm install...\"\n  npm install\nfi\n\n# Check if Prisma schema exists (might need generate)\nif [ -f \"prisma/schema.prisma\" ]; then\n  echo \"Note: Prisma schema detected\"\n  echo \"Running npx prisma generate...\"\n  npx prisma generate\nfi\n\n# Check for other setup scripts\nif [ -f \"scripts/setup.sh\" ]; then\n  echo \"Note: Found setup script\"\n  echo \"Running scripts/setup.sh...\"\n  bash scripts/setup.sh\nfi\n```\n\n### 13. Update TODO.md\n\nAdd issue to \"In Progress\" section:\n\n```markdown\n## In Progress\n\n- [ ] #201 - Curriculum Framework (feat/201-curriculum-framework)\n  - **Started**: 2025-10-21\n  - **Branch**: feat/201-curriculum-framework\n  - **Specs**: docs/specs/curriculum-management/spec.md\n  - **Priority**: P1\n  - **Milestone**: S2\n```\n\nIf TODO.md doesn't have \"In Progress\" section, create it:\n\n```bash\n# Check if section exists\nif ! grep -q \"## In Progress\" TODO.md; then\n  # Add section after sprint section\n  sed -i '/^## Phase/a \\\\n## In Progress\\n' TODO.md\nfi\n\n# Add issue entry\ncat >> TODO.md << EOF\n\n- [ ] #${ISSUE_NUMBER} - ${TITLE} (${BRANCH_NAME})\n  - **Started**: $(date +%Y-%m-%d)\n  - **Branch**: ${BRANCH_NAME}\n  - **Specs**: ${AFFECTED_SPECS}\n  - **Priority**: ${PRIORITY}\n  - **Milestone**: ${MILESTONE}\nEOF\n```\n\n### 14. Update Sprint File\n\nFind the relevant sprint file and update story status:\n\n```bash\n# Find sprint file (match milestone to sprint file)\nMILESTONE=$(gh issue view $ISSUE_NUMBER --json milestone --jq .milestone.title)\nSPRINT_NUM=$(echo \"$MILESTONE\" | rg \"S([0-9]+)\" -o -r '$1')\nSPRINT_FILE=\"docs/sprint/S${SPRINT_NUM}.md\"\n\nif [ -f \"$SPRINT_FILE\" ]; then\n  # Find the story section and update status\n  # This is complex; in practice, manually update the file\n  echo \"Update $SPRINT_FILE:\"\n  echo \"  - Find story section for: $TITLE\"\n  echo \"  - Add: **Status**: In Progress\"\n  echo \"  - Add: **Branch**: $BRANCH_NAME\"\n  echo \"  - Add: **Started**: $(date +%Y-%m-%d)\"\nfi\n```\n\nExample sprint file update:\n\n```markdown\n## Curriculum Framework\n\n**User Story**: As an educator...\n\n**Status**: In Progress\n**Branch**: feat/201-curriculum-framework\n**Started**: 2025-10-21\n**Issue**: #201\n```\n\n### 15. Provide Summary\n\n```\n✓ Started work on issue #201\n\nIssue: Curriculum Framework\nBranch: feat/201-curriculum-framework\nPriority: P1\nMilestone: S2\n\nAffected specs:\n  - docs/specs/curriculum-management/spec.md\n\nReview comments: 1 comment (review suggestions available)\n\nNext steps:\n  1. Review issue comments and review suggestions\n  2. Review spec requirements and scenarios\n  3. Implement according to acceptance criteria (considering review feedback)\n  4. Write tests per test plan\n  5. Run 'test-issue' before submitting\n  6. Run 'submit-issue' when ready for PR\n\nDependencies to watch:\n  - None identified\n\nHappy coding! 🚀\n```\n\n## Priority Order\n\nIssues are recommended in this order:\n\n1. **P0 - Critical**: Blocking bugs, production issues\n2. **P1 - High**: Important features, high-value work\n3. **P2 - Medium**: Standard features, improvements\n4. **P3 - Low**: Nice-to-have, technical debt\n\nWithin same priority:\n- Current sprint milestone before future sprints\n- Issues with ready specs before those needing spec work\n- Non-blocked issues before those with dependencies\n\n## Dependency Checking\n\n### Types of Dependencies\n\n1. **Hard dependencies**: \"Blocked by #123\", \"Depends on #123\"\n   - Must be completed first\n   - Halt if not complete\n\n2. **Soft dependencies**: \"Related to #123\", \"See also #123\"\n   - Provide context but not blocking\n   - Read for additional information\n\n3. **Spec dependencies**: One spec depends on another\n   - Check if dependency specs exist\n   - Verify dependency requirements are clear\n\n### Handling Blocked Issues\n\nIf selected issue is blocked:\n\n```\n⚠ Issue #203 is blocked by #201 (Curriculum Framework)\n\n#201 status: In Progress (50% complete)\n\nOptions:\n1. Wait for #201 to complete\n2. Select different issue\n3. Proceed with risk (may need rework)\n\nRecommendation: Select different issue and return to #203 later.\n```\n\n## Spec Readiness Validation\n\nBefore starting work, ensure:\n\n- [ ] All referenced specs exist in `docs/specs/`\n- [ ] Specs have clear requirements\n- [ ] Each requirement has scenarios\n- [ ] Dependencies between specs are documented\n- [ ] Design docs exist for complex changes\n\nIf spec is incomplete:\n1. Consider running `init-spec` to complete it\n2. Or flag issue for spec refinement before starting\n\n## File Update Patterns\n\n### TODO.md Format\n\n```markdown\n## In Progress\n\n- [ ] #201 - Curriculum Framework (feat/201-curriculum-framework)\n  - **Started**: 2025-10-21\n  - **Branch**: feat/201-curriculum-framework\n  - **Specs**: docs/specs/curriculum-management/spec.md\n  - **Priority**: P1\n  - **Milestone**: S2\n  - **Dependencies**: None\n```\n\n### Sprint File Format\n\n```markdown\n## Curriculum Framework\n\n**User Story**: As an educator, I want to define course structures...\n\n**Acceptance Criteria**:\n- Course hierarchy supported\n- Learning objectives trackable\n\n**Status**: In Progress\n**Branch**: feat/201-curriculum-framework\n**Started**: 2025-10-21\n**Issue**: #201\n**Assigned**: @username\n```\n\n## Error Handling\n\n### Dirty Working Directory\n\n```\n⚠ Error: Uncommitted changes detected\n\nPlease commit or stash changes before starting new issue:\n  git add .\n  git commit -m \"wip: save progress\"\n  # or\n  git stash\n\nThen run 'next-issue' again.\n```\n\n### Not on Main Branch\n\n```\n⚠ Error: Currently on branch: feat/123-old-issue\n\nPlease finish current work first:\n  1. Complete implementation\n  2. Run 'submit-issue' to create PR\n  3. Or: git switch main (to abandon work)\n\nThen run 'next-issue' again.\n```\n\n### Missing Specs\n\n```\n⚠ Error: Spec not found\n  docs/specs/curriculum-management/spec.md\n\nIssue #201 references specs that don't exist yet.\n\nAction required:\n  1. Run: init-spec curriculum-management\n  2. Create spec.md with requirements\n  3. Run 'next-issue' again\n```\n\n### No Available Issues\n\n```\nℹ No issues assigned to you.\n\nPossible actions:\n  1. Check sprint backlog in GitHub\n  2. Assign yourself an issue from current sprint\n  3. Run 'seed-sprint' to create new issues\n  4. Contact Scrum Master for assignment\n```\n\n## Advanced: Context Caching\n\nTo optimize repeated API calls, consider caching:\n\n```bash\n# Cache issue list for 5 minutes\nCACHE_FILE=\"/tmp/gh-issues-cache-$(date +%Y%m%d-%H%M).json\"\nif [ ! -f \"$CACHE_FILE\" ]; then\n  gh issue list --assignee @me --state open --json number,title,labels,milestone > \"$CACHE_FILE\"\nfi\n\n# Use cached data\nISSUES=$(cat \"$CACHE_FILE\")\n```\n\n## Notes\n\n- Always verify clean state before starting new work\n- Read all related issues for full context\n- Check spec completeness before implementation\n- Update tracking files immediately after branch creation\n- Consider dependencies when selecting issues\n- Prefer current sprint issues over future work\n- Validate specs exist and are complete\n- Note any setup requirements (npm install, prisma generate, etc.)\n",
        "skills/prd-authoring/SKILL.md": "---\nname: prd-authoring\ndescription: Use this skill for early-stage project planning. It leverages the Gemini CLI to generate high-quality first drafts of Product Briefs, Research Documents, and full PRDs, guiding users from idea to validated requirements. Triggers include \"create PRD\", \"product brief\", or \"validate requirements\".\n---\n\n# PRD Authoring Skill\n\n## Purpose\n\nTo accelerate and enhance early-stage project planning by using a powerful generative AI to create high-quality first drafts of key strategic documents. This skill integrates the Gemini CLI into the PRD authoring workflow, transforming it from a manual template-filling exercise into a dynamic, AI-assisted process.\n\nThe skill guides users from a vague project idea to a well-defined Product Requirements Document (PRD) by:\n- **Generating a Product Brief:** Creates a comprehensive brief from a simple project name.\n- **Generating a Research Plan:** Uses the product brief to generate a targeted research document.\n- **Generating a full PRD:** Synthesizes the brief and research into a detailed PRD with objectives, requirements, and success criteria.\n\nThis approach bridges the gap between \"we have an idea\" and \"we're ready to write specs\" with unprecedented speed and quality.\n\n## When to Use\n\nUse this skill in the following situations:\n\n- Starting a new project from an initial concept.\n- Generating a first draft of a product brief, research plan, or PRD.\n- Validating an existing PRD against quality standards.\n- Breaking down a PRD into epics for sprint planning.\n\nDo NOT use this skill for:\n- Implementation-level specifications (use spec-authoring instead).\n- Sprint planning from approved specs (use sprint-planner instead).\n\n## Prerequisites\n\n- Project initialized with AgenticDev structure (`docs/` directory exists).\n- `gemini` CLI tool installed and authenticated.\n\n## PRD Philosophy\n\n**Strategy Before Tactics**: PRDs define WHAT we're building and WHY before specs define HOW we'll build it. This skill uses AI to rapidly generate the \"WHAT\" and \"WHY\" so that teams can focus on review, refinement, and strategic alignment.\n\n---\n\n## Workflow Commands\n\n### The `status` Command\n\n#### Purpose\n\nAssess project readiness and provide guidance on next workflow steps. This is the recommended starting point.\n\n#### Workflow\n\nRun the status check to understand the current state of your PRD documents.\n```bash\nbash scripts/prd-authoring.sh status [project-name]\n```\nThe script will report which documents exist (`product-brief.md`, `research.md`, `prd.md`, etc.) and recommend the next logical command to run.\n\n---\n\n### The `brief` Command\n\n#### Purpose\n\nGenerate a comprehensive, high-quality first draft of a Product Brief from a simple project name.\n\n#### Workflow\n\n##### Step 1: Run Brief Generation Script\n\nExecute the script with your project name.\n```bash\nbash scripts/prd-authoring.sh brief \"Your Awesome Project Name\"\n```\n\n##### Step 2: Understand What the Script Does\n\nInstead of creating an empty template, the script calls the **Gemini CLI** with a detailed prompt, asking it to generate a full product brief. This includes plausible, well-structured content for:\n- Problem Statement\n- Target Users\n- Proposed Solution\n- Value Proposition\n- Success Metrics\n\nThe output from Gemini is saved as the first draft in `docs/prds/your-awesome-project-name/product-brief.md`.\n\n##### Step 3: Review and Refine\n\nOpen the generated file. Review the AI-generated content with your team and stakeholders, refining the details to match your specific vision. The draft provides a strong foundation, saving hours of initial writing.\n\n---\n\n### The `research` Command\n\n#### Purpose\n\nGenerate a targeted, context-aware market research plan based on the contents of your product brief.\n\n#### Workflow\n\n##### Step 1: Run Research Generation Script\n\nOnce your product brief is reviewed and saved, run the research command:\n```bash\nbash scripts/prd-authoring.sh research your-awesome-project-name\n```\n\n##### Step 2: Understand What the Script Does\n\nThe script sends the entire content of your `product-brief.md` to the **Gemini CLI**. It prompts the AI to act as a business analyst and generate a research plan that logically follows from the brief. The generated draft will include sections for:\n- Competitive Analysis\n- Market Insights\n- User Feedback Analysis\n- Technical Considerations\n- Actionable Recommendations\n\nThis draft is saved to `docs/prds/your-awesome-project-name/research.md`.\n\n##### Step 3: Execute Research and Refine Document\n\nUse the AI-generated document as a guide for your research activities. Fill in the details and refine the analysis based on your actual findings.\n\n---\n\n### The `create-prd` Command\n\n#### Purpose\n\nGenerate a comprehensive, detailed first draft of a Product Requirements Document (PRD) by synthesizing the product brief and the research document.\n\n#### Workflow\n\n##### Step 1: Run PRD Creation Script\n\nAfter completing your brief and research documents, run the `create-prd` command:\n```bash\nbash scripts/prd-authoring.sh create-prd your-awesome-project-name\n```\n\n##### Step 2: Understand What the Script Does\n\nThis is the most powerful feature. The script sends the **full content of both your product brief and your research document** to the **Gemini CLI**. It prompts the AI to generate a detailed PRD that includes:\n- SMART Objectives\n- Measurable Success Criteria\n- Specific Functional and Non-Functional Requirements\n- Constraints, Assumptions, and Out-of-Scope items\n\nThe resulting draft, saved in `docs/prds/your-awesome-project-name/prd.md`, is a deeply contextualized document that connects business goals from the brief with insights from the research.\n\n##### Step 3: Review, Validate, and Refine\n\nThe generated PRD provides an excellent starting point. Review it with your team to ensure all requirements are accurate, testable, and aligned with project goals. Use the `validate-prd` command to check for quality.\n\n---\n\n### The `validate-prd` Command\n\n#### Purpose\n\nValidate an existing PRD against quality standards, checking for missing sections, vague requirements, and unmeasurable success criteria. This command does **not** use the Gemini CLI; it uses pattern matching to enforce quality.\n\n#### Workflow\n\nRun the validation check on your PRD:\n```bash\nbash scripts/prd-authoring.sh validate-prd your-awesome-project-name\n```\nReview the report and address any issues found.\n\n---\n\n### The `decompose` Command\n\n#### Purpose\n\nBreak down a validated PRD into epics for sprint planning. This helps transition from strategic planning to tactical execution.\n\n#### Workflow\n\nOnce your PRD is validated, run the decompose command:\n```bash\nbash scripts/prd-authoring.sh decompose your-awesome-project-name\n```\nThis creates an `epics.md` file with a template structure for you to define your epics.\n\n---\n\n## Error Handling and Troubleshooting\n\n### Gemini CLI Issues\n\n**Symptom**: The script fails during the `brief`, `research`, or `create-prd` commands with an error related to the `gemini` command.\n\n**Solution**:\n- Ensure the `gemini` CLI is installed and in your system's PATH.\n- Verify you are authenticated. Run `gemini auth` if needed.\n- Check for any Gemini API-related issues or outages.\n- Examine the prompt being constructed in the `prd-authoring.sh` script for any potential issues.\n\n### Other Issues\n\nFor issues related to file existence, permissions, or validation errors, the script provides detailed error messages and recommendations. Always check the script's output for guidance.\n\n---\n\n## Best Practices\n\n- **Review and Refine**: The AI-generated drafts are a starting point, not a final product. Always review and tailor the content to your specific project needs.\n- **Garbage In, Garbage Out**: The quality of the generated `research` and `prd` documents depends on the quality of the `product-brief` you provide. Take time to refine the initial brief.\n- **Iterate**: Use the `status` command to guide you through the workflow. Don't be afraid to go back and refine a previous document if new insights emerge.",
        "skills/prd-authoring/examples/01-product-brief-example.md": "---\ntitle: Payment Gateway Integration\ntype: product-brief\nstatus: draft\ncreated: 2025-11-04\nupdated: 2025-11-04\n---\n\n# Product Brief: Payment Gateway Integration\n\n## Problem Statement\n\n**What problem exists?**\nOur e-commerce platform currently lacks integrated payment processing capabilities, forcing customers to complete purchases through manual invoice processing. This creates significant friction in the buying process, with 45% of customers abandoning their carts during checkout when they discover they cannot pay immediately online.\n\n**Who experiences this problem?**\n- E-commerce customers attempting to purchase products online (15,000 unique monthly visitors)\n- Sales team manually processing invoices and payment confirmations (handling 800-1,000 transactions/month)\n- Finance team reconciling payments and updating accounting systems (20 hours/week manual work)\n- Customer support handling payment-related inquiries (30% of all support tickets)\n\n**How often does it occur?**\n- Affects 100% of purchase transactions (approximately 1,000 transactions per month)\n- Daily manual payment processing required for 30-40 orders\n- Weekly reconciliation bottlenecks cause 2-3 day delays in order fulfillment\n\n**What's the business impact?**\n- Lost revenue: $2.4M annually from cart abandonment (45% abandonment rate on $5.3M annual pipeline)\n- Operational costs: $120K/year in manual payment processing labor (sales + finance teams)\n- Customer satisfaction: NPS score of 35 (below industry average of 50) with payment process cited as top complaint\n- Competitive disadvantage: Losing deals to competitors with seamless online checkout\n\n## Target Users\n\n### Primary Users\n\n**Persona 1: Online Shopper (Sarah)**\n- **Who they are**: Tech-savvy consumers aged 25-45, making purchases $50-$500, expect modern e-commerce experience\n- **Key goals**: Complete purchases quickly and securely, receive instant confirmation, avoid payment delays\n- **Pain points**: Cannot pay online, must wait for invoice email, manual payment is time-consuming and feels outdated\n- **Frequency of use**: 1-3 purchases per month, expect to checkout in under 2 minutes\n\n**Persona 2: Sales Representative (Mike)**\n- **Who they are**: Inside sales team member, processes 25-30 orders daily, manages customer relationships\n- **Key goals**: Close deals faster, reduce administrative work, focus on selling not payment processing\n- **Pain points**: Spends 2 hours daily creating invoices and following up on payments, manual errors cause delays\n- **Frequency of use**: Multiple times daily, processes every transaction\n\n### Secondary Users\n\n- **Finance Team**: Needs automated reconciliation and accurate transaction records, currently spends 20 hours/week on manual entry\n- **Customer Support**: Handles payment status inquiries and issues, needs visibility into transaction status\n- **Business Leadership**: Requires revenue reporting, conversion metrics, and fraud prevention\n\n## Proposed Solution\n\n**Solution Overview**\nIntegrate a best-in-class payment gateway (Stripe) to enable secure, real-time online payment processing with support for credit/debit cards, digital wallets (Apple Pay, Google Pay), and one-click checkout for returning customers. The solution will automate payment processing, provide instant confirmation, and integrate with our existing CRM and accounting systems.\n\n**How it addresses the problem**\nBy enabling online payment processing, customers can complete purchases immediately without friction, eliminating the manual invoice workflow. Sales team can focus on selling instead of payment administration, finance team benefits from automated reconciliation, and the business captures revenue that was previously lost to abandonment.\n\n**Key capabilities**\n- Secure payment processing for credit/debit cards and digital wallets with PCI DSS compliance\n- One-click checkout for returning customers with saved payment methods\n- Real-time payment confirmation and automated receipt generation\n- Integration with Salesforce CRM for order management and customer records\n- Automated reconciliation with QuickBooks accounting system\n- Fraud detection and prevention with 3D Secure 2.0\n\n**What makes this solution different?**\nUnlike our current manual process, this provides instant payment processing (under 3 seconds) with zero manual intervention. Compared to basic payment gateways, we're choosing Stripe for its superior developer experience, comprehensive documentation, and proven reliability at scale.\n\n## Value Proposition\n\n### User Benefits\n\n- **Speed**: Reduce checkout time from 24-48 hours (manual invoice) to under 60 seconds (online payment)\n- **Convenience**: Pay with preferred method (card, Apple Pay, Google Pay) without leaving the site\n- **Security**: PCI-compliant payment processing eliminates concerns about sharing card details\n- **Trust**: Instant confirmation email and receipt provides peace of mind\n- **Returning customers**: Save payment method for one-click future purchases\n\n### Business Benefits\n\n- **Revenue**: Reduce cart abandonment from 45% to 15%, recovering $1.8M in annual revenue\n- **Operational efficiency**: Eliminate 20 hours/week of manual payment processing, saving $100K annually\n- **Cash flow**: Accelerate payment collection from 3-5 days to instant, improving cash flow by $200K\n- **Scalability**: Support 10x growth without adding payment processing headcount\n- **Data insights**: Real-time transaction analytics and conversion funnel visibility\n- **Customer satisfaction**: Improve NPS score from 35 to 55+ with modern checkout experience\n\n### Competitive Advantages\n\n- Achieve parity with competitors on basic online payment capability (table stakes)\n- Differentiate with faster checkout experience (target: under 60 seconds vs industry average 2-3 minutes)\n- Build foundation for future innovations: subscription billing, international expansion, marketplace features\n- Create switching cost through saved payment methods and purchase history\n\n## Success Metrics\n\n### Launch Success Criteria\n<!-- Metrics that indicate a successful launch (measured in first 30 days) -->\n\n- **Checkout conversion rate**: 55% → 75% (reduce abandonment from 45% to 25%)\n- **Average checkout time**: N/A (manual) → 45 seconds (90th percentile)\n- **Payment success rate**: N/A → 98% (transactions completed successfully)\n- **Customer satisfaction**: 35 NPS → 50+ NPS for checkout experience\n- **Payment processing uptime**: Target 99.9% (maximum 45 minutes downtime per month)\n\n### Long-term Success Metrics\n<!-- Metrics tracked over 6-12 months post-launch -->\n\n- **Monthly transaction volume**: 1,000 → 5,000 transactions per month within 6 months\n- **Revenue recovery**: Recover $1.5M+ in previously abandoned cart revenue within 12 months\n- **Saved payment method adoption**: 60% of customers save payment method for future use\n- **Operational cost reduction**: Reduce manual payment processing costs by 80% ($100K annual savings)\n- **Average order value**: Increase from $275 to $325 due to reduced friction\n\n### Leading Indicators\n<!-- Early signals that predict success -->\n\n- First-week transaction volume exceeds 100 successful payments\n- 70%+ of users complete checkout without contacting support\n- Less than 5% of transactions require sales team intervention\n- Payment-related support tickets decrease by 50% in first month\n- 80%+ customer satisfaction rating on post-purchase survey\n",
        "skills/prd-authoring/examples/02-research-example.md": "---\ntitle: Payment Gateway Integration Research\ntype: research\nstatus: complete\ncreated: 2025-11-04\nupdated: 2025-11-04\n---\n\n# Research: Payment Gateway Integration\n\n## Competitive Analysis\n\n### Competitor 1: Stripe\n\n**Overview**\nMarket leader in developer-focused payment processing with 40%+ market share among tech companies. Powers payment processing for millions of businesses worldwide including Amazon, Shopify, and Lyft.\n\n**Strengths**\n- Superior API design and documentation (rated #1 by developers)\n- Supports 135+ currencies and 45+ countries\n- Comprehensive fraud detection with Radar (machine learning-based)\n- Strong developer ecosystem with extensive libraries\n- Excellent uptime (99.99% historical availability)\n- Built-in PCI compliance (SAQ-A eligible)\n- Transparent, predictable pricing\n\n**Weaknesses**\n- Higher fees for international cards (3.9% + $0.30 vs 2.9% + $0.30 domestic)\n- Limited phone support (primarily email and chat)\n- Can hold funds for new accounts (rolling reserve for high-risk industries)\n\n**Key Features**\n- Payment processing (cards, wallets, bank transfers)\n- Recurring billing and subscription management\n- Payment method tokenization\n- 3D Secure 2.0 and fraud detection\n- Real-time webhooks\n- Mobile SDKs for iOS and Android\n\n**Pricing Model**\nStandard: 2.9% + $0.30 per successful card charge (US domestic), 3.9% + $0.30 for international. No setup or monthly fees.\n\n**Market Position**\nPremium developer-friendly solution targeting startups, SaaS companies, and growth-stage businesses.\n\n**Our Advantage Over Them**\nWe leverage their strengths while they handle payment processing complexity, compliance, and fraud detection.\n\n---\n\n### Competitor 2: PayPal/Braintree\n\n**Overview**\nConsumer payment giant with 400M+ active accounts. Braintree is PayPal's developer product. Strong brand recognition and customer trust.\n\n**Strengths**\n- Massive user base (400M+ PayPal accounts)\n- Strong buyer trust and brand recognition\n- Built-in buyer protection\n- Venmo integration\n- International presence in 200+ markets\n\n**Weaknesses**\n- Higher dispute and chargeback rates\n- More complex API compared to Stripe\n- Account holds more common\n- Slower innovation\n\n**Key Features**\n- PayPal checkout\n- Credit/debit cards via Braintree\n- Venmo integration\n- PayPal Credit (BNPL)\n- Recurring billing support\n\n**Pricing Model**\nPayPal Standard: 3.49% + $0.49, Braintree: 2.59% + $0.49\n\n**Market Position**\nConsumer-focused platform with strong brand trust, prioritizing buyer confidence over developer experience.\n\n**Our Advantage Over Them**\nPayPal's higher fees and complex integration make Stripe more attractive. May add PayPal in Phase 2.\n\n---\n\n### Competitor 3: Square\n\n**Overview**\nPayment processor for small businesses and omnichannel commerce. Known for simple pricing and POS hardware.\n\n**Strengths**\n- Unified platform for in-person and online\n- Simple, flat-rate pricing\n- No monthly fees or commitments\n- Fast payouts (next business day)\n- Integrated POS hardware\n\n**Weaknesses**\n- Limited international support\n- Fewer currencies than Stripe\n- Less sophisticated API capabilities\n- Higher fees for keyed transactions\n\n**Key Features**\n- Card processing (in-person and online)\n- Square Terminal and readers\n- Inventory management\n- Invoicing and recurring payments\n- E-commerce integration\n\n**Pricing Model**\nOnline: 2.9% + $0.30, In-person: 2.6% + $0.10, Keyed: 3.5% + $0.15. No monthly fees.\n\n**Market Position**\nSmall business and retail-focused, positioned as simple all-in-one for businesses needing both online and in-person.\n\n**Our Advantage Over Them**\nSquare is optimized for retail/POS, not pure e-commerce. Stripe's API-first approach suits our needs better.\n\n---\n\n## Market Insights\n\n### Market Size & Growth\nGlobal digital payment market: $79.3B in 2020 → $154.1B by 2025 (14.2% CAGR). Growth drivers: e-commerce adoption, shift from cash, mobile wallets, subscriptions.\n\n**Primary segment: E-commerce businesses (SMB)**\n- Size: 2.1 million e-commerce businesses in US\n- Growth rate: 15% annual growth\n- Key characteristics: Need reliable, easy-to-integrate processing with low fixed costs\n\n### Market Trends\n- Mobile wallet adoption: 25% of e-commerce transactions (up from 10% in 2020)\n- One-click checkout: 40% abandon if they must re-enter payment details\n- Buy Now, Pay Later: 300% growth since 2020 for purchases >$200\n- Fraud concerns: $20B globally in 2021, driving demand for advanced detection\n- Embedded finance: Payment processing embedded directly in software platforms\n\n### Regulatory & Compliance\n- PCI DSS Level 1: Required for card processing; using tokenization (SAQ-A) reduces compliance burden\n- Strong Customer Authentication (SCA): EU regulation requiring 2FA; 3D Secure 2.0 is table stakes\n- Data privacy (GDPR, CCPA): Payment data subject to strict privacy regulations\n\n### Industry Standards & Best Practices\n- OAuth 2.0 for API authentication\n- 3D Secure 2.0 for SCA compliance\n- Tokenization (never store card numbers)\n- Webhooks for async events\n- TLS 1.3 for encryption\n- CVV verification for fraud reduction\n\n## User Feedback Analysis\n\n### Common Pain Points\n\n1. **Checkout complexity**: 70% mention as pain point. \"I filled my cart but gave up at the 8-step checkout\"\n   - Impact: 69.8% average cart abandonment rate\n\n2. **Payment method limitations**: 40% request more options. \"No Apple Pay, went to competitor\"\n   - Impact: 10-15% abandon if preferred method unavailable\n\n3. **Security concerns**: 55% cite as top concern. \"Don't feel safe entering card on small websites\"\n   - Impact: Trust badges increase conversion 20-30%\n\n4. **Re-entering information**: 60% of returning customers frustrated. \"Why can't this site remember my card like Amazon?\"\n   - Impact: Saved methods reduce checkout time 75%\n\n5. **Slow processing**: 30% mention frustration. \"Waited 10 seconds, thought it failed\"\n   - Impact: Each second reduces conversions 7%\n\n### Desired Features\n\n**Must-have** (Table stakes)\n- Credit/debit card acceptance (Visa, MC, Amex, Discover)\n- Mobile-responsive checkout\n- Secure processing with trust indicators\n- Email receipt and confirmation\n- Basic fraud detection\n\n**High-value** (Differentiators)\n- Digital wallets (Apple Pay, Google Pay)\n- One-click for returning customers\n- Guest checkout option\n- Real-time updates during checkout\n- Instant confirmation\n\n**Nice-to-have** (Future)\n- Buy now, pay later (Klarna, Affirm)\n- Cryptocurrency support\n- International currencies\n- Subscription billing\n\n### User Preferences & Expectations\n- Checkout speed: Complete within 60 seconds (2 min maximum tolerance)\n- Payment security: Want trust badges, recognizable brands\n- Guest checkout: 25% prefer not to create account first\n- Save payment: 70% willing if they trust the site\n- Mobile: 60% of traffic; expect wallet options\n- Error messages: Want clear, actionable feedback\n\n## Technical Considerations\n\n### Competitor Technical Approaches\n- **Tokenization**: All providers use it to avoid storing card data (SAQ-A vs SAQ-D compliance)\n- **Integration patterns**: Hosted (easiest), Elements (balanced), API (most flexible)\n- **Webhooks**: All use for async event handling (requires retry logic, idempotency)\n\n### Architecture Patterns\n- **PSP pattern**: Use third-party provider vs building in-house\n  - Pros: Fast deployment, reduced compliance, proven reliability\n  - Cons: Dependency, transaction fees\n  - Recommendation: Strongly recommended\n\n- **Event-driven**: Use webhooks for downstream actions\n  - Pros: Decouples payment from business logic\n  - Cons: Requires robust event processing\n  - Recommendation: Essential for production\n\n### Integration Requirements\n- Stripe SDK: REST API + JavaScript SDK\n- CRM: Salesforce (update customer records, orders)\n- Accounting: QuickBooks (automated posting, reconciliation)\n- Email: SendGrid (confirmations, receipts, failures)\n\n### Performance & Scalability\n- Expected load: 1,000/month currently, 5,000/month in 6 months\n- Performance targets: API <500ms p95, checkout <3s total, page load <2s\n- Scalability: Stripe handles scaling, we need webhook queue for high volume\n\n### Technical Risks\n- Stripe downtime: 99.99% uptime but would block all payments\n  - Mitigation: Graceful degradation, monitoring, communication plan\n\n- Webhook failures: Network issues could cause missed events\n  - Mitigation: Stripe retries for 3 days, implement idempotency, poll as backup\n\n- PCI violations: Improper storage could result in fines\n  - Mitigation: Never store cards, use tokens, annual SAQ-A, security audits\n\n- Fraud: Costs 2-3x transaction amount\n  - Mitigation: Stripe Radar, CVV required, 3D Secure, velocity limits\n\n## Recommendations\n\n### Priority Features\n\n**Must-build**\n1. Credit/debit card processing - 100% of competitors have this, 80% of transactions\n2. PCI compliance - Legal requirement, use Stripe tokenization for SAQ-A\n3. Mobile-responsive - 60% of traffic is mobile\n4. Basic fraud detection - 1-2% fraud rate costs 2-3x transaction value\n\n**Should-build**\n1. Digital wallets - 25% of transactions, converts 10-15% higher\n2. Saved payment methods - 75% faster checkout, 30-40% higher repeat rate\n3. CRM/accounting integration - Saves $100K annually in manual work\n\n**Could-build**\n- BNPL (Phase 2), Cryptocurrency (Phase 3), Subscriptions (Phase 2)\n\n### Technical Approach\n\n**Recommended**: Cloud-native API integration with event-driven fulfillment\n\n**Key choices**:\n- Payment processor: Stripe (best DX, features, pricing, documentation)\n- Integration: Stripe Elements (balances customization with ease)\n- Backend: Stripe Node.js SDK\n- Events: Webhook processing with queue (Bull/Redis or SQS)\n- Database: Add payment_methods and transactions tables (metadata only, no card data)\n\n### Go-to-Market Positioning\n\"Complete your purchase in under 60 seconds with secure, one-click checkout - just like major e-commerce brands\"\n\n**Target**: E-commerce customers (B2C) expecting modern, frictionless experiences\n\n**Differentiators**:\n- 60 seconds vs 3-5 minutes competitors\n- Amazon-like one-click for returning customers\n- Multiple payment methods including Apple/Google Pay\n- Enterprise security with consumer UX\n\n### Constraints & Considerations\n\n**Compliance**: PCI DSS SAQ-A (cannot store card numbers)\n\n**Budget**: 2.9% + $0.30 = $99K annually at 1,000 transactions averaging $275\n- Acceptable given $1.8M revenue recovery\n\n**Timeline**: Q2 2026 (6 months) - favors proven solutions\n\n**Resources**: 2 FE, 1 BE, 1 QA - must use SDK/libraries, not build from scratch\n\n### Risk Assessment\n\n1. **Stripe dependency**\n   - Likelihood: Low, Impact: High\n   - Mitigation: Monitor status, communication plan, backup provider Phase 2\n\n2. **Fraud/chargebacks**\n   - Likelihood: Medium (1-2%), Impact: Medium ($200-500 per incident)\n   - Mitigation: Radar, CVV, velocity limits, 3D Secure for high-value\n\n3. **Integration complexity**\n   - Likelihood: Medium, Impact: Medium (delay or missing features)\n   - Mitigation: Official SDKs, integration guides, schedule buffer\n\n4. **User adoption of saved payments**\n   - Likelihood: Low (60-70% industry), Impact: Low\n   - Mitigation: Security messaging, trust indicators, incentives\n\n5. **Compliance violations**\n   - Likelihood: Low (following best practices), Impact: High (fines, loss of processing)\n   - Mitigation: Never store cards, annual SAQ-A, security audits\n",
        "skills/prd-authoring/examples/03-prd-example-abbreviated.md": "---\ntitle: Payment Gateway Integration PRD\ntype: prd\nstatus: draft\ncreated: 2025-11-04\nupdated: 2025-11-04\n---\n\n# Product Requirements Document: Payment Gateway Integration\n\n## Objectives\n\n### Primary Objectives\n\n1. **Enable Real-time Online Payment Processing**\n   - **Goal**: Allow customers to complete purchases instantly without manual invoice processing\n   - **Measure**: Checkout conversion rate and average checkout time\n   - **Target**: 75% conversion rate (up from 55%), average checkout time under 45 seconds\n   - **Timeline**: Launch by Q2 2026, achieve targets within 3 months post-launch\n   - **Why it matters**: Eliminates primary source of cart abandonment (45% currently) and recovers $1.8M in lost annual revenue\n\n2. **Reduce Operational Costs and Manual Work**\n   - **Goal**: Automate payment processing and reconciliation to eliminate manual labor\n   - **Measure**: Hours spent on manual payment processing and reconciliation\n   - **Target**: Reduce from 20 hours/week to 4 hours/week (80% reduction)\n   - **Timeline**: Immediate upon launch\n   - **Why it matters**: Saves $100K annually in labor costs, allows sales/finance teams to focus on high-value work\n\n3. **Improve Customer Satisfaction with Modern Checkout**\n   - **Goal**: Provide seamless, secure checkout experience matching major e-commerce sites\n   - **Measure**: NPS score for checkout experience and payment-related support tickets\n   - **Target**: NPS 50+ (up from 35), reduce payment support tickets by 50%\n   - **Timeline**: Measure within 30 days post-launch\n   - **Why it matters**: Customer satisfaction drives repeat purchases and positive word-of-mouth\n\n### Secondary Objectives\n\n1. Enable subscription and recurring billing capabilities (Phase 2 - deferred 6-12 months)\n2. Support international currencies and payment methods (Phase 2 - market dependent)\n\n## Success Criteria\n\n### Launch Criteria (Must-Have)\n\n**Functional Completeness**\n- [ ] Process 100 test transactions with 0% failure rate\n- [ ] Support card payments (Visa, MC, Amex, Discover) and digital wallets (Apple Pay, Google Pay)\n- [ ] One-click checkout functional for returning customers with saved payment methods\n- [ ] Integration with Salesforce CRM and QuickBooks accounting complete\n- [ ] Email confirmations sent within 30 seconds of successful payment\n\n**Quality Standards**\n- [ ] Payment processing time <3 seconds at 95th percentile\n- [ ] Checkout page load time <2 seconds\n- [ ] PCI DSS SAQ-A compliance validation complete\n- [ ] Security audit passed with zero critical vulnerabilities\n- [ ] Mobile-responsive checkout tested on iOS and Android\n\n**Operational Readiness**\n- [ ] Stripe integration monitoring and alerting configured\n- [ ] Webhook processing with retry logic implemented\n- [ ] Runbooks for common payment issues created\n- [ ] Support team trained on new checkout flow and troubleshooting\n- [ ] Customer-facing documentation published\n\n### Success Metrics (Post-Launch)\n\n**Adoption Metrics (30 days)**\n- [ ] **Transaction volume**: 0 → 1,000+ online transactions processed\n- [ ] **Saved payment adoption**: 60% of customers save payment method on first use\n\n**Engagement Metrics (30 days)**\n- [ ] **Checkout conversion**: 55% → 75% (reduce abandonment 45% → 25%)\n- [ ] **Average checkout time**: N/A → 45 seconds (90th percentile)\n\n**Business Metrics (90 days)**\n- [ ] **Revenue recovery**: $150K+ in previously abandoned cart revenue\n- [ ] **Operational cost reduction**: 80% reduction in manual payment processing time\n- [ ] **Customer satisfaction**: NPS 35 → 50+ for checkout experience\n\n**Quality Metrics (30 days)**\n- [ ] **Payment success rate**: 98%+ of initiated transactions complete successfully\n- [ ] **System uptime**: 99.9%+ (max 45 minutes downtime per month)\n- [ ] **Support ticket reduction**: 50% fewer payment-related inquiries\n\n## Functional Requirements\n\n### FR1: Credit/Debit Card Payment Processing\n\n**Description**: Process credit and debit card payments securely in real-time with instant confirmation\n\n**User Story**: As an online shopper, I want to pay with my credit/debit card directly on the checkout page, so that I can complete my purchase immediately without waiting for invoices\n\n**Inputs**:\n- Card number, expiration date, CVV (via Stripe Elements)\n- Billing address\n- Purchase amount and order details\n- Customer email\n\n**Outputs**:\n- Payment confirmation with transaction ID\n- Order receipt via email\n- Updated order status in CRM\n\n**Business Rules**:\n- Accept Visa, Mastercard, American Express, Discover\n- Require CVV for all transactions (fraud prevention)\n- Maximum transaction amount: $10,000 (fraud threshold)\n- Minimum transaction amount: $1.00\n\n**Acceptance Criteria**:\n- [ ] Given valid card details, when customer submits payment, then transaction processes in <3 seconds\n- [ ] Given invalid card number, when customer submits, then clear error message displays before submission\n- [ ] Given successful payment, when transaction completes, then confirmation email sent within 30 seconds\n- [ ] Given payment failure, when Stripe returns error, then user-friendly message explains issue and suggests resolution\n\n**Priority**: Must Have\n\n**Dependencies**: Stripe API integration, email service (SendGrid)\n\n---\n\n### FR2: Digital Wallet Support (Apple Pay / Google Pay)\n\n**Description**: Enable payment via Apple Pay and Google Pay for faster mobile checkout\n\n**User Story**: As a mobile shopper, I want to pay with Apple Pay/Google Pay, so that I can checkout with a single tap using my saved payment method\n\n**Inputs**:\n- Apple Pay/Google Pay token\n- Purchase amount\n- Shipping address (from wallet if available)\n\n**Outputs**:\n- Payment confirmation\n- Order receipt\n\n**Business Rules**:\n- Available only on supported browsers/devices\n- Gracefully degrade to card entry if wallet unavailable\n- Auto-fill shipping address from wallet when possible\n\n**Acceptance Criteria**:\n- [ ] Given iPhone with Apple Pay, when user selects Apple Pay, then payment completes with Face ID/Touch ID\n- [ ] Given Android with Google Pay, when user selects Google Pay, then payment completes with fingerprint/PIN\n- [ ] Given wallet payment, when user confirms, then checkout completes in <10 seconds total\n- [ ] Given unsupported browser, when checkout loads, then wallet buttons hidden and card entry shown\n\n**Priority**: Should Have\n\n**Dependencies**: Stripe Payment Request API, HTTPS (required for Apple Pay)\n\n---\n\n### FR3: Saved Payment Methods (One-Click Checkout)\n\n**Description**: Allow customers to securely save payment methods for faster future checkouts\n\n**User Story**: As a returning customer, I want to save my payment method, so that I can checkout with one click on future purchases without re-entering my card\n\n**Inputs**:\n- \"Save payment method\" checkbox selection\n- Customer account (must be logged in)\n- Payment method details (tokenized by Stripe)\n\n**Outputs**:\n- Payment method saved to customer account (Stripe token stored)\n- Display last 4 digits and card brand in account\n\n**Business Rules**:\n- Maximum 5 saved payment methods per customer\n- Must be logged in to save payment method\n- Can set one method as default\n- Can delete saved methods anytime\n\n**Acceptance Criteria**:\n- [ ] Given logged-in customer, when they check \"save payment method\", then method saved after successful payment\n- [ ] Given returning customer, when they view saved methods, then see last 4 digits and expiration date (not full number)\n- [ ] Given saved payment method, when customer selects it at checkout, then auto-fills payment form\n- [ ] Given multiple saved methods, when customer sets default, then it pre-selects at checkout\n\n**Priority**: Must Have\n\n**Dependencies**: FR1, user authentication, Stripe payment methods API\n\n---\n\n### FR4: CRM Integration (Salesforce)\n\n**Description**: Automatically sync payment transactions and customer payment methods with Salesforce CRM\n\n**User Story**: As a sales rep, I want payment information automatically updated in Salesforce, so that I have complete customer transaction history without manual entry\n\n**Inputs**:\n- Successful payment transaction\n- Customer email (matches Salesforce contact)\n- Order details\n\n**Outputs**:\n- Salesforce opportunity updated to \"Closed Won\"\n- Transaction record created in Salesforce\n- Customer payment method status updated\n\n**Business Rules**:\n- Match customers by email address\n- Create new contact if email not found\n- Update opportunity within 5 minutes of payment\n- Store only last 4 digits of card in Salesforce\n\n**Acceptance Criteria**:\n- [ ] Given successful payment, when transaction completes, then Salesforce opportunity updated within 5 minutes\n- [ ] Given new customer, when payment completes, then new Salesforce contact created\n- [ ] Given existing customer, when payment completes, then transaction added to existing contact\n- [ ] Given CRM sync failure, when Stripe payment succeeds, then retry CRM update 3 times with exponential backoff\n\n**Priority**: Must Have\n\n**Dependencies**: Salesforce API access, webhook processing\n\n---\n\n### FR5: Accounting Integration (QuickBooks)\n\n**Description**: Automatically post successful transactions to QuickBooks for revenue recognition and reconciliation\n\n**User Story**: As a finance team member, I want transactions automatically posted to QuickBooks, so that I don't spend 20 hours/week on manual data entry and reconciliation\n\n**Inputs**:\n- Successful payment transaction\n- Customer details\n- Product/service purchased\n- Payment amount and fees\n\n**Outputs**:\n- QuickBooks invoice created and marked paid\n- Revenue recognized in correct account\n- Stripe fees recorded as expense\n\n**Business Rules**:\n- Post within 1 hour of successful payment\n- Separate revenue and Stripe fees into different accounts\n- Match customer to existing QuickBooks customer or create new\n- Handle partial refunds correctly\n\n**Acceptance Criteria**:\n- [ ] Given successful payment, when transaction completes, then QuickBooks invoice posted within 1 hour\n- [ ] Given $100 transaction with $3.20 Stripe fee, when posted, then $100 revenue and $3.20 fee expense recorded\n- [ ] Given full refund, when processed, then QuickBooks invoice voided\n- [ ] Given partial refund, when processed, then credit memo created for refund amount\n\n**Priority**: Should Have\n\n**Dependencies**: QuickBooks API integration, webhook processing\n\n---\n\n## Non-Functional Requirements\n\n### NFR1: Performance\n\n**Response Time**:\n- Payment API calls: <500ms at 95th percentile\n- Checkout page load: <2 seconds\n- Payment processing (submit to confirmation): <3 seconds at 95th percentile\n\n**Throughput**:\n- Support 1,000 concurrent users during peak sales\n- Process 150 transactions per hour during peak load\n- Handle webhook processing for 200 events/hour\n\n**Testing Requirements**:\n- Load test with 1,000 concurrent users for 1 hour\n- Stress test to 2x expected peak load\n\n---\n\n### NFR2: Security\n\n**Authentication/Authorization**:\n- API keys stored in environment variables (never in code)\n- Use Stripe API key with minimum required permissions\n- Session-based auth for saved payment methods (must be logged in)\n\n**Data Protection**:\n- Never store raw credit card numbers (use Stripe tokens only)\n- All payment data transmitted via TLS 1.3\n- PCI DSS SAQ-A compliance (tokenization model)\n- 3D Secure 2.0 enabled for high-risk transactions\n\n**Compliance**:\n- Complete PCI DSS SAQ-A questionnaire annually\n- GDPR compliant (support payment method deletion requests)\n- SOC 2 compliant webhook processing\n\n**Security Testing**:\n- Pass OWASP Top 10 security audit\n- Penetration testing before launch\n- Annual security review\n\n---\n\n### NFR3: Reliability\n\n**Availability**:\n- 99.9% uptime SLA (maximum 45 minutes downtime per month)\n- Graceful degradation if Stripe API unavailable\n\n**Error Handling**:\n- Retry transient Stripe API failures (3 retries with exponential backoff)\n- Display user-friendly error messages (never show raw API errors)\n- Log all errors for debugging and alerting\n\n**Data Integrity**:\n- Idempotent payment processing (prevent duplicate charges)\n- Webhook processing with deduplication\n- Transaction logging for audit trail\n\n**Monitoring & Alerting**:\n- Alert if payment success rate <95% over 15-minute window\n- Alert if average response time >5 seconds\n- Alert on any Stripe webhook failures\n- Daily reconciliation report comparing Stripe transactions to database\n\n---\n\n### NFR4: Usability\n\n**Checkout Experience**:\n- Maximum 4 steps to complete checkout (cart → info → payment → confirm)\n- Guest checkout option (no account required)\n- Auto-fill billing address from shipping address\n- Clear progress indicator showing checkout steps\n\n**Mobile Experience**:\n- Fully responsive design (mobile, tablet, desktop)\n- Digital wallet buttons prominent on mobile\n- Card input fields optimized for mobile keyboards\n- Minimum tap target size 44x44 pixels\n\n**Accessibility**:\n- WCAG 2.1 AA compliance\n- Keyboard navigation for all form fields\n- Screen reader compatible\n- Clear focus indicators\n\n**Error Messages**:\n- Specific, actionable error messages (\"Card declined - try different card\" not \"Error 402\")\n- Inline validation (show errors immediately, not after submit)\n- Error summary at top of form\n\n---\n\n## Constraints\n\n**Technical Constraints**:\n- Must use Stripe as payment processor (existing vendor relationship)\n- Must integrate with existing Salesforce CRM instance\n- Must use existing QuickBooks accounting system\n- Frontend must support IE11+ (legacy enterprise requirement)\n\n**Business Constraints**:\n- Launch deadline: June 30, 2026 (hard deadline for fiscal year)\n- Budget: $150K total (development + first year transaction fees)\n- Transaction fee budget: 3% of GMV (already factored into pricing)\n\n**Regulatory Constraints**:\n- PCI DSS compliance required (using SAQ-A)\n- GDPR compliance (right to deletion of payment data)\n- State sales tax collection required (out of scope for payment integration)\n\n**Resource Constraints**:\n- 2 frontend engineers, 1 backend engineer, 1 QA engineer\n- 16-week development timeline (4 sprints of 4 weeks each)\n- No dedicated DevOps engineer (must use existing infrastructure)\n\n---\n\n## Assumptions\n\n**User Assumptions**:\n- 60% of users will access from mobile devices\n- 70% of users will save payment method if offered\n- Users have modern browsers (Chrome, Safari, Firefox, Edge - last 2 versions)\n- Average transaction value: $275\n\n**Technical Assumptions**:\n- Stripe API maintains 99.99% uptime (historical average)\n- Stripe API remains backward compatible (no breaking changes)\n- Webhooks delivered within 5 minutes (Stripe SLA)\n- Current infrastructure can handle 10x transaction volume growth\n\n**Business Assumptions**:\n- Transaction volume grows from 1,000/month to 5,000/month within 6 months\n- Cart abandonment reduces from 45% to 25% after launch\n- Customers willing to pay current pricing plus transaction fees\n- Sales team capacity sufficient for increased order volume\n\n---\n\n## Out of Scope\n\n**Features Explicitly Excluded**:\n- Cryptocurrency payments (deferred to Phase 3, market still nascent)\n- Buy now, pay later (BNPL) options like Klarna/Affirm (Phase 2, evaluate demand)\n- Subscription and recurring billing (Phase 2, not needed for MVP)\n- International currency support beyond USD (Phase 2, market dependent)\n- ACH/bank transfer payments (low demand, complex compliance)\n- Gift cards and store credit (Phase 3 feature)\n\n**Deferred to Future Phases**:\n- Advanced fraud detection rules customization (use Stripe Radar defaults for MVP)\n- Multi-currency pricing and display (Phase 2, after international expansion)\n- Invoice payment portal for net-30 terms (separate project)\n- Payment plan/installment options (Phase 2 after BNPL evaluation)\n\n**Platforms Not Supported**:\n- Internet Explorer 10 and older (< 2% traffic, not worth compatibility effort)\n- Native mobile apps (web-only for MVP, may build apps in Phase 3)\n- In-person/POS payments (separate product line, not e-commerce focus)\n",
        "skills/prd-authoring/examples/IMPLEMENTATION_SUMMARY.md": "# PRD Authoring Skill - Issue #107 Implementation Summary\n\n## Issue Overview\n**Issue #107**: Create comprehensive usage examples and test the complete PRD authoring workflow\n\n**Assigned**: Implementation of examples, testing, and documentation for prd-authoring skill\n\n## Deliverables Completed\n\n### 1. Examples Directory Created\nLocation: `/skills/prd-authoring/examples/`\n\nContains 5 comprehensive files demonstrating the complete workflow:\n\n#### a. Product Brief Example (`01-product-brief-example.md`)\n- **Project**: Payment Gateway Integration\n- **Content**: Complete product brief with real-world business case\n- **Key Features**:\n  - Quantified problem statement: 45% cart abandonment, $2.4M lost revenue\n  - Detailed user personas: Online Shopper Sarah, Sales Rep Mike\n  - Measurable success metrics: 55% → 75% conversion rate\n  - Clear value propositions for users and business\n\n#### b. Research Document Example (`02-research-example.md`)\n- **Scope**: Comprehensive market research supporting the PRD\n- **Content**:\n  - Competitive analysis: Stripe, PayPal/Braintree, Square (full profiles)\n  - Market insights: $154B market, 14.2% CAGR growth\n  - User feedback analysis: Pain points and desired features\n  - Technical considerations: APIs, compliance, architecture patterns\n  - Risk assessment with mitigation strategies\n  - Clear recommendation: Use Stripe for best developer experience\n\n#### c. PRD Example - Abbreviated (`03-prd-example-abbreviated.md`)\n- **Format**: Condensed but complete PRD (easier to digest than full template)\n- **Content**:\n  - 3 SMART primary objectives linked to business outcomes\n  - Comprehensive success criteria (launch, metrics, stretch goals)\n  - 5 detailed functional requirements (FR1-FR5) with full acceptance criteria\n  - 4 non-functional requirements: Performance, Security, Reliability, Usability\n  - Constraints, assumptions, and explicit out-of-scope items\n- **Quality**: Demonstrates proper requirement structure, acceptance criteria format, and traceability\n\n#### d. Workflow Test Log (`workflow-test-log.md`)\n- **Scope**: Complete testing of all commands and edge cases\n- **Test Coverage**:\n  - Happy path: All 7 commands tested successfully\n  - Edge cases: 10 scenarios tested (missing files, duplicates, invalid input)\n  - Validation quality: Tests for vague language, unmeasurable criteria, missing sections\n  - **Result**: ALL TESTS PASSED ✓\n- **Value**: Proves skill is production-ready with robust error handling\n\n#### e. Examples README (`README.md`)\n- **Purpose**: Guide users through the examples\n- **Content**:\n  - Overview of each example file\n  - How to use examples for learning and testing\n  - Project statistics and breakdown\n  - Common patterns demonstrated\n  - Tips and next steps\n\n### 2. SKILL.md Updated\n\n#### Added Examples Section (Lines 1538-1689)\n- **Project Overview**: Payment Gateway Integration example\n- **Example Files**: Descriptions of all 4 example documents\n- **Key Patterns Demonstrated**:\n  - Problem statement format\n  - Success metric format\n  - Functional requirement structure\n  - Complete FR1 example showing all components\n- **Running the Example Workflow**: Step-by-step commands\n- **Expected Timeline**: 18-36 hours of planning work\n- **ROI Calculation**: 1 week upfront prevents weeks of rework\n\n#### Added Troubleshooting Section (Lines 1693-2110)\nComprehensive troubleshooting guide with 3 categories:\n\n**Common Errors (9 issues)**:\n1. Missing docs/prds directory\n2. Product brief already exists\n3. Project directory doesn't exist\n4. Research document not found (warning)\n5. Vague language detected\n6. Unmeasurable success criteria\n7. Missing acceptance criteria\n8. Epics document already exists\n9. Spec proposal directory already exists\n\n**Quality Issues (4 issues)**:\n1. PRD validation passes but requirements unclear\n2. Epic dependencies complex and create bottlenecks\n3. Stakeholders disagree on objectives\n4. Research taking too long\n\n**Integration Issues (2 issues)**:\n1. Unclear how to transition from PRD to spec-authoring\n2. Multiple people working on same PRD causing conflicts\n\nEach issue includes:\n- **Symptom**: What the user observes\n- **Cause**: Why it happens\n- **Solution**: Step-by-step fix with commands\n- **Prevention**: How to avoid in future (where applicable)\n\n### 3. Testing Completed\n\n#### Happy Path Testing\n**All 7 commands tested successfully**:\n1. ✓ `status` - Works with and without project name\n2. ✓ `brief` - Creates template with proper structure\n3. ✓ `research` - Generates comprehensive research template\n4. ✓ `create-prd` - Creates full PRD template\n5. ✓ `validate-prd` - Detects quality issues accurately (strict & lenient modes)\n6. ✓ `decompose` - Generates epic breakdown template\n7. ✓ `generate-spec` - Creates spec proposal structure\n\n#### Edge Case Testing\n**10 edge cases tested, all handled correctly**:\n1. ✓ Missing directories - Proper error messages\n2. ✓ Duplicate files - Prevents overwriting\n3. ✓ Missing prerequisites - Clear guidance provided\n4. ✓ Invalid project names - Sanitization works\n5. ✓ Incomplete documents - Warnings appropriate\n6. ✓ Invalid commands - Help text displayed\n7. ✓ Missing arguments - Usage guidance provided\n8. ✓ Parallel projects - Proper isolation\n9. ✓ Validation modes - Both work as expected\n10. ✓ Epic generation - Handles missing epics gracefully\n\n#### Validation Quality Testing\n**Validation accurately detects**:\n- Vague language (should, might, probably, good, fast)\n- Unmeasurable criteria (qualitative without numbers)\n- Missing sections (strict mode)\n- Missing acceptance criteria\n- YAML frontmatter issues\n\n### 4. Example Project Statistics\n\n**Payment Gateway Integration**:\n- **Problem**: 45% cart abandonment, $2.4M lost revenue annually\n- **Solution**: Stripe integration for real-time payments\n- **Value**: $1.8M revenue recovery + $100K cost savings = 12x ROI\n- **Timeline**: 6 months to launch (Q2 2026)\n- **Team**: 2 FE, 1 BE, 1 QA engineer\n- **Budget**: $150K (development + first year fees)\n- **Scope**: 5 functional requirements, 4 NFRs\n- **Expected Volume**: 1,000 → 5,000 transactions/month\n\n## Quality Metrics\n\n### Documentation Coverage\n- ✓ All 7 commands documented with examples\n- ✓ 15 troubleshooting scenarios covered\n- ✓ Complete workflow demonstrated end-to-end\n- ✓ Best practices and patterns documented\n- ✓ Error handling and edge cases explained\n\n### Example Quality\n- ✓ Realistic business case (e-commerce payment integration)\n- ✓ Quantified metrics throughout (no vague statements)\n- ✓ Proper formatting and structure\n- ✓ Demonstrates SMART criteria\n- ✓ Shows traceability from business goals to requirements\n\n### Testing Coverage\n- ✓ 100% of commands tested\n- ✓ 10 edge cases validated\n- ✓ Both validation modes tested\n- ✓ Error messages verified for clarity\n- ✓ End-to-end workflow validated\n\n## Files Created/Modified\n\n### Created Files (5):\n1. `/skills/prd-authoring/examples/01-product-brief-example.md` (128 lines)\n2. `/skills/prd-authoring/examples/02-research-example.md` (316 lines)\n3. `/skills/prd-authoring/examples/03-prd-example-abbreviated.md` (394 lines)\n4. `/skills/prd-authoring/examples/workflow-test-log.md` (385 lines)\n5. `/skills/prd-authoring/examples/README.md` (185 lines)\n\n### Modified Files (1):\n1. `/skills/prd-authoring/SKILL.md`\n   - Added Examples section (151 lines)\n   - Added Troubleshooting section (417 lines)\n   - Total additions: 568 lines\n\n**Total Lines Added**: ~2,000 lines of comprehensive documentation and examples\n\n## Acceptance Criteria Met\n\n### From Issue #107:\n\n✓ **Examples cover common project types**\n- Feature project demonstrated (payment gateway integration)\n- Example applicable to system and enhancement projects\n\n✓ **All commands tested and working**\n- 7/7 commands tested successfully\n- Both happy path and edge cases validated\n\n✓ **Edge cases identified and documented**\n- 10 edge cases tested\n- 15 troubleshooting scenarios documented\n\n✓ **Troubleshooting guides added for common errors**\n- 15 issues with symptom/cause/solution\n- Preventive guidance included\n\n✓ **Examples are included in skill documentation**\n- Examples section added to SKILL.md\n- README added to examples directory\n- Cross-references between examples and documentation\n\n## Key Achievements\n\n### 1. Production-Ready Validation\n- All commands tested and working\n- Robust error handling confirmed\n- Clear, actionable error messages verified\n\n### 2. Comprehensive Examples\n- Real-world business case (payment gateway)\n- Complete workflow from brief → PRD → epics → spec\n- $1.8M revenue recovery + $100K cost savings ROI\n\n### 3. Extensive Troubleshooting\n- 15 common issues documented\n- Solutions with step-by-step commands\n- Prevention guidance for avoiding issues\n\n### 4. Quality Documentation\n- 2,000+ lines of new documentation\n- Examples demonstrate best practices\n- Clear patterns for users to follow\n\n## Usage Recommendations\n\n### For New Users\n1. Start with `examples/README.md` for overview\n2. Read `01-product-brief-example.md` to see a well-formed brief\n3. Review `03-prd-example-abbreviated.md` for PRD structure\n4. Use `workflow-test-log.md` to understand testing approach\n\n### For Testing\n1. Copy examples to test environment\n2. Run through workflow commands\n3. Verify output matches expected results\n4. Test edge cases from workflow-test-log.md\n\n### For Production Use\n1. Use examples as templates (customize for context)\n2. Reference troubleshooting section for issues\n3. Follow patterns demonstrated in examples\n4. Validate PRD early and often\n\n## Lessons Learned\n\n### What Worked Well\n1. **Realistic Example**: Payment gateway project is relatable and well-scoped\n2. **Complete Coverage**: Testing all commands and edge cases proved robustness\n3. **Structured Troubleshooting**: Symptom/Cause/Solution format is clear and actionable\n4. **Quantified Metrics**: Real numbers throughout examples make them credible\n\n### Recommendations\n1. Consider adding video walkthrough of workflow\n2. Create additional examples for different project types (system redesign, enhancement)\n3. Add templates for common industries (fintech, healthcare, e-commerce)\n4. Create validation ruleset customization guide\n\n## Time Investment\n\n### Estimated Effort\n- Example creation: 6 hours (product brief, research, PRD)\n- Testing and validation: 3 hours (all commands, edge cases)\n- Documentation updates: 4 hours (examples section, troubleshooting)\n- README and summary: 1 hour\n- **Total**: ~14 hours\n\n### ROI of This Work\n- **Upfront time**: 14 hours\n- **Prevents**: Hours of user confusion and support requests\n- **Enables**: Self-service learning and troubleshooting\n- **Result**: Skill is production-ready and well-documented\n\n## Conclusion\n\nIssue #107 has been successfully implemented with comprehensive examples, thorough testing, and extensive troubleshooting documentation. The prd-authoring skill is now production-ready with:\n\n- ✓ Complete workflow examples (payment gateway integration)\n- ✓ All 7 commands tested and validated\n- ✓ 10 edge cases handled correctly\n- ✓ 15 troubleshooting scenarios documented\n- ✓ ~2,000 lines of quality documentation added\n\nUsers can now learn the PRD authoring workflow through realistic examples, test commands in a safe environment, and troubleshoot issues independently using the comprehensive troubleshooting guide.\n\n**Status**: COMPLETE ✓\n**Quality**: PRODUCTION-READY ✓\n**Documentation**: COMPREHENSIVE ✓\n",
        "skills/prd-authoring/examples/QUICK_START.md": "# PRD Authoring - Quick Start Guide\n\n## 5-Minute Overview\n\nThe PRD authoring skill guides you from vague project ideas to validated Product Requirements Documents ready for implementation.\n\n**Workflow**: status → brief → research → create-prd → validate-prd → decompose → generate-spec\n\n**Time Investment**: 18-36 hours of planning (saves weeks of rework later)\n\n**Output**: Validated PRD with measurable objectives, testable requirements, and epic breakdown\n\n## Prerequisites\n\n```bash\n# Ensure you have docs/prds directory\nmkdir -p docs/prds\n\n# Navigate to project root\ncd /path/to/your/project\n```\n\n## Quick Workflow\n\n### Step 1: Check Status (30 seconds)\n```bash\nbash skills/prd-authoring/scripts/prd-authoring.sh status\n```\n**Output**: Shows what exists, recommends next step\n\n### Step 2: Create Product Brief (2-4 hours)\n```bash\nbash skills/prd-authoring/scripts/prd-authoring.sh brief \"Your Project Name\"\n```\n**Then**: Edit `docs/prds/your-project-name/product-brief.md`\n\n**Fill in**:\n- Problem statement (what, who, frequency, business impact)\n- Target users (personas with goals and pain points)\n- Proposed solution (what you'll build and why)\n- Value proposition (user benefits, business benefits)\n- Success metrics (baseline → target within timeframe)\n\n**Example**: See `examples/01-product-brief-example.md`\n\n### Step 3: Conduct Research (4-8 hours)\n```bash\nbash skills/prd-authoring/scripts/prd-authoring.sh research your-project-name\n```\n**Then**: Edit `docs/prds/your-project-name/research.md`\n\n**Research**:\n- Competitive analysis (3-5 competitors)\n- Market insights (size, growth, trends)\n- User feedback (pain points, desired features)\n- Technical considerations (approaches, risks)\n- Recommendations (must-build, should-build, could-build)\n\n**Example**: See `examples/02-research-example.md`\n\n### Step 4: Create PRD (8-16 hours)\n```bash\nbash skills/prd-authoring/scripts/prd-authoring.sh create-prd your-project-name\n```\n**Then**: Edit `docs/prds/your-project-name/prd.md`\n\n**Define**:\n- Objectives (SMART: Specific, Measurable, Achievable, Relevant, Time-bound)\n- Success criteria (launch criteria, post-launch metrics)\n- Functional requirements (FR1, FR2, etc. with acceptance criteria)\n- Non-functional requirements (performance, security, reliability, usability)\n- Constraints and assumptions\n- Out of scope (what you won't build)\n\n**Example**: See `examples/03-prd-example-abbreviated.md`\n\n### Step 5: Validate PRD (iterative)\n```bash\n# Draft validation (lenient mode)\nbash skills/prd-authoring/scripts/prd-authoring.sh validate-prd your-project-name --lenient\n\n# Fix issues, then strict validation\nbash skills/prd-authoring/scripts/prd-authoring.sh validate-prd your-project-name\n```\n**Goal**: \"GOOD\" or \"EXCELLENT\" rating with zero critical issues\n\n**Common fixes**:\n- Replace vague terms (\"fast\" → \"<200ms at p95\")\n- Add measurable targets (\"improve UX\" → \"task completion rate >85%\")\n- Add acceptance criteria to requirements\n\n### Step 6: Decompose into Epics (4-8 hours)\n```bash\nbash skills/prd-authoring/scripts/prd-authoring.sh decompose your-project-name\n```\n**Then**: Edit `docs/prds/your-project-name/epics.md`\n\n**Break down**:\n- Group requirements into 3-7 independently deliverable epics\n- Map epic dependencies\n- Ensure 100% requirements coverage\n- Estimate effort (2-4 sprints per epic)\n\n### Step 7: Generate Spec Proposals\n```bash\nbash skills/prd-authoring/scripts/prd-authoring.sh generate-spec your-project-name \"Epic Name\"\n```\n**Output**: Creates `docs/changes/epic-name/` with:\n- `proposal.md` (epic scope and objectives)\n- `spec-delta.md` (technical requirements)\n- `tasks.md` (implementation breakdown)\n\n**Then**: Transition to spec-authoring workflow for each epic\n\n## Command Reference\n\n| Command | Purpose | When to Use |\n|---------|---------|-------------|\n| `status` | Check project state | Start of session, after each step |\n| `brief` | Create product brief | First step for new project |\n| `research` | Create research doc | After brief is complete |\n| `create-prd` | Create PRD template | After brief and research |\n| `validate-prd` | Check PRD quality | After writing PRD, before decompose |\n| `decompose` | Break into epics | After PRD validated |\n| `generate-spec` | Create spec proposal | For each epic, transition to development |\n\n## Common Patterns\n\n### Problem Statement\n```\n[What problem] + [Who experiences] + [Frequency] + [Business impact]\n\nExample: \"Our e-commerce platform lacks payment processing, forcing\ncustomers through manual invoices. This affects 100% of transactions\n(1,000/month), causing 45% cart abandonment and $2.4M lost revenue annually.\"\n```\n\n### Success Metric\n```\n[Metric name]: [Baseline] → [Target] within [Timeframe]\n\nExample: \"Checkout conversion rate: 55% → 75% within 30 days post-launch\"\n```\n\n### Functional Requirement\n```markdown\n### FR1: [Requirement Name]\n\n**Description**: [What the system must do]\n\n**User Story**: As a [user], I want [capability], so that [benefit]\n\n**Acceptance Criteria**:\n- [ ] Given [precondition], when [action], then [result]\n- [ ] Given [precondition], when [action], then [result]\n- [ ] Given [precondition], when [action], then [result]\n\n**Priority**: Must Have / Should Have / Could Have\n\n**Dependencies**: [Other requirements or systems]\n```\n\n## Troubleshooting Quick Fixes\n\n### \"docs/prds/ directory does not exist\"\n```bash\nmkdir -p docs/prds\n```\n\n### \"Product brief already exists\"\n```bash\n# Check what exists\nbash scripts/prd-authoring.sh status\n\n# Edit existing or use different name\nvim docs/prds/project-name/product-brief.md\n```\n\n### \"Vague language detected\"\nReplace with specific metrics:\n- \"fast\" → \"<200ms at 95th percentile\"\n- \"many users\" → \"10,000 concurrent users\"\n- \"good UX\" → \"task completion rate >85%\"\n\n### \"Success criteria may lack measurable targets\"\nAdd numbers:\n- Before: \"Improve customer satisfaction\"\n- After: \"Customer satisfaction: NPS 35 → 55 within 3 months\"\n\n## Tips for Success\n\n### Do This ✓\n- Run `status` frequently to track progress\n- Be specific with numbers (avoid \"fast\", \"good\", \"many\")\n- Link requirements back to objectives (traceability)\n- Validate early and often (use lenient mode for drafts)\n- Time-box research (4-8 hours max)\n- Include out-of-scope to prevent scope creep\n\n### Avoid This ✗\n- Skipping research (leads to uninformed requirements)\n- Vague requirements (\"should be fast and secure\")\n- Unmeasurable success criteria (\"improve user experience\")\n- Missing acceptance criteria (how do you test?)\n- Over-engineering the PRD (done > perfect)\n- Changing PRD endlessly (lock after 2-3 iterations)\n\n## Example Project\n\n**Payment Gateway Integration** (see `examples/` directory):\n- **Problem**: 45% cart abandonment, $2.4M lost revenue\n- **Solution**: Stripe integration for real-time payments\n- **Value**: $1.8M revenue recovery + $100K cost savings\n- **Timeline**: 18-36 hours planning, 6 months to launch\n- **Outcome**: 5 functional requirements, 4 epics, validated PRD\n\n## Next Steps\n\n1. **Learn**: Read `examples/README.md` for detailed examples\n2. **Practice**: Run workflow on test project\n3. **Apply**: Create brief for your real project\n4. **Validate**: Use validate-prd to check quality\n5. **Iterate**: Refine based on feedback\n6. **Deploy**: Transition to spec-authoring for implementation\n\n## Need Help?\n\n- **Examples**: See `skills/prd-authoring/examples/` directory\n- **Troubleshooting**: See SKILL.md Troubleshooting section\n- **Workflow Details**: See SKILL.md for command documentation\n- **Test Results**: See `examples/workflow-test-log.md`\n\n## Time Budget\n\n| Activity | Time | Cumulative |\n|----------|------|------------|\n| Product Brief | 2-4 hours | 2-4 hours |\n| Research | 4-8 hours | 6-12 hours |\n| PRD Creation | 8-16 hours | 14-28 hours |\n| Validation | 1-2 hours | 15-30 hours |\n| Epic Decomposition | 4-8 hours | 19-38 hours |\n| **Total Planning** | **18-36 hours** | |\n\n**ROI**: 1 week of planning prevents 4-8 weeks of rework from unclear requirements\n\n## Success Criteria\n\nYour PRD is ready when:\n- ✓ Validation passes with \"GOOD\" or \"EXCELLENT\"\n- ✓ All objectives are SMART (Specific, Measurable, Achievable, Relevant, Time-bound)\n- ✓ Every requirement has acceptance criteria\n- ✓ Success metrics have baseline → target → timeframe\n- ✓ Stakeholders approve and understand what to build\n- ✓ Team knows how to test each requirement\n\n## Remember\n\n> \"Hours of planning save weeks of rework. A validated PRD is your blueprint for success.\"\n\nStart with `status`, follow the workflow, validate often, and maintain traceability. Good luck!\n",
        "skills/prd-authoring/examples/README.md": "# PRD Authoring Examples\n\nThis directory contains comprehensive examples demonstrating the complete PRD authoring workflow for the payment gateway integration project.\n\n## Example Files\n\n### 1. Product Brief (`01-product-brief-example.md`)\nA complete product brief for a payment gateway integration project showing:\n- Clear problem statement with quantified business impact\n- Well-defined user personas (primary and secondary)\n- Specific value propositions for users and business\n- Measurable success metrics (SMART criteria)\n\n**Key Takeaways**:\n- Problem statement includes who, what, frequency, and business impact\n- Success metrics are specific numbers with baselines and targets\n- Value propositions tied to concrete outcomes ($1.8M revenue recovery)\n\n### 2. Research Document (`02-research-example.md`)\nComprehensive market research supporting the PRD, including:\n- Competitive analysis of 3 major providers (Stripe, PayPal, Square)\n- Market size, growth trends, and regulatory landscape\n- User feedback analysis with pain points and desired features\n- Technical considerations and risk assessment\n\n**Key Takeaways**:\n- Each competitor analyzed for strengths, weaknesses, features, pricing\n- Research findings directly inform PRD recommendations\n- Technical risks identified early with mitigation strategies\n- Clear recommendation: Use Stripe for best developer experience\n\n### 3. PRD - Abbreviated Version (`03-prd-example-abbreviated.md`)\nA condensed but complete PRD showing:\n- 3 SMART primary objectives linked to business outcomes\n- Comprehensive success criteria (launch, metrics, stretch goals)\n- 5 detailed functional requirements with acceptance criteria\n- 4 non-functional requirements (performance, security, reliability, usability)\n- Constraints, assumptions, and explicit out-of-scope items\n\n**Key Takeaways**:\n- Each requirement has description, user story, inputs, outputs, acceptance criteria, priority\n- Non-functional requirements are measurable (99.9% uptime, <3s response time)\n- Out of scope clearly defines what will NOT be built to prevent scope creep\n- Full traceability from requirements back to objectives\n\n### 4. Workflow Test Log (`workflow-test-log.md`)\nComplete test results showing:\n- Happy path: Full workflow from status → brief → research → PRD → validate → decompose → generate-spec\n- Edge cases: 10 error scenarios tested (missing files, duplicates, invalid input)\n- Validation quality: Tests for vague language, unmeasurable criteria, missing sections\n- All tests passed with proper error handling\n\n**Key Takeaways**:\n- All 7 commands work correctly\n- Error messages are clear and actionable\n- Validation accurately detects quality issues\n- Workflow maintains traceability throughout\n\n## Using These Examples\n\n### For Learning\n1. Start with `01-product-brief-example.md` to see a well-formed brief\n2. Read `02-research-example.md` to understand depth of research needed\n3. Study `03-prd-example-abbreviated.md` for PRD structure and completeness\n4. Review `workflow-test-log.md` to understand the complete workflow\n\n### For Your Own Projects\n1. Use these as templates, but customize for your specific context\n2. Note the level of detail and specificity required\n3. Pay attention to how requirements link back to objectives\n4. Observe how assumptions and constraints are documented\n\n### For Testing\n1. Set up a test environment: `mkdir -p /tmp/test-prd && cd /tmp/test-prd && mkdir -p docs/prds`\n2. Copy an example to test with: `cp 01-product-brief-example.md /tmp/test-prd/docs/prds/test-project/product-brief.md`\n3. Run commands to test workflow\n\n## Example Project: Payment Gateway Integration\n\nThis example represents a realistic e-commerce payment integration project with:\n\n**Problem**: 45% cart abandonment due to manual invoice process\n**Solution**: Integrate Stripe for real-time online payments\n**Value**: Recover $1.8M in lost revenue, save $100K in operational costs\n**Scope**: Credit card processing, digital wallets, saved payment methods, CRM/accounting integration\n**Timeline**: 6 months to launch (Q2 2026)\n\n### Project Statistics\n- **Transaction Volume**: 1,000/month current → 5,000/month target\n- **Team Size**: 2 frontend, 1 backend, 1 QA engineer\n- **Budget**: $150K (development + first year fees)\n- **Expected ROI**: $1.8M revenue recovery + $100K cost savings = 12x ROI\n\n### Requirements Breakdown\n- **Functional Requirements**: 5 detailed (FR1-FR5)\n  - Payment processing\n  - Digital wallets\n  - Saved payment methods\n  - CRM integration\n  - Accounting integration\n\n- **Non-Functional Requirements**: 4 categories\n  - Performance (<3s payment processing)\n  - Security (PCI DSS compliance)\n  - Reliability (99.9% uptime)\n  - Usability (WCAG 2.1 AA)\n\n### Epic Decomposition (Not Shown but Tested)\nThe PRD would decompose into 4-5 epics:\n1. Payment Processing Core (Stripe integration, card payments)\n2. Payment Methods (Apple Pay, Google Pay, saved methods)\n3. CRM & Accounting Integration\n4. Security & Compliance (PCI, fraud detection)\n\nEach epic would then become a spec using the spec-authoring workflow.\n\n## Common Patterns Demonstrated\n\n### Problem Statements\nFormat: What problem + Who experiences + Frequency + Business impact\n\nExample:\n> \"Our e-commerce platform lacks payment processing, forcing customers through manual invoices. This affects 100% of transactions (1,000/month), causing 45% cart abandonment and $2.4M lost revenue annually.\"\n\n### Success Metrics\nFormat: Metric name: Baseline → Target within Timeframe\n\nExample:\n> \"Checkout conversion rate: 55% → 75% within 30 days post-launch\"\n\n### Functional Requirements\nFormat: Description + User Story + Inputs + Outputs + Business Rules + Acceptance Criteria + Priority + Dependencies\n\nExample FR1 shows complete structure for payment processing requirement.\n\n### Acceptance Criteria\nFormat: Given [precondition], when [action], then [expected result]\n\nExample:\n> \"Given valid card details, when customer submits payment, then transaction processes in <3 seconds\"\n\n## Tips from These Examples\n\n1. **Be Specific**: Notice how every metric has a number, every timeline has a date\n2. **Show Impact**: Every feature ties back to business value (revenue, cost, satisfaction)\n3. **Link Everything**: Requirements → Objectives → Business goals (traceability)\n4. **Set Boundaries**: Out of scope is as important as in scope\n5. **Document Assumptions**: Make implicit assumptions explicit\n6. **Measure Quality**: Use validate-prd to catch vague language early\n\n## Next Steps\n\nAfter reviewing these examples:\n1. Create your own project brief using the `brief` command\n2. Conduct research for your specific domain\n3. Write your PRD referencing these examples for structure\n4. Validate early and often using `validate-prd`\n5. Decompose into epics when PRD is complete\n6. Transition to spec-authoring for implementation\n\n## Questions?\n\n- Refer to SKILL.md for detailed command documentation\n- Review workflow-test-log.md for edge cases and error handling\n- Compare your work to these examples for quality benchmarking\n",
        "skills/prd-authoring/examples/workflow-test-log.md": "# PRD Authoring Workflow - Test Results\n\n## Test Date: 2025-11-04\n\n## Test Environment\n- Project: payment-gateway-integration\n- Location: /tmp/test-prd-authoring\n\n## Test Scenario 1: Complete Happy Path Workflow\n\n### Step 1: Status Command (No Projects)\n```bash\n$ bash prd-authoring.sh status\n```\n\n**Result**: PASSED\n- Correctly identified no projects exist\n- Recommended running `brief` command\n- Provided correct next command\n\n### Step 2: Brief Command\n```bash\n$ bash prd-authoring.sh brief \"Payment Gateway Integration\"\n```\n\n**Result**: PASSED\n- Created directory: `docs/prds/payment-gateway-integration/`\n- Created file: `product-brief.md` with proper YAML frontmatter\n- Kebab-cased project name correctly\n- Template included all required sections:\n  - Problem Statement\n  - Target Users\n  - Proposed Solution\n  - Value Proposition\n  - Success Metrics\n\n### Step 3: Status Command (Brief Created)\n```bash\n$ bash prd-authoring.sh status payment-gateway-integration\n```\n\n**Result**: PASSED\n- Detected brief exists\n- Validated brief completeness (all required sections present)\n- Status: \"Brief Complete\"\n- Recommended running `research` command\n\n### Step 4: Research Command\n```bash\n$ bash prd-authoring.sh research payment-gateway-integration\n```\n\n**Result**: PASSED\n- Created file: `research.md` with YAML frontmatter\n- Template included all sections:\n  - Competitive Analysis (3 competitor templates)\n  - Market Insights\n  - User Feedback Analysis\n  - Technical Considerations\n  - Recommendations\n\n### Step 5: Status Command (Research Created)\n```bash\n$ bash prd-authoring.sh status payment-gateway-integration\n```\n\n**Result**: PASSED\n- Detected both brief and research exist\n- Validated completeness\n- Status: \"Research Phase\"\n- Recommended running `create-prd` command\n\n### Step 6: Create PRD Command\n```bash\n$ bash prd-authoring.sh create-prd payment-gateway-integration\n```\n\n**Result**: PASSED\n- Created file: `prd.md` with comprehensive template\n- YAML frontmatter present\n- All major sections included:\n  - Objectives (Primary and Secondary)\n  - Success Criteria (Launch, Metrics, Stretch Goals)\n  - Functional Requirements (numbered FR1, FR2, etc.)\n  - Non-Functional Requirements (NFR1-6)\n  - Constraints\n  - Assumptions\n  - Out of Scope\n\n### Step 7: Validate PRD Command (Draft Mode)\n```bash\n$ bash prd-authoring.sh validate-prd payment-gateway-integration --lenient\n```\n\n**Result**: PASSED (Lenient Mode)\n- Detected incomplete PRD (template placeholders)\n- Warnings issued for vague language\n- Recommended completing sections\n- Lenient mode allowed template placeholders\n\n### Step 8: Validate PRD Command (Strict Mode - After Completion)\n```bash\n$ bash prd-authoring.sh validate-prd payment-gateway-integration\n```\n\n**Result**: PASSED (after populating PRD)\n- All required sections present\n- SMART criteria validated\n- Measurable success criteria detected\n- No critical issues found\n- Rating: \"GOOD\" (some minor warnings acceptable)\n\n### Step 9: Decompose Command\n```bash\n$ bash prd-authoring.sh decompose payment-gateway-integration\n```\n\n**Result**: PASSED\n- Created file: `epics.md`\n- Template included:\n  - Epic decomposition guidelines\n  - Epic templates (1-3 examples)\n  - Dependencies and sequencing section\n  - Requirements traceability matrix\n  - Sprint planning guidance\n\n### Step 10: Generate Spec Command\n```bash\n$ bash prd-authoring.sh generate-spec payment-gateway-integration \"Payment Processing Core\"\n```\n\n**Result**: PASSED\n- Created directory: `docs/changes/payment-processing-core/`\n- Created files:\n  - `proposal.md` (Epic scope and objectives)\n  - `spec-delta.md` (Technical specifications)\n  - `tasks.md` (Initial task breakdown)\n- All files properly linked back to PRD and epic\n\n---\n\n## Test Scenario 2: Edge Cases and Error Handling\n\n### Test 2.1: Missing docs/prds Directory\n```bash\n$ rm -rf docs/prds\n$ bash prd-authoring.sh status\n```\n\n**Result**: PASSED\n- Error message: \"Error: docs/prds/ directory does not exist.\"\n- Helpful guidance: \"Please create it first: mkdir -p docs/prds\"\n- Non-zero exit code\n\n### Test 2.2: Brief Already Exists\n```bash\n$ bash prd-authoring.sh brief \"Payment Gateway Integration\"\n$ bash prd-authoring.sh brief \"Payment Gateway Integration\"\n```\n\n**Result**: PASSED\n- Error message: \"Error: Product brief already exists\"\n- File not overwritten\n- Suggested using different name or editing existing\n\n### Test 2.3: Research Without Brief\n```bash\n$ bash prd-authoring.sh research nonexistent-project\n```\n\n**Result**: PASSED\n- Error: \"Error: Project directory 'docs/prds/nonexistent-project' does not exist.\"\n- Recommended: \"Run 'brief' command first\"\n\n### Test 2.4: Create PRD Without Prerequisites\n```bash\n$ mkdir -p docs/prds/incomplete-project\n$ bash prd-authoring.sh create-prd incomplete-project\n```\n\n**Result**: PASSED\n- Detected missing product brief\n- Error: \"Run 'brief' command first to create the product brief.\"\n\n### Test 2.5: Create PRD Without Research (Warning)\n```bash\n$ bash prd-authoring.sh brief \"No Research Project\"\n$ bash prd-authoring.sh create-prd no-research-project\n```\n\n**Result**: PASSED\n- Warning: \"Research document not found. PRD quality may be reduced.\"\n- Prompted for confirmation: \"Continue anyway? (y/n)\"\n- Allowed proceeding with 'y' but discouraged it\n\n### Test 2.6: Validate PRD That Doesn't Exist\n```bash\n$ bash prd-authoring.sh validate-prd nonexistent-project\n```\n\n**Result**: PASSED\n- Error: \"Error: PRD not found\"\n- Recommended: \"Run 'create-prd' command first\"\n\n### Test 2.7: Decompose Without Complete PRD\n```bash\n$ bash prd-authoring.sh decompose payment-gateway-integration\n```\n(With incomplete/template PRD)\n\n**Result**: PASSED\n- Warning: \"PRD appears incomplete\"\n- Recommended running validate-prd first\n- Still allowed decomposition (user judgment)\n\n### Test 2.8: Generate Spec for Non-existent Epic\n```bash\n$ bash prd-authoring.sh generate-spec payment-gateway-integration \"Nonexistent Epic\"\n```\n\n**Result**: PASSED\n- Warning: \"Could not find epic 'Nonexistent Epic' in epics.md\"\n- Generated generic template anyway\n- User responsible for populating manually\n\n### Test 2.9: Generate Spec When Spec Already Exists\n```bash\n$ bash prd-authoring.sh generate-spec payment-gateway-integration \"Payment Processing Core\"\n$ bash prd-authoring.sh generate-spec payment-gateway-integration \"Payment Processing Core\"\n```\n\n**Result**: PASSED\n- Error: \"Spec proposal directory already exists\"\n- Suggested using different name or deleting existing\n- Files not overwritten\n\n### Test 2.10: Invalid Project Name Characters\n```bash\n$ bash prd-authoring.sh brief \"Test@#$%Project!\"\n```\n\n**Result**: PASSED\n- Sanitized to kebab-case: \"testproject\"\n- Special characters removed\n- Valid directory created\n\n---\n\n## Test Scenario 3: Validation Quality Checks\n\n### Test 3.1: Vague Language Detection\nCreated PRD with vague terms: \"should\", \"might\", \"probably\", \"good\", \"fast\"\n\n**Result**: PASSED\n- Validation detected all vague terms\n- Listed line numbers where issues occurred\n- Provided suggestions for making language specific\n- Example warnings:\n  - \"Line 45: Contains 'should' - be more specific\"\n  - \"Line 67: Contains 'fast' - provide numeric target\"\n\n### Test 3.2: Unmeasurable Success Criteria\nCreated PRD with qualitative success criteria: \"improve user experience\", \"better performance\"\n\n**Result**: PASSED\n- Validation flagged unmeasurable criteria\n- Suggested adding numeric targets\n- Example: \"improve UX\" → \"task completion rate > 85%\"\n\n### Test 3.3: Missing Required Sections\nCreated PRD without \"Assumptions\" section\n\n**Result**: PASSED (Strict Mode)\n- Error: \"Missing required section: ## Assumptions\"\n- Validation failed with recommendation to add section\n\n**Result**: PASSED (Lenient Mode)\n- Warning: \"Missing section: ## Assumptions (lenient mode)\"\n- Validation passed but noted improvement needed\n\n### Test 3.4: Well-Formed PRD\nCreated PRD with:\n- All sections present\n- Specific, measurable requirements\n- SMART objectives\n- Clear acceptance criteria\n\n**Result**: PASSED\n- Validation: \"EXCELLENT ✓\"\n- \"PRD meets all quality standards\"\n- Zero issues, zero warnings\n\n---\n\n## Test Scenario 4: Command Variations\n\n### Test 4.1: Status Command Without Project Name\n```bash\n$ bash prd-authoring.sh status\n```\n(With multiple projects)\n\n**Result**: PASSED\n- Listed all projects in docs/prds/\n- Suggested running status with specific project name\n\n### Test 4.2: Validate PRD Lenient Mode\n```bash\n$ bash prd-authoring.sh validate-prd payment-gateway-integration --lenient\n```\n\n**Result**: PASSED\n- Lenient mode enabled\n- Warnings instead of errors for missing sections\n- Useful for draft PRDs\n\n### Test 4.3: Invalid Command\n```bash\n$ bash prd-authoring.sh invalid-command\n```\n\n**Result**: PASSED\n- Error: \"Unknown command 'invalid-command'\"\n- Usage help displayed\n- Listed all valid commands\n\n### Test 4.4: Missing Required Argument\n```bash\n$ bash prd-authoring.sh brief\n```\n\n**Result**: PASSED\n- Error: \"Project name not provided for 'brief' command\"\n- Usage help: \"Usage: $0 brief <project-name>\"\n\n---\n\n## Test Scenario 5: Integration Tests\n\n### Test 5.1: Complete Workflow End-to-End\nExecuted full workflow from status → brief → research → create-prd → validate-prd → decompose → generate-spec\n\n**Result**: PASSED\n- All commands executed successfully\n- Each step built on previous\n- Final output: Complete spec proposal ready for development\n- Traceability maintained: spec → epic → PRD → brief\n\n### Test 5.2: Parallel Projects\nCreated two separate projects:\n1. payment-gateway-integration\n2. mobile-app-redesign\n\n**Result**: PASSED\n- Both projects coexist independently\n- Status command lists both\n- No cross-contamination of data\n- Proper isolation in separate directories\n\n---\n\n## Test Scenario 6: Validation Accuracy\n\n### Test 6.1: YAML Frontmatter Validation\n- Missing frontmatter: FAILED validation ✓\n- Incomplete frontmatter: WARNING issued ✓\n- Proper frontmatter: PASSED ✓\n\n### Test 6.2: Section Completeness\n- All sections present: PASSED ✓\n- Missing Objectives: FAILED ✓\n- Missing Success Criteria: FAILED ✓\n- Missing Constraints: FAILED (strict) / WARNING (lenient) ✓\n\n### Test 6.3: Requirements Quality\n- Specific acceptance criteria: PASSED ✓\n- Vague requirements: WARNED ✓\n- Missing acceptance criteria: WARNED ✓\n- Unnumbered requirements: WARNED ✓\n\n---\n\n## Summary of Test Results\n\n### Commands Tested: 7/7 PASSED\n1. ✓ status - Works with and without project name\n2. ✓ brief - Creates template with proper structure\n3. ✓ research - Generates comprehensive research template\n4. ✓ create-prd - Creates full PRD template\n5. ✓ validate-prd - Detects quality issues accurately\n6. ✓ decompose - Generates epic breakdown template\n7. ✓ generate-spec - Creates spec proposal structure\n\n### Edge Cases Tested: 10/10 PASSED\n1. ✓ Missing directories - Proper error messages\n2. ✓ Duplicate files - Prevents overwriting\n3. ✓ Missing prerequisites - Clear guidance provided\n4. ✓ Invalid project names - Sanitization works correctly\n5. ✓ Incomplete documents - Warnings appropriate\n6. ✓ Invalid commands - Help text displayed\n7. ✓ Missing arguments - Usage guidance provided\n8. ✓ Parallel projects - Proper isolation\n9. ✓ Validation modes - Strict and lenient work as expected\n10. ✓ Epic generation - Handles missing epics gracefully\n\n### Validation Quality: EXCELLENT\n- Detects vague language accurately\n- Identifies unmeasurable criteria\n- Checks section completeness\n- SMART criteria validation working\n- Both strict and lenient modes functional\n\n### Overall Assessment: ALL TESTS PASSED ✓\n\nThe prd-authoring skill is production-ready with:\n- Complete functionality for all commands\n- Robust error handling for edge cases\n- Clear, actionable error messages\n- Proper validation of document quality\n- Helpful guidance at each step\n- Maintains traceability throughout workflow\n\n## Recommendations\n\n1. **Documentation**: Add examples to SKILL.md showing this workflow\n2. **Troubleshooting**: Document common errors and solutions\n3. **Edge Cases**: Add more examples of error scenarios to documentation\n4. **User Guidance**: Consider adding more inline help in templates\n",
        "skills/project-init/SKILL.md": "---\nname: project-init\ndescription: Use this skill when starting a new project or adding AgenticDev to an existing project. Scaffolds the directory structure (docs/specs, docs/changes) and configuration files needed for the spec-driven development workflow.\n---\n\n# Project Init Skill\n\n## Purpose\n\nInitialize a new project with the AgenticDev directory structure and configuration files. This skill sets up the foundational folders needed for the spec-driven development workflow, creating a standard structure for specifications, change proposals, and documentation.\n\n## When to Use\n\nUse this skill in the following situations:\n\n- Starting a completely new project that will use AgenticDev\n- Adding AgenticDev methodology to an existing project **with no existing documentation**\n- Setting up a consistent structure for spec-driven development\n- Ensuring project follows AgenticDev conventions from the beginning\n\n**Important**: If the project already has documentation in a `docs/` directory, use the **project-migrate** skill instead. It will properly catalog, categorize, and migrate existing documentation into the AgenticDev structure while preserving git history and updating links.\n\n## Prerequisites\n\n- Write permissions to the target directory\n- Git repository already initialized (recommended but not required)\n\n## Workflow\n\n### Step 1: Assess the Current Project State\n\nBefore initializing, determine:\n- Is this a brand new project or an existing codebase?\n- Does a `docs/` directory already exist?\n- If `docs/` exists, does it contain markdown files?\n- Where should the AgenticDev structure be created?\n\n**Decision Tree**:\n- **No docs/ directory**: Proceed with project-init (this skill)\n- **Empty docs/ directory**: Proceed with project-init (this skill)\n- **docs/ with existing markdown files**: Use **project-migrate** skill instead\n\nThe init-project.sh script will automatically detect existing documentation and suggest using project-migrate if appropriate.\n\n### Step 2: Run the Initialization Script\n\nExecute the helper script to create the directory structure:\n\n**For current directory:**\n```bash\nbash scripts/init-project.sh\n```\n\n**For a specific directory:**\n```bash\nbash scripts/init-project.sh -d /path/to/project\n```\n\nThe script will create:\n- `docs/specs/` - Source-of-truth for approved specifications\n- `docs/changes/` - Staging area for proposed changes (Spec PRs)\n\n### Step 3: Verify Structure Creation\n\nCheck that the directories were created successfully:\n```bash\nls -la docs/\n```\n\nExpected output:\n```\ndocs/\n├── specs/\n└── changes/\n```\n\n### Step 4: Initialize Supporting Files (Manual)\n\nAfter the directory structure is created, consider adding these files:\n\n**Create RETROSPECTIVE.md** (in project root):\n```bash\ncat > RETROSPECTIVE.md << 'EOF'\n# Development Retrospective\n\nThis file captures learnings from completed tasks to inform and improve future development work.\n\n## Active Improvements\nEOF\n```\n\n**Create AGENTS.md** (using agent-integrator skill):\n```bash\n# Use the agent-integrator skill to create AGENTS.md\nbash skills/agent-integrator/scripts/update-agents-file.sh\n```\n\n### Step 5: Next Steps\n\nAfter initialization, guide the user on getting started:\n\n1. **Create first specification**: Use the `spec-authoring` skill to propose the first feature\n2. **Set up GitHub integration**: Create GitHub repository if not exists, set up project board\n3. **Document the system**: Add initial specs to `docs/specs/` directory\n4. **Initialize git tracking**: Ensure new directories are committed to version control\n\n## Error Handling\n\n### Directory Already Exists\n\n**Symptom**: Script reports that directories already exist or initialization appears to do nothing\n\n**Solution**:\n- Check if `docs/specs/` and `docs/changes/` already exist\n- If they exist, the project is already initialized\n- No action needed - the script is idempotent\n\n### Permission Denied\n\n**Symptom**: \"Permission denied\" when creating directories\n\n**Solution**:\n- Verify write permissions to the target directory\n- Check if parent directory exists\n- Try with appropriate permissions: `sudo` if necessary (rare)\n\n### Wrong Directory Initialized\n\n**Symptom**: Directories created in unexpected location\n\n**Solution**:\n- Remove incorrect directories: `rm -rf docs/`\n- Re-run with explicit path: `bash scripts/init-project.sh -d /correct/path`\n- Always verify current working directory before running\n\n## Directory Structure Explained\n\n### docs/specs/\n\n**Purpose**: Source-of-truth for all approved specifications\n\n**Contents**:\n- Approved specification files\n- Design documents\n- Architecture decisions\n- System requirements\n\n**Example structure**:\n```\ndocs/specs/\n├── 001-initial-system.md\n├── 002-authentication.md\n└── feature-name/\n    ├── spec.md\n    └── design.md\n```\n\n### docs/changes/\n\n**Purpose**: Staging area for proposed changes before approval\n\n**Contents**:\n- Change proposals in review\n- Spec deltas for new features\n- Task breakdowns\n- Planning documents\n\n**Example structure**:\n```\ndocs/changes/\n├── my-feature/\n│   ├── proposal.md\n│   ├── spec-delta.md\n│   └── tasks.md\n└── another-feature/\n    └── proposal.md\n```\n\n**Workflow**: Changes start in `docs/changes/`, get approved via Spec PR, then move to `docs/specs/`\n\n## project-init vs project-migrate\n\nUnderstanding when to use each skill:\n\n### Use project-init when:\n- Starting a **brand new project** from scratch\n- Project has **no existing documentation**\n- docs/ directory is **empty** or doesn't exist\n- You just need the basic AgenticDev directory structure\n\n### Use project-migrate when:\n- Project has **existing documentation** in docs/ or other locations\n- You want to **migrate legacy docs** into AgenticDev structure\n- You need to **preserve git history** during migration\n- Documentation has **relative links** that need updating\n- You want **doc-indexer compliant frontmatter** added automatically\n\n### Smooth Handoff\n\nThe init-project.sh script automatically detects existing documentation and will:\n1. Count markdown files in docs/ (excluding docs/specs/ and docs/changes/)\n2. If found, display a recommendation to use project-migrate\n3. Show the benefits of using project-migrate over basic initialization\n4. Give you the option to continue with project-init or cancel\n\nThis ensures you always use the right skill for your situation.\n\n## Notes\n\n- The script is **idempotent** - safe to run multiple times\n- Existing directories won't be overwritten or deleted\n- The script only creates directories, no files are created automatically\n- Consider adding `.gitkeep` files to track empty directories in git\n- This is just the directory scaffold - content comes from using other skills\n- The structure is intentionally minimal - projects add what they need\n- **Detection logic**: The script checks for markdown files in docs/, excluding those already in specs/ or changes/ subdirectories\n",
        "skills/project-migrate/SKILL.md": "---\nname: project-migrate\ndescription: Use this skill to migrate existing projects to the AgenticDev structure. It uses an AI-powered analysis to intelligently discover, categorize, and migrate documentation, generate rich frontmatter, and preserve git history.\n---\n\n# Project Migrate Skill\n\n## Purpose\n\nTo intelligently migrate existing projects (brownfield) to the AgenticDev directory structure using a powerful, AI-assisted workflow. This skill goes beyond simple file moving by leveraging the **Gemini CLI** to analyze document content, ensuring accurate categorization and the generation of rich, meaningful metadata. It provides a safe, guided migration with discovery, analysis, backup, and validation phases to ensure zero data loss and high-quality results.\n\n## When to Use\n\nUse this skill in the following situations:\n\n- Adding AgenticDev to an existing project with established documentation.\n- Migrating docs from an ad-hoc structure to AgenticDev conventions.\n- When you want to automatically and intelligently categorize and add metadata to existing documents.\n- To ensure a safe migration with backups and rollback capabilities.\n\n## Prerequisites\n\n- Project with existing documentation (`docs/`, `documentation/`, `wiki/`, or markdown files).\n- Git repository initialized.\n- Write permissions to the project directory.\n- `gemini` CLI tool installed and authenticated.\n- `doc-indexer` skill available for final compliance checking.\n\n## Workflow\n\nThe skill guides you through a series of phases with interactive approval.\n\n### Step 1: Run the Migration Script\n\nExecute with one of three modes:\n\n**Interactive (default)** - Review and approve each phase:\n```bash\nbash scripts/project-migrate.sh\n```\n\n**Dry-run** - Preview the plan without making any changes:\n```bash\nbash scripts/project-migrate.sh --dry-run\n```\n\n**Auto-approve** - Skip prompts for automation (useful for CI/CD):\n```bash\nbash scripts/project-migrate.sh --auto-approve\n```\n\n### Step 2: Review Each Phase\n\n**Phase 1 & 2 - AI-Powered Discovery and Analysis**:\nThe script scans for all markdown files. For each file, it calls the **Gemini CLI** to analyze the document's *content*, not just its filename. This results in a much more accurate categorization of files into types like `spec`, `proposal`, `adr`, etc. The output is a detailed plan mapping each file to its new, correct location in the AgenticDev structure.\n\n**Phase 3 - Planning**:\nShows you the complete, AI-driven migration plan for your approval. You can review source and target mappings before any files are moved.\n\n**Phase 4 - Backup**:\nCreates a timestamped backup directory of your entire `docs/` folder and includes a `rollback.sh` script before any changes are made.\n\n**Phase 5 - Migration**:\nExecutes the plan, moving files using `git mv` to preserve history and creating the necessary directory structure.\n\n**Phase 6 - LLM-Based Link Updates**:\nUses the Gemini CLI to intelligently identify and correct broken or outdated relative links within migrated files. This LLM-based approach is more robust than simple path recalculation, as it understands document context and can handle edge cases that pattern matching might miss.\n\n**Phase 7 - Validation**:\nVerifies that all files were migrated correctly, checks link integrity, and validates the new directory structure.\n\n**Phase 8 - AI-Powered Frontmatter Generation (Optional)**:\nFor files that lack YAML frontmatter, the script uses the **Gemini CLI** to read the file content and generate rich, `doc-indexer` compliant frontmatter. This includes a suggested `title`, the `type` determined during the analysis phase, and a concise `description` summarizing the document's purpose.\n\n### Step 3: Post-Migration\n\nAfter successful completion:\n- Review the validation report for any warnings.\n- Run the `doc-indexer` skill to verify full documentation compliance.\n- Commit the migration changes to git.\n\n## Error Handling\n\n### Gemini CLI Issues\n\n**Symptom**: The script fails during the \"Analysis\" or \"Frontmatter Generation\" phase with an error related to the `gemini` command.\n\n**Solution**:\n- Ensure the `gemini` CLI is installed and in your system's PATH.\n- Verify you are authenticated by running `gemini auth`.\n- Check for Gemini API outages or network connectivity issues.\n- The script has basic fallbacks, but for best results, ensure the Gemini CLI is functional.\n\n### Other Issues\n\nFor issues related to permissions, conflicts, or broken links, the script provides detailed error messages and resolution suggestions during its interactive execution. The backup and rollback script is always available for a safe exit.\n\n## Notes\n\n- **AI-Enhanced**: Uses Gemini for intelligent content analysis, not just simple pattern matching.\n- **Safe by default**: Creates a full backup with a rollback script before making any changes.\n- **Git-aware**: Preserves file history using `git mv`.\n- **Interactive**: You review and approve the AI-generated plan before execution.\n- **Rich Metadata**: Generates high-quality frontmatter, including titles and descriptions.\n- **LLM-Powered Link Correction**: Uses Gemini to intelligently update relative links with context awareness.",
        "skills/skill-lister/SKILL.md": "---\nname: skill-lister\ndescription: Use this skill to discover all available AgenticDev skills and their capabilities. Provides a bootstrap context for AI agents by listing all skills, their descriptions, and script paths from the .claude/skills/ directory.\n---\n\n# Skill Lister\n\n## Purpose\n\nProvide a comprehensive overview of all available AgenticDev skills in the project. The skill-lister scans the `.claude/skills/` directory, extracts skill metadata from SKILL.md files, and returns a formatted list of all discovered skills with their descriptions and script paths. This enables AI agents to quickly understand what capabilities are available without manually exploring the directory structure.\n\n## When to Use\n\nUse this skill in the following situations:\n\n- At the beginning of any work session to understand available AgenticDev capabilities\n- When onboarding to a new project using AgenticDev\n- Before deciding which skill to use for a particular task\n- When documenting or auditing the project's AgenticDev setup\n- To verify that all expected skills are installed and accessible\n\n## Prerequisites\n\n- The project must have a `.claude/skills/` directory\n- Skills should follow the convention of including SKILL.md files with YAML frontmatter\n- No additional tools required (pure bash implementation)\n\n## Workflow\n\n### Step 1: Run the Skill Lister\n\nExecute the helper script to scan all skills in the .claude/skills/ directory:\n\n```bash\nbash .claude/skills/skill-lister/scripts/list-skills.sh\n```\n\nThis will output a human-readable summary showing each skill's metadata including:\n- Skill name\n- Description\n- Available scripts\n\nFor machine-readable JSON output (useful for programmatic processing):\n\n```bash\nbash .claude/skills/skill-lister/scripts/list-skills.sh -j\n```\n\n### Step 2: Review the Skills List\n\nThe scanner returns information about all skills found in `.claude/skills/`, including:\n\n- **Skill name**: The identifier for the skill (from YAML frontmatter)\n- **Description**: What the skill does and when to use it\n- **Script paths**: All executable scripts available for the skill\n- **Directory**: Location of the skill in the filesystem\n\n### Step 3: Choose the Appropriate Skill\n\nBased on the output, select the skill that best matches your current task:\n\n- Need to understand documentation? → Use `doc-indexer`\n- Starting work on an issue? → Use `issue-executor`\n- Proposing a change? → Use `spec-authoring`\n- Planning a sprint? → Use `sprint-planner`\n- Setting up a new project? → Use `project-init`\n\n## Error Handling\n\n### No Skills Directory Found\n\n**Symptom**: Script reports that `.claude/skills/` directory doesn't exist\n\n**Solution**:\n- Verify you're in the project root directory\n- Run `project-init` skill to set up AgenticDev\n- Check if skills are installed in a different location\n\n### Missing SKILL.md Files\n\n**Symptom**: Script lists skills but shows no metadata\n\n**Solution**:\n- Verify that each skill directory contains a SKILL.md file\n- Check that SKILL.md files have proper YAML frontmatter with `name` and `description` fields\n- Run validation script if available: `bash scripts/validate-skills.sh`\n\n### No Scripts Found\n\n**Symptom**: Skill is listed but shows no scripts\n\n**Solution**:\n- Verify that the skill's `scripts/` directory exists and contains executable files\n- Check file permissions: `chmod +x .claude/skills/*/scripts/*`\n- Some skills may not have scripts (documentation-only skills)\n\n### Permission Denied\n\n**Symptom**: Cannot read skill directories or files\n\n**Solution**:\n- Check directory permissions: `ls -la .claude/skills/`\n- Ensure you have read access to the skills directory\n- Verify the script itself is executable: `chmod +x .claude/skills/skill-lister/scripts/list-skills.sh`\n\n## Notes\n\n- **Bootstrap context**: Designed to be run by agent-integrator to provide AI agents with skill discovery capability\n- **Lightweight**: Minimal dependencies, works with standard bash tools\n- **Extensible**: Automatically discovers new skills as they're added\n- **JSON support**: Can output structured data for integration with other tools\n- **Convention-based**: Relies on standard AgenticDev skill structure (SKILL.md + scripts/)\n- **Safe to run**: Read-only operation with no side effects\n- **Discovery pattern**: Similar to doc-indexer but for skills instead of documentation\n",
        "skills/spec-authoring/SKILL.md": "---\nname: spec-authoring\ndescription: Use this skill to propose changes via the Spec PR process. It uses the Gemini CLI to generate high-quality draft specifications and to analyze PR feedback, accelerating the spec-driven development workflow. Triggers include \"create spec\" or \"propose change\".\n---\n\n# Spec Authoring Skill\n\n## Purpose\n\nTo manage the creation and refinement of feature specifications using a powerful, AI-assisted workflow. This skill leverages the **Gemini CLI** to accelerate the spec-driven development process by:\n1.  **Generating Drafts**: Automatically creates high-quality, multi-file draft proposals for new features.\n2.  **Analyzing Feedback**: Synthesizes review comments from Pull Requests into an actionable summary of recommended changes.\n\nThis approach allows developers and product managers to move from idea to an approved, implementation-ready specification with greater speed and clarity.\n\n## When to Use\n\nUse this skill in the following situations:\n\n- Proposing a new feature or significant change.\n- Generating a first draft of a specification for review.\n- Processing and incorporating feedback from a Spec PR.\n\n## Prerequisites\n\n- Project initialized with AgenticDev structure (`docs/specs/` and `docs/changes/` directories exist).\n- GitHub repository set up.\n- `gh` CLI tool installed and authenticated.\n- `gemini` CLI tool installed and authenticated.\n\n## Spec PR Philosophy\n\n**Specs as Code**: All specification changes follow the same rigor as code changes—proposed via branches, reviewed via PRs, and merged upon approval. This skill supercharges that philosophy with AI.\n\n---\n\n## The `propose` Command\n\n### Purpose\n\nGenerate a comprehensive, multi-file draft proposal for a new feature from a single command.\n\n### Workflow\n\n#### Step 1: Define the Proposal Name\n\nChoose a clear, descriptive name for your feature, such as \"User Authentication System\" or \"Real-time Notifications\".\n\n#### Step 2: Run the Helper Script\n\nExecute the script to generate the draft proposal:\n```bash\nbash scripts/spec-authoring.sh propose \"Feature Name\"\n```\n\nThe script will:\n1.  Create a new directory in `docs/changes/feature-name/`.\n2.  Make three parallel calls to the **Gemini CLI** to generate drafts for `proposal.md`, `spec-delta.md`, and `tasks.md`.\n    - **`proposal.md`**: A high-level overview with problem statement, proposed solution, and success criteria.\n    - **`spec-delta.md`**: A detailed technical specification with requirements and design decisions.\n    - **`tasks.md`**: A preliminary breakdown of implementation tasks.\n3.  Save the AI-generated content into these files.\n\n#### Step 3: Review and Refine the Drafts\n\nThe script provides you with a complete, context-aware first draft of your entire proposal. Your next step is to review and refine these documents to ensure they align with your vision before opening a Spec PR.\n\n---\n\n## The `update` Command\n\n### Purpose\n\nIntelligently process feedback from a Spec PR by using AI to analyze review comments and generate a summarized action plan.\n\n### Workflow\n\n#### Step 1: Identify the PR Number\n\nDetermine which Spec PR you need to update.\n\n#### Step 2: Run the Feedback Analysis Script\n\nExecute the script with the PR number:\n```bash\nbash scripts/spec-authoring.sh update PR_NUMBER\n```\n\nThis command will:\n1.  Find the local files associated with the PR's branch.\n2.  Fetch all review comments from the PR.\n3.  Send the full content of your spec files and all the comments to the **Gemini CLI**.\n4.  Ask the AI to act as a reviewer and provide a summarized list of recommended changes for each file.\n\n#### Step 3: Address the Synthesized Feedback\n\nThe script will output a clear, actionable plan that synthesizes all the reviewer feedback. Use this analysis to efficiently update your proposal files, address the comments, and push your changes for re-review.\n\n---\n\n## Error Handling\n\n### Gemini CLI Issues\n\n**Symptom**: The script fails during the `propose` or `update` commands with an error related to the `gemini` command.\n**Solution**:\n- Ensure the `gemini` CLI is installed and in your system's PATH.\n- Verify you are authenticated (`gemini auth`).\n- Check for Gemini API outages or network issues.\n\n### Proposal Directory Already Exists\n\n**Symptom**: The `propose` command reports that the directory already exists.\n**Solution**: Choose a different name for your proposal or work with the existing one.\n\n### Could Not Find Proposal Directory\n\n**Symptom**: The `update` command cannot find the local files for the PR.\n**Solution**: Ensure you have the correct PR branch checked out and that the local directory in `docs/changes/` matches the branch name.\n\n## Notes\n\n- **AI-Assisted Workflow**: This skill is designed to be a powerful assistant. It generates high-quality drafts and analyzes feedback, but the final strategic decisions and refinements are yours to make.\n- **Speed and Quality**: By automating the initial drafting and feedback synthesis, this skill allows you to focus on the high-value work of design, review, and alignment.\n- **Iterative Process**: Use the `propose` command to start, and the `update` command to iterate based on team feedback, creating a rapid and efficient spec development cycle.",
        "skills/sprint-manager/SKILL.md": "---\nname: sprint-manager\ndescription: This skill orchestrates autonomous sprint execution by coordinating subagents to implement GitHub issues serially. It manages the full lifecycle: generating implementation plans via Gemini CLI, delegating implementation to subagents, reviewing PRs with Codex MCP, merging approved code, and running post-merge integration. Use this skill when asked to \"run a sprint\", \"execute sprint issues\", \"implement issues autonomously\", or \"manage sprint workflow\".\n---\n\n# Sprint Manager\n\n## Purpose\n\nTo autonomously execute a sprint by coordinating the implementation of GitHub issues through a structured workflow that leverages subagents for isolated work and maintains a clean context window for sprint-level coordination.\n\n## When to Use\n\nUse this skill in the following situations:\n\n- Starting work on a set of sprint issues from a GitHub milestone\n- Implementing multiple issues autonomously with minimal user intervention\n- Coordinating a development workflow that requires code review and integration\n- Managing serial execution of dependent or independent issues\n\n## Prerequisites\n\n- GitHub repository with issues assigned to a milestone\n- Git working directory is clean (no uncommitted changes)\n- `gh` CLI tool installed and authenticated\n- `gemini` CLI tool installed and authenticated (optional, for plan generation)\n- Codex MCP available for PR review\n- Project has `issue-executor` and `change-integrator` skills (or equivalent workflow)\n\n## Architecture\n\nThe sprint manager operates as a coordinator that delegates work to subagents:\n\n```\nSprint Manager (main context)\n│\n├── For each issue:\n│   ├── 1. Generate implementation plan (Gemini CLI or manual)\n│   ├── 2. Create feature branch\n│   ├── 3. Launch implementer subagent → creates PR\n│   ├── 4. Review PR (Codex MCP)\n│   ├── 5. Fix issues if needed (another subagent)\n│   ├── 6. Merge on approval\n│   └── 7. Launch integrator subagent → cleanup & retrospective\n│\n└── Report sprint summary\n```\n\n## Core Workflow\n\n### Phase 1: Sprint Setup\n\n1. **Identify sprint issues** by querying the GitHub milestone:\n   ```bash\n   gh issue list --milestone \"Sprint X\" --state open --json number,title,labels\n   ```\n\n2. **Prioritize issues** based on labels (P0 > P1 > P2) and dependencies\n\n3. **Track progress** using the TodoWrite tool with all sprint issues\n\n### Phase 2: Issue Execution Loop\n\nFor each issue in priority order:\n\n#### Step 1: Generate Implementation Plan\n\nOption A - Use issue-executor skill (if Gemini available):\n```bash\nbash scripts/work-on-issue.sh <issue-number>\n```\n\nOption B - Manual plan generation:\n1. Fetch issue details: `gh issue view <number> --json title,body`\n2. Read relevant specs from `docs/specs/` or `docs/changes/`\n3. Call Gemini CLI with context to generate a step-by-step plan\n4. Create feature branch following convention: `feat/<number>-<kebab-title>`\n\n#### Step 2: Delegate Implementation to Subagent\n\nLaunch a Task subagent with a comprehensive prompt including:\n\n- Issue number and acceptance criteria\n- Implementation plan from Step 1\n- Project conventions (from CLAUDE.md)\n- File paths and schema context\n- Expected deliverables (PR URL, test results, files created)\n- Fallback instructions if tools fail\n\nSelect appropriate subagent type based on the issue:\n- `backend-architect` - API routes, database schemas, backend logic\n- `frontend-developer` - React components, UI, client-side code\n- `general-purpose` - Mixed or unclear scope\n\nExample prompt structure (see `references/implementer-prompt-template.md`):\n```\n## Task: Implement GitHub Issue #<number> - <title>\n\nYou are working on branch `<branch-name>` in `<working-directory>`.\n\n### Issue Summary\n<brief description>\n\n### Implementation Plan\n<step-by-step plan from Gemini or manual>\n\n### Project Conventions\n<key conventions from CLAUDE.md>\n\n### Your Deliverables\n1. Implement the code\n2. Run lint and tests\n3. Commit with conventional commit message\n4. Push and create PR\n\n### Report Back\n<what to return: PR URL, test results, issues encountered>\n```\n\n#### Step 3: Review PR with Codex MCP\n\nAfter subagent returns with PR URL:\n\n```\nmcp__codex__codex with prompt:\n\"Review PR #<number>: <title>\nURL: <pr-url>\n\nThe PR implements: <summary>\n\nFocus your review on: <relevant concerns>\n\nSay APPROVED if ready to merge, or list issues with severity.\"\n```\n\n#### Step 4: Handle Review Feedback\n\nIf Codex finds issues:\n1. Launch another subagent to fix the issues\n2. Provide specific fix instructions from Codex feedback\n3. Re-review after fixes are pushed\n\nIf Codex approves:\n- Proceed to merge\n\n#### Step 5: Merge PR\n\n```bash\ngh pr merge <number> --squash --auto\n```\n\nWait for CI to pass, then verify merge:\n```bash\ngh pr view <number> --json state\n```\n\n#### Step 6: Post-Merge Integration\n\nLaunch integrator subagent (see `references/integrator-prompt-template.md`):\n\n1. Switch to main and pull latest\n2. Delete feature branch (local and remote)\n3. Update retrospective with learnings\n4. Close issue if not auto-closed\n5. Report completion status\n\n### Phase 3: Sprint Completion\n\nAfter all issues are processed:\n\n1. Update TodoWrite to mark all issues complete\n2. Summarize sprint results:\n   - Issues completed\n   - PRs merged\n   - Key learnings\n   - Any blockers encountered\n3. Report to user\n\n## Error Handling\n\n### Gemini CLI Fails\n\nIf the Gemini CLI fails during plan generation:\n- Fall back to manual plan creation\n- Read issue details directly via `gh issue view`\n- Check relevant specs in `docs/specs/` or `docs/changes/`\n- Construct implementation plan based on acceptance criteria\n\n### Subagent Fails\n\nIf an implementer subagent fails:\n- Review the error reported\n- Launch a new subagent with adjusted instructions\n- Consider breaking the task into smaller pieces\n- Flag for user intervention if repeated failures\n\n### Codex Review Times Out\n\nIf Codex MCP doesn't respond:\n- Retry the review request\n- Fall back to basic automated checks (lint, tests)\n- Flag PR for user manual review\n\n### PR Merge Conflicts\n\nIf merge fails due to conflicts:\n- Rebase the branch on main\n- Launch subagent to resolve conflicts\n- Re-run tests and review\n\n## Prompt Templates\n\nSee the `references/` directory for detailed prompt templates:\n\n- `references/implementer-prompt-template.md` - Template for implementation subagents\n- `references/integrator-prompt-template.md` - Template for post-merge integration subagents\n- `references/review-prompt-template.md` - Template for Codex PR reviews\n\n## Best Practices\n\n### Context Management\n\n- Keep sprint-level state in the main context (issue tracking, PR URLs, blockers)\n- Delegate all implementation details to subagents\n- Each subagent gets a fresh context - include all needed info in the prompt\n\n### Prompt Crafting\n\n- Be specific about file paths and existing code context\n- Include project conventions explicitly (subagents don't read CLAUDE.md)\n- Specify exact deliverables and report format\n- Provide fallback instructions for common failure modes\n\n### Serial vs Parallel\n\n- Default to serial execution for safety and easier debugging\n- Only parallelize truly independent issues with explicit user approval\n- Never parallelize issues with shared file dependencies\n\n### User Communication\n\n- Report progress after each issue completes\n- Flag blockers immediately rather than retrying indefinitely\n- Provide sprint summary at the end\n\n## Notes\n\n- This skill is designed for serial execution to maintain context clarity\n- Each issue gets its own subagent context, keeping the main context clean\n- The workflow integrates with existing issue-executor and change-integrator skills\n- Codex MCP provides automated code review without user intervention\n- Retrospective updates capture learnings for future sprints\n",
        "skills/sprint-manager/references/implementer-prompt-template.md": "# Implementer Subagent Prompt Template\n\nUse this template when launching a subagent to implement a GitHub issue.\n\n## Template\n\n```markdown\n## Task: Implement GitHub Issue #<ISSUE_NUMBER> - <ISSUE_TITLE>\n\nYou are working on branch `<BRANCH_NAME>` in `<WORKING_DIRECTORY>`.\n\n### Issue Summary\n\n<Brief description of what needs to be implemented>\n\n### Implementation Plan\n\n<Step-by-step implementation plan, either from Gemini CLI or manually constructed>\n\n**Step 1: <First task>**\n<Details>\n\n**Step 2: <Second task>**\n<Details>\n\n... (continue for all steps)\n\n### Existing Code Context\n\n<Relevant files and their purposes>\n- `<file_path>` - <description>\n- `<file_path>` - <description>\n\n### Schema/Type Definitions\n\n<If relevant, include type definitions the subagent needs>\n\n```typescript\n// Example type context\ninterface ExampleType {\n  field: string;\n}\n```\n\n### Project Conventions\n\n- TypeScript with 2-space indentation\n- Use `@/` path alias for imports\n- Conventional Commits: `feat:`, `fix:`, `chore:`\n- Run `npm run lint` before committing\n- Run `npm run test` to verify tests pass\n\n### Test Requirements\n\n<List specific tests to implement>\n- Test: <description>\n- Test: <description>\n\n### Your Deliverables\n\n1. Create/modify the necessary files\n2. Implement all acceptance criteria\n3. Write tests as specified\n4. Run `npm run lint` - fix any errors\n5. Run `npm run test` - ensure tests pass\n6. Commit with message: `<type>: <description> (#<ISSUE_NUMBER>)`\n7. Push: `git push -u origin <BRANCH_NAME>`\n8. Create PR: `gh pr create --title \"<PR_TITLE>\" --body \"...\" --label \"<labels>\" --milestone \"<MILESTONE>\"`\n\n### Report Back\n\nWhen done, report:\n1. PR URL\n2. Test results summary (pass/fail count)\n3. Files created/modified\n4. Any issues encountered\n```\n\n## Variables to Fill\n\n| Variable | Description | Example |\n|----------|-------------|---------|\n| `<ISSUE_NUMBER>` | GitHub issue number | `144` |\n| `<ISSUE_TITLE>` | Issue title | `Design Lesson Content JSON Schema` |\n| `<BRANCH_NAME>` | Feature branch name | `feat/144-design-lesson-content-json-schema` |\n| `<WORKING_DIRECTORY>` | Absolute path to repo | `/home/user/project` |\n| `<MILESTONE>` | Sprint milestone name | `Sprint 5: Rich Curriculum` |\n\n## Subagent Type Selection\n\nChoose the subagent type based on the issue:\n\n| Issue Type | Subagent Type | Use When |\n|------------|---------------|----------|\n| API routes, backend | `backend-architect` | Database, APIs, server logic |\n| React components, UI | `frontend-developer` | Components, styling, client-side |\n| Database/schema | `backend-architect` | Prisma, migrations |\n| Mixed/unclear | `general-purpose` | Multiple areas, small tasks |\n| Quick fixes | `general-purpose` with `model: haiku` | Simple changes |\n\n## Tips for Effective Prompts\n\n1. **Be explicit about file paths** - Subagents don't have your context\n2. **Include type definitions** - Copy relevant interfaces/types into the prompt\n3. **Specify exact test cases** - Don't leave testing open-ended\n4. **Provide fallback instructions** - What to do if a step fails\n5. **Request specific output format** - Makes parsing the response easier\n",
        "skills/sprint-manager/references/integrator-prompt-template.md": "# Integrator Subagent Prompt Template\n\nUse this template when launching a subagent to perform post-merge integration tasks.\n\n## Template\n\n```markdown\n## Task: Post-Merge Integration for PR #<PR_NUMBER>\n\nWorking directory: `<WORKING_DIRECTORY>`\n\nPR #<PR_NUMBER> (Issue #<ISSUE_NUMBER>: <ISSUE_TITLE>) has been merged.\n\n### Steps\n\n1. Switch to main and pull:\n```bash\ngit switch main && git pull --ff-only\n```\n\n2. Delete feature branch:\n```bash\ngit push origin --delete <BRANCH_NAME> || echo \"Already deleted\"\ngit branch -D <BRANCH_NAME> || echo \"Already deleted\"\ngit remote prune origin\n```\n\n3. Update retrospective - append to `<RETROSPECTIVE_PATH>`:\n\n```markdown\n\n## PR #<PR_NUMBER> - <ISSUE_TITLE>\n\n**Date**: <DATE>\n**Issue**: #<ISSUE_NUMBER>\n**Epic**: #<EPIC_NUMBER> - <EPIC_TITLE>\n\n### What Went Well\n- <key accomplishment 1>\n- <key accomplishment 2>\n- <key accomplishment 3>\n\n### Lessons Learned\n- <lesson 1>\n- <lesson 2>\n\n### Technical Notes\n- <technical detail 1>\n- <technical detail 2>\n```\n\n4. Commit and push:\n```bash\ngit add docs/\ngit commit -m \"docs: Add retrospective for PR #<PR_NUMBER>\"\ngit push\n```\n\n5. Close issue (if not auto-closed):\n```bash\ngh issue close <ISSUE_NUMBER> --comment \"Completed in PR #<PR_NUMBER>\"\n```\n\n### Report Back\n- Branch cleanup status\n- Retrospective update status\n- Issue close status\n```\n\n## Variables to Fill\n\n| Variable | Description | Example |\n|----------|-------------|---------|\n| `<PR_NUMBER>` | Pull request number | `152` |\n| `<ISSUE_NUMBER>` | GitHub issue number | `144` |\n| `<ISSUE_TITLE>` | Issue title | `Design Lesson Content JSON Schema` |\n| `<BRANCH_NAME>` | Feature branch to delete | `feat/144-design-lesson-content-json-schema` |\n| `<WORKING_DIRECTORY>` | Absolute path to repo | `/home/user/project` |\n| `<RETROSPECTIVE_PATH>` | Path to retrospective file | `docs/changes/retrospective.md` |\n| `<DATE>` | Current date | `2025-11-22` |\n| `<EPIC_NUMBER>` | Parent epic issue number | `143` |\n| `<EPIC_TITLE>` | Parent epic title | `Rich Curriculum and Interactive Content` |\n\n## Retrospective Content Guidelines\n\n### What Went Well\nFocus on:\n- Clean implementation patterns discovered\n- Good test coverage achieved\n- Smooth integration with existing code\n- Effective use of libraries/frameworks\n\n### Lessons Learned\nFocus on:\n- Gotchas encountered and how they were resolved\n- Patterns that didn't work initially\n- Things to do differently next time\n- Edge cases discovered during implementation\n\n### Technical Notes\nInclude:\n- Key file paths created/modified\n- Dependencies added\n- Schema changes made\n- Configuration changes\n- Breaking changes or migration notes\n\n## Tips\n\n1. **Use haiku model** - Integration tasks are straightforward, save tokens\n2. **Check for auto-close** - Many PRs auto-close issues via \"Closes #X\" in PR body\n3. **Create retrospective if missing** - First integration should create the file\n4. **Keep retrospectives concise** - Focus on actionable learnings\n",
        "skills/sprint-manager/references/review-prompt-template.md": "# Code Review Prompt Template (Codex MCP)\n\nUse this template when calling Codex MCP to review a pull request.\n\n## Basic Review Template\n\n```markdown\nReview PR #<PR_NUMBER>: <PR_TITLE>\nURL: <PR_URL>\n\nThe PR implements:\n<bullet list of what the PR does>\n\nFocus your review on:\n<specific areas of concern based on the PR type>\n\nIf everything looks good, say \"APPROVED\". If there are issues, list them with severity (critical/major/minor).\n```\n\n## Review Focus by PR Type\n\n### Schema/Type Changes\n```markdown\nFocus your review on:\n- Schema design correctness\n- TypeScript type inference quality\n- Validation logic completeness\n- Forward/backward compatibility\n- JSDoc documentation quality\n```\n\n### React Components\n```markdown\nFocus your review on:\n- React component patterns and hooks usage\n- Error boundary implementation\n- Accessibility (keyboard nav, ARIA, alt text)\n- Responsive design considerations\n- TypeScript type safety\n- Test coverage quality\n```\n\n### API Routes\n```markdown\nFocus your review on:\n- Authentication and authorization checks\n- Input validation and sanitization\n- Error handling and response codes\n- Database query efficiency\n- TypeScript type safety\n- Security considerations (injection, OWASP)\n```\n\n### Database/Schema Changes\n```markdown\nFocus your review on:\n- Migration safety (can it be rolled back?)\n- Index implications for query performance\n- Data integrity constraints\n- Backward compatibility with existing data\n- Required environment/deployment steps\n```\n\n### Integration Changes\n```markdown\nFocus your review on:\n- Hydration handling (server/client consistency)\n- Feature flag implementation correctness\n- Backward compatibility\n- Error boundaries and fallbacks\n- Loading and skeleton states\n```\n\n## Re-Review Template (After Fixes)\n\n```markdown\nRe-review PR #<PR_NUMBER> after fixes were applied:\n\n<list of fixes made>\n\nVerify the fixes address all previous concerns. Say \"APPROVED\" if ready to merge.\n```\n\n## Handling Review Results\n\n### If APPROVED\n```bash\ngh pr merge <PR_NUMBER> --squash --auto\n```\n\n### If Issues Found\n\n1. Parse the issues by severity\n2. For critical/major issues: Launch fix subagent\n3. For minor issues: Consider accepting with follow-up task\n4. Re-review after fixes\n\n### Fix Subagent Prompt\n\n```markdown\n## Task: Fix Code Review Issues for PR #<PR_NUMBER>\n\nWorking in `<WORKING_DIRECTORY>` on branch `<BRANCH_NAME>`.\n\n### Issues to Fix\n\n**1. <SEVERITY> - <Issue title>** (<file:lines>)\n<Problem description>\n\n**Fix**: <Specific fix instructions>\n\n... (repeat for each issue)\n\n### Steps\n1. Pull latest from branch\n2. Fix all issues in the component files\n3. Add tests if needed\n4. Run `npm run lint`\n5. Run tests to verify all pass\n6. Commit: `fix: address code review feedback (#<ISSUE_NUMBER>)`\n7. Push to branch\n\n### Report Back\n- Confirmation that all issues are fixed\n- Test results\n- Any additional issues found\n```\n\n## Severity Guidelines\n\n| Severity | Description | Action |\n|----------|-------------|--------|\n| Critical | Breaks functionality, security issue, data loss risk | Must fix before merge |\n| High | Significant bug, missing error handling | Should fix before merge |\n| Medium | Code quality, edge cases | Fix or create follow-up |\n| Minor/Low | Style, optimization, nice-to-have | Accept with optional follow-up |\n\n## Tips\n\n1. **Be specific about focus areas** - Guide Codex to relevant concerns\n2. **Include PR URL** - Helps Codex fetch the actual diff\n3. **Summarize what PR does** - Provides context for the review\n4. **Request severity levels** - Makes triage decisions clearer\n5. **Re-review is cheaper** - Verify fixes rather than re-reviewing everything\n",
        "skills/sprint-planner/SKILL.md": "---\nname: sprint-planner\ndescription: Use this skill to plan a new sprint. It uses the Gemini CLI to intelligently decompose approved specs into atomic GitHub issues for the development team. Triggers include \"plan sprint\", \"create sprint\", or \"start new sprint\".\n---\n\n# Sprint Planner Skill\n\n## Purpose\n\nTo plan and initialize a new sprint by intelligently decomposing approved specifications into a comprehensive set of atomic GitHub issues. This skill bridges the gap between high-level specs and executable work items by using the **Gemini CLI** to analyze the spec's content and generate a thoughtful task breakdown. It then automates the creation of these tasks as GitHub issues within a new sprint milestone.\n\n## When to Use\n\nUse this skill in the following situations:\n\n- Starting a new sprint or development cycle.\n- Converting an approved spec into actionable GitHub issues.\n- When you want an AI-assisted breakdown of an epic into atomic implementation tasks.\n\n## Prerequisites\n\n- Project board configured with an \"Approved Backlog\" status column.\n- Approved spec files exist in the `docs/specs/` directory.\n- An Epic issue exists on GitHub that links to the spec file in its body.\n- `gh` CLI tool installed and authenticated.\n- `jq` tool installed for JSON parsing.\n- `gemini` CLI tool installed and authenticated.\n\n## Workflow\n\n### Step 1: Review Project Board\n\nCheck the project board for approved specs (represented as Epics) ready to be planned.\n\n### Step 2: Discuss Sprint Scope with User\n\nEngage the user to determine which epic(s) from the \"Approved Backlog\" to include in the sprint.\n\n### Step 3: Define Sprint Metadata\n\nWork with the user to establish the sprint name (e.g., \"Sprint 4\").\n\n### Step 4: Run the Helper Script\n\nExecute the sprint planning script to automate GitHub issue creation:\n\n```bash\nbash scripts/create-sprint-issues.sh\n```\n\n### Step 5: Understand What the Script Does\n\nThe helper script automates these steps:\n\n1.  **Queries Project Board**: Fetches all items from the \"Approved Backlog\" and prompts you to select an Epic to plan.\n2.  **Extracts Spec File**: Parses the selected Epic's body to find the associated spec file path.\n3.  **Creates Milestone**: Prompts you for a sprint name and creates the corresponding GitHub milestone.\n4.  **Decomposes Spec with AI**: Instead of relying on a rigid format, the script sends the full content of the spec file and the parent Epic to the **Gemini CLI**. It asks the AI to generate a list of atomic, actionable tasks based on its understanding of the document.\n5.  **Creates GitHub Issues**: The script parses the structured task list from Gemini's response and creates a GitHub issue for each task. Each issue is automatically titled, assigned to the new milestone, and includes a description and references to the parent Epic and spec file.\n\n### Step 6: Verify Issue Creation\n\nAfter the script completes, review the newly created issues in your milestone.\n\n```bash\ngh issue list --milestone \"Your Sprint Name\"\n```\n\n### Step 7: Review Created Issues with User\n\nWalk through the AI-generated issues with your team. The generated tasks provide a strong baseline, but you should review them to confirm completeness, adjust priorities, and make any necessary refinements.\n\n## Error Handling\n\n### jq or Gemini Not Installed\n\n**Symptom**: Script reports that `jq` or `gemini` command is not found.\n**Solution**: Install the required tool and ensure it's in your system's PATH.\n\n### No Approved Epics Found\n\n**Symptom**: Script reports no epics in the approved backlog.\n**Solution**: Ensure your Epics are in the correct status column on your project board.\n\n### Epic Body Missing Spec Reference\n\n**Symptom**: Script cannot find a spec file path in the Epic's body.\n**Solution**: Edit the Epic's issue body on GitHub to include a valid path to a spec file (e.g., `docs/specs/my-feature.md`).\n\n### Gemini CLI Issues\n\n**Symptom**: The script fails during the task decomposition step with an error from the `gemini` command.\n**Solution**:\n- Ensure the `gemini` CLI is installed and authenticated (`gemini auth`).\n- Check for API outages or network issues.\n- The quality of the task breakdown depends on a functional Gemini CLI.\n\n## Notes\n\n- **Intelligent Decomposition**: The skill no longer relies on a rigid task format in spec files. Gemini reads and understands the document to create tasks.\n- **LLM guides strategy, script executes**: You decide which spec to plan; the script uses AI to handle the tedious decomposition and issue creation.\n- **One epic per run**: Run the script once for each Epic you want to plan for the sprint.\n- **Traceability is built-in**: Each created task issue automatically references the parent Epic and the source spec file.\n- **Manual refinement is expected**: The AI-generated task list is a starting point. Review and adjust it with your team."
      },
      "plugins": [
        {
          "name": "synthesisflow-skills",
          "description": "SynthesisFlow: Modular skills for spec-driven development with hybrid LLM-guided + helper-script architecture",
          "source": "./skills",
          "strict": false,
          "skills": [
            "./project-init",
            "./project-migrate",
            "./prd-authoring",
            "./doc-indexer",
            "./spec-authoring",
            "./sprint-planner",
            "./issue-executor",
            "./change-integrator",
            "./agent-integrator"
          ],
          "categories": [],
          "install_commands": [
            "/plugin marketplace add bodangren/git-workflow",
            "/plugin install synthesisflow-skills@bodangren-skills"
          ]
        }
      ]
    }
  ]
}